{"id": "2507.13476", "categories": ["cs.NI"], "pdf": "https://arxiv.org/pdf/2507.13476", "abs": "https://arxiv.org/abs/2507.13476", "authors": ["Jaber Daneshamooz", "Jessica Nguyen", "William Chen", "Sanjay Chandrasekaran", "Satyandra Guthula", "Ankit Gupta", "Arpit Gupta", "Walter Willinger"], "title": "Addressing the ML Domain Adaptation Problem for Networking: Realistic and Controllable Training Data Generation with NetReplica", "comment": null, "summary": "Machine learning models in networking suffer from the domain adaptation\nproblem; models trained in one domain often fail when deployed in different\nproduction environments. This paper presents the design and implementation of\nNetReplica, a system that addresses this challenge by generating training\ndatasets with two critical properties: realism in protocol dynamics and\ncontrollability of network conditions. NetReplica models networks as\ncollections of bottleneck links with specific attributes, achieves realism by\nleveraging production network traces, and enables controllability through fine\ngrained control knobs for each link attribute. Our evaluation using Puffer\ndemonstrates that NetReplica not only matches existing data characteristics but\ngenerates realistic samples that are underrepresented in or absent from Puffer\ndata. Models trained on NetReplica augmented datasets show substantially\nimproved generalizability, reducing transmission time prediction error by up to\n47% for challenging network conditions compared to models trained solely on\nPuffer data. This work represents a significant step toward solving the domain\nadaptation problem that has limited the effectiveness of ML based networking\nsystems.", "AI": {"tldr": "NetReplica\u901a\u8fc7\u751f\u6210\u771f\u5b9e\u4e14\u53ef\u63a7\u7684\u8bad\u7ec3\u6570\u636e\uff0c\u663e\u8457\u63d0\u5347\u7f51\u7edc\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u89e3\u51b3\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7f51\u7edc\u9886\u57df\u4e2d\u56e0\u73af\u5883\u53d8\u5316\u5bfc\u81f4\u7684\u9886\u57df\u9002\u5e94\u95ee\u9898\u3002", "method": "NetReplica\u5c06\u7f51\u7edc\u5efa\u6a21\u4e3a\u5177\u6709\u7279\u5b9a\u5c5e\u6027\u7684\u74f6\u9888\u94fe\u8def\u96c6\u5408\uff0c\u5229\u7528\u751f\u4ea7\u7f51\u7edc\u75d5\u8ff9\u5b9e\u73b0\u771f\u5b9e\u6027\uff0c\u5e76\u901a\u8fc7\u7ec6\u7c92\u5ea6\u7684\u94fe\u8def\u5c5e\u6027\u63a7\u5236\u5b9e\u73b0\u53ef\u63a7\u6027\u3002", "result": "\u4f7f\u7528NetReplica\u589e\u5f3a\u7684\u6570\u636e\u96c6\u8bad\u7ec3\u7684\u6a21\u578b\u5728\u6311\u6218\u6027\u7f51\u7edc\u6761\u4ef6\u4e0b\u4f20\u8f93\u65f6\u95f4\u9884\u6d4b\u8bef\u5dee\u964d\u4f4e\u4e8647%\u3002", "conclusion": "NetReplica\u901a\u8fc7\u751f\u6210\u5177\u6709\u771f\u5b9e\u6027\u548c\u53ef\u63a7\u6027\u7684\u8bad\u7ec3\u6570\u636e\u96c6\uff0c\u663e\u8457\u63d0\u5347\u4e86\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5728\u7f51\u7edc\u9886\u57df\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4e3a\u89e3\u51b3\u9886\u57df\u9002\u5e94\u95ee\u9898\u8fc8\u51fa\u4e86\u91cd\u8981\u4e00\u6b65\u3002"}}
{"id": "2507.13522", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.13522", "abs": "https://arxiv.org/abs/2507.13522", "authors": ["Ankit Bhardwaj", "Weiyang Wang", "Jeremy Carin", "Adam Belay", "Manya Ghobadi"], "title": "Checkmate: Zero-Overhead Model Checkpointing via Network Gradient Replication", "comment": "18 pages, 11 figures", "summary": "This paper presents Checkmate, a system that enables per-iteration\ncheckpointing in DNN training without any training slowdown. The traditional\napproach to checkpointing requires a pause in training to copy model states to\na separate location, allowing the state to be restored in the event of failure.\nThis approach fundamentally has a tradeoff between the frequency of checkpoints\nand the cost of a failure. We avoid this tradeoff; our key insight is that in\ndata-parallel training, all information necessary to create a checkpoint\nalready exists in the network as gradients. Our core contribution is a new\nmulticast abstraction that simultaneously delivers gradients to a separate\nCPU-based shadow cluster. The shadow maintains a checkpoint by applying those\ngradients to a copy of the model. Our evaluation shows that Checkmate performs\nper-iteration checkpointing with training throughput comparable to an ideal\nno-checkpoint baseline. Checkmate achieves 5 to 34.5x more frequent\ncheckpointing compared to state-of-the-art checkpointing systems, resulting in\n80% to 97.1% reduction in repeated work per failure. At the same checkpointing\nfrequency, Checkmate delivers 1.3x to 6.5x throughput compared to other\nsystems.", "AI": {"tldr": "Checkmate \u662f\u4e00\u79cd\u65e0\u9700\u8bad\u7ec3\u51cf\u901f\u7684 DNN \u8bad\u7ec3\u68c0\u67e5\u70b9\u7cfb\u7edf\uff0c\u901a\u8fc7\u68af\u5ea6\u591a\u64ad\u5b9e\u73b0\u9ad8\u6548\u68c0\u67e5\u70b9\uff0c\u663e\u8457\u63d0\u5347\u68c0\u67e5\u70b9\u9891\u7387\u548c\u541e\u5410\u91cf\u3002", "motivation": "\u4f20\u7edf\u68c0\u67e5\u70b9\u65b9\u6cd5\u9700\u8981\u5728\u8bad\u7ec3\u6682\u505c\u65f6\u590d\u5236\u6a21\u578b\u72b6\u6001\uff0c\u5b58\u5728\u68c0\u67e5\u70b9\u9891\u7387\u4e0e\u5931\u8d25\u6210\u672c\u4e4b\u95f4\u7684\u6743\u8861\uff0cCheckmate \u65e8\u5728\u907f\u514d\u8fd9\u79cd\u6743\u8861\u3002", "method": "\u5229\u7528\u6570\u636e\u5e76\u884c\u8bad\u7ec3\u4e2d\u7684\u68af\u5ea6\u4fe1\u606f\uff0c\u901a\u8fc7\u591a\u64ad\u62bd\u8c61\u5c06\u68af\u5ea6\u540c\u65f6\u4f20\u9012\u5230\u57fa\u4e8e CPU \u7684\u5f71\u5b50\u96c6\u7fa4\uff0c\u5f71\u5b50\u96c6\u7fa4\u901a\u8fc7\u5e94\u7528\u68af\u5ea6\u7ef4\u62a4\u6a21\u578b\u526f\u672c\u4f5c\u4e3a\u68c0\u67e5\u70b9\u3002", "result": "Checkmate \u5b9e\u73b0\u4e86\u4e0e\u7406\u60f3\u65e0\u68c0\u67e5\u70b9\u57fa\u7ebf\u76f8\u5f53\u7684\u8bad\u7ec3\u541e\u5410\u91cf\uff0c\u68c0\u67e5\u70b9\u9891\u7387\u6bd4\u73b0\u6709\u7cfb\u7edf\u9ad8 5 \u81f3 34.5 \u500d\uff0c\u6bcf\u6b21\u5931\u8d25\u7684\u91cd\u590d\u5de5\u4f5c\u91cf\u51cf\u5c11 80% \u81f3 97.1%\u3002", "conclusion": "Checkmate \u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u7684\u591a\u64ad\u62bd\u8c61\u548c\u68af\u5ea6\u5e94\u7528\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u65e0\u9700\u8bad\u7ec3\u51cf\u901f\u7684\u6bcf\u8fed\u4ee3\u68c0\u67e5\u70b9\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u67e5\u70b9\u9891\u7387\u5e76\u51cf\u5c11\u4e86\u91cd\u590d\u5de5\u4f5c\u91cf\u3002"}}
{"id": "2507.13676", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.13676", "abs": "https://arxiv.org/abs/2507.13676", "authors": ["Cheng Jiang", "Yihe Yan", "Yanxiang Wang", "Jiawei Hu", "Chun Tung Chou", "Wen Hu"], "title": "CARTS: Cooperative and Adaptive Resource Triggering and Stitching for 5G ISAC", "comment": null, "summary": "This paper presents CARTS, an adaptive 5G uplink sensing scheme designed to\nprovide Integrated Sensing and Communication (ISAC) services. The performance\nof both communication and sensing fundamentally depends on the availability of\naccurate and up-to-date channel state information (CSI). In modern 5G networks,\nuplink CSI is derived from two reference signals: the demodulation reference\nsignal (DMRS) and the sounding reference signal (SRS). However, current base\nstation implementations treat these CSI measurements as separate information\nstreams. The key innovation of CARTS is to fuse these two CSI streams, thereby\nincreasing the frequency of CSI updates and extending sensing opportunities to\nmore users. CARTS addresses two key challenges: (i) a novel channel stitching\nand compensation method that integrates asynchronous CSI estimates from DMRS\nand SRS, despite their different time and frequency allocations, and (ii) a\nreal-time SRS triggering algorithm that complements the inherently\nuncontrollable DMRS schedule, ensuring sufficient and non-redundant sensing\nopportunities for all users. Our trace-driven evaluation shows that CARTS\nsignificantly improves scalability, achieving a channel estimation error (NMSE)\nof 0.167 and UE tracking accuracy of 85 cm while supporting twice the number of\nusers as a periodic SRS-only baseline with similar performance. By\nopportunistically combining DMRS and SRS, CARTS therefore provides a practical,\nstandard-compliant solution to improve CSI availability for ISAC without\nrequiring additional radio resources.", "AI": {"tldr": "CARTS\u662f\u4e00\u79cd\u81ea\u9002\u5e945G\u4e0a\u884c\u611f\u77e5\u65b9\u6848\uff0c\u901a\u8fc7\u878d\u5408DMRS\u548cSRS\u7684CSI\u6d41\uff0c\u63d0\u5347ISAC\u6027\u80fd\uff0c\u652f\u6301\u66f4\u591a\u7528\u6237\u4e14\u65e0\u9700\u989d\u5916\u8d44\u6e90\u3002", "motivation": "\u73b0\u4ee35G\u7f51\u7edc\u4e2d\uff0c\u4e0a\u884cCSI\u6765\u81eaDMRS\u548cSRS\uff0c\u4f46\u5f53\u524d\u57fa\u7ad9\u5b9e\u73b0\u5c06\u5b83\u4eec\u89c6\u4e3a\u72ec\u7acb\u4fe1\u606f\u6d41\uff0c\u9650\u5236\u4e86CSI\u66f4\u65b0\u9891\u7387\u548c\u611f\u77e5\u673a\u4f1a\u3002CARTS\u65e8\u5728\u878d\u5408\u8fd9\u4e24\u4e2aCSI\u6d41\u4ee5\u63d0\u5347\u6027\u80fd\u3002", "method": "CARTS \u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u4fe1\u9053\u62fc\u63a5\u548c\u8865\u507f\u65b9\u6cd5\uff0c\u6574\u5408\u4e86\u6765\u81eaDMRS\u548cSRS\u7684\u5f02\u6b65CSI\u4f30\u8ba1\uff0c\u4ee5\u53ca\u5b9e\u65f6SRS\u89e6\u53d1\u7b97\u6cd5\u3002", "result": "CARTS\u663e\u8457\u63d0\u5347\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u5b9e\u73b0\u4e860.167\u7684\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u548c85\u5398\u7c73\u7684UE\u8ddf\u8e2a\u7cbe\u5ea6\uff0c\u652f\u6301\u7684\u7528\u6237\u6570\u662f\u4ec5\u4f7f\u7528\u5468\u671f\u6027SRS\u57fa\u51c6\u7684\u4e24\u500d\u3002", "conclusion": "CARTS \u63d0\u4f9b\u4e86\u4e00\u79cd\u7b26\u5408\u6807\u51c6\u7684\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u878d\u5408DMRS\u548cSRS\u7684CSI\u6d41\uff0c\u63d0\u9ad8\u4e86ISAC\u7684CSI\u53ef\u7528\u6027\uff0c\u4e14\u65e0\u9700\u989d\u5916\u7684\u65e0\u7ebf\u8d44\u6e90\u3002"}}
{"id": "2507.13601", "categories": ["cs.DC", "cs.ET", "cs.PF", "90B36, 90C27, 68M14, 68W40", "C.1.2; C.1.4; C.3.1; D.1.3; G.1.6"], "pdf": "https://arxiv.org/pdf/2507.13601", "abs": "https://arxiv.org/abs/2507.13601", "authors": ["Jorge Villarrubia", "Luis Costero", "Francisco D. Igual", "Katzalin Olcoz"], "title": "Leveraging Multi-Instance GPUs through moldable task scheduling", "comment": null, "summary": "NVIDIA MIG (Multi-Instance GPU) allows partitioning a physical GPU into\nmultiple logical instances with fully-isolated resources, which can be\ndynamically reconfigured. This work highlights the untapped potential of MIG\nthrough moldable task scheduling with dynamic reconfigurations. Specifically,\nwe propose a makespan minimization problem for multi-task execution under MIG\nconstraints. Our profiling shows that assuming monotonicity in task work with\nrespect to resources is not viable, as is usual in multicore scheduling.\nRelying on a state-of-the-art proposal that does not require such an\nassumption, we present FAR, a 3-phase algorithm to solve the problem. Phase 1\nof FAR builds on a classical task moldability method, phase 2 combines Longest\nProcessing Time First and List Scheduling with a novel repartitioning tree\nheuristic tailored to MIG constraints, and phase 3 employs local search via\ntask moves and swaps. FAR schedules tasks in batches offline, concatenating\ntheir schedules on the fly in an improved way that favors resource reuse.\nExcluding reconfiguration costs, the List Scheduling proof shows an\napproximation factor of 7/4 on the NVIDIA A30 model. We adapt the technique to\nthe particular constraints of an NVIDIA A100/H100 to obtain an approximation\nfactor of 2. Including the reconfiguration cost, our real-world experiments\nreveal a makespan with respect to the optimum no worse than 1.22x for a\nwell-known suite of benchmarks, and 1.10x for synthetic inputs inspired by real\nkernels. We obtain good experimental results for each batch of tasks, but also\nin the concatenation of batches, with large improvements over the\nstate-of-the-art and proposals without GPU reconfiguration. Beyond the\nalgorithm, the paper demonstrates the research potential of the MIG technology\nand suggests useful metrics, workload characterizations and evaluation\ntechniques for future work in this field.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFAR\u7b97\u6cd5\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5\u65b9\u6cd5\u4f18\u5316NVIDIA MIG\u7684\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u4efb\u52a1\u8c03\u5ea6\uff0c\u663e\u8457\u964d\u4f4e\u4e86makespan\uff0c\u5e76\u5c55\u793a\u4e86MIG\u6280\u672f\u7684\u7814\u7a76\u6f5c\u529b\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u63a2\u7d22NVIDIA MIG\u6280\u672f\u901a\u8fc7\u52a8\u6001\u91cd\u65b0\u914d\u7f6e\u8fdb\u884c\u53ef\u5851\u6027\u4efb\u52a1\u8c03\u5ea6\u7684\u672a\u5f00\u53d1\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u5728MIG\u7ea6\u675f\u4e0b\u591a\u4efb\u52a1\u6267\u884c\u7684makespan\u6700\u5c0f\u5316\u95ee\u9898\u3002", "method": "\u6211\u4eec\u63d0\u51fa\u4e86FAR\u7b97\u6cd5\uff0c\u4e00\u4e2a\u5206\u4e09\u9636\u6bb5\u89e3\u51b3\u95ee\u9898\u7684\u65b9\u6cd5\u3002\u7b2c\u4e00\u9636\u6bb5\u57fa\u4e8e\u7ecf\u5178\u7684\u4efb\u52a1\u53ef\u5851\u6027\u65b9\u6cd5\uff0c\u7b2c\u4e8c\u9636\u6bb5\u7ed3\u5408\u4e86\u6700\u957f\u5904\u7406\u65f6\u95f4\u4f18\u5148\u548c\u5217\u8868\u8c03\u5ea6\uff0c\u5e76\u5f15\u5165\u4e86\u9488\u5bf9MIG\u7ea6\u675f\u7684\u65b0\u9896\u91cd\u65b0\u5206\u533a\u6811\u542f\u53d1\u5f0f\u65b9\u6cd5\uff0c\u7b2c\u4e09\u9636\u6bb5\u901a\u8fc7\u4efb\u52a1\u79fb\u52a8\u548c\u4ea4\u6362\u8fdb\u884c\u5c40\u90e8\u641c\u7d22\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cFAR\u7b97\u6cd5\u5728\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cmakespan\u76f8\u5bf9\u4e8e\u6700\u4f18\u89e3\u7684\u6bd4\u7387\u4e0d\u8d85\u8fc71.22\u500d\uff08\u5df2\u77e5\u57fa\u51c6\u6d4b\u8bd5\uff09\u548c1.10\u500d\uff08\u53d7\u771f\u5b9e\u5185\u6838\u542f\u53d1\u7684\u5408\u6210\u8f93\u5165\uff09\u3002", "conclusion": "\u672c\u6587\u5c55\u793a\u4e86MIG\u6280\u672f\u7684\u7814\u7a76\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u8be5\u9886\u57df\u672a\u6765\u5de5\u4f5c\u4e2d\u6709\u7528\u7684\u6307\u6807\u3001\u5de5\u4f5c\u8d1f\u8f7d\u7279\u5f81\u548c\u8bc4\u4f30\u6280\u672f\u3002"}}
{"id": "2507.13717", "categories": ["cs.NI", "C.2.3"], "pdf": "https://arxiv.org/pdf/2507.13717", "abs": "https://arxiv.org/abs/2507.13717", "authors": ["Yingming Mao", "Qiaozhu Zhai", "Zhen Yao", "Xia Zhu", "Ximeng Liu", "Xinchi Han"], "title": "ATRO: A Fast Solver-Free Algorithm for Topology and Routing Optimization of Reconfigurable Datacenter Networks", "comment": null, "summary": "The growing scale and complexity of reconfigurable data center networks\n(DCNs) demand more scalable and efficient algorithms for computing logical\ntopologies and routing. Reconfigurable DCNs typically operate in two modes:\none-hop configurations that require frequent topology optimization (TO), and\nmulti-hop scenarios that involve joint topology and routing optimization (TRO).\nIn both cases, the combinatorial nature of topology decisions makes it\ndifficult for existing methods to balance solution quality and runtime\nefficiency. To address this, we introduce Alternating Topology and Routing\nOptimization (ATRO), a solver-free framework that alternates between TO and\nrouting optimization (RO). This decomposition exploits two key insights: first,\neach alternating update step monotonically reduces maximum link utilization\n(MLU), ensuring consistent performance improvement across iterations; second,\nthe TO subproblem, equivalent to one-hop optimization, exhibits a monotonic\nstructure that enables optimal solutions via an efficient Accelerated Binary\nSearch Method (ABSM). To preserve the solver-free design, RO is solved using\nexisting Traffic Engineering accelerators. ATRO attains the global optimum in\none-hop scenarios and significantly outperforms baselines in multi-hop settings\nin terms of both runtime and solution quality. Evaluations confirm its\nscalability and robustness across diverse DCNs.", "AI": {"tldr": "ATRO\u662f\u4e00\u4e2a\u65e0\u9700\u6c42\u89e3\u5668\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u62d3\u6251\u548c\u8def\u7531\uff0c\u663e\u8457\u63d0\u5347\u53ef\u91cd\u6784\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\u7684\u6548\u7387\u548c\u6027\u80fd\u3002", "motivation": "\u9762\u5bf9\u53ef\u91cd\u6784\u6570\u636e\u4e2d\u5fc3\u7f51\u7edc\uff08DCNs\uff09\u7684\u89c4\u6a21\u548c\u590d\u6742\u6027\u589e\u52a0\uff0c\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5e73\u8861\u89e3\u7684\u8d28\u91cf\u548c\u8fd0\u884c\u6548\u7387\u3002", "method": "ATRO\u6846\u67b6\u901a\u8fc7\u4ea4\u66ff\u8fdb\u884c\u62d3\u6251\u4f18\u5316\uff08TO\uff09\u548c\u8def\u7531\u4f18\u5316\uff08RO\uff09\uff0c\u5229\u7528\u52a0\u901f\u4e8c\u5206\u641c\u7d22\u65b9\u6cd5\uff08ABSM\uff09\u9ad8\u6548\u89e3\u51b3TO\u5b50\u95ee\u9898\uff0c\u5e76\u4f7f\u7528\u73b0\u6709\u6d41\u91cf\u5de5\u7a0b\u52a0\u901f\u5668\u89e3\u51b3RO\u3002", "result": "ATRO\u5728\u5355\u8df3\u548c\u591a\u8df3\u573a\u666f\u4e2d\u5747\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u6700\u5927\u94fe\u8def\u5229\u7528\u7387\uff08MLU\uff09\uff0c\u5e76\u5728\u591a\u6837\u5316\u7684DCNs\u4e2d\u9a8c\u8bc1\u4e86\u5176\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "ATRO\u5728\u5355\u8df3\u573a\u666f\u4e0b\u8fbe\u5230\u5168\u5c40\u6700\u4f18\uff0c\u5e76\u5728\u591a\u8df3\u8bbe\u7f6e\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u8868\u73b0\u51fa\u826f\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002"}}
{"id": "2507.13833", "categories": ["cs.DC"], "pdf": "https://arxiv.org/pdf/2507.13833", "abs": "https://arxiv.org/abs/2507.13833", "authors": ["Zhixin Wang", "Tianyi Zhou", "Liming Liu", "Ao Li", "Jiarui Hu", "Dian Yang", "Jinlong Hou", "Siyuan Feng", "Yuan Cheng", "Yuan Qi"], "title": "DistFlow: A Fully Distributed RL Framework for Scalable and Efficient LLM Post-Training", "comment": null, "summary": "Reinforcement learning (RL) has become the pivotal post-training technique\nfor large language model. Effectively scaling reinforcement learning is now the\nkey to unlocking advanced reasoning capabilities and ensuring safe,\ngoal-aligned behavior in the most powerful LLMs. Mainstream frameworks usually\nemploy a hybrid-controller architecture where a single-controller dispatches\nthe overall execution logic and manages overall data transfer and the\nmulti-controller executes distributed computation. For large-scale\nreinforcement learning, minor load imbalances can introduce significant\nbottlenecks, ultimately constraining the scalability of the system. To address\nthis limitation, we introduce DistFlow, a novel, fully distributed RL framework\ndesigned to break scaling barrier. We adopt a multi-controller paradigm that\ndispatches data transfer and execution tasks to all workers, which eliminates\nthe centralized node. This allows each worker to operate independently, leading\nto near-linear scalability up to thousands of GPUs and dramatic efficiency\ngains. Furthermore, our architecture decouples resource configuration from\nexecution logic, allowing each worker to have a unique execution flow, offering\nsignificant flexibility for rapid and cost-effective algorithmic\nexperimentation. Extensive experiments show that DistFlow achieves excellent\nlinear scalability and up to a 7x end-to-end throughput improvement over\nstate-of-the-art (SOTA) frameworks.", "AI": {"tldr": "DistFlow \u662f\u4e00\u79cd\u65b0\u578b\u5168\u5206\u5e03\u5f0f\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u63a7\u5236\u5668\u67b6\u6784\u89e3\u51b3\u6269\u5c55\u74f6\u9888\uff0c\u5b9e\u73b0\u9ad8\u6548\u3001\u7075\u6d3b\u7684\u5927\u89c4\u6a21\u8bad\u7ec3\u3002", "motivation": "\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u4e2d\u5fae\u5c0f\u7684\u8d1f\u8f7d\u4e0d\u5e73\u8861\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u74f6\u9888\uff0c\u9650\u5236\u7cfb\u7edf\u6269\u5c55\u6027\u3002", "method": "\u91c7\u7528\u591a\u63a7\u5236\u5668\u8303\u5f0f\uff0c\u5c06\u6570\u636e\u4f20\u8f93\u548c\u6267\u884c\u4efb\u52a1\u5206\u914d\u7ed9\u6240\u6709\u5de5\u4f5c\u8282\u70b9\uff0c\u6d88\u9664\u4e2d\u5fc3\u8282\u70b9\uff0c\u4f7f\u6bcf\u4e2a\u5de5\u4f5c\u8282\u70b9\u80fd\u72ec\u7acb\u8fd0\u884c\u3002", "result": "DistFlow \u5b9e\u73b0\u4e86\u8fd1\u7ebf\u6027\u7684\u6269\u5c55\u6027\uff0c\u7aef\u5230\u7aef\u541e\u5410\u91cf\u6bd4\u73b0\u6709\u6700\u4f73\u6846\u67b6\u63d0\u9ad8\u4e867\u500d\u3002", "conclusion": "DistFlow \u901a\u8fc7\u5176\u5168\u5206\u5e03\u5f0f\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u5927\u89c4\u6a21\u5f3a\u5316\u5b66\u4e60\u4e2d\u7684\u8d1f\u8f7d\u5747\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u8fd1\u7ebf\u6027\u7684\u6269\u5c55\u6027\u548c\u663e\u8457\u7684\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2507.13889", "categories": ["cs.NI", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.13889", "abs": "https://arxiv.org/abs/2507.13889", "authors": ["Bilal Karaman", "Ilhan Basturk", "Ferdi Kara", "Metin Ozturk", "Sezai Taskin", "Halil Yanikomeroglu"], "title": "On the Trade-Off Between Sum-Rate and Energy Efficiency through the Convergence of HAPS and Active RIS Technologies", "comment": "accepted in PIMRC2025", "summary": "This paper investigates the integration of active reconfigurable intelligent\nsurfaces (RIS) relay with high-altitude platform stations (HAPS) to enhance\nnon-terrestrial network (NTN) performance in next-generation wireless systems.\nWhile prior studies focused on passive RIS architectures, the severe path loss\nand double fading in long-distance HAPS links make active RIS a more suitable\nalternative due to its inherent signal amplification capabilities. We formulate\na sum-rate maximization problem to jointly optimize power allocation and RIS\nelement assignment for ground user equipments (UEs) supported by a HAPS-based\nactive RIS-assisted communication system. To reduce power consumption and\nhardware complexity, several sub-connected active RIS architectures are also\nexplored. Simulation results reveal that active RIS configurations\nsignificantly outperform passive RIS in terms of quality of service (QoS).\nMoreover, although fully-connected architectures achieve the highest\nthroughput, sub-connected schemes demonstrate superior energy efficiency under\npractical power constraints. These findings highlight the potential of active\nRIS-enabled HAPS systems to meet the growing demands of beyond-cellular\ncoverage and green networking.", "AI": {"tldr": "Active RIS with HAPS enhances NTN performance by addressing path loss and double fading, outperforming passive RIS in QoS and energy efficiency.", "motivation": "The severe path loss and double fading in long-distance HAPS links make passive RIS architectures less effective, prompting the investigation of active RIS due to its inherent signal amplification capabilities.", "method": "The study formulates a sum-rate maximization problem to jointly optimize power allocation and RIS element assignment for ground UEs supported by a HAPS-based active RIS-assisted communication system. It also explores sub-connected active RIS architectures to reduce power consumption and hardware complexity.", "result": "Simulation results show that active RIS configurations significantly outperform passive RIS in QoS, with sub-connected schemes demonstrating superior energy efficiency under practical power constraints, despite fully-connected architectures achieving the highest throughput.", "conclusion": "This paper highlights the potential of active RIS-enabled HAPS systems to meet the demands of beyond-cellular coverage and green networking, demonstrating superior energy efficiency under practical power constraints."}}
{"id": "2507.14069", "categories": ["cs.DC", "cs.AI", "cs.ET", "cs.NE"], "pdf": "https://arxiv.org/pdf/2507.14069", "abs": "https://arxiv.org/abs/2507.14069", "authors": ["Shuiguang Deng", "Di Yu", "Changze Lv", "Xin Du", "Linshan Jiang", "Xiaofan Zhao", "Wentao Tong", "Xiaoqing Zheng", "Weijia Fang", "Peng Zhao", "Gang Pan", "Schahram Dustdar", "Albert Y. Zomaya"], "title": "Edge Intelligence with Spiking Neural Networks", "comment": "This work has been submitted to Proceeding of IEEE for possible\n  publication", "summary": "The convergence of artificial intelligence and edge computing has spurred\ngrowing interest in enabling intelligent services directly on\nresource-constrained devices. While traditional deep learning models require\nsignificant computational resources and centralized data management, the\nresulting latency, bandwidth consumption, and privacy concerns have exposed\ncritical limitations in cloud-centric paradigms. Brain-inspired computing,\nparticularly Spiking Neural Networks (SNNs), offers a promising alternative by\nemulating biological neuronal dynamics to achieve low-power, event-driven\ncomputation. This survey provides a comprehensive overview of Edge Intelligence\nbased on SNNs (EdgeSNNs), examining their potential to address the challenges\nof on-device learning, inference, and security in edge scenarios. We present a\nsystematic taxonomy of EdgeSNN foundations, encompassing neuron models,\nlearning algorithms, and supporting hardware platforms. Three representative\npractical considerations of EdgeSNN are discussed in depth: on-device inference\nusing lightweight SNN models, resource-aware training and updating under\nnon-stationary data conditions, and secure and privacy-preserving issues.\nFurthermore, we highlight the limitations of evaluating EdgeSNNs on\nconventional hardware and introduce a dual-track benchmarking strategy to\nsupport fair comparisons and hardware-aware optimization. Through this study,\nwe aim to bridge the gap between brain-inspired learning and practical edge\ndeployment, offering insights into current advancements, open challenges, and\nfuture research directions. To the best of our knowledge, this is the first\ndedicated and comprehensive survey on EdgeSNNs, providing an essential\nreference for researchers and practitioners working at the intersection of\nneuromorphic computing and edge intelligence.", "AI": {"tldr": "\u672c\u6587\u662f\u5173\u4e8e\u57fa\u4e8e\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\uff08SNNs\uff09\u7684\u8fb9\u7f18\u667a\u80fd\uff08EdgeSNNs\uff09\u7684\u9996\u7bc7\u5168\u9762\u7efc\u8ff0\uff0c\u63a2\u8ba8\u4e86\u5176\u5728\u8bbe\u5907\u4e0a\u5b66\u4e60\u3001\u63a8\u7406\u548c\u5b89\u5168\u6027\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "\u4eba\u5de5\u667a\u80fd\u4e0e\u8fb9\u7f18\u8ba1\u7b97\u7684\u878d\u5408\u6fc0\u53d1\u4e86\u5bf9\u8d44\u6e90\u53d7\u9650\u8bbe\u5907\u4e0a\u76f4\u63a5\u63d0\u4f9b\u667a\u80fd\u670d\u52a1\u7684\u5174\u8da3\u3002\u4f20\u7edf\u7684\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u5b58\u5728\u5ef6\u8fdf\u3001\u5e26\u5bbd\u6d88\u8017\u548c\u9690\u79c1\u95ee\u9898\uff0c\u800c\u8111\u542f\u53d1\u8ba1\u7b97\uff08\u5982SNNs\uff09\u901a\u8fc7\u6a21\u62df\u751f\u7269\u795e\u7ecf\u5143\u52a8\u6001\u63d0\u4f9b\u4e86\u4e00\u79cd\u4f4e\u529f\u8017\u3001\u4e8b\u4ef6\u9a71\u52a8\u7684\u8ba1\u7b97\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u672c\u6587\u63d0\u4f9b\u4e86\u57fa\u4e8eSNNs\u7684\u8fb9\u7f18\u667a\u80fd\uff08EdgeSNNs\uff09\u7684\u7cfb\u7edf\u5206\u7c7b\uff0c\u5305\u62ec\u795e\u7ecf\u5143\u6a21\u578b\u3001\u5b66\u4e60\u7b97\u6cd5\u548c\u652f\u6301\u7684\u786c\u4ef6\u5e73\u53f0\uff0c\u5e76\u6df1\u5165\u8ba8\u8bba\u4e86\u4e09\u4e2a\u5b9e\u9645\u8003\u8651\u56e0\u7d20\uff1a\u8f7b\u91cf\u7ea7SNN\u6a21\u578b\u7684\u8bbe\u5907\u4e0a\u63a8\u7406\u3001\u975e\u5e73\u7a33\u6570\u636e\u6761\u4ef6\u4e0b\u7684\u8d44\u6e90\u611f\u77e5\u8bad\u7ec3\u548c\u66f4\u65b0\uff0c\u4ee5\u53ca\u5b89\u5168\u548c\u9690\u79c1\u4fdd\u62a4\u95ee\u9898\u3002", "result": "\u672c\u6587\u4ecb\u7ecd\u4e86EdgeSNNs\u7684\u6f5c\u529b\uff0c\u5e76\u63d0\u51fa\u4e86\u53cc\u8f68\u57fa\u51c6\u6d4b\u8bd5\u7b56\u7565\u4ee5\u652f\u6301\u516c\u5e73\u6bd4\u8f83\u548c\u786c\u4ef6\u611f\u77e5\u4f18\u5316\u3002", "conclusion": "\u8fd9\u7bc7\u7efc\u8ff0\u65e8\u5728\u5f25\u5408\u8111\u542f\u53d1\u5b66\u4e60\u4e0e\u5b9e\u9645\u8fb9\u7f18\u90e8\u7f72\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u4ece\u4e1a\u8005\u63d0\u4f9b\u4e86\u5173\u4e8eEdgeSNNs\u5f53\u524d\u8fdb\u5c55\u3001\u5f00\u653e\u6311\u6218\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u7684\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2507.13511", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13511", "abs": "https://arxiv.org/abs/2507.13511", "authors": ["Nabil Abdelaziz Ferhat Taleb", "Abdolazim Rezaei", "Raj Atulkumar Patel", "Mehdi Sookhak"], "title": "GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination", "comment": null, "summary": "Large Language Models (LLMs) offer significant promise for intelligent\ntraffic management; however, current chain-based systems like TrafficGPT are\nhindered by sequential task execution, high token usage, and poor scalability,\nmaking them inefficient for complex, real-world scenarios. To address these\nlimitations, we propose GraphTrafficGPT, a novel graph-based architecture,\nwhich fundamentally redesigns the task coordination process for LLM-driven\ntraffic applications. GraphTrafficGPT represents tasks and their dependencies\nas nodes and edges in a directed graph, enabling efficient parallel execution\nand dynamic resource allocation. The main idea behind the proposed model is a\nBrain Agent that decomposes user queries, constructs optimized dependency\ngraphs, and coordinates a network of specialized agents for data retrieval,\nanalysis, visualization, and simulation. By introducing advanced context-aware\ntoken management and supporting concurrent multi-query processing, the proposed\narchitecture handles interdependent tasks typical of modern urban mobility\nenvironments. Experimental results demonstrate that GraphTrafficGPT reduces\ntoken consumption by 50.2% and average response latency by 19.0% compared to\nTrafficGPT, while supporting simultaneous multi-query execution with up to\n23.0% improvement in efficiency.", "AI": {"tldr": "GraphTrafficGPT\u662f\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684LLM\u4ea4\u901a\u7ba1\u7406\u67b6\u6784\uff0c\u901a\u8fc7\u5e76\u884c\u4efb\u52a1\u5904\u7406\u548c\u52a8\u6001\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u6548\u7387\u548c\u6269\u5c55\u6027\u3002", "motivation": "\u73b0\u6709\u94fe\u5f0f\u7cfb\u7edf\uff08\u5982TrafficGPT\uff09\u5b58\u5728\u987a\u5e8f\u4efb\u52a1\u6267\u884c\u3001\u9ad8token\u6d88\u8017\u548c\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\uff0c\u96be\u4ee5\u5e94\u5bf9\u590d\u6742\u7684\u73b0\u5b9e\u4ea4\u901a\u573a\u666f\u3002", "method": "\u63d0\u51faGraphTrafficGPT\uff0c\u4e00\u79cd\u57fa\u4e8e\u56fe\u7684\u4efb\u52a1\u534f\u8c03\u67b6\u6784\uff0c\u901a\u8fc7Brain Agent\u5206\u89e3\u67e5\u8be2\u3001\u6784\u5efa\u4f9d\u8d56\u56fe\uff0c\u5e76\u534f\u8c03\u591a\u4e2a\u4e13\u4e1a\u4ee3\u7406\u8fdb\u884c\u6570\u636e\u5904\u7406\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cGraphTrafficGPT\u76f8\u6bd4TrafficGPT\u5728token\u6d88\u8017\u51cf\u5c1150.2%\uff0c\u54cd\u5e94\u5ef6\u8fdf\u964d\u4f4e19.0%\uff0c\u591a\u67e5\u8be2\u6548\u7387\u63d0\u534723.0%\u3002", "conclusion": "GraphTrafficGPT\u901a\u8fc7\u56fe\u57fa\u67b6\u6784\u663e\u8457\u63d0\u5347\u4e86LLM\u5728\u4ea4\u901a\u7ba1\u7406\u4e2d\u7684\u6548\u7387\uff0c\u51cf\u5c11\u4e8650.2%\u7684token\u6d88\u8017\u548c19.0%\u7684\u54cd\u5e94\u5ef6\u8fdf\uff0c\u540c\u65f6\u652f\u6301\u591a\u67e5\u8be2\u5e76\u884c\u5904\u7406\u3002"}}
{"id": "2507.13933", "categories": ["cs.NI", "cs.AI", "cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.13933", "abs": "https://arxiv.org/abs/2507.13933", "authors": ["Sichang \"Steven\" He", "Ramesh Govindan", "Harsha V. Madhyastha"], "title": "Preprint: Did I Just Browse A Website Written by LLMs?", "comment": "In submission. 2 pages. 3 figures", "summary": "Increasingly, web content is automatically generated by large language models\n(LLMs) with little human input. We call this \"LLM-dominant\" content. Since LLMs\nplagiarize and hallucinate, LLM-dominant content can be unreliable and\nunethical. Yet, websites rarely disclose such content, and human readers\nstruggle to distinguish it. Thus, we must develop reliable detectors for\nLLM-dominant content. However, state-of-the-art LLM detectors are insufficient,\nbecause they perform well mainly on clean, prose-like text, while web content\nhas complex markup and diverse genres.\n  We propose a highly reliable, scalable pipeline that classifies entire\nwebsites. Instead of naively classifying text extracted from each page, we\nclassify each site based on an LLM text detector's outputs of multiple\nprose-like pages. We train and evaluate our detector by collecting 2 distinct\nground truth datasets totaling 120 sites, and obtain 100% accuracies testing\nacross them. In the wild, we detect a sizable portion of sites as LLM-dominant\namong 10k sites in search engine results and 10k in Common Crawl archives. We\nfind LLM-dominant sites are growing in prevalence and rank highly in search\nresults, raising questions about their impact on end users and the overall Web\necosystem.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u68c0\u6d4bLLM-dominant\u7f51\u7ad9\u7684\u9ad8\u6548\u65b9\u6cd5\uff0c\u5e76\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u9a8c\u8bc1\u4e86\u5176100%\u7684\u51c6\u786e\u7387\uff0c\u53d1\u73b0\u6b64\u7c7b\u7f51\u7ad9\u5728\u7f51\u7edc\u4e2d\u7684\u5360\u6bd4\u548c\u6392\u540d\u6b63\u5728\u4e0a\u5347\u3002", "motivation": "\u7531\u4e8eLLM\u751f\u6210\u7684\u5185\u5bb9\u53ef\u80fd\u4e0d\u53ef\u9760\u4e14\u4e0d\u9053\u5fb7\uff0c\u4e14\u7f51\u7ad9\u5f88\u5c11\u62ab\u9732\u6b64\u7c7b\u5185\u5bb9\uff0c\u4eba\u7c7b\u8bfb\u8005\u96be\u4ee5\u533a\u5206\uff0c\u56e0\u6b64\u9700\u8981\u5f00\u53d1\u53ef\u9760\u7684LLM-dominant\u5185\u5bb9\u68c0\u6d4b\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u5ea6\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u6d41\u7a0b\uff0c\u901a\u8fc7\u57fa\u4e8e\u591a\u4e2a\u6563\u6587\u5f0f\u9875\u9762\u7684LLM\u6587\u672c\u68c0\u6d4b\u5668\u8f93\u51fa\u5bf9\u6574\u4e2a\u7f51\u7ad9\u8fdb\u884c\u5206\u7c7b\u3002", "result": "\u5728\u6536\u96c6\u7684\u4e24\u4e2a\u4e0d\u540c\u771f\u5b9e\u6570\u636e\u96c6\u4e2d\uff08\u5171120\u4e2a\u7f51\u7ad9\uff09\uff0c\u68c0\u6d4b\u5668\u8fbe\u5230\u4e86100%\u7684\u51c6\u786e\u7387\u3002\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\uff0c\u68c0\u6d4b\u5230\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u548cCommon Crawl\u5b58\u6863\u4e2d\u54041\u4e07\u4e2a\u7f51\u7ad9\u4e2d\u6709\u76f8\u5f53\u4e00\u90e8\u5206\u662fLLM-dominant\u3002", "conclusion": "LLM-dominant\u5185\u5bb9\u5728\u641c\u7d22\u5f15\u64ce\u7ed3\u679c\u548cCommon Crawl\u5b58\u6863\u4e2d\u5360\u636e\u76f8\u5f53\u6bd4\u4f8b\uff0c\u4e14\u589e\u957f\u8fc5\u901f\uff0c\u6392\u540d\u9760\u524d\uff0c\u8fd9\u5bf9\u7ec8\u7aef\u7528\u6237\u548c\u6574\u4e2a\u7f51\u7edc\u751f\u6001\u7cfb\u7edf\u7684\u5f71\u54cd\u503c\u5f97\u5173\u6ce8\u3002"}}
{"id": "2507.14080", "categories": ["cs.DC", "D.2.4; C.2.4"], "pdf": "https://arxiv.org/pdf/2507.14080", "abs": "https://arxiv.org/abs/2507.14080", "authors": ["Derek Leung", "Nickolai Zeldovich", "Frans Kaashoek"], "title": "Shipwright: Proving liveness of distributed systems with Byzantine participants", "comment": "14 pages, 13 figures", "summary": "Ensuring liveness in a decentralized system, such as PBFT, is critical,\nbecause there may not be any single administrator that can restart the system\nif it encounters a liveness bug. At the same time, liveness is challenging to\nachieve because any single participant could be malicious, and yet the overall\nsystem must make forward progress. While verification is a promising approach\nfor ensuring the absence of bugs, no prior work has been able to verify\nliveness for an executable implementation of PBFT.\n  Shipwright is a verification framework for proving correctness and liveness\nof distributed systems where some participants might be malicious. Shipwright\nintroduces three techniques that enable formal reasoning about decentralized\nsettings with malicious participants, allow developers to decompose their\nsystem and proof in a modular fashion into sub-protocols and sub-proofs, and\nsupport sound reasoning about cryptographic signatures that may be embedded in\nmessages. We used Shipwright to implement and verify an initial prototype of\nagreement on a single log entry in PBFT (with a few limitations) and translate\nit to an executable implementation in Go. We experimentally demonstrate its\noperation and liveness both in the common case and in several failure\nscenarios.", "AI": {"tldr": "Shipwright\u6846\u67b6\u901a\u8fc7\u4e09\u79cd\u65b0\u6280\u672f\u9a8c\u8bc1\u4e86PBFT\u7684\u6d3b\u6027\uff0c\u6210\u529f\u5b9e\u73b0\u5e76\u6d4b\u8bd5\u4e86\u5355\u4e2a\u65e5\u5fd7\u6761\u76ee\u534f\u8bae\u7684\u53ef\u6267\u884c\u7248\u672c\u3002", "motivation": "\u5728\u53bb\u4e2d\u5fc3\u5316\u7cfb\u7edf\u4e2d\u786e\u4fdd\u6d3b\u6027\uff08\u5982PBFT\uff09\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u5de5\u4f5c\u672a\u80fd\u9a8c\u8bc1\u53ef\u6267\u884cPBFT\u5b9e\u73b0\u7684\u6d3b\u6027\u3002", "method": "Shipwright\u5f15\u5165\u4e86\u4e09\u79cd\u6280\u672f\uff1a\u652f\u6301\u6076\u610f\u53c2\u4e0e\u8005\u7684\u5f62\u5f0f\u5316\u63a8\u7406\u3001\u6a21\u5757\u5316\u5206\u89e3\u7cfb\u7edf\u4e0e\u8bc1\u660e\u3001\u4ee5\u53ca\u652f\u6301\u52a0\u5bc6\u7b7e\u540d\u7684\u5408\u7406\u63a8\u7406\u3002", "result": "\u901a\u8fc7Shipwright\u6846\u67b6\uff0c\u5b9e\u73b0\u4e86PBFT\u4e2d\u5355\u4e2a\u65e5\u5fd7\u6761\u76ee\u534f\u8bae\u7684\u9a8c\u8bc1\uff0c\u5e76\u8f6c\u5316\u4e3aGo\u8bed\u8a00\u53ef\u6267\u884c\u5b9e\u73b0\u3002", "conclusion": "Shipwright\u6210\u529f\u9a8c\u8bc1\u4e86PBFT\u4e2d\u5173\u4e8e\u5355\u4e2a\u65e5\u5fd7\u6761\u76ee\u534f\u8bae\u7684\u521d\u59cb\u539f\u578b\uff0c\u5e76\u5c55\u793a\u4e86\u5176\u5728\u5e38\u89c1\u60c5\u51b5\u548c\u6545\u969c\u573a\u666f\u4e0b\u7684\u64cd\u4f5c\u548c\u6d3b\u6027\u3002"}}
{"id": "2507.13541", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13541", "abs": "https://arxiv.org/abs/2507.13541", "authors": ["Shuyue Stella Li", "Melanie Sclar", "Hunter Lang", "Ansong Ni", "Jacqueline He", "Puxin Xu", "Andrew Cohen", "Chan Young Park", "Yulia Tsvetkov", "Asli Celikyilmaz"], "title": "PrefPalette: Personalized Preference Modeling with Latent Attributes", "comment": "17 pages, 6 tables, 5 figures", "summary": "Personalizing AI systems requires understanding not just what users prefer,\nbut the reasons that underlie those preferences - yet current preference models\ntypically treat human judgment as a black box. We introduce PrefPalette, a\nframework that decomposes preferences into attribute dimensions and tailors its\npreference prediction to distinct social community values in a\nhuman-interpretable manner. PrefPalette operationalizes a cognitive science\nprinciple known as multi-attribute decision making in two ways: (1) a scalable\ncounterfactual attribute synthesis step that involves generating synthetic\ntraining data to isolate for individual attribute effects (e.g., formality,\nhumor, cultural values), and (2) attention-based preference modeling that\nlearns how different social communities dynamically weight these attributes.\nThis approach moves beyond aggregate preference modeling to capture the diverse\nevaluation frameworks that drive human judgment. When evaluated on 45 social\ncommunities from the online platform Reddit, PrefPalette outperforms GPT-4o by\n46.6% in average prediction accuracy. Beyond raw predictive improvements,\nPrefPalette also shed light on intuitive, community-specific profiles:\nscholarly communities prioritize verbosity and stimulation, conflict-oriented\ncommunities value sarcasm and directness, and support-based communities\nemphasize empathy. By modeling the attribute-mediated structure of human\njudgment, PrefPalette delivers both superior preference modeling and\ntransparent, interpretable insights, and serves as a first step toward more\ntrustworthy, value-aware personalized applications.", "AI": {"tldr": "PrefPalette\u662f\u4e00\u4e2a\u5206\u89e3\u504f\u597d\u4e3a\u5c5e\u6027\u7ef4\u5ea6\u5e76\u57fa\u4e8e\u793e\u533a\u52a8\u6001\u52a0\u6743\u7684\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u51c6\u786e\u7387\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u793e\u533a\u504f\u597d\u6d1e\u5bdf\u3002", "motivation": "\u5f53\u524d\u504f\u597d\u6a21\u578b\u901a\u5e38\u5c06\u4eba\u7c7b\u5224\u65ad\u89c6\u4e3a\u9ed1\u7bb1\uff0c\u800c\u4e2a\u6027\u5316AI\u7cfb\u7edf\u9700\u8981\u7406\u89e3\u7528\u6237\u504f\u597d\u7684\u539f\u56e0\u3002PrefPalette\u65e8\u5728\u5206\u89e3\u504f\u597d\u4e3a\u5c5e\u6027\u7ef4\u5ea6\uff0c\u5e76\u4ee5\u4eba\u7c7b\u53ef\u89e3\u91ca\u7684\u65b9\u5f0f\u4e3a\u4e0d\u540c\u793e\u4ea4\u793e\u533a\u5b9a\u5236\u504f\u597d\u9884\u6d4b\u3002", "method": "PrefPalette\u91c7\u7528\u591a\u5c5e\u6027\u51b3\u7b56\u8ba4\u77e5\u79d1\u5b66\u539f\u7406\uff0c\u901a\u8fc7\uff081\uff09\u53ef\u6269\u5c55\u7684\u53cd\u4e8b\u5b9e\u5c5e\u6027\u5408\u6210\u6b65\u9aa4\u751f\u6210\u5408\u6210\u8bad\u7ec3\u6570\u636e\u4ee5\u9694\u79bb\u5355\u4e2a\u5c5e\u6027\u6548\u5e94\uff0c\u548c\uff082\uff09\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u504f\u597d\u5efa\u6a21\uff0c\u5b66\u4e60\u4e0d\u540c\u793e\u4ea4\u793e\u533a\u5982\u4f55\u52a8\u6001\u52a0\u6743\u8fd9\u4e9b\u5c5e\u6027\u3002", "result": "\u5728Reddit\u768445\u4e2a\u793e\u4ea4\u793e\u533a\u8bc4\u4f30\u4e2d\uff0cPrefPalette\u7684\u5e73\u5747\u9884\u6d4b\u51c6\u786e\u7387\u6bd4GPT-4o\u9ad8\u51fa46.6%\uff0c\u5e76\u63ed\u793a\u4e86\u793e\u533a\u7279\u5b9a\u7684\u504f\u597d\u7279\u5f81\u3002", "conclusion": "PrefPalette\u901a\u8fc7\u5efa\u6a21\u4eba\u7c7b\u5224\u65ad\u7684\u5c5e\u6027\u4e2d\u4ecb\u7ed3\u6784\uff0c\u4e0d\u4ec5\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u504f\u597d\u9884\u6d4b\uff0c\u8fd8\u63d0\u4f9b\u4e86\u900f\u660e\u3001\u53ef\u89e3\u91ca\u7684\u6d1e\u5bdf\uff0c\u4e3a\u66f4\u503c\u5f97\u4fe1\u8d56\u3001\u4ef7\u503c\u611f\u77e5\u7684\u4e2a\u6027\u5316\u5e94\u7528\u8fc8\u51fa\u4e86\u7b2c\u4e00\u6b65\u3002"}}
{"id": "2507.14111", "categories": ["cs.AI", "cs.DC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14111", "abs": "https://arxiv.org/abs/2507.14111", "authors": ["Xiaoya Li", "Xiaofei Sun", "Albert Wang", "Jiwei Li", "Chris Shum"], "title": "CUDA-L1: Improving CUDA Optimization via Contrastive Reinforcement Learning", "comment": "Preprint Version", "summary": "The exponential growth in demand for GPU computing resources, driven by the\nrapid advancement of Large Language Models, has created an urgent need for\nautomated CUDA optimization strategies. While recent advances in LLMs show\npromise for code generation, current SOTA models (e.g. R1, o1) achieve low\nsuccess rates in improving CUDA speed. In this paper, we introduce CUDA-L1, an\nautomated reinforcement learning framework for CUDA optimization.\n  CUDA-L1 achieves performance improvements on the CUDA optimization task:\ntrained on NVIDIA A100, it delivers an average speedup of x17.7 across all 250\nCUDA kernels of KernelBench, with peak speedups reaching x449. Furthermore, the\nmodel also demonstrates excellent portability across GPU architectures,\nachieving average speedups of x17.8 on H100, x19.0 on RTX 3090, x16.5 on L40,\nx14.7 on H800, and x13.9 on H20 despite being optimized specifically for A100.\nBeyond these benchmark results, CUDA-L1 demonstrates several remarkable\nproperties: 1) Discovers a variety of CUDA optimization techniques and learns\nto combine them strategically to achieve optimal performance; 2) Uncovers\nfundamental principles of CUDA optimization; 3) Identifies non-obvious\nperformance bottlenecks and rejects seemingly beneficial optimizations that\nharm performance.\n  The capabilities of CUDA-L1 demonstrate that reinforcement learning can\ntransform an initially poor-performing LLM into an effective CUDA optimizer\nthrough speedup-based reward signals alone, without human expertise or domain\nknowledge. More importantly, the trained RL model extend the acquired reasoning\nabilities to new kernels. This paradigm opens possibilities for automated\noptimization of CUDA operations, and holds promise to substantially promote GPU\nefficiency and alleviate the rising pressure on GPU computing resources.", "AI": {"tldr": "CUDA-L1\u662f\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5316CUDA\u4f18\u5316\u6846\u67b6\uff0c\u663e\u8457\u63d0\u5347\u6027\u80fd\u5e76\u5c55\u793a\u8de8GPU\u67b6\u6784\u7684\u53ef\u79fb\u690d\u6027\uff0c\u65e0\u9700\u4eba\u7c7b\u5e72\u9884\u3002", "motivation": "\u7531\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0cGPU\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\u5448\u6307\u6570\u7ea7\u589e\u957f\uff0c\u4e9f\u9700\u81ea\u52a8\u5316CUDA\u4f18\u5316\u7b56\u7565\u3002", "method": "\u5f15\u5165CUDA-L1\uff0c\u4e00\u4e2a\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u81ea\u52a8\u5316\u6846\u67b6\uff0c\u7528\u4e8eCUDA\u4f18\u5316\u3002", "result": "\u5728NVIDIA A100\u4e0a\u8bad\u7ec3\uff0cCUDA-L1\u5728KernelBench\u7684250\u4e2aCUDA\u5185\u6838\u4e0a\u5e73\u5747\u52a0\u901f17.7\u500d\uff0c\u5cf0\u503c\u52a0\u901f\u8fbe449\u500d\uff0c\u5e76\u5c55\u793a\u4e86\u51fa\u8272\u7684\u8de8GPU\u67b6\u6784\u53ef\u79fb\u690d\u6027\u3002", "conclusion": "CUDA-L1\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u6210\u529f\u5c06\u6027\u80fd\u4e0d\u4f73\u7684\u5927\u578b\u8bed\u8a00\u6a21\u578b\u8f6c\u5316\u4e3a\u6709\u6548\u7684CUDA\u4f18\u5316\u5668\uff0c\u4ec5\u57fa\u4e8e\u52a0\u901f\u5956\u52b1\u4fe1\u53f7\uff0c\u65e0\u9700\u4eba\u7c7b\u4e13\u4e1a\u77e5\u8bc6\u3002\u8fd9\u4e00\u8303\u5f0f\u4e3aCUDA\u64cd\u4f5c\u7684\u81ea\u52a8\u5316\u4f18\u5316\u5f00\u8f9f\u4e86\u53ef\u80fd\u6027\uff0c\u6709\u671b\u663e\u8457\u63d0\u5347GPU\u6548\u7387\u5e76\u7f13\u89e3GPU\u8ba1\u7b97\u8d44\u6e90\u7684\u538b\u529b\u3002"}}
{"id": "2507.13550", "categories": ["cs.AI", "cs.CL", "cs.SC"], "pdf": "https://arxiv.org/pdf/2507.13550", "abs": "https://arxiv.org/abs/2507.13550", "authors": ["Eduardo C. Garrido-Merch\u00e1n", "Cristina Puente"], "title": "GOFAI meets Generative AI: Development of Expert Systems by means of Large Language Models", "comment": null, "summary": "The development of large language models (LLMs) has successfully transformed\nknowledge-based systems such as open domain question nswering, which can\nautomatically produce vast amounts of seemingly coherent information. Yet,\nthose models have several disadvantages like hallucinations or confident\ngeneration of incorrect or unverifiable facts. In this paper, we introduce a\nnew approach to the development of expert systems using LLMs in a controlled\nand transparent way. By limiting the domain and employing a well-structured\nprompt-based extraction approach, we produce a symbolic representation of\nknowledge in Prolog, which can be validated and corrected by human experts.\nThis approach also guarantees interpretability, scalability and reliability of\nthe developed expert systems. Via quantitative and qualitative experiments with\nClaude Sonnet 3.7 and GPT-4.1, we show strong adherence to facts and semantic\ncoherence on our generated knowledge bases. We present a transparent hybrid\nsolution that combines the recall capacity of LLMs with the precision of\nsymbolic systems, thereby laying the foundation for dependable AI applications\nin sensitive domains.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408LLMs\u548c\u7b26\u53f7\u7cfb\u7edf\u7684\u900f\u660e\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u4e13\u5bb6\u9a8c\u8bc1\u751f\u6210\u53ef\u9760\u7684\u77e5\u8bc6\u5e93\uff0c\u4e3a\u654f\u611f\u9886\u57df\u7684AI\u5e94\u7528\u5960\u5b9a\u57fa\u7840\u3002", "motivation": "\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5728\u751f\u6210\u770b\u4f3c\u8fde\u8d2f\u4fe1\u606f\u65f6\u5b58\u5728\u5e7b\u89c9\u6216\u81ea\u4fe1\u751f\u6210\u9519\u8bef\u4e8b\u5b9e\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u63a7\u3001\u900f\u660e\u7684\u65b9\u6cd5\u6765\u5f00\u53d1\u4e13\u5bb6\u7cfb\u7edf\u3002", "method": "\u901a\u8fc7\u9650\u5236\u9886\u57df\u5e76\u91c7\u7528\u7ed3\u6784\u5316\u7684\u63d0\u793a\u63d0\u53d6\u65b9\u6cd5\uff0c\u5c06\u77e5\u8bc6\u8f6c\u5316\u4e3aProlog\u7b26\u53f7\u8868\u793a\uff0c\u5e76\u7531\u4eba\u7c7b\u4e13\u5bb6\u9a8c\u8bc1\u548c\u4fee\u6b63\u3002", "result": "\u5b9a\u91cf\u548c\u5b9a\u6027\u5b9e\u9a8c\u8868\u660e\uff0c\u751f\u6210\u7684\u77e5\u8bc6\u5e93\u5728\u4e8b\u5b9e\u51c6\u786e\u6027\u548c\u8bed\u4e49\u8fde\u8d2f\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u548c\u7b26\u53f7\u7cfb\u7edf\u7684\u900f\u660e\u6df7\u5408\u89e3\u51b3\u65b9\u6848\uff0c\u4e3a\u654f\u611f\u9886\u57df\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u4eba\u5de5\u667a\u80fd\u5e94\u7528\u57fa\u7840\u3002"}}
{"id": "2507.13558", "categories": ["cs.AI", "cs.DB", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.13558", "abs": "https://arxiv.org/abs/2507.13558", "authors": ["David Poole"], "title": "Why Isn't Relational Learning Taking Over the World?", "comment": "10 pages (6 pages + references + appendices)", "summary": "AI seems to be taking over the world with systems that model pixels, words,\nand phonemes. The world is arguably made up, not of pixels, words, and phonemes\nbut of entities (objects, things, including events) with properties and\nrelations among them. Surely we should model these, not the perception or\ndescription of them. You might suspect that concentrating on modeling words and\npixels is because all of the (valuable) data in the world is in terms of text\nand images. If you look into almost any company you will find their most\nvaluable data is in spreadsheets, databases and other relational formats. These\nare not the form that are studied in introductory machine learning, but are\nfull of product numbers, student numbers, transaction numbers and other\nidentifiers that can't be interpreted naively as numbers. The field that\nstudies this sort of data has various names including relational learning,\nstatistical relational AI, and many others. This paper explains why relational\nlearning is not taking over the world -- except in a few cases with restricted\nrelations -- and what needs to be done to bring it to it's rightful prominence.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5173\u7cfb\u578b\u5b66\u4e60\u5728AI\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u6307\u51fa\u5176\u5f53\u524d\u53d7\u9650\u7684\u539f\u56e0\uff0c\u5e76\u547c\u5401\u52a0\u5f3a\u7814\u7a76\u4ee5\u5b9e\u73b0\u5176\u6f5c\u529b\u3002", "motivation": "\u5f53\u524dAI\u6280\u672f\u4e3b\u8981\u5173\u6ce8\u50cf\u7d20\u548c\u6587\u5b57\u7b49\u611f\u77e5\u6570\u636e\u7684\u5efa\u6a21\uff0c\u800c\u5ffd\u89c6\u4e86\u5b9e\u4f53\u53ca\u5176\u5173\u7cfb\u7684\u76f4\u63a5\u5efa\u6a21\uff0c\u8fd9\u4e0e\u73b0\u5b9e\u4e16\u754c\u7684\u6784\u6210\u65b9\u5f0f\u4e0d\u7b26\u3002\u8bba\u6587\u65e8\u5728\u63ed\u793a\u8fd9\u4e00\u5dee\u8ddd\u5e76\u63a8\u52a8\u5173\u7cfb\u578b\u5b66\u4e60\u7684\u53d1\u5c55\u3002", "method": "\u901a\u8fc7\u5206\u6790\u73b0\u6709AI\u6280\u672f\u7684\u5c40\u9650\u6027\uff08\u5982\u4e3b\u8981\u5904\u7406\u6587\u672c\u548c\u56fe\u50cf\u6570\u636e\uff09\u548c\u5173\u7cfb\u578b\u5b66\u4e60\u7684\u6f5c\u529b\uff0c\u8bba\u6587\u63a2\u8ba8\u4e86\u5173\u7cfb\u578b\u5b66\u4e60\u672a\u80fd\u5e7f\u6cdb\u5e94\u7528\u7684\u539f\u56e0\u3002", "result": "\u8bba\u6587\u6307\u51fa\u5173\u7cfb\u578b\u5b66\u4e60\u5728\u53d7\u9650\u5173\u7cfb\u4e2d\u5df2\u6709\u6210\u529f\u5e94\u7528\uff0c\u4f46\u8981\u5b9e\u73b0\u5176\u5e7f\u6cdb\u666e\u53ca\uff0c\u8fd8\u9700\u89e3\u51b3\u73b0\u6709\u6311\u6218\u3002", "conclusion": "\u8be5\u8bba\u6587\u547c\u5401\u5e94\u66f4\u91cd\u89c6\u5173\u7cfb\u578b\u5b66\u4e60\u7684\u7814\u7a76\u4e0e\u5e94\u7528\uff0c\u4ee5\u5f25\u8865\u5f53\u524dAI\u9886\u57df\u5728\u5904\u7406\u5b9e\u4f53\u53ca\u5176\u5173\u7cfb\u4e0a\u7684\u4e0d\u8db3\uff0c\u5e76\u63d0\u51fa\u4e86\u63a8\u52a8\u5176\u53d1\u5c55\u7684\u5fc5\u8981\u63aa\u65bd\u3002"}}
{"id": "2507.13625", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13625", "abs": "https://arxiv.org/abs/2507.13625", "authors": ["Yuxin Zhang", "Xi Wang", "Mo Hu", "Zhenyu Zhang"], "title": "BifrostRAG: Bridging Dual Knowledge Graphs for Multi-Hop Question Answering in Construction Safety", "comment": "19 pages, 13 figures", "summary": "Information retrieval and question answering from safety regulations are\nessential for automated construction compliance checking but are hindered by\nthe linguistic and structural complexity of regulatory text. Many\ncompliance-related queries are multi-hop, requiring synthesis of information\nacross interlinked clauses. This poses a challenge for traditional\nretrieval-augmented generation (RAG) systems. To overcome this, we introduce\nBifrostRAG: a dual-graph RAG-integrated system that explicitly models both\nlinguistic relationships (via an Entity Network Graph) and document structure\n(via a Document Navigator Graph). This architecture powers a hybrid retrieval\nmechanism that combines graph traversal with vector-based semantic search,\nenabling large language models to reason over both the meaning and the\nstructure of the text. Evaluation on a multi-hop question dataset shows that\nBifrostRAG achieves 92.8 percent precision, 85.5 percent recall, and an F1\nscore of 87.3 percent. These results significantly outperform vector-only and\ngraph-only RAG baselines that represent current leading approaches. Error\nanalysis further highlights the comparative advantages of our hybrid method\nover single-modality RAGs. These findings establish BifrostRAG as a robust\nknowledge engine for LLM-driven compliance checking. Its dual-graph, hybrid\nretrieval mechanism offers a transferable blueprint for navigating complex\ntechnical documents across knowledge-intensive engineering domains.", "AI": {"tldr": "BifrostRAG\u901a\u8fc7\u53cc\u56fe\u6df7\u5408\u68c0\u7d22\u673a\u5236\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u6cd5\u89c4\u6587\u672c\u7684\u591a\u8df3\u95ee\u7b54\u6027\u80fd\u3002", "motivation": "\u5b89\u5168\u6cd5\u89c4\u7684\u4fe1\u606f\u68c0\u7d22\u548c\u95ee\u7b54\u5bf9\u81ea\u52a8\u5316\u65bd\u5de5\u5408\u89c4\u6027\u68c0\u67e5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u6cd5\u89c4\u6587\u672c\u7684\u8bed\u8a00\u548c\u7ed3\u6784\u590d\u6742\u6027\u963b\u788d\u4e86\u4f20\u7edfRAG\u7cfb\u7edf\u5904\u7406\u591a\u8df3\u67e5\u8be2\u3002", "method": "\u5f15\u5165BifrostRAG\uff1a\u4e00\u79cd\u53cc\u56feRAG\u96c6\u6210\u7cfb\u7edf\uff0c\u901a\u8fc7\u5b9e\u4f53\u7f51\u7edc\u56fe\u5efa\u6a21\u8bed\u8a00\u5173\u7cfb\uff0c\u901a\u8fc7\u6587\u6863\u5bfc\u822a\u56fe\u5efa\u6a21\u6587\u6863\u7ed3\u6784\uff0c\u7ed3\u5408\u56fe\u904d\u5386\u548c\u5411\u91cf\u8bed\u4e49\u641c\u7d22\u7684\u6df7\u5408\u68c0\u7d22\u673a\u5236\u3002", "result": "\u5728\u591a\u8df3\u95ee\u9898\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0cBifrostRAG\u7684\u7cbe\u786e\u5ea6\u4e3a92.8%\uff0c\u53ec\u56de\u7387\u4e3a85.5%\uff0cF1\u5f97\u5206\u4e3a87.3%\uff0c\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u65b9\u6cd5\u3002", "conclusion": "BifrostRAG\u7684\u53cc\u56fe\u6df7\u5408\u68c0\u7d22\u673a\u5236\u4e3a\u77e5\u8bc6\u5bc6\u96c6\u578b\u5de5\u7a0b\u9886\u57df\u4e2d\u7684\u590d\u6742\u6280\u672f\u6587\u6863\u5bfc\u822a\u63d0\u4f9b\u4e86\u53ef\u8f6c\u79fb\u7684\u84dd\u56fe\u3002"}}
{"id": "2507.13651", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13651", "abs": "https://arxiv.org/abs/2507.13651", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Buggy rule diagnosis for combined steps through final answer evaluation in stepwise tasks", "comment": null, "summary": "Many intelligent tutoring systems can support a student in solving a stepwise\ntask. When a student combines several steps in one step, the number of possible\npaths connecting consecutive inputs may be very large. This combinatorial\nexplosion makes error diagnosis hard. Using a final answer to diagnose a\ncombination of steps can mitigate the combinatorial explosion, because there\nare generally fewer possible (erroneous) final answers than (erroneous)\nsolution paths. An intermediate input for a task can be diagnosed by\nautomatically completing it according to the task solution strategy and\ndiagnosing this solution. This study explores the potential of automated error\ndiagnosis based on a final answer. We investigate the design of a service that\nprovides a buggy rule diagnosis when a student combines several steps. To\nvalidate the approach, we apply the service to an existing dataset (n=1939) of\nunique student steps when solving quadratic equations, which could not be\ndiagnosed by a buggy rule service that tries to connect consecutive inputs with\na single rule. Results show that final answer evaluation can diagnose 29,4% of\nthese steps. Moreover, a comparison of the generated diagnoses with teacher\ndiagnoses on a subset (n=115) shows that the diagnoses align in 97% of the\ncases. These results can be considered a basis for further exploration of the\napproach.", "AI": {"tldr": "\u7814\u7a76\u9a8c\u8bc1\u4e86\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u81ea\u52a8\u9519\u8bef\u8bca\u65ad\u65b9\u6cd5\u5728\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u663e\u8457\u51cf\u5c11\u7ec4\u5408\u7206\u70b8\u95ee\u9898\uff0c\u8bca\u65ad\u51c6\u786e\u7387\u9ad8\u8fbe97%\u3002", "motivation": "\u667a\u80fd\u8f85\u5bfc\u7cfb\u7edf\u5728\u5b66\u751f\u9010\u6b65\u5b8c\u6210\u4efb\u52a1\u65f6\u63d0\u4f9b\u652f\u6301\uff0c\u4f46\u5f53\u5b66\u751f\u5c06\u591a\u4e2a\u6b65\u9aa4\u5408\u5e76\u4e3a\u4e00\u4e2a\u6b65\u9aa4\u65f6\uff0c\u53ef\u80fd\u7684\u8def\u5f84\u7ec4\u5408\u7206\u70b8\uff0c\u4f7f\u9519\u8bef\u8bca\u65ad\u53d8\u5f97\u56f0\u96be\u3002\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u8bca\u65ad\u53ef\u4ee5\u51cf\u5c11\u7ec4\u5408\u7206\u70b8\u7684\u95ee\u9898\u3002", "method": "\u7814\u7a76\u8bbe\u8ba1\u4e86\u4e00\u4e2a\u670d\u52a1\uff0c\u7528\u4e8e\u5728\u5b66\u751f\u5408\u5e76\u591a\u4e2a\u6b65\u9aa4\u65f6\u63d0\u4f9b\u9519\u8bef\u89c4\u5219\u8bca\u65ad\u3002\u8be5\u65b9\u6cd5\u901a\u8fc7\u81ea\u52a8\u5b8c\u6210\u4efb\u52a1\u5e76\u6839\u636e\u4efb\u52a1\u89e3\u51b3\u7b56\u7565\u8bca\u65ad\u89e3\u51b3\u65b9\u6848\u6765\u8bca\u65ad\u4e2d\u95f4\u8f93\u5165\u3002", "result": "\u5728\u4e8c\u6b21\u65b9\u7a0b\u6c42\u89e3\u7684\u6570\u636e\u96c6\uff08n=1939\uff09\u4e2d\uff0c\u6700\u7ec8\u7b54\u6848\u8bc4\u4f30\u53ef\u8bca\u65ad29.4%\u7684\u6b65\u9aa4\u3002\u4e0e\u6559\u5e08\u8bca\u65ad\u7684\u5bf9\u6bd4\uff08n=115\uff09\u663e\u793a\uff0c97%\u7684\u60c5\u51b5\u4e0b\u8bca\u65ad\u7ed3\u679c\u4e00\u81f4\u3002", "conclusion": "\u8be5\u7814\u7a76\u63a2\u7d22\u4e86\u57fa\u4e8e\u6700\u7ec8\u7b54\u6848\u7684\u81ea\u52a8\u9519\u8bef\u8bca\u65ad\u65b9\u6cd5\u7684\u6f5c\u529b\uff0c\u5e76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2507.13652", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13652", "abs": "https://arxiv.org/abs/2507.13652", "authors": ["Gerben van der Hoek", "Johan Jeuring", "Rogier Bos"], "title": "Combining model tracing and constraint-based modeling for multistep strategy diagnoses", "comment": null, "summary": "Model tracing and constraint-based modeling are two approaches to diagnose\nstudent input in stepwise tasks. Model tracing supports identifying consecutive\nproblem-solving steps taken by a student, whereas constraint-based modeling\nsupports student input diagnosis even when several steps are combined into one\nstep. We propose an approach that merges both paradigms. By defining\nconstraints as properties that a student input has in common with a step of a\nstrategy, it is possible to provide a diagnosis when a student deviates from a\nstrategy even when the student combines several steps. In this study we explore\nthe design of a system for multistep strategy diagnoses, and evaluate these\ndiagnoses. As a proof of concept, we generate diagnoses for an existing dataset\ncontaining steps students take when solving quadratic equations (n=2136). To\ncompare with human diagnoses, two teachers coded a random sample of deviations\n(n=70) and applications of the strategy (n=70). Results show that that the\nsystem diagnosis aligned with the teacher coding in all of the 140 student\nsteps.", "AI": {"tldr": "\u7ed3\u5408\u6a21\u578b\u8ffd\u8e2a\u548c\u7ea6\u675f\u5efa\u6a21\uff0c\u63d0\u51fa\u65b0\u65b9\u6cd5\u4ee5\u8bca\u65ad\u5b66\u751f\u591a\u6b65\u7ec4\u5408\u8f93\u5165\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u5176\u4e0e\u6559\u5e08\u5224\u65ad\u5b8c\u5168\u4e00\u81f4\u3002", "motivation": "\u89e3\u51b3\u5b66\u751f\u5728\u591a\u6b65\u4efb\u52a1\u4e2d\u7ec4\u5408\u6b65\u9aa4\u65f6\u4f20\u7edf\u65b9\u6cd5\uff08\u6a21\u578b\u8ffd\u8e2a\u548c\u7ea6\u675f\u5efa\u6a21\uff09\u65e0\u6cd5\u6709\u6548\u8bca\u65ad\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7ed3\u5408\u6a21\u578b\u8ffd\u8e2a\u548c\u7ea6\u675f\u5efa\u6a21\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u5c06\u7ea6\u675f\u5b9a\u4e49\u4e3a\u5b66\u751f\u8f93\u5165\u4e0e\u7b56\u7565\u6b65\u9aa4\u5171\u6709\u7684\u5c5e\u6027\uff0c\u5b9e\u73b0\u5bf9\u591a\u6b65\u7ec4\u5408\u8f93\u5165\u7684\u8bca\u65ad\u3002", "result": "\u57282136\u4e2a\u4e8c\u6b21\u65b9\u7a0b\u6c42\u89e3\u6b65\u9aa4\u7684\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u7cfb\u7edf\u8bca\u65ad\u4e0e\u6559\u5e08\u7f16\u7801\u5728140\u4e2a\u968f\u673a\u6837\u672c\u4e2d\u5b8c\u5168\u4e00\u81f4\u3002", "conclusion": "\u7cfb\u7edf\u8bca\u65ad\u4e0e\u6559\u5e08\u7f16\u7801\u5728\u6240\u6709140\u4e2a\u5b66\u751f\u6b65\u9aa4\u4e2d\u5b8c\u5168\u4e00\u81f4\uff0c\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2507.13737", "categories": ["cs.AI", "cs.CL", "cs.HC", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.13737", "abs": "https://arxiv.org/abs/2507.13737", "authors": ["Ye Tian", "Xiaoyuan Ren", "Zihao Wang", "Onat Gungor", "Xiaofan Yu", "Tajana Rosing"], "title": "DailyLLM: Context-Aware Activity Log Generation Using Multi-Modal Sensors and LLMs", "comment": null, "summary": "Rich and context-aware activity logs facilitate user behavior analysis and\nhealth monitoring, making them a key research focus in ubiquitous computing.\nThe remarkable semantic understanding and generation capabilities of Large\nLanguage Models (LLMs) have recently created new opportunities for activity log\ngeneration. However, existing methods continue to exhibit notable limitations\nin terms of accuracy, efficiency, and semantic richness. To address these\nchallenges, we propose DailyLLM. To the best of our knowledge, this is the\nfirst log generation and summarization system that comprehensively integrates\ncontextual activity information across four dimensions: location, motion,\nenvironment, and physiology, using only sensors commonly available on\nsmartphones and smartwatches. To achieve this, DailyLLM introduces a\nlightweight LLM-based framework that integrates structured prompting with\nefficient feature extraction to enable high-level activity understanding.\nExtensive experiments demonstrate that DailyLLM outperforms state-of-the-art\n(SOTA) log generation methods and can be efficiently deployed on personal\ncomputers and Raspberry Pi. Utilizing only a 1.5B-parameter LLM model, DailyLLM\nachieves a 17% improvement in log generation BERTScore precision compared to\nthe 70B-parameter SOTA baseline, while delivering nearly 10x faster inference\nspeed.", "AI": {"tldr": "DailyLLM \u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7 LLM \u6846\u67b6\uff0c\u901a\u8fc7\u6574\u5408\u591a\u7ef4\u5ea6\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u6d3b\u52a8\u65e5\u5fd7\u751f\u6210\u7684\u7cbe\u5ea6\u548c\u901f\u5ea6\u3002", "motivation": "\u73b0\u6709\u7684\u6d3b\u52a8\u65e5\u5fd7\u751f\u6210\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u8bed\u4e49\u4e30\u5bcc\u5ea6\u65b9\u9762\u5b58\u5728\u663e\u8457\u5c40\u9650\u6027\uff0c\u800c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u8bed\u4e49\u7406\u89e3\u548c\u751f\u6210\u80fd\u529b\u4e3a\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a\u3002", "method": "DailyLLM \u5f15\u5165\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u7684\u57fa\u4e8e\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u63d0\u793a\u548c\u9ad8\u6548\u7279\u5f81\u63d0\u53d6\u5b9e\u73b0\u9ad8\u7ea7\u6d3b\u52a8\u7406\u89e3\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cDailyLLM \u5728\u65e5\u5fd7\u751f\u6210 BERTScore \u7cbe\u5ea6\u4e0a\u6bd4 70B \u53c2\u6570\u7684 SOTA \u57fa\u7ebf\u63d0\u9ad8\u4e86 17%\uff0c\u63a8\u7406\u901f\u5ea6\u63d0\u5347\u4e86\u8fd1 10 \u500d\uff0c\u4e14\u53ef\u5728\u4e2a\u4eba\u8ba1\u7b97\u673a\u548c Raspberry Pi \u4e0a\u9ad8\u6548\u90e8\u7f72\u3002", "conclusion": "DailyLLM \u662f\u4e00\u79cd\u521b\u65b0\u7684\u65e5\u5fd7\u751f\u6210\u548c\u6458\u8981\u7cfb\u7edf\uff0c\u901a\u8fc7\u7efc\u5408\u6574\u5408\u4f4d\u7f6e\u3001\u8fd0\u52a8\u3001\u73af\u5883\u548c\u751f\u7406\u56db\u4e2a\u7ef4\u5ea6\u7684\u4e0a\u4e0b\u6587\u6d3b\u52a8\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e5\u5fd7\u751f\u6210\u7684\u51c6\u786e\u6027\u3001\u6548\u7387\u548c\u8bed\u4e49\u4e30\u5bcc\u5ea6\u3002"}}
{"id": "2507.13759", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13759", "abs": "https://arxiv.org/abs/2507.13759", "authors": ["Carlos Bobed", "Carlota Quintana", "Eduardo Mena", "Jorge Bobed", "Fernando Bobillo"], "title": "OntView: What you See is What you Meant", "comment": null, "summary": "In the field of knowledge management and computer science, ontologies provide\na structured framework for modeling domain-specific knowledge by defining\nconcepts and their relationships. However, the lack of tools that provide\neffective visualization is still a significant challenge. While numerous\nontology editors and viewers exist, most of them fail to graphically represent\nontology structures in a meaningful and non-overwhelming way, limiting users'\nability to comprehend dependencies and properties within large ontological\nframeworks.\n  In this paper, we present OntView, an ontology viewer that is designed to\nprovide users with an intuitive visual representation of ontology concepts and\ntheir formal definitions through a user-friendly interface. Building on the use\nof a DL reasoner, OntView follows a \"What you see is what you meant\" paradigm,\nshowing the actual inferred knowledge. One key aspect for this is its ability\nto visualize General Concept Inclusions (GCI), a feature absent in existing\nvisualization tools. Moreover, to avoid a possible information overload,\nOntView also offers different ways to show a simplified view of the ontology\nby: 1) creating ontology summaries by assessing the importance of the concepts\n(according to different available algorithms), 2) focusing the visualization on\nthe existing TBox elements between two given classes and 3) allowing to\nhide/show different branches in a dynamic way without losing the semantics.\nOntView has been released with an open-source license for the whole community.", "AI": {"tldr": "OntView\u662f\u4e00\u4e2a\u5f00\u6e90\u672c\u4f53\u67e5\u770b\u5668\uff0c\u901a\u8fc7\u76f4\u89c2\u53ef\u89c6\u5316\u548c\u7b80\u5316\u89c6\u56fe\u529f\u80fd\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u5927\u578b\u672c\u4f53\u8868\u793a\u4e2d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u672c\u4f53\u7f16\u8f91\u5668\u548c\u67e5\u770b\u5668\u5728\u56fe\u5f62\u5316\u8868\u793a\u672c\u4f53\u7ed3\u6784\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9650\u5236\u4e86\u7528\u6237\u5bf9\u5927\u578b\u672c\u4f53\u6846\u67b6\u4e2d\u4f9d\u8d56\u5173\u7cfb\u548c\u5c5e\u6027\u7684\u7406\u89e3\u3002", "method": "OntView\u57fa\u4e8eDL\u63a8\u7406\u5668\uff0c\u91c7\u7528\u201c\u6240\u89c1\u5373\u6240\u5f97\u201d\u8303\u5f0f\uff0c\u53ef\u89c6\u5316\u901a\u7528\u6982\u5ff5\u5305\u542b\uff08GCI\uff09\uff0c\u5e76\u63d0\u4f9b\u7b80\u5316\u89c6\u56fe\u529f\u80fd\uff0c\u5982\u672c\u4f53\u6458\u8981\u3001TBox\u5143\u7d20\u805a\u7126\u548c\u52a8\u6001\u5206\u652f\u9690\u85cf/\u663e\u793a\u3002", "result": "OntView\u6210\u529f\u5b9e\u73b0\u4e86\u76f4\u89c2\u7684\u672c\u4f53\u53ef\u89c6\u5316\uff0c\u652f\u6301GCI\u5c55\u793a\uff0c\u5e76\u901a\u8fc7\u7b80\u5316\u89c6\u56fe\u529f\u80fd\u907f\u514d\u4e86\u4fe1\u606f\u8fc7\u8f7d\uff0c\u5df2\u4f5c\u4e3a\u5f00\u6e90\u5de5\u5177\u53d1\u5e03\u3002", "conclusion": "OntView\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u3001\u7528\u6237\u53cb\u597d\u7684\u672c\u4f53\u67e5\u770b\u5668\uff0c\u901a\u8fc7\u76f4\u89c2\u7684\u53ef\u89c6\u5316\u5c55\u793a\u548c\u7b80\u5316\u89c6\u56fe\u529f\u80fd\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u5de5\u5177\u5728\u5927\u578b\u672c\u4f53\u6846\u67b6\u4e2d\u8868\u793a\u548c\u7406\u89e3\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2507.13768", "categories": ["cs.AI", "I.2.7"], "pdf": "https://arxiv.org/pdf/2507.13768", "abs": "https://arxiv.org/abs/2507.13768", "authors": ["Renato Ghisellini", "Remo Pareschi", "Marco Pedroni", "Giovanni Battista Raggi"], "title": "From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning", "comment": "Peer-reviewed full paper accepted through a double-blind review\n  process at the HAR 2025 conference (https://har-conf.eu/). The official\n  version will appear in a volume of the Lecture Notes in Computer Science\n  (LNCS) series", "summary": "We present a hybrid architecture for agent-augmented strategic reasoning,\ncombining heuristic extraction, semantic activation, and compositional\nsynthesis. Drawing on sources ranging from classical military theory to\ncontemporary corporate strategy, our model activates and composes multiple\nheuristics through a process of semantic interdependence inspired by research\nin quantum cognition. Unlike traditional decision engines that select the best\nrule, our system fuses conflicting heuristics into coherent and\ncontext-sensitive narratives, guided by semantic interaction modeling and\nrhetorical framing. We demonstrate the framework via a Meta vs. FTC case study,\nwith preliminary validation through semantic metrics. Limitations and\nextensions (e.g., dynamic interference tuning) are discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u8bed\u4e49\u6fc0\u6d3b\u548c\u7ec4\u5408\u5408\u6210\u5b9e\u73b0\u6218\u7565\u63a8\u7406\uff0c\u80fd\u591f\u878d\u5408\u51b2\u7a81\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u51b3\u7b56\u5f15\u64ce\u901a\u5e38\u9009\u62e9\u6700\u4f73\u89c4\u5219\uff0c\u800c\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u80fd\u591f\u878d\u5408\u51b2\u7a81\u542f\u53d1\u5f0f\u89c4\u5219\u7684\u65b0\u65b9\u6cd5\uff0c\u4ee5\u751f\u6210\u66f4\u8fde\u8d2f\u4e14\u60c5\u5883\u654f\u611f\u7684\u53d9\u8ff0\u3002", "method": "\u7ed3\u5408\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u8bed\u4e49\u6fc0\u6d3b\u548c\u7ec4\u5408\u5408\u6210\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u8bed\u4e49\u4e92\u52a8\u5efa\u6a21\u548c\u4fee\u8f9e\u6846\u67b6\u6765\u878d\u5408\u51b2\u7a81\u7684\u542f\u53d1\u5f0f\u89c4\u5219\u3002", "result": "\u901a\u8fc7Meta vs. FTC\u6848\u4f8b\u7814\u7a76\u5c55\u793a\u4e86\u8be5\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u901a\u8fc7\u8bed\u4e49\u6307\u6807\u8fdb\u884c\u4e86\u521d\u6b65\u9a8c\u8bc1\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6df7\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u542f\u53d1\u5f0f\u63d0\u53d6\u3001\u8bed\u4e49\u6fc0\u6d3b\u548c\u7ec4\u5408\u5408\u6210\uff0c\u5b9e\u73b0\u4e86\u4ee3\u7406\u589e\u5f3a\u7684\u6218\u7565\u63a8\u7406\u3002\u8be5\u67b6\u6784\u80fd\u591f\u878d\u5408\u51b2\u7a81\u7684\u542f\u53d1\u5f0f\u89c4\u5219\uff0c\u751f\u6210\u8fde\u8d2f\u4e14\u60c5\u5883\u654f\u611f\u7684\u53d9\u8ff0\uff0c\u5e76\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u548c\u8bed\u4e49\u6307\u6807\u8fdb\u884c\u4e86\u521d\u6b65\u9a8c\u8bc1\u3002"}}
{"id": "2507.13825", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13825", "abs": "https://arxiv.org/abs/2507.13825", "authors": ["Haoyang Li", "Yuming Xu", "Yiming Li", "Hanmo Liu", "Darian Li", "Chen Jason Zhang", "Lei Chen", "Qing Li"], "title": "When Speed meets Accuracy: an Efficient and Effective Graph Model for Temporal Link Prediction", "comment": "Submitted in 2024. Accepted in 2025", "summary": "Temporal link prediction in dynamic graphs is a critical task with\napplications in diverse domains such as social networks, recommendation\nsystems, and e-commerce platforms. While existing Temporal Graph Neural\nNetworks (T-GNNs) have achieved notable success by leveraging complex\narchitectures to model temporal and structural dependencies, they often suffer\nfrom scalability and efficiency challenges due to high computational overhead.\nIn this paper, we propose EAGLE, a lightweight framework that integrates\nshort-term temporal recency and long-term global structural patterns. EAGLE\nconsists of a time-aware module that aggregates information from a node's most\nrecent neighbors to reflect its immediate preferences, and a structure-aware\nmodule that leverages temporal personalized PageRank to capture the influence\nof globally important nodes. To balance these attributes, EAGLE employs an\nadaptive weighting mechanism to dynamically adjust their contributions based on\ndata characteristics. Also, EAGLE eliminates the need for complex multi-hop\nmessage passing or memory-intensive mechanisms, enabling significant\nimprovements in efficiency. Extensive experiments on seven real-world temporal\ngraphs demonstrate that EAGLE consistently achieves superior performance\nagainst state-of-the-art T-GNNs in both effectiveness and efficiency,\ndelivering more than a 50x speedup over effective transformer-based T-GNNs.", "AI": {"tldr": "EAGLE\u662f\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\uff0c\u7ed3\u5408\u77ed\u671f\u65f6\u95f4\u548c\u957f\u671f\u7ed3\u6784\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u7684\u6548\u7387\u548c\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u7684T-GNN\u6a21\u578b\u867d\u7136\u6210\u529f\u4f46\u5b58\u5728\u8ba1\u7b97\u5f00\u9500\u5927\u3001\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u8f7b\u91cf\u7ea7\u6846\u67b6\u6765\u5e73\u8861\u65f6\u95f4\u4e0e\u7ed3\u6784\u4f9d\u8d56\u6027\u3002", "method": "EAGLE\u6846\u67b6\u5305\u542b\u65f6\u95f4\u611f\u77e5\u6a21\u5757\u548c\u7ed3\u6784\u611f\u77e5\u6a21\u5757\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u52a0\u6743\u673a\u5236\u52a8\u6001\u8c03\u6574\u4e24\u8005\u7684\u8d21\u732e\uff0c\u907f\u514d\u4e86\u590d\u6742\u7684\u591a\u8df3\u6d88\u606f\u4f20\u9012\u6216\u5185\u5b58\u5bc6\u96c6\u578b\u673a\u5236\u3002", "result": "\u5728\u4e03\u4e2a\u771f\u5b9e\u4e16\u754c\u65f6\u95f4\u56fe\u4e0a\uff0cEAGLE\u5728\u6548\u679c\u548c\u6548\u7387\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709T-GNN\u6a21\u578b\uff0c\u901f\u5ea6\u63d0\u5347\u8d85\u8fc750\u500d\u3002", "conclusion": "EAGLE\u6846\u67b6\u901a\u8fc7\u6574\u5408\u77ed\u671f\u65f6\u95f4\u4e34\u8fd1\u6027\u548c\u957f\u671f\u5168\u5c40\u7ed3\u6784\u6a21\u5f0f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a8\u6001\u56fe\u4e2d\u65f6\u95f4\u94fe\u63a5\u9884\u6d4b\u7684\u6548\u7387\u548c\u6548\u679c\uff0c\u4e14\u5728\u591a\u4e2a\u771f\u5b9e\u4e16\u754c\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002"}}
{"id": "2507.13846", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13846", "abs": "https://arxiv.org/abs/2507.13846", "authors": ["Kathrin Korte", "Christian Medeiros Adriano", "Sona Ghahremani", "Holger Giese"], "title": "Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments", "comment": null, "summary": "[Context] Multi-agent reinforcement learning (MARL) has achieved notable\nsuccess in environments where agents must learn coordinated behaviors. However,\ntransferring knowledge across agents remains challenging in non-stationary\nenvironments with changing goals. [Problem] Traditional knowledge transfer\nmethods in MARL struggle to generalize, and agents often require costly\nretraining to adapt. [Approach] This paper introduces a causal knowledge\ntransfer framework that enables RL agents to learn and share compact causal\nrepresentations of paths within a non-stationary environment. As the\nenvironment changes (new obstacles), agents' collisions require adaptive\nrecovery strategies. We model each collision as a causal intervention\ninstantiated as a sequence of recovery actions (a macro) whose effect\ncorresponds to a causal knowledge of how to circumvent the obstacle while\nincreasing the chances of achieving the agent's goal (maximizing cumulative\nreward). This recovery action macro is transferred online from a second agent\nand is applied in a zero-shot fashion, i.e., without retraining, just by\nquerying a lookup model with local context information (collisions). [Results]\nOur findings reveal two key insights: (1) agents with heterogeneous goals were\nable to bridge about half of the gap between random exploration and a fully\nretrained policy when adapting to new environments, and (2) the impact of\ncausal knowledge transfer depends on the interplay between environment\ncomplexity and agents' heterogeneous goals.", "AI": {"tldr": "\u63d0\u51fa\u56e0\u679c\u77e5\u8bc6\u8f6c\u79fb\u6846\u67b6\uff0c\u901a\u8fc7\u96f6\u6837\u672c\u8f6c\u79fb\u6062\u590d\u52a8\u4f5c\u5b8f\u63d0\u5347\u591a\u667a\u80fd\u4f53\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u7684\u9002\u5e94\u6027\uff0c\u51cf\u5c11\u518d\u8bad\u7ec3\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u77e5\u8bc6\u8f6c\u79fb\u7684\u6311\u6218\uff0c\u51cf\u5c11\u518d\u8bad\u7ec3\u6210\u672c\u5e76\u63d0\u5347\u9002\u5e94\u6027\u3002", "method": "\u5f15\u5165\u56e0\u679c\u77e5\u8bc6\u8f6c\u79fb\u6846\u67b6\uff0c\u901a\u8fc7\u5efa\u6a21\u78b0\u649e\u4e3a\u56e0\u679c\u5e72\u9884\uff0c\u751f\u6210\u6062\u590d\u52a8\u4f5c\u5b8f\uff08macro\uff09\u5e76\u5728\u667a\u80fd\u4f53\u95f4\u96f6\u6837\u672c\u8f6c\u79fb\u3002", "result": "\u667a\u80fd\u4f53\u5728\u5f02\u6784\u76ee\u6807\u4e0b\u80fd\u7f29\u5c0f\u968f\u673a\u63a2\u7d22\u4e0e\u5b8c\u5168\u518d\u8bad\u7ec3\u7b56\u7565\u4e4b\u95f4\u7ea6\u4e00\u534a\u7684\u5dee\u8ddd\uff0c\u4e14\u56e0\u679c\u8f6c\u79fb\u6548\u679c\u53d7\u73af\u5883\u590d\u6742\u6027\u548c\u76ee\u6807\u5f02\u8d28\u6027\u4ea4\u4e92\u5f71\u54cd\u3002", "conclusion": "\u56e0\u679c\u77e5\u8bc6\u8f6c\u79fb\u6846\u67b6\u5728\u975e\u5e73\u7a33\u73af\u5883\u4e2d\u6709\u6548\u63d0\u5347\u4e86\u591a\u667a\u80fd\u4f53\u5f3a\u5316\u5b66\u4e60\u7684\u9002\u5e94\u6027\uff0c\u51cf\u5c11\u4e86\u518d\u8bad\u7ec3\u9700\u6c42\uff0c\u540c\u65f6\u63ed\u793a\u4e86\u73af\u5883\u590d\u6742\u6027\u4e0e\u667a\u80fd\u4f53\u76ee\u6807\u5f02\u8d28\u6027\u4e4b\u95f4\u7684\u4ea4\u4e92\u5f71\u54cd\u3002"}}
{"id": "2507.13874", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13874", "abs": "https://arxiv.org/abs/2507.13874", "authors": ["Mateusz Bystro\u0144ski", "Miko\u0142aj Ho\u0142ysz", "Grzegorz Piotrowski", "Nitesh V. Chawla", "Tomasz Kajdanowicz"], "title": "Large Language Models as Innovators: A Framework to Leverage Latent Space Exploration for Novelty Discovery", "comment": null, "summary": "Innovative idea generation remains a core challenge in AI, as large language\nmodels (LLMs) often struggle to produce outputs that are both novel and\nrelevant. Despite their fluency, LLMs tend to replicate patterns seen during\ntraining, limiting their ability to diverge creatively without extensive prompt\nengineering. Prior work has addressed this through domain-specific heuristics\nand structured prompting pipelines, but such solutions are brittle and\ndifficult to generalize. In this paper, we propose a model-agnostic\nlatent-space ideation framework that enables controlled, scalable creativity by\nnavigating the continuous embedding space of ideas. Unlike prior methods, our\nframework requires no handcrafted rules and adapts easily to different domains,\ninput formats, and creative tasks. This paper introduces an early-stage\nprototype of our method, outlining the conceptual framework and preliminary\nresults highlighting its potential as a general-purpose co-ideator for human-AI\ncollaboration.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u521b\u610f\u6846\u67b6\uff0c\u65e0\u9700\u624b\u5de5\u89c4\u5219\u5373\u53ef\u5b9e\u73b0\u53ef\u63a7\u521b\u610f\u751f\u6210\uff0c\u521d\u6b65\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u901a\u7528\u6027\u548c\u9002\u5e94\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u5728\u751f\u6210\u65b0\u9896\u4e14\u76f8\u5173\u521b\u610f\u65f6\u7684\u5c40\u9650\u6027\uff0c\u907f\u514d\u4f9d\u8d56\u9886\u57df\u7279\u5b9a\u542f\u53d1\u5f0f\u6216\u7ed3\u6784\u5316\u63d0\u793a\u7ba1\u9053\u7684\u8106\u5f31\u6027\u3002", "method": "\u91c7\u7528\u4e86\u4e00\u79cd\u6a21\u578b\u65e0\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u521b\u610f\u6846\u67b6\uff0c\u901a\u8fc7\u5bfc\u822a\u8fde\u7eed\u7684\u5d4c\u5165\u7a7a\u95f4\u6765\u5b9e\u73b0\u521b\u610f\u751f\u6210\uff0c\u65e0\u9700\u624b\u5de5\u89c4\u5219\uff0c\u4e14\u80fd\u9002\u5e94\u4e0d\u540c\u9886\u57df\u548c\u4efb\u52a1\u3002", "result": "\u521d\u6b65\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u65e0\u9700\u624b\u5de5\u89c4\u5219\u7684\u60c5\u51b5\u4e0b\uff0c\u80fd\u591f\u9002\u5e94\u4e0d\u540c\u9886\u57df\u548c\u8f93\u5165\u683c\u5f0f\uff0c\u5c55\u73b0\u51fa\u4f5c\u4e3a\u901a\u7528\u521b\u610f\u534f\u4f5c\u5de5\u5177\u7684\u6f5c\u529b\u3002", "conclusion": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u6a21\u578b\u65e0\u5173\u7684\u6f5c\u5728\u7a7a\u95f4\u521b\u610f\u6846\u67b6\uff0c\u5c55\u793a\u4e86\u5176\u5728\u4fc3\u8fdb\u53ef\u63a7\u3001\u53ef\u6269\u5c55\u7684\u521b\u9020\u529b\u65b9\u9762\u7684\u6f5c\u529b\uff0c\u4e3a\u4eba\u7c7b-AI\u534f\u4f5c\u4e2d\u7684\u521b\u610f\u751f\u6210\u63d0\u4f9b\u4e86\u65b0\u7684\u53ef\u80fd\u6027\u3002"}}
{"id": "2507.13956", "categories": ["cs.AI", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2507.13956", "abs": "https://arxiv.org/abs/2507.13956", "authors": ["Yutao Jin", "Haowen Xiao", "Jielei Chu", "Fengmao Lv", "Yuxiao Li", "Tianrui Li"], "title": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "comment": null, "summary": "Mild Cognitive Impairment (MCI) serves as a prodromal stage of Alzheimer's\nDisease (AD), where early identification and intervention can effectively slow\nthe progression to dementia. However, diagnosing AD remains a significant\nchallenge in neurology due to the confounders caused mainly by the selection\nbias of multimodal data and the complex relationships between variables. To\naddress these issues, we propose a novel visual-language causal intervention\nframework named Alzheimer's Disease Prediction with Cross-modal Causal\nIntervention (ADPC) for diagnostic assistance. Our ADPC employs large language\nmodel (LLM) to summarize clinical data under strict templates, maintaining\nstructured text outputs even with incomplete or unevenly distributed datasets.\nThe ADPC model utilizes Magnetic Resonance Imaging (MRI), functional MRI (fMRI)\nimages and textual data generated by LLM to classify participants into\nCognitively Normal (CN), MCI, and AD categories. Because of the presence of\nconfounders, such as neuroimaging artifacts and age-related biomarkers,\nnon-causal models are likely to capture spurious input-output correlations,\ngenerating less reliable results. Our framework implicitly eliminates\nconfounders through causal intervention. Experimental results demonstrate the\noutstanding performance of our method in distinguishing CN/MCI/AD cases,\nachieving state-of-the-art (SOTA) metrics across most evaluation metrics. The\nstudy showcases the potential of integrating causal reasoning with multi-modal\nlearning for neurological disease diagnosis.", "AI": {"tldr": "ADPC\u6846\u67b6\u7ed3\u5408\u89c6\u89c9-\u8bed\u8a00\u56e0\u679c\u5e72\u9884\u548cLLM\uff0c\u6709\u6548\u6d88\u9664\u6df7\u6742\u56e0\u7d20\uff0c\u663e\u8457\u63d0\u5347AD\u8bca\u65ad\u51c6\u786e\u6027\u3002", "motivation": "\u65e9\u671f\u8bc6\u522b\u548c\u5e72\u9884MCI\u53ef\u4ee5\u6709\u6548\u51cf\u7f13AD\u8fdb\u5c55\uff0c\u4f46\u5f53\u524d\u8bca\u65ad\u65b9\u6cd5\u56e0\u591a\u6a21\u6001\u6570\u636e\u7684\u9009\u62e9\u504f\u5dee\u548c\u53d8\u91cf\u95f4\u590d\u6742\u5173\u7cfb\u800c\u9762\u4e34\u6311\u6218\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aADPC\u7684\u89c6\u89c9-\u8bed\u8a00\u56e0\u679c\u5e72\u9884\u6846\u67b6\uff0c\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLM\uff09\u603b\u7ed3\u4e34\u5e8a\u6570\u636e\uff0c\u5e76\u7ed3\u5408MRI\u548cfMRI\u56fe\u50cf\u6570\u636e\uff0c\u901a\u8fc7\u56e0\u679c\u5e72\u9884\u6d88\u9664\u6df7\u6742\u56e0\u7d20\u3002", "result": "ADPC\u6846\u67b6\u5728\u533a\u5206CN/MCI/AD\u75c5\u4f8b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u5728\u5927\u591a\u6570\u8bc4\u4f30\u6307\u6807\u4e0a\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u5c55\u793a\u4e86\u5c06\u56e0\u679c\u63a8\u7406\u4e0e\u591a\u6a21\u6001\u5b66\u4e60\u76f8\u7ed3\u5408\u5728\u795e\u7ecf\u75be\u75c5\u8bca\u65ad\u4e2d\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u533a\u5206\u8ba4\u77e5\u6b63\u5e38\uff08CN\uff09\u3001\u8f7b\u5ea6\u8ba4\u77e5\u969c\u788d\uff08MCI\uff09\u548c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\uff08AD\uff09\u65b9\u9762\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2507.13958", "categories": ["cs.AI", "cs.LO"], "pdf": "https://arxiv.org/pdf/2507.13958", "abs": "https://arxiv.org/abs/2507.13958", "authors": ["Pedro Cabalar", "Mart\u00edn Di\u00e9guez", "Fran\u00e7ois Olivier", "Torsten Schaub", "Igor St\u00e9phan"], "title": "Towards Constraint Temporal Answer Set Programming", "comment": null, "summary": "Reasoning about dynamic systems with a fine-grained temporal and numeric\nresolution presents significant challenges for logic-based approaches like\nAnswer Set Programming (ASP). To address this, we introduce and elaborate upon\na novel temporal and constraint-based extension of the logic of Here-and-There\nand its nonmonotonic equilibrium extension, representing, to the best of our\nknowledge, the first approach to nonmonotonic temporal reasoning with\nconstraints specifically tailored for ASP. This expressive system is achieved\nby a synergistic combination of two foundational ASP extensions: the\nlinear-time logic of Here-and-There, providing robust nonmonotonic temporal\nreasoning capabilities, and the logic of Here-and-There with constraints,\nenabling the direct integration and manipulation of numeric constraints, among\nothers. This work establishes the foundational logical framework for tackling\ncomplex dynamic systems with high resolution within the ASP paradigm.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u65f6\u6001\u548c\u975e\u5355\u8c03\u63a8\u7406\u7684ASP\u6269\u5c55\uff0c\u7528\u4e8e\u9ad8\u5206\u8fa8\u7387\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u3002", "motivation": "\u89e3\u51b3\u57fa\u4e8e\u903b\u8f91\u7684\u65b9\u6cd5\uff08\u5982ASP\uff09\u5728\u7ec6\u7c92\u5ea6\u65f6\u6001\u548c\u6570\u503c\u5206\u8fa8\u7387\u4e0b\u5bf9\u52a8\u6001\u7cfb\u7edf\u63a8\u7406\u7684\u6311\u6218\u3002", "method": "\u901a\u8fc7\u7ed3\u5408\u7ebf\u6027\u65f6\u95f4\u7684Here-and-There\u903b\u8f91\u548c\u5e26\u7ea6\u675f\u7684Here-and-There\u903b\u8f91\uff0c\u5b9e\u73b0\u4e86\u975e\u5355\u8c03\u65f6\u6001\u63a8\u7406\u4e0e\u6570\u503c\u7ea6\u675f\u7684\u76f4\u63a5\u96c6\u6210\u4e0e\u64cd\u4f5c\u3002", "result": "\u63d0\u51fa\u4e86\u9996\u4e2a\u4e13\u4e3aASP\u8bbe\u8ba1\u7684\u975e\u5355\u8c03\u65f6\u6001\u63a8\u7406\u4e0e\u7ea6\u675f\u7ed3\u5408\u7684\u6269\u5c55\u7cfb\u7edf\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u9896\u7684\u65f6\u6001\u548c\u7ea6\u675f\u57fa\u7840\u7684\u903b\u8f91\u6269\u5c55\uff0c\u4e3aASP\u8303\u5f0f\u4e0b\u7684\u9ad8\u5206\u8fa8\u7387\u52a8\u6001\u7cfb\u7edf\u5efa\u6a21\u63d0\u4f9b\u4e86\u57fa\u7840\u903b\u8f91\u6846\u67b6\u3002"}}
{"id": "2507.14032", "categories": ["cs.AI"], "pdf": "https://arxiv.org/pdf/2507.14032", "abs": "https://arxiv.org/abs/2507.14032", "authors": ["Lam Nguyen", "Erika Barcelos", "Roger French", "Yinghui Wu"], "title": "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models", "comment": "Accepted to the 24th International Semantic Web Conference Research\n  Track (ISWC 2025)", "summary": "Ontology Matching (OM) is a cornerstone task of semantic interoperability,\nyet existing systems often rely on handcrafted rules or specialized models with\nlimited adaptability. We present KROMA, a novel OM framework that harnesses\nLarge Language Models (LLMs) within a Retrieval-Augmented Generation (RAG)\npipeline to dynamically enrich the semantic context of OM tasks with\nstructural, lexical, and definitional knowledge. To optimize both performance\nand efficiency, KROMA integrates a bisimilarity-based concept matching and a\nlightweight ontology refinement step, which prune candidate concepts and\nsubstantially reduce the communication overhead from invoking LLMs. Through\nexperiments on multiple benchmark datasets, we show that integrating knowledge\nretrieval with context-augmented LLMs significantly enhances ontology matching,\noutperforming both classic OM systems and cutting-edge LLM-based approaches\nwhile keeping communication overhead comparable. Our study highlights the\nfeasibility and benefit of the proposed optimization techniques (targeted\nknowledge retrieval, prompt enrichment, and ontology refinement) for ontology\nmatching at scale.", "AI": {"tldr": "KROMA\u662f\u4e00\u4e2a\u5229\u7528LLM\u548cRAG\u6d41\u7a0b\u7684\u672c\u4f53\u5339\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u4f18\u5316\u6280\u672f\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u540c\u65f6\u63a7\u5236\u901a\u4fe1\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u672c\u4f53\u5339\u914d\u7cfb\u7edf\u4f9d\u8d56\u624b\u5de5\u89c4\u5219\u6216\u9002\u5e94\u6027\u6709\u9650\u7684\u4e13\u7528\u6a21\u578b\uff0cKROMA\u65e8\u5728\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08LLMs\uff09\u63d0\u5347\u8bed\u4e49\u4e92\u64cd\u4f5c\u6027\u3002", "method": "KROMA\u91c7\u7528\u68c0\u7d22\u589e\u5f3a\u751f\u6210\uff08RAG\uff09\u6d41\u7a0b\uff0c\u7ed3\u5408\u53cc\u76f8\u4f3c\u5ea6\u6982\u5ff5\u5339\u914d\u548c\u8f7b\u91cf\u7ea7\u672c\u4f53\u7ec6\u5316\u6b65\u9aa4\uff0c\u52a8\u6001\u4e30\u5bcc\u672c\u4f53\u5339\u914d\u4efb\u52a1\u7684\u8bed\u4e49\u4e0a\u4e0b\u6587\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cKROMA\u5728\u591a\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u7ecf\u5178\u672c\u4f53\u5339\u914d\u7cfb\u7edf\u548c\u524d\u6cbf\u7684LLM\u65b9\u6cd5\u3002", "conclusion": "KROMA\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u77e5\u8bc6\u68c0\u7d22\u548c\u4e0a\u4e0b\u6587\u589e\u5f3a\u7684LLM\uff0c\u663e\u8457\u63d0\u5347\u4e86\u672c\u4f53\u5339\u914d\u7684\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u901a\u4fe1\u5f00\u9500\u7684\u53ef\u6bd4\u6027\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u51fa\u7684\u4f18\u5316\u6280\u672f\u5728\u5927\u89c4\u6a21\u672c\u4f53\u5339\u914d\u4e2d\u7684\u53ef\u884c\u6027\u548c\u4f18\u52bf\u3002"}}
{"id": "2507.14077", "categories": ["cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.14077", "abs": "https://arxiv.org/abs/2507.14077", "authors": ["Temiloluwa Prioleau", "Baiying Lu", "Yanjun Cui"], "title": "Glucose-ML: A collection of longitudinal diabetes datasets for development of robust AI solutions", "comment": "19 pages, 3 figures, 6 tables", "summary": "Artificial intelligence (AI) algorithms are a critical part of\nstate-of-the-art digital health technology for diabetes management. Yet, access\nto large high-quality datasets is creating barriers that impede development of\nrobust AI solutions. To accelerate development of transparent, reproducible,\nand robust AI solutions, we present Glucose-ML, a collection of 10 publicly\navailable diabetes datasets, released within the last 7 years (i.e., 2018 -\n2025). The Glucose-ML collection comprises over 300,000 days of continuous\nglucose monitor (CGM) data with a total of 38 million glucose samples collected\nfrom 2500+ people across 4 countries. Participants include persons living with\ntype 1 diabetes, type 2 diabetes, prediabetes, and no diabetes. To support\nresearchers and innovators with using this rich collection of diabetes\ndatasets, we present a comparative analysis to guide algorithm developers with\ndata selection. Additionally, we conduct a case study for the task of blood\nglucose prediction - one of the most common AI tasks within the field. Through\nthis case study, we provide a benchmark for short-term blood glucose prediction\nacross all 10 publicly available diabetes datasets within the Glucose-ML\ncollection. We show that the same algorithm can have significantly different\nprediction results when developed/evaluated with different datasets. Findings\nfrom this study are then used to inform recommendations for developing robust\nAI solutions within the diabetes or broader health domain. We provide direct\nlinks to each longitudinal diabetes dataset in the Glucose-ML collection and\nopenly provide our code.", "AI": {"tldr": "Glucose-ML\u662f\u4e00\u4e2a\u5305\u542b10\u4e2a\u516c\u5f00\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\u7684\u96c6\u5408\uff0c\u65e8\u5728\u52a0\u901f\u900f\u660e\u3001\u53ef\u590d\u73b0\u7684AI\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3002\u7814\u7a76\u53d1\u73b0\u4e0d\u540c\u6570\u636e\u96c6\u5bf9\u7b97\u6cd5\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002", "motivation": "\u5927\u578b\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u7684\u83b7\u53d6\u56f0\u96be\u963b\u788d\u4e86\u7a33\u5065AI\u89e3\u51b3\u65b9\u6848\u7684\u5f00\u53d1\uff0c\u56e0\u6b64\u9700\u8981\u516c\u5f00\u53ef\u7528\u7684\u6570\u636e\u96c6\u6765\u52a0\u901f\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u6536\u96c6\u548c\u6574\u540810\u4e2a\u516c\u5f00\u53ef\u7528\u7684\u7cd6\u5c3f\u75c5\u6570\u636e\u96c6\uff08Glucose-ML\uff09\uff0c\u5e76\u8fdb\u884c\u6bd4\u8f83\u5206\u6790\u548c\u6848\u4f8b\u7814\u7a76\uff08\u8840\u7cd6\u9884\u6d4b\u4efb\u52a1\uff09\uff0c\u8bc4\u4f30\u4e0d\u540c\u6570\u636e\u96c6\u5bf9\u7b97\u6cd5\u6027\u80fd\u7684\u5f71\u54cd\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0c\u540c\u4e00\u7b97\u6cd5\u5728\u4e0d\u540c\u6570\u636e\u96c6\u4e0a\u7684\u9884\u6d4b\u7ed3\u679c\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u8fd9\u4e3a\u5f00\u53d1\u7a33\u5065AI\u89e3\u51b3\u65b9\u6848\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002", "conclusion": "\u7814\u7a76\u5f3a\u8c03\u4e86\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u5728\u5f00\u53d1\u7a33\u5065AI\u89e3\u51b3\u65b9\u6848\u4e2d\u7684\u91cd\u8981\u6027\uff0c\u5e76\u63d0\u51fa\u4e86Glucose-ML\u6570\u636e\u96c6\u96c6\u5408\uff0c\u4ee5\u652f\u6301\u900f\u660e\u3001\u53ef\u590d\u73b0\u548c\u7a33\u5065\u7684AI\u89e3\u51b3\u65b9\u6848\u5f00\u53d1\u3002"}}
{"id": "2507.14097", "categories": ["cs.AI", "cs.CV"], "pdf": "https://arxiv.org/pdf/2507.14097", "abs": "https://arxiv.org/abs/2507.14097", "authors": ["Hari Iyer", "Neel Macwan", "Atharva Jitendra Hude", "Heejin Jeong", "Shenghan Guo"], "title": "Generative AI-Driven High-Fidelity Human Motion Simulation", "comment": null, "summary": "Human motion simulation (HMS) supports cost-effective evaluation of worker\nbehavior, safety, and productivity in industrial tasks. However, existing\nmethods often suffer from low motion fidelity. This study introduces\nGenerative-AI-Enabled HMS (G-AI-HMS), which integrates text-to-text and\ntext-to-motion models to enhance simulation quality for physical tasks.\nG-AI-HMS tackles two key challenges: (1) translating task descriptions into\nmotion-aware language using Large Language Models aligned with MotionGPT's\ntraining vocabulary, and (2) validating AI-enhanced motions against real human\nmovements using computer vision. Posture estimation algorithms are applied to\nreal-time videos to extract joint landmarks, and motion similarity metrics are\nused to compare them with AI-enhanced sequences. In a case study involving\neight tasks, the AI-enhanced motions showed lower error than human created\ndescriptions in most scenarios, performing better in six tasks based on spatial\naccuracy, four tasks based on alignment after pose normalization, and seven\ntasks based on overall temporal similarity. Statistical analysis showed that\nAI-enhanced prompts significantly (p $<$ 0.0001) reduced joint error and\ntemporal misalignment while retaining comparable posture accuracy.", "AI": {"tldr": "G-AI-HMS\u5229\u7528\u751f\u6210\u5f0fAI\u63d0\u5347\u5de5\u4e1a\u8fd0\u52a8\u6a21\u62df\u4fdd\u771f\u5ea6\uff0c\u901a\u8fc7\u6587\u672c\u5230\u52a8\u4f5c\u6a21\u578b\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u9a8c\u8bc1\uff0c\u5728\u591a\u9879\u4efb\u52a1\u4e2d\u4f18\u4e8e\u4eba\u5de5\u63cf\u8ff0\u3002", "motivation": "\u73b0\u6709\u7684\u4eba\u4f53\u8fd0\u52a8\u6a21\u62df\u65b9\u6cd5\u5728\u8fd0\u52a8\u4fdd\u771f\u5ea6\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5f71\u54cd\u4e86\u5de5\u4e1a\u4efb\u52a1\u4e2d\u5de5\u4eba\u884c\u4e3a\u3001\u5b89\u5168\u548c\u751f\u4ea7\u6548\u7387\u7684\u8bc4\u4f30\u6548\u679c\u3002", "method": "\u7814\u7a76\u91c7\u7528\u751f\u6210\u5f0fAI\u6280\u672f\uff0c\u7ed3\u5408\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff08\u5982MotionGPT\uff09\u548c\u8ba1\u7b97\u673a\u89c6\u89c9\u6280\u672f\uff0c\u5c06\u4efb\u52a1\u63cf\u8ff0\u8f6c\u5316\u4e3a\u52a8\u4f5c\u611f\u77e5\u8bed\u8a00\uff0c\u5e76\u901a\u8fc7\u59ff\u6001\u4f30\u8ba1\u7b97\u6cd5\u548c\u8fd0\u52a8\u76f8\u4f3c\u6027\u5ea6\u91cf\u9a8c\u8bc1AI\u751f\u6210\u52a8\u4f5c\u4e0e\u771f\u5b9e\u4eba\u7c7b\u52a8\u4f5c\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728\u516b\u9879\u4efb\u52a1\u7684\u6848\u4f8b\u7814\u7a76\u4e2d\uff0cAI\u589e\u5f3a\u52a8\u4f5c\u5728\u5927\u591a\u6570\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u4e8e\u4eba\u5de5\u63cf\u8ff0\uff0c\u5177\u4f53\u5728\u516d\u9879\u4efb\u52a1\u7684\u7a7a\u95f4\u51c6\u786e\u6027\u3001\u56db\u9879\u4efb\u52a1\u7684\u59ff\u6001\u5f52\u4e00\u5316\u5bf9\u9f50\u548c\u4e03\u9879\u4efb\u52a1\u7684\u6574\u4f53\u65f6\u95f4\u76f8\u4f3c\u6027\u4e0a\u8868\u73b0\u66f4\u4f73\u3002\u7edf\u8ba1\u663e\u793aAI\u63d0\u793a\u663e\u8457\u964d\u4f4e\u4e86\u5173\u8282\u8bef\u5dee\u548c\u65f6\u95f4\u9519\u4f4d\uff08p < 0.0001\uff09\u3002", "conclusion": "G-AI-HMS\u901a\u8fc7\u6574\u5408\u6587\u672c\u5230\u6587\u672c\u548c\u6587\u672c\u5230\u52a8\u4f5c\u6a21\u578b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5de5\u4e1a\u4efb\u52a1\u4e2d\u4eba\u4f53\u8fd0\u52a8\u6a21\u62df\u7684\u4fdd\u771f\u5ea6\uff0c\u5e76\u5728\u591a\u4e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u4e8e\u4eba\u5de5\u63cf\u8ff0\u7684\u6027\u80fd\u3002"}}
{"id": "2507.14107", "categories": ["cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2507.14107", "abs": "https://arxiv.org/abs/2507.14107", "authors": ["Viraj Nishesh Darji", "Callie C. Liao", "Duoduo Liao"], "title": "Automated Interpretation of Non-Destructive Evaluation Contour Maps Using Large Language Models for Bridge Condition Assessment", "comment": null, "summary": "Bridge maintenance and safety are essential for transportation authorities,\nand Non-Destructive Evaluation (NDE) techniques are critical to assessing\nstructural integrity. However, interpreting NDE data can be time-consuming and\nrequires expertise, potentially delaying decision-making. Recent advancements\nin Large Language Models (LLMs) offer new ways to automate and improve this\nanalysis. This pilot study introduces a holistic assessment of LLM capabilities\nfor interpreting NDE contour maps and demonstrates the effectiveness of LLMs in\nproviding detailed bridge condition analyses. It establishes a framework for\nintegrating LLMs into bridge inspection workflows, indicating that LLM-assisted\nanalysis can enhance efficiency without compromising accuracy. In this study,\nseveral LLMs are explored with prompts specifically designed to enhance the\nquality of image descriptions, which are applied to interpret five different\nNDE contour maps obtained through technologies for assessing bridge conditions.\nEach LLM model is evaluated based on its ability to produce detailed\ndescriptions, identify defects, provide actionable recommendations, and\ndemonstrate overall accuracy. The research indicates that four of the nine\nmodels provide better image descriptions, effectively covering a wide range of\ntopics related to the bridge's condition. The outputs from these four models\nare summarized using five different LLMs to form a comprehensive overview of\nthe bridge. Notably, LLMs ChatGPT-4 and Claude 3.5 Sonnet generate more\neffective summaries. The findings suggest that LLMs have the potential to\nsignificantly improve efficiency and accuracy. This pilot study presents an\ninnovative approach that leverages LLMs for image captioning in parallel and\nsummarization, enabling faster decision-making in bridge maintenance and\nenhancing infrastructure management and safety assessments.", "AI": {"tldr": "LLM\u80fd\u9ad8\u6548\u89e3\u91caNDE\u6570\u636e\uff0cChatGPT-4\u548cClaude 3.5 Sonnet\u8868\u73b0\u6700\u4f73\uff0c\u4e3a\u6865\u6881\u7ef4\u62a4\u63d0\u4f9b\u5feb\u901f\u51c6\u786e\u7684\u5206\u6790\u652f\u6301\u3002", "motivation": "\u4f20\u7edfNDE\u6570\u636e\u5206\u6790\u8017\u65f6\u4e14\u4f9d\u8d56\u4e13\u4e1a\u77e5\u8bc6\uff0cLLM\u7684\u8fdb\u6b65\u4e3a\u81ea\u52a8\u5316\u5206\u6790\u63d0\u4f9b\u4e86\u65b0\u53ef\u80fd\uff0c\u65e8\u5728\u63d0\u5347\u6865\u6881\u68c0\u67e5\u6548\u7387\u4e0e\u51b3\u7b56\u901f\u5ea6\u3002", "method": "\u7814\u7a76\u63a2\u7d22\u4e86\u591a\u79cdLLM\u6a21\u578b\uff0c\u901a\u8fc7\u7279\u5b9a\u8bbe\u8ba1\u7684\u63d0\u793a\u8bcd\u89e3\u91ca\u4e94\u79cdNDE\u7b49\u9ad8\u7ebf\u56fe\uff0c\u8bc4\u4f30\u6a21\u578b\u751f\u6210\u8be6\u7ec6\u63cf\u8ff0\u3001\u8bc6\u522b\u7f3a\u9677\u3001\u63d0\u4f9b\u53ef\u64cd\u4f5c\u5efa\u8bae\u53ca\u6574\u4f53\u51c6\u786e\u6027\u7684\u80fd\u529b\u3002", "result": "\u4e5d\u4e2a\u6a21\u578b\u4e2d\u6709\u56db\u4e2a\u5728\u56fe\u50cf\u63cf\u8ff0\u4e0a\u8868\u73b0\u66f4\u597d\uff0cChatGPT-4\u548cClaude 3.5 Sonnet\u751f\u6210\u7684\u6458\u8981\u66f4\u6709\u6548\u3002LLM\u8f85\u52a9\u5206\u6790\u53ef\u63d0\u5347\u6865\u6881\u7ef4\u62a4\u6548\u7387\u4e0e\u51c6\u786e\u6027\u3002", "conclusion": "LLMs\uff0c\u7279\u522b\u662fChatGPT-4\u548cClaude 3.5 Sonnet\uff0c\u5728\u89e3\u91caNDE\u7b49\u9ad8\u7ebf\u56fe\u548c\u751f\u6210\u6865\u6881\u72b6\u51b5\u7efc\u5408\u5206\u6790\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u6548\u7387\u800c\u4e0d\u727a\u7272\u51c6\u786e\u6027\u3002"}}
