<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 80]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.GR](#cs.GR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Salience Adjustment for Context-Based Emotion Recognition](https://arxiv.org/abs/2507.15878)
*Bin Han,Jonathan Gratch*

Main category: cs.CV

TL;DR: A framework using BCI and VLMs improves emotion recognition by dynamically weighting facial and contextual cues, validated in prisoner's dilemma scenarios.


<details>
  <summary>Details</summary>
Motivation: Emotion recognition in dynamic social contexts requires an understanding of the complex interaction between facial expressions and situational cues.

Method: A salience-adjusted framework for context-aware emotion recognition with Bayesian Cue Integration (BCI) and Visual-Language Models (VLMs) to dynamically weight facial and contextual information based on the expressivity of facial cues.

Result: The approach was evaluated using human annotations and automatic emotion recognition systems in prisoner's dilemma scenarios, showing enhanced performance.

Conclusion: Incorporating salience adjustment enhances emotion recognition performance, offering promising directions for future research to extend this framework to broader social contexts and multimodal applications.

Abstract: Emotion recognition in dynamic social contexts requires an understanding of
the complex interaction between facial expressions and situational cues. This
paper presents a salience-adjusted framework for context-aware emotion
recognition with Bayesian Cue Integration (BCI) and Visual-Language Models
(VLMs) to dynamically weight facial and contextual information based on the
expressivity of facial cues. We evaluate this approach using human annotations
and automatic emotion recognition systems in prisoner's dilemma scenarios,
which are designed to evoke emotional reactions. Our findings demonstrate that
incorporating salience adjustment enhances emotion recognition performance,
offering promising directions for future research to extend this framework to
broader social contexts and multimodal applications.

</details>


### [2] [Document Haystack: A Long Context Multimodal Image/Document Understanding Vision LLM Benchmark](https://arxiv.org/abs/2507.15882)
*Goeric Huybrechts,Srikanth Ronanki,Sai Muralidhar Jayanthi,Jack Fitzgerald,Srinivasan Veeravanallur*

Main category: cs.CV

TL;DR: 本文提出Document Haystack基准测试，用于评估视觉语言模型在长文档上的检索能力，包含400种文档变体和8,250个问题，并分析了不同模型的性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在分析和理解复杂多模态数据输入方面取得了显著进展，但长文档处理研究仍显不足，主要原因是缺乏合适的基准测试。

Method: 本文提出并详细描述了Document Haystack的构建过程，该基准包含400种文档变体和8,250个问题，通过在不同深度插入纯文本或多模态文本+图像“针”来测试VLMs的检索能力。

Result: Document Haystack基准测试展示了不同VLMs在长文档检索任务上的性能表现，为后续研究提供了客观、自动化的评估框架。

Conclusion: 本文介绍了Document Haystack这一综合性基准测试，旨在评估视觉语言模型（VLMs）在长且视觉复杂的文档上的表现。通过分析不同VLMs在该基准上的结果，本文探讨了该领域的潜在研究方向。

Abstract: The proliferation of multimodal Large Language Models has significantly
advanced the ability to analyze and understand complex data inputs from
different modalities. However, the processing of long documents remains
under-explored, largely due to a lack of suitable benchmarks. To address this,
we introduce Document Haystack, a comprehensive benchmark designed to evaluate
the performance of Vision Language Models (VLMs) on long, visually complex
documents. Document Haystack features documents ranging from 5 to 200 pages and
strategically inserts pure text or multimodal text+image "needles" at various
depths within the documents to challenge VLMs' retrieval capabilities.
Comprising 400 document variants and a total of 8,250 questions, it is
supported by an objective, automated evaluation framework. We detail the
construction and characteristics of the Document Haystack dataset, present
results from prominent VLMs and discuss potential research avenues in this
area.

</details>


### [3] [PAT++: a cautionary tale about generative visual augmentation for Object Re-identification](https://arxiv.org/abs/2507.15888)
*Leonardo Santiago Benitez Pereira,Arathy Jeevan*

Main category: cs.CV

TL;DR: 生成式数据增强在对象重识别任务中效果不佳，PAT++模型实验显示性能下降，暴露当前方法在身份保持应用中的局限性。


<details>
  <summary>Details</summary>
Motivation: 探索生成式数据增强在对象重识别任务中的有效性，尤其是在需要保留细粒度视觉细节的场景。

Method: 提出了PAT++模型，结合Diffusion Self-Distillation和Part-Aware Transformer，用于身份保持的图像生成。

Result: 实验表明，使用生成图像进行模型训练和查询扩展会导致性能下降，主要原因是域偏移和未能保留身份定义特征。

Conclusion: 生成式数据增强在细粒度识别任务中存在局限性，尤其是在需要保留身份定义特征的对象重识别任务中，当前方法可能导致性能下降。

Abstract: Generative data augmentation has demonstrated gains in several vision tasks,
but its impact on object re-identification - where preserving fine-grained
visual details is essential - remains largely unexplored. In this work, we
assess the effectiveness of identity-preserving image generation for object
re-identification. Our novel pipeline, named PAT++, incorporates Diffusion
Self-Distillation into the well-established Part-Aware Transformer. Using the
Urban Elements ReID Challenge dataset, we conduct extensive experiments with
generated images used for both model training and query expansion. Our results
show consistent performance degradation, driven by domain shifts and failure to
retain identity-defining features. These findings challenge assumptions about
the transferability of generative models to fine-grained recognition tasks and
expose key limitations in current approaches to visual augmentation for
identity-preserving applications.

</details>


### [4] [Local Dense Logit Relations for Enhanced Knowledge Distillation](https://arxiv.org/abs/2507.15911)
*Liuchi Xu,Kang Liu,Jinshuai Liu,Lu Wang,Lisheng Xu,Jun Cheng*

Main category: cs.CV

TL;DR: 提出LDRLD方法，通过递归解耦和重组对数信息捕捉类间关系，并结合ADW策略优化性能，实验显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究尚未深入探讨对数知识中的细粒度关系，因此需要一种更详细、更清晰的方法来指导学生学习。

Method: 提出了一种新颖的局部密集关系对数蒸馏方法（LDRLD），通过递归解耦和重组对数信息来捕捉类间关系。此外，引入了自适应衰减权重（ADW）策略，动态调整关键类别对的权重。

Result: 在CIFAR-100、ImageNet-1K和Tiny-ImageNet等数据集上的实验表明，该方法优于现有的基于对数的蒸馏方法。

Conclusion: 该方法通过传递细粒度知识并强调最关键的关系，提升了学生的性能。

Abstract: State-of-the-art logit distillation methods exhibit versatility, simplicity,
and efficiency. Despite the advances, existing studies have yet to delve
thoroughly into fine-grained relationships within logit knowledge. In this
paper, we propose Local Dense Relational Logit Distillation (LDRLD), a novel
method that captures inter-class relationships through recursively decoupling
and recombining logit information, thereby providing more detailed and clearer
insights for student learning. To further optimize the performance, we
introduce an Adaptive Decay Weight (ADW) strategy, which can dynamically adjust
the weights for critical category pairs using Inverse Rank Weighting (IRW) and
Exponential Rank Decay (ERD). Specifically, IRW assigns weights inversely
proportional to the rank differences between pairs, while ERD adaptively
controls weight decay based on total ranking scores of category pairs.
Furthermore, after the recursive decoupling, we distill the remaining
non-target knowledge to ensure knowledge completeness and enhance performance.
Ultimately, our method improves the student's performance by transferring
fine-grained knowledge and emphasizing the most critical relationships.
Extensive experiments on datasets such as CIFAR-100, ImageNet-1K, and
Tiny-ImageNet demonstrate that our method compares favorably with
state-of-the-art logit-based distillation approaches. The code will be made
publicly available.

</details>


### [5] [An empirical study for the early detection of Mpox from skin lesion images using pretrained CNN models leveraging XAI technique](https://arxiv.org/abs/2507.15915)
*Mohammad Asifur Rahim,Muhammad Nazmul Arefin,Md. Mizanur Rahman,Md Ali Hossain,Ahmed Moustafa*

Main category: cs.CV

TL;DR: 研究评估了预训练CNN模型（如InceptionV3和MobileNetV2）在猴痘检测中的效果，并利用Grad-CAM增强模型可解释性。结果显示高准确率，但也存在过拟合问题。未来需优化数据集和探索更多解释技术。


<details>
  <summary>Details</summary>
Motivation: 猴痘与其他皮肤病相似，早期准确诊断具有挑战性。AI尤其是深度学习在医学图像分析中表现优异，但预训练模型和XAI技术在猴痘检测中的应用尚未充分探索。

Method: 采用MSLD和MSLD v2.0数据集，通过迁移学习技术微调预训练CNN模型（VGG16、VGG19、InceptionV3、MobileNetV2），冻结初始层并添加自定义层以适应猴痘检测任务并避免过拟合。使用准确率、精确率、召回率、F1分数和ROC等指标评估模型性能，并利用Grad-CAM可视化关键特征。

Result: InceptionV3在二分类数据集上表现最佳，准确率达95%；MobileNetV2在多分类数据集上表现最优，准确率为93%。Grad-CAM成功突出关键图像区域。部分模型出现过拟合倾向。

Conclusion: 本研究强调了预训练CNN模型在猴痘检测中的潜力以及XAI技术的价值。未来工作应解决数据集限制，整合多模态数据，并探索更多可解释性技术以提高诊断可靠性和模型透明度。

Abstract: Context: Mpox is a zoonotic disease caused by the Mpox virus, which shares
similarities with other skin conditions, making accurate early diagnosis
challenging. Artificial intelligence (AI), especially Deep Learning (DL), has a
strong tool for medical image analysis; however, pre-trained models like CNNs
and XAI techniques for mpox detection is underexplored. Objective: This study
aims to evaluate the effectiveness of pre-trained CNN models (VGG16, VGG19,
InceptionV3, MobileNetV2) for the early detection of monkeypox using binary and
multi-class datasets. It also seeks to enhance model interpretability using
Grad-CAM an XAI technique. Method: Two datasets, MSLD and MSLD v2.0, were used
for training and validation. Transfer learning techniques were applied to
fine-tune pre-trained CNN models by freezing initial layers and adding custom
layers for adapting the final features for mpox detection task and avoid
overfitting. Models performance were evaluated using metrics such as accuracy,
precision, recall, F1-score and ROC. Grad-CAM was utilized for visualizing
critical features. Results: InceptionV3 demonstrated the best performance on
the binary dataset with an accuracy of 95%, while MobileNetV2 outperformed on
the multi-class dataset with an accuracy of 93%. Grad-CAM successfully
highlighted key image regions. Despite high accuracy, some models showed
overfitting tendencies, as videnced by discrepancies between training and
validation losses. Conclusion: This study underscores the potential of
pre-trained CNN models in monkeypox detection and the value of XAI techniques.
Future work should address dataset limitations, incorporate multimodal data,
and explore additional interpretability techniques to improve diagnostic
reliability and model transparency

</details>


### [6] [A Lightweight Face Quality Assessment Framework to Improve Face Verification Performance in Real-Time Screening Applications](https://arxiv.org/abs/2507.15961)
*Ahmed Aman Ibrahim,Hamad Mansour Alawar,Abdulnasser Abbas Zehi,Ahmed Mohammad Alkendi,Bilal Shafi Ashfaq Ahmed Mirza,Shan Ullah,Ismail Lujain Jaleel,Hassan Ugail*

Main category: cs.CV

TL;DR: 提出一种轻量级人脸质量评估框架，通过归一化关键点和随机森林分类器提升验证系统性能，显著减少误拒率。


<details>
  <summary>Details</summary>
Motivation: 低质量人脸图像（如运动模糊、光照不良、遮挡和极端姿态变化）会显著降低人脸识别模型的性能，导致更高的误拒和误接受率。

Method: 利用归一化面部关键点和随机森林回归分类器进行图像质量评估。

Result: 该方法在真实数据集上实现了96.67%的准确率，误拒率降低了99.7%，并与ArcFace模型结合提升了性能。

Conclusion: 该论文提出的轻量级框架通过整合面部质量评估模块，显著提升了人脸验证系统的性能，特别是在减少误拒率和提高余弦相似度分数方面表现优异。

Abstract: Face image quality plays a critical role in determining the accuracy and
reliability of face verification systems, particularly in real-time screening
applications such as surveillance, identity verification, and access control.
Low-quality face images, often caused by factors such as motion blur, poor
lighting conditions, occlusions, and extreme pose variations, significantly
degrade the performance of face recognition models, leading to higher false
rejection and false acceptance rates. In this work, we propose a lightweight
yet effective framework for automatic face quality assessment, which aims to
pre-filter low-quality face images before they are passed to the verification
pipeline. Our approach utilises normalised facial landmarks in conjunction with
a Random Forest Regression classifier to assess image quality, achieving an
accuracy of 96.67\%. By integrating this quality assessment module into the
face verification process, we observe a substantial improvement in performance,
including a comfortable 99.7\% reduction in the false rejection rate and
enhanced cosine similarity scores when paired with the ArcFace face
verification model. To validate our approach, we have conducted experiments on
a real-world dataset collected comprising over 600 subjects captured from CCTV
footage in unconstrained environments within Dubai Police. Our results
demonstrate that the proposed framework effectively mitigates the impact of
poor-quality face images, outperforming existing face quality assessment
techniques while maintaining computational efficiency. Moreover, the framework
specifically addresses two critical challenges in real-time screening:
variations in face resolution and pose deviations, both of which are prevalent
in practical surveillance scenarios.

</details>


### [7] [FW-VTON: Flattening-and-Warping for Person-to-Person Virtual Try-on](https://arxiv.org/abs/2507.16010)
*Zheng Wang,Xianbing Sun,Shengyi Wu,Jiahui Zhan,Jianlou Si,Chi Zhang,Liqing Zhang,Jianfu Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种名为FW-VTON的新方法，用于解决人物到人物的虚拟试穿任务，通过三个阶段实现：提取、变形和整合，并引入新数据集以提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统虚拟试穿方法主要关注服装到人物的任务，需要平面服装表示。本文旨在解决人物到人物的试穿任务，仅需目标人物和穿着服装的另一个人的图像。

Method: FW-VTON方法分为三个阶段：(1)从源图像中提取平面化的服装图像；(2)将服装变形以对齐目标姿势；(3)将变形后的服装无缝整合到目标人物上。

Result: 实验表明，FW-VTON在定性和定量评估中均达到最先进性能，并在服装提取子任务中表现优异。

Conclusion: FW-VTON通过创新的三阶段方法和专用数据集，显著提升了人物到人物虚拟试穿的效果。

Abstract: Traditional virtual try-on methods primarily focus on the garment-to-person
try-on task, which requires flat garment representations. In contrast, this
paper introduces a novel approach to the person-to-person try-on task. Unlike
the garment-to-person try-on task, the person-to-person task only involves two
input images: one depicting the target person and the other showing the garment
worn by a different individual. The goal is to generate a realistic combination
of the target person with the desired garment. To this end, we propose
Flattening-and-Warping Virtual Try-On (\textbf{FW-VTON}), a method that
operates in three stages: (1) extracting the flattened garment image from the
source image; (2) warping the garment to align with the target pose; and (3)
integrating the warped garment seamlessly onto the target person. To overcome
the challenges posed by the lack of high-quality datasets for this task, we
introduce a new dataset specifically designed for person-to-person try-on
scenarios. Experimental evaluations demonstrate that FW-VTON achieves
state-of-the-art performance, with superior results in both qualitative and
quantitative assessments, and also excels in garment extraction subtasks.

</details>


### [8] [Is Tracking really more challenging in First Person Egocentric Vision?](https://arxiv.org/abs/2507.16015)
*Matteo Dunnhofer,Zaira Manigrasso,Christian Micheloni*

Main category: cs.CV

TL;DR: 论文通过新基准研究，区分了自我中心视觉中第一人称视角与人类-物体活动理解的挑战，为相关任务提供了更精准的见解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决自我中心视觉中跟踪和分割性能下降的原因，区分第一人称视角与人类-物体活动领域的挑战。

Method: 引入了一个新的基准研究，设计了一种评估策略，以区分第一人称视角和人类-物体活动领域的挑战。

Result: 通过评估策略，论文更精确地分离了第一人称视角的独特挑战与人类-物体活动领域的挑战。

Conclusion: 通过新的基准研究，该论文更精确地区分了第一人称视角与人类-物体活动理解领域的挑战，为自我中心视觉中的跟踪和分割任务提供了更深入的见解。

Abstract: Visual object tracking and segmentation are becoming fundamental tasks for
understanding human activities in egocentric vision. Recent research has
benchmarked state-of-the-art methods and concluded that first person egocentric
vision presents challenges compared to previously studied domains. However,
these claims are based on evaluations conducted across significantly different
scenarios. Many of the challenging characteristics attributed to egocentric
vision are also present in third person videos of human-object activities. This
raises a critical question: how much of the observed performance drop stems
from the unique first person viewpoint inherent to egocentric vision versus the
domain of human-object activities? To address this question, we introduce a new
benchmark study designed to disentangle such factors. Our evaluation strategy
enables a more precise separation of challenges related to the first person
perspective from those linked to the broader domain of human-object activity
understanding. By doing so, we provide deeper insights into the true sources of
difficulty in egocentric tracking and segmentation, facilitating more targeted
advancements on this task.

</details>


### [9] [Artifacts and Attention Sinks: Structured Approximations for Efficient Vision Transformers](https://arxiv.org/abs/2507.16018)
*Andrew Lu,Wentinn Liao,Liuhui Wang,Huzheng Yang,Jianbo Shi*

Main category: cs.CV

TL;DR: 研究发现Vision transformers中的大令牌和伪令牌通过注意力机制相互抑制，提出FNA方法在线性时间内近似自注意力，并通过掩码策略提升性能，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 研究Vision transformers中大令牌和伪令牌的现象及其在注意力机制中的作用，以更好地理解其内部工作原理。

Method: 提出了Fast Nyström Attention (FNA)，一种训练自由的方法，通过利用大令牌和伪令牌形成的结构化模式，在线性时间和空间内近似自注意力。此外，还提出了一种掩码策略来降低这些令牌的噪声影响。

Result: 在流行的预训练视觉骨干上评估，FNA在检索、分类、分割和视觉问答任务中表现出竞争性性能，同时显著减少计算开销。

Conclusion: Vision transformers中的大令牌和伪令牌通过注意力机制相互抑制，在调节网络信息流中起关键作用。提出的FNA方法和掩码策略在减少计算开销的同时保持了竞争性性能。

Abstract: Vision transformers have emerged as a powerful tool across a wide range of
applications, yet their inner workings remain only partially understood. In
this work, we examine the phenomenon of massive tokens - tokens with
exceptionally high activation norms that act as attention sinks - and artifact
tokens that emerge as a byproduct during inference. Our analysis reveals that
these tokens mutually suppress one another through the attention mechanism,
playing a critical role in regulating information flow within the network.
Leveraging these insights, we introduce Fast Nystr\"om Attention (FNA), a
training-free method that approximates self-attention in linear time and space
by exploiting the structured patterns formed by massive and artifact tokens.
Additionally, we propose a masking strategy to mitigate noise from these
tokens, yielding modest performance gains at virtually no cost. We evaluate our
approach on popular pretrained vision backbones and demonstrate competitive
performance on retrieval, classification, segmentation, and visual question
answering (VQA), all while reducing computational overhead.

</details>


### [10] [Discovering and using Spelke segments](https://arxiv.org/abs/2507.16038)
*Rahul Venkatesh,Klemen Kotar,Lilian Naing Chen,Seungwoo Kim,Luca Thomas Wheeler,Jared Watrous,Ashley Xu,Gia Ancone,Wanhee Lee,Honglin Chen,Daniel Bear,Stefan Stojanov,Daniel Yamins*

Main category: cs.CV

TL;DR: 论文提出SpelkeNet，一种基于预测未来运动的视觉模型，用于提取Spelke对象，在分割和对象操纵任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究人类通过Spelke对象（基于物理运动关系的无类别对象）感知世界的方式，以改进计算机视觉中的分割任务。

Method: 提出SpelkeNet，一种视觉世界模型，通过预测未来运动分布来提取Spelke片段，并利用统计反事实探测定义Spelke片段。

Result: SpelkeNet在SpelkeBench上优于监督基线如SegmentAnything (SAM)，并在下游任务中表现出优越性能。

Conclusion: 论文展示了SpelkeNet在3DEditBench基准测试中用于物理对象操纵的下游任务中表现出色，验证了Spelke概念的实用性。

Abstract: Segments in computer vision are often defined by semantic considerations and
are highly dependent on category-specific conventions. In contrast,
developmental psychology suggests that humans perceive the world in terms of
Spelke objects--groupings of physical things that reliably move together when
acted on by physical forces. Spelke objects thus operate on category-agnostic
causal motion relationships which potentially better support tasks like
manipulation and planning. In this paper, we first benchmark the Spelke object
concept, introducing the SpelkeBench dataset that contains a wide variety of
well-defined Spelke segments in natural images. Next, to extract Spelke
segments from images algorithmically, we build SpelkeNet, a class of visual
world models trained to predict distributions over future motions. SpelkeNet
supports estimation of two key concepts for Spelke object discovery: (1) the
motion affordance map, identifying regions likely to move under a poke, and (2)
the expected-displacement map, capturing how the rest of the scene will move.
These concepts are used for "statistical counterfactual probing", where diverse
"virtual pokes" are applied on regions of high motion-affordance, and the
resultant expected displacement maps are used define Spelke segments as
statistical aggregates of correlated motion statistics. We find that SpelkeNet
outperforms supervised baselines like SegmentAnything (SAM) on SpelkeBench.
Finally, we show that the Spelke concept is practically useful for downstream
applications, yielding superior performance on the 3DEditBench benchmark for
physical object manipulation when used in a variety of off-the-shelf object
manipulation models.

</details>


### [11] [Disrupting Semantic and Abstract Features for Better Adversarial Transferability](https://arxiv.org/abs/2507.16052)
*Yuyang Luo,Xiaosen Wang,Zhijin Ge,Yingzhe He*

Main category: cs.CV

TL;DR: SAFER通过平衡语义和抽象特征的干扰，提升了对抗样本的可转移性。


<details>
  <summary>Details</summary>
Motivation: 现有特征级攻击主要操纵语义信息，而忽略了CNN更关注高频分量的特性。基于此，提出平衡语义和抽象特征干扰的方法。

Method: SAFER通过在输入图像上执行BLOCKMIX和在频谱上执行SELF-MIX来计算权重矩阵，以突出关键特征。

Result: 在ImageNet数据集上的广泛实验验证了SAFER在提升对抗样本可转移性方面的有效性。

Conclusion: SAFER方法通过平衡语义和抽象特征的干扰，显著提升了对抗样本的可转移性，为黑盒攻击提供了更有效的工具。

Abstract: Adversarial examples pose significant threats to deep neural networks (DNNs),
and their property of transferability in the black-box setting has led to the
emergence of transfer-based attacks, making it feasible to target real-world
applications employing DNNs. Among them, feature-level attacks, where
intermediate features are perturbed based on feature importance weight matrix
computed from transformed images, have gained popularity. In this work, we find
that existing feature-level attacks primarily manipulate the semantic
information to derive the weight matrix. Inspired by several works that find
CNNs tend to focus more on high-frequency components (a.k.a. abstract features,
e.g., texture, edge, etc.), we validate that transforming images in the
high-frequency space also improves transferability. Based on this finding, we
propose a balanced approach called Semantic and Abstract FEatures disRuption
(SAFER). Specifically, SAFER conducts BLOCKMIX on the input image and SELF-MIX
on the frequency spectrum when computing the weight matrix to highlight crucial
features. By using such a weight matrix, we can direct the attacker to disrupt
both semantic and abstract features, leading to improved transferability.
Extensive experiments on the ImageNet dataset also demonstrate the
effectiveness of our method in boosting adversarial transferability.

</details>


### [12] [Improving Personalized Image Generation through Social Context Feedback](https://arxiv.org/abs/2507.16095)
*Parul Gupta,Abhinav Dhall,Thanh-Toan Do*

Main category: cs.CV

TL;DR: 论文提出通过反馈微调改进个性化图像生成，解决姿势、身份和视线不自然的问题，并在三个基准数据集上验证了效果。


<details>
  <summary>Details</summary>
Motivation: 现有个性化图像生成方法在复杂活动、身份保持和视线自然性方面存在不足。

Method: 利用最先进的姿势、交互、面部识别和视线检测器对扩散模型进行反馈微调，并分时间步引入不同反馈模块。

Result: 在三个基准数据集上，生成的图像在交互、面部身份和图像质量方面均有提升。

Conclusion: 反馈微调方法有效提升了个性化图像生成的性能，解决了现有方法的局限性。

Abstract: Personalized image generation, where reference images of one or more subjects
are used to generate their image according to a scene description, has gathered
significant interest in the community. However, such generated images suffer
from three major limitations -- complex activities, such as $<$man, pushing,
motorcycle$>$ are not generated properly with incorrect human poses, reference
human identities are not preserved, and generated human gaze patterns are
unnatural/inconsistent with the scene description. In this work, we propose to
overcome these shortcomings through feedback-based fine-tuning of existing
personalized generation methods, wherein, state-of-art detectors of pose,
human-object-interaction, human facial recognition and human gaze-point
estimation are used to refine the diffusion model. We also propose
timestep-based inculcation of different feedback modules, depending upon
whether the signal is low-level (such as human pose), or high-level (such as
gaze point). The images generated in this manner show an improvement in the
generated interactions, facial identities and image quality over three
benchmark datasets.

</details>


### [13] [Stop-band Energy Constraint for Orthogonal Tunable Wavelet Units in Convolutional Neural Networks for Computer Vision problems](https://arxiv.org/abs/2507.16114)
*An D. Le,Hung Nguyen,Sungbal Seo,You-Suk Bae,Truong Q. Nguyen*

Main category: cs.CV

TL;DR: 通过带阻能量约束优化滤波器，显著提升CNN在纹理数据集上的分类和异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提升CNN在纹理丰富数据集上的图像分类和异常检测性能。

Method: 通过引入带阻能量约束的滤波器，并将其集成到ResNet-18和ResNet-34中，优化了卷积、池化和下采样操作。

Result: 在CIFAR-10上准确率提升了2.48%，在Describable Textures数据集上提升了13.56%。在MVTec hazelnut异常检测任务中，分割和检测性能均优于现有方法。

Conclusion: 该论文提出的方法在图像分类和异常检测任务中表现出色，特别是在纹理丰富的数据集上，显著提升了CNN模型的性能。

Abstract: This work introduces a stop-band energy constraint for filters in orthogonal
tunable wavelet units with a lattice structure, aimed at improving image
classification and anomaly detection in CNNs, especially on texture-rich
datasets. Integrated into ResNet-18, the method enhances convolution, pooling,
and downsampling operations, yielding accuracy gains of 2.48% on CIFAR-10 and
13.56% on the Describable Textures dataset. Similar improvements are observed
in ResNet-34. On the MVTec hazelnut anomaly detection task, the proposed method
achieves competitive results in both segmentation and detection, outperforming
existing approaches.

</details>


### [14] [PUSA V1.0: Surpassing Wan-I2V with $500 Training Cost by Vectorized Timestep Adaptation](https://arxiv.org/abs/2507.16116)
*Yaofang Liu,Yumeng Ren,Aitor Artola,Yuxuan Hu,Xiaodong Cun,Xiaotong Zhao,Alan Zhao,Raymond H. Chan,Suiyun Zhang,Rui Liu,Dandan Tu,Jean-Michel Morel*

Main category: cs.CV

TL;DR: Pusa通过VTA技术提升了视频扩散模型的效率和多任务能力，以极低成本实现了高性能的I2V生成，并支持零样本多任务。


<details>
  <summary>Details</summary>
Motivation: 传统视频扩散模型在时间建模上存在局限性，如帧演化的刚性同步，导致计算效率低下、灾难性遗忘或适用范围狭窄。

Method: 采用向量化时间步适应（VTA）对SOTA Wan2.1-T2V-14B模型进行微调，保留了基础模型的能力，同时注入了时间动态。

Result: Pusa在I2V生成中达到了87.32%的VBench-I2V总分（优于Wan-I2V-14B的86.86%），训练成本仅为1/200（\$500 vs. \$100,000），数据集大小为1/2500（4K vs. 10M样本）。

Conclusion: Pusa通过向量化时间步适应（VTA）在统一视频扩散框架中实现了细粒度时间控制，不仅提升了图像到视频（I2V）生成的性能，还解锁了零样本多任务能力，为下一代视频合成建立了可扩展、高效且多功能的范例。

Abstract: The rapid advancement of video diffusion models has been hindered by
fundamental limitations in temporal modeling, particularly the rigid
synchronization of frame evolution imposed by conventional scalar timestep
variables. While task-specific adaptations and autoregressive models have
sought to address these challenges, they remain constrained by computational
inefficiency, catastrophic forgetting, or narrow applicability. In this work,
we present Pusa, a groundbreaking paradigm that leverages vectorized timestep
adaptation (VTA) to enable fine-grained temporal control within a unified video
diffusion framework. Besides, VTA is a non-destructive adaptation, which means
it fully preserves the capabilities of the base model. By finetuning the SOTA
Wan2.1-T2V-14B model with VTA, we achieve unprecedented efficiency --
surpassing the performance of Wan-I2V-14B with $\leq$ 1/200 of the training
cost (\$500 vs. $\geq$ \$100,000) and $\leq$ 1/2500 of the dataset size (4K vs.
$\geq$ 10M samples). Pusa not only sets a new standard for image-to-video (I2V)
generation, achieving a VBench-I2V total score of 87.32\% (vs. 86.86\% of
Wan-I2V-14B), but also unlocks many zero-shot multi-task capabilities such as
start-end frames and video extension -- all without task-specific training.
Meanwhile, Pusa can still perform text-to-video generation. Mechanistic
analyses reveal that our approach preserves the foundation model's generative
priors while surgically injecting temporal dynamics, avoiding the combinatorial
explosion inherent to vectorized timesteps. This work establishes a scalable,
efficient, and versatile paradigm for next-generation video synthesis,
democratizing high-fidelity video generation for research and industry alike.
Code is open-sourced at https://github.com/Yaofang-Liu/Pusa-VidGen

</details>


### [15] [Universal Wavelet Units in 3D Retinal Layer Segmentation](https://arxiv.org/abs/2507.16119)
*An D. Le,Hung Nguyen,Melanie Tran,Jesse Most,Dirk-Uwe G. Bartsch,William R Freeman,Shyamanga Borooah,Truong Q. Nguyen,Cheolhong An*

Main category: cs.CV

TL;DR: 首次将可调小波单元（UwUs）应用于3D视网膜层分割，通过集成三种小波模块到MGU-Net中，显著提升了OCT图像的分割精度。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统最大池化在3D视网膜层分割中的局限性，研究探索了可调小波单元的应用。

Method: 研究将三种基于小波的下采样模块（OrthLattUwU、BiorthLattUwU和LS-BiorthLattUwU）集成到运动校正的MGU-Net架构中，利用可学习的格型滤波器组保留低频和高频特征。

Result: 在Jacobs Retina Center（JRC）OCT数据集上的评估显示，该方法在准确性和Dice分数上有显著提升，尤其是LS-BiorthLattUwU模块表现最佳。

Conclusion: 该研究展示了可调小波单元（UwUs）在3D视网膜层分割中的有效性，特别是在OCT体积图像中，通过LS-BiorthLattUwU模块显著提升了分割精度。

Abstract: This paper presents the first study to apply tunable wavelet units (UwUs) for
3D retinal layer segmentation from Optical Coherence Tomography (OCT) volumes.
To overcome the limitations of conventional max-pooling, we integrate three
wavelet-based downsampling modules, OrthLattUwU, BiorthLattUwU, and
LS-BiorthLattUwU, into a motion-corrected MGU-Net architecture. These modules
use learnable lattice filter banks to preserve both low- and high-frequency
features, enhancing spatial detail and structural consistency. Evaluated on the
Jacobs Retina Center (JRC) OCT dataset, our framework shows significant
improvement in accuracy and Dice score, particularly with LS-BiorthLattUwU,
highlighting the benefits of tunable wavelet filters in volumetric medical
image segmentation.

</details>


### [16] [LongSplat: Online Generalizable 3D Gaussian Splatting from Long Sequence Images](https://arxiv.org/abs/2507.16144)
*Guichen Huang,Ruoyu Wang,Xiangjun Gao,Che Sun,Yuwei Wu,Shenghua Gao,Yunde Jia*

Main category: cs.CV

TL;DR: LongSplat是一种实时3D高斯重建框架，通过流式更新和GIR表示，高效处理长序列输入，显著提升实时性和压缩效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D高斯重建方法在长序列场景中效率低、无法实时更新的问题。

Method: 提出了LongSplat框架，采用流式更新机制和GIR表示，实现高效增量更新和历史高斯选择性压缩。

Result: LongSplat在实时新视角合成中实现了效率与质量的最佳权衡，高斯数量减少44%，且能实时重建。

Conclusion: LongSplat通过高效的流式更新机制和Gaussian-Image Representation（GIR），在实时3D高斯重建中实现了效率与质量的平衡，显著降低了高斯数量并提升了实时性。

Abstract: 3D Gaussian Splatting achieves high-fidelity novel view synthesis, but its
application to online long-sequence scenarios is still limited. Existing
methods either rely on slow per-scene optimization or fail to provide efficient
incremental updates, hindering continuous performance. In this paper, we
propose LongSplat, an online real-time 3D Gaussian reconstruction framework
designed for long-sequence image input. The core idea is a streaming update
mechanism that incrementally integrates current-view observations while
selectively compressing redundant historical Gaussians. Crucial to this
mechanism is our Gaussian-Image Representation (GIR), a representation that
encodes 3D Gaussian parameters into a structured, image-like 2D format. GIR
simultaneously enables efficient fusion of current-view and historical
Gaussians and identity-aware redundancy compression. These functions enable
online reconstruction and adapt the model to long sequences without
overwhelming memory or computational costs. Furthermore, we leverage an
existing image compression method to guide the generation of more compact and
higher-quality 3D Gaussians. Extensive evaluations demonstrate that LongSplat
achieves state-of-the-art efficiency-quality trade-offs in real-time novel view
synthesis, delivering real-time reconstruction while reducing Gaussian counts
by 44\% compared to existing per-pixel Gaussian prediction methods.

</details>


### [17] [SPACT18: Spiking Human Action Recognition Benchmark Dataset with Complementary RGB and Thermal Modalities](https://arxiv.org/abs/2507.16151)
*Yasser Ashraf,Ahmed Sharshar,Velibor Bojkovic,Bin Gu*

Main category: cs.CV

TL;DR: 本文提出了首个尖峰相机视频动作识别数据集，结合RGB和热成像模态，为SNNs提供基准测试，推动能量高效的视频理解研究。


<details>
  <summary>Details</summary>
Motivation: 尖峰相机提供了超高的能量效率和卓越的时间分辨率，为连续变化提供了更精确的表示，这为研究能量高效的视频理解提供了独特的机会。

Method: 引入了首个使用尖峰相机的视频动作识别数据集，并与同步的RGB和热成像模态结合，为脉冲神经网络（SNNs）提供了全面的基准测试。

Result: 三个数据集为多模态视频理解提供了独特的平台，并作为直接比较尖峰、热成像和RGB模态的宝贵资源。

Conclusion: 本文贡献了一个新颖的尖峰相机数据集，推动了基于尖峰数据的动作识别研究，特别适用于能量高效、超低功耗的视频理解。

Abstract: Spike cameras, bio-inspired vision sensors, asynchronously fire spikes by
accumulating light intensities at each pixel, offering ultra-high energy
efficiency and exceptional temporal resolution. Unlike event cameras, which
record changes in light intensity to capture motion, spike cameras provide even
finer spatiotemporal resolution and a more precise representation of continuous
changes. In this paper, we introduce the first video action recognition (VAR)
dataset using spike camera, alongside synchronized RGB and thermal modalities,
to enable comprehensive benchmarking for Spiking Neural Networks (SNNs). By
preserving the inherent sparsity and temporal precision of spiking data, our
three datasets offer a unique platform for exploring multimodal video
understanding and serve as a valuable resource for directly comparing spiking,
thermal, and RGB modalities. This work contributes a novel dataset that will
drive research in energy-efficient, ultra-low-power video understanding,
specifically for action recognition tasks using spike-based data.

</details>


### [18] [LSSGen: Leveraging Latent Space Scaling in Flow and Diffusion for Efficient Text to Image Generation](https://arxiv.org/abs/2507.16154)
*Jyun-Ze Tang,Chih-Fan Hsu,Jeng-Lin Li,Ming-Ching Chang,Wei-Chao Chen*

Main category: cs.CV

TL;DR: LSSGen是一种在潜在空间直接进行分辨率缩放的框架，显著提升图像生成效率和质量，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法在像素空间进行降采样和上采样会引入伪影和失真，影响最终图像质量。

Method: 提出了一种轻量级的潜在空间上采样器（LSSGen），直接在潜在空间进行分辨率缩放，无需改变Transformer或U-Net架构。

Result: 在生成$1024^2$图像时，LSSGen在相似速度下实现了高达246%的TOPIQ分数提升。

Conclusion: LSSGen框架通过在潜在空间直接进行分辨率缩放，显著提升了图像生成的效率和质量，支持灵活的多分辨率生成，且在文本-图像对齐和感知质量方面优于传统方法。

Abstract: Flow matching and diffusion models have shown impressive results in
text-to-image generation, producing photorealistic images through an iterative
denoising process. A common strategy to speed up synthesis is to perform early
denoising at lower resolutions. However, traditional methods that downscale and
upscale in pixel space often introduce artifacts and distortions. These issues
arise when the upscaled images are re-encoded into the latent space, leading to
degraded final image quality. To address this, we propose {\bf Latent Space
Scaling Generation (LSSGen)}, a framework that performs resolution scaling
directly in the latent space using a lightweight latent upsampler. Without
altering the Transformer or U-Net architecture, LSSGen improves both efficiency
and visual quality while supporting flexible multi-resolution generation. Our
comprehensive evaluation covering text-image alignment and perceptual quality
shows that LSSGen significantly outperforms conventional scaling approaches.
When generating $1024^2$ images at similar speeds, it achieves up to 246\%
TOPIQ score improvement.

</details>


### [19] [AMMNet: An Asymmetric Multi-Modal Network for Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.16158)
*Hui Ye,Haodong Chen,Zeke Zexi Hu,Xiaoming Chen,Yuk Ying Chung*

Main category: cs.CV

TL;DR: AMMNet通过非对称架构设计，优化RGB和DSM数据融合，提升语义分割效率与精度。


<details>
  <summary>Details</summary>
Motivation: 遥感图像语义分割中，RGB和DSM数据的融合常面临计算复杂性增加和模态不对齐的问题，影响分割效率和精度。

Method: AMMNet采用非对称双编码器（ADE）模块、非对称先验融合器（APF）和分布对齐（DA）模块，分别针对冗余计算、模态对齐和特征分布对齐进行优化。

Result: 在ISPRS Vaihingen和Potsdam数据集上的实验表明，AMMNet在减少计算和内存需求的同时，达到了多模态网络中最先进的分割精度。

Conclusion: AMMNet通过非对称多模态网络设计，有效解决了RGB和DSM数据融合中的计算复杂性和模态对齐问题，显著提升了语义分割的效率和鲁棒性。

Abstract: Semantic segmentation in remote sensing (RS) has advanced significantly with
the incorporation of multi-modal data, particularly the integration of RGB
imagery and the Digital Surface Model (DSM), which provides complementary
contextual and structural information about the ground object. However,
integrating RGB and DSM often faces two major limitations: increased
computational complexity due to architectural redundancy, and degraded
segmentation performance caused by modality misalignment. These issues
undermine the efficiency and robustness of semantic segmentation, particularly
in complex urban environments where precise multi-modal integration is
essential. To overcome these limitations, we propose Asymmetric Multi-Modal
Network (AMMNet), a novel asymmetric architecture that achieves robust and
efficient semantic segmentation through three designs tailored for RGB-DSM
input pairs. To reduce architectural redundancy, the Asymmetric Dual Encoder
(ADE) module assigns representational capacity based on modality-specific
characteristics, employing a deeper encoder for RGB imagery to capture rich
contextual information and a lightweight encoder for DSM to extract sparse
structural features. Besides, to facilitate modality alignment, the Asymmetric
Prior Fuser (APF) integrates a modality-aware prior matrix into the fusion
process, enabling the generation of structure-aware contextual features.
Additionally, the Distribution Alignment (DA) module enhances cross-modal
compatibility by aligning feature distributions through divergence
minimization. Extensive experiments on the ISPRS Vaihingen and Potsdam datasets
demonstrate that AMMNet attains state-of-the-art segmentation accuracy among
multi-modal networks while reducing computational and memory requirements.

</details>


### [20] [AtrousMamaba: An Atrous-Window Scanning Visual State Space Model for Remote Sensing Change Detection](https://arxiv.org/abs/2507.16172)
*Tao Wang,Tiecheng Bai,Chao Xu,Bin Liu,Erlei Zhang,Jiyun Huang,Hongming Zhang*

Main category: cs.CV

TL;DR: 提出AtrousMamba模型，通过空洞窗口选择性扫描机制平衡局部与全局信息提取，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在增强全局感受野时往往忽视局部信息的重要性，且Mamba是否能像CNN一样有效提取局部特征尚待研究。

Method: 提出了AtrousMamba模型，结合了空洞窗口选择性扫描机制，逐步扩展扫描范围并调整速率，以平衡细粒度局部细节和全局上下文信息的提取。

Result: 在六个基准数据集上的实验结果表明，所提框架优于现有的基于CNN、Transformer和Mamba的方法。

Conclusion: Mamba模型不仅能捕捉视觉数据中的长距离依赖关系，还能有效保留细粒度的局部细节。

Abstract: Recently, a novel visual state space (VSS) model, referred to as Mamba, has
demonstrated significant progress in modeling long sequences with linear
complexity, comparable to Transformer models, thereby enhancing its
adaptability for processing visual data. Although most methods aim to enhance
the global receptive field by directly modifying Mamba's scanning mechanism,
they tend to overlook the critical importance of local information in dense
prediction tasks. Additionally, whether Mamba can effectively extract local
features as convolutional neural networks (CNNs) do remains an open question
that merits further investigation. In this paper, We propose a novel model,
AtrousMamba, which effectively balances the extraction of fine-grained local
details with the integration of global contextual information. Specifically,
our method incorporates an atrous-window selective scan mechanism, enabling a
gradual expansion of the scanning range with adjustable rates. This design
shortens the distance between adjacent tokens, enabling the model to
effectively capture fine-grained local features and global context. By
leveraging the atrous window scan visual state space (AWVSS) module, we design
dedicated end-to-end Mamba-based frameworks for binary change detection (BCD)
and semantic change detection (SCD), referred to as AWMambaBCD and AWMambaSCD,
respectively. Experimental results on six benchmark datasets show that the
proposed framework outperforms existing CNN-based, Transformer-based, and
Mamba-based methods. These findings clearly demonstrate that Mamba not only
captures long-range dependencies in visual data but also effectively preserves
fine-grained local details.

</details>


### [21] [Explicit Context Reasoning with Supervision for Visual Tracking](https://arxiv.org/abs/2507.16191)
*Fansheng Zeng,Bineng Zhong,Haiying Xia,Yufei Tan,Xiantao Hu,Liangtao Shi,Shuxiang Song*

Main category: cs.CV

TL;DR: RSTrack通过上下文推理、前向监督和高效状态建模三个机制，解决了传统跟踪算法在上下文关联中的问题，实现了高性能和实时运行。


<details>
  <summary>Details</summary>
Motivation: 主流跟踪算法通常仅通过堆叠历史信息来关联上下文，缺乏对关联过程的显式监督，难以有效建模目标的动态演变。

Method: RSTrack通过三个核心机制进行上下文推理：1) 上下文推理机制构建目标状态推理管道；2) 前向监督策略利用真实目标特征作为锚点；3) 高效状态建模采用压缩-重构机制提取目标核心特征。

Result: 实验结果表明，RSTrack在多个基准数据集上实现了最先进的性能，同时保持了实时运行速度。

Conclusion: RSTrack通过其三个核心机制有效解决了传统时间建模中的上下文关联发散问题，并在多个基准数据集上实现了最先进的性能，同时保持了实时运行速度。

Abstract: Contextual reasoning with constraints is crucial for enhancing temporal
consistency in cross-frame modeling for visual tracking. However, mainstream
tracking algorithms typically associate context by merely stacking historical
information without explicitly supervising the association process, making it
difficult to effectively model the target's evolving dynamics. To alleviate
this problem, we propose RSTrack, which explicitly models and supervises
context reasoning via three core mechanisms. \textit{1) Context Reasoning
Mechanism}: Constructs a target state reasoning pipeline, converting
unconstrained contextual associations into a temporal reasoning process that
predicts the current representation based on historical target states, thereby
enhancing temporal consistency. \textit{2) Forward Supervision Strategy}:
Utilizes true target features as anchors to constrain the reasoning pipeline,
guiding the predicted output toward the true target distribution and
suppressing drift in the context reasoning process. \textit{3) Efficient State
Modeling}: Employs a compression-reconstruction mechanism to extract the core
features of the target, removing redundant information across frames and
preventing ineffective contextual associations. These three mechanisms
collaborate to effectively alleviate the issue of contextual association
divergence in traditional temporal modeling. Experimental results show that
RSTrack achieves state-of-the-art performance on multiple benchmark datasets
while maintaining real-time running speeds. Our code is available at
https://github.com/GXNU-ZhongLab/RSTrack.

</details>


### [22] [LMM4Edit: Benchmarking and Evaluating Multimodal Image Editing with LMMs](https://arxiv.org/abs/2507.16193)
*Zitong Xu,Huiyu Duan,Bingnan Liu,Guangji Ma,Jiarui Wang,Liu Yang,Shiqi Gao,Xiaoyu Wang,Jia Wang,Xiongkuo Min,Guangtao Zhai,Weisi Lin*

Main category: cs.CV

TL;DR: EBench-18K是首个大规模TIE评估基准，结合LMM4Edit指标，显著提升了对TIE模型的评估效果，实验结果验证了其优越性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前TIE模型在图像质量、编辑对齐和与原始图像的一致性方面存在不足，且现有评估基准和指标在规模或与人类感知对齐方面有局限性。

Method: 提出EBench-18K，一个包含18K编辑图像的大规模评估基准，并基于此开发LMM4Edit，一个基于LMM的评估指标，从多个维度全面评估TIE模型。

Result: LMM4Edit在实验中表现优异，与人类偏好高度一致，并在其他数据集上展示了良好的泛化能力。

Conclusion: EBench-18K和LMM4Edit的引入显著提升了文本引导图像编辑（TIE）模型的评估效果，LMM4Edit在感知质量、编辑对齐、属性保留和任务特定QA准确性方面表现出色，并与人类偏好高度一致。

Abstract: The rapid advancement of Text-guided Image Editing (TIE) enables image
modifications through text prompts. However, current TIE models still struggle
to balance image quality, editing alignment, and consistency with the original
image, limiting their practical applications. Existing TIE evaluation
benchmarks and metrics have limitations on scale or alignment with human
perception. To this end, we introduce EBench-18K, the first large-scale image
Editing Benchmark including 18K edited images with fine-grained human
preference annotations for evaluating TIE. Specifically, EBench-18K includes
1,080 source images with corresponding editing prompts across 21 tasks, 18K+
edited images produced by 17 state-of-the-art TIE models, 55K+ mean opinion
scores (MOSs) assessed from three evaluation dimensions, and 18K+
question-answering (QA) pairs. Based on EBench-18K, we employ outstanding LMMs
to assess edited images, while the evaluation results, in turn, provide
insights into assessing the alignment between the LMMs' understanding ability
and human preferences. Then, we propose LMM4Edit, a LMM-based metric for
evaluating image Editing models from perceptual quality, editing alignment,
attribute preservation, and task-specific QA accuracy in an all-in-one manner.
Extensive experiments show that LMM4Edit achieves outstanding performance and
aligns well with human preference. Zero-shot validation on the other datasets
also shows the generalization ability of our model. The dataset and code are
available at https://github.com/IntMeGroup/LMM4Edit.

</details>


### [23] [A Single-step Accurate Fingerprint Registration Method Based on Local Feature Matching](https://arxiv.org/abs/2507.16201)
*Yuwei Jia,Zhe Cui,Fei Su*

Main category: cs.CV

TL;DR: 提出了一种端到端单步指纹配准算法，通过预测半密集匹配点直接对齐指纹，减少了细节配准失败风险，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 指纹图像的失真会导致识别性能下降，而现有配准方法在低质量图像中因细节减少容易导致初始配准失败，从而影响整个配准过程。

Method: 提出了一种端到端的单步指纹配准算法，通过直接预测两个指纹之间的半密集匹配点对应关系，结合全局-局部注意力机制，实现端到端的像素级对齐。

Result: 实验结果表明，该方法仅通过单步配准即可达到最先进的匹配性能，并可与密集配准算法结合进一步提升性能。

Conclusion: 该研究提出的端到端单步指纹配准算法通过直接预测半密集匹配点对应关系，有效减少了细节配准失败的风险，并利用全局-局部注意力实现了端到端的像素级对齐，实验证明其具有最先进的匹配性能。

Abstract: Distortion of the fingerprint images leads to a decline in fingerprint
recognition performance, and fingerprint registration can mitigate this
distortion issue by accurately aligning two fingerprint images. Currently,
fingerprint registration methods often consist of two steps: an initial
registration based on minutiae, and a dense registration based on matching
points. However, when the quality of fingerprint image is low, the number of
detected minutiae is reduced, leading to frequent failures in the initial
registration, which ultimately causes the entire fingerprint registration
process to fail. In this study, we propose an end-to-end single-step
fingerprint registration algorithm that aligns two fingerprints by directly
predicting the semi-dense matching points correspondences between two
fingerprints. Thus, our method minimizes the risk of minutiae registration
failure and also leverages global-local attentions to achieve end-to-end
pixel-level alignment between the two fingerprints. Experiment results prove
that our method can achieve the state-of-the-art matching performance with only
single-step registration, and it can also be used in conjunction with dense
registration algorithms for further performance improvements.

</details>


### [24] [Advancing Visual Large Language Model for Multi-granular Versatile Perception](https://arxiv.org/abs/2507.16213)
*Wentao Xiang,Haoxian Tan,Cong Wei,Yujie Zhong,Dengjie Li,Yujiu Yang*

Main category: cs.CV

TL;DR: MVP-LM是一种多粒度通用视觉感知框架，结合视觉大语言模型，支持多种任务，实验证明其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常局限于少数感知任务组合，限制了其适用性。MVP-LM旨在提供一种通用且多功能的感知框架。

Method: 提出MVP-LM框架，结合视觉大语言模型，支持词级和句级感知任务，并引入多粒度解码器和CoT启发式数据集统一策略。

Result: 在多个基准测试中，MVP-LM在词级和句级感知任务中均表现出色。

Conclusion: MVP-LM框架通过多粒度解码器和数据集统一策略，展示了在多种视觉感知任务中的高效性和通用性。

Abstract: Perception is a fundamental task in the field of computer vision,
encompassing a diverse set of subtasks that can be systematically categorized
into four distinct groups based on two dimensions: prediction type and
instruction type. Notably, existing researches often focus solely on a limited
subset of these potential combinations, which constrains their applicability
and versatility across various contexts. In response to this challenge, we
present MVP-LM, a Multi-granular and Versatile Perception framework
incorporating Visual Large Language Model. Our framework is designed to
integrate both word-based and sentence-based perception tasks alongside box and
mask predictions within a single architecture. MVP-LM features an innovative
multi-granularity decoder in conjunction with a CoT-inspired dataset
unification strategy, enabling seamless supervised fine-tuning across a wide
spectrum of tasks, including but not limited to panoptic segmentation,
detection, grounding, and referring expression segmentation. Furthermore, we
introduce a query enhancement strategy aimed at harnessing the decoding and
generative capabilities inherent in VLLMs. Extensive experiments conducted
across a range of benchmarks in both word-based and sentence-based perception
tasks substantiate the efficacy of our framework. The code will be available at
https://github.com/xiangwentao666/MVP-LM.

</details>


### [25] [ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning](https://arxiv.org/abs/2507.16815)
*Chi-Pin Huang,Yueh-Hua Wu,Min-Hung Chen,Yu-Chiang Frank Wang,Fu-En Yang*

Main category: cs.CV

TL;DR: ThinkAct是一种结合推理与动作执行的双系统框架，通过强化视觉潜在规划提升复杂任务中的适应性和规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常以端到端方式训练，缺乏显式推理能力，难以实现多步规划或适应复杂任务变化。

Method: 提出ThinkAct双系统框架，通过强化视觉潜在规划连接高层推理与低层动作执行，训练多模态LLM生成体现推理计划，并通过视觉潜在计划条件化下游动作模型。

Result: 在体现推理和机器人操作基准测试中，ThinkAct表现出few-shot适应、长程规划和自我纠正能力。

Conclusion: ThinkAct框架通过结合高层推理与低层动作执行，在复杂体现AI任务中实现了few-shot适应、长程规划和自我纠正行为。

Abstract: Vision-language-action (VLA) reasoning tasks require agents to interpret
multimodal instructions, perform long-horizon planning, and act adaptively in
dynamic environments. Existing approaches typically train VLA models in an
end-to-end fashion, directly mapping inputs to actions without explicit
reasoning, which hinders their ability to plan over multiple steps or adapt to
complex task variations. In this paper, we propose ThinkAct, a dual-system
framework that bridges high-level reasoning with low-level action execution via
reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate
embodied reasoning plans guided by reinforcing action-aligned visual rewards
based on goal completion and trajectory consistency. These reasoning plans are
compressed into a visual plan latent that conditions a downstream action model
for robust action execution on target environments. Extensive experiments on
embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct
enables few-shot adaptation, long-horizon planning, and self-correction
behaviors in complex embodied AI tasks.

</details>


### [26] [LDRFusion: A LiDAR-Dominant multimodal refinement framework for 3D object detection](https://arxiv.org/abs/2507.16224)
*Jijun Wang,Yan Wu,Yujian Mo,Junqiao Zhao,Jun Yan,Yinghao Hu*

Main category: cs.CV

TL;DR: LDRFusion是一种LiDAR主导的两阶段优化框架，通过分层伪点残差编码增强伪点云表示，显著提升3D物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有LiDAR-Camera融合方法中伪点云引入噪声导致预测不准确的问题，充分利用各模态的特性和可靠性。

Method: 提出LDRFusion，一种基于LiDAR主导的两阶段优化框架，第一阶段仅依赖LiDAR生成精确定位的提案，第二阶段结合伪点云检测挑战性实例，并通过分层伪点残差编码模块增强伪点云的局部结构表示。

Result: 在KITTI数据集上的实验表明，该框架在多个类别和难度级别上均取得强劲性能。

Conclusion: LDRFusion框架在KITTI数据集上表现出色，能够稳定提升多类别和不同难度级别的3D物体检测性能。

Abstract: Existing LiDAR-Camera fusion methods have achieved strong results in 3D
object detection. To address the sparsity of point clouds, previous approaches
typically construct spatial pseudo point clouds via depth completion as
auxiliary input and adopts a proposal-refinement framework to generate
detection results. However, introducing pseudo points inevitably brings noise,
potentially resulting in inaccurate predictions. Considering the differing
roles and reliability levels of each modality, we propose LDRFusion, a novel
Lidar-dominant two-stage refinement framework for multi-sensor fusion. The
first stage soley relies on LiDAR to produce accurately localized proposals,
followed by a second stage where pseudo point clouds are incorporated to detect
challenging instances. The instance-level results from both stages are
subsequently merged. To further enhance the representation of local structures
in pseudo point clouds, we present a hierarchical pseudo point residual
encoding module, which encodes neighborhood sets using both feature and
positional residuals. Experiments on the KITTI dataset demonstrate that our
framework consistently achieves strong performance across multiple categories
and difficulty levels.

</details>


### [27] [MONITRS: Multimodal Observations of Natural Incidents Through Remote Sensing](https://arxiv.org/abs/2507.16228)
*Shreelekha Revankar,Utkarsh Mall,Cheng Perng Phoo,Kavita Bala,Bharath Hariharan*

Main category: cs.CV

TL;DR: MONITRS是一个新型多模态数据集，结合卫星图像和自然语言注释，显著提升了机器学习在灾害监测中的表现。


<details>
  <summary>Details</summary>
Motivation: 自然灾害每年对社区和基础设施造成破坏，但现有计算机视觉和深度学习技术受限于特定灾害类型、依赖专家手动解释及缺乏足够时间粒度或自然语言注释的数据集。

Method: 提出了MONITRS数据集，包含超过10,000个FEMA灾害事件的时间序列卫星图像、自然语言注释、地理标记位置和问答对。通过微调现有MLLMs在该数据集上的训练，验证了其性能提升。

Result: 微调后的MLLMs在灾害监测任务中表现出显著性能提升，验证了MONITRS数据集的有效性。

Conclusion: MONITRS数据集通过结合时间序列卫星图像和自然语言注释，显著提升了现有MLLMs在灾害监测任务中的性能，为机器学习辅助的灾害响应系统设立了新基准。

Abstract: Natural disasters cause devastating damage to communities and infrastructure
every year. Effective disaster response is hampered by the difficulty of
accessing affected areas during and after events. Remote sensing has allowed us
to monitor natural disasters in a remote way. More recently there have been
advances in computer vision and deep learning that help automate satellite
imagery analysis, However, they remain limited by their narrow focus on
specific disaster types, reliance on manual expert interpretation, and lack of
datasets with sufficient temporal granularity or natural language annotations
for tracking disaster progression. We present MONITRS, a novel multimodal
dataset of more than 10,000 FEMA disaster events with temporal satellite
imagery and natural language annotations from news articles, accompanied by
geotagged locations, and question-answer pairs. We demonstrate that fine-tuning
existing MLLMs on our dataset yields significant performance improvements for
disaster monitoring tasks, establishing a new benchmark for machine
learning-assisted disaster response systems. Code can be found at:
https://github.com/ShreelekhaR/MONITRS

</details>


### [28] [Positive Style Accumulation: A Style Screening and Continuous Utilization Framework for Federated DG-ReID](https://arxiv.org/abs/2507.16238)
*Xin Xu,Chaoyue Ren,Wei Liu,Wenke Huang,Bin Yang,Zhixi Yu,Kui Jiang*

Main category: cs.CV

TL;DR: 提出SSCU框架，通过GGDSM筛选正样本风格，CST策略持续利用，显著提升模型泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过风格变换增强样本多样性，但并非所有风格都有助于泛化性能。因此，需筛选并持续利用正样本风格。

Method: 设计了GGDSM模块用于筛选和积累正样本风格，并提出风格记忆识别损失函数；采用CST策略，结合新生成风格和记忆中的正样本风格进行双分支训练。

Result: 实验结果表明，该方法在源域和目标域均优于现有方法。

Conclusion: 论文提出的SSCU框架通过GGDSM和CST策略，有效筛选并持续利用正样本风格，显著提升了模型在源域和目标域的泛化性能。

Abstract: The Federated Domain Generalization for Person re-identification (FedDG-ReID)
aims to learn a global server model that can be effectively generalized to
source and target domains through distributed source domain data. Existing
methods mainly improve the diversity of samples through style transformation,
which to some extent enhances the generalization performance of the model.
However, we discover that not all styles contribute to the generalization
performance. Therefore, we define styles that are beneficial or harmful to the
model's generalization performance as positive or negative styles. Based on
this, new issues arise: How to effectively screen and continuously utilize the
positive styles. To solve these problems, we propose a Style Screening and
Continuous Utilization (SSCU) framework. Firstly, we design a Generalization
Gain-guided Dynamic Style Memory (GGDSM) for each client model to screen and
accumulate generated positive styles. Meanwhile, we propose a style memory
recognition loss to fully leverage the positive styles memorized by Memory.
Furthermore, we propose a Collaborative Style Training (CST) strategy to make
full use of positive styles. Unlike traditional learning strategies, our
approach leverages both newly generated styles and the accumulated positive
styles stored in memory to train client models on two distinct branches. This
training strategy is designed to effectively promote the rapid acquisition of
new styles by the client models, and guarantees the continuous and thorough
utilization of positive styles, which is highly beneficial for the model's
generalization performance. Extensive experimental results demonstrate that our
method outperforms existing methods in both the source domain and the target
domain.

</details>


### [29] [Scale Your Instructions: Enhance the Instruction-Following Fidelity of Unified Image Generation Model by Self-Adaptive Attention Scaling](https://arxiv.org/abs/2507.16240)
*Chao Zhou,Tianyi Wei,Nenghai Yu*

Main category: cs.CV

TL;DR: SaaS 方法通过动态调整注意力机制，解决了统一图像生成模型在多子指令文本下的指令忽视问题，提升了生成效果。


<details>
  <summary>Details</summary>
Motivation: 统一图像生成模型在处理包含多子指令的文本时存在指令忽视问题，影响生成效果。

Method: 通过扰动分析识别关键步骤和层，利用相邻时间步跨注意力的一致性动态缩放每个子指令的注意力激活。

Result: 实验证明 SaaS 在指令遵循保真度上优于现有方法。

Conclusion: Self-Adaptive Attention Scaling (SaaS) 方法有效提升了统一图像生成模型在遵循多子指令文本时的性能，无需额外训练或测试时优化。

Abstract: Recent advancements in unified image generation models, such as OmniGen, have
enabled the handling of diverse image generation and editing tasks within a
single framework, accepting multimodal, interleaved texts and images in free
form. This unified architecture eliminates the need for text encoders, greatly
reducing model complexity and standardizing various image generation and
editing tasks, making it more user-friendly. However, we found that it suffers
from text instruction neglect, especially when the text instruction contains
multiple sub-instructions. To explore this issue, we performed a perturbation
analysis on the input to identify critical steps and layers. By examining the
cross-attention maps of these key steps, we observed significant conflicts
between neglected sub-instructions and the activations of the input image. In
response, we propose Self-Adaptive Attention Scaling (SaaS), a method that
leverages the consistency of cross-attention between adjacent timesteps to
dynamically scale the attention activation for each sub-instruction. Our SaaS
enhances instruction-following fidelity without requiring additional training
or test-time optimization. Experimental results on instruction-based image
editing and visual conditional image generation validate the effectiveness of
our SaaS, showing superior instruction-following fidelity over existing
methods. The code is available https://github.com/zhouchao-ops/SaaS.

</details>


### [30] [HoliTracer: Holistic Vectorization of Geographic Objects from Large-Size Remote Sensing Imagery](https://arxiv.org/abs/2507.16251)
*Yu Wang,Bo Dang,Wanchun Li,Wei Chen,Yansheng Li*

Main category: cs.CV

TL;DR: HoliTracer是首个从大尺寸遥感影像中全面提取矢量化地理对象的框架，通过CAN和MCR-PST管道实现，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于处理小图像块，导致上下文信息丢失和输出碎片化，需开发新框架以全面提取大尺寸遥感影像中的矢量化地理对象。

Method: HoliTracer结合Context Attention Net（CAN）进行大尺寸影像分割，利用Mask Contour Reformer（MCR）重建多边形，并通过Polygon Sequence Tracer（PST）追踪顶点。

Result: 在建筑物、水体和道路等大尺寸遥感影像数据集上的实验表明，HoliTracer优于现有方法。

Conclusion: HoliTracer框架通过CAN和MCR-PST管道，首次实现了从大尺寸遥感影像中全面提取矢量化地理对象，显著提升了处理效果，代码和数据已开源。

Abstract: With the increasing resolution of remote sensing imagery (RSI), large-size
RSI has emerged as a vital data source for high-precision vector mapping of
geographic objects. Existing methods are typically constrained to processing
small image patches, which often leads to the loss of contextual information
and produces fragmented vector outputs. To address these, this paper introduces
HoliTracer, the first framework designed to holistically extract vectorized
geographic objects from large-size RSI. In HoliTracer, we enhance segmentation
of large-size RSI using the Context Attention Net (CAN), which employs a
local-to-global attention mechanism to capture contextual dependencies.
Furthermore, we achieve holistic vectorization through a robust pipeline that
leverages the Mask Contour Reformer (MCR) to reconstruct polygons and the
Polygon Sequence Tracer (PST) to trace vertices. Extensive experiments on
large-size RSI datasets, including buildings, water bodies, and roads,
demonstrate that HoliTracer outperforms state-of-the-art methods. Our code and
data are available in https://github.com/vvangfaye/HoliTracer.

</details>


### [31] [Edge-case Synthesis for Fisheye Object Detection: A Data-centric Perspective](https://arxiv.org/abs/2507.16254)
*Seunghyeon Kim,Kyeongryeol Go*

Main category: cs.CV

TL;DR: 本文提出了一种数据驱动的边缘案例合成方法，通过识别和解决模型盲点，显著提升了鱼眼镜头物体检测的性能。


<details>
  <summary>Details</summary>
Motivation: 鱼眼相机引入的显著扭曲给基于传统数据集训练的物体检测模型带来了独特挑战，需要一种系统性的方法来提升检测性能。

Method: 提出了一种以数据为中心的流程，通过错误分析识别模型盲点，并利用边缘案例合成技术直接解决这些问题。具体包括微调图像生成模型，并通过精心设计的提示生成复制真实世界失败模式的合成图像，然后使用高质量检测器进行伪标注并整合到训练中。

Result: 该方法在鱼眼物体检测中实现了持续的性能提升。

Conclusion: 通过深入理解数据并选择性修复其弱点，可以显著提升鱼眼镜头物体检测等专业领域的性能。

Abstract: Fisheye cameras introduce significant distortion and pose unique challenges
to object detection models trained on conventional datasets. In this work, we
propose a data-centric pipeline that systematically improves detection
performance by focusing on the key question of identifying the blind spots of
the model. Through detailed error analysis, we identify critical edge-cases
such as confusing class pairs, peripheral distortions, and underrepresented
contexts. Then we directly address them through edge-case synthesis. We
fine-tuned an image generative model and guided it with carefully crafted
prompts to produce images that replicate real-world failure modes. These
synthetic images are pseudo-labeled using a high-quality detector and
integrated into training. Our approach results in consistent performance gains,
highlighting how deeply understanding data and selectively fixing its
weaknesses can be impactful in specialized domains like fisheye object
detection.

</details>


### [32] [Quality Text, Robust Vision: The Role of Language in Enhancing Visual Robustness of Vision-Language Models](https://arxiv.org/abs/2507.16257)
*Futa Waseda,Saku Sugawara,Isao Echizen*

Main category: cs.CV

TL;DR: QT-AFT利用高质量文本指导对抗性微调，提升CLIP等视觉语言模型的零样本鲁棒性，解决了现有方法的过拟合和语义不足问题，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗训练方法在微调视觉语言模型时，忽视了语言对视觉鲁棒性的增强作用，导致过拟合或语义指导不足。QT-AFT旨在解决这些问题。

Method: 提出了Quality Text-guided Adversarial Fine-Tuning (QT-AFT)，利用高质量文本描述生成对抗样本，指导视觉编码器在对抗噪声下识别更广泛的图像特征。

Result: QT-AFT在16个零样本数据集上实现了最先进的对抗鲁棒性和清洁准确率，并揭示了语言描述（如对象属性）对零样本鲁棒性的进一步促进作用。

Conclusion: QT-AFT通过利用高质量文本指导对抗性微调，显著提升了视觉语言模型在零样本任务中的鲁棒性和准确性，同时揭示了语言在增强视觉鲁棒性中的关键作用，为未来研究提供了重要方向。

Abstract: Defending pre-trained vision-language models (VLMs), such as CLIP, against
adversarial attacks is crucial, as these models are widely used in diverse
zero-shot tasks, including image classification. However, existing adversarial
training (AT) methods for robust fine-tuning largely overlook the role of
language in enhancing visual robustness. Specifically, (1) supervised AT
methods rely on short texts (e.g., class labels) to generate adversarial
perturbations, leading to overfitting to object classes in the training data,
and (2) unsupervised AT avoids this overfitting but remains suboptimal against
practical text-guided adversarial attacks due to its lack of semantic guidance.
To address these limitations, we propose Quality Text-guided Adversarial
Fine-Tuning (QT-AFT), which leverages high-quality captions during training to
guide adversarial examples away from diverse semantics present in images. This
enables the visual encoder to robustly recognize a broader range of image
features even under adversarial noise, thereby enhancing robustness across
diverse downstream tasks. QT-AFT overcomes the key weaknesses of prior methods
-- overfitting in supervised AT and lack of semantic awareness in unsupervised
AT -- achieving state-of-the-art zero-shot adversarial robustness and clean
accuracy, evaluated across 16 zero-shot datasets. Furthermore, our
comprehensive study uncovers several key insights into the role of language in
enhancing vision robustness; for example, describing object properties in
addition to object names further enhances zero-shot robustness. Our findings
point to an urgent direction for future work -- centering high-quality
linguistic supervision in robust visual representation learning.

</details>


### [33] [ToFe: Lagged Token Freezing and Reusing for Efficient Vision Transformer Inference](https://arxiv.org/abs/2507.16260)
*Haoyue Zhang,Jie Zhang,Song Guo*

Main category: cs.CV

TL;DR: ToFe框架动态冻结和重用不重要token，平衡ViT的计算开销与性能，实验显示计算成本减半且准确率下降可控。


<details>
  <summary>Details</summary>
Motivation: 现有token减少方法不可逆地丢弃不重要token，而ViT在不同层级关注不同信息，早期丢弃的token可能在后续层级有用。ToFe旨在在模型性能和计算开销之间取得平衡。

Method: 设计了一个预测模块用于token识别，以及一个近似模块用于冻结token的恢复，通过计算预算感知的端到端训练联合优化。

Result: ToFe将LV-ViT模型的计算成本降低了50%，Top-1准确率下降不到2%，优于现有方法。

Conclusion: ToFe框架通过动态冻结和重用不重要token，显著降低了计算成本，同时保持了模型性能，为资源受限设备上的ViT部署提供了更优的解决方案。

Abstract: Although vision transformers (ViT) have shown remarkable success in various
vision tasks, their computationally expensive self-attention hinder their
deployment on resource-constrained devices. Token reduction, which discards
less important tokens during forward propagation, has been proposed to enhance
the efficiency of transformer models. However, existing methods handle
unimportant tokens irreversibly, preventing their reuse in subsequent blocks.
Considering that transformers focus on different information among blocks,
tokens reduced in early blocks might be useful later. Furthermore, to adapt
transformer models for resource-constrained devices, it is crucial to strike a
balance between model performance and computational overhead. To address these
challenges, in this paper, we introduce a novel Token Freezing and Reusing
(ToFe) framework, where we identify important tokens at each stage and
temporarily freeze the unimportant ones, allowing their lagged reusing at a
later stage. Specifically, we design a prediction module for token
identification and an approximate module for recovery of the frozen tokens. By
jointly optimizing with the backbone through computation budget-aware
end-to-end training, ToFe can adaptively process the necessary tokens at each
block, thereby reducing computational cost while maintaining performance.
Extensive experiments demonstrate that ToFe reduces the computational cost of
LV-ViT model by 50% with less than 2% drop in Top-1 accuracy, achieving a
better trade-off between performance and complexity compared to
state-of-the-art methods.

</details>


### [34] [MAN++: Scaling Momentum Auxiliary Network for Supervised Local Learning in Vision Tasks](https://arxiv.org/abs/2507.16279)
*Junhao Su,Feiyu Zhu,Hengyu Shi,Tianyang Han,Yurui Qiu,Junfeng Luo,Xiaoming Wei,Jialin Gao*

Main category: cs.CV

TL;DR: MAN++ 通过动态交互机制和可学习缩放偏置改进监督局部学习，性能接近端到端训练且节省内存。


<details>
  <summary>Details</summary>
Motivation: 端到端反向传播存在参数优化锁定、高 GPU 内存消耗和缺乏生物合理性的问题，而现有监督局部学习方法因梯度仅在局部块内传播导致性能下降。

Method: MAN++ 通过引入动态交互机制（利用相邻块的参数指数移动平均 EMA）和可学习的缩放偏置来增强跨块信息流，解决局部块间特征差异问题。

Result: 在图像分类、目标检测和图像分割任务中，MAN++ 的性能与端到端训练相当，同时显著降低了 GPU 内存使用。

Conclusion: MAN++ 提供了一种新颖的监督局部学习方法，显著减少了 GPU 内存使用，同时性能接近端到端训练，为传统训练方法提供了可行的替代方案。

Abstract: Deep learning typically relies on end-to-end backpropagation for training, a
method that inherently suffers from issues such as update locking during
parameter optimization, high GPU memory consumption, and a lack of biological
plausibility. In contrast, supervised local learning seeks to mitigate these
challenges by partitioning the network into multiple local blocks and designing
independent auxiliary networks to update each block separately. However,
because gradients are propagated solely within individual local blocks,
performance degradation occurs, preventing supervised local learning from
supplanting end-to-end backpropagation. To address these limitations and
facilitate inter-block information flow, we propose the Momentum Auxiliary
Network++ (MAN++). MAN++ introduces a dynamic interaction mechanism by
employing the Exponential Moving Average (EMA) of parameters from adjacent
blocks to enhance communication across the network. The auxiliary network,
updated via EMA, effectively bridges the information gap between blocks.
Notably, we observed that directly applying EMA parameters can be suboptimal
due to feature discrepancies between local blocks. To resolve this issue, we
introduce a learnable scaling bias that balances feature differences, thereby
further improving performance. We validate MAN++ through extensive experiments
on tasks that include image classification, object detection, and image
segmentation, utilizing multiple network architectures. The experimental
results demonstrate that MAN++ achieves performance comparable to end-to-end
training while significantly reducing GPU memory usage. Consequently, MAN++
offers a novel perspective for supervised local learning and presents a viable
alternative to conventional training methods.

</details>


### [35] [Beyond Label Semantics: Language-Guided Action Anatomy for Few-shot Action Recognition](https://arxiv.org/abs/2507.16287)
*Zefeng Qian,Xincheng Yao,Yifei Huang,Chongyang Zhang,Jiangyong Ying,Hong Sun*

Main category: cs.CV

TL;DR: LGA框架通过LLM和视觉解剖模块，结合文本和视频特征，显著提升了少样本动作识别的性能。


<details>
  <summary>Details</summary>
Motivation: 少样本动作识别（FSAR）由于训练数据稀缺，需要利用额外模态（如文本）来捕捉动作的细微变化（如姿势、运动动态和对象交互），这些是动作标签无法完全表达的。

Method: LGA框架利用LLM将动作标签分解为原子动作描述（主题、动作、对象），并通过视觉解剖模块分割视频动作，采用细粒度融合策略整合文本和视觉特征，最后通过多模态匹配机制实现鲁棒的少样本分类。

Result: LGA在多个FSAR基准测试中实现了最先进的性能。

Conclusion: LGA框架通过结合大型语言模型（LLM）和视觉解剖模块，显著提升了少样本动作识别的性能，并在多个基准测试中达到了最先进水平。

Abstract: Few-shot action recognition (FSAR) aims to classify human actions in videos
with only a small number of labeled samples per category. The scarcity of
training data has driven recent efforts to incorporate additional modalities,
particularly text. However, the subtle variations in human posture, motion
dynamics, and the object interactions that occur during different phases, are
critical inherent knowledge of actions that cannot be fully exploited by action
labels alone. In this work, we propose Language-Guided Action Anatomy (LGA), a
novel framework that goes beyond label semantics by leveraging Large Language
Models (LLMs) to dissect the essential representational characteristics hidden
beneath action labels. Guided by the prior knowledge encoded in LLM, LGA
effectively captures rich spatiotemporal cues in few-shot scenarios.
Specifically, for text, we prompt an off-the-shelf LLM to anatomize labels into
sequences of atomic action descriptions, focusing on the three core elements of
action (subject, motion, object). For videos, a Visual Anatomy Module segments
actions into atomic video phases to capture the sequential structure of
actions. A fine-grained fusion strategy then integrates textual and visual
features at the atomic level, resulting in more generalizable prototypes.
Finally, we introduce a Multimodal Matching mechanism, comprising both
video-video and video-text matching, to ensure robust few-shot classification.
Experimental results demonstrate that LGA achieves state-of-the-art performance
across multipe FSAR benchmarks.

</details>


### [36] [Dens3R: A Foundation Model for 3D Geometry Prediction](https://arxiv.org/abs/2507.16290)
*Xianze Fang,Jingnan Gao,Zhe Wang,Zhuo Chen,Xingyu Ren,Jiangjing Lyu,Qiaomu Ren,Zhonglei Yang,Xiaokang Yang,Yichao Yan,Chengfei Lyu*

Main category: cs.CV

TL;DR: Dens3R 是一个用于联合几何密集预测的3D基础模型，通过两阶段训练和共享主干设计，实现了多几何量的一致回归，并在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的方法大多局限于从输入图像预测单一几何量，而几何量（如深度、表面法线、点图）本质上是相关的，孤立估计它们往往无法保证一致性，限制了准确性和实际应用。因此，探索一个统一框架来显式建模不同几何属性间的结构耦合以实现联合回归。

Method: Dens3R 采用两阶段训练框架，设计了一个轻量级的共享编码器-解码器主干，并引入了位置插值的旋转位置编码。通过整合图像对匹配特征与内在不变性建模，实现了从单视图到多视图输入的一致几何感知。

Result: Dens3R 能够准确回归多个几何量（如表面法线和深度），并在各种密集3D预测任务中表现出色。

Conclusion: Dens3R 展示了在多种密集3D预测任务中的卓越性能，突显了其在更广泛应用中的潜力。

Abstract: Recent advances in dense 3D reconstruction have led to significant progress,
yet achieving accurate unified geometric prediction remains a major challenge.
Most existing methods are limited to predicting a single geometry quantity from
input images. However, geometric quantities such as depth, surface normals, and
point maps are inherently correlated, and estimating them in isolation often
fails to ensure consistency, thereby limiting both accuracy and practical
applicability. This motivates us to explore a unified framework that explicitly
models the structural coupling among different geometric properties to enable
joint regression. In this paper, we present Dens3R, a 3D foundation model
designed for joint geometric dense prediction and adaptable to a wide range of
downstream tasks. Dens3R adopts a two-stage training framework to progressively
build a pointmap representation that is both generalizable and intrinsically
invariant. Specifically, we design a lightweight shared encoder-decoder
backbone and introduce position-interpolated rotary positional encoding to
maintain expressive power while enhancing robustness to high-resolution inputs.
By integrating image-pair matching features with intrinsic invariance modeling,
Dens3R accurately regresses multiple geometric quantities such as surface
normals and depth, achieving consistent geometry perception from single-view to
multi-view inputs. Additionally, we propose a post-processing pipeline that
supports geometrically consistent multi-view inference. Extensive experiments
demonstrate the superior performance of Dens3R across various dense 3D
prediction tasks and highlight its potential for broader applications.

</details>


### [37] [MotionShot: Adaptive Motion Transfer across Arbitrary Objects for Text-to-Video Generation](https://arxiv.org/abs/2507.16310)
*Yanchen Liu,Yanan Sun,Zhening Xing,Junyao Gao,Kai Chen,Wenjie Pei*

Main category: cs.CV

TL;DR: MotionShot是一个无需训练的框架，通过细粒度解析参考-目标对应关系，实现在外观和结构差异显著的对象间高保真度运动转移。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频方法在参考对象与目标对象之间外观或结构差异较大时，难以实现平滑的运动转移。

Method: MotionShot首先进行语义特征匹配以确保参考和目标对象之间的高级对齐，然后通过参考到目标的形状重定向进一步建立低级别形态对齐，最后通过时间注意力编码运动以实现连贯的运动转移。

Result: 广泛的实验表明，MotionShot能够在对象外观和结构差异显著的情况下，连贯地转移运动。

Conclusion: MotionShot通过细粒度的参考-目标对应解析，实现了高保真度的运动转移，并在外观上保持了连贯性，为现有文本到视频方法在对象外观或结构差异较大时的运动转移挑战提供了有效解决方案。

Abstract: Existing text-to-video methods struggle to transfer motion smoothly from a
reference object to a target object with significant differences in appearance
or structure between them. To address this challenge, we introduce MotionShot,
a training-free framework capable of parsing reference-target correspondences
in a fine-grained manner, thereby achieving high-fidelity motion transfer while
preserving coherence in appearance. To be specific, MotionShot first performs
semantic feature matching to ensure high-level alignments between the reference
and target objects. It then further establishes low-level morphological
alignments through reference-to-target shape retargeting. By encoding motion
with temporal attention, our MotionShot can coherently transfer motion across
objects, even in the presence of significant appearance and structure
disparities, demonstrated by extensive experiments. The project page is
available at: https://motionshot.github.io/.

</details>


### [38] [M-SpecGene: Generalized Foundation Model for RGBT Multispectral Vision](https://arxiv.org/abs/2507.16318)
*Kailai Zhou,Fuqiang Yang,Shixian Wang,Bihan Wen,Chongde Zi,Linsen Chen,Qiu Shen,Xun Cao*

Main category: cs.CV

TL;DR: M-SpecGene 是一个通用的 RGBT 多光谱基础模型，通过自监督学习和 CMSS 渐进掩码策略，解决了人工归纳偏差和数据瓶颈问题，在多个下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的 RGBT 多光谱任务研究通常依赖手动定制的模型，存在人工归纳偏差、模态偏差和数据瓶颈等局限性。为了克服这些限制，研究首次尝试构建一个通用的 RGBT 多光谱基础模型（M-SpecGene），旨在通过自监督学习从大规模广泛数据中学习模态不变的表示。

Method: 研究提出了 Cross-Modality Structural Sparsity (CMSS) 指标来衡量 RGBT 数据中的信息密度，并开发了 GMM-CMSS 渐进掩码策略，实现了灵活、由易到难且以对象为中心的预训练过程。

Result: M-SpecGene 在 11 个数据集上的 4 个 RGBT 下游任务中表现出优秀的泛化能力。

Conclusion: M-SpecGene 作为一个通用的 RGBT 多光谱基础模型，通过自监督学习从大规模数据中提取模态不变表示，成功解决了人工归纳偏差、模态偏差和数据瓶颈等问题，并在多个下游任务中展现了强大的泛化能力。

Abstract: RGB-Thermal (RGBT) multispectral vision is essential for robust perception in
complex environments. Most RGBT tasks follow a case-by-case research paradigm,
relying on manually customized models to learn task-oriented representations.
Nevertheless, this paradigm is inherently constrained by artificial inductive
bias, modality bias, and data bottleneck. To address these limitations, we make
the initial attempt to build a Generalized RGBT MultiSpectral foundation model
(M-SpecGene), which aims to learn modality-invariant representations from
large-scale broad data in a self-supervised manner. M-SpecGene provides new
insights into multispectral fusion and integrates prior case-by-case studies
into a unified paradigm. Considering the unique characteristic of information
imbalance in RGBT data, we introduce the Cross-Modality Structural Sparsity
(CMSS) metric to quantify the information density across two modalities. Then
we develop the GMM-CMSS progressive masking strategy to facilitate a flexible,
easy-to-hard, and object-centric pre-training process. Comprehensive
experiments validate M-SpecGene's generalizability across eleven datasets for
four RGBT downstream tasks. The code will be available at
https://github.com/CalayZhou/M-SpecGene.

</details>


### [39] [Scene Text Detection and Recognition "in light of" Challenging Environmental Conditions using Aria Glasses Egocentric Vision Cameras](https://arxiv.org/abs/2507.16330)
*Joseph De Mathia,Carlos Francisco Moreno-García*

Main category: cs.CV

TL;DR: 本文通过Meta的Project Aria智能眼镜研究了环境变量对STDR算法性能的影响，发现分辨率和距离是关键因素，图像放大显著降低错误率，眼动追踪可优化效率，为自适应AR系统奠定基础。


<details>
  <summary>Details</summary>
Motivation: 随着可穿戴技术的普及，STDR在自我中心视角下的应用变得尤为重要。本文旨在探讨环境变量如何影响STDR算法的性能，并为自适应、用户感知的AR系统提供理论基础。

Method: 本文利用Meta的Project Aria智能眼镜收集数据，构建了一个自定义数据集，并在受控条件下评估了两种OCR管道：EAST与CRNN结合，以及EAST与PyTesseract结合。通过分析环境变量（光照、距离、分辨率）对STDR算法性能的影响，并测试了图像放大作为预处理技术的效果。

Result: 研究发现分辨率和距离对STDR算法的识别准确性有显著影响，而光照的作用较难预测。图像放大作为预处理技术，将字符错误率从0.65降至0.48。此外，整合眼动追踪可以优化处理效率。

Conclusion: 本文通过Meta的Project Aria智能眼镜研究了环境变量（如光照、距离和分辨率）对STDR算法性能的影响，并提出了一种新颖的自定义数据集。研究发现分辨率和距离对识别准确性有显著影响，而光照的作用较难预测。此外，图像放大作为关键预处理技术显著降低了字符错误率。本文还展示了通过整合眼动追踪优化处理效率的潜力，为自适应、用户感知的AR系统奠定了基础。

Abstract: In an era where wearable technology is reshaping applications, Scene Text
Detection and Recognition (STDR) becomes a straightforward choice through the
lens of egocentric vision. Leveraging Meta's Project Aria smart glasses, this
paper investigates how environmental variables, such as lighting, distance, and
resolution, affect the performance of state-of-the-art STDR algorithms in
real-world scenarios. We introduce a novel, custom-built dataset captured under
controlled conditions and evaluate two OCR pipelines: EAST with CRNN, and EAST
with PyTesseract. Our findings reveal that resolution and distance
significantly influence recognition accuracy, while lighting plays a less
predictable role. Notably, image upscaling emerged as a key pre-processing
technique, reducing Character Error Rate (CER) from 0.65 to 0.48. We further
demonstrate the potential of integrating eye-gaze tracking to optimise
processing efficiency by focusing on user attention zones. This work not only
benchmarks STDR performance under realistic conditions but also lays the
groundwork for adaptive, user-aware AR systems. Our contributions aim to
inspire future research in robust, context-sensitive text recognition for
assistive and research-oriented applications, such as asset inspection and
nutrition analysis. The code is available at
https://github.com/josepDe/Project_Aria_STR.

</details>


### [40] [One Polyp Identifies All: One-Shot Polyp Segmentation with SAM via Cascaded Priors and Iterative Prompt Evolution](https://arxiv.org/abs/2507.16337)
*Xinyu Mao,Xiaohan Xing,Fei Meng,Jianbang Liu,Fan Bai,Qiang Nie,Max Meng*

Main category: cs.CV

TL;DR: OP-SAM利用SAM模型自动生成提示，通过CPG、SPF和EPE技术提升息肉分割效果，减少标注依赖，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统全监督方法在息肉分割中面临形态多变性和领域偏移问题，且依赖大规模标注。SAM模型虽具强泛化能力，但其提示依赖特性限制了医疗应用的自动化。

Method: OP-SAM基于SAM模型，引入CPG进行语义标签转移，SPF适应息肉尺寸变化并过滤噪声，以及EPE实现迭代提示优化。

Result: 在Kvasir数据集上，OP-SAM的IoU达到76.93%，超越现有最佳方法11.44%。

Conclusion: OP-SAM框架通过自动化提示生成和迭代优化，显著提升了息肉分割的准确性和泛化能力，无需额外标注负担，且在多个数据集上表现优异。

Abstract: Polyp segmentation is vital for early colorectal cancer detection, yet
traditional fully supervised methods struggle with morphological variability
and domain shifts, requiring frequent retraining. Additionally, reliance on
large-scale annotations is a major bottleneck due to the time-consuming and
error-prone nature of polyp boundary labeling. Recently, vision foundation
models like Segment Anything Model (SAM) have demonstrated strong
generalizability and fine-grained boundary detection with sparse prompts,
effectively addressing key polyp segmentation challenges. However, SAM's
prompt-dependent nature limits automation in medical applications, since
manually inputting prompts for each image is labor-intensive and
time-consuming. We propose OP-SAM, a One-shot Polyp segmentation framework
based on SAM that automatically generates prompts from a single annotated
image, ensuring accurate and generalizable segmentation without additional
annotation burdens. Our method introduces Correlation-based Prior Generation
(CPG) for semantic label transfer and Scale-cascaded Prior Fusion (SPF) to
adapt to polyp size variations as well as filter out noisy transfers. Instead
of dumping all prompts at once, we devise Euclidean Prompt Evolution (EPE) for
iterative prompt refinement, progressively enhancing segmentation quality.
Extensive evaluations across five datasets validate OP-SAM's effectiveness.
Notably, on Kvasir, it achieves 76.93% IoU, surpassing the state-of-the-art by
11.44%.

</details>


### [41] [Navigating Large-Pose Challenge for High-Fidelity Face Reenactment with Video Diffusion Model](https://arxiv.org/abs/2507.16341)
*Mingtao Guo,Guanyu Xing,Yanci Zhang,Yanli Liu*

Main category: cs.CV

TL;DR: FRVD是一种新的人脸重现视频扩散模型，通过运动提取器和WFM模块，在极端姿态变化下实现高保真效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于隐式或显式关键点的方法在极端姿态变化下表现不佳，存在变形伪影或粗粒度面部标志限制的问题。

Method: FRVD框架首先使用运动提取器从源图像和驱动图像中提取隐式面部关键点，通过变形模块进行运动对齐。为解决变形带来的退化问题，引入了Warping Feature Mapper（WFM），将变形后的源图像映射到预训练的I2V模型的运动感知潜在空间中。

Result: FRVD在极端姿态变化下的挑战性场景中，实现了优于现有方法的姿态准确性、身份保持和视觉质量。

Conclusion: FRVD模型通过结合运动提取器和Warping Feature Mapper，显著提升了极端姿态变化下的人脸重现效果，在姿态准确性、身份保持和视觉质量上优于现有方法。

Abstract: Face reenactment aims to generate realistic talking head videos by
transferring motion from a driving video to a static source image while
preserving the source identity. Although existing methods based on either
implicit or explicit keypoints have shown promise, they struggle with large
pose variations due to warping artifacts or the limitations of coarse facial
landmarks. In this paper, we present the Face Reenactment Video Diffusion model
(FRVD), a novel framework for high-fidelity face reenactment under large pose
changes. Our method first employs a motion extractor to extract implicit facial
keypoints from the source and driving images to represent fine-grained motion
and to perform motion alignment through a warping module. To address the
degradation introduced by warping, we introduce a Warping Feature Mapper (WFM)
that maps the warped source image into the motion-aware latent space of a
pretrained image-to-video (I2V) model. This latent space encodes rich priors of
facial dynamics learned from large-scale video data, enabling effective warping
correction and enhancing temporal coherence. Extensive experiments show that
FRVD achieves superior performance over existing methods in terms of pose
accuracy, identity preservation, and visual quality, especially in challenging
scenarios with extreme pose variations.

</details>


### [42] [Mamba-OTR: a Mamba-based Solution for Online Take and Release Detection from Untrimmed Egocentric Video](https://arxiv.org/abs/2507.16342)
*Alessandro Sebastiano Catinello,Giovanni Maria Farinella,Antonino Furnari*

Main category: cs.CV

TL;DR: Mamba-OTR是一种高效的自中心视频物体拿取和释放检测模型，通过Mamba架构和焦点损失优化，在准确性和效率上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决未修剪的自中心视频中物体拿取和释放（OTR）的在线检测问题，面临标签不平衡、时间稀疏的正标注和计算效率等挑战。

Method: 基于Mamba架构，利用时间递归进行推理，训练时采用短视频片段，并结合焦点损失和新颖的正则化方案以解决标签不平衡问题。

Result: 在EPIC-KITCHENS-100上的实验显示，Mamba-OTR在滑动窗口和流模式下分别达到45.48和43.35的mp-mAP，显著优于传统Transformer和Mamba方法。

Conclusion: Mamba-OTR提供了OTR任务的强基线，并在准确性和效率上均优于传统方法，特别是在处理长视频或高帧率序列时表现突出。

Abstract: This work tackles the problem of Online detection of Take and Release (OTR)
of an object in untrimmed egocentric videos. This task is challenging due to
severe label imbalance, with temporally sparse positive annotations, and the
need for precise temporal predictions. Furthermore, methods need to be
computationally efficient in order to be deployed in real-world online
settings. To address these challenges, we propose Mamba-OTR, a model based on
the Mamba architecture. Mamba-OTR is designed to exploit temporal recurrence
during inference while being trained on short video clips. To address label
imbalance, our training pipeline incorporates the focal loss and a novel
regularization scheme that aligns model predictions with the evaluation metric.
Extensive experiments on EPIC-KITCHENS-100, the comparisons with
transformer-based approach, and the evaluation of different training and test
schemes demonstrate the superiority of Mamba-OTR in both accuracy and
efficiency. These finding are particularly evident when evaluating full-length
videos or high frame-rate sequences, even when trained on short video snippets
for computational convenience. The proposed Mamba-OTR achieves a noteworthy
mp-mAP of 45.48 when operating in a sliding-window fashion, and 43.35 in
streaming mode, versus the 20.32 of a vanilla transformer and 25.16 of a
vanilla Mamba, thus providing a strong baseline for OTR. We will publicly
release the source code of Mamba-OTR to support future research.

</details>


### [43] [LPTR-AFLNet: Lightweight Integrated Chinese License Plate Rectification and Recognition Network](https://arxiv.org/abs/2507.16362)
*Guangzhu Xu,Pengcheng Zuo,Zhi Ke,Bangjun Lei*

Main category: cs.CV

TL;DR: LPTR-AFLNet 是一种轻量级、端到端的车牌校正与识别网络，结合透视校正模块和优化识别网络，在复杂环境中表现优异，运行高效。


<details>
  <summary>Details</summary>
Motivation: 中文车牌识别（CLPR）在无约束和复杂环境中面临诸多挑战，特别是由于各种拍摄角度引起的透视畸变以及单线和双线车牌的校正问题。考虑到边缘设备的有限计算资源，开发一种低复杂度、端到端的集成网络以实现实时和高效部署至关重要。

Method: 提出了一种轻量级、统一的网络 LPTR-AFLNet，结合了透视变换校正模块（PTR）和优化的车牌识别网络 AFLNet。网络利用识别输出作为弱监督信号，有效指导校正过程，确保准确的透视畸变校正。为了提高识别准确率，对 LPRNet 进行了多项改进，包括改进的注意力模块以减少相似字符的混淆，以及使用 Focal Loss 解决训练中的类别不平衡问题。

Result: 实验结果表明，LPTR-AFLNet 在纠正透视畸变和识别双行车牌图像方面表现优异，并在各种挑战性场景中保持高识别准确率。在低中端 GPU 平台上，该方法运行时间少于 10 毫秒。

Conclusion: LPTR-AFLNet 在纠正透视畸变和识别双行车牌图像方面表现出色，并在各种挑战性场景中保持高识别准确率。此外，在低中端 GPU 平台上，该方法运行时间少于 10 毫秒，证明了其实用性和广泛适用性。

Abstract: Chinese License Plate Recognition (CLPR) faces numerous challenges in
unconstrained and complex environments, particularly due to perspective
distortions caused by various shooting angles and the correction of single-line
and double-line license plates. Considering the limited computational resources
of edge devices, developing a low-complexity, end-to-end integrated network for
both correction and recognition is essential for achieving real-time and
efficient deployment. In this work, we propose a lightweight, unified network
named LPTR-AFLNet for correcting and recognizing Chinese license plates, which
combines a perspective transformation correction module (PTR) with an optimized
license plate recognition network, AFLNet. The network leverages the
recognition output as a weak supervisory signal to effectively guide the
correction process, ensuring accurate perspective distortion correction. To
enhance recognition accuracy, we introduce several improvements to LPRNet,
including an improved attention module to reduce confusion among similar
characters and the use of Focal Loss to address class imbalance during
training. Experimental results demonstrate the exceptional performance of
LPTR-AFLNet in rectifying perspective distortion and recognizing double-line
license plate images, maintaining high recognition accuracy across various
challenging scenarios. Moreover, on lower-mid-range GPUs platform, the method
runs in less than 10 milliseconds, indicating its practical efficiency and
broad applicability.

</details>


### [44] [STAR: A Benchmark for Astronomical Star Fields Super-Resolution](https://arxiv.org/abs/2507.16385)
*Kuo-Cheng Wu,Guohang Zhuang,Jinyang Huang,Xiang Zhang,Wanli Ouyang,Yan Lu*

Main category: cs.CV

TL;DR: STAR是一个大规模天文SR数据集，结合了FISR模型，显著提升了超分辨率性能，特别适用于天体物理学应用。


<details>
  <summary>Details</summary>
Motivation: 现有天文SR数据集存在流量不一致、对象裁剪设置和数据集多样性不足等问题，限制了ASR的发展。

Method: 提出了STAR数据集，包含54,738对流量一致的星场图像对，并通过流量保持数据生成流程生成低分辨率对应物。此外，设计了Flux Error（FE）评估指标，并提出了Flux-Invariant Super Resolution（FISR）模型。

Result: FISR模型在流量一致性指标上优于现有方法24.84%，证明了其在天体物理学中的优势。

Conclusion: STAR数据集和FISR模型显著提升了天文超分辨率（ASR）的性能，通过提供大规模、物理一致的数据集和新的评估指标，推动了ASR在物理学中的应用。

Abstract: Super-resolution (SR) advances astronomical imaging by enabling
cost-effective high-resolution capture, crucial for detecting faraway celestial
objects and precise structural analysis. However, existing datasets for
astronomical SR (ASR) exhibit three critical limitations: flux inconsistency,
object-crop setting, and insufficient data diversity, significantly impeding
ASR development. We propose STAR, a large-scale astronomical SR dataset
containing 54,738 flux-consistent star field image pairs covering wide
celestial regions. These pairs combine Hubble Space Telescope high-resolution
observations with physically faithful low-resolution counterparts generated
through a flux-preserving data generation pipeline, enabling systematic
development of field-level ASR models. To further empower the ASR community,
STAR provides a novel Flux Error (FE) to evaluate SR models in physical view.
Leveraging this benchmark, we propose a Flux-Invariant Super Resolution (FISR)
model that could accurately infer the flux-consistent high-resolution images
from input photometry, suppressing several SR state-of-the-art methods by
24.84% on a novel designed flux consistency metric, showing the priority of our
method for astrophysics. Extensive experiments demonstrate the effectiveness of
our proposed method and the value of our dataset. Code and models are available
at https://github.com/GuoCheng12/STAR.

</details>


### [45] [From Flat to Round: Redefining Brain Decoding with Surface-Based fMRI and Cortex Structure](https://arxiv.org/abs/2507.16389)
*Sijin Yu,Zijiao Chen,Wenxuan Wu,Shengxian Chen,Zhongliang Liu,Jingxin Nie,Xiaofen Xing,Xiangmin Xu,Xin Zhang*

Main category: cs.CV

TL;DR: 该论文通过建模fMRI信号的球形空间关系、整合sMRI数据及正样本混合策略，显著提升了视觉刺激重建的准确性和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法常忽略大脑结构与功能的关键关系，导致空间信息扁平化并忽视个体解剖变异。本研究旨在解决这些问题，提升重建精度和生物解释性。

Method: 1. 提出了一种新颖的球面标记器，将fMRI信号建模为皮层表面的空间相干2D球形数据；2. 整合了结构MRI（sMRI）数据，实现个体解剖变异的个性化编码；3. 采用正样本混合策略，高效利用与同一视觉刺激相关的多个fMRI扫描。

Result: 实验表明，该方法在重建性能上优于现有技术（SOTA），验证了其生物信息学方法的有效性和解释性。

Conclusion: 该论文提出了一种结合脑结构和功能关系的新方法，显著提高了从fMRI数据重建视觉刺激的准确性和解释性，并在实验中展示了优于现有方法的性能。

Abstract: Reconstructing visual stimuli from human brain activity (e.g., fMRI) bridges
neuroscience and computer vision by decoding neural representations. However,
existing methods often overlook critical brain structure-function
relationships, flattening spatial information and neglecting individual
anatomical variations. To address these issues, we propose (1) a novel sphere
tokenizer that explicitly models fMRI signals as spatially coherent 2D
spherical data on the cortical surface; (2) integration of structural MRI
(sMRI) data, enabling personalized encoding of individual anatomical
variations; and (3) a positive-sample mixup strategy for efficiently leveraging
multiple fMRI scans associated with the same visual stimulus. Collectively,
these innovations enhance reconstruction accuracy, biological interpretability,
and generalizability across individuals. Experiments demonstrate superior
reconstruction performance compared to SOTA methods, highlighting the
effectiveness and interpretability of our biologically informed approach.

</details>


### [46] [Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?](https://arxiv.org/abs/2507.16393)
*Lazaro Janier Gonzalez-Sole,Juan E. Tapia,Christoph Busch*

Main category: cs.CV

TL;DR: 本文提出了一种基于基础模型的零样本PAD方法，解决了现有方法对大量数据和未知攻击泛化能力不足的问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管人脸识别系统在过去十年取得了显著进展，但它们容易受到攻击演示（AP）的影响。现有的PAD方法需要大量数据且对未知攻击缺乏泛化能力。

Method: 本文首先评估了基础模型在已知和挑战性实验场景中的有效性和泛化能力，随后提出了一个简单但有效的零样本PAD框架。

Result: 实验结果表明，基础模型在困难场景中表现优异，其性能超越了现有最先进的方法，特别是在SiW-Mv2数据库上的留一协议测试中。

Conclusion: 基础模型在零样本PAD任务中表现出色，能够在不依赖大量训练数据的情况下实现高性能，并在面对未知攻击时展现出较强的泛化能力。

Abstract: Although face recognition systems have undergone an impressive evolution in
the last decade, these technologies are vulnerable to attack presentations
(AP). These attacks are mostly easy to create and, by executing them against
the system's capture device, the malicious actor can impersonate an authorised
subject and thus gain access to the latter's information (e.g., financial
transactions). To protect facial recognition schemes against presentation
attacks, state-of-the-art deep learning presentation attack detection (PAD)
approaches require a large amount of data to produce reliable detection
performances and even then, they decrease their performance for unknown
presentation attack instruments (PAI) or database (information not seen during
training), i.e. they lack generalisability. To mitigate the above problems,
this paper focuses on zero-shot PAD. To do so, we first assess the
effectiveness and generalisability of foundation models in established and
challenging experimental scenarios and then propose a simple but effective
framework for zero-shot PAD. Experimental results show that these models are
able to achieve performance in difficult scenarios with minimal effort of the
more advanced PAD mechanisms, whose weights were optimised mainly with training
sets that included APs and bona fide presentations. The top-performing
foundation model outperforms by a margin the best from the state of the art
observed with the leaving-one-out protocol on the SiW-Mv2 database, which
contains challenging unknown 2D and 3D attacks

</details>


### [47] [ADCD-Net: Robust Document Image Forgery Localization via Adaptive DCT Feature and Hierarchical Content Disentanglement](https://arxiv.org/abs/2507.16397)
*Kahim Wong,Jicheng Zhou,Haiwei Wu,Yain-Whar Si,Jiantao Zhou*

Main category: cs.CV

TL;DR: ADCD-Net 是一种鲁棒的文档伪造定位模型，通过自适应利用 RGB/DCT 痕迹和分层内容解耦，显著提升了定位准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自然图像伪造检测器在文档图像上效果不佳，而现有的文档专用方法对多种退化缺乏足够的鲁棒性，限制了实际应用。

Method: ADCD-Net 采用自适应调制 DCT 特征贡献的方法解决块不对齐问题，并提出分层内容解耦方法以减少文本与背景差异，同时构建原始原型捕捉未篡改区域的痕迹。

Result: ADCD-Net 在五种失真类型下平均优于现有方法 20.79%，表现出卓越的伪造定位性能。

Conclusion: ADCD-Net 通过自适应利用 RGB/DCT 取证痕迹并整合文档图像的关键特征，显著提升了伪造定位的准确性和鲁棒性，在多种失真情况下平均优于现有方法 20.79%。

Abstract: The advancement of image editing tools has enabled malicious manipulation of
sensitive document images, underscoring the need for robust document image
forgery detection.Though forgery detectors for natural images have been
extensively studied, they struggle with document images, as the tampered
regions can be seamlessly blended into the uniform document background (BG) and
structured text. On the other hand, existing document-specific methods lack
sufficient robustness against various degradations, which limits their
practical deployment. This paper presents ADCD-Net, a robust document forgery
localization model that adaptively leverages the RGB/DCT forensic traces and
integrates key characteristics of document images. Specifically, to address the
DCT traces' sensitivity to block misalignment, we adaptively modulate the DCT
feature contribution based on a predicted alignment score, resulting in much
improved resilience to various distortions, including resizing and cropping.
Also, a hierarchical content disentanglement approach is proposed to boost the
localization performance via mitigating the text-BG disparities. Furthermore,
noticing the predominantly pristine nature of BG regions, we construct a
pristine prototype capturing traces of untampered regions, and eventually
enhance both the localization accuracy and robustness. Our proposed ADCD-Net
demonstrates superior forgery localization performance, consistently
outperforming state-of-the-art methods by 20.79\% averaged over 5 types of
distortions. The code is available at https://github.com/KAHIMWONG/ACDC-Net.

</details>


### [48] [ReasonVQA: A Multi-hop Reasoning Benchmark with Structural Knowledge for Visual Question Answering](https://arxiv.org/abs/2507.16403)
*Thuy-Duong Tran,Trung-Kien Tran,Manfred Hauswirth,Danh Le Phuoc*

Main category: cs.CV

TL;DR: ReasonVQA是一个新的大型VQA数据集，整合了结构化知识，能生成复杂问题，对现有模型构成挑战，且易于扩展。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有VQA数据集在复杂推理和外部知识整合方面的不足，提出了ReasonVQA数据集。

Method: 通过自动整合结构化百科全书知识，并使用低成本框架构建复杂、多跳问题的方法来创建ReasonVQA数据集。

Result: 评估显示，现有最先进的VQA模型在ReasonVQA上表现不佳，表明该数据集具有挑战性。此外，数据集规模远超现有需要外部知识的最大数据集。

Conclusion: ReasonVQA数据集为视觉问答（VQA）任务提供了新的基准，展示了其在该领域推动技术进步和模型评估的潜力。

Abstract: In this paper, we propose a new dataset, ReasonVQA, for the Visual Question
Answering (VQA) task. Our dataset is automatically integrated with structured
encyclopedic knowledge and constructed using a low-cost framework, which is
capable of generating complex, multi-hop questions. We evaluated
state-of-the-art VQA models on ReasonVQA, and the empirical results demonstrate
that ReasonVQA poses significant challenges to these models, highlighting its
potential for benchmarking and advancing the field of VQA. Additionally, our
dataset can be easily scaled with respect to input images; the current version
surpasses the largest existing datasets requiring external knowledge by more
than an order of magnitude.

</details>


### [49] [Sparse-View 3D Reconstruction: Recent Advances and Open Challenges](https://arxiv.org/abs/2507.16406)
*Tanveer Younis,Zhanglin Cheng*

Main category: cs.CV

TL;DR: 该综述探讨了稀疏视角3D重建的最新进展，分析了神经隐式、显式和混合方法的优缺点，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 稀疏视角3D重建在机器人、增强/虚拟现实（AR/VR）和自主系统等密集图像采集不切实际的应用中至关重要，传统方法（如SfM和MVS）因图像重叠不足而失效。

Method: 综述分析了神经隐式模型（如NeRF及其正则化版本）、显式点云方法（如3D高斯泼溅）以及结合扩散和视觉基础模型（VFMs）先验的混合框架。

Result: 在标准基准上的比较结果揭示了重建精度、效率和泛化能力之间的关键权衡。

Conclusion: 该综述提供了对几何基础、神经隐式和生成式（基于扩散的）方法的统一视角，并指出了领域泛化和无姿态重建中的持续挑战，为开发3D原生生成先验和实现实时、不受限制的稀疏视角重建指明了未来方向。

Abstract: Sparse-view 3D reconstruction is essential for applications in which dense
image acquisition is impractical, such as robotics, augmented/virtual reality
(AR/VR), and autonomous systems. In these settings, minimal image overlap
prevents reliable correspondence matching, causing traditional methods, such as
structure-from-motion (SfM) and multiview stereo (MVS), to fail. This survey
reviews the latest advances in neural implicit models (e.g., NeRF and its
regularized versions), explicit point-cloud-based approaches (e.g., 3D Gaussian
Splatting), and hybrid frameworks that leverage priors from diffusion and
vision foundation models (VFMs).We analyze how geometric regularization,
explicit shape modeling, and generative inference are used to mitigate
artifacts such as floaters and pose ambiguities in sparse-view settings.
Comparative results on standard benchmarks reveal key trade-offs between the
reconstruction accuracy, efficiency, and generalization. Unlike previous
reviews, our survey provides a unified perspective on geometry-based, neural
implicit, and generative (diffusion-based) methods. We highlight the persistent
challenges in domain generalization and pose-free reconstruction and outline
future directions for developing 3D-native generative priors and achieving
real-time, unconstrained sparse-view reconstruction.

</details>


### [50] [Towards Railway Domain Adaptation for LiDAR-based 3D Detection: Road-to-Rail and Sim-to-Real via SynDRA-BBox](https://arxiv.org/abs/2507.16413)
*Xavier Diaz,Gianluca D'Amico,Raul Dominguez-Sanchez,Federico Nesti,Max Ronecker,Giorgio Buttazzo*

Main category: cs.CV

TL;DR: SynDRA-BBox是首个专为铁路领域设计的合成数据集，结合领域适应技术，有效提升了铁路环境下的物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 铁路领域缺乏公开的真实标注数据集，阻碍了新感知方案的测试和验证，因此需要合成数据集来填补这一空白。

Method: 提出了SynDRA-BBox合成数据集，并采用半监督领域适应方法，将汽车感知领域的先进技术适配到铁路场景中。

Result: 实验结果表明，合成数据集和领域适应技术在铁路环境中的3D物体检测任务上表现良好。

Conclusion: 合成数据集SynDRA-BBox和领域适应技术在提升铁路环境感知能力方面表现出色，为铁路领域的视觉任务提供了有效的解决方案。

Abstract: In recent years, interest in automatic train operations has significantly
increased. To enable advanced functionalities, robust vision-based algorithms
are essential for perceiving and understanding the surrounding environment.
However, the railway sector suffers from a lack of publicly available
real-world annotated datasets, making it challenging to test and validate new
perception solutions in this domain. To address this gap, we introduce
SynDRA-BBox, a synthetic dataset designed to support object detection and other
vision-based tasks in realistic railway scenarios. To the best of our
knowledge, is the first synthetic dataset specifically tailored for 2D and 3D
object detection in the railway domain, the dataset is publicly available at
https://syndra.retis.santannapisa.it. In the presented evaluation, a
state-of-the-art semi-supervised domain adaptation method, originally developed
for automotive perception, is adapted to the railway context, enabling the
transferability of synthetic data to 3D object detection. Experimental results
demonstrate promising performance, highlighting the effectiveness of synthetic
datasets and domain adaptation techniques in advancing perception capabilities
for railway environments.

</details>


### [51] [Combined Image Data Augmentations diminish the benefits of Adaptive Label Smoothing](https://arxiv.org/abs/2507.16427)
*Georg Siedel,Ekagra Gupta,Weijia Shao,Silvia Vock,Andrey Morozov*

Main category: cs.CV

TL;DR: 本文扩展自适应标签平滑至随机擦除和噪声注入增强，发现其在单一增强类型中有效，但在多样化变换中无效，且过度平滑损害鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨如何通过自适应标签平滑增强图像分类器的监督学习过程，尤其是在使用其他类型激进增强时。

Method: 本文扩展了自适应标签平滑框架，将其应用于随机擦除和噪声注入等激进增强方法，并通过实验验证其效果。

Result: 实验表明，自适应标签平滑在随机擦除增强中效果显著，但在TrivialAugment等多样化变换方法中效果消失，且过度平滑会降低鲁棒性。

Conclusion: 自适应标签平滑在训练数据分布由有限且同质的图像变换类型主导时最为有效，但过度使用会损害对常见损坏的鲁棒性。

Abstract: Soft augmentation regularizes the supervised learning process of image
classifiers by reducing label confidence of a training sample based on the
magnitude of random-crop augmentation applied to it. This paper extends this
adaptive label smoothing framework to other types of aggressive augmentations
beyond random-crop. Specifically, we demonstrate the effectiveness of the
method for random erasing and noise injection data augmentation. Adaptive label
smoothing permits stronger regularization via higher-intensity Random Erasing.
However, its benefits vanish when applied with a diverse range of image
transformations as in the state-of-the-art TrivialAugment method, and excessive
label smoothing harms robustness to common corruptions. Our findings suggest
that adaptive label smoothing should only be applied when the training data
distribution is dominated by a limited, homogeneous set of image transformation
types.

</details>


### [52] [Robust Noisy Pseudo-label Learning for Semi-supervised Medical Image Segmentation Using Diffusion Model](https://arxiv.org/abs/2507.16429)
*Lin Xi,Yingliang Ma,Cheng Wang,Sandra Howell,Aldo Rinaldi,Kawal S. Rhode*

Main category: cs.CV

TL;DR: 提出扩散框架优化半监督医学图像分割，通过原型对比一致性增强潜在空间语义结构，在噪声伪标签下表现优异，实验验证其超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像像素级标注成本高且耗时，现有半监督方法因伪标签噪声导致潜在空间语义分布结构不佳。本文旨在通过扩散模型改进半监督医学图像分割的准确性和鲁棒性。

Method: 提出了一种新颖的扩散框架，通过在去噪扩散过程中引入原型对比一致性约束，优化潜在空间中的语义标签结构。模型利用类原型作为锚点集中表示语义，而非显式划分语义边界，从而增强密集预测的鲁棒性。

Result: 在EndoScapes2023和MOSXAV数据集上的实验表明，该方法在半监督学习设置下优于现有最先进方法，验证了其有效性和鲁棒性。

Conclusion: 本文提出了一种基于扩散的半监督医学图像分割框架，通过原型对比一致性增强潜在空间中的语义分布结构，显著提升了分割性能，尤其在存在噪声伪标签的情况下表现优异。该方法在EndoScapes2023和MOSXAV数据集上超越了现有先进技术，展示了其在临床应用中的广泛潜力。

Abstract: Obtaining pixel-level annotations in the medical domain is both expensive and
time-consuming, often requiring close collaboration between clinical experts
and developers. Semi-supervised medical image segmentation aims to leverage
limited annotated data alongside abundant unlabeled data to achieve accurate
segmentation. However, existing semi-supervised methods often struggle to
structure semantic distributions in the latent space due to noise introduced by
pseudo-labels. In this paper, we propose a novel diffusion-based framework for
semi-supervised medical image segmentation. Our method introduces a constraint
into the latent structure of semantic labels during the denoising diffusion
process by enforcing prototype-based contrastive consistency. Rather than
explicitly delineating semantic boundaries, the model leverages class
prototypes centralized semantic representations in the latent space as anchors.
This strategy improves the robustness of dense predictions, particularly in the
presence of noisy pseudo-labels. We also introduce a new publicly available
benchmark: Multi-Object Segmentation in X-ray Angiography Videos (MOSXAV),
which provides detailed, manually annotated segmentation ground truth for
multiple anatomical structures in X-ray angiography videos. Extensive
experiments on the EndoScapes2023 and MOSXAV datasets demonstrate that our
method outperforms state-of-the-art medical image segmentation approaches under
the semi-supervised learning setting. This work presents a robust and
data-efficient diffusion model that offers enhanced flexibility and strong
potential for a wide range of clinical applications.

</details>


### [53] [VGGT-Long: Chunk it, Loop it, Align it -- Pushing VGGT's Limits on Kilometer-scale Long RGB Sequences](https://arxiv.org/abs/2507.16443)
*Kai Deng,Zexin Ti,Jiawei Xu,Jian Yang,Jin Xie*

Main category: cs.CV

TL;DR: VGGT-Long提出了一种简单有效的系统，通过分块处理策略和轻量级闭环优化，实现了千米级无边界室外环境的单目3D重建，无需相机校准或深度监督。


<details>
  <summary>Details</summary>
Motivation: 扩展3D视觉基础模型至大规模RGB流3D重建存在内存限制的挑战。

Method: 采用分块处理策略结合重叠对齐和轻量级闭环优化，解决现有模型的可扩展性瓶颈。

Result: 在KITTI、Waymo和Virtual KITTI数据集上，VGGT-Long表现与传统方法相当，且能在长RGB序列中稳定运行。

Conclusion: VGGT-Long展示了基础模型在现实场景（如自动驾驶）中实现可扩展单目3D重建的潜力。

Abstract: Foundation models for 3D vision have recently demonstrated remarkable
capabilities in 3D perception. However, extending these models to large-scale
RGB stream 3D reconstruction remains challenging due to memory limitations. In
this work, we propose VGGT-Long, a simple yet effective system that pushes the
limits of monocular 3D reconstruction to kilometer-scale, unbounded outdoor
environments. Our approach addresses the scalability bottlenecks of existing
models through a chunk-based processing strategy combined with overlapping
alignment and lightweight loop closure optimization. Without requiring camera
calibration, depth supervision or model retraining, VGGT-Long achieves
trajectory and reconstruction performance comparable to traditional methods. We
evaluate our method on KITTI, Waymo, and Virtual KITTI datasets. VGGT-Long not
only runs successfully on long RGB sequences where foundation models typically
fail, but also produces accurate and consistent geometry across various
conditions. Our results highlight the potential of leveraging foundation models
for scalable monocular 3D scene in real-world settings, especially for
autonomous driving scenarios. Code is available at
https://github.com/DengKaiCQ/VGGT-Long.

</details>


### [54] [DenseSR: Image Shadow Removal as Dense Prediction](https://arxiv.org/abs/2507.16472)
*Yu-Fan Lin,Chia-Ming Lee,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: DenseSR结合几何语义先验和新型DFB模块，有效解决单图像阴影去除中的不一致恢复和模糊问题，提升恢复质量。


<details>
  <summary>Details</summary>
Motivation: 传统方法在单图像阴影去除中难以同时恢复阴影内细节和保持边界锐度，导致不一致恢复和模糊问题，影响下游应用和视觉体验。

Method: DenseSR框架采用密集预测视角，结合深度场景理解（几何语义先验）和DFB模块（包括ACSM和TBRM），实现高保真恢复。

Result: 实验结果表明，DenseSR在恢复质量和边界清晰度上优于现有方法。

Conclusion: DenseSR通过结合几何语义先验和新型Dense Fusion Block（DFB），有效解决了单图像阴影去除中的不一致恢复和模糊问题，显著提升了恢复质量和边界清晰度。

Abstract: Shadows are a common factor degrading image quality. Single-image shadow
removal (SR), particularly under challenging indirect illumination, is hampered
by non-uniform content degradation and inherent ambiguity. Consequently,
traditional methods often fail to simultaneously recover intra-shadow details
and maintain sharp boundaries, resulting in inconsistent restoration and
blurring that negatively affect both downstream applications and the overall
viewing experience. To overcome these limitations, we propose the DenseSR,
approaching the problem from a dense prediction perspective to emphasize
restoration quality. This framework uniquely synergizes two key strategies: (1)
deep scene understanding guided by geometric-semantic priors to resolve
ambiguity and implicitly localize shadows, and (2) high-fidelity restoration
via a novel Dense Fusion Block (DFB) in the decoder. The DFB employs adaptive
component processing-using an Adaptive Content Smoothing Module (ACSM) for
consistent appearance and a Texture-Boundary Recuperation Module (TBRM) for
fine textures and sharp boundaries-thereby directly tackling the inconsistent
restoration and blurring issues. These purposefully processed components are
effectively fused, yielding an optimized feature representation preserving both
consistency and fidelity. Extensive experimental results demonstrate the merits
of our approach over existing methods. Our code can be available on
https://github$.$com/VanLinLin/DenseSR

</details>


### [55] [Survival Modeling from Whole Slide Images via Patch-Level Graph Clustering and Mixture Density Experts](https://arxiv.org/abs/2507.16476)
*Ardhendu Sekhar,Vasu Soni,Keshav Aske,Garima Jain,Pranav Jeevan,Amit Sethi*

Main category: cs.CV

TL;DR: 提出了一种模块化框架，通过动态补丁选择、聚类、注意力机制和混合密度建模，显著提高了癌症生存率预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 动机是提高全切片病理图像（WSIs）预测癌症特异性生存率的准确性。

Method: 方法包括动态补丁选择、图引导k均值聚类、注意力机制建模以及专家指导的混合密度建模。

Result: 在TCGA-KIRC和TCGA-LUAD数据集上，模型分别达到了0.712±0.028和0.645±0.017的一致性指数，以及0.254±0.018和0.281±0.031的Brier分数。

Conclusion: 该论文提出的模块化框架在预测癌症特异性生存率方面显著优于现有技术，展示了其在多种癌症类型中的预测潜力。

Abstract: We introduce a modular framework for predicting cancer-specific survival from
whole slide pathology images (WSIs) that significantly improves upon the
state-of-the-art accuracy. Our method integrating four key components. Firstly,
to tackle large size of WSIs, we use dynamic patch selection via quantile-based
thresholding for isolating prognostically informative tissue regions. Secondly,
we use graph-guided k-means clustering to capture phenotype-level heterogeneity
through spatial and morphological coherence. Thirdly, we use attention
mechanisms that model both intra- and inter-cluster relationships to
contextualize local features within global spatial relations between various
types of tissue compartments. Finally, we use an expert-guided mixture density
modeling for estimating complex survival distributions using Gaussian mixture
models. The proposed model achieves a concordance index of $0.712 \pm 0.028$
and Brier score of $0.254 \pm 0.018$ on TCGA-KIRC (renal cancer), and a
concordance index of $0.645 \pm 0.017$ and Brier score of $0.281 \pm 0.031$ on
TCGA-LUAD (lung adenocarcinoma). These results are significantly better than
the state-of-art and demonstrate predictive potential of the proposed method
across diverse cancer types.

</details>


### [56] [PlantSAM: An Object Detection-Driven Segmentation Pipeline for Herbarium Specimens](https://arxiv.org/abs/2507.16506)
*Youcef Sklab,Florian Castanet,Hanane Ariouat,Souhila Arib,Jean-Daniel Zucker,Eric Chenin,Edi Prifti*

Main category: cs.CV

TL;DR: PlantSAM结合YOLOv10和SAM2，通过背景分割提升植物标本图像分类准确性。


<details>
  <summary>Details</summary>
Motivation: 解决植物标本图像背景异质性导致的噪声和伪影问题，提高分类模型性能。

Method: 集成了YOLOv10用于植物区域检测和Segment Anything Model (SAM2)进行分割，通过微调并在植物标本图像上评估。

Result: PlantSAM实现了最先进的分割性能（IoU 0.94，Dice系数0.97），分类模型在五个植物性状上性能提升（准确率最高提升4.36%，F1分数提升4.15%）。

Conclusion: PlantSAM通过背景移除显著提高了植物标本图像的分类准确性，使模型能更有效聚焦于前景植物结构。

Abstract: Deep learning-based classification of herbarium images is hampered by
background heterogeneity, which introduces noise and artifacts that can
potentially mislead models and reduce classification accuracy. Addressing these
background-related challenges is critical to improving model performance. We
introduce PlantSAM, an automated segmentation pipeline that integrates YOLOv10
for plant region detection and the Segment Anything Model (SAM2) for
segmentation. YOLOv10 generates bounding box prompts to guide SAM2, enhancing
segmentation accuracy. Both models were fine-tuned on herbarium images and
evaluated using Intersection over Union (IoU) and Dice coefficient metrics.
PlantSAM achieved state-of-the-art segmentation performance, with an IoU of
0.94 and a Dice coefficient of 0.97. Incorporating segmented images into
classification models led to consistent performance improvements across five
tested botanical traits, with accuracy gains of up to 4.36% and F1-score
improvements of 4.15%. Our findings highlight the importance of background
removal in herbarium image analysis, as it significantly enhances
classification accuracy by allowing models to focus more effectively on the
foreground plant structures.

</details>


### [57] [C2-Evo: Co-Evolving Multimodal Data and Model for Self-Improving Reasoning](https://arxiv.org/abs/2507.16518)
*Xiuwei Chen,Wentao Hu,Hanhui Li,Jun Zhou,Zisheng Chen,Meng Cao,Yihan Zeng,Kui Zhang,Yu-Jie Yuan,Jianhua Han,Hang Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: 提出C2-Evo框架，通过联合进化数据和模型能力，解决现有自改进模型的数据不一致和任务难度不匹配问题，显著提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有自改进模型在视觉或文本数据增强上存在不一致性，且数据与模型进化分离，导致任务难度不匹配。为解决这些问题，提出了C2-Evo框架。

Method: 提出了C2-Evo，一个自动、闭环的自改进框架，包括跨模态数据进化循环和数据-模型进化循环，通过生成复杂的多模态问题和自适应选择问题来交替进行监督微调和强化学习。

Result: C2-Evo在多数学推理基准测试中持续获得显著性能提升。

Conclusion: C2-Evo框架通过联合进化训练数据和模型能力，持续提升了多模态大语言模型的性能，并在多个数学推理基准测试中取得了显著成果。

Abstract: Recent advances in multimodal large language models (MLLMs) have shown
impressive reasoning capabilities. However, further enhancing existing MLLMs
necessitates high-quality vision-language datasets with carefully curated task
complexities, which are both costly and challenging to scale. Although recent
self-improving models that iteratively refine themselves offer a feasible
solution, they still suffer from two core challenges: (i) most existing methods
augment visual or textual data separately, resulting in discrepancies in data
complexity (e.g., over-simplified diagrams paired with redundant textual
descriptions); and (ii) the evolution of data and models is also separated,
leading to scenarios where models are exposed to tasks with mismatched
difficulty levels. To address these issues, we propose C2-Evo, an automatic,
closed-loop self-improving framework that jointly evolves both training data
and model capabilities. Specifically, given a base dataset and a base model,
C2-Evo enhances them by a cross-modal data evolution loop and a data-model
evolution loop. The former loop expands the base dataset by generating complex
multimodal problems that combine structured textual sub-problems with
iteratively specified geometric diagrams, while the latter loop adaptively
selects the generated problems based on the performance of the base model, to
conduct supervised fine-tuning and reinforcement learning alternately.
Consequently, our method continuously refines its model and training data, and
consistently obtains considerable performance gains across multiple
mathematical reasoning benchmarks. Our code, models, and datasets will be
released.

</details>


### [58] [Spatial 3D-LLM: Exploring Spatial Awareness in 3D Vision-Language Models](https://arxiv.org/abs/2507.16524)
*Xiaoyan Wang,Zeju Li,Yifan Xu,Jiaxing Qi,Zhifei Yang,Ruifei Ma,Xiangde Liu,Chao Zhang*

Main category: cs.CV

TL;DR: Spatial 3D-LLM是一种增强3D空间感知能力的多模态LLM，通过渐进式空间感知方案显著提升了任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D多模态LLM在空间感知能力上存在不足，限制了其在3D场景中的表现。

Method: 提出了Spatial 3D-LLM，结合LLM主干和渐进式空间感知方案，生成位置丰富的3D场景嵌入作为视觉提示。

Result: 实验结果表明，Spatial 3D-LLM在多种3D视觉语言任务中性能最优。

Conclusion: Spatial 3D-LLM通过渐进式空间感知方案显著提升了3D视觉语言任务中的空间感知能力，并在多项任务中实现了最先进的性能。

Abstract: New era has unlocked exciting possibilities for extending Large Language
Models (LLMs) to tackle 3D vision-language tasks. However, most existing 3D
multimodal LLMs (MLLMs) rely on compressing holistic 3D scene information or
segmenting independent objects to perform these tasks, which limits their
spatial awareness due to insufficient representation of the richness inherent
in 3D scenes. To overcome these limitations, we propose Spatial 3D-LLM, a 3D
MLLM specifically designed to enhance spatial awareness for 3D vision-language
tasks by enriching the spatial embeddings of 3D scenes. Spatial 3D-LLM
integrates an LLM backbone with a progressive spatial awareness scheme that
progressively captures spatial information as the perception field expands,
generating location-enriched 3D scene embeddings to serve as visual prompts.
Furthermore, we introduce two novel tasks: 3D object distance measurement and
3D layout editing, and construct a 3D instruction dataset, MODEL, to evaluate
the model's spatial awareness capabilities. Experimental results demonstrate
that Spatial 3D-LLM achieves state-of-the-art performance across a wide range
of 3D vision-language tasks, revealing the improvements stemmed from our
progressive spatial awareness scheme of mining more profound spatial
information. Our code is available at
https://github.com/bjshuyuan/Spatial-3D-LLM.

</details>


### [59] [EarthCrafter: Scalable 3D Earth Generation via Dual-Sparse Latent Diffusion](https://arxiv.org/abs/2507.16535)
*Shang Liu,Chenjie Cao,Chaohui Yu,Wen Qian,Jing Wang,Fan Wang*

Main category: cs.CV

TL;DR: 该论文通过Aerial-Earth3D数据集和EarthCrafter框架，解决了大规模3D地球生成的挑战，实现了高效且多样化的地理场景建模。


<details>
  <summary>Details</summary>
Motivation: 尽管3D生成技术取得了显著进展，但扩展到地理范围（如数千平方公里的地球表面）仍是一个未解决的挑战。

Method: 提出了EarthCrafter框架，采用稀疏解耦的潜在扩散方法，通过双稀疏3D-VAEs压缩几何体素和纹理2D高斯泼溅，以及条件感知流匹配模型独立建模几何和纹理特征。

Result: 实验证明，EarthCrafter在极大规模生成任务中表现显著优于其他方法，支持从语义引导的城市布局生成到无条件地形合成的多样化应用。

Conclusion: EarthCrafter框架通过创新的数据基础设施和模型架构，成功解决了大规模3D地球生成的挑战，支持多样化的应用场景，并保持了地理合理性。

Abstract: Despite the remarkable developments achieved by recent 3D generation works,
scaling these methods to geographic extents, such as modeling thousands of
square kilometers of Earth's surface, remains an open challenge. We address
this through a dual innovation in data infrastructure and model architecture.
First, we introduce Aerial-Earth3D, the largest 3D aerial dataset to date,
consisting of 50k curated scenes (each measuring 600m x 600m) captured across
the U.S. mainland, comprising 45M multi-view Google Earth frames. Each scene
provides pose-annotated multi-view images, depth maps, normals, semantic
segmentation, and camera poses, with explicit quality control to ensure terrain
diversity. Building on this foundation, we propose EarthCrafter, a tailored
framework for large-scale 3D Earth generation via sparse-decoupled latent
diffusion. Our architecture separates structural and textural generation: 1)
Dual sparse 3D-VAEs compress high-resolution geometric voxels and textural 2D
Gaussian Splats (2DGS) into compact latent spaces, largely alleviating the
costly computation suffering from vast geographic scales while preserving
critical information. 2) We propose condition-aware flow matching models
trained on mixed inputs (semantics, images, or neither) to flexibly model
latent geometry and texture features independently. Extensive experiments
demonstrate that EarthCrafter performs substantially better in extremely
large-scale generation. The framework further supports versatile applications,
from semantic-guided urban layout generation to unconditional terrain
synthesis, while maintaining geographic plausibility through our rich data
priors from Aerial-Earth3D.

</details>


### [60] [Optimization of DNN-based HSI Segmentation FPGA-based SoC for ADS: A Practical Approach](https://arxiv.org/abs/2507.16556)
*Jon Gutiérrez-Zaballa,Koldo Basterretxea,Javier Echanobe*

Main category: cs.CV

TL;DR: 该研究提出了一套优化技术，用于在FPGA-based SoC上高效部署DNN-based HSI分割处理器，显著提升了推理速度和资源利用率，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 高光谱成像（HSI）在自主导航系统中具有潜力，但需满足安全关键系统（如ADS）对延迟、资源消耗和安全性的严格要求，因此需要将ML工作负载转移到边缘平台。

Method: 研究提出了一套优化技术，包括功能软件/硬件任务分配、硬件感知预处理、ML模型压缩和完整的流水线部署。

Result: 应用压缩技术后，设计的DNN复杂度降至原始操作的24.34%，参数数量降至原始的1.02%，推理任务速度提升2.86倍，且分割精度无明显下降。

Conclusion: 通过优化技术，该研究成功在FPGA-based SoC上实现了DNN-based HSI分割处理器的实时部署，显著降低了计算复杂度和参数数量，同时保持了分割精度。

Abstract: The use of HSI for autonomous navigation is a promising research field aimed
at improving the accuracy and robustness of detection, tracking, and scene
understanding systems based on vision sensors. Combining advanced computer
algorithms, such as DNNs, with small-size snapshot HSI cameras enhances the
reliability of these systems. HSI overcomes intrinsic limitations of greyscale
and RGB imaging in depicting physical properties of targets, particularly
regarding spectral reflectance and metamerism. Despite promising results in
HSI-based vision developments, safety-critical systems like ADS demand strict
constraints on latency, resource consumption, and security, motivating the
shift of ML workloads to edge platforms. This involves a thorough
software/hardware co-design scheme to distribute and optimize the tasks
efficiently among the limited resources of computing platforms. With respect to
inference, the over-parameterized nature of DNNs poses significant
computational challenges for real-time on-the-edge deployment. In addition, the
intensive data preprocessing required by HSI, which is frequently overlooked,
must be carefully managed in terms of memory arrangement and inter-task
communication to enable an efficient integrated pipeline design on a SoC. This
work presents a set of optimization techniques for the practical co-design of a
DNN-based HSI segmentation processor deployed on a FPGA-based SoC targeted at
ADS, including key optimizations such as functional software/hardware task
distribution, hardware-aware preprocessing, ML model compression, and a
complete pipelined deployment. Applied compression techniques significantly
reduce the complexity of the designed DNN to 24.34% of the original operations
and to 1.02% of the original number of parameters, achieving a 2.86x speed-up
in the inference task without noticeable degradation of the segmentation
accuracy.

</details>


### [61] [Comparative validation of surgical phase recognition, instrument keypoint estimation, and instrument instance segmentation in endoscopy: Results of the PhaKIR 2024 challenge](https://arxiv.org/abs/2507.16559)
*Tobias Rueckert,David Rauber,Raphaela Maerkl,Leonard Klausmann,Suemeyye R. Yildiran,Max Gutbrod,Danilo Weber Nunes,Alvaro Fernandez Moreno,Imanol Luengo,Danail Stoyanov,Nicolas Toussaint,Enki Cho,Hyeon Bae Kim,Oh Sung Choo,Ka Young Kim,Seong Tae Kim,Gonçalo Arantes,Kehan Song,Jianjun Zhu,Junchen Xiong,Tingyi Lin,Shunsuke Kikuchi,Hiroki Matsuzaki,Atsushi Kouno,João Renato Ribeiro Manesco,João Paulo Papa,Tae-Min Choi,Tae Kyeong Jeong,Juyoun Park,Oluwatosin Alabi,Meng Wei,Tom Vercauteren,Runzhi Wu,Mengya Xu,An Wang,Long Bai,Hongliang Ren,Amine Yamlahi,Jakob Hennighausen,Lena Maier-Hein,Satoshi Kondo,Satoshi Kasai,Kousuke Hirasawa,Shu Yang,Yihui Wang,Hao Chen,Santiago Rodríguez,Nicolás Aparicio,Leonardo Manrique,Juan Camilo Lyons,Olivia Hosie,Nicolás Ayobi,Pablo Arbeláez,Yiping Li,Yasmina Al Khalil,Sahar Nasirihaghighi,Stefanie Speidel,Daniel Rueckert,Hubertus Feussner,Dirk Wilhelm,Christoph Palm*

Main category: cs.CV

TL;DR: PhaKIR子挑战提供了一个多中心数据集，用于联合研究器械定位和手术上下文，推动了RAMIS领域的时间感知和上下文驱动方法发展。


<details>
  <summary>Details</summary>
Motivation: 在计算机和机器人辅助微创手术（RAMIS）中，可靠的手术器械识别和定位是多种应用的基础，但现实条件下的鲁棒性能仍是一个重大挑战。

Method: 引入了包含13个完整腹腔镜胆囊切除术视频的多中心数据集，统一标注了三个相关任务：手术阶段识别、器械关键点估计和器械实例分割。

Result: 报告了根据BIAS指南的结果和发现，支持在整个手术过程中整合时间信息。

Conclusion: PhaKIR子挑战通过提供一个独特的基准，推动了RAMIS领域中时间感知和上下文驱动方法的发展，并为未来手术场景理解研究提供了高质量资源。

Abstract: Reliable recognition and localization of surgical instruments in endoscopic
video recordings are foundational for a wide range of applications in computer-
and robot-assisted minimally invasive surgery (RAMIS), including surgical
training, skill assessment, and autonomous assistance. However, robust
performance under real-world conditions remains a significant challenge.
Incorporating surgical context - such as the current procedural phase - has
emerged as a promising strategy to improve robustness and interpretability.
  To address these challenges, we organized the Surgical Procedure Phase,
Keypoint, and Instrument Recognition (PhaKIR) sub-challenge as part of the
Endoscopic Vision (EndoVis) challenge at MICCAI 2024. We introduced a novel,
multi-center dataset comprising thirteen full-length laparoscopic
cholecystectomy videos collected from three distinct medical institutions, with
unified annotations for three interrelated tasks: surgical phase recognition,
instrument keypoint estimation, and instrument instance segmentation. Unlike
existing datasets, ours enables joint investigation of instrument localization
and procedural context within the same data while supporting the integration of
temporal information across entire procedures.
  We report results and findings in accordance with the BIAS guidelines for
biomedical image analysis challenges. The PhaKIR sub-challenge advances the
field by providing a unique benchmark for developing temporally aware,
context-driven methods in RAMIS and offers a high-quality resource to support
future research in surgical scene understanding.

</details>


### [62] [A Multimodal Deviation Perceiving Framework for Weakly-Supervised Temporal Forgery Localization](https://arxiv.org/abs/2507.16596)
*Wenbo Xu,Junyan Wu,Wei Lu,Xiangyang Luo,Qian Wang*

Main category: cs.CV

TL;DR: MDP框架通过多模态交互和偏差感知损失，在弱监督下实现了高效的Deepfake时间伪造定位。


<details>
  <summary>Details</summary>
Motivation: 解决现有Deepfake取证方法通常将检测视为分类任务或时间伪造定位问题，存在限制性、耗时且难以扩展的问题。

Method: MDP框架通过多模态交互机制（MI）和可扩展的偏差感知损失来感知多模态偏差，精确定位伪造片段的起止时间戳。

Result: 大量实验证明MDP框架的有效性，并在多个评估指标上达到了与全监督方法相当的结果。

Conclusion: 提出的多模态偏差感知框架（MDP）在弱监督条件下实现了可与全监督方法相媲美的伪造片段定位效果。

Abstract: Current researches on Deepfake forensics often treat detection as a
classification task or temporal forgery localization problem, which are usually
restrictive, time-consuming, and challenging to scale for large datasets. To
resolve these issues, we present a multimodal deviation perceiving framework
for weakly-supervised temporal forgery localization (MDP), which aims to
identify temporal partial forged segments using only video-level annotations.
The MDP proposes a novel multimodal interaction mechanism (MI) and an
extensible deviation perceiving loss to perceive multimodal deviation, which
achieves the refined start and end timestamps localization of forged segments.
Specifically, MI introduces a temporal property preserving cross-modal
attention to measure the relevance between the visual and audio modalities in
the probabilistic embedding space. It could identify the inter-modality
deviation and construct comprehensive video features for temporal forgery
localization. To explore further temporal deviation for weakly-supervised
learning, an extensible deviation perceiving loss has been proposed, aiming at
enlarging the deviation of adjacent segments of the forged samples and reducing
that of genuine samples. Extensive experiments demonstrate the effectiveness of
the proposed framework and achieve comparable results to fully-supervised
approaches in several evaluation metrics.

</details>


### [63] [Dyna3DGR: 4D Cardiac Motion Tracking with Dynamic 3D Gaussian Representation](https://arxiv.org/abs/2507.16608)
*Xueming Fu,Pei Wu,Yingtai Li,Xin Luo,Zihang Jiang,Junhao Mei,Jian Lu,Gao-Jun Teng,S. Kevin Zhou*

Main category: cs.CV

TL;DR: Dyna3DGR：结合3D高斯与神经运动场的新框架，自监督优化心脏运动跟踪，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（基于图像或表示）在心脏运动跟踪中存在局限性，如拓扑一致性不足或图像细节丢失，需新方法解决这些问题。

Method: 提出Dynamic 3D Gaussian Representation (Dyna3DGR)框架，结合显式3D高斯表示与隐式神经运动场建模，通过可微分体积渲染自监督优化心脏结构与运动。

Result: 在ACDC数据集上，Dyna3DGR在追踪准确性上超越了现有基于深度学习的微分同胚配准方法。

Conclusion: Dyna3DGR通过结合显式3D高斯表示和隐式神经运动场建模，显著提升了心脏运动跟踪的准确性，并在ACDC数据集上验证了其优越性。

Abstract: Accurate analysis of cardiac motion is crucial for evaluating cardiac
function. While dynamic cardiac magnetic resonance imaging (CMR) can capture
detailed tissue motion throughout the cardiac cycle, the fine-grained 4D
cardiac motion tracking remains challenging due to the homogeneous nature of
myocardial tissue and the lack of distinctive features. Existing approaches can
be broadly categorized into image based and representation-based, each with its
limitations. Image-based methods, including both raditional and deep
learning-based registration approaches, either struggle with topological
consistency or rely heavily on extensive training data. Representation-based
methods, while promising, often suffer from loss of image-level details. To
address these limitations, we propose Dynamic 3D Gaussian Representation
(Dyna3DGR), a novel framework that combines explicit 3D Gaussian representation
with implicit neural motion field modeling. Our method simultaneously optimizes
cardiac structure and motion in a self-supervised manner, eliminating the need
for extensive training data or point-to-point correspondences. Through
differentiable volumetric rendering, Dyna3DGR efficiently bridges continuous
motion representation with image-space alignment while preserving both
topological and temporal consistency. Comprehensive evaluations on the ACDC
dataset demonstrate that our approach surpasses state-of-the-art deep
learning-based diffeomorphic registration methods in tracking accuracy. The
code will be available in https://github.com/windrise/Dyna3DGR.

</details>


### [64] [CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast Cardiac Risk Prediction Using Cine MRIs](https://arxiv.org/abs/2507.16612)
*Haoyang Su,Shaohao Rui,Jinyi Xiang,Lianming Wu,Xiaosong Wang*

Main category: cs.CV

TL;DR: 自监督框架CTSL通过多视角蒸馏和码书特征学习，无需分割掩膜即可从Cine MRI预测MACE，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的MACE预测方法通常需要基于人工精修掩膜的有监督学习，这在无对比剂情况下不切实际。因此，需要一种无需分割掩膜的自监督学习框架。

Method: CTSL采用多视角蒸馏策略，教师模型处理多视角Cine数据，学生模型从降维的Cine-SA序列中学习。通过基于码书的特征表示和运动线索的动态病变自检测，捕捉复杂的时空依赖性和运动模式。

Result: CTSL在MACE风险预测中表现优于传统的依赖对比剂的方法，提供了高置信度的预测结果。

Conclusion: CTSL框架通过自监督学习从原始Cine MRI序列中提取时空特征，无需依赖对比剂或人工标注的分割掩膜，实现了高准确性的MACE预测，为临床心脏风险评估提供了快速、非侵入性的解决方案。

Abstract: Accurate and contrast-free Major Adverse Cardiac Events (MACE) prediction
from Cine MRI sequences remains a critical challenge. Existing methods
typically necessitate supervised learning based on human-refined masks in the
ventricular myocardium, which become impractical without contrast agents. We
introduce a self-supervised framework, namely Codebook-based Temporal-Spatial
Learning (CTSL), that learns dynamic, spatiotemporal representations from raw
Cine data without requiring segmentation masks. CTSL decouples temporal and
spatial features through a multi-view distillation strategy, where the teacher
model processes multiple Cine views, and the student model learns from
reduced-dimensional Cine-SA sequences. By leveraging codebook-based feature
representations and dynamic lesion self-detection through motion cues, CTSL
captures intricate temporal dependencies and motion patterns. High-confidence
MACE risk predictions are achieved through our model, providing a rapid,
non-invasive solution for cardiac risk assessment that outperforms traditional
contrast-dependent methods, thereby enabling timely and accessible heart
disease diagnosis in clinical settings.

</details>


### [65] [Automatic Fine-grained Segmentation-assisted Report Generation](https://arxiv.org/abs/2507.16623)
*Frederic Jonske,Constantin Seibold,Osman Alperen Koras,Fin Bahnsen,Marie Bauer,Amin Dada,Hamza Kalisch,Anton Schily,Jens Kleesiek*

Main category: cs.CV

TL;DR: ASaRG通过融合分割图提升报告生成性能，验证了评估的可信度，性能显著优于基线和其他方法。


<details>
  <summary>Details</summary>
Motivation: 减轻放射科医生的工作负担，并为临床医生或患者提供可信的第二意见，需要报告生成模型具备高性能和内在的验证能力。

Method: ASaRG扩展了LLaVA架构，通过简单拼接将中间特征和精细分割图融入多模态投影层，仅增加少量参数。

Result: ASaRG在CE F1分数上比LLaVA基线提升0.89%（仅中间特征）和2.77%（中间特征加分割图），优于其他方法COMG和ORID。

Conclusion: ASaRG通过融合中间特征和精细分割图，显著提升了报告生成的性能，同时提供了可验证的评估基础，未来可与其他LLaVA架构改进结合使用。

Abstract: Reliable end-to-end clinical report generation has been a longstanding goal
of medical ML research. The end goal for this process is to alleviate
radiologists' workloads and provide second opinions to clinicians or patients.
Thus, a necessary prerequisite for report generation models is a strong general
performance and some type of innate grounding capability, to convince
clinicians or patients of the veracity of the generated reports. In this paper,
we present ASaRG (\textbf{A}utomatic \textbf{S}egmentation-\textbf{a}ssisted
\textbf{R}eport \textbf{G}eneration), an extension of the popular LLaVA
architecture that aims to tackle both of these problems. ASaRG proposes to fuse
intermediate features and fine-grained segmentation maps created by specialist
radiological models into LLaVA's multi-modal projection layer via simple
concatenation. With a small number of added parameters, our approach achieves a
+0.89\% performance gain ($p=0.012$) in CE F1 score compared to the LLaVA
baseline when using only intermediate features, and +2.77\% performance gain
($p<0.001$) when adding a combination of intermediate features and fine-grained
segmentation maps. Compared with COMG and ORID, two other report generation
methods that utilize segmentations, the performance gain amounts to 6.98\% and
6.28\% in F1 score, respectively. ASaRG is not mutually exclusive with other
changes made to the LLaVA architecture, potentially allowing our method to be
combined with other advances in the field. Finally, the use of an arbitrary
number of segmentations as part of the input demonstrably allows tracing
elements of the report to the corresponding segmentation maps and verifying the
groundedness of assessments. Our code will be made publicly available at a
later date.

</details>


### [66] [A2Mamba: Attention-augmented State Space Models for Visual Recognition](https://arxiv.org/abs/2507.16624)
*Meng Lou,Yunxiang Fu,Yizhou Yu*

Main category: cs.CV

TL;DR: A2Mamba是一种结合Transformer和Mamba的混合架构，通过MASS模块实现多尺度注意力与SSM的深度融合，在多项视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅简单堆叠Transformer和Mamba层，缺乏深度交互机制。A2Mamba旨在解决这一问题，实现二者的深度融合。

Method: 提出A2Mamba架构，引入MASS模块（多尺度注意力增强状态空间模型），通过跨注意力机制增强SSM的空间依赖性和动态建模能力。

Result: A2Mamba在ImageNet-1K上达到86.1% top-1准确率，语义分割任务超越CAFormer-S36 2.5% mIoU，目标检测和实例分割任务表现优于MambaVision-B，且参数更少。

Conclusion: A2Mamba提出了一种新颖的Transformer-Mamba混合网络架构，通过MASS模块实现了多尺度注意力与状态空间模型的深度融合，显著提升了视觉识别任务的性能。

Abstract: Transformers and Mamba, initially invented for natural language processing,
have inspired backbone architectures for visual recognition. Recent studies
integrated Local Attention Transformers with Mamba to capture both local
details and global contexts. Despite competitive performance, these methods are
limited to simple stacking of Transformer and Mamba layers without any
interaction mechanism between them. Thus, deep integration between Transformer
and Mamba layers remains an open problem. We address this problem by proposing
A2Mamba, a powerful Transformer-Mamba hybrid network architecture, featuring a
new token mixer termed Multi-scale Attention-augmented State Space Model
(MASS), where multi-scale attention maps are integrated into an
attention-augmented SSM (A2SSM). A key step of A2SSM performs a variant of
cross-attention by spatially aggregating the SSM's hidden states using the
multi-scale attention maps, which enhances spatial dependencies pertaining to a
two-dimensional space while improving the dynamic modeling capabilities of
SSMs. Our A2Mamba outperforms all previous ConvNet-, Transformer-, and
Mamba-based architectures in visual recognition tasks. For instance, A2Mamba-L
achieves an impressive 86.1% top-1 accuracy on ImageNet-1K. In semantic
segmentation, A2Mamba-B exceeds CAFormer-S36 by 2.5% in mIoU, while exhibiting
higher efficiency. In object detection and instance segmentation with Cascade
Mask R-CNN, A2Mamba-S surpasses MambaVision-B by 1.2%/0.9% in AP^b/AP^m, while
having 40% less parameters. Code is publicly available at
https://github.com/LMMMEng/A2Mamba.

</details>


### [67] [Benchmarking pig detection and tracking under diverse and challenging conditions](https://arxiv.org/abs/2507.16639)
*Jonathan Henrich,Christian Post,Maximilian Zilke,Parth Shiroya,Emma Chanut,Amir Mollazadeh Yamchi,Ramin Yahyapour,Thomas Kneib,Imke Traulsen*

Main category: cs.CV

TL;DR: 研究创建了两个猪只行为监测数据集，评估了检测与跟踪技术，发现高质量数据提升性能，模型泛化能力强，代码数据已开源。


<details>
  <summary>Details</summary>
Motivation: 传统猪只行为监测依赖人工，效率低。机器学习虽能自动化，但缺乏系统性基准研究。本研究旨在填补这一空白。

Method: 研究通过构建两个数据集（PigDetect用于目标检测，PigTrack用于多目标跟踪），基于多样化的真实猪舍图像和视频材料，评估了不同方法的性能。

Result: 挑战性训练图像提升检测性能；SORT方法在检测上优于端到端模型，但后者在关联性能上表现更好，显示未来潜力。模型在未见过的猪舍中表现良好。

Conclusion: 该研究通过创建PigDetect和PigTrack数据集，系统评估了猪只检测与多目标跟踪技术，证明了高质量训练数据的重要性及模型的良好泛化能力。数据集和代码已公开，以促进可重复性和进一步研究。

Abstract: To ensure animal welfare and effective management in pig farming, monitoring
individual behavior is a crucial prerequisite. While monitoring tasks have
traditionally been carried out manually, advances in machine learning have made
it possible to collect individualized information in an increasingly automated
way. Central to these methods is the localization of animals across space
(object detection) and time (multi-object tracking). Despite extensive research
of these two tasks in pig farming, a systematic benchmarking study has not yet
been conducted. In this work, we address this gap by curating two datasets:
PigDetect for object detection and PigTrack for multi-object tracking. The
datasets are based on diverse image and video material from realistic barn
conditions, and include challenging scenarios such as occlusions or bad
visibility. For object detection, we show that challenging training images
improve detection performance beyond what is achievable with randomly sampled
images alone. Comparing different approaches, we found that state-of-the-art
models offer substantial improvements in detection quality over real-time
alternatives. For multi-object tracking, we observed that SORT-based methods
achieve superior detection performance compared to end-to-end trainable models.
However, end-to-end models show better association performance, suggesting they
could become strong alternatives in the future. We also investigate
characteristic failure cases of end-to-end models, providing guidance for
future improvements. The detection and tracking models trained on our datasets
perform well in unseen pens, suggesting good generalization capabilities. This
highlights the importance of high-quality training data. The datasets and
research code are made publicly available to facilitate reproducibility, re-use
and further development.

</details>


### [68] [Synthetic Data Matters: Re-training with Geo-typical Synthetic Labels for Building Detection](https://arxiv.org/abs/2507.16657)
*Shuang Song,Yang Tang,Rongjun Qin*

Main category: cs.CV

TL;DR: 该论文提出了一种利用地理典型合成数据和对抗域适应框架提升遥感建筑分割泛化能力的新方法，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在遥感建筑分割中取得了显著进展，但模型难以泛化到不同地理区域的数据，因为城市布局和建筑类型、大小及位置的分布存在差异。此外，捕获全球多样性的标注数据耗时且难以满足数据密集型模型的需求。

Method: 提出了一种在测试时使用针对目标区域城市布局定制的合成数据重新训练模型的新方法。利用OpenStreetMap等地理空间数据生成地理典型合成数据，并通过程序建模和基于物理的渲染创建高分辨率合成图像。

Result: 实验表明，该方法显著提升了性能，中位数改进高达12%，具体取决于域差距。

Conclusion: 该方法通过结合地理知识和合成影像，提供了一种可扩展且成本效益高的解决方案，显著提升了遥感建筑分割的泛化能力，无需大量真实世界标注。

Abstract: Deep learning has significantly advanced building segmentation in remote
sensing, yet models struggle to generalize on data of diverse geographic
regions due to variations in city layouts and the distribution of building
types, sizes and locations. However, the amount of time-consuming annotated
data for capturing worldwide diversity may never catch up with the demands of
increasingly data-hungry models. Thus, we propose a novel approach: re-training
models at test time using synthetic data tailored to the target region's city
layout. This method generates geo-typical synthetic data that closely
replicates the urban structure of a target area by leveraging geospatial data
such as street network from OpenStreetMap. Using procedural modeling and
physics-based rendering, very high-resolution synthetic images are created,
incorporating domain randomization in building shapes, materials, and
environmental illumination. This enables the generation of virtually unlimited
training samples that maintain the essential characteristics of the target
environment. To overcome synthetic-to-real domain gaps, our approach integrates
geo-typical data into an adversarial domain adaptation framework for building
segmentation. Experiments demonstrate significant performance enhancements,
with median improvements of up to 12%, depending on the domain gap. This
scalable and cost-effective method blends partial geographic knowledge with
synthetic imagery, providing a promising solution to the "model collapse" issue
in purely synthetic datasets. It offers a practical pathway to improving
generalization in remote sensing building segmentation without extensive
real-world annotations.

</details>


### [69] [QRetinex-Net: Quaternion-Valued Retinex Decomposition for Low-Level Computer Vision Applications](https://arxiv.org/abs/2507.16683)
*Sos Agaian,Vladimir Frants*

Main category: cs.CV

TL;DR: 四元数Retinex模型通过Hamilton乘积改进经典Retinex，解决了独立通道处理等问题，在多个任务中性能提升2-11%，且色彩保真度和噪声控制更优。


<details>
  <summary>Details</summary>
Motivation: 经典Retinex模型存在四项关键缺陷：独立处理RGB通道、缺乏神经科学颜色视觉模型、无法完美重建输入图像、无法解释人类颜色恒常性。

Method: 引入首个四元数Retinex公式，将场景表示为四元数反射率和照明的Hamilton乘积，并提出反射一致性指数评估反射率的不变性。

Result: 在低光裂纹检查、不同光照下的人脸检测和红外-可见光融合任务中，性能提升2-11%。

Conclusion: 提出的四元数Retinex模型在低光条件下的裂纹检测、不同光照下的人脸检测以及红外-可见光融合任务中，性能优于现有方法2-11%，并展现出更好的色彩保真度、更低噪声和更高的反射率稳定性。

Abstract: Images taken in low light often show color shift, low contrast, noise, and
other artifacts that hurt computer-vision accuracy. Retinex theory addresses
this by viewing an image S as the pixel-wise product of reflectance R and
illumination I, mirroring the way people perceive stable object colors under
changing light. The decomposition is ill-posed, and classic Retinex models have
four key flaws: (i) they treat the red, green, and blue channels independently;
(ii) they lack a neuroscientific model of color vision; (iii) they cannot
perfectly rebuild the input image; and (iv) they do not explain human color
constancy. We introduce the first Quaternion Retinex formulation, in which the
scene is written as the Hamilton product of quaternion-valued reflectance and
illumination. To gauge how well reflectance stays invariant, we propose the
Reflectance Consistency Index. Tests on low-light crack inspection, face
detection under varied lighting, and infrared-visible fusion show gains of 2-11
percent over leading methods, with better color fidelity, lower noise, and
higher reflectance stability.

</details>


### [70] [Enhancing Remote Sensing Vision-Language Models Through MLLM and LLM-Based High-Quality Image-Text Dataset Generation](https://arxiv.org/abs/2507.16716)
*Yiguo He,Junjie Zhu,Yiying Li,Xiaoyu Zhang,Chunping Qiu,Jun Wang,Qiangjuan Huang,Ke Yang*

Main category: cs.CV

TL;DR: 提出MpGI方法生成高质量遥感图像标注，构建HQRS-IT-210K数据集，训练模型性能超越SOTA且减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像-文本对数据稀缺及现有标注质量低的问题，以提升视觉语言基础模型在遥感任务中的性能。

Method: 采用两阶段方法MpGI，结合Rule-MLLM和MLLMs生成多视角描述，再通过LLMs整合为全面标注，最终构建了HQRS-IT-210K数据集。

Result: HQRS-CLIP在仅使用4.2%训练数据的情况下超越了之前的SOTA模型，RS-CoCa生成的标注甚至优于人工标注。

Conclusion: 论文提出的MpGI方法和HQRS-IT-210K数据集显著提升了视觉语言基础模型在遥感图像任务中的性能，尤其是在减少训练数据量的情况下仍能超越现有方法。

Abstract: The application of Vision-language foundation models (VLFMs) to remote
sensing (RS) imagery has garnered significant attention due to their superior
capability in various downstream tasks. A key challenge lies in the scarcity of
high-quality, large-scale, image-text paired training data. Recently, several
works introduced extensive image-text datasets for RS and trained their VLFMs.
However, due to the rudimentary methods used for generating captions, the
quality of datasets is suboptimal, requiring larger volumes of training data,
while only yielding modest performance improvements. In this paper, we propose
a two-stage method named MpGI(Multi-Perspective Generation and Integration) for
generating high-quality text captions for RS images. Firstly, we generate
distinct and detailed descriptions from different perspectives using
Rule-MLLM(Multimodal Large Language Model) Relay Generation and MLLMs
generation methods. Next, we utilize Large Language Models (LLMs) to integrate
these diverse descriptions into comprehensive captions, capturing details from
multiple perspectives. Finally, we have created the HQRS-IT-210K dataset,
including about 210,000 RS images and 1.3 million captions. We fine-tuned two
VLFMs using our dataset: CLIP, a discriminative model, and CoCa, an
image-to-text generative model. This process resulted in our proposed HQRS-CLIP
and RS-CoCa models. Experimental results demonstrate that HQRS-CLIP surpassed
the previous SOTA RS CLIP model in various downstream tasks while using only
4.2\% of the training data. RS-CoCa outperforms other advanced approaches
across benchmark datasets and can generate captions for RS images that rival or
even exceed manual annotations. Dataset, pre-trained models, and codes will be
released at https://github.com/YiguoHe/HQRS-210K-and-HQRS-CLIP.

</details>


### [71] [Temporally-Constrained Video Reasoning Segmentation and Automated Benchmark Construction](https://arxiv.org/abs/2507.16718)
*Yiqing Shen,Chenjia Li,Chenxiao Fan,Mathias Unberath*

Main category: cs.CV

TL;DR: 论文提出时间约束的视频推理分割任务，解决传统方法无法处理动态上下文的问题，并构建了TCVideoRSBenchmark数据集。


<details>
  <summary>Details</summary>
Motivation: 传统视频分割方法局限于预定义对象类别，无法处理复杂文本查询中的隐含对象或动态变化的上下文相关性，限制了在复杂场景（如手术室视频分析）中的应用。

Method: 引入时间约束的视频推理分割任务，提出自动化基准构建方法，并基于MVOR数据集构建了包含52个样本的TCVideoRSBenchmark数据集。

Result: 提出了时间约束的视频推理分割任务，并通过自动化方法构建了TCVideoRSBenchmark数据集，为模型在动态上下文中的对象分割能力提供了评估基准。

Conclusion: 论文提出了时间约束的视频推理分割任务，并构建了TCVideoRSBenchmark数据集，为复杂场景下的视频分割提供了新的解决方案。

Abstract: Conventional approaches to video segmentation are confined to predefined
object categories and cannot identify out-of-vocabulary objects, let alone
objects that are not identified explicitly but only referred to implicitly in
complex text queries. This shortcoming limits the utility for video
segmentation in complex and variable scenarios, where a closed set of object
categories is difficult to define and where users may not know the exact object
category that will appear in the video. Such scenarios can arise in operating
room video analysis, where different health systems may use different workflows
and instrumentation, requiring flexible solutions for video analysis. Reasoning
segmentation (RS) now offers promise towards such a solution, enabling natural
language text queries as interaction for identifying object to segment.
However, existing video RS formulation assume that target objects remain
contextually relevant throughout entire video sequences. This assumption is
inadequate for real-world scenarios in which objects of interest appear,
disappear or change relevance dynamically based on temporal context, such as
surgical instruments that become relevant only during specific procedural
phases or anatomical structures that gain importance at particular moments
during surgery. Our first contribution is the introduction of
temporally-constrained video reasoning segmentation, a novel task formulation
that requires models to implicitly infer when target objects become
contextually relevant based on text queries that incorporate temporal
reasoning. Since manual annotation of temporally-constrained video RS datasets
would be expensive and limit scalability, our second contribution is an
innovative automated benchmark construction method. Finally, we present
TCVideoRSBenchmark, a temporally-constrained video RS dataset containing 52
samples using the videos from the MVOR dataset.

</details>


### [72] [HarmonPaint: Harmonized Training-Free Diffusion Inpainting](https://arxiv.org/abs/2507.16732)
*Ying Li,Xinzhe Li,Yong Du,Yangyang Xu,Junyu Dong,Shengfeng He*

Main category: cs.CV

TL;DR: HarmonPaint 是一种无需训练的修复框架，通过扩散模型的注意力机制和掩码策略，实现高质量、协调一致的图像修复。


<details>
  <summary>Details</summary>
Motivation: 现有修复方法通常需要大量重新训练或微调，且难以保持修复区域与背景在结构和风格上的一致性。

Method: HarmonPaint 利用扩散模型的自注意力机制和掩码策略，确保结构保真度，并通过未掩码区域传递风格信息。

Result: 大量实验证明，HarmonPaint 在不同场景和风格中均表现优异，验证了其多功能性和高性能。

Conclusion: HarmonPaint 是一种无需训练的修复框架，通过利用扩散模型的注意力机制和自掩码策略，实现了高质量、协调一致的图像修复。

Abstract: Existing inpainting methods often require extensive retraining or fine-tuning
to integrate new content seamlessly, yet they struggle to maintain coherence in
both structure and style between inpainted regions and the surrounding
background. Motivated by these limitations, we introduce HarmonPaint, a
training-free inpainting framework that seamlessly integrates with the
attention mechanisms of diffusion models to achieve high-quality, harmonized
image inpainting without any form of training. By leveraging masking strategies
within self-attention, HarmonPaint ensures structural fidelity without model
retraining or fine-tuning. Additionally, we exploit intrinsic diffusion model
properties to transfer style information from unmasked to masked regions,
achieving a harmonious integration of styles. Extensive experiments demonstrate
the effectiveness of HarmonPaint across diverse scenes and styles, validating
its versatility and performance.

</details>


### [73] [DFR: A Decompose-Fuse-Reconstruct Framework for Multi-Modal Few-Shot Segmentation](https://arxiv.org/abs/2507.16736)
*Shuai Chen,Fanman Meng,Xiwei Zhang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: DFR是一种整合视觉、文本和音频模态的少样本分割框架，通过分解、融合和重建三步骤提升性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有少样本分割方法主要依赖单模态或双模态，限制了多模态信息的充分利用，DFR旨在通过整合视觉、文本和音频模态来克服这一局限。

Method: DFR框架包含三个关键创新：1）多模态分解（视觉区域提案、文本细粒度描述、音频特征处理）；2）多模态对比融合（通过对比学习保持模态一致性）；3）双路径重建（结合语义指导和几何线索）。

Result: 实验表明，DFR在视觉、文本和音频模态下的性能均显著优于现有方法。

Conclusion: DFR框架通过系统性整合视觉、文本和音频模态，显著提升了少样本分割任务的性能，且在合成和真实场景中均优于现有最先进方法。

Abstract: This paper presents DFR (Decompose, Fuse and Reconstruct), a novel framework
that addresses the fundamental challenge of effectively utilizing multi-modal
guidance in few-shot segmentation (FSS). While existing approaches primarily
rely on visual support samples or textual descriptions, their single or
dual-modal paradigms limit exploitation of rich perceptual information
available in real-world scenarios. To overcome this limitation, the proposed
approach leverages the Segment Anything Model (SAM) to systematically integrate
visual, textual, and audio modalities for enhanced semantic understanding. The
DFR framework introduces three key innovations: 1) Multi-modal Decompose: a
hierarchical decomposition scheme that extracts visual region proposals via
SAM, expands textual semantics into fine-grained descriptors, and processes
audio features for contextual enrichment; 2) Multi-modal Contrastive Fuse: a
fusion strategy employing contrastive learning to maintain consistency across
visual, textual, and audio modalities while enabling dynamic semantic
interactions between foreground and background features; 3) Dual-path
Reconstruct: an adaptive integration mechanism combining semantic guidance from
tri-modal fused tokens with geometric cues from multi-modal location priors.
Extensive experiments across visual, textual, and audio modalities under both
synthetic and real settings demonstrate DFR's substantial performance
improvements over state-of-the-art methods.

</details>


### [74] [Denoising-While-Completing Network (DWCNet): Robust Point Cloud Completion Under Corruption](https://arxiv.org/abs/2507.16743)
*Keneni W. Tesema,Lyndon Hill,Mark W. Jones,Gary K. L. Tam*

Main category: cs.CV

TL;DR: 提出了DWCNet，一种结合噪声管理模块的点云补全框架，在多种退化情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于噪声和遮挡，从真实环境中获取干净完整的点云具有挑战性。现有方法在合成数据上训练，难以应对真实世界的退化问题。

Method: 提出了DWCNet框架，包含一个噪声管理模块（NMM），利用对比学习和自注意力机制来抑制噪声并建模结构关系。

Result: DWCNet在干净和退化的合成及真实世界数据集上均达到了最先进的性能。

Conclusion: DWCNet（Denoising-While-Completing Network）通过结合对比学习和自注意力机制的噪声管理模块（NMM），在合成和真实世界的点云数据上实现了最先进的性能。数据集和代码将公开提供。

Abstract: Point cloud completion is crucial for 3D computer vision tasks in autonomous
driving, augmented reality, and robotics. However, obtaining clean and complete
point clouds from real-world environments is challenging due to noise and
occlusions. Consequently, most existing completion networks -- trained on
synthetic data -- struggle with real-world degradations. In this work, we
tackle the problem of completing and denoising highly corrupted partial point
clouds affected by multiple simultaneous degradations. To benchmark robustness,
we introduce the Corrupted Point Cloud Completion Dataset (CPCCD), which
highlights the limitations of current methods under diverse corruptions.
Building on these insights, we propose DWCNet (Denoising-While-Completing
Network), a completion framework enhanced with a Noise Management Module (NMM)
that leverages contrastive learning and self-attention to suppress noise and
model structural relationships. DWCNet achieves state-of-the-art performance on
both clean and corrupted, synthetic and real-world datasets. The dataset and
code will be publicly available at
https://github.com/keneniwt/DWCNET-Robust-Point-Cloud-Completion-against-Corruptions

</details>


### [75] [Zebra-CoT: A Dataset for Interleaved Vision Language Reasoning](https://arxiv.org/abs/2507.16746)
*Ang Li,Charles Wang,Kaiyu Yue,Zikui Cai,Ollie Liu,Deqing Fu,Peng Guo,Wang Bill Zhu,Vatsal Sharan,Robin Jia,Willie Neiswanger,Furong Huang,Tom Goldstein,Micah Goldblum*

Main category: cs.CV

TL;DR: Zebra-CoT是一个大规模多样化数据集，用于训练视觉CoT模型，显著提升多模态推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决视觉CoT领域的两大挑战：现成视觉CoT性能不佳和高质量训练数据的缺乏。

Method: 通过微调Anole-7B和Bagel-7B模型在Zebra-CoT训练集上，生成高质量的交错视觉推理链。

Result: 微调Anole-7B模型在测试集准确率提升12%，在标准VLM基准评估中性能提升高达13%。

Conclusion: Zebra-CoT数据集和模型的开源支持了视觉CoT的发展和评估，展示了其在提升多模态推理能力方面的有效性。

Abstract: Humans often use visual aids, for example diagrams or sketches, when solving
complex problems. Training multimodal models to do the same, known as Visual
Chain of Thought (Visual CoT), is challenging due to: (1) poor off-the-shelf
visual CoT performance, which hinders reinforcement learning, and (2) the lack
of high-quality visual CoT training data. We introduce $\textbf{Zebra-CoT}$, a
diverse large-scale dataset with 182,384 samples, containing logically coherent
interleaved text-image reasoning traces. We focus on four categories of tasks
where sketching or visual reasoning is especially natural, spanning scientific
questions such as geometry, physics, and algorithms; 2D visual reasoning tasks
like visual search and jigsaw puzzles; 3D reasoning tasks including 3D
multi-hop inference, embodied and robot planning; visual logic problems and
strategic games like chess. Fine-tuning the Anole-7B model on the Zebra-CoT
training corpus results in an improvement of +12% in our test-set accuracy and
yields up to +13% performance gain on standard VLM benchmark evaluations.
Fine-tuning Bagel-7B yields a model that generates high-quality interleaved
visual reasoning chains, underscoring Zebra-CoT's effectiveness for developing
multimodal reasoning abilities. We open-source our dataset and models to
support development and evaluation of visual CoT.

</details>


### [76] [CMP: A Composable Meta Prompt for SAM-Based Cross-Domain Few-Shot Segmentation](https://arxiv.org/abs/2507.16753)
*Shuai Chen,Fanman Meng,Chunjin Yang,Haoran Wei,Chenhao Wu,Qingbo Wu,Hongliang Li*

Main category: cs.CV

TL;DR: CMP框架通过三个模块解决跨域少样本分割的挑战，在1-shot和5-shot场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决跨域少样本分割（CD-FSS）中因数据有限和域偏移带来的挑战，并克服SAM在手动提示依赖和跨域能力不足的问题。

Method: 提出了可组合元提示（CMP）框架，包含三个关键模块：RCT模块（语义扩展）、CMPG模块（自动元提示合成）和FAI模块（域差异缓解）。

Result: 在四个跨域数据集上的评估显示，CMP在1-shot和5-shot场景下分别达到71.8%和74.5%的mIoU，性能领先。

Conclusion: CMP框架在跨域少样本分割任务中表现出色，1-shot和5-shot场景下的mIoU分别达到71.8%和74.5%，验证了其先进性能。

Abstract: Cross-Domain Few-Shot Segmentation (CD-FSS) remains challenging due to
limited data and domain shifts. Recent foundation models like the Segment
Anything Model (SAM) have shown remarkable zero-shot generalization capability
in general segmentation tasks, making it a promising solution for few-shot
scenarios. However, adapting SAM to CD-FSS faces two critical challenges:
reliance on manual prompt and limited cross-domain ability. Therefore, we
propose the Composable Meta-Prompt (CMP) framework that introduces three key
modules: (i) the Reference Complement and Transformation (RCT) module for
semantic expansion, (ii) the Composable Meta-Prompt Generation (CMPG) module
for automated meta-prompt synthesis, and (iii) the Frequency-Aware Interaction
(FAI) module for domain discrepancy mitigation. Evaluations across four
cross-domain datasets demonstrate CMP's state-of-the-art performance, achieving
71.8\% and 74.5\% mIoU in 1-shot and 5-shot scenarios respectively.

</details>


### [77] [Faithful, Interpretable Chest X-ray Diagnosis with Anti-Aliased B-cos Networks](https://arxiv.org/abs/2507.16761)
*Marcel Kleinmann,Shashank Agnihotri,Margret Keuper*

Main category: cs.CV

TL;DR: 改进B-cos网络以解决伪影问题并支持多标签分类，在胸部X光分析中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准B-cos模型在解释图中存在严重的伪影，且原B-cos公式仅适用于多类设置，而胸部X光分析通常需要多标签分类。

Method: 通过引入FLCPooling (FLC)和BlurPool (BP)的抗锯齿策略，并扩展B-cos网络以支持多标签分类。

Result: 实验表明，改进后的B-cos网络在胸部X光数据集上保持了预测性能，同时提供了无伪影的解释。

Conclusion: 改进后的B-cos网络（B-cos_FLC和B-cos_BP）在多标签分类任务中保持了强大的预测性能，同时提供了适合临床应用的无伪影解释。

Abstract: Faithfulness and interpretability are essential for deploying deep neural
networks (DNNs) in safety-critical domains such as medical imaging. B-cos
networks offer a promising solution by replacing standard linear layers with a
weight-input alignment mechanism, producing inherently interpretable,
class-specific explanations without post-hoc methods. While maintaining
diagnostic performance competitive with state-of-the-art DNNs, standard B-cos
models suffer from severe aliasing artifacts in their explanation maps, making
them unsuitable for clinical use where clarity is essential. Additionally, the
original B-cos formulation is limited to multi-class settings, whereas chest
X-ray analysis often requires multi-label classification due to co-occurring
abnormalities. In this work, we address both limitations: (1) we introduce
anti-aliasing strategies using FLCPooling (FLC) and BlurPool (BP) to
significantly improve explanation quality, and (2) we extend B-cos networks to
support multi-label classification. Our experiments on chest X-ray datasets
demonstrate that the modified $\text{B-cos}_\text{FLC}$ and
$\text{B-cos}_\text{BP}$ preserve strong predictive performance while providing
faithful and artifact-free explanations suitable for clinical application in
multi-label settings. Code available at:
$\href{https://github.com/mkleinma/B-cos-medical-paper}{GitHub repository}$.

</details>


### [78] [Task-Specific Zero-shot Quantization-Aware Training for Object Detection](https://arxiv.org/abs/2507.16782)
*Changhao Li,Xinrui Chen,Ji Wang,Kang Zhao,Jianfei Chen*

Main category: cs.CV

TL;DR: 本文提出了一种任务特定的零样本量化框架，通过合成任务特定校准集和知识蒸馏，显著提升了目标检测网络的量化性能，实验证明了其高效性和先进性。


<details>
  <summary>Details</summary>
Motivation: 传统量化方法依赖原始训练数据，但隐私和安全问题限制了其应用。零样本量化通过合成数据解决了这一问题，但现有方法在目标检测中表现不佳，因此需要任务特定的解决方案。

Method: 提出了一种新颖的任务特定零样本量化框架，包括两个主要阶段：边界框和类别采样策略生成任务特定校准集，以及任务特定训练与知识蒸馏的结合。

Result: 在MS-COCO和Pascal VOC数据集上的广泛实验证明了该方法的效率和最先进性能。

Conclusion: 本文提出的任务特定零样本量化框架在目标检测网络中表现出色，通过特定任务的训练和知识蒸馏，显著提升了量化网络的性能。

Abstract: Quantization is a key technique to reduce network size and computational
complexity by representing the network parameters with a lower precision.
Traditional quantization methods rely on access to original training data,
which is often restricted due to privacy concerns or security challenges.
Zero-shot Quantization (ZSQ) addresses this by using synthetic data generated
from pre-trained models, eliminating the need for real training data. Recently,
ZSQ has been extended to object detection. However, existing methods use
unlabeled task-agnostic synthetic images that lack the specific information
required for object detection, leading to suboptimal performance. In this
paper, we propose a novel task-specific ZSQ framework for object detection
networks, which consists of two main stages. First, we introduce a bounding box
and category sampling strategy to synthesize a task-specific calibration set
from the pre-trained network, reconstructing object locations, sizes, and
category distributions without any prior knowledge. Second, we integrate
task-specific training into the knowledge distillation process to restore the
performance of quantized detection networks. Extensive experiments conducted on
the MS-COCO and Pascal VOC datasets demonstrate the efficiency and
state-of-the-art performance of our method. Our code is publicly available at:
https://github.com/DFQ-Dojo/dfq-toolkit .

</details>


### [79] [Enhancing Domain Diversity in Synthetic Data Face Recognition with Dataset Fusion](https://arxiv.org/abs/2507.16790)
*Anjith George,Sebastien Marcel*

Main category: cs.CV

TL;DR: 研究提出结合两种不同架构的合成人脸数据集，减少伪影和增强多样性，在基准测试中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前人脸识别系统训练数据集多通过网络爬取未经用户明确同意，存在伦理和隐私问题。虽然合成数据被用于训练，但其性能通常不及真实数据，且单一生成器模型会导致模型特定的伪影和过拟合问题。

Method: 本研究提出了一种解决方案，即结合两种使用不同架构骨干生成的合成人脸数据集，以减少模型特定的伪影并增强数据多样性。

Result: 在标准人脸识别基准测试中，使用结合后的数据集训练的模型表现优于其他方法。

Conclusion: 通过结合两种架构不同的合成人脸数据集，本研究成功减少了模型特定的伪影，增强了数据多样性，并在标准人脸识别基准测试中取得了优越的性能。

Abstract: While the accuracy of face recognition systems has improved significantly in
recent years, the datasets used to train these models are often collected
through web crawling without the explicit consent of users, raising ethical and
privacy concerns. To address this, many recent approaches have explored the use
of synthetic data for training face recognition models. However, these models
typically underperform compared to those trained on real-world data. A common
limitation is that a single generator model is often used to create the entire
synthetic dataset, leading to model-specific artifacts that may cause
overfitting to the generator's inherent biases and artifacts. In this work, we
propose a solution by combining two state-of-the-art synthetic face datasets
generated using architecturally distinct backbones. This fusion reduces
model-specific artifacts, enhances diversity in pose, lighting, and
demographics, and implicitly regularizes the face recognition model by
emphasizing identity-relevant features. We evaluate the performance of models
trained on this combined dataset using standard face recognition benchmarks and
demonstrate that our approach achieves superior performance across many of
these benchmarks.

</details>


### [80] [HOComp: Interaction-Aware Human-Object Composition](https://arxiv.org/abs/2507.16813)
*Dong Liang,Jinyuan Jia,Yuhao Liu,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: HOComp通过MRPG和DCAP技术，解决了人-物交互合成中的无缝性和一致性问题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像引导合成方法在涉及人-物交互时难以实现无缝合成，HOComp旨在解决这一问题。

Method: HOComp结合了MLLMs驱动的区域姿态引导（MRPG）和细节一致外观保持（DCAP），包括粗到细的姿势约束和多视角外观损失。

Result: 实验结果表明，HOComp在IHOC数据集上定性定量优于相关方法。

Conclusion: HOComp方法通过MRPG和DCAP设计，有效生成了和谐的人-物交互，并在外观一致性上表现优异，优于现有方法。

Abstract: While existing image-guided composition methods may help insert a foreground
object onto a user-specified region of a background image, achieving natural
blending inside the region with the rest of the image unchanged, we observe
that these existing methods often struggle in synthesizing seamless
interaction-aware compositions when the task involves human-object
interactions. In this paper, we first propose HOComp, a novel approach for
compositing a foreground object onto a human-centric background image, while
ensuring harmonious interactions between the foreground object and the
background person and their consistent appearances. Our approach includes two
key designs: (1) MLLMs-driven Region-based Pose Guidance (MRPG), which utilizes
MLLMs to identify the interaction region as well as the interaction type (e.g.,
holding and lefting) to provide coarse-to-fine constraints to the generated
pose for the interaction while incorporating human pose landmarks to track
action variations and enforcing fine-grained pose constraints; and (2)
Detail-Consistent Appearance Preservation (DCAP), which unifies a shape-aware
attention modulation mechanism, a multi-view appearance loss, and a background
consistency loss to ensure consistent shapes/textures of the foreground and
faithful reproduction of the background human. We then propose the first
dataset, named Interaction-aware Human-Object Composition (IHOC), for the task.
Experimental results on our dataset show that HOComp effectively generates
harmonious human-object interactions with consistent appearances, and
outperforms relevant methods qualitatively and quantitatively.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [81] [Fast Task Planning with Neuro-Symbolic Relaxation](https://arxiv.org/abs/2507.15975)
*Qiwei Du,Bowen Li,Yi Du,Shaoshu Su,Taimeng Fu,Zitong Zhan,Zhipeng Zhao,Chen Wang*

Main category: cs.RO

TL;DR: Flax通过神经符号松弛策略结合神经预测与符号扩展，显著提升任务规划的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务规划需要在大量实体和复杂关系上进行长视野推理，导致经典符号规划器面临组合爆炸问题。现有方法通过神经网络预测少数“重要”实体来简化任务，但可能导致关键实体遗漏或资源浪费。

Method: 结合神经重要性预测与符号扩展，首先学习图神经网络预测实体重要性以创建简化任务，然后用符号规划器解决；接着解决规则松弛任务以获取粗略计划，并重新整合所有引用实体以恢复可能被忽略的关键元素；最后应用补充规则细化更新后的任务。

Result: 在合成和现实世界迷宫导航基准测试中，Flax将平均成功率提高了20.82%，并将平均规划时间缩短了17.65%。

Conclusion: Flax提供了一种在复杂环境中实现快速、可扩展、长视野任务规划的实用路径。

Abstract: Real-world task planning requires long-horizon reasoning over large sets of
entities with complex relationships and attributes, leading to a combinatorial
explosion for classical symbolic planners. To prune the search space, recent
methods prioritize searching on a simplified task only containing a few
"important" entities predicted by a neural network. However, such a simple
neuro-symbolic (NeSy) integration risks omitting critical entities and wasting
resources on unsolvable simplified tasks. To enable Fast and reliable planning,
we introduce a NeSy relaxation strategy (Flax), combining neural importance
prediction with symbolic expansion. Specifically, we first learn a graph neural
network to predict entity importance to create a simplified task and solve it
with a symbolic planner. Then, we solve a rule-relaxed task to obtain a quick
rough plan, and reintegrate all referenced entities into the simplified task to
recover any overlooked but essential elements. Finally, we apply complementary
rules to refine the updated task, keeping it both reliable and compact.
Extensive experiments are conducted on both synthetic and real-world maze
navigation benchmarks where a robot must traverse through a maze and interact
with movable objects. The results show that Flax boosts the average success
rate by 20.82% and cuts mean wall-clock planning time by 17.65% compared with
the state-of-the-art NeSy baseline. We expect that Flax offers a practical path
toward fast, scalable, long-horizon task planning in complex environments.

</details>


### [82] [A Comprehensive Evaluation of LiDAR Odometry Techniques](https://arxiv.org/abs/2507.16000)
*Easton Potokar,Michael Kaess*

Main category: cs.RO

TL;DR: 本文系统评估了LiDAR Odometry（LO）管道的各种技术组件，并基于实证数据提出了优化建议，以提高未来LO管道的精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前研究缺乏对LO管道各构建模块的系统性比较，本文旨在填补这一空白，提供更全面的技术评估。

Method: 总结并实证评估了LO管道的各种技术组件，包括在不同数据集、LiDAR类型和车辆运动环境下的测试。

Result: 通过对多种环境、LiDAR类型和车辆运动的广泛数据集测试，得出了各LO组件的性能表现。

Conclusion: 本文通过实证研究，为未来LiDAR Odometry（LO）管道的设计提供了基于数据的建议，旨在实现最高精度和可靠性。

Abstract: Light Detection and Ranging (LiDAR) sensors have become the sensor of choice
for many robotic state estimation tasks. Because of this, in recent years there
has been significant work done to fine the most accurate method to perform
state estimation using these sensors. In each of these prior works, an
explosion of possible technique combinations has occurred, with each work
comparing LiDAR Odometry (LO) "pipelines" to prior "pipelines". Unfortunately,
little work up to this point has performed the significant amount of ablation
studies comparing the various building-blocks of a LO pipeline. In this work,
we summarize the various techniques that go into defining a LO pipeline and
empirically evaluate these LO components on an expansive number of datasets
across environments, LiDAR types, and vehicle motions. Finally, we make
empirically-backed recommendations for the design of future LO pipelines to
provide the most accurate and reliable performance.

</details>


### [83] [Improved Semantic Segmentation from Ultra-Low-Resolution RGB Images Applied to Privacy-Preserving Object-Goal Navigation](https://arxiv.org/abs/2507.16034)
*Xuying Huang,Sicong Pan,Olga Zatsarynna,Juergen Gall,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出一种联合学习方法，通过超低分辨率语义分割实现隐私保护的机器人导航，在分割和导航任务上均优于基线。


<details>
  <summary>Details</summary>
Motivation: 移动机器人中的用户隐私已成为关键问题，现有方法往往在任务性能与隐私保护之间取舍，后者常限制任务执行效果。

Method: 提出了一种新颖的全联合学习方法，结合了凝聚特征提取器和分割感知判别器，以解决超低分辨率语义分割问题。

Result: 该方法在超低分辨率语义分割任务上表现优于基线，并提升了隐私约束场景下的语义目标导航成功率。

Conclusion: 该方法在超低分辨率语义分割上表现优于不同基线，并提高了真实世界隐私约束场景下语义目标导航的成功率。

Abstract: User privacy in mobile robotics has become a critical concern. Existing
methods typically prioritize either the performance of downstream robotic tasks
or privacy protection, with the latter often constraining the effectiveness of
task execution. To jointly address both objectives, we study semantic-based
robot navigation in an ultra-low-resolution setting to preserve visual privacy.
A key challenge in such scenarios is recovering semantic segmentation from
ultra-low-resolution RGB images. In this work, we introduce a novel fully
joint-learning method that integrates an agglomerative feature extractor and a
segmentation-aware discriminator to solve ultra-low-resolution semantic
segmentation, thereby enabling privacy-preserving, semantic object-goal
navigation. Our method outperforms different baselines on ultra-low-resolution
semantic segmentation and our improved segmentation results increase the
success rate of the semantic object-goal navigation in a real-world
privacy-constrained scenario.

</details>


### [84] [Therapist-Exoskeleton-Patient Interaction: An Immersive Gait Therapy](https://arxiv.org/abs/2507.16059)
*Emek Barış Küçüktabak,Matthew R. Short,Lorenzo Vianello,Daniel Ludvig,Levi Hargrove,Kevin Lynch,Jose Pons*

Main category: cs.RO

TL;DR: pHRHI结合机器人外骨骼与治疗师直觉，通过双向交互改善中风患者步态康复效果。


<details>
  <summary>Details</summary>
Motivation: 传统康复治疗中，治疗师的高强度手动辅助既费力又难以同时控制多个关节，而现有机器人外骨骼控制策略限制了治疗师的参与和适应性。

Method: 提出了一种基于物理人-机器人-人交互（pHRHI）的新型步态康复范式，治疗师和患者均穿戴下肢外骨骼，通过弹簧-阻尼元件虚拟连接髋关节和膝关节。

Result: 在八名慢性中风患者的研究中，pHRHI训练在关节活动范围、步态指标、肌肉激活和患者动机方面均优于传统的治疗师引导跑步机行走。

Conclusion: pHRHI范式结合了机器人精确性和治疗师直觉，显著改善了康复效果，展示了其在康复治疗中的潜力。

Abstract: Following a stroke, individuals often experience mobility and balance
impairments due to lower-limb weakness and loss of independent joint control.
Gait recovery is a key goal of rehabilitation, traditionally achieved through
high-intensity therapist-led training. However, manual assistance can be
physically demanding and limits the therapist's ability to interact with
multiple joints simultaneously. Robotic exoskeletons offer multi-joint support,
reduce therapist strain, and provide objective feedback, but current control
strategies often limit therapist involvement and adaptability.
  We present a novel gait rehabilitation paradigm based on physical
Human-Robot-Human Interaction (pHRHI), where both the therapist and the
post-stroke individual wear lower-limb exoskeletons virtually connected at the
hips and knees via spring-damper elements. This enables bidirectional
interaction, allowing the therapist to guide movement and receive haptic
feedback. In a study with eight chronic stroke patients, pHRHI training
outperformed conventional therapist-guided treadmill walking, leading to
increased joint range of motion, step metrics, muscle activation, and
motivation. These results highlight pHRHI's potential to combine robotic
precision with therapist intuition for improved rehabilitation outcomes.

</details>


### [85] [Compositional Coordination for Multi-Robot Teams with Large Language Models](https://arxiv.org/abs/2507.16068)
*Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LAN2CB利用LLMs将自然语言任务描述直接转换为多机器人系统的可执行代码，简化协调流程并提升灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统多机器人协调流程依赖领域专家手动将自然语言任务描述转化为数学公式、算法设计和可执行代码，这一过程耗时、对非专家不友好且难以适应任务需求变化。

Method: LAN2CB框架包含两个关键组件：任务分解与任务表示（将任务解析为带依赖关系的任务图）和代码生成（利用任务图与结构化知识库生成可部署的机器人控制代码）。

Result: 实验结果表明，LAN2CB在仿真和实际场景中均能实现从自然语言到多机器人协调的有效转换，显著减少人工干预。

Conclusion: LAN2CB框架通过利用大型语言模型（LLMs）直接从自然语言描述生成可执行代码，显著减少了多机器人协调中的手工工程需求，并支持跨任务类型的泛化。

Abstract: Multi-robot coordination has traditionally relied on a task-specific and
expert-driven pipeline, where natural language mission descriptions are
manually translated by domain experts into mathematical formulation, algorithm
design, and executable code. This conventional process is labor-intensive,
inaccessible to non-experts, and inflexible to changes in mission requirements.
Here, we propose LAN2CB (Language to Collective Behavior), a novel framework
that leverages large language models (LLMs) to streamline and generalize the
multi-robot coordination pipeline. LAN2CB directly converts natural language
mission descriptions into executable Python code for multi-robot systems
through two key components: (1) Mission Decomposition for Task Representation,
which parses the mission into a task graph with dependencies, and (2) Code
Generation, which uses the task graph and a structured knowledge base to
generate deployable robot control code. We further introduce a dataset of
natural language mission specifications to support development and
benchmarking. Experimental results in both simulation and real-world settings
show that LAN2CB enables effective and flexible multi-robot coordination from
natural language, significantly reducing the need for manual engineering while
supporting generalization across mission types. Website:
https://sites.google.com/view/lan2cb.

</details>


### [86] [FTIN: Frequency-Time Integration Network for Inertial Odometry](https://arxiv.org/abs/2507.16120)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 本文提出了一种结合频域和时域信息的网络架构，通过频域学习建模长期依赖和时域LSTM捕获序列依赖，显著提升了惯性里程计的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有惯性里程计方法主要依赖时域CNN，难以捕捉IMU数据的长期依赖，限制了定位精度的进一步提升。

Method: 提出了一种新颖的网络架构，结合频域和时域信息，利用频域学习的全局视角和能量压缩特性建模长期依赖，并引入Scalar LSTM捕获时域序列依赖，实现跨域信息融合。

Result: 在多个公开数据集（如RIDI、RoNIN、OxIOD等）上的实验验证了所提方法的有效性，尤其在RoNIN数据集上表现显著。

Conclusion: 本文提出的频域-时域融合策略显著提升了惯性里程计的定位精度，尤其在RoNIN数据集上表现突出，绝对轨迹误差和相对轨迹误差分别降低了43.0%和13.1%。

Abstract: In recent years, machine learning has achieved significant advancements in
inertial odometry. However, most existing inertial odometry methods primarily
rely on CNNs in the time domain. These methods often struggle to capture
long-term dependency in inertial measurement unit data, thereby constraining
the potential for further improvements in localization accuracy. To address
these issues, we propose a novel network architecture that integrates both
frequency-domain and time-domain information. Specifically, we leverage the
global view and energy compaction properties of frequency-domain learning to
effectively model long-term dependency and reduce redundancy in IMU data.
Additionally, we introduce a Scalar LSTM to capture sequential dependencies in
the time domain, enabling cross-domain information fusion and providing a
stable and reliable reference for localization. Experimental evaluations on
multiple public datasets (e.g., RIDI, RoNIN, OxIOD, RNIN, TLIO, and IMUNet)
demonstrate the effectiveness of the proposed frequency-time domain fusion
strategy. Notably, on the RoNIN dataset, our method achieves a 43.0% reduction
in absolute trajectory error and a 13.1% reduction in relative trajectory error
compared to RoNIN ResNet.

</details>


### [87] [DWSFormer: A Lightweight Inertial Odometry Network for Complex Motion Modeling](https://arxiv.org/abs/2507.16121)
*Shanshan Zhang,Qi Zhang,Siyue Wang,Tianshui Wen,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出一种轻量级IO框架，通过高维特征投影、协作注意力机制和多尺度门控卷积，显著提升复杂运动下的定位精度，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有IO方法在复杂运动模式（如转弯）下存在漂移误差，限制了其在现实场景中的适用性。

Method: 使用Star Operation方法将惯性数据投影到高维隐式非线性特征空间，引入协作注意力机制联合建模全局运动动态，并设计多尺度门控卷积单元捕捉细粒度动态变化。

Result: 在六个广泛使用的惯性数据集上，该方法均优于现有最优基线，其中在RoNIN数据集上ATE降低了2.26%至65.78%。

Conclusion: 本文提出的轻量级IO框架通过Star Operation方法、协作注意力机制和多尺度门控卷积单元，显著提升了惯性里程计的定位精度，特别是在复杂运动模式下的表现，为惯性里程计领域设立了新的基准。

Abstract: Inertial odometry (IO) directly estimates the position of a carrier from
inertial sensor measurements and serves as a core technology for the widespread
deployment of consumer grade localization systems. While existing IO methods
can accurately reconstruct simple and near linear motion trajectories, they
often fail to account for drift errors caused by complex motion patterns such
as turning. This limitation significantly degrades localization accuracy and
restricts the applicability of IO systems in real world scenarios. To address
these challenges, we propose a lightweight IO framework. Specifically, inertial
data is projected into a high dimensional implicit nonlinear feature space
using the Star Operation method, enabling the extraction of complex motion
features that are typically overlooked. We further introduce a collaborative
attention mechanism that jointly models global motion dynamics across both
channel and temporal dimensions. In addition, we design Multi Scale Gated
Convolution Units to capture fine grained dynamic variations throughout the
motion process, thereby enhancing the model's ability to learn rich and
expressive motion representations. Extensive experiments demonstrate that our
proposed method consistently outperforms SOTA baselines across six widely used
inertial datasets. Compared to baseline models on the RoNIN dataset, it
achieves reductions in ATE ranging from 2.26% to 65.78%, thereby establishing a
new benchmark in the field.

</details>


### [88] [Benchmarking LLM Privacy Recognition for Social Robot Decision Making](https://arxiv.org/abs/2507.16124)
*Dakota Sullivan,Shirley Zhang,Jennica Li,Heather Kirkorian,Bilge Mutlu,Kassem Fawaz*

Main category: cs.RO

TL;DR: 研究评估LLMs在家庭社交机器人中的隐私意识，发现与人类偏好差异大，但提示策略可改善其表现。


<details>
  <summary>Details</summary>
Motivation: 探索现成LLMs在家庭社交机器人环境中的隐私意识程度，以平衡实用性与隐私风险。

Method: 通过Contextual Integrity框架设计隐私相关场景，调查用户隐私偏好（N=450），并对比10种先进LLMs的反应。实施四种提示策略以评估LLMs作为隐私控制器的能力。

Result: 发现人类与LLMs在隐私偏好上的一致性较低，但通过特定提示策略可提升LLMs的隐私意识表现。

Conclusion: 论文讨论了LLMs在家庭社交机器人中隐私意识的潜力，并探讨了人类与LLMs在隐私偏好上的差异，提出了未来改进的方向。

Abstract: Social robots are embodied agents that interact with people while following
human communication norms. These robots interact using verbal and non-verbal
cues, and share the physical environments of people. While social robots have
previously utilized rule-based systems or probabilistic models for user
interaction, the rapid evolution of large language models (LLMs) presents new
opportunities to develop LLM-empowered social robots for enhanced human-robot
interaction. To fully realize these capabilities, however, robots need to
collect data such as audio, fine-grained images, video, and locations. As a
result, LLMs often process sensitive personal information, particularly within
home environments. Given the tension between utility and privacy risks,
evaluating how current LLMs manage sensitive data is critical. Specifically, we
aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the
context of household social robots. In this study, we present a set of
privacy-relevant scenarios crafted through the lens of Contextual Integrity
(CI). We first survey users' privacy preferences regarding in-home social robot
behaviors and then examine how their privacy orientation affects their choices
of these behaviors (N = 450). We then provide the same set of scenarios and
questions to state-of-the-art LLMs (N = 10) and find that the agreement between
humans and LLMs is low. To further investigate the capabilities of LLMs as a
potential privacy controller, we implement four additional prompting strategies
and compare their results. Finally, we discuss the implications and potential
of AI privacy awareness in human-robot interaction.

</details>


### [89] [Equivariant Goal Conditioned Contrastive Reinforcement Learning](https://arxiv.org/abs/2507.16139)
*Arsh Tangri,Nichols Crawford Taylor,Haojie Huang,Robert Platt*

Main category: cs.RO

TL;DR: ECRL通过等变约束优化对比强化学习，提升了样本效率和泛化能力，在模拟和离线任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用目标条件操作任务中的固有对称性，提升对比强化学习的样本效率和泛化能力。

Method: 提出Goal-Conditioned Group-Invariant MDPs框架，结合旋转不变性critic和旋转等变性actor进行对比强化学习。

Result: 在模拟任务中（包括基于状态和图像的设置）表现优于基线方法，并在离线RL任务中验证了有效性。

Conclusion: Equivariant CRL (ECRL)通过引入等变约束，有效提升了样本效率和空间泛化能力，并在离线RL设置中展现了良好的性能。

Abstract: Contrastive Reinforcement Learning (CRL) provides a promising framework for
extracting useful structured representations from unlabeled interactions. By
pulling together state-action pairs and their corresponding future states,
while pushing apart negative pairs, CRL enables learning nontrivial policies
without manually designed rewards. In this work, we propose Equivariant CRL
(ECRL), which further structures the latent space using equivariant
constraints. By leveraging inherent symmetries in goal-conditioned manipulation
tasks, our method improves both sample efficiency and spatial generalization.
Specifically, we formally define Goal-Conditioned Group-Invariant MDPs to
characterize rotation-symmetric robotic manipulation tasks, and build on this
by introducing a novel rotation-invariant critic representation paired with a
rotation-equivariant actor for Contrastive RL. Our approach consistently
outperforms strong baselines across a range of simulated tasks in both
state-based and image-based settings. Finally, we extend our method to the
offline RL setting, demonstrating its effectiveness across multiple tasks.

</details>


### [90] [Scanning Bot: Efficient Scan Planning using Panoramic Cameras](https://arxiv.org/abs/2507.16175)
*Euijeong Lee,Kyung Min Han,Young J. Kim*

Main category: cs.RO

TL;DR: 提出自主扫描规划方法，解决手动操作耗时问题，实验显示其扫描覆盖率达99%，速度提升3倍。


<details>
  <summary>Details</summary>
Motivation: 解决全景RGB-D相机在手动选择视点和物理移动相机时耗时繁琐的问题，以及新手用户因空间限制（如确保视点帧间足够特征重叠）面临的挑战。

Method: 提出了一种完全自主的扫描规划方法，生成高效的环境扫描路径，确保无碰撞导航和视点间足够的特征重叠。

Result: 在合成和真实环境中进行的广泛实验验证了该规划器的性能，特别在真实实验中实现了99%的平均扫描覆盖率，总扫描时间比现有先进规划器快3倍。

Conclusion: 该论文提出的完全自主扫描规划方法在真实环境中实现了99%的平均扫描覆盖率，并且扫描速度比现有先进规划器快3倍。

Abstract: Panoramic RGB-D cameras are known for their ability to produce high quality
3D scene reconstructions. However, operating these cameras involves manually
selecting viewpoints and physically transporting the camera, making the
generation of a 3D model time consuming and tedious. Additionally, the process
can be challenging for novice users due to spatial constraints, such as
ensuring sufficient feature overlap between viewpoint frames. To address these
challenges, we propose a fully autonomous scan planning that generates an
efficient tour plan for environment scanning, ensuring collision-free
navigation and adequate overlap between viewpoints within the plan. Extensive
experiments conducted in both synthetic and real-world environments validate
the performance of our planner against state-of-the-art view planners. In
particular, our method achieved an average scan coverage of 99 percent in the
real-world experiment, with our approach being up to 3 times faster than
state-of-the-art planners in total scan time.

</details>


### [91] [Adaptive Relative Pose Estimation Framework with Dual Noise Tuning for Safe Approaching Maneuvers](https://arxiv.org/abs/2507.16214)
*Batu Candan,Simone Servadio*

Main category: cs.RO

TL;DR: 该论文提出了一种结合CNN和自适应UKF的集成系统，用于提升主动碎片清除任务中的相对姿态估计精度和稳健性，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对主动碎片清除任务中翻滚失效卫星（如ENVISAT）的相对姿态估计挑战，需要一种高精度且稳健的解决方案。

Method: 结合卷积神经网络（CNN）和图像预处理技术检测结构标记，通过相机建模将2D坐标转换为3D测量值，并在无迹卡尔曼滤波器（UKF）框架中融合这些测量值，采用双重自适应策略动态调整噪声协方差。

Result: 通过高保真仿真验证，该系统在多种条件下（包括测量中断）均能提供准确的相对姿态估计，显著提升了相对导航能力。

Conclusion: 该论文提出了一种集成先进计算机视觉技术和自适应非线性滤波的完整流程，显著提升了主动碎片清除任务中相对导航的稳健性和准确性。

Abstract: Accurate and robust relative pose estimation is crucial for enabling
challenging Active Debris Removal (ADR) missions targeting tumbling derelict
satellites such as ESA's ENVISAT. This work presents a complete pipeline
integrating advanced computer vision techniques with adaptive nonlinear
filtering to address this challenge. A Convolutional Neural Network (CNN),
enhanced with image preprocessing, detects structural markers (corners) from
chaser imagery, whose 2D coordinates are converted to 3D measurements using
camera modeling. These measurements are fused within an Unscented Kalman Filter
(UKF) framework, selected for its ability to handle nonlinear relative
dynamics, to estimate the full relative pose. Key contributions include the
integrated system architecture and a dual adaptive strategy within the UKF:
dynamic tuning of the measurement noise covariance compensates for varying CNN
measurement uncertainty, while adaptive tuning of the process noise covariance,
utilizing measurement residual analysis, accounts for unmodeled dynamics or
maneuvers online. This dual adaptation enhances robustness against both
measurement imperfections and dynamic model uncertainties. The performance of
the proposed adaptive integrated system is evaluated through high-fidelity
simulations using a realistic ENVISAT model, comparing estimates against ground
truth under various conditions, including measurement outages. This
comprehensive approach offers an enhanced solution for robust onboard relative
navigation, significantly advancing the capabilities required for safe
proximity operations during ADR missions.

</details>


### [92] [GFM-Planner: Perception-Aware Trajectory Planning with Geometric Feature Metric](https://arxiv.org/abs/2507.16233)
*Yue Lin,Xiaoxuan Zhang,Yang Liu,Dong Wang,Huchuan Lu*

Main category: cs.RO

TL;DR: GFM-Planner通过几何特征度量和轨迹规划，提升LiDAR定位精度，避免特征退化区域。


<details>
  <summary>Details</summary>
Motivation: 自主机器人依赖特征丰富的环境进行精确定位，类似于人类依赖地标进行导航。

Method: 提出GFM-Planner框架，包括几何特征度量（GFM）的推导、2D网格度量编码地图（MEM）的设计、恒定时间解码算法的开发，以及感知感知轨迹规划算法的实现。

Result: 实验表明，GFM-Planner能有效引导机器人选择特征丰富的轨迹，显著提升LiDAR定位精度。

Conclusion: GFM-Planner通过引导机器人避开特征退化区域，显著提高了LiDAR定位的准确性，仿真和真实实验均验证了其有效性。

Abstract: Like humans who rely on landmarks for orientation, autonomous robots depend
on feature-rich environments for accurate localization. In this paper, we
propose the GFM-Planner, a perception-aware trajectory planning framework based
on the geometric feature metric, which enhances LiDAR localization accuracy by
guiding the robot to avoid degraded areas. First, we derive the Geometric
Feature Metric (GFM) from the fundamental LiDAR localization problem. Next, we
design a 2D grid-based Metric Encoding Map (MEM) to efficiently store GFM
values across the environment. A constant-time decoding algorithm is further
proposed to retrieve GFM values for arbitrary poses from the MEM. Finally, we
develop a perception-aware trajectory planning algorithm that improves LiDAR
localization capabilities by guiding the robot in selecting trajectories
through feature-rich areas. Both simulation and real-world experiments
demonstrate that our approach enables the robot to actively select trajectories
that significantly enhance LiDAR localization accuracy.

</details>


### [93] [Trajectory Planning of a Curtain Wall Installation Robot Based on Biomimetic Mechanisms](https://arxiv.org/abs/2507.16305)
*Xiao Liu,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 研究提出了一种仿生轨迹规划框架，结合人类运动特征和PSO算法，显著降低了建筑机器人的能耗，并在幕墙安装任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人市场的快速发展使得能耗问题日益突出，尤其是建筑机器人的应用受到限制，研究从人体上肢举重运动中获取灵感，旨在解决这一挑战。

Method: 通过收集哑铃弯举时的运动轨迹和肌电图（EMG）信号，构建了结合人体施力模式和能耗模式的仿人轨迹规划，并利用粒子群优化（PSO）算法实现基于人类运动特征的动态负载分配。

Result: 仿真结果显示，通过动能和势能的智能转换，能耗降低了48.4%，验证了该轨迹规划方法的正确性和优越性。

Conclusion: 该研究通过仿生轨迹规划框架，显著降低了建筑机器人在幕墙安装任务中的能耗，为实际搬运任务中的能源优化提供了新的理论支持。

Abstract: As the robotics market rapidly evolves, energy consumption has become a
critical issue, particularly restricting the application of construction
robots. To tackle this challenge, our study innovatively draws inspiration from
the mechanics of human upper limb movements during weight lifting, proposing a
bio-inspired trajectory planning framework that incorporates human energy
conversion principles. By collecting motion trajectories and electromyography
(EMG) signals during dumbbell curls, we construct an anthropomorphic trajectory
planning that integrates human force exertion patterns and energy consumption
patterns. Utilizing the Particle Swarm Optimization (PSO) algorithm, we achieve
dynamic load distribution for robotic arm trajectory planning based on
human-like movement features. In practical application, these bio-inspired
movement characteristics are applied to curtain wall installation tasks,
validating the correctness and superiority of our trajectory planning method.
Simulation results demonstrate a 48.4% reduction in energy consumption through
intelligent conversion between kinetic and potential energy. This approach
provides new insights and theoretical support for optimizing energy use in
curtain wall installation robots during actual handling tasks.

</details>


### [94] [Design and Dimensional Optimization of Legged Structures for Construction Robots](https://arxiv.org/abs/2507.16328)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文提出了一种针对建筑场景的腿部配置设计与优化方法，通过运动学建模、工作空间分析和虚拟仿真，优化了腿部的运动性能，为复杂地形下的自主移动提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 面对复杂非结构化的建筑环境，轮式和履带式机器人在地形适应性和灵活性上存在显著局限，难以满足自主操作需求。受自然界蚂蚁启发，旨在提升建筑机器人的自主移动能力。

Method: 通过运动学建模和多维工作空间分析，引入“改进工作空间”概念，并采用图形方法优化摆动阶段的腿部尺寸。基于速度雅可比矩阵引入“平均可操作性”概念，应用数值解获得最大化可操作性的腿部比例。通过ADAMS中的虚拟原型仿真探索机器人身体最优灵活性与腿部比例的关系。

Result: 获得了具有最佳综合运动性能的腿部比例，提出了首个针对建筑环境的腿部运动性能多维定量评估框架。

Conclusion: 本研究为建筑环境中的腿式机器人提出了一种多维定量评估框架，为复杂地形下的自主移动提供了结构设计基础。

Abstract: Faced with complex and unstructured construction environments, wheeled and
tracked robots exhibit significant limitations in terrain adaptability and
flexibility, making it difficult to meet the requirements of autonomous
operation. Inspired by ants in nature, this paper proposes a leg configuration
design and optimization method tailored for construction scenarios, aiming to
enhance the autonomous mobility of construction robots. This paper analyzes the
full operational motion performance of the leg during both swing and stance
phases. First, based on kinematic modeling and multi-dimensional workspace
analysis, the concept of an "improved workspace" is introduced, and graphical
methods are used to optimize the leg dimensions during the swing phase.
Furthermore, a new concept of "average manipulability" is introduced based on
the velocity Jacobian matrix, and numerical solutions are applied to obtain the
leg segment ratio that maximizes manipulability. To overcome the difficulties
associated with traditional analytical methods, virtual prototype simulations
are conducted in ADAMS to explore the relationship between the robot body's
optimal flexibility and leg segment proportions. In summary, the leg segment
proportions with the best comprehensive motion performance are obtained. This
study presents the first multi-dimensional quantitative evaluation framework
for leg motion performance tailored for construction environments, providing a
structural design foundation for legged construction robots to achieve
autonomous mobility in complex terrains.

</details>


### [95] [Topology Optimization of Leg Structures for Construction Robots Based on Variable Density Method](https://arxiv.org/abs/2507.16335)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 该论文提出了一种基于SIMP方法的腿部结构拓扑优化策略，通过有限元分析验证，成功实现轻量化设计，为复杂环境中的施工机器人提供了技术支持。


<details>
  <summary>Details</summary>
Motivation: 复杂地形施工环境对机器人同时具备高负载能力和移动灵活性提出了高要求，腿部结构作为关键承载部件的优化尤为重要。

Method: 采用基于SIMP变量密度法的拓扑优化策略和结构重新设计方法，通过ANSYS进行有限元分析，验证设计性能。首先进行静态和模态分析评估初始设计合理性，然后对腿部重量占比最大的股骨部分进行拓扑优化和二次结构重建。

Result: 优化后，股骨质量减少19.45%，整体腿部质量降低7.92%，实现了轻量化设计目标，且优化后的腿部仍满足结构性能要求。

Conclusion: 该研究为复杂地形施工环境中机器人的轻量化设计提供了可靠的理论和技术支持，并为其高效运行奠定了基础。

Abstract: In complex terrain construction environments, there are high demands for
robots to achieve both high payload capacity and mobility flexibility. As the
key load-bearing component, the optimization of robotic leg structures is of
particular importance. Therefore, this study focuses on the optimization of leg
structures for construction robots, proposing a topology optimization strategy
based on the SIMP (Solid Isotropic Microstructures with Penalization) variable
density method along with a structural re-design approach. The design
performance is comprehensively validated through finite element analysis using
ANSYS. First, static and modal analyses are conducted to evaluate the
rationality of the initial design. Then, topology optimization using the
SIMP-based variable density method is applied to the femur section, which
accounts for the largest proportion of the leg's weight. Based on iterative
calculations, the femur undergoes secondary structural reconstruction. After
optimization, the mass of the femur is reduced by 19.45\%, and the overall leg
mass decreases by 7.92\%, achieving the goal of lightweight design. Finally,
static and modal analyses are conducted on the reconstructed leg. The results
demonstrate that the optimized leg still meets structural performance
requirements, validating the feasibility of lightweight design. This research
provides robust theoretical and technical support for lightweight construction
robot design and lays a foundation for their efficient operation in complex
construction environments.

</details>


### [96] [Humanoid Robot Whole-body Geometric Calibration with Embedded Sensors and a Single Plane](https://arxiv.org/abs/2507.16369)
*Thanh D V Nguyen,Vincent Bonnet,Pierre Fernbach,David Daney,Florent Lamiraux*

Main category: cs.RO

TL;DR: 提出IROC算法和单平面校准方法，显著简化人形机器人全身运动学校准，实验验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 人形机器人的全身几何校准是一个耗时且实验负担重的任务，但在人形机器人社区中常被忽视。为了解决这一问题，作者提出了一种无需人工干预的校准方法。

Method: 提出了一种新颖的实用方法，利用单个平面、嵌入式力传感器和导纳控制器，无需人工干预即可校准人形机器人的全身运动学。此外，还开发了IROC算法，用于生成和确定最小化的最优校准姿态集。

Result: 在TALOS人形机器人上验证了IROC算法和单平面校准方法的有效性。仅使用31个最优姿态和3点接触，校准后的平均均方根误差比制造商模型降低了2.3倍。

Conclusion: 论文提出了一种名为IROC的新算法，结合单平面校准方法，显著减少了人形机器人全身运动学校准的时间和实验负担，验证了其有效性和实用性。

Abstract: Whole-body geometric calibration of humanoid robots using classical robot
calibration methods is a timeconsuming and experimentally burdensome task.
However, despite its significance for accurate control and simulation, it is
often overlooked in the humanoid robotics community. To address this issue, we
propose a novel practical method that utilizes a single plane, embedded force
sensors, and an admittance controller to calibrate the whole-body kinematics of
humanoids without requiring manual intervention. Given the complexity of
humanoid robots, it is crucial to generate and determine a minimal set of
optimal calibration postures. To do so, we propose a new algorithm called IROC
(Information Ranking algorithm for selecting Optimal Calibration postures).
IROC requires a pool of feasible candidate postures to build a normalized
weighted information matrix for each posture. Then, contrary to other
algorithms from the literature, IROC will determine the minimal number of
optimal postures that are to be played onto a robot for its calibration. Both
IROC and the single-plane calibration method were experimentally validated on a
TALOS humanoid robot. The total whole-body kinematics chain was calibrated
using solely 31 optimal postures with 3-point contacts on a table by the robot
gripper. In a cross-validation experiment, the average root-mean-square (RMS)
error was reduced by a factor of 2.3 compared to the manufacturer's model.

</details>


### [97] [Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance](https://arxiv.org/abs/2507.16382)
*Chenhao Yao,Zike Yuan,Xiaoxu Liu,Chi Zhu*

Main category: cs.RO

TL;DR: A novel MARL framework using LLMs to dynamically adjust reward functions improves FCCA efficiency in dynamic environments, validated by simulations and real-world tests.


<details>
  <summary>Details</summary>
Motivation: The complexity of Formation Control with Collision Avoidance (FCCA) in MAS necessitates an innovative approach to reward function design for optimal policy convergence.

Method: The framework leverages large language models (LLMs) to dynamically adjust reward functions based on task prioritization and observable information, using advanced evaluation metrics.

Result: Empirical studies confirm the framework's practicality and effectiveness, enabling simultaneous achievement of formation control and obstacle avoidance with fewer iterations.

Conclusion: The proposed framework effectively addresses the challenge of designing reward functions in MARL for FCCA, demonstrating enhanced efficiency and performance in both simulation and real-world settings.

Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through
the collaborative efforts of individual agents. Among the methodologies
employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of
the most efficacious algorithms. However, when confronted with the complex
objective of Formation Control with Collision Avoidance (FCCA): designing an
effective reward function that facilitates swift convergence of the policy
network to an optimal solution. In this paper, we introduce a novel framework
that aims to overcome this challenge. By giving large language models (LLMs) on
the prioritization of tasks and the observable information available to each
agent, our framework generates reward functions that can be dynamically
adjusted online based on evaluation outcomes by employing more advanced
evaluation metrics rather than the rewards themselves. This mechanism enables
the MAS to simultaneously achieve formation control and obstacle avoidance in
dynamic environments with enhanced efficiency, requiring fewer iterations to
reach superior performance levels. Our empirical studies, conducted in both
simulation and real-world settings, validate the practicality and effectiveness
of our proposed approach.

</details>


### [98] [AI or Human? Understanding Perceptions of Embodied Robots with LLMs](https://arxiv.org/abs/2507.16398)
*Lavinia Hriscu,Alberto Sanfeliu,Anais Garrell*

Main category: cs.RO

TL;DR: 研究通过图灵测试发现，参与者难以区分AI和人类控制的机器人，为机器人设计和AI智能评估提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 探索在图灵测试中评估系统智能的有效性，特别是在人机交互领域中的应用和相关性。

Method: 研究通过在机器人平台上进行图灵测试，评估了34名参与者在信息检索和包裹交接两个交互任务中对AI和人类操作机器人的区分能力。

Result: 参与者无法可靠地区分AI和人类控制的机器人，分析揭示了影响对人工与人类智能感知的关键因素。

Conclusion: 研究结果表明，参与者在区分AI和人类控制的机器人方面表现与随机猜测无显著差异，这为未来交互式机器人的设计提供了重要见解，并促进了AI系统中智能评估的持续讨论。

Abstract: The pursuit of artificial intelligence has long been associated to the the
challenge of effectively measuring intelligence. Even if the Turing Test was
introduced as a means of assessing a system intelligence, its relevance and
application within the field of human-robot interaction remain largely
underexplored. This study investigates the perception of intelligence in
embodied robots by performing a Turing Test within a robotic platform. A total
of 34 participants were tasked with distinguishing between AI- and
human-operated robots while engaging in two interactive tasks: an information
retrieval and a package handover. These tasks assessed the robot perception and
navigation abilities under both static and dynamic conditions. Results indicate
that participants were unable to reliably differentiate between AI- and
human-controlled robots beyond chance levels. Furthermore, analysis of
participant responses reveals key factors influencing the perception of
artificial versus human intelligence in embodied robotic systems. These
findings provide insights into the design of future interactive robots and
contribute to the ongoing discourse on intelligence assessment in AI-driven
systems.

</details>


### [99] [Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones](https://arxiv.org/abs/2507.16458)
*Yang Xu,Jesús Bautista,José Hinojosa,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出一种不依赖速度调节的固定翼无人机编队算法，通过路径引导和振荡行为实现协调，经理论和实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机在编队飞行中速度调节受限，因其速度范围严格受限且通常设计为以标称空速飞行，因此提出一种不依赖速度调节的编队算法。

Method: 算法通过引导无人机沿特定路径飞行，并在引导向量场上叠加振荡行为来控制路径上的平均速度，实现无人机间的协调。采用分布式闭环方式调整振荡幅度，并引入一种新颖的共识算法，利用非负、非对称饱和函数。

Result: 算法成功实现了固定翼无人机的编队飞行，通过理论证明和实验验证了其可行性和有效性。

Conclusion: 本文提出了一种无需调节固定翼无人机速度即可实现编队飞行的算法，通过理论分析、数值模拟和实际飞行验证了其有效性。

Abstract: The autonomous formation flight of fixed-wing drones is hard when the
coordination requires the actuation over their speeds since they are critically
bounded and aircraft are mostly designed to fly at a nominal airspeed. This
paper proposes an algorithm to achieve formation flights of fixed-wing drones
without requiring any actuation over their speed. In particular, we guide all
the drones to travel over specific paths, e.g., parallel straight lines, and we
superpose an oscillatory behavior onto the guiding vector field that drives the
drones to the paths. This oscillation enables control over the average velocity
along the path, thereby facilitating inter-drone coordination. Each drone
adjusts its oscillation amplitude distributively in a closed-loop manner by
communicating with neighboring agents in an undirected and connected graph. A
novel consensus algorithm is introduced, leveraging a non-negative, asymmetric
saturation function. This unconventional saturation is justified since negative
amplitudes do not make drones travel backward or have a negative velocity along
the path. Rigorous theoretical analysis of the algorithm is complemented by
validation through numerical simulations and a real-world formation flight.

</details>


### [100] [Designing for Difference: How Human Characteristics Shape Perceptions of Collaborative Robots](https://arxiv.org/abs/2507.16480)
*Sabrina Livanec,Laura Londoño,Michael Gorki,Adrian Röfer,Abhinav Valada,Andrea Kiesel*

Main category: cs.RO

TL;DR: 研究探讨人机协作中机器人行为与人类需求的评估，发现亲社会设计和反思方法（如CAM）对开发用户中心机器人系统至关重要。


<details>
  <summary>Details</summary>
Motivation: 填补现有研究中关于参与者如何评估不同机器人行为与多样化人类需求结合的空白，尤其是在参与者对先进家用机器人实际经验有限的情况下。

Method: 通过在线研究，112名参与者评估了28种人机协作类型的7个视频，实验组在评分前完成了认知情感映射（CAM）练习。

Result: 反社会机器人行为评分最低，而与老年人协作的场景获得更敏感的评估。包含物体传递的场景比不包含的更受欢迎。CAM反思未显著影响总体评分，但对某些机器人行为与人类条件的组合评估更为明显。

Conclusion: 研究强调了亲社会设计的重要性，并展示了反思方法（如CAM）在获取细致反馈方面的潜力，支持开发以用户为中心且对社会负责的机器人系统。

Abstract: The development of assistive robots for social collaboration raises critical
questions about responsible and inclusive design, especially when interacting
with individuals from protected groups such as those with disabilities or
advanced age. Currently, research is scarce on how participants assess varying
robot behaviors in combination with diverse human needs, likely since
participants have limited real-world experience with advanced domestic robots.
In the current study, we aim to address this gap while using methods that
enable participants to assess robot behavior, as well as methods that support
meaningful reflection despite limited experience. In an online study, 112
participants (from both experimental and control groups) evaluated 7 videos
from a total of 28 variations of human-robot collaboration types. The
experimental group first completed a cognitive-affective mapping (CAM) exercise
on human-robot collaboration before providing their ratings. Although CAM
reflection did not significantly affect overall ratings, it led to more
pronounced assessments for certain combinations of robot behavior and human
condition. Most importantly, the type of human-robot collaboration influences
the assessment. Antisocial robot behavior was consistently rated as the lowest,
while collaboration with aged individuals elicited more sensitive evaluations.
Scenarios involving object handovers were viewed more positively than those
without them. These findings suggest that both human characteristics and
interaction paradigms influence the perceived acceptability of collaborative
robots, underscoring the importance of prosocial design. They also highlight
the potential of reflective methods, such as CAM, to elicit nuanced feedback,
supporting the development of user-centered and socially responsible robotic
systems tailored to diverse populations.

</details>


### [101] [Guided Reinforcement Learning for Omnidirectional 3D Jumping in Quadruped Robots](https://arxiv.org/abs/2507.16481)
*Riccardo Bussola,Michele Focchi,Giulio Turrisi,Claudio Semini,Luigi Palopoli*

Main category: cs.RO

TL;DR: 提出一种结合Bézier曲线和UARM模型的引导式强化学习方法，显著提升四足机器人跳跃运动的效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法耗时且依赖大量机器人及地形参数知识，鲁棒性不足；传统端到端强化学习方法样本复杂度高且难以保证最终运动的安全性。

Method: 采用引导式强化学习方法，结合Bézier曲线和均匀加速直线运动模型（UARM），以物理直觉为基础设计跳跃运动。

Result: 仿真和实验结果表明，该方法在样本复杂度和运动可预测性上优于现有方法。

Conclusion: 本文提出了一种结合Bézier曲线和均匀加速直线运动模型（UARM）的引导式强化学习方法，显著提高了四足机器人跳跃运动的效率和可解释性，并通过大量仿真和实验验证了其优越性。

Abstract: Jumping poses a significant challenge for quadruped robots, despite being
crucial for many operational scenarios. While optimisation methods exist for
controlling such motions, they are often time-consuming and demand extensive
knowledge of robot and terrain parameters, making them less robust in
real-world scenarios. Reinforcement learning (RL) is emerging as a viable
alternative, yet conventional end-to-end approaches lack efficiency in terms of
sample complexity, requiring extensive training in simulations, and
predictability of the final motion, which makes it difficult to certify the
safety of the final motion. To overcome these limitations, this paper
introduces a novel guided reinforcement learning approach that leverages
physical intuition for efficient and explainable jumping, by combining B\'ezier
curves with a Uniformly Accelerated Rectilinear Motion (UARM) model. Extensive
simulation and experimental results clearly demonstrate the advantages of our
approach over existing alternatives.

</details>


### [102] [A Target-based Multi-LiDAR Multi-Camera Extrinsic Calibration System](https://arxiv.org/abs/2507.16621)
*Lorenzo Gentilini,Pierpaolo Serio,Valentina Donzella,Lorenzo Pollini*

Main category: cs.RO

TL;DR: 提出了一种针对多LiDAR和多相机传感器套件的外参标定系统，通过自定义标定板和优化方法实现高效交叉标定，测试验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中，外参标定的准确性对感知系统至关重要，现代传感器系统收集的数据类型多样，增加了数据对齐的难度。

Method: 使用自定义的ChArUco标定板和优化的非线性优化方法进行LiDAR与相机之间的交叉标定。

Result: 在真实仓库环境中采集的数据测试表明，所提方法有效。

Conclusion: 该论文提出的标定系统在多LiDAR和多相机传感器套件中表现出色，证明了针对不同类型传感器定制独特管道的可行性。

Abstract: Extrinsic Calibration represents the cornerstone of autonomous driving. Its
accuracy plays a crucial role in the perception pipeline, as any errors can
have implications for the safety of the vehicle. Modern sensor systems collect
different types of data from the environment, making it harder to align the
data. To this end, we propose a target-based extrinsic calibration system
tailored for a multi-LiDAR and multi-camera sensor suite. This system enables
cross-calibration between LiDARs and cameras with limited prior knowledge using
a custom ChArUco board and a tailored nonlinear optimization method. We test
the system with real-world data gathered in a warehouse. Results demonstrated
the effectiveness of the proposed method, highlighting the feasibility of a
unique pipeline tailored for various types of sensors.

</details>


### [103] [Morpheus: A Neural-driven Animatronic Face with Hybrid Actuation and Diverse Emotion Control](https://arxiv.org/abs/2507.16645)
*Zongzheng Zhang,Jiawen Yang,Ziqiao Peng,Meng Yang,Jianzhu Ma,Lin Cheng,Huazhe Xu,Hang Zhao,Hao Zhao*

Main category: cs.RO

TL;DR: 提出混合驱动方法和自建模网络，结合刚性驱动和肌腱驱动的优点，实现精确且高效的面部情感表达，并能从语音输入生成情感细微差别的控制信号。


<details>
  <summary>Details</summary>
Motivation: 以往的动画面部因硬件和软件限制无法有效表达情感。刚性驱动机制控制精确但设计复杂，肌腱驱动机制空间效率高但控制困难。本研究旨在结合两者的优点，设计一个既能精确控制又能高效表达情感的解决方案。

Method: 提出了一种混合驱动方法，结合刚性驱动和肌腱驱动的优点，用于控制眼睛、嘴巴、鼻子和脸颊等关键区域。算法方面，引入了一个自建模网络，通过梯度反向传播建立面部表情与电机控制信号之间的关系，并训练神经网络将语音输入映射到相应的blendshape控制。

Result: 通过混合驱动方法和自建模网络，成功生成了包括快乐、恐惧、厌恶和愤怒等多种情感表达，每种情感都具有细微差别的控制信号。硬件和代码已开源。

Conclusion: 本研究提出了一种混合驱动方法，结合了刚性驱动和肌腱驱动的优点，设计了一个紧凑且多功能的硬件平台，能够表达广泛的情感。同时，通过自建模网络和神经网络的结合，实现了从语音输入到面部表情的自动映射，生成了具有情感细微差别的控制信号。

Abstract: Previous animatronic faces struggle to express emotions effectively due to
hardware and software limitations. On the hardware side, earlier approaches
either use rigid-driven mechanisms, which provide precise control but are
difficult to design within constrained spaces, or tendon-driven mechanisms,
which are more space-efficient but challenging to control. In contrast, we
propose a hybrid actuation approach that combines the best of both worlds. The
eyes and mouth-key areas for emotional expression-are controlled using rigid
mechanisms for precise movement, while the nose and cheek, which convey subtle
facial microexpressions, are driven by strings. This design allows us to build
a compact yet versatile hardware platform capable of expressing a wide range of
emotions. On the algorithmic side, our method introduces a self-modeling
network that maps motor actions to facial landmarks, allowing us to
automatically establish the relationship between blendshape coefficients for
different facial expressions and the corresponding motor control signals
through gradient backpropagation. We then train a neural network to map speech
input to corresponding blendshape controls. With our method, we can generate
distinct emotional expressions such as happiness, fear, disgust, and anger,
from any given sentence, each with nuanced, emotion-specific control signals-a
feature that has not been demonstrated in earlier systems. We release the
hardware design and code at https://github.com/ZZongzheng0918/Morpheus-Hardware
and https://github.com/ZZongzheng0918/Morpheus-Software.

</details>


### [104] [Experience is the Best Teacher: Grounding VLMs for Robotics through Self-Generated Memory](https://arxiv.org/abs/2507.16713)
*Guowei Lan,Kaixian Qu,René Zurbrügg,Changan Chen,Christopher E. Mower,Haitham Bou-Ammar,Marco Hutter*

Main category: cs.RO

TL;DR: ExpTeach框架通过自生成经验记忆和闭环学习，显著提升视觉语言模型在机器人任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在机器人领域的应用面临从互联网数据到多样化真实机器人任务的迁移挑战。

Method: ExpTeach通过自主规划行动、验证结果、反思失败并调整机器人行为的闭环过程，构建长期记忆，并通过检索增强生成（RAG）指导未来任务，同时增强了空间理解能力。

Result: 实验表明，反思将四个挑战性机器人任务的成功率从36%提升至84%，长期记忆使12个真实场景（包括8个未见场景）的单次成功率从22%提升至80%。

Conclusion: ExpTeach框架通过构建自生成经验记忆，显著提升了视觉语言模型（VLMs）在机器人任务中的成功率和适应性，证明了其有效性和泛化能力。

Abstract: Vision-language models (VLMs) have been widely adopted in robotics to enable
autonomous planning. However, grounding VLMs, originally trained on internet
data, to diverse real-world robots remains a challenge. This paper presents
ExpTeach, a framework that grounds VLMs to physical robots by building a
self-generated memory of real-world experiences. In ExpTeach, the VLM
autonomously plans actions, verifies outcomes, reflects on failures, and adapts
robot behaviors in a closed loop. The self-generated experiences during this
process are then summarized into a long-term memory, enabling retrieval of
learned knowledge to guide future tasks via retrieval-augmented generation
(RAG). Additionally, ExpTeach enhances the spatial understanding of VLMs with
an on-demand image annotation module. In experiments, we show that reflection
improves success rates from 36% to 84% on four challenging robotic tasks and
observe the emergence of intelligent object interactions, including creative
tool use. Across extensive tests on 12 real-world scenarios (including eight
unseen ones), we find that grounding with long-term memory boosts single-trial
success rates from 22% to 80%, demonstrating the effectiveness and
generalizability of ExpTeach.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [105] [The Sweet Danger of Sugar: Debunking Representation Learning for Encrypted Traffic Classification](https://arxiv.org/abs/2507.16438)
*Yuqi Zhao,Giovanni Dettori,Matteo Boffa,Luca Vassio,Marco Mellia*

Main category: cs.NI

TL;DR: 论文批判性评估了基于语言模型的流量表示学习方法，发现其高准确性源于数据准备问题，并提出了Pcap-Encoder作为解决方案，但指出其实用性受限，呼吁更严格的评估方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于语言模型的流量表示学习方法在加密流量分类中声称高达98%的准确性，但实际性能可能被数据准备问题夸大，作者希望从网络专家角度重新评估这些模型的真实性能。

Method: 通过广泛分析，作者评估了现有模型的性能，并引入了Pcap-Encoder，一个专门设计用于从协议头提取特征的表示学习模型。

Result: 分析表明，现有模型的成功很大程度上依赖于数据准备问题导致的虚假相关性，而在真实场景中表现不佳。Pcap-Encoder是唯一能提供有效流量分类表示的模型，但其复杂性限制了实际应用。

Conclusion: 论文指出了当前基于语言模型的流量表示学习方法在数据集准备和模型训练中的缺陷，提出了更严格的评估方法，并强调了严谨基准测试的必要性。

Abstract: Recently we have witnessed the explosion of proposals that, inspired by
Language Models like BERT, exploit Representation Learning models to create
traffic representations. All of them promise astonishing performance in
encrypted traffic classification (up to 98% accuracy). In this paper, with a
networking expert mindset, we critically reassess their performance. Through
extensive analysis, we demonstrate that the reported successes are heavily
influenced by data preparation problems, which allow these models to find easy
shortcuts - spurious correlation between features and labels - during
fine-tuning that unrealistically boost their performance. When such shortcuts
are not present - as in real scenarios - these models perform poorly. We also
introduce Pcap-Encoder, an LM-based representation learning model that we
specifically design to extract features from protocol headers. Pcap-Encoder
appears to be the only model that provides an instrumental representation for
traffic classification. Yet, its complexity questions its applicability in
practical settings. Our findings reveal flaws in dataset preparation and model
training, calling for a better and more conscious test design. We propose a
correct evaluation methodology and stress the need for rigorous benchmarking.

</details>


### [106] [An Experimental Study of Split-Learning TinyML on Ultra-Low-Power Edge/IoT Nodes](https://arxiv.org/abs/2507.16594)
*Zied Jenhani,Mounir Bensalem,Jasenka Dizdarević,Admela Jukan*

Main category: cs.NI

TL;DR: 研究构建了首个TinyML + SL测试平台，比较了多种无线通信方法在边缘/IoT环境下的性能，ESP-NOW在延迟和能效上表现最优。


<details>
  <summary>Details</summary>
Motivation: 解决在超低功耗边缘/IoT节点上直接运行深度学习推理时，受限于微控制器的严格内存和计算预算的问题。

Method: 研究构建了一个基于Espressif ESP32-S3板的首个端到端TinyML + SL测试平台，用于基准测试边缘/IoT环境中分割学习TinyML的无线性能。采用MobileNetV2图像识别模型，量化至8位整数，并通过无线更新分发到节点。

Result: 在UDP/IP下，分割模型后的5.66 kB张量传输时间为3.2 ms，稳态往返延迟为5.8 s。ESP-NOW的往返时间最佳（3.7 s），BLE虽延长电池寿命但延迟超过10秒。

Conclusion: 该研究展示了在超低功耗边缘/IoT节点上实现深度学习推理的可行性，通过分割学习（SL）和多种无线通信方法的比较，ESP-NOW在延迟和能效方面表现最佳。

Abstract: Running deep learning inference directly on ultra-low-power edge/IoT nodes
has been limited by the tight memory and compute budgets of microcontrollers.
Split learning (SL) addresses this limitation in which it executes part of the
inference process on the sensor and off-loads the remainder to a companion
device. In the context of constrained devices and the related impact of
low-power, over-the-air transport protocols, the performance of split learning
remains largely unexplored. TO the best of our knowledge, this paper presents
the first end-to-end TinyML + SL testbed built on Espressif ESP32-S3 boards,
designed to benchmark the over-the-air performance of split learning TinyML in
edge/IoT environments. We benchmark the performance of a MobileNetV2 image
recognition model, which is quantized to 8-bit integers, partitioned, and
delivered to the nodes via over-the-air updates. The intermediate activations
are exchanged through different wireless communication methods: ESP-NOW, BLE,
and traditional UDP/IP and TCP/IP, enabling a head-to-head comparison on
identical hardware. Measurements show that splitting the model after
block_16_project_BN layer generates a 5.66 kB tensor that traverses the link in
3.2 ms, when UDP is used, achieving a steady-state round-trip latency of 5.8 s.
ESP-NOW presents the most favorable RTT performance 3.7 s; BLE extends battery
life further but increases latency beyond 10s.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [107] [From Reasoning to Super-Intelligence: A Search-Theoretic Perspective](https://arxiv.org/abs/2507.15865)
*Shai Shalev-Shwartz,Amnon Shashua*

Main category: cs.AI

TL;DR: Diligent Learner 是一种新的学习范式，通过深度优先搜索和回溯解决 CoT 学习中的核心障碍，为大型推理模型的开发提供了理论基础和实践路径。


<details>
  <summary>Details</summary>
Motivation: 尽管 Chain-of-Thought (CoT) 推理增强了大型语言模型（LLMs）的解决问题的能力，但现有方法（如 SFT、RL、ToT 和 MCTS）在复杂推理任务上表现不佳，且缺乏理论基础。

Method: 引入了 Diligent Learner，一种新的学习范式，将推理建模为由验证器引导的深度优先搜索，并支持失败时的回溯。

Result: 在两种温和且现实的假设下，证明 Diligent Learner 能有效从 CoT 数据中学习，而现有方法无法做到。

Conclusion: Diligent Learner 提供了一种可扩展且可靠的学习框架，能够从自然发生的不完整数据中学习，为开发具有鲁棒性和可解释性解决问题能力的大型推理模型（LRMs）铺平了道路。

Abstract: Chain-of-Thought (CoT) reasoning has emerged as a powerful tool for enhancing
the problem-solving capabilities of large language models (LLMs). However, the
theoretical foundations of learning from CoT data remain underdeveloped, and
existing approaches -- such as Supervised Fine-Tuning (SFT), Reinforcement
Learning (RL), Tree-of-Thoughts (ToT), and Monte Carlo Tree Search (MCTS) --
often fail on complex reasoning tasks. In this work, we identify core obstacles
that hinder effective CoT learning, including distribution drift, lack of
embedded search, and exponential inference costs. We introduce the Diligent
Learner, a new learning paradigm that explicitly models reasoning as a
depth-first search guided by a validator and supports backtracking upon
failure. Under two mild and realistic assumptions, we prove that the Diligent
Learner can efficiently learn from CoT data while existing methods fail to do
so. This framework offers a path toward building scalable and reliable
reasoning systems trained on naturally occurring, incomplete data -- paving the
way for the development of Large Reasoning Models (LRMs) with robust,
interpretable problem-solving abilities.

</details>


### [108] [Purchase and Production Optimization in a Meat Processing Plant](https://arxiv.org/abs/2507.15866)
*Marek Vlk,Premysl Sucha,Jaroslaw Rudy,Radoslaw Idzikowski*

Main category: cs.AI

TL;DR: 论文提出了一种基于整数线性规划的迭代方法，解决了肉类加工公司采购和材料处理的优化问题，特别处理了最小订单量和替代品最小百分比约束，并在真实数据中实现了高效求解。


<details>
  <summary>Details</summary>
Motivation: 肉类生产行业面临诸多挑战，尤其是能源危机加剧了这些问题，因此高效利用输入材料对企业的利润至关重要。本文旨在优化肉类加工公司的采购和材料处理问题，不同于大多数现有研究，本论文专注于生产阶段。

Method: 论文采用了一种基于整数线性规划的迭代方法，特别处理了材料处理中的替代方式、不同保质期的材料库存，以及现有文献中常忽略的最小订单量和替代品最小百分比约束。

Result: 研究结果表明，所设计的算法能够在几秒内为所有考虑的使用案例找到最优解，且相比商业求解器，该方法还能缓解由数据值范围广泛引起的数值问题。

Conclusion: 论文通过设计一种基于整数线性规划的简单迭代方法，成功解决了肉类加工公司在采购和材料处理中的优化问题，并且在真实数据测试中表现高效，能在几秒内找到最优解。

Abstract: The food production industry, especially the meat production sector, faces
many challenges that have even escalated due to the recent outbreak of the
energy crisis in the European Union. Therefore, efficient use of input
materials is an essential aspect affecting the profit of such companies. This
paper addresses an optimization problem concerning the purchase and subsequent
material processing we solved for a meat processing company. Unlike the
majority of existing papers, we do not concentrate on how this problem concerns
supply chain management, but we focus purely on the production stage. The
problem involves the concept of alternative ways of material processing, stock
of material with different expiration dates, and extra constraints widely
neglected in the current literature, namely, the minimum order quantity and the
minimum percentage in alternatives. We prove that each of these two constraints
makes the problem \mbox{$\mathcal{NP}$-hard}, and hence we design a simple
iterative approach based on integer linear programming that allows us to solve
real-life instances even using an open-source integer linear programming
solver. Another advantage of this approach is that it mitigates numerical
issues, caused by the extensive range of data values, we experienced with a
commercial solver. The results obtained using real data from the meat
processing company showed that our algorithm can find the optimum solution in a
few seconds for all considered use cases.

</details>


### [109] [Why Braking? Scenario Extraction and Reasoning Utilizing LLM](https://arxiv.org/abs/2507.15874)
*Yin Wu,Daniel Slieter,Vivek Subramanian,Ahmed Abouelazm,Robin Bohn,J. Marius Zöllner*

Main category: cs.AI

TL;DR: 本文提出了一种利用LLM理解和推理驾驶场景的新框架，通过双路径检索（类别搜索和嵌入检索）提升了对已知和未知场景的识别能力，实验验证了其在复杂环境中的优越性。


<details>
  <summary>Details</summary>
Motivation: 随着配备ADAS的车辆增多，驾驶数据激增，但大部分数据反映的是常规驾驶行为。从海量数据中识别和理解安全关键角落案例（如刹车事件）具有挑战性，现有基于规则的方法在复杂城市环境中泛化能力不足。

Method: 提出了一种结合LLM的场景理解和推理框架，通过自然语言描述与低层数值信号的映射，实现了对驾驶场景的解读和分类。方法包括基于类别的已知场景搜索和基于嵌入的未知场景检索。

Result: 实验结果表明，该方法在Argoverse 2传感器数据集上优于基于规则的基线方法，并能有效处理分布外（OOD）场景。

Conclusion: 本文提出的基于大型语言模型（LLM）的双路径场景检索框架在识别和分类驾驶场景方面优于传统基于规则的方法，尤其在复杂城市环境中表现出良好的泛化能力。

Abstract: The growing number of ADAS-equipped vehicles has led to a dramatic increase
in driving data, yet most of them capture routine driving behavior. Identifying
and understanding safety-critical corner cases within this vast dataset remains
a significant challenge. Braking events are particularly indicative of
potentially hazardous situations, motivating the central question of our
research: Why does a vehicle brake? Existing approaches primarily rely on
rule-based heuristics to retrieve target scenarios using predefined condition
filters. While effective in simple environments such as highways, these methods
lack generalization in complex urban settings. In this paper, we propose a
novel framework that leverages Large Language Model (LLM) for scenario
understanding and reasoning. Our method bridges the gap between low-level
numerical signals and natural language descriptions, enabling LLM to interpret
and classify driving scenarios. We propose a dual-path scenario retrieval that
supports both category-based search for known scenarios and embedding-based
retrieval for unknown Out-of-Distribution (OOD) scenarios. To facilitate
evaluation, we curate scenario annotations on the Argoverse 2 Sensor Dataset.
Experimental results show that our method outperforms rule-based baselines and
generalizes well to OOD scenarios.

</details>


### [110] [Differential Multimodal Transformers](https://arxiv.org/abs/2507.15875)
*Jerry Li,Timothy Oh,Joseph Hoang,Vardhit Veeramachaneni*

Main category: cs.AI

TL;DR: 扩展Differential Attention机制至多模态模型PaliGemma，通过微调显著减少噪声和幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型在处理多模态数据（如视觉信息）时，常因注意力机制过度关注无关上下文而引入噪声，导致幻觉问题。

Method: 通过LoRA微调PaliGemma 3B模型，并引入Differential Attention机制，实验了不同参数设置和配置。

Result: 实验证明，Differential Attention能有效减少噪声信息检索和幻觉问题。

Conclusion: Differential Attention机制可以成功整合到现有模型的微调中，显著提升了噪声信息检索和问答能力。

Abstract: Small language models have gained significant popularity due to their
efficiency and growing capabilities. However, incorporating additional
modalities, such as vision, can exacerbate the challenge of limited context
windows by introducing noise. Recent studies have highlighted that Transformer
attention mechanisms often disproportionately focus on irrelevant contexts. In
this work, we extend the Differential Attention mechanism, originally designed
for text-only models, to the text-vision model PaliGemma. Our aim is to
evaluate its ability to mitigate noisy information retrieval and reduce
hallucinations. To this end, we fine-tuned the PaliGemma 3B model using LoRA,
incorporating Differential Attention, and experimented with various parameter
settings and configurations. We demonstrate that Differential Attention can be
adapted and integrated into the fine-tuning of existing models to enhance noisy
information retrieval and question-answering capabilities.

</details>


### [111] [Re-evaluating Short- and Long-Term Trend Factors in CTA Replication: A Bayesian Graphical Approach](https://arxiv.org/abs/2507.15876)
*Eric Benhamou,Jean-Jacques Ohana,Alban Etienne,Béatrice Guez,Ethan Setrouk,Thomas Jacquot*

Main category: cs.AI

TL;DR: 本文通过贝叶斯图模型动态分解CTA收益，探讨了短期与长期趋势系统的相互作用及其对绩效的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管趋势跟踪策略已有大量研究，但短期与长期趋势系统的相对优势及相互作用仍存在争议，本文旨在通过动态分解方法增进对这一问题的理解。

Method: 采用贝叶斯图模型对CTA收益进行动态分解，区分短期趋势、长期趋势和市场贝塔因子。

Result: 研究发现，不同时间尺度趋势的组合对策略的风险调整后绩效有显著影响，为CTA策略的设计提供了实证支持。

Conclusion: 本文通过动态分解CTA收益为短期趋势、长期趋势和市场贝塔因子，揭示了不同时间尺度趋势系统的相互作用及其对风险调整后绩效的影响，为CTA策略的优化提供了新的视角。

Abstract: Commodity Trading Advisors (CTAs) have historically relied on trend-following
rules that operate on vastly different horizons from long-term breakouts that
capture major directional moves to short-term momentum signals that thrive in
fast-moving markets. Despite a large body of work on trend following, the
relative merits and interactions of short-versus long-term trend systems remain
controversial. This paper adds to the debate by (i) dynamically decomposing CTA
returns into short-term trend, long-term trend and market beta factors using a
Bayesian graphical model, and (ii) showing how the blend of horizons shapes the
strategy's risk-adjusted performance.

</details>


### [112] [Out-of-Distribution Generalization in the ARC-AGI Domain: Comparing Execution-Guided Neural Program Synthesis and Test-Time Fine-Tuning](https://arxiv.org/abs/2507.15877)
*Simon Ouellette*

Main category: cs.AI

TL;DR: 在ARC-AGI实验中，神经程序合成在组合泛化上优于TTFT，后者依赖激发LLM的分布内知识。


<details>
  <summary>Details</summary>
Motivation: 探索在开放世界问题域中，泛化分布外能力对成功的关键作用。

Method: 在ARC-AGI领域进行控制性组合泛化实验，比较神经程序合成和测试时微调方法。

Result: 执行引导的神经程序合成表现最佳，TTFT则主要通过激发分布内知识实现成功。

Conclusion: 执行引导的神经程序合成在组合新解决方案方面优于所有参考算法，而TTFT的成功主要在于激发LLM内部未能直接依赖的分布内知识。

Abstract: We run a controlled compositional generalization experiment in the ARC-AGI
domain: an open-world problem domain in which the ability to generalize
out-of-distribution is, by design, an essential characteristic for success. We
compare neural program synthesis and test-time fine-tuning approaches on this
experiment. We find that execution-guided neural program synthesis outperforms
all reference algorithms in its ability to compose novel solutions. Our
empirical findings also suggest that the success of TTFT on ARC-AGI lies mainly
in eliciting in-distribution knowledge that the LLM otherwise fails to rely on
directly.

</details>


### [113] [The Recursive Coherence Principle: A Formal Constraint on Scalable Intelligence, Alignment, and Reasoning Architecture](https://arxiv.org/abs/2507.15880)
*Andy E. Williams*

Main category: cs.AI

TL;DR: 论文提出递归一致性原则（RCP）和功能性智能模型（FMI），证明FMI是唯一满足RCP的算子，为AI对齐和可扩展性提供新思路。


<details>
  <summary>Details</summary>
Motivation: 探讨复杂智能系统在扩展时如何保持语义一致性，解决AI常见的错位、幻觉和不稳定性问题。

Method: 通过形式化定义FMI，分析其内部和外部功能，并证明缺乏FMI的系统会在扩展时出现递归一致性崩溃。

Result: 证明了FMI作为满足RCP的唯一算子，为AI对齐和可扩展性提供了理论基础。

Conclusion: 本研究提出了递归一致性原则（RCP）和功能性智能模型（FMI），证明了FMI是唯一能满足RCP的算子，为AI对齐和可扩展性提供了新视角。

Abstract: Intelligence-biological, artificial, or collective-requires structural
coherence across recursive reasoning processes to scale effectively. As complex
systems grow, coherence becomes fragile unless a higher-order structure ensures
semantic consistency. This paper introduces the Recursive Coherence Principle
(RCP): a foundational constraint stating that for any reasoning system of order
N, composed of systems operating over conceptual spaces of order N-1, semantic
coherence is preserved only by a recursively evaluable generalization operator
that spans and aligns those lower-order conceptual spaces. Crucially, this
coherence enables structural alignment. Without recursive coherence, no system
can reliably preserve goals, meanings, or reasoning consistency at scale. We
formally define the Functional Model of Intelligence (FMI) as the only known
operator capable of satisfying the RCP at any scale. The FMI is a minimal,
composable architecture with internal functions (evaluation, modeling,
adaptation, stability, decomposition, bridging) and external functions
(storage, recall, System 1 and System 2 reasoning) vital for preserving
semantic structure across inference and coordination layers. We prove that any
system lacking the FMI will experience recursive coherence breakdown as it
scales, arguing that common AI issues like misalignment, hallucination, and
instability are symptoms of this structural coherence loss. Unlike other
foundational principles, RCP uniquely captures the internal, recursive dynamics
needed for coherent, alignable intelligence, modeling semantic coherence under
recursion. This work significantly impacts AI alignment, advocating a shift
from behavioral constraints to structural coherence, and offers a pathway for
safely generalizable, robustly coherent AI at scale.

</details>


### [114] [ADEPTS: A Capability Framework for Human-Centered Agent Design](https://arxiv.org/abs/2507.15885)
*Pierluca D'Oro,Caley Drooff,Joy Chen,Joseph Tighe*

Main category: cs.AI

TL;DR: ADEPTS是一个AI代理能力框架，基于六大人本中心设计原则，旨在提供统一的开发指导，加速用户相关能力提升，并建立共享语言。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一个简洁、用户面向的词汇表来指导团队开发AI代理，现有指南分散且不统一。

Method: 基于六大人本中心设计原则，提出ADEPTS框架，定义AI代理应具备的最小用户面向能力，以确保其可理解、可控和可信。

Result: ADEPTS框架填补了现有框架和分类法的空白，为AI研究人员、设计师、工程师和政策审查者提供了可操作的指导。

Conclusion: ADEPTS框架旨在通过定义一组核心用户面向能力，为AI代理的开发提供统一指导，加速用户相关能力的提升，并提供一个共享语言来跟踪和讨论AI代理开发的进展。

Abstract: Large language models have paved the way to powerful and flexible AI agents,
assisting humans by increasingly integrating into their daily life. This
flexibility, potential, and growing adoption demands a holistic and
cross-disciplinary approach to developing, monitoring and discussing the
capabilities required for agent-driven user experiences. However, current
guidance on human-centered AI agent development is scattered: UX heuristics
focus on interface behaviors, engineering taxonomies describe internal
pipelines, and ethics checklists address high-level governance. There is no
concise, user-facing vocabulary that tells teams what an agent should
fundamentally be able to do. We introduce ADEPTS, a capability framework
defining a set of core user-facing capabilities to provide unified guidance
around the development of AI agents. ADEPTS is based on six principles for
human-centered agent design, that express the minimal, user-facing capabilities
an AI agent should demonstrate to be understandable, controllable and
trustworthy in everyday use. ADEPTS complements existing frameworks and
taxonomies; differently from them, it sits at the interface between technical
and experience development. By presenting ADEPTS, we aim to condense complex
AI-UX requirements into a compact framework that is actionable guidance for AI
researchers, designers, engineers, and policy reviewers alike. We believe
ADEPTS has the potential of accelerating the improvement of user-relevant agent
capabilities, of easing the design of experiences that take advantage of those
capabilities, and of providing a shared language to track and discuss progress
around the development of AI agents.

</details>


### [115] [Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture](https://arxiv.org/abs/2507.15895)
*Lisa Dargasz*

Main category: cs.AI

TL;DR: 研究提出了一种基于原因的智能道德代理（RBAMA）架构，扩展强化学习以实现道德决策，初步实验验证其潜力，为开发伦理自主代理提供了可行框架。


<details>
  <summary>Details</summary>
Motivation: 随着自主代理（如人形机器人或自动驾驶汽车）从实验室原型过渡到现实环境，设计符合伦理行为的系统成为关键需求。研究旨在通过开发RBAMAs，解决计算机科学与哲学交叉领域的挑战。

Method: 研究扩展了强化学习架构，赋予代理学习原因理论的能力，使其能够处理道德相关命题并推导道德义务。代理通过案例反馈调整行为以确保符合这些义务。

Result: RBAMAs通过原因理论实现道德决策，增强了其行为的道德可辩护性、道德稳健性和道德可信度。初步实验验证了该架构的潜力。

Conclusion: 该研究提出了基于原因的智能道德代理（RBAMA）的扩展强化学习架构，并通过初步实验展示了其潜力，为开发符合关键伦理要求的AMAs提供了具体且可部署的框架。

Abstract: Reinforcement Learning is a machine learning methodology that has
demonstrated strong performance across a variety of tasks. In particular, it
plays a central role in the development of artificial autonomous agents. As
these agents become increasingly capable, market readiness is rapidly
approaching, which means those agents, for example taking the form of humanoid
robots or autonomous cars, are poised to transition from laboratory prototypes
to autonomous operation in real-world environments. This transition raises
concerns leading to specific requirements for these systems - among them, the
requirement that they are designed to behave ethically. Crucially, research
directed toward building agents that fulfill the requirement to behave
ethically - referred to as artificial moral agents(AMAs) - has to address a
range of challenges at the intersection of computer science and philosophy.
This study explores the development of reason-based artificial moral agents
(RBAMAs). RBAMAs are build on an extension of the reinforcement learning
architecture to enable moral decision-making based on sound normative
reasoning, which is achieved by equipping the agent with the capacity to learn
a reason-theory - a theory which enables it to process morally relevant
propositions to derive moral obligations - through case-based feedback. They
are designed such that they adapt their behavior to ensure conformance to these
obligations while they pursue their designated tasks. These features contribute
to the moral justifiability of the their actions, their moral robustness, and
their moral trustworthiness, which proposes the extended architecture as a
concrete and deployable framework for the development of AMAs that fulfills key
ethical desiderata. This study presents a first implementation of an RBAMA and
demonstrates the potential of RBAMAs in initial experiments.

</details>


### [116] [Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation](https://arxiv.org/abs/2507.15901)
*Joydeep Chandra,Satyam Kumar Navneet*

Main category: cs.AI

TL;DR: 本文探讨了家庭自动化中代理AI的伦理挑战，提出了透明、包容的设计建议，特别关注弱势群体的需求。


<details>
  <summary>Details</summary>
Motivation: 探讨代理AI在家庭环境中的应用，从反应性到主动性的转变，隐私、公平和用户控制等问题。

Method: 回顾了负责任创新框架、以人为中心的设计原则和治理实践，提炼出伦理智能家居系统的实用指导。

Result: 详细研究了弱势用户群体（如老年人、儿童和神经多样性人群）在代理AI背景下面临的更高风险，并提出了设计要点，如定制化解释性、细粒度同意机制和强大的覆盖控制。

Conclusion: 本文为开发透明、包容且可信赖的家庭自动化代理AI提供了概念基础和建议。

Abstract: The implementation of Artificial Intelligence (AI) in household environments,
especially in the form of proactive autonomous agents, brings about
possibilities of comfort and attention as well as it comes with intra or
extramural ethical challenges. This article analyzes agentic AI and its
applications, focusing on its move from reactive to proactive autonomy,
privacy, fairness and user control. We review responsible innovation
frameworks, human-centered design principles, and governance practices to
distill practical guidance for ethical smart home systems. Vulnerable user
groups such as elderly individuals, children, and neurodivergent who face
higher risks of surveillance, bias, and privacy risks were studied in detail in
context of Agentic AI. Design imperatives are highlighted such as tailored
explainability, granular consent mechanisms, and robust override controls,
supported by participatory and inclusive methodologies. It was also explored
how data-driven insights, including social media analysis via Natural Language
Processing(NLP), can inform specific user needs and ethical concerns. This
survey aims to provide both a conceptual foundation and suggestions for
developing transparent, inclusive, and trustworthy agentic AI in household
automation.

</details>


### [117] [Does More Inference-Time Compute Really Help Robustness?](https://arxiv.org/abs/2507.15974)
*Tong Wu,Chong Xiang,Jiachen T. Wang,Weichen Yu,Chawin Sitawarin,Vikash Sehwag,Prateek Mittal*

Main category: cs.AI

TL;DR: 论文展示了开源模型也能通过推理时间扩展受益，但揭示了中间推理步骤暴露会降低模型鲁棒性的安全风险，并讨论了实际应用中的潜在漏洞。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于揭示并批判性地检验先前工作中的隐含假设，即中间推理步骤对攻击者是隐藏的，并通过放松这一假设来识别重要的安全风险。

Method: 论文采用了一种简单的预算强制策略来展示开源模型在推理时间扩展中的益处，并通过放松先前工作中的隐含假设来识别安全风险。

Result: 研究结果表明，如果中间推理步骤变得明确可访问，增加的推理时间计算会持续降低模型的鲁棒性。此外，论文还讨论了实际场景中隐藏推理链的模型仍然容易受到攻击的情况。

Conclusion: 论文结论强调了在安全敏感的实际应用中，应用推理时间扩展时需要仔细权衡其微妙的权衡。

Abstract: Recently, Zaremba et al. demonstrated that increasing inference-time
computation improves robustness in large proprietary reasoning LLMs. In this
paper, we first show that smaller-scale, open-source models (e.g., DeepSeek R1,
Qwen3, Phi-reasoning) can also benefit from inference-time scaling using a
simple budget forcing strategy. More importantly, we reveal and critically
examine an implicit assumption in prior work: intermediate reasoning steps are
hidden from adversaries. By relaxing this assumption, we identify an important
security risk, intuitively motivated and empirically verified as an inverse
scaling law: if intermediate reasoning steps become explicitly accessible,
increased inference-time computation consistently reduces model robustness.
Finally, we discuss practical scenarios where models with hidden reasoning
chains are still vulnerable to attacks, such as models with tool-integrated
reasoning and advanced reasoning extraction attacks. Our findings collectively
demonstrate that the robustness benefits of inference-time scaling depend
heavily on the adversarial setting and deployment context. We urge
practitioners to carefully weigh these subtle trade-offs before applying
inference-time scaling in security-sensitive, real-world applications.

</details>


### [118] [Micromobility Flow Prediction: A Bike Sharing Station-level Study via Multi-level Spatial-Temporal Attention Neural Network](https://arxiv.org/abs/2507.16020)
*Xi Yang,Jiachen Wang,Song Han,Suining He*

Main category: cs.AI

TL;DR: BikeMAN是一种多级时空注意力神经网络，用于预测整个共享单车系统的站点级交通流量，实验证明其在纽约市数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 共享单车系统由于站点级供需不平衡导致维护困难，而现有研究在预测整个系统的站点级交通流量时面临时空复杂性和站点数量多的挑战。

Method: 提出了BikeMAN，一个包含编码器和解码器的多级时空注意力神经网络，其中编码器和解码器分别通过注意力机制捕捉站点间的空间相关性和交通流量的时间特征。

Result: 在纽约市超过1000万次骑行数据（覆盖700多个站点）的实验表明，BikeMAN能够高精度预测所有站点的交通流量。

Conclusion: BikeMAN通过多级时空注意力神经网络有效预测了整个共享单车系统的站点级交通流量，实验证明其在纽约市700多个站点上的预测准确性很高。

Abstract: Efficient use of urban micromobility resources such as bike sharing is
challenging due to the unbalanced station-level demand and supply, which causes
the maintenance of the bike sharing systems painstaking. Prior efforts have
been made on accurate prediction of bike traffics, i.e., demand/pick-up and
return/drop-off, to achieve system efficiency. However, bike station-level
traffic prediction is difficult because of the spatial-temporal complexity of
bike sharing systems. Moreover, such level of prediction over entire bike
sharing systems is also challenging due to the large number of bike stations.
To fill this gap, we propose BikeMAN, a multi-level spatio-temporal attention
neural network to predict station-level bike traffic for entire bike sharing
systems. The proposed network consists of an encoder and a decoder with an
attention mechanism representing the spatial correlation between features of
bike stations in the system and another attention mechanism describing the
temporal characteristic of bike station traffic. Through experimental study on
over 10 millions trips of bike sharing systems (> 700 stations) of New York
City, our network showed high accuracy in predicting the bike station traffic
of all stations in the city.

</details>


### [119] [From Logic to Language: A Trust Index for Problem Solving with LLMs](https://arxiv.org/abs/2507.16028)
*Tehseen Rug,Felix Böhmer,Tessa Pfattheicher*

Main category: cs.AI

TL;DR: 论文提出了一种统一框架，对比形式语言和自然语言问题解决范式，引入向量信任指数Q和统计质量维度，以更严谨地理解LLMs的能力与局限性。


<details>
  <summary>Details</summary>
Motivation: 传统计算范式难以处理具有模糊性、动态环境和主观语境的人类问题，而LLMs的出现为这一领域带来了新的可能性。本文旨在对比这两种问题解决范式，并提供一个更严谨的理解框架。

Method: 论文提出了一个统一框架，定义了形式语言和自然语言可解决的问题空间，并引入了向量值信任指数Q。此外，还提出了两个统计质量维度：归一化双语义熵和情感效价映射。

Result: 通过提出的框架和统计质量维度，论文区分了形式语言和自然语言解决方案的评价标准，并展示了LLMs在模糊问题上的潜力。

Conclusion: 本文提出了一个统一框架来理解和对比基于形式语言和自然语言的问题解决范式，并引入了向量值信任指数Q来衡量解决方案质量。这一框架为理解LLMs的能力、局限性和本质提供了更严谨的基础。

Abstract: Classical computation, grounded in formal, logical systems, has been the
engine of technological progress for decades, excelling at problems that can be
described with unambiguous rules. This paradigm, however, leaves a vast ocean
of human problems -- those characterized by ambiguity, dynamic environments,
and subjective context -- largely untouched. The advent of Large Language
Models (LLMs) represents a fundamental shift, enabling computational systems to
engage with this previously inaccessible domain using natural language. This
paper introduces a unified framework to understand and contrast these
problem-solving paradigms. We define and delineate the problem spaces
addressable by formal languages versus natural language. While solutions to the
former problem class can be evaluated using binary quality measures, the latter
requires a much more nuanced definition of approximate solution space taking
into account the vagueness, subjectivity and ambiguity inherent to natural
language. We therefore introduce a vector-valued trust index Q, which reflects
solution quality and distinguishes the binary correctness of formal solutions
from the continuous adequacy spectrum characteristic of natural language
solutions. Within this framework, we propose two statistical quality
dimensions. Normalized bi-semantic entropy measures robustness and conceptual
diversity of LLM answers given semantic variation in problem formulations.
Emotional valence maps subjective valuation of a solution to a quantifiable
metric that can be maximized by invoking statistical measures. The concepts
introduced in this work will provide a more rigorous understanding of the
capabilities, limitations, and inherent nature of problem-solving in the age of
LLMs.

</details>


### [120] [A Unifying Framework for Semiring-Based Constraint Logic Programming With Negation (full version)](https://arxiv.org/abs/2507.16067)
*Jeroen Spaans,Jesse Heyninck*

Main category: cs.AI

TL;DR: 本文扩展了约束逻辑编程（CLP），允许子句体中的否定，并通过近似不动点理论提供语义，统一了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的CLP扩展未研究子句体中允许否定的情况，本文旨在填补这一空白并统一现有扩展。

Method: 采用近似不动点理论框架，分析了半环性质对语义的影响。

Result: 提出了一个统一框架，能够捕获现有方法并扩展更具表达力的语言。

Conclusion: 本文提出了一个统一的框架，扩展了约束逻辑编程（CLP），允许在子句体中使用否定，并通过近似不动点理论为其提供语义。

Abstract: Constraint Logic Programming (CLP) is a logic programming formalism used to
solve problems requiring the consideration of constraints, like resource
allocation and automated planning and scheduling. It has previously been
extended in various directions, for example to support fuzzy constraint
satisfaction, uncertainty, or negation, with different notions of semiring
being used as a unifying abstraction for these generalizations. None of these
extensions have studied clauses with negation allowed in the body. We
investigate an extension of CLP which unifies many of these extensions and
allows negation in the body. We provide semantics for such programs, using the
framework of approximation fixpoint theory, and give a detailed overview of the
impacts of properties of the semirings on the resulting semantics. As such, we
provide a unifying framework that captures existing approaches and allows
extending them with a more expressive language.

</details>


### [121] [Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization](https://arxiv.org/abs/2507.16110)
*Shengchao Liu,Hannan Xu,Yan Ai,Huanxin Li,Yoshua Bengio,Harry Guo*

Main category: cs.AI

TL;DR: ChatBattery是一个整合领域知识的LLM框架，成功发现三种高性能锂离子电池阴极材料，展示了AI在材料发现中的潜力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理能力主要在解决数学和编码问题中展示，其在特定领域应用（如电池发现）的潜力尚未充分探索。

Method: 引入ChatBattery，一个新型代理框架，整合领域知识以引导LLM在材料设计中更有效地推理。

Result: 成功识别、合成并表征了三种新型锂离子电池阴极材料，其实际容量分别比广泛使用的NMC811提高了28.8%、25.2%和18.5%。

Conclusion: ChatBattery展示了AI驱动推理在材料发现中的变革潜力，为电池材料发明提供了一个成功的LLM驱动和基于推理的平台。

Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to
tackle complex problems, representing a transformative breakthrough in
artificial intelligence (AI). However, their reasoning capabilities have
primarily been demonstrated in solving math and coding problems, leaving their
potential for domain-specific applications-such as battery discovery-largely
unexplored. Inspired by the idea that reasoning mirrors a form of guided
search, we introduce ChatBattery, a novel agentic framework that integrates
domain knowledge to steer LLMs toward more effective reasoning in materials
design. Using ChatBattery, we successfully identify, synthesize, and
characterize three novel lithium-ion battery cathode materials, which achieve
practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over
the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this
discovery, ChatBattery paves a new path by showing a successful LLM-driven and
reasoning-based platform for battery materials invention. This complete
AI-driven cycle-from design to synthesis to characterization-demonstrates the
transformative potential of AI-driven reasoning in revolutionizing materials
discovery.

</details>


### [122] [TaxCalcBench: Evaluating Frontier Models on the Tax Calculation Task](https://arxiv.org/abs/2507.16126)
*Michael R. Bock,Kara Molisee,Zachary Ozer,Sumit Shah*

Main category: cs.AI

TL;DR: TaxCalcBench基准评估显示，AI在计算联邦所得税申报时表现不佳，错误率高，需更多基础设施支持。


<details>
  <summary>Details</summary>
Motivation: 计算美国个人所得税需要理解大量英文文本并精确计算，当前AI在此任务上的能力尚不明确。

Method: 提出了TaxCalcBench基准，用于评估模型在给定所有必要信息后计算个人所得税申报的能力。

Result: 实验显示，模型在税务计算中常误用税率表、计算错误及错误判定资格。

Conclusion: 当前最先进的模型在简化样本集上仅能成功计算不到三分之一的联邦所得税申报，表明AI在税务计算任务中仍需更多基础设施支持。

Abstract: Can AI file your taxes? Not yet. Calculating US personal income taxes is a
task that requires building an understanding of vast amounts of English text
and using that knowledge to carefully compute results. We propose TaxCalcBench,
a benchmark for determining models' abilities to calculate personal income tax
returns given all of the necessary information. Our experiment shows that
state-of-the-art models succeed in calculating less than a third of federal
income tax returns even on this simplified sample set. Our analysis concludes
that models consistently misuse tax tables, make errors in tax calculation, and
incorrectly determine eligibility. Our findings point to the need for
additional infrastructure to apply LLMs to the personal income tax calculation
task.

</details>


### [123] [Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery](https://arxiv.org/abs/2507.16229)
*Bo Wen,Chen Wang,Qiwei Han,Raquel Norel,Julia Liu,Thaddeus Stappenbeck,Jeffrey L. Rogers*

Main category: cs.AI

TL;DR: 语音AI代理在医疗保健中可提高可及性和效率，试点研究显示患者接受度高，且成本效益显著。


<details>
  <summary>Details</summary>
Motivation: 探索语音AI代理在增强预防性护理和持续患者监测中的作用，特别是在服务不足的人群中，以解决数字医疗服务的经济和可及性差距。

Method: 本文通过开发和试点研究Agent PULSE（患者理解与联络支持引擎），结合IBM Research、克利夫兰诊所基金会和莫尔豪斯医学院的合作，提出了一个经济模型，展示AI代理如何在人力干预经济不可行的情况下提供经济高效的医疗服务。

Result: 试点研究显示，33名炎症性肠病患者中70%接受AI驱动的监测，37%更倾向于AI而非传统方式。成本效用分析显示，AI代理在常规监测任务中具有巨大的潜在节省。

Conclusion: 语音AI代理在医疗保健领域的整合为弥合数字医疗服务的经济和可及性差距提供了变革性机会。通过解决当前的技术限制并与伦理和监管框架保持一致，语音AI代理可以成为实现公平、可持续数字医疗解决方案的关键入口。

Abstract: The integration of voice-based AI agents in healthcare presents a
transformative opportunity to bridge economic and accessibility gaps in digital
health delivery. This paper explores the role of large language model
(LLM)-powered voice assistants in enhancing preventive care and continuous
patient monitoring, particularly in underserved populations. Drawing insights
from the development and pilot study of Agent PULSE (Patient Understanding and
Liaison Support Engine) -- a collaborative initiative between IBM Research,
Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an
economic model demonstrating how AI agents can provide cost-effective
healthcare services where human intervention is economically unfeasible. Our
pilot study with 33 inflammatory bowel disease patients revealed that 70\%
expressed acceptance of AI-driven monitoring, with 37\% preferring it over
traditional modalities. Technical challenges, including real-time
conversational AI processing, integration with healthcare systems, and privacy
compliance, are analyzed alongside policy considerations surrounding
regulation, bias mitigation, and patient autonomy. Our findings suggest that
AI-driven voice agents not only enhance healthcare scalability and efficiency
but also improve patient engagement and accessibility. For healthcare
executives, our cost-utility analysis demonstrates huge potential savings for
routine monitoring tasks, while technologists can leverage our framework to
prioritize improvements yielding the highest patient impact. By addressing
current limitations and aligning AI development with ethical and regulatory
frameworks, voice-based AI agents can serve as a critical entry point for
equitable, sustainable digital healthcare solutions.

</details>


### [124] [SpiroLLM: Finetuning Pretrained LLMs to Understand Spirogram Time Series with Clinical Validation in COPD Reporting](https://arxiv.org/abs/2507.16145)
*Shuhao Mei,Yongchao Long,Shan Cao,Xiaobo Han,Shijia Geng,Jinbo Sun,Yuxi Zhou,Shenda Hong*

Main category: cs.AI

TL;DR: SpiroLLM是首个能理解呼吸图的多模态大型语言模型，通过融合呼吸曲线与PFT数值，显著提升了COPD诊断的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前大多数AI模型仅输出COPD分类结果而不提供诊断过程的理由，而现有大型语言模型无法理解呼吸图，这严重限制了临床信任和采用。

Method: 研究利用UK Biobank（UKB）的234,028名个体队列，提出了首个能理解呼吸图的多模态大型语言模型SpiroLLM。该模型通过SpiroEncoder从呼吸曲线中提取形态特征，并使用SpiroProjector将它们与PFT数值在统一潜在空间中对齐，最终赋能大型语言模型生成全面的诊断报告。

Result: 实验证实SpiroLLM的诊断AUROC为0.8980（95% CI: 0.8820-0.9132）。在核心数据缺失的鲁棒性测试中，其保持了100%的有效响应率，远超文本模型的13.4%。

Conclusion: 该研究展示了将生理信号与大型语言模型深度融合的巨大潜力，为下一代可解释且可靠的临床决策支持工具建立了新范式。

Abstract: Chronic Obstructive Pulmonary Disease (COPD), a major chronic respiratory
disease with persistent airflow limitation, is a leading global cause of
disability and mortality. Respiratory spirogram time series, routinely
collected during pulmonary function tests (PFTs), play a critical role in the
early detection of repsiratory diseases and in monitoring lung function over
time. However, most current AI models for COPD diagnosis are limited to
outputting classification results without providing a rationale for their
diagnostic process, while current Large Language Models (LLMs) cannot
understand spirograms yet, which severely limits their clinical trust and
adoption. To tackle this challenge, we leverage a cohort of 234,028 individuals
from the UK Biobank (UKB) to propose SpiroLLM, the first multimodal large
language model that can understand spirogram. The model extracts morphological
features from respiratory curves via a SpiroEncoder and aligns them with PFT
numerical values in a unified latent space using a SpiroProjector, ultimately
empowering a large language model to generate a comprehensive diagnostic
report. Experimental results confirm that SpiroLLM achieved a diagnostic AUROC
of 0.8980 (95% CI: 0.8820-0.9132). In a robustness test with missing core data,
it maintained a 100% valid response rate, far surpassing the 13.4% of a
text-only model and showcasing the superiority of its multimodal design. This
work demonstrates the substantial potential of deeply fusing physiological
signals with large language models, establishing a new paradigm for the next
generation of interpretable and reliable clinical decision support tools.

</details>


### [125] [LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning](https://arxiv.org/abs/2507.16395)
*Bo Hou,Xin Tan,Kai Zheng,Fang Liu,Yinghao Zhu,Li Zhang*

Main category: cs.AI

TL;DR: ColaUntangle利用LLM驱动的多智能体框架，通过显式和隐式依赖分析，显著提升提交解缠效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有提交解缠方法依赖浅层信号、无法区分显式和隐式依赖的问题，提升代码审查和维护效率。

Method: ColaUntangle采用多智能体架构，结合显式和隐式依赖分析，通过多版本程序依赖图（delta-PDG）进行深度推理。

Result: 在C#和Java数据集上，ColaUntangle分别比最佳基线提升了44%和100%。

Conclusion: ColaUntangle通过多智能体协作框架显著提升了提交解缠任务的性能，展示了基于LLM的协作框架在自动化代码维护任务中的潜力。

Abstract: Atomic commits, each of which addresses a single development concern, are a
best practice in software development. However, developers frequently produce
tangled commits that mix unrelated changes due to practical constraints or
unclear boundaries, negatively impacting code review and maintenance. Although
prior commit untangling approaches: rule-based, feature-based, or graph-based,
have made progress, they often rely on shallow signals and fail to distinguish
between explicit dependencies (e.g., control/data flow) and implicit ones
(e.g., semantic or conceptual relationships). In this paper, we propose
ColaUntangle, a new collaborative consultation framework for commit untangling
that models both explicit and implicit dependencies among code changes.
ColaUntangle integrates Large Language Model (LLM)-driven agents in a
multi-agent architecture: one agent specializes in explicit dependencies,
another in implicit ones, and a reviewer agent synthesizes their perspectives
through iterative consultation. To capture explicit and implicit contextual
information, we construct multi-version Program Dependency Graphs (delta-PDG),
enabling agents to reason over code relationships with both symbolic and
semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C#
and 14k Java tangled commits). Experimental results show that ColaUntangle
outperforms the best-performing baseline, achieving an improvement of 44% on
the C# dataset and 100% on the Java dataset. These findings highlight the
potential of LLM-based collaborative frameworks for advancing automated commit
untangling tasks.

</details>


### [126] [Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)](https://arxiv.org/abs/2507.16184)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: 研究发现Agentic Flow架构意外地与四种心智理论结构一致，实验显示其性能优于基线LLM代理，提出了PEACE作为描述性元架构。


<details>
  <summary>Details</summary>
Motivation: 旨在解决大型语言模型（LLMs）的局限性，并探索理论结构如何通过实际设计选择而非自上而下的理论自然浮现。

Method: 设计了Agentic Flow，一个由五个相互依赖模块（检索、认知、控制、记忆和行动）组成的循环认知架构，并与基线LLM代理在多步推理任务上进行了对比实验。

Result: 结构化代理在任务成功率上达到95.8%，显著优于基线系统的62.3%，同时表现出较强的约束遵守能力。

Conclusion: 本文提出了PEACE作为一种描述性元架构，旨在捕捉Agentic Flow中观察到的设计层面规律性，而非作为一种新理论。它提供了一个共享词汇来理解由实际实现需求塑造的架构。

Abstract: We report the discovery of a structural convergence across four influential
theories of mind: Kahneman's dual-system theory, Friston's predictive
processing, Minsky's society of mind, and Clark's extended mind-emerging
unintentionally within a practical AI agent architecture called Agentic Flow.
Designed to address limitations in large language models (LLMs), Agentic Flow
comprises five interdependent modules such as Retrieval, Cognition, Control,
Memory, and Action arranged in a recurrent cognitive loop. Although originally
inspired only by Minsky and Clark, the system's structure retrospectively
aligns with computational motifs found in all four theories, including
predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with
baseline LLM agents on multi-step reasoning tasks. The structured agent
achieved 95.8% task success and exhibited strong constraint adherence, while
the baseline system succeeded 62.3% of the time. These results were not aimed
at proving superiority, but at illustrating how theoretical structures may
emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures
design-level regularities observed in Agentic Flow. Not intended as a new
theory, PEACE provides a shared vocabulary for understanding architectures
shaped by real-world implementation demands. This paper should be read as a
position paper - an exploratory reflection on how implementation can surface
latent structural echoes of cognitive theory, without asserting theoretical
unification.

</details>


### [127] [ACT: Bridging the Gap in Code Translation through Synthetic Data Generation & Adaptive Training](https://arxiv.org/abs/2507.16478)
*Shreya Saxena,Siva Prasad,Zishan Ahmad,Vishal Vaddina*

Main category: cs.AI

TL;DR: ACT框架通过内部微调开源LLM和自动化数据生成，提升了代码翻译的灵活性和性能，为开发者提供了安全高效的工具。


<details>
  <summary>Details</summary>
Motivation: 传统自动化翻译方法依赖手工转换规则，缺乏灵活性和可扩展性；而先进的语言模型受限于专有API实现，存在数据安全和依赖性问题。因此，需要一种既能利用开源模型又能保证高性能的解决方案。

Method: ACT框架包含合成数据生成模块、评估框架和控制器模块，通过动态调整超参数和迭代数据生成与微调来优化整个流程。

Result: ACT显著提升了开源模型的性能，缩小了与闭源解决方案的差距，并在行业级项目中实现了开发加速。

Conclusion: ACT框架通过内部微调开源大语言模型，显著提升了代码翻译能力，为企业和开发者提供了安全可靠的替代方案。其数据生成管道在行业级迁移项目中的应用进一步加速了开发进程。

Abstract: Code translation is a crucial process in software development and migration
projects, enabling interoperability between different programming languages and
enhancing software adaptability and thus longevity. Traditional automated
translation methods rely heavily on handcrafted transformation rules, which
often lack flexibility and scalability. Meanwhile, advanced language models
present promising alternatives but are often limited by proprietary, API-based
implementations that raise concerns over data security and reliance. In this
paper, we present Auto-Train for Code Translation (ACT), an innovative
framework that aims to improve code translation capabilities by enabling
in-house finetuning of open-source Large Language Models (LLMs). ACT's
automated pipeline significantly boosts the performance of these models,
narrowing the gap between open-source accessibility and the high performance of
closed-source solutions. Central to ACT is its synthetic data generation
module, which builds extensive, high-quality datasets from initial code
samples, incorporating unit tests to ensure functional accuracy and diversity.
ACT's evaluation framework incorporates execution-level checks, offering a
comprehensive assessment of translation quality. A key feature in ACT is its
controller module, which manages the entire pipeline by dynamically adjusting
hyperparameters, orchestrating iterative data generation, and finetuning based
on real-time evaluations. This enables ACT to intelligently optimize when to
continue training, generate additional targeted training data, or stop the
process. Our results demonstrate that ACT consistently enhances the
effectiveness of open-source models, offering businesses and developers a
secure and reliable alternative. Additionally, applying our data generation
pipeline to industry-scale migration projects has led to a notable increase in
developer acceleration.

</details>


### [128] [CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks](https://arxiv.org/abs/2507.16204)
*Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: cs.AI

TL;DR: 提出了一种基于多功能可重构智能表面（MF-RIS）的空间-空中-地面一体化网络（SAGIN）架构，通过CHIMERA框架优化能效，显著优于传统方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决低地球轨道（LEO）卫星在阴影区域运行时能量短缺的问题，同时考虑SAGIN节点间的通信和计算能耗。

Method: 为了解决高度非凸和非线性问题，提出了压缩混合智能双模型增强多智能体深度强化学习（CHIMERA）框架，集成了语义状态-动作压缩和混合强化学习下的参数共享。

Result: 仿真结果表明，提出的CHIMERA方案在能效方面显著优于传统基准，包括固定配置或无能量收集的MF-RIS、传统RIS和无RIS情况，以及集中式和多智能体深度强化学习基线。

Conclusion: 提出的SAGIN-MF-RIS架构通过互补覆盖实现了卓越的能效性能，显著优于独立的卫星、空中或地面部署方案。

Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed,
empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS)
capable of simultaneously reflecting, amplifying, and harvesting wireless
energy. The MF-RIS plays a pivotal role in addressing the energy shortages of
low-Earth orbit (LEO) satellites operating in shadowed regions, while
explicitly accounting for both communication and computing energy consumption
across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we
formulate a joint optimization problem over the MF-RIS parameters, including
signal amplification, phase-shifts, energy harvesting ratio, and active element
selection as well as the SAGIN parameters of beamforming vectors, high-altitude
platform station (HAPS) deployment, user association, and computing capability.
The formulated problem is highly non-convex and non-linear and contains mixed
discrete-continuous parameters. To tackle this, we conceive a compressed hybrid
intelligence for twin-model enhanced multi-agent deep reinforcement learning
(CHIMERA) framework, which integrates semantic state-action compression and
parametrized sharing under hybrid reinforcement learning to efficiently explore
suitable complex actions. The simulation results have demonstrated that the
proposed CHIMERA scheme substantially outperforms the conventional benchmarks,
including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and
no-RIS cases, as well as centralized and multi-agent deep reinforcement
learning baselines in terms of the highest EE. Moreover, the proposed
SAGIN-MF-RIS architecture achieves superior EE performance due to its
complementary coverage, offering notable advantages over either standalone
satellite, aerial, or ground-only deployments.

</details>


### [129] [Distilled Large Language Model in Confidential Computing Environment for System-on-Chip Design](https://arxiv.org/abs/2507.16226)
*Dong Ben,Hui Feng,Qian Wang*

Main category: cs.AI

TL;DR: 论文探索了在TEE中高效部署LLMs的方法，发现蒸馏和量化模型在资源受限环境中表现优异，为半导体CAD应用提供了潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 保护LLMs及其训练数据的机密性，同时解决TEE在资源密集型LLMs中的效率问题。

Method: 在TEE、CPU-only和CPU-GPU混合三种环境下进行实验，评估了不同模型（如DeepSeek、量化模型）的性能。

Result: 蒸馏模型（如DeepSeek）表现最佳；量化模型（Q4/Q8）性能提升高达3倍；TDX在安全环境中对小参数集（如DeepSeek-r1-1.5B）的计算效率优于CPU。

Conclusion: 轻量级LLMs（如DeepSeek）在资源受限的系统中高效部署具有潜力，特别是在半导体CAD应用中。

Abstract: Large Language Models (LLMs) are increasingly used in circuit design tasks
and have typically undergone multiple rounds of training. Both the trained
models and their associated training data are considered confidential
intellectual property (IP) and must be protected from exposure. Confidential
Computing offers a promising solution to protect data and models through
Trusted Execution Environments (TEEs). However, existing TEE implementations
are not designed to support the resource-intensive nature of LLMs efficiently.
In this work, we first present a comprehensive evaluation of the LLMs within a
TEE-enabled confidential computing environment, specifically utilizing Intel
Trust Domain Extensions (TDX). We constructed experiments on three
environments: TEE-based, CPU-only, and CPU-GPU hybrid implementations, and
evaluated their performance in terms of tokens per second.
  Our first observation is that distilled models, i.e., DeepSeek, surpass other
models in performance due to their smaller parameters, making them suitable for
resource-constrained devices. Also, in the quantized models such as 4-bit
quantization (Q4) and 8-bit quantization (Q8), we observed a performance gain
of up to 3x compared to FP16 models. Our findings indicate that for fewer
parameter sets, such as DeepSeek-r1-1.5B, the TDX implementation outperforms
the CPU version in executing computations within a secure environment. We
further validate the results using a testbench designed for SoC design tasks.
These validations demonstrate the potential of efficiently deploying
lightweight LLMs on resource-constrained systems for semiconductor CAD
applications.

</details>


### [130] [ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry](https://arxiv.org/abs/2507.16280)
*Tianze Xu,Pengrui Lu,Lyumanshan Ye,Xiangkun Hu,Pengfei Liu*

Main category: cs.AI

TL;DR: ResearcherBench 是首个专注于评估高级AI研究系统（DARS）在前沿科学问题上能力的基准，通过双评估框架验证了OpenAI和Gemini系统在开放性问题上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估AI系统在网页检索和报告生成方面的能力，忽视了其在科学前沿发现新见解的潜力。

Method: 通过结合专家设计的评分标准（rubric assessment）和事实评估（factual assessment），对多个领先的商业DARS和基线系统进行了评估。

Result: OpenAI Deep Research 和 Gemini Deep Research 在开放式咨询问题上表现显著优于其他系统。

Conclusion: ResearcherBench 的推出为评估高级AI研究系统（DARS）在前沿科学问题上的能力提供了首个基准，标志着AI自我改进的重要一步，与ASI愿景一致。

Abstract: The emergence of deep research systems presents significant capabilities in
problem-solving, extending from basic queries to sophisticated research tasks.
However, existing benchmarks primarily evaluate these systems as agents for web
retrieval and report generation, overlooking their potential to discover novel
insights on the frontiers of scientific research. To address this gap, we
introduce ResearcherBench, the first benchmark focused on evaluating the
capabilities of these advanced, agentic systems - which we refer to as Deep AI
Research Systems (DARS) - on frontier AI scientific questions. We compiled a
dataset of 65 research questions expertly selected from real-world scientific
scenarios such as laboratory discussions and interviews, spanning 35 different
AI subjects and categorized into three types: technical details, literature
review, and open consulting. Our dual evaluation framework combines rubric
assessment, which uses expert-designed criteria to evaluate insight quality,
with factual assessment, which measures citation accuracy (faithfulness) and
coverage (groundedness). We evaluated several leading commercial DARS and
baseline systems. Results show that OpenAI Deep Research and Gemini Deep
Research significantly outperform other systems, with particular strength in
open-ended consulting questions. Such capabilities represent a meaningful step
toward AI self-improvement, aligning with the vision of ASI for AI. We
open-source ResearcherBench to provide a standardized platform for promoting
the development of next-generation AI research assistants, hoping to foster a
new perspective in AI research evaluation for a novel pattern of scientific
collaboration: https://github.com/GAIR-NLP/ResearcherBench.

</details>


### [131] [Cross-Modal Distillation For Widely Differing Modalities](https://arxiv.org/abs/2507.16296)
*Cairong Zhao,Yufeng Jin,Zifan Song,Haonan Chen,Duoqian Miao,Guosheng Hu*

Main category: cs.AI

TL;DR: 论文提出跨模态蒸馏框架，通过软约束知识蒸馏和自适应权重模块解决过拟合问题，在说话人识别和图像分类任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习性能提升面临模型规模增大的效率瓶颈，多模态学习通过引入更丰富的信息输入来缓解这一问题。然而，多模态数据在实际使用中的获取受限，因此需要通过知识蒸馏实现跨模态知识传递。

Method: 研究提出了一种跨模态蒸馏框架，包括特征级别和分类器级别的软约束知识蒸馏策略，以及一个基于质量的自适应权重模块来权衡输入样本。

Result: 实验结果表明，该方法在图像、文本和语音等差异较大的模态之间实现了有效的知识传递。

Conclusion: 该论文提出的跨模态蒸馏框架通过软约束知识蒸馏策略和基于质量的自适应权重模块，有效解决了跨模态知识传递中的过拟合问题，并在说话人识别和图像分类任务中验证了其有效性。

Abstract: Deep learning achieved great progress recently, however, it is not easy or
efficient to further improve its performance by increasing the size of the
model. Multi-modal learning can mitigate this challenge by introducing richer
and more discriminative information as input. To solve the problem of limited
access to multi-modal data at the time of use, we conduct multi-modal learning
by introducing a teacher model to transfer discriminative knowledge to a
student model during training. However, this knowledge transfer via
distillation is not trivial because the big domain gap between the widely
differing modalities can easily lead to overfitting. In this work, we introduce
a cross-modal distillation framework. Specifically, we find hard constrained
loss, e.g. l2 loss forcing the student being exact the same as the teacher, can
easily lead to overfitting in cross-modality distillation. To address this, we
propose two soft constrained knowledge distillation strategies at the feature
level and classifier level respectively. In addition, we propose a
quality-based adaptive weights module to weigh input samples via quantified
data quality, leading to robust model training. We conducted experiments on
speaker recognition and image classification tasks, and the results show that
our approach is able to effectively achieve knowledge transfer between the
commonly used and widely differing modalities of image, text, and speech.

</details>


### [132] [Mind the Gap: Evaluating the Representativeness of Quantitative Medical Language Reasoning LLM Benchmarks for African Disease Burdens](https://arxiv.org/abs/2507.16322)
*Fred Mutisya,Shikoh Gitau,Christine Syovata,Diana Oigara,Ibrahim Matende,Muna Aden,Munira Ali,Ryan Nyotu,Diana Marion,Job Nyangena,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha,Eric Mibuari,Jean Philbert Nsengemana,Talkmore Chidede*

Main category: cs.AI

TL;DR: 研究发现现有医学LLM基准在非洲代表性不足，开发了基于肯尼亚指南的Alama Health QA，其在非洲疾病负担和临床相关性方面表现最佳，强调了区域定制基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的医学LLM基准在高收入地区以外的有效性受到质疑，尤其是在非洲，因为这些基准未能充分反映当地的疾病负担和临床指南。

Method: 系统回顾了31篇定量LLM评估论文（2019年1月至2025年5月），识别了19个英语医学QA基准。开发了基于检索增强生成框架的Alama Health QA，并与其他五个广泛使用的基准集进行了统一的语义分析和专家盲评。

Result: Alama Health QA在所有基准中捕获了超过40%的NTD提及，并在疟疾、HIV和TB方面的频率最高。全球基准在非洲疾病负担方面的代表性较低，而Alama在临床相关性和指南对齐方面得分最高。

Conclusion: 现有的医学LLM基准主要反映高收入地区的考试大纲和疾病概况，这引发了对其在非洲部署有效性的质疑，因为非洲的疾病负担主要由疟疾、HIV、TB、镰状细胞病和其他被忽视的热带疾病（NTDs）构成。通过开发基于肯尼亚临床实践指南的Alama Health QA，研究表明区域定制的基准对于非洲医疗系统的安全、公平模型评估和部署至关重要。

Abstract: Introduction: Existing medical LLM benchmarks largely reflect examination
syllabi and disease profiles from high income settings, raising questions about
their validity for African deployment where malaria, HIV, TB, sickle cell
disease and other neglected tropical diseases (NTDs) dominate burden and
national guidelines drive care. Methodology: We systematically reviewed 31
quantitative LLM evaluation papers (Jan 2019 May 2025) identifying 19 English
medical QA benchmarks. Alama Health QA was developed using a retrieval
augmented generation framework anchored on the Kenyan Clinical Practice
Guidelines. Six widely used sets (AfriMedQA, MMLUMedical, PubMedQA, MedMCQA,
MedQAUSMLE, and guideline grounded Alama Health QA) underwent harmonized
semantic profiling (NTD proportion, recency, readability, lexical diversity
metrics) and blinded expert rating across five dimensions: clinical relevance,
guideline alignment, clarity, distractor plausibility, and language/cultural
fit. Results: Alama Health QA captured >40% of all NTD mentions across corpora
and the highest within set frequencies for malaria (7.7%), HIV (4.1%), and TB
(5.2%); AfriMedQA ranked second but lacked formal guideline linkage. Global
benchmarks showed minimal representation (e.g., sickle cell disease absent in
three sets) despite large scale. Qualitatively, Alama scored highest for
relevance and guideline alignment; PubMedQA lowest for clinical utility.
Discussion: Quantitative medical LLM benchmarks widely used in the literature
underrepresent African disease burdens and regulatory contexts, risking
misleading performance claims. Guideline anchored, regionally curated resources
such as Alama Health QA and expanded disease specific derivatives are essential
for safe, equitable model evaluation and deployment across African health
systems.

</details>


### [133] [Higher Gauge Flow Models](https://arxiv.org/abs/2507.16334)
*Alexander Strunk,Roland Assam*

Main category: cs.AI

TL;DR: 本文提出了Higher Gauge Flow Models，基于普通Gauge Flow Models，利用L$_{\infty}$-代数扩展Lie代数，将高几何和高对称性融入生成流模型，实验表明在Gaussian Mixture Model数据集上性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统Flow Models在生成任务中存在局限性，需要更高几何和对称性的框架来提升性能。

Method: 通过扩展Lie代数为L$_{\infty}$-代数，构建Higher Gauge Flow Models，整合高几何和高对称性。

Result: 在Gaussian Mixture Model数据集上，Higher Gauge Flow Models性能显著优于传统Flow Models。

Conclusion: Higher Gauge Flow Models通过引入L$_{\infty}$-代数和高几何/对称性，有效提升了生成流模型的性能。

Abstract: This paper introduces Higher Gauge Flow Models, a novel class of Generative
Flow Models. Building upon ordinary Gauge Flow Models (arXiv:2507.13414), these
Higher Gauge Flow Models leverage an L$_{\infty}$-algebra, effectively
extending the Lie Algebra. This expansion allows for the integration of the
higher geometry and higher symmetries associated with higher groups into the
framework of Generative Flow Models. Experimental evaluation on a Gaussian
Mixture Model dataset revealed substantial performance improvements compared to
traditional Flow Models.

</details>


### [134] [Learning to Call: A Field Trial of a Collaborative Bandit Algorithm for Improved Message Delivery in Mobile Maternal Health](https://arxiv.org/abs/2507.16356)
*Arpan Dasgupta,Mizhaan Maniyar,Awadhesh Srivastava,Sanat Kumar,Amrita Mahale,Aparna Hedge,Arun Suggala,Karthikeyan Shanmugam,Aparna Taneja,Milind Tambe*

Main category: cs.AI

TL;DR: 研究通过协作式bandit算法优化印度Kilkari项目的呼叫时间，显著提高了接听率，展示了机器学习在移动健康中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前随机呼叫调度导致大量未接来电和消息传递效率低下，影响了健康信息的传播效果。

Method: 部署了一种协作式bandit算法，通过学习个体母亲偏好的呼叫时间优化呼叫时机。

Result: 与基线随机呼叫方法相比，bandit算法显著提高了接听率。

Conclusion: 个性化调度在移动健康干预中的有效性，以及机器学习在提升大规模母婴健康服务中的潜力。

Abstract: Mobile health (mHealth) programs utilize automated voice messages to deliver
health information, particularly targeting underserved communities,
demonstrating the effectiveness of using mobile technology to disseminate
crucial health information to these populations, improving health outcomes
through increased awareness and behavioral change. India's Kilkari program
delivers vital maternal health information via weekly voice calls to millions
of mothers. However, the current random call scheduling often results in missed
calls and reduced message delivery. This study presents a field trial of a
collaborative bandit algorithm designed to optimize call timing by learning
individual mothers' preferred call times. We deployed the algorithm with around
$6500$ Kilkari participants as a pilot study, comparing its performance to the
baseline random calling approach. Our results demonstrate a statistically
significant improvement in call pick-up rates with the bandit algorithm,
indicating its potential to enhance message delivery and impact millions of
mothers across India. This research highlights the efficacy of personalized
scheduling in mobile health interventions and underscores the potential of
machine learning to improve maternal health outreach at scale.

</details>


### [135] [Canonical Representations of Markovian Structural Causal Models: A Framework for Counterfactual Reasoning](https://arxiv.org/abs/2507.16370)
*Lucas de Lara*

Main category: cs.AI

TL;DR: 本文提出反事实模型作为结构因果模型的替代，通过随机过程概率分布选择反事实概念，并引入归一化程序，实现在不改变观测和干预约束的情况下指定多种反事实概念。


<details>
  <summary>Details</summary>
Motivation: 反事实推理是因果关系的最高精细层次，但许多反事实陈述无法通过随机实验验证。为解决如何形式化和实现反事实信念这一基础科学问题，本文提出了新的模型。

Method: 在Pearl因果框架的马尔可夫设定中，引入反事实模型（即结构因果模型的规范表示），通过随机过程概率分布选择反事实概念，并提出了归一化程序来描述和实施各种反事实概念。

Result: 反事实模型允许分析师通过预分配边缘的随机过程概率分布选择反事实概念，并表征结构因果模型的反事实等价类。归一化程序使得在不改变观测和干预约束的情况下指定多种反事实概念成为可能。

Conclusion: 本文提出了一种替代结构因果模型的方法，称为反事实模型或结构因果模型的规范表示，用于在给定因果图模型下表示兼容的反事实。通过归一化程序，可以描述和实施多种反事实概念，而无需改变观测和干预约束。

Abstract: Counterfactual reasoning aims at answering contrary-to-fact questions like
''Would have Alice recovered had she taken aspirin?'' and corresponds to the
most fine-grained layer of causation. Critically, while many counterfactual
statements cannot be falsified -- even by randomized experiments -- they
underpin fundamental concepts like individual-wise fairness. Therefore,
providing models to formalize and implement counterfactual beliefs remains a
fundamental scientific problem. In the Markovian setting of Pearl's causal
framework, we propose an alternative approach to structural causal models to
represent counterfactuals compatible with a given causal graphical model. More
precisely, we introduce counterfactual models, also called canonical
representations of structural causal models. They enable analysts to choose a
counterfactual conception via random-process probability distributions with
preassigned marginals and characterize the counterfactual equivalence class of
structural causal models. Then, we present a normalization procedure to
describe and implement various counterfactual conceptions. Compared to
structural causal models, it allows to specify many counterfactual conceptions
without altering the observational and interventional constraints. Moreover,
the content of the model corresponding to the counterfactual layer does not
need to be estimated; only to make a choice. Finally, we illustrate the
specific role of counterfactuals in causality and the benefits of our approach
on theoretical and numerical examples.

</details>


### [136] [Self-Supervised Inductive Logic Programming](https://arxiv.org/abs/2507.16405)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: Poker是一种自监督ILP算法，无需特定背景理论或负例，通过自动生成示例学习，表现优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 探讨在缺乏特定背景理论或负例的情况下，如何实现有效的归纳逻辑编程学习。

Method: 提出了一种新的MIL算法Poker，能够在自监督ILP设置中从正例和未标记示例中学习，并自动生成和标记新的正负示例。

Result: Poker在实验中表现优于Louise，尤其是在自动生成示例数量增加时，而Louise因缺乏负例而过度泛化。

Conclusion: Poker算法在缺乏特定背景理论和负例的情况下，通过自动生成和标记正负示例，表现优于依赖专家知识的Louise系统。

Abstract: Inductive Logic Programming (ILP) approaches like Meta \-/ Interpretive
Learning (MIL) can learn, from few examples, recursive logic programs with
invented predicates that generalise well to unseen instances. This ability
relies on a background theory and negative examples, both carefully selected
with expert knowledge of a learning problem and its solutions. But what if such
a problem-specific background theory or negative examples are not available? We
formalise this question as a new setting for Self-Supervised ILP and present a
new MIL algorithm that learns in the new setting from some positive labelled,
and zero or more unlabelled examples, and automatically generates, and labels,
new positive and negative examples during learning. We implement this algorithm
in Prolog in a new MIL system, called Poker. We compare Poker to
state-of-the-art MIL system Louise on experiments learning grammars for
Context-Free and L-System languages from labelled, positive example strings, no
negative examples, and just the terminal vocabulary of a language, seen in
examples, as a first-order background theory. We introduce a new approach for
the principled selection of a second-order background theory as a Second Order
Definite Normal Form (SONF), sufficiently general to learn all programs in a
class, thus removing the need for a backgound theory tailored to a learning
task. We find that Poker's performance improves with increasing numbers of
automatically generated examples while Louise, bereft of negative examples,
over-generalises.

</details>


### [137] [Identifying Pre-training Data in LLMs: A Neuron Activation-Based Detection Framework](https://arxiv.org/abs/2507.16414)
*Hongyi Tang,Zhihao Zhu,Yi Yang*

Main category: cs.AI

TL;DR: NA-PDD通过神经元激活差异检测预训练数据，性能优于现有方法，并引入CCNewsPDD基准确保时间分布一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有预训练数据检测方法依赖表面特征（如预测置信度和损失）导致性能不佳的问题，并应对数据版权和隐私的伦理法律挑战。

Method: 提出NA-PDD算法，通过分析训练数据与非训练数据在LLM推理过程中激活的神经元差异来检测预训练数据。同时引入CCNewsPDD基准，确保时间分布一致性。

Result: NA-PDD在三个基准测试和多个LLM上显著优于现有方法。

Conclusion: NA-PDD通过分析LLM中神经元激活模式的差异，显著提升了预训练数据检测的性能，并在多个基准测试中优于现有方法。

Abstract: The performance of large language models (LLMs) is closely tied to their
training data, which can include copyrighted material or private information,
raising legal and ethical concerns. Additionally, LLMs face criticism for
dataset contamination and internalizing biases. To address these issues, the
Pre-Training Data Detection (PDD) task was proposed to identify if specific
data was included in an LLM's pre-training corpus. However, existing PDD
methods often rely on superficial features like prediction confidence and loss,
resulting in mediocre performance. To improve this, we introduce NA-PDD, a
novel algorithm analyzing differential neuron activation patterns between
training and non-training data in LLMs. This is based on the observation that
these data types activate different neurons during LLM inference. We also
introduce CCNewsPDD, a temporally unbiased benchmark employing rigorous data
transformations to ensure consistent time distributions between training and
non-training data. Our experiments demonstrate that NA-PDD significantly
outperforms existing methods across three benchmarks and multiple LLMs.

</details>


### [138] [From model-based learning to model-free behaviour with Meta-Interpretive Learning](https://arxiv.org/abs/2507.16434)
*Stassa Patsantzis*

Main category: cs.AI

TL;DR: 通过元解释学习结合模型基和无模型方法，创建了一个自主代理，并在两种环境中验证了其能力。


<details>
  <summary>Details</summary>
Motivation: 自主代理需要结合模型基和无模型的能力，以在未知环境中独立行动。

Method: 使用元解释学习来学习一个模型基求解器（Solver），并用它来训练一个无模型控制器（Controller）。在两种环境中测试：随机生成的迷宫和开阔的湖区地图。

Result: 所有被模型基求解器解决的导航问题同样可以被无模型控制器解决，表明两者能力等价。

Conclusion: 研究表明，通过元解释学习（Meta-Interpretive Learning）可以创建一个结合模型基和无模型能力的自主代理，且两种代理在解决规划问题时能力相当。

Abstract: A "model" is a theory that describes the state of an environment and the
effects of an agent's decisions on the environment. A model-based agent can use
its model to predict the effects of its future actions and so plan ahead, but
must know the state of the environment. A model-free agent cannot plan, but can
act without a model and without completely observing the environment. An
autonomous agent capable of acting independently in novel environments must
combine both sets of capabilities. We show how to create such an agent with
Meta-Interpretive Learning used to learn a model-based Solver used to train a
model-free Controller that can solve the same planning problems as the Solver.
We demonstrate the equivalence in problem-solving ability of the two agents on
grid navigation problems in two kinds of environment: randomly generated mazes,
and lake maps with wide open areas. We find that all navigation problems solved
by the Solver are also solved by the Controller, indicating the two are
equivalent.

</details>


### [139] [Improving ASP-based ORS Schedules through Machine Learning Predictions](https://arxiv.org/abs/2507.16454)
*Pierangela Bruno,Carmine Dodaro,Giuseppe Galatà,Marco Maratea,Marco Mochi*

Main category: cs.AI

TL;DR: 结合机器学习和演绎技术，提出了一种更鲁棒的手术室调度方法，能生成临时性调度表并在实际数据中验证。


<details>
  <summary>Details</summary>
Motivation: 现有的基于答案集编程（ASP）的手术室调度解决方案在应用于实际数据时，仅能验证编码与数据的对齐性，无法生成临时性调度表且结果不够鲁棒。

Method: 首先使用机器学习算法从历史数据中预测手术持续时间以计算临时性调度表，然后将预测置信度作为额外输入更新编码，以计算更鲁棒的调度表。

Result: 在意大利ASL1 Liguria的历史数据上验证了所提方法的可行性。

Conclusion: 通过结合机器学习和演绎技术，本文提出了一种更鲁棒的手术室调度方法，能够生成临时性调度表，并在意大利ASL1 Liguria的历史数据上验证了其可行性。

Abstract: The Operating Room Scheduling (ORS) problem deals with the optimization of
daily operating room surgery schedules. It is a challenging problem subject to
many constraints, like to determine the starting time of different surgeries
and allocating the required resources, including the availability of beds in
different department units. Recently, solutions to this problem based on Answer
Set Programming (ASP) have been delivered. Such solutions are overall
satisfying but, when applied to real data, they can currently only verify
whether the encoding aligns with the actual data and, at most, suggest
alternative schedules that could have been computed. As a consequence, it is
not currently possible to generate provisional schedules. Furthermore, the
resulting schedules are not always robust.
  In this paper, we integrate inductive and deductive techniques for solving
these issues. We first employ machine learning algorithms to predict the
surgery duration, from historical data, to compute provisional schedules. Then,
we consider the confidence of such predictions as an additional input to our
problem and update the encoding correspondingly in order to compute more robust
schedules. Results on historical data from the ASL1 Liguria in Italy confirm
the viability of our integration.
  Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [140] [Learning Temporal Abstractions via Variational Homomorphisms in Option-Induced Abstract MDPs](https://arxiv.org/abs/2507.16473)
*Chang Li,Yaren Zhang,Haoran Lv,Qiong Cao,Chao Xue,Xiaodong He*

Main category: cs.AI

TL;DR: 论文提出了一种隐式推理框架VMOC，通过潜在选项空间高效学习抽象技能，在逻辑推理和运动任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决生成显式链式思维（CoT）提示的高计算成本和慢速问题，作者旨在开发一种高效的隐式推理框架，使模型在潜在空间中“思考”。

Method: 论文提出了变分马尔可夫选项批评（VMOC）算法，结合分层强化学习和变分推断，并扩展了连续MDP同态理论，提供了一种冷启动过程利用监督微调数据初始化潜在选项空间。

Result: 实验表明，该方法在复杂逻辑推理基准和挑战性运动任务中表现优异。

Conclusion: 该论文提出的框架通过隐式推理在潜在空间中高效学习抽象技能，验证了其在复杂逻辑推理和运动任务中的强大性能。

Abstract: Large Language Models (LLMs) have shown remarkable reasoning ability through
explicit Chain-of-Thought (CoT) prompting, but generating these step-by-step
textual explanations is computationally expensive and slow. To overcome this,
we aim to develop a framework for efficient, implicit reasoning, where the
model "thinks" in a latent space without generating explicit text for every
step. We propose that these latent thoughts can be modeled as
temporally-extended abstract actions, or options, within a hierarchical
reinforcement learning framework. To effectively learn a diverse library of
options as latent embeddings, we first introduce the Variational Markovian
Option Critic (VMOC), an off-policy algorithm that uses variational inference
within the HiT-MDP framework. To provide a rigorous foundation for using these
options as an abstract reasoning space, we extend the theory of continuous MDP
homomorphisms. This proves that learning a policy in the simplified, abstract
latent space, for which VMOC is suited, preserves the optimality of the
solution to the original, complex problem. Finally, we propose a cold-start
procedure that leverages supervised fine-tuning (SFT) data to distill human
reasoning demonstrations into this latent option space, providing a rich
initialization for the model's reasoning capabilities. Extensive experiments
demonstrate that our approach achieves strong performance on complex logical
reasoning benchmarks and challenging locomotion tasks, validating our framework
as a principled method for learning abstract skills for both language and
control.

</details>


### [141] [Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications](https://arxiv.org/abs/2507.16507)
*Jean Lelong,Adnane Errazine,Annabelle Blangero*

Main category: cs.AI

TL;DR: INRAExplorer 是一个基于LLM的代理RAG系统，专为科学数据探索设计，通过多工具架构和知识图谱解决复杂查询问题。


<details>
  <summary>Details</summary>
Motivation: 传统RAG系统在处理复杂查询时存在局限，无法满足知识密集型领域的需求。

Method: INRAExplorer 采用基于LLM的代理和多工具架构，结合从INRAE开放获取出版物中提取的全面知识图谱，实现动态知识检索。

Result: INRAExplorer 能够执行迭代定向查询、检索详尽数据集（如某作者的所有出版物）、进行多跳推理，并提供结构化答案。

Conclusion: INRAExplorer 展示了如何在专业领域通过智能代理和多工具架构增强知识交互，为复杂查询提供结构化、全面的答案。

Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large
Language Models (LLMs) but often fall short on complex queries, delivering
limited, extractive answers and struggling with multiple targeted retrievals or
navigating intricate entity relationships. This is a critical gap in
knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system
for exploring the scientific data of INRAE (France's National Research
Institute for Agriculture, Food and Environment). INRAExplorer employs an
LLM-based agent with a multi-tool architecture to dynamically engage a rich
knowledge base, through a comprehensive knowledge graph derived from open
access INRAE publications. This design empowers INRAExplorer to conduct
iterative, targeted queries, retrieve exhaustive datasets (e.g., all
publications by an author), perform multi-hop reasoning, and deliver
structured, comprehensive answers. INRAExplorer serves as a concrete
illustration of enhancing knowledge interaction in specialized fields.

</details>


### [142] [Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report](https://arxiv.org/abs/2507.16534)
*Shanghai AI Lab,:,Xiaoyang Chen,Yunhao Chen,Zeren Chen,Zhiyun Chen,Hanyun Cui,Yawen Duan,Jiaxuan Guo,Qi Guo,Xuhao Hu,Hong Huang,Lige Huang,Chunxiao Li,Juncheng Li,Qihao Lin,Dongrui Liu,Xinmin Liu,Zicheng Liu,Chaochao Lu,Xiaoya Lu,Jingjing Qu,Qibing Ren,Jing Shao,Jingwei Shi,Jingwei Sun,Peng Wang,Weibing Wang,Jia Xu,Lewen Yan,Xiao Yu,Yi Yu,Boxuan Zhang,Jie Zhang,Weichen Zhang,Zhijie Zheng,Tianyi Zhou,Bowen Zhou*

Main category: cs.AI

TL;DR: 本文通过E-T-C分析和‘AI-45°法则’评估了前沿AI模型的七大风险领域，发现所有模型均处于可控区域，未触及红色警戒线，呼吁集体行动应对潜在挑战。


<details>
  <summary>Details</summary>
Motivation: 研究旨在识别快速发展的AI模型带来的前所未有的风险，为风险管理和政策制定提供科学依据。

Method: 报告采用了E-T-C分析（部署环境、威胁来源、赋能能力）框架，结合‘AI-45°法则’评估风险，定义了‘红线’（不可容忍阈值）和‘黄线’（早期预警指标）来划分风险区域。

Result: 实验结果显示，所有前沿AI模型均处于绿色和黄色区域，未突破红色警戒线。具体而言，在网络安全和自主AI研发风险中，所有模型均未触及黄线；而在自我复制、战略欺骗和策划方面，多数模型处于绿色区域，部分推理模型处于黄色区域。

Conclusion: 本文总结了前沿AI模型的风险评估结果，指出当前所有模型均处于绿色和黄色区域，未触及红色警戒线。研究强调了集体行动的必要性，以应对这些风险挑战。

Abstract: To understand and identify the unprecedented risks posed by rapidly advancing
artificial intelligence (AI) models, this report presents a comprehensive
assessment of their frontier risks. Drawing on the E-T-C analysis (deployment
environment, threat source, enabling capability) from the Frontier AI Risk
Management Framework (v1.0) (SafeWork-F1-Framework), we identify critical risks
in seven areas: cyber offense, biological and chemical risks, persuasion and
manipulation, uncontrolled autonomous AI R\&D, strategic deception and
scheming, self-replication, and collusion. Guided by the "AI-$45^\circ$ Law,"
we evaluate these risks using "red lines" (intolerable thresholds) and "yellow
lines" (early warning indicators) to define risk zones: green (manageable risk
for routine deployment and continuous monitoring), yellow (requiring
strengthened mitigations and controlled deployment), and red (necessitating
suspension of development and/or deployment). Experimental results show that
all recent frontier AI models reside in green and yellow zones, without
crossing red lines. Specifically, no evaluated models cross the yellow line for
cyber offense or uncontrolled AI R\&D risks. For self-replication, and
strategic deception and scheming, most models remain in the green zone, except
for certain reasoning models in the yellow zone. In persuasion and
manipulation, most models are in the yellow zone due to their effective
influence on humans. For biological and chemical risks, we are unable to rule
out the possibility of most models residing in the yellow zone, although
detailed threat modeling and in-depth assessment are required to make further
claims. This work reflects our current understanding of AI frontier risks and
urges collective action to mitigate these challenges.

</details>


### [143] [Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems](https://arxiv.org/abs/2507.16635)
*Ali Mohamed Ali,Luca Tirel,Hashim A. Hashim*

Main category: cs.AI

TL;DR: 论文提出一种基于MDP和DRL的工业装配线优化框架，结合动作屏蔽和多智能体技术，显著提升调度效率并通过模拟验证性能。


<details>
  <summary>Details</summary>
Motivation: 现代工业装配线需高效规划活动以维持制造标准并避免成本超支，但传统方法（如整数规划或启发式算法）在大规模场景下存在计算不可行或解质量低的问题。因此，需开发一种可扩展且高效的优化方案。

Method: 研究采用马尔可夫决策过程（MDP）建模通用工业装配线，并利用深度强化学习（DRL）训练智能体进行优化。提出的动作屏蔽技术确保智能体仅选择可行动作，多智能体方法则通过分散管理工作站来缩减状态和动作空间。采用集中训练分散执行的框架，实现离线学习和实时决策。

Result: 数值模拟表明，所提方案相比基于模型的方法能更快收敛至最优解，验证了其在工业装配线调度中的有效性。

Conclusion: 论文提出的基于MDP和DRL的框架，结合动作屏蔽技术和多智能体方法，显著提高了工业装配线任务和资源调度的效率，并通过数值模拟验证了其快速收敛至最优解的能力。

Abstract: Efficient planning of activities is essential for modern industrial assembly
lines to uphold manufacturing standards, prevent project constraint violations,
and achieve cost-effective operations. While exact solutions to such challenges
can be obtained through Integer Programming (IP), the dependence of the search
space on input parameters often makes IP computationally infeasible for
large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also
be applied, but they frequently produce suboptimal solutions in extensive
cases. This paper introduces a novel mathematical model of a generic industrial
assembly line formulated as a Markov Decision Process (MDP), without imposing
assumptions on the type of assembly line a notable distinction from most
existing models. The proposed model is employed to create a virtual environment
for training Deep Reinforcement Learning (DRL) agents to optimize task and
resource scheduling. To enhance the efficiency of agent training, the paper
proposes two innovative tools. The first is an action-masking technique, which
ensures the agent selects only feasible actions, thereby reducing training
time. The second is a multi-agent approach, where each workstation is managed
by an individual agent, as a result, the state and action spaces were reduced.
A centralized training framework with decentralized execution is adopted,
offering a scalable learning architecture for optimizing industrial assembly
lines. This framework allows the agents to learn offline and subsequently
provide real-time solutions during operations by leveraging a neural network
that maps the current factory state to the optimal action. The effectiveness of
the proposed scheme is validated through numerical simulations, demonstrating
significantly faster convergence to the optimal solution compared to a
comparable model-based approach.

</details>


### [144] [Adaptive Inventory Strategies using Deep Reinforcement Learning for Dynamic Agri-Food Supply Chains](https://arxiv.org/abs/2507.16670)
*Amandeep Kaur,Gyan Prakash*

Main category: cs.AI

TL;DR: 该研究提出了一种深度强化学习算法，优化农产品库存管理，解决了不确定性和易腐性问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文献未充分考虑食品供应链中各利益相关者的协调问题，且传统方法在应对需求和交货时间不确定性及产品易腐性时表现不佳。

Method: 提出了一种新颖的深度强化学习（DRL）算法，结合值和策略的DRL方法，通过连续动作空间选择最优订单量。

Result: 实验结果表明，所提出的库存补充策略在随机需求模式和交货时间情景下表现更优。

Conclusion: 本研究提出了一种结合值和策略的深度强化学习算法，用于在不确定条件下优化农产品库存管理，有效解决了传统方法在考虑产品易腐性和不确定性时的局限性。

Abstract: Agricultural products are often subject to seasonal fluctuations in
production and demand. Predicting and managing inventory levels in response to
these variations can be challenging, leading to either excess inventory or
stockouts. Additionally, the coordination among stakeholders at various level
of food supply chain is not considered in the existing body of literature. To
bridge these research gaps, this study focuses on inventory management of
agri-food products under demand and lead time uncertainties. By implementing
effective inventory replenishment policy results in maximize the overall profit
throughout the supply chain. However, the complexity of the problem increases
due to these uncertainties and shelf-life of the product, that makes
challenging to implement traditional approaches to generate optimal set of
solutions. Thus, the current study propose a novel Deep Reinforcement Learning
(DRL) algorithm that combines the benefits of both value- and policy-based DRL
approaches for inventory optimization under uncertainties. The proposed
algorithm can incentivize collaboration among stakeholders by aligning their
interests and objectives through shared optimization goal of maximizing
profitability along the agri-food supply chain while considering perishability,
and uncertainty simultaneously. By selecting optimal order quantities with
continuous action space, the proposed algorithm effectively addresses the
inventory optimization challenges. To rigorously evaluate this algorithm, the
empirical data from fresh agricultural products supply chain inventory is
considered. Experimental results corroborate the improved performance of the
proposed inventory replenishment policy under stochastic demand patterns and
lead time scenarios. The research findings hold managerial implications for
policymakers to manage the inventory of agricultural products more effectively
under uncertainty.

</details>


### [145] [Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints](https://arxiv.org/abs/2507.16727)
*Zhenyun Yin,Shujie Wang,Xuhong Wang,Xingjun Ma,Yinchun Wang*

Main category: cs.AI

TL;DR: Deliberative Searcher integrates certainty calibration with retrieval-based search for more reliable LLM outputs, showing improved confidence-correctness alignment.


<details>
  <summary>Details</summary>
Motivation: Improving the reliability of large language models (LLMs) is critical for their deployment in real-world scenarios.

Method: The framework employs multi-step reflection and verification over Wikipedia data, trained with a reinforcement learning algorithm optimized for accuracy under a soft reliability constraint.

Result: Empirical results demonstrate improved alignment between model confidence and correctness.

Conclusion: The proposed Deliberative Searcher framework enhances the reliability of LLMs by integrating certainty calibration with retrieval-based search, leading to more trustworthy outputs.

Abstract: Improving the reliability of large language models (LLMs) is critical for
deploying them in real-world scenarios. In this paper, we propose
\textbf{Deliberative Searcher}, the first framework to integrate certainty
calibration with retrieval-based search for open-domain question answering. The
agent performs multi-step reflection and verification over Wikipedia data and
is trained with a reinforcement learning algorithm that optimizes for accuracy
under a soft reliability constraint. Empirical results show that proposed
method improves alignment between model confidence and correctness, leading to
more trustworthy outputs. This paper will be continuously updated.

</details>


### [146] [WGRAMMAR: Leverage Prior Knowledge to Accelerate Structured Decoding](https://arxiv.org/abs/2507.16768)
*Ran Wang,Xiaoxuan Liu,Hao Ren,Gang Chen,Fanchao Qi,Maosong Sun*

Main category: cs.AI

TL;DR: wgrammar通过约束分解和轻量级解码引擎，显著提升LLMs结构化解码效率，最高加速250倍。


<details>
  <summary>Details</summary>
Motivation: 现有结构化解码方法因语法编译、状态跟踪和掩码创建导致效率瓶颈，而实际任务中输出结构通常有强先验知识可利用。

Method: 提出约束分解为静态和动态组件的方法，预编译静态结构，运行时用语法片段实例化动态参数。采用一组组合运算符替代下推自动机来建模正则格式。

Result: wgrammar实现了高达250倍的加速，优于现有系统。

Conclusion: wgrammar通过静态和动态约束分解、轻量级解码引擎及领域感知优化，显著提升了结构化解码效率，最高可加速250倍。其源代码已开源。

Abstract: Structured decoding enables large language models (LLMs) to generate outputs
in formats required by downstream systems, such as HTML or JSON. However,
existing methods suffer from efficiency bottlenecks due to grammar compilation,
state tracking, and mask creation. We observe that many real-world tasks embed
strong prior knowledge about output structure. Leveraging this, we propose a
decomposition of constraints into static and dynamic components -- precompiling
static structures offline and instantiating dynamic arguments at runtime using
grammar snippets. Instead of relying on pushdown automata, we employ a
compositional set of operators to model regular formats, achieving lower
transition latency. We introduce wgrammar, a lightweight decoding engine that
integrates domain-aware simplification, constraint decomposition, and mask
caching, achieving up to 250x speedup over existing systems. wgrammar's source
code is publicly available at https://github.com/wrran/wgrammar.

</details>


### [147] [ChatChecker: A Framework for Dialogue System Testing and Evaluation Through Non-cooperative User Simulation](https://arxiv.org/abs/2507.16792)
*Roman Mayr,Michel Schimpf,Thomas Bohné*

Main category: cs.AI

TL;DR: ChatChecker是一个自动化评估和测试复杂对话系统的框架，利用LLMs模拟用户交互并识别故障，无需参考对话，提高了测试效率和通用性。


<details>
  <summary>Details</summary>
Motivation: 现代对话系统不仅依赖LLMs，还整合了多种LLMs、外部工具和数据库，因此需要整体评估，但现有方法主要关注回合级分析，缺乏对话级质量保证。

Method: ChatChecker使用LLMs模拟多样化的用户交互，识别对话故障，并评估质量。设计减少了设置工作，且不依赖参考对话或目标系统的实现细节。

Result: ChatChecker通过包含错误分类提示和非合作用户模拟器，提高了故障检测性能，并更有效地暴露目标系统的弱点。

Conclusion: ChatChecker提供了一个全面且可扩展的测试框架，帮助研究人员和开发者加速开发健壮的对话系统。

Abstract: While modern dialogue systems heavily rely on large language models (LLMs),
their implementation often goes beyond pure LLM interaction. Developers
integrate multiple LLMs, external tools, and databases. Therefore, assessment
of the underlying LLM alone does not suffice, and the dialogue systems must be
tested and evaluated as a whole. However, this remains a major challenge. With
most previous work focusing on turn-level analysis, less attention has been
paid to integrated dialogue-level quality assurance. To address this, we
present ChatChecker, a framework for automated evaluation and testing of
complex dialogue systems. ChatChecker uses LLMs to simulate diverse user
interactions, identify dialogue breakdowns, and evaluate quality. Compared to
previous approaches, our design reduces setup effort and is generalizable, as
it does not require reference dialogues and is decoupled from the
implementation of the target dialogue system. We improve breakdown detection
performance over a prior LLM-based approach by including an error taxonomy in
the prompt. Additionally, we propose a novel non-cooperative user simulator
based on challenging personas that uncovers weaknesses in target dialogue
systems more effectively. Through this, ChatChecker contributes to thorough and
scalable testing. This enables both researchers and practitioners to accelerate
the development of robust dialogue systems.

</details>


### [148] [Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2507.16796)
*Mian Ibad Ali Shah,Enda Barrett,Karl Mason*

Main category: cs.AI

TL;DR: 本文提出了一种结合不确定性感知预测与多智能体强化学习（MARL）的P2P能源交易框架，显著提升了交易效率和经济效益。


<details>
  <summary>Details</summary>
Motivation: 当前P2P能源交易研究多依赖确定性预测，缺乏对不确定性的量化，而实际环境中不确定性对决策至关重要。本文旨在填补这一空白。

Method: 提出了一种名为KTU的异方差概率Transformer预测模型，通过领域特定特征和自定义损失函数生成可靠的预测及置信区间，并将其集成到MARL框架中。

Result: 实验表明，不确定性感知DQN降低了能源采购成本（无P2P时5.7%，有P2P时3.2%），提升了电力销售收益（分别6.4%和44.7%），并显著减少了高峰电网需求。

Conclusion: 不确定性感知预测与P2P交易机制的协同作用，为能源社区提供了更具韧性和经济效率的解决方案。

Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading
that integrates uncertainty-aware prediction with multi-agent reinforcement
learning (MARL), addressing a critical gap in current literature. In contrast
to previous works relying on deterministic forecasts, the proposed approach
employs a heteroscedastic probabilistic transformer-based prediction model
called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify
prediction uncertainty, which is essential for robust decision-making in the
stochastic environment of P2P energy trading. The KTU model leverages
domain-specific features and is trained with a custom loss function that
ensures reliable probabilistic forecasts and confidence intervals for each
prediction. Integrating these uncertainty-aware forecasts into the MARL
framework enables agents to optimize trading strategies with a clear
understanding of risk and variability. Experimental results show that the
uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to
5.7% without P2P trading and 3.2% with P2P trading, while increasing
electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak
hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These
improvements are even more pronounced when P2P trading is enabled, highlighting
the synergy between advanced forecasting and market mechanisms for resilient,
economically efficient energy communities.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [149] [Resilience Evaluation of Kubernetes in Cloud-Edge Environments via Failure Injection](https://arxiv.org/abs/2507.16109)
*Zihao Chen,Mohammad Goudarzi,Adel Nadjaran Toosi*

Main category: cs.DC

TL;DR: 本文提出了一种新的弹性评估框架，通过整合故障注入和流量模拟工具，系统评估Kubernetes在混合云边环境下的弹性表现，并提供了首个全面的数据集。


<details>
  <summary>Details</summary>
Motivation: 随着Kubernetes在关键任务微服务中的广泛应用，评估其在混合云边环境下的系统弹性变得至关重要。

Method: 整合主流故障注入工具（如Chaos Mesh、Gremlin、ChaosBlade）和自动化工作负载生成工具，进行全面的云边Kubernetes测试。

Result: 创建了首个混合云边Kubernetes部署的全面弹性数据集，包含11,965个故障注入场景的性能数据。分析显示，云边部署在网络延迟和分区条件下表现更稳定，而云部署在带宽限制下更具弹性。

Conclusion: 云边混合部署的Kubernetes在特定故障条件下表现出不同的弹性优势，为架构决策提供了定量指导。

Abstract: Kubernetes has emerged as an essential platform for deploying containerised
applications across cloud and edge infrastructures. As Kubernetes gains
increasing adoption for mission-critical microservices, evaluating system
resilience under realistic fault conditions becomes crucial. However,
systematic resilience assessments of Kubernetes in hybrid cloud-edge
environments are currently limited in research. To address this gap, a novel
resilience evaluation framework integrates mainstream fault injection tools
with automated workload generation for comprehensive cloud-edge Kubernetes
testing. Multiple fault injection platforms, including Chaos Mesh, Gremlin, and
ChaosBlade are combined with realistic traffic simulation tools, enabling
automated orchestration of complex failure scenarios. Through this framework,
comprehensive experiments are conducted that systematically target node-level,
pod-level, and network failures across cloud and cloud-edge environments. The
first comprehensive resilience dataset for hybrid cloud-edge Kubernetes
deployments is created, comprising over 30 GB of performance data from 11,965
fault injection scenarios including response times, failure rates, and error
patterns. Analysis reveals that cloud-edge deployments demonstrate 80% superior
response stability under network delay and partition conditions, while cloud
deployments exhibit 47% better resilience under bandwidth limitations,
providing quantitative guidance for architectural decision-making in cloud-edge
deployments.

</details>


### [150] [Parallel Ray Tracing of Black Hole Images Using the Schwarzschild Metric](https://arxiv.org/abs/2507.16165)
*Liam Naddell,Marcelo Ponce*

Main category: cs.DC

TL;DR: 本文介绍了一个并行开源程序，利用多种科学计算技术实现黑洞几何环境下的光线追踪成像。


<details>
  <summary>Details</summary>
Motivation: 黑洞图像的渲染在科学和天体物理可视化中有广泛应用，而通用光线追踪技术在计算机图形学领域也广泛使用。

Method: 结合数学近似、科学库的使用、共享内存和分布式内存并行等并行科学计算技术，实现了一个并行开源程序。

Result: 成功开发了一个能够在黑洞几何环境下进行光线追踪的并行开源程序。

Conclusion: 本文展示了一个并行开源程序的实现，该程序能够在黑洞几何存在的情况下进行光线追踪成像，结合了多种并行科学计算技术。

Abstract: Rendering images of black holes by utilizing ray tracing techniques is a
common methodology employed in many aspects of scientific and astrophysical
visualizations. Similarly, general ray tracing techniques are widely used in
areas related to computer graphics. In this work we describe the implementation
of a parallel open-source program that can ray trace images in the presence of
a black hole geometry. We do this by combining a couple of different techniques
usually present in parallel scientific computing, such as, mathematical
approximations, utilization of scientific libraries, shared-memory and
distributed-memory parallelism.

</details>


### [151] [Autonomous Dominant Resource Fairness for Blockchain Ecosystems](https://arxiv.org/abs/2507.16350)
*Serdar Metin*

Main category: cs.DC

TL;DR: 本研究提出了一种适用于区块链环境的高效多资源分配算法Autonomous Dominant Resource Fairness，通过避免循环迭代适应区块链限制，实证证明其高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 区块链在资源管理中的应用主要集中在单一资源分配场景，即使涉及多种资源类型，也常被简化为单一资源类型处理。本研究旨在解决多资源类型在异构资源需求任务中的分配问题。

Method: 通过智能合约适配Precomputed Dominant Resource Fairness算法，避免了循环迭代，适应区块链的区块gas限制。

Result: 实证数据显示，Autonomous Dominant Resource Fairness算法在gas成本上高效，适用于管理大量资源类型和用户。

Conclusion: 研究提出了一种名为Autonomous Dominant Resource Fairness的算法，该算法在区块链环境中高效且可扩展，能够管理数百种资源类型和无限制的用户数量。

Abstract: Blockchain systems have been a part of mainstream academic research, and a
hot topic at that. It has spread to almost every subfield in the computer
science literature, as well as economics and finance. Especially in a world
where digital trust is much sought for, blockchains offer a rich variety of
desired properties, such as immutability, public auditing, decentralised record
keeping, among others. Not only has it been a research topic of its own, the
integration of blockchains into other systems has been proposed as solutions in
many areas, ranging from grid computing, cloud and fog computing, to internet
of things, self driving vehicles , and smart cities. In many cases the primary
function attributed to blockchains in these contexts is resource management.
Although much attention is paid to this topic, the focus is on single resource
allocation scenarios. Even the cases where multiple resource types are to be
allocated, are treated as single resource type scenarios, and problems are
formulated as allocating standardised bundles consisting of a fixed amount of
each of them, such as virtual machines. The present study addresses the problem
of allocating multiple resource types among tasks with heterogeneous resource
demands with a smart contract adaptation of Precomputed Dominant Resource
Fairness; an algorithm that approximates Dominant Resource Fairness, without
loop iterations, which makes it preferable in the blockchain context because of
the block gas limit. We present the resulting algorithm, Autonomous Dominant
Resource Fairness, along with the empirical data collected from the tests run
on the algorithm. The results show that Autonomous Dominant Resource Fairness
is a gas-cost efficient algorithm, which can be used to manage hundreds of
resource types for unlimited number of users.

</details>


### [152] [FOGNITE: Federated Learning-Enhanced Fog-Cloud Architecture](https://arxiv.org/abs/2507.16668)
*Somayeh Sobati-M*

Main category: cs.DC

TL;DR: FOGNITE是一种结合联邦学习、强化学习和数字孪生的雾计算框架，显著提升智能电网的负载平衡和能效。


<details>
  <summary>Details</summary>
Motivation: 现代智能电网需要快速、智能且节能的边缘计算来实时管理波动并确保可靠运行，FOGNITE旨在通过下一代雾云框架提升分布式能源系统的性能。

Method: FOGNITE框架结合了联邦学习（本地CNN-LSTM模型训练）、强化学习（动态任务调度）和数字孪生验证（分层模拟潜在行动），通过在Raspberry Pi设备上实现，验证了其有效性。

Result: 在真实测试环境中，FOGNITE相比传统架构实现了负载平衡准确率提升93.7%和能源浪费减少63.2%。

Conclusion: FOGNITE通过结合联邦学习、强化学习和数字孪生验证，显著提升了分布式能源系统的自主性、弹性和效率，为更智能、自适应和可持续的能源基础设施迈出了重要一步。

Abstract: Modern smart grids demand fast, intelligent, and energy-aware computing at
the edge to manage real time fluctuations and ensure reliable operation. This
paper introduces FOGNITE Fog-based Grid In intelligence with Neural Integration
and Twin based Execution a next-generation fog cloud framework designed to
enhance autonomy, resilience, and efficiency in distributed energy systems.
FOGNITE combines three core components: federated learning, reinforcement
learning, and digital twin validation. Each fog node trains a local CNN LSTM
model on private energy consumption data, enabling predictive intelligence
while preserving data privacy through federated aggregation. A reinforcement
learning agent dynamically schedules tasks based on current system load and
energy conditions, optimizing for performance under uncertainty.
  To prevent unsafe or inefficient decisions, a hierarchical digital twin layer
simulates potential actions before deployment, significantly reducing execution
errors and energy waste. We evaluate FOGNITE on a real world testbed of
Raspberry Pi devices, showing up to a 93.7% improvement in load balancing
accuracy and a 63.2% reduction in energy waste compared to conventional
architectures. By shifting smart grid control from reactive correction to
proactive optimization, FOGNITE represents a step toward more intelligent,
adaptive, and sustainable energy infrastructures

</details>


### [153] [AcceleratedKernels.jl: Cross-Architecture Parallel Algorithms from a Unified, Transpiled Codebase](https://arxiv.org/abs/2507.16710)
*Andrei-Leonard Nicusan,Dominik Werner,Simon Branford,Simon Hartley,Andrew J. Morris,Kit Windows-Yule*

Main category: cs.DC

TL;DR: AcceleratedKernels.jl 是一个支持多硬件加速器的 Julia 库，通过独特的转译架构实现高效并行计算，性能优异且经济高效。


<details>
  <summary>Details</summary>
Motivation: 解决并行计算中多硬件加速器的兼容性问题，降低实现和使用复杂度，提升性能和经济效益。

Method: 通过独特的转译架构，支持 NVIDIA、AMD、Intel 和 Apple 加速器，实现了统一的代码库和简化的并行编程。

Result: 在算术密集型内核测试中，性能与 C 和 OpenMP 多线程 CPU 实现相当，甚至在某些情况下更优。使用 200 个 NVIDIA A100 GPU 实现了 538-855 GB/s 的世界级排序吞吐量。

Conclusion: AcceleratedKernels.jl 展示了在 Julia 中实现高效并行计算的潜力，特别是在多硬件加速器上的表现优异，且具有出色的可组合性和经济性。

Abstract: AcceleratedKernels.jl is introduced as a backend-agnostic library for
parallel computing in Julia, natively targeting NVIDIA, AMD, Intel, and Apple
accelerators via a unique transpilation architecture. Written in a unified,
compact codebase, it enables productive parallel programming with minimised
implementation and usage complexities. Benchmarks of arithmetic-heavy kernels
show performance on par with C and OpenMP-multithreaded CPU implementations,
with Julia sometimes offering more consistent and predictable numerical
performance than conventional C compilers. Exceptional composability is
highlighted as simultaneous CPU-GPU co-processing is achievable - such as
CPU-GPU co-sorting - with transparent use of hardware-specialised MPI
implementations. Tests on the Baskerville Tier 2 UK HPC cluster achieved
world-class sorting throughputs of 538-855 GB/s using 200 NVIDIA A100 GPUs,
comparable to the highest literature-reported figure of 900 GB/s achieved on
262,144 CPU cores. The use of direct NVLink GPU-to-GPU interconnects resulted
in a 4.93x speedup on average; normalised by a combined capital, running and
environmental cost, communication-heavy HPC tasks only become economically
viable on GPUs if GPUDirect interconnects are employed.

</details>


### [154] [Collaborative Inference and Learning between Edge SLMs and Cloud LLMs: A Survey of Algorithms, Execution, and Open Challenges](https://arxiv.org/abs/2507.16731)
*Senyao Li,Haozhao Wang,Wenchao Xu,Rui Zhang,Song Guo,Jingling Yuan,Xian Zhong,Tianwei Zhang,Ruixuan Li*

Main category: cs.DC

TL;DR: 综述探讨了云端LLM与边缘小型语言模型（SLM）在推理和训练中的协作，提出了协作策略分类法，并总结了相关技术和应用。


<details>
  <summary>Details</summary>
Motivation: 由于延迟、隐私、成本和个性化问题，单独在云端部署大型语言模型（LLMs）或将其压缩到边缘设备已不足够。

Method: 提出了一个统一的边缘-云协作策略分类法，包括推理任务的任务分配、任务划分和混合协作，以及训练的分布式适应技术。

Result: 总结了数据集、基准测试和部署案例，并强调了隐私保护方法和垂直应用。

Conclusion: 这篇综述为LLM-SLM协作提供了首个系统性基础，通过系统和算法的协同设计，实现了高效、可扩展且可信的边缘-云智能。

Abstract: As large language models (LLMs) evolve, deploying them solely in the cloud or
compressing them for edge devices has become inadequate due to concerns about
latency, privacy, cost, and personalization. This survey explores a
collaborative paradigm in which cloud-based LLMs and edge-deployed small
language models (SLMs) cooperate across both inference and training. We present
a unified taxonomy of edge-cloud collaboration strategies. For inference, we
categorize approaches into task assignment, task division, and mixture-based
collaboration at both task and token granularity, encompassing adaptive
scheduling, resource-aware offloading, speculative decoding, and modular
routing. For training, we review distributed adaptation techniques, including
parameter alignment, pruning, bidirectional distillation, and
small-model-guided optimization. We further summarize datasets, benchmarks, and
deployment cases, and highlight privacy-preserving methods and vertical
applications. This survey provides the first systematic foundation for LLM-SLM
collaboration, bridging system and algorithm co-design to enable efficient,
scalable, and trustworthy edge-cloud intelligence.

</details>


### [155] [Cooling Matters: Benchmarking Large Language Models and Vision-Language Models on Liquid-Cooled Versus Air-Cooled H100 GPU Systems](https://arxiv.org/abs/2507.16781)
*Imran Latif,Muhammad Ali Shafique,Hayat Ullah,Alex C. Newkirk,Xi Yu,Arslan Munir*

Main category: cs.DC

TL;DR: 液体冷却在AI工作负载中表现优于空气冷却，提供更稳定的温度控制和更高的能效。


<details>
  <summary>Details</summary>
Motivation: AI工作负载（尤其是LLMs和VLMs）的快速增长加剧了数据中心的电力和冷却需求，本研究旨在评估不同冷却技术的效果。

Method: 使用GPU Burn、Weights and Biases和IPMItool工具，在配备8x NVIDIA H100 GPU的两个HGX节点上，对LLMs和VLMs进行液体和空气冷却的详细热、功耗及计算数据收集。

Result: 液体冷却系统将GPU温度维持在41-50°C，性能提升17%（54 TFLOPs/GPU vs. 46 TFLOPs/GPU），并显著提高能效和系统效率。

Conclusion: 液体冷却系统在维持GPU温度稳定、提升性能表现和能效方面优于空气冷却系统，为超大规模数据中心提供了可持续的能源解决方案。

Abstract: The unprecedented growth in artificial intelligence (AI) workloads, recently
dominated by large language models (LLMs) and vision-language models (VLMs),
has intensified power and cooling demands in data centers. This study
benchmarks LLMs and VLMs on two HGX nodes, each with 8x NVIDIA H100 graphics
processing units (GPUs), using liquid and air cooling. Leveraging GPU Burn,
Weights and Biases, and IPMItool, we collect detailed thermal, power, and
computation data. Results show that the liquid-cooled systems maintain GPU
temperatures between 41-50 degrees Celsius, while the air-cooled counterparts
fluctuate between 54-72 degrees Celsius under load. This thermal stability of
liquid-cooled systems yields 17 percent higher performance (54 TFLOPs per GPU
vs. 46 TFLOPs per GPU), improved performance per watt, reduced energy overhead,
and greater system efficiency than the air-cooled counterparts. These findings
underscore the energy and sustainability benefits of liquid cooling, offering a
compelling path forward for hyperscale data centers s

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [156] [Online Combinatorial Optimization with Graphical Dependencies](https://arxiv.org/abs/2507.16031)
*Zhimeng Gao,Evangelia Gergatsouli,Kalen Patton,Sahil Singla*

Main category: cs.DS

TL;DR: 本文研究了MRF模型下的在线组合优化问题，提出了实现O(Δ)-竞争算法的一般性技术，覆盖最小化和最大化问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多假设输入来自独立分布，但实际中这种假设常不成立。本文研究MRF这一中间模型，能够捕捉温和相关性，同时允许非平凡的算法设计。

Method: 对于最小化问题（如设施选址和Steiner树），采用p-sample模型；对于最大化问题（如匹配和组合拍卖），扩展了在线分配问题的“平衡价格”框架。

Result: 提出了针对MRF分布输入的一般性技术，实现了O(Δ)-竞争算法，适用于最小化和最大化问题。

Conclusion: 本文提出了在马尔可夫随机场（MRF）分布输入下，针对在线组合优化问题的一般性技术，能够实现O(Δ)-竞争算法，覆盖最小化和最大化问题。

Abstract: Most existing work in online stochastic combinatorial optimization assumes
that inputs are drawn from independent distributions -- a strong assumption
that often fails in practice. At the other extreme, arbitrary correlations are
equivalent to worst-case inputs via Yao's minimax principle, making good
algorithms often impossible. This motivates the study of intermediate models
that capture mild correlations while still permitting non-trivial algorithms.
  In this paper, we study online combinatorial optimization under Markov Random
Fields (MRFs), a well-established graphical model for structured dependencies.
MRFs parameterize correlation strength via the maximum weighted degree
$\Delta$, smoothly interpolating between independence ($\Delta = 0$) and full
correlation ($\Delta \to \infty$). While na\"ively this yields
$e^{O(\Delta)}$-competitive algorithms and $\Omega(\Delta)$ hardness, we ask:
when can we design tight $\Theta(\Delta)$-competitive algorithms?
  We present general techniques achieving $O(\Delta)$-competitive algorithms
for both minimization and maximization problems under MRF-distributed inputs.
For minimization problems with coverage constraints (e.g., Facility Location
and Steiner Tree), we reduce to the well-studied $p$-sample model. For
maximization problems (e.g., matchings and combinatorial auctions with XOS
buyers), we extend the "balanced prices" framework for online allocation
problems to MRFs.

</details>


### [157] [Online Joint Replenishment Problem with Arbitrary Holding and Backlog Costs](https://arxiv.org/abs/2507.16096)
*Yossi Azar,Shahar Lewkowicz*

Main category: cs.DS

TL;DR: 本文解决了JRP中未解决的开放性问题，设计了一个动态优先级的常数竞争算法，适用于任意请求依赖函数。


<details>
  <summary>Details</summary>
Motivation: 解决Moseley等人未解决的开放性问题，即设计一个适用于任意请求依赖函数的常数竞争算法。

Method: 设计了一种动态优先级的请求处理算法，不同于固定优先级和按截止日期顺序处理请求的方法。

Result: 针对单物品情况建立了4-竞争算法，针对多物品情况建立了16-竞争算法。

Conclusion: 本文解决了Moseley、Niaparast和Ravi提出的开放性问题，设计了一个适用于任意请求依赖函数的常数竞争算法。

Abstract: In their seminal paper Moseley, Niaparast, and Ravi introduced the Joint
Replenishment Problem (JRP) with holding and backlog costs that models the
trade-off between ordering costs, holding costs, and backlog costs in supply
chain planning systems. Their model generalized the classical the make-to-order
version as well make-to-stock version. For the case where holding costs
function of all items are the same and all backlog costs are the same, they
provide a constant competitive algorithm, leaving designing a constant
competitive algorithm for arbitrary functions open. Moreover, they noticed that
their algorithm does not work for arbitrary (request dependent) holding costs
and backlog costs functions. We resolve their open problem and design a
constant competitive algorithm that works for arbitrary request dependent
functions. Specifically, we establish a 4-competitive algorithm for the
single-item case and a 16-competitive for the general (multi-item) version. The
algorithm of Moseley, Niaparast, and Ravi is based on fixed priority on the
requests to items, and request to an item are always served by order of
deadlines. In contrast, we design an algorithm with dynamic priority over the
requests such that instead of servicing a prefix by deadline of requests, we
may need to service a general subset of the requests.

</details>


### [158] [An Exact Solver for Maximizing a Submodular Function Subject to a Knapsack Constraint](https://arxiv.org/abs/2507.16149)
*Sabine Münch,Stephen Raach*

Main category: cs.DS

TL;DR: 提出了一种精确分支定界算法及加速技术，用于解决子模背包问题，并在实验中验证了其优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管子模背包问题是NP难问题，但许多应用需要精确解，因为近似解在实践中往往不足。

Method: 提出了一种针对子模背包问题的精确分支定界算法，并引入了多种加速技术以提高效率。

Result: 在三个基准问题上评估了所提出的加速技术，并与Sakaue和Ishihata的两种现有先进求解器进行了比较，结果表明所提方法优于现有方法。

Conclusion: 本文提出的分支定界算法及其加速技术在子模背包问题上表现优异，优于现有的先进方法。

Abstract: We study the problem of maximizing a monotone increasing submodular function
over a set of weighted elements subject to a knapsack constraint.
  Although this problem is NP-hard, many applications require exact solutions,
as approximate solutions are often insufficient in practice.
  To address this need, we propose an exact branch-and-bound algorithm tailored
for the submodular knapsack problem and introduce several acceleration
techniques to enhance its efficiency. We evaluate these techniques on instances
of three benchmark problems and compare the proposed solvers to two solvers by
Sakaue and Ishihata, which are considered state-of-the-art, demonstrating that
the presented methods outperform the existing methods.

</details>


### [159] [Toward a Lightweight and Robust Design for Caching with Predictions](https://arxiv.org/abs/2507.16242)
*Peng Chen,Hailiang Zhao,Jiaji Zhang,Xueyan Tang,Yixuan Wang,Shuiguang Deng*

Main category: cs.DS

TL;DR: \textsc{Guard} 是一个轻量级框架，提升学习增强缓存算法的鲁棒性至2H_k + 2，同时保持1-一致性和低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的鲁棒化方法要么牺牲1-一致性，要么引入显著的计算开销，而学习增强缓存算法虽然能达到理想的1-一致性，但缺乏鲁棒性保证。

Method: 引入\textsc{Guard}，一个轻量级的鲁棒化框架，通过仅增加每请求O(1)的开销来增强学习增强缓存算法的鲁棒性。

Result: \textsc{Guard} 实现了当前已知的最佳一致性与鲁棒性权衡，并在多个真实数据集和预测模型中验证了其有效性。

Conclusion: \textsc{Guard} 框架在保持学习增强缓存算法的1-一致性的同时，显著提升了其鲁棒性至2H_k + 2，并在实践中验证了其有效性。

Abstract: The online caching problem aims to minimize cache misses when serving a
sequence of requests under a limited cache size. While naive learning-augmented
caching algorithms achieve ideal $1$-consistency, they lack robustness
guarantees. Existing robustification methods either sacrifice $1$-consistency
or introduce significant computational overhead. In this paper, we introduce
\textsc{Guard}, a lightweight robustification framework that enhances the
robustness of a broad class of learning-augmented caching algorithms to $2H_k +
2$, while preserving their $1$-consistency. \textsc{Guard} achieves the current
best-known trade-off between consistency and robustness, with only
$\mathcal{O}(1)$ additional per-request overhead, thereby maintaining the
original time complexity of the base algorithm. Extensive experiments across
multiple real-world datasets and prediction models validate the effectiveness
of \textsc{Guard} in practice.

</details>


### [160] [Longest Unbordered Factors on Run-Length Encoded Strings](https://arxiv.org/abs/2507.16285)
*Shoma Sekizaki,Takuya Mieno*

Main category: cs.DS

TL;DR: 本文研究了RLE压缩字符串的最长无边框因子问题，提出了一种时间复杂度为$O(m^{1.5} \log^2 m)$、空间复杂度为$O(m \log^2 m)$的算法，在$m$较小时可能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 最长无边框因子问题是字符串学中的一个基本问题，与字符串周期性密切相关。尽管已有研究实现了次二次和近线性时间算法，但最坏情况下的时间复杂度仍为$O(n \log n)$。本文旨在通过在压缩字符串处理（特别是RLE字符串）的背景下研究该问题，进一步优化算法性能。

Method: 通过将无边框因子与RLE压缩字符串的结构关联，本文提出了一种基于新组合见解的算法。该算法模拟了Gawrychowski等人提出的$O(n^{1.5})$时间算法的关键思想，并通过适应RLE设置实现了优化。

Result: 提出的算法在RLE压缩字符串上的时间复杂度和空间复杂度分别为$O(m^{1.5} \log^2 m)$和$O(m \log^2 m)$，当$m$较小时可能表现出线性时间行为。

Conclusion: 本文提出了一种针对RLE压缩字符串的最长无边框因子算法，其时间复杂度和空间复杂度分别为$O(m^{1.5} \log^2 m)$和$O(m \log^2 m)$。当RLE大小$m$相对于原始字符串长度$n$较小时，该算法可能表现出线性时间行为，从而在某些情况下优于现有方法。

Abstract: A border of a string is a non-empty proper prefix of the string that is also
a suffix. A string is unbordered if it has no border. The longest unbordered
factor is a fundamental notion in stringology, closely related to string
periodicity. This paper addresses the longest unbordered factor problem: given
a string of length $n$, the goal is to compute its longest factor that is
unbordered. While recent work has achieved subquadratic and near-linear time
algorithms for this problem, the best known worst-case time complexity remains
$O(n \log n)$ [Kociumaka et al., ISAAC 2018]. In this paper, we investigate the
problem in the context of compressed string processing, particularly focusing
on run-length encoded (RLE) strings. We first present a simple yet crucial
structural observation relating unbordered factors and RLE-compressed strings.
Building on this, we propose an algorithm that solves the problem in $O(m^{1.5}
\log^2 m)$ time and $O(m \log^2 m)$ space, where $m$ is the size of the
RLE-compressed input string. To achieve this, our approach simulates a key idea
from the $O(n^{1.5})$-time algorithm by [Gawrychowski et al., SPIRE 2015],
adapting it to the RLE setting through new combinatorial insights. When the RLE
size $m$ is sufficiently small compared to $n$, our algorithm may show
linear-time behavior in $n$, potentially leading to improved performance over
existing methods in such cases.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [161] [AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?](https://arxiv.org/abs/2507.15887)
*Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press*

Main category: cs.SE

TL;DR: AlgoTune基准测试旨在评估语言模型在开放算法设计任务中的表现，发现当前模型虽能加速但缺乏创新。


<details>
  <summary>Details</summary>
Motivation: 当前的语言模型评估主要集中于人类已解决的问题，缺乏对模型设计和实现算法的开放能力测试。

Method: 提出了AlgoTune基准测试，包含155个来自领域专家的编码任务，并开发了一个验证和计时框架，用于比较模型生成的解决方案代码与开源参考实现。同时开发了基线LM代理AlgoTuner。

Result: AlgoTuner在参考求解器上实现了平均1.72倍的加速，但当前模型未能发现算法创新，仅偏好表面优化。

Conclusion: AlgoTune benchmark旨在推动语言模型代理在创造性问题解决方面超越人类现有水平的开发。

Abstract: Despite progress in language model (LM) capabilities, evaluations have thus
far focused on models' performance on tasks that humans have previously solved,
including in programming (Jimenez et al., 2024) and mathematics (Glazer et al.,
2024). We therefore propose testing models' ability to design and implement
algorithms in an open-ended benchmark: We task LMs with writing code that
efficiently solves computationally challenging problems in computer science,
physics, and mathematics. Our AlgoTune benchmark consists of 155 coding tasks
collected from domain experts and a framework for validating and timing
LM-synthesized solution code, which is compared to reference implementations
from popular open-source packages. In addition, we develop a baseline LM agent,
AlgoTuner, and evaluate its performance across a suite of frontier models.
AlgoTuner achieves an average 1.72x speedup against our reference solvers,
which use libraries such as SciPy, sk-learn and CVXPY. However, we find that
current models fail to discover algorithmic innovations, instead preferring
surface-level optimizations. We hope that AlgoTune catalyzes the development of
LM agents exhibiting creative problem solving beyond state-of-the-art human
performance.

</details>


### [162] [Dr. Boot: Bootstrapping Program Synthesis Language Models to Perform Repairing](https://arxiv.org/abs/2507.15889)
*Noah van der Vleuten*

Main category: cs.SE

TL;DR: Bootstrapping algorithm for program synthesis improves performance by teaching models to repair, though inference repairing may not beat sampling. APPS dataset issues noted.


<details>
  <summary>Details</summary>
Motivation: Address limitations of current program synthesis models, which are data-hungry and misaligned with human iterative development processes.

Method: Introduces a bootstrapping algorithm for program synthesis that teaches models to repair code iteratively.

Result: Bootstrapping outperforms regular fine-tuning, with models performing on par with larger fine-tuned models. Repairing during inference may not be better than sampling multiple solutions.

Conclusion: Bootstrapping with repairing improves program synthesis performance, though repairing during inference may not be superior to sampling multiple solutions. Issues with APPS dataset test cases are highlighted.

Abstract: Language models for program synthesis are usually trained and evaluated on
programming competition datasets (MBPP, APPS). However, these datasets are
limited in size and quality, while these language models are extremely data
hungry. Additionally, the language models have a misaligned program synthesis
process compared to humans. While humans iteratively develop code with the help
of a compiler, most program synthesis models currently produce code in one go.
To solve these issues, we introduce a bootstrapping algorithm for program
synthesis, that supports teaching models how to repair. We show that
bootstrapping consistently outperforms regular fine-tuning. Compared to other
work, our bootstrapped model performs on par with fine-tuned models that are
68\% larger. Notably, bootstrapping with repairing also improves non-repairing
performance compared to regular bootstrapping during inference. However, on our
models, repairing during inference is likely inferior to simply sampling the
same number of solutions. Furthermore, we find that there are issues with the
example test cases in the training portion of the APPS dataset that are
valuable to the community, as many repairing and reinforcement learning methods
rely on them.

</details>


### [163] [StaAgent: An Agentic Framework for Testing Static Analyzers](https://arxiv.org/abs/2507.15892)
*Elijah Nnorom,Md Basim Uddin Ahmed,Jiho Shin,Hung Viet Pham,Song Wang*

Main category: cs.SE

TL;DR: StaAgent利用LLM驱动的多智能体框架系统化评估静态分析器规则，成功发现64个问题规则，展示了其在提升分析器可靠性的有效性。


<details>
  <summary>Details</summary>
Motivation: 静态分析器的规则实现常因测试不足而存在不一致性，需一种系统化方法来评估和改进其可靠性。

Method: StaAgent框架包含四个智能体：种子生成、代码验证、变异生成和分析器评估，通过LLM生成和验证代码，进行蜕变测试。

Result: 实验评估了五种LLM和五种静态分析器，揭示了64个问题规则，其中53个无法被现有基线检测到，部分问题已提交并得到开发者确认或修复。

Conclusion: StaAgent框架通过LLM驱动的多智能体系统，有效提升了静态分析器的可靠性，成功揭示了64个有问题的规则，并展示了其在软件工程中的潜力。

Abstract: Static analyzers play a critical role in identifying bugs early in the
software development lifecycle, but their rule implementations are often
under-tested and prone to inconsistencies. To address this, we propose
StaAgent, an agentic framework that harnesses the generative capabilities of
Large Language Models (LLMs) to systematically evaluate static analyzer rules.
StaAgent comprises four specialized agents: a Seed Generation Agent that
translates bug detection rules into concrete, bug-inducing seed programs; a
Code Validation Agent that ensures the correctness of these seeds; a Mutation
Generation Agent that produces semantically equivalent mutants; and an Analyzer
Evaluation Agent that performs metamorphic testing by comparing the static
analyzer's behavior on seeds and their corresponding mutants. By revealing
inconsistent behaviors, StaAgent helps uncover flaws in rule implementations.
This LLM-driven, multi-agent framework offers a scalable and adaptable solution
to improve the reliability of static analyzers. We evaluated StaAgent with five
state-of-the-art LLMs (CodeL-lama, DeepSeek, Codestral, Qwen, and GPT-4o)
across five widely used static analyzers (SpotBugs, SonarQube, ErrorProne,
Infer, and PMD). The experimental results show that our approach can help
reveal 64 problematic rules in the latest versions of these five static
analyzers (i.e., 28 in SpotBugs, 18 in SonarQube, 6 in ErrorProne, 4 in Infer,
and 8 in PMD). In addition, 53 out of the 64 bugs cannot be detected by the
SOTA baseline. We have reported all the bugs to developers, with two of them
already fixed. Three more have been confirmed by developers, while the rest are
awaiting response. These results demonstrate the effectiveness of our approach
and underscore the promise of agentic, LLM-driven data synthesis to advance
software engineering.

</details>


### [164] [A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights](https://arxiv.org/abs/2507.16037)
*Zhili Zeng,Kimya Khakzad Shahandashti,Alvine Boaye Belle,Song Wang,Zhen Ming,Jiang*

Main category: cs.SE

TL;DR: 该研究评估了基于LLM的代理方法在Android到iOS应用翻译中的表现，识别了失败点并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着移动应用的快速发展，跨平台兼容性需求日益增长，传统方法效率低下且缺乏上下文理解，而LLM在跨平台应用翻译中的表现和局限性尚未充分探索。

Method: 开发了一个考虑依赖关系、规范、程序结构和控制流的代理链，用于将Android应用翻译到iOS平台，并通过手动检查翻译代码的语法正确性、语义准确性和功能完整性来评估性能。

Result: 研究发现，LLM在跨平台应用翻译中具有一定的潜力，但仍存在局限性，需进一步改进。

Conclusion: 本研究通过评估基于LLM的代理方法在移动应用翻译中的表现，识别了关键失败点，并提出了改进翻译性能的指南。

Abstract: The rapid advancement of mobile applications has led to a significant demand
for cross-platform compatibility, particularly between the Android and iOS
platforms. Traditional approaches to mobile application translation often rely
on manual intervention or rule-based systems, which are labor-intensive and
time-consuming. While recent advancements in machine learning have introduced
automated methods, they often lack contextual understanding and adaptability,
resulting in suboptimal translations. Large Language Models (LLMs) were
recently leveraged to enhance code translation at different granularities,
including the method, class, and repository levels. Researchers have
investigated common errors, limitations, and potential strategies to improve
these tasks. However, LLM-based application translation across different
platforms, such as migrating mobile applications between Android and iOS or
adapting software across diverse frameworks, remains underexplored.
Understanding the performance, strengths, and limitations of LLMs in
cross-platform application translation is critical for advancing software
engineering automation. This study aims to fill this gap by evaluating
LLM-based agentic approaches for mobile application translation, identifying
key failure points, and proposing guidelines to improve translation
performance. We developed a chain of agents that account for dependencies,
specifications, program structure, and program control flow when translating
applications from Android to iOS. To evaluate the performance, we manually
examined the translated code for syntactic correctness, semantic accuracy, and
functional completeness. For translation failures, we further conducted a
detailed root cause analysis to understand the underlying limitations of the
agentic translation process and identify opportunities for improvement.

</details>


### [165] [Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs](https://arxiv.org/abs/2507.16044)
*Meriem Mastouri,Emna Ksontini,Wael Kessentini*

Main category: cs.SE

TL;DR: AutoMCP是一个从OpenAPI规范自动生成MCP服务器的工具，显著减少了手动开发工作量，并在修复规范问题后实现了99.9%的成功率。


<details>
  <summary>Details</summary>
Motivation: MCP服务器的构建过程仍然需要大量手动工作，这与MCP旨在消除的集成努力相矛盾。本文旨在研究是否可以将MCP服务器的构建过程自动化。

Method: 本文提出了AutoMCP，一个从OpenAPI 2.0/3.0规范生成MCP服务器的编译器，能够自动处理模式注册和认证。

Result: 在50个真实API上评估AutoMCP，覆盖5,066个端点，初始成功率为76.5%。经过对OpenAPI规范的微小修复后，成功率提升至99.9%。

Conclusion: AutoMCP成功地将MCP服务器的构建自动化，显著减少了手动开发的工作量，并通过修复OpenAPI规范中的常见问题，实现了高达99.9%的成功率。

Abstract: Large Language Models (LLMs) are evolving from passive text generators into
active agents that invoke external tools. To support this shift, scalable
protocols for tool integration are essential. The Model Context Protocol (MCP),
introduced by Anthropic in 2024, offers a schema-driven standard for dynamic
tool discovery and invocation. Yet, building MCP servers remains manual and
repetitive, requiring developers to write glue code, handle authentication, and
configure schemas by hand-replicating much of the integration effort MCP aims
to eliminate.
  This paper investigates whether MCP server construction can be meaningfully
automated. We begin by analyzing adoption trends: among 22,000+ MCP-tagged
GitHub repositories created within six months of release, fewer than 5% include
servers, typically small, single-maintainer projects dominated by repetitive
scaffolding. To address this gap, we present AutoMCP, a compiler that generates
MCP servers from OpenAPI 2.0/3.0 specifications. AutoMCP parses REST API
definitions and produces complete server implementations, including schema
registration and authentication handling.
  We evaluate AutoMCP on 50 real-world APIs spanning 5,066 endpoints across
over 10 domains. From a stratified sample of 1,023 tool calls, 76.5% succeeded
out of the box. Manual failure analysis revealed five recurring issues, all
attributable to inconsistencies or omissions in the OpenAPI contracts. After
minor fixes, averaging 19 lines of spec changes per API, AutoMCP achieved 99.9%
success.
  Our findings (i) analyze MCP adoption and quantify the cost of manual server
development, (ii) demonstrate that OpenAPI specifications, despite quality
issues, enable near-complete MCP server automation, and (iii) contribute a
corpus of 5,066 callable tools along with insights on repairing common
specification flaws.

</details>


### [166] [AI-Powered Commit Explorer (APCE)](https://arxiv.org/abs/2507.16063)
*Yousab Grees,Polina Iaremchuk,Ramtin Ehsani,Esteban Parra,Preetha Chatterjee,Sonia Haiduc*

Main category: cs.SE

TL;DR: APCE是一个支持LLM生成提交消息的工具，提供提示存储、增强和评估功能。


<details>
  <summary>Details</summary>
Motivation: 提交消息是描述代码变更的重要信息源，但实践中常被忽视。LLM生成的提交消息可缓解此问题，但需工具支持其使用和研究。

Method: 引入AI-Powered Commit Explorer (APCE)，支持存储不同LLM提示并提供评估提示，以增强LLM生成的提交消息。同时提供自动化和人工评估机制。

Result: APCE工具为LLM生成的提交消息提供了存储、增强和评估的机制，支持开发者和研究人员。

Conclusion: APCE工具通过提供存储和评估LLM生成的提交消息的功能，支持开发者和研究人员更有效地利用LLM生成高质量提交消息。

Abstract: Commit messages in a version control system provide valuable information for
developers regarding code changes in software systems. Commit messages can be
the only source of information left for future developers describing what was
changed and why. However, writing high-quality commit messages is often
neglected in practice. Large Language Model (LLM) generated commit messages
have emerged as a way to mitigate this issue. We introduce the AI-Powered
Commit Explorer (APCE), a tool to support developers and researchers in the use
and study of LLM-generated commit messages. APCE gives researchers the option
to store different prompts for LLMs and provides an additional evaluation
prompt that can further enhance the commit message provided by LLMs. APCE also
provides researchers with a straightforward mechanism for automated and human
evaluation of LLM-generated messages. Demo link https://youtu.be/zYrJ9s6sZvo

</details>


### [167] [Ten Essential Guidelines for Building High-Quality Research Software](https://arxiv.org/abs/2507.16166)
*Nasir U. Eisty,David E. Bernholdt,Alex Koufos,David J. Luet,Miranda Mundt*

Main category: cs.SE

TL;DR: 本文提出了十条指南，帮助研究人员创建高质量、可持续的科研软件，涵盖开发全周期的关键实践。


<details>
  <summary>Details</summary>
Motivation: 高质量的科研软件是现代科学进步的基石，但创建此类软件需要遵循确保健壮性、可用性和可持续性的最佳实践。

Method: 本文提出了十条关于生产高质量科研软件的指南，涵盖了开发生命周期的每个阶段。

Result: 这些指南强调了规划、编写清晰可读的代码、使用版本控制和实施全面测试策略的重要性，并涵盖了模块化设计、可重复性、性能优化和长期维护等关键原则。

Conclusion: 遵循这些指南可以帮助研究人员创建高质量的科研软件，促进科学目标的实现，并为更广泛的可靠和可重用研究工具生态系统做出贡献。

Abstract: High-quality research software is a cornerstone of modern scientific
progress, enabling researchers to analyze complex data, simulate phenomena, and
share reproducible results. However, creating such software requires adherence
to best practices that ensure robustness, usability, and sustainability. This
paper presents ten guidelines for producing high-quality research software,
covering every stage of the development lifecycle. These guidelines emphasize
the importance of planning, writing clean and readable code, using version
control, and implementing thorough testing strategies. Additionally, they
address key principles such as modular design, reproducibility, performance
optimization, and long-term maintenance. The paper also highlights the role of
documentation and community engagement in enhancing software usability and
impact. By following these guidelines, researchers can create software that
advances their scientific objectives and contributes to a broader ecosystem of
reliable and reusable research tools. This work serves as a practical resource
for researchers and developers aiming to elevate the quality and impact of
their research software.

</details>


### [168] [LOCOFY Large Design Models -- Design to code conversion solution](https://arxiv.org/abs/2507.16208)
*Sohaib Muhammad,Ashwati Vipin,Karan Shetti,Honey Mittal*

Main category: cs.SE

TL;DR: 论文提出LDMs范式，通过设计优化、UI元素检测和自动组件化，实现高效可靠的设计到代码转换，性能优于现有LLMs。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs和多模态LLMs快速发展，但在设计到代码转换中存在可解释性、扩展性、资源需求和可重复性等挑战。

Method: 1) 设计优化器处理次优设计；2) 使用预训练和微调模型进行标记和特征检测；3) 自动组件提取重复UI结构为可重用组件。

Result: LDMs在节点定位、响应性和可重复性上表现优于LLMs，且自定义标记和特征检测模型在UI元素识别上表现出高精度和一致性。

Conclusion: 提出的LDMs（大型设计模型）是理解设计并生成高效可靠生产代码的可靠且优越解决方案。

Abstract: Despite rapid advances in Large Language Models and Multimodal Large Language
Models (LLMs), numerous challenges related to interpretability, scalability,
resource requirements and repeatability remain, related to their application in
the design-to-code space. To address this, we introduce the Large Design Models
(LDMs) paradigm specifically trained on designs and webpages to enable seamless
conversion from design-to-code. We have developed a training and inference
pipeline by incorporating data engineering and appropriate model architecture
modification. The training pipeline consists of the following: 1)Design
Optimiser: developed using a proprietary ground truth dataset and addresses
sub-optimal designs; 2)Tagging and feature detection: using pre-trained and
fine-tuned models, this enables the accurate detection and classification of UI
elements; and 3)Auto Components: extracts repeated UI structures into reusable
components to enable creation of modular code, thus reducing redundancy while
enhancing code reusability. In this manner, each model addresses distinct but
key issues for design-to-code conversion. Separately, our inference pipeline
processes real-world designs to produce precise and interpretable instructions
for code generation and ensures reliability. Additionally, our models
illustrated exceptional end-to-end design-to-code conversion accuracy using a
novel preview match score metric. Comparative experiments indicated superior
performance of LDMs against LLMs on accuracy of node positioning,
responsiveness and reproducibility. Moreover, our custom-trained tagging and
feature detection model demonstrated high precision and consistency in
identifying UI elements across a wide sample of test designs. Thus, our
proposed LDMs are a reliable and superior solution to understanding designs
that subsequently enable the generation of efficient and reliable
production-ready code.

</details>


### [169] [Search-based Generation of Waypoints for Triggering Self-Adaptations in Maritime Autonomous Vessels](https://arxiv.org/abs/2507.16327)
*Karoline Nylænder,Aitor Arrieta,Shaukat Ali,Paolo Arcaini*

Main category: cs.SE

TL;DR: WPgen是一种基于多目标搜索的方法，用于生成海上自主船舶导航航点的微小修改，以测试其自适应行为。实验显示不同策略在不同船舶上效果不一。


<details>
  <summary>Details</summary>
Motivation: 理解并识别应触发自适应行为的场景，以验证海上自主船舶（AVs）导航软件中自适应行为的实现。

Method: 提出了一种基于多目标搜索的方法WPgen，利用NSGA-II算法和三种初始种群生成策略，生成对预设航点的微小修改。

Result: 实验结果表明，WPgen的三种变体在不同AV上的表现各异，其中某些变体在特定AV上表现更优。

Conclusion: WPgen的三种变体在不同AV上的有效性存在差异，研究结果对WPgen的实际应用具有指导意义。

Abstract: Self-adaptation in maritime autonomous vessels (AVs) enables them to adapt
their behaviors to address unexpected situations while maintaining
dependability requirements. During the design of such AVs, it is crucial to
understand and identify the settings that should trigger adaptations, enabling
validation of their implementation. To this end, we focus on the navigation
software of AVs, which must adapt their behavior during operation through
adaptations. AVs often rely on predefined waypoints to guide them along
designated routes, ensuring safe navigation. We propose a multiobjective
search-based approach, called WPgen, to generate minor modifications to the
predefined set of waypoints, keeping them as close as possible to the original
waypoints, while causing the AV to navigate inappropriately when navigating
with the generated waypoints. WPgen uses NSGA-II as the multi-objective search
algorithm with three seeding strategies for its initial population, resulting
in three variations of WPgen. We evaluated these variations on three AVs (one
overwater tanker and two underwater). We compared the three variations of WPgen
with Random Search as the baseline and with each other. Experimental results
showed that the effectiveness of these variations varied depending on the AV.
Based on the results, we present the research and practical implications of
WPgen.

</details>


### [170] [Improving Code LLM Robustness to Prompt Perturbations via Layer-Aware Model Editing](https://arxiv.org/abs/2507.16407)
*Shuhan Liu,Xing Hu,Kerui Huang,Xiaohu Yang,David Lo,Xin Xia*

Main category: cs.SE

TL;DR: CREME通过轻量级参数编辑提升LLM对提示扰动的鲁棒性，实验显示其显著提高扰动输入的代码生成准确率，同时不影响原始性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码生成中对提示扰动高度敏感，轻微修改可能导致功能正确性显著下降。为提高实际应用中的可靠性，需提升模型对扰动的鲁棒性。

Method: CREME通过比较原始提示和扰动变体的隐藏状态，识别鲁棒性敏感层，并在这些层进行轻量级参数编辑以减少性能下降。

Result: 在HumanEval和MBPP基准测试及其扰动版本上，CREME将扰动提示的Pass@1准确率提高了63%，同时在原始输入上保持性能稳定（准确率偏差在1%以内）。

Conclusion: CREME通过定位和编辑模型中对提示扰动敏感的层，显著提升了大型语言模型在代码生成中的鲁棒性，同时保持了原始输入的稳定性能。此外，分析发现鲁棒性敏感层主要位于网络的中间和深层，且位置因模型架构而异，为未来鲁棒性导向的编辑策略提供了重要基础。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities in
code generation, where the natural language prompt plays a crucial role in
conveying user intent to the model. However, prior studies have shown that LLMs
are highly sensitive to prompt perturbations. Minor modifications in wording,
syntax, or formatting can significantly reduce the functional correctness of
generated code. As perturbations frequently occur in real-world scenarios,
improving the robustness of LLMs to prompt perturbations is essential for
ensuring reliable performance in practical code generation. In this paper, we
introduce CREME (Code Robustness Enhancement via Model Editing), a novel
approach that enhances LLM robustness through targeted parameter updates. CREME
first identifies robustness-sensitive layers by comparing hidden states between
an original prompt and its perturbed variant. Then, it performs lightweight
parameter editing at the identified layer to reduce performance degradation. We
evaluate CREME on two widely used code generation benchmarks (HumanEval and
MBPP) along with their perturbed counterparts. Experimental results show that
CREME improves Pass@1 accuracy by 63% on perturbed prompts while maintaining
stable performance on clean inputs, with accuracy deviations within 1%. Further
analysis reveals that robustness-sensitive layers are primarily concentrated in
the middle and deeper layers of the network, and their locations vary across
different model architectures. These insights provide a valuable foundation for
developing future robustness-oriented editing strategies.

</details>


### [171] [Exploring Large Language Models for Analyzing and Improving Method Names in Scientific Code](https://arxiv.org/abs/2507.16439)
*Gunnar Larsen,Carol Wong,Anthony Peruma*

Main category: cs.SE

TL;DR: 研究评估LLMs在科学代码方法名称分析中的表现，发现其有一定效果但需人工辅助。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在科学软件中方法名称质量分析的自动化潜力。

Method: 评估四种流行LLM对496个Python Jupyter Notebook方法名称的语法模式分析和改进建议能力。

Result: LLMs能有效分析方法名称并遵循良好命名实践，但对领域术语处理不一致，与人工标注一致性中等。

Conclusion: LLMs在分析科学代码方法名称时表现尚可，但需人工评估其建议，以提高科学代码质量。

Abstract: Research scientists increasingly rely on implementing software to support
their research. While previous research has examined the impact of identifier
names on program comprehension in traditional programming environments, limited
work has explored this area in scientific software, especially regarding the
quality of method names in the code. The recent advances in Large Language
Models (LLMs) present new opportunities for automating code analysis tasks,
such as identifier name appraisals and recommendations. Our study evaluates
four popular LLMs on their ability to analyze grammatical patterns and suggest
improvements for 496 method names extracted from Python-based Jupyter
Notebooks. Our findings show that the LLMs are somewhat effective in analyzing
these method names and generally follow good naming practices, like starting
method names with verbs. However, their inconsistent handling of
domain-specific terminology and only moderate agreement with human annotations
indicate that automated suggestions require human evaluation. This work
provides foundational insights for improving the quality of scientific code
through AI automation.

</details>


### [172] [On the Effectiveness of LLM-as-a-judge for Code Generation and Summarization](https://arxiv.org/abs/2507.16587)
*Giuseppe Crupi,Rosalia Tufano,Alejandro Velasco,Antonio Mastropaolo,Denys Poshyvanyk,Gabriele Bavota*

Main category: cs.SE

TL;DR: 研究验证了GPT-4-turbo作为LLM评判者在代码生成和摘要任务中的领先地位，但误判问题仍需关注。


<details>
  <summary>Details</summary>
Motivation: 探索LLM作为评判者在代码生成和代码摘要任务中的有效性，以解决定量指标不足和大规模人工评估成本高的问题。

Method: 研究了八个LLM在判断1,405个Java方法和1,281个Python函数的正确性方面的能力，以及五个LLM在判断约1.2k个代码摘要质量方面的能力，并与人类评判进行比较。

Result: GPT-4-turbo在两项任务中表现最佳，但所有LLM均存在频繁的误判现象。

Conclusion: GPT-4-turbo是目前在代码生成和代码摘要任务中表现最佳的LLM评判者，但即使是性能最好的LLM也经常出现误判。

Abstract: Large Language Models have been recently exploited as judges for complex
natural language processing tasks, such as Q&A. The basic idea is to delegate
to an LLM the assessment of the "quality" of the output provided by an
automated technique for tasks for which: (i) quantitative metrics would only
tell part of the story, and; (ii) a large-scale human-based evaluation would be
too expensive. LLMs-as-a-judge, if proven effective for a specific task, can
also unlock new possibilities for automation, with several LLMs proposing a
solution for a given instance of the task and others judging and deciding what
is the best output to show the user. We study the effectiveness of
LLMs-as-a-judge for two code-related tasks, namely code generation and code
summarization. The rationale for choosing these tasks is two-fold. First,
quantitative metrics are usually not enough for the assessment of code
summarizers/generators. For example, it is well documented that metrics such as
BLEU are quite weak proxies for the quality of the generated summaries. Second,
even state-of-the-art techniques still struggle with handling complex instances
of these tasks, making them good candidates for benefiting from more advanced
solutions envisioning collaboration among LLMs. For code generation, we check
whether eight LLMs are able to judge the correctness of 1,405 Java methods and
1,281 Python functions generated by the same LLMs or implemented by humans. For
code summarization, we compare the judgment of five LLMs to those provided by
nine humans for ~1.2k summaries, related to both Java and Python functions. Our
findings show that GPT-4-turbo is the best LLM in terms of judging capabilities
for both tasks, with "smaller" LLMs featuring tens of billions parameters not
being able to cope with judging tasks. However, even the best-performing LLM
frequently misjudges the correctness of the code and summary quality.

</details>


### [173] [VulCoCo: A Simple Yet Effective Method for Detecting Vulnerable Code Clones](https://arxiv.org/abs/2507.16661)
*Tan Bui,Yan Naing Tun,Thanh Phuc Nguyen,Yindu Su,Ferdian Thung,Yikun Li,Han Wei Ang,Yide Yin,Frank Liauw,Lwin Khin Shar,Eng Lieh Ouh,Ting Zhang,David Lo*

Main category: cs.SE

TL;DR: VulCoCo 通过嵌入检索与 LLM 验证，高效检测脆弱代码克隆，实验显示其优于现有方法，并在实际项目中验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有脆弱代码克隆检测工具依赖语法相似性或预测粗糙且缺乏解释，实用性受限。

Method: 提出 VulCoCo 方法，结合嵌入检索与 LLM 验证，构建合成基准测试。

Result: VulCoCo 在 Precision@k 和 MAP 上优于现有方法，实际提交的 PR 中 75 个被合并，15 个导致新 CVE 发布。

Conclusion: VulCoCo 结合嵌入检索与大语言模型验证，显著提升了脆弱代码克隆检测的精度，并在实际开源项目中验证了其有效性，为未来研究提供了方向。

Abstract: Code reuse is common in modern software development, but it can also spread
vulnerabilities when developers unknowingly copy risky code. The code fragments
that preserve the logic of known vulnerabilities are known as vulnerable code
clones (VCCs). Detecting those VCCs is a critical but challenging task.
Existing VCC detection tools often rely on syntactic similarity or produce
coarse vulnerability predictions without clear explanations, limiting their
practical utility. In this paper, we propose VulCoCo, a lightweight and
scalable approach that combines embedding-based retrieval with large language
model (LLM) validation. Starting from a set of known vulnerable functions, we
retrieve syntactically or semantically similar candidate functions from a large
corpus and use an LLM to assess whether the candidates retain the
vulnerability. Given that there is a lack of reproducible vulnerable code clone
benchmarks, we first construct a synthetic benchmark that spans various clone
types.
  Our experiments on the benchmark show that VulCoCo outperforms prior
state-of-the-art methods in terms of Precision@k and mean average precision
(MAP). In addition, we also demonstrate VulCoCo's effectiveness in real-world
projects by submitting 400 pull requests (PRs) to 284 open-source projects.
Among them, 75 PRs were merged, and 15 resulted in newly published CVEs. We
also provide insights to inspire future work to further improve the precision
of vulnerable code clone detection.

</details>


### [174] [VulGuard: An Unified Tool for Evaluating Just-In-Time Vulnerability Prediction Models](https://arxiv.org/abs/2507.16685)
*Duong Nguyen,Manh Tran-Duc,Thanh Le-Cong,Triet Huynh Minh Le,M. Ali Babar,Quyet-Thang Huynh*

Main category: cs.SE

TL;DR: VulGuard是一个自动化工具，用于GitHub提交的提取和分析，支持即时漏洞预测研究，解决了可重复性和可扩展性问题，并在FFmpeg和Linux内核中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决软件安全研究中可重复性和可扩展性的挑战，VulGuard旨在提供一个统一的框架，支持从仓库规模挖掘到模型级实验的全流程。

Method: VulGuard自动挖掘提交历史，提取细粒度代码变更、提交消息和软件工程指标，并将其格式化为下游分析。此外，它集成了多个最先进的漏洞预测模型，支持模型的训练、评估和比较。

Result: VulGuard在FFmpeg和Linux内核两个有影响力的开源项目中展示了其有效性，证明了其加速实际JIT-VP研究和促进标准化基准测试的潜力。

Conclusion: VulGuard是一个自动化的工具，旨在通过提取、处理和分析GitHub提交来简化即时漏洞预测（JIT-VP）研究。它支持大规模仓库挖掘和模型实验，解决了软件安全研究中的可重复性和可扩展性挑战。

Abstract: We present VulGuard, an automated tool designed to streamline the extraction,
processing, and analysis of commits from GitHub repositories for Just-In-Time
vulnerability prediction (JIT-VP) research. VulGuard automatically mines commit
histories, extracts fine-grained code changes, commit messages, and software
engineering metrics, and formats them for downstream analysis. In addition, it
integrates several state-of-the-art vulnerability prediction models, allowing
researchers to train, evaluate, and compare models with minimal setup. By
supporting both repository-scale mining and model-level experimentation within
a unified framework, VulGuard addresses key challenges in reproducibility and
scalability in software security research. VulGuard can also be easily
integrated into the CI/CD pipeline. We demonstrate the effectiveness of the
tool in two influential open-source projects, FFmpeg and the Linux kernel,
highlighting its potential to accelerate real-world JIT-VP research and promote
standardized benchmarking. A demo video is available at:
https://youtu.be/j96096-pxbs

</details>


### [175] [Never Come Up Empty: Adaptive HyDE Retrieval for Improving LLM Developer Support](https://arxiv.org/abs/2507.16754)
*Fangjian Lei,Mariam El Mezouar,Shayan Noei,Ying Zou*

Main category: cs.SE

TL;DR: 研究通过构建大规模Stack Overflow语料库和探索多种RAG管道设计，验证了优化的RAG管道能显著提升LLMs生成答案的质量，适用于新旧问题。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在辅助开发者解决代码相关问题方面表现出潜力，但其生成的答案可能存在不可靠性（如幻觉）。为解决这一问题，研究探索了RAG管道的设计，以减少LLMs的不可靠性。

Method: 本研究构建了一个包含300多万个Java和Python相关Stack Overflow帖子的检索语料库，并探索了7种不同的RAG管道设计和63种变体，以评估其在生成准确和可靠答案方面的效果。

Result: 研究发现，结合HyDE和完整答案上下文的RAG管道在检索和回答Stack Overflow问题时表现最佳。此外，优化的RAG管道在4种开源LLMs上的表现均优于零样本基线，显著提升了答案的有用性、正确性和细节。

Conclusion: 研究结果表明，优化的RAG管道显著提升了不同LLMs生成的答案质量，无论是对于已有相似问题还是新问题，均能提供更准确、详细和有用的回答。

Abstract: Large Language Models (LLMs) have shown promise in assisting developers with
code-related questions; however, LLMs carry the risk of generating unreliable
answers. To address this, Retrieval-Augmented Generation (RAG) has been
proposed to reduce the unreliability (i.e., hallucinations) of LLMs. However,
designing effective pipelines remains challenging due to numerous design
choices. In this paper, we construct a retrieval corpus of over 3 million Java
and Python related Stack Overflow posts with accepted answers, and explore
various RAG pipeline designs to answer developer questions, evaluating their
effectiveness in generating accurate and reliable responses. More specifically,
we (1) design and evaluate 7 different RAG pipelines and 63 pipeline variants
to answer questions that have historically similar matches, and (2) address new
questions without any close prior matches by automatically lowering the
similarity threshold during retrieval, thereby increasing the chance of finding
partially relevant context and improving coverage for unseen cases. We find
that implementing a RAG pipeline combining hypothetical-documentation-embedding
(HyDE) with the full-answer context performs best in retrieving and answering
similarcontent for Stack Overflow questions. Finally, we apply our optimal RAG
pipeline to 4 open-source LLMs and compare the results to their zero-shot
performance. Our findings show that RAG with our optimal RAG pipeline
consistently outperforms zero-shot baselines across models, achieving higher
scores for helpfulness, correctness, and detail with LLM-as-a-judge. These
findings demonstrate that our optimal RAG pipelines robustly enhance answer
quality for a wide range of developer queries including both previously seen
and novel questions across different LLMs

</details>


### [176] [Rethinking LLM-Based RTL Code Optimization Via Timing Logic Metamorphosis](https://arxiv.org/abs/2507.16808)
*Zhihao Xu,Bixin Li,Lulu Wang*

Main category: cs.SE

TL;DR: LLM在RTL优化中逻辑操作表现优，但复杂时序处理不足，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 传统RTL优化方法依赖人工和启发式，效率低且易错，LLM的潜力尚未在复杂时序逻辑中充分评估。

Method: 提出基于变形的新基准和系统评估方法，验证LLM在复杂时序逻辑RTL代码优化中的有效性。

Result: LLM在逻辑操作优化上优于传统方法，但在时序控制流和时钟域优化上表现不佳。

Conclusion: LLM-Based RTL优化方法在逻辑操作上表现优异，但在复杂时序逻辑处理上不及传统编译方法，未来研究需解决LLM对时序逻辑理解的挑战。

Abstract: Register Transfer Level(RTL) code optimization is crucial for achieving high
performance and low power consumption in digital circuit design. However,
traditional optimization methods often rely on manual tuning and heuristics,
which can be time-consuming and error-prone. Recent studies proposed to
leverage Large Language Models(LLMs) to assist in RTL code optimization. LLMs
can generate optimized code snippets based on natural language descriptions,
potentially speeding up the optimization process. However, existing approaches
have not thoroughly evaluated the effectiveness of LLM-Based code optimization
methods for RTL code with complex timing logic. To address this gap, we
conducted a comprehensive empirical investigation to assess the capability of
LLM-Based RTL code optimization methods in handling RTL code with complex
timing logic. In this study, we first propose a new benchmark for RTL
optimization evaluation. It comprises four subsets, each corresponding to a
specific area of RTL code optimization. Then we introduce a method based on
metamorphosis to systematically evaluate the effectiveness of LLM-Based RTL
code optimization methods.Our key insight is that the optimization
effectiveness should remain consistent for semantically equivalent but more
complex code. After intensive experiments, we revealed several key findings.
(1) LLM-Based RTL optimization methods can effectively optimize logic
operations and outperform existing compiler-based methods. (2) LLM-Based RTL
optimization methods do not perform better than existing compiler-based methods
on RTL code with complex timing logic, particularly in timing control flow
optimization and clock domain optimization. This is primarily attributed to the
challenges LLMs face in understanding timing logic in RTL code. Based on these
findings, we provide insights for further research in leveraging LLMs for RTL
code optimization.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [177] [Dream, Lift, Animate: From Single Images to Animatable Gaussian Avatars](https://arxiv.org/abs/2507.15979)
*Marcel C. Bühler,Ye Yuan,Xueting Li,Yangyi Huang,Koki Nagano,Umar Iqbal*

Main category: cs.GR

TL;DR: DLA是一个从单张图像重建可动画化3D虚拟形象的新框架，结合多视角生成和UV空间映射，实现高保真和实时渲染。


<details>
  <summary>Details</summary>
Motivation: 为了解决从单张图像重建可动画化3D人体虚拟形象的挑战，DLA旨在结合生成模型和结构化表示的优势，以实现高保真和实时渲染。

Method: DLA利用多视角生成、3D高斯提升和姿势感知的UV空间映射技术，通过基于transformer的编码器将3D高斯投影到结构化潜在表示中，从而实现动画化。

Result: DLA在ActorsHQ和4D-Dress数据集上表现优异，在感知质量和光度准确性方面均优于现有最先进方法。

Conclusion: DLA通过结合视频扩散模型的生成能力和姿势感知的UV空间高斯映射，弥合了非结构化3D表示与高保真、可动画化虚拟形象之间的差距。

Abstract: We introduce Dream, Lift, Animate (DLA), a novel framework that reconstructs
animatable 3D human avatars from a single image. This is achieved by leveraging
multi-view generation, 3D Gaussian lifting, and pose-aware UV-space mapping of
3D Gaussians. Given an image, we first dream plausible multi-views using a
video diffusion model, capturing rich geometric and appearance details. These
views are then lifted into unstructured 3D Gaussians. To enable animation, we
propose a transformer-based encoder that models global spatial relationships
and projects these Gaussians into a structured latent representation aligned
with the UV space of a parametric body model. This latent code is decoded into
UV-space Gaussians that can be animated via body-driven deformation and
rendered conditioned on pose and viewpoint. By anchoring Gaussians to the UV
manifold, our method ensures consistency during animation while preserving fine
visual details. DLA enables real-time rendering and intuitive editing without
requiring post-processing. Our method outperforms state-of-the-art approaches
on ActorsHQ and 4D-Dress datasets in both perceptual quality and photometric
accuracy. By combining the generative strengths of video diffusion models with
a pose-aware UV-space Gaussian mapping, DLA bridges the gap between
unstructured 3D representations and high-fidelity, animation-ready avatars.

</details>


### [178] [MMS Player: an open source software for parametric data-driven animation of Sign Language avatars](https://arxiv.org/abs/2507.16463)
*Fabrizio Nunnari,Shailesh Mishra,Patrick Gebhard*

Main category: cs.GR

TL;DR: MMS-Player开源软件利用MMS格式增强手语动画合成，支持Blender集成和多格式输出。


<details>
  <summary>Details</summary>
Motivation: 增强基于gloss的手语表示，通过添加并行执行、时间和变位信息，提升手语动画的准确性和表现力。

Method: 实现基于Python脚本，集成于Blender 3D创作工具，可通过命令行或HTTP API调用。

Result: 成功开发出能够合成手语动画的软件，支持多种输出格式，并开源供社区使用。

Conclusion: MMS-Player是一个开源软件，能够从新型手语表示格式MMS合成手语动画，支持视频渲染和3D动画格式导出，采用GPL-3.0许可证免费提供。

Abstract: This paper describes the MMS-Player, an open source software able to
synthesise sign language animations from a novel sign language representation
format called MMS (MultiModal Signstream). The MMS enhances gloss-based
representations by adding information on parallel execution of signs, timing,
and inflections. The implementation consists of Python scripts for the popular
Blender 3D authoring tool and can be invoked via command line or HTTP API.
Animations can be rendered as videos or exported in other popular 3D animation
exchange formats. The software is freely available under GPL-3.0 license at
https://github.com/DFKI-SignLanguage/MMS-Player.

</details>
