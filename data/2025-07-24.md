<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 95]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.RO](#cs.RO) [Total: 38]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.AI](#cs.AI) [Total: 21]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.DC](#cs.DC) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Post-Disaster Affected Area Segmentation with a Vision Transformer (ViT)-based EVAP Model using Sentinel-2 and Formosat-5 Imagery](https://arxiv.org/abs/2507.16849)
*Yi-Shan Chu,Hsuan-Cheng Wei*

Main category: cs.CV

TL;DR: 提出基于ViT的深度学习框架，通过弱监督训练提升灾害区域分割的平滑性和可靠性，适用于缺乏准确地面真实数据的场景。


<details>
  <summary>Details</summary>
Motivation: 旨在支持和增强台湾太空机构（TASA）开发的紧急增值产品（EVAP），通过改进灾害影响区域的分割来提升灾害映射的准确性。

Method: 提出了一种基于ViT的深度学习框架，结合PCA特征空间分析和置信指数（CI）扩展标签，构建弱监督训练集，并支持多解码器变体和多阶段损失策略。

Result: 案例研究表明，该框架在2022年鄱阳湖干旱和2023年罗得岛野火中显著提高了分割结果的平滑性和可靠性。

Conclusion: 该框架通过改进分割结果的平滑性和可靠性，为灾害映射提供了一种可扩展的方法，特别是在缺乏准确地面真实数据的情况下。

Abstract: We propose a vision transformer (ViT)-based deep learning framework to refine
disaster-affected area segmentation from remote sensing imagery, aiming to
support and enhance the Emergent Value Added Product (EVAP) developed by the
Taiwan Space Agency (TASA). The process starts with a small set of manually
annotated regions. We then apply principal component analysis (PCA)-based
feature space analysis and construct a confidence index (CI) to expand these
labels, producing a weakly supervised training set. These expanded labels are
then used to train ViT-based encoder-decoder models with multi-band inputs from
Sentinel-2 and Formosat-5 imagery. Our architecture supports multiple decoder
variants and multi-stage loss strategies to improve performance under limited
supervision. During the evaluation, model predictions are compared with
higher-resolution EVAP output to assess spatial coherence and segmentation
consistency. Case studies on the 2022 Poyang Lake drought and the 2023 Rhodes
wildfire demonstrate that our framework improves the smoothness and reliability
of segmentation results, offering a scalable approach for disaster mapping when
accurate ground truth is unavailable.

</details>


### [2] [Toward a Real-Time Framework for Accurate Monocular 3D Human Pose Estimation with Geometric Priors](https://arxiv.org/abs/2507.16850)
*Mohamed Adjel*

Main category: cs.CV

TL;DR: 结合实时2D关键点检测与几何感知的2D到3D提升，利用相机内参和解剖学先验，实现快速、个性化的单目3D姿态估计。


<details>
  <summary>Details</summary>
Motivation: 单目3D人体姿态估计在实时设置和无约束环境中仍是一个具有挑战性的问题。直接图像到3D方法需要大量标注数据和复杂模型，而2D到3D提升方法更轻量且灵活，尤其是在结合先验知识时。

Method: 提出了一种框架，结合实时2D关键点检测与几何感知的2D到3D提升，利用相机内参和特定解剖学先验。基于自校准和生物力学约束逆向运动学，从MoCap和合成数据集中生成大规模、合理的2D-3D训练对。

Result: 该方法能够实现快速、个性化且准确的3D姿态估计，无需专用硬件。

Conclusion: 该框架通过结合实时2D关键点检测与几何感知的2D到3D提升，利用已知相机内参和特定解剖学先验，实现了快速、个性化且准确的单目3D姿态估计，无需专用硬件。

Abstract: Monocular 3D human pose estimation remains a challenging and ill-posed
problem, particularly in real-time settings and unconstrained environments.
While direct imageto-3D approaches require large annotated datasets and heavy
models, 2D-to-3D lifting offers a more lightweight and flexible
alternative-especially when enhanced with prior knowledge. In this work, we
propose a framework that combines real-time 2D keypoint detection with
geometry-aware 2D-to-3D lifting, explicitly leveraging known camera intrinsics
and subject-specific anatomical priors. Our approach builds on recent advances
in self-calibration and biomechanically-constrained inverse kinematics to
generate large-scale, plausible 2D-3D training pairs from MoCap and synthetic
datasets. We discuss how these ingredients can enable fast, personalized, and
accurate 3D pose estimation from monocular images without requiring specialized
hardware. This proposal aims to foster discussion on bridging data-driven
learning and model-based priors to improve accuracy, interpretability, and
deployability of 3D human motion capture on edge devices in the wild.

</details>


### [3] [Coarse-to-fine crack cue for robust crack detection](https://arxiv.org/abs/2507.16851)
*Zelong Liu,Yuliang Gu,Zhichao Sun,Huachao Zhu,Xin Xiao,Bo Du,Laurent Najman,Yongchao Xu*

Main category: cs.CV

TL;DR: CrackCue利用裂纹的细长结构特性生成鲁棒线索，显著提升裂纹检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在裂纹检测中泛化能力不足，且忽视了裂纹的细长结构特性。

Method: 提出CrackCue方法，基于粗到细的裂纹线索生成，包括最大池化和上采样操作生成粗裂纹背景，再通过重建网络得到细裂纹背景，最终生成细裂纹线索。

Result: 实验结果表明，CrackCue显著提高了基线方法的泛化能力和鲁棒性。

Conclusion: CrackCue通过利用裂纹的细长结构特性生成鲁棒的裂纹线索，显著提升了基线方法的泛化能力和鲁棒性。

Abstract: Crack detection is an important task in computer vision. Despite impressive
in-dataset performance, deep learning-based methods still struggle in
generalizing to unseen domains. The thin structure property of cracks is
usually overlooked by previous methods. In this work, we introduce CrackCue, a
novel method for robust crack detection based on coarse-to-fine crack cue
generation. The core concept lies on leveraging the thin structure property to
generate a robust crack cue, guiding the crack detection. Specifically, we
first employ a simple max-pooling and upsampling operation on the crack image.
This results in a coarse crack-free background, based on which a fine
crack-free background can be obtained via a reconstruction network. The
difference between the original image and fine crack-free background provides a
fine crack cue. This fine cue embeds robust crack prior information which is
unaffected by complex backgrounds, shadow, and varied lighting. As a
plug-and-play method, we incorporate the proposed CrackCue into three advanced
crack detection networks. Extensive experimental results demonstrate that the
proposed CrackCue significantly improves the generalization ability and
robustness of the baseline methods. The source code will be publicly available.

</details>


### [4] [CLAMP: Contrastive Learning with Adaptive Multi-loss and Progressive Fusion for Multimodal Aspect-Based Sentiment Analysis](https://arxiv.org/abs/2507.16854)
*Xiaoqiang He*

Main category: cs.CV

TL;DR: CLAMP框架通过渐进式注意力融合、多任务对比学习和自适应多损失聚合，解决了多模态情感分析中的跨模态对齐和表示一致性问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态基于方面的情感分析中存在跨模态对齐噪声和细粒度表示一致性不足的问题，特别是全局模态对齐方法忽略了方面词与其对应局部视觉区域的联系。

Method: CLAMP框架包含三个模块：渐进式注意力融合网络（通过分层多阶段跨模态交互增强细粒度对齐）、多任务对比学习（结合全局模态对比和局部粒度对齐以增强表示一致性）和自适应多损失聚合（基于动态不确定性加权机制校准损失贡献）。

Result: 在标准公共基准测试中，CLAMP框架性能显著优于现有大多数最先进方法。

Conclusion: CLAMP框架通过渐进式注意力融合网络、多任务对比学习和自适应多损失聚合，显著提升了多模态基于方面的情感分析性能，并在标准公共基准测试中超越了现有最先进方法。

Abstract: Multimodal aspect-based sentiment analysis(MABSA) seeks to identify aspect
terms within paired image-text data and determine their fine grained sentiment
polarities, representing a fundamental task for improving the effectiveness of
applications such as product review systems and public opinion monitoring.
Existing methods face challenges such as cross modal alignment noise and
insufficient consistency in fine-grained representations. While global modality
alignment methods often overlook the connection between aspect terms and their
corresponding local visual regions, bridging the representation gap between
text and images remains a challenge. To address these limitations, this paper
introduces an end to end Contrastive Learning framework with Adaptive
Multi-loss and Progressive Attention Fusion(CLAMP). The framework is composed
of three novel modules: Progressive Attention Fusion network, Multi-task
Contrastive Learning, and Adaptive Multi-loss Aggregation. The Progressive
Attention Fusion network enhances fine-grained alignment between textual
features and image regions via hierarchical, multi-stage cross modal
interactions, effectively suppressing irrelevant visual noise. Secondly,
multi-task contrastive learning combines global modal contrast and local
granularity alignment to enhance cross modal representation consistency.
Adaptive Multi-loss Aggregation employs a dynamic uncertainty based weighting
mechanism to calibrate loss contributions according to each task's uncertainty,
thereby mitigating gradient interference. Evaluation on standard public
benchmarks demonstrates that CLAMP consistently outperforms the vast majority
of existing state of the art methods.

</details>


### [5] [SIA: Enhancing Safety via Intent Awareness for Vision-Language Models](https://arxiv.org/abs/2507.16856)
*Youngjin Na,Sangheon Jeong,Youngwan Lee*

Main category: cs.CV

TL;DR: SIA是一个无需训练的框架，通过三阶段推理动态检测和减轻多模态输入中的有害意图，显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型在现实应用中的部署增加，图像与文本的微妙交互可能揭示有害意图，导致不安全模型响应。传统方法难以检测此类潜在风险。

Method: SIA采用三阶段推理过程：视觉抽象（通过字幕生成）、意图推断（通过少样本思维链提示）和意图条件响应精炼。

Result: 在SIUO、MM-SafetyBench和HoliSafe等安全关键基准测试中，SIA显著优于现有方法，展现出安全性的显著提升。

Conclusion: SIA（通过意图意识实现安全）是一个无需训练的提示工程框架，通过动态适应图像-文本对的隐含意图，显著提升了视觉语言模型的安全性，尽管在一般推理准确性上略有下降。

Abstract: As vision-language models (VLMs) are increasingly deployed in real-world
applications, new safety risks arise from the subtle interplay between images
and text. In particular, seemingly innocuous inputs can combine to reveal
harmful intent, leading to unsafe model responses. Despite increasing attention
to multimodal safety, previous approaches based on post hoc filtering or static
refusal prompts struggle to detect such latent risks, especially when
harmfulness emerges only from the combination of inputs. We propose SIA (Safety
via Intent Awareness), a training-free prompt engineering framework that
proactively detects and mitigates harmful intent in multimodal inputs. SIA
employs a three-stage reasoning process: (1) visual abstraction via captioning,
(2) intent inference through few-shot chain-of-thought prompting, and (3)
intent-conditioned response refinement. Rather than relying on predefined rules
or classifiers, SIA dynamically adapts to the implicit intent inferred from the
image-text pair. Through extensive experiments on safety-critical benchmarks
including SIUO, MM-SafetyBench, and HoliSafe, we demonstrate that SIA achieves
substantial safety improvements, outperforming prior methods. Although SIA
shows a minor reduction in general reasoning accuracy on MMStar, the
corresponding safety gains highlight the value of intent-aware reasoning in
aligning VLMs with human-centric values.

</details>


### [6] [Look Before You Fuse: 2D-Guided Cross-Modal Alignment for Robust 3D Detection](https://arxiv.org/abs/2507.16861)
*Xiang Li*

Main category: cs.CV

TL;DR: 利用2D目标先验校正LiDAR与相机特征错位，提出PGDC、DAGF、SGDM三阶段方法，显著提升BEV融合效果，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR与相机特征因标定误差和运动导致的投影错位问题，利用2D目标先验预对齐特征以提升融合精度。

Method: 提出Prior Guided Depth Calibration (PGDC)局部校正特征对齐，Discontinuity Aware Geometric Fusion (DAGF)全局抑制噪声并增强边界，以及Structural Guidance Depth Modulator (SGDM)高效融合对齐特征。

Result: 在nuScenes验证集上达到mAP 71.5%和NDS 73.6%的SOTA性能。

Conclusion: 通过结合2D目标先验和创新的特征对齐方法，该研究显著提升了LiDAR与相机特征的融合效果，在nuScenes数据集上实现了最优性能（mAP 71.5%，NDS 73.6%）。

Abstract: Integrating LiDAR and camera inputs into a unified Bird's-Eye-View (BEV)
representation is crucial for enhancing 3D perception capabilities of
autonomous vehicles. However, current methods are often affected by
misalignment between camera and LiDAR features. This misalignment leads to
inaccurate depth supervision in camera branch and erroneous fusion during
cross-modal feature aggregation. The root cause of this misalignment lies in
projection errors, stemming from minor extrinsic calibration inaccuracies and
rolling shutter effect of LiDAR during vehicle motion. In this work, our key
insight is that these projection errors are predominantly concentrated at
object-background boundaries, which are readily identified by 2D detectors.
Based on this, our main motivation is to utilize 2D object priors to pre-align
cross-modal features before fusion. To address local misalignment, we propose
Prior Guided Depth Calibration (PGDC), which leverages 2D priors to correct
local misalignment and preserve correct cross-modal feature pairs. To resolve
global misalignment, we introduce Discontinuity Aware Geometric Fusion (DAGF)
to process calibrated results from PGDC, suppressing noise and explicitly
enhancing sharp transitions at object-background boundaries. To effectively
utilize these transition-aware depth representations, we incorporate Structural
Guidance Depth Modulator (SGDM), using a gated attention mechanism to
efficiently fuse aligned depth and image features. Our proposed method achieves
state-of-the-art performance on nuScenes validation dataset, with its mAP and
NDS reaching 71.5% and 73.6% respectively.

</details>


### [7] [Pixels, Patterns, but No Poetry: To See The World like Humans](https://arxiv.org/abs/2507.16863)
*Hongcheng Gao,Zihao Huang,Lin Xu,Jingyi Tang,Xinhao Li,Yue Liu,Haoyang Li,Taihang Hu,Minhua Lin,Xinlong Yang,Ge Wu,Balong Bi,Hongyu Chen,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文提出图灵眼测试（TET）评估MLLMs的感知能力，发现当前模型在人类直觉任务中表现极差，视觉模块微调是唯一有效的改进方法，揭示了MLLMs与人类感知的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在推理能力上取得了进展，但其是否具备类似人类的感知能力仍是一个核心问题。本文旨在填补这一研究空白，通过设计感知导向的基准测试来评估MLLMs的真实感知能力。

Method: 本文提出了图灵眼测试（TET），一个专注于感知的基准测试，包含四个诊断任务，用于评估MLLMs在合成图像上的表现。通过对比上下文学习、语言主干训练和视觉模块微调的效果，分析了MLLMs的感知能力。

Result: 实验结果表明，当前最先进的MLLMs在TET任务中表现极差，甚至无法完成对人类来说简单的任务。上下文学习和语言主干训练均无法提升性能，而视觉模块的微调则显著改善了表现，揭示了视觉泛化能力的关键作用。

Conclusion: 当前的多模态大型语言模型（MLLMs）在视觉感知任务上存在显著不足，尤其是在人类直觉处理的合成图像任务中表现极差。通过微调视觉模块可以快速适应，但语言主干的知识和推理能力无法弥补这一差距，突显了MLLMs与人类感知之间的关键差异。

Abstract: Achieving human-like perception and reasoning in Multimodal Large Language
Models (MLLMs) remains a central challenge in artificial intelligence. While
recent research has primarily focused on enhancing reasoning capabilities in
MLLMs, a fundamental question persists: Can Multimodal Large Language Models
truly perceive the world as humans do? This paper shifts focus from reasoning
to perception. Rather than constructing benchmarks specifically for reasoning,
we introduce the Turing Eye Test (TET), a challenging perception-oriented
benchmark comprising four diagnostic tasks that evaluate MLLMs' performance on
synthetic images that humans process intuitively. Our findings reveal that
state-of-the-art MLLMs exhibit catastrophic failures on our perceptual tasks
trivial for humans. Both in-context learning and training on language
backbone-effective for previous benchmarks-fail to improve performance on our
tasks, while fine-tuning the vision tower enables rapid adaptation, suggesting
that our benchmark poses challenges for vision tower generalization rather than
for the knowledge and reasoning capabilities of the language backbone-a key gap
between current MLLMs and human perception. We release a representative subset
of TET tasks in this version, and will introduce more diverse tasks and methods
to enhance visual generalization in future work.

</details>


### [8] [HIPPO-Video: Simulating Watch Histories with Large Language Models for Personalized Video Highlighting](https://arxiv.org/abs/2507.16873)
*Jeongeun Lee,Youngjae Yu,Dongha Lee*

Main category: cs.CV

TL;DR: HIPPO-Video是一个个性化视频高亮数据集，通过LLM模拟用户生成多样化偏好数据，HiPHer方法利用这些数据显著提升高亮效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频数据集缺乏个性化，无法捕捉用户行为的复杂性，因此需要创建反映多样用户偏好的数据集。

Method: 提出HiPHer方法，利用个性化观看历史预测偏好条件下的片段显著性分数。

Result: HIPPO-Video数据集包含2,040对（观看历史，显著性分数），覆盖170个语义类别，实验证明HiPHer方法优于现有方法。

Conclusion: HIPPO-Video数据集和HiPHer方法在个性化视频高亮任务中表现出色，优于现有通用和基于查询的方法，展示了其在真实场景中的潜力。

Abstract: The exponential growth of video content has made personalized video
highlighting an essential task, as user preferences are highly variable and
complex. Existing video datasets, however, often lack personalization, relying
on isolated videos or simple text queries that fail to capture the intricacies
of user behavior. In this work, we introduce HIPPO-Video, a novel dataset for
personalized video highlighting, created using an LLM-based user simulator to
generate realistic watch histories reflecting diverse user preferences. The
dataset includes 2,040 (watch history, saliency score) pairs, covering 20,400
videos across 170 semantic categories. To validate our dataset, we propose
HiPHer, a method that leverages these personalized watch histories to predict
preference-conditioned segment-wise saliency scores. Through extensive
experiments, we demonstrate that our method outperforms existing generic and
query-based approaches, showcasing its potential for highly user-centric video
highlighting in real-world scenarios.

</details>


### [9] [ReMeREC: Relation-aware and Multi-entity Referring Expression Comprehension](https://arxiv.org/abs/2507.16877)
*Yizhi Hu,Zezhao Tian,Xingqun Qi,Chen Su,Bingkun Yang,Junhui Yin,Muyi Sun,Man Zhang,Zhenan Sun*

Main category: cs.CV

TL;DR: ReMeREC是一个新框架，通过动态推断实体和增强关系推理，提升了多实体场景中的定位和关系建模能力，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多实体场景中忽略复杂实体间关系，且缺乏高质量的数据集，限制了准确性和可靠性。

Method: 提出ReMeREC框架，包括Text-adaptive Multi-entity Perceptron (TMP)和Entity Inter-relationship Reasoner (EIR)，用于动态推断实体数量和范围，并增强关系推理。

Result: 在四个基准数据集上的实验表明，ReMeREC在多实体定位和关系预测方面达到了最先进的性能。

Conclusion: ReMeREC通过结合视觉和文本线索，成功地在多实体场景中实现了准确的定位和关系建模，显著优于现有方法。

Abstract: Referring Expression Comprehension (REC) aims to localize specified entities
or regions in an image based on natural language descriptions. While existing
methods handle single-entity localization, they often ignore complex
inter-entity relationships in multi-entity scenes, limiting their accuracy and
reliability. Additionally, the lack of high-quality datasets with fine-grained,
paired image-text-relation annotations hinders further progress. To address
this challenge, we first construct a relation-aware, multi-entity REC dataset
called ReMeX, which includes detailed relationship and textual annotations. We
then propose ReMeREC, a novel framework that jointly leverages visual and
textual cues to localize multiple entities while modeling their
inter-relations. To address the semantic ambiguity caused by implicit entity
boundaries in language, we introduce the Text-adaptive Multi-entity Perceptron
(TMP), which dynamically infers both the quantity and span of entities from
fine-grained textual cues, producing distinctive representations. Additionally,
our Entity Inter-relationship Reasoner (EIR) enhances relational reasoning and
global scene understanding. To further improve language comprehension for
fine-grained prompts, we also construct a small-scale auxiliary dataset,
EntityText, generated using large language models. Experiments on four
benchmark datasets show that ReMeREC achieves state-of-the-art performance in
multi-entity grounding and relation prediction, outperforming existing
approaches by a large margin.

</details>


### [10] [CausalStep: A Benchmark for Explicit Stepwise Causal Reasoning in Videos](https://arxiv.org/abs/2507.16878)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang,Wentao Zhang*

Main category: cs.CV

TL;DR: CausalStep 是一个针对视频逐步因果推理的基准，通过严格设计和诊断指标揭示当前模型与人类推理能力的差距。


<details>
  <summary>Details</summary>
Motivation: 现有视频基准主要评估浅层理解和推理，允许模型利用全局上下文，未能严格评估真实的因果和逐步推理。

Method: CausalStep 将视频分割为因果关联的单元，并采用严格的逐步问答协议，要求顺序回答并防止捷径解决方案。每个问题包括基于错误类型分类的干扰项。

Result: CausalStep 包含100个视频和1,852个多选题对，引入七种诊断指标。实验显示当前模型与人类逐步推理能力存在显著差距。

Conclusion: CausalStep 提供了一个严格的基准，推动稳健和可解释的视频推理进展。

Abstract: Recent advances in large language models (LLMs) have improved reasoning in
text and image domains, yet achieving robust video reasoning remains a
significant challenge. Existing video benchmarks mainly assess shallow
understanding and reasoning and allow models to exploit global context, failing
to rigorously evaluate true causal and stepwise reasoning. We present
CausalStep, a benchmark designed for explicit stepwise causal reasoning in
videos. CausalStep segments videos into causally linked units and enforces a
strict stepwise question-answer (QA) protocol, requiring sequential answers and
preventing shortcut solutions. Each question includes carefully constructed
distractors based on error type taxonomy to ensure diagnostic value. The
benchmark features 100 videos across six categories and 1,852 multiple-choice
QA pairs. We introduce seven diagnostic metrics for comprehensive evaluation,
enabling precise diagnosis of causal reasoning capabilities. Experiments with
leading proprietary and open-source models, as well as human baselines, reveal
a significant gap between current models and human-level stepwise reasoning.
CausalStep provides a rigorous benchmark to drive progress in robust and
interpretable video reasoning.

</details>


### [11] [Finding Dori: Memorization in Text-to-Image Diffusion Models Is Less Local Than Assumed](https://arxiv.org/abs/2507.16880)
*Antoni Kowalczuk,Dominik Hintersdorf,Lukas Struppek,Kristian Kersting,Adam Dziedzic,Franziska Boenisch*

Main category: cs.CV

TL;DR: 文本到图像扩散模型的数据记忆问题现有缓解策略不足，作者提出对抗性微调方法增强鲁棒性，挑战记忆局部性假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对文本到图像扩散模型可能无意中记忆和复制训练数据的数据隐私和知识产权问题的担忧。尽管已有缓解努力集中于识别和剪枝触发复制的权重，但作者质疑这些方法的有效性。

Method: 研究评估了基于剪枝的防御方法的鲁棒性，并挑战了记忆局部性的基本假设。通过展示即使剪枝后，输入提示的文本嵌入的微小调整仍可重新触发数据复制，证明了这些防御的脆弱性。此外，作者提出了一种迭代搜索复制触发器并更新模型以增强鲁棒性的对抗性微调方法。

Result: 研究表明，现有剪枝方法无法有效防止数据复制，且记忆并不局限于模型的特定部分。作者提出的对抗性微调方法展示了提高模型鲁棒性的潜力。

Conclusion: 文本到图像扩散模型（DMs）中数据记忆问题的现有缓解策略不足，需要开发真正移除记忆内容的方法。作者提出了一种新颖的对抗性微调方法，为构建更可信和合规的生成AI奠定了基础。

Abstract: Text-to-image diffusion models (DMs) have achieved remarkable success in
image generation. However, concerns about data privacy and intellectual
property remain due to their potential to inadvertently memorize and replicate
training data. Recent mitigation efforts have focused on identifying and
pruning weights responsible for triggering replication, based on the assumption
that memorization can be localized. Our research assesses the robustness of
these pruning-based approaches. We demonstrate that even after pruning, minor
adjustments to text embeddings of input prompts are sufficient to re-trigger
data replication, highlighting the fragility of these defenses. Furthermore, we
challenge the fundamental assumption of memorization locality, by showing that
replication can be triggered from diverse locations within the text embedding
space, and follows different paths in the model. Our findings indicate that
existing mitigation strategies are insufficient and underscore the need for
methods that truly remove memorized content, rather than attempting to suppress
its retrieval. As a first step in this direction, we introduce a novel
adversarial fine-tuning method that iteratively searches for replication
triggers and updates the model to increase robustness. Through our research, we
provide fresh insights into the nature of memorization in text-to-image DMs and
a foundation for building more trustworthy and compliant generative AI.

</details>


### [12] [Sparser2Sparse: Single-shot Sparser-to-Sparse Learning for Spatial Transcriptomics Imputation with Natural Image Co-learning](https://arxiv.org/abs/2507.16886)
*Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee A. Cooper,Bo Zhou*

Main category: cs.CV

TL;DR: S2S-ST是一种新型ST插补框架，通过自监督学习和跨域协同学习，仅需稀疏ST数据和自然图像即可实现高精度插补，显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 高成本和高分辨率ST数据的稀缺性是当前生物医学研究的重大挑战。

Method: S2S-ST整合了三个关键创新：1) 利用ST数据内在空间模式的自监督学习策略，2) 与自然图像的跨域协同学习以增强特征表示，3) 迭代优化预测并保持采样基因数据保真度的Cascaded Data Consistent Imputation Network (CDCIN)。

Result: 在多种组织类型（如乳腺癌、肝脏和淋巴组织）上的广泛实验表明，S2S-ST在插补准确性上优于现有最优方法。

Conclusion: S2S-ST框架通过仅需单一低成本的稀疏采样ST数据集和广泛可用的自然图像进行协同训练，显著降低了对高成本高分辨率数据的依赖，促进了生物医学研究和临床应用的更广泛采用。

Abstract: Spatial transcriptomics (ST) has revolutionized biomedical research by
enabling high resolution gene expression profiling within tissues. However, the
high cost and scarcity of high resolution ST data remain significant
challenges. We present Single-shot Sparser-to-Sparse (S2S-ST), a novel
framework for accurate ST imputation that requires only a single and low-cost
sparsely sampled ST dataset alongside widely available natural images for
co-training. Our approach integrates three key innovations: (1) a
sparser-to-sparse self-supervised learning strategy that leverages intrinsic
spatial patterns in ST data, (2) cross-domain co-learning with natural images
to enhance feature representation, and (3) a Cascaded Data Consistent
Imputation Network (CDCIN) that iteratively refines predictions while
preserving sampled gene data fidelity. Extensive experiments on diverse tissue
types, including breast cancer, liver, and lymphoid tissue, demonstrate that
our method outperforms state-of-the-art approaches in imputation accuracy. By
enabling robust ST reconstruction from sparse inputs, our framework
significantly reduces reliance on costly high resolution data, facilitating
potential broader adoption in biomedical research and clinical applications.

</details>


### [13] [AURA: A Multi-Modal Medical Agent for Understanding, Reasoning & Annotation](https://arxiv.org/abs/2507.16940)
*Nima Fathi,Amar Kumar,Tal Arbel*

Main category: cs.CV

TL;DR: AURA是首个专为医学图像设计的视觉语言解释代理，基于Qwen-32B架构，整合了分割、反事实生成和评估工具，提升了AI在医学影像中的透明度和交互性。


<details>
  <summary>Details</summary>
Motivation: 尽管基于LLM的代理系统在许多领域表现出潜力，但在医学影像领域的应用仍处于初级阶段。AURA旨在填补这一空白，提供全面的医学图像分析和解释。

Method: AURA基于Qwen-32B架构，整合了模块化工具箱，包括分割套件、反事实图像生成模块和评估工具。

Result: AURA通过动态交互、上下文解释和假设测试，实现了对医学图像的全面分析和解释，推动了AI系统在医学领域的透明度和适应性。

Conclusion: AURA代表了向更透明、适应性强且与临床需求对齐的AI系统迈出的重要一步，展示了代理式AI在医学图像分析中的潜力。

Abstract: Recent advancements in Large Language Models (LLMs) have catalyzed a paradigm
shift from static prediction systems to agentic AI agents capable of reasoning,
interacting with tools, and adapting to complex tasks. While LLM-based agentic
systems have shown promise across many domains, their application to medical
imaging remains in its infancy. In this work, we introduce AURA, the first
visual linguistic explainability agent designed specifically for comprehensive
analysis, explanation, and evaluation of medical images. By enabling dynamic
interactions, contextual explanations, and hypothesis testing, AURA represents
a significant advancement toward more transparent, adaptable, and clinically
aligned AI systems. We highlight the promise of agentic AI in transforming
medical image analysis from static predictions to interactive decision support.
Leveraging Qwen-32B, an LLM-based architecture, AURA integrates a modular
toolbox comprising: (i) a segmentation suite with phase grounding, pathology
segmentation, and anatomy segmentation to localize clinically meaningful
regions; (ii) a counterfactual image-generation module that supports reasoning
through image-level explanations; and (iii) a set of evaluation tools including
pixel-wise difference-map analysis, classification, and advanced
state-of-the-art components to assess diagnostic relevance and visual
interpretability.

</details>


### [14] [Toward Long-Tailed Online Anomaly Detection through Class-Agnostic Concepts](https://arxiv.org/abs/2507.16946)
*Chiao-An Yang,Kuan-Chuan Peng,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 论文提出了一种类不可知的长尾在线异常检测框架，解决了在线设置中无法获取类标签的问题，并在多个离线设置中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决在线设置中无法获取类标签的问题，并扩展长尾异常检测（LTAD）到在线学习场景，作者提出了长尾在线异常检测（LTOAD）任务。

Method: 论文首先识别了离线LTAD方法无法直接应用于在线设置的问题，提出了一个类不可知的LTAD框架，并将其适应于在线学习设置。

Result: 在离线LTAD设置中，该方法在MVTec上比现有方法提高了4.63%的图像AUROC；在最具挑战性的长尾在线设置中，比基线方法提高了0.53%的图像AUROC。

Conclusion: 该论文提出了一种类不可知的长尾在线异常检测（LTOAD）框架，并在多个离线长尾异常检测（LTAD）设置中表现出优于现有方法的性能，特别是在工业制造和医疗领域。

Abstract: Anomaly detection (AD) identifies the defect regions of a given image. Recent
works have studied AD, focusing on learning AD without abnormal images, with
long-tailed distributed training data, and using a unified model for all
classes. In addition, online AD learning has also been explored. In this work,
we expand in both directions to a realistic setting by considering the novel
task of long-tailed online AD (LTOAD). We first identified that the offline
state-of-the-art LTAD methods cannot be directly applied to the online setting.
Specifically, LTAD is class-aware, requiring class labels that are not
available in the online setting. To address this challenge, we propose a
class-agnostic framework for LTAD and then adapt it to our online learning
setting. Our method outperforms the SOTA baselines in most offline LTAD
settings, including both the industrial manufacturing and the medical domain.
In particular, we observe +4.63% image-AUROC on MVTec even compared to methods
that have access to class labels and the number of classes. In the most
challenging long-tailed online setting, we achieve +0.53% image-AUROC compared
to baselines. Our LTOAD benchmark is released here:
https://doi.org/10.5281/zenodo.16283852 .

</details>


### [15] [Divisive Decisions: Improving Salience-Based Training for Generalization in Binary Classification Tasks](https://arxiv.org/abs/2507.17000)
*Jacob Piland,Chris Sweet,Adam Czajka*

Main category: cs.CV

TL;DR: 本文提出结合真实类和错误类CAM的三种新训练方法，显著提升了二分类任务的模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在二分类任务中，真实类和错误类的CAM应该在人类识别的重要特征上有所差异，这一假设被用来改进模型的训练策略。

Method: 提出了三种新的显著性引导训练方法，结合了真实类和错误类的CAM，并开发了一种新颖的后处理工具来识别重要特征。

Result: 在多种二分类任务（如合成人脸检测、生物特征呈现攻击检测和胸部X射线扫描异常分类）中，新方法显著提升了模型的泛化能力。

Conclusion: 提出的方法通过结合真实类和错误类的CAM，显著提高了深度学习模型的泛化能力，超越了传统仅使用真实类CAM的方法。

Abstract: Existing saliency-guided training approaches improve model generalization by
incorporating a loss term that compares the model's class activation map (CAM)
for a sample's true-class ({\it i.e.}, correct-label class) against a human
reference saliency map. However, prior work has ignored the false-class CAM(s),
that is the model's saliency obtained for incorrect-label class. We hypothesize
that in binary tasks the true and false CAMs should diverge on the important
classification features identified by humans (and reflected in human saliency
maps). We use this hypothesis to motivate three new saliency-guided training
methods incorporating both true- and false-class model's CAM into the training
strategy and a novel post-hoc tool for identifying important features. We
evaluate all introduced methods on several diverse binary close-set and
open-set classification tasks, including synthetic face detection, biometric
presentation attack detection, and classification of anomalies in chest X-ray
scans, and find that the proposed methods improve generalization capabilities
of deep learning models over traditional (true-class CAM only) saliency-guided
training approaches. We offer source codes and model weights\footnote{GitHub
repository link removed to preserve anonymity} to support reproducible
research.

</details>


### [16] [Bringing Balance to Hand Shape Classification: Mitigating Data Imbalance Through Generative Models](https://arxiv.org/abs/2507.17008)
*Gaston Gustavo Rios,Pedro Dal Bianco,Franco Ronchetti,Facundo Quiroga,Oscar Stanchi,Santiago Ponte Ahón,Waldo Hasperué*

Main category: cs.CV

TL;DR: 通过GAN生成合成数据增强手语手势分类器训练，提升准确率5%并实现跨数据集泛化。


<details>
  <summary>Details</summary>
Motivation: 解决手语手势数据集小且不平衡的问题，提升分类器性能。

Method: 使用EfficientNet分类器，结合两种GAN架构（ReACGAN和SPADE）生成合成数据。ReACGAN通过辅助分类器利用标签信息，SPADE则利用空间自适应归一化基于姿态信息生成图像。

Result: 在RWTH数据集上准确率提升5%，并展示了跨数据集泛化的能力。

Conclusion: 通过合成数据增强方法，显著提升了手语手势分类器的性能，解决了数据集小且不平衡的问题，并在跨数据集泛化方面表现出色。

Abstract: Most sign language handshape datasets are severely limited and unbalanced,
posing significant challenges to effective model training. In this paper, we
explore the effectiveness of augmenting the training data of a handshape
classifier by generating synthetic data. We use an EfficientNet classifier
trained on the RWTH German sign language handshape dataset, which is small and
heavily unbalanced, applying different strategies to combine generated and real
images. We compare two Generative Adversarial Networks (GAN) architectures for
data generation: ReACGAN, which uses label information to condition the data
generation process through an auxiliary classifier, and SPADE, which utilizes
spatially-adaptive normalization to condition the generation on pose
information. ReACGAN allows for the generation of realistic images that align
with specific handshape labels, while SPADE focuses on generating images with
accurate spatial handshape configurations. Our proposed techniques improve the
current state-of-the-art accuracy on the RWTH dataset by 5%, addressing the
limitations of small and unbalanced datasets. Additionally, our method
demonstrates the capability to generalize across different sign language
datasets by leveraging pose-based generation trained on the extensive HaGRID
dataset. We achieve comparable performance to single-source trained classifiers
without the need for retraining the generator.

</details>


### [17] [Transformer Based Building Boundary Reconstruction using Attraction Field Maps](https://arxiv.org/abs/2507.17038)
*Muhammad Kamran,Mohammad Moein Sheikholeslami,Andreas Wichmann,Gunho Sohn*

Main category: cs.CV

TL;DR: 论文提出了一种基于GCNs的深度学习方法Decoupled-PolyGCN，通过整合几何规则性和多尺度特征，显著提升了卫星图像中建筑物轮廓的自动提取精度。


<details>
  <summary>Details</summary>
Motivation: 由于卫星图像中基于基元的对象表示仍是一个挑战，高质量空间地图往往依赖人工处理，因此需要一种自动化且精确的方法来重建建筑物轮廓。

Method: 利用图卷积网络（GCNs），结合几何规则性、多尺度多分辨率特征以及吸引力场图（Attraction Field Maps），提出了一种名为Decoupled-PolyGCN的深度学习模型。

Result: Decoupled-PolyGCN模型在AP和AR指标上分别比现有方法提升了6%和10%，能够在多样化和具有挑战性的场景中生成准确且规则化的建筑物轮廓。

Conclusion: 论文提出了一种基于图卷积网络（GCNs）的新方法Decoupled-PolyGCN，显著提升了从单张卫星图像中自动提取建筑物轮廓的精度和效率，为城市规划、灾害管理等应用提供了可扩展且精确的解决方案。

Abstract: In recent years, the number of remote satellites orbiting the Earth has grown
significantly, streaming vast amounts of high-resolution visual data to support
diverse applications across civil, public, and military domains. Among these
applications, the generation and updating of spatial maps of the built
environment have become critical due to the extensive coverage and detailed
imagery provided by satellites. However, reconstructing spatial maps from
satellite imagery is a complex computer vision task, requiring the creation of
high-level object representations, such as primitives, to accurately capture
the built environment. While the past decade has witnessed remarkable
advancements in object detection and representation using visual data,
primitives-based object representation remains a persistent challenge in
computer vision. Consequently, high-quality spatial maps often rely on
labor-intensive and manual processes. This paper introduces a novel deep
learning methodology leveraging Graph Convolutional Networks (GCNs) to address
these challenges in building footprint reconstruction. The proposed approach
enhances performance by incorporating geometric regularity into building
boundaries, integrating multi-scale and multi-resolution features, and
embedding Attraction Field Maps into the network. These innovations provide a
scalable and precise solution for automated building footprint extraction from
a single satellite image, paving the way for impactful applications in urban
planning, disaster management, and large-scale spatial analysis. Our model,
Decoupled-PolyGCN, outperforms existing methods by 6% in AP and 10% in AR,
demonstrating its ability to deliver accurate and regularized building
footprints across diverse and challenging scenarios.

</details>


### [18] [Controllable Hybrid Captioner for Improved Long-form Video Understanding](https://arxiv.org/abs/2507.17047)
*Kuleen Sasse,Efsun Sarioglu Kayi,Arun Reddy*

Main category: cs.CV

TL;DR: 通过文本摘要和LLM推理，构建了一个高效的长视频理解系统，结合动作和场景描述，提升了字幕质量和可回答问题范围。


<details>
  <summary>Details</summary>
Motivation: 解决长视频的高维度和信息密度问题，通过文本摘要提供紧凑且易于LLM处理的视频内容表示。

Method: 使用LaViLa视频字幕生成器处理视频短片段，结合LLM进行推理。探索视频分割方法以更准确反映视频内容结构，并利用LLaVA VLM引入静态场景描述。微调LaViLa以生成混合字幕（动作和场景描述）。

Result: 成功构建了可控混合字幕生成器，能够根据视频场景变化生成不同类型的字幕，显著提高了字幕日志的详细性和完整性，扩大了可回答问题的范围。

Conclusion: 通过结合LaViLa视频字幕生成器和LLM，成功构建了一个能够回答视频相关问题的视频理解系统。通过改进视频分割方式和引入静态场景描述，显著提升了字幕日志的质量和可回答问题范围。此外，通过微调LaViLa生成混合字幕，进一步提高了字幕生成效率。

Abstract: Video data, especially long-form video, is extremely dense and
high-dimensional. Text-based summaries of video content offer a way to
represent query-relevant content in a much more compact manner than raw video.
In addition, textual representations are easily ingested by state-of-the-art
large language models (LLMs), which enable reasoning over video content to
answer complex natural language queries. To solve this issue, we rely on the
progressive construction of a text-based memory by a video captioner operating
on shorter chunks of the video, where spatio-temporal modeling is
computationally feasible. We explore ways to improve the quality of the
activity log comprised solely of short video captions. Because the video
captions tend to be focused on human actions, and questions may pertain to
other information in the scene, we seek to enrich the memory with static scene
descriptions using Vision Language Models (VLMs). Our video understanding
system relies on the LaViLa video captioner in combination with a LLM to answer
questions about videos. We first explored different ways of partitioning the
video into meaningful segments such that the textual descriptions more
accurately reflect the structure of the video content. Furthermore, we
incorporated static scene descriptions into the captioning pipeline using LLaVA
VLM, resulting in a more detailed and complete caption log and expanding the
space of questions that are answerable from the textual memory. Finally, we
have successfully fine-tuned the LaViLa video captioner to produce both action
and scene captions, significantly improving the efficiency of the captioning
pipeline compared to using separate captioning models for the two tasks. Our
model, controllable hybrid captioner, can alternate between different types of
captions according to special input tokens that signals scene changes detected
in the video.

</details>


### [19] [Toward Scalable Video Narration: A Training-free Approach Using Multimodal Large Language Models](https://arxiv.org/abs/2507.17050)
*Tz-Ying Wu,Tahani Trigui,Sharath Nittur Sridhar,Anand Bodas,Subarna Tripathi*

Main category: cs.CV

TL;DR: VideoNarrator 是一种无需训练的流程，通过现成模型协同工作，生成高质量、时间对齐的视频字幕，减少幻觉并支持下游任务。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在视频理解方面取得了进展，但在时间对齐的叙述上仍存在困难，且容易在陌生场景中产生幻觉。VideoNarrator 旨在解决这些问题。

Method: VideoNarrator 采用了一种灵活的流程，利用现成的多模态大语言模型（MLLMs）和视觉语言模型（VLMs）作为字幕生成器、上下文提供者或字幕验证器。

Result: 实验结果表明，VideoNarrator 通过各组件协同作用，显著提升了视频叙述的质量和准确性。

Conclusion: VideoNarrator 的有效性通过实验验证，显著提升了视频叙述的质量和准确性，减少了幻觉并改善了时间对齐。

Abstract: In this paper, we introduce VideoNarrator, a novel training-free pipeline
designed to generate dense video captions that offer a structured snapshot of
video content. These captions offer detailed narrations with precise
timestamps, capturing the nuances present in each segment of the video. Despite
advancements in multimodal large language models (MLLMs) for video
comprehension, these models often struggle with temporally aligned narrations
and tend to hallucinate, particularly in unfamiliar scenarios. VideoNarrator
addresses these challenges by leveraging a flexible pipeline where
off-the-shelf MLLMs and visual-language models (VLMs) can function as caption
generators, context providers, or caption verifiers. Our experimental results
demonstrate that the synergistic interaction of these components significantly
enhances the quality and accuracy of video narrations, effectively reducing
hallucinations and improving temporal alignment. This structured approach not
only enhances video understanding but also facilitates downstream tasks such as
video summarization and video question answering, and can be potentially
extended for advertising and marketing applications.

</details>


### [20] [Few-Shot Learning in Video and 3D Object Detection: A Survey](https://arxiv.org/abs/2507.17079)
*Md Meftahul Ferdaus,Kendall N. Niles,Joe Tom,Mahdi Abdelguerfi,Elias Ioup*

Main category: cs.CV

TL;DR: This survey explores few-shot learning (FSL) for video and 3D object detection, emphasizing techniques to minimize annotation costs and enable practical deployment in real-world applications.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the laborious and costly manual annotation process in video and 3D object detection by leveraging few-shot learning to recognize novel classes with minimal labeled examples.

Method: The survey examines recent FSL advancements in video and 3D object detection, focusing on techniques like tube proposals, temporal matching networks for video, and specialized point cloud networks for 3D data.

Result: The survey highlights effective FSL techniques for video and 3D detection, addressing challenges like sparsity and class imbalance, and showcases their potential to reduce annotation needs.

Conclusion: Few-shot learning (FSL) demonstrates significant potential in reducing annotation requirements for video and 3D object detection, enabling practical deployment in real-world applications by leveraging spatiotemporal and data modality information.

Abstract: Few-shot learning (FSL) enables object detection models to recognize novel
classes given only a few annotated examples, thereby reducing expensive manual
data labeling. This survey examines recent FSL advances for video and 3D object
detection. For video, FSL is especially valuable since annotating objects
across frames is more laborious than for static images. By propagating
information across frames, techniques like tube proposals and temporal matching
networks can detect new classes from a couple examples, efficiently leveraging
spatiotemporal structure. FSL for 3D detection from LiDAR or depth data faces
challenges like sparsity and lack of texture. Solutions integrate FSL with
specialized point cloud networks and losses tailored for class imbalance.
Few-shot 3D detection enables practical autonomous driving deployment by
minimizing costly 3D annotation needs. Core issues in both domains include
balancing generalization and overfitting, integrating prototype matching, and
handling data modality properties. In summary, FSL shows promise for reducing
annotation requirements and enabling real-world video, 3D, and other
applications by efficiently leveraging information across feature, temporal,
and data modalities. By comprehensively surveying recent advancements, this
paper illuminates FSL's potential to minimize supervision needs and enable
deployment across video, 3D, and other real-world applications.

</details>


### [21] [SDGOCC: Semantic and Depth-Guided Bird's-Eye View Transformation for 3D Multimodal Occupancy Prediction](https://arxiv.org/abs/2507.17083)
*Zaipeng Duan,Chenxu Dang,Xuzhong Hu,Pei An,Junfeng Ding,Jie Zhan,Yunbiao Xu,Jie Ma*

Main category: cs.CV

TL;DR: SDG-OCC 是一种新型多模态 3D 占用预测网络，通过联合语义和深度引导的视图转换及主动蒸馏，解决了现有单模态方法的局限性，在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的单模态方法（如基于摄像头的方法缺乏深度信息，基于 LiDAR 的方法难以处理遮挡）和轻量级方法（如 LSS 管道）在深度估计和利用 3D LiDAR 点的几何和语义信息方面存在不足。

Method: SDG-OCC 结合了联合语义和深度引导的视图转换以及融合到占用驱动的主动蒸馏。SDG-Fusion 仅使用融合，而 SDG-KL 结合了融合和蒸馏以实现更快的推理。

Result: 在 Occ3D-nuScenes 数据集上实现了实时处理的最先进性能，并在 SurroundOcc-nuScenes 数据集上表现出了相当的鲁棒性。

Conclusion: SDG-OCC 在 Occ3D-nuScenes 数据集上实现了最先进的性能，并在更具挑战性的 SurroundOcc-nuScenes 数据集上表现出了相当的鲁棒性。

Abstract: Multimodal 3D occupancy prediction has garnered significant attention for its
potential in autonomous driving. However, most existing approaches are
single-modality: camera-based methods lack depth information, while LiDAR-based
methods struggle with occlusions. Current lightweight methods primarily rely on
the Lift-Splat-Shoot (LSS) pipeline, which suffers from inaccurate depth
estimation and fails to fully exploit the geometric and semantic information of
3D LiDAR points. Therefore, we propose a novel multimodal occupancy prediction
network called SDG-OCC, which incorporates a joint semantic and depth-guided
view transformation coupled with a fusion-to-occupancy-driven active
distillation. The enhanced view transformation constructs accurate depth
distributions by integrating pixel semantics and co-point depth through
diffusion and bilinear discretization. The fusion-to-occupancy-driven active
distillation extracts rich semantic information from multimodal data and
selectively transfers knowledge to image features based on LiDAR-identified
regions. Finally, for optimal performance, we introduce SDG-Fusion, which uses
fusion alone, and SDG-KL, which integrates both fusion and distillation for
faster inference. Our method achieves state-of-the-art (SOTA) performance with
real-time processing on the Occ3D-nuScenes dataset and shows comparable
performance on the more challenging SurroundOcc-nuScenes dataset, demonstrating
its effectiveness and robustness. The code will be released at
https://github.com/DzpLab/SDGOCC.

</details>


### [22] [FedVLM: Scalable Personalized Vision-Language Models through Federated Learning](https://arxiv.org/abs/2507.17088)
*Arkajyoti Mitra,Afia Anjum,Paul Agbaje,Mert Pesé,Habeeb Olufowobi*

Main category: cs.CV

TL;DR: FedVLM框架通过个性化LoRA（pLoRA）在联邦学习中优化VLMs微调，显著提升非iid数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决在联邦环境中微调VLMs时的数据分散性和非独立同分布（non-iid）问题，现有方法如LoRA在异构数据上表现不佳。

Method: 提出了FedVLM框架，结合个性化的LoRA（pLoRA），动态调整每个客户的LoRA参数以适应其独特的数据分布。

Result: 在RLAIF-V数据集上的实验显示，pLoRA比标准LoRA提高了24.5%的客户特定性能。

Conclusion: FedVLM提供了一个可扩展且高效的解决方案，用于在联邦设置中微调VLMs，推动了分布式学习场景中的个性化适应。

Abstract: Vision-language models (VLMs) demonstrate impressive zero-shot and few-shot
learning capabilities, making them essential for several downstream tasks.
However, fine-tuning these models at scale remains challenging, particularly in
federated environments where data is decentralized and non-iid across clients.
Existing parameter-efficient tuning methods like LoRA (Low-Rank Adaptation)
reduce computational overhead but struggle with heterogeneous client data,
leading to suboptimal generalization. To address these challenges, we propose
FedVLM, a federated LoRA fine-tuning framework that enables decentralized
adaptation of VLMs while preserving model privacy and reducing reliance on
centralized training. To further tackle data heterogeneity, we introduce
personalized LoRA (pLoRA), which dynamically adapts LoRA parameters to each
client's unique data distribution, significantly improving local adaptation
while maintaining global model aggregation. Experiments on the RLAIF-V dataset
show that pLoRA improves client-specific performance by 24.5% over standard
LoRA, demonstrating superior adaptation in non-iid settings. FedVLM provides a
scalable and efficient solution for fine-tuning VLMs in federated settings,
advancing personalized adaptation in distributed learning scenarios.

</details>


### [23] [IONext: Unlocking the Next Era of Inertial Odometry](https://arxiv.org/abs/2507.17089)
*Shanshan Zhang,Siyue Wang,Tianshui Wen,Qi Zhang,Ziheng Zhou,Lingxiang Zheng,Yu Yang*

Main category: cs.CV

TL;DR: IONext, a CNN-based model with DADM and STGU, outperforms SOTA methods by better capturing motion features and improving temporal modeling.


<details>
  <summary>Details</summary>
Motivation: Addresses the limitations of Transformer-based models in local motion sensitivity and lack of inductive biases, and the temporal modeling shortcomings in existing CNN approaches.

Method: Proposes the Dual-wing Adaptive Dynamic Mixer (DADM) for adaptive global and local motion feature capture, and the Spatio-Temporal Gating Unit (STGU) for enhanced temporal modeling, forming the IONext backbone.

Result: IONext reduces the average ATE by 10% and RTE by 12% compared to iMOT on the RNIN dataset, showcasing superior performance.

Conclusion: IONext, a novel CNN-based inertial odometry backbone integrating DADM and STGU, consistently outperforms SOTA Transformer- and CNN-based methods across six public datasets, demonstrating significant improvements in localization accuracy and generalization.

Abstract: Researchers have increasingly adopted Transformer-based models for inertial
odometry. While Transformers excel at modeling long-range dependencies, their
limited sensitivity to local, fine-grained motion variations and lack of
inherent inductive biases often hinder localization accuracy and
generalization. Recent studies have shown that incorporating large-kernel
convolutions and Transformer-inspired architectural designs into CNN can
effectively expand the receptive field, thereby improving global motion
perception. Motivated by these insights, we propose a novel CNN-based module
called the Dual-wing Adaptive Dynamic Mixer (DADM), which adaptively captures
both global motion patterns and local, fine-grained motion features from
dynamic inputs. This module dynamically generates selective weights based on
the input, enabling efficient multi-scale feature aggregation. To further
improve temporal modeling, we introduce the Spatio-Temporal Gating Unit (STGU),
which selectively extracts representative and task-relevant motion features in
the temporal domain. This unit addresses the limitations of temporal modeling
observed in existing CNN approaches. Built upon DADM and STGU, we present a new
CNN-based inertial odometry backbone, named Next Era of Inertial Odometry
(IONext). Extensive experiments on six public datasets demonstrate that IONext
consistently outperforms state-of-the-art (SOTA) Transformer- and CNN-based
methods. For instance, on the RNIN dataset, IONext reduces the average ATE by
10% and the average RTE by 12% compared to the representative model iMOT.

</details>


### [24] [Robust Five-Class and binary Diabetic Retinopathy Classification Using Transfer Learning and Data Augmentation](https://arxiv.org/abs/2507.17121)
*Faisal Ahmed,Mohammad Alfrad Nobel Bhuiyan*

Main category: cs.CV

TL;DR: 提出了一种结合迁移学习和数据增强的深度学习框架，用于糖尿病视网膜病变的自动分类，在二分类和五类分类任务中均取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是全球视力丧失的主要原因，通过自动视网膜图像分析早期诊断可显著降低失明风险。

Method: 利用迁移学习和广泛的数据增强，评估了包括ResNet和EfficientNet变体在内的多种预训练卷积神经网络架构，处理类别不平衡和有限训练数据的挑战。

Result: 在二分类任务中，模型达到了98.9%的准确率；在五类严重程度分类任务中，获得了84.6%的准确率，均优于现有方法。EfficientNet-B0和ResNet34在准确性和计算效率之间提供了最佳平衡。

Conclusion: 结合类别平衡的数据增强和迁移学习，提出的框架为糖尿病视网膜病变（DR）筛查提供了可扩展且准确的解决方案，具有在实际临床环境中部署的潜力。

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss worldwide, and
early diagnosis through automated retinal image analysis can significantly
reduce the risk of blindness. This paper presents a robust deep learning
framework for both binary and five-class DR classification, leveraging transfer
learning and extensive data augmentation to address the challenges of class
imbalance and limited training data. We evaluate a range of pretrained
convolutional neural network architectures, including variants of ResNet and
EfficientNet, on the APTOS 2019 dataset.
  For binary classification, our proposed model achieves a state-of-the-art
accuracy of 98.9%, with a precision of 98.6%, recall of 99.3%, F1-score of
98.9%, and an AUC of 99.4%. In the more challenging five-class severity
classification task, our model obtains a competitive accuracy of 84.6% and an
AUC of 94.1%, outperforming several existing approaches. Our findings also
demonstrate that EfficientNet-B0 and ResNet34 offer optimal trade-offs between
accuracy and computational efficiency across both tasks.
  These results underscore the effectiveness of combining class-balanced
augmentation with transfer learning for high-performance DR diagnosis. The
proposed framework provides a scalable and accurate solution for DR screening,
with potential for deployment in real-world clinical environments.

</details>


### [25] [ScSAM: Debiasing Morphology and Distributional Variability in Subcellular Semantic Segmentation](https://arxiv.org/abs/2507.17149)
*Bo Fang,Jianan Fan,Dongnan Liu,Hang Chang,Gerald J. Shami,Filip Braet,Weidong Cai*

Main category: cs.CV

TL;DR: ScSAM通过融合SAM和MAE先验知识，解决了子细胞分割中的特征偏差问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 子细胞成分的形态和分布变异性大，导致基于学习的细胞器分割模型容易学习到有偏特征。现有方法常依赖单一映射关系，忽视特征多样性，导致训练偏差。

Method: 设计了一个特征对齐和融合模块，将预训练的嵌入对齐到同一特征空间，并高效结合不同表示；提出了基于余弦相似度矩阵的类别提示编码器，以激活类别特定特征来识别子细胞类别。

Result: 在多种子细胞图像数据集上的实验表明，ScSAM优于现有最先进方法。

Conclusion: ScSAM通过结合预训练的SAM和MAE引导的细胞先验知识，有效缓解了数据不平衡带来的训练偏差，提升了子细胞结构分割的准确性和鲁棒性。

Abstract: The significant morphological and distributional variability among
subcellular components poses a long-standing challenge for learning-based
organelle segmentation models, significantly increasing the risk of biased
feature learning. Existing methods often rely on single mapping relationships,
overlooking feature diversity and thereby inducing biased training. Although
the Segment Anything Model (SAM) provides rich feature representations, its
application to subcellular scenarios is hindered by two key challenges: (1) The
variability in subcellular morphology and distribution creates gaps in the
label space, leading the model to learn spurious or biased features. (2) SAM
focuses on global contextual understanding and often ignores fine-grained
spatial details, making it challenging to capture subtle structural alterations
and cope with skewed data distributions. To address these challenges, we
introduce ScSAM, a method that enhances feature robustness by fusing
pre-trained SAM with Masked Autoencoder (MAE)-guided cellular prior knowledge
to alleviate training bias from data imbalance. Specifically, we design a
feature alignment and fusion module to align pre-trained embeddings to the same
feature space and efficiently combine different representations. Moreover, we
present a cosine similarity matrix-based class prompt encoder to activate
class-specific features to recognize subcellular categories. Extensive
experiments on diverse subcellular image datasets demonstrate that ScSAM
outperforms state-of-the-art methods.

</details>


### [26] [UNICE: Training A Universal Image Contrast Enhancer](https://arxiv.org/abs/2507.17157)
*Ruodai Cui,Lei Zhang*

Main category: cs.CV

TL;DR: UNICE是一种无需人工标注的通用图像对比度增强方法，通过生成和融合多曝光序列，显著提升了泛化性能，超越了现有方法和人工基准。


<details>
  <summary>Details</summary>
Motivation: 探索是否能够学习一个通用且泛化的模型来处理多种图像对比度增强任务，观察到这些任务的共同关键在于曝光和对比度调整，而高动态范围（HDR）输入可以很好地解决这一问题。

Method: 通过收集46,928张HDR原始图像并渲染328,496张sRGB图像构建多曝光序列（MES）及其伪sRGB基准，训练一个网络从单张sRGB图像生成MES，再训练另一个网络将生成的MES融合为增强图像。

Result: UNICE方法在不同任务之间和任务内部均表现出比现有方法更强的泛化性能，并在多个无参考图像质量指标上超越了人工标注的基准。

Conclusion: UNICE（UNiversal Image Contrast Enhancer）方法在无需昂贵人工标注的情况下，显著提高了图像对比度增强任务的泛化性能，甚至在某些无参考图像质量指标上超越了人工标注的基准。

Abstract: Existing image contrast enhancement methods are typically designed for
specific tasks such as under-/over-exposure correction, low-light and backlit
image enhancement, etc. The learned models, however, exhibit poor
generalization performance across different tasks, even across different
datasets of a specific task. It is important to explore whether we can learn a
universal and generalized model for various contrast enhancement tasks. In this
work, we observe that the common key factor of these tasks lies in the need of
exposure and contrast adjustment, which can be well-addressed if high-dynamic
range (HDR) inputs are available. We hence collect 46,928 HDR raw images from
public sources, and render 328,496 sRGB images to build multi-exposure
sequences (MES) and the corresponding pseudo sRGB ground-truths via
multi-exposure fusion. Consequently, we train a network to generate an MES from
a single sRGB image, followed by training another network to fuse the generated
MES into an enhanced image. Our proposed method, namely UNiversal Image
Contrast Enhancer (UNICE), is free of costly human labeling. However, it
demonstrates significantly stronger generalization performance than existing
image contrast enhancement methods across and within different tasks, even
outperforming manually created ground-truths in multiple no-reference image
quality metrics. The dataset, code and model are available at
https://github.com/BeyondHeaven/UNICE.

</details>


### [27] [DOOMGAN:High-Fidelity Dynamic Identity Obfuscation Ocular Generative Morphing](https://arxiv.org/abs/2507.17158)
*Bharath Krishnamurthy,Ajita Rattani*

Main category: cs.CV

TL;DR: DOOMGAN是一种新型生成模型，显著提升了可见光谱眼部生物特征的变形攻击效果，并发布了首个相关数据集。


<details>
  <summary>Details</summary>
Motivation: 尽管可见光谱眼部生物特征因其高准确性和抗欺骗性而受到关注，但变形攻击在这一领域的研究仍不足，需要先进的生成模型来模拟此类攻击。

Method: DOOMGAN结合了基于标志点的可见眼部解剖编码、注意力引导的生成技术以及多面损失函数的动态加权优化。

Result: DOOMGAN在严格阈值下的攻击成功率比基准方法高出20%，同时提升了20%的椭圆虹膜结构生成准确性和30%的视线一致性。

Conclusion: DOOMGAN显著提高了可见光谱眼部生物特征的攻击成功率，并生成了更真实的合成特征，为相关研究领域提供了首个全面的眼部变形数据集。

Abstract: Ocular biometrics in the visible spectrum have emerged as a prominent
modality due to their high accuracy, resistance to spoofing, and non-invasive
nature. However, morphing attacks, synthetic biometric traits created by
blending features from multiple individuals, threaten biometric system
integrity. While extensively studied for near-infrared iris and face
biometrics, morphing in visible-spectrum ocular data remains underexplored.
Simulating such attacks demands advanced generation models that handle
uncontrolled conditions while preserving detailed ocular features like iris
boundaries and periocular textures. To address this gap, we introduce DOOMGAN,
that encompasses landmark-driven encoding of visible ocular anatomy,
attention-guided generation for realistic morph synthesis, and dynamic
weighting of multi-faceted losses for optimized convergence. DOOMGAN achieves
over 20% higher attack success rates than baseline methods under stringent
thresholds, along with 20% better elliptical iris structure generation and 30%
improved gaze consistency. We also release the first comprehensive ocular
morphing dataset to support further research in this domain.

</details>


### [28] [Multi-Scale PCB Defect Detection with YOLOv8 Network Improved via Pruning and Lightweight Network](https://arxiv.org/abs/2507.17176)
*Li Pingzhen,Xu Sheng,Chen Jing,Su Chengyue*

Main category: cs.CV

TL;DR: 改进YOLOv8的多尺度PCB缺陷检测方法，通过轻量化和自适应剪枝，显著提升检测速度和精度。


<details>
  <summary>Details</summary>
Motivation: 传统PCB缺陷检测模型难以兼顾精度和计算成本，无法满足高精度和实时检测微小缺陷的需求，因此需要一种改进方法。

Method: 论文采用多尺度PCB缺陷检测方法，通过优化主干网络（Ghost-HGNetv2结构）、颈部网络（C2f-Faster）、检测头（GCDetect）、损失函数（Inner-MPDIoU）和自适应剪枝率，实现了高效且精确的缺陷检测。

Result: 在公开的PCB缺陷数据集上，mAP0.5达到99.32%，mAP0.5:0.9达到75.18%，较YOLOv8n提升了10.13%。

Conclusion: 该论文通过改进YOLOv8，结合微小目标敏感策略、网络轻量化和自适应剪枝，显著提升了PCB缺陷检测的速度和准确性。实验结果表明，该方法在公开的PCB缺陷数据集上表现优异，mAP0.5达到99.32%，mAP0.5:0.9达到75.18%，较YOLOv8n提升了10.13%。

Abstract: With the high density of printed circuit board (PCB) design and the high
speed of production, the traditional PCB defect detection model is difficult to
take into account the accuracy and computational cost, and cannot meet the
requirements of high accuracy and real-time detection of tiny defects.
Therefore, in this paper, a multi-scale PCB defect detection method is improved
with YOLOv8 using a comprehensive strategy of tiny target sensitivity strategy,
network lightweighting and adaptive pruning, which is able to improve the
detection speed and accuracy by optimizing the backbone network, the neck
network and the detection head, the loss function and the adaptive pruning
rate. Firstly, a Ghost-HGNetv2 structure with fewer parameters is used in the
backbone network, and multilevel features are used to extract image semantic
features to discover accurate defects. Secondly, we integrate C2f-Faster with
small number of parameters in the neck section to enhance the ability of
multi-level feature fusion. Next, in the Head part, we design a new GCDetect
detection head, which allows the prediction of bounding boxes and categories to
share the weights of GroupConv, and uses a small number of grouping
convolutions to accomplish the regression and classification tasks, which
significantly reduces the number of parameters while maintaining the accuracy
of detection. We also design the Inner-MPDIoU boundary loss function to improve
the detection and localization of tiny targets. Finally, the model was pruned
by an optimized adaptive pruning rate to further reduce the complexity of the
model. Experimental results show that the model exhibits advantages in terms of
accuracy and speed. On the publicly available PCB defect dataset, mAP0.5
reaches 99.32% and mAP0.5:0.9 reaches 75.18%, which is 10.13% higher compared
to YOLOv8n.

</details>


### [29] [Hierarchical Fusion and Joint Aggregation: A Multi-Level Feature Representation Method for AIGC Image Quality Assessment](https://arxiv.org/abs/2507.17182)
*Linghe Meng,Jiarun Song*

Main category: cs.CV

TL;DR: A multi-level visual paradigm (MGLF-Net and MPEF-Net) outperforms single-level methods in AIGC quality assessment by capturing complex distortions through hierarchical feature fusion.


<details>
  <summary>Details</summary>
Motivation: Existing methods rely on single-level visual features, limiting their ability to capture complex distortions in AIGC images. A multi-level approach is needed to improve quality assessment.

Method: A multi-level visual representation paradigm with three stages: multi-level feature extraction, hierarchical fusion, and joint aggregation. Two networks (MGLF-Net and MPEF-Net) are developed for perceptual quality assessment and Text-to-Image correspondence, respectively.

Result: Experiments on benchmarks show outstanding performance on both perceptual quality assessment and Text-to-Image correspondence tasks.

Conclusion: The proposed multi-level visual representation paradigm, implemented through MGLF-Net and MPEF-Net, effectively addresses the limitations of existing single-level feature methods, demonstrating outstanding performance in AIGC quality assessment.

Abstract: The quality assessment of AI-generated content (AIGC) faces multi-dimensional
challenges, that span from low-level visual perception to high-level semantic
understanding. Existing methods generally rely on single-level visual features,
limiting their ability to capture complex distortions in AIGC images. To
address this limitation, a multi-level visual representation paradigm is
proposed with three stages, namely multi-level feature extraction, hierarchical
fusion, and joint aggregation. Based on this paradigm, two networks are
developed. Specifically, the Multi-Level Global-Local Fusion Network (MGLF-Net)
is designed for the perceptual quality assessment, extracting complementary
local and global features via dual CNN and Transformer visual backbones. The
Multi-Level Prompt-Embedded Fusion Network (MPEF-Net) targets Text-to-Image
correspondence by embedding prompt semantics into the visual feature fusion
process at each feature level. The fused multi-level features are then
aggregated for final evaluation. Experiments on benchmarks demonstrate
outstanding performance on both tasks, validating the effectiveness of the
proposed multi-level visual assessment paradigm.

</details>


### [30] [Asymmetric Lesion Detection with Geometric Patterns and CNN-SVM Classification](https://arxiv.org/abs/2507.17185)
*M. A. Rasel,Sameem Abdul Kareem,Zhenli Kwan,Nik Aimee Azizah Faheem,Winn Hui Han,Rebecca Kai Jan Choong,Shin Shen Yong,Unaizah Obaidellah*

Main category: cs.CV

TL;DR: 论文提出结合几何分析和CNN的方法，提升皮肤病变形状分类准确率，非对称病变检测率达99%，分类性能指标优异。


<details>
  <summary>Details</summary>
Motivation: 皮肤病变形状在皮肤病诊断中至关重要，尤其是非对称形状是黑色素瘤的诊断标准之一。现有方法对非专家不友好，因此需要开发辅助技术。

Method: 首先基于临床评估标注对称性信息，随后提出监督学习图像处理算法分析病变几何模式，并利用预训练的CNN提取形状、颜色和纹理特征，训练多类SVM分类器。

Result: 几何实验中对非对称病变的检测率达到99%。CNN实验中，分类性能最佳表现为Kappa Score 94%、Macro F1-score 95%、Weighted F1-score 97%。

Conclusion: 论文提出了一种结合几何分析和CNN特征提取的方法，显著提高了皮肤病变形状分类的准确性，特别是在非对称病变检测上达到了99%的识别率。

Abstract: In dermoscopic images, which allow visualization of surface skin structures
not visible to the naked eye, lesion shape offers vital insights into skin
diseases. In clinically practiced methods, asymmetric lesion shape is one of
the criteria for diagnosing melanoma. Initially, we labeled data for a
non-annotated dataset with symmetrical information based on clinical
assessments. Subsequently, we propose a supporting technique, a supervised
learning image processing algorithm, to analyze the geometrical pattern of
lesion shape, aiding non-experts in understanding the criteria of an asymmetric
lesion. We then utilize a pre-trained convolutional neural network (CNN) to
extract shape, color, and texture features from dermoscopic images for training
a multiclass support vector machine (SVM) classifier, outperforming
state-of-the-art methods from the literature. In the geometry-based experiment,
we achieved a 99.00% detection rate for dermatological asymmetric lesions. In
the CNN-based experiment, the best performance is found with 94% Kappa Score,
95% Macro F1-score, and 97% Weighted F1-score for classifying lesion shapes
(Asymmetric, Half-Symmetric, and Symmetric).

</details>


### [31] [Vec2Face+ for Face Dataset Generation](https://arxiv.org/abs/2507.17192)
*Haiyu Wu,Jaskirat Singh,Sicong Tian,Liang Zheng,Kevin W. Bowyer*

Main category: cs.CV

TL;DR: 论文提出Vec2Face+生成模型，通过三种策略生成高质量人脸数据，首次在准确率上超越真实数据集CASIA-WebFace，并揭示了合成数据的偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在增加类内属性变化时忽视了保持类内身份一致性的必要性，导致生成的数据质量不足。论文旨在解决这一问题，生成高质量的人脸训练数据。

Method: 论文提出Vec2Face+生成模型，通过三种策略生成高质量合成数据：1）采样足够差异的向量以生成身份分离良好的图像；2）提出AttrOP算法增加属性变化；3）提出基于LoRA的姿态控制方法，更高效且保持身份一致性。

Result: Vec2Face+生成的VFace10K数据集在七个真实测试集上达到最先进准确率，扩展至4M和12M图像的VFace100K和VFace300K在五个测试集上超越CASIA-WebFace。同时发现合成数据集在双胞胎验证中表现不佳，且训练模型存在偏见。

Conclusion: 该论文首次展示了合成数据集（VFace10K、VFace100K和VFace300K）在平均准确率上超越了真实数据集CASIA-WebFace，并指出合成身份训练模型存在偏见，这对未来研究具有重要意义。

Abstract: When synthesizing identities as face recognition training data, it is
generally believed that large inter-class separability and intra-class
attribute variation are essential for synthesizing a quality dataset. % This
belief is generally correct, and this is what we aim for. However, when
increasing intra-class variation, existing methods overlook the necessity of
maintaining intra-class identity consistency. % To address this and generate
high-quality face training data, we propose Vec2Face+, a generative model that
creates images directly from image features and allows for continuous and easy
control of face identities and attributes. Using Vec2Face+, we obtain datasets
with proper inter-class separability and intra-class variation and identity
consistency using three strategies: 1) we sample vectors sufficiently different
from others to generate well-separated identities; 2) we propose an AttrOP
algorithm for increasing general attribute variations; 3) we propose LoRA-based
pose control for generating images with profile head poses, which is more
efficient and identity-preserving than AttrOP. % Our system generates VFace10K,
a synthetic face dataset with 10K identities, which allows an FR model to
achieve state-of-the-art accuracy on seven real-world test sets. Scaling the
size to 4M and 12M images, the corresponding VFace100K and VFace300K datasets
yield higher accuracy than the real-world training dataset, CASIA-WebFace, on
five real-world test sets. This is the first time a synthetic dataset beats the
CASIA-WebFace in average accuracy. In addition, we find that only 1 out of 11
synthetic datasets outperforms random guessing (\emph{i.e., 50\%}) in twin
verification and that models trained with synthetic identities are more biased
than those trained with real identities. Both are important aspects for future
investigation.

</details>


### [32] [DesignLab: Designing Slides Through Iterative Detection and Correction](https://arxiv.org/abs/2507.17202)
*Jooyeol Yun,Heng Wang,Yotaro Shimose,Jaegul Choo,Shingo Takamatsu*

Main category: cs.CV

TL;DR: DesignLab通过分解设计角色和迭代优化，利用大型语言模型提升幻灯片设计质量，超越现有工具。


<details>
  <summary>Details</summary>
Motivation: 非专业人士在设计高质量演示幻灯片时面临复杂的设计选择挑战，现有自动化工具缺乏自我优化能力，难以满足实际工作流程需求。

Method: 研究团队将设计过程分解为设计评审者和设计贡献者两个角色，并利用大型语言模型进行微调。通过引入受控扰动模拟中间草稿，使评审者学习设计错误，贡献者学习如何修复它们。

Result: 实验表明，DesignLab通过迭代设计过程，能够生成比现有设计生成方法（包括商业工具）更专业、更精致的幻灯片。

Conclusion: DesignLab通过将设计过程分解为设计评审者和设计贡献者两个角色，并利用大型语言模型进行微调，显著提升了幻灯片设计的质量，超越了现有设计生成方法。

Abstract: Designing high-quality presentation slides can be challenging for non-experts
due to the complexity involved in navigating various design choices. Numerous
automated tools can suggest layouts and color schemes, yet often lack the
ability to refine their own output, which is a key aspect in real-world
workflows. We propose DesignLab, which separates the design process into two
roles, the design reviewer, who identifies design-related issues, and the
design contributor who corrects them. This decomposition enables an iterative
loop where the reviewer continuously detects issues and the contributor
corrects them, allowing a draft to be further polished with each iteration,
reaching qualities that were unattainable. We fine-tune large language models
for these roles and simulate intermediate drafts by introducing controlled
perturbations, enabling the design reviewer learn design errors and the
contributor learn how to fix them. Our experiments show that DesignLab
outperforms existing design-generation methods, including a commercial tool, by
embracing the iterative nature of designing which can result in polished,
professional slides.

</details>


### [33] [VBCD: A Voxel-Based Framework for Personalized Dental Crown Design](https://arxiv.org/abs/2507.17205)
*Linda Wei,Chang Liu,Wenran Zhang,Zengji Zhang,Shaoting Zhang,Hongsheng Li*

Main category: cs.CV

TL;DR: VBCD框架通过体素化和细粒度优化，结合新型损失函数和位置提示，实现了高效、准确的自动化牙冠设计。


<details>
  <summary>Details</summary>
Motivation: 牙科技术人员从口腔扫描中设计修复性牙冠的过程劳动密集，亟需自动化解决方案以提高效率和准确性。

Method: 提出了一种基于体素的牙冠设计框架VBCD，包括粗粒度生成和细粒度优化两个阶段，并引入了距离感知监督和CMPL损失函数以提升对齐效果。

Result: 在大规模口腔扫描数据集上的评估表明，VBCD框架优于现有方法，显著提升了牙冠设计的准确性和质量。

Conclusion: VBCD框架通过体素化口腔扫描和细粒度优化，结合距离感知监督和CMPL损失函数，显著提高了牙冠设计的准确性和质量，为个性化牙冠设计提供了高效解决方案。

Abstract: The design of restorative dental crowns from intraoral scans is
labor-intensive for dental technicians. To address this challenge, we propose a
novel voxel-based framework for automated dental crown design (VBCD). The VBCD
framework generates an initial coarse dental crown from voxelized intraoral
scans, followed by a fine-grained refiner incorporating distance-aware
supervision to improve accuracy and quality. During the training stage, we
employ the Curvature and Margin line Penalty Loss (CMPL) to enhance the
alignment of the generated crown with the margin line. Additionally, a
positional prompt based on the FDI tooth numbering system is introduced to
further improve the accuracy of the generated dental crowns. Evaluation on a
large-scale dataset of intraoral scans demonstrated that our approach
outperforms existing methods, providing a robust solution for personalized
dental crown design.

</details>


### [34] [A Low-Cost Machine Learning Approach for Timber Diameter Estimation](https://arxiv.org/abs/2507.17219)
*Fatemeh Hasanzadeh Fard,Sanaz Hasanzadeh Fard,Mehdi Jonoobi*

Main category: cs.CV

TL;DR: 研究提出了一种基于YOLOv5的轻量级方法，通过RGB图像自动估计木材直径，适用于实际工业环境，尤其在中小型工厂中具有应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统木材识别方法依赖人工，效率低且易出错，尤其在处理大量木材时。因此，需要一种实用且经济高效的自动化解决方案。

Method: 研究采用YOLOv5目标检测算法，并在公开数据集TimberSeg 1.0上进行微调，通过边界框尺寸估计木材厚度。

Result: 模型在真实工业环境下拍摄的图像上实现了0.64的平均精度（mAP@0.5），证明了其可靠的检测能力。

Conclusion: 该研究提出的基于YOLOv5的轻量级解决方案在木材直径估计中表现出色，尤其适合中小型木材加工厂的现有工作流程集成。

Abstract: The wood processing industry, particularly in facilities such as sawmills and
MDF production lines, requires accurate and efficient identification of species
and thickness of the wood. Although traditional methods rely heavily on expert
human labor, they are slow, inconsistent, and prone to error, especially when
processing large volumes. This study focuses on practical and cost-effective
machine learning frameworks that automate the estimation of timber log diameter
using standard RGB images captured under real-world working conditions. We
employ the YOLOv5 object detection algorithm, fine-tuned on a public dataset
(TimberSeg 1.0), to detect individual timber logs and estimate thickness
through bounding-box dimensions. Unlike previous methods that require expensive
sensors or controlled environments, this model is trained on images taken in
typical industrial sheds during timber delivery. Experimental results show that
the model achieves a mean Average Precision (mAP@0.5) of 0.64, demonstrating
reliable log detection even with modest computing resources. This lightweight,
scalable solution holds promise for practical integration into existing
workflows, including on-site inventory management and preliminary sorting,
particularly in small and medium-sized operations.

</details>


### [35] [PIG-Nav: Key Insights for Pretrained Image Goal Navigation Models](https://arxiv.org/abs/2507.17220)
*Jiansong Wan,Chengming Zhou,Jinkua Liu,Xiangge Huang,Xiaoyu Chen,Xiaohan Yi,Qisen Yang,Baiting Zhu,Xin-Qiang Cai,Lixing Liu,Rushuai Yang,Chuheng Zhang,Sherif Abdelfattah,Hayong Shin,Pushi Zhang,Li Zhao,Jiang Bian*

Main category: cs.CV

TL;DR: PIG-Nav通过早期融合网络结构和辅助任务改进预训练视觉导航模型，结合游戏视频数据增强，显著提升零样本和微调性能，减少对标记数据的需求。


<details>
  <summary>Details</summary>
Motivation: 探索预训练模型在视觉机器人导航中的应用，以实现通用化导航和跨环境的正向迁移，同时提升在未见环境中的零样本性能。

Method: 提出了PIG-Nav方法，包括两个关键设计选择：(1) 使用预训练的ViT图像编码器实现早期融合网络结构；(2) 引入辅助任务增强全局导航表示学习。此外，提出了一种新的数据预处理流程，用于高效标注大规模游戏视频数据集。

Result: 在两种复杂模拟环境和一种真实环境中，PIG-Nav模型在零样本设置中平均提升22.6%，在微调设置中提升37.5%，且所需微调数据显著减少。

Conclusion: PIG-Nav模型在零样本和微调设置中均显著优于现有视觉导航基础模型，展示了在真实世界部署中的潜力，尤其是在标记监督较少的情况下。

Abstract: Recent studies have explored pretrained (foundation) models for vision-based
robotic navigation, aiming to achieve generalizable navigation and positive
transfer across diverse environments while enhancing zero-shot performance in
unseen settings. In this work, we introduce PIG-Nav (Pretrained Image-Goal
Navigation), a new approach that further investigates pretraining strategies
for vision-based navigation models and contributes in two key areas.
Model-wise, we identify two critical design choices that consistently improve
the performance of pretrained navigation models: (1) integrating an
early-fusion network structure to combine visual observations and goal images
via appropriately pretrained Vision Transformer (ViT) image encoder, and (2)
introducing suitable auxiliary tasks to enhance global navigation
representation learning, thus further improving navigation performance.
Dataset-wise, we propose a novel data preprocessing pipeline for efficiently
labeling large-scale game video datasets for navigation model training. We
demonstrate that augmenting existing open navigation datasets with diverse
gameplay videos improves model performance. Our model achieves an average
improvement of 22.6% in zero-shot settings and a 37.5% improvement in
fine-tuning settings over existing visual navigation foundation models in two
complex simulated environments and one real-world environment. These results
advance the state-of-the-art in pretrained image-goal navigation models.
Notably, our model maintains competitive performance while requiring
significantly less fine-tuning data, highlighting its potential for real-world
deployment with minimal labeled supervision.

</details>


### [36] [MaskedCLIP: Bridging the Masked and CLIP Space for Semi-Supervised Medical Vision-Language Pre-training](https://arxiv.org/abs/2507.17239)
*Lei Zhu,Jun Zhou,Rick Siow Mong Goh,Yong Liu*

Main category: cs.CV

TL;DR: MaskedCLIP通过结合masked image modeling和CLIP预训练，利用paired和unpaired图像数据提升医学图像基础模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅利用paired或unpaired图像数据限制了特征学习的全面性，需探索如何同时利用两种数据提升基础模型性能。

Method: 提出MaskedCLIP框架，结合masked image modeling和contrastive language-image pre-training，通过bridge transformer连接两种数据特征空间，并设计masked knowledge distillation损失。

Result: 在视网膜图像分析任务中验证了方法的有效性和数据效率。

Conclusion: MaskedCLIP框架通过结合paired和unpaired图像数据，有效提升了医学图像分析中基础模型的泛化能力，实验证明了其高效性和数据效率。

Abstract: Foundation models have recently gained tremendous popularity in medical image
analysis. State-of-the-art methods leverage either paired image-text data via
vision-language pre-training or unpaired image data via self-supervised
pre-training to learn foundation models with generalizable image features to
boost downstream task performance. However, learning foundation models
exclusively on either paired or unpaired image data limits their ability to
learn richer and more comprehensive image features. In this paper, we
investigate a novel task termed semi-supervised vision-language pre-training,
aiming to fully harness the potential of both paired and unpaired image data
for foundation model learning. To this end, we propose MaskedCLIP, a
synergistic masked image modeling and contrastive language-image pre-training
framework for semi-supervised vision-language pre-training. The key challenge
in combining paired and unpaired image data for learning a foundation model
lies in the incompatible feature spaces derived from these two types of data.
To address this issue, we propose to connect the masked feature space with the
CLIP feature space with a bridge transformer. In this way, the more semantic
specific CLIP features can benefit from the more general masked features for
semantic feature extraction. We further propose a masked knowledge distillation
loss to distill semantic knowledge of original image features in CLIP feature
space back to the predicted masked image features in masked feature space. With
this mutually interactive design, our framework effectively leverages both
paired and unpaired image data to learn more generalizable image features for
downstream tasks. Extensive experiments on retinal image analysis demonstrate
the effectiveness and data efficiency of our method.

</details>


### [37] [Perceptual Classifiers: Detecting Generative Images using Perceptual Features](https://arxiv.org/abs/2507.17240)
*Krishna Srikar Durbha,Asvin Kumar Venkataramanan,Rajesh Sureddi,Alan C. Bovik*

Main category: cs.CV

TL;DR: IQA模型特征训练的两层网络能有效检测AI生成图像，对图像退化鲁棒。


<details>
  <summary>Details</summary>
Motivation: 生成模型的进步导致大量GenAI内容涌现，现有检测方法需提升泛化能力。

Method: 利用现有IQA模型的特征空间训练两层网络进行GenAI图像检测。

Result: 该方法在检测不同生成模型的假图像上表现优异，且对图像退化具有鲁棒性。

Conclusion: IQA模型的特征空间训练的两层网络在检测生成式AI图像方面表现出色，且对图像退化具有显著鲁棒性。

Abstract: Image Quality Assessment (IQA) models are employed in many practical image
and video processing pipelines to reduce storage, minimize transmission costs,
and improve the Quality of Experience (QoE) of millions of viewers. These
models are sensitive to a diverse range of image distortions and can accurately
predict image quality as judged by human viewers. Recent advancements in
generative models have resulted in a significant influx of "GenAI" content on
the internet. Existing methods for detecting GenAI content have progressed
significantly with improved generalization performance on images from unseen
generative models. Here, we leverage the capabilities of existing IQA models,
which effectively capture the manifold of real images within a bandpass
statistical space, to distinguish between real and AI-generated images. We
investigate the generalization ability of these perceptual classifiers to the
task of GenAI image detection and evaluate their robustness against various
image degradations. Our results show that a two-layer network trained on the
feature space of IQA models demonstrates state-of-the-art performance in
detecting fake images across generative models, while maintaining significant
robustness against image degradations.

</details>


### [38] [Unsupervised Exposure Correction](https://arxiv.org/abs/2507.17252)
*Ruodai Cui,Li Niu,Guosheng Hu*

Main category: cs.CV

TL;DR: 提出无监督曝光校正方法（UEC），无需人工标注，泛化能力更强，性能优于监督方法，适用于低层次视觉任务。


<details>
  <summary>Details</summary>
Motivation: 现有曝光校正方法存在人工标注成本高、泛化能力有限及在低层次视觉任务中性能下降的问题，亟需一种无需人工标注且性能更优的解决方案。

Method: 采用模拟ISP流程生成配对数据进行无监督训练，开发了一种保留图像细节的转换函数，并构建了一个大规模放射校正数据集以强调曝光变化。

Result: UEC方法在性能上超越现有监督方法[12]，仅使用其0.01%的参数，同时在下游任务（如边缘检测）中有效缓解曝光不良的影响。

Conclusion: 本研究提出的无监督曝光校正方法（UEC）通过模拟ISP流程生成配对数据，无需人工标注，显著提升泛化能力，并在低层次视觉任务中表现优异。

Abstract: Current exposure correction methods have three challenges, labor-intensive
paired data annotation, limited generalizability, and performance degradation
in low-level computer vision tasks. In this work, we introduce an innovative
Unsupervised Exposure Correction (UEC) method that eliminates the need for
manual annotations, offers improved generalizability, and enhances performance
in low-level downstream tasks. Our model is trained using freely available
paired data from an emulated Image Signal Processing (ISP) pipeline. This
approach does not need expensive manual annotations, thereby minimizing
individual style biases from the annotation and consequently improving its
generalizability. Furthermore, we present a large-scale Radiometry Correction
Dataset, specifically designed to emphasize exposure variations, to facilitate
unsupervised learning. In addition, we develop a transformation function that
preserves image details and outperforms state-of-the-art supervised methods
[12], while utilizing only 0.01% of their parameters. Our work further
investigates the broader impact of exposure correction on downstream tasks,
including edge detection, demonstrating its effectiveness in mitigating the
adverse effects of poor exposure on low-level features. The source code and
dataset are publicly available at https://github.com/BeyondHeaven/uec_code.

</details>


### [39] [VisionTrap: Unanswerable Questions On Visual Data](https://arxiv.org/abs/2507.17262)
*Asir Saadat,Syem Aziz,Shahriar Mahmud,Abdullah Ibne Masud Mahi,Sabbir Ahmed*

Main category: cs.CV

TL;DR: 研究探讨VQA模型处理不可回答问题的能力，引入VisionTrap数据集，发现模型常错误回答，建议改进评估标准。


<details>
  <summary>Details</summary>
Motivation: 探索VQA模型如何处理不可回答问题，特别是模型是否能够识别其知识局限性并避免提供错误答案。

Method: 研究引入了VisionTrap数据集，包含三类不可回答问题：混合实体、非常规场景和虚构人物。

Result: 研究发现模型在应避免回答时仍倾向于提供答案，凸显了评估模型识别其局限性的必要性。

Conclusion: 该研究强调了在VQA基准测试中纳入不可回答问题的重要性，以评估模型在应避免回答时的表现。

Abstract: Visual Question Answering (VQA) has been a widely studied topic, with
extensive research focusing on how VLMs respond to answerable questions based
on real-world images. However, there has been limited exploration of how these
models handle unanswerable questions, particularly in cases where they should
abstain from providing a response. This research investigates VQA performance
on unrealistically generated images or asking unanswerable questions, assessing
whether models recognize the limitations of their knowledge or attempt to
generate incorrect answers. We introduced a dataset, VisionTrap, comprising
three categories of unanswerable questions across diverse image types: (1)
hybrid entities that fuse objects and animals, (2) objects depicted in
unconventional or impossible scenarios, and (3) fictional or non-existent
figures. The questions posed are logically structured yet inherently
unanswerable, testing whether models can correctly recognize their limitations.
Our findings highlight the importance of incorporating such questions into VQA
benchmarks to evaluate whether models tend to answer, even when they should
abstain.

</details>


### [40] [PolarAnything: Diffusion-based Polarimetric Image Synthesis](https://arxiv.org/abs/2507.17268)
*Kailong Zhang,Youwei Lyu,Heng Guo,Si Li,Zhanyu Ma,Boxin Shi*

Main category: cs.CV

TL;DR: PolarAnything 通过扩散模型从单一 RGB 输入合成高质量偏振图像，解决了对 3D 资产的依赖。


<details>
  <summary>Details</summary>
Motivation: 偏振图像在图像增强和 3D 重建任务中具有重要作用，但偏振相机的普及受限，现有模拟器依赖大量 3D 资产，限制了其应用。

Method: 提出了一种基于扩散的生成框架，结合有效的表示策略，保留了偏振特性的保真度。

Result: 实验表明，PolarAnything 能够生成高质量的偏振图像，并支持下游任务。

Conclusion: PolarAnything 能够通过单一 RGB 输入合成具有高真实性和物理准确性的偏振图像，解决了对 3D 资产依赖的问题，并支持下游任务如形状重建。

Abstract: Polarization images facilitate image enhancement and 3D reconstruction tasks,
but the limited accessibility of polarization cameras hinders their broader
application. This gap drives the need for synthesizing photorealistic
polarization images.The existing polarization simulator Mitsuba relies on a
parametric polarization image formation model and requires extensive 3D assets
covering shape and PBR materials, preventing it from generating large-scale
photorealistic images. To address this problem, we propose PolarAnything,
capable of synthesizing polarization images from a single RGB input with both
photorealism and physical accuracy, eliminating the dependency on 3D asset
collections. Drawing inspiration from the zero-shot performance of pretrained
diffusion models, we introduce a diffusion-based generative framework with an
effective representation strategy that preserves the fidelity of polarization
properties. Experiments show that our model generates high-quality polarization
images and supports downstream tasks like shape from polarization.

</details>


### [41] [Fully Automated SAM for Single-source Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2507.17281)
*Huanli Zhuo,Leilei Ma,Haifeng Zhao,Shiwei Zhou,Dengdi Sun,Yanping Fu*

Main category: cs.CV

TL;DR: FA-SAM通过自动生成提示和融合多尺度信息，解决了SAM在医学图像分割中的依赖专家提示和错误提示问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: SAM在跨域医学图像分割中依赖专家标注提示且易受错误提示影响，限制了其临床应用的自动化程度。FA-SAM旨在实现完全自动化的SAM分割并减少错误提示的影响。

Method: FA-SAM框架包含两个关键创新：1) 配备SUFM模块的AGM分支，用于生成目标域的边界框提示；2) 集成到SAM掩码解码器的IPEF模块，融合多尺度信息以捕获目标对象的全局和局部细节。

Result: 在公开的前列腺和眼底血管数据集上的实验表明，FA-SAM能够有效生成自动化提示并减少错误提示的影响，验证了其解决上述挑战的潜力。

Conclusion: FA-SAM框架通过引入AGM分支和IPEF模块，有效解决了SAM在医学图像分割中依赖专家标注提示和错误提示导致分割错误的问题，实验验证了其有效性。

Abstract: Although SAM-based single-source domain generalization models for medical
image segmentation can mitigate the impact of domain shift on the model in
cross-domain scenarios, these models still face two major challenges. First,
the segmentation of SAM is highly dependent on domain-specific expert-annotated
prompts, which prevents SAM from achieving fully automated medical image
segmentation and therefore limits its application in clinical settings. Second,
providing poor prompts (such as bounding boxes that are too small or too large)
to the SAM prompt encoder can mislead SAM into generating incorrect mask
results. Therefore, we propose the FA-SAM, a single-source domain
generalization framework for medical image segmentation that achieves fully
automated SAM. FA-SAM introduces two key innovations: an Auto-prompted
Generation Model (AGM) branch equipped with a Shallow Feature Uncertainty
Modeling (SUFM) module, and an Image-Prompt Embedding Fusion (IPEF) module
integrated into the SAM mask decoder. Specifically, AGM models the uncertainty
distribution of shallow features through the SUFM module to generate bounding
box prompts for the target domain, enabling fully automated segmentation with
SAM. The IPEF module integrates multiscale information from SAM image
embeddings and prompt embeddings to capture global and local details of the
target object, enabling SAM to mitigate the impact of poor prompts. Extensive
experiments on publicly available prostate and fundus vessel datasets validate
the effectiveness of FA-SAM and highlight its potential to address the above
challenges.

</details>


### [42] [VLM-Guided Visual Place Recognition for Planet-Scale Geo-Localization](https://arxiv.org/abs/2507.17455)
*Sania Waheed,Na Min An,Michael Milford,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出混合VLM与VPR的地理定位框架，显著提升准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统检索方法在可扩展性和感知混淆方面存在不足，分类方法缺乏泛化性且需要大量训练数据，而VLM虽准确但易产生幻觉且缺乏可解释性。

Method: 提出了一种混合框架，首先利用VLM生成地理先验以引导检索搜索空间，随后通过检索步骤和重新排序机制选择最地理上合理的匹配。

Result: 在多个地理定位基准测试中，该方法在街道级别（最高提升4.51%）和城市级别（最高提升13.52%）上均优于现有最先进方法。

Conclusion: 结合视觉语言模型（VLM）和基于检索的视觉位置识别（VPR）方法，提出了一种新型混合地理定位框架，显著提高了地理定位的准确性、可扩展性和鲁棒性。

Abstract: Geo-localization from a single image at planet scale (essentially an advanced
or extreme version of the kidnapped robot problem) is a fundamental and
challenging task in applications such as navigation, autonomous driving and
disaster response due to the vast diversity of locations, environmental
conditions, and scene variations. Traditional retrieval-based methods for
geo-localization struggle with scalability and perceptual aliasing, while
classification-based approaches lack generalization and require extensive
training data. Recent advances in vision-language models (VLMs) offer a
promising alternative by leveraging contextual understanding and reasoning.
However, while VLMs achieve high accuracy, they are often prone to
hallucinations and lack interpretability, making them unreliable as standalone
solutions. In this work, we propose a novel hybrid geo-localization framework
that combines the strengths of VLMs with retrieval-based visual place
recognition (VPR) methods. Our approach first leverages a VLM to generate a
prior, effectively guiding and constraining the retrieval search space. We then
employ a retrieval step, followed by a re-ranking mechanism that selects the
most geographically plausible matches based on feature similarity and proximity
to the initially estimated coordinates. We evaluate our approach on multiple
geo-localization benchmarks and show that it consistently outperforms prior
state-of-the-art methods, particularly at street (up to 4.51%) and city level
(up to 13.52%). Our results demonstrate that VLM-generated geographic priors in
combination with VPR lead to scalable, robust, and accurate geo-localization
systems.

</details>


### [43] [PointLAMA: Latent Attention meets Mamba for Efficient Point Cloud Pretraining](https://arxiv.org/abs/2507.17296)
*Xuanyu Lin,Xiaona Zeng,Xianwei Zheng,Xutao Li*

Main category: cs.CV

TL;DR: PointLAMA 是一种结合任务感知序列化、混合编码器和条件扩散机制的点云预训练框架，弥补了 Mamba 在局部几何结构建模上的不足，实现了高效性能。


<details>
  <summary>Details</summary>
Motivation: Mamba 作为点云建模的骨干模型，虽然具有高效的全局序列建模能力，但缺乏局部归纳偏置，限制了其在 3D 数据中捕捉细粒度几何结构的能力。

Method: PointLAMA 采用任务感知的点云序列化（Hilbert/Trans-Hilbert 空间填充曲线和轴排序）、混合编码器（集成 Latent Attention 和 Mamba 块）以及基于 Mamba 的条件扩散机制。

Result: 实验结果表明，PointLAMA 在多个基准数据集上实现了竞争性性能，且参数量和计算量（FLOPs）极低。

Conclusion: PointLAMA 通过结合任务感知的点云序列化、混合编码器和条件扩散机制，成功提升了 Mamba 在点云建模中的表现，尤其在捕捉细粒度几何结构方面。

Abstract: Mamba has recently gained widespread attention as a backbone model for point
cloud modeling, leveraging a state-space architecture that enables efficient
global sequence modeling with linear complexity. However, its lack of local
inductive bias limits its capacity to capture fine-grained geometric structures
in 3D data. To address this limitation, we propose \textbf{PointLAMA}, a point
cloud pretraining framework that combines task-aware point cloud serialization,
a hybrid encoder with integrated Latent Attention and Mamba blocks, and a
conditional diffusion mechanism built upon the Mamba backbone. Specifically,
the task-aware point cloud serialization employs Hilbert/Trans-Hilbert
space-filling curves and axis-wise sorting to structurally align point tokens
for classification and segmentation tasks, respectively. Our lightweight Latent
Attention block features a Point-wise Multi-head Latent Attention (PMLA)
module, which is specifically designed to align with the Mamba architecture by
leveraging the shared latent space characteristics of PMLA and Mamba. This
enables enhanced local context modeling while preserving overall efficiency. To
further enhance representation learning, we incorporate a conditional diffusion
mechanism during pretraining, which denoises perturbed feature sequences
without relying on explicit point-wise reconstruction. Experimental results
demonstrate that PointLAMA achieves competitive performance on multiple
benchmark datasets with minimal parameter count and FLOPs, validating its
effectiveness for efficient point cloud pretraining.

</details>


### [44] [From Scan to Action: Leveraging Realistic Scans for Embodied Scene Understanding](https://arxiv.org/abs/2507.17585)
*Anna-Maria Halacheva,Jan-Nico Zaech,Sombit Dey,Luc Van Gool,Danda Pani Paudel*

Main category: cs.CV

TL;DR: 本文提出了一种利用USD格式整合3D场景扫描数据的方法，解决了数据量大和格式不兼容的问题，并在两个应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现实世界的3D场景级扫描具有高度的真实感，可以提升下游应用的泛化能力，但数据量大、注释格式多样及工具兼容性问题限制了其应用。

Method: 提出了一种基于USD的统一注释集成方法，并设计了特定于应用的USD变体。

Result: 在基于LLM的场景编辑中实现了80%的成功率，在机器人仿真中达到了87%的策略学习成功率。

Conclusion: 本文提出了一种利用USD格式统一整合3D场景扫描数据及其注释的方法，并通过两个下游应用验证了其有效性。

Abstract: Real-world 3D scene-level scans offer realism and can enable better
real-world generalizability for downstream applications. However, challenges
such as data volume, diverse annotation formats, and tool compatibility limit
their use. This paper demonstrates a methodology to effectively leverage these
scans and their annotations. We propose a unified annotation integration using
USD, with application-specific USD flavors. We identify challenges in utilizing
holistic real-world scan datasets and present mitigation strategies. The
efficacy of our approach is demonstrated through two downstream applications:
LLM-based scene editing, enabling effective LLM understanding and adaptation of
the data (80% success), and robotic simulation, achieving an 87% success rate
in policy learning.

</details>


### [45] [Learning-based Stage Verification System in Manual Assembly Scenarios](https://arxiv.org/abs/2507.17304)
*Xingjian Zhang,Yutong Duan,Zaishu Chen*

Main category: cs.CV

TL;DR: 提出一种基于机器学习的装配监控方法，仅需少量视觉传感器即可实现高精度（>92%）和实时指导，降低硬件成本。


<details>
  <summary>Details</summary>
Motivation: 在工业4.0背景下，传统多传感器或复杂硬件监控方法成本高且难以适应动态工业环境，亟需一种仅依赖少量视觉传感器的高效监控方案。

Method: 研究采用多种机器学习模型，并通过整合相同时间戳的状态信息，实现对装配过程当前阶段的检测和确认。

Result: 该方法在装配过程监控中平均准确率超过92%，且具备更强的错误检测和可视化能力，能实时提供操作指导。

Conclusion: 该研究提出了一种在视觉传感器数量有限的情况下，通过集成机器学习模型实现高精度监控的新方法，显著提升了工业装配过程的监控效率和准确性，同时降低了硬件成本。

Abstract: In the context of Industry 4.0, effective monitoring of multiple targets and
states during assembly processes is crucial, particularly when constrained to
using only visual sensors. Traditional methods often rely on either multiple
sensor types or complex hardware setups to achieve high accuracy in monitoring,
which can be cost-prohibitive and difficult to implement in dynamic industrial
environments. This study presents a novel approach that leverages multiple
machine learning models to achieve precise monitoring under the limitation of
using a minimal number of visual sensors. By integrating state information from
identical timestamps, our method detects and confirms the current stage of the
assembly process with an average accuracy exceeding 92%. Furthermore, our
approach surpasses conventional methods by offering enhanced error detection
and visuali-zation capabilities, providing real-time, actionable guidance to
operators. This not only improves the accuracy and efficiency of assembly
monitoring but also re-duces dependency on expensive hardware solutions, making
it a more practical choice for modern industrial applications.

</details>


### [46] [PRIX: Learning to Plan from Raw Pixels for End-to-End Autonomous Driving](https://arxiv.org/abs/2507.17596)
*Maciej K. Wozniak,Lianhang Liu,Yixi Cai,Patric Jensfelt*

Main category: cs.CV

TL;DR: PRIX是一种仅使用摄像头的高效端到端自动驾驶架构，无需LiDAR或BEV，通过CaRT模块增强特征，在多个基准测试中表现优异且更高效。


<details>
  <summary>Details</summary>
Motivation: 解决当前端到端自动驾驶模型因模型体积大、依赖昂贵的LiDAR传感器和计算密集的BEV特征表示而难以实际部署的问题，尤其是针对仅配备摄像头的量产车辆。

Method: PRIX采用视觉特征提取器与生成式规划头结合的方式，直接从原始像素输入预测轨迹，并引入Context-aware Recalibration Transformer（CaRT）模块增强多级视觉特征。

Result: PRIX在NavSim和nuScenes基准测试中达到最先进性能，与更大的多模态扩散规划器能力相当，同时在推理速度和模型大小上显著更高效。

Conclusion: PRIX（Plan from Raw Pixels）是一种高效且实用的端到端自动驾驶架构，仅使用摄像头数据，无需显式的BEV表示或LiDAR，通过结合视觉特征提取器和生成式规划头，直接预测安全轨迹。

Abstract: While end-to-end autonomous driving models show promising results, their
practical deployment is often hindered by large model sizes, a reliance on
expensive LiDAR sensors and computationally intensive BEV feature
representations. This limits their scalability, especially for mass-market
vehicles equipped only with cameras. To address these challenges, we propose
PRIX (Plan from Raw Pixels). Our novel and efficient end-to-end driving
architecture operates using only camera data, without explicit BEV
representation and forgoing the need for LiDAR. PRIX leverages a visual feature
extractor coupled with a generative planning head to predict safe trajectories
from raw pixel inputs directly. A core component of our architecture is the
Context-aware Recalibration Transformer (CaRT), a novel module designed to
effectively enhance multi-level visual features for more robust planning. We
demonstrate through comprehensive experiments that PRIX achieves
state-of-the-art performance on the NavSim and nuScenes benchmarks, matching
the capabilities of larger, multimodal diffusion planners while being
significantly more efficient in terms of inference speed and model size, making
it a practical solution for real-world deployment. Our work is open-source and
the code will be at https://maxiuw.github.io/prix.

</details>


### [47] [CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance](https://arxiv.org/abs/2507.17312)
*Peiqi Chen,Lei Yu,Yi Wan,Yingying Pei,Xinyi Liu,Yongxiang Yao,Yingying Zhang,Lixiang Ru,Liheng Zhong,Jingdong Chen,Ming Yang,Yongjun Zhang*

Main category: cs.CV

TL;DR: CasP 是一种新型半密集特征匹配方法，通过级联对应先验和两阶段匹配提升效率和精度，适合高鲁棒性应用。


<details>
  <summary>Details</summary>
Motivation: 现有半密集特征匹配方法依赖于全局搜索，限制了精度和效率的进一步提升。

Method: CasP 采用了一种新颖的流水线，通过级联的对应先验进行引导。匹配阶段被分解为两个渐进阶段，通过区域选择性交叉注意力机制增强特征区分性。第二阶段的搜索范围限制在先前确定的一对多先验区域内。

Result: CasP 在高分辨率下加速效果显著，lite 模型在1152分辨率下比ELoFTR快约2.2倍，同时在几何估计中表现出色。

Conclusion: CasP 在几何估计中表现出色，尤其在跨域泛化方面，适合对延迟敏感和高鲁棒性要求的应用，如SLAM和无人机系统。

Abstract: Semi-dense feature matching methods have shown strong performance in
challenging scenarios. However, the existing pipeline relies on a global search
across the entire feature map to establish coarse matches, limiting further
improvements in accuracy and efficiency. Motivated by this limitation, we
propose a novel pipeline, CasP, which leverages cascaded correspondence priors
for guidance. Specifically, the matching stage is decomposed into two
progressive phases, bridged by a region-based selective cross-attention
mechanism designed to enhance feature discriminability. In the second phase,
one-to-one matches are determined by restricting the search range to the
one-to-many prior areas identified in the first phase. Additionally, this
pipeline benefits from incorporating high-level features, which helps reduce
the computational costs of low-level feature extraction. The acceleration gains
of CasP increase with higher resolution, and our lite model achieves a speedup
of $\sim2.2\times$ at a resolution of 1152 compared to the most efficient
method, ELoFTR. Furthermore, extensive experiments demonstrate its superiority
in geometric estimation, particularly with impressive cross-domain
generalization. These advantages highlight its potential for latency-sensitive
and high-robustness applications, such as SLAM and UAV systems. Code is
available at https://github.com/pq-chen/CasP.

</details>


### [48] [Monocular Semantic Scene Completion via Masked Recurrent Networks](https://arxiv.org/abs/2507.17661)
*Xuzhi Wang,Xinran Wu,Song Wang,Lingdong Kong,Ziping Zhao*

Main category: cs.CV

TL;DR: 论文提出了一种两阶段框架MonoMRN，通过掩码循环网络和距离注意力投影提升了单目语义场景补全的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有单阶段方法在同时处理可见区域分割和遮挡区域预测时性能不佳，尤其是在复杂场景中，且受深度估计不准确的影响。

Method: 提出了一个两阶段框架，将MSSC分解为粗MSSC和掩码循环网络（Masked Recurrent Network）。具体包括掩码稀疏门控循环单元（MS-GRU）和距离注意力投影，以减少计算成本并提升投影精度。

Result: MonoMRN在NYUv2和SemanticKITTI数据集上实现了最优性能，并通过鲁棒性分析验证了其抗干扰能力。

Conclusion: 论文提出的MonoMRN框架在单目语义场景补全任务中表现出色，支持室内外场景，并在NYUv2和SemanticKITTI数据集上实现了最先进的性能。此外，通过鲁棒性分析验证了掩码循环网络在增强模型抗干扰能力中的作用。

Abstract: Monocular Semantic Scene Completion (MSSC) aims to predict the voxel-wise
occupancy and semantic category from a single-view RGB image. Existing methods
adopt a single-stage framework that aims to simultaneously achieve visible
region segmentation and occluded region hallucination, while also being
affected by inaccurate depth estimation. Such methods often achieve suboptimal
performance, especially in complex scenes. We propose a novel two-stage
framework that decomposes MSSC into coarse MSSC followed by the Masked
Recurrent Network. Specifically, we propose the Masked Sparse Gated Recurrent
Unit (MS-GRU) which concentrates on the occupied regions by the proposed mask
updating mechanism, and a sparse GRU design is proposed to reduce the
computation cost. Additionally, we propose the distance attention projection to
reduce projection errors by assigning different attention scores according to
the distance to the observed surface. Experimental results demonstrate that our
proposed unified framework, MonoMRN, effectively supports both indoor and
outdoor scenes and achieves state-of-the-art performance on the NYUv2 and
SemanticKITTI datasets. Furthermore, we conduct robustness analysis under
various disturbances, highlighting the role of the Masked Recurrent Network in
enhancing the model's resilience to such challenges. The source code is
publicly available.

</details>


### [49] [CartoonAlive: Towards Expressive Live2D Modeling from Single Portraits](https://arxiv.org/abs/2507.17327)
*Chao He,Jianqiang Ren,Jianjing Xiang,Xiejie Shen*

Main category: cs.CV

TL;DR: CartoonAlive是一种创新方法，可从单张肖像图像快速生成高质量Live2D数字人，结合3D形状基概念和面部关键点检测，实现高效、高表现力的2D卡通角色创建。


<details>
  <summary>Details</summary>
Motivation: 当前主流数字人方法主要关注3D模型和2D视频表示，而交互式2D卡通风格数字人研究较少。Live2D模型提供了一种更高效和富有表现力的替代方案。

Method: 利用3D面部建模中常用的形状基概念构建适用于Live2D的面部混合形状，并通过从输入图像中检测面部关键点推断相应的混合形状权重。

Result: CartoonAlive能够在不到半分钟的时间内从单张输入肖像图像生成高质量、高度表现力的Live2D模型。

Conclusion: CartoonAlive提供了一种实用且可扩展的解决方案，用于创建交互式2D卡通角色，为数字内容创作和虚拟角色动画开辟了新可能性。

Abstract: With the rapid advancement of large foundation models, AIGC, cloud rendering,
and real-time motion capture technologies, digital humans are now capable of
achieving synchronized facial expressions and body movements, engaging in
intelligent dialogues driven by natural language, and enabling the fast
creation of personalized avatars. While current mainstream approaches to
digital humans primarily focus on 3D models and 2D video-based representations,
interactive 2D cartoon-style digital humans have received relatively less
attention. Compared to 3D digital humans that require complex modeling and high
rendering costs, and 2D video-based solutions that lack flexibility and
real-time interactivity, 2D cartoon-style Live2D models offer a more efficient
and expressive alternative. By simulating 3D-like motion through layered
segmentation without the need for traditional 3D modeling, Live2D enables
dynamic and real-time manipulation. In this technical report, we present
CartoonAlive, an innovative method for generating high-quality Live2D digital
humans from a single input portrait image. CartoonAlive leverages the shape
basis concept commonly used in 3D face modeling to construct facial blendshapes
suitable for Live2D. It then infers the corresponding blendshape weights based
on facial keypoints detected from the input image. This approach allows for the
rapid generation of a highly expressive and visually accurate Live2D model that
closely resembles the input portrait, within less than half a minute. Our work
provides a practical and scalable solution for creating interactive 2D cartoon
characters, opening new possibilities in digital content creation and virtual
character animation. The project homepage is
https://human3daigc.github.io/CartoonAlive_webpage/.

</details>


### [50] [Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras](https://arxiv.org/abs/2507.17664)
*Lingdong Kong,Dongyue Lu,Ao Liang,Rong Li,Yuhao Dong,Tianshuai Hu,Lai Xing Ng,Wei Tsang Ooi,Benoit R. Cottereau*

Main category: cs.CV

TL;DR: Talk2Event是首个大规模语言驱动事件相机感知基准，EventRefer框架通过多属性专家动态融合提升性能，为多模态时间感知研究铺路。


<details>
  <summary>Details</summary>
Motivation: 事件相机具有微秒级延迟和抗运动模糊特性，但如何将其异步数据流与人类语言连接仍是挑战。

Method: 提出了EventRefer框架，通过Mixture of Event-Attribute Experts (MoEE)动态融合多属性表征，适应不同模态和场景动态。

Result: 在纯事件、纯帧及事件-帧融合设置中，方法均优于现有基线。

Conclusion: Talk2Event和EventRefer为事件相机与语言驱动的感知任务提供了大规模基准和高效框架，为机器人及自动驾驶领域的多模态、时间感知研究奠定了基础。

Abstract: Event cameras offer microsecond-level latency and robustness to motion blur,
making them ideal for understanding dynamic environments. Yet, connecting these
asynchronous streams to human language remains an open challenge. We introduce
Talk2Event, the first large-scale benchmark for language-driven object
grounding in event-based perception. Built from real-world driving data, we
provide over 30,000 validated referring expressions, each enriched with four
grounding attributes -- appearance, status, relation to viewer, and relation to
other objects -- bridging spatial, temporal, and relational reasoning. To fully
exploit these cues, we propose EventRefer, an attribute-aware grounding
framework that dynamically fuses multi-attribute representations through a
Mixture of Event-Attribute Experts (MoEE). Our method adapts to different
modalities and scene dynamics, achieving consistent gains over state-of-the-art
baselines in event-only, frame-only, and event-frame fusion settings. We hope
our dataset and approach will establish a foundation for advancing multimodal,
temporally-aware, and language-driven perception in real-world robotics and
autonomy.

</details>


### [51] [PARTE: Part-Guided Texturing for 3D Human Reconstruction from a Single Image](https://arxiv.org/abs/2507.17332)
*Hyeongjin Nam,Donghwan Kim,Gyeongsik Moon,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: PARTE是一种利用3D人体部位信息指导纹理重建的新框架，通过部位分割和纹理对齐模块显著提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体重建方法在纹理对齐方面存在局限，尤其是不同人体部位的纹理容易混淆。PARTE旨在通过显式利用部位分割先验信息来解决这一问题。

Method: PARTE框架包含两个核心组件：3D部位分割模块（PartSegmenter）和部位引导的纹理重建模块（PartTexturer）。PartSegmenter从单张图像推断3D人体部位信息，而PartTexturer则利用预训练的图像生成网络知识来对齐人体部位的纹理。

Result: 实验表明，PARTE在3D人体重建质量上达到了最先进的水平。

Conclusion: PARTE框架通过利用3D人体部位信息作为关键指导，显著提升了3D人体纹理重建的质量，实现了最先进的性能。

Abstract: The misaligned human texture across different human parts is one of the main
limitations of existing 3D human reconstruction methods. Each human part, such
as a jacket or pants, should maintain a distinct texture without blending into
others. The structural coherence of human parts serves as a crucial cue to
infer human textures in the invisible regions of a single image. However, most
existing 3D human reconstruction methods do not explicitly exploit such part
segmentation priors, leading to misaligned textures in their reconstructions.
In this regard, we present PARTE, which utilizes 3D human part information as a
key guide to reconstruct 3D human textures. Our framework comprises two core
components. First, to infer 3D human part information from a single image, we
propose a 3D part segmentation module (PartSegmenter) that initially
reconstructs a textureless human surface and predicts human part labels based
on the textureless surface. Second, to incorporate part information into
texture reconstruction, we introduce a part-guided texturing module
(PartTexturer), which acquires prior knowledge from a pre-trained image
generation network on texture alignment of human parts. Extensive experiments
demonstrate that our framework achieves state-of-the-art quality in 3D human
reconstruction. The project page is available at
https://hygenie1228.github.io/PARTE/.

</details>


### [52] [Perspective-Invariant 3D Object Detection](https://arxiv.org/abs/2507.17665)
*Ao Liang,Lingdong Kong,Dongyue Lu,Youquan Liu,Jian Fang,Huaici Zhao,Wei Tsang Ooi*

Main category: cs.CV

TL;DR: Pi3DET introduces a multi-platform LiDAR dataset and a cross-platform adaptation framework for 3D object detection, showing significant improvements over existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing datasets and methods focus mainly on vehicle-mounted platforms, leaving other autonomous platforms underexplored. This gap is addressed by introducing Pi3DET.

Method: The paper proposes a novel cross-platform adaptation framework that transfers knowledge from vehicle platforms to others, achieving perspective-invariant detection through geometric and feature-level alignment.

Result: Extensive experiments show the approach's effectiveness in cross-platform tasks, outperforming existing adaptation methods. The Pi3DET dataset and tools are made publicly available.

Conclusion: This work introduces Pi3DET, a benchmark for LiDAR-based 3D object detection across multiple autonomous platforms, and proposes a cross-platform adaptation framework. It aims to pave the way for generalizable and unified 3D perception systems in diverse environments.

Abstract: With the rise of robotics, LiDAR-based 3D object detection has garnered
significant attention in both academia and industry. However, existing datasets
and methods predominantly focus on vehicle-mounted platforms, leaving other
autonomous platforms underexplored. To bridge this gap, we introduce Pi3DET,
the first benchmark featuring LiDAR data and 3D bounding box annotations
collected from multiple platforms: vehicle, quadruped, and drone, thereby
facilitating research in 3D object detection for non-vehicle platforms as well
as cross-platform 3D detection. Based on Pi3DET, we propose a novel
cross-platform adaptation framework that transfers knowledge from the
well-studied vehicle platform to other platforms. This framework achieves
perspective-invariant 3D detection through robust alignment at both geometric
and feature levels. Additionally, we establish a benchmark to evaluate the
resilience and robustness of current 3D detectors in cross-platform scenarios,
providing valuable insights for developing adaptive 3D perception systems.
Extensive experiments validate the effectiveness of our approach on challenging
cross-platform tasks, demonstrating substantial gains over existing adaptation
methods. We hope this work paves the way for generalizable and unified 3D
perception systems across diverse and complex environments. Our Pi3DET dataset,
cross-platform benchmark suite, and annotation toolkit have been made publicly
available.

</details>


### [53] [Temporal Point-Supervised Signal Reconstruction: A Human-Annotation-Free Framework for Weak Moving Target Detection](https://arxiv.org/abs/2507.17334)
*Weihua Gao,Chunxu Ren,Wenlong Niu,Xiaodong Peng*

Main category: cs.CV

TL;DR: A novel Temporal Point-Supervised framework detects weak moving targets without manual annotations, using temporal signal modeling and achieving high performance at 1000+ FPS.


<details>
  <summary>Details</summary>
Motivation: Existing methods for detecting weak moving targets in low-altitude surveillance systems struggle with robust feature extraction and lack reliable annotations, prompting the development of a novel, annotation-free approach.

Method: The framework reformulates detection as a pixel-wise temporal signal modeling problem, utilizing a Temporal Signal Reconstruction Network (TSRNet) with Dynamic Multi-Scale Attention (DMSAttention) and a graph-based trajectory mining strategy for enhanced sensitivity and consistency.

Result: Experiments on a low-SNR dataset show the framework outperforms state-of-the-art methods, achieving strong detection performance and operating at over 1000 FPS.

Conclusion: The proposed Temporal Point-Supervised (TPS) framework effectively addresses the challenge of detecting weak moving targets in low-altitude surveillance systems without requiring manual annotations, achieving high performance and real-time operation.

Abstract: In low-altitude surveillance and early warning systems, detecting weak moving
targets remains a significant challenge due to low signal energy, small spatial
extent, and complex background clutter. Existing methods struggle with
extracting robust features and suffer from the lack of reliable annotations. To
address these limitations, we propose a novel Temporal Point-Supervised (TPS)
framework that enables high-performance detection of weak targets without any
manual annotations.Instead of conventional frame-based detection, our framework
reformulates the task as a pixel-wise temporal signal modeling problem, where
weak targets manifest as short-duration pulse-like responses. A Temporal Signal
Reconstruction Network (TSRNet) is developed under the TPS paradigm to
reconstruct these transient signals.TSRNet adopts an encoder-decoder
architecture and integrates a Dynamic Multi-Scale Attention (DMSAttention)
module to enhance its sensitivity to diverse temporal patterns. Additionally, a
graph-based trajectory mining strategy is employed to suppress false alarms and
ensure temporal consistency.Extensive experiments on a purpose-built low-SNR
dataset demonstrate that our framework outperforms state-of-the-art methods
while requiring no human annotations. It achieves strong detection performance
and operates at over 1000 FPS, underscoring its potential for real-time
deployment in practical scenarios.

</details>


### [54] [TransLPRNet: Lite Vision-Language Network for Single/Dual-line Chinese License Plate Recognition](https://arxiv.org/abs/2507.17335)
*Guangzhu Xu,Zhi Ke,Pengcheng Zuo,Bangjun Lei*

Main category: cs.CV

TL;DR: 论文提出了一种结合轻量级视觉编码器和文本解码器的预训练框架，用于单双线车牌识别，通过视角校正网络提升准确率，实验结果显示高准确率和快速处理速度。


<details>
  <summary>Details</summary>
Motivation: 针对CNN和CRNN在车牌识别中的局限性，以及双线车牌数据集稀缺的问题，研究旨在提出一种更高效的解决方案。

Method: 论文提出了一种轻量级视觉编码器与文本解码器结合的预训练框架，并引入了视角校正网络（PTN）以提高识别准确率。

Result: 在粗定位干扰下，算法在CCPD测试集上的平均识别准确率为99.34%；在细定位干扰下提升至99.58%。双线车牌测试集上的平均识别准确率为98.70%，处理速度达167帧/秒。

Conclusion: 该论文提出的统一解决方案在单双线车牌识别中表现出色，识别准确率高且处理速度快，具有很强的实际应用价值。

Abstract: License plate recognition in open environments is widely applicable across
various domains; however, the diversity of license plate types and imaging
conditions presents significant challenges. To address the limitations
encountered by CNN and CRNN-based approaches in license plate recognition, this
paper proposes a unified solution that integrates a lightweight visual encoder
with a text decoder, within a pre-training framework tailored for single and
double-line Chinese license plates. To mitigate the scarcity of double-line
license plate datasets, we constructed a single/double-line license plate
dataset by synthesizing images, applying texture mapping onto real scenes, and
blending them with authentic license plate images. Furthermore, to enhance the
system's recognition accuracy, we introduce a perspective correction network
(PTN) that employs license plate corner coordinate regression as an implicit
variable, supervised by license plate view classification information. This
network offers improved stability, interpretability, and low annotation costs.
The proposed algorithm achieves an average recognition accuracy of 99.34% on
the corrected CCPD test set under coarse localization disturbance. When
evaluated under fine localization disturbance, the accuracy further improves to
99.58%. On the double-line license plate test set, it achieves an average
recognition accuracy of 98.70%, with processing speeds reaching up to 167
frames per second, indicating strong practical applicability.

</details>


### [55] [Swin-TUNA : A Novel PEFT Approach for Accurate Food Image Segmentation](https://arxiv.org/abs/2507.17347)
*Haotian Chen,Zhiyong Xiao*

Main category: cs.CV

TL;DR: Swin-TUNA 是一种高效轻量级的食品图像分割方法，通过多尺度适配器和分层特征适应机制，仅需更新4%参数，显著降低计算资源需求，同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模 Transformer 模型（如 FoodSAM）因参数过多和计算资源需求高，难以满足实际部署需求。

Method: Swin-TUNA 是一种参数高效微调（PEFT）方法，通过将多尺度可训练适配器集成到 Swin Transformer 架构中，仅更新4%的参数。其核心创新是分层特征适应机制，包括深度可分离卷积和多尺度维度映射，结合动态平衡策略处理任务无关和任务特定特征。

Result: 在 FoodSeg103 和 UECFoodPix Complete 数据集上，Swin-TUNA 分别实现了50.56%和74.94%的 mIoU，超越了完全参数化的 FoodSAM 模型，同时参数数量减少至8.13M（减少98.7%）。此外，在低数据场景下表现出更快的收敛速度和更强的泛化能力。

Conclusion: Swin-TUNA 提供了一种高效的轻量级食品图像分割解决方案，显著减少了参数数量（减少98.7%）并提升了性能，适用于实际部署。

Abstract: In the field of food image processing, efficient semantic segmentation
techniques are crucial for industrial applications. However, existing
large-scale Transformer-based models (such as FoodSAM) face challenges in
meeting practical deploymentrequirements due to their massive parameter counts
and high computational resource demands. This paper introduces TUNable Adapter
module (Swin-TUNA), a Parameter Efficient Fine-Tuning (PEFT) method that
integrates multiscale trainable adapters into the Swin Transformer
architecture, achieving high-performance food image segmentation by updating
only 4% of the parameters. The core innovation of Swin-TUNA lies in its
hierarchical feature adaptation mechanism: it designs separable convolutions in
depth and dimensional mappings of varying scales to address the differences in
features between shallow and deep networks, combined with a dynamic balancing
strategy for tasks-agnostic and task-specific features. Experiments demonstrate
that this method achieves mIoU of 50.56% and 74.94% on the FoodSeg103 and
UECFoodPix Complete datasets, respectively, surpassing the fully parameterized
FoodSAM model while reducing the parameter count by 98.7% (to only 8.13M).
Furthermore, Swin-TUNA exhibits faster convergence and stronger generalization
capabilities in low-data scenarios, providing an efficient solution for
assembling lightweight food image.

</details>


### [56] [DeMo++: Motion Decoupling for Autonomous Driving](https://arxiv.org/abs/2507.17342)
*Bozhou Zhang,Nan Song,Xiatian Zhu,Li Zhang*

Main category: cs.CV

TL;DR: DeMo++通过解耦运动意图与时空状态，结合跨场景交互，显著提升了自动驾驶系统的轨迹预测和规划能力。


<details>
  <summary>Details</summary>
Motivation: 现有的一查询一轨迹范式在建模复杂时空轨迹演化时表现不佳，可能导致碰撞或次优结果。

Method: 提出了DeMo++框架，将运动估计解耦为整体运动意图和精细时空状态，并引入跨场景轨迹交互机制。采用结合Attention和Mamba的混合模型架构。

Result: DeMo++在多个基准测试（Argoverse 2、nuScenes、nuPlan、NAVSIM）中实现了最先进的性能。

Conclusion: DeMo++通过解耦运动估计为整体运动意图和精细时空状态，结合跨场景轨迹交互机制，实现了对运动意图多样性和轨迹时空演化的全面建模，在多个基准测试中达到了最先进的性能。

Abstract: Motion forecasting and planning are tasked with estimating the trajectories
of traffic agents and the ego vehicle, respectively, to ensure the safety and
efficiency of autonomous driving systems in dynamically changing environments.
State-of-the-art methods typically adopt a one-query-one-trajectory paradigm,
where each query corresponds to a unique trajectory for predicting multi-mode
trajectories. While this paradigm can produce diverse motion intentions, it
often falls short in modeling the intricate spatiotemporal evolution of
trajectories, which can lead to collisions or suboptimal outcomes. To overcome
this limitation, we propose DeMo++, a framework that decouples motion
estimation into two distinct components: holistic motion intentions to capture
the diverse potential directions of movement, and fine spatiotemporal states to
track the agent's dynamic progress within the scene and enable a
self-refinement capability. Further, we introduce a cross-scene trajectory
interaction mechanism to explore the relationships between motions in adjacent
scenes. This allows DeMo++ to comprehensively model both the diversity of
motion intentions and the spatiotemporal evolution of each trajectory. To
effectively implement this framework, we developed a hybrid model combining
Attention and Mamba. This architecture leverages the strengths of both
mechanisms for efficient scene information aggregation and precise trajectory
state sequence modeling. Extensive experiments demonstrate that DeMo++ achieves
state-of-the-art performance across various benchmarks, including motion
forecasting (Argoverse 2 and nuScenes), motion planning (nuPlan), and
end-to-end planning (NAVSIM).

</details>


### [57] [SFUOD: Source-Free Unknown Object Detection](https://arxiv.org/abs/2507.17373)
*Keon-Hee Park,Seun-An Choe,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: 提出SFUOD场景和CollaPAUL框架，通过协作调谐和主轴标记实现源自由未知对象检测，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决源自由目标检测中仅能识别预定义对象的限制，提出SFUOD场景以检测未知对象。

Method: CollaPAUL通过协作调谐和基于主轴的未知标记，结合跨领域注意力机制和主轴投影估计物体性。

Result: CollaPAUL在SFUOD基准测试中表现优异，验证了其有效性。

Conclusion: CollaPAUL框架在SFUOD基准测试中实现了最先进的性能，并通过广泛实验验证了其有效性。

Abstract: Source-free object detection adapts a detector pre-trained on a source domain
to an unlabeled target domain without requiring access to labeled source data.
While this setting is practical as it eliminates the need for the source
dataset during domain adaptation, it operates under the restrictive assumption
that only pre-defined objects from the source domain exist in the target
domain. This closed-set setting prevents the detector from detecting undefined
objects. To ease this assumption, we propose Source-Free Unknown Object
Detection (SFUOD), a novel scenario which enables the detector to not only
recognize known objects but also detect undefined objects as unknown objects.
To this end, we propose CollaPAUL (Collaborative tuning and Principal
Axis-based Unknown Labeling), a novel framework for SFUOD. Collaborative tuning
enhances knowledge adaptation by integrating target-dependent knowledge from
the auxiliary encoder with source-dependent knowledge from the pre-trained
detector through a cross-domain attention mechanism. Additionally, principal
axes-based unknown labeling assigns pseudo-labels to unknown objects by
estimating objectness via principal axes projection and confidence scores from
model predictions. The proposed CollaPAUL achieves state-of-the-art
performances on SFUOD benchmarks, and extensive experiments validate its
effectiveness.

</details>


### [58] [Principled Multimodal Representation Learning](https://arxiv.org/abs/2507.17343)
*Xiaohao Liu,Xiaobo Xia,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: PMRL 是一种无锚点依赖的多模态表示学习框架，通过优化主导奇异值实现稳定对齐，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预定义的锚模态，限制了多模态对齐的灵活性。现有方法在多模态同时对齐中存在固定锚点和优化不稳定等问题。

Method: PMRL 框架基于理论洞察，即完全对齐对应于秩-1 的 Gram 矩阵，通过优化表示矩阵的主导奇异值来实现多模态对齐。提出了一种基于 softmax 的损失函数，将奇异值视为 logits，以优先考虑最大奇异值。此外，通过实例级对比正则化保持实例间分离性。

Result: PMRL 在多个任务上的实验表明其优于基线方法。

Conclusion: PMRL 通过优化表示矩阵的主导奇异值，实现了多模态的无锚点依赖对齐，并在实验中表现出优于基线方法的性能。

Abstract: Multimodal representation learning seeks to create a unified representation
space by integrating diverse data modalities to improve multimodal
understanding. Traditional methods often depend on pairwise contrastive
learning, which relies on a predefined anchor modality, restricting alignment
across all modalities. Recent advances have investigated the simultaneous
alignment of multiple modalities, yet several challenges remain, such as
limitations imposed by fixed anchor points and instability arising from
optimizing the product of singular values. To address the challenges, in this
paper, we propose Principled Multimodal Representation Learning (PMRL), a novel
framework that achieves simultaneous alignment of multiple modalities without
anchor dependency in a more stable manner. Specifically, grounded in the
theoretical insight that full alignment corresponds to a rank-1 Gram matrix,
PMRL optimizes the dominant singular value of the representation matrix to
align modalities along a shared leading direction. We propose a softmax-based
loss function that treats singular values as logits to prioritize the largest
singular value. Besides, instance-wise contrastive regularization on the
leading eigenvectors maintains inter-instance separability and prevents
representation collapse. Extensive experiments across diverse tasks demonstrate
PMRL's superiority compared to baseline methods. The source code will be
publicly available.

</details>


### [59] [HiProbe-VAD: Video Anomaly Detection via Hidden States Probing in Tuning-Free Multimodal LLMs](https://arxiv.org/abs/2507.17394)
*Zhaolin Cai,Fan Li,Ziwei Zheng,Yanjun Qin*

Main category: cs.CV

TL;DR: HiProbe-VAD利用MLLMs的中间隐藏状态，通过DLSP机制和轻量级模块实现高效视频异常检测，无需微调且性能优越。


<details>
  <summary>Details</summary>
Motivation: 传统方法存在计算需求高和依赖大量标注数据的限制，HiProbe-VAD旨在解决这些问题，利用MLLMs的中间隐藏状态实现无需微调的高效异常检测。

Method: 提出了动态层显著性探测（DLSP）机制，智能识别并提取MLLMs推理过程中最优中间层的最具信息量的隐藏状态，随后通过轻量级异常评分器和时间定位模块高效检测异常并生成解释。

Result: 在UCF-Crime和XD-Violence数据集上的实验表明，HiProbe-VAD优于现有的无训练方法和大多数传统方法，并展示了出色的跨模型泛化能力。

Conclusion: HiProbe-VAD 通过利用预训练的多模态大语言模型（MLLMs）的中间隐藏状态，显著提升了视频异常检测的性能，并在无需微调的情况下展示了卓越的跨模型泛化能力。

Abstract: Video Anomaly Detection (VAD) aims to identify and locate deviations from
normal patterns in video sequences. Traditional methods often struggle with
substantial computational demands and a reliance on extensive labeled datasets,
thereby restricting their practical applicability. To address these
constraints, we propose HiProbe-VAD, a novel framework that leverages
pre-trained Multimodal Large Language Models (MLLMs) for VAD without requiring
fine-tuning. In this paper, we discover that the intermediate hidden states of
MLLMs contain information-rich representations, exhibiting higher sensitivity
and linear separability for anomalies compared to the output layer. To
capitalize on this, we propose a Dynamic Layer Saliency Probing (DLSP)
mechanism that intelligently identifies and extracts the most informative
hidden states from the optimal intermediate layer during the MLLMs reasoning.
Then a lightweight anomaly scorer and temporal localization module efficiently
detects anomalies using these extracted hidden states and finally generate
explanations. Experiments on the UCF-Crime and XD-Violence datasets demonstrate
that HiProbe-VAD outperforms existing training-free and most traditional
approaches. Furthermore, our framework exhibits remarkable cross-model
generalization capabilities in different MLLMs without any tuning, unlocking
the potential of pre-trained MLLMs for video anomaly detection and paving the
way for more practical and scalable solutions.

</details>


### [60] [Exploring Active Learning for Label-Efficient Training of Semantic Neural Radiance Field](https://arxiv.org/abs/2507.17351)
*Yuzhe Zhu,Lile Cai,Kangkang Lu,Fayao Liu,Xulei Yang*

Main category: cs.CV

TL;DR: 通过主动学习策略，显著降低语义感知NeRF的标注成本，效率提升2倍。


<details>
  <summary>Details</summary>
Motivation: 语义感知NeRF的训练通常需要像素级类别标注，但标注成本高昂，因此研究如何通过主动学习减轻标注负担。

Method: 探索了主动学习在语义感知NeRF中的应用，包括选择粒度和策略，并提出了一种考虑3D几何约束的新策略。

Result: 实验表明，主动学习能显著减少标注成本，效率是随机采样的2倍以上。

Conclusion: 主动学习策略能有效降低语义感知NeRF的训练标注成本，相比随机采样，标注成本减少了2倍以上。

Abstract: Neural Radiance Field (NeRF) models are implicit neural scene representation
methods that offer unprecedented capabilities in novel view synthesis.
Semantically-aware NeRFs not only capture the shape and radiance of a scene,
but also encode semantic information of the scene. The training of
semantically-aware NeRFs typically requires pixel-level class labels, which can
be prohibitively expensive to collect. In this work, we explore active learning
as a potential solution to alleviate the annotation burden. We investigate
various design choices for active learning of semantically-aware NeRF,
including selection granularity and selection strategies. We further propose a
novel active learning strategy that takes into account 3D geometric constraints
in sample selection. Our experiments demonstrate that active learning can
effectively reduce the annotation cost of training semantically-aware NeRF,
achieving more than 2X reduction in annotation cost compared to random
sampling.

</details>


### [61] [Content-based 3D Image Retrieval and a ColBERT-inspired Re-ranking for Tumor Flagging and Staging](https://arxiv.org/abs/2507.17412)
*Farnaz Khun Jush,Steffen Vogler,Matthias Lenga*

Main category: cs.CV

TL;DR: 该研究提出C-MIR方法，通过上下文感知重新排序提升3D医学影像检索效率，显著改善肿瘤标记性能，为临床实践提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 医疗影像数量的增加使放射科医生在检索相关病例时面临挑战，现有的CBIR系统缺乏标准化评估和全面研究，因此需要更高效的解决方案。

Method: 研究提出了C-MIR，一种基于ColBERT上下文化后期交互机制的3D医学影像重新排序方法，无需依赖预分割数据或器官特定数据集，并在四种肿瘤部位上进行了全面评估。

Result: C-MIR在肿瘤标记（尤其是结肠和肺部肿瘤）中表现出显著性能提升（p<0.05），并展示了在肿瘤分期中的潜力，同时有效定位感兴趣区域，避免了昂贵的数据预处理步骤。

Conclusion: 该研究通过C-MIR方法成功将先进的检索技术应用于医疗影像，显著提升了肿瘤标记和分期的性能，为医疗诊断流程的改进铺平了道路。

Abstract: The increasing volume of medical images poses challenges for radiologists in
retrieving relevant cases. Content-based image retrieval (CBIR) systems offer
potential for efficient access to similar cases, yet lack standardized
evaluation and comprehensive studies. Building on prior studies for tumor
characterization via CBIR, this study advances CBIR research for volumetric
medical images through three key contributions: (1) a framework eliminating
reliance on pre-segmented data and organ-specific datasets, aligning with large
and unstructured image archiving systems, i.e. PACS in clinical practice; (2)
introduction of C-MIR, a novel volumetric re-ranking method adapting ColBERT's
contextualized late interaction mechanism for 3D medical imaging; (3)
comprehensive evaluation across four tumor sites using three feature extractors
and three database configurations. Our evaluations highlight the significant
advantages of C-MIR. We demonstrate the successful adaptation of the late
interaction principle to volumetric medical images, enabling effective
context-aware re-ranking. A key finding is C-MIR's ability to effectively
localize the region of interest, eliminating the need for pre-segmentation of
datasets and offering a computationally efficient alternative to systems
relying on expensive data enrichment steps. C-MIR demonstrates promising
improvements in tumor flagging, achieving improved performance, particularly
for colon and lung tumors (p<0.05). C-MIR also shows potential for improving
tumor staging, warranting further exploration of its capabilities. Ultimately,
our work seeks to bridge the gap between advanced retrieval techniques and
their practical applications in healthcare, paving the way for improved
diagnostic processes.

</details>


### [62] [Exploring Active Learning for Semiconductor Defect Segmentation](https://arxiv.org/abs/2507.17359)
*Lile Cai,Ramanpreet Singh Pahwa,Xun Xu,Jie Wang,Richard Chang,Lining Zhang,Chuan-Sheng Foo*

Main category: cs.CV

TL;DR: 该论文提出了一种结合对比预训练和稀有感知采集函数的主动学习方法，用于减少半导体X射线显微镜扫描的标注需求，并有效处理类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 针对半导体X射线显微镜扫描中深度学习模型需要大量标注数据的问题，探索主动学习作为解决方案，同时应对域偏移和类别不平衡的挑战。

Method: 论文采用了对比预训练和稀有感知采集函数的主动学习方法，以减轻标注负担并处理类别不平衡。

Result: 在由高带宽内存结构的X射线显微镜扫描组成的半导体数据集上，所提方法达到了最先进的性能。

Conclusion: 该论文提出了一种结合对比预训练和稀有感知采集函数的主动学习方法，有效解决了半导体X射线显微镜扫描中的大域偏移和严重类别不平衡问题，并在实验中展现了最先进的性能。

Abstract: The development of X-Ray microscopy (XRM) technology has enabled
non-destructive inspection of semiconductor structures for defect
identification. Deep learning is widely used as the state-of-the-art approach
to perform visual analysis tasks. However, deep learning based models require
large amount of annotated data to train. This can be time-consuming and
expensive to obtain especially for dense prediction tasks like semantic
segmentation. In this work, we explore active learning (AL) as a potential
solution to alleviate the annotation burden. We identify two unique challenges
when applying AL on semiconductor XRM scans: large domain shift and severe
class-imbalance. To address these challenges, we propose to perform contrastive
pretraining on the unlabelled data to obtain the initialization weights for
each AL cycle, and a rareness-aware acquisition function that favors the
selection of samples containing rare classes. We evaluate our method on a
semiconductor dataset that is compiled from XRM scans of high bandwidth memory
structures composed of logic and memory dies, and demonstrate that our method
achieves state-of-the-art performance.

</details>


### [63] [Exploring Spatial Diversity for Region-based Active Learning](https://arxiv.org/abs/2507.17367)
*Lile Cai,Xun Xu,Lining Zhang,Chuan-Sheng Foo*

Main category: cs.CV

TL;DR: Proposed a region-based active learning framework with spatial diversity to reduce annotation costs, achieving near-fully supervised performance with minimal labeled data.


<details>
  <summary>Details</summary>
Motivation: To reduce the high annotation costs associated with acquiring large-scale labeled datasets for semantic segmentation, especially for dense pixel-level prediction tasks.

Method: We propose enforcing local spatial diversity in a unified optimization framework for region-based active learning, combining it with traditional active selection criteria like data sample uncertainty.

Result: The inclusion of spatial diversity effectively improves the performance of uncertainty-based and feature diversity-based active learning methods on the Cityscapes and PASCAL VOC datasets.

Conclusion: Our framework achieves 95% performance of fully supervised methods with only 5-9% of the labeled pixels, outperforming all state-of-the-art region-based active learning methods for semantic segmentation.

Abstract: State-of-the-art methods for semantic segmentation are based on deep neural
networks trained on large-scale labeled datasets. Acquiring such datasets would
incur large annotation costs, especially for dense pixel-level prediction tasks
like semantic segmentation. We consider region-based active learning as a
strategy to reduce annotation costs while maintaining high performance. In this
setting, batches of informative image regions instead of entire images are
selected for labeling. Importantly, we propose that enforcing local spatial
diversity is beneficial for active learning in this case, and to incorporate
spatial diversity along with the traditional active selection criterion, e.g.,
data sample uncertainty, in a unified optimization framework for region-based
active learning. We apply this framework to the Cityscapes and PASCAL VOC
datasets and demonstrate that the inclusion of spatial diversity effectively
improves the performance of uncertainty-based and feature diversity-based
active learning methods. Our framework achieves $95\%$ performance of fully
supervised methods with only $5-9\%$ of the labeled pixels, outperforming all
state-of-the-art region-based active learning methods for semantic
segmentation.

</details>


### [64] [Probing Vision-Language Understanding through the Visual Entailment Task: promises and pitfalls](https://arxiv.org/abs/2507.17467)
*Elena Pitta,Tom Kouwenhoven,Tessa Verhoef*

Main category: cs.CV

TL;DR: 研究探讨视觉蕴含任务对多模态语言模型视觉语言理解的诊断能力，通过实验发现三样本推理最佳但额外示例引入噪声，微调表现优异但视觉基础存疑。


<details>
  <summary>Details</summary>
Motivation: 旨在探究视觉蕴含（VE）任务作为多模态语言模型中视觉语言理解的可靠探针的程度，并解释这些结果对VE任务潜在可能性和局限性的启示。

Method: 通过零样本、少样本和微调设置的一系列实验，探讨了提示设计、上下文示例的数量和顺序以及视觉信息访问等因素对VE性能的影响，并采用基于解释的评估进一步探究模型的推理过程。

Result: 三样本推理优于零样本基线，但额外示例会引入噪声；提示中标签顺序显著影响预测；缺乏视觉信息时模型易产生幻觉；微调后在e-SNLI-VE数据集上达到83.3%的准确率，超过OFA-X模型；解释评估显示微调模型提供与人类相似的语义解释（BERTScore F1-score为89.2%）。

Conclusion: 本研究强调了视觉蕴含（VE）任务作为视觉语言理解诊断工具的实用性和局限性，并指出了改进多模态评估方法的方向。

Abstract: This study investigates the extent to which the Visual Entailment (VE) task
serves as a reliable probe of vision-language understanding in multimodal
language models, using the LLaMA 3.2 11B Vision model as a test case. Beyond
reporting performance metrics, we aim to interpret what these results reveal
about the underlying possibilities and limitations of the VE task. We conduct a
series of experiments across zero-shot, few-shot, and fine-tuning settings,
exploring how factors such as prompt design, the number and order of in-context
examples and access to visual information might affect VE performance. To
further probe the reasoning processes of the model, we used explanation-based
evaluations. Results indicate that three-shot inference outperforms the
zero-shot baselines. However, additional examples introduce more noise than
they provide benefits. Additionally, the order of the labels in the prompt is a
critical factor that influences the predictions. In the absence of visual
information, the model has a strong tendency to hallucinate and imagine
content, raising questions about the model's over-reliance on linguistic
priors. Fine-tuning yields strong results, achieving an accuracy of 83.3% on
the e-SNLI-VE dataset and outperforming the state-of-the-art OFA-X model.
Additionally, the explanation evaluation demonstrates that the fine-tuned model
provides semantically meaningful explanations similar to those of humans, with
a BERTScore F1-score of 89.2%. We do, however, find comparable BERTScore
results in experiments with limited vision, questioning the visual grounding of
this task. Overall, our results highlight both the utility and limitations of
VE as a diagnostic task for vision-language understanding and point to
directions for refining multimodal evaluation methods.

</details>


### [65] [Unsupervised anomaly detection using Bayesian flow networks: application to brain FDG PET in the context of Alzheimer's disease](https://arxiv.org/abs/2507.17486)
*Hugues Roy,Reuben Dorent,Ninon Burgos*

Main category: cs.CV

TL;DR: AnoBFN, a new BFN-based method, excels in detecting Alzheimer's anomalies in PET images, beating current top techniques with lower false positives.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of identifying neurological disorders through unsupervised anomaly detection in neuroimaging, leveraging the untapped potential of Bayesian flow networks (BFNs) in medical imaging.

Method: AnoBFN leverages Bayesian flow networks (BFNs) for UAD, combining diffusion frameworks and Bayesian inference. It features conditional image generation under high noise and recursive feedback to preserve subject specificity.

Result: AnoBFN outperforms state-of-the-art methods (beta-VAE, f-AnoGAN, AnoDDPM) in detecting Alzheimer's disease-related anomalies, with reduced false positive rates.

Conclusion: AnoBFN, an extension of Bayesian flow networks (BFNs), demonstrates superior performance in unsupervised anomaly detection (UAD) for Alzheimer's disease-related anomalies in FDG PET images, outperforming existing methods like beta-VAE, f-AnoGAN, and AnoDDPM.

Abstract: Unsupervised anomaly detection (UAD) plays a crucial role in neuroimaging for
identifying deviations from healthy subject data and thus facilitating the
diagnosis of neurological disorders. In this work, we focus on Bayesian flow
networks (BFNs), a novel class of generative models, which have not yet been
applied to medical imaging or anomaly detection. BFNs combine the strength of
diffusion frameworks and Bayesian inference. We introduce AnoBFN, an extension
of BFNs for UAD, designed to: i) perform conditional image generation under
high levels of spatially correlated noise, and ii) preserve subject specificity
by incorporating a recursive feedback from the input image throughout the
generative process. We evaluate AnoBFN on the challenging task of Alzheimer's
disease-related anomaly detection in FDG PET images. Our approach outperforms
other state-of-the-art methods based on VAEs (beta-VAE), GANs (f-AnoGAN), and
diffusion models (AnoDDPM), demonstrating its effectiveness at detecting
anomalies while reducing false positive rates.

</details>


### [66] [A Conditional Probability Framework for Compositional Zero-shot Learning](https://arxiv.org/abs/2507.17377)
*Peng Wu,Qiuxia Lai,Hao Fang,Guo-Sen Xie,Yilong Yin,Xiankai Lu,Wenguan Wang*

Main category: cs.CV

TL;DR: 本文提出了一种条件概率框架（CPF），通过显式建模属性-对象依赖关系，结合文本描述符和交叉注意力机制，有效提升组合零样本学习性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法将属性和对象视为独立实体，忽略了组合内部的语义约束和上下文依赖。例如，某些属性天然与特定对象配对（如“条纹”适用于“斑马”或“衬衫”，但不适用于“天空”或“水”）。因此，捕捉属性-对象相互依赖是CZSL中一个长期被忽视的挑战。

Method: 采用条件概率框架（CPF）分解组合概率为对象似然和条件属性似然，结合文本描述符增强对象特征学习，并通过交叉注意力机制引导属性学习。

Result: 在多个CZSL基准测试中，该方法表现出优越性。

Conclusion: 通过条件概率框架（CPF）显式建模属性-对象依赖关系，联合优化对象似然和条件属性似然，有效捕捉组合依赖关系，并在未见组合上表现优异。

Abstract: Compositional Zero-Shot Learning (CZSL) aims to recognize unseen combinations
of known objects and attributes by leveraging knowledge from previously seen
compositions. Traditional approaches primarily focus on disentangling
attributes and objects, treating them as independent entities during learning.
However, this assumption overlooks the semantic constraints and contextual
dependencies inside a composition. For example, certain attributes naturally
pair with specific objects (e.g., "striped" applies to "zebra" or "shirts" but
not "sky" or "water"), while the same attribute can manifest differently
depending on context (e.g., "young" in "young tree" vs. "young dog"). Thus,
capturing attribute-object interdependence remains a fundamental yet
long-ignored challenge in CZSL. In this paper, we adopt a Conditional
Probability Framework (CPF) to explicitly model attribute-object dependencies.
We decompose the probability of a composition into two components: the
likelihood of an object and the conditional likelihood of its attribute. To
enhance object feature learning, we incorporate textual descriptors to
highlight semantically relevant image regions. These enhanced object features
then guide attribute learning through a cross-attention mechanism, ensuring
better contextual alignment. By jointly optimizing object likelihood and
conditional attribute likelihood, our method effectively captures compositional
dependencies and generalizes well to unseen compositions. Extensive experiments
on multiple CZSL benchmarks demonstrate the superiority of our approach. Code
is available at here.

</details>


### [67] [EndoGen: Conditional Autoregressive Endoscopic Video Generation](https://arxiv.org/abs/2507.17388)
*Xinyu Liu,Hengyu Liu,Cheng Wang,Tianming Liu,Yixuan Yuan*

Main category: cs.CV

TL;DR: EndoGen是首个条件性内窥镜视频生成框架，结合SGP和SAT机制，有效生成动态视频并提升下游任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么局限于静态图像，缺乏动态上下文，要么是无条件生成，无法为临床医生提供有意义的参考。因此，需要一种条件性内窥镜视频生成框架。

Method: 构建了一个自回归模型，结合了Spatiotemporal Grid-Frame Patterning（SGP）策略和Semantic-Aware Token Masking（SAT）机制。

Result: 实验证明了EndoGen在生成高质量、条件性引导的内窥镜内容方面的有效性，并提升了息肉分割任务的性能。

Conclusion: EndoGen框架通过创新的Spatiotemporal Grid-Frame Patterning策略和Semantic-Aware Token Masking机制，成功实现了高质量的条件性内窥镜视频生成，并提升了下游息肉分割任务的性能。

Abstract: Endoscopic video generation is crucial for advancing medical imaging and
enhancing diagnostic capabilities. However, prior efforts in this field have
either focused on static images, lacking the dynamic context required for
practical applications, or have relied on unconditional generation that fails
to provide meaningful references for clinicians. Therefore, in this paper, we
propose the first conditional endoscopic video generation framework, namely
EndoGen. Specifically, we build an autoregressive model with a tailored
Spatiotemporal Grid-Frame Patterning (SGP) strategy. It reformulates the
learning of generating multiple frames as a grid-based image generation
pattern, which effectively capitalizes the inherent global dependency modeling
capabilities of autoregressive architectures. Furthermore, we propose a
Semantic-Aware Token Masking (SAT) mechanism, which enhances the model's
ability to produce rich and diverse content by selectively focusing on
semantically meaningful regions during the generation process. Through
extensive experiments, we demonstrate the effectiveness of our framework in
generating high-quality, conditionally guided endoscopic content, and improves
the performance of downstream task of polyp segmentation. Code released at
https://www.github.com/CUHK-AIM-Group/EndoGen.

</details>


### [68] [Vision Transformer attention alignment with human visual perception in aesthetic object evaluation](https://arxiv.org/abs/2507.17616)
*Miguel Carrasco,César González-Martín,José Aranda,Luis Oliveros*

Main category: cs.CV

TL;DR: 研究表明，ViT的某些注意力头（如第12头）能近似人类视觉行为，但整体上ViT的注意力更全局化。这为产品设计和美学评估提供了新思路，但也揭示了AI与人类注意力策略的差异。


<details>
  <summary>Details</summary>
Motivation: 尽管ViT在计算机视觉任务中表现出色，但其与人类视觉注意力模式的关联性，尤其是在美学评估中，尚未充分探索。本研究旨在填补这一空白，探究ViT注意力机制与人类视觉行为的相关性。

Method: 研究通过眼动追踪实验（30名参与者）记录人类视觉注意力模式，并使用预训练的ViT模型（DINO）提取注意力图。通过Kullback-Leibler散度比较人类和ViT的注意力分布，并分析不同高斯参数（sigma=0.1至3.0）下的相关性。

Result: 统计显示，在sigma=2.4 +-0.03时相关性最佳，注意力头#12与人类视觉模式最接近。注意力头#7和#9与人类注意力的差异最大（p<0.05）。

Conclusion: 研究发现，尽管ViT的注意力模式比人类的焦点注意力更全局化，但某些注意力头（如第12头）能够近似人类的视觉行为，尤其是在特定物体特征（如篮筐物品的扣环）上。这表明ViT注意力机制在产品设计和美学评估中具有潜在应用价值，同时也揭示了人类感知与当前AI模型在注意力策略上的根本差异。

Abstract: Visual attention mechanisms play a crucial role in human perception and
aesthetic evaluation. Recent advances in Vision Transformers (ViTs) have
demonstrated remarkable capabilities in computer vision tasks, yet their
alignment with human visual attention patterns remains underexplored,
particularly in aesthetic contexts. This study investigates the correlation
between human visual attention and ViT attention mechanisms when evaluating
handcrafted objects. We conducted an eye-tracking experiment with 30
participants (9 female, 21 male, mean age 24.6 years) who viewed 20 artisanal
objects comprising basketry bags and ginger jars. Using a Pupil Labs
eye-tracker, we recorded gaze patterns and generated heat maps representing
human visual attention. Simultaneously, we analyzed the same objects using a
pre-trained ViT model with DINO (Self-DIstillation with NO Labels), extracting
attention maps from each of the 12 attention heads. We compared human and ViT
attention distributions using Kullback-Leibler divergence across varying
Gaussian parameters (sigma=0.1 to 3.0). Statistical analysis revealed optimal
correlation at sigma=2.4 +-0.03, with attention head #12 showing the strongest
alignment with human visual patterns. Significant differences were found
between attention heads, with heads #7 and #9 demonstrating the greatest
divergence from human attention (p< 0.05, Tukey HSD test). Results indicate
that while ViTs exhibit more global attention patterns compared to human focal
attention, certain attention heads can approximate human visual behavior,
particularly for specific object features like buckles in basketry items. These
findings suggest potential applications of ViT attention mechanisms in product
design and aesthetic evaluation, while highlighting fundamental differences in
attention strategies between human perception and current AI models.

</details>


### [69] [HLFormer: Enhancing Partially Relevant Video Retrieval with Hyperbolic Learning](https://arxiv.org/abs/2507.17402)
*Li Jun,Wang Jinpeng,Tan Chaolei,Lian Niu,Chen Long,Zhang Min,Wang Yaowei,Xia Shu-Tao,Chen Bin*

Main category: cs.CV

TL;DR: HLFormer是首个利用双曲空间学习的PRVR框架，通过混合空间编码和动态特征融合，显著提升了视频与文本查询的部分相关性匹配效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在欧几里得空间中存在几何失真，导致视频的层次结构表达不准确，影响了时间建模效果。

Method: HLFormer结合了Lorentz Attention Block和Euclidean Attention Block，在混合空间中编码视频嵌入，并通过Mean-Guided Adaptive Interaction Module动态融合特征。此外，引入了Partial Order Preservation Loss以强化层次结构。

Result: 实验表明，HLFormer在PRVR任务上优于现有最先进方法。

Conclusion: HLFormer通过双曲空间学习优化了部分相关视频检索（PRVR）中的层次建模能力，显著提升了性能。

Abstract: Partially Relevant Video Retrieval (PRVR) addresses the critical challenge of
matching untrimmed videos with text queries describing only partial content.
Existing methods suffer from geometric distortion in Euclidean space that
sometimes misrepresents the intrinsic hierarchical structure of videos and
overlooks certain hierarchical semantics, ultimately leading to suboptimal
temporal modeling. To address this issue, we propose the first hyperbolic
modeling framework for PRVR, namely HLFormer, which leverages hyperbolic space
learning to compensate for the suboptimal hierarchical modeling capabilities of
Euclidean space. Specifically, HLFormer integrates the Lorentz Attention Block
and Euclidean Attention Block to encode video embeddings in hybrid spaces,
using the Mean-Guided Adaptive Interaction Module to dynamically fuse features.
Additionally, we introduce a Partial Order Preservation Loss to enforce "text <
video" hierarchy through Lorentzian cone constraints. This approach further
enhances cross-modal matching by reinforcing partial relevance between video
content and text queries. Extensive experiments show that HLFormer outperforms
state-of-the-art methods. Code is released at
https://github.com/lijun2005/ICCV25-HLFormer.

</details>


### [70] [Yume: An Interactive World Generation Model](https://arxiv.org/abs/2507.17744)
*Xiaofeng Mao,Shaoheng Lin,Zhen Li,Chuanhao Li,Wenshuo Peng,Tong He,Jiangmiao Pang,Mingmin Chi,Yu Qiao,Kaipeng Zhang*

Main category: cs.CV

TL;DR: Yume通过创新框架从静态图像生成动态交互世界，支持键盘探索，计划持续更新。


<details>
  <summary>Details</summary>
Motivation: Yume旨在利用图像、文本或视频创建交互式、逼真且动态的世界，支持通过外围设备或神经信号进行探索和控制。

Method: 方法包括相机运动量化、视频生成架构（MVDT）、先进的采样器（AAM和TTS-SDE）以及模型加速（对抗蒸馏和缓存机制）。

Result: 在高质量数据集\sekai上训练的\method在多样场景和应用中取得了显著成果。

Conclusion: Yume项目通过其创新的框架和方法，成功实现了从静态图像生成动态、交互式视频世界的能力，并计划持续更新以实现其最初目标。

Abstract: Yume aims to use images, text, or videos to create an interactive, realistic,
and dynamic world, which allows exploration and control using peripheral
devices or neural signals. In this report, we present a preview version of
\method, which creates a dynamic world from an input image and allows
exploration of the world using keyboard actions. To achieve this high-fidelity
and interactive video world generation, we introduce a well-designed framework,
which consists of four main components, including camera motion quantization,
video generation architecture, advanced sampler, and model acceleration. First,
we quantize camera motions for stable training and user-friendly interaction
using keyboard inputs. Then, we introduce the Masked Video Diffusion
Transformer~(MVDT) with a memory module for infinite video generation in an
autoregressive manner. After that, training-free Anti-Artifact Mechanism (AAM)
and Time Travel Sampling based on Stochastic Differential Equations (TTS-SDE)
are introduced to the sampler for better visual quality and more precise
control. Moreover, we investigate model acceleration by synergistic
optimization of adversarial distillation and caching mechanisms. We use the
high-quality world exploration dataset \sekai to train \method, and it achieves
remarkable results in diverse scenes and applications. All data, codebase, and
model weights are available on https://github.com/stdstu12/YUME. Yume will
update monthly to achieve its original goal. Project page:
https://stdstu12.github.io/YUME-Project/.

</details>


### [71] [Physics-based Human Pose Estimation from a Single Moving RGB Camera](https://arxiv.org/abs/2507.17406)
*Ayce Idil Aytekin,Chuqiao Li,Diogo Luvizon,Rishabh Dabral,Martin Oswald,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 提出MoviCam数据集和PhysDynPose方法，解决动态相机和非平面环境中的人体姿态跟踪问题，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有单目和基于物理的人体姿态跟踪方法在场景地面不平坦或相机移动时易产生伪影，且缺乏真实世界数据的基准。

Method: 结合了最先进的运动学估计器和鲁棒的SLAM方法，通过场景感知的物理优化器对运动学姿态估计进行细化。

Result: PhysDynPose在动态相机和非平面环境中表现优于现有方法，能够稳健估计人体和相机姿态。

Conclusion: 论文提出的PhysDynPose方法在动态相机和非平面环境中能够稳健地估计人体和相机姿态，显著优于现有方法。MoviCam数据集的引入填补了非合成数据集的空白，为未来研究提供了重要基准。

Abstract: Most monocular and physics-based human pose tracking methods, while achieving
state-of-the-art results, suffer from artifacts when the scene does not have a
strictly flat ground plane or when the camera is moving. Moreover, these
methods are often evaluated on in-the-wild real world videos without
ground-truth data or on synthetic datasets, which fail to model the real world
light transport, camera motion, and pose-induced appearance and geometry
changes. To tackle these two problems, we introduce MoviCam, the first
non-synthetic dataset containing ground-truth camera trajectories of a
dynamically moving monocular RGB camera, scene geometry, and 3D human motion
with human-scene contact labels. Additionally, we propose PhysDynPose, a
physics-based method that incorporates scene geometry and physical constraints
for more accurate human motion tracking in case of camera motion and non-flat
scenes. More precisely, we use a state-of-the-art kinematics estimator to
obtain the human pose and a robust SLAM method to capture the dynamic camera
trajectory, enabling the recovery of the human pose in the world frame. We then
refine the kinematic pose estimate using our scene-aware physics optimizer.
From our new benchmark, we found that even state-of-the-art methods struggle
with this inherently challenging setting, i.e. a moving camera and non-planar
environments, while our method robustly estimates both human and camera poses
in world coordinates.

</details>


### [72] [Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention](https://arxiv.org/abs/2507.17745)
*Yiwen Chen,Zhihao Li,Yikai Wang,Hu Zhang,Qin Li,Chi Zhang,Guosheng Lin*

Main category: cs.CV

TL;DR: Ultra3D 通过 VecSet 和 Part Attention 机制高效加速稀疏体素建模，支持高分辨率 3D 生成，性能领先。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏体素表示框架由于两阶段扩散流程中注意力机制的二次复杂度，存在严重的计算效率低下问题。Ultra3D 旨在通过高效方法加速稀疏体素建模，同时不牺牲生成质量。

Method: Ultra3D 采用两阶段扩散流程，第一阶段使用紧凑的 VecSet 表示生成粗略对象布局以减少令牌数量，第二阶段通过几何感知的局部注意力机制（Part Attention）细化每个体素的潜在特征，限制注意力计算在语义一致的部分区域内。

Result: Ultra3D 实现了高达 6.7 倍的潜在生成加速，支持 1024 分辨率的高分辨率 3D 生成，并在视觉保真度和用户偏好方面达到最先进水平。

Conclusion: Ultra3D 通过引入 VecSet 表示和 Part Attention 机制，显著提升了稀疏体素建模的效率，同时保持了高质量生成，支持 1024 分辨率的高分辨率 3D 生成，并在视觉保真度和用户偏好方面达到最先进水平。

Abstract: Recent advances in sparse voxel representations have significantly improved
the quality of 3D content generation, enabling high-resolution modeling with
fine-grained geometry. However, existing frameworks suffer from severe
computational inefficiencies due to the quadratic complexity of attention
mechanisms in their two-stage diffusion pipelines. In this work, we propose
Ultra3D, an efficient 3D generation framework that significantly accelerates
sparse voxel modeling without compromising quality. Our method leverages the
compact VecSet representation to efficiently generate a coarse object layout in
the first stage, reducing token count and accelerating voxel coordinate
prediction. To refine per-voxel latent features in the second stage, we
introduce Part Attention, a geometry-aware localized attention mechanism that
restricts attention computation within semantically consistent part regions.
This design preserves structural continuity while avoiding unnecessary global
attention, achieving up to 6.7x speed-up in latent generation. To support this
mechanism, we construct a scalable part annotation pipeline that converts raw
meshes into part-labeled sparse voxels. Extensive experiments demonstrate that
Ultra3D supports high-resolution 3D generation at 1024 resolution and achieves
state-of-the-art performance in both visual fidelity and user preference.

</details>


### [73] [CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography](https://arxiv.org/abs/2507.17420)
*Sneha George Gnanakalavathy,Hairil Abdul Razak,Robert Meertens,Jonathan E. Fieldsend,Xujiong Ye,Mohammed M. Abdelsamea*

Main category: cs.CV

TL;DR: CAPRI-CT是一种新型因果感知深度学习框架，用于优化CT成像质量，通过VAEs集合建模因果关系，支持预测和反事实推理。


<details>
  <summary>Details</summary>
Motivation: 在CT成像中，如何在最小化辐射暴露的同时实现高质量图像是一个关键临床挑战。

Method: 该研究采用了一种新颖的因果感知深度学习框架CAPRI-CT，利用变分自编码器（VAEs）的集合来提取特征并生成因果表示，支持反事实推理。

Result: CAPRI-CT通过集成学习方法训练和验证，表现出强大的预测性能，支持SNR预测和反事实推理。

Conclusion: CAPRI-CT通过集成图像数据和采集元数据，成功建模了影响CT图像质量的因果关系，为优化CT成像协议提供了可操作的见解。

Abstract: In computed tomography (CT), achieving high image quality while minimizing
radiation exposure remains a key clinical challenge. This paper presents
CAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and
Predictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT
integrates image data with acquisition metadata (such as tube voltage, tube
current, and contrast agent types) to model the underlying causal relationships
that influence image quality. An ensemble of Variational Autoencoders (VAEs) is
employed to extract meaningful features and generate causal representations
from observational data, including CT images and associated imaging parameters.
These input features are fused to predict the Signal-to-Noise Ratio (SNR) and
support counterfactual inference, enabling what-if simulations, such as changes
in contrast agents (types and concentrations) or scan parameters. CAPRI-CT is
trained and validated using an ensemble learning approach, achieving strong
predictive performance. By facilitating both prediction and interpretability,
CAPRI-CT provides actionable insights that could help radiologists and
technicians design more efficient CT protocols without repeated physical scans.
The source code and dataset are publicly available at
https://github.com/SnehaGeorge22/capri-ct.

</details>


### [74] [Dynamic-DINO: Fine-Grained Mixture of Experts Tuning for Real-time Open-Vocabulary Object Detection](https://arxiv.org/abs/2507.17436)
*Yehao Lu,Minghe Weng,Zekang Xiao,Rui Jiang,Wei Su,Guangcong Zheng,Ping Lu,Xi Li*

Main category: cs.CV

TL;DR: Dynamic-DINO通过MoE-Tuning和粒度分解机制，显著提升了开放词汇目标检测器的性能，优于现有密集模型。


<details>
  <summary>Details</summary>
Motivation: 探索Mixture of Experts (MoE)在实时开放词汇目标检测器中的应用潜力，以解决现有模型在小规模数据集上的性能限制。

Method: 提出了Dynamic-DINO框架，包括MoE-Tuning策略、粒度分解机制、预训练权重分配策略和路由器初始化方法。

Result: 实验表明，Dynamic-DINO在仅使用1.56M开源数据预训练的情况下，性能优于基于私有Grounding20M数据集预训练的Grounding DINO 1.5 Edge。

Conclusion: Dynamic-DINO通过高效的MoE-Tuning策略和粒度分解机制，成功将Grounding DINO 1.5 Edge从密集模型扩展为动态推理框架，显著提升了性能。

Abstract: The Mixture of Experts (MoE) architecture has excelled in Large
Vision-Language Models (LVLMs), yet its potential in real-time open-vocabulary
object detectors, which also leverage large-scale vision-language datasets but
smaller models, remains unexplored. This work investigates this domain,
revealing intriguing insights. In the shallow layers, experts tend to cooperate
with diverse peers to expand the search space. While in the deeper layers,
fixed collaborative structures emerge, where each expert maintains 2-3 fixed
partners and distinct expert combinations are specialized in processing
specific patterns. Concretely, we propose Dynamic-DINO, which extends Grounding
DINO 1.5 Edge from a dense model to a dynamic inference framework via an
efficient MoE-Tuning strategy. Additionally, we design a granularity
decomposition mechanism to decompose the Feed-Forward Network (FFN) of base
model into multiple smaller expert networks, expanding the subnet search space.
To prevent performance degradation at the start of fine-tuning, we further
propose a pre-trained weight allocation strategy for the experts, coupled with
a specific router initialization. During inference, only the input-relevant
experts are activated to form a compact subnet. Experiments show that,
pretrained with merely 1.56M open-source data, Dynamic-DINO outperforms
Grounding DINO 1.5 Edge, pretrained on the private Grounding20M dataset.

</details>


### [75] [Dynamic Scoring with Enhanced Semantics for Training-Free Human-Object Interaction Detection](https://arxiv.org/abs/2507.17456)
*Francesco Tonini,Lorenzo Vaquero,Alessandro Conti,Cigdem Beyan,Elisa Ricci*

Main category: cs.CV

TL;DR: DYSCO是一种无训练的HOI检测框架，利用视觉语言模型和多模态注册表提升交互理解，尤其在罕见交互中效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有HOI方法依赖大量人工标注数据，成本高且难以扩展，而视觉语言模型的潜力未被充分利用。DYSCO旨在填补这一空白，提升交互表示的鲁棒性和泛化能力。

Method: 提出了一种无训练的HOI检测框架DYSCO，结合视觉语言模型的潜力，通过多模态注册表和创新交互签名增强语义对齐，并采用多头注意力机制自适应加权视觉和文本特征。

Result: DYSCO在无训练方法中表现最优，与基于训练的方法竞争，尤其在罕见交互场景中表现突出。

Conclusion: DYSCO框架通过动态评分和增强语义的方法，有效利用多模态注册表中的文本和视觉交互表示，显著提升了HOI检测的性能，尤其在罕见交互中表现优异。

Abstract: Human-Object Interaction (HOI) detection aims to identify humans and objects
within images and interpret their interactions. Existing HOI methods rely
heavily on large datasets with manual annotations to learn interactions from
visual cues. These annotations are labor-intensive to create, prone to
inconsistency, and limit scalability to new domains and rare interactions. We
argue that recent advances in Vision-Language Models (VLMs) offer untapped
potential, particularly in enhancing interaction representation. While prior
work has injected such potential and even proposed training-free methods, there
remain key gaps. Consequently, we propose a novel training-free HOI detection
framework for Dynamic Scoring with enhanced semantics (DYSCO) that effectively
utilizes textual and visual interaction representations within a multimodal
registry, enabling robust and nuanced interaction understanding. This registry
incorporates a small set of visual cues and uses innovative interaction
signatures to improve the semantic alignment of verbs, facilitating effective
generalization to rare interactions. Additionally, we propose a unique
multi-head attention mechanism that adaptively weights the contributions of the
visual and textual features. Experimental results demonstrate that our DYSCO
surpasses training-free state-of-the-art models and is competitive with
training-based approaches, particularly excelling in rare interactions. Code is
available at https://github.com/francescotonini/dysco.

</details>


### [76] [ERMV: Editing 4D Robotic Multi-view images to enhance embodied agents](https://arxiv.org/abs/2507.17462)
*Chang Nie,Guangming Wang,Zhe Lie,Hesheng Wang*

Main category: cs.CV

TL;DR: ERMV是一个用于编辑4D多视角序列数据的新框架，通过EMA-Attn、稀疏STT和反馈干预机制解决数据稀缺问题，提升VLA模型的性能。


<details>
  <summary>Details</summary>
Motivation: 4D多视角序列数据的高成本和稀缺性限制了机器人模仿学习的泛化与应用，现有方法缺乏针对此类数据的编辑手段。

Method: ERMV框架包括：1) Epipolar Motion-Aware Attention (EMA-Attn)机制确保运动模糊的时空一致性；2) 稀疏Spatio-Temporal (STT)模块降低计算成本；3) 反馈干预机制通过MLLM检查编辑不一致性。

Result: 实验表明，ERMV增强的数据显著提升了VLA模型在模拟和真实环境中的性能。

Conclusion: ERMV框架通过创新的EMA-Attn机制、稀疏STT模块和反馈干预机制，有效解决了4D多视角序列数据编辑的三大挑战，显著提升了VLA模型的鲁棒性和泛化能力。

Abstract: Robot imitation learning relies on 4D multi-view sequential images. However,
the high cost of data collection and the scarcity of high-quality data severely
constrain the generalization and application of embodied intelligence policies
like Vision-Language-Action (VLA) models. Data augmentation is a powerful
strategy to overcome data scarcity, but methods for editing 4D multi-view
sequential images for manipulation tasks are currently lacking. Thus, we
propose ERMV (Editing Robotic Multi-View 4D data), a novel data augmentation
framework that efficiently edits an entire multi-view sequence based on
single-frame editing and robot state conditions. This task presents three core
challenges: (1) maintaining geometric and appearance consistency across dynamic
views and long time horizons; (2) expanding the working window with low
computational costs; and (3) ensuring the semantic integrity of critical
objects like the robot arm. ERMV addresses these challenges through a series of
innovations. First, to ensure spatio-temporal consistency in motion blur, we
introduce a novel Epipolar Motion-Aware Attention (EMA-Attn) mechanism that
learns pixel shift caused by movement before applying geometric constraints.
Second, to maximize the editing working window, ERMV pioneers a Sparse
Spatio-Temporal (STT) module, which decouples the temporal and spatial views
and remodels a single-frame multi-view problem through sparse sampling of the
views to reduce computational demands. Third, to alleviate error accumulation,
we incorporate a feedback intervention Mechanism, which uses a Multimodal Large
Language Model (MLLM) to check editing inconsistencies and request targeted
expert guidance only when necessary. Extensive experiments demonstrate that
ERMV-augmented data significantly boosts the robustness and generalization of
VLA models in both simulated and real-world environments.

</details>


### [77] [SRMambaV2: Biomimetic Attention for Sparse Point Cloud Upsampling in Autonomous Driving](https://arxiv.org/abs/2507.17479)
*Chuang Chen,Xiaolin Qin,Jing Hu,Wenyi Ge*

Main category: cs.CV

TL;DR: SRMambaV2 通过生物启发机制和双分支网络，显著提升了自动驾驶稀疏点云上采样的精度和几何重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法将 3D 空间场景转换为 2D 图像超分辨率任务，但由于距离图像的特征稀疏和模糊，难以准确重建复杂的空间拓扑结构。

Method: 提出了一种名为 SRMambaV2 的新型稀疏点云上采样方法，结合了生物启发的 2D 选择性扫描自注意力机制（2DSSA）和双分支网络架构，并引入了渐进自适应损失函数（PAL）以优化细节重建。

Result: 实验结果表明，SRMambaV2 在定性和定量评估中均优于现有方法，验证了其在稀疏点云上采样任务中的有效性和实用价值。

Conclusion: SRMambaV2 在自动驾驶稀疏点云上采样任务中表现出色，通过生物启发机制和双分支网络架构，显著提升了长距离稀疏区域的精度和整体几何重建质量。

Abstract: Upsampling LiDAR point clouds in autonomous driving scenarios remains a
significant challenge due to the inherent sparsity and complex 3D structures of
the data. Recent studies have attempted to address this problem by converting
the complex 3D spatial scenes into 2D image super-resolution tasks. However,
due to the sparse and blurry feature representation of range images, accurately
reconstructing detailed and complex spatial topologies remains a major
difficulty. To tackle this, we propose a novel sparse point cloud upsampling
method named SRMambaV2, which enhances the upsampling accuracy in long-range
sparse regions while preserving the overall geometric reconstruction quality.
Specifically, inspired by human driver visual perception, we design a
biomimetic 2D selective scanning self-attention (2DSSA) mechanism to model the
feature distribution in distant sparse areas. Meanwhile, we introduce a
dual-branch network architecture to enhance the representation of sparse
features. In addition, we introduce a progressive adaptive loss (PAL) function
to further refine the reconstruction of fine-grained details during the
upsampling process. Experimental results demonstrate that SRMambaV2 achieves
superior performance in both qualitative and quantitative evaluations,
highlighting its effectiveness and practical value in automotive sparse point
cloud upsampling tasks.

</details>


### [78] [DFDNet: Dynamic Frequency-Guided De-Flare Network](https://arxiv.org/abs/2507.17489)
*Minglong Xue,Aoxiang Ning,Shivakumara Palaiahnakote,Mingliang Zhou*

Main category: cs.CV

TL;DR: DFDNet通过频率域解耦光晕与内容信息，结合动态频率引导和对比学习，有效去除大规模光晕伪影并修复局部细节。


<details>
  <summary>Details</summary>
Motivation: 夜间摄影中的强光源常导致图像中出现光晕，严重影响视觉质量和下游任务性能。现有方法难以去除大规模光晕伪影及修复光源附近区域的结构损伤。

Method: DFDNet主要由全局动态频率域引导模块（GDFG）和局部细节引导模块（LDGM）组成。GDFG通过动态优化全局频率域特征，引导网络感知光晕伪影的频率特性；LDGM通过对比学习策略对齐光源局部特征与参考图像，减少局部细节损伤。

Result: 实验结果表明，DFDNet在性能上优于现有最先进方法。

Conclusion: 本文提出的动态频率引导去光晕网络（DFDNet）通过频率域解耦内容信息与光晕伪影，有效去除大规模光晕伪影，并在实验中获得优于现有方法的性能。

Abstract: Strong light sources in nighttime photography frequently produce flares in
images, significantly degrading visual quality and impacting the performance of
downstream tasks. While some progress has been made, existing methods continue
to struggle with removing large-scale flare artifacts and repairing structural
damage in regions near the light source. We observe that these challenging
flare artifacts exhibit more significant discrepancies from the reference
images in the frequency domain compared to the spatial domain. Therefore, this
paper presents a novel dynamic frequency-guided deflare network (DFDNet) that
decouples content information from flare artifacts in the frequency domain,
effectively removing large-scale flare artifacts. Specifically, DFDNet consists
mainly of a global dynamic frequency-domain guidance (GDFG) module and a local
detail guidance module (LDGM). The GDFG module guides the network to perceive
the frequency characteristics of flare artifacts by dynamically optimizing
global frequency domain features, effectively separating flare information from
content information. Additionally, we design an LDGM via a contrastive learning
strategy that aligns the local features of the light source with the reference
image, reduces local detail damage from flare removal, and improves
fine-grained image restoration. The experimental results demonstrate that the
proposed method outperforms existing state-of-the-art methods in terms of
performance. The code is available at
\href{https://github.com/AXNing/DFDNet}{https://github.com/AXNing/DFDNet}.

</details>


### [79] [Illicit object detection in X-ray imaging using deep learning techniques: A comparative evaluation](https://arxiv.org/abs/2507.17508)
*Jorgen Cani,Christos Diou,Spyridon Evangelatos,Vasileios Argyriou,Panagiotis Radoglou-Grammatikis,Panagiotis Sarigiannidis,Iraklis Varlamis,Georgios Th. Papadopoulos*

Main category: cs.CV

TL;DR: 该论文通过系统评估六大数据集和十种深度学习模型，全面比较了X射线违禁品检测方法的性能，强调了关键观察并为未来研究提供了公开代码和模型权重。


<details>
  <summary>Details</summary>
Motivation: 自动化X射线检查在公共场合的高效和非侵入性安全筛查中至关重要，但物体遮挡、物品物理性质变化、X射线扫描设备多样性以及有限训练数据等问题阻碍了准确可靠的违禁品检测。

Method: 开发了一个全面的评估框架，包括六个大型公开数据集、十种最先进的物体检测方案以及多种检测和时间/计算复杂性指标。

Result: 研究提供了对不同物体检测方案的综合评估结果，包括整体行为、物体级性能、数据集特定观察和时间效率及计算复杂性分析。

Conclusion: 该研究通过系统、详细和全面的比较评估，揭示了基于深度学习的X射线物体检测方法的研究现状，并提供了关键观察和见解，强调了物体检测方案的整体行为、物体级检测性能、数据集特定观察以及时间效率和计算复杂性分析。

Abstract: Automated X-ray inspection is crucial for efficient and unobtrusive security
screening in various public settings. However, challenges such as object
occlusion, variations in the physical properties of items, diversity in X-ray
scanning devices, and limited training data hinder accurate and reliable
detection of illicit items. Despite the large body of research in the field,
reported experimental evaluations are often incomplete, with frequently
conflicting outcomes. To shed light on the research landscape and facilitate
further research, a systematic, detailed, and thorough comparative evaluation
of recent Deep Learning (DL)-based methods for X-ray object detection is
conducted. For this, a comprehensive evaluation framework is developed,
composed of: a) Six recent, large-scale, and widely used public datasets for
X-ray illicit item detection (OPIXray, CLCXray, SIXray, EDS, HiXray, and
PIDray), b) Ten different state-of-the-art object detection schemes covering
all main categories in the literature, including generic Convolutional Neural
Network (CNN), custom CNN, generic transformer, and hybrid CNN-transformer
architectures, and c) Various detection (mAP50 and mAP50:95) and
time/computational-complexity (inference time (ms), parameter size (M), and
computational load (GFLOPS)) metrics. A thorough analysis of the results leads
to critical observations and insights, emphasizing key aspects such as: a)
Overall behavior of the object detection schemes, b) Object-level detection
performance, c) Dataset-specific observations, and d) Time efficiency and
computational complexity analysis. To support reproducibility of the reported
experimental results, the evaluation code and model weights are made publicly
available at https://github.com/jgenc/xray-comparative-evaluation.

</details>


### [80] [Accelerating Parallel Diffusion Model Serving with Residual Compression](https://arxiv.org/abs/2507.17511)
*Jiajun Luo,Yicheng Xiao,Jianru Xu,Yangxiu You,Rongwei Lu,Chen Tang,Jingyan Jiang,Zhi Wang*

Main category: cs.CV

TL;DR: CompactFusion 是一种压缩框架，通过残差压缩减少扩散模型并行推断中的通信开销，显著提升效率并保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型需要大量计算资源，并行推断引入的通信开销限制了效率和可扩展性。CompactFusion 旨在减少通信开销同时保持生成质量。

Method: CompactFusion 采用残差压缩技术，仅传输压缩后的残差（步间激活差异），并通过轻量级错误反馈防止误差累积。

Result: 在 4xL20 上实现了 3.0 倍的加速，同时在慢速网络上支持序列并行，实现了 6.7 倍的加速。

Conclusion: CompactFusion 通过残差压缩和轻量级错误反馈机制，显著减少了并行扩散推断中的通信开销，同时保持了生成质量，实现了低延迟和高生成质量。

Abstract: Diffusion models produce realistic images and videos but require substantial
computational resources, necessitating multi-accelerator parallelism for
real-time deployment. However, parallel inference introduces significant
communication overhead from exchanging large activations between devices,
limiting efficiency and scalability. We present CompactFusion, a compression
framework that significantly reduces communication while preserving generation
quality. Our key observation is that diffusion activations exhibit strong
temporal redundancy-adjacent steps produce highly similar activations,
saturating bandwidth with near-duplicate data carrying little new information.
To address this inefficiency, we seek a more compact representation that
encodes only the essential information. CompactFusion achieves this via
Residual Compression that transmits only compressed residuals (step-wise
activation differences). Based on empirical analysis and theoretical
justification, we show that it effectively removes redundant data, enabling
substantial data reduction while maintaining high fidelity. We also integrate
lightweight error feedback to prevent error accumulation. CompactFusion
establishes a new paradigm for parallel diffusion inference, delivering lower
latency and significantly higher generation quality than prior methods. On
4xL20, it achieves 3.0x speedup while greatly improving fidelity. It also
uniquely supports communication-heavy strategies like sequence parallelism on
slow networks, achieving 6.7x speedup over prior overlap-based method.
CompactFusion applies broadly across diffusion models and parallel settings,
and integrates easily without requiring pipeline rework. Portable
implementation demonstrated on xDiT is publicly available at
https://github.com/Cobalt-27/CompactFusion

</details>


### [81] [URPO: A Unified Reward & Policy Optimization Framework for Large Language Models](https://arxiv.org/abs/2507.17515)
*Songshuo Lu,Hua Wang,Zhi Chen,Yaohua Tang*

Main category: cs.CV

TL;DR: URPO框架统一奖励与策略模型，简化对齐流程并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统对齐流程中资源密集、性能受限的问题，通过统一模型和训练阶段提升效率和效果。

Method: 提出了统一奖励与策略优化（URPO）框架，使用单一模型和训练阶段，通过Group-Relative Policy Optimization（GRPO）循环优化。

Result: 在Qwen2.5-7B模型上，URPO显著优于基线，指令跟随和推理分数均有提升，内部评估器表现更优。

Conclusion: URPO通过将奖励模型与策略模型统一，简化了大规模对齐流程，提升了性能，并培养了更优的内部评估器。

Abstract: Large-scale alignment pipelines typically pair a policy model with a
separately trained reward model whose parameters remain frozen during
reinforcement learning (RL). This separation creates a complex,
resource-intensive pipeline and suffers from a performance ceiling due to a
static reward signal. We propose a novel framework, Unified Reward & Policy
Optimization (URPO), that unifies instruction-following ("player") and reward
modeling ("referee") within a single model and a single training phase. Our
method recasts all alignment data-including preference pairs, verifiable
reasoning, and open-ended instructions-into a unified generative format
optimized by a single Group-Relative Policy Optimization (GRPO) loop. This
enables the model to learn from ground-truth preferences and verifiable logic
while simultaneously generating its own rewards for open-ended tasks.
Experiments on the Qwen2.5-7B model demonstrate URPO's superiority. Our unified
model significantly outperforms a strong baseline using a separate generative
reward model, boosting the instruction-following score on AlpacaEval from 42.24
to 44.84 and the composite reasoning average from 32.66 to 35.66. Furthermore,
URPO cultivates a superior internal evaluator as a byproduct of training,
achieving a RewardBench score of 85.15 and surpassing the dedicated reward
model it replaces (83.55). By eliminating the need for a separate reward model
and fostering a co-evolutionary dynamic between generation and evaluation, URPO
presents a simpler, more efficient, and more effective path towards robustly
aligned language models.

</details>


### [82] [STQE: Spatial-Temporal Quality Enhancement for G-PCC Compressed Dynamic Point Clouds](https://arxiv.org/abs/2507.17522)
*Tian Guo,Hui Yuan,Xiaolong Mao,Shiqi Jiang,Raouf Hamzaoui,Sam Kwong*

Main category: cs.CV

TL;DR: STQE网络通过时空属性质量增强方法，显著提升了压缩动态点云的视觉质量和编码效率。


<details>
  <summary>Details</summary>
Motivation: 目前很少有研究关注压缩动态点云的质量增强，尤其是如何有效利用点云帧间的时空相关性。

Method: 提出了一个基于重新着色的运动补偿模块、通道感知的时间注意力模块、高斯引导的邻域特征聚合模块以及基于皮尔逊相关系数的联合损失函数。

Result: STQE在最新的G-PCC测试模型中，Luma、Cb和Cr组件的delta PSNR分别提高了0.855 dB、0.682 dB和0.828 dB，BD-rate分别降低了-25.2%、-31.6%和-32.5%。

Conclusion: STQE网络通过利用空间和时间相关性，显著提升了G-PCC压缩动态点云的视觉质量，并在PSNR和BD-rate方面取得了显著改进。

Abstract: Very few studies have addressed quality enhancement for compressed dynamic
point clouds. In particular, the effective exploitation of spatial-temporal
correlations between point cloud frames remains largely unexplored. Addressing
this gap, we propose a spatial-temporal attribute quality enhancement (STQE)
network that exploits both spatial and temporal correlations to improve the
visual quality of G-PCC compressed dynamic point clouds. Our contributions
include a recoloring-based motion compensation module that remaps reference
attribute information to the current frame geometry to achieve precise
inter-frame geometric alignment, a channel-aware temporal attention module that
dynamically highlights relevant regions across bidirectional reference frames,
a Gaussian-guided neighborhood feature aggregation module that efficiently
captures spatial dependencies between geometry and color attributes, and a
joint loss function based on the Pearson correlation coefficient, designed to
alleviate over-smoothing effects typical of point-wise mean squared error
optimization. When applied to the latest G-PCC test model, STQE achieved
improvements of 0.855 dB, 0.682 dB, and 0.828 dB in delta PSNR, with
Bj{\o}ntegaard Delta rate (BD-rate) reductions of -25.2%, -31.6%, and -32.5%
for the Luma, Cb, and Cr components, respectively.

</details>


### [83] [Multi-modal Multi-task Pre-training for Improved Point Cloud Understanding](https://arxiv.org/abs/2507.17533)
*Liwen Liu,Weidong Yang,Lipeng Ma,Ben Fei*

Main category: cs.CV

TL;DR: MMPT是一种多模态多任务预训练框架，通过三个自监督任务提升点云理解能力，无需3D标注，在多种下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有多模态预训练框架仅依赖单一任务，限制了模型获取其他相关任务信息的能力，影响了复杂领域的性能。

Method: 提出了MMPT框架，包含三个预训练任务：Token级重建（TLR）、点级重建（PLR）和多模态对比学习（MCL），通过自监督方式结合3D点云和2D图像模态。

Result: 在多种判别性和生成性应用中，MMPT框架的性能优于现有最先进方法。

Conclusion: MMPT框架通过多任务预训练显著提升了点云理解能力，且在多种下游任务中表现出色，无需3D标注，具有高度可扩展性。

Abstract: Recent advances in multi-modal pre-training methods have shown promising
effectiveness in learning 3D representations by aligning multi-modal features
between 3D shapes and their corresponding 2D counterparts. However, existing
multi-modal pre-training frameworks primarily rely on a single pre-training
task to gather multi-modal data in 3D applications. This limitation prevents
the models from obtaining the abundant information provided by other relevant
tasks, which can hinder their performance in downstream tasks, particularly in
complex and diverse domains. In order to tackle this issue, we propose MMPT, a
Multi-modal Multi-task Pre-training framework designed to enhance point cloud
understanding. Specifically, three pre-training tasks are devised: (i)
Token-level reconstruction (TLR) aims to recover masked point tokens, endowing
the model with representative learning abilities. (ii) Point-level
reconstruction (PLR) is integrated to predict the masked point positions
directly, and the reconstructed point cloud can be considered as a transformed
point cloud used in the subsequent task. (iii) Multi-modal contrastive learning
(MCL) combines feature correspondences within and across modalities, thus
assembling a rich learning signal from both 3D point cloud and 2D image
modalities in a self-supervised manner. Moreover, this framework operates
without requiring any 3D annotations, making it scalable for use with large
datasets. The trained encoder can be effectively transferred to various
downstream tasks. To demonstrate its effectiveness, we evaluated its
performance compared to state-of-the-art methods in various discriminant and
generative applications under widely-used benchmarks.

</details>


### [84] [An h-space Based Adversarial Attack for Protection Against Few-shot Personalization](https://arxiv.org/abs/2507.17554)
*Xide Xu,Sandesh Kamath,Muhammad Atif Butt,Bogdan Raducanu*

Main category: cs.CV

TL;DR: 提出HAAD和HAAD-KV方法，通过h-space对抗攻击有效保护扩散模型免受定制化攻击，HAAD-KV更高效。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在少样本定制化图像生成中的隐私问题，尤其是未经授权的私人内容修改，促使开发基于对抗攻击的保护机制。

Method: 提出HAAD方法，利用h-space的对抗攻击来干扰图像生成过程，并进一步推出HAAD-KV，仅基于h-space的KV参数构建扰动。

Result: HAAD和HAAD-KV方法在对抗扩散模型定制化方面效果显著，HAAD-KV在保护强度更高且计算成本更低。

Conclusion: HAAD和HAAD-KV方法在对抗扩散模型的定制化攻击中表现出色，优于现有技术，且HAAD-KV在计算成本上更为高效。

Abstract: The versatility of diffusion models in generating customized images from few
samples raises significant privacy concerns, particularly regarding
unauthorized modifications of private content. This concerning issue has
renewed the efforts in developing protection mechanisms based on adversarial
attacks, which generate effective perturbations to poison diffusion models. Our
work is motivated by the observation that these models exhibit a high degree of
abstraction within their semantic latent space (`h-space'), which encodes
critical high-level features for generating coherent and meaningful content. In
this paper, we propose a novel anti-customization approach, called HAAD
(h-space based Adversarial Attack for Diffusion models), that leverages
adversarial attacks to craft perturbations based on the h-space that can
efficiently degrade the image generation process. Building upon HAAD, we
further introduce a more efficient variant, HAAD-KV, that constructs
perturbations solely based on the KV parameters of the h-space. This strategy
offers a stronger protection, that is computationally less expensive. Despite
their simplicity, our methods outperform state-of-the-art adversarial attacks,
highlighting their effectiveness.

</details>


### [85] [Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors](https://arxiv.org/abs/2507.17577)
*Chen Ma,Xinjie Xu,Shuyu Cheng,Qi Xuan*

Main category: cs.CV

TL;DR: 本文提出了一种先验引导的硬标签攻击方法，通过改进梯度估计和利用转移先验，显著提高了查询效率，理论和实验均验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 硬标签攻击是一种实用且具有挑战性的黑盒对抗攻击类型，现有方法在梯度估计中使用“符号技巧”以减少查询次数，但其梯度估计质量有待理论分析和改进。

Method: 本文通过利用来自替代模型的转移先验，并提出一种梯度估计器，以查询高效的方式近似真实梯度在这些先验和随机方向子空间上的投影。

Result: 在ImageNet和CIFAR-10数据集上的大量实验表明，该方法在查询效率方面显著优于11种最先进的方法。

Conclusion: 本文提出了一种新颖的先验引导方法来提高射线搜索效率，理论和实验均证明了其有效性，显著优于现有的11种最先进方法。

Abstract: One of the most practical and challenging types of black-box adversarial
attacks is the hard-label attack, where only the top-1 predicted label is
available. One effective approach is to search for the optimal ray direction
from the benign image that minimizes the $\ell_p$-norm distance to the
adversarial region. The unique advantage of this approach is that it transforms
the hard-label attack into a continuous optimization problem. The objective
function value is the ray's radius, which can be obtained via binary search at
a high query cost. Existing methods use a "sign trick" in gradient estimation
to reduce the number of queries. In this paper, we theoretically analyze the
quality of this gradient estimation and propose a novel prior-guided approach
to improve ray search efficiency both theoretically and empirically.
Specifically, we utilize the transfer-based priors from surrogate models, and
our gradient estimators appropriately integrate them by approximating the
projection of the true gradient onto the subspace spanned by these priors and
random directions, in a query-efficient manner. We theoretically derive the
expected cosine similarities between the obtained gradient estimators and the
true gradient, and demonstrate the improvement achieved by incorporating
priors. Extensive experiments on the ImageNet and CIFAR-10 datasets show that
our approach significantly outperforms 11 state-of-the-art methods in terms of
query efficiency.

</details>


### [86] [Dual-branch Prompting for Multimodal Machine Translation](https://arxiv.org/abs/2507.17588)
*Jie Wang,Zhendong Yang,Liansong Zong,Xiaobo Zhang,Dexian Wang,Ji Zhang*

Main category: cs.CV

TL;DR: D2P-MMT通过扩散模型生成图像和双分支提示策略，提升了多模态机器翻译的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有MMT方法依赖成对图文输入且对无关视觉噪声敏感，限制了其鲁棒性和实用性。

Method: 提出D2P-MMT框架，利用预训练扩散模型生成图像以过滤视觉噪声，采用双分支提示策略联合学习真实和生成图像，并通过分布对齐损失减少模态差异。

Result: 在Multi30K数据集上的实验显示，D2P-MMT在翻译性能上优于当前最先进方法。

Conclusion: D2P-MMT通过扩散模型生成的图像和双分支提示策略，显著提升了多模态机器翻译的鲁棒性和性能，实验证明其在Multi30K数据集上优于现有方法。

Abstract: Multimodal Machine Translation (MMT) typically enhances text-only translation
by incorporating aligned visual features. Despite the remarkable progress,
state-of-the-art MMT approaches often rely on paired image-text inputs at
inference and are sensitive to irrelevant visual noise, which limits their
robustness and practical applicability. To address these issues, we propose
D2P-MMT, a diffusion-based dual-branch prompting framework for robust
vision-guided translation. Specifically, D2P-MMT requires only the source text
and a reconstructed image generated by a pre-trained diffusion model, which
naturally filters out distracting visual details while preserving semantic
cues. During training, the model jointly learns from both authentic and
reconstructed images using a dual-branch prompting strategy, encouraging rich
cross-modal interactions. To bridge the modality gap and mitigate
training-inference discrepancies, we introduce a distributional alignment loss
that enforces consistency between the output distributions of the two branches.
Extensive experiments on the Multi30K dataset demonstrate that D2P-MMT achieves
superior translation performance compared to existing state-of-the-art
approaches.

</details>


### [87] [RemixFusion: Residual-based Mixed Representation for Large-scale Online RGB-D Reconstruction](https://arxiv.org/abs/2507.17594)
*Yuqing Lan,Chenyang Zhu,Shuaifeng Zhi,Jiazhao Zhang,Zhoufeng Wang,Renjiao Yi,Yijie Wang,Kai Xu*

Main category: cs.CV

TL;DR: RemixFusion通过残差混合表示和自适应梯度放大技术，显著提升大规模在线RGB-D重建质量和效率。


<details>
  <summary>Details</summary>
Motivation: 解决神经隐式表示在细节重建和时间效率上的不足，提升大规模在线重建的实用性。

Method: 提出残差混合表示，结合显式TSDF网格和隐式神经模块，以及多帧联合位姿优化的自适应梯度放大技术。

Result: 在大型场景重建和相机跟踪精度上超越现有方法。

Conclusion: RemixFusion通过残差混合表示显著提升了大规模在线RGB-D重建的质量和效率，超越了现有方法。

Abstract: The introduction of the neural implicit representation has notably propelled
the advancement of online dense reconstruction techniques. Compared to
traditional explicit representations, such as TSDF, it improves the mapping
completeness and memory efficiency. However, the lack of reconstruction details
and the time-consuming learning of neural representations hinder the widespread
application of neural-based methods to large-scale online reconstruction. We
introduce RemixFusion, a novel residual-based mixed representation for scene
reconstruction and camera pose estimation dedicated to high-quality and
large-scale online RGB-D reconstruction. In particular, we propose a
residual-based map representation comprised of an explicit coarse TSDF grid and
an implicit neural module that produces residuals representing fine-grained
details to be added to the coarse grid. Such mixed representation allows for
detail-rich reconstruction with bounded time and memory budget, contrasting
with the overly-smoothed results by the purely implicit representations, thus
paving the way for high-quality camera tracking. Furthermore, we extend the
residual-based representation to handle multi-frame joint pose optimization via
bundle adjustment (BA). In contrast to the existing methods, which optimize
poses directly, we opt to optimize pose changes. Combined with a novel
technique for adaptive gradient amplification, our method attains better
optimization convergence and global optimality. Furthermore, we adopt a local
moving volume to factorize the mixed scene representation with a
divide-and-conquer design to facilitate efficient online learning in our
residual-based framework. Extensive experiments demonstrate that our method
surpasses all state-of-the-art ones, including those based either on explicit
or implicit representations, in terms of the accuracy of both mapping and
tracking on large-scale scenes.

</details>


### [88] [InvRGB+L: Inverse Rendering of Complex Scenes with Unified Color and LiDAR Reflectance Modeling](https://arxiv.org/abs/2507.17613)
*Xiaoxue Chen,Bhargav Chandaka,Chih-Hao Lin,Ya-Qin Zhang,David Forsyth,Hao Zhao,Shenlong Wang*

Main category: cs.CV

TL;DR: InvRGB+L是一种结合RGB和LiDAR数据的逆向渲染模型，通过LiDAR强度值提升材质估计，适用于动态场景和复杂光照，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统逆向图形方法主要依赖RGB观测，LiDAR仅用于几何信息，导致材质估计不准确。LiDAR的强度值在不同光谱范围内捕获，为材质估计提供了互补线索。

Method: 提出了一种基于物理的LiDAR着色模型和RGB-LiDAR材质一致性损失函数，利用LiDAR强度值作为补充信息进行材质估计。

Result: InvRGB+L能够生成城市和室内场景的新视角RGB和LiDAR渲染，支持重光照、夜间模拟和动态对象插入，性能超越现有方法。

Conclusion: InvRGB+L模型通过结合RGB和LiDAR数据，提出了一种新颖的逆向渲染方法，显著提升了场景重建和材质估计的准确性，适用于动态场景和复杂光照条件下的应用。

Abstract: We present InvRGB+L, a novel inverse rendering model that reconstructs large,
relightable, and dynamic scenes from a single RGB+LiDAR sequence. Conventional
inverse graphics methods rely primarily on RGB observations and use LiDAR
mainly for geometric information, often resulting in suboptimal material
estimates due to visible light interference. We find that LiDAR's intensity
values-captured with active illumination in a different spectral range-offer
complementary cues for robust material estimation under variable lighting.
Inspired by this, InvRGB+L leverages LiDAR intensity cues to overcome
challenges inherent in RGB-centric inverse graphics through two key
innovations: (1) a novel physics-based LiDAR shading model and (2) RGB-LiDAR
material consistency losses. The model produces novel-view RGB and LiDAR
renderings of urban and indoor scenes and supports relighting, night
simulations, and dynamic object insertions, achieving results that surpass
current state-of-the-art methods in both scene-level urban inverse rendering
and LiDAR simulation.

</details>


### [89] [Reusing Attention for One-stage Lane Topology Understanding](https://arxiv.org/abs/2507.17617)
*Yang Li,Zongzheng Zhang,Xuchong Qiu,Xinrun Li,Ziming Liu,Leichen Wang,Ruikai Li,Zhenxin Zhu,Huan-ang Gao,Xiaojian Lin,Zhiyong Cui,Hang Zhao,Hao Zhao*

Main category: cs.CV

TL;DR: 提出一种单阶段架构，通过重用Transformer解码器中的注意力资源，同时预测交通元素、车道和拓扑关系，显著提升了车道拓扑理解的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段方法因错误传播和计算开销大而效率低下，需改进车道拓扑理解的准确性和推理速度。

Method: 提出了一种单阶段架构，通过重用不同Transformer解码器中的中间注意力资源，同时预测交通元素、车道中心线和拓扑关系，避免了额外的计算开销。

Result: 在OpenLane-V2数据集上的实验表明，该方法在准确性和效率上均优于基线方法。

Conclusion: 该方法在OpenLane-V2数据集上表现出色，在车道检测、交通元素识别和拓扑关系推理方面均优于基线方法，同时提高了推理速度。

Abstract: Understanding lane toplogy relationships accurately is critical for safe
autonomous driving. However, existing two-stage methods suffer from
inefficiencies due to error propagations and increased computational overheads.
To address these challenges, we propose a one-stage architecture that
simultaneously predicts traffic elements, lane centerlines and topology
relationship, improving both the accuracy and inference speed of lane topology
understanding for autonomous driving. Our key innovation lies in reusing
intermediate attention resources within distinct transformer decoders. This
approach effectively leverages the inherent relational knowledge within the
element detection module to enable the modeling of topology relationships among
traffic elements and lanes without requiring additional computationally
expensive graph networks. Furthermore, we are the first to demonstrate that
knowledge can be distilled from models that utilize standard definition (SD)
maps to those operates without using SD maps, enabling superior performance
even in the absence of SD maps. Extensive experiments on the OpenLane-V2
dataset show that our approach outperforms baseline methods in both accuracy
and efficiency, achieving superior results in lane detection, traffic element
identification, and topology reasoning. Our code is available at
https://github.com/Yang-Li-2000/one-stage.git.

</details>


### [90] [The Early Bird Identifies the Worm: You Can't Beat a Head Start in Long-Term Body Re-ID (ECHO-BID)](https://arxiv.org/abs/2507.17640)
*Thomas M. Metz,Matthew Q. Hill,Alice J. O'Toole*

Main category: cs.CV

TL;DR: ECHO-BID是一种基于EVA-02 Large骨干的长期重识别模型，在衣物变化和遮挡场景中表现优异，显著优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决在非约束视角环境下因距离、视角、成像条件和衣物变化导致的人物识别挑战。

Method: 介绍了基于EVA-02 Large骨干的ECHO-BID模型，并与9种不同骨干架构、模型大小、目标分类预训练规模和迁移学习协议的模型进行了比较。

Result: ECHO-BID在最具挑战性的衣物变化数据上实现了最先进的长期重识别性能，并在遮挡场景中大幅领先其他方法。

Conclusion: 选择合适的预训练骨干架构和迁移学习协议可以显著提升长期重识别性能。

Abstract: Person identification in unconstrained viewing environments presents
significant challenges due to variations in distance, viewpoint, imaging
conditions, and clothing. We introduce $\textbf{E}$va $\textbf{C}$lothes-Change
from $\textbf{H}$idden $\textbf{O}$bjects - $\textbf{B}$ody
$\textbf{ID}$entification (ECHO-BID), a class of long-term re-id models built
on object-pretrained EVA-02 Large backbones. We compare ECHO-BID to 9 other
models that vary systematically in backbone architecture, model size, scale of
object classification pretraining, and transfer learning protocol. Models were
evaluated on benchmark datasets across constrained, unconstrained, and occluded
settings. ECHO-BID, with transfer learning on the most challenging
clothes-change data, achieved state-of-the-art results on long-term re-id --
substantially outperforming other methods. ECHO-BID also surpassed other
methods by a wide margin in occluded viewing scenarios. A combination of
increased model size and Masked Image Modeling during pretraining underlie
ECHO-BID's strong performance on long-term re-id. Notably, a smaller, but more
challenging transfer learning dataset, generalized better across datasets than
a larger, less challenging one. However, the larger dataset with an additional
fine-tuning step proved best on the most difficult data. Selecting the correct
pretrained backbone architecture and transfer learning protocols can drive
substantial gains in long-term re-id performance.

</details>


### [91] [CNS-Bench: Benchmarking Image Classifier Robustness Under Continuous Nuisance Shifts](https://arxiv.org/abs/2507.17651)
*Olaf Dünkel,Artur Jesslen,Jiahao Xie,Christian Theobalt,Christian Rupprecht,Adam Kortylewski*

Main category: cs.CV

TL;DR: 本研究提出CNS-Bench，一个用于评估图像分类器在连续且现实干扰变化下OOD鲁棒性的基准，发现模型排名会因干扰变化和尺度而变化，且连续评估能更细致地识别失效点。


<details>
  <summary>Details</summary>
Motivation: 评估计算机视觉模型在潜在分布外（OOD）场景中的性能是一个重要挑战。虽然简单的合成干扰常用于测试OOD鲁棒性，但它们往往无法捕捉现实世界中的干扰变化。扩散模型虽能生成真实图像用于基准测试，但仅限于二元干扰变化。

Method: 本研究提出了CNS-Bench，一个通过LoRA适配器在扩散模型上生成连续且现实的生成性干扰变化的基准。为了解决失败案例，还提出了一种优于先前方法的过滤机制。

Result: 通过CNS-Bench，研究者评估了40多个分类器在各种干扰变化下的鲁棒性。研究发现，模型排名会因干扰变化和尺度而变化，且连续尺度评估能识别模型失效点。

Conclusion: 通过CNS-Bench的引入，本研究展示了连续且现实的生成性干扰变化对图像分类器OOD鲁棒性评估的重要性。研究发现，模型排名会因不同干扰变化和尺度而变化，这是传统二元变化无法捕捉的。此外，连续尺度的评估能更细致地识别模型失效点，为模型鲁棒性提供了更深入的理解。

Abstract: An important challenge when using computer vision models in the real world is
to evaluate their performance in potential out-of-distribution (OOD) scenarios.
While simple synthetic corruptions are commonly applied to test OOD robustness,
they often fail to capture nuisance shifts that occur in the real world.
Recently, diffusion models have been applied to generate realistic images for
benchmarking, but they are restricted to binary nuisance shifts. In this work,
we introduce CNS-Bench, a Continuous Nuisance Shift Benchmark to quantify OOD
robustness of image classifiers for continuous and realistic generative
nuisance shifts. CNS-Bench allows generating a wide range of individual
nuisance shifts in continuous severities by applying LoRA adapters to diffusion
models. To address failure cases, we propose a filtering mechanism that
outperforms previous methods, thereby enabling reliable benchmarking with
generative models. With the proposed benchmark, we perform a large-scale study
to evaluate the robustness of more than 40 classifiers under various nuisance
shifts. Through carefully designed comparisons and analyses, we find that model
rankings can change for varying shifts and shift scales, which cannot be
captured when applying common binary shifts. Additionally, we show that
evaluating the model performance on a continuous scale allows the
identification of model failure points, providing a more nuanced understanding
of model robustness. Project page including code and data:
https://genintel.github.io/CNS.

</details>


### [92] [Attention (as Discrete-Time Markov) Chains](https://arxiv.org/abs/2507.17657)
*Yotam Erel,Olaf Dünkel,Rishabh Dabral,Vladislav Golyanik,Christian Theobalt,Amit H. Bermano*

Main category: cs.CV

TL;DR: 该论文提出了一种基于马尔可夫链的注意力矩阵解释框架，统一了注意力操作并引入间接注意力，通过TokenRank提升图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过马尔可夫链框架统一注意力操作（如选择、求和、平均），并扩展至间接注意力建模，超越以往仅关注直接效应的研究。

Method: 通过将注意力矩阵解释为离散时间马尔可夫链，利用矩阵乘法和特征分析计算元稳定状态及其普遍性，提出了TokenRank作为全局令牌重要性的度量工具。

Result: 展示了在零样本分割任务中的最先进性能，并通过TokenRank在无条件图像生成中实现了改进。

Conclusion: 该论文提出了一种新的注意力矩阵解释框架，通过马尔可夫链的视角统一了注意力操作，并引入了间接注意力的概念。TokenRank作为马尔可夫链的稳态向量，展示了在无条件图像生成中的改进潜力，为现代视觉Transformer中的注意力机制提供了新视角。

Abstract: We introduce a new interpretation of the attention matrix as a discrete-time
Markov chain. Our interpretation sheds light on common operations involving
attention scores such as selection, summation, and averaging in a unified
framework. It further extends them by considering indirect attention,
propagated through the Markov chain, as opposed to previous studies that only
model immediate effects. Our main observation is that tokens corresponding to
semantically similar regions form a set of metastable states, where the
attention clusters, while noisy attention scores tend to disperse. Metastable
states and their prevalence can be easily computed through simple matrix
multiplication and eigenanalysis, respectively. Using these lightweight tools,
we demonstrate state-of-the-art zero-shot segmentation. Lastly, we define
TokenRank -- the steady state vector of the Markov chain, which measures global
token importance. We demonstrate that using it brings improvements in
unconditional image generation. We believe our framework offers a fresh view of
how tokens are being attended in modern visual transformers.

</details>


### [93] [See the Forest and the Trees: A Synergistic Reasoning Framework for Knowledge-Based Visual Question Answering](https://arxiv.org/abs/2507.17659)
*Junjie Wang,Yunhan Tang,Yijie Wang,Zhihao Yuan,Huan Wang,Yangfan He,Bin Li*

Main category: cs.CV

TL;DR: Synergos-VQA通过融合整体、结构和因果三种证据流，显著提升了KBVQA任务的性能，成为新的SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLM在KBVQA任务中依赖于单一维度的证据（‘只见树木，不见森林’），限制了其多角度理解和鲁棒性。受‘既见森林，又见树木’原则的启发，作者提出Synergos-VQA以解决这一问题。

Method: Synergos-VQA提出了一种新颖的协同推理框架，在推理时同时生成并融合三种互补的证据流：1) 整体证据（感知整个场景）；2) 结构证据（通过原型驱动模块识别关键对象）；3) 因果证据（通过反事实探测确保推理的鲁棒性）。

Result: Synergos-VQA在OK-VQA和A-OKVQA等三个具有挑战性的基准测试中确立了新的最先进水平，并展示了强大的即插即用能力。

Conclusion: Synergos-VQA通过协同融合多维度证据流（整体、结构和因果证据），显著提升了KBVQA任务的性能，并在多个基准测试中达到新的最先进水平。该方法还展示了强大的即插即用能力，能够显著提升开源MLLM的性能。

Abstract: Multimodal Large Language Models (MLLMs) have pushed the frontiers of
Knowledge-Based Visual Question Answering (KBVQA), yet their reasoning is
fundamentally bottlenecked by a reliance on uni-dimensional evidence. This
"seeing only the trees, but not the forest" approach prevents robust,
multi-faceted understanding. Inspired by the principle of seeing both the
forest and trees, we propose Synergos-VQA, a novel synergistic reasoning
framework. At its core, Synergos-VQA concurrently generates and fuses three
complementary evidence streams at inference time: (1) Holistic Evidence to
perceive the entire scene (the "forest"), (2) Structural Evidence from a
prototype-driven module to identify key objects (the "trees"), and (3) Causal
Evidence from a counterfactual probe to ensure the reasoning is robustly
grounded. By synergistically fusing this multi-faceted evidence, our framework
achieves a more comprehensive and reliable reasoning process. Extensive
experiments show that Synergos-VQA decisively establishes a new
state-of-the-art on three challenging benchmarks, including OK-VQA and A-OKVQA.
Furthermore, our approach demonstrates strong plug-and-play capabilities,
significantly boosting various open-source MLLMs and proving that superior
methodological design can outperform sheer model scale.

</details>


### [94] [BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems](https://arxiv.org/abs/2507.17722)
*Malsha Ashani Mahawatta Dona,Beatriz Cabrero-Daniel,Yinan Yu,Christian Berger*

Main category: cs.CV

TL;DR: 研究评估VLMs在交通场景中的表现，发现其虽能理解复杂图像但存在幻觉，提出BetterCheck检测策略以提升安全性。


<details>
  <summary>Details</summary>
Motivation: LLMs和VLMs在自动驾驶感知系统中具有潜力，但其幻觉问题可能导致严重错误，需系统性评估和改进。

Method: 系统评估了3种最先进的VLMs在Waymo Open Dataset的多样化交通场景子集上的表现，并提出了幻觉检测策略BetterCheck。

Result: VLMs展现出卓越的图像理解能力，但仍存在幻觉问题，需检测策略来确保可靠性。

Conclusion: 大型语言模型（LLMs）和视觉语言模型（VLMs）在复杂交通场景理解方面表现出色，但仍存在幻觉问题，需要如BetterCheck等检测策略来提升安全性。

Abstract: Large language models (LLMs) are growingly extended to process multimodal
data such as text and video simultaneously. Their remarkable performance in
understanding what is shown in images is surpassing specialized neural networks
(NNs) such as Yolo that is supporting only a well-formed but very limited
vocabulary, ie., objects that they are able to detect. When being
non-restricted, LLMs and in particular state-of-the-art vision language models
(VLMs) show impressive performance to describe even complex traffic situations.
This is making them potentially suitable components for automotive perception
systems to support the understanding of complex traffic situations or edge case
situation. However, LLMs and VLMs are prone to hallucination, which mean to
either potentially not seeing traffic agents such as vulnerable road users who
are present in a situation, or to seeing traffic agents who are not there in
reality. While the latter is unwanted making an ADAS or autonomous driving
systems (ADS) to unnecessarily slow down, the former could lead to disastrous
decisions from an ADS. In our work, we are systematically assessing the
performance of 3 state-of-the-art VLMs on a diverse subset of traffic
situations sampled from the Waymo Open Dataset to support safety guardrails for
capturing such hallucinations in VLM-supported perception systems. We observe
that both, proprietary and open VLMs exhibit remarkable image understanding
capabilities even paying thorough attention to fine details sometimes difficult
to spot for us humans. However, they are also still prone to making up elements
in their descriptions to date requiring hallucination detection strategies such
as BetterCheck that we propose in our work.

</details>


### [95] [A Comprehensive Evaluation Framework for the Study of the Effects of Facial Filters on Face Recognition Accuracy](https://arxiv.org/abs/2507.17729)
*Kagan Ozturk,Louisa Conwill,Jacob Gutierrez,Kevin Bowyer,Walter J. Scheirer*

Main category: cs.CV

TL;DR: 研究提出了一个评估面部滤镜对自动识别影响的框架，揭示了跨文化差异，并展示了如何通过检测和恢复滤镜影响来提高识别性能。


<details>
  <summary>Details</summary>
Motivation: 面部滤镜在全球社交媒体用户中广泛使用，但之前的研究仅关注少数特定风格的滤镜，无法全面反映各种社交应用中滤镜的多样性。

Method: 研究提出了一个框架，包括一个控制的面部图像数据集、一个原则性的滤镜选择过程以及一系列实验来评估滤镜对识别的影响。

Result: 通过案例研究揭示了Instagram、Snapchat、Meitu和Pitu等应用中滤镜的跨文化差异，并展示了如何检测和恢复滤镜对面部识别的影响。

Conclusion: 研究表明，通过检测和恢复面部滤镜在面部嵌入空间中的影响，可以显著提高自动面部识别的性能。

Abstract: Facial filters are now commonplace for social media users around the world.
Previous work has demonstrated that facial filters can negatively impact
automated face recognition performance. However, these studies focus on small
numbers of hand-picked filters in particular styles. In order to more
effectively incorporate the wide ranges of filters present on various social
media applications, we introduce a framework that allows for larger-scale study
of the impact of facial filters on automated recognition. This framework
includes a controlled dataset of face images, a principled filter selection
process that selects a representative range of filters for experimentation, and
a set of experiments to evaluate the filters' impact on recognition. We
demonstrate our framework with a case study of filters from the American
applications Instagram and Snapchat and the Chinese applications Meitu and Pitu
to uncover cross-cultural differences. Finally, we show how the filtering
effect in a face embedding space can easily be detected and restored to improve
face recognition performance.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [96] [Optimal Pure Differentially Private Sparse Histograms in Near-Linear Deterministic Time](https://arxiv.org/abs/2507.17017)
*Florian Kerschbaum,Steven Lee,Hao Wu*

Main category: cs.DS

TL;DR: 提出了一种高效纯差分隐私稀疏直方图算法，突破二次时间屏障，运行时间为O(n ln ln d)。


<details>
  <summary>Details</summary>
Motivation: 在高维数据（d ≫ n）下，现有方法在确定时间内达到最优ℓ∞估计误差的效率不足，尤其是存在二次时间屏障的问题。

Method: 采用了一种新颖的私有项覆盖技术（private item blanket technique）和目标长度填充（target-length padding），将近似差分隐私的基于稳定性的直方图算法转化为纯差分隐私算法。

Result: 算法在word-RAM模型中严格运行时间为O(n ln ln d)，优于先前已知的确定性时间界限Õ(n²)，并实现了最优ℓ∞估计误差。

Conclusion: 该论文提出了一种纯差分隐私稀疏直方图发布算法，解决了Balcer和Vadhan（2019）提出的打破二次时间屏障的开放性问题。

Abstract: We introduce an algorithm that releases a pure differentially private sparse
histogram over $n$ participants drawn from a domain of size $d \gg n$. Our
method attains the optimal $\ell_\infty$-estimation error and runs in strictly
$O(n \ln \ln d)$ time in the word-RAM model, thereby improving upon the
previous best known deterministic-time bound of $\tilde{O}(n^2)$ and resolving
the open problem of breaking this quadratic barrier (Balcer and Vadhan, 2019).
Central to our algorithm is a novel private item blanket technique with
target-length padding, which transforms the approximate differentially private
stability-based histogram algorithm into a pure differentially private one.

</details>


### [97] [Compatibility of Max and Sum Objectives for Committee Selection and $k$-Facility Location](https://arxiv.org/abs/2507.17063)
*Yue Han,Elliot Anshelevich*

Main category: cs.DS

TL;DR: 研究发现，在设施选址或委员会选择问题中，可以形成同时满足多个目标的解决方案，而无需牺牲一个目标。


<details>
  <summary>Details</summary>
Motivation: 探讨不同目标之间的兼容性，以及是否存在可以同时接近最优的解决方案。

Method: 研究在任意度量空间中选择k个设施为客户端C服务的四种不同目标，包括客户端最小化其到选定设施的距离之和或最大值，以及整体目标考虑个体客户端成本之和或最大值。

Result: 证明了存在可以同时接近任何一对上述目标最优的解决方案。

Conclusion: 研究表明，在选择设施或代表委员会时，可以形成一个同时满足多个目标的解决方案，而无需牺牲一个目标来实现另一个目标。

Abstract: We study a version of the metric facility location problem (or, equivalently,
variants of the committee selection problem) in which we must choose $k$
facilities in an arbitrary metric space to serve some set of clients $C$. We
consider four different objectives, where each client $i\in C$ attempts to
minimize either the sum or the maximum of its distance to the chosen
facilities, and where the overall objective either considers the sum or the
maximum of the individual client costs. Rather than optimizing a single
objective at a time, we study how compatible these objectives are with each
other, and show the existence of solutions which are simultaneously
close-to-optimum for any pair of the above objectives. Our results show that
when choosing a set of facilities or a representative committee, it is often
possible to form a solution which is good for several objectives at the same
time, instead of sacrificing one desideratum to achieve another.

</details>


### [98] [Advancing Quantum State Preparation using LimTDD](https://arxiv.org/abs/2507.17170)
*Xin Hong,Aochu Dai,Chenjian Li,Sanjiang Li,Shenggang Ying,Mingsheng Ying*

Main category: cs.DS

TL;DR: 提出基于LimTDDs的高效量子态制备算法，显著优于现有方法并展示指数级改进。


<details>
  <summary>Details</summary>
Motivation: 量子态制备是量子计算和量子信息处理中的基本任务，对许多量子算法的执行至关重要。

Method: 基于新型决策图（LimTDDs）的方法，结合张量网络和决策图，降低了量子电路的复杂度。

Result: 实验表明，该方法在运行时和门复杂度方面均显著优于现有方法，并展示了更好的可扩展性。

Conclusion: 本文提出了一系列针对不同辅助量子比特数量的高效量子态制备算法，显著优于现有方法，并在最佳情况下展示了指数级改进。

Abstract: Quantum state preparation (QSP) is a fundamental task in quantum computing
and quantum information processing. It is critical to the execution of many
quantum algorithms, including those in quantum machine learning. In this paper,
we propose a family of efficient QSP algorithms tailored to different numbers
of available ancilla qubits - ranging from no ancilla qubits, to a single
ancilla qubit, to a sufficiently large number of ancilla qubits. Our algorithms
are based on a novel decision diagram that is fundamentally different from the
approaches used in previous QSP algorithms. Specifically, our approach exploits
the power of Local Invertible Map Tensor Decision Diagrams (LimTDDs) - a highly
compact representation of quantum states that combines tensor networks and
decision diagrams to reduce quantum circuit complexity. Extensive experiments
demonstrate that our methods significantly outperform existing approaches and
exhibit better scalability for large-scale quantum states, both in terms of
runtime and gate complexity. Furthermore, our method shows exponential
improvement in best-case scenarios. This paper is an extended version of [1],
with three more algorithms proposed.

</details>


### [99] [RLZ-r and LZ-End-r: Enhancing Move-r](https://arxiv.org/abs/2507.17300)
*Patrick Dinklage,Johannes Fischer,Lukas Nalbach,Jan Zumbrink*

Main category: cs.DS

TL;DR: 研究通过增强r-index和Move-r的压缩后缀数组，显著提升了定位查询性能，尤其是在模式频繁出现时，并提供了两种压缩方案的空间与性能权衡。


<details>
  <summary>Details</summary>
Motivation: 尽管r-index和Move-r在压缩空间和查询时间上已取得进展，但实践中仍存在因评估函数Φ而导致的性能瓶颈。这促使研究者探索通过压缩后缀数组来提升定位查询效率。

Method: 本研究基于Relative Lempel-Ziv和LZ-End两种压缩方案，对r-index和Move-r进行了增强，并评估了定位查询的性能。

Result: 实验显示，采用压缩后缀数组技术后，r-index和Move-r的定位查询性能得到显著提升，特别是在模式出现次数较多的情况下。

Conclusion: 通过实验证明，采用压缩后缀数组技术可以显著提升r-index和Move-r在定位查询中的性能，尤其是在模式出现次数较多的情况下。两种压缩方案（Relative Lempel-Ziv和LZ-End）为索引大小与查询性能之间的权衡提供了新的选择。

Abstract: In pattern matching on strings, a locate query asks for an enumeration of all
the occurrences of a given pattern in a given text. The r-index [Gagie et al.,
2018] is a recently presented compressed self index that stores the text and
auxiliary information in compressed space. With some modifications, locate
queries can be answered in optimal time [Nishimoto & Tabei, 2021], which has
recently been proven relevant in practice in the form of Move-r [Bertram et
al., 2024]. However, there remains the practical bottleneck of evaluating
function $\Phi$ for every occurrence to report. This motivates enhancing the
index by a compressed representation of the suffix array featuring efficient
random access, trading off space for faster answering of locate queries
[Puglisi & Zhukova, 2021]. In this work, we build upon this idea considering
two suitable compression schemes: Relative Lempel-Ziv [Kuruppu et al., 2010],
improving the work by Puglisi and Zhukova, and LZ-End [Kreft & Navarro, 2010],
introducing a different trade-off where compression is better than for Relative
Lempel-Ziv at the cost of slower access times. We enhance both the r-index and
Move-r by the compressed suffix arrays and evaluate locate query performance in
an experiment. We show that locate queries can be sped up considerably in both
the r-index and Move-r, especially if the queried pattern has many occurrences.
The choice between two different compression schemes offers new trade-offs
regarding index size versus query performance.

</details>


### [100] [Residual Prophet Inequalities](https://arxiv.org/abs/2507.17391)
*Jose Correa,Sebastian Perez-Salazar,Dana Pizarro,Bruno Ziliotto*

Main category: cs.DS

TL;DR: 本文提出了残差先知不等式（RPI）及其两种变体（FI/NI模型），并设计了数据驱动的随机算法，分别在两种模型中达到了最优或接近最优的竞争比。针对k=1的同分布实例，分析了单阈值算法的性能界限。


<details>
  <summary>Details</summary>
Motivation: 研究经典先知不等式的变体，即残差先知不等式（RPI），以解决在移除前k个最大值后，剩余序列的最优停止问题。

Method: 在FI模型中，提出了一种数据驱动的随机算法，仅需访问输入分布中k+1个最大值的单一样本。在NI模型中，设计了类似的算法。对于k=1的同分布实例，构建了单阈值算法并分析了其性能界限。

Result: 在FI模型中，算法的竞争比至少为1/(k+2)，且证明该界限是紧的；在NI模型中，算法的竞争比为1/(2k+2)。对于k=1的同分布实例，单阈值算法的竞争比至少为0.4901，上限为0.5464。

Conclusion: 本文提出了残差先知不等式（RPI）的两种变体，并在FI模型和NI模型中分别提出了具有最优竞争比的随机算法。此外，针对k=1的同分布实例，分析了单阈值算法的性能界限。

Abstract: We introduce a variant of the classic prophet inequality, called
\emph{residual prophet inequality} (RPI). In the RPI problem, we consider a
finite sequence of $n$ nonnegative independent random values with known
distributions, and a known integer $0\leq k\leq n-1$. Before the gambler
observes the sequence, the top $k$ values are removed, whereas the remaining
$n-k$ values are streamed sequentially to the gambler. For example, one can
assume that the top $k$ values have already been allocated to a higher-priority
agent. Upon observing a value, the gambler must decide irrevocably whether to
accept or reject it, without the possibility of revisiting past values.
  We study two variants of RPI, according to whether the gambler learns online
of the identity of the variable that he sees (FI model) or not (NI model). Our
main result is a randomized algorithm in the FI model with \emph{competitive
ratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is
data-driven and requires access only to the $k+1$ largest values of a single
sample from the $n$ input distributions. In the NI model, we provide a similar
algorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze
independent and identically distributed instances when $k=1$. We build a
single-threshold algorithm with a competitive ratio of at least 0.4901, and
show that no single-threshold strategy can get a competitive ratio greater than
0.5464.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [101] [Summarizing Normative Driving Behavior From Large-Scale NDS Datasets for Vehicle System Development](https://arxiv.org/abs/2507.16839)
*Gregory Beale,Gibran Ali*

Main category: cs.RO

TL;DR: 本文提出了一种处理大规模自然驾驶研究数据的方法，用于描述五种驾驶指标的驾驶行为，并通过交互式工具进行可视化分析，支持车辆安全和智能交通系统的发展。


<details>
  <summary>Details</summary>
Motivation: 描述规范性驾驶行为，以帮助开发车辆安全和智能交通系统。

Method: 利用来自第二次战略公路研究计划（SHRP 2）NDS的数据，包括超过3400名驾驶员的3400万英里驾驶数据，通过车辆、GPS和前向雷达数据生成每个驾驶指标的摘要。此外，开发了交互式在线分析工具，通过动态数据选择和分组来可视化和比较不同群体的驾驶行为。

Result: 例如，在SHRP 2 NDS中，16-19岁的女性在65英里/小时的道路上略微比同龄男性更频繁地超过限速7.5至15英里/小时，年轻驾驶员比年长驾驶员更频繁地保持1.5秒以下的跟车距离。

Conclusion: 本研究通过量化规范性驾驶行为，为更好的车辆系统和更安全的交通基础设施提供了支持，并提供了一种分析自然驾驶研究数据集以进行跨群体比较的方法。

Abstract: This paper presents a methodology to process large-scale naturalistic driving
studies (NDS) to describe the driving behavior for five vehicle metrics,
including speed, speeding, lane keeping, following distance, and headway,
contextualized by roadway characteristics, vehicle classes, and driver
demographics. Such descriptions of normative driving behaviors can aid in the
development of vehicle safety and intelligent transportation systems. The
methodology is demonstrated using data from the Second Strategic Highway
Research Program (SHRP 2) NDS, which includes over 34 million miles of driving
across more than 3,400 drivers. Summaries of each driving metric were generated
using vehicle, GPS, and forward radar data. Additionally, interactive online
analytics tools were developed to visualize and compare driving behavior across
groups through dynamic data selection and grouping. For example, among drivers
on 65-mph roads for the SHRP 2 NDS, females aged 16-19 exceeded the speed limit
by 7.5 to 15 mph slightly more often than their male counterparts, and younger
drivers maintained headways under 1.5 seconds more frequently than older
drivers. This work supports better vehicle systems and safer infrastructure by
quantifying normative driving behaviors and offers a methodology for analyzing
NDS datasets for cross group comparisons.

</details>


### [102] [AquaChat: An LLM-Guided ROV Framework for Adaptive Inspection of Aquaculture Net Pens](https://arxiv.org/abs/2507.16841)
*Waseem Akram,Muhayy Ud Din,Abdelhaleem Saad,Irfan Hussain*

Main category: cs.RO

TL;DR: AquaChat是一个结合大型语言模型的ROV框架，用于智能自适应水产养殖网箱检查，通过多层架构实现自然语言交互和精确控制，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统检查方法依赖于预编程任务或手动控制，难以适应动态水下环境和用户特定需求。

Method: 提出了AquaChat框架，采用多层架构：高层规划层使用LLM解释自然语言命令生成符号任务计划；中层任务管理器将计划转换为ROV控制序列；低层运动控制层执行导航和检查任务。

Result: 在模拟和控制的水产养殖网箱环境中验证了框架的有效性，结果显示任务灵活性、检查准确性和操作效率均有所提升。

Conclusion: AquaChat展示了将基于语言的人工智能与海洋机器人技术结合的潜力，为可持续水产养殖操作提供了智能、用户交互式的检查系统。

Abstract: Inspection of aquaculture net pens is essential for maintaining the
structural integrity, biosecurity, and operational efficiency of fish farming
systems. Traditional inspection approaches rely on pre-programmed missions or
manual control, offering limited adaptability to dynamic underwater conditions
and user-specific demands. In this study, we propose AquaChat, a novel Remotely
Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs)
for intelligent and adaptive net pen inspection. The system features a
multi-layered architecture: (1) a high-level planning layer that interprets
natural language user commands using an LLM to generate symbolic task plans;
(2) a mid-level task manager that translates plans into ROV control sequences;
and (3) a low-level motion control layer that executes navigation and
inspection tasks with precision. Real-time feedback and event-triggered
replanning enhance robustness in challenging aquaculture environments. The
framework is validated through experiments in both simulated and controlled
aquatic environments representative of aquaculture net pens. Results
demonstrate improved task flexibility, inspection accuracy, and operational
efficiency. AquaChat illustrates the potential of integrating language-based AI
with marine robotics to enable intelligent, user-interactive inspection systems
for sustainable aquaculture operations.

</details>


### [103] [Sensor-Space Based Robust Kinematic Control of Redundant Soft Manipulator by Learning](https://arxiv.org/abs/2507.16842)
*Yinan Meng,Kun Qian,Jiong Yang,Renbo Su,Zhenhong Li,Charlie C. L. Wang*

Main category: cs.RO

TL;DR: 提出SS-ILKC框架，结合强化学习和模仿学习，解决软体机械臂在受限环境和未知负载下的运动学控制问题，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 软体机械臂的高自由度和固有柔顺性使其在安全交互和灵活任务执行方面具有优势，但其运动学控制面临未知外部载荷导致的变形和受限环境中不当零空间调节引起的执行器饱和问题。

Method: 采用双学习策略：基于强化学习原理的多目标传感器空间控制框架用于开放空间，生成对抗模仿学习方法用于受限空间。此外，提出了预处理仿真到现实转移机制以减少仿真与现实之间的差距。

Result: 实验结果表明，该方法能够有效控制软体机械臂，在受限环境和未知负载条件下实现精确操作。

Conclusion: 论文提出的SS-ILKC框架能够有效控制气动驱动的软体机械臂，在未知负载条件下实现精确路径跟踪和受限环境中的物体操作。

Abstract: The intrinsic compliance and high degree of freedom (DoF) of redundant soft
manipulators facilitate safe interaction and flexible task execution. However,
effective kinematic control remains highly challenging, as it must handle
deformations caused by unknown external loads and avoid actuator saturation due
to improper null-space regulation - particularly in confined environments. In
this paper, we propose a Sensor-Space Imitation Learning Kinematic Control
(SS-ILKC) framework to enable robust kinematic control under actuator
saturation and restrictive environmental constraints. We employ a dual-learning
strategy: a multi-goal sensor-space control framework based on reinforcement
learning principle is trained in simulation to develop robust control policies
for open spaces, while a generative adversarial imitation learning approach
enables effective policy learning from sparse expert demonstrations for
confined spaces. To enable zero-shot real-world deployment, a pre-processed
sim-to-real transfer mechanism is proposed to mitigate the
simulation-to-reality gap and accurately characterize actuator saturation
limits. Experimental results demonstrate that our method can effectively
control a pneumatically actuated soft manipulator, achieving precise
path-following and object manipulation in confined environments under unknown
loading conditions.

</details>


### [104] [Analytical Formulation of Autonomous Vehicle Freeway Merging Control with State-Dependent Discharge Rates](https://arxiv.org/abs/2507.16846)
*Qing Tang,Xianbiao Hu*

Main category: cs.RO

TL;DR: 该论文提出了一种基于动态规划的自主车辆多阶段动态合并控制方法，优化了交通延迟和碰撞风险，实验证明其优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 传统自由流合并控制模型忽视了拥堵期间交汇交通对流量率的影响，导致模型与实际观测不符。本研究旨在通过分析多阶段动态合并过程，提出更准确的模型以提高交通效率和安全性。

Method: 研究采用封闭形式公式分析推导了多阶段动态合并过程中的有效排放率，并基于此推导了队列长度和交通延迟等性能指标。同时，建立了碰撞风险函数以定量评估合并过程中的潜在碰撞。最终，问题被表述为一个动态规划模型，以合并位置和速度为决策变量。

Result: 数值实验表明，所提出的模型在效率和安全性上优于两种基准算法，验证了有效排放率的准确性。

Conclusion: 该研究通过动态规划模型联合优化延迟和碰撞风险，提出了一种更高效、更安全的自由流合并控制方法，并通过NGSIM数据集验证了其有效性。

Abstract: The core of the freeway merging control problem lies in dynamic queue
propagation and dissipation linked to merging vehicle behavior. Traditionally,
queuing is modeled through demand-supply interactions with time varying demand
and fixed capacity. However, field observations show flow rates decrease during
congestion at freeway merges due to the impact of intersecting traffic, a
factor overlooked in fundamental diagrams. This manuscript introduces an
analytical approach to characterize and control the dynamic multi-stage merging
of autonomous vehicles, prioritizing traffic efficiency and safety. For the
first time, the effective discharge rate at the merging point, reduced by the
multi-stage dynamic merging process, is analytically derived using a closed
form formulation. Leveraging this expression, performance metrics such as queue
length and traffic delay are derived as the first objective. Additionally, a
crash risk function is established to quantitatively assess potential
collisions during the merging process, serving as the second objective.
Finally, the problem is formulated as a dynamic programming model to jointly
minimize delay and crash risk, with the merging location and speed as decision
variables. Given the terminal state, the ramp vehicle merging task is
formulated as a recursive optimization problem, employing backward induction to
find the minimum cost solution. Numerical experiments using the NGSIM dataset
validate the derived effective discharge rate. The results indicate that the
proposed model outperforms two benchmark algorithms, leading to a more
efficient and safer merging process.

</details>


### [105] [MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation](https://arxiv.org/abs/2507.16853)
*Ning Li,Xiangmou Qu,Jiamu Zhou,Jun Wang,Muning Wen,Kounianhua Du,Xingyu Lou,Qiuying Peng,Jun Wang,Weinan Zhang*

Main category: cs.RO

TL;DR: MobileUse 是一个针对移动任务执行的 GUI 代理，通过分层反射架构和主动探索模块解决了长期任务和冷启动问题，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在移动设备上自动化复杂任务方面展现出潜力，但其在真实移动场景中的应用仍面临长期任务执行、错误恢复和冷启动等挑战。

Method: MobileUse 采用分层反射架构实现自我监控、错误检测和恢复，并通过主动探索模块解决冷启动问题。

Result: 在 AndroidWorld 和 AndroidLab 基准测试中，MobileUse 分别取得了 62.9% 和 44.2% 的成功率，并发布了开箱即用的工具包。

Conclusion: MobileUse 通过引入分层反射架构和主动探索模块，显著提升了在移动设备上执行复杂任务的鲁棒性和适应性，并在 AndroidWorld 和 AndroidLab 基准测试中取得了新的最佳性能。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the
development of mobile agents that can understand visual inputs and follow user
instructions, unlocking new possibilities for automating complex tasks on
mobile devices. However, applying these models to real-world mobile scenarios
remains a significant challenge due to the long-horizon task execution,
difficulty in error recovery, and the cold-start problem in unfamiliar
environments. To address these challenges, we propose MobileUse, a GUI agent
designed for robust and adaptive mobile task execution. To improve resilience
in long-horizon tasks and dynamic environments, we introduce a hierarchical
reflection architecture that enables the agent to self-monitor, detect, and
recover from errors across multiple temporal scales-ranging from individual
actions to overall task completion-while maintaining efficiency through a
reflection-on-demand strategy. To tackle cold-start issues, we further
introduce a proactive exploration module, which enriches the agent's
understanding of the environment through self-planned exploration. Evaluations
on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse
establishes new state-of-the-art performance, achieving success rates of 62.9%
and 44.2%, respectively. To facilitate real-world applications, we release an
out-of-the-box toolkit for automated task execution on physical mobile devices,
which is available at https://github.com/MadeAgents/mobile-use.

</details>


### [106] [Leveraging multi-source and heterogeneous signals for fatigue detection](https://arxiv.org/abs/2507.16859)
*Luobin Cui,Yanlai Wu,Tang Ying,Weikai Li*

Main category: cs.RO

TL;DR: 该论文提出了一种异构多源疲劳检测框架，解决了现有方法依赖高端传感器和受控环境的问题，实验证明其在实际场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有疲劳检测方法多依赖高端传感器和受控环境，限制了其在实际场景中的应用。本研究旨在解决这一局限性。

Method: 提出了一种异构多源疲劳检测框架，自适应利用目标域可用模态，同时受益于源域的多样化配置。

Result: 实验表明，该方法在实际部署的传感器设置和公开数据集上表现出实用性、鲁棒性和更好的泛化能力。

Conclusion: 该研究提出了一种异构多源疲劳检测框架，有效结合了目标域可用模态和源域多样配置，为传感器受限场景下的疲劳监测提供了实用解决方案。

Abstract: Fatigue detection plays a critical role in safety-critical applications such
as aviation, mining, and long-haul transport. However, most existing methods
rely on high-end sensors and controlled environments, limiting their
applicability in real world settings. This paper formally defines a practical
yet underexplored problem setting for real world fatigue detection, where
systems operating with context-appropriate sensors aim to leverage knowledge
from differently instrumented sources including those using impractical sensors
deployed in controlled environments. To tackle this challenge, we propose a
heterogeneous and multi-source fatigue detection framework that adaptively
utilizes the available modalities in the target domain while benefiting from
the diverse configurations present in source domains. Our experiments,
conducted using a realistic field-deployed sensor setup and two publicly
available datasets, demonstrate the practicality, robustness, and improved
generalization of our approach, paving the practical way for effective fatigue
monitoring in sensor-constrained scenarios.

</details>


### [107] [ResKACNNet: A Residual ChebyKAN Network for Inertial Odometry](https://arxiv.org/abs/2507.16865)
*Shanshan Zhang,Tianshui Wen,Siyue Wang,Qi Zhang,Ziheng Zhou,Huiru Zheng,Lingxiang Zheng,Yu Yang*

Main category: cs.RO

TL;DR: 提出ResChebyKAN网络和EKSA模块，显著提升惯性定位精度，并证明移除重力分量可优化性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于CNN的惯性定位方法难以捕捉IMU数据中的非线性运动特征和长期依赖关系，因此需要一种更高效的解决方案。

Method: 提出了一种名为ResChebyKAN的新型惯性定位网络，利用切比雪夫多项式的非线性逼近能力建模复杂运动模式，并引入EKSA模块以增强长期依赖建模。

Result: 在多个公开数据集上验证，该方法相比现有基准方法绝对轨迹误差降低了3.79%至42.32%。

Conclusion: 移除加速度数据中的重力分量显著提升了惯性定位性能，且提出的ResChebyKAN网络和EKSA模块在多个公开数据集上表现优异，绝对轨迹误差降低了3.79%至42.32%。

Abstract: Inertial Measurement Unit (IMU) has become a key technology for achieving
low-cost and precise positioning. However, traditional CNN-based inertial
positioning methods struggle to capture the nonlinear motion characteristics
and long-term dependencies in IMU data. To address this limitation, we propose
a novel inertial positioning network with a generic backbone called
ResChebyKAN, which leverages the nonlinear approximation capabilities of
Chebyshev polynomials to model complex motion patterns. Additionally, we
introduce an Efficient Kernel-based Self-Attention (EKSA) module to effectively
capture contextual information and enhance long-term dependency modeling.
Experimental results on public datasets (e.g., RIDI, RoNIN, RNIN-VIO, OxIOD,
IMUNet, and TLIO) demonstrate that our method reduces the absolute trajectory
error by 3.79% to 42.32% compared to existing benchmark methods. Furthermore,
we release a preprocessed dataset and empirically show that removing the
gravity component from acceleration data significantly improves inertial
positioning performance.

</details>


### [108] [Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection](https://arxiv.org/abs/2507.16941)
*Daniel Correa,Tero Kaarlela,Jose Fuentes,Paulo Padrao,Alain Duran,Leonardo Bobadilla*

Main category: cs.RO

TL;DR: 论文提出了一种结合强化学习、数字孪生和实时运动捕捉的创新方法，实现了水下机器人珊瑚采样的自主控制，验证了零样本从仿真到现实的策略。


<details>
  <summary>Details</summary>
Motivation: 为珊瑚礁保护和研究的自主水下机器人采样任务开发一种高效、可靠的解决方案，解决传统方法的局限性。

Method: 采用软件在环（SIL）和硬件在环（HIL）技术，结合数字孪生（DT）在仿真中训练强化学习（RL）控制器，并通过物理实验验证。使用水下运动捕捉（MOCAP）系统提供实时3D位置和方向反馈，确保数字与物理域的精确同步。

Result: 成功开发并验证了一种基于强化学习的自主水下机器人采样控制器，展示了零样本从仿真到现实的策略的可行性。

Conclusion: 该论文提出了一种结合强化学习、数字孪生和实时水下运动捕捉的创新方法，成功实现了水下机器人珊瑚采样的自主控制，验证了零样本从仿真到现实的策略的有效性。

Abstract: This paper presents a reinforcement learning (RL) environment for developing
an autonomous underwater robotic coral sampling agent, a crucial coral reef
conservation and research task. Using software-in-the-loop (SIL) and
hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI)
controller is developed using a digital twin (DT) in simulation and
subsequently verified in physical experiments. An underwater motion capture
(MOCAP) system provides real-time 3D position and orientation feedback during
verification testing for precise synchronization between the digital and
physical domains. A key novelty of this approach is the combined use of a
general-purpose game engine for simulation, deep RL, and real-time underwater
motion capture for an effective zero-shot sim-to-real strategy.

</details>


### [109] [RAPTAR: Radar Radiation Pattern Acquisition through Automated Collaborative Robotics](https://arxiv.org/abs/2507.16988)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: cs.RO

TL;DR: RAPTAR是一种基于协作机器人的便携式自主系统，用于3D辐射模式测量，解决了传统方法的局限性，并在实验中表现出高精度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 传统探针台技术存在角度覆盖有限、依赖定制硬件且需频繁手动校准的问题，RAPTAR旨在解决这些限制，特别是在复杂真实场景下的雷达模块测试。

Method: RAPTAR系统基于协作机器人技术，采用7自由度Franka cobot进行无碰撞操作，结合实时运动规划和校准，实现半球空间域的精确测量。

Result: 实验结果显示，RAPTAR在60 GHz雷达模块的测量中，与全波电磁仿真相比，平均绝对误差小于2 dB，且比基线方法降低了36.5%的平均绝对误差。

Conclusion: RAPTAR系统通过机器人自动化实现了高精度的3D辐射模式测量，显著提升了现代片上天线表征的准确性和效率。

Abstract: Accurate characterization of modern on-chip antennas remains challenging, as
current probe-station techniques offer limited angular coverage, rely on
bespoke hardware, and require frequent manual alignment. This research
introduces RAPTAR (Radiation Pattern Acquisition through Robotic Automation), a
portable, state-of-the-art, and autonomous system based on collaborative
robotics. RAPTAR enables 3D radiation-pattern measurement of integrated radar
modules without dedicated anechoic facilities. The system is designed to
address the challenges of testing radar modules mounted in diverse real-world
configurations, including vehicles, UAVs, AR/VR headsets, and biomedical
devices, where traditional measurement setups are impractical. A
7-degree-of-freedom Franka cobot holds the receiver probe and performs
collision-free manipulation across a hemispherical spatial domain, guided by
real-time motion planning and calibration accuracy with RMS error below 0.9 mm.
The system achieves an angular resolution upto 2.5 degree and integrates
seamlessly with RF instrumentation for near- and far-field power measurements.
Experimental scans of a 60 GHz radar module show a mean absolute error of less
than 2 dB compared to full-wave electromagnetic simulations ground truth.
Benchmarking against baseline method demonstrates 36.5% lower mean absolute
error, highlighting RAPTAR accuracy and repeatability.

</details>


### [110] [Shared Control of Holonomic Wheelchairs through Reinforcement Learning](https://arxiv.org/abs/2507.17055)
*Jannis Bähler,Diego Paez-Granados,Jorge Peña-Queralta*

Main category: cs.RO

TL;DR: 提出基于强化学习的共享控制方法，提升全向轮椅的用户体验和安全性，首次实现真实世界应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在全向系统中常导致用户行为不直观，未能充分利用全向驾驶潜力，因此需要一种新方法来提升用户舒适度和减少认知负荷。

Method: 采用强化学习方法，将2D用户输入转化为3D运动，同时在Isaac Gym中进行训练，并在Gazebo仿真中测试。

Result: 研究显示，该方法能确保无碰撞导航，智能调整轮椅方向，并在平滑性上优于或媲美传统非学习方法，同时首次实现了基于RL的共享控制在真实全向移动平台上的应用。

Conclusion: 本研究提出了一种基于强化学习的共享控制方法，有效提升了全向移动平台的用户体验和安全性，并在实际应用中展示了其潜力。

Abstract: Smart electric wheelchairs can improve user experience by supporting the
driver with shared control. State-of-the-art work showed the potential of
shared control in improving safety in navigation for non-holonomic robots.
However, for holonomic systems, current approaches often lead to unintuitive
behavior for the user and fail to utilize the full potential of omnidirectional
driving. Therefore, we propose a reinforcement learning-based method, which
takes a 2D user input and outputs a 3D motion while ensuring user comfort and
reducing cognitive load on the driver. Our approach is trained in Isaac Gym and
tested in simulation in Gazebo. We compare different RL agent architectures and
reward functions based on metrics considering cognitive load and user comfort.
We show that our method ensures collision-free navigation while smartly
orienting the wheelchair and showing better or competitive smoothness compared
to a previous non-learning-based method. We further perform a sim-to-real
transfer and demonstrate, to the best of our knowledge, the first real-world
implementation of RL-based shared control for an omnidirectional mobility
platform.

</details>


### [111] [Deformable Cluster Manipulation via Whole-Arm Policy Learning](https://arxiv.org/abs/2507.17085)
*Jayadeep Jacob,Wenzheng Zhang,Houston Warren,Paulo Borges,Tirthankar Bandyopadhyay,Fabio Ramos*

Main category: cs.RO

TL;DR: A novel RL framework integrates 3D point clouds and touch indicators for manipulating deformable objects, achieving efficient training and real-time inference, with successful sim-to-real transfer.


<details>
  <summary>Details</summary>
Motivation: The challenge lies in the limited capacity for realistic model synthesis, high uncertainty in perception, and lack of efficient spatial abstractions in contact-rich whole-arm interactions with deformable objects.

Method: The framework employs a reinforcement learning approach with a distributional state representation and kernel mean embeddings, alongside a novel context-agnostic occlusion heuristic for clearing deformables from target regions.

Result: The agent generates creative strategies leveraging multiple arm links for de-occlusion and successfully performs zero-shot sim-to-real policy transfer, clearing real branches with unknown occlusion patterns and uncertain dynamics.

Conclusion: The proposed framework successfully addresses the challenges of manipulating clusters of deformable objects by integrating 3D point clouds and proprioceptive touch indicators, achieving real-time inference and creative de-occlusion strategies. The zero-shot sim-to-real policy transfer demonstrates its practical applicability in real-world scenarios like power line clearance.

Abstract: Manipulating clusters of deformable objects presents a substantial challenge
with widespread applicability, but requires contact-rich whole-arm
interactions. A potential solution must address the limited capacity for
realistic model synthesis, high uncertainty in perception, and the lack of
efficient spatial abstractions, among others. We propose a novel framework for
learning model-free policies integrating two modalities: 3D point clouds and
proprioceptive touch indicators, emphasising manipulation with full body
contact awareness, going beyond traditional end-effector modes. Our
reinforcement learning framework leverages a distributional state
representation, aided by kernel mean embeddings, to achieve improved training
efficiency and real-time inference. Furthermore, we propose a novel
context-agnostic occlusion heuristic to clear deformables from a target region
for exposure tasks. We deploy the framework in a power line clearance scenario
and observe that the agent generates creative strategies leveraging multiple
arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy
transfer, allowing the arm to clear real branches with unknown occlusion
patterns, unseen topology, and uncertain dynamics.

</details>


### [112] [MARSCalib: Multi-robot, Automatic, Robust, Spherical Target-based Extrinsic Calibration in Field and Extraterrestrial Environments](https://arxiv.org/abs/2507.17130)
*Seokhwan Jeong,Hogyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 提出了一种鲁棒的LiDAR-相机标定方法，适用于室外多机器人系统，能有效处理目标和传感器损坏。


<details>
  <summary>Details</summary>
Motivation: 针对室外多机器人系统中目标和传感器损坏的问题，开发一种鲁棒的LiDAR-相机外参标定方法。

Method: 提出了一种基于球形目标的LiDAR-相机外参标定方法，结合SAM模型分解图像并提取椭圆中心，同时通过分层加权和处理点云中的噪声。

Result: 实验表明，该方法在多种LiDAR和相机配置下均能稳健检测球形目标，优于其他标定目标。

Conclusion: 该方法在多种LiDAR和相机配置下表现出色，能够有效应对目标和传感器损坏，且在室外多机器人系统中验证了其鲁棒性。

Abstract: This paper presents a novel spherical target-based LiDAR-camera extrinsic
calibration method designed for outdoor environments with multi-robot systems,
considering both target and sensor corruption. The method extracts the 2D
ellipse center from the image and the 3D sphere center from the pointcloud,
which are then paired to compute the transformation matrix. Specifically, the
image is first decomposed using the Segment Anything Model (SAM). Then, a novel
algorithm extracts an ellipse from a potentially corrupted sphere, and the
extracted center of ellipse is corrected for errors caused by the perspective
projection model. For the LiDAR pointcloud, points on the sphere tend to be
highly noisy due to the absence of flat regions. To accurately extract the
sphere from these noisy measurements, we apply a hierarchical weighted sum to
the accumulated pointcloud. Through experiments, we demonstrated that the
sphere can be robustly detected even under both types of corruption,
outperforming other targets. We evaluated our method using three different
types of LiDARs (spinning, solid-state, and non-repetitive) with cameras
positioned in three different locations. Furthermore, we validated the
robustness of our method to target corruption by experimenting with spheres
subjected to various types of degradation. These experiments were conducted in
both a planetary test and a field environment. Our code is available at
https://github.com/sparolab/MARSCalib.

</details>


### [113] [Dynamic Modeling and Dimensional Optimization of Legged Mechanisms for Construction Robot](https://arxiv.org/abs/2507.17132)
*Xiao Liu,Xianlong Yang,Weijun Wang,Wei Feng*

Main category: cs.RO

TL;DR: 本文针对建筑机器人腿部结构进行设计与优化，通过仿生设计和动力学模型优化，显著降低能耗并提升负载能力，为高性能建筑机器人设计提供支持。


<details>
  <summary>Details</summary>
Motivation: 建筑行业快速发展带来的恶劣工作环境、高强度高风险任务及劳动力短缺问题日益突出，推动了对建筑机器人在低能耗、高机动性和高负载能力方面的更高需求。

Method: 基于蚂蚁腿部的自然结构设计机器人腿部，提出新的结构优化方法。利用拉格朗日方法建立腿部动力学模型，结合运动轨迹，制定多种动态评价指标，对各腿段几何参数进行综合优化研究。

Result: 优化后的腿部结构使关节峰值扭矩和能耗降低超过20%，动态仿真实验验证了优化后各关节驱动力显著降低。

Conclusion: 本研究为重型高性能建筑机器人的设计提供了理论基础和技术支持，验证了所提策略的有效性和合理性。

Abstract: With the rapid development of the construction industry, issues such as harsh
working environments, high-intensity and high-risk tasks, and labor shortages
have become increasingly prominent. This drives higher demands for construction
robots in terms of low energy consumption, high mobility, and high load
capacity. This paper focuses on the design and optimization of leg structures
for construction robots, aiming to improve their dynamic performance, reduce
energy consumption, and enhance load-bearing capabilities. Firstly, based on
the leg configuration of ants in nature, we design a structure for the robot's
leg. Secondly, we propose a novel structural optimization method. Using the
Lagrangian approach, a dynamic model of the leg was established. Combining the
dynamic model with the leg's motion trajectory, we formulated multiple dynamic
evaluation metrics and conducted a comprehensive optimization study on the
geometric parameters of each leg segment. The results show that the optimized
leg structure reduces peak joint torques and energy consumption by over 20%.
Finally, dynamic simulation experiments were conducted using ADAMS. The results
demonstrate a significant reduction in the driving power of each joint after
optimization, validating the effectiveness and rationality of the proposed
strategy. This study provides a theoretical foundation and technical support
for the design of heavy-load, high-performance construction robots.

</details>


### [114] [Dynamic Parameter Identification of a Curtain Wall Installation Robotic Arm](https://arxiv.org/abs/2507.17136)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Wei Feng*

Main category: cs.RO

TL;DR: 本文设计了一种液压驱动幕墙安装机械臂及动态参数识别方法，通过D-H模型和Stribeck摩擦模型实现了高精度参数识别，实验验证残差标准差低于0.4 Nm，提升了安装智能化水平。


<details>
  <summary>Details</summary>
Motivation: 传统建筑行业方法无法满足现代效率和质量需求，幕墙安装作为关键环节亟需智能化解决方案。

Method: 设计了一种液压驱动机械臂和动态参数识别方法，建立了基于D-H模型的复合参数系统，并采用Stribeck摩擦模型驱动。通过设计高信噪比的位移激励信号和傅里叶级数构建最优激励轨迹，结合分层渐进参数识别策略，分别识别和联合校准液压缸和机械臂的动态参数。

Result: 实验验证显示理论扭矩与实测扭矩的残差标准差低于0.4 Nm，证实了高精度的动态参数识别。

Conclusion: 实验验证表明，液压驱动幕墙安装机械臂的动态参数识别精度高，理论扭矩与实测扭矩的残差标准差低于0.4 Nm，显著提升了幕墙安装作业的智能化水平。

Abstract: In the construction industry, traditional methods fail to meet the modern
demands for efficiency and quality. The curtain wall installation is a critical
component of construction projects. We design a hydraulically driven robotic
arm for curtain wall installation and a dynamic parameter identification
method. We establish a Denavit-Hartenberg (D-H) model based on measured robotic
arm structural parameters and integrate hydraulic cylinder dynamics to
construct a composite parametric system driven by a Stribeck friction model. By
designing high-signal-to-noise ratio displacement excitation signals for
hydraulic cylinders and combining Fourier series to construct optimal
excitation trajectories that satisfy joint constraints, this method effectively
excites the characteristics of each parameter in the minimal parameter set of
the dynamic model of the robotic arm. On this basis, a hierarchical progressive
parameter identification strategy is proposed: least squares estimation is
employed to separately identify and jointly calibrate the dynamic parameters of
both the hydraulic cylinder and the robotic arm, yielding Stribeck model curves
for each joint. Experimental validation on a robotic arm platform demonstrates
residual standard deviations below 0.4 Nm between theoretical and measured
joint torques, confirming high-precision dynamic parameter identification for
the hydraulic-driven curtain wall installation robotic arm. This significantly
contributes to enhancing the intelligence level of curtain wall installation
operations.

</details>


### [115] [Multi-Objective Trajectory Planning for a Robotic Arm in Curtain Wall Installation](https://arxiv.org/abs/2507.17140)
*Xiao Liu,Yunxiao Cheng,Weijun Wang,Tianlun Huang,Zhiyong Wang,Wei Feng*

Main category: cs.RO

TL;DR: 论文提出NSGA-III-FO算法优化建筑机械臂轨迹，实验证明其高效实用，优于其他算法。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺和成本上升背景下，建筑机器人被视为革新传统建筑方法的关键，但传统单目标轨迹优化方法难以满足复杂建筑环境的需求。

Method: 设计了用于幕墙安装的机械臂，并提出了NSGA-III-FO算法，该算法结合了聚焦算子筛选机制以加速收敛。

Result: NSGA-III-FO算法在DTLZ3和WFG3测试函数上显著优于NSGA-III、MOEA/D和MSOPS-II算法，实验验证了其在轨迹规划中的高效性。

Conclusion: 论文提出的NSGA-III-FO算法在解决幕墙安装任务的轨迹规划问题上表现出高效性和实用性，通过实验验证了其优于其他对比算法。

Abstract: In the context of labor shortages and rising costs, construction robots are
regarded as the key to revolutionizing traditional construction methods and
improving efficiency and quality in the construction industry. In order to
ensure that construction robots can perform tasks efficiently and accurately in
complex construction environments, traditional single-objective trajectory
optimization methods are difficult to meet the complex requirements of the
changing construction environment. Therefore, we propose a multi-objective
trajectory optimization for the robotic arm used in the curtain wall
installation. First, we design a robotic arm for curtain wall installation,
integrating serial, parallel, and folding arm elements, while considering its
physical properties and motion characteristics. In addition, this paper
proposes an NSGA-III-FO algorithm (NSGA-III with Focused Operator, NSGA-III-FO)
that incorporates a focus operator screening mechanism to accelerate the
convergence of the algorithm towards the Pareto front, thereby effectively
balancing the multi-objective constraints of construction robots. The proposed
algorithm is tested against NSGA-III, MOEA/D, and MSOPS-II in ten consecutive
trials on the DTLZ3 and WFG3 test functions, showing significantly better
convergence efficiency than the other algorithms. Finally, we conduct two sets
of experiments on the designed robotic arm platform, which confirm the
efficiency and practicality of the NSGA-III-FO algorithm in solving
multi-objective trajectory planning problems for curtain wall installation
tasks.

</details>


### [116] [Towards Human-level Intelligence via Human-like Whole-Body Manipulation](https://arxiv.org/abs/2507.17141)
*Guang Gao,Jianan Wang,Jinbo Zuo,Junnan Jiang,Jingfan Zhang,Xianwen Zeng,Yuejiang Zhu,Lianyang Ma,Ke Chen,Minhua Sheng,Ruirui Zhang,Zhaohui An*

Main category: cs.RO

TL;DR: Astribot Suite是一个解决通用机器人全身操作挑战的集成系统，展示了在多样任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 模仿人类进化轨迹，通过与环境持续互动学习，目标是构建通用智能机器人。

Method: 提出了Astribot Suite，一个用于全身操作的学习套件，解决硬件设计、远程操作接口和算法学习三大挑战。

Result: 展示了Astribot在多种需要全身协调、广泛可达性、人类级灵巧性和敏捷性的活动中的有效性。

Conclusion: Astribot Suite的整合体现了在实现通用全身机器人操作方面的重要进展，为下一代智能机器人奠定了基础。

Abstract: Building general-purpose intelligent robots has long been a fundamental goal
of robotics. A promising approach is to mirror the evolutionary trajectory of
humans: learning through continuous interaction with the environment, with
early progress driven by the imitation of human behaviors. Achieving this goal
presents three core challenges: (1) designing safe robotic hardware with
human-level physical capabilities; (2) developing an intuitive and scalable
whole-body teleoperation interface for data collection; and (3) creating
algorithms capable of learning whole-body visuomotor policies from human
demonstrations. To address these challenges in a unified framework, we propose
Astribot Suite, a robot learning suite for whole-body manipulation aimed at
general daily tasks across diverse environments. We demonstrate the
effectiveness of our system on a wide range of activities that require
whole-body coordination, extensive reachability, human-level dexterity, and
agility. Our results show that Astribot's cohesive integration of embodiment,
teleoperation interface, and learning pipeline marks a significant step towards
real-world, general-purpose whole-body robotic manipulation, laying the
groundwork for the next generation of intelligent robots.

</details>


### [117] [Falconry-like palm landing by a flapping-wing drone based on the human gesture interaction and distance-aware flight planning](https://arxiv.org/abs/2507.17144)
*Kazuki Numazato,Keiichiro Kan,Masaki Kitagawa,Yunong Li,Johannes Kubel,Moju Zhao*

Main category: cs.RO

TL;DR: 本研究受训鹰师启发，设计了一种扑翼无人机手掌着陆系统，通过轨迹规划确保安全，首次实现了人机接触式交互。


<details>
  <summary>Details</summary>
Motivation: 扑翼无人机因其仿生飞行特性被认为更适合人机交互，但目前缺乏实际交互研究。受训鹰师引导猛禽降落的启发，本研究旨在建立类似的交互系统。

Method: 设计了一种考虑人类安全和心理因素的轨迹规划方法，并使用商业扑翼平台进行实验评估。

Result: 实验证明，所提出的方法能够实现安全且流畅的手掌着陆交互。

Conclusion: 本研究首次实现了扑翼无人机与人类之间的接触式交互，展示了安全且流畅的手掌着陆性能。

Abstract: Flapping-wing drones have attracted significant attention due to their
biomimetic flight. They are considered more human-friendly due to their
characteristics such as low noise and flexible wings, making them suitable for
human-drone interactions. However, few studies have explored the practical
interaction between humans and flapping-wing drones. On establishing a physical
interaction system with flapping-wing drones, we can acquire inspirations from
falconers who guide birds of prey to land on their arms. This interaction
interprets the human body as a dynamic landing platform, which can be utilized
in various scenarios such as crowded or spatially constrained environments.
Thus, in this study, we propose a falconry-like interaction system in which a
flapping-wing drone performs a palm landing motion on a human hand. To achieve
a safe approach toward humans, we design a trajectory planning method that
considers both physical and psychological factors of the human safety such as
the drone's velocity and distance from the user. We use a commercial flapping
platform with our implemented motion planning and conduct experiments to
evaluate the palm landing performance and safety. The results demonstrate that
our approach enables safe and smooth hand landing interactions. To the best of
our knowledge, it is the first time to achieve a contact-based interaction
between flapping-wing drones and humans.

</details>


### [118] [JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction](https://arxiv.org/abs/2507.17152)
*Fangze Lin,Ying He,Fei Yu,Hong Zhang*

Main category: cs.RO

TL;DR: JAM框架通过两阶段方法（轨迹分类与联合预测）提升多智能体交互预测性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体联合预测中低概率模式生成质量低的问题。

Method: 采用两阶段多智能体交互预测框架（JAM），第一阶段为分类感知边缘提议的轨迹类型分类，第二阶段为联合预测过程，利用关键路径点引导联合预测模块。

Result: 在Waymo Open Motion Dataset上的实验表明，JAM框架优于其他预测框架，性能领先。

Conclusion: 提出的JAM框架在交互式轨迹预测任务中表现出色，实现了最先进的性能，代码已开源以供未来研究。

Abstract: Predicting the future motion of road participants is a critical task in
autonomous driving. In this work, we address the challenge of low-quality
generation of low-probability modes in multi-agent joint prediction. To tackle
this issue, we propose a two-stage multi-agent interactive prediction framework
named \textit{keypoint-guided joint prediction after classification-aware
marginal proposal} (JAM). The first stage is modeled as a marginal prediction
process, which classifies queries by trajectory type to encourage the model to
learn all categories of trajectories, providing comprehensive mode information
for the joint prediction module. The second stage is modeled as a joint
prediction process, which takes the scene context and the marginal proposals
from the first stage as inputs to learn the final joint distribution. We
explicitly introduce key waypoints to guide the joint prediction module in
better capturing and leveraging the critical information from the initial
predicted trajectories. We conduct extensive experiments on the real-world
Waymo Open Motion Dataset interactive prediction benchmark. The results show
that our approach achieves competitive performance. In particular, in the
framework comparison experiments, the proposed JAM outperforms other prediction
frameworks and achieves state-of-the-art performance in interactive trajectory
prediction. The code is available at https://github.com/LinFunster/JAM to
facilitate future research.

</details>


### [119] [Reconfigurable Tendon-Driven Robots: Eliminating Inter-segmental Coupling via Independently Lockable Joints](https://arxiv.org/abs/2507.17163)
*Botao Lin,Shuang Song,Jiaole Wang*

Main category: cs.RO

TL;DR: 本文提出了一种可重构肌腱驱动机器人（RTR），通过可锁定关节设计消除段间耦合，实验验证了其运动学和静力学模型，展示了其在复杂环境中的优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统肌腱驱动机器人（TDR）在增加段数以提高灵活性和工作空间时，段间耦合问题加剧，导致需要更复杂的模型和更多电机。本文旨在通过可锁定关节设计解决这一问题。

Method: 本文设计了具有可锁定关节的RTR，每个关节的状态（锁定/自由）可通过一对拮抗肌腱独立控制。通过选择性驱动目标机器人段，消除了段间耦合。推导了RTR的运动学和静力学模型，并进行了仿真和实验验证。

Result: RTR通过可锁定关节设计消除了段间耦合，避免了复杂的段间协调控制。仿真和实验表明，RTR在复杂环境中具有优异的可重构性和移动能力，仅需六个电机即可驱动七关节原型。

Conclusion: 本文提出了一种可重构肌腱驱动机器人（RTR），通过创新的可锁定关节设计，有效消除了传统肌腱驱动机器人（TDR）的段间耦合问题。实验验证了RTR的运动学和静力学模型，并通过七关节RTR原型展示了其在复杂环境中的可重构性和移动能力，仅需六个电机即可实现驱动。

Abstract: With a slender redundant body, the tendon-driven robot (TDR) has a large
workspace and great maneuverability while working in complex environments. TDR
comprises multiple independently controlled robot segments, each with a set of
driving tendons. While increasing the number of robot segments enhances
dexterity and expands the workspace, this structural expansion also introduces
intensified inter-segmental coupling. Therefore, achieving precise TDR control
requires more complex models and additional motors. This paper presents a
reconfigurable tendon-driven robot (RTR) equipped with innovative lockable
joints. Each joint's state (locked/free) can be individually controlled through
a pair of antagonistic tendons, and its structure eliminates the need for a
continuous power supply to maintain the state. Operators can selectively
actuate the targeted robot segments, and this scheme fundamentally eliminates
the inter-segmental coupling, thereby avoiding the requirement for complex
coordinated control between segments. The workspace of RTR has been simulated
and compared with traditional TDRs' workspace, and RTR's advantages are further
revealed. The kinematics and statics models of the RTR have been derived and
validation experiments have been conducted. Demonstrations have been performed
using a seven-joint RTR prototype to show its reconfigurability and moving
ability in complex environments with an actuator pack comprising only six
motors.

</details>


### [120] [FAST-Calib: LiDAR-Camera Extrinsic Calibration in One Second](https://arxiv.org/abs/2507.17210)
*Chunran Zheng,Fu Zhang*

Main category: cs.RO

TL;DR: FAST-Calib是一种快速、用户友好的LiDAR-相机外参校准工具，支持多种LiDAR，通过高效边缘提取和椭圆拟合实现高精度校准。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有LiDAR-相机外参校准工具的效率和鲁棒性问题，尤其是在支持不同LiDAR类型（机械式和固态式）时的挑战。

Method: FAST-Calib 提出了一种基于定制3D目标的快速校准方法，利用高效的边缘提取算法（适用于不同LiDAR扫描模式），并通过椭圆拟合补偿LiDAR光斑扩散导致的边缘膨胀问题，支持多场景联合优化。

Result: 实验验证显示，FAST-Calib 在Ouster、Avia和Mid360三种LiDAR模型上均表现出卓越的准确性和鲁棒性，点对点配准误差低于6.5mm，总处理时间小于0.7秒。

Conclusion: FAST-Calib 是一个高效、准确且基于目标的自动校准工具，通过开源代码和数据集为机器人社区提供了便利。

Abstract: This paper proposes FAST-Calib, a fast and user-friendly LiDAR-camera
extrinsic calibration tool based on a custom-made 3D target. FAST-Calib
supports both mechanical and solid-state LiDARs by leveraging an efficient and
reliable edge extraction algorithm that is agnostic to LiDAR scan patterns. It
also compensates for edge dilation artifacts caused by LiDAR spot spread
through ellipse fitting, and supports joint optimization across multiple
scenes. We validate FAST-Calib on three LiDAR models (Ouster, Avia, and
Mid360), each paired with a wide-angle camera. Experimental results demonstrate
superior accuracy and robustness compared to existing methods. With
point-to-point registration errors consistently below 6.5mm and total
processing time under 0.7s, FAST-Calib provides an efficient, accurate, and
target-based automatic calibration pipeline. We have open-sourced our code and
dataset on GitHub to benefit the robotics community.

</details>


### [121] [Optimizing Delivery Logistics: Enhancing Speed and Safety with Drone Technology](https://arxiv.org/abs/2507.17253)
*Maharshi Shastri,Ujjval Shrivastav*

Main category: cs.RO

TL;DR: 该论文提出了一个AI集成的无人机配送系统，通过优化路线和实时跟踪提高配送效率，初步结果显示其在时间和准确性上优于传统物流。


<details>
  <summary>Details</summary>
Motivation: 随着对快速且经济高效的最后一英里配送解决方案的需求增加，无人机物流技术得到了显著发展。本研究旨在开发一个集成了AI的无人机配送系统，以解决传统地面物流的效率问题。

Method: 研究采用了YOLOv4 Tiny进行物体检测，NEO 6M GPS模块进行导航，A7670 SIM模块实现实时通信。此外，通过比较轻量级AI模型和硬件组件，确定了实时无人机配送的最佳配置。

Result: 初步研究表明，相比传统地面物流，该系统在配送时间上有显著提升，并通过面部识别实现了高精度的收件人认证。此外，研究还解决了电池效率、法规合规性和安全性等关键挑战。

Conclusion: 该研究提出了一个集成了AI的无人机配送系统，通过优化路线、物体检测、安全包裹处理和实时跟踪，显著提高了最后一英里配送的效率和准确性。研究还讨论了无人机配送的伦理问题和社会接受度，并确保符合多个国际航空监管标准。

Abstract: The increasing demand for fast and cost effective last mile delivery
solutions has catalyzed significant advancements in drone based logistics. This
research describes the development of an AI integrated drone delivery system,
focusing on route optimization, object detection, secure package handling, and
real time tracking. The proposed system leverages YOLOv4 Tiny for object
detection, the NEO 6M GPS module for navigation, and the A7670 SIM module for
real time communication. A comparative analysis of lightweight AI models and
hardware components is conducted to determine the optimal configuration for
real time UAV based delivery. Key challenges including battery efficiency,
regulatory compliance, and security considerations are addressed through the
integration of machine learning techniques, IoT devices, and encryption
protocols. Preliminary studies demonstrate improvement in delivery time
compared to conventional ground based logistics, along with high accuracy
recipient authentication through facial recognition. The study also discusses
ethical implications and societal acceptance of drone deliveries, ensuring
compliance with FAA, EASA and DGCA regulatory standards. Note: This paper
presents the architecture, design, and preliminary simulation results of the
proposed system. Experimental results, simulation benchmarks, and deployment
statistics are currently being acquired. A comprehensive analysis will be
included in the extended version of this work.

</details>


### [122] [Prolonging Tool Life: Learning Skillful Use of General-purpose Tools through Lifespan-guided Reinforcement Learning](https://arxiv.org/abs/2507.17275)
*Po-Yen Wu,Cheng-Yu Kuo,Yuki Kadokawa,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 论文提出了一种强化学习框架，通过估计工具剩余寿命并集成到奖励函数中，实现了在完成任务的同时延长工具寿命的策略，验证了其在实际任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在不确定任务需求的不可访问环境中，通用工具缺乏预定义的使用策略，导致工具寿命对使用方式高度敏感。如何让机器人学习既能完成任务又能延长工具寿命的策略是一个关键挑战。

Method: 采用强化学习（RL）框架，结合有限元分析（FEA）和Miner法则来估计工具的剩余使用寿命（RUL），并通过自适应奖励归一化（ARN）机制动态调整奖励规模。

Result: 在模拟和现实世界的工具使用任务中验证了方法的有效性，学习到的策略显著延长了工具寿命（模拟中最高达8.01倍），并能有效迁移到实际应用中。

Conclusion: 该论文提出了一种结合工具寿命的强化学习框架，通过集成剩余使用寿命（RUL）估计和自适应奖励归一化机制，成功实现了在完成任务的同时延长工具寿命的目标。

Abstract: In inaccessible environments with uncertain task demands, robots often rely
on general-purpose tools that lack predefined usage strategies. These tools are
not tailored for particular operations, making their longevity highly sensitive
to how they are used. This creates a fundamental challenge: how can a robot
learn a tool-use policy that both completes the task and prolongs the tool's
lifespan? In this work, we address this challenge by introducing a
reinforcement learning (RL) framework that incorporates tool lifespan as a
factor during policy optimization. Our framework leverages Finite Element
Analysis (FEA) and Miner's Rule to estimate Remaining Useful Life (RUL) based
on accumulated stress, and integrates the RUL into the RL reward to guide
policy learning toward lifespan-guided behavior. To handle the fact that RUL
can only be estimated after task execution, we introduce an Adaptive Reward
Normalization (ARN) mechanism that dynamically adjusts reward scaling based on
estimated RULs, ensuring stable learning signals. We validate our method across
simulated and real-world tool use tasks, including Object-Moving and
Door-Opening with multiple general-purpose tools. The learned policies
consistently prolong tool lifespan (up to 8.01x in simulation) and transfer
effectively to real-world settings, demonstrating the practical value of
learning lifespan-guided tool use strategies.

</details>


### [123] [VLA-Touch: Enhancing Vision-Language-Action Models with Dual-Level Tactile Feedback](https://arxiv.org/abs/2507.17294)
*Jianxin Bi,Kevin Yuchen Ma,Ce Hao,Mike Zheng Shou,Harold Soh*

Main category: cs.RO

TL;DR: VLA-Touch通过预训练触觉语言模型和扩散控制器，无需微调基础VLA即可提升触觉反馈在机器人任务中的效果。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型缺乏触觉信号处理能力，限制了其在接触密集型任务中的有效性，且缺乏多模态数据集。

Method: 提出了一种结合预训练触觉语言模型的管道和基于扩散的控制器，以语义触觉反馈优化任务规划和动作执行。

Result: 实验证明，VLA-Touch在任务规划和执行方面均表现出色。

Conclusion: VLA-Touch通过双重触觉反馈集成显著提升了任务规划效率和执行精度，且无需微调基础VLA模型。

Abstract: Tactile feedback is generally recognized to be crucial for effective
interaction with the physical world. However, state-of-the-art
Vision-Language-Action (VLA) models lack the ability to interpret and use
tactile signals, limiting their effectiveness in contact-rich tasks.
Incorporating tactile feedback into these systems is challenging due to the
absence of large multi-modal datasets. We present VLA-Touch, an approach that
enhances generalist robot policies with tactile sensing \emph{without
fine-tuning} the base VLA. Our method introduces two key innovations: (1) a
pipeline that leverages a pretrained tactile-language model that provides
semantic tactile feedback for high-level task planning, and (2) a
diffusion-based controller that refines VLA-generated actions with tactile
signals for contact-rich manipulation. Through real-world experiments, we
demonstrate that our dual-level integration of tactile feedback improves task
planning efficiency while enhancing execution precision. Code is open-sourced
at \href{https://github.com/jxbi1010/VLA-Touch}{this URL}.

</details>


### [124] [HuNavSim 2.0](https://arxiv.org/abs/2507.17317)
*Miguel Escudero-Jiménez,Noé Pérez-Higueras,Andrés Martínez-Silva,Fernando Caballero,Luis Merino*

Main category: cs.RO

TL;DR: 新版HuNavSim通过行为树技术提升对人类导航行为的模拟能力，支持更复杂场景下的人机交互评估。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个开源工具，以促进人机导航系统的开发和评估，特别是在模拟环境中实现人类感知的机器人导航。

Method: 该工具基于ROS 2框架开发，可与Gazebo或NVidia Isaac Sim等机器人模拟器配合使用，通过行为树技术实现人类导航行为的模拟。

Result: 新版本改进了多项功能并新增了特性，如扩展的行为树动作和条件组合，支持更复杂和真实的人类行为模拟。

Conclusion: 新版HuNavSim通过改进和新增功能，如扩展的行为树动作和条件组合，提升了模拟复杂和真实人类行为的能力，进一步促进了人机导航系统的开发和评估。

Abstract: This work presents a new iteration of the Human Navigation Simulator
(HuNavSim), a novel open-source tool for the simulation of different
human-agent navigation behaviors in scenarios with mobile robots. The tool,
programmed under the ROS 2 framework, can be used together with different
well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main
goal is to facilitate the development and evaluation of human-aware robot
navigation systems in simulation. In this new version, several features have
been improved and new ones added, such as the extended set of actions and
conditions that can be combined in Behavior Trees to compound complex and
realistic human behaviors.

</details>


### [125] [Mobile Manipulation with Active Inference for Long-Horizon Rearrangement Tasks](https://arxiv.org/abs/2507.17338)
*Corrado Pezzato,Ozan Çatal,Toon Van de Maele,Riddhi J. Pitliya,Tim Verbelen*

Main category: cs.RO

TL;DR: 提出分层主动推理架构，首次证明其在复杂机器人任务中的可扩展性和优越性能。


<details>
  <summary>Details</summary>
Motivation: 尽管主动推理在机器人控制中的兴趣日益增长，但其在复杂、长视野任务中的应用尚未得到充分测试。

Method: 引入了一种完全分层的主动推理架构，结合高层主动推理模型和全身主动推理控制器，实现离散技能的选择和灵活组合。

Result: 在Habitat Benchmark的移动操作任务中，该方法在三个长视野任务上优于现有技术基准。

Conclusion: 本研究首次证明了主动推理可以扩展到现代机器人基准的复杂性，通过分层架构在复杂、长视野任务中实现了优于现有技术的性能。

Abstract: Despite growing interest in active inference for robotic control, its
application to complex, long-horizon tasks remains untested. We address this
gap by introducing a fully hierarchical active inference architecture for
goal-directed behavior in realistic robotic settings. Our model combines a
high-level active inference model that selects among discrete skills realized
via a whole-body active inference controller. This unified approach enables
flexible skill composition, online adaptability, and recovery from task
failures without requiring offline training. Evaluated on the Habitat Benchmark
for mobile manipulation, our method outperforms state-of-the-art baselines
across the three long-horizon tasks, demonstrating for the first time that
active inference can scale to the complexity of modern robotics benchmarks.

</details>


### [126] [An Exploratory Study on Human-Robot Interaction using Semantics-based Situational Awareness](https://arxiv.org/abs/2507.17376)
*Tianshu Ruan,Aniketh Ramesh,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 研究发现，高层次语义能显著改善HRT中的操作员体验，包括减轻工作负担、增强信任和加快反应速度。


<details>
  <summary>Details</summary>
Motivation: 探索高层次语义如何改善HRT范式，特别是在复杂任务中提升操作员的情境感知（SA）和决策效率。

Method: 应用基于语义的框架，在模拟灾难响应任务中评估环境的不同语义指标。

Result: 语义信息减轻了操作员的工作负担，提高了对SA的信任，并减少了切换自主级别时的反应时间。信任度高的参与者更倾向于使用远程操作模式。

Conclusion: 高层次的语义信息在人类-机器人团队（HRT）和人机交互（HRI）中具有显著影响，能够减轻操作员的工作负担、增强信任并缩短反应时间。

Abstract: In this paper, we investigate the impact of high-level semantics (evaluation
of the environment) on Human-Robot Teams (HRT) and Human-Robot Interaction
(HRI) in the context of mobile robot deployments. Although semantics has been
widely researched in AI, how high-level semantics can benefit the HRT paradigm
is underexplored, often fuzzy, and intractable. We applied a semantics-based
framework that could reveal different indicators of the environment (i.e. how
much semantic information exists) in a mock-up disaster response mission. In
such missions, semantics are crucial as the HRT should handle complex
situations and respond quickly with correct decisions, where humans might have
a high workload and stress. Especially when human operators need to shift their
attention between robots and other tasks, they will struggle to build
Situational Awareness (SA) quickly. The experiment suggests that the presented
semantics: 1) alleviate the perceived workload of human operators; 2) increase
the operator's trust in the SA; and 3) help to reduce the reaction time in
switching the level of autonomy when needed. Additionally, we find that
participants with higher trust in the system are encouraged by high-level
semantics to use teleoperation mode more.

</details>


### [127] [Language-Conditioned Open-Vocabulary Mobile Manipulation with Pretrained Models](https://arxiv.org/abs/2507.17379)
*Shen Tan,Dong Zhou,Xiangyu Shao,Junqiao Wang,Guanghui Sun*

Main category: cs.RO

TL;DR: LOVMM框架结合LLM和VLM，通过自然语言指令解决家庭环境中的开放词汇移动操作任务，展示了强大的泛化和多任务学习能力。


<details>
  <summary>Details</summary>
Motivation: 开放词汇移动操作（OVMM）在不同工作空间中处理新颖和未见过的对象对实际机器人应用仍是一个重大挑战。

Method: 提出了一种名为LOVMM的新框架，结合LLM和VLM，通过自由形式的自然语言指令解决各种开放词汇移动操作任务。

Result: 在复杂家庭环境中的模拟实验显示，LOVMM具有强大的零样本泛化和多任务学习能力，且在多种桌面操作任务中表现优于其他先进方法。

Conclusion: LOVMM框架通过结合大型语言模型（LLM）和视觉语言模型（VLM），在家庭环境中展示了强大的零样本泛化和多任务学习能力，且在多种桌面操作任务中表现优于现有方法。

Abstract: Open-vocabulary mobile manipulation (OVMM) that involves the handling of
novel and unseen objects across different workspaces remains a significant
challenge for real-world robotic applications. In this paper, we propose a
novel Language-conditioned Open-Vocabulary Mobile Manipulation framework, named
LOVMM, incorporating the large language model (LLM) and vision-language model
(VLM) to tackle various mobile manipulation tasks in household environments.
Our approach is capable of solving various OVMM tasks with free-form natural
language instructions (e.g. "toss the food boxes on the office room desk to the
trash bin in the corner", and "pack the bottles from the bed to the box in the
guestroom"). Extensive experiments simulated in complex household environments
show strong zero-shot generalization and multi-task learning abilities of
LOVMM. Moreover, our approach can also generalize to multiple tabletop
manipulation tasks and achieve better success rates compared to other
state-of-the-art methods.

</details>


### [128] [Confidence Calibration in Vision-Language-Action Models](https://arxiv.org/abs/2507.17383)
*Thomas P Zollo,Richard Zemel*

Main category: cs.RO

TL;DR: 本文首次系统研究了VLA模型的置信度校准，发现任务性能与校准不冲突，提出提示集成和动作维度独立的Platt缩放方法以提高置信度估计的可靠性。


<details>
  <summary>Details</summary>
Motivation: 为了确保机器人行为的可信度，不仅需要高任务成功率，还需可靠量化其成功可能性。

Method: 通过广泛的基准测试分析任务成功率与校准误差的关系，引入轻量级的提示集成算法，并提出了动作维度独立的Platt缩放方法。

Result: 研究发现任务性能与校准并不冲突，提示集成算法能持续改善校准，且置信度在任务进展后更可靠。动作维度独立的Platt缩放方法能提供更好的置信度估计。

Conclusion: 本研究旨在通过可靠的置信度校准工具和概念理解，使视觉-语言-动作（VLA）基础模型既高性能又高可信度。

Abstract: Trustworthy robot behavior requires not only high levels of task success but
also that the robot can reliably quantify how likely it is to succeed. To this
end, we present the first systematic study of confidence calibration in
vision-language-action (VLA) foundation models, which map visual observations
and natural-language instructions to low-level robot motor commands. We begin
with extensive benchmarking to understand the critical relationship between
task success and calibration error across multiple datasets and VLA variants,
finding that task performance and calibration are not in tension. Next, we
introduce prompt ensembles for VLAs, a lightweight, Bayesian-inspired algorithm
that averages confidence across paraphrased instructions and consistently
improves calibration. We further analyze calibration over the task time
horizon, showing that confidence is often most reliable after making some
progress, suggesting natural points for risk-aware intervention. Finally, we
reveal differential miscalibration across action dimensions and propose
action-wise Platt scaling, a method to recalibrate each action dimension
independently to produce better confidence estimates. Our aim in this study is
to begin to develop the tools and conceptual understanding necessary to render
VLAs both highly performant and highly trustworthy via reliable uncertainty
quantification.

</details>


### [129] [The Wilhelm Tell Dataset of Affordance Demonstrations](https://arxiv.org/abs/2507.17401)
*Rachel Ringe,Mihai Pomarlan,Nikolaos Tsiogkas,Stefano De Giorgis,Maria Hedblom,Rainer Malaka*

Main category: cs.RO

TL;DR: 论文介绍了一个新的视频数据集，用于学习家庭任务中的动态可供性表现，旨在提升机器人感知能力。


<details>
  <summary>Details</summary>
Motivation: 现有的可供性学习方法主要基于静态图像或形状的标注，而实际任务中的动态表现和预备动作（如任务空间布置）对机器人协作尤为重要。

Method: 通过收集多个参与者的视频序列（第一和第三人称视角）以及相关元数据，构建了一个包含约七小时人类活动的数据集。

Result: 数据集不仅捕捉了任务执行中的可供性表现，还记录了人们在任务前的准备动作，为协作服务机器人的研究提供了丰富资源。

Conclusion: 该论文提出了一个新颖的数据集，用于学习常见家庭任务中的功能可供性，旨在训练感知系统识别这些可供性表现。

Abstract: Affordances - i.e. possibilities for action that an environment or objects in
it provide - are important for robots operating in human environments to
perceive. Existing approaches train such capabilities on annotated static
images or shapes. This work presents a novel dataset for affordance learning of
common household tasks. Unlike previous approaches, our dataset consists of
video sequences demonstrating the tasks from first- and third-person
perspectives, along with metadata about the affordances that are manifested in
the task, and is aimed towards training perception systems to recognize
affordance manifestations. The demonstrations were collected from several
participants and in total record about seven hours of human activity. The
variety of task performances also allows studying preparatory maneuvers that
people may perform for a task, such as how they arrange their task space, which
is also relevant for collaborative service robots.

</details>


### [130] [IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception](https://arxiv.org/abs/2507.17445)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: IndoorBEV是一种新颖的基于掩码的鸟瞰图方法，用于室内移动机器人，能有效检测复杂3D点云中的多样物体，提供直接用于机器人任务的2D BEV结果。


<details>
  <summary>Details</summary>
Motivation: 传统边界框方法在处理复杂室内3D点云中的多样化物体形状、杂乱环境和静态与动态元素共存时表现不佳，因此需要一种更鲁棒的替代方案。

Method: IndoorBEV采用轴向紧凑编码器和基于窗口的主干网络从BEV地图中提取丰富的空间特征，随后通过基于查询的解码头在BEV空间中同时预测物体类别和实例掩码。

Result: 在包含静态物体和动态元素（如机器人和其他物品）的自定义室内数据集上，IndoorBEV展示了其强大的室内场景理解能力。

Conclusion: IndoorBEV提供了一种基于掩码的鸟瞰图方法，有效解决了复杂室内3D点云中多样物体检测的挑战，为机器人感知任务如导航、运动预测和规划提供了直接可用的2D BEV结果。

Abstract: Detecting diverse objects within complex indoor 3D point clouds presents
significant challenges for robotic perception, particularly with varied object
shapes, clutter, and the co-existence of static and dynamic elements where
traditional bounding box methods falter. To address these limitations, we
propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor
mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles
naturally occlusions and provides a consistent top-down view aiding to
distinguish static obstacles from dynamic agents. The obtained 2D BEV results
is directly usable to downstream robotic tasks like navigation, motion
prediction, and planning. Our architecture utilizes an axis compact encoder and
a window-based backbone to extract rich spatial features from this BEV map. A
query-based decoder head then employs learned object queries to concurrently
predict object classes and instance masks in the BEV space. This mask-centric
formulation effectively captures the footprint of both static and dynamic
objects regardless of their shape, offering a robust alternative to bounding
box regression. We demonstrate the effectiveness of IndoorBEV on a custom
indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its
potential for robust indoor scene understanding.

</details>


### [131] [Terrain-Aware Adaptation for Two-Dimensional UAV Path Planners](https://arxiv.org/abs/2507.17519)
*Kostas Karakontis,Thanos Petsanis,Athanasios Ch. Kapoutsis,Pavlos Ch. Kapoutsis,Elias B. Kosmatopoulos*

Main category: cs.RO

TL;DR: 提出DARP-3D算法，通过调整无人机高度和相机方向改进3D重建，实验验证其在垂直特征区域的优越性能。


<details>
  <summary>Details</summary>
Motivation: 商业软件中的多无人机覆盖路径规划（mCPP）算法通常将感兴趣区域（RoI）仅视为2D平面，忽略了重要的3D结构特征，导致3D重建不完整。

Method: 提出了一种模块化算法，扩展了商业二维路径规划器（如DARP算法），通过调整无人机高度和相机方向实现地形感知规划。

Result: 在多个3D环境和实际飞行测试中，DARP-3D相比基线方法显著提升了3D重建质量，特别是在垂直特征明显的区域。

Conclusion: 本文提出的DARP-3D算法通过调整无人机高度和相机方向，显著提升了3D重建质量，特别是在垂直特征明显的区域，验证了其在实际应用中的有效性。

Abstract: Multi-UAV Coverage Path Planning (mCPP) algorithms in popular commercial
software typically treat a Region of Interest (RoI) only as a 2D plane,
ignoring important3D structure characteristics. This leads to incomplete
3Dreconstructions, especially around occluded or vertical surfaces. In this
paper, we propose a modular algorithm that can extend commercial
two-dimensional path planners to facilitate terrain-aware planning by adjusting
altitude and camera orientations. To demonstrate it, we extend the well-known
DARP (Divide Areas for Optimal Multi-Robot Coverage Path Planning) algorithm
and produce DARP-3D. We present simulation results in multiple 3D environments
and a real-world flight test using DJI hardware. Compared to baseline, our
approach consistently captures improved 3D reconstructions, particularly in
areas with significant vertical features. An open-source implementation of the
algorithm is available here:https://github.com/konskara/TerraPlan

</details>


### [132] [InstructVLA: Vision-Language-Action Instruction Tuning from Understanding to Manipulation](https://arxiv.org/abs/2507.17520)
*Shuai Yang,Hao Li,Yilun Chen,Bin Wang,Yang Tian,Tai Wang,Hanqing Wang,Feng Zhao,Yiyi Liao,Jiangmiao Pang*

Main category: cs.RO

TL;DR: InstructVLA是一种端到端VLA模型，通过VLA-IT训练范式，结合多模态训练和专家混合适应，显著提升了文本推理和动作生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型往往牺牲推理或动作生成能力，局限于特定任务操作数据，并存在对预训练视觉-语言能力的灾难性遗忘。

Method: 引入了一种新颖的训练范式Vision-Language-Action Instruction Tuning (VLA-IT)，采用多模态训练与专家混合适应，联合优化文本推理和动作生成。

Result: 在SimplerEnv任务上提升30.5%，在SimplerEnv-Instruct基准上优于微调OpenVLA 92%和GPT-4o辅助的动作专家29%。

Conclusion: InstructVLA展示了在直觉和可操控的人机交互与高效策略学习之间架设桥梁的潜力。

Abstract: To operate effectively in the real world, robots must integrate multimodal
reasoning with precise action generation. However, existing
vision-language-action (VLA) models often sacrifice one for the other, narrow
their abilities to task-specific manipulation data, and suffer catastrophic
forgetting of pre-trained vision-language capabilities. To bridge this gap, we
introduce InstructVLA, an end-to-end VLA model that preserves the flexible
reasoning of large vision-language models (VLMs) while delivering leading
manipulation performance. InstructVLA introduces a novel training paradigm,
Vision-Language-Action Instruction Tuning (VLA-IT), which employs multimodal
training with mixture-of-experts adaptation to jointly optimize textual
reasoning and action generation on both standard VLM corpora and a curated
650K-sample VLA-IT dataset. On in-domain SimplerEnv tasks, InstructVLA achieves
30.5% improvement over SpatialVLA. To evaluate generalization, we introduce
SimplerEnv-Instruct, an 80-task benchmark requiring closed-loop control and
high-level instruction understanding, where it outperforms a fine-tuned OpenVLA
by 92% and an action expert aided by GPT-4o by 29%. Additionally, InstructVLA
surpasses baseline VLMs on multimodal tasks and exhibits inference-time scaling
by leveraging textual reasoning to boost manipulation performance in both
simulated and real-world settings. These results demonstrate InstructVLA's
potential for bridging intuitive and steerable human-robot interaction with
efficient policy learning.

</details>


### [133] [When and Where Localization Fails: An Analysis of the Iterative Closest Point in Evolving Environment](https://arxiv.org/abs/2507.17531)
*Abdel-Raouf Dannaoui,Johann Laconte,Christophe Debain,Francois Pomerleau,Paul Checchin*

Main category: cs.RO

TL;DR: 该研究提出了一个高分辨率短期多时态数据集，评估了ICP在动态户外环境中的性能，发现点对平面ICP更优。


<details>
  <summary>Details</summary>
Motivation: 解决短期环境变化（如几天或几周内）对3D激光雷达定位的挑战，填补现有研究的空白。

Method: 使用两种迭代最近点（ICP）变体（点对点和点对平面）评估点云地图与地面真实数据的对齐精度。

Result: 点对平面ICP在稀疏特征或密集植被区域提供了更稳定和准确的配准。

Conclusion: 本研究强调了局部几何和环境变化对定位成功的影响，为设计更具弹性的机器人系统提供了见解。

Abstract: Robust relocalization in dynamic outdoor environments remains a key challenge
for autonomous systems relying on 3D lidar. While long-term localization has
been widely studied, short-term environmental changes, occurring over days or
weeks, remain underexplored despite their practical significance. To address
this gap, we present a highresolution, short-term multi-temporal dataset
collected weekly from February to April 2025 across natural and semi-urban
settings. Each session includes high-density point cloud maps, 360 deg
panoramic images, and trajectory data. Projected lidar scans, derived from the
point cloud maps and modeled with sensor-accurate occlusions, are used to
evaluate alignment accuracy against the ground truth using two Iterative
Closest Point (ICP) variants: Point-to-Point and Point-to-Plane. Results show
that Point-to-Plane offers significantly more stable and accurate registration,
particularly in areas with sparse features or dense vegetation. This study
provides a structured dataset for evaluating short-term localization
robustness, a reproducible framework for analyzing scan-to-map alignment under
noise, and a comparative evaluation of ICP performance in evolving outdoor
environments. Our analysis underscores how local geometry and environmental
variability affect localization success, offering insights for designing more
resilient robotic systems.

</details>


### [134] [Robot-mediated physical Human-Human Interaction in Neurorehabilitation: a position paper](https://arxiv.org/abs/2507.17561)
*Lorenzo Vianello,Matthew Short,Julia Manczurowsky,Emek Barış Küçüktabak,Francesco Di Tommaso,Alessia Noccaro,Laura Bandini,Shoshana Clark,Alaina Fiorenza,Francesca Lunardini,Alberto Canton,Marta Gandolla,Alessandra L. G. Pedrocchi,Emilia Ambrosini,Manuel Murie-Fernandez,Carmen B. Roman,Jesus Tornero,Natacha Leon,Andrew Sawers,Jim Patton,Domenico Formica,Nevio Luigi Tagliamonte,Georg Rauter,Kilian Baur,Fabian Just,Christopher J. Hasson,Vesna D. Novak,Jose L. Pons*

Main category: cs.RO

TL;DR: 本文提出了一种新型机器人介导的物理人-人交互框架，结合了治疗师的临床专长与机器人技术的优势，旨在改善神经康复效果。


<details>
  <summary>Details</summary>
Motivation: 传统神经康复依赖患者与物理治疗师的互动，机器人技术虽能增强物理反馈，但未能充分利用治疗师的临床专长。本文旨在整合两者的优势。

Method: 采用多学科团队（工程师、医生、物理治疗师）合作，提出统一分类法、基于社会心理学的交互框架及无缝促进自然人际互动的技术方案。

Result: 机器人介导的物理人-人交互框架成为连接传统手动治疗与康复机器人的桥梁，协调两者的优势。

Conclusion: 该框架为神经康复提供了新方向，结合治疗师的临床决策与机器人的精准性，有望提升康复效果。

Abstract: Neurorehabilitation conventionally relies on the interaction between a
patient and a physical therapist. Robotic systems can improve and enrich the
physical feedback provided to patients after neurological injury, but they
under-utilize the adaptability and clinical expertise of trained therapists. In
this position paper, we advocate for a novel approach that integrates the
therapist's clinical expertise and nuanced decision-making with the strength,
accuracy, and repeatability of robotics: Robot-mediated physical Human-Human
Interaction. This framework, which enables two individuals to physically
interact through robotic devices, has been studied across diverse research
groups and has recently emerged as a promising link between conventional manual
therapy and rehabilitation robotics, harmonizing the strengths of both
approaches. This paper presents the rationale of a multidisciplinary
team-including engineers, doctors, and physical therapists-for conducting
research that utilizes: a unified taxonomy to describe robot-mediated
rehabilitation, a framework of interaction based on social psychology, and a
technological approach that makes robotic systems seamless facilitators of
natural human-human interaction.

</details>


### [135] [KernelSOS for Global Sampling-Based Optimal Control and Estimation via Semidefinite Programming](https://arxiv.org/abs/2507.17572)
*Antoine Groudiev,Fabian Schramm,Éloïse Berthier,Justin Carpentier,Frederike Dümbgen*

Main category: cs.RO

TL;DR: KernelSOS框架结合多项式优化和核方法，有效解决控制和估计问题中的局部最小值问题，适用于非多项式和参数化问题，并能作为局部求解器的初始化方法。


<details>
  <summary>Details</summary>
Motivation: 解决控制和估计问题中的局部最小值问题，利用KernelSOS的样本特性和黑盒模拟器兼容性。

Method: 应用Kernel Sum of Squares（KernelSOS）框架，结合多项式优化和核方法的优势。

Result: KernelSOS在多项问题上表现优异，尤其适用于非多项式和非参数化问题，并能提升轨迹优化问题的求解效果。

Conclusion: KernelSOS框架在控制和估计问题中表现出色，尤其在非多项式和参数化问题中具有竞争力，并能作为局部求解器的强大初始化方法。

Abstract: Global optimization has gained attraction over the past decades, thanks to
the development of both theoretical foundations and efficient numerical
routines to cope with optimization problems of various complexities. Among
recent methods, Kernel Sum of Squares (KernelSOS) appears as a powerful
framework, leveraging the potential of sum of squares methods from the
polynomial optimization community with the expressivity of kernel methods
widely used in machine learning. This paper applies the kernel sum of squares
framework for solving control and estimation problems, which exhibit poor local
minima. We demonstrate that KernelSOS performs well on a selection of problems
from both domains. In particular, we show that KernelSOS is competitive with
other sum of squares approaches on estimation problems, while being applicable
to non-polynomial and non-parametric formulations. The sample-based nature of
KernelSOS allows us to apply it to trajectory optimization problems with an
integrated simulator treated as a black box, both as a standalone method and as
a powerful initialization method for local solvers, facilitating the discovery
of better solutions.

</details>


### [136] [Event Detection for Active Lower Limb Prosthesis](https://arxiv.org/abs/2507.17649)
*J. D. Clark,P. Ellison*

Main category: cs.RO

TL;DR: 研究通过双髁膝关节设计探讨交叉韧带拉伸对事件检测的作用，发现特定步态阶段的拉伸特征可用于提升动力假肢的事件预测准确性。


<details>
  <summary>Details</summary>
Motivation: 自然膝关节运动复杂，简化会导致部分行为丢失，研究旨在探讨交叉韧带拉伸在事件检测中的作用。

Method: 采用双髁膝关节设计，并通过模拟前交叉韧带和后交叉韧带的约束，利用LVDT记录韧带拉伸数据，在跑步机上以3种速度采集数据。

Result: 研究发现交叉韧带拉伸存在速度依赖性，且在步态周期的特定阶段（如前交叉韧带在80%、后交叉韧带在5%）表现显著，这些静态事件可作为初始接触或足平预测的指标。

Conclusion: 使用双髁膝关节设计可以提高步态周期中的事件检测准确性，从而提升动力假肢控制器的精确度。

Abstract: Accurate event detection is key to the successful design of semi-passive and
powered prosthetics. Kinematically, the natural knee is complex, with
translation and rotation components that have a substantial impact on gait
characteristics. When simplified to a pin joint, some of this behaviour is
lost. This study investigates the role of cruciate ligament stretch in event
detection. A bicondylar knee design was used, constrained by analogues of the
anterior and posterior cruciate ligaments. This offers the ability to
characterize knee kinematics by the stretch of the ligaments. The ligament
stretch was recorded using LVDTs parallel to the ligaments of the Russell knee
on a bent knee crutch. Which was used to capture data on a treadmill at 3
speeds. This study finds speed dependence within the stretch of the cruciate
ligaments, prominently around 5\% and 80\% of the gait cycle for the posterior
and anterior. The cycle profile remains consistent with speed; therefore, other
static events such as the turning point feature at around 90\% and 95\% of the
cycle, for the posterior and anterior, respectively, could be used as a
predictive precursor for initial contact. Likewise at 90\% and 95\%, another
pair of turning points that in this case could be used to predict foot flat.
This concludes that the use of a bicondylar knee design could improve the
detection of events during the gait cycle, and therefore could increase the
accuracy of subsequent controllers for powered prosthetics.

</details>


### [137] [Safety Assurance for Quadrotor Kinodynamic Motion Planning](https://arxiv.org/abs/2507.17679)
*Theodoros Tavoulareas,Marzia Cescon*

Main category: cs.RO

TL;DR: 本文提出了一种结合安全保证的无人机运动规划方法，通过分层设计确保操作安全，并在模拟环境中验证。


<details>
  <summary>Details</summary>
Motivation: 随着无人机在民用领域的广泛应用，确保其安全运行至关重要。现有运动规划技术虽能生成无碰撞轨迹，但未充分考虑系统安全操作区域，可能导致安全约束违反。

Method: 首先使用基于采样的几何规划器确定高层无碰撞路径，然后设计了一个低层安全保证过滤器，为线性二次调节器（LQR）的控制输入提供安全保证。

Result: 在模拟环境中使用Crazyflie 2.0无人机模型验证了所提方法的有效性。

Conclusion: 本文提出了一种结合运行时安全保证的动力学运动规划方法，有效满足了无人机系统的操作约束，并在模拟环境中验证了其有效性。

Abstract: Autonomous drones have gained considerable attention for applications in
real-world scenarios, such as search and rescue, inspection, and delivery. As
their use becomes ever more pervasive in civilian applications, failure to
ensure safe operation can lead to physical damage to the system, environmental
pollution, and even loss of human life. Recent work has demonstrated that
motion planning techniques effectively generate a collision-free trajectory
during navigation. However, these methods, while creating the motion plans, do
not inherently consider the safe operational region of the system, leading to
potential safety constraints violation during deployment. In this paper, we
propose a method that leverages run time safety assurance in a kinodynamic
motion planning scheme to satisfy the system's operational constraints. First,
we use a sampling-based geometric planner to determine a high-level
collision-free path within a user-defined space. Second, we design a low-level
safety assurance filter to provide safety guarantees to the control input of a
Linear Quadratic Regulator (LQR) designed with the purpose of trajectory
tracking. We demonstrate our proposed approach in a restricted 3D simulation
environment using a model of the Crazyflie 2.0 drone.

</details>


### [138] [CA-Cut: Crop-Aligned Cutout for Data Augmentation to Learn More Robust Under-Canopy Navigation](https://arxiv.org/abs/2507.17727)
*Robel Mamo,Taeyeong Choi*

Main category: cs.RO

TL;DR: CA-Cut 是一种新型数据增强方法，通过偏向作物行的掩码分布提升视觉导航模型的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有数据增强技术在复杂冠层环境下表现不佳，需要一种更有效的方法来模拟遮挡并提升模型鲁棒性。

Method: 提出了一种新颖的数据增强方法 CA-Cut，通过在输入图像中随机掩码作物行周围的区域，以鼓励模型捕捉高层上下文特征。

Result: 实验表明，CA-Cut 显著提升了预测准确性，在公共玉米田数据集上实现了高达 36.9% 的预测误差降低。

Conclusion: Crop-Aligned Cutout (CA-Cut) 是一种有效的数据增强方法，通过模拟遮挡并偏向作物行分布，显著提升了视觉导航中语义关键点预测的准确性和泛化能力。

Abstract: State-of-the-art visual under-canopy navigation methods are designed with
deep learning-based perception models to distinguish traversable space from
crop rows. While these models have demonstrated successful performance, they
require large amounts of training data to ensure reliability in real-world
field deployment. However, data collection is costly, demanding significant
human resources for in-field sampling and annotation. To address this
challenge, various data augmentation techniques are commonly employed during
model training, such as color jittering, Gaussian blur, and horizontal flip, to
diversify training data and enhance model robustness. In this paper, we
hypothesize that utilizing only these augmentation techniques may lead to
suboptimal performance, particularly in complex under-canopy environments with
frequent occlusions, debris, and non-uniform spacing of crops. Instead, we
propose a novel augmentation method, so-called Crop-Aligned Cutout (CA-Cut)
which masks random regions out in input images that are spatially distributed
around crop rows on the sides to encourage trained models to capture high-level
contextual features even when fine-grained information is obstructed. Our
extensive experiments with a public cornfield dataset demonstrate that
masking-based augmentations are effective for simulating occlusions and
significantly improving robustness in semantic keypoint predictions for visual
navigation. In particular, we show that biasing the mask distribution toward
crop rows in CA-Cut is critical for enhancing both prediction accuracy and
generalizability across diverse environments achieving up to a 36.9% reduction
in prediction error. In addition, we conduct ablation studies to determine the
number of masks, the size of each mask, and the spatial distribution of masks
to maximize overall performance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [139] [Controllable Video Generation: A Survey](https://arxiv.org/abs/2507.16869)
*Yue Ma,Kunyu Feng,Zhongyuan Hu,Xinyu Wang,Yucheng Wang,Mingzhe Zheng,Xuanhua He,Chenyang Zhu,Hongyu Liu,Yingqing He,Zeyu Wang,Zhifeng Li,Xiu Li,Wei Liu,Dan Xu,Linfeng Zhang,Qifeng Chen*

Main category: cs.GR

TL;DR: 本调查系统回顾了可控视频生成的理论与最新进展，探讨了多模态控制信号在视频扩散模型中的应用，并分类总结了现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成内容（AIGC）的快速发展，视频生成成为其最具活力和影响力的子领域之一。现有基础模型多基于文本到视频生成，但文本提示往往不足以表达复杂、多模态和细粒度的用户需求，因此需要探索非文本条件的集成以实现更可控的视频合成。

Method: 通过分析视频扩散模型中的控制机制，探讨了如何将不同类型的条件（如相机运动、深度图和人体姿态）融入去噪过程以指导生成。

Result: 调查总结了现有方法，并根据控制信号类型（单条件生成、多条件生成和通用可控生成）进行了分类。

Conclusion: 本调查系统回顾了可控视频生成的理论基础和最新进展，强调了多模态和细粒度控制信号在提升视频生成灵活性和实用性中的重要性。

Abstract: With the rapid development of AI-generated content (AIGC), video generation
has emerged as one of its most dynamic and impactful subfields. In particular,
the advancement of video generation foundation models has led to growing demand
for controllable video generation methods that can more accurately reflect user
intent. Most existing foundation models are designed for text-to-video
generation, where text prompts alone are often insufficient to express complex,
multi-modal, and fine-grained user requirements. This limitation makes it
challenging for users to generate videos with precise control using current
models. To address this issue, recent research has explored the integration of
additional non-textual conditions, such as camera motion, depth maps, and human
pose, to extend pretrained video generation models and enable more controllable
video synthesis. These approaches aim to enhance the flexibility and practical
applicability of AIGC-driven video generation systems. In this survey, we
provide a systematic review of controllable video generation, covering both
theoretical foundations and recent advances in the field. We begin by
introducing the key concepts and commonly used open-source video generation
models. We then focus on control mechanisms in video diffusion models,
analyzing how different types of conditions can be incorporated into the
denoising process to guide generation. Finally, we categorize existing methods
based on the types of control signals they leverage, including single-condition
generation, multi-condition generation, and universal controllable generation.
For a complete list of the literature on controllable video generation
reviewed, please visit our curated repository at
https://github.com/mayuelala/Awesome-Controllable-Video-Generation.

</details>


### [140] [StreamME: Simplify 3D Gaussian Avatar within Live Stream](https://arxiv.org/abs/2507.17029)
*Luchuan Song,Yang Zhou,Zhan Xu,Yi Zhou,Deepali Aneja,Chenliang Xu*

Main category: cs.GR

TL;DR: StreamME是一种实时3D头像重建方法，基于3D高斯喷洒技术，通过优化点云分布实现快速训练，适用于VR和在线会议等场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统3D头像重建方法依赖预缓存数据、速度慢的问题，StreamME旨在实现实时视频流的同步记录与重建，保护面部隐私并减少通信带宽。

Method: StreamME基于3D高斯喷洒（3DGS）技术，消除了对MLP的依赖，仅依赖几何结构，并引入了基于主点的简化策略，优化了点云数量和分布。

Result: StreamME实现了快速的3D头像重建，显著提升了面部表情适应速度，并优化了点云分布，保持了渲染质量。

Conclusion: StreamME通过实时3D头像重建技术，显著提升了面部表情适应速度，并优化了点云分布，保持了渲染质量的同时减少了对通信带宽的需求，适用于VR系统和在线会议等下游应用。

Abstract: We propose StreamME, a method focuses on fast 3D avatar reconstruction. The
StreamME synchronously records and reconstructs a head avatar from live video
streams without any pre-cached data, enabling seamless integration of the
reconstructed appearance into downstream applications. This exceptionally fast
training strategy, which we refer to as on-the-fly training, is central to our
approach. Our method is built upon 3D Gaussian Splatting (3DGS), eliminating
the reliance on MLPs in deformable 3DGS and relying solely on geometry, which
significantly improves the adaptation speed to facial expression. To further
ensure high efficiency in on-the-fly training, we introduced a simplification
strategy based on primary points, which distributes the point clouds more
sparsely across the facial surface, optimizing points number while maintaining
rendering quality. Leveraging the on-the-fly training capabilities, our method
protects the facial privacy and reduces communication bandwidth in VR system or
online conference. Additionally, it can be directly applied to downstream
application such as animation, toonify, and relighting. Please refer to our
project page for more details: https://songluchuan.github.io/StreamME/.

</details>


### [141] [GhostUMAP2: Measuring and Analyzing (r,d)-Stability of UMAP](https://arxiv.org/abs/2507.17174)
*Myeongwon Jung,Takanori Fujiwara,Jaemin Jo*

Main category: cs.GR

TL;DR: 该论文提出(r,d)-稳定性框架，通过‘ghosts’和自适应丢弃方案优化UMAP投影的随机性问题，减少计算时间并提高稳定性，附带可视化工具和真实数据集验证。


<details>
  <summary>Details</summary>
Motivation: UMAP的随机优化过程对结果的影响尚未充分研究，导致投影结果不稳定，数据点的位置更多由随机性而非邻近结构决定。为了解决这一问题，作者提出了(r,d)-稳定性框架。

Method: 通过引入‘ghosts’（数据点的副本）来模拟随机性对数据点投影位置的影响，定义(r,d)-稳定性来衡量投影的稳定性。开发了一种自适应丢弃方案以减少计算时间，并设计了一个可视化工具用于交互式分析。

Result: 自适应丢弃方案将运行时间减少了60%，同时保留了约90%的不稳定点。框架在真实数据集上验证了有效性，并提供了使用指南。

Conclusion: 该论文提出了一个名为(r,d)-稳定性的框架，用于分析UMAP投影中数据点的随机定位问题，并通过引入‘ghosts’概念和自适应丢弃方案，显著提高了计算效率。此外，还提供了一个可视化工具来交互式探索数据点的稳定性，并展示了该框架在真实数据集上的有效性。

Abstract: Despite the widespread use of Uniform Manifold Approximation and Projection
(UMAP), the impact of its stochastic optimization process on the results
remains underexplored. We observed that it often produces unstable results
where the projections of data points are determined mostly by chance rather
than reflecting neighboring structures. To address this limitation, we
introduce (r,d)-stability to UMAP: a framework that analyzes the stochastic
positioning of data points in the projection space. To assess how stochastic
elements, specifically initial projection positions and negative sampling,
impact UMAP results, we introduce "ghosts", or duplicates of data points
representing potential positional variations due to stochasticity. We define a
data point's projection as (r,d)-stable if its ghosts perturbed within a circle
of radius r in the initial projection remain confined within a circle of radius
d for their final positions. To efficiently compute the ghost projections, we
develop an adaptive dropping scheme that reduces a runtime up to 60% compared
to an unoptimized baseline while maintaining approximately 90% of unstable
points. We also present a visualization tool that supports the interactive
exploration of the (r,d)-stability of data points. Finally, we demonstrate the
effectiveness of our framework by examining the stability of projections of
real-world datasets and present usage guidelines for the effective use of our
framework.

</details>


### [142] [A Scientist Question: Research on the Impact of Super Structured Quadrilateral Meshes on Convergence and Accuracy of Finite Element Analysis](https://arxiv.org/abs/2507.17184)
*Hui Zhao*

Main category: cs.GR

TL;DR: 本文提出研究超结构四边形网格整体排列结构对有限元计算收敛性的影响，采用现代几何拓扑理论设计可控网格，解决当前依赖‘经验’的问题。


<details>
  <summary>Details</summary>
Motivation: 当前行业和学术界在有限元计算中，网格生成的方法和质量直接影响计算的收敛性和准确性。然而，现有研究主要关注四边形和六面体的局部质量，缺乏对整体全局排列结构的系统性研究。

Method: 通过应用大量现代二维和三维几何拓扑理论（如模空间、Teichmüller空间、调和叶状结构、动力系统、曲面映射、亚纯二次微分等），生成和设计具有可控整体排列结构的超结构四边形网格。

Result: 研究结果表明，通过探索超结构四边形网格的整体全局排列结构，可以明确判断哪些网格生成全局排列能确保有限元计算的收敛性。

Conclusion: 本文提出了一种全新的研究方向，即研究超结构四边形网格的整体全局排列结构对有限元计算收敛性和准确性的影响，为解决当前行业和学术界在网格生成阶段严重依赖‘经验’的非严谨状态提供了理论依据。

Abstract: In the current practices of both industry and academia, the convergence and
accuracy of finite element calculations are closely related to the methods and
quality of mesh generation. For years, the research on high-quality mesh
generation in the domestic academic field has mainly referred to the local
quality of quadrilaterals and hexahedrons approximating that of squares and
cubes. The main contribution of this paper is to propose a brand-new research
direction and content: it is necessary to explore and study the influence of
the overall global arrangement structure and pattern of super structured
quadrilateral meshes on the convergence and calculation accuracy of finite
element calculations. Through the research in this new field, it can help solve
the non-rigorous state of serious reliance on "experience" in the mesh
generation stage during simulation in the current industry and academia, and
make clear judgments on which global arrangements of mesh generation can ensure
the convergence of finite element calculations. In order to generate and design
super-structured quadrilateral meshes with controllable overall arrangement
structures, a large number of modern two-dimensional and three-dimensional
geometric topology theories are required, such as moduli space, Teichm\"uller
space, harmonic foliations, dynamical systems, surface mappings, meromorphic
quadratic differentials, surface mappings, etc.

</details>


### [143] [Visualization-Driven Illumination for Density Plots](https://arxiv.org/abs/2507.17265)
*Xin Chen,Yunhai Wang,Huaiwei Bao,Kecheng Lu,Jaemin Jo,Chi-Wing Fu,Jean-Daniel Fekete*

Main category: cs.GR

TL;DR: 提出了一种新型密度图光照模型，解决了颜色失真和细节隐藏问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 散点图和点密度图在可视化大规模离散点样本时存在过度绘制问题，而现有密度图的光照模型可能导致颜色失真和低密度区域细节丢失，阻碍了密度值的查找、比较和异常值检测。

Method: 论文提出了（i）一个可视化驱动光照模型，支持密度图特定分析任务；（ii）一种新的图像合成技术，减少图像阴影与颜色编码密度值之间的干扰。

Result: 通过定量研究、控制实验和两个案例研究，验证了该技术在12个数据集（最多200万个数据点样本）中的有效性。

Conclusion: 该论文提出了一种新颖的可视化驱动光照模型，有效增强了密度图的可视化效果，解决了现有技术在高低密度区域中的细节显示和颜色失真问题。

Abstract: We present a novel visualization-driven illumination model for density plots,
a new technique to enhance density plots by effectively revealing the detailed
structures in high- and medium-density regions and outliers in low-density
regions, while avoiding artifacts in the density field's colors. When
visualizing large and dense discrete point samples, scatterplots and dot
density maps often suffer from overplotting, and density plots are commonly
employed to provide aggregated views while revealing underlying structures.
Yet, in such density plots, existing illumination models may produce color
distortion and hide details in low-density regions, making it challenging to
look up density values, compare them, and find outliers. The key novelty in
this work includes (i) a visualization-driven illumination model that
inherently supports density-plot-specific analysis tasks and (ii) a new image
composition technique to reduce the interference between the image shading and
the color-encoded density values. To demonstrate the effectiveness of our
technique, we conducted a quantitative study, an empirical evaluation of our
technique in a controlled study, and two case studies, exploring twelve
datasets with up to two million data point samples.

</details>


### [144] [Temporal Smoothness-Aware Rate-Distortion Optimized 4D Gaussian Splatting](https://arxiv.org/abs/2507.17336)
*Hyeongmin Lee,Kyungjune Baek*

Main category: cs.GR

TL;DR: 本文提出了一种针对4D高斯泼溅的RD优化压缩框架，通过小波变换显著提升存储效率，实现高达91倍的压缩比，适用于多种场景。


<details>
  <summary>Details</summary>
Motivation: 4D高斯泼溅（4DGS）在表示体积视频时存在大量高斯分布、时间冗余和缺乏熵感知压缩框架的问题，导致存储需求大，限制了实际部署和数据传输效率。

Method: 基于全显式动态高斯泼溅（Ex4DGS）作为基线，采用小波变换来增强存储效率，而非独立存储每点的运动轨迹。

Result: 实验表明，该方法实现了高达91倍的压缩比，同时保持了高视觉保真度。

Conclusion: 本文提出的RD优化压缩框架显著提升了4D高斯泼溅（4DGS）的存储效率，实现了高达91倍的压缩比，同时保持高视觉保真度，适用于从边缘设备到高性能环境的各种场景。

Abstract: Dynamic 4D Gaussian Splatting (4DGS) effectively extends the high-speed
rendering capabilities of 3D Gaussian Splatting (3DGS) to represent volumetric
videos. However, the large number of Gaussians, substantial temporal
redundancies, and especially the absence of an entropy-aware compression
framework result in large storage requirements. Consequently, this poses
significant challenges for practical deployment, efficient edge-device
processing, and data transmission. In this paper, we introduce a novel
end-to-end RD-optimized compression framework tailored for 4DGS, aiming to
enable flexible, high-fidelity rendering across varied computational platforms.
Leveraging Fully Explicit Dynamic Gaussian Splatting (Ex4DGS), one of the
state-of-the-art 4DGS methods, as our baseline, we start from the existing 3DGS
compression methods for compatibility while effectively addressing additional
challenges introduced by the temporal axis. In particular, instead of storing
motion trajectories independently per point, we employ a wavelet transform to
reflect the real-world smoothness prior, significantly enhancing storage
efficiency. This approach yields significantly improved compression ratios and
provides a user-controlled balance between compression efficiency and rendering
quality. Extensive experiments demonstrate the effectiveness of our method,
achieving up to 91x compression compared to the original Ex4DGS model while
maintaining high visual fidelity. These results highlight the applicability of
our framework for real-time dynamic scene rendering in diverse scenarios, from
resource-constrained edge devices to high-performance environments.

</details>


### [145] [Parametric Integration with Neural Integral Operators](https://arxiv.org/abs/2507.17440)
*Christoph Schied,Alexander Keller*

Main category: cs.GR

TL;DR: 提出了一种在材质着色前去噪的方法（MAD），通过神经网络近似光传输积分，实现实时、高效的噪声消除。


<details>
  <summary>Details</summary>
Motivation: 实时渲染中采样预算有限导致图像噪声，传统去噪方法在着色后处理效果不佳。

Method: 利用神经网络近似光传输积分算子，进行参数化积分，实现在材质着色前去噪。

Result: 实现了实时、单帧数据需求、与现有去噪技术无缝集成的材质无关去噪方法，且训练高效。

Conclusion: 该方法通过去噪处理在材质着色前提升图像质量，实现了材质无关的去噪（MAD），并通过神经网络近似光传输积分算子，实现了实时渲染且易于与现有技术集成。

Abstract: Real-time rendering imposes strict limitations on the sampling budget for
light transport simulation, often resulting in noisy images. However, denoisers
have demonstrated that it is possible to produce noise-free images through
filtering. We enhance image quality by removing noise before material shading,
rather than filtering already shaded noisy images. This approach allows for
material-agnostic denoising (MAD) and leverages machine learning by
approximating the light transport integral operator with a neural network,
effectively performing parametric integration with neural operators. Our method
operates in real-time, requires data from only a single frame, seamlessly
integrates with existing denoisers and temporal anti-aliasing techniques, and
is efficient to train. Additionally, it is straightforward to incorporate with
physically based rendering algorithms.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [146] [Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots](https://arxiv.org/abs/2507.17049)
*Pablo Valle,Chengjie Lu,Shaukat Ali,Aitor Arrieta*

Main category: cs.SE

TL;DR: 本文为VLA模型提出质量与不确定性指标，实证显示其与专家评估相关性强，可弥补仅用成功率评估的不足。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型评估仅依赖任务成功率，无法捕捉执行质量和模型决策信心，需开发更全面的评估指标。

Method: 设计了八种不确定性指标和五种质量指标，并通过大规模实证研究（908次成功任务执行）评估其有效性，结合人类专家标注分析指标与专家判断的相关性。

Result: 多个指标与人类专家评估呈现中到强相关性，部分指标能区分高、中、低质量执行，甚至无测试预言时仍有效。

Conclusion: 当前仅依赖二元成功率（成功/失败）的评估方法存在不足，本文提出的质量与不确定性指标为VLA模型的实时监控和自适应增强提供了改进方向。

Abstract: Visual Language Action (VLA) models are a multi-modal class of Artificial
Intelligence (AI) systems that integrate visual perception, natural language
understanding, and action planning to enable agents to interpret their
environment, comprehend instructions, and perform embodied tasks autonomously.
Recently, significant progress has been made to advance this field. These kinds
of models are typically evaluated through task success rates, which fail to
capture the quality of task execution and the mode's confidence in its
decisions. In this paper, we propose eight uncertainty metrics and five quality
metrics specifically designed for VLA models for robotic manipulation tasks. We
assess their effectiveness through a large-scale empirical study involving 908
successful task executions from three state-of-the-art VLA models across four
representative robotic manipulation tasks. Human domain experts manually
labeled task quality, allowing us to analyze the correlation between our
proposed metrics and expert judgments. The results reveal that several metrics
show moderate to strong correlation with human assessments, highlighting their
utility for evaluating task quality and model confidence. Furthermore, we found
that some of the metrics can discriminate between high-, medium-, and
low-quality executions from unsuccessful tasks, which can be interesting when
test oracles are not available. Our findings challenge the adequacy of current
evaluation practices that rely solely on binary success rates and pave the way
for improved real-time monitoring and adaptive enhancement of VLA-enabled
robotic systems.

</details>


### [147] [Assessing Reliability of Statistical Maximum Coverage Estimators in Fuzzing](https://arxiv.org/abs/2507.17093)
*Danushka Liyanage,Nelum Attanayake,Zijian Luo,Rahul Gopinath*

Main category: cs.SE

TL;DR: 通过合成和真实程序验证可达性估计器的可靠性，提出评估框架和协议。


<details>
  <summary>Details</summary>
Motivation: 模糊测试通常以覆盖率为指导，但静态可达性分析的上界估计往往不准确。生物统计学的物种丰富度估计方法被提出，但缺乏可靠的基准数据限制了其准确性评估。

Method: 1. 提出一个评估框架，通过合成生成具有复杂控制流的大型程序，提供明确的标签和评估基础。2. 在真实世界基准上通过调整采样单元大小进行可靠性检查，理论上不应影响估计结果。

Result: 研究通过合成和真实世界基准的双重验证，回答了当前可达性估计器是否可靠的问题，并定义了未来改进的评估协议。

Conclusion: 本研究通过提出一个评估框架和可靠性检查方法，验证了当前可达性估计器的可靠性，并为未来改进提供了评估协议。

Abstract: Background: Fuzzers are often guided by coverage, making the estimation of
maximum achievable coverage a key concern in fuzzing. However, achieving 100%
coverage is infeasible for most real-world software systems, regardless of
effort. While static reachability analysis can provide an upper bound, it is
often highly inaccurate. Recently, statistical estimation methods based on
species richness estimators from biostatistics have been proposed as a
potential solution. Yet, the lack of reliable benchmarks with labeled ground
truth has limited rigorous evaluation of their accuracy.
  Objective: This work examines the reliability of reachability estimators from
two axes: addressing the lack of labeled ground truth and evaluating their
reliability on real-world programs.
  Methods: (1) To address the challenge of labeled ground truth, we propose an
evaluation framework that synthetically generates large programs with complex
control flows, ensuring well-defined reachability and providing ground truth
for evaluation. (2) To address the criticism from use of synthetic benchmarks,
we adapt a reliability check for reachability estimators on real-world
benchmarks without labeled ground truth -- by varying the size of sampling
units, which, in theory, should not affect the estimate.
  Results: These two studies together will help answer the question of whether
current reachability estimators are reliable, and defines a protocol to
evaluate future improvements in reachability estimation.

</details>


### [148] [Can LLMs Write CI? A Study on Automatic Generation of GitHub Actions Configurations](https://arxiv.org/abs/2507.17165)
*Taher A. Ghaleb,Dulina Rathnayake*

Main category: cs.SE

TL;DR: 论文研究了六种LLM在生成GitHub Actions配置时的表现，发现零样本提示的相似度为69%，但完美匹配率低，揭示了LLM在CI配置生成中的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于YAML配置文件的编写繁琐且容易出错，而LLM在此类任务中的应用尚未充分探索，因此有必要研究LLM在生成CI配置方面的能力。

Method: 论文评估了六种LLM（包括三种通用基础模型和三种代码预训练模型）在从自然语言描述生成GitHub Actions配置的能力。

Result: 零样本提示的生成结果与真实配置的相似度最高可达69%，但仅有3%完全匹配。代码预训练模型在YAML任务中表现略逊于通用模型。

Conclusion: 论文的研究为改进LLM与配置语言的匹配提供了见解，并为未来CI自动化和工具支持的努力提供了指导。

Abstract: Continuous Integration (CI) services, such as GitHub Actions, require
developers to write YAML-based configurations, which can be tedious and
error-prone. Despite the increasing use of Large Language Models (LLMs) to
automate software engineering tasks, their ability to generate CI
configurations remains underexplored. This paper presents a preliminary study
evaluating six LLMs for generating GitHub Actions configurations from natural
language descriptions. We assess three general-purpose foundation models
(GPT-4o, Llama, and Gemma) and three code-pretrained models (GPT-4.1, Code
Llama, and CodeGemma). We also introduce the first labeled dataset of its kind,
constructed from GitHub Actions documentation, pairing descriptions with
corresponding best-practice YAML configurations. Zero-shot prompting achieves
up to 69% similarity with the ground truth, with only 3% perfect matches.
Code-pretrained models slightly underperform compared to general-purpose ones
in YAML-based CI tasks, revealing LLM limitations for CI configuration
generation. Analyzing GPT-4o outputs reveals issues like missing or renamed
steps, misinterpreted descriptions, and unnecessary additions that may affect
structural and contextual correctness, indicating a gap between generation
quality and the precision required for executable CI configurations. Our
research offers insights for improving LLM alignment with configuration
languages and guiding future efforts on CI automation and tooling support.

</details>


### [149] [On the Feasibility of Quantum Unit Testing](https://arxiv.org/abs/2507.17235)
*Andriy Miranskyy,José Campos,Anila Mjeda,Lei Zhang,Ignacio García Rodríguez de Guzmán*

Main category: cs.SE

TL;DR: 该研究比较了量子电路的传统统计测试与量子中心测试，发现后者（如Statevector和Inverse测试）在精确性和效率上更优，有助于量子软件的可靠测试。


<details>
  <summary>Details</summary>
Motivation: 量子软件复杂度的增加给软件验证和验证带来了挑战，尤其是在单元测试方面，需要更有效的测试方法。

Method: 通过实证研究和对1,796,880个突变量子电路的详细分析，比较了传统统计方法与专门为量子电路设计的测试方法（如Statevector测试、Swap测试和Inverse测试）。

Result: 量子中心测试在检测量子电路预期与实际状态之间的细微差异方面表现更优，且所需测量次数更少，可靠性更高。

Conclusion: 量子中心测试（特别是Statevector测试和Inverse测试）在精确性和效率上具有明显优势，减少了假阳性和假阴性，为量子软件的测试提供了更可靠和可扩展的策略。

Abstract: The increasing complexity of quantum software presents significant challenges
for software verification and validation, particularly in the context of unit
testing. This work presents a comprehensive study on quantum-centric unit
tests, comparing traditional statistical approaches with tests specifically
designed for quantum circuits. These include tests that run only on a classical
computer, such as the Statevector test, as well as those executable on quantum
hardware, such as the Swap test and the novel Inverse test. Through an
empirical study and detailed analysis on 1,796,880 mutated quantum circuits, we
investigate (a) each test's ability to detect subtle discrepancies between the
expected and actual states of a quantum circuit, and (b) the number of
measurements required to achieve high reliability. The results demonstrate that
quantum-centric tests, particularly the Statevector test and the Inverse test,
provide clear advantages in terms of precision and efficiency, reducing both
false positives and false negatives compared to statistical tests. This work
contributes to the development of more robust and scalable strategies for
testing quantum software, supporting the future adoption of fault-tolerant
quantum computers and promoting more reliable practices in quantum software
engineering.

</details>


### [150] [Understanding Prompt Programming Tasks and Questions](https://arxiv.org/abs/2507.17264)
*Jenny T. Liang,Chenyang Yang,Agnia Sergeyuk,Travis D. Breaux,Brad A. Myers*

Main category: cs.SE

TL;DR: 研究分析了提示编程的任务和问题，发现当前工具支持不足，提出了改进机会。


<details>
  <summary>Details</summary>
Motivation: 随着提示编程在研究和商业工具中的普及，目前尚不清楚提示程序员的需求是否得到充分满足。

Method: 通过访谈16位提示程序员、观察8位开发者修改提示的过程，并对50位开发者进行调查，开发了一个包含25个任务和51个问题的分类法。然后将该分类法与48种研究和商业工具进行比较。

Result: 研究发现提示编程支持不足：所有任务均需手动完成，51个问题中有16个（包括大多数最重要的问题）仍未解答。

Conclusion: 提示编程工具目前支持不足，所有任务仍需手动完成，且许多重要问题未得到解答。文章提出了改进提示编程工具的重要机会。

Abstract: Prompting foundation models (FMs) like large language models (LLMs) have
enabled new AI-powered software features (e.g., text summarization) that
previously were only possible by fine-tuning FMs. Now, developers are embedding
prompts in software, known as prompt programs. The process of prompt
programming requires the developer to make many changes to their prompt. Yet,
the questions developers ask to update their prompt is unknown, despite the
answers to these questions affecting how developers plan their changes. With
the growing number of research and commercial prompt programming tools, it is
unclear whether prompt programmers' needs are being adequately addressed. We
address these challenges by developing a taxonomy of 25 tasks prompt
programmers do and 51 questions they ask, measuring the importance of each task
and question. We interview 16 prompt programmers, observe 8 developers make
prompt changes, and survey 50 developers. We then compare the taxonomy with 48
research and commercial tools. We find that prompt programming is not
well-supported: all tasks are done manually, and 16 of the 51 questions --
including a majority of the most important ones -- remain unanswered. Based on
this, we outline important opportunities for prompt programming tools.

</details>


### [151] [Lessons from a Big-Bang Integration: Challenges in Edge Computing and Machine Learning](https://arxiv.org/abs/2507.17270)
*Alessandro Aneggi,Andrea Janes*

Main category: cs.SE

TL;DR: 论文分析了一个分布式实时分析系统项目的失败原因，指出大爆炸集成方法和沟通不畅是主要问题，建议早期模拟部署和结构化集成周期。


<details>
  <summary>Details</summary>
Motivation: 分析一个为期一年的项目，该项目专注于使用边缘计算和机器学习构建分布式实时分析系统，旨在识别项目失败的原因并提出改进建议。

Method: 通过根因分析，研究识别了技术和组织障碍，包括沟通不畅、缺乏早期集成测试以及对自上而下规划的抵制。还考虑了心理因素，如对完全开发组件的偏好超过模拟。

Result: 项目集成努力仅实现了六分钟的系统功能，远低于预期的40分钟。研究发现技术和组织障碍是主要原因。

Conclusion: 论文主张通过早期模拟部署、强化沟通基础设施和采用自上而下的思维来管理复杂性和降低风险，同时指出传统敏捷方法在此类项目中的局限性，并提出了模拟驱动工程和结构化集成周期作为未来成功的关键推动因素。

Abstract: This experience report analyses a one year project focused on building a
distributed real-time analytics system using edge computing and machine
learning. The project faced critical setbacks due to a big-bang integration
approach, where all components developed by multiple geographically dispersed
partners were merged at the final stage. The integration effort resulted in
only six minutes of system functionality, far below the expected 40 minutes.
Through root cause analysis, the study identifies technical and organisational
barriers, including poor communication, lack of early integration testing, and
resistance to topdown planning. It also considers psychological factors such as
a bias toward fully developed components over mockups. The paper advocates for
early mock based deployment, robust communication infrastructures, and the
adoption of topdown thinking to manage complexity and reduce risk in reactive,
distributed projects. These findings underscore the limitations of traditional
Agile methods in such contexts and propose simulation-driven engineering and
structured integration cycles as key enablers for future success.

</details>


### [152] [Seed&Steer: Guiding Large Language Models with Compilable Prefix and Branch Signals for Unit Test Generation](https://arxiv.org/abs/2507.17271)
*Shuaiyu Zhou,Zhengran Zeng,Xiaoling Zhou,Rui Xie,Shikun Zhang,Wei Ye*

Main category: cs.SE

TL;DR: Seed&Steer通过结合传统测试工具和LLM能力，显著提升单元测试的编译通过率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 重新审视基于LLM的单元测试生成，解耦前缀生成和断言生成，以解决编译成功率和测试覆盖率问题。

Method: Seed&Steer结合传统单元测试工具（如EvoSuite）生成高编译通过率的方法调用作为种子，引导LLM构建有效测试上下文；并通过分支提示帮助LLM探索多样化执行路径生成高覆盖率断言。

Result: Seed&Steer在五个真实Java项目上评估，编译通过率提升约7%，分支和行覆盖率达到约73%，覆盖率提升1.09*至1.26*。

Conclusion: Seed&Steer方法显著提高了LLM生成的单元测试的编译通过率和覆盖率，为未来研究和实际应用提供了有价值的工具和数据集。

Abstract: Unit tests play a vital role in the software development lifecycle. Recent
advances in Large Language Model (LLM)-based approaches have significantly
improved automated test generation, garnering attention from both academia and
industry. We revisit LLM-based unit test generation from a novel perspective by
decoupling prefix generation and assertion generation. To characterize their
respective challenges, we define Initialization Complexity and adopt Cyclomatic
Complexity to measure the difficulty of prefix and assertion generation,
revealing that the former primarily affects compilation success, while the
latter influences test coverage. To address these challenges, we propose
Seed&Steer, a two-step approach that combines traditional unit testing
techniques with the capabilities of large language models. Seed&Steer leverages
conventional unit testing tools (e.g., EvoSuite) to generate method invocations
with high compilation success rates, which serve as seeds to guide LLMs in
constructing effective test contexts. It then introduces branching cues to help
LLMs explore diverse execution paths (e.g., normal, boundary, and exception
cases) and generate assertions with high coverage. We evaluate Seed&Steer on
five real-world Java projects against state-of-the-art baselines. Results show
that Seed&Steer improves the compilation pass rate by approximately 7%,
successfully compiling 792 and 887 previously failing cases on two LLMs. It
also achieves up to ~73% branch and line coverage across focal methods of
varying complexity, with coverage improvements ranging from 1.09* to 1.26*. Our
code, dataset, and experimental scripts will be publicly released to support
future research and reproducibility.

</details>


### [153] [Data Virtualization for Machine Learning](https://arxiv.org/abs/2507.17293)
*Saiful Khan,Joyraj Chakraborty,Philip Beaucamp,Niraj Bhujel,Min Chen*

Main category: cs.SE

TL;DR: 本文提出了一种数据虚拟化服务的设计和实现，以支持多个机器学习工作流的高效管理和扩展。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习工作流的复杂性和数据量的增加，需要一种高效的数据虚拟化技术来支持多应用和多流程的并发操作。

Method: 本文介绍了数据虚拟化服务的设计和实现，重点描述了其服务架构和服务操作。

Result: 该基础设施目前支持六个机器学习应用，每个应用包含多个工作流，并具备未来扩展能力。

Conclusion: 数据虚拟化服务的设计和实现为机器学习工作流提供了关键支持，能够有效管理和扩展多个应用和流程。

Abstract: Nowadays, machine learning (ML) teams have multiple concurrent ML workflows
for different applications. Each workflow typically involves many experiments,
iterations, and collaborative activities and commonly takes months and
sometimes years from initial data wrangling to model deployment.
Organizationally, there is a large amount of intermediate data to be stored,
processed, and maintained. \emph{Data virtualization} becomes a critical
technology in an infrastructure to serve ML workflows. In this paper, we
present the design and implementation of a data virtualization service,
focusing on its service architecture and service operations. The infrastructure
currently supports six ML applications, each with more than one ML workflow.
The data virtualization service allows the number of applications and workflows
to grow in the coming years.

</details>


### [154] [How Do Code Smells Affect Skill Growth in Scratch Novice Programmers?](https://arxiv.org/abs/2507.17314)
*Ricardo Hidalgo Aragón,Jesús M. González-Barahona,Gregorio Robles*

Main category: cs.SE

TL;DR: 该研究分析了Scratch项目中代码异味与计算思维能力的关联，发现CT能力与设计缺陷之间存在显著联系，为教育实践提供了数据支持。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索初学者在块编程环境中代码异味与计算思维能力的关联，以填补这一领域的研究空白。

Method: 从约200万个公开Scratch项目中随机抽样，使用开源工具提取9个CT评分和40个代码异味指标，经过严格预处理后，应用描述性分析、相关性测试、分层交叉验证和机器学习模型，辅以定性检查。

Result: 研究首次提供了CT能力与具体设计缺陷之间的大规模精细映射，为教育课程和自动化反馈系统提供了依据。

Conclusion: 该研究通过大规模数据分析，揭示了初学者在Scratch项目中代码异味与计算思维（CT）能力之间的关联，为计算教育理论和实践工具提供了重要见解。

Abstract: Context. Code smells, which are recurring anomalies in design or style, have
been extensively researched in professional code. However, their significance
in block-based projects created by novices is still largely unknown.
Block-based environments such as Scratch offer a unique, data-rich setting to
examine how emergent design problems intersect with the cultivation of
computational-thinking (CT) skills. Objective. This research explores the
connection between CT proficiency and design-level code smells--issues that may
hinder software maintenance and evolution--in programs created by Scratch
developers. We seek to identify which CT dimensions align most strongly with
which code smells and whether task context moderates those associations.
Method. A random sample of aprox. 2 million public Scratch projects is mined.
Using open-source linters, we extract nine CT scores and 40 code smell
indicators from these projects. After rigorous pre-processing, we apply
descriptive analytics, robust correlation tests, stratified cross-validation,
and exploratory machine-learning models; qualitative spot-checks contextualize
quantitative patterns. Impact. The study will deliver the first large-scale,
fine-grained map linking specific CT competencies to concrete design flaws and
antipatterns. Results are poised to (i) inform evidence-based curricula and
automated feedback systems, (ii) provide effect-size benchmarks for future
educational interventions, and (iii) supply an open, pseudonymized dataset and
reproducible analysis pipeline for the research community. By clarifying how
programming habits influence early skill acquisition, the work advances both
computing-education theory and practical tooling for sustainable software
maintenance and evolution.

</details>


### [155] [Roseau: Fast, Accurate, Source-based API Breaking Change Analysis in Java](https://arxiv.org/abs/2507.17369)
*Corentin Latappy,Thomas Degueule,Jean-Rémy Falleri,Romain Robbes,Lina Ochoa*

Main category: cs.SE

TL;DR: Roseau 是一个新型静态分析工具，能够高效检测 API 演化和破坏性变更，优于现有工具，适用于大规模纵向研究。


<details>
  <summary>Details</summary>
Motivation: 现有工具（如 JApiCmp 和 Revapi）依赖二进制 JAR 文件，限制了其在大规模纵向研究和细粒度分析（如提交级破坏性变更检测）中的应用。

Method: Roseau 通过构建技术无关的 API 模型，并利用丰富的语义分析功能，实现了对 API 演化和破坏性变更的高效检测。

Result: Roseau 在准确性（F1 = 0.99）和性能（检测版本间破坏性变更仅需不到两秒）上显著优于基线工具。此外，Roseau 能够高效分析 Google Guava API 的 14 年演化历史，将分析时间从几天缩短到几分钟。

Conclusion: Roseau 是一个高效的静态分析工具，能够从源代码或字节码构建技术无关的 API 模型，适用于大规模纵向研究，并在准确性和性能上优于现有工具（如 JApiCmp 和 Revapi）。

Abstract: Understanding API evolution and the introduction of breaking changes (BCs) in
software libraries is essential for library maintainers to manage backward
compatibility and for researchers to conduct empirical studies on software
library evolution. In Java, tools such as JApiCmp and Revapi are commonly used
to detect BCs between library releases, but their reliance on binary JARs
limits their applicability. This restriction hinders large-scale longitudinal
studies of API evolution and fine-grained analyses such as commit-level BC
detection. In this paper, we introduce Roseau, a novel static analysis tool
that constructs technology-agnostic API models from library code equipped with
rich semantic analyses. API models can be analyzed to study API evolution and
compared to identify BCs between any two versions of a library (releases,
commits, branches, etc.). Unlike traditional approaches, Roseau can build API
models from source code or bytecode, and is optimized for large-scale
longitudinal analyses of library histories. We assess the accuracy,
performance, and suitability of Roseau for longitudinal studies of API
evolution, using JApiCmp and Revapi as baselines. We extend and refine an
established benchmark of BCs and show that Roseau achieves higher accuracy (F1
= 0.99) than JApiCmp (F1 = 0.86) and Revapi (F1 = 0.91). We analyze 60 popular
libraries from Maven Central and find that Roseau delivers excellent
performance, detecting BCs between versions in under two seconds, including in
libraries with hundreds of thousands of lines of code. We further illustrate
the limitations of JApiCmp and Revapi for longitudinal studies and the novel
analysis capabilities offered by Roseau by tracking the evolution of Google's
Guava API and the introduction of BCs over 14 years and 6,839 commits, reducing
analysis times from a few days to a few minutes.

</details>


### [156] [Investigating Training Data Detection in AI Coders](https://arxiv.org/abs/2507.17389)
*Tianlin Li,Yunxiang Wei,Zhiming Li,Aishan Liu,Qing Guo,Xianglong Liu,Dongning Sun,Yang Liu*

Main category: cs.SE

TL;DR: 该论文研究了CodeLLMs中训练数据检测（TDD）方法的有效性，通过CodeSnitch数据集和突变策略评估了七种TDD方法，为未来开发更鲁棒的检测技术提供了指导。


<details>
  <summary>Details</summary>
Motivation: CodeLLMs偶尔会输出包含专有或敏感代码片段的内容，引发了对训练数据合规性、隐私和知识产权的担忧，因此需要有效的TDD方法来确保其负责任和合规的部署。

Method: 研究对七种最先进的TDD方法在源代码数据上进行了全面的实证研究，同时引入了CodeSnitch基准数据集，包含9,000个代码样本，并设计了基于代码克隆检测分类的突变策略。

Result: 研究评估了八种CodeLLMs的性能，并提出了CodeSnitch数据集和三种突变策略，以测试TDD方法的鲁棒性。

Conclusion: 该研究系统地评估了当前针对代码的训练数据检测（TDD）技术，并提供了未来开发更有效和鲁棒的检测方法的指导。

Abstract: Recent advances in code large language models (CodeLLMs) have made them
indispensable tools in modern software engineering. However, these models
occasionally produce outputs that contain proprietary or sensitive code
snippets, raising concerns about potential non-compliant use of training data,
and posing risks to privacy and intellectual property. To ensure responsible
and compliant deployment of CodeLLMs, training data detection (TDD) has become
a critical task. While recent TDD methods have shown promise in natural
language settings, their effectiveness on code data remains largely
underexplored. This gap is particularly important given code's structured
syntax and distinct similarity criteria compared to natural language. To
address this, we conduct a comprehensive empirical study of seven
state-of-the-art TDD methods on source code data, evaluating their performance
across eight CodeLLMs. To support this evaluation, we introduce CodeSnitch, a
function-level benchmark dataset comprising 9,000 code samples in three
programming languages, each explicitly labeled as either included or excluded
from CodeLLM training. Beyond evaluation on the original CodeSnitch, we design
targeted mutation strategies to test the robustness of TDD methods under three
distinct settings. These mutation strategies are grounded in the
well-established Type-1 to Type-4 code clone detection taxonomy. Our study
provides a systematic assessment of current TDD techniques for code and offers
insights to guide the development of more effective and robust detection
methods in the future.

</details>


### [157] [AssertFlip: Reproducing Bugs via Inversion of LLM-Generated Passing Tests](https://arxiv.org/abs/2507.17542)
*Lara Khatib,Noble Saji Mathews,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 


<details>
  <summary>Details</summary>
Motivation: 现有的方法在直接生成会失败的测试时存在效率问题，作者假设LLMs在编写通过测试时更为高效，因此提出了AssertFlip方法。

Method: AssertFlip技术通过首先生成在错误行为上通过的测试，然后反转这些测试以在错误出现时失败。

Result: AssertFlip在SWT-Bench基准测试中表现优于所有已知技术，具体来说，在SWT-Bench-Verified子集上实现了43.6%的失败转成功成功率。

Conclusion: 为了解决软件调试和修复过程中大多数错误缺乏可执行测试的问题，作者提出了AssertFlip技术，这是一种利用大型语言模型（LLMs）自动生成BugReproducibleTests（BRTs）的新方法。

Abstract: Bug reproduction is critical in the software debugging and repair process,
yet the majority of bugs in open-source and industrial settings lack executable
tests to reproduce them at the time they are reported, making diagnosis and
resolution more difficult and time-consuming. To address this challenge, we
introduce AssertFlip, a novel technique for automatically generating Bug
Reproducible Tests (BRTs) using large language models (LLMs). Unlike existing
methods that attempt direct generation of failing tests, AssertFlip first
generates passing tests on the buggy behaviour and then inverts these tests to
fail when the bug is present. We hypothesize that LLMs are better at writing
passing tests than ones that crash or fail on purpose. Our results show that
AssertFlip outperforms all known techniques in the leaderboard of SWT-Bench, a
benchmark curated for BRTs. Specifically, AssertFlip achieves a fail-to-pass
success rate of 43.6% on the SWT-Bench-Verified subset.

</details>


### [158] [CodeReasoner: Enhancing the Code Reasoning Ability with Reinforcement Learning](https://arxiv.org/abs/2507.17548)
*Lingxiao Tang,He Ye,Zhongxin Liu,Xiaoxue Ren,Lingfeng Bao*

Main category: cs.SE

TL;DR: CodeReasoner通过高质量数据集和两阶段训练，显著提升代码推理性能，7B模型媲美GPT-4o，14B模型全面超越。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于监督微调，但训练数据质量低且难以泛化，无法有效提升代码推理能力。

Method: 提出CodeReasoner框架，包括基于Python程序核心执行逻辑的数据集构建方法，以及通过指令微调和GRPO强化学习的两阶段训练流程。

Result: 在三个代码推理基准测试中，CodeReasoner比现有方法性能提升27.1%至40.2%，7B模型与GPT-4o相当，14B模型全面超越。

Conclusion: CodeReasoner框架通过高质量数据集构建和两阶段训练流程，显著提升了代码推理任务的性能，7B模型在关键任务上媲美GPT-4o，14B模型则全面超越。

Abstract: Code reasoning is a fundamental capability for large language models (LLMs)
in the code domain. It involves understanding and predicting a program's
execution behavior, such as determining the output for a given input or whether
a specific statement will be executed. This capability is essential for
downstream tasks like debugging, code generation, and program repair. Prior
approaches mainly rely on supervised fine-tuning to improve performance in code
reasoning tasks. However, they often show limited gains and fail to generalize
across diverse scenarios. We argue this is due to two core issues: the low
quality of training data and the limitations of supervised fine-tuning, which
struggles to teach general reasoning skills. To address these challenges, we
propose CodeReasoner, a framework that spans both dataset construction and a
two-stage training process. First, we introduce a method to construct datasets
that focus on the core execution logic of Python programs. Next, we apply
instruction tuning to inject execution-specific knowledge distilled from a
powerful teacher model. We then enhance reasoning and generalization through
GRPO reinforcement learning on top of the fine-tuned model. Experiments on
three widely-used code reasoning benchmarks show that CodeReasoner improves
performance by 27.1% to 40.2% over prior methods using a 7B model. Notably, the
7B model matches GPT-4o on key tasks like input/output and coverage prediction.
When scaled to 14B, CodeReasoner outperforms GPT-4o across all benchmarks.
Ablation studies confirm the effectiveness of each training stage and highlight
the importance of reasoning chains.

</details>


### [159] [Contextual Code Retrieval for Commit Message Generation: A Preliminary Study](https://arxiv.org/abs/2507.17690)
*Bo Xiong,Linghao Zhang,Chong Wang,Peng Liang*

Main category: cs.SE

TL;DR: 研究提出C3Gen方法，通过检索并融入上下文代码片段提升提交信息生成质量，实验验证其有效性并揭示相似性度量的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有CMG方法仅依赖代码差异（code diff）生成提交信息，但这种方式无法捕捉生成高质量信息所需的完整上下文。

Method: 提出了一种名为C3Gen的上下文代码检索方法，通过从仓库中检索与提交相关的代码片段，并将其融入模型输入，以提供仓库范围内的更丰富上下文信息。

Result: 实验表明，C3Gen通过融入上下文代码，使模型能有效利用额外信息生成更全面、实用的提交信息。同时，研究还通过人类评估验证了生成信息的实际价值。

Conclusion: 通过引入上下文代码检索方法C3Gen，研究证实了在提交信息生成（CMG）中融入更丰富的上下文信息能显著提升生成信息的质量和实用性。研究还揭示了基于相似性度量的可靠性问题，为CMG领域提供了实证见解。

Abstract: A commit message describes the main code changes in a commit and plays a
crucial role in software maintenance. Existing commit message generation (CMG)
approaches typically frame it as a direct mapping which inputs a code diff and
produces a brief descriptive sentence as output. However, we argue that relying
solely on the code diff is insufficient, as raw code diff fails to capture the
full context needed for generating high-quality and informative commit
messages. In this paper, we propose a contextual code retrieval-based method
called C3Gen to enhance CMG by retrieving commit-relevant code snippets from
the repository and incorporating them into the model input to provide richer
contextual information at the repository scope. In the experiments, we
evaluated the effectiveness of C3Gen across various models using four objective
and three subjective metrics. Meanwhile, we design and conduct a human
evaluation to investigate how C3Gen-generated commit messages are perceived by
human developers. The results show that by incorporating contextual code into
the input, C3Gen enables models to effectively leverage additional information
to generate more comprehensive and informative commit messages with greater
practical value in real-world development scenarios. Further analysis
underscores concerns about the reliability of similaritybased metrics and
provides empirical insights for CMG.

</details>


### [160] [CASCADE: LLM-Powered JavaScript Deobfuscator at Google](https://arxiv.org/abs/2507.17691)
*Shan Jiang,Pranoy Kovuri,David Tao,Zhixun Tan*

Main category: cs.SE

TL;DR: CASCADE 结合 Gemini 和 JSIR，高效反混淆 JavaScript 代码，已在 Google 生产环境中验证。


<details>
  <summary>Details</summary>
Motivation: JavaScript 混淆技术阻碍了代码理解和分析，对软件测试、静态分析和恶意软件检测提出了重大挑战。

Method: CASCADE 利用 Gemini 识别关键的 prelude 函数，并通过 JSIR 进行代码转换，恢复原始字符串、API 名称和程序行为。

Result: CASCADE 消除了数百至数千条硬编码规则，显著提升了反混淆效率，并减少了逆向工程的工作量。

Conclusion: CASCADE 是一种创新的混合方法，通过结合 Gemini 的编码能力和 JSIR 的确定性转换能力，显著提高了 JavaScript 反混淆的效率和可靠性，已在 Google 的生产环境中部署并验证了其效果。

Abstract: Software obfuscation, particularly prevalent in JavaScript, hinders code
comprehension and analysis, posing significant challenges to software testing,
static analysis, and malware detection. This paper introduces CASCADE, a novel
hybrid approach that integrates the advanced coding capabilities of Gemini with
the deterministic transformation capabilities of a compiler Intermediate
Representation (IR), specifically JavaScript IR (JSIR). By employing Gemini to
identify critical prelude functions, the foundational components underlying the
most prevalent obfuscation techniques, and leveraging JSIR for subsequent code
transformations, CASCADE effectively recovers semantic elements like original
strings and API names, and reveals original program behaviors. This method
overcomes limitations of existing static and dynamic deobfuscation techniques,
eliminating hundreds to thousands of hardcoded rules while achieving
reliability and flexibility. CASCADE is already deployed in Google's production
environment, demonstrating substantial improvements in JavaScript deobfuscation
efficiency and reducing reverse engineering efforts.

</details>


### [161] [Educational Insights from Code: Mapping Learning Challenges in Object-Oriented Programming through Code-Based Evidence](https://arxiv.org/abs/2507.17743)
*Andre Menolli,Bruno Strik*

Main category: cs.SE

TL;DR: 研究探讨了代码问题与面向对象编程学习困难的关系，开发了一个概念模型并验证了其教育适用性。


<details>
  <summary>Details</summary>
Motivation: 探索代码问题指标与面向对象编程学习过程中常见挑战之间的关系，以帮助解决学生在理解抽象概念时的困难。

Method: 通过定性分析识别学习困难的主要类别，并通过文献综述建立了这些困难、代码异味和SOLID原则违规之间的联系。

Result: 开发了一个将代码相关问题与特定学习挑战联系起来的概念地图，并通过专家评估验证了其适用性。

Conclusion: 本研究开发了一个概念模型，将代码相关的问题与面向对象编程中的学习挑战联系起来，并通过专家评估验证了其在教育环境中的相关性和适用性。

Abstract: Object-Oriented programming is frequently challenging for undergraduate
Computer Science students, particularly in understanding abstract concepts such
as encapsulation, inheritance, and polymorphism. Although the literature
outlines various methods to identify potential design and coding issues in
object-oriented programming through source code analysis, such as code smells
and SOLID principles, few studies explore how these code-level issues relate to
learning difficulties in Object-Oriented Programming. In this study, we explore
the relationship of the code issue indicators with common challenges
encountered during the learning of object-oriented programming. Using
qualitative analysis, we identified the main categories of learning
difficulties and, through a literature review, established connections between
these difficulties, code smells, and violations of the SOLID principles. As a
result, we developed a conceptual map that links code-related issues to
specific learning challenges in Object-Oriented Programming. The model was then
evaluated by an expert who applied it in the analysis of the student code to
assess its relevance and applicability in educational contexts.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [162] [Our Cars Can Talk: How IoT Brings AI to Vehicles](https://arxiv.org/abs/2507.17214)
*Amod Kant Agrawal*

Main category: cs.AI

TL;DR: 本文探讨了AI在车辆中的应用，提出通过AI副驾驶实现机器与驾驶员互通，推动智能车辆和预测性维护的未来发展。


<details>
  <summary>Details</summary>
Motivation: 通过AI副驾驶实现机器与驾驶员的语言互通，推动智能车辆系统、预测性维护和AI驱动的用户交互的未来研究和开发。

Method: 提供了概念和技术视角，旨在激发跨学科对话。

Result: 提出了一个框架，以指导未来在智能车辆系统和预测性维护领域的研究和开发。

Conclusion: 本文强调了将AI集成到车辆中作为感知平台的重要性，以推动维护从被动转向主动。

Abstract: Bringing AI to vehicles and enabling them as sensing platforms is key to
transforming maintenance from reactive to proactive. Now is the time to
integrate AI copilots that speak both languages: machine and driver. This
article offers a conceptual and technical perspective intended to spark
interdisciplinary dialogue and guide future research and development in
intelligent vehicle systems, predictive maintenance, and AI-powered user
interaction.

</details>


### [163] [Towards Autonomous Sustainability Assessment via Multimodal AI Agents](https://arxiv.org/abs/2507.17012)
*Zhihan Zhang,Alexander Metzger,Yuxuan Mei,Felix Hähnlein,Zachary Englhardt,Tingyu Cheng,Gregory D. Abowd,Shwetak Patel,Adriana Schulz,Vikram Iyer*

Main category: cs.AI

TL;DR: 论文提出了一种基于AI的新型LCA方法，通过多模态代理和数据分析，显著提高了效率和准确性，填补了数据缺口。


<details>
  <summary>Details</summary>
Motivation: 传统LCA所需的数据往往不可用，且耗时较长。为了解决这些问题，作者重新构思了LCA方法，利用AI技术提高效率和填补数据缺口。

Method: 通过引入多模态AI代理模拟LCA专家与利益相关者的交互，利用定制数据抽象和软件工具从在线文本和图像中提取信息，生成详细的生命周期清单。此外，还开发了直接估算环境影响和基于数据驱动的排放因子生成方法。

Result: 该方法将专家时间从数周或数月缩短至不到一分钟，碳足迹估算误差在19%以内。直接估算方法在电子产品上的MAPE为12.28%，数据驱动的排放因子生成方法比专家选择最接近的LCA数据库条目提高了120.26%的MAPE。

Conclusion: 该论文提出了一种基于多模态AI代理的新型LCA方法，显著减少了传统LCA所需的时间和数据缺口，同时保持了较高的准确性。此外，还开发了直接估算环境影响的方法和数据驱动的排放因子生成方法，为未来LCA工作流程提供了重要参考。

Abstract: Interest in sustainability information has surged in recent years. However,
the data required for a life cycle assessment (LCA) that maps the materials and
processes from product manufacturing to disposal into environmental impacts
(EI) are often unavailable. Here we reimagine conventional LCA by introducing
multimodal AI agents that emulate interactions between LCA experts and
stakeholders like product managers and engineers to calculate the
cradle-to-gate (production) carbon emissions of electronic devices. The AI
agents iteratively generate a detailed life-cycle inventory leveraging a custom
data abstraction and software tools that extract information from online text
and images from repair communities and government certifications. This approach
reduces weeks or months of expert time to under one minute and closes data
availability gaps while yielding carbon footprint estimates within 19% of
expert LCAs with zero proprietary data. Additionally, we develop a method to
directly estimate EI by comparing an input to a cluster of products with
similar descriptions and known carbon footprints. This runs in 3 ms on a laptop
with a MAPE of 12.28% on electronic products. Further, we develop a data-driven
method to generate emission factors. We use the properties of an unknown
material to represent it as a weighted sum of emission factors for similar
materials. Compared to human experts picking the closest LCA database entry,
this improves MAPE by 120.26%. We analyze the data and compute scaling of this
approach and discuss its implications for future LCA workflows.

</details>


### [164] [Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks](https://arxiv.org/abs/2507.17695)
*Ilias Chatzistefanidis,Navid Nikaein*

Main category: cs.AI

TL;DR: 本文提出了一种结合LLM和实时优化算法的共生代理范式，显著提升了决策准确性和资源效率，为下一代AGI驱动网络奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决从专用智能向通用人工智能（AGI）驱动网络过渡的需求，提升实时决策能力和网络功能管理的多样性。

Method: 设计了两种新型代理：无线接入网络优化器和多代理服务级别协议（SLA）协商器，并提出了AGI网络的端到端架构。在5G测试平台上评估了该架构。

Result: 共生代理将决策错误减少了五倍，小型语言模型（SLM）在GPU资源开销减少99.9%的情况下达到相似精度，实时循环时间为82毫秒。多代理演示减少了无线接入网络（RAN）的过载约44%。

Conclusion: 本文提出了一种结合大型语言模型（LLM）与实时优化算法的共生代理范式，作为下一代AGI驱动网络的基础，旨在保持适应性、高效性和可信赖性。

Abstract: Large Language Model (LLM)-based autonomous agents are expected to play a
vital role in the evolution of 6G networks, by empowering real-time
decision-making related to management and service provisioning to end-users.
This shift facilitates the transition from a specialized intelligence approach,
where artificial intelligence (AI) algorithms handle isolated tasks, to
artificial general intelligence (AGI)-driven networks, where agents possess
broader reasoning capabilities and can manage diverse network functions. In
this paper, we introduce a novel agentic paradigm that combines LLMs with
real-time optimization algorithms towards Trustworthy AI, defined as symbiotic
agents. Optimizers at the LLM's input-level provide bounded uncertainty
steering for numerically precise tasks, whereas output-level optimizers
supervised by the LLM enable adaptive real-time control. We design and
implement two novel agent types including: (i) Radio Access Network optimizers,
and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We
further propose an end-to-end architecture for AGI networks and evaluate it on
a 5G testbed capturing channel fluctuations from moving vehicles. Results show
that symbiotic agents reduce decision errors fivefold compared to standalone
LLM-based agents, while smaller language models (SLM) achieve similar accuracy
with a 99.9% reduction in GPU resource overhead and in near-real-time loops of
82 ms. A multi-agent demonstration for collaborative RAN on the real-world
testbed highlights significant flexibility in service-level agreement and
resource allocation, reducing RAN over-utilization by approximately 44%.
Drawing on our findings and open-source implementations, we introduce the
symbiotic paradigm as the foundation for next-generation, AGI-driven
networks-systems designed to remain adaptable, efficient, and trustworthy even
as LLMs advance.

</details>


### [165] [New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding](https://arxiv.org/abs/2507.17054)
*Shao-Hung Chan,Thomy Phan,Jiaoyang Li,Sven Koenig*

Main category: cs.AI

TL;DR: EECBS with new flex distribution methods (Conflict-Based, Delay-Based, Mixed-Strategy) improves efficiency over the original greedy approach by better handling collisions and delays.


<details>
  <summary>Details</summary>
Motivation: The original EECBS with flex distribution may push the sum of path costs (SOC) beyond the optimal bound, reducing efficiency by switching among path sets instead of resolving collisions. This paper aims to address this inefficiency.

Method: The paper introduces three new flex distribution mechanisms: Conflict-Based Flex Distribution, Delay-Based Flex Distribution, and Mixed-Strategy Flex Distribution, integrated into EECBS to improve efficiency by distributing flex in proportion to collisions and estimating delays for constraints.

Result: Experimental results demonstrate that the proposed approaches outperform the original greedy flex distribution in EECBS.

Conclusion: EECBS with Conflict-Based, Delay-Based, and Mixed-Strategy Flex Distribution mechanisms is proven to be complete and bounded-suboptimal, outperforming the original greedy flex distribution in efficiency.

Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of
collision-free paths, one for each agent in a shared environment. Its objective
is to minimize the sum of path costs (SOC), where the path cost of each agent
is defined as the travel time from its start location to its target location.
Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for
bounded-suboptimal MAPF, with the SOC of the solution being at most a
user-specified factor $w$ away from optimal. EECBS maintains sets of paths and
a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of
paths whose SOC is at most $w \cdot LB$ and introduces constraints to resolve
collisions. For each path in a set, EECBS maintains a lower bound on its
optimal path that satisfies constraints. By finding an individually
bounded-suboptimal path with cost at most a threshold of $w$ times its lower
bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up
EECBS, previous work uses flex distribution to increase the threshold. Though
EECBS with flex distribution guarantees to find a bounded-suboptimal solution,
increasing the thresholds may push the SOC beyond $w \cdot LB$, forcing EECBS
to switch among different sets of paths instead of resolving collisions on a
particular set of paths, and thus reducing efficiency. To address this issue,
we propose Conflict-Based Flex Distribution that distributes flex in proportion
to the number of collisions. We also estimate the delays needed to satisfy
constraints and propose Delay-Based Flex Distribution. On top of that, we
propose Mixed-Strategy Flex Distribution, combining both in a hierarchical
framework. We prove that EECBS with our new flex distribution mechanisms is
complete and bounded-suboptimal. Our experiments show that our approaches
outperform the original (greedy) flex distribution.

</details>


### [166] [LoRA is All You Need for Safety Alignment of Reasoning LLMs](https://arxiv.org/abs/2507.17075)
*Yihao Xue,Baharan Mirzasoleiman*

Main category: cs.AI

TL;DR: LoRA微调在保持LLM推理能力的同时有效提升安全性，避免了“安全税”问题。


<details>
  <summary>Details</summary>
Motivation: 解决安全对齐微调导致的推理能力下降问题（即“安全税”现象）。

Method: 采用LoRA（Low-Rank Adaptation）进行监督微调（SFT），限制安全权重更新至低秩空间，减少对推理权重的干扰。

Result: 在数学、科学和编程四个基准测试中，该方法实现了与全模型微调相当的安全水平，同时保持了推理能力。此外，LoRA诱导的权重更新与初始权重重叠较小，进一步减少重叠的方法在部分任务中有所提升。

Conclusion: 使用LoRA进行SFT在拒绝数据集上能有效对齐模型安全性而不损害其推理能力，为设计更优的推理-安全性权衡方法提供了方向。

Abstract: Reasoning LLMs have demonstrated remarkable breakthroughs in solving complex
problems that were previously out of reach. To ensure LLMs do not assist with
harmful requests, safety alignment fine-tuning is necessary in the
post-training phase. However, safety alignment fine-tuning has recently been
shown to significantly degrade reasoning abilities, a phenomenon known as the
"Safety Tax". In this work, we show that using LoRA for SFT on refusal datasets
effectively aligns the model for safety without harming its reasoning
capabilities. This is because restricting the safety weight updates to a
low-rank space minimizes the interference with the reasoning weights. Our
extensive experiments across four benchmarks covering math, science, and coding
show that this approach produces highly safe LLMs -- with safety levels
comparable to full-model fine-tuning -- without compromising their reasoning
abilities. Additionally, we observe that LoRA induces weight updates with
smaller overlap with the initial weights compared to full-model fine-tuning. We
also explore methods that further reduce such overlap -- via regularization or
during weight merging -- and observe some improvement on certain tasks. We hope
this result motivates designing approaches that yield more consistent
improvements in the reasoning-safety trade-off.

</details>


### [167] [HySafe-AI: Hybrid Safety Architectural Analysis Framework for AI Systems: A Case Study](https://arxiv.org/abs/2507.17118)
*Mandar Pitale,Jelena Frtunikj,Abhinaw Priyadershi,Vasu Singh,Maria Spence*

Main category: cs.AI

TL;DR: 本文提出HySAFE-AI框架，结合传统方法评估AI系统安全性，并探讨未来AI安全标准的发展方向。


<details>
  <summary>Details</summary>
Motivation: AI在安全关键领域（如自动驾驶系统和机器人技术）的应用日益广泛，但现有的安全性分析方法在评估基础模型（如LLMs和VLMs）时存在不足。

Method: 通过回顾不同的架构解决方案，并评估常见安全性分析方法（如FMEA和FTA）的有效性，提出了一种混合框架HySAFE-AI。

Result: 展示了如何改进传统安全性分析技术以应对基础模型的复杂性，特别是其在形成和利用潜在表示方面的特性。

Conclusion: 本文提出了HySAFE-AI框架，用于评估AI系统的安全性，并提出了未来AI安全标准发展的方向。

Abstract: AI has become integral to safety-critical areas like autonomous driving
systems (ADS) and robotics. The architecture of recent autonomous systems are
trending toward end-to-end (E2E) monolithic architectures such as large
language models (LLMs) and vision language models (VLMs). In this paper, we
review different architectural solutions and then evaluate the efficacy of
common safety analyses such as failure modes and effect analysis (FMEA) and
fault tree analysis (FTA). We show how these techniques can be improved for the
intricate nature of the foundational models, particularly in how they form and
utilize latent representations. We introduce HySAFE-AI, Hybrid Safety
Architectural Analysis Framework for AI Systems, a hybrid framework that adapts
traditional methods to evaluate the safety of AI systems. Lastly, we offer
hints of future work and suggestions to guide the evolution of future AI safety
standards.

</details>


### [168] [Improving LLMs' Generalized Reasoning Abilities by Graph Problems](https://arxiv.org/abs/2507.17168)
*Qifan Zhang,Nuo Chen,Zehua Li,Miao Peng,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: 本研究利用图问题推理（GPR）和GraphPile数据集，显著提升了LLMs在数学和非数学推理任务上的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理任务上表现优异，但在新颖和复杂问题上表现不佳；领域特定的CPT方法（如数学推理）缺乏通用性。GPR任务因其复杂的逻辑和关系推理能力，适合用于提升LLMs的通用推理能力。

Method: 引入GraphPile数据集（包含23个图任务，总计10.9B tokens）对Llama 3、3.1和Gemma 2等基础模型进行持续预训练（CPT），生成GraphMind模型。

Result: GraphMind在数学推理任务上准确率提升4.9%，在非数学推理任务（如逻辑和常识推理）上提升21.2%。

Conclusion: 本研究通过GraphPile数据集和GraphMind模型，首次利用图问题推理（GPR）提升了LLMs的通用推理能力，填补了领域特定预训练与通用推理能力之间的空白。

Abstract: Large Language Models (LLMs) have made remarkable strides in reasoning tasks,
yet their performance often falters on novel and complex problems.
Domain-specific continued pretraining (CPT) methods, such as those tailored for
mathematical reasoning, have shown promise but lack transferability to broader
reasoning tasks. In this work, we pioneer the use of Graph Problem Reasoning
(GPR) to enhance the general reasoning capabilities of LLMs. GPR tasks,
spanning pathfinding, network analysis, numerical computation, and topological
reasoning, require sophisticated logical and relational reasoning, making them
ideal for teaching diverse reasoning patterns. To achieve this, we introduce
GraphPile, the first large-scale corpus specifically designed for CPT using GPR
data. Spanning 10.9 billion tokens across 23 graph tasks, the dataset includes
chain-of-thought, program-of-thought, trace of execution, and real-world graph
data. Using GraphPile, we train GraphMind on popular base models Llama 3 and
3.1, as well as Gemma 2, achieving up to 4.9 percent higher accuracy in
mathematical reasoning and up to 21.2 percent improvement in non-mathematical
reasoning tasks such as logical and commonsense reasoning. By being the first
to harness GPR for enhancing reasoning patterns and introducing the first
dataset of its kind, our work bridges the gap between domain-specific
pretraining and universal reasoning capabilities, advancing the adaptability
and robustness of LLMs.

</details>


### [169] [Agent Identity Evals: Measuring Agentic Identity](https://arxiv.org/abs/2507.17257)
*Elija Perrier,Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 本文提出了AIE框架，用于测量语言模型代理（LMAs）维持其代理身份的能力，以增强其可靠性和实用性。


<details>
  <summary>Details</summary>
Motivation: 语言模型代理（LMAs）继承了大型语言模型（LLMs）的病理特性（如无状态性、随机性、对提示的敏感性和语言中介性），这些特性可能削弱其可识别性、连续性、持久性和一致性。为了解决这些问题，需要一种方法来测量和维护LMAs的代理身份。

Method: AIE框架包括一套新颖的度量标准，这些标准可以与性能、能力和代理鲁棒性的其他测量相结合。文中还详细描述了适用于LMA生命周期各阶段的正式定义和方法，并提供了实际应用案例。

Result: AIE框架提供了一套严格的、基于统计的实证方法，用于测量LMAs在时间维度上维持其代理身份的能力，包括其恢复状态扰动的能力。

Conclusion: 本文提出了一个名为'agent identity evals'（AIE）的框架，用于衡量语言模型代理（LMAs）在时间维度上维持其代理身份的程度。通过这一框架，可以辅助设计更优的LMA基础设施和支撑工具。

Abstract: Central to agentic capability and trustworthiness of language model agents
(LMAs) is the extent they maintain stable, reliable, identity over time.
However, LMAs inherit pathologies from large language models (LLMs)
(statelessness, stochasticity, sensitivity to prompts and
linguistically-intermediation) which can undermine their identifiability,
continuity, persistence and consistency. This attrition of identity can erode
their reliability, trustworthiness and utility by interfering with their
agentic capabilities such as reasoning, planning and action. To address these
challenges, we introduce \textit{agent identity evals} (AIE), a rigorous,
statistically-driven, empirical framework for measuring the degree to which an
LMA system exhibit and maintain their agentic identity over time, including
their capabilities, properties and ability to recover from state perturbations.
AIE comprises a set of novel metrics which can integrate with other measures of
performance, capability and agentic robustness to assist in the design of
optimal LMA infrastructure and scaffolding such as memory and tools. We set out
formal definitions and methods that can be applied at each stage of the LMA
life-cycle, and worked examples of how to apply them.

</details>


### [170] [Students' Feedback Requests and Interactions with the SCRIPT Chatbot: Do They Get What They Ask For?](https://arxiv.org/abs/2507.17258)
*Andreas Scholl,Natalie Kiesler*

Main category: cs.AI

TL;DR: 开发了基于ChatGPT-4o-mini的聊天机器人SCRIPT，实验显示其能有效匹配学生反馈需求（75%），为AI辅助学习系统设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 基于生成式AI（GenAI）在编程教育中的潜力，开发SCRIPT以支持新手学习者，探索如何通过开放互动和结构化引导提升学习效果。

Method: 研究通过实验评估了基于ChatGPT-4o-mini的聊天机器人SCRIPT，分析了136名学生在编程任务中与SCRIPT的互动及其反馈偏好。

Result: 学生反馈请求呈现特定顺序，聊天机器人响应与请求类型匹配度达75%，且遵守系统提示约束。

Conclusion: 研究结果强调了在AI辅助工具设计中平衡引导与灵活性的重要性，并为GenAI学习支持系统的设计提供了见解。

Abstract: Building on prior research on Generative AI (GenAI) and related tools for
programming education, we developed SCRIPT, a chatbot based on ChatGPT-4o-mini,
to support novice learners. SCRIPT allows for open-ended interactions and
structured guidance through predefined prompts. We evaluated the tool via an
experiment with 136 students from an introductory programming course at a large
German university and analyzed how students interacted with SCRIPT while
solving programming tasks with a focus on their feedback preferences. The
results reveal that students' feedback requests seem to follow a specific
sequence. Moreover, the chatbot responses aligned well with students' requested
feedback types (in 75%), and it adhered to the system prompt constraints. These
insights inform the design of GenAI-based learning support systems and
highlight challenges in balancing guidance and flexibility in AI-assisted
tools.

</details>


### [171] [Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments](https://arxiv.org/abs/2507.17289)
*Shitong Zhu,Chenhao Fang,Derek Larson,Neel Reddy Pochareddy,Rajeev Rao,Sophie Zeng,Yanqing Peng,Wendy Summer,Alex Goncalves,Arya Pudota,Herve Robert*

Main category: cs.AI

TL;DR: CBA是一款AI助手，通过智能路由机制提升合规任务效率，实验证明其性能显著优于普通LLM。


<details>
  <summary>Details</summary>
Motivation: 提升企业环境中合规任务的效率，平衡响应质量与延迟。

Method: 设计了用户查询路由器，支持FastTrack和FullAgentic两种模式，分别处理简单和复杂请求。

Result: CBA在关键词匹配率（83.7% vs. 41.7%）和LLM-judge通过率（82.0% vs. 20.0%）上显著优于普通LLM，且路由设计在保持运行时相近的情况下表现更优。

Conclusion: CBA通过智能路由机制在响应质量和延迟之间取得了良好平衡，显著提升了合规任务的效率。

Abstract: This paper presents Compliance Brain Assistant (CBA), a conversational,
agentic AI assistant designed to boost the efficiency of daily compliance tasks
for personnel in enterprise environments. To strike a good balance between
response quality and latency, we design a user query router that can
intelligently choose between (i) FastTrack mode: to handle simple requests that
only need additional relevant context retrieved from knowledge corpora; and
(ii) FullAgentic mode: to handle complicated requests that need composite
actions and tool invocations to proactively discover context across various
compliance artifacts, and/or involving other APIs/models for accommodating
requests. A typical example would be to start with a user query, use its
description to find a specific entity and then use the entity's information to
query other APIs for curating and enriching the final AI response.
  Our experimental evaluations compared CBA against an out-of-the-box LLM on
various real-world privacy/compliance-related queries targeting various
personas. We found that CBA substantially improved upon the vanilla LLM's
performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and
LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full
routing-based design against the `fast-track only` and `full-agentic` modes and
found that it had a better average match-rate and pass-rate while keeping the
run-time approximately the same. This finding validated our hypothesis that the
routing mechanism leads to a good trade-off between the two worlds.

</details>


### [172] [Ctx2TrajGen: Traffic Context-Aware Microscale Vehicle Trajectories using Generative Adversarial Imitation Learning](https://arxiv.org/abs/2507.17418)
*Joobin Jin,Seokjun Hong,Gyeongseon Baek,Yeeun Kim,Byeongjoon Noh*

Main category: cs.AI

TL;DR: Ctx2TrajGen 是一个基于 GAIL 的上下文感知轨迹生成框架，通过结合 PPO 和 WGAN-GP 解决了微观场景中的非线性依赖和训练不稳定问题，显著提升了轨迹生成的真实性和多样性。


<details>
  <summary>Details</summary>
Motivation: 精确建模微观车辆轨迹对交通行为分析和自动驾驶系统至关重要。

Method: 利用 GAIL、PPO 和 WGAN-GP 构建了一个上下文感知的轨迹生成框架，明确考虑了周围车辆和道路几何形状。

Result: 在无人机捕获的 DRIFT 数据集上，Ctx2TrajGen 在真实性、行为多样性和上下文保真度方面优于现有方法。

Conclusion: Ctx2TrajGen 提供了一种无需模拟的稳健解决方案，解决了数据稀缺和领域转移问题，并在无人机捕获的 DRIFT 数据集上展示了卓越的性能。

Abstract: Precise modeling of microscopic vehicle trajectories is critical for traffic
behavior analysis and autonomous driving systems. We propose Ctx2TrajGen, a
context-aware trajectory generation framework that synthesizes realistic urban
driving behaviors using GAIL. Leveraging PPO and WGAN-GP, our model addresses
nonlinear interdependencies and training instability inherent in microscopic
settings. By explicitly conditioning on surrounding vehicles and road geometry,
Ctx2TrajGen generates interaction-aware trajectories aligned with real-world
context. Experiments on the drone-captured DRIFT dataset demonstrate superior
performance over existing methods in terms of realism, behavioral diversity,
and contextual fidelity, offering a robust solution to data scarcity and domain
shift without simulation.

</details>


### [173] [An Uncertainty-Driven Adaptive Self-Alignment Framework for Large Language Models](https://arxiv.org/abs/2507.17477)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.AI

TL;DR: UDASA框架通过量化输出不确定性并分阶段优化，显著提升了LLM的对齐性能，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在指令跟随和通用推理方面取得了显著进展，但在无需人工标注的情况下实现与人类意图和安全规范的高质量对齐仍是一个根本性挑战。

Method: UDASA框架通过生成多个响应并量化语义、事实性和价值对齐三个维度的不确定性，构建偏好对，并将训练样本按不确定性差异分为保守、中等和探索三个阶段，逐步优化模型。

Result: 实验结果表明，UDASA在多个任务上优于现有的对齐方法，显著提升了模型性能。

Conclusion: UDASA框架在无需人工标注的情况下，显著提升了LLM在无害性、帮助性、真实性和情感控制生成等多个任务上的对齐性能。

Abstract: Large Language Models (LLMs) have demonstrated remarkable progress in
instruction following and general-purpose reasoning. However, achieving
high-quality alignment with human intent and safety norms without human
annotations remains a fundamental challenge. In this work, we propose an
Uncertainty-Driven Adaptive Self-Alignment (UDASA) framework designed to
improve LLM alignment in a fully automated manner. UDASA first generates
multiple responses for each input and quantifies output uncertainty across
three dimensions: semantics, factuality, and value alignment. Based on these
uncertainty scores, the framework constructs preference pairs and categorizes
training samples into three stages, conservative, moderate, and exploratory,
according to their uncertainty difference. The model is then optimized
progressively across these stages. In addition, we conduct a series of
preliminary studies to validate the core design assumptions and provide strong
empirical motivation for the proposed framework. Experimental results show that
UDASA outperforms existing alignment methods across multiple tasks, including
harmlessness, helpfulness, truthfulness, and controlled sentiment generation,
significantly improving model performance.

</details>


### [174] [LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning](https://arxiv.org/abs/2507.17482)
*Luca Salvatore Lorello,Nikolaos Manginas,Marco Lippi,Stefano Melacci*

Main category: cs.AI

TL;DR: LTLZinc是一个基准框架，用于生成神经符号和持续学习方法评估的时序和约束驱动任务，实验显示现有方法在时间推理方面存在不足。


<details>
  <summary>Details</summary>
Motivation: 现有神经符号人工智能方法多应用于静态场景，而需要沿时间维度推理的挑战性设置较少被探索。本文旨在填补这一空白。

Method: 提出LTLZinc基准框架，通过线性时序逻辑规范和MiniZinc约束生成表达性时序推理和持续学习任务，并结合任意图像分类数据集。细粒度注释支持多种神经和神经符号训练设置。

Result: 在六个神经符号序列分类和四个类持续学习任务上的实验展示了时间学习和推理的挑战性，并揭示了当前最先进方法的局限性。

Conclusion: 该论文介绍了LTLZinc基准框架，用于生成涵盖多种问题的数据集，以评估神经符号和持续学习方法在时间和约束驱动维度上的表现。实验表明，当前最先进方法在时间学习和推理方面存在局限性，并发布了LTLZinc生成器和十个现成任务以促进研究。

Abstract: Neuro-symbolic artificial intelligence aims to combine neural architectures
with symbolic approaches that can represent knowledge in a human-interpretable
formalism. Continual learning concerns with agents that expand their knowledge
over time, improving their skills while avoiding to forget previously learned
concepts. Most of the existing approaches for neuro-symbolic artificial
intelligence are applied to static scenarios only, and the challenging setting
where reasoning along the temporal dimension is necessary has been seldom
explored. In this work we introduce LTLZinc, a benchmarking framework that can
be used to generate datasets covering a variety of different problems, against
which neuro-symbolic and continual learning methods can be evaluated along the
temporal and constraint-driven dimensions. Our framework generates expressive
temporal reasoning and continual learning tasks from a linear temporal logic
specification over MiniZinc constraints, and arbitrary image classification
datasets. Fine-grained annotations allow multiple neural and neuro-symbolic
training settings on the same generated datasets. Experiments on six
neuro-symbolic sequence classification and four class-continual learning tasks
generated by LTLZinc, demonstrate the challenging nature of temporal learning
and reasoning, and highlight limitations of current state-of-the-art methods.
We release the LTLZinc generator and ten ready-to-use tasks to the
neuro-symbolic and continual learning communities, in the hope of fostering
research towards unified temporal learning and reasoning frameworks.

</details>


### [175] [CQE under Epistemic Dependencies: Algorithms and Experiments (extended version)](https://arxiv.org/abs/2507.17487)
*Lorenzo Marconi,Flavia Ricci,Riccardo Rosati*

Main category: cs.AI

TL;DR: 该论文研究了在受控查询评估中结合最优GA审查器和全EDs的方法，证明了其在安全性和计算效率上的优势，并通过实验验证了其实际可行性。


<details>
  <summary>Details</summary>
Motivation: 研究目的是在保证信息安全的条件下，优化基于本体的受控查询评估（CQE）的计算效率和实用性。

Method: 论文采用了一阶重写算法，针对DL-Lite_R本体和特定EDs子类，实现了数据复杂度为AC^0的BUCQs查询应答。

Result: 研究结果表明，在特定EDs和DL-Lite_R本体下，基于交集的最优GA审查器方法在安全性和计算效率上均表现良好，并通过实验验证了其可行性。

Conclusion: 该论文通过结合最优GA审查器与全EDs，证明了在特定条件下基于交集的方法在安全性和计算效率上的优势，并通过实验验证了其实际可行性。

Abstract: We investigate Controlled Query Evaluation (CQE) over ontologies, where
information disclosure is regulated by epistemic dependencies (EDs), a family
of logical rules recently proposed for the CQE framework. In particular, we
combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground
atoms that are entailed by the ontology and can be safely revealed. We focus on
answering Boolean unions of conjunctive queries (BUCQs) with respect to the
intersection of all optimal GA censors - an approach that has been shown in
other contexts to ensure strong security guarantees with favorable
computational behavior. First, we characterize the security of this
intersection-based approach and identify a class of EDs (namely, full EDs) for
which it remains safe. Then, for a subclass of EDs and for DL-Lite_R
ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0
in data complexity by presenting a suitable, detailed first-order rewriting
algorithm. Finally, we report on experiments conducted in two different
evaluation scenarios, showing the practical feasibility of our rewriting
function.

</details>


### [176] [Automated Hybrid Grounding Using Structural and Data-Driven Heuristics](https://arxiv.org/abs/2507.17493)
*Alexander Beiser,Markus Hecher,Stefan Woltran*

Main category: cs.AI

TL;DR: 提出自动混合基础方法，结合体解耦和传统基础，通过启发式算法优化基础过程，实验显示其在复杂场景中表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决混合基础中何时使用体解耦基础或传统自底向上基础的不明确问题，以提高答案集编程的工业应用普及率。

Method: 提出了一种基于数据结构和启发式的分割算法，自动决定何时使用体解耦基础或传统自底向上基础。

Result: 实验结果表明，该方法在难以基础场景中表现优异，在难以解决实例中接近最先进水平。

Conclusion: 自动混合基础解决了答案集编程中的基础瓶颈问题，通过结合传统自底向上基础和体解耦技术，提高了处理难以基础和难以解决实例的效率。

Abstract: The grounding bottleneck poses one of the key challenges that hinders the
widespread adoption of Answer Set Programming in industry. Hybrid Grounding is
a step in alleviating the bottleneck by combining the strength of standard
bottom-up grounding with recently proposed techniques where rule bodies are
decoupled during grounding. However, it has remained unclear when hybrid
grounding shall use body-decoupled grounding and when to use standard bottom-up
grounding. In this paper, we address this issue by developing automated hybrid
grounding: we introduce a splitting algorithm based on data-structural
heuristics that detects when to use body-decoupled grounding and when standard
grounding is beneficial. We base our heuristics on the structure of rules and
an estimation procedure that incorporates the data of the instance. The
experiments conducted on our prototypical implementation demonstrate promising
results, which show an improvement on hard-to-ground scenarios, whereas on
hard-to-solve instances we approach state-of-the-art performance.

</details>


### [177] [Can One Domain Help Others? A Data-Centric Study on Multi-Domain Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.17512)
*Yu Li,Zhuoshi Pan,Honglin Lin,Mengyuan Sun,Conghui He,Lijun Wu*

Main category: cs.AI

TL;DR: 该论文系统研究了多领域推理在RLVR框架下的表现，评估了模型在单领域和跨领域的性能，分析了训练中的交互作用及影响因素，为优化LLMs的多领域推理能力提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 现实世界的推理场景需要多种认知技能的综合应用，而现有研究多集中于孤立领域（如数学、编程或逻辑推理），对强化学习下这些技能的相互作用缺乏理解。

Method: 利用GRPO算法和Qwen-2.5-7B模型家族，对模型在单领域数据集上的域内改进和跨领域泛化能力进行全面评估，并分析跨领域训练中的交互作用（如相互增强或冲突）。同时比较了基础模型与指导模型在相同强化学习配置下的性能差异，并探讨了课程学习策略、奖励设计变化及语言特定因素的影响。

Result: 通过大量实验揭示了领域间交互的动态机制，明确了影响专业化和泛化推理性能的关键因素。

Conclusion: 研究结果为优化强化学习方法以培养LLMs在多领域的综合推理能力提供了宝贵指导。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has emerged as a
powerful paradigm for enhancing the reasoning capabilities of LLMs. Existing
research has predominantly concentrated on isolated reasoning domains such as
mathematical problem-solving, coding tasks, or logical reasoning. However, real
world reasoning scenarios inherently demand an integrated application of
multiple cognitive skills. Despite this, the interplay among these reasoning
skills under reinforcement learning remains poorly understood. To bridge this
gap, we present a systematic investigation of multi-domain reasoning within the
RLVR framework, explicitly focusing on three primary domains: mathematical
reasoning, code generation, and logical puzzle solving. We conduct a
comprehensive study comprising four key components: (1) Leveraging the GRPO
algorithm and the Qwen-2.5-7B model family, our study thoroughly evaluates the
models' in-domain improvements and cross-domain generalization capabilities
when trained on single-domain datasets. (2) Additionally, we examine the
intricate interactions including mutual enhancements and conflicts that emerge
during combined cross-domain training. (3) To further understand the influence
of SFT on RL, we also analyze and compare performance differences between base
and instruct models under identical RL configurations. (4) Furthermore, we
delve into critical RL training details, systematically exploring the impacts
of curriculum learning strategies, variations in reward design, and
language-specific factors. Through extensive experiments, our results offer
significant insights into the dynamics governing domain interactions, revealing
key factors influencing both specialized and generalizable reasoning
performance. These findings provide valuable guidance for optimizing RL
methodologies to foster comprehensive, multi-domain reasoning capabilities in
LLMs.

</details>


### [178] [TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment](https://arxiv.org/abs/2507.17514)
*Athanasios Davvetas,Xenia Ziouvelou,Ypatia Dami,Alexis Kaponis,Konstantina Giouvanopoulou,Michael Papademas*

Main category: cs.AI

TL;DR: TAI Scan Tool是一个基于RAG的TAI自我评估工具，支持AI法案合规性评估，通过两步法有效预测风险并检索相关文章。


<details>
  <summary>Details</summary>
Motivation: 开发TAI Scan Tool旨在通过最小化输入实现RAG-based的TAI自我评估，尤其关注AI法案的合规性。

Method: 该工具采用两步法，包括预筛选和评估阶段，支持法律TAI评估，特别关注于促进符合AI法案。

Result: 评估输出包括根据AI法案的风险级别见解，同时检索相关文章以帮助合规并通知义务。定性评估显示工具能正确预测风险级别并检索相关文章。

Conclusion: TAI Scan Tool的定性评估显示出有前景的结果，能够准确预测风险级别并检索相关文章，其推理依赖于与高风险系统设置的比较。

Abstract: This paper introduces the TAI Scan Tool, a RAG-based TAI self-assessment tool
with minimalistic input. The current version of the tool supports the legal TAI
assessment, with a particular emphasis on facilitating compliance with the AI
Act. It involves a two-step approach with a pre-screening and an assessment
phase. The assessment output of the system includes insight regarding the
risk-level of the AI system according to the AI Act, while at the same time
retrieving relevant articles to aid with compliance and notify on their
obligations. Our qualitative evaluation using use-case scenarios yields
promising results, correctly predicting risk levels while retrieving relevant
articles across three distinct semantic groups. Furthermore, interpretation of
results shows that the tool's reasoning relies on comparison with the setting
of high-risk systems, a behaviour attributed to their deployment requiring
careful consideration, and therefore frequently presented within the AI Act.

</details>


### [179] [Constructing Ophthalmic MLLM for Positioning-diagnosis Collaboration Through Clinical Cognitive Chain Reasoning](https://arxiv.org/abs/2507.17539)
*Xinyao Liu,Diping Song*

Main category: cs.AI

TL;DR: FundusExpert是一个眼科专用MLLM，通过集成定位-诊断推理能力和智能数据集FundusGen，显著提升了眼科诊断的准确性和临床一致性，同时在数据利用效率上表现出色。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在医学诊断领域显示出巨大潜力，但在眼科等专业领域面临关键挑战，如注释粒度的碎片化和临床推理逻辑的不一致性，阻碍了精确的跨模态理解。

Method: 本文介绍了FundusExpert，一个具有集成定位-诊断推理能力的眼科专用MLLM，以及通过智能Fundus-Engine系统构建的数据集FundusGen。Fundus-Engine自动化定位并利用基于MLLM的语义扩展，将全局疾病分类、局部对象检测和细粒度特征分析整合到单个眼底图像中。此外，通过构建临床对齐的认知链，引导模型生成可解释的推理路径。

Result: FundusExpert在眼科问答任务中表现最佳，超过40B MedRegA平均准确率26.6%，并在零样本报告生成任务中达到77.0%的临床一致性，显著优于GPT-4o的47.6%。此外，揭示了数据质量与模型能力之间的缩放规律（$L \propto N^{0.068}$），表明FundusGen中的认知对齐注释提高了数据利用效率。

Conclusion: FundusExpert通过整合区域级定位与诊断推理链，开发了一个可扩展且临床对齐的多模态大语言模型（MLLM），并探索了在特定MLLM中弥合视觉-语言差距的途径。

Abstract: Multimodal large language models (MLLMs) demonstrate significant potential in
the field of medical diagnosis. However, they face critical challenges in
specialized domains such as ophthalmology, particularly the fragmentation of
annotation granularity and inconsistencies in clinical reasoning logic, which
hinder precise cross-modal understanding. This paper introduces FundusExpert,
an ophthalmology-specific MLLM with integrated positioning-diagnosis reasoning
capabilities, along with FundusGen, a dataset constructed through the
intelligent Fundus-Engine system. Fundus-Engine automates localization and
leverages MLLM-based semantic expansion to integrate global disease
classification, local object detection, and fine-grained feature analysis
within a single fundus image. Additionally, by constructing a clinically
aligned cognitive chain, it guides the model to generate interpretable
reasoning paths. FundusExpert, fine-tuned with instruction data from FundusGen,
achieves the best performance in ophthalmic question-answering tasks,
surpassing the average accuracy of the 40B MedRegA by 26.6%. It also excels in
zero-shot report generation tasks, achieving a clinical consistency of 77.0%,
significantly outperforming GPT-4o's 47.6%. Furthermore, we reveal a scaling
law between data quality and model capability ($L \propto N^{0.068}$),
demonstrating that the cognitive alignment annotations in FundusGen enhance
data utilization efficiency. By integrating region-level localization with
diagnostic reasoning chains, our work develops a scalable, clinically-aligned
MLLM and explores a pathway toward bridging the visual-language gap in specific
MLLMs. Our project can be found at https://github.com/MeteorElf/FundusExpert.

</details>


### [180] [Simulating multiple human perspectives in socio-ecological systems using large language models](https://arxiv.org/abs/2507.17680)
*Yongchao Zeng,Calum Brown,Ioannis Kyriakou,Ronja Hotz,Mark Rounsevell*

Main category: cs.AI

TL;DR: HoPeS框架利用LLMs模拟多利益相关者视角，支持用户体验和整合不同观点，揭示了政策推荐与实施的现实挑战，展现了跨学科合作潜力。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法难以获取多元利益相关者视角的问题，通过模拟探索不同视角，促进对社会生态系统的深入理解。

Method: 开发了基于大语言模型（LLMs）的HoPeS建模框架，包括代理角色模拟和仿真协议，支持用户体验和整合不同视角。

Result: 原型系统在土地用途变化和制度动态背景下验证了HoPeS的有效性，用户通过角色体验揭示了研究者与决策者视角的现实差异。

Conclusion: HoPeS框架通过模拟不同利益相关者视角，展示了在复杂社会生态系统中探索多视角的潜力，尽管存在政策推荐与实施之间的差异，但系统为跨学科合作提供了新途径。

Abstract: Understanding socio-ecological systems requires insights from diverse
stakeholder perspectives, which are often hard to access. To enable
alternative, simulation-based exploration of different stakeholder
perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting)
modelling framework. HoPeS employs agents powered by large language models
(LLMs) to represent various stakeholders; users can step into the agent roles
to experience perspectival differences. A simulation protocol serves as a
"scaffold" to streamline multiple perspective-taking simulations, supporting
users in reflecting on, transitioning between, and integrating across
perspectives. A prototype system is developed to demonstrate HoPeS in the
context of institutional dynamics and land use change, enabling both
narrative-driven and numerical experiments. In an illustrative experiment, a
user successively adopts the perspectives of a system observer and a researcher
- a role that analyses data from the embedded land use model to inform
evidence-based decision-making for other LLM agents representing various
institutions. Despite the user's effort to recommend technically sound
policies, discrepancies persist between the policy recommendation and
implementation due to stakeholders' competing advocacies, mirroring real-world
misalignment between researcher and policymaker perspectives. The user's
reflection highlights the subjective feelings of frustration and disappointment
as a researcher, especially due to the challenge of maintaining political
neutrality while attempting to gain political influence. Despite this, the user
exhibits high motivation to experiment with alternative narrative framing
strategies, suggesting the system's potential in exploring different
perspectives. Further system and protocol refinement are likely to enable new
forms of interdisciplinary collaboration in socio-ecological simulations.

</details>


### [181] [Thinking Isn't an Illusion: Overcoming the Limitations of Reasoning Models via Tool Augmentations](https://arxiv.org/abs/2507.17699)
*Zhao Song,Song Yue,Jiahao Zhang*

Main category: cs.AI

TL;DR: 工具增强的LRMs在所有复杂度任务中均优于非推理模型，挑战了推理无效的观点。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型（LRMs）在复杂推理任务中表现出潜力，但近期实证研究表明其推理过程可能并未真正增强推理能力。本研究旨在探讨在引入工具增强后，LRMs的局限性是否仍然存在。

Method: 本研究引入了两种工具（Python解释器和草稿本），并在苹果的基准推理谜题上评估了三种代表性LLM及其LRM对应模型。

Result: 研究发现，在正确使用工具的情况下，LRMs在所有任务复杂度水平上均持续优于非推理模型。

Conclusion: 工具增强的大型推理模型（LRMs）在所有任务复杂度水平上均优于非推理模型，挑战了推理仅为幻觉的近期观点，并突显了工具增强LRMs解决复杂问题的潜力。

Abstract: Large Reasoning Models (LRMs) have become a central focus in today's large
language model (LLM) research, where models are designed to output a
step-by-step thinking process before arriving at a final answer to handle
complex reasoning tasks. Despite their promise, recent empirical studies (e.g.,
[Shojaee et al., 2025] from Apple) suggest that this thinking process may not
actually enhance reasoning ability, where LLMs without explicit reasoning
actually outperform LRMs on tasks with low or high complexity. In this work, we
revisit these findings and investigate whether the limitations of LRMs persist
when tool augmentations are introduced. We incorporate two types of tools,
Python interpreters and scratchpads, and evaluate three representative LLMs and
their LRM counterparts on Apple's benchmark reasoning puzzles. Our results show
that, with proper tool use, LRMs consistently outperform their non-reasoning
counterparts across all levels of task complexity. These findings challenge the
recent narrative that reasoning is an illusion and highlight the potential of
tool-augmented LRMs for solving complex problems.

</details>


### [182] [Online Submission and Evaluation System Design for Competition Operations](https://arxiv.org/abs/2507.17730)
*Zhe Chen,Daniel Harabor,Ryan Hechnenberger,Nathan R. Sturtevant*

Main category: cs.AI

TL;DR: 本文提出了一种自动化在线竞赛系统，解决了竞赛组织中的操作负担和兼容性问题，并已在多个竞赛中成功应用。


<details>
  <summary>Details</summary>
Motivation: 研究领域中的基准数据集和竞赛虽然有助于跟踪技术进步，但组织和管理这些竞赛具有显著的操作负担和兼容性问题。

Method: 该系统利用隔离环境评估提交的解决方案，解决了兼容性问题，并高效管理大量提交。

Result: 该系统已在包括Grid-Based Pathfinding Competition和League of Robot Runners竞赛在内的多个竞赛中成功实施。

Conclusion: 本文介绍了一个在线竞赛系统，该系统通过自动化的提交和评估流程，有效减轻了组织者的操作负担，并已在多个竞赛中成功应用。

Abstract: Research communities have developed benchmark datasets across domains to
compare the performance of algorithms and techniques However, tracking the
progress in these research areas is not easy, as publications appear in
different venues at the same time, and many of them claim to represent the
state-of-the-art. To address this, research communities often organise periodic
competitions to evaluate the performance of various algorithms and techniques,
thereby tracking advancements in the field. However, these competitions pose a
significant operational burden. The organisers must manage and evaluate a large
volume of submissions. Furthermore, participants typically develop their
solutions in diverse environments, leading to compatibility issues during the
evaluation of their submissions. This paper presents an online competition
system that automates the submission and evaluation process for a competition.
The competition system allows organisers to manage large numbers of submissions
efficiently, utilising isolated environments to evaluate submissions. This
system has already been used successfully for several competitions, including
the Grid-Based Pathfinding Competition and the League of Robot Runners
competition.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [183] [LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks](https://arxiv.org/abs/2507.17188)
*Lijie Zheng,Ji He,Shih Yu Chang,Yulong Shen,Dusit Niyato*

Main category: cs.NI

TL;DR: 论文提出分层优化框架，结合S2DC算法和LLM-HeMARL，提升异构无人机网络的安全速率和能源效率。


<details>
  <summary>Details</summary>
Motivation: 解决异构无人机网络中因无人机能力差异和能源-安全权衡被忽视而导致的物理层安全问题。

Method: 内层采用基于SDR的S2DC算法解决固定位置下的安全预编码问题，外层引入LLM-HeMARL进行轨迹优化，结合专家启发式策略。

Result: 仿真结果表明，该方法在安全速率和能源效率上优于现有基线，且在不同无人机群规模和随机种子下表现稳健。

Conclusion: 该论文提出的分层优化框架结合了SDR-based S2DC算法和LLM-HeMARL方法，在异构无人机网络中有效提升了安全速率和能源效率，具有鲁棒性。

Abstract: This work tackles the physical layer security (PLS) problem of maximizing the
secrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy
constraints. Unlike prior studies that assume uniform UAV capabilities or
overlook energy-security trade-offs, we consider a realistic scenario where
UAVs with diverse payloads and computation resources collaborate to serve
ground terminals in the presence of eavesdroppers. To manage the complex
coupling between UAV motion and communication, we propose a hierarchical
optimization framework. The inner layer uses a semidefinite relaxation
(SDR)-based S2DC algorithm combining penalty functions and difference-of-convex
(d.c.) programming to solve the secrecy precoding problem with fixed UAV
positions. The outer layer introduces a Large Language Model (LLM)-guided
heuristic multi-agent reinforcement learning approach (LLM-HeMARL) for
trajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics
policy generated by the LLM, enabling UAVs to learn energy-aware,
security-driven trajectories without the inference overhead of real-time LLM
calls. The simulation results show that our method outperforms existing
baselines in secrecy rate and energy efficiency, with consistent robustness
across varying UAV swarm sizes and random seeds.

</details>


### [184] [Closed-Form and Boundary Expressions for Task-Success Probability in Status-Driven Systems](https://arxiv.org/abs/2507.17195)
*Jianpeng Qi,Chao Liu,Rui Wang,Junyu Dong,Yanwei Yu*

Main category: cs.NI

TL;DR: 论文提出了一种分析框架，用于计算动态任务和延迟下的任务成功概率，验证了其准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 在计算优先的网络系统中，及时有效地传播服务器状态至关重要，但现有模型难以应对动态任务到达、有限服务器容量和双向链路延迟的挑战。

Method: 引入了一个统一的分析框架，将AP转发规则抽象为单一概率，并通过拉普拉斯变换建模所有网络和等待延迟。

Result: 框架生成了端到端任务成功概率的闭式表达式，并提供了上下界，验证了理论预测与模拟结果的一致性，准确度在0.01（上界）和0.016（下界）内。

Conclusion: 该论文提出了一个统一的分析框架，用于计算端到端任务成功概率，并验证了其理论预测和界限在实际模拟中的准确性。

Abstract: Timely and efficient dissemination of server status is critical in
compute-first networking systems, where user tasks arrive dynamically and
computing resources are limited and stochastic. In such systems, the access
point plays a key role in forwarding tasks to a server based on its latest
received server status. However, modeling the task-success probability
suffering the factors of stochastic arrivals, limited server capacity, and
bidirectional link delays. Therefore, we introduce a unified analytical
framework that abstracts the AP forwarding rule as a single probability and
models all network and waiting delays via their Laplace transforms. This
approach yields a closed form expression for the end to end task success
probability, together with upper and lower bounds that capture Erlang loss
blocking, information staleness, and random uplink/downlink delays. We validate
our results through simulations across a wide range of parameters, showing that
theoretical predictions and bounds consistently enclose observed success rates.
Our framework requires only two interchangeable inputs (the forwarding
probability and the delay transforms), making it readily adaptable to
alternative forwarding policies and delay distributions. Experiments
demonstrate that our bounds are able to achieve accuracy within 0.01 (upper
bound) and 0.016 (lower bound) of the empirical task success probability.

</details>


### [185] [Custody Transfer and Compressed Status Reporting for Bundle Protocol Version 7](https://arxiv.org/abs/2507.17403)
*Alice Le Bihan,Felix Flentge,Juan A. Fraire*

Main category: cs.NI

TL;DR: 本文介绍了BPv7的新托管传输过程，通过序列编号和扩展块提高效率，并在仿真场景中验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 随着空间任务的增加，需要一种高效可靠的网络中心通信方法。BPv7移除了BPv6的托管传输机制，因此需要定义相应的可靠性扩展。

Method: 设计并实现了一种新的托管传输方法，包括序列编号策略、新的托管传输扩展块和压缩报告扩展块，并通过仿真场景进行测试。

Result: 新机制在ESA BP实现中成功原型化，并在地球观测和月球通信仿真场景中进行了测试。

Conclusion: 本文提出了BPv7的新托管传输过程，并通过在ESA BP实现中的原型测试验证了其有效性。未来工作将聚焦于DTN可靠传输领域的进一步研究。

Abstract: As space missions increase, there is a growing need to replace point-to-point
communication with an efficient and reliable network-centric communication
approach. Disruption/Delay Tolerant Networking (DTN) with the Bundle Protocol
(BP) has been selected as an interoperable network protocol in the LunaNet
Interoperability Specification. It is also considered for future Earth
Observation and Mars communication scenarios. In a DTN, the "bundle" -- the
fundamental data unit of BP -- requires dedicated mechanisms to ensure
reliability due to the challenges posed by intermittent connectivity and long
delays. The previous version of BP, BPv6, contained a mechanism for reliable
transfer between "custodial nodes" called "custody transfer". However, this
approach has been removed from the core protocol specification for BPv7, which
requires a corresponding BP reliability extension to be defined separately.
This paper introduces a new custody transfer process for BPv7 (expected to be
published by CCSDS as an experimental specification in 2025). The core features
of this new custody transfer method for BPv7 are: (1) A strategy to efficiently
identify sets of bundles by sequence numbering (2) A new Custody Transfer
Extension Block and a corresponding administrative record, Compressed Custody
Signal, to efficiently report on the acceptance or rejection of custody using
sequence numbering (3) A new Compressed Reporting Extension Block requesting
reporting on bundle processing steps using a corresponding administrative
record with sequence numbering for efficiency. The paper will describe those
concepts and their design, specification, and implementation in detail. These
mechanisms have been prototyped in the ESA BP implementation and tested in
Earth Observation and Lunar communication simulation scenarios. The results
will be presented, as will an outlook on future work in the DTN reliable
transfer domain.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [186] [Mapple: A Domain-Specific Language for Mapping Distributed Heterogeneous Parallel Programs](https://arxiv.org/abs/2507.17087)
*Anjiang Wei,Rohan Yadav,Hang Song,Wonchan Lee,Ke Wang,Alex Aiken*

Main category: cs.DC

TL;DR: Mapple 是一种高级声明式映射接口，显著简化分布式应用的映射器开发，减少代码量并提升性能。


<details>
  <summary>Details</summary>
Motivation: 分布式异构系统中优化并行程序复杂且需大量代码修改，现有任务型编程系统的映射接口过于底层，缺乏高级抽象。

Method: Mapple 是一个高级声明式编程接口，提供转换原语（如 decompose）来解决迭代空间与处理器空间之间的维度不匹配问题，并在 Legion 运行时上实现。

Result: 在九个应用中，Mapple 将映射器代码量减少14倍，性能提升最高达1.34倍，分解原语比现有启发式方法提升最高达1.83倍。

Conclusion: Mapple 简化了分布式应用高性能映射器的开发，通过其高级声明式编程接口和分解原语，显著减少了代码量并提升了性能。

Abstract: Optimizing parallel programs for distributed heterogeneous systems remains a
complex task, often requiring significant code modifications. Task-based
programming systems improve modularity by separating performance decisions from
core application logic, but their mapping interfaces are often too low-level.
In this work, we introduce Mapple, a high-level, declarative programming
interface for mapping distributed applications. Mapple provides transformation
primitives to resolve dimensionality mismatches between iteration and processor
spaces, including a key primitive, decompose, that helps minimize communication
volume. We implement Mapple on top of the Legion runtime by translating Mapple
mappers into its low-level C++ interface. Across nine applications, including
six matrix multiplication algorithms and three scientific computing workloads,
Mapple reduces mapper code size by 14X and enables performance improvements of
up to 1.34X over expert-written C++ mappers. In addition, the decompose
primitive achieves up to 1.83X improvement over existing
dimensionality-resolution heuristics. These results demonstrate that Mapple
simplifies the development of high-performance mappers for distributed
applications.

</details>


### [187] [PathWeaver: A High-Throughput Multi-GPU System for Graph-Based Approximate Nearest Neighbor Search](https://arxiv.org/abs/2507.17094)
*Sukjin Kim,Seongyeon Park,Si Ung Noh,Junguk Hong,Taehee Kwon,Hunseong Lim,Jinho Lee*

Main category: cs.DC

TL;DR: PathWeaver是一种创新的多GPU框架，通过流水线路径扩展、幽灵暂存和方向引导选择技术，显著提升了大规模数据集上的ANNS搜索效率。


<details>
  <summary>Details</summary>
Motivation: 现有ANNS框架在多GPU扩展性上存在不足，仅将额外GPU视为内存扩展，导致效率低下。PathWeaver旨在解决这一问题，提升多GPU环境下的ANNS性能。

Method: PathWeaver提出了三种关键技术：1) 基于流水线的路径扩展机制，减少冗余搜索迭代；2) 幽灵暂存技术，通过代表性数据集优化查询起点；3) 方向引导选择，提前过滤无关数据点。

Result: 实验表明，PathWeaver在多样化数据集上实现了显著的性能提升，尤其在95%召回率下表现优异。

Conclusion: PathWeaver框架通过创新的多GPU设计，显著提升了大规模数据集上的近似最近邻搜索（ANNS）性能，实现了3.24倍的几何平均加速和最高5.30倍的加速。

Abstract: Graph-based Approximate Nearest Neighbor Search (ANNS) is widely adopted in
numerous applications, such as recommendation systems, natural language
processing, and computer vision. While recent works on GPU-based acceleration
have significantly advanced ANNS performance, the ever-growing scale of
datasets now demands efficient multi-GPU solutions. However, the design of
existing works overlooks multi-GPU scalability, resulting in naive approaches
that treat additional GPUs as a means to extend memory capacity for large
datasets. This inefficiency arises from partitioning the dataset and
independently searching for data points similar to the queries in each GPU. We
therefore propose PathWeaver, a novel multi-GPU framework designed to scale and
accelerate ANNS for large datasets. First, we propose pipelining-based path
extension, a GPU-aware pipelining mechanism that reduces prior work's redundant
search iterations by leveraging GPU-to-GPU communication. Second, we design
ghost staging that leverages a representative dataset to identify optimal query
starting points, reducing the search space for challenging queries. Finally, we
introduce direction-guided selection, a data selection technique that filters
irrelevant points early in the search process, minimizing unnecessary memory
accesses and distance computations. Comprehensive evaluations across diverse
datasets demonstrate that PathWeaver achieves 3.24$\times$ geomean speedup and
up to 5.30$\times$ speedup on 95% recall rate over state-of-the-art
multi-GPU-based ANNS frameworks.

</details>


### [188] [BucketServe: Bucket-Based Dynamic Batching for Smart and Efficient LLM Inference Serving](https://arxiv.org/abs/2507.17120)
*Wanyi Zheng,Minxian Xu,Shengye Song,Kejiang Ye*

Main category: cs.DC

TL;DR: BucketServe是一种动态批处理框架，通过优化GPU内存使用和优先级调度，显著提升LLM推理性能，实验表现优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务系统在异构工作负载下存在GPU内存利用效率低、延迟增加的问题，且无法适应动态工作负载波动。

Method: 提出BucketServe框架，基于序列长度将请求分组为大小均匀的桶，实时调整批处理大小以减少填充开销并优化GPU内存使用。

Result: 实验显示BucketServe在吞吐量上比UELLM提升3.58倍，在80% SLO达成率下比DistServe处理多1.93倍的请求负载，系统负载能力比UELLM高1.975倍。

Conclusion: BucketServe通过动态批处理和优先级调度显著提升了LLM推理性能，优于现有解决方案。

Abstract: Large language models (LLMs) have become increasingly popular in various
areas, traditional business gradually shifting from rule-based systems to
LLM-based solutions. However, the inference of LLMs is resource-intensive or
latency-sensitive, posing significant challenges for serving systems. Existing
LLM serving systems often use static or continuous batching strategies, which
can lead to inefficient GPU memory utilization and increased latency,
especially under heterogeneous workloads. These methods may also struggle to
adapt to dynamic workload fluctuations, resulting in suboptimal throughput and
potential service level objective (SLO) violations. In this paper, we introduce
BucketServe, a bucket-based dynamic batching framework designed to optimize LLM
inference performance. By grouping requests into size-homogeneous buckets based
on sequence length, BucketServe minimizes padding overhead and optimizes GPU
memory usage through real-time batch size adjustments preventing out-of-memory
(OOM) errors. It introduces adaptive bucket splitting/merging and
priority-aware scheduling to mitigate resource fragmentation and ensure SLO
compliance. Experiment shows that BucketServe significantly outperforms UELLM
in throughput, achieving up to 3.58x improvement. It can also handle 1.93x more
request load under the SLO attainment of 80% compared with DistServe and
demonstrates 1.975x higher system load capacity compared to the UELLM.

</details>


### [189] [Auto-scaling Approaches for Cloud-native Applications: A Survey and Taxonomy](https://arxiv.org/abs/2507.17128)
*Minxian Xu,Linfeng Wen,Junhan Liao,Huaming Wu,Kejiang Ye,Chengzhong Xu*

Main category: cs.DC

TL;DR: 本文综述了云原生应用自动扩展的最新技术，提出了分类法并比较了各种方法，总结了研究现状并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 云原生应用中的交互复杂且动态变化，对自动扩展方法提出了更高要求。本文旨在解决微服务依赖分析、性能分析、异常检测、工作负载特征化和任务共置等挑战，优化系统和应用性能。

Method: 本文系统地综述了2020年以来云原生应用自动扩展的最先进方法，并探讨了技术演变。此外，提出了一个详细的分类法，从基础设施、架构、扩展方法、优化目标和行为建模五个角度对当前研究进行了分类。

Result: 本文全面比较和深入讨论了每种方法的关键特性、优点、局限性和应用场景，考虑了它们在多样化环境和条件下的性能表现。

Conclusion: 本文总结了云原生应用自动扩展领域的研究现状，指出了当前存在的差距和未解决的挑战，并强调了未来探索的有前景方向，如大模型应用、微服务依赖管理和元学习技术的使用。

Abstract: The interactions within cloud-native applications are complex, with a
constantly changing number of services and loads, posing higher demands on
auto-scaling approach. This mainly involves several challenges such as
microservices dependency analysis, performance profiling, anomaly detection,
workload characterization and task co-location. Therefore, some advanced
algorithms have been investigated into auto-scaling cloud-native applications
to optimize system and application performance. These algorithms can learn from
historical data and appropriately adjust resource allocation based on the
current environment and load conditions to optimize resource utilization and
system performance. In this paper, we systematically review the literature on
state-of-the-art auto-scaling approaches for cloud-native applications from
2020, and further explore the technological evolution. Additionally, we propose
a detailed taxonomy to categorize current research from five perspectives,
including infrastructure, architecture, scaling methods, optimization
objectives, and behavior modeling. Then, we provide a comprehensive comparison
and in-depth discussion of the key features, advantages, limitations, and
application scenarios of each approach, considering their performance in
diverse environments and under various conditions. Finally, we summarize the
current state of research in this field, identify the gaps and unresolved
challenges, and emphasize promising directions for future exploration,
particularly in areas such as the application of large models, microservice
dependency management, and the use of meta-learning techniques to enhance model
applicability and adaptability across different environments.

</details>


### [190] [BrownoutServe: SLO-Aware Inference Serving under Bursty Workloads for MoE-based LLMs](https://arxiv.org/abs/2507.17133)
*Jianmin Hu,Minxian Xu,Kejiang Ye,Chengzhong Xu*

Main category: cs.DC

TL;DR: BrownoutServe 是一种针对 MoE 架构 LLMs 的动态服务框架，通过联合专家和动态降载机制显著提升效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的 MoE 架构系统因静态模型放置和缺乏动态工作负载适应而导致效率低下，资源利用不足和延迟增加。

Method: 引入了联合专家（united experts）以减少专家访问次数和推理延迟，并提出了动态降载机制来适应性地调整令牌处理。

Result: 在各种工作负载下，BrownoutServe 的吞吐量比 vLLM 提高了 2.07 倍，SLO 违规减少了 90.28%，同时在突发流量下保持可接受的推理准确性。

Conclusion: BrownoutServe 是一种新颖的服务框架，旨在优化基于 MoE 的 LLMs 的推理效率和服务可靠性，通过动态调整和联合专家机制，显著提升了吞吐量并减少了 SLO 违规。

Abstract: In recent years, the Mixture-of-Experts (MoE) architecture has been widely
applied to large language models (LLMs), providing a promising solution that
activates only a subset of the model's parameters during computation, thereby
reducing overall memory requirements and allowing for faster inference compared
to dense models. Despite these advantages, existing systems still face issues
of low efficiency due to static model placement and lack of dynamic workloads
adaptation. This leads to suboptimal resource utilization and increased
latency, especially during bursty requests periods.
  To address these challenges, this paper introduces BrownoutServe, a novel
serving framework designed to optimize inference efficiency and maintain
service reliability for MoE-based LLMs under dynamic computational demands and
traffic conditions. BrownoutServe introduces "united experts" that integrate
knowledge from multiple experts, reducing the times of expert access and
inference latency. Additionally, it proposes a dynamic brownout mechanism to
adaptively adjust the processing of certain tokens, optimizing inference
performance while guaranteeing service level objectives (SLOs) are met. Our
evaluations show the effectiveness of BrownoutServe under various workloads: it
achieves up to 2.07x throughput improvement compared to vLLM and reduces SLO
violations by 90.28%, showcasing its robustness under bursty traffic while
maintaining acceptable inference accuracy.

</details>


### [191] [Efficient Column-Wise N:M Pruning on RISC-V CPU](https://arxiv.org/abs/2507.17301)
*Chi-Wei Chu,Ding-Yong Hong,Jan-Jan Wu*

Main category: cs.DC

TL;DR: 提出列式N:M剪枝策略及优化方法，显著提升CNN推理效率且精度损失小。


<details>
  <summary>Details</summary>
Motivation: 深度学习中，权重剪枝是提升计算效率的关键技术，但不同实现方法对性能和内存开销影响显著。

Method: 提出了基于瓦片级别的列式N:M剪枝策略，并优化了XNNPACK以适配RISC-V向量架构；同时融合im2col和数据打包操作以减少冗余内存访问。

Result: ResNet推理吞吐量提升高达4.0倍，ImageNet top-1精度损失控制在2.1%以内。

Conclusion: 本文提出的列式N:M剪枝策略及优化方法显著提升了卷积神经网络的推理效率，同时保持了较高的模型精度。

Abstract: In deep learning frameworks, weight pruning is a widely used technique for
improving computational efficiency by reducing the size of large models. This
is especially critical for convolutional operators, which often act as
performance bottlenecks in convolutional neural networks (CNNs). However, the
effectiveness of pruning heavily depends on how it is implemented, as different
methods can significantly impact both computational performance and memory
footprint. In this work, we propose a column-wise N:M pruning strategy applied
at the tile level and modify XNNPACK to enable efficient execution of pruned
models on the RISC-V vector architecture. Additionally, we propose fusing the
operations of im2col and data packing to minimize redundant memory accesses and
memory overhead. To further optimize performance, we incorporate AITemplate's
profiling technique to identify the optimal implementation for each
convolutional operator. Our proposed approach effectively increases ResNet
inference throughput by as much as 4.0x, and preserves ImageNet top-1 accuracy
within 2.1\% of the dense baseline.

</details>


### [192] [Multiprocessor Scheduling with Memory Constraints: Fundamental Properties and Finding Optimal Solutions](https://arxiv.org/abs/2507.17411)
*Pál András Papp,Toni Böhnlein,A. N. Yzelman*

Main category: cs.DC

TL;DR: 论文研究多处理器两级内存下的DAG调度问题，提出基于ILP的整体算法，实验证明其优于传统分离优化方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决多处理器两级内存层次结构中的DAG调度问题，该问题同时涉及工作负载平衡、通信和缓存大小限制导致的数据移动，是文献中多个重要模型的自然推广。

Method: 论文首先从理论角度分析了问题的计算复杂性，并提出了基于整数线性规划（ILP）的整体调度算法。通过实验在小规模计算任务基准上验证了其性能。

Result: 实验结果表明，基于ILP的方法比结合经典调度算法和内存管理策略的基线方法能找到更优的解。

Conclusion: 该论文证明了在多处理器两级内存层次结构中，综合考虑并行化和内存管理的整体调度算法比传统的分离优化方法能显著提升性能。

Abstract: We study the problem of scheduling a general computational DAG on multiple
processors in a 2-level memory hierarchy. This setting is a natural
generalization of several prominent models in the literature, and it
simultaneously captures workload balancing, communication, and data movement
due to cache size limitations. We first analyze the fundamental properties of
this problem from a theoretical perspective, such as its computational
complexity. We also prove that optimizing parallelization and memory management
separately, as done in many applications, can result in a solution that is a
linear factor away from the optimum.
  On the algorithmic side, we discuss a natural technique to represent and
solve the problem as an Integer Linear Program (ILP). We develop a holistic
scheduling algorithm based on this approach, and we experimentally study its
performance and properties on a small benchmark of computational tasks. Our
results confirm that the ILP-based method can indeed find considerably better
solutions than a baseline which combines classical scheduling algorithms and
memory management policies.

</details>


### [193] [Distributed P2P quantile tracking with relative value error](https://arxiv.org/abs/2507.17458)
*Marco Pulimeno,Italo Epicoco,Massimo Cafaro*

Main category: cs.DC

TL;DR: \textsc{DUDDSketch} 是一种分布式 gossip 协议，用于非结构化 P2P 网络中的分位数跟踪，其正确性和收敛性均得到验证。


<details>
  <summary>Details</summary>
Motivation: 为了解决在非结构化 P2P 网络中准确跟踪分位数的需求，提出了一种分布式版本的 \textsc{UDDSketch} 算法。

Method: 设计了一个完全去中心化的分布式协议，并对其正确性进行了形式化证明。通过大量实验验证了算法的收敛性。

Result: 实验结果表明，\textsc{DUDDSketch} 能够收敛到顺序算法的结果，验证了其有效性。

Conclusion: \textsc{DUDDSketch} 是一种分布式、基于 gossip 的协议，能够在非结构化 P2P 网络中准确跟踪分位数，其正确性得到了形式化证明，并通过实验验证了其与顺序算法结果的一致性。

Abstract: In this paper we present \textsc{DUDDSketch}, a distributed version of the
\textsc{UDDSketch} algorithm for accurate tracking of quantiles. The algorithm
is a fully decentralized, gossip-based distributed protocol working in the
context of unstructured P2P networks. We discuss the algorithm's design and
formally prove its correctness. We also show, through extensive experimental
results, that the algorithm converges to the results provided by the sequential
algorithm, which is a fundamental and highly desirable property.

</details>
