<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 5]
- [eess.IV](#eess.IV) [Total: 11]
- [cs.SE](#cs.SE) [Total: 15]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.RO](#cs.RO) [Total: 15]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Quantum-Cognitive Tunnelling Neural Networks for Military-Civilian Vehicle Classification and Sentiment Analysis](https://arxiv.org/abs/2507.18645)
*Milan Maksimovic,Anna Bohdanets,Immaculate Motsi-Omoijiade,Guido Governatori,Ivan S. Maksymov*

Main category: cs.CV

TL;DR: QT-based neural networks improve AI's ability to distinguish military vs. civilian vehicles and analyze sentiment in battlefield scenarios, mimicking human reasoning.


<details>
  <summary>Details</summary>
Motivation: To capture important nuances of human perception, particularly in recognizing ambiguous objects and sentiment analysis, by incorporating quantum tunnelling (QT) probability into neural network models.

Method: novel QT-based neural networks are employed to assess effectiveness in distinguishing customised CIFAR-format images of military and civilian vehicles, as well as sentiment analysis using a proprietary military-specific vocabulary.

Result: The QT-based models effectively distinguish between military and civilian vehicles and perform sentiment analysis in military-specific contexts.

Conclusion: QT-based models can enhance multimodal AI applications in battlefield scenarios, particularly in human-operated drone warfare, by imbuing AI with human-like reasoning traits.

Abstract: Prior work has demonstrated that incorporating well-known quantum tunnelling
(QT) probability into neural network models effectively captures important
nuances of human perception, particularly in the recognition of ambiguous
objects and sentiment analysis. In this paper, we employ novel QT-based neural
networks and assess their effectiveness in distinguishing customised
CIFAR-format images of military and civilian vehicles, as well as sentiment,
using a proprietary military-specific vocabulary. We suggest that QT-based
models can enhance multimodal AI applications in battlefield scenarios,
particularly within human-operated drone warfare contexts, imbuing AI with
certain traits of human reasoning.

</details>


### [2] [Livatar-1: Real-Time Talking Heads Generation with Tailored Flow Matching](https://arxiv.org/abs/2507.18649)
*Haiyang Liu,Xiaolin Hong,Xuancheng Yang,Yudi Ruan,Xiang Lian,Michael Lingelbach,Hongwei Yi,Wei Li*

Main category: cs.CV

TL;DR: Livatar是一个实时音频驱动虚拟头像生成框架，通过流匹配优化唇同步和姿势稳定性，在性能和精度上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有基线在唇同步精度和长期姿势漂移方面的局限性。

Method: 采用基于流匹配的框架，并结合系统优化。

Result: 在HDTF数据集上获得8.50的LipSync Confidence，单A10 GPU上实现141 FPS的吞吐量和0.17秒的端到端延迟。

Conclusion: Livatar框架通过流匹配和系统优化，显著提升了唇同步质量和实时性能，使高保真虚拟头像更广泛适用。

Abstract: We present Livatar, a real-time audio-driven talking heads videos generation
framework. Existing baselines suffer from limited lip-sync accuracy and
long-term pose drift. We address these limitations with a flow matching based
framework. Coupled with system optimizations, Livatar achieves competitive
lip-sync quality with a 8.50 LipSync Confidence on the HDTF dataset, and
reaches a throughput of 141 FPS with an end-to-end latency of 0.17s on a single
A10 GPU. This makes high-fidelity avatars accessible to broader applications.
Our project is available at https://www.hedra.com/ with with examples at
https://h-liu1997.github.io/Livatar-1/

</details>


### [3] [Features extraction for image identification using computer vision](https://arxiv.org/abs/2507.18650)
*Venant Niyonkuru,Sylla Sekou,Jimmy Jackson Sinzinkayo*

Main category: cs.CV

TL;DR: ViTs在计算机视觉中优于CNNs，但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 探讨不同特征提取技术的优缺点，特别是在ViTs与传统CNNs之间的性能比较。

Method: 研究了多种特征提取技术，包括ViTs、GANs、深度特征模型、传统方法（SIFT、SURF、ORB）以及非对比和对比特征模型。

Result: 实验结果表明ViTs在架构上（如patch嵌入、位置编码和多头自注意力机制）优于CNNs。

Conclusion: Vision Transformers (ViTs) 在计算机视觉中表现出优于传统卷积神经网络（CNNs）的性能，但其仍有局限性。

Abstract: This study examines various feature extraction techniques in computer vision,
the primary focus of which is on Vision Transformers (ViTs) and other
approaches such as Generative Adversarial Networks (GANs), deep feature models,
traditional approaches (SIFT, SURF, ORB), and non-contrastive and contrastive
feature models. Emphasizing ViTs, the report summarizes their architecture,
including patch embedding, positional encoding, and multi-head self-attention
mechanisms with which they overperform conventional convolutional neural
networks (CNNs). Experimental results determine the merits and limitations of
both methods and their utilitarian applications in advancing computer vision.

</details>


### [4] [Adapt, But Don't Forget: Fine-Tuning and Contrastive Routing for Lane Detection under Distribution Shift](https://arxiv.org/abs/2507.18653)
*Mohammed Abdul Hafeez Khan,Parth Ganeriwala,Sarah M. Lehman,Siddhartha Bhattacharyya,Amy Alvarez,Natasha Neogi*

Main category: cs.CV

TL;DR: 提出了一种动态路由和选择性微调的框架，有效应对跨数据集分布偏移，减少参数使用量并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决跨数据集分布偏移导致的灾难性遗忘问题，提升模型在封闭世界评估中的适应性和参数效率。

Method: 首先在源分布上训练基础模型，然后通过创建独立分支并选择性微调组件来适应新目标分布，同时保持原始源分支固定。采用监督对比学习模型在推理时识别输入分布并动态路由到相应分支。

Result: 该框架在显著减少参数使用量的情况下，实现了接近最优的F1分数。

Conclusion: 该框架通过动态路由和选择性微调，实现了在跨数据集分布偏移下的高效参数适应，显著减少了参数使用量，同时保持了接近最优的性能。

Abstract: Lane detection models are often evaluated in a closed-world setting, where
training and testing occur on the same dataset. We observe that, even within
the same domain, cross-dataset distribution shifts can cause severe
catastrophic forgetting during fine-tuning. To address this, we first train a
base model on a source distribution and then adapt it to each new target
distribution by creating separate branches, fine-tuning only selected
components while keeping the original source branch fixed. Based on a
component-wise analysis, we identify effective fine-tuning strategies for
target distributions that enable parameter-efficient adaptation. At inference
time, we propose using a supervised contrastive learning model to identify the
input distribution and dynamically route it to the corresponding branch. Our
framework achieves near-optimal F1-scores while using significantly fewer
parameters than training separate models for each distribution.

</details>


### [5] [A New One-Shot Federated Learning Framework for Medical Imaging Classification with Feature-Guided Rectified Flow and Knowledge Distillation](https://arxiv.org/abs/2507.19045)
*Yufei Ma,Hanwen Zhang,Qiya Yang,Guibo Luo,Yuesheng Zhu*

Main category: cs.CV

TL;DR: 提出FG-RF和DLKD方法，提升单次联邦学习在医疗影像中的效率和隐私保护，实验显示性能优于多轮联邦学习和基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成模型在单次联邦学习中效率低、隐私泄露及非独立同分布数据下难以收敛的问题。

Method: 提出了FG-RF（特征引导校正流模型）和DLKD（双层知识蒸馏）聚合方法，前者通过合成特征级图像加速生成模型并保护隐私，后者通过模仿输出逻辑和对齐中间层特征处理非独立同分布数据。

Result: 在三个非独立同分布医疗影像数据集上，新框架比多轮联邦学习性能提升21.73%，平均优于FedISCA基线21.75%，且特征级合成图像显著降低隐私泄露风险。

Conclusion: 提出的FG-RF和DLKD方法在医疗影像的非独立同分布数据场景下显著提升了单次联邦学习的效率和隐私保护能力，实验证明其性能优于多轮联邦学习方法和基线FedISCA。

Abstract: In multi-center scenarios, One-Shot Federated Learning (OSFL) has attracted
increasing attention due to its low communication overhead, requiring only a
single round of transmission. However, existing generative model-based OSFL
methods suffer from low training efficiency and potential privacy leakage in
the healthcare domain. Additionally, achieving convergence within a single
round of model aggregation is challenging under non-Independent and Identically
Distributed (non-IID) data. To address these challenges, in this paper a
modified OSFL framework is proposed, in which a new Feature-Guided Rectified
Flow Model (FG-RF) and Dual-Layer Knowledge Distillation (DLKD) aggregation
method are developed. FG-RF on the client side accelerates generative modeling
in medical imaging scenarios while preserving privacy by synthesizing
feature-level images rather than pixel-level images. To handle non-IID
distributions, DLKD enables the global student model to simultaneously mimic
the output logits and align the intermediate-layer features of client-side
teacher models during aggregation. Experimental results on three non-IID
medical imaging datasets show that our new framework and method outperform
multi-round federated learning approaches, achieving up to 21.73% improvement,
and exceeds the baseline FedISCA by an average of 21.75%. Furthermore, our
experiments demonstrate that feature-level synthetic images significantly
reduce privacy leakage risks compared to pixel-level synthetic images.

</details>


### [6] [Part Segmentation of Human Meshes via Multi-View Human Parsing](https://arxiv.org/abs/2507.18655)
*James Dickens,Kamyar Hamad*

Main category: cs.CV

TL;DR: 提出一种基于几何信息的人体网格语义分割方法，通过伪标注流程和高效采样策略，实现了高准确率的语义解析。


<details>
  <summary>Details</summary>
Motivation: 结合点云深度学习与人体解析领域，实现大规模人体网格的逐顶点语义分割。

Method: 开发了Thuman2.1数据集的伪地面真值标注流程，采用窗口化迭代最远点采样（FPS）和空间填充曲线序列化的高效采样策略，结合PointTransformer进行纯几何分割。

Result: 实验结果表明，所提方法在不依赖纹理信息的情况下，能有效且准确地进行人体网格的语义解析。

Conclusion: 该方法通过伪地面真值标注流程和高效采样策略，实现了基于几何信息的人体网格语义分割，验证了方法的有效性和准确性。

Abstract: Recent advances in point cloud deep learning have led to models that achieve
high per-part labeling accuracy on large-scale point clouds, using only the raw
geometry of unordered point sets. In parallel, the field of human parsing
focuses on predicting body part and clothing/accessory labels from images. This
work aims to bridge these two domains by enabling per-vertex semantic
segmentation of large-scale human meshes. To achieve this, a pseudo-ground
truth labeling pipeline is developed for the Thuman2.1 dataset: meshes are
first aligned to a canonical pose, segmented from multiple viewpoints, and the
resulting point-level labels are then backprojected onto the original mesh to
produce per-point pseudo ground truth annotations. Subsequently, a novel,
memory-efficient sampling strategy is introduced, a windowed iterative farthest
point sampling (FPS) with space-filling curve-based serialization to
effectively downsample the point clouds. This is followed by a purely geometric
segmentation using PointTransformer, enabling semantic parsing of human meshes
without relying on texture information. Experimental results confirm the
effectiveness and accuracy of the proposed approach.

</details>


### [7] [ShrinkBox: Backdoor Attack on Object Detection to Disrupt Collision Avoidance in Machine Learning-based Advanced Driver Assistance Systems](https://arxiv.org/abs/2507.18656)
*Muhammad Zaeem Shahzad,Muhammad Abdullah Hanif,Bassem Ouni,Muhammad Shafique*

Main category: cs.CV

TL;DR: 论文提出了一种针对ML-ADAS的新型后门攻击ShrinkBox，通过细微缩小边界框破坏距离估计，攻击成功率高且隐蔽。


<details>
  <summary>Details</summary>
Motivation: ML-ADAS依赖低成本摄像头和DNNs，但其对象检测器的安全漏洞可能被利用，导致碰撞避免功能失效。

Method: 采用YOLOv9m对象检测器，在KITTI数据集上以低毒化比例实现攻击，并通过宽松的毒化策略引入低误差目标。

Result: ShrinkBox在YOLOv9m上实现了96%的攻击成功率，毒化比例仅为4%，并使下游距离估计的MAE增加了3倍以上。

Conclusion: 论文提出了ShrinkBox这种针对碰撞避免ML-ADAS的新型后门攻击方法，通过细微缩小边界框来破坏距离估计的准确性，展示了高攻击成功率和对下游任务的严重影响。

Abstract: Advanced Driver Assistance Systems (ADAS) significantly enhance road safety
by detecting potential collisions and alerting drivers. However, their reliance
on expensive sensor technologies such as LiDAR and radar limits accessibility,
particularly in low- and middle-income countries. Machine learning-based ADAS
(ML-ADAS), leveraging deep neural networks (DNNs) with only standard camera
input, offers a cost-effective alternative. Critical to ML-ADAS is the
collision avoidance feature, which requires the ability to detect objects and
estimate their distances accurately. This is achieved with specialized DNNs
like YOLO, which provides real-time object detection, and a lightweight,
detection-wise distance estimation approach that relies on key features
extracted from the detections like bounding box dimensions and size. However,
the robustness of these systems is undermined by security vulnerabilities in
object detectors. In this paper, we introduce ShrinkBox, a novel backdoor
attack targeting object detection in collision avoidance ML-ADAS. Unlike
existing attacks that manipulate object class labels or presence, ShrinkBox
subtly shrinks ground truth bounding boxes. This attack remains undetected in
dataset inspections and standard benchmarks while severely disrupting
downstream distance estimation. We demonstrate that ShrinkBox can be realized
in the YOLOv9m object detector at an Attack Success Rate (ASR) of 96%, with
only a 4% poisoning ratio in the training instances of the KITTI dataset.
Furthermore, given the low error targets introduced in our relaxed poisoning
strategy, we find that ShrinkBox increases the Mean Absolute Error (MAE) in
downstream distance estimation by more than 3x on poisoned samples, potentially
resulting in delays or prevention of collision warnings altogether.

</details>


### [8] [VGS-ATD: Robust Distributed Learning for Multi-Label Medical Image Classification Under Heterogeneous and Imbalanced Conditions](https://arxiv.org/abs/2507.18657)
*Zehui Zhao,Laith Alzubaidi,Haider A. Alwzwazy,Jinglan Zhang,Yuantong Gu*

Main category: cs.CV

TL;DR: VGS-ATD是一种新型分布式学习框架，解决了隐私、数据异构性和扩展性问题，在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统集中式学习存在隐私风险，而现有的去中心化方法（如联邦学习和群体学习）在处理异构和不平衡数据时效率低下，且难以应对临床环境的动态复杂性。

Method: 提出了一种名为VGS-ATD的新型分布式学习框架，通过在分布式节点上进行模型训练，仅共享模型权重，避免了数据隐私问题。

Result: VGS-ATD在30个数据集和80个独立标签的实验中，总体准确率达到92.7%，优于集中式学习（84.9%）和群体学习（72.99%），并在扩展性和计算成本方面表现卓越。

Conclusion: VGS-ATD框架在分布式学习中表现出色，不仅解决了隐私问题，还显著提高了模型的准确性、扩展性和效率。

Abstract: In recent years, advanced deep learning architectures have shown strong
performance in medical imaging tasks. However, the traditional centralized
learning paradigm poses serious privacy risks as all data is collected and
trained on a single server. To mitigate this challenge, decentralized
approaches such as federated learning and swarm learning have emerged, allowing
model training on local nodes while sharing only model weights. While these
methods enhance privacy, they struggle with heterogeneous and imbalanced data
and suffer from inefficiencies due to frequent communication and the
aggregation of weights. More critically, the dynamic and complex nature of
clinical environments demands scalable AI systems capable of continuously
learning from diverse modalities and multilabels. Yet, both centralized and
decentralized models are prone to catastrophic forgetting during system
expansion, often requiring full model retraining to incorporate new data. To
address these limitations, we propose VGS-ATD, a novel distributed learning
framework. To validate VGS-ATD, we evaluate it in experiments spanning 30
datasets and 80 independent labels across distributed nodes, VGS-ATD achieved
an overall accuracy of 92.7%, outperforming centralized learning (84.9%) and
swarm learning (72.99%), while federated learning failed under these conditions
due to high requirements on computational resources. VGS-ATD also demonstrated
strong scalability, with only a 1% drop in accuracy on existing nodes after
expansion, compared to a 20% drop in centralized learning, highlighting its
resilience to catastrophic forgetting. Additionally, it reduced computational
costs by up to 50% relative to both centralized and swarm learning, confirming
its superior efficiency and scalability.

</details>


### [9] [Fuzzy Theory in Computer Vision: A Review](https://arxiv.org/abs/2507.18660)
*Adilet Yerkin,Ayan Igali,Elnara Kadyrgali,Maksat Shagyrov,Malika Ziyada,Muragul Muratbekova,Pakizar Shamoi*

Main category: cs.CV

TL;DR: 论文探讨模糊逻辑在计算机视觉中的应用，强调其在处理不确定性和噪声方面的优势，以及与深度学习的结合潜力。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉应用广泛，但传统方法在处理不确定性、噪声和不精确性时存在局限。模糊逻辑因其模拟渐进过渡和类人推理的能力，为计算机视觉提供了新的解决方案。

Method: 探讨了模糊聚类、模糊推理系统、类型2模糊集和模糊规则决策等关键技术，并分析了模糊逻辑与深度学习模型（如CNN）的集成。

Result: 模糊方法在对象识别、图像分割和特征提取等方面提供了更适应性强且可解释的解决方案，并与深度学习结合提升了复杂视觉任务的性能。

Conclusion: 模糊逻辑在计算机视觉中的应用展现出处理不确定性、噪声和不精确性的潜力，尤其在结合深度学习模型时表现突出。未来趋势包括混合模糊-深度学习模型和可解释AI的发展。

Abstract: Computer vision applications are omnipresent nowadays. The current paper
explores the use of fuzzy logic in computer vision, stressing its role in
handling uncertainty, noise, and imprecision in image data. Fuzzy logic is able
to model gradual transitions and human-like reasoning and provides a promising
approach to computer vision. Fuzzy approaches offer a way to improve object
recognition, image segmentation, and feature extraction by providing more
adaptable and interpretable solutions compared to traditional methods. We
discuss key fuzzy techniques, including fuzzy clustering, fuzzy inference
systems, type-2 fuzzy sets, and fuzzy rule-based decision-making. The paper
also discusses various applications, including medical imaging, autonomous
systems, and industrial inspection. Additionally, we explore the integration of
fuzzy logic with deep learning models such as convolutional neural networks
(CNNs) to enhance performance in complex vision tasks. Finally, we examine
emerging trends such as hybrid fuzzy-deep learning models and explainable AI.

</details>


### [10] [Eyes Will Shut: A Vision-Based Next GPS Location Prediction Model by Reinforcement Learning from Visual Map Feed Back](https://arxiv.org/abs/2507.18661)
*Ruixing Zhang,Yang Zhang,Tongyu Zhu,Leilei Sun,Weifeng Lv*

Main category: cs.CV

TL;DR: 论文提出VLMLocPredictor，通过视觉语言模型和强化学习实现人类式的下一位置预测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有下一位置预测模型缺乏人类基于地图的直观推理能力。视觉语言模型（VLM）的视觉感知和推理能力为模拟人类推理方式提供了新可能。

Method: 提出了VGLS方法评估通用VLM的轨迹推理能力，随后开发了VLMLocPredictor，包含两个阶段：1) 通过监督微调任务让VLM理解路网和轨迹结构；2) 引入基于视觉地图反馈的强化学习，使模型通过与环境交互自我提升。

Result: 在四个城市的数据集上，VLMLocPredictor实现了最先进的性能，并优于其他基于LLM的方法。

Conclusion: 通过结合视觉语言模型（VLM）和强化学习，VLMLocPredictor在下一位置预测任务中实现了最先进的性能，并展示了优秀的跨城市泛化能力。

Abstract: Next Location Prediction is a fundamental task in the study of human
mobility, with wide-ranging applications in transportation planning, urban
governance, and epidemic forecasting. In practice, when humans attempt to
predict the next location in a trajectory, they often visualize the trajectory
on a map and reason based on road connectivity and movement trends. However,
the vast majority of existing next-location prediction models do not reason
over maps \textbf{in the way that humans do}. Fortunately, the recent
development of Vision-Language Models (VLMs) has demonstrated strong
capabilities in visual perception and even visual reasoning. This opens up a
new possibility: by rendering both the road network and trajectory onto an
image and leveraging the reasoning abilities of VLMs, we can enable models to
perform trajectory inference in a human-like manner. To explore this idea, we
first propose a method called Vision-Guided Location Search (VGLS), which
evaluates whether a general-purpose VLM is capable of trajectory-based
reasoning without modifying any of its internal parameters. Based on insights
from the VGLS results, we further propose our main approach: VLMLocPredictor,
which is composed of two stages: In the first stage, we design two Supervised
Fine-Tuning (SFT) tasks that help the VLM understand road network and
trajectory structures and acquire basic reasoning ability on such visual
inputs. In the second stage, we introduce Reinforcement Learning from Visual
Map Feedback, enabling the model to self-improve its next-location prediction
ability through interaction with the environment. Experiments conducted on
datasets from four different cities show that our method achieves
state-of-the-art (SOTA) performance and exhibits superior cross-city
generalization compared to other LLM-based approaches.

</details>


### [11] [Gen-AI Police Sketches with Stable Diffusion](https://arxiv.org/abs/2507.18667)
*Nicholas Fidalgo,Aaron Contreras,Katherine Harvey,Johnny Ni*

Main category: cs.CV

TL;DR: 研究使用多模态AI方法优化嫌疑人素描，发现基线Stable Diffusion模型在图像质量和清晰度上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究多模态AI驱动方法以自动化和增强嫌疑人素描。

Method: 开发并评估了三种多模态AI驱动的管道：（1）基线图像到图像的Stable Diffusion模型，（2）与预训练CLIP模型集成的模型以对齐文本和图像，（3）结合LoRA微调CLIP模型的新方法，应用于自注意力和交叉注意力层，并与Stable Diffusion集成。消融研究确认微调自注意力和交叉注意力层能实现最佳的文本描述与草图对齐。

Result: Model 1在SSIM（0.72）和PSNR（25 dB）上表现最佳，优于Model 2和Model 3。迭代优化提高了感知相似性（LPIPS），Model 3优于Model 2但仍不及Model 1。定性评估显示Model 1生成的草图面部特征最清晰。

Conclusion: Model 1（基线图像到图像的Stable Diffusion模型）在结构相似性（SSIM）和峰值信噪比（PSNR）上表现最佳，尽管其简单性，但生成的草图具有最清晰的面部特征，显示出其稳健性。

Abstract: This project investigates the use of multimodal AI-driven approaches to
automate and enhance suspect sketching. Three pipelines were developed and
evaluated: (1) baseline image-to-image Stable Diffusion model, (2) same model
integrated with a pre-trained CLIP model for text-image alignment, and (3)
novel approach incorporating LoRA fine-tuning of the CLIP model, applied to
self-attention and cross-attention layers, and integrated with Stable
Diffusion. An ablation study confirmed that fine-tuning both self- and
cross-attention layers yielded the best alignment between text descriptions and
sketches. Performance testing revealed that Model 1 achieved the highest
structural similarity (SSIM) of 0.72 and a peak signal-to-noise ratio (PSNR) of
25 dB, outperforming Model 2 and Model 3. Iterative refinement enhanced
perceptual similarity (LPIPS), with Model 3 showing improvement over Model 2
but still trailing Model 1. Qualitatively, sketches generated by Model 1
demonstrated the clearest facial features, highlighting its robustness as a
baseline despite its simplicity.

</details>


### [12] [Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks](https://arxiv.org/abs/2507.18675)
*Sanyam Jain,Marsha Mariya Kappan,Vijeta Sharma*

Main category: cs.CV

TL;DR: 论文探讨了CLIP模型在医疗动作识别中的应用，通过掩码策略分析其局限性，并提出类别特定噪声增强方法，以提高准确性和减少偏差。


<details>
  <summary>Details</summary>
Motivation: 人类动作识别在医疗保健和医学中扮演关键角色，但传统模型如CNNs和RNNs在多样化和复杂动作上的泛化能力有限。视觉语言模型（如基于Transformer的CLIP模型）为视频数据的动作识别提供了新的可能性。

Method: 论文评估了CLIP在UCF-101数据集上的表现，并系统地分析了三种掩码策略下的性能。提出了通过自定义损失函数学习类别特定噪声的方法，以增强对类别定义特征的注意力。

Result: 研究发现CLIP在视觉线索被遮挡时表现不一致且频繁误分类。提出的增强方法提高了分类准确性和模型信心，同时减少了偏差。

Conclusion: 论文总结了在临床领域应用此类模型的挑战，并提出了未来工作方向，以提高在领域无关的医疗场景中的泛化能力。

Abstract: Human action recognition plays a critical role in healthcare and medicine,
supporting applications such as patient behavior monitoring, fall detection,
surgical robot supervision, and procedural skill assessment. While traditional
models like CNNs and RNNs have achieved moderate success, they often struggle
to generalize across diverse and complex actions. Recent advancements in
vision-language models, especially the transformer-based CLIP model, offer
promising capabilities for generalizing action recognition from video data. In
this work, we evaluate CLIP on the UCF-101 dataset and systematically analyze
its performance under three masking strategies: (1) percentage-based and
shape-based black masking at 10%, 30%, and 50%, (2) feature-specific masking to
suppress bias-inducing elements, and (3) isolation masking that retains only
class-specific regions. Our results reveal that CLIP exhibits inconsistent
behavior and frequent misclassifications, particularly when essential visual
cues are obscured. To overcome these limitations, we propose incorporating
class-specific noise, learned via a custom loss function, to reinforce
attention to class-defining features. This enhancement improves classification
accuracy and model confidence while reducing bias. We conclude with a
discussion on the challenges of applying such models in clinical domains and
outline directions for future work to improve generalizability across
domain-independent healthcare scenarios.

</details>


### [13] [HeartUnloadNet: A Weakly-Supervised Cycle-Consistent Graph Network for Predicting Unloaded Cardiac Geometry from Diastolic States](https://arxiv.org/abs/2507.18677)
*Siyu Mu,Wei Xuan Chan,Choon Hwai Yap*

Main category: cs.CV

TL;DR: HeartUnloadNet 是一种深度学习框架，通过图注意力架构和循环一致性策略，高效预测心脏无负载几何形状，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 估计心脏的无负载几何形状对于个性化生物力学建模至关重要，但传统方法计算成本高且依赖迭代优化。

Method: 采用图注意力架构和循环一致性策略，实现双向（加载和卸载）预测，通过部分自监督提高准确性并减少对大训练数据集的需求。

Result: 在 20,700 次有限元模拟中，HeartUnloadNet 实现了亚毫米精度，平均 DSC 为 0.986，HD 为 0.083 cm，推理时间缩短至每例 0.02 秒。

Conclusion: HeartUnloadNet 提供了一种可扩展且准确的替代传统逆有限元求解器的方法，支持未来的实时临床应用。

Abstract: The unloaded cardiac geometry (i.e., the state of the heart devoid of luminal
pressure) serves as a valuable zero-stress and zero-strain reference and is
critical for personalized biomechanical modeling of cardiac function, to
understand both healthy and diseased physiology and to predict the effects of
cardiac interventions. However, estimating the unloaded geometry from clinical
images remains a challenging task. Traditional approaches rely on inverse
finite element (FE) solvers that require iterative optimization and are
computationally expensive. In this work, we introduce HeartUnloadNet, a deep
learning framework that predicts the unloaded left ventricular (LV) shape
directly from the end diastolic (ED) mesh while explicitly incorporating
biophysical priors. The network accepts a mesh of arbitrary size along with
physiological parameters such as ED pressure, myocardial stiffness scale, and
fiber helix orientation, and outputs the corresponding unloaded mesh. It adopts
a graph attention architecture and employs a cycle-consistency strategy to
enable bidirectional (loading and unloading) prediction, allowing for partial
self-supervision that improves accuracy and reduces the need for large training
datasets. Trained and tested on 20,700 FE simulations across diverse LV
geometries and physiological conditions, HeartUnloadNet achieves sub-millimeter
accuracy, with an average DSC of 0.986 and HD of 0.083 cm, while reducing
inference time to just 0.02 seconds per case, over 10^5 times faster and
significantly more accurate than traditional inverse FE solvers. Ablation
studies confirm the effectiveness of the architecture. Notably, the
cycle-consistent design enables the model to maintain a DSC of 97% even with as
few as 200 training samples. This work thus presents a scalable and accurate
surrogate for inverse FE solvers, supporting real-time clinical applications in
the future.

</details>


### [14] [Towards Scalable Spatial Intelligence via 2D-to-3D Data Lifting](https://arxiv.org/abs/2507.18678)
*Xingyu Miao,Haoran Duan,Quanhao Qian,Jiuniu Wang,Yang Long,Ling Shao,Deli Zhao,Ran Xu,Gongjie Zhang*

Main category: cs.CV

TL;DR: 提出一种从单视图图像生成3D数据的管道，显著降低数据收集成本并推动空间智能发展。


<details>
  <summary>Details</summary>
Motivation: 解决大规模3D数据集稀缺的问题，利用丰富的2D图像资源填补3D数据需求与现有资源之间的差距。

Method: 集成了深度估计、相机校准和尺度校准，将单视图图像转换为全面的、尺度和外观真实的3D表示。

Result: 生成了两个空间数据集（COCO-3D和Objects365-v2-3D），并通过实验证明生成的数据可提升多种3D任务的性能。

Conclusion: 该研究提出了一种可扩展的管道，通过自动生成真实的、尺度感知的3D数据，显著降低了数据收集成本，并为推进空间智能开辟了新途径。

Abstract: Spatial intelligence is emerging as a transformative frontier in AI, yet it
remains constrained by the scarcity of large-scale 3D datasets. Unlike the
abundant 2D imagery, acquiring 3D data typically requires specialized sensors
and laborious annotation. In this work, we present a scalable pipeline that
converts single-view images into comprehensive, scale- and appearance-realistic
3D representations - including point clouds, camera poses, depth maps, and
pseudo-RGBD - via integrated depth estimation, camera calibration, and scale
calibration. Our method bridges the gap between the vast repository of imagery
and the increasing demand for spatial scene understanding. By automatically
generating authentic, scale-aware 3D data from images, we significantly reduce
data collection costs and open new avenues for advancing spatial intelligence.
We release two generated spatial datasets, i.e., COCO-3D and Objects365-v2-3D,
and demonstrate through extensive experiments that our generated data can
benefit various 3D tasks, ranging from fundamental perception to MLLM-based
reasoning. These results validate our pipeline as an effective solution for
developing AI systems capable of perceiving, understanding, and interacting
with physical environments.

</details>


### [15] [SaLF: Sparse Local Fields for Multi-Sensor Rendering in Real-Time](https://arxiv.org/abs/2507.18713)
*Yun Chen,Matthew Haines,Jingkang Wang,Krzysztof Baron-Lis,Sivabalan Manivasagam,Ze Yang,Raquel Urtasun*

Main category: cs.CV

TL;DR: SaLF是一种新型体积表示方法，支持多种传感器模拟，训练和渲染速度快，适用于大场景，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的NeRF和3DGS方法在自动驾驶传感器模拟中存在训练和渲染速度慢、传感器类型受限以及表示与渲染过程耦合的问题，限制了其通用性和可扩展性。SaLF旨在解决这些问题。

Method: SaLF通过稀疏的3D体素基元表示体积，每个体素是一个局部隐式场，结合了自适应修剪和密集化技术，以处理大场景，并支持非针孔相机和旋转LiDAR。

Result: SaLF实现了快速训练（<30分钟）和高效渲染（相机50+ FPS，LiDAR 600+ FPS），具有与现有方法相似的逼真度，同时在效率和能力上有所提升。

Conclusion: SaLF（Sparse Local Fields）作为一种新型的体积表示方法，支持光栅化和光线追踪，具有快速训练和渲染能力，能够适应大场景处理，并支持多种传感器类型，为自动驾驶传感器模拟提供了更高效和可扩展的解决方案。

Abstract: High-fidelity sensor simulation of light-based sensors such as cameras and
LiDARs is critical for safe and accurate autonomy testing. Neural radiance
field (NeRF)-based methods that reconstruct sensor observations via ray-casting
of implicit representations have demonstrated accurate simulation of driving
scenes, but are slow to train and render, hampering scale. 3D Gaussian
Splatting (3DGS) has demonstrated faster training and rendering times through
rasterization, but is primarily restricted to pinhole camera sensors,
preventing usage for realistic multi-sensor autonomy evaluation. Moreover, both
NeRF and 3DGS couple the representation with the rendering procedure (implicit
networks for ray-based evaluation, particles for rasterization), preventing
interoperability, which is key for general usage. In this work, we present
Sparse Local Fields (SaLF), a novel volumetric representation that supports
rasterization and raytracing. SaLF represents volumes as a sparse set of 3D
voxel primitives, where each voxel is a local implicit field. SaLF has fast
training (<30 min) and rendering capabilities (50+ FPS for camera and 600+ FPS
LiDAR), has adaptive pruning and densification to easily handle large scenes,
and can support non-pinhole cameras and spinning LiDARs. We demonstrate that
SaLF has similar realism as existing self-driving sensor simulation methods
while improving efficiency and enhancing capabilities, enabling more scalable
simulation. https://waabi.ai/salf/

</details>


### [16] [KuiSCIMA v2.0: Improved Baselines, Calibration, and Cross-Notation Generalization for Historical Chinese Music Notations in Jiang Kui's Baishidaoren Gequ](https://arxiv.org/abs/2507.18741)
*Tristan Repolusk,Eduardo Veas*

Main category: cs.CV

TL;DR: 本文提出了一种改进的光学音乐识别模型，显著提升了历史中国乐谱的识别准确率，特别是在数据稀缺和类别不平衡的情况下，推动了文化遗产的数字化。


<details>
  <summary>Details</summary>
Motivation: 解决历史中国乐谱因类别高度不平衡和训练数据有限而带来的识别挑战，特别是针对姜夔的《白石道人歌曲》集。

Method: 采用温度缩放技术优化模型校准，并使用留一版本交叉验证方法确保模型在五个历史版本中的鲁棒性。

Result: 将俗字谱的字符错误率（CER）从10.4%降至7.1%，律吕谱的CER达到0.9%，优于人类转录水平（平均CER 15.9%）。

Conclusion: 本研究通过改进的光学音乐识别（OMR）模型，显著提升了历史中国乐谱（如俗字谱和律吕谱）的识别准确率，推动了历史中国音乐的数字化和可访问性。

Abstract: Optical Music Recognition (OMR) for historical Chinese musical notations,
such as suzipu and l\"ul\"upu, presents unique challenges due to high class
imbalance and limited training data. This paper introduces significant
advancements in OMR for Jiang Kui's influential collection Baishidaoren Gequ
from 1202. In this work, we develop and evaluate a character recognition model
for scarce imbalanced data. We improve upon previous baselines by reducing the
Character Error Rate (CER) from 10.4% to 7.1% for suzipu, despite working with
77 highly imbalanced classes, and achieve a remarkable CER of 0.9% for
l\"ul\"upu. Our models outperform human transcribers, with an average human CER
of 15.9% and a best-case CER of 7.6%. We employ temperature scaling to achieve
a well-calibrated model with an Expected Calibration Error (ECE) below 0.0162.
Using a leave-one-edition-out cross-validation approach, we ensure robust
performance across five historical editions. Additionally, we extend the
KuiSCIMA dataset to include all 109 pieces from Baishidaoren Gequ, encompassing
suzipu, l\"ul\"upu, and jianzipu notations. Our findings advance the
digitization and accessibility of historical Chinese music, promoting cultural
diversity in OMR and expanding its applicability to underrepresented music
traditions.

</details>


### [17] [Diffusion-FS: Multimodal Free-Space Prediction via Diffusion for Autonomous Driving](https://arxiv.org/abs/2507.18763)
*Keshav Gupta,Tejas S. Stanley,Pranjal Paul,Arun K. Singh,K. Madhava Krishna*

Main category: cs.CV

TL;DR: 提出自监督方法ContourDiff，利用未来轨迹和单目图像预测可驾驶走廊，通过扩散模型和轮廓点去噪实现结构化预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接假设BEV表示难以获取，而将可驾驶自由空间走廊预测作为纯图像感知任务面临数据不足的挑战。

Method: 采用扩散过程建模图像中自由空间段的分布，并引入ContourDiff架构，基于轮廓点而非二值掩码表示进行去噪。

Result: 在nuScenes和CARLA数据集上的定性和定量评估表明，该方法能准确预测图像中的多模态安全可导航走廊。

Conclusion: 论文提出了一种新的自监督方法ContourDiff，通过利用未来自车轨迹和前方摄像头图像生成自由空间样本，有效预测图像中的可驾驶走廊。

Abstract: Drivable Free-space prediction is a fundamental and crucial problem in
autonomous driving. Recent works have addressed the problem by representing the
entire non-obstacle road regions as the free-space. In contrast our aim is to
estimate the driving corridors that are a navigable subset of the entire road
region. Unfortunately, existing corridor estimation methods directly assume a
BEV-centric representation, which is hard to obtain. In contrast, we frame
drivable free-space corridor prediction as a pure image perception task, using
only monocular camera input. However such a formulation poses several
challenges as one doesn't have the corresponding data for such free-space
corridor segments in the image. Consequently, we develop a novel
self-supervised approach for free-space sample generation by leveraging future
ego trajectories and front-view camera images, making the process of visual
corridor estimation dependent on the ego trajectory. We then employ a diffusion
process to model the distribution of such segments in the image. However, the
existing binary mask-based representation for a segment poses many limitations.
Therefore, we introduce ContourDiff, a specialized diffusion-based architecture
that denoises over contour points rather than relying on binary mask
representations, enabling structured and interpretable free-space predictions.
We evaluate our approach qualitatively and quantitatively on both nuScenes and
CARLA, demonstrating its effectiveness in accurately predicting safe multimodal
navigable corridors in the image.

</details>


### [18] [SAR-TEXT: A Large-Scale SAR Image-Text Dataset Built with SAR-Narrator and Progressive Transfer Learning](https://arxiv.org/abs/2507.18743)
*Xinjun Cheng,Yiguo He,Junjie Zhu,Chunping Qiu,Jun Wang,Qiangjuan Huang,Ke Yang*

Main category: cs.CV

TL;DR: 构建了大规模SAR图像-文本数据集SAR-Text，通过SAR-Narrator框架生成文本描述，显著提升了多个视觉语言任务的性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模高质量的SAR图像-文本数据集，SAR图像的语义理解受到限制。

Method: 通过多阶段渐进式迁移学习策略设计的SAR-Narrator框架，构建了包含13万对SAR图像-文本的大规模高质量数据集SAR-Text。

Result: SAR-RS-CLIP在检索任务中显著提升召回率；SAR-RS-CoCa在图像描述任务中各项指标远超原模型；SAR-GPT在VQA任务中表现出更强的语义理解和推理能力。

Conclusion: SAR-Text数据集和SAR-Narrator框架显著提升了SAR图像的语义理解能力，并在多个视觉语言任务中取得了显著成果。

Abstract: Vision Language Models (VLMs) have achieved remarkable breakthroughs in the
field of remote sensing in recent years. Synthetic Aperture Radar (SAR)
imagery, with its all-weather capability, is essential in remote sensing, yet
the lack of large-scale, high-quality SAR image-text datasets hinders its
semantic understanding. In this paper, we construct SAR-Text, a large-scale and
high-quality dataset consisting of over 130,000 SAR image-text pairs. To
construct the SAR-Text dataset, we design the SAR-Narrator framework, which
generates textual descriptions for SAR images through a multi-stage progressive
transfer learning strategy. To verify the effectiveness of the SAR-TEXT
dataset, we conduct experiments on three typical vision-language tasks:
image-text retrieval, image captioning, and visual question answering (VQA).
Specifically, we construct three representative models on SAR-TEXT:
SAR-RS-CLIP, SAR-RS-CoCa, and SAR-GPT. SAR-RS-CLIP achieves notable
improvements in retrieval performance, boosting average recall by 16.43% and
10.54% on the OSdataset-512 and HRSID test sets, respectively. In the
captioning task, SAR-RS-CoCa achieves BLEU-4, SPICE, and CIDEr scores exceeding
those of the original CoCa model by more than 8x, 4x, and 10x, respectively. In
the VQA task, SAR-GPT outperforms baseline and single-stage models on multiple
SAR-VQA datasets, demonstrating stronger semantic understanding and reasoning
ability, as further confirmed by qualitative results. It is worth noting that,
as a flexible captioning tool, SAR-Narrator can be readily adopted by the
community to construct larger-scale SAR image-text datasets.

</details>


### [19] [Perspective from a Higher Dimension: Can 3D Geometric Priors Help Visual Floorplan Localization?](https://arxiv.org/abs/2507.18881)
*Bolei Chen,Jiaxu Kang,Haonan Yang,Ping Zhong,Jianxin Wang*

Main category: cs.CV

TL;DR: 本文提出通过3D几何先验增强2D平面图定位，利用多视角约束和自监督学习，显著提升定位准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有2D平面图定位方法因视觉变化和遮挡导致的定位误差问题。

Method: 利用多视角约束和自监督对比学习，建模几何感知视图不变性和视图-场景对齐的几何先验。

Result: 在广泛的实际场景中验证，方法显著优于现有技术，大幅提升FLoc准确性。

Conclusion: 通过引入3D几何先验，本文提出的方法显著提升了2D平面图定位（FLoc）的准确性，无需额外注释，且计算负担未增加。

Abstract: Since a building's floorplans are easily accessible, consistent over time,
and inherently robust to changes in visual appearance, self-localization within
the floorplan has attracted researchers' interest. However, since floorplans
are minimalist representations of a building's structure, modal and geometric
differences between visual perceptions and floorplans pose challenges to this
task. While existing methods cleverly utilize 2D geometric features and pose
filters to achieve promising performance, they fail to address the localization
errors caused by frequent visual changes and view occlusions due to variously
shaped 3D objects. To tackle these issues, this paper views the 2D Floorplan
Localization (FLoc) problem from a higher dimension by injecting 3D geometric
priors into the visual FLoc algorithm. For the 3D geometric prior modeling, we
first model geometrically aware view invariance using multi-view constraints,
i.e., leveraging imaging geometric principles to provide matching constraints
between multiple images that see the same points. Then, we further model the
view-scene aligned geometric priors, enhancing the cross-modal geometry-color
correspondences by associating the scene's surface reconstruction with the RGB
frames of the sequence. Both 3D priors are modeled through self-supervised
contrastive learning, thus no additional geometric or semantic annotations are
required. These 3D priors summarized in extensive realistic scenes bridge the
modal gap while improving localization success without increasing the
computational burden on the FLoc algorithm. Sufficient comparative studies
demonstrate that our method significantly outperforms state-of-the-art methods
and substantially boosts the FLoc accuracy. All data and code will be released
after the anonymous review.

</details>


### [20] [Learning Efficient and Generalizable Human Representation with Human Gaussian Model](https://arxiv.org/abs/2507.18758)
*Yifan Liu,Shengjun Zhang,Chensheng Dai,Yang Chen,Hao Liu,Chen Li,Yueqi Duan*

Main category: cs.CV

TL;DR: 提出 Human Gaussian Graph 方法，通过双层次结构和节点操作建模高斯与 SMPL 网格的关系，显著提升了动画人体建模的效果。


<details>
  <summary>Details</summary>
Motivation: 现有的前馈方法独立预测每帧的高斯分布，未能充分利用不同时间戳高斯之间的关系，因此需要一种更有效的方法来建模可动画的人体表示。

Method: 提出了 Human Gaussian Graph 的双层次结构，其中第一层为高斯节点，第二层为 SMPL 网格顶点节点，并设计了 intra-node 和 inter-node 操作来聚合信息和传递消息。

Result: 实验证明，该方法在新颖视角合成和姿态动画中表现出高效性和良好的泛化能力。

Conclusion: Human Gaussian Graph 通过双层次结构和节点操作，有效提升了动画人体建模的效率和泛化能力，实验结果表明其在新颖视角合成和姿态动画中的优越性能。

Abstract: Modeling animatable human avatars from videos is a long-standing and
challenging problem. While conventional methods require per-instance
optimization, recent feed-forward methods have been proposed to generate 3D
Gaussians with a learnable network. However, these methods predict Gaussians
for each frame independently, without fully capturing the relations of
Gaussians from different timestamps. To address this, we propose Human Gaussian
Graph to model the connection between predicted Gaussians and human SMPL mesh,
so that we can leverage information from all frames to recover an animatable
human representation. Specifically, the Human Gaussian Graph contains dual
layers where Gaussians are the first layer nodes and mesh vertices serve as the
second layer nodes. Based on this structure, we further propose the intra-node
operation to aggregate various Gaussians connected to one mesh vertex, and
inter-node operation to support message passing among mesh node neighbors.
Experimental results on novel view synthesis and novel pose animation
demonstrate the efficiency and generalization of our method.

</details>


### [21] [EffiComm: Bandwidth Efficient Multi Agent Communication](https://arxiv.org/abs/2507.19354)
*Melih Yazgan,Allen Xavier Arasan,J. Marius Zöllner*

Main category: cs.CV

TL;DR: EffiComm通过选择性传输和自适应网格缩减减少数据传输量，同时保持高精度3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决V2V通信中传输原始点云或完整特征图导致的延迟和可扩展性问题。

Method: EffiComm采用两阶段数据缩减管道：选择性传输(ST)剪枝低效用区域，自适应网格缩减(AGR)根据车辆角色和网络负载分配保留比例，最后通过软门控混合专家(MoE)注意力层融合特征。

Result: 在OPV2V基准测试中，EffiComm达到0.84 mAP@0.7，每帧平均仅传输约1.5 MB，优于现有方法。

Conclusion: EffiComm通过自适应学习通信策略，在保持高精度的同时显著减少了数据传输量，为可扩展的V2X感知提供了有效解决方案。

Abstract: Collaborative perception allows connected vehicles to exchange sensor
information and overcome each vehicle's blind spots. Yet transmitting raw point
clouds or full feature maps overwhelms Vehicle-to-Vehicle (V2V) communications,
causing latency and scalability problems. We introduce EffiComm, an end-to-end
framework that transmits less than 40% of the data required by prior art while
maintaining state-of-the-art 3D object detection accuracy. EffiComm operates on
Bird's-Eye-View (BEV) feature maps from any modality and applies a two-stage
reduction pipeline: (1) Selective Transmission (ST) prunes low-utility regions
with a confidence mask; (2) Adaptive Grid Reduction (AGR) uses a Graph Neural
Network (GNN) to assign vehicle-specific keep ratios according to role and
network load. The remaining features are fused with a soft-gated
Mixture-of-Experts (MoE) attention layer, offering greater capacity and
specialization for effective feature integration. On the OPV2V benchmark,
EffiComm reaches 0.84 mAP@0.7 while sending only an average of approximately
1.5 MB per frame, outperforming previous methods on the accuracy-per-bit curve.
These results highlight the value of adaptive, learned communication for
scalable Vehicle-to-Everything (V2X) perception.

</details>


### [22] [Tell Me What You See: An Iterative Deep Learning Framework for Image Captioning](https://arxiv.org/abs/2507.18788)
*Hitesh Kumar Gupta*

Main category: cs.CV

TL;DR: 该论文通过迭代开发验证了注意力机制在图像描述任务中的重要性，最终模型Nexus表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索图像描述任务中视觉主干与注意力机制的协同作用，验证传统CNN-LSTM范式中单纯升级视觉主干可能导致的性能下降问题。

Method: 研究从简单的CNN-LSTM编码器-解码器开始，逐步发展到具有EfficientNetV2B3主干和动态注意力机制的先进模型Nexus。通过实验验证了架构改进的影响。

Result: 最终模型Nexus在MS COCO 2017数据集上取得了BLEU-4得分31.4，超越了多个基准模型。

Conclusion: 该研究通过系统化的迭代开发，验证了注意力机制在现代视觉-语言任务中的核心作用，并提供了一个清晰、可复现的架构设计蓝图。

Abstract: Image captioning, a task at the confluence of computer vision and natural
language processing, requires a sophisticated understanding of both visual
scenes and linguistic structure. While modern approaches are dominated by
large-scale Transformer architectures, this paper documents a systematic,
iterative development of foundational image captioning models, progressing from
a simple CNN-LSTM encoder-decoder to a competitive attention-based system. We
present a series of five models, beginning with Genesis and concluding with
Nexus, an advanced model featuring an EfficientNetV2B3 backbone and a dynamic
attention mechanism. Our experiments chart the impact of architectural
enhancements and demonstrate a key finding within the classic CNN-LSTM
paradigm: merely upgrading the visual backbone without a corresponding
attention mechanism can degrade performance, as the single-vector bottleneck
cannot transmit the richer visual detail. This insight validates the
architectural shift to attention. Trained on the MS COCO 2017 dataset, our
final model, Nexus, achieves a BLEU-4 score of 31.4, surpassing several
foundational benchmarks and validating our iterative design process. This work
provides a clear, replicable blueprint for understanding the core architectural
principles that underpin modern vision-language tasks.

</details>


### [23] [Fast Learning of Non-Cooperative Spacecraft 3D Models through Primitive Initialization](https://arxiv.org/abs/2507.19459)
*Pol Francesch Huc,Emily Bates,Simone D'Amico*

Main category: cs.CV

TL;DR: 该论文提出了一种基于CNN的3DGS初始化方法，显著降低了训练成本和姿态需求，适用于空间应用。


<details>
  <summary>Details</summary>
Motivation: NeRF和3DGS等新视角合成技术存在训练时需要精确姿态和高计算成本的限制，阻碍了其在空间应用中的使用。

Method: 提出了一种基于CNN的3DGS基元初始化器，能够从单目图像生成粗略3D模型，并结合多种姿态估计变体，显著降低了训练成本。

Result: 实验表明，即使姿态估计不完美，该流程仍能学习高保真3D表示，训练迭代和输入图像需求减少至少一个数量级。

Conclusion: 该研究通过CNN基元初始化器和改进的流程，成功解决了NeRF和3DGS在空间应用中需要精确姿态和高计算成本的问题，为空间应用中的新视角合成技术打开了大门。

Abstract: The advent of novel view synthesis techniques such as NeRF and 3D Gaussian
Splatting (3DGS) has enabled learning precise 3D models only from posed
monocular images. Although these methods are attractive, they hold two major
limitations that prevent their use in space applications: they require poses
during training, and have high computational cost at training and inference. To
address these limitations, this work contributes: (1) a Convolutional Neural
Network (CNN) based primitive initializer for 3DGS using monocular images; (2)
a pipeline capable of training with noisy or implicit pose estimates; and (3)
and analysis of initialization variants that reduce the training cost of
precise 3D models. A CNN takes a single image as input and outputs a coarse 3D
model represented as an assembly of primitives, along with the target's pose
relative to the camera. This assembly of primitives is then used to initialize
3DGS, significantly reducing the number of training iterations and input images
needed -- by at least an order of magnitude. For additional flexibility, the
CNN component has multiple variants with different pose estimation techniques.
This work performs a comparison between these variants, evaluating their
effectiveness for downstream 3DGS training under noisy or implicit pose
estimates. The results demonstrate that even with imperfect pose supervision,
the pipeline is able to learn high-fidelity 3D representations, opening the
door for the use of novel view synthesis in space applications.

</details>


### [24] [Deepfake Detection Via Facial Feature Extraction and Modeling](https://arxiv.org/abs/2507.18815)
*Benjamin Carter,Nathan Dilla,Micheal Callahan,Atuhaire Ambala*

Main category: cs.CV

TL;DR: 本文提出了一种基于面部标志点的深度伪造检测方法，通过识别面部动作的细微不一致，展示了在多种神经网络模型中的有效性，挑战了传统图像处理的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造技术的发展，区分真实与AI生成的媒体变得愈发困难，亟需新的检测模型。现有方法多集中于直接图像处理，本研究旨在探索一种不依赖原始图像处理的新途径。

Method: 本文介绍了一种仅使用面部标志点进行深度伪造检测的方法，通过提取面部标志点来识别面部动作中的细微不一致，而非直接处理原始图像数据。

Result: 实验结果显示，该面部特征提取技术在多种神经网络模型中表现良好，其中RNN和ANN模型的准确率分别达到96%和93%，CNN模型约为78%。

Conclusion: 本研究挑战了通过原始图像处理识别深度伪造视频的必要性，提出了一种基于面部特征提取的方法，该方法兼容多种神经网络模型且参数需求较少。

Abstract: The rise of deepfake technology brings forth new questions about the
authenticity of various forms of media found online today. Videos and images
generated by artificial intelligence (AI) have become increasingly more
difficult to differentiate from genuine media, resulting in the need for new
models to detect artificially-generated media. While many models have attempted
to solve this, most focus on direct image processing, adapting a convolutional
neural network (CNN) or a recurrent neural network (RNN) that directly
interacts with the video image data. This paper introduces an approach of using
solely facial landmarks for deepfake detection. Using a dataset consisting of
both deepfake and genuine videos of human faces, this paper describes an
approach for extracting facial landmarks for deepfake detection, focusing on
identifying subtle inconsistencies in facial movements instead of raw image
processing. Experimental results demonstrated that this feature extraction
technique is effective in various neural network models, with the same facial
landmarks tested on three neural network models, with promising performance
metrics indicating its potential for real-world applications. The findings
discussed in this paper include RNN and artificial neural network (ANN) models
with accuracy between 96% and 93%, respectively, with a CNN model hovering
around 78%. This research challenges the assumption that raw image processing
is necessary to identify deepfake videos by presenting a facial feature
extraction approach compatible with various neural network models while
requiring fewer parameters.

</details>


### [25] [Efficient Lines Detection for Robot Soccer](https://arxiv.org/abs/2507.19469)
*João G. Melo,João P. Mafaldo,Edna Barros*

Main category: cs.CV

TL;DR: 提出了一种基于ELSED算法和PSO的轻量级高效足球场线条检测方法，适用于实时低功耗机器人平台。


<details>
  <summary>Details</summary>
Motivation: 在机器人足球中，自我定位至关重要，准确检测视野特征（如线条和边界）对可靠姿态估计至关重要。

Method: 使用ELSED算法扩展了分类步骤，通过分析RGB颜色过渡来识别球场线条，并引入基于粒子群优化(PSO)的阈值校准管道。

Result: 该方法在仅需少量标注样本的情况下，优化了检测性能，达到了与深度学习模型相当的准确性。

Conclusion: 该方法在低功耗机器人平台上实现了与最先进深度学习模型相当的准确性，同时提供更高的处理速度，适合实时应用。

Abstract: Self-localization is essential in robot soccer, where accurate detection of
visual field features, such as lines and boundaries, is critical for reliable
pose estimation. This paper presents a lightweight and efficient method for
detecting soccer field lines using the ELSED algorithm, extended with a
classification step that analyzes RGB color transitions to identify lines
belonging to the field. We introduce a pipeline based on Particle Swarm
Optimization (PSO) for threshold calibration to optimize detection performance,
requiring only a small number of annotated samples. Our approach achieves
accuracy comparable to a state-of-the-art deep learning model while offering
higher processing speed, making it well-suited for real-time applications on
low-power robotic platforms.

</details>


### [26] [Flow Stochastic Segmentation Networks](https://arxiv.org/abs/2507.18838)
*Fabio De Sousa Ribeiro,Omar Todd,Charles Jones,Avinash Kori,Raghav Mehta,Ben Glocker*

Main category: cs.CV

TL;DR: Flow-SSNs是一种高效生成分割模型，通过离散和连续时间流变体解决低秩限制，在医学影像中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决先前方法低秩参数化的根本限制，提高生成分割模型的效率和表达能力。

Method: Flow-SSNs采用离散时间自回归和现代连续时间流变体，能够估计任意高秩像素协方差，无需假设秩或存储分布参数。

Result: Flow-SSNs在采样效率上优于基于扩散的标准分割模型，并在医学影像基准测试中达到最先进水平。

Conclusion: Flow-SSNs在医学影像基准测试中取得了最先进的结果，证明了其高效性和表达能力的优势。

Abstract: We introduce the Flow Stochastic Segmentation Network (Flow-SSN), a
generative segmentation model family featuring discrete-time autoregressive and
modern continuous-time flow variants. We prove fundamental limitations of the
low-rank parameterisation of previous methods and show that Flow-SSNs can
estimate arbitrarily high-rank pixel-wise covariances without assuming the rank
or storing the distributional parameters. Flow-SSNs are also more efficient to
sample from than standard diffusion-based segmentation models, thanks to most
of the model capacity being allocated to learning the base distribution of the
flow, constituting an expressive prior. We apply Flow-SSNs to challenging
medical imaging benchmarks and achieve state-of-the-art results. Code
available: https://github.com/biomedia-mira/flow-ssn.

</details>


### [27] [PTCMIL: Multiple Instance Learning via Prompt Token Clustering for Whole Slide Image Analysis](https://arxiv.org/abs/2507.18848)
*Beidi Zhao,SangMook Kim,Hao Chen,Chen Zhou,Zu-hua Gao,Gang Wang,Xiaoxiao Li*

Main category: cs.CV

TL;DR: PTCMIL是一种基于Prompt Token聚类的ViT方法，用于MIL聚合，通过端到端框架动态对齐聚类与下游任务，显著提升WSI分析性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法在处理WSI的复杂性和异质性时面临挑战，ViT和聚类方法虽有效但计算量大且无法捕捉任务和切片特异性。

Method: PTCMIL通过引入可学习的prompt tokens到ViT骨干网络中，将聚类和预测任务统一为端到端框架，采用投影聚类和原型池化来高效捕获任务相关模式。

Result: 在8个数据集上的实验表明，PTCMIL在分类和生存分析任务中表现优异，系统消融研究证实了其鲁棒性和强解释性。

Conclusion: PTCMIL提出了一种新颖的Prompt Token聚类方法，显著提升了WSI分析的性能，并在分类和生存分析任务中优于现有方法。

Abstract: Multiple Instance Learning (MIL) has advanced WSI analysis but struggles with
the complexity and heterogeneity of WSIs. Existing MIL methods face challenges
in aggregating diverse patch information into robust WSI representations. While
ViTs and clustering-based approaches show promise, they are computationally
intensive and fail to capture task-specific and slide-specific variability. To
address these limitations, we propose PTCMIL, a novel Prompt Token
Clustering-based ViT for MIL aggregation. By introducing learnable prompt
tokens into the ViT backbone, PTCMIL unifies clustering and prediction tasks in
an end-to-end manner. It dynamically aligns clustering with downstream tasks,
using projection-based clustering tailored to each WSI, reducing complexity
while preserving patch heterogeneity. Through token merging and prototype-based
pooling, PTCMIL efficiently captures task-relevant patterns. Extensive
experiments on eight datasets demonstrate its superior performance in
classification and survival analysis tasks, outperforming state-of-the-art
methods. Systematic ablation studies confirm its robustness and strong
interpretability. The code is released at https://github.com/ubc-tea/PTCMIL.

</details>


### [28] [Phoneme-Level Visual Speech Recognition via Point-Visual Fusion and Language Model Reconstruction](https://arxiv.org/abs/2507.18863)
*Matthew Kit Khinn Teng,Haibo Zhang,Takeshi Saitoh*

Main category: cs.CV

TL;DR: 论文提出了一种基于音素的两阶段V-ASR方法，结合视觉与地标特征和LLM模型，显著降低了词错误率。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接从视觉线索预测单词或字符，但由于音素视觉模糊性（viseme歧义）和高错误率，效果不佳。本文旨在通过音素预测和LLM模型重建来解决这些问题。

Method: 提出了一个基于音素的两阶段框架：第一阶段融合视觉和地标运动特征进行V-ASR，输出预测音素；第二阶段使用NLLB（LLM模型）将音素重建为单词。

Result: PV-ASR在LRS2和LRS3数据集上分别实现了17.4%和21.0%的词错误率（WER），性能优于现有方法。

Conclusion: 提出的PV-ASR方法通过两阶段框架（视觉特征与地标特征融合，LLM模型单词重建）显著提升了V-ASR性能，在LRS2和LRS3数据集上分别达到17.4%和21.0%的WER。

Abstract: Visual Automatic Speech Recognition (V-ASR) is a challenging task that
involves interpreting spoken language solely from visual information, such as
lip movements and facial expressions. This task is notably challenging due to
the absence of auditory cues and the visual ambiguity of phonemes that exhibit
similar visemes-distinct sounds that appear identical in lip motions. Existing
methods often aim to predict words or characters directly from visual cues, but
they commonly suffer from high error rates due to viseme ambiguity and require
large amounts of pre-training data. We propose a novel phoneme-based two-stage
framework that fuses visual and landmark motion features, followed by an LLM
model for word reconstruction to address these challenges. Stage 1 consists of
V-ASR, which outputs the predicted phonemes, thereby reducing training
complexity. Meanwhile, the facial landmark features address speaker-specific
facial characteristics. Stage 2 comprises an encoder-decoder LLM model, NLLB,
that reconstructs the output phonemes back to words. Besides using a large
visual dataset for deep learning fine-tuning, our PV-ASR method demonstrates
superior performance by achieving 17.4% WER on the LRS2 and 21.0% WER on the
LRS3 dataset.

</details>


### [29] [Transferable and Undefendable Point Cloud Attacks via Medial Axis Transform](https://arxiv.org/abs/2507.18870)
*Keke Tang,Yuze Gao,Weilong Peng,Xiaofei Wang,Meie Fang,Peican Zhu*

Main category: cs.CV

TL;DR: MAT-Adv通过扰动点云的中轴变换表示提升对抗攻击的迁移性和不可防御性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在白盒设置下效果良好，但在迁移性和对抗防御机制方面表现不足。

Method: 采用自编码器将输入点云投影为紧凑的MAT表示，通过扰动这些内在表示引入结构级对抗特性，并引入dropout策略优化扰动。

Result: 实验表明MAT-Adv在迁移性和不可防御性上显著优于现有方法。

Conclusion: MAT-Adv通过扰动点云的中轴变换（MAT）表示，显著提升了对抗攻击的迁移性和不可防御性，优于现有方法。

Abstract: Studying adversarial attacks on point clouds is essential for evaluating and
improving the robustness of 3D deep learning models. However, most existing
attack methods are developed under ideal white-box settings and often suffer
from limited transferability to unseen models and insufficient robustness
against common defense mechanisms. In this paper, we propose MAT-Adv, a novel
adversarial attack framework that enhances both transferability and
undefendability by explicitly perturbing the medial axis transform (MAT)
representations, in order to induce inherent adversarialness in the resulting
point clouds. Specifically, we employ an autoencoder to project input point
clouds into compact MAT representations that capture the intrinsic geometric
structure of point clouds. By perturbing these intrinsic representations,
MAT-Adv introduces structural-level adversarial characteristics that remain
effective across diverse models and defense strategies. To mitigate overfitting
and prevent perturbation collapse, we incorporate a dropout strategy into the
optimization of MAT perturbations, further improving transferability and
undefendability. Extensive experiments demonstrate that MAT-Adv significantly
outperforms existing state-of-the-art methods in both transferability and
undefendability. Codes will be made public upon paper acceptance.

</details>


### [30] [WiSE-OD: Benchmarking Robustness in Infrared Object Detection](https://arxiv.org/abs/2507.18925)
*Heitor R. Medeiros,Atif Belal,Masih Aminbeidokhti,Eric Granger,Marco Pedersoli*

Main category: cs.CV

TL;DR: 本文提出WiSE-OD方法，通过权重空间集成提升红外图像目标检测的跨模态和抗干扰鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决红外图像目标检测中因模态差异导致的分布偏移鲁棒性问题。

Method: 提出了WiSE-OD，一种权重空间集成方法，包括WiSE-OD$_{ZS}$和WiSE-OD$_{LP}$两种变体。

Result: WiSE-OD在三个RGB预训练检测器和两个鲁棒基线上的评估显示，其在跨模态和抗干扰方面表现更优。

Conclusion: WiSE-OD方法在不增加训练或推理成本的情况下，提高了跨模态和抗干扰的鲁棒性。

Abstract: Object detection (OD) in infrared (IR) imagery is critical for low-light and
nighttime applications. However, the scarcity of large-scale IR datasets forces
models to rely on weights pre-trained on RGB images. While fine-tuning on IR
improves accuracy, it often compromises robustness under distribution shifts
due to the inherent modality gap between RGB and IR. To address this, we
introduce LLVIP-C and FLIR-C, two cross-modality out-of-distribution (OOD)
benchmarks built by applying corruption to standard IR datasets. Additionally,
to fully leverage the complementary knowledge from RGB and infrared trained
models, we propose WiSE-OD, a weight-space ensembling method with two variants:
WiSE-OD$_{ZS}$, which combines RGB zero-shot and IR fine-tuned weights, and
WiSE-OD$_{LP}$, which blends zero-shot and linear probing. Evaluated across
three RGB-pretrained detectors and two robust baselines, WiSE-OD improves both
cross-modality and corruption robustness without any additional training or
inference cost.

</details>


### [31] [MGHFT: Multi-Granularity Hierarchical Fusion Transformer for Cross-Modal Sticker Emotion Recognition](https://arxiv.org/abs/2507.18929)
*Jian Chen,Yuxuan Hu,Haifeng Lu,Wei Wang,Min Yang,Chengming Li,Xiping Hu*

Main category: cs.CV

TL;DR: MGHFT通过多模态大语言模型和层次融合Transformer，显著提升贴纸情感识别的准确性和细粒度。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练视觉模型在视觉特征提取方面表现出色，但贴纸情感理解仍依赖多视角信息（如背景知识和风格线索），现有方法难以有效融合这些信息。

Method: 提出了一种新颖的多粒度层次融合Transformer（MGHFT），结合多模态大语言模型的多视角贴纸解释器，通过对比学习和注意力机制将文本特征注入视觉主干的不同阶段，并设计文本引导的融合注意力机制整合多模态特征。

Result: 在2个公开的贴纸情感数据集上，MGHFT显著优于现有方法，F1值提升5.4%，准确率提升4.0%。

Conclusion: MGHFT通过多粒度层次融合Transformer和基于多模态大语言模型的多视角贴纸解释器，显著提升了贴纸情感识别的准确性和细粒度，优于现有方法。

Abstract: Although pre-trained visual models with text have demonstrated strong
capabilities in visual feature extraction, sticker emotion understanding
remains challenging due to its reliance on multi-view information, such as
background knowledge and stylistic cues. To address this, we propose a novel
multi-granularity hierarchical fusion transformer (MGHFT), with a multi-view
sticker interpreter based on Multimodal Large Language Models. Specifically,
inspired by the human ability to interpret sticker emotions from multiple
views, we first use Multimodal Large Language Models to interpret stickers by
providing rich textual context via multi-view descriptions. Then, we design a
hierarchical fusion strategy to fuse the textual context into visual
understanding, which builds upon a pyramid visual transformer to extract both
global and local sticker features at multiple stages. Through contrastive
learning and attention mechanisms, textual features are injected at different
stages of the visual backbone, enhancing the fusion of global- and
local-granularity visual semantics with textual guidance. Finally, we introduce
a text-guided fusion attention mechanism to effectively integrate the overall
multimodal features, enhancing semantic understanding. Extensive experiments on
2 public sticker emotion datasets demonstrate that MGHFT significantly
outperforms existing sticker emotion recognition approaches, achieving higher
accuracy and more fine-grained emotion recognition. Compared to the best
pre-trained visual models, our MGHFT also obtains an obvious improvement, 5.4%
on F1 and 4.0% on accuracy. The code is released at
https://github.com/cccccj-03/MGHFT_ACMMM2025.

</details>


### [32] [Underwater Waste Detection Using Deep Learning A Performance Comparison of YOLOv7 to 10 and Faster RCNN](https://arxiv.org/abs/2507.18967)
*UMMPK Nawarathne,HMNS Kumari,HMLS Kumari*

Main category: cs.CV

TL;DR: 研究比较五种目标识别算法，YOLOv8以80.9% mAP表现最佳，适用于水下垃圾检测。


<details>
  <summary>Details</summary>
Motivation: 水下污染是当前重大环境问题之一，准确检测垃圾材料对废物管理和环境监测至关重要。

Method: 研究比较了五种先进的目标识别算法（YOLOv7、YOLOv8、YOLOv9、YOLOv10和Faster R-CNN），在包含15个类别的多样化条件下训练和测试。

Result: YOLOv8在性能上超越其他模型，归功于其改进的无锚机制和自监督学习等先进特征。

Conclusion: YOLOv8模型在识别水下垃圾材料方面表现最佳，其80.9%的平均精度（mAP）表明其作为全球污染治理工具有显著潜力。

Abstract: Underwater pollution is one of today's most significant environmental
concerns, with vast volumes of garbage found in seas, rivers, and landscapes
around the world. Accurate detection of these waste materials is crucial for
successful waste management, environmental monitoring, and mitigation
strategies. In this study, we investigated the performance of five cutting-edge
object recognition algorithms, namely YOLO (You Only Look Once) models,
including YOLOv7, YOLOv8, YOLOv9, YOLOv10, and Faster Region-Convolutional
Neural Network (R-CNN), to identify which model was most effective at
recognizing materials in underwater situations. The models were thoroughly
trained and tested on a large dataset containing fifteen different classes
under diverse conditions, such as low visibility and variable depths. From the
above-mentioned models, YOLOv8 outperformed the others, with a mean Average
Precision (mAP) of 80.9%, indicating a significant performance. This increased
performance is attributed to YOLOv8's architecture, which incorporates advanced
features such as improved anchor-free mechanisms and self-supervised learning,
allowing for more precise and efficient recognition of items in a variety of
settings. These findings highlight the YOLOv8 model's potential as an effective
tool in the global fight against pollution, improving both the detection
capabilities and scalability of underwater cleanup operations.

</details>


### [33] [Synthetic-to-Real Camouflaged Object Detection](https://arxiv.org/abs/2507.18911)
*Zhihao Luo,Luojun Lin,Zheng Lin*

Main category: cs.CV

TL;DR: 提出CSRDA框架，通过循环学习和伪标签解决COD任务中合成数据与真实数据之间的适应问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于数据收集和标注成本高，伪装目标检测（COD）的数据集较少，尤其是某些特定类别。合成数据集可以部分缓解数据有限的问题，但直接使用合成数据集训练会导致模型性能下降。

Method: 基于学生-教师模型，提出了循环合成到真实领域适应框架（CSRDA），通过伪标签和一致性正则化将类信息从标记的源域传播到未标记的目标域。

Result: 通过广泛的实验验证了CSRDA框架的有效性，能够缓解COD任务中数据有限和手工标注的问题。

Conclusion: 提出的CSRDA框架通过循环学习框架和伪标签结合一致性正则化，有效缓解了COD任务中数据有限和手工标注的问题，并在实验中证明了其有效性。

Abstract: Due to the high cost of collection and labeling, there are relatively few
datasets for camouflaged object detection (COD). In particular, for certain
specialized categories, the available image dataset is insufficiently
populated. Synthetic datasets can be utilized to alleviate the problem of
limited data to some extent. However, directly training with synthetic datasets
compared to real datasets can lead to a degradation in model performance. To
tackle this problem, in this work, we investigate a new task, namely
Syn-to-Real Camouflaged Object Detection (S2R-COD). In order to improve the
model performance in real world scenarios, a set of annotated synthetic
camouflaged images and a limited number of unannotated real images must be
utilized. We propose the Cycling Syn-to-Real Domain Adaptation Framework
(CSRDA), a method based on the student-teacher model. Specially, CSRDA
propagates class information from the labeled source domain to the unlabeled
target domain through pseudo labeling combined with consistency regularization.
Considering that narrowing the intra-domain gap can improve the quality of
pseudo labeling, CSRDA utilizes a recurrent learning framework to build an
evolving real domain for bridging the source and target domain. Extensive
experiments demonstrate the effectiveness of our framework, mitigating the
problem of limited data and handcraft annotations in COD. Our code is publicly
available at: https://github.com/Muscape/S2R-COD

</details>


### [34] [MedIQA: A Scalable Foundation Model for Prompt-Driven Medical Image Quality Assessment](https://arxiv.org/abs/2507.19004)
*Siyi Xun,Yue Sun,Jingkun Chen,Zitong Yu,Tong Tong,Xiaohong Liu,Mingxiang Wu,Tao Tan*

Main category: cs.CV

TL;DR: MedIQA 是首个综合性医学图像质量评估基础模型，通过多模态数据集和自动提示策略，显著提升评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像质量评估方法难以适应不同模态和临床场景的多样性，因此需要一种通用的基础模型来应对这些挑战。

Method: 开发了一个大规模多模态数据集，并集成了显著切片评估模块和自动提示策略，以对齐上游物理参数预训练和下游专家标注微调。

Result: MedIQA 在多个下游任务中显著优于基线方法。

Conclusion: MedIQA 建立了一个可扩展的医学图像质量评估框架，显著提升了诊断工作流程和临床决策的准确性。

Abstract: Rapid advances in medical imaging technology underscore the critical need for
precise and automated image quality assessment (IQA) to ensure diagnostic
accuracy. Existing medical IQA methods, however, struggle to generalize across
diverse modalities and clinical scenarios. In response, we introduce MedIQA,
the first comprehensive foundation model for medical IQA, designed to handle
variability in image dimensions, modalities, anatomical regions, and types. We
developed a large-scale multi-modality dataset with plentiful manually
annotated quality scores to support this. Our model integrates a salient slice
assessment module to focus on diagnostically relevant regions feature retrieval
and employs an automatic prompt strategy that aligns upstream physical
parameter pre-training with downstream expert annotation fine-tuning. Extensive
experiments demonstrate that MedIQA significantly outperforms baselines in
multiple downstream tasks, establishing a scalable framework for medical IQA
and advancing diagnostic workflows and clinical decision-making.

</details>


### [35] [HQ-SMem: Video Segmentation and Tracking Using Memory Efficient Object Embedding With Selective Update and Self-Supervised Distillation Feedback](https://arxiv.org/abs/2507.18921)
*Elham Soltani Kazemi,Imad Eddine Toubal,Gani Rahmon,Jaired Collins,K. Palaniappan*

Main category: cs.CV

TL;DR: HQ-SMem通过高精度掩码、智能内存和动态外观模型，显著提升视频对象分割性能，尤其在复杂场景和长视频中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割模型在精确掩码描绘、可变形对象、拓扑变换对象、跟踪漂移和长视频序列等方面存在局限，HQ-SMem旨在解决这些问题。

Method: 1. 使用SAM-HQ高精度掩码和基于外观的候选选择优化粗分割掩码；2. 动态智能内存机制选择性地存储关键帧；3. 动态更新外观模型以处理复杂拓扑变化和减少漂移。

Result: 在VOTS和VOTSt 2024数据集上排名前二，并在Long Video Dataset和LVOS上创下新基准，展示了其在复杂多对象动态和长时视频中的有效性。

Conclusion: HQ-SMem通过引入SAM-HQ高精度掩码、动态智能内存机制和动态更新外观模型，显著提升了视频对象分割的性能，尤其在复杂对象动态和长视频序列中表现优异。

Abstract: Video Object Segmentation (VOS) is foundational to numerous computer vision
applications, including surveillance, autonomous driving, robotics and
generative video editing. However, existing VOS models often struggle with
precise mask delineation, deformable objects, topologically transforming
objects, tracking drift and long video sequences. In this paper, we introduce
HQ-SMem, for High Quality video segmentation and tracking using Smart Memory, a
novel method that enhances the performance of VOS base models by addressing
these limitations. Our approach incorporates three key innovations: (i)
leveraging SAM with High-Quality masks (SAM-HQ) alongside appearance-based
candidate-selection to refine coarse segmentation masks, resulting in improved
object boundaries; (ii) implementing a dynamic smart memory mechanism that
selectively stores relevant key frames while discarding redundant ones, thereby
optimizing memory usage and processing efficiency for long-term videos; and
(iii) dynamically updating the appearance model to effectively handle complex
topological object variations and reduce drift throughout the video. These
contributions mitigate several limitations of existing VOS models including,
coarse segmentations that mix-in background pixels, fixed memory update
schedules, brittleness to drift and occlusions, and prompt ambiguity issues
associated with SAM. Extensive experiments conducted on multiple public
datasets and state-of-the-art base trackers demonstrate that our method
consistently ranks among the top two on VOTS and VOTSt 2024 datasets. Moreover,
HQ-SMem sets new benchmarks on Long Video Dataset and LVOS, showcasing its
effectiveness in challenging scenarios characterized by complex multi-object
dynamics over extended temporal durations.

</details>


### [36] [Gaussian Set Surface Reconstruction through Per-Gaussian Optimization](https://arxiv.org/abs/2507.18923)
*Zhentao Huang,Di Wu,Zhenbang He,Minglun Gong*

Main category: cs.CV

TL;DR: GSSR通过法线一致性和光度一致性优化高斯分布，提升几何精度，支持高效3D环境生成。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS及其变体（如PGSR）在场景几何重建上存在不足，高斯分布不均匀且偏离潜在表面，导致重建和编辑困难。

Method: GSSR通过像素级和高斯级的单视角法线一致性及多视角光度一致性，结合不透明度正则化损失和周期性深度/法线引导的高斯重新初始化，优化高斯分布。

Result: 实验证明GSSR在保持高质量渲染性能的同时，显著提升了几何精度。

Conclusion: GSSR显著提高了高斯分布的几何精度，支持直观的场景编辑和高效的新型高斯3D环境生成。

Abstract: 3D Gaussian Splatting (3DGS) effectively synthesizes novel views through its
flexible representation, yet fails to accurately reconstruct scene geometry.
While modern variants like PGSR introduce additional losses to ensure proper
depth and normal maps through Gaussian fusion, they still neglect individual
placement optimization. This results in unevenly distributed Gaussians that
deviate from the latent surface, complicating both reconstruction refinement
and scene editing. Motivated by pioneering work on Point Set Surfaces, we
propose Gaussian Set Surface Reconstruction (GSSR), a method designed to
distribute Gaussians evenly along the latent surface while aligning their
dominant normals with the surface normal. GSSR enforces fine-grained geometric
alignment through a combination of pixel-level and Gaussian-level single-view
normal consistency and multi-view photometric consistency, optimizing both
local and global perspectives. To further refine the representation, we
introduce an opacity regularization loss to eliminate redundant Gaussians and
apply periodic depth- and normal-guided Gaussian reinitialization for a
cleaner, more uniform spatial distribution. Our reconstruction results
demonstrate significantly improved geometric precision in Gaussian placement,
enabling intuitive scene editing and efficient generation of novel
Gaussian-based 3D environments. Extensive experiments validate GSSR's
effectiveness, showing enhanced geometric accuracy while preserving
high-quality rendering performance.

</details>


### [37] [Closing the Modality Gap for Mixed Modality Search](https://arxiv.org/abs/2507.19054)
*Binxu Li,Yuhui Zhang,Xiaohan Wang,Weixin Liang,Ludwig Schmidt,Serena Yeung-Levy*

Main category: cs.CV

TL;DR: GR-CLIP是一种轻量级的后校准方法，解决了CLIP模型在混合模态搜索中的模态间隙问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 混合模态搜索（跨图像、文本和多模态文档检索）是重要但未充分探索的实际应用。CLIP等模型在此任务中存在模态间隙问题。

Method: 提出GR-CLIP，通过后校准消除CLIP嵌入空间中的模态间隙。

Result: 在MixBench基准测试中，GR-CLIP的NDCG@10比CLIP提升26个百分点，优于其他模型且计算量减少75倍。

Conclusion: GR-CLIP有效解决了模态间隙问题，显著提升了混合模态搜索性能。

Abstract: Mixed modality search -- retrieving information across a heterogeneous corpus
composed of images, texts, and multimodal documents -- is an important yet
underexplored real-world application. In this work, we investigate how
contrastive vision-language models, such as CLIP, perform on the mixed modality
search task. Our analysis reveals a critical limitation: these models exhibit a
pronounced modality gap in the embedding space, where image and text embeddings
form distinct clusters, leading to intra-modal ranking bias and inter-modal
fusion failure. To address this issue, we propose GR-CLIP, a lightweight
post-hoc calibration method that removes the modality gap in CLIP's embedding
space. Evaluated on MixBench -- the first benchmark specifically designed for
mixed modality search -- GR-CLIP improves NDCG@10 by up to 26 percentage points
over CLIP, surpasses recent vision-language generative embedding models by 4
percentage points, while using 75x less compute.

</details>


### [38] [MedSymmFlow: Bridging Generative Modeling and Classification in Medical Imaging through Symmetrical Flow Matching](https://arxiv.org/abs/2507.19098)
*Francisco Caetano,Lemar Abdi,Christiaan Viviers,Amaan Valiuddin,Fons van der Sommen*

Main category: cs.CV

TL;DR: MedSymmFlow 是一种结合生成和判别模型的混合方法，用于医学影像分类和不确定性量化，表现优于基线，并通过选择性预测验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 在临床高风险的医疗影像分类中，不仅需要准确的预测，还需要可靠的不确定性估计。现有的判别模型在这方面存在局限，因此需要一种能够统一分类、生成和不确定性量化的方法。

Method: MedSymmFlow 结合了生成和判别模型的特点，利用对称流匹配技术构建，采用了潜在空间公式以适应高分辨率输入，并引入了语义掩码条件机制以增强诊断相关性。

Result: 在四个 MedMNIST 数据集上的评估表明，MedSymmFlow 在分类准确率和 AUC 上匹配或超过现有基线，同时通过生成采样过程自然估计不确定性，验证了其可靠性。

Conclusion: MedSymmFlow 是一种基于对称流匹配的生成-判别混合模型，能够在医学影像分类、生成和不确定性量化方面提供统一解决方案，其表现优于或与现有基线相当，尤其在选择性预测中验证了其不确定性估计的可靠性。

Abstract: Reliable medical image classification requires accurate predictions and
well-calibrated uncertainty estimates, especially in high-stakes clinical
settings. This work presents MedSymmFlow, a generative-discriminative hybrid
model built on Symmetrical Flow Matching, designed to unify classification,
generation, and uncertainty quantification in medical imaging. MedSymmFlow
leverages a latent-space formulation that scales to high-resolution inputs and
introduces a semantic mask conditioning mechanism to enhance diagnostic
relevance. Unlike standard discriminative models, it naturally estimates
uncertainty through its generative sampling process. The model is evaluated on
four MedMNIST datasets, covering a range of modalities and pathologies. The
results show that MedSymmFlow matches or exceeds the performance of established
baselines in classification accuracy and AUC, while also delivering reliable
uncertainty estimates validated by performance improvements under selective
prediction.

</details>


### [39] [PDT: Point Distribution Transformation with Diffusion Models](https://arxiv.org/abs/2507.18939)
*Jionghao Wang,Cheng Lin,Yuan Liu,Rui Xu,Zhiyang Dou,Xiao-Xiao Long,Hao-Xiang Guo,Taku Komura,Wenping Wang,Xin Li*

Main category: cs.CV

TL;DR: PDT是一种基于扩散模型的新框架，可将无序点云转换为语义化结构分布，适用于多种3D几何处理任务。


<details>
  <summary>Details</summary>
Motivation: 尽管点云在几何数据结构中至关重要，但如何从无序分布中提取有意义的结构信息并转换为语义分布仍是一个未充分探索的问题。

Method: PDT利用具有新颖架构和学习策略的扩散模型，通过去噪过程有效关联源分布和目标分布。

Result: 实验表明，PDT能够将输入点云转换为多种结构化输出（如表面关键点、内部稀疏关节和连续特征线），展示了其捕捉几何和语义特征的能力。

Conclusion: PDT框架通过扩散模型成功将无序点云转换为具有语义意义的结构化点分布，为3D几何处理任务提供了强大工具。

Abstract: Point-based representations have consistently played a vital role in
geometric data structures. Most point cloud learning and processing methods
typically leverage the unordered and unconstrained nature to represent the
underlying geometry of 3D shapes. However, how to extract meaningful structural
information from unstructured point cloud distributions and transform them into
semantically meaningful point distributions remains an under-explored problem.
We present PDT, a novel framework for point distribution transformation with
diffusion models. Given a set of input points, PDT learns to transform the
point set from its original geometric distribution into a target distribution
that is semantically meaningful. Our method utilizes diffusion models with
novel architecture and learning strategy, which effectively correlates the
source and the target distribution through a denoising process. Through
extensive experiments, we show that our method successfully transforms input
point clouds into various forms of structured outputs - ranging from
surface-aligned keypoints, and inner sparse joints to continuous feature lines.
The results showcase our framework's ability to capture both geometric and
semantic features, offering a powerful tool for various 3D geometry processing
tasks where structured point distributions are desired. Code will be available
at this link: https://github.com/shanemankiw/PDT.

</details>


### [40] [PatchTraj: Dynamic Patch Representation Learning for Time-Frequency Trajectory Prediction](https://arxiv.org/abs/2507.19119)
*Yanghong Liu,Xingping Dong,Ming Li,Weixing Zhang,Yidong Lou*

Main category: cs.CV

TL;DR: PatchTraj是一种动态分块轨迹预测框架，统一时域和频域表示，通过多尺度特征提取和跨模态注意力实现高效预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在建模人类运动动态时存在不足，无法平衡局部运动细节与长距离时空依赖，且时间表示缺乏与频域的交互。

Method: 提出了PatchTraj框架，通过动态分块分割轨迹，结合自适应嵌入层和多尺度特征提取，利用跨模态注意力融合时域和频域信息，最终通过Transformer编码器-解码器预测未来轨迹。

Result: 在ETH-UCY、SDD、NBA和JRDB数据集上的实验表明，PatchTraj实现了高效的最先进性能。

Conclusion: PatchTraj在多个数据集上实现了最先进的性能，证明了其统一时域和频域表示的有效性。

Abstract: Pedestrian trajectory prediction is crucial for autonomous driving and
robotics. While existing point-based and grid-based methods expose two key
limitations: insufficiently modeling human motion dynamics, as they fail to
balance local motion details with long-range spatiotemporal dependencies, and
the time representation lacks interaction with the frequency domain in modeling
trajectory sequences. To address these challenges, we propose PatchTraj, a
dynamic patch-based trajectory prediction framework that unifies time-domain
and frequency-domain representations. Specifically, we decompose the trajectory
into raw time sequences and frequency components, employing dynamic patch
partitioning for multi-scale trajectory segmentation to capture hierarchical
motion patterns. Each patch is processed by an adaptive embedding layer with
scale-aware feature extraction, followed by hierarchical feature aggregation to
model both fine-grained and long-range dependencies. The outputs of two
branches interact via cross-modal attention, enabling complementary fusion of
temporal and spectral cues. Finally, a Transformer encoder-decoder integrates
both modalities to autoregressively predict future trajectories. Extensive
experiments on ETH-UCY, SDD, NBA, and JRDB datasets demonstrate that our method
achieves state-of-the-art performance with high efficiency.

</details>


### [41] [Structure Matters: Revisiting Boundary Refinement in Video Object Segmentation](https://arxiv.org/abs/2507.18944)
*Guanyi Qin,Ziyue Wang,Daiyun Shen,Haofeng Liu,Hantao Zhou,Junde Wu,Runze Hu,Yueming Jin*

Main category: cs.CV

TL;DR: OASIS是一种新型半监督视频对象分割方法，通过边界修正和结构细化模块提升分割精度，尤其在遮挡场景中表现优异，实验证明其性能优于现有方法且具备实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的基于记忆的SVOS方法在处理遮挡、对象交互和高特征相似性场景时表现不佳，且难以满足下游应用的实时处理需求。

Method: 提出了一种轻量级的结构细化模块，结合Canny滤波器捕获的粗糙边缘先验和存储的对象特征，生成对象级结构图并通过突出边界特征来优化表示。此外，引入了证据学习用于不确定性估计以应对遮挡区域的挑战。

Result: 在DAVIS-17和YouTubeVOS 2019验证集上分别实现了F值91.6（对比89.7）和G值86.6（对比86.2），同时保持了48 FPS的实时处理速度。

Conclusion: OASIS方法在保持高效设计的同时，通过边界修正和结构细化模块显著提升了视频对象分割的准确性，尤其在处理遮挡和高特征相似性场景时表现出色，实验证明了其优于现有方法的性能和实时处理能力。

Abstract: Given an object mask, Semi-supervised Video Object Segmentation (SVOS)
technique aims to track and segment the object across video frames, serving as
a fundamental task in computer vision. Although recent memory-based methods
demonstrate potential, they often struggle with scenes involving occlusion,
particularly in handling object interactions and high feature similarity. To
address these issues and meet the real-time processing requirements of
downstream applications, in this paper, we propose a novel bOundary Amendment
video object Segmentation method with Inherent Structure refinement, hereby
named OASIS. Specifically, a lightweight structure refinement module is
proposed to enhance segmentation accuracy. With the fusion of rough edge priors
captured by the Canny filter and stored object features, the module can
generate an object-level structure map and refine the representations by
highlighting boundary features. Evidential learning for uncertainty estimation
is introduced to further address challenges in occluded regions. The proposed
method, OASIS, maintains an efficient design, yet extensive experiments on
challenging benchmarks demonstrate its superior performance and competitive
inference speed compared to other state-of-the-art methods, i.e., achieving the
F values of 91.6 (vs. 89.7 on DAVIS-17 validation set) and G values of 86.6
(vs. 86.2 on YouTubeVOS 2019 validation set) while maintaining a competitive
speed of 48 FPS on DAVIS.

</details>


### [42] [PerioDet: Large-Scale Panoramic Radiograph Benchmark for Clinical-Oriented Apical Periodontitis Detection](https://arxiv.org/abs/2507.18958)
*Xiaocheng Fang,Jieyi Cai,Huanyu Liu,Chengju Zhou,Minhua Lu,Bingzhi Chen*

Main category: cs.CV

TL;DR: 发布了首个根尖周炎自动诊断基准数据集PerioXrays，并提出了结合BDA和IDC机制的PerioDet检测范式，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模高质量标注数据集，根尖周炎的计算机辅助诊断（CAD）应用发展受限。

Method: 提出了PerioDet范式，结合了背景去噪注意力（BDA）和IoU动态校准（IDC）机制，以解决自动检测中的背景噪声和小目标问题。

Result: 在PerioXrays数据集上的广泛实验证明了PerioDet在自动根尖周炎检测中的优越性。

Conclusion: PerioDet通过结合BDA和IDC机制，显著提升了根尖周炎的自动检测性能，并在人机协作实验中证明了其作为辅助诊断工具的临床实用性。

Abstract: Apical periodontitis is a prevalent oral pathology that presents significant
public health challenges. Despite advances in automated diagnostic systems
across various medical fields, the development of Computer-Aided Diagnosis
(CAD) applications for apical periodontitis is still constrained by the lack of
a large-scale, high-quality annotated dataset. To address this issue, we
release a large-scale panoramic radiograph benchmark called "PerioXrays",
comprising 3,673 images and 5,662 meticulously annotated instances of apical
periodontitis. To the best of our knowledge, this is the first benchmark
dataset for automated apical periodontitis diagnosis. This paper further
proposes a clinical-oriented apical periodontitis detection (PerioDet)
paradigm, which jointly incorporates Background-Denoising Attention (BDA) and
IoU-Dynamic Calibration (IDC) mechanisms to address the challenges posed by
background noise and small targets in automated detection. Extensive
experiments on the PerioXrays dataset demonstrate the superiority of PerioDet
in advancing automated apical periodontitis detection. Additionally, a
well-designed human-computer collaborative experiment underscores the clinical
applicability of our method as an auxiliary diagnostic tool for professional
dentists.

</details>


### [43] [YOLO for Knowledge Extraction from Vehicle Images: A Baseline Study](https://arxiv.org/abs/2507.18966)
*Saraa Al-Saddik,Manna Elizabeth Philip,Ali Haidar*

Main category: cs.CV

TL;DR: 研究评估了三种YOLO模型在车辆属性识别上的表现，发现MVI方法和较小YOLO变体在复杂数据集中效果更佳。


<details>
  <summary>Details</summary>
Motivation: 准确识别车辆属性（如品牌、颜色和形状）对执法和情报应用至关重要。

Method: 研究评估了YOLO-v11、YOLO-World和YOLO-Classification三种深度学习模型在真实世界车辆图像数据集上的表现，采用了多视角推理（MVI）方法增强预测性能。数据集包含超过10万张图像，分为品牌、形状和颜色三个任务。

Result: 最佳模型在品牌、形状、颜色和颜色二分类任务上的准确率分别为93.70%、82.86%、85.19%和94.86%。

Conclusion: 研究表明，使用多视角推理（MVI）方法在复杂现实数据集中是必要的，YOLO-v11和YOLO-World在车辆品牌和形状提取上优于纯分类模型，且较小YOLO变体在实时预测中效率更高。

Abstract: Accurate identification of vehicle attributes such as make, colour, and shape
is critical for law enforcement and intelligence applications. This study
evaluates the effectiveness of three state-of-the-art deep learning approaches
YOLO-v11, YOLO-World, and YOLO-Classification on a real-world vehicle image
dataset. This dataset was collected under challenging and unconstrained
conditions by NSW Police Highway Patrol Vehicles. A multi-view inference (MVI)
approach was deployed to enhance the performance of the models' predictions. To
conduct the analyses, datasets with 100,000 plus images were created for each
of the three metadata prediction tasks, specifically make, shape and colour.
The models were tested on a separate dataset with 29,937 images belonging to
1809 number plates. Different sets of experiments have been investigated by
varying the models sizes. A classification accuracy of 93.70%, 82.86%, 85.19%,
and 94.86% was achieved with the best performing make, shape, colour, and
colour-binary models respectively. It was concluded that there is a need to use
MVI to get usable models within such complex real-world datasets. Our findings
indicated that the object detection models YOLO-v11 and YOLO-World outperformed
classification-only models in make and shape extraction. Moreover, smaller YOLO
variants perform comparably to larger counterparts, offering substantial
efficiency benefits for real-time predictions. This work provides a robust
baseline for extracting vehicle metadata in real-world scenarios. Such models
can be used in filtering and sorting user queries, minimising the time required
to search large vehicle images datasets.

</details>


### [44] [AEDR: Training-Free AI-Generated Image Attribution via Autoencoder Double-Reconstruction](https://arxiv.org/abs/2507.18988)
*Chao Wang,Kejiang Chen,Zijin Yang,Yaofei Wang,Weiming Zhang*

Main category: cs.CV

TL;DR: AEDR是一种无需训练的图像生成模型归因方法，通过双重重建和校准技术，显著提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 随着图像生成技术的快速发展，追踪生成图像的来源以应对安全威胁变得尤为重要，但现有重建归因方法在准确性和计算成本上存在不足。

Method: AEDR采用连续自编码器进行双重重建，利用两次重建损失比作为归因信号，并通过图像同质性指标校准以提高准确性。

Result: 在八种顶级潜在扩散模型上的实验表明，AEDR比现有重建方法归因准确率提高25.5%，同时仅需1%的计算时间。

Conclusion: AEDR（AutoEncoder Double-Reconstruction）作为一种新型的无训练归因方法，通过双重重建损失比和图像同质性校准，显著提高了生成模型图像来源追踪的准确性和计算效率。

Abstract: The rapid advancement of image-generation technologies has made it possible
for anyone to create photorealistic images using generative models, raising
significant security concerns. To mitigate malicious use, tracing the origin of
such images is essential. Reconstruction-based attribution methods offer a
promising solution, but they often suffer from reduced accuracy and high
computational costs when applied to state-of-the-art (SOTA) models. To address
these challenges, we propose AEDR (AutoEncoder Double-Reconstruction), a novel
training-free attribution method designed for generative models with continuous
autoencoders. Unlike existing reconstruction-based approaches that rely on the
value of a single reconstruction loss, AEDR performs two consecutive
reconstructions using the model's autoencoder, and adopts the ratio of these
two reconstruction losses as the attribution signal. This signal is further
calibrated using the image homogeneity metric to improve accuracy, which
inherently cancels out absolute biases caused by image complexity, with
autoencoder-based reconstruction ensuring superior computational efficiency.
Experiments on eight top latent diffusion models show that AEDR achieves 25.5%
higher attribution accuracy than existing reconstruction-based methods, while
requiring only 1% of the computational time.

</details>


### [45] [Multistream Network for LiDAR and Camera-based 3D Object Detection in Outdoor Scenes](https://arxiv.org/abs/2507.19304)
*Muhammad Ibrahim,Naveed Akhtar,Haitian Wang,Saeed Anwar,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出MuStD网络，通过多流结构融合LiDAR和RGB数据，在KITTI基准测试中取得优异结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决室外3D物体检测中的实际挑战，融合LiDAR和RGB数据以提高检测精度，但仍需解决多模态有效融合的问题。

Method: 提出了一个多流检测网络（MuStD），包括LiDAR-PillarNet流、LiDAR-Height压缩流和3D多模态流，通过UV映射和极坐标索引结合RGB和LiDAR特征。

Result: 在KITTI物体检测基准测试中取得了新的最先进或极具竞争力的结果。

Conclusion: 该方法在KITTI物体检测基准测试中取得了新的最先进或极具竞争力的结果，同时保持了高效性。

Abstract: Fusion of LiDAR and RGB data has the potential to enhance outdoor 3D object
detection accuracy. To address real-world challenges in outdoor 3D object
detection, fusion of LiDAR and RGB input has started gaining traction. However,
effective integration of these modalities for precise object detection task
still remains a largely open problem. To address that, we propose a MultiStream
Detection (MuStD) network, that meticulously extracts task-relevant information
from both data modalities. The network follows a three-stream structure. Its
LiDAR-PillarNet stream extracts sparse 2D pillar features from the LiDAR input
while the LiDAR-Height Compression stream computes Bird's-Eye View features. An
additional 3D Multimodal stream combines RGB and LiDAR features using UV
mapping and polar coordinate indexing. Eventually, the features containing
comprehensive spatial, textural and geometric information are carefully fused
and fed to a detection head for 3D object detection. Our extensive evaluation
on the challenging KITTI Object Detection Benchmark using public testing server
at
https://www.cvlibs.net/datasets/kitti/eval_object_detail.php?&result=d162ec699d6992040e34314d19ab7f5c217075e0
establishes the efficacy of our method by achieving new state-of-the-art or
highly competitive results in different categories while remaining among the
most efficient methods. Our code will be released through MuStD GitHub
repository at https://github.com/IbrahimUWA/MuStD.git

</details>


### [46] [UPP: Unified Point-Level Prompting for Robust Point Cloud Analysis](https://arxiv.org/abs/2507.18997)
*Zixiang Ai,Zhenyu Cui,Yuxin Peng,Jiahuan Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种统一的点级提示方法，通过修正和补全提示机制增强点云质量，显著提升了噪声和不完整点云数据的处理效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在点云增强和下游任务之间存在隔离，且去噪和补全任务的目标冲突限制了关键几何特征的保留。为解决这些问题，论文提出了一种参数高效的统一提示方法。

Method: 论文提出了一种统一的点级提示方法，包括Rectification Prompter和Completion Prompter，通过预测的修正向量提示和辅助点提示来增强点云质量，并结合Shape-Aware Unit模块捕获几何特征。

Result: 在四个数据集上的实验表明，该方法在处理噪声和不完整点云数据时优于现有方法。

Conclusion: 该论文提出的统一点级提示方法在噪声和不完整点云数据处理方面表现出优越性和鲁棒性，显著优于现有最先进方法。

Abstract: Pre-trained point cloud analysis models have shown promising advancements in
various downstream tasks, yet their effectiveness is typically suffering from
low-quality point cloud (i.e., noise and incompleteness), which is a common
issue in real scenarios due to casual object occlusions and unsatisfactory data
collected by 3D sensors. To this end, existing methods focus on enhancing point
cloud quality by developing dedicated denoising and completion models. However,
due to the isolation between the point cloud enhancement and downstream tasks,
these methods fail to work in various real-world domains. In addition, the
conflicting objectives between denoising and completing tasks further limit the
ensemble paradigm to preserve critical geometric features. To tackle the above
challenges, we propose a unified point-level prompting method that reformulates
point cloud denoising and completion as a prompting mechanism, enabling robust
analysis in a parameter-efficient manner. We start by introducing a
Rectification Prompter to adapt to noisy points through the predicted
rectification vector prompts, effectively filtering noise while preserving
intricate geometric features essential for accurate analysis. Sequentially, we
further incorporate a Completion Prompter to generate auxiliary point prompts
based on the rectified point clouds, facilitating their robustness and
adaptability. Finally, a Shape-Aware Unit module is exploited to efficiently
unify and capture the filtered geometric features for the downstream point
cloud analysis.Extensive experiments on four datasets demonstrate the
superiority and robustness of our method when handling noisy and incomplete
point cloud data against existing state-of-the-art methods. Our code is
released at https://github.com/zhoujiahuan1991/ICCV2025-UPP.

</details>


### [47] [SIDE: Sparse Information Disentanglement for Explainable Artificial Intelligence](https://arxiv.org/abs/2507.19321)
*Viktar Dubovik,Łukasz Struski,Jacek Tabor,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: SIDE通过稀疏性训练和剪枝方案，显著提升原型解释的可理解性，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在医疗影像和自动驾驶等高风险领域缺乏透明度，原型部件网络虽提供概念级解释，但大多局限于细粒度分类任务，且现有方法如InfoDisent的解释过于复杂。

Method: SIDE采用了一种新的训练和剪枝方案，结合sigmoid激活函数替代softmax，使每个类别仅与少量相关原型关联。

Result: SIDE在保持准确性的同时，将解释大小减少了90%以上，显著提升了原型解释的可理解性。

Conclusion: SIDE方法通过稀疏性训练和剪枝方案，显著提高了原型部件解释的可理解性，同时在准确性上与现有方法相当。

Abstract: Understanding the decisions made by deep neural networks is essential in
high-stakes domains such as medical imaging and autonomous driving. Yet, these
models often lack transparency, particularly in computer vision.
Prototypical-parts-based neural networks have emerged as a promising solution
by offering concept-level explanations. However, most are limited to
fine-grained classification tasks, with few exceptions such as InfoDisent.
InfoDisent extends prototypical models to large-scale datasets like ImageNet,
but produces complex explanations.
  We introduce Sparse Information Disentanglement for Explainability (SIDE), a
novel method that improves the interpretability of prototypical parts through a
dedicated training and pruning scheme that enforces sparsity. Combined with
sigmoid activations in place of softmax, this approach allows SIDE to associate
each class with only a small set of relevant prototypes. Extensive experiments
show that SIDE matches the accuracy of existing methods while reducing
explanation size by over $90\%$, substantially enhancing the understandability
of prototype-based explanations.

</details>


### [48] [GPSMamba: A Global Phase and Spectral Prompt-guided Mamba for Infrared Image Super-Resolution](https://arxiv.org/abs/2507.18998)
*Yongsong Huang,Tomo Miyazaki,Xiaofeng Liu,Shinichiro Omachi*

Main category: cs.CV

TL;DR: GPSMamba框架通过非因果监督和语义-频率提示，解决了红外图像超分辨率中的长程建模问题，实现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 红外图像超分辨率（IRSR）因低对比度和稀疏纹理而具有挑战性，需要强大的长程建模以保持全局一致性。

Method: 提出了GPSMamba框架，结合ASF-SSM模块和热-谱注意力与相位一致性损失，通过非因果监督增强全局结构性和光谱保真度。

Result: 实验表明，GPSMamba在红外图像恢复任务中达到了最先进的性能。

Conclusion: GPSMamba通过结合自适应语义-频率状态空间模块（ASF-SSM）和热-谱注意力与相位一致性损失，提出了一种系统策略来缓解因果建模的局限性，实现了红外图像超分辨率的先进性能。

Abstract: Infrared Image Super-Resolution (IRSR) is challenged by the low contrast and
sparse textures of infrared data, requiring robust long-range modeling to
maintain global coherence. While State-Space Models like Mamba offer
proficiency in modeling long-range dependencies for this task, their inherent
1D causal scanning mechanism fragments the global context of 2D images,
hindering fine-detail restoration. To address this, we propose Global Phase and
Spectral Prompt-guided Mamba (GPSMamba), a framework that synergizes
architectural guidance with non-causal supervision. First, our Adaptive
Semantic-Frequency State Space Module (ASF-SSM) injects a fused
semantic-frequency prompt directly into the Mamba block, integrating non-local
context to guide reconstruction. Then, a novel Thermal-Spectral Attention and
Phase Consistency Loss provides explicit, non-causal supervision to enforce
global structural and spectral fidelity. By combining these two innovations,
our work presents a systematic strategy to mitigate the limitations of causal
modeling. Extensive experiments demonstrate that GPSMamba achieves
state-of-the-art performance, validating our approach as a powerful new
paradigm for infrared image restoration. Code is available at
https://github.com/yongsongH/GPSMamba.

</details>


### [49] [LOTUS: A Leaderboard for Detailed Image Captioning from Quality to Societal Bias and User Preferences](https://arxiv.org/abs/2507.19362)
*Yusuke Hirota,Boyi Li,Ryo Hachiuma,Yueh-Hua Wu,Boris Ivanovic,Yuta Nakashima,Marco Pavone,Yejin Choi,Yu-Chiang Frank Wang,Chao-Han Huck Yang*

Main category: cs.CV

TL;DR: LOTUS 是一个针对详细图像描述的评估排行榜，填补了现有评估的空白，分析显示模型表现因标准而异，且用户偏好影响最佳模型选择。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法缺乏标准化标准、偏见感知和用户偏好考虑，LOTUS 旨在填补这些空白，提供更全面的评估框架。

Method: LOTUS 是一个评估详细图像描述的排行榜，通过标准化评估标准、考虑偏见感知和用户偏好，对图像描述的质量、风险和社会偏见进行全面评估。

Result: 分析显示，没有单一模型在所有评估标准上表现优秀，且描述细节与偏见风险之间存在相关性。偏好导向评估表明，最佳模型选择取决于用户优先级。

Conclusion: LOTUS 提供了一个全面的评估框架，用于详细图像描述，揭示了当前大型视觉语言模型在多个评估维度上的表现差异，并强调了根据用户偏好选择模型的重要性。

Abstract: Large Vision-Language Models (LVLMs) have transformed image captioning,
shifting from concise captions to detailed descriptions. We introduce LOTUS, a
leaderboard for evaluating detailed captions, addressing three main gaps in
existing evaluations: lack of standardized criteria, bias-aware assessments,
and user preference considerations. LOTUS comprehensively evaluates various
aspects, including caption quality (e.g., alignment, descriptiveness), risks
(\eg, hallucination), and societal biases (e.g., gender bias) while enabling
preference-oriented evaluations by tailoring criteria to diverse user
preferences. Our analysis of recent LVLMs reveals no single model excels across
all criteria, while correlations emerge between caption detail and bias risks.
Preference-oriented evaluations demonstrate that optimal model selection
depends on user priorities.

</details>


### [50] [Enhancing Reward Models for High-quality Image Generation: Beyond Text-Image Alignment](https://arxiv.org/abs/2507.19002)
*Ying Ba,Tianyu Zhang,Yalong Bai,Wenyi Mo,Tao Liang,Bing Su,Ji-Rong Wen*

Main category: cs.CV

TL;DR: 该研究揭示了现有图像生成评估框架的缺陷，并提出ICT和HP分数模型，显著提升了评估准确性和图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有评估框架未能跟上图像生成系统的高保真和美学质量提升，导致与人类审美偏好存在显著差异。

Method: 设计了ICT（Image-Contained-Text）分数来评估图像与文本内容的匹配程度，并进一步训练了仅基于图像模态的HP（High-Preference）分数模型，以增强图像的美学和细节质量。

Result: 实验表明，所提出的评估模型比现有方法提高了10%以上的评分准确性，并在优化最先进的文本到图像模型方面取得了显著成果。

Conclusion: 本研究提出了一种新的评估分数ICT和高偏好分数HP，显著提升了图像生成技术的评估准确性，并为朝向更高阶人类审美偏好的技术进步提供了理论和实证支持。

Abstract: Contemporary image generation systems have achieved high fidelity and
superior aesthetic quality beyond basic text-image alignment. However, existing
evaluation frameworks have failed to evolve in parallel. This study reveals
that human preference reward models fine-tuned based on CLIP and BLIP
architectures have inherent flaws: they inappropriately assign low scores to
images with rich details and high aesthetic value, creating a significant
discrepancy with actual human aesthetic preferences. To address this issue, we
design a novel evaluation score, ICT (Image-Contained-Text) score, that
achieves and surpasses the objectives of text-image alignment by assessing the
degree to which images represent textual content. Building upon this
foundation, we further train an HP (High-Preference) score model using solely
the image modality to enhance image aesthetics and detail quality while
maintaining text-image alignment. Experiments demonstrate that the proposed
evaluation model improves scoring accuracy by over 10\% compared to existing
methods, and achieves significant results in optimizing state-of-the-art
text-to-image models. This research provides theoretical and empirical support
for evolving image generation technology toward higher-order human aesthetic
preferences. Code is available at https://github.com/BarretBa/ICTHP.

</details>


### [51] [CXR-CML: Improved zero-shot classification of long-tailed multi-label diseases in Chest X-Rays](https://arxiv.org/abs/2507.19398)
*Rajesh Madhipati,Sheethal Bhat,Lukas Buess,Andreas Maier*

Main category: cs.CV

TL;DR: 针对胸部X光片的长尾分类问题，提出了一种基于GMM和学生t分布的潜在空间优化方法，显著提升了零样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言模型（如CLIP）在长尾类别上的分类效果不佳，需要一种能够有效处理类别不平衡的方法。

Method: 提出了一种类别加权机制，利用GMM聚类潜在空间，并通过学生t分布进一步优化聚类结果，结合度量损失调整嵌入表示。

Result: 在MIMIC-CXR-JPG数据集的40个类别上，零样本AUC平均提升了7%，显著优于现有最优模型。

Conclusion: 通过结合高斯混合模型（GMM）聚类和学生t分布优化潜在空间中的类别分布，该方法显著提升了零样本分类性能，尤其在长尾类别上表现突出，平均AUC提高了7%。

Abstract: Chest radiography (CXR) plays a crucial role in the diagnosis of various
diseases. However, the inherent class imbalance in the distribution of clinical
findings presents a significant challenge for current self-supervised deep
learning models. These models often fail to accurately classify long-tailed
classes. Current Vision-Language models such as Contrastive Language Image
Pre-training (CLIP) models effectively model the manifold distribution of the
latent space, enabling high zero-shot classification accuracies. Although CLIP
performs well on most of the primary classes in the dataset, our work reveals
that its effectiveness decreases significantly for classes with a long-tailed
distribution. Our approach employs a class-weighting mechanism that directly
aligns with the distribution of classes within the latent space. This method
ensures a substantial improvement in overall classification performance, with
particular emphasis on enhancing the recognition and accuracy of rarely
observed classes. We accomplish this by applying Gaussian Mixture Model (GMM)
clustering to the latent space. The subsequent clusters are further refined by
Student t-distribution, followed by a metric loss that utilizes the altered
embeddings. Our approach facilitates stable and adaptive clustering of the
features. This results in a notable average improvement of 7\% points in
zero-shot AUC scores across 40 classes in the MIMIC-CXR-JPG dataset from
previous SOTA models.

</details>


### [52] [A Survey of Multimodal Hallucination Evaluation and Detection](https://arxiv.org/abs/2507.19024)
*Zhiyuan Chen,Yuecong Min,Jie Zhang,Bei Yan,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: 该论文综述了多模态大语言模型中的幻觉问题，提出了分类法，总结了评估基准和检测方法，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在整合视觉和文本信息时经常产生幻觉内容，这促使了对幻觉问题的深入研究和评估方法的系统性调查。

Method: 研究首先基于忠实性和事实性提出了幻觉的分类法，然后概述了现有的幻觉评估基准，并总结了最新的幻觉检测方法。

Result: 研究提供了幻觉的分类法、评估基准的概述以及检测方法的总结，并指出了当前方法的局限性。

Conclusion: 该研究总结了当前多模态大语言模型中幻觉问题的评估基准和检测方法的主要局限性，并提出了未来研究的潜在方向。

Abstract: Multi-modal Large Language Models (MLLMs) have emerged as a powerful paradigm
for integrating visual and textual information, supporting a wide range of
multi-modal tasks. However, these models often suffer from hallucination,
producing content that appears plausible but contradicts the input content or
established world knowledge. This survey offers an in-depth review of
hallucination evaluation benchmarks and detection methods across Image-to-Text
(I2T) and Text-to-image (T2I) generation tasks. Specifically, we first propose
a taxonomy of hallucination based on faithfulness and factuality, incorporating
the common types of hallucinations observed in practice. Then we provide an
overview of existing hallucination evaluation benchmarks for both T2I and I2T
tasks, highlighting their construction process, evaluation objectives, and
employed metrics. Furthermore, we summarize recent advances in hallucination
detection methods, which aims to identify hallucinated content at the instance
level and serve as a practical complement of benchmark-based evaluation.
Finally, we highlight key limitations in current benchmarks and detection
methods, and outline potential directions for future research.

</details>


### [53] [Probing Multimodal Fusion in the Brain: The Dominance of Audiovisual Streams in Naturalistic Encoding](https://arxiv.org/abs/2507.19052)
*Hamid Abdollahi,Amir Hossein Mansouri Majoumerd,Amir Hossein Bagheri Baboukani,Amir Abolfazl Suratgar,Mohammad Bagher Menhaj*

Main category: cs.CV

TL;DR: 研究开发了基于X-CLIP和Whisper的大脑编码模型，发现简单线性模型在OOD数据上更稳健，语言特征对预测无帮助，强调严格OOD测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 预测大脑对自然多模态刺激的反应是计算神经科学中的一个关键挑战，现有编码模型的泛化能力在全新环境下往往未经充分测试。

Method: 使用最先进的视觉（X-CLIP）和听觉（Whisper）特征提取器开发大脑编码模型，并在分布内（ID）和多样化的分布外（OOD）数据上进行严格评估。

Result: 研究发现模型复杂性与泛化能力之间存在根本权衡：高容量的基于注意力的模型在ID数据上表现优异，但更简单的线性模型在OOD集上更稳健，表现优于竞争基线18%。语言特征并未提高预测准确性，表明对于熟悉语言，神经编码可能主要由连续的视觉和听觉流主导。

Conclusion: 研究结果表明，严格的分布外测试对于构建稳健的神经AI模型至关重要，并提供了关于模型架构、刺激特征和感觉层次如何影响多模态世界神经编码的细致见解。

Abstract: Predicting brain activity in response to naturalistic, multimodal stimuli is
a key challenge in computational neuroscience. While encoding models are
becoming more powerful, their ability to generalize to truly novel contexts
remains a critical, often untested, question. In this work, we developed brain
encoding models using state-of-the-art visual (X-CLIP) and auditory (Whisper)
feature extractors and rigorously evaluated them on both in-distribution (ID)
and diverse out-of-distribution (OOD) data. Our results reveal a fundamental
trade-off between model complexity and generalization: a higher-capacity
attention-based model excelled on ID data, but a simpler linear model was more
robust, outperforming a competitive baseline by 18\% on the OOD set.
Intriguingly, we found that linguistic features did not improve predictive
accuracy, suggesting that for familiar languages, neural encoding may be
dominated by the continuous visual and auditory streams over redundant textual
information. Spatially, our approach showed marked performance gains in the
auditory cortex, underscoring the benefit of high-fidelity speech
representations. Collectively, our findings demonstrate that rigorous OOD
testing is essential for building robust neuro-AI models and provides nuanced
insights into how model architecture, stimulus characteristics, and sensory
hierarchies shape the neural encoding of our rich, multimodal world.

</details>


### [54] [ScenePainter: Semantically Consistent Perpetual 3D Scene Generation with Concept Relation Alignment](https://arxiv.org/abs/2507.19058)
*Chong Xia,Shengjun Zhang,Fangfu Liu,Chang Liu,Khodchaphun Hirunyaratsameewong,Yueqi Duan*

Main category: cs.CV

TL;DR: ScenePainter利用SceneConceptGraph解决3D场景生成中的语义漂移问题，生成更一致的视图序列。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长范围3D场景生成中因外推模块累积偏差导致的语义漂移问题。

Method: 提出了ScenePainter框架，利用SceneConceptGraph构建多层次场景概念之间的关系，指导外推模块生成一致的新视图。

Result: 实验证明ScenePainter克服了语义漂移问题，生成了更一致和沉浸式的3D视图序列。

Conclusion: ScenePainter通过引入SceneConceptGraph解决了语义漂移问题，生成了更一致和沉浸式的3D视图序列。

Abstract: Perpetual 3D scene generation aims to produce long-range and coherent 3D view
sequences, which is applicable for long-term video synthesis and 3D scene
reconstruction. Existing methods follow a "navigate-and-imagine" fashion and
rely on outpainting for successive view expansion. However, the generated view
sequences suffer from semantic drift issue derived from the accumulated
deviation of the outpainting module. To tackle this challenge, we propose
ScenePainter, a new framework for semantically consistent 3D scene generation,
which aligns the outpainter's scene-specific prior with the comprehension of
the current scene. To be specific, we introduce a hierarchical graph structure
dubbed SceneConceptGraph to construct relations among multi-level scene
concepts, which directs the outpainter for consistent novel views and can be
dynamically refined to enhance diversity. Extensive experiments demonstrate
that our framework overcomes the semantic drift issue and generates more
consistent and immersive 3D view sequences. Project Page:
https://xiac20.github.io/ScenePainter/.

</details>


### [55] [Revisiting DETR for Small Object Detection via Noise-Resilient Query Optimization](https://arxiv.org/abs/2507.19059)
*Xiaocheng Fang,Jieyi Cai,Huanyu Liu,Wenxiu Cai,Yishu Liu,Bingzhi Chen*

Main category: cs.CV

TL;DR: NRQO通过NT-FPN和PS-RPN的创新结合，有效解决了小目标检测中的噪声敏感性和查询质量问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer的小目标检测器在特征金字塔网络（FPN）固有的噪声敏感性和现有标签分配策略中查询质量下降方面面临挑战。

Method: 提出了一种新颖的噪声弹性查询优化（NRQO）范式，包括噪声容忍特征金字塔网络（NT-FPN）和成对相似性区域提议网络（PS-RPN）。NT-FPN通过保持空间和语义信息完整性来减少FPN中的噪声，PS-RPN通过增强锚点-真值匹配来生成高质量的正查询。

Result: 在多个基准测试上的广泛实验表明，NRQO优于现有最先进的基线方法。

Conclusion: NRQO范式通过NT-FPN和PS-RPN的创新结合，显著提升了小目标检测的性能，并在多个基准测试中优于现有最先进方法。

Abstract: Despite advancements in Transformer-based detectors for small object
detection (SOD), recent studies show that these detectors still face challenges
due to inherent noise sensitivity in feature pyramid networks (FPN) and
diminished query quality in existing label assignment strategies. In this
paper, we propose a novel Noise-Resilient Query Optimization (NRQO) paradigm,
which innovatively incorporates the Noise-Tolerance Feature Pyramid Network
(NT-FPN) and the Pairwise-Similarity Region Proposal Network (PS-RPN).
Specifically, NT-FPN mitigates noise during feature fusion in FPN by preserving
spatial and semantic information integrity. Unlike existing label assignment
strategies, PS-RPN generates a sufficient number of high-quality positive
queries by enhancing anchor-ground truth matching through position and shape
similarities, without the need for additional hyperparameters. Extensive
experiments on multiple benchmarks consistently demonstrate the superiority of
NRQO over state-of-the-art baselines.

</details>


### [56] [Negation-Aware Test-Time Adaptation for Vision-Language Models](https://arxiv.org/abs/2507.19064)
*Haochen Han,Alex Jinpeng Wang,Fangming Liu*

Main category: cs.CV

TL;DR: 论文针对视觉语言模型在否定理解上的不足，提出了一种名为NEAT的低碳测试时适应方法，通过调整分布参数有效解决了问题，实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在否定理解上存在关键局限性，现有方法因需要大量数据和计算资源而难以广泛采用。论文旨在以低碳方式解决这一问题。

Method: 提出了一种Negation-Aware Test-Time Adaptation (NEAT)方法，通过在推理时高效调整分布相关参数，减少语义一致性的分布偏移并消除无关语义的虚假分布一致性。

Result: 在各种否定理解任务上的广泛实验验证了NEAT方法的有效性。

Conclusion: 论文提出了一种名为NEAT的低碳方法，通过测试时适应调整分布相关参数，有效解决了视觉语言模型在否定理解上的局限性。实验证明了该方法的有效性。

Abstract: In this paper, we study a practical but less-touched problem in
Vision-Language Models (VLMs), \ie, negation understanding. Specifically, many
real-world applications require models to explicitly identify what is false or
non-existent, \eg, radiologists may search for images that exclude specific
conditions. Despite the impressive transferability of VLMs through large-scale
training, they suffer from a critical limitation that fails to handle negation.
To address this challenge, existing methods attribute its root cause to the
scarcity of negation training data and propose to fine-tune VLMs on massive
data containing explicit negation. Undoubtedly, such data-centric solutions
demand substantial data and computational resources, limiting their sustainable
widespread adoption. To tackle negation in a low-carbon manner, we empirically
observe that the key obstacle lies in the dual-concept shifts between the
affirmation and negation distributions. Therefore, we propose a Negation-Aware
Test-Time Adaptation (NEAT) method to efficiently adjust distribution-related
parameters during inference. In brief, NEAT can reduce distribution shift in
consistent semantics while eliminating false distributional consistency in
unrelated semantics. Extensive experiments on the various negation
understanding tasks verify the effectiveness of the proposed method. The code
is available at https://github.com/hhc1997/NEAT.

</details>


### [57] [Cross-Subject Mind Decoding from Inaccurate Representations](https://arxiv.org/abs/2507.19071)
*Yangyang Xu,Bangzhen Liu,Wenqi Shao,Yong Du,Shengfeng He,Tingting Zhu*

Main category: cs.CV

TL;DR: 提出双向自动编码器框架，通过双向映射和模块优化解决跨主题图像重建误差问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨主题映射中因认知差异和主题特异性导致重建误差累积，需要更精确的表示预测方法。

Method: 采用双向映射和主题偏置调制模块统一多个主题，同时引入语义细化模块和视觉一致性模块来优化表示预测。

Result: 在基准数据集上，该方法在定性和定量评估中均优于现有最先进方法，并对新主题表现出强适应性。

Conclusion: 提出的双向自动编码器交织框架在跨主题映射中表现出色，结合ControlNet和Stable Diffusion，显著提升了图像重建的准确性和适应性。

Abstract: Decoding stimulus images from fMRI signals has advanced with pre-trained
generative models. However, existing methods struggle with cross-subject
mappings due to cognitive variability and subject-specific differences. This
challenge arises from sequential errors, where unidirectional mappings generate
partially inaccurate representations that, when fed into diffusion models,
accumulate errors and degrade reconstruction fidelity. To address this, we
propose the Bidirectional Autoencoder Intertwining framework for accurate
decoded representation prediction. Our approach unifies multiple subjects
through a Subject Bias Modulation Module while leveraging bidirectional mapping
to better capture data distributions for precise representation prediction. To
further enhance fidelity when decoding representations into stimulus images, we
introduce a Semantic Refinement Module to improve semantic representations and
a Visual Coherence Module to mitigate the effects of inaccurate visual
representations. Integrated with ControlNet and Stable Diffusion, our method
outperforms state-of-the-art approaches on benchmark datasets in both
qualitative and quantitative evaluations. Moreover, our framework exhibits
strong adaptability to new subjects with minimal training samples.

</details>


### [58] [SP-Mamba: Spatial-Perception State Space Model for Unsupervised Medical Anomaly Detection](https://arxiv.org/abs/2507.19076)
*Rui Pan,Ruiying Lu*

Main category: cs.CV

TL;DR: SP-Mamba是一种基于Mamba的无监督医学异常检测框架，通过窗口滑动原型学习和Circular-Hilbert扫描优化空间信息利用，在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像协议针对特定解剖区域，导致图像具有高度一致性和重复结构模式。尽管CNN和transformer在医学异常检测中表现出色，但CNN在捕捉长距离依赖方面存在局限，而transformer的计算复杂度较高。Mamba-based模型通过优越的长距离建模、结构特征提取和线性计算效率，成为一种有前景的替代方案。

Method: 本研究提出了SP-Mamba，一种空间感知Mamba框架，用于无监督医学异常检测。通过窗口滑动原型学习和基于Circular-Hilbert扫描的Mamba，更好地利用一致的解剖模式和空间信息进行异常检测。

Result: 在三个不同的医学异常检测基准测试中，SP-Mamba表现出最先进的性能。

Conclusion: SP-Mamba框架在三个不同的医学异常检测基准测试中表现出最先进的性能，验证了其有效性和鲁棒性。

Abstract: Radiography imaging protocols target on specific anatomical regions,
resulting in highly consistent images with recurrent structural patterns across
patients. Recent advances in medical anomaly detection have demonstrated the
effectiveness of CNN- and transformer-based approaches. However, CNNs exhibit
limitations in capturing long-range dependencies, while transformers suffer
from quadratic computational complexity. In contrast, Mamba-based models,
leveraging superior long-range modeling, structural feature extraction, and
linear computational efficiency, have emerged as a promising alternative. To
capitalize on the inherent structural regularity of medical images, this study
introduces SP-Mamba, a spatial-perception Mamba framework for unsupervised
medical anomaly detection. The window-sliding prototype learning and
Circular-Hilbert scanning-based Mamba are introduced to better exploit
consistent anatomical patterns and leverage spatial information for medical
anomaly detection. Furthermore, we excavate the concentration and contrast
characteristics of anomaly maps for improving anomaly detection. Extensive
experiments on three diverse medical anomaly detection benchmarks confirm the
proposed method's state-of-the-art performance, validating its efficacy and
robustness. The code is available at https://github.com/Ray-RuiPan/SP-Mamba.

</details>


### [59] [Multi-Task Dense Prediction Fine-Tuning with Mixture of Fine-Grained Experts](https://arxiv.org/abs/2507.19077)
*Yangyang Xu,Xi Ye,Duo Su*

Main category: cs.CV

TL;DR: 提出FGMoE架构，通过细粒度专家混合、共享专家和全局专家改进多任务学习，实验显示其在参数效率和性能上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 多任务学习（MTL）在密集预测中表现良好，但共享表示与任务特定专业化之间的平衡仍存在挑战。

Method: 提出了FGMoE架构，包括三个关键创新：1. 任务内专家（沿MLP中间隐藏维度分区）；2. 共享专家（整合任务间共同信息）；3. 全局专家（跨任务自适应知识迁移）。结合微调方法，仅训练解码器参数以提高效率。

Result: FGMoE在NYUD-v2和PASCAL-Context数据集上，使用更少参数，显著优于当前MoE-based MTL模型。

Conclusion: FGMoE架构通过引入细粒度专家混合、共享专家和全局专家，结合微调方法，显著提升了多任务学习的性能和参数效率，优于现有的MoE-based MTL模型。

Abstract: Multi-task learning (MTL) for dense prediction has shown promising results
but still faces challenges in balancing shared representations with
task-specific specialization. In this paper, we introduce a novel Fine-Grained
Mixture of Experts (FGMoE) architecture that explores MoE-based MTL models
through a combination of three key innovations and fine-tuning. First, we
propose intra-task experts that partition along intermediate hidden dimensions
of MLPs, enabling finer decomposition of task information while maintaining
parameter efficiency. Second, we introduce shared experts that consolidate
common information across different contexts of the same task, reducing
redundancy, and allowing routing experts to focus on unique aspects. Third, we
design a global expert that facilitates adaptive knowledge transfer across
tasks based on both input feature and task requirements, promoting beneficial
information sharing while preventing harmful interference. In addition, we use
the fine-tuning approach to improve parameter efficiency only by training the
parameters of the decoder. Extensive experimental results show that the
proposed FGMoE uses fewer parameters and significantly outperforms current
MoE-based competitive MTL models on two dense prediction datasets
(\textit{i.e.,} NYUD-v2, PASCAL-Context) in various metrics.

</details>


### [60] [LISA: A Layer-wise Integration and Suppression Approach for Hallucination Mitigation in Multimodal Large Language Models](https://arxiv.org/abs/2507.19110)
*Zhihui Guo,Xin Man,Hui Xu,Jie Shao*

Main category: cs.CV

TL;DR: LISA是一种分层集成和抑制方法，有效减少MLLMs中的对象幻觉，提升生成一致性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在视觉语言任务中表现出色，但容易产生对象幻觉，即描述图像中不存在的对象。为了缓解这一问题，提出了LISA方法。

Method: LISA是一种分层集成和抑制方法，通过区域特定的光谱调制和基于锚点的路由融合多层token级logits，增强生成一致性。

Result: 实验表明，LISA在CHAIR_I基准上将幻觉减少高达53.6%，并在POPE F1上提高了4.5%。

Conclusion: LISA通过分层调制和多层融合显著减少了MLLMs中的对象幻觉问题，并在多个基准测试中表现出色，证明了其跨模型和任务的强泛化能力。

Abstract: Multimodal Large Language Models (MLLMs) excel in vision-language tasks such
as image captioning but remain prone to object hallucinations, where they
describe objects that do not appear in the image. To mitigate this, we propose
\textbf{LISA}, a \textbf{L}ayer-wise \textbf{I}ntegration and
\textbf{S}uppression \textbf{A}pproach that enhances generation consistency
through hierarchical modulation and multi-layer fusion. LISA leverages the
functional hierarchy within MLLMs, where shallow layers provide visual
grounding, middle layers encode semantics, and deep layers tend to amplify
spurious signals. First, zone-specific spectral modulation stabilizes attention
by suppressing over-amplified activations in deeper layers while preserving
alignment cues in earlier layers. Second, token-level logits from selected
layers are fused via anchor-based routing, with token-wise anchor selection and
soft logit fusion enabling adaptive integration during decoding. LISA is fully
\textbf{plug-and-play} and can be seamlessly integrated into existing MLLMs,
including Qwen2.5-VL. Experiments on multiple benchmarks show that LISA reduces
hallucinations by up to 53.6\% in $\mathrm{CHAIR}_I$ and improves POPE F1 by
4.5\%, demonstrating strong generalization across models and tasks.

</details>


### [61] [Cross Spatial Temporal Fusion Attention for Remote Sensing Object Detection via Image Feature Matching](https://arxiv.org/abs/2507.19118)
*Abu Sadat Mohammad Salehin Amit,Xiaoli Zhang,Md Masum Billa Shagar,Zhaojun Liu,Xiongfei Li,Fanlong Meng*

Main category: cs.CV

TL;DR: CSTF机制通过融合尺度不变关键点和双重相似性匹配方法，显著提升了跨模态遥感图像匹配的性能，并在物体检测任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 由于多模态图像之间存在显著的几何和辐射差异，有效描述跨模态遥感图像匹配的特征仍然是一个挑战。现有方法通常在全连接层提取特征，但往往无法有效捕捉跨模态相似性。

Method: 提出了一种跨时空融合（CSTF）机制，通过独立检测参考图像和查询图像中的尺度不变关键点来增强特征表示。该方法利用SoftMax和全卷积网络（FCN）层将相似性匹配重新定义为分类任务，同时创建对应图以利用多区域信息。

Result: 在HRSC2016和DOTA基准数据集上，CSTF方法实现了平均mAP分别为90.99%和90.86%的最先进性能，推理速度为12.5 FPS。

Conclusion: CSTF模型通过结合尺度不变关键点和双重相似性匹配方法，显著提升了跨模态遥感图像匹配的性能，并在HRSC2016和DOTA数据集上实现了最先进的性能，验证了其在物体检测等下游任务中的实用性。

Abstract: Effectively describing features for cross-modal remote sensing image matching
remains a challenging task due to the significant geometric and radiometric
differences between multimodal images. Existing methods primarily extract
features at the fully connected layer but often fail to capture cross-modal
similarities effectively. We propose a Cross Spatial Temporal Fusion (CSTF)
mechanism that enhances feature representation by integrating scale-invariant
keypoints detected independently in both reference and query images. Our
approach improves feature matching in two ways: First, by creating
correspondence maps that leverage information from multiple image regions
simultaneously, and second, by reformulating the similarity matching process as
a classification task using SoftMax and Fully Convolutional Network (FCN)
layers. This dual approach enables CSTF to maintain sensitivity to distinctive
local features while incorporating broader contextual information, resulting in
robust matching across diverse remote sensing modalities. To demonstrate the
practical utility of improved feature matching, we evaluate CSTF on object
detection tasks using the HRSC2016 and DOTA benchmark datasets. Our method
achieves state-of-theart performance with an average mAP of 90.99% on HRSC2016
and 90.86% on DOTA, outperforming existing models. The CSTF model maintains
computational efficiency with an inference speed of 12.5 FPS. These results
validate that our approach to crossmodal feature matching directly enhances
downstream remote sensing applications such as object detection.

</details>


### [62] [Preserving Topological and Geometric Embeddings for Point Cloud Recovery](https://arxiv.org/abs/2507.19121)
*Kaiyue Zhou,Zelong Tan,Hongxiao Wang,Ya-li Li,Shengjin Wang*

Main category: cs.CV

TL;DR: TopGeoFormer 是一种端到端架构，通过融合拓扑和几何属性，显著提升点云采样和恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效利用拓扑和几何属性，导致点云恢复效果不佳。

Method: 1. 使用连续映射提取拓扑嵌入，并在采样和恢复阶段整合。2. 提出 InterTwining Attention 完全融合拓扑和几何嵌入。3. 引入全几何损失和拓扑约束损失优化嵌入。

Result: 实验结果表明，TopGeoFormer 在定量和定性上均显著优于现有采样和恢复方法。

Conclusion: TopGeoFormer 通过结合拓扑和几何属性，在点云采样和恢复任务中显著优于现有方法，证明了其在保持原始空间结构和几何细节方面的有效性。

Abstract: Recovering point clouds involves the sequential process of sampling and
restoration, yet existing methods struggle to effectively leverage both
topological and geometric attributes. To address this, we propose an end-to-end
architecture named \textbf{TopGeoFormer}, which maintains these critical
features throughout the sampling and restoration phases. First, we revisit
traditional feature extraction techniques to yield topological embedding using
a continuous mapping of relative relationships between neighboring points, and
integrate it in both phases for preserving the structure of the original space.
Second, we propose the \textbf{InterTwining Attention} to fully merge
topological and geometric embeddings, which queries shape with local awareness
in both phases to form a learnable shape context facilitated with point-wise,
point-shape-wise, and intra-shape features. Third, we introduce a full geometry
loss and a topological constraint loss to optimize the embeddings in both
Euclidean and topological spaces. The geometry loss uses inconsistent matching
between coarse-to-fine generations and targets for reconstructing better
geometric details, and the constraint loss limits embedding variances for
better approximation of the topological space. In experiments, we
comprehensively analyze the circumstances using the conventional and
learning-based sampling/upsampling algorithms. The quantitative and qualitative
results demonstrate that our method significantly outperforms existing sampling
and recovery methods.

</details>


### [63] [MixA-Q: Revisiting Activation Sparsity for Vision Transformers from a Mixed-Precision Quantization Perspective](https://arxiv.org/abs/2507.19131)
*Weitian Wang,Rai Shubham,Cecilia De La Parra,Akash Kumar*

Main category: cs.CV

TL;DR: MixA-Q是一种混合精度激活量化框架，通过稀疏感知量化显著提升窗口视觉Transformer的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决量化窗口视觉Transformer在效率和性能之间的权衡问题，利用激活稀疏性优化量化配置。

Method: 提出了MixA-Q框架，利用层内激活稀疏性，通过双分支Swin块分别处理高和低比特精度的激活，支持QAT和PTQ方法。

Result: 在COCO数据集上，MixA-Q在PTQ配置下实现了1.35倍的计算加速且无精度损失；QAT配置下实现了1.25倍无损加速和1.53倍加速（仅1% mAP下降）。W4A4模型的mAP提升了0.7%，量化退化减少了24%。

Conclusion: MixA-Q通过混合精度激活量化和稀疏感知量化适应，显著提升了量化窗口视觉Transformer的效率和性能，减少了量化误差。

Abstract: In this paper, we propose MixA-Q, a mixed-precision activation quantization
framework that leverages intra-layer activation sparsity (a concept widely
explored in activation pruning methods) for efficient inference of quantized
window-based vision transformers. For a given uniform-bit quantization
configuration, MixA-Q separates the batched window computations within Swin
blocks and assigns a lower bit width to the activations of less important
windows, improving the trade-off between model performance and efficiency. We
introduce a Two-Branch Swin Block that processes activations separately in
high- and low-bit precision, enabling seamless integration of our method with
most quantization-aware training (QAT) and post-training quantization (PTQ)
methods, or with simple modifications. Our experimental evaluations over the
COCO dataset demonstrate that MixA-Q achieves a training-free 1.35x
computational speedup without accuracy loss in PTQ configuration. With QAT,
MixA-Q achieves a lossless 1.25x speedup and a 1.53x speedup with only a 1% mAP
drop by incorporating activation pruning. Notably, by reducing the quantization
error in important regions, our sparsity-aware quantization adaptation improves
the mAP of the quantized W4A4 model (with both weights and activations in 4-bit
precision) by 0.7%, reducing quantization degradation by 24%.

</details>


### [64] [Balancing Conservatism and Aggressiveness: Prototype-Affinity Hybrid Network for Few-Shot Segmentation](https://arxiv.org/abs/2507.19140)
*Tianyu Zou,Shengwu Xiong,Ruilin Yao,Yi Rong*

Main category: cs.CV

TL;DR: PAHNet结合原型和亲和力学习，通过PFE和ASC模块平衡保守与激进信息，提升few-shot分割性能。


<details>
  <summary>Details</summary>
Motivation: 观察到原型学习方法预测保守而亲和力学习方法预测激进，希望通过平衡这两种信息来提升分割性能。

Method: 提出了Prototype-Affinity Hybrid Network (PAHNet)，包含Prototype-guided Feature Enhancement (PFE)模块和Attention Score Calibration (ASC)模块，利用预训练的原型预测器来增强前景信息并抑制不匹配的前景-背景关系。

Result: 在PASCAL-5$^i$和COCO-20$^i$数据集上的实验表明，PAHNet在1-shot和5-shot设置下优于现有方法。

Conclusion: PAHNet通过结合原型学习和亲和力学习的优势，有效平衡了保守和激进的信息，从而在few-shot分割任务中取得了更高的准确率。

Abstract: This paper studies the few-shot segmentation (FSS) task, which aims to
segment objects belonging to unseen categories in a query image by learning a
model on a small number of well-annotated support samples. Our analysis of two
mainstream FSS paradigms reveals that the predictions made by prototype
learning methods are usually conservative, while those of affinity learning
methods tend to be more aggressive. This observation motivates us to balance
the conservative and aggressive information captured by these two types of FSS
frameworks so as to improve the segmentation performance. To achieve this, we
propose a **P**rototype-**A**ffinity **H**ybrid **Net**work (PAHNet), which
introduces a Prototype-guided Feature Enhancement (PFE) module and an Attention
Score Calibration (ASC) module in each attention block of an affinity learning
model (called affinity learner). These two modules utilize the predictions
generated by a pre-trained prototype learning model (called prototype
predictor) to enhance the foreground information in support and query image
representations and suppress the mismatched foreground-background (FG-BG)
relationships between them, respectively. In this way, the aggressiveness of
the affinity learner can be effectively mitigated, thereby eventually
increasing the segmentation accuracy of our PAHNet method. Experimental results
show that PAHNet outperforms most recently proposed methods across 1-shot and
5-shot settings on both PASCAL-5$^i$ and COCO-20$^i$ datasets, suggesting its
effectiveness. The code is available at: [GitHub - tianyu-zou/PAHNet: Balancing
Conservatism and Aggressiveness: Prototype-Affinity Hybrid Network for Few-Shot
Segmentation (ICCV'25)](https://github.com/tianyu-zou/PAHNet)

</details>


### [65] [DASH: 4D Hash Encoding with Self-Supervised Decomposition for Real-Time Dynamic Scene Rendering](https://arxiv.org/abs/2507.19141)
*Jie Chen,Zhangchi Hu,Peixi Wu,Huyue Zhu,Hebei Li,Xiaoyan Sun*

Main category: cs.CV

TL;DR: DASH框架通过自监督分解和多分辨率4D哈希编码，解决了动态场景渲染中的低秩假设和哈希冲突问题，实现了高质量实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有基于平面的动态高斯泼溅方法因低秩假设不当导致特征重叠和渲染质量差，而直接应用4D哈希编码又会导致哈希冲突和冗余。

Method: 采用自监督分解机制分离动态与静态组件，引入多分辨率4D哈希编码器处理动态元素，并提出时空平滑正则化策略以减少不稳定形变伪影。

Result: 在真实数据集上，DASH实现了最先进的动态渲染性能，视觉质量显著提升且实时运行。

Conclusion: DASH框架通过结合4D哈希编码与自监督分解，实现了实时动态场景渲染，显著提升了视觉质量，并在单块4090 GPU上达到264 FPS的性能。

Abstract: Dynamic scene reconstruction is a long-term challenge in 3D vision. Existing
plane-based methods in dynamic Gaussian splatting suffer from an unsuitable
low-rank assumption, causing feature overlap and poor rendering quality.
Although 4D hash encoding provides an explicit representation without low-rank
constraints, directly applying it to the entire dynamic scene leads to
substantial hash collisions and redundancy. To address these challenges, we
present DASH, a real-time dynamic scene rendering framework that employs 4D
hash encoding coupled with self-supervised decomposition. Our approach begins
with a self-supervised decomposition mechanism that separates dynamic and
static components without manual annotations or precomputed masks. Next, we
introduce a multiresolution 4D hash encoder for dynamic elements, providing an
explicit representation that avoids the low-rank assumption. Finally, we
present a spatio-temporal smoothness regularization strategy to mitigate
unstable deformation artifacts. Experiments on real-world datasets demonstrate
that DASH achieves state-of-the-art dynamic rendering performance, exhibiting
enhanced visual quality at real-time speeds of 264 FPS on a single 4090 GPU.
Code: https://github.com/chenj02/DASH.

</details>


### [66] [Patch Pruning Strategy Based on Robust Statistical Measures of Attention Weight Diversity in Vision Transformers](https://arxiv.org/abs/2507.19175)
*Yuki Igaue,Hiroaki Aizawa*

Main category: cs.CV

TL;DR: 提出基于多头自注意力权重方差的patch修剪策略，提高计算效率且保持准确性，鲁棒统计量和重叠patch嵌入进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 多头自注意力机制在视觉Transformer中表现优异，但计算复杂度高，因此需要一种高效的patch修剪方法来提升计算效率。

Method: 提出了一种基于多头自注意力权重方差的patch修剪策略，评估每个patch的重要性，并可应用于训练和推理阶段。

Result: 该方法在保持分类准确性的同时提高了吞吐量，且在预训练模型微调等场景中表现良好。使用鲁棒统计量和重叠patch嵌入进一步优化了性能。

Conclusion: 通过提出的基于注意力权重方差的patch修剪策略，该方法在保持分类准确性的同时提高了计算效率。此外，使用鲁棒统计量（如中位数绝对偏差）和重叠patch嵌入进一步提升了性能。

Abstract: Multi-head self-attention is a distinctive feature extraction mechanism of
vision transformers that computes pairwise relationships among all input
patches, contributing significantly to their high performance. However, it is
known to incur a quadratic computational complexity with respect to the number
of patches. One promising approach to address this issue is patch pruning,
which improves computational efficiency by identifying and removing redundant
patches. In this work, we propose a patch pruning strategy that evaluates the
importance of each patch based on the variance of attention weights across
multiple attention heads. This approach is inspired by the design of multi-head
self-attention, which aims to capture diverse attention patterns across
different subspaces of feature representations. The proposed method can be
easily applied during both training and inference, and achieves improved
throughput while maintaining classification accuracy in scenarios such as
fine-tuning with pre-trained models. In addition, we also found that using
robust statistical measures, such as the median absolute deviation in place of
variance, to assess patch importance can similarly lead to strong performance.
Furthermore, by introducing overlapping patch embeddings, our method achieves
better performance with comparable throughput to conventional approaches that
utilize all patches.

</details>


### [67] [Continual Learning-Based Unified Model for Unpaired Image Restoration Tasks](https://arxiv.org/abs/2507.19184)
*Kotha Kartheek,Lingamaneni Gnanesh Chowdary,Snehasis Mukherjee*

Main category: cs.CV

TL;DR: 提出一种持续学习框架，通过选择性核融合、弹性权重巩固和循环对比损失，实现多天气图像恢复，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法多针对单一天气条件，而自动驾驶等应用需要能处理多种天气的统一模型。因此，提出一个持续学习框架以解决多天气图像恢复问题。

Method: 采用持续学习方法，结合选择性核融合层（SKF）、弹性权重巩固（EWC）和循环对比损失（Cycle-Contrastive Loss），构建了一个不依赖配对训练数据的统一图像恢复框架。

Result: 在标准基准数据集上的实验表明，该方法在去雾、去雪和去雨任务中显著优于现有技术，PSNR、SSIM和感知质量均有提升。

Conclusion: 论文提出的统一框架通过选择性核融合层、弹性权重巩固和循环对比损失，显著提升了图像恢复的PSNR、SSIM和感知质量，尤其在去雾、去雪和去雨任务中表现优异。

Abstract: Restoration of images contaminated by different adverse weather conditions
such as fog, snow, and rain is a challenging task due to the varying nature of
the weather conditions. Most of the existing methods focus on any one
particular weather conditions. However, for applications such as autonomous
driving, a unified model is necessary to perform restoration of corrupted
images due to different weather conditions. We propose a continual learning
approach to propose a unified framework for image restoration. The proposed
framework integrates three key innovations: (1) Selective Kernel Fusion layers
that dynamically combine global and local features for robust adaptive feature
selection; (2) Elastic Weight Consolidation (EWC) to enable continual learning
and mitigate catastrophic forgetting across multiple restoration tasks; and (3)
a novel Cycle-Contrastive Loss that enhances feature discrimination while
preserving semantic consistency during domain translation. Further, we propose
an unpaired image restoration approach to reduce the dependance of the proposed
approach on the training data. Extensive experiments on standard benchmark
datasets for dehazing, desnowing and deraining tasks demonstrate significant
improvements in PSNR, SSIM, and perceptual quality over the state-of-the-art.

</details>


### [68] [VisHall3D: Monocular Semantic Scene Completion from Reconstructing the Visible Regions to Hallucinating the Invisible Regions](https://arxiv.org/abs/2507.19188)
*Haoang Lu,Yuanqi Su,Xiaoning Zhang,Longjun Gao,Yu Xue,Le Wang*

Main category: cs.CV

TL;DR: VisHall3D是一种两阶段单目语义场景补全框架，通过分阶段处理可见和不可见区域，显著提升了重建质量和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单目语义场景补全中存在特征纠缠和几何不一致的问题，VisHall3D旨在通过分阶段处理来解决这些问题。

Method: VisHall3D采用两阶段框架：第一阶段使用VisFrontierNet模块重建可见区域，第二阶段通过OcclusionMAE网络生成不可见区域的几何结构。

Result: 在SemanticKITTI和SSCBench-KITTI-360等基准测试中，VisHall3D显著优于现有方法。

Conclusion: VisHall3D通过两阶段框架有效解决了现有方法中的特征纠缠和几何不一致问题，显著提升了重建质量，并在多个基准测试中实现了最先进的性能。

Abstract: This paper introduces VisHall3D, a novel two-stage framework for monocular
semantic scene completion that aims to address the issues of feature
entanglement and geometric inconsistency prevalent in existing methods.
VisHall3D decomposes the scene completion task into two stages: reconstructing
the visible regions (vision) and inferring the invisible regions
(hallucination). In the first stage, VisFrontierNet, a visibility-aware
projection module, is introduced to accurately trace the visual frontier while
preserving fine-grained details. In the second stage, OcclusionMAE, a
hallucination network, is employed to generate plausible geometries for the
invisible regions using a noise injection mechanism. By decoupling scene
completion into these two distinct stages, VisHall3D effectively mitigates
feature entanglement and geometric inconsistency, leading to significantly
improved reconstruction quality.
  The effectiveness of VisHall3D is validated through extensive experiments on
two challenging benchmarks: SemanticKITTI and SSCBench-KITTI-360. VisHall3D
achieves state-of-the-art performance, outperforming previous methods by a
significant margin and paves the way for more accurate and reliable scene
understanding in autonomous driving and other applications.

</details>


### [69] [Querying Autonomous Vehicle Point Clouds: Enhanced by 3D Object Counting with CounterNet](https://arxiv.org/abs/2507.19209)
*Xiaoyu Zhang,Zhifeng Bao,Hai Dong,Ziwei Wang,Jiajun Liu*

Main category: cs.CV

TL;DR: CounterNet通过热图网络和动态策略提升点云数据中物体计数准确性，改善查询结果。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆生成的点云数据量大且仅部分相关，现有方法在3D点云数据中物体计数不准确，导致查询结果误差大。

Method: 提出了CounterNet，一种基于热图的网络，通过检测物体中心而非精确定位来提高计数准确性，并结合特征图分区策略和动态模型选择策略。

Result: 在三个真实自动驾驶数据集上，CounterNet将物体计数准确性提升了5%至20%，显著改善了查询结果。

Conclusion: CounterNet显著提高了点云数据中物体计数的准确性，从而提升了查询结果的可靠性，特别是在RETRIEVAL、COUNT和AGGREGATION三类查询中表现优异。

Abstract: Autonomous vehicles generate massive volumes of point cloud data, yet only a
subset is relevant for specific tasks such as collision detection, traffic
analysis, or congestion monitoring. Effectively querying this data is essential
to enable targeted analytics. In this work, we formalize point cloud querying
by defining three core query types: RETRIEVAL, COUNT, and AGGREGATION, each
aligned with distinct analytical scenarios. All these queries rely heavily on
accurate object counts to produce meaningful results, making precise object
counting a critical component of query execution. Prior work has focused on
indexing techniques for 2D video data, assuming detection models provide
accurate counting information. However, when applied to 3D point cloud data,
state-of-the-art detection models often fail to generate reliable object
counts, leading to substantial errors in query results. To address this
limitation, we propose CounterNet, a heatmap-based network designed for
accurate object counting in large-scale point cloud data. Rather than focusing
on accurate object localization, CounterNet detects object presence by finding
object centers to improve counting accuracy. We further enhance its performance
with a feature map partitioning strategy using overlapping regions, enabling
better handling of both small and large objects in complex traffic scenes. To
adapt to varying frame characteristics, we introduce a per-frame dynamic model
selection strategy that selects the most effective configuration for each
input. Evaluations on three real-world autonomous vehicle datasets show that
CounterNet improves counting accuracy by 5% to 20% across object categories,
resulting in more reliable query outcomes across all supported query types.

</details>


### [70] [PRE-MAP: Personalized Reinforced Eye-tracking Multimodal LLM for High-Resolution Multi-Attribute Point Prediction](https://arxiv.org/abs/2507.19213)
*Hanbing Wu,Ping Jiang,Anyang Su,Chenxu Zhao,Tianyu Fu,Minghui Wu,Beiping Tan,Huiying Li*

Main category: cs.CV

TL;DR: SPA-ADV是一个大规模多模态数据集，结合PRE-MAP模型，通过强化学习和多属性用户档案优化个性化视觉注意力预测。


<details>
  <summary>Details</summary>
Motivation: 现有模型和数据集忽视了主观认知多样性对注视行为的影响，且传统显著性预测模型在捕捉个性化注意力模式方面存在局限性。

Method: 提出了PRE-MAP模型，利用强化学习优化的眼动追踪技术，结合多属性用户档案预测个性化视觉注意力点，并引入C-GRPO策略确保预测点的格式和空间准确性。

Result: 在SPA-ADV和其他基准测试上的广泛实验验证了PRE-MAP的有效性。

Conclusion: SPA-ADV数据集和PRE-MAP模型通过结合多属性用户档案和强化学习优化，显著提升了个性化视觉注意力预测的准确性和格式一致性。

Abstract: Visual selective attention, driven by individual preferences, regulates human
prioritization of visual stimuli by bridging subjective cognitive mechanisms
with objective visual elements, thereby steering the semantic interpretation
and hierarchical processing of dynamic visual scenes. However, existing models
and datasets predominantly neglect the influence of subjective cognitive
diversity on fixation behavior. Conventional saliency prediction models,
typically employing segmentation approaches, rely on low-resolution imagery to
generate saliency heatmaps, subsequently upscaled to native resolutions, which
limiting their capacity to capture personalized attention patterns.
Furthermore, MLLMs are constrained by factors such as hallucinations, making it
very costly to strictly adhere to the expected format in tasks involving
multiple point predictions, and achieving precise point positioning is
challenging. To address these limitations, we present Subjective Personalized
Attention for Advertisement Videos, namely SPA-ADV, a large-scale multimodal
dataset capturing gaze behaviors from over 4,500 participants varying in age
and gender with 486 videos. Furthermore, we propose PRE-MAP, a novel
eye-tracking saliency model that characterizes Personalized visual disparities
through Reinforcement learning-optimized Eye-tracking, built upon MLLMs and
guided by Multi-Attribute user profiles to predict Points. To ensure MLLMs
produce prediction points that are both format-correct and spatially accurate,
we introduce Consistency Group Relative Policy Optimization (C-GRPO), inspired
by the variability in eye movement points and Multi-Attribute profiles.
Extensive experiments on SPA-ADV and other benchmarks demonstrate the
effectiveness of our approach. The code and dataset are available at
\href{https://github.com/mininglamp-MLLM/PRE-MAP}{this URL}.

</details>


### [71] [Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene](https://arxiv.org/abs/2507.19232)
*Donggeun Lim,Jinseok Bae,Inwoo Hwang,Seungmin Lee,Hwanhee Lee,Young Min Kim*

Main category: cs.CV

TL;DR: 论文提出一种利用LLM生成多人类动态场景的框架，通过事件分解和高级模块实现高效上下文捕捉，展示了高可扩展性。


<details>
  <summary>Details</summary>
Motivation: 生成多人类上下文动作需要对人类间及人类与场景间的动态关系进行整体推理，现有方法难以处理这种复杂性和规模。

Method: 框架包括事件生成器将动态场景分解为小事件序列，以及高级模块将事件转化为相对描述以实现精确坐标检索。

Result: 基准测试和用户研究表明，该框架能有效捕捉场景上下文并具有高可扩展性。

Conclusion: 该论文提出了一个利用大型语言模型（LLM）生成多人类虚拟动态场景的框架，通过事件生成器和高级模块实现了场景上下文的高效捕捉和可扩展性。

Abstract: In this work, we propose a framework that creates a lively virtual dynamic
scene with contextual motions of multiple humans. Generating multi-human
contextual motion requires holistic reasoning over dynamic relationships among
human-human and human-scene interactions. We adapt the power of a large
language model (LLM) to digest the contextual complexity within textual input
and convert the task into tangible subproblems such that we can generate
multi-agent behavior beyond the scale that was not considered before.
Specifically, our event generator formulates the temporal progression of a
dynamic scene into a sequence of small events. Each event calls for a
well-defined motion involving relevant characters and objects. Next, we
synthesize the motions of characters at positions sampled based on spatial
guidance. We employ a high-level module to deliver scalable yet comprehensive
context, translating events into relative descriptions that enable the
retrieval of precise coordinates. As the first to address this problem at scale
and with diversity, we offer a benchmark to assess diverse aspects of
contextual reasoning. Benchmark results and user studies show that our
framework effectively captures scene context with high scalability. The code
and benchmark, along with result videos, are available at our project page:
https://rms0329.github.io/Event-Driven-Storytelling/.

</details>


### [72] [CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception](https://arxiv.org/abs/2507.19239)
*Jiaru Zhong,Jiahao Wang,Jiahui Xu,Xiaofan Li,Zaiqing Nie,Haibao Yu*

Main category: cs.CV

TL;DR: CoopTrack is an end-to-end framework for cooperative tracking, improving perception with low transmission costs, achieving top results on V2X-Seq.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of single-vehicle autonomous driving systems and the lack of thorough investigation in cooperative sequential perception tasks, such as cooperative 3D multi-object tracking.

Method: CoopTrack is a fully instance-level end-to-end framework featuring learnable instance association, Multi-Dimensional Feature Extraction, and Cross-Agent Association and Aggregation.

Result: CoopTrack attains 39.0% mAP and 32.8% AMOTA on the V2X-Seq dataset, showcasing excellent performance.

Conclusion: CoopTrack achieves state-of-the-art performance in cooperative sequential perception tasks, demonstrating its effectiveness in enhancing perception capabilities while maintaining low transmission costs.

Abstract: Cooperative perception aims to address the inherent limitations of
single-vehicle autonomous driving systems through information exchange among
multiple agents. Previous research has primarily focused on single-frame
perception tasks. However, the more challenging cooperative sequential
perception tasks, such as cooperative 3D multi-object tracking, have not been
thoroughly investigated. Therefore, we propose CoopTrack, a fully
instance-level end-to-end framework for cooperative tracking, featuring
learnable instance association, which fundamentally differs from existing
approaches. CoopTrack transmits sparse instance-level features that
significantly enhance perception capabilities while maintaining low
transmission costs. Furthermore, the framework comprises two key components:
Multi-Dimensional Feature Extraction, and Cross-Agent Association and
Aggregation, which collectively enable comprehensive instance representation
with semantic and motion features, and adaptive cross-agent association and
fusion based on a feature graph. Experiments on both the V2X-Seq and Griffin
datasets demonstrate that CoopTrack achieves excellent performance.
Specifically, it attains state-of-the-art results on V2X-Seq, with 39.0\% mAP
and 32.8\% AMOTA. The project is available at
https://github.com/zhongjiaru/CoopTrack.

</details>


### [73] [BridgeNet: A Unified Multimodal Framework for Bridging 2D and 3D Industrial Anomaly Detection](https://arxiv.org/abs/2507.19253)
*An Xiang,Zixuan Huang,Xitong Gao,Kejiang Ye,Cheng-zhong Xu*

Main category: cs.CV

TL;DR: 提出统一多模态异常检测框架，分离深度与外观信息，生成丰富异常，桥接2D与3D检测，实验表现优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 由于仅使用2D信息识别3D深度异常不足，且工业数据中异常样本稀缺，尤其是在多模态场景下，需要模拟真实世界的异常样本，因此提出了这一框架。

Method: 论文提出了一种统一多模态异常检测框架，包括从3D点云数据中提取可见深度信息，使用2D RGB图像表示外观，并设计了多尺度高斯异常生成器和统一纹理异常生成器来生成更丰富的RGB和深度异常。

Result: 实验结果表明，该方法在MVTec-3D AD和Eyecandies数据集上优于最先进的方法。

Conclusion: 该论文提出了一种新颖的统一多模态异常检测框架，通过分离深度和外观信息，支持统一的异常生成，并有效桥接了2D和3D异常检测。实验证明该方法在MVTec-3D AD和Eyecandies数据集上优于最先进的方法。

Abstract: Industrial anomaly detection for 2D objects has gained significant attention
and achieved progress in anomaly detection (AD) methods. However, identifying
3D depth anomalies using only 2D information is insufficient. Despite
explicitly fusing depth information into RGB images or using point cloud
backbone networks to extract depth features, both approaches struggle to
adequately represent 3D information in multimodal scenarios due to the
disparities among different modal information. Additionally, due to the
scarcity of abnormal samples in industrial data, especially in multimodal
scenarios, it is necessary to perform anomaly generation to simulate real-world
abnormal samples. Therefore, we propose a novel unified multimodal anomaly
detection framework to address these issues. Our contributions consist of 3 key
aspects. (1) We extract visible depth information from 3D point cloud data
simply and use 2D RGB images to represent appearance, which disentangles depth
and appearance to support unified anomaly generation. (2) Benefiting from the
flexible input representation, the proposed Multi-Scale Gaussian Anomaly
Generator and Unified Texture Anomaly Generator can generate richer anomalies
in RGB and depth. (3) All modules share parameters for both RGB and depth data,
effectively bridging 2D and 3D anomaly detection. Subsequent modules can
directly leverage features from both modalities without complex fusion.
Experiments show our method outperforms state-of-the-art (SOTA) on MVTec-3D AD
and Eyecandies datasets. Code available at:
https://github.com/Xantastic/BridgeNet

</details>


### [74] [OVFact: Measuring and Improving Open-Vocabulary Factuality for Long Caption Models](https://arxiv.org/abs/2507.19262)
*Monika Wysoczańska,Shyamal Buch,Anurag Arnab,Cordelia Schmid*

Main category: cs.CV

TL;DR: OV-Fact是一种无需人工标注的长字幕事实性评估方法，通过视觉定位和工具验证提升评估效果，并在数据过滤中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大视觉语言模型（VLMs）在生成长且事实性强的字幕时存在困难，且传统评估方法不适用于长字幕或无人工标注的场景。

Method: 利用开放词汇视觉定位和工具验证，设计了一种无需参考的评估方法。

Result: OV-Fact方法在人类判断一致性、描述性（召回）和事实精确性方面表现更优，且基于其过滤的数据集训练模型能显著提升事实性精确度而不牺牲描述性。

Conclusion: OV-Fact方法通过开放词汇视觉定位和工具验证，无需依赖人工标注即可有效评估长字幕的事实性，且在数据过滤应用中表现出色。

Abstract: Large vision-language models (VLMs) often struggle to generate long and
factual captions. However, traditional measures for hallucination and
factuality are not well suited for evaluating longer, more diverse captions and
in settings where ground-truth human-annotated captions are unavailable. We
introduce OV-Fact, a novel method for measuring caption factuality of long
captions that leverages open-vocabulary visual grounding and tool-based
verification without depending on human annotations. Our method improves
agreement with human judgments and captures both caption descriptiveness
(recall) and factual precision in the same metric. Furthermore, unlike previous
metrics, our reference-free method design enables new applications towards
factuality-based data filtering. We observe models trained on an
OVFact-filtered (2.5-5x less) subset of a large-scale, noisy (VLM-generated)
pretraining set meaningfully improve factuality precision without sacrificing
caption descriptiveness across a range of downstream long caption benchmarks.

</details>


### [75] [SimMLM: A Simple Framework for Multi-modal Learning with Missing Modality](https://arxiv.org/abs/2507.19264)
*Sijie Li,Chen Chen,Jungong Han*

Main category: cs.CV

TL;DR: SimMLM 是一种简单而强大的多模态学习框架，通过动态模态专家混合和 MoFe 排名损失，显著提升了缺失模态场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态学习方法依赖于复杂的网络架构或数据插补技术，SimMLM 旨在提供一种更简单且强大的框架，以适应缺失模态的场景。

Method: SimMLM 采用动态模态专家混合（DMoME）架构，结合动态可学习的门控机制，并提出 More vs. Fewer（MoFe）排名损失函数。

Result: 在 BraTS 2018、UPMC Food-101 和 avMNIST 任务中，SimMLM 均优于竞争方法，展现了更高的准确性、可解释性、鲁棒性和可靠性。

Conclusion: SimMLM 提供了一个通用且有效的解决方案，适用于各种缺失模态场景，具有更高的准确性和鲁棒性。

Abstract: In this paper, we propose SimMLM, a simple yet powerful framework for
multimodal learning with missing modalities. Unlike existing approaches that
rely on sophisticated network architectures or complex data imputation
techniques, SimMLM provides a generic and effective solution that can adapt to
various missing modality scenarios with improved accuracy and robustness.
Specifically, SimMLM consists of a generic Dynamic Mixture of Modality Experts
(DMoME) architecture, featuring a dynamic, learnable gating mechanism that
automatically adjusts each modality's contribution in both full and partial
modality settings. A key innovation of SimMLM is the proposed More vs. Fewer
(MoFe) ranking loss, which ensures that task accuracy improves or remains
stable as more modalities are made available. This aligns the model with an
intuitive principle: removing one or more modalities should not increase
accuracy. We validate SimMLM on multimodal medical image segmentation (BraTS
2018) and multimodal classification (UPMC Food-101, avMNIST) tasks, where it
consistently surpasses competitive methods, demonstrating superior accuracy,
interpretability, robustness, and reliability across both complete and missing
modality scenarios at test time.

</details>


### [76] [Video Self-Distillation for Single-Image Encoders: A Step Toward Physically Plausible Perception](https://arxiv.org/abs/2507.19272)
*Marcel Simon,Tae-Ho Kim,Seul-Ki Yeom*

Main category: cs.CV

TL;DR: 提出一种通过视频自蒸馏训练的单图像编码器，利用时间线索提升几何感知能力，显著提升ADE20K性能。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法主要基于静态图像训练，忽略了视频中固有的时间线索，限制了模型的几何感知能力。

Method: 通过训练单图像编码器预测下一帧的表示，无需光流或跟踪，直接注入3D空间和时间先验。

Result: 在单2小时视频上预训练后，ADE20K的平均交并比（mIoU）从35.0（DoRA）提升至36.4，同时保持对图像管道的即插即用兼容性。

Conclusion: 视频自蒸馏作为一种轻量级方法，能够通过学习时间线索增强单图像编码器的几何感知能力，为物理AI和世界模型提供了重要支持。

Abstract: Self-supervised image encoders such as DINO have recently gained significant
interest for learning robust visual features without labels. However, most SSL
methods train on static images and miss the temporal cues inherent in videos.
We introduce a video-distilled single-image encoder trained to predict the
next-frame representation from the current frame. This simple objective injects
3D spatial and temporal priors without optical flow or tracking. When
pre-training on a single 2-hour video, our approach raises the mean
Intersection-over-Union (mIoU) on ADE20K from 35.0 (DoRA) to 36.4 while
remaining a drop-in replacement for image-only pipelines. Our results highlight
video self-distillation as a lightweight route to geometry-aware perception an
essential ingredient for physically plausible world models and Physical AI.

</details>


### [77] [RemoteReasoner: Towards Unifying Geospatial Reasoning Workflow](https://arxiv.org/abs/2507.19280)
*Liang Yao,Fan Liu,Hongbo Lu,Chuanyi Zhang,Rui Min,Shengxiang Xu,Shimin Di,Pai Peng*

Main category: cs.CV

TL;DR: 本文提出了RemoteReasoner，一个灵活且鲁棒的遥感推理工作流，通过多模态大语言模型和强化学习实现自主推理，支持多粒度输出，无需任务特定解码器或微调。


<details>
  <summary>Details</summary>
Motivation: 遥感图像数据庞大且非结构化，现有方法依赖监督微调，限制了推理的自主性。本文旨在构建一个能处理复杂查询、自主推理的地球观测工作流。

Method: 提出RemoteReasoner框架，结合多模态大语言模型和任务自适应策略，通过强化学习训练以实现自主推理，支持多粒度输出。

Result: 初步实验表明，RemoteReasoner在多粒度推理任务中表现优异，包括区域级和像素级任务，并能实现轮廓提取等新能力。

Conclusion: RemoteReasoner通过自主推理和多粒度输出设计，显著提升了遥感图像复杂查询的处理能力，超越了现有方法。

Abstract: Remote sensing imagery presents vast, inherently unstructured spatial data,
demanding sophisticated reasoning to interpret complex user intents and
contextual relationships beyond simple recognition tasks. In this paper, we aim
to construct an Earth observation workflow to handle complex queries by
reasoning about spatial context and user intent. As a reasoning workflow, it
should be somewhat autonomous, where predefined ground-truth reasoning paths do
not constrain the learning process. Furthermore, its architecture ought to be
unified yet flexible, enabling the model to perform diverse reasoning tasks
with distinct output formats through a single forward pass. Existing remote
sensing approaches fail to address these requirements, as they rely on
supervised fine-tuning paradigms that constrain the autonomy of reasoning. To
this end, we propose RemoteReasoner, a flexible and robust workflow for remote
sensing reasoning tasks. The design of RemoteReasoner integrates a multi-modal
large language model (MLLM) for interpreting user instructions and localizing
targets, together with task adaptation strategies that enable multi-granularity
output generation. In contrast to existing methods, our framework is trained
with reinforcement learning (RL) to endow the MLLM sufficient autonomy for
precise reasoning. At the inference stage, our adaptation strategies enable
diverse output formats at inference time without requiring task-specific
decoders or further fine-tuning. Preliminary experiments demonstrated that
RemoteReasoner achieves remarkable performance across multi-granularity
reasoning tasks, including region-level and pixel-level. Additionally, our
framework enables novel capabilities such as the contour extraction task beyond
the reach of existing reasoning pipelines.

</details>


### [78] [PINO: Person-Interaction Noise Optimization for Long-Duration and Customizable Motion Generation of Arbitrary-Sized Groups](https://arxiv.org/abs/2507.19292)
*Sakuya Ota,Qing Yu,Kent Fujiwara,Satoshi Ikehata,Ikuro Sato*

Main category: cs.CV

TL;DR: PINO 是一种无需训练的框架，通过分解群组交互为成对交互并优化噪声，生成逼真且物理合理的多人交互。


<details>
  <summary>Details</summary>
Motivation: 现有的条件扩散模型在生成多人交互时依赖单一共享提示，限制了细微控制和导致交互过于简化，难以应对群组规模扩大带来的复杂性。

Method: PINO 采用了一种无需训练的框架，通过物理基础的惩罚来优化噪声，确保生成的交互在物理上合理，避免了角色重叠或穿透等常见问题。

Result: 综合评估表明，PINO 能够生成视觉上逼真、物理上连贯且可定制的多人交互。

Conclusion: PINO 框架通过分解复杂群组交互为语义相关的成对交互，并利用预训练的两人交互扩散模型，成功生成了视觉上逼真、物理上连贯且可定制的多人交互，适用于动画、游戏和机器人等多种应用。

Abstract: Generating realistic group interactions involving multiple characters remains
challenging due to increasing complexity as group size expands. While existing
conditional diffusion models incrementally generate motions by conditioning on
previously generated characters, they rely on single shared prompts, limiting
nuanced control and leading to overly simplified interactions. In this paper,
we introduce Person-Interaction Noise Optimization (PINO), a novel,
training-free framework designed for generating realistic and customizable
interactions among groups of arbitrary size. PINO decomposes complex group
interactions into semantically relevant pairwise interactions, and leverages
pretrained two-person interaction diffusion models to incrementally compose
group interactions. To ensure physical plausibility and avoid common artifacts
such as overlapping or penetration between characters, PINO employs
physics-based penalties during noise optimization. This approach allows precise
user control over character orientation, speed, and spatial relationships
without additional training. Comprehensive evaluations demonstrate that PINO
generates visually realistic, physically coherent, and adaptable multi-person
interactions suitable for diverse animation, gaming, and robotics applications.

</details>


### [79] [ABCD: Automatic Blood Cell Detection via Attention-Guided Improved YOLOX](https://arxiv.org/abs/2507.19296)
*Ahmed Endris Hasen,Yang Shangming,Chiagoziem C. Ukwuoma,Biniyam Gashaw,Abel Zenebe Yutra*

Main category: cs.CV

TL;DR: 提出基于改进YOLOX的ABCD方法，通过CBAM和ASFF优化特征提取与融合，使用CIOU加速收敛，在BCCD数据集上表现优异，适用于实时检测。


<details>
  <summary>Details</summary>
Motivation: 手动血液细胞检测耗时、低效且易出错，深度学习为基础的检测方法能有效解决这些问题。

Method: 基于改进版YOLOX的自动血液细胞检测方法（ABCD），引入了CBAM模块增强特征提取效率，ASFF优化特征融合，并使用CIOU损失函数加速模型收敛。

Result: 在BCCD数据集上，ABCD方法比基线算法mAP@0.5提高2.8%，mAP@0.5-0.9提高23.41%，检测速度提升2.9%。

Conclusion: 本研究提出的ABCD方法在BCCD数据集上表现优于现有方法，实现了95.49%的mAP@0.5和86.89%的mAP@0.5-0.9，检测速度提升了2.9%，适用于实时应用。

Abstract: Detection of blood cells in microscopic images has become a major focus of
medical image analysis, playing a crucial role in gaining valuable insights
into a patient's health. Manual blood cell checks for disease detection are
known to be time-consuming, inefficient, and error-prone. To address these
limitations, analyzing blood cells using deep learning-based object detectors
can be regarded as a feasible solution. In this study, we propose automatic
blood cell detection method (ABCD) based on an improved version of YOLOX, an
object detector, for detecting various types of blood cells, including white
blood cells, red blood cells, and platelets. Firstly, we introduce the
Convolutional Block Attention Module (CBAM) into the network's backbone to
enhance the efficiency of feature extraction. Furthermore, we introduce the
Adaptively Spatial Feature Fusion (ASFF) into the network's neck, which
optimizes the fusion of different features extracted from various stages of the
network. Finally, to speed up the model's convergence, we substitute the
Intersection over Union (IOU) loss function with the Complete Intersection over
Union (CIOU) loss function. The experimental results demonstrate that the
proposed method is more effective than other existing methods for BCCD dataset.
Compared to the baseline algorithm, our method ABCD achieved 95.49 % mAP@0.5
and 86.89 % mAP@0.5-0.9, which are 2.8% and 23.41% higher, respectively, and
increased the detection speed by 2.9%, making it highly efficient for real-time
applications.

</details>


### [80] [SemGes: Semantics-aware Co-Speech Gesture Generation using Semantic Coherence and Relevance Learning](https://arxiv.org/abs/2507.19359)
*Lanmiao Liu,Esam Ghaleb,Aslı Özyürek,Zerrin Yumak*

Main category: cs.CV

TL;DR: A novel two-stage approach for generating semantically coherent gestures in virtual avatars, integrating speech and text-based semantics, outperforms existing methods in realism and coherence.


<details>
  <summary>Details</summary>
Motivation: Existing gesture generation research primarily focused on rhythmic beat gestures, neglecting semantic context, which limits the realism and coherence of virtual avatars. This paper addresses this gap by integrating semantic information at both fine-grained and global levels.

Method: The method involves a two-stage process: first, learning motion prior through a vector-quantized variational autoencoder, and second, generating gestures from speech, text-based semantics, and speaker identity using semantic coherence and relevance modules.

Result: Experimental results demonstrate superior performance in generating semantically coherent gestures compared to state-of-the-art methods, validated through extensive experiments and user studies.

Conclusion: The proposed approach significantly enhances the realism and coherence of semantic gestures in virtual avatars, outperforming existing state-of-the-art methods in both objective and subjective evaluations.

Abstract: Creating a virtual avatar with semantically coherent gestures that are
aligned with speech is a challenging task. Existing gesture generation research
mainly focused on generating rhythmic beat gestures, neglecting the semantic
context of the gestures. In this paper, we propose a novel approach for
semantic grounding in co-speech gesture generation that integrates semantic
information at both fine-grained and global levels. Our approach starts with
learning the motion prior through a vector-quantized variational autoencoder.
Built on this model, a second-stage module is applied to automatically generate
gestures from speech, text-based semantics and speaker identity that ensures
consistency between the semantic relevance of generated gestures and
co-occurring speech semantics through semantic coherence and relevance modules.
Experimental results demonstrate that our approach enhances the realism and
coherence of semantic gestures. Extensive experiments and user studies show
that our method outperforms state-of-the-art approaches across two benchmarks
in co-speech gesture generation in both objective and subjective metrics. The
qualitative results of our model, code, dataset and pre-trained models can be
viewed at https://semgesture.github.io/.

</details>


### [81] [EA-ViT: Efficient Adaptation for Elastic Vision Transformer](https://arxiv.org/abs/2507.19360)
*Chen Zhu,Wangbo Zhao,Huiwen Zhang,Samir Khaki,Yuhao Zhou,Weidong Tang,Shuo Wang,Zhihang Yuan,Yuzhang Shang,Xiaojiang Peng,Kai Wang,Dawei Yang*

Main category: cs.CV

TL;DR: EA-ViT提出一种高效ViT适应框架，通过弹性架构和路由器，单次适应即可生成多种规模模型，解决多样化部署需求。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在多样化资源约束下部署时需多次训练不同规模模型的时间和能源消耗问题。

Method: 采用两阶段方法：第一阶段通过嵌套弹性架构增强预训练ViT，支持MLP扩展比、注意力头数、嵌入维度和网络深度的结构灵活性；第二阶段设计轻量级路由器，根据计算预算和任务需求选择子模型。

Result: 在多个基准测试中验证了EA-ViT的有效性和多功能性，代码已开源。

Conclusion: EA-ViT框架通过嵌套弹性架构和轻量级路由器，有效解决了Vision Transformers在不同资源约束下部署的挑战，展示了其在多个基准测试中的高效性和多功能性。

Abstract: Vision Transformers (ViTs) have emerged as a foundational model in computer
vision, excelling in generalization and adaptation to downstream tasks.
However, deploying ViTs to support diverse resource constraints typically
requires retraining multiple, size-specific ViTs, which is both time-consuming
and energy-intensive. To address this issue, we propose an efficient ViT
adaptation framework that enables a single adaptation process to generate
multiple models of varying sizes for deployment on platforms with various
resource constraints. Our approach comprises two stages. In the first stage, we
enhance a pre-trained ViT with a nested elastic architecture that enables
structural flexibility across MLP expansion ratio, number of attention heads,
embedding dimension, and network depth. To preserve pre-trained knowledge and
ensure stable adaptation, we adopt a curriculum-based training strategy that
progressively increases elasticity. In the second stage, we design a
lightweight router to select submodels according to computational budgets and
downstream task demands. Initialized with Pareto-optimal configurations derived
via a customized NSGA-II algorithm, the router is then jointly optimized with
the backbone. Extensive experiments on multiple benchmarks demonstrate the
effectiveness and versatility of EA-ViT. The code is available at
https://github.com/zcxcf/EA-ViT.

</details>


### [82] [BEV-LLM: Leveraging Multimodal BEV Maps for Scene Captioning in Autonomous Driving](https://arxiv.org/abs/2507.19370)
*Felix Brandstaetter,Erik Schuetz,Katharina Winter,Fabian Flohr*

Main category: cs.CV

TL;DR: BEV-LLM是一种轻量级3D场景描述模型，结合LiDAR和多视角图像，性能优越，并发布新数据集nuView和GroundView以填补基准空白。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶技术的广泛应用依赖于可解释和透明的决策系统。场景描述（生成驾驶环境的自然语言描述）在提升透明度、安全性和人机交互方面起着关键作用。

Method: BEV-LLM利用BEVFusion技术结合3D LiDAR点云和多视角图像，并采用了一种新型绝对位置编码方法，用于生成视图特定的场景描述。

Result: BEV-LLM在nuCaption数据集上表现优异，BLEU分数超越现有技术最高达5%。新发布的数据集nuView和GroundView提供了更全面的评估标准。

Conclusion: BEV-LLM通过结合3D LiDAR点云和多视角图像，引入了一种新型绝对位置编码，用于视图特定的场景描述。尽管使用了小型1B参数基础模型，BEV-LLM在nuCaption数据集上表现优异，BLEU分数超越现有技术最高达5%。此外，新发布的两个数据集nuView和GroundView，旨在更全面地评估不同驾驶场景下的场景描述能力，填补了当前基准的空白。

Abstract: Autonomous driving technology has the potential to transform transportation,
but its wide adoption depends on the development of interpretable and
transparent decision-making systems. Scene captioning, which generates natural
language descriptions of the driving environment, plays a crucial role in
enhancing transparency, safety, and human-AI interaction. We introduce BEV-LLM,
a lightweight model for 3D captioning of autonomous driving scenes. BEV-LLM
leverages BEVFusion to combine 3D LiDAR point clouds and multi-view images,
incorporating a novel absolute positional encoding for view-specific scene
descriptions. Despite using a small 1B parameter base model, BEV-LLM achieves
competitive performance on the nuCaption dataset, surpassing state-of-the-art
by up to 5\% in BLEU scores. Additionally, we release two new datasets - nuView
(focused on environmental conditions and viewpoints) and GroundView (focused on
object grounding) - to better assess scene captioning across diverse driving
scenarios and address gaps in current benchmarks, along with initial
benchmarking results demonstrating their effectiveness.

</details>


### [83] [Modality Agnostic Efficient Long Range Encoder](https://arxiv.org/abs/2507.19409)
*Toufiq Parag,Ahmed Elgammal*

Main category: cs.CV

TL;DR: MAELRE是一种高效的Transformer架构，通过token合并和动态注意力机制优化长上下文处理，在多种模态任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决通用单设备实现中长上下文处理的挑战，通过减少二次内存占用和推理成本，克服现有方法在模态特定性和效率-准确性权衡上的不足。

Method: MAELRE通过将token合并与注意力近似相结合，逐步在不同计算阶段合并token，并在token数量较大时采用轻量级注意力近似，随着序列通过连续聚合变短时切换为标准点积注意力。

Result: MAELRE在涵盖文本、时间序列、音频和视觉的多种模态分类任务上，相比现有长上下文模型，实现了更高的准确性并降低了计算成本。

Conclusion: MAELRE作为一种统一且高效的Transformer架构，能够在多种模态上实现长距离编码，同时降低计算成本并保持高准确性。

Abstract: The long-context capability of recent large transformer models can be
surmised to rely on techniques such as attention/model parallelism, as well as
hardware-level optimizations. While these strategies allow input lengths to
scale to millions of tokens, they do not fundamentally mitigate the quadratic
computational and memory complexity of the core attention mechanism. In this
paper, we address the challenge of long-context processing on a single device
using generic implementations by reducing the quadratic memory footprint and
inference cost. Existing approaches to extend the context length for generic
single device implementations -- such as token merging and modified attentions
-- are often modality specific and attain a suboptimal tradeoff between
accuracy and efficiency. To overcome these limitations, we propose MAELRE
(Modality Agnostic Efficient Long Range Encoder), a unified and efficient
transformer architecture designed for long-range encoding across diverse
modalities. MAELRE integrates token merging with attention approximation,
progressively merging tokens at different stages of internal computational
blocks. It employs a lightweight attention approximation when the number of
tokens is large, and switches to standard dot-product attention as the sequence
becomes shorter through successive aggregation. We demonstrate that MAELRE
achieves superior accuracy while reducing computational cost compared to
existing long-context models on classification tasks spanning multiple
modalities, including text, time series, audio, and vision.

</details>


### [84] [DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment](https://arxiv.org/abs/2507.19418)
*Yiwei Lou,Yuanpeng He,Rongchao Zhang,Yongzhi Cao,Hanpin Wang,Yu Huang*

Main category: cs.CV

TL;DR: DEFNet通过多任务优化和可信信息融合策略，提升了盲图像质量评估的性能，并展示了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有盲图像质量评估方法因集成不足和缺乏灵活的不确定性估计而导致性能不佳。

Method: 提出了一种基于多任务的深度证据融合网络（DEFNet），结合场景和失真类型分类任务进行多任务优化，并设计了可信信息融合策略。

Result: 在合成和真实失真数据集上的大量实验证明了DEFNet的有效性和鲁棒性。

Conclusion: DEFNet通过多任务优化和可信信息融合策略，显著提升了盲图像质量评估的性能，并展示了强大的泛化能力和适应性。

Abstract: Blind image quality assessment (BIQA) methods often incorporate auxiliary
tasks to improve performance. However, existing approaches face limitations due
to insufficient integration and a lack of flexible uncertainty estimation,
leading to suboptimal performance. To address these challenges, we propose a
multitasks-based Deep Evidential Fusion Network (DEFNet) for BIQA, which
performs multitask optimization with the assistance of scene and distortion
type classification tasks. To achieve a more robust and reliable
representation, we design a novel trustworthy information fusion strategy. It
first combines diverse features and patterns across sub-regions to enhance
information richness, and then performs local-global information fusion by
balancing fine-grained details with coarse-grained context. Moreover, DEFNet
exploits advanced uncertainty estimation technique inspired by evidential
learning with the help of normal-inverse gamma distribution mixture. Extensive
experiments on both synthetic and authentic distortion datasets demonstrate the
effectiveness and robustness of the proposed framework. Additional evaluation
and analysis are carried out to highlight its strong generalization capability
and adaptability to previously unseen scenarios.

</details>


### [85] [CircuitProbe: Dissecting Spatiotemporal Visual Semantics with Circuit Tracing](https://arxiv.org/abs/2507.19420)
*Yiming Zhang,Chengzhang Yu,Zhuokai Zhao,Kun Wang,Qiankun Li,Zihan Chen,Yang Liu,Zenghui Ding,Yining Sun*

Main category: cs.CV

TL;DR: 本文提出一个电路框架研究LVLMs的时空语义处理，发现视觉语义高度集中于特定标记且中后层对时空语义有专门定位，为设计更鲁棒模型提供见解。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型（LVLMs）的语言和图像理解处理机制已得到广泛研究，但其内部时空理解的推理机制仍知之甚少。

Method: 提出了一个基于电路的框架，包含视觉审计电路、语义追踪电路和注意力流电路，用于研究LVLMs中时空视觉语义的表示和处理。

Result: 发现视觉语义高度集中于特定对象标记，移除这些标记会使模型性能下降高达92.6%；同时发现对象和动作的可解释概念在LVLMs的中后层逐渐细化，且这些层对时空语义表现出专门的功能定位。

Conclusion: 研究发现为LVLMs的时空语义分析提供了重要的机制性见解，为设计更鲁棒和可解释的模型奠定了基础。

Abstract: The processing mechanisms underlying language and image understanding in
large vision-language models (LVLMs) have been extensively studied. However,
the internal reasoning mechanisms of LVLMs for spatiotemporal understanding
remain poorly understood. In this work, we introduce a systematic,
circuit-based framework designed to investigate how spatiotemporal visual
semantics are represented and processed within these LVLMs. Specifically, our
framework comprises three circuits: visual auditing circuit, semantic tracing
circuit, and attention flow circuit. Through the lens of these circuits, we
discover that visual semantics are highly localized to specific object
tokens--removing these tokens can degrade model performance by up to 92.6%.
Furthermore, we identify that interpretable concepts of objects and actions
emerge and become progressively refined in the middle-to-late layers of LVLMs.
In contrary to the current works that solely focus on objects in one image, we
reveal that the middle-to-late layers of LVLMs exhibit specialized functional
localization for spatiotemporal semantics. Our findings offer significant
mechanistic insights into spatiotemporal semantics analysis of LVLMs, laying a
foundation for designing more robust and interpretable models.

</details>


### [86] [GS-Occ3D: Scaling Vision-only Occupancy Reconstruction for Autonomous Driving with Gaussian Splatting](https://arxiv.org/abs/2507.19451)
*Baijun Ye,Minghui Qin,Saining Zhang,Moonjun Gong,Shaoting Zhu,Zebang Shen,Luan Zhang,Lu Zhang,Hao Zhao,Hang Zhao*

Main category: cs.CV

TL;DR: GS-Occ3D提出了一种基于视觉的可扩展占用重建框架，通过优化显式表示和场景分解，解决了现有方法的局限性，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖LiDAR标注，限制了可扩展性和利用众包数据进行自动标注的能力。视觉占用重建面临稀疏视角、动态元素和遮挡等挑战。

Method: GS-Occ3D采用Octree-based Gaussian Surfel公式优化显式占用表示，并将场景分解为静态背景、地面和动态对象，分别建模。

Result: 在Waymo数据集上，GS-Occ3D实现了最先进的几何重建结果，并在Occ3D-Waymo和Occ3D-nuScenes上展示了卓越的零样本泛化能力。

Conclusion: GS-Occ3D展示了基于视觉的占用重建作为自动驾驶感知新范式的潜力，通过优化显式占用表示和场景分解策略，实现了高效的几何重建。

Abstract: Occupancy is crucial for autonomous driving, providing essential geometric
priors for perception and planning. However, existing methods predominantly
rely on LiDAR-based occupancy annotations, which limits scalability and
prevents leveraging vast amounts of potential crowdsourced data for
auto-labeling. To address this, we propose GS-Occ3D, a scalable vision-only
framework that directly reconstructs occupancy. Vision-only occupancy
reconstruction poses significant challenges due to sparse viewpoints, dynamic
scene elements, severe occlusions, and long-horizon motion. Existing
vision-based methods primarily rely on mesh representation, which suffer from
incomplete geometry and additional post-processing, limiting scalability. To
overcome these issues, GS-Occ3D optimizes an explicit occupancy representation
using an Octree-based Gaussian Surfel formulation, ensuring efficiency and
scalability. Additionally, we decompose scenes into static background, ground,
and dynamic objects, enabling tailored modeling strategies: (1) Ground is
explicitly reconstructed as a dominant structural element, significantly
improving large-area consistency; (2) Dynamic vehicles are separately modeled
to better capture motion-related occupancy patterns. Extensive experiments on
the Waymo dataset demonstrate that GS-Occ3D achieves state-of-the-art geometry
reconstruction results. By curating vision-only binary occupancy labels from
diverse urban scenes, we show their effectiveness for downstream occupancy
models on Occ3D-Waymo and superior zero-shot generalization on Occ3D-nuScenes.
It highlights the potential of large-scale vision-based occupancy
reconstruction as a new paradigm for autonomous driving perception. Project
Page: https://gs-occ3d.github.io/

</details>


### [87] [Back to the Features: DINO as a Foundation for Video World Models](https://arxiv.org/abs/2507.19468)
*Federico Baldassarre,Marc Szafraniec,Basile Terver,Vasil Khalidov,Francisco Massa,Yann LeCun,Patrick Labatut,Maximilian Seitzer,Piotr Bojanowski*

Main category: cs.CV

TL;DR: DINO-world是一个基于DINOv2的视频世界模型，通过预测未来帧在潜在空间中的表现，优于现有模型，并能适应规划任务。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过预训练图像编码器和未来预测器，构建一个通用的视频世界模型，以理解和预测多样场景的动态。

Method: 利用预训练的DINOv2图像编码器，在大规模未筛选视频数据集上训练未来帧预测器，学习多样场景的时间动态。

Result: DINO-world在多个视频预测基准测试中优于先前模型，展示了强大的直观物理理解能力，并能通过微调用于规划任务。

Conclusion: DINO-world展示了在视频预测任务中的优越性能，并能通过微调适应观察-动作轨迹，为潜在空间中的规划提供了新的可能性。

Abstract: We present DINO-world, a powerful generalist video world model trained to
predict future frames in the latent space of DINOv2. By leveraging a
pre-trained image encoder and training a future predictor on a large-scale
uncurated video dataset, DINO-world learns the temporal dynamics of diverse
scenes, from driving and indoor scenes to simulated environments. We show that
DINO-world outperforms previous models on a variety of video prediction
benchmarks, e.g. segmentation and depth forecasting, and demonstrates strong
understanding of intuitive physics. Furthermore, we show that it is possible to
fine-tune the predictor on observation-action trajectories. The resulting
action-conditioned world model can be used for planning by simulating candidate
trajectories in latent space.

</details>


### [88] [DINO-SLAM: DINO-informed RGB-D SLAM for Neural Implicit and Explicit Representations](https://arxiv.org/abs/2507.19474)
*Ziren Gong,Xiaohan Li,Fabio Tosi,Youmin Zhang,Stefano Mattoccia,Jun Wu,Matteo Poggi*

Main category: cs.CV

TL;DR: DINO-SLAM利用EDINO特征增强NeRF和3DGS在SLAM中的表现，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 通过更全面的场景表示来增强神经隐式（NeRF）和显式（3DGS）表示在SLAM系统中的性能。

Method: 提出了一种场景结构编码器（SSE），将DINO特征增强为EDINO特征，以捕捉场景的层次结构和关系，并基于此设计了两种SLAM系统的范式。

Result: 在Replica、ScanNet和TUM数据集上，DINO-SLAM的性能优于现有方法。

Conclusion: DINO-SLAM通过整合EDINO特征，在NeRF和3DGS SLAM系统中实现了优于现有技术的性能。

Abstract: This paper presents DINO-SLAM, a DINO-informed design strategy to enhance
neural implicit (Neural Radiance Field -- NeRF) and explicit representations
(3D Gaussian Splatting -- 3DGS) in SLAM systems through more comprehensive
scene representations. Purposely, we rely on a Scene Structure Encoder (SSE)
that enriches DINO features into Enhanced DINO ones (EDINO) to capture
hierarchical scene elements and their structural relationships. Building upon
it, we propose two foundational paradigms for NeRF and 3DGS SLAM systems
integrating EDINO features. Our DINO-informed pipelines achieve superior
performance on the Replica, ScanNet, and TUM compared to state-of-the-art
methods.

</details>


### [89] [MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents](https://arxiv.org/abs/2507.19478)
*Xuehui Wang,Zhenyu Wu,JingJing Xie,Zichen Ding,Bowen Yang,Zehao Li,Zhaoyang Liu,Qingyun Li,Xuan Dong,Zhe Chen,Weiyun Wang,Xiangyu Zhao,Jixuan Chen,Haodong Duan,Tianbao Xie,Chenyu Yang,Shiqian Su,Yue Yu,Yuan Huang,Yiqian Liu,Xiao Zhang,Yanting Zhang,Xiangyu Yue,Weijie Su,Xizhou Zhu,Wei Shen,Jifeng Dai,Wenhai Wang*

Main category: cs.CV

TL;DR: MMBench-GUI是一个跨平台GUI自动化代理评估基准，提出EQA指标并发现视觉定位和任务效率是关键挑战。


<details>
  <summary>Details</summary>
Motivation: 为了解决GUI自动化代理在跨平台任务中的评估问题，并识别影响任务成功的关键因素（如视觉定位和任务效率）。

Method: 提出了一个分层基准MMBench-GUI，包含四个级别（GUI内容理解、元素定位、任务自动化和任务协作），并引入EQA指标评估在线自动化场景中的执行效率。

Result: 发现视觉定位是任务成功的关键，模块化框架和跨平台泛化能力至关重要，且当前模型存在效率低下的问题。

Conclusion: MMBench-GUI的引入强调了视觉定位、任务规划和跨平台泛化能力对GUI自动化代理的重要性，同时指出了任务效率这一未充分探索的维度。通过提出EQA指标和公开基准代码，为未来研究提供了重要工具和方向。

Abstract: We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI
automation agents across Windows, macOS, Linux, iOS, Android, and Web
platforms. It comprises four levels: GUI Content Understanding, Element
Grounding, Task Automation, and Task Collaboration, covering essential skills
for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA)
metric to assess GUI agent execution efficiency in online automation scenarios.
Through MMBench-GUI, we identify accurate visual grounding as a critical
determinant of overall task success, emphasizing the substantial benefits of
modular frameworks that integrate specialized grounding modules. Furthermore,
to achieve reliable GUI automation, an agent requires strong task planning and
cross-platform generalization abilities, with long-context memory, a broad
action space, and long-term reasoning playing a critical role. More important,
task efficiency remains a critically underexplored dimension, and all models
suffer from substantial inefficiencies, with excessive redundant steps even
when tasks are ultimately completed. The integration of precise localization,
effective planning, and early stopping strategies is indispensable to enable
truly efficient and scalable GUI automation. Our benchmark code, evaluation
data, and running environment will be publicly available at
https://github.com/open-compass/MMBench-GUI.

</details>


### [90] [HairCUP: Hair Compositional Universal Prior for 3D Gaussian Avatars](https://arxiv.org/abs/2507.19481)
*Byungjun Kim,Shunsuke Saito,Giljoo Nam,Tomas Simon,Jason Saragih,Hanbyul Joo,Junxuan Li*

Main category: cs.CV

TL;DR: 提出了一种显式分离脸部和头发潜在空间的3D头像先验模型，支持灵活的面部和发型交换，并通过少样本微调生成高保真头像。


<details>
  <summary>Details</summary>
Motivation: 现有3D头像先验建模方法通常将脸部和头发视为不可分割的整体，导致难以自然解耦表示，且无法灵活支持面部和发型交换等应用。

Method: 提出了一种显式考虑脸部和头发组合性的先验模型，通过合成无发数据集训练分离的脸部和头发潜在空间，并利用组合性作为归纳偏置。

Result: 模型能够无缝转移不同头像的脸部和头发组件，同时保持身份一致性，并通过少样本微调生成高质量3D头像。

Conclusion: 该模型通过显式分离脸部和头发的潜在空间，实现了灵活可控的3D面部和发型交换，并通过少样本微调支持高保真3D头像生成，具有实际应用价值。

Abstract: We present a universal prior model for 3D head avatars with explicit hair
compositionality. Existing approaches to build generalizable priors for 3D head
avatars often adopt a holistic modeling approach, treating the face and hair as
an inseparable entity. This overlooks the inherent compositionality of the
human head, making it difficult for the model to naturally disentangle face and
hair representations, especially when the dataset is limited. Furthermore, such
holistic models struggle to support applications like 3D face and hairstyle
swapping in a flexible and controllable manner. To address these challenges, we
introduce a prior model that explicitly accounts for the compositionality of
face and hair, learning their latent spaces separately. A key enabler of this
approach is our synthetic hairless data creation pipeline, which removes hair
from studio-captured datasets using estimated hairless geometry and texture
derived from a diffusion prior. By leveraging a paired dataset of hair and
hairless captures, we train disentangled prior models for face and hair,
incorporating compositionality as an inductive bias to facilitate effective
separation. Our model's inherent compositionality enables seamless transfer of
face and hair components between avatars while preserving identity.
Additionally, we demonstrate that our model can be fine-tuned in a few-shot
manner using monocular captures to create high-fidelity, hair-compositional 3D
head avatars for unseen subjects. These capabilities highlight the practical
applicability of our approach in real-world scenarios, paving the way for
flexible and expressive 3D avatar generation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [91] [Initial Steps in Integrating Large Reasoning and Action Models for Service Composition](https://arxiv.org/abs/2507.18775)
*Ilche Georgievski,Marco Aiello*

Main category: cs.AI

TL;DR: 论文提出集成LRM和LAM的框架，以解决服务组合中的推理和执行挑战，实现自动化、用户友好的流程。


<details>
  <summary>Details</summary>
Motivation: 服务组合在构建自适应和智能软件系统中仍面临挑战，现有方法在推理能力和执行机制上存在局限。

Method: 提出了一种集成大型推理模型（LRM）和大型动作模型（LAM）的架构框架。

Result: 集成LRM和LAM的系统能够在推理服务需求和约束的同时动态执行工作流，弥合意图与执行之间的差距。

Conclusion: 整合LRM和LAM的架构框架为自动化服务组合提供了有前景的方向，有望实现由高级自然语言意图驱动的用户友好流程。

Abstract: Service composition remains a central challenge in building adaptive and
intelligent software systems, often constrained by limited reasoning
capabilities or brittle execution mechanisms. This paper explores the
integration of two emerging paradigms enabled by large language models: Large
Reasoning Models (LRMs) and Large Action Models (LAMs). We argue that LRMs
address the challenges of semantic reasoning and ecosystem complexity while
LAMs excel in dynamic action execution and system interoperability. However,
each paradigm has complementary limitations - LRMs lack grounded action
capabilities, and LAMs often struggle with deep reasoning. We propose an
integrated LRM-LAM architectural framework as a promising direction for
advancing automated service composition. Such a system can reason about service
requirements and constraints while dynamically executing workflows, thus
bridging the gap between intention and execution. This integration has the
potential to transform service composition into a fully automated,
user-friendly process driven by high-level natural language intent.

</details>


### [92] [Simulation-Driven Reinforcement Learning in Queuing Network Routing Optimization](https://arxiv.org/abs/2507.18795)
*Fatima Al-Ani,Molly Wang,Jevon Charles,Aaron Ong,Joshua Forday,Vinayak Modi*

Main category: cs.AI

TL;DR: 提出Dyna-DDPG框架优化排队网络路由，实验显示其鲁棒性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统排队方法在动态和不确定环境中表现不佳，因此需要一种更鲁棒的强化学习框架来优化路由决策。

Method: 采用Deep Deterministic Policy Gradient (DDPG)与Dyna-style规划相结合的Dyna-DDPG方法，构建了灵活的仿真环境以模拟多样化排队场景。

Result: 实验证明，该框架能快速学习有效的路由策略，在干扰下保持鲁棒性能，并能扩展到更大规模的网络。

Conclusion: 该研究提出了一种结合Dyna-DDPG的强化学习框架，有效优化了复杂排队网络中的路由决策，并在制造和通信应用中展示了鲁棒性和可扩展性。

Abstract: This study focuses on the development of a simulation-driven reinforcement
learning (RL) framework for optimizing routing decisions in complex queueing
network systems, with a particular emphasis on manufacturing and communication
applications. Recognizing the limitations of traditional queueing methods,
which often struggle with dynamic, uncertain environments, we propose a robust
RL approach leveraging Deep Deterministic Policy Gradient (DDPG) combined with
Dyna-style planning (Dyna-DDPG). The framework includes a flexible and
configurable simulation environment capable of modeling diverse queueing
scenarios, disruptions, and unpredictable conditions. Our enhanced Dyna-DDPG
implementation incorporates separate predictive models for next-state
transitions and rewards, significantly improving stability and sample
efficiency. Comprehensive experiments and rigorous evaluations demonstrate the
framework's capability to rapidly learn effective routing policies that
maintain robust performance under disruptions and scale effectively to larger
network sizes. Additionally, we highlight strong software engineering practices
employed to ensure reproducibility and maintainability of the framework,
enabling practical deployment in real-world scenarios.

</details>


### [93] [A Neuroscience-Inspired Dual-Process Model of Compositional Generalization](https://arxiv.org/abs/2507.18868)
*Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun*

Main category: cs.AI

TL;DR: MIRAGE框架通过模拟人脑的HPC-PFC机制，结合Transformer和模式引擎，实现了高效的组合泛化能力，在SCAN测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决AI系统在组合泛化（构建和理解已知构建块的新组合）方面的核心挑战，受人类认知中HPC与PFC交互机制的启发。

Method: MIRAGE包含两个模块：基于元训练的Transformer神经分解器和模式引擎，分别模拟大脑的直觉性模式识别和深思熟虑的HPC-PFC循环。

Result: 在SCAN基准测试中，MIRAGE实现了>99%的准确率，且Transformer模块仅需1.19M参数。消融研究证实了模式质量和迭代优化过程的关键作用。

Conclusion: MIRAGE框架通过模拟人脑的HPC-PFC交互机制，实现了系统性的组合泛化能力，尤其在SCAN基准测试中表现出色。

Abstract: Systematic compositional generalization - constructing and understanding
novel combinations of known building blocks - remains a core challenge for AI
systems. Human cognition achieves this flexibility via the interplay of the
hippocampus (HPC) and prefrontal cortex (PFC): the hippocampus rapidly encodes
episodes, and the prefrontal cortex consolidates them into reusable schemas for
reasoning. Drawing on these insights, we present MIRAGE (Meta-Inference with
Rules and Abstractions from Generalized Experience), a framework that achieves
systematic generalization on compositional tasks. MIRAGE has two interacting
modules mirroring the brain's deliberative HPC-PFC loop and intuitive
neocortical pattern recognition. (1) The meta-trained Transformer Neural
Decomposer, paralleling neocortical "System 1" computation, is trained on a
task-agnostic stream of randomly sampled compositional grammars and applies one
decomposition step per pass, with successive passes iteratively refining the
sequence representation. (2) The Schema Engine, analogous to the HPC-PFC
"System 2" loop, dynamically extracts, ranks, and applies reusable schemas,
storing variable bindings in episodic memory and expanding them when needed. By
explicitly equipping the Transformer component of MIRAGE with actively managed
schematic structures, our model performs systematic compositional operations
through explicit schema application and transformation, relying solely on
frozen weights when solving entirely novel tasks. This approach demonstrates
systematic compositional generalization on the SCAN benchmark, achieving > 99%
accuracy on all task splits with only 1.19M parameters in the transformer
module. Ablation studies confirm that MIRAGE's systematicity critically depends
on the quality of extracted schemas and the model's iterative refinement
process.

</details>


### [94] [Success in Humanoid Reinforcement Learning under Partial Observation](https://arxiv.org/abs/2507.18883)
*Wuhao Wang,Zhiyong Chen*

Main category: cs.AI

TL;DR: 首次在部分可观测环境下成功训练人形机器人策略，性能媲美全状态访问，关键创新是历史编码器。


<details>
  <summary>Details</summary>
Motivation: 解决在部分可观测条件下高维任务（如人形机器人运动）中策略学习的挑战。

Method: 采用标准无模型算法结合新型历史编码器处理固定长度的过去观测序列。

Result: 学习到的策略在仅使用原始状态1/3至2/3的情况下，性能与全状态访问的最先进结果相当，并展示了对机器人属性变化的适应性。

Conclusion: 本研究成功在部分可观测环境下训练出与全状态访问性能相当的人形机器人策略，关键在于新型历史编码器的应用。

Abstract: Reinforcement learning has been widely applied to robotic control, but
effective policy learning under partial observability remains a major
challenge, especially in high-dimensional tasks like humanoid locomotion. To
date, no prior work has demonstrated stable training of humanoid policies with
incomplete state information in the benchmark Gymnasium Humanoid-v4
environment. The objective in this environment is to walk forward as fast as
possible without falling, with rewards provided for staying upright and moving
forward, and penalties incurred for excessive actions and external contact
forces. This research presents the first successful instance of learning under
partial observability in this environment. The learned policy achieves
performance comparable to state-of-the-art results with full state access,
despite using only one-third to two-thirds of the original states. Moreover,
the policy exhibits adaptability to robot properties, such as variations in
body part masses. The key to this success is a novel history encoder that
processes a fixed-length sequence of past observations in parallel. Integrated
into a standard model-free algorithm, the encoder enables performance on par
with fully observed baselines. We hypothesize that it reconstructs essential
contextual information from recent observations, thereby enabling robust
decision-making.

</details>


### [95] [Towards Improving Long-Tail Entity Predictions in Temporal Knowledge Graphs through Global Similarity and Weighted Sampling](https://arxiv.org/abs/2507.18977)
*Mehrnoosh Mirtaheri,Ryan A. Rossi,Sungchul Kim,Kanak Mahadik,Tong Yu,Xiang Chen,Mohammad Rostami*

Main category: cs.AI

TL;DR: 提出一种针对时态知识图谱的增量训练框架，通过增强层和加权采样策略处理新实体和稀疏连接，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统TKG补全模型假设训练时可访问整个图谱，忽视了图谱动态演化带来的挑战，如新知识吸收和新实体处理。

Method: 结合模型无关的增强层和加权采样策略，增强层利用全局实体相似性定义，加权采样策略则强调稀疏实体的边。

Result: 在两个基准数据集上，该方法在整体链接预测、归纳链接预测及长尾实体处理方面优于现有方法，MRR提升了15%。

Conclusion: 该论文提出的增量训练框架显著提升了时态知识图谱（TKG）补全方法的性能，特别是在处理新实体和稀疏连接实体方面，展现了其在增量训练场景中的潜力。

Abstract: Temporal Knowledge Graph (TKG) completion models traditionally assume access
to the entire graph during training. This overlooks challenges stemming from
the evolving nature of TKGs, such as: (i) the model's requirement to generalize
and assimilate new knowledge, and (ii) the task of managing new or unseen
entities that often have sparse connections. In this paper, we present an
incremental training framework specifically designed for TKGs, aiming to
address entities that are either not observed during training or have sparse
connections. Our approach combines a model-agnostic enhancement layer with a
weighted sampling strategy, that can be augmented to and improve any existing
TKG completion method. The enhancement layer leverages a broader, global
definition of entity similarity, which moves beyond mere local neighborhood
proximity of GNN-based methods. The weighted sampling strategy employed in
training accentuates edges linked to infrequently occurring entities. We
evaluate our method on two benchmark datasets, and demonstrate that our
framework outperforms existing methods in total link prediction, inductive link
prediction, and in addressing long-tail entities. Notably, our method achieves
a 10\% improvement and a 15\% boost in MRR for these datasets. The results
underscore the potential of our approach in mitigating catastrophic forgetting
and enhancing the robustness of TKG completion methods, especially in an
incremental training context

</details>


### [96] [Fine-Grained Traffic Inference from Road to Lane via Spatio-Temporal Graph Node Generation](https://arxiv.org/abs/2507.19089)
*Shuhao Li,Weidong Yang,Yue Cui,Xiaoxing Liu,Lingkai Meng,Lipeng Ma,Fan Zhang*

Main category: cs.AI

TL;DR: 提出FRTI任务及RoadDiff框架，利用有限道路数据推断车道级交通信息，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决因传感器类型和数量限制以及跟踪算法精度问题导致的车道级交通数据获取瓶颈。

Method: 设计了两阶段框架RoadDiff，包括Road-Lane Correlation Autoencoder-Decoder和Lane Diffusion Module，充分利用道路数据的时空依赖性和分布关系。

Result: 在六个不同道路条件下的数据集上验证了RoadDiff模型的有效性。

Conclusion: FRTI任务通过RoadDiff框架成功实现了基于有限道路数据的细粒度车道级交通信息推断，为精确交通管理提供了高效且经济的解决方案。

Abstract: Fine-grained traffic management and prediction are fundamental to key
applications such as autonomous driving, lane change guidance, and traffic
signal control. However, obtaining lane-level traffic data has become a
critical bottleneck for data-driven models due to limitations in the types and
number of sensors and issues with the accuracy of tracking algorithms. To
address this, we propose the Fine-grained Road Traffic Inference (FRTI) task,
which aims to generate more detailed lane-level traffic information using
limited road data, providing a more energy-efficient and cost-effective
solution for precise traffic management. This task is abstracted as the first
scene of the spatio-temporal graph node generation problem. We designed a
two-stage framework--RoadDiff--to solve the FRTI task. solve the FRTI task.
This framework leverages the Road-Lane Correlation Autoencoder-Decoder and the
Lane Diffusion Module to fully utilize the limited spatio-temporal dependencies
and distribution relationships of road data to accurately infer fine-grained
lane traffic states. Based on existing research, we designed several baseline
models with the potential to solve the FRTI task and conducted extensive
experiments on six datasets representing different road conditions to validate
the effectiveness of the RoadDiff model in addressing the FRTI task. The
relevant datasets and code are available at
https://github.com/ShuhaoLii/RoadDiff.

</details>


### [97] [Pareto-NRPA: A Novel Monte-Carlo Search Algorithm for Multi-Objective Optimization](https://arxiv.org/abs/2507.19109)
*Noé Lallouet,Tristan Cazenave,Cyrille Enderli*

Main category: cs.AI

TL;DR: Pareto-NRPA是一种新型多目标蒙特卡洛算法，扩展自NRPA，适用于离散搜索空间，在性能上优于现有进化多目标算法。


<details>
  <summary>Details</summary>
Motivation: 为了解决离散搜索空间中的多目标优化问题，扩展单目标NRPA算法以适应多目标场景。

Method: Pareto-NRPA通过一组策略并行探索解空间的不同区域，并在搜索的每个层级维护非支配前沿，策略更新基于Pareto前沿内序列的多样性和隔离性。

Result: 在MO-TSPTW和神经网络架构搜索任务上，Pareto-NRPA在收敛性和解多样性方面均表现出与最先进多目标算法竞争的性能。

Conclusion: Pareto-NRPA是NRPA算法的多目标优化扩展，首次将NRPA应用于多目标设置，并在受限搜索空间上显著优于现有的进化多目标算法。

Abstract: We introduce Pareto-NRPA, a new Monte-Carlo algorithm designed for
multi-objective optimization problems over discrete search spaces. Extending
the Nested Rollout Policy Adaptation (NRPA) algorithm originally formulated for
single-objective problems, Pareto-NRPA generalizes the nested search and policy
update mechanism to multi-objective optimization. The algorithm uses a set of
policies to concurrently explore different regions of the solution space and
maintains non-dominated fronts at each level of search. Policy adaptation is
performed with respect to the diversity and isolation of sequences within the
Pareto front. We benchmark Pareto-NRPA on two classes of problems: a novel
bi-objective variant of the Traveling Salesman Problem with Time Windows
problem (MO-TSPTW), and a neural architecture search task on well-known
benchmarks. Results demonstrate that Pareto-NRPA achieves competitive
performance against state-of-the-art multi-objective algorithms, both in terms
of convergence and diversity of solutions. Particularly, Pareto-NRPA strongly
outperforms state-of-the-art evolutionary multi-objective algorithms on
constrained search spaces. To our knowledge, this work constitutes the first
adaptation of NRPA to the multi-objective setting.

</details>


### [98] [OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?](https://arxiv.org/abs/2507.19132)
*Xuetian Chen,Yinghao Chen,Xinfeng Yuan,Zhuo Peng,Lu Chen,Yuekeng Li,Zhoujia Zhang,Yingqian Huang,Leyan Huang,Jiaqing Liang,Tianbao Xie,Zhiyong Wu,Qiushi Sun,Biqing Qi,Bowen Zhou*

Main category: cs.AI

TL;DR: OS-MAP 是一个用于日常计算机自动化任务的基准，通过五级分类和需求层次评估代理能力，揭示了当前代理在高级任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能充分考虑任务异质性与实际用户需求的匹配，阻碍了针对性能力开发和研究成果的实际部署。

Method: 提出了 OS-MAP 基准，通过五级自动化分类和需求层次结构评估代理能力，形成性能-泛化评估矩阵。

Result: 实验表明，即使是最先进的代理在涉及感知、推理和协调的高级任务中仍表现不佳。

Conclusion: OS-MAP 提供了一个结构化且全面的评估框架，揭示了当前最先进代理在高级任务中的局限性，强调了未来研究的重点方向。

Abstract: Computer-using agents have shown strong potential to boost human productivity
and enable new application forms across platforms. While recent advances have
led to usable applications, existing benchmarks fail to account for the
internal task heterogeneity and the corresponding agent capabilities, as well
as their alignment with actual user demands-hindering both targeted capability
development and the reliable transition of research progress into practical
deployment. To bridge the gap, we present OS-MAP, a benchmark for daily
computer-using automation that organizes its 416 realistic tasks across 15
applications along two key dimensions: a five-level taxonomy of automation and
a generalization scope derived from a real-world user demand hierarchy. To
enable fine-grained analysis of required capabilities and alignment with
real-world scenarios, OS-MAP evaluates agents along two dimensions: automation
level across a five-level taxonomy, and generalization scope across a demand
hierarchy. This design captures varying levels of required agent autonomy and
generalization, forming a performance-generalization evaluation matrix for
structured and comprehensive assessment. Experiments show that even
State-of-the-Art agents with VLM backbones struggle with higher-level tasks
involving perception, reasoning, and coordination-highlighting the need for a
deeper understanding of current strengths and limitations to drive the future
progress in computer-using agents research and deployment. All code,
environments, baselines, and data are publicly available at
https://github.com/OS-Copilot/OS-Map.

</details>


### [99] [PhysDrive: A Multimodal Remote Physiological Measurement Dataset for In-vehicle Driver Monitoring](https://arxiv.org/abs/2507.19172)
*Jiyao Wang,Xiao Yang,Qingyong Hu,Jiankai Tang,Can Liu,Dengbo He,Yuntao Wang,Yingcong Chen,Kaishun Wu*

Main category: cs.AI

TL;DR: PhysDrive是首个大规模多模态车内生理传感数据集，覆盖多样驾驶条件，为驾驶员监测研究提供基准和开源资源。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在规模、模态多样性、生物特征标注广度和捕获条件范围上存在局限，无法反映真实驾驶环境中的挑战。因此，需要构建一个全面且多样化的数据集来推动远程生理测量的实际应用。

Method: 通过收集48名驾驶员的数据，包括同步的RGB、近红外摄像头和原始毫米波雷达数据，以及六种同步的地面真实值（ECG、BVP、呼吸、心率、呼吸率和血氧饱和度），覆盖了广泛的自然驾驶条件。

Result: PhysDrive数据集在信号处理和深度学习方法上进行了广泛评估，建立了全面的基准，并发布了与主流公共工具箱兼容的开源代码。

Conclusion: PhysDrive数据集作为首个大规模多模态车内生理传感数据集，为多模态驾驶员监测和智能座舱系统的研究提供了基础资源，并有望加速相关领域的发展。

Abstract: Robust and unobtrusive in-vehicle physiological monitoring is crucial for
ensuring driving safety and user experience. While remote physiological
measurement (RPM) offers a promising non-invasive solution, its translation to
real-world driving scenarios is critically constrained by the scarcity of
comprehensive datasets. Existing resources are often limited in scale, modality
diversity, the breadth of biometric annotations, and the range of captured
conditions, thereby omitting inherent real-world challenges in driving. Here,
we present PhysDrive, the first large-scale multimodal dataset for contactless
in-vehicle physiological sensing with dedicated consideration on various
modality settings and driving factors. PhysDrive collects data from 48 drivers,
including synchronized RGB, near-infrared camera, and raw mmWave radar data,
accompanied with six synchronized ground truths (ECG, BVP, Respiration, HR, RR,
and SpO2). It covers a wide spectrum of naturalistic driving conditions,
including driver motions, dynamic natural light, vehicle types, and road
conditions. We extensively evaluate both signal-processing and deep-learning
methods on PhysDrive, establishing a comprehensive benchmark across all
modalities, and release full open-source code with compatibility for mainstream
public toolboxes. We envision PhysDrive will serve as a foundational resource
and accelerate research on multimodal driver monitoring and smart-cockpit
systems.

</details>


### [100] [Faster Lifting for Ordered Domains with Predecessor Relations](https://arxiv.org/abs/2507.19182)
*Kuncheng Zou,Jiahao Mai,Yonggang Zhang,Yuyi Wang,Ondřej Kuželka,Yuanhong Wang,Yi Chang*

Main category: cs.AI

TL;DR: 本文提出了一种高效处理有序域上前驱关系的新算法，显著提升了加权一阶模型计数的效率，尤其在处理k阶前驱关系时表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的WFOMC方法在处理有序域上前驱关系时效率低下，尤其是在涉及前驱关系时表现不佳。

Method: 通过将前驱关系直接编码为公理的一部分，设计了一种新算法，避免了传统加权一阶模型计数（WFOMC）方法的局限性。

Result: 新算法在处理直接和第二前驱关系时实现了指数级加速，并能处理一般的k阶前驱关系。实验表明，该算法在提升推理任务和组合数学问题上的效率显著。

Conclusion: 本文提出了一种新颖的算法，将前驱关系作为公理的原生部分，显著提升了处理有序域上前驱关系的效率，尤其在处理k阶前驱关系时表现出色。

Abstract: We investigate lifted inference on ordered domains with predecessor
relations, where the elements of the domain respect a total (cyclic) order, and
every element has a distinct (clockwise) predecessor. Previous work has
explored this problem through weighted first-order model counting (WFOMC),
which computes the weighted sum of models for a given first-order logic
sentence over a finite domain. In WFOMC, the order constraint is typically
encoded by the linear order axiom introducing a binary predicate in the
sentence to impose a linear ordering on the domain elements. The immediate and
second predecessor relations are then encoded by the linear order predicate.
Although WFOMC with the linear order axiom is theoretically tractable, existing
algorithms struggle with practical applications, particularly when the
predecessor relations are involved. In this paper, we treat predecessor
relations as a native part of the axiom and devise a novel algorithm that
inherently supports these relations. The proposed algorithm not only provides
an exponential speedup for the immediate and second predecessor relations,
which are known to be tractable, but also handles the general k-th predecessor
relations. The extensive experiments on lifted inference tasks and
combinatorics math problems demonstrate the efficiency of our algorithm,
achieving speedups of a full order of magnitude.

</details>


### [101] [Knowledge Grafting: A Mechanism for Optimizing AI Model Deployment in Resource-Constrained Environments](https://arxiv.org/abs/2507.19261)
*Osama Almurshed,Ashish Kaushal,Asmail Muftah,Nitin Auluck,Omer Rana*

Main category: cs.AI

TL;DR: 知识嫁接技术通过移植大型模型特征到小型模型，显著减小体积并提升性能，适用于资源受限设备。


<details>
  <summary>Details</summary>
Motivation: 解决AI模型在资源受限环境中因模型体积大、计算需求高而难以部署的问题。

Method: 提出了一种名为‘知识嫁接’的新机制，通过将大型模型中的部分特征（scion）移植到小型模型（rootstock）中，优化模型在资源受限环境下的表现。

Result: 知识嫁接技术将模型体积减少了88.54%，同时提升了验证准确率（89.97% vs 87.47%）和测试准确率（90.45%），验证损失也显著降低（0.2976 vs 0.5068）。

Conclusion: 知识嫁接技术通过将大型模型的特征选择性移植到小型模型中，显著减小了模型体积（从64.39 MB降至7.38 MB），同时提升了模型性能（验证准确率从87.47%提升至89.97%），并展示了在资源受限设备上的高效部署潜力。

Abstract: The increasing adoption of Artificial Intelligence (AI) has led to larger,
more complex models with numerous parameters that require substantial computing
power -- resources often unavailable in many real-world application scenarios.
Our paper addresses this challenge by introducing knowledge grafting, a novel
mechanism that optimizes AI models for resource-constrained environments by
transferring selected features (the scion) from a large donor model to a
smaller rootstock model. The approach achieves an 88.54% reduction in model
size (from 64.39 MB to 7.38 MB), while improving generalization capability of
the model. Our new rootstock model achieves 89.97% validation accuracy (vs.
donor's 87.47%), maintains lower validation loss (0.2976 vs. 0.5068), and
performs exceptionally well on unseen test data with 90.45% accuracy. It
addresses the typical size vs performance trade-off, and enables deployment of
AI frameworks on resource-constrained devices with enhanced performance. We
have tested our approach on an agricultural weed detection scenario, however,
it can be extended across various edge computing scenarios, potentially
accelerating AI adoption in areas with limited hardware/software support -- by
mirroring in a similar manner the horticultural grafting enables productive
cultivation in challenging agri-based environments.

</details>


### [102] [Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games](https://arxiv.org/abs/2507.19263)
*Achille Morenville,Éric Piette*

Main category: cs.AI

TL;DR: 本文探讨了在不完全信息博弈中表示信念的两种方法（约束基础和概率扩展），发现两者性能相近，约束基础方法可能已足够。


<details>
  <summary>Details</summary>
Motivation: 在不完全信息博弈中，代理需要基于部分知识做出决策，而Belief Stochastic Game模型通过将状态估计委托给游戏模型本身来解决这一挑战，从而减少对特定游戏推理逻辑的需求。

Method: 本文研究了两种表示信念的方法：基于约束的模型（使用约束满足问题）和概率扩展（使用信念传播来估计边际概率）。

Result: 评估结果表明，基于约束的信念与概率推理的结果相当，代理性能差异微小。

Conclusion: 约束基础的信念状态在许多情况下可能足以支持有效的决策。

Abstract: In imperfect-information games, agents must make decisions based on partial
knowledge of the game state. The Belief Stochastic Game model addresses this
challenge by delegating state estimation to the game model itself. This allows
agents to operate on externally provided belief states, thereby reducing the
need for game-specific inference logic. This paper investigates two approaches
to represent beliefs in games with hidden piece identities: a constraint-based
model using Constraint Satisfaction Problems and a probabilistic extension
using Belief Propagation to estimate marginal probabilities. We evaluated the
impact of both representations using general-purpose agents across two
different games. Our findings indicate that constraint-based beliefs yield
results comparable to those of probabilistic inference, with minimal
differences in agent performance. This suggests that constraint-based belief
states alone may suffice for effective decision-making in many settings.

</details>


### [103] [Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges](https://arxiv.org/abs/2507.19364)
*Patrick Taillandier,Jean Daniel Zucker,Arnaud Grignard,Benoit Gaudou,Nghi Quang Huynh,Alexis Drogoul*

Main category: cs.AI

TL;DR: 本文分析了大语言模型（LLMs）在社交模拟中的潜力与局限，主张将其与传统基于代理的建模平台结合，以平衡灵活性与严谨性。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLMs）在社交模拟中的潜力与局限性，从计算社会科学的角度分析其应用前景。

Method: 第一部分回顾了LLMs在复制人类认知关键方面的能力，如心智理论推理和社会推断，同时指出了其认知偏见、缺乏真正理解和行为不一致等显著局限性。第二部分调查了LLMs在多代理模拟框架中的新兴应用，重点关注系统架构、规模和验证策略。

Result: LLMs在交互式模拟和严肃游戏中具有直接价值，但在解释性或预测性建模中的应用则存在较多问题。

Conclusion: 本文主张采用混合方法，将大语言模型（LLMs）整合到传统基于代理的建模平台（如GAMA、Netlogo等）中，以结合语言推理的表达灵活性和经典基于规则系统的透明性与分析严谨性。

Abstract: This position paper examines the use of Large Language Models (LLMs) in
social simulation, analyzing both their potential and their limitations from a
computational social science perspective. The first part reviews recent
findings on the ability of LLMs to replicate key aspects of human cognition,
including Theory of Mind reasoning and social inference, while also
highlighting significant limitations such as cognitive biases, lack of true
understanding, and inconsistencies in behavior. The second part surveys
emerging applications of LLMs in multi-agent simulation frameworks, focusing on
system architectures, scale, and validation strategies. Notable projects such
as Generative Agents (Smallville) and AgentSociety are discussed in terms of
their design choices, empirical grounding, and methodological innovations.
Particular attention is given to the challenges of behavioral fidelity,
calibration, and reproducibility in large-scale LLM-driven simulations. The
final section distinguishes between contexts where LLMs, like other black-box
systems, offer direct value-such as interactive simulations and serious
games-and those where their use is more problematic, notably in explanatory or
predictive modeling. The paper concludes by advocating for hybrid approaches
that integrate LLMs into traditional agent-based modeling platforms (GAMA,
Netlogo, etc), enabling modelers to combine the expressive flexibility of
language-based reasoning with the transparency and analytical rigor of
classical rule-based systems.

</details>


### [104] [Learning neuro-symbolic convergent term rewriting systems](https://arxiv.org/abs/2507.19372)
*Flavio Petruzzellis,Alberto Testolin,Alessandro Sperduti*

Main category: cs.AI

TL;DR: 论文提出了一种神经符号架构（NRS和FastNRS），用于学习符号算法，显著优于现有基线模型，并在多领域任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决符号算法学习中的泛化和跨分布性能问题，尤其是在执行复杂数学公式简化等任务时，现有神经网络模型的局限性。

Method: 论文提出了一种基于神经符号架构的通用框架，用于学习收敛的项重写系统。具体实现了两个模块化架构：Neural Rewriting System (NRS) 和 Fast Neural Rewriting System (FastNRS)，后者在内存效率、训练速度和推理时间上有显著提升。

Result: 提出的系统在四个数学公式简化任务中表现优异，显著优于Neural Data Router和GPT-4o等基线模型，且在多领域学习场景中展现了强大的性能。

Conclusion: 论文提出的神经符号架构（NRS和FastNRS）在符号算法学习任务中表现出色，尤其在泛化和跨分布性能上优于现有基线模型（如Neural Data Router和GPT-4o），并在多领域学习场景中展现了强大的适应性。

Abstract: Building neural systems that can learn to execute symbolic algorithms is a
challenging open problem in artificial intelligence, especially when aiming for
strong generalization and out-of-distribution performance. In this work, we
introduce a general framework for learning convergent term rewriting systems
using a neuro-symbolic architecture inspired by the rewriting algorithm itself.
We present two modular implementations of such architecture: the Neural
Rewriting System (NRS) and the Fast Neural Rewriting System (FastNRS). As a
result of algorithmic-inspired design and key architectural elements, both
models can generalize to out-of-distribution instances, with FastNRS offering
significant improvements in terms of memory efficiency, training speed, and
inference time. We evaluate both architectures on four tasks involving the
simplification of mathematical formulas and further demonstrate their
versatility in a multi-domain learning scenario, where a single model is
trained to solve multiple types of problems simultaneously. The proposed system
significantly outperforms two strong neural baselines: the Neural Data Router,
a recent transformer variant specifically designed to solve algorithmic
problems, and GPT-4o, one of the most powerful general-purpose large-language
models. Moreover, our system matches or outperforms the latest o1-preview model
from OpenAI that excels in reasoning benchmarks.

</details>


### [105] [Hierarchical Deep Reinforcement Learning Framework for Multi-Year Asset Management Under Budget Constraints](https://arxiv.org/abs/2507.19458)
*Amir Fard,Arnold X. -X. Yuan*

Main category: cs.AI

TL;DR: 论文提出了一种分层深度强化学习方法，用于解决基础设施预算规划和维护优化的复杂性问题，通过分解为高低两层规划者，实现了高效、可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 基础设施的预算规划和维护优化面临组合动作空间、资产退化多样性、严格预算约束和环境不确定性等复杂性，限制了现有方法的可扩展性。

Method: 论文采用分层深度强化学习方法，结合线性规划投影和分层Soft Actor-Critic框架，将问题分解为高层预算规划和低层维护规划两个层次。

Result: 案例研究表明，该方法在10、15和20个污水管网规模下均能快速收敛、有效扩展，并提供接近最优的解决方案，优于传统的深度Q学习和增强遗传算法。

Conclusion: 论文提出了一种针对多年基础设施规划的分层深度强化学习方法，通过将问题分解为高层预算规划者和低层维护规划者两个层次，有效解决了组合动作空间、资产退化多样性和严格预算约束等复杂性问题。该方法在收敛速度、可扩展性和解决方案质量方面优于传统方法。

Abstract: Budget planning and maintenance optimization are crucial for infrastructure
asset management, ensuring cost-effectiveness and sustainability. However, the
complexity arising from combinatorial action spaces, diverse asset
deterioration, stringent budget constraints, and environmental uncertainty
significantly limits existing methods' scalability. This paper proposes a
Hierarchical Deep Reinforcement Learning methodology specifically tailored to
multi-year infrastructure planning. Our approach decomposes the problem into
two hierarchical levels: a high-level Budget Planner allocating annual budgets
within explicit feasibility bounds, and a low-level Maintenance Planner
prioritizing assets within the allocated budget. By structurally separating
macro-budget decisions from asset-level prioritization and integrating linear
programming projection within a hierarchical Soft Actor-Critic framework, the
method efficiently addresses exponential growth in the action space and ensures
rigorous budget compliance. A case study evaluating sewer networks of varying
sizes (10, 15, and 20 sewersheds) illustrates the effectiveness of the proposed
approach. Compared to conventional Deep Q-Learning and enhanced genetic
algorithms, our methodology converges more rapidly, scales effectively, and
consistently delivers near-optimal solutions even as network size grows.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [106] [Third-Party Assessment of Mobile Performance in the 5G Era](https://arxiv.org/abs/2507.18834)
*ASM Rizvi,John Heidemann,David Plonka*

Main category: cs.NI

TL;DR: 通过全球CDN数据分析移动网络体验，发现延迟和吞吐量存在显著差异，少数用户能享受高性能，多数用户体验受限。


<details>
  <summary>Details</summary>
Motivation: 在5G时代，用户对高性能数据网络的需求日益增长，但移动体验的实际表现缺乏全面评估。

Method: 通过商业、全球分布的CDN数据，分析移动客户端的延迟、吞吐量和稳定性。

Result: 移动用户有时能体验到极低延迟（如6毫秒），但仅5%的用户能持续体验低于20毫秒的延迟。60%的用户吞吐量低于50 Mb/s，最小延迟在特定位置相对稳定。

Conclusion: 移动网络体验在5G时代至关重要，但用户实际体验存在显著差异，高延迟和低吞吐量问题普遍存在。

Abstract: The web experience using mobile devices is important since a significant
portion of the Internet traffic is initiated from mobile devices. In the era of
5G, users expect a high-performance data network to stream media content and
for other latency-sensitive applications. In this paper, we characterize mobile
experience in terms of latency, throughput, and stability measured from a
commercial, globally-distributed CDN. Unlike prior work, CDN data provides a
relatively neutral, carrier-agnostic perspective, providing a clear view of
multiple and international providers. Our analysis of mobile client traffic
shows mobile users sometimes experience markedly low latency, even as low as 6
ms. However, only the top 5% users regularly experience less than 20 ms of
minimum latency. While 100 Mb/s throughput is not rare, we show around 60%
users observe less than 50 Mb/s throughput. We find the minimum mobile latency
is generally stable at a specific location which can be an important
characteristic for anomaly detection.

</details>


### [107] [Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks](https://arxiv.org/abs/2507.19050)
*Qiong Wu,Yu Xie,Pingyi Fan,Dong Qin,Kezhi Wang,Nan Cheng,Khaled B. Letaief*

Main category: cs.NI

TL;DR: 论文提出了一种基于LLM的数字孪生边缘计算网络任务卸载策略，性能优于传统MARL方法。


<details>
  <summary>Details</summary>
Motivation: 解决多车辆生成的计算任务在卸载到服务器时的排队挑战，研究任务卸载策略、队列稳定性和资源分配。

Method: 采用Lyapunov优化将长期约束转化为短期决策，并基于大语言模型（LLM）的上下文学习方法替代传统MARL框架。

Result: 实验结果表明，基于LLM的方法在性能上与MARL相当或更优。

Conclusion: 该论文提出的基于大语言模型（LLM）的任务卸载策略在性能上与传统多智能体强化学习（MARL）框架相当甚至更优。

Abstract: In this paper, we propose a general digital twin edge computing network
comprising multiple vehicles and a server. Each vehicle generates multiple
computing tasks within a time slot, leading to queuing challenges when
offloading tasks to the server. The study investigates task offloading
strategies, queue stability, and resource allocation. Lyapunov optimization is
employed to transform long-term constraints into tractable short-term
decisions. To solve the resulting problem, an in-context learning approach
based on large language model (LLM) is adopted, replacing the conventional
multi-agent reinforcement learning (MARL) framework. Experimental results
demonstrate that the LLM-based method achieves comparable or even superior
performance to MARL.

</details>


### [108] [iPLAN: Redefining Indoor Wireless Network Planning Through Large Language Models](https://arxiv.org/abs/2507.19096)
*Jinbo Hou,Stefanos Bakirtzis,Kehai Qiu,Sichong Liao,Hui Song,Haonan Hu,Kezhi Wang,Jie Zhang*

Main category: cs.NI

TL;DR: iPLAN框架利用大型语言模型（LLM）优化室内无线网络规划，通过多模态室内环境表示和智能代理协作，显著提升5G室内服务质量和无线网络性能。


<details>
  <summary>Details</summary>
Motivation: 传统元启发式和人工智能规划方法难以应对室内环境（IE）与无线网络需求之间的复杂交互，亟需更高效的解决方案。

Method: 提出iPLAN框架，将多模态IE表示集成到LLM驱动的优化器中，支持基于现有IE的规划和新建筑联合设计，采用多代理策略分步处理子任务。

Result: 仿真结果表明，iPLAN在无线网络规划任务中表现优异，并通过IE与IWN的联合设计优化建筑无线性能。

Conclusion: iPLAN代表了室内无线网络规划范式的转变，展示了LLM在复杂规划问题中的潜力。

Abstract: Efficient indoor wireless network (IWN) planning is crucial for providing
high-quality 5G in-building services. However, traditional meta-heuristic and
artificial intelligence-based planning methods face significant challenges due
to the intricate interplay between indoor environments (IEs) and IWN demands.
In this article, we present an indoor wireless network Planning with large
LANguage models (iPLAN) framework, which integrates multi-modal IE
representations into large language model (LLM)-powered optimizers to improve
IWN planning. First, we instate the role of LLMs as optimizers, outlining
embedding techniques for IEs, and introducing two core applications of iPLAN:
(i) IWN planning based on pre-existing IEs and (ii) joint design of IWN and IE
for new wireless-friendly buildings. For the former, we embed essential
information into LLM optimizers by leveraging indoor descriptions,
domain-specific knowledge, and performance-driven perception. For the latter,
we conceptualize a multi-agent strategy, where intelligent agents
collaboratively address key planning sub-tasks in a step-by-step manner while
ensuring optimal trade-offs between the agents. The simulation results
demonstrate that iPLAN achieves superior performance in IWN planning tasks and
optimizes building wireless performance through the joint design of IEs and
IWNs, exemplifying a paradigm shift in IWN planning.

</details>


### [109] [AI Enabled 6G for Semantic Metaverse: Prospects, Challenges and Solutions for Future Wireless VR](https://arxiv.org/abs/2507.19124)
*Muhammad Ahmed Mohsin,Sagnik Bhattacharya,Abhiram Gorle,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.NI

TL;DR: 该论文提出了一种结合非线性收发器和DRL优化的方法，显著提升多用户VR应用的无线传输效率和功率节省，实验数据优于现有标准。


<details>
  <summary>Details</summary>
Motivation: 解决多用户VR应用（如3D游戏、数字AI化身和远程协作）中由于低秩信道导致的无线支持挑战。

Method: 采用最优非线性收发器（上行链路使用广义决策反馈或连续消除，下行链路使用叠加或脏纸预编码）以及用户能量分配和解码顺序的优化方法，并结合深度强化学习（DRL）降低实时计算复杂度。

Result: 实验结果显示，提出的算法在给定功率水平下，比OMA、NOMA和MC-NOMA分别提升了39%、28%和16%的总数据速率；在相同数据速率下，分别节省了75%、45%和40%的功率。DRL框架实现了5倍的速度提升，达到全局最优的83%。

Conclusion: 该论文提出的非线性收发器和优化方法显著提升了多用户VR应用中的数据传输效率和功率节省，特别是在低秩信道条件下。

Abstract: Wireless support of virtual reality (VR) has challenges when a network has
multiple users, particularly for 3D VR gaming, digital AI avatars, and remote
team collaboration. This work addresses these challenges through investigation
of the low-rank channels that inevitably occur when there are more active users
than there are degrees of spatial freedom, effectively often the number of
antennas. The presented approach uses optimal nonlinear transceivers,
equivalently generalized decision-feedback or successive cancellation for
uplink and superposition or dirty-paper precoders for downlink. Additionally, a
powerful optimization approach for the users' energy allocation and decoding
order appears to provide large improvements over existing methods, effectively
nearing theoretical optima. As the latter optimization methods pose real-time
challenges, approximations using deep reinforcement learning (DRL) are used to
approximate best performance with much lower (5x at least) complexity.
Experimental results show significantly larger sum rates and very large power
savings to attain the data rates found necessary to support VR. Experimental
results show the proposed algorithm outperforms current industry standards like
orthogonal multiple access (OMA), non-orthogonal multiple access (NOMA), as
well as the highly researched methods in multi-carrier NOMA (MC-NOMA),
enhancing sum data rate by 39%, 28%, and 16%, respectively, at a given power
level. For the same data rate, it achieves power savings of 75%, 45%, and 40%,
making it ideal for VR applications. Additionally, a near-optimal deep
reinforcement learning (DRL)-based resource allocation framework for real-time
use by being 5x faster and reaching 83% of the global optimum is introduced.

</details>


### [110] [Virne: A Comprehensive Benchmark for Deep RL-based Network Resource Allocation in NFV](https://arxiv.org/abs/2507.19234)
*Tianfu Wang,Liwei Deng,Xi Chen,Junyang Wang,Huiguo He,Leilei Ding,Wei Wu,Qilin Fan,Hui Xiong*

Main category: cs.NI

TL;DR: Virne是一个全面的NFV-RA基准测试框架，支持深度强化学习方法，提供多样化模拟和丰富实现，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏系统化的基准测试框架和深入分析，导致网络功能虚拟化（NFV）中的资源分配（RA）问题研究受限，评估不一致。

Method: Virne框架提供了可定制的模拟环境，支持云、边缘和5G网络场景，并采用模块化和可扩展的实现流程。

Result: Virne通过广泛的实验提供了性能权衡的深入分析，为高效实现和未来研究提供了实用指导。

Conclusion: Virne作为一个全面的基准测试框架，支持多样化的网络场景和超过30种方法，为NFV-RA问题和深度强化学习应用提供了宝贵的见解和未来研究方向。

Abstract: Resource allocation (RA) is critical to efficient service deployment in
Network Function Virtualization (NFV), a transformative networking paradigm.
Recently, deep Reinforcement Learning (RL)-based methods have been showing
promising potential to address this complexity. However, the lack of a
systematic benchmarking framework and thorough analysis hinders the exploration
of emerging networks and the development of more robust algorithms while
causing inconsistent evaluation. In this paper, we introduce Virne, a
comprehensive benchmarking framework for the NFV-RA problem, with a focus on
supporting deep RL-based methods. Virne provides customizable simulations for
diverse network scenarios, including cloud, edge, and 5G environments. It also
features a modular and extensible implementation pipeline that supports over 30
methods of various types, and includes practical evaluation perspectives beyond
effectiveness, such as scalability, generalization, and scalability.
Furthermore, we conduct in-depth analysis through extensive experiments to
provide valuable insights into performance trade-offs for efficient
implementation and offer actionable guidance for future research directions.
Overall, with its diverse simulations, rich implementations, and extensive
evaluation capabilities, Virne could serve as a comprehensive benchmark for
advancing NFV-RA methods and deep RL applications. The code is publicly
available at https://github.com/GeminiLight/virne.

</details>


### [111] [Deep Reinforcement Learning-Based Scheduling for Wi-Fi Multi-Access Point Coordination](https://arxiv.org/abs/2507.19377)
*David Nunez,Francesc Wilhelmi,Maksymilian Wojnar,Katarzyna Kosek-Szott,Szymon Szott,Boris Bellalta*

Main category: cs.NI

TL;DR: 论文提出一种基于DRL的MAPC调度方法，显著降低密集Wi-Fi网络的最坏延迟，性能优于基线30%。


<details>
  <summary>Details</summary>
Motivation: 在重叠基本服务集（OBSS）中，高效调度策略在多样化的流量和干扰条件下难以实现，亟需一种能最小化网络范围内最坏情况延迟的解决方案。

Method: 通过将MAPC调度建模为顺序决策问题，并采用近端策略优化（PPO）训练的DRL代理，在802.11bn兼容的Gymnasium环境中优化调度决策。

Result: 仿真结果表明，该方法在多种网络负载和流量模式下均优于现有启发式策略，99%延迟降低高达30%。

Conclusion: 该论文提出的基于深度强化学习（DRL）的多接入点协调（MAPC）调度方法在密集Wi-Fi部署中显著降低了最坏情况下的延迟，性能优于现有启发式策略。

Abstract: Multi-access point coordination (MAPC) is a key feature of IEEE 802.11bn,
with a potential impact on future Wi-Fi networks. MAPC enables joint scheduling
decisions across multiple access points (APs) to improve throughput, latency,
and reliability in dense Wi-Fi deployments. However, implementing efficient
scheduling policies under diverse traffic and interference conditions in
overlapping basic service sets (OBSSs) remains a complex task. This paper
presents a method to minimize the network-wide worst-case latency by
formulating MAPC scheduling as a sequential decision-making problem and
proposing a deep reinforcement learning (DRL) mechanism to minimize worst-case
delays in OBSS deployments. Specifically, we train a DRL agent using proximal
policy optimization (PPO) within an 802.11bn-compatible Gymnasium environment.
This environment provides observations of queue states, delay metrics, and
channel conditions, enabling the agent to schedule multiple AP-station pairs to
transmit simultaneously by leveraging spatial reuse (SR) groups. Simulations
demonstrate that our proposed solution outperforms state-of-the-art heuristic
strategies across a wide range of network loads and traffic patterns. The
trained machine learning (ML) models consistently achieve lower 99th-percentile
delays, showing up to a 30% improvement over the best baseline.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [112] [Generating real-time detailed ground visualisations from sparse aerial point clouds](https://arxiv.org/abs/2507.18664)
*Aidan Murray,Eddie Waite,Caleb Ross,Scarlet Mitchell,Alexander Bradley,Joanna Jamrozy,Kenny Mitchell*

Main category: cs.GR

TL;DR: 论文提出一种自动化方法，通过放大真实扫描数据并实时渲染3D动画，解决传统高成本低精度问题，适用于多种应用场景。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量艺术家团队进行建模、纹理、材质着色和照明，成本高昂且难以准确反映真实世界景观的多样性。

Method: 定义了一个自动化流程，用于放大真实世界扫描数据并实时渲染3D动画。

Result: 提出的方法能够自动放大扫描数据，实现高质量的实时3D渲染，适用于训练、模拟、视频游戏和可视化应用。

Conclusion: 该论文提出了一个自动化流程，通过放大真实世界扫描数据并实时渲染高质量的3D动画，解决了传统方法成本高且准确性不足的问题。

Abstract: Building realistic wide scale outdoor 3D content with sufficient visual
quality to observe at walking eye level or from driven vehicles is often
carried out by large teams of artists skilled in modelling, texturing, material
shading and lighting, which typically leads to both prohibitive costs and
reduced accuracy honoring the variety of real world ground truth landscapes. In
our proposed method, we define a process to automatically amplify real-world
scanned data and render real-time in animated 3D to explore at close range with
high quality for training, simulation, video game and visualisation
applications.

</details>


### [113] [Procedural city modeling](https://arxiv.org/abs/2507.18899)
*Thomas Lechner,Ben Watson,Uri Wilensky,Martin Felsen*

Main category: cs.GR

TL;DR: 提出一种基于代理的城市生成方法，通过简单规则模拟复杂城市发展，支持艺术参数调整，实现从村庄到都市的逼真过渡。


<details>
  <summary>Details</summary>
Motivation: 旨在生成既熟悉又复杂的人工城市，捕捉城市发展行为，而非复制现有城市，确保在任何发展阶段都显得逼真。

Method: 采用基于代理的模拟方法，通过代理与行为的交互影响模拟环境，专注于土地使用和建筑分布。

Result: 开发了一个自自动化模型，仅需地形描述作为必要输入，支持高低级参数调整，实现了从简单规则集中涌现复杂行为的目标。

Conclusion: 该方法通过简单的代理行为规则集，成功模拟了从村庄到都市的复杂城市发展过程，证明了其自扩展性和艺术贡献支持能力。

Abstract: We propose a method to procedurally generate a familiar yet complex human
artifact: the city. We are not trying to reproduce existing cities, but to
generate artificial cities that are convincing and plausible by capturing
developmental behavior. In addition, our results are meant to build upon
themselves, such that they ought to look compelling at any point along the
transition from village to metropolis. Our approach largely focuses upon land
usage and building distribution for creating realistic city environments,
whereas previous attempts at city modeling have mainly focused on populating
road networks. Finally, we want our model to be self automated to the point
that the only necessary input is a terrain description, but other high-level
and low-level parameters can be specified to support artistic contributions.
With the aid of agent based simulation we are generating a system of agents and
behaviors that interact with one another through their effects upon a simulated
environment. Our philosophy is that as each agent follows a simple behavioral
rule set, a more complex behavior will tend to emerge out of the interactions
between the agents and their differing rule sets. By confining our model to a
set of simple rules for each class of agents, we hope to make our model
extendible not only in regard to the types of structures that are produced, but
also in describing the social and cultural influences prevalent in all cities

</details>


### [114] [TiVy: Time Series Visual Summary for Scalable Visualization](https://arxiv.org/abs/2507.18972)
*Gromit Yeuk-Yin Chan,Luis Gustavo Nonato,Themis Palpanas,Cláudio T. Silva,Juliana Freire*

Main category: cs.GR

TL;DR: TiVy是一种新算法，通过DTW和频繁序列模式提取相似子序列，解决了时间序列可视化的可扩展性问题，速度提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有时间序列可视化方法在可扩展性上存在不足，导致视觉混乱或过多小倍数图表，难以清晰展示长期跨度的数据。

Method: 提出TiVy算法，利用动态时间规整（DTW）将时间序列转换为基于子序列视觉相似性的符号序列，并通过频繁序列模式构建不相交的相似子序列分组。

Result: TiVy算法能清晰准确地提取时间序列模式，相比直接的DTW聚类速度提升1000倍，并能实时渲染大规模时间序列数据。

Conclusion: TiVy算法通过提取时间序列中的相似子序列模式，有效解决了可视化中的可扩展性和视觉清晰度问题，并在实验中展示了高准确性和显著的速度提升。

Abstract: Visualizing multiple time series presents fundamental tradeoffs between
scalability and visual clarity. Time series capture the behavior of many
large-scale real-world processes, from stock market trends to urban activities.
Users often gain insights by visualizing them as line charts, juxtaposing or
superposing multiple time series to compare them and identify trends and
patterns. However, existing representations struggle with scalability: when
covering long time spans, leading to visual clutter from too many small
multiples or overlapping lines. We propose TiVy, a new algorithm that
summarizes time series using sequential patterns. It transforms the series into
a set of symbolic sequences based on subsequence visual similarity using
Dynamic Time Warping (DTW), then constructs a disjoint grouping of similar
subsequences based on the frequent sequential patterns. The grouping result, a
visual summary of time series, provides uncluttered superposition with fewer
small multiples. Unlike common clustering techniques, TiVy extracts similar
subsequences (of varying lengths) aligned in time. We also present an
interactive time series visualization that renders large-scale time series in
real-time. Our experimental evaluation shows that our algorithm (1) extracts
clear and accurate patterns when visualizing time series data, (2) achieves a
significant speed-up (1000X) compared to a straightforward DTW clustering. We
also demonstrate the efficiency of our approach to explore hidden structures in
massive time series data in two usage scenarios.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [115] [CUTHERMO: Understanding GPU Memory Inefficiencies with Heat Map Profiling](https://arxiv.org/abs/2507.18729)
*Yanbo Zhao,Jinku Cui,Zecheng Li,Shuyin Jiao,Xu Liu,Jiajia Li*

Main category: cs.DC

TL;DR: cuThermo是一个无需修改硬件或代码的GPU内存分析工具，通过热图识别内存低效问题，最高提升性能721.79%。


<details>
  <summary>Details</summary>
Motivation: GPU在高性能计算和机器学习等领域至关重要，但缺乏全面的运行时和细粒度内存分析工具，限制了其计算潜力的充分发挥。

Method: cuThermo通过分析GPU二进制文件，在运行时基于不同的访问warp计数生成热图，以表示字-扇区级别的数据共享情况，从而识别内存低效问题并提供优化建议。

Result: 实验表明，cuThermo在六种应用中识别出五种可移植的内存访问模式，并在两种GPU上评估优化后实现了最高721.79%的性能提升。

Conclusion: cuThermo作为一种轻量级、实用的GPU内存分析工具，能够在不修改硬件、操作系统或应用源代码的情况下，通过热图识别内存低效问题，并提供优化指导，最高可带来721.79%的性能提升。

Abstract: GPUs have become indispensable in high-performance computing, machine
learning, and many other domains. Efficiently utilizing the memory subsystem on
GPUs is critical for maximizing computing power through massive parallelism.
Analyzing memory access patterns has proven to be an effective method for
understanding memory bottlenecks in applications. However, comprehensive
runtime and fine-grained memory profiling support is lacking on GPU
architectures. In this work, we introduce cuThermo, a lightweight and practical
profiling tool for GPU memory analysis. It operates on GPU binaries without
requiring any modifications to hardware, operating system, or application
source code. Given a CUDA application, cuThermo identifies memory
inefficiencies at runtime via a heat map based on distinct visited warp counts
to represent word-sector-level data sharing and provides optimization guidance
in performance tuning iterations. Through our experiments on six applications,
we identified five memory access patterns that are portable across different
GPU architectures. By evaluating optimization on two GPUs, cuThermo achieves up
to $721.79\%$ performance improvement.

</details>


### [116] [PPipe: Efficient Video Analytics Serving on Heterogeneous GPU Clusters via Pool-Based Pipeline Parallelism](https://arxiv.org/abs/2507.18748)
*Z. Jonny Kong,Qiang Xu,Y. Charlie Hu*

Main category: cs.DC

TL;DR: PPipe利用异构GPU集群的管道并行技术，显著提高了低端GPU的利用率和整体服务吞吐量。


<details>
  <summary>Details</summary>
Motivation: 随着GPU的快速创新，异构GPU集群在公共云和本地数据中心中越来越普遍。本文探讨如何利用管道并行技术，在异构GPU集群上有效服务延迟敏感的模型推理。

Method: PPipe采用池化管道并行技术，通过基于MILP的控制平面和基于资源预留的自适应批处理数据平面，优化了模型推理服务的性能。

Result: 在18种CNN模型上的评估结果显示，PPipe在保持高端GPU高利用率的同时，将低端GPU的利用率提高了41.1%至65.5%，服务吞吐量比基线提高了32.2%至75.1%。

Conclusion: PPipe通过利用低端和高端GPU的协同效应，实现了更高的资源利用率和吞吐量，为异构GPU集群上的模型推理服务提供了有效解决方案。

Abstract: With the rapid innovation of GPUs, heterogeneous GPU clusters in both public
clouds and on-premise data centers have become increasingly commonplace. In
this paper, we demonstrate how pipeline parallelism, a technique wellstudied
for throughput-oriented deep learning model training, can be used effectively
for serving latency-bound model inference, e.g., in video analytics systems, on
heterogeneous GPU clusters. Our work exploits the synergy between diversity in
model layers and diversity in GPU architectures, which results in comparable
inference latency for many layers when running on low-class and high-class
GPUs. We explore how such overlooked capability of low-class GPUs can be
exploited using pipeline parallelism and present a novel inference serving
system, PPipe, that employs pool-based pipeline parallelism via an MILP-based
control plane and a data plane that performs resource reservation-based
adaptive batching. Evaluation results on diverse workloads (18 CNN models) show
that PPipe achieves 41.1% - 65.5% higher utilization of low-class GPUs while
maintaining high utilization of high-class GPUs, leading to 32.2% - 75.1%
higher serving throughput compared to various baselines.

</details>


### [117] [Deadline-Aware Joint Task Scheduling and Offloading in Mobile Edge Computing Systems](https://arxiv.org/abs/2507.18864)
*Ngoc Hung Nguyen,Van-Dinh Nguyen,Anh Tuan Nguyen,Nguyen Van Thieu,Hoang Nam Nguyen,Symeon Chatzinotas*

Main category: cs.DC

TL;DR: 本文针对移动边缘计算和云系统中的任务调度问题，提出了一种低复杂度且高效的最优调度算法，并通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 由于移动边缘计算和云系统对交互式服务质量要求的提高，需要优化任务调度以减少延迟和未满足截止期限的任务数量。

Method: 研究提出了一种最优任务调度算法，用于确定给定任务集的最优任务顺序，并开发了一种在线方法以应对随机到达任务的不确定性，具备快速中断检测能力。

Result: 性能分析表明，该算法具有线对数时间复杂度O(nlogn)，在线方法的时间复杂度为O(n)，能够有效提高服务比率并降低调度成本。

Conclusion: 本文提出的最优任务调度算法在服务比率和调度成本方面表现出色，同时具备低复杂度和快速响应能力，适用于移动边缘计算和云系统中的实时任务处理。

Abstract: The demand for stringent interactive quality-of-service has intensified in
both mobile edge computing (MEC) and cloud systems, driven by the imperative to
improve user experiences. As a result, the processing of computation-intensive
tasks in these systems necessitates adherence to specific deadlines or
achieving extremely low latency. To optimize task scheduling performance,
existing research has mainly focused on reducing the number of late jobs whose
deadlines are not met. However, the primary challenge with these methods lies
in the total search time and scheduling efficiency. In this paper, we present
the optimal job scheduling algorithm designed to determine the optimal task
order for a given set of tasks. In addition, users are enabled to make informed
decisions for offloading tasks based on the information provided by servers.
The details of performance analysis are provided to show its optimality and low
complexity with the linearithmic time O(nlogn), where $n$ is the number of
tasks. To tackle the uncertainty of the randomly arriving tasks, we further
develop an online approach with fast outage detection that achieves rapid
acceptance times with time complexity of O(n). Extensive numerical results are
provided to demonstrate the effectiveness of the proposed algorithm in terms of
the service ratio and scheduling cost.

</details>


### [118] [GPUnion: Autonomous GPU Sharing on Campus](https://arxiv.org/abs/2507.18928)
*Yufang Li,Yuanbo Zhang,Hanlong Liao,Guoming Tang,Deke Guo*

Main category: cs.DC

TL;DR: GPUnion是一个校园规模的GPU共享平台，通过容器化技术和提供者优先架构，实现了资源的高效利用和自主管理，显著提升了GPU利用率和任务迁移成功率。


<details>
  <summary>Details</summary>
Motivation: 校园GPU资源存在明显不平衡，一些实验室拥有未充分利用的服务器，而其他实验室缺乏AI研究所需的计算能力。现有平台通常依赖集中式监督和持久分配模型，与学术资源所有权的自愿和自主性质相冲突。

Method: GPUnion采用了三种核心机制：i)基于容器的任务调度和执行，ii)资源提供者优先的架构，iii)具有自动检查点和迁移功能的弹性执行。

Result: 在多个校园场景的案例研究中，GPUnion展示了30%的GPU利用率提升、40%的交互会话增加，以及在提供者离开时94%的工作负载成功迁移。

Conclusion: GPUnion证明了提供者自主性和平台可靠性可以共存，挑战了传统的集中式范式，并在校园网络内民主化了计算资源的访问。

Abstract: A pronounced imbalance in GPU resources exists on campus, where some
laboratories own underutilized servers while others lack the compute needed for
AI research. GPU sharing can alleviate this disparity, while existing platforms
typically rely on centralized oversight and persistent allocation models,
conflicting with the voluntary and autonomous nature of academic resource
ownership. We present GPUnion, a campus-scale GPU sharing platform enabling
voluntary participation while preserving full provider autonomy. GPUnion
incorporates three core mechanisms: i) container-based task dispatching and
execution, ii) resource provider-first architecture, and iii) resilient
execution featuring automatic checkpointing and migration. GPUnion also
supports custom data storage and integrates the non-root execution and image
attestation for isolation and security improvement for containerization. Case
studies across multiple campus scenarios demonstrate 30% more GPU utilization
improvement, 40% increase in interactive sessions, and 94% successful workload
migration during provider departures. GPUnion demonstrates that provider
autonomy and platform reliability can coexist, challenging conventional
centralized paradigms and democratizing access to computational resources
within campus networks.

</details>


### [119] [The Case for Time-Shared Computing Resources](https://arxiv.org/abs/2507.19287)
*Pierre Jacquet,Adrien Luxey-Bitri*

Main category: cs.DC

TL;DR: 论文探讨了ICT行业的环境影响，提出通过改善资源共享减少物理资源使用，并强调在性能折衷下的能效提升。


<details>
  <summary>Details</summary>
Motivation: 信息与通信技术（ICT）的环境影响持续增长，主要由于使用量增加、反弹效应和新兴需求。尽管服务具有虚拟性质，但该行业仍受限于其物质性，无法依赖无限的资源池。因此，未来可能需要在托管设施中对多样化的服务实施更严格的限制。

Method: 论文回顾了当前的技术现状，识别了挑战与机遇，提出了时间共享计算的解释，并概述了关键的研究方向。

Result: 研究表明，租户通常不共享计算资源，即使在通常被视为共享的环境（如云平台）中也是如此。通过提高资源共享，可以在接受性能折衷的情况下减少集群规模并提高能效。

Conclusion: 论文提倡通过改善租户间的资源共享来减少物理资源的使用，提出了一种超越传统硬件层面时间共享的高层次抽象方法，以在‘降低性能’的条件下‘用更少资源完成更多任务’。这种方法有望通过基础设施的共享减少集群规模并提高能效。

Abstract: The environmental impact of Information and Communication Technologies (ICT)
continues to grow, driven notably by increasing usage, rebound effects, and
emerging demands. However, despite the virtual nature of its services, the
sector remains inherently constrained by its materiality and cannot rely on an
infinite pool of resources. As a result, the wide variety of supported services
may need to be managed under stricter limits within hosting facilities in the
future. Contrary to common assumptions, we show that tenants typically do not
share computing resources, even in environments commonly perceived as
mutualized, such as cloud platforms. Time-sharing has been progressively phased
out for reasons of performance, security, predictability, and, perhaps more
importantly, due to the decreasing cost of computing resources. This paper
advocates for managing fewer physical resources by improving resource sharing
between tenants. It represents a paradigm shift, moving beyond traditional
time-sharing at the hardware level to a higher abstraction. This approach
entails "doing with fewer resources" under conditions of "reduced performance".
Nonetheless, enhancing the mutualization of infrastructure can reduce cluster
sizes (through consolidation) and improve energy efficiency, with gains related
to the accepted performance trade-off, a situation potentially more socially
acceptable than eliminating services. We review the current state of the art,
identify challenges and opportunities, propose interpretations of Time-Shared
Computing, and outline key research directions.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [120] [XAI-Guided Analysis of Residual Networks for Interpretable Pneumonia Detection in Paediatric Chest X-rays](https://arxiv.org/abs/2507.18647)
*Rayyan Ridwan*

Main category: eess.IV

TL;DR: 该论文提出了一种可解释的深度学习模型，用于儿童肺炎的自动诊断，结合高性能和临床可解释性，展示了其在医疗AI中的重要性。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球儿童死亡的主要原因之一，迫切需要快速、准确的诊断工具。

Method: 提出了一种基于残差网络（ResNets）的可解释深度学习模型，用于自动诊断儿童肺炎的胸部X光片。通过贝叶斯梯度加权类激活映射（BayesGrad-CAM）增强可解释性，量化视觉解释中的不确定性，并提供模型决策过程的空间位置。

Result: 在大型儿童胸部X光数据集上训练的ResNet-50模型实现了高分类准确率（95.94%）、AUC-ROC（98.91%）和Cohen's Kappa（0.913），并提供了具有临床意义的视觉解释。

Conclusion: 研究表明，高性能和可解释性对于临床AI部署不仅是可实现的，而且是至关重要的。

Abstract: Pneumonia remains one of the leading causes of death among children
worldwide, underscoring a critical need for fast and accurate diagnostic tools.
In this paper, we propose an interpretable deep learning model on Residual
Networks (ResNets) for automatically diagnosing paediatric pneumonia on chest
X-rays. We enhance interpretability through Bayesian Gradient-weighted Class
Activation Mapping (BayesGrad-CAM), which quantifies uncertainty in visual
explanations, and which offers spatial locations accountable for the
decision-making process of the model. Our ResNet-50 model, trained on a large
paediatric chest X-rays dataset, achieves high classification accuracy
(95.94%), AUC-ROC (98.91%), and Cohen's Kappa (0.913), accompanied by
clinically meaningful visual explanations. Our findings demonstrate that high
performance and interpretability are not only achievable but critical for
clinical AI deployment.

</details>


### [121] [Learned Single-Pixel Fluorescence Microscopy](https://arxiv.org/abs/2507.18740)
*Serban C. Tudosie,Valerio Gandolfi,Shivaprasad Varakkoth,Andrea Farina,Cosimo D'Andrea,Simon Arridge*

Main category: eess.IV

TL;DR: 本文提出了一种基于自监督自动编码器的单像素成像方法，显著提升了荧光显微镜中的重建速度、图像质量和多光谱能力。


<details>
  <summary>Details</summary>
Motivation: 在荧光显微镜中，单像素成像需要快速采集和重建，传统方法虽然使用总变差最小化进行重建，但通过学习测量向量和重建过程可以进一步提升压缩、重建质量和速度。

Method: 本文提出了一种自监督训练的自动编码器，用于学习编码器（测量矩阵）和解码器，并将其应用于物理获取的多光谱和强度数据。

Result: 实验结果表明，该方法能够将重建时间减少两个数量级，实现更优的图像质量，并支持多光谱重建。

Conclusion: 通过学习自监督的自动编码器，该方法显著提升了荧光显微镜中单像素成像的性能，包括重建速度、图像质量以及多光谱重建能力，有望推动诊断和生物学研究的进步。

Abstract: Single-pixel imaging has emerged as a key technique in fluorescence
microscopy, where fast acquisition and reconstruction are crucial. In this
context, images are reconstructed from linearly compressed measurements. In
practice, total variation minimisation is still used to reconstruct the image
from noisy measurements of the inner product between orthogonal sampling
pattern vectors and the original image data. However, data can be leveraged to
learn the measurement vectors and the reconstruction process, thereby enhancing
compression, reconstruction quality, and speed. We train an autoencoder through
self-supervision to learn an encoder (or measurement matrix) and a decoder. We
then test it on physically acquired multispectral and intensity data. During
acquisition, the learned encoder becomes part of the physical device. Our
approach can enhance single-pixel imaging in fluorescence microscopy by
reducing reconstruction time by two orders of magnitude, achieving superior
image quality, and enabling multispectral reconstructions. Ultimately, learned
single-pixel fluorescence microscopy could advance diagnosis and biological
research, providing multispectral imaging at a fraction of the cost.

</details>


### [122] [RealDeal: Enhancing Realism and Details in Brain Image Generation via Image-to-Image Diffusion Models](https://arxiv.org/abs/2507.18830)
*Shen Zhu,Yinzhu Jin,Tyler Spears,Ifrah Zawar,P. Thomas Fletcher*

Main category: eess.IV

TL;DR: RealDeal是一种图像到图像的扩散模型，通过添加细节和噪声提升LDM生成的脑部MRI图像的真实感，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成模型在生物医学图像生成中应用广泛，但现有LDM生成的脑部MRI图像因潜在压缩而过于平滑，缺乏真实图像中的细微解剖结构和扫描噪声。因此，本文旨在解决这一问题，提升生成图像的真实感和细节。

Method: 本研究采用图像到图像的扩散模型框架，针对LDM生成图像过于平滑的问题，通过引入锐利边缘、精细纹理和成像噪声等细节，提升图像的真实感。评估指标包括常用的FID和LPIPS，以及新提出的噪声分布、锐度和纹理指标。

Result: 实验结果表明，RealDeal能有效提升LDM生成图像的质量，新引入的指标验证了生成图像在噪声分布、锐度和纹理方面更接近真实图像。

Conclusion: 本文提出了一种图像到图像的扩散模型RealDeal，旨在通过添加锐利边缘、精细纹理、细微解剖特征和成像噪声来增强生成脑部图像的真实感和细节。实验结果表明，该方法在提升LDM生成图像质量方面表现优异，并通过新引入的指标验证了生成图像在噪声分布、锐度和纹理方面的真实性。

Abstract: We propose image-to-image diffusion models that are designed to enhance the
realism and details of generated brain images by introducing sharp edges, fine
textures, subtle anatomical features, and imaging noise. Generative models have
been widely adopted in the biomedical domain, especially in image generation
applications. Latent diffusion models achieve state-of-the-art results in
generating brain MRIs. However, due to latent compression, generated images
from these models are overly smooth, lacking fine anatomical structures and
scan acquisition noise that are typically seen in real images. This work
formulates the realism enhancing and detail adding process as image-to-image
diffusion models, which refines the quality of LDM-generated images. We employ
commonly used metrics like FID and LPIPS for image realism assessment.
Furthermore, we introduce new metrics to demonstrate the realism of images
generated by RealDeal in terms of image noise distribution, sharpness, and
texture.

</details>


### [123] [Dealing with Segmentation Errors in Needle Reconstruction for MRI-Guided Brachytherapy](https://arxiv.org/abs/2507.18895)
*Vangelis Kostoulas,Arthur Guijt,Ellen M. Kerkhof,Bradley R. Pieters,Peter A. N. Bosman,Tanja Alderliesten*

Main category: eess.IV

TL;DR: 提出改进后处理技术，有效管理分割错误，显著提高针重建精度。


<details>
  <summary>Details</summary>
Motivation: 手动标注针在患者图像上耗时且具有挑战性，现有后处理技术对分割错误的鲁棒性不足。

Method: 采用两阶段流程，包括分割阶段和后处理阶段，并提出针对分割错误的现有后处理技术的改进。

Result: 在基于MRI扫描的前列腺癌数据集上，最佳改进后处理技术的针尖和针底点定位中位误差分别为1.07毫米和0.43毫米，轴误差为0.75毫米，测试集上无假阳性和假阴性针。

Conclusion: 提出的后处理技术改进能有效管理分割错误，显著提高了针重建的准确性。

Abstract: Brachytherapy involves bringing a radioactive source near tumor tissue using
implanted needles. Image-guided brachytherapy planning requires amongst others,
the reconstruction of the needles. Manually annotating these needles on patient
images can be a challenging and time-consuming task for medical professionals.
For automatic needle reconstruction, a two-stage pipeline is commonly adopted,
comprising a segmentation stage followed by a post-processing stage. While deep
learning models are effective for segmentation, their results often contain
errors. No currently existing post-processing technique is robust to all
possible segmentation errors. We therefore propose adaptations to existing
post-processing techniques mainly aimed at dealing with segmentation errors and
thereby improving the reconstruction accuracy. Experiments on a prostate cancer
dataset, based on MRI scans annotated by medical professionals, demonstrate
that our proposed adaptations can help to effectively manage segmentation
errors, with the best adapted post-processing technique achieving median
needle-tip and needle-bottom point localization errors of $1.07$ (IQR $\pm
1.04$) mm and $0.43$ (IQR $\pm 0.46$) mm, respectively, and median shaft error
of $0.75$ (IQR $\pm 0.69$) mm with 0 false positive and 0 false negative
needles on a test set of 261 needles.

</details>


### [124] [Dual Path Learning -- learning from noise and context for medical image denoising](https://arxiv.org/abs/2507.19035)
*Jitindra Fartiyal,Pedro Freire,Yasmeen Whayeb,James S. Wolffsohn,Sergei K. Turitsyn,Sergei G. Sokolov*

Main category: eess.IV

TL;DR: DPL模型结合噪声和上下文信息，显著提升医学图像去噪效果，适用于多种模态和噪声类型。


<details>
  <summary>Details</summary>
Motivation: 医学图像中的噪声会降低图像质量，影响临床诊断。现有去噪方法通常仅针对单一模态或噪声类型，缺乏通用性。

Method: 本研究提出了一种双路径学习（DPL）模型架构，通过同时利用噪声特征和图像上下文信息进行去噪，并在多种成像模态和噪声类型下进行评估。

Result: DPL在多种模态和噪声类型下表现优异，PSNR比基线UNet提升了3.35%（高斯噪声）。

Conclusion: DPL模型通过结合噪声和上下文信息，有效提升了医学图像去噪的鲁棒性和泛化能力，显著优于基线UNet模型。

Abstract: Medical imaging plays a critical role in modern healthcare, enabling
clinicians to accurately diagnose diseases and develop effective treatment
plans. However, noise, often introduced by imaging devices, can degrade image
quality, leading to misinterpretation and compromised clinical outcomes.
Existing denoising approaches typically rely either on noise characteristics or
on contextual information from the image. Moreover, they are commonly developed
and evaluated for a single imaging modality and noise type. Motivated by Geng
et.al CNCL, which integrates both noise and context, this study introduces a
Dual-Pathway Learning (DPL) model architecture that effectively denoises
medical images by leveraging both sources of information and fusing them to
generate the final output. DPL is evaluated across multiple imaging modalities
and various types of noise, demonstrating its robustness and generalizability.
DPL improves PSNR by 3.35% compared to the baseline UNet when evaluated on
Gaussian noise and trained across all modalities. The code is available at
10.5281/zenodo.15836053.

</details>


### [125] [Joint Holistic and Lesion Controllable Mammogram Synthesis via Gated Conditional Diffusion Model](https://arxiv.org/abs/2507.19201)
*Xin Li,Kaixiang Yang,Qiang Li,Zhiwei Wang*

Main category: eess.IV

TL;DR: GCDM是一种新型门控条件扩散模型，通过联合合成乳腺X光图像和局部病变，解决现有方法在病变特征强调和数据多样性上的不足，实验证明其有效性和临床潜力。


<details>
  <summary>Details</summary>
Motivation: 当前乳腺X光筛查中，深度学习技术的应用受限于数据不足和病变特征多样性缺乏。现有生成模型在病变特异性特征及其与周围组织关系的强调上表现不足。

Method: GCDM基于潜在去噪扩散框架，通过将噪声潜在图像与表示乳腺、病变及其过渡区域的软掩码嵌入连接，确保在去噪过程中的解剖连贯性。此外，GCDM引入门控条件分支，动态选择和融合病变的最相关放射组学和几何特征，以指导去噪过程。

Result: 实验结果表明，GCDM能够精确控制小病变区域，同时提升合成乳腺X光图像的逼真度和多样性。

Conclusion: GCDM作为一种新型框架，通过门控条件扩散模型联合合成整体乳腺X光图像和局部病变，增强了合成图像的逼真度和多样性，为乳腺X光合成提供了有前景的临床工具。

Abstract: Mammography is the most commonly used imaging modality for breast cancer
screening, driving an increasing demand for deep-learning techniques to support
large-scale analysis. However, the development of accurate and robust methods
is often limited by insufficient data availability and a lack of diversity in
lesion characteristics. While generative models offer a promising solution for
data synthesis, current approaches often fail to adequately emphasize
lesion-specific features and their relationships with surrounding tissues. In
this paper, we propose Gated Conditional Diffusion Model (GCDM), a novel
framework designed to jointly synthesize holistic mammogram images and
localized lesions. GCDM is built upon a latent denoising diffusion framework,
where the noised latent image is concatenated with a soft mask embedding that
represents breast, lesion, and their transitional regions, ensuring anatomical
coherence between them during the denoising process. To further emphasize
lesion-specific features, GCDM incorporates a gated conditioning branch that
guides the denoising process by dynamically selecting and fusing the most
relevant radiomic and geometric properties of lesions, effectively capturing
their interplay. Experimental results demonstrate that GCDM achieves precise
control over small lesion areas while enhancing the realism and diversity of
synthesized mammograms. These advancements position GCDM as a promising tool
for clinical applications in mammogram synthesis. Our code is available at
https://github.com/lixinHUST/Gated-Conditional-Diffusion-Model/

</details>


### [126] [A Self-training Framework for Semi-supervised Pulmonary Vessel Segmentation and Its Application in COPD](https://arxiv.org/abs/2507.19074)
*Shuiqing Zhao,Meihuan Wang,Jiaxuan Xu,Jie Feng,Wei Qian,Rongchang Chen,Zhenyu Liang,Shouliang Qi,Yanan Wu*

Main category: eess.IV

TL;DR: 该研究提出了一种半监督学习方法（Semi2），通过教师-学生模型框架提升肺血管分割精确度至90.3%，并分析了COPD患者肺血管的差异。


<details>
  <summary>Details</summary>
Motivation: 准确分割和量化COPD患者的肺血管（尤其是小血管）对疾病分析至关重要。

Method: 研究采用半监督学习方法，通过教师-学生模型框架进行肺血管分割。首先通过交互方式获取高质量标注数据，然后用全监督模型在小规模标注CT图像上训练教师模型。教师模型生成未标注CT图像的伪标签，基于特定策略选择可靠的伪标签用于训练学生模型。该过程迭代进行直至达到最佳性能。

Result: 在125名COPD患者的非增强CT扫描上进行了广泛实验，定量和定性分析表明，所提方法Semi2显著提高了血管分割的精确度2.3%，达到90.3%。此外，定量分析揭示了不同疾病严重程度下肺血管的差异。

Conclusion: 该研究提出的方法不仅能提高肺血管分割的性能，还可应用于COPD分析。代码将在GitHub上公开。

Abstract: Background: It is fundamental for accurate segmentation and quantification of
the pulmonary vessel, particularly smaller vessels, from computed tomography
(CT) images in chronic obstructive pulmonary disease (COPD) patients.
Objective: The aim of this study was to segment the pulmonary vasculature using
a semi-supervised method. Methods: In this study, a self-training framework is
proposed by leveraging a teacher-student model for the segmentation of
pulmonary vessels. First, the high-quality annotations are acquired in the
in-house data by an interactive way. Then, the model is trained in the
semi-supervised way. A fully supervised model is trained on a small set of
labeled CT images, yielding the teacher model. Following this, the teacher
model is used to generate pseudo-labels for the unlabeled CT images, from which
reliable ones are selected based on a certain strategy. The training of the
student model involves these reliable pseudo-labels. This training process is
iteratively repeated until an optimal performance is achieved. Results:
Extensive experiments are performed on non-enhanced CT scans of 125 COPD
patients. Quantitative and qualitative analyses demonstrate that the proposed
method, Semi2, significantly improves the precision of vessel segmentation by
2.3%, achieving a precision of 90.3%. Further, quantitative analysis is
conducted in the pulmonary vessel of COPD, providing insights into the
differences in the pulmonary vessel across different severity of the disease.
Conclusion: The proposed method can not only improve the performance of
pulmonary vascular segmentation, but can also be applied in COPD analysis. The
code will be made available at
https://github.com/wuyanan513/semi-supervised-learning-for-vessel-segmentation.

</details>


### [127] [Learned Image Compression with Hierarchical Progressive Context Modeling](https://arxiv.org/abs/2507.19125)
*Yuqi Li,Haotian Zhang,Li Li,Dong Liu*

Main category: eess.IV

TL;DR: HPCM是一种分层渐进式上下文模型，通过分层编码和渐进式融合机制，更高效地利用长距离依赖和多样化上下文信息，提升了图像压缩性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用长距离依赖和不同编码步骤间的多样化上下文信息方面效率不足。

Method: HPCM采用分层编码计划逐步建模多尺度潜在变量之间的上下文依赖关系，并提出渐进式上下文融合机制，整合先前编码步骤的上下文信息。

Result: 实验结果表明，HPCM实现了最先进的率失真性能。

Conclusion: HPCM方法在率失真性能和计算复杂度之间取得了更好的平衡，实现了最先进的压缩性能。

Abstract: Context modeling is essential in learned image compression for accurately
estimating the distribution of latents. While recent advanced methods have
expanded context modeling capacity, they still struggle to efficiently exploit
long-range dependency and diverse context information across different coding
steps. In this paper, we introduce a novel Hierarchical Progressive Context
Model (HPCM) for more efficient context information acquisition. Specifically,
HPCM employs a hierarchical coding schedule to sequentially model the
contextual dependencies among latents at multiple scales, which enables more
efficient long-range context modeling. Furthermore, we propose a progressive
context fusion mechanism that incorporates contextual information from previous
coding steps into the current step, effectively exploiting diverse contextual
information. Experimental results demonstrate that our method achieves
state-of-the-art rate-distortion performance and strikes a better balance
between compression performance and computational complexity. The code is
available at https://github.com/lyq133/LIC-HPCM.

</details>


### [128] [Reconstruct or Generate: Exploring the Spectrum of Generative Modeling for Cardiac MRI](https://arxiv.org/abs/2507.19186)
*Niklas Bubeck,Yundi Zhang,Suprosanna Shit,Daniel Rueckert,Jiazhen Pan*

Main category: eess.IV

TL;DR: 论文分析了扩散模型和自回归模型在医学影像重建与生成任务中的表现，发现扩散模型适合无条件生成但易在高掩码比例下产生幻觉，而自回归模型表现稳定但保真度较低。


<details>
  <summary>Details</summary>
Motivation: 探讨生成模型在医学影像中的两个关键任务（重建和生成）中的表现差异，以解决它们在感知质量和数据保真度之间的权衡问题。

Method: 引入“生成模型动物园”，系统地分析了现代潜在扩散模型和自回归模型在重建与生成任务中的表现，并在代表性心脏医学影像任务上进行基准测试，重点关注不同掩码比例和采样策略下的图像修复以及无条件图像生成。

Result: 扩散模型在无条件生成任务中提供更优的感知质量，但在高掩码比例下容易产生幻觉；自回归模型在各种掩码比例下表现稳定，但保真度较低。

Conclusion: 扩散模型在无条件生成任务中表现更优，但在高掩码比例下容易产生幻觉；自回归模型则在各种掩码比例下保持稳定的感知性能，尽管其保真度较低。

Abstract: In medical imaging, generative models are increasingly relied upon for two
distinct but equally critical tasks: reconstruction, where the goal is to
restore medical imaging (usually inverse problems like inpainting or
superresolution), and generation, where synthetic data is created to augment
datasets or carry out counterfactual analysis. Despite shared architecture and
learning frameworks, they prioritize different goals: generation seeks high
perceptual quality and diversity, while reconstruction focuses on data fidelity
and faithfulness. In this work, we introduce a "generative model zoo" and
systematically analyze how modern latent diffusion models and autoregressive
models navigate the reconstruction-generation spectrum. We benchmark a suite of
generative models across representative cardiac medical imaging tasks, focusing
on image inpainting with varying masking ratios and sampling strategies, as
well as unconditional image generation. Our findings show that diffusion models
offer superior perceptual quality for unconditional generation but tend to
hallucinate as masking ratios increase, whereas autoregressive models maintain
stable perceptual performance across masking levels, albeit with generally
lower fidelity.

</details>


### [129] [Unstable Prompts, Unreliable Segmentations: A Challenge for Longitudinal Lesion Analysis](https://arxiv.org/abs/2507.19230)
*Niels Rocholl,Ewoud Smit,Mathias Prokop,Alessa Hering*

Main category: eess.IV

TL;DR: ULS23模型在纵向病灶分割中表现不佳，主要因扫描间配准错误和病灶对应过程崩溃。需转向专为时间分析设计的集成模型。


<details>
  <summary>Details</summary>
Motivation: 研究ULS23分割模型在纵向背景下的性能，揭示单时间点模型应用于纵向数据的根本局限性。

Method: 使用公共临床数据集中的基线和随访CT扫描，评估ULS23模型在纵向背景下分割和跟踪病灶的能力。通过人工位移输入体积相对于真实病灶中心的受控实验，系统探测模型的脆弱性。

Result: 模型性能高度依赖于病灶居中的假设；当病灶位移足够大时，分割准确性崩溃。

Conclusion: 稳健的肿瘤跟踪需要从级联的单用途工具转向专为时间分析设计的集成端到端模型。

Abstract: Longitudinal lesion analysis is crucial for oncological care, yet automated
tools often struggle with temporal consistency. While universal lesion
segmentation models have advanced, they are typically designed for single time
points. This paper investigates the performance of the ULS23 segmentation model
in a longitudinal context. Using a public clinical dataset of baseline and
follow-up CT scans, we evaluated the model's ability to segment and track
lesions over time. We identified two critical, interconnected failure modes: a
sharp degradation in segmentation quality in follow-up cases due to inter-scan
registration errors, and a subsequent breakdown of the lesion correspondence
process. To systematically probe this vulnerability, we conducted a controlled
experiment where we artificially displaced the input volume relative to the
true lesion center. Our results demonstrate that the model's performance is
highly dependent on its assumption of a centered lesion; segmentation accuracy
collapses when the lesion is sufficiently displaced. These findings reveal a
fundamental limitation of applying single-timepoint models to longitudinal
data. We conclude that robust oncological tracking requires a paradigm shift
away from cascading single-purpose tools towards integrated, end-to-end models
inherently designed for temporal analysis.

</details>


### [130] [NerT-CA: Efficient Dynamic Reconstruction from Sparse-view X-ray Coronary Angiography](https://arxiv.org/abs/2507.19328)
*Kirsten W. H. Maas,Danny Ruijters,Nicola Pezzotti,Anna Vilanova*

Main category: eess.IV

TL;DR: NerT-CA结合神经和张力表示，加速4D冠状动脉重建，减少视图需求并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在稀疏视图下重建冠状动脉时训练时间长、依赖手动或自动分割的问题。

Method: 提出NerT-CA，一种混合神经和张力表示的方法，利用低秩静态重建和动态稀疏重建的分解。

Result: 在训练时间和重建准确性上均优于先前工作，仅需三个血管造影视图即可获得合理重建。

Conclusion: NerT-CA通过结合神经和张力表示，显著提高了4D重建的训练速度和准确性，即使在极少的血管造影视图下也能获得合理结果。

Abstract: Three-dimensional (3D) and dynamic 3D+time (4D) reconstruction of coronary
arteries from X-ray coronary angiography (CA) has the potential to improve
clinical procedures. However, there are multiple challenges to be addressed,
most notably, blood-vessel structure sparsity, poor background and blood vessel
distinction, sparse-views, and intra-scan motion. State-of-the-art
reconstruction approaches rely on time-consuming manual or error-prone
automatic segmentations, limiting clinical usability. Recently, approaches
based on Neural Radiance Fields (NeRF) have shown promise for automatic
reconstructions in the sparse-view setting. However, they suffer from long
training times due to their dependence on MLP-based representations. We propose
NerT-CA, a hybrid approach of Neural and Tensorial representations for
accelerated 4D reconstructions with sparse-view CA. Building on top of the
previous NeRF-based work, we model the CA scene as a decomposition of low-rank
and sparse components, utilizing fast tensorial fields for low-rank static
reconstruction and neural fields for dynamic sparse reconstruction. Our
approach outperforms previous works in both training time and reconstruction
accuracy, yielding reasonable reconstructions from as few as three angiogram
views. We validate our approach quantitatively and qualitatively on
representative 4D phantom datasets.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [131] [Exploring the Landscape of Fairness Interventions in Software Engineering](https://arxiv.org/abs/2507.18726)
*Sadia Afrin Mim*

Main category: cs.SE

TL;DR: 本文综述了AI公平性问题的现有干预方法，强调在实际应用中解决这些挑战的重要性。


<details>
  <summary>Details</summary>
Motivation: AI在医疗和金融等关键领域的广泛应用带来了潜在风险，如数据偏见，因此需要系统梳理和总结现有的公平性干预方法。

Method: 作为一篇综述性论文，本文通过收集和分析现有研究，系统地总结了针对AI公平性问题的各种干预措施。

Result: 论文概述了多种公平性干预措施，为研究者和实践者提供了全面的参考。

Conclusion: 论文总结了当前解决AI公平性问题的多种方法，并强调了在实际应用中持续关注和解决这些挑战的重要性。

Abstract: Current developments in AI made it broadly significant for reducing human
labor and expenses across several essential domains, including healthcare and
finance. However, the application of AI in the actual world poses multiple
risks and disadvantages due to potential risk factors in data (e.g., biased
dataset). Practitioners developed a number of fairness interventions for
addressing these kinds of problems. The paper acts as a survey, summarizing the
various studies and approaches that have been developed to address fairness
issues

</details>


### [132] [Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback](https://arxiv.org/abs/2507.18755)
*Chandra Maddila,Adam Tait,Claire Chang,Daniel Cheng,Nauman Ahmad,Vijayaraghavan Murali,Marshall Roch,Arnaud Avondet,Aaron Meltzer,Victor Montalvao,Michael Hopko,Chris Waterson,Parth Thakkar,Renuka Fernandez,Kristian Kristensen,Sivan Barzily,Sherry Chen,Rui Abreu,Nachiappan Nagappan,Payam Shodjai,Killian Murphy,James Everingham,Aparna Ramani,Peter C. Rigby*

Main category: cs.SE

TL;DR: 开发了一个基于LLM的工程代理，通过ReAct框架和LLM-as-a-Judge在规模化代码修复中表现优异，31.5%的补丁被采用。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的发展，大型组织可以利用其进行复杂的程序修复。本研究旨在开发一个能够基于测试失败大规模修复源代码的工程代理。

Method: 利用Llama作为基础模型，结合ReAct框架开发了一个工程代理。该代理通过15种动作（从读取文件到生成补丁）进行推理，并通过静态分析和测试失败反馈优化解决方案。同时，使用LLM-as-a-Judge确保补丁符合人工审核标准。

Result: 离线评估显示，专有的70B模型与更大的Llama-405B相比具有竞争力。结合符号信息和测试执行跟踪的ReAct框架显著提升了性能。生产环境中，31.5%的生成补丁被采用。

Conclusion: 该研究表明，基于LLM的工程代理在规模化修复代码时具有实际应用价值，尤其是在结合符号信息和测试执行跟踪的情况下，能够高效生成符合标准的补丁。

Abstract: Aim: With the advent of LLMs, sophisticated agentic program repair has become
viable at large organizations with large codebases. In this work, we develop an
Engineering Agent that fixes the source code based on test failures at scale
across diverse software offerings internally.
  Method: Using Llama as the base, we employ the ReAct harness to develop an
agent. We start with a test failure that was triaged by a rule-based test
failure bot. We then set up an agentic harness and allow the agent to reason
and run a set of 15 actions from reading a file to generating a patch. We
provide feedback to the agent through static analysis and test failures so it
can refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch
conforms to the standards followed by a human review to land fixes.
  Benchmark Findings: We curated offline benchmarks for our patch generator,
the Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we
found that a specialized 70B model is highly competitive with the much larger
but vanilla Llama-405B. In an ablation study, we found that the ReAct harness
(neural model) benefited from the symbolic information from static analysis
tools and test execution traces. A model that strikes a balance between the
solve rate and error rate vs the cost and latency has a benchmark solve rate of
42.3% using an average 11.8 feedback iterations.
  Production Findings: In a three month period, 80% of the generated fixes were
reviewed, of which 31.5% were landed (25.5% of the total number of generated
fixes).
  Feedback from Engineers: We used open coding to extract qualitative themes
from engineers' feedback. We saw positive feedback in the form of quick
approvals, gratitude, and surprise. We also found mixed feedback when the
Engineering Agent's solution was partially correct and it served as a good
starting point.

</details>


### [133] [MemoCoder: Automated Function Synthesis using LLM-Supported Agents](https://arxiv.org/abs/2507.18812)
*Yiping Jia,Zhen Ming Jiang,Shayan Noei,Ying Zou*

Main category: cs.SE

TL;DR: MemoCoder是一个多智能体框架，通过知识积累和协作修复提升代码生成能力，实验显示其在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在迭代调试和错误处理上表现不足，且缺乏知识积累机制，MemoCoder旨在解决这些局限。

Method: 提出MemoCoder框架，包含Fixing Knowledge Set和Mentor Agent，支持协作问题解决和从历史修复中学习。

Result: 在MBPP、HumanEval和LiveCodeBench基准测试中，MemoCoder在Pass@10和Pass@50指标上分别提升3.1%-12.1%和1.4%-14.5%。

Conclusion: MemoCoder通过多智能体协作和知识积累机制，显著提升了代码生成的迭代调试和错误处理能力，实验结果表明其在多个基准测试中优于现有方法。

Abstract: With the widespread adoption of Large Language Models (LLMs) such as GitHub
Copilot and ChatGPT, developers increasingly rely on AI-assisted tools to
support code generation. While LLMs can generate syntactically correct
solutions for well-structured programming tasks, they often struggle with
challenges that require iterative debugging, error handling, or adaptation to
diverse problem structures. Existing approaches such as fine-tuning or
self-repair strategies either require costly retraining or lack mechanisms to
accumulate and reuse knowledge from previous attempts.
  To address these limitations, we propose MemoCoder, a multi-agent framework
that enables collaborative problem solving and persistent learning from past
fixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores
successful repairs and supports retrieval for future tasks. A central Mentor
Agent supervises the repair process by identifying recurring error patterns and
refining high-level fixing strategies, providing a novel supervisory role that
guides the self-repair loop. We evaluate MemoCoder across three public
benchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem
complexities. Experimental results show that MemoCoder consistently outperforms
both zero-shot prompting and a Self-Repair strategy, with improvements ranging
from 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating
its effectiveness in iterative refinement and knowledge-guided code generation.

</details>


### [134] [Exploring the Jupyter Ecosystem: An Empirical Study of Bugs and Vulnerabilities](https://arxiv.org/abs/2507.18833)
*Wenyuan Jiang,Diany Pressato,Harsh Darji,Thibaud Lutellier*

Main category: cs.SE

TL;DR: 该论文通过大规模实证研究分析了Jupyter笔记本中的错误和漏洞，发现配置问题和API误用是最常见的错误，并探讨了部署框架的常见风险，指出笔记本相比传统软件支持不足，导致代码复杂、配置错误和维护差。


<details>
  <summary>Details</summary>
Motivation: Jupyter notebooks are one of the main tools used by data scientists. Notebooks include features (configuration scripts, markdown, images, etc.) that make them challenging to analyze compared to traditional software. As a result, existing software engineering models, tools, and studies do not capture the uniqueness of Notebook's behavior. This paper aims to provide a large-scale empirical study of bugs and vulnerabilities in the Notebook ecosystem.

Method: We collected and analyzed a large dataset of Notebooks from two major platforms. Our methodology involved quantitative analyses of notebook characteristics (such as complexity metrics, contributor activity, and documentation) to identify factors correlated with bugs. Additionally, we conducted a qualitative study using grounded theory to categorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally, we analyzed security-related commits and vulnerability reports to assess risks associated with Notebook deployment frameworks.

Result: Our findings highlight that configuration issues are among the most common bugs in notebook documents, followed by incorrect API usage. Finally, we explore common vulnerabilities associated with popular deployment frameworks to better understand risks associated with Notebook development.

Conclusion: This work highlights that notebooks are less well-supported than traditional software, resulting in more complex code, misconfiguration, and poor maintenance.

Abstract: Background. Jupyter notebooks are one of the main tools used by data
scientists. Notebooks include features (configuration scripts, markdown,
images, etc.) that make them challenging to analyze compared to traditional
software. As a result, existing software engineering models, tools, and studies
do not capture the uniqueness of Notebook's behavior. Aims. This paper aims to
provide a large-scale empirical study of bugs and vulnerabilities in the
Notebook ecosystem. Method. We collected and analyzed a large dataset of
Notebooks from two major platforms. Our methodology involved quantitative
analyses of notebook characteristics (such as complexity metrics, contributor
activity, and documentation) to identify factors correlated with bugs.
Additionally, we conducted a qualitative study using grounded theory to
categorize notebook bugs, resulting in a comprehensive bug taxonomy. Finally,
we analyzed security-related commits and vulnerability reports to assess risks
associated with Notebook deployment frameworks. Results. Our findings highlight
that configuration issues are among the most common bugs in notebook documents,
followed by incorrect API usage. Finally, we explore common vulnerabilities
associated with popular deployment frameworks to better understand risks
associated with Notebook development. Conclusions. This work highlights that
notebooks are less well-supported than traditional software, resulting in more
complex code, misconfiguration, and poor maintenance.

</details>


### [135] [SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents](https://arxiv.org/abs/2507.18957)
*Jianming Chang,Jieke Shi,Yunbo Lyu,Xin Zhou,Lulu Wang,Zhou Yang,Bixin Li,David Lo*

Main category: cs.SE

TL;DR: SliceMate是一种基于LLM代理的静态程序切片解决方案，通过三个协同代理（合成、验证、细化）提升切片准确性和效率，无需显式依赖图。在大型基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统切片工具依赖计算成本高的可达性分析，难以扩展到大型程序且对语法不完整的代码处理不佳。学习型方法虽更鲁棒，但在规范代码上性能仍不及传统方法。

Method: SliceMate利用三个LLM代理（合成代理、验证代理和细化代理）协同工作，通过增量扫描、验证和修复来生成高质量切片，无需构建显式依赖图。

Result: SliceMate在包含2,200个手动标注的Java和Python程序的SliceBench基准测试中，显著优于传统和学习型切片工具。

Conclusion: SliceMate通过集成三个专门设计的LLM代理（合成、验证和细化代理），在无需显式依赖图构建的情况下，显著提高了静态程序切片的准确性和效率。实验证明其在大型程序上的优越性能。

Abstract: Static program slicing, which extracts the executable portions of a program
that affect the values at a specific location, supports many software analysis
tasks such as debugging and security auditing. However, traditional slicing
tools rely on computationally expensive reachability analysis over dependency
graphs, which struggle to scale to large programs and often fail to handle code
with incomplete syntax. Recently emerged learning-based methods, while more
robust to such cases, still fall short of achieving comparable performance to
traditional methods on well-formed code.
  In this work, we propose SliceMate, a novel static program slicing solution
powered by Large Language Model (LLM) agents. It bypasses the need for explicit
dependency graph construction and achieving superior slicing accuracy.
Concretely, SliceMate integrates three specialized agents: (1) a synthesis
agent that produces candidate slices by incrementally expanding the scan scope
across functions and files guided by LLM-inferred dependencies; (2) a
verification agent that performs conciseness and completeness checks of the
candidate slices, detecting missing or irrelevant statements; and (3) a
refinement agent that repairs the slices with minimal edits in accordance with
the verification results. These agents are orchestrated by a control module
that ensures timely convergence and outputs high-quality slices without manual
intervention. For rigorous evaluation, we construct a new and high-quality
benchmark, SliceBench, comprising 2,200 manually annotated Java and Python
programs, with program lengths ranging from 5 to 8,577 lines, significantly
larger than those in existing slicing benchmarks. Experimental results show
that SliceMate greatly outperforms both traditional and learning-based slicing
tools.

</details>


### [136] [Classifying Issues in Open-source GitHub Repositories](https://arxiv.org/abs/2507.18982)
*Amir Hossain Raaj,Fairuz Nawer Meem,Sadia Afrin Mim*

Main category: cs.SE

TL;DR: 研究使用ML和DNN模型自动分类GitHub问题，DNN表现最佳，有助于提升开发效率。


<details>
  <summary>Details</summary>
Motivation: GitHub问题标签的不一致性影响了开发效率，自动分类有助于快速解决问题。

Method: 分析了GitHub上知名开源仓库的问题，并使用ML和DNN模型对问题进行自动分类。

Result: DNN模型在问题分类任务中表现最佳。

Conclusion: DNN模型在GitHub问题的自动分类上表现优于其他机器学习模型，有助于提高开源社区的开发效率。

Abstract: GitHub is the most widely used platform for software maintenance in the
open-source community. Developers report issues on GitHub from time to time
while facing difficulties. Having labels on those issues can help developers
easily address those issues with prior knowledge of labels. However, most of
the GitHub repositories do not maintain regular labeling for the issues. The
goal of this work is to classify issues in the open-source community using ML
\& DNN models. There are thousands of open-source repositories on GitHub. Some
of the repositories label their issues properly whereas some of them do not.
When issues are pre-labeled, the problem-solving process and the immediate
assignment of corresponding personnel are facilitated for the team, thereby
expediting the development process. In this work, we conducted an analysis of
prominent GitHub open-source repositories. We classified the issues in some
common labels which are: API, Documentation, Enhancement, Question, Easy,
Help-wanted, Dependency, CI, Waiting for OP's response, Test, Bug, etc. Our
study shows that DNN models outperf

</details>


### [137] [SDVDiag: A Modular Platform for the Diagnosis of Connected Vehicle Functions](https://arxiv.org/abs/2507.19403)
*Matthias Weiß,Falk Dettinger,Michael Weyrich*

Main category: cs.SE

TL;DR: SDVDiag是一个自动化诊断平台，通过动态依赖图和异常监控快速定位连接车辆系统的故障根因，测试显示其能有效减少停机时间。


<details>
  <summary>Details</summary>
Motivation: 连接车辆系统的高可靠性和可用性要求快速故障诊断，但复杂的云/边缘架构和依赖关系使得手动分析不可行，亟需自动化解决方案。

Method: SDVDiag是一个可扩展的诊断平台，支持从数据收集到根因追踪的全流程管道构建，具备运行时模块交换能力，并通过动态依赖图和异常监控实现自适应分析。

Result: 在5G测试车队环境中部署SDVDiag后，平台能够可靠检测注入的故障，证明了其在早期问题识别和减少停机时间方面的潜力。

Conclusion: SDVDiag平台通过自动化诊断和动态依赖图分析，显著提高了连接车辆系统的故障检测效率和准确性，减少了停机时间，为早期问题识别提供了新视角。

Abstract: Connected and software-defined vehicles promise to offer a broad range of
services and advanced functions to customers, aiming to increase passenger
comfort and support autonomous driving capabilities. Due to the high
reliability and availability requirements of connected vehicles, it is crucial
to resolve any occurring failures quickly. To achieve this however, a complex
cloud/edge architecture with a mesh of dependencies must be navigated to
diagnose the responsible root cause. As such, manual analyses become unfeasible
since they would significantly delay the troubleshooting.
  To address this challenge, this paper presents SDVDiag, an extensible
platform for the automated diagnosis of connected vehicle functions. The
platform enables the creation of pipelines that cover all steps from initial
data collection to the tracing of potential root causes. In addition, SDVDiag
supports self-adaptive behavior by the ability to exchange modules at runtime.
Dependencies between functions are detected and continuously updated, resulting
in a dynamic graph view of the system. In addition, vital system metrics are
monitored for anomalies. Whenever an incident is investigated, a snapshot of
the graph is taken and augmented by relevant anomalies. Finally, the analysis
is performed by traversing the graph and creating a ranking of the most likely
causes.
  To evaluate the platform, it is deployed inside an 5G test fleet environment
for connected vehicle functions. The results show that injected faults can be
detected reliably. As such, the platform offers the potential to gain new
insights and reduce downtime by identifying problems and their causes at an
early stage.

</details>


### [138] [SESR-Eval: Dataset for Evaluating LLMs in the Title-Abstract Screening of Systematic Reviews](https://arxiv.org/abs/2507.19027)
*Aleksi Huotala,Miikka Kuutila,Mika Mäntylä*

Main category: cs.SE

TL;DR: 研究创建了SESR-Eval数据集，评估了9个LLMs在软件工程系统评审标题-摘要筛选中的性能，发现LLMs表现相似但准确性差异大，成本低但尚未推荐自动化使用。


<details>
  <summary>Details</summary>
Motivation: 创建基准数据集以评估LLMs在系统评审标题-摘要筛选过程中的性能，并提供关于在软件工程中使用LLMs进行标题-摘要筛选是否可取的证据。

Method: 我们从169个系统评审研究工件开始，筛选出24个适合纳入数据集的研究。使用该数据集，我们通过9个LLMs对标题-摘要筛选进行了基准测试。

Result: 我们提出了SESR-Eval（软件工程系统评审评估）数据集，包含34,528个标记的初步研究，源自发表在软件工程期刊上的24个二级研究。大多数LLMs表现相似，且二级研究之间的筛选准确性差异大于LLMs之间的差异。使用LLM的成本相对较低，即使是最昂贵的模型，每个二级研究的成本也低于40美元。

Conclusion: 我们的基准测试能够监控人工智能在软件工程系统评审筛选任务中的表现。目前，尚不推荐使用大语言模型（LLMs）来自动化标题-摘要筛选过程，因为不同二级研究的准确性差异较大，且没有LLM能在保持合理精确度的同时实现高召回率。未来，我们计划研究影响LLM在不同研究间筛选性能的因素。

Abstract: Background: The use of large language models (LLMs) in the title-abstract
screening process of systematic reviews (SRs) has shown promising results, but
suffers from limited performance evaluation. Aims: Create a benchmark dataset
to evaluate the performance of LLMs in the title-abstract screening process of
SRs. Provide evidence whether using LLMs in title-abstract screening in
software engineering is advisable. Method: We start with 169 SR research
artifacts and find 24 of those to be suitable for inclusion in the dataset.
Using the dataset we benchmark title-abstract screening using 9 LLMs. Results:
We present the SESR-Eval (Software Engineering Systematic Review Evaluation)
dataset containing 34,528 labeled primary studies, sourced from 24 secondary
studies published in software engineering (SE) journals. Most LLMs performed
similarly and the differences in screening accuracy between secondary studies
are greater than differences between LLMs. The cost of using an LLM is
relatively low - less than $40 per secondary study even for the most expensive
model. Conclusions: Our benchmark enables monitoring AI performance in the
screening task of SRs in software engineering. At present, LLMs are not yet
recommended for automating the title-abstract screening process, since accuracy
varies widely across secondary studies, and no LLM managed a high recall with
reasonable precision. In future, we plan to investigate factors that influence
LLM screening performance between studies.

</details>


### [139] [An OpenSource CI/CD Pipeline for Variant-Rich Software-Defined Vehicles](https://arxiv.org/abs/2507.19446)
*Matthias Weiß,Anish Navalgund,Johannes Stümpfle,Falk Dettinger,Michael Weyrich*

Main category: cs.SE

TL;DR: 论文提出了一种开源CI/CD管道，用于管理SDV的软件变体和OTA更新，通过容器化工具和自定义中间件实现自动化构建、测试和部署，并在AVP场景中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆（SDV）通过OTA机制不断更新功能，导致软件版本和变体数量增加，且缺乏统一的集成环境，使得开发复杂化。为确保异构系统中的可靠运行，需要动态编排功能。

Method: 论文提出了一种针对SDV的开源CI/CD管道，结合容器化的开源工具自动化构建、测试和部署阶段，创建了一个标准化、可移植且可扩展的生态系统。此外，还开发了自定义OTA中间件来分发软件更新并支持回滚。

Result: 通过自动代客泊车（AVP）场景评估，结果显示无缝OTA更新、正确的变体选择以及跨所有目标的成功编排。开发并部署了两个对象检测变体以满足硬件特定需求。

Conclusion: 论文提出的开源CI/CD管道为软件定义车辆（SDV）提供了一个可扩展且高效的解决方案，用于管理软件变体和OTA更新，推动了未来移动技术的发展。

Abstract: Software-defined vehicles (SDVs) offer a wide range of connected
functionalities, including enhanced driving behavior and fleet management.
These features are continuously updated via over-the-air (OTA) mechanisms,
resulting in a growing number of software versions and variants due to the
diversity of vehicles, cloud/edge environments, and stakeholders involved. The
lack of a unified integration environment further complicates development, as
connected mobility solutions are often built in isolation. To ensure reliable
operations across heterogeneous systems, a dynamic orchestration of functions
that considers hardware and software variability is essential. This paper
presents an open-source CI/CD pipeline tailored for SDVs. It automates the
build, test, and deployment phases using a combination of containerized
open-source tools, creating a standardized, portable, and scalable ecosystem
accessible to all stakeholders. Additionally, a custom OTA middleware
distributes software updates and supports rollbacks across vehicles and backend
services. Update variants are derived based on deployment target dependencies
and hardware configurations. The pipeline also supports continuous development
and deployment of AI models for autonomous driving features. Its effectiveness
is evaluated using an automated valet parking (AVP) scenario involving
TurtleBots and a coordinating backend server. Two object detection variants are
developed and deployed to match hardware-specific requirements. Results
demonstrate seamless OTA updates, correct variant selection, and successful
orchestration across all targets. Overall, the proposed pipeline provides a
scalable and efficient solution for managing software variants and OTA updates
in SDVs, contributing to the advancement of future mobility technologies.

</details>


### [140] [Exploring the Use of LLMs for Requirements Specification in an IT Consulting Company](https://arxiv.org/abs/2507.19113)
*Liliana Pasquale,Azzurra Ragone,Emanuele Piemontese,Armin Amiri Darban*

Main category: cs.SE

TL;DR: 论文探讨了LLMs在自动化需求规范中的应用，发现其能有效减少人工投入，但需与人类协同以确保文档质量。


<details>
  <summary>Details</summary>
Motivation: 需求规范的生成过程因知识分散在不同来源（如会议记录、邮件、高层产品描述）中而变得繁琐耗时，研究旨在探索LLMs在自动化这一过程中的潜力。

Method: 研究比较了三种先进LLMs与人类分析师生成的FDS文档的正确性和质量，评估了LLMs在自动化需求规范过程中的表现。

Result: 结果表明，LLMs能帮助自动化和标准化需求规范，减少时间和人力投入，但其生成的FDS质量高度依赖输入，常需人工修订。

Conclusion: 论文主张采用LLMs与人类分析师协同工作的方法，LLMs作为高效的起草工具，而人类分析师提供关键的技术监督，以确保高质量的RE文档。

Abstract: In practice, requirements specification remains a critical challenge. The
knowledge necessary to generate a specification can often be fragmented across
diverse sources (e.g., meeting minutes, emails, and high-level product
descriptions), making the process cumbersome and time-consuming. In this paper,
we report our experience using large language models (LLMs) in an IT consulting
company to automate the requirements specification process. In this company,
requirements are specified using a Functional Design Specification (FDS), a
document that outlines the functional requirements and features of a system,
application, or process. We provide LLMs with a summary of the requirements
elicitation documents and FDS templates, prompting them to generate Epic FDS
(including high-level product descriptions) and user stories, which are
subsequently compiled into a complete FDS document. We compared the correctness
and quality of the FDS generated by three state-of-the-art LLMs against those
produced by human analysts. Our results show that LLMs can help automate and
standardize the requirements specification, reducing time and human effort.
However, the quality of LLM-generated FDS highly depends on inputs and often
requires human revision. Thus, we advocate for a synergistic approach in which
an LLM serves as an effective drafting tool while human analysts provide the
critical contextual and technical oversight necessary for high-quality
requirements engineering (RE) documentation.

</details>


### [141] [Automated Code Review Using Large Language Models at Ericsson: An Experience Report](https://arxiv.org/abs/2507.19115)
*Shweta Ramesh,Joy Bose,Hamender Singh,A K Raghavan,Sujoy Roychowdhury,Giriprasad Sridhara,Nishrith Saini,Ricardo Britto*

Main category: cs.SE

TL;DR: 利用LLMs和静态分析开发自动化代码审查工具，初步实验效果良好。


<details>
  <summary>Details</summary>
Motivation: 代码审查是保证软件质量的重要手段，但资深开发者时间有限，自动化代码审查可以减轻他们的负担，使其专注于编写代码和修复错误。

Method: 结合大型语言模型（LLMs）和静态程序分析技术，开发了一个轻量级的代码审查工具。

Result: 初步实验显示，该工具在资深开发者的评估中取得了令人鼓舞的结果。

Conclusion: 初步实验表明，利用大型语言模型（LLMs）和静态程序分析开发的轻量级工具在自动化代码审查方面具有潜力，能够减轻资深开发者的认知负担。

Abstract: Code review is one of the primary means of assuring the quality of released
software along with testing and static analysis. However, code review requires
experienced developers who may not always have the time to perform an in-depth
review of code. Thus, automating code review can help alleviate the cognitive
burden on experienced software developers allowing them to focus on their
primary activities of writing code to add new features and fix bugs. In this
paper, we describe our experience in using Large Language Models towards
automating the code review process in Ericsson. We describe the development of
a lightweight tool using LLMs and static program analysis. We then describe our
preliminary experiments with experienced developers in evaluating our code
review tool and the encouraging results.

</details>


### [142] [Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects](https://arxiv.org/abs/2507.19271)
*Igli Begolli,Meltem Aksoy,Daniel Neider*

Main category: cs.SE

TL;DR: 研究评估了单语言微调对开源LMs在自动化代码审查任务中的表现，发现其在准确性和相关性上优于多语言基线，但人类审查员在复杂任务中仍占优。


<details>
  <summary>Details</summary>
Motivation: 代码审查对维护软件质量至关重要，但在工业环境中通常耗时且认知要求高。语言模型的最新进展为自动化核心审查任务提供了新途径。本研究旨在探讨编程语言和自然语言在训练数据中的不同配置如何影响LMs的性能，尤其是在评论生成方面。

Method: 本研究通过单语言微调评估了三种开源LMs（CodeReviewer、CodeLlama-7B和DeepSeek-R1-Distill）在三个关键自动化代码审查任务上的表现：代码变更质量评估、审查评论生成和代码优化。使用了结合公共基准和工业仓库的C#特定数据集进行微调。

Result: 单语言微调提高了模型的准确性和相关性。LMs在支持代码审查工作流方面表现良好，尤其是在常规或重复性任务中，但在处理语义复杂或上下文敏感的变更时仍不及人类审查员。

Conclusion: 单语言微调在提高语言模型（LMs）在代码审查任务中的准确性和相关性方面表现优于多语言基线。尽管LMs能有效支持代码审查工作流，尤其是在处理常规或重复性任务时，人类审查员在处理语义复杂或上下文敏感的变更时仍具有优势。研究强调了语言对齐和任务特定适应在优化LMs用于自动化代码审查中的重要性。

Abstract: Code review is essential for maintaining software quality but often
time-consuming and cognitively demanding, especially in industrial
environments. Recent advancements in language models (LMs) have opened new
avenues for automating core review tasks. This study presents the empirical
evaluation of monolingual fine-tuning on the performance of open-source LMs
across three key automated code review tasks: Code Change Quality Estimation,
Review Comment Generation, and Code Refinement. We fine-tuned three distinct
models, CodeReviewer, CodeLlama-7B, and DeepSeek-R1-Distill, on a C\# specific
dataset combining public benchmarks with industrial repositories. Our study
investigates how different configurations of programming languages and natural
languages in the training data affect LM performance, particularly in comment
generation. Additionally, we benchmark the fine-tuned models against an
automated software analysis tool (ASAT) and human reviewers to evaluate their
practical utility in real-world settings. Our results show that monolingual
fine-tuning improves model accuracy and relevance compared to multilingual
baselines. While LMs can effectively support code review workflows, especially
for routine or repetitive tasks, human reviewers remain superior in handling
semantically complex or context-sensitive changes. Our findings highlight the
importance of language alignment and task-specific adaptation in optimizing LMs
for automated code review.

</details>


### [143] [Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports](https://arxiv.org/abs/2507.19275)
*Bo Wang,Pengyang Wang,Chong Chen,Qi Sun,Jieke Shi,Chengran Yang,Ming Deng,Youfang Lin,Zhou Yang,David Lo*

Main category: cs.SE

TL;DR: Mut4All利用LLMs和编译器知识自动化生成突变器，显著提升了编译器漏洞检测的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 现代编程语言的复杂构造（如模板、宏）使得设计高质量的突变器具有挑战性，现有方法依赖人工设计或修正，限制了可扩展性和跨语言通用性。

Method: Mut4All框架包含三个代理：突变器发明代理、突变器实现合成代理和突变器优化代理，分别负责识别突变目标、生成初始实现及通过单元测试反馈进行验证和修正。

Result: 处理1000个错误报告（500 Rust，500 C++），生成了319个Rust和403个C++突变器，每个成本约0.08美元。自定义模糊测试工具使用这些突变器，分别在Rust和C++编译器中发现了62和34个漏洞。

Conclusion: Mut4All是一种完全自动化、语言无关的框架，通过结合LLMs和编译器特定知识，成功生成了高质量的突变器，显著提升了编译器漏洞检测的效率和效果。

Abstract: Mutation-based fuzzing is effective for uncovering compiler bugs, but
designing high-quality mutators for modern languages with complex constructs
(e.g., templates, macros) remains challenging. Existing methods rely heavily on
manual design or human-in-the-loop correction, limiting scalability and
cross-language generalizability.
  We present Mut4All, a fully automated, language-agnostic framework that
synthesizes mutators using Large Language Models (LLMs) and compiler-specific
knowledge from bug reports. It consists of three agents: (1) a mutator
invention agent that identifies mutation targets and generates mutator metadata
using compiler-related insights; (2) a mutator implementation synthesis agent,
fine-tuned to produce initial implementations; and (3) a mutator refinement
agent that verifies and corrects the mutators via unit-test feedback.
  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and
403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these
mutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++
compilers (16 new, 1 fixed). Mut4All outperforms existing methods in both
unique crash detection and coverage, ranking first on Rust and second on C++.

</details>


### [144] [ReCatcher: Towards LLMs Regression Testing for Code Generation](https://arxiv.org/abs/2507.19390)
*Altaf Allah Abbassi,Leuson Da Silva,Amin Nikanjam,Foutse Khomh*

Main category: cs.SE

TL;DR: ReCatcher 是一个回归测试框架，用于评估代码生成 LLM 的更新，发现不同更新方式会导致逻辑、质量和性能的回归问题。


<details>
  <summary>Details</summary>
Motivation: LLM 的更新（如微调、合并或新模型发布）可能导致回归问题，影响代码的正确性、质量和性能。

Method: 提出了 ReCatcher 框架，通过三个维度（逻辑正确性、静态代码质量和执行性能）系统比较两个 LLM 模型。

Result: 评估显示，不同更新场景（微调、合并、模型发布）会导致不同程度的回归问题，如语法错误增加 12%、正确性下降 18%、性能下降 80% 等。ReCatcher 在逻辑和性能方面表现优于基线方法。

Conclusion: ReCatcher 是一个有效的回归测试框架，能够系统地评估代码生成模型的更新，帮助研究者和从业者做出更明智的更新决策。

Abstract: Large Language Models (LLMs) for code generation evolve rapidly through
fine-tuning, merging, or new model releases. However, such updates can
introduce regressions, not only in correctness but also in code quality and
performance. To address this, we present ReCatcher, a regression testing
framework for Python code generation. ReCatcher systematically compares two
LLMs, typically a current model and a candidate update, across three
dimensions: logical correctness, static code quality, and execution
performance. We apply ReCatcher to assess regressions across three update
scenarios, fine-tuning, merging, and model release, using CodeLlama,
DeepSeek-Coder, and GPT-4o. Our evaluation shows that fine-tuning with
cross-language datasets increases syntax errors by up to 12%. Merging with
general-purpose models like Llama2 leads to regressions in correctness by up to
18%. GPT-4o introduces regressions of up to 50% in handling missing imports
compared to GPT-3.5-turbo, while GPT-4o-mini suffers up to 80% performance
degradation in execution time versus GPT-4o. Overall, logical correctness,
performance, and error handling (e.g., syntax errors and missing imports) are
the most regression-prone areas. Comparing ReCatcher with baseline solutions,
it presents better and consistent accuracy across logical and performance
aspects. ReCatcher highlights the importance of systematic regression
evaluation before adopting new models, while assisting researchers and
practitioners in making more informed update decisions.

</details>


### [145] [Resolving Build Conflicts via Example-Based and Rule-Based Program Transformations](https://arxiv.org/abs/2507.19432)
*Sheikh Shadab Towqir,Fei He,Todd Mytkowicz,Na Meng*

Main category: cs.SE

TL;DR: BUCOR是一种新型构建冲突解决工具，结合基于示例和基于规则的策略，有效解决复杂合并冲突，实验证明其在实际冲突中表现良好。


<details>
  <summary>Details</summary>
Motivation: 合并冲突（包括文本冲突和构建测试冲突）会降低软件质量并影响开发效率，现有工具在解决如方法移除等复杂冲突时支持有限。

Method: BUCOR通过比较基础版本（b）、左分支（l）和右分支（r）来检测冲突，并采用两种互补策略：基于示例的转换（BUCOR-E）和基于规则的转换（BUCOR-R）。

Result: 在88个真实构建冲突中，BUCOR为65个案例生成了至少一个解决方案，并正确解决了43个冲突。

Conclusion: BUCOR结合了基于示例和基于规则的转换策略，有效解决了构建冲突，为未来更智能、自动化的合并工具提供了方向。

Abstract: Merge conflicts often arise when developers integrate changes from different
software branches. The conflicts can result from overlapping edits in programs
(i.e., textual conflicts) or cause build and test errors (i.e., build and test
conflicts). They degrade software quality and hinder programmer productivity.
While several tools detect build conflicts, few offer meaningful support for
resolving cases like those caused by method removal. To overcome limitations of
existing tools, we introduce BUCOR (Build Conflict Resolver), a new conflict
resolver. BUCOR first detects conflicts by comparing three versions related to
a merging scenario: base b, left l, and right r. To resolve conflicts, it
employs two complementary strategies: example-based transformation (BUCOR-E)
and rule-based transformation (BUCOR-R). BUCOR-R applies predefined rules to
handle common, well-understood conflicts. BUCOR-E mines branch versions (l and
r) for exemplar edits applied to fix related build errors. From these examples,
it infers and generalizes program transformation patterns to resolve more
complex conflicts.
  We evaluated BUCOR on 88 real-world build conflicts spanning 21 distinct
conflict types. BUCOR generated at least one solution for 65 cases and
correctly resolved 43 conflicts. We observed that this hybrid
approach--combining context-aware, example-based learning with structured,
rule-based resolution--can effectively help resolve conflicts. Our research
sheds light on future directions for more intelligent and automated merge
tools.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [146] [A Truly Subcubic Combinatorial Algorithm for Induced 4-Cycle Detection](https://arxiv.org/abs/2507.18845)
*Amir Abboud,Shyan Akmal,Nick Fischer*

Main category: cs.DS

TL;DR: 提出了首个次立方组合算法，用于检测诱导4-周期，运行时间为O(n^2.84)，解决了诱导H-检测分类中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 解决诱导H-检测时间复杂度的分类问题，尤其是针对诱导4-周期检测是否为三角形难的问题，这是当前分类中的最后一个未解案例。

Method: 通过创新的图分解技术，该算法突破了传统子图检测方法的局限，利用了图分解的最新进展。

Result: 算法在n节点图上的运行时间为O(n^2.84)，首次提供了非平凡的确定性算法来检测诱导4-周期。

Conclusion: 该论文提出了首个真正的次立方组合算法，用于检测图中的诱导4-周期，运行时间为O(n^2.84)，从而将诱导4-周期检测与三角形检测的时间复杂度区分开来。

Abstract: We present the first truly subcubic, combinatorial algorithm for detecting an
induced $4$-cycle in a graph. The running time is $O(n^{2.84})$ on $n$-node
graphs, thus separating the task of detecting induced $4$-cycles from detecting
triangles, which requires $n^{3-o(1)}$ time combinatorially under the popular
BMM hypothesis.
  Significant work has gone into characterizing the exact time complexity of
induced $H$-detection, relative to the complexity of detecting cliques of
various sizes. Prior work identified the question of whether induced $4$-cycle
detection is triangle-hard as the only remaining case towards completing the
lowest level of the classification, dubbing it a "curious" case [Dalirrooyfard,
Vassilevska W., FOCS 2022]. Our result can be seen as a negative resolution of
this question.
  Our algorithm deviates from previous techniques in the large body of subgraph
detection algorithms and employs the trendy topic of graph decomposition that
has hitherto been restricted to more global problems (as in the use of expander
decompositions for flow problems) or to shaving subpolynomial factors (as in
the application of graph regularity lemmas). While our algorithm is slower than
the (non-combinatorial) state-of-the-art $\tilde{O}(n^{\omega})$-time algorithm
based on polynomial identity testing [Vassilevska W., Wang, Williams, Yu, SODA
2014], combinatorial advancements often come with other benefits. In
particular, we give the first nontrivial deterministic algorithm for detecting
induced $4$-cycles.

</details>


### [147] [String Consensus Problems with Swaps and Substitutions](https://arxiv.org/abs/2507.19139)
*Estéban Gabory,Laurent Bulteau,Gabriele Fici,Hilde Verbeek*

Main category: cs.DS

TL;DR: 本文研究了允许字符替换和交换的字符串共识问题，证明其对参数d是FPT的，并针对最小化总距离的变体提出了多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于扩展传统的字符串共识问题，考虑更多操作类型（如交换），并探索其计算复杂性及高效解决方案。

Method: 作者研究了字符串共识问题的广义版本，考虑了字符替换和相邻字符交换的操作，并分析了其参数化复杂性。对于最小化总距离的变体，提出了具体的算法设计。

Result: 结果表明，广义问题对于参数d是FPT的，且针对特定变体存在多项式时间算法。

Conclusion: 本文证明了在允许相邻字符交换的情况下，字符串共识问题对于参数d是固定参数可解的（FPT），并针对最小化输出字符串与所有输入字符串距离之和的变体提出了多项式时间算法。

Abstract: String consensus problems aim at finding a string that minimizes some given
distance with respect to an input set of strings. In particular, in the
\textsc{Closest String} problem, we are given a set of strings of equal length
and a radius $d$. The objective is to find a new string that differs from each
input string by at most $d$ substitutions. We study a generalization of this
problem where, in addition to substitutions, swaps of adjacent characters are
also permitted, each operation incurring a unit cost. Amir et al. showed that
this generalized problem is NP-hard, even when only swaps are allowed. In this
paper, we show that it is FPT with respect to the parameter $d$. Moreover, we
investigate a variant in which the goal is to minimize the sum of distances
from the output string to all input strings. For this version, we present a
polynomial-time algorithm.

</details>


### [148] [Budget and Profit Approximations for Spanning Tree Interdiction](https://arxiv.org/abs/2507.19178)
*Rafail Ostrovsky,Yuval Rabani,Yoav Siman Tov*

Main category: cs.DS

TL;DR: 论文提出多项式时间对数近似算法，解决最小生成树阻断问题的预算最小化和利润最大化版本，并展示了特定条件下的多项式时间可解性。


<details>
  <summary>Details</summary>
Motivation: 研究最小生成树阻断问题的动机在于解决在预算限制下如何有效增加最小生成树权重的问题，现有方法无法直接应用于权重增加的目标。

Method: 通过图论松弛和批处理贪心算法，解决了NP难的最小生成树阻断问题。

Result: 论文展示了预算最小化和利润最大化版本的多项式时间对数近似保证，并提供了一个高效算法来解决特定版本的阻断问题。

Conclusion: 该论文通过研究最小生成树阻断问题，提出了多项式时间内对数近似保证的算法，解决了预算最小化和利润最大化版本的问题，并展示了在特定条件下问题的多项式时间可解性。

Abstract: We give polynomial time logarithmic approximation guarantees for the budget
minimization, as well as for the profit maximization versions of minimum
spanning tree interdiction. In this problem, the goal is to remove some edges
of an undirected graph with edge weights and edge costs, so as to increase the
weight of a minimum spanning tree. In the budget minimization version, the goal
is to minimize the total cost of the removed edges, while achieving a desired
increase $\Delta$ in the weight of the minimum spanning tree. An alternative
objective within the same framework is to maximize the profit of interdiction,
namely the increase in the weight of the minimum spanning tree, subject to a
budget constraint. There are known polynomial time $O(1)$ approximation
guarantees for a similar objective (maximizing the total cost of the tree,
rather than the increase). However, the guarantee does not seem to apply to the
increase in cost. Moreover, the same techniques do not seem to apply to the
budget version.
  Our approximation guarantees are motivated by studying the question of
minimizing the cost of increasing the minimum spanning tree by any amount. We
show that in contrast to the budget and profit problems, this version of
interdiction is polynomial time-solvable, and we give an efficient algorithm
for solving it. The solution motivates a graph-theoretic relaxation of the
NP-hard interdiction problem. The gain in minimum spanning tree weight, as a
function of the set of removed edges, is super-modular. Thus, the budget
problem is an instance of minimizing a linear function subject to a
super-modular covering constraint. We use the graph-theoretic relaxation to
design and analyze a batch greedy-based algorithm.

</details>


### [149] [Query Efficient Structured Matrix Learning](https://arxiv.org/abs/2507.19290)
*Noah Amsel,Pratyush Avi,Tyler Chen,Feyza Duman Keles,Chinmay Hegde,Cameron Musco,Christopher Musco,David Persson*

Main category: cs.DS

TL;DR: 论文提出在matvec查询模型中，学习矩阵近似结构的查询复杂度可近乎二次优化至$\tilde{O}(\sqrt{\log|\mathcal{F}|})$，优于传统界限，并适用于无限矩阵族。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于科学计算和机器学习中快速矩阵乘法、逆运算、一阶优化的预条件构建等应用需求，旨在更一般化地理解学习矩阵近似结构的查询复杂度。

Method: 论文通过覆盖数论证和矩阵草图技术，研究了从有限或无限矩阵族中学习近似结构的查询复杂度。特别关注了线性矩阵族的维度$q$与查询复杂度的关系。

Result: 论文证明了在matvec模型中，学习一般矩阵族的近似结构可以实现$\tilde{O}(\sqrt{\log|\mathcal{F}|})$的查询复杂度，显著优于传统的$O(\log|\mathcal{F}|)$界限，并扩展至无限矩阵族（如线性矩阵族），将查询复杂度从$O(q)$改进为$\tilde{O}(\sqrt{q})$。

Conclusion: 该论文的主要结论是，在矩阵向量乘积（matvec）查询模型中，通过学习一般矩阵族的近似结构，可以实现近乎二次的复杂度改进，达到$\tilde{O}(\sqrt{\log|\mathcal{F}|})$，且这一界限在忽略对数对数因子时是紧的。

Abstract: We study the problem of learning a structured approximation (low-rank,
sparse, banded, etc.) to an unknown matrix $A$ given access to matrix-vector
product (matvec) queries of the form $x \rightarrow Ax$ and $x \rightarrow
A^Tx$. This problem is of central importance to algorithms across scientific
computing and machine learning, with applications to fast multiplication and
inversion for structured matrices, building preconditioners for first-order
optimization, and as a model for differential operator learning. Prior work
focuses on obtaining query complexity upper and lower bounds for learning
specific structured matrix families that commonly arise in applications.
  We initiate the study of the problem in greater generality, aiming to
understand the query complexity of learning approximations from general matrix
families. Our main result focuses on finding a near-optimal approximation to
$A$ from any finite-sized family of matrices, $\mathcal{F}$. Standard results
from matrix sketching show that $O(\log|\mathcal{F}|)$ matvec queries suffice
in this setting. This bound can also be achieved, and is optimal, for
vector-matrix-vector queries of the form $x,y\rightarrow x^TAy$, which have
been widely studied in work on rank-$1$ matrix sensing.
  Surprisingly, we show that, in the matvec model, it is possible to obtain a
nearly quadratic improvement in complexity, to
$\tilde{O}(\sqrt{\log|\mathcal{F}|})$. Further, we prove that this bound is
tight up to log-log factors.Via covering number arguments, our result extends
to well-studied infinite families. As an example, we establish that a
near-optimal approximation from any \emph{linear matrix family} of dimension
$q$ can be learned with $\tilde{O}(\sqrt{q})$ matvec queries, improving on an
$O(q)$ bound achievable via sketching techniques and vector-matrix-vector
queries.

</details>


### [150] [Edge-weighted Matching in the Dark](https://arxiv.org/abs/2507.19366)
*Zhiyi Huang,Enze Sun,Xiaowei Wu,Jiahao Zhao*

Main category: cs.DS

TL;DR: 提出Quadratic Ranking算法，在无分布Oblivious Bipartite Matching中实现0.659竞争比，突破1−1/e界限，优于现有依赖分布算法。


<details>
  <summary>Details</summary>
Motivation: 解决Tang等人提出的开放性问题，突破1−1/e的竞争比限制，并提升现有依赖分布算法的性能。

Method: 通过参数化两个函数，并让算法定义和分析中的两个关键表达式成为这两个函数的二次形式，利用二次规划求解器优化函数选择。

Result: 提出的Quadratic Ranking算法在无分布设置下实现了0.659的竞争比，优于现有依赖分布算法的0.641。

Conclusion: 该论文提出的Quadratic Ranking算法在无分布版本的Oblivious Bipartite Matching问题中实现了0.659的竞争比，打破了1−1/e的界限，并优于现有依赖分布的算法。

Abstract: We present a $0.659$-competitive Quadratic Ranking algorithm for the
Oblivious Bipartite Matching problem, a distribution-free version of
Query-Commit Matching. This result breaks the $1-\frac{1}{e}$ barrier,
addressing an open question raised by Tang, Wu, and Zhang (JACM 2023).
Moreover, the competitive ratio of this distribution-free algorithm improves
the best existing $0.641$ ratio for Query-Commit Matching achieved by the
distribution-dependent algorithm of Chen, Huang, Li, and Tang (SODA 2025).
  Quadratic Ranking is a novel variant of the classic Ranking algorithm. We
parameterize the algorithm with two functions, and let two key expressions in
the definition and analysis of the algorithm be quadratic forms of the two
functions. We show that the quadratic forms are the unique choices that satisfy
a set of natural properties. Further, they allow us to optimize the choice of
the two functions using powerful quadratic programming solvers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [151] [Perpetua: Multi-Hypothesis Persistence Modeling for Semi-Static Environments](https://arxiv.org/abs/2507.18808)
*Miguel Saavedra-Ruiz,Samer B. Nashed,Charlie Gauthier,Liam Paull*

Main category: cs.RO

TL;DR: Perpetua 是一种用于建模半静态特征动态的贝叶斯方法，优于现有技术，适用于复杂动态环境。


<details>
  <summary>Details</summary>
Motivation: 现有机器人建图或环境建模算法无法有效表示动态特征的未来状态，Perpetua 旨在解决这一问题。

Method: 通过将“持久性”和“涌现性”滤波器混合链接，在贝叶斯框架中建模特征消失或重现的概率。

Result: 实验表明，Perpetua 在模拟和真实数据中均表现出更高的准确性，且能在线适应和应对缺失观测。

Conclusion: Perpetua 是一种高效、可扩展且通用的方法，能够在复杂动态环境中预测半静态特征的未来状态，实验证明其优于现有方法。

Abstract: Many robotic systems require extended deployments in complex, dynamic
environments. In such deployments, parts of the environment may change between
subsequent robot observations. Most robotic mapping or environment modeling
algorithms are incapable of representing dynamic features in a way that enables
predicting their future state. Instead, they opt to filter certain state
observations, either by removing them or some form of weighted averaging. This
paper introduces Perpetua, a method for modeling the dynamics of semi-static
features. Perpetua is able to: incorporate prior knowledge about the dynamics
of the feature if it exists, track multiple hypotheses, and adapt over time to
enable predicting of future feature states. Specifically, we chain together
mixtures of "persistence" and "emergence" filters to model the probability that
features will disappear or reappear in a formal Bayesian framework. The
approach is an efficient, scalable, general, and robust method for estimating
the states of features in an environment, both in the present as well as at
arbitrary future times. Through experiments on simulated and real-world data,
we find that Perpetua yields better accuracy than similar approaches while also
being online adaptable and robust to missing observations.

</details>


### [152] [Probabilistic Collision Risk Estimation through Gauss-Legendre Cubature and Non-Homogeneous Poisson Processes](https://arxiv.org/abs/2507.18819)
*Trent Weiss,Madhur Behl*

Main category: cs.RO

TL;DR: GLR算法通过两阶段积分方法显著提升高速赛车中的碰撞风险评估精度，平均误差降低77%。


<details>
  <summary>Details</summary>
Motivation: 现有碰撞风险评估方法在高速赛车场景中过于简化或保守，无法满足精确、实时的需求。

Method: 引入了Gauss-Legendre Rectangle (GLR)算法，一种结合Gauss-Legendre和非均匀泊松过程的两阶段积分方法。

Result: 在446个超车场景中，GLR平均误差降低77%，优于其他五种最先进方法，且运行频率达1000 Hz。

Conclusion: GLR算法在高速自动驾驶赛车中表现出色，显著降低了碰撞风险评估的平均误差，并适用于更广泛的运动规划场景。

Abstract: Overtaking in high-speed autonomous racing demands precise, real-time
estimation of collision risk; particularly in wheel-to-wheel scenarios where
safety margins are minimal. Existing methods for collision risk estimation
either rely on simplified geometric approximations, like bounding circles, or
perform Monte Carlo sampling which leads to overly conservative motion planning
behavior at racing speeds. We introduce the Gauss-Legendre Rectangle (GLR)
algorithm, a principled two-stage integration method that estimates collision
risk by combining Gauss-Legendre with a non-homogeneous Poisson process over
time. GLR produces accurate risk estimates that account for vehicle geometry
and trajectory uncertainty. In experiments across 446 overtaking scenarios in a
high-fidelity Formula One racing simulation, GLR outperforms five
state-of-the-art baselines achieving an average error reduction of 77% and
surpassing the next-best method by 52%, all while running at 1000 Hz. The
framework is general and applicable to broader motion planning contexts beyond
autonomous racing.

</details>


### [153] [MetaMorph -- A Metamodelling Approach For Robot Morphology](https://arxiv.org/abs/2507.18820)
*Rachel Ringe,Robin Nolte,Nima Zargham,Robert Porzel,Rainer Malaka*

Main category: cs.RO

TL;DR: MetaMorph是一个基于222个机器人数据的元建模框架，解决了现有机器人外观分类方法的局限性，为HRI研究提供了更全面的形态分类工具。


<details>
  <summary>Details</summary>
Motivation: 现有机器人外观分类方法过于宽泛或局限于拟人化特征，无法全面分类所有类型机器人，限制了设计与交互效果的关联研究。

Method: 采用元建模方法，基于IEEE Robots Guide中的222个机器人数据，建立了MetaMorph框架。

Result: MetaMorph框架能够系统化比较机器人视觉特征，评估模型间的视觉差异，并探索适合不同任务和场景的设计特征。

Conclusion: MetaMorph提供了一个全面的机器人形态分类框架，填补了现有分类方法的不足，为HRI研究提供了更精确的工具。

Abstract: Robot appearance crucially shapes Human-Robot Interaction (HRI) but is
typically described via broad categories like anthropomorphic, zoomorphic, or
technical. More precise approaches focus almost exclusively on anthropomorphic
features, which fail to classify robots across all types, limiting the ability
to draw meaningful connections between robot design and its effect on
interaction. In response, we present MetaMorph, a comprehensive framework for
classifying robot morphology. Using a metamodeling approach, MetaMorph was
synthesized from 222 robots in the IEEE Robots Guide, offering a structured
method for comparing visual features. This model allows researchers to assess
the visual distances between robot models and explore optimal design traits
tailored to different tasks and contexts.

</details>


### [154] [Equivariant Volumetric Grasping](https://arxiv.org/abs/2507.18847)
*Pinhao Song,Yutong Hu,Pengteng Li,Renaud Detry*

Main category: cs.RO

TL;DR: 提出一种等变旋转的三平面抓取模型，显著提升样本效率和性能，同时降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 提高样本效率，通过等变旋转设计改善抓取模型的性能。

Method: 采用三平面体积特征表示和新型可变形可转向卷积，结合GIGA和IGD的等变适应，提出基于流匹配的等变抓取方向生成模型。

Result: 模型在模拟和真实实验中表现优异，计算和内存成本显著降低。

Conclusion: 提出的基于三平面特征的等变抓取模型在计算和内存成本上显著降低，同时在性能上优于非等变模型，仅需适度的计算开销。

Abstract: We propose a new volumetric grasp model that is equivariant to rotations
around the vertical axis, leading to a significant improvement in sample
efficiency. Our model employs a tri-plane volumetric feature representation --
i.e., the projection of 3D features onto three canonical planes. We introduce a
novel tri-plane feature design in which features on the horizontal plane are
equivariant to 90{\deg} rotations, while the sum of features from the other two
planes remains invariant to the same transformations. This design is enabled by
a new deformable steerable convolution, which combines the adaptability of
deformable convolutions with the rotational equivariance of steerable ones.
This allows the receptive field to adapt to local object geometry while
preserving equivariance properties. We further develop equivariant adaptations
of two state-of-the-art volumetric grasp planners, GIGA and IGD. Specifically,
we derive a new equivariant formulation of IGD's deformable attention mechanism
and propose an equivariant generative model of grasp orientations based on flow
matching. We provide a detailed analytical justification of the proposed
equivariance properties and validate our approach through extensive simulated
and real-world experiments. Our results demonstrate that the proposed
projection-based design significantly reduces both computational and memory
costs. Moreover, the equivariant grasp models built on top of our tri-plane
features consistently outperform their non-equivariant counterparts, achieving
higher performance with only a modest computational overhead. Video and code
can be viewed in: https://mousecpn.github.io/evg-page/

</details>


### [155] [A Fast and Light-weight Non-Iterative Visual Odometry with RGB-D Cameras](https://arxiv.org/abs/2507.18886)
*Zheng Yang,Kuan Xu,Shenghai Yuan,Lihua Xie*

Main category: cs.RO

TL;DR: 提出了一种非迭代的6自由度位姿估计方法，通过分离旋转和平移估计，显著提升了计算效率，尤其在低纹理环境中效果更佳。


<details>
  <summary>Details</summary>
Motivation: 传统RGB-D视觉里程计（RGBD-VO）依赖迭代优化和特征匹配，计算负担大且耗时。为了解决这一问题，作者提出了一种更高效的方法。

Method: 利用场景中的重叠平面特征计算旋转矩阵，随后通过核互相关器（KCC）确定平移，避免了传统迭代优化和特征提取的耗时过程。

Result: 该方法在低端i5 CPU上实现了71Hz的性能，且在低纹理退化环境中表现优于现有技术。

Conclusion: 该论文提出了一种解耦、非迭代的6自由度机器人位姿估计方法，通过分离旋转和平移的估计，显著提高了计算效率，尤其在低纹理退化环境中表现优于现有技术。

Abstract: In this paper, we introduce a novel approach for efficiently estimating the
6-Degree-of-Freedom (DoF) robot pose with a decoupled, non-iterative method
that capitalizes on overlapping planar elements. Conventional RGB-D visual
odometry(RGBD-VO) often relies on iterative optimization solvers to estimate
pose and involves a process of feature extraction and matching. This results in
significant computational burden and time delays. To address this, our
innovative method for RGBD-VO separates the estimation of rotation and
translation. Initially, we exploit the overlaid planar characteristics within
the scene to calculate the rotation matrix. Following this, we utilize a kernel
cross-correlator (KCC) to ascertain the translation. By sidestepping the
resource-intensive iterative optimization and feature extraction and alignment
procedures, our methodology offers improved computational efficacy, achieving a
performance of 71Hz on a lower-end i5 CPU. When the RGBD-VO does not rely on
feature points, our technique exhibits enhanced performance in low-texture
degenerative environments compared to state-of-the-art methods.

</details>


### [156] [GEAR: Gaze-Enabled Human-Robot Collaborative Assembly](https://arxiv.org/abs/2507.18947)
*Asad Ali Shahid,Angelo Moroncelli,Drazen Brscic,Takayuki Kanda,Loris Roveda*

Main category: cs.RO

TL;DR: GEAR系统利用视线交互提升人机协作效率，实验证明其在复杂组装任务中优于传统触摸屏界面，减少体力负担并改善用户体验。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人自主性和安全性有所提升，但复杂组装任务仍面临挑战，需要精确操作和应对任务多变性。本研究旨在探索机器人在辅助角色中的潜力，通过视线交互提升协作效率。

Method: 本研究引入了GEAR，一个基于视线交互的系统，用于增强人机协作。通过实验比较GEAR与传统触摸屏界面的效果，评估其在两种不同复杂度的组装任务中的表现。

Result: 实验结果表明，与触摸屏界面相比，GEAR在复杂任务中显著减少了操作者的体力需求和工作量，同时保持了高效的对象传递和组装性能，用户体验也得到提升。

Conclusion: GEAR系统通过视线交互显著提升了人机协作效率，尤其在复杂组装任务中减少了操作者的体力负担和努力，同时保持了良好的性能表现。

Abstract: Recent progress in robot autonomy and safety has significantly improved
human-robot interactions, enabling robots to work alongside humans on various
tasks. However, complex assembly tasks still present significant challenges due
to inherent task variability and the need for precise operations. This work
explores deploying robots in an assistive role for such tasks, where the robot
assists by fetching parts while the skilled worker provides high-level guidance
and performs the assembly. We introduce GEAR, a gaze-enabled system designed to
enhance human-robot collaboration by allowing robots to respond to the user's
gaze. We evaluate GEAR against a touch-based interface where users interact
with the robot through a touchscreen. The experimental study involved 30
participants working on two distinct assembly scenarios of varying complexity.
Results demonstrated that GEAR enabled participants to accomplish the assembly
with reduced physical demand and effort compared to the touchscreen interface,
especially for complex tasks, maintaining great performance, and receiving
objects effectively. Participants also reported enhanced user experience while
performing assembly tasks. Project page: sites.google.com/view/gear-hri

</details>


### [157] [Frequency Response Data-Driven Disturbance Observer Design for Flexible Joint Robots](https://arxiv.org/abs/2507.18979)
*Deokjin Lee,Junho Song,Alireza Karimi,Sehoon Oh*

Main category: cs.RO

TL;DR: 本文提出一种FRF-based优化方法，提升柔性关节机器人干扰观测器的性能，实验证明其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 柔性关节机器人（FJR）的运动控制受限于关节的固有柔性和系统动态的配置依赖性变化，传统干扰观测器（DOB）的性能因此受限。

Method: 采用FRF-based优化方法，最大化控制带宽并有效抑制振动，同时利用Nyquist稳定性准则严格证明了闭环稳定性。

Result: 实验验证表明，所提方法在关节柔性和系统变化的条件下，显著提升了系统的鲁棒性和运动性能。

Conclusion: 本文提出了一种基于频率响应函数（FRF）的优化方法，显著提高了柔性关节机器人（FJR）的干扰观测器（DOB）性能，增强了系统鲁棒性和运动性能。

Abstract: Motion control of flexible joint robots (FJR) is challenged by inherent
flexibility and configuration-dependent variations in system dynamics. While
disturbance observers (DOB) can enhance system robustness, their performance is
often limited by the elasticity of the joints and the variations in system
parameters, which leads to a conservative design of the DOB. This paper
presents a novel frequency response function (FRF)-based optimization method
aimed at improving DOB performance, even in the presence of flexibility and
system variability. The proposed method maximizes control bandwidth and
effectively suppresses vibrations, thus enhancing overall system performance.
Closed-loop stability is rigorously proven using the Nyquist stability
criterion. Experimental validation on a FJR demonstrates that the proposed
approach significantly improves robustness and motion performance, even under
conditions of joint flexibility and system variation.

</details>


### [158] [SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research](https://arxiv.org/abs/2507.19079)
*Feng Zhu,Zihang Zhang,Kangcheng Teng,Abduhelil Yakup,Xiaohong Zhang*

Main category: cs.RO

TL;DR: 本文提出SmartPNT数据集，整合多传感器数据并覆盖多样环境，解决了现有数据集的局限性，为高精度导航研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在传感器多样性和环境覆盖方面存在局限性，限制了高精度导航算法的测试与提升。

Method: 数据集整合了GNSS、IMU、光学相机和LiDAR等多种传感器数据，并详细记录了传感器配置、坐标系定义及标定流程。采用标准化数据采集与处理框架，确保一致性和可扩展性。

Result: 通过VINS-Mono和LIO-SAM等先进SLAM算法验证，数据集在复杂环境中表现出良好的适用性，覆盖城市、校园、隧道等多种场景。

Conclusion: 本文通过开发SmartPNT多源集成导航、定位和姿态数据集，解决了现有数据集在传感器多样性和环境覆盖方面的不足，为多传感器融合和高精度导航研究提供了丰富资源。

Abstract: High-precision navigation and positioning systems are critical for
applications in autonomous vehicles and mobile mapping, where robust and
continuous localization is essential. To test and enhance the performance of
algorithms, some research institutions and companies have successively
constructed and publicly released datasets. However, existing datasets still
suffer from limitations in sensor diversity and environmental coverage. To
address these shortcomings and advance development in related fields, the
SmartPNT Multisource Integrated Navigation, Positioning, and Attitude Dataset
has been developed. This dataset integrates data from multiple sensors,
including Global Navigation Satellite Systems (GNSS), Inertial Measurement
Units (IMU), optical cameras, and LiDAR, to provide a rich and versatile
resource for research in multi-sensor fusion and high-precision navigation. The
dataset construction process is thoroughly documented, encompassing sensor
configurations, coordinate system definitions, and calibration procedures for
both cameras and LiDAR. A standardized framework for data collection and
processing ensures consistency and scalability, enabling large-scale analysis.
Validation using state-of-the-art Simultaneous Localization and Mapping (SLAM)
algorithms, such as VINS-Mono and LIO-SAM, demonstrates the dataset's
applicability for advanced navigation research. Covering a wide range of
real-world scenarios, including urban areas, campuses, tunnels, and suburban
environments, the dataset offers a valuable tool for advancing navigation
technologies and addressing challenges in complex environments. By providing a
publicly accessible, high-quality dataset, this work aims to bridge gaps in
sensor diversity, data accessibility, and environmental representation,
fostering further innovation in the field.

</details>


### [159] [Bot Appétit! Exploring how Robot Morphology Shapes Perceived Affordances via a Mise en Place Scenario in a VR Kitchen](https://arxiv.org/abs/2507.19082)
*Rachel Ringe,Leandra Thiele,Mihai Pomarlan,Nima Zargham,Robin Nolte,Lars Hurrelbrink,Rainer Malaka*

Main category: cs.RO

TL;DR: 研究通过VR实验发现人类偏好生物形态机器人，感官能力信念受形态影响较小，与纤细机器人共享空间时回避策略较少。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人视觉设计的哪些因素会影响人类在协作烹饪场景中的空间布置和任务分配。

Method: 研究通过在虚拟现实（VR）环境中设置协作烹饪场景，收集了参与者布置厨房的多模态数据、思维口语记录及结构化问卷回答。

Result: 研究发现人类偏好与生物形态机器人合作，对机器人感官能力的信念受形态影响较小，且在与纤细机器人共享空间时采取更少的回避策略。

Conclusion: 本研究提出了几个假设，包括人类更倾向于与生物形态机器人合作，对机器人感官能力的信念受形态影响较小，以及在与纤细机器人共享空间时人类会采取更少的回避策略。这些假设将在后续研究中验证。

Abstract: This study explores which factors of the visual design of a robot may
influence how humans would place it in a collaborative cooking scenario and how
these features may influence task delegation. Human participants were placed in
a Virtual Reality (VR) environment and asked to set up a kitchen for cooking
alongside a robot companion while considering the robot's morphology. We
collected multimodal data for the arrangements created by the participants,
transcripts of their think-aloud as they were performing the task, and
transcripts of their answers to structured post-task questionnaires. Based on
analyzing this data, we formulate several hypotheses: humans prefer to
collaborate with biomorphic robots; human beliefs about the sensory
capabilities of robots are less influenced by the morphology of the robot than
beliefs about action capabilities; and humans will implement fewer avoidance
strategies when sharing space with gracile robots. We intend to verify these
hypotheses in follow-up studies.

</details>


### [160] [Monocular Vision-Based Swarm Robot Localization Using Equilateral Triangular Formations](https://arxiv.org/abs/2507.19100)
*Taewon Kang,Ji-Wook Kwon,Il Bae,Jin Hyo Kim*

Main category: cs.RO

TL;DR: 提出基于等边三角形编队的低成本单目视觉定位方法，适用于开放空间群机器人，定位误差显著优于传统航位推测。


<details>
  <summary>Details</summary>
Motivation: 为在完全开放空间（无地标或定位基础设施支持）中部署群机器人（如搜救任务）提供一种准确的定位系统。

Method: 利用等边三角形的几何特性，通过低成本单目视觉传感器获取机器人之间的一维横向距离信息，估计每个参与机器人的二维位置。

Result: 实验和仿真结果表明，该方法在长时间运行时的定位误差显著低于传统航位推测系统。

Conclusion: 该论文提出了一种基于等边三角形编队的定位方法，适用于仅配备低成本单目视觉传感器的群机器人，实验和仿真结果表明，随着运行时间的增加，该方法的定位误差显著小于传统的航位推测系统。

Abstract: Localization of mobile robots is crucial for deploying robots in real-world
applications such as search and rescue missions. This work aims to develop an
accurate localization system applicable to swarm robots equipped only with
low-cost monocular vision sensors and visual markers. The system is designed to
operate in fully open spaces, without landmarks or support from positioning
infrastructures. To achieve this, we propose a localization method based on
equilateral triangular formations. By leveraging the geometric properties of
equilateral triangles, the accurate two-dimensional position of each
participating robot is estimated using one-dimensional lateral distance
information between robots, which can be reliably and accurately obtained with
a low-cost monocular vision sensor. Experimental and simulation results
demonstrate that, as travel time increases, the positioning error of the
proposed method becomes significantly smaller than that of a conventional
dead-reckoning system, another low-cost localization approach applicable to
open environments.

</details>


### [161] [Diverse and Adaptive Behavior Curriculum for Autonomous Driving: A Student-Teacher Framework with Multi-Agent RL](https://arxiv.org/abs/2507.19146)
*Ahmed Abouelazm,Johannes Ratz,Philip Schörner,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 提出一种学生-教师框架，通过自适应课程学习提升自动驾驶代理在复杂交通中的表现，实验结果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习训练方法主要依赖基于规则的交通场景，缺乏对常规与关键行为的平衡覆盖，且课程学习多依赖人工设计，无法动态调整难度。

Method: 采用基于图的多智能体强化学习（RL）教师模型，自适应生成不同难度级别的交通行为，并结合深度RL学生模型进行训练。

Result: 实验结果表明，使用自动课程学习训练的学生代理在奖励和驾驶行为平衡性上均优于基于规则交通训练的代理。

Conclusion: 该研究提出的学生-教师框架通过自适应课程学习，显著提升了自动驾驶代理在复杂交通场景中的表现，实现了从常规到关键行为的平衡训练。

Abstract: Autonomous driving faces challenges in navigating complex real-world traffic,
requiring safe handling of both common and critical scenarios. Reinforcement
learning (RL), a prominent method in end-to-end driving, enables agents to
learn through trial and error in simulation. However, RL training often relies
on rule-based traffic scenarios, limiting generalization. Additionally, current
scenario generation methods focus heavily on critical scenarios, neglecting a
balance with routine driving behaviors. Curriculum learning, which
progressively trains agents on increasingly complex tasks, is a promising
approach to improving the robustness and coverage of RL driving policies.
However, existing research mainly emphasizes manually designed curricula,
focusing on scenery and actor placement rather than traffic behavior dynamics.
This work introduces a novel student-teacher framework for automatic curriculum
learning. The teacher, a graph-based multi-agent RL component, adaptively
generates traffic behaviors across diverse difficulty levels. An adaptive
mechanism adjusts task difficulty based on student performance, ensuring
exposure to behaviors ranging from common to critical. The student, though
exchangeable, is realized as a deep RL agent with partial observability,
reflecting real-world perception constraints. Results demonstrate the teacher's
ability to generate diverse traffic behaviors. The student, trained with
automatic curricula, outperformed agents trained on rule-based traffic,
achieving higher rewards and exhibiting balanced, assertive driving.

</details>


### [162] [ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination](https://arxiv.org/abs/2507.19151)
*Michael Amir,Guang Yang,Zhan Gao,Keisuke Okumura,Heedo Woo,Amanda Prorok*

Main category: cs.RO

TL;DR: ReCoDe结合优化控制器和强化学习，通过动态约束提升多智能体协调能力，优于纯人工设计和其他混合方法。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，人工设计的约束可能无法满足复杂协调需求，ReCoDe旨在通过强化学习补充这些约束。

Method: ReCoDe是一个分散式混合框架，通过局部通信学习动态约束，优化专家控制器。

Result: 在需要复杂、基于上下文的移动和共识的多智能体导航任务中，ReCoDe优于其他方法，并通过实验和理论验证了其有效性。

Conclusion: ReCoDe通过结合基于优化的控制器和多智能体强化学习，在复杂协调任务中表现出色，优于纯人工设计的控制器和其他混合方法。

Abstract: Constraint-based optimization is a cornerstone of robotics, enabling the
design of controllers that reliably encode task and safety requirements such as
collision avoidance or formation adherence. However, handcrafted constraints
can fail in multi-agent settings that demand complex coordination. We introduce
ReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid
framework that merges the reliability of optimization-based controllers with
the adaptability of multi-agent reinforcement learning. Rather than discarding
expert controllers, ReCoDe improves them by learning additional, dynamic
constraints that capture subtler behaviors, for example, by constraining agent
movements to prevent congestion in cluttered scenarios. Through local
communication, agents collectively constrain their allowed actions to
coordinate more effectively under changing conditions. In this work, we focus
on applications of ReCoDe to multi-agent navigation tasks requiring intricate,
context-based movements and consensus, where we show that it outperforms purely
handcrafted controllers, other hybrid approaches, and standard MARL baselines.
We give empirical (real robot) and theoretical evidence that retaining a
user-defined controller, even when it is imperfect, is more efficient than
learning from scratch, especially because ReCoDe can dynamically change the
degree to which it relies on this controller.

</details>


### [163] [Towards Multimodal Social Conversations with Robots: Using Vision-Language Models](https://arxiv.org/abs/2507.19196)
*Ruben Janssens,Tony Belpaeme*

Main category: cs.RO

TL;DR: 论文探讨了视觉语言模型如何使社交机器人具备多模态社交对话能力，并提出了技术挑战和评估方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然使社交机器人能够进行开放领域对话，但仍缺乏利用多模态信息的能力，这是社交互动的关键。

Method: 作者提出利用视觉语言模型来处理广泛的视觉信息，并描述了如何将这些模型适应于自主社交机器人的设置。

Result: 论文论证了视觉语言模型能够以足够通用的方式处理多模态社交对话中的视觉信息。

Conclusion: 论文强调了视觉语言模型在处理多模态社交对话中的潜力，并提出了适应社交机器人场景的技术挑战和评估方法。

Abstract: Large language models have given social robots the ability to autonomously
engage in open-domain conversations. However, they are still missing a
fundamental social skill: making use of the multiple modalities that carry
social interactions. While previous work has focused on task-oriented
interactions that require referencing the environment or specific phenomena in
social interactions such as dialogue breakdowns, we outline the overall needs
of a multimodal system for social conversations with robots. We then argue that
vision-language models are able to process this wide range of visual
information in a sufficiently general manner for autonomous social robots. We
describe how to adapt them to this setting, which technical challenges remain,
and briefly discuss evaluation practices.

</details>


### [164] [Foundation Model-Driven Grasping of Unknown Objects via Center of Gravity Estimation](https://arxiv.org/abs/2507.19242)
*Kang Xiangli,Yage He,Xianwu Gong,Zehan Liu,Yuru Bai*

Main category: cs.RO

TL;DR: 利用扩散模型定位物体重心，提升机器人抓取成功率，尤其在质量分布不均匀的物体上表现优异。


<details>
  <summary>Details</summary>
Motivation: 在机器人抓取中，CoG偏差常导致姿态不稳，而现有的基于关键点或功能驱动的方法存在局限性。

Method: 构建了一个包含790张图像的数据集，用于标注CoG关键点，并开发了一个基于基础模型的视觉驱动框架，实现CoG感知的抓取。

Result: 实验评估表明，该方法比传统基于关键点的方法成功率提高了49%，比最先进的功能驱动方法提高了11%，且在未见物体上具有76%的CoG定位准确率。

Conclusion: 该研究通过利用扩散模型定位未知物体的重心（CoG），提出了一种针对质量分布不均匀物体的抓取方法，为精确和稳定的抓取任务提供了新颖解决方案。

Abstract: This study presents a grasping method for objects with uneven mass
distribution by leveraging diffusion models to localize the center of gravity
(CoG) on unknown objects. In robotic grasping, CoG deviation often leads to
postural instability, where existing keypoint-based or affordance-driven
methods exhibit limitations. We constructed a dataset of 790 images featuring
unevenly distributed objects with keypoint annotations for CoG localization. A
vision-driven framework based on foundation models was developed to achieve
CoG-aware grasping. Experimental evaluations across real-world scenarios
demonstrate that our method achieves a 49\% higher success rate compared to
conventional keypoint-based approaches and an 11\% improvement over
state-of-the-art affordance-driven methods. The system exhibits strong
generalization with a 76\% CoG localization accuracy on unseen objects,
providing a novel solution for precise and stable grasping tasks.

</details>


### [165] [How Age Influences the Interpretation of Emotional Body Language in Humanoid Robots -- long paper version](https://arxiv.org/abs/2507.19335)
*Ilaria Consoli,Claudio Mattutino,Cristina Gena,Berardina de Carolis,Giuseppe Palestra*

Main category: cs.RO

TL;DR: 研究比较了不同年龄组对机器人NAO情感身体语言的理解，发现年轻和老年用户的理解相似，但与年轻成年人不同。


<details>
  <summary>Details</summary>
Motivation: 探讨用户如何感知和响应机器人代理的情感线索，评估机器人在向不同用户群体传达情感方面的有效性。

Method: 通过实证研究，收集了老年参与者的数据，并与之前收集的年轻成年人和儿童的数据进行比较分析。

Result: 年轻用户和老年用户对机器人情感身体语言的理解相似，但与年轻成年人不同。

Conclusion: 研究发现，不同年龄组对机器人NAO表达的情感身体语言的理解存在差异，年轻用户和老年用户的理解较为相似，但与年轻成年人不同。

Abstract: This paper presents an empirical study investigating how individuals across
different age groups, children, young and older adults, interpret emotional
body language expressed by the humanoid robot NAO. The aim is to offer insights
into how users perceive and respond to emotional cues from robotic agents,
through an empirical evaluation of the robot's effectiveness in conveying
emotions to different groups of users. By analyzing data collected from elderly
participants and comparing these findings with previously gathered data from
young adults and children, the study highlights similarities and differences
between the groups, with younger and older users more similar but different
from young adults.

</details>
