<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 89]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.NI](#cs.NI) [Total: 19]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.RO](#cs.RO) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Quality-Guided Mixture of Score-Fusion Experts Framework for Human Recognition](https://arxiv.org/abs/2508.00053)
*Jie Zhu,Yiyang Su,Minchul Kim,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: QME框架通过可学习的分数融合策略，显著提升了多模态全身生物特征识别的性能。


<details>
  <summary>Details</summary>
Motivation: 传统全身生物特征识别方法在处理多模态时忽视了分数分布的差异，限制了性能提升。

Method: 提出了一种新颖的QME框架，结合了Mixture of Experts (MoE)策略，引入了伪质量损失和质量估计器(QE)以及分数三元组损失。

Result: 在多个数据集上实现了最先进的性能，优于基线方法。

Conclusion: QME框架通过可学习的分数融合策略显著提升了全身生物特征识别的性能，解决了传统方法中分数分布差异和数据质量变化的挑战。

Abstract: Whole-body biometric recognition is a challenging multimodal task that
integrates various biometric modalities, including face, gait, and body. This
integration is essential for overcoming the limitations of unimodal systems.
Traditionally, whole-body recognition involves deploying different models to
process multiple modalities, achieving the final outcome by score-fusion (e.g.,
weighted averaging of similarity matrices from each model). However, these
conventional methods may overlook the variations in score distributions of
individual modalities, making it challenging to improve final performance. In
this work, we present \textbf{Q}uality-guided \textbf{M}ixture of score-fusion
\textbf{E}xperts (QME), a novel framework designed for improving whole-body
biometric recognition performance through a learnable score-fusion strategy
using a Mixture of Experts (MoE). We introduce a novel pseudo-quality loss for
quality estimation with a modality-specific Quality Estimator (QE), and a score
triplet loss to improve the metric performance. Extensive experiments on
multiple whole-body biometric datasets demonstrate the effectiveness of our
proposed approach, achieving state-of-the-art results across various metrics
compared to baseline methods. Our method is effective for multimodal and
multi-model, addressing key challenges such as model misalignment in the
similarity score domain and variability in data quality.

</details>


### [2] [Punching Bag vs. Punching Person: Motion Transferability in Videos](https://arxiv.org/abs/2508.00085)
*Raiyaan Abdullah,Jared Claypoole,Michael Cogswell,Ajay Divakaran,Yogesh Rawat*

Main category: cs.CV

TL;DR: 研究评估了动作识别模型在新情境下的迁移能力，发现模型在跨情境识别高级动作时表现显著下降，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 探索动作识别模型是否能将高级动作概念（如‘拳击’）有效迁移到多样化的情境中，即使是在相似分布内。

Method: 引入了一个运动迁移性框架，包括三个数据集（Syn-TA、Kinetics400-TA、Something-Something-v2-TA），评估了13种最先进的模型，并分析了模型在跨情境识别中的表现。

Result: 研究发现：1）多模态模型在细粒度未知动作上表现更差；2）无偏的Syn-TA数据集与真实数据集同样具有挑战性；3）大模型在空间线索主导时表现更好，但在时间推理密集时表现较差。此外，解耦粗粒度和细粒度动作可以提升识别效果。

Conclusion: 本研究为动作识别中的运动迁移性评估建立了一个重要基准，揭示了现有模型在新情境下识别高级动作时的局限性，并提出了改进方向。

Abstract: Action recognition models demonstrate strong generalization, but can they
effectively transfer high-level motion concepts across diverse contexts, even
within similar distributions? For example, can a model recognize the broad
action "punching" when presented with an unseen variation such as "punching
person"? To explore this, we introduce a motion transferability framework with
three datasets: (1) Syn-TA, a synthetic dataset with 3D object motions; (2)
Kinetics400-TA; and (3) Something-Something-v2-TA, both adapted from natural
video datasets. We evaluate 13 state-of-the-art models on these benchmarks and
observe a significant drop in performance when recognizing high-level actions
in novel contexts. Our analysis reveals: 1) Multimodal models struggle more
with fine-grained unknown actions than with coarse ones; 2) The bias-free
Syn-TA proves as challenging as real-world datasets, with models showing
greater performance drops in controlled settings; 3) Larger models improve
transferability when spatial cues dominate but struggle with intensive temporal
reasoning, while reliance on object and background cues hinders generalization.
We further explore how disentangling coarse and fine motions can improve
recognition in temporally challenging datasets. We believe this study
establishes a crucial benchmark for assessing motion transferability in action
recognition. Datasets and relevant code:
https://github.com/raiyaan-abdullah/Motion-Transfer.

</details>


### [3] [The Monado SLAM Dataset for Egocentric Visual-Inertial Tracking](https://arxiv.org/abs/2508.00088)
*Mateo de Mayo,Daniel Cremers,Taihú Pire*

Main category: cs.CV

TL;DR: 论文提出Monado SLAM数据集，解决头戴设备使用场景中VIO/SLAM系统的挑战，推动相关技术发展。


<details>
  <summary>Details</summary>
Motivation: 现有视觉惯性里程计（VIO）和同步定位与地图构建（SLAM）系统在头戴设备使用场景中面临诸多挑战，如高强度运动、动态遮挡等，而现有数据集未能充分覆盖这些场景。

Method: 提出了Monado SLAM数据集，包含来自多个虚拟现实头戴设备的真实序列，并以CC BY 4.0许可发布。

Result: Monado SLAM数据集的发布填补了现有数据集的不足，为VIO/SLAM研究提供了更全面的测试环境。

Conclusion: 该论文通过发布Monado SLAM数据集，旨在推动VIO/SLAM技术的发展，解决现有数据集在头戴设备使用场景中的不足。

Abstract: Humanoid robots and mixed reality headsets benefit from the use of
head-mounted sensors for tracking. While advancements in visual-inertial
odometry (VIO) and simultaneous localization and mapping (SLAM) have produced
new and high-quality state-of-the-art tracking systems, we show that these are
still unable to gracefully handle many of the challenging settings presented in
the head-mounted use cases. Common scenarios like high-intensity motions,
dynamic occlusions, long tracking sessions, low-textured areas, adverse
lighting conditions, saturation of sensors, to name a few, continue to be
covered poorly by existing datasets in the literature. In this way, systems may
inadvertently overlook these essential real-world issues. To address this, we
present the Monado SLAM dataset, a set of real sequences taken from multiple
virtual reality headsets. We release the dataset under a permissive CC BY 4.0
license, to drive advancements in VIO/SLAM research and development.

</details>


### [4] [Exploring the Feasibility of Deep Learning Techniques for Accurate Gender Classification from Eye Images](https://arxiv.org/abs/2508.00135)
*Basna Mohammed Salih Hasan,Ramadhan J. Mstafa*

Main category: cs.CV

TL;DR: 该论文提出了一种基于眼周区域彩色图像的CNN模型，用于性别分类，在两大数据集上分别达到99%和96%的高准确率，适用于安全和监控等领域。


<details>
  <summary>Details</summary>
Motivation: 性别分类在安全、人机交互、监控和广告等领域至关重要，但化妆品和伪装等因素可能影响分类准确性。因此，研究专注于利用眼周区域的彩色图像进行性别分类。

Method: 采用了一种复杂的卷积神经网络（CNN）模型，利用眼周区域的彩色图像数据库进行性别分类。

Result: 模型在CVBL数据集上达到99%的准确率，在Female and Male数据集上达到96%的准确率，且参数量较少（7,235,089）。

Conclusion: 该研究提出的CNN模型在基于眼周区域的性别分类中表现出色，准确率高达99%（CVBL数据集）和96%（Female and Male数据集），展示了其在安全和监控等领域的实际应用潜力。

Abstract: Gender classification has emerged as a crucial aspect in various fields,
including security, human-machine interaction, surveillance, and advertising.
Nonetheless, the accuracy of this classification can be influenced by factors
such as cosmetics and disguise. Consequently, our study is dedicated to
addressing this concern by concentrating on gender classification using color
images of the periocular region. The periocular region refers to the area
surrounding the eye, including the eyelids, eyebrows, and the region between
them. It contains valuable visual cues that can be used to extract key features
for gender classification. This paper introduces a sophisticated Convolutional
Neural Network (CNN) model that utilizes color image databases to evaluate the
effectiveness of the periocular region for gender classification. To validate
the model's performance, we conducted tests on two eye datasets, namely CVBL
and (Female and Male). The recommended architecture achieved an outstanding
accuracy of 99% on the previously unused CVBL dataset while attaining a
commendable accuracy of 96% with a small number of learnable parameters
(7,235,089) on the (Female and Male) dataset. To ascertain the effectiveness of
our proposed model for gender classification using the periocular region, we
evaluated its performance through an extensive range of metrics and compared it
with other state-of-the-art approaches. The results unequivocally demonstrate
the efficacy of our model, thereby suggesting its potential for practical
application in domains such as security and surveillance.

</details>


### [5] [World Consistency Score: A Unified Metric for Video Generation Quality](https://arxiv.org/abs/2508.00144)
*Akshat Rakheja,Aarsh Ashdhir,Aryan Bhattacharjee,Vanshika Sharma*

Main category: cs.CV

TL;DR: WCS 是一种新颖的视频生成模型评估指标，通过整合四个子组件（物体持久性等）并学习加权公式，全面评估时间连贯性，弥补现有指标的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频评估指标仅关注视觉保真度或提示对齐，缺乏对时间连贯性和物理一致性的评估，WCS 旨在填补这一空白。

Method: WCS 整合了四个可解释的子组件（物体持久性、关系稳定性、因果合规性和闪烁惩罚），并通过学习的加权公式生成一个与人类判断一致的一致性分数。

Result: WCS 通过实验验证（如 VBench-2.0、EvalCrafter 和 LOVE）展示了其与人类评估的相关性，并在敏感度分析和与现有指标（FVD、CLIPScore、VBench、FVMD）的比较中表现优异。

Conclusion: WCS 提供了一个全面且可解释的框架，用于评估视频生成模型在维持时间连贯性方面的能力，弥补了现有指标在视觉保真度或提示对齐方面的不足。

Abstract: We introduce World Consistency Score (WCS), a novel unified evaluation metric
for generative video models that emphasizes internal world consistency of the
generated videos. WCS integrates four interpretable sub-components - object
permanence, relation stability, causal compliance, and flicker penalty - each
measuring a distinct aspect of temporal and physical coherence in a video.
These submetrics are combined via a learned weighted formula to produce a
single consistency score that aligns with human judgments. We detail the
motivation for WCS in the context of existing video evaluation metrics,
formalize each submetric and how it is computed with open-source tools
(trackers, action recognizers, CLIP embeddings, optical flow), and describe how
the weights of the WCS combination are trained using human preference data. We
also outline an experimental validation blueprint: using benchmarks like
VBench-2.0, EvalCrafter, and LOVE to test WCS's correlation with human
evaluations, performing sensitivity analyses, and comparing WCS against
established metrics (FVD, CLIPScore, VBench, FVMD). The proposed WCS offers a
comprehensive and interpretable framework for evaluating video generation
models on their ability to maintain a coherent "world" over time, addressing
gaps left by prior metrics focused only on visual fidelity or prompt alignment.

</details>


### [6] [GeoExplorer: Active Geo-localization with Curiosity-Driven Exploration](https://arxiv.org/abs/2508.00152)
*Li Mi,Manon Bechaz,Zeming Chen,Antoine Bosselut,Devis Tuia*

Main category: cs.CV

TL;DR: GeoExplorer通过好奇心驱动探索提升主动地理定位的鲁棒性和泛化能力，实验证明其在多样环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于距离奖励的强化学习方法在距离估计困难或面对未见目标和环境时，由于探索策略不可靠，导致鲁棒性和泛化能力下降。

Method: 提出了一种名为GeoExplorer的AGL智能体，采用基于内在奖励的好奇心驱动探索策略，替代传统基于距离的奖励机制。

Result: 在四个AGL基准测试中，GeoExplorer展现出卓越的效果和泛化能力，尤其是在定位陌生目标和环境时。

Conclusion: GeoExplorer通过引入好奇心驱动的探索机制，显著提升了在主动地理定位任务中的鲁棒性和泛化能力，特别是在处理未见过的目标和环境时表现突出。

Abstract: Active Geo-localization (AGL) is the task of localizing a goal, represented
in various modalities (e.g., aerial images, ground-level images, or text),
within a predefined search area. Current methods approach AGL as a
goal-reaching reinforcement learning (RL) problem with a distance-based reward.
They localize the goal by implicitly learning to minimize the relative distance
from it. However, when distance estimation becomes challenging or when
encountering unseen targets and environments, the agent exhibits reduced
robustness and generalization ability due to the less reliable exploration
strategy learned during training. In this paper, we propose GeoExplorer, an AGL
agent that incorporates curiosity-driven exploration through intrinsic rewards.
Unlike distance-based rewards, our curiosity-driven reward is goal-agnostic,
enabling robust, diverse, and contextually relevant exploration based on
effective environment modeling. These capabilities have been proven through
extensive experiments across four AGL benchmarks, demonstrating the
effectiveness and generalization ability of GeoExplorer in diverse settings,
particularly in localizing unfamiliar targets and environments.

</details>


### [7] [Robust 3D Object Detection using Probabilistic Point Clouds from Single-Photon LiDARs](https://arxiv.org/abs/2508.00169)
*Bhavya Goyal,Felipe Gutierrez-Barragan,Wei Lin,Andreas Velten,Yin Li,Mohit Gupta*

Main category: cs.CV

TL;DR: PPC通过为点云添加概率属性封装测量不确定性，提升3D物体检测鲁棒性，在挑战性场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代LiDAR在远距离或低反射率物体等现实场景中产生稀疏或错误的点云，这些误差会传播到下游感知模型，导致准确性严重下降。传统3D处理流程在构建点云时未保留原始测量中的不确定性信息。

Method: 提出PPC表示方法，并为3D物体检测引入推理方法，这些方法可作为计算轻量级的模块集成到现有3D推理流程中。

Result: 通过仿真和实际捕获数据验证，PPC-based的3D推理方法在室内外挑战性场景（如小、远、低反射率物体及强环境光）中优于LiDAR及相机-LiDAR融合模型的多个基线方法。

Conclusion: PPC（概率点云）作为一种新型3D场景表示方法，通过为每个点添加概率属性来封装原始数据中的测量不确定性，显著提升了3D物体检测的鲁棒性。

Abstract: LiDAR-based 3D sensors provide point clouds, a canonical 3D representation
used in various scene understanding tasks. Modern LiDARs face key challenges in
several real-world scenarios, such as long-distance or low-albedo objects,
producing sparse or erroneous point clouds. These errors, which are rooted in
the noisy raw LiDAR measurements, get propagated to downstream perception
models, resulting in potentially severe loss of accuracy. This is because
conventional 3D processing pipelines do not retain any uncertainty information
from the raw measurements when constructing point clouds.
  We propose Probabilistic Point Clouds (PPC), a novel 3D scene representation
where each point is augmented with a probability attribute that encapsulates
the measurement uncertainty (or confidence) in the raw data. We further
introduce inference approaches that leverage PPC for robust 3D object
detection; these methods are versatile and can be used as computationally
lightweight drop-in modules in 3D inference pipelines. We demonstrate, via both
simulations and real captures, that PPC-based 3D inference methods outperform
several baselines using LiDAR as well as camera-LiDAR fusion models, across
challenging indoor and outdoor scenarios involving small, distant, and
low-albedo objects, as well as strong ambient light.
  Our project webpage is at https://bhavyagoyal.github.io/ppc .

</details>


### [8] [On the Risk of Misleading Reports: Diagnosing Textual Biases in Multimodal Clinical AI](https://arxiv.org/abs/2508.00171)
*David Restrepo,Ira Ktena,Maria Vakalopoulou,Stergios Christodoulidis,Enzo Ferrante*

Main category: cs.CV

TL;DR: 提出选择性模态转移（SMS）方法，揭示视觉语言模型在医学任务中对文本的过度依赖，强调需真正整合多模态信息。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在二元分类任务中可能表现出对某一模态的强烈偏见，常忽略关键的视觉线索而偏向文本信息。

Method: 引入选择性模态转移（SMS），一种基于扰动的量化方法，通过系统地在样本间交换图像或文本来揭示模态特定偏差。

Result: 评估了六个开源VLM模型，发现尽管存在互补的视觉信息，模型仍显著依赖文本输入。

Conclusion: 本研究强调了设计和评估真正整合视觉和文本线索的多模态医学模型的重要性，而不是依赖单一模态信号。

Abstract: Clinical decision-making relies on the integrated analysis of medical images
and the associated clinical reports. While Vision-Language Models (VLMs) can
offer a unified framework for such tasks, they can exhibit strong biases toward
one modality, frequently overlooking critical visual cues in favor of textual
information. In this work, we introduce Selective Modality Shifting (SMS), a
perturbation-based approach to quantify a model's reliance on each modality in
binary classification tasks. By systematically swapping images or text between
samples with opposing labels, we expose modality-specific biases. We assess six
open-source VLMs-four generalist models and two fine-tuned for medical data-on
two medical imaging datasets with distinct modalities: MIMIC-CXR (chest X-ray)
and FairVLMed (scanning laser ophthalmoscopy). By assessing model performance
and the calibration of every model in both unperturbed and perturbed settings,
we reveal a marked dependency on text input, which persists despite the
presence of complementary visual information. We also perform a qualitative
attention-based analysis which further confirms that image content is often
overshadowed by text details. Our findings highlight the importance of
designing and evaluating multimodal medical models that genuinely integrate
visual and textual cues, rather than relying on single-modality signals.

</details>


### [9] [Graph Lineages and Skeletal Graph Products](https://arxiv.org/abs/2508.00197)
*Eric Mjolsness,Cory B. Scott*

Main category: cs.CV

TL;DR: 本文提出了一种层次化增长的图结构理论，适用于定义模型架构和算法，并在深度学习和多网格方法中进行了应用。


<details>
  <summary>Details</summary>
Motivation: 为了在机器学习和计算科学等领域中指定数学模型的架构，需要一种能够层次化增长的图结构。

Method: 定义了结构化的图'lineages'，通过层次化增长方式，结合双分图和延长映射，推导出低成本的'骨架'变体标准代数图操作和类型构造器。

Result: 开发了空间高效的一元操作符（如增厚和升级）和骨架二元操作符，适用于分级图和层次图谱系，并展示了在深度神经网络和多网格数值方法中的应用。

Conclusion: 本文提出了一种代数类型理论，用于分级图和有层次结构的图谱系，适用于定义层次模型架构（'hierarchitectures'）及其上的局部采样、搜索或优化算法。

Abstract: Graphs, and sequences of growing graphs, can be used to specify the
architecture of mathematical models in many fields including machine learning
and computational science. Here we define structured graph "lineages" (ordered
by level number) that grow in a hierarchical fashion, so that: (1) the number
of graph vertices and edges increases exponentially in level number; (2)
bipartite graphs connect successive levels within a graph lineage and, as in
multigrid methods, can constrain matrices relating successive levels; (3) using
prolongation maps within a graph lineage, process-derived distance measures
between graphs at successive levels can be defined; (4) a category of "graded
graphs" can be defined, and using it low-cost "skeletal" variants of standard
algebraic graph operations and type constructors (cross product, box product,
disjoint sum, and function types) can be derived for graded graphs and hence
hierarchical graph lineages; (5) these skeletal binary operators have similar
but not identical algebraic and category-theoretic properties to their standard
counterparts; (6) graph lineages and their skeletal product constructors can
approach continuum limit objects. Additional space-efficient unary operators on
graded graphs are also derived: thickening, which creates a graph lineage of
multiscale graphs, and escalation to a graph lineage of search frontiers
(useful as a generalization of adaptive grids and in defining "skeletal"
functions). The result is an algebraic type theory for graded graphs and
(hierarchical) graph lineages. The approach is expected to be well suited to
defining hierarchical model architectures - "hierarchitectures" - and local
sampling, search, or optimization algorithms on them. We demonstrate such
application to deep neural networks (including visual and feature scale spaces)
and to multigrid numerical methods.

</details>


### [10] [Learning Personalised Human Internal Cognition from External Expressive Behaviours for Real Personality Recognition](https://arxiv.org/abs/2508.00205)
*Xiangyu Kong,Hengde Zhu,Haoqin Sun,Zhihao Guo,Jiayan Gu,Xinyi Ni,Wei Zhang,Shizhe Liu,Siyang Song*

Main category: cs.CV

TL;DR: 本文提出了一种基于2D-GNN的自动真实人格识别方法，通过模拟个性化内部认知来提升识别准确性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的人格识别解决方案通常作为外部观察者，基于目标个体的表达行为推断观察者的人格印象，这与真实人格存在显著偏差，导致识别性能不佳。本文受真实人格与人类内部认知之间的关联启发，提出了一种更准确的方法。

Method: 提出了一种基于2D图神经网络（2D-GNN）的方法，通过模拟目标个体的个性化内部认知，并将其编码为一个包含二维节点和边特征矩阵的新图结构，从而推断真实人格特质。采用端到端的策略联合训练认知模拟、2D图构建和人格识别模块。

Result: 提出的方法能够有效模拟个性化的内部认知，并通过2D-GNN从模拟的认知中推断真实人格特质，实验证明了其优越性。

Conclusion: 本文提出了一种新颖的自动真实人格识别（RPR）方法，通过模拟个性化的内部认知来提升人格识别的准确性。实验结果表明，该方法在识别真实人格特质方面优于现有解决方案。

Abstract: Automatic real personality recognition (RPR) aims to evaluate human real
personality traits from their expressive behaviours. However, most existing
solutions generally act as external observers to infer observers' personality
impressions based on target individuals' expressive behaviours, which
significantly deviate from their real personalities and consistently lead to
inferior recognition performance. Inspired by the association between real
personality and human internal cognition underlying the generation of
expressive behaviours, we propose a novel RPR approach that efficiently
simulates personalised internal cognition from easy-accessible external short
audio-visual behaviours expressed by the target individual. The simulated
personalised cognition, represented as a set of network weights that enforce
the personalised network to reproduce the individual-specific facial reactions,
is further encoded as a novel graph containing two-dimensional node and edge
feature matrices, with a novel 2D Graph Neural Network (2D-GNN) proposed for
inferring real personality traits from it. To simulate real personality-related
cognition, an end-to-end strategy is designed to jointly train our cognition
simulation, 2D graph construction, and personality recognition modules.

</details>


### [11] [SAM-PTx: Text-Guided Fine-Tuning of SAM with Parameter-Efficient, Parallel-Text Adapters](https://arxiv.org/abs/2508.00213)
*Shayan Jalilian,Abdul Bais*

Main category: cs.CV

TL;DR: SAM-PTx通过冻结CLIP文本嵌入作为语义指导，提出轻量级适配器Parallel-Text，提升SAM的语义引导分割性能。


<details>
  <summary>Details</summary>
Motivation: 探索语义文本提示在SAM中的潜力，相比传统的空间提示（如点和框）仍未充分开发。

Method: 提出了一种轻量级适配器设计Parallel-Text，将CLIP衍生的文本嵌入注入SAM的图像编码器，保留大部分原始架构冻结。

Result: 在COD10K数据集及COCO和ADE20K的低数据子集上，固定文本嵌入作为输入显著提升了分割性能。

Conclusion: 将语义条件集成到SAM架构中，为高效适应提供了实用且可扩展的路径，同时计算复杂度最低。

Abstract: The Segment Anything Model (SAM) has demonstrated impressive generalization
in prompt-based segmentation. Yet, the potential of semantic text prompts
remains underexplored compared to traditional spatial prompts like points and
boxes. This paper introduces SAM-PTx, a parameter-efficient approach for
adapting SAM using frozen CLIP-derived text embeddings as class-level semantic
guidance. Specifically, we propose a lightweight adapter design called
Parallel-Text that injects text embeddings into SAM's image encoder, enabling
semantics-guided segmentation while keeping most of the original architecture
frozen. Our adapter modifies only the MLP-parallel branch of each transformer
block, preserving the attention pathway for spatial reasoning. Through
supervised experiments and ablations on the COD10K dataset as well as low-data
subsets of COCO and ADE20K, we show that incorporating fixed text embeddings as
input improves segmentation performance over purely spatial prompt baselines.
To our knowledge, this is the first work to use text prompts for segmentation
on the COD10K dataset. These results suggest that integrating semantic
conditioning into SAM's architecture offers a practical and scalable path for
efficient adaptation with minimal computational complexity.

</details>


### [12] [Object-Centric Cropping for Visual Few-Shot Classification](https://arxiv.org/abs/2508.00218)
*Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon*

Main category: cs.CV

TL;DR: 通过引入物体局部位置信息及简单标注或无监督方法，Few-Shot图像分类性能显著提升。


<details>
  <summary>Details</summary>
Motivation: Few-Shot图像分类中，图像因多物体或复杂背景导致的模糊性会显著降低性能，需要更有效的解决方案。

Method: 利用Segment Anything Model（仅需标注目标物体的一个像素）或完全无监督的前景物体提取方法，结合物体局部位置信息。

Result: 在现有基准测试中，分类性能显著提升。

Conclusion: 在Few-Shot图像分类领域，通过引入物体局部位置信息，显著提升了分类性能，且使用Segment Anything Model或完全无监督的前景物体提取方法即可实现大部分改进。

Abstract: In the domain of Few-Shot Image Classification, operating with as little as
one example per class, the presence of image ambiguities stemming from multiple
objects or complex backgrounds can significantly deteriorate performance. Our
research demonstrates that incorporating additional information about the local
positioning of an object within its image markedly enhances classification
across established benchmarks. More importantly, we show that a significant
fraction of the improvement can be achieved through the use of the Segment
Anything Model, requiring only a pixel of the object of interest to be pointed
out, or by employing fully unsupervised foreground object extraction methods.

</details>


### [13] [Guided Depth Map Super-Resolution via Multi-Scale Fusion U-shaped Mamba Network](https://arxiv.org/abs/2508.00248)
*Chenggang Guo,Hao Xu,XianMing Wan*

Main category: cs.CV

TL;DR: 提出了一种多尺度融合U形Mamba模型（MSF-UM），通过结合卷积层和状态空间模型的优势，有效提升了深度图超分辨率的重建精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统卷积神经网络在处理长距离依赖和全局上下文信息建模方面存在局限性，而Transformer虽能建模全局依赖但计算复杂度和内存消耗高，限制了其处理高分辨率深度图的能力。

Method: 结合残差密集通道注意力块和Mamba状态空间模块的多尺度U形融合结构，融合了卷积层的局部特征提取能力和状态空间模型对长距离依赖的建模优势，并采用多尺度跨模态融合策略利用彩色图像的高频纹理信息指导深度图超分辨率过程。

Result: 与现有主流方法相比，MSF-UM模型在显著减少模型参数的同时实现了更好的重建精度。

Conclusion: 提出的MSF-UM模型在减少参数量的同时显著提升了重建精度，并在多个公开数据集上验证了其有效性，尤其在大规模深度图超分辨率任务中表现出优秀的泛化能力。

Abstract: Depth map super-resolution technology aims to improve the spatial resolution
of low-resolution depth maps and effectively restore high-frequency detail
information. Traditional convolutional neural network has limitations in
dealing with long-range dependencies and are unable to fully model the global
contextual information in depth maps. Although transformer can model global
dependencies, its computational complexity and memory consumption are
quadratic, which significantly limits its ability to process high-resolution
depth maps. In this paper, we propose a multi-scale fusion U-shaped Mamba
(MSF-UM) model, a novel guided depth map super-resolution framework. The core
innovation of this model is to integrate Mamba's efficient state-space modeling
capabilities into a multi-scale U-shaped fusion structure guided by a color
image. The structure combining the residual dense channel attention block and
the Mamba state space module is designed, which combines the local feature
extraction capability of the convolutional layer with the modeling advantage of
the state space model for long-distance dependencies. At the same time, the
model adopts a multi-scale cross-modal fusion strategy to make full use of the
high-frequency texture information from the color image to guide the
super-resolution process of the depth map. Compared with existing mainstream
methods, the proposed MSF-UM significantly reduces the number of model
parameters while achieving better reconstruction accuracy. Extensive
experiments on multiple publicly available datasets validate the effectiveness
of the model, especially showing excellent generalization ability in the task
of large-scale depth map super-resolution.

</details>


### [14] [PointGauss: Point Cloud-Guided Multi-Object Segmentation for Gaussian Splatting](https://arxiv.org/abs/2508.00259)
*Wentao Sun,Hanqing Xu,Quanyun Wu,Dedong Zhang,Yiping Chen,Lingfei Ma,John S. Zelek,Jonathan Li*

Main category: cs.CV

TL;DR: PointGauss 是一种实时多目标分割框架，通过点云引导和高斯泼溅表示提升分割效率与一致性，并引入新数据集 DesktopObjects-360 解决现有基准问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在初始化时间长、多视角一致性不足的问题，需要高效且一致的 3D 分割解决方案。

Method: 通过点云分割驱动的流水线直接解析高斯基元，包括点云高斯基元解码器和 GPU 加速的 2D 掩码渲染系统。

Result: 在多视角 mIoU 上实现了 1.89% 至 31.78% 的性能提升，并保持了较高的计算效率。

Conclusion: PointGauss 提出了一种基于点云引导的高斯泼溅表示实时多目标分割框架，显著提升了多视角一致性和计算效率，并通过新数据集 DesktopObjects-360 解决了当前基准的局限性。

Abstract: We introduce PointGauss, a novel point cloud-guided framework for real-time
multi-object segmentation in Gaussian Splatting representations. Unlike
existing methods that suffer from prolonged initialization and limited
multi-view consistency, our approach achieves efficient 3D segmentation by
directly parsing Gaussian primitives through a point cloud segmentation-driven
pipeline. The key innovation lies in two aspects: (1) a point cloud-based
Gaussian primitive decoder that generates 3D instance masks within 1 minute,
and (2) a GPU-accelerated 2D mask rendering system that ensures multi-view
consistency. Extensive experiments demonstrate significant improvements over
previous state-of-the-art methods, achieving performance gains of 1.89 to
31.78% in multi-view mIoU, while maintaining superior computational efficiency.
To address the limitations of current benchmarks (single-object focus,
inconsistent 3D evaluation, small scale, and partial coverage), we present
DesktopObjects-360, a novel comprehensive dataset for 3D segmentation in
radiance fields, featuring: (1) complex multi-object scenes, (2) globally
consistent 2D annotations, (3) large-scale training data (over 27 thousand 2D
masks), (4) full 360{\deg} coverage, and (5) 3D evaluation masks.

</details>


### [15] [Instruction-Grounded Visual Projectors for Continual Learning of Generative Vision-Language Models](https://arxiv.org/abs/2508.00260)
*Hyundong Jin,Hyung Jin Chang,Eunwoo Kim*

Main category: cs.CV

TL;DR: 新框架通过混合视觉投影器和专家策略，解决了持续学习中语言指令被忽视的问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在持续学习中倾向于忽视语言指令，特别是在处理重复类型文本指令的任务时，导致模型过于依赖视觉输入。

Method: 引入了一种混合视觉投影器框架，每个投影器作为基于指令上下文的视觉到语言的翻译专家，并采用专家推荐策略和专家剪枝来优化任务适应性和减少干扰。

Result: 在多样化视觉语言任务上的实验表明，该方法在生成遵循指令的响应方面优于现有持续学习方法。

Conclusion: 提出的新框架通过视觉投影器混合和专家推荐策略，有效解决了持续学习中语言指令被忽视的问题，并在多样化视觉语言任务中表现出色。

Abstract: Continual learning enables pre-trained generative vision-language models
(VLMs) to incorporate knowledge from new tasks without retraining data from
previous ones. Recent methods update a visual projector to translate visual
information for new tasks, connecting pre-trained vision encoders with large
language models. However, such adjustments may cause the models to prioritize
visual inputs over language instructions, particularly learning tasks with
repetitive types of textual instructions. To address the neglect of language
instructions, we propose a novel framework that grounds the translation of
visual information on instructions for language models. We introduce a mixture
of visual projectors, each serving as a specialized visual-to-language
translation expert based on the given instruction context to adapt to new
tasks. To avoid using experts for irrelevant instruction contexts, we propose
an expert recommendation strategy that reuses experts for tasks similar to
those previously learned. Additionally, we introduce expert pruning to
alleviate interference from the use of experts that cumulatively activated in
previous tasks. Extensive experiments on diverse vision-language tasks
demonstrate that our method outperforms existing continual learning approaches
by generating instruction-following responses.

</details>


### [16] [Controllable Pedestrian Video Editing for Multi-View Driving Scenarios via Motion Sequence](https://arxiv.org/abs/2508.00299)
*Danzhen Fu,Jiagao Hu,Daiguo Zhou,Fei Wang,Zepeng Wang,Wenhua Liao*

Main category: cs.CV

TL;DR: 提出了一种多视角行人视频编辑框架，结合视频修复和运动控制技术，有效增强自动驾驶数据集的多样性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统中行人检测模型因训练数据集中危险行人场景表示不足而缺乏鲁棒性的问题。

Method: 首先识别多摄像头视角中的行人感兴趣区域，扩展检测边界框并以固定比例调整大小，随后将这些区域拼接成统一画布。应用二进制掩码指定可编辑区域，并通过姿势序列控制条件指导行人编辑。

Result: 实验证明，该框架能够实现高质量的行人编辑，具有强视觉真实感、时空连贯性和跨视角一致性。

Conclusion: 提出的框架通过视频修复和人体运动控制技术，实现了多视角驾驶场景中可控的行人视频编辑，为自动驾驶领域的数据增强和场景模拟提供了强大工具。

Abstract: Pedestrian detection models in autonomous driving systems often lack
robustness due to insufficient representation of dangerous pedestrian scenarios
in training datasets. To address this limitation, we present a novel framework
for controllable pedestrian video editing in multi-view driving scenarios by
integrating video inpainting and human motion control techniques. Our approach
begins by identifying pedestrian regions of interest across multiple camera
views, expanding detection bounding boxes with a fixed ratio, and resizing and
stitching these regions into a unified canvas while preserving cross-view
spatial relationships. A binary mask is then applied to designate the editable
area, within which pedestrian editing is guided by pose sequence control
conditions. This enables flexible editing functionalities, including pedestrian
insertion, replacement, and removal. Extensive experiments demonstrate that our
framework achieves high-quality pedestrian editing with strong visual realism,
spatiotemporal coherence, and cross-view consistency. These results establish
the proposed method as a robust and versatile solution for multi-view
pedestrian video generation, with broad potential for applications in data
augmentation and scenario simulation in autonomous driving.

</details>


### [17] [Multimodal Referring Segmentation: A Survey](https://arxiv.org/abs/2508.00265)
*Henghui Ding,Song Tang,Shuting He,Chang Liu,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 本文综述了多模态指代分割的背景、方法、应用及挑战，总结了代表性方法并提供了性能比较。


<details>
  <summary>Details</summary>
Motivation: 多模态指代分割在基于用户指令的精确对象感知应用中至关重要，近年来因卷积神经网络、Transformer和大语言模型的进步而受到广泛关注。

Method: 介绍了统一的元架构，并回顾了图像、视频和3D场景中的代表性方法，讨论了广义指代表达（GREx）方法。

Result: 提供了标准基准上的广泛性能比较，并讨论了实际应用中的挑战和解决方案。

Conclusion: 本文提供了多模态指代分割的全面综述，总结了该领域的背景、方法、挑战及未来方向，并持续跟踪相关研究进展。

Abstract: Multimodal referring segmentation aims to segment target objects in visual
scenes, such as images, videos, and 3D scenes, based on referring expressions
in text or audio format. This task plays a crucial role in practical
applications requiring accurate object perception based on user instructions.
Over the past decade, it has gained significant attention in the multimodal
community, driven by advances in convolutional neural networks, transformers,
and large language models, all of which have substantially improved multimodal
perception capabilities. This paper provides a comprehensive survey of
multimodal referring segmentation. We begin by introducing this field's
background, including problem definitions and commonly used datasets. Next, we
summarize a unified meta architecture for referring segmentation and review
representative methods across three primary visual scenes, including images,
videos, and 3D scenes. We further discuss Generalized Referring Expression
(GREx) methods to address the challenges of real-world complexity, along with
related tasks and practical applications. Extensive performance comparisons on
standard benchmarks are also provided. We continually track related works at
https://github.com/henghuiding/Awesome-Multimodal-Referring-Segmentation.

</details>


### [18] [Reducing the gap between general purpose data and aerial images in concentrated solar power plants](https://arxiv.org/abs/2508.00440)
*M. A. Pérez-Cutiño,J. Valverde,J. Capitán,J. M. Díaz-Báñez*

Main category: cs.CV

TL;DR: 提出AerialCSP虚拟数据集，通过合成数据预训练模型，显著提升CSP电站缺陷检测效果，减少手动标注需求。


<details>
  <summary>Details</summary>
Motivation: CSP电站的航拍图像具有高反射面和领域特定元素，传统计算机视觉模型难以泛化，手动标注成本高且耗时长。

Method: 提出AerialCSP虚拟数据集，模拟CSP电站的航拍图像，用于预训练模型，减少手动标注需求。

Result: AerialCSP数据集为CSP相关视觉任务建立了基准，预训练显著提升了真实场景中的缺陷检测性能。

Conclusion: AerialCSP合成数据集显著提高了CSP电站的实时缺陷检测能力，尤其是对小而罕见的缺陷，减少了对手动标注数据的依赖。

Abstract: In the context of Concentrated Solar Power (CSP) plants, aerial images
captured by drones present a unique set of challenges. Unlike urban or natural
landscapes commonly found in existing datasets, solar fields contain highly
reflective surfaces, and domain-specific elements that are uncommon in
traditional computer vision benchmarks. As a result, machine learning models
trained on generic datasets struggle to generalize to this setting without
extensive retraining and large volumes of annotated data. However, collecting
and labeling such data is costly and time-consuming, making it impractical for
rapid deployment in industrial applications.
  To address this issue, we propose a novel approach: the creation of
AerialCSP, a virtual dataset that simulates aerial imagery of CSP plants. By
generating synthetic data that closely mimic real-world conditions, our
objective is to facilitate pretraining of models before deployment,
significantly reducing the need for extensive manual labeling. Our main
contributions are threefold: (1) we introduce AerialCSP, a high-quality
synthetic dataset for aerial inspection of CSP plants, providing annotated data
for object detection and image segmentation; (2) we benchmark multiple models
on AerialCSP, establishing a baseline for CSP-related vision tasks; and (3) we
demonstrate that pretraining on AerialCSP significantly improves real-world
fault detection, particularly for rare and small defects, reducing the need for
extensive manual labeling. AerialCSP is made publicly available at
https://mpcutino.github.io/aerialcsp/.

</details>


### [19] [Towards Robust Semantic Correspondence: A Benchmark and Insights](https://arxiv.org/abs/2508.00272)
*Wenyue Chong*

Main category: cs.CV

TL;DR: 本文建立了一个恶劣条件下的语义对应基准数据集，发现现有方法性能显著下降，大规模视觉模型（如DINO）和任务特定设计能提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有语义对应研究多集中在高质量可控条件下，而在恶劣场景下的鲁棒性研究较少。本文旨在填补这一空白，推动语义对应在复杂场景中的应用。

Method: 通过建立一个包含14种常见成像问题的基准数据集，评估语义对应方法在恶劣条件下的表现，并分析大规模视觉模型（如DINO和Stable Diffusion）及其融合的效果。

Result: 所有现有方法在恶劣条件下性能均显著下降。大规模视觉模型能提升整体鲁棒性，但微调会降低相对鲁棒性。DINO模型在相对鲁棒性上优于Stable Diffusion，融合两者可提升绝对鲁棒性。通用数据增强策略效果有限。

Conclusion: 研究表明，现有语义对应方法在恶劣条件下性能显著下降，大规模视觉模型虽能提升整体鲁棒性，但微调会降低相对鲁棒性。DINO模型在相对鲁棒性上优于Stable Diffusion，两者融合可提升绝对鲁棒性。此外，通用数据增强策略效果有限，需设计任务特定的增强方法。

Abstract: Semantic correspondence aims to identify semantically meaningful
relationships between different images and is a fundamental challenge in
computer vision. It forms the foundation for numerous tasks such as 3D
reconstruction, object tracking, and image editing. With the progress of
large-scale vision models, semantic correspondence has achieved remarkable
performance in controlled and high-quality conditions. However, the robustness
of semantic correspondence in challenging scenarios is much less investigated.
In this work, we establish a novel benchmark for evaluating semantic
correspondence in adverse conditions. The benchmark dataset comprises 14
distinct challenging scenarios that reflect commonly encountered imaging
issues, including geometric distortion, image blurring, digital artifacts, and
environmental occlusion. Through extensive evaluations, we provide several key
insights into the robustness of semantic correspondence approaches: (1) All
existing methods suffer from noticeable performance drops under adverse
conditions; (2) Using large-scale vision models can enhance overall robustness,
but fine-tuning on these models leads to a decline in relative robustness; (3)
The DINO model outperforms the Stable Diffusion in relative robustness, and
their fusion achieves better absolute robustness; Moreover, We evaluate common
robustness enhancement strategies for semantic correspondence and find that
general data augmentations are ineffective, highlighting the need for
task-specific designs. These results are consistent across both our dataset and
real-world benchmarks.

</details>


### [20] [Context-based Motion Retrieval using Open Vocabulary Methods for Autonomous Driving](https://arxiv.org/abs/2508.00589)
*Stefan Englmeier,Max A. Büttner,Katharina Winter,Fabian B. Flohr*

Main category: cs.CV

TL;DR: 提出了一种基于SMPL和视频帧的多模态嵌入空间方法，通过文本查询高效检索人类行为及其上下文，在WayMoCo数据集上表现优于现有最优模型27.5%。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统在安全关键场景中必须可靠运行，尤其是在涉及易受伤害道路使用者（VRUs）的异常或复杂行为时。从大规模数据集中检索这些罕见的人类行为场景具有挑战性，但对系统的鲁棒评估和泛化至关重要。

Method: 结合基于SMPL的运动序列和相应视频帧，将它们编码到与自然语言对齐的多模态嵌入空间，通过文本查询实现人类行为及其上下文的可扩展检索。

Result: 在WayMoCo数据集上的评估显示，该方法在运动上下文检索准确率上比现有最优模型提升了27.5%。

Conclusion: 论文提出的方法在WayMoCo数据集上比现有最优模型在运动上下文检索准确率上提升了27.5%，证明了其有效性。

Abstract: Autonomous driving systems must operate reliably in safety-critical
scenarios, particularly those involving unusual or complex behavior by
Vulnerable Road Users (VRUs). Identifying these edge cases in driving datasets
is essential for robust evaluation and generalization, but retrieving such rare
human behavior scenarios within the long tail of large-scale datasets is
challenging. To support targeted evaluation of autonomous driving systems in
diverse, human-centered scenarios, we propose a novel context-aware motion
retrieval framework. Our method combines Skinned Multi-Person Linear
(SMPL)-based motion sequences and corresponding video frames before encoding
them into a shared multimodal embedding space aligned with natural language.
Our approach enables the scalable retrieval of human behavior and their context
through text queries. This work also introduces our dataset WayMoCo, an
extension of the Waymo Open Dataset. It contains automatically labeled motion
and scene context descriptions derived from generated pseudo-ground-truth SMPL
sequences and corresponding image data. Our approach outperforms
state-of-the-art models by up to 27.5% accuracy in motion-context retrieval,
when evaluated on the WayMoCo dataset.

</details>


### [21] [Privacy-Preserving Driver Drowsiness Detection with Spatial Self-Attention and Federated Learning](https://arxiv.org/abs/2508.00287)
*Tran Viet Khoa,Do Hai Son,Mohammad Abu Alsheikh,Yibeltal F Alem,Dinh Thai Hoang*

Main category: cs.CV

TL;DR: 提出了一种结合SSA和LSTM的新框架，用于在分散数据中检测驾驶员 drowsiness，通过GSC支持联邦学习，实现了89.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 驾驶员 drowsiness 是道路事故的主要原因之一，但在现实环境中准确检测 drowsiness 仍具挑战性，尤其是面对分散且多样化的面部数据。

Method: 提出了一个新颖的框架，结合了新的空间自注意力（SSA）机制与长短期记忆（LSTM）网络，以更好地提取关键面部特征并提高检测性能。此外，采用梯度相似性比较（GSC）支持联邦学习，选择最相关的训练模型进行聚合。

Result: 实验结果表明，该框架在联邦学习设置下的检测准确率达到89.9%，优于现有方法。

Conclusion: 该框架在联邦学习设置下实现了89.9%的检测准确率，优于现有方法，展示了处理现实世界数据多样性的有效性，并突显了其在智能交通系统中部署的潜力，以通过早期可靠的 drowsiness 检测提升道路安全。

Abstract: Driver drowsiness is one of the main causes of road accidents and is
recognized as a leading contributor to traffic-related fatalities. However,
detecting drowsiness accurately remains a challenging task, especially in
real-world settings where facial data from different individuals is
decentralized and highly diverse. In this paper, we propose a novel framework
for drowsiness detection that is designed to work effectively with
heterogeneous and decentralized data. Our approach develops a new Spatial
Self-Attention (SSA) mechanism integrated with a Long Short-Term Memory (LSTM)
network to better extract key facial features and improve detection
performance. To support federated learning, we employ a Gradient Similarity
Comparison (GSC) that selects the most relevant trained models from different
operators before aggregation. This improves the accuracy and robustness of the
global model while preserving user privacy. We also develop a customized tool
that automatically processes video data by extracting frames, detecting and
cropping faces, and applying data augmentation techniques such as rotation,
flipping, brightness adjustment, and zooming. Experimental results show that
our framework achieves a detection accuracy of 89.9% in the federated learning
settings, outperforming existing methods under various deployment scenarios.
The results demonstrate the effectiveness of our approach in handling
real-world data variability and highlight its potential for deployment in
intelligent transportation systems to enhance road safety through early and
reliable drowsiness detection.

</details>


### [22] [IGL-Nav: Incremental 3D Gaussian Localization for Image-goal Navigation](https://arxiv.org/abs/2508.00823)
*Wenxuan Guo,Xiuwei Xu,Hang Yin,Ziwei Wang,Jianjiang Feng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: IGL-Nav通过增量式3D高斯定位和分层策略，高效解决了图像目标导航中的几何关系建模和定位效率问题，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法充分建模探索的3D环境与目标图像之间的几何关系，且3DGS优化和6-DoF相机姿态搜索空间大导致效率低下。

Method: 提出了IGL-Nav框架，通过增量式3D高斯定位和分层定位策略（粗定位与细定位结合），结合可微分渲染优化目标姿态。

Result: IGL-Nav在效率和3D感知方面表现出色，支持自由视角图像目标导航，并能在现实世界中部署。

Conclusion: IGL-Nav框架在多样化的实验配置中显著优于现有最先进方法，并能处理更具挑战性的自由视角图像目标导航任务，同时适用于现实世界机器人平台。

Abstract: Visual navigation with an image as goal is a fundamental and challenging
problem. Conventional methods either rely on end-to-end RL learning or
modular-based policy with topological graph or BEV map as memory, which cannot
fully model the geometric relationship between the explored 3D environment and
the goal image. In order to efficiently and accurately localize the goal image
in 3D space, we build our navigation system upon the renderable 3D gaussian
(3DGS) representation. However, due to the computational intensity of 3DGS
optimization and the large search space of 6-DoF camera pose, directly
leveraging 3DGS for image localization during agent exploration process is
prohibitively inefficient. To this end, we propose IGL-Nav, an Incremental 3D
Gaussian Localization framework for efficient and 3D-aware image-goal
navigation. Specifically, we incrementally update the scene representation as
new images arrive with feed-forward monocular prediction. Then we coarsely
localize the goal by leveraging the geometric information for discrete space
matching, which can be equivalent to efficient 3D convolution. When the agent
is close to the goal, we finally solve the fine target pose with optimization
via differentiable rendering. The proposed IGL-Nav outperforms existing
state-of-the-art methods by a large margin across diverse experimental
configurations. It can also handle the more challenging free-view image-goal
setting and be deployed on real-world robotic platform using a cellphone to
capture goal image at arbitrary pose. Project page:
https://gwxuan.github.io/IGL-Nav/.

</details>


### [23] [TITAN-Guide: Taming Inference-Time AligNment for Guided Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.00289)
*Christian Simon,Masato Ishii,Akio Hayakawa,Zhi Zhong,Shusuke Takahashi,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: TITAN-Guide 是一种无需微调的训练免费引导方法，通过优化扩散潜在表示显著降低内存需求并提升T2V性能。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费引导框架因内存需求高或控制效果不佳而限制了在计算密集型任务（如T2V扩散模型）中的应用。

Method: 开发了一种无需反向传播的扩散潜在优化方法，研究了前向梯度下降在引导扩散任务中的应用，并探索了多种方向性指令选项。

Result: 实验证明，TITAN-Guide 在潜在优化过程中高效管理内存，显著提升了T2V性能，并在多个扩散引导基准测试中表现优异。

Conclusion: TITAN-Guide 提出了一种高效的方法，无需通过判别性引导模型进行反向传播即可优化扩散潜在表示，显著降低了内存需求并提升了文本到视频（T2V）扩散模型的性能。

Abstract: In the recent development of conditional diffusion models still require heavy
supervised fine-tuning for performing control on a category of tasks.
Training-free conditioning via guidance with off-the-shelf models is a
favorable alternative to avoid further fine-tuning on the base model. However,
the existing training-free guidance frameworks either have heavy memory
requirements or offer sub-optimal control due to rough estimation. These
shortcomings limit the applicability to control diffusion models that require
intense computation, such as Text-to-Video (T2V) diffusion models. In this
work, we propose Taming Inference Time Alignment for Guided Text-to-Video
Diffusion Model, so-called TITAN-Guide, which overcomes memory space issues,
and provides more optimal control in the guidance process compared to the
counterparts. In particular, we develop an efficient method for optimizing
diffusion latents without backpropagation from a discriminative guiding model.
In particular, we study forward gradient descents for guided diffusion tasks
with various options on directional directives. In our experiments, we
demonstrate the effectiveness of our approach in efficiently managing memory
during latent optimization, while previous methods fall short. Our proposed
approach not only minimizes memory requirements but also significantly enhances
T2V performance across a range of diffusion guidance benchmarks. Code, models,
and demo are available at https://titanguide.github.io.

</details>


### [24] [AniMer+: Unified Pose and Shape Estimation Across Mammalia and Aves via Family-Aware Transformer](https://arxiv.org/abs/2508.00298)
*Jin Lyu,Liang An,Li Lin,Pujin Cheng,Yebin Liu,Xiaoying Tang*

Main category: cs.CV

TL;DR: AniMer+通过家族感知ViT和合成数据集，统一估计哺乳动物和鸟类的姿态与形状，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决因网络容量限制和多物种数据集稀缺导致的跨物种动物姿态与形状估计研究不足问题。

Method: AniMer+采用家族感知Vision Transformer（ViT）和Mixture-of-Experts（MoE）设计，将网络层分为特定类群和共享类群组件，并利用扩散模型生成大规模合成数据集（CtrlAni3D和CtrlAVES3D）。

Result: 在包含41.3k哺乳动物和12.4k鸟类图像的混合数据集上训练后，AniMer+在多个基准测试中表现优于现有方法，包括具有挑战性的Animal Kingdom数据集。

Conclusion: AniMer+通过高容量的家族感知ViT和MoE设计，结合合成数据集，显著提升了跨物种动物姿态和形状估计的性能，为生物研究提供了强大的定量分析工具。

Abstract: In the era of foundation models, achieving a unified understanding of
different dynamic objects through a single network has the potential to empower
stronger spatial intelligence. Moreover, accurate estimation of animal pose and
shape across diverse species is essential for quantitative analysis in
biological research. However, this topic remains underexplored due to the
limited network capacity of previous methods and the scarcity of comprehensive
multi-species datasets. To address these limitations, we introduce AniMer+, an
extended version of our scalable AniMer framework. In this paper, we focus on a
unified approach for reconstructing mammals (mammalia) and birds (aves). A key
innovation of AniMer+ is its high-capacity, family-aware Vision Transformer
(ViT) incorporating a Mixture-of-Experts (MoE) design. Its architecture
partitions network layers into taxa-specific components (for mammalia and aves)
and taxa-shared components, enabling efficient learning of both distinct and
common anatomical features within a single model. To overcome the critical
shortage of 3D training data, especially for birds, we introduce a
diffusion-based conditional image generation pipeline. This pipeline produces
two large-scale synthetic datasets: CtrlAni3D for quadrupeds and CtrlAVES3D for
birds. To note, CtrlAVES3D is the first large-scale, 3D-annotated dataset for
birds, which is crucial for resolving single-view depth ambiguities. Trained on
an aggregated collection of 41.3k mammalian and 12.4k avian images (combining
real and synthetic data), our method demonstrates superior performance over
existing approaches across a wide range of benchmarks, including the
challenging out-of-domain Animal Kingdom dataset. Ablation studies confirm the
effectiveness of both our novel network architecture and the generated
synthetic datasets in enhancing real-world application performance.

</details>


### [25] [Exploring Fourier Prior and Event Collaboration for Low-Light Image Enhancement](https://arxiv.org/abs/2508.00308)
*Chunyan She,Fujun Han,Chengyu Fang,Shukai Duan,Lidan Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种两阶段低光图像增强方法，通过解耦可见性恢复和结构细化，结合动态对齐和对比学习，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的事件增强方法未能充分利用模态特异性优势，限制了性能提升。因此，通过分析每种传感模态的作用，将增强流程解耦为两个阶段：可见性恢复和结构细化。

Method: 1. 设计了一个基于振幅-相位纠缠的可见性恢复网络。2. 提出了一个动态对齐的融合策略以减少两种传感模态之间的空间不匹配问题。3. 利用空间-频率插值模拟多样化的负样本，开发了对比损失函数以增强模型的判别性表示学习。

Result: 该方法在低光图像增强任务中表现出色，超越了现有最先进模型的性能。

Conclusion: 实验证明，所提出的方法在性能上超越了现有的最先进模型。

Abstract: The event camera, benefiting from its high dynamic range and low latency,
provides performance gain for low-light image enhancement. Unlike frame-based
cameras, it records intensity changes with extremely high temporal resolution,
capturing sufficient structure information. Currently, existing event-based
methods feed a frame and events directly into a single model without fully
exploiting modality-specific advantages, which limits their performance.
Therefore, by analyzing the role of each sensing modality, the enhancement
pipeline is decoupled into two stages: visibility restoration and structure
refinement. In the first stage, we design a visibility restoration network with
amplitude-phase entanglement by rethinking the relationship between amplitude
and phase components in Fourier space. In the second stage, a fusion strategy
with dynamic alignment is proposed to mitigate the spatial mismatch caused by
the temporal resolution discrepancy between two sensing modalities, aiming to
refine the structure information of the image enhanced by the visibility
restoration network. In addition, we utilize spatial-frequency interpolation to
simulate negative samples with diverse illumination, noise and artifact
degradations, thereby developing a contrastive loss that encourages the model
to learn discriminative representations. Experiments demonstrate that the
proposed method outperforms state-of-the-art models.

</details>


### [26] [DocTron-Formula: Generalized Formula Recognition in Complex and Structured Scenarios](https://arxiv.org/abs/2508.00311)
*Yufeng Zhong,Zhixiong Zeng,Lei Chen,Longrong Yang,Liming Zheng,Jing Huang,Siqi Yang,Lin Ma*

Main category: cs.CV

TL;DR: DocTron-Formula通过通用视觉语言模型和CSFormula数据集，实现了数学公式OCR的最先进性能，超越了专用模型。


<details>
  <summary>Details</summary>
Motivation: 数学公式OCR对于科学文献的智能分析至关重要，但现有任务专用和通用视觉语言模型难以处理数学内容的结构多样性、复杂性和现实变异性。

Method: 提出了DocTron-Formula，一个基于通用视觉语言模型的统一框架，无需专用架构。同时引入了CSFormula数据集，涵盖多学科和结构复杂的公式。

Result: 实验结果表明，该方法不仅在准确性和鲁棒性上超越了专用模型，还为复杂科学文档的自动理解树立了新标杆。

Conclusion: DocTron-Formula通过简单的监督微调，在多种风格、科学领域和复杂布局中实现了最先进的性能，为复杂科学文档的自动理解建立了新范式。

Abstract: Optical Character Recognition (OCR) for mathematical formula is essential for
the intelligent analysis of scientific literature. However, both task-specific
and general vision-language models often struggle to handle the structural
diversity, complexity, and real-world variability inherent in mathematical
content. In this work, we present DocTron-Formula, a unified framework built
upon general vision-language models, thereby eliminating the need for
specialized architectures. Furthermore, we introduce CSFormula, a large-scale
and challenging dataset that encompasses multidisciplinary and structurally
complex formulas at the line, paragraph, and page levels. Through
straightforward supervised fine-tuning, our approach achieves state-of-the-art
performance across a variety of styles, scientific domains, and complex
layouts. Experimental results demonstrate that our method not only surpasses
specialized models in terms of accuracy and robustness, but also establishes a
new paradigm for the automated understanding of complex scientific documents.

</details>


### [27] [GV-VAD : Exploring Video Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2508.00312)
*Suhang Cai,Xiaohao Peng,Chong Wang,Xiaojie Cai,Jiangbo Qian*

Main category: cs.CV

TL;DR: GV-VAD利用生成合成视频增强训练数据，提升视频异常检测性能，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决真实异常数据稀缺、不可预测且标注成本高的问题，提升视频异常检测模型的性能和泛化能力。

Method: 提出了一种基于文本条件视频生成模型的弱监督视频异常检测框架（GV-VAD），利用合成视频低成本扩充训练数据，并采用合成样本损失缩放策略优化训练。

Result: 在UCF-Crime数据集上表现优于现有最先进方法。

Conclusion: GV-VAD框架通过生成合成视频增强训练数据，显著提升了视频异常检测的性能，并在UCF-Crime数据集上超越了现有方法。

Abstract: Video anomaly detection (VAD) plays a critical role in public safety
applications such as intelligent surveillance. However, the rarity,
unpredictability, and high annotation cost of real-world anomalies make it
difficult to scale VAD datasets, which limits the performance and
generalization ability of existing models. To address this challenge, we
propose a generative video-enhanced weakly-supervised video anomaly detection
(GV-VAD) framework that leverages text-conditioned video generation models to
produce semantically controllable and physically plausible synthetic videos.
These virtual videos are used to augment training data at low cost. In
addition, a synthetic sample loss scaling strategy is utilized to control the
influence of generated synthetic samples for efficient training. The
experiments show that the proposed framework outperforms state-of-the-art
methods on UCF-Crime datasets. The code is available at
https://github.com/Sumutan/GV-VAD.git.

</details>


### [28] [Steering Guidance for Personalized Text-to-Image Diffusion Models](https://arxiv.org/abs/2508.00319)
*Sunghyun Park,Seokeon Choi,Hyoungwoo Park,Sungrack Yun*

Main category: cs.CV

TL;DR: 提出个性化引导方法，动态控制弱模型学习程度，平衡目标分布对齐与文本可编辑性，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决现有采样引导方法（如CFG和AG）在目标分布对齐和文本可编辑性之间的权衡不足问题。

Method: 提出了一种基于未学习弱模型的个性化引导方法，通过权重插值动态控制未学习程度，无需额外计算开销。

Result: 实验结果表明，该方法能提升文本对齐和目标分布保真度，且与多种微调策略兼容。

Conclusion: 本文提出的个性化引导方法有效解决了文本到图像扩散模型在少样本微调中的权衡问题，通过动态控制弱模型的学习程度，实现了目标分布对齐与文本可编辑性的平衡。

Abstract: Personalizing text-to-image diffusion models is crucial for adapting the
pre-trained models to specific target concepts, enabling diverse image
generation. However, fine-tuning with few images introduces an inherent
trade-off between aligning with the target distribution (e.g., subject
fidelity) and preserving the broad knowledge of the original model (e.g., text
editability). Existing sampling guidance methods, such as classifier-free
guidance (CFG) and autoguidance (AG), fail to effectively guide the output
toward well-balanced space: CFG restricts the adaptation to the target
distribution, while AG compromises text alignment. To address these
limitations, we propose personalization guidance, a simple yet effective method
leveraging an unlearned weak model conditioned on a null text prompt. Moreover,
our method dynamically controls the extent of unlearning in a weak model
through weight interpolation between pre-trained and fine-tuned models during
inference. Unlike existing guidance methods, which depend solely on guidance
scales, our method explicitly steers the outputs toward a balanced latent space
without additional computational overhead. Experimental results demonstrate
that our proposed guidance can improve text alignment and target distribution
fidelity, integrating seamlessly with various fine-tuning strategies.

</details>


### [29] [Spectral Sensitivity Estimation with an Uncalibrated Diffraction Grating](https://arxiv.org/abs/2508.00330)
*Lilika Makabe,Hiroaki Santo,Fumio Okura,Michael S. Brown,Yasuyuki Matsushita*

Main category: cs.CV

TL;DR: 提出了一种仅需现成衍射光栅片的相机光谱灵敏度校准方法，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 相机光谱灵敏度的准确校准对计算机视觉任务（如颜色校正、光照估计和材料分析）至关重要。现有方法需要特殊窄带滤光片或已知光谱反射率的参考目标，而该方法仅需现成的非校准衍射光栅片。

Method: 提出了一种使用非校准衍射光栅片的闭式方法，通过捕获直接照明及其衍射图案的图像，同时估计相机光谱灵敏度和衍射光栅参数。

Result: 在合成和真实数据上的实验表明，该方法优于传统的基于参考目标的方法。

Conclusion: 该方法通过衍射光栅实现了相机光谱灵敏度的实用且准确校准，优于传统基于参考目标的方法，展示了其有效性和实用性。

Abstract: This paper introduces a practical and accurate calibration method for camera
spectral sensitivity using a diffraction grating. Accurate calibration of
camera spectral sensitivity is crucial for various computer vision tasks,
including color correction, illumination estimation, and material analysis.
Unlike existing approaches that require specialized narrow-band filters or
reference targets with known spectral reflectances, our method only requires an
uncalibrated diffraction grating sheet, readily available off-the-shelf. By
capturing images of the direct illumination and its diffracted pattern through
the grating sheet, our method estimates both the camera spectral sensitivity
and the diffraction grating parameters in a closed-form manner. Experiments on
synthetic and real-world data demonstrate that our method outperforms
conventional reference target-based methods, underscoring its effectiveness and
practicality.

</details>


### [30] [Analyze-Prompt-Reason: A Collaborative Agent-Based Framework for Multi-Image Vision-Language Reasoning](https://arxiv.org/abs/2508.00356)
*Angelos Vlachos,Giorgos Filandrianos,Maria Lymperaiou,Nikolaos Spanos,Ilias Mitsouras,Vasileios Karampinis,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 提出协作代理框架，通过双代理系统实现多图像推理，在多种任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决跨多样数据集和任务格式的交错多模态推理挑战。

Method: 采用基于双代理系统的协作代理框架，包括语言基础的PromptEngineer生成任务特定提示，以及视觉基础的VisionReasoner进行最终推理。该框架完全自动化、模块化且无需训练。

Result: 在18个多样化数据集上评估，Claude 3.7在TQA（99.13%准确率）、DocVQA（96.87%）和MMCoQA（75.28 ROUGE-L）等任务中表现优异。

Conclusion: 该研究展示了大型视觉语言模型（LVLM）在通过信息丰富的提示引导下，能够有效地进行多图像推理，并在多种任务中取得接近顶峰的优异表现。

Abstract: We present a Collaborative Agent-Based Framework for Multi-Image Reasoning.
Our approach tackles the challenge of interleaved multimodal reasoning across
diverse datasets and task formats by employing a dual-agent system: a
language-based PromptEngineer, which generates context-aware, task-specific
prompts, and a VisionReasoner, a large vision-language model (LVLM) responsible
for final inference. The framework is fully automated, modular, and
training-free, enabling generalization across classification, question
answering, and free-form generation tasks involving one or multiple input
images. We evaluate our method on 18 diverse datasets from the 2025 MIRAGE
Challenge (Track A), covering a broad spectrum of visual reasoning tasks
including document QA, visual comparison, dialogue-based understanding, and
scene-level inference. Our results demonstrate that LVLMs can effectively
reason over multiple images when guided by informative prompts. Notably, Claude
3.7 achieves near-ceiling performance on challenging tasks such as TQA (99.13%
accuracy), DocVQA (96.87%), and MMCoQA (75.28 ROUGE-L). We also explore how
design choices-such as model selection, shot count, and input length-influence
the reasoning performance of different LVLMs.

</details>


### [31] [Stable at Any Speed: Speed-Driven Multi-Object Tracking with Learnable Kalman Filtering](https://arxiv.org/abs/2508.00358)
*Yan Gong,Mengjun Chen,Hao Liu,Gao Yongsheng,Lei Yang,Naibang Wang,Ziying Song,Haoqun Ma*

Main category: cs.CV

TL;DR: SG-LKF通过动态适应自车速度的不确定性建模，显著提升多目标跟踪在高动态场景的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于检测的跟踪方法忽视了自车速度引起的观测噪声和参考帧变化，导致在高动态、高速场景中跟踪性能下降。

Method: 提出了Speed-Guided Learnable Kalman Filter (SG-LKF) 和 MotionScaleNet (MSNet)，结合自监督轨迹一致性损失。

Result: 在KITTI 2D MOT上以79.59% HOTA排名第一，KITTI 3D MOT上82.03% HOTA，nuScenes 3D MOT上比SimpleTrack提高2.2% AMOTA。

Conclusion: SG-LKF通过动态调整不确定性建模以适应自车速度，显著提高了高动态场景下的跟踪稳定性和准确性。

Abstract: Multi-object tracking (MOT) enables autonomous vehicles to continuously
perceive dynamic objects, supplying essential temporal cues for prediction,
behavior understanding, and safe planning. However, conventional
tracking-by-detection methods typically rely on static coordinate
transformations based on ego-vehicle poses, disregarding ego-vehicle
speed-induced variations in observation noise and reference frame changes,
which degrades tracking stability and accuracy in dynamic, high-speed
scenarios. In this paper, we investigate the critical role of ego-vehicle speed
in MOT and propose a Speed-Guided Learnable Kalman Filter (SG-LKF) that
dynamically adapts uncertainty modeling to ego-vehicle speed, significantly
improving stability and accuracy in highly dynamic scenarios. Central to SG-LKF
is MotionScaleNet (MSNet), a decoupled token-mixing and channel-mixing MLP that
adaptively predicts key parameters of SG-LKF. To enhance inter-frame
association and trajectory continuity, we introduce a self-supervised
trajectory consistency loss jointly optimized with semantic and positional
constraints. Extensive experiments show that SG-LKF ranks first among all
vision-based methods on KITTI 2D MOT with 79.59% HOTA, delivers strong results
on KITTI 3D MOT with 82.03% HOTA, and outperforms SimpleTrack by 2.2% AMOTA on
nuScenes 3D MOT.

</details>


### [32] [CoST: Efficient Collaborative Perception From Unified Spatiotemporal Perspective](https://arxiv.org/abs/2508.00359)
*Zongheng Tang,Yi Liu,Yifan Sun,Yulu Gao,Jinyu Chen,Runsheng Xu,Si Liu*

Main category: cs.CV

TL;DR: CoST通过统一时空空间聚合多智能体和多时间观测，提升了协作感知的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统协作感知方法中多智能体融合和多时间融合分离导致的效率低下和特征融合不全面的问题。

Method: 提出了一种高效的协作感知方法，通过统一的时空空间同时聚合多智能体和多时间的观测，避免了传统方法中特征重复传输的问题。

Result: CoST在效率和准确性上均有提升，且兼容多数现有方法，降低了传输带宽需求。

Conclusion: CoST（Collaborative perception with Spatio-temporal Transformer）通过统一的时空空间聚合多智能体和多时间观测，显著提升了协作感知的效率和准确性，且兼容多数现有方法。

Abstract: Collaborative perception shares information among different agents and helps
solving problems that individual agents may face, e.g., occlusions and small
sensing range. Prior methods usually separate the multi-agent fusion and
multi-time fusion into two consecutive steps. In contrast, this paper proposes
an efficient collaborative perception that aggregates the observations from
different agents (space) and different times into a unified spatio-temporal
space simultanesouly. The unified spatio-temporal space brings two benefits,
i.e., efficient feature transmission and superior feature fusion. 1) Efficient
feature transmission: each static object yields a single observation in the
spatial temporal space, and thus only requires transmission only once (whereas
prior methods re-transmit all the object features multiple times). 2) superior
feature fusion: merging the multi-agent and multi-time fusion into a unified
spatial-temporal aggregation enables a more holistic perspective, thereby
enhancing perception performance in challenging scenarios. Consequently, our
Collaborative perception with Spatio-temporal Transformer (CoST) gains
improvement in both efficiency and accuracy. Notably, CoST is not tied to any
specific method and is compatible with a majority of previous methods,
enhancing their accuracy while reducing the transmission bandwidth.

</details>


### [33] [Honey Classification using Hyperspectral Imaging and Machine Learning](https://arxiv.org/abs/2508.00361)
*Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh*

Main category: cs.CV

TL;DR: A machine learning method using LDA, SVM, and KNN achieves high accuracy in classifying honey origins.


<details>
  <summary>Details</summary>
Motivation: To automatically classify honey botanical origins using machine learning, improving accuracy and efficiency over traditional methods.

Method: The method involves dataset preparation with class transformation, feature extraction using Linear Discriminant Analysis (LDA), and classification with Support Vector Machines (SVM) and K-Nearest Neighbors (KNN).

Result: The system achieves 95.13% accuracy for hyperspectral image-based classification and 92.80% for hyperspectral instance-based classification.

Conclusion: The proposed machine learning-based method achieves state-of-the-art results in classifying honey botanical origins, with high accuracy rates of 95.13% for image-based and 92.80% for instance-based classification.

Abstract: In this paper, we propose a machine learning-based method for automatically
classifying honey botanical origins. Dataset preparation, feature extraction,
and classification are the three main steps of the proposed method. We use a
class transformation method in the dataset preparation phase to maximize the
separability across classes. The feature extraction phase employs the Linear
Discriminant Analysis (LDA) technique for extracting relevant features and
reducing the number of dimensions. In the classification phase, we use Support
Vector Machines (SVM) and K-Nearest Neighbors (KNN) models to classify the
extracted features of honey samples into their botanical origins. We evaluate
our system using a standard honey hyperspectral imaging (HSI) dataset.
Experimental findings demonstrate that the proposed system produces
state-of-the-art results on this dataset, achieving the highest classification
accuracy of 95.13% for hyperspectral image-based classification and 92.80% for
hyperspectral instance-based classification.

</details>


### [34] [SparseRecon: Neural Implicit Surface Reconstruction from Sparse Views with Feature and Depth Consistencies](https://arxiv.org/abs/2508.00366)
*Liang Han,Xu Zhang,Haichuan Song,Kanle Shi,Yu-Shen Liu,Zhizhong Han*

Main category: cs.CV

TL;DR: SparseRecon 是一种新的神经隐式重建方法，通过特征一致性和深度约束提升稀疏视图重建质量，实验结果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏视图重建中存在泛化性差或重建质量受限的问题，SparseRecon 旨在通过多视角特征一致性和深度约束解决这些挑战。

Method: 采用体积渲染特征一致性损失和不确定性引导深度约束，前者确保重建结果的完整性和平滑性，后者在遮挡和特征不明显区域补充几何细节。

Result: 实验结果表明，SparseRecon 在稀疏视图输入下优于现有方法，能够生成高质量的几何重建结果。

Conclusion: SparseRecon 提出了一种新颖的神经隐式重建方法，通过体积渲染特征一致性和不确定性引导的深度约束，显著提升了稀疏视图重建的质量，特别是在重叠视图较少的场景中。

Abstract: Surface reconstruction from sparse views aims to reconstruct a 3D shape or
scene from few RGB images. The latest methods are either generalization-based
or overfitting-based. However, the generalization-based methods do not
generalize well on views that were unseen during training, while the
reconstruction quality of overfitting-based methods is still limited by the
limited geometry clues. To address this issue, we propose SparseRecon, a novel
neural implicit reconstruction method for sparse views with volume
rendering-based feature consistency and uncertainty-guided depth constraint.
Firstly, we introduce a feature consistency loss across views to constrain the
neural implicit field. This design alleviates the ambiguity caused by
insufficient consistency information of views and ensures completeness and
smoothness in the reconstruction results. Secondly, we employ an
uncertainty-guided depth constraint to back up the feature consistency loss in
areas with occlusion and insignificant features, which recovers geometry
details for better reconstruction quality. Experimental results demonstrate
that our method outperforms the state-of-the-art methods, which can produce
high-quality geometry with sparse-view input, especially in the scenarios with
small overlapping views. Project page: https://hanl2010.github.io/SparseRecon/.

</details>


### [35] [Representation Shift: Unifying Token Compression with FlashAttention](https://arxiv.org/abs/2508.00367)
*Joonmyung Choi,Sanghyeok Lee,Byungoh Ko,Eunseo Kim,Jihyung Kil,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: 提出Representation Shift方法，通过测量token表示变化实现压缩，与FlashAttention兼容，显著提升速度。


<details>
  <summary>Details</summary>
Motivation: 随着任务复杂度的增加，Transformer模型和token数量的增长导致自注意力的二次计算成本和GPU内存访问开销增加。现有的token压缩方法大多依赖注意力图，无法与FlashAttention兼容。

Method: 提出Representation Shift方法，通过测量每个token表示的变化程度来实现token压缩，无需依赖注意力图或重新训练。

Result: 实验表明，Representation Shift能与FlashAttention无缝集成，在视频-文本检索和视频问答任务中分别实现了高达5.5%和4.4%的速度提升。

Conclusion: Representation Shift是一种无需训练、模型无关的度量方法，能够有效减少自注意力计算成本，并与FlashAttention兼容，显著提升了视频-文本检索和视频问答任务的速度。

Abstract: Transformers have demonstrated remarkable success across vision, language,
and video. Yet, increasing task complexity has led to larger models and more
tokens, raising the quadratic cost of self-attention and the overhead of GPU
memory access. To reduce the computation cost of self-attention, prior work has
proposed token compression techniques that drop redundant or less informative
tokens. Meanwhile, fused attention kernels such as FlashAttention have been
developed to alleviate memory overhead by avoiding attention map construction
and its associated I/O to HBM. This, however, makes it incompatible with most
training-free token compression methods, which rely on attention maps to
determine token importance. Here, we propose Representation Shift, a
training-free, model-agnostic metric that measures the degree of change in each
token's representation. This seamlessly integrates token compression with
FlashAttention, without attention maps or retraining. Our method further
generalizes beyond Transformers to CNNs and state space models. Extensive
experiments show that Representation Shift enables effective token compression
compatible with FlashAttention, yielding significant speedups of up to 5.5% and
4.4% in video-text retrieval and video QA, respectively. Code is available at
https://github.com/mlvlab/Representation-Shift.

</details>


### [36] [Bidirectional Action Sequence Learning for Long-term Action Anticipation with Large Language Models](https://arxiv.org/abs/2508.00374)
*Yuji Sato,Yasunori Ishii,Takayoshi Yamashita*

Main category: cs.CV

TL;DR: BiAnt通过双向预测和大型语言模型提升视频长期动作预测性能，优于传统单向方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于编码器-解码器的方法由于单向性限制了性能，且难以捕捉场景中语义不同的子动作。

Method: BiAnt结合了前向预测和后向预测，利用大型语言模型来捕捉场景中语义不同的子动作。

Result: 在Ego4D数据集上的实验表明，BiAnt在编辑距离指标上优于基线方法。

Conclusion: BiAnt通过结合前向预测和后向预测，利用大型语言模型，显著提升了长期动作预测的性能，特别是在编辑距离指标上优于基线方法。

Abstract: Video-based long-term action anticipation is crucial for early risk detection
in areas such as automated driving and robotics. Conventional approaches
extract features from past actions using encoders and predict future events
with decoders, which limits performance due to their unidirectional nature.
These methods struggle to capture semantically distinct sub-actions within a
scene. The proposed method, BiAnt, addresses this limitation by combining
forward prediction with backward prediction using a large language model.
Experimental results on Ego4D demonstrate that BiAnt improves performance in
terms of edit distance compared to baseline methods.

</details>


### [37] [Advancing Welding Defect Detection in Maritime Operations via Adapt-WeldNet and Defect Detection Interpretability Analysis](https://arxiv.org/abs/2508.00381)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出Adapt-WeldNet和DDIA框架，提升焊接缺陷检测的性能和可解释性，增强自动化决策的信任度。


<details>
  <summary>Details</summary>
Motivation: 传统NDT方法和现有神经网络方法在检测焊接缺陷时存在性能不足和可解释性差的问题，影响安全和可靠性。

Method: 提出Adapt-WeldNet框架，系统评估预训练架构、迁移学习策略和自适应优化器；引入DDIA框架，结合XAI技术和领域专家验证。

Result: Adapt-WeldNet优化了缺陷检测性能，DDIA框架提升了系统透明度和信任度，经专家验证有效。

Conclusion: 本研究通过提出Adapt-WeldNet和DDIA框架，显著提升了焊接缺陷检测的性能和可解释性，增强了在海洋和离岸环境中自动化决策的信任度。

Abstract: Weld defect detection is crucial for ensuring the safety and reliability of
piping systems in the oil and gas industry, especially in challenging marine
and offshore environments. Traditional non-destructive testing (NDT) methods
often fail to detect subtle or internal defects, leading to potential failures
and costly downtime. Furthermore, existing neural network-based approaches for
defect classification frequently rely on arbitrarily selected pretrained
architectures and lack interpretability, raising safety concerns for
deployment. To address these challenges, this paper introduces
``Adapt-WeldNet", an adaptive framework for welding defect detection that
systematically evaluates various pre-trained architectures, transfer learning
strategies, and adaptive optimizers to identify the best-performing model and
hyperparameters, optimizing defect detection and providing actionable insights.
Additionally, a novel Defect Detection Interpretability Analysis (DDIA)
framework is proposed to enhance system transparency. DDIA employs Explainable
AI (XAI) techniques, such as Grad-CAM and LIME, alongside domain-specific
evaluations validated by certified ASNT NDE Level II professionals.
Incorporating a Human-in-the-Loop (HITL) approach and aligning with the
principles of Trustworthy AI, DDIA ensures the reliability, fairness, and
accountability of the defect detection system, fostering confidence in
automated decisions through expert validation. By improving both performance
and interpretability, this work enhances trust, safety, and reliability in
welding defect detection systems, supporting critical operations in offshore
and marine environments.

</details>


### [38] [$MV_{Hybrid}$: Improving Spatial Transcriptomics Prediction with Hybrid State Space-Vision Transformer Backbone in Pathology Vision Foundation Models](https://arxiv.org/abs/2508.00383)
*Won June Cho,Hongjun Yoon,Daeky Jeong,Hyeongyeol Lim,Yosep Chong*

Main category: cs.CV

TL;DR: 提出混合SSM和ViT的$MV_{Hybrid}$架构，显著提升病理图像中基因表达预测的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学的高成本和技术复杂性限制了其临床应用，预测常规病理图像中的基因表达为替代方案，但现有ViT模型性能不足。

Method: 引入$MV_{Hybrid}$，一种结合状态空间模型（SSMs）和ViT的混合骨干架构，通过负实特征值初始化捕捉低频、细微的形态学模式。

Result: 在LOSO评估中，$MV_{Hybrid}$比最佳ViT模型相关性高57%，性能下降减少43%，表现出更强的鲁棒性。

Conclusion: $MV_{Hybrid}$展示了作为下一代病理视觉基础模型骨干的潜力，在分类、图像块检索和生存预测任务中表现优于或等同于ViT。

Abstract: Spatial transcriptomics reveals gene expression patterns within tissue
context, enabling precision oncology applications such as treatment response
prediction, but its high cost and technical complexity limit clinical adoption.
Predicting spatial gene expression (biomarkers) from routine histopathology
images offers a practical alternative, yet current vision foundation models
(VFMs) in pathology based on Vision Transformer (ViT) backbones perform below
clinical standards. Given that VFMs are already trained on millions of diverse
whole slide images, we hypothesize that architectural innovations beyond ViTs
may better capture the low-frequency, subtle morphological patterns correlating
with molecular phenotypes. By demonstrating that state space models initialized
with negative real eigenvalues exhibit strong low-frequency bias, we introduce
$MV_{Hybrid}$, a hybrid backbone architecture combining state space models
(SSMs) with ViT. We compare five other different backbone architectures for
pathology VFMs, all pretrained on identical colorectal cancer datasets using
the DINOv2 self-supervised learning method. We evaluate all pretrained models
using both random split and leave-one-study-out (LOSO) settings of the same
biomarker dataset. In LOSO evaluation, $MV_{Hybrid}$ achieves 57% higher
correlation than the best-performing ViT and shows 43% smaller performance
degradation compared to random split in gene expression prediction,
demonstrating superior performance and robustness, respectively. Furthermore,
$MV_{Hybrid}$ shows equal or better downstream performance in classification,
patch retrieval, and survival prediction tasks compared to that of ViT, showing
its promise as a next-generation pathology VFM backbone. Our code is publicly
available at: https://github.com/deepnoid-ai/MVHybrid.

</details>


### [39] [Cued-Agent: A Collaborative Multi-Agent System for Automatic Cued Speech Recognition](https://arxiv.org/abs/2508.00391)
*Guanjie Huang,Danny H. K. Tsang,Shan Yang,Guangzhi Lei,Li Liu*

Main category: cs.CV

TL;DR: Cued-Agent 是首个用于自动 Cued Speech 识别的协作多智能体系统，通过四个子智能体协同工作，显著提升了识别性能，尤其在听障场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统 ACSR 方法因数据有限和手部与唇部动作的异步性，难以有效训练多模态融合机制，导致性能不佳。多智能体系统在有限数据下处理复杂任务的优势为解决这一问题提供了新思路。

Method: Cued-Agent 是一个协作多智能体系统，包含四个子智能体：基于多模态大语言模型的手势识别、基于预训练 Transformer 的唇部识别、动态整合手部提示与唇部特征的手部提示解码，以及通过语义细化实现音素到自然语言转换的自校正智能体。

Result: Cued-Agent 在正常和听障场景下均表现出卓越性能，实验验证了其有效性。

Conclusion: Cued-Agent 在自动 Cued Speech 识别（ACSR）中表现出色，尤其在处理听障场景时优于现有最先进方法。

Abstract: Cued Speech (CS) is a visual communication system that combines lip-reading
with hand coding to facilitate communication for individuals with hearing
impairments. Automatic CS Recognition (ACSR) aims to convert CS hand gestures
and lip movements into text via AI-driven methods. Traditionally, the temporal
asynchrony between hand and lip movements requires the design of complex
modules to facilitate effective multimodal fusion. However, constrained by
limited data availability, current methods demonstrate insufficient capacity
for adequately training these fusion mechanisms, resulting in suboptimal
performance. Recently, multi-agent systems have shown promising capabilities in
handling complex tasks with limited data availability. To this end, we propose
the first collaborative multi-agent system for ACSR, named Cued-Agent. It
integrates four specialized sub-agents: a Multimodal Large Language Model-based
Hand Recognition agent that employs keyframe screening and CS expert prompt
strategies to decode hand movements, a pretrained Transformer-based Lip
Recognition agent that extracts lip features from the input video, a Hand
Prompt Decoding agent that dynamically integrates hand prompts with lip
features during inference in a training-free manner, and a Self-Correction
Phoneme-to-Word agent that enables post-process and end-to-end conversion from
phoneme sequences to natural language sentences for the first time through
semantic refinement. To support this study, we expand the existing Mandarin CS
dataset by collecting data from eight hearing-impaired cuers, establishing a
mixed dataset of fourteen subjects. Extensive experiments demonstrate that our
Cued-Agent performs superbly in both normal and hearing-impaired scenarios
compared with state-of-the-art methods. The implementation is available at
https://github.com/DennisHgj/Cued-Agent.

</details>


### [40] [Decouple before Align: Visual Disentanglement Enhances Prompt Tuning](https://arxiv.org/abs/2508.00395)
*Fei Zhang,Tianfei Zhou,Jiangchao Yao,Ya Zhang,Ivor W. Tsang,Yanfeng Wang*

Main category: cs.CV

TL;DR: DAPT通过解耦和对齐视觉模态的前景与背景表示，解决了提示调优中的信息不对称问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究提示调优（PT）中视觉和文本模态之间的信息不对称问题，即视觉模态通常比面向对象的文本模态传递更多上下文，导致模型仅关注上下文区域的偏见注意力。

Method: 提出了DAPT框架，基于解耦再对齐的概念，首先通过粗到细的视觉分割线索显式解耦视觉模态为前景和背景表示，然后将这些解耦模式与原始前景文本和手工制作的背景类别对齐。此外，还引入了针对前景-背景模式的视觉拉推正则化，以增强视觉集中度。

Result: DAPT在少样本学习、基础到新类别的泛化以及数据高效学习中表现出卓越性能，超越了现有基准。

Conclusion: DAPT框架通过解耦和对齐视觉模态的前景与背景表示，有效解决了提示调优中的信息不对称问题，提升了模型在少样本学习、基础到新类别的泛化以及数据高效学习中的性能。

Abstract: Prompt tuning (PT), as an emerging resource-efficient fine-tuning paradigm,
has showcased remarkable effectiveness in improving the task-specific
transferability of vision-language models. This paper delves into a previously
overlooked information asymmetry issue in PT, where the visual modality mostly
conveys more context than the object-oriented textual modality.
Correspondingly, coarsely aligning these two modalities could result in the
biased attention, driving the model to merely focus on the context area. To
address this, we propose DAPT, an effective PT framework based on an intuitive
decouple-before-align concept. First, we propose to explicitly decouple the
visual modality into the foreground and background representation via
exploiting coarse-and-fine visual segmenting cues, and then both of these
decoupled patterns are aligned with the original foreground texts and the
hand-crafted background classes, thereby symmetrically strengthening the modal
alignment. To further enhance the visual concentration, we propose a visual
pull-push regularization tailored for the foreground-background patterns,
directing the original visual representation towards unbiased attention on the
region-of-interest object. We demonstrate the power of architecture-free DAPT
through few-shot learning, base-to-novel generalization, and data-efficient
learning, all of which yield superior performance across prevailing benchmarks.
Our code will be released at https://github.com/Ferenas/DAPT.

</details>


### [41] [Video Forgery Detection with Optical Flow Residuals and Spatial-Temporal Consistency](https://arxiv.org/abs/2508.00397)
*Xi Xue,Kunio Suzuki,Nabarun Goswami,Takuya Shintate*

Main category: cs.CV

TL;DR: 提出一种结合RGB和光流残差的双分支框架，有效检测AI生成视频中的伪造内容，实验验证其鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着扩散基视频生成模型的快速发展，合成内容日益逼真，现有方法难以捕捉细粒度时间不一致性，尤其是在视觉保真度高且运动连贯的AI生成视频中。

Method: 采用双分支架构，一支分析RGB帧以检测外观层面伪影，另一支处理光流残差以揭示不完美时间合成导致的细微运动异常。

Result: 在十种不同的生成模型上进行的文本到视频和图像到视频任务的广泛实验表明，该方法具有鲁棒性和强泛化能力。

Conclusion: 该论文提出的双分支框架通过结合RGB外观特征和光流残差，有效检测了视频伪造，展现了强大的泛化能力。

Abstract: The rapid advancement of diffusion-based video generation models has led to
increasingly realistic synthetic content, presenting new challenges for video
forgery detection. Existing methods often struggle to capture fine-grained
temporal inconsistencies, particularly in AI-generated videos with high visual
fidelity and coherent motion. In this work, we propose a detection framework
that leverages spatial-temporal consistency by combining RGB appearance
features with optical flow residuals. The model adopts a dual-branch
architecture, where one branch analyzes RGB frames to detect appearance-level
artifacts, while the other processes flow residuals to reveal subtle motion
anomalies caused by imperfect temporal synthesis. By integrating these
complementary features, the proposed method effectively detects a wide range of
forged videos. Extensive experiments on text-to-video and image-to-video tasks
across ten diverse generative models demonstrate the robustness and strong
generalization ability of the proposed approach.

</details>


### [42] [iSafetyBench: A video-language benchmark for safety in industrial environment](https://arxiv.org/abs/2508.00399)
*Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas*

Main category: cs.CV

TL;DR: iSafetyBench 是一个新的视频-语言基准测试，用于评估工业环境中模型的表现。现有模型在识别危险活动和多标签场景中表现不佳，突显了需要更强大的安全感知多模态模型。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型在工业高风险领域的能力尚未充分探索，尤其是在识别常规操作和安全关键异常方面。为了填补这一空白，研究团队开发了 iSafetyBench。

Method: 研究团队引入了 iSafetyBench，包含 1,100 个来自真实工业环境的视频片段，标注了 98 个常规和 67 个危险动作类别的开放词汇多标签动作标签。每个视频片段配有多选题，用于单标签和多标签评估。

Result: 评估了八种最先进的视频-语言模型在零样本条件下的表现。尽管这些模型在现有视频基准测试中表现优异，但在 iSafetyBench 上表现不佳，尤其是在危险活动识别和多标签场景中。

Conclusion: iSafetyBench 是一个专为工业环境设计的视频-语言基准测试，旨在评估模型在正常和危险场景下的性能。尽管现有视觉-语言模型在零样本设置下表现优异，但在工业安全关键领域的表现仍有显著不足，尤其是在识别危险活动和多标签场景方面。

Abstract: Recent advances in vision-language models (VLMs) have enabled impressive
generalization across diverse video understanding tasks under zero-shot
settings. However, their capabilities in high-stakes industrial domains-where
recognizing both routine operations and safety-critical anomalies is
essential-remain largely underexplored. To address this gap, we introduce
iSafetyBench, a new video-language benchmark specifically designed to evaluate
model performance in industrial environments across both normal and hazardous
scenarios. iSafetyBench comprises 1,100 video clips sourced from real-world
industrial settings, annotated with open-vocabulary, multi-label action tags
spanning 98 routine and 67 hazardous action categories. Each clip is paired
with multiple-choice questions for both single-label and multi-label
evaluation, enabling fine-grained assessment of VLMs in both standard and
safety-critical contexts. We evaluate eight state-of-the-art video-language
models under zero-shot conditions. Despite their strong performance on existing
video benchmarks, these models struggle with iSafetyBench-particularly in
recognizing hazardous activities and in multi-label scenarios. Our results
reveal significant performance gaps, underscoring the need for more robust,
safety-aware multimodal models for industrial applications. iSafetyBench
provides a first-of-its-kind testbed to drive progress in this direction. The
dataset is available at: https://github.com/raiyaan-abdullah/iSafety-Bench.

</details>


### [43] [Sari Sandbox: A Virtual Retail Store Environment for Embodied AI Agents](https://arxiv.org/abs/2508.00400)
*Janika Deborah Gajo,Gerarld Paul Merales,Jerome Escarcha,Brenden Ashley Molina,Gian Nartea,Emmanuel G. Maminta,Juan Carlos Roldan,Rowel O. Atienza*

Main category: cs.CV

TL;DR: Sari Sandbox 是一个高保真3D零售店模拟环境，用于基准化实体代理与人类在购物任务中的表现，包含250+交互商品和SariBench数据集。


<details>
  <summary>Details</summary>
Motivation: 解决零售特定模拟环境在实体代理训练中的不足，提供一个高保真、逼真的3D零售店模拟环境。

Method: Sari Sandbox 包含超过250种交互式杂货商品，分布在三种商店配置中，可通过API控制。支持虚拟现实（VR）和视觉语言模型（VLM）驱动的实体代理。还引入了SariBench数据集，包含不同任务难度的人类示范注释。

Result: Sari Sandbox 使实体代理能够导航、检查和操作零售商品，并提供与人类表现的基准对比。

Conclusion: Sari Sandbox 提供了一个高保真、逼真的3D零售店模拟环境，用于基准化实体代理在购物任务中与人类表现的对比。通过基准测试和性能分析，提出了增强真实性和可扩展性的建议。

Abstract: We present Sari Sandbox, a high-fidelity, photorealistic 3D retail store
simulation for benchmarking embodied agents against human performance in
shopping tasks. Addressing a gap in retail-specific sim environments for
embodied agent training, Sari Sandbox features over 250 interactive grocery
items across three store configurations, controlled via an API. It supports
both virtual reality (VR) for human interaction and a vision language model
(VLM)-powered embodied agent. We also introduce SariBench, a dataset of
annotated human demonstrations across varied task difficulties. Our sandbox
enables embodied agents to navigate, inspect, and manipulate retail items,
providing baselines against human performance. We conclude with benchmarks,
performance analysis, and recommendations for enhancing realism and
scalability. The source code can be accessed via
https://github.com/upeee/sari-sandbox-env.

</details>


### [44] [PMR: Physical Model-Driven Multi-Stage Restoration of Turbulent Dynamic Videos](https://arxiv.org/abs/2508.00406)
*Tao Wu,Jingyuan Ye,Ying Fu*

Main category: cs.CV

TL;DR: 提出动态效率指数(DEI)和多阶段视频恢复框架(PMR)，有效解决湍流导致的视频失真问题，尤其在复杂动态场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以恢复边缘细节和消除混合失真，尤其是在强湍流和复杂动态条件下。

Method: 提出动态效率指数(DEI)量化视频动态强度，并开发了物理模型驱动的多阶段视频恢复框架(PMR)，包括去倾斜、动态区域增强和去模糊三个阶段。

Result: 实验结果表明，PMR框架能有效抑制运动拖尾伪影、恢复边缘细节，并展现出强泛化能力。

Conclusion: 该方法通过动态效率指数(DEI)和多阶段视频恢复框架(PMR)，有效解决了大气湍流导致的几何失真和模糊问题，尤其在强湍流和复杂动态场景下表现优异。

Abstract: Geometric distortions and blurring caused by atmospheric turbulence degrade
the quality of long-range dynamic scene videos. Existing methods struggle with
restoring edge details and eliminating mixed distortions, especially under
conditions of strong turbulence and complex dynamics. To address these
challenges, we introduce a Dynamic Efficiency Index ($DEI$), which combines
turbulence intensity, optical flow, and proportions of dynamic regions to
accurately quantify video dynamic intensity under varying turbulence conditions
and provide a high-dynamic turbulence training dataset. Additionally, we
propose a Physical Model-Driven Multi-Stage Video Restoration ($PMR$) framework
that consists of three stages: \textbf{de-tilting} for geometric stabilization,
\textbf{motion segmentation enhancement} for dynamic region refinement, and
\textbf{de-blurring} for quality restoration. $PMR$ employs lightweight
backbones and stage-wise joint training to ensure both efficiency and high
restoration quality. Experimental results demonstrate that the proposed method
effectively suppresses motion trailing artifacts, restores edge details and
exhibits strong generalization capability, especially in real-world scenarios
characterized by high-turbulence and complex dynamics. We will make the code
and datasets openly available.

</details>


### [45] [Sortblock: Similarity-Aware Feature Reuse for Diffusion Model](https://arxiv.org/abs/2508.00412)
*Hanqi Chen,Xu Zhang,Xiaoliu Guan,Lielin Jiang,Guanzhong Wang,Zeyu Chen,Yi Liu*

Main category: cs.CV

TL;DR: Sortblock 是一种无需训练的推理加速框架，通过动态缓存和选择性跳过冗余计算，显著提升 DiT 的推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器（DiTs）在生成能力上表现出色，但序列去噪过程导致高推理延迟，现有方法未能充分考虑去噪阶段和 Transformer 块间的语义变化。

Method: 提出 Sortblock 框架，通过动态缓存块级特征并基于相邻时间步的相似性进行排序，自适应地确定重计算比率，选择性跳过冗余计算，并结合轻量级线性预测机制减少累积误差。

Result: 在各种任务和 DiT 架构上的实验表明，Sortblock 实现了超过 2 倍的推理加速，且输出质量仅有最小程度的下降。

Conclusion: Sortblock 提供了一种无需训练的高效推理加速框架，通过动态缓存块级特征和选择性跳过冗余计算，显著提升了扩散变换器的推理速度，同时保持了生成质量。

Abstract: Diffusion Transformers (DiTs) have demonstrated remarkable generative
capabilities, particularly benefiting from Transformer architectures that
enhance visual and artistic fidelity. However, their inherently sequential
denoising process results in high inference latency, limiting their deployment
in real-time scenarios. Existing training-free acceleration approaches
typically reuse intermediate features at fixed timesteps or layers, overlooking
the evolving semantic focus across denoising stages and Transformer blocks.To
address this, we propose Sortblock, a training-free inference acceleration
framework that dynamically caches block-wise features based on their similarity
across adjacent timesteps. By ranking the evolution of residuals, Sortblock
adaptively determines a recomputation ratio, selectively skipping redundant
computations while preserving generation quality. Furthermore, we incorporate a
lightweight linear prediction mechanism to reduce accumulated errors in skipped
blocks.Extensive experiments across various tasks and DiT architectures
demonstrate that Sortblock achieves over 2$\times$ inference speedup with
minimal degradation in output quality, offering an effective and generalizable
solution for accelerating diffusion-based generative models.

</details>


### [46] [DC-AE 1.5: Accelerating Diffusion Model Convergence with Structured Latent Space](https://arxiv.org/abs/2508.00413)
*Junyu Chen,Dongyun Zou,Wenkun He,Junsong Chen,Enze Xie,Song Han,Han Cai*

Main category: cs.CV

TL;DR: DC-AE 1.5通过结构化潜在空间和增强扩散训练，显著提升高分辨率扩散模型的生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决增加自编码器潜在通道数导致扩散模型收敛慢、生成质量下降的问题，突破潜在扩散模型的质量限制。

Method: 采用结构化潜在空间和增强扩散训练策略，前者通过训练在潜在空间中实现通道级结构划分，后者通过额外扩散训练目标加速收敛。

Result: 在ImageNet 512x512上，DC-AE-1.5-f64c128比DC-AE-f32c32生成质量更高且速度快4倍。

Conclusion: DC-AE 1.5通过结构化潜在空间和增强扩散训练，显著提升了高分辨率扩散模型的收敛速度和生成质量，突破了潜在扩散模型的质量上限。

Abstract: We present DC-AE 1.5, a new family of deep compression autoencoders for
high-resolution diffusion models. Increasing the autoencoder's latent channel
number is a highly effective approach for improving its reconstruction quality.
However, it results in slow convergence for diffusion models, leading to poorer
generation quality despite better reconstruction quality. This issue limits the
quality upper bound of latent diffusion models and hinders the employment of
autoencoders with higher spatial compression ratios. We introduce two key
innovations to address this challenge: i) Structured Latent Space, a
training-based approach to impose a desired channel-wise structure on the
latent space with front latent channels capturing object structures and latter
latent channels capturing image details; ii) Augmented Diffusion Training, an
augmented diffusion training strategy with additional diffusion training
objectives on object latent channels to accelerate convergence. With these
techniques, DC-AE 1.5 delivers faster convergence and better diffusion scaling
results than DC-AE. On ImageNet 512x512, DC-AE-1.5-f64c128 delivers better
image generation quality than DC-AE-f32c32 while being 4x faster. Code:
https://github.com/dc-ai-projects/DC-Gen.

</details>


### [47] [IN2OUT: Fine-Tuning Video Inpainting Model for Video Outpainting Using Hierarchical Discriminator](https://arxiv.org/abs/2508.00418)
*Sangwoo Youn,Minji Lee,Nokap Tony Park,Yeonggyoo Jeon,Taeyoung Na*

Main category: cs.CV

TL;DR: 本文提出了一种分层判别器和专门损失函数，显著提升了视频扩展的视觉质量和一致性，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩展方法主要关注背景生成，而忽视了对象流学习和重建。直接应用或微调修复模型在扩展任务中效果不佳，导致模糊结果。

Method: 我们提出了一种分层判别器，将对抗训练的目标分为全局和局部，并开发了一个利用判别器局部和全局特征的专门扩展损失函数。

Result: 我们的方法在定量和定性评估中均优于现有技术。

Conclusion: 通过引入分层判别器和专门的扩展损失函数，我们的方法在视频扩展任务中实现了视觉吸引力和全局一致性的提升，显著优于现有技术。

Abstract: Video outpainting presents a unique challenge of extending the borders while
maintaining consistency with the given content. In this paper, we suggest the
use of video inpainting models that excel in object flow learning and
reconstruction in outpainting rather than solely generating the background as
in existing methods. However, directly applying or fine-tuning inpainting
models to outpainting has shown to be ineffective, often leading to blurry
results. Our extensive experiments on discriminator designs reveal that a
critical component missing in the outpainting fine-tuning process is a
discriminator capable of effectively assessing the perceptual quality of the
extended areas. To tackle this limitation, we differentiate the objectives of
adversarial training into global and local goals and introduce a hierarchical
discriminator that meets both objectives. Additionally, we develop a
specialized outpainting loss function that leverages both local and global
features of the discriminator. Fine-tuning on this adversarial loss function
enhances the generator's ability to produce both visually appealing and
globally coherent outpainted scenes. Our proposed method outperforms
state-of-the-art methods both quantitatively and qualitatively. Supplementary
materials including the demo video and the code are available in SigPort.

</details>


### [48] [Contact-Aware Amodal Completion for Human-Object Interaction via Multi-Regional Inpainting](https://arxiv.org/abs/2508.00427)
*Seunggeun Chi,Enna Sachdeva,Pin-Hao Huang,Kwonjoon Lee*

Main category: cs.CV

TL;DR: 提出一种结合物理先验和多区域修复的新方法，显著提升动态场景中遮挡物体补全的准确性和真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景中因对人类-物体交互（HOI）理解有限而难以生成合理的补全结果，因此需要一种更有效的方法。

Method: 采用基于物理约束的多区域修复技术，结合人类拓扑和接触信息，定义主次区域，并在扩散模型中应用定制化的去噪策略。

Result: 实验结果表明，该方法在HOI场景中显著优于现有方法，且无需真实接触标注即可保持鲁棒性。

Conclusion: 该论文提出了一种结合物理先验知识和多区域修复技术的新方法，显著提升了动态场景中遮挡物体补全的准确性和真实性，使机器感知更接近人类对动态环境的理解。

Abstract: Amodal completion, which is the process of inferring the full appearance of
objects despite partial occlusions, is crucial for understanding complex
human-object interactions (HOI) in computer vision and robotics. Existing
methods, such as those that use pre-trained diffusion models, often struggle to
generate plausible completions in dynamic scenarios because they have a limited
understanding of HOI. To solve this problem, we've developed a new approach
that uses physical prior knowledge along with a specialized multi-regional
inpainting technique designed for HOI. By incorporating physical constraints
from human topology and contact information, we define two distinct regions:
the primary region, where occluded object parts are most likely to be, and the
secondary region, where occlusions are less probable. Our multi-regional
inpainting method uses customized denoising strategies across these regions
within a diffusion model. This improves the accuracy and realism of the
generated completions in both their shape and visual detail. Our experimental
results show that our approach significantly outperforms existing methods in
HOI scenarios, moving machine perception closer to a more human-like
understanding of dynamic environments. We also show that our pipeline is robust
even without ground-truth contact annotations, which broadens its applicability
to tasks like 3D reconstruction and novel view/pose synthesis.

</details>


### [49] [UIS-Mamba: Exploring Mamba for Underwater Instance Segmentation via Dynamic Tree Scan and Hidden State Weaken](https://arxiv.org/abs/2508.00421)
*Runmin Cong,Zongji Yu,Hao Fang,Haoyan Sun,Sam Kwong*

Main category: cs.CV

TL;DR: UIS-Mamba模型通过DTS和HSW模块解决水下实例分割中的连续性保持和背景干扰问题，在多个数据集上表现最优。


<details>
  <summary>Details</summary>
Motivation: 水下场景的特殊性（如颜色失真和边界模糊）导致现有固定补丁扫描机制难以保持实例连续性，且复杂背景会抑制实例理解。

Method: 提出UIS-Mamba模型，包含动态树扫描(DTS)和隐藏状态弱化(HSW)模块。DTS通过动态偏移和缩放保持实例内部特征连续性，HSW通过Ncut机制抑制背景干扰。

Result: 在UIIS和USIS10K数据集上达到最优性能，同时保持低参数和计算复杂度。

Conclusion: UIS-Mamba模型通过动态树扫描(DTS)和隐藏状态弱化(HSW)模块，成功将Mamba模型迁移至水下实例分割任务，并在UIIS和USIS10K数据集上实现了最优性能。

Abstract: Underwater Instance Segmentation (UIS) tasks are crucial for underwater
complex scene detection. Mamba, as an emerging state space model with
inherently linear complexity and global receptive fields, is highly suitable
for processing image segmentation tasks with long sequence features. However,
due to the particularity of underwater scenes, there are many challenges in
applying Mamba to UIS. The existing fixed-patch scanning mechanism cannot
maintain the internal continuity of scanned instances in the presence of
severely underwater color distortion and blurred instance boundaries, and the
hidden state of the complex underwater background can also inhibit the
understanding of instance objects. In this work, we propose the first
Mamba-based underwater instance segmentation model UIS-Mamba, and design two
innovative modules, Dynamic Tree Scan (DTS) and Hidden State Weaken (HSW), to
migrate Mamba to the underwater task. DTS module maintains the continuity of
the internal features of the instance objects by allowing the patches to
dynamically offset and scale, thereby guiding the minimum spanning tree and
providing dynamic local receptive fields. HSW module suppresses the
interference of complex backgrounds and effectively focuses the information
flow of state propagation to the instances themselves through the Ncut-based
hidden state weakening mechanism. Experimental results show that UIS-Mamba
achieves state-of-the-art performance on both UIIS and USIS10K datasets, while
maintaining a low number of parameters and computational complexity. Code is
available at https://github.com/Maricalce/UIS-Mamba.

</details>


### [50] [TopoTTA: Topology-Enhanced Test-Time Adaptation for Tubular Structure Segmentation](https://arxiv.org/abs/2508.00442)
*Jiale Zhou,Wenhan Wang,Shikun Li,Xiaolei Qu,Xin Guo,Yizhong Liu,Wenzhong Tang,Xun Lin,Yefeng Zheng*

Main category: cs.CV

TL;DR: TopoTTA是一种针对TSS的测试时间适应框架，通过两阶段方法有效应对域偏移，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: TSS对域偏移特别敏感，因为拓扑结构的变化可能破坏分割完整性，而局部特征的变化（如纹理和对比度）可能进一步干扰拓扑连续性。为了解决这些问题，提出了TopoTTA。

Method: TopoTTA包括两个阶段：第一阶段通过Topological Meta Difference Convolutions（TopoMDCs）调整模型以适应跨域拓扑差异；第二阶段通过Topology Hard sample Generation（TopoHG）策略和伪标签预测对齐来提升拓扑连续性。

Result: 在四种场景和十个数据集上的广泛实验证明了TopoTTA在处理拓扑分布偏移方面的有效性，平均提高了31.81%的clDice分数。

Conclusion: TopoTTA是一种有效的测试时间适应框架，专门为TSS设计，能够显著提升在未见目标域中的性能表现，平均提高了31.81%的clDice分数。

Abstract: Tubular structure segmentation (TSS) is important for various applications,
such as hemodynamic analysis and route navigation. Despite significant progress
in TSS, domain shifts remain a major challenge, leading to performance
degradation in unseen target domains. Unlike other segmentation tasks, TSS is
more sensitive to domain shifts, as changes in topological structures can
compromise segmentation integrity, and variations in local features
distinguishing foreground from background (e.g., texture and contrast) may
further disrupt topological continuity. To address these challenges, we propose
Topology-enhanced Test-Time Adaptation (TopoTTA), the first test-time
adaptation framework designed specifically for TSS. TopoTTA consists of two
stages: Stage 1 adapts models to cross-domain topological discrepancies using
the proposed Topological Meta Difference Convolutions (TopoMDCs), which enhance
topological representation without altering pre-trained parameters; Stage 2
improves topological continuity by a novel Topology Hard sample Generation
(TopoHG) strategy and prediction alignment on hard samples with pseudo-labels
in the generated pseudo-break regions. Extensive experiments across four
scenarios and ten datasets demonstrate TopoTTA's effectiveness in handling
topological distribution shifts, achieving an average improvement of 31.81% in
clDice. TopoTTA also serves as a plug-and-play TTA solution for CNN-based TSS
models.

</details>


### [51] [LesiOnTime -- Joint Temporal and Clinical Modeling for Small Breast Lesion Segmentation in Longitudinal DCE-MRI](https://arxiv.org/abs/2508.00496)
*Mohammed Kamran,Maria Bernathova,Raoul Varga,Christian Singer,Zsuzsanna Bago-Horvath,Thomas Helbich,Georg Langs,Philipp Seeböck*

Main category: cs.CV

TL;DR: LesiOnTime方法通过整合纵向影像和BI-RADS评分，提升乳腺癌DCE-MRI小病变分割准确性，比现有方法高5% Dice。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法主要针对大病变，忽视了纵向和临床信息，而实际筛查中需对比时间点并考虑如BI-RADS评分等临床评估。

Method: 提出了一种新颖的3D分割方法LesiOnTime，包括时间先验注意力（TPA）块和BI-RADS一致性正则化（BCR）损失，以模拟临床诊断流程。

Result: 在DCE-MRI纵向数据集上，LesiOnTime比现有单时间点和纵向基线方法在Dice指标上高出5%。消融研究表明TPA和BCR均带来互补性能提升。

Conclusion: LesiOnTime方法通过整合纵向影像和BI-RADS评分，显著提升了小病变的分割准确性，验证了在乳腺癌筛查中融入时间和临床背景的重要性。

Abstract: Accurate segmentation of small lesions in Breast Dynamic Contrast-Enhanced
MRI (DCE-MRI) is critical for early cancer detection, especially in high-risk
patients. While recent deep learning methods have advanced lesion segmentation,
they primarily target large lesions and neglect valuable longitudinal and
clinical information routinely used by radiologists. In real-world screening,
detecting subtle or emerging lesions requires radiologists to compare across
timepoints and consider previous radiology assessments, such as the BI-RADS
score. We propose LesiOnTime, a novel 3D segmentation approach that mimics
clinical diagnostic workflows by jointly leveraging longitudinal imaging and
BIRADS scores. The key components are: (1) a Temporal Prior Attention (TPA)
block that dynamically integrates information from previous and current scans;
and (2) a BI-RADS Consistency Regularization (BCR) loss that enforces latent
space alignment for scans with similar radiological assessments, thus embedding
domain knowledge into the training process. Evaluated on a curated in-house
longitudinal dataset of high-risk patients with DCE-MRI, our approach
outperforms state-of-the-art single-timepoint and longitudinal baselines by 5%
in terms of Dice. Ablation studies demonstrate that both TPA and BCR contribute
complementary performance gains. These results highlight the importance of
incorporating temporal and clinical context for reliable early lesion
segmentation in real-world breast cancer screening. Our code is publicly
available at https://github.com/cirmuw/LesiOnTime

</details>


### [52] [SDMatte: Grafting Diffusion Models for Interactive Matting](https://arxiv.org/abs/2508.00443)
*Longfei Huang,Yu Liang,Hao Zhang,Jinwei Chen,Wei Dong,Lunde Chen,Wanyu Liu,Bo Li,Pengtao Jiang*

Main category: cs.CV

TL;DR: SDMatte是一种基于扩散模型的交互式抠图方法，通过视觉提示驱动和掩膜自注意力机制，显著提升了边缘细节的提取能力。


<details>
  <summary>Details</summary>
Motivation: 现有交互式抠图方法在边缘区域细节提取上表现不足，而扩散模型在复杂数据分布建模和纹理细节合成方面表现优异，因此探索其应用于交互式抠图。

Method: 利用扩散模型的强大先验知识，将文本驱动交互能力转化为视觉提示驱动交互能力；整合坐标嵌入和透明度嵌入到U-Net中；提出掩膜自注意力机制以聚焦视觉提示区域。

Result: 在多个数据集上的广泛实验表明，SDMatte在交互式抠图中表现优异。

Conclusion: SDMatte通过扩散模型驱动的交互式抠图方法，显著提升了边缘区域细节的提取能力，并通过实验验证了其有效性。

Abstract: Recent interactive matting methods have shown satisfactory performance in
capturing the primary regions of objects, but they fall short in extracting
fine-grained details in edge regions. Diffusion models trained on billions of
image-text pairs, demonstrate exceptional capability in modeling highly complex
data distributions and synthesizing realistic texture details, while exhibiting
robust text-driven interaction capabilities, making them an attractive solution
for interactive matting. To this end, we propose SDMatte, a diffusion-driven
interactive matting model, with three key contributions. First, we exploit the
powerful priors of diffusion models and transform the text-driven interaction
capability into visual prompt-driven interaction capability to enable
interactive matting. Second, we integrate coordinate embeddings of visual
prompts and opacity embeddings of target objects into U-Net, enhancing
SDMatte's sensitivity to spatial position information and opacity information.
Third, we propose a masked self-attention mechanism that enables the model to
focus on areas specified by visual prompts, leading to better performance.
Extensive experiments on multiple datasets demonstrate the superior performance
of our method, validating its effectiveness in interactive matting. Our code
and model are available at https://github.com/vivoCameraResearch/SDMatte.

</details>


### [53] [AutoDebias: Automated Framework for Debiasing Text-to-Image Models](https://arxiv.org/abs/2508.00445)
*Hongyi Cai,Mohammad Mahdinur Rahman,Mingkang Dong,Jie Li,Muxin Pu,Zhili Fang,Yinan Peng,Hanjun Luo,Yang Liu*

Main category: cs.CV

TL;DR: AutoDebias 是一种自动去偏框架，有效识别和减轻 T2I 模型中的社会偏见，无需先验知识，显著减少偏见输出且保持图像质量。


<details>
  <summary>Details</summary>
Motivation: T2I 模型常表现出性别或种族等社会偏见，现有方法难以处理微妙或重叠的偏见，因此需要一种无需先验知识的自动去偏方法。

Method: AutoDebias 利用视觉语言模型检测偏见视觉模式，并通过生成反映平衡表征的包容性替代提示来构建公平指南，这些指南驱动 CLIP 引导的训练过程。

Result: 在覆盖 25 种以上偏见场景的基准测试中，AutoDebias 以 91.6% 的准确率检测有害模式，将偏见输出从 90% 降至可忽略水平，同时保持原始模型的视觉保真度。

Conclusion: AutoDebias 是一种有效识别和减轻 T2I 模型中社会偏见的框架，无需预先了解具体偏见类型，显著减少了偏见输出，同时保持了图像质量和多样性。

Abstract: Text-to-Image (T2I) models generate high-quality images from text prompts but
often exhibit unintended social biases, such as gender or racial stereotypes,
even when these attributes are not mentioned. Existing debiasing methods work
well for simple or well-known cases but struggle with subtle or overlapping
biases. We propose AutoDebias, a framework that automatically identifies and
mitigates harmful biases in T2I models without prior knowledge of specific bias
types. Specifically, AutoDebias leverages vision-language models to detect
biased visual patterns and constructs fairness guides by generating inclusive
alternative prompts that reflect balanced representations. These guides drive a
CLIP-guided training process that promotes fairer outputs while preserving the
original model's image quality and diversity. Unlike existing methods,
AutoDebias effectively addresses both subtle stereotypes and multiple
interacting biases. We evaluate the framework on a benchmark covering over 25
bias scenarios, including challenging cases where multiple biases occur
simultaneously. AutoDebias detects harmful patterns with 91.6% accuracy and
reduces biased outputs from 90% to negligible levels, while preserving the
visual fidelity of the original model.

</details>


### [54] [CLIPTime: Time-Aware Multimodal Representation Learning from Images and Text](https://arxiv.org/abs/2508.00447)
*Anju Rani,Daniel Ortiz-Arroyo,Petar Durdevic*

Main category: cs.CV

TL;DR: CLIPTime 是基于 CLIP 的多任务框架，通过合成真菌生长数据集训练，能预测生长阶段和时间戳，适用于生物监测。


<details>
  <summary>Details</summary>
Motivation: 因现有视觉-语言模型（如 CLIP）在捕捉时间动态方面表现有限，需开发能预测生物生长阶段和时间戳的框架。

Method: 基于 CLIP 架构，提出了 CLIPTime 多模态多任务框架，通过联合学习视觉-文本嵌入，实现无需显式时间输入的时序推理。

Result: 实验结果表明，CLIPTime 能有效建模生物生长进程，并生成可解释的时间相关输出。

Conclusion: CLIPTime 成功建模了生物生长的时间动态，展示了视觉-语言模型在现实世界生物监测应用中的潜力。

Abstract: Understanding the temporal dynamics of biological growth is critical across
diverse fields such as microbiology, agriculture, and biodegradation research.
Although vision-language models like Contrastive Language Image Pretraining
(CLIP) have shown strong capabilities in joint visual-textual reasoning, their
effectiveness in capturing temporal progression remains limited. To address
this, we propose CLIPTime, a multimodal, multitask framework designed to
predict both the developmental stage and the corresponding timestamp of fungal
growth from image and text inputs. Built upon the CLIP architecture, our model
learns joint visual-textual embeddings and enables time-aware inference without
requiring explicit temporal input during testing. To facilitate training and
evaluation, we introduce a synthetic fungal growth dataset annotated with
aligned timestamps and categorical stage labels. CLIPTime jointly performs
classification and regression, predicting discrete growth stages alongside
continuous timestamps. We also propose custom evaluation metrics, including
temporal accuracy and regression error, to assess the precision of time-aware
predictions. Experimental results demonstrate that CLIPTime effectively models
biological progression and produces interpretable, temporally grounded outputs,
highlighting the potential of vision-language models in real-world biological
monitoring applications.

</details>


### [55] [Wukong Framework for Not Safe For Work Detection in Text-to-Image systems](https://arxiv.org/abs/2508.00591)
*Mingrui Liu,Sixiao Zhang,Cheng Long*

Main category: cs.CV

TL;DR: Wukong是一种高效的NSFW内容检测框架，利用扩散模型的中间输出和预训练参数，显著优于文本过滤器，与图像过滤器精度相当但更高效。


<details>
  <summary>Details</summary>
Motivation: 现有的NSFW内容外部防护措施存在不足：文本过滤器易受对抗性攻击，图像过滤器计算成本高且引入延迟。

Method: 基于扩散模型早期去噪步骤的中间输出和U-Net预训练的交叉注意力参数，提出了一种基于Transformer的NSFW检测框架Wukong。

Result: Wukong在提出的新数据集和两个公共基准上表现优异，实现了早期检测而不需要等待完整图像生成。

Conclusion: Wukong框架在NSFW内容检测中显著优于基于文本的防护措施，并与基于图像的过滤器精度相当，同时提供了更高的效率。

Abstract: Text-to-Image (T2I) generation is a popular AI-generated content (AIGC)
technology enabling diverse and creative image synthesis. However, some outputs
may contain Not Safe For Work (NSFW) content (e.g., violence), violating
community guidelines. Detecting NSFW content efficiently and accurately, known
as external safeguarding, is essential. Existing external safeguards fall into
two types: text filters, which analyze user prompts but overlook T2I
model-specific variations and are prone to adversarial attacks; and image
filters, which analyze final generated images but are computationally costly
and introduce latency. Diffusion models, the foundation of modern T2I systems
like Stable Diffusion, generate images through iterative denoising using a
U-Net architecture with ResNet and Transformer blocks. We observe that: (1)
early denoising steps define the semantic layout of the image, and (2)
cross-attention layers in U-Net are crucial for aligning text and image
regions. Based on these insights, we propose Wukong, a transformer-based NSFW
detection framework that leverages intermediate outputs from early denoising
steps and reuses U-Net's pre-trained cross-attention parameters. Wukong
operates within the diffusion process, enabling early detection without waiting
for full image generation. We also introduce a new dataset containing prompts,
seeds, and image-specific NSFW labels, and evaluate Wukong on this and two
public benchmarks. Results show that Wukong significantly outperforms
text-based safeguards and achieves comparable accuracy of image filters, while
offering much greater efficiency.

</details>


### [56] [PIF-Net: Ill-Posed Prior Guided Multispectral and Hyperspectral Image Fusion via Invertible Mamba and Fusion-Aware LoRA](https://arxiv.org/abs/2508.00453)
*Baisong Li,Xingwang Wang,Haixiao Xu*

Main category: cs.CV

TL;DR: PIF-Net通过可逆Mamba架构和动态校准模块，有效解决了多光谱与高光谱图像融合的病态问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多光谱与高光谱图像融合（MHIF）因光谱与空间信息的固有权衡及观测数据有限而具有病态性，现有研究未能有效解决数据未对齐导致的病态问题。

Method: 提出了一种基于可逆Mamba架构的融合框架PIF-Net，设计了Fusion-Aware Low-Rank Adaptation模块动态校准光谱与空间特征。

Result: PIF-Net在多个基准数据集上显著优于当前最优方法，同时保持了模型的高效性。

Conclusion: PIF-Net通过引入ill-posed priors和创新的可逆Mamba架构，显著提升了多光谱和高光谱图像融合的性能，同时在多个基准数据集上验证了其优越性。

Abstract: The goal of multispectral and hyperspectral image fusion (MHIF) is to
generate high-quality images that simultaneously possess rich spectral
information and fine spatial details. However, due to the inherent trade-off
between spectral and spatial information and the limited availability of
observations, this task is fundamentally ill-posed. Previous studies have not
effectively addressed the ill-posed nature caused by data misalignment. To
tackle this challenge, we propose a fusion framework named PIF-Net, which
explicitly incorporates ill-posed priors to effectively fuse multispectral
images and hyperspectral images. To balance global spectral modeling with
computational efficiency, we design a method based on an invertible Mamba
architecture that maintains information consistency during feature
transformation and fusion, ensuring stable gradient flow and process
reversibility. Furthermore, we introduce a novel fusion module called the
Fusion-Aware Low-Rank Adaptation module, which dynamically calibrates spectral
and spatial features while keeping the model lightweight. Extensive experiments
on multiple benchmark datasets demonstrate that PIF-Net achieves significantly
better image restoration performance than current state-of-the-art methods
while maintaining model efficiency.

</details>


### [57] [Semantic and Temporal Integration in Latent Diffusion Space for High-Fidelity Video Super-Resolution](https://arxiv.org/abs/2508.00471)
*Yiwen Wang,Xinning Chai,Yuhong Zhang,Zhengxue Cheng,Jun Zhao,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: SeTe-VSR通过结合语义和时空引导，在视频超分辨率任务中实现了细节恢复和时间一致性的平衡，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频超分辨率模型在生成过程中难以同时实现高保真度对齐低分辨率输入和保持帧间时间一致性，因此需要一种更有效的方法来解决这些挑战。

Method: 提出了一种新颖的语义和时间引导视频超分辨率方法（SeTe-VSR），通过在潜在扩散空间中结合高层次语义信息及时空信息，实现细节恢复和时间一致性的平衡。

Result: 实验表明，SeTe-VSR在细节恢复和感知质量上显著优于现有方法，能够有效提升视频超分辨率的效果。

Conclusion: SeTe-VSR方法在视频超分辨率任务中表现出色，不仅在细节恢复和感知质量上优于现有方法，还能有效平衡细节恢复和时间一致性。

Abstract: Recent advancements in video super-resolution (VSR) models have demonstrated
impressive results in enhancing low-resolution videos. However, due to
limitations in adequately controlling the generation process, achieving high
fidelity alignment with the low-resolution input while maintaining temporal
consistency across frames remains a significant challenge. In this work, we
propose Semantic and Temporal Guided Video Super-Resolution (SeTe-VSR), a novel
approach that incorporates both semantic and temporal-spatio guidance in the
latent diffusion space to address these challenges. By incorporating high-level
semantic information and integrating spatial and temporal information, our
approach achieves a seamless balance between recovering intricate details and
ensuring temporal coherence. Our method not only preserves high-reality visual
content but also significantly enhances fidelity. Extensive experiments
demonstrate that SeTe-VSR outperforms existing methods in terms of detail
recovery and perceptual quality, highlighting its effectiveness for complex
video super-resolution tasks.

</details>


### [58] [Backdoor Attacks on Deep Learning Face Detection](https://arxiv.org/abs/2508.00620)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi*

Main category: cs.CV

TL;DR: 论文展示了针对面部检测系统的对象生成攻击和地标偏移攻击，并提出了缓解措施。


<details>
  <summary>Details</summary>
Motivation: 研究在非约束环境下工作的面部识别系统，因光照、姿态等变化带来的挑战，以及面部检测模块的潜在漏洞。

Method: 通过对象生成攻击和地标偏移攻击，研究面部检测系统的脆弱性。

Result: 证明了对象生成攻击和地标偏移攻击对回归边界框和地标坐标的面部检测任务的有效性。

Conclusion: 该论文提出了针对面部检测系统的对象生成攻击（Face Generation Attacks）和首次展示的地标偏移攻击（Landmark Shift Attack），并提供了针对这些漏洞的缓解措施。

Abstract: Face Recognition Systems that operate in unconstrained environments capture
images under varying conditions,such as inconsistent lighting, or diverse face
poses. These challenges require including a Face Detection module that
regresses bounding boxes and landmark coordinates for proper Face Alignment.
This paper shows the effectiveness of Object Generation Attacks on Face
Detection, dubbed Face Generation Attacks, and demonstrates for the first time
a Landmark Shift Attack that backdoors the coordinate regression task performed
by face detectors. We then offer mitigations against these vulnerabilities.

</details>


### [59] [HyPCV-Former: Hyperbolic Spatio-Temporal Transformer for 3D Point Cloud Video Anomaly Detection](https://arxiv.org/abs/2508.00473)
*Jiaping Cao,Kangkang Zhou,Juan Du*

Main category: cs.CV

TL;DR: 提出HyPCV-Former，一种基于双曲时空变换器的方法，用于3D点云视频的异常检测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于欧几里得表示的方法在捕捉层次化事件结构和时空连续性方面存在局限性。

Method: 提出了一种新颖的双曲时空变换器HyPCV-Former，利用洛伦兹双曲空间嵌入点云序列的每帧空间特征，并引入双曲多头自注意力机制（HMHA）来建模时间动态。

Result: HyPCV-Former在TIMo和DAD数据集上分别实现了7%和5.6%的性能提升。

Conclusion: HyPCV-Former通过在完整的洛伦兹空间中进行特征转换和异常评分，显著提升了3D点云视频中的异常检测性能，在多个数据集上达到了最先进的水平。

Abstract: Video anomaly detection is a fundamental task in video surveillance, with
broad applications in public safety and intelligent monitoring systems.
Although previous methods leverage Euclidean representations in RGB or depth
domains, such embeddings are inherently limited in capturing hierarchical event
structures and spatio-temporal continuity. To address these limitations, we
propose HyPCV-Former, a novel hyperbolic spatio-temporal transformer for
anomaly detection in 3D point cloud videos. Our approach first extracts
per-frame spatial features from point cloud sequences via point cloud
extractor, and then embeds them into Lorentzian hyperbolic space, which better
captures the latent hierarchical structure of events. To model temporal
dynamics, we introduce a hyperbolic multi-head self-attention (HMHA) mechanism
that leverages Lorentzian inner products and curvature-aware softmax to learn
temporal dependencies under non-Euclidean geometry. Our method performs all
feature transformations and anomaly scoring directly within full Lorentzian
space rather than via tangent space approximation. Extensive experiments
demonstrate that HyPCV-Former achieves state-of-the-art performance across
multiple anomaly categories, with a 7\% improvement on the TIMo dataset and a
5.6\% gain on the DAD dataset compared to benchmarks. The code will be released
upon paper acceptance.

</details>


### [60] [LAMIC: Layout-Aware Multi-Image Composition via Scalability of Multimodal Diffusion Transformer](https://arxiv.org/abs/2508.00477)
*Yuzhuo Chen,Zehua Ma,Jianhua Wang,Kai Kang,Shunyu Yao,Weiming Zhang*

Main category: cs.CV

TL;DR: LAMIC是一种布局感知多图像合成框架，通过GIA和RMA两种注意力机制，无需训练即可将单参考扩散模型扩展到多参考场景，实现了布局控制、背景一致性和身份保持的卓越性能。


<details>
  <summary>Details</summary>
Motivation: 在可控图像合成中，从多个参考生成具有空间布局意识的连贯且一致的图像仍是一个开放挑战。

Method: LAMIC基于MMDiT模型，引入了两种即插即用的注意力机制：1) Group Isolation Attention (GIA) 用于增强实体解耦；2) Region-Modulated Attention (RMA) 用于实现布局感知生成。

Result: LAMIC在大多数主要指标上实现了最先进的性能：在所有设置中，ID-S、BG-S、IN-R和AVG得分均优于现有的多参考基线，并在复杂合成任务中实现了最佳DPG。

Conclusion: LAMIC通过引入GIA和RMA两种注意力机制，首次在无需训练的情况下将单参考扩散模型扩展到多参考场景，展示了强大的零样本泛化能力，并为可控多图像合成建立了新的无训练范式。

Abstract: In controllable image synthesis, generating coherent and consistent images
from multiple references with spatial layout awareness remains an open
challenge. We present LAMIC, a Layout-Aware Multi-Image Composition framework
that, for the first time, extends single-reference diffusion models to
multi-reference scenarios in a training-free manner. Built upon the MMDiT
model, LAMIC introduces two plug-and-play attention mechanisms: 1) Group
Isolation Attention (GIA) to enhance entity disentanglement; and 2)
Region-Modulated Attention (RMA) to enable layout-aware generation. To
comprehensively evaluate model capabilities, we further introduce three
metrics: 1) Inclusion Ratio (IN-R) and Fill Ratio (FI-R) for assessing layout
control; and 2) Background Similarity (BG-S) for measuring background
consistency. Extensive experiments show that LAMIC achieves state-of-the-art
performance across most major metrics: it consistently outperforms existing
multi-reference baselines in ID-S, BG-S, IN-R and AVG scores across all
settings, and achieves the best DPG in complex composition tasks. These results
demonstrate LAMIC's superior abilities in identity keeping, background
preservation, layout control, and prompt-following, all achieved without any
training or fine-tuning, showcasing strong zero-shot generalization ability. By
inheriting the strengths of advanced single-reference models and enabling
seamless extension to multi-image scenarios, LAMIC establishes a new
training-free paradigm for controllable multi-image composition. As foundation
models continue to evolve, LAMIC's performance is expected to scale
accordingly. Our implementation is available at:
https://github.com/Suchenl/LAMIC.

</details>


### [61] [D3: Training-Free AI-Generated Video Detection Using Second-Order Features](https://arxiv.org/abs/2508.00701)
*Chende Zheng,Ruiqi suo,Chenhao Lin,Zhengyu Zhao,Le Yang,Shuai Liu,Minghui Yang,Cong Wang,Chao Shen*

Main category: cs.CV

TL;DR: D3是一种无需训练的视频检测方法，通过二阶时间差异显著提升检测性能，计算高效且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对合成视频中时间伪影的探索不足，需开发更有效的检测技术以应对高保真AI生成视频的泛滥。

Method: 提出了Detection by Difference of Differences (D3)方法，基于牛顿力学下的二阶动力学分析，专注于时间伪影检测。

Result: 在4个开源数据集（40个子集）上验证了D3的优越性，如在Gen-Video上比之前最佳方法提升10.39%的mAP。

Conclusion: D3方法通过利用二阶时间差异，显著提高了AI生成视频的检测性能，并在计算效率和鲁棒性方面表现出色。

Abstract: The evolution of video generation techniques, such as Sora, has made it
increasingly easy to produce high-fidelity AI-generated videos, raising public
concern over the dissemination of synthetic content. However, existing
detection methodologies remain limited by their insufficient exploration of
temporal artifacts in synthetic videos. To bridge this gap, we establish a
theoretical framework through second-order dynamical analysis under Newtonian
mechanics, subsequently extending the Second-order Central Difference features
tailored for temporal artifact detection. Building on this theoretical
foundation, we reveal a fundamental divergence in second-order feature
distributions between real and AI-generated videos. Concretely, we propose
Detection by Difference of Differences (D3), a novel training-free detection
method that leverages the above second-order temporal discrepancies. We
validate the superiority of our D3 on 4 open-source datasets (Gen-Video,
VideoPhy, EvalCrafter, VidProM), 40 subsets in total. For example, on GenVideo,
D3 outperforms the previous best method by 10.39% (absolute) mean Average
Precision. Additional experiments on time cost and post-processing operations
demonstrate D3's exceptional computational efficiency and strong robust
performance. Our code is available at https://github.com/Zig-HS/D3.

</details>


### [62] [SAMSA 2.0: Prompting Segment Anything with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation](https://arxiv.org/abs/2508.00493)
*Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou*

Main category: cs.CV

TL;DR: SAMSA 2.0结合光谱和空间信息，提升高光谱医学图像分割性能，无需重新训练即超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱医学图像分割中因数据稀疏和噪声导致的性能下降问题，提升分割的准确性和泛化能力。

Method: 提出了一个交互式分割框架，结合光谱角度提示和空间线索，指导Segment Anything Model（SAM）进行分割。

Result: 在不重新训练的情况下，SAMSA 2.0比仅使用RGB的模型Dice分数提高了3.8%，比之前的光谱融合方法提高了3.1%。

Conclusion: SAMSA 2.0通过引入光谱角度提示，结合光谱和空间信息，显著提升了高光谱医学图像的分割精度和鲁棒性，无需重新训练即可在多种数据集上超越现有方法。

Abstract: We present SAMSA 2.0, an interactive segmentation framework for hyperspectral
medical imaging that introduces spectral angle prompting to guide the Segment
Anything Model (SAM) using spectral similarity alongside spatial cues. This
early fusion of spectral information enables more accurate and robust
segmentation across diverse spectral datasets. Without retraining, SAMSA 2.0
achieves up to +3.8% higher Dice scores compared to RGB-only models and up to
+3.1% over prior spectral fusion methods. Our approach enhances few-shot and
zero-shot performance, demonstrating strong generalization in challenging
low-data and noisy scenarios common in clinical imaging.

</details>


### [63] [Is It Really You? Exploring Biometric Verification Scenarios in Photorealistic Talking-Head Avatar Videos](https://arxiv.org/abs/2508.00748)
*Laura Pedrouzo-Rodriguez,Pedro Delgado-DeRobles,Luis F. Gomez,Ruben Tolosana,Ruben Vera-Rodriguez,Aythami Morales,Julian Fierrez*

Main category: cs.CV

TL;DR: 本文研究了虚拟化身中的生物特征验证问题，提出了一种基于面部运动模式的轻量级身份验证方法，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 探讨在虚拟化身介导的场景中，面部运动模式是否可以作为可靠的行为生物特征来验证身份，以应对虚拟化身带来的安全风险。

Method: 引入了一个新的虚拟化身视频数据集，并提出了一个轻量级的、可解释的时空图卷积网络架构，结合时间注意力池化，仅使用面部关键点来建模动态面部表情。

Result: 实验结果表明，面部运动线索能够实现有意义的身份验证，AUC值接近80%。

Conclusion: 面部运动模式可以作为可靠的行为生物特征进行身份验证，在虚拟化身交流系统中具有实际应用价值。

Abstract: Photorealistic talking-head avatars are becoming increasingly common in
virtual meetings, gaming, and social platforms. These avatars allow for more
immersive communication, but they also introduce serious security risks. One
emerging threat is impersonation: an attacker can steal a user's
avatar-preserving their appearance and voice-making it nearly impossible to
detect its fraudulent usage by sight or sound alone. In this paper, we explore
the challenge of biometric verification in such avatar-mediated scenarios. Our
main question is whether an individual's facial motion patterns can serve as
reliable behavioral biometrics to verify their identity when the avatar's
visual appearance is a facsimile of its owner. To answer this question, we
introduce a new dataset of realistic avatar videos created using a
state-of-the-art one-shot avatar generation model, GAGAvatar, with genuine and
impostor avatar videos. We also propose a lightweight, explainable
spatio-temporal Graph Convolutional Network architecture with temporal
attention pooling, that uses only facial landmarks to model dynamic facial
gestures. Experimental results demonstrate that facial motion cues enable
meaningful identity verification with AUC values approaching 80%. The proposed
benchmark and biometric system are available for the research community in
order to bring attention to the urgent need for more advanced behavioral
biometric defenses in avatar-based communication systems.

</details>


### [64] [Sample-Aware Test-Time Adaptation for Medical Image-to-Image Translation](https://arxiv.org/abs/2508.00766)
*Irene Iele,Francesco Di Feola,Valerio Guarrasi,Paolo Soda*

Main category: cs.CV

TL;DR: 提出了一种动态调整的测试时间适应框架，通过样本特定的调整提升了医学图像翻译模型的性能，特别是在处理分布外样本时。


<details>
  <summary>Details</summary>
Motivation: 解决图像到图像翻译在处理分布外样本时性能下降的问题。

Method: 提出了一个包含重建模块（用于量化域偏移）和动态适应块（选择性地修改预训练翻译模型的内部特征）的测试时间适应（TTA）框架。

Result: 在两个医学图像到图像翻译任务上（低剂量CT去噪和T1到T2 MRI转换）均显示出比基线翻译模型和先前的TTA方法更一致的改进。

Conclusion: 动态、样本特定的调整为提高模型在现实场景中的韧性提供了一条有前景的路径。

Abstract: Image-to-image translation has emerged as a powerful technique in medical
imaging, enabling tasks such as image denoising and cross-modality conversion.
However, it suffers from limitations in handling out-of-distribution samples
without causing performance degradation. To address this limitation, we propose
a novel Test-Time Adaptation (TTA) framework that dynamically adjusts the
translation process based on the characteristics of each test sample. Our
method introduces a Reconstruction Module to quantify the domain shift and a
Dynamic Adaptation Block that selectively modifies the internal features of a
pretrained translation model to mitigate the shift without compromising the
performance on in-distribution samples that do not require adaptation. We
evaluate our approach on two medical image-to-image translation tasks: low-dose
CT denoising and T1 to T2 MRI translation, showing consistent improvements over
both the baseline translation model without TTA and prior TTA methods. Our
analysis highlights the limitations of the state-of-the-art that uniformly
apply the adaptation to both out-of-distribution and in-distribution samples,
demonstrating that dynamic, sample-specific adjustment offers a promising path
to improve model resilience in real-world scenarios. The code is available at:
https://github.com/cosbidev/Sample-Aware_TTA.

</details>


### [65] [Leveraging Convolutional and Graph Networks for an Unsupervised Remote Sensing Labelling Tool](https://arxiv.org/abs/2508.00506)
*Tulsi Patel,Mark W. Jones,Thomas Redfern*

Main category: cs.CV

TL;DR: 本文开发了一种无监督的管道方法，利用卷积和图神经网络分割Sentinel-2卫星图像，实现了更鲁棒的图像比较和细粒度标注，减少了对预标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 遥感图像的标注通常需要专家分析，耗时且成本高。现有的标注工具依赖于预标注数据进行训练，以标记新的未见数据。本文旨在开发一种无监督的管道方法，减少对预标注数据的依赖。

Method: 采用卷积神经网络和图神经网络进行分割，将图像分割为基于颜色和空间相似性的同质像素区域，图神经网络用于聚合周围片段的信息，使特征表示能够编码局部邻域信息同时保留自身局部信息。

Result: 该方法减少了标注工具中的异常值，允许用户在更细粒度上进行标注，并在编码空间内形成旋转不变的语义关系。

Conclusion: 本文提出了一种无监督的管道方法，用于在Sentinel-2卫星图像中寻找和标记具有相似上下文和内容的区域，通过结合卷积和图神经网络的分割技术，克服了先前方法的限制，提供了一个更鲁棒的图像比较特征空间。

Abstract: Machine learning for remote sensing imaging relies on up-to-date and accurate
labels for model training and testing. Labelling remote sensing imagery is time
and cost intensive, requiring expert analysis. Previous labelling tools rely on
pre-labelled data for training in order to label new unseen data. In this work,
we define an unsupervised pipeline for finding and labelling geographical areas
of similar context and content within Sentinel-2 satellite imagery. Our
approach removes limitations of previous methods by utilising segmentation with
convolutional and graph neural networks to encode a more robust feature space
for image comparison. Unlike previous approaches we segment the image into
homogeneous regions of pixels that are grouped based on colour and spatial
similarity. Graph neural networks are used to aggregate information about the
surrounding segments enabling the feature representation to encode the local
neighbourhood whilst preserving its own local information. This reduces
outliers in the labelling tool, allows users to label at a granular level, and
allows a rotationally invariant semantic relationship at the image level to be
formed within the encoding space.

</details>


### [66] [Fine-grained Spatiotemporal Grounding on Egocentric Videos](https://arxiv.org/abs/2508.00518)
*Shuo Liang,Yiwu Zhong,Zi-Yuan Hu,Yeyao Tao,Liwei Wang*

Main category: cs.CV

TL;DR: 研究提出首个像素级自我中心视频时空定位基准EgoMask，通过自动标注流程构建，并创建训练数据集EgoMask-Train，实验表明微调可提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频在增强现实和机器人技术等应用中日益重要，但现有研究主要关注他中心视频，自我中心视频的时空定位仍待探索。

Method: 通过系统分析自我中心与他中心视频的差异，提出自动标注流程构建EgoMask基准，并创建大规模训练数据集EgoMask-Train。

Result: 实验显示现有时空定位模型在EgoMask上表现不佳，但通过微调可显著提升性能，同时保持在他中心数据集上的表现。

Conclusion: 本研究为提升自我中心视频理解提供了关键资源和洞见，包括EgoMask基准和EgoMask-Train数据集，实验表明现有模型在EgoMask上表现不佳，但通过微调可显著提升性能。

Abstract: Spatiotemporal video grounding aims to localize target entities in videos
based on textual queries. While existing research has made significant progress
in exocentric videos, the egocentric setting remains relatively underexplored,
despite its growing importance in applications such as augmented reality and
robotics. In this work, we conduct a systematic analysis of the discrepancies
between egocentric and exocentric videos, revealing key challenges such as
shorter object durations, sparser trajectories, smaller object sizes, and
larger positional shifts. To address these challenges, we introduce EgoMask,
the first pixel-level benchmark for fine-grained spatiotemporal grounding in
egocentric videos. It is constructed by our proposed automatic annotation
pipeline, which annotates referring expressions and object masks across short-,
medium-, and long-term videos. Additionally, we create EgoMask-Train, a
large-scale training dataset to facilitate model development. Experiments
demonstrate that the state-of-the-art spatiotemporal grounding models perform
poorly on our benchmark EgoMask, but fine-tuning on EgoMask-Train yields
significant improvements, while preserving performance on exocentric datasets.
Our work thus provides essential resources and insights for advancing
egocentric video understanding. Our code is available at
https://github.com/LaVi-Lab/EgoMask .

</details>


### [67] [EPANet: Efficient Path Aggregation Network for Underwater Fish Detection](https://arxiv.org/abs/2508.00528)
*Jinsong Yang,Zeyuan Hu,Yichen Li*

Main category: cs.CV

TL;DR: EPANet是一种高效的水下鱼类检测网络，通过创新的路径聚合和多尺度瓶颈设计，实现了高精度和轻量化的检测性能。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测（UFD）由于目标分辨率低、背景干扰严重以及目标与周围环境视觉相似度高，一直是计算机视觉中的挑战性任务。现有方法主要关注局部特征增强或引入复杂的注意力机制，但往往导致模型复杂度增加和效率降低。

Method: EPANet由两个关键组件组成：高效的路径聚合特征金字塔网络（EPA-FPN）和多尺度多样化分割短路径瓶颈（MS-DDSP瓶颈）。EPA-FPN通过跨尺度的长程跳跃连接提升语义-空间互补性，而MS-DDSP瓶颈通过更细粒度的特征分割和多样化卷积操作增加局部特征的多样性和表示能力。

Result: EPANet在基准UFD数据集上表现出色，检测精度和推理速度均优于现有方法，且参数复杂度相当或更低。

Conclusion: EPANet在基准UFD数据集上的实验表明，其在检测精度和推理速度上优于现有方法，同时保持了相当的参数复杂度。

Abstract: Underwater fish detection (UFD) remains a challenging task in computer vision
due to low object resolution, significant background interference, and high
visual similarity between targets and surroundings. Existing approaches
primarily focus on local feature enhancement or incorporate complex attention
mechanisms to highlight small objects, often at the cost of increased model
complexity and reduced efficiency. To address these limitations, we propose an
efficient path aggregation network (EPANet), which leverages complementary
feature integration to achieve accurate and lightweight UFD. EPANet consists of
two key components: an efficient path aggregation feature pyramid network
(EPA-FPN) and a multi-scale diverse-division short path bottleneck (MS-DDSP
bottleneck). The EPA-FPN introduces long-range skip connections across
disparate scales to improve semantic-spatial complementarity, while cross-layer
fusion paths are adopted to enhance feature integration efficiency. The MS-DDSP
bottleneck extends the conventional bottleneck structure by introducing
finer-grained feature division and diverse convolutional operations, thereby
increasing local feature diversity and representation capacity. Extensive
experiments on benchmark UFD datasets demonstrate that EPANet outperforms
state-of-the-art methods in terms of detection accuracy and inference speed,
while maintaining comparable or even lower parameter complexity.

</details>


### [68] [Video Color Grading via Look-Up Table Generation](https://arxiv.org/abs/2508.00548)
*Seunghyun Shin,Dongmin Shin,Jisu Shin,Hae-Gon Jeon,Joon-Young Lee*

Main category: cs.CV

TL;DR: 本文提出了一种基于参考和扩散模型的视频色彩分级框架，通过LUT实现色彩对齐，并结合文本提示增强用户偏好，实验证明其高效且易用。


<details>
  <summary>Details</summary>
Motivation: 视频色彩分级通常需要专业技能，本文旨在简化这一复杂过程，使其更易用且高效。

Method: 采用扩散模型生成查找表（LUT）以实现参考场景与输入视频的色彩属性对齐，并通过训练目标确保高层次特征（如外观、情绪）相似。

Result: 实验结果表明，该方法能保持视频帧结构细节不丢失，并实现快速推理，用户研究进一步验证了其效果。

Conclusion: 本文提出的基于参考和扩散模型的视频色彩分级框架，通过生成查找表（LUT）实现色彩属性对齐，并结合用户偏好文本提示进行低层次特征增强，实验证明了其有效性。

Abstract: Different from color correction and transfer, color grading involves
adjusting colors for artistic or storytelling purposes in a video, which is
used to establish a specific look or mood. However, due to the complexity of
the process and the need for specialized editing skills, video color grading
remains primarily the domain of professional colorists. In this paper, we
present a reference-based video color grading framework. Our key idea is
explicitly generating a look-up table (LUT) for color attribute alignment
between reference scenes and input video via a diffusion model. As a training
objective, we enforce that high-level features of the reference scenes like
look, mood, and emotion should be similar to that of the input video. Our
LUT-based approach allows for color grading without any loss of structural
details in the whole video frames as well as achieving fast inference. We
further build a pipeline to incorporate a user-preference via text prompts for
low-level feature enhancement such as contrast and brightness, etc.
Experimental results, including extensive user studies, demonstrate the
effectiveness of our approach for video color grading. Codes are publicly
available at https://github.com/seunghyuns98/VideoColorGrading.

</details>


### [69] [Your other Left! Vision-Language Models Fail to Identify Relative Positions in Medical Images](https://arxiv.org/abs/2508.00549)
*Daniel Wolf,Heiko Hillenhagen,Billurvan Taskin,Alex Bäuerle,Meinrad Beer,Michael Götz,Timo Ropinski*

Main category: cs.CV

TL;DR: 研究发现当前VLMs在医学图像中判断相对位置的能力不足，依赖先验知识而非图像内容，提出MIRP数据集以推动研究。


<details>
  <summary>Details</summary>
Motivation: 临床决策依赖于对解剖结构相对位置的理解，但VLMs在此任务上的能力尚未充分探索。

Method: 评估了GPT-4o、Llama3.2、Pixtral和JanusPro等先进VLMs的能力，并研究了视觉提示（如字母数字或彩色标记）对性能的影响。

Result: 所有模型均无法完成基础任务，视觉提示仅带来有限改进，医学图像上的表现显著低于自然图像。

Conclusion: VLMs在医学图像中的相对位置判断能力不足，主要依赖先验解剖学知识而非图像内容，导致错误结论。为了促进该领域研究，作者引入了MIRP基准数据集。

Abstract: Clinical decision-making relies heavily on understanding relative positions
of anatomical structures and anomalies. Therefore, for Vision-Language Models
(VLMs) to be applicable in clinical practice, the ability to accurately
determine relative positions on medical images is a fundamental prerequisite.
Despite its importance, this capability remains highly underexplored. To
address this gap, we evaluate the ability of state-of-the-art VLMs, GPT-4o,
Llama3.2, Pixtral, and JanusPro, and find that all models fail at this
fundamental task. Inspired by successful approaches in computer vision, we
investigate whether visual prompts, such as alphanumeric or colored markers
placed on anatomical structures, can enhance performance. While these markers
provide moderate improvements, results remain significantly lower on medical
images compared to observations made on natural images. Our evaluations suggest
that, in medical imaging, VLMs rely more on prior anatomical knowledge than on
actual image content for answering relative position questions, often leading
to incorrect conclusions. To facilitate further research in this area, we
introduce the MIRP , Medical Imaging Relative Positioning, benchmark dataset,
designed to systematically evaluate the capability to identify relative
positions in medical images.

</details>


### [70] [DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification](https://arxiv.org/abs/2508.00552)
*Chihan Huang,Belal Alsinglawi,Islam Al-qudah*

Main category: cs.CV

TL;DR: DBLP 是一种高效扩散桥蒸馏对抗净化框架，通过噪声桥对齐和语义增强技术，实现了实时净化并达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络（DNNs）取得了显著成功，但其对对抗扰动的敏感性仍是一个关键漏洞。现有扩散净化方法因需密集迭代去噪而难以实际部署。

Method: DBLP 通过噪声桥蒸馏目标构建对抗噪声分布与干净数据分布之间的对齐，并结合自适应语义增强技术（多尺度金字塔边缘图融合）指导净化过程。

Result: 实验表明，DBLP 在多个数据集上实现了最先进的鲁棒精度、优异的图像质量，且推理时间仅约0.2秒。

Conclusion: DBLP 提出了一种高效且新颖的扩散桥蒸馏净化方法，显著提升了对抗净化的实时性和鲁棒性，为实际部署提供了可行方案。

Abstract: Recent advances in deep neural networks (DNNs) have led to remarkable success
across a wide range of tasks. However, their susceptibility to adversarial
perturbations remains a critical vulnerability. Existing diffusion-based
adversarial purification methods often require intensive iterative denoising,
severely limiting their practical deployment. In this paper, we propose
Diffusion Bridge Distillation for Purification (DBLP), a novel and efficient
diffusion-based framework for adversarial purification. Central to our approach
is a new objective, noise bridge distillation, which constructs a principled
alignment between the adversarial noise distribution and the clean data
distribution within a latent consistency model (LCM). To further enhance
semantic fidelity, we introduce adaptive semantic enhancement, which fuses
multi-scale pyramid edge maps as conditioning input to guide the purification
process. Extensive experiments across multiple datasets demonstrate that DBLP
achieves state-of-the-art (SOTA) robust accuracy, superior image quality, and
around 0.2s inference time, marking a significant step toward real-time
adversarial purification.

</details>


### [71] [HiPrune: Training-Free Visual Token Pruning via Hierarchical Attention in Vision-Language Models](https://arxiv.org/abs/2508.00553)
*Jizhihui Liu,Feiyi Du,Guangdao Zhu,Niu Lian,Jun Li,Bin Chen*

Main category: cs.CV

TL;DR: HiPrune 是一种无需训练的视觉令牌剪枝框架，通过分层注意力机制选择关键令牌，显著提升推理效率并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）因编码图像为长序列视觉令牌而导致计算开销大、推理效率低，HiPrune 旨在解决这一问题。

Method: HiPrune 通过分析视觉编码器中不同层的注意力机制，选择三种信息丰富的令牌：锚令牌、缓冲令牌和注册令牌，以实现高效的令牌剪枝。

Result: 实验表明，HiPrune 在 LLaVA-1.5、LLaVA-NeXT 和 Qwen2.5-VL 上实现了最先进的剪枝性能，仅用 33.3% 的令牌即可保留 99.3% 的任务准确性，同时减少推理 FLOPs 和延迟高达 9 倍。

Conclusion: HiPrune 是一种无需训练且模型无关的视觉令牌剪枝框架，利用视觉编码器中的分层注意力结构，显著提升了推理效率，同时保持了高任务准确性。

Abstract: Vision-Language Models (VLMs) encode images into lengthy sequences of visual
tokens, leading to excessive computational overhead and limited inference
efficiency. While prior efforts prune or merge tokens to address this issue,
they often rely on special tokens (e.g., CLS) or require task-specific
training, hindering scalability across architectures. In this paper, we propose
HiPrune, a training-free and model-agnostic token Pruning framework that
exploits the Hierarchical attention structure within vision encoders. We
identify that middle layers attend to object-centric regions, while deep layers
capture global contextual features. Based on this observation, HiPrune selects
three types of informative tokens: (1) Anchor tokens with high attention in
object-centric layers, (2) Buffer tokens adjacent to anchors for spatial
continuity, and (3) Register tokens with strong attention in deep layers for
global summarization. Our method requires no retraining and integrates
seamlessly with any ViT-based VLM. Extensive experiments on LLaVA-1.5,
LLaVA-NeXT, and Qwen2.5-VL demonstrate that HiPrune achieves state-of-the-art
pruning performance, preserving up to 99.3% task accuracy with only 33.3%
tokens, and maintaining 99.5% accuracy with just 11.1% tokens. Meanwhile, it
reduces inference FLOPs and latency by up to 9$\times$, showcasing strong
generalization across models and tasks. Code is available at
https://github.com/Danielement321/HiPrune.

</details>


### [72] [Training-Free Class Purification for Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2508.00557)
*Qi Chen,Lingxiao Yang,Yun Chen,Nailong Zhao,Jianhuang Lai,Jie Shao,Xiaohua Xie*

Main category: cs.CV

TL;DR: FreeCP是一种无需训练的类别纯化框架，通过净化语义类别和纠正冗余与模糊性错误，显著提升了开放词汇语义分割的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的无需训练方法忽视了类别冗余和视觉语言模糊性带来的挑战，导致次优的类别激活图和亲和力精炼激活图。

Method: FreeCP是一种无需训练的类别纯化框架，专注于净化语义类别并纠正由冗余和模糊性引起的错误。

Result: 在八个基准测试中验证了FreeCP的有效性，结果显示其显著提升了分割性能。

Conclusion: FreeCP作为一种即插即用的模块，与其他OVSS方法结合时显著提升了分割性能。

Abstract: Fine-tuning pre-trained vision-language models has emerged as a powerful
approach for enhancing open-vocabulary semantic segmentation (OVSS). However,
the substantial computational and resource demands associated with training on
large datasets have prompted interest in training-free methods for OVSS.
Existing training-free approaches primarily focus on modifying model
architectures and generating prototypes to improve segmentation performance.
However, they often neglect the challenges posed by class redundancy, where
multiple categories are not present in the current test image, and
visual-language ambiguity, where semantic similarities among categories create
confusion in class activation. These issues can lead to suboptimal class
activation maps and affinity-refined activation maps. Motivated by these
observations, we propose FreeCP, a novel training-free class purification
framework designed to address these challenges. FreeCP focuses on purifying
semantic categories and rectifying errors caused by redundancy and ambiguity.
The purified class representations are then leveraged to produce final
segmentation predictions. We conduct extensive experiments across eight
benchmarks to validate FreeCP's effectiveness. Results demonstrate that FreeCP,
as a plug-and-play module, significantly boosts segmentation performance when
combined with other OVSS methods.

</details>


### [73] [Guiding Diffusion-Based Articulated Object Generation by Partial Point Cloud Alignment and Physical Plausibility Constraints](https://arxiv.org/abs/2508.00558)
*Jens U. Kreber,Joerg Stueckler*

Main category: cs.CV

TL;DR: PhysNAP 是一种基于扩散模型的方法，通过 SDFs 和物理约束生成物理上合理的铰接物体，并在点云对齐和约束一致性上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 铰接物体是日常环境中重要的可交互对象。现有的方法在生成物理上合理的铰接物体方面存在不足，因此需要一种新方法来改善点云对齐和物理合理性。

Method: PhysNAP 使用带符号距离函数（SDFs）表示部件形状，并通过点云对齐损失指导反向扩散过程。此外，还引入了基于部件 SDFs 的非穿透性和移动性约束，以生成物理上更合理的物体。模型还支持类别感知，以在有类别信息时进一步优化点云对齐。

Result: 在 PartNet-Mobility 数据集上的实验表明，PhysNAP 在生成能力和约束一致性上优于未引导的基线扩散模型，能够提供更好的平衡。

Conclusion: PhysNAP 是一种基于扩散模型的新方法，能够生成与部分点云对齐且物理上更合理的铰接物体。通过结合点云对齐损失和非穿透性及移动性约束，PhysNAP 在生成能力和约束一致性之间取得了平衡。

Abstract: Articulated objects are an important type of interactable objects in everyday
environments. In this paper, we propose PhysNAP, a novel diffusion model-based
approach for generating articulated objects that aligns them with partial point
clouds and improves their physical plausibility. The model represents part
shapes by signed distance functions (SDFs). We guide the reverse diffusion
process using a point cloud alignment loss computed using the predicted SDFs.
Additionally, we impose non-penetration and mobility constraints based on the
part SDFs for guiding the model to generate more physically plausible objects.
We also make our diffusion approach category-aware to further improve point
cloud alignment if category information is available. We evaluate the
generative ability and constraint consistency of samples generated with PhysNAP
using the PartNet-Mobility dataset. We also compare it with an unguided
baseline diffusion model and demonstrate that PhysNAP can improve constraint
consistency and provides a tradeoff with generative ability.

</details>


### [74] [Weakly Supervised Virus Capsid Detection with Image-Level Annotations in Electron Microscopy Images](https://arxiv.org/abs/2508.00563)
*Hannah Kniesel,Leon Sick,Tristan Payer,Tim Bergner,Kavitha Shaga Devan,Clarissa Read,Paul Walther,Timo Ropinski*

Main category: cs.CV

TL;DR: 该论文提出一种仅需图像级标注的弱监督对象检测算法，通过知识蒸馏和优化方法生成伪标签，实验证明其在有限标注时间下优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 获取大量数据集的标注边界框成本高昂且耗时，尤其是需要领域专家参与，因此需要一种仅依赖图像级标注的弱监督对象检测方法。

Method: 使用预训练模型的知识蒸馏，通过优化方法和缩小的感受野直接提取病毒颗粒，无需特定网络架构。

Result: 提出的伪标签方法更容易获取，并且在标注时间有限的情况下，表现优于其他弱标注方法甚至真实标注。

Conclusion: 该论文提出的弱监督对象检测算法在标注时间有限的情况下，不仅比其他弱标注方法表现更好，甚至在某些情况下优于真实标注标签。

Abstract: Current state-of-the-art methods for object detection rely on annotated
bounding boxes of large data sets for training. However, obtaining such
annotations is expensive and can require up to hundreds of hours of manual
labor. This poses a challenge, especially since such annotations can only be
provided by experts, as they require knowledge about the scientific domain. To
tackle this challenge, we propose a domain-specific weakly supervised object
detection algorithm that only relies on image-level annotations, which are
significantly easier to acquire. Our method distills the knowledge of a
pre-trained model, on the task of predicting the presence or absence of a virus
in an image, to obtain a set of pseudo-labels that can be used to later train a
state-of-the-art object detection model. To do so, we use an optimization
approach with a shrinking receptive field to extract virus particles directly
without specific network architectures. Through a set of extensive studies, we
show how the proposed pseudo-labels are easier to obtain, and, more
importantly, are able to outperform other existing weak labeling methods, and
even ground truth labels, in cases where the time to obtain the annotation is
limited.

</details>


### [75] [CoProU-VO: Combining Projected Uncertainty for End-to-End Unsupervised Monocular Visual Odometry](https://arxiv.org/abs/2508.00568)
*Jingchao Xie,Oussema Dhaouadi,Weirong Chen,Johannes Meier,Jacques Kaiser,Daniel Cremers*

Main category: cs.CV

TL;DR: CoProU-VO通过跨帧不确定性传播提升动态场景下的视觉里程计性能，实验显示其在挑战性场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无监督视觉里程计方法在动态对象违反静态场景假设时表现不佳，传统不确定性建模仅考虑单帧信息，忽略了跨帧不确定性的传播。

Method: 提出了一种名为CoProU-VO的端到端方法，结合了目标帧和参考帧的不确定性，基于视觉变换器架构同时学习深度、不确定性估计和相机位姿。

Result: 在KITTI和nuScenes数据集上的实验显示，CoProU-VO显著优于之前的无监督单目端到端双帧方法，并在高速公路场景中表现突出。

Conclusion: CoProU-VO通过跨帧不确定性传播显著提升了动态场景下的视觉里程计性能，特别是在高速公路等挑战性场景中表现优异。

Abstract: Visual Odometry (VO) is fundamental to autonomous navigation, robotics, and
augmented reality, with unsupervised approaches eliminating the need for
expensive ground-truth labels. However, these methods struggle when dynamic
objects violate the static scene assumption, leading to erroneous pose
estimations. We tackle this problem by uncertainty modeling, which is a
commonly used technique that creates robust masks to filter out dynamic objects
and occlusions without requiring explicit motion segmentation. Traditional
uncertainty modeling considers only single-frame information, overlooking the
uncertainties across consecutive frames. Our key insight is that uncertainty
must be propagated and combined across temporal frames to effectively identify
unreliable regions, particularly in dynamic scenes. To address this challenge,
we introduce Combined Projected Uncertainty VO (CoProU-VO), a novel end-to-end
approach that combines target frame uncertainty with projected reference frame
uncertainty using a principled probabilistic formulation. Built upon vision
transformer backbones, our model simultaneously learns depth, uncertainty
estimation, and camera poses. Consequently, experiments on the KITTI and
nuScenes datasets demonstrate significant improvements over previous
unsupervised monocular end-to-end two-frame-based methods and exhibit strong
performance in challenging highway scenes where other approaches often fail.
Additionally, comprehensive ablation studies validate the effectiveness of
cross-frame uncertainty propagation.

</details>


### [76] [Uncertainty-Aware Likelihood Ratio Estimation for Pixel-Wise Out-of-Distribution Detection](https://arxiv.org/abs/2508.00587)
*Marc Hölle,Walter Kellermann,Vasileios Belagiannis*

Main category: cs.CV

TL;DR: 提出了一种不确定性感知的似然比估计方法，显著提升了自动驾驶场景中未知物体的检测性能，计算开销低且性能优越。


<details>
  <summary>Details</summary>
Motivation: 现实自动驾驶场景中，语义分割模型常因未知物体而误分类，现有方法在复杂场景中难以区分稀有类别与真正未知物体。

Method: 引入了一种基于不确定性感知的似然比估计方法，利用证据分类器在似然比测试中区分已知和未知像素特征，并明确考虑不确定性。

Result: 通过显式考虑不确定性，该方法更有效地利用了离群值暴露，显著提升了未知物体检测的性能。

Conclusion: 该方法在五个标准基准数据集上实现了最低的平均误报率（2.5%），同时保持了高平均精度（90.91%），且计算开销可忽略不计。

Abstract: Semantic segmentation models trained on known object classes often fail in
real-world autonomous driving scenarios by confidently misclassifying unknown
objects. While pixel-wise out-of-distribution detection can identify unknown
objects, existing methods struggle in complex scenes where rare object classes
are often confused with truly unknown objects. We introduce an
uncertainty-aware likelihood ratio estimation method that addresses these
limitations. Our approach uses an evidential classifier within a likelihood
ratio test to distinguish between known and unknown pixel features from a
semantic segmentation model, while explicitly accounting for uncertainty.
Instead of producing point estimates, our method outputs probability
distributions that capture uncertainty from both rare training examples and
imperfect synthetic outliers. We show that by incorporating uncertainty in this
way, outlier exposure can be leveraged more effectively. Evaluated on five
standard benchmark datasets, our method achieves the lowest average false
positive rate (2.5%) among state-of-the-art while maintaining high average
precision (90.91%) and incurring only negligible computational overhead. Code
is available at https://github.com/glasbruch/ULRE.

</details>


### [77] [A Novel Modeling Framework and Data Product for Extended VIIRS-like Artificial Nighttime Light Image Reconstruction (1986-2024)](https://arxiv.org/abs/2508.00590)
*Yihe Tian,Kwan Man Cheng,Zhengbo Zhang,Tao Zhang,Suju Li,Dongmei Yan,Bing Xu*

Main category: cs.CV

TL;DR: 提出EVAL框架，通过两阶段重建提升夜间灯光数据质量，覆盖1986年至今，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有VIIRS-like夜间灯光时间序列方法在光强度低估和结构遗漏方面的不足。

Method: 提出了一个由构建和细化两阶段组成的重建框架，包括层次融合解码器（HFD）和双特征细化器（DFR）。

Result: 开发的EVAL产品将标准数据记录回溯至1986年，显著提升了R²（0.68到0.80）并降低了RMSE（1.27到0.99），具有优异的时间一致性和社会经济参数相关性。

Conclusion: EVAL数据集为研究社区提供了一个宝贵的新资源，显著提升了夜间灯光数据的准确性和时间覆盖范围，支持长期社会经济分析。

Abstract: Artificial Night-Time Light (NTL) remote sensing is a vital proxy for
quantifying the intensity and spatial distribution of human activities.
Although the NPP-VIIRS sensor provides high-quality NTL observations, its
temporal coverage, which begins in 2012, restricts long-term time-series
studies that extend to earlier periods. Despite the progress in extending
VIIRS-like NTL time-series, current methods still suffer from two significant
shortcomings: the underestimation of light intensity and the structural
omission. To overcome these limitations, we propose a novel reconstruction
framework consisting of a two-stage process: construction and refinement. The
construction stage features a Hierarchical Fusion Decoder (HFD) designed to
enhance the fidelity of the initial reconstruction. The refinement stage
employs a Dual Feature Refiner (DFR), which leverages high-resolution
impervious surface masks to guide and enhance fine-grained structural details.
Based on this framework, we developed the Extended VIIRS-like Artificial
Nighttime Light (EVAL) product for China, extending the standard data record
backwards by 26 years to begin in 1986. Quantitative evaluation shows that EVAL
significantly outperforms existing state-of-the-art products, boosting the
$\text{R}^2$ from 0.68 to 0.80 while lowering the RMSE from 1.27 to 0.99.
Furthermore, EVAL exhibits excellent temporal consistency and maintains a high
correlation with socioeconomic parameters, confirming its reliability for
long-term analysis. The resulting EVAL dataset provides a valuable new resource
for the research community and is publicly available at
https://doi.org/10.11888/HumanNat.tpdc.302930.

</details>


### [78] [GeoMoE: Divide-and-Conquer Motion Field Modeling with Mixture-of-Experts for Two-View Geometry](https://arxiv.org/abs/2508.00592)
*Jiajun Le,Jiayi Ma*

Main category: cs.CV

TL;DR: GeoMoE利用Mixture-of-Experts技术，通过结构感知分解和定制专家建模，有效处理异质性运动模式，在运动场估计中取得优异表现。


<details>
  <summary>Details</summary>
Motivation: 在复杂现实场景中，运动场常表现出多样化和异质性的运动模式，现有方法缺乏针对性建模策略，导致估计的运动场偏离真实结构和分布。

Method: 首先设计了一种概率先验引导分解策略，利用内点概率信号对运动场进行结构感知分解；其次引入了MoE增强的双路径校正器，通过空间-上下文和通道-语义路径增强每个子场，并将其路由到定制专家进行定向建模。

Result: GeoMoE在相对姿态和单应性估计中表现优于现有方法，并具有强泛化能力。

Conclusion: GeoMoE通过其精简的设计，在相对姿态和单应性估计方面超越了现有最先进方法，并展现出强大的泛化能力。

Abstract: Recent progress in two-view geometry increasingly emphasizes enforcing
smoothness and global consistency priors when estimating motion fields between
pairs of images. However, in complex real-world scenes, characterized by
extreme viewpoint and scale changes as well as pronounced depth
discontinuities, the motion field often exhibits diverse and heterogeneous
motion patterns. Most existing methods lack targeted modeling strategies and
fail to explicitly account for this variability, resulting in estimated motion
fields that diverge from their true underlying structure and distribution. We
observe that Mixture-of-Experts (MoE) can assign dedicated experts to motion
sub-fields, enabling a divide-and-conquer strategy for heterogeneous motion
patterns. Building on this insight, we re-architect motion field modeling in
two-view geometry with GeoMoE, a streamlined framework. Specifically, we first
devise a Probabilistic Prior-Guided Decomposition strategy that exploits inlier
probability signals to perform a structure-aware decomposition of the motion
field into heterogeneous sub-fields, sharply curbing outlier-induced bias.
Next, we introduce an MoE-Enhanced Bi-Path Rectifier that enhances each
sub-field along spatial-context and channel-semantic paths and routes it to a
customized expert for targeted modeling, thereby decoupling heterogeneous
motion regimes, suppressing cross-sub-field interference and representational
entanglement, and yielding fine-grained motion-field rectification. With this
minimalist design, GeoMoE outperforms prior state-of-the-art methods in
relative pose and homography estimation and shows strong generalization. The
source code and pre-trained models are available at
https://github.com/JiajunLe/GeoMoE.

</details>


### [79] [DPoser-X: Diffusion Model as Robust 3D Whole-body Human Pose Prior](https://arxiv.org/abs/2508.00599)
*Junzhe Lu,Jing Lin,Hongkun Dou,Ailing Zeng,Yue Deng,Xian Liu,Zhongang Cai,Lei Yang,Yulun Zhang,Haoqian Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: DPoser-X是一种基于扩散模型的全身人体姿势先验模型，通过创新方法解决了数据稀缺和复杂性问题，在多个任务中超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 由于人体姿势的复杂性和高质量全身姿势数据集的稀缺，构建一个通用且鲁棒的全身人体姿势先验模型具有挑战性。

Method: 采用扩散模型作为姿势先验（DPoser），并扩展为DPoser-X，结合变分扩散采样和截断时间步调度方法，以及掩码训练机制。

Result: 在身体、手部、面部和全身姿势建模的多个基准测试中，DPoser-X表现出卓越的鲁棒性和通用性。

Conclusion: DPoser-X 通过扩散模型和创新的训练机制，为3D全身人体姿势建模设立了新的基准，显著优于现有方法。

Abstract: We present DPoser-X, a diffusion-based prior model for 3D whole-body human
poses. Building a versatile and robust full-body human pose prior remains
challenging due to the inherent complexity of articulated human poses and the
scarcity of high-quality whole-body pose datasets. To address these
limitations, we introduce a Diffusion model as body Pose prior (DPoser) and
extend it to DPoser-X for expressive whole-body human pose modeling. Our
approach unifies various pose-centric tasks as inverse problems, solving them
through variational diffusion sampling. To enhance performance on downstream
applications, we introduce a novel truncated timestep scheduling method
specifically designed for pose data characteristics. We also propose a masked
training mechanism that effectively combines whole-body and part-specific
datasets, enabling our model to capture interdependencies between body parts
while avoiding overfitting to specific actions. Extensive experiments
demonstrate DPoser-X's robustness and versatility across multiple benchmarks
for body, hand, face, and full-body pose modeling. Our model consistently
outperforms state-of-the-art alternatives, establishing a new benchmark for
whole-body human pose prior modeling.

</details>


### [80] [Minimum Data, Maximum Impact: 20 annotated samples for explainable lung nodule classification](https://arxiv.org/abs/2508.00639)
*Luisa Gallée,Catharina Silvia Lisson,Christoph Gerhard Lisson,Daniela Drees,Felix Weig,Daniel Vogele,Meinrad Beer,Michael Götz*

Main category: cs.CV

TL;DR: 通过生成属性注释数据，增强医学图像可解释模型的性能，解决数据集限制问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模医学图像数据集缺乏属性注释的问题，以增强AI决策的透明度和可解释性，使其更符合临床推理。

Method: 通过增强扩散模型（Diffusion Model）的属性条件，仅使用20个来自LIDC-IDRI数据集的属性标记肺结节样本进行训练，生成属性注释数据。

Result: 使用生成图像训练可解释模型后，属性预测准确率提高了13.4%，目标预测准确率提高了1.8%。

Conclusion: 该研究展示了合成数据在克服医学图像数据集限制方面的潜力，增强了可解释模型在医学图像分析中的适用性。

Abstract: Classification models that provide human-interpretable explanations enhance
clinicians' trust and usability in medical image diagnosis. One research focus
is the integration and prediction of pathology-related visual attributes used
by radiologists alongside the diagnosis, aligning AI decision-making with
clinical reasoning. Radiologists use attributes like shape and texture as
established diagnostic criteria and mirroring these in AI decision-making both
enhances transparency and enables explicit validation of model outputs.
However, the adoption of such models is limited by the scarcity of large-scale
medical image datasets annotated with these attributes. To address this
challenge, we propose synthesizing attribute-annotated data using a generative
model. We enhance the Diffusion Model with attribute conditioning and train it
using only 20 attribute-labeled lung nodule samples from the LIDC-IDRI dataset.
Incorporating its generated images into the training of an explainable model
boosts performance, increasing attribute prediction accuracy by 13.4% and
target prediction accuracy by 1.8% compared to training with only the small
real attribute-annotated dataset. This work highlights the potential of
synthetic data to overcome dataset limitations, enhancing the applicability of
explainable models in medical image analysis.

</details>


### [81] [Revisiting Adversarial Patch Defenses on Object Detectors: Unified Evaluation, Large-Scale Dataset, and New Insights](https://arxiv.org/abs/2508.00649)
*Junhao Zheng,Jiahao Sun,Chenhao Lin,Zhengyu Zhao,Chen Ma,Chong Zhang,Cong Wang,Qian Wang,Chao Shen*

Main category: cs.CV

TL;DR: 研究构建了首个对抗性补丁防御基准，揭示了现有防御的局限性，并提出了改进方向，如利用多样化补丁分布提升防御性能15.09% AP@0.5。


<details>
  <summary>Details</summary>
Motivation: 现有对抗补丁攻击的防御评估缺乏统一全面的框架，导致对当前方法的评估不一致且不完整。

Method: 研究重新评估了11种代表性防御方法，构建了包含2种攻击目标、13种补丁攻击、11种目标检测器和4种多样指标的基准测试，生成了包含94种补丁类型和94,000张图像的大规模对抗性补丁数据集。

Result: 研究发现：（1）防御自然补丁的难点在于数据分布而非高频特征；（2）攻击目标的平均精度与防御性能高度一致；（3）自适应攻击能显著绕过现有防御，而复杂/随机模型或通用补丁属性的防御相对稳健。

Conclusion: 该研究通过建立首个对抗性补丁防御基准，揭示了现有防御方法的局限性，并提出了改进方向，如利用多样化的补丁分布提升防御性能15.09% AP@0.5。研究还发现，防御性能与攻击目标的平均精度高度一致，而非传统追求的补丁检测准确率。

Abstract: Developing reliable defenses against patch attacks on object detectors has
attracted increasing interest. However, we identify that existing defense
evaluations lack a unified and comprehensive framework, resulting in
inconsistent and incomplete assessments of current methods. To address this
issue, we revisit 11 representative defenses and present the first patch
defense benchmark, involving 2 attack goals, 13 patch attacks, 11 object
detectors, and 4 diverse metrics. This leads to the large-scale adversarial
patch dataset with 94 types of patches and 94,000 images. Our comprehensive
analyses reveal new insights: (1) The difficulty in defending against
naturalistic patches lies in the data distribution, rather than the commonly
believed high frequencies. Our new dataset with diverse patch distributions can
be used to improve existing defenses by 15.09% AP@0.5. (2) The average
precision of the attacked object, rather than the commonly pursued patch
detection accuracy, shows high consistency with defense performance. (3)
Adaptive attacks can substantially bypass existing defenses, and defenses with
complex/stochastic models or universal patch properties are relatively robust.
We hope that our analyses will serve as guidance on properly evaluating patch
attacks/defenses and advancing their design. Code and dataset are available at
https://github.com/Gandolfczjh/APDE, where we will keep integrating new
attacks/defenses.

</details>


### [82] [Can Large Pretrained Depth Estimation Models Help With Image Dehazing?](https://arxiv.org/abs/2508.00698)
*Hongfei Zhang,Kun Zhou,Ruizheng Wu,Jiangbo Lu*

Main category: cs.CV

TL;DR: 提出一种基于预训练深度特征的RGB-D融合模块，可适配多种去雾架构，提升去雾效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在架构特定设计上限制了其在不同场景下的适应性和效率，因此需要一种更通用的解决方案。

Method: 系统研究了预训练深度表示在图像去雾中的泛化能力，并基于此提出了一个RGB-D融合模块。

Result: 提出的RGB-D融合模块在多个基准测试中表现出色，验证了其有效性和广泛适用性。

Conclusion: 通过学习预训练的深度特征，提出了一个即插即用的RGB-D融合模块，该模块能够与多种去雾架构无缝集成，并在多个基准测试中验证了其有效性和广泛适用性。

Abstract: Image dehazing remains a challenging problem due to the spatially varying
nature of haze in real-world scenes. While existing methods have demonstrated
the promise of large-scale pretrained models for image dehazing, their
architecture-specific designs hinder adaptability across diverse scenarios with
different accuracy and efficiency requirements. In this work, we systematically
investigate the generalization capability of pretrained depth
representations-learned from millions of diverse images-for image dehazing. Our
empirical analysis reveals that the learned deep depth features maintain
remarkable consistency across varying haze levels. Building on this insight, we
propose a plug-and-play RGB-D fusion module that seamlessly integrates with
diverse dehazing architectures. Extensive experiments across multiple
benchmarks validate both the effectiveness and broad applicability of our
approach.

</details>


### [83] [MIHBench: Benchmarking and Mitigating Multi-Image Hallucinations in Multimodal Large Language Models](https://arxiv.org/abs/2508.00726)
*Jiale Li,Mingrui Wu,Zixiang Jin,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: 论文首次系统研究了多图像MLLMs中的幻觉现象，提出了MIHBench基准和动态注意力平衡机制，有效减少幻觉并提升多图像场景的语义整合。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单图像设置下的幻觉问题，而多图像场景中的幻觉现象尚未被充分探索。

Method: 论文通过构建MIHBench基准，评估多图像MLLMs中的对象相关幻觉，并提出动态注意力平衡机制来调整图像间的注意力分布。

Result: 实验表明，动态注意力平衡机制能显著减少多图像幻觉，并提高语义理解和推理的稳定性。

Conclusion: 论文提出了一种动态注意力平衡机制，有效减少了多图像场景中的幻觉现象，并提升了语义整合和推理的稳定性。

Abstract: Despite growing interest in hallucination in Multimodal Large Language
Models, existing studies primarily focus on single-image settings, leaving
hallucination in multi-image scenarios largely unexplored. To address this gap,
we conduct the first systematic study of hallucinations in multi-image MLLMs
and propose MIHBench, a benchmark specifically tailored for evaluating
object-related hallucinations across multiple images. MIHBench comprises three
core tasks: Multi-Image Object Existence Hallucination, Multi-Image Object
Count Hallucination, and Object Identity Consistency Hallucination, targeting
semantic understanding across object existence, quantity reasoning, and
cross-view identity consistency. Through extensive evaluation, we identify key
factors associated with the occurrence of multi-image hallucinations,
including: a progressive relationship between the number of image inputs and
the likelihood of hallucination occurrences; a strong correlation between
single-image hallucination tendencies and those observed in multi-image
contexts; and the influence of same-object image ratios and the positional
placement of negative samples within image sequences on the occurrence of
object identity consistency hallucination. To address these challenges, we
propose a Dynamic Attention Balancing mechanism that adjusts inter-image
attention distributions while preserving the overall visual attention
proportion. Experiments across multiple state-of-the-art MLLMs demonstrate that
our method effectively reduces hallucination occurrences and enhances semantic
integration and reasoning stability in multi-image scenarios.

</details>


### [84] [YOLO-Count: Differentiable Object Counting for Text-to-Image Generation](https://arxiv.org/abs/2508.00728)
*Guanning Zeng,Xiang Zhang,Zirui Wang,Haiyang Xu,Zeyuan Chen,Bingnan Li,Zhuowen Tu*

Main category: cs.CV

TL;DR: YOLO-Count 是一种可微开放词汇对象计数模型，通过‘cardinality map’和混合监督方案，实现了高精度计数和T2I生成的精确控制。


<details>
  <summary>Details</summary>
Motivation: 解决通用计数挑战并为文本到图像（T2I）生成提供精确的数量控制。

Method: YOLO-Count 提出了一种称为‘cardinality map’的新型回归目标，结合表征对齐和混合强弱监督方案，实现了开放词汇计数与T2I生成控制的桥梁。

Result: 广泛的实验表明，YOLO-Count 在计数准确性上达到了最新技术水平，并为T2I系统提供了强大且有效的数量控制。

Conclusion: YOLO-Count 通过其完全可微的架构，在开放词汇对象计数和文本到图像生成的精确数量控制方面取得了最新技术水平的成果。

Abstract: We propose YOLO-Count, a differentiable open-vocabulary object counting model
that tackles both general counting challenges and enables precise quantity
control for text-to-image (T2I) generation. A core contribution is the
'cardinality' map, a novel regression target that accounts for variations in
object size and spatial distribution. Leveraging representation alignment and a
hybrid strong-weak supervision scheme, YOLO-Count bridges the gap between
open-vocabulary counting and T2I generation control. Its fully differentiable
architecture facilitates gradient-based optimization, enabling accurate object
count estimation and fine-grained guidance for generative models. Extensive
experiments demonstrate that YOLO-Count achieves state-of-the-art counting
accuracy while providing robust and effective quantity control for T2I systems.

</details>


### [85] [Rethinking Backbone Design for Lightweight 3D Object Detection in LiDAR](https://arxiv.org/abs/2508.00744)
*Adwait Chandorkar,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: Dense Backbone是一种专为点云数据3D目标检测设计的轻量级骨干网络，显著降低计算成本，保持高精度。


<details>
  <summary>Details</summary>
Motivation: 尽管LiDAR-based 3D目标检测取得了显著进展，但现有方法仍依赖复杂的VGG或ResNet骨干网络，增加了模型复杂度。轻量级骨干网络在2D目标检测中已有研究，但在3D目标检测中仍有限。

Method: 提出了Dense Backbone，一种轻量级骨干网络，结合了高处理速度、轻量级架构和鲁棒检测精度。通过适配PillarNet等SoTA 3D目标检测器，验证了其有效性。

Result: DensePillarNet在nuScenes测试集上实现了29%的模型参数减少和28%的延迟降低，仅带来2%的检测精度下降。

Conclusion: Dense Backbone为3D目标检测提供了一种轻量级、高效且易于集成的解决方案，显著降低了计算成本，同时保持了较高的检测精度。

Abstract: Recent advancements in LiDAR-based 3D object detection have significantly
accelerated progress toward the realization of fully autonomous driving in
real-world environments. Despite achieving high detection performance, most of
the approaches still rely on a VGG-based or ResNet-based backbone for feature
exploration, which increases the model complexity. Lightweight backbone design
is well-explored for 2D object detection, but research on 3D object detection
still remains limited. In this work, we introduce Dense Backbone, a lightweight
backbone that combines the benefits of high processing speed, lightweight
architecture, and robust detection accuracy. We adapt multiple SoTA 3d object
detectors, such as PillarNet, with our backbone and show that with our
backbone, these models retain most of their detection capability at a
significantly reduced computational cost. To our knowledge, this is the first
dense-layer-based backbone tailored specifically for 3D object detection from
point cloud data. DensePillarNet, our adaptation of PillarNet, achieves a 29%
reduction in model parameters and a 28% reduction in latency with just a 2%
drop in detection accuracy on the nuScenes test set. Furthermore, Dense
Backbone's plug-and-play design allows straightforward integration into
existing architectures, requiring no modifications to other network components.

</details>


### [86] [GECO: Geometrically Consistent Embedding with Lightspeed Inference](https://arxiv.org/abs/2508.00746)
*Regine Hartwig,Dominik Muhle,Riccardo Marin,Daniel Cremers*

Main category: cs.CV

TL;DR: GECO提出了一种基于最优传输的几何一致特征学习方法，显著提升了3D几何感知和语义对应性能，同时运行效率极高。


<details>
  <summary>Details</summary>
Motivation: 解决自监督视觉基础模型在捕捉语义对应时缺乏3D几何感知的问题。

Method: 基于最优传输的训练框架，支持在遮挡和去遮挡情况下的监督学习，轻量级架构实现实时处理。

Result: 在PFPascal、APK和CUB数据集上达到最先进性能，PCK分别提升6.0%、6.2%和4.1%，运行速度达30fps，比现有方法快98.2%。

Conclusion: GECO通过引入几何一致的特征学习和新的评估指标，弥补了现有自监督视觉基础模型在3D几何感知上的不足，并在性能和效率上实现了显著提升。

Abstract: Recent advances in feature learning have shown that self-supervised vision
foundation models can capture semantic correspondences but often lack awareness
of underlying 3D geometry. GECO addresses this gap by producing geometrically
coherent features that semantically distinguish parts based on geometry (e.g.,
left/right eyes, front/back legs). We propose a training framework based on
optimal transport, enabling supervision beyond keypoints, even under occlusions
and disocclusions. With a lightweight architecture, GECO runs at 30 fps, 98.2%
faster than prior methods, while achieving state-of-the-art performance on
PFPascal, APK, and CUB, improving PCK by 6.0%, 6.2%, and 4.1%, respectively.
Finally, we show that PCK alone is insufficient to capture geometric quality
and introduce new metrics and insights for more geometry-aware feature
learning. Link to project page:
https://reginehartwig.github.io/publications/geco/

</details>


### [87] [SU-ESRGAN: Semantic and Uncertainty-Aware ESRGAN for Super-Resolution of Satellite and Drone Imagery with Fine-Tuning for Cross Domain Evaluation](https://arxiv.org/abs/2508.00750)
*Prerana Ramkumar*

Main category: cs.CV

TL;DR: SU-ESRGAN是首个为卫星图像设计的超分辨率框架，结合语义分割和不确定性估计，提升遥感图像质量。


<details>
  <summary>Details</summary>
Motivation: 解决GAN在超分辨率中缺乏语义一致性和像素级置信度的问题，提升关键遥感应用的可信度。

Method: 结合ESRGAN、DeepLabv3分割损失和蒙特卡洛dropout，生成像素级不确定性地图。

Result: 在PSNR、SSIM、LPIPS等指标上与基线ESRGAN相当，尤其在无人机数据集上表现更优。

Conclusion: SU-ESRGAN在卫星图像超分辨率中表现出色，尤其在无人机和卫星系统中具有实用价值，强调了领域感知训练的重要性。

Abstract: Generative Adversarial Networks (GANs) have achieved realistic
super-resolution (SR) of images however, they lack semantic consistency and
per-pixel confidence, limiting their credibility in critical remote sensing
applications such as disaster response, urban planning and agriculture. This
paper introduces Semantic and Uncertainty-Aware ESRGAN (SU-ESRGAN), the first
SR framework designed for satellite imagery to integrate the ESRGAN,
segmentation loss via DeepLabv3 for class detail preservation and Monte Carlo
dropout to produce pixel-wise uncertainty maps. The SU-ESRGAN produces results
(PSNR, SSIM, LPIPS) comparable to the Baseline ESRGAN on aerial imagery. This
novel model is valuable in satellite systems or UAVs that use wide
field-of-view (FoV) cameras, trading off spatial resolution for coverage. The
modular design allows integration in UAV data pipelines for on-board or
post-processing SR to enhance imagery resulting due to motion blur, compression
and sensor limitations. Further, the model is fine-tuned to evaluate its
performance on cross domain applications. The tests are conducted on two drone
based datasets which differ in altitude and imaging perspective. Performance
evaluation of the fine-tuned models show a stronger adaptation to the Aerial
Maritime Drone Dataset, whose imaging characteristics align with the training
data, highlighting the importance of domain-aware training in SR-applications.

</details>


### [88] [Zero-Shot Anomaly Detection with Dual-Branch Prompt Learning](https://arxiv.org/abs/2508.00777)
*Zihan Wang,Samira Ebrahimi Kahou,Narges Armanfard*

Main category: cs.CV

TL;DR: PILOT通过动态双重分支提示学习和无标签测试时适应策略，解决了零样本异常检测在领域偏移下的泛化问题，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本异常检测方法在领域偏移下表现不佳，因其训练数据来源有限且难以泛化到新分布。

Method: 采用双重分支提示学习机制和基于高置信度伪标签的无标签测试时适应策略。

Result: 在13个工业和医疗基准测试中，PILOT在领域偏移下的异常检测和定位性能达到最优。

Conclusion: PILOT框架通过双重分支提示学习和无标签测试时适应策略，在领域偏移下实现了最先进的异常检测和定位性能。

Abstract: Zero-shot anomaly detection (ZSAD) enables identifying and localizing defects
in unseen categories by relying solely on generalizable features rather than
requiring any labeled examples of anomalies. However, existing ZSAD methods,
whether using fixed or learned prompts, struggle under domain shifts because
their training data are derived from limited training domains and fail to
generalize to new distributions. In this paper, we introduce PILOT, a framework
designed to overcome these challenges through two key innovations: (1) a novel
dual-branch prompt learning mechanism that dynamically integrates a pool of
learnable prompts with structured semantic attributes, enabling the model to
adaptively weight the most relevant anomaly cues for each input image; and (2)
a label-free test-time adaptation strategy that updates the learnable prompt
parameters using high-confidence pseudo-labels from unlabeled test data.
Extensive experiments on 13 industrial and medical benchmarks demonstrate that
PILOT achieves state-of-the-art performance in both anomaly detection and
localization under domain shift.

</details>


### [89] [Cross-Dataset Semantic Segmentation Performance Analysis: Unifying NIST Point Cloud City Datasets for 3D Deep Learning](https://arxiv.org/abs/2508.00822)
*Alexander Nikitas Dimopoulos,Joseph Grasso*

Main category: cs.CV

TL;DR: 研究分析了异构标注点云数据集在公共安全应用中的语义分割性能，发现大型物体分割效果较好，小型安全关键特征识别率低，需标准化标注和改进技术。


<details>
  <summary>Details</summary>
Motivation: 研究异构标注点云数据集在公共安全应用中的语义分割性能，特别是针对预事件规划系统。

Method: 采用分级标注方案和KPConv架构，通过IoU指标评估安全相关特征的性能。

Result: 结果表明，几何较大的物体（如楼梯、窗户）分割性能较高，而小型安全关键特征的识别率较低，性能受类别不平衡和典型激光雷达扫描中小物体几何区分度有限的影响。

Conclusion: 可靠的点云语义分割在公共安全领域需要标准化的标注协议和改进的标注技术，以解决数据异质性和小型安全关键元素的检测问题。

Abstract: This study analyzes semantic segmentation performance across heterogeneously
labeled point-cloud datasets relevant to public safety applications, including
pre-incident planning systems derived from lidar scans. Using NIST's Point
Cloud City dataset (Enfield and Memphis collections), we investigate challenges
in unifying differently labeled 3D data. Our methodology employs a graded
schema with the KPConv architecture, evaluating performance through IoU metrics
on safety-relevant features. Results indicate performance variability:
geometrically large objects (e.g. stairs, windows) achieve higher segmentation
performance, suggesting potential for navigational context, while smaller
safety-critical features exhibit lower recognition rates. Performance is
impacted by class imbalance and the limited geometric distinction of smaller
objects in typical lidar scans, indicating limitations in detecting certain
safety-relevant features using current point-cloud methods. Key identified
challenges include insufficient labeled data, difficulties in unifying class
labels across datasets, and the need for standardization. Potential directions
include automated labeling and multi-dataset learning strategies. We conclude
that reliable point-cloud semantic segmentation for public safety necessitates
standardized annotation protocols and improved labeling techniques to address
data heterogeneity and the detection of small, safety-critical elements.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [90] [Composable OS Kernel Architectures for Autonomous Intelligence](https://arxiv.org/abs/2508.00604)
*Rajpreet Singh,Vidhi Kothari*

Main category: cs.OS

TL;DR: 该论文提出了一种新型AI集成的操作系统内核架构，通过扩展Linux内核和引入神经符号设计，使操作系统能自适应智能应用的需求。


<details>
  <summary>Details</summary>
Motivation: 随着智能系统在边缘设备、云基础设施和嵌入式实时环境中的普及，传统静态资源管理的内核架构已无法满足智能系统的需求，因此需要一种新的自适应、AI集成的内核架构。

Method: 1. 将可加载内核模块（LKMs）视为AI导向的计算单元，用于内核空间的快速感知和认知处理；2. 将Linux内核扩展为AI原生环境，内置深度学习推理、浮点加速和实时自适应调度，以高效处理机器学习工作负载；3. 引入神经符号内核设计，利用范畴论和同伦类型理论在操作系统内部统一符号推理和可微分逻辑。

Result: 通过这些方法，操作系统能够主动预测并适应自主智能应用的认知需求。

Conclusion: 该研究提出了一种新的操作系统内核架构，将内核从静态资源管理器转变为自适应、AI集成的平台，以满足智能系统的需求。

Abstract: As intelligent systems permeate edge devices, cloud infrastructure, and
embedded real-time environments, this research proposes a new OS kernel
architecture for intelligent systems, transforming kernels from static resource
managers to adaptive, AI-integrated platforms. Key contributions include: (1)
treating Loadable Kernel Modules (LKMs) as AI-oriented computation units for
fast sensory and cognitive processing in kernel space; (2) expanding the Linux
kernel into an AI-native environment with built-in deep learning inference,
floating-point acceleration, and real-time adaptive scheduling for efficient ML
workloads; and (3) introducing a Neurosymbolic kernel design leveraging
Category Theory and Homotopy Type Theory to unify symbolic reasoning and
differentiable logic within OS internals. Together, these approaches enable
operating systems to proactively anticipate and adapt to the cognitive needs of
autonomous intelligent applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [91] [Git Context Controller: Manage the Context of LLM-based Agents like Git](https://arxiv.org/abs/2508.00031)
*Junde Wu*

Main category: cs.SE

TL;DR: GCC 是一个结构化上下文管理框架，显著提升 LLM 智能体在长周期任务中的性能，尤其在软件缺陷解决和任务自复制方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 解决基于 LLM 的智能体在长周期工作流（如大型长期项目编码）中上下文管理的瓶颈问题。

Method: GCC 是一个受软件版本控制系统启发的结构化上下文管理框架，将智能体记忆组织为持久性文件系统，支持 COMMIT、BRANCH、MERGE 和 CONTEXT 等操作。

Result: GCC 在 SWE-Bench-Lite 基准测试中解决了 48.00% 的软件缺陷，优于 26 个竞争系统；在自复制案例中，任务解决率从 11.7% 提升至 40.7%。

Conclusion: Git-Context-Controller (GCC) 显著提升了基于大型语言模型（LLM）的智能体在长周期工作流中的上下文管理能力，实现了最先进的性能表现。

Abstract: Large language model (LLM) based agents have shown impressive capabilities by
interleaving internal reasoning with external tool use. However, as these
agents are deployed in long-horizon workflows, such as coding for a big,
long-term project, context management becomes a critical bottleneck. We
introduce Git-Context-Controller (GCC), a structured context management
framework inspired by software version control systems. GCC elevates context as
versioned memory hierarchy like Git. It structures agent memory as a persistent
file system with explicit operations: COMMIT, BRANCH, MERGE, and CONTEXT,
enabling milestone-based checkpointing, exploration of alternative plans, and
structured reflection. Our approach empowers agents to manage long-term goals,
isolate architectural experiments, and recover or hand off memory across
sessions and agents. Empirically, agents equipped with GCC achieve
state-of-the-art performance on the SWE-Bench-Lite benchmark, resolving 48.00
of software bugs, outperforming 26 competitive systems. In a self-replication
case study, a GCC-augmented agent builds a new CLI agent from scratch,
achieving 40.7 task resolution, compared to only 11.7 without GCC. The code is
released at: https://github.com/theworldofagents/GCC

</details>


### [92] [GPT-4.1 Sets the Standard in Automated Experiment Design Using Novel Python Libraries](https://arxiv.org/abs/2508.00033)
*Nuno Fachada,Daniel Fernandes,Carlos M. Fernandes,Bruno D. Ferreira-Saraiva,João P. Matos-Carvalho*

Main category: cs.SE

TL;DR: 本研究评估了LLMs在生成复杂Python代码任务中的表现，发现GPT-4.1表现最佳，同时揭示了库文档和模型能力的改进需求。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为科学研究中自动化代码生成的工具发展迅速，但其解释和使用不熟悉的Python API进行复杂计算实验的能力仍未得到充分表征。

Method: 本研究系统地基准测试了一系列最先进的大型语言模型（LLMs），在两种日益复杂的场景中生成功能性Python代码：使用ParShift库进行对话数据分析，以及使用pyclugen和scikit-learn生成和聚类合成数据。实验采用结构化、零样本提示，详细指定要求但省略上下文示例。

Result: 结果表明，只有一小部分模型能始终生成正确、可执行的代码，GPT-4.1是唯一在两项任务中均成功的模型。此外，该方法还帮助识别了第三方库的不足，如文档不清晰或实现中的隐蔽错误。

Conclusion: 研究突出了当前大型语言模型（LLMs）在端到端科学自动化中的局限性，强调了精心设计提示、全面的库文档以及语言模型能力的持续进步的必要性。

Abstract: Large Language Models (LLMs) have advanced rapidly as tools for automating
code generation in scientific research, yet their ability to interpret and use
unfamiliar Python APIs for complex computational experiments remains poorly
characterized. This study systematically benchmarks a selection of
state-of-the-art LLMs in generating functional Python code for two increasingly
challenging scenarios: conversational data analysis with the \textit{ParShift}
library, and synthetic data generation and clustering using \textit{pyclugen}
and \textit{scikit-learn}. Both experiments use structured, zero-shot prompts
specifying detailed requirements but omitting in-context examples. Model
outputs are evaluated quantitatively for functional correctness and prompt
compliance over multiple runs, and qualitatively by analyzing the errors
produced when code execution fails. Results show that only a small subset of
models consistently generate correct, executable code, with GPT-4.1 standing
out as the only model to always succeed in both tasks. In addition to
benchmarking LLM performance, this approach helps identify shortcomings in
third-party libraries, such as unclear documentation or obscure implementation
bugs. Overall, these findings highlight current limitations of LLMs for
end-to-end scientific automation and emphasize the need for careful prompt
design, comprehensive library documentation, and continued advances in language
model capabilities.

</details>


### [93] [Machine Learning Pipeline for Software Engineering: A Systematic Literature Review](https://arxiv.org/abs/2508.00045)
*Samah Kansab*

Main category: cs.SE

TL;DR: 本文通过系统性文献综述，总结了机器学习在软件工程中的应用现状，强调了稳健预处理和集成方法的重要性，并提供了优化建议，为未来研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 随着软件工程系统复杂度的增加，传统方法难以扩展，导致调试时间延长、缺陷检测效率低下以及资源密集型开发周期。机器学习成为关键解决方案，但其在软件工程中的有效性依赖于其流水线的稳健性。

Method: 本文采用系统性文献综述（SLR）方法，整合了为软件工程设计的先进机器学习流水线，包括最佳实践、挑战和差距。

Result: 研究发现，如SMOTE数据平衡和基于SZZ的特征选择等稳健预处理提高了模型可靠性。集成方法（如随机森林和梯度提升）在任务中表现优异，而朴素贝叶斯等简单模型在效率和可解释性方面仍有价值。AUC、F1分数和精确度是最常见的评估指标，而新指标如最佳算术平均（BAM）在特定应用中崭露头角。验证技术（如自助法）广泛用于确保模型稳定性和泛化性。

Conclusion: 本研究强调了设计良好的机器学习流水线对于解决软件工程挑战的重要性，并为研究人员和从业者提供了优化软件质量和效率的可操作见解。通过识别差距和趋势，本研究为在日益复杂的开发环境中推进机器学习应用和促进创新奠定了基础。

Abstract: The rapid advancement of software development practices has introduced
challenges in ensuring quality and efficiency across the software engineering
(SE) lifecycle. As SE systems grow in complexity, traditional approaches often
fail to scale, resulting in longer debugging times, inefficient defect
detection, and resource-heavy development cycles. Machine Learning (ML) has
emerged as a key solution, enabling automation in tasks such as defect
prediction, code review, and release quality estimation. However, the
effectiveness of ML in SE depends on the robustness of its pipeline, including
data collection, preprocessing, feature engineering, algorithm selection,
validation, and evaluation.
  This systematic literature review (SLR) examines state-of-the-art ML
pipelines designed for SE, consolidating best practices, challenges, and gaps.
Our findings show that robust preprocessing, such as SMOTE for data balancing
and SZZ-based algorithms for feature selection, improves model reliability.
Ensemble methods like Random Forest and Gradient Boosting dominate performance
across tasks, while simpler models such as Naive Bayes remain valuable for
efficiency and interpretability. Evaluation metrics including AUC, F1-score,
and precision are most common, with new metrics like Best Arithmetic Mean (BAM)
emerging in niche applications. Validation techniques such as bootstrapping are
widely used to ensure model stability and generalizability.
  This SLR highlights the importance of well-designed ML pipelines for
addressing SE challenges and provides actionable insights for researchers and
practitioners seeking to optimize software quality and efficiency. By
identifying gaps and trends, this study sets a foundation for advancing ML
adoption and fostering innovation in increasingly complex development
environments.

</details>


### [94] [A Survey on Code Generation with LLM-based Agents](https://arxiv.org/abs/2508.00083)
*Yihong Dong,Xue Jiang,Jiaru Qian,Tian Wang,Kechi Zhang,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: 本文系统调查了基于LLM的代码生成代理，涵盖其发展轨迹、核心技术、应用场景、评估工具及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 代码生成代理正在改变软件开发范式，具有自主性、扩展任务范围和增强工程实用性三大核心特征，展现了巨大的应用潜力。

Method: 本文对基于LLM的代码生成代理领域进行了系统性调查，追溯了技术的发展轨迹，并系统分类了其核心技术，包括单代理和多代理架构。

Result: 本文详细介绍了LLM-based代理在整个软件开发生命周期中的应用，总结了主流的评估基准和指标，并列举了代表性工具。

Conclusion: 本文通过分析LLM-based代码生成代理的主要挑战，提出了该领域未来工作的几个基础性、长期研究方向。

Abstract: Code generation agents powered by large language models (LLMs) are
revolutionizing the software development paradigm. Distinct from previous code
generation techniques, code generation agents are characterized by three core
features. 1) Autonomy: the ability to independently manage the entire workflow,
from task decomposition to coding and debugging. 2) Expanded task scope:
capabilities that extend beyond generating code snippets to encompass the full
software development lifecycle (SDLC). 3) Enhancement of engineering
practicality: a shift in research emphasis from algorithmic innovation toward
practical engineering challenges, such as system reliability, process
management, and tool integration. This domain has recently witnessed rapid
development and an explosion in research, demonstrating significant application
potential. This paper presents a systematic survey of the field of LLM-based
code generation agents. We trace the technology's developmental trajectory from
its inception and systematically categorize its core techniques, including both
single-agent and multi-agent architectures. Furthermore, this survey details
the applications of LLM-based agents across the full SDLC, summarizes
mainstream evaluation benchmarks and metrics, and catalogs representative
tools. Finally, by analyzing the primary challenges, we identify and propose
several foundational, long-term research directions for the future work of the
field.

</details>


### [95] [How Quantization Impacts Privacy Risk on LLMs for Code?](https://arxiv.org/abs/2508.00128)
*Md Nazmul Haque,Hua Yang,Zhou Yang,Bowen Xu*

Main category: cs.SE

TL;DR: 量化技术可降低代码大模型的隐私风险，同时揭示性能与风险的权衡，为实际部署提供指导。


<details>
  <summary>Details</summary>
Motivation: 量化模型仍保留原始训练数据中的知识，但其对隐私信息保留和暴露能力的影响尚不明确，这对理解实际部署中的隐私风险至关重要。

Method: 本研究实现了广泛使用的量化技术（静态和动态）应用于三种代表性模型家族（Pythia、CodeGen和GPTNeo），并评估了其对任务性能和隐私风险的影响。

Result: 量化显著降低了隐私风险，并发现任务性能与隐私风险之间存在正相关关系。此外，量化较大模型可能比使用全精度小模型获得更好的平衡。

Conclusion: 量化技术显著降低了LLMs4Code的隐私风险，同时揭示了任务性能与隐私风险之间的权衡关系，为部署压缩模型提供了实用指导。

Abstract: Large language models for code (LLMs4Code) rely heavily on massive training
data, including sensitive data, such as cloud service credentials of the
projects and personal identifiable information of the developers, raising
serious privacy concerns. Membership inference (MI) has recently emerged as an
effective tool for assessing privacy risk by identifying whether specific data
belong to a model's training set. In parallel, model compression techniques,
especially quantization, have gained traction for reducing computational costs
and enabling the deployment of large models. However, while quantized models
still retain knowledge learned from the original training data, it remains
unclear whether quantization affects their ability to retain and expose privacy
information. Answering this question is of great importance to understanding
privacy risks in real-world deployments. In this work, we conduct the first
empirical study on how quantization influences task performance and privacy
risk simultaneously in LLMs4Code. To do this, we implement widely used
quantization techniques (static and dynamic) to three representative model
families, namely Pythia, CodeGen, and GPTNeo. Our results demonstrate that
quantization has a significant impact on reducing the privacy risk relative to
the original model. We also uncover a positive correlation between task
performance and privacy risk, indicating an underlying tradeoff. Moreover, we
reveal the possibility that quantizing larger models could yield better balance
than using full-precision small models. Finally, we demonstrate that these
findings generalize across different architectures, model sizes and MI methods,
offering practical guidance for safeguarding privacy when deploying compressed
LLMs4Code.

</details>


### [96] [Testing the Untestable? An Empirical Study on the Testing Process of LLM-Powered Software Systems](https://arxiv.org/abs/2508.00198)
*Cleyton Magalhaes,Italo Santos,Brody Stuart-Verner,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 本研究探讨了在现实应用开发中如何测试基于LLM的系统，发现测试策略需结合手动与自动化方法，并面临如不可预测输出等挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在代码生成、调试和文档等任务中的应用已有很多研究，但关于在开发过程中如何测试集成LLM的完整系统的研究却很少。本研究旨在探索在现实应用开发中如何测试基于LLM的系统。

Method: 我们进行了一项探索性案例研究，分析了99份由学生撰写的报告，这些报告记录了他们在大学课程中构建和部署基于LLM的应用程序的过程。每份报告都通过主题分析和结构化编码过程进行了独立分析。

Result: 测试策略结合了手动和自动化方法来评估系统逻辑和模型行为。常见实践包括探索性测试、单元测试和提示迭代。报告的挑战包括集成失败、不可预测的输出、提示敏感性、幻觉以及对正确性的不确定性。

Conclusion: 测试基于LLM的系统需要调整传统的验证方法，结合源代码层面的推理和行为感知评估。这些发现为软件系统中生成式组件的实际测试环境提供了证据。

Abstract: Background: Software systems powered by large language models are becoming a
routine part of everyday technologies, supporting applications across a wide
range of domains. In software engineering, many studies have focused on how
LLMs support tasks such as code generation, debugging, and documentation.
However, there has been limited focus on how full systems that integrate LLMs
are tested during development. Aims: This study explores how LLM-powered
systems are tested in the context of real-world application development.
Method: We conducted an exploratory case study using 99 individual reports
written by students who built and deployed LLM-powered applications as part of
a university course. Each report was independently analyzed using thematic
analysis, supported by a structured coding process. Results: Testing strategies
combined manual and automated methods to evaluate both system logic and model
behavior. Common practices included exploratory testing, unit testing, and
prompt iteration. Reported challenges included integration failures,
unpredictable outputs, prompt sensitivity, hallucinations, and uncertainty
about correctness. Conclusions: Testing LLM-powered systems required
adaptations to traditional verification methods, blending source-level
reasoning with behavior-aware evaluations. These findings provide evidence on
the practical context of testing generative components in software systems.

</details>


### [97] [Functional vs. Object-Oriented: Comparing How Programming Paradigms Affect the Architectural Characteristics of Systems](https://arxiv.org/abs/2508.00244)
*Briza Mel Dias de Sousa,Renato Cordeiro Ferreira,Alfredo Goldman*

Main category: cs.SE

TL;DR: 研究比较了OOP和FP对软件架构的影响，通过Kotlin和Scala实现数字钱包系统，结合定性和定量分析，为开发者提供范式选择参考。


<details>
  <summary>Details</summary>
Motivation: 随着函数式编程在软件行业中的关注度增加，本研究旨在比较OOP和FP对软件系统架构特性的影响，帮助开发者和组织做出更明智的范式选择。

Method: 通过定性（自民族志分析）和定量（基于调查的分析）方法，比较了Kotlin（OOP）和Scala（FP）实现的数字钱包系统的设计和实现。

Result: 定性分析揭示了开发者编写代码时的视角，定量分析则展示了不同背景开发者对代码的阅读印象。

Conclusion: 研究结果表明，函数式编程（FP）和面向对象编程（OOP）在软件系统架构特性上各有优劣，具体选择取决于项目需求和开发者背景。

Abstract: After decades of dominance by object-oriented programming (OOP), functional
programming (FP) is gaining increasing attention in the software industry. This
study compares the impact of OOP and FP on the architectural characteristics of
software systems. For that, it examines the design and implementation of a
Digital Wallet system, developed in Kotlin (representing OOP) and Scala
(representing FP). The comparison is made through both qualitative and
quantitative analyses to explore how each paradigm influences the system's
architectural characteristics. The self-ethnographic qualitative analysis
provides a side-by-side comparison of both implementations, revealing the
perspective of those writing such code. The survey-based quantitative analysis
gathers feedback from developers with diverse backgrounds, showing their
impressions of those reading this code. Hopefully, these results may be useful
for developers or organizations seeking to make more informed decisions about
which paradigm is best suited for their next project.

</details>


### [98] [Leveraging Large Language Model for Information Retrieval-based Bug Localization](https://arxiv.org/abs/2508.00253)
*Moumita Asad,Rafed Muhammad Yasir,Armin Geramirad,Sam Malek*

Main category: cs.SE

TL;DR: GenLoc是一种基于LLM的bug定位方法，通过迭代分析代码和可选语义检索，显著提升了定位准确率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（从向量空间模型到深度学习模型）在bug定位中的效果受限于bug报告与源代码之间的词汇不匹配问题。

Method: 提出了一种名为GenLoc的新型方法，结合LLM和代码探索功能迭代分析代码库，并可选择性地使用向量嵌入检索语义相关文件以获取更好的上下文。

Result: 在六个大型Java项目的9000多个真实bug报告上评估，GenLoc在多个指标上优于五种最先进的bug定位技术。

Conclusion: GenLoc通过利用大型语言模型（LLM）和代码探索功能，显著提升了基于信息检索的bug定位效果，平均在Accuracy@1指标上提升了60%以上。

Abstract: Information Retrieval-based Bug Localization aims to identify buggy source
files for a given bug report. While existing approaches -- ranging from vector
space models to deep learning models -- have shown potential in this domain,
their effectiveness is often limited by the vocabulary mismatch between bug
reports and source code. To address this issue, we propose a novel Large
Language Model (LLM) based bug localization approach, called GenLoc. Given a
bug report, GenLoc leverages an LLM equipped with code-exploration functions to
iteratively analyze the code base and identify potential buggy files. To gather
better context, GenLoc may optionally retrieve semantically relevant files
using vector embeddings. GenLoc has been evaluated on over 9,000 real-world bug
reports from six large-scale Java projects. Experimental results show that
GenLoc outperforms five state-of-the-art bug localization techniques across
multiple metrics, achieving an average improvement of more than 60\% in
Accuracy@1.

</details>


### [99] [Accurate and Consistent Graph Model Generation from Text with Large Language Models](https://arxiv.org/abs/2508.00255)
*Boqi Chen,Ou Wei,Bingzhou Zheng,Gunter Mussbacher*

Main category: cs.SE

TL;DR: 本文提出一个抽象-具体化框架，通过聚合和细化LLM的多个输出来提高图模型生成的一致性和质量，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 解决LLM生成的图模型中存在的语法违规、约束不一致和准确性不足的问题。

Method: 通过构建一个概率性部分模型来聚合所有候选输出，然后将其细化为满足所有约束的最合适具体模型。

Result: 评估结果表明，该方法在多个开源和闭源LLM上显著提高了生成图模型的一致性和质量。

Conclusion: 提出的抽象-具体化框架显著提高了LLM生成的图模型的一致性和质量。

Abstract: Graph model generation from natural language description is an important task
with many applications in software engineering. With the rise of large language
models (LLMs), there is a growing interest in using LLMs for graph model
generation. Nevertheless, LLM-based graph model generation typically produces
partially correct models that suffer from three main issues: (1) syntax
violations: the generated model may not adhere to the syntax defined by its
metamodel, (2) constraint inconsistencies: the structure of the model might not
conform to some domain-specific constraints, and (3) inaccuracy: due to the
inherent uncertainty in LLMs, the models can include inaccurate, hallucinated
elements. While the first issue is often addressed through techniques such as
constraint decoding or filtering, the latter two remain largely unaddressed.
Motivated by recent self-consistency approaches in LLMs, we propose a novel
abstraction-concretization framework that enhances the consistency and quality
of generated graph models by considering multiple outputs from an LLM. Our
approach first constructs a probabilistic partial model that aggregates all
candidate outputs and then refines this partial model into the most appropriate
concrete model that satisfies all constraints. We evaluate our framework on
several popular open-source and closed-source LLMs using diverse datasets for
model generation tasks. The results demonstrate that our approach significantly
improves both the consistency and quality of the generated graph models.

</details>


### [100] [Benchmarking LLMs for Unit Test Generation from Real-World Functions](https://arxiv.org/abs/2508.00408)
*Dong Huang,Jie M. Zhang,Mark Harman,Qianru Zhang,Mingzhe Du,See-Kiong Ng*

Main category: cs.SE

TL;DR: ULT是一个针对LLM单元测试生成的新基准，解决了现有基准的数据污染和结构简单问题，结果表明其更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM测试生成基准存在数据污染和结构简单的问题，导致科学结论的有效性受限。

Method: 通过多阶段筛选过程构建ULT，确保高圈复杂度和减少测试用例污染，同时提供PLT作为对比基准。

Result: LLMs在ULT上的表现（准确率41.32%，语句覆盖率45.10%等）显著低于TestEval和PLT，证明ULT更具挑战性。

Conclusion: ULT（UnLeakedTestbench）作为一个新设计的基准测试，显著提升了评估LLMs在单元测试生成领域的挑战性和真实性，同时通过PLT（PreLeakedTestbench）提供了对记忆与推理能力的控制分析。

Abstract: Recently, large language models (LLMs) have shown great promise in automating
unit test generation, significantly reducing the manual effort required by
developers. To effectively evaluate the capabilities of LLMs in this domain, it
is crucial to have a well-designed benchmark that accurately reflects
real-world scenarios and mitigates common pitfalls. Existing LLM test
generation benchmarks are limited by two critical drawbacks: data contamination
and structurally simple function code. As a result, we often cannot rely on the
validity of scientific conclusions drawn from empirical studies using these
limited benchmarks. The empirical evidence presented may be biased due to
contamination and may fail to generalize beyond toy programs due to structural
simplicity.
  To address these problems, we introduce ULT (UnLeakedTestbench), a new
benchmark specifically designed for function-level unit test generation from
real-world Python functions. ULT is constructed through a multi-stage curation
process that ensures high cyclomatic complexity and mitigates test case
contamination. With 3,909 carefully selected function-level tasks, ULT provides
a more realistic and challenging evaluation of LLMs' test generation
capabilities. We also provide PLT (PreLeakedTestbench), a pair benchmark of ULT
with leaked tests designed to enable a controlled analysis of memorization
versus reasoning in test generation. Our evaluation results demonstrate that
ULT is significantly more challenging. For example, test cases generated by
LLMs only achieve 41.32\%, 45.10\%, 30.22\%, and 40.21\% for accuracy,
statement coverage, branch coverage, and mutation score on average for all
LLMs, respectively. These results are substantially lower than the
corresponding metrics on TestEval (91.79\%, 92.18\%, 82.04\%, and 49.69\%) and
PLT (47.07\%, 55.13\%, 40.07\%, and 50.80\%).

</details>


### [101] [Managing Power Gaps as a Topic of Pair Programming Skill: A Grounded Theory](https://arxiv.org/abs/2508.00462)
*Linus Ververs,Lutz Prechelt*

Main category: cs.SE

TL;DR: 该研究通过扎根理论分析22个工业结对编程会话并调查292名参与者，揭示了权力差距现象及其负面影响，建议避免层级行为并增加平衡行为以提高结对编程效果。


<details>
  <summary>Details</summary>
Motivation: 了解在工业中使用的结对编程中出现的与权力相关的现象，并为从业者提供如何更好地进行结对编程的建议。

Method: 分析22个工业结对编程会话，使用扎根理论方法论。制定关于权力相关行为的扎根理论。对292名参与者进行关于该理论的调查，以证明这些现象的普遍性。

Result: 我们的理论描述了权力差距现象：感知到的参与机会差异。理论展示了导致权力差距的行为或由此产生的行为。权力差距往往会损害知识传递、代码质量和流程效率。调查结果表明，我们理论中的所有概念在实践中都很常见。

Conclusion: 掌握避免权力差距的能力是结对编程技能的重要组成部分。具体来说，结对伙伴需要避免层级行为（这往往会创造或加剧权力差距），并应执行足够的平衡行为（这可以防止或减少权力差距）。

Abstract: Context: Pair Programming as a work mode is used (occasionally or frequently)
throughout professional software development. Objective: Understand what
power-related phenomena occur in pair programming as it is used in industry;
give advice to practitioners on how to do better pair programming. Method:
Analyze 22 industrial pair programming sessions using Grounded Theory
Methodology. Formulate a Grounded Theory on power-related behaviors. Run a
survey with 292 participants about that theory. Use it to demonstrate that the
phenomena are common. Results: Our theory describes the phenomenon of Power
Gap: a perceived difference in participation opportunities. The theory shows
the behaviors that create a Power Gap or result from it. Power Gaps tend to
damage knowledge transfer, code quality, and process effi ciency. The survey
results show that all concepts from our theory are frequent in practice. They
also provide more grounding for concepts that are observable only indirectly.
Conclusions: It is a valuable component of pair programming skill to be able to
avoid Power Gaps. Specifically, pair partners need to avoid Hierarchical
Behavior (which tends to create or increase a Power Gap) and should perform
enough Equalizing Behavior (which prevents or reduces a Power Gap).

</details>


### [102] [Desyan: A Platform for Seamless Value-Flow and Symbolic Analysis](https://arxiv.org/abs/2508.00508)
*Panagiotis Diamantakis,Thanassis Avgerinos,Yannis Smaragdakis*

Main category: cs.SE

TL;DR: Desyan是一个统一平台，无缝集成价值流和符号分析，支持多种推理模式，显著提升分析效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 价值流分析和符号分析虽然各自在多个应用领域取得成功，但缺乏统一的平台实现高效集成，限制了其联合应用的潜力。

Method: Desyan扩展了生产级的Datalog固定点引擎（Soufflé），集成了全功能的SMT求解能力，并支持Datalog原生符号推理模块。

Result: Desyan在价值流分析中表现卓越（执行时间提升20倍以上），在需要复杂SMT求解的场景下也能高效利用领先的SMT求解器，同时在轻量级符号推理中实现显著加速（速度提升2倍以上）。

Conclusion: Desyan平台成功填补了价值流分析和符号分析之间的技术空白，提供了一个高效、灵活的统一平台，支持多种分析需求的混合推理。

Abstract: Over the past two decades, two different types of static analyses have
emerged as dominant paradigms both in academia and industry: value-flow
analysis (e.g., data-flow analysis or points-to analysis) and symbolic analysis
(e.g., symbolic execution). Despite their individual successes in numerous
application fields, the two approaches have remained largely separate; an
artifact of the simple reality that there is no broadly adopted unifying
platform for effortless and efficient integration of symbolic techniques with
high-performance data-flow reasoning.
  To bridge this gap, we introduce Desyan: a platform for writing program
analyses with seamless integration of value-flow and symbolic reasoning. Desyan
expands a production-ready Datalog fixpoint engine (Souffl\'e) with
full-fledged SMT solving invoking industry-leading SMT engines. Desyan provides
constructs for automatically (and efficiently!) handling typical patterns that
come up in program analysis. At the same time, the integration is agnostic with
respect to the solving technology, and supports Datalog-native symbolic
reasoning, via a bottom-up algebraic reasoning module.
  The result is an engine that allows blending different kinds of reasoning, as
needed for the underlying analysis. For value-flow analysis, the engine is the
best-in-class Datalog evaluator (often by a factor of over 20x in execution
time); for applications that require full SMT (e.g., a concolic execution
engine or other symbolic evaluator that needs to solve arbitrarily complex
conditions), the engine is leveraging the leading SMT solvers; for lightweight
symbolic evaluation (e.g., solving simple conditionals in the context of a
path-sensitive analysis), the engine can use Datalog-native symbolic reasoning,
achieving large speedups (often of over 2x) compared to eagerly appealing to an
SMT solver.

</details>


### [103] [SPENCER: Self-Adaptive Model Distillation for Efficient Code Retrieval](https://arxiv.org/abs/2508.00546)
*Wenchao Gu,Zongyi Lyu,Yanlin Wang,Hongyu Zhang,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: SPENCER框架结合双编码器和交叉编码器提升代码检索性能，并通过模型蒸馏技术减少70%推理时间，保持98%性能。


<details>
  <summary>Details</summary>
Motivation: 双编码器缺乏底层代码片段和描述的交互，限制了模型性能，需要提升效率的同时保持效果。

Method: 提出SPENCER框架，结合双编码器和交叉编码器，并引入自适应的模型蒸馏技术和助教选择策略。

Result: 实验表明，双编码器与交叉编码器结合显著提升性能，模型蒸馏技术减少70%推理时间且保留98%以上性能。

Conclusion: SPENCER框架通过结合双编码器和交叉编码器，显著提升了代码检索的性能，同时通过创新的模型蒸馏技术，大幅减少了推理时间，保持了98%以上的性能。

Abstract: Code retrieval aims to provide users with desired code snippets based on
users' natural language queries. With the development of deep learning
technologies, adopting pre-trained models for this task has become mainstream.
Considering the retrieval efficiency, most of the previous approaches adopt a
dual-encoder for this task, which encodes the description and code snippet into
representation vectors, respectively. However, the model structure of the
dual-encoder tends to limit the model's performance, since it lacks the
interaction between the code snippet and description at the bottom layer of the
model during training. To improve the model's effectiveness while preserving
its efficiency, we propose a framework, which adopts Self-AdaPtive Model
Distillation for Efficient CodE Retrieval, named SPENCER. SPENCER first adopts
the dual-encoder to narrow the search space and then adopts the cross-encoder
to improve accuracy. To improve the efficiency of SPENCER, we propose a novel
model distillation technique, which can greatly reduce the inference time of
the dual-encoder while maintaining the overall performance. We also propose a
teaching assistant selection strategy for our model distillation, which can
adaptively select the suitable teaching assistant models for different
pre-trained models during the model distillation to ensure the model
performance. Extensive experiments demonstrate that the combination of
dual-encoder and cross-encoder improves overall performance compared to solely
dual-encoder-based models for code retrieval. Besides, our model distillation
technique retains over 98% of the overall performance while reducing the
inference time of the dual-encoder by 70%.

</details>


### [104] [Can User Feedback Help Issue Detection? An Empirical Study on a One-billion-user Online Service System](https://arxiv.org/abs/2508.00593)
*Shuyao Jiang,Jiazhen Gu,Wujie Zheng,Yangfan Zhou,Michael R. Lyu*

Main category: cs.SE

TL;DR: 本文通过实证研究发现用户反馈中存在大量无关信息，仅依赖反馈特征难以检测严重问题，但反馈主题分布相似性支持机器学习方法的应用，为大规模系统问题检测提供了实证基础。


<details>
  <summary>Details</summary>
Motivation: 为了开发更好的基于反馈的问题检测方法，首先需要全面了解真实生产系统中用户反馈的特点。

Method: 本文对来自一个拥有十亿用户的在线服务系统中六个真实服务的50,378,766条用户反馈进行了实证研究。首先研究了用户在反馈中提供的内容，然后检验了反馈项的某些特征是否可以作为严重问题的良好指标，最后探讨了采用机器学习技术分析用户反馈的合理性。

Result: 研究结果表明，大量用户反馈提供了与系统问题无关的信息，因此处理用户反馈时过滤掉与问题无关的信息至关重要。此外，研究发现仅基于用户反馈特征难以轻易检测到严重问题。最后，研究发现不同时间间隔内反馈主题的分布相似，这证实了设计基于机器学习的方法是更好分析用户反馈的可行方向。

Conclusion: 本文的发现可为大规模服务系统中基于反馈的问题检测提供实证基础，为实用问题检测方法的设计和实现提供启示。

Abstract: Background: It has long been suggested that user feedback, typically written
in natural language by end-users, can help issue detection. However, for
large-scale online service systems that receive a tremendous amount of
feedback, it remains a challenging task to identify severe issues from user
feedback. Aims: To develop a better feedback-based issue detection approach, it
is crucial first to gain a comprehensive understanding of the characteristics
of user feedback in real production systems. Method: In this paper, we conduct
an empirical study on 50,378,766 user feedback items from six real-world
services in a one-billion-user online service system. We first study what users
provide in their feedback. We then examine whether certain features of feedback
items can be good indicators of severe issues. Finally, we investigate whether
adopting machine learning techniques to analyze user feedback is reasonable.
Results: Our results show that a large proportion of user feedback provides
irrelevant information about system issues. As a result, it is crucial to
filter out issue-irrelevant information when processing user feedback.
Moreover, we find severe issues that cannot be easily detected based solely on
user feedback characteristics. Finally, we find that the distributions of the
feedback topics in different time intervals are similar. This confirms that
designing machine learning-based approaches is a viable direction for better
analyzing user feedback. Conclusions: We consider that our findings can serve
as an empirical foundation for feedback-based issue detection in large-scale
service systems, which sheds light on the design and implementation of
practical issue detection approaches.

</details>


### [105] [MCeT: Behavioral Model Correctness Evaluation using Large Language Models](https://arxiv.org/abs/2508.00630)
*Khaled Ahmed,Jialing Song,Boqi Chen,Ou Wei,Bingzhou Zheng*

Main category: cs.SE

TL;DR: MCeT是首个自动化评估行为模型（序列图）正确性的工具，通过多角度细粒度检查和自一致性验证，显著提升问题发现率和精确度。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在模型生成中的广泛应用，需要自动化工具评估行为模型的正确性，以支持工程师和AI助手改进模型质量。

Method: 提出MCeT工具，利用LLMs的自然语言理解能力，将序列图分解为原子交互，并与需求文本的原子项进行多角度对比，同时引入自一致性检查以减少LLM的幻觉问题。

Result: MCeT的联合方法将直接检查的精确度从0.58提升至0.81，发现问题的数量比直接方法多90%，平均每张图报告6个新问题。

Conclusion: MCeT通过多角度、细粒度的检查方法，显著提高了行为模型（如序列图）正确性评估的准确性和问题发现率，为系统工程师和AI助手提供了有效的反馈和改进机制。

Abstract: Behavioral model diagrams, e.g., sequence diagrams, are an essential form of
documentation that are typically designed by system engineers from requirements
documentation, either fully manually or assisted by design tools. With the
growing use of Large Language Models (LLM) as AI modeling assistants, more
automation will be involved in generating diagrams. This necessitates the
advancement of automatic model correctness evaluation tools. Such a tool can be
used to evaluate both manually and AI automatically generated models; to
provide feedback to system engineers, and enable AI assistants to self-evaluate
and self-enhance their generated models.
  In this paper, we propose MCeT, the first fully automated tool to evaluate
the correctness of a behavioral model, sequence diagrams in particular, against
its corresponding requirements text and produce a list of issues that the model
has. We utilize LLMs for the correctness evaluation tasks as they have shown
outstanding natural language understanding ability. However, we show that
directly asking an LLM to compare a diagram to requirements finds less than 35%
of issues that experienced engineers can find. We propose to supplement the
direct check with a fine-grained, multi-perspective approach; we split the
diagram into atomic, non-divisible interactions, and split the requirements
text into atomic, self-contained items. We compare the diagram with atomic
requirements and each diagram-atom with the requirements. We also propose a
self-consistency checking approach that combines perspectives to mitigate LLM
hallucinated issues. Our combined approach improves upon the precision of the
direct approach from 0.58 to 0.81 in a dataset of real requirements. Moreover,
the approach finds 90% more issues that the experienced engineers found than
the direct approach, and reports an average of 6 new issues per diagram.

</details>


### [106] [Is LLM-Generated Code More Maintainable \& Reliable than Human-Written Code?](https://arxiv.org/abs/2508.00700)
*Alfred Santa Molison,Marcia Moraes,Glaucia Melo,Fabio Santos,Wesley K. G. Assuncao*

Main category: cs.SE

TL;DR: 研究发现LLM生成的代码缺陷更少且修复成本更低，但在复杂场景中可能引入关键问题，需系统评估。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在软件开发中的使用日益广泛，但其生成的代码解决方案在软件质量方面的表现以及与人编写代码的比较仍不明确。

Method: 实证研究整合了编码任务数据集、三种LLM配置（零样本、少样本和微调）以及SonarQube来评估软件质量。数据集包含三个难度级别的Python代码解决方案：入门级、面试级和竞赛级。分析了包括可维护性和可靠性在内的关键代码质量指标，以及解决代码问题所需的预估工作量。

Result: 分析显示，LLM生成的代码总体上有更少的缺陷且修复所需工作量更少。有趣的是，微调模型减少了高严重性问题的发生率，如阻塞性和关键性缺陷，并将其转移到较低严重性类别，但降低了模型性能。在竞赛级问题中，LLM解决方案有时会引入人编写代码中不存在的结构性问题。

Conclusion: 研究结果提供了关于LLM生成代码质量的有价值见解，但在更复杂场景中引入的关键问题凸显了对LLM解决方案进行系统评估和验证的必要性。这项工作加深了对LLM在代码生成中优势和局限性的理解。

Abstract: Background: The rise of Large Language Models (LLMs) in software development
has opened new possibilities for code generation. Despite the widespread use of
this technology, it remains unclear how well LLMs generate code solutions in
terms of software quality and how they compare to human-written code. Aims:
This study compares the internal quality attributes of LLM-generated and
human-written code. Method: Our empirical study integrates datasets of coding
tasks, three LLM configurations (zero-shot, few-shot, and fine-tuning), and
SonarQube to assess software quality. The dataset comprises Python code
solutions across three difficulty levels: introductory, interview, and
competition. We analyzed key code quality metrics, including maintainability
and reliability, and the estimated effort required to resolve code issues.
Results: Our analysis shows that LLM-generated code has fewer bugs and requires
less effort to fix them overall. Interestingly, fine-tuned models reduced the
prevalence of high-severity issues, such as blocker and critical bugs, and
shifted them to lower-severity categories, but decreased the model's
performance. In competition-level problems, the LLM solutions sometimes
introduce structural issues that are not present in human-written code.
Conclusion: Our findings provide valuable insights into the quality of
LLM-generated code; however, the introduction of critical issues in more
complex scenarios highlights the need for a systematic evaluation and
validation of LLM solutions. Our work deepens the understanding of the
strengths and limitations of LLMs for code generation.

</details>


### [107] [Tool-Assisted Conformance Checking to Reference Process Models](https://arxiv.org/abs/2508.00738)
*Bernhard Rumpe,Max Stachon,Sebastian Stüber,Valdes Voufo*

Main category: cs.SE

TL;DR: 本文提出了一种自动化检查流程模型与参考模型一致性的新方法，通过因果依赖分析增强验证能力。


<details>
  <summary>Details</summary>
Motivation: 现有的流程模型一致性检查方法主要关注流程执行轨迹的验证，缺乏语义模型比较的表达能力和自动化需求，这一问题尚未解决。

Method: 本文提出了一种基于任务和事件因果依赖分析的算法，用于自动化检查具体流程模型与参考模型的一致性。

Result: 通过案例研究评估了算法的有效性，并讨论了其优势和局限性。

Conclusion: 本研究通过因果依赖分析提出了一种自动化一致性检查方法，增强了流程模型一致性验证的准确性和灵活性。

Abstract: Reference models convey best practices and standards. The reference
frameworks necessitate conformance checks to ensure adherence to established
guidelines and principles, which is crucial for maintaining quality and
consistency in various processes. This paper explores automated conformance
checks for concrete process models against reference models using causal
dependency analysis of tasks and events. Existing notions of conformance
checking for process models focus on verifying process execution traces and
lack the expressiveness and automation needed for semantic model comparison,
leaving this question unresolved. We integrate our approach into a broader
semantic framework for defining reference model conformance. We outline an
algorithm for reference process model conformance checking, evaluate it through
a case study, and discuss its strengths and limitations. Our research provides
a tool-assisted solution enhancing accuracy and flexibility in process model
conformance verification.

</details>


### [108] [Dynamic Symbolic Execution for Semantic Difference Analysis of Component and Connector Architectures](https://arxiv.org/abs/2508.00749)
*Johanna Grahl,Bernhard Rumpe,Max Stachon,Sebastian Stüber*

Main category: cs.SE

TL;DR: 本文探讨了动态符号执行（DSE）在组件和连接器架构语义差异分析中的应用，增强了MontiArc模型的数据收集能力，并评估了DSE的适用性，发现其潜力但可扩展性有限。


<details>
  <summary>Details</summary>
Motivation: 在模型驱动开发中，确保演化模型的正确性和一致性至关重要。

Method: 增强了现有的MontiArc-to-Java生成器，收集符号和具体执行数据，包括过渡条件、访问状态和自动机内部变量。

Result: 评估了基于运行时效率、最小性和完整性的各种执行策略，建立了评估DSE在语义差异分析中适用性的框架。

Conclusion: 尽管DSE在分析组件和连接器架构方面显示出潜力，但可扩展性仍是主要限制，需要进一步研究以提升其在大型系统中的实用性。

Abstract: In the context of model-driven development, ensuring the correctness and
consistency of evolving models is paramount. This paper investigates the
application of Dynamic Symbolic Execution (DSE) for semantic difference
analysis of component-and-connector architectures, specifically utilizing
MontiArc models. We have enhanced the existing MontiArc-to-Java generator to
gather both symbolic and concrete execution data at runtime, encompassing
transition conditions, visited states, and internal variables of automata. This
data facilitates the identification of significant execution traces that
provide critical insights into system behavior. We evaluate various execution
strategies based on the criteria of runtime efficiency, minimality, and
completeness, establishing a framework for assessing the applicability of DSE
in semantic difference analysis. Our findings indicate that while DSE shows
promise for analyzing component and connector architectures, scalability
remains a primary limitation, suggesting further research is needed to enhance
its practical utility in larger systems.

</details>


### [109] [From Code to Career: Assessing Competitive Programmers for Industry Placement](https://arxiv.org/abs/2508.00772)
*Md Imranur Rahman Akib,Fathima Binthe Muhammed,Umit Saha,Md Fazlul Karim Patwary,Mehrin Anannya,Md Alomgeer Hussein,Md Biplob Hosen*

Main category: cs.SE

TL;DR: 研究利用Codeforces数据和随机森林模型预测程序员就业准备情况，成功区分不同技能水平，为职业评估提供机器学习基础。


<details>
  <summary>Details</summary>
Motivation: 快速发展的科技行业需要评估程序员基于编码表现的就业准备情况的工具。本研究旨在分析用户的竞争编程活动与其获得不同级别软件工程职位机会之间的相关性。

Method: 使用Codeforces API收集用户数据，处理关键性能指标，并利用随机森林分类器构建预测模型。系统通过Flask实现，并部署在Render上以进行实时预测。

Result: 评估表明，该方法能有效根据编码熟练度和参与度区分不同技能水平，将用户分类为四个就业准备级别。

Conclusion: 该研究为机器学习在职业评估中的应用奠定了基础，并可以扩展到预测更广泛技术领域的就业准备情况。

Abstract: In today's fast-paced tech industry, there is a growing need for tools that
evaluate a programmer's job readiness based on their coding performance. This
study focuses on predicting the potential of Codeforces users to secure various
levels of software engineering jobs. The primary objective is to analyze how a
user's competitive programming activity correlates with their chances of
obtaining positions, ranging from entry-level roles to jobs at major tech
companies. We collect user data using the Codeforces API, process key
performance metrics, and build a prediction model using a Random Forest
classifier. The model categorizes users into four levels of employability,
ranging from those needing further development to those ready for top-tier tech
jobs. The system is implemented using Flask and deployed on Render for
real-time predictions. Our evaluation demonstrates that the approach
effectively distinguishes between different skill levels based on coding
proficiency and participation. This work lays a foundation for the use of
machine learning in career assessment and could be extended to predict job
readiness in broader technical fields.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [110] [Agent Network Protocol Technical White Paper](https://arxiv.org/abs/2508.00007)
*Gaowei Chang,Eidan Lin,Chengxuan Yuan,Rizhao Cai,Binbin Chen,Xuan Xie,Yin Zhang*

Main category: cs.NI

TL;DR: ANP是一种面向智能体网络的新一代通信协议，通过AI原生设计和三层协议系统解决大规模智能体互联与协作的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有互联网基础设施主要为人类交互设计，导致智能体之间存在数据孤岛、不友好接口和高协作成本，难以支持大规模智能体互联与协作的需求。

Method: ANP采用AI原生设计，保持与现有互联网协议的兼容性，采用模块化可组合架构，遵循简约但可扩展的原则，并基于现有基础设施实现快速部署。

Result: ANP通过三层协议系统（身份与加密通信层、元协议协商层和应用协议层）系统性解决了智能体身份认证、动态协商和能力发现互操作性等问题。

Conclusion: ANP提出了一种新一代的通信协议，旨在解决大规模智能体互联与协作的需求，通过三层协议系统系统性解决了身份认证、动态协商和能力发现互操作性等问题。

Abstract: With the development of large models and autonomous decision-making AI,
agents are rapidly becoming the new entities of the internet, following mobile
apps. However, existing internet infrastructure is primarily designed for human
interaction, creating data silos, unfriendly interfaces, and high collaboration
costs among agents, making it difficult to support the needs for large-scale
agent interconnection and collaboration. The internet is undergoing a profound
transformation, showing four core trends: agents replacing traditional
software, universal agent interconnection, native protocol-based connections,
and autonomous agent organization and collaboration. To align with these
trends, Agent Network Protocol (ANP) proposes a new generation of communication
protocols for the Agentic Web. ANP adheres to AI-native design, maintains
compatibility with existing internet protocols, adopts a modular composable
architecture, follows minimalist yet extensible principles, and enables rapid
deployment based on existing infrastructure. Through a three-layer protocol
system--identity and encrypted communication layer, meta-protocol negotiation
layer, and application protocol layer--ANP. systematically solves the problems
of agent identity authentication, dynamic negotiation, and capability discovery
interoperability.

</details>


### [111] [Enabling Immersive XR Collaborations over FTTR Networks (Invited)](https://arxiv.org/abs/2508.00009)
*Sourav Mondal,Elaine Wong*

Main category: cs.NI

TL;DR: FTTR通过预测性带宽分配和无缝切换方案，支持高质量的室内扩展现实协作体验。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决室内扩展现实协作中高质量沉浸式体验的需求。

Method: 本文探讨了在FTTR上实施的预测性带宽分配和无缝切换方案。

Result: 研究表明，通过所提出的方案，可以实现高质量的沉浸式体验。

Conclusion: Fiber-To-The-Room（FTTR）是实现室内扩展现实协作的潜在解决方案，通过预测性带宽分配和无缝切换方案，能够提供高质量的沉浸式体验。

Abstract: Fiber-To-The-Room is a potential solution to achieve in-premise extended
reality collaborations. This paper explores predictive bandwidth allocation and
seamless handover schemes over FTTR, showing high-quality immersive experience
for in-premise collaborations can be achieved. \c{opyright} 2025 The Author(s).

</details>


### [112] [Quality-of-Service Aware LLM Routing for Edge Computing with Multiple Experts](https://arxiv.org/abs/2508.00234)
*Jin Yang,Qiong Wu,Zhiying Feng,Zhi Zhou,Deke Guo,Xu Chen*

Main category: cs.NI

TL;DR: 本文提出一种基于DRL的QoS感知LLM路由框架，通过动态状态抽象和HAN优化路由，显著提升服务质量和资源效率。


<details>
  <summary>Details</summary>
Motivation: 解决云LLM服务的高延迟、响应不稳定和隐私问题，以及现有路由算法无法同时处理LLM服务异构性、请求干扰和动态工作负载的挑战。

Method: 采用动态状态抽象技术和异构图注意力网络（HAN）紧凑表示全局状态特征，并引入动作影响估计器和定制奖励函数指导DRL代理。

Result: 在Poisson和真实工作负载上的实验表明，该算法显著提升了平均QoS和资源效率。

Conclusion: 本文提出的基于深度强化学习（DRL）的QoS感知LLM路由框架显著提升了平均QoS和计算资源效率，优于现有基线方法。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities,
leading to a significant increase in user demand for LLM services. However,
cloud-based LLM services often suffer from high latency, unstable
responsiveness, and privacy concerns. Therefore, multiple LLMs are usually
deployed at the network edge to boost real-time responsiveness and protect data
privacy, particularly for many emerging smart mobile and IoT applications.
Given the varying response quality and latency of LLM services, a critical
issue is how to route user requests from mobile and IoT devices to an
appropriate LLM service (i.e., edge LLM expert) to ensure acceptable
quality-of-service (QoS). Existing routing algorithms fail to simultaneously
address the heterogeneity of LLM services, the interference among requests, and
the dynamic workloads necessary for maintaining long-term stable QoS. To meet
these challenges, in this paper we propose a novel deep reinforcement learning
(DRL)-based QoS-aware LLM routing framework for sustained high-quality LLM
services. Due to the dynamic nature of the global state, we propose a dynamic
state abstraction technique to compactly represent global state features with a
heterogeneous graph attention network (HAN). Additionally, we introduce an
action impact estimator and a tailored reward function to guide the DRL agent
in maximizing QoS and preventing latency violations. Extensive experiments on
both Poisson and real-world workloads demonstrate that our proposed algorithm
significantly improves average QoS and computing resource efficiency compared
to existing baselines.

</details>


### [113] [Non-Terrestrial Network Models Using Stochastic Geometry: Planar or Spherical?](https://arxiv.org/abs/2508.00010)
*Ruibo Wang,Baha Eddine Youcef Belmekki,Howard H. Yang,Mohamed Slim Alouini*

Main category: cs.NI

TL;DR: 本文量化平面与球面模型的相对误差，提出点过程生成与误差估计算法，并推导最优平面高度，为高空非地面网络分析提供理论支持。


<details>
  <summary>Details</summary>
Motivation: 随着非地面网络的爆炸性部署，网络性能分析的计算复杂性迅速增加。平面模型忽略地球曲率，导致高空非地面网络分析存在偏差，但仍因简单性被广泛使用。

Method: 提出点过程生成算法同时生成一对同质且渐近相似的平面和球面点过程，引入多种相似性度量指标，并基于这些指标开发了相对误差估计算法。

Result: 数值结果研究了部署高度和区域如何影响非地面网络建模，并通过HAP和LEO卫星星座的案例研究验证了方法的有效性。

Conclusion: 本文通过引入相对误差量化平面与球面模型之间的差距，提出了一种点过程生成算法和相对误差估计算法，并推导了最优平面高度的解析表达式，为平面近似提供了理论支持。

Abstract: With the explosive deployment of non-terrestrial networks (NTNs), the
computational complexity of network performance analysis is rapidly escalating.
As one of the most suitable mathematical tools for analyzing large-scale
network topologies, stochastic geometry (SG) enables the representation of
network performance metrics as functions of network parameters, thus offering
low-complexity performance analysis solutions. However, choosing between planar
and spherical models remains challenging. Planar models neglect Earth's
curvature, causing deviations in high-altitude NTN analysis, yet are still
often used for simplicity. This paper introduces relative error to quantify the
gap between planar and spherical models, helping determine when planar modeling
is sufficient. To calculate the relative error, we first propose a point
process (PP) generation algorithm that simultaneously generates a pair of
homogeneous and asymptotically similar planar and spherical PPs. We then
introduce several typical similarity metrics, including topology-related and
network-level metrics, and further develop a relative error estimation
algorithm based on these metrics. In addition, we derive an analytical
expression for the optimal planar altitude, which reduces computational
complexity and provides theoretical support for planar approximation. Finally,
numerical results investigate how deployment altitude and region affect NTN
modeling, with case studies on HAP and LEO satellite constellations.

</details>


### [114] [AoI-Aware Resource Allocation with Deep Reinforcement Learning for HAPS-V2X Networks](https://arxiv.org/abs/2508.00011)
*Ahmet Melih Ince,Ayse Elif Canbilen,Halim Yanikomeroglu*

Main category: cs.NI

TL;DR: The paper proposes a DDPG-based approach to optimize AoI in HAPS-enabled V2X networks, enhancing 6G reliability for autonomous vehicles.


<details>
  <summary>Details</summary>
Motivation: 6G networks aim to meet HRLLC requirements for safety-critical applications like autonomous driving. Integrating NTN, especially HAPS, provides redundancy and ensures communication continuity under extreme conditions, particularly in rural or infrastructure-limited areas.

Method: The paper presents reinforcement learning-based approaches using deep deterministic policy gradient (DDPG) to dynamically optimize the age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks.

Result: The proposed method improves information freshness and network reliability by enabling independent learning without centralized coordination.

Conclusion: The study highlights the potential of HAPS-supported solutions combined with DDPG-based learning for efficient AoI-aware resource allocation in platoon-based autonomous vehicle systems.

Abstract: Sixth-generation (6G) networks are designed to meet the hyper-reliable and
low-latency communication (HRLLC) requirements of safety-critical applications
such as autonomous driving. Integrating non-terrestrial networks (NTN) into the
6G infrastructure brings redundancy to the network, ensuring continuity of
communications even under extreme conditions. In particular, high-altitude
platform stations (HAPS) stand out for their wide coverage and low latency
advantages, supporting communication reliability and enhancing information
freshness, especially in rural areas and regions with infrastructure
constraints. In this paper, we present reinforcement learning-based approaches
using deep deterministic policy gradient (DDPG) to dynamically optimize the
age-of-information (AoI) in HAPS-enabled vehicle-to-everything (V2X) networks.
The proposed method improves information freshness and overall network
reliability by enabling independent learning without centralized coordination.
The findings reveal the potential of HAPS-supported solutions, combined with
DDPG-based learning, for efficient AoI-aware resource allocation in
platoon-based autonomous vehicle systems.

</details>


### [115] [Performance Analysis of SAGIN from the Relay Perspective: A Spherical Stochastic Geometry Approach](https://arxiv.org/abs/2508.00020)
*Ferdaous Tarhouni,Ruibo Wang,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文利用球形随机几何（SSG）从继电器角度评估了HAPs在SAGIN中的性能，引入了三个新指标并提供了BREP的闭式表达式，分析了网络拓扑影响和最小传输功率需求。


<details>
  <summary>Details</summary>
Motivation: 随着全球无线通信需求的增长，卫星-空中-地面一体化网络（SAGIN）变得至关重要。高海拔平台（HAPs）作为通信枢纽和中继器，可以提升通信性能。本文旨在从继电器角度评估HAPs在SAGIN中的网络性能。

Method: 采用球形随机几何（SSG）作为工具，推导了三个性能指标的解析表达式，以实现低复杂度的性能评估。特别提供了端到端性能指标BREP的闭式表达式。

Result: 研究提供了BREP的闭式表达式，分析了卫星网络拓扑对性能的影响，并确定了满足数据速率需求的最小HAP传输功率。这些结果突出了SSG框架的优势。

Conclusion: 本文通过引入三个性能指标（平均接入数据速率、平均回程数据速率和回程速率超越概率BREP），利用球形随机几何（SSG）工具，从继电器角度评估了HAPs在SAGIN中的网络性能。研究还分析了卫星网络拓扑对性能的影响，并确定了满足短期和长期数据速率需求的最小HAP传输功率。

Abstract: In recent years, the satellite-aerial-ground integrated network (SAGIN) has
become essential in meeting the increasing demands for global wireless
communications. In SAGIN, high-altitude platforms (HAPs) can serve as
communication hubs and act as relays to enhance communication performance. In
this paper, we evaluate network performance and analyze the role of HAPs in
SAGIN from the relay perspective. Based on this unique perspective, we
introduce three metrics to evaluate the performance, named the average access
data rate, the average backhaul data rate, and the backhaul rate exceedance
probability (BREP). Considering the need for dynamic topology and interference
analysis, we choose spherical stochastic geometry (SSG) as a tool and derive
analytical expressions for the above metrics to achieve low-complexity
performance evaluation. Specifically, we provide a closed-form expression for
the end-to-end performance metric BREP. Given that there is no existing
literature in the SSG field studying networks from a relay perspective, we
specifically investigate the impact of satellite network topology on
performance in our numerical results to further highlight the advantages of the
SSG framework. Additionally, we analyze the minimum HAP transmission power
required to maintain both short-term and long-term data rate demands.

</details>


### [116] [Scalable Spectrum Availability Prediction using a Markov Chain Framework and ITU-R Propagation Models](https://arxiv.org/abs/2508.00028)
*Abir Ray*

Main category: cs.NI

TL;DR: 论文提出了一种结合马尔可夫链和传播模型的频谱预测框架，能高效识别可用频谱，适用于实时频谱管理。


<details>
  <summary>Details</summary>
Motivation: 频谱资源在时间和空间上经常未被充分利用，动态频谱访问策略允许次要用户利用未使用的频率，但关键挑战是预测频谱何时何地可用以避免干扰。

Method: 结合了两状态马尔可夫链模型和ITU-R的高保真传播模型（建议P.528和P.2108），预测频谱在时间和空间上的可用性。

Result: 结果表明，该方法能够准确预测频谱机会，计算效率高，适用于多种频段和场景。

Conclusion: 论文提出的框架能够有效识别可用频谱，计算成本低，适用于认知无线电网络和其他动态频谱共享系统的实时频谱管理。

Abstract: Spectrum resources are often underutilized across time and space, motivating
dynamic spectrum access strategies that allow secondary users to exploit unused
frequencies. A key challenge is predicting when and where spectrum will be
available (i.e., unused by primary licensed users) in order to enable proactive
and interference-free access. This paper proposes a scalable framework for
spectrum availability prediction that combines a two-state Markov chain model
of primary user activity with high-fidelity propagation models from the ITU-R
(specifically Recommendations P.528 and P.2108). The Markov chain captures
temporal occupancy patterns, while the propagation models incorporate path loss
and clutter effects to determine if primary signals exceed interference
thresholds at secondary user locations. By integrating these components, the
proposed method can predict spectrum opportunities both in time and space with
improved accuracy. We develop the system model and algorithm for the approach,
analyze its scalability and computational efficiency, and discuss assumptions,
limitations, and potential applications. The framework is flexible and can be
adapted to various frequency bands and scenarios. The results and analysis show
that the proposed approach can effectively identify available spectrum with low
computational cost, making it suitable for real-time spectrum management in
cognitive radio networks and other dynamic spectrum sharing systems.

</details>


### [117] [Towards Reliable AI in 6G: Detecting Concept Drift in Wireless Network](https://arxiv.org/abs/2508.00042)
*Athanasios Tziouvaras,Carolina Fortuna,George Floros,Kostas Kolomvatsos,Panagiotis Sarigiannidis,Marko Grobelnik,Blaž Bertalanič*

Main category: cs.NI

TL;DR: 本文提出两种无监督概念漂移检测器，显著提升6G网络中模型适应性和性能。


<details>
  <summary>Details</summary>
Motivation: AI原生6G网络中，无线环境的非平稳性导致概念漂移，现有方法要么过于特定领域，要么难以应对某些类型的概念漂移。

Method: 介绍了两种无监督、模型无关的批量概念漂移检测器，通过计算预期效用分数来决定是否需要模型重新训练。

Result: 在室外指纹定位和链路异常检测两个真实无线用例中验证，性能优于传统检测器20-40个百分点，F1分数达0.94和1.00，误报率降低最多20个百分点。

Conclusion: 本文提出的两种无监督、模型无关的批量概念漂移检测器在真实无线用例中表现出色，显著优于传统检测器，有效减少了误报率。

Abstract: AI-native 6G networks promise unprecedented automation and performance by
embedding machine-learning models throughout the radio access and core segments
of the network. However, the non-stationary nature of wireless environments due
to infrastructure changes, user mobility, and emerging traffic patterns,
induces concept drifts that can quickly degrade these model accuracies.
Existing methods in general are very domain specific, or struggle with certain
type of concept drift. In this paper, we introduce two unsupervised,
model-agnostic, batch concept drift detectors. Both methods compute an
expected-utility score to decide when concept drift occurred and if model
retraining is warranted, without requiring ground-truth labels after
deployment. We validate our framework on two real-world wireless use cases in
outdoor fingerprinting for localization and for link-anomaly detection, and
demonstrate that both methods are outperforming classical detectors such as
ADWIN, DDM, CUSUM by 20-40 percentage points. Additionally, they achieve an
F1-score of 0.94 and 1.00 in correctly triggering retraining alarm, thus
reducing the false alarm rate by up to 20 percentage points compared to the
best classical detectors.

</details>


### [118] [Benchmarking XRootD-HTTPS on 400Gbps Links with Variable Latencies](https://arxiv.org/abs/2508.00228)
*Aashay Arora,Diego Davila,Frank Würthwein,John Graham,Dima Mishin,Justas Balcas,Tom Lehman,Xi Yang,Chin Guok,Harvey Newman*

Main category: cs.NI

TL;DR: 研究探讨了US-CMS Tier-2站点如何优化软件和硬件以支持400 Gbps带宽需求，重点测试了XRootD HTTP第三方拷贝的性能。


<details>
  <summary>Details</summary>
Motivation: High Luminosity-LHC时代预计将带来网络流量的显著增长，需确保软件和硬件能够支持生产和用户数据分析访问的带宽需求。

Method: 通过系统性测试，包括调整每个集群的起源点数量和CPU分配，模拟真实网络条件（如创建跨多个交换机的网络“循环”），评估XRootD HTTP第三方拷贝在多个400 Gbps链接上的性能。

Result: 研究识别了在不同主机和传输配置下XRootD HTTP第三方拷贝的性能表现，为优化网络传输提供了依据。

Conclusion: 为应对High Luminosity-LHC时代的需求，US-CMS Tier-2站点需在软件和硬件上进行改进，以满足400 Gbps带宽需求并应对不同站点间延迟的挑战。

Abstract: In anticipation of the High Luminosity-LHC era, there is a critical need to
oversee software readiness for upcoming growth in network traffic for
production and user data analysis access. This paper looks into software and
hardware required improvements in US-CMS Tier-2 sites to be able to sustain and
meet the projected 400 Gbps bandwidth demands while tackling the challenge
posed by varying latencies between sites. Specifically, our study focuses on
identifying the performance of XRootD HTTP third-party copies across multiple
400 Gbps links and exploring different host and transfer configurations. Our
approach involves systematic testing with variations in the number of origins
per cluster and CPU allocations for each origin. By replicating real network
conditions and creating network "loops" that traverse multiple switches across
the wide area network, we are able to replicate authentic network conditions

</details>


### [119] [Large AI Model-Enabled Secure Communications in Low-Altitude Wireless Networks: Concepts, Perspectives and Case Study](https://arxiv.org/abs/2508.00256)
*Chuang Zhang,Geng Sun,Jiacheng Wang,Yijing Lin,Weijie Yuan,Sinem Coleri,Dusit Niyato,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 论文探讨了LAM在解决LAWNs安全通信挑战中的应用，提出了一种基于LAM的优化框架，并通过案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: LAWNs因其低空操作、频繁移动和依赖非授权频谱等特点，面临独特的安全挑战，传统AI方法存在局限性。因此，研究LAM在LAWNs安全通信中的应用具有重要价值。

Method: 论文首先探讨了LAWNs中传统AI方法的安全风险和局限性，随后介绍了LAM的基本概念及其在解决这些挑战中的作用。提出了一种新颖的基于LAM的优化框架，利用LLMs生成增强的状态特征和设计内在奖励，以提升强化学习在安全通信任务中的性能。

Result: 通过典型案例研究，仿真结果验证了所提出的LAM-based优化框架在提升LAWNs安全通信性能方面的有效性。

Conclusion: 论文提出了一个基于LAM的优化框架，通过结合大型语言模型（LLMs）和强化学习，提升了LAWNs中的安全通信性能，并通过案例研究验证了其有效性。同时，展望了LAM在安全LAWN应用中的未来方向。

Abstract: Low-altitude wireless networks (LAWNs) have the potential to revolutionize
communications by supporting a range of applications, including urban parcel
delivery, aerial inspections and air taxis. However, compared with traditional
wireless networks, LAWNs face unique security challenges due to low-altitude
operations, frequent mobility and reliance on unlicensed spectrum, making it
more vulnerable to some malicious attacks. In this paper, we investigate some
large artificial intelligence model (LAM)-enabled solutions for secure
communications in LAWNs. Specifically, we first explore the amplified security
risks and important limitations of traditional AI methods in LAWNs. Then, we
introduce the basic concepts of LAMs and delve into the role of LAMs in
addressing these challenges. To demonstrate the practical benefits of LAMs for
secure communications in LAWNs, we propose a novel LAM-based optimization
framework that leverages large language models (LLMs) to generate enhanced
state features on top of handcrafted representations, and to design intrinsic
rewards accordingly, thereby improving reinforcement learning performance for
secure communication tasks. Through a typical case study, simulation results
validate the effectiveness of the proposed framework. Finally, we outline
future directions for integrating LAMs into secure LAWN applications.

</details>


### [120] [Energy Efficient Trajectory Control and Resource Allocation in Multi-UAV-assisted MEC via Deep Reinforcement Learning](https://arxiv.org/abs/2508.00261)
*Saichao Liu,Geng Sun,Chuang Zhang,Xuejie Liu,Jiacheng Wang,Changyuan Zhao,Dusit Niyato*

Main category: cs.NI

TL;DR: 研究了一种无人机辅助的移动边缘计算系统，提出了一种增强的深度强化学习算法（DPPOIL），通过优化飞行路径和资源分配来提高系统性能，仿真结果表明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）的性能受限于其固定位置和有限的服务范围，因此研究了无人机（UAV）辅助的MEC系统以提高系统性能。

Method: 提出了一种增强的深度强化学习（DRL）算法，即分布式近端策略优化与模仿学习（DPPOIL），该算法结合了生成对抗模仿学习技术以提高策略性能。

Result: 通过优化无人机的飞行路径和分配给服务智能设备（SDs）的计算资源，同时最大化无人机的卸载数量并最小化总卸载延迟和无人机的总能耗。

Conclusion: 仿真结果证明了所提出的DPPOIL算法的有效性，并且证明了其学习策略优于其他基线方法。

Abstract: Mobile edge computing (MEC) is a promising technique to improve the
computational capacity of smart devices (SDs) in Internet of Things (IoT).
However, the performance of MEC is restricted due to its fixed location and
limited service scope. Hence, we investigate an unmanned aerial vehicle
(UAV)-assisted MEC system, where multiple UAVs are dispatched and each UAV can
simultaneously provide computing service for multiple SDs. To improve the
performance of system, we formulated a UAV-based trajectory control and
resource allocation multi-objective optimization problem (TCRAMOP) to
simultaneously maximize the offloading number of UAVs and minimize total
offloading delay and total energy consumption of UAVs by optimizing the flight
paths of UAVs as well as the computing resource allocated to served SDs. Then,
consider that the solution of TCRAMOP requires continuous decision-making and
the system is dynamic, we propose an enhanced deep reinforcement learning (DRL)
algorithm, namely, distributed proximal policy optimization with imitation
learning (DPPOIL). This algorithm incorporates the generative adversarial
imitation learning technique to improve the policy performance. Simulation
results demonstrate the effectiveness of our proposed DPPOIL and prove that the
learned strategy of DPPOIL is better compared with other baseline methods.

</details>


### [121] [Mamba for Wireless Communications and Networking: Principles and Opportunities](https://arxiv.org/abs/2508.00403)
*Rongsheng Zhang,Ruichen Zhang,Yang Lu,Wei Chen,Bo Ai,Dusit Niyato*

Main category: cs.NI

TL;DR: Mamba在无线通信中展现出潜力，通过两种应用框架和案例研究验证了其在特征增强和计算效率上的优势，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络的异构性和动态性增加，Mamba在平衡计算效率和效果方面的潜力引发了研究兴趣。

Method: 文章首先分析了Mamba在无线信号处理中的潜力，然后提出了两种应用框架，并通过案例研究展示了其性能提升。

Result: Mamba在特征增强和计算效率方面表现出显著改进，并通过案例研究验证了其应用效果。

Conclusion: 文章强调了Mamba在无线通信中的潜力，并提出了未来研究方向和关键挑战。

Abstract: Mamba has emerged as a powerful model for efficiently addressing tasks
involving temporal and spatial data. Regarding the escalating heterogeneity and
dynamics in wireless networks, Mamba holds the potential to revolutionize
wireless communication and networking designs by balancing the trade-off
between computational efficiency and effectiveness. This article presents a
comprehensive overview of Mamba' applications in wireless systems.
Specifically, we first analyze the potentials of Mamba for wireless signal
processing tasks from the perspectives of long-range dependency modeling and
spatial feature extraction. Then we propose two application frameworks for
Mamba in wireless communications, i.e., replacement of traditional algorithms,
and enabler of novel paradigms. Guided by the two frameworks, we conduct case
studies on intelligent resource allocation and joint source and channel
decoding to demonstrate Mamba's improvements in both feature enhancement and
computational efficiency. Finally, we highlight critical challenges and outline
potential research directions for Mamba in wireless communications and
networking.

</details>


### [122] [Enhancing Wireless Networks for IoT with Large Vision Models: Foundations and Applications](https://arxiv.org/abs/2508.00583)
*Yunting Xu,Jiacheng Wang,Ruichen Zhang,Dusit Niyato,Deepu Rajan,Liang Yu,Haibo Zhou,Abbas Jamalipour,Xianbin Wang*

Main category: cs.NI

TL;DR: 本文探讨了LVMs在无线通信中的应用，提出了一种渐进式微调框架，并在低空经济网络中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: LVMs在视觉任务中表现出色，但在无线通信领域的应用面临模型规模大和重训练挑战。

Method: 提出了一种渐进式微调框架，逐步调整预训练的LVMs以适应无线领域的多任务联合优化。

Result: 在低空经济网络的案例研究中，提出的框架在联合波束成形和定位任务上优于传统CNNs。

Conclusion: 大视觉模型（LVMs）在智能无线系统中展现出巨大潜力，特别是在联合优化多任务方面，如低空经济网络中的波束成形和定位任务。

Abstract: Large vision models (LVMs) have emerged as a foundational paradigm in visual
intelligence, achieving state-of-the-art performance across diverse visual
tasks. Recent advances in LVMs have facilitated their integration into Internet
of Things (IoT) scenarios, offering superior generalization and adaptability
for vision-assisted network optimization. In this paper, we first investigate
the functionalities and core architectures of LVMs, highlighting their
capabilities across classification, segmentation, generation, and multimodal
visual processing. We then explore a variety of LVM applications in wireless
communications, covering representative tasks across the physical layer,
network layer, and application layer. Furthermore, given the substantial model
size of LVMs and the challenges of model retraining in wireless domains, we
propose a progressive fine-tuning framework that incrementally adapts
pretrained LVMs for joint optimization of multiple IoT tasks. A case study in
low-altitude economy networks (LAENets) demonstrates the effectiveness of the
proposed framework over conventional CNNs in joint beamforming and positioning
tasks for Internet of drones, underscoring a promising direction for
integrating LVMs into intelligent wireless systems.

</details>


### [123] [Joint Association and Phase Shifts Design for UAV-mounted Stacked Intelligent Metasurfaces-assisted Communications](https://arxiv.org/abs/2508.00616)
*Mingzhe Fan,Geng Sun,Hongyang Pan,Jiacheng Wang,Jiancheng An,Hongyang Du,Chau Yuen*

Main category: cs.NI

TL;DR: 研究提出UAV-SIMs辅助通信系统，通过分解和交替优化解决非凸问题，提升网络容量。


<details>
  <summary>Details</summary>
Motivation: 固定式SIM限制了系统通信性能，而移动式SIM（如UAV-SIMs）能灵活部署以提升性能。

Method: 将USBJOP分解为三个子优化问题（AUUOP、ULOP、USPSOP），并采用交替优化（AO）策略解决。AUUOP和ULOP通过CVX工具转化为凸形式求解，USPSOP采用逐层迭代优化方法。

Result: 通过优化UAV-SIMs与用户的关联、UAV位置及相位偏移，最大化网络容量。

Conclusion: 仿真结果验证了所提策略在不同仿真设置下的有效性。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a promising
technology for realizing wave-domain signal processing, while the fixed SIMs
will limit the communication performance of the system compared to the mobile
SIMs. In this work, we consider a UAV-mounted SIMs (UAV-SIMs) assisted
communication system, where UAVs as base stations (BSs) can cache the data
processed by SIMs, and also as mobile vehicles flexibly deploy SIMs to enhance
the communication performance. To this end, we formulate a UAV-SIM-based joint
optimization problem (USBJOP) to comprehensively consider the association
between UAV-SIMs and users, the locations of UAV-SIMs, and the phase shifts of
UAV-SIMs, aiming to maximize the network capacity. Due to the non-convexity and
NP-hardness of USBJOP, we decompose it into three sub-optimization problems,
which are the association between UAV-SIMs and users optimization problem
(AUUOP), the UAV location optimization problem (ULOP), and the UAV-SIM phase
shifts optimization problem (USPSOP). Then, these three sub-optimization
problems are solved by an alternating optimization (AO) strategy. Specifically,
AUUOP and ULOP are transformed to a convex form and then solved by the CVX
tool, while we employ a layer-by-layer iterative optimization method for
USPSOP. Simulation results verify the effectiveness of the proposed strategy
under different simulation setups.

</details>


### [124] [Energy-Aware CPU Orchestration in O-RAN: A dApp-Driven Lightweight Approach](https://arxiv.org/abs/2508.00629)
*Francisco Crespo,Javier Villegas,Carlos Baena,Eduardo Baena,Sergio Fortes,Raquel Barco*

Main category: cs.NI

TL;DR: 提出一种轻量级dApp，动态协调CPU资源，提高O-RAN能源效率和利用率，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 软化的无线接入网络（RAN）转型引入了在严格实时约束下高效管理CPU资源的新挑战，现有操作系统调度器与延迟敏感的RAN工作负载交互时性能不佳且能耗高。

Method: 该dApp与操作系统形成闭环，利用线程级遥测（如上下文切换、每周期指令数IPC和缓存指标）实时调整CPU线程亲和性、核心隔离和频率缩放。

Result: 实验结果表明，该解决方案在商用级srsRAN部署中实现了持续的节能效果，且不影响实时处理性能。

Conclusion: 该论文提出了一种轻量级、可编程的分布式应用（dApp），用于在分布式单元（DU）级别动态协调CPU使用，无需访问专有RAN软件或硬件特定功能，显著提高了能源效率和CPU利用率。

Abstract: The transition toward softwarized Radio Access Networks (RANs), driven by the
Open RAN (O-RAN) paradigm, enables flexible, vendor-neutral deployments through
disaggregation and virtualization of base station functions. However, this
shift introduces new challenges in managing CPU resources efficiently under
strict real-time constraints. In particular, the interplay between
latency-sensitive RAN workloads and general-purpose Operating System (OS)
schedulers often leads to sub-optimal performance and unnecessary energy
consumption. This work proposes a lightweight, programmable distributed
application (dApp) deployed at the Distributed Unit (DU) level to dynamically
orchestrate CPU usage. The dApp operates in closed loop with the OS, leveraging
thread-level telemetry like context switches, Instructions Per Cycle (IPC), and
cache metrics, to adapt CPU thread affinity, core isolation, and frequency
scaling in real time. Unlike existing solutions, it requires no access to
proprietary RAN software, hardware-specific features, or kernel modifications.
Fully compliant with the O-RAN architecture and agnostic to the underlying RAN
stack, the proposed solution introduces negligible overhead while improving
energy efficiency and CPU utilization. Experimental results using a
commercial-grade srsRAN deployment demonstrate consistent power savings without
compromising real-time processing performance, highlighting the potential of
low-latency dApps for fine-grained resource control in next-generation networks

</details>


### [125] [Criticality-Based Dynamic Topology Optimization for Enhancing Aerial-Marine Swarm Resilience](https://arxiv.org/abs/2508.00688)
*Ruiyang Huang,Haocheng Wang,Yixuan Shen,Ning Gao,Qiang Ni,Shi Jin,Yifan Wu*

Main category: cs.NI

TL;DR: A two-step framework enhances swarm network resilience by dynamically ranking critical nodes and optimizing topology, reducing connectivity degradation by 30% and improving mission success.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of targeted communication disruptions and structural weaknesses in adversarial environments for heterogeneous marine-aerial swarm networks.

Method: The framework includes a three-layer architecture for representing dependencies and the SurBi-Ranking method using graph convolutional networks for dynamic criticality evaluation. The NSGA-III algorithm is then applied for topology optimization.

Result: The SurBi-Ranking method outperforms traditional methods in identifying critical components, and the optimization approach reduces connectivity degradation by around 30%, achieving higher mission success rates and lower reconfiguration costs.

Conclusion: The proposed two-step framework, combining node prioritization based on criticality with multi-objective topology optimization, significantly enhances the resilience of heterogeneous marine-aerial swarm networks in adversarial environments.

Abstract: Heterogeneous marine-aerial swarm networks encounter substantial difficulties
due to targeted communication disruptions and structural weaknesses in
adversarial environments. This paper proposes a two-step framework to
strengthen the network's resilience. Specifically, our framework combines the
node prioritization based on criticality with multi-objective topology
optimization. First, we design a three-layer architecture to represent
structural, communication, and task dependencies of the swarm networks. Then,
we introduce the SurBi-Ranking method, which utilizes graph convolutional
networks, to dynamically evaluate and rank the criticality of nodes and edges
in real time. Next, we apply the NSGA-III algorithm to optimize the network
topology, aiming to balance communication efficiency, global connectivity, and
mission success rate. Experiments demonstrate that compared to traditional
methods like K-Shell, our SurBi-Ranking method identifies critical nodes and
edges with greater accuracy, as deliberate attacks on these components cause
more significant connectivity degradation. Furthermore, our optimization
approach, when prioritizing SurBi-Ranked critical components under attack,
reduces the natural connectivity degradation by around 30%, achieves higher
mission success rates, and incurs lower communication reconfiguration costs,
ensuring sustained connectivity and mission effectiveness across multi-phase
operations.

</details>


### [126] [Deep Joint Source-Channel Coding for Small Satellite Applications](https://arxiv.org/abs/2508.00715)
*Olga Kondrateva,Grace Li Zhang,Julian Zobel,Björn Scheuermann,Stefan Dietzel*

Main category: cs.NI

TL;DR: 论文提出了一种针对卫星通信的自适应DJSCC框架ADJSCC-SAT，通过注意力模块实现单一网络适应多种信道状态，显著减少存储需求并提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决小卫星在低地球轨道中因有限接触时间和复杂信道条件导致的通信瓶颈问题，探索DJSCC在复杂卫星环境中的实际应用。

Method: 论文首先建立了基础系统DJSCC-SAT，并整合了多状态统计信道模型来指导其训练和评估。随后引入了自适应架构ADJSCC-SAT，利用注意力模块使单一神经网络能够适应广泛的信道状态。

Result: 在Sentinel-2多光谱数据上的广泛评估表明，自适应方法在性能上与使用多个专用网络相当，同时显著减少了模型存储需求，并增强了对抗信道估计误差的鲁棒性。

Conclusion: 所提出的ADJSCC-SAT框架为实际卫星任务中部署鲁棒、自适应的DJSCC系统提供了实用且高效的解决方案。

Abstract: Small satellites used for Earth observation generate vast amounts of
high-dimensional data, but their operation in low Earth orbit creates a
significant communication bottleneck due to limited contact times and harsh,
varying channel conditions. While deep joint source-channel coding (DJSCC) has
emerged as a promising technique, its practical application to the complex
satellite environment remains an open question. This paper presents a
comprehensive DJSCC framework tailored for satellite communications. We first
establish a basic system, DJSCC-SAT, and integrate a realistic, multi-state
statistical channel model to guide its training and evaluation. To overcome the
impracticality of using separate models for every channel condition, we then
introduce an adaptable architecture, ADJSCC-SAT, which leverages attention
modules to allow a single neural network to adjust to a wide range of channel
states with minimal overhead. Through extensive evaluation on Sentinel-2
multi-spectral data, we demonstrate that our adaptable approach achieves
performance comparable to using multiple specialized networks while
significantly reducing model storage requirements. Furthermore, the adaptable
model shows enhanced robustness to channel estimation errors, outperforming the
non-adaptable baseline. The proposed framework is a practical and efficient
step toward deploying robust, adaptive DJSCC systems for real-world satellite
missions.

</details>


### [127] [Overlapping IPv4, IPv6, and TCP data: exploring errors, test case context and multiple overlaps inside network stacks and NIDSes with PYROLYSE](https://arxiv.org/abs/2508.00735)
*Lucas Aubard,Johan Mazel,Gilles Guette,Pierre Chifflier*

Main category: cs.NI

TL;DR: 论文提出了PYROLYSE工具，用于测试IP和TCP重组策略，发现策略多样性高且存在安全漏洞，建议NIDS在n>2时不应仅应用n=2的策略。


<details>
  <summary>Details</summary>
Motivation: IPv4、IPv6和TCP的重组策略在不同协议实现中存在差异，导致NIDS可能与被监控的主机OS对数据包的解释不一致，从而产生安全漏洞。

Method: 论文提出了PYROLYSE工具，用于全面测试和描述各种IP和TCP实现类型的重组策略，并通过测试n<=3的重叠块序列来验证其正确性。

Result: 研究发现，重组策略的多样性远超预期，测试的23种实现中观察到14到20种不同的行为。此外，报告了8个错误，涉及1个OS、2个NIDS和2个嵌入式堆栈，可能导致安全问题。

Conclusion: 论文指出，当前的IP和TCP重组策略在n>2时与n=2的策略不一致，因此NIDS或其他网络流量分析工具在重叠块超过两个时不应仅应用n=2的策略。

Abstract: IP fragmentation and TCP segmentation allow for splitting large data packets
into smaller ones, e.g., for transmission across network links of limited
capacity. These mechanisms permit complete or partial overlaps with different
data on the overlapping portions. IPv4, IPv6, and TCP reassembly policies,
i.e., the data chunk preferences that depend on the overlap types, differ
across protocol implementations. This leads to vulnerabilities, as NIDSes may
interpret the packet differently from the monitored host OSes. Some NIDSes,
such as Suricata or Snort, can be configured so that their policies are
consistent with the monitored OSes. The first contribution of the paper is
PYROLYSE, an audit tool that exhaustively tests and describes the reassembly
policies of various IP and TCP implementation types. This tool ensures that
implementations reassemble overlapping chunk sequences without errors. The
second contribution is the analysis of PYROLYSE artifacts. We first show that
the reassembly policies are much more diverse than previously thought. Indeed,
by testing all the overlap possibilities for n <= 3 test case chunks and
different testing scenarios, we observe from 14 to 20 different behaviors out
of 23 tested implementations depending on the protocol. Second, we report eight
errors impacting one OS, two NIDSes, and two embedded stacks, which can lead to
security issues such as NIDS pattern-matching bypass or DoS attacks. A CVE was
assigned to a NIDS error. Finally, we show that implemented IP and TCP policies
obtained through chunk pair testing are usually inconsistent with the observed
triplet reassemblies. Therefore, contrarily to what they currently do, NIDSes
or other network traffic analysis tools should not apply n = 2 pair policies
when the number of overlapping chunks exceeds two.

</details>


### [128] [Data Movement Manager (DMM) for the SENSE-Rucio Interoperation Prototype](https://arxiv.org/abs/2508.00792)
*Aashay Arora,Diego Davila,Jonathan Guiang,Frank Würthwein,Harvey Newman,Justas Balcas,Tom Lehman,Xi Yang*

Main category: cs.NI

TL;DR: DMM是一个连接Rucio和SENSE的原型接口，优化了高能物理数据流的网络使用，实现了基于优先级的带宽分配和细粒度监控。


<details>
  <summary>Details</summary>
Motivation: 为了优化高能物理数据流在全球LHC计算网格基础设施上的传输效率。

Method: 通过设计并实现DMM原型接口，利用主机级吞吐量指标和FTS数据传输作业级指标进行监控。

Result: DMM实现了SDN-enabled的高能物理数据流，并通过优先级分配和监控提升了网络性能。

Conclusion: DMM成功地将Rucio与SENSE连接，实现了基于优先级的带宽分配和细粒度监控，优化了网络使用。

Abstract: The Data Movement Manager (DMM) is a prototype interface that connects CERN's
data management software, Rucio, with the Sofware-Defined Networking (SDN)
service SENSE by ESNet. It enables SDN-enabled high-energy physics data flows
using the existing worldwide LHC computing grid infrastructure. A key feature
of DMM is transfer priority-based bandwidth allocation, optimizing network
usage. Additionally, it provides fine-grained monitoring of underperforming
flows by leveraging end-to-end data flow monitoring. This is achieved through
access to host-level (network interface) throughput metrics and transfer-tool
(FTS) data transfer job-level metrics. This paper details the design and
implementation of DMM.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [129] [From Dynamic Programs to Greedy Algorithms](https://arxiv.org/abs/2508.00776)
*Dieter van Melkebeek*

Main category: cs.DS

TL;DR: 本文提出了一种从动态规划推导贪心算法的方法，适用于教学和算法正确性论证，展示了在区间调度、背包和最短路径问题中的应用。


<details>
  <summary>Details</summary>
Motivation: 为算法课程提供一种新的教学方法，展示如何从一般动态规划中推导出特定贪心算法，并解释其正确性。

Method: 通过反复扩展动态规划中的贝尔曼方程，并利用单调性性质来确定在特定限制下哪些项产生最优值。

Result: 成功展示了在区间调度、背包问题和最短路径问题中，如何从动态规划中推导出贪心算法，并阐明了区间调度中顺序变化的原因。

Conclusion: 通过动态规划和单调性性质，本文展示了如何从一般情况下的动态规划中简单推导出特定情况下的经典贪心算法，为算法教学和正确性论证提供了新视角。

Abstract: We show for several computational problems how classical greedy algorithms
for special cases can be derived in a simple way from dynamic programs for the
general case: interval scheduling (restricted to unit weights), knapsack
(restricted to unit values), and shortest paths (restricted to nonnegative edge
lengths). Conceptually, we repeatedly expand the Bellman equations underlying
the dynamic program and use straightforward monotonicity properties to figure
out which terms yield the optimal value under the respective restrictions. The
approach offers an alternative for developing these greedy algorithms in
undergraduate algorithms courses and/or for arguing their correctness. In the
setting of interval scheduling, it elucidates the change in order from earliest
start time first for the memoized dynamic program to earliest finish time first
for the greedy algorithm.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [130] [Integrated user scheduling and beam steering in over-the-air federated learning for mobile IoT](https://arxiv.org/abs/2508.00341)
*Shengheng Liu,Ningning Fu,Zhonghao Zhang,Yongming Huang,Tony Q. S. Quek*

Main category: cs.DC

TL;DR: 该论文通过结合空中计算技术和优化用户调度策略，提升了联邦学习的通信效率和准确性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）的普及，数据隐私问题日益突出。联邦学习（FL）作为一种去中心化训练范式，能够解决这一问题，但其在大规模网络中的通信效率和准确性仍需优化。

Method: 论文提出了一种集成用户调度和接收波束控制的方法，利用差分凸技术将非凸优化问题分解为两个子问题，并通过迭代求解。此外，还提出了一种基于无线信道特性分析的低复杂度用户调度策略。

Result: 实验结果表明，所提出的方法在聚合误差和学习性能上优于现有方法。

Conclusion: 该论文提出了一种结合空中计算技术的联邦学习框架，通过优化用户调度和接收波束控制策略，显著提高了通信效率和推断准确性。实验验证了该方法的优越性。

Abstract: The rising popularity of Internet of things (IoT) has spurred technological
advancements in mobile internet and interconnected systems. While offering
flexible connectivity and intelligent applications across various domains, IoT
service providers must gather vast amounts of sensitive data from users, which
nonetheless concomitantly raises concerns about privacy breaches. Federated
learning (FL) has emerged as a promising decentralized training paradigm to
tackle this challenge. This work focuses on enhancing the aggregation
efficiency of distributed local models by introducing over-the-air computation
into the FL framework. Due to radio resource scarcity in large-scale networks,
only a subset of users can participate in each training round. This highlights
the need for effective user scheduling and model transmission strategies to
optimize communication efficiency and inference accuracy. To address this, we
propose an integrated approach to user scheduling and receive beam steering,
subject to constraints on the number of selected users and transmit power.
Leveraging the difference-of-convex technique, we decompose the primal
non-convex optimization problem into two sub-problems, yielding an iterative
solution. While effective, the computational load of the iterative method
hampers its practical implementation. To overcome this, we further propose a
low-complexity user scheduling policy based on characteristic analysis of the
wireless channel to directly determine the user subset without iteration.
Extensive experiments validate the superiority of the proposed method in terms
of aggregation error and learning performance over existing approaches.

</details>


### [131] [Tetris: Efficient Intra-Datacenter Calls Packing for Large Conferencing Services](https://arxiv.org/abs/2508.00426)
*Rohan Gandhi,Ankur Mallick,Ken Sueda,Rui Liang*

Main category: cs.DC

TL;DR: Tetris框架通过优化呼叫分配和迁移，减少热点MP服务器使用，提升会议服务性能。


<details>
  <summary>Details</summary>
Motivation: 现有算法在处理呼叫分配时忽视了CPU使用率的变异性，导致部分MP服务器过载，影响性能并增加成本。

Method: Tetris采用多步骤框架，包括利用历史数据优化初始呼叫分配，以及通过线性优化周期性迁移热点MP上的呼叫。

Result: 基于24小时超过1000万次呼叫的跟踪数据，Tetris将热点MP上的参与者数量减少了至少2.5倍。

Conclusion: Tetris框架通过优化初始呼叫分配和周期性迁移呼叫，显著减少了热点MP服务器的使用，提升了会议服务的性能和成本效益。

Abstract: Conference services like Zoom, Microsoft Teams, and Google Meet facilitate
millions of daily calls, yet ensuring high performance at low costs remains a
significant challenge. This paper revisits the problem of packing calls across
Media Processor (MP) servers that host the calls within individual datacenters
(DCs). We show that the algorithm used in Teams -- a large scale conferencing
service as well as other state-of-art algorithms are prone to placing calls
resulting in some of the MPs becoming hot (high CPU utilization) that leads to
degraded performance and/or elevated hosting costs. The problem arises from
disregarding the variability in CPU usage among calls, influenced by
differences in participant numbers and media types (audio/video), compounded by
bursty call arrivals. To tackle this, we propose Tetris, a multi-step framework
which (a) optimizes initial call assignments by leveraging historical data and
(b) periodically migrates calls from hot MPs using linear optimization, aiming
to minimize hot MP usage. Evaluation based on a 24-hour trace of over 10
million calls in one DC shows that Tetris reduces participant numbers on hot
MPs by at least 2.5X.

</details>


### [132] [SwarnRaft: Leveraging Consensus for Robust Drone Swarm Coordination in GNSS-Degraded Environments](https://arxiv.org/abs/2508.00622)
*Kapel Dev,Yash Madhwal,Sofia Shevelo,Pavel Osinenko,Yury Yanovich*

Main category: cs.DC

TL;DR: SwarnRaft是一种基于区块链的框架，用于在GNSS信号缺失时维持无人机群的协调和数据完整性，通过Raft共识算法实现分布式定位和状态更新。


<details>
  <summary>Details</summary>
Motivation: 无人机群在关键应用中的可靠性高度依赖GNSS信号，而信号在现实场景中可能因干扰、环境条件或敌对攻击而中断，导致迷失方向、碰撞风险和任务失败。

Method: 该论文提出了SwarnRaft框架，这是一种受区块链启发的定位和共识框架，利用Raft共识算法，使分布式无人机（节点）能够在GNSS信号缺失的情况下就状态更新（如位置和航向）达成一致。

Result: 原型系统展示了在模拟群中，通过轻量级、可扩展的通信模型，SwarnRaft能够有效维持群的一致性和容错能力。

Conclusion: SwarnRaft 提供了一个实用且安全的基础，支持在不可预测的环境中实现去中心化无人机操作，增强了无人机群在GNSS信号缺失情况下的鲁棒性和容错能力。

Abstract: Unmanned aerial vehicle (UAV) swarms are increasingly used in critical
applications such as aerial mapping, environmental monitoring, and autonomous
delivery. However, the reliability of these systems is highly dependent on
uninterrupted access to the Global Navigation Satellite Systems (GNSS) signals,
which can be disrupted in real-world scenarios due to interference,
environmental conditions, or adversarial attacks, causing disorientation,
collision risks, and mission failure. This paper proposes SwarnRaft, a
blockchain-inspired positioning and consensus framework for maintaining
coordination and data integrity in UAV swarms operating under GNSS-denied
conditions. SwarnRaft leverages the Raft consensus algorithm to enable
distributed drones (nodes) to agree on state updates such as location and
heading, even in the absence of GNSS signals for one or more nodes. In our
prototype, each node uses GNSS and local sensing, and communicates over WiFi in
a simulated swarm. Upon signal loss, consensus is used to reconstruct or verify
the position of the failed node based on its last known state and trajectory.
Our system demonstrates robustness in maintaining swarm coherence and fault
tolerance through a lightweight, scalable communication model. This work offers
a practical and secure foundation for decentralized drone operation in
unpredictable environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [133] [Occlusion-robust Stylization for Drawing-based 3D Animation](https://arxiv.org/abs/2508.00398)
*Sunjae Yoon,Gwanhyeong Koo,Younghwan Lee,Ji Woo Hong,Chang D. Yoo*

Main category: cs.GR

TL;DR: 提出OSF框架，通过光流解决遮挡导致的风格化性能下降，实现更快更省内存的单次运行。


<details>
  <summary>Details</summary>
Motivation: 现有方法在遮挡情况下（如重叠身体部分）会导致轮廓闪烁和笔触模糊，主要由于训练与推理时的姿态差异（即'风格化姿态间隙'）。

Method: 利用光流提供遮挡鲁棒的边缘引导，优化风格化网络，使其在单次运行中完成处理，而非传统的两阶段方法。

Result: OSF在遮挡情况下仍能保持一致的风格化效果，推理速度提升2.4倍，内存占用减少2.1倍。

Conclusion: 提出了Occlusion-robust Stylization Framework (OSF)，通过光流提供遮挡鲁棒的边缘引导，解决了风格化网络在遮挡情况下的性能下降问题，显著提升了推理速度和内存效率。

Abstract: 3D animation aims to generate a 3D animated video from an input image and a
target 3D motion sequence. Recent advances in image-to-3D models enable the
creation of animations directly from user-hand drawings. Distinguished from
conventional 3D animation, drawing-based 3D animation is crucial to preserve
artist's unique style properties, such as rough contours and distinct stroke
patterns. However, recent methods still exhibit quality deterioration in style
properties, especially under occlusions caused by overlapping body parts,
leading to contour flickering and stroke blurring. This occurs due to a
`stylization pose gap' between training and inference in stylization networks
designed to preserve drawing styles in drawing-based 3D animation systems. The
stylization pose gap denotes that input target poses used to train the
stylization network are always in occlusion-free poses, while target poses
encountered in an inference include diverse occlusions under dynamic motions.
To this end, we propose Occlusion-robust Stylization Framework (OSF) for
drawing-based 3D animation. We found that while employing object's edge can be
effective input prior for guiding stylization, it becomes notably inaccurate
when occlusions occur at inference. Thus, our proposed OSF provides
occlusion-robust edge guidance for stylization network using optical flow,
ensuring a consistent stylization even under occlusions. Furthermore, OSF
operates in a single run instead of the previous two-stage method, achieving
2.4x faster inference and 2.1x less memory.

</details>


### [134] [CrossSet: Unveiling the Complex Interplay of Two Set-typed Dimensions in Multivariate Data](https://arxiv.org/abs/2508.00424)
*Kresimir Matkovic,Rainer Splechtna,Denis Gracanin,Helwig Hauser*

Main category: cs.GR

TL;DR: CrossSet是一种新颖的方法，通过层次矩阵布局和交互式多尺度分析，支持两个集合类型维度及其相互作用的联合研究。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案主要针对单个集合类型维度的研究，缺乏对两个集合类型维度及其相互作用的联合分析方法。

Method: 基于任务分析，提出了一种多尺度的交互式可视化探索和分析方法，采用层次矩阵布局联合可视化两个集合类型数据维度。

Result: 通过多个应用场景的评估，证明了CrossSet在交互式视觉多尺度探索和分析双变量集合类型数据方面的有效性和效率。

Conclusion: CrossSet提供了一种有效且高效的方法，用于交互式可视化分析双变量集合类型数据，通过多层次矩阵布局和钻取功能，支持对集合类型维度及其相互作用的详细研究。

Abstract: The interactive visual analysis of set-typed data, i.e., data with attributes
that are of type set, is a rewarding area of research and applications.
Valuable prior work has contributed solutions that enable the study of such
data with individual set-typed dimensions. In this paper, we present CrossSet,
a novel method for the joint study of two set-typed dimensions and their
interplay. Based on a task analysis, we describe a new, multi-scale approach to
the interactive visual exploration and analysis of such data. Two set-typed
data dimensions are jointly visualized using a hierarchical matrix layout,
enabling the analysis of the interactions between two set-typed attributes at
several levels, in addition to the analysis of individual such dimensions.
CrossSet is anchored at a compact, large-scale overview that is complemented by
drill-down opportunities to study the relations between and within the
set-typed dimensions, enabling an interactive visual multi-scale exploration
and analysis of bivariate set-typed data. Such an interactive approach makes it
possible to study single set-typed dimensions in detail, to gain an overview of
the interaction and association between two such dimensions, to refine one of
the dimensions to gain additional details at several levels, and to drill down
to the specific interactions of individual set-elements from the set-typed
dimensions. To demonstrate the effectiveness and efficiency of CrossSet, we
have evaluated the new method in the context of several application scenarios.

</details>


### [135] [Sel3DCraft: Interactive Visual Prompts for User-Friendly Text-to-3D Generation](https://arxiv.org/abs/2508.00428)
*Nan Xiang,Tianyi Liang,Haiwen Huang,Shiqi Jiang,Hao Huang,Yifei Huang,Liangyu Chen,Changbo Wang,Chenhui Li*

Main category: cs.GR

TL;DR: Sel3DCraft是一个创新的视觉提示工程系统，通过双分支结构和多视图评分方法，显著提升文本到3D生成的效率和创造性。


<details>
  <summary>Details</summary>
Motivation: 解决文本到3D生成中因盲目试错提示导致结果不可预测的问题，提升多视图一致性和空间理解的挑战。

Method: 采用双分支结构（检索与生成）探索多样候选，结合多视图混合评分方法，利用MLLMs和高层次指标评估3D模型，并提供提示驱动的视觉分析套件。

Result: Sel3DCraft在广泛测试和用户研究中表现优于其他T23D系统，有效支持设计师的创造性工作。

Conclusion: Sel3DCraft通过其创新的视觉提示工程系统，显著提升了文本到3D生成的效率和创造性，为设计师提供了更直观的工具。

Abstract: Text-to-3D (T23D) generation has transformed digital content creation, yet
remains bottlenecked by blind trial-and-error prompting processes that yield
unpredictable results. While visual prompt engineering has advanced in
text-to-image domains, its application to 3D generation presents unique
challenges requiring multi-view consistency evaluation and spatial
understanding. We present Sel3DCraft, a visual prompt engineering system for
T23D that transforms unstructured exploration into a guided visual process. Our
approach introduces three key innovations: a dual-branch structure combining
retrieval and generation for diverse candidate exploration; a multi-view hybrid
scoring approach that leverages MLLMs with innovative high-level metrics to
assess 3D models with human-expert consistency; and a prompt-driven visual
analytics suite that enables intuitive defect identification and refinement.
Extensive testing and user studies demonstrate that Sel3DCraft surpasses other
T23D systems in supporting creativity for designers.

</details>


### [136] [SpA2V: Harnessing Spatial Auditory Cues for Audio-driven Spatially-aware Video Generation](https://arxiv.org/abs/2508.00782)
*Kien T. Pham,Yingqing He,Yazhou Xing,Qifeng Chen,Long Chen*

Main category: cs.GR

TL;DR: SpA2V是一个两阶段框架，通过提取音频中的空间和语义线索构建视频布局，并利用扩散模型生成高质量视频，显著提升了音频驱动视频生成的语义和空间准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注语义信息（如声源类别），而忽略了空间属性（如位置和运动方向），导致生成的视频在内容和空间构成上不准确。人类不仅能识别声源的语义类别，还能确定其空间属性。因此，研究团队提出SpA2V，首次明确利用音频中的空间听觉线索来生成语义和空间对应的高质量视频。

Method: SpA2V框架分为两个阶段：1) 音频引导的视频规划，利用MLLM从音频中提取空间和语义线索构建视频场景布局(VSLs)；2) 基于布局的视频生成，将VSLs作为条件指导无缝集成到预训练的扩散模型中，实现无需训练的VSL锚定视频生成。

Result: 大量实验表明，SpA2V在生成与输入音频语义和空间对齐的逼真视频方面表现出色。

Conclusion: SpA2V通过明确利用音频中的空间听觉线索，成功生成了与输入音频在语义和空间上高度一致的逼真视频，证明了其在音频驱动视频生成领域的优越性。

Abstract: Audio-driven video generation aims to synthesize realistic videos that align
with input audio recordings, akin to the human ability to visualize scenes from
auditory input. However, existing approaches predominantly focus on exploring
semantic information, such as the classes of sounding sources present in the
audio, limiting their ability to generate videos with accurate content and
spatial composition. In contrast, we humans can not only naturally identify the
semantic categories of sounding sources but also determine their deeply encoded
spatial attributes, including locations and movement directions. This useful
information can be elucidated by considering specific spatial indicators
derived from the inherent physical properties of sound, such as loudness or
frequency. As prior methods largely ignore this factor, we present SpA2V, the
first framework explicitly exploits these spatial auditory cues from audios to
generate videos with high semantic and spatial correspondence. SpA2V decomposes
the generation process into two stages: 1) Audio-guided Video Planning: We
meticulously adapt a state-of-the-art MLLM for a novel task of harnessing
spatial and semantic cues from input audio to construct Video Scene Layouts
(VSLs). This serves as an intermediate representation to bridge the gap between
the audio and video modalities. 2) Layout-grounded Video Generation: We develop
an efficient and effective approach to seamlessly integrate VSLs as conditional
guidance into pre-trained diffusion models, enabling VSL-grounded video
generation in a training-free manner. Extensive experiments demonstrate that
SpA2V excels in generating realistic videos with semantic and spatial alignment
to the input audios.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [137] [Rethinking Evidence Hierarchies in Medical Language Benchmarks: A Critical Evaluation of HealthBench](https://arxiv.org/abs/2508.00081)
*Fred Mutisya,Shikoh Gitau,Nasubo Ongoma,Keith Mbae,Elizabeth Wamicha*

Main category: cs.AI

TL;DR: HealthBench依赖专家意见可能引入偏见，特别是在中低收入地区。为解决这一问题，研究提出基于严格审查CPGs的奖励机制，结合强化学习和伦理考量，以开发更全球相关和公平的医学语言模型。


<details>
  <summary>Details</summary>
Motivation: HealthBench依赖于专家意见而非高级临床证据，可能固化区域偏见和个体临床医生特质，尤其在中低收入环境中问题更为突出，如忽视热带疾病覆盖不足和地区指南不匹配。非洲背景下的独特挑战（数据稀缺、基础设施不足和监管框架不成熟）凸显了对更全球相关和公平基准的迫切需求。

Method: 提出通过‘证据稳健’的强化学习，包括评分标准与指南的链接、证据加权评分和上下文覆盖逻辑，结合伦理考量和延迟结果反馈的整合。

Result: 提出了一种基于版本控制CPGs的奖励函数锚定方法，结合系统评价和GRADE证据评级，以解决HealthBench的局限性。

Conclusion: 通过将奖励机制基于严格审查的临床实践指南（CPGs），同时保持HealthBench的透明度和医生参与，旨在培养不仅在语言上精炼，而且在临床可信、道德合理且全球相关的医学语言模型。

Abstract: HealthBench, a benchmark designed to measure the capabilities of AI systems
for health better (Arora et al., 2025), has advanced medical language model
evaluation through physician-crafted dialogues and transparent rubrics.
However, its reliance on expert opinion, rather than high-tier clinical
evidence, risks codifying regional biases and individual clinician
idiosyncrasies, further compounded by potential biases in automated grading
systems. These limitations are particularly magnified in low- and middle-income
settings, where issues like sparse neglected tropical disease coverage and
region-specific guideline mismatches are prevalent.
  The unique challenges of the African context, including data scarcity,
inadequate infrastructure, and nascent regulatory frameworks, underscore the
urgent need for more globally relevant and equitable benchmarks. To address
these shortcomings, we propose anchoring reward functions in version-controlled
Clinical Practice Guidelines (CPGs) that incorporate systematic reviews and
GRADE evidence ratings.
  Our roadmap outlines "evidence-robust" reinforcement learning via
rubric-to-guideline linkage, evidence-weighted scoring, and contextual override
logic, complemented by a focus on ethical considerations and the integration of
delayed outcome feedback. By re-grounding rewards in rigorously vetted CPGs,
while preserving HealthBench's transparency and physician engagement, we aim to
foster medical language models that are not only linguistically polished but
also clinically trustworthy, ethically sound, and globally relevant.

</details>


### [138] [Hyperproperty-Constrained Secure Reinforcement Learning](https://arxiv.org/abs/2508.00106)
*Ernest Bonnah,Luan Viet Nguyen,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: 本文提出了一种基于HyperTWTL约束的安全强化学习方法，通过动态Boltzmann softmax RL学习最优策略，并在机器人任务中验证其优于基线算法。


<details>
  <summary>Details</summary>
Motivation: 现有研究中，虽然有时序逻辑约束的安全强化学习（SRL）文献，但缺乏基于超属性（hyperproperties）的安全感知强化学习（SecRL）探索。

Method: 使用动态Boltzmann softmax RL方法，结合HyperTWTL约束，学习安全感知的最优策略。

Result: 提出的方法在拾取和交付机器人任务案例中表现优于两种基线RL算法。

Conclusion: 本文提出了一种基于HyperTWTL约束的安全强化学习方法，通过动态Boltzmann softmax RL学习安全感知的最优策略，并在机器人任务案例中验证了其有效性和可扩展性。

Abstract: Hyperproperties for Time Window Temporal Logic (HyperTWTL) is a
domain-specific formal specification language known for its effectiveness in
compactly representing security, opacity, and concurrency properties for
robotics applications. This paper focuses on HyperTWTL-constrained secure
reinforcement learning (SecRL). Although temporal logic-constrained safe
reinforcement learning (SRL) is an evolving research problem with several
existing literature, there is a significant research gap in exploring
security-aware reinforcement learning (RL) using hyperproperties. Given the
dynamics of an agent as a Markov Decision Process (MDP) and opacity/security
constraints formalized as HyperTWTL, we propose an approach for learning
security-aware optimal policies using dynamic Boltzmann softmax RL while
satisfying the HyperTWTL constraints. The effectiveness and scalability of our
proposed approach are demonstrated using a pick-up and delivery robotic mission
case study. We also compare our results with two other baseline RL algorithms,
showing that our proposed method outperforms them.

</details>


### [139] [No AI Without PI! Object-Centric Process Mining as the Enabler for Generative, Predictive, and Prescriptive Artificial Intelligence](https://arxiv.org/abs/2508.00116)
*Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 本文探讨了AI在工业流程中的应用挑战，提出通过Object-Centric Process Mining（OCPM）和Process Intelligence（PI）来提升AI的有效性，强调了数据与流程结合的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于组织在工业环境中成功应用AI面临挑战，特别是在端到端操作流程中，本文旨在探讨如何通过Process Intelligence（PI）和OCPM来提升AI在流程改进中的有效性。

Method: 本文通过分析生成式、预测式和规定式AI在工业环境中的应用挑战，提出使用Object-Centric Process Mining（OCPM）来结构化流程相关数据，从而支持AI的落地。

Result: 研究表明，OCPM是连接数据和流程的关键，能够支持多种AI形式的应用，从而提升操作流程的效率。

Conclusion: 本文强调了Process Intelligence（PI）作为连接数据和流程的关键桥梁，使得生成式、预测式和规定式AI能够在组织环境中有效应用。通过Object-Centric Process Mining（OCPM），AI可以更好地诊断和改进端到端的操作流程。

Abstract: The uptake of Artificial Intelligence (AI) impacts the way we work, interact,
do business, and conduct research. However, organizations struggle to apply AI
successfully in industrial settings where the focus is on end-to-end
operational processes. Here, we consider generative, predictive, and
prescriptive AI and elaborate on the challenges of diagnosing and improving
such processes. We show that AI needs to be grounded using Object-Centric
Process Mining (OCPM). Process-related data are structured and
organization-specific and, unlike text, processes are often highly dynamic.
OCPM is the missing link connecting data and processes and enables different
forms of AI. We use the term Process Intelligence (PI) to refer to the
amalgamation of process-centric data-driven techniques able to deal with a
variety of object and event types, enabling AI in an organizational context.
This paper explains why AI requires PI to improve operational processes and
highlights opportunities for successfully combining OCPM and generative,
predictive, and prescriptive AI.

</details>


### [140] [Algorithmic Detection of Rank Reversals, Transitivity Violations, and Decomposition Inconsistencies in Multi-Criteria Decision Analysis](https://arxiv.org/abs/2508.00129)
*Agustín Borda,Juan Bautista Cabral,Gonzalo Giarda,Diego Nicolás Gimenez Irusta,Paula Pacheco,Alvaro Roy Schachner*

Main category: cs.AI

TL;DR: 本文提出三种测试检测多标准决策中的Rank Reversals问题，并在Scikit-Criteria库中实现，讨论了其对方法评估的重要性。


<details>
  <summary>Details</summary>
Motivation: Rank Reversals是多标准决策分析中的一个严重问题，可能极大影响决策方法的结果，因此需要一种机制来测量方法在特定替代方案集上的性能。

Method: 提出了三种检测Rank Reversals的测试，并在Scikit-Criteria库中实现了这些测试，同时解决了在一般场景中实施这些测试时出现的复杂性问题。

Result: 成功开发并实现了三种测试来检测Rank Reversals，并解决了实施过程中的设计挑战。

Conclusion: 本文讨论了如何通过提出的三种测试来检测Rank Reversals问题，并探讨了这些测试在Scikit-Criteria库中的实现及其对多标准决策方法评估的潜在影响。

Abstract: In Multi-Criteria Decision Analysis, Rank Reversals are a serious problem
that can greatly affect the results of a Multi-Criteria Decision Method against
a particular set of alternatives. It is therefore useful to have a mechanism
that allows one to measure the performance of a method on a set of
alternatives. This idea could be taken further to build a global ranking of the
effectiveness of different methods to solve a problem. In this paper, we
present three tests that detect the presence of Rank Reversals, along with
their implementation in the Scikit-Criteria library. We also address the
complications that arise when implementing these tests for general scenarios
and the design considerations we made to handle them. We close with a
discussion about how these additions could play a major role in the judgment of
multi-criteria decision methods for problem solving.

</details>


### [141] [SHACL Validation under Graph Updates (Extended Paper)](https://arxiv.org/abs/2508.00137)
*Shqiponja Ahmetaj,George Konstantinidis,Magdalena Ortiz,Paolo Pareti,Mantas Simkus*

Main category: cs.AI

TL;DR: 本文提出一种SHACL更新语言，通过回归技术验证RDF图更新后是否仍满足SHACL规范，并分析了计算复杂度和实现原型。


<details>
  <summary>Details</summary>
Motivation: 研究RDF图在更新后的SHACL验证问题，为推理演化中的RDF图提供基础服务。

Method: 采用回归技术将更新操作嵌入SHACL约束中，将静态验证问题转化为SHACL约束的（不）可满足性问题，并分析了计算复杂度。

Result: 通过原型实现验证了方法的有效性，并进行了初步实验。

Conclusion: 本文提出了一种基于SHACL的更新语言，用于验证RDF图在更新后是否仍满足SHACL规范，并通过原型实现展示了其可行性。

Abstract: SHACL (SHApe Constraint Language) is a W3C standardized constraint language
for RDF graphs. In this paper, we study SHACL validation in RDF graphs under
updates. We present a SHACL-based update language that can capture intuitive
and realistic modifications on RDF graphs and study the problem of static
validation under such updates. This problem asks to verify whether every graph
that validates a SHACL specification will still do so after applying a given
update sequence. More importantly, it provides a basis for further services for
reasoning about evolving RDF graphs. Using a regression technique that embeds
the update actions into SHACL constraints, we show that static validation under
updates can be reduced to (un)satisfiability of constraints in (a minor
extension of) SHACL. We analyze the computational complexity of the static
validation problem for SHACL and some key fragments. Finally, we present a
prototype implementation that performs static validation and other static
analysis tasks on SHACL constraints and demonstrate its behavior through
preliminary experiments.

</details>


### [142] [Co-Producing AI: Toward an Augmented, Participatory Lifecycle](https://arxiv.org/abs/2508.00138)
*Rashid Mushkani,Hugo Berard,Toumadher Ammar,Cassandre Chatonnier,Shin Koseki*

Main category: cs.AI

TL;DR: 论文提出了一种增强的AI生命周期，强调共同生产和多学科合作，以解决AI算法的不平等影响。


<details>
  <summary>Details</summary>
Motivation: 尽管已有努力减轻AI算法的风险和偏见，但这些算法仍对文化边缘化群体产生不成比例的影响，需要从根本上重新设计AI生产流程。

Method: 通过结合设计正义、扩展学习理论和参与式AI的实证研究，提出了一个由五个相互关联阶段组成的增强AI生命周期：共同框架、共同设计、共同实施、共同部署和共同维护。

Result: 提出的生命周期基于四个多学科研讨会，并体现了分布式权威和迭代知识交换的主题，与多个领先的伦理框架相关联。

Conclusion: 论文提出了一种基于共同生产的AI生命周期，强调多样性、公平性和包容性（DEI）以及多学科合作，以解决AI算法对文化边缘化群体的不平等影响。

Abstract: Despite efforts to mitigate the inherent risks and biases of artificial
intelligence (AI) algorithms, these algorithms can disproportionately impact
culturally marginalized groups. A range of approaches has been proposed to
address or reduce these risks, including the development of ethical guidelines
and principles for responsible AI, as well as technical solutions that promote
algorithmic fairness. Drawing on design justice, expansive learning theory, and
recent empirical work on participatory AI, we argue that mitigating these harms
requires a fundamental re-architecture of the AI production pipeline. This
re-design should center co-production, diversity, equity, inclusion (DEI), and
multidisciplinary collaboration. We introduce an augmented AI lifecycle
consisting of five interconnected phases: co-framing, co-design,
co-implementation, co-deployment, and co-maintenance. The lifecycle is informed
by four multidisciplinary workshops and grounded in themes of distributed
authority and iterative knowledge exchange. Finally, we relate the proposed
lifecycle to several leading ethical frameworks and outline key research
questions that remain for scaling participatory governance.

</details>


### [143] [Beyond Agreement: Rethinking Ground Truth in Educational AI Annotation](https://arxiv.org/abs/2508.00143)
*Danielle R. Thomas,Conrad Borchers,Kenneth R. Koedinger*

Main category: cs.AI

TL;DR: 论文指出人类评估的局限性，提出五种替代方法以提高标注质量，强调教育影响而非单纯共识。


<details>
  <summary>Details</summary>
Motivation: 由于人类评估者存在偏见和不可靠性，过度依赖人类评估者间的信度（IRR）作为标注质量的守门员，阻碍了在教育数据分类中的进步。

Method: 论文提出了五种补充评估方法，如多标签标注方案、基于专家的方法和闭环有效性验证。

Result: 论文强调，这些补充方法能比单独使用IRR方法产生更有效的训练数据和模型，从而改善学生学习和提供更可操作的见解。

Conclusion: 该论文呼吁重新思考标注质量和‘真实标准’，强调应优先考虑有效性和教育影响，而不仅仅是共识。

Abstract: Humans can be notoriously imperfect evaluators. They are often biased,
unreliable, and unfit to define "ground truth." Yet, given the surging need to
produce large amounts of training data in educational applications using AI,
traditional inter-rater reliability (IRR) metrics like Cohen's kappa remain
central to validating labeled data. IRR remains a cornerstone of many machine
learning pipelines for educational data. Take, for example, the classification
of tutors' moves in dialogues or labeling open responses in machine-graded
assessments. This position paper argues that overreliance on human IRR as a
gatekeeper for annotation quality hampers progress in classifying data in ways
that are valid and predictive in relation to improving learning. To address
this issue, we highlight five examples of complementary evaluation methods,
such as multi-label annotation schemes, expert-based approaches, and
close-the-loop validity. We argue that these approaches are in a better
position to produce training data and subsequent models that produce improved
student learning and more actionable insights than IRR approaches alone. We
also emphasize the importance of external validity, for example, by
establishing a procedure of validating tutor moves and demonstrating that it
works across many categories of tutor actions (e.g., providing hints). We call
on the field to rethink annotation quality and ground truth--prioritizing
validity and educational impact over consensus alone.

</details>


### [144] [Model-Based Soft Maximization of Suitable Metrics of Long-Term Human Power](https://arxiv.org/abs/2508.00159)
*Jobst Heitzig,Ram Potham*

Main category: cs.AI

TL;DR: 本文提出了一种通过管理人类与AI的权力平衡来促进安全和福祉的方法，设计了一个衡量人类权力的指标，并通过算法计算其影响。


<details>
  <summary>Details</summary>
Motivation: 探讨通过明确要求AI代理增强人类权力并管理人类与AI代理之间的权力平衡，以促进安全和福祉。

Method: 使用原则性的部分公理化方法，设计了一个可参数化和可分解的客观函数，代表了一种不平等和风险厌恶的长期人类权力聚合。通过逆向归纳或通过多智能体强化学习近似计算该指标。

Result: 在不同典型情境中展示了（软性）最大化该指标的后果，并描述了它可能隐含的工具性子目标。

Conclusion: 软性最大化适合的人类权力聚合指标可能构成对代理AI系统有益的目标，比直接基于效用的目标更安全。

Abstract: Power is a key concept in AI safety: power-seeking as an instrumental goal,
sudden or gradual disempowerment of humans, power balance in human-AI
interaction and international AI governance. At the same time, power as the
ability to pursue diverse goals is essential for wellbeing.
  This paper explores the idea of promoting both safety and wellbeing by
forcing AI agents explicitly to empower humans and to manage the power balance
between humans and AI agents in a desirable way. Using a principled, partially
axiomatic approach, we design a parametrizable and decomposable objective
function that represents an inequality- and risk-averse long-term aggregate of
human power. It takes into account humans' bounded rationality and social
norms, and, crucially, considers a wide variety of possible human goals.
  We derive algorithms for computing that metric by backward induction or
approximating it via a form of multi-agent reinforcement learning from a given
world model. We exemplify the consequences of (softly) maximizing this metric
in a variety of paradigmatic situations and describe what instrumental
sub-goals it will likely imply. Our cautious assessment is that softly
maximizing suitable aggregate metrics of human power might constitute a
beneficial objective for agentic AI systems that is safer than direct
utility-based objectives.

</details>


### [145] [RL-PLUS: Countering Capability Boundary Collapse of LLMs in Reinforcement Learning with Hybrid-policy Optimization](https://arxiv.org/abs/2508.00222)
*Yihong Dong,Xue Jiang,Yongding Tao,Huanyu Liu,Kechi Zhang,Lili Mou,Rongyu Cao,Yingwei Ma,Jue Chen,Binhua Li,Zhi Jin,Fei Huang,Yongbin Li,Ge Li*

Main category: cs.AI

TL;DR: RL-PLUS通过结合内部思考和外部学习，显著提升LLM推理能力，解决能力边界崩溃问题，并在多个基准测试中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法因固有的策略限制和稀疏奖励，难以突破基础模型的能力边界，甚至导致能力边界崩溃。

Method: RL-PLUS整合了多重重要性采样和基于探索的优势函数，以处理外部数据的分布不匹配问题，并引导模型探索高价值推理路径。

Result: RL-PLUS在六个数学推理基准测试中表现最佳，并在六个分布外推理任务中展现出优越性能，平均相对提升21.1%至69.2%。

Conclusion: RL-PLUS通过结合内部探索和外部数据，显著提升了大型语言模型的推理能力，并解决了能力边界崩溃问题。

Abstract: Reinforcement Learning with Verifiable Reward (RLVR) has significantly
advanced the complex reasoning abilities of Large Language Models (LLMs).
However, it struggles to break through the inherent capability boundaries of
the base LLM, due to its inherently on-policy strategy with LLM's immense
action space and sparse reward. Further, RLVR can lead to the capability
boundary collapse, narrowing the LLM's problem-solving scope. To address this
problem, we propose RL-PLUS, a novel approach that synergizes internal
exploitation (i.e., Thinking) with external data (i.e., Learning) to achieve
stronger reasoning capabilities and surpass the boundaries of base models.
RL-PLUS integrates two core components: Multiple Importance Sampling to address
for distributional mismatch from external data, and an Exploration-Based
Advantage Function to guide the model towards high-value, unexplored reasoning
paths. We provide both theoretical analysis and extensive experiments to
demonstrate the superiority and generalizability of our approach. The results
show that RL-PLUS achieves state-of-the-art performance compared with existing
RLVR methods on six math reasoning benchmarks and exhibits superior performance
on six out-of-distribution reasoning tasks. It also achieves consistent and
significant gains across diverse model families, with average relative
improvements ranging from 21.1\% to 69.2\%. Moreover, Pass@k curves across
multiple benchmarks indicate that RL-PLUS effectively resolves the capability
boundary collapse problem.

</details>


### [146] [MetaAgent: Toward Self-Evolving Agent via Tool Meta-Learning](https://arxiv.org/abs/2508.00271)
*Hongjin Qian,Zheng Liu*

Main category: cs.AI

TL;DR: MetaAgent是一个自进化代理系统，通过'做中学'不断改进推理和工具使用策略，无需调整模型参数或后训练，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 受'做中学'原则启发，旨在通过实践和持续自我改进开发专业知识。

Method: MetaAgent通过最小化工作流程启动，具备基本推理和自适应求助能力。遇到知识缺口时，生成自然语言求助请求，并通过专用工具路由器路由到最合适的外部工具。任务解决过程中持续进行自我反思和答案验证，将可操作经验提炼为简洁文本并动态整合到未来任务中。此外，自主构建内部工具和持久知识库。

Result: 在GAIA、WebWalkerQA和BrowseCamp等知识发现基准测试中，MetaAgent持续优于基于工作流程的基线，并匹配或超越端到端训练代理。

Conclusion: MetaAgent展示了自进化代理系统在稳健、通用知识发现方面的潜力，并在多个基准测试中表现优异。

Abstract: In this work, we propose MetaAgent, an agentic paradigm inspired by the
principle of learning-by-doing, where expertise is developed through hands-on
practice and continual self-improvement. MetaAgent starts with a minimal
workflow, equipped only with basic reasoning and adaptive help-seeking
abilities. When a knowledge gap is encountered, MetaAgent generates natural
language help requests, which are routed to the most suitable external tool by
a dedicated tool router. As MetaAgent solves tasks, it continually conducts
self-reflection and answer verification, distilling actionable experience into
concise texts that are dynamically incorporated into future task contexts.
Besides, MetaAgent autonomously builds in-house tools and a persistent
knowledge base by organizing its tool-use history, further enhancing its
ability to retrieve and integrate relevant information We term this continual,
data-driven process as \textit{meta tool learning}, through which MetaAgent
incrementally refines its reasoning and tool-use strategies, without changing
model parameters or requiring further post-training. Evaluated on challenging
knowledge discovery benchmarks, including GAIA, WebWalkerQA, and BrowseCamp,
MetaAgent consistently outperforms workflow-based baselines and matches or
exceeds end-to-end trained agents, demonstrating the promise of self-evolving
agentic systems for robust, general-purpose knowledge discovery. We provide our
source codes in https://github.com/qhjqhj00/MetaAgent.

</details>


### [147] [Mind the Gap: The Divergence Between Human and LLM-Generated Tasks](https://arxiv.org/abs/2508.00282)
*Yi-Long Lu,Jiajun Song,Chunhui Zhang,Wei Wang*

Main category: cs.AI

TL;DR: 研究发现LLM生成的任务与人类行为模式存在显著差异，突显了整合内在动机和物理基础的必要性。


<details>
  <summary>Details</summary>
Motivation: 探讨生成代理（如LLMs）是否能模拟人类复杂行为背后的认知原则，尤其是心理驱动因素的作用。

Method: 通过任务生成实验，比较人类与LLM代理（GPT-4o）的反应，分析心理驱动因素（如个人价值观和认知风格）对任务生成的影响。

Result: 人类任务生成受心理驱动因素显著影响，而LLM即使明确提供这些驱动因素，生成的任务仍更抽象、社交性和物理性较低，且与人类行为模式不符。虽然LLM的任务被认为更有趣和新颖，但其语言能力与生成人类类似具身目标的能力存在脱节。

Conclusion: 研究指出，人类认知的价值驱动和具身特性与大型语言模型(LLMs)的统计模式之间存在核心差距，强调了在设计更符合人类行为的智能体时，必须融入内在动机和物理基础。

Abstract: Humans constantly generate a diverse range of tasks guided by internal
motivations. While generative agents powered by large language models (LLMs)
aim to simulate this complex behavior, it remains uncertain whether they
operate on similar cognitive principles. To address this, we conducted a
task-generation experiment comparing human responses with those of an LLM agent
(GPT-4o). We find that human task generation is consistently influenced by
psychological drivers, including personal values (e.g., Openness to Change) and
cognitive style. Even when these psychological drivers are explicitly provided
to the LLM, it fails to reflect the corresponding behavioral patterns. They
produce tasks that are markedly less social, less physical, and thematically
biased toward abstraction. Interestingly, while the LLM's tasks were perceived
as more fun and novel, this highlights a disconnect between its linguistic
proficiency and its capacity to generate human-like, embodied goals.We conclude
that there is a core gap between the value-driven, embodied nature of human
cognition and the statistical patterns of LLMs, highlighting the necessity of
incorporating intrinsic motivation and physical grounding into the design of
more human-aligned agents.

</details>


### [148] [Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning](https://arxiv.org/abs/2508.00323)
*Jianyi Zhang,Xu Ji,Ziyin Zhou,Yuchen Zhou,Shubo Shi,Haoyu Wu,Zhen Li,Shizhao Liu*

Main category: cs.AI

TL;DR: 提出了首个专注于结构化图形推理任务的评估基准ReasonBench，测试了11个VLMs的性能，发现局限性并通过双重优化策略提升33.5%。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型（VLMs）在复杂图形推理任务中的性能，现有研究多关注简单图形，缺乏对复杂推理能力的全面评估。

Method: 提出了ReasonBench评估基准，包含1,613个来自真实世界智力测试的问题，覆盖位置、属性、数量和多元素任务等推理维度。并提出了双重优化策略：Diagrammatic Reasoning Chain（DiaCoT）和ReasonTune。

Result: 基准测试了11个主流VLMs，揭示了当前模型的显著局限性。双重优化策略显著提升了模型性能。

Conclusion: 当前主流视觉语言模型（VLMs）在复杂图形推理任务中存在显著局限性，但通过提出的双重优化策略（DiaCoT和ReasonTune），模型性能提升了33.5%。

Abstract: Evaluating the performance of visual language models (VLMs) in graphic
reasoning tasks has become an important research topic. However, VLMs still
show obvious deficiencies in simulating human-level graphic reasoning
capabilities, especially in complex graphic reasoning and abstract problem
solving, which are less studied and existing studies only focus on simple
graphics. To evaluate the performance of VLMs in complex graphic reasoning, we
propose ReasonBench, the first evaluation benchmark focused on structured
graphic reasoning tasks, which includes 1,613 questions from real-world
intelligence tests. ReasonBench covers reasoning dimensions related to
location, attribute, quantity, and multi-element tasks, providing a
comprehensive evaluation of the performance of VLMs in spatial, relational, and
abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including
closed-source and open-source models) and reveal significant limitations of
current models. Based on these findings, we propose a dual optimization
strategy: Diagrammatic Reasoning Chain (DiaCoT) enhances the interpretability
of reasoning by decomposing layers, and ReasonTune enhances the task
adaptability of model reasoning through training, all of which improves VLM
performance by 33.5\%. All experimental data and code are in the repository:
https://huggingface.co/datasets/cistine/ReasonBench.

</details>


### [149] [R1-ACT: Efficient Reasoning Model Safety Alignment by Activating Safety Knowledge](https://arxiv.org/abs/2508.00324)
*Yeonjun In,Wonjoong Kim,Sangwu Park,Chanyoung Park*

Main category: cs.AI

TL;DR: R1-Act通过结构化推理显式触发模型安全知识，高效提升大型推理模型的安全性，且不影响性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型推理模型在复杂任务上表现出色，但研究发现它们容易执行有害指令，存在安全隐患。模型已具备足够的安全知识，但在推理过程中未能有效激活。

Method: 提出了R1-Act方法，通过结构化推理过程显式触发模型已有的安全知识。

Result: R1-Act在仅需1,000个训练样本和90分钟训练时间（单张RTX A6000 GPU）的情况下，显著提升了模型安全性，且不影响推理性能。

Conclusion: R1-Act是一种简单高效的后训练方法，通过结构化推理过程显式触发安全知识，显著提升了大型推理模型的安全性，同时保持了推理性能，优于现有的对齐方法。

Abstract: Although large reasoning models (LRMs) have demonstrated impressive
capabilities on complex tasks, recent studies reveal that these models
frequently fulfill harmful user instructions, raising significant safety
concerns. In this paper, we investigate the underlying cause of LRM safety
risks and find that models already possess sufficient safety knowledge but fail
to activate it during reasoning. Based on this insight, we propose R1-Act, a
simple and efficient post-training method that explicitly triggers safety
knowledge through a structured reasoning process. R1-Act achieves strong safety
improvements while preserving reasoning performance, outperforming prior
alignment methods. Notably, it requires only 1,000 training examples and 90
minutes of training on a single RTX A6000 GPU. Extensive experiments across
multiple LRM backbones and sizes demonstrate the robustness, scalability, and
practical efficiency of our approach.

</details>


### [150] [CoRGI: Verified Chain-of-Thought Reasoning with Visual Grounding](https://arxiv.org/abs/2508.00378)
*Shixin Yi,Lin Shang*

Main category: cs.AI

TL;DR: CoRGI是一个引入视觉验证的多模态推理框架，通过三阶段流程提升推理的准确性和解释的可信度。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain-of-Thought提示方法在视觉语言模型中常产生缺乏视觉内容基础的幻觉解释，需引入显式验证机制。

Method: CoRGI采用三阶段流程：生成文本推理链、通过专用模块（VEVM）提取视觉证据、结合文本推理与视觉证据生成验证答案。

Result: 在VCR基准测试中，CoRGI提升了Qwen-2.5VL和LLaVA-1.6等VLM的推理性能，并通过消融实验验证了各步骤的贡献。

Conclusion: CoRGI框架通过引入视觉验证机制，显著提升了多模态推理的鲁棒性，并生成了更事实性和有帮助的解释。

Abstract: Chain-of-Thought (CoT) prompting has shown promise in improving reasoning in
vision-language models (VLMs), but it often produces explanations that are
linguistically fluent yet lack grounding in visual content. We observe that
such hallucinations arise in part from the absence of an explicit verification
mechanism during multi-step reasoning. To address this, we propose
\textbf{CoRGI}(\textbf{C}hain \textbf{o}f \textbf{R}easoning with
\textbf{G}rounded \textbf{I}nsights), a modular framework that introduces
visual verification into the reasoning process. CoRGI follows a three-stage
pipeline: it first generates a textual reasoning chain, then extracts
supporting visual evidence for each reasoning step via a dedicated module
(VEVM), and finally synthesizes the textual rationale with visual evidence to
generate a grounded, verified answer. The framework can be integrated with
existing VLMs without end-to-end retraining. We evaluate CoRGI on the VCR
benchmark and find that it improves reasoning performance on two representative
open-source VLM backbones, Qwen-2.5VL and LLaVA-1.6. Ablation studies confirm
the contribution of each step in the verification module, and human evaluations
suggest that CoRGI leads to more factual and helpful explanations. We also
examine alternative designs for the visual verification step and discuss
potential limitations of post-hoc verification frameworks. These findings
highlight the importance of grounding intermediate reasoning steps in visual
evidence to enhance the robustness of multimodal reasoning.

</details>


### [151] [Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation](https://arxiv.org/abs/2508.00401)
*Riddhi J. Pitliya,Ozan Catal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen*

Main category: cs.AI

TL;DR: 提出基于ToM的主动推理方法，实现无需共享模型或通信的多智能体协作，实验验证其在避碰和觅食任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统多智能体协作方法常依赖共享模型或显式通信，限制了其通用性。本研究旨在通过ToM实现更灵活、通用的协作，仅通过观察行为推断他人信念。

Method: 我们扩展了基于推理树的规划算法，通过递归推理系统探索联合策略空间。智能体维护自身及他人信念和目标的独立表征，无需依赖任务特定的共享生成模型或显式通信。

Result: 实验表明，配备ToM的智能体在避碰和觅食任务中表现优于非ToM智能体，能有效避免碰撞并减少冗余行为。

Conclusion: 本研究通过将心智理论（ToM）融入主动推理框架，提出了一种新型多智能体合作方法。该方法不仅提升了智能体间的协作效率，还为人工智能的实践应用提供了新的方向，并深化了对ToM的计算理解。

Abstract: We present a novel approach to multi-agent cooperation by implementing theory
of mind (ToM) within active inference. ToM - the ability to understand that
others can have differing knowledge and goals - enables agents to reason about
others' beliefs while planning their own actions. Unlike previous active
inference approaches to multi-agent cooperation, our method neither relies on
task-specific shared generative models nor requires explicit communication,
while being generalisable. In our framework, the ToM-equipped agent maintains
distinct representations of its own and others' beliefs and goals. We extend
the sophisticated inference tree-based planning algorithm to systematically
explore joint policy spaces through recursive reasoning. Our approach is
evaluated through collision avoidance and foraging task simulations. Results
demonstrate that ToM-equipped agents cooperate better compared to non-ToM
counterparts by being able to avoid collisions and reduce redundant efforts.
Crucially, ToM agents accomplish this by inferring others' beliefs solely from
observable behaviour. This work advances practical applications in artificial
intelligence while providing computational insights into ToM.

</details>


### [152] [Cognitive Kernel-Pro: A Framework for Deep Research Agents and Agent Foundation Models Training](https://arxiv.org/abs/2508.00414)
*Tianqing Fang,Zhisong Zhang,Xiaoyang Wang,Rui Wang,Can Qin,Yuxuan Wan,Jun-Yu Ma,Ce Zhang,Jiaqi Chen,Xiyun Li,Hongming Zhang,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: Cognitive Kernel-Pro是一个开源免费的AI代理框架，通过高质量训练数据和创新策略提升了代理性能，在GAIA测试中超越现有系统。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理系统多为闭源或依赖付费API和专有工具，限制了研究社区的可访问性和可重复性。本文旨在通过开源框架Cognitive Kernel-Pro来推动高级AI代理的民主化开发和评估。

Method: 通过系统研究高质量训练数据的构建，包括查询、轨迹和可验证答案的生成，以及探索代理的测试时反思和投票策略，以增强代理的鲁棒性和性能。

Result: Cognitive Kernel-Pro在GAIA上实现了开源免费代理中的最先进性能，8B参数的开源模型超越了之前的领先系统WebDancer和WebSailor。

Conclusion: Cognitive Kernel-Pro 作为一个完全开源且最大限度免费的代理框架，成功提升了AI代理的可访问性和可重复性，并在GAIA基准测试中取得了最先进的结果，为高性能AI代理设立了新标准。

Abstract: General AI Agents are increasingly recognized as foundational frameworks for
the next generation of artificial intelligence, enabling complex reasoning, web
interaction, coding, and autonomous research capabilities. However, current
agent systems are either closed-source or heavily reliant on a variety of paid
APIs and proprietary tools, limiting accessibility and reproducibility for the
research community. In this work, we present \textbf{Cognitive Kernel-Pro}, a
fully open-source and (to the maximum extent) free multi-module agent framework
designed to democratize the development and evaluation of advanced AI agents.
Within Cognitive Kernel-Pro, we systematically investigate the curation of
high-quality training data for Agent Foundation Models, focusing on the
construction of queries, trajectories, and verifiable answers across four key
domains: web, file, code, and general reasoning. Furthermore, we explore novel
strategies for agent test-time reflection and voting to enhance agent
robustness and performance. We evaluate Cognitive Kernel-Pro on GAIA, achieving
state-of-the-art results among open-source and free agents. Notably, our
8B-parameter open-source model surpasses previous leading systems such as
WebDancer and WebSailor, establishing a new performance standard for
accessible, high-capability AI agents. Code is available at
https://github.com/Tencent/CognitiveKernel-Pro

</details>


### [153] [Thinking Machines: Mathematical Reasoning in the Age of LLMs](https://arxiv.org/abs/2508.00459)
*Andrea Asperti,Alberto Naibo,Claudio Sacerdoti Coen*

Main category: cs.AI

TL;DR: LLMs在非正式数学中表现优异，但在正式定理证明中仍面临挑战；研究探讨了其局限性及未来发展方向。


<details>
  <summary>Details</summary>
Motivation: LLMs在非正式数学问题解决中表现出色，但在正式定理证明中表现脆弱，这引发了对LLMs推理方式、监督方法及内部状态跟踪的深入探讨。

Method: 分析了当前最先进的模型和基准测试，探讨了机器学习与数学认知交叉的三个核心问题。

Result: 研究发现正式数学与代码合成之间存在显著差异，揭示了LLMs在证明生成中的脆弱性，并提出了可能的改进方向。

Conclusion: 本文探讨了LLMs在正式数学中的局限性，并提出了未来可能的研究方向，旨在扩展当前的能力边界。

Abstract: Large Language Models (LLMs) have shown remarkable abilities in structured
reasoning and symbolic tasks, with coding emerging as a particular area of
strength. This success has sparked growing interest in applying LLMs to
mathematics, both in informal problem-solving and formal theorem proving.
However, progress in formal mathematics has proven to be significantly more
difficult, despite surface-level similarities between programming and proof
construction. This discrepancy raises important questions about how LLMs
``reason'', how they are supervised, and whether they internally track a notion
of computational or deductive state. In this article, we address the
state-of-the-art of the discipline, focusing on recent models and benchmarks,
and explore three central issues at the intersection of machine learning and
mathematical cognition: (i) the trade-offs between formal and informal
mathematics as training domains; (ii) the deeper reasons why proof generation
remains more brittle than code synthesis; (iii) and the question of whether
LLMs represent, or merely mimic, a notion of evolving logical state. Our goal
is not to draw hard boundaries, but to identify where the current limits lie,
and how they might be extended.

</details>


### [154] [Pro2Guard: Proactive Runtime Enforcement of LLM Agent Safety via Probabilistic Model Checking](https://arxiv.org/abs/2508.00500)
*Haoyu Wang,Chris M. Poskitt,Jun Sun,Jiali Wei*

Main category: cs.AI

TL;DR: Pro2Guard是一种主动安全框架，通过概率可达性分析预测LLM代理的未来风险，提前干预，显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于规则的执行系统（如AgentSpec）缺乏预见性，难以处理长期依赖和分布变化，Pro2Guard旨在解决这些局限性。

Method: Pro2Guard 将代理行为抽象为符号状态，并从执行轨迹中学习离散时间马尔可夫链（DTMC），在运行时估计到达不安全状态的概率。

Result: 在家庭代理任务中，Pro2Guard 在低阈值下可提前阻止93.6%的不安全任务；在自动驾驶场景中，能100%预测交通违规和碰撞，提前38.66秒预警风险。

Conclusion: Pro2Guard 是一种基于概率可达性分析的主动运行时执行框架，能够通过预测未来风险并提前干预，显著提高LLM代理的安全性。

Abstract: Large Language Model (LLM) agents exhibit powerful autonomous capabilities
across domains such as robotics, virtual assistants, and web automation.
However, their stochastic behavior introduces significant safety risks that are
difficult to anticipate. Existing rule-based enforcement systems, such as
AgentSpec, focus on developing reactive safety rules, which typically respond
only when unsafe behavior is imminent or has already occurred. These systems
lack foresight and struggle with long-horizon dependencies and distribution
shifts. To address these limitations, we propose Pro2Guard, a proactive runtime
enforcement framework grounded in probabilistic reachability analysis.
Pro2Guard abstracts agent behaviors into symbolic states and learns a
Discrete-Time Markov Chain (DTMC) from execution traces. At runtime, it
anticipates future risks by estimating the probability of reaching unsafe
states, triggering interventions before violations occur when the predicted
risk exceeds a user-defined threshold. By incorporating semantic validity
checks and leveraging PAC bounds, Pro2Guard ensures statistical reliability
while approximating the underlying ground-truth model. We evaluate Pro2Guard
extensively across two safety-critical domains: embodied household agents and
autonomous vehicles. In embodied agent tasks, Pro2Guard enforces safety early
on up to 93.6% of unsafe tasks using low thresholds, while configurable modes
(e.g., reflect) allow balancing safety with task success, maintaining up to
80.4% task completion. In autonomous driving scenarios, Pro2Guard achieves 100%
prediction of traffic law violations and collisions, anticipating risks up to
38.66 seconds ahead.

</details>


### [155] [MultiSHAP: A Shapley-Based Framework for Explaining Cross-Modal Interactions in Multimodal AI Models](https://arxiv.org/abs/2508.00576)
*Zhanliang Wang,Kai Wang*

Main category: cs.AI

TL;DR: MultiSHAP是一种模型无关的解释框架，通过Shapley Interaction Index量化多模态模型中的跨模态交互，适用于开源和闭源模型，提供实例级和数据集级解释。


<details>
  <summary>Details</summary>
Motivation: 解决多模态AI模型因'黑盒'特性在高风险应用中部署时面临的解释性和可信度挑战。

Method: 利用Shapley Interaction Index，MultiSHAP将多模态预测归因于视觉和文本细粒度元素之间的成对交互作用。

Result: 在公共多模态基准测试中验证了MultiSHAP能准确捕捉跨模态推理机制，并通过实际案例展示了其实际效用。

Conclusion: MultiSHAP框架为多模态AI模型提供了一种模型无关的解释方法，能够精确量化模态间的协同效应，适用于开源和闭源模型，具有广泛的扩展性和实际应用价值。

Abstract: Multimodal AI models have achieved impressive performance in tasks that
require integrating information from multiple modalities, such as vision and
language. However, their "black-box" nature poses a major barrier to deployment
in high-stakes applications where interpretability and trustworthiness are
essential. How to explain cross-modal interactions in multimodal AI models
remains a major challenge. While existing model explanation methods, such as
attention map and Grad-CAM, offer coarse insights into cross-modal
relationships, they cannot precisely quantify the synergistic effects between
modalities, and are limited to open-source models with accessible internal
weights. Here we introduce MultiSHAP, a model-agnostic interpretability
framework that leverages the Shapley Interaction Index to attribute multimodal
predictions to pairwise interactions between fine-grained visual and textual
elements (such as image patches and text tokens), while being applicable to
both open- and closed-source models. Our approach provides: (1) instance-level
explanations that reveal synergistic and suppressive cross-modal effects for
individual samples - "why the model makes a specific prediction on this input",
and (2) dataset-level explanation that uncovers generalizable interaction
patterns across samples - "how the model integrates information across
modalities". Experiments on public multimodal benchmarks confirm that MultiSHAP
faithfully captures cross-modal reasoning mechanisms, while real-world case
studies demonstrate its practical utility. Our framework is extensible beyond
two modalities, offering a general solution for interpreting complex multimodal
AI models.

</details>


### [156] [From EMR Data to Clinical Insight: An LLM-Driven Framework for Automated Pre-Consultation Questionnaire Generation](https://arxiv.org/abs/2508.00581)
*Ruiqing Ding,Qianfang Sun,Yongkang Leng,Hui Yin,Xiaojian Li*

Main category: cs.AI

TL;DR: 论文提出了一种多阶段LLM驱动框架，用于从EMR生成预咨询问卷，解决了直接LLM方法的不足，并在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 由于直接从复杂且庞大的电子医疗记录（EMRs）生成全面的预咨询问卷是一项具有挑战性的任务，直接使用大型语言模型（LLM）方法在信息完整性、逻辑顺序和疾病级综合方面存在困难，因此需要一种新的方法来解决这一问题。

Method: 论文提出了一种新颖的多阶段LLM驱动框架：第一阶段从EMR中提取原子断言；第二阶段构建个人因果网络并从EMR语料库中聚类代表性网络以综合疾病知识；第三阶段基于这些结构化表示生成个性化的标准化疾病特定问卷。

Result: 在真实世界的EMR数据集上评估并由临床专家验证，该方法在信息覆盖、诊断相关性、可理解性和生成时间方面表现出优越性能。

Conclusion: 该论文提出的多阶段LLM驱动框架在信息覆盖、诊断相关性、可理解性和生成时间方面表现出色，展现了提升患者信息收集效率的实际潜力。

Abstract: Pre-consultation is a critical component of effective healthcare delivery.
However, generating comprehensive pre-consultation questionnaires from complex,
voluminous Electronic Medical Records (EMRs) is a challenging task. Direct
Large Language Model (LLM) approaches face difficulties in this task,
particularly regarding information completeness, logical order, and
disease-level synthesis. To address this issue, we propose a novel multi-stage
LLM-driven framework: Stage 1 extracts atomic assertions (key facts with
timing) from EMRs; Stage 2 constructs personal causal networks and synthesizes
disease knowledge by clustering representative networks from an EMR corpus;
Stage 3 generates tailored personal and standardized disease-specific
questionnaires based on these structured representations. This framework
overcomes limitations of direct methods by building explicit clinical
knowledge. Evaluated on a real-world EMR dataset and validated by clinical
experts, our method demonstrates superior performance in information coverage,
diagnostic relevance, understandability, and generation time, highlighting its
practical potential to enhance patient information collection.

</details>


### [157] [Multi-Agent Game Generation and Evaluation via Audio-Visual Recordings](https://arxiv.org/abs/2508.00632)
*Alexia Jolicoeur-Martineau*

Main category: cs.AI

TL;DR: 提出了AVR-Eval和AVR-Agent系统，用于评估和生成交互式音视频内容，实验显示其优于单次生成方法，但利用资产和反馈能力仍有不足。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLMs在生成复杂交互式内容（如视频游戏）时缺乏自动化评估指标和利用高质量资产能力的问题。

Method: 提出了AVR-Eval评估指标和AVR-Agent多智能体系统，结合全模态模型和文本模型进行内容质量评估与代码生成优化。

Result: AVR-Agent生成的内容在实验中表现优于单次生成的内容，但未能有效利用自定义资产和AVR反馈。

Conclusion: 当前AI在生成交互式音视频内容方面存在挑战，特别是利用高质量资产和音视频反馈的能力不足，揭示了人类与机器内容创作方法的根本差异。

Abstract: While AI excels at generating text, audio, images, and videos, creating
interactive audio-visual content such as video games remains challenging.
Current LLMs can generate JavaScript games and animations, but lack automated
evaluation metrics and struggle with complex content that normally requires
teams of humans working for many months (multi-shot, multi-agents) using assets
made by artists. To tackle these issues, we built a new metric and a
multi-agent system.
  We propose AVR-Eval, a relative metric for multimedia content quality using
Audio-Visual Recordings (AVRs). An omni-modal model (processing text, video,
and audio) compares the AVRs of two contents, with a text model reviewing
evaluations to determine superiority. We show that AVR-Eval properly identifies
good from broken or mismatched content.
  We built AVR-Agent, a multi-agent system generating JavaScript code from a
bank of multimedia assets (audio, images, 3D models). The coding agent selects
relevant assets, generates multiple initial codes, uses AVR-Eval to identify
the best version, and iteratively improves it through omni-modal agent feedback
from the AVR.
  We run experiments on games and animations with AVR-Eval (win rate of content
A against B). We find that content generated by AVR-Agent has a significantly
higher win rate against content made through one-shot generation. However,
models struggle to leverage custom assets and AVR feedback effectively, showing
no higher win rate. This reveals a critical gap: while humans benefit from
high-quality assets and audio-visual feedback, current coding models do not
seem to utilize these resources as effectively, highlighting fundamental
differences between human and machine content creation approaches.

</details>


### [158] [Multi-Band Variable-Lag Granger Causality: A Unified Framework for Causal Time Series Inference across Frequencies](https://arxiv.org/abs/2508.00658)
*Chakattrai Sookkongwaree,Tattep Lakmuang,Chainarong Amornbunchornvej*

Main category: cs.AI

TL;DR: 该论文提出MB-VLGC框架，解决了传统Granger因果性在频带和时间延迟上的局限性，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统Granger因果性和VLGC方法无法处理因果交互在时间延迟和频带上的变化，特别是在脑信号等复杂系统中。

Method: 提出了一种新颖的MB-VLGC框架，包括正式定义、理论证明和高效推理流程。

Result: 在合成和真实数据集上，MB-VLGC框架显著优于现有方法。

Conclusion: MB-VLGC框架通过显式建模频率依赖的因果延迟，显著优于现有方法，适用于多种时间序列数据。

Abstract: Understanding causal relationships in time series is fundamental to many
domains, including neuroscience, economics, and behavioral science. Granger
causality is one of the well-known techniques for inferring causality in time
series. Typically, Granger causality frameworks have a strong fix-lag
assumption between cause and effect, which is often unrealistic in complex
systems. While recent work on variable-lag Granger causality (VLGC) addresses
this limitation by allowing a cause to influence an effect with different time
lags at each time point, it fails to account for the fact that causal
interactions may vary not only in time delay but also across frequency bands.
For example, in brain signals, alpha-band activity may influence another region
with a shorter delay than slower delta-band oscillations. In this work, we
formalize Multi-Band Variable-Lag Granger Causality (MB-VLGC) and propose a
novel framework that generalizes traditional VLGC by explicitly modeling
frequency-dependent causal delays. We provide a formal definition of MB-VLGC,
demonstrate its theoretical soundness, and propose an efficient inference
pipeline. Extensive experiments across multiple domains demonstrate that our
framework significantly outperforms existing methods on both synthetic and
real-world datasets, confirming its broad applicability to any type of time
series data. Code and datasets are publicly available.

</details>


### [159] [Transparent Adaptive Learning via Data-Centric Multimodal Explainable AI](https://arxiv.org/abs/2508.00665)
*Maryam Mosleh,Marie Devlin,Ellis Solaiman*

Main category: cs.AI

TL;DR: 本文提出混合XAI与生成式AI的框架，生成个性化解释，强调用户角色与目标，推动透明且用户友好的AI教育系统。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动的自适应学习系统缺乏透明度，且多数XAI技术忽视用户角色和理解。

Method: 提出了一种混合框架，结合传统XAI技术与生成式AI模型及用户个性化，生成符合用户需求的多模态个性化解释。

Result: 重新定义可解释性为动态沟通过程，并探讨了框架设计、XAI在教育中的局限性及研究方向。

Conclusion: 本文旨在推动可解释AI的发展，以增强透明度并支持以用户为中心的体验。

Abstract: Artificial intelligence-driven adaptive learning systems are reshaping
education through data-driven adaptation of learning experiences. Yet many of
these systems lack transparency, offering limited insight into how decisions
are made. Most explainable AI (XAI) techniques focus on technical outputs but
neglect user roles and comprehension. This paper proposes a hybrid framework
that integrates traditional XAI techniques with generative AI models and user
personalisation to generate multimodal, personalised explanations tailored to
user needs. We redefine explainability as a dynamic communication process
tailored to user roles and learning goals. We outline the framework's design,
key XAI limitations in education, and research directions on accuracy,
fairness, and personalisation. Our aim is to move towards explainable AI that
enhances transparency while supporting user-centred experiences.

</details>


### [160] [Context-Aware Visualization for Explainable AI Recommendations in Social Media: A Vision for User-Aligned Explanations](https://arxiv.org/abs/2508.00674)
*Banan Alkhateeb,Ellis Solaiman*

Main category: cs.AI

TL;DR: 论文提出了一种用户分段的、上下文感知的视觉解释系统，首次在一个流程中同时调整解释风格和粒度，以满足不同用户需求，并通过试点验证其效果。


<details>
  <summary>Details</summary>
Motivation: 当前社交媒体平台的AI推荐解释普遍缺乏针对用户特定需求的个性化，导致用户不理解推荐原因，降低了推荐的价值。

Method: 论文提出了一个视觉解释系统，该系统根据用户需求和上下文展示不同形式的解释，包括针对AI专家的技术详细版本和针对普通用户的简化版本。

Result: 通过一个包含30名X用户的公开试点，验证了该框架对用户决策和信任的影响。

Conclusion: 该论文提出了一个用户分段的、上下文感知的解释层框架，通过多样化的可视化解释方法，首次在一个流程中同时调整解释风格和粒度，以满足不同用户的需求。

Abstract: Social media platforms today strive to improve user experience through AI
recommendations, yet the value of such recommendations vanishes as users do not
understand the reasons behind them. This issue arises because explainability in
social media is general and lacks alignment with user-specific needs. In this
vision paper, we outline a user-segmented and context-aware explanation layer
by proposing a visual explanation system with diverse explanation methods. The
proposed system is framed by the variety of user needs and contexts, showing
explanations in different visualized forms, including a technically detailed
version for AI experts and a simplified one for lay users. Our framework is the
first to jointly adapt explanation style (visual vs. numeric) and granularity
(expert vs. lay) inside a single pipeline. A public pilot with 30 X users will
validate its impact on decision-making and trust.

</details>


### [161] [Unraveling Hidden Representations: A Multi-Modal Layer Analysis for Better Synthetic Content Forensics](https://arxiv.org/abs/2508.00784)
*Tom Or,Omri Azencot*

Main category: cs.AI

TL;DR: 提出利用大型预训练多模态模型的潜在编码训练线性分类器，实现跨模态的高效假检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 恶意用户利用合成媒体传播错误信息和深度伪造内容，现有分类器通常仅在同一生成器家族和数据模态内有效，泛化能力差，亟需一种通用分类器。

Method: 提出使用大型预训练多模态模型进行生成内容检测，利用其潜在编码自然区分真实与虚假信息，并在线性分类器上训练这些特征。

Result: 在音频和图像的假检测中，性能超越或匹配强基线方法。

Conclusion: 利用大型预训练多模态模型的潜在编码可以有效区分真实与生成内容，线性分类器在这些特征上训练后，能在多种模态上达到最先进的结果，且计算高效、训练快速，甚至在少样本设置下也有效。

Abstract: Generative models achieve remarkable results in multiple data domains,
including images and texts, among other examples. Unfortunately, malicious
users exploit synthetic media for spreading misinformation and disseminating
deepfakes. Consequently, the need for robust and stable fake detectors is
pressing, especially when new generative models appear everyday. While the
majority of existing work train classifiers that discriminate between real and
fake information, such tools typically generalize only within the same family
of generators and data modalities, yielding poor results on other generative
classes and data domains. Towards a universal classifier, we propose the use of
large pre-trained multi-modal models for the detection of generative content.
Effectively, we show that the latent code of these models naturally captures
information discriminating real from fake. Building on this observation, we
demonstrate that linear classifiers trained on these features can achieve
state-of-the-art results across various modalities, while remaining
computationally efficient, fast to train, and effective even in few-shot
settings. Our work primarily focuses on fake detection in audio and images,
achieving performance that surpasses or matches that of strong baseline
methods.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [162] [XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation](https://arxiv.org/abs/2508.00097)
*Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang*

Main category: cs.RO

TL;DR: XRoboToolkit 是一个基于 OpenXR 的跨平台遥操作框架，通过低延迟视觉反馈和模块化设计，解决了当前机器人数据收集的 scalability 和质量问题。


<details>
  <summary>Details</summary>
Motivation: 由于当前遥操作方法在可扩展性、设置复杂性和数据质量方面存在不足，亟需一种更高效、高质量的机器人演示数据集收集方案。

Method: 该系统采用低延迟立体视觉反馈、基于优化的逆运动学以及多种跟踪模式（如头部、控制器、手部和辅助运动跟踪器），支持模块化架构，可无缝集成多种机器人平台和仿真环境。

Result: XRoboToolkit 在精确操作任务中表现出色，并通过训练 VLA 模型验证了其数据质量，模型展现出强大的自主性能。

Conclusion: XRoboToolkit 是一个高效、可扩展的跨平台框架，通过 OpenXR 标准实现基于扩展现实的机器人遥操作，显著提升了数据收集的质量和效率。

Abstract: The rapid advancement of Vision-Language-Action models has created an urgent
need for large-scale, high-quality robot demonstration datasets. Although
teleoperation is the predominant method for data collection, current approaches
suffer from limited scalability, complex setup procedures, and suboptimal data
quality. This paper presents XRoboToolkit, a cross-platform framework for
extended reality based robot teleoperation built on the OpenXR standard. The
system features low-latency stereoscopic visual feedback, optimization-based
inverse kinematics, and support for diverse tracking modalities including head,
controller, hand, and auxiliary motion trackers. XRoboToolkit's modular
architecture enables seamless integration across robotic platforms and
simulation environments, spanning precision manipulators, mobile robots, and
dexterous hands. We demonstrate the framework's effectiveness through precision
manipulation tasks and validate data quality by training VLA models that
exhibit robust autonomous performance.

</details>


### [163] [CHILD (Controller for Humanoid Imitation and Live Demonstration): a Whole-Body Humanoid Teleoperation System](https://arxiv.org/abs/2508.00162)
*Noboru Myers,Obin Kwon,Sankalp Yamsani,Joohyung Kim*

Main category: cs.RO

TL;DR: CHILD 是一个紧凑的遥操作系统，支持仿人机器人的关节级控制，通过自适应力反馈提升操作体验，并开源硬件设计以促进可访问性。


<details>
  <summary>Details</summary>
Motivation: 现有研究很少支持仿人机器人的全身关节级遥操作，限制了任务的多样性。CHILD 旨在解决这一问题。

Method: 开发了 CHILD，一个紧凑可重构的遥操作系统，支持仿人机器人的关节级控制，并集成自适应力反馈以增强操作体验和安全性。

Result: 在仿人机器人和多臂系统上验证了 CHILD 的全身控制和移动操作能力，并开源了硬件设计。

Conclusion: CHILD 系统通过开源设计促进了可访问性和可重复性，为仿人机器人的全身关节级遥操作提供了有效的解决方案。

Abstract: Recent advances in teleoperation have demonstrated robots performing complex
manipulation tasks. However, existing works rarely support whole-body
joint-level teleoperation for humanoid robots, limiting the diversity of tasks
that can be accomplished. This work presents Controller for Humanoid Imitation
and Live Demonstration (CHILD), a compact reconfigurable teleoperation system
that enables joint level control over humanoid robots. CHILD fits within a
standard baby carrier, allowing the operator control over all four limbs, and
supports both direct joint mapping for full-body control and loco-manipulation.
Adaptive force feedback is incorporated to enhance operator experience and
prevent unsafe joint movements. We validate the capabilities of this system by
conducting loco-manipulation and full-body control examples on a humanoid robot
and multiple dual-arm systems. Lastly, we open-source the design of the
hardware promoting accessibility and reproducibility. Additional details and
open-source information are available at our project website:
https://uiuckimlab.github.io/CHILD-pages.

</details>


### [164] [Topology-Inspired Morphological Descriptor for Soft Continuum Robots](https://arxiv.org/abs/2508.00258)
*Zhiwei Wu,Siyi Wei,Jiahao Luo,Jinhui Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种结合PRB模型和莫尔斯理论的拓扑形态描述符，用于软连续机器人的定量形态描述、分类和控制，提升医疗应用的精确性。


<details>
  <summary>Details</summary>
Motivation: 为了提高软连续机器人在医疗应用（如微创手术和血管内介入）中的精确性和适应性，需要一种定量的形态描述和控制方法。

Method: 结合伪刚体（PRB）模型与莫尔斯理论，通过计算方向投影的临界点，提出了一种拓扑启发的形态描述符。

Result: 提出的描述符实现了多模态配置的离散表示，并促进了形态分类，同时通过优化问题实现了形态控制。

Conclusion: 该框架为软连续机器人的形态描述、分类和控制提供了一种统一的方法论，有望提升其在医疗应用中的精确性和适应性。

Abstract: This paper presents a topology-inspired morphological descriptor for soft
continuum robots by combining a pseudo-rigid-body (PRB) model with Morse theory
to achieve a quantitative characterization of robot morphologies. By counting
critical points of directional projections, the proposed descriptor enables a
discrete representation of multimodal configurations and facilitates
morphological classification. Furthermore, we apply the descriptor to
morphology control by formulating the target configuration as an optimization
problem to compute actuation parameters that generate equilibrium shapes with
desired topological features. The proposed framework provides a unified
methodology for quantitative morphology description, classification, and
control of soft continuum robots, with the potential to enhance their precision
and adaptability in medical applications such as minimally invasive surgery and
endovascular interventions.

</details>


### [165] [UAV-ON: A Benchmark for Open-World Object Goal Navigation with Aerial Agents](https://arxiv.org/abs/2508.00288)
*Jianqiang Xiao,Yuexuan Sun,Yixin Shao,Boxi Gan,Rongqiang Liu,Yanjing Wu,Weili Gua,Xiang Deng*

Main category: cs.RO

TL;DR: UAV-ON是一个针对空中智能体的大规模目标导航基准，旨在解决传统VLN范式的局限性，通过语义目标驱动在复杂环境中实现自主导航。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖视觉和语言导航(VLN)范式，依赖顺序语言指令，限制了可扩展性和自主性。

Method: 论文提出了UAV-ON基准，包含14个高保真Unreal Engine环境和1270个标注目标对象，并实现了Aerial ObjectNav Agent (AOA)等基线方法。

Result: 所有基线方法在这一设定下表现不佳，突显了空中导航和语义目标基础的复合挑战。

Conclusion: UAV-ON旨在推动复杂现实环境中基于语义目标描述的可扩展无人机自主性研究。

Abstract: Aerial navigation is a fundamental yet underexplored capability in embodied
intelligence, enabling agents to operate in large-scale, unstructured
environments where traditional navigation paradigms fall short. However, most
existing research follows the Vision-and-Language Navigation (VLN) paradigm,
which heavily depends on sequential linguistic instructions, limiting its
scalability and autonomy. To address this gap, we introduce UAV-ON, a benchmark
for large-scale Object Goal Navigation (ObjectNav) by aerial agents in
open-world environments, where agents operate based on high-level semantic
goals without relying on detailed instructional guidance as in VLN. UAV-ON
comprises 14 high-fidelity Unreal Engine environments with diverse semantic
regions and complex spatial layouts, covering urban, natural, and mixed-use
settings. It defines 1270 annotated target objects, each characterized by an
instance-level instruction that encodes category, physical footprint, and
visual descriptors, allowing grounded reasoning. These instructions serve as
semantic goals, introducing realistic ambiguity and complex reasoning
challenges for aerial agents. To evaluate the benchmark, we implement several
baseline methods, including Aerial ObjectNav Agent (AOA), a modular policy that
integrates instruction semantics with egocentric observations for long-horizon,
goal-directed exploration. Empirical results show that all baselines struggle
in this setting, highlighting the compounded challenges of aerial navigation
and semantic goal grounding. UAV-ON aims to advance research on scalable UAV
autonomy driven by semantic goal descriptions in complex real-world
environments.

</details>


### [166] [TopoDiffuser: A Diffusion-Based Multimodal Trajectory Prediction Model with Topometric Maps](https://arxiv.org/abs/2508.00303)
*Zehui Xu,Junhui Wang,Yongliang Shi,Chao Gao,Guyue Zhou*

Main category: cs.RO

TL;DR: TopoDiffuser是一个基于扩散模型的多模态轨迹预测框架，通过结合拓扑地图生成准确、多样且符合道路要求的未来运动预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成未来运动预测时往往依赖显式约束，难以自然符合道路几何形状。TopoDiffuser旨在通过嵌入拓扑地图的结构线索，实现无需显式约束的轨迹生成。

Method: 提出了一种多模态条件编码器，融合LiDAR观测、历史运动和路线信息为统一的鸟瞰图（BEV）表示，并通过扩散模型的去噪过程生成轨迹。

Result: 在KITTI基准测试中，TopoDiffuser超越了现有方法，同时保持了强几何一致性。消融实验验证了各输入模态和去噪步骤的贡献。

Conclusion: TopoDiffuser通过结合拓扑地图和扩散模型，实现了无需显式约束的高质量轨迹预测，为未来研究提供了开源代码。

Abstract: This paper introduces TopoDiffuser, a diffusion-based framework for
multimodal trajectory prediction that incorporates topometric maps to generate
accurate, diverse, and road-compliant future motion forecasts. By embedding
structural cues from topometric maps into the denoising process of a
conditional diffusion model, the proposed approach enables trajectory
generation that naturally adheres to road geometry without relying on explicit
constraints. A multimodal conditioning encoder fuses LiDAR observations,
historical motion, and route information into a unified bird's-eye-view (BEV)
representation. Extensive experiments on the KITTI benchmark demonstrate that
TopoDiffuser outperforms state-of-the-art methods, while maintaining strong
geometric consistency. Ablation studies further validate the contribution of
each input modality, as well as the impact of denoising steps and the number of
trajectory samples. To support future research, we publicly release our code at
https://github.com/EI-Nav/TopoDiffuser.

</details>


### [167] [Omni-Scan: Creating Visually-Accurate Digital Twin Object Models Using a Bimanual Robot with Handover and Gaussian Splat Merging](https://arxiv.org/abs/2508.00354)
*Tianshuang Qiu,Zehan Ma,Karim El-Refai,Hiya Shah,Chung Min Kim,Justin Kerr,Ken Goldberg*

Main category: cs.RO

TL;DR: Omni-Scan是一种使用双机械臂和计算机视觉技术生成高质量3D高斯溅射模型的流程，适用于零件缺陷检测，准确率达83%。


<details>
  <summary>Details</summary>
Motivation: 现有的3D物体扫描方法通常需要多相机阵列或精确的激光扫描仪，这些方法受限于工作空间。Omni-Scan旨在通过双机械臂系统实现高质量3D高斯溅射模型的全方向建模。

Method: 提出了一种使用双机械臂抓取物体并旋转的流程，结合DepthAnything、Segment Anything和RAFT光流模型来识别和隔离物体，并修改了3DGS训练流程以支持带有抓取遮挡的拼接数据集。

Result: 通过Omni-Scan流程，成功生成了物体的全方向（360度视角）模型，并在零件缺陷检测中表现出色。

Conclusion: Omni-Scan 能够以83%的平均准确率识别12种工业和家用物体的视觉或几何缺陷。

Abstract: 3D Gaussian Splats (3DGSs) are 3D object models derived from multi-view
images. Such "digital twins" are useful for simulations, virtual reality,
marketing, robot policy fine-tuning, and part inspection. 3D object scanning
usually requires multi-camera arrays, precise laser scanners, or robot
wrist-mounted cameras, which have restricted workspaces. We propose Omni-Scan,
a pipeline for producing high-quality 3D Gaussian Splat models using a
bi-manual robot that grasps an object with one gripper and rotates the object
with respect to a stationary camera. The object is then re-grasped by a second
gripper to expose surfaces that were occluded by the first gripper. We present
the Omni-Scan robot pipeline using DepthAny-thing, Segment Anything, as well as
RAFT optical flow models to identify and isolate objects held by a robot
gripper while removing the gripper and the background. We then modify the 3DGS
training pipeline to support concatenated datasets with gripper occlusion,
producing an omni-directional (360 degree view) model of the object. We apply
Omni-Scan to part defect inspection, finding that it can identify visual or
geometric defects in 12 different industrial and household objects with an
average accuracy of 83%. Interactive videos of Omni-Scan 3DGS models can be
found at https://berkeleyautomation.github.io/omni-scan/

</details>


### [168] [TOP: Time Optimization Policy for Stable and Accurate Standing Manipulation with Humanoid Robots](https://arxiv.org/abs/2508.00355)
*Zhenghan Chen,Haocheng Xu,Haodong Zhang,Liang Zhang,He Li,Dongqi Wang,Jiyu Yu,Yifei Yang,Zhongxiang Zhou,Rong Xiong*

Main category: cs.RO

TL;DR: 提出了一种时间优化策略（TOP），结合VAE和解耦控制器，以同时确保人形机器人在站立操作任务中的平衡、精确性和时间效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时确保高维上半身关节的精确控制和整体系统的鲁棒性，尤其是在上半身运动快速时。

Method: 1. 使用变分自编码器（VAE）表示上半身运动以增强上下半身协调能力；2. 将全身控制解耦为上半身PD控制器（精确控制）和下半身强化学习控制器（增强鲁棒稳定性）；3. 结合TOP方法训练以减少快速上半身运动对平衡的负担。

Result: 通过仿真和真实实验验证，该方法在站立操作任务中表现出优越的稳定性和精确性。

Conclusion: 提出的时间优化策略（TOP）与解耦控制器和VAE结合，有效提升了人形机器人在站立操作任务中的稳定性、精确性和时间效率。

Abstract: Humanoid robots have the potential capability to perform a diverse range of
manipulation tasks, but this is based on a robust and precise standing
controller. Existing methods are either ill-suited to precisely control
high-dimensional upper-body joints, or difficult to ensure both robustness and
accuracy, especially when upper-body motions are fast. This paper proposes a
novel time optimization policy (TOP), to train a standing manipulation control
model that ensures balance, precision, and time efficiency simultaneously, with
the idea of adjusting the time trajectory of upper-body motions but not only
strengthening the disturbance resistance of the lower-body. Our approach
consists of three parts. Firstly, we utilize motion prior to represent
upper-body motions to enhance the coordination ability between the upper and
lower-body by training a variational autoencoder (VAE). Then we decouple the
whole-body control into an upper-body PD controller for precision and a
lower-body RL controller to enhance robust stability. Finally, we train TOP
method in conjunction with the decoupled controller and VAE to reduce the
balance burden resulting from fast upper-body motions that would destabilize
the robot and exceed the capabilities of the lower-body RL policy. The
effectiveness of the proposed approach is evaluated via both simulation and
real world experiments, which demonstrate the superiority on standing
manipulation tasks stably and accurately. The project page can be found at
https://anonymous.4open.science/w/top-258F/.

</details>


### [169] [A Whole-Body Motion Imitation Framework from Human Data for Full-Size Humanoid Robot](https://arxiv.org/abs/2508.00362)
*Zhenghan Chen,Haodong Zhang,Dongqi Wang,Jiyu Yu,Haocheng Xu,Yue Wang,Rong Xiong*

Main category: cs.RO

TL;DR: A novel framework for humanoid robots to imitate human motions accurately, using motion retargeting and predictive control, validated by experiments.


<details>
  <summary>Details</summary>
Motivation: Motion imitation enhances humanoid robots' ability to perform complex, human-like movements, but kinematic and dynamic differences pose challenges in maintaining balance and accuracy.

Method: The method combines contact-aware whole-body motion retargeting for initial trajectory values and a non-linear centroidal model predictive controller for real-time balance and accuracy.

Result: Experiments show the framework's capability to accurately imitate various human motions while maintaining balance and overcoming disturbances.

Conclusion: The proposed framework effectively enables humanoid robots to imitate human motions with accuracy and adaptability, validated through both simulation and real-world experiments.

Abstract: Motion imitation is a pivotal and effective approach for humanoid robots to
achieve a more diverse range of complex and expressive movements, making their
performances more human-like. However, the significant differences in
kinematics and dynamics between humanoid robots and humans present a major
challenge in accurately imitating motion while maintaining balance. In this
paper, we propose a novel whole-body motion imitation framework for a full-size
humanoid robot. The proposed method employs contact-aware whole-body motion
retargeting to mimic human motion and provide initial values for reference
trajectories, and the non-linear centroidal model predictive controller ensures
the motion accuracy while maintaining balance and overcoming external
disturbances in real time. The assistance of the whole-body controller allows
for more precise torque control. Experiments have been conducted to imitate a
variety of human motions both in simulation and in a real-world humanoid robot.
These experiments demonstrate the capability of performing with accuracy and
adaptability, which validates the effectiveness of our approach.

</details>


### [170] [On Learning Closed-Loop Probabilistic Multi-Agent Simulator](https://arxiv.org/abs/2508.00384)
*Juanwu Lu,Rohit Gupta,Ahmadreza Moradipari,Kyungtae Han,Ruqi Zhang,Ziran Wang*

Main category: cs.RO

TL;DR: NIVA是一个基于分层贝叶斯模型的多智能体模拟框架，通过闭环模拟在自动驾驶评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶车辆的快速迭代部署，构建真实且可扩展的多智能体交通模拟器以进行高效评估的需求日益增长。

Method: NIVA是一个基于分层贝叶斯模型的概率框架，通过自回归采样从潜在的高斯分布混合中进行闭环、观察条件模拟。

Result: NIVA在Waymo Open Motion数据集上的实验表明，其性能与现有方法相当，且在意图和驾驶风格控制方面表现更优。

Conclusion: NIVA框架在Waymo Open Motion数据集上表现出与现有方法竞争的性能，同时提供了对意图和驾驶风格的增强控制。

Abstract: The rapid iteration of autonomous vehicle (AV) deployments leads to
increasing needs for building realistic and scalable multi-agent traffic
simulators for efficient evaluation. Recent advances in this area focus on
closed-loop simulators that enable generating diverse and interactive
scenarios. This paper introduces Neural Interactive Agents (NIVA), a
probabilistic framework for multi-agent simulation driven by a hierarchical
Bayesian model that enables closed-loop, observation-conditioned simulation
through autoregressive sampling from a latent, finite mixture of Gaussian
distributions. We demonstrate how NIVA unifies preexisting sequence-to-sequence
trajectory prediction models and emerging closed-loop simulation models trained
on Next-token Prediction (NTP) from a Bayesian inference perspective.
Experiments on the Waymo Open Motion Dataset demonstrate that NIVA attains
competitive performance compared to the existing method while providing
embellishing control over intentions and driving styles.

</details>


### [171] [SubCDM: Collective Decision-Making with a Swarm Subset](https://arxiv.org/abs/2508.00467)
*Samratul Fuady,Danesh Tarapore,Mohammad D. Soorati*

Main category: cs.RO

TL;DR: SubCDM是一种资源高效的集体决策方法，通过动态子集减少参与机器人数，保持决策准确性。


<details>
  <summary>Details</summary>
Motivation: 现有集体决策策略需要所有机器人参与，资源密集且限制了群体执行其他任务的能力。

Method: 提出Subset-Based Collective Decision-Making (SubCDM)，通过动态和分散的子集构建，仅依赖局部信息，自适应确定子集大小以实现准确的决策。

Result: 使用一百个机器人的模拟结果表明，SubCDM在保持决策准确性的同时显著减少了参与决策的机器人数量。

Conclusion: SubCDM方法通过动态和分散的子集构建，实现了资源高效的集体决策，其准确性与使用整个群体相当，同时减少了参与决策的机器人数量。

Abstract: Collective decision-making is a key function of autonomous robot swarms,
enabling them to reach a consensus on actions based on environmental features.
Existing strategies require the participation of all robots in the
decision-making process, which is resource-intensive and prevents the swarm
from allocating the robots to any other tasks. We propose Subset-Based
Collective Decision-Making (SubCDM), which enables decisions using only a swarm
subset. The construction of the subset is dynamic and decentralized, relying
solely on local information. Our method allows the swarm to adaptively
determine the size of the subset for accurate decision-making, depending on the
difficulty of reaching a consensus. Simulation results using one hundred robots
show that our approach achieves accuracy comparable to using the entire swarm
while reducing the number of robots required to perform collective
decision-making, making it a resource-efficient solution for collective
decision-making in swarm robotics.

</details>


### [172] [HannesImitation: Grasping with the Hannes Prosthetic Hand via Imitation Learning](https://arxiv.org/abs/2508.00491)
*Carlo Alessi,Federico Vasile,Federico Ceola,Giulia Pasquale,Nicolò Boccardo,Lorenzo Natale*

Main category: cs.RO

TL;DR: 该论文提出了一种基于模仿学习的假肢手控制方法HannesImitationPolicy，通过训练扩散策略实现非结构化环境中的物体抓取，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人抓取和复杂操作任务中显示出潜力，但在假肢手控制中的应用尚未充分探索。填补这一空白可以提升假肢手的灵活性，使其在更多无约束场景中通过演示学习任务。

Method: 提出了HannesImitationPolicy，一种基于模仿学习的方法，用于控制Hannes假肢手。该方法利用HannesImitationDataset中的数据训练单个扩散策略，预测手腕方向和手部闭合以实现抓取。

Result: 实验评估表明，该方法在不同物体和条件下均能成功抓取，并且在非结构化场景中表现优于基于分割的视觉伺服控制器。

Conclusion: HannesImitationPolicy通过模仿学习方法成功提升了假肢手的控制能力，使其在非结构化环境中能够实现物体抓取，并且在非结构化场景中表现优于基于分割的视觉伺服控制器。

Abstract: Recent advancements in control of prosthetic hands have focused on increasing
autonomy through the use of cameras and other sensory inputs. These systems aim
to reduce the cognitive load on the user by automatically controlling certain
degrees of freedom. In robotics, imitation learning has emerged as a promising
approach for learning grasping and complex manipulation tasks while simplifying
data collection. Its application to the control of prosthetic hands remains,
however, largely unexplored. Bridging this gap could enhance dexterity
restoration and enable prosthetic devices to operate in more unconstrained
scenarios, where tasks are learned from demonstrations rather than relying on
manually annotated sequences. To this end, we present HannesImitationPolicy, an
imitation learning-based method to control the Hannes prosthetic hand, enabling
object grasping in unstructured environments. Moreover, we introduce the
HannesImitationDataset comprising grasping demonstrations in table, shelf, and
human-to-prosthesis handover scenarios. We leverage such data to train a single
diffusion policy and deploy it on the prosthetic hand to predict the wrist
orientation and hand closure for grasping. Experimental evaluation demonstrates
successful grasps across diverse objects and conditions. Finally, we show that
the policy outperforms a segmentation-based visual servo controller in
unstructured scenarios. Additional material is provided on our project page:
https://hsp-iit.github.io/HannesImitation

</details>


### [173] [OmniUnet: A Multimodal Network for Unstructured Terrain Segmentation on Planetary Rovers Using RGB, Depth, and Thermal Imagery](https://arxiv.org/abs/2508.00580)
*Raul Castilla-Arquillo,Carlos Perez-del-Pulgar,Levin Gerdes,Alfonso Garcia-Cerezo,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: OmniUnet是一种基于Transformer的RGB-D-T图像语义分割网络，在火星类似环境中表现优异，适合机器人部署。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的机器人导航需要多模态感知系统，而火星探索中热成像对地形安全评估尤为重要。

Method: 开发了OmniUnet，一种基于Transformer的神经网络架构，用于RGB-D-T图像的语义分割，并利用3D打印定制多模态传感器外壳收集数据。

Result: 模型在像素准确率上达到80.37%，在复杂非结构化地形分割中表现优异，推理时间平均为673毫秒。

Conclusion: OmniUnet架构在RGB-D-T图像上的语义分割表现出色，适用于资源受限的机器人部署，且其软件实现和标注数据集已公开，支持未来研究。

Abstract: Robot navigation in unstructured environments requires multimodal perception
systems that can support safe navigation. Multimodality enables the integration
of complementary information collected by different sensors. However, this
information must be processed by machine learning algorithms specifically
designed to leverage heterogeneous data. Furthermore, it is necessary to
identify which sensor modalities are most informative for navigation in the
target environment. In Martian exploration, thermal imagery has proven valuable
for assessing terrain safety due to differences in thermal behaviour between
soil types. This work presents OmniUnet, a transformer-based neural network
architecture for semantic segmentation using RGB, depth, and thermal (RGB-D-T)
imagery. A custom multimodal sensor housing was developed using 3D printing and
mounted on the Martian Rover Testbed for Autonomy (MaRTA) to collect a
multimodal dataset in the Bardenas semi-desert in northern Spain. This location
serves as a representative environment of the Martian surface, featuring
terrain types such as sand, bedrock, and compact soil. A subset of this dataset
was manually labeled to support supervised training of the network. The model
was evaluated both quantitatively and qualitatively, achieving a pixel accuracy
of 80.37% and demonstrating strong performance in segmenting complex
unstructured terrain. Inference tests yielded an average prediction time of 673
ms on a resource-constrained computer (Jetson Orin Nano), confirming its
suitability for on-robot deployment. The software implementation of the network
and the labeled dataset have been made publicly available to support future
research in multimodal terrain perception for planetary robotics.

</details>


### [174] [A control scheme for collaborative object transportation between a human and a quadruped robot using the MIGHTY suction cup](https://arxiv.org/abs/2508.00584)
*Konstantinos Plotas,Emmanouil Papadakis,Drosakis Drosakis,Panos Trahanias,Dimitrios Papageorgiou*

Main category: cs.RO

TL;DR: A passive control scheme for human-robot object transport using admittance control and barrier potential ensures object security and reduces human effort, validated by experiments.


<details>
  <summary>Details</summary>
Motivation: To improve human-robot collaboration in object transportation by increasing controllability and reducing human effort while ensuring the object remains securely attached to the robot.

Method: The control scheme is based on admittance control and incorporates a variable damping term to enhance human controllability and reduce effort. An additional control signal based on a barrier artificial potential ensures the object remains attached to the suction cup.

Result: Experimental evaluations confirm the scheme's effectiveness in maintaining object attachment and enhancing collaboration.

Conclusion: The proposed control scheme for human-robot collaborative object transportation is proven to be passive and effective, as demonstrated by experimental evaluations using the Unitree Go1 robot equipped with the MIGHTY suction cup.

Abstract: In this work, a control scheme for human-robot collaborative object
transportation is proposed, considering a quadruped robot equipped with the
MIGHTY suction cup that serves both as a gripper for holding the object and a
force/torque sensor. The proposed control scheme is based on the notion of
admittance control, and incorporates a variable damping term aiming towards
increasing the controllability of the human and, at the same time, decreasing
her/his effort. Furthermore, to ensure that the object is not detached from the
suction cup during the collaboration, an additional control signal is proposed,
which is based on a barrier artificial potential. The proposed control scheme
is proven to be passive and its performance is demonstrated through
experimental evaluations conducted using the Unitree Go1 robot equipped with
the MIGHTY suction cup.

</details>


### [175] [OpenScout v1.1 mobile robot: a case study on open hardware continuation](https://arxiv.org/abs/2508.00625)
*Bartosz Krawczyk,Ahmed Elbary,Robbie Cato,Jagdish Patil,Kaung Myat,Anyeh Ndi-Tah,Nivetha Sakthivel,Mark Crampton,Gautham Das,Charles Fox*

Main category: cs.RO

TL;DR: OpenScout v1.1是一个改进版的开源硬件移动机器人，简化了设计、降低了成本并增强了计算能力，适用于研究和工业应用。


<details>
  <summary>Details</summary>
Motivation: 为研究和工业应用提供一个更经济、更高效的开源硬件移动机器人平台。

Method: 项目通过简化硬件设计、降低成本和增强计算能力进行改进，并提供了ROS2接口和Gazebo模拟。

Result: OpenScout v1.1成功实现了硬件简化、成本降低和计算能力提升，并提供了模拟接口。

Conclusion: OpenScout v1.1的改进使其成为研究和工业应用中更具成本效益和功能强大的开源硬件移动机器人。

Abstract: OpenScout is an Open Source Hardware (OSH) mobile robot for research and
industry. It is extended to v1.1 which includes simplified, cheaper and more
powerful onboard compute hardware; a simulated ROS2 interface; and a Gazebo
simulation. Changes, their rationale, project methodology, and results are
reported as an OSH case study.

</details>


### [176] [Towards Data-Driven Adaptive Exoskeleton Assistance for Post-stroke Gait](https://arxiv.org/abs/2508.00691)
*Fabian C. Weigend,Dabin K. Choe,Santiago Canete,Conor J. Walsh*

Main category: cs.RO

TL;DR: 本研究开发了一个多任务TCN模型，用于中风后行走时的踝关节扭矩估计，验证了数据驱动方法在外骨骼控制中的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动方法在健康年轻人中已显示出对外骨骼控制的适应性，但在中风后人群中的应用面临高异质性和缺乏训练数据的挑战。本研究旨在探索数据驱动方法在中风后行走外骨骼控制中的潜力。

Method: 使用从四名中风后参与者在跑步机上行走的数据训练了一个多任务时间卷积网络（TCN），结合三个惯性测量单元（IMU）的数据，并预训练了六名健康参与者的行走数据。

Result: 模型在测试中表现出较高的准确性（R^2为0.74±0.13），并通过一个中风后参与者的实时传感、估计和驱动验证了方法的可行性。

Conclusion: 本研究通过数据驱动的方法，成功开发了一个多任务时间卷积网络（TCN），用于中风后行走时的踝关节扭矩估计，为外骨骼控制提供了实时传感、估计和驱动的可行性验证。

Abstract: Recent work has shown that exoskeletons controlled through data-driven
methods can dynamically adapt assistance to various tasks for healthy young
adults. However, applying these methods to populations with neuromotor gait
deficits, such as post-stroke hemiparesis, is challenging. This is due not only
to high population heterogeneity and gait variability but also to a lack of
post-stroke gait datasets to train accurate models. Despite these challenges,
data-driven methods offer a promising avenue for control, potentially allowing
exoskeletons to function safely and effectively in unstructured community
settings. This work presents a first step towards enabling adaptive
plantarflexion and dorsiflexion assistance from data-driven torque estimation
during post-stroke walking. We trained a multi-task Temporal Convolutional
Network (TCN) using collected data from four post-stroke participants walking
on a treadmill ($R^2$ of $0.74 \pm 0.13$). The model uses data from three
inertial measurement units (IMU) and was pretrained on healthy walking data
from 6 participants. We implemented a wearable prototype for our ankle torque
estimation approach for exoskeleton control and demonstrated the viability of
real-time sensing, estimation, and actuation with one post-stroke participant.

</details>


### [177] [On-Device Diffusion Transformer Policy for Efficient Robot Manipulation](https://arxiv.org/abs/2508.00697)
*Yiming Wu,Huan Wang,Zhenghao Chen,Jianxin Pang,Dong Xu*

Main category: cs.RO

TL;DR: LightDP 是一种专为移动设备设计的框架，通过压缩去噪模块和减少采样步骤加速扩散策略，实现了实时动作预测且性能不逊于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人操作任务中取得了显著进展，但由于计算效率低和内存占用大，其在资源受限的移动平台上的应用仍具挑战性。

Method: LightDP 通过两种核心策略加速扩散策略：对去噪模块进行网络压缩和减少所需的采样步骤。首先对现有扩散策略架构进行广泛计算分析，识别出延迟的主要来源是去噪网络。随后引入统一的剪枝和重新训练流程，明确优化模型剪枝后的恢复能力，并结合一致性蒸馏技术减少采样步骤。

Result: 实验评估表明，LightDP 在标准数据集（如 PushT、Robomimic、CALVIN 和 LIBERO）上实现了移动设备上的实时动作预测，且性能具有竞争力。

Conclusion: LightDP 成功实现了在资源有限的移动设备上实时部署扩散策略，性能与最先进的扩散策略相当，为实际应用迈出了重要一步。

Abstract: Diffusion Policies have significantly advanced robotic manipulation tasks via
imitation learning, but their application on resource-constrained mobile
platforms remains challenging due to computational inefficiency and extensive
memory footprint. In this paper, we propose LightDP, a novel framework
specifically designed to accelerate Diffusion Policies for real-time deployment
on mobile devices. LightDP addresses the computational bottleneck through two
core strategies: network compression of the denoising modules and reduction of
the required sampling steps. We first conduct an extensive computational
analysis on existing Diffusion Policy architectures, identifying the denoising
network as the primary contributor to latency. To overcome performance
degradation typically associated with conventional pruning methods, we
introduce a unified pruning and retraining pipeline, optimizing the model's
post-pruning recoverability explicitly. Furthermore, we combine pruning
techniques with consistency distillation to effectively reduce sampling steps
while maintaining action prediction accuracy. Experimental evaluations on the
standard datasets, \ie, PushT, Robomimic, CALVIN, and LIBERO, demonstrate that
LightDP achieves real-time action prediction on mobile devices with competitive
performance, marking an important step toward practical deployment of
diffusion-based policies in resource-limited environments. Extensive real-world
experiments also show the proposed LightDP can achieve performance comparable
to state-of-the-art Diffusion Policies.

</details>


### [178] [Video Generators are Robot Policies](https://arxiv.org/abs/2508.00795)
*Junbang Liang,Pavel Tokmakov,Ruoshi Liu,Sruthi Sudhakar,Paarth Shah,Rares Ambrus,Carl Vondrick*

Main category: cs.RO

TL;DR: 利用视频生成作为机器人策略学习的代理，提出Video Policy框架，显著提高鲁棒性和样本效率，并展示强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前视觉运动策略在感知或行为分布变化下的泛化能力有限，且性能受限于人类示范数据的规模。

Method: 我们提出了Video Policy，一个结合视频和动作生成的模块化框架，可以端到端训练。

Result: 我们的方法在模拟和现实世界中展示了对未见物体、背景和任务的强大泛化能力，且任务成功与生成的视频密切相关。

Conclusion: 通过利用大规模视频生成模型，我们的方法在机器人策略学习中实现了比传统行为克隆更优的性能，为更可扩展和数据高效的策略学习铺平了道路。

Abstract: Despite tremendous progress in dexterous manipulation, current visuomotor
policies remain fundamentally limited by two challenges: they struggle to
generalize under perceptual or behavioral distribution shifts, and their
performance is constrained by the size of human demonstration data. In this
paper, we use video generation as a proxy for robot policy learning to address
both limitations simultaneously. We propose Video Policy, a modular framework
that combines video and action generation that can be trained end-to-end. Our
results demonstrate that learning to generate videos of robot behavior allows
for the extraction of policies with minimal demonstration data, significantly
improving robustness and sample efficiency. Our method shows strong
generalization to unseen objects, backgrounds, and tasks, both in simulation
and the real world. We further highlight that task success is closely tied to
the generated video, with action-free video data providing critical benefits
for generalizing to novel tasks. By leveraging large-scale video generative
models, we achieve superior performance compared to traditional behavior
cloning, paving the way for more scalable and data-efficient robot policy
learning.

</details>
