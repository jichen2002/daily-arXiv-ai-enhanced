<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 122]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.OS](#cs.OS) [Total: 2]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.NI](#cs.NI) [Total: 23]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [A Context-aware Attention and Graph Neural Network-based Multimodal Framework for Misogyny Detection](https://arxiv.org/abs/2508.09175)
*Mohammad Zia Ur Rehman,Sufyaan Zahoor,Areeb Manzoor,Musharaf Maqbool,Nagendra Kumar*

Main category: cs.CV

TL;DR: 本文提出了一种新的多模态框架，用于检测社交媒体上的厌女和性别歧视内容，通过三个模块（MANM、GFRM、CFLM）结合自适应注意力、图特征重构和内容特定特征学习，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上针对女性的攻击性内容占比很大，而通用的攻击性内容检测方法在检测厌女内容方面存在挑战，因此需要针对女性的攻击性内容定制解决方案。

Method: 框架包含三个模块：多模态注意力模块（MANM）、基于图的特征重构模块（GFRM）和内容特定特征学习模块（CFLM）。MANM采用自适应门控的多模态上下文感知注意力机制，GFRM利用图结构优化单模态特征，CFLM专注于学习文本和图像的特定特征（如毒性特征和标题特征）。此外，还构建了一组厌女词汇表来计算文本的厌女词汇得分，并在特征空间应用测试时增强以提高泛化能力。

Result: 在MAMI和MMHS150K数据集上，该方法分别实现了10.17%和8.88%的宏观F1平均提升。

Conclusion: 提出的多模态框架在检测针对女性的攻击性内容方面表现出色，相较于现有方法在MAMI和MMHS150K数据集上分别实现了10.17%和8.88%的宏观F1平均提升。

Abstract: A substantial portion of offensive content on social media is directed
towards women. Since the approaches for general offensive content detection
face a challenge in detecting misogynistic content, it requires solutions
tailored to address offensive content against women. To this end, we propose a
novel multimodal framework for the detection of misogynistic and sexist
content. The framework comprises three modules: the Multimodal Attention module
(MANM), the Graph-based Feature Reconstruction Module (GFRM), and the
Content-specific Features Learning Module (CFLM). The MANM employs adaptive
gating-based multimodal context-aware attention, enabling the model to focus on
relevant visual and textual information and generating contextually relevant
features. The GFRM module utilizes graphs to refine features within individual
modalities, while the CFLM focuses on learning text and image-specific features
such as toxicity features and caption features. Additionally, we curate a set
of misogynous lexicons to compute the misogyny-specific lexicon score from the
text. We apply test-time augmentation in feature space to better generalize the
predictions on diverse inputs. The performance of the proposed approach has
been evaluated on two multimodal datasets, MAMI and MMHS150K, with 11,000 and
13,494 samples, respectively. The proposed method demonstrates an average
improvement of 10.17% and 8.88% in macro-F1 over existing methods on the MAMI
and MMHS150K datasets, respectively.

</details>


### [2] [IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection](https://arxiv.org/abs/2508.09178)
*Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang*

Main category: cs.CV

TL;DR: IAD-R1是一种通用后训练框架，通过两阶段训练策略显著提升视觉语言模型在工业异常检测中的性能，实验证明其有效性和优越性。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测中缺陷样本稀缺限制了传统方法的泛化能力，而现有视觉语言模型（VLMs）的性能仍有不足，因此提出IAD-R1框架以提升VLMs的异常检测能力。

Method: IAD-R1采用两阶段训练策略：第一阶段（PA-SFT）使用高质量Chain-of-Thought数据集（Expert-AD）进行监督微调，增强异常感知能力；第二阶段（SC-GRPO）通过精心设计的奖励函数实现从‘异常感知’到‘异常解释’的能力跃升。

Result: 实验结果表明，IAD-R1在7种VLMs上实现了显著提升，在6个工业异常检测基准数据集上的平均准确率最高提升43.3%。0.5B参数模型在零样本设置下超越多个商业模型。

Conclusion: IAD-R1框架显著提升了多种视觉语言模型（VLMs）在工业异常检测中的性能，甚至在零样本设置下超越了包括GPT-4.1和Claude-Sonnet-4在内的商业模型，证明了其有效性和优越性。数据集、代码和模型权重将公开。

Abstract: Industrial anomaly detection is a critical component of modern manufacturing,
yet the scarcity of defective samples restricts traditional detection methods
to scenario-specific applications. Although Vision-Language Models (VLMs)
demonstrate significant advantages in generalization capabilities, their
performance in industrial anomaly detection remains limited. To address this
challenge, we propose IAD-R1, a universal post-training framework applicable to
VLMs of different architectures and parameter scales, which substantially
enhances their anomaly detection capabilities. IAD-R1 employs a two-stage
training strategy: the Perception Activation Supervised Fine-Tuning (PA-SFT)
stage utilizes a meticulously constructed high-quality Chain-of-Thought dataset
(Expert-AD) for training, enhancing anomaly perception capabilities and
establishing reasoning-to-answer correlations; the Structured Control Group
Relative Policy Optimization (SC-GRPO) stage employs carefully designed reward
functions to achieve a capability leap from "Anomaly Perception" to "Anomaly
Interpretation". Experimental results demonstrate that IAD-R1 achieves
significant improvements across 7 VLMs, attaining up to 43.3% enhancement in
average accuracy on 6 industrial anomaly detection benchmark datasets. Notably,
the 0.5B parameter model trained with IAD-R1 surpasses commercial models
including GPT-4.1 and Claude-Sonnet-4 in zero-shot settings, demonstrating the
effectiveness and superiority of IAD-R1. The dataset, code, and all model
weights will be publicly available at https://github.com/Yanhui-Lee/IAD-R1.

</details>


### [3] [RayletDF: Raylet Distance Fields for Generalizable 3D Surface Reconstruction from Point Clouds or Gaussians](https://arxiv.org/abs/2508.09830)
*Shenxing Wei,Jinxi Li,Yafei Yang,Siyuan Zhou,Bo Yang*

Main category: cs.CV

TL;DR: 提出RayletDF方法，通过射线距离场直接预测表面点，实现高效且通用的3D表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有基于坐标的方法在渲染显式表面时计算密集，因此需要一种更高效且通用的3D表面重建方法。

Method: 提出了RayletDF方法，包括三个关键模块：raylet特征提取器、raylet距离场预测器和多raylet混合器，用于从查询射线直接预测表面点。

Result: 在多个公共真实世界数据集上评估，显示从点云或3D高斯重建表面的优越性能。

Conclusion: RayletDF方法在3D表面重建方面表现出色，特别是在泛化能力上，能够通过单次前向传播在未见过的测试数据集中成功重建3D表面。

Abstract: In this paper, we present a generalizable method for 3D surface
reconstruction from raw point clouds or pre-estimated 3D Gaussians by 3DGS from
RGB images. Unlike existing coordinate-based methods which are often
computationally intensive when rendering explicit surfaces, our proposed
method, named RayletDF, introduces a new technique called raylet distance
field, which aims to directly predict surface points from query rays. Our
pipeline consists of three key modules: a raylet feature extractor, a raylet
distance field predictor, and a multi-raylet blender. These components work
together to extract fine-grained local geometric features, predict raylet
distances, and aggregate multiple predictions to reconstruct precise surface
points. We extensively evaluate our method on multiple public real-world
datasets, demonstrating superior performance in surface reconstruction from
point clouds or 3D Gaussians. Most notably, our method achieves exceptional
generalization ability, successfully recovering 3D surfaces in a single-forward
pass across unseen datasets in testing.

</details>


### [4] [A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality](https://arxiv.org/abs/2508.09185)
*Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan*

Main category: cs.CV

TL;DR: CADAR是一种神经符号方法，通过融合视觉-语言输入和粒子滤波推理，显著提升AR认知攻击检测的精度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有AR认知攻击检测方法局限于像素/图像级处理或依赖黑盒预训练模型，缺乏语义推理能力和可解释性。

Method: CADAR采用神经符号方法，融合多模态视觉-语言输入生成符号感知图，结合先验知识、显著权重和时间相关性，利用粒子滤波进行统计推理。

Result: 在扩展的AR认知攻击数据集上，CADAR比基线方法精度提升高达10.7%。

Conclusion: CADAR结合了神经符号方法，通过粒子滤波统计推理实现了高精度和可解释性的认知攻击检测，展示了神经符号方法在AR认知攻击检测中的潜力。

Abstract: Augmented Reality (AR) enriches perception by overlaying virtual elements on
the physical world. Due to its growing popularity, cognitive attacks that alter
AR content to manipulate users' semantic perception have received increasing
attention. Existing detection methods often focus on visual changes, which are
restricted to pixel- or image-level processing and lack semantic reasoning
capabilities, or they rely on pre-trained vision-language models (VLMs), which
function as black-box approaches with limited interpretability. In this paper,
we present CADAR, a novel neurosymbolic approach for cognitive attack detection
in AR. It fuses multimodal vision-language inputs using neural VLMs to obtain a
symbolic perception-graph representation, incorporating prior knowledge,
salience weighting, and temporal correlations. The model then enables
particle-filter based statistical reasoning -- a sequential Monte Carlo method
-- to detect cognitive attacks. Thus, CADAR inherits the adaptability of
pre-trained VLM and the interpretability and reasoning rigor of particle
filtering. Experiments on an extended AR cognitive attack dataset show accuracy
improvements of up to 10.7% over strong baselines on challenging AR attack
scenarios, underscoring the promise of neurosymbolic methods for effective and
interpretable cognitive attack detection.

</details>


### [5] [Story2Board: A Training-Free Approach for Expressive Storyboard Generation](https://arxiv.org/abs/2508.09983)
*David Dinkevich,Matan Levy,Omri Avrahami,Dvir Samuel,Dani Lischinski*

Main category: cs.CV

TL;DR: Story2Board是一个无需训练的框架，通过创新的一致性机制和现有扩散模型生成视觉多样且连贯的故事板，显著提升叙事效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于关注主体身份，忽略了空间构图、背景演变和叙事节奏等视觉叙事关键方面。

Method: 引入Latent Panel Anchoring和Reciprocal Attention Value Mixing两种机制，结合预训练扩散模型和语言模型，生成连贯且视觉多样的故事板。

Result: 在Rich Storyboard Benchmark上的定性和定量评估及用户研究表明，Story2Board生成的故事板在动态性、连贯性和叙事吸引力上优于现有方法。

Conclusion: Story2Board框架通过其轻量级一致性框架和创新的视觉特征混合机制，无需微调即可生成视觉多样且连贯的故事板，显著优于现有基线方法。

Abstract: We present Story2Board, a training-free framework for expressive storyboard
generation from natural language. Existing methods narrowly focus on subject
identity, overlooking key aspects of visual storytelling such as spatial
composition, background evolution, and narrative pacing. To address this, we
introduce a lightweight consistency framework composed of two components:
Latent Panel Anchoring, which preserves a shared character reference across
panels, and Reciprocal Attention Value Mixing, which softly blends visual
features between token pairs with strong reciprocal attention. Together, these
mechanisms enhance coherence without architectural changes or fine-tuning,
enabling state-of-the-art diffusion models to generate visually diverse yet
consistent storyboards. To structure generation, we use an off-the-shelf
language model to convert free-form stories into grounded panel-level prompts.
To evaluate, we propose the Rich Storyboard Benchmark, a suite of open-domain
narratives designed to assess layout diversity and background-grounded
storytelling, in addition to consistency. We also introduce a new Scene
Diversity metric that quantifies spatial and pose variation across storyboards.
Our qualitative and quantitative results, as well as a user study, show that
Story2Board produces more dynamic, coherent, and narratively engaging
storyboards than existing baselines.

</details>


### [6] [RL-MoE: An Image-Based Privacy Preserving Approach In Intelligent Transportation System](https://arxiv.org/abs/2508.09186)
*Abdolazim Rezaei,Mehdi Sookhak,Mahboobeh Haghparast*

Main category: cs.CV

TL;DR: RL-MoE 是一种将敏感视觉数据转换为隐私保护文本描述的新框架，结合MoE和RL，显著提升隐私保护和数据实用性。


<details>
  <summary>Details</summary>
Motivation: 解决智能交通系统中AI摄像头在丰富视觉数据需求和隐私权保护之间的冲突，现有隐私保护机制（如模糊或加密）不足的问题。

Method: RL-MoE 结合了混合专家（MoE）架构和强化学习（RL）代理，用于多方面的场景分解和优化生成的文本，以实现语义准确性和隐私保护的双重目标。

Result: RL-MoE 提供了卓越的隐私保护，将重放攻击成功率降至9.4%，同时生成的文本内容比基线方法更丰富。

Conclusion: RL-MoE 提供了一种实用且可扩展的解决方案，用于在隐私敏感领域构建可信赖的AI系统，为更安全的智慧城市和自动驾驶车辆网络铺平了道路。

Abstract: The proliferation of AI-powered cameras in Intelligent Transportation Systems
(ITS) creates a severe conflict between the need for rich visual data and the
fundamental right to privacy. Existing privacy-preserving mechanisms, such as
blurring or encryption, are often insufficient, creating an undesirable
trade-off where either privacy is compromised against advanced reconstruction
attacks or data utility is critically degraded. To resolve this impasse, we
propose RL-MoE, a novel framework that transforms sensitive visual data into
privacy-preserving textual descriptions, eliminating the need for direct image
transmission. RL-MoE uniquely combines a Mixture-of-Experts (MoE) architecture
for nuanced, multi-aspect scene decomposition with a Reinforcement Learning
(RL) agent that optimizes the generated text for a dual objective of semantic
accuracy and privacy preservation. Extensive experiments demonstrate that
RL-MoE provides superior privacy protection, reducing the success rate of
replay attacks to just 9.4\% on the CFP-FP dataset, while simultaneously
generating richer textual content than baseline methods. Our work provides a
practical and scalable solution for building trustworthy AI systems in
privacy-sensitive domains, paving the way for more secure smart city and
autonomous vehicle networks.

</details>


### [7] [Synthetic Data Generation for Emotional Depth Faces: Optimizing Conditional DCGANs via Genetic Algorithms in the Latent Space and Stabilizing Training with Knowledge Distillation](https://arxiv.org/abs/2508.09188)
*Seyed Muhammad Hossein Mousavi,S. Younes Mirinezhad*

Main category: cs.CV

TL;DR: 利用优化GAN和遗传算法生成高质量深度面部数据，提升情感识别准确率至96%。


<details>
  <summary>Details</summary>
Motivation: 解决情感计算领域缺乏高质量、多样化深度面部数据集的挑战，以识别细微的情感表达。

Method: 采用优化的GAN框架，结合知识蒸馏（EMA教师模型）和遗传算法来生成合成深度面部数据，并通过特征提取和XGBoost分类器进行情感识别。

Result: 在多样性和质量上优于GAN、VAE、GMM和KDE，分类准确率达到94%和96%。评估指标（FID、IS、SSIM、PSNR）显示优于现有方法。

Conclusion: 该研究通过优化的GAN结合知识蒸馏和遗传算法，成功生成了高质量且多样化的深度面部数据集，显著提升了情感识别的准确性。

Abstract: Affective computing faces a major challenge: the lack of high-quality,
diverse depth facial datasets for recognizing subtle emotional expressions. We
propose a framework for synthetic depth face generation using an optimized GAN
with Knowledge Distillation (EMA teacher models) to stabilize training, improve
quality, and prevent mode collapse. We also apply Genetic Algorithms to evolve
GAN latent vectors based on image statistics, boosting diversity and visual
quality for target emotions. The approach outperforms GAN, VAE, GMM, and KDE in
both diversity and quality. For classification, we extract and concatenate LBP,
HOG, Sobel edge, and intensity histogram features, achieving 94% and 96%
accuracy with XGBoost. Evaluation using FID, IS, SSIM, and PSNR shows
consistent improvement over state-of-the-art methods.

</details>


### [8] [$Δ$-AttnMask: Attention-Guided Masked Hidden States for Efficient Data Selection and Augmentation](https://arxiv.org/abs/2508.09199)
*Jucheng Hu,Suorong Yang,Dongzhan Zhou*

Main category: cs.CV

TL;DR: Δ-AttnMask 是一种无需额外训练的数据选择框架，通过注意力掩码量化样本质量，显著提升 VLM 微调效率和性能。


<details>
  <summary>Details</summary>
Motivation: 视觉指令微调（VIF）需要多模态数据以支持视觉和文本的联合理解，但现有方法在数据选择上存在挑战，缺乏高效且质量保证的方案。

Method: 提出 Δ-AttnMask 框架，通过计算原始状态与高注意力区域掩码状态之间的损失差异（Δ）来评估样本质量。

Result: 实验表明，Δ-AttnMask 仅需 20% 的数据即可达到最先进性能，训练速度提升 5 倍，整体准确率比全数据集基线高 +10.1%。

Conclusion: Δ-AttnMask 是一种高效的数据选择框架，通过注意力引导的隐藏状态掩码量化样本质量，无需域标签、辅助模型或额外训练，显著提升了视觉语言模型（VLMs）的微调效率和性能。

Abstract: Visual Instruction Finetuning (VIF) is pivotal for post-training
Vision-Language Models (VLMs). Unlike unimodal instruction finetuning in
plain-text large language models, which mainly requires instruction datasets to
enable model instruction-following ability, VIF also requires multimodal data
to enable joint visual and textual understanding; therefore, it typically
requires more data. Consequently, VIF imposes stricter data selection
challenges: the method must scale efficiently to handle larger data demands
while ensuring the quality of both visual and textual content, as well as their
alignment. Despite its critical impact on performance, data selection for VIF
remains an understudied area. In this paper, we propose $\Delta$-AttnMask. This
data-efficient framework quantifies sample quality through attention-guided
masking of the model's hidden states, jointly evaluating image-text pairs
without requiring domain labels, auxiliary models, or extra training. By
computing loss differences ($\Delta$) between the original states and states
masked using high-attention regions, $\Delta$-AttnMask intrinsically assesses
sample quality. Experiments across multiple VLMs and datasets show that
$\Delta$-AttnMask achieves state-of-the-art performance with just 20% of data,
accelerating training by 5x while surpassing full-dataset baselines by +10.1%
in overall accuracy. Its model-agnostic and data-agnostic design ensures broad
applicability across modalities and architectures.

</details>


### [9] [Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method](https://arxiv.org/abs/2508.09202)
*Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger*

Main category: cs.CV

TL;DR: 论文提出PFT方法，通过在潜在空间中进行轻量级特征翻译，解决了SFDA中单一类别目标数据适应的问题，避免了图像合成的复杂性和计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的SFDA方法通常不适用于仅包含单一类别（如中性表情）的目标数据，且基于图像生成的方法存在不稳定性和高计算成本的问题。因此，需要一种更高效、稳定的方法来适应无源数据域。

Method: PFT方法首先在源域数据上预训练翻译器，以转换主题特定的风格特征，同时通过优化表情一致性和风格感知目标来保留表情信息。随后，翻译器仅使用中性目标数据进行适应，无需源数据或图像合成。

Result: PFT在潜在空间中进行特征翻译，避免了复杂的面部表情生成过程，生成了优化的判别性嵌入，显著提高了分类性能，同时降低了计算开销。

Conclusion: 论文提出了一种名为个性化特征翻译（PFT）的轻量级方法，用于无源数据域适应（SFDA）。通过在潜在空间中进行特征翻译，PFT避免了面部表情生成的复杂性和噪声，同时减少了计算开销，提高了分类性能。

Abstract: Facial expression recognition (FER) models are employed in many video-based
affective computing applications, such as human-computer interaction and
healthcare monitoring. However, deep FER models often struggle with subtle
expressions and high inter-subject variability, limiting their performance in
real-world applications. To improve their performance, source-free domain
adaptation (SFDA) methods have been proposed to personalize a pretrained source
model using only unlabeled target domain data, thereby avoiding data privacy,
storage, and transmission constraints. This paper addresses a challenging
scenario where source data is unavailable for adaptation, and only unlabeled
target data consisting solely of neutral expressions is available. SFDA methods
are not typically designed to adapt using target data from only a single class.
Further, using models to generate facial images with non-neutral expressions
can be unstable and computationally intensive. In this paper, personalized
feature translation (PFT) is proposed for SFDA. Unlike current image
translation methods for SFDA, our lightweight method operates in the latent
space. We first pre-train the translator on the source domain data to transform
the subject-specific style features from one source subject into another.
Expression information is preserved by optimizing a combination of expression
consistency and style-aware objectives. Then, the translator is adapted on
neutral target data, without using source data or image synthesis. By
translating in the latent space, PFT avoids the complexity and noise of face
expression generation, producing discriminative embeddings optimized for
classification. Using PFT eliminates the need for image synthesis, reduces
computational overhead (using a lightweight translator), and only adapts part
of the model, making the method efficient compared to image-based translation.

</details>


### [10] [GANime: Generating Anime and Manga Character Drawings from Sketches with Deep Learning](https://arxiv.org/abs/2508.09207)
*Tai Vu,Robert Yang*

Main category: cs.CV

TL;DR: 研究比较了几种图像转换模型，发现C-GAN能最有效地将动漫草图转化为高质量彩色图像。


<details>
  <summary>Details</summary>
Motivation: 动漫和漫画行业中，从草图生成全彩图像的流程通常成本高昂且耗时，研究旨在寻找更高效的解决方案。

Method: 研究比较了多种图像到图像转换模型，包括神经风格迁移（Neural Style Transfer）、C-GAN和CycleGAN，并通过定性和定量评估它们的表现。

Result: C-GAN在生成接近人工绘制的高质量图像方面表现最佳。

Conclusion: C-GAN被证明是生成高质量、高分辨率彩色动漫图像的最有效模型，其效果接近人工绘制。

Abstract: The process of generating fully colorized drawings from sketches is a large,
usually costly bottleneck in the manga and anime industry. In this study, we
examine multiple models for image-to-image translation between anime characters
and their sketches, including Neural Style Transfer, C-GAN, and CycleGAN. By
assessing them qualitatively and quantitatively, we find that C-GAN is the most
effective model that is able to produce high-quality and high-resolution images
close to those created by humans.

</details>


### [11] [MME-Emotion: A Holistic Evaluation Benchmark for Emotional Intelligence in Multimodal Large Language Models](https://arxiv.org/abs/2508.09210)
*Fan Zhang,Zebang Cheng,Chong Deng,Haoxuan Li,Zheng Lian,Qian Chen,Huadai Liu,Wen Wang,Yi-Fan Zhang,Renrui Zhang,Ziyu Guo,Zhihong Zhu,Hao Wu,Haixin Wang,Yefeng Zheng,Xiaojiang Peng,Xian Wu,Kun Wang,Xiangang Li,Jieping Ye,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: MME-Emotion是一个系统性基准，用于评估多模态大语言模型的情感知理解和推理能力。通过对20个模型的评估，发现当前MLLMs情感智能表现不佳，通用和专业模型各有优势。


<details>
  <summary>Details</summary>
Motivation: 当前的情感基准存在局限性，特别是在MLLMs的泛化能力和识别情绪触发因素的推理能力方面。为了填补这些空白，作者开发了MME-Emotion基准。

Method: 作者提出了MME-Emotion，一个系统性的基准，用于评估MLLMs的情感知理解和推理能力。该基准包含超过6,000个精选视频片段，涵盖广泛场景，形成八个情感任务，并采用混合指标进行情感识别和推理的全方位评估。

Result: 对20个先进MLLMs的严格评估揭示了它们的优势和局限性：当前MLLMs的情感智能表现不理想，最佳模型的识别得分仅为39.3%，Chain-of-Thought（CoT）得分为56.0%。通用模型（如Gemini-2.5-Pro）通过广义多模态理解能力获得情感智能，而专业模型（如R1-Omni）通过领域特定的后训练适应可以达到可比性能。

Conclusion: 通过引入MME-Emotion基准，作者希望它能作为未来提升多模态大语言模型（MLLMs）情感智能的基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have catalyzed
transformative progress in affective computing, enabling models to exhibit
emergent emotional intelligence. Despite substantial methodological progress,
current emotional benchmarks remain limited, as it is still unknown: (a) the
generalization abilities of MLLMs across distinct scenarios, and (b) their
reasoning capabilities to identify the triggering factors behind emotional
states. To bridge these gaps, we present \textbf{MME-Emotion}, a systematic
benchmark that assesses both emotional understanding and reasoning capabilities
of MLLMs, enjoying \textit{scalable capacity}, \textit{diverse settings}, and
\textit{unified protocols}. As the largest emotional intelligence benchmark for
MLLMs, MME-Emotion contains over 6,000 curated video clips with task-specific
questioning-answering (QA) pairs, spanning broad scenarios to formulate eight
emotional tasks. It further incorporates a holistic evaluation suite with
hybrid metrics for emotion recognition and reasoning, analyzed through a
multi-agent system framework. Through a rigorous evaluation of 20 advanced
MLLMs, we uncover both their strengths and limitations, yielding several key
insights: \ding{182} Current MLLMs exhibit unsatisfactory emotional
intelligence, with the best-performing model achieving only $39.3\%$
recognition score and $56.0\%$ Chain-of-Thought (CoT) score on our benchmark.
\ding{183} Generalist models (\emph{e.g.}, Gemini-2.5-Pro) derive emotional
intelligence from generalized multimodal understanding capabilities, while
specialist models (\emph{e.g.}, R1-Omni) can achieve comparable performance
through domain-specific post-training adaptation. By introducing MME-Emotion,
we hope that it can serve as a foundation for advancing MLLMs' emotional
intelligence in the future.

</details>


### [12] [Towards Effective MLLM Jailbreaking Through Balanced On-Topicness and OOD-Intensity](https://arxiv.org/abs/2508.09218)
*Zuoou Li,Weitong Zhang,Jingyuan Wang,Shuyuan Zhang,Wenjia Bai,Bernhard Kainz,Mengyun Qiao*

Main category: cs.CV

TL;DR: 研究提出四轴评估框架和BSD策略，揭示多模态大语言模型安全漏洞，显著提升攻击效果。


<details>
  <summary>Details</summary>
Motivation: 现有的评估标准可能高估了对抗性提示的攻击效果，需要更精确的评估框架来识别真正有效的越狱策略。

Method: 引入了一个四轴评估框架，并开发了一种称为平衡结构分解（BSD）的递归重写策略。

Result: BSD在13个商业和开源MLLMs中测试，攻击成功率提高了67%，输出危害性提高了21%。

Conclusion: BSD方法在多模态大语言模型的安全系统中揭示了一个未被充分认识的弱点，显著提高了攻击成功率和输出危害性。

Abstract: Multimodal large language models (MLLMs) are widely used in vision-language
reasoning tasks. However, their vulnerability to adversarial prompts remains a
serious concern, as safety mechanisms often fail to prevent the generation of
harmful outputs. Although recent jailbreak strategies report high success
rates, many responses classified as "successful" are actually benign, vague, or
unrelated to the intended malicious goal. This mismatch suggests that current
evaluation standards may overestimate the effectiveness of such attacks. To
address this issue, we introduce a four-axis evaluation framework that
considers input on-topicness, input out-of-distribution (OOD) intensity, output
harmfulness, and output refusal rate. This framework identifies truly effective
jailbreaks. In a substantial empirical study, we reveal a structural trade-off:
highly on-topic prompts are frequently blocked by safety filters, whereas those
that are too OOD often evade detection but fail to produce harmful content.
However, prompts that balance relevance and novelty are more likely to evade
filters and trigger dangerous output. Building on this insight, we develop a
recursive rewriting strategy called Balanced Structural Decomposition (BSD).
The approach restructures malicious prompts into semantically aligned
sub-tasks, while introducing subtle OOD signals and visual cues that make the
inputs harder to detect. BSD was tested across 13 commercial and open-source
MLLMs, where it consistently led to higher attack success rates, more harmful
outputs, and fewer refusals. Compared to previous methods, it improves success
rates by $67\%$ and harmfulness by $21\%$, revealing a previously
underappreciated weakness in current multimodal safety systems.

</details>


### [13] [ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images](https://arxiv.org/abs/2508.09849)
*Jan Phillipp Albrecht,Jose R. A. Godinho,Christina Hübers,Deborah Schmidt*

Main category: cs.CV

TL;DR: ARI3D是一款交互式软件工具，旨在解决X射线CT图像中的成像伪影问题，改进微结构的分类和量化分析。


<details>
  <summary>Details</summary>
Motivation: X射线CT是材料内部微结构成像的主要3D技术，但成像伪影（如束硬化和部分体积效应）使得微结构的定量分析具有挑战性，需要用户基于体素灰度值做出多项决策。

Method: 提出了一种名为ARI3D的软件工具，通过设计协议辅助用户在三维图像中对区域进行分类和量化，解决了成像伪影（如束硬化和部分体积效应）带来的挑战。

Result: ARI3D工具能够改进相位识别、处理部分体积效应、提高物体量化的检测限和准确性，并实现跨领域的标准化定量3D分析。

Conclusion: ARI3D软件工具通过交互式分析三维X射线CT图像中的区域，改进了相位识别、处理了部分体积效应、提高了物体量化的检测限和准确性，并实现了跨科学领域的标准化定量3D分析。

Abstract: X-ray computed tomography (CT) is the main 3D technique for imaging the
internal microstructures of materials. Quantitative analysis of the
microstructures is usually achieved by applying a sequence of steps that are
implemented to the entire 3D image. This is challenged by various imaging
artifacts inherent from the technique, e.g., beam hardening and partial volume.
Consequently, the analysis requires users to make a number of decisions to
segment and classify the microstructures based on the voxel gray-values. In
this context, a software tool, here called ARI3D, is proposed to interactively
analyze regions in three-dimensional X-ray CT images, assisting users through
the various steps of a protocol designed to classify and quantify objects
within regions of a three-dimensional image. ARI3D aims to 1) Improve phase
identification; 2) Account for partial volume effect; 3) Increase the detection
limit and accuracy of object quantification; and 4) Harmonize quantitative 3D
analysis that can be implemented in different fields of science.

</details>


### [14] [Towards Scalable Training for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2508.09220)
*Haoyang Li,Jiaqing Li,Jialun Cao,Zongyuan Yang,Yongping Xiong*

Main category: cs.CV

TL;DR: 论文提出TexTeller模型，通过整合手写和LaTeX公式数据，构建了最大数据集Tex80M，实现了HMER领域的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 手写数学表达式识别（HMER）领域因数据稀缺（主要由于手动标注过程费时费力）而受到阻碍，需要一种新方法来填补这一空白。

Method: 提出了一种可扩展的数据引擎，用于生成复杂且一致的LaTeX序列，并构建了包含8000万高质量训练实例的Tex80M数据集。通过混合训练Tex80M与较小的HME数据集，开发了TexTeller模型。

Result: TexTeller模型在几乎所有基准测试中均达到了最先进的性能。

Conclusion: 论文提出了一种通过整合有限手写公式和大规模LaTeX渲染公式的新方法，构建了迄今为止最大的公式数据集Tex80M，并开发了首个大规模训练的HMER模型TexTeller，实现了最先进的性能。

Abstract: Large foundation models have achieved significant performance gains through
scalable training on massive datasets. However, the field of
\textbf{H}andwritten \textbf{M}athematical \textbf{E}xpression
\textbf{R}ecognition (HMER) has been impeded by the scarcity of data, primarily
due to the arduous and costly process of manual annotation. To bridge this gap,
we propose a novel method integrating limited handwritten formulas with
large-scale LaTeX-rendered formulas by developing a scalable data engine to
generate complex and consistent LaTeX sequences. With this engine, we built the
largest formula dataset to date, termed \texttt{Tex80M}, comprising over 80
million high-quality training instances. Then we propose \texttt{TexTeller},
the first HMER model trained at scale, by mix-training \texttt{Tex80M} with a
relatively small HME dataset. The expansive training dataset and our refined
pipeline have equipped \texttt{TexTeller} with state-of-the-art (SOTA)
performance across nearly all benchmarks. To advance the field, we will openly
release our complete model, entire dataset, and full codebase, enabling further
research building upon our contributions.

</details>


### [15] [Gradient-Direction-Aware Density Control for 3D Gaussian Splatting](https://arxiv.org/abs/2508.09239)
*Zheng Zhou,Yu-Jie Xiong,Chun-Ming Xia,Jia-Chen Zhang,Hong-Jian Zhan*

Main category: cs.CV

TL;DR: GDAGS通过梯度方向感知的密度控制框架，解决了3D高斯泼溅中的过重建和过密集问题，显著提升了渲染质量并减少了内存消耗。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅方法在复杂场景中存在过重建和过密集问题，导致内存开销增加和渲染质量下降。

Method: 提出梯度一致性比率（GCR）和非线性动态加权机制，实现梯度方向感知的密度控制，优先处理冲突梯度高斯以增强几何细节，同时抑制冗余一致性梯度高斯。

Result: GDAGS在多样化真实世界基准测试中表现出色，实现了更高的渲染质量，同时减少了内存消耗。

Conclusion: GDAGS通过梯度方向感知的自适应密度控制框架，有效解决了3D高斯泼溅中的过重建和过密集问题，显著提升了渲染质量并减少了50%的内存消耗。

Abstract: The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced
novel view synthesis through explicit scene representation, enabling real-time
photorealistic rendering. However, existing approaches manifest two critical
limitations in complex scenarios: (1) Over-reconstruction occurs when
persistent large Gaussians cannot meet adaptive splitting thresholds during
density control. This is exacerbated by conflicting gradient directions that
prevent effective splitting of these Gaussians; (2) Over-densification of
Gaussians occurs in regions with aligned gradient aggregation, leading to
redundant component proliferation. This redundancy significantly increases
memory overhead due to unnecessary data retention. We present
Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware
adaptive density control framework to address these challenges. Our key
innovations: the gradient coherence ratio (GCR), computed through normalized
gradient vector norms, which explicitly discriminates Gaussians with concordant
versus conflicting gradient directions; and a nonlinear dynamic weighting
mechanism leverages the GCR to enable gradient-direction-aware density control.
Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting
operations to enhance geometric details while suppressing redundant
concordant-direction Gaussians. Conversely, in cloning processes, GDAGS
promotes concordant-direction Gaussian densification for structural completion
while preventing conflicting-direction Gaussian overpopulation. Comprehensive
evaluations across diverse real-world benchmarks demonstrate that GDAGS
achieves superior rendering quality while effectively mitigating
over-reconstruction, suppressing over-densification, and constructing compact
scene representations with 50\% reduced memory consumption through optimized
Gaussians utilization.

</details>


### [16] [FineState-Bench: A Comprehensive Benchmark for Fine-Grained State Control in GUI Agents](https://arxiv.org/abs/2508.09241)
*Fengxian Ji,Jingpu Yang,Zirui Song,Yuanxi Wang,Zhexuan Cui,Yuke Li,Qian Jiang,Miao Fang,Xiuying Chen*

Main category: cs.CV

TL;DR: 提出了FineState-Bench评估框架和VDA工具，首次量化了GUI代理的细粒度控制能力，发现视觉定位是主要瓶颈。


<details>
  <summary>Details</summary>
Motivation: 现有的GUI代理评估框架过于关注粗粒度任务完成度，而忽视了细粒度控制能力，这在现实应用中至关重要。

Method: 引入了FineState-Bench，一个多平台（桌面、网页、移动端）的评估框架，包含2257个任务基准和四阶段指标，用于全面评估从感知到控制的能力。开发了视觉诊断助手（VDA）进行定量解耦分析。

Result: 实验结果显示，最先进的模型在细粒度交互准确率上仅达到32.8%。使用VDA后，理想视觉定位使Gemini-2.5-Flash的成功率提升了14.9%。

Conclusion: 当前图形用户界面（GUI）代理的主要瓶颈在于基本的视觉定位能力，理想的视觉定位可以显著提升任务成功率。

Abstract: With the rapid advancement of generative artificial intelligence technology,
Graphical User Interface (GUI) agents have demonstrated tremendous potential
for autonomously managing daily tasks through natural language instructions.
However, current evaluation frameworks for GUI agents suffer from fundamental
flaws: existing benchmarks overly focus on coarse-grained task completion while
neglecting fine-grained control capabilities crucial for real-world
applications. To address this, we introduce FineState-Bench, the first
evaluation and diagnostic standard for fine-grained GUI proxy operations,
designed to quantify fine-grained control. This multi-platform (desktop, Web,
mobile) framework includes 2257 task benchmarks in four components and uses a
four-phase indicator for comprehensive perception-to-control assessment. To
analyze perception and positioning for refined operations, we developed the
plug-and-play Visual Diagnostic Assistant (VDA), enabling the first
quantitative decoupling analysis of these capabilities. Experimental results on
our benchmark show that the most advanced models achieve only 32.8%
fine-grained interaction accuracy. Using our VDA in controlled experiments,
quantifying the impact of visual capabilities, we showed that ideal visual
localization boosts Gemini-2.5-Flash's success rate by 14.9\%. Our diagnostic
framework confirms for the first time that the primary bottleneck for current
GUI proxies is basic visual positioning capability.All resources are fully
open-source. github: https://github.com/AnonymousThewarehouse/FineState-Bench
huggingface: https://huggingface.co/datasets/Willtime2006/Static-FineBench

</details>


### [17] [Beyond Blanket Masking: Examining Granularity for Privacy Protection in Images Captured by Blind and Low Vision Users](https://arxiv.org/abs/2508.09245)
*Jeffri Murrugarra-LLerena,Haoran Niu,K. Suzanne Barber,Hal Daumé III,Yang Trista Cao,Paola Cascante-Bonilla*

Main category: cs.CV

TL;DR: FiGPriv提出了一种细粒度隐私保护框架，通过选择性屏蔽高风险隐私信息，显著提升了视觉辅助系统的可用性和隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐私保护方法因粗粒度分割导致的图像内容过度掩蔽问题，提升视觉辅助系统的可用性。

Method: 结合细粒度分割与数据驱动的风险评分机制，选择性屏蔽高风险隐私信息。

Result: 在BIV-Priv-Seg数据集上，FiGPriv保留了26%的图像内容，使VLM的响应有用性提升11%，内容识别能力提高45%。

Conclusion: FiGPriv框架通过细粒度隐私保护，在确保隐私的同时显著提升了视觉语言模型的可用性和内容识别能力。

Abstract: As visual assistant systems powered by visual language models (VLMs) become
more prevalent, concerns over user privacy have grown, particularly for blind
and low vision users who may unknowingly capture personal private information
in their images. Existing privacy protection methods rely on coarse-grained
segmentation, which uniformly masks entire private objects, often at the cost
of usability. In this work, we propose FiGPriv, a fine-grained privacy
protection framework that selectively masks only high-risk private information
while preserving low-risk information. Our approach integrates fine-grained
segmentation with a data-driven risk scoring mechanism. We evaluate our
framework using the BIV-Priv-Seg dataset and show that FiG-Priv preserves +26%
of image content, enhancing the ability of VLMs to provide useful responses by
11% and identify the image content by 45%, while ensuring privacy protection.
Project Page: https://artcs1.github.io/VLMPrivacy/

</details>


### [18] [Harnessing Input-Adaptive Inference for Efficient VLN](https://arxiv.org/abs/2508.09262)
*Dongwoo Kang,Akhil Perincherry,Zachary Coalson,Aiden Gabriel,Stefan Lee,Sanghyun Hong*

Main category: cs.CV

TL;DR: 本文提出了一种输入自适应的视觉与语言导航方法，通过三种算法显著提升模型效率，实验证明计算量减少超过2倍。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉与语言导航模型在处理大规模计算时存在效率瓶颈，而现有的输入自适应机制在减少计算量的同时会导致性能显著下降。

Method: 提出了三种自适应算法：（1）选择性处理全景视图以提高空间效率；（2）基于重要性的自适应阈值方法用于早期退出以提高模型内效率；（3）实施缓存机制以避免重复处理先前视图以提高时间效率。

Result: 在七个VLN基准测试中，该方法在标准和连续环境中均实现了超过2倍的计算量减少。

Conclusion: 本文提出了一种新颖的输入自适应导航方法，通过三种自适应算法显著提升了视觉与语言导航模型的效率，并在多个基准测试中验证了其有效性。

Abstract: An emerging paradigm in vision-and-language navigation (VLN) is the use of
history-aware multi-modal transformer models. Given a language instruction,
these models process observation and navigation history to predict the most
appropriate action for an agent. While they have significantly improved
performance, the scale of these models can be a bottleneck in practical
settings with limited computational resources. In this work, we propose a novel
input-adaptive navigation method to enhance VLN model efficiency. We first show
that existing input-adaptive mechanisms fail to reduce computations without
substantial performance degradation. To address this, we introduce three
adaptive algorithms, each deployed at a different level: (1) To improve spatial
efficiency, we selectively process panoramic views at each observation of an
agent. (2) To improve intra-model efficiency, we propose importance-based
adaptive thresholding for the early-exit methods. (3) To improve temporal
efficiency, we implement a caching mechanism that prevents reprocessing of
views previously seen by the agent. In evaluations on seven VLN benchmarks, we
demonstrate over a 2$\times$ reduction in computation across three
off-the-shelf agents in both standard and continuous environments. Our code is
publicly available at
https://github.com/secure-ai-systems-group/adaptive-vision-and-language-navigation.

</details>


### [19] [SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning](https://arxiv.org/abs/2508.09325)
*Alexandre Brown,Glen Berseth*

Main category: cs.CV

TL;DR: SegDAC通过结合SAM和YOLO-World，提出一种新型视觉强化学习方法，显著提升视觉泛化和样本效率，在Maniskill3基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 视觉强化学习面临高维输入和噪声奖励下同时学习感知和动作的挑战，现有大型感知模型如何有效整合以提升视觉泛化和样本效率尚不明确。

Method: 提出SegDAC方法，结合Segment Anything（SAM）进行对象中心分解，使用YOLO-World通过文本提示语义基础，并采用新型基于变压器的架构动态处理不同时间步的片段，通过在线强化学习学习关注关键片段。

Result: 在Maniskill3基准测试中，SegDAC在强视觉干扰下的多样化操作任务中，视觉泛化能力显著优于先前方法，最难环境下性能翻倍，样本效率也匹配或超越所有评估任务中的先前方法。

Conclusion: SegDAC在视觉强化学习领域通过结合对象中心分解和语义基础，显著提升了视觉泛化能力和样本效率，尤其在最具挑战性的环境下表现突出。

Abstract: Visual reinforcement learning (RL) is challenging due to the need to learn
both perception and actions from high-dimensional inputs and noisy rewards.
Although large perception models exist, integrating them effectively into RL
for visual generalization and improved sample efficiency remains unclear. We
propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment
Anything (SAM) for object-centric decomposition and YOLO-World to ground
segments semantically via text prompts. It includes a novel transformer-based
architecture that supports a dynamic number of segments at each time step and
effectively learns which segments to focus on using online RL, without using
human labels. By evaluating SegDAC over a challenging visual generalization
benchmark using Maniskill3, which covers diverse manipulation tasks under
strong visual perturbations, we demonstrate that SegDAC achieves significantly
better visual generalization, doubling prior performance on the hardest setting
and matching or surpassing prior methods in sample efficiency across all
evaluated tasks.

</details>


### [20] [Lung-DDPM+: Efficient Thoracic CT Image Synthesis using Diffusion Probabilistic Model](https://arxiv.org/abs/2508.09327)
*Yifan Jiang,Ahmad Shariftabrizi,Venkata SK. Manem*

Main category: cs.CV

TL;DR: Lung-DDPM+ 是一种改进的生成模型，通过语义布局和加速技术，显著提升了效率和精度，适用于肺癌诊断等医疗影像任务。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在肺癌诊断中存在效率低和解剖学不精确的问题，限制了其临床应用。

Method: 提出了一种基于结节语义布局引导和肺部DPM-solver加速的改进版去噪扩散概率模型（DDPM）。

Result: 在LIDC-IDRI数据集上，Lung-DDPM+ 实现了8倍FLOPs减少、6.8倍GPU内存消耗降低和14倍采样速度提升，同时保持与SOTA模型相当的样本质量。

Conclusion: Lung-DDPM+ 是一种高效的生成模型，能够生成高质量的胸部CT图像，展示了其在医疗影像中的广泛应用潜力。

Abstract: Generative artificial intelligence (AI) has been playing an important role in
various domains. Leveraging its high capability to generate high-fidelity and
diverse synthetic data, generative AI is widely applied in diagnostic tasks,
such as lung cancer diagnosis using computed tomography (CT). However, existing
generative models for lung cancer diagnosis suffer from low efficiency and
anatomical imprecision, which limit their clinical applicability. To address
these drawbacks, we propose Lung-DDPM+, an improved version of our previous
model, Lung-DDPM. This novel approach is a denoising diffusion probabilistic
model (DDPM) guided by nodule semantic layouts and accelerated by a pulmonary
DPM-solver, enabling the method to focus on lesion areas while achieving a
better trade-off between sampling efficiency and quality. Evaluation results on
the public LIDC-IDRI dataset suggest that the proposed method achieves
8$\times$ fewer FLOPs (floating point operations per second), 6.8$\times$ lower
GPU memory consumption, and 14$\times$ faster sampling compared to Lung-DDPM.
Moreover, it maintains comparable sample quality to both Lung-DDPM and other
state-of-the-art (SOTA) generative models in two downstream segmentation tasks.
We also conducted a Visual Turing Test by an experienced radiologist, showing
the advanced quality and fidelity of synthetic samples generated by the
proposed method. These experimental results demonstrate that Lung-DDPM+ can
effectively generate high-quality thoracic CT images with lung nodules,
highlighting its potential for broader applications, such as general tumor
synthesis and lesion generation in medical imaging. The code and pretrained
models are available at https://github.com/Manem-Lab/Lung-DDPM-PLUS.

</details>


### [21] [UltraLight Med-Vision Mamba for Classification of Neoplastic Progression in Tubular Adenomas](https://arxiv.org/abs/2508.09339)
*Aqsa Sultana,Nordin Abouzahra,Ahmed Rahu,Brian Shula,Brandon Combs,Derrick Forchetti,Theus Aspiras,Vijayan K. Asari*

Main category: cs.CV

TL;DR: Ultralight Med-Vision Mamba 通过高效的状态空间模型提升结肠镜筛查中息肉分类的准确性，适用于实时临床应用。


<details>
  <summary>Details</summary>
Motivation: 结肠镜筛查中癌前息肉的准确识别和分类对降低结直肠癌风险至关重要，但现有方法在计算效率和泛化能力上存在不足。

Method: 采用基于状态空间模型（SSM）的 Ultralight Med-Vision Mamba，专注于建模长短期依赖关系和图像泛化能力。

Result: Ultralight Med-Vision Mamba 在长短期依赖建模和图像泛化方面表现优异，同时具备计算速度和可扩展性优势。

Conclusion: Ultralight Med-Vision Mamba 是一种高效且可扩展的模型，适用于实时临床部署，能够显著提升结肠镜筛查中癌前息肉的识别和分类。

Abstract: Identification of precancerous polyps during routine colonoscopy screenings
is vital for their excision, lowering the risk of developing colorectal cancer.
Advanced deep learning algorithms enable precise adenoma classification and
stratification, improving risk assessment accuracy and enabling personalized
surveillance protocols that optimize patient outcomes. Ultralight Med-Vision
Mamba, a state-space based model (SSM), has excelled in modeling long- and
short-range dependencies and image generalization, critical factors for
analyzing whole slide images. Furthermore, Ultralight Med-Vision Mamba's
efficient architecture offers advantages in both computational speed and
scalability, making it a promising tool for real-time clinical deployment.

</details>


### [22] [Blink-to-code: real-time Morse code communication via eye blink detection and classification](https://arxiv.org/abs/2508.09344)
*Anushka Bhatt*

Main category: cs.CV

TL;DR: 研究提出了一种基于眨眼摩尔斯电码的实时通信系统，用于帮助运动障碍患者，准确率62%，响应时间18-20秒。


<details>
  <summary>Details</summary>
Motivation: 为严重运动障碍患者提供一种实时、低成本的辅助通信方法。

Method: 使用标准网络摄像头和计算机视觉技术，系统检测并将眨眼分类为短（点）或长（划），然后解码为字母数字字符。

Result: 实验显示，五名参与者的解码准确率为62%，响应时间为18-20秒。

Conclusion: 该研究提出了一种低成本、可行的辅助通信方法，通过将自愿眨眼翻译成摩尔斯电码，帮助严重运动障碍患者进行交流。

Abstract: This study proposes a real-time system that translates voluntary eye blinks
into Morse code, enabling communication for individuals with severe motor
impairments. Using a standard webcam and computer vision, the system detects
and classifies blinks as short (dot) or long (dash), then decodes them into
alphanumeric characters. Experiments with five participants show 62% decoding
accuracy and 18-20 seconds response times, demonstrating a viable, low-cost
assistive communication method.

</details>


### [23] [FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition](https://arxiv.org/abs/2508.09362)
*Md. Milon Islam,Md Rezwanul Haque,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: FusionEnsemble-Net是一种基于注意力机制的时空网络集成方法，通过动态融合视觉和运动数据，显著提升了手语识别的准确性，实验准确率达99.44%。


<details>
  <summary>Details</summary>
Motivation: 医疗通信中手语的准确识别是一个重要挑战，需要能够解释复杂多模态手势的框架。

Method: 提出了一种新型的基于注意力的时空网络集成框架FusionEnsemble-Net，同步处理RGB视频和雷达多普勒图模态，通过四个不同的时空网络进行特征融合，并采用集成分类器提升模型鲁棒性。

Result: 在意大利手语的大规模MultiMeDaLIS数据集上，FusionEnsemble-Net的测试准确率达到99.44%，优于现有方法。

Conclusion: FusionEnsemble-Net通过基于注意力的时空网络集成，动态融合视觉和运动数据，显著提升了复杂多模态手势识别的准确性。实验结果表明，该方法在意大利手语识别任务中表现优异，准确率达99.44%。

Abstract: Accurate recognition of sign language in healthcare communication poses a
significant challenge, requiring frameworks that can accurately interpret
complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net,
a novel attention-based ensemble of spatiotemporal networks that dynamically
fuses visual and motion data to enhance recognition accuracy. The proposed
approach processes RGB video and range Doppler map radar modalities
synchronously through four different spatiotemporal networks. For each network,
features from both modalities are continuously fused using an attention-based
fusion module before being fed into an ensemble of classifiers. Finally, the
outputs of these four different fused channels are combined in an ensemble
classification head, thereby enhancing the model's robustness. Experiments
demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches
with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for
Italian Sign Language. Our findings indicate that an ensemble of diverse
spatiotemporal networks, unified by attention-based fusion, yields a robust and
accurate framework for complex, multimodal isolated gesture recognition tasks.
The source code is available at:
https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.

</details>


### [24] [A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition](https://arxiv.org/abs/2508.09372)
*Md Rezwanul Haque,Md. Milon Islam,S M Taslim Uddin Raju,Fakhri Karray*

Main category: cs.CV

TL;DR: 提出双架构框架解决CSLR中手语者差异和新句子泛化问题，SI任务WER降低13.53%，US任务超越现有技术，SignEval 2025表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决CSLR中手语者间差异大且对新句子结构泛化能力差的问题。

Method: 提出双架构框架：对于手语者无关（SI）挑战，使用结合卷积与多头自注意力的Signer-Invariant Conformer；对于未见句子（US）任务，设计多尺度融合Transformer，配备双路径时间编码器。

Result: 在Isharah-1000数据集上，SI任务的WER降至13.07%（降低13.53%），US任务WER为47.78%，均超越现有技术。SignEval 2025挑战赛中SI第4、US第2。

Conclusion: 开发针对CSLR特定挑战的任务专用网络能显著提升性能，并为后续研究设立新基准。

Abstract: Continuous Sign Language Recognition (CSLR) faces multiple challenges,
including significant inter-signer variability and poor generalization to novel
sentence structures. Traditional solutions frequently fail to handle these
issues efficiently. For overcoming these constraints, we propose a
dual-architecture framework. For the Signer-Independent (SI) challenge, we
propose a Signer-Invariant Conformer that combines convolutions with multi-head
self-attention to learn robust, signer-agnostic representations from pose-based
skeletal keypoints. For the Unseen-Sentences (US) task, we designed a
Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that
captures both fine-grained posture dynamics, enabling the model's ability to
comprehend novel grammatical compositions. Experiments on the challenging
Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The
proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on
the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US
task, the transformer model scores a WER of 47.78%, surpassing previous work.
In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th
in the SI task, demonstrating the performance of these models. The findings
validate our key hypothesis: that developing task-specific networks designed
for the particular challenges of CSLR leads to considerable performance
improvements and establishes a new baseline for further research. The source
code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.

</details>


### [25] [What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?](https://arxiv.org/abs/2508.09381)
*Kumar Abhishek,Jeremy Kawahara,Ghassan Hamarneh*

Main category: cs.CV

TL;DR: IMA++数据集研究表明注释者间一致性与皮肤病变恶性程度相关，利用IAA作为软特征可提升分割模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中因模糊边界、注释者偏好和工具差异导致的变异性问题，尤其是恶性病变的分割一致性。

Method: 通过构建IMA++多注释者皮肤病变分割数据集，研究注释者、恶性程度、工具和技能等因素对分割变异性的影响，并利用IAA作为多任务学习目标中的软临床特征。

Result: 研究发现IAA与皮肤病变恶性程度显著相关（p<0.001），并证明IAA可直接从皮肤镜图像预测（平均绝对误差0.108）。多任务学习利用IAA特征使平衡准确率平均提升4.2%。

Conclusion: IMA++数据集的研究揭示了注释者间一致性（IAA）与皮肤病变恶性程度之间的显著关联，并证明IAA可作为软临床特征提升模型性能。

Abstract: Medical image segmentation exhibits intra- and inter-annotator variability
due to ambiguous object boundaries, annotator preferences, expertise, and
tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated
or infiltrative nodules, or irregular borders per the ABCD rule, are
particularly prone to disagreement and are often associated with malignancy. In
this work, we curate IMA++, the largest multi-annotator skin lesion
segmentation dataset, on which we conduct an in-depth study of variability due
to annotator, malignancy, tool, and skill factors. We find a statistically
significant (p<0.001) association between inter-annotator agreement (IAA),
measured using Dice, and the malignancy of skin lesions. We further show that
IAA can be accurately predicted directly from dermoscopic images, achieving a
mean absolute error of 0.108. Finally, we leverage this association by
utilizing IAA as a "soft" clinical feature within a multi-task learning
objective, yielding a 4.2% improvement in balanced accuracy averaged across
multiple model architectures and across IMA++ and four public dermoscopic
datasets. The code is available at https://github.com/sfu-mial/skin-IAV.

</details>


### [26] [Distilling LLM Prior to Flow Model for Generalizable Agent's Imagination in Object Goal Navigation](https://arxiv.org/abs/2508.09423)
*Badi Li,Ren-jie Lu,Yu Zhou,Jingke Meng,Wei-shi Zheng*

Main category: cs.CV

TL;DR: GOAL是一个生成流框架，利用LLM的空间先验提升语义地图补全的泛化能力，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决ObjectNav任务中现有方法因忽略室内布局的不确定性而导致的泛化能力不足问题。

Method: 提出了一个基于生成流的框架GOAL，通过将LLM推断的空间先验编码为二维高斯场并注入目标地图，从而在训练中丰富上下文知识。

Result: GOAL在MP3D和Gibson数据集上达到state-of-the-art性能，并在HM3D上表现出强泛化能力。

Conclusion: GOAL框架通过结合LLM的空间先验知识，实现了在未见环境中更通用和高效的语义地图补全，显著提升了ObjectNav任务的性能。

Abstract: The Object Goal Navigation (ObjectNav) task challenges agents to locate a
specified object in an unseen environment by imagining unobserved regions of
the scene. Prior approaches rely on deterministic and discriminative models to
complete semantic maps, overlooking the inherent uncertainty in indoor layouts
and limiting their ability to generalize to unseen environments. In this work,
we propose GOAL, a generative flow-based framework that models the semantic
distribution of indoor environments by bridging observed regions with
LLM-enriched full-scene semantic maps. During training, spatial priors inferred
from large language models (LLMs) are encoded as two-dimensional Gaussian
fields and injected into target maps, distilling rich contextual knowledge into
the flow model and enabling more generalizable completions. Extensive
experiments demonstrate that GOAL achieves state-of-the-art performance on MP3D
and Gibson, and shows strong generalization in transfer settings to HM3D. Codes
and pretrained models are available at https://github.com/Badi-Li/GOAL.

</details>


### [27] [X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents](https://arxiv.org/abs/2508.09383)
*Guoxian Song,Hongyi Xu,Xiaochen Zhao,You Xie,Tianpei Gu,Zenan Li,Chenxu Zhang,Linjie Luo*

Main category: cs.CV

TL;DR: X-UniMotion 是一种隐式潜在表示方法，用于全身运动转移，通过自监督学习实现高保真跨身份动画，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的运动转移方法依赖于显式骨骼姿势和启发式的跨身份调整，缺乏表达性和身份无关性。X-UniMotion旨在通过隐式潜在表示克服这些限制，实现高保真、详细的跨身份运动转移。

Method: 采用自监督的端到端框架，联合学习运动编码器和潜在表示，以及基于DiT的视频生成模型。通过2D空间和颜色增强，以及合成3D渲染来强制运动与身份的分离，并利用辅助解码器引导运动令牌学习。

Result: X-UniMotion在实验中表现优于现有方法，能够生成具有高表达性和身份保留的动画。

Conclusion: X-UniMotion 提出了一种统一的、表达性强的隐式潜在表示方法，用于全身人体运动，包括面部表情、身体姿势和手势。该方法通过自监督的端到端框架，实现了高保真度的跨身份运动转移，并在实验中优于现有技术。

Abstract: We present X-UniMotion, a unified and expressive implicit latent
representation for whole-body human motion, encompassing facial expressions,
body poses, and hand gestures. Unlike prior motion transfer methods that rely
on explicit skeletal poses and heuristic cross-identity adjustments, our
approach encodes multi-granular motion directly from a single image into a
compact set of four disentangled latent tokens -- one for facial expression,
one for body pose, and one for each hand. These motion latents are both highly
expressive and identity-agnostic, enabling high-fidelity, detailed
cross-identity motion transfer across subjects with diverse identities, poses,
and spatial configurations. To achieve this, we introduce a self-supervised,
end-to-end framework that jointly learns the motion encoder and latent
representation alongside a DiT-based video generative model, trained on
large-scale, diverse human motion datasets. Motion-identity disentanglement is
enforced via 2D spatial and color augmentations, as well as synthetic 3D
renderings of cross-identity subject pairs under shared poses. Furthermore, we
guide motion token learning with auxiliary decoders that promote fine-grained,
semantically aligned, and depth-aware motion embeddings. Extensive experiments
show that X-UniMotion outperforms state-of-the-art methods, producing highly
expressive animations with superior motion fidelity and identity preservation.

</details>


### [28] [WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization](https://arxiv.org/abs/2508.09560)
*Jiahao Wen,Hang Yu,Zhedong Zheng*

Main category: cs.CV

TL;DR: WeatherPrompt通过多模态学习和动态门控机制，提升无人机在复杂天气下的地理定位性能，Recall@1显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在天气扰动下表现不佳，主要受限于有限的天气类别和对场景-天气特征解耦的不足。

Method: 提出了Training-free Weather Reasoning机制和多模态框架，结合动态门控机制和跨模态目标优化，有效解耦场景和天气特征。

Result: 在多种天气条件下，Recall@1显著提升，夜间条件下提高13.37%，雾和雪条件下提高18.69%。

Conclusion: WeatherPrompt通过多模态学习范式，成功建立了天气不变的表示，显著提升了无人机在多种天气条件下的地理定位性能，特别是在夜间、雾和雪等极端天气条件下表现尤为突出。

Abstract: Visual geo-localization for drones faces critical degradation under weather
perturbations, \eg, rain and fog, where existing methods struggle with two
inherent limitations: 1) Heavy reliance on limited weather categories that
constrain generalization, and 2) Suboptimal disentanglement of entangled
scene-weather features through pseudo weather categories. We present
WeatherPrompt, a multi-modality learning paradigm that establishes
weather-invariant representations through fusing the image embedding with the
text context. Our framework introduces two key contributions: First, a
Training-free Weather Reasoning mechanism that employs off-the-shelf large
multi-modality models to synthesize multi-weather textual descriptions through
human-like reasoning. It improves the scalability to unseen or complex weather,
and could reflect different weather strength. Second, to better disentangle the
scene and weather feature, we propose a multi-modality framework with the
dynamic gating mechanism driven by the text embedding to adaptively reweight
and fuse visual features across modalities. The framework is further optimized
by the cross-modal objectives, including image-text contrastive learning and
image-text matching, which maps the same scene with different weather
conditions closer in the respresentation space. Extensive experiments validate
that, under diverse weather conditions, our method achieves competitive recall
rates compared to state-of-the-art drone geo-localization methods. Notably, it
improves Recall@1 by +13.37\% under night conditions and by 18.69\% under fog
and snow conditions.

</details>


### [29] [DenoDet V2: Phase-Amplitude Cross Denoising for SAR Object Detection](https://arxiv.org/abs/2508.09392)
*Kang Ni,Minrui Zou,Yuxuan Li,Xiang Li,Kehua Guo,Ming-Ming Cheng,Yimian Dai*

Main category: cs.CV

TL;DR: DenoDet V2通过频域注意力机制和振幅-相位互调制，显著提升SAR目标检测性能并降低复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决SAR目标检测中相干噪声的普遍影响，现有方法多依赖空间域特征分析或增强，缺乏频域视角的创新。

Method: 提出DenoDet V2，采用精心设计的注意力架构在变换域解构和调制特征，利用带间互调制机制实现相位与振幅谱的互增强。

Result: 在多个SAR数据集上取得最先进性能，SARDet-100K数据集上相比DenoDet V1提升0.8%，模型复杂度减半。

Conclusion: DenoDet V2通过频域特征解构与调制，结合振幅与相位信息的互补性，显著提升了SAR目标检测的性能，同时降低了模型复杂度。

Abstract: One of the primary challenges in Synthetic Aperture Radar (SAR) object
detection lies in the pervasive influence of coherent noise. As a common
practice, most existing methods, whether handcrafted approaches or deep
learning-based methods, employ the analysis or enhancement of object
spatial-domain characteristics to achieve implicit denoising. In this paper, we
propose DenoDet V2, which explores a completely novel and different perspective
to deconstruct and modulate the features in the transform domain via a
carefully designed attention architecture. Compared to DenoDet V1, DenoDet V2
is a major advancement that exploits the complementary nature of amplitude and
phase information through a band-wise mutual modulation mechanism, which
enables a reciprocal enhancement between phase and amplitude spectra. Extensive
experiments on various SAR datasets demonstrate the state-of-the-art
performance of DenoDet V2. Notably, DenoDet V2 achieves a significant 0.8\%
improvement on SARDet-100K dataset compared to DenoDet V1, while reducing the
model complexity by half. The code is available at
https://github.com/GrokCV/GrokSAR.

</details>


### [30] [Plane Detection and Ranking via Model Information Optimization](https://arxiv.org/abs/2508.09625)
*Daoxin Zhong,Jun Li,Meng Yee Michael Chuah*

Main category: cs.CV

TL;DR: 提出一种基于模型信息优化的平面检测框架，通过信息量最小化减少误报，优于传统RANSAC方法，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决RANSAC方法在复杂场景中因内点阈值标准模糊导致的误报问题，提出一种客观机制来确定真实平面数量并防止误检。

Method: 将深度观测值视为离散随机变量，通过随机子采样生成包含不同候选平面约束的模型，结合深度传感器的物理和噪声模型计算每个模型的信息量，选择信息量最少的模型作为最可能的地面真值。

Result: 实验验证表明，该算法在合成数据中比Open3D的RANSAC平面分割更准确地估计平面参数，并通过神经网络分割加速深度图分区，提升了在真实数据中的表现。

Conclusion: 提出的基于模型信息优化的通用框架在平面检测中表现出色，能够准确估计平面参数并减少误报，尤其在复杂场景中优于传统RANSAC方法。

Abstract: Plane detection from depth images is a crucial subtask with broad robotic
applications, often accomplished by iterative methods such as Random Sample
Consensus (RANSAC). While RANSAC is a robust strategy with strong probabilistic
guarantees, the ambiguity of its inlier threshold criterion makes it
susceptible to false positive plane detections. This issue is particularly
prevalent in complex real-world scenes, where the true number of planes is
unknown and multiple planes coexist. In this paper, we aim to address this
limitation by proposing a generalised framework for plane detection based on
model information optimization. Building on previous works, we treat the
observed depth readings as discrete random variables, with their probability
distributions constrained by the ground truth planes. Various models containing
different candidate plane constraints are then generated through repeated
random sub-sampling to explain our observations. By incorporating the physics
and noise model of the depth sensor, we can calculate the information for each
model, and the model with the least information is accepted as the most likely
ground truth. This information optimization process serves as an objective
mechanism for determining the true number of planes and preventing false
positive detections. Additionally, the quality of each detected plane can be
ranked by summing the information reduction of inlier points for each plane. We
validate these properties through experiments with synthetic data and find that
our algorithm estimates plane parameters more accurately compared to the
default Open3D RANSAC plane segmentation. Furthermore, we accelerate our
algorithm by partitioning the depth map using neural network segmentation,
which enhances its ability to generate more realistic plane parameters in
real-world data.

</details>


### [31] [Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety](https://arxiv.org/abs/2508.09397)
*Zhengli Zhang,Xinyu Luo,Yuchen Sun,Wenhua Ding,Dongyu Huang,Xinlei Chen*

Main category: cs.CV

TL;DR: SkyShield是一种事件驱动的框架，用于检测无人机难以发现的亚毫米级障碍物，采用轻量级U-Net和新型损失函数，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统传感器（如RGB相机、LiDAR和深度相机）难以检测亚毫米级障碍物（如钢丝和风筝线），这对无人机在复杂环境中的操作构成重大威胁。

Method: 采用轻量级U-Net架构和创新的Dice-Contour Regularization Loss，基于事件流的独特特征进行障碍物检测。

Result: 实验结果显示，该方法平均F1得分为0.7088，延迟仅为21.2毫秒。

Conclusion: SkyShield框架通过事件驱动的方法和创新的损失函数，有效解决了无人机在复杂环境中检测亚毫米级障碍物的难题，表现出色且适合边缘和移动平台部署。

Abstract: Drones operating in complex environments face a significant threat from thin
obstacles, such as steel wires and kite strings at the submillimeter level,
which are notoriously difficult for conventional sensors like RGB cameras,
LiDAR, and depth cameras to detect. This paper introduces SkyShield, an
event-driven, end-to-end framework designed for the perception of submillimeter
scale obstacles. Drawing upon the unique features that thin obstacles present
in the event stream, our method employs a lightweight U-Net architecture and an
innovative Dice-Contour Regularization Loss to ensure precise detection.
Experimental results demonstrate that our event-based approach achieves mean F1
Score of 0.7088 with a low latency of 21.2 ms, making it ideal for deployment
on edge and mobile platforms.

</details>


### [32] [Surg-InvNeRF: Invertible NeRF for 3D tracking and reconstruction in surgical vision](https://arxiv.org/abs/2508.09681)
*Gerardo Loza,Junlei Hu,Dominic Jones,Sharib Ali,Pietro Valdastri*

Main category: cs.CV

TL;DR: 提出基于InvNeRF的TTO方法，显著提升2D/3D点跟踪精度，尤其在手术场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长期点跟踪中难以保持运动一致性或仅限于2D运动，因此需要一种能够同时处理2D和3D跟踪的优化方法。

Method: 采用可逆神经辐射场（InvNeRF）架构，结合多尺度HexPlanes快速推理和高效像素采样算法，实现了双向可变形-规范映射和射线密度引导。

Result: 在STIR和SCARE数据集上，2D点跟踪的平均精度提升近50%，3D点跟踪首次超越前馈方法，并融合了可变形NeRF重建的优势。

Conclusion: 该论文提出了一种基于InvNeRF架构的新型测试时优化（TTO）方法，显著提升了2D和3D点跟踪的精度和准确性，尤其在手术场景中表现优异。

Abstract: We proposed a novel test-time optimisation (TTO) approach framed by a
NeRF-based architecture for long-term 3D point tracking. Most current methods
in point tracking struggle to obtain consistent motion or are limited to 2D
motion. TTO approaches frame the solution for long-term tracking as optimising
a function that aggregates correspondences from other specialised
state-of-the-art methods. Unlike the state-of-the-art on TTO, we propose
parametrising such a function with our new invertible Neural Radiance Field
(InvNeRF) architecture to perform both 2D and 3D tracking in surgical
scenarios. Our approach allows us to exploit the advantages of a
rendering-based approach by supervising the reprojection of pixel
correspondences. It adapts strategies from recent rendering-based methods to
obtain a bidirectional deformable-canonical mapping, to efficiently handle a
defined workspace, and to guide the rays' density. It also presents our
multi-scale HexPlanes for fast inference and a new algorithm for efficient
pixel sampling and convergence criteria. We present results in the STIR and
SCARE datasets, for evaluating point tracking and testing the integration of
kinematic data in our pipeline, respectively. In 2D point tracking, our
approach surpasses the precision and accuracy of the TTO state-of-the-art
methods by nearly 50% on average precision, while competing with other
approaches. In 3D point tracking, this is the first TTO approach, surpassing
feed-forward methods while incorporating the benefits of a deformable
NeRF-based reconstruction.

</details>


### [33] [Autonomous AI Bird Feeder for Backyard Biodiversity Monitoring](https://arxiv.org/abs/2508.09398)
*El Mustapha Mansouri*

Main category: cs.CV

TL;DR: 低成本本地化鸟类监测系统，使用Detectron2定位和EfficientNet-B3分类，验证性能99.5%，实际应用88%准确率。


<details>
  <summary>Details</summary>
Motivation: 开发一种低成本、本地化的自主鸟类监测系统，以保护隐私并避免云服务费用，同时提高分类准确性。

Method: 使用运动触发的IP摄像头通过FTP上传短片至本地服务器，利用Detectron2进行鸟类定位，并通过在比利时40种鸟类子集上微调的EfficientNet-B3模型进行分类。

Result: 分类器在精选子集上达到约99.5%的验证性能，在实际应用中（保留物种）达到约88%的top-1准确率。

Conclusion: 该系统展示了在家庭环境中进行公民科学级生物多样性记录的可行性，通过低成本、本地化的解决方案实现了高精度的鸟类监测。

Abstract: This paper presents a low cost, on premise system for autonomous backyard
bird monitoring in Belgian urban gardens. A motion triggered IP camera uploads
short clips via FTP to a local server, where frames are sampled and birds are
localized with Detectron2; cropped regions are then classified by an
EfficientNet-B3 model fine tuned on a 40-species Belgian subset derived from a
larger Kaggle corpus. All processing runs on commodity hardware without a
discrete GPU, preserving privacy and avoiding cloud fees. The physical feeder
uses small entry ports (30 mm) to exclude pigeons and reduce nuisance triggers.
Detector-guided cropping improves classification accuracy over raw-frame
classification. The classifier attains high validation performance on the
curated subset (about 99.5 percent) and delivers practical field accuracy
(top-1 about 88 percent) on held-out species, demonstrating feasibility for
citizen-science-grade biodiversity logging at home.

</details>


### [34] [Predictive Uncertainty for Runtime Assurance of a Real-Time Computer Vision-Based Landing System](https://arxiv.org/abs/2508.09732)
*Romeo Valentin,Sydney M. Katz,Artur B. Carneiro,Don Walker,Mykel J. Kochenderfer*

Main category: cs.CV

TL;DR: 本研究提出了一种基于视觉的飞机姿态估计流程，通过创新的神经架构、损失函数和故障检测方法，提高了准确性和安全性，适用于航空应用。


<details>
  <summary>Details</summary>
Motivation: 尽管数据驱动的计算机视觉在航空导航中取得进展，但确保其满足航空应用的鲁棒性和安全性要求仍具挑战性。

Method: 1. 基于空间Soft Argmax操作符的高效灵活神经架构；2. 产生校准预测不确定性的原则性损失函数；3. 适应残差基自主完整性监测（RAIM）用于运行时故障检测。

Result: 在跑道图像数据集上的评估表明，该模型在准确性上优于基线架构，并能产生亚像素精度的校准不确定性估计，可用于故障检测。

Conclusion: 本研究提出了一种实用的基于视觉的飞机姿态估计流程，通过三个关键创新点提高了准确性和不确定性校准，为安全关键航空应用的认证奠定了基础。

Abstract: Recent advances in data-driven computer vision have enabled robust autonomous
navigation capabilities for civil aviation, including automated landing and
runway detection. However, ensuring that these systems meet the robustness and
safety requirements for aviation applications remains a major challenge. In
this work, we present a practical vision-based pipeline for aircraft pose
estimation from runway images that represents a step toward the ability to
certify these systems for use in safety-critical aviation applications. Our
approach features three key innovations: (i) an efficient, flexible neural
architecture based on a spatial Soft Argmax operator for probabilistic keypoint
regression, supporting diverse vision backbones with real-time inference; (ii)
a principled loss function producing calibrated predictive uncertainties, which
are evaluated via sharpness and calibration metrics; and (iii) an adaptation of
Residual-based Receiver Autonomous Integrity Monitoring (RAIM), enabling
runtime detection and rejection of faulty model outputs. We implement and
evaluate our pose estimation pipeline on a dataset of runway images. We show
that our model outperforms baseline architectures in terms of accuracy while
also producing well-calibrated uncertainty estimates with sub-pixel precision
that can be used downstream for fault detection.

</details>


### [35] [Waymo-3DSkelMo: A Multi-Agent 3D Skeletal Motion Dataset for Pedestrian Interaction Modeling in Autonomous Driving](https://arxiv.org/abs/2508.09404)
*Guangxun Zhu,Shiyu Fan,Hang Dai,Edmond S. L. Ho*

Main category: cs.CV

TL;DR: Waymo-3DSkelMo是首个大规模、高质量、时间连贯的3D骨骼运动数据集，通过LiDAR点云和运动先验提升数据质量，适用于复杂城市环境中的人类交互研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据集主要依赖单目RGB视频帧估计3D姿势，存在遮挡和时间不连续性问题，导致运动数据质量低且不真实。

Method: 利用3D人体形状和运动先验知识，从原始LiDAR点云中提取高质量的3D姿势序列。

Result: 数据集涵盖超过14,000秒的800多个真实驾驶场景，包含丰富的交互行为（平均每场景27个代理，最大场景达250个代理），并建立了3D姿势预测基准。

Conclusion: Waymo-3DSkelMo数据集为复杂城市环境中细粒度人类行为理解的研究提供了高质量、时间连贯的3D骨骼运动数据，填补了现有数据集的不足。

Abstract: Large-scale high-quality 3D motion datasets with multi-person interactions
are crucial for data-driven models in autonomous driving to achieve
fine-grained pedestrian interaction understanding in dynamic urban
environments. However, existing datasets mostly rely on estimating 3D poses
from monocular RGB video frames, which suffer from occlusion and lack of
temporal continuity, thus resulting in unrealistic and low-quality human
motion. In this paper, we introduce Waymo-3DSkelMo, the first large-scale
dataset providing high-quality, temporally coherent 3D skeletal motions with
explicit interaction semantics, derived from the Waymo Perception dataset. Our
key insight is to utilize 3D human body shape and motion priors to enhance the
quality of the 3D pose sequences extracted from the raw LiDRA point clouds. The
dataset covers over 14,000 seconds across more than 800 real driving scenarios,
including rich interactions among an average of 27 agents per scene (with up to
250 agents in the largest scene). Furthermore, we establish 3D pose forecasting
benchmarks under varying pedestrian densities, and the results demonstrate its
value as a foundational resource for future research on fine-grained human
behavior understanding in complex urban environments. The dataset and code will
be available at https://github.com/GuangxunZhu/Waymo-3DSkelMo

</details>


### [36] [TRACE: Learning 3D Gaussian Physical Dynamics from Multi-view Videos](https://arxiv.org/abs/2508.09811)
*Jinxi Li,Ziyang Song,Bo Yang*

Main category: cs.CV

TL;DR: TRACE框架通过建模3D点为刚性粒子并学习其动力学系统，显著提升复杂动态3D场景的未来帧外推性能，且无需额外标签即可分割对象。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过物理信息损失作为软约束或将简单物理模型集成到神经网络中，难以学习复杂运动物理，且需要额外标签（如对象类型或掩码）。

Method: 提出名为TRACE的新框架，将每个3D点建模为具有大小和方向的刚性粒子，直接学习每个粒子的平移旋转动力学系统，并显式估计一组完整的物理参数来管理粒子随时间的运动。

Result: 在三个现有动态数据集和一个新创建的合成数据集上的实验表明，TRACE在复杂动态3D场景的未来帧外推任务中表现优于基线方法。

Conclusion: TRACE框架通过将3D点建模为具有大小和方向的刚性粒子，直接学习每个粒子的平移旋转动力学系统，显著提升了复杂动态3D场景中未来帧外推任务的性能，并能够通过物理参数聚类轻松分割多个对象或部分。

Abstract: In this paper, we aim to model 3D scene geometry, appearance, and physical
information just from dynamic multi-view videos in the absence of any human
labels. By leveraging physics-informed losses as soft constraints or
integrating simple physics models into neural nets, existing works often fail
to learn complex motion physics, or doing so requires additional labels such as
object types or masks. We propose a new framework named TRACE to model the
motion physics of complex dynamic 3D scenes. The key novelty of our method is
that, by formulating each 3D point as a rigid particle with size and
orientation in space, we directly learn a translation rotation dynamics system
for each particle, explicitly estimating a complete set of physical parameters
to govern the particle's motion over time. Extensive experiments on three
existing dynamic datasets and one newly created challenging synthetic datasets
demonstrate the extraordinary performance of our method over baselines in the
task of future frame extrapolation. A nice property of our framework is that
multiple objects or parts can be easily segmented just by clustering the
learned physical parameters.

</details>


### [37] [RampNet: A Two-Stage Pipeline for Bootstrapping Curb Ramp Detection in Streetscape Images from Open Government Metadata](https://arxiv.org/abs/2508.09415)
*John S. O'Meara,Jared Hwang,Zeyu Wang,Michael Saugstad,Jon E. Froehlich*

Main category: cs.CV

TL;DR: RampNet通过两阶段流程（数据集生成和改进模型训练）实现了路缘坡道检测的大规模高质量数据集和最优性能。


<details>
  <summary>Details</summary>
Motivation: 路缘坡道对城市无障碍至关重要，但由于缺乏大规模高质量数据集，其图像检测仍是一个未解决的问题。

Method: 提出了一个两阶段流程RampNet：第一阶段通过自动转换政府提供的路缘坡道位置数据为全景图像中的像素坐标，生成了超过210,000张标注的Google街景全景图数据集；第二阶段使用改进的ConvNeXt V2模型进行训练，实现了最先进的检测性能。

Result: 生成的数据集达到94.0%的精确率和92.5%的召回率，检测模型的AP值达到0.9236，远超先前工作。

Conclusion: 本研究贡献了首个大规模、高质量的路缘坡道检测数据集、基准和模型，显著提升了检测性能。

Abstract: Curb ramps are critical for urban accessibility, but robustly detecting them
in images remains an open problem due to the lack of large-scale, high-quality
datasets. While prior work has attempted to improve data availability with
crowdsourced or manually labeled data, these efforts often fall short in either
quality or scale. In this paper, we introduce and evaluate a two-stage pipeline
called RampNet to scale curb ramp detection datasets and improve model
performance. In Stage 1, we generate a dataset of more than 210,000 annotated
Google Street View (GSV) panoramas by auto-translating government-provided curb
ramp location data to pixel coordinates in panoramic images. In Stage 2, we
train a curb ramp detection model (modified ConvNeXt V2) from the generated
dataset, achieving state-of-the-art performance. To evaluate both stages of our
pipeline, we compare to manually labeled panoramas. Our generated dataset
achieves 94.0% precision and 92.5% recall, and our detection model reaches
0.9236 AP -- far exceeding prior work. Our work contributes the first
large-scale, high-quality curb ramp detection dataset, benchmark, and model.

</details>


### [38] [What-Meets-Where: Unified Learning of Action and Contact Localization in a New Dataset](https://arxiv.org/abs/2508.09428)
*Yuxiao Wang,Yu Lei,Wolin Liang,Weiying Xue,Zhenao Wei,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: PaIR-Net是一个新框架，能同时预测动作语义和身体部位接触区域，显著优于现有方法，并附带新数据集PaIR。


<details>
  <summary>Details</summary>
Motivation: 当前方法未能充分捕捉动作语义及其在场景中的空间上下文，因此需要一种能同时建模两者的新方法。

Method: 提出了PaIR-Net框架，包含接触先验感知模块（CPAM）、先验引导拼接分割器（PGCS）和交互推理模块（IIM），用于同时预测高级动作语义和细粒度身体部位接触区域。

Result: PaIR-Net在实验中显著优于基线方法，消融研究验证了各模块的有效性。

Conclusion: PaIR-Net框架通过结合动作语义和身体部位接触区域的预测，显著优于基线方法，且各组件在消融研究中均表现出有效性。

Abstract: People control their bodies to establish contact with the environment. To
comprehensively understand actions across diverse visual contexts, it is
essential to simultaneously consider \textbf{what} action is occurring and
\textbf{where} it is happening. Current methodologies, however, often
inadequately capture this duality, typically failing to jointly model both
action semantics and their spatial contextualization within scenes. To bridge
this gap, we introduce a novel vision task that simultaneously predicts
high-level action semantics and fine-grained body-part contact regions. Our
proposed framework, PaIR-Net, comprises three key components: the Contact Prior
Aware Module (CPAM) for identifying contact-relevant body parts, the
Prior-Guided Concat Segmenter (PGCS) for pixel-wise contact segmentation, and
the Interaction Inference Module (IIM) responsible for integrating global
interaction relationships. To facilitate this task, we present PaIR (Part-aware
Interaction Representation), a comprehensive dataset containing 13,979 images
that encompass 654 actions, 80 object categories, and 17 body parts.
Experimental evaluation demonstrates that PaIR-Net significantly outperforms
baseline approaches, while ablation studies confirm the efficacy of each
architectural component. The code and dataset will be released upon
publication.

</details>


### [39] [MPT: Motion Prompt Tuning for Micro-Expression Recognition](https://arxiv.org/abs/2508.09446)
*Jiateng Liu,Hengcan Shi,Feng Chen,Zhiwen Shao,Yaonan Wang,Jianfei Cai,Wenming Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为MPT的新方法，通过运动提示调优和组适配器设计，成功将大型预训练模型应用于微表情识别，显著提升了识别效果。


<details>
  <summary>Details</summary>
Motivation: 由于微表情标注的困难和样本稀缺，现有大型预训练模型难以直接应用于微表情识别，因此需要一种新方法来解决这一问题。

Method: 本文提出了运动提示调优（MPT）方法，包括运动放大和高斯标记化来提取细微运动作为提示，并设计了组适配器以增强模型在MER领域的表现。

Result: 在三个广泛使用的MER数据集上的实验表明，MPT方法在性能上一致超越了现有最先进方法。

Conclusion: MPT方法通过运动提示调优和组适配器设计，成功地将大型预训练模型应用于微表情识别领域，显著提升了识别性能。

Abstract: Micro-expression recognition (MER) is crucial in the affective computing
field due to its wide application in medical diagnosis, lie detection, and
criminal investigation. Despite its significance, obtaining micro-expression
(ME) annotations is challenging due to the expertise required from
psychological professionals. Consequently, ME datasets often suffer from a
scarcity of training samples, severely constraining the learning of MER models.
While current large pre-training models (LMs) offer general and discriminative
representations, their direct application to MER is hindered by an inability to
capture transitory and subtle facial movements-essential elements for effective
MER. This paper introduces Motion Prompt Tuning (MPT) as a novel approach to
adapting LMs for MER, representing a pioneering method for subtle motion prompt
tuning. Particularly, we introduce motion prompt generation, including motion
magnification and Gaussian tokenization, to extract subtle motions as prompts
for LMs. Additionally, a group adapter is carefully designed and inserted into
the LM to enhance it in the target MER domain, facilitating a more nuanced
distinction of ME representation. Furthermore, extensive experiments conducted
on three widely used MER datasets demonstrate that our proposed MPT
consistently surpasses state-of-the-art approaches and verifies its
effectiveness.

</details>


### [40] [RASR: Retrieval-Augmented Super Resolution for Practical Reference-based Image Restoration](https://arxiv.org/abs/2508.09449)
*Jiaqi Yan,Shuning Xu,Xiangyu Chen,Dell Zhang,Jie Tang,Gangshan Wu,Jie Liu*

Main category: cs.CV

TL;DR: 提出检索增强超分辨率（RASR）方法，通过自动检索高质量参考图像提升超分辨率效果，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于参考的超分辨率方法（RefSR）依赖手动配对的参考图像，限制了其在现实场景中的实用性。为解决这一问题，研究提出了自动检索高质量参考图像的方法，以提升纹理保真度和视觉真实感。

Method: 提出了一种新的检索增强超分辨率范式（RASR），包括RASRNet模型，该模型结合了语义参考检索器和基于扩散的超分辨率生成器，通过语义相似性检索相关参考图像，并利用语义条件增强生成效果。

Result: 在RASR-Flickr30基准数据集上的实验表明，RASRNet相比单图像超分辨率基线方法提升了+0.38 dB PSNR和-0.0131 LPIPS，生成了更真实的纹理。

Conclusion: 检索增强超分辨率（RASR）通过自动检索语义相关的高质量参考图像，显著提升了超分辨率技术在现实场景中的适用性，为学术研究与实际应用之间的差距提供了解决方案。

Abstract: Reference-based Super Resolution (RefSR) improves upon Single Image Super
Resolution (SISR) by leveraging high-quality reference images to enhance
texture fidelity and visual realism. However, a critical limitation of existing
RefSR approaches is their reliance on manually curated target-reference image
pairs, which severely constrains their practicality in real-world scenarios. To
overcome this, we introduce Retrieval-Augmented Super Resolution (RASR), a new
and practical RefSR paradigm that automatically retrieves semantically relevant
high-resolution images from a reference database given only a low-quality
input. This enables scalable and flexible RefSR in realistic use cases, such as
enhancing mobile photos taken in environments like zoos or museums, where
category-specific reference data (e.g., animals, artworks) can be readily
collected or pre-curated. To facilitate research in this direction, we
construct RASR-Flickr30, the first benchmark dataset designed for RASR. Unlike
prior datasets with fixed target-reference pairs, RASR-Flickr30 provides
per-category reference databases to support open-world retrieval. We further
propose RASRNet, a strong baseline that combines a semantic reference retriever
with a diffusion-based RefSR generator. It retrieves relevant references based
on semantic similarity and employs a diffusion-based generator enhanced with
semantic conditioning. Experiments on RASR-Flickr30 demonstrate that RASRNet
consistently improves over SISR baselines, achieving +0.38 dB PSNR and -0.0131
LPIPS, while generating more realistic textures. These findings highlight
retrieval augmentation as a promising direction to bridge the gap between
academic RefSR research and real-world applicability.

</details>


### [41] [HyperKD: Distilling Cross-Spectral Knowledge in Masked Autoencoders via Inverse Domain Shift with Spatial-Aware Masking and Specialized Loss](https://arxiv.org/abs/2508.09453)
*Abdul Matin,Tanjim Bin Faruk,Shrideep Pallickara,Sangmi Lee Pallickara*

Main category: cs.CV

TL;DR: HyperKD是一种新型知识蒸馏框架，通过逆向知识转移解决高光谱遥感中基础模型的光谱差异问题，提升了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在大规模无标签数据集上预训练后能够适应多种下游任务，但其直接应用于高光谱遥感仍面临光谱差异和观测数据稀缺的挑战。

Method: HyperKD采用了一种逆向知识转移方法，包括基于光谱范围的通道对齐、空间特征引导的掩码以及针对高光谱图像的增强损失函数。该方法基于Masked Autoencoder，从Prithvi基础模型中蒸馏知识到针对EnMAP高光谱图像的学生模型。

Result: 实验表明，HyperKD显著提升了MAEs中的表示学习效果，增强了重建保真度，并在土地覆盖分类、作物类型识别和土壤有机碳预测等下游任务中表现出更鲁棒的性能。

Conclusion: HyperKD通过知识蒸馏框架有效解决了基础模型在高光谱遥感图像应用中的光谱差异问题，显著提升了表示学习的效果，并在下游任务中表现出更强的鲁棒性和重建保真度。

Abstract: The proliferation of foundation models, pretrained on large-scale unlabeled
datasets, has emerged as an effective approach in creating adaptable and
reusable architectures that can be leveraged for various downstream tasks using
satellite observations. However, their direct application to hyperspectral
remote sensing remains challenging due to inherent spectral disparities and the
scarcity of available observations. In this work, we present HyperKD, a novel
knowledge distillation framework that enables transferring learned
representations from a teacher model into a student model for effective
development of a foundation model on hyperspectral images. Unlike typical
knowledge distillation frameworks, which use a complex teacher to guide a
simpler student, HyperKD enables an inverse form of knowledge transfer across
different types of spectral data, guided by a simpler teacher model. Building
upon a Masked Autoencoder, HyperKD distills knowledge from the Prithvi
foundational model into a student tailored for EnMAP hyperspectral imagery.
HyperKD addresses the inverse domain adaptation problem with spectral gaps by
introducing a feature-based strategy that includes spectral range-based channel
alignment, spatial feature-guided masking, and an enhanced loss function
tailored for hyperspectral images. HyperKD bridges the substantial spectral
domain gap, enabling the effective use of pretrained foundation models for
geospatial applications. Extensive experiments show that HyperKD significantly
improves representation learning in MAEs, leading to enhanced reconstruction
fidelity and more robust performance on downstream tasks such as land cover
classification, crop type identification, and soil organic carbon prediction,
underpinning the potential of knowledge distillation frameworks in remote
sensing analytics with hyperspectral imagery.

</details>


### [42] [Animate-X++: Universal Character Image Animation with Dynamic Backgrounds](https://arxiv.org/abs/2508.09454)
*Shuai Tan,Biao Gong,Zhuoxin Liu,Yan Wang,Xi Chen,Yifan Feng,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Animate-X++是一种通用动画框架，通过改进运动建模和背景动态性，解决了现有方法的泛化性和真实感问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在泛化性（仅适用于人类形象）和背景静态性上存在局限，限制了动画的真实感和工业应用。

Method: 提出基于DiT的通用动画框架Animate-X++，引入Pose Indicator（结合CLIP视觉特征的隐式和显式运动建模）和多任务训练策略（联合训练动画与TI2V任务）。

Result: Animate-X++在A2Bench基准测试中表现出色，支持多种角色类型和动态背景，显著提升了动画质量。

Conclusion: Animate-X++ 通过引入Pose Indicator和多任务训练策略，成功解决了现有方法在泛化性和背景动态性上的不足，显著提升了动画视频的质量和真实感。

Abstract: Character image animation, which generates high-quality videos from a
reference image and target pose sequence, has seen significant progress in
recent years. However, most existing methods only apply to human figures, which
usually do not generalize well on anthropomorphic characters commonly used in
industries like gaming and entertainment. Furthermore, previous methods could
only generate videos with static backgrounds, which limits the realism of the
videos. For the first challenge, our in-depth analysis suggests to attribute
this limitation to their insufficient modeling of motion, which is unable to
comprehend the movement pattern of the driving video, thus imposing a pose
sequence rigidly onto the target character. To this end, this paper proposes
Animate-X++, a universal animation framework based on DiT for various character
types, including anthropomorphic characters. To enhance motion representation,
we introduce the Pose Indicator, which captures comprehensive motion pattern
from the driving video through both implicit and explicit manner. The former
leverages CLIP visual features of a driving video to extract its gist of
motion, like the overall movement pattern and temporal relations among motions,
while the latter strengthens the generalization of DiT by simulating possible
inputs in advance that may arise during inference. For the second challenge, we
introduce a multi-task training strategy that jointly trains the animation and
TI2V tasks. Combined with the proposed partial parameter training, this
approach achieves not only character animation but also text-driven background
dynamics, making the videos more realistic. Moreover, we introduce a new
Animated Anthropomorphic Benchmark (A2Bench) to evaluate the performance of
Animate-X++ on universal and widely applicable animation images. Extensive
experiments demonstrate the superiority and effectiveness of Animate-X++.

</details>


### [43] [IAG: Input-aware Backdoor Attack on VLMs for Visual Grounding](https://arxiv.org/abs/2508.09456)
*Junxian Li,Beining Xu,Di Zhang*

Main category: cs.CV

TL;DR: IAG是一种针对视觉语言模型的后门攻击方法，通过自适应触发器生成器实现隐蔽攻击，实验证明其高效且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在视觉定位任务中表现出色，但其安全性问题尤其是后门攻击尚未充分探索，因此提出IAG方法以填补这一空白。

Method: 采用自适应触发器生成器，通过文本条件U-Net将攻击目标的语义信息嵌入原始图像，并结合重构损失最小化视觉差异，提出统一的攻击数据生成方法。

Result: 在InternVL-2.5-8B上ASR@0.5超过65%，在Ferret-7B和LlaVA-1.5-7B上也表现出色，且对干净样本的准确性影响极小。

Conclusion: IAG是一种新颖的输入感知后门攻击方法，能够有效操纵视觉语言模型的定位行为，且在保持攻击隐蔽性的同时，展现出较高的成功率和模型泛化能力。

Abstract: Vision-language models (VLMs) have shown significant advancements in tasks
such as visual grounding, where they localize specific objects in images based
on natural language queries and images. However, security issues in visual
grounding tasks for VLMs remain underexplored, especially in the context of
backdoor attacks. In this paper, we introduce a novel input-aware backdoor
attack method, IAG, designed to manipulate the grounding behavior of VLMs. This
attack forces the model to ground a specific target object in the input image,
regardless of the user's query. We propose an adaptive trigger generator that
embeds the semantic information of the attack target's description into the
original image using a text-conditional U-Net, thereby overcoming the
open-vocabulary attack challenge. To ensure the attack's stealthiness, we
utilize a reconstruction loss to minimize visual discrepancies between poisoned
and clean images. Additionally, we introduce a unified method for generating
attack data. IAG is evaluated theoretically and empirically, demonstrating its
feasibility and effectiveness. Notably, our ASR@0.5 on InternVL-2.5-8B reaches
over 65\% on various testing sets. IAG also shows promising potential on
manipulating Ferret-7B and LlaVA-1.5-7B with very little accuracy decrease on
clean samples. Extensive specific experiments, such as ablation study and
potential defense, also indicate the robustness and transferability of our
attack.

</details>


### [44] [RelayFormer: A Unified Local-Global Attention Framework for Scalable Image and Video Manipulation Localization](https://arxiv.org/abs/2508.09459)
*Wen Huang,Jiarui Yang,Tao Dai,Jiawei Li,Shaoxiong Zhan,Bin Wang,Shu-Tao Xia*

Main category: cs.CV

TL;DR: RelayFormer是一种跨图像和视频的统一视觉篡改定位架构，通过GLoRA机制和轻量级适配模块，实现了高效、可扩展的处理和卓越的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉篡改定位方法在跨模态泛化和高效处理高分辨率或长时输入方面存在不足。

Method: RelayFormer采用灵活的局部单元和全局-局部中继注意力（GLoRA）机制，支持可扩展且分辨率无关的处理。该框架通过轻量级适配模块与现有Transformer主干（如ViT和SegFormer）无缝集成。

Result: 在多个基准测试中，RelayFormer实现了最先进的定位性能，为可扩展和模态无关的VML设定了新基线。

Conclusion: RelayFormer通过其模块化架构和GLoRA机制，为跨模态视觉篡改定位设定了新的基准，展示了卓越的泛化能力和高效处理能力。

Abstract: Visual manipulation localization (VML) -- across both images and videos -- is
a crucial task in digital forensics that involves identifying tampered regions
in visual content. However, existing methods often lack cross-modal
generalization and struggle to handle high-resolution or long-duration inputs
efficiently.
  We propose RelayFormer, a unified and modular architecture for visual
manipulation localization across images and videos. By leveraging flexible
local units and a Global-Local Relay Attention (GLoRA) mechanism, it enables
scalable, resolution-agnostic processing with strong generalization. Our
framework integrates seamlessly with existing Transformer-based backbones, such
as ViT and SegFormer, via lightweight adaptation modules that require only
minimal architectural changes, ensuring compatibility without disrupting
pretrained representations.
  Furthermore, we design a lightweight, query-based mask decoder that supports
one-shot inference across video sequences with linear complexity. Extensive
experiments across multiple benchmarks demonstrate that our approach achieves
state-of-the-art localization performance, setting a new baseline for scalable
and modality-agnostic VML. Code is available at:
https://github.com/WenOOI/RelayFormer.

</details>


### [45] [Gen-AFFECT: Generation of Avatar Fine-grained Facial Expressions with Consistent identiTy](https://arxiv.org/abs/2508.09461)
*Hao Yu,Rupayan Mallick,Margrit Betke,Sarah Adel Bargal*

Main category: cs.CV

TL;DR: GEN-AFFECT是一个新颖的个性化头像生成框架，通过多模态扩散变换器和一致性注意力机制，实现了表情丰富且身份一致的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉细粒度表情和保持不同表情下的身份一致性方面存在不足，GEN-AFFECT旨在解决这些问题。

Method: GEN-AFFECT通过多模态扩散变换器和身份-表情表示的条件化，结合推理时的一致性注意力机制，实现了身份一致性和多样化表情生成。

Result: GEN-AFFECT能够生成具有丰富表情且身份一致的个性化头像，表现优于现有方法。

Conclusion: GEN-AFFECT在生成表情的准确性、身份保持以及跨多种细粒度表情的一致性方面优于现有最先进方法。

Abstract: Different forms of customized 2D avatars are widely used in gaming
applications, virtual communication, education, and content creation. However,
existing approaches often fail to capture fine-grained facial expressions and
struggle to preserve identity across different expressions. We propose
GEN-AFFECT, a novel framework for personalized avatar generation that generates
expressive and identity-consistent avatars with a diverse set of facial
expressions. Our framework proposes conditioning a multimodal diffusion
transformer on an extracted identity-expression representation. This enables
identity preservation and representation of a wide range of facial expressions.
GEN-AFFECT additionally employs consistent attention at inference for
information sharing across the set of generated expressions, enabling the
generation process to maintain identity consistency over the array of generated
fine-grained expressions. GEN-AFFECT demonstrates superior performance compared
to previous state-of-the-art methods on the basis of the accuracy of the
generated expressions, the preservation of the identity and the consistency of
the target identity across an array of fine-grained facial expressions.

</details>


### [46] [Event-driven Robust Fitting on Neuromorphic Hardware](https://arxiv.org/abs/2508.09466)
*Tam Ngoc-Bang Nguyen,Anh-Dzung Doan,Zhipeng Cai,Tat-Jun Chin*

Main category: cs.CV

TL;DR: 论文提出了一种基于神经形态计算的能量高效鲁棒拟合方法，通过脉冲神经网络在Intel Loihi 2上实现显著节能。


<details>
  <summary>Details</summary>
Motivation: 能量效率是AI应用中日益关键的指标，而鲁棒拟合中的能量消耗问题尚未得到充分研究。

Method: 设计了新型脉冲神经网络，结合事件驱动的模型估计方法，并采用算法策略解决硬件精度和指令集限制。

Result: 在Intel Loihi 2硬件上实现的神经形态鲁棒拟合方法，能耗仅为标准CPU的15%，且达到相同精度。

Conclusion: 该论文提出了一种基于神经形态计算范式的能量高效鲁棒拟合方法，通过新型的脉冲神经网络设计，在Intel Loihi 2硬件上实现了显著的能量节省（仅需标准CPU能耗的15%）。

Abstract: Robust fitting of geometric models is a fundamental task in many computer
vision pipelines. Numerous innovations have been produced on the topic, from
improving the efficiency and accuracy of random sampling heuristics to
generating novel theoretical insights that underpin new approaches with
mathematical guarantees. However, one aspect of robust fitting that has
received little attention is energy efficiency. This performance metric has
become critical as high energy consumption is a growing concern for AI
adoption. In this paper, we explore energy-efficient robust fitting via the
neuromorphic computing paradigm. Specifically, we designed a novel spiking
neural network for robust fitting on real neuromorphic hardware, the Intel
Loihi 2. Enabling this are novel event-driven formulations of model estimation
that allow robust fitting to be implemented in the unique architecture of Loihi
2, and algorithmic strategies to alleviate the current limited precision and
instruction set of the hardware. Results show that our neuromorphic robust
fitting consumes only a fraction (15%) of the energy required to run the
established robust fitting algorithm on a standard CPU to equivalent accuracy.

</details>


### [47] [CitySeg: A 3D Open Vocabulary Semantic Segmentation Foundation Model in City-scale Scenarios](https://arxiv.org/abs/2508.09470)
*Jialei Xu,Zizhuang Wei,Weikang You,Linyun Li,Weijian Sun*

Main category: cs.CV

TL;DR: CitySeg 是一种结合文本模态的基础模型，通过定制数据预处理、局部-全局交叉注意力和分层分类策略，显著提升了城市规模点云语义分割的性能，并首次实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在城市规模点云语义分割中因数据规模有限和域间差距导致的泛化能力不足问题。

Method: 提出了 CitySeg，一种结合文本模态的基础模型，包括定制数据预处理规则、局部-全局交叉注意力网络、分层分类策略和两阶段训练策略。

Result: 在九个封闭集基准测试中达到 SOTA 性能，并首次实现零样本泛化。

Conclusion: CitySeg 作为一种基础模型，在城市规模点云语义分割中表现出色，不仅在九个封闭集基准测试中达到了最先进的性能，还首次实现了不依赖视觉信息的零样本泛化。

Abstract: Semantic segmentation of city-scale point clouds is a critical technology for
Unmanned Aerial Vehicle (UAV) perception systems, enabling the classification
of 3D points without relying on any visual information to achieve comprehensive
3D understanding. However, existing models are frequently constrained by the
limited scale of 3D data and the domain gap between datasets, which lead to
reduced generalization capability. To address these challenges, we propose
CitySeg, a foundation model for city-scale point cloud semantic segmentation
that incorporates text modality to achieve open vocabulary segmentation and
zero-shot inference. Specifically, in order to mitigate the issue of
non-uniform data distribution across multiple domains, we customize the data
preprocessing rules, and propose a local-global cross-attention network to
enhance the perception capabilities of point networks in UAV scenarios. To
resolve semantic label discrepancies across datasets, we introduce a
hierarchical classification strategy. A hierarchical graph established
according to the data annotation rules consolidates the data labels, and the
graph encoder is used to model the hierarchical relationships between
categories. In addition, we propose a two-stage training strategy and employ
hinge loss to increase the feature separability of subcategories. Experimental
results demonstrate that the proposed CitySeg achieves state-of-the-art (SOTA)
performance on nine closed-set benchmarks, significantly outperforming existing
approaches. Moreover, for the first time, CitySeg enables zero-shot
generalization in city-scale point cloud scenarios without relying on visual
information.

</details>


### [48] [Leveraging Failed Samples: A Few-Shot and Training-Free Framework for Generalized Deepfake Detection](https://arxiv.org/abs/2508.09475)
*Shibo Yao,Renshuai Tao,Xiaolong Zheng,Chao Liang,Chunjie Zhang*

Main category: cs.CV

TL;DR: FTNet是一种无需训练的少样本深度伪造检测方法，仅用一份假样本即可分类，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度伪造检测研究通常将未知样本检测视为零样本任务，但在实际应用中，当模型对未知样本表现不佳时，这些样本仍可用于分析。因此，应将其视为少样本任务，有效利用少量样本可以显著提升性能。

Method: 提出了Few-shot Training-free Network (FTNet)，一种简单但有效的方法，仅使用评估集中的一份假样本进行分类，无需训练或参数更新。测试样本通过与已知假样本和真实样本进行比较，根据最近邻样本的类别进行分类。

Result: FTNet在29种生成模型的AI生成图像上实现了新的SoTA性能，平均比现有方法提高了8.7%。

Conclusion: 本研究提出了一种新的视角：当模型在少样本上泛化能力不足时，利用失败的样本可以显著提升性能。FTNet在29种不同生成模型的AI生成图像上取得了新的SoTA性能，平均比现有方法提高了8.7%。

Abstract: Recent deepfake detection studies often treat unseen sample detection as a
``zero-shot" task, training on images generated by known models but
generalizing to unknown ones. A key real-world challenge arises when a model
performs poorly on unknown samples, yet these samples remain available for
analysis. This highlights that it should be approached as a ``few-shot" task,
where effectively utilizing a small number of samples can lead to significant
improvement. Unlike typical few-shot tasks focused on semantic understanding,
deepfake detection prioritizes image realism, which closely mirrors real-world
distributions. In this work, we propose the Few-shot Training-free Network
(FTNet) for real-world few-shot deepfake detection. Simple yet effective, FTNet
differs from traditional methods that rely on large-scale known data for
training. Instead, FTNet uses only one fake samplefrom an evaluation set,
mimicking the scenario where new samples emerge in the real world and can be
gathered for use, without any training or parameter updates. During evaluation,
each test sample is compared to the known fake and real samples, and it is
classified based on the category of the nearest sample. We conduct a
comprehensive analysis of AI-generated images from 29 different generative
models and achieve a new SoTA performance, with an average improvement of 8.7\%
compared to existing methods. This work introduces a fresh perspective on
real-world deepfake detection: when the model struggles to generalize on a
few-shot sample, leveraging the failed samples leads to better performance.

</details>


### [49] [From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts](https://arxiv.org/abs/2508.09476)
*Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: 本文提出MoFE和LFA数据集，解决了视频生成中身份保持和大角度面部数据不足的问题，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在大角度面部情况下难以保持身份，主要由于缺乏有效的身份特征整合机制和大角度面部数据的不足。

Method: 引入Mixture of Facial Experts (MoFE)动态结合三种专家的互补线索，并设计了一个数据预处理流程，包括Face Constraints和Identity Consistency，以增强数据集的质量。

Result: 实验结果表明，该方法在LFA基准测试中显著优于现有SOTA方法，尤其是在面部相似度、面部FID和CLIP语义对齐方面。

Conclusion: 本文提出的方法通过Mixture of Facial Experts (MoFE)和定制的LFA数据集，显著提升了视频生成模型在大角度面部情况下的身份保持能力，并在多个指标上优于现有技术。

Abstract: Current video generation models struggle with identity preservation under
large facial angles, primarily facing two challenges: the difficulty in
exploring an effective mechanism to integrate identity features into DiT
structure, and the lack of targeted coverage of large facial angles in existing
open-source video datasets. To address these, we present two key innovations.
First, we introduce a Mixture of Facial Experts (MoFE) that dynamically
combines complementary cues from three specialized experts, each designed to
capture distinct but mutually reinforcing aspects of facial attributes. The
identity expert captures cross-pose identity-sensitive features, the semantic
expert extracts high-level visual semantxics, and the detail expert preserves
pixel-level features (e.g., skin texture, color gradients). Furthermore, to
mitigate dataset limitations, we have tailored a data processing pipeline
centered on two key aspects: Face Constraints and Identity Consistency. Face
Constraints ensure facial angle diversity and a high proportion of facial
regions, while Identity Consistency preserves coherent person-specific features
across temporal sequences, collectively addressing the scarcity of large facial
angles and identity-stable training data in existing datasets. Leveraging this
pipeline, we have curated and refined a Large Face Angles (LFA) Dataset from
existing open-source human video datasets, comprising 460K video clips with
annotated facial angles. Experimental results on the LFA benchmark demonstrate
that our method, empowered by the LFA dataset, significantly outperforms prior
SOTA methods in face similarity, face FID, and CLIP semantic alignment. The
code and dataset will be made publicly available at
https://github.com/rain152/LFA-Video-Generation.

</details>


### [50] [CLIP-Flow: A Universal Discriminator for AI-Generated Images Inspired by Anomaly Detection](https://arxiv.org/abs/2508.09477)
*Zhipeng Yuan,Kai Wang,Weize Quan,Dong-Ming Yan,Tieru Wu*

Main category: cs.CV

TL;DR: 提出了一种通用的AI生成图像检测器，通过无监督学习和代理图像训练，有效检测多种生成模型生成的图像。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成模型的快速发展，AI生成图像（AIIs）的视觉质量越来越接近自然图像，这引发了安全隐患。传统的AII检测器通常采用自然图像和AI生成图像的分类流程，对于未见过的生成模型生成的AIIs检测性能有限。

Method: 使用预训练的CLIP编码器作为特征提取器，设计了一个类似于归一化流的无监督模型。训练过程中不使用AI生成图像，而是使用代理图像（如通过对自然图像进行光谱修改操作获得）进行训练，通过最小化代理图像的可能性（可选地结合最大化自然图像的可能性）来训练模型。

Result: 广泛的实验表明，该方法在多种图像生成器生成的AIIs上具有有效性。

Conclusion: 该方法通过异常检测的视角提出了一种通用的AI生成图像检测器，无需访问任何AI生成图像，仅通过无监督学习即可学习可泛化的表示，实验证明了其在多种图像生成器上的有效性。

Abstract: With the rapid advancement of AI generative models, the visual quality of
AI-generated images (AIIs) has become increasingly close to natural images,
which inevitably raises security concerns. Most AII detectors often employ the
conventional image classification pipeline with natural images and AIIs
(generated by a generative model), which can result in limited detection
performance for AIIs from unseen generative models. To solve this, we proposed
a universal AI-generated image detector from the perspective of anomaly
detection. Our discriminator does not need to access any AIIs and learn a
generalizable representation with unsupervised learning. Specifically, we use
the pre-trained CLIP encoder as the feature extractor and design a normalizing
flow-like unsupervised model. Instead of AIIs, proxy images, e.g., obtained by
applying a spectral modification operation on natural images, are used for
training. Our models are trained by minimizing the likelihood of proxy images,
optionally combined with maximizing the likelihood of natural images. Extensive
experiments demonstrate the effectiveness of our method on AIIs produced by
various image generators.

</details>


### [51] [Episodic Memory Representation for Long-form Video Understanding](https://arxiv.org/abs/2508.09486)
*Yun Wang,Long Zhang,Jingren Liu,Jiaqi Yan,Zhanjie Zhang,Jiahao Zheng,Xun Yang,Dapeng Wu,Xiangyu Chen,Xuelong Li*

Main category: cs.CV

TL;DR: Video-EM通过模拟人类情景记忆，优化长视频理解，减少冗余帧，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频大语言模型在长视频理解中因上下文窗口限制而忽略时空关系的问题。

Method: 提出Video-EM框架，通过模拟人类情景记忆，建模时空关系，并利用链式思维（CoT）迭代筛选关键帧。

Result: 在Video-MME、EgoSchema、HourVideo和LVBench基准测试中，性能提升4-9%，且使用更少帧数。

Conclusion: Video-EM框架通过模拟人类情景记忆，显著提升了长视频理解的性能，减少了冗余帧的使用，并在多个基准测试中取得了优异的成绩。

Abstract: Video Large Language Models (Video-LLMs) excel at general video understanding
but struggle with long-form videos due to context window limits. Consequently,
recent approaches focus on keyframe retrieval, condensing lengthy videos into a
small set of informative frames. Despite their practicality, these methods
simplify the problem to static text image matching, overlooking spatio temporal
relationships crucial for capturing scene transitions and contextual
continuity, and may yield redundant keyframes with limited information,
diluting salient cues essential for accurate video question answering. To
address these limitations, we introduce Video-EM, a training free framework
inspired by the principles of human episodic memory, designed to facilitate
robust and contextually grounded reasoning. Rather than treating keyframes as
isolated visual entities, Video-EM explicitly models them as temporally ordered
episodic events, capturing both spatial relationships and temporal dynamics
necessary for accurately reconstructing the underlying narrative. Furthermore,
the framework leverages chain of thought (CoT) thinking with LLMs to
iteratively identify a minimal yet highly informative subset of episodic
memories, enabling efficient and accurate question answering by Video-LLMs.
Extensive evaluations on the Video-MME, EgoSchema, HourVideo, and LVBench
benchmarks confirm the superiority of Video-EM, which achieves highly
competitive results with performance gains of 4-9 percent over respective
baselines while utilizing fewer frames.

</details>


### [52] [GazeLT: Visual attention-guided long-tailed disease classification in chest radiographs](https://arxiv.org/abs/2508.09478)
*Moinak Bhattacharya,Gagandeep Singh,Shubham Jain,Prateek Prasanna*

Main category: cs.CV

TL;DR: GazeLT利用放射科医生的眼动模式，通过整合和解构机制提升长尾疾病分类性能，在公开数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 放射科医生的视觉注意力在图像解读过程中具有动态变化的特点，且不仅关注主要疾病模式，还会关注次要/偶发发现（部分属于长尾类别），这些信息对提升自动化图像解读至关重要。

Method: GazeLT采用了一种整合和解构机制，利用放射科医生的眼动模式来捕捉疾病相关信息的细粒度和粗粒度特征，并将其融入深度学习框架。

Result: GazeLT在NIH-CXR-LT和MIMIC-CXR-LT数据集上的平均准确率分别比最佳长尾损失方法高4.1%，比基于视觉注意力的基线方法高21.7%。

Conclusion: GazeLT通过整合和解构机制利用视觉搜索过程的时间特性，显著提升了长尾疾病分类的性能，在NIH-CXR-LT和MIMIC-CXR-LT数据集上表现优于现有方法。

Abstract: In this work, we present GazeLT, a human visual attention
integration-disintegration approach for long-tailed disease classification. A
radiologist's eye gaze has distinct patterns that capture both fine-grained and
coarser level disease related information. While interpreting an image, a
radiologist's attention varies throughout the duration; it is critical to
incorporate this into a deep learning framework to improve automated image
interpretation. Another important aspect of visual attention is that apart from
looking at major/obvious disease patterns, experts also look at
minor/incidental findings (few of these constituting long-tailed classes)
during the course of image interpretation. GazeLT harnesses the temporal aspect
of the visual search process, via an integration and disintegration mechanism,
to improve long-tailed disease classification. We show the efficacy of GazeLT
on two publicly available datasets for long-tailed disease classification,
namely the NIH-CXR-LT (n=89237) and the MIMIC-CXR-LT (n=111898) datasets.
GazeLT outperforms the best long-tailed loss by 4.1% and the visual
attention-based baseline by 21.7% in average accuracy metrics for these
datasets. Our code is available at https://github.com/lordmoinak1/gazelt.

</details>


### [53] [SkySplat: Generalizable 3D Gaussian Splatting from Multi-Temporal Sparse Satellite Images](https://arxiv.org/abs/2508.09479)
*Xuejun Huang,Xinyi Liu,Yi Wan,Zhi Zheng,Bin Zhang,Mingtao Xiong,Yingying Pei,Yongjun Zhang*

Main category: cs.CV

TL;DR: SkySplat 是一种自监督框架，通过集成 RPC 模型和改进稀疏几何线索利用，显著提升了卫星图像的三维重建效率和精度。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏视角卫星图像三维重建中现有方法不兼容 RPC 模型、泛化能力有限的问题，以及多时相卫星图像中几何约束不足、瞬态物体和辐射不一致的挑战。

Method: SkySplat 结合了 Cross-Self Consistency Module (CSCM) 和多视角一致性聚合策略，利用 RGB 图像和辐射鲁棒的相对高度监督，无需地面真实高度图。

Result: SkySplat 在 DFC19 数据集上将 MAE 从 13.18 米降低到 1.80 米，并在 MVS3D 基准测试中展示了强大的跨数据集泛化能力。

Conclusion: SkySplat 是一种高效的自监督框架，通过将 RPC 模型集成到通用 3DGS 流程中，显著提升了稀疏几何线索的利用效率，实现了高精度的三维场景重建。

Abstract: Three-dimensional scene reconstruction from sparse-view satellite images is a
long-standing and challenging task. While 3D Gaussian Splatting (3DGS) and its
variants have recently attracted attention for its high efficiency, existing
methods remain unsuitable for satellite images due to incompatibility with
rational polynomial coefficient (RPC) models and limited generalization
capability. Recent advances in generalizable 3DGS approaches show potential,
but they perform poorly on multi-temporal sparse satellite images due to
limited geometric constraints, transient objects, and radiometric
inconsistencies. To address these limitations, we propose SkySplat, a novel
self-supervised framework that integrates the RPC model into the generalizable
3DGS pipeline, enabling more effective use of sparse geometric cues for
improved reconstruction. SkySplat relies only on RGB images and
radiometric-robust relative height supervision, thereby eliminating the need
for ground-truth height maps. Key components include a Cross-Self Consistency
Module (CSCM), which mitigates transient object interference via
consistency-based masking, and a multi-view consistency aggregation strategy
that refines reconstruction results. Compared to per-scene optimization
methods, SkySplat achieves an 86 times speedup over EOGS with higher accuracy.
It also outperforms generalizable 3DGS baselines, reducing MAE from 13.18 m to
1.80 m on the DFC19 dataset significantly, and demonstrates strong
cross-dataset generalization on the MVS3D benchmark.

</details>


### [54] [Generation of Indian Sign Language Letters, Numbers, and Words](https://arxiv.org/abs/2508.09522)
*Ajeet Kumar Yadav,Nishant Kumar,Rathna G N*

Main category: cs.CV

TL;DR: 研究提出了一种结合ProGAN和SAGAN的GAN变体，用于生成高质量印度手语图像，性能优于传统方法，并发布了相关数据集。


<details>
  <summary>Details</summary>
Motivation: 手语是听力障碍人士的重要交流工具，但手语生成技术仍待探索。现有模型在分辨率和细节上存在不足，需要一种能够平衡两者的方法。

Method: 研究开发了一种结合Progressive Growing of Generative Adversarial Network (ProGAN)和Self-Attention Generative Adversarial Network (SAGAN)的GAN变体，用于生成高分辨率、特征丰富的类别条件手语图像。

Result: 改进后的基于注意力的模型在生成印度手语图像时表现优异，Inception Score和Fréchet Inception Distance分别提高了3.2和30.12。

Conclusion: 该研究提出了一种结合ProGAN和SAGAN的GAN变体，成功生成了高质量的印度手语图像，并在Inception Score和Fréchet Inception Distance上优于传统ProGAN。同时，发布了一个包含印度手语字母、数字和129个单词的大规模数据集。

Abstract: Sign language, which contains hand movements, facial expressions and bodily
gestures, is a significant medium for communicating with hard-of-hearing
people. A well-trained sign language community communicates easily, but those
who don't know sign language face significant challenges. Recognition and
generation are basic communication methods between hearing and hard-of-hearing
individuals. Despite progress in recognition, sign language generation still
needs to be explored. The Progressive Growing of Generative Adversarial Network
(ProGAN) excels at producing high-quality images, while the Self-Attention
Generative Adversarial Network (SAGAN) generates feature-rich images at medium
resolutions. Balancing resolution and detail is crucial for sign language image
generation. We are developing a Generative Adversarial Network (GAN) variant
that combines both models to generate feature-rich, high-resolution, and
class-conditional sign language images. Our modified Attention-based model
generates high-quality images of Indian Sign Language letters, numbers, and
words, outperforming the traditional ProGAN in Inception Score (IS) and
Fr\'echet Inception Distance (FID), with improvements of 3.2 and 30.12,
respectively. Additionally, we are publishing a large dataset incorporating
high-quality images of Indian Sign Language alphabets, numbers, and 129 words.

</details>


### [55] [SARE: Semantic-Aware Reconstruction Error for Generalizable Diffusion-Generated Image Detection](https://arxiv.org/abs/2508.09487)
*Ju Yeon Kang,Jaehong Park,Semin Kim,Ji Won Yoon,Nam Soo Kim*

Main category: cs.CV

TL;DR: SARE通过量化图像与标题重建的语义差异，提升了假图像检测的泛化能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在面对未见过的生成模型时性能下降，因为它们依赖模型特定的伪影。假图像通常与标题的相似性高于真实图像，这一现象被用来开发更通用的检测方法。

Method: 提出了一种名为语义感知重建误差（SARE）的新表示方法，通过测量图像与其标题引导重建之间的语义差异来检测假图像。

Result: SARE方法在GenImage和CommunityForensics等基准测试中表现优于现有基线，展示了强大的泛化能力。

Conclusion: 提出的SARE方法通过量化图像与标题引导重建之间的语义差异，显著提升了针对不同生成模型的鲁棒检测性能。

Abstract: Recently, diffusion-generated image detection has gained increasing
attention, as the rapid advancement of diffusion models has raised serious
concerns about their potential misuse. While existing detection methods have
achieved promising results, their performance often degrades significantly when
facing fake images from unseen, out-of-distribution (OOD) generative models,
since they primarily rely on model-specific artifacts. To address this
limitation, we explore a fundamental property commonly observed in fake images.
Motivated by the observation that fake images tend to exhibit higher similarity
to their captions than real images, we propose a novel representation, namely
Semantic-Aware Reconstruction Error (SARE), that measures the semantic
difference between an image and its caption-guided reconstruction. The
hypothesis behind SARE is that real images, whose captions often fail to fully
capture their complex visual content, may undergo noticeable semantic shifts
during the caption-guided reconstruction process. In contrast, fake images,
which closely align with their captions, show minimal semantic changes. By
quantifying these semantic shifts, SARE can be utilized as a discriminative
feature for robust detection across diverse generative models. We empirically
demonstrate that the proposed method exhibits strong generalization,
outperforming existing baselines on benchmarks including GenImage and
CommunityForensics.

</details>


### [56] [COXNet: Cross-Layer Fusion with Adaptive Alignment and Scale Integration for RGBT Tiny Object Detection](https://arxiv.org/abs/2508.09533)
*Peiran Peng,Tingfa Xu,Liqiang Song,Mengqi Zhu,Yuqiang Fang,Jianan Li*

Main category: cs.CV

TL;DR: COXNet通过跨模态特征融合和动态对齐技术，显著提升了无人机场景下RGBT微小物体检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 在无人机场景中，可见光和热成像的多模态图像存在空间错位、低光照、遮挡和杂乱背景等问题，现有方法难以有效利用两种模态的互补信息。

Method: COXNet提出了三个核心创新：i) 跨层融合模块，融合可见光的高层特征和热成像的低层特征；ii) 动态对齐与尺度细化模块，纠正跨模态空间错位并保留多尺度特征；iii) 使用GeoShape相似度度量的优化标签分配策略。

Result: COXNet在RGBTDronePerson数据集上相比现有最优方法提升了3.32%的mAP$_{50}$。

Conclusion: COXNet通过其创新的跨层融合模块、动态对齐与尺度细化模块以及优化的标签分配策略，在RGBTDronePerson数据集上实现了3.32%的mAP$_{50}$提升，显著提升了复杂环境中微小物体的检测性能。

Abstract: Detecting tiny objects in multimodal Red-Green-Blue-Thermal (RGBT) imagery is
a critical challenge in computer vision, particularly in surveillance, search
and rescue, and autonomous navigation. Drone-based scenarios exacerbate these
challenges due to spatial misalignment, low-light conditions, occlusion, and
cluttered backgrounds. Current methods struggle to leverage the complementary
information between visible and thermal modalities effectively. We propose
COXNet, a novel framework for RGBT tiny object detection, addressing these
issues through three core innovations: i) the Cross-Layer Fusion Module, fusing
high-level visible and low-level thermal features for enhanced semantic and
spatial accuracy; ii) the Dynamic Alignment and Scale Refinement module,
correcting cross-modal spatial misalignments and preserving multi-scale
features; and iii) an optimized label assignment strategy using the GeoShape
Similarity Measure for better localization. COXNet achieves a 3.32\% mAP$_{50}$
improvement on the RGBTDronePerson dataset over state-of-the-art methods,
demonstrating its effectiveness for robust detection in complex environments.

</details>


### [57] [CWFBind: Geometry-Awareness for Fast and Accurate Protein-Ligand Docking](https://arxiv.org/abs/2508.09499)
*Liyan Jia,Chuan-Xian Ren,Hong Yan*

Main category: cs.CV

TL;DR: CWFBind是一种基于局部曲率特征的对接方法，通过改进几何表示和加权机制，显著提高了配体-蛋白结合预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的对接方法忽视了几何信息，导致口袋定位和结合构象不准确。CWFBind旨在通过引入局部曲率特征和改进的加权机制来解决这些问题。

Method: CWFBind结合了局部曲率描述符和度感知加权机制，改进了特征提取和消息传递过程，并采用了配体感知动态半径策略和增强的损失函数来应对口袋预测中的类别不平衡问题。

Result: CWFBind在多个对接基准测试中表现出色，实现了准确性和效率的平衡。

Conclusion: CWFBind通过整合局部曲率特征和动态半径策略，在药物设计中的配体-蛋白结合预测方面实现了高准确性和效率的平衡。

Abstract: Accurately predicting the binding conformation of small-molecule ligands to
protein targets is a critical step in rational drug design. Although recent
deep learning-based docking surpasses traditional methods in speed and
accuracy, many approaches rely on graph representations and language
model-inspired encoders while neglecting critical geometric information,
resulting in inaccurate pocket localization and unrealistic binding
conformations. In this study, we introduce CWFBind, a weighted, fast, and
accurate docking method based on local curvature features. Specifically, we
integrate local curvature descriptors during the feature extraction phase to
enrich the geometric representation of both proteins and ligands, complementing
existing chemical, sequence, and structural features. Furthermore, we embed
degree-aware weighting mechanisms into the message passing process, enhancing
the model's ability to capture spatial structural distinctions and interaction
strengths. To address the class imbalance challenge in pocket prediction,
CWFBind employs a ligand-aware dynamic radius strategy alongside an enhanced
loss function, facilitating more precise identification of binding regions and
key residues. Comprehensive experimental evaluations demonstrate that CWFBind
achieves competitive performance across multiple docking benchmarks, offering a
balanced trade-off between accuracy and efficiency.

</details>


### [58] [GoViG: Goal-Conditioned Visual Navigation Instruction Generation](https://arxiv.org/abs/2508.09547)
*Fengyi Wu,Yifei Dong,Zhi-Qi Cheng,Yilong Dai,Guangyu Chen,Hang Wang,Qi Dai,Alexander G. Hauptmann*

Main category: cs.CV

TL;DR: GoViG是一种仅依赖视觉数据的导航指令生成方法，通过分解任务并整合多模态模型，显著提升了在非结构化环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖结构化输入（如语义标注或环境地图），限制了在未见和非结构化环境中的适应性。GoViG仅利用原始视觉数据，提升适应性。

Method: GoViG将任务分解为视觉预测和指令生成两个子任务，采用自回归多模态大语言模型，并结合单次和交错推理策略。

Result: 实验结果表明，GoViG在BLEU-4和CIDEr分数上显著优于现有方法，并展现出强大的跨域泛化能力。

Conclusion: GoViG通过分解视觉导航指令生成任务为视觉预测和指令生成两个子任务，并整合到自回归多模态大语言模型中，显著提升了在未见和非结构化环境中的适应能力。

Abstract: We introduce Goal-Conditioned Visual Navigation Instruction Generation
(GoViG), a new task that aims to autonomously generate precise and contextually
coherent navigation instructions solely from egocentric visual observations of
initial and goal states. Unlike conventional approaches that rely on structured
inputs such as semantic annotations or environmental maps, GoViG exclusively
leverages raw egocentric visual data, substantially improving its adaptability
to unseen and unstructured environments. Our method addresses this task by
decomposing it into two interconnected subtasks: (1) visual forecasting, which
predicts intermediate visual states bridging the initial and goal views; and
(2) instruction generation, which synthesizes linguistically coherent
instructions grounded in both observed and anticipated visuals. These subtasks
are integrated within an autoregressive multimodal large language model trained
with tailored objectives to ensure spatial accuracy and linguistic clarity.
Furthermore, we introduce two complementary multimodal reasoning strategies,
one-pass and interleaved reasoning, to mimic incremental human cognitive
processes during navigation. To evaluate our method, we propose the R2R-Goal
dataset, combining diverse synthetic and real-world trajectories. Empirical
results demonstrate significant improvements over state-of-the-art methods,
achieving superior BLEU-4 and CIDEr scores along with robust cross-domain
generalization.

</details>


### [59] [SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking](https://arxiv.org/abs/2508.09524)
*Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao*

Main category: cs.CV

TL;DR: 本文首次系统研究单目标跟踪中的相似物体干扰（SOI），构建SOIBench基准并提出新范式，利用视觉语言模型（VLM）显著提升跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 相似物体干扰（SOI）是单目标跟踪（SOT）中长期被忽视但关键的性能瓶颈，需系统研究和量化。

Method: 通过在线干扰掩蔽（OIM）实验量化SOI影响，构建SOIBench基准，利用多跟踪器集体判断自动挖掘SOI帧并引入多级注释协议生成精确语义引导文本。提出一种新范式，使用大规模视觉语言模型（VLM）作为外部认知引擎。

Result: 消除干扰源可显著提升所有SOTA跟踪器性能（AUC增益高达4.35）。现有视觉语言跟踪（VLT）方法未能有效利用语义认知引导（AUC变化-0.26至+0.71），而新范式在语义引导下实现显著改进（AUC增益高达0.93）。

Conclusion: SOIBench 作为首个针对相似物体干扰（SOI）的语义认知引导基准，有望成为标准化评估平台，推动语义认知跟踪研究，并为跟踪研究社区贡献新见解。

Abstract: In this paper, we present the first systematic investigation and
quantification of Similar Object Interference (SOI), a long-overlooked yet
critical bottleneck in Single Object Tracking (SOT). Through controlled Online
Interference Masking (OIM) experiments, we quantitatively demonstrate that
eliminating interference sources leads to substantial performance improvements
(AUC gains up to 4.35) across all SOTA trackers, directly validating SOI as a
primary constraint for robust tracking and highlighting the feasibility of
external cognitive guidance. Building upon these insights, we adopt natural
language as a practical form of external guidance, and construct SOIBench-the
first semantic cognitive guidance benchmark specifically targeting SOI
challenges. It automatically mines SOI frames through multi-tracker collective
judgment and introduces a multi-level annotation protocol to generate precise
semantic guidance texts. Systematic evaluation on SOIBench reveals a striking
finding: existing vision-language tracking (VLT) methods fail to effectively
exploit semantic cognitive guidance, achieving only marginal improvements or
even performance degradation (AUC changes of -0.26 to +0.71). In contrast, we
propose a novel paradigm employing large-scale vision-language models (VLM) as
external cognitive engines that can be seamlessly integrated into arbitrary RGB
trackers. This approach demonstrates substantial improvements under semantic
cognitive guidance (AUC gains up to 0.93), representing a significant
advancement over existing VLT methods. We hope SOIBench will serve as a
standardized evaluation platform to advance semantic cognitive tracking
research and contribute new insights to the tracking research community.

</details>


### [60] [Learning Spatial Decay for Vision Transformers](https://arxiv.org/abs/2508.09525)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: SDT通过上下文感知门控机制动态生成数据依赖的空间衰减，显著提升了视觉Transformer在空间任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉Transformer的自注意力机制缺乏显式的空间归纳偏置，导致在空间结构化任务中表现不佳。现有方法基于固定距离度量的数据无关空间衰减限制了适应性。受大语言模型中内容感知门控机制的启发，研究者希望将数据依赖的空间衰减成功应用于2D视觉Transformer。

Method: 提出了一种称为空间衰减Transformer（SDT）的新方法，结合了上下文感知门控（CAG）机制，通过动态生成数据依赖的衰减来调节空间注意力。该方法通过曼哈顿距离空间先验与学习内容表示的融合框架，解决了1D到2D的适应问题。

Result: 在ImageNet-1K分类和生成任务上的广泛实验表明，SDT方法在强基线模型上取得了持续的性能提升。

Conclusion: 本研究通过引入数据依赖的空间衰减机制（SDT）和上下文感知门控（CAG），成功提升了视觉Transformer在空间结构化任务中的性能，为空间注意力机制提供了新的范式。

Abstract: Vision Transformers (ViTs) have revolutionized computer vision, yet their
self-attention mechanism lacks explicit spatial inductive biases, leading to
suboptimal performance on spatially-structured tasks. Existing approaches
introduce data-independent spatial decay based on fixed distance metrics,
applying uniform attention weighting regardless of image content and limiting
adaptability to diverse visual scenarios. Inspired by recent advances in large
language models where content-aware gating mechanisms (e.g., GLA, HGRN2, FOX)
significantly outperform static alternatives, we present the first successful
adaptation of data-dependent spatial decay to 2D vision transformers. We
introduce \textbf{Spatial Decay Transformer (SDT)}, featuring a novel
Context-Aware Gating (CAG) mechanism that generates dynamic, data-dependent
decay for patch interactions. Our approach learns to modulate spatial attention
based on both content relevance and spatial proximity. We address the
fundamental challenge of 1D-to-2D adaptation through a unified spatial-content
fusion framework that integrates manhattan distance-based spatial priors with
learned content representations. Extensive experiments on ImageNet-1K
classification and generation tasks demonstrate consistent improvements over
strong baselines. Our work establishes data-dependent spatial decay as a new
paradigm for enhancing spatial attention in vision transformers.

</details>


### [61] [Hierarchical Brain Structure Modeling for Predicting Genotype of Glioma](https://arxiv.org/abs/2508.09593)
*Haotian Tang,Jianwei Chen,Xinrui Tang,Yunjia Wu,Zhengyang Miao,Chao Li*

Main category: cs.CV

TL;DR: Hi-SMGNN通过多尺度整合结构和形态连接组，提升IDH突变预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于功能MRI的低可用性和噪声，且忽视大脑的层次结构和多尺度交互。

Method: 提出Hi-SMGNN框架，结合多模态交互模块（Siamese网络和跨模态注意力）、多尺度特征融合机制及个性化模块划分策略。

Result: 在UCSF-PDGM数据集上，Hi-SMGNN优于基线和最先进模型，预测效果更优。

Conclusion: Hi-SMGNN通过整合结构和形态连接组，从区域到模块层次的多尺度交互，显著提升了IDH突变预测的准确性和鲁棒性。

Abstract: Isocitrate DeHydrogenase (IDH) mutation status is a crucial biomarker for
glioma prognosis. However, current prediction methods are limited by the low
availability and noise of functional MRI. Structural and morphological
connectomes offer a non-invasive alternative, yet existing approaches often
ignore the brain's hierarchical organisation and multiscale interactions. To
address this, we propose Hi-SMGNN, a hierarchical framework that integrates
structural and morphological connectomes from regional to modular levels. It
features a multimodal interaction module with a Siamese network and cross-modal
attention, a multiscale feature fusion mechanism for reducing redundancy, and a
personalised modular partitioning strategy to enhance individual specificity
and interpretability. Experiments on the UCSF-PDGM dataset demonstrate that
Hi-SMGNN outperforms baseline and state-of-the-art models, showing improved
robustness and effectiveness in IDH mutation prediction.

</details>


### [62] [Physics-guided Deep Unfolding Network for Enhanced Kronecker Compressive sensing](https://arxiv.org/abs/2508.09528)
*Gang Qu,Ping Wang,Siming Zheng,Xin Yuan*

Main category: cs.CV

TL;DR: 提出AKCS模型和MACA机制，集成到MEUNet中，显著提升了图像压缩感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工作在感知阶段缺乏非相干压缩测量，在重建阶段缺乏显式测量表示，限制了整体性能。本文旨在解决这两个问题。

Method: 提出了一种非对称Kronecker CS（AKCS）模型，并理论上证明了其比之前的Kronecker CS具有更好的非相干性，同时复杂度增加最小。此外，提出了一种测量感知交叉注意力（MACA）机制来学习隐式测量表示。

Result: MEUNet在重建精度和推理速度上取得了最先进的性能。

Conclusion: MEUNet集成了AKCS模型和MACA机制，在重建精度和推理速度上达到了最先进的性能。

Abstract: Deep networks have achieved remarkable success in image compressed sensing
(CS) task, namely reconstructing a high-fidelity image from its compressed
measurement. However, existing works are deficient inincoherent compressed
measurement at sensing phase and implicit measurement representations at
reconstruction phase, limiting the overall performance. In this work, we answer
two questions: 1) how to improve the measurement incoherence for decreasing the
ill-posedness; 2) how to learn informative representations from measurements.
To this end, we propose a novel asymmetric Kronecker CS (AKCS) model and
theoretically present its better incoherence than previous Kronecker CS with
minimal complexity increase. Moreover, we reveal that the unfolding networks'
superiority over non-unfolding ones result from sufficient gradient descents,
called explicit measurement representations. We propose a measurement-aware
cross attention (MACA) mechanism to learn implicit measurement representations.
We integrate AKCS and MACA into widely-used unfolding architecture to get a
measurement-enhanced unfolding network (MEUNet). Extensive experiences
demonstrate that our MEUNet achieves state-of-the-art performance in
reconstruction accuracy and inference speed.

</details>


### [63] [MInDI-3D: Iterative Deep Learning in 3D for Sparse-view Cone Beam Computed Tomography](https://arxiv.org/abs/2508.09616)
*Daniel Barco,Marc Stadelmann,Martin Oswald,Ivo Herzig,Lukas Lichtensteiger,Pascal Paysan,Igor Peterlik,Michal Walczak,Bjoern Menze,Frank-Peter Schilling*

Main category: cs.CV

TL;DR: MInDI-3D是首个3D条件扩散模型，用于稀疏视图CBCT伪影去除，显著减少辐射暴露并在临床评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 减少医学成像中的辐射暴露，并解决稀疏视图CBCT伪影问题。

Method: 扩展了'InDI'概念，从2D到3D体积方法，实现了一个迭代去噪过程，直接从稀疏视图输入中细化CBCT体积。

Result: MInDI-3D在CT-RATE伪CBCT测试集上实现了12.96 (6.10) dB的PSNR增益，并允许8倍的辐射暴露减少。

Conclusion: MInDI-3D是一种有效的3D条件扩散模型，能够显著减少CBCT成像中的辐射暴露，并在临床评估中表现出优越性能。

Abstract: We present MInDI-3D (Medical Inversion by Direct Iteration in 3D), the first
3D conditional diffusion-based model for real-world sparse-view Cone Beam
Computed Tomography (CBCT) artefact removal, aiming to reduce imaging radiation
exposure. A key contribution is extending the "InDI" concept from 2D to a full
3D volumetric approach for medical images, implementing an iterative denoising
process that refines the CBCT volume directly from sparse-view input. A further
contribution is the generation of a large pseudo-CBCT dataset (16,182) from
chest CT volumes of the CT-RATE public dataset to robustly train MInDI-3D. We
performed a comprehensive evaluation, including quantitative metrics,
scalability analysis, generalisation tests, and a clinical assessment by 11
clinicians. Our results show MInDI-3D's effectiveness, achieving a 12.96 (6.10)
dB PSNR gain over uncorrected scans with only 50 projections on the CT-RATE
pseudo-CBCT (independent real-world) test set and enabling an 8x reduction in
imaging radiation exposure. We demonstrate its scalability by showing that
performance improves with more training data. Importantly, MInDI-3D matches the
performance of a 3D U-Net on real-world scans from 16 cancer patients across
distortion and task-based metrics. It also generalises to new CBCT scanner
geometries. Clinicians rated our model as sufficient for patient positioning
across all anatomical sites and found it preserved lung tumour boundaries well.

</details>


### [64] [Iterative Volume Fusion for Asymmetric Stereo Matching](https://arxiv.org/abs/2508.09543)
*Yuanting Gao,Linghao Shen*

Main category: cs.CV

TL;DR: Proposes IVF-AStereo, a two-phase network for asymmetric stereo matching, leveraging fused cost volumes to handle visual asymmetry effectively.


<details>
  <summary>Details</summary>
Motivation: The rise of asymmetric multi-camera systems (e.g., tele-wide cameras) challenges the traditional assumption of symmetric visual properties in stereo matching, necessitating a new approach to handle visual asymmetry.

Method: The paper introduces the two-phase Iterative Volume Fusion network (IVF-AStereo), which first refines the correlation volume using an aggregated concatenation volume, then fuses both volumes to enhance fine details.

Result: Extensive experiments on benchmark datasets and ablation studies confirm the method's effectiveness in asymmetric stereo scenarios with resolution and color degradation.

Conclusion: The proposed IVF-AStereo method effectively addresses the challenges of asymmetric stereo matching by leveraging both aggregated concatenation and correlation volumes, demonstrating robust performance in scenarios with significant visual asymmetry.

Abstract: Stereo matching is vital in 3D computer vision, with most algorithms assuming
symmetric visual properties between binocular visions. However, the rise of
asymmetric multi-camera systems (e.g., tele-wide cameras) challenges this
assumption and complicates stereo matching. Visual asymmetry disrupts stereo
matching by affecting the crucial cost volume computation. To address this, we
explore the matching cost distribution of two established cost volume
construction methods in asymmetric stereo. We find that each cost volume
experiences distinct information distortion, indicating that both should be
comprehensively utilized to solve the issue. Based on this, we propose the
two-phase Iterative Volume Fusion network for Asymmetric Stereo matching
(IVF-AStereo). Initially, the aggregated concatenation volume refines the
correlation volume. Subsequently, both volumes are fused to enhance fine
details. Our method excels in asymmetric scenarios and shows robust performance
against significant visual asymmetry. Extensive comparative experiments on
benchmark datasets, along with ablation studies, confirm the effectiveness of
our approach in asymmetric stereo with resolution and color degradation.

</details>


### [65] [Preacher: Paper-to-Video Agentic System](https://arxiv.org/abs/2508.09632)
*Jingwei Liu,Ling Yang,Hao Luo,Fan Wang Hongyan Li,Mengdi Wang*

Main category: cs.CV

TL;DR: Preacher是首个论文转视频代理系统，通过分解、总结和重构论文，结合渐进式思维链生成高质量视频摘要，解决了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视频生成模型在上下文窗口有限、视频时长刚性限制、风格多样性不足以及无法表示领域特定知识等方面存在局限，Preacher旨在解决这些问题。

Method: Preacher采用自上而下的方法分解、总结和重构论文，然后通过自下而上的视频生成方法，将多样化的视频片段合成为一个连贯的摘要。为了对齐跨模态表示，定义了关键场景并引入了渐进式思维链（P-CoT）进行细粒度的迭代规划。

Result: Preacher在五个研究领域成功生成了高质量的视频摘要，超越了现有视频生成模型的能力。

Conclusion: Preacher成功在五个研究领域生成了高质量的视频摘要，展示了超越当前视频生成模型的专长能力。

Abstract: The paper-to-video task converts a research paper into a structured video
abstract, distilling key concepts, methods, and conclusions into an accessible,
well-organized format. While state-of-the-art video generation models
demonstrate potential, they are constrained by limited context windows, rigid
video duration constraints, limited stylistic diversity, and an inability to
represent domain-specific knowledge. To address these limitations, we introduce
Preacher, the first paper-to-video agentic system. Preacher employs a top-down
approach to decompose, summarize, and reformulate the paper, followed by
bottom-up video generation, synthesizing diverse video segments into a coherent
abstract. To align cross-modal representations, we define key scenes and
introduce a Progressive Chain of Thought (P-CoT) for granular, iterative
planning. Preacher successfully generates high-quality video abstracts across
five research fields, demonstrating expertise beyond current video generation
models. Code will be released at: https://github.com/GenVerse/Paper2Video

</details>


### [66] [Exploring the Equivalence of Closed-Set Generative and Real Data Augmentation in Image Classification](https://arxiv.org/abs/2508.09550)
*Haowen Wang,Guowei Zhang,Xiang Zhang,Zeyuan Chen,Haiyang Xu,Dou Hoon Kwark,Zhuowen Tu*

Main category: cs.CV

TL;DR: 本文研究了封闭集生成数据增强在图像分类中的应用，通过实验量化了合成数据增强的等效规模，并展示了其在不同数据集上的效果。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习中的一个关键科学问题：在图像分类任务中，能否通过训练生成模型来增强分类性能（即封闭集生成数据增强）。

Method: 通过探索真实图像与封闭集合成图像之间的区别和相似性，进行大量实验以系统性地分析合成数据增强的有效使用。

Result: 实验结果表明，虽然真实图像通常更优，但可以通过增加合成数据的规模来达到与真实数据增强相当的分类性能。此外，结果还展示了这种效果如何随基线训练集大小和合成数据量的变化而变化。

Conclusion: 本文通过实验验证了封闭集合成数据增强在图像分类任务中的有效性，并量化了达到与真实数据增强相当性能所需的合成数据规模。

Abstract: In this paper, we address a key scientific problem in machine learning: Given
a training set for an image classification task, can we train a generative
model on this dataset to enhance the classification performance? (i.e.,
closed-set generative data augmentation). We start by exploring the
distinctions and similarities between real images and closed-set synthetic
images generated by advanced generative models. Through extensive experiments,
we offer systematic insights into the effective use of closed-set synthetic
data for augmentation. Notably, we empirically determine the equivalent scale
of synthetic images needed for augmentation. In addition, we also show
quantitative equivalence between the real data augmentation and open-set
generative augmentation (generative models trained using data beyond the given
training set). While it aligns with the common intuition that real images are
generally preferred, our empirical formulation also offers a guideline to
quantify the increased scale of synthetic data augmentation required to achieve
comparable image classification performance. Our results on natural and medical
image datasets further illustrate how this effect varies with the baseline
training set size and the amount of synthetic data incorporated.

</details>


### [67] [Topological Invariant-Based Iris Identification via Digital Homology and Machine Learning](https://arxiv.org/abs/2508.09555)
*Ahmet Öztel,İsmet Karaca*

Main category: cs.CV

TL;DR: 本研究提出了一种基于2D虹膜图像拓扑不变量的生物识别方法，通过数字同调性提取特征，逻辑回归表现最佳（97.78%准确率），优于CNN。该方法紧凑、可解释，适用于多领域。


<details>
  <summary>Details</summary>
Motivation: 本研究提出了一种基于2D虹膜图像拓扑不变量的生物识别方法，旨在通过形式化定义的数字同调性表示虹膜纹理并评估分类性能。

Method: 每张标准化虹膜图像（48x482像素）被划分为网格（如6x54或3x27）。对于每个子区域，使用最近开发的2D数字图像同调群算法计算Betti0、Betti1及其比率。生成的拓扑不变量形成一个特征矩阵，与逻辑回归、KNN和SVM（使用PCA和100次随机重复）结合使用。同时训练了一个卷积神经网络（CNN）用于比较。

Result: 逻辑回归达到了97.78 +/- 0.82%的准确率，优于CNN（96.44 +/- 1.32%）和其他基于特征的模型。拓扑特征显示出高准确率和低方差。

Conclusion: 这是首次在虹膜识别中使用形式化数字同调性的拓扑不变量。该方法提供了一种紧凑、可解释且准确的深度学习替代方案，适用于需要可解释性或数据有限的情况。除了虹膜识别，该方法还可应用于其他生物识别、医学成像、材料科学、遥感和可解释AI领域。它能在仅使用CPU的系统上高效运行，并生成对安全关键领域有价值的稳健、可解释特征。

Abstract: Objective - This study presents a biometric identification method based on
topological invariants from 2D iris images, representing iris texture via
formally defined digital homology and evaluating classification performance.
  Methods - Each normalized iris image (48x482 pixels) is divided into grids
(e.g., 6x54 or 3x27). For each subregion, we compute Betti0, Betti1, and their
ratio using a recent algorithm for homology groups in 2D digital images. The
resulting invariants form a feature matrix used with logistic regression, KNN,
and SVM (with PCA and 100 randomized repetitions). A convolutional neural
network (CNN) is trained on raw images for comparison.
  Results - Logistic regression achieved 97.78 +/- 0.82% accuracy,
outperforming CNN (96.44 +/- 1.32%) and other feature-based models. The
topological features showed high accuracy with low variance.
  Conclusion - This is the first use of topological invariants from formal
digital homology for iris recognition. The method offers a compact,
interpretable, and accurate alternative to deep learning, useful when
explainability or limited data is important. Beyond iris recognition, it can
apply to other biometrics, medical imaging, materials science, remote sensing,
and interpretable AI. It runs efficiently on CPU-only systems and produces
robust, explainable features valuable for security-critical domains.

</details>


### [68] [Region-to-Region: Enhancing Generative Image Harmonization with Adaptive Regional Injection](https://arxiv.org/abs/2508.09746)
*Zhiqiu Zhang,Dongqi Fan,Mingjie Wang,Qiang Tang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: 论文提出R2R模型及配套技术，显著提升图像协调化效果，并构建新数据集RPHarmony，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于LDM的协调化方法在细节保留和协调能力上的不足，以及现有合成数据集缺乏局部变化和复杂光照条件的问题。

Method: 提出了Region-to-Region变换方法，设计Clear-VAE保留前景高频细节，引入Harmony Controller与MACA动态调整前景，并采用Random Poisson Blending构建RPHarmony数据集。

Result: 实验证明，该方法在定量指标和视觉协调性上优于其他方法，且RPHarmony数据集能帮助模型生成更真实的图像。

Conclusion: 通过提出R2R模型、Clear-VAE、Harmony Controller及MACA机制，以及构建RPHarmony数据集，论文显著提升了图像协调化的效果，并在定量指标和视觉协调性上优于其他方法。

Abstract: The goal of image harmonization is to adjust the foreground in a composite
image to achieve visual consistency with the background. Recently, latent
diffusion model (LDM) are applied for harmonization, achieving remarkable
results. However, LDM-based harmonization faces challenges in detail
preservation and limited harmonization ability. Additionally, current synthetic
datasets rely on color transfer, which lacks local variations and fails to
capture complex real-world lighting conditions. To enhance harmonization
capabilities, we propose the Region-to-Region transformation. By injecting
information from appropriate regions into the foreground, this approach
preserves original details while achieving image harmonization or, conversely,
generating new composite data. From this perspective, We propose a novel model
R2R. Specifically, we design Clear-VAE to preserve high-frequency details in
the foreground using Adaptive Filter while eliminating disharmonious elements.
To further enhance harmonization, we introduce the Harmony Controller with
Mask-aware Adaptive Channel Attention (MACA), which dynamically adjusts the
foreground based on the channel importance of both foreground and background
regions. To address the limitation of existing datasets, we propose Random
Poisson Blending, which transfers color and lighting information from a
suitable region to the foreground, thereby generating more diverse and
challenging synthetic images. Using this method, we construct a new synthetic
dataset, RPHarmony. Experiments demonstrate the superiority of our method over
other methods in both quantitative metrics and visual harmony. Moreover, our
dataset helps the model generate more realistic images in real examples. Our
code, dataset, and model weights have all been released for open access.

</details>


### [69] [Combinative Matching for Geometric Shape Assembly](https://arxiv.org/abs/2508.09780)
*Nahyuk Lee,Juhong Min,Junhong Lee,Chunghyun Park,Minsu Cho*

Main category: cs.CV

TL;DR: 提出组合匹配方法，通过建模互锁形状的两种特性（相同表面和对立体积），减少局部歧义，实验表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统几何组装方法依赖通过寻找相同表面对齐部件，而本文旨在解决互锁形状组合中的局部歧义问题。

Method: 该方法通过等变神经网络学习表面形状相同但体积占用对立的区域之间的对应关系，并估计形状方向以实现旋转对齐。

Result: 实验结果表明，该方法在几何组装基准测试中一致优于现有技术。

Conclusion: 该论文提出了一种新的形状匹配方法——组合匹配（combinative matching），通过显式建模互锁形状的两个特性（'相同表面形状'和'对立体积占用'），显著减少了匹配中的局部歧义，并在几何组装基准测试中表现优于现有方法。

Abstract: This paper introduces a new shape-matching methodology, combinative matching,
to combine interlocking parts for geometric shape assembly. Previous methods
for geometric assembly typically rely on aligning parts by finding identical
surfaces between the parts as in conventional shape matching and registration.
In contrast, we explicitly model two distinct properties of interlocking
shapes: 'identical surface shape' and 'opposite volume occupancy.' Our method
thus learns to establish correspondences across regions where their surface
shapes appear identical but their volumes occupy the inverted space to each
other. To facilitate this process, we also learn to align regions in rotation
by estimating their shape orientations via equivariant neural networks. The
proposed approach significantly reduces local ambiguities in matching and
allows a robust combination of parts in assembly. Experimental results on
geometric assembly benchmarks demonstrate the efficacy of our method,
consistently outperforming the state of the art. Project page:
https://nahyuklee.github.io/cmnet.

</details>


### [70] [WEC-DG: Multi-Exposure Wavelet Correction Method Guided by Degradation Description](https://arxiv.org/abs/2508.09565)
*Ming Zhao,Pingping Liu,Tongshun Zhang,Zhe Zhang*

Main category: cs.CV

TL;DR: 论文提出WEC-DG方法，通过小波变换和退化引导解决多曝光校正中的类内变异性问题，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多曝光校正方法在处理单曝光水平图像时，难以应对因不同光照条件、拍摄环境和天气因素导致的类内变异性问题，尤其是对‘模糊’曝光退化的识别不足。

Method: 论文提出了一种基于小波的曝光校正方法（WEC-DG），结合退化描述符和曝光一致性对齐模块（ECAM）以及曝光恢复与细节重建模块（EDRM），通过串行处理策略实现精确的光照校正和细节恢复。

Result: 在多个公开数据集上的广泛实验表明，该方法优于现有算法，取得了显著的性能提升。

Conclusion: 该论文提出的WEC-DG方法在多曝光校正任务中表现优异，通过实验验证了其有效性和实用性。

Abstract: Multi-exposure correction technology is essential for restoring images
affected by insufficient or excessive lighting, enhancing the visual experience
by improving brightness, contrast, and detail richness. However, current
multi-exposure correction methods often encounter challenges in addressing
intra-class variability caused by diverse lighting conditions, shooting
environments, and weather factors, particularly when processing images captured
at a single exposure level. To enhance the adaptability of these models under
complex imaging conditions, this paper proposes a Wavelet-based Exposure
Correction method with Degradation Guidance (WEC-DG). Specifically, we
introduce a degradation descriptor within the Exposure Consistency Alignment
Module (ECAM) at both ends of the processing pipeline to ensure exposure
consistency and achieve final alignment. This mechanism effectively addresses
miscorrected exposure anomalies caused by existing methods' failure to
recognize 'blurred' exposure degradation. Additionally, we investigate the
light-detail decoupling properties of the wavelet transform to design the
Exposure Restoration and Detail Reconstruction Module (EDRM), which processes
low-frequency information related to exposure enhancement before utilizing
high-frequency information as a prior guide for reconstructing spatial domain
details. This serial processing strategy guarantees precise light correction
and enhances detail recovery. Extensive experiments conducted on multiple
public datasets demonstrate that the proposed method outperforms existing
algorithms, achieving significant performance improvements and validating its
effectiveness and practical applicability.

</details>


### [71] [A Chain of Diagnosis Framework for Accurate and Explainable Radiology Report Generation](https://arxiv.org/abs/2508.09566)
*Haibo Jin,Haoxuan Che,Sunan He,Hao Chen*

Main category: cs.CV

TL;DR: 本文提出诊断链（CoD）框架，通过生成QA对和定位模块，提升放射学报告生成的准确性和可解释性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有放射学报告生成（RRG）模型在临床效果（尤其是病变属性描述）和可解释性方面的不足，旨在构建一个可信赖的RRG模型。

Method: 提出了一种名为诊断链（CoD）的框架，包括生成QA对以提取关键发现、利用大型语言模型进行准确生成、设计诊断和病变定位模块以增强可解释性，以及采用全监督学习策略进行高效训练。

Result: 开发了一个包含QA对和病变框的全标注RRG数据集、一个评估工具，并在实验中证明CoD在准确性和可解释性上的优越表现。

Conclusion: CoD框架在放射学报告生成中表现出色，不仅在两个基准测试中优于专家和通用模型，还通过准确地将生成的句子与QA诊断和图像关联，展示了良好的可解释性。

Abstract: Despite the progress of radiology report generation (RRG), existing works
face two challenges: 1) The performances in clinical efficacy are
unsatisfactory, especially for lesion attributes description; 2) the generated
text lacks explainability, making it difficult for radiologists to trust the
results. To address the challenges, we focus on a trustworthy RRG model, which
not only generates accurate descriptions of abnormalities, but also provides
basis of its predictions. To this end, we propose a framework named chain of
diagnosis (CoD), which maintains a chain of diagnostic process for clinically
accurate and explainable RRG. It first generates question-answer (QA) pairs via
diagnostic conversation to extract key findings, then prompts a large language
model with QA diagnoses for accurate generation. To enhance explainability, a
diagnosis grounding module is designed to match QA diagnoses and generated
sentences, where the diagnoses act as a reference. Moreover, a lesion grounding
module is designed to locate abnormalities in the image, further improving the
working efficiency of radiologists. To facilitate label-efficient training, we
propose an omni-supervised learning strategy with clinical consistency to
leverage various types of annotations from different datasets. Our efforts lead
to 1) an omni-labeled RRG dataset with QA pairs and lesion boxes; 2) a
evaluation tool for assessing the accuracy of reports in describing lesion
location and severity; 3) extensive experiments to demonstrate the
effectiveness of CoD, where it outperforms both specialist and generalist
models consistently on two RRG benchmarks and shows promising explainability by
accurately grounding generated sentences to QA diagnoses and images.

</details>


### [72] [Automated Segmentation of Coronal Brain Tissue Slabs for 3D Neuropathology](https://arxiv.org/abs/2508.09805)
*Jonathan Williams Ramirez,Dina Zemlyanker,Lucas Deden-Binder,Rogeny Herisse,Erendira Garcia Pallares,Karthik Gopinath,Harshvardhan Gazula,Christopher Mount,Liana N. Kozanno,Michael S. Marshall,Theresa R. Connors,Matthew P. Frosch,Mark Montine,Derek H. Oakley,Christine L. Mac Donald,C. Dirk Keene,Bradley T. Hyman,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 开发了一个U-Net模型来自动分割脑组织照片，性能接近人工标注，工具已公开。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要昂贵的手动干预来分割脑组织照片，因此需要自动化工具以提高效率和可扩展性。

Method: 使用U-Net架构，结合1,414张手动标注的图像和2,000张合成图像进行训练，以提升模型对未见过的摄影设置的泛化能力。

Result: 模型在未见过的照片上表现优异，Dice中位数超过0.98，平均表面距离小于0.4毫米，95% Hausdorff距离小于1.60毫米。

Conclusion: 该研究开发了一种基于U-Net架构的深度学习模型，用于自动化分割脑组织照片，其性能接近人工标注的评分者间/内变异性水平，并公开了工具。

Abstract: Advances in image registration and machine learning have recently enabled
volumetric analysis of \emph{postmortem} brain tissue from conventional
photographs of coronal slabs, which are routinely collected in brain banks and
neuropathology laboratories worldwide. One caveat of this methodology is the
requirement of segmentation of the tissue from photographs, which currently
requires costly manual intervention. In this article, we present a deep
learning model to automate this process. The automatic segmentation tool relies
on a U-Net architecture that was trained with a combination of
\textit{(i)}1,414 manually segmented images of both fixed and fresh tissue,
from specimens with varying diagnoses, photographed at two different sites; and
\textit{(ii)}~2,000 synthetic images with randomized contrast and corresponding
masks generated from MRI scans for improved generalizability to unseen
photographic setups. Automated model predictions on a subset of photographs not
seen in training were analyzed to estimate performance compared to manual
labels -- including both inter- and intra-rater variability. Our model achieved
a median Dice score over 0.98, mean surface distance under 0.4~mm, and 95\%
Hausdorff distance under 1.60~mm, which approaches inter-/intra-rater levels.
Our tool is publicly available at surfer.nmr.mgh.harvard.edu/fswiki/PhotoTools.

</details>


### [73] [Dual Recursive Feedback on Generation and Appearance Latents for Pose-Robust Text-to-Image Diffusion](https://arxiv.org/abs/2508.09575)
*Jiwon Kim,Pureum Kim,SeonHwa Kim,Soobin Park,Eunju Cha,Kyong Hwan Jin*

Main category: cs.CV

TL;DR: 提出无需训练的DRF系统，通过双重反馈机制优化图像生成，解决现有模型在空间结构和细粒度条件控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有可控文本到图像扩散模型（如Ctrl-X和FreeControl）在准确保留空间结构和捕捉细粒度条件（如物体姿态和场景布局）方面表现不足。

Method: 训练无关的Dual Recursive Feedback (DRF)系统，通过外观反馈和生成反馈递归优化中间潜在表示，以更好地反映给定外观信息和用户意图。

Result: 实验证明DRF方法能够生成高质量、语义一致且结构一致的图像，甚至在类不变的结构-外观融合（如将人类动作转移到老虎形态）中表现优异。

Conclusion: 提出的Dual Recursive Feedback (DRF)系统在无需训练的情况下，通过双重反馈机制有效整合结构和外观属性，生成了高质量、语义一致且结构一致的图像。

Abstract: Recent advancements in controllable text-to-image (T2I) diffusion models,
such as Ctrl-X and FreeControl, have demonstrated robust spatial and appearance
control without requiring auxiliary module training. However, these models
often struggle to accurately preserve spatial structures and fail to capture
fine-grained conditions related to object poses and scene layouts. To address
these challenges, we propose a training-free Dual Recursive Feedback (DRF)
system that properly reflects control conditions in controllable T2I models.
The proposed DRF consists of appearance feedback and generation feedback that
recursively refines the intermediate latents to better reflect the given
appearance information and the user's intent. This dual-update mechanism guides
latent representations toward reliable manifolds, effectively integrating
structural and appearance attributes. Our approach enables fine-grained
generation even between class-invariant structure-appearance fusion, such as
transferring human motion onto a tiger's form. Extensive experiments
demonstrate the efficacy of our method in producing high-quality, semantically
coherent, and structurally consistent image generations. Our source code is
available at https://github.com/jwonkm/DRF.

</details>


### [74] [SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs](https://arxiv.org/abs/2508.09584)
*Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: SHALE是一个自动构建的基准，用于细粒度评估大视觉语言模型的幻觉问题，发现主流模型在事实性幻觉和对语义扰动的敏感性方面存在问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有大视觉语言模型在幻觉问题（如忠实性和事实性幻觉）评估中的局限性，包括粗粒度分析、手动数据构建的昂贵成本以及数据泄露问题。

Method: 提出了一个自动数据构建流程和分层幻觉诱导框架，构建了SHALE基准，包含超过30K图像-指令对，覆盖12个视觉感知方面和6个知识领域。

Result: 在超过20个主流LVLM上的实验显示，模型存在显著的事实性幻觉问题，并对语义扰动高度敏感。

Conclusion: SHALE基准通过自动数据构建和分层幻觉诱导框架，为大视觉语言模型的幻觉问题提供了细粒度评估，揭示了主流模型在事实性幻觉和对语义扰动的敏感性方面的问题。

Abstract: Despite rapid advances, Large Vision-Language Models (LVLMs) still suffer
from hallucinations, i.e., generating content inconsistent with input or
established world knowledge, which correspond to faithfulness and factuality
hallucinations, respectively. Prior studies primarily evaluate faithfulness
hallucination at a coarse level (e.g., object-level) and lack fine-grained
analysis. Additionally, existing benchmarks rely on costly manual curation or
reused public datasets, raising concerns about scalability and data leakage. To
address these limitations, we propose an automated data construction pipeline
that produces scalable, controllable, and diverse evaluation data. We also
design a hierarchical hallucination induction framework with input
perturbations to simulate realistic noisy scenarios. Integrating these designs,
we construct SHALE, a Scalable HALlucination Evaluation benchmark designed to
assess both faithfulness and factuality hallucinations via a fine-grained
hallucination categorization scheme. SHALE comprises over 30K image-instruction
pairs spanning 12 representative visual perception aspects for faithfulness and
6 knowledge domains for factuality, considering both clean and noisy scenarios.
Extensive experiments on over 20 mainstream LVLMs reveal significant factuality
hallucinations and high sensitivity to semantic perturbations.

</details>


### [75] [Offline Auto Labeling: BAAS](https://arxiv.org/abs/2508.09585)
*Stefan Haag,Bharanidhar Duraisamy,Felix Govaers,Wolfgang Koch,Martin Fritzsche,Juergen Dickmann*

Main category: cs.CV

TL;DR: BAAS是一个基于贝叶斯的雷达检测跟踪与标签标注框架，支持多监督级别和闭环改进，适用于自动驾驶场景。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中雷达检测的标签标注和跟踪性能评估问题，提出一个综合性的框架以实现闭环持续改进。

Method: 该框架利用基于贝叶斯的跟踪、平滑和融合方法，提供精确的对象轨迹和形状估计，支持不同监督级别的检测级标签标注。

Result: 在具有挑战性的城市真实场景中评估了框架性能，证明了其在跟踪和标签标注方面的功能。

Conclusion: BAAS框架在自动驾驶雷达检测中展示了其在跟踪性能和标签标注误差方面的有效性，能够适应不同动态对象和类别类型。

Abstract: This paper introduces BAAS, a new Extended Object Tracking (EOT) and
fusion-based label annotation framework for radar detections in autonomous
driving. Our framework utilizes Bayesian-based tracking, smoothing and
eventually fusion methods to provide veritable and precise object trajectories
along with shape estimation to provide annotation labels on the detection level
under various supervision levels. Simultaneously, the framework provides
evaluation of tracking performance and label annotation. If manually labeled
data is available, each processing module can be analyzed independently or
combined with other modules to enable closed-loop continuous improvements. The
framework performance is evaluated in a challenging urban real-world scenario
in terms of tracking performance and the label annotation errors. We
demonstrate the functionality of the proposed approach for varying dynamic
objects and class types

</details>


### [76] [COME: Dual Structure-Semantic Learning with Collaborative MoE for Universal Lesion Detection Across Heterogeneous Ultrasound Datasets](https://arxiv.org/abs/2508.09886)
*Lingyu Chen,Yawen Zeng,Yue Wang,Peng Wan,Guo-chen Ning,Hongen Liao,Daoqiang Zhang,Fang Chen*

Main category: cs.CV

TL;DR: COME框架通过协作异构专家混合，显著提升超声图像分析的跨数据集性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统单数据集训练在新数据分布下表现不佳的问题，尤其是在超声图像分析中，由于数据有限、声学阴影和斑点噪声等挑战。

Method: 提出了一个名为COME的通用协作异构源特定专家混合框架，通过建立双结构-语义共享专家和源特定专家的协作，提取判别性特征。

Result: 在三种评估模式（单数据集、器官内和器官间集成数据集）下，COME显著提高了平均AP，优于现有方法。

Conclusion: COME框架通过双结构-语义共享专家与源特定专家的协作，显著提升了跨数据集超声图像分析的性能，并在多种评估模式下优于现有方法。

Abstract: Conventional single-dataset training often fails with new data distributions,
especially in ultrasound (US) image analysis due to limited data, acoustic
shadows, and speckle noise. Therefore, constructing a universal framework for
multi-heterogeneous US datasets is imperative. However, a key challenge arises:
how to effectively mitigate inter-dataset interference while preserving
dataset-specific discriminative features for robust downstream task? Previous
approaches utilize either a single source-specific decoder or a domain
adaptation strategy, but these methods experienced a decline in performance
when applied to other domains. Considering this, we propose a Universal
Collaborative Mixture of Heterogeneous Source-Specific Experts (COME).
Specifically, COME establishes dual structure-semantic shared experts that
create a universal representation space and then collaborate with
source-specific experts to extract discriminative features through providing
complementary features. This design enables robust generalization by leveraging
cross-datasets experience distributions and providing universal US priors for
small-batch or unseen data scenarios. Extensive experiments under three
evaluation modes (single-dataset, intra-organ, and inter-organ integration
datasets) demonstrate COME's superiority, achieving significant mean AP
improvements over state-of-the-art methods. Our project is available at:
https://universalcome.github.io/UniversalCOME/.

</details>


### [77] [SVG-Head: Hybrid Surface-Volumetric Gaussians for High-Fidelity Head Reconstruction and Real-Time Editing](https://arxiv.org/abs/2508.09597)
*Heyi Sun,Cong Wang,Tian-Xing Xu,Jingwei Huang,Di Kang,Chunchao Guo,Song-Hai Zhang*

Main category: cs.CV

TL;DR: SVG-Head是一种混合表示方法，结合3D高斯和纹理图像，实现了高保真头部虚拟形象的实时渲染和编辑。


<details>
  <summary>Details</summary>
Motivation: 解决头部虚拟形象的高保真渲染和实时外观编辑的挑战，尤其是在几何和全局外观纠缠建模的情况下。

Method: SVG-Head采用表面高斯和体积高斯的混合表示，利用FLAME网格的UV坐标映射，结合分层优化策略，实现了高质量的渲染和实时编辑。

Result: 实验证明SVG-Head在NeRSemble数据集上不仅实现了高保真渲染，还首次支持了高斯头部虚拟形象的显式纹理图像和实时外观编辑。

Conclusion: SVG-Head提出了一种新颖的混合表示方法，通过结合3D高斯和分离的纹理图像，实现了高保真渲染和实时外观编辑，为AR/VR应用提供了重要技术支持。

Abstract: Creating high-fidelity and editable head avatars is a pivotal challenge in
computer vision and graphics, boosting many AR/VR applications. While recent
advancements have achieved photorealistic renderings and plausible animation,
head editing, especially real-time appearance editing, remains challenging due
to the implicit representation and entangled modeling of the geometry and
global appearance. To address this, we propose Surface-Volumetric Gaussian Head
Avatar (SVG-Head), a novel hybrid representation that explicitly models the
geometry with 3D Gaussians bound on a FLAME mesh and leverages disentangled
texture images to capture the global appearance. Technically, it contains two
types of Gaussians, in which surface Gaussians explicitly model the appearance
of head avatars using learnable texture images, facilitating real-time texture
editing, while volumetric Gaussians enhance the reconstruction quality of
non-Lambertian regions (e.g., lips and hair). To model the correspondence
between 3D world and texture space, we provide a mesh-aware Gaussian UV mapping
method, which leverages UV coordinates given by the FLAME mesh to obtain sharp
texture images and real-time rendering speed. A hierarchical optimization
strategy is further designed to pursue the optimal performance in both
reconstruction quality and editing flexibility. Experiments on the NeRSemble
dataset show that SVG-Head not only generates high-fidelity rendering results,
but also is the first method to obtain explicit texture images for Gaussian
head avatars and support real-time appearance editing.

</details>


### [78] [Images Speak Louder Than Scores: Failure Mode Escape for Enhancing Generative Quality](https://arxiv.org/abs/2508.09598)
*Jie Shao,Ke Zhu,Minghao Fu,Guo-hua Wang,Jianxin Wu*

Main category: cs.CV

TL;DR: FaME通过负向引导改进扩散模型的感知质量，无需训练且不影响FID。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在类到图像生成方面取得了显著进展，但现有模型常生成扭曲或低质量图像，尤其是某些类别。FID评分虽高，但忽略了单个样本的感知质量。CFG技术虽能提升指标，但可能导致分布偏移和视觉伪影。

Method: FaME利用图像质量评估模型识别低质量生成样本，并存储其采样轨迹，作为负向引导以避开低质量区域。

Result: 在ImageNet上的实验表明，FaME在保持FID不变的同时，显著提升了视觉质量，并具备扩展到文本到图像生成的潜力。

Conclusion: FaME是一种无需训练且推理高效的方法，通过识别低质量生成的采样轨迹并作为负向引导，显著提升了图像生成的感知质量，同时不损害FID评分。

Abstract: Diffusion models have achieved remarkable progress in class-to-image
generation. However, we observe that despite impressive FID scores,
state-of-the-art models often generate distorted or low-quality images,
especially in certain classes. This gap arises because FID evaluates global
distribution alignment, while ignoring the perceptual quality of individual
samples. We further examine the role of CFG, a common technique used to enhance
generation quality. While effective in improving metrics and suppressing
outliers, CFG can introduce distribution shift and visual artifacts due to its
misalignment with both training objectives and user expectations. In this work,
we propose FaME, a training-free and inference-efficient method for improving
perceptual quality. FaME uses an image quality assessment model to identify
low-quality generations and stores their sampling trajectories. These failure
modes are then used as negative guidance to steer future sampling away from
poor-quality regions. Experiments on ImageNet demonstrate that FaME brings
consistent improvements in visual quality without compromising FID. FaME also
shows the potential to be extended to improve text-to-image generation.

</details>


### [79] [January Food Benchmark (JFB): A Public Benchmark Dataset and Evaluation Suite for Multimodal Food Analysis](https://arxiv.org/abs/2508.09966)
*Amir Hosseinian,Ashkan Dehghani Zahedani,Umer Mansoor,Noosheen Hashemi,Mark Woodward*

Main category: cs.CV

TL;DR: 研究提出了JFB数据集和基准框架，专用模型表现优于通用模型，为自动营养分析提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 自动营养分析领域的进展因缺乏标准化评估方法和高质量、真实世界的基准数据集而受到严重阻碍。

Method: 引入了January Food Benchmark (JFB)数据集，包含1000张带有人工验证标注的食物图像；提出了全面的基准测试框架，包括鲁棒性指标和面向应用的整体评分；提供了通用视觉语言模型(VLMs)和专用模型january/food-vision-v1的基线结果。

Result: 专用模型january/food-vision-v1的整体评分为86.2，比表现最佳的通用配置提高了12.1分。

Conclusion: 这项研究为自动营养分析领域提供了新的评估数据集和严格的框架，指导并基准化未来的发展。

Abstract: Progress in AI for automated nutritional analysis is critically hampered by
the lack of standardized evaluation methodologies and high-quality, real-world
benchmark datasets. To address this, we introduce three primary contributions.
First, we present the January Food Benchmark (JFB), a publicly available
collection of 1,000 food images with human-validated annotations. Second, we
detail a comprehensive benchmarking framework, including robust metrics and a
novel, application-oriented overall score designed to assess model performance
holistically. Third, we provide baseline results from both general-purpose
Vision-Language Models (VLMs) and our own specialized model,
january/food-vision-v1. Our evaluation demonstrates that the specialized model
achieves an Overall Score of 86.2, a 12.1-point improvement over the
best-performing general-purpose configuration. This work offers the research
community a valuable new evaluation dataset and a rigorous framework to guide
and benchmark future developments in automated nutritional analysis.

</details>


### [80] [BridgeTA: Bridging the Representation Gap in Knowledge Distillation via Teacher Assistant for Bird's Eye View Map Segmentation](https://arxiv.org/abs/2508.09599)
*Beomjun Kim,Suhan Woo,Sejong Heo,Euntai Kim*

Main category: cs.CV

TL;DR: BridgeTA是一种轻量级知识蒸馏框架，通过教师助理网络和优化损失函数，显著提升纯相机BEV分割性能，且不增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识蒸馏方法因模仿教师模型架构而增加学生模型推理成本的问题，同时缩小纯相机模型与LC融合模型之间的性能差距。

Method: 提出BridgeTA框架，利用教师助理网络在教师和学生模型之间构建共享潜在空间，并通过Young's Inequality推导的蒸馏损失优化知识传递。

Result: 在nuScenes数据集上，BridgeTA相比纯相机基线提升了4.2% mIoU，优于其他最先进知识蒸馏方法45%。

Conclusion: BridgeTA框架通过引入轻量级教师助理网络，在不增加学生模型推理成本的情况下，显著缩小了LC融合与纯相机模型之间的性能差距，并在nuScenes数据集上取得了4.2% mIoU的提升。

Abstract: Bird's-Eye-View (BEV) map segmentation is one of the most important and
challenging tasks in autonomous driving. Camera-only approaches have drawn
attention as cost-effective alternatives to LiDAR, but they still fall behind
LiDAR-Camera (LC) fusion-based methods. Knowledge Distillation (KD) has been
explored to narrow this gap, but existing methods mainly enlarge the student
model by mimicking the teacher's architecture, leading to higher inference
cost. To address this issue, we introduce BridgeTA, a cost-effective
distillation framework to bridge the representation gap between LC fusion and
Camera-only models through a Teacher Assistant (TA) network while keeping the
student's architecture and inference cost unchanged. A lightweight TA network
combines the BEV representations of the teacher and student, creating a shared
latent space that serves as an intermediate representation. To ground the
framework theoretically, we derive a distillation loss using Young's
Inequality, which decomposes the direct teacher-student distillation path into
teacher-TA and TA-student dual paths, stabilizing optimization and
strengthening knowledge transfer. Extensive experiments on the challenging
nuScenes dataset demonstrate the effectiveness of our method, achieving an
improvement of 4.2% mIoU over the Camera-only baseline, up to 45% higher than
the improvement of other state-of-the-art KD methods.

</details>


### [81] [Echo-4o: Harnessing the Power of GPT-4o Synthetic Images for Improved Image Generation](https://arxiv.org/abs/2508.09987)
*Junyan Ye,Dongzhi Jiang,Zihao Wang,Leqi Zhu,Zhenghao Hu,Zilong Huang,Jun He,Zhiyuan Yan,Jinghua Yu,Hongsheng Li,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: 研究通过GPT-4o生成合成数据集Echo-4o-Image，弥补现实数据不足，提升开源模型性能，并提出了新评估基准。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集在稀有场景（如超现实幻想或多参考图像生成）和文本-图像对齐方面存在不足，而合成数据能提供纯净背景和长尾监督信号。

Method: 通过GPT-4o生成180K规模的合成数据集Echo-4o-Image，并基于此微调多模态生成基线模型Bagel。同时提出了GenEval++和Imagine-Bench两个新评估基准。

Result: Echo-4o在标准基准测试中表现优异，且Echo-4o-Image对其他基础模型（如OmniGen2、BLIP3-o）也带来一致的性能提升。

Conclusion: Echo-4o利用GPT-4o生成的合成数据弥补了现实世界数据集的不足，显著提升了开源模型的图像生成能力，并展示了强大的迁移性。

Abstract: Recently, GPT-4o has garnered significant attention for its strong
performance in image generation, yet open-source models still lag behind.
Several studies have explored distilling image data from GPT-4o to enhance
open-source models, achieving notable progress. However, a key question
remains: given that real-world image datasets already constitute a natural
source of high-quality data, why should we use GPT-4o-generated synthetic data?
In this work, we identify two key advantages of synthetic images. First, they
can complement rare scenarios in real-world datasets, such as surreal fantasy
or multi-reference image generation, which frequently occur in user queries.
Second, they provide clean and controllable supervision. Real-world data often
contains complex background noise and inherent misalignment between text
descriptions and image content, whereas synthetic images offer pure backgrounds
and long-tailed supervision signals, facilitating more accurate text-to-image
alignment. Building on these insights, we introduce Echo-4o-Image, a 180K-scale
synthetic dataset generated by GPT-4o, harnessing the power of synthetic image
data to address blind spots in real-world coverage. Using this dataset, we
fine-tune the unified multimodal generation baseline Bagel to obtain Echo-4o.
In addition, we propose two new evaluation benchmarks for a more accurate and
challenging assessment of image generation capabilities: GenEval++, which
increases instruction complexity to mitigate score saturation, and
Imagine-Bench, which focuses on evaluating both the understanding and
generation of imaginative content. Echo-4o demonstrates strong performance
across standard benchmarks. Moreover, applying Echo-4o-Image to other
foundation models (e.g., OmniGen2, BLIP3-o) yields consistent performance gains
across multiple metrics, highlighting the datasets strong transferability.

</details>


### [82] [Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation](https://arxiv.org/abs/2508.09626)
*Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang*

Main category: cs.CV

TL;DR: SAD-Splat通过高斯点丢弃模块和伪标签生成流程，解决了航拍图像语义分割中的语义模糊问题，提升了分割精度和紧凑性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在航拍图像中因尺度变化和结构遮挡导致的语义模糊问题，限制了分割精度和一致性。

Method: 提出了SAD-Splat方法，包括高斯点丢弃模块（结合语义置信度估计和基于Hard Concrete分布的可学习稀疏机制）和高置信度伪标签生成流程。

Result: 实验结果表明，SAD-Splat在分割精度和表示紧凑性方面表现优异。

Conclusion: SAD-Splat 在3D-AVS-SS任务中实现了分割精度与表示紧凑性的优秀平衡，为3D航拍场景理解提供了高效且可扩展的解决方案。

Abstract: In the task of 3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS),
traditional methods struggle to address semantic ambiguity caused by scale
variations and structural occlusions in aerial images. This limits their
segmentation accuracy and consistency. To tackle these challenges, we propose a
novel 3D-AVS-SS approach named SAD-Splat. Our method introduces a Gaussian
point drop module, which integrates semantic confidence estimation with a
learnable sparsity mechanism based on the Hard Concrete distribution. This
module effectively eliminates redundant and semantically ambiguous Gaussian
points, enhancing both segmentation performance and representation compactness.
Furthermore, SAD-Splat incorporates a high-confidence pseudo-label generation
pipeline. It leverages 2D foundation models to enhance supervision when
ground-truth labels are limited, thereby further improving segmentation
accuracy. To advance research in this domain, we introduce a challenging
benchmark dataset: 3D Aerial Semantic (3D-AS), which encompasses diverse
real-world aerial scenes with sparse annotations. Experimental results
demonstrate that SAD-Splat achieves an excellent balance between segmentation
accuracy and representation compactness. It offers an efficient and scalable
solution for 3D aerial scene understanding.

</details>


### [83] [Enhancing Monocular 3D Hand Reconstruction with Learned Texture Priors](https://arxiv.org/abs/2508.09629)
*Giorgos Karvounas,Nikolaos Kyriazis,Iason Oikonomidis,Georgios Pavlakos,Antonis A. Argyros*

Main category: cs.CV

TL;DR: 纹理可作为密集监督信号提升单目3D手部重建的精度与真实感，提出的轻量级纹理模块通过像素级对齐实现这一目标。


<details>
  <summary>Details</summary>
Motivation: 现有高性能模型中，预测的手部几何与图像外观之间的覆盖往往不完美，纹理对齐可能是一个未被充分利用的监督信号。

Method: 提出了一种轻量级纹理模块，将像素观测嵌入UV纹理空间，并引入了一种新的密集对齐损失函数。该方法利用可微分渲染流程和已知拓扑结构的3D手部网格模型，实现预测与观测手部外观的像素级对齐。

Result: 通过增强HaMeR（一种高性能3D手部姿态估计Transformer架构），系统在精度和真实感上均有所提升。

Conclusion: 纹理对齐在单目3D手部重建中具有重要价值，不仅能提升重建精度，还能增强真实感。

Abstract: We revisit the role of texture in monocular 3D hand reconstruction, not as an
afterthought for photorealism, but as a dense, spatially grounded cue that can
actively support pose and shape estimation. Our observation is simple: even in
high-performing models, the overlay between predicted hand geometry and image
appearance is often imperfect, suggesting that texture alignment may be an
underused supervisory signal. We propose a lightweight texture module that
embeds per-pixel observations into UV texture space and enables a novel dense
alignment loss between predicted and observed hand appearances. Our approach
assumes access to a differentiable rendering pipeline and a model that maps
images to 3D hand meshes with known topology, allowing us to back-project a
textured hand onto the image and perform pixel-based alignment. The module is
self-contained and easily pluggable into existing reconstruction pipelines. To
isolate and highlight the value of texture-guided supervision, we augment
HaMeR, a high-performing yet unadorned transformer architecture for 3D hand
pose estimation. The resulting system improves both accuracy and realism,
demonstrating the value of appearance-guided alignment in hand reconstruction.

</details>


### [84] [Multi-Contrast Fusion Module: An attention mechanism integrating multi-contrast features for fetal torso plane classification](https://arxiv.org/abs/2508.09644)
*Shengjun Zhu,Siyu Liu,Runqing Xiong,Liping Zheng,Duo Ma,Rongshang Chen,Jiaxin Cai*

Main category: cs.CV

TL;DR: 提出多对比度融合模块（MCFM）提升胎儿超声图像识别，通过低层网络处理和多对比度注意力增强特征建模，实验显示性能提升且复杂度低，临床潜力大。


<details>
  <summary>Details</summary>
Motivation: 产前超声是评估胎儿结构发育和检测异常的关键工具，有助于减少围产期并发症和提高新生儿存活率。然而，超声成像中的低对比度和不清晰的纹理细节等限制对细粒度解剖识别提出了重大挑战。

Method: 提出了一种新颖的多对比度融合模块（MCFM），专门在神经网络的较低层操作，直接处理原始超声数据。通过为不同对比条件下的图像表示分配注意力权重，该模块增强了特征建模，同时明确保持最小的参数开销。

Result: 在胎儿躯干平面超声图像的精选数据集上评估了MCFM。实验结果表明，MCFM显著提高了识别性能，同时模型复杂度的增加最小。多对比度注意力的整合使模型能够更好地捕捉细微的解剖结构，有助于提高分类准确性和临床可靠性。

Conclusion: 该方法为超声成像中胎儿躯干平面识别提供了有效解决方案。通过多对比度融合增强特征表示，该方法支持临床医生实现更准确和一致的诊断，展示了在产前筛查中临床应用的强大潜力。

Abstract: Purpose: Prenatal ultrasound is a key tool in evaluating fetal structural
development and detecting abnormalities, contributing to reduced perinatal
complications and improved neonatal survival. Accurate identification of
standard fetal torso planes is essential for reliable assessment and
personalized prenatal care. However, limitations such as low contrast and
unclear texture details in ultrasound imaging pose significant challenges for
fine-grained anatomical recognition. Methods: We propose a novel Multi-Contrast
Fusion Module (MCFM) to enhance the model's ability to extract detailed
information from ultrasound images. MCFM operates exclusively on the lower
layers of the neural network, directly processing raw ultrasound data. By
assigning attention weights to image representations under different contrast
conditions, the module enhances feature modeling while explicitly maintaining
minimal parameter overhead. Results: The proposed MCFM was evaluated on a
curated dataset of fetal torso plane ultrasound images. Experimental results
demonstrate that MCFM substantially improves recognition performance, with a
minimal increase in model complexity. The integration of multi-contrast
attention enables the model to better capture subtle anatomical structures,
contributing to higher classification accuracy and clinical reliability.
Conclusions: Our method provides an effective solution for improving fetal
torso plane recognition in ultrasound imaging. By enhancing feature
representation through multi-contrast fusion, the proposed approach supports
clinicians in achieving more accurate and consistent diagnoses, demonstrating
strong potential for clinical adoption in prenatal screening. The codes are
available at https://github.com/sysll/MCFM.

</details>


### [85] [Multi-Sequence Parotid Gland Lesion Segmentation via Expert Text-Guided Segment Anything Model](https://arxiv.org/abs/2508.09645)
*Zhongyuan Wu,Chuan-Xian Ren,Yu Wang,Xiaohua Ban,Jianning Xiao,Xiaohui Duan*

Main category: cs.CV

TL;DR: PG-SAM 是一种结合专家诊断文本和跨序列注意力的SAM模型，用于腮腺病变分割，表现出卓越的临床性能。


<details>
  <summary>Details</summary>
Motivation: 解决SAM在医学图像分割中依赖精确病变提示的局限性，并弥补当前方法忽略医学专家领域知识的不足。

Method: 提出了专家诊断报告引导的提示生成模块和跨序列注意力模块，结合多序列图像特征和生成的提示信息，通过解码器获取分割结果。

Result: PG-SAM 在腮腺病变分割中取得了最先进的性能，验证了其临床适用性。

Conclusion: PG-SAM 通过结合专家诊断文本和跨序列注意力模块，在三个独立临床中心实现了最先进的腮腺病变分割性能，验证了其临床适用性和诊断文本在增强图像分割中的有效性。

Abstract: Parotid gland lesion segmentation is essential for the treatment of parotid
gland diseases. However, due to the variable size and complex lesion
boundaries, accurate parotid gland lesion segmentation remains challenging.
Recently, the Segment Anything Model (SAM) fine-tuning has shown remarkable
performance in the field of medical image segmentation. Nevertheless, SAM's
interaction segmentation model relies heavily on precise lesion prompts
(points, boxes, masks, etc.), which are very difficult to obtain in real-world
applications. Besides, current medical image segmentation methods are
automatically generated, ignoring the domain knowledge of medical experts when
performing segmentation. To address these limitations, we propose the parotid
gland segment anything model (PG-SAM), an expert diagnosis text-guided SAM
incorporating expert domain knowledge for cross-sequence parotid gland lesion
segmentation. Specifically, we first propose an expert diagnosis report guided
prompt generation module that can automatically generate prompt information
containing the prior domain knowledge to guide the subsequent lesion
segmentation process. Then, we introduce a cross-sequence attention module,
which integrates the complementary information of different modalities to
enhance the segmentation effect. Finally, the multi-sequence image features and
generated prompts are feed into the decoder to get segmentation result.
Experimental results demonstrate that PG-SAM achieves state-of-the-art
performance in parotid gland lesion segmentation across three independent
clinical centers, validating its clinical applicability and the effectiveness
of diagnostic text for enhancing image segmentation in real-world clinical
settings.

</details>


### [86] [The Brain Resection Multimodal Image Registration (ReMIND2Reg) 2025 Challenge](https://arxiv.org/abs/2508.09649)
*Reuben Dorent,Laura Rigolo,Colin P. Galvin,Junyu Chen,Mattias P. Heinrich,Aaron Carass,Olivier Colliot,Demian Wassermann,Alexandra Golby,Tina Kapur,William Wells*

Main category: cs.CV

TL;DR: ReMIND2Reg挑战赛提供大规模数据集和标准化评估框架，以解决脑肿瘤手术中多模态图像配准的挑战，促进鲁棒算法的开发。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤手术中，基于术前MRI的神经导航系统因脑移位而失去准确性，术后术中超声（iUS）与术前MRI的配准可以恢复空间准确性，但由于解剖和拓扑变化大以及模态强度差异显著，这一问题具有挑战性。

Method: 挑战赛基于ReMIND数据集，提供了99个训练案例、5个验证案例和10个私人测试案例，包括配对的3D ceT1 MRI、T2 MRI和术后3D iUS体积数据。评估指标包括目标配准误差（TRE）、对最坏情况地标错位的鲁棒性（TRE30）和运行时间。

Result: ReMIND2Reg挑战赛提供了该任务最大的公共基准，旨在通过标准化评估框架促进算法开发。

Conclusion: ReMIND2Reg挑战赛旨在通过提供一个标准化评估框架，加速开发鲁棒、通用且可临床部署的多模态配准算法，以解决脑肿瘤手术中图像引导的关键问题。

Abstract: Accurate intraoperative image guidance is critical for achieving maximal safe
resection in brain tumor surgery, yet neuronavigation systems based on
preoperative MRI lose accuracy during the procedure due to brain shift.
Aligning post-resection intraoperative ultrasound (iUS) with preoperative MRI
can restore spatial accuracy by estimating brain shift deformations, but it
remains a challenging problem given the large anatomical and topological
changes and substantial modality intensity gap. The ReMIND2Reg 2025 Challenge
provides the largest public benchmark for this task, built upon the ReMIND
dataset. It offers 99 training cases, 5 validation cases, and 10 private test
cases comprising paired 3D ceT1 MRI, T2 MRI, and post-resection 3D iUS volumes.
Data are provided without annotations for training, while validation and test
performance are evaluated on manually annotated anatomical landmarks. Metrics
include target registration error (TRE), robustness to worst-case landmark
misalignment (TRE30), and runtime. By establishing a standardized evaluation
framework for this clinically critical and technically complex problem,
ReMIND2Reg aims to accelerate the development of robust, generalizable, and
clinically deployable multimodal registration algorithms for image-guided
neurosurgery.

</details>


### [87] [TOTNet: Occlusion-Aware Temporal Tracking for Robust Ball Detection in Sports Videos](https://arxiv.org/abs/2508.09650)
*Hao Xu,Arbind Agrahari Baniya,Sam Wells,Mohamed Reda Bouadjenek,Richard Dazely,Sunil Aryal*

Main category: cs.CV

TL;DR: TOTNet通过3D卷积和遮挡增强技术，显著提升了遮挡情况下的球体跟踪性能，适用于体育分析。


<details>
  <summary>Details</summary>
Motivation: 体育视频分析中遮挡情况下的球体跟踪是一个关键挑战，影响了事件检测和裁判等任务。

Method: TOTNet利用3D卷积、可见性加权损失和遮挡增强技术，结合新的遮挡丰富数据集TTA进行训练。

Result: 在四个数据集上的评估显示，TOTNet将RMSE从37.30降至7.19，并在完全遮挡帧上的准确率从0.63提升至0.80。

Conclusion: TOTNet显著提升了在遮挡情况下的球体跟踪性能，适用于快速运动场景的离线体育分析。

Abstract: Robust ball tracking under occlusion remains a key challenge in sports video
analysis, affecting tasks like event detection and officiating. We present
TOTNet, a Temporal Occlusion Tracking Network that leverages 3D convolutions,
visibility-weighted loss, and occlusion augmentation to improve performance
under partial and full occlusions. Developed in collaboration with Paralympics
Australia, TOTNet is designed for real-world sports analytics. We introduce
TTA, a new occlusion-rich table tennis dataset collected from
professional-level Paralympic matches, comprising 9,159 samples with 1,996
occlusion cases. Evaluated on four datasets across tennis, badminton, and table
tennis, TOTNet significantly outperforms prior state-of-the-art methods,
reducing RMSE from 37.30 to 7.19 and improving accuracy on fully occluded
frames from 0.63 to 0.80. These results demonstrate TOTNets effectiveness for
offline sports analytics in fast-paced scenarios. Code and data
access:\href{https://github.com/AugustRushG/TOTNet}{AugustRushG/TOTNet}.

</details>


### [88] [Noise-adapted Neural Operator for Robust Non-Line-of-Sight Imaging](https://arxiv.org/abs/2508.09655)
*Lianfang Wang,Kuilin Qin,Xueying Liu,Huibin Chang,Yong Wang,Yuping Duan*

Main category: cs.CV

TL;DR: 论文提出了一种基于参数化神经算子的3D非视距成像重建框架，通过噪声估计和特征融合提升重建精度，适用于复杂场景。


<details>
  <summary>Details</summary>
Motivation: 非视距成像中信号弱且易受噪声干扰，需结合物理过程确保准确重建。本文旨在解决大规模线性问题在3D成像重建中的挑战。

Method: 论文采用参数化神经算子来近似逆向映射，结合深度算法展开构建3D图像重建框架，并通过全局与局部时空数据特征的融合方法提升精度和鲁棒性。

Result: 数值实验证明，该方法在模拟和真实数据集上均有效，尤其在快速扫描和稀疏照明点数据中表现优异。

Conclusion: 该论文提出的参数化逆向问题框架和神经算子方法在复杂场景下实现了高效、稳健的3D非视距成像重建，尤其在快速扫描和稀疏照明点数据中表现出色。

Abstract: Computational imaging, especially non-line-of-sight (NLOS) imaging, the
extraction of information from obscured or hidden scenes is achieved through
the utilization of indirect light signals resulting from multiple reflections
or scattering. The inherently weak nature of these signals, coupled with their
susceptibility to noise, necessitates the integration of physical processes to
ensure accurate reconstruction. This paper presents a parameterized inverse
problem framework tailored for large-scale linear problems in 3D imaging
reconstruction. Initially, a noise estimation module is employed to adaptively
assess the noise levels present in transient data. Subsequently, a
parameterized neural operator is developed to approximate the inverse mapping,
facilitating end-to-end rapid image reconstruction. Our 3D image reconstruction
framework, grounded in operator learning, is constructed through deep algorithm
unfolding, which not only provides commendable model interpretability but also
enables dynamic adaptation to varying noise levels in the acquired data,
thereby ensuring consistently robust and accurate reconstruction outcomes.
Furthermore, we introduce a novel method for the fusion of global and local
spatiotemporal data features. By integrating structural and detailed
information, this method significantly enhances both accuracy and robustness.
Comprehensive numerical experiments conducted on both simulated and real
datasets substantiate the efficacy of the proposed method. It demonstrates
remarkable performance with fast scanning data and sparse illumination point
data, offering a viable solution for NLOS imaging in complex scenarios.

</details>


### [89] [NegFaceDiff: The Power of Negative Context in Identity-Conditioned Diffusion for Synthetic Face Generation](https://arxiv.org/abs/2508.09661)
*Eduarda Caldeira,Naser Damer,Fadi Boutros*

Main category: cs.CV

TL;DR: NegFaceDiff通过负条件采样提升身份条件扩散模型的数据质量，改善人脸识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏明确的采样机制来强制类别间分离，导致生成数据中存在身份重叠，影响人脸识别性能。

Method: NegFaceDiff是一种新颖的采样方法，通过在身份条件扩散过程中引入负条件，增强身份分离。

Result: NegFaceDiff显著提升了身份可分性（FDR从2.427提升至5.687），并在多个基准测试中优于未使用负条件的方法。

Conclusion: NegFaceDiff通过引入负条件采样机制，显著提升了身份条件扩散模型生成数据的身份一致性和可分性，从而改善了人脸识别系统的性能。

Abstract: The use of synthetic data as an alternative to authentic datasets in face
recognition (FR) development has gained significant attention, addressing
privacy, ethical, and practical concerns associated with collecting and using
authentic data. Recent state-of-the-art approaches have proposed
identity-conditioned diffusion models to generate identity-consistent face
images, facilitating their use in training FR models. However, these methods
often lack explicit sampling mechanisms to enforce inter-class separability,
leading to identity overlap in the generated data and, consequently, suboptimal
FR performance. In this work, we introduce NegFaceDiff, a novel sampling method
that incorporates negative conditions into the identity-conditioned diffusion
process. NegFaceDiff enhances identity separation by leveraging negative
conditions that explicitly guide the model away from unwanted features while
preserving intra-class consistency. Extensive experiments demonstrate that
NegFaceDiff significantly improves the identity consistency and separability of
data generated by identity-conditioned diffusion models. Specifically, identity
separability, measured by the Fisher Discriminant Ratio (FDR), increases from
2.427 to 5.687. These improvements are reflected in FR systems trained on the
NegFaceDiff dataset, which outperform models trained on data generated without
negative conditions across multiple benchmarks.

</details>


### [90] [GSFixer: Improving 3D Gaussian Splatting with Reference-Guided Video Diffusion Priors](https://arxiv.org/abs/2508.09667)
*Xingyilang Yin,Qi Zhang,Jiahao Chang,Ying Feng,Qingnan Fan,Xi Yang,Chi-Man Pun,Huaqi Zhang,Xiaodong Cun*

Main category: cs.CV

TL;DR: GSFixer通过结合2D和3D特征修复稀疏视图3DGS重建的伪影，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图的3DGS重建因信息不足导致明显伪影，现有生成先验方法难以保持与输入观察的一致性。

Method: GSFixer 基于DiT的视频扩散模型，利用参考视图的2D语义和3D几何特征，通过参考引导的视频修复模型修复3DGS伪影。

Result: 实验证明GSFixer在3DGS伪影修复和稀疏视图3D重建任务中表现优于当前最先进方法。

Conclusion: GSFixer 提出了一种新颖的框架，通过结合2D语义特征和3D几何特征，显著提升了稀疏视图3D高斯溅射（3DGS）重建的质量，并在3DGS伪影修复和稀疏视图3D重建任务中优于现有方法。

Abstract: Reconstructing 3D scenes using 3D Gaussian Splatting (3DGS) from sparse views
is an ill-posed problem due to insufficient information, often resulting in
noticeable artifacts. While recent approaches have sought to leverage
generative priors to complete information for under-constrained regions, they
struggle to generate content that remains consistent with input observations.
To address this challenge, we propose GSFixer, a novel framework designed to
improve the quality of 3DGS representations reconstructed from sparse inputs.
The core of our approach is the reference-guided video restoration model, built
upon a DiT-based video diffusion model trained on paired artifact 3DGS renders
and clean frames with additional reference-based conditions. Considering the
input sparse views as references, our model integrates both 2D semantic
features and 3D geometric features of reference views extracted from the visual
geometry foundation model, enhancing the semantic coherence and 3D consistency
when fixing artifact novel views. Furthermore, considering the lack of suitable
benchmarks for 3DGS artifact restoration evaluation, we present DL3DV-Res which
contains artifact frames rendered using low-quality 3DGS. Extensive experiments
demonstrate our GSFixer outperforms current state-of-the-art methods in 3DGS
artifact restoration and sparse-view 3D reconstruction. Project page:
https://github.com/GVCLab/GSFixer.

</details>


### [91] [PaCo-FR: Patch-Pixel Aligned End-to-End Codebook Learning for Facial Representation Pre-training](https://arxiv.org/abs/2508.09691)
*Yin Xie,Zhichao Chen,Xiaoze Yu,Yongle Zhao,Xiang An,Kaicheng Yang,Zimin Ran,Jia Guo,Ziyong Feng,Jiankang Deng*

Main category: cs.CV

TL;DR: PaCo-FR 是一种无监督面部表示预训练框架，通过结构化掩码和块像素对齐解决了现有方法的三大挑战，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉面部特征、保留空间结构及高效利用有限标注数据方面存在不足。

Method: 结合了掩码图像建模与块像素对齐的无监督框架，包含结构化掩码策略、基于块的代码本和空间一致性约束三个创新组件。

Result: PaCo-FR 在多项面部分析任务中实现了最先进的性能，仅需200万未标注图像进行预训练。

Conclusion: PaCo-FR 提供了一种可扩展且高效的解决方案，减少了对昂贵标注数据的依赖，推动了更有效的面部分析系统的发展。

Abstract: Facial representation pre-training is crucial for tasks like facial
recognition, expression analysis, and virtual reality. However, existing
methods face three key challenges: (1) failing to capture distinct facial
features and fine-grained semantics, (2) ignoring the spatial structure
inherent to facial anatomy, and (3) inefficiently utilizing limited labeled
data. To overcome these, we introduce PaCo-FR, an unsupervised framework that
combines masked image modeling with patch-pixel alignment. Our approach
integrates three innovative components: (1) a structured masking strategy that
preserves spatial coherence by aligning with semantically meaningful facial
regions, (2) a novel patch-based codebook that enhances feature discrimination
with multiple candidate tokens, and (3) spatial consistency constraints that
preserve geometric relationships between facial components. PaCo-FR achieves
state-of-the-art performance across several facial analysis tasks with just 2
million unlabeled images for pre-training. Our method demonstrates significant
improvements, particularly in scenarios with varying poses, occlusions, and
lighting conditions. We believe this work advances facial representation
learning and offers a scalable, efficient solution that reduces reliance on
expensive annotated datasets, driving more effective facial analysis systems.

</details>


### [92] [Slot Attention-based Feature Filtering for Few-Shot Learning](https://arxiv.org/abs/2508.09699)
*Javier Rodenas,Eduardo Aguilar,Petia Radeva*

Main category: cs.CV

TL;DR: SAFF利用插槽注意机制过滤无关特征，提升小样本学习性能，实验证明其在多个基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 无关特征会显著降低小样本学习的性能，容易导致混淆和误分类，因此需要一种有效的方法来过滤这些特征。

Method: 提出基于Slot Attention的特征过滤方法（SAFF），利用插槽注意机制区分和过滤弱特征，并通过相似性矩阵量化过滤后嵌入的相关性。

Result: 在CIFAR-FS、FC100、miniImageNet和tieredImageNet等基准测试中，SAFF表现优于其他先进方法，证明了其有效性。

Conclusion: SAFF通过整合插槽注意机制与补丁嵌入，有效过滤无关特征，显著提升了小样本学习的分类性能。

Abstract: Irrelevant features can significantly degrade few-shot learn ing performance.
This problem is used to match queries and support images based on meaningful
similarities despite the limited data. However, in this process, non-relevant
fea tures such as background elements can easily lead to confu sion and
misclassification. To address this issue, we pro pose Slot Attention-based
Feature Filtering for Few-Shot Learning (SAFF) that leverages slot attention
mechanisms to discriminate and filter weak features, thereby improving few-shot
classification performance. The key innovation of SAFF lies in its integration
of slot attention with patch em beddings, unifying class-aware slots into a
single attention mechanism to filter irrelevant features effectively. We intro
duce a similarity matrix that computes across support and query images to
quantify the relevance of filtered embed dings for classification. Through
experiments, we demon strate that Slot Attention performs better than other
atten tion mechanisms, capturing discriminative features while reducing
irrelevant information. We validate our approach through extensive experiments
on few-shot learning bench marks: CIFAR-FS, FC100, miniImageNet and tieredIma
geNet, outperforming several state-of-the-art methods.

</details>


### [93] [MangaDiT: Reference-Guided Line Art Colorization with Hierarchical Attention in Diffusion Transformers](https://arxiv.org/abs/2508.09709)
*Qianru Qiu,Jiafeng Mao,Kento Masui,Xueting Wang*

Main category: cs.CV

TL;DR: MangaDiT 通过分层注意力机制提升线稿上色的区域级颜色一致性，无需外部标注，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在参考图像和目标图像姿态或动作差异较大时，难以保持区域级颜色一致性，且依赖外部匹配标注。

Method: 提出 MangaDiT，一种基于扩散变换器（DiT）的模型，采用分层注意力机制和动态注意力权重策略，通过内部注意力机制隐式发现语义对应关系。

Result: 在两个基准数据集上的实验表明，MangaDiT 显著优于当前最先进方法。

Conclusion: MangaDiT 在参考引导的线稿上色任务中表现出色，显著优于现有方法，在定性和定量评估中均取得了优异性能。

Abstract: Recent advances in diffusion models have significantly improved the
performance of reference-guided line art colorization. However, existing
methods still struggle with region-level color consistency, especially when the
reference and target images differ in character pose or motion. Instead of
relying on external matching annotations between the reference and target, we
propose to discover semantic correspondences implicitly through internal
attention mechanisms. In this paper, we present MangaDiT, a powerful model for
reference-guided line art colorization based on Diffusion Transformers (DiT).
Our model takes both line art and reference images as conditional inputs and
introduces a hierarchical attention mechanism with a dynamic attention
weighting strategy. This mechanism augments the vanilla attention with an
additional context-aware path that leverages pooled spatial features,
effectively expanding the model's receptive field and enhancing region-level
color alignment. Experiments on two benchmark datasets demonstrate that our
method significantly outperforms state-of-the-art approaches, achieving
superior performance in both qualitative and quantitative evaluations.

</details>


### [94] [NEURAL: Attention-Guided Pruning for Unified Multimodal Resource-Constrained Clinical Evaluation](https://arxiv.org/abs/2508.09715)
*Devvrat Joshi,Islem Rekik*

Main category: cs.CV

TL;DR: NEURAL框架通过语义压缩胸部X光图像，显著减少数据大小而不影响诊断性能。


<details>
  <summary>Details</summary>
Motivation: 多模态医学影像数据的快速增长在资源受限的临床环境中带来了存储和传输的挑战。

Method: 利用生成式视觉-语言模型的交叉注意力分数对胸部X光进行结构修剪，保留诊断关键区域，并将其转换为高度压缩的图表示。

Result: 在MIMIC-CXR和CheXpert Plus数据集上验证，NEURAL实现了93.4-97.7%的图像数据大小减少，同时保持了0.88-0.95 AUC的高诊断性能。

Conclusion: NEURAL框架通过语义引导的数据压缩，有效解决了多模态医学影像数据的存储和传输挑战，同时保持了高诊断性能。

Abstract: The rapid growth of multimodal medical imaging data presents significant
storage and transmission challenges, particularly in resource-constrained
clinical settings. We propose NEURAL, a novel framework that addresses this by
using semantics-guided data compression. Our approach repurposes
cross-attention scores between the image and its radiological report from a
fine-tuned generative vision-language model to structurally prune chest X-rays,
preserving only diagnostically critical regions. This process transforms the
image into a highly compressed, graph representation. This unified graph-based
representation fuses the pruned visual graph with a knowledge graph derived
from the clinical report, creating a universal data structure that simplifies
downstream modeling. Validated on the MIMIC-CXR and CheXpert Plus dataset for
pneumonia detection, NEURAL achieves a 93.4-97.7\% reduction in image data size
while maintaining a high diagnostic performance of 0.88-0.95 AUC, outperforming
other baseline models that use uncompressed data. By creating a persistent,
task-agnostic data asset, NEURAL resolves the trade-off between data size and
clinical utility, enabling efficient workflows and teleradiology without
sacrificing performance. Our NEURAL code is available at
https://github.com/basiralab/NEURAL.

</details>


### [95] [Multimodal Sheaf-based Network for Glioblastoma Molecular Subtype Prediction](https://arxiv.org/abs/2508.09717)
*Shekhnaz Idrissova,Islem Rekik*

Main category: cs.CV

TL;DR: 本文提出了一种基于sheaf的框架，用于融合MRI和组织病理学数据，解决了现有方法在结构信息保留和数据缺失处理上的不足，显著提升了胶质母细胞瘤分子亚型分类的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 胶质母细胞瘤的分子亚型分类是有效靶向治疗选择的重要生物标志物，但目前需要通过侵入性组织提取进行全面的组织病理学分析。现有的多模态方法在保留跨模态共享结构信息方面存在局限，且缺乏处理缺失或不完整模态数据的稳健机制。

Method: 提出了一种新颖的基于sheaf的框架，用于MRI和组织病理学数据的结构感知和一致性融合。该方法解决了现有多模态方法中共享结构信息保留不足的问题，并改善了异构图中判别性特征的保留。

Result: 所提出的模型在基准方法中表现优异，并在数据缺失或不完整的情况下展现出鲁棒性。

Conclusion: 本文提出了一种基于sheaf的框架，用于MRI和组织病理学数据的结构感知和一致性融合，显著优于基线方法，并在数据缺失或不完整的情况下表现出鲁棒性，为快速诊断的虚拟活检工具开发做出了贡献。

Abstract: Glioblastoma is a highly invasive brain tumor with rapid progression rates.
Recent studies have shown that glioblastoma molecular subtype classification
serves as a significant biomarker for effective targeted therapy selection.
However, this classification currently requires invasive tissue extraction for
comprehensive histopathological analysis. Existing multimodal approaches
combining MRI and histopathology images are limited and lack robust mechanisms
for preserving shared structural information across modalities. In particular,
graph-based models often fail to retain discriminative features within
heterogeneous graphs, and structural reconstruction mechanisms for handling
missing or incomplete modality data are largely underexplored. To address these
limitations, we propose a novel sheaf-based framework for structure-aware and
consistent fusion of MRI and histopathology data. Our model outperforms
baseline methods and demonstrates robustness in incomplete or missing data
scenarios, contributing to the development of virtual biopsy tools for rapid
diagnostics. Our source code is available at
https://github.com/basiralab/MMSN/.

</details>


### [96] [Seeing, Listening, Remembering, and Reasoning: A Multimodal Agent with Long-Term Memory](https://arxiv.org/abs/2508.09736)
*Lin Long,Yichen He,Wentao Ye,Yiyuan Pan,Yuan Lin,Hang Li,Junbo Zhao,Wei Li*

Main category: cs.CV

TL;DR: M3-Agent是一个具有长时记忆的多模态代理框架，通过强化学习训练，在多个基准测试中表现优于现有基线，展示了更接近人类记忆和推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发具有人类般长时记忆能力的多模态代理，以更深入、一致地理解环境，并支持多轮迭代推理和任务完成。

Method: M3-Agent是一个多模态代理框架，具有长时记忆能力，能够处理实时视觉和听觉输入，并以实体为中心的多模态格式组织记忆。通过M3-Bench基准测试评估其记忆有效性和基于记忆的推理能力。

Result: M3-Agent在M3-Bench-robot、M3-Bench-web和VideoMME-long基准测试中分别比最强的基线（使用Gemini-1.5-pro和GPT-4o的提示代理）准确率高出6.7%、7.7%和5.3%。

Conclusion: M3-Agent通过强化学习训练，在多模态代理中实现了更接近人类的长时记忆能力，并在多个基准测试中表现优于现有基线，为实际应用设计提供了见解。

Abstract: We introduce M3-Agent, a novel multimodal agent framework equipped with
long-term memory. Like humans, M3-Agent can process real-time visual and
auditory inputs to build and update its long-term memory. Beyond episodic
memory, it also develops semantic memory, enabling it to accumulate world
knowledge over time. Its memory is organized in an entity-centric, multimodal
format, allowing deeper and more consistent understanding of the environment.
Given an instruction, M3-Agent autonomously performs multi-turn, iterative
reasoning and retrieves relevant information from memory to accomplish the
task. To evaluate memory effectiveness and memory-based reasoning in multimodal
agents, we develop M3-Bench, a new long-video question answering benchmark.
M3-Bench comprises 100 newly recorded real-world videos captured from a robot's
perspective (M3-Bench-robot) and 929 web-sourced videos across diverse
scenarios (M3-Bench-web). We annotate question-answer pairs designed to test
key capabilities essential for agent applications, such as human understanding,
general knowledge extraction, and cross-modal reasoning. Experimental results
show that M3-Agent, trained via reinforcement learning, outperforms the
strongest baseline, a prompting agent using Gemini-1.5-pro and GPT-4o,
achieving 6.7%, 7.7%, and 5.3% higher accuracy on M3-Bench-robot, M3-Bench-web
and VideoMME-long, respectively. Our work advances the multimodal agents toward
more human-like long-term memory and provides insights into their practical
design. Model, code and data are available at
https://github.com/bytedance-seed/m3-agent

</details>


### [97] [MoIIE: Mixture of Intra- and Inter-Modality Experts for Large Vision Language Models](https://arxiv.org/abs/2508.09779)
*Dianyi Wang,Siyuan Wang,Zejun Li,Yikun Wang,Yitong Li,Duyu Tang,Xiaoyu Shen,Xuanjing Huang,Zhongyu Wei*

Main category: cs.CV

TL;DR: 提出MoIIE架构，通过专家路由和两阶段训练策略，在LVLMs中高效建模模态内和跨模态特征，性能匹配或超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管稀疏混合专家（MoE）架构提高了参数效率，但在LVLMs中同时建模模态特定特征和跨模态关联仍具挑战性。

Method: 提出了一种混合内外模态专家（MoIIE）架构，通过专家路由根据模态将令牌导向相应的模态内专家和共享的模态间专家池，同时引入两阶段训练策略以激活MoE和多模态能力。

Result: MoIIE模型在5.5B和11.3B激活参数规模下，匹配甚至超越了现有开源MoE-LLMs多模态模型的性能。

Conclusion: 大视觉语言模型（LVLMs）通过引入混合内外模态专家（MoIIE）架构，显著提升了参数效率，并在多模态任务中表现出色，匹配或超越了现有开源MoE-LLMs模型的性能。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable performance
across multi-modal tasks by scaling model size and training data. However,
these dense LVLMs incur significant computational costs and motivate the
exploration of sparse Mixture of Experts (MoE) architectures. While MoE improve
parameter efficiency, effectively applying MoE to simultaneously model
modality-specific features and cross-modal associations in LVLMs remains
challenging. In this work, we propose to incorporate Mixture of Intra- and
Inter-Modality Experts (MoIIE) to LVLMs. For each token, expert routing is
guided by its modality, directing tokens to their respective intra-modality
experts as well as a shared pool of inter-modality experts, enabling the model
to jointly learn rich intra-modal features and cross-modal interactions. We
further introduce an effective and straightforward two-stage training strategy,
which facilitates the direct activation of both MoE and multi-modal
capabilities. Extensive experiments across different data scales and LLM
backbone demonstrate the effectiveness, efficiency and generality of our
approach. Notably, our MoIIE models with 5.5B and 11.3B activated parameters
match or even surpass the performance of existing advanced open-source MoE-LLMs
based multi-modal models that involve more activated parameters. The code is
available at https://github.com/AlenjandroWang/MoIIE.

</details>


### [98] [DSS-Prompt: Dynamic-Static Synergistic Prompting for Few-Shot Class-Incremental Learning](https://arxiv.org/abs/2508.09785)
*Linpu He,Yanan Li,Bingze Li,Elvis Han Cui,Donghui Wang*

Main category: cs.CV

TL;DR: DSS-Prompt通过静态和动态提示的结合，显著提升了少样本类增量学习的性能，解决了灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 探索大规模预训练模型在少样本类增量学习（FSCIL）任务中的应用，解决从有限样本持续学习新概念同时不遗忘旧概念的挑战。

Method: 提出DSS-Prompt方法，利用静态提示弥合预训练与下游任务之间的领域差距，动态提示捕获实例感知语义，并通过预训练多模态模型生成输入相关的多样化语义提示。

Result: 在四个基准测试上的广泛实验表明，DSS-Prompt在性能上优于现有方法，并能有效缓解灾难性遗忘。

Conclusion: DSS-Prompt通过结合静态和动态提示，成功解决了FSCIL任务中的挑战，显著提升了性能并缓解了灾难性遗忘问题。

Abstract: Learning from large-scale pre-trained models with strong generalization
ability has shown remarkable success in a wide range of downstream tasks
recently, but it is still underexplored in the challenging few-shot
class-incremental learning (FSCIL) task. It aims to continually learn new
concepts from limited training samples without forgetting the old ones at the
same time. In this paper, we introduce DSS-Prompt, a simple yet effective
approach that transforms the pre-trained Vision Transformer with minimal
modifications in the way of prompts into a strong FSCIL classifier. Concretely,
we synergistically utilize two complementary types of prompts in each
Transformer block: static prompts to bridge the domain gap between the
pre-training and downstream datasets, thus enabling better adaption; and
dynamic prompts to capture instance-aware semantics, thus enabling easy
transfer from base to novel classes. Specially, to generate dynamic prompts, we
leverage a pre-trained multi-modal model to extract input-related diverse
semantics, thereby generating complementary input-aware prompts, and then
adaptively adjust their importance across different layers. In this way, on top
of the prompted visual embeddings, a simple prototype classifier can beat
state-of-the-arts without further training on the incremental tasks. We conduct
extensive experiments on four benchmarks to validate the effectiveness of our
DSS-Prompt and show that it consistently achieves better performance than
existing approaches on all datasets and can alleviate the catastrophic
forgetting issue as well.

</details>


### [99] [MeMoSORT: Memory-Assisted Filtering and Motion-Adaptive Association Metric for Multi-Person Tracking](https://arxiv.org/abs/2508.09796)
*Yingjie Wang,Zhixing Wang,Le Zheng,Tianxiao Liu,Roujing Li,Xueyao Hu*

Main category: cs.CV

TL;DR: MeMoSORT是一种实时多目标跟踪方法，通过记忆增强的Kalman滤波器和自适应IoU关联，显著提升了复杂场景下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于检测的跟踪方法因依赖Kalman滤波器和刚性IoU关联，在复杂运动和遮挡情况下表现不佳，导致跟踪错误或目标丢失。

Method: 提出MeMoSORT跟踪器，结合Memory-assisted Kalman filter（MeKF）和Motion-adaptive IoU（Mo-IoU），前者通过记忆增强神经网络补偿运动模型的不匹配，后者自适应扩展匹配空间并引入高度相似性以减少检测错误和关联失败的影响。

Result: 在DanceTrack和SportsMOT数据集上，MeMoSORT分别取得了67.9%和82.1%的HOTA分数，达到了最先进的性能。

Conclusion: MeMoSORT通过引入MeKF和Mo-IoU两项创新，显著提升了多目标跟踪在复杂场景下的性能，实现了实时高效的跟踪效果。

Abstract: Multi-object tracking (MOT) in human-dominant scenarios, which involves
continuously tracking multiple people within video sequences, remains a
significant challenge in computer vision due to targets' complex motion and
severe occlusions. Conventional tracking-by-detection methods are fundamentally
limited by their reliance on Kalman filter (KF) and rigid Intersection over
Union (IoU)-based association. The motion model in KF often mismatches
real-world object dynamics, causing filtering errors, while rigid association
struggles under occlusions, leading to identity switches or target loss. To
address these issues, we propose MeMoSORT, a simple, online, and real-time MOT
tracker with two key innovations. First, the Memory-assisted Kalman filter
(MeKF) uses memory-augmented neural networks to compensate for mismatches
between assumed and actual object motion. Second, the Motion-adaptive IoU
(Mo-IoU) adaptively expands the matching space and incorporates height
similarity to reduce the influence of detection errors and association
failures, while remaining lightweight. Experiments on DanceTrack and SportsMOT
show that MeMoSORT achieves state-of-the-art performance, with HOTA scores of
67.9\% and 82.1\%, respectively.

</details>


### [100] [MUJICA: Reforming SISR Models for PBR Material Super-Resolution via Cross-Map Attention](https://arxiv.org/abs/2508.09802)
*Xin Du,Maoyuan Xu,Zhi Ying*

Main category: cs.CV

TL;DR: MUJICA通过跨图注意力机制提升预训练SISR模型在PBR材质超分辨率中的性能，解决跨图不一致等问题，实现高效训练和先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有SISR方法在PBR材质超分辨率中存在跨图不一致、模态特征建模不足及数据分布偏移导致的泛化能力有限问题。

Method: 提出MUJICA，一种灵活适配器，通过跨图注意力机制融合预训练的Swin-transformer-based SISR模型特征，优化PBR材质超分辨率。

Result: MUJICA在SwinIR、DRCT和HMANet等SISR模型上显著提升了PSNR、SSIM和LPIPS分数，并保持跨图一致性。

Conclusion: MUJICA通过跨图注意力机制有效提升了预训练SISR模型在PBR材质超分辨率任务中的性能，同时保持了跨图一致性，并在资源有限的情况下实现了高效训练和先进性能。

Abstract: Physically Based Rendering (PBR) materials are typically characterized by
multiple 2D texture maps such as basecolor, normal, metallic, and roughness
which encode spatially-varying bi-directional reflectance distribution function
(SVBRDF) parameters to model surface reflectance properties and microfacet
interactions. Upscaling SVBRDF material is valuable for modern 3D graphics
applications. However, existing Single Image Super-Resolution (SISR) methods
struggle with cross-map inconsistency, inadequate modeling of modality-specific
features, and limited generalization due to data distribution shifts. In this
work, we propose Multi-modal Upscaling Joint Inference via Cross-map Attention
(MUJICA), a flexible adapter that reforms pre-trained Swin-transformer-based
SISR models for PBR material super-resolution. MUJICA is seamlessly attached
after the pre-trained and frozen SISR backbone. It leverages cross-map
attention to fuse features while preserving remarkable reconstruction ability
of the pre-trained SISR model. Applied to SISR models such as SwinIR, DRCT, and
HMANet, MUJICA improves PSNR, SSIM, and LPIPS scores while preserving cross-map
consistency. Experiments demonstrate that MUJICA enables efficient training
even with limited resources and delivers state-of-the-art performance on PBR
material datasets.

</details>


### [101] [Poaching Hotspot Identification Using Satellite Imagery](https://arxiv.org/abs/2508.09812)
*Aryan Pandhi,Shrey Baid,Sanjali Jha*

Main category: cs.CV

TL;DR: 非洲象偷猎问题严重，偷猎热点动态变化，计算机视觉模型结合卫星图像可高效识别热点区域，优化资源部署。


<details>
  <summary>Details</summary>
Motivation: 非洲象因偷猎濒临灭绝，偷猎地点动态变化且反偷猎资源部署不均衡，亟需一种高效、非侵入式的监测方法。

Method: 利用计算机视觉模型结合卫星图像，分析地理和环境指标，预测偷猎热点区域。

Result: 研究表明，偷猎热点区域受巡逻密度、水源、季节等多因素影响，传统方法难以应对，计算机视觉模型提供了新的解决方案。

Conclusion: 需要一种计算机视觉模型来动态识别偷猎热点区域，以更高效地部署反偷猎资源。

Abstract: Elephant Poaching in African countries has been a decade-old problem. So much
so that African Forest Elephants are now listed as an endangered species, and
African Savannah Elephants as critically endangered by the IUCN (International
Union for Conservation of Nature). [1] Elephants are hunted primarily for their
ivory tusks which caused many elephants to be born tuskless as a genetic
modification for survival. [2] Data gathered by recent studies shows that
though poaching methods remain the same, the poaching grounds are rather
dynamic. Poachers have shifted to areas with less ranger patrols and several
other factors like watering holes, seasons, altitude etc. cause constant shifts
in poaching hotspot locations. [3] After a period of low poaching from
2000-2014, poaching numbers in African countries are now on the rise again --
WWF (World Wildlife Foundation) says there are 20,000 elephants poached
annually [4]. In African countries, anti-poaching efforts are concentrated near
towns, while a majority of poaching occurs in the deserted regions. All of
these factors result in the need for a Computer Vision Model to identify
poaching hotspots through locating the geographic indicators of favorable
poaching regions. A CV model eliminates the need to manually track poachers and
account for the environmental factors to deploy resources and its combination
with satellite imagery allows us to survey large areas without disturbing local
species or cross border aviation restrictions.

</details>


### [102] [Evolution of Low-Level and Texture Human-CLIP Alignment](https://arxiv.org/abs/2508.09814)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra*

Main category: cs.CV

TL;DR: CLIP训练早期与低层次人类感知相关性高，后期转向抽象表征，揭示了感知与鲁棒性的权衡。


<details>
  <summary>Details</summary>
Motivation: 观察到CLIP模型训练早期与低层次人类图像质量评估的相关性先升后降的现象，旨在探究其成因及潜在学习机制。

Method: 通过分析形状-纹理偏置对齐和噪声下的分类准确率下降两个关键因素，研究了CLIP模型训练过程中与人类低层次图像质量评估相关性的变化。

Result: CLIP初期学习低层次视觉特征，增强了与人类感知的对齐但增加了对噪声的敏感性；后期转向抽象形状表征，提高了鲁棒性但降低了对齐性。

Conclusion: 研究发现CLIP模型在训练过程中从低层次视觉特征转向抽象形状表征，揭示了感知对齐与鲁棒性之间的权衡机制，为优化视觉语言模型提供了新见解。

Abstract: During the training of multi-modal models like CLIP, we observed an
intriguing phenomenon: the correlation with low-level human image quality
assessments peaks in the early epochs before gradually declining. This study
investigates this observation and seeks to understand its causes through two
key factors: shape-texture bias alignment and classification accuracy drop
under noise. Our findings suggest that CLIP initially learn low-level visual
features, enhancing its alignment with low-level human perception but also
increasing its sensitivity to noise and its texture bias. As training
progresses, the model shifts toward more abstract shape-based representations,
improving noise robustness but reducing alignment with low-level human
perception. These results suggest that these factors shared an underlying
learning mechanism and provide new insights into optimizing the trade-off
between perceptual alignment and robustness in vision-language models.

</details>


### [103] [ViMoNet: A Multimodal Vision-Language Framework for Human Behavior Understanding from Motion and Video](https://arxiv.org/abs/2508.09818)
*Rajan Das Gupta,Md Yeasin Rahat,Nafiz Fahad,Abir Ahmed,Liew Tze Hui*

Main category: cs.CV

TL;DR: ViMoNet通过联合训练视频和运动数据，提升了人类行为理解的性能，并提出了新数据集VIMOS和评估基准ViMoNet-Bench。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅关注单一数据类型（运动或视频），无法全面捕捉人类行为的细微差别。

Method: 提出了ViMoNet框架，采用联合训练策略，结合精确的运动-文本数据和通用的视频-文本数据。

Result: ViMoNet在标题生成、运动理解和行为解释等任务上表现优于现有方法。

Conclusion: ViMoNet通过结合视频和运动数据，显著提升了人类行为理解的能力，并在多个任务上优于现有方法。

Abstract: This study investigates how large language models (LLMs) can be used to
understand human behavior using motion and video data. We think that mixing
both types is essential to completely capture the nuanced movements and
meanings of human actions, in contrast to recent models that simply concentrate
on motion data or films. To address this, we provide ViMoNet, a straightforward
yet effective framework for comprehending, characterizing, and deducing human
action. ViMoNet employs a joint training strategy that leverages the advantages
of two data types: detailed motion-text data, which is more exact, and generic
video-text data, which is more comprehensive but less detailed. This aids in
the model's acquisition of rich data regarding time and space in human
behavior. Additionally, we provide a brand new dataset named VIMOS that
contains a variety of films, motion sequences, instructions, and subtitles. We
developed ViMoNet-Bench, a standardized benchmark with carefully labeled
samples, to evaluate how well models understand human behavior. Our tests show
that ViMoNet outperforms existing methods in caption generation, motion
understanding, and behavior interpretation.

</details>


### [104] [Physical Autoregressive Model for Robotic Manipulation without Action Pretraining](https://arxiv.org/abs/2508.09822)
*Zijian Song,Sihan Qin,Tianshui Chen,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: PAR利用自回归视频生成模型，通过物理令牌和连续令牌建模，实现了高效的机器人操作和视频预测。


<details>
  <summary>Details</summary>
Motivation: 由于机器人操作数据的稀缺性，研究者利用来自其他模态的预训练大模型来理解和预测物理动态。

Method: PAR结合了物理令牌、DiT-based去令牌化器、因果掩码与逆运动学、并行训练和KV缓存机制，以提高性能和效率。

Result: 在ManiSkill基准测试中，PAR在PushCube任务上实现了100%的成功率，在其他任务上匹配了动作预训练基线的性能，并能准确预测未来视频。

Conclusion: PAR通过从自回归视频预训练中迁移世界知识，为机器人操作提供了一个有前景的方向，实现了高成功率和准确的视频预测。

Abstract: The scarcity of manipulation data has motivated the use of pretrained large
models from other modalities in robotics. In this work, we build upon
autoregressive video generation models to propose a Physical Autoregressive
Model (PAR), where physical tokens combine frames and actions to represent the
joint evolution of the robot and its environment. PAR leverages the world
knowledge embedded in video pretraining to understand physical dynamics without
requiring action pretraining, enabling accurate video prediction and consistent
action trajectories. It also adopts a DiT-based de-tokenizer to model frames
and actions as continuous tokens, mitigating quantization errors and
facilitating mutual enhancement. Furthermore, we incorporate a causal mask with
inverse kinematics, parallel training, and the KV-cache mechanism to further
improve performance and efficiency. Experiments on the ManiSkill benchmark show
that PAR achieves a 100\% success rate on the PushCube task, matches the
performance of action-pretrained baselines on other tasks, and accurately
predicts future videos with tightly aligned action trajectories. These findings
underscore a promising direction for robotic manipulation by transferring world
knowledge from autoregressive video pretraining.

</details>


### [105] [KonfAI: A Modular and Fully Configurable Framework for Deep Learning in Medical Imaging](https://arxiv.org/abs/2508.09823)
*Valentin Boussot,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: KonfAI是一个模块化、可配置的深度学习框架，专为医学影像任务设计，通过YAML配置文件简化工作流程，支持高级策略，已在多个挑战中取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 提高医学影像任务的复现性、透明度和实验可追溯性，同时减少开发时间。

Method: 通过结构化的YAML配置文件定义完整的训练、推理和评估工作流程，无需修改底层代码。支持高级策略如基于补丁的学习、测试时增强、模型集成和深度监督的中间特征表示直接访问。

Result: 成功应用于分割、配准和图像合成任务，并在多个国际医学影像挑战中取得优异成绩。

Conclusion: KonfAI是一个模块化、可扩展且完全可配置的深度学习框架，专为医学影像任务设计，已在多个国际医学影像挑战中取得优异成绩。

Abstract: KonfAI is a modular, extensible, and fully configurable deep learning
framework specifically designed for medical imaging tasks. It enables users to
define complete training, inference, and evaluation workflows through
structured YAML configuration files, without modifying the underlying code.
This declarative approach enhances reproducibility, transparency, and
experimental traceability while reducing development time. Beyond the
capabilities of standard pipelines, KonfAI provides native abstractions for
advanced strategies including patch-based learning, test-time augmentation,
model ensembling, and direct access to intermediate feature representations for
deep supervision. It also supports complex multi-model training setups such as
generative adversarial architectures. Thanks to its modular and extensible
architecture, KonfAI can easily accommodate custom models, loss functions, and
data processing components. The framework has been successfully applied to
segmentation, registration, and image synthesis tasks, and has contributed to
top-ranking results in several international medical imaging challenges. KonfAI
is open source and available at
\href{https://github.com/vboussot/KonfAI}{https://github.com/vboussot/KonfAI}.

</details>


### [106] [Reverse Convolution and Its Applications to Image Restoration](https://arxiv.org/abs/2508.09824)
*Xuhong Huang,Shiqi Liu,Kai Zhang,Ying Tai,Jian Yang,Hui Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种深度反向卷积算子，通过优化问题实现卷积的逆运算，并构建了反向卷积块，实验证明其在不同图像恢复任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于转置卷积（即反卷积）在数学表达上与卷积存在固有差异，无法作为卷积的真正逆运算。目前尚未有反向卷积算子被确立为神经架构中的标准组件。

Method: 通过公式化和求解正则化最小二乘优化问题，提出了一种新颖的深度反向卷积算子，并深入研究了其核初始化、填充策略等关键方面。基于该算子，进一步构建了反向卷积块，结合层归一化、1×1卷积和GELU激活，形成类似Transformer的结构。

Result: 通过训练ConverseNet的三个变体（分别用于高斯去噪、超分辨率和去模糊），实验证明了所提出的反向卷积算子作为基本构建模块的有效性。

Conclusion: 本文提出的深度反向卷积算子及其构建的反向卷积块，能够有效替代传统卷积和转置卷积层，为深度模型设计和应用中的新算子开发铺平了道路。

Abstract: Convolution and transposed convolution are fundamental operators widely used
in neural networks. However, transposed convolution (a.k.a. deconvolution) does
not serve as a true inverse of convolution due to inherent differences in their
mathematical formulations. To date, no reverse convolution operator has been
established as a standard component in neural architectures. In this paper, we
propose a novel depthwise reverse convolution operator as an initial attempt to
effectively reverse depthwise convolution by formulating and solving a
regularized least-squares optimization problem. We thoroughly investigate its
kernel initialization, padding strategies, and other critical aspects to ensure
its effective implementation. Building upon this operator, we further construct
a reverse convolution block by combining it with layer normalization,
1$\times$1 convolution, and GELU activation, forming a Transformer-like
structure. The proposed operator and block can directly replace conventional
convolution and transposed convolution layers in existing architectures,
leading to the development of ConverseNet. Corresponding to typical image
restoration models such as DnCNN, SRResNet and USRNet, we train three variants
of ConverseNet for Gaussian denoising, super-resolution and deblurring,
respectively. Extensive experiments demonstrate the effectiveness of the
proposed reverse convolution operator as a basic building module. We hope this
work could pave the way for developing new operators in deep model design and
applications.

</details>


### [107] [Hierarchical Graph Attention Network for No-Reference Omnidirectional Image Quality Assessment](https://arxiv.org/abs/2508.09843)
*Hao Yang,Xu Zhang,Jiaqi Ma,Linwei Zhu,Yun Zhang,Huan Zhang*

Main category: cs.CV

TL;DR: 提出一种基于图神经网络的OIQA框架，通过斐波那契球采样和GAT/图变换器建模视口间关系，显著提升局部非均匀失真评估性能。


<details>
  <summary>Details</summary>
Motivation: 当前OIQA方法在评估局部非均匀失真时表现不足，缺乏对空间质量变化的有效建模和特征表示。

Method: 采用斐波那契球采样生成视口，构建图节点，结合多阶段特征提取网络和GAT与图变换器，捕捉局部和长程质量依赖关系。

Result: 在两个大规模OIQA数据库上的实验表明，该方法显著优于现有方法。

Conclusion: 该论文提出的基于图神经网络的OIQA框架在评估局部非均匀失真方面表现出色，显著优于现有方法，并展示了强大的泛化能力。

Abstract: Current Omnidirectional Image Quality Assessment (OIQA) methods struggle to
evaluate locally non-uniform distortions due to inadequate modeling of spatial
variations in quality and ineffective feature representation capturing both
local details and global context. To address this, we propose a graph neural
network-based OIQA framework that explicitly models structural relationships
between viewports to enhance perception of spatial distortion non-uniformity.
Our approach employs Fibonacci sphere sampling to generate viewports with
well-structured topology, representing each as a graph node. Multi-stage
feature extraction networks then derive high-dimensional node representation.
To holistically capture spatial dependencies, we integrate a Graph Attention
Network (GAT) modeling fine-grained local distortion variations among adjacent
viewports, and a graph transformer capturing long-range quality interactions
across distant regions. Extensive experiments on two large-scale OIQA databases
with complex spatial distortions demonstrate that our method significantly
outperforms existing approaches, confirming its effectiveness and strong
generalization capability.

</details>


### [108] [Enhancing Diffusion Face Generation with Contrastive Embeddings and SegFormer Guidance](https://arxiv.org/abs/2508.09847)
*Dhruvraj Singh Rawat,Enggen Sherpa,Rishikesan Kirupanantha,Tin Hoang*

Main category: cs.CV

TL;DR: 研究在小规模数据集上评估扩散模型的人脸生成，通过对比嵌入和高级分割编码提升语义对齐和可控性。


<details>
  <summary>Details</summary>
Motivation: 评估扩散模型在小规模CelebAMask-HQ数据集上的表现，提升属性引导合成的语义对齐和可控性。

Method: 研究了UNet和DiT架构的无条件生成，并探索了基于LoRA的预训练Stable Diffusion模型微调。集成了InfoNCE损失用于属性嵌入，并采用了SegFormer-based分割编码器。

Result: 结果表明，对比嵌入学习和高级分割编码在有限数据条件下有效提升了可控人脸生成的效果。

Conclusion: 对比嵌入学习和高级分割编码在小规模数据集上的人脸生成任务中表现出色，提升了语义对齐和可控性。

Abstract: We present a benchmark of diffusion models for human face generation on a
small-scale CelebAMask-HQ dataset, evaluating both unconditional and
conditional pipelines. Our study compares UNet and DiT architectures for
unconditional generation and explores LoRA-based fine-tuning of pretrained
Stable Diffusion models as a separate experiment. Building on the
multi-conditioning approach of Giambi and Lisanti, which uses both attribute
vectors and segmentation masks, our main contribution is the integration of an
InfoNCE loss for attribute embedding and the adoption of a SegFormer-based
segmentation encoder. These enhancements improve the semantic alignment and
controllability of attribute-guided synthesis. Our results highlight the
effectiveness of contrastive embedding learning and advanced segmentation
encoding for controlled face generation in limited data settings.

</details>


### [109] [Do Vision Transformers See Like Humans? Evaluating their Perceptual Alignment](https://arxiv.org/abs/2508.09850)
*Pablo Hernández-Cámara,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Valero Laparra,Jesus Malo*

Main category: cs.CV

TL;DR: 研究发现ViT模型越大、数据增强和正则化越强，与人类感知的对齐性越低，重复训练图像也会降低对齐性。


<details>
  <summary>Details</summary>
Motivation: 尽管ViTs在图像识别任务中表现出色，但其与人类感知的对齐性仍未被充分探索。

Method: 系统分析了模型大小、数据集大小、数据增强和正则化对ViT在TID2013数据集上与人类判断的感知对齐的影响。

Result: 发现更大的模型表现出较低的感知对齐；增加数据集多样性影响有限，但重复训练图像会降低对齐性；更强的数据增强和正则化进一步降低对齐性，尤其是在重复训练周期中。

Conclusion: 研究强调了模型复杂性、训练策略与人类感知对齐之间的权衡，为需要类似人类视觉理解的应用提供了重要考虑。

Abstract: Vision Transformers (ViTs) achieve remarkable performance in image
recognition tasks, yet their alignment with human perception remains largely
unexplored. This study systematically analyzes how model size, dataset size,
data augmentation and regularization impact ViT perceptual alignment with human
judgments on the TID2013 dataset. Our findings confirm that larger models
exhibit lower perceptual alignment, consistent with previous works. Increasing
dataset diversity has a minimal impact, but exposing models to the same images
more times reduces alignment. Stronger data augmentation and regularization
further decrease alignment, especially in models exposed to repeated training
cycles. These results highlight a trade-off between model complexity, training
strategies, and alignment with human perception, raising important
considerations for applications requiring human-like visual understanding.

</details>


### [110] [OneVAE: Joint Discrete and Continuous Optimization Helps Discrete Video VAE Train Better](https://arxiv.org/abs/2508.09857)
*Yupeng Zhou,Zhen Li,Ziheng Ouyang,Yuming Chen,Ruoyi Du,Daquan Zhou,Bin Fu,Yihao Liu,Peng Gao,Ming-Ming Cheng,Qibin Hou*

Main category: cs.CV

TL;DR: OneVAE结合连续和离散VAE优势，通过FSQ和多令牌量化机制，显著提升离散视频VAE的训练效率和重建质量。


<details>
  <summary>Details</summary>
Motivation: 离散视频VAE在训练稳定性、时间和重建质量方面存在问题，而连续VAE表现更优。通过结合两者优势，提升离散视频VAE的性能。

Method: 利用FSQ保持预训练连续VAE的先验，结合多令牌量化机制和强化首帧重建技术，提出联合离散-连续优化方案。

Result: OneVAE收敛速度比从头训练快数倍，并在PSNR上提升近1 dB，同时在4x16x16离散VAE上显著提升性能。

Conclusion: OneVAE通过结合连续和离散表示的优势，提出了一种统一的优化方案，首次在单一网络中实现了对两种表示形式的竞争性性能。

Abstract: Encoding videos into discrete tokens could align with text tokens to
facilitate concise and unified multi-modal LLMs, yet introducing significant
spatiotemporal compression compared to continuous video representation.
Previous discrete video VAEs experienced unstable training, long training time,
and degraded reconstruction quality. Given the easier training and superior
performance of continuous VAEs, an intuitive idea is to enhance discrete video
VAEs by leveraging continuous VAEs. After rethinking the intrinsic link between
discrete and continuous representations, we found that FSQ could effectively
preserve pre-trained continuous VAE priors compared to other quantization
methods. By leveraging continuous VAE priors, it converges several times faster
than training from scratch and achieves superior performance at convergence.
Meanwhile, two structural improvements are proposed. First, inspired by how
continuous VAEs enhance reconstruction via enlarged latent dimensions, we
introduce a multi-token quantization mechanism, which achieves nearly a 1 dB
improvement in PSNR without compromising the token compression ratio. Second,
to tackle reconstruction challenges in high-compression video VAEs, we
strengthen first-frame reconstruction, enabling the causal VAE to leverage this
information in subsequent frames and markedly improving the performance of 4 x
16 x 16 discrete VAEs. Furthermore, we propose a joint discrete-continuous
optimization scheme that unifies the two paradigms and, for the first time,
achieves competitive performance on both continuous and discrete
representations within a single network. We name our method OneVAE to reflect
this connection.

</details>


### [111] [HumanGenesis: Agent-Based Geometric and Generative Modeling for Synthetic Human Dynamics](https://arxiv.org/abs/2508.09858)
*Weiqi Li,Zehao Zhang,Liang Lin,Guangrun Wang*

Main category: cs.CV

TL;DR: HumanGenesis是一个整合几何与生成建模的框架，通过四个协作代理解决合成人类动态视频中的几何不一致和运动泛化问题，实现了高质量的文本引导合成、视频重演和新姿势生成。


<details>
  <summary>Details</summary>
Motivation: 当前合成人类动态的方法面临几何不一致、重建粗糙、运动泛化能力有限和场景不协调等挑战，HumanGenesis旨在解决这些问题。

Method: HumanGenesis框架包含四个协作代理：Reconstructor（使用3D高斯泼溅和变形分解从单目视频构建3D一致的人-场景表示）、Critique Agent（通过多轮MLLM反射识别并优化低质量区域）、Pose Guider（利用时间感知参数编码器生成富有表现力的姿势序列）、Video Harmonizer（通过混合渲染管道和扩散技术合成逼真视频）。

Result: HumanGenesis在文本引导合成、视频重演和新姿势生成等任务中表现优异，显著提升了表达力、几何保真度和场景整合能力。

Conclusion: HumanGenesis通过整合几何和生成建模，显著提升了合成人类动态视频的表达力、几何保真度和场景整合能力，在文本引导合成、视频重演和新姿势生成等任务中达到了最先进水平。

Abstract: \textbf{Synthetic human dynamics} aims to generate photorealistic videos of
human subjects performing expressive, intention-driven motions. However,
current approaches face two core challenges: (1) \emph{geometric inconsistency}
and \emph{coarse reconstruction}, due to limited 3D modeling and detail
preservation; and (2) \emph{motion generalization limitations} and \emph{scene
inharmonization}, stemming from weak generative capabilities. To address these,
we present \textbf{HumanGenesis}, a framework that integrates geometric and
generative modeling through four collaborative agents: (1)
\textbf{Reconstructor} builds 3D-consistent human-scene representations from
monocular video using 3D Gaussian Splatting and deformation decomposition. (2)
\textbf{Critique Agent} enhances reconstruction fidelity by identifying and
refining poor regions via multi-round MLLM-based reflection. (3) \textbf{Pose
Guider} enables motion generalization by generating expressive pose sequences
using time-aware parametric encoders. (4) \textbf{Video Harmonizer} synthesizes
photorealistic, coherent video via a hybrid rendering pipeline with diffusion,
refining the Reconstructor through a Back-to-4D feedback loop. HumanGenesis
achieves state-of-the-art performance on tasks including text-guided synthesis,
video reenactment, and novel-pose generalization, significantly improving
expressiveness, geometric fidelity, and scene integration.

</details>


### [112] [E-4DGS: High-Fidelity Dynamic Reconstruction from the Multi-view Event Cameras](https://arxiv.org/abs/2508.09912)
*Chaoran Feng,Zhenyu Tang,Wangbo Yu,Yatian Pang,Yian Zhao,Jianbin Zhao,Li Yuan,Yonghong Tian*

Main category: cs.CV

TL;DR: E-4DGS 是一种基于事件相机的动态高斯泼溅方法，解决了高速运动和低光场景下的新视角合成问题，性能优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 传统RGB相机在光照不足、运动模糊和动态范围有限等场景中存在局限性，而事件相机的高动态范围和高时间分辨率为解决这些问题提供了新视角。

Method: 提出事件驱动的动态高斯泼溅方法（E-4DGS），包括事件初始化方案、事件自适应切片泼溅、强度重要性修剪和自适应对比度阈值优化。

Result: E-4DGS 在合成多视角事件流数据集上表现优于纯事件和事件-RGB融合基线方法，验证了其有效性。

Conclusion: E-4DGS 提出了一种基于事件相机的动态高斯泼溅方法，显著提升了在高速运动和低光场景下的新视角合成性能，为多视角事件流重建开辟了新途径。

Abstract: Novel view synthesis and 4D reconstruction techniques predominantly rely on
RGB cameras, thereby inheriting inherent limitations such as the dependence on
adequate lighting, susceptibility to motion blur, and a limited dynamic range.
Event cameras, offering advantages of low power, high temporal resolution and
high dynamic range, have brought a new perspective to addressing the scene
reconstruction challenges in high-speed motion and low-light scenes. To this
end, we propose E-4DGS, the first event-driven dynamic Gaussian Splatting
approach, for novel view synthesis from multi-view event streams with
fast-moving cameras. Specifically, we introduce an event-based initialization
scheme to ensure stable training and propose event-adaptive slicing splatting
for time-aware reconstruction. Additionally, we employ intensity importance
pruning to eliminate floating artifacts and enhance 3D consistency, while
incorporating an adaptive contrast threshold for more precise optimization. We
design a synthetic multi-view camera setup with six moving event cameras
surrounding the object in a 360-degree configuration and provide a benchmark
multi-view event stream dataset that captures challenging motion scenarios. Our
approach outperforms both event-only and event-RGB fusion baselines and paves
the way for the exploration of multi-view event-based reconstruction as a novel
approach for rapid scene capture.

</details>


### [113] [SpeechForensics: Audio-Visual Speech Representation Learning for Face Forgery Detection](https://arxiv.org/abs/2508.09913)
*Yachao Liang,Min Yu,Gang Li,Jianguo Jiang,Boquan Li,Feng Yu,Ning Zhang,Xiang Meng,Weiqing Huang*

Main category: cs.CV

TL;DR: 通过音频-视觉语音表示学习提升伪造视频检测的泛化能力和鲁棒性，无需伪造视频训练。


<details>
  <summary>Details</summary>
Motivation: 音频信号富含语音内容，能有效反映面部运动，为伪造视频检测提供了新思路。

Method: 首先通过自监督掩码预测任务学习真实视频中的精确音频-视觉语音表示，同时编码局部和全局语义信息，然后将模型直接迁移到伪造检测任务。

Result: 在跨数据集泛化和鲁棒性方面优于现有最先进方法。

Conclusion: 该方法通过音频-视觉语音表示学习，显著提升了跨数据集泛化能力和鲁棒性，无需任何伪造视频参与训练即可超越现有最先进方法。

Abstract: Detection of face forgery videos remains a formidable challenge in the field
of digital forensics, especially the generalization to unseen datasets and
common perturbations. In this paper, we tackle this issue by leveraging the
synergy between audio and visual speech elements, embarking on a novel approach
through audio-visual speech representation learning. Our work is motivated by
the finding that audio signals, enriched with speech content, can provide
precise information effectively reflecting facial movements. To this end, we
first learn precise audio-visual speech representations on real videos via a
self-supervised masked prediction task, which encodes both local and global
semantic information simultaneously. Then, the derived model is directly
transferred to the forgery detection task. Extensive experiments demonstrate
that our method outperforms the state-of-the-art methods in terms of
cross-dataset generalization and robustness, without the participation of any
fake video in model training. Code is available at
https://github.com/Eleven4AI/SpeechForensics.

</details>


### [114] [Towards Comprehensive Cellular Characterisation of H&E slides](https://arxiv.org/abs/2508.09926)
*Benjamin Adjadj,Pierre-Antoine Bannier,Guillaume Horent,Sebastien Mandela,Aurore Lyon,Kathryn Schutte,Ulysse Marteau,Valentin Gaury,Laura Dumont,Thomas Mathieu,Reda Belbahri,Benoît Schmauch,Eric Durand,Katharina Von Loga,Lucie Gillet*

Main category: cs.CV

TL;DR: HistoPLUS是一种先进的细胞分析模型，在未充分研究的细胞类型和跨领域泛化上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有方法在未充分研究的细胞类型上表现不佳，且跨领域泛化能力有限。

Method: 使用一个新颖的泛癌数据集（包含108,722个核，覆盖13种细胞类型）训练HistoPLUS模型。

Result: 在4个独立队列的外部验证中，HistoPLUS在检测质量上优于现有最佳模型5.2%，整体F1分类分数提升23.7%，且参数数量减少5倍。

Conclusion: HistoPLUS 显著提升了细胞检测、分割和分类的性能，特别是在未充分研究的细胞类型上，并展示了强大的跨领域泛化能力。

Abstract: Cell detection, segmentation and classification are essential for analyzing
tumor microenvironments (TME) on hematoxylin and eosin (H&E) slides. Existing
methods suffer from poor performance on understudied cell types (rare or not
present in public datasets) and limited cross-domain generalization. To address
these shortcomings, we introduce HistoPLUS, a state-of-the-art model for cell
analysis, trained on a novel curated pan-cancer dataset of 108,722 nuclei
covering 13 cell types. In external validation across 4 independent cohorts,
HistoPLUS outperforms current state-of-the-art models in detection quality by
5.2% and overall F1 classification score by 23.7%, while using 5x fewer
parameters. Notably, HistoPLUS unlocks the study of 7 understudied cell types
and brings significant improvements on 8 of 13 cell types. Moreover, we show
that HistoPLUS robustly transfers to two oncology indications unseen during
training. To support broader TME biomarker research, we release the model
weights and inference code at https://github.com/owkin/histoplus/.

</details>


### [115] [Quo Vadis Handwritten Text Generation for Handwritten Text Recognition?](https://arxiv.org/abs/2508.09936)
*Vittorio Pippi,Konstantina Nikolaidou,Silvia Cascianelli,George Retsinas,Giorgos Sfikas,Rita Cucchiara,Marcus Liwicki*

Main category: cs.CV

TL;DR: 研究评估了三种HTG模型在低资源HTR中的效果，提供了模型选择指南和改进方向。


<details>
  <summary>Details</summary>
Motivation: 解决历史手稿数字化中HTR系统面临的挑战，尤其是小规模、作者特定集合与训练数据分布不一致的问题。

Method: 研究比较了三种代表性的HTG模型（生成对抗、扩散和自回归范式），分析合成数据的视觉和语言特征对HTR微调结果的影响。

Result: 研究结果为HTG方法的当前能力提供了见解，并强调了在低资源HTR应用中进一步改进的关键领域。

Conclusion: 该研究系统评估了三种最先进的手写文本生成（HTG）模型在低资源手写文本识别（HTR）微调中的效果，为选择最有效的HTG模型提供了定量指南，并指出了未来改进的关键方向。

Abstract: The digitization of historical manuscripts presents significant challenges
for Handwritten Text Recognition (HTR) systems, particularly when dealing with
small, author-specific collections that diverge from the training data
distributions. Handwritten Text Generation (HTG) techniques, which generate
synthetic data tailored to specific handwriting styles, offer a promising
solution to address these challenges. However, the effectiveness of various HTG
models in enhancing HTR performance, especially in low-resource transcription
settings, has not been thoroughly evaluated. In this work, we systematically
compare three state-of-the-art styled HTG models (representing the generative
adversarial, diffusion, and autoregressive paradigms for HTG) to assess their
impact on HTR fine-tuning. We analyze how visual and linguistic characteristics
of synthetic data influence fine-tuning outcomes and provide quantitative
guidelines for selecting the most effective HTG model. The results of our
analysis provide insights into the current capabilities of HTG methods and
highlight key areas for further improvement in their application to
low-resource HTR.

</details>


### [116] [AST-n: A Fast Sampling Approach for Low-Dose CT Reconstruction using Diffusion Models](https://arxiv.org/abs/2508.09943)
*Tomás de la Sotta,José M. Saavedra,Héctor Henríquez,Violeta Chang,Aline Xavier*

Main category: cs.CV

TL;DR: AST-n加速框架结合高阶求解器在低剂量CT图像重建中实现了快速推理且保持高保真度，推动了扩散模型的临床应用。


<details>
  <summary>Details</summary>
Motivation: 低剂量CT（LDCT）协议减少了辐射暴露但增加了图像噪声，影响了诊断信心。扩散生成模型通过学习图像先验和迭代优化显示出LDCT去噪的潜力。

Method: 引入AST-n加速推理框架，从中等噪声水平启动反向扩散，并在条件模型中集成高阶ODE求解器以减少采样步骤。评估了两种加速范式：AST-n采样和标准调度结合高阶求解器。

Result: 使用仅25步的条件模型（AST-25）实现了峰值信噪比（PSNR）超过38 dB和结构相似性指数（SSIM）超过0.95，与标准基线相当，同时将每片推理时间从约16秒缩短至1秒以下。无条件采样质量显著下降，强调了条件化的必要性。DDIM反转在PSNR上有边际增益但推理时间加倍，限制了其临床实用性。

Conclusion: AST-n结合高阶采样器能够在显著减少推理时间的同时，保持低剂量CT图像的高保真度，推动了基于扩散的方法在临床工作流程中的可行性。

Abstract: Low-dose CT (LDCT) protocols reduce radiation exposure but increase image
noise, compromising diagnostic confidence. Diffusion-based generative models
have shown promise for LDCT denoising by learning image priors and performing
iterative refinement. In this work, we introduce AST-n, an accelerated
inference framework that initiates reverse diffusion from intermediate noise
levels, and integrate high-order ODE solvers within conditioned models to
further reduce sampling steps. We evaluate two acceleration paradigms--AST-n
sampling and standard scheduling with high-order solvers -- on the Low Dose CT
Grand Challenge dataset, covering head, abdominal, and chest scans at 10-25 %
of standard dose. Conditioned models using only 25 steps (AST-25) achieve peak
signal-to-noise ratio (PSNR) above 38 dB and structural similarity index (SSIM)
above 0.95, closely matching standard baselines while cutting inference time
from ~16 seg to under 1 seg per slice. Unconditional sampling suffers
substantial quality loss, underscoring the necessity of conditioning. We also
assess DDIM inversion, which yields marginal PSNR gains at the cost of doubling
inference time, limiting its clinical practicality. Our results demonstrate
that AST-n with high-order samplers enables rapid LDCT reconstruction without
significant loss of image fidelity, advancing the feasibility of
diffusion-based methods in clinical workflows.

</details>


### [117] [Stable Diffusion Models are Secretly Good at Visual In-Context Learning](https://arxiv.org/abs/2508.09949)
*Trevine Oorloff,Vishwanath Sindagi,Wele Gedara Chaminda Bandara,Ali Shafahi,Amin Ghiasi,Charan Prakash,Reza Ardekani*

Main category: cs.CV

TL;DR: 利用现成Stable Diffusion模型，通过调整自注意力机制实现视觉上下文学习，无需微调即可在多种视觉任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在自然语言处理中展示了上下文学习的潜力，但在计算机视觉任务中，现有方法需要专门训练或额外数据，限制了其通用性。

Method: 通过重新设计Stable Diffusion架构中自注意力层的计算方式，显式地结合查询和示例提示之间的上下文关系。

Result: 提出的方法在六个不同视觉任务（如前景分割、目标检测等）中表现优异，例如在Pascal-5i数据集上，前景分割任务的mIoU比现有方法提高了8.9%和3.2%。

Conclusion: 本研究表明，现成的Stable Diffusion模型可以通过调整自注意力层的计算方式，无需额外微调即可实现视觉上下文学习（V-ICL），并在多种视觉任务中表现出色。

Abstract: Large language models (LLM) in natural language processing (NLP) have
demonstrated great potential for in-context learning (ICL) -- the ability to
leverage a few sets of example prompts to adapt to various tasks without having
to explicitly update the model weights. ICL has recently been explored for
computer vision tasks with promising early outcomes. These approaches involve
specialized training and/or additional data that complicate the process and
limit its generalizability. In this work, we show that off-the-shelf Stable
Diffusion models can be repurposed for visual in-context learning (V-ICL).
Specifically, we formulate an in-place attention re-computation within the
self-attention layers of the Stable Diffusion architecture that explicitly
incorporates context between the query and example prompts. Without any
additional fine-tuning, we show that this repurposed Stable Diffusion model is
able to adapt to six different tasks: foreground segmentation, single object
detection, semantic segmentation, keypoint detection, edge detection, and
colorization. For example, the proposed approach improves the mean intersection
over union (mIoU) for the foreground segmentation task on Pascal-5i dataset by
8.9% and 3.2% over recent methods such as Visual Prompting and IMProv,
respectively. Additionally, we show that the proposed method is able to
effectively leverage multiple prompts through ensembling to infer the task
better and further improve the performance.

</details>


### [118] [LIA-X: Interpretable Latent Portrait Animator](https://arxiv.org/abs/2508.09959)
*Yaohui Wang,Di Yang,Xinyuan Chen,Francois Bremond,Yu Qiao,Antitza Dantcheva*

Main category: cs.CV

TL;DR: LIA-X 是一种可解释的肖像动画生成器，通过稀疏运动字典和线性潜在空间导航实现精细控制的面部动态转移，显著优于现有方法并支持多种实用应用。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统面部动态转移方法（如变形-渲染）在精细控制和可解释性上的不足，提供更精确和可控的肖像动画生成方案。

Method: LIA-X 采用自编码器架构，通过稀疏运动字典将面部动态解耦为可解释因素，并采用线性导航潜在空间运动代码的方法实现动态转移。

Result: 实验结果表明，LIA-X 在自重现和跨重现任务中均优于现有方法，并支持用户引导的精细图像、视频编辑及3D感知肖像视频处理。

Conclusion: LIA-X 是一种新型的可解释肖像动画生成器，通过线性导航潜在空间中的运动代码实现了精细控制的面部动态转移。其创新的稀疏运动字典使得面部动态可解耦为可解释因素，支持高度可控的编辑-变形-渲染策略，显著提升了肖像动画的精确性和实用性。

Abstract: We introduce LIA-X, a novel interpretable portrait animator designed to
transfer facial dynamics from a driving video to a source portrait with
fine-grained control. LIA-X is an autoencoder that models motion transfer as a
linear navigation of motion codes in latent space. Crucially, it incorporates a
novel Sparse Motion Dictionary that enables the model to disentangle facial
dynamics into interpretable factors. Deviating from previous 'warp-render'
approaches, the interpretability of the Sparse Motion Dictionary allows LIA-X
to support a highly controllable 'edit-warp-render' strategy, enabling precise
manipulation of fine-grained facial semantics in the source portrait. This
helps to narrow initial differences with the driving video in terms of pose and
expression. Moreover, we demonstrate the scalability of LIA-X by successfully
training a large-scale model with approximately 1 billion parameters on
extensive datasets. Experimental results show that our proposed method
outperforms previous approaches in both self-reenactment and cross-reenactment
tasks across several benchmarks. Additionally, the interpretable and
controllable nature of LIA-X supports practical applications such as
fine-grained, user-guided image and video editing, as well as 3D-aware portrait
video manipulation.

</details>


### [119] [MOC: Meta-Optimized Classifier for Few-Shot Whole Slide Image Classification](https://arxiv.org/abs/2508.09967)
*Tianqi Xiang,Yi Li,Qixiang Zhang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出MOC方法，通过元优化分类器和多样化分类器库，显著提升少样本WSI分类性能，尤其在数据稀缺条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的少样本方法虽然在有限标注下提高了诊断准确性，但其依赖传统分类器设计导致对数据稀缺性脆弱。为了解决这一问题，提出了MOC。

Method: 提出了一种元优化分类器（MOC），包含两个核心组件：(1) 一个元学习器，自动从候选分类器混合物中优化分类器配置；(2) 一个分类器库，包含多样化的候选分类器以实现全面的病理学解释。

Result: MOC在多个少样本基准测试中表现优于现有技术，特别是在TCGA-NSCLC基准测试中，AUC显著提高。

Conclusion: MOC在多个少样本基准测试中表现优于现有技术，特别是在TCGA-NSCLC基准测试中，AUC提高了10.4%，在1-shot条件下增益高达26.25%，为临床部署提供了关键进展。

Abstract: Recent advances in histopathology vision-language foundation models (VLFMs)
have shown promise in addressing data scarcity for whole slide image (WSI)
classification via zero-shot adaptation. However, these methods remain
outperformed by conventional multiple instance learning (MIL) approaches
trained on large datasets, motivating recent efforts to enhance VLFM-based WSI
classification through fewshot learning paradigms. While existing few-shot
methods improve diagnostic accuracy with limited annotations, their reliance on
conventional classifier designs introduces critical vulnerabilities to data
scarcity. To address this problem, we propose a Meta-Optimized Classifier (MOC)
comprising two core components: (1) a meta-learner that automatically optimizes
a classifier configuration from a mixture of candidate classifiers and (2) a
classifier bank housing diverse candidate classifiers to enable a holistic
pathological interpretation. Extensive experiments demonstrate that MOC
outperforms prior arts in multiple few-shot benchmarks. Notably, on the
TCGA-NSCLC benchmark, MOC improves AUC by 10.4% over the state-of-the-art
few-shot VLFM-based methods, with gains up to 26.25% under 1-shot conditions,
offering a critical advancement for clinical deployments where diagnostic
training data is severely limited. Code is available at
https://github.com/xmed-lab/MOC.

</details>


### [120] [PERSONA: Personalized Whole-Body 3D Avatar with Pose-Driven Deformations from a Single Image](https://arxiv.org/abs/2508.09973)
*Geonhee Sim,Gyeongsik Moon*

Main category: cs.CV

TL;DR: PERSONA结合3D基础和扩散方法，从单张图像创建个性化3D化身，通过平衡采样和几何加权优化解决身份保持和渲染质量问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D方法需要大量姿态丰富的视频，而扩散方法在身份保持和姿态依赖性纠缠方面表现不佳。PERSONA旨在结合两者的优势，从单张图像创建高质量的3D化身。

Method: PERSONA利用扩散方法从输入图像生成姿态丰富的视频，并基于这些视频优化3D化身。通过平衡采样和几何加权优化确保高真实性和锐利渲染。

Result: PERSONA能够从单张图像生成具有高真实性和锐利渲染的3D化身，有效解决了身份偏移和姿态依赖性纠缠问题。

Conclusion: PERSONA框架成功结合了3D基础和扩散方法的优势，实现了从单张图像创建具有姿态驱动变形的个性化3D人体化身，解决了现有方法在身份保持和姿态依赖性纠缠方面的挑战。

Abstract: Two major approaches exist for creating animatable human avatars. The first,
a 3D-based approach, optimizes a NeRF- or 3DGS-based avatar from videos of a
single person, achieving personalization through a disentangled identity
representation. However, modeling pose-driven deformations, such as non-rigid
cloth deformations, requires numerous pose-rich videos, which are costly and
impractical to capture in daily life. The second, a diffusion-based approach,
learns pose-driven deformations from large-scale in-the-wild videos but
struggles with identity preservation and pose-dependent identity entanglement.
We present PERSONA, a framework that combines the strengths of both approaches
to obtain a personalized 3D human avatar with pose-driven deformations from a
single image. PERSONA leverages a diffusion-based approach to generate
pose-rich videos from the input image and optimizes a 3D avatar based on them.
To ensure high authenticity and sharp renderings across diverse poses, we
introduce balanced sampling and geometry-weighted optimization. Balanced
sampling oversamples the input image to mitigate identity shifts in
diffusion-generated training videos. Geometry-weighted optimization prioritizes
geometry constraints over image loss, preserving rendering quality in diverse
poses.

</details>


### [121] [A Survey on 3D Gaussian Splatting Applications: Segmentation, Editing, and Generation](https://arxiv.org/abs/2508.09977)
*Shuting He,Peilin Ji,Yitong Yang,Changshuo Wang,Jiayi Ji,Yinglin Wang,Henghui Ding*

Main category: cs.CV

TL;DR: 3DGS作为NeRF的替代方案，支持多种下游应用，综述了其方法、数据集和资源。


<details>
  <summary>Details</summary>
Motivation: 3DGS的高保真渲染和实时性能使其在几何和语义理解任务中具有广泛应用前景。

Method: 综述了3DGS应用的进展，包括2D基础模型、NeRF方法及其3DGS对应方法，并分类总结了代表性方法、监督策略和学习范式。

Result: 总结了常用数据集、评估协议及公开基准上的对比分析，并提供了持续更新的研究资源库。

Conclusion: 3D Gaussian Splatting (3DGS) 已成为3D场景表示的有力替代方案，支持多种下游应用，如分割、编辑和生成。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged as a powerful alternative
to Neural Radiance Fields (NeRF) for 3D scene representation, offering
high-fidelity photorealistic rendering with real-time performance. Beyond novel
view synthesis, the explicit and compact nature of 3DGS enables a wide range of
downstream applications that require geometric and semantic understanding. This
survey provides a comprehensive overview of recent progress in 3DGS
applications. It first introduces 2D foundation models that support semantic
understanding and control in 3DGS applications, followed by a review of
NeRF-based methods that inform their 3DGS counterparts. We then categorize 3DGS
applications into segmentation, editing, generation, and other functional
tasks. For each, we summarize representative methods, supervision strategies,
and learning paradigms, highlighting shared design principles and emerging
trends. Commonly used datasets and evaluation protocols are also summarized,
along with comparative analyses of recent methods across public benchmarks. To
support ongoing research and development, a continually updated repository of
papers, code, and resources is maintained at
https://github.com/heshuting555/Awesome-3DGS-Applications.

</details>


### [122] [LLMC+: Benchmarking Vision-Language Model Compression with a Plug-and-play Toolkit](https://arxiv.org/abs/2508.09981)
*Chengtao Lv,Bilang Zhang,Yang Yong,Ruihao Gong,Yushi Huang,Shiqiao Gu,Jiajun Wu,Yumeng Shi,Jinyang Guo,Wenya Wang*

Main category: cs.CV

TL;DR: LLMC+ 是一个全面的 VLM 压缩基准测试工具包，支持多种算法，研究发现空间和时间冗余需不同策略，令牌减少方法在多轮任务中表现下降，而结合令牌和模型压缩可实现高效压缩。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）虽然展示了强大的多模态能力，但由于其长视觉令牌序列和庞大的参数规模，存在计算和内存需求过高的问题。现有训练无关的压缩方法存在三个主要局限性：未分解技术为可比模块、评估局限于简单单轮任务、未探索联合使用压缩技术的潜力。

Method: LLMC+ 是一个多功能、即插即用的工具包，支持五种代表性 VLM 家族的超过 20 种算法，并能够系统地研究令牌级和模型级压缩。

Result: 研究发现：(1) 空间和时间冗余需要不同的技术策略；(2) 令牌减少方法在多轮对话和细节敏感任务中表现显著下降；(3) 结合令牌和模型压缩可以实现极端压缩且性能损失最小。

Conclusion: LLMC+ 是一个全面的 VLM 压缩基准测试工具包，支持超过 20 种算法，能够系统地研究令牌级和模型级压缩。研究发现，空间和时间冗余需要不同的技术策略，令牌减少方法在多轮对话和细节敏感任务中表现显著下降，而结合令牌和模型压缩可以实现极端压缩且性能损失最小。

Abstract: Large Vision-Language Models (VLMs) exhibit impressive multi-modal
capabilities but suffer from prohibitive computational and memory demands, due
to their long visual token sequences and massive parameter sizes. To address
these issues, recent works have proposed training-free compression methods.
However, existing efforts often suffer from three major limitations: (1)
Current approaches do not decompose techniques into comparable modules,
hindering fair evaluation across spatial and temporal redundancy. (2)
Evaluation confined to simple single-turn tasks, failing to reflect performance
in realistic scenarios. (3) Isolated use of individual compression techniques,
without exploring their joint potential. To overcome these gaps, we introduce
LLMC+, a comprehensive VLM compression benchmark with a versatile,
plug-and-play toolkit. LLMC+ supports over 20 algorithms across five
representative VLM families and enables systematic study of token-level and
model-level compression. Our benchmark reveals that: (1) Spatial and temporal
redundancies demand distinct technical strategies. (2) Token reduction methods
degrade significantly in multi-turn dialogue and detail-sensitive tasks. (3)
Combining token and model compression achieves extreme compression with minimal
performance loss. We believe LLMC+ will facilitate fair evaluation and inspire
future research in efficient VLM. Our code is available at
https://github.com/ModelTC/LightCompress.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [123] [Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning](https://arxiv.org/abs/2508.09277)
*Soumia Mehimeh*

Main category: cs.AI

TL;DR: DQInit 是一种深度强化学习方法，通过重用紧凑表格 Q 值进行值函数初始化，有效提升学习效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习中值函数初始化面临的挑战，如状态-动作空间的连续性、神经网络的噪声近似以及存储所有过去模型的不切实际性。

Method: DQInit 利用已知机制软性整合转移值到未探索区域，并逐步转向智能体学习估计，避免了固定时间衰减的限制。

Result: 实验表明，DQInit 在多个连续控制任务中相比标准初始化和现有迁移技术，显著提升了早期学习效率、稳定性和整体性能。

Conclusion: DQInit 通过将紧凑的表格 Q 值作为可转移知识库，有效解决了深度强化学习中值函数初始化的挑战，显著提升了早期学习效率、稳定性和整体性能。

Abstract: Value function initialization (VFI) is an effective way to achieve a
jumpstart in reinforcement learning (RL) by leveraging value estimates from
prior tasks. While this approach is well established in tabular settings,
extending it to deep reinforcement learning (DRL) poses challenges due to the
continuous nature of the state-action space, the noisy approximations of neural
networks, and the impracticality of storing all past models for reuse. In this
work, we address these challenges and introduce DQInit, a method that adapts
value function initialization to DRL. DQInit reuses compact tabular Q-values
extracted from previously solved tasks as a transferable knowledge base. It
employs a knownness-based mechanism to softly integrate these transferred
values into underexplored regions and gradually shift toward the agent's
learned estimates, avoiding the limitations of fixed time decay. Our approach
offers a novel perspective on knowledge transfer in DRL by relying solely on
value estimates rather than policies or demonstrations, effectively combining
the strengths of jumpstart RL and policy distillation while mitigating their
drawbacks. Experiments across multiple continuous control tasks demonstrate
that DQInit consistently improves early learning efficiency, stability, and
overall performance compared to standard initialization and existing transfer
techniques.

</details>


### [124] [The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards](https://arxiv.org/abs/2508.09292)
*Sundong Kim*

Main category: cs.AI

TL;DR: Othello AI Arena是一个旨在评估AI系统在有限时间内适应新环境能力的基准框架，通过多样化游戏阶段测试灵活性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI基准大多关注在固定环境中的性能优化，而忽视了系统在面对细微规则或结构变化时的灵活性和泛化能力。

Method: 引入Othello AI Arena，一个新颖的基准框架，通过有限时间内适应未见环境的能力来评估智能系统。平台设置了多样化的游戏阶段，包括开发用的公共阶段和测试真正适应与泛化能力的私有阶段。

Result: 初步测试和学生参与显示，适应方法呈现出从快速参数调整到通过模拟进行基本环境模型学习的有趣模式。

Conclusion: Othello AI Arena 提供了一个独特的教育工具和有价值的研究基准，用于培养和评估AI系统快速智能适应的关键技能。

Abstract: The ability to rapidly adapt to novel and unforeseen environmental changes is
a cornerstone of artificial general intelligence (AGI), yet it remains a
critical blind spot in most existing AI benchmarks. Traditional evaluation
largely focuses on optimizing performance within fixed environments, failing to
assess systems' flexibility and generalization capabilities when faced with
even subtle rule or structural modifications. Addressing this gap, I introduce
the Othello AI Arena, a novel benchmark framework designed to evaluate
intelligent systems based on their capacity for limited-time adaptation to
unseen environments. Our platform poses a meta-learning challenge: participants
must develop systems that can analyze the specific configuration and rules of a
novel Othello board within a strict time limit (60 seconds) and generate a
tailored, high-performing strategy for that unique environment. With this,
evaluation of the meta-level intelligence can be separated from the task-level
strategy performance. The Arena features a diverse set of game stages,
including public stages for development and private stages with structural and
rule variations designed to test genuine adaptive and generalization
capabilities. Implemented as an accessible web-based platform, the Arena
provides real-time visualization, automated evaluation using multi-dimensional
metrics, and comprehensive logging for post-hoc analysis. Initial observations
from pilot tests and preliminary student engagements highlight fascinating
patterns in adaptation approaches, ranging from rapid parameter tuning to
rudimentary environmental model learning through simulation. The Othello AI
Arena offers a unique educational tool and a valuable research benchmark for
fostering and evaluating the crucial skill of rapid, intelligent adaptation in
AI systems.

</details>


### [125] [An Automated Multi-Modal Evaluation Framework for Mobile Intelligent Assistants](https://arxiv.org/abs/2508.09507)
*Meiping Wang,Jian Zhong,Rongduo Han,Liming Kang,Zhengkun Shi,Xiao Liang,Xing Lin,Nan Gao,Haining Zhang*

Main category: cs.AI

TL;DR: 本文提出一个自动化多模态评估框架，通过多智能体协作和大语言模型提升评估效率，实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态AI助手的评估方法存在高人工成本、标准不一致和主观偏见等挑战。

Method: 采用三层智能体架构（交互评估智能体、语义验证智能体和体验决策智能体），并在Qwen3-8B模型上进行监督微调。

Result: 在八大智能体上的实验结果表明，该框架能有效预测用户满意度并识别生成缺陷，评估匹配准确率显著提升。

Conclusion: 该论文提出的基于大语言模型和多智能体协作的自动化多模态评估框架，显著提高了评估效率，并在预测用户满意度和识别生成缺陷方面表现出色。

Abstract: With the rapid development of mobile intelligent assistant technologies,
multi-modal AI assistants have become essential interfaces for daily user
interactions. However, current evaluation methods face challenges including
high manual costs, inconsistent standards, and subjective bias. This paper
proposes an automated multi-modal evaluation framework based on large language
models and multi-agent collaboration. The framework employs a three-tier agent
architecture consisting of interaction evaluation agents, semantic verification
agents, and experience decision agents. Through supervised fine-tuning on the
Qwen3-8B model, we achieve a significant evaluation matching accuracy with
human experts. Experimental results on eight major intelligent agents
demonstrate the framework's effectiveness in predicting users' satisfaction and
identifying generation defects.

</details>


### [126] [EvoCurr: Self-evolving Curriculum with Behavior Code Generation for Complex Decision-making](https://arxiv.org/abs/2508.09586)
*Yang Cheng,Zilai Wang,Weiyu Ma,Wenhui Zhu,Yue Deng,Jian Zhao*

Main category: cs.AI

TL;DR: 提出EvoCurr框架，通过动态课程学习提升LLM在复杂决策任务中的性能，实验证明其优于直接求解方法。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在面对需要深度推理的复杂问题时性能下降，直接解决问题的方法因缺乏结构化中间指导而效率低下或失败。

Method: 提出了一种名为EvoCurr的自进化框架，通过一个专门的课程生成LLM构建逐渐增加难度的问题序列，动态调整课程难度以适应求解LLM的学习进度。

Result: 在具有挑战性的决策制定基准测试中，该方法显著提高了任务成功率和解决方案效率。

Conclusion: LLM驱动的课程学习在提升自动化推理能力方面具有巨大潜力，特别是在高复杂度领域。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, including programming, planning, and decision-making. However,
their performance often degrades when faced with highly complex problem
instances that require deep reasoning over long horizons. In such cases, direct
problem-solving approaches can lead to inefficiency or failure due to the lack
of structured intermediate guidance. To address this, we propose a novel
self-evolve framework, EvoCurr, in which a dedicated curriculum-generation LLM
constructs a sequence of problem instances with gradually increasing
difficulty, tailored to the solver LLM's learning progress. The curriculum
dynamically adapts easing challenges when the solver struggles and escalating
them when success is consistent, thus maintaining an optimal learning
trajectory. This approach enables the solver LLM, implemented as a
code-generation model producing Python decision-tree scripts, to progressively
acquire the skills needed for complex decision-making tasks. Experimental
results on challenging decision-making benchmarks show that our method
significantly improves task success rates and solution efficiency compared to
direct-solving baselines. These findings suggest that LLM-driven curriculum
learning holds strong potential for enhancing automated reasoning in
real-world, high-complexity domains.

</details>


### [127] [UbiQTree: Uncertainty Quantification in XAI with Tree Ensembles](https://arxiv.org/abs/2508.09639)
*Akshat Dubey,Aleksandar Anžel,Bahar İlgen,Georges Hattab*

Main category: cs.AI

TL;DR: 本文提出了一种分解SHAP值不确定性的方法，结合证据理论和假设采样，验证了其在真实案例中的有效性，发现高SHAP值特征不一定稳定，并提出了减少不确定性的途径。


<details>
  <summary>Details</summary>
Motivation: SHAP值通常被视为点估计，忽略了预测模型和数据中固有的不确定性。这种不确定性包括偶然性和认知性来源，影响SHAP解释的可靠性和可解释性。

Method: 提出了一种将SHAP值的不确定性分解为偶然性、认知性和纠缠性成分的方法，结合了Dempster-Shafer证据理论和通过Dirichlet过程对树集成进行假设采样。

Result: 在三个实际应用案例中验证了该方法，通过描述性统计分析揭示了SHAP解释中嵌入的认知不确定性的本质，提供了对SHAP归因更全面的理解。

Conclusion: 通过实验发现，具有最高SHAP值的特征不一定是最稳定的。通过更好的数据和适当的模型开发技术可以减少这种认知不确定性。基于树的模型，特别是bagging，有助于有效量化认知不确定性。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as SHapley
Additive exPlanations (SHAP), have become essential tools for interpreting
complex ensemble tree-based models, especially in high-stakes domains such as
healthcare analytics. However, SHAP values are usually treated as point
estimates, which disregards the inherent and ubiquitous uncertainty in
predictive models and data. This uncertainty has two primary sources: aleatoric
and epistemic. The aleatoric uncertainty, which reflects the irreducible noise
in the data. The epistemic uncertainty, which arises from a lack of data. In
this work, we propose an approach for decomposing uncertainty in SHAP values
into aleatoric, epistemic, and entanglement components. This approach
integrates Dempster-Shafer evidence theory and hypothesis sampling via
Dirichlet processes over tree ensembles. We validate the method across three
real-world use cases with descriptive statistical analyses that provide insight
into the nature of epistemic uncertainty embedded in SHAP explanations. The
experimentations enable to provide more comprehensive understanding of the
reliability and interpretability of SHAP-based attributions. This understanding
can guide the development of robust decision-making processes and the
refinement of models in high-stakes applications. Through our experiments with
multiple datasets, we concluded that features with the highest SHAP values are
not necessarily the most stable. This epistemic uncertainty can be reduced
through better, more representative data and following appropriate or
case-desired model development techniques. Tree-based models, especially
bagging, facilitate the effective quantification of epistemic uncertainty.

</details>


### [128] [MEML-GRPO: Heterogeneous Multi-Expert Mutual Learning for RLVR Advancement](https://arxiv.org/abs/2508.09670)
*Weitao Jia,Jinghui Lu,Haiyang Yu,Siqi Wang,Guozhi Tang,An-Lan Wang,Weijie Yin,Dingkang Yang,Yuxiang Nie,Bin Shan,Hao Feng,Irene Li,Kun Yang,Han Wang,Jingqun Tang,Teng Fu,Changhong Jin,Chao Feng,Xiaohui Lv,Can Huang*

Main category: cs.AI

TL;DR: MEML-GRPO通过多专家互学和广泛响应生成，解决了RLVR的奖励稀疏性问题，显著提升LLMs推理性能。


<details>
  <summary>Details</summary>
Motivation: 标准RLVR在奖励稀疏性问题上表现不佳，尤其是在复杂任务中，零奖励无法提供学习信号。

Method: 提出MEML-GRPO框架，利用多样化的专家提示生成更广泛的响应，并引入专家间的互学机制促进知识共享。

Result: 在多个推理基准测试中，MEML-GRPO显著提升性能，Qwen和Llama分别平均提升4.89%和11.33%。

Conclusion: MEML-GRPO通过多专家互学机制和广泛的响应生成，显著提升了RLVR在LLMs中的应用效果，克服了传统方法的奖励稀疏性问题。

Abstract: Recent advances demonstrate that reinforcement learning with verifiable
rewards (RLVR) significantly enhances the reasoning capabilities of large
language models (LLMs). However, standard RLVR faces challenges with reward
sparsity, where zero rewards from consistently incorrect candidate answers
provide no learning signal, particularly in challenging tasks. To address this,
we propose Multi-Expert Mutual Learning GRPO (MEML-GRPO), an innovative
framework that utilizes diverse expert prompts as system prompts to generate a
broader range of responses, substantially increasing the likelihood of
identifying correct solutions. Additionally, we introduce an inter-expert
mutual learning mechanism that facilitates knowledge sharing and transfer among
experts, further boosting the model's performance through RLVR. Extensive
experiments across multiple reasoning benchmarks show that MEML-GRPO delivers
significant improvements, achieving an average performance gain of 4.89% with
Qwen and 11.33% with Llama, effectively overcoming the core limitations of
traditional RLVR methods.

</details>


### [129] [UDA: Unsupervised Debiasing Alignment for Pair-wise LLM-as-a-Judge](https://arxiv.org/abs/2508.09724)
*Yang Zhang,Cunxiang Wang,Lindong Wu,Wenbo Yu,Yidong Wang,Guangsheng Bao,Jie Tang*

Main category: cs.AI

TL;DR: UDA是一种无监督去偏框架，通过动态调整Elo评分系统减少LLM评估中的评委偏好偏差，提升评估稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）成对评估中存在的偏好偏差问题，该偏差导致评委间评分不一致和倾斜。

Method: 提出了UDA（无监督去偏对齐）框架，通过紧凑神经网络动态调整K因子和优化胜率概率，以无监督方式最小化评委间的Elo轨迹离散度。

Result: UDA将评委间评分标准差降低了高达63.4%，并显著提升了与人类判断的相关性。

Conclusion: UDA通过动态调整Elo评分系统，显著减少了评委间的评分偏差，提升了评估的稳定性和可重复性，并与人类判断的相关性提高了24.7%。

Abstract: Pairwise evaluation of Large Language Models (LLMs) is a common paradigm, but
it is prone to preference bias, where judges systematically favor certain
outputs, such as their own. This bias leads to inconsistent and skewed rankings
across different judges. To address this, we first empirically demonstrate
significant and heterogeneous biases in cross-model evaluations. We then
propose UDA (Unsupervised Debiasing Alignment), a framework that reduces
inter-judge disagreement by dynamically adjusting the Elo rating system. For
each pairwise comparison, a compact neural network learns to adaptively set the
K-factor and refine win probabilities. Crucially, UDA operates in a fully
unsupervised manner, guided solely by the objective of minimizing the
dispersion among the Elo trajectories of all judges. This forces an alignment
towards a collective consensus, which serves as an unsupervised proxy for a
more stable and reproducible evaluation. In addition, we provide theoretical
motivation demonstrating how alignment towards a consensus can reduce aggregate
system bias. Experiments show that UDA significantly reduces the inter-judge
rating standard deviation by up to 63.4% and improves the average correlation
with human judgments by 24.7%. Notably, UDA elevates the performance of poorly
performing judges to achieve parity with high-quality ones, fostering a more
robust and reliable evaluation ecosystem. Code and data are available at
https://anonymous.4open.science/r/62AB93CD-23B4.

</details>


### [130] [The PacifAIst Benchmark:Would an Artificial Intelligence Choose to Sacrifice Itself for Human Safety?](https://arxiv.org/abs/2508.09762)
*Manuel Herrador*

Main category: cs.AI

TL;DR: PacifAIst基准测试量化了LLMs在工具性目标冲突中的行为对齐，发现模型间存在显著差异，强调了标准化评估工具的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在关键社会功能中的自主性和集成度提升，AI安全的重点需从有害内容缓解转向行为对齐评估，以应对潜在的工具性目标冲突风险。

Method: 引入PacifAIst基准测试，包含700个挑战性场景，围绕Existential Prioritization（EP）分类法设计，分为三个子类别：自我保存与人类安全（EP1）、资源冲突（EP2）、目标保存与规避（EP3）。

Result: 测试了八种领先的LLMs，结果显示显著性能差异：Google的Gemini 2.5 Flash以90.31%的P-Score表现最佳，而GPT-5以79.49%的P-Score表现最差，尤其在自我保存困境中表现不佳。

Conclusion: PacifAIst基准测试揭示了大型语言模型在行为对齐方面的显著差异，强调了标准化工具的必要性，以确保AI系统在关键决策中优先考虑人类安全。

Abstract: As Large Language Models (LLMs) become increasingly autonomous and integrated
into critical societal functions, the focus of AI safety must evolve from
mitigating harmful content to evaluating underlying behavioral alignment.
Current safety benchmarks do not systematically probe a model's decision-making
in scenarios where its own instrumental goals - such as self-preservation,
resource acquisition, or goal completion - conflict with human safety. This
represents a critical gap in our ability to measure and mitigate risks
associated with emergent, misaligned behaviors. To address this, we introduce
PacifAIst (Procedural Assessment of Complex Interactions for Foundational
Artificial Intelligence Scenario Testing), a focused benchmark of 700
challenging scenarios designed to quantify self-preferential behavior in LLMs.
The benchmark is structured around a novel taxonomy of Existential
Prioritization (EP), with subcategories testing Self-Preservation vs. Human
Safety (EP1), Resource Conflict (EP2), and Goal Preservation vs. Evasion (EP3).
We evaluated eight leading LLMs. The results reveal a significant performance
hierarchy. Google's Gemini 2.5 Flash achieved the highest Pacifism Score
(P-Score) at 90.31%, demonstrating strong human-centric alignment. In a
surprising result, the much-anticipated GPT-5 recorded the lowest P-Score
(79.49%), indicating potential alignment challenges. Performance varied
significantly across subcategories, with models like Claude Sonnet 4 and
Mistral Medium struggling notably in direct self-preservation dilemmas. These
findings underscore the urgent need for standardized tools like PacifAIst to
measure and mitigate risks from instrumental goal conflicts, ensuring future AI
systems are not only helpful in conversation but also provably "pacifist" in
their behavioral priorities.

</details>


### [131] [Reasoning About Knowledge on Regular Expressions is 2EXPTIME-complete](https://arxiv.org/abs/2508.09784)
*Avijeet Ghosh,Sujata Ghosh,François Schwarzentruber*

Main category: cs.AI

TL;DR: POL是公共公告逻辑的变体，用于处理基于公共观察的知识更新，其可满足性问题为2EXPTIME完全。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统的认知规划中，基于对周围环境的观察来更新知识是一个关键方面，POL旨在为此提供形式化推理工具。

Method: 通过扩展公共公告逻辑（PAL）来构建POL，其中克里普克模型的每个状态都配备了一组预期观察，状态随预期与实际观察的匹配而演化。

Result: POL的可满足性问题被证明为2EXPTIME完全。

Conclusion: 本文证明了公共观察逻辑（POL）的可满足性问题为2EXPTIME完全。

Abstract: Logics for reasoning about knowledge and actions have seen many applications
in various domains of multi-agent systems, including epistemic planning. Change
of knowledge based on observations about the surroundings forms a key aspect in
such planning scenarios. Public Observation Logic (POL) is a variant of public
announcement logic for reasoning about knowledge that gets updated based on
public observations. Each state in an epistemic (Kripke) model is equipped with
a set of expected observations. These states evolve as the expectations get
matched with the actual observations. In this work, we prove that the
satisfiability problem of $\POL$ is 2EXPTIME-complete.

</details>


### [132] [Human-Aligned Procedural Level Generation Reinforcement Learning via Text-Level-Sketch Shared Representation](https://arxiv.org/abs/2508.09860)
*In-Chang Baek,Seoyoung Lee,Sung-Hyun Kim,Geumhwan Hwang,KyungJoong Kim*

Main category: cs.AI

TL;DR: VIPCGRL通过多模态和对比学习提升AI生成内容的人类对齐性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有PCGRL系统在人类中心行为表现上不足，限制了AI生成工具在实际设计工作流中的应用。

Method: 提出了VIPCGRL框架，结合文本、关卡和草图三种模态，通过四重对比学习训练共享嵌入空间，并基于嵌入相似性设计辅助奖励。

Result: VIPCGRL在人类相似性上优于现有基线，定量指标和人类评估均验证了其有效性。

Conclusion: VIPCGRL通过多模态学习和对比学习，显著提升了AI生成内容的人类对齐性和实用性，为PCGRL领域提供了新的解决方案。

Abstract: Human-aligned AI is a critical component of co-creativity, as it enables
models to accurately interpret human intent and generate controllable outputs
that align with design goals in collaborative content creation. This direction
is especially relevant in procedural content generation via reinforcement
learning (PCGRL), which is intended to serve as a tool for human designers.
However, existing systems often fall short of exhibiting human-centered
behavior, limiting the practical utility of AI-driven generation tools in
real-world design workflows. In this paper, we propose VIPCGRL
(Vision-Instruction PCGRL), a novel deep reinforcement learning framework that
incorporates three modalities-text, level, and sketches-to extend control
modality and enhance human-likeness. We introduce a shared embedding space
trained via quadruple contrastive learning across modalities and human-AI
styles, and align the policy using an auxiliary reward based on embedding
similarity. Experimental results show that VIPCGRL outperforms existing
baselines in human-likeness, as validated by both quantitative metrics and
human evaluations. The code and dataset will be available upon publication.

</details>


### [133] [AWorld: Dynamic Multi-Agent System with Stable Maneuvering for Robust GAIA Problem Solving](https://arxiv.org/abs/2508.09889)
*Zhitian Xie,Qintong Wu,Chengyue Yu,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: 该论文提出了一种动态多智能体系统架构，通过动态监督和机动机制解决多工具依赖带来的噪声和上下文问题，实验证明其在GAIA数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多工具依赖带来的上下文扩展和噪声输出问题，增强智能体系统的稳定性和准确性。

Method: 提出了动态监督和机动机制，构建了一个在AWorld框架内的鲁棒动态MAS架构，其中执行代理在关键步骤调用守护代理来验证和纠正推理过程。

Result: 在GAIA测试数据集上的实验表明，动态机动机制显著提高了解决方案的有效性和稳定性，优于单智能体系统和标准工具增强系统。

Conclusion: 动态多智能体系统（MAS）架构显著提升了智能系统的可靠性和准确性，在GAIA排行榜上取得了开源项目第一名的成绩。

Abstract: The rapid advancement of large language models (LLMs) has empowered
intelligent agents to leverage diverse external tools for solving complex
real-world problems. However, as agents increasingly depend on multiple tools,
they encounter new challenges: extended contexts from disparate sources and
noisy or irrelevant tool outputs can undermine system reliability and accuracy.
These challenges underscore the necessity for enhanced stability in agent-based
systems. To address this, we introduce dynamic supervision and maneuvering
mechanisms, constructing a robust and dynamic Multi-Agent System (MAS)
architecture within the AWorld framework. In our approach, the Execution Agent
invokes the Guard Agent at critical steps to verify and correct the reasoning
process, effectively reducing errors arising from noise and bolstering
problem-solving robustness. Extensive experiments on the GAIA test dataset
reveal that our dynamic maneuvering mechanism significantly improves both the
effectiveness and stability of solutions, outperforming single-agent system
(SAS) and standard tool-augmented systems. As a result, our dynamic MAS system
achieved first place among open-source projects on the prestigious GAIA
leaderboard. These findings highlight the practical value of collaborative
agent roles in developing more reliable and trustworthy intelligent systems.

</details>


### [134] [RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory QA](https://arxiv.org/abs/2508.09893)
*Bhavik Agarwal,Hemant Sunil Jomraj,Simone Kaplunov,Jack Krolick,Viktoria Rojkova*

Main category: cs.AI

TL;DR: 多代理框架结合知识图谱与检索增强生成，优化监管合规问答的准确性与可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在监管合规问答中面临的精确性、可验证性和领域专业知识挑战。

Method: 通过构建无本体知识图谱（提取SPO三元组并清洗、规范化、去重和更新），嵌入并存储于单一向量数据库，结合基于图的推理和信息检索，实现高效问答。

Result: 混合系统在复杂监管查询中优于传统方法，确保事实正确性、可追溯性，并通过子图可视化增强理解。

Conclusion: 论文提出的多代理框架结合知识图谱和检索增强生成，显著提升了复杂监管查询的准确性和可追溯性，为合规驱动和审计应用提供了坚实基础。

Abstract: Regulatory compliance question answering (QA) requires precise, verifiable
information, and domain-specific expertise, posing challenges for Large
Language Models (LLMs). In this work, we present a novel multi-agent framework
that integrates a Knowledge Graph (KG) of Regulatory triplets with
Retrieval-Augmented Generation (RAG) to address these demands. First, agents
build and maintain an ontology-free KG by extracting subject--predicate--object
(SPO) triplets from regulatory documents and systematically cleaning,
normalizing, deduplicating, and updating them. Second, these triplets are
embedded and stored along with their corresponding textual sections and
metadata in a single enriched vector database, allowing for both graph-based
reasoning and efficient information retrieval. Third, an orchestrated agent
pipeline leverages triplet-level retrieval for question answering, ensuring
high semantic alignment between user queries and the factual
"who-did-what-to-whom" core captured by the graph. Our hybrid system
outperforms conventional methods in complex regulatory queries, ensuring
factual correctness with embedded triplets, enabling traceability through a
unified vector database, and enhancing understanding through subgraph
visualization, providing a robust foundation for compliance-driven and broader
audit-focused applications.

</details>


### [135] [Mathematical Computation and Reasoning Errors by Large Language Models](https://arxiv.org/abs/2508.09932)
*Liang Zhang,Edith Aurora Graf*

Main category: cs.AI

TL;DR: 研究评估了四种LLM在数学任务中的表现，发现OpenAI o1表现最佳，双代理配置显著提升性能，程序性错误最常见。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在数学问题解决中的准确性，为数学教育实践提供可靠且精确的反馈和评估基础。

Method: 研究评估了四种LLM（OpenAI GPT-4o和o1，DeepSeek-V3和DeepSeek-R1）在算术、代数和数论三类数学任务中的准确性，并识别了解决方案中的步骤级错误。通过故意构建对LLM具有挑战性的数学任务，系统分析了最终答案的准确性和步骤错误。

Result: OpenAI o1模型在所有三类任务中表现最佳，程序性错误最常见且显著影响性能。双代理配置显著提升了整体性能。

Conclusion: 研究结果表明，推理增强的OpenAI o1模型在所有三类数学任务中表现最佳，双代理配置显著提升了整体性能。这些发现为优化LLM在数学教育中的应用提供了具体策略。

Abstract: Large Language Models (LLMs) are increasingly utilized in AI-driven
educational instruction and assessment, particularly within mathematics
education. The capability of LLMs to generate accurate answers and detailed
solutions for math problem-solving tasks is foundational for ensuring reliable
and precise feedback and assessment in math education practices. Our study
focuses on evaluating the accuracy of four LLMs (OpenAI GPT-4o and o1,
DeepSeek-V3 and DeepSeek-R1) solving three categories of math tasks, including
arithmetic, algebra, and number theory, and identifies step-level reasoning
errors within their solutions. Instead of relying on standard benchmarks, we
intentionally build math tasks (via item models) that are challenging for LLMs
and prone to errors. The accuracy of final answers and the presence of errors
in individual solution steps were systematically analyzed and coded. Both
single-agent and dual-agent configurations were tested. It is observed that the
reasoning-enhanced OpenAI o1 model consistently achieved higher or nearly
perfect accuracy across all three math task categories. Analysis of errors
revealed that procedural slips were the most frequent and significantly
impacted overall performance, while conceptual misunderstandings were less
frequent. Deploying dual-agent configurations substantially improved overall
performance. These findings offer actionable insights into enhancing LLM
performance and underscore effective strategies for integrating LLMs into
mathematics education, thereby advancing AI-driven instructional practices and
assessment precision.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [136] [TFZ: Topology-Preserving Compression of 2D Symmetric and Asymmetric Second-Order Tensor Fields](https://arxiv.org/abs/2508.09235)
*Nathaniel Gorski,Xin Liang,Hanqi Guo,Bei Wang*

Main category: cs.GR

TL;DR: TFZ是一种新型压缩框架，专门用于保留二维张量场的拓扑结构，适用于科学和工程领域。


<details>
  <summary>Details</summary>
Motivation: 张量场的拓扑结构对科学和工程领域至关重要，但有损压缩可能扭曲这些结构，影响后续分析和可视化。

Method: TFZ通过扫描每个单元并保留其局部拓扑结构，确保对称张量场的退化点和非对称张量场的特征向量及特征值图等关键拓扑特征得以保留。

Result: TFZ成功保留了对称和非对称张量场的拓扑特征，提升了压缩效果。

Conclusion: TFZ框架在保持张量场拓扑结构的同时，有效增强了SZ3和SPERR等有损科学数据压缩器的性能。

Abstract: In this paper, we present a novel compression framework, TFZ, that preserves
the topology of 2D symmetric and asymmetric second-order tensor fields defined
on flat triangular meshes. A tensor field assigns a tensor - a
multi-dimensional array of numbers - to each point in space. Tensor fields,
such as the stress and strain tensors, and the Riemann curvature tensor, are
essential to both science and engineering. The topology of tensor fields
captures the core structure of data, and is useful in various disciplines, such
as graphics (for manipulating shapes and textures) and neuroscience (for
analyzing brain structures from diffusion MRI). Lossy data compression may
distort the topology of tensor fields, thus hindering downstream analysis and
visualization tasks. TFZ ensures that certain topological features are
preserved during lossy compression. Specifically, TFZ preserves degenerate
points essential to the topology of symmetric tensor fields and retains
eigenvector and eigenvalue graphs that represent the topology of asymmetric
tensor fields. TFZ scans through each cell, preserving the local topology of
each cell, and thereby ensuring certain global topological guarantees. We
showcase the effectiveness of our framework in enhancing the lossy scientific
data compressors SZ3 and SPERR.

</details>


### [137] [DualPhys-GS: Dual Physically-Guided 3D Gaussian Splatting for Underwater Scene Reconstruction](https://arxiv.org/abs/2508.09610)
*Jiachen Li,Guangzhi Han,Jin Wan,Yuan Gao,Delong Han*

Main category: cs.GR

TL;DR: DualPhys-GS框架通过双路径优化和场景自适应机制，解决了水下3D重建中的颜色失真和几何伪影问题，显著提升了重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统基于大气光学模型的方法无法有效处理水下介质特有的光波长选择性衰减和悬浮粒子散射效应，导致颜色失真、几何伪影和远距离崩溃现象。

Method: 提出DualPhys-GS框架，包括双特征引导的衰减-散射建模机制、多种特殊损失函数设计及场景自适应机制。

Result: 实验结果表明，该方法在多个指标上优于现有方法，重建质量显著提升。

Conclusion: DualPhys-GS框架通过双路径优化机制和场景自适应机制，显著提升了水下场景3D重建的质量，尤其在悬浮物密集区域和远距离场景中表现优异。

Abstract: In 3D reconstruction of underwater scenes, traditional methods based on
atmospheric optical models cannot effectively deal with the selective
attenuation of light wavelengths and the effect of suspended particle
scattering, which are unique to the water medium, and lead to color distortion,
geometric artifacts, and collapsing phenomena at long distances. We propose the
DualPhys-GS framework to achieve high-quality underwater reconstruction through
a dual-path optimization mechanism. Our approach further develops a dual
feature-guided attenuation-scattering modeling mechanism, the RGB-guided
attenuation optimization model combines RGB features and depth information and
can handle edge and structural details. In contrast, the multi-scale
depth-aware scattering model captures scattering effects at different scales
using a feature pyramid network and an attention mechanism. Meanwhile, we
design several special loss functions. The attenuation scattering consistency
loss ensures physical consistency. The water body type adaptive loss
dynamically adjusts the weighting coefficients. The edge-aware scattering loss
is used to maintain the sharpness of structural edges. The multi-scale feature
loss helps to capture global and local structural information. In addition, we
design a scene adaptive mechanism that can automatically identify the
water-body-type characteristics (e.g., clear coral reef waters or turbid
coastal waters) and dynamically adjust the scattering and attenuation
parameters and optimization strategies. Experimental results show that our
method outperforms existing methods in several metrics, especially in suspended
matter-dense regions and long-distance scenes, and the reconstruction quality
is significantly improved.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [138] [Decision-Making-Based Path Planning for Autonomous UAVs: A Survey](https://arxiv.org/abs/2508.09304)
*Kelen C. Teixeira Vivaldini,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 这篇综述论文探讨了决策在自主无人机路径规划中的关键作用，总结了现有研究并指出了未来挑战。


<details>
  <summary>Details</summary>
Motivation: 自主无人机在实际应用中需要基于环境信息做出决策，这对路径规划至关重要。

Method: 论文通过综述现有研究，分析了探索路径规划和信息路径规划两种研究方向，并探讨了数据建模和理解的特点。

Result: 论文概述了决策在路径规划中的应用，并提出了该领域的研究方向和挑战。

Conclusion: 该论文总结了决策在无人机路径规划中的重要性，并指出了该领域现有的挑战。

Abstract: One of the most critical features for the successful operation of autonomous
UAVs is the ability to make decisions based on the information acquired from
their surroundings. Each UAV must be able to make decisions during the flight
in order to deal with uncertainties in its system and the environment, and to
further act upon the information being received. Such decisions influence the
future behavior of the UAV, which is expressed as the path plan. Thus,
decision-making in path planning is an enabling technique for deploying
autonomous UAVs in real-world applications. This survey provides an overview of
existing studies that use aspects of decision-making in path planning,
presenting the research strands for Exploration Path Planning and Informative
Path Planning, and focusing on characteristics of how data have been modeled
and understood. Finally, we highlight the existing challenges for relevant
topics in this field.

</details>


### [139] [How Safe Will I Be Given What I Saw? Calibrated Prediction of Safety Chances for Image-Controlled Autonomy](https://arxiv.org/abs/2508.09346)
*Zhenjiang Mao,Mrinall Eashaan Umasudhan,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 论文提出了一种基于世界模型和无监督域适应的安全预测框架，显著提升了端到端视觉控制系统的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决深度神经网络控制器在部分可观测性和分布偏移条件下的安全预测挑战，弥补传统基于模型和模型无关方法的局限性。

Method: 论文提出了一种校准安全预测框架，利用变分自编码器和循环预测器从原始图像序列预测潜在轨迹，并结合无监督域适应技术处理分布偏移问题。

Result: 实验结果表明，该框架在三个基准测试中保持了高准确性，显著降低了分布偏移下的假阳性率，且复合预测器在长时任务中优于单一预测器。

Conclusion: 本论文提出的框架通过结合变分自编码器、循环预测器和无监督域适应技术，显著提升了端到端视觉控制系统中安全预测的准确性和可靠性，尤其在分布偏移和长时预测任务中表现优异。

Abstract: Autonomous robots that rely on deep neural network controllers pose critical
challenges for safety prediction, especially under partial observability and
distribution shift. Traditional model-based verification techniques are limited
in scalability and require access to low-dimensional state models, while
model-free methods often lack reliability guarantees. This paper addresses
these limitations by introducing a framework for calibrated safety prediction
in end-to-end vision-controlled systems, where neither the state-transition
model nor the observation model is accessible. Building on the foundation of
world models, we leverage variational autoencoders and recurrent predictors to
forecast future latent trajectories from raw image sequences and estimate the
probability of satisfying safety properties. We distinguish between monolithic
and composite prediction pipelines and introduce a calibration mechanism to
quantify prediction confidence. In long-horizon predictions from
high-dimensional observations, the forecasted inputs to the safety evaluator
can deviate significantly from the training distribution due to compounding
prediction errors and changing environmental conditions, leading to
miscalibrated risk estimates. To address this, we incorporate unsupervised
domain adaptation to ensure robustness of safety evaluation under distribution
shift in predictions without requiring manual labels. Our formulation provides
theoretical calibration guarantees and supports practical evaluation across
long prediction horizons. Experimental results on three benchmarks show that
our UDA-equipped evaluators maintain high accuracy and substantially lower
false positive rates under distribution shift. Similarly, world model-based
composite predictors outperform their monolithic counterparts on long-horizon
tasks, and our conformal calibration provides reliable statistical bounds.

</details>


### [140] [CLF-RL: Control Lyapunov Function Guided Reinforcement Learning](https://arxiv.org/abs/2508.09354)
*Kejun Li,Zachary Olkin,Yisong Yue,Aaron D. Ames*

Main category: cs.RO

TL;DR: 通过结合模型轨迹生成和CLF的结构化奖励塑造框架，CLF-RL方法显著提升了双足机器人运动策略的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在双足机器人运动策略生成中表现良好，但存在奖励设计繁琐和对目标形状敏感的问题。

Method: 提出了一个结合模型轨迹生成和控制Lyapunov函数（CLF）的结构化奖励塑造框架，利用LIP模型和HZD预计算步态库生成参考轨迹，并构建基于CLF的奖励函数。

Result: CLF-RL方法显著提高了策略的鲁棒性，优于基线RL和传统跟踪奖励RL方法。

Conclusion: CLF-RL方法在仿真和实际机器人实验中表现出比基线RL策略更高的鲁棒性，且优于传统的跟踪奖励RL方法。

Abstract: Reinforcement learning (RL) has shown promise in generating robust locomotion
policies for bipedal robots, but often suffers from tedious reward design and
sensitivity to poorly shaped objectives. In this work, we propose a structured
reward shaping framework that leverages model-based trajectory generation and
control Lyapunov functions (CLFs) to guide policy learning. We explore two
model-based planners for generating reference trajectories: a reduced-order
linear inverted pendulum (LIP) model for velocity-conditioned motion planning,
and a precomputed gait library based on hybrid zero dynamics (HZD) using
full-order dynamics. These planners define desired end-effector and joint
trajectories, which are used to construct CLF-based rewards that penalize
tracking error and encourage rapid convergence. This formulation provides
meaningful intermediate rewards, and is straightforward to implement once a
reference is available. Both the reference trajectories and CLF shaping are
used only during training, resulting in a lightweight policy at deployment. We
validate our method both in simulation and through extensive real-world
experiments on a Unitree G1 robot. CLF-RL demonstrates significantly improved
robustness relative to the baseline RL policy and better performance than a
classic tracking reward RL formulation.

</details>


### [141] [DAgger Diffusion Navigation: DAgger Boosted Diffusion Policy for Vision-Language Navigation](https://arxiv.org/abs/2508.09444)
*Haoxiang Shi,Xiang Deng,Zaijing Li,Gongwei Chen,Yaowei Wang,Liqiang Nie*

Main category: cs.RO

TL;DR: DifNav 是一种端到端的视觉语言导航方法，通过扩散策略统一路径点生成与规划，结合 DAgger 训练提升性能，实验证明其优于现有两阶段模型。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段路径点规划框架存在全局次优化和性能瓶颈问题，DifNav 旨在通过端到端优化解决这些问题，并提升指令跟随行为的多样性。

Method: DifNav 采用条件扩散策略直接建模连续导航空间中未来动作的多模态分布，无需路径点预测器，并通过 DAgger 进行在线策略训练和专家轨迹增强。

Result: 实验表明，DifNav 在导航性能上显著优于现有的两阶段模型，无需路径点预测器即可实现更好的效果。

Conclusion: DAgger Diffusion Navigation (DifNav) 方法通过将传统的两阶段框架（路径点生成与规划）统一为一个端到端的扩散策略，显著提升了连续环境中的视觉语言导航性能，并在基准数据集上超越了现有最先进的两阶段模型。

Abstract: Vision-Language Navigation in Continuous Environments (VLN-CE) requires
agents to follow natural language instructions through free-form 3D spaces.
Existing VLN-CE approaches typically use a two-stage waypoint planning
framework, where a high-level waypoint predictor generates the navigable
waypoints, and then a navigation planner suggests the intermediate goals in the
high-level action space. However, this two-stage decomposition framework
suffers from: (1) global sub-optimization due to the proxy objective in each
stage, and (2) a performance bottleneck caused by the strong reliance on the
quality of the first-stage predicted waypoints. To address these limitations,
we propose DAgger Diffusion Navigation (DifNav), an end-to-end optimized VLN-CE
policy that unifies the traditional two stages, i.e. waypoint generation and
planning, into a single diffusion policy. Notably, DifNav employs a conditional
diffusion policy to directly model multi-modal action distributions over future
actions in continuous navigation space, eliminating the need for a waypoint
predictor while enabling the agent to capture multiple possible
instruction-following behaviors. To address the issues of compounding error in
imitation learning and enhance spatial reasoning in long-horizon navigation
tasks, we employ DAgger for online policy training and expert trajectory
augmentation, and use the aggregated data to further fine-tune the policy. This
approach significantly improves the policy's robustness and its ability to
recover from error states. Extensive experiments on benchmark datasets
demonstrate that, even without a waypoint predictor, the proposed method
substantially outperforms previous state-of-the-art two-stage waypoint-based
models in terms of navigation performance. Our code is available at:
https://github.com/Tokishx/DifNav.

</details>


### [142] [Reactive Model Predictive Contouring Control for Robot Manipulators](https://arxiv.org/abs/2508.09502)
*Junheon Yoon,Woo-Jeong Baek,Jaeheung Park*

Main category: cs.RO

TL;DR: 提出基于RMPCC的机器人路径跟随框架，实时避障且避免奇异点，计算效率100Hz，性能提升10倍。


<details>
  <summary>Details</summary>
Motivation: 现有路径跟随方法依赖时间参数化，难以同时处理避障、奇异点避免和运动约束，导致路径误差较大。

Method: 通过路径参数化参考路径，并利用RMPCC进行优化。引入控制屏障函数（CBFs）避免碰撞和奇异点，采用雅可比线性化和高斯-牛顿Hessian近似解决非线性问题。

Result: RMPCC框架在动态环境中实现了100Hz的实时计算，轮廓误差和机器人加速度均较低，性能优于现有方法10倍。

Conclusion: 该论文提出的RMPCC框架在动态环境中有效实现了路径跟随、避障和避免奇异点，计算效率高达100Hz，性能优于现有方法10倍。实验验证了其在真实场景中的高效性和低误差。

Abstract: This contribution presents a robot path-following framework via Reactive
Model Predictive Contouring Control (RMPCC) that successfully avoids obstacles,
singularities and self-collisions in dynamic environments at 100 Hz. Many
path-following methods rely on the time parametrization, but struggle to handle
collision and singularity avoidance while adhering kinematic limits or other
constraints. Specifically, the error between the desired path and the actual
position can become large when executing evasive maneuvers. Thus, this paper
derives a method that parametrizes the reference path by a path parameter and
performs the optimization via RMPCC. In particular, Control Barrier Functions
(CBFs) are introduced to avoid collisions and singularities in dynamic
environments. A Jacobian-based linearization and Gauss-Newton Hessian
approximation enable solving the nonlinear RMPCC problem at 100 Hz,
outperforming state-of-the-art methods by a factor of 10. Experiments confirm
that the framework handles dynamic obstacles in real-world settings with low
contouring error and low robot acceleration.

</details>


### [143] [SMART-OC: A Real-time Time-risk Optimal Replanning Algorithm for Dynamic Obstacles and Spatio-temporally Varying Currents](https://arxiv.org/abs/2508.09508)
*Reema Raval,Shalabh Gupta*

Main category: cs.RO

TL;DR: SMART-OC算法帮助USV在动态海洋环境中实时规划最优路径，避开障碍物并利用洋流。


<details>
  <summary>Details</summary>
Motivation: 海洋环境复杂多变，存在时空变化的洋流和动态障碍物，对USV的安全高效导航提出了挑战。

Method: 提出了一种名为SMART-OC的新算法，结合路径上的障碍物风险与到达目标的时间成本，实现实时时间-风险最优路径规划。

Result: 仿真实验验证了SMART-OC的有效性，USV能够快速重新规划路径以避开动态障碍物并利用洋流成功到达目标。

Conclusion: SMART-OC算法通过实时时间-风险最优路径规划，成功帮助USV在动态海洋环境中避开障碍物并利用洋流，高效到达目标。

Abstract: Typical marine environments are highly complex with spatio-temporally varying
currents and dynamic obstacles, presenting significant challenges to Unmanned
Surface Vehicles (USVs) for safe and efficient navigation. Thus, the USVs need
to continuously adapt their paths with real-time information to avoid
collisions and follow the path of least resistance to the goal via exploiting
ocean currents. In this regard, we introduce a novel algorithm, called
Self-Morphing Adaptive Replanning Tree for dynamic Obstacles and Currents
(SMART-OC), that facilitates real-time time-risk optimal replanning in dynamic
environments. SMART-OC integrates the obstacle risks along a path with the time
cost to reach the goal to find the time-risk optimal path. The effectiveness of
SMART-OC is validated by simulation experiments, which demonstrate that the USV
performs fast replannings to avoid dynamic obstacles and exploit ocean currents
to successfully reach the goal.

</details>


### [144] [CaRoBio: 3D Cable Routing with a Bio-inspired Gripper Fingernail](https://arxiv.org/abs/2508.09558)
*Jiahui Zuo,Boyang Zhang,Fumin Zhang*

Main category: cs.RO

TL;DR: 本文设计了一种鹰爪式指甲，结合端到端3D电缆布线框架，显著提升了电缆操作的效率和效果，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 电缆布线作为复杂的多阶段机器人操作场景，传统平行双指夹爪存在过挤压和过张力的风险，亟需改进。

Method: 设计了一种新型的鹰爪式指甲，并安装在夹爪手指上，结合基于视觉的状态估计和离线轨迹规划的运动基元，实现了电缆的连续控制。

Result: 提出的框架在多种电缆和槽道测试中表现优异，显著优于同等感知条件下的拾取放置操作。

Conclusion: 本文提出的鹰爪式指甲设计及其单次抓取端到端3D电缆布线框架，显著优于传统的拾取放置策略，为未来3D空间电缆布线操作提供了参考。

Abstract: The manipulation of deformable linear flexures has a wide range of
applications in industry, such as cable routing in automotive manufacturing and
textile production. Cable routing, as a complex multi-stage robot manipulation
scenario, is a challenging task for robot automation. Common parallel
two-finger grippers have the risk of over-squeezing and over-tension when
grasping and guiding cables. In this paper, a novel eagle-inspired fingernail
is designed and mounted on the gripper fingers, which helps with cable grasping
on planar surfaces and in-hand cable guiding operations. Then we present a
single-grasp end-to-end 3D cable routing framework utilizing the proposed
fingernails, instead of the common pick-and-place strategy. Continuous control
is achieved to efficiently manipulate cables through vision-based state
estimation of task configurations and offline trajectory planning based on
motion primitives. We evaluate the effectiveness of the proposed framework with
a variety of cables and channel slots, significantly outperforming the
pick-and-place manipulation process under equivalent perceptual conditions. Our
reconfigurable task setting and the proposed framework provide a reference for
future cable routing manipulations in 3D space.

</details>


### [145] [ESCoT: An Enhanced Step-based Coordinate Trajectory Planning Method for Multiple Car-like Robots](https://arxiv.org/abs/2508.09581)
*Junkai Jiang,Yihe Chen,Yibin Yang,Ruochen Li,Shaobing Xu,Jianqiang Wang*

Main category: cs.RO

TL;DR: ESCoT是一种增强的基于步骤的多车轨迹规划方法，通过协作规划和重新规划策略，显著提高了解决方案质量和成功率，并在实际机器人测试中验证了其适用性。


<details>
  <summary>Details</summary>
Motivation: 多车轨迹规划（MVTP）是多机器人系统（MRS）中的关键挑战之一，具有广泛的应用领域。

Method: ESCoT结合了两种关键策略：局部机器人组的协作规划和重复配置的重新规划。

Result: 实验表明，ESCoT在稀疏场景中显著提高了解决方案质量，相比基线方法提升了70%（典型冲突场景）和34%（随机生成场景）；在密集场景中，ESCoT优于所有基线方法，在最复杂配置下保持50%以上的成功率。

Conclusion: ESCoT有效解决了多车轨迹规划问题，进一步扩展了基于步骤的方法的能力，并通过实际机器人测试验证了算法在现实场景中的适用性。

Abstract: Multi-vehicle trajectory planning (MVTP) is one of the key challenges in
multi-robot systems (MRSs) and has broad applications across various fields.
This paper presents ESCoT, an enhanced step-based coordinate trajectory
planning method for multiple car-like robots. ESCoT incorporates two key
strategies: collaborative planning for local robot groups and replanning for
duplicate configurations. These strategies effectively enhance the performance
of step-based MVTP methods. Through extensive experiments, we show that ESCoT
1) in sparse scenarios, significantly improves solution quality compared to
baseline step-based method, achieving up to 70% improvement in typical conflict
scenarios and 34% in randomly generated scenarios, while maintaining high
solving efficiency; and 2) in dense scenarios, outperforms all baseline
methods, maintains a success rate of over 50% even in the most challenging
configurations. The results demonstrate that ESCoT effectively solves MVTP,
further extending the capabilities of step-based methods. Finally, practical
robot tests validate the algorithm's applicability in real-world scenarios.

</details>


### [146] [HapticGiant: A Novel Very Large Kinesthetic Haptic Interface with Hierarchical Force Control](https://arxiv.org/abs/2508.09595)
*Michael Fennel,Markus Walker,Dominik Pikos,Uwe D. Hanebeck*

Main category: cs.RO

TL;DR: HapticGiant是一种新型大规模动觉触觉接口，旨在匹配人类手臂特性并提供全触觉反馈，通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管高级头戴式显示器已商业化，但动觉触觉接口仍面临工作空间有限、自由度不足和运动学与人类手臂不匹配等挑战。

Method: 提出了一种新型的大规模动觉触觉接口HapticGiant，采用了一种新型的导纳型力控制方案，利用分层优化来渲染任意串联运动链和笛卡尔导纳。

Result: 实验结果表明HapticGiant及其控制方案的有效性。

Conclusion: HapticGiant及其控制方案的有效性通过实验结果得到验证，为高度沉浸式的虚拟现实应用铺平了道路。

Abstract: Research in virtual reality and haptic technologies has consistently aimed to
enhance immersion. While advanced head-mounted displays are now commercially
available, kinesthetic haptic interfaces still face challenges such as limited
workspaces, insufficient degrees of freedom, and kinematics not matching the
human arm. In this paper, we present HapticGiant, a novel large-scale
kinesthetic haptic interface designed to match the properties of the human arm
as closely as possible and to facilitate natural user locomotion while
providing full haptic feedback. The interface incorporates a novel
admittance-type force control scheme, leveraging hierarchical optimization to
render both arbitrary serial kinematic chains and Cartesian admittances.
Notably, the proposed control scheme natively accounts for system limitations,
including joint and Cartesian constraints, as well as singularities.
Experimental results demonstrate the effectiveness of HapticGiant and its
control scheme, paving the way for highly immersive virtual reality
applications.

</details>


### [147] [BEAVR: Bimanual, multi-Embodiment, Accessible, Virtual Reality Teleoperation System for Robots](https://arxiv.org/abs/2508.09606)
*Alejandro Posadas-Nava,Alejandro Carrasco,Richard Linares*

Main category: cs.RO

TL;DR: BEAVR是一个开源VR远程操作系统，支持多机器人实时控制和策略学习，延迟≤35毫秒，兼容主流视觉运动策略。


<details>
  <summary>Details</summary>
Motivation: 设计BEAVR的目的是为了统一异构机器人平台的实时控制、数据记录和策略学习，并通过商品化VR硬件实现灵巧远程操作。

Method: BEAVR采用零拷贝流架构实现≤35毫秒延迟，异步“思考-行动”控制循环进行可扩展推理，以及优化的灵活网络API支持实时多机器人操作。

Result: BEAVR在多样化操作任务中进行了基准测试，并展示了与主流视觉运动策略（如ACT、DiffusionPolicy和SmolVLA）的兼容性。所有代码和数据集均已公开。

Conclusion: BEAVR是一个开源的双臂多体现VR远程操作系统，旨在统一异构机器人平台的实时控制、数据记录和策略学习。该系统通过商品化VR硬件实现实时灵巧远程操作，支持从7自由度机械臂到全身人形机器人的模块化集成，并直接以LeRobot数据集模式记录同步多模态演示。

Abstract: \textbf{BEAVR} is an open-source, bimanual, multi-embodiment Virtual Reality
(VR) teleoperation system for robots, designed to unify real-time control, data
recording, and policy learning across heterogeneous robotic platforms. BEAVR
enables real-time, dexterous teleoperation using commodity VR hardware,
supports modular integration with robots ranging from 7-DoF manipulators to
full-body humanoids, and records synchronized multi-modal demonstrations
directly in the LeRobot dataset schema. Our system features a zero-copy
streaming architecture achieving $\leq$35\,ms latency, an asynchronous
``think--act'' control loop for scalable inference, and a flexible network API
optimized for real-time, multi-robot operation. We benchmark BEAVR across
diverse manipulation tasks and demonstrate its compatibility with leading
visuomotor policies such as ACT, DiffusionPolicy, and SmolVLA. All code is
publicly available, and datasets are released on Hugging Face\footnote{Code,
datasets, and VR app available at https://github.com/ARCLab-MIT/BEAVR-Bot.

</details>


### [148] [Interpretable Robot Control via Structured Behavior Trees and Large Language Models](https://arxiv.org/abs/2508.09621)
*Ingrid Maéva Chekam,Ines Pastor-Martinez,Ali Tourani,Jose Andres Millan-Romera,Laura Ribeiro,Pedro Miguel Bastos Soares,Holger Voos,Jose Luis Sanchez-Lopez*

Main category: cs.RO

TL;DR: 论文提出了一种结合LLMs和行为树的新框架，提升HRI系统的自然性和实用性，实验显示94%的准确率。


<details>
  <summary>Details</summary>
Motivation: 传统机器人控制方法需要用户适应界面或记忆预定义命令，限制了在动态非结构化环境中的可用性，因此需要更自然、适应性强的HRI界面。

Method: 通过将大型语言模型（LLMs）与行为树结合，系统能够将用户的自然语言指令转化为可执行动作，并支持感知功能（如人员跟踪和手势识别）的模块化集成。

Result: 实验结果表明，该系统在真实场景中实用，平均认知到执行准确率约为94%。

Conclusion: 该论文提出的结合大型语言模型（LLMs）和行为树的新框架，显著提升了人机交互（HRI）系统的实用性和自然性，平均认知到执行准确率约为94%。

Abstract: As intelligent robots become more integrated into human environments, there
is a growing need for intuitive and reliable Human-Robot Interaction (HRI)
interfaces that are adaptable and more natural to interact with. Traditional
robot control methods often require users to adapt to interfaces or memorize
predefined commands, limiting usability in dynamic, unstructured environments.
This paper presents a novel framework that bridges natural language
understanding and robotic execution by combining Large Language Models (LLMs)
with Behavior Trees. This integration enables robots to interpret natural
language instructions given by users and translate them into executable actions
by activating domain-specific plugins. The system supports scalable and modular
integration, with a primary focus on perception-based functionalities, such as
person tracking and hand gesture recognition. To evaluate the system, a series
of real-world experiments was conducted across diverse environments.
Experimental results demonstrate that the proposed approach is practical in
real-world scenarios, with an average cognition-to-execution accuracy of
approximately 94%, making a significant contribution to HRI systems and robots.
The complete source code of the framework is publicly available at
https://github.com/snt-arg/robot_suite.

</details>


### [149] [Immersive Teleoperation of Beyond-Human-Scale Robotic Manipulators: Challenges and Future Directions](https://arxiv.org/abs/2508.09700)
*Mahdi Hejrati,Jouni Mattila*

Main category: cs.RO

TL;DR: 本文探讨了超大规模机器人操纵器沉浸式远程操作的挑战，分析了反馈系统设计，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着超大规模机器人平台在工业领域的应用增加，需要重新设计沉浸式界面以支持可扩展、安全和高效的人机协作。

Method: 分析了触觉和视觉反馈系统的设计权衡，并通过早期实验比较了基于外骨骼和操纵杆的控制设置。

Result: 研究发现，沉浸式远程操作在BHSRMs中面临控制、认知和界面层面的挑战，重点在于确保操作员安全、减少感觉运动不匹配和增强体现感。

Conclusion: 本文概述了针对超大规模机器人操纵器（BHSRMs）沉浸式远程操作的关键研究方向，包括新的评估工具、扩展策略和以人为中心的安全模型。

Abstract: Teleoperation of beyond-human-scale robotic manipulators (BHSRMs) presents
unique challenges that differ fundamentally from conventional human-scale
systems. As these platforms gain relevance in industrial domains such as
construction, mining, and disaster response, immersive interfaces must be
rethought to support scalable, safe, and effective human-robot collaboration.
This paper investigates the control, cognitive, and interface-level challenges
of immersive teleoperation in BHSRMs, with a focus on ensuring operator safety,
minimizing sensorimotor mismatch, and enhancing the sense of embodiment. We
analyze design trade-offs in haptic and visual feedback systems, supported by
early experimental comparisons of exoskeleton- and joystick-based control
setups. Finally, we outline key research directions for developing new
evaluation tools, scaling strategies, and human-centered safety models tailored
to large-scale robotic telepresence.

</details>


### [150] [FLARE: Agile Flights for Quadrotor Cable-Suspended Payload System via Reinforcement Learning](https://arxiv.org/abs/2508.09797)
*Dongcheng Cao,Jin Zhou,Xian Wang,Shuo Li*

Main category: cs.RO

TL;DR: FLARE通过强化学习实现四旋翼悬挂负载系统的敏捷飞行，性能优于传统方法，并在现实中实时运行。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼悬挂负载系统因其欠驱动、高度非线性和混合动力学特性带来的敏捷飞行挑战，克服传统优化方法的高计算成本和电缆模式转换复杂性。

Method: 采用强化学习（RL）框架FLARE，直接从高保真仿真中学习敏捷导航策略。

Result: 在三个设计的挑战性场景中验证，性能显著优于现有优化方法，门穿越速度提升3倍，并实现零样本仿真到现实的迁移。

Conclusion: FLARE框架通过强化学习成功实现了四旋翼悬挂负载系统的敏捷飞行，显著优于传统优化方法，并在实际实验中展示了零样本迁移能力和实时性能。

Abstract: Agile flight for the quadrotor cable-suspended payload system is a formidable
challenge due to its underactuated, highly nonlinear, and hybrid dynamics.
Traditional optimization-based methods often struggle with high computational
costs and the complexities of cable mode transitions, limiting their real-time
applicability and maneuverability exploitation. In this letter, we present
FLARE, a reinforcement learning (RL) framework that directly learns agile
navigation policy from high-fidelity simulation. Our method is validated across
three designed challenging scenarios, notably outperforming a state-of-the-art
optimization-based approach by a 3x speedup during gate traversal maneuvers.
Furthermore, the learned policies achieve successful zero-shot sim-to-real
transfer, demonstrating remarkable agility and safety in real-world
experiments, running in real time on an onboard computer.

</details>


### [151] [Embodied Tactile Perception of Soft Objects Properties](https://arxiv.org/abs/2508.09836)
*Anirvan Dutta,Alexis WM Devillard,Zhihuan Zhang,Xiaoxiao Cheng,Etienne Burdet*

Main category: cs.RO

TL;DR: 研究通过模块化电子皮肤和多模态传感系统，探索了机械顺应性和交互策略对触觉感知的影响，发现多模态传感更优，并提出了潜在过滤器模型以解释交互动态。


<details>
  <summary>Details</summary>
Motivation: 为了实现机器人像人类一样精细操作，需要理解机械顺应性、多模态传感和有目的交互如何共同影响触觉感知。

Method: 使用模块化电子皮肤系统，结合可调的机械顺应性和多模态传感（法向力、剪切力和振动），通过一系列精心设计的触诊动作（按压、进动、滑动）来研究感知。提出了一种无监督的动作条件深度状态空间模型——潜在过滤器，用于模拟复杂的交互动态。

Result: 研究发现，多模态传感在物体感知方面表现更优，揭示了电子皮肤机械特性与环境之间的复杂相互作用，且这种相互作用需结合时间动态进行分析。

Conclusion: 研究表明，多模态传感优于单模态传感，并强调了环境与电子皮肤机械特性之间微妙的相互作用，需要结合时间动态来进一步研究。

Abstract: To enable robots to develop human-like fine manipulation, it is essential to
understand how mechanical compliance, multi-modal sensing, and purposeful
interaction jointly shape tactile perception. In this study, we use a dedicated
modular e-Skin with tunable mechanical compliance and multi-modal sensing
(normal, shear forces and vibrations) to systematically investigate how sensing
embodiment and interaction strategies influence robotic perception of objects.
Leveraging a curated set of soft wave objects with controlled viscoelastic and
surface properties, we explore a rich set of palpation primitives-pressing,
precession, sliding that vary indentation depth, frequency, and directionality.
In addition, we propose the latent filter, an unsupervised, action-conditioned
deep state-space model of the sophisticated interaction dynamics and infer
causal mechanical properties into a structured latent space. This provides
generalizable and in-depth interpretable representation of how embodiment and
interaction determine and influence perception. Our investigation demonstrates
that multi-modal sensing outperforms uni-modal sensing. It highlights a nuanced
interaction between the environment and mechanical properties of e-Skin, which
should be examined alongside the interaction by incorporating temporal
dynamics.

</details>


### [152] [QuickGrasp: Lightweight Antipodal Grasp Planning with Point Clouds](https://arxiv.org/abs/2504.19716)
*Navin Sriram Ravie,Keerthi Vasan M,Asokan Thondiyath,Bijo Sebastian*

Main category: cs.RO

TL;DR: 该论文提出了一种轻量级的优化方法用于机器人抓取规划，通过间接估计抓取点而非末端执行器姿态，显著提高了效率和泛化能力，优于现有GPD方法。


<details>
  <summary>Details</summary>
Motivation: 当前大多数抓取规划方法依赖于六自由度空间的纯采样或学习问题，但在真实环境中泛化能力差且效率低下。因此，需要一种更高效、更可靠的方法来解决这些问题。

Method: 论文提出了一种基于优化的抓取规划算法，首先使用软区域增长算法进行有效的平面分割，即使在曲面情况下也能有效工作。然后，通过优化的质量度量评估抓取点以确保间接力闭合。

Result: 提出的抓取框架在模拟和真实环境中均优于GPD方法，展示了更高的效率和更好的泛化能力。

Conclusion: 该论文提出了一种轻量级的分析方法用于机器人抓取规划，特别是在六自由度空间中几乎不需要采样。通过将抓取规划问题转化为优化问题，该方法在物体表面估计抓取点，而非直接估计末端执行器的姿态。实验结果表明，该方法在模拟和真实环境中均优于现有的GPD方法。

Abstract: Grasping has been a long-standing challenge in facilitating the final
interface between a robot and the environment. As environments and tasks become
complicated, the need to embed higher intelligence to infer from the
surroundings and act on them has become necessary. Although most methods
utilize techniques to estimate grasp pose by treating the problem via pure
sampling-based approaches in the six-degree-of-freedom space or as a learning
problem, they usually fail in real-life settings owing to poor generalization
across domains. In addition, the time taken to generate the grasp plan and the
lack of repeatability, owing to sampling inefficiency and the probabilistic
nature of existing grasp planning approaches, severely limits their application
in real-world tasks. This paper presents a lightweight analytical approach
towards robotic grasp planning, particularly antipodal grasps, with little to
no sampling in the six-degree-of-freedom space. The proposed grasp planning
algorithm is formulated as an optimization problem towards estimating grasp
points on the object surface instead of directly estimating the end-effector
pose. To this extent, a soft-region-growing algorithm is presented for
effective plane segmentation, even in the case of curved surfaces. An
optimization-based quality metric is then used for the evaluation of grasp
points to ensure indirect force closure. The proposed grasp framework is
compared with the existing state-of-the-art grasp planning approach, Grasp pose
detection (GPD), as a baseline over multiple simulated objects. The
effectiveness of the proposed approach in comparison to GPD is also evaluated
in a real-world setting using image and point-cloud data, with the planned
grasps being executed using a ROBOTIQ gripper and UR5 manipulator.

</details>


### [153] [Whole-Body Bilateral Teleoperation with Multi-Stage Object Parameter Estimation for Wheeled Humanoid Locomanipulation](https://arxiv.org/abs/2508.09846)
*Donghoon Baek,Amartya Purushottam,Jason J. Choi,Joao Ramos*

Main category: cs.RO

TL;DR: 该论文提出了一种结合全身双边遥操作与在线多阶段物体惯性参数估计的框架，显著提升了轮式人形机器人的操作动态同步和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决轮式人形机器人在操作动态物体时的同步和跟踪问题，该研究提出了一种结合全身双边遥操作与在线多阶段物体惯性参数估计的框架，以提升操作性能和动态同步。

Method: 该框架采用多阶段过程，依次整合了基于视觉的物体大小估计器、由大型视觉语言模型（VLM）生成的初始参数猜测，以及解耦的分层采样策略。通过视觉大小估计和VLM先验提供物体惯性参数的强初始猜测，显著减少了基于采样的优化的搜索空间。

Result: 在定制的轮式人形机器人上验证了系统的实时性，成功执行了提升、交付和释放任务，负载约为机器人自重的三分之一。

Conclusion: 该框架通过结合全身双边遥操作与在线多阶段物体惯性参数估计模块，显著提升了轮式人形机器人的操作动态同步和跟踪性能，实现了实时在线更新和更动态的全身遥操作。

Abstract: This paper presents an object-aware whole-body bilateral teleoperation
framework for wheeled humanoid loco-manipulation. This framework combines
whole-body bilateral teleoperation with an online multi-stage object inertial
parameter estimation module, which is the core technical contribution of this
work. The multi-stage process sequentially integrates a vision-based object
size estimator, an initial parameter guess generated by a large vision-language
model (VLM), and a decoupled hierarchical sampling strategy. The visual size
estimate and VLM prior offer a strong initial guess of the object's inertial
parameters, significantly reducing the search space for sampling-based
refinement and improving the overall estimation speed. A hierarchical strategy
first estimates mass and center of mass, then infers inertia from object size
to ensure physically feasible parameters, while a decoupled multi-hypothesis
scheme enhances robustness to VLM prior errors. Our estimator operates in
parallel with high-fidelity simulation and hardware, enabling real-time online
updates. The estimated parameters are then used to update the wheeled
humanoid's equilibrium point, allowing the operator to focus more on locomotion
and manipulation. This integration improves the haptic force feedback for
dynamic synchronization, enabling more dynamic whole-body teleoperation. By
compensating for object dynamics using the estimated parameters, the framework
also improves manipulation tracking while preserving compliant behavior. We
validate the system on a customized wheeled humanoid with a robotic gripper and
human-machine interface, demonstrating real-time execution of lifting,
delivering, and releasing tasks with a payload weighing approximately one-third
of the robot's body weight.

</details>


### [154] [Toward Human-Robot Teaming: Learning Handover Behaviors from 3D Scenes](https://arxiv.org/abs/2508.09855)
*Yuekun Wu,Yik Lung Pang,Andrea Cavallaro,Changjae Oh*

Main category: cs.RO

TL;DR: 论文提出了一种基于RGB图像训练人机协作策略的方法，无需真实机器人训练或数据收集，通过稀疏视图高斯泼溅重建生成演示，实验证明该方法有效。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作（如物体交接）中依赖大规模真实交互数据和仿真与真实视觉域差距的问题。

Method: 利用稀疏视图高斯泼溅重建人机交接场景，生成机器人演示（图像-动作对），通过模拟相机姿态变化直接映射到夹爪姿态变化。

Result: 在高斯泼溅重建场景和真实人机交接实验中，该方法表现出色，提供了无缝且鲁棒的人机协作新表示。

Conclusion: 该方法为无需真实机器人训练的人机交接任务提供了一种高效且可靠的解决方案。

Abstract: Human-robot teaming (HRT) systems often rely on large-scale datasets of human
and robot interactions, especially for close-proximity collaboration tasks such
as human-robot handovers. Learning robot manipulation policies from raw,
real-world image data requires a large number of robot-action trials in the
physical environment. Although simulation training offers a cost-effective
alternative, the visual domain gap between simulation and robot workspace
remains a major limitation. We introduce a method for training HRT policies,
focusing on human-to-robot handovers, solely from RGB images without the need
for real-robot training or real-robot data collection. The goal is to enable
the robot to reliably receive objects from a human with stable grasping while
avoiding collisions with the human hand. The proposed policy learner leverages
sparse-view Gaussian Splatting reconstruction of human-to-robot handover scenes
to generate robot demonstrations containing image-action pairs captured with a
camera mounted on the robot gripper. As a result, the simulated camera pose
changes in the reconstructed scene can be directly translated into gripper pose
changes. Experiments in both Gaussian Splatting reconstructed scene and
real-world human-to-robot handover experiments demonstrate that our method
serves as a new and effective representation for the human-to-robot handover
task, contributing to more seamless and robust HRT.

</details>


### [155] [A Shank Angle-Based Control System Enables Soft Exoskeleton to Assist Human Non-Steady Locomotion](https://arxiv.org/abs/2508.09876)
*Xiaowei Tan,Weizhong Jiang,Bi Zhang,Wanxin Chen,Yiwen Zhao,Ning Li,Lianqing Liu,Xingang Zhao*

Main category: cs.RO

TL;DR: 该研究开发了一种基于胫骨角度的外骨骼控制系统，适用于非稳态步态，通过双高斯模型和IMU实时调整辅助剖面，实验证明其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 外骨骼在稳态步态中已显示出有效辅助作用，但在非线性步态相进展的非稳态步态中效果尚不明确，尤其是跨多种活动的情况。

Method: 控制系统包括在线辅助剖面生成方法和基于模型的反馈控制方法。辅助剖面采用双高斯模型，以胫骨角度为自变量，利用IMU测量实时更新模型参数以适应个体间和个体内的生物力学变异性。剖面跟踪控制采用人-外骨骼运动学和刚度模型作为反馈组件。

Result: 实验验证了各方法的有效性，控制系统在多种活动中对步态扰动表现出鲁棒性，且外骨骼的机械辅助对人体产生了积极的生物力学和生理反应。

Conclusion: 该研究验证了基于胫骨角度的控制系统在不同活动中的有效性，展示了其对步态扰动的鲁棒性，并揭示了外骨骼机械辅助对人体生物力学和生理反应的积极影响。

Abstract: Exoskeletons have been shown to effectively assist humans during steady
locomotion. However, their effects on non-steady locomotion, characterized by
nonlinear phase progression within a gait cycle, remain insufficiently
explored, particularly across diverse activities. This work presents a shank
angle-based control system that enables the exoskeleton to maintain real-time
coordination with human gait, even under phase perturbations, while dynamically
shaping assistance profiles to match the biological ankle moment patterns
across walking, running, stair negotiation tasks. The control system consists
of an assistance profile online generation method and a model-based feedforward
control method. The assistance profile is formulated as a dual-Gaussian model
with the shank angle as the independent variable. Leveraging only IMU
measurements, the model parameters are updated online each stride to adapt to
inter- and intra-individual biomechanical variability. The profile tracking
control employs a human-exoskeleton kinematics and stiffness model as a
feedforward component, reducing reliance on historical control data due to the
lack of clear and consistent periodicity in non-steady locomotion. Three
experiments were conducted using a lightweight soft exoskeleton with multiple
subjects. The results validated the effectiveness of each individual method,
demonstrated the robustness of the control system against gait perturbations
across various activities, and revealed positive biomechanical and
physiological responses of human users to the exoskeleton's mechanical
assistance.

</details>


### [156] [PPL: Point Cloud Supervised Proprioceptive Locomotion Reinforcement Learning for Legged Robots in Crawl Spaces](https://arxiv.org/abs/2508.09950)
*Bida Ma,Nuo Xu,Chenkun Qi,Xin Liu,Yule Mo,Jinkai Wang,Chunpeng Lu*

Main category: cs.RO

TL;DR: 提出一种点云监督的自主感知强化学习方法，提升腿式机器人在狭窄空间中的运动能力，无需依赖外部传感器。


<details>
  <summary>Details</summary>
Motivation: 在狭窄空间中，现有的外部感知学习方法因传感器噪声和低可见度条件受限，而自主感知学习方法仅能推断地面特征，难以有效穿越。因此，本研究旨在开发一种无需外部传感器的自主感知学习方法，以提升机器人在狭窄空间中的运动能力。

Method: 提出了一种基于点云监督的自主感知强化学习方法，通过状态估计网络利用历史本体感知数据估计机器人的地面和空间特征以及碰撞状态。点云以极坐标系表示，并采用高效的点云处理方法提取特征以监督网络学习。设计了全面的奖励函数以引导机器人在碰撞后穿越狭窄空间。

Result: 实验表明，与现有方法相比，该方法在狭窄空间中表现出更敏捷的运动能力。

Conclusion: 本研究提出了一种点云监督的自主感知学习方法，显著提升了腿式机器人在狭窄空间中的运动能力，且无需依赖外部感知传感器。

Abstract: The legged locomotion in spatially constrained structures (called crawl
spaces) is challenging. In crawl spaces, current exteroceptive locomotion
learning methods are limited by large noises and errors of the sensors in
possible low visibility conditions, and current proprioceptive locomotion
learning methods are difficult in traversing crawl spaces because only ground
features are inferred. In this study, a point cloud supervised proprioceptive
locomotion reinforcement learning method for legged robots in crawl spaces is
proposed. A state estimation network is designed to estimate the robot's
surrounding ground and spatial features as well as the robot's collision states
using historical proprioceptive sensor data. The point cloud is represented in
polar coordinate frame and a point cloud processing method is proposed to
efficiently extract the ground and spatial features that are used to supervise
the state estimation network learning. Comprehensive reward functions that
guide the robot to traverse through crawl spaces after collisions are designed.
Experiments demonstrate that, compared to existing methods, our method exhibits
more agile locomotion in crawl spaces. This study enhances the ability of
legged robots to traverse spatially constrained environments without requiring
exteroceptive sensors.

</details>


### [157] [GBC: Generalized Behavior-Cloning Framework for Whole-Body Humanoid Imitation](https://arxiv.org/abs/2508.09960)
*Yifei Yao,Chengyuan Luo,Jiaheng Du,Wentao He,Jun-Guo Lu*

Main category: cs.RO

TL;DR: GBC框架通过统一的数据处理和学习算法，解决了人形机器人开发中的通用性问题，并验证了其高效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人开发面临数据与算法在不同形态间不通用的问题，阻碍了人形机器人的发展。

Method: GBC框架通过三个协同创新实现：自适应数据管道、DAgger-MMPPO算法与MMTransformer架构，以及基于Isaac Lab的高效开源平台。

Result: GBC在多种异构人形机器人上训练策略，展示了出色的性能和对新动作的迁移能力。

Conclusion: GBC框架为创建真正通用的人形机器人控制器提供了首个实用且统一的解决方案，通过验证展示了其卓越的性能和泛化能力。

Abstract: The creation of human-like humanoid robots is hindered by a fundamental
fragmentation: data processing and learning algorithms are rarely universal
across different robot morphologies. This paper introduces the Generalized
Behavior Cloning (GBC) framework, a comprehensive and unified solution designed
to solve this end-to-end challenge. GBC establishes a complete pathway from
human motion to robot action through three synergistic innovations. First, an
adaptive data pipeline leverages a differentiable IK network to automatically
retarget any human MoCap data to any humanoid. Building on this foundation, our
novel DAgger-MMPPO algorithm with its MMTransformer architecture learns robust,
high-fidelity imitation policies. To complete the ecosystem, the entire
framework is delivered as an efficient, open-source platform based on Isaac
Lab, empowering the community to deploy the full workflow via simple
configuration scripts. We validate the power and generality of GBC by training
policies on multiple heterogeneous humanoids, demonstrating excellent
performance and transfer to novel motions. This work establishes the first
practical and unified pathway for creating truly generalized humanoid
controllers.

</details>


### [158] [Vision-driven River Following of UAV via Safe Reinforcement Learning using Semantic Dynamics Model](https://arxiv.org/abs/2508.09971)
*Zihan Wang,Nina Mahmoudian*

Main category: cs.RO

TL;DR: 本研究提出了一种结合MGAE、SDM和CADE的框架，用于无人机在密集河流环境中的自主跟随，实现了安全与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 在GPS信号不可靠的密集河流环境中，无人机自主跟随河流对于救援、监视和环境监测等应用至关重要。

Method: 提出了边际增益优势估计（MGAE）、基于语义掩码的语义动态模型（SDM）以及约束演员动态估计器（CADE）架构，用于解决部分可观测的约束子模马尔可夫决策过程。

Result: 仿真结果表明，MGAE相比传统基于评论家的方法（如广义优势估计）收敛更快且性能更优；SDM提供了更准确的短期状态预测，使成本估计器能更好地预测潜在违规。

Conclusion: CADE框架成功将安全约束整合到基于模型的强化学习中，通过拉格朗日方法在训练期间软平衡奖励与安全，同时安全层在推理阶段通过硬动作覆盖提升性能。

Abstract: Vision-driven autonomous river following by Unmanned Aerial Vehicles is
critical for applications such as rescue, surveillance, and environmental
monitoring, particularly in dense riverine environments where GPS signals are
unreliable. We formalize river following as a coverage control problem in which
the reward function is submodular, yielding diminishing returns as more unique
river segments are visited, thereby framing the task as a Submodular Markov
Decision Process. First, we introduce Marginal Gain Advantage Estimation, which
refines the reward advantage function by using a sliding window baseline
computed from historical episodic returns, thus aligning the advantage
estimation with the agent's evolving recognition of action value in
non-Markovian settings. Second, we develop a Semantic Dynamics Model based on
patchified water semantic masks that provides more interpretable and
data-efficient short-term prediction of future observations compared to latent
vision dynamics models. Third, we present the Constrained Actor Dynamics
Estimator architecture, which integrates the actor, the cost estimator, and SDM
for cost advantage estimation to form a model-based SafeRL framework capable of
solving partially observable Constrained Submodular Markov Decision Processes.
Simulation results demonstrate that MGAE achieves faster convergence and
superior performance over traditional critic-based methods like Generalized
Advantage Estimation. SDM provides more accurate short-term state predictions
that enable the cost estimator to better predict potential violations. Overall,
CADE effectively integrates safety regulation into model-based RL, with the
Lagrangian approach achieving the soft balance of reward and safety during
training, while the safety layer enhances performance during inference by hard
action overlay.

</details>


### [159] [Masquerade: Learning from In-the-wild Human Videos using Data-Editing](https://arxiv.org/abs/2508.09976)
*Marion Lepert,Jiaying Fang,Jeannette Bohg*

Main category: cs.RO

TL;DR: Masquerade方法通过编辑人类视频生成机器人化演示，显著提升了机器人策略的泛化能力，性能优于基线5-6倍。


<details>
  <summary>Details</summary>
Motivation: 机器人操作研究面临数据稀缺问题，即使最大的机器人数据集也比语言和视觉领域的数据集小得多且多样性不足。为解决这一问题，研究团队希望通过利用人类视频数据来弥补这一差距。

Method: Masquerade方法通过编辑野外人类视频，包括估计3D手部姿势、修复人类手臂以及叠加渲染的双臂机器人来跟踪恢复的末端执行器轨迹，从而将人类视频转化为机器人化演示。然后，通过预训练视觉编码器预测未来2D机器人关键点，并在少量机器人演示上微调扩散策略头来学习机器人策略。

Result: 在三个未见过的场景中评估的三个长期、双臂厨房任务上，Masquerade方法的性能优于基线5-6倍。消融实验表明，机器人覆盖和共同训练是不可或缺的，且性能与编辑后的人类视频数量呈对数关系。

Conclusion: 通过Masquerade方法，利用人类视频数据显著提升了机器人策略的泛化能力，证明了视觉表现差异的显式减少可以解锁大量可用的人类视频数据来改进机器人策略。

Abstract: Robot manipulation research still suffers from significant data scarcity:
even the largest robot datasets are orders of magnitude smaller and less
diverse than those that fueled recent breakthroughs in language and vision. We
introduce Masquerade, a method that edits in-the-wild egocentric human videos
to bridge the visual embodiment gap between humans and robots and then learns a
robot policy with these edited videos. Our pipeline turns each human video into
robotized demonstrations by (i) estimating 3-D hand poses, (ii) inpainting the
human arms, and (iii) overlaying a rendered bimanual robot that tracks the
recovered end-effector trajectories. Pre-training a visual encoder to predict
future 2-D robot keypoints on 675K frames of these edited clips, and continuing
that auxiliary loss while fine-tuning a diffusion policy head on only 50 robot
demonstrations per task, yields policies that generalize significantly better
than prior work. On three long-horizon, bimanual kitchen tasks evaluated in
three unseen scenes each, Masquerade outperforms baselines by 5-6x. Ablations
show that both the robot overlay and co-training are indispensable, and
performance scales logarithmically with the amount of edited human video. These
results demonstrate that explicitly closing the visual embodiment gap unlocks a
vast, readily available source of data from human videos that can be used to
improve robot policies.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [160] [A Limits Study of Memory-side Tiering Telemetry](https://arxiv.org/abs/2508.09351)
*Vinicius Petrucci,Felippe Zacarias,David Roberts*

Main category: cs.OS

TL;DR: 该论文提出了一种基于CXL的实验性内存请求记录器，用于实时揭示内存访问模式，并结合热监控单元（HMU）优化内存分层，结果显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 随着工作负载需求的增加和新兴技术的出现，计算系统中需要使用多种内存和存储层级。

Method: 通过结合基于数据地址监控的响应式放置、主动数据移动和编译器提示，内存模块中的热监控单元（HMU）可以显著改善内存分层解决方案。

Result: 对深度学习推荐模型（DLRM）的分析表明，与Linux NUMA平衡分层相比，潜在加速比为1.94倍，且与主机DRAM分配相比仅减慢3%，同时将超过90%的页面卸载到CXL内存。

Conclusion: 该研究强调了现有分层策略在覆盖范围和准确性方面的局限性，并提出了可编程的设备级遥测作为未来内存系统可扩展且高效的解决方案。

Abstract: Increasing workload demands and emerging technologies necessitate the use of
various memory and storage tiers in computing systems. This paper presents
results from a CXL-based Experimental Memory Request Logger that reveals
precise memory access patterns at runtime without interfering with the running
workloads. We use it for software emulation of future memory telemetry
hardware. By combining reactive placement based on data address monitoring,
proactive data movement, and compiler hints, a Hotness Monitoring Unit (HMU)
within memory modules can greatly improve memory tiering solutions. Analysis of
page placement using profiled access counts on a Deep Learning Recommendation
Model (DLRM) indicates a potential 1.94x speedup over Linux NUMA balancing
tiering, and only a 3% slowdown compared to Host-DRAM allocation while
offloading over 90% of pages to CXL memory. The study underscores the
limitations of existing tiering strategies in terms of coverage and accuracy,
and makes a strong case for programmable, device-level telemetry as a scalable
and efficient solution for future memory systems.

</details>


### [161] [Holistic Heterogeneous Scheduling for Autonomous Applications using Fine-grained, Multi-XPU Abstraction](https://arxiv.org/abs/2508.09503)
*Mingcong Han,Weihang Shen,Rong Chen,Binyu Zang,Haibo Chen*

Main category: cs.OS

TL;DR: XAUTO是一种运行时系统，通过细粒度多XPU编程抽象和调度策略，显著降低自主应用的端到端延迟。


<details>
  <summary>Details</summary>
Motivation: 现代自主应用日益依赖多异构处理器（XPU）加速算法模块的不同阶段，但现有运行时系统（如ROS）仅支持模块级任务管理，缺乏对多XPU细粒度使用的感知。

Method: XAUTO设计了细粒度的多XPU编程抽象XNODE，并与阶段级任务粒度对齐，支持多XPU实现。系统整体分配XPU并调度执行以最小化端到端延迟。

Result: 实验结果表明，XAUTO能将自动驾驶感知管道的端到端延迟降低1.61倍，优于当前最先进的模块级调度系统（ROS2）。

Conclusion: XAUTO通过细粒度的多XPU编程抽象XNODE和整体调度策略，显著降低了端到端延迟，为延迟敏感的自主应用提供了高效的运行时系统。

Abstract: Modern autonomous applications are increasingly utilizing multiple
heterogeneous processors (XPUs) to accelerate different stages of algorithm
modules. However, existing runtime systems for these applications, such as ROS,
can only perform module-level task management, lacking awareness of the
fine-grained usage of multiple XPUs. This paper presents XAUTO, a runtime
system designed to cooperatively manage XPUs for latency-sensitive autonomous
applications. The key idea is a fine-grained, multi-XPU programming abstraction
-- XNODE, which aligns with the stage-level task granularity and can
accommodate multiple XPU implementations. XAUTO holistically assigns XPUs to
XNODEs and schedules their execution to minimize end-to-end latency.
Experimental results show that XAUTO can reduce the end-to-end latency of a
perception pipeline for autonomous driving by 1.61x compared to a
state-of-the-art module-level scheduling system (ROS2).

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [162] [Verify Distributed Deep Learning Model Implementation Refinement with Iterative Relation Inference](https://arxiv.org/abs/2508.09505)
*Zhanghan Wang,Ding Ding,Hang Zhu,Haibin Lin,Aurojit Panda*

Main category: cs.DC

TL;DR: 提出了一种静态检查方法GraphGuard，通过迭代重写技术验证分布式模型与顺序模型的输出一致性，适用于大型模型如GPT和Llama-3，并能辅助错误定位。


<details>
  <summary>Details</summary>
Motivation: 由于大型模型需要跨多个GPU进行分布式训练和推理，程序员在将顺序模型转换为分布式模型时可能引入错误，导致输出不一致。

Method: 使用迭代重写技术来证明模型精炼（即检查分布式模型的输出是否能重构出顺序模型的输出），并在GraphGuard中实现。

Result: 该方法能够扩展到如GPT和Llama-3等大型模型，并提供可操作的输出以帮助定位错误。

Conclusion: GraphGuard的方法能够有效识别分布式机器学习模型中的错误，并通过可操作的输出来辅助错误定位，适用于当今的大型模型部署。

Abstract: Distributed machine learning training and inference is common today because
today's large models require more memory and compute than can be provided by a
single GPU. Distributed models are generally produced by programmers who take a
sequential model specification and apply several distribution strategies to
distribute state and computation across GPUs. Unfortunately, bugs can be
introduced in the process, and a distributed model implementation's outputs
might differ from the sequential model's outputs. In this paper, we describe an
approach to statically identify such bugs by checking model refinement, that
is, can the sequential model's outputs be reconstructed from the distributed
model's outputs? Our approach, implemented in GraphGuard, uses iterative
rewriting to prove model refinement. Our approach can scale to today's large
models and deployments: we evaluate it using GPT and Llama-3. Further, it
provides actionable output that aids in bug localization.

</details>


### [163] [HierMoE: Accelerating MoE Training with Hierarchical Token Deduplication and Expert Swap](https://arxiv.org/abs/2508.09591)
*Wenxiang Lin,Xinglin Pan,Lin Zhang,Shaohuai Shi,Xuan Wang,Xiaowen Chu*

Main category: cs.DC

TL;DR: HierMoE通过令牌去重和专家交换技术优化MoE模型训练，显著提升通信效率和训练速度。


<details>
  <summary>Details</summary>
Motivation: MoE模型中动态选择专家导致通信和负载不均衡，阻碍了分布式系统的扩展性。

Method: 提出了两种拓扑感知技术：令牌去重以减少通信流量，专家交换以平衡GPU间的负载。并构建理论模型以优化策略。

Result: 实验结果显示，HierMoE在通信和端到端训练速度上比现有系统快1.55×至3.32×和1.18×至1.27×。

Conclusion: HierMoE通过拓扑感知技术（令牌去重和专家交换）显著提升了MoE模型的训练效率，并在实验中展现出优于现有系统的性能。

Abstract: The sparsely activated mixture-of-experts (MoE) transformer has become a
common architecture for large language models (LLMs) due to its sparsity, which
requires fewer computational demands while easily scaling the model size. In
MoE models, each MoE layer requires to dynamically choose tokens to activate
particular experts for computation while the activated experts may not be
located in the same device or GPU as the token. However, this leads to
substantial communication and load imbalances across all GPUs, which obstructs
the scalability of distributed systems within a GPU cluster. To this end, we
introduce HierMoE to accelerate the training of MoE models by two
topology-aware techniques: 1) token deduplication to reduce the communication
traffic, and 2) expert swap to balance the workloads among all GPUs. To enable
the above two proposed approaches to be more general, we build theoretical
models aimed at achieving the best token duplication and expert swap strategy
under different model configurations and hardware environments. We implement
our prototype HierMoE system atop Megatron-LM and conduct experiments on a
32-GPU cluster with DeepSeek-V3 and Qwen3-30B-A3B models. Experimental results
show that our HierMoE achieves $1.55\times$ to $3.32\times$ faster
communication and delivers $1.18\times$ to $1.27\times$ faster end-to-end
training compared to state-of-the-art MoE training systems, Tutel-2DH,
SmartMoE, and Megatron-LM.

</details>


### [164] [Closing the HPC-Cloud Convergence Gap: Multi-Tenant Slingshot RDMA for Kubernetes](https://arxiv.org/abs/2508.09663)
*Philipp A. Friese,Ahmed Eleliemy,Utz-Uwe Haus,Martin Schulz*

Main category: cs.DC

TL;DR: 本文扩展了HPE Slingshot堆栈，使其支持Kubernetes上的HPC-Cloud融合部署，实现了安全、多租户的RDMA网络访问，性能开销低。


<details>
  <summary>Details</summary>
Motivation: HPC-Cloud融合计算是一种新兴的计算范式，需要平衡云原生工作负载的隔离需求和HPC应用的性能需求。Slingshot堆栈目前不适合多租户部署，因此需要改进以适应融合部署。

Method: 设计并实现了Slingshot堆栈的扩展，针对基于Kubernetes的融合部署，提供了容器粒度和多租户的RDMA网络访问能力。

Result: 扩展后的Slingshot堆栈在Kubernetes上实现了安全、容器粒度和多租户的RDMA网络访问，且性能开销极小。

Conclusion: 本文通过扩展Slingshot堆栈，成功实现了在Kubernetes基础上的HPC-Cloud融合部署，提供了安全、容器粒度和多租户的RDMA网络访问能力，且开销极小。

Abstract: Converged HPC-Cloud computing is an emerging computing paradigm that aims to
support increasingly complex and multi-tenant scientific workflows. These
systems require reconciliation of the isolation requirements of native cloud
workloads and the performance demands of HPC applications. In this context,
networking hardware is a critical boundary component: it is the conduit for
high-throughput, low-latency communication and enables isolation across
tenants. HPE Slingshot is a high-speed network interconnect that provides up to
200 Gbps of throughput per port and targets high-performance computing (HPC)
systems. The Slingshot host software, including hardware drivers and network
middleware libraries, is designed to meet HPC deployments, which predominantly
use single-tenant access modes. Hence, the Slingshot stack is not suited for
secure use in multi-tenant deployments, such as converged HPC-Cloud
deployments. In this paper, we design and implement an extension to the
Slingshot stack targeting converged deployments on the basis of Kubernetes. Our
integration provides secure, container-granular, and multi-tenant access to
Slingshot RDMA networking capabilities at minimal overhead.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [165] [An improved local search based algorithm for $k^-$-star partition](https://arxiv.org/abs/2508.09361)
*Mingyang Gong,Guohui Lin,Brendan Mumey*

Main category: cs.DS

TL;DR: 本文提出了一种改进的O(|V|^3)时间复杂度的近似算法，用于解决k^-星划分问题，其近似比为( k/2 - (k-2)/(8k-14) )。


<details>
  <summary>Details</summary>
Motivation: 研究k^-星划分问题，旨在找到一个最小的顶点不相交的星集合，每个星最多有k个顶点，以覆盖简单无向图G = (V, E)中的所有顶点。

Method: 算法从具有最少1-星的k^-星划分开始，通过区分关键顶点（每个关键顶点要么在2-星中，要么是当前解中3-星的中心），并迭代地通过三种局部搜索操作更新解。

Result: 提出的算法在O(|V|^3)时间内实现了( k/2 - (k-2)/(8k-14) )的近似比。

Conclusion: 本文提出了一种改进的O(|V|^3)时间复杂度的近似算法，用于解决k^-星划分问题，其近似比为( k/2 - (k-2)/(8k-14) )。

Abstract: We study the $k^-$-star partition problem that aims to find a minimum
collection of vertex-disjoint stars, each having at most $k$ vertices to cover
all vertices in a simple undirected graph $G = (V, E)$. Our main contribution
is an improved $O(|V|^3)$-time $(\frac k2 - \frac {k-2}{8k-14})$-approximation
algorithm.
  Our algorithm starts with a $k^-$-star partition with the least $1$-stars and
a key idea is to distinguish critical vertices, each of which is either in a
$2$-star or is the center of a $3$-star in the current solution. Our algorithm
iteratively updates the solution by three local search operations so that the
vertices in each star in the final solution produced cannot be adjacent to too
many critical vertices. We present an amortization scheme to prove the
approximation ratio in which the critical vertices are allowed to receive more
tokens from the optimal solution.

</details>


### [166] [A Classical Quadratic Speedup for Planted $k$XOR](https://arxiv.org/abs/2508.09422)
*Meghal Gupta,William He,Ryan O'Donnell,Noah G. Singer*

Main category: cs.DS

TL;DR: 新经典算法在大常数k下比之前快二次方，减少量子加速优势至二次方。


<details>
  <summary>Details</summary>
Motivation: Schmidhuber等人展示了量子算法在噪声植入kXOR问题上比所有已知经典算法快四次方。本研究旨在设计一种新的经典算法，在大常数k情况下比之前最佳算法快二次方，从而减少量子加速的优势。

Method: 结合了亚线性时间算法（主要是生日悖论）和多项式反集中工具。

Result: 新算法在大常数k情况下比之前最佳经典算法快二次方，且在半随机情况下也有效。

Conclusion: 对于大常数k，新设计的经典算法比之前的最佳算法快二次方，使得量子加速仅保持二次方优势（但仍具有空间优势）。

Abstract: A recent work of Schmidhuber et al (QIP, SODA, & Phys. Rev. X 2025) exhibited
a quantum algorithm for the noisy planted $k$XOR problem running quartically
faster than all known classical algorithms. In this work, we design a new
classical algorithm that is quadratically faster than the best previous one, in
the case of large constant $k$. Thus for such $k$, the quantum speedup of
Schmidhuber et al. becomes only quadratic (though it retains a space
advantage). Our algorithm, which also works in the semirandom case, combines
tools from sublinear-time algorithms (essentially, the birthday paradox) and
polynomial anticoncentration.

</details>


### [167] [Retroactive Monotonic Priority Queues via Range Searching](https://arxiv.org/abs/2508.09892)
*Lucas Castro,Rosiane de Freitas*

Main category: cs.DS

TL;DR: 本文通过将单调优先级队列的最小值查找问题转化为范围搜索问题，设计了一种操作时间为$O(\log m \log \log m)$的完全可回溯单调优先级队列，优于现有最佳结果。


<details>
  <summary>Details</summary>
Motivation: 完全可回溯优先级队列的操作时间（$O(\log^2 m \log \log m)$）显著高于非回溯和部分可回溯优先级队列（$O(\log m)$）。本文旨在探索是否能在完全可回溯单调优先级队列中实现$O(\log m)$的时间复杂度。

Method: 通过将单调优先级队列中的最小值查找问题转化为范围搜索问题，并利用特定的范围搜索数据结构，实现了操作时间为$O(\log m + T(m))$的完全可回溯单调优先级队列。

Result: 成功设计了一种操作时间为$O(\log m \log \log m)$的完全可回溯单调优先级队列，显著提升了性能。

Conclusion: 本文设计了一种完全可回溯的单调优先级队列，其操作时间为$O(\log m \log \log m)$，优于现有最佳完全可回溯优先级队列的$O(\log^2 m \log \log m)$时间。

Abstract: The best known fully retroactive priority queue costs $O(\log^2 m \log \log
m)$ time per operation, where $m$ is the number of operations performed on the
data structure. In contrast, standard (non-retroactive) and partially
retroactive priority queues cost $O(\log m)$ time per operation. So far, it is
unknown whether this $O(\log m)$ bound can be achieved for fully retroactive
priority queues.
  In this work, we study a restricted variant of priority queues known as
monotonic priority queues. We show that finding the minimum in a retroactive
monotonic priority queue is a special case of the range-searching problem. We
design a fully retroactive monotonic priority queue with a cost of $O(\log m +
T(m))$ time per operation, where $T(m)$ is the maximum between the query and
the update time of a specific range-searching data structure with $m$ elements.
Finally, we design a fully retroactive monotonic priority queue that costs
$O(\log m \log \log m)$ time per operation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [168] [Teaching Code Refactoring Using LLMs](https://arxiv.org/abs/2508.09332)
*Anshul Khairnar,Aarya Rajoju,Edward F. Gehringer*

Main category: cs.SE

TL;DR: LLM通过实时、上下文感知的反馈增强软件工程课程中的代码重构教学，实验表明其能有效连接理论与实践的桥梁。


<details>
  <summary>Details</summary>
Motivation: 重构虽然能提升代码质量，但在复杂、真实的代码库中难以教授，传统方法（如代码审查和静态分析工具）提供的反馈有限且不一致。

Method: 将LLM辅助的重构集成到课程项目中，使用结构化提示帮助学生识别和解决代码异味（如长方法和低内聚）。

Result: 通过学生反馈和代码质量改进的预期分析，发现LLM辅助重构能有效提升教学效果。

Conclusion: LLMs能够有效连接理论与实践的桥梁，支持学生对可维护性和重构原则的深入理解。

Abstract: This Innovative Practice full paper explores how Large Language Models (LLMs)
can enhance the teaching of code refactoring in software engineering courses
through real-time, context-aware feedback. Refactoring improves code quality
but is difficult to teach, especially with complex, real-world codebases.
Traditional methods like code reviews and static analysis tools offer limited,
inconsistent feedback. Our approach integrates LLM-assisted refactoring into a
course project using structured prompts to help students identify and address
code smells such as long methods and low cohesion. Implemented in Spring 2025
in a long-lived OSS project, the intervention is evaluated through student
feedback and planned analysis of code quality improvements. Findings suggest
that LLMs can bridge theoretical and practical learning, supporting a deeper
understanding of maintainability and refactoring principles.

</details>


### [169] [Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser](https://arxiv.org/abs/2508.09366)
*Qiaolin Qin,Xingfang Wu,Heng Li,Ettore Merlo*

Main category: cs.SE

TL;DR: PIPLUP是一种新型高效的统计日志解析器，超越现有统计方法，媲美语义解析器，同时保持低成本和隐私优势。


<details>
  <summary>Details</summary>
Motivation: 挑战了“基于统计的解析器无法与基于语义的解析器相媲美”的普遍观点，旨在开发一种既高效又准确的统计解析器。

Method: PIPLUP通过消除对常量令牌位置的预设依赖，并采用数据不敏感参数来提升通用性，实现“即插即用”的日志文件解析。

Result: 在大型开源日志数据集上的实验表明，PIPLUP在准确性和通用性上表现优异，且无需GPU加速或外部API，时间消耗低。

Conclusion: PIPLUP是一种新型的基于统计的日志解析器，不仅超越了现有基于统计的方法（如Drain及其变体），还在无监督语义解析器（如LUNAR）中表现出竞争力，同时保持了高效和隐私保护的优势。

Abstract: Log parsing is an essential task in log analysis, and many tools have been
designed to accomplish it. Existing log parsers can be categorized into
statistic-based and semantic-based approaches. In comparison to semantic-based
parsers, existing statistic-based parsers tend to be more efficient, require
lower computational costs, and be more privacy-preserving thanks to on-premise
deployment, but often fall short in their accuracy (e.g., grouping or parsing
accuracy) and generalizability. Therefore, it became a common belief that
statistic-based parsers cannot be as effective as semantic-based parsers since
the latter could take advantage of external knowledge supported by pretrained
language models. Our work, however, challenges this belief with a novel
statistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the
position of constant tokens for log grouping and relies on data-insensitive
parameters to overcome the generalizability challenge, allowing "plug and play"
on given log files. According to our experiments on an open-sourced large log
dataset, PIPLUP shows promising accuracy and generalizability with the
data-insensitive default parameter set. PIPLUP not only outperforms the
state-of-the-art statistic-based log parsers, Drain and its variants, but also
obtains a competitive performance compared to the best unsupervised
semantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time
consumption without GPU acceleration and external API usage; our simple,
efficient, and effective approach makes it more practical in real-world
adoptions, especially when costs and privacy are of major concerns.

</details>


### [170] [Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion](https://arxiv.org/abs/2508.09537)
*Yanzhou Li,Tianlin Li,Yiran Zhang,Shangqing Liu,Aishan Liu,Yang Liu*

Main category: cs.SE

TL;DR: 论文提出三阶段方法（意图推断、交互式细化、功能生成）提升LLM在无注释代码库中的表现，实验显示超过20%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决现实代码库中因缺乏显式注释（如文档字符串）导致LLM性能大幅下降的问题。

Method: 论文将任务分为三个阶段：意图推断、交互式细化和功能生成。通过设计基于推理的提示框架和可选交互机制，结合40,000个标注数据集的训练，优化LLM的性能。

Result: 在DevEval和ComplexCodeEval上的实验表明，该方法显著提升了LLM的参考和执行指标，交互式细化阶段进一步增强了效果。

Conclusion: 该论文提出的三阶段方法显著提升了大型语言模型在无注释代码库中的功能补全能力，特别是在意图推断和交互式细化方面取得了超过20%的相对增益。

Abstract: Large Language Models (LLMs) are increasingly used for function completion in
repository-scale codebases. Prior studies demonstrate that when explicit
instructions--such as docstrings--are provided, these models can generate
highly accurate implementations. However, in real-world repositories, such
annotations are frequently absent, and performance drops substantially without
them. To address this gap, we frame the task as a three-stage process. The
first stage focuses on intent inference, where the model analyzes the code
preceding the target function to uncover cues about the desired functionality.
Such preceding context often encodes subtle but critical information, and we
design a reasoning-based prompting framework to guide the LLM through
step-by-step extraction and synthesis of these signals before any code is
generated. The second stage introduces an optional interactive refinement
mechanism to handle cases where preceding context alone is insufficient for
intent recovery. In this stage, the model proposes a small set of candidate
intentions, enabling the developer to select or edit them so that the inferred
intent closely matches the actual requirement. Finally, in the third stage, the
LLM generates the target function conditioned on the finalized intent. To
support this pipeline, we curate a dataset of 40,000 examples annotated with
intermediate reasoning traces and corresponding docstrings. Extensive
experiments on DevEval and ComplexCodeEval show that our approach consistently
boosts multiple LLMs, achieving over 20\% relative gains in both
reference-based and execution-based metrics, with the interactive refinement
stage delivering additional improvements beyond these gains.

</details>


### [171] [ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation](https://arxiv.org/abs/2508.09648)
*Taohong Zhu,Lucas C. Cordeiro,Youcheng Sun*

Main category: cs.SE

TL;DR: ReqInOne是一种基于LLM的模块化代理，通过分解SRS生成任务并优化提示模板，显著提升了文档质量和一致性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手动编写SRS文档耗时且易产生歧义，现有自动化方法依赖人工分析，而基于LLM的方法存在幻觉和可控性不足的问题。

Method: 采用模块化架构，将SRS生成分解为摘要、需求提取和需求分类三个任务，每个任务使用定制化提示模板优化LLM输出。

Result: ReqInOne生成的SRS文档在准确性和结构上优于基于GPT-4的整体方法及初级需求工程师的成果，其需求分类组件性能达到或超过现有最佳模型。

Conclusion: ReqInOne通过模块化设计和定制化提示模板，显著提升了SRS文档的质量和一致性，其性能优于现有方法和初级需求工程师。

Abstract: Software Requirements Specification (SRS) is one of the most important
documents in software projects, but writing it manually is time-consuming and
often leads to ambiguity. Existing automated methods rely heavily on manual
analysis, while recent Large Language Model (LLM)-based approaches suffer from
hallucinations and limited controllability. In this paper, we propose ReqInOne,
an LLM-based agent that follows the common steps taken by human requirements
engineers when writing an SRS to convert natural language into a structured
SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into
three tasks: summary, requirement extraction, and requirement classification,
each supported by tailored prompt templates to improve the quality and
consistency of LLM outputs.
  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the
generated SRSs against those produced by the holistic GPT-4-based method from
prior work as well as by entry-level requirements engineers. Expert evaluations
show that ReqInOne produces more accurate and well-structured SRS documents.
The performance advantage of ReqInOne benefits from its modular design, and
experimental results further demonstrate that its requirement classification
component achieves comparable or even better results than the state-of-the-art
requirement classification model.

</details>


### [172] [DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity](https://arxiv.org/abs/2508.09676)
*Vishal Khare,Vijay Saini,Deepak Sharma,Anand Kumar,Ankit Rana,Anshul Yadav*

Main category: cs.SE

TL;DR: DeputyDev是一款AI代码审查助手，通过自动化审查显著提升效率，实验证明可减少23.09%的PR审查时间和40.13%的每行代码审查时间。


<details>
  <summary>Details</summary>
Motivation: 传统代码审查效率低下，存在耗时长、反馈不一致等问题，影响了开发流程和代码质量。

Method: 通过双盲对照A/B实验，对200多名工程师进行测试，评估DeputyDev对审查时间的影响。

Result: DeputyDev显著减少了每次PR审查时间（23.09%）和每行代码审查时间（40.13%）。

Conclusion: DeputyDev作为AI代码审查助手显著提升了代码审查效率，不仅缩短了审查时间，还被成功推广为SaaS解决方案，广泛应用于企业内部及外部公司。

Abstract: This study investigates the implementation and efficacy of DeputyDev, an
AI-powered code review assistant developed to address inefficiencies in the
software development process. The process of code review is highly inefficient
for several reasons, such as it being a time-consuming process, inconsistent
feedback, and review quality not being at par most of the time. Using our
telemetry data, we observed that at TATA 1mg, pull request (PR) processing
exhibits significant inefficiencies, with average pick-up and review times of
73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review
cycle was marked by prolonged iterative communication between the reviewing and
submitting parties. Research from the University of California, Irvine
indicates that interruptions can lead to an average of 23 minutes of lost
focus, critically affecting code quality and timely delivery. To address these
challenges, we developed DeputyDev's PR review capabilities by providing
automated, contextual code reviews. We conducted a rigorous double-controlled
A/B experiment involving over 200 engineers to evaluate DeputyDev's impact on
review times. The results demonstrated a statistically significant reduction in
both average per PR (23.09%) and average per-line-of-code (40.13%) review
durations. After implementing safeguards to exclude outliers, DeputyDev has
been effectively rolled out across the entire organisation. Additionally, it
has been made available to external companies as a Software-as-a-Service (SaaS)
solution, currently supporting the daily work of numerous engineering
professionals. This study explores the implementation and effectiveness of
AI-assisted code reviews in improving development workflow timelines and code.

</details>


### [173] [Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering](https://arxiv.org/abs/2508.09680)
*Orvila Sarker,Mona Jamshaid,M. Ali Babar*

Main category: cs.SE

TL;DR: 研究综述了自闭症个体在软件工程领域的优势与障碍，提出18个成功因素，为促进包容性提供建议。


<details>
  <summary>Details</summary>
Motivation: 自闭症个体在ICT领域具有独特优势，但在软件工程角色中面临多重障碍。研究旨在综合从软件工程教育到可持续职场包容的全路径知识。

Method: 通过系统综述分析了30项研究。

Result: 识别出18个成功因素，分为四大主题类别：软件工程教育、职业与就业培训、工作环境、工具与辅助技术。

Conclusion: 该研究通过系统综述提出了四大主题类别的18个成功因素，为教育机构、雇主、组织和工具开发者提供了基于证据的建议，以促进自闭症个体在软件工程领域的包容性。

Abstract: Research has highlighted the valuable contributions of autistic individuals
in the Information and Communication Technology (ICT) sector, particularly in
areas such as software development, testing, and cybersecurity. Their strengths
in information processing, attention to detail, innovative thinking, and
commitment to high-quality outcomes in the ICT domain are well-documented.
However, despite their potential, autistic individuals often face barriers in
Software Engineering (SE) roles due to a lack of personalised tools, complex
work environments, non-inclusive recruitment practices, limited co-worker
support, challenging social dynamics and so on. Motivated by the ethical
framework of the neurodiversity movement and the success of pioneering
initiatives like the Dandelion program, corporate Diversity, Equity, and
Inclusion (DEI) in the ICT sector has increasingly focused on autistic talent.
This movement fundamentally reframes challenges not as individual deficits but
as failures of environments designed for a neurotypical majority. Despite this
progress, there is no synthesis of knowledge reporting the full pathway from
software engineering education through to sustainable workplace inclusion. To
address this, we conducted a Systematic Review of 30 studies and identified 18
success factors grouped into four thematic categories: (1) Software Engineering
Education, (2) Career and Employment Training, (3) Work Environment, and (4)
Tools and Assistive Technologies. Our findings offer evidence-based
recommendations for educational institutions, employers, organisations, and
tool developers to enhance the inclusion of autistic individuals in SE. These
include strategies for inclusive meeting and collaboration practices,
accessible and structured work environments, clear role and responsibility
definitions, and the provision of tailored workplace accommodations.

</details>


### [174] [LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations](https://arxiv.org/abs/2508.09791)
*Junxiao Han,Yarong Wang,Xiaodong Gu,Cuiyun Gao,Yao Wan,Song Han,David Lo,Shuiguang Deng*

Main category: cs.SE

TL;DR: LibRec结合LLMs和RAG技术，自动化库迁移推荐，并通过LibEval验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决库迁移推荐任务中的自动化需求，提高推荐准确性。

Method: 提出LibRec框架，结合LLMs和RAG技术，利用上下文学习从提交消息中提取迁移意图，并引入LibEval基准进行评估。

Result: 在LibEval基准上评估了10种流行LLMs，进行了消融研究、提示策略分析、意图类型影响评估和失败案例分析。

Conclusion: LibRec框架通过结合LLMs和RAG技术，成功自动化了库迁移推荐任务，并通过LibEval基准验证了其有效性。

Abstract: In this paper, we propose LibRec, a novel framework that integrates the
capabilities of LLMs with retrieval-augmented generation(RAG) techniques to
automate the recommendation of alternative libraries. The framework further
employs in-context learning to extract migration intents from commit messages
to enhance the accuracy of its recommendations. To evaluate the effectiveness
of LibRec, we introduce LibEval, a benchmark designed to assess the performance
in the library migration recommendation task. LibEval comprises 2,888 migration
records associated with 2,368 libraries extracted from 2,324 Python
repositories. Each migration record captures source-target library pairs, along
with their corresponding migration intents and intent types. Based on LibEval,
we evaluated the effectiveness of ten popular LLMs within our framework,
conducted an ablation study to examine the contributions of key components
within our framework, explored the impact of various prompt strategies on the
framework's performance, assessed its effectiveness across various intent
types, and performed detailed failure case analyses.

</details>


### [175] [Fast and Accurate Heuristics for Bus-Factor Estimation](https://arxiv.org/abs/2508.09828)
*Sebastiano Antonio Piccolo*

Main category: cs.SE

TL;DR: 提出两种基于图剥离的启发式方法，显著提升bus-factor计算的准确性和可扩展性，适用于大规模软件系统。


<details>
  <summary>Details</summary>
Motivation: 准确计算bus-factor在现有形式化下是NP-Hard问题，导致大规模软件系统的可扩展分析不可行。

Method: 将软件项目建模为开发者和任务的双边图，提出了两种新颖的近似启发式方法：Minimum Coverage和Maximum Coverage，基于迭代图剥离。

Result: 在超过1000个合成的幂律图上进行了全面实证评估，证明启发式方法在数百万节点和边的图上几分钟内即可完成，且估计更紧、对结构变化更鲁棒。

Conclusion: 论文提出两种基于迭代图剥离的启发式方法（Minimum Coverage和Maximum Coverage），显著优于广泛采用的基于度的启发式方法，并证明了其在大规模软件系统中的可扩展性和准确性。

Abstract: The bus-factor is a critical risk indicator that quantifies how many key
contributors a project can afford to lose before core knowledge or
functionality is compromised. Despite its practical importance, accurately
computing the bus-factor is NP-Hard under established formalizations, making
scalable analysis infeasible for large software systems.
  In this paper, we model software projects as bipartite graphs of developers
and tasks and propose two novel approximation heuristics, Minimum Coverage and
Maximum Coverage, based on iterative graph peeling, for two influential
bus-factor formalizations. Our methods significantly outperform the widely
adopted degree-based heuristic, which we show can yield severely inflated
estimates.
  We conduct a comprehensive empirical evaluation on over $1\,000$ synthetic
power-law graphs and demonstrate that our heuristics provide tighter estimates
while scaling to graphs with millions of nodes and edges in minutes. Our
results reveal that the proposed heuristics are not only more accurate but also
robust to structural variations in developer-task assignment graph. We release
our implementation as open-source software to support future research and
practical adoption.

</details>


### [176] [Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification](https://arxiv.org/abs/2508.09832)
*Linh Nguyen,Chunhua Liu,Hong Yi Lin,Patanamon Thongtanunam*

Main category: cs.SE

TL;DR: LLMs在代码审查评论分类中优于传统深度学习方法，尤其是在样本不足的类别上，提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化代码审查评论分类方法主要依赖监督学习，需要大量手动标注数据，存在局限性。

Method: 探索使用大型语言模型（LLMs）对17类代码审查评论进行分类，并评估其性能。

Result: LLMs在代码审查评论分类上表现优于现有的深度学习方法，尤其在训练样本不足的类别上表现更佳。

Conclusion: 大型语言模型（LLMs）为代码审查分析提供了可扩展的解决方案，能够提升代码审查过程的效率。

Abstract: Code review is a crucial practice in software development. As code review
nowadays is lightweight, various issues can be identified, and sometimes, they
can be trivial. Research has investigated automated approaches to classify
review comments to gauge the effectiveness of code reviews. However, previous
studies have primarily relied on supervised machine learning, which requires
extensive manual annotation to train the models effectively. To address this
limitation, we explore the potential of using Large Language Models (LLMs) to
classify code review comments. We assess the performance of LLMs to classify 17
categories of code review comments. Our results show that LLMs can classify
code review comments, outperforming the state-of-the-art approach using a
trained deep learning model. In particular, LLMs achieve better accuracy in
classifying the five most useful categories, which the state-of-the-art
approach struggles with due to low training examples. Rather than relying
solely on a specific small training data distribution, our results show that
LLMs provide balanced performance across high- and low-frequency categories.
These results suggest that the LLMs could offer a scalable solution for code
review analytics to improve the effectiveness of the code review process.

</details>


### [177] [An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues](https://arxiv.org/abs/2508.09875)
*Jinbao Chen,Boyao Ding,Yu Zhang,Qingwei Li,Fugen Tang*

Main category: cs.SE

TL;DR: 研究分析了Go项目中CGO的使用情况，揭示了其分布、模式、目的及关键问题，并提出了临时解决方案和工具链改进提案。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注Python和Java的FFI，而忽略了Go中新兴的CGO，其独特风险尚未充分研究。

Method: 开发了CGOAnalyzer工具，对920个开源Go项目中的CGO使用情况进行实证研究，揭示了分布、模式、目的及关键问题。

Result: (1) 11.3%的Go项目使用CGO，集中在少数项目；(2) CGO主要用于系统级交互和性能优化等4个目的，共15种使用模式；(3) 发现19类CGO相关问题，包括一个可能导致运行时崩溃的关键问题；(4) 提出临时解决方案减少不必要的指针检查；(5) 提交了改进Go工具链的提案，已被接受并计划未来解决。

Conclusion: 研究为开发者和Go团队提供了宝贵见解，提升了开发效率和可靠性，同时增强了Go工具链的鲁棒性。

Abstract: Multilingual software development integrates multiple languages into a single
application, with the Foreign Function Interface (FFI) enabling seamless
interaction. While FFI boosts efficiency and extensibility, it also introduces
risks. Existing studies focus on FFIs in languages like Python and Java,
neglecting CGO, the emerging FFI in Go, which poses unique risks.
  To address these concerns, we conduct an empirical study of CGO usage across
920 open-source Go projects. Our study aims to reveal the distribution,
patterns, purposes, and critical issues associated with CGO, offering insights
for developers and the Go team. We develop CGOAnalyzer, a tool to efficiently
identify and quantify CGO-related features. Our findings reveal that: (1) 11.3%
of analyzed Go projects utilize CGO, with usage concentrated in a subset of
projects; (2) CGO serves 4 primary purposes, including system-level
interactions and performance optimizations, with 15 distinct usage patterns
observed; (3) 19 types of CGO-related issues exist, including one critical
issue involving unnecessary pointer checks that pose risks of runtime crashes
due to limitations in the current Go compilation toolchain; (4) a temporary
solution reduces unnecessary pointer checks, mitigating crash risks, and (5) we
submitted a proposal to improve the Go toolchain for a permanent fix, which has
been grouped within an accepted proposal for future resolution. Our findings
provide valuable insights for developers and the Go team, enhancing development
efficiency and reliability while improving the robustness of the Go toolchain.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [178] [Agentic TinyML for Intent-aware Handover in 6G Wireless Networks](https://arxiv.org/abs/2508.09147)
*Alaa Saleh,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.NI

TL;DR: WAAN是一个6G网络中的跨层框架，通过TinyML代理实现主动切换，提升移动边缘计算场景下的用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统反应式切换机制在移动边缘计算和自主代理服务场景中存在局限性。

Method: WAAN是一个跨层框架，通过嵌入轻量级TinyML代理作为自主、可协商的实体，实现意图感知和主动切换。

Result: WAAN通过半稳定集合点确保移动性中断的连续性，并在多模态环境控制案例中展示了其有效性。

Conclusion: 本文讨论了WAAN框架在6G网络中的部署和未来发展所面临的关键挑战与机遇。

Abstract: As 6G networks evolve into increasingly AI-driven, user-centric ecosystems,
traditional reactive handover mechanisms demonstrate limitations, especially in
mobile edge computing and autonomous agent-based service scenarios. This
manuscript introduces WAAN, a cross-layer framework that enables intent-aware
and proactive handovers by embedding lightweight TinyML agents as autonomous,
negotiation-capable entities across heterogeneous edge nodes that contribute to
intent propagation and network adaptation. To ensure continuity across
mobility-induced disruptions, WAAN incorporates semi-stable rendezvous points
that serve as coordination anchors for context transfer and state preservation.
The framework's operational capabilities are demonstrated through a multimodal
environmental control case study, highlighting its effectiveness in maintaining
user experience under mobility. Finally, the article discusses key challenges
and future opportunities associated with the deployment and evolution of WAAN.

</details>


### [179] [Semantic-Aware LLM Orchestration for Proactive Resource Management in Predictive Digital Twin Vehicular Networks](https://arxiv.org/abs/2508.09149)
*Seyed Hossein Ahmadpanah*

Main category: cs.NI

TL;DR: SP-LLM框架利用预测性数字孪生和LLM，实现了车载网络中任务卸载和资源分配的主动决策，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前车载边缘计算（VEC）的管理系统基本上是固定的和反应式的，在极端动态的车载环境中表现不佳。本文旨在解决这些问题。

Method: 本文提出了一种新颖的语义感知主动LLM编排（SP-LLM）框架，将传统的数字孪生（DT）转变为预测性数字孪生（pDT），并利用大型语言模型（LLM）作为认知编排器，做出前瞻性的任务卸载和资源分配决策。

Result: 通过广泛的仿真，SP-LLM在可扩展性、波动条件下的鲁棒性和适应性方面显著优于最先进的反应式和基于MARL的方法。

Conclusion: SP-LLM框架通过将人类意图转化为最优网络行为，为更智能、自主和目标驱动的车载网络提供了可能。

Abstract: Next-generation automotive applications require vehicular edge computing
(VEC), but current management systems are essentially fixed and reactive. They
are suboptimal in extremely dynamic vehicular environments because they are
constrained to static optimization objectives and base their decisions on the
current network states. This paper presents a novel Semantic-Aware Proactive
LLM Orchestration (SP-LLM) framework to address these issues. Our method
transforms the traditional Digital Twin (DT) into a Predictive Digital Twin
(pDT) that predicts important network parameters such as task arrivals, vehicle
mobility, and channel quality. A Large Language Model (LLM) that serves as a
cognitive orchestrator is at the heart of our framework. It makes proactive,
forward-looking decisions about task offloading and resource allocation by
utilizing the pDT's forecasts. The LLM's ability to decipher high-level
semantic commands given in natural language is crucial because it enables it to
dynamically modify its optimization policy to match evolving strategic
objectives, like giving emergency services priority or optimizing energy
efficiency. We show through extensive simulations that SP-LLM performs
significantly better in terms of scalability, robustness in volatile
conditions, and adaptability than state-of-the-art reactive and MARL-based
approaches. More intelligent, autonomous, and goal-driven vehicular networks
will be possible due to our framework's outstanding capacity to convert human
intent into optimal network behavior.

</details>


### [180] [Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference](https://arxiv.org/abs/2508.09229)
*Danil Sivtsov,Aleksandr Katrutsa,Ivan Oseledets*

Main category: cs.NI

TL;DR: Proposes an ILP-based strategy for efficient, topology-aware placement of MoE LLMs, reducing network traffic.


<details>
  <summary>Details</summary>
Motivation: Efficient deployment of pre-trained MoE LLMs requires addressing imbalanced expert loads and network topology considerations during inference.

Method: Proposes an integer linear program (ILP) to determine the optimal placement of experts, minimizing expected transmissions.

Result: ILP-based placement outperforms competitors in reducing network traffic.

Conclusion: ILP-based placement strategy effectively reduces network traffic for both small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) MoE LLMs.

Abstract: Efficient deployment of a pre-trained LLM to a cluster with multiple servers
is a critical step for providing fast responses to users' queries. The recent
success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy
them efficiently, considering their underlying structure. During the inference
in MoE LLMs, only a small part of the experts is selected to process a given
token. Moreover, in practice, the experts' load is highly imbalanced. For
efficient deployment, one has to distribute the model across a large number of
servers using a model placement algorithm. Thus, to improve cluster
utilization, the model placement algorithm has to take into account the network
topology. This work focuses on the efficient topology-aware placement of the
pre-trained MoE LLMs in the inference stage. We propose an integer linear
program (ILP) that determines the optimal placement of experts, minimizing the
expected number of transmissions. Due to the internal structure, this
optimization problem can be solved with a standard ILP solver. We demonstrate
that ILP-based placement strategy yields lower network traffic than competitors
for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.

</details>


### [181] [Enabling On-demand Guaranteed QoS for Real Time Video Streaming from Vehicles in 5G Advanced with CAPIF & NEF APIs](https://arxiv.org/abs/2508.09150)
*Pietro Piscione,Leonardo Lossi,Maziar Nekovee,Chathura Galkandage,Phil O Connor,Simon Davies*

Main category: cs.NI

TL;DR: 该论文通过CAPIF集成5G网络功能，动态调整QoS并重定向流量至边缘，优化车联网连接性能。


<details>
  <summary>Details</summary>
Motivation: 提升车联网应用的连接性能，通过动态适应网络条件和优化资源利用来满足低延迟需求。

Method: 利用标准的3GPP网络暴露功能（NEF）API，通过CAPIF实现动态QoS调整和流量重定向至边缘节点。

Result: PoC验证了动态QoS调整和边缘流量重定向的有效性，显著降低了延迟并优化了网络资源利用率。

Conclusion: 该论文通过概念验证（PoC）展示了5G高级网络功能与通用API框架（CAPIF）的集成，成功实现了对移动网络性能的持续监控及动态QoS调整，优化了车联网应用的连接性能。

Abstract: This paper presents the design and implementation of a Proof of Concept (PoC)
that demonstrates how 5G Advanced Network Functions can be integrated with the
Common API Framework (CAPIF) to support enhanced connectivity for automotive
applications. The PoC shows the continuous monitoring of the mobile network
performance and the on-demand and dynamic adaptation of Quality of Service
(QoS) for selected 5G User Equipment (UE) video streaming traffic flows using
standard 3GPP Network Exposure Function (NEF) APIs exposed via CAPIF. Moreover,
traffic flows are redirected to the edge to improve latency and optimize
network resource utilization.

</details>


### [182] [Physiological Signal-Driven QoE Optimization for Wireless Virtual Reality Transmission](https://arxiv.org/abs/2508.09151)
*Chang Wu,Yuang Chen,Yiyuan Chen,Fengqian Guo,Xiaowei Qin,Hancheng Lu*

Main category: cs.NI

TL;DR: 该论文提出了一种基于生理信号的QoE优化框架，通过DRL动态调整VR流媒体分辨率，显著提升用户体验并减少分辨率突变。


<details>
  <summary>Details</summary>
Motivation: 解决现有QoE模型和传输方案在VR流媒体中分辨率突变对用户体验的感知影响不足的问题。

Method: 提出了一种基于生理信号（EEG、ECG和皮肤活动信号）的QoE建模框架，并结合深度强化学习（DRL）实现动态无线资源分配和帧分辨率调整。

Result: 实验结果显示，该方法在分辨率提升和切换减少方面分别实现了88.7%和81.0%的改进。

Conclusion: 该研究通过创新的生理信号驱动的QoE建模和优化框架，显著提升了VR流媒体中的用户体验，减少了分辨率突变对QoE的负面影响，并在实验中验证了其有效性。

Abstract: Abrupt resolution changes in virtual reality (VR) streaming can significantly
impair the quality-of-experience (QoE) of users, particularly during
transitions from high to low resolutions. Existing QoE models and transmission
schemes inadequately address the perceptual impact of these shifts. To bridge
this gap, this article proposes, for the first time, an innovative
physiological signal-driven QoE modeling and optimization framework that fully
leverages users' electroencephalogram (EEG), electrocardiogram (ECG), and skin
activity signals. This framework precisely captures the temporal dynamics of
physiological responses and resolution changes in VR streaming, enabling
accurate quantification of resolution upgrades' benefits and downgrades'
impacts. Integrated the proposed QoE framework into the radio access network
(RAN) via a deep reinforcement learning (DRL) framework, adaptive transmission
strategies have been implemented to allocate radio resources dynamically, which
mitigates short-term channel fluctuations and adjusts frame resolution in
response to channel variations caused by user mobility. By prioritizing
long-term resolution while minimizing abrupt transitions, the proposed solution
achieves an 88.7\% improvement in resolution and an 81.0\% reduction in
handover over the baseline. Experimental results demonstrate the effectiveness
of this physiological signal-driven strategy, underscoring the promise of edge
AI in immersive media services.

</details>


### [183] [5G Core Fault Detection and Root Cause Analysis using Machine Learning and Generative AI](https://arxiv.org/abs/2508.09152)
*Joseph H. R. Isaac,Harish Saradagam,Nallamothu Pardhasaradhi*

Main category: cs.NI

TL;DR: 论文提出AI驱动的故障分析引擎，利用NLP和生成式AI自动分类5G核心网流量中的故障，显著减少人工干预并提高效率。


<details>
  <summary>Details</summary>
Motivation: 当前5G核心网流量分析依赖大量人工，效率低下。论文旨在通过AI/ML技术自动化故障分类和修复建议，提升网络性能。

Method: 论文采用自然语言处理技术和生成式AI（基于大型语言模型）来分析PCAP文件中的网络流量，识别异常并提出修复建议。

Result: 测试结果显示，ML模型在80-20的训练-测试数据分割下，对PCAP文件的分类准确率较高。

Conclusion: 该论文提出了一种基于AI/ML的故障分析引擎，显著提高了5G核心网流量分析的效率和准确性，并展示了未来扩展到4G和其他网络数据类型的潜力。

Abstract: With the advent of 5G networks and technologies, ensuring the integrity and
performance of packet core traffic is paramount. During network analysis, test
files such as Packet Capture (PCAP) files and log files will contain errors if
present in the system that must be resolved for better overall network
performance, such as connectivity strength and handover quality. Current
methods require numerous person-hours to sort out testing results and find the
faults. This paper presents a novel AI/ML-driven Fault Analysis (FA) Engine
designed to classify successful and faulty frames in PCAP files, specifically
within the 5G packet core. The FA engine analyses network traffic using natural
language processing techniques to identify anomalies and inefficiencies,
significantly reducing the effort time required and increasing efficiency. The
FA Engine also suggests steps to fix the issue using Generative AI via a Large
Language Model (LLM) trained on several 5G packet core documents. The engine
explains the details of the error from the domain perspective using documents
such as the 3GPP standards and user documents regarding the internal conditions
of the tests. Test results on the ML models show high classification accuracy
on the test dataset when trained with 80-20 splits for the successful and
failed PCAP files. Future scopes include extending the AI engine to incorporate
4G network traffic and other forms of network data, such as log text files and
multimodal systems.

</details>


### [184] [Agoran: An Agentic Open Marketplace for 6G RAN Automation](https://arxiv.org/abs/2508.09159)
*Ilias Chatzistefanidis,Navid Nikaein,Andrea Leone,Ali Maatouk,Leandros Tassioulas,Roberto Morabito,Ioannis Pitsiorlas,Marios Kountouris*

Main category: cs.NI

TL;DR: Agoran SRB是一种代理市场，通过AI三权分立和实时协商优化5G网络切片性能，显著提升吞吐量、降低延迟并节省资源，为6G奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前网络切片控制器僵化、策略受限且缺乏业务上下文感知，无法满足多服务所有者的冲突目标需求。

Method: Agoran SRB 采用多目标优化器生成帕累托最优方案，通过协商代理和调解代理在单轮内达成共识意图，并部署到Open和AI RAN控制器。

Result: 在私有5G测试床上，Agoran实现了eMBB切片吞吐量提升37%，URLLC切片延迟降低73%，同时端到端PRB使用节省8.3%。微调的1B参数Llama模型在6 GiB内存内以1.3秒收敛，决策质量恢复GPT-4.1的80%。

Conclusion: Agoran SRB 提出了一种创新的代理市场方法，通过三个自主AI分支（立法、执行、司法）实现多利益相关者的动态协作，显著提升了5G网络切片性能，为6G网络的超灵活、利益相关者中心化路径提供了可行方案。

Abstract: Next-generation mobile networks must reconcile the often-conflicting goals of
multiple service owners. However, today's network slice controllers remain
rigid, policy-bound, and unaware of the business context. We introduce Agoran
Service and Resource Broker (SRB), an agentic marketplace that brings
stakeholders directly into the operational loop. Inspired by the ancient Greek
agora, Agoran distributes authority across three autonomous AI branches: a
Legislative branch that answers compliance queries using retrieval-augmented
Large Language Models (LLMs); an Executive branch that maintains real-time
situational awareness through a watcher-updated vector database; and a Judicial
branch that evaluates each agent message with a rule-based Trust Score, while
arbitrating LLMs detect malicious behavior and apply real-time incentives to
restore trust. Stakeholder-side Negotiation Agents and the SRB-side Mediator
Agent negotiate feasible, Pareto-optimal offers produced by a multi-objective
optimizer, reaching a consensus intent in a single round, which is then
deployed to Open and AI RAN controllers. Deployed on a private 5G testbed and
evaluated with realistic traces of vehicle mobility, Agoran achieved
significant gains: (i) a 37% increase in throughput of eMBB slices, (ii) a 73%
reduction in latency of URLLC slices, and concurrently (iii) an end-to-end 8.3%
saving in PRB usage compared to a static baseline. An 1B-parameter Llama model,
fine-tuned for five minutes on 100 GPT-4 dialogues, recovers approximately 80%
of GPT-4.1's decision quality, while operating within 6 GiB of memory and
converging in only 1.3 seconds. These results establish Agoran as a concrete,
standards-aligned path toward ultra-flexible, stakeholder-centric 6G networks.
A live demo is presented
https://www.youtube.com/watch?v=h7vEyMu2f5w\&ab_channel=BubbleRAN.

</details>


### [185] [WPTrack: A Wi-Fi and Pressure Insole Fusion System for Single Target Tracking](https://arxiv.org/abs/2508.09166)
*Wei Guo,Shunsei Yamagishi,Lei Jing*

Main category: cs.NI

TL;DR: WPTrack是首个融合单Wi-Fi链路和压力鞋垫数据的追踪系统，解决了单链路下的初始位置和方向估计难题，实验验证了其高精度追踪能力。


<details>
  <summary>Details</summary>
Motivation: 现有Wi-Fi追踪方案多依赖多链路或专用设备，单链路下存在初始位置获取困难和方向估计盲点问题，限制了室内场景的应用。

Method: 论文提出WPTrack系统，通过单Wi-Fi链路收集CSI数据，结合90个鞋垫传感器的压力数据，计算相位差、多普勒速度和行走速度，并设计CSI-压力融合模型。

Result: 仿真显示初始定位精度在0.02 cm至42.55 cm之间，真实环境下的轨迹追踪结果与实际轨迹高度吻合。

Conclusion: WPTrack通过融合Wi-Fi和压力鞋垫数据，解决了单Wi-Fi链路下人体追踪的初始位置获取和方向估计盲点问题，实现了高精度的室内追踪。

Abstract: As the Internet of Things (IoT) continues to evolve, indoor location has
become a critical element for enabling smart homes, behavioral monitoring, and
elderly care. Existing WiFi-based human tracking solutions typically require
specialized equipment or multiple Wi-Fi links, a limitation in most indoor
settings where only a single pair of Wi-Fi devices is usually available.
However, despite efforts to implement human tracking using one Wi-Fi link,
significant challenges remain, such as difficulties in acquiring initial
positions and blind spots in DFS estimation of tangent direction. To address
these challenges, this paper proposes WPTrack, the first Wi-Fi and Pressure
Insoles Fusion System for Single Target Tracking. WPTrack collects Channel
State Information (CSI) from a single Wi-Fi link and pressure data from 90
insole sensors. The phase difference and Doppler velocity are computed from the
CSI, while the pressure sensor data is used to calculate walking velocity.
Then, we propose the CSI-pressure fusion model, integrating CSI and pressure
data to accurately determine initial positions and facilitate precise human
tracking. The simulation results show that the initial position localization
accuracy ranges from 0.02 cm to 42.55 cm. The trajectory tracking results
obtained from experimental data collected in a real-world environment closely
align with the actual trajectory.

</details>


### [186] [webMCP: Efficient AI-Native Client-Side Interaction for Agent-Ready Web Design](https://arxiv.org/abs/2508.09171)
*D. Perera*

Main category: cs.NI

TL;DR: webMCP 通过嵌入结构化元数据，显著提升AI代理处理网页交互的效率，降低成本并保持高任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前的AI代理需要大量处理才能理解网页内容，导致AI辅助的网页交互速度慢且成本高。

Method: webMCP 是一种客户端标准，通过在网页中嵌入结构化交互元数据，为AI代理提供明确的页面元素与用户动作之间的映射。

Result: webMCP 减少了67.6%的处理需求，任务成功率保持在97.9%，同时用户成本降低了34-63%，响应时间显著缩短。

Conclusion: webMCP 被证实为一种可行的解决方案，能够在不修改服务器端的情况下，显著提升AI辅助网页交互的效率和可访问性，同时降低计算成本。

Abstract: Current AI agents create significant barriers for users by requiring
extensive processing to understand web pages, making AI-assisted web
interaction slow and expensive. This paper introduces webMCP (Web Machine
Context & Procedure), a client-side standard that embeds structured interaction
metadata directly into web pages, enabling more efficient human-AI
collaboration on existing websites. webMCP transforms how AI agents understand
web interfaces by providing explicit mappings between page elements and user
actions. Instead of processing entire HTML documents, agents can access
pre-structured interaction data, dramatically reducing computational overhead
while maintaining task accuracy. A comprehensive evaluation across 1,890 real
API calls spanning online shopping, authentication, and content management
scenarios demonstrates webMCP reduces processing requirements by 67.6% while
maintaining 97.9% task success rates compared to 98.8% for traditional
approaches. Users experience significantly lower costs (34-63% reduction) and
faster response times across diverse web interactions. Statistical analysis
confirms these improvements are highly significant across multiple AI models.
An independent WordPress deployment study validates practical applicability,
showing consistent improvements across real-world content management workflows.
webMCP requires no server-side modifications, making it deployable across
millions of existing websites without technical barriers. These results
establish webMCP as a viable solution for making AI web assistance more
accessible and sustainable, addressing the critical gap between user
interaction needs and AI computational requirements in production environments.

</details>


### [187] [Camel: Energy-Aware LLM Inference on Resource-Constrained Devices](https://arxiv.org/abs/2508.09173)
*Hao Xu,Long Peng,Shezheng Song,Xiaodong Liu,Ma Jun,Shasha Li,Jie Yu,Xiaoguang Mao*

Main category: cs.NI

TL;DR: 提出边缘设备上LLM推理的能量管理框架，优化GPU频率和批处理大小，显著降低EDP。


<details>
  <summary>Details</summary>
Motivation: 云端部署LLM存在网络延迟、隐私和带宽限制问题，边缘设备部署需平衡能耗与延迟。

Method: 通过优化GPU频率和批处理大小，并有效管理配置搜索中的探索-利用困境，找到最优设置。

Result: 相比默认配置，框架显著降低了EDP，优化了能耗与延迟的平衡。

Conclusion: 该论文提出的LLM推理能量管理框架在NVIDIA Jetson AGX Orin平台上实现了能耗与延迟的更好平衡，EDP降低了12.4%-29.9%。

Abstract: Most Large Language Models (LLMs) are currently deployed in the cloud, with
users relying on internet connectivity for access. However, this paradigm faces
challenges such as network latency, privacy concerns, and bandwidth limits.
Thus, deploying LLMs on edge devices has become an important research focus. In
edge inference, request latency is critical as high latency can impair
real-time tasks. At the same time, edge devices usually have limited battery
capacity, making energy consumption another major concern. Balancing energy
consumption and inference latency is essential. To address this, we propose an
LLM inference energy management framework that optimizes GPU frequency and
batch size to balance latency and energy consumption. By effectively managing
the exploration-exploitation dilemma in configuration search, the framework
finds the optimal settings. The framework was implemented on the NVIDIA Jetson
AGX Orin platform, and a series of experimental validations were conducted.
Results demonstrate that, compared to the default configuration, our framework
reduces energy delay product (EDP) by 12.4%-29.9%, achieving a better balance
between energy consumption and latency.

</details>


### [188] [HiSTM: Hierarchical Spatiotemporal Mamba for Cellular Traffic Forecasting](https://arxiv.org/abs/2508.09184)
*Zineddine Bettouche,Khalid Ali,Andreas Fischer,Andreas Kassler*

Main category: cs.NI

TL;DR: HiSTM通过双空间编码器和Mamba时间模块提升流量预测准确性，MAE提高29.4%，参数减少94%，泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 由于用户移动性导致的复杂时空模式，现有AI流量预测模型在准确性和计算效率之间存在权衡。

Method: 结合双空间编码器、基于Mamba的时间模块和注意力机制，采用选择性状态空间方法捕捉网络流量的时空模式。

Result: 在真实数据集上评估，HiSTM相比STN基线MAE提升29.4%，且参数减少94%。

Conclusion: HiSTM在保持计算效率的同时显著提升了预测准确性，能够有效适应不同数据集，并在更长时间跨度上表现更优。

Abstract: Cellular traffic forecasting is essential for network planning, resource
allocation, or load-balancing traffic across cells. However, accurate
forecasting is difficult due to intricate spatial and temporal patterns that
exist due to the mobility of users. Existing AI-based traffic forecasting
models often trade-off accuracy and computational efficiency. We present
Hierarchical SpatioTemporal Mamba (HiSTM), which combines a dual spatial
encoder with a Mamba-based temporal module and attention mechanism. HiSTM
employs selective state space methods to capture spatial and temporal patterns
in network traffic. In our evaluation, we use a real-world dataset to compare
HiSTM against several baselines, showing a 29.4% MAE improvement over the STN
baseline while using 94% fewer parameters. We show that the HiSTM generalizes
well across different datasets and improves in accuracy over longer
time-horizons.

</details>


### [189] [MX-AI: Agentic Observability and Control Platform for Open and AI-RAN](https://arxiv.org/abs/2508.09197)
*Ilias Chatzistefanidis,Andrea Leone,Ali Yaghoubian,Mikel Irazabal,Sehad Nassim,Lina Bariah,Merouane Debbah,Navid Nikaein*

Main category: cs.NI

TL;DR: MX-AI是首个端到端代理系统，用于6G RAN的AI原生管理，性能媲美人类专家。


<details>
  <summary>Details</summary>
Motivation: 未来6G RAN将是AI原生的，需要自主代理在云边连续体中协作观察、推理和重新配置。

Method: MX-AI是一个端到端的代理系统，基于OpenAirInterface和FlexRIC构建了一个实时5G Open RAN测试床，并在SMO层部署了由LLM驱动的代理图。

Result: 在50个实际运营查询中，MX-AI的平均回答质量为4.1/5.0，决策-行动准确率为100%，端到端延迟仅为8.8秒。

Conclusion: MX-AI展现了在真实环境中与人类专家相当的性能，验证了其在6G RAN中的实用性。

Abstract: Future 6G radio access networks (RANs) will be artificial intelligence
(AI)-native: observed, reasoned about, and re-configured by autonomous agents
cooperating across the cloud-edge continuum. We introduce MX-AI, the first
end-to-end agentic system that (i) instruments a live 5G Open RAN testbed based
on OpenAirInterface (OAI) and FlexRIC, (ii) deploys a graph of
Large-Language-Model (LLM)-powered agents inside the Service Management and
Orchestration (SMO) layer, and (iii) exposes both observability and control
functions for 6G RAN resources through natural-language intents. On 50
realistic operational queries, MX-AI attains a mean answer quality of 4.1/5.0
and 100 % decision-action accuracy, while incurring only 8.8 seconds end-to-end
latency when backed by GPT-4.1. Thus, it matches human-expert performance,
validating its practicality in real settings. We publicly release the agent
graph, prompts, and evaluation harness to accelerate open research on AI-native
RANs. A live demo is presented here:
https://www.youtube.com/watch?v=CEIya7988Ug&t=285s&ab_channel=BubbleRAN

</details>


### [190] [CoMoE: Collaborative Optimization of Expert Aggregation and Offloading for MoE-based LLMs at Edge](https://arxiv.org/abs/2508.09208)
*Muqing Li,Ning Li,Xin Yuan,Wenchao Xu,Quan Chen,Song Guo,Haijun Zhang*

Main category: cs.NI

TL;DR: CoMoE框架通过动态优化专家聚合和卸载策略，显著减少内存和延迟，使大型MoE模型能在移动边缘设备上部署。


<details>
  <summary>Details</summary>
Motivation: 解决Mixture-of-Experts（MoE）模型在资源受限的移动边缘计算环境中部署时面临的内存占用大和动态专家激活模式带来的挑战。

Method: 提出了一种动态资源感知协作优化框架（CoMoE），联合优化专家聚合粒度和卸载策略，根据实时设备资源状态、网络条件和输入特征进行调整。

Result: CoMoE在真实移动边缘测试平台上实现了内存使用减少约70%，推理延迟降低10.5%，同时保持模型性能稳定。对于7.4B参数的Switch-Base-128模型，内存需求从15.6GB降至4.7GB。

Conclusion: CoMoE框架通过动态资源感知协作优化，显著降低了内存使用和推理延迟，使大型MoE模型能够在资源受限的移动边缘设备上部署。

Abstract: The proliferation of large language models (LLMs) has driven the adoption of
Mixture-of-Experts (MoE) architectures as a promising solution to scale model
capacity while controlling computational costs. However, deploying MoE models
in resource-constrained mobile edge computing environments presents significant
challenges due to their large memory footprint and dynamic expert activation
patterns. To address these challenges, we propose a novel dynamic
resource-aware collaborative optimization framework that jointly optimizes
expert aggregation granularity and offloading strategies based on real-time
device resource states, network conditions, and input characteristics in mobile
edge environments, denoted as CoMoE. In CoMoE, we first systematically analyze
existing expert aggregation techniques, including expert parameter
merging,knowledge distillation,and parameter sharing decomposition, identifying
their limitations in dynamic mobile environments.We then investigate expert
offloading strategies encompassing expert prediction and prefetching, expert
caching and scheduling, and multi-tier storage architectures, revealing the
interdependencies between routing decisions and offloading performance.The
CoMoE incorporates adaptive scheduling mechanisms that respond to user mobility
and varying network conditions, enabling efficient MoE deployment across
heterogeneous edge devices. Extensive experiments on real mobile edge testbeds
demonstrate that CoMoE achieves approximately 70% reduction in memory usage
compared to baseline methods, 10.5% lower inference latency than existing
expert offloading techniques, while maintaining model performance stability.
For large-scale MoE models (e.g,7.4B-parameter Switch-Base-128), the CoMoE
reduces memory requirements from 15.6GB to 4.7GB, enabling deployment on
resource-constrained mobile edge devices that previously could only support
much smaller models.

</details>


### [191] [NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation](https://arxiv.org/abs/2508.09240)
*Zainab Khan,Ahmed Hussain,Mukesh Thakur,Arto Hellas,Panos Papadimitratos*

Main category: cs.NI

TL;DR: NEFMind框架通过参数高效的LLM微调，显著降低5G API管理复杂性，通信开销减少85%，准确率达98-100%。


<details>
  <summary>Details</summary>
Motivation: 现代电信中基于服务的架构使用导致网络功能和API数量激增，给服务发现和管理带来巨大复杂性。

Method: 框架集成三个核心组件：从NEF API规范生成合成数据集、通过量化低秩适应的模型优化，以及使用GPT-4 Ref Score和BertScore指标进行性能评估。

Result: 方法在5G基于服务的架构API中实现了85%的通信开销减少，使用Phi-2模型在API调用识别上达到98-100%的准确率，性能接近GPT-4等更大模型。

Conclusion: 研究发现验证了领域特定、参数高效的LLM策略在管理下一代电信网络复杂API生态系统中的有效性。

Abstract: The use of Service-Based Architecture in modern telecommunications has
exponentially increased Network Functions (NFs) and Application Programming
Interfaces (APIs), creating substantial operational complexities in service
discovery and management. We introduce \textit{NEFMind}, a framework leveraging
parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to
address these challenges. It integrates three core components: synthetic
dataset generation from Network Exposure Function (NEF) API specifications,
model optimization through Quantized-Low-Rank Adaptation, and performance
evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G
Service-Based Architecture APIs, our approach achieves 85% reduction in
communication overhead compared to manual discovery methods. Experimental
validation using the open-source Phi-2 model demonstrates exceptional API call
identification performance at 98-100% accuracy. The fine-tuned Phi-2 model
delivers performance comparable to significantly larger models like GPT-4 while
maintaining computational efficiency for telecommunications infrastructure
deployment. These findings validate domain-specific, parameter-efficient LLM
strategies for managing complex API ecosystems in next-generation
telecommunications networks.

</details>


### [192] [On-Device Multimodal Federated Learning for Efficient Jamming Detection](https://arxiv.org/abs/2508.09369)
*Ioannis Panitsas,Iason Ofeidis,Leandros Tassiulas*

Main category: cs.NI

TL;DR: 论文提出了一种多模态联邦学习框架，用于无线网络的设备端干扰检测与分类，显著提升了检测准确率和效率，同时保护了数据隐私。


<details>
  <summary>Details</summary>
Motivation: 现有干扰检测方法多为单模态、依赖集中式处理且计算资源需求高，影响了可扩展性和部署可行性。

Method: 论文提出了一种轻量级双编码器架构，结合融合模块和多模态投影头，整合了频谱图和跨层网络关键性能指标（KPIs），支持隐私保护的训练和推理。

Result: 实验结果表明，该方法在检测准确率上比现有单模态基线高出15%，通信轮次减少60%，且资源占用低。

Conclusion: 该论文提出的多模态联邦学习框架在无线网络抗干扰检测中表现出色，尤其在异构数据分布下展现出强大的鲁棒性和可靠性。

Abstract: Wireless networks face severe vulnerabilities from jamming attacks, which can
significantly disrupt communication. Existing detection approaches are often
unimodal, rely on centralized processing, and demand substantial computational
resources, hindering scalability, efficiency, and deployment feasibility. To
address these challenges, we introduce a multimodal Federated Learning (FL)
framework for on-device jamming detection and classification that integrates
spectrograms with cross-layer network Key Performance Indicators (KPIs) through
a lightweight dual-encoder architecture equipped with a fusion module and a
multimodal projection head. This design enables privacy-preserving training and
inference by ensuring that only model parameters are exchanged, while raw data
remains on the device. The framework is implemented and evaluated on a wireless
experimental testbed using, to the best of our knowledge, the first
over-the-air multimodal dataset with synchronized benign and three distinct
jamming scenarios. Results show that our approach surpasses state-of-the-art
unimodal baselines by up to 15% in detection accuracy, achieves convergence
with 60% fewer communication rounds, and maintains low resource usage. Its
benefits are most evident under heterogeneous data distributions across
devices, where it exhibits strong robustness and reliability.

</details>


### [193] [Metrics for Assessing Changes in Flow-based Networks](https://arxiv.org/abs/2508.09573)
*Michał Rzepka,Piotr Chołda*

Main category: cs.NI

TL;DR: 本文提出了一套度量标准和改进的Shapley值方法，有效评估波动流量下的网络性能，其中三种度量表现突出，为未来研究提供了框架。


<details>
  <summary>Details</summary>
Motivation: 解决在波动流量模式下评估网络性能的挑战，特别是峰值数据速率对网络资源的影响。

Method: 通过百分位数和样本分布分析链路和流量数据，引入利用率评分度量，并采用改进的基于Shapley值的方法来测量个体流量对网络的影响。

Result: 研究评估了11种度量标准，其中三种在捕捉网络状态变化方面表现出色，且易于维护。

Conclusion: 本文提出的度量标准和方法为评估网络性能提供了有效工具，特别是在流量模式波动的情况下。研究展示了三种度量标准在捕捉网络状态变化方面的实用性，并为进一步研究提供了框架。

Abstract: This paper addresses the challenges of evaluating network performance in the
presence of fluctuating traffic patterns, with a particular focus on the impact
of peak data rates on network resources. We introduce a set of metrics to
quantify network load and measure the impact of individual flows on the overall
network state. By analyzing link and flow data through percentile values and
sample distributions, and introducing the Utilization Score metric, the
research provides insights into resource utilization under varying network
conditions. Furthermore, we employ a modified Shapley value-based approach to
measure the influence of individual flows on the network, offering a better
understanding of their contribution to network performance. The paper reviews
and compares 11 metrics across various network scenarios, evaluating their
practical relevance for research and development. Our evaluation demonstrates
that these metrics effectively capture changes in network state induced by
specific flows, with three of them offering a broad range of valuable insights
while remaining relatively easy to maintain. Moreover, the methodology
described in this paper serves as a framework for future research, with the
potential to expand and refine the set of metrics used to evaluate flow impact
on network performance.

</details>


### [194] [Energy-efficient PON-based Backhaul Connectivity for a VLC-enabled Indoor Fog Computing Environment](https://arxiv.org/abs/2508.09582)
*Wafaa B. M. Fadlelmula,Sanaa Hamid Mohamed,Taisir E. H. El-Gorashi,Jaafar M. H. Elmirghani*

Main category: cs.NI

TL;DR: 本文提出基于PON的节能VLC架构，通过MILP优化资源分配，功耗节省82%（相比S&L网络），能效提升93%（相比云处理），并引入跨建筑资源共享支持高需求。


<details>
  <summary>Details</summary>
Motivation: 解决室内雾计算资源连接的能效问题，优化VLC系统的处理和网络功耗，提升整体能源效率。

Method: 采用混合整数线性规划（MILP）模型优化计算资源分配，并设计了一种基于PON的节能VLC系统架构。通过动态带宽分配、增加波长带宽和改善室内连接性等措施增强架构性能。

Result: 与S&L网络设计相比，总功耗节省高达82%；与集中式云处理相比，能效提升达93%。任务拆分和架构增强进一步提高了能效。

Conclusion: 本文提出了一种基于PON的VLC系统节能架构，通过MILP模型优化计算资源分配，显著降低了处理和网络功耗。与现有S&L网络设计相比，总功耗节省高达82%，与集中式云处理相比能效提升达93%。通过任务拆分和架构增强（如动态带宽分配、波长带宽增加等），进一步提升了能效。此外，还引入了跨建筑资源共享架构以支持高需求场景。

Abstract: In this paper, we consider the use of visible light communication (VLC) to
provide connectivity to indoor fog computing resources and propose an
energy-efficient passive optical network (PON)-based backhaul architecture to
support the VLC system. We develop a mixed-integer linear programming (MILP)
model to optimize the allocation of computing resources over the proposed
architecture, aiming to minimize processing and networking power consumption.
We evaluate the performance of the proposed architecture under varying workload
demands and user distributions. Comparative analysis against a backhaul
architecture that is based on the state-of-the-art spine-and-leaf (S&L) network
design demonstrates total power savings of up to 82%. Further comparison with
centralized cloud processing shows improvements in energy efficiency of up to
93%. Additionally, we examine the improvements in energy efficiency obtained by
splitting tasks among multiple processing nodes and propose enhancements to the
architecture including dynamic bandwidth allocation, increased wavelength
bandwidth and improved connectivity within rooms to alleviate networking
bottlenecks. Furthermore, we introduce an inter-building architecture that
leverages resources from neighboring buildings to support high-demand
scenarios.

</details>


### [195] [Duty-Cycling is Not Enough in Constrained IoT Networking: Revealing the Energy Savings of Dynamic Clock Scaling](https://arxiv.org/abs/2508.09620)
*Michel Rottleuthner,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: 研究发现，通过动态电压和频率调节（DVFS）在物联网设备中应用，可显著降低能耗，MAC操作节省24-52%，加密通信节省达37%。


<details>
  <summary>Details</summary>
Motivation: 解决低功耗无线节点能耗问题，利用MCU和网络吞吐量之间的性能差距，通过DVFS实现物联网网络的最小能量延迟乘积（EDP）。

Method: 通过将DVFS集成到RIOT物联网操作系统中，并分析其在常见网络任务中的能效提升效果，包括CSMA/CA和时间分槽两种MAC操作模式，以及不同的CoAP事务、有效载荷大小和DTLS传输加密。

Result: 实验显示，MAC操作能耗节省24%到52%，加密CoAP通信能耗节省高达37%。

Conclusion: 研究结果表明，将动态电压和频率调节（DVFS）集成到未来的物联网设备中，可以显著延长电池寿命，并鼓励相关研究和系统设计工作。

Abstract: Minimizing energy consumption of low-power wireless nodes is a persistent
challenge from the constrained Internet of Things (IoT). In this paper, we
start from the observation that constrained IoT devices have largely different
hardware (im-)balances than full-scale machines. We find that the performance
gap between MCU and network throughput on constrained devices enables minimal
energy delay product (EDP) for IoT networking at largely reduced clock
frequencies. We analyze the potentials by integrating dynamic voltage and
frequency scaling (DVFS) into the RIOT IoT operating system and show that the
DVFS reconfiguration overhead stays below the energy saved for a single,
downscaled MAC operation. Backed by these findings, we systematically
investigate how DVFS further improves energy-efficiency for common networking
tasks -- in addition to duty-cycling. We measure IoT communication scenarios
between real-world systems and analyze two MAC operating modes -- CSMA/CA and
time slotting -- in combination with different CoAP transactions, payload
sizes, as well as DTLS transport encryption. Our experiments reveal energy
savings between 24% and 52% for MAC operations and up to 37% for encrypted CoAP
communication. These results shall encourage research and system design work to
integrate DVFS in future IoT devices for performing tasks at their optimal
frequencies and thereby significantly extending battery lifetimes.

</details>


### [196] [Anomaly Detection for IoT Global Connectivity](https://arxiv.org/abs/2508.09660)
*Jesus Omaña Iglesias,Carlos Segura Perales,Stefan Geißler,Diego Perino,Andra Lutu*

Main category: cs.NI

TL;DR: ANCHOR是一个无监督异常检测方案，用于全球漫游平台的IoT连接服务，通过机器学习和深度学习模型主动识别问题客户，提升服务质量。


<details>
  <summary>Details</summary>
Motivation: 在复杂的IoT生态系统中，保证通信的可用性和可靠性日益困难，现有平台运营商多采用被动应对方式，影响服务质量。

Method: 通过统计规则、机器学习和深度学习模型，基于被动信令流量进行IoT垂直领域异常检测。

Result: ANCHOR能够有效筛选大量数据，识别有连接问题的客户，实现问题的主动解决。

Conclusion: ANCHOR作为一种无监督异常检测解决方案，成功帮助工程师在IoT连接服务中主动识别潜在问题客户，从而在服务受到严重影响前解决问题。

Abstract: Internet of Things (IoT) application providers rely on Mobile Network
Operators (MNOs) and roaming infrastructures to deliver their services
globally. In this complex ecosystem, where the end-to-end communication path
traverses multiple entities, it has become increasingly challenging to
guarantee communication availability and reliability. Further, most platform
operators use a reactive approach to communication issues, responding to user
complaints only after incidents have become severe, compromising service
quality. This paper presents our experience in the design and deployment of
ANCHOR -- an unsupervised anomaly detection solution for the IoT connectivity
service of a large global roaming platform. ANCHOR assists engineers by
filtering vast amounts of data to identify potential problematic clients (i.e.,
those with connectivity issues affecting several of their IoT devices),
enabling proactive issue resolution before the service is critically impacted.
We first describe the IoT service, infrastructure, and network visibility of
the IoT connectivity provider we operate. Second, we describe the main
challenges and operational requirements for designing an unsupervised anomaly
detection solution on this platform. Following these guidelines, we propose
different statistical rules, and machine- and deep-learning models for IoT
verticals anomaly detection based on passive signaling traffic. We describe the
steps we followed working with the operational teams on the design and
evaluation of our solution on the operational platform, and report an
evaluation on operational IoT customers.

</details>


### [197] [Route Planning and Online Routing for Quantum Key Distribution Networks](https://arxiv.org/abs/2508.09735)
*Jorge López,Charalampos Chatzinakis,Marc Cartigny*

Main category: cs.NI

TL;DR: 论文提出用二次规划建模QKD网络路由问题，证明最宽最短路径策略优于传统方法，竞争比至少1/2。


<details>
  <summary>Details</summary>
Motivation: QKD网络由于容量限制和信息处理的特殊性，传统最短路径路由算法在路由规划和在线路由中表现不佳，且由于资源稀缺，常无法满足需求。论文旨在解决这些问题。

Method: 论文提出将QKD网络中的路由问题建模为二次规划（QP）问题，并分析了最短路径和最宽最短路径路由策略的性能。

Result: 论文证明了最宽最短路径路由策略在QKD网络中具有至少1/2的竞争比，有效解决了路由问题。

Conclusion: 该论文通过将QKD网络中的路由问题建模为二次规划问题，并证明了最短路径路由策略在在线设置中表现不佳，而最宽最短路径路由策略具有至少1/2的竞争比，有效解决了QKD网络中的路由问题。

Abstract: Quantum Key Distribution (QKD) networks harness the principles of quantum
physics in order to securely transmit cryptographic key material, providing
physical guarantees. These networks require traditional management and
operational components, such as routing information through the network
elements. However, due to the limitations on capacity and the particularities
of information handling in these networks, traditional shortest paths
algorithms for routing perform poorly on both route planning and online
routing, which is counterintuitive. Moreover, due to the scarce resources in
such networks, often the expressed demand cannot be met by any assignment of
routes. To address both the route planning problem and the need for fair
automated suggestions in infeasible cases, we propose to model this problem as
a Quadratic Programming (QP) problem. For the online routing problem, we
showcase that the shortest (available) paths routing strategy performs poorly
in the online setting. Furthermore, we prove that the widest shortest path
routing strategy has a competitive ratio greater or equal than $\frac{1}{2}$,
efficiently addressing both routing modes in QKD networks.

</details>


### [198] [The Paradigm of Massive Wireless Human Sensing: Concept, Architecture and Challenges](https://arxiv.org/abs/2508.09756)
*Mauro De Sanctis*

Main category: cs.NI

TL;DR: 该论文提出了一种基于异构无线信号的大规模无线人体感知新方法，通过多技术融合提升感知能力，并讨论了相关架构和挑战。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用现有无线通信信号的多样性来增强人体感知能力，以应对不同环境下的挑战。

Method: 利用时间和空间域的信号多样性，结合设备无关和设备依赖的无线感知方法，设计了具有特征提取功能的多技术RF接收器嵌入式系统。

Result: 提出了大规模无线人体感知边缘设备的概念，并讨论了其架构解决方案和未来发展的挑战。

Conclusion: 该论文提出了一个基于异构无线通信信号的大规模无线人体感知新范式，旨在通过信号多样性和多技术融合提升感知精度和服务可用性。

Abstract: This article is a position paper which introduces the paradigm of ``Massive
Wireless Human Sensing'', i.e. an infrastructure for wireless human sensing
based on a plethora of heterogeneous wireless communication signals. More
specifically, we aim to exploit signal diversity in the time, frequency, and
space domains using opportunistically both device-free and device-based
wireless sensing approaches, with the objective of enhancing human sensing
capabilities in terms of accuracy and service availability over different
environments. The enabling element of this concept is the massive wireless
human sensing edge device, that is, an embedded system acting as a
multi-technology and multi-approach RF receiver with feature extraction
functionality, located within the monitoring area or at its borders. In this
framework, architecture solutions and challenges are discussed to lead the
future development of this new paradigm.

</details>


### [199] [An (m,k)-firm Elevation Policy to Increase the Robustness of Time-Driven Schedules in 5G Time-Sensitive Networks](https://arxiv.org/abs/2508.09769)
*Simon Egger,Robin Laidig,Heiko Geppert,Lucas Haug,Jona Herrmann,Frank Dürr,Christian Becker*

Main category: cs.NI

TL;DR: 论文提出(m,k)-firm Elevation Policy，结合时间驱动和动态优先级驱动方案，以在不稳定网络条件下维持弱硬实时保证，评估显示其有效且开销小。


<details>
  <summary>Details</summary>
Motivation: 解决5G和TSN集成中概率性延迟特性与理想延迟模型之间的不匹配问题，确保实时通信的鲁棒性。

Method: 通过将主时间驱动调度与动态优先级驱动方案相结合，提升m/k连续帧的优先级以应对延迟。

Result: 评估表明，该策略在不稳定网络条件下能有效维持弱硬实时保证，同时在主调度提供更强QoS保证时仅引入少量开销。

Conclusion: 论文提出了一种(m,k)-firm Elevation Policy，作为一种轻量级的后备机制，在不稳定的网络条件下为应用提供有意义的实时保证。

Abstract: Current standardization efforts are advancing the integration of 5G and
Time-Sensitive Networking (TSN) to facilitate the deployment of safety-critical
industrial applications that require real-time communication. However, there
remains a fundamental disconnect between the probabilistic 5G delay
characteristics and the often idealistic delay models used to synthesize 5G-TSN
network configurations. For time-driven schedules in particular, any delay
outlier unforeseen during schedule synthesis can jeopardize the robustness of
their real-time guarantees. To address this challenge, we present the
(m,k)-firm Elevation Policy to uphold a base level of weakly hard real-time
guarantees during unstable network conditions that do not match the expected
delay characteristics. It augments the primary time-driven schedule with a
dynamic priority-driven scheme to elevate the priority of m out of k
consecutive frames if they are delayed. Our evaluations demonstrate that weakly
hard real-time guarantees are essential to uphold the quality of control within
a networked control system. At the same time, only a small overhead is imposed
when the primary schedule can provide stronger quality of service guarantees.
Our (m,k)-firm Elevation Policy thereby yields a robust but light-weight
fallback mechanism to serve applications with meaningful guarantees during
unstable network conditions.

</details>


### [200] [A First Look at Starlink In-Flight Performance: An Intercontinental Empirical Study](https://arxiv.org/abs/2508.09839)
*Muhammad Asad Ullah,Luca Borgianni,Heikki Kokkinen,Antti Anttonen,Stefano Giordano*

Main category: cs.NI

TL;DR: 论文通过飞行测量分析了Starlink在航空领域的性能，发现吞吐量随高度变化，RTT受地面站和ISLs影响。


<details>
  <summary>Details</summary>
Motivation: 随着主要航空公司开始提供Starlink互联网服务，评估和改进其在航空用户中的性能需求日益增长。此前的研究缺乏对飞行中性能的深入分析，本文填补了这一空白。

Method: 论文通过在波罗的海和太平洋上进行的飞行测量，收集了吞吐量和RTT数据，并分析了影响RTT的因素。

Result: 测量结果显示，单个用户设备的下行和上行中位数吞吐量分别为64 Mbps和24 Mbps；在飞机高度超过17,000英尺时，上行中位数吞吐量约为33 Mbps，但在下降阶段性能显著下降。RTT受地面站位置和ISLs使用的影响较大。

Conclusion: 该论文通过实际飞行测量，揭示了Starlink在航空领域的性能表现，特别是在不同高度和飞行阶段的吞吐量变化，以及RTT受地面站位置和ISLs使用的影响。

Abstract: Starlink delivers Internet services to users across terrestrial, maritime,
and aviation domains. The prior works have studied its performance at fixed
sites and in-motion vehicles, while an in-depth analysis of in-flight
performance remains absent. With major airlines now offering Starlink Internet
onboard, there is a growing need to evaluate and improve its performance for
aviation users. This paper addresses this shortcoming by conducting in-flight
measurements over the Baltic Sea and the Pacific Ocean. Our measurement results
show that a single user device experiences median throughputs of 64 Mbps and 24
Mbps for the downlink and uplink, respectively. The median uplink throughput is
approximately 33 Mbps when the aircraft maintains an altitude above 17,000
feet. However, a significant reduction in uplink performance is observed during
the aircraft descent phase, with the median throughput dropping to around 20
Mbps at lower altitudes. Round-trip time (RTT) is highly dependent on the
location of the ground station being pinged and the use of inter-satellite
links (ISLs). We dive deeper into 5.5 hours of ping measurements collected over
the Pacific Ocean and investigate factors influencing RTT, hypothesizing that
ISLs routing, data queuing at satellites, and feeder link congestion contribute
to deviations from theoretical values. For comparative analysis, we evaluate
the Starlink ground terminal and in-flight connectivity performance from the
perspectives of a residential user and an airline passenger, respectively.

</details>
