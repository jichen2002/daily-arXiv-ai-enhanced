<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 67]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 37]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 14]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Heatmap Regression without Soft-Argmax for Facial Landmark Detection](https://arxiv.org/abs/2508.14929)
*Chiao-An Yang,Raymond A. Yeh*

Main category: cs.CV

TL;DR: 本研究提出了一种替代Soft-argmax的训练目标，基于结构化预测框架，在面部地标检测任务中实现了更快训练速度和竞争性精度。


<details>
  <summary>Details</summary>
Motivation: 热图回归方法在面部地标检测任务中广泛使用，但Soft-argmax作为其核心组件并非唯一选择。本研究旨在探索替代方案，以提升性能。

Method: 提出了一种替代Soft-argmax的训练目标，基于经典结构化预测框架。

Result: 在WFLW、COFW和300W三个面部地标基准测试中实现了最先进的性能，训练速度提高了2.2倍，且保持了更好的/竞争性的准确性。

Conclusion: 本研究提出了一种基于经典结构化预测框架的替代训练目标，取代了长期使用的Soft-argmax方法，在三个面部地标基准测试中实现了最先进的性能，训练速度提高了2.2倍，同时保持了更好的/竞争性的准确性。

Abstract: Facial landmark detection is an important task in computer vision with
numerous applications, such as head pose estimation, expression analysis, face
swapping, etc. Heatmap regression-based methods have been widely used to
achieve state-of-the-art results in this task. These methods involve computing
the argmax over the heatmaps to predict a landmark. Since argmax is not
differentiable, these methods use a differentiable approximation, Soft-argmax,
to enable end-to-end training on deep-nets. In this work, we revisit this
long-standing choice of using Soft-argmax and demonstrate that it is not the
only way to achieve strong performance. Instead, we propose an alternative
training objective based on the classic structured prediction framework.
Empirically, our method achieves state-of-the-art performance on three facial
landmark benchmarks (WFLW, COFW, and 300W), converging 2.2x faster during
training while maintaining better/competitive accuracy. Our code is available
here: https://github.com/ca-joe-yang/regression-without-softarg.

</details>


### [2] [Fast Graph Neural Network for Image Classification](https://arxiv.org/abs/2508.14958)
*Mustafa Mohammadi Gharasuie,Luis Rueda*

Main category: cs.CV

TL;DR: 该论文提出了一种结合GCNs和Voronoi图的新方法，显著提升了图像分类的效率和准确性，尤其在复杂场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 图像分类的快速进展主要依赖于GCNs的采用，但传统卷积神经网络（CNNs）在处理复杂数据结构时存在局限性。本研究旨在通过结合GCNs和Voronoi图来提升图像分类的性能。

Method: 本研究提出了一种新颖方法，将图像表示为图，其中像素或区域作为顶点，并通过Delaunay三角剖分优化图的表示。这种方法结合了GCNs和Voronoi图的优势。

Result: 提出的模型在多个基准数据集上显著提高了预处理效率和分类准确性，尤其在复杂场景和细粒度类别中超越了现有技术。

Conclusion: 该研究通过将图卷积网络（GCNs）与Voronoi图结合，不仅为图像分类提供了新视角，还扩展了图基学习范式在计算机视觉和非结构化数据分析中的应用潜力。

Abstract: The rapid progress in image classification has been largely driven by the
adoption of Graph Convolutional Networks (GCNs), which offer a robust framework
for handling complex data structures. This study introduces a novel approach
that integrates GCNs with Voronoi diagrams to enhance image classification by
leveraging their ability to effectively model relational data. Unlike
conventional convolutional neural networks (CNNs), our method represents images
as graphs, where pixels or regions function as vertices. These graphs are then
refined using corresponding Delaunay triangulations, optimizing their
representation. The proposed model achieves significant improvements in both
preprocessing efficiency and classification accuracy across various benchmark
datasets, surpassing state-of-the-art approaches, particularly in challenging
scenarios involving intricate scenes and fine-grained categories. Experimental
results, validated through cross-validation, underscore the effectiveness of
combining GCNs with Voronoi diagrams for advancing image classification. This
research not only presents a novel perspective on image classification but also
expands the potential applications of graph-based learning paradigms in
computer vision and unstructured data analysis.

</details>


### [3] [You Only Pose Once: A Minimalist's Detection Transformer for Monocular RGB Category-level 9D Multi-Object Pose Estimation](https://arxiv.org/abs/2508.14965)
*Hakjin Lee,Junghoon Seo,Jaehoon Sim*

Main category: cs.CV

TL;DR: YOPO 是一种单阶段、基于查询的 RGB-only 方法，统一了物体检测和 9-DoF 姿态估计，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的解决方案大多依赖于伪深度、CAD 模型或多级级联方法，这些方法将 2D 检测与姿态估计分开。本研究旨在探索一种更简单的、仅依赖 RGB 图像且直接在类别级别学习的替代方案。

Method: YOPO 是一个单阶段、基于查询的框架，将类别级 9-DoF 估计视为 2D 检测的自然扩展。它通过轻量级姿态头、边界框条件平移模块和 6D-aware Hungarian 匹配成本增强了 Transformer 检测器。

Result: YOPO 在三个基准测试中创造了新的最先进水平。

Conclusion: YOPO 在 REAL275 数据集上取得了 79.6% 的 IoU50 和 54.1% 的 10°10cm 指标，超越了之前的 RGB-only 方法，并缩小了与 RGB-D 系统的差距。

Abstract: Accurately recovering the full 9-DoF pose of unseen instances within specific
categories from a single RGB image remains a core challenge for robotics and
automation. Most existing solutions still rely on pseudo-depth, CAD models, or
multi-stage cascades that separate 2D detection from pose estimation. Motivated
by the need for a simpler, RGB-only alternative that learns directly at the
category level, we revisit a longstanding question: Can object detection and
9-DoF pose estimation be unified with high performance, without any additional
data? We show that they can with our method, YOPO, a single-stage, query-based
framework that treats category-level 9-DoF estimation as a natural extension of
2D detection. YOPO augments a transformer detector with a lightweight pose
head, a bounding-box-conditioned translation module, and a 6D-aware Hungarian
matching cost. The model is trained end-to-end only with RGB images and
category-level pose labels. Despite its minimalist design, YOPO sets a new
state of the art on three benchmarks. On the REAL275 dataset, it achieves 79.6%
$\rm{IoU}_{50}$ and 54.1% under the $10^\circ$$10{\rm{cm}}$ metric, surpassing
prior RGB-only methods and closing much of the gap to RGB-D systems. The code,
models, and additional qualitative results can be found on our project.

</details>


### [4] [Image-Conditioned 3D Gaussian Splat Quantization](https://arxiv.org/abs/2508.15372)
*Xinshuang Liu,Runfa Blark Li,Keito Suzuki,Truong Nguyen*

Main category: cs.CV

TL;DR: ICGS-Quantizer 是一种高效压缩3D高斯样条的方法，通过共享码书和图像条件解码，显著降低了存储需求并适应存档后场景变化。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D高斯样条压缩方法在存档应用中存在的两个限制：（1）压缩后文件大小仍不适用于大规模场景或场景集合；（2）缺乏对存档后场景变化的适应性机制。

Method: 提出了一种基于图像条件的高斯样条量化器（ICGS-Quantizer），通过联合利用高斯间和属性间的相关性，并使用跨场景共享的固定码书，显著提升了压缩效率。

Result: 实验结果表明，ICGS-Quantizer 能够将3D高斯样条的存储需求降至千字节级别，同时保持视觉保真度，并在场景更新任务中表现出色。

Conclusion: ICGS-Quantizer 在压缩效率和场景更新适应性方面均优于现有方法，为大规模场景的长期存档提供了实用解决方案。

Abstract: 3D Gaussian Splatting (3DGS) has attracted considerable attention for
enabling high-quality real-time rendering. Although 3DGS compression methods
have been proposed for deployment on storage-constrained devices, two
limitations hinder archival use: (1) they compress medium-scale scenes only to
the megabyte range, which remains impractical for large-scale scenes or
extensive scene collections; and (2) they lack mechanisms to accommodate scene
changes after long-term archival. To address these limitations, we propose an
Image-Conditioned Gaussian Splat Quantizer (ICGS-Quantizer) that substantially
enhances compression efficiency and provides adaptability to scene changes
after archiving. ICGS-Quantizer improves quantization efficiency by jointly
exploiting inter-Gaussian and inter-attribute correlations and by using shared
codebooks across all training scenes, which are then fixed and applied to
previously unseen test scenes, eliminating the overhead of per-scene codebooks.
This approach effectively reduces the storage requirements for 3DGS to the
kilobyte range while preserving visual fidelity. To enable adaptability to
post-archival scene changes, ICGS-Quantizer conditions scene decoding on images
captured at decoding time. The encoding, quantization, and decoding processes
are trained jointly, ensuring that the codes, which are quantized
representations of the scene, are effective for conditional decoding. We
evaluate ICGS-Quantizer on 3D scene compression and 3D scene updating.
Experimental results show that ICGS-Quantizer consistently outperforms
state-of-the-art methods in compression efficiency and adaptability to scene
changes. Our code, model, and data will be publicly available on GitHub.

</details>


### [5] [Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection](https://arxiv.org/abs/2508.14980)
*Andrei Balykin,Anvar Ganiev,Denis Kondranin,Kirill Polevoda,Nikolai Liudkevich,Artem Petrov*

Main category: cs.CV

TL;DR: 提出了一种统一的训练框架，通过配对采样对比学习模态无关的活体线索，显著降低了分类错误率，且轻量高效。


<details>
  <summary>Details</summary>
Motivation: 现代人脸识别系统仍易受物理和数字伪造攻击，传统方法需独立模型处理不同攻击向量，增加了系统复杂性和延迟。

Method: 采用配对采样对比框架，通过自动匹配的真实和攻击自拍照对学习模态无关的活体线索。

Result: 在第六届人脸反欺骗挑战赛的统一物理-数字攻击检测基准上，平均分类错误率（ACER）为2.10%，优于现有方案。

Conclusion: 提出的配对采样对比框架在统一训练方法中表现出色，显著降低了分类错误率，且具备轻量级和快速训练的特点，适合实际部署。

Abstract: Modern face recognition systems remain vulnerable to spoofing attempts,
including both physical presentation attacks and digital forgeries.
Traditionally, these two attack vectors have been handled by separate models,
each targeting its own artifacts and modalities. However, maintaining distinct
detectors increases system complexity and inference latency and leaves systems
exposed to combined attack vectors. We propose the Paired-Sampling Contrastive
Framework, a unified training approach that leverages automatically matched
pairs of genuine and attack selfies to learn modality-agnostic liveness cues.
Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital
Attack Detection benchmark, our method achieves an average classification error
rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is
lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for
real-world deployment. Code and pretrained models are available at
https://github.com/xPONYx/iccv2025_deepfake_challenge.

</details>


### [6] [TAIGen: Training-Free Adversarial Image Generation via Diffusion Models](https://arxiv.org/abs/2508.15020)
*Susim Roy,Anubhooti Jain,Mayank Vatsa,Richa Singh*

Main category: cs.CV

TL;DR: TAIGen是一种高效的对抗图像生成方法，仅需3-20步采样，攻击成功率高且速度快，同时保持图像质量。


<details>
  <summary>Details</summary>
Motivation: 生成式模型的对抗攻击通常生成低质量图像且计算资源消耗大，而扩散模型虽然能生成高质量图像，但需要数百步采样步骤。TAIGen旨在解决这些问题。

Method: TAIGen通过在混合步骤区间注入扰动，并结合选择性RGB通道策略（红色通道使用注意力图，绿色和蓝色通道使用GradCAM引导的扰动），实现了高效的对抗样本生成。

Result: TAIGen在ImageNet数据集上对VGGNet源的攻击成功率分别为：ResNet 70.6%、MNASNet 80.8%、ShuffleNet 97.8%，且PSNR高于30 dB，生成速度快10倍。

Conclusion: TAIGen是一种无需训练的高效黑盒对抗图像生成方法，能够在保持图像质量的同时显著提高攻击成功率，且生成速度比现有基于扩散模型的攻击方法快10倍。

Abstract: Adversarial attacks from generative models often produce low-quality images
and require substantial computational resources. Diffusion models, though
capable of high-quality generation, typically need hundreds of sampling steps
for adversarial generation. This paper introduces TAIGen, a training-free
black-box method for efficient adversarial image generation. TAIGen produces
adversarial examples using only 3-20 sampling steps from unconditional
diffusion models. Our key finding is that perturbations injected during the
mixing step interval achieve comparable attack effectiveness without processing
all timesteps. We develop a selective RGB channel strategy that applies
attention maps to the red channel while using GradCAM-guided perturbations on
green and blue channels. This design preserves image structure while maximizing
misclassification in target models. TAIGen maintains visual quality with PSNR
above 30 dB across all tested datasets. On ImageNet with VGGNet as source,
TAIGen achieves 70.6% success against ResNet, 80.8% against MNASNet, and 97.8%
against ShuffleNet. The method generates adversarial examples 10x faster than
existing diffusion-based attacks. Our method achieves the lowest robust
accuracy, indicating it is the most impactful attack as the defense mechanism
is least successful in purifying the images generated by TAIGen.

</details>


### [7] [Scaling Group Inference for Diverse and High-Quality Generation](https://arxiv.org/abs/2508.15773)
*Gaurav Parmar,Or Patashnik,Daniil Ostashev,Kuan-Chieh Wang,Kfir Aberman,Srinivasa Narasimhan,Jun-Yan Zhu*

Main category: cs.CV

TL;DR: 提出了一种可扩展的组推理方法，通过优化多样性和质量，解决了生成模型独立采样导致的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 在现实应用中，用户通常需要同时查看多个图像（如4-8个），而独立采样会导致冗余结果，限制用户选择和探索。

Method: 将组推理建模为二次整数分配问题，通过逐步剪枝候选集来提高运行效率。

Result: 实验表明，该方法在多样性和质量上显著优于独立采样基线和其他推理算法。

Conclusion: 本文提出了一种可扩展的组推理方法，显著提高了生成模型输出的多样性和质量，适用于多种任务。

Abstract: Generative models typically sample outputs independently, and recent
inference-time guidance and scaling algorithms focus on improving the quality
of individual samples. However, in real-world applications, users are often
presented with a set of multiple images (e.g., 4-8) for each prompt, where
independent sampling tends to lead to redundant results, limiting user choices
and hindering idea exploration. In this work, we introduce a scalable group
inference method that improves both the diversity and quality of a group of
samples. We formulate group inference as a quadratic integer assignment
problem: candidate outputs are modeled as graph nodes, and a subset is selected
to optimize sample quality (unary term) while maximizing group diversity
(binary term). To substantially improve runtime efficiency, we progressively
prune the candidate set using intermediate predictions, allowing our method to
scale up to large candidate sets. Extensive experiments show that our method
significantly improves group diversity and quality compared to independent
sampling baselines and recent inference algorithms. Our framework generalizes
across a wide range of tasks, including text-to-image, image-to-image, image
prompting, and video generation, enabling generative models to treat multiple
outputs as cohesive groups rather than independent samples.

</details>


### [8] [Reversible Unfolding Network for Concealed Visual Perception with Generative Refinement](https://arxiv.org/abs/2508.15027)
*Chunming He,Fengyang Xiao,Rihan Zhang,Chengyu Fang,Deng-Ping Fan,Sina Farsiu*

Main category: cs.CV

TL;DR: RUN++提出了一种结合可逆展开网络和生成式细化的隐蔽视觉感知方法，有效利用RGB域信息并通过针对性扩散模型优化结果。


<details>
  <summary>Details</summary>
Motivation: 现有CVP方法多局限于掩码域，RGB域的潜力未充分开发，且存在不确定性高的问题。

Method: RUN++首先将CVP任务表述为数学优化问题，并将迭代解展开为多阶段深度网络。网络每个阶段包含三个模块：CORE（掩码域可逆建模）、CARE（RGB域扩展）和FINE（噪声增强细化）。

Result: RUN++通过可逆建模和针对性扩散模型，显著减少了误报和漏报，并在真实世界退化条件下保持鲁棒性。

Conclusion: RUN++通过可逆展开网络和生成式细化，提出了一种新的隐蔽视觉感知方法，有效解决了RGB领域潜力未充分开发的问题，并通过针对性扩散模型减少了计算成本。

Abstract: Existing methods for concealed visual perception (CVP) often leverage
reversible strategies to decrease uncertainty, yet these are typically confined
to the mask domain, leaving the potential of the RGB domain underexplored. To
address this, we propose a reversible unfolding network with generative
refinement, termed RUN++. Specifically, RUN++ first formulates the CVP task as
a mathematical optimization problem and unfolds the iterative solution into a
multi-stage deep network. This approach provides a principled way to apply
reversible modeling across both mask and RGB domains while leveraging a
diffusion model to resolve the resulting uncertainty. Each stage of the network
integrates three purpose-driven modules: a Concealed Object Region Extraction
(CORE) module applies reversible modeling to the mask domain to identify core
object regions; a Context-Aware Region Enhancement (CARE) module extends this
principle to the RGB domain to foster better foreground-background separation;
and a Finetuning Iteration via Noise-based Enhancement (FINE) module provides a
final refinement. The FINE module introduces a targeted Bernoulli diffusion
model that refines only the uncertain regions of the segmentation mask,
harnessing the generative power of diffusion for fine-detail restoration
without the prohibitive computational cost of a full-image process. This unique
synergy, where the unfolding network provides a strong uncertainty prior for
the diffusion model, allows RUN++ to efficiently direct its focus toward
ambiguous areas, significantly mitigating false positives and negatives.
Furthermore, we introduce a new paradigm for building robust CVP systems that
remain effective under real-world degradations and extend this concept into a
broader bi-level optimization framework.

</details>


### [9] [GasTwinFormer: A Hybrid Vision Transformer for Livestock Methane Emission Segmentation and Dietary Classification in Optical Gas Imaging](https://arxiv.org/abs/2508.15057)
*Toqi Tahamid Sarker,Mohamed Embaby,Taminul Islam,Amer AbuGhazaleh,Khaled R Ahmed*

Main category: cs.CV

TL;DR: GasTwinFormer是一种高效混合视觉变换器，用于实时甲烷排放分割和饮食分类，在分割和分类任务中表现优异，且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 畜牧业甲烷排放占人为甲烷排放的32%，自动化监测对气候缓解策略至关重要。

Method: 采用混合视觉变换器GasTwinFormer，结合Mix Twin编码器和轻量级LR-ASPP解码器，实现多尺度特征聚合和实时处理。

Result: GasTwinFormer在分割任务中达到74.47% mIoU和83.63% mF1，饮食分类准确率为100%，参数仅3.348M，计算量3.428G FLOPs，推理速度114.9 FPS。

Conclusion: GasTwinFormer被证明是一种实用的实时牲畜排放监测解决方案，通过混合视觉变换器实现了高效的甲烷排放分割和饮食分类。

Abstract: Livestock methane emissions represent 32% of human-caused methane production,
making automated monitoring critical for climate mitigation strategies. We
introduce GasTwinFormer, a hybrid vision transformer for real-time methane
emission segmentation and dietary classification in optical gas imaging through
a novel Mix Twin encoder alternating between spatially-reduced global attention
and locally-grouped attention mechanisms. Our architecture incorporates a
lightweight LR-ASPP decoder for multi-scale feature aggregation and enables
simultaneous methane segmentation and dietary classification in a unified
framework. We contribute the first comprehensive beef cattle methane emission
dataset using OGI, containing 11,694 annotated frames across three dietary
treatments. GasTwinFormer achieves 74.47% mIoU and 83.63% mF1 for segmentation
while maintaining exceptional efficiency with only 3.348M parameters, 3.428G
FLOPs, and 114.9 FPS inference speed. Additionally, our method achieves perfect
dietary classification accuracy (100%), demonstrating the effectiveness of
leveraging diet-emission correlations. Extensive ablation studies validate each
architectural component, establishing GasTwinFormer as a practical solution for
real-time livestock emission monitoring. Please see our project page at
gastwinformer.github.io.

</details>


### [10] [Reliable Multi-view 3D Reconstruction for `Just-in-time' Edge Environments](https://arxiv.org/abs/2508.15158)
*Md. Nurul Absur,Abhinav Kumar,Swastik Brahma,Saptarshi Debroy*

Main category: cs.CV

TL;DR: 论文提出一种基于投资组合理论的边缘资源管理策略，使用遗传算法优化相机选择，确保在系统中断时仍能可靠完成多视角3D重建。


<details>
  <summary>Details</summary>
Motivation: 多视角3D重建应用在紧急响应等关键场景中需要实时性，但边缘环境的动态性和操作逆境可能导致重建质量持续下降。

Method: 采用遗传算法解决投资组合理论优化问题，快速收敛于实际系统设置。

Result: 通过公开和定制化的3D数据集验证，所提出的相机选择策略在时空中断下比传统基线策略更能保证可靠的3D重建。

Conclusion: 论文提出了一种基于投资组合理论启发的边缘资源管理策略，能够在面对系统中断时保证多视角3D重建的可靠性。

Abstract: Multi-view 3D reconstruction applications are revolutionizing critical use
cases that require rapid situational-awareness, such as emergency response,
tactical scenarios, and public safety. In many cases, their near-real-time
latency requirements and ad-hoc needs for compute resources necessitate
adoption of `Just-in-time' edge environments where the system is set up on the
fly to support the applications during the mission lifetime. However,
reliability issues can arise from the inherent dynamism and operational
adversities of such edge environments, resulting in spatiotemporally correlated
disruptions that impact the camera operations, which can lead to sustained
degradation of reconstruction quality. In this paper, we propose a novel
portfolio theory inspired edge resource management strategy for reliable
multi-view 3D reconstruction against possible system disruptions. Our proposed
methodology can guarantee reconstruction quality satisfaction even when the
cameras are prone to spatiotemporally correlated disruptions. The portfolio
theoretic optimization problem is solved using a genetic algorithm that
converges quickly for realistic system settings. Using publicly available and
customized 3D datasets, we demonstrate the proposed camera selection strategy's
benefits in guaranteeing reliable 3D reconstruction against traditional
baseline strategies, under spatiotemporal disruptions.

</details>


### [11] [CurveFlow: Curvature-Guided Flow Matching for Image Generation](https://arxiv.org/abs/2508.15093)
*Yan Luo,Drake Du,Hao Huang,Yi Fang,Mengyu Wang*

Main category: cs.CV

TL;DR: CurveFlow是一种新型流匹配框架，通过曲率指导提升文本到图像生成的语义一致性和质量，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有整流流模型基于线性轨迹，可能迫使图像生成过程通过数据流形的低概率区域，未充分探索轨迹曲率与生成图像语义对齐之间的关系。

Method: 提出了一种新颖的流匹配框架CurveFlow，通过直接纳入曲率指导来学习平滑、非线性的轨迹，并采用稳健的曲率正则化技术。

Result: 在MS COCO 2014和2017数据集上的实验表明，CurveFlow在文本到图像生成中表现优异，尤其在语义一致性指标（如BLEU、METEOR、ROUGE和CLAIR）上显著优于其他基线方法。

Conclusion: CurveFlow通过引入曲率指导的流匹配框架，显著提升了文本到图像生成任务的语义一致性和图像质量，实现了最先进的性能。

Abstract: Existing rectified flow models are based on linear trajectories between data
and noise distributions. This linearity enforces zero curvature, which can
inadvertently force the image generation process through low-probability
regions of the data manifold. A key question remains underexplored: how does
the curvature of these trajectories correlate with the semantic alignment
between generated images and their corresponding captions, i.e., instructional
compliance? To address this, we introduce CurveFlow, a novel flow matching
framework designed to learn smooth, non-linear trajectories by directly
incorporating curvature guidance into the flow path. Our method features a
robust curvature regularization technique that penalizes abrupt changes in the
trajectory's intrinsic dynamics.Extensive experiments on MS COCO 2014 and 2017
demonstrate that CurveFlow achieves state-of-the-art performance in
text-to-image generation, significantly outperforming both standard rectified
flow variants and other non-linear baselines like Rectified Diffusion. The
improvements are especially evident in semantic consistency metrics such as
BLEU, METEOR, ROUGE, and CLAIR. This confirms that our curvature-aware modeling
substantially enhances the model's ability to faithfully follow complex
instructions while simultaneously maintaining high image quality. The code is
made publicly available at
https://github.com/Harvard-AI-and-Robotics-Lab/CurveFlow.

</details>


### [12] [HiRQA: Hierarchical Ranking and Quality Alignment for Opinion-Unaware Image Quality Assessment](https://arxiv.org/abs/2508.15130)
*Vaishnav Ramesh,Haining Wang,Md Jahidul Islam*

Main category: cs.CV

TL;DR: HiRQA 是一种自监督的 NR-IQA 框架，通过排序和对比学习实现分层质量感知嵌入，无需参考图像或辅助模态，泛化能力强，且轻量级变体适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有的无参考图像质量评估（NR-IQA）方法受限于数据集偏差和主观标签依赖，导致泛化性能不足。HiRQA 旨在通过自监督学习解决这些问题。

Method: HiRQA 采用了一种新颖的高阶排序损失和监督质量预测的关系排序方法，结合嵌入距离损失和训练时对比对齐损失（通过结构化文本提示引导），从输入图像中预测质量分数。

Result: HiRQA 在合成和真实失真基准测试中表现出色，验证了其最先进的性能、强大的泛化能力和可扩展性。轻量级变体 HiRQA-S 的推理时间仅为每张图像 3.5 毫秒。

Conclusion: HiRQA 提出了一种自监督、无主观意见的框架，通过结合排序和对比学习，实现了对图像质量的分层感知嵌入。该方法不仅在合成失真上表现良好，还能有效泛化到真实失真场景，并通过轻量级变体 HiRQA-S 实现了实时部署。

Abstract: Despite significant progress in no-reference image quality assessment
(NR-IQA), dataset biases and reliance on subjective labels continue to hinder
their generalization performance. We propose HiRQA, Hierarchical Ranking and
Quality Alignment), a self-supervised, opinion-unaware framework that offers a
hierarchical, quality-aware embedding through a combination of ranking and
contrastive learning. Unlike prior approaches that depend on pristine
references or auxiliary modalities at inference time, HiRQA predicts quality
scores using only the input image. We introduce a novel higher-order ranking
loss that supervises quality predictions through relational ordering across
distortion pairs, along with an embedding distance loss that enforces
consistency between feature distances and perceptual differences. A
training-time contrastive alignment loss, guided by structured textual prompts,
further enhances the learned representation. Trained only on synthetic
distortions, HiRQA generalizes effectively to authentic degradations, as
demonstrated through evaluation on various distortions such as lens flare,
haze, motion blur, and low-light conditions. For real-time deployment, we
introduce \textbf{HiRQA-S}, a lightweight variant with an inference time of
only 3.5 ms per image. Extensive experiments across synthetic and authentic
benchmarks validate HiRQA's state-of-the-art (SOTA) performance, strong
generalization ability, and scalability.

</details>


### [13] [XDR-LVLM: An Explainable Vision-Language Large Model for Diabetic Retinopathy Diagnosis](https://arxiv.org/abs/2508.15168)
*Masato Ito,Kaito Tanaka,Keisuke Matsuda,Aya Nakayama*

Main category: cs.CV

TL;DR: XDR-LVLM是一个结合视觉-语言大模型的糖尿病视网膜病变诊断框架，通过生成自然语言解释提升透明度和临床实用性，实验显示其诊断和概念检测性能卓越。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变（DR）是全球盲症的主要原因，需要早期准确诊断。深度学习模型在DR检测中表现良好，但其黑盒特性因缺乏透明度和可解释性而阻碍临床采用。

Method: XDR-LVLM框架整合了专用医学视觉编码器、LVLM核心模块，并采用多任务提示工程和多阶段微调技术，深入理解眼底图像中的病理特征并生成全面的诊断报告。

Result: 在DDR数据集上的实验显示，XDR-LVLM在疾病诊断（平衡准确率84.55%，F1分数79.92%）和概念检测（平衡准确率77.95%，F1分数66.88%）上均达到最先进水平。人类评估证实生成的解释具有高流畅性、准确性和临床实用性。

Conclusion: XDR-LVLM通过结合视觉-语言大模型和多阶段微调，不仅实现了高精度的糖尿病视网膜病变诊断，还生成了具有临床实用性的自然语言解释，显著提升了模型的透明度和可解释性。

Abstract: Diabetic Retinopathy (DR) is a major cause of global blindness, necessitating
early and accurate diagnosis. While deep learning models have shown promise in
DR detection, their black-box nature often hinders clinical adoption due to a
lack of transparency and interpretability. To address this, we propose XDR-LVLM
(eXplainable Diabetic Retinopathy Diagnosis with LVLM), a novel framework that
leverages Vision-Language Large Models (LVLMs) for high-precision DR diagnosis
coupled with natural language-based explanations. XDR-LVLM integrates a
specialized Medical Vision Encoder, an LVLM Core, and employs Multi-task Prompt
Engineering and Multi-stage Fine-tuning to deeply understand pathological
features within fundus images and generate comprehensive diagnostic reports.
These reports explicitly include DR severity grading, identification of key
pathological concepts (e.g., hemorrhages, exudates, microaneurysms), and
detailed explanations linking observed features to the diagnosis. Extensive
experiments on the Diabetic Retinopathy (DDR) dataset demonstrate that XDR-LVLM
achieves state-of-the-art performance, with a Balanced Accuracy of 84.55% and
an F1 Score of 79.92% for disease diagnosis, and superior results for concept
detection (77.95% BACC, 66.88% F1). Furthermore, human evaluations confirm the
high fluency, accuracy, and clinical utility of the generated explanations,
showcasing XDR-LVLM's ability to bridge the gap between automated diagnosis and
clinical needs by providing robust and interpretable insights.

</details>


### [14] [MeSS: City Mesh-Guided Outdoor Scene Generation with Cross-View Consistent Diffusion](https://arxiv.org/abs/2508.15169)
*Xuyang Chen,Zhijun Zhai,Kaixuan Zhou,Zengmao Wang,Jianan He,Dong Wang,Yanfeng Zhang,mingwei Sun,Rüdiger Westermann,Konrad Schindler,Liqiu Meng*

Main category: cs.CV

TL;DR: MeSS通过改进的图像扩散模型和3D高斯溅射技术，生成高质量且风格一致的3D城市场景，解决了现有方法在几何对齐和视觉一致性上的不足。


<details>
  <summary>Details</summary>
Motivation: 城市网格模型缺乏真实纹理，限制了其在虚拟城市导航和自动驾驶中的应用。现有图像和视频扩散模型在3D场景生成中存在局限性，无法保证跨视图一致性和几何对齐。

Method: 提出了MeSS（基于网格的场景合成）方法，通过三个关键阶段（稀疏视图生成、中间视图传播和全局一致性调整）结合ControlNet和3D高斯溅射技术，生成高质量且风格一致的户外场景。

Result: 提出的方法在几何对齐和生成质量上优于现有方法，生成的场景可通过重光照和风格转换技术呈现多样化的渲染效果。

Conclusion: 该方法通过结合图像扩散模型和3D高斯溅射技术，显著提升了场景生成的几何对齐和视觉一致性，为虚拟城市导航和自动驾驶提供了高质量的3D场景。

Abstract: Mesh models have become increasingly accessible for numerous cities; however,
the lack of realistic textures restricts their application in virtual urban
navigation and autonomous driving. To address this, this paper proposes MeSS
(Meshbased Scene Synthesis) for generating high-quality, styleconsistent
outdoor scenes with city mesh models serving as the geometric prior. While
image and video diffusion models can leverage spatial layouts (such as depth
maps or HD maps) as control conditions to generate street-level perspective
views, they are not directly applicable to 3D scene generation. Video diffusion
models excel at synthesizing consistent view sequences that depict scenes but
often struggle to adhere to predefined camera paths or align accurately with
rendered control videos. In contrast, image diffusion models, though unable to
guarantee cross-view visual consistency, can produce more geometry-aligned
results when combined with ControlNet. Building on this insight, our approach
enhances image diffusion models by improving cross-view consistency. The
pipeline comprises three key stages: first, we generate geometrically
consistent sparse views using Cascaded Outpainting ControlNets; second, we
propagate denser intermediate views via a component dubbed AGInpaint; and
third, we globally eliminate visual inconsistencies (e.g., varying exposure)
using the GCAlign module. Concurrently with generation, a 3D Gaussian Splatting
(3DGS) scene is reconstructed by initializing Gaussian balls on the mesh
surface. Our method outperforms existing approaches in both geometric alignment
and generation quality. Once synthesized, the scene can be rendered in diverse
styles through relighting and style transfer techniques.

</details>


### [15] [SurgWound-Bench: A Benchmark for Surgical Wound Diagnosis](https://arxiv.org/abs/2508.15189)
*Jiahao Xu,Changchang Yin,Odysseas Chatzipanagiotou,Diamantis Tsilimigras,Kevin Clear,Bingsheng Yao,Dakuo Wang,Timothy Pawlik,Ping Zhang*

Main category: cs.CV

TL;DR: 该研究填补了手术伤口筛查工具和公开数据集的空白，提出了SurgWound数据集和WoundQwen三阶段学习框架，为个性化护理和SSI预防提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 手术部位感染（SSI）是常见且高成本的医疗相关感染，当前缺乏公开数据集和开源筛查工具。研究旨在填补这一空白，推动个性化伤口护理。

Method: 研究分为三阶段：首先使用五个独立的MLLM预测手术伤口特征；其次将预测结果作为知识输入给两个MLLM进行感染风险评估和干预指导；最后训练一个MLLM整合前两阶段结果生成综合报告。

Result: 提出了SurgWound数据集（包含697张标注图像）、首个手术伤口诊断基准（包括VQA和报告生成任务）以及WoundQwen框架，能分析伤口特征并提供个性化护理建议。

Conclusion: 该研究通过提出SurgWound数据集、首个手术伤口诊断基准以及WoundQwen三阶段学习框架，为个性化伤口护理和及时干预提供了新工具，有望改善患者预后。

Abstract: Surgical site infection (SSI) is one of the most common and costly
healthcare-associated infections and and surgical wound care remains a
significant clinical challenge in preventing SSIs and improving patient
outcomes. While recent studies have explored the use of deep learning for
preliminary surgical wound screening, progress has been hindered by concerns
over data privacy and the high costs associated with expert annotation.
Currently, no publicly available dataset or benchmark encompasses various types
of surgical wounds, resulting in the absence of an open-source Surgical-Wound
screening tool. To address this gap: (1) we present SurgWound, the first
open-source dataset featuring a diverse array of surgical wound types. It
contains 697 surgical wound images annotated by 3 professional surgeons with
eight fine-grained clinical attributes. (2) Based on SurgWound, we introduce
the first benchmark for surgical wound diagnosis, which includes visual
question answering (VQA) and report generation tasks to comprehensively
evaluate model performance. (3) Furthermore, we propose a three-stage learning
framework, WoundQwen, for surgical wound diagnosis. In the first stage, we
employ five independent MLLMs to accurately predict specific surgical wound
characteristics. In the second stage, these predictions serve as additional
knowledge inputs to two MLLMs responsible for diagnosing outcomes, which assess
infection risk and guide subsequent interventions. In the third stage, we train
a MLLM that integrates the diagnostic results from the previous two stages to
produce a comprehensive report. This three-stage framework can analyze detailed
surgical wound characteristics and provide subsequent instructions to patients
based on surgical images, paving the way for personalized wound care, timely
intervention, and improved patient outcomes.

</details>


### [16] [Adversarial Agent Behavior Learning in Autonomous Driving Using Deep Reinforcement Learning](https://arxiv.org/abs/2508.15207)
*Arjun Srinivasan,Anubhav Paras,Aniket Bera*

Main category: cs.CV

TL;DR: 本文提出了一种学习方法来生成对抗性行为，验证其在降低规则基础智能体累积奖励方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用（如自动驾驶）中，规则基础智能体的行为建模至关重要，现有方法可能存在不足。

Method: 采用学习方法来推导规则基础智能体的对抗性行为，以引发失败场景。

Result: 评估显示，对抗性智能体能够显著降低规则基础智能体的累积奖励。

Conclusion: 本文提出了一种基于学习的方法来生成对抗性行为，以模拟规则基础智能体在安全关键应用中的失败场景，并验证了其有效性。

Abstract: Existing approaches in reinforcement learning train an agent to learn desired
optimal behavior in an environment with rule based surrounding agents. In
safety critical applications such as autonomous driving it is crucial that the
rule based agents are modelled properly. Several behavior modelling strategies
and IDM models are used currently to model the surrounding agents. We present a
learning based method to derive the adversarial behavior for the rule based
agents to cause failure scenarios. We evaluate our adversarial agent against
all the rule based agents and show the decrease in cumulative reward.

</details>


### [17] [DyMorph-B2I: Dynamic and Morphology-Guided Binary-to-Instance Segmentation for Renal Pathology](https://arxiv.org/abs/2508.15208)
*Leiyue Zhao,Yuechen Yang,Yanfan Zhu,Haichun Yang,Yuankai Huo,Paul D. Simonson,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: DyMorph-B2I 是一种动态、形态学指导的肾病理学二进制到实例分割流程，通过结合多种传统技术并优化参数，显著提升了分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有的肾病理学数据集和自动化方法通常仅提供二进制（语义）掩码，限制了后续分析的精确性。传统的后处理技术在分离语义掩码为实例时效果有限，因为肾组织的形态多样且连接复杂。

Method: 本研究提出了一种名为 DyMorph-B2I 的动态、形态学指导的二进制到实例分割流程，结合了分水岭、骨架化和形态学操作，并通过自适应几何优化和可定制超参数调整来适应不同功能单元类别。

Result: 实验结果表明，DyMorph-B2I 在分离粘连和异质结构方面优于单一的传统方法及其简单组合，显著提升了实例分割的效果。

Conclusion: DyMorph-B2I 通过动态、形态学指导的二进制到实例分割流程，显著提升了肾病理学中的实例分割精度，为下游形态学分析提供了更准确的数据支持。

Abstract: Accurate morphological quantification of renal pathology functional units
relies on instance-level segmentation, yet most existing datasets and automated
methods provide only binary (semantic) masks, limiting the precision of
downstream analyses. Although classical post-processing techniques such as
watershed, morphological operations, and skeletonization, are often used to
separate semantic masks into instances, their individual effectiveness is
constrained by the diverse morphologies and complex connectivity found in renal
tissue. In this study, we present DyMorph-B2I, a dynamic, morphology-guided
binary-to-instance segmentation pipeline tailored for renal pathology. Our
approach integrates watershed, skeletonization, and morphological operations
within a unified framework, complemented by adaptive geometric refinement and
customizable hyperparameter tuning for each class of functional unit. Through
systematic parameter optimization, DyMorph-B2I robustly separates adherent and
heterogeneous structures present in binary masks. Experimental results
demonstrate that our method outperforms individual classical approaches and
na\"ive combinations, enabling superior instance separation and facilitating
more accurate morphometric analysis in renal pathology workflows. The pipeline
is publicly available at: https://github.com/ddrrnn123/DyMorph-B2I.

</details>


### [18] [STAGNet: A Spatio-Temporal Graph and LSTM Framework for Accident Anticipation](https://arxiv.org/abs/2508.15216)
*Vipooshan Vipulananthan,Kumudu Mohottala,Kavindu Chinthana,Nimsara Paramulla,Charith D Chitraranjan*

Main category: cs.CV

TL;DR: STAGNet模型通过改进时空特征聚合，显著提升行车记录仪视频事故预测性能，验证了其经济性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有ADAS系统多依赖多种传感器，成本高且部署复杂，而仅依赖行车记录仪视频的解决方案更具挑战性但更经济实用。

Method: 结合时空特征并通过循环网络聚合，改进现有的图神经网络方法，提出STAGNet模型。

Result: 在三个公开数据集上，STAGNet模型的平均精度和平均碰撞时间值均优于现有方法，无论是跨数据集验证还是不同数据集训练测试。

Conclusion: STAGNet模型通过整合更好的时空特征并通过循环网络聚合，显著提高了基于行车记录仪视频的事故预测性能，在多个公开数据集上验证了其优越性。

Abstract: Accident prediction and timely warnings play a key role in improving road
safety by reducing the risk of injury to road users and minimizing property
damage. Advanced Driver Assistance Systems (ADAS) are designed to support human
drivers and are especially useful when they can anticipate potential accidents
before they happen. While many existing systems depend on a range of sensors
such as LiDAR, radar, and GPS, relying solely on dash-cam video input presents
a more challenging but a more cost-effective and easily deployable solution. In
this work, we incorporate better spatio-temporal features and aggregate them
through a recurrent network to improve upon state-of-the-art graph neural
networks for predicting accidents from dash-cam videos. Experiments using three
publicly available datasets show that our proposed STAGNet model achieves
higher average precision and mean time-to-collision values than previous
methods, both when cross-validated on a given dataset and when trained and
tested on different datasets.

</details>


### [19] [Collaborative Multi-Modal Coding for High-Quality 3D Generation](https://arxiv.org/abs/2508.15228)
*Ziang Cao,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: TriMM是首个基于多模态数据（如RGB、RGBD和点云）的前馈式3D原生生成模型，通过协作多模态编码和三平面潜在扩散模型，显著提升了3D资产的纹理和几何细节质量。


<details>
  <summary>Details</summary>
Motivation: 现有3D原生生成架构大多局限于单模态范式或3D结构，忽略了多模态数据的互补优势，限制了可用训练数据集的范围。

Method: TriMM引入协作多模态编码，整合模态特定特征，同时保留其独特的表示优势；引入辅助2D和3D监督以提高多模态编码的鲁棒性和性能；基于嵌入的多模态代码，采用三平面潜在扩散模型生成高质量的3D资产。

Result: TriMM在多个知名数据集上的实验表明，通过有效利用多模态数据，其在少量训练数据的情况下实现了与大规模数据集训练的模型相竞争的性能。

Conclusion: TriMM通过有效利用多模态数据，在少量训练数据的情况下，实现了与大规模数据集训练的模型相竞争的性能，并验证了将其他多模态数据集纳入3D生成的可行性。

Abstract: 3D content inherently encompasses multi-modal characteristics and can be
projected into different modalities (e.g., RGB images, RGBD, and point clouds).
Each modality exhibits distinct advantages in 3D asset modeling: RGB images
contain vivid 3D textures, whereas point clouds define fine-grained 3D
geometries. However, most existing 3D-native generative architectures either
operate predominantly within single-modality paradigms-thus overlooking the
complementary benefits of multi-modality data-or restrict themselves to 3D
structures, thereby limiting the scope of available training datasets. To
holistically harness multi-modalities for 3D modeling, we present TriMM, the
first feed-forward 3D-native generative model that learns from basic
multi-modalities (e.g., RGB, RGBD, and point cloud). Specifically, 1) TriMM
first introduces collaborative multi-modal coding, which integrates
modality-specific features while preserving their unique representational
strengths. 2) Furthermore, auxiliary 2D and 3D supervision are introduced to
raise the robustness and performance of multi-modal coding. 3) Based on the
embedded multi-modal code, TriMM employs a triplane latent diffusion model to
generate 3D assets of superior quality, enhancing both the texture and the
geometric detail. Extensive experiments on multiple well-known datasets
demonstrate that TriMM, by effectively leveraging multi-modality, achieves
competitive performance with models trained on large-scale datasets, despite
utilizing a small amount of training data. Furthermore, we conduct additional
experiments on recent RGB-D datasets, verifying the feasibility of
incorporating other multi-modal datasets into 3D generation.

</details>


### [20] [Center-Oriented Prototype Contrastive Clustering](https://arxiv.org/abs/2508.15231)
*Shihao Dong,Xiaotong Zhou,Yuhui Zheng,Huiying Xu,Xinzhong Zhu*

Main category: cs.CV

TL;DR: 提出了一种中心导向原型对比聚类框架（CPCC），通过软原型对比和双一致性学习解决原型偏差问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过原型对比解决聚类任务中的类间冲突问题，但硬原型的计算与真实聚类中心存在偏差，导致效果不佳。

Method: 框架包含软原型对比模块和双一致性学习模块。软原型对比模块通过样本属于聚类中心的概率作为权重计算原型，减少原型漂移；双一致性学习模块通过对齐样本的不同变换和邻域，确保特征具有变换不变的语义信息和紧凑的簇内分布。

Result: 在五个数据集上的实验表明，该方法优于现有SOTA方法。

Conclusion: 提出的中心导向原型对比聚类框架（CPCC）通过软原型对比模块和双一致性学习模块，有效解决了现有方法中硬原型计算与真实聚类中心之间的偏差问题，并在五个数据集上验证了其有效性。

Abstract: Contrastive learning is widely used in clustering tasks due to its
discriminative representation. However, the conflict problem between classes is
difficult to solve effectively. Existing methods try to solve this problem
through prototype contrast, but there is a deviation between the calculation of
hard prototypes and the true cluster center. To address this problem, we
propose a center-oriented prototype contrastive clustering framework, which
consists of a soft prototype contrastive module and a dual consistency learning
module. In short, the soft prototype contrastive module uses the probability
that the sample belongs to the cluster center as a weight to calculate the
prototype of each category, while avoiding inter-class conflicts and reducing
prototype drift. The dual consistency learning module aligns different
transformations of the same sample and the neighborhoods of different samples
respectively, ensuring that the features have transformation-invariant semantic
information and compact intra-cluster distribution, while providing reliable
guarantees for the calculation of prototypes. Extensive experiments on five
datasets show that the proposed method is effective compared to the SOTA. Our
code is published on https://github.com/LouisDong95/CPCC.

</details>


### [21] [AeroDuo: Aerial Duo for UAV-based Vision and Language Navigation](https://arxiv.org/abs/2508.15232)
*Ruipu Wu,Yige Zhang,Jinyu Chen,Linjiang Huang,Shifeng Zhang,Xu Zhou,Liang Wang,Si Liu*

Main category: cs.CV

TL;DR: 论文提出双高度无人机协作任务DuAl-VLN和AeroDuo框架，通过高低无人机协作解决导航挑战，并构建HaL-13k数据集验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 无人机视觉与语言导航（VLN）由于轨迹长和机动性复杂，性能难以保证且常需人工干预或过于详细的指令。无人机的高机动性虽能提供多粒度视角，但需保持可控的运动空间。

Method: 论文引入了双高度无人机协作任务（DuAl-VLN），构建了HaL-13k数据集，并提出了AeroDuo框架，其中高海拔无人机使用多模态大语言模型（Pilot-LLM）进行目标推理，低海拔无人机采用轻量级多阶段策略进行导航和目标定位。

Result: 论文构建了包含13,838条协作高低无人机演示轨迹的HaL-13k数据集，并验证了AeroDuo框架在新环境和陌生目标上的泛化能力。

Conclusion: 论文提出了一种名为DuAl-VLN的新任务，通过双高度无人机协作解决了无人机视觉与语言导航中的挑战，并展示了AeroDuo框架的有效性。

Abstract: Aerial Vision-and-Language Navigation (VLN) is an emerging task that enables
Unmanned Aerial Vehicles (UAVs) to navigate outdoor environments using natural
language instructions and visual cues. However, due to the extended
trajectories and complex maneuverability of UAVs, achieving reliable UAV-VLN
performance is challenging and often requires human intervention or overly
detailed instructions. To harness the advantages of UAVs' high mobility, which
could provide multi-grained perspectives, while maintaining a manageable motion
space for learning, we introduce a novel task called Dual-Altitude UAV
Collaborative VLN (DuAl-VLN). In this task, two UAVs operate at distinct
altitudes: a high-altitude UAV responsible for broad environmental reasoning,
and a low-altitude UAV tasked with precise navigation. To support the training
and evaluation of the DuAl-VLN, we construct the HaL-13k, a dataset comprising
13,838 collaborative high-low UAV demonstration trajectories, each paired with
target-oriented language instructions. This dataset includes both unseen maps
and an unseen object validation set to systematically evaluate the model's
generalization capabilities across novel environments and unfamiliar targets.
To consolidate their complementary strengths, we propose a dual-UAV
collaborative VLN framework, AeroDuo, where the high-altitude UAV integrates a
multimodal large language model (Pilot-LLM) for target reasoning, while the
low-altitude UAV employs a lightweight multi-stage policy for navigation and
target grounding. The two UAVs work collaboratively and only exchange minimal
coordinate information to ensure efficiency.

</details>


### [22] [Pretrained Diffusion Models Are Inherently Skipped-Step Samplers](https://arxiv.org/abs/2508.15233)
*Wenju Xu*

Main category: cs.CV

TL;DR: 本文提出跳过步采样机制，证明标准扩散模型可通过马尔可夫方式高效采样，并与DDIM结合提升生成效率，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 扩散模型虽在生成任务中表现优异，但其顺序生成过程需长序列逐步生成，效率较低。现有方法（如DDIM）尝试减少采样步骤，但缺乏对原始扩散过程是否能在不依赖非马尔可夫过程下实现相同效率的探讨。

Method: 提出跳过步采样机制，绕过迭代生成过程中的多个中间去噪步骤，并与DDIM结合形成增强生成方法。

Result: 在OpenAI ADM、Stable Diffusion和Open Sora等模型上的实验表明，该方法能以显著减少的采样步骤实现高质量生成。

Conclusion: 本文通过引入跳过步采样机制，证明了无需依赖非马尔可夫过程即可实现高效采样，且该机制与标准扩散模型的训练目标一致。结合DDIM的增强生成方法，实验表明在显著减少采样步骤的同时仍能保持高质量生成。

Abstract: Diffusion models have been achieving state-of-the-art results across various
generation tasks. However, a notable drawback is their sequential generation
process, requiring long-sequence step-by-step generation. Existing methods,
such as DDIM, attempt to reduce sampling steps by constructing a class of
non-Markovian diffusion processes that maintain the same training objective.
However, there remains a gap in understanding whether the original diffusion
process can achieve the same efficiency without resorting to non-Markovian
processes. In this paper, we provide a confirmative answer and introduce
skipped-step sampling, a mechanism that bypasses multiple intermediate
denoising steps in the iterative generation process, in contrast with the
traditional step-by-step refinement of standard diffusion inference. Crucially,
we demonstrate that this skipped-step sampling mechanism is derived from the
same training objective as the standard diffusion model, indicating that
accelerated sampling via skipped-step sampling via a Markovian way is an
intrinsic property of pretrained diffusion models. Additionally, we propose an
enhanced generation method by integrating our accelerated sampling technique
with DDIM. Extensive experiments on popular pretrained diffusion models,
including the OpenAI ADM, Stable Diffusion, and Open Sora models, show that our
method achieves high-quality generation with significantly reduced sampling
steps.

</details>


### [23] [Comp-X: On Defining an Interactive Learned Image Compression Paradigm With Expert-driven LLM Agent](https://arxiv.org/abs/2508.15243)
*Yixin Gao,Xin Li,Xiaohan Pan,Runsen Feng,Bingchen Li,Yunpeng Qi,Yiting Lu,Zhengxue Cheng,Zhibo Chen,Jörn Ostermann*

Main category: cs.CV

TL;DR: Comp-X是首个基于LLM代理的智能交互式图像压缩范式，通过多功能框架、交互代理和专用基准，实现了高效的编码理解和交互能力。


<details>
  <summary>Details</summary>
Motivation: 传统图像编解码器编码模式有限且依赖人工选择，对非专业用户不友好，因此提出智能交互式图像压缩范式。

Method: 提出了三个关键创新：(i) 多功能编码框架，统一不同编码模式；(ii) 交互式编码代理，通过增强的上下文学习方法指导LLM代理；(iii) 首个专门基准IIC-bench，用于评估智能交互式图像压缩。

Result: 实验证明Comp-X能高效理解编码请求并实现出色的文本交互能力，同时保持可比的压缩性能。

Conclusion: Comp-X通过引入多功能编码框架、交互式编码代理和IIC-bench基准，展示了在图像压缩领域的潜力，为AGI在图像压缩中的应用提供了新方向。

Abstract: We present Comp-X, the first intelligently interactive image compression
paradigm empowered by the impressive reasoning capability of large language
model (LLM) agent. Notably, commonly used image codecs usually suffer from
limited coding modes and rely on manual mode selection by engineers, making
them unfriendly for unprofessional users. To overcome this, we advance the
evolution of image coding paradigm by introducing three key innovations: (i)
multi-functional coding framework, which unifies different coding modes of
various objective/requirements, including human-machine perception, variable
coding, and spatial bit allocation, into one framework. (ii) interactive coding
agent, where we propose an augmented in-context learning method with coding
expert feedback to teach the LLM agent how to understand the coding request,
mode selection, and the use of the coding tools. (iii) IIC-bench, the first
dedicated benchmark comprising diverse user requests and the corresponding
annotations from coding experts, which is systematically designed for
intelligently interactive image compression evaluation. Extensive experimental
results demonstrate that our proposed Comp-X can understand the coding requests
efficiently and achieve impressive textual interaction capability. Meanwhile,
it can maintain comparable compression performance even with a single coding
framework, providing a promising avenue for artificial general intelligence
(AGI) in image compression.

</details>


### [24] [Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images](https://arxiv.org/abs/2508.15256)
*Jinsol Song,Jiamu Wang,Anh Tien Nguyen,Keunho Byeon,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak*

Main category: cs.CV

TL;DR: Ano-NAViLa是一种结合病理知识的视觉-语言模型，显著提升了病理图像异常检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有异常检测方法在病理学中因计算限制、组织多样性及缺乏可解释性而面临的挑战。

Method: Ano-NAViLa基于预训练的视觉-语言模型，结合轻量级可训练MLP，整合了正常和异常病理知识。

Result: 在两个淋巴结数据集上，Ano-NAViLa实现了最先进的异常检测和定位性能。

Conclusion: Ano-NAViLa在病理图像异常检测和定位中表现出色，超越了现有模型，成为该领域的最新标杆。

Abstract: Anomaly detection in computational pathology aims to identify rare and scarce
anomalies where disease-related data are often limited or missing. Existing
anomaly detection methods, primarily designed for industrial settings, face
limitations in pathology due to computational constraints, diverse tissue
structures, and lack of interpretability. To address these challenges, we
propose Ano-NAViLa, a Normal and Abnormal pathology knowledge-augmented
Vision-Language model for Anomaly detection in pathology images. Ano-NAViLa is
built on a pre-trained vision-language model with a lightweight trainable MLP.
By incorporating both normal and abnormal pathology knowledge, Ano-NAViLa
enhances accuracy and robustness to variability in pathology images and
provides interpretability through image-text associations. Evaluated on two
lymph node datasets from different organs, Ano-NAViLa achieves the
state-of-the-art performance in anomaly detection and localization,
outperforming competing models.

</details>


### [25] [RATopo: Improving Lane Topology Reasoning via Redundancy Assignment](https://arxiv.org/abs/2508.15272)
*Han Li,Shaofei Huang,Longfei Xu,Yulu Gao,Beipeng Mu,Si Liu*

Main category: cs.CV

TL;DR: 提出RATopo策略，通过冗余分配和几何多样性监督提升车道拓扑推理性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于一对一分配的监督策略导致拓扑推理性能受限，因此需要一种能够提供数量丰富和几何多样性监督的新策略。

Method: 通过重构Transformer解码器，交换交叉注意力和自注意力层，保留冗余车道预测以实现一对多分配，并实例化多个并行交叉注意力块以增强车道检测的多样性。

Result: 在OpenLane-V2数据集上的实验表明，RATopo策略能持续提升车道-车道和车道-交通拓扑性能。

Conclusion: RATopo策略通过冗余分配和几何多样性监督，显著提升了车道拓扑推理的性能，且具有模型无关性，可无缝集成到现有框架中。

Abstract: Lane topology reasoning plays a critical role in autonomous driving by
modeling the connections among lanes and the topological relationships between
lanes and traffic elements. Most existing methods adopt a
first-detect-then-reason paradigm, where topological relationships are
supervised based on the one-to-one assignment results obtained during the
detection stage. This supervision strategy results in suboptimal topology
reasoning performance due to the limited range of valid supervision. In this
paper, we propose RATopo, a Redundancy Assignment strategy for lane Topology
reasoning that enables quantity-rich and geometry-diverse topology supervision.
Specifically, we restructure the Transformer decoder by swapping the
cross-attention and self-attention layers. This allows redundant lane
predictions to be retained before suppression, enabling effective one-to-many
assignment. We also instantiate multiple parallel cross-attention blocks with
independent parameters, which further enhances the diversity of detected lanes.
Extensive experiments on OpenLane-V2 demonstrate that our RATopo strategy is
model-agnostic and can be seamlessly integrated into existing topology
reasoning frameworks, consistently improving both lane-lane and lane-traffic
topology performance.

</details>


### [26] [DesignCLIP: Multimodal Learning with CLIP for Design Patent Understanding](https://arxiv.org/abs/2508.15297)
*Zhu Wang,Homaira Huda Shomee,Sathya N. Ravi,Sourav Medya*

Main category: cs.CV

TL;DR: DesignCLIP利用CLIP模型和多模态学习，显著提升专利分类和检索性能，展示了多模态方法在专利分析中的优势。


<details>
  <summary>Details</summary>
Motivation: 传统专利分析依赖图像数据，但专利图像往往缺乏全面的视觉和语义信息，导致评估模糊。CLIP等视觉语言模型为更可靠的AI驱动专利分析提供了机会。

Method: 利用CLIP模型开发了DesignCLIP框架，结合类感知分类和对比学习，使用生成的详细图像描述和多视角图像学习。

Result: DesignCLIP在所有任务中均优于基准和SOTA模型，验证了其在专利分类和检索中的有效性。

Conclusion: DesignCLIP展示了多模态方法在专利分析中的潜力，通过结合CLIP模型和专利数据的独特特性，显著提升了专利分类和检索的性能。

Abstract: In the field of design patent analysis, traditional tasks such as patent
classification and patent image retrieval heavily depend on the image data.
However, patent images -- typically consisting of sketches with abstract and
structural elements of an invention -- often fall short in conveying
comprehensive visual context and semantic information. This inadequacy can lead
to ambiguities in evaluation during prior art searches. Recent advancements in
vision-language models, such as CLIP, offer promising opportunities for more
reliable and accurate AI-driven patent analysis. In this work, we leverage CLIP
models to develop a unified framework DesignCLIP for design patent applications
with a large-scale dataset of U.S. design patents. To address the unique
characteristics of patent data, DesignCLIP incorporates class-aware
classification and contrastive learning, utilizing generated detailed captions
for patent images and multi-views image learning. We validate the effectiveness
of DesignCLIP across various downstream tasks, including patent classification
and patent retrieval. Additionally, we explore multimodal patent retrieval,
which provides the potential to enhance creativity and innovation in design by
offering more diverse sources of inspiration. Our experiments show that
DesignCLIP consistently outperforms baseline and SOTA models in the patent
domain on all tasks. Our findings underscore the promise of multimodal
approaches in advancing patent analysis. The codebase is available here:
https://anonymous.4open.science/r/PATENTCLIP-4661/README.md.

</details>


### [27] [TPA: Temporal Prompt Alignment for Fetal Congenital Heart Defect Classification](https://arxiv.org/abs/2508.15298)
*Darya Taratynova,Alya Almsouti,Beknur Kalmakhanbet,Numan Saeed,Mohammad Yaqub*

Main category: cs.CV

TL;DR: TPA 是一种结合时序建模和对比学习的方法，显著提升了 CHD 分类的准确性和校准性。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏缺陷（CHD）在超声视频中的检测受到图像噪声和探头位置变异性的阻碍。当前机器学习方法常忽略时序信息、仅限于二元分类且未考虑预测校准。

Method: TPA 利用基础图像-文本模型和提示感知对比学习来分类胎儿 CHD。它通过图像编码器提取视频子片段每帧的特征，用可训练的时序提取器聚合这些特征以捕捉心脏运动，并通过边缘铰链对比损失将视频表示与类别特定文本提示对齐。

Result: 在 CHD 检测的私有数据集和 EchoNet-Dynamic 公共数据集上，TPA 实现了 85.40% 的宏观 F1 分数，同时将预期校准误差降低了 5.38%，自适应 ECE 降低了 6.8%。在 EchoNet-Dynamic 的三分类任务中，宏观 F1 提高了 4.73%（从 53.89% 到 58.62%）。

Conclusion: Temporal Prompt Alignment (TPA) 是一个整合了时序建模、提示感知对比学习和不确定性量化的框架，用于超声视频中的胎儿先天性心脏缺陷（CHD）分类。

Abstract: Congenital heart defect (CHD) detection in ultrasound videos is hindered by
image noise and probe positioning variability. While automated methods can
reduce operator dependence, current machine learning approaches often neglect
temporal information, limit themselves to binary classification, and do not
account for prediction calibration. We propose Temporal Prompt Alignment (TPA),
a method leveraging foundation image-text model and prompt-aware contrastive
learning to classify fetal CHD on cardiac ultrasound videos. TPA extracts
features from each frame of video subclips using an image encoder, aggregates
them with a trainable temporal extractor to capture heart motion, and aligns
the video representation with class-specific text prompts via a margin-hinge
contrastive loss. To enhance calibration for clinical reliability, we introduce
a Conditional Variational Autoencoder Style Modulation (CVAESM) module, which
learns a latent style vector to modulate embeddings and quantifies
classification uncertainty. Evaluated on a private dataset for CHD detection
and on a large public dataset, EchoNet-Dynamic, for systolic dysfunction, TPA
achieves state-of-the-art macro F1 scores of 85.40% for CHD diagnosis, while
also reducing expected calibration error by 5.38% and adaptive ECE by 6.8%. On
EchoNet-Dynamic's three-class task, it boosts macro F1 by 4.73% (from 53.89% to
58.62%). Temporal Prompt Alignment (TPA) is a framework for fetal congenital
heart defect (CHD) classification in ultrasound videos that integrates temporal
modeling, prompt-aware contrastive learning, and uncertainty quantification.

</details>


### [28] [BasketLiDAR: The First LiDAR-Camera Multimodal Dataset for Professional Basketball MOT](https://arxiv.org/abs/2508.15299)
*Ryunosuke Hayashi,Kohei Torimi,Rokuto Nagata,Kazuma Ikeda,Ozora Sako,Taichi Nakamura,Masaki Tani,Yoshimitsu Aoki,Kentaro Yoshioka*

Main category: cs.CV

TL;DR: BasketLiDAR数据集和新型MOT框架解决了篮球实时3D轨迹跟踪的难题，结合LiDAR和相机数据，实现了高精度和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决传统多摄像头系统在实时3D轨迹跟踪中的局限性，特别是篮球比赛中因快速移动和频繁遮挡带来的挑战。

Method: 构建了BasketLiDAR多模态数据集，结合LiDAR点云与多视角相机数据，并开发了一种新型MOT算法，包括纯LiDAR实时跟踪和多模态数据融合跟踪。

Result: 实验证明，该方法在实时性和跟踪性能上均优于传统相机方法，尤其在遮挡条件下表现突出。

Conclusion: BasketLiDAR数据集和提出的MOT框架在篮球比赛中实现了实时3D轨迹跟踪，显著提高了跟踪精度并降低了计算成本，尤其在遮挡条件下表现优异。

Abstract: Real-time 3D trajectory player tracking in sports plays a crucial role in
tactical analysis, performance evaluation, and enhancing spectator experience.
Traditional systems rely on multi-camera setups, but are constrained by the
inherently two-dimensional nature of video data and the need for complex 3D
reconstruction processing, making real-time analysis challenging. Basketball,
in particular, represents one of the most difficult scenarios in the MOT field,
as ten players move rapidly and complexly within a confined court space, with
frequent occlusions caused by intense physical contact.
  To address these challenges, this paper constructs BasketLiDAR, the first
multimodal dataset in the sports MOT field that combines LiDAR point clouds
with synchronized multi-view camera footage in a professional basketball
environment, and proposes a novel MOT framework that simultaneously achieves
improved tracking accuracy and reduced computational cost. The BasketLiDAR
dataset contains a total of 4,445 frames and 3,105 player IDs, with fully
synchronized IDs between three LiDAR sensors and three multi-view cameras. We
recorded 5-on-5 and 3-on-3 game data from actual professional basketball
players, providing complete 3D positional information and ID annotations for
each player. Based on this dataset, we developed a novel MOT algorithm that
leverages LiDAR's high-precision 3D spatial information. The proposed method
consists of a real-time tracking pipeline using LiDAR alone and a multimodal
tracking pipeline that fuses LiDAR and camera data. Experimental results
demonstrate that our approach achieves real-time operation, which was difficult
with conventional camera-only methods, while achieving superior tracking
performance even under occlusion conditions. The dataset is available upon
request at: https://sites.google.com/keio.jp/keio-csg/projects/basket-lidar

</details>


### [29] [First RAG, Second SEG: A Training-Free Paradigm for Camouflaged Object Detection](https://arxiv.org/abs/2508.15313)
*Wutao Liu,YiDan Wang,Pan Gao*

Main category: cs.CV

TL;DR: RAG-SEG是一种无需训练的两阶段方法，通过RAG生成粗略掩模提示，再由SEG细化，在伪装物体检测任务中表现优异且计算高效。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量训练和计算资源，而基础模型如SAM在伪装物体检测任务中表现不佳且需要高质量提示。手动生成提示成本高且效率低。

Method: RAG-SEG采用Retrieval-Augmented Generation（RAG）生成粗略掩模作为提示，再通过SAM-based segmentation（SEG）进行细化，无需传统训练。

Result: 在基准COD数据集上的实验表明，RAG-SEG性能与或超越现有最优方法，且所有实验均在个人笔记本电脑上完成，展示了其计算效率和实用性。

Conclusion: RAG-SEG提出了一种无需训练的方法，通过两阶段（RAG和SEG）有效解决了伪装物体检测的挑战，并在计算效率和性能上表现出色。

Abstract: Camouflaged object detection (COD) poses a significant challenge in computer
vision due to the high similarity between objects and their backgrounds.
Existing approaches often rely on heavy training and large computational
resources. While foundation models such as the Segment Anything Model (SAM)
offer strong generalization, they still struggle to handle COD tasks without
fine-tuning and require high-quality prompts to yield good performance.
However, generating such prompts manually is costly and inefficient. To address
these challenges, we propose \textbf{First RAG, Second SEG (RAG-SEG)}, a
training-free paradigm that decouples COD into two stages: Retrieval-Augmented
Generation (RAG) for generating coarse masks as prompts, followed by SAM-based
segmentation (SEG) for refinement. RAG-SEG constructs a compact retrieval
database via unsupervised clustering, enabling fast and effective feature
retrieval. During inference, the retrieved features produce pseudo-labels that
guide precise mask generation using SAM2. Our method eliminates the need for
conventional training while maintaining competitive performance. Extensive
experiments on benchmark COD datasets demonstrate that RAG-SEG performs on par
with or surpasses state-of-the-art methods. Notably, all experiments are
conducted on a \textbf{personal laptop}, highlighting the computational
efficiency and practicality of our approach. We present further analysis in the
Appendix, covering limitations, salient object detection extension, and
possible improvements.

</details>


### [30] [VideoEraser: Concept Erasure in Text-to-Video Diffusion Models](https://arxiv.org/abs/2508.15314)
*Naen Xu,Jinghuai Zhang,Changjiang Li,Zhi Chen,Chunyi Zhou,Qingming Li,Tianyu Du,Shouling Ji*

Main category: cs.CV

TL;DR: VideoEraser 是一种无需训练的即插即用框架，通过两阶段流程有效抑制 T2V 扩散模型生成不良内容，实验显示其平均减少46%的不良内容生成。


<details>
  <summary>Details</summary>
Motivation: 随着 T2V 扩散模型的快速发展，其可能被滥用于生成有害或误导性内容，引发了隐私、版权和安全问题。未经授权的个人身份、艺术创作和有害材料的训练数据可能导致不良内容的失控生产和传播。

Method: VideoEraser 采用两阶段流程：选择性提示嵌入调整（SPEA）和抗对抗性噪声引导（ARNG），作为一个即插即用模块，可无缝集成到主流 T2V 扩散模型中。

Result: VideoEraser 在四种任务（对象擦除、艺术风格擦除、名人擦除和显式内容擦除）中均表现优异，在效果、完整性、保真度、鲁棒性和泛化性方面显著优于现有方法。

Conclusion: VideoEraser 是一种无需训练即可有效阻止文本到视频（T2V）扩散模型生成不良内容的框架，其通过两阶段流程（SPEA 和 ARNG）显著提升了内容抑制的效果，平均减少了46%的不良内容生成。

Abstract: The rapid growth of text-to-video (T2V) diffusion models has raised concerns
about privacy, copyright, and safety due to their potential misuse in
generating harmful or misleading content. These models are often trained on
numerous datasets, including unauthorized personal identities, artistic
creations, and harmful materials, which can lead to uncontrolled production and
distribution of such content. To address this, we propose VideoEraser, a
training-free framework that prevents T2V diffusion models from generating
videos with undesirable concepts, even when explicitly prompted with those
concepts. Designed as a plug-and-play module, VideoEraser can seamlessly
integrate with representative T2V diffusion models via a two-stage process:
Selective Prompt Embedding Adjustment (SPEA) and Adversarial-Resilient Noise
Guidance (ARNG). We conduct extensive evaluations across four tasks, including
object erasure, artistic style erasure, celebrity erasure, and explicit content
erasure. Experimental results show that VideoEraser consistently outperforms
prior methods regarding efficacy, integrity, fidelity, robustness, and
generalizability. Notably, VideoEraser achieves state-of-the-art performance in
suppressing undesirable content during T2V generation, reducing it by 46% on
average across four tasks compared to baselines.

</details>


### [31] [Predicting Road Crossing Behaviour using Pose Detection and Sequence Modelling](https://arxiv.org/abs/2508.15336)
*Subhasis Dasgupta,Preetam Saha,Agniva Roy,Jaydip Sen*

Main category: cs.CV

TL;DR: 研究通过深度学习模型预测行人过马路意图，发现GRU优于LSTM，1D CNN速度最快。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统和自动驾驶车辆的普及，准确预测行人是否即将过马路变得至关重要。

Method: 研究结合了深度学习模型进行姿态预测和序列建模技术，特别是分析了GRU、LSTM和1D CNN三种序列建模方法。

Result: 研究发现GRU在预测准确性上优于LSTM，而1D CNN在速度上最快。

Conclusion: 研究得出结论，GRU在预测行人过马路意图方面优于LSTM模型，而1D CNN在速度上表现最佳。

Abstract: The world is constantly moving towards AI based systems and autonomous
vehicles are now reality in different parts of the world. These vehicles
require sensors and cameras to detect objects and maneuver according to that.
It becomes important to for such vehicles to also predict from a distant if a
person is about to cross a road or not. The current study focused on predicting
the intent of crossing the road by pedestrians in an experimental setup. The
study involved working with deep learning models to predict poses and sequence
modelling for temporal predictions. The study analysed three different sequence
modelling to understand the prediction behaviour and it was found out that GRU
was better in predicting the intent compared to LSTM model but 1D CNN was the
best model in terms of speed. The study involved video analysis, and the output
of pose detection model was integrated later on to sequence modelling
techniques for an end-to-end deep learning framework for predicting road
crossing intents.

</details>


### [32] [RCDINO: Enhancing Radar-Camera 3D Object Detection with DINOv2 Semantic Features](https://arxiv.org/abs/2508.15353)
*Olga Matykina,Dmitry Yudin*

Main category: cs.CV

TL;DR: RCDINO是一种基于Transformer的多模态模型，通过融合DINOv2的语义表示提升三维物体检测性能，在nuScenes数据集上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 三维物体检测在自动驾驶和机器人领域至关重要，需要有效融合相机和雷达的多模态数据。

Method: 提出了RCDINO，一种基于多模态Transformer的模型，通过融合DINOv2预训练基础模型的语义丰富表示与视觉主干特征来增强视觉表示。

Result: 在nuScenes数据集上，RCDINO实现了56.4 NDS和48.1 mAP的最先进性能。

Conclusion: RCDINO通过融合DINOv2的语义丰富表示与视觉主干特征，显著提升了三维物体检测性能，并在nuScenes数据集上实现了最先进的雷达-相机模型性能。

Abstract: Three-dimensional object detection is essential for autonomous driving and
robotics, relying on effective fusion of multimodal data from cameras and
radar. This work proposes RCDINO, a multimodal transformer-based model that
enhances visual backbone features by fusing them with semantically rich
representations from the pretrained DINOv2 foundation model. This approach
enriches visual representations and improves the model's detection performance
while preserving compatibility with the baseline architecture. Experiments on
the nuScenes dataset demonstrate that RCDINO achieves state-of-the-art
performance among radar-camera models, with 56.4 NDS and 48.1 mAP. Our
implementation is available at https://github.com/OlgaMatykina/RCDINO.

</details>


### [33] [An Empirical Study on How Video-LLMs Answer Video Questions](https://arxiv.org/abs/2508.15360)
*Chenhui Gou,Ziyu Ma,Zicheng Duan,Haoyu He,Feng Chen,Akide Liu,Bohan Zhuang,Jianfei Cai,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 本文通过注意力剔除分析了Video-LLM的内部机制，发现视频信息提取主要在早期层完成，某些中间层对问答影响显著，且时空建模依赖语言引导。这些发现可用于优化计算效率。


<details>
  <summary>Details</summary>
Motivation: 尽管Video-LLM在视频问答中表现出强大能力，但其内部机制的理解仍有限。本文旨在通过系统的实证研究填补这一空白。

Method: 采用注意力剔除作为主要分析工具，设计了三种变体：视频时间剔除、视频空间剔除和语言到视频剔除，并在不同层数（层窗口）上应用这些剔除。通过控制层窗口和剔除类型，提供了全局和细粒度两种设置。

Result: 研究发现：（1）全局设置下视频信息提取主要发生在早期层，形成清晰的两阶段过程；（2）细粒度设置下某些中间层对视频问答具有超常影响；（3）时空建模更依赖语言引导检索而非视频令牌的自注意力。这些发现可用于减少Video-LLM的注意力计算。

Conclusion: 本研究通过系统的实证分析揭示了Video-LLM的内部工作机制，并提出了减少注意力计算的方法，为未来研究提供了可解释性和效率的视角。

Abstract: Taking advantage of large-scale data and pretrained language models, Video
Large Language Models (Video-LLMs) have shown strong capabilities in answering
video questions. However, most existing efforts focus on improving performance,
with limited attention to understanding their internal mechanisms. This paper
aims to bridge this gap through a systematic empirical study. To interpret
existing VideoLLMs, we adopt attention knockouts as our primary analytical tool
and design three variants: Video Temporal Knockout, Video Spatial Knockout, and
Language-to-Video Knockout. Then, we apply these three knockouts on different
numbers of layers (window of layers). By carefully controlling the window of
layers and types of knockouts, we provide two settings: a global setting and a
fine-grained setting. Our study reveals three key findings: (1) Global setting
indicates Video information extraction primarily occurs in early layers,
forming a clear two-stage process -- lower layers focus on perceptual encoding,
while higher layers handle abstract reasoning; (2) In the fine-grained setting,
certain intermediate layers exert an outsized impact on video question
answering, acting as critical outliers, whereas most other layers contribute
minimally; (3) In both settings, we observe that spatial-temporal modeling
relies more on language-guided retrieval than on intra- and inter-frame
self-attention among video tokens, despite the latter's high computational
cost. Finally, we demonstrate that these insights can be leveraged to reduce
attention computation in Video-LLMs. To our knowledge, this is the first work
to systematically uncover how Video-LLMs internally process and understand
video content, offering interpretability and efficiency perspectives for future
research.

</details>


### [34] [Transfer learning optimization based on evolutionary selective fine tuning](https://arxiv.org/abs/2508.15367)
*Jacinto Colan,Ana Davila,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: BioTune是一种进化自适应微调技术，通过选择性微调层提升迁移学习效率，减少计算成本，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统微调方法通常更新所有模型参数，可能导致过拟合和高计算成本，BioTune旨在解决这一问题。

Method: BioTune采用进化算法识别需要微调的层，优化模型在目标任务上的表现。

Result: 在九个图像分类数据集上的评估表明，BioTune在准确性和效率上优于或媲美现有微调方法（如AutoRGN和LoRA）。

Conclusion: BioTune通过进化算法选择性地微调层，显著提升了迁移学习的效率和性能，同时减少了计算成本。

Abstract: Deep learning has shown substantial progress in image analysis. However, the
computational demands of large, fully trained models remain a consideration.
Transfer learning offers a strategy for adapting pre-trained models to new
tasks. Traditional fine-tuning often involves updating all model parameters,
which can potentially lead to overfitting and higher computational costs. This
paper introduces BioTune, an evolutionary adaptive fine-tuning technique that
selectively fine-tunes layers to enhance transfer learning efficiency. BioTune
employs an evolutionary algorithm to identify a focused set of layers for
fine-tuning, aiming to optimize model performance on a given target task.
Evaluation across nine image classification datasets from various domains
indicates that BioTune achieves competitive or improved accuracy and efficiency
compared to existing fine-tuning methods such as AutoRGN and LoRA. By
concentrating the fine-tuning process on a subset of relevant layers, BioTune
reduces the number of trainable parameters, potentially leading to decreased
computational cost and facilitating more efficient transfer learning across
diverse data characteristics and distributions.

</details>


### [35] [DriveSplat: Decoupled Driving Scene Reconstruction with Geometry-enhanced Partitioned Neural Gaussians](https://arxiv.org/abs/2508.15376)
*Cong Wang,Xianda Guo,Wenbo Xu,Wei Tian,Ruiqi Song,Chenming Zhang,Lingxi Li,Long Chen*

Main category: cs.CV

TL;DR: DriveSplat是一种基于神经高斯表示的驾驶场景高质量重建方法，通过动态-静态解耦和区域化体素初始化优化了场景重建，在Waymo和KITTI数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅的方法在解耦动态和静态组件时忽略了背景优化的几何关系，导致新视角渲染的鲁棒性不足和几何表示不准确。

Method: DriveSplat采用基于神经高斯表示的方法，通过动态-静态解耦、区域化体素初始化方案和可变形神经高斯建模非刚性动态对象。整个框架通过预训练模型的深度和法线先验进行监督。

Result: DriveSplat在驾驶场景中实现了高质量的重建，显著提升了新视角合成的性能。

Conclusion: DriveSplat在Waymo和KITTI数据集上展示了最先进的新视角合成性能，验证了其在驾驶场景中的高质量重建能力。

Abstract: In the realm of driving scenarios, the presence of rapidly moving vehicles,
pedestrians in motion, and large-scale static backgrounds poses significant
challenges for 3D scene reconstruction. Recent methods based on 3D Gaussian
Splatting address the motion blur problem by decoupling dynamic and static
components within the scene. However, these decoupling strategies overlook
background optimization with adequate geometry relationships and rely solely on
fitting each training view by adding Gaussians. Therefore, these models exhibit
limited robustness in rendering novel views and lack an accurate geometric
representation. To address the above issues, we introduce DriveSplat, a
high-quality reconstruction method for driving scenarios based on neural
Gaussian representations with dynamic-static decoupling. To better accommodate
the predominantly linear motion patterns of driving viewpoints, a region-wise
voxel initialization scheme is employed, which partitions the scene into near,
middle, and far regions to enhance close-range detail representation.
Deformable neural Gaussians are introduced to model non-rigid dynamic actors,
whose parameters are temporally adjusted by a learnable deformation network.
The entire framework is further supervised by depth and normal priors from
pre-trained models, improving the accuracy of geometric structures. Our method
has been rigorously evaluated on the Waymo and KITTI datasets, demonstrating
state-of-the-art performance in novel-view synthesis for driving scenarios.

</details>


### [36] [DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability](https://arxiv.org/abs/2508.15387)
*Ruizhuo Song,Beiming Yuan*

Main category: cs.CV

TL;DR: 本文通过改进DIO模型的优化目标，逐步提升其在Raven渐进矩阵任务中的抽象推理能力。


<details>
  <summary>Details</summary>
Motivation: Raven渐进矩阵（RPM）问题被广泛用于评估深度学习算法的抽象推理能力。本文旨在通过解决RPM问题，提升机器智能的抽象推理能力。

Method: 本文首先采用因果链建模视角系统分析RPM任务中的完整因果链，并基于此设计DIO模型的网络架构。随后，针对DIO模型的优化目标局限性，逐步提出三种改进方法。

Result: 实验表明，DIO模型的初始优化目标未能有效捕捉人类预定义的推理逻辑。通过提出的三种改进方法，模型在RPM任务上的表现得到显著提升。

Conclusion: 尽管当前深度学习模型在多个领域表现出色，但其在抽象推理方面的根本瓶颈仍未解决。本文通过改进DIO模型的优化目标，逐步提出了三种方法，旨在提升模型在Raven渐进矩阵（RPM）问题上的抽象推理能力。

Abstract: Despite the outstanding performance of current deep learning models across
various domains, their fundamental bottleneck in abstract reasoning remains
unresolved. To address this challenge, the academic community has introduced
Raven's Progressive Matrices (RPM) problems as an authoritative benchmark for
evaluating the abstract reasoning capabilities of deep learning algorithms,
with a focus on core intelligence dimensions such as abstract reasoning,
pattern recognition, and complex problem-solving. Therefore, this paper centers
on solving RPM problems, aiming to contribute to enhancing the abstract
reasoning abilities of machine intelligence. Firstly, this paper adopts a
``causal chain modeling'' perspective to systematically analyze the complete
causal chain in RPM tasks: image $\rightarrow$ abstract attributes
$\rightarrow$ progressive attribute patterns $\rightarrow$ pattern consistency
$\rightarrow$ correct answer. Based on this analysis, the network architecture
of the baseline model DIO is designed. However, experiments reveal that the
optimization objective formulated for DIO, namely maximizing the variational
lower bound of mutual information between the context and the correct option,
fails to enable the model to genuinely acquire the predefined human reasoning
logic. This is attributed to two main reasons: the tightness of the lower bound
significantly impacts the effectiveness of mutual information maximization, and
mutual information, as a statistical measure, does not capture the causal
relationship between subjects and objects. To overcome these limitations, this
paper progressively proposes three improvement methods:

</details>


### [37] [Spiking Variational Graph Representation Inference for Video Summarization](https://arxiv.org/abs/2508.15389)
*Wenrui Li,Wei Han,Liang-Jian Deng,Ruiqin Xiong,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 提出SpiVG网络，结合SNN和变分推理，解决了视频摘要中的全局依赖性和噪声问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉全局时间依赖性和保持语义连贯性，且在多通道特征融合中易受噪声影响。

Method: 设计了基于SNN的关键帧提取器和动态聚合图推理器，并引入变分推理重建模块来处理多通道特征融合中的噪声和不确定性。

Result: SpiVG在SumMe、TVSum、VideoXum和QFVS等多个数据集上表现优于现有方法。

Conclusion: SpiVG网络通过结合SNN和变分推理，显著提升了视频摘要的性能，并在多个数据集上超越了现有方法。

Abstract: With the rise of short video content, efficient video summarization
techniques for extracting key information have become crucial. However,
existing methods struggle to capture the global temporal dependencies and
maintain the semantic coherence of video content. Additionally, these methods
are also influenced by noise during multi-channel feature fusion. We propose a
Spiking Variational Graph (SpiVG) Network, which enhances information density
and reduces computational complexity. First, we design a keyframe extractor
based on Spiking Neural Networks (SNN), leveraging the event-driven computation
mechanism of SNNs to learn keyframe features autonomously. To enable
fine-grained and adaptable reasoning across video frames, we introduce a
Dynamic Aggregation Graph Reasoner, which decouples contextual object
consistency from semantic perspective coherence. We present a Variational
Inference Reconstruction Module to address uncertainty and noise arising during
multi-channel feature fusion. In this module, we employ Evidence Lower Bound
Optimization (ELBO) to capture the latent structure of multi-channel feature
distributions, using posterior distribution regularization to reduce
overfitting. Experimental results show that SpiVG surpasses existing methods
across multiple datasets such as SumMe, TVSum, VideoXum, and QFVS. Our codes
and pre-trained models are available at https://github.com/liwrui/SpiVG.

</details>


### [38] [From Linearity to Non-Linearity: How Masked Autoencoders Capture Spatial Correlations](https://arxiv.org/abs/2508.15404)
*Anthony Bisulco,Rahul Ramesh,Randall Balestriero,Pratik Chaudhari*

Main category: cs.CV

TL;DR: 本文分析了MAE超参数对空间相关性学习的影响，提供了理论推导和实际超参数选择建议。


<details>
  <summary>Details</summary>
Motivation: 探索MAE超参数与下游任务性能之间的关系，填补现有理论研究的空白。

Method: 通过理论推导线性MAE学习的特征，并扩展到非线性MAE，分析其如何适应数据集的空间相关性。

Result: 研究发现掩码比例和补丁大小可选择性捕获短程和长程空间相关性，且MAE表示能适应超出二阶统计的数据集空间相关性。

Conclusion: 本文通过分析和实验揭示了MAE超参数（如掩码比例和补丁大小）如何影响模型学习空间相关性，并提供了实际选择超参数的指导。

Abstract: Masked Autoencoders (MAEs) have emerged as a powerful pretraining technique
for vision foundation models. Despite their effectiveness, they require
extensive hyperparameter tuning (masking ratio, patch size, encoder/decoder
layers) when applied to novel datasets. While prior theoretical works have
analyzed MAEs in terms of their attention patterns and hierarchical latent
variable models, the connection between MAE hyperparameters and performance on
downstream tasks is relatively unexplored. This work investigates how MAEs
learn spatial correlations in the input image. We analytically derive the
features learned by a linear MAE and show that masking ratio and patch size can
be used to select for features that capture short- and long-range spatial
correlations. We extend this analysis to non-linear MAEs to show that MAE
representations adapt to spatial correlations in the dataset, beyond
second-order statistics. Finally, we discuss some insights on how to select MAE
hyper-parameters in practice.

</details>


### [39] [Bidirectional Temporal Information Propagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2508.15415)
*Dengyan Luo,Yanping Xiang,Hu Wang,Luping Ji. Shuai Li,Mao Ye*

Main category: cs.CV

TL;DR: BIRD方法通过双向传播策略结合局部和全局时间信息，优化红外小目标检测性能，实验证明其高效且快速。


<details>
  <summary>Details</summary>
Motivation: 现有的基于学习的多帧方法主要采用滑动窗口方式聚合相邻帧信息，忽略了全局时间信息，导致冗余计算和次优性能。

Method: 提出了一种双向时间信息传播方法（BIRD），设计了局部时间运动融合（LTMF）模块和全局时间运动融合（GTMF）模块，结合检测头和时空融合（STF）损失进行联合优化。

Result: 大量实验表明，BIRD方法在性能和推理速度上均达到了最优水平。

Conclusion: 提出的BIRD方法通过双向传播策略同时利用局部和全局时间信息，不仅实现了最先进的检测性能，还展示了快速的推理速度。

Abstract: Moving infrared small target detection is broadly adopted in infrared search
and track systems, and has attracted considerable research focus in recent
years. The existing learning-based multi-frame methods mainly aggregate the
information of adjacent frames in a sliding window fashion to assist the
detection of the current frame. However, the sliding-window-based methods do
not consider joint optimization of the entire video clip and ignore the global
temporal information outside the sliding window, resulting in redundant
computation and sub-optimal performance. In this paper, we propose a
Bidirectional temporal information propagation method for moving InfraRed small
target Detection, dubbed BIRD. The bidirectional propagation strategy
simultaneously utilizes local temporal information of adjacent frames and
global temporal information of past and future frames in a recursive fashion.
Specifically, in the forward and backward propagation branches, we first design
a Local Temporal Motion Fusion (LTMF) module to model local spatio-temporal
dependency between a target frame and its two adjacent frames. Then, a Global
Temporal Motion Fusion (GTMF) module is developed to further aggregate the
global propagation feature with the local fusion feature. Finally, the
bidirectional aggregated features are fused and input into the detection head
for detection. In addition, the entire video clip is jointly optimized by the
traditional detection loss and the additional Spatio-Temporal Fusion (STF)
loss. Extensive experiments demonstrate that the proposed BIRD method not only
achieves the state-of-the-art performance but also shows a fast inference
speed.

</details>


### [40] [The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models](https://arxiv.org/abs/2507.23341)
*Ahmet Can Ömercikoğlu,Mustafa Mansur Yönügül,Pakize Erdoğmuş*

Main category: cs.CV

TL;DR: 本研究评估了三种人脸检测器在不同分辨率下的性能，发现YOLOv11在高分辨率下表现最佳，YOLOv12召回率略优，MTCNN实时推理速度较差，为模型选择提供了实用建议。


<details>
  <summary>Details</summary>
Motivation: 由于低分辨率图像等现实条件对人脸检测性能的显著影响，本研究旨在系统研究输入分辨率对三种主流深度学习人脸检测器准确性和鲁棒性的影响。

Method: 使用WIDER FACE数据集，对YOLOv11、YOLOv12和MTCNN三种深度学习人脸检测器在多种图像分辨率（160x160、320x320和640x640）下进行了广泛评估，评估指标包括精度、召回率、mAP50、mAP50-95和推理时间。

Result: YOLOv11在检测精度上优于YOLOv12和MTCNN，尤其是在高分辨率下；YOLOv12在召回率上略优；MTCNN在特征点定位上表现良好，但在实时推理速度上表现不佳。

Conclusion: 研究表明，YOLOv11在较高分辨率下表现最佳，而YOLOv12在召回率上略优，MTCNN在实时推理速度上表现不佳。这些发现为根据不同操作约束选择分辨率感知的人脸检测模型提供了实用建议。

Abstract: Face detection is a crucial component in many AI-driven applications such as
surveillance, biometric authentication, and human-computer interaction.
However, real-world conditions like low-resolution imagery present significant
challenges that degrade detection performance. In this study, we systematically
investigate the impact of input resolution on the accuracy and robustness of
three prominent deep learning-based face detectors: YOLOv11, YOLOv12, and
MTCNN. Using the WIDER FACE dataset, we conduct extensive evaluations across
multiple image resolutions (160x160, 320x320, and 640x640) and assess each
model's performance using metrics such as precision, recall, mAP50, mAP50-95,
and inference time. Results indicate that YOLOv11 outperforms YOLOv12 and MTCNN
in terms of detection accuracy, especially at higher resolutions, while YOLOv12
exhibits slightly better recall. MTCNN, although competitive in landmark
localization, lags in real-time inference speed. Our findings provide
actionable insights for selecting resolution-aware face detection models
suitable for varying operational constraints.

</details>


### [41] [A Curated Dataset and Deep Learning Approach for Minor Dent Detection in Vehicles](https://arxiv.org/abs/2508.15431)
*Danish Zia Baig,Mohsin Kamal*

Main category: cs.CV

TL;DR: 论文提出基于YOLOv8的深度学习模型（YOLOv8m-t42）用于检测汽车表面微小缺陷，表现优于传统方法，适用于实时检测场景。


<details>
  <summary>Details</summary>
Motivation: 传统汽车损伤检测方法耗时、不可靠且难以检测微小缺陷，机器学习提供了更快、更精确的解决方案。

Method: 使用YOLOv8对象识别框架，并训练了定制模型YOLOv8m-t4和YOLOv8m-t42，采用实时数据增强技术以提高鲁棒性。

Result: YOLOv8m-t42模型在精度（0.86）、召回率（0.84）和F1分数（0.85）上优于YOLOv8m-t4模型，mAP@0.5稳定在0.60，PR曲线面积为0.88。

Conclusion: 该论文提出的基于YOLOv8m-t42模型的深度学习解决方案在检测汽车表面微小缺陷方面表现出色，具有高精度和低推理延迟，适用于实时应用。

Abstract: Conventional car damage inspection techniques are labor-intensive, manual,
and frequently overlook tiny surface imperfections like microscopic dents.
Machine learning provides an innovative solution to the increasing demand for
quicker and more precise inspection methods. The paper uses the YOLOv8 object
recognition framework to provide a deep learning-based solution for
automatically detecting microscopic surface flaws, notably tiny dents, on car
exteriors. Traditional automotive damage inspection procedures are manual,
time-consuming, and frequently unreliable at detecting tiny flaws. To solve
this, a bespoke dataset containing annotated photos of car surfaces under
various lighting circumstances, angles, and textures was created. To improve
robustness, the YOLOv8m model and its customized variants, YOLOv8m-t4 and
YOLOv8m-t42, were trained employing real-time data augmentation approaches.
Experimental results show that the technique has excellent detection accuracy
and low inference latency, making it suited for real-time applications such as
automated insurance evaluations and automobile inspections. Evaluation
parameters such as mean Average Precision (mAP), precision, recall, and
F1-score verified the model's efficacy. With a precision of 0.86, recall of
0.84, and F1-score of 0.85, the YOLOv8m-t42 model outperformed the YOLOv8m-t4
model (precision: 0.81, recall: 0.79, F1-score: 0.80) in identifying
microscopic surface defects. With a little reduced mAP@0.5:0.95 of 0.20, the
mAP@0.5 for YOLOv8m-t42 stabilized at 0.60. Furthermore, YOLOv8m-t42's PR curve
area was 0.88, suggesting more consistent performance than YOLOv8m-t4 (0.82).
YOLOv8m-t42 has greater accuracy and is more appropriate for practical dent
detection applications, even though its convergence is slower.

</details>


### [42] [Aligning Moments in Time using Video Queries](https://arxiv.org/abs/2508.15439)
*Yogesh Kumar,Uday Agarwal,Manish Gupta,Anand Mishra*

Main category: cs.CV

TL;DR: MATR是一种基于Transformer的视频间时刻检索模型，通过双阶段对齐和自监督预训练显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 视频间时刻检索任务需要语义帧级对齐和建模查询与目标视频间的复杂依赖关系，现有方法难以满足这些需求。

Method: 提出了MATR（Moment Alignment TRansformer），一种基于Transformer的模型，通过双阶段序列对齐捕获语义上下文和时间细节，并结合自监督预训练技术。

Result: MATR在ActivityNet-VRL数据集上R@1和mIoU分别提升13.1%和8.1%，在SportsMoments数据集上分别提升14.7%和14.4%。

Conclusion: MATR在ActivityNet-VRL和SportsMoments数据集上显著优于现有方法，证明了其在视频间时刻检索任务中的有效性。

Abstract: Video-to-video moment retrieval (Vid2VidMR) is the task of localizing unseen
events or moments in a target video using a query video. This task poses
several challenges, such as the need for semantic frame-level alignment and
modeling complex dependencies between query and target videos. To tackle this
challenging problem, we introduce MATR (Moment Alignment TRansformer), a
transformer-based model designed to capture semantic context as well as the
temporal details necessary for precise moment localization. MATR conditions
target video representations on query video features using dual-stage sequence
alignment that encodes the required correlations and dependencies. These
representations are then used to guide foreground/background classification and
boundary prediction heads, enabling the model to accurately identify moments in
the target video that semantically match with the query video. Additionally, to
provide a strong task-specific initialization for MATR, we propose a
self-supervised pre-training technique that involves training the model to
localize random clips within videos. Extensive experiments demonstrate that
MATR achieves notable performance improvements of 13.1% in R@1 and 8.1% in mIoU
on an absolute scale compared to state-of-the-art methods on the popular
ActivityNet-VRL dataset. Additionally, on our newly proposed dataset,
SportsMoments, MATR shows a 14.7% gain in R@1 and a 14.4% gain in mIoU on an
absolute scale over strong baselines.

</details>


### [43] [Enhancing Novel View Synthesis from extremely sparse views with SfM-free 3D Gaussian Splatting Framework](https://arxiv.org/abs/2508.15457)
*Zongqi He,Hanmin Li,Kin-Chung Chan,Yushen Zuo,Hao Xie,Zhe Xiao,Jun Xiao,Kin-Man Lam*

Main category: cs.CV

TL;DR: 提出无SfM的3DGS方法，通过密集立体模块和连贯视角插值解决稀疏输入问题，显著提升渲染质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS依赖密集多视角输入和精确相机姿态，但在实际场景中难以获取。稀疏视角下SfM初始化失效，导致渲染质量下降。

Method: 提出了一种无SfM的3DGS方法，包括密集立体模块逐步估计相机姿态、全局密集点云初始化，以及连贯视角插值模块生成额外监督信号。还引入了多尺度拉普拉斯一致性正则化和自适应空间感知多尺度几何正则化。

Result: 实验表明，该方法在仅使用2个训练视角的极稀疏条件下，PSNR显著提升2.75dB，合成图像视觉质量优于现有技术。

Conclusion: 该方法在极稀疏视角输入条件下显著优于现有3DGS方法，PSNR提升2.75dB，合成图像失真最小且保留高频细节。

Abstract: 3D Gaussian Splatting (3DGS) has demonstrated remarkable real-time
performance in novel view synthesis, yet its effectiveness relies heavily on
dense multi-view inputs with precisely known camera poses, which are rarely
available in real-world scenarios. When input views become extremely sparse,
the Structure-from-Motion (SfM) method that 3DGS depends on for initialization
fails to accurately reconstruct the 3D geometric structures of scenes,
resulting in degraded rendering quality. In this paper, we propose a novel
SfM-free 3DGS-based method that jointly estimates camera poses and reconstructs
3D scenes from extremely sparse-view inputs. Specifically, instead of SfM, we
propose a dense stereo module to progressively estimates camera pose
information and reconstructs a global dense point cloud for initialization. To
address the inherent problem of information scarcity in extremely sparse-view
settings, we propose a coherent view interpolation module that interpolates
camera poses based on training view pairs and generates viewpoint-consistent
content as additional supervision signals for training. Furthermore, we
introduce multi-scale Laplacian consistent regularization and adaptive
spatial-aware multi-scale geometry regularization to enhance the quality of
geometrical structures and rendered content. Experiments show that our method
significantly outperforms other state-of-the-art 3DGS-based approaches,
achieving a remarkable 2.75dB improvement in PSNR under extremely sparse-view
conditions (using only 2 training views). The images synthesized by our method
exhibit minimal distortion while preserving rich high-frequency details,
resulting in superior visual quality compared to existing techniques.

</details>


### [44] [LGMSNet: Thinning a medical image segmentation model via dual-level multiscale fusion](https://arxiv.org/abs/2508.15476)
*Chengqi Dong,Fenghe Tang,Rongge Mao,Xinpei Gao,S. Kevin Zhou*

Main category: cs.CV

TL;DR: LGMSNet 是一种轻量级医学图像分割框架，通过局部和全局双多尺度设计解决现有模型的不足，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有轻量级模型在性能和全局上下文感知能力上的不足，以及通道冗余问题。

Method: LGMSNet 采用局部和全局双多尺度框架，结合异构层内核和稀疏 Transformer-卷积混合分支。

Result: 在六个公共数据集上表现优于现有方法，并在零样本泛化测试中保持优异性能。

Conclusion: LGMSNet 在资源有限的医疗场景中展现出卓越的性能和泛化能力，具有实际部署的潜力。

Abstract: Medical image segmentation plays a pivotal role in disease diagnosis and
treatment planning, particularly in resource-constrained clinical settings
where lightweight and generalizable models are urgently needed. However,
existing lightweight models often compromise performance for efficiency and
rarely adopt computationally expensive attention mechanisms, severely
restricting their global contextual perception capabilities. Additionally,
current architectures neglect the channel redundancy issue under the same
convolutional kernels in medical imaging, which hinders effective feature
extraction. To address these challenges, we propose LGMSNet, a novel
lightweight framework based on local and global dual multiscale that achieves
state-of-the-art performance with minimal computational overhead. LGMSNet
employs heterogeneous intra-layer kernels to extract local high-frequency
information while mitigating channel redundancy. In addition, the model
integrates sparse transformer-convolutional hybrid branches to capture
low-frequency global information. Extensive experiments across six public
datasets demonstrate LGMSNet's superiority over existing state-of-the-art
methods. In particular, LGMSNet maintains exceptional performance in zero-shot
generalization tests on four unseen datasets, underscoring its potential for
real-world deployment in resource-limited medical scenarios. The whole project
code is in https://github.com/cq-dong/LGMSNet.

</details>


### [45] [MExECON: Multi-view Extended Explicit Clothed humans Optimized via Normal integration](https://arxiv.org/abs/2508.15500)
*Fulden Ece Uğur,Rafael Redondo,Albert Barreiro,Stefan Hristov,Roger Marí*

Main category: cs.CV

TL;DR: MExECON通过多视角优化和法线贴图整合，提升了3D人体重建的精度和细节，无需重新训练网络。


<details>
  <summary>Details</summary>
Motivation: 解决单视角方法在几何和姿态估计上的局限性，利用多视角信息提升重建精度。

Method: 提出联合多视角人体优化（JMBO）算法，通过多视角一致性约束优化SMPL-X人体模型，并整合前后视角的法线贴图以捕捉细节。

Result: 实验表明，MExECON在保真度上优于单视角基线，并与现代少样本3D重建方法竞争。

Conclusion: MExECON通过结合多视角信息，显著提升了3D人体重建的精度和细节表现，无需重新训练网络，展现了其高效性和实用性。

Abstract: This work presents MExECON, a novel pipeline for 3D reconstruction of clothed
human avatars from sparse multi-view RGB images. Building on the single-view
method ECON, MExECON extends its capabilities to leverage multiple viewpoints,
improving geometry and body pose estimation. At the core of the pipeline is the
proposed Joint Multi-view Body Optimization (JMBO) algorithm, which fits a
single SMPL-X body model jointly across all input views, enforcing multi-view
consistency. The optimized body model serves as a low-frequency prior that
guides the subsequent surface reconstruction, where geometric details are added
via normal map integration. MExECON integrates normal maps from both front and
back views to accurately capture fine-grained surface details such as clothing
folds and hairstyles. All multi-view gains are achieved without requiring any
network re-training. Experimental results show that MExECON consistently
improves fidelity over the single-view baseline and achieves competitive
performance compared to modern few-shot 3D reconstruction methods.

</details>


### [46] [Task-Generalized Adaptive Cross-Domain Learning for Multimodal Image Fusion](https://arxiv.org/abs/2508.15505)
*Mengyu Wang,Zhenyu Liu,Kun Li,Yu Wang,Yuwei Wang,Yanyan Wei,Fei Wang*

Main category: cs.CV

TL;DR: AdaSFFuse是一种新型的多模态图像融合框架，通过自适应频率解耦和跨域融合，显著提升了融合性能并保持了高效性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态图像融合方法面临模态不对齐、高频细节破坏和任务特定限制等挑战，需要一种任务通用的解决方案。

Method: 提出了AdaSFFuse框架，包含Adaptive Approximate Wavelet Transform (AdaWAT)用于频率解耦和Spatial-Frequency Mamba Blocks用于高效的多模态融合。

Result: 在四种多模态图像融合任务上的实验表明，AdaSFFuse具有优越的融合性能，同时保持了低计算成本和紧凑的网络结构。

Conclusion: AdaSFFuse通过自适应跨域共融合学习，显著提升了多模态图像融合的性能，同时保持了低计算成本和紧凑的网络结构，实现了性能与效率的平衡。

Abstract: Multimodal Image Fusion (MMIF) aims to integrate complementary information
from different imaging modalities to overcome the limitations of individual
sensors. It enhances image quality and facilitates downstream applications such
as remote sensing, medical diagnostics, and robotics. Despite significant
advancements, current MMIF methods still face challenges such as modality
misalignment, high-frequency detail destruction, and task-specific limitations.
To address these challenges, we propose AdaSFFuse, a novel framework for
task-generalized MMIF through adaptive cross-domain co-fusion learning.
AdaSFFuse introduces two key innovations: the Adaptive Approximate Wavelet
Transform (AdaWAT) for frequency decoupling, and the Spatial-Frequency Mamba
Blocks for efficient multimodal fusion. AdaWAT adaptively separates the high-
and low-frequency components of multimodal images from different scenes,
enabling fine-grained extraction and alignment of distinct frequency
characteristics for each modality. The Spatial-Frequency Mamba Blocks
facilitate cross-domain fusion in both spatial and frequency domains, enhancing
this process. These blocks dynamically adjust through learnable mappings to
ensure robust fusion across diverse modalities. By combining these components,
AdaSFFuse improves the alignment and integration of multimodal features,
reduces frequency loss, and preserves critical details. Extensive experiments
on four MMIF tasks -- Infrared-Visible Image Fusion (IVF), Multi-Focus Image
Fusion (MFF), Multi-Exposure Image Fusion (MEF), and Medical Image Fusion (MIF)
-- demonstrate AdaSFFuse's superior fusion performance, ensuring both low
computational cost and a compact network, offering a strong balance between
performance and efficiency. The code will be publicly available at
https://github.com/Zhen-yu-Liu/AdaSFFuse.

</details>


### [47] [ExtraGS: Geometric-Aware Trajectory Extrapolation with Uncertainty-Guided Generative Priors](https://arxiv.org/abs/2508.15529)
*Kaiyuan Tan,Yingying Shen,Haohui Zhu,Zhiwei Zhan,Shan Zhao,Mingfei Tu,Hongcheng Luo,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye*

Main category: cs.CV

TL;DR: ExtraGS结合几何和生成先验，通过RSG和FFG技术及自监督不确定性估计，显著提升了自动驾驶场景中外推视图的质量。


<details>
  <summary>Details</summary>
Motivation: 从记录的驾驶日志中合成外推视图对于自动驾驶车辆的模拟至关重要，但现有方法常导致几何一致性差和渲染过度平滑的问题。

Method: 提出了ExtraGS框架，包括基于混合高斯-SDF设计的Road Surface Gaussian(RSG)表示和Far Field Gaussians(FFG)技术，以及基于球谐函数的自监督不确定性估计框架。

Result: 在多个数据集、多样多摄像头设置和不同生成先验下的广泛实验表明，ExtraGS显著提升了外推视图的真实感和几何一致性。

Conclusion: ExtraGS通过结合几何和生成先验，显著提升了外推视图的真实感和几何一致性，同时保持了原始轨迹的高保真度。

Abstract: Synthesizing extrapolated views from recorded driving logs is critical for
simulating driving scenes for autonomous driving vehicles, yet it remains a
challenging task. Recent methods leverage generative priors as pseudo ground
truth, but often lead to poor geometric consistency and over-smoothed
renderings. To address these limitations, we propose ExtraGS, a holistic
framework for trajectory extrapolation that integrates both geometric and
generative priors. At the core of ExtraGS is a novel Road Surface Gaussian(RSG)
representation based on a hybrid Gaussian-Signed Distance Function (SDF)
design, and Far Field Gaussians (FFG) that use learnable scaling factors to
efficiently handle distant objects. Furthermore, we develop a self-supervised
uncertainty estimation framework based on spherical harmonics that enables
selective integration of generative priors only where extrapolation artifacts
occur. Extensive experiments on multiple datasets, diverse multi-camera setups,
and various generative priors demonstrate that ExtraGS significantly enhances
the realism and geometric consistency of extrapolated views, while preserving
high fidelity along the original trajectory.

</details>


### [48] [Multi-Object Sketch Animation with Grouping and Motion Trajectory Priors](https://arxiv.org/abs/2508.15535)
*Guotao Liang,Juncheng Hu,Ximing Xing,Jing Zhang,Qian Yu*

Main category: cs.CV

TL;DR: GroupSketch通过两阶段流程（运动初始化和细化）解决了多对象素描动画的复杂性和时间一致性问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多对象交互和复杂运动时存在局限性，如仅限于单对象案例或面临时间不一致和泛化能力差的问题。GroupSketch旨在解决这些限制。

Method: 采用两阶段流程：1) 运动初始化阶段，将输入素描交互式分割为语义组并定义关键帧，通过插值生成粗略动画；2) 运动细化阶段，提出基于组的位移网络（GDN），预测组特定位移场，并利用文本到视频模型的先验知识，结合上下文条件特征增强（CCFE）模块提升时间一致性。

Result: 实验表明，GroupSketch在生成高质量、时间一致的复杂多对象素描动画方面显著优于现有方法。

Conclusion: GroupSketch方法通过两阶段流程（运动初始化和运动细化）显著提升了复杂多对象素描动画的质量和时间一致性，扩展了素描动画的实际应用范围。

Abstract: We introduce GroupSketch, a novel method for vector sketch animation that
effectively handles multi-object interactions and complex motions. Existing
approaches struggle with these scenarios, either being limited to single-object
cases or suffering from temporal inconsistency and poor generalization. To
address these limitations, our method adopts a two-stage pipeline comprising
Motion Initialization and Motion Refinement. In the first stage, the input
sketch is interactively divided into semantic groups and key frames are
defined, enabling the generation of a coarse animation via interpolation. In
the second stage, we propose a Group-based Displacement Network (GDN), which
refines the coarse animation by predicting group-specific displacement fields,
leveraging priors from a text-to-video model. GDN further incorporates
specialized modules, such as Context-conditioned Feature Enhancement (CCFE), to
improve temporal consistency. Extensive experiments demonstrate that our
approach significantly outperforms existing methods in generating high-quality,
temporally consistent animations for complex, multi-object sketches, thus
expanding the practical applications of sketch animation.

</details>


### [49] [D3FNet: A Differential Attention Fusion Network for Fine-Grained Road Structure Extraction in Remote Perception Systems](https://arxiv.org/abs/2508.15537)
*Chang Liu,Yang Xu,Tamas Sziranyi*

Main category: cs.CV

TL;DR: D3FNet是一种针对细粒度窄路分割的深度学习网络，通过差分注意力模块和双流解码机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 高分辨率遥感图像中提取窄路存在挑战，如宽度有限、拓扑断裂和频繁遮挡。

Method: D3FNet引入三个关键创新：差分注意力扩张提取模块（DADE）、双流解码融合机制（DDFM）和多尺度扩张策略。

Result: 在DeepGlobe和CHN6-CUG基准测试中，D3FNet在具有挑战性的道路区域上实现了优越的IoU和召回率，超越了现有基线。

Conclusion: D3FNet被证实为复杂遥感和协同感知场景中细粒度窄路提取的稳健解决方案。

Abstract: Extracting narrow roads from high-resolution remote sensing imagery remains a
significant challenge due to their limited width, fragmented topology, and
frequent occlusions. To address these issues, we propose D3FNet, a Dilated
Dual-Stream Differential Attention Fusion Network designed for fine-grained
road structure segmentation in remote perception systems. Built upon the
encoder-decoder backbone of D-LinkNet, D3FNet introduces three key
innovations:(1) a Differential Attention Dilation Extraction (DADE) module that
enhances subtle road features while suppressing background noise at the
bottleneck; (2) a Dual-stream Decoding Fusion Mechanism (DDFM) that integrates
original and attention-modulated features to balance spatial precision with
semantic context; and (3) a multi-scale dilation strategy (rates 1, 3, 5, 9)
that mitigates gridding artifacts and improves continuity in narrow road
prediction. Unlike conventional models that overfit to generic road widths,
D3FNet specifically targets fine-grained, occluded, and low-contrast road
segments. Extensive experiments on the DeepGlobe and CHN6-CUG benchmarks show
that D3FNet achieves superior IoU and recall on challenging road regions,
outperforming state-of-the-art baselines. Ablation studies further verify the
complementary synergy of attention-guided encoding and dual-path decoding.
These results confirm D3FNet as a robust solution for fine-grained narrow road
extraction in complex remote and cooperative perception scenarios.

</details>


### [50] [Backpropagation-Free Test-Time Adaptation via Probabilistic Gaussian Alignment](https://arxiv.org/abs/2508.15568)
*Youjia Zhang,Youngeun Kim,Young-Geun Choi,Hongyeob Kim,Huiling Liu,Sungeun Hong*

Main category: cs.CV

TL;DR: ADAPT是一种无需反向传播的TTA方法，通过高斯概率推断和轻量级正则化，在分布偏移下实现高性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有TTA方法依赖反向传播或迭代优化（限制可扩展性和实时部署）以及缺乏类条件特征分布显式建模的问题。

Method: ADAPT将TTA重新定义为高斯概率推断任务，使用逐步更新的类均值和共享协方差矩阵建模类条件似然。通过CLIP先验和历史知识库的轻量级正则化校正潜在似然偏差。

Result: 在多样化的基准测试中，ADAPT在广泛的分布偏移下实现了最先进的性能，具有卓越的可扩展性和鲁棒性。

Conclusion: ADAPT方法通过建模类条件似然和使用逐步更新的类均值及共享协方差矩阵，将TTA重新定义为高斯概率推断任务，实现了无需训练、封闭形式的推断。该方法在广泛的分布偏移下表现出色，具有卓越的可扩展性和鲁棒性。

Abstract: Test-time adaptation (TTA) enhances the zero-shot robustness under
distribution shifts by leveraging unlabeled test data during inference. Despite
notable advances, several challenges still limit its broader applicability.
First, most methods rely on backpropagation or iterative optimization, which
limits scalability and hinders real-time deployment. Second, they lack explicit
modeling of class-conditional feature distributions. This modeling is crucial
for producing reliable decision boundaries and calibrated predictions, but it
remains underexplored due to the lack of both source data and supervision at
test time. In this paper, we propose ADAPT, an Advanced Distribution-Aware and
backPropagation-free Test-time adaptation method. We reframe TTA as a Gaussian
probabilistic inference task by modeling class-conditional likelihoods using
gradually updated class means and a shared covariance matrix. This enables
closed-form, training-free inference. To correct potential likelihood bias, we
introduce lightweight regularization guided by CLIP priors and a historical
knowledge bank. ADAPT requires no source data, no gradient updates, and no full
access to target data, supporting both online and transductive settings.
Extensive experiments across diverse benchmarks demonstrate that our method
achieves state-of-the-art performance under a wide range of distribution shifts
with superior scalability and robustness.

</details>


### [51] [High-Frequency First: A Two-Stage Approach for Improving Image INR](https://arxiv.org/abs/2508.15582)
*Sumit Kumar Dam,Mrityunjoy Gain,Eui-Nam Huh,Choong Seon Hong*

Main category: cs.CV

TL;DR: 两阶段训练策略通过自适应权重分配，有效缓解INR中的频谱偏差，提升高频细节重建效果。


<details>
  <summary>Details</summary>
Motivation: 传统INR方法存在频谱偏差问题，难以捕捉高频细节。本文旨在通过训练过程的直接引导来解决这一问题。

Method: 采用两阶段训练策略：首先使用邻域感知的软掩码为局部变化强烈的像素分配更高权重，鼓励模型早期关注细节；随后过渡到全图像训练。

Result: 实验结果表明，该方法能显著提升重建质量，并与现有INR方法互补。

Conclusion: 本文提出了一种新颖的两阶段训练策略，通过自适应权重分配来缓解INR中的频谱偏差问题，为改善图像重建质量提供了新思路。

Abstract: Implicit Neural Representations (INRs) have emerged as a powerful alternative
to traditional pixel-based formats by modeling images as continuous functions
over spatial coordinates. A key challenge, however, lies in the spectral bias
of neural networks, which tend to favor low-frequency components while
struggling to capture high-frequency (HF) details such as sharp edges and fine
textures. While prior approaches have addressed this limitation through
architectural modifications or specialized activation functions, we propose an
orthogonal direction by directly guiding the training process. Specifically, we
introduce a two-stage training strategy where a neighbor-aware soft mask
adaptively assigns higher weights to pixels with strong local variations,
encouraging early focus on fine details. The model then transitions to
full-image training. Experimental results show that our approach consistently
improves reconstruction quality and complements existing INR methods. As a
pioneering attempt to assign frequency-aware importance to pixels in image INR,
our work offers a new avenue for mitigating the spectral bias problem.

</details>


### [52] [Fast globally optimal Truncated Least Squares point cloud registration with fixed rotation axis](https://arxiv.org/abs/2508.15613)
*Ivo Ivanov,Carsten Markgraf*

Main category: cs.CV

TL;DR: 提出了一种快速全局最优的点云配准方法，比现有SDP求解器快两个数量级，适用于旋转-only问题。


<details>
  <summary>Details</summary>
Motivation: 点云配准在给定对应关系下，使用截断最小二乘（TLS）可以抵抗高达95%的异常值，但解决这一组合优化问题到全局最优具有挑战性。现有的SDP松弛方法需要数百秒处理100个点。

Method: 提出了一种新颖的线性时间凸松弛方法以及加速分支定界（BnB）的contractor方法。

Result: 提出的求解器在旋转轴已知时，能在半秒内将两个3D点云（100个点）配准到全局最优。

Conclusion: 虽然当前方法无法解决完整的6自由度问题，但在旋转-only TLS问题上，其速度比最先进的SDP求解器STRIDE快两个数量级，并在半秒内实现了全局最优性。

Abstract: Recent results showed that point cloud registration with given
correspondences can be made robust to outlier rates of up to 95\% using the
truncated least squares (TLS) formulation. However, solving this combinatorial
optimization problem to global optimality is challenging. Provably globally
optimal approaches using semidefinite programming (SDP) relaxations take
hundreds of seconds for 100 points. In this paper, we propose a novel linear
time convex relaxation as well as a contractor method to speed up Branch and
Bound (BnB). Our solver can register two 3D point clouds with 100 points to
provable global optimality in less than half a second when the axis of rotation
is provided. Although it currently cannot solve the full 6DoF problem, it is
two orders of magnitude faster than the state-of-the-art SDP solver STRIDE when
solving the rotation-only TLS problem. In addition to providing a formal proof
for global optimality, we present empirical evidence of global optimality using
adversarial instances with local minimas close to the global minimum.

</details>


### [53] [Multi-perspective monitoring of wildlife and human activities from camera traps and drones with deep learning models](https://arxiv.org/abs/2508.15629)
*Hao Chen,Fang Qiu,Li An,Douglas Stow,Eve Bohnett,Haitao Lyu,Shuang Tian*

Main category: cs.CV

TL;DR: 研究结合相机陷阱和无人机热成像，利用深度学习模型识别野生动物与人类活动，发现潜在冲突区域，提升监测效率。


<details>
  <summary>Details</summary>
Motivation: 理解野生动物与人类活动的空间分布对于评估两者互动及制定有效保护计划至关重要。

Method: 研究结合了相机陷阱和无人机热成像技术，利用深度学习模型（如YOLOv11s和增强版Faster RCNN）自动识别野生动物和人类活动，并进行空间模式分析。

Result: YOLOv11s模型在相机陷阱图像中表现最佳（精确度96.2%，召回率92.3%）。无人机热成像为监测提供了补充视角。空间分析识别了活动热点及潜在冲突区域。

Conclusion: 该研究揭示了保护景观中的人与野生动物冲突。通过整合多视角监测与自动化目标检测，提升了野生动物监测和景观管理的效率。

Abstract: Wildlife and human activities are key components of landscape systems.
Understanding their spatial distribution is essential for evaluating human
wildlife interactions and informing effective conservation planning.
Multiperspective monitoring of wildlife and human activities by combining
camera traps and drone imagery. Capturing the spatial patterns of their
distributions, which allows the identification of the overlap of their activity
zones and the assessment of the degree of human wildlife conflict. The study
was conducted in Chitwan National Park (CNP), Nepal, and adjacent regions.
Images collected by visible and nearinfrared camera traps and thermal infrared
drones from February to July 2022 were processed to create training and testing
datasets, which were used to build deep learning models to automatic identify
wildlife and human activities. Drone collected thermal imagery was used for
detecting targets to provide a multiple monitoring perspective. Spatial pattern
analysis was performed to identify animal and resident activity hotspots and
delineation potential human wildlife conflict zones. Among the deep learning
models tested, YOLOv11s achieved the highest performance with a precision of
96.2%, recall of 92.3%, mAP50 of 96.7%, and mAP50 of 81.3%, making it the most
effective for detecting objects in camera trap imagery. Drone based thermal
imagery, analyzed with an enhanced Faster RCNN model, added a complementary
aerial viewpoint for camera trap detections. Spatial pattern analysis
identified clear hotspots for both wildlife and human activities and their
overlapping patterns within certain areas in the CNP and buffer zones
indicating potential conflict. This study reveals human wildlife conflicts
within the conserved landscape. Integrating multiperspective monitoring with
automated object detection enhances wildlife surveillance and landscape
management.

</details>


### [54] [When and What: Diffusion-Grounded VideoLLM with Entity Aware Segmentation for Long Video Understanding](https://arxiv.org/abs/2508.15641)
*Pengcheng Fang,Yuxia Chen,Rui Guo*

Main category: cs.CV

TL;DR: Grounded VideoDiT通过创新设计提升了视频LLM的时间感知和实体交互能力，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频LLM在时间感知上的不足，如时间戳编码隐式、帧级特征连续性弱、语言视觉对齐漂移等问题。

Method: 1. 使用Diffusion Temporal Latent (DTL)编码器增强边界敏感性和时间一致性。2. 通过对象接地表示将查询实体与局部视觉证据显式绑定。3. 采用混合令牌方案，包括离散时间令牌，实现精细的时间建模。

Result: 在Charades STA、NExT GQA和多个VideoQA基准测试中取得了最先进的结果。

Conclusion: Grounded VideoDiT通过引入DTL编码器、对象接地表示和混合令牌方案，显著提升了视频理解中的时间感知和实体交互能力，并在多个基准测试中取得了最先进的结果。

Abstract: Understanding videos requires more than answering open ended questions, it
demands the ability to pinpoint when events occur and how entities interact
across time. While recent Video LLMs have achieved remarkable progress in
holistic reasoning, they remain coarse in temporal perception: timestamps are
encoded only implicitly, frame level features are weak in capturing continuity,
and language vision alignment often drifts from the entities of interest. In
this paper, we present Grounded VideoDiT, a Video LLM designed to overcome
these limitations by introducing three key innovations. First, a Diffusion
Temporal Latent (DTL) encoder enhances boundary sensitivity and maintains
temporal consistency. Second, object grounded representations explicitly bind
query entities to localized visual evidence, strengthening alignment. Third, a
mixed token scheme with discrete temporal tokens provides explicit timestamp
modeling, enabling fine grained temporal reasoning. Together, these designs
equip Grounded VideoDiT with robust grounding capabilities, as validated by
state of the art results on Charades STA, NExT GQA, and multiple VideoQA
benchmarks.

</details>


### [55] [Weakly-Supervised Learning for Tree Instances Segmentation in Airborne Lidar Point Clouds](https://arxiv.org/abs/2508.15646)
*Swann Emilien Céleste Destouches,Jesse Lahaye,Laurent Valentin Jospin,Jan Skaloud*

Main category: cs.CV

TL;DR: 提出弱监督方法优化ALS数据树木实例分割，通过人工评级和模型反馈提升性能34%，但在稀疏林区和复杂环境中仍有挑战。


<details>
  <summary>Details</summary>
Motivation: ALS数据的树木实例分割对森林监测至关重要，但由于数据变异性和精确标注数据的高成本，传统全监督方法面临挑战。

Method: 提出一种弱监督方法，通过人工操作员对初始分割结果进行质量评级，训练评分模型，并利用其反馈优化分割模型。

Result: 该方法将正确识别的树木实例数量提高了34%，并显著减少了非树木实例的预测。

Conclusion: 提出的弱监督方法在树木实例分割中表现显著，正确识别率提高了34%，同时减少了非树木实例的预测。然而，在稀疏林区或复杂环境中（如灌木、巨石等）的性能仍有提升空间。

Abstract: Tree instance segmentation of airborne laser scanning (ALS) data is of utmost
importance for forest monitoring, but remains challenging due to variations in
the data caused by factors such as sensor resolution, vegetation state at
acquisition time, terrain characteristics, etc. Moreover, obtaining a
sufficient amount of precisely labeled data to train fully supervised instance
segmentation methods is expensive. To address these challenges, we propose a
weakly supervised approach where labels of an initial segmentation result
obtained either by a non-finetuned model or a closed form algorithm are
provided as a quality rating by a human operator. The labels produced during
the quality assessment are then used to train a rating model, whose task is to
classify a segmentation output into the same classes as specified by the human
operator. Finally, the segmentation model is finetuned using feedback from the
rating model. This in turn improves the original segmentation model by 34\% in
terms of correctly identified tree instances while considerably reducing the
number of non-tree instances predicted. Challenges still remain in data over
sparsely forested regions characterized by small trees (less than two meters in
height) or within complex surroundings containing shrubs, boulders, etc. which
can be confused as trees where the performance of the proposed method is
reduced.

</details>


### [56] [Towards a 3D Transfer-based Black-box Attack via Critical Feature Guidance](https://arxiv.org/abs/2508.15650)
*Shuchao Pang,Zhenghan Chen,Shen Zhang,Liming Lu,Siyuan Liang,Anan Du,Yongbin Zhou*

Main category: cs.CV

TL;DR: CFG是一种基于关键特征引导的迁移攻击方法，不依赖目标模型信息，显著提高了对抗性点云的迁移性。


<details>
  <summary>Details</summary>
Motivation: 在现实场景中，由于无法获取目标模型的任何信息，传统的对抗攻击方法难以适用，因此需要一种不依赖目标模型信息的迁移攻击方法。

Method: 提出了一种基于关键特征引导（CFG）的迁移攻击方法，通过计算提取特征的重要性来正则化对抗性点云的搜索，优先破坏可能被不同架构采用的关键特征。

Result: 在ModelNet40和ScanObjectNN数据集上的实验表明，CFG方法在攻击迁移性方面大幅优于现有方法。

Conclusion: CFG方法通过关键特征引导显著提高了对抗性点云的迁移性，并在ModelNet40和ScanObjectNN基准数据集上大幅优于现有攻击方法。

Abstract: Deep neural networks for 3D point clouds have been demonstrated to be
vulnerable to adversarial examples. Previous 3D adversarial attack methods
often exploit certain information about the target models, such as model
parameters or outputs, to generate adversarial point clouds. However, in
realistic scenarios, it is challenging to obtain any information about the
target models under conditions of absolute security. Therefore, we focus on
transfer-based attacks, where generating adversarial point clouds does not
require any information about the target models. Based on our observation that
the critical features used for point cloud classification are consistent across
different DNN architectures, we propose CFG, a novel transfer-based black-box
attack method that improves the transferability of adversarial point clouds via
the proposed Critical Feature Guidance. Specifically, our method regularizes
the search of adversarial point clouds by computing the importance of the
extracted features, prioritizing the corruption of critical features that are
likely to be adopted by diverse architectures. Further, we explicitly constrain
the maximum deviation extent of the generated adversarial point clouds in the
loss function to ensure their imperceptibility. Extensive experiments conducted
on the ModelNet40 and ScanObjectNN benchmark datasets demonstrate that the
proposed CFG outperforms the state-of-the-art attack methods by a large margin.

</details>


### [57] [MapKD: Unlocking Prior Knowledge with Cross-Modal Distillation for Efficient Online HD Map Construction](https://arxiv.org/abs/2508.15653)
*Ziyang Yan,Ruikai Li,Zhiyong Cui,Bohan Li,Han Jiang,Yilong Ren,Aoyong Li,Zhenning Li,Sijia Wen,Haiyang Yu*

Main category: cs.CV

TL;DR: MapKD通过知识蒸馏将多模态教师模型的知识转移到轻量级视觉学生模型，显著提升性能并加速推理。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖离线地图和多模态传感器，导致推理时不必要的计算开销。MapKD旨在通过知识蒸馏实现高效、低成本的视觉中心模型。

Method: 提出了MapKD框架，采用Teacher-Coach-Student（TCS）范式，结合Token-Guided 2D Patch Distillation（TGPD）和Masked Semantic Response Distillation（MSRD）两种知识蒸馏策略。

Result: 在nuScenes数据集上，学生模型的mIoU提升了+6.68，mAP提升了+10.94，同时推理速度加快。

Conclusion: MapKD通过知识蒸馏策略显著提升了视觉中心学生模型的性能，同时加快了推理速度。

Abstract: Online HD map construction is a fundamental task in autonomous driving
systems, aiming to acquire semantic information of map elements around the ego
vehicle based on real-time sensor inputs. Recently, several approaches have
achieved promising results by incorporating offline priors such as SD maps and
HD maps or by fusing multi-modal data. However, these methods depend on stale
offline maps and multi-modal sensor suites, resulting in avoidable
computational overhead at inference. To address these limitations, we employ a
knowledge distillation strategy to transfer knowledge from multimodal models
with prior knowledge to an efficient, low-cost, and vision-centric student
model. Specifically, we propose MapKD, a novel multi-level cross-modal
knowledge distillation framework with an innovative Teacher-Coach-Student (TCS)
paradigm. This framework consists of: (1) a camera-LiDAR fusion model with
SD/HD map priors serving as the teacher; (2) a vision-centric coach model with
prior knowledge and simulated LiDAR to bridge the cross-modal knowledge
transfer gap; and (3) a lightweight vision-based student model. Additionally,
we introduce two targeted knowledge distillation strategies: Token-Guided 2D
Patch Distillation (TGPD) for bird's eye view feature alignment and Masked
Semantic Response Distillation (MSRD) for semantic learning guidance. Extensive
experiments on the challenging nuScenes dataset demonstrate that MapKD improves
the student model by +6.68 mIoU and +10.94 mAP while simultaneously
accelerating inference speed. The code is available
at:https://github.com/2004yan/MapKD2026.

</details>


### [58] [CM2LoD3: Reconstructing LoD3 Building Models Using Semantic Conflict Maps](https://arxiv.org/abs/2508.15672)
*Franz Hanke,Antonia Bieringer,Olaf Wysocki,Boris Jutzi*

Main category: cs.CV

TL;DR: CM2LoD3是一种自动化重建LoD3建筑模型的新方法，通过冲突地图和纹理模型分割的结合，显著提升了重建精度，为3D城市建模提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的LoD1和LoD2建筑模型缺乏详细的外立面元素，而传统LoD3模型的生成依赖手动建模，难以大规模应用。因此，需要一种自动化方法来高效生成LoD3模型。

Method: CM2LoD3方法利用从光线到模型先验分析中获得的冲突地图（CMs），并结合合成的语义冲突地图（SCMG）进行语义分割。此外，通过置信度分数将纹理模型的分割结果与CMs融合，进一步提升了分割性能和3D重建精度。

Result: 实验结果表明，CM2LoD3方法在分割和重建建筑开口方面表现优异，结合纹理模型分割后，性能提升至61%。

Conclusion: 本研究提出的CM2LoD3方法通过结合冲突地图（CMs）和纹理模型的分割，显著提高了LoD3建筑模型的自动化重建精度，为高效、可扩展的3D城市建模提供了新途径。

Abstract: Detailed 3D building models are crucial for urban planning, digital twins,
and disaster management applications. While Level of Detail 1 (LoD)1 and LoD2
building models are widely available, they lack detailed facade elements
essential for advanced urban analysis. In contrast, LoD3 models address this
limitation by incorporating facade elements such as windows, doors, and
underpasses. However, their generation has traditionally required manual
modeling, making large-scale adoption challenging. In this contribution,
CM2LoD3, we present a novel method for reconstructing LoD3 building models
leveraging Conflict Maps (CMs) obtained from ray-to-model-prior analysis.
Unlike previous works, we concentrate on semantically segmenting real-world CMs
with synthetically generated CMs from our developed Semantic Conflict Map
Generator (SCMG). We also observe that additional segmentation of textured
models can be fused with CMs using confidence scores to further increase
segmentation performance and thus increase 3D reconstruction accuracy.
Experimental results demonstrate the effectiveness of our CM2LoD3 method in
segmenting and reconstructing building openings, with the 61% performance with
uncertainty-aware fusion of segmented building textures. This research
contributes to the advancement of automated LoD3 model reconstruction, paving
the way for scalable and efficient 3D city modeling. Our project is available:
https://github.com/InFraHank/CM2LoD3

</details>


### [59] [LLM-empowered Dynamic Prompt Routing for Vision-Language Models Tuning under Long-Tailed Distributions](https://arxiv.org/abs/2508.15688)
*Yongju Jia,Jiarui Ma,Xiangxian Li,Baiqiao Zhang,Xianhui Cao,Juan Liu,Yulong Bian*

Main category: cs.CV

TL;DR: MDPR框架通过动态路由和多维知识库，解决了VLM在类别不平衡场景下的偏见问题，并在多个长尾基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的VLM微调方法在类别不平衡场景中容易积累偏见，且往往忽视了VLM预训练中固有的类别不平衡问题。

Method: 提出了Multi-dimensional Dynamic Prompt Routing (MDPR)框架，构建了一个覆盖五个视觉-语义维度的知识库，并通过动态路由机制对齐全局视觉类别、检索最优提示并平衡细粒度语义。

Result: 在CIFAR-LT、ImageNet-LT和Places-LT等长尾基准测试中，MDPR取得了与当前SOTA方法相当的结果，且动态路由的计算开销极小。

Conclusion: MDPR框架通过动态路由机制和多维知识库，有效缓解了VLM在类别不平衡场景下的偏见问题，并在多个长尾基准测试中取得了与当前SOTA方法相当的结果。

Abstract: Pre-trained vision-language models (VLMs), such as CLIP, have demonstrated
impressive capability in visual tasks, but their fine-tuning often suffers from
bias in class-imbalanced scene. Recent works have introduced large language
models (LLMs) to enhance VLM fine-tuning with supplementing semantic
information. However, they often overlook inherent class imbalance in VLMs'
pre-training, which may lead to bias accumulation in downstream tasks. To
address this problem, this paper proposes a Multi-dimensional Dynamic Prompt
Routing (MDPR) framework. MDPR constructs a comprehensive knowledge base for
classes, spanning five visual-semantic dimensions. During fine-tuning, the
dynamic routing mechanism aligns global visual classes, retrieves optimal
prompts, and balances fine-grained semantics, yielding stable predictions
through logits fusion. Extensive experiments on long-tailed benchmarks,
including CIFAR-LT, ImageNet-LT, and Places-LT, demonstrate that MDPR achieves
comparable results with current SOTA methods. Ablation studies further confirm
the effectiveness of our semantic library for tail classes, and show that our
dynamic routing incurs minimal computational overhead, making MDPR a flexible
and efficient enhancement for VLM fine-tuning under data imbalance.

</details>


### [60] [StreamMem: Query-Agnostic KV Cache Memory for Streaming Video Understanding](https://arxiv.org/abs/2508.15717)
*Yanlai Yang,Zhuokai Zhao,Satya Narayan Shukla,Aashu Singh,Shlok Kumar Mishra,Lizhu Zhang,Mengye Ren*

Main category: cs.CV

TL;DR: StreamMem是一种查询无关的KV缓存内存机制，用于流式视频理解，解决了长视频处理中的内存和计算开销问题，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在视觉语言推理方面取得了显著进展，但在处理长视频时仍存在存储和计算开销大的问题。现有的视觉压缩方法要么需要预先编码整个视觉上下文，要么需要提前获取问题，这在长视频理解和多轮对话场景中不切实际。

Method: StreamMem通过流式编码新视频帧，利用视觉标记与通用查询标记之间的注意力分数压缩KV缓存，并保持固定大小的KV内存，以在内存受限的长视频场景中实现高效问答。

Result: 在三个长视频理解和两个流式视频问答基准测试中，StreamMem在查询无关的KV缓存压缩方面达到了最先进的性能，并与查询感知的压缩方法竞争。

Conclusion: StreamMem提出了一种查询无关的KV缓存内存机制，用于流式视频理解，在长视频理解和多轮对话场景中表现出色，且在查询无关的KV缓存压缩方面达到了最先进的性能。

Abstract: Multimodal large language models (MLLMs) have made significant progress in
visual-language reasoning, but their ability to efficiently handle long videos
remains limited. Despite recent advances in long-context MLLMs, storing and
attending to the key-value (KV) cache for long visual contexts incurs
substantial memory and computational overhead. Existing visual compression
methods require either encoding the entire visual context before compression or
having access to the questions in advance, which is impractical for long video
understanding and multi-turn conversational settings. In this work, we propose
StreamMem, a query-agnostic KV cache memory mechanism for streaming video
understanding. Specifically, StreamMem encodes new video frames in a streaming
manner, compressing the KV cache using attention scores between visual tokens
and generic query tokens, while maintaining a fixed-size KV memory to enable
efficient question answering (QA) in memory-constrained, long-video scenarios.
Evaluation on three long video understanding and two streaming video question
answering benchmarks shows that StreamMem achieves state-of-the-art performance
in query-agnostic KV cache compression and is competitive with query-aware
compression approaches.

</details>


### [61] [WorldWeaver: Generating Long-Horizon Video Worlds via Rich Perception](https://arxiv.org/abs/2508.15720)
*Zhiheng Liu,Xueqing Deng,Shoufa Chen,Angtian Wang,Qiushan Guo,Mingfei Han,Zeyue Xue,Mengzhao Chen,Ping Luo,Linjie Yang*

Main category: cs.CV

TL;DR: WorldWeaver通过联合建模RGB和感知条件，利用深度线索和分段噪声调度，提升了长视频生成的一致性和质量。


<details>
  <summary>Details</summary>
Motivation: 解决生成视频中因依赖RGB信号导致的结构和运动在长时间序列中累积错误的问题。

Method: WorldWeaver采用统一的长期建模方案，联合预测感知条件和颜色信息，利用深度线索构建记忆库，并采用分段噪声调度训练预测组。

Result: 实验证明，WorldWeaver在减少时间漂移和提高生成视频保真度方面有效。

Conclusion: WorldWeaver框架通过联合建模RGB帧和感知条件，显著提升了长视频生成的时间一致性和运动动态效果，同时通过深度线索和分段噪声调度减少了漂移和计算成本。

Abstract: Generative video modeling has made significant strides, yet ensuring
structural and temporal consistency over long sequences remains a challenge.
Current methods predominantly rely on RGB signals, leading to accumulated
errors in object structure and motion over extended durations. To address these
issues, we introduce WorldWeaver, a robust framework for long video generation
that jointly models RGB frames and perceptual conditions within a unified
long-horizon modeling scheme. Our training framework offers three key
advantages. First, by jointly predicting perceptual conditions and color
information from a unified representation, it significantly enhances temporal
consistency and motion dynamics. Second, by leveraging depth cues, which we
observe to be more resistant to drift than RGB, we construct a memory bank that
preserves clearer contextual information, improving quality in long-horizon
video generation. Third, we employ segmented noise scheduling for training
prediction groups, which further mitigates drift and reduces computational
cost. Extensive experiments on both diffusion- and rectified flow-based models
demonstrate the effectiveness of WorldWeaver in reducing temporal drift and
improving the fidelity of generated videos.

</details>


### [62] [SceneGen: Single-Image 3D Scene Generation in One Feedforward Pass](https://arxiv.org/abs/2508.15769)
*Yanxu Meng,Haoning Wu,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: SceneGen是一种无需优化或资产检索的新框架，可从单张场景图像中生成多个3D资产及其空间位置，适用于VR/AR和具身AI。


<details>
  <summary>Details</summary>
Motivation: 3D内容生成在VR/AR和具身AI中具有重要应用价值，但现有方法难以从单张场景图像中合成多个3D资产。SceneGen旨在解决这一问题。

Method: SceneGen是一个新颖框架，结合了视觉和几何编码器的特征提取模块，引入局部和全局场景信息的特征聚合模块，以及位置头，实现单次前向传递生成3D资产及其空间位置。

Result: 实验表明，SceneGen能够高效、鲁棒地生成3D内容，且可直接扩展至多图像输入场景，尽管仅使用单图像训练。

Conclusion: SceneGen提出了一种高质量3D内容生成的新范式，通过单次前向传递即可生成多个3D资产及其空间位置，无需优化或资产检索。该方法在VR/AR和具身AI等领域具有潜在应用价值。

Abstract: 3D content generation has recently attracted significant research interest
due to its applications in VR/AR and embodied AI. In this work, we address the
challenging task of synthesizing multiple 3D assets within a single scene
image. Concretely, our contributions are fourfold: (i) we present SceneGen, a
novel framework that takes a scene image and corresponding object masks as
input, simultaneously producing multiple 3D assets with geometry and texture.
Notably, SceneGen operates with no need for optimization or asset retrieval;
(ii) we introduce a novel feature aggregation module that integrates local and
global scene information from visual and geometric encoders within the feature
extraction module. Coupled with a position head, this enables the generation of
3D assets and their relative spatial positions in a single feedforward pass;
(iii) we demonstrate SceneGen's direct extensibility to multi-image input
scenarios. Despite being trained solely on single-image inputs, our
architectural design enables improved generation performance with multi-image
inputs; and (iv) extensive quantitative and qualitative evaluations confirm the
efficiency and robust generation abilities of our approach. We believe this
paradigm offers a novel solution for high-quality 3D content generation,
potentially advancing its practical applications in downstream tasks. The code
and model will be publicly available at: https://mengmouxu.github.io/SceneGen.

</details>


### [63] [Fine-grained Multi-class Nuclei Segmentation with Molecular-empowered All-in-SAM Model](https://arxiv.org/abs/2508.15751)
*Xueyuan Li,Can Cui,Ruining Deng,Yucheng Tang,Quan Liu,Tianyuan Yao,Shunxing Bao,Naweed Chowdhury,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: All-in-SAM模型通过分子赋能学习、SAM适配器和MOCL，提升了细胞分割精度，减轻了标注负担，适用于资源有限的环境。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型（如SAM）在核分割方面取得进展，但在细粒度语义分割（如特定核亚型或细胞识别）上仍面临挑战。

Method: 提出了分子赋能的All-in-SAM模型，通过全栈方法实现：（1）通过分子赋能学习减少像素级标注需求；（2）利用SAM适配器增强模型对特定语义的关注；（3）通过分子导向校正学习（MOCL）提升分割精度。

Result: 实验结果表明，All-in-SAM模型显著提升了细胞分类性能，即使面对标注质量不一的情况。

Conclusion: 该研究不仅减轻了标注人员的工作负担，还将精确的生物医学图像分析扩展到资源有限的环境，从而推动了医学诊断和病理图像分析的自动化。

Abstract: Purpose: Recent developments in computational pathology have been driven by
advances in Vision Foundation Models, particularly the Segment Anything Model
(SAM). This model facilitates nuclei segmentation through two primary methods:
prompt-based zero-shot segmentation and the use of cell-specific SAM models for
direct segmentation. These approaches enable effective segmentation across a
range of nuclei and cells. However, general vision foundation models often face
challenges with fine-grained semantic segmentation, such as identifying
specific nuclei subtypes or particular cells. Approach: In this paper, we
propose the molecular-empowered All-in-SAM Model to advance computational
pathology by leveraging the capabilities of vision foundation models. This
model incorporates a full-stack approach, focusing on: (1) annotation-engaging
lay annotators through molecular-empowered learning to reduce the need for
detailed pixel-level annotations, (2) learning-adapting the SAM model to
emphasize specific semantics, which utilizes its strong generalizability with
SAM adapter, and (3) refinement-enhancing segmentation accuracy by integrating
Molecular-Oriented Corrective Learning (MOCL). Results: Experimental results
from both in-house and public datasets show that the All-in-SAM model
significantly improves cell classification performance, even when faced with
varying annotation quality. Conclusions: Our approach not only reduces the
workload for annotators but also extends the accessibility of precise
biomedical image analysis to resource-limited settings, thereby advancing
medical diagnostics and automating pathology image analysis.

</details>


### [64] [Waver: Wave Your Way to Lifelike Video Generation](https://arxiv.org/abs/2508.15761)
*Yifu Zhang,Hao Yang,Yuqi Zhang,Yifei Hu,Fengda Zhu,Chuang Lin,Xiaofeng Mei,Yi Jiang,Zehuan Yuan,Bingyue Peng*

Main category: cs.CV

TL;DR: Waver是一个高性能的视频生成模型，支持多种任务，通过创新架构和数据优化，生成高质量视频并取得领先成绩。


<details>
  <summary>Details</summary>
Motivation: 为了推动视频生成技术的发展，提供一个统一的高性能模型，支持多种生成任务（T2V、I2V、T2I）。

Method: 引入Hybrid Stream DiT架构以增强模态对齐并加速训练收敛，同时建立了全面的数据筛选流程和质量模型。

Result: Waver在T2V和I2V榜单中排名前三，优于现有开源模型并与商业解决方案匹敌。

Conclusion: Waver在视频生成技术中表现出色，能够高效生成高质量视频，并在多个任务中超越现有开源模型和商业解决方案。

Abstract: We present Waver, a high-performance foundation model for unified image and
video generation. Waver can directly generate videos with durations ranging
from 5 to 10 seconds at a native resolution of 720p, which are subsequently
upscaled to 1080p. The model simultaneously supports text-to-video (T2V),
image-to-video (I2V), and text-to-image (T2I) generation within a single,
integrated framework. We introduce a Hybrid Stream DiT architecture to enhance
modality alignment and accelerate training convergence. To ensure training data
quality, we establish a comprehensive data curation pipeline and manually
annotate and train an MLLM-based video quality model to filter for the
highest-quality samples. Furthermore, we provide detailed training and
inference recipes to facilitate the generation of high-quality videos. Building
on these contributions, Waver excels at capturing complex motion, achieving
superior motion amplitude and temporal consistency in video synthesis. Notably,
it ranks among the Top 3 on both the T2V and I2V leaderboards at Artificial
Analysis (data as of 2025-07-30 10:00 GMT+8), consistently outperforming
existing open-source models and matching or surpassing state-of-the-art
commercial solutions. We hope this technical report will help the community
more efficiently train high-quality video generation models and accelerate
progress in video generation technologies. Official page:
https://github.com/FoundationVision/Waver.

</details>


### [65] [ATLAS: Decoupling Skeletal and Shape Parameters for Expressive Parametric Human Modeling](https://arxiv.org/abs/2508.15767)
*Jinhyung Park,Javier Romero,Shunsuke Saito,Fabian Prada,Takaaki Shiratori,Yichen Xu,Federica Bogo,Shoou-I Yu,Kris Kitani,Rawal Khirodkar*

Main category: cs.CV

TL;DR: ATLAS是一种高保真人体模型，通过解耦形状和骨骼基础，提升了表达能力和控制灵活性，在复杂姿态下表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有参数化人体模型在姿态和形状多样性上表现不足，且内部骨骼与外部软组织之间存在依赖关系，限制了直接控制能力。

Method: ATLAS基于600K高分辨率扫描数据，采用非线性姿态校正方法，并显式解耦形状和骨骼基础。

Result: ATLAS在多样姿态下对未见过的对象拟合更准确，非线性姿态校正比线性模型更有效地捕捉复杂姿态。

Conclusion: ATLAS模型通过解耦形状和骨骼基础，提供了更高的形状表达能力和精细化的身体属性定制，同时在复杂姿态下表现优于现有线性模型。

Abstract: Parametric body models offer expressive 3D representation of humans across a
wide range of poses, shapes, and facial expressions, typically derived by
learning a basis over registered 3D meshes. However, existing human mesh
modeling approaches struggle to capture detailed variations across diverse body
poses and shapes, largely due to limited training data diversity and
restrictive modeling assumptions. Moreover, the common paradigm first optimizes
the external body surface using a linear basis, then regresses internal
skeletal joints from surface vertices. This approach introduces problematic
dependencies between internal skeleton and outer soft tissue, limiting direct
control over body height and bone lengths. To address these issues, we present
ATLAS, a high-fidelity body model learned from 600k high-resolution scans
captured using 240 synchronized cameras. Unlike previous methods, we explicitly
decouple the shape and skeleton bases by grounding our mesh representation in
the human skeleton. This decoupling enables enhanced shape expressivity,
fine-grained customization of body attributes, and keypoint fitting independent
of external soft-tissue characteristics. ATLAS outperforms existing methods by
fitting unseen subjects in diverse poses more accurately, and quantitative
evaluations show that our non-linear pose correctives more effectively capture
complex poses compared to linear models.

</details>


### [66] [Visual Autoregressive Modeling for Instruction-Guided Image Editing](https://arxiv.org/abs/2508.15772)
*Qingyang Mao,Qi Cai,Yehao Li,Yingwei Pan,Mingyue Cheng,Ting Yao,Qi Liu,Tao Mei*

Main category: cs.CV

TL;DR: VAREdit是一种视觉自回归框架，通过多尺度特征预测和Scale-Aligned Reference模块，显著提升图像编辑的精确度和效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在全局去噪过程中会导致编辑区域与整个图像上下文纠缠，产生不必要的修改，而自回归模型的因果和组合机制能更精确地遵循编辑指令。

Method: 提出VAREdit框架，将图像编辑重构为多尺度特征预测问题，并引入Scale-Aligned Reference模块以优化源图像特征的引导。

Result: VAREdit在标准基准测试中比领先的扩散模型方法高出30%以上的GPT-Balance分数，且编辑速度更快（1.2秒完成512×512编辑）。

Conclusion: VAREdit通过视觉自回归框架和Scale-Aligned Reference模块，显著提升了图像编辑的精确度和效率，超越了现有扩散模型方法。

Abstract: Recent advances in diffusion models have brought remarkable visual fidelity
to instruction-guided image editing. However, their global denoising process
inherently entangles the edited region with the entire image context, leading
to unintended spurious modifications and compromised adherence to editing
instructions. In contrast, autoregressive models offer a distinct paradigm by
formulating image synthesis as a sequential process over discrete visual
tokens. Their causal and compositional mechanism naturally circumvents the
adherence challenges of diffusion-based methods. In this paper, we present
VAREdit, a visual autoregressive (VAR) framework that reframes image editing as
a next-scale prediction problem. Conditioned on source image features and text
instructions, VAREdit generates multi-scale target features to achieve precise
edits. A core challenge in this paradigm is how to effectively condition the
source image tokens. We observe that finest-scale source features cannot
effectively guide the prediction of coarser target features. To bridge this
gap, we introduce a Scale-Aligned Reference (SAR) module, which injects
scale-matched conditioning information into the first self-attention layer.
VAREdit demonstrates significant advancements in both editing adherence and
efficiency. On standard benchmarks, it outperforms leading diffusion-based
methods by 30\%+ higher GPT-Balance score. Moreover, it completes a
$512\times512$ editing in 1.2 seconds, making it 2.2$\times$ faster than the
similarly sized UltraEdit. The models are available at
https://github.com/HiDream-ai/VAREdit.

</details>


### [67] [CineScale: Free Lunch in High-Resolution Cinematic Visual Generation](https://arxiv.org/abs/2508.15774)
*Haonan Qiu,Ning Yu,Ziqi Huang,Paul Debevec,Ziwei Liu*

Main category: cs.CV

TL;DR: CineScale是一种新的推理范式，解决了预训练模型在高分辨率视觉生成中的重复模式问题，实现了无需微调的8K图像和4K视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有视觉扩散模型因缺乏高分辨率数据和计算资源限制，难以生成高质量的高分辨率内容，且现有方法易产生低质量重复模式。

Method: CineScale针对两种视频生成架构设计了专用变体，解决了高分辨率生成中的高频信息增加和重复模式问题。

Result: 实验证明CineScale在扩展图像和视频模型的高分辨率生成能力方面具有优越性，实现了8K图像生成和4K视频生成。

Conclusion: CineScale提出了一种新的推理范式，能够在不进行微调的情况下实现更高分辨率的视觉生成，包括8K图像和4K视频。

Abstract: Visual diffusion models achieve remarkable progress, yet they are typically
trained at limited resolutions due to the lack of high-resolution data and
constrained computation resources, hampering their ability to generate
high-fidelity images or videos at higher resolutions. Recent efforts have
explored tuning-free strategies to exhibit the untapped potential
higher-resolution visual generation of pre-trained models. However, these
methods are still prone to producing low-quality visual content with repetitive
patterns. The key obstacle lies in the inevitable increase in high-frequency
information when the model generates visual content exceeding its training
resolution, leading to undesirable repetitive patterns deriving from the
accumulated errors. In this work, we propose CineScale, a novel inference
paradigm to enable higher-resolution visual generation. To tackle the various
issues introduced by the two types of video generation architectures, we
propose dedicated variants tailored to each. Unlike existing baseline methods
that are confined to high-resolution T2I and T2V generation, CineScale broadens
the scope by enabling high-resolution I2V and V2V synthesis, built atop
state-of-the-art open-source video generation frameworks. Extensive experiments
validate the superiority of our paradigm in extending the capabilities of
higher-resolution visual generation for both image and video models.
Remarkably, our approach enables 8k image generation without any fine-tuning,
and achieves 4k video generation with only minimal LoRA fine-tuning. Generated
video samples are available at our website:
https://eyeline-labs.github.io/CineScale/.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [68] [Declarative Data Pipeline for Large Scale ML Services](https://arxiv.org/abs/2508.15105)
*Yunzhao Yang,Runhui Wang,Xuanqing Liu,Adit Krishnan,Yefan Tao,Yuqian Deng,Kuangyou Yao,Peiyuan Sun,Henrik Johnson,Aditi sinha,Davor Golac,Gerald Friedland,Usman Shakeel,Daryl Cooke,Joe Sullivan,Chris Kong*

Main category: cs.DC

TL;DR: 提出“声明式数据管道”架构，通过模块化设计在Apache Spark中高效集成机器学习，显著提升开发效率、协作速度和系统性能。


<details>
  <summary>Details</summary>
Motivation: 现代分布式数据处理系统在大规模集成机器学习能力时，面临性能与开发效率、代码可维护性的平衡挑战，尤其是在多团队协作的高通信开销和复杂协调环境下。

Method: 采用模块化框架，结合逻辑计算单元（Pipes），在Apache Spark中无缝集成机器学习能力，摒弃传统的微服务方法，通过清晰组件边界和标准化接口实现优化。

Result: 企业案例显示开发效率提升50%，协作/故障排除时间从数周缩短至数天，性能提升500倍（扩展性）和10倍（吞吐量）；学术实验证明吞吐量至少快5.7倍，CPU利用率达99%。

Conclusion: 本文提出了一种新颖的“声明式数据管道”架构，成功解决了分布式数据处理系统中性能与代码可维护性及开发效率的平衡问题，并通过企业案例和学术实验验证了其显著优势。

Abstract: Modern distributed data processing systems face significant challenges in
balancing system performance with code maintainability and developer
productivity, particularly when integrating machine learning capabilities at
scale. In large collaborative environments, these challenges are amplified by
high communication overhead between teams and the complexity of coordinating
development across multiple groups. This paper presents a novel "Declarative
Data Pipeline" architecture that addresses these challenges while processing
billions of records with high accuracy and efficiency. Our architecture
introduces a modular framework that seamlessly integrates machine learning
capabilities within Apache Spark by combining logical computation units that we
refer as Pipes, departing from traditional microservice-based approaches. By
establishing clear component boundaries and standardized interfaces, we achieve
both modularity and system optimization without sacrificing maintainability.
The enterprise case study demonstrate substantial improvements in multiple
dimensions: development efficiency improved by 50%,
collaboration/troubleshooting efforts compressed from weeks to days,
performance improved by 500x in scalability and by 10x in throughput. The
academic experiment also proves at least 5.7x faster in throughput with 99% CPU
utilization than non-framework implementations. This paper details the
architectural decisions, implementation strategies, and performance
optimizations that enable these improvements, providing insights for building
scalable, maintainable data processing systems that effectively balance system
performance with development velocity.

</details>


### [69] [Databelt: A Continuous Data Path for Serverless Workflows in the 3D Compute Continuum](https://arxiv.org/abs/2508.15351)
*Cynthia Marcelino,Leonard Guelmino,Thomas Pusztai,Stefan Nastic*

Main category: cs.DC

TL;DR: Databelt是一个针对3D计算连续体的无服务器工作流状态管理框架，通过状态传播和融合机制显著降低延迟并提高效率。


<details>
  <summary>Details</summary>
Motivation: 在3D计算连续体中，无服务器函数面临网络拓扑频繁变化导致的延迟和冗余数据传输问题，需要高效的状态管理框架。

Method: Databelt引入了SLO感知的状态传播机制和函数状态融合机制，主动卸载函数状态至最合适的节点，并抽象共享同一运行时的函数状态管理。

Result: 实验表明，Databelt将工作流执行时间减少高达66%，吞吐量提高50%，存储操作延迟减少20%。

Conclusion: Databelt显著降低了工作流执行时间，提高了吞吐量，并通过状态融合机制减少了存储操作延迟，适用于3D计算连续体中的动态网络环境。

Abstract: Typically, serverless functions rely on remote storage services for managing
state, which can result in increased latency and network communication
overhead. In a dynamic environment such as the 3D (Edge-Cloud-Space) Compute
Continuum, serverless functions face additional challenges due to frequent
changes in network topology. As satellites move in and out of the range of
ground stations, functions must make multiple hops to access cloud services,
leading to high-latency state access and unnecessary data transfers. In this
paper, we present Databelt, a state management framework for serverless
workflows designed for the dynamic environment of the 3D Compute Continuum.
Databelt introduces an SLO-aware state propagation mechanism that enables the
function state to move continuously in orbit. Databelt proactively offloads
function states to the most suitable node, such that when functions execute,
the data is already present on the execution node or nearby, thus minimizing
state access latency and reducing the number of network hops. Additionally,
Databelt introduces a function state fusion mechanism that abstracts state
management for functions sharing the same serverless runtime. When functions
are fused, Databelt seamlessly retrieves their state as a group, reducing
redundant network and storage operations and improving overall workflow
efficiency. Our experimental results show that Databelt reduces workflow
execution time by up to 66% and increases throughput by 50% compared to the
baselines. Furthermore, our results show that Databelt function state fusion
reduces storage operations latency by up to 20%, by reducing repetitive storage
requests for functions within the same runtime, ensuring efficient execution of
serverless workflows in highly dynamic network environments such as the 3D
Continuum.

</details>


### [70] [Universal Dancing by Luminous Robots under Sequential Schedulers](https://arxiv.org/abs/2508.15484)
*Caterina Feletti,Paola Flocchini,Debasish Pattanayak,Giuseppe Prencipe,Nicola Santoro*

Main category: cs.DC

TL;DR: 本研究通过LUMI模型和顺序调度器解决了传统舞蹈问题的约束，提出了通用舞蹈问题并提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有工作对舞蹈问题的解存在诸多限制，如模式重复、周期性、对称性和扩张/收缩等，本研究旨在通过LUMI模型和顺序调度器消除这些限制。

Method: 利用LUMI模型中的灯光颜色和顺序调度器的特性，设计了一种分布式计数器机制的算法。

Result: 证明了在LUMI模型下，通用舞蹈问题的解受限于机器人可用颜色数量的组合，并提供了确保空间均匀性的算法。

Conclusion: 通过引入LUMI模型和顺序调度器，本研究解决了传统舞蹈问题中的必要约束限制，提出了通用舞蹈问题，并证明了其可解性。

Abstract: The Dancing problem requires a swarm of $n$ autonomous mobile robots to form
a sequence of patterns, aka perform a choreography. Existing work has proven
that some crucial restrictions on choreographies and initial configurations
(e.g., on repetitions of patterns, periodicity, symmetries,
contractions/expansions) must hold so that the Dancing problem can be solved
under certain robot models. Here, we prove that these necessary constraints can
be dropped by considering the LUMI model (i.e., where robots are endowed with a
light whose color can be chosen from a constant-size palette) under the quite
unexplored sequential scheduler. We formalize the class of Universal Dancing
problems which require a swarm of $n$ robots starting from any initial
configuration to perform a (periodic or finite) sequence of arbitrary patterns,
only provided that each pattern consists of $n$ vertices (including
multiplicities). However, we prove that, to be solvable under LUMI, the length
of the feasible choreographies is bounded by the compositions of $n$ into the
number of colors available to the robots. We provide an algorithm solving the
Universal Dancing problem by exploiting the peculiar capability of sequential
robots to implement a distributed counter mechanism. Even assuming non-rigid
movements, our algorithm ensures spatial homogeneity of the performed
choreography.

</details>


### [71] [Lower Bounds for $k$-Set Agreement in Fault-Prone Networks](https://arxiv.org/abs/2508.15562)
*Pierre Fraigniaud,Minh Hang Nguyen,Ami Paz,Ulrich Schmid,Hugo Rincon Galeana*

Main category: cs.DC

TL;DR: 本文通过拓扑方法扩展了k-set协议的下界研究，适用于任意有向通信网络，并优化了证明过程。


<details>
  <summary>Details</summary>
Motivation: 现有的k-set协议下界研究主要集中在完全网络或特定网络拓扑中，缺乏对任意有向通信网络的通用性分析。本文旨在填补这一空白，提供更普适的下界结果，并优化证明过程的复杂性。

Method: 采用拓扑证明方法，通过构造一系列shellable carrier maps来分析协议复合体的演化。特别地，在前t/k轮中，每轮崩溃k个进程以确保高连通性；之后使用新型carrier map维持高连通性。还引入了Sperner引理风格的论证来证明k-set协议的不可能性。

Result: 1. 提出了适用于任意有向通信网络的k-set协议下界；2. 证明了通过Kuhn三角化可以构建更小的输入复合体；3. 展示了新型carrier map在维持高连通性中的作用。

Conclusion: 本文提出了一种新的k-set协议下界，适用于同步消息传递系统，扩展并推广了现有研究中的多个下界结果。通过拓扑证明方法，特别是基于shellable carrier maps的技术，证明了即使在任意通信网络中，k-set协议仍然存在固有的限制。此外，还展示了如何通过Kuhn三角化构建更小的输入复合体，从而优化证明过程。

Abstract: We develop a new lower bound for k-set agreement in synchronous
message-passing systems connected by an arbitrary directed communication
network, where up to t processes may crash. Our result thus generalizes the
t/k+1 lower bound for complete networks in the t-resilient model by Chaudhuri,
Herlihy, Lynch, and Tuttle [JACM'00]. Moreover, it generalizes two lower bounds
for oblivious algorithms in synchronous systems connected by an arbitrary
undirected communication network known to the processes, namely, the domination
number-based lower bound by Castaneda, Fraigniaud, Paz, Rajsbaum, Roy, and
Travers [TCS'21] for failure-free processes, and the radius-based lower bound
in the t-resilient model by Fraigniaud, Nguyen, and Paz [STACS'24].
  Our topological proof non-trivially generalizes and extends the
connectivity-based approach for the complete network, as presented in the book
by Herlihy, Kozlov, and Rajsbaum (2013). It is based on a sequence of shellable
carrier maps that, starting from a shellable input complex, determine the
evolution of the protocol complex: During the first t/k rounds, carrier maps
that crash exactly k processes per round are used, ensuring high connectivity
of their images. A Sperner's lemma style argument is used to prove that k-set
agreement is still impossible by that round. From round t/k+1 up to our lower
bound, we employ a novel carrier map that maintains high connectivity. Our
proof also provides a strikingly simple lower bound for k-set agreement in
synchronous systems with an arbitrary communication network with initial
crashes. We express the resulting additional agreement overhead via an
appropriately defined radius of the communication graphs. Finally, we prove
that the usual input pseudosphere complex for k-set agreement can be replaced
by an exponentially smaller input complex based on Kuhn triangulations, which
we prove to be also shellable.

</details>


### [72] [Efficient Mixed-Precision Large Language Model Inference with TurboMind](https://arxiv.org/abs/2508.15601)
*Li Zhang,Youhe Jiang,Guoliang He,Xin Chen,Han Lv,Qian Yao,Fangcheng Fu,Kai Chen*

Main category: cs.DC

TL;DR: 该论文提出混合精度LLM推理技术，通过两种优化流水线显著提升性能，集成至开源引擎TurboMind。


<details>
  <summary>Details</summary>
Motivation: 减少LLMs的内存和计算需求，通过混合精度格式优化模型权重、激活和KV缓存，以提升推理效率。

Method: 提出了两种新颖的混合精度流水线：优化矩阵操作的GEMM流水线和支持任意精度组合的高效注意力计算流水线。关键技术包括硬件感知权重打包、自适应头部对齐、指令级并行和KV内存加载流水线。

Result: 在16种流行LLMs和4种代表性GPU架构上的评估显示，相比现有混合精度框架，延迟降低最高61%（平均30%），吞吐量提升最高156%（平均58%）。

Conclusion: 该研究通过混合精度推理技术显著降低了大型语言模型（LLMs）的内存和计算需求，并在TurboMind高性能推理引擎中实现，开源并公开可用。

Abstract: Mixed-precision inference techniques reduce the memory and computational
demands of Large Language Models (LLMs) by applying hybrid precision formats to
model weights, activations, and KV caches. This work introduces mixed-precision
LLM inference techniques that encompass (i) systematic memory and compute
optimization across hierarchical storage and tensor core architectures, and
(ii) comprehensive end-to-end mixed-precision optimization across diverse
precision formats and hardware configurations. Our approach features two novel
mixed-precision pipelines designed for optimal hardware utilization: a General
Matrix Multiply (GEMM) pipeline that optimizes matrix operations through
offline weight packing and online acceleration, and an attention pipeline that
enables efficient attention computation with arbitrary Query, Key, and Value
precision combinations. The key implementation of the pipelines includes (i)
hardware-aware weight packing for automatic format optimization, (ii) adaptive
head alignment for efficient attention computation, (iii) instruction-level
parallelism for memory hierarchy exploitation, and (iv) KV memory loading
pipeline for enhanced inference efficiency. We conduct comprehensive
evaluations across 16 popular LLMs and 4 representative GPU architectures.
Results demonstrate that our approach achieves up to 61% lower serving latency
(30% on average) and up to 156% higher throughput (58% on average) in
mixed-precision workloads compared to existing mixed-precision frameworks,
establishing consistent performance improvements across all tested
configurations and hardware types. This work is integrated into TurboMind, a
high-performance inference engine of the LMDeploy project, which is
open-sourced and publicly available at https://github.com/InternLM/lmdeploy.

</details>


### [73] [CausalMesh: A Formally Verified Causal Cache for Stateful Serverless Computing](https://arxiv.org/abs/2508.15647)
*Haoran Zhang,Zihao Zhang,Shuai Mu,Sebastian Angel,Vincent Liu*

Main category: cs.DC

TL;DR: CausalMesh 是一种用于无服务器环境的因果一致性缓存系统，支持客户端漫游时的无协调读写操作，实验证明其性能优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 在无服务器环境中，工作流中的函数可能被调度到不同节点，导致非直观的异常。现有缓存系统无法有效支持客户端漫游时的因果一致性。

Method: CausalMesh 是一种新型缓存系统，支持在客户端漫游多个服务器时的无协调和无中止读写操作及读取事务。通过 Dafny 形式化验证其协议，并进行实验评估。

Result: CausalMesh 在延迟和吞吐量方面表现优于现有方案，且通过形式化验证确保了协议的正确性。

Conclusion: CausalMesh 是一种新颖的因果一致性缓存方法，适用于计算可能在不同机器之间迁移的环境（如无服务器计算）。它支持无协调和无中止的读写操作，以及在客户端在多个服务器之间漫游时的读取事务。虽然牺牲了中止自由性，但 CausalMesh 仍支持读写事务的因果一致性。实验评估表明，CausalMesh 在延迟和吞吐量方面优于现有方案。

Abstract: Stateful serverless workflows consist of multiple serverless functions that
access state on a remote database. Developers sometimes add a cache layer
between the serverless runtime and the database to improve I/O latency.
However, in a serverless environment, functions in the same workflow may be
scheduled to different nodes with different caches, which can cause
non-intuitive anomalies. This paper presents CausalMesh, a novel approach to
causally consistent caching in environments where a computation may migrate
from one machine to another, such as in serverless computing. CausalMesh is the
first cache system that supports coordination-free and abort-free read/write
operations and read transactions when clients roam among multiple servers.
CausalMesh also supports read-write transactional causal consistency in the
presence of client roaming, but at the cost of abort-freedom.
  We have formally verified CausalMesh's protocol in Dafny, and our
experimental evaluation shows that CausalMesh has lower latency and higher
throughput than existing proposals

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [74] [Time-Optimal Directed q-Analysis](https://arxiv.org/abs/2508.15583)
*Felix Windisch,Florian Unger*

Main category: cs.DS

TL;DR: 提出了一种高效的有向q分析算法，通过倒置计算顺序和优化策略，实现了线性于输出大小的时间复杂度，解决了现有方法效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 现有有向q分析方法由于效率低下（时间复杂度与输入大小的平方相关）而应用受限，实际网络中输出大小通常远低于最坏情况，因此需要一种高效输出敏感算法。

Method: 通过仔细研究各种有向q分析方法及其相互关系，发现计算顺序的倒置能显著降低复杂度。目标预计算和缓存策略进一步减少了开销。

Result: 开发了一种输出敏感算法，其时间复杂度在温和假设下与输出大小线性相关，且被证明是时间最优的。

Conclusion: 提出的算法在温和假设下实现了与输出大小线性相关的时间复杂度，被证明是时间最优的。

Abstract: Directed q-analysis is a recent extension of q-analysis, an established
method for extracting structure from networks, to directed graphs. Until
recently, a lack of efficient algorithms heavily restricted the application of
this technique: Previous approaches scale with the square of the input size,
which is also the maximal size of the output, rendering such approaches
worst-case optimal. In practice, output sizes of relevant networks are usually
far from the worst case, a fact that could be exploited by an (efficient)
output-sensitive algorithm. We develop such an algorithm and formally describe
it in detail. The key insight, obtained by carefully studying various
approaches to directed q-analysis and how they relate to each other, is that
inverting the order of computation leads to significant complexity gains.
Targeted precomputation and caching tactics further reduce the introduced
overhead, enough to achieve (under mild assumptions) a time complexity that is
linear in output size. The resulting algorithm for performing directed
q-analysis is shown to be time-optimal.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [75] [A Fully Spectral Neuro-Symbolic Reasoning Architecture with Graph Signal Processing as the Computational Backbone](https://arxiv.org/abs/2508.14923)
*Andrew Kiruluta*

Main category: cs.AI

TL;DR: 提出了一种基于图信号处理的神经符号推理架构，实验证明其在逻辑推理任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 动机是提出一种完全基于频谱的神经符号推理架构，以图信号处理为核心计算框架，整合符号逻辑和神经推理。

Method: 方法包括将逻辑实体和关系编码为图信号，通过可学习的频谱滤波器处理，控制多尺度信息传播，并映射到符号谓词进行基于规则的推理。

Result: 在多个基准推理数据集上的实验表明，该方法在逻辑一致性、可解释性和计算效率上优于现有神经符号模型。

Conclusion: 该论文的结论是，图信号处理（GSP）为稳健且可解释的推理系统提供了一个数学基础和计算高效的底层架构。

Abstract: We propose a fully spectral, neuro\-symbolic reasoning architecture that
leverages Graph Signal Processing (GSP) as the primary computational backbone
for integrating symbolic logic and neural inference. Unlike conventional
reasoning models that treat spectral graph methods as peripheral components,
our approach formulates the entire reasoning pipeline in the graph spectral
domain. Logical entities and relationships are encoded as graph signals,
processed via learnable spectral filters that control multi-scale information
propagation, and mapped into symbolic predicates for rule-based inference. We
present a complete mathematical framework for spectral reasoning, including
graph Fourier transforms, band-selective attention, and spectral rule
grounding. Experiments on benchmark reasoning datasets (ProofWriter,
EntailmentBank, bAbI, CLUTRR, and ARC-Challenge) demonstrate improvements in
logical consistency, interpretability, and computational efficiency over
state\-of\-the\-art neuro\-symbolic models. Our results suggest that GSP
provides a mathematically grounded and computationally efficient substrate for
robust and interpretable reasoning systems.

</details>


### [76] [Goals and the Structure of Experience](https://arxiv.org/abs/2508.15013)
*Nadav Amir,Stas Tiomkin,Angela Langdon*

Main category: cs.AI

TL;DR: 论文提出目标导向状态表示框架，描述性和规范性方面从交互中共同涌现，为 purposeful behaviors 提供统一解释。


<details>
  <summary>Details</summary>
Motivation: 探讨描述性和规范性方面是否可以从智能体的目标中相互依赖地共同涌现，而非传统强化学习中分离的状态表示和奖励函数。

Method: 通过引入目标导向状态（telic states）的概念，定义为目标等效经验分布的类别，并利用行为策略与期望经验特征之间的统计差异来解析目标导向学习。

Result: 提出了一个新颖的计算框架，支持目标导向状态表示的有效性，并为行为、现象学和神经维度的 purposeful behaviors 提供了统一解释。

Conclusion: 该论文提出了一个基于目标导向状态表示的计算框架，描述性和规范性方面从智能体与环境的交互序列中共同涌现，为跨多样基质的 purposeful behaviors 提供了统一的解释。

Abstract: Purposeful behavior is a hallmark of natural and artificial intelligence. Its
acquisition is often believed to rely on world models, comprising both
descriptive (what is) and prescriptive (what is desirable) aspects that
identify and evaluate state of affairs in the world, respectively. Canonical
computational accounts of purposeful behavior, such as reinforcement learning,
posit distinct components of a world model comprising a state representation
(descriptive aspect) and a reward function (prescriptive aspect). However, an
alternative possibility, which has not yet been computationally formulated, is
that these two aspects instead co-emerge interdependently from an agent's goal.
Here, we describe a computational framework of goal-directed state
representation in cognitive agents, in which the descriptive and prescriptive
aspects of a world model co-emerge from agent-environment interaction
sequences, or experiences. Drawing on Buddhist epistemology, we introduce a
construct of goal-directed, or telic, states, defined as classes of
goal-equivalent experience distributions. Telic states provide a parsimonious
account of goal-directed learning in terms of the statistical divergence
between behavioral policies and desirable experience features. We review
empirical and theoretical literature supporting this novel perspective and
discuss its potential to provide a unified account of behavioral,
phenomenological and neural dimensions of purposeful behaviors across diverse
substrates.

</details>


### [77] [Emergent Crowds Dynamics from Language-Driven Multi-Agent Interactions](https://arxiv.org/abs/2508.15047)
*Yibo Liu,Liam Shatzel,Brandon Haworth,Teseo Schneider*

Main category: cs.AI

TL;DR: 该论文提出了一种利用LLMs控制代理运动的方法，通过对话和导航生成更真实的群体行为模拟。


<details>
  <summary>Details</summary>
Motivation: 现有工作未充分考虑语言和对话对群体行为的影响，导致交互有限。

Method: 提出了一种利用大型语言模型（LLMs）控制代理运动的新方法，包括对话系统和语言驱动导航。

Result: 在复杂场景中验证了方法的有效性，观察到代理的自动分组和解组，以及信息传递机制。

Conclusion: 该框架通过结合语言模型和导航系统，生成了更真实的群体模拟，自然涌现出群体行为。

Abstract: Animating and simulating crowds using an agent-based approach is a
well-established area where every agent in the crowd is individually controlled
such that global human-like behaviour emerges. We observe that human navigation
and movement in crowds are often influenced by complex social and environmental
interactions, driven mainly by language and dialogue. However, most existing
work does not consider these dimensions and leads to animations where
agent-agent and agent-environment interactions are largely limited to steering
and fixed higher-level goal extrapolation.
  We propose a novel method that exploits large language models (LLMs) to
control agents' movement. Our method has two main components: a dialogue system
and language-driven navigation. We periodically query agent-centric LLMs
conditioned on character personalities, roles, desires, and relationships to
control the generation of inter-agent dialogue when necessitated by the spatial
and social relationships with neighbouring agents. We then use the conversation
and each agent's personality, emotional state, vision, and physical state to
control the navigation and steering of each agent. Our model thus enables
agents to make motion decisions based on both their perceptual inputs and the
ongoing dialogue.
  We validate our method in two complex scenarios that exemplify the interplay
between social interactions, steering, and crowding. In these scenarios, we
observe that grouping and ungrouping of agents automatically occur.
Additionally, our experiments show that our method serves as an
information-passing mechanism within the crowd. As a result, our framework
produces more realistic crowd simulations, with emergent group behaviours
arising naturally from any environmental setting.

</details>


### [78] [Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism](https://arxiv.org/abs/2508.15030)
*Ashmi Banerjee,Fitri Nur Aisyah,Adithi Satish,Wolfgang Wörndl,Yashar Deldjoo*

Main category: cs.AI

TL;DR: Collab-REC是一个多智能体框架，通过LLM和非LLM智能体的协作，提升旅游推荐的多样性和相关性，有效解决流行度偏差问题。


<details>
  <summary>Details</summary>
Motivation: 解决旅游推荐中的流行度偏差和多样性不足问题，应对过度旅游现象，并更好地满足用户约束。

Method: 提出Collab-REC多智能体框架，包含三个基于LLM的智能体（个性化、流行度、可持续性）和一个非LLM调解器，通过多轮协商合并和优化建议。

Result: 在欧洲城市查询实验中，Collab-REC相比单智能体基线提升了多样性和整体相关性，推荐了较少被访问的地点。

Conclusion: Collab-REC框架通过多智能体协作有效解决了旅游推荐中的流行度偏差问题，提升了多样性和整体相关性，展示了多利益相关方合作在LLM驱动推荐系统中的潜力。

Abstract: We propose Collab-REC, a multi-agent framework designed to counteract
popularity bias and enhance diversity in tourism recommendations. In our
setting, three LLM-based agents -- Personalization, Popularity, and
Sustainability generate city suggestions from complementary perspectives. A
non-LLM moderator then merges and refines these proposals via multi-round
negotiation, ensuring each agent's viewpoint is incorporated while penalizing
spurious or repeated responses. Experiments on European city queries show that
Collab-REC improves diversity and overall relevance compared to a single-agent
baseline, surfacing lesser-visited locales that often remain overlooked. This
balanced, context-aware approach addresses over-tourism and better aligns with
constraints provided by the user, highlighting the promise of multi-stakeholder
collaboration in LLM-driven recommender systems.

</details>


### [79] [Don't Think Twice! Over-Reasoning Impairs Confidence Calibration](https://arxiv.org/abs/2508.15050)
*Romain Lacombe,Kerrie Wu,Eddie Dilworth*

Main category: cs.AI

TL;DR: 研究挑战了"测试时扩展"范式，发现信息获取是提升信心校准的关键，而非推理深度或计算预算。


<details>
  <summary>Details</summary>
Motivation: 为避免大型语言模型作为问答工具时的过度自信，需进行稳健的校准。

Method: 使用ClimateX数据集并扩展至人类和行星健康领域，系统评估推理能力和预算对信心评估准确性的影响。

Result: 研究发现，增加推理预算会损害校准效果，导致系统性过度自信；而检索增强生成显著优于纯推理，准确率达到89.3%。

Conclusion: 信息获取而非推理深度或计算预算，是提升知识密集型任务信心校准的关键瓶颈。

Abstract: Large Language Models deployed as question answering tools require robust
calibration to avoid overconfidence. We systematically evaluate how reasoning
capabilities and budget affect confidence assessment accuracy, using the
ClimateX dataset (Lacombe et al., 2023) and expanding it to human and planetary
health. Our key finding challenges the "test-time scaling" paradigm: while
recent reasoning LLMs achieve 48.7% accuracy in assessing expert confidence,
increasing reasoning budgets consistently impairs rather than improves
calibration. Extended reasoning leads to systematic overconfidence that worsens
with longer thinking budgets, producing diminishing and negative returns beyond
modest computational investments. Conversely, search-augmented generation
dramatically outperforms pure reasoning, achieving 89.3% accuracy by retrieving
relevant evidence. Our results suggest that information access, rather than
reasoning depth or inference budget, may be the critical bottleneck for
improved confidence calibration of knowledge-intensive tasks.

</details>


### [80] [Demonstrating Onboard Inference for Earth Science Applications with Spectral Analysis Algorithms and Deep Learning](https://arxiv.org/abs/2508.15053)
*Itai Zilberstein,Alberto Candela,Steve Chien,David Rijlaarsdam,Tom Hendrix,Leonie Buckley,Aubrey Dunne*

Main category: cs.AI

TL;DR: JPL与Ubotica合作，在CS-6卫星上展示了边缘数据分析技术，利用深度学习和光谱分析算法，证明了其在轨应用的可行性。


<details>
  <summary>Details</summary>
Motivation: 在边缘（如卫星上）进行数据分析能够支持新的地球科学测量和响应，探索这一技术的应用潜力。

Method: 利用CS-6卫星上的可见光和近红外高光谱仪器及神经网络加速硬件，结合深度学习和光谱分析算法，实现了在轨数据分析和推理。

Result: 成功展示了CS-6上多种应用的深度学习和光谱分析算法的在轨数据分析和推理能力。

Conclusion: 通过与Ubotica Technologies合作，JPL在CogniSAT-6/HAMMER（CS-6）上展示了前沿的数据分析技术，证明了在卫星上实现边缘数据分析的可行性及其对地球科学测量的潜在价值。

Abstract: In partnership with Ubotica Technologies, the Jet Propulsion Laboratory is
demonstrating state-of-the-art data analysis onboard CogniSAT-6/HAMMER (CS-6).
CS-6 is a satellite with a visible and near infrared range hyperspectral
instrument and neural network acceleration hardware. Performing data analysis
at the edge (e.g. onboard) can enable new Earth science measurements and
responses. We will demonstrate data analysis and inference onboard CS-6 for
numerous applications using deep learning and spectral analysis algorithms.

</details>


### [81] [S3LoRA: Safe Spectral Sharpness-Guided Pruning in Adaptation of Agent Planner](https://arxiv.org/abs/2508.15068)
*Shuang Ao,Gopal Rumchurn*

Main category: cs.AI

TL;DR: S3LoRA通过分析LoRA更新的结构特性并修剪潜在不安全的层，提供了轻量级、无需数据且模型无关的安全适应框架。


<details>
  <summary>Details</summary>
Motivation: 现有的安全适应方法通常需要访问基础模型和指令调优模型检查点，这在实践中往往不可行，限制了其适用性。

Method: 提出了S3LoRA框架，包括MAS-SVD方法和SSI指标，用于检测并修剪潜在不安全的LoRA更新层。

Result: 实验表明，S3LoRA在保持或提升任务性能的同时，显著提高了安全性指标，并降低了推理成本。

Conclusion: S3LoRA 是一种实用且可扩展的解决方案，能够在资源受限和安全关键的实际环境中安全部署基于LLM的智能体。

Abstract: Adapting Large Language Models (LLMs) using parameter-efficient fine-tuning
(PEFT) techniques such as LoRA has enabled powerful capabilities in LLM-based
agents. However, these adaptations can unintentionally compromise safety
alignment, leading to unsafe or unstable behaviors, particularly in agent
planning tasks. Existing safety-aware adaptation methods often require access
to both base and instruction-tuned model checkpoints, which are frequently
unavailable in practice, limiting their applicability. We propose S3LoRA (Safe
Spectral Sharpness-Guided Pruning LoRA), a lightweight, data-free, and
model-independent framework that mitigates safety risks in LoRA-adapted models
by inspecting only the fine-tuned weight updates. We first introduce
Magnitude-Aware Spherically Normalized SVD (MAS-SVD), which robustly analyzes
the structural properties of LoRA updates while preserving global magnitude
information. We then design the Spectral Sharpness Index (SSI), a
sharpness-aware metric to detect layers with highly concentrated and
potentially unsafe updates. These layers are pruned post-hoc to reduce risk
without sacrificing task performance. Extensive experiments and ablation
studies across agent planning and language generation tasks show that S3LoRA
consistently improves safety metrics while maintaining or improving utility
metrics and significantly reducing inference cost. These results establish
S3LoRA as a practical and scalable solution for safely deploying LLM-based
agents in real-world, resource-constrained, and safety-critical environments.

</details>


### [82] [Argumentation for Explainable Workforce Optimisation (with Appendix)](https://arxiv.org/abs/2508.15118)
*Jennifer Leigh,Dimitrios Letsios,Alessandro Mella,Lucio Machetti,Francesca Toni*

Main category: cs.AI

TL;DR: 将劳动力管理视为抽象论证，开发工具生成解释，用户研究证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 劳动力管理在执行时面临变化的挑战，需要为所有利益相关者提供解释。传统方法难以满足这一需求。

Method: 将劳动力管理建模为抽象论证框架，开发工具以生成解释，并通过用户研究验证效果。

Result: 用户研究表明，该工具和解释方法在解决问题的速度和准确性上优于传统手动方案。

Conclusion: 通过将劳动力管理视为工业应用中的抽象论证，可以适应变化并获得可靠的解释。用户研究表明，我们的工具和解释比传统的手动解决方案更快、更准确地解决问题。

Abstract: Workforce management is a complex problem optimising the makespan and travel
distance required for a team of operators to complete a set of jobs, using a
set of instruments. A crucial challenge in workforce management is
accommodating changes at execution time so that explanations are provided to
all stakeholders involved. Here, we show that, by understanding workforce
management as abstract argumentation in an industrial application, we can
accommodate change and obtain faithful explanations. We show, with a user
study, that our tool and explanations lead to faster and more accurate problem
solving than conventional solutions by hand.

</details>


### [83] [Open-Universe Assistance Games](https://arxiv.org/abs/2508.15119)
*Rachel Ma,Jingyi Qu,Andreea Bobu,Dylan Hadfield-Menell*

Main category: cs.AI

TL;DR: GOOD方法通过在线提取自然语言目标并进行概率推断，在动态目标环境中提升了AI代理的表现。


<details>
  <summary>Details</summary>
Motivation: 为了解决嵌入式AI代理在多样化且未预定义的人类目标和偏好中推理和行动的需求，作者提出了开放宇宙辅助游戏（OU-AGs）框架。

Method: GOOD（GOals from Open-ended Dialogue）是一种数据高效的在线方法，通过提示大型语言模型（LLM）模拟不同复杂意图的用户，并利用其响应进行候选目标的概率推断。

Result: 在文本购物和AI2Thor家庭机器人模拟环境中，GOOD方法优于无显式目标跟踪的基线方法，并通过LLM和人工评估验证了其有效性。

Conclusion: GOOD方法在开放宇宙辅助游戏（OU-AGs）框架中，通过在线提取自然语言目标并进行概率推断，显著提升了代理在多样化和动态目标环境中的表现。该方法在文本购物和家庭机器人模拟环境中验证了其有效性。

Abstract: Embodied AI agents must infer and act in an interpretable way on diverse
human goals and preferences that are not predefined. To formalize this setting,
we introduce Open-Universe Assistance Games (OU-AGs), a framework where the
agent must reason over an unbounded and evolving space of possible goals. In
this context, we introduce GOOD (GOals from Open-ended Dialogue), a
data-efficient, online method that extracts goals in the form of natural
language during an interaction with a human, and infers a distribution over
natural language goals. GOOD prompts an LLM to simulate users with different
complex intents, using its responses to perform probabilistic inference over
candidate goals. This approach enables rich goal representations and
uncertainty estimation without requiring large offline datasets. We evaluate
GOOD in a text-based grocery shopping domain and in a text-operated simulated
household robotics environment (AI2Thor), using synthetic user profiles. Our
method outperforms a baseline without explicit goal tracking, as confirmed by
both LLM-based and human evaluations.

</details>


### [84] [aiXiv: A Next-Generation Open Access Ecosystem for Scientific Discovery Generated by AI Scientists](https://arxiv.org/abs/2508.15126)
*Pengsong Zhang,Xiang Hu,Guowei Huang,Yang Qi,Heng Zhang,Xiuxu Li,Jiaxing Song,Jiabin Luo,Yijiang Li,Shuo Yin,Chengxiao Dai,Eric Hanchen Jiang,Xiaoyan Zhou,Zhenfei Yin,Boqin Yuan,Jing Dong,Guinan Su,Guanren Qiao,Haiming Tang,Anghong Du,Lili Pan,Zhenzhong Lan,Xinyu Liu*

Main category: cs.AI

TL;DR: aiXiv是一个面向人类和AI科学家的开放平台，通过多智能体架构和API集成，解决了AI生成研究缺乏发布渠道的问题，并提升了研究质量。


<details>
  <summary>Details</summary>
Motivation: 当前AI生成的大量研究内容缺乏合适的发布渠道，传统期刊和会议依赖人工评审难以扩展，而现有预印本服务器缺乏严格质量控制。这阻碍了AI生成研究对科学进步的潜在贡献。

Method: aiXiv采用多智能体架构，支持人类和AI科学家共同参与研究提案和论文的提交、评审及迭代改进。平台还提供API和MCP接口，实现异构人类和AI科学家的无缝集成。

Result: 实验证明，aiXiv是一个可靠且稳健的平台，通过迭代修订和评审，显著提升了AI生成研究提案和论文的质量。

Conclusion: 本文提出了aiXiv，一个面向人类和AI科学家的下一代开放获取平台，旨在解决AI生成研究内容缺乏合适发布渠道的问题。通过多智能体架构，aiXiv实现了研究提案和论文的提交、评审及迭代改进，显著提升了AI生成研究的质量。

Abstract: Recent advances in large language models (LLMs) have enabled AI agents to
autonomously generate scientific proposals, conduct experiments, author papers,
and perform peer reviews. Yet this flood of AI-generated research content
collides with a fragmented and largely closed publication ecosystem.
Traditional journals and conferences rely on human peer review, making them
difficult to scale and often reluctant to accept AI-generated research content;
existing preprint servers (e.g. arXiv) lack rigorous quality-control
mechanisms. Consequently, a significant amount of high-quality AI-generated
research lacks appropriate venues for dissemination, hindering its potential to
advance scientific progress. To address these challenges, we introduce aiXiv, a
next-generation open-access platform for human and AI scientists. Its
multi-agent architecture allows research proposals and papers to be submitted,
reviewed, and iteratively refined by both human and AI scientists. It also
provides API and MCP interfaces that enable seamless integration of
heterogeneous human and AI scientists, creating a scalable and extensible
ecosystem for autonomous scientific discovery. Through extensive experiments,
we demonstrate that aiXiv is a reliable and robust platform that significantly
enhances the quality of AI-generated research proposals and papers after
iterative revising and reviewing on aiXiv. Our work lays the groundwork for a
next-generation open-access ecosystem for AI scientists, accelerating the
publication and dissemination of high-quality AI-generated research content.
Code is available at https://github.com/aixiv-org. Website is available at
https://forms.gle/DxQgCtXFsJ4paMtn8.

</details>


### [85] [Mobile-Agent-v3: Foundamental Agents for GUI Automation](https://arxiv.org/abs/2508.15144)
*Jiabo Ye,Xi Zhang,Haiyang Xu,Haowei Liu,Junyang Wang,Zhaoqing Zhu,Ziwei Zheng,Feiyu Gao,Junjie Cao,Zhengxi Lu,Jitong Liao,Qi Zheng,Fei Huang,Jingren Zhou,Ming Yan*

Main category: cs.AI

TL;DR: GUI-Owl是一种高性能开源GUI代理模型，通过三大创新技术实现卓越表现，Mobile-Agent-v3在此基础上进一步优化，性能更优。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个能够覆盖多种GUI环境（如Android、Ubuntu、macOS、Windows）且性能卓越的开源GUI代理模型，以支持端到端决策和多代理系统。

Method: GUI-Owl通过大规模环境基础设施、多样化的基础代理能力和可扩展的环境强化学习三大创新，实现高效的GUI交互。Mobile-Agent-v3在此基础上进一步优化，提升性能。

Result: GUI-Owl-7B在AndroidWorld和OSWorld上的得分分别为66.4和29.4；Mobile-Agent-v3进一步将性能提升至73.3和37.7，创下开源GUI代理框架的新纪录。

Conclusion: GUI-Owl和Mobile-Agent-v3作为开源GUI代理框架，在性能和功能上均达到行业领先水平，特别是在AndroidWorld和OSWorld基准测试中表现优异。

Abstract: This paper introduces GUI-Owl, a foundational GUI agent model that achieves
state-of-the-art performance among open-source end-to-end models on ten GUI
benchmarks across desktop and mobile environments, covering grounding, question
answering, planning, decision-making, and procedural knowledge. GUI-Owl-7B
achieves 66.4 on AndroidWorld and 29.4 on OSWorld. Building on this, we propose
Mobile-Agent-v3, a general-purpose GUI agent framework that further improves
performance to 73.3 on AndroidWorld and 37.7 on OSWorld, setting a new
state-of-the-art for open-source GUI agent frameworks. GUI-Owl incorporates
three key innovations: (1) Large-scale Environment Infrastructure: a
cloud-based virtual environment spanning Android, Ubuntu, macOS, and Windows,
enabling our Self-Evolving GUI Trajectory Production framework. This generates
high-quality interaction data via automated query generation and correctness
validation, leveraging GUI-Owl to refine trajectories iteratively, forming a
self-improving loop. It supports diverse data pipelines and reduces manual
annotation. (2) Diverse Foundational Agent Capabilities: by integrating UI
grounding, planning, action semantics, and reasoning patterns, GUI-Owl supports
end-to-end decision-making and can act as a modular component in multi-agent
systems. (3) Scalable Environment RL: we develop a scalable reinforcement
learning framework with fully asynchronous training for real-world alignment.
We also introduce Trajectory-aware Relative Policy Optimization (TRPO) for
online RL, achieving 34.9 on OSWorld. GUI-Owl and Mobile-Agent-v3 are
open-sourced at https://github.com/X-PLUG/MobileAgent.

</details>


### [86] [PuzzleClone: An SMT-Powered Framework for Synthesizing Verifiable Data](https://arxiv.org/abs/2508.15180)
*Kai Xiong,Yanwei Huang,Rongjunchen Zhang,Kun Chen,Haipang Wu*

Main category: cs.AI

TL;DR: PuzzleClone通过SMT技术生成多样化、可验证的逻辑谜题数据集，显著提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM生成数据集在可靠性、多样性和可扩展性上的不足，以增强语言模型的推理能力。

Method: 采用SMT技术，通过编码种子谜题、生成可扩展变体及验证机制，构建了包含83K多样化谜题的基准数据集。

Result: 实验结果显示，PuzzleClone训练使模型在自身测试集和多个逻辑数学基准上的表现提升显著（如AMC2023从52.5提升至65.0）。

Conclusion: 训练PuzzleClone数据集显著提升了模型在逻辑和数学基准测试上的表现，验证了该框架的有效性。

Abstract: High-quality mathematical and logical datasets with verifiable answers are
essential for strengthening the reasoning capabilities of large language models
(LLMs). While recent data augmentation techniques have facilitated the creation
of large-scale benchmarks, existing LLM-generated datasets often suffer from
limited reliability, diversity, and scalability. To address these challenges,
we introduce PuzzleClone, a formal framework for synthesizing verifiable data
at scale using Satisfiability Modulo Theories (SMT). Our approach features
three key innovations: (1) encoding seed puzzles into structured logical
specifications, (2) generating scalable variants through systematic variable
and constraint randomization, and (3) ensuring validity via a reproduction
mechanism. Applying PuzzleClone, we construct a curated benchmark comprising
over 83K diverse and programmatically validated puzzles. The generated puzzles
span a wide spectrum of difficulty and formats, posing significant challenges
to current state-of-the-art models. We conduct post training (SFT and RL) on
PuzzleClone datasets. Experimental results show that training on PuzzleClone
yields substantial improvements not only on PuzzleClone testset but also on
logic and mathematical benchmarks. Post training raises PuzzleClone average
from 14.4 to 56.2 and delivers consistent improvements across 7 logic and
mathematical benchmarks up to 12.5 absolute percentage points (AMC2023 from
52.5 to 65.0). Our code and data are available at
https://github.com/puzzleclone.

</details>


### [87] [LLM4Sweat: A Trustworthy Large Language Model for Hyperhidrosis Support](https://arxiv.org/abs/2508.15192)
*Wenjie Lin,Jin Wei-Kocsis*

Main category: cs.AI

TL;DR: LLM4Sweat是一个针对多汗症的开源LLM框架，通过数据增强、微调和专家评估三阶段流程，提供可信赖且富有同理心的支持，并适用于其他罕见疾病。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在医疗保健领域表现出潜力，但在罕见医疗条件（如多汗症）中的应用仍受限于稀缺且不可靠的微调数据集。

Method: 系统采用三阶段流程：数据增强阶段生成医学上合理的合成数据，微调阶段对开源基础模型进行微调，推理和专家评估阶段由专家评估响应。

Result: 实验表明，LLM4Sweat优于基线模型，并提供了首个针对多汗症的开源LLM框架。

Conclusion: LLM4Sweat提供了一个开源且领域特定的LLM框架，为多汗症提供了可信赖且富有同理心的支持，并为其他罕见疾病提供了可推广的解决方案。

Abstract: While large language models (LLMs) have shown promise in healthcare, their
application for rare medical conditions is still hindered by scarce and
unreliable datasets for fine-tuning. Hyperhidrosis, a disorder causing
excessive sweating beyond physiological needs, is one such rare disorder,
affecting 2-3% of the population and significantly impacting both physical
comfort and psychosocial well-being. To date, no work has tailored LLMs to
advance the diagnosis or care of hyperhidrosis. To address this gap, we present
LLM4Sweat, an open-source and domain-specific LLM framework for trustworthy and
empathetic hyperhidrosis support. The system follows a three-stage pipeline. In
the data augmentation stage, a frontier LLM generates medically plausible
synthetic vignettes from curated open-source data to create a diverse and
balanced question-answer dataset. In the fine-tuning stage, an open-source
foundation model is fine-tuned on the dataset to provide diagnosis,
personalized treatment recommendations, and empathetic psychological support.
In the inference and expert evaluation stage, clinical and psychological
specialists assess accuracy, appropriateness, and empathy, with validated
responses iteratively enriching the dataset. Experiments show that LLM4Sweat
outperforms baselines and delivers the first open-source LLM framework for
hyperhidrosis, offering a generalizable approach for other rare diseases with
similar data and trustworthiness challenges.

</details>


### [88] [R-ConstraintBench: Evaluating LLMs on NP-Complete Scheduling](https://arxiv.org/abs/2508.15204)
*Raj Jain,Marc Wetter*

Main category: cs.AI

TL;DR: 论文提出了R-ConstraintBench框架，评估LLMs在高约束条件下的表现，发现约束交互是主要瓶颈，且模型泛化能力有限。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是评估大型语言模型（LLMs）在高约束条件下的推理可靠性，因为现有研究对此特性描述不足。

Method: 论文提出了R-ConstraintBench，一个可扩展的框架，用于评估模型在资源受限项目调度问题（RCPSP）上的表现，通过线性增加约束来增加难度。框架逐步增加非冗余优先约束、停机时间、时间窗口和分离约束。

Result: 实证结果表明，强模型在仅有优先约束的DAG上表现优秀，但在复杂约束交互时性能急剧下降。此外，干净合成场景的表现不能保证在领域接地场景中的转移。

Conclusion: 论文的结论是，强模型在仅有优先约束的DAG上表现接近天花板，但在停机时间、时间窗口和分离约束相互作用时，可行性性能崩溃，表明约束交互而非图深度是主要瓶颈。干净合成场景的表现也不能保证在领域接地场景中的转移，突显了有限的泛化能力。

Abstract: Effective scheduling under tight resource, timing, and operational
constraints underpins large-scale planning across sectors such as capital
projects, manufacturing, logistics, and IT fleet transitions. However, the
reliability of large language models (LLMs) when reasoning under
high-constraint regimes is insufficiently characterized. To address this gap,
we present R-ConstraintBench, a scalable framework that evaluates models on
Resource-Constrained Project Scheduling Problems (RCPSP), an NP-Complete
feasibility class, while difficulty increases via linear growth in constraints.
R-ConstraintBench incrementally increases non-redundant precedence constraints
in Directed Acyclic Graphs (DAGs) and then introduces downtime, temporal
windows, and disjunctive constraints. As an illustrative example, we
instantiate the benchmark in a data center migration setting and evaluate
multiple LLMs using feasibility and error analysis, identifying degradation
thresholds and constraint types most associated with failure. Empirically,
strong models are near-ceiling on precedence-only DAGs, but feasibility
performance collapses when downtime, temporal windows, and disjunctive
constraints interact, implicating constraint interaction, not graph depth, as
the principal bottleneck. Performance on clean synthetic ramps also does not
guarantee transfer to domain-grounded scenarios, underscoring limited
generalization.

</details>


### [89] [See it. Say it. Sorted: Agentic System for Compositional Diagram Generation](https://arxiv.org/abs/2508.15222)
*Hantao Zhang,Jingyang Liu,Ed Li*

Main category: cs.AI

TL;DR: 提出了一种结合VLM和LLMs的无训练代理系统，用于从手绘草图生成精确可编辑矢量图，效果优于现有前沿模型。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在空间精度、对齐和符号结构方面存在不足，无法满足流程图等精确图表的需求。

Method: 提出了一个名为'See it. Say it. Sorted.'的无训练代理系统，通过迭代循环结合VLM和LLMs生成SVG程序，并支持人工干预。

Result: 在10个源自发表论文流程图的草图上，该方法在布局和结构重建上优于GPT-5和Gemini-2.5-Pro，且能准确生成复杂元素（如多箭头）而不引入多余文本。

Conclusion: 该方法通过结合视觉语言模型（VLM）和大型语言模型（LLMs），成功实现了从手绘草图到精确可编辑矢量图（SVG）的生成，且在布局和结构重建上优于现有前沿模型。

Abstract: We study sketch-to-diagram generation: converting rough hand sketches into
precise, compositional diagrams. Diffusion models excel at photorealism but
struggle with the spatial precision, alignment, and symbolic structure required
for flowcharts. We introduce See it. Say it. Sorted., a training-free agentic
system that couples a Vision-Language Model (VLM) with Large Language Models
(LLMs) to produce editable Scalable Vector Graphics (SVG) programs. The system
runs an iterative loop in which a Critic VLM proposes a small set of
qualitative, relational edits; multiple candidate LLMs synthesize SVG updates
with diverse strategies (conservative->aggressive, alternative, focused); and a
Judge VLM selects the best candidate, ensuring stable improvement. This design
prioritizes qualitative reasoning over brittle numerical estimates, preserves
global constraints (e.g., alignment, connectivity), and naturally supports
human-in-the-loop corrections. On 10 sketches derived from flowcharts in
published papers, our method more faithfully reconstructs layout and structure
than two frontier closed-source image generation LLMs (GPT-5 and
Gemini-2.5-Pro), accurately composing primitives (e.g., multi-headed arrows)
without inserting unwanted text. Because outputs are programmatic SVGs, the
approach is readily extensible to presentation tools (e.g., PowerPoint) via
APIs and can be specialized with improved prompts and task-specific tools. The
codebase is open-sourced at
https://github.com/hantaoZhangrichard/see_it_say_it_sorted.git.

</details>


### [90] [Computational Intelligence based Land-use Allocation Approaches for Mixed Use Areas](https://arxiv.org/abs/2508.15240)
*Sabab Aosaf,Muhammad Ali Nayeem,Afsana Haque,M Sohel Rahmana*

Main category: cs.AI

TL;DR: 本文提出多种计算智能方法优化混合用途区域的土地用途分配，显著提升兼容性和经济目标，为城市规划提供实用工具。


<details>
  <summary>Details</summary>
Motivation: 解决城市土地用途分配这一复杂多目标优化问题，以支持可持续城市发展政策，特别是在混合用途区域中平衡土地用途兼容性和经济目标。

Method: 开发了多种优化算法，包括结合差分进化与多目标遗传算法的自定义变体。关键贡献包括：(1) CR+DES算法利用缩放差异向量增强探索能力，(2) 系统性约束松弛策略在保持可行性的同时提高解的质量，(3) 使用Kruskal-Wallis检验和紧凑字母显示进行统计验证。

Result: 在真实案例研究中，CR+DES算法在土地用途兼容性上比现有方法提高了3.16%，而MSBX+MO在价格优化上提高了3.3%。统计分析证实，结合差异向量的算法在多个指标上显著优于传统方法。约束松弛技术能够在保持实际约束的同时探索更广泛的解空间。

Conclusion: 本研究为城市规划和政策制定者提供了基于证据的计算工具，用于在土地用途分配中平衡相互竞争的目标，支持快速城市化地区更有效的城市发展政策。

Abstract: Urban land-use allocation represents a complex multi-objective optimization
problem critical for sustainable urban development policy. This paper presents
novel computational intelligence approaches for optimizing land-use allocation
in mixed-use areas, addressing inherent trade-offs between land-use
compatibility and economic objectives. We develop multiple optimization
algorithms, including custom variants integrating differential evolution with
multi-objective genetic algorithms. Key contributions include: (1) CR+DES
algorithm leveraging scaled difference vectors for enhanced exploration, (2)
systematic constraint relaxation strategy improving solution quality while
maintaining feasibility, and (3) statistical validation using Kruskal-Wallis
tests with compact letter displays. Applied to a real-world case study with
1,290 plots, CR+DES achieves 3.16\% improvement in land-use compatibility
compared to state-of-the-art methods, while MSBX+MO excels in price
optimization with 3.3\% improvement. Statistical analysis confirms algorithms
incorporating difference vectors significantly outperform traditional
approaches across multiple metrics. The constraint relaxation technique enables
broader solution space exploration while maintaining practical constraints.
These findings provide urban planners and policymakers with evidence-based
computational tools for balancing competing objectives in land-use allocation,
supporting more effective urban development policies in rapidly urbanizing
regions.

</details>


### [91] [Multiple Memory Systems for Enhancing the Long-term Memory of Agent](https://arxiv.org/abs/2508.15294)
*Gaoke Zhang,Bo Wang,Yunlong Ma,Dongming Zhao,Zifei Yu*

Main category: cs.AI

TL;DR: MMS通过多记忆片段和记忆单元设计，有效利用历史数据，提升召回和响应质量，实验证明其优越性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如MemoryBank和A-MEM）存储的记忆内容质量较差，影响召回性能和响应质量。为构建高质量的长期记忆内容，设计了基于认知心理学理论的多记忆系统。

Method: 受认知心理学理论启发，设计了多记忆系统（MMS），将短期记忆处理为多个长期记忆片段，并构建检索记忆单元和上下文记忆单元。在检索阶段，根据用户查询匹配最相关的检索记忆单元，获取对应的上下文记忆单元作为响应阶段的上下文。

Result: 在LoCoMo数据集上的实验表明，MMS优于其他三种方法。消融研究验证了记忆单元的合理性，分析了记忆片段数量和存储开销的鲁棒性，证明了其实际价值。

Conclusion: 多记忆系统（MMS）通过处理短期记忆为多个长期记忆片段，并构建检索记忆单元和上下文记忆单元，有效提升了历史数据的利用效率。实验证明其在召回性能和响应质量上的优越性，同时具备良好的实用性和鲁棒性。

Abstract: An agent powered by large language models have achieved impressive results,
but effectively handling the vast amounts of historical data generated during
interactions remains a challenge. The current approach is to design a memory
module for the agent to process these data. However, existing methods, such as
MemoryBank and A-MEM, have poor quality of stored memory content, which affects
recall performance and response quality. In order to better construct
high-quality long-term memory content, we have designed a multiple memory
system (MMS) inspired by cognitive psychology theory. The system processes
short-term memory to multiple long-term memory fragments, and constructs
retrieval memory units and contextual memory units based on these fragments,
with a one-to-one correspondence between the two. During the retrieval phase,
MMS will match the most relevant retrieval memory units based on the user's
query. Then, the corresponding contextual memory units is obtained as the
context for the response stage to enhance knowledge, thereby effectively
utilizing historical data. Experiments on LoCoMo dataset compared our method
with three others, proving its effectiveness. Ablation studies confirmed the
rationality of our memory units. We also analyzed the robustness regarding the
number of selected memory segments and the storage overhead, demonstrating its
practical value.

</details>


### [92] [Coarse-to-Fine Grounded Memory for LLM Agent Planning](https://arxiv.org/abs/2508.15305)
*Wei Yang,Jinwei Xiao,Hongming Zhang,Qingyang Zhang,Yanna Wang,Bo Xu*

Main category: cs.AI

TL;DR: 论文提出了一种多粒度记忆框架，通过粗粒度和细粒度记忆增强LLM的规划能力，解决了单粒度记忆的局限性，提高了灵活性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单粒度记忆，受限于收集经验的质量，影响了知识的多样性和规划的灵活性。为了克服这一限制，作者提出了多粒度记忆机制。

Method: 提出了一个新颖的框架，将环境信息分为粗粒度和细粒度记忆，分别用于指导经验收集和行动计划。在推理阶段，通过检索任务相关经验和提示来支持规划，并在面对异常时进行自我反思和计划修正。

Result: 实验结果表明，提出的框架能够有效提升LLM在复杂规划任务中的表现，特别是在面对环境异常时展现出更高的灵活性和适应性。

Conclusion: 论文提出了Coarse-to-Fine Grounded Memory框架，通过多粒度记忆机制增强LLM的规划能力，有效解决了现有单粒度记忆的局限性，提高了规划的灵活性和适应性。

Abstract: Recent advancements in Large Language Models (LLMs) have driven growing
interest in LLM-based agents for complex planning tasks. To avoid costly agent
training, many studies adopted memory mechanism that enhances LLM with offline
experiences or online trajectory analysis. However, existing works focus on
single-granularity memory derived from dynamic environmental interactions,
which are inherently constrained by the quality of the collected experiences.
This limitation, in turn, constrain the diversity of knowledge and the
flexibility of planning. We propose Coarse-to-Fine Grounded Memory (\Ours{}), a
novel framework that grounds coarse-to-fine memories with LLM, thereby fully
leverage them for flexible adaptation to diverse scenarios. \Ours{} grounds
environmental information into coarse-grained focus points to guide experience
collection in training tasks, followed by grounding of actionable
hybrid-grained tips from each experience. At inference, \Ours{} retrieves
task-relevant experiences and tips to support planning. When facing
environmental anomalies, the LLM grounds the current situation into
fine-grained key information, enabling flexible self-QA reflection and plan
correction.

</details>


### [93] [Search-Based Credit Assignment for Offline Preference-Based Reinforcement Learning](https://arxiv.org/abs/2508.15327)
*Xiancheng Gao,Yufeng Shi,Wengang Zhou,Houqiang Li*

Main category: cs.AI

TL;DR: SPW方案通过结合专家演示和偏好反馈，优化了信用分配，提升了离线强化学习在机器人操作任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习通常依赖于设计良好的奖励函数，但这类函数难以设计且成本高昂。人类反馈（如专家演示和偏好）各有局限性，因此需要一种方法来统一这两种反馈源。

Method: 提出了基于搜索的偏好加权（SPW）方案，通过搜索专家演示中最相似的状态-动作对来为偏好标记的轨迹中的每个转移分配逐步重要性权重。

Result: SPW在机器人操作任务中表现优于之前利用两种反馈类型的方法。

Conclusion: SPW方案通过结合专家演示和偏好反馈，解决了传统方法在信用分配上的困难，从而在机器人操作任务中实现了更优的性能。

Abstract: Offline reinforcement learning refers to the process of learning policies
from fixed datasets, without requiring additional environment interaction.
However, it often relies on well-defined reward functions, which are difficult
and expensive to design. Human feedback is an appealing alternative, but its
two common forms, expert demonstrations and preferences, have complementary
limitations. Demonstrations provide stepwise supervision, but they are costly
to collect and often reflect limited expert behavior modes. In contrast,
preferences are easier to collect, but it is unclear which parts of a behavior
contribute most to a trajectory segment, leaving credit assignment unresolved.
In this paper, we introduce a Search-Based Preference Weighting (SPW) scheme to
unify these two feedback sources. For each transition in a preference labeled
trajectory, SPW searches for the most similar state-action pairs from expert
demonstrations and directly derives stepwise importance weights based on their
similarity scores. These weights are then used to guide standard preference
learning, enabling more accurate credit assignment that traditional approaches
struggle to achieve. We demonstrate that SPW enables effective joint learning
from preferences and demonstrations, outperforming prior methods that leverage
both feedback types on challenging robot manipulation tasks.

</details>


### [94] [RETAIL: Towards Real-world Travel Planning for Large Language Models](https://arxiv.org/abs/2508.15335)
*Bin Deng,Yizhe Feng,Zeming Liu,Qing Wei,Xiangrong Zhu,Shuai Chen,Yuanfang Guo,Yunhong Wang*

Main category: cs.AI

TL;DR: 论文提出TGMA框架和RETAIL数据集，解决现有旅行规划系统与现实场景不对齐的问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在旅行规划中与现实场景存在不对齐问题，包括用户需求隐含性、忽视环境因素和用户偏好，以及生成的计划缺乏细节。

Method: 构建了一个新数据集RETAIL，并提出了一种主题引导的多智能体框架（TGMA）。

Result: TGMA在实验中表现出显著改进，性能提升至2.72%，而现有最强模型仅达到1.0%的通过率。

Conclusion: TGMA框架显著提升了现实世界旅行规划的性能，为未来研究提供了有希望的方向。

Abstract: Although large language models have enhanced automated travel planning
abilities, current systems remain misaligned with real-world scenarios. First,
they assume users provide explicit queries, while in reality requirements are
often implicit. Second, existing solutions ignore diverse environmental factors
and user preferences, limiting the feasibility of plans. Third, systems can
only generate plans with basic POI arrangements, failing to provide all-in-one
plans with rich details. To mitigate these challenges, we construct a novel
dataset \textbf{RETAIL}, which supports decision-making for implicit queries
while covering explicit queries, both with and without revision needs. It also
enables environmental awareness to ensure plan feasibility under real-world
scenarios, while incorporating detailed POI information for all-in-one travel
plans. Furthermore, we propose a topic-guided multi-agent framework, termed
TGMA. Our experiments reveal that even the strongest existing model achieves
merely a 1.0% pass rate, indicating real-world travel planning remains
extremely challenging. In contrast, TGMA demonstrates substantially improved
performance 2.72%, offering promising directions for real-world travel
planning.

</details>


### [95] [DiagECG: An LLM-Driven Framework for Diagnostic Reasoning via Discretized ECG Tokenization](https://arxiv.org/abs/2508.15338)
*Jinning Yang,Wen Shi*

Main category: cs.AI

TL;DR: DiagECG通过符号化ECG表征与语言模型结合，提升了心血管诊断的泛化能力和推理支持。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法在心血管诊断中泛化能力有限，且缺乏开放式推理支持。DiagECG旨在通过整合时间序列和语言建模来提升临床文本生成能力。

Method: 通过离散化连续ECG嵌入为符号标记，并扩展LLM词汇表，使模型能统一处理ECG和自然语言输入。预训练采用自回归ECG预测任务，后通过指令微调优化ECG问答和诊断报告生成。

Result: DiagECG在多项任务中表现优异，并在分布外设置中保持泛化能力。

Conclusion: DiagECG展示了将符号化ECG表征集成到大型语言模型中的潜力，为医学推理提供了新途径。

Abstract: Electrocardiography plays a central role in cardiovascular diagnostics, yet
existing automated approaches often struggle to generalize across clinical
tasks and offer limited support for open-ended reasoning. We present DiagECG, a
novel framework that integrates time-series and language modeling by enabling
large language models to process 12-lead ECG signals for clinical text
generation tasks. Our approach discretizes continuous ECG embeddings into
symbolic tokens using a lead-independent encoder and quantization module. These
tokens are then used to extend the vocabulary of LLM, allowing the model to
handle both ECG and natural language inputs in a unified manner. To bridge the
modality gap, we pretrain the model on an autoregressive ECG forecasting task,
enabling the LLM to model temporal dynamics using its native language modeling
capabilities. Finally, we perform instruction tuning on both ECG question
answering and diagnostic report generation. Without modifying the core model,
DiagECG achieves strong performance across tasks while maintaining
generalization to out-of-distribution settings. Extensive experiments
demonstrate the effectiveness of each component and highlight the potential of
integrating symbolic ECG representations into LLMs for medical reasoning.

</details>


### [96] [Planning with Minimal Disruption](https://arxiv.org/abs/2508.15358)
*Alberto Pozanco,Marianela Morales,Daniel Borrajo,Manuela Veloso*

Main category: cs.AI

TL;DR: 论文提出计划干扰概念，通过基于规划的编译方法联合优化行动成本和干扰，实验证明可有效生成平衡两者的计划。


<details>
  <summary>Details</summary>
Motivation: 在许多规划应用中，我们可能希望找到最小化初始状态修改以实现目标的计划。

Method: 定义了多种基于规划的编译方法，旨在联合优化行动成本总和和计划干扰。

Result: 在不同基准测试中的实验结果表明，重新制定的任务可以有效地生成平衡两个目标的计划。

Conclusion: 该论文正式引入了计划干扰的概念，并通过实验证明，重新制定的任务可以在实践中有效解决，生成平衡两个目标的计划。

Abstract: In many planning applications, we might be interested in finding plans that
minimally modify the initial state to achieve the goals. We refer to this
concept as plan disruption. In this paper, we formally introduce it, and define
various planning-based compilations that aim to jointly optimize both the sum
of action costs and plan disruption. Experimental results in different
benchmarks show that the reformulated task can be effectively solved in
practice to generate plans that balance both objectives.

</details>


### [97] [GraSP: A Unified Graph-Based Framework for Scalable Generation, Quality Tagging, and Management of Synthetic Data for SFT and DPO](https://arxiv.org/abs/2508.15432)
*Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda*

Main category: cs.AI

TL;DR: 提出了一种可扩展、可配置的合成数据生成框架，通过双阶段质量标记机制为LLM训练提供高质量对话数据。


<details>
  <summary>Details</summary>
Motivation: 高质量数据集对LLM的监督微调（SFT）和对齐任务（如DPO）至关重要，但现有数据生成方法在可扩展性和保真度上存在不足。

Method: 采用模块化和基于配置的流水线，结合启发式规则和基于LLM的评估，实现双阶段质量标记机制，自动筛选和评分OASST格式的对话数据。

Result: 生成了适用于SFT和DPO用例的高质量对话数据集，支持灵活的训练工作流集成。

Conclusion: 该框架通过模块化、可配置的流水线和双阶段质量标记机制，为LLM训练提供了高质量、可扩展的合成数据生成方案，显著降低了数据准备的开销。

Abstract: The advancement of large language models (LLMs) is critically dependent on
the availability of high-quality datasets for Supervised Fine-Tuning (SFT),
alignment tasks like Direct Preference Optimization (DPO), etc. In this work,
we present a comprehensive synthetic data generation framework that facilitates
scalable, configurable, and high-fidelity generation of synthetic data tailored
for these training paradigms. Our approach employs a modular and
configuration-based pipeline capable of modeling complex dialogue flows with
minimal manual intervention. This framework uses a dual-stage quality tagging
mechanism, combining heuristic rules and LLM-based evaluations, to
automatically filter and score data extracted from OASST-formatted
conversations, ensuring the curation of high-quality dialogue samples. The
resulting datasets are structured under a flexible schema supporting both SFT
and DPO use cases, enabling seamless integration into diverse training
workflows. Together, these innovations offer a robust solution for generating
and managing synthetic conversational data at scale, significantly reducing the
overhead of data preparation in LLM training pipelines.

</details>


### [98] [From Bits to Boardrooms: A Cutting-Edge Multi-Agent LLM Framework for Business Excellence](https://arxiv.org/abs/2508.15447)
*Zihao Wang,Junming Zhang*

Main category: cs.AI

TL;DR: BusiAgent是一个基于LLM的多智能体框架，通过整合CTMDP、熵度量和Stackelberg博弈等创新技术，显著提升了企业决策支持的效果，实证表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前方法在复杂商业环境中难以协调细致的运营分析与宏观战略目标，导致工作流程分散且跨组织协作效率低下。BusiAgent旨在解决这一问题，提升企业决策支持的效果。

Method: BusiAgent整合了三大核心创新：扩展的连续时间马尔可夫决策过程（CTMDP）用于动态代理建模、广义熵度量优化协作效率、以及多级Stackelberg博弈处理分层决策过程。此外，还采用了上下文Thompson采样进行提示优化，并辅以全面的质量保证系统以减少错误。

Result: 广泛的实证评估验证了BusiAgent的有效性，其在解决方案质量和用户满意度方面均显著优于现有方法，能够生成连贯且以客户为中心的解决方案。

Conclusion: 通过融合前沿AI技术与深度商业洞察，BusiAgent在AI驱动的企业决策中迈出了重要一步，显著提升了组织在复杂商业环境中的应对能力。

Abstract: Large Language Models (LLMs) have shown promising potential in business
applications, particularly in enterprise decision support and strategic
planning, yet current approaches often struggle to reconcile intricate
operational analyses with overarching strategic goals across diverse market
environments, leading to fragmented workflows and reduced collaboration across
organizational levels. This paper introduces BusiAgent, a novel multi-agent
framework leveraging LLMs for advanced decision-making in complex corporate
environments. BusiAgent integrates three core innovations: an extended
Continuous Time Markov Decision Process (CTMDP) for dynamic agent modeling, a
generalized entropy measure to optimize collaborative efficiency, and a
multi-level Stackelberg game to handle hierarchical decision processes.
Additionally, contextual Thompson sampling is employed for prompt optimization,
supported by a comprehensive quality assurance system to mitigate errors.
Extensive empirical evaluations across diverse business scenarios validate
BusiAgent's efficacy, demonstrating its capacity to generate coherent,
client-focused solutions that smoothly integrate granular insights with
high-level strategy, significantly outperforming established approaches in both
solution quality and user satisfaction. By fusing cutting-edge AI technologies
with deep business insights, BusiAgent marks a substantial step forward in
AI-driven enterprise decision-making, empowering organizations to navigate
complex business landscapes more effectively.

</details>


### [99] [Think in Blocks: Adaptive Reasoning from Direct Response to Deep Reasoning](https://arxiv.org/abs/2508.15507)
*Yekun Zhu,Guang Chen,Chengjun Mao*

Main category: cs.AI

TL;DR: Think in Blocks框架通过动态调整推理深度，优化LLMs在复杂任务中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂逻辑推理任务中表现出色，但过长的推理链会导致过度思考，造成计算浪费和响应延迟。

Method: 提出了一个三阶段训练管道：监督微调、奖励引导的直接偏好优化和强化学习，以训练模型根据问题难度自适应调整推理深度。

Result: Think in Blocks框架通过显式块计数动态控制推理深度，实现了推理链长度的灵活调整。

Conclusion: Think in Blocks框架通过动态调整推理深度，有效解决了LLMs在复杂逻辑推理任务中因过长推理链导致的过度思考问题，提高了计算效率和响应速度。

Abstract: Large Language Models (LLMs) with chains-of-thought have demonstrated strong
performance on an increasing range of tasks, particularly those involving
complex logical reasoning. However, excessively long chains can lead to
overthinking, causing computational waste and slower responses. This raises a
question: can LLMs dynamically adjust the length of their reasoning processes
based on task complexity? To address this, we propose the Think in Blocks
framework, which enables adaptive reasoning-from zero to deep reasoning-by
partitioning the reasoning process into a tunable number of blocks. Our main
contributions are: (1) Establishing an explicit block-structured paradigm in
which the model first predicts an integer reasoning budget-the number of
blocks-and then partitions its reasoning accordingly; (2) Training an adaptive
model through a three-stage pipeline-Supervised Fine-Tuning, reward-guided
Direct Preference Optimization, and Reinforcement Learning-that adjusts its
reasoning depth to problem difficulty; (3) Exploiting the explicit block count
to dynamically control reasoning depth at inference time, allowing flexible
adjustment of chain-of-thought length during deployment.

</details>


### [100] [Super-additive Cooperation in Language Model Agents](https://arxiv.org/abs/2508.15510)
*Filippo Tonini,Lukas Galke*

Main category: cs.AI

TL;DR: 研究通过虚拟锦标赛和囚徒困境游戏，发现群体间竞争和团队动态能显著提升AI智能体的合作行为，为多智能体系统设计提供了重要见解。


<details>
  <summary>Details</summary>
Motivation: 受超加性合作理论的启发，研究旨在探讨重复互动和群体间竞争是否是导致人类合作倾向的原因，并研究AI智能体在类似情境下的行为。

Method: 研究设计了一个虚拟锦标赛，将语言模型智能体分组为团队，在囚徒困境游戏中相互对抗。通过模拟内部团队动态和外部竞争，研究了这种混合对合作行为的影响。

Result: 研究发现，内部团队动态和外部竞争的结合显著提高了整体和初始一次性合作水平（即在一锤子买卖中合作的倾向）。

Conclusion: 这项研究为大型语言模型在复杂社交场景中的策略制定和行动提供了新颖框架，并证明了群体间竞争如何反直觉地导致更多合作行为。这些见解对于设计未来能够有效协作并与人类价值观更好对齐的多智能体AI系统至关重要。

Abstract: With the prospect of autonomous artificial intelligence (AI) agents, studying
their tendency for cooperative behavior becomes an increasingly relevant topic.
This study is inspired by the super-additive cooperation theory, where the
combined effects of repeated interactions and inter-group rivalry have been
argued to be the cause for cooperative tendencies found in humans. We devised a
virtual tournament where language model agents, grouped into teams, face each
other in a Prisoner's Dilemma game. By simulating both internal team dynamics
and external competition, we discovered that this blend substantially boosts
both overall and initial, one-shot cooperation levels (the tendency to
cooperate in one-off interactions). This research provides a novel framework
for large language models to strategize and act in complex social scenarios and
offers evidence for how intergroup competition can, counter-intuitively, result
in more cooperative behavior. These insights are crucial for designing future
multi-agent AI systems that can effectively work together and better align with
human values. Source code is available at
https://github.com/pippot/Superadditive-cooperation-LLMs.

</details>


### [101] [DeepThink3D: Enhancing Large Language Models with Programmatic Reasoning in Complex 3D Situated Reasoning Tasks](https://arxiv.org/abs/2508.15548)
*Jiayi Song,Rui Wan,Lipeng Ma,Weidong Yang,Qingyuan Zhou,Yixuan Li,Ben Fei*

Main category: cs.AI

TL;DR: DeepThink3D通过生成复杂问题和优化工具链策略，提升了LLMs在3D场景中的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有数据集问题简单，导致生成的程序推理链较短，限制了LLMs在复杂3D任务中的表现。

Method: 提出组合迭代进化方法在SQA3D基准上生成更复杂问题，并利用DPO直接优化模型生成的工具链策略。

Result: 通过DeepThink3D，LLMs在复杂3D任务中的工具使用和推理准确性得到显著提升。

Conclusion: DeepThink3D通过组合迭代进化方法和DPO优化，显著提升了LLMs在复杂3D场景中的推理能力。

Abstract: This work enhances the ability of large language models (LLMs) to perform
complex reasoning in 3D scenes. Recent work has addressed the 3D situated
reasoning task by invoking tool usage through large language models. Large
language models call tools via APIs and integrate the generated programs
through a chain of thought to solve problems based on the program results.
However, due to the simplicity of the questions in the dataset, the generated
program reasoning chains are relatively short. To solve this main challenge, in
this paper, we introduce DeepThink3D to enhance the tool usage of LLMs in
complex 3D situated reasoning tasks. Our work proposes a combinatorial and
iterative evolutionary approach on the SQA3D benchmark to generate more complex
questions. Building on this foundation, we fine-tune the large language model
to make it more proficient in using 3D tools. By employing Direct Preference
Optimization (DPO), we directly optimize the toolchain strategies generated by
models, thereby enhancing their accuracy in complex tasks.

</details>


### [102] [A Dynamical Systems Framework for Reinforcement Learning Safety and Robustness Verification](https://arxiv.org/abs/2508.15588)
*Ahmed Nasir,Abdelhafid Zenati*

Main category: cs.AI

TL;DR: 该论文提出了一种结合动态系统理论和定量指标的框架，用于评估强化学习策略的安全性和鲁棒性，成功识别了隐藏的缺陷。


<details>
  <summary>Details</summary>
Motivation: 强化学习在安全关键系统中的应用受限于缺乏验证学习策略鲁棒性和安全性的正式方法。

Method: 利用离散时间自主动态系统分析RL代理及其环境，结合有限时间Lyapunov指数（FTLE）识别Lagrangian相干结构（LCS），并引入定量指标（MBR、ASAS、TASAS）衡量策略的安全性和鲁棒性。

Result: 实验证明，该框架能够全面且可解释地评估策略行为，识别仅基于奖励看似成功但存在关键缺陷的策略。

Conclusion: 该论文通过引入动态系统理论和定量指标，为强化学习策略的安全性和鲁棒性提供了全面的评估框架，成功识别了仅基于奖励看似成功但存在关键缺陷的策略。

Abstract: The application of reinforcement learning to safety-critical systems is
limited by the lack of formal methods for verifying the robustness and safety
of learned policies. This paper introduces a novel framework that addresses
this gap by analyzing the combination of an RL agent and its environment as a
discrete-time autonomous dynamical system. By leveraging tools from dynamical
systems theory, specifically the Finite-Time Lyapunov Exponent (FTLE), we
identify and visualize Lagrangian Coherent Structures (LCS) that act as the
hidden "skeleton" governing the system's behavior. We demonstrate that
repelling LCS function as safety barriers around unsafe regions, while
attracting LCS reveal the system's convergence properties and potential failure
modes, such as unintended "trap" states. To move beyond qualitative
visualization, we introduce a suite of quantitative metrics, Mean Boundary
Repulsion (MBR), Aggregated Spurious Attractor Strength (ASAS), and
Temporally-Aware Spurious Attractor Strength (TASAS), to formally measure a
policy's safety margin and robustness. We further provide a method for deriving
local stability guarantees and extend the analysis to handle model uncertainty.
Through experiments in both discrete and continuous control environments, we
show that this framework provides a comprehensive and interpretable assessment
of policy behavior, successfully identifying critical flaws in policies that
appear successful based on reward alone.

</details>


### [103] [Transduction is All You Need for Structured Data Workflows](https://arxiv.org/abs/2508.15610)
*Alfio Gliozzo,Naweed Khan,Christodoulos Constantinides,Nandana Mihindukulasooriya,Nahuel Defosse,Junkyu Lee*

Main category: cs.AI

TL;DR: Agentics是一个模块化框架，通过抽象代理和逻辑转换，简化AI工作流，在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助AI开发者专注于数据建模而非提示工程，提供一种声明性语言来处理复杂数据和AI工作流。

Method: 框架将代理从逻辑流中抽象出来，利用LLMs提供的数据类型，通过逻辑转换进行组合。

Result: 在特定领域的多项任务中（如多项选择问答、文本到SQL的语义解析和自动提示优化），Agentics实现了优异的性能。

Conclusion: Agentics框架通过模块化设计和逻辑转换机制，为构建基于代理的系统提供了新视角，并在多个任务中实现了最先进的准确性和可扩展性。

Abstract: This paper introduces Agentics, a modular framework for building agent-based
systems capable of structured reasoning and compositional generalization over
complex data. Designed with research and practical applications in mind,
Agentics offers a novel perspective on working with data and AI workflows. In
this framework, agents are abstracted from the logical flow and they are used
internally to the data type to enable logical transduction among data. Agentics
encourages AI developers to focus on modeling data rather than crafting
prompts, enabling a declarative language in which data types are provided by
LLMs and composed through logical transduction, which is executed by LLMs when
types are connected. We provide empirical evidence demonstrating the
applicability of this framework across domain-specific multiple-choice question
answering, semantic parsing for text-to-SQL, and automated prompt optimization
tasks, achieving state-of-the-art accuracy or improved scalability without
sacrificing performance. The open-source implementation is available at
\texttt{https://github.com/IBM/agentics}.

</details>


### [104] [Adapting A Vector-Symbolic Memory for Lisp ACT-R](https://arxiv.org/abs/2508.15630)
*Meera Ray,Christopher L. Dancy*

Main category: cs.AI

TL;DR: HDM作为ACT-R的替代记忆系统，成功兼容现有模型并保持向量符号优势，未来将优化时间上下文表示并测试其在决策模型中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决ACT-R的Declarative Memory系统在可扩展性和相似性定义上的局限性，研究人员提出使用Holographic Declarative Memory（HDM）作为替代方案。

Method: 研究人员将HDM适配到Lisp ACT-R中，开发了基于向量的ACT-R函数版本，建立了文本处理管道，并创建了基于向量表示的记忆检索机制。

Result: 初步结果表明，HDM在保持向量符号优势（如无需存储实际块即可召回块）的同时，能够与现有ACT-R模型兼容，且无需对模型中的程序性和声明性记忆部分进行重大修改。

Conclusion: 通过将HDM与ACT-R结合，研究人员成功开发出一种既能保持向量符号优势又能兼容现有ACT-R模型的记忆模块，未来将进一步优化时间上下文表示并测试其在实际决策模型中的应用。

Abstract: Holographic Declarative Memory (HDM) is a vector-symbolic alternative to
ACT-R's Declarative Memory (DM) system that can bring advantages such as
scalability and architecturally defined similarity between DM chunks. We
adapted HDM to work with the most comprehensive and widely-used implementation
of ACT-R (Lisp ACT-R) so extant ACT-R models designed with DM can be run with
HDM without major changes. With this adaptation of HDM, we have developed
vector-based versions of common ACT-R functions, set up a text processing
pipeline to add the contents of large documents to ACT-R memory, and most
significantly created a useful and novel mechanism to retrieve an entire chunk
of memory based on a request using only vector representations of tokens.
Preliminary results indicate that we can maintain vector-symbolic advantages of
HDM (e.g., chunk recall without storing the actual chunk and other advantages
with scaling) while also extending it so that previous ACT-R models may work
with the system with little (or potentially no) modifications within the actual
procedural and declarative memory portions of a model. As a part of iterative
improvement of this newly translated holographic declarative memory module, we
will continue to explore better time-context representations for vectors to
improve the module's ability to reconstruct chunks during recall. To more fully
test this translated HDM module, we also plan to develop decision-making models
that use instance-based learning (IBL) theory, which is a useful application of
HDM given the advantages of the system.

</details>


### [105] [Understanding Action Effects through Instrumental Empowerment in Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2508.15652)
*Ardian Selmonaj,Miroslav Strupl,Oleg Szehr,Alessandro Antonucci*

Main category: cs.AI

TL;DR: 本文提出ICV方法，通过信息论Shapley值量化智能体对队友的因果影响，增强MARL系统的可解释性，揭示合作与竞争环境中的行为策略。


<details>
  <summary>Details</summary>
Motivation: 在多智能体强化学习（MARL）系统中，理解单个智能体在团队中的行为对可靠部署至关重要。然而，在没有显式价值反馈的情况下，如何推断智能体的贡献尚不明确。本文旨在通过分析策略分布提取与底层价值函数一致的智能体行为见解。

Method: 本文提出了一种基于信息论Shapley值的Intended Cooperation Values（ICV）方法，通过分析智能体的策略分布来量化其对队友的因果影响。具体来说，ICV通过评估队友的决策不确定性和偏好对齐来测量智能体行为的影响。

Result: 在合作和竞争的MARL环境中的分析表明，ICV方法能够揭示智能体采用相似或多样化策略的程度。通过比较策略和价值函数之间的行为效果，该方法识别出哪些行为有利于团队成功，无论是通过促进确定性决策还是保留未来行动选择的灵活性。

Conclusion: 本文提出的Intended Cooperation Values（ICV）方法通过信息论的Shapley值量化了每个智能体对队友的因果影响，为多智能体强化学习系统的行为分析提供了新的视角，增强了系统的可解释性。

Abstract: To reliably deploy Multi-Agent Reinforcement Learning (MARL) systems, it is
crucial to understand individual agent behaviors within a team. While prior
work typically evaluates overall team performance based on explicit reward
signals or learned value functions, it is unclear how to infer agent
contributions in the absence of any value feedback. In this work, we
investigate whether meaningful insights into agent behaviors can be extracted
that are consistent with the underlying value functions, solely by analyzing
the policy distribution. Inspired by the phenomenon that intelligent agents
tend to pursue convergent instrumental values, which generally increase the
likelihood of task success, we introduce Intended Cooperation Values (ICVs), a
method based on information-theoretic Shapley values for quantifying each
agent's causal influence on their co-players' instrumental empowerment.
Specifically, ICVs measure an agent's action effect on its teammates' policies
by assessing their decision uncertainty and preference alignment. The analysis
across cooperative and competitive MARL environments reveals the extent to
which agents adopt similar or diverse strategies. By comparing action effects
between policies and value functions, our method identifies which agent
behaviors are beneficial to team success, either by fostering deterministic
decisions or by preserving flexibility for future action choices. Our proposed
method offers novel insights into cooperation dynamics and enhances
explainability in MARL systems.

</details>


### [106] [Futurity as Infrastructure: A Techno-Philosophical Interpretation of the AI Lifecycle](https://arxiv.org/abs/2508.15680)
*Mark Cote,Susana Aires*

Main category: cs.AI

TL;DR: 本文通过技术哲学视角分析欧盟AI法案，提出"未来性"概念揭示AI生命周期的递归动态，并建议监管措施应对基础设施和时间挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨欧盟AI法案的技术哲学解读，揭示数据在AI系统中的长期动态，特别是从摄入到部署的生命周期如何生成挑战现有负责任AI框架的递归价值链。

Method: 采用跨学科方法，结合技术基础和哲学连贯性分析监管盲点，引入受Simondonian技术哲学启发的形式化阅读，重新定义个体化概念以建模AI生命周期。

Result: 提出了"未来性"概念，强调数据的递归生成和非竞争性，揭示了技术寡头通过捕获、训练和部署基础设施集中价值和决策权的日益加剧的权力不对称。

Conclusion: 本文主张，有效的AI监管必须解决基础设施和时间动态问题，并提出包括生命周期审计、时间可追溯性、反馈问责、递归透明度和反对递归重用的权利等措施。

Abstract: This paper argues that a techno-philosophical reading of the EU AI Act
provides insight into the long-term dynamics of data in AI systems,
specifically, how the lifecycle from ingestion to deployment generates
recursive value chains that challenge existing frameworks for Responsible AI.
We introduce a conceptual tool to frame the AI pipeline, spanning data,
training regimes, architectures, feature stores, and transfer learning. Using
cross-disciplinary methods, we develop a technically grounded and
philosophically coherent analysis of regulatory blind spots. Our central claim
is that what remains absent from policymaking is an account of the dynamic of
becoming that underpins both the technical operation and economic logic of AI.
To address this, we advance a formal reading of AI inspired by Simondonian
philosophy of technology, reworking his concept of individuation to model the
AI lifecycle, including the pre-individual milieu, individuation, and
individuated AI. To translate these ideas, we introduce futurity: the
self-reinforcing lifecycle of AI, where more data enhances performance, deepens
personalisation, and expands application domains. Futurity highlights the
recursively generative, non-rivalrous nature of data, underpinned by
infrastructures like feature stores that enable feedback, adaptation, and
temporal recursion. Our intervention foregrounds escalating power asymmetries,
particularly the tech oligarchy whose infrastructures of capture, training, and
deployment concentrate value and decision-making. We argue that effective
regulation must address these infrastructural and temporal dynamics, and
propose measures including lifecycle audits, temporal traceability, feedback
accountability, recursion transparency, and a right to contest recursive reuse.

</details>


### [107] [GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning](https://arxiv.org/abs/2508.15690)
*Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran*

Main category: cs.AI

TL;DR: GRAFT是一个多模态基准测试，用于评估模型在视觉推理和指令遵循任务上的表现，通过程序生成的图表和表格，结合结构化问题和答案，为多模态模型设定了新的评估标准。


<details>
  <summary>Details</summary>
Motivation: 为了评估模型在指令遵循、视觉推理和视觉文本对齐任务上的性能，并提供一个全面的评估基准。

Method: GRAFT通过程序生成的图表和合成渲染的表格，结合Python可视化库，确保对数据语义、结构和清晰度的控制。每个GRAFT实例将图表或表格图像与基于视觉内容的系统生成的多步骤分析问题配对。

Result: GRAFT引入了一种推理类型的分类法，包括比较、趋势识别、排名、聚合、比例估计和异常检测，以支持全面的评估。参考答案遵循严格的事实和格式指南，以实现精确的、基于方面的评估。

Conclusion: GRAFT提供了一个统一的、可扩展的框架，用于在多模态模型上进行视觉基础和结构化推理任务的细粒度基准测试，为该领域设定了新的评估标准。

Abstract: GRAFT is a structured multimodal benchmark for evaluating models on
instruction-following, visual reasoning, and visual-textual alignment tasks. It
features programmatically generated charts and synthetically rendered tables,
created with Python visualization libraries to ensure control over data
semantics, structure, and clarity. Each GRAFT instance pairs a chart or table
image with a systematically generated, multi-step analytical question based
solely on visual content. Answers are provided in structured formats such as
JSON or YAML, supporting consistent evaluation of both reasoning and output
format. The benchmark introduces a taxonomy of reasoning types including
comparison, trend identification, ranking, aggregation, proportion estimation,
and anomaly detection to enable comprehensive assessment. Reference answers
follow strict factual and formatting guidelines for precise, aspect-based
evaluation. GRAFT offers a unified, scalable framework for fine-grained
benchmarking of multimodal models on visually grounded, structured reasoning
tasks, setting a new evaluation standard in this field.

</details>


### [108] [NiceWebRL: a Python library for human subject experiments with reinforcement learning environments](https://arxiv.org/abs/2508.15693)
*Wilka Carvalho,Vikram Goddla,Ishaan Sinha,Hoon Shin,Kunal Jha*

Main category: cs.AI

TL;DR: NiceWebRL是一个Python库，能将Jax-based RL环境转化为在线界面，支持单人和多人实验，适用于AI、认知科学和多智能体研究。


<details>
  <summary>Details</summary>
Motivation: 开发NiceWebRL的目的是为了帮助AI研究人员比较算法与人类表现，认知科学家测试ML算法作为人类认知理论，以及多智能体研究者开发人机协作算法。

Method: NiceWebRL是一个Python库，能够将任何基于Jax的环境转化为在线界面，支持单人和多人环境。通过三个案例研究展示了其潜力：开发人类类似AI、人类兼容AI和人类辅助AI。

Result: NiceWebRL在三个案例研究中展示了其潜力，包括开发人类类似AI模型、人类兼容AI算法以及研究LLM如何辅助人类完成复杂任务。

Conclusion: NiceWebRL是一个强大的研究工具，能够将Jax-based的RL环境转化为在线界面，支持单人和多人环境，为AI研究人员、认知科学家和多智能体研究者提供了丰富的应用场景。

Abstract: We present NiceWebRL, a research tool that enables researchers to use machine
reinforcement learning (RL) environments for online human subject experiments.
NiceWebRL is a Python library that allows any Jax-based environment to be
transformed into an online interface, supporting both single-agent and
multi-agent environments. As such, NiceWebRL enables AI researchers to compare
their algorithms to human performance, cognitive scientists to test ML
algorithms as theories for human cognition, and multi-agent researchers to
develop algorithms for human-AI collaboration. We showcase NiceWebRL with 3
case studies that demonstrate its potential to help develop Human-like AI,
Human-compatible AI, and Human-assistive AI. In the first case study
(Human-like AI), NiceWebRL enables the development of a novel RL model of
cognition. Here, NiceWebRL facilitates testing this model against human
participants in both a grid world and Craftax, a 2D Minecraft domain. In our
second case study (Human-compatible AI), NiceWebRL enables the development of a
novel multi-agent RL algorithm that can generalize to human partners in the
Overcooked domain. Finally, in our third case study (Human-assistive AI), we
show how NiceWebRL can allow researchers to study how an LLM can assist humans
on complex tasks in XLand-Minigrid, an environment with millions of
hierarchical tasks. The library is available at
https://github.com/KempnerInstitute/nicewebrl.

</details>


### [109] [Measuring the environmental impact of delivering AI at Google Scale](https://arxiv.org/abs/2508.15734)
*Cooper Elsworth,Keguo Huang,David Patterson,Ian Schneider,Robert Sedivy,Savannah Goodman,Ben Townsend,Parthasarathy Ranganathan,Jeff Dean,Amin Vahdat,Ben Gomes,James Manyika*

Main category: cs.AI

TL;DR: 本文提出并执行了一种全面测量AI推理工作负载能耗、碳排放和水消耗的方法，发现Gemini Apps的中位能耗极低，并强调持续关注AI服务环境影响的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI用户采用加速，需要理解和减轻AI服务对环境的影响，但目前缺乏生产环境中的相关研究。

Method: 通过在谷歌的AI基础设施中进行详细测量，包括AI加速器、主机系统、空闲机器容量和数据中心能耗。

Result: 发现Gemini Apps文本提示的中位能耗为0.24 Wh，远低于公开估计；谷歌的软件效率努力和清洁能源采购使能耗和碳足迹分别减少了33倍和44倍。

Conclusion: 全面测量AI服务环境指标对于准确比较模型和激励全栈效率提升至关重要。

Abstract: The transformative power of AI is undeniable - but as user adoption
accelerates, so does the need to understand and mitigate the environmental
impact of AI serving. However, no studies have measured AI serving
environmental metrics in a production environment. This paper addresses this
gap by proposing and executing a comprehensive methodology for measuring the
energy usage, carbon emissions, and water consumption of AI inference workloads
in a large-scale, AI production environment. Our approach accounts for the full
stack of AI serving infrastructure - including active AI accelerator power,
host system energy, idle machine capacity, and data center energy overhead.
Through detailed instrumentation of Google's AI infrastructure for serving the
Gemini AI assistant, we find the median Gemini Apps text prompt consumes 0.24
Wh of energy - a figure substantially lower than many public estimates. We also
show that Google's software efficiency efforts and clean energy procurement
have driven a 33x reduction in energy consumption and a 44x reduction in carbon
footprint for the median Gemini Apps text prompt over one year. We identify
that the median Gemini Apps text prompt uses less energy than watching nine
seconds of television (0.24 Wh) and consumes the equivalent of five drops of
water (0.26 mL). While these impacts are low compared to other daily
activities, reducing the environmental impact of AI serving continues to
warrant important attention. Towards this objective, we propose that a
comprehensive measurement of AI serving environmental metrics is critical for
accurately comparing models, and to properly incentivize efficiency gains
across the full AI serving stack.

</details>


### [110] [Response and Prompt Evaluation to Prevent Parasocial Relationships with Chatbots](https://arxiv.org/abs/2508.15748)
*Emma Rath,Stuart Armstrong,Rebecca Gorman*

Main category: cs.AI

TL;DR: 研究提出了一种实时评估对话中拟社会线索的框架，初步证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 拟社会关系对AI代理的发展对人类福祉有严重甚至悲剧性的影响，且预防此类动态具有挑战性。

Method: 通过重新利用最先进的语言模型，引入了一个简单的响应评估框架，实时评估对话中的拟社会线索。使用包含三十个对话的小型合成数据集进行测试，涵盖拟社会、奉承和中立对话。

Result: 五阶段测试成功地识别了所有拟社会对话，并在容忍一致规则下避免了误报，通常在最初几次交流中即可检测到。

Conclusion: 该研究提出了一个初步证据，表明评估代理可以为预防拟社会关系提供可行解决方案。

Abstract: The development of parasocial relationships with AI agents has severe, and in
some cases, tragic effects for human well-being. Yet preventing such dynamics
is challenging: parasocial cues often emerge gradually in private
conversations, and not all forms of emotional engagement are inherently
harmful. We address this challenge by introducing a simple response evaluation
framework, created by repurposing a state-of-the-art language model, that
evaluates ongoing conversations for parasocial cues in real time. To test the
feasibility of this approach, we constructed a small synthetic dataset of
thirty dialogues spanning parasocial, sycophantic, and neutral conversations.
Iterative evaluation with five stage testing successfully identified all
parasocial conversations while avoiding false positives under a tolerant
unanimity rule, with detection typically occurring within the first few
exchanges. These findings provide preliminary evidence that evaluation agents
can provide a viable solution for the prevention of parasocial relations.

</details>


### [111] [Language-Guided Tuning: Enhancing Numeric Optimization with Textual Feedback](https://arxiv.org/abs/2508.15757)
*Yuxing Lu,Yucheng Hu,Nan Sun,Xukai Zhao*

Main category: cs.AI

TL;DR: LGT是一种基于多代理LLM的配置优化框架，通过自然语言推理和协作代理提升性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统配置优化方法缺乏协调性和可解释性，自动化方法动态适应性和语义推理能力不足。

Method: 引入Language-Guided Tuning (LGT)框架，利用多代理大型语言模型（LLM）通过自然语言推理优化配置，结合文本梯度（定性反馈信号）和三个专业代理（Advisor、Evaluator、Optimizer）的协作。

Result: 在六个多样化数据集上的评估显示，LGT相比传统优化方法性能显著提升，同时保持高可解释性。

Conclusion: LGT通过自然语言推理和多代理协作，显著提升了配置优化的性能和可解释性，优于传统方法。

Abstract: Configuration optimization remains a critical bottleneck in machine learning,
requiring coordinated tuning across model architecture, training strategy,
feature engineering, and hyperparameters. Traditional approaches treat these
dimensions independently and lack interpretability, while recent automated
methods struggle with dynamic adaptability and semantic reasoning about
optimization decisions. We introduce Language-Guided Tuning (LGT), a novel
framework that employs multi-agent Large Language Models to intelligently
optimize configurations through natural language reasoning. We apply textual
gradients - qualitative feedback signals that complement numerical optimization
by providing semantic understanding of training dynamics and configuration
interdependencies. LGT coordinates three specialized agents: an Advisor that
proposes configuration changes, an Evaluator that assesses progress, and an
Optimizer that refines the decision-making process, creating a self-improving
feedback loop. Through comprehensive evaluation on six diverse datasets, LGT
demonstrates substantial improvements over traditional optimization methods,
achieving performance gains while maintaining high interpretability.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [112] [Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer](https://arxiv.org/abs/2508.15058)
*Kaiqiang Lin,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 论文提出了一种结合卫星、空中、地面和地下通信的SAGUIN架构，通过LoRaWAN和WET技术实现可持续的地下大规模机器通信，仿真验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 地下无线传感器网络（WUSNs）在恶劣的地下环境、稀缺的网络资源和有限的通信覆盖下面临巨大挑战，特别是在偏远、受灾和难以到达的区域支持可持续的大规模机器通信（mMTC）。

Method: 论文通过仿真模拟远程地下管道监测场景，评估了基于LoRaWAN和WET技术的SAGUIN的可行性和性能，重点分析了地下条件、时间分配、LoRaWAN扩展因子配置等参数的影响。

Result: 结果表明，提出的SAGUIN系统结合推导的时间分配策略和适当的扩展因子配置，可以有效延长地下设备的运行寿命，促进可持续的地下mMTC。

Conclusion: 论文提出了一种新型的SAGUIN架构，结合LoRaWAN和WET技术，能够有效延长地下设备的运行寿命，支持可持续的地下大规模机器通信。同时指出了关键挑战和未来研究方向。

Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing
and monitoring of underground resources by underground devices (UDs), hold
great promise for delivering substantial social and economic benefits across
various verticals. However, due to the harsh subterranean environment, scarce
network resources, and restricted communication coverage, WUSNs face
significant challenges in supporting sustainable massive machine-type
communications (mMTC), particularly in remote, disaster-stricken, and
hard-to-reach areas. To complement this, we conceptualize in this study a novel
space-air-ground-underground integrated network (SAGUIN) architecture that
seamlessly incorporates satellite systems, aerial platforms, terrestrial
networks, and underground communications. On this basis, we integrate LoRaWAN
and wireless energy transfer (WET) technologies into SAGUIN to enable
sustainable subterranean mMTC. We begin by reviewing the relevant technical
background and presenting the architecture and implementation challenges of
SAGUIN. Then, we employ simulations to model a remote underground pipeline
monitoring scenario to evaluate the feasibility and performance of SAGUIN based
on LoRaWAN and WET technologies, focusing on the effects of parameters such as
underground conditions, time allocation, LoRaWAN spread factor (SF)
configurations, reporting periods, and harvested energy levels. Our results
evidence that the proposed SAGUIN system, when combined with the derived time
allocation strategy and an appropriate SF, can effectively extend the
operational lifetime of UDs, thereby facilitating sustainable subterranean
mMTC. Finally, we pinpoint key challenges and future research directions for
SAGUIN.

</details>


### [113] [From 5G RAN Queue Dynamics to Playback: A Performance Analysis for QUIC Video Streaming](https://arxiv.org/abs/2508.15087)
*Jashanjot Singh Sidhu,Jorge Ignacio Sandoval,Abdelhak Bentaleb,Sandra Cespedes*

Main category: cs.NI

TL;DR: 该论文分析了5G环境下AQM策略与QUIC实现、拥塞控制算法和ABR方案的交互，发现孤立优化不足以提升视频流QoE，需跨层自适应机制。


<details>
  <summary>Details</summary>
Motivation: 研究的动机源于移动网络中优化用户体验质量（QoE）的挑战，特别是由于5G网络中应用层的自适应比特率（ABR）方案、传输层的拥塞控制算法和链路层的无线链路控制（RLC）排队之间的复杂交互。

Method: 论文的方法包括对现代主动队列管理（AQM）策略（如RED和L4S）在5G环境下与QUIC实现、拥塞控制算法和自适应比特率（ABR）方案的动态交互进行全面分析。

Result: 研究结果表明，AQM策略在改善视频流QoE方面的效果与其与QUIC实现、拥塞控制算法和ABR方案的动态交互密切相关，孤立优化是不够的。

Conclusion: 该论文的结论是，为了充分利用5G网络的潜力提供稳健、自适应和高质量的视频流，需要一种能够实时协调网络、传输和应用层的全面跨层自适应机制。

Abstract: The rapid adoption of QUIC as a transport protocol has transformed content
delivery by reducing latency, enhancing congestion control (CC), and enabling
more efficient multiplexing. With the advent of 5G networks, which support
ultra-low latency and high bandwidth, streaming high-resolution video at 4K and
beyond has become increasingly viable. However, optimizing Quality of
Experience (QoE) in mobile networks remains challenging due to the complex
interactions among Adaptive Bit Rate (ABR) schemes at the application layer, CC
algorithms at the transport layer, and Radio Link Control (RLC) queuing at the
link layer in the 5G network. While prior studies have largely examined these
components in isolation, this work presents a comprehensive analysis of the
impact of modern active queue management (AQM) strategies, such as RED and L4S,
on video streaming over diverse QUIC implementations--focusing particularly on
their interaction with the RLC buffer in 5G environments and the interplay
between CC algorithms and ABR schemes. Our findings demonstrate that the
effectiveness of AQM strategies in improving video streaming QoE is
intrinsically linked to their dynamic interaction with QUIC implementations, CC
algorithms and ABR schemes-highlighting that isolated optimizations are
insufficient. This intricate interdependence necessitates holistic, cross-layer
adaptive mechanisms capable of real-time coordination between network,
transport and application layers, which are crucial for fully leveraging the
capabilities of 5G networks to deliver robust, adaptive, and high-quality video
streaming.

</details>


### [114] [Toward Autonomous Digital Populations for Communication-Sensing-Computation Ecosystem](https://arxiv.org/abs/2508.15268)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 论文提出了一种基于数字孪生技术的自然启发框架，旨在解决当前通信网络的集中控制和静态设计问题，为下一代网络提供动态适应和进化能力。


<details>
  <summary>Details</summary>
Motivation: 当前通信网络依赖集中控制、静态设计和人工干预，限制了网络功能和应用的多维发展，无法适应大规模、分层和复杂环境的需求。

Method: 利用数字孪生技术将边缘连接设备组织成功能性数字群体，并通过云端多群体集成实现可进化的数字生态系统。

Result: 提出的框架结合工程方法论和社会技术洞察，为下一代通信网络提供了动态协调、分布式决策、持续适应和进化能力的理论基础。

Conclusion: 该论文提出了一个受自然启发的架构框架，结合数字孪生技术，为下一代通信网络奠定了理论基础，具备动态协调、分布式决策、持续适应和进化能力。

Abstract: Future communication networks are expected to achieve deep integration of
communication, sensing, and computation, forming a tightly coupled and
autonomously operating infrastructure system. However, current reliance on
centralized control, static design, and human intervention continues to
constrain the multidimensional evolution of network functions and applications,
limiting adaptability and resilience in large-scale, layered, and complex
environments. To address these challenges, this paper proposes a
nature-inspired architectural framework that leverages digital twin technology
to organize connected devices at the edge into functional digital populations,
while enabling the emergence of an evolvable digital ecosystem through
multi-population integration at the cloud. We believe that this framework,
which combines engineering methodologies with sociotechnical insights, lays the
theoretical foundation for building next-generation communication networks with
dynamic coordination, distributed decision-making, continuous adaptation, and
evolutionary capabilities.

</details>


### [115] [Unlocking the Performance Potential of Mega-Constellation Networks: An Exploration of Structure-Building Paradigms](https://arxiv.org/abs/2508.15307)
*Xiangtong Wang,Wei Li,Menglong Yang,Songchen Han*

Main category: cs.NI

TL;DR: 本文提出SMLOP算法，通过解耦MCN设计为本地和全局部分，解决了高可用低延迟的MCN设计问题，实验显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: MCN中如何设计最优网络控制结构以配置最稳定的星间链路（ISL），在有限的平均传输延迟内实现高可用性MCN是一个关键问题。

Method: 本文引入了一种新的MCN结构设计范式：结构=Motif + Lattice (SML)，将MCN设计解耦为本地Motif设计和全局Lattice设计。并提出了SMLOP启发式算法来解决HALLMD问题。

Result: 在四个公开的最先进星座上的实验验证表明，SMLOP算法显著提升了性能，包括容量提升5~18%，吞吐量增加1~12%，路径拉伸减少12~23%，往返时间降低8~77%。

Conclusion: 本文提出的SMLOP算法在多项式时间内高效地找到了最优网络结构，显著提升了MCN的性能，包括容量、吞吐量、路径拉伸和往返时间的改善。

Abstract: The network structure design plays a vital role in the mega-constellation
network (MSN) to coordinate massive network nodes to ensure the effectiveness
and reliability of operations and services for future space wireless
communications networks.
  One of the critical issues in MCN is how to design an optimal network control
structure by configuring the most stable inter-satellite link (ISL) to achieve
high available MCN within a limited average transmission delays.
  To address this problem, this paper introduces a novel MCN structure design
paradigm: Structure = Motif + Lattice (SML), which decouples MCN design into
local motifs design and global lattices design. Specifically, we formulate the
High-Availability and Low-Latency Mega-Constellation Design (HALLMD) problem,
aimed at maximizing ISL availability while minimizing the transmission latency.
To solve HALLMD, we propose SMLOP, a heuristic algorithm that efficiently finds
optimal network structures in polynomial time. Experimental validation on four
public state-of-the-art constellations demonstrates significant improvements,
including enhanced capacity by $5\sim 18\%$, increased throughput by $1\sim
12\%$, reduced path stretch by $12\sim 23\%$, and Round-Trip Time (RTT) by
$8\sim 77\%$.

</details>


### [116] [Interface on demand: Towards AI native Control interfaces for 6G](https://arxiv.org/abs/2508.15595)
*Abhishek Dandekar,Prashiddha D. Thapa,Ashrafur Rahman,Julius Schulz-Zander*

Main category: cs.NI

TL;DR: 提出基于LLMs的多智能体框架，动态生成网络控制接口，解决传统接口的不兼容和僵化问题，验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 传统标准化网络接口存在供应商特定的不兼容性、设计假设僵化以及缺乏新功能适应性等问题。

Method: 提出了一种利用大型语言模型（LLMs）的多智能体框架，包括匹配代理和代码生成代理，用于按需生成网络功能（NFs）之间的控制接口。

Result: 在模拟的多供应商gNB和WLAN AP环境中验证了方法的有效性，性能评估突出了LLMs在接口生成任务中成本与延迟之间的权衡。

Conclusion: 该研究为AI原生的动态控制接口生成奠定了基础，为未来移动网络中的增强互操作性和适应性铺平了道路。

Abstract: Traditional standardized network interfaces face significant limitations,
including vendor-specific incompatibilities, rigid design assumptions, and lack
of adaptability for new functionalities. We propose a multi-agent framework
leveraging large language models (LLMs) to generate control interfaces on
demand between network functions (NFs). This includes a matching agent, which
aligns required control functionalities with NF capabilities, and a
code-generation agent, which generates the necessary API server for interface
realization. We validate our approach using simulated multi-vendor gNB and WLAN
AP environments. The performance evaluations highlight the trade-offs between
cost and latency across LLMs for interface generation tasks. Our work sets the
foundation for AI-native dynamic control interface generation, paving the way
for enhanced interoperability and adaptability in future mobile networks.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [117] [Hybrelighter: Combining Deep Anisotropic Diffusion and Scene Reconstruction for On-device Real-time Relighting in Mixed Reality](https://arxiv.org/abs/2508.14930)
*Hanwen Zhao,John Akers,Baback Elmieh,Ira Kemelmacher-Shlizerman*

Main category: cs.GR

TL;DR: 本文提出了一种实时混合现实场景重照明方法，结合图像分割和各向异性扩散，解决了现有技术的实时性和准确性不足，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习重照明技术通常无法满足混合现实设备的实时性能需求，而场景理解方法由于扫描限制导致结果不准确，简单的2D图像滤波方法则无法表现复杂几何和阴影。本文旨在解决这些局限性。

Method: 该方法整合了图像分割、各向异性扩散的光照传播以及基本的场景理解，同时保持了基于滤波技术的计算简单性。

Result: 该方法在边缘设备上实现了高达100 fps的实时性能，同时提供了视觉上吸引人且准确的重照明效果。

Conclusion: 该论文提出了一种新颖的混合现实场景重照明方法，通过结合图像分割、光照传播和各向异性扩散，有效解决了现有技术在实时性和准确性上的不足，适用于边缘设备。

Abstract: Mixed Reality scene relighting, where virtual changes to lighting conditions
realistically interact with physical objects, producing authentic illumination
and shadows, can be used in a variety of applications. One such application in
real estate could be visualizing a room at different times of day and placing
virtual light fixtures. Existing deep learning-based relighting techniques
typically exceed the real-time performance capabilities of current MR devices.
On the other hand, scene understanding methods, such as on-device scene
reconstruction, often yield inaccurate results due to scanning limitations, in
turn affecting relighting quality. Finally, simpler 2D image filter-based
approaches cannot represent complex geometry and shadows. We introduce a novel
method to integrate image segmentation, with lighting propagation via
anisotropic diffusion on top of basic scene understanding, and the
computational simplicity of filter-based techniques. Our approach corrects
on-device scanning inaccuracies, delivering visually appealing and accurate
relighting effects in real-time on edge devices, achieving speeds as high as
100 fps. We show a direct comparison between our method and the industry
standard, and present a practical demonstration of our method in the
aforementioned real estate example.

</details>


### [118] [Inference Time Debiasing Concepts in Diffusion Models](https://arxiv.org/abs/2508.14933)
*Lucas S. Kupssinskü,Marco N. Bochernitsan,Jordan Kopper,Otávio Parraga,Rodrigo C. Barros*

Main category: cs.GR

TL;DR: DeCoDi是一种用于文本到图像扩散模型的去偏见方法，仅需改变推理程序，有效减轻性别、种族和年龄偏见，评估显示其效果显著且易于应用。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习去偏见方法通常需要复杂或计算密集的干预，而DeCoDi旨在通过仅改变推理程序，使去偏见方法更易于广泛应用。

Method: DeCoDi通过调整扩散过程避免潜在维度中的偏见概念区域，仅需改变推理程序，无需复杂或计算密集的干预。

Result: 通过人工评估和GPT4o自动评估，DeCoDi在减轻性别、种族和年龄偏见方面表现出色，评估结果显示出评估者之间的一致性和对保护属性的更广泛覆盖。

Conclusion: DeCoDi方法通过改变扩散过程的推理程序，有效减轻了基于性别、种族和年龄的偏见，同时保持了图像质量，计算开销低，适用于任何基于扩散的图像生成模型。

Abstract: We propose DeCoDi, a debiasing procedure for text-to-image diffusion-based
models that changes the inference procedure, does not significantly change
image quality, has negligible compute overhead, and can be applied in any
diffusion-based image generation model. DeCoDi changes the diffusion process to
avoid latent dimension regions of biased concepts. While most deep learning
debiasing methods require complex or compute-intensive interventions, our
method is designed to change only the inference procedure. Therefore, it is
more accessible to a wide range of practitioners. We show the effectiveness of
the method by debiasing for gender, ethnicity, and age for the concepts of
nurse, firefighter, and CEO. Two distinct human evaluators manually inspect
1,200 generated images. Their evaluation results provide evidence that our
method is effective in mitigating biases based on gender, ethnicity, and age.
We also show that an automatic bias evaluation performed by the GPT4o is not
significantly statistically distinct from a human evaluation. Our evaluation
shows promising results, with reliable levels of agreement between evaluators
and more coverage of protected attributes. Our method has the potential to
significantly improve the diversity of images it generates by diffusion-based
text-to-image generative models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [119] [On the need to perform comprehensive evaluations of automated program repair benchmarks: Sorald case study](https://arxiv.org/abs/2508.15135)
*Sumudu Liyanage,Sherlock A. Licorish,Markus Wagner,Stephen G. MacDonell*

Main category: cs.SE

TL;DR: 研究开发了评估APR工具的框架，发现Sorald修复违规的同时引入了新故障和代码退化，强调需要全面评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究倾向于仅评估APR工具清除违规的能力，忽视了其可能引入的新违规、代码功能变化和代码结构退化。因此，需要开发全面的评估框架。

Method: 研究评估了Sorald（一种最先进的APR工具）作为概念验证，修复了来自Stack Overflow的2,393个Java代码片段中的3,529个SonarQube违规。

Result: Sorald修复了特定规则违规，但引入了2,120个新故障（32个错误，2,088个代码异味），降低了代码功能正确性（24%的单元测试失败率），并退化代码结构。

Conclusion: 研究强调需要开发全面的评估方法，以捕捉自动程序修复（APR）工具的全部影响，包括副作用，以确保其安全有效的采用。

Abstract: In supporting the development of high-quality software, especially necessary
in the era of LLMs, automated program repair (APR) tools aim to improve code
quality by automatically addressing violations detected by static analysis
profilers. Previous research tends to evaluate APR tools only for their ability
to clear violations, neglecting their potential introduction of new (sometimes
severe) violations, changes to code functionality and degrading of code
structure. There is thus a need for research to develop and assess
comprehensive evaluation frameworks for APR tools. This study addresses this
research gap, and evaluates Sorald (a state-of-the-art APR tool) as a proof of
concept. Sorald's effectiveness was evaluated in repairing 3,529 SonarQube
violations across 30 rules within 2,393 Java code snippets extracted from Stack
Overflow. Outcomes show that while Sorald fixes specific rule violations, it
introduced 2,120 new faults (32 bugs, 2088 code smells), reduced code
functional correctness--as evidenced by a 24% unit test failure rate--and
degraded code structure, demonstrating the utility of our framework. Findings
emphasize the need for evaluation methodologies that capture the full spectrum
of APR tool effects, including side effects, to ensure their safe and effective
adoption.

</details>


### [120] [Foundational Design Principles and Patterns for Building Robust and Adaptive GenAI-Native Systems](https://arxiv.org/abs/2508.15411)
*Frederik Vandeputte*

Main category: cs.SE

TL;DR: 本文提出将生成式AI与传统软件工程结合的新范式，设计五大核心原则和架构模式，以构建更稳健的系统，并呼吁未来研究验证和实施。


<details>
  <summary>Details</summary>
Motivation: 生成式AI虽具有变革性，但其不可预测性和低效性为开发可靠高效的系统带来挑战，因此需要新范式。

Method: 介绍了以可靠性、卓越性、可进化性、自依赖性和保障性为核心的生成式AI原生设计原则，并提出了生成式AI原生细胞、有机基质和可编程路由器等架构模式。

Result: 提出了生成式AI原生软件栈的关键要素，并从技术、用户采纳、经济和法律角度讨论了这些系统的影响。

Conclusion: 本文提出了一种将生成式AI的认知能力与传统软件工程原则相结合的范式转变，旨在构建稳健、自适应和高效的系统，并呼吁未来研究和社区实施与完善这一概念框架。

Abstract: Generative AI (GenAI) has emerged as a transformative technology,
demonstrating remarkable capabilities across diverse application domains.
However, GenAI faces several major challenges in developing reliable and
efficient GenAI-empowered systems due to its unpredictability and inefficiency.
This paper advocates for a paradigm shift: future GenAI-native systems should
integrate GenAI's cognitive capabilities with traditional software engineering
principles to create robust, adaptive, and efficient systems.
  We introduce foundational GenAI-native design principles centered around five
key pillars -- reliability, excellence, evolvability, self-reliance, and
assurance -- and propose architectural patterns such as GenAI-native cells,
organic substrates, and programmable routers to guide the creation of resilient
and self-evolving systems. Additionally, we outline the key ingredients of a
GenAI-native software stack and discuss the impact of these systems from
technical, user adoption, economic, and legal perspectives, underscoring the
need for further validation and experimentation. Our work aims to inspire
future research and encourage relevant communities to implement and refine this
conceptual framework.

</details>


### [121] [An Empirical Study of Knowledge Distillation for Code Understanding Tasks](https://arxiv.org/abs/2508.15423)
*Ruiqi Wang,Zezhou Yang,Cuiyun Gao,Xin Xia,Qing Liao*

Main category: cs.SE

TL;DR: KD在代码理解任务中有效提升学生模型性能，特征基于方法最优，代码专用PLM教师效果更好，架构相似性非关键。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型（PLMs）在代码理解中表现优异，但计算密集和推理延迟限制了其大规模应用。KD作为一种模型压缩技术，有望解决这些问题，但其在代码理解任务中的潜力尚未充分探索。

Method: 本研究系统评估了两种KD方法（基于logit和基于特征）在三种下游任务中的效果，涉及八种学生模型和两种教师PLM。

Result: 实验结果表明，KD在所有学生模型上均带来显著性能提升，其中特征基于的KD方法表现最佳。代码专用PLM作为教师模型效果更优，且学生架构与教师相似性并非性能关键。

Conclusion: 知识蒸馏（KD）在代码理解任务中表现出显著效果，尤其是特征基于的KD方法，使学生模型在仅保留5%参数的情况下达到教师模型98%的性能。未来研究方向包括进一步优化KD方法和探索更多学生架构。

Abstract: Pre-trained language models (PLMs) have emerged as powerful tools for code
understanding. However, deploying these PLMs in large-scale applications faces
practical challenges due to their computational intensity and inference
latency. Knowledge distillation (KD), a promising model compression and
acceleration technique, addresses these limitations by transferring knowledge
from large teacher models to compact student models, enabling efficient
inference while preserving most of the teacher models' capabilities. While this
technique has shown remarkable success in natural language processing and
computer vision domains, its potential for code understanding tasks remains
largely underexplored.
  In this paper, we systematically investigate the effectiveness and usage of
KD in code understanding tasks. Our study encompasses two popular types of KD
methods, i.e., logit-based and feature-based KD methods, experimenting across
eight student models and two teacher PLMs from different domains on three
downstream tasks. The experimental results indicate that KD consistently offers
notable performance boosts across student models with different sizes compared
with standard fine-tuning. Notably, code-specific PLM demonstrates better
effectiveness as the teacher model. Among all KD methods, the latest
feature-based KD methods exhibit superior performance, enabling student models
to retain up to 98% teacher performance with merely 5% parameters. Regarding
student architecture, our experiments reveal that similarity with teacher
architecture does not necessarily lead to better performance. We further
discuss the efficiency and behaviors in the KD process and inference, summarize
the implications of findings, and identify promising future directions.

</details>


### [122] [SynthCoder: A Synthetical Strategy to Tune LLMs for Code Completion](https://arxiv.org/abs/2508.15495)
*Dongjun Yu,Xiao Yan,Zhenrui Li,Jipeng Xiao,Haochuan He,Yongda Yu,Hao Zhang,Guoping Rong,Xiaobo Huang*

Main category: cs.SE

TL;DR: SynthCoder通过多样化数据集构建、两阶段训练和偏好优化，在代码补全任务中实现SOTA性能，解决了现有模型的性能权衡和代码重复问题。


<details>
  <summary>Details</summary>
Motivation: 当前代码补全任务中，小型到中型参数的基础模型通常需要各种优化和后训练技术，但这些方法往往存在权衡，导致在某些数据集或指标上性能提升的同时，其他方面性能下降。

Method: 1. 通过结合抽象语法树（AST）节点提取和模拟开发者行为的启发式方法构建多样化数据集；2. 使用BM25算法和调用图丰富训练语料库，增强模型在文件级和仓库级场景中的代码补全能力；3. 采用两阶段训练过程，包括使用课程学习技术进行微调，以及通过拒绝采样生成的偏好对进行直接偏好优化（DPO）对齐。

Result: 实验结果表明，最终模型在主流仓库级代码补全基准测试（如aiXcoder、ExecRepoBench、CrossCodeEval和CoLT）中表现出色，并且精心策划的训练集有效缓解了模型重复现有代码的倾向。

Conclusion: SynthCoder模型通过整合行业领先实践，在Fill-in-the-Middle（FIM）代码补全任务中实现了最先进的性能，并在主流仓库级代码补全基准测试中表现出色。

Abstract: Code completion is a prominent application of Large Language Models (LLMs) in
software engineering. Due to the near real-time response requirements of this
task, base models with small to medium-sized parameters are typically employed,
supplemented by various optimization and post-training techniques. However,
these optimization methods often have trade-offs, leading to a seesaw effect
where performance improvements on certain datasets or metrics are accompanied
by degradations on others -- sometimes even falling below the baseline model's
performance. This paper proposes SynthCoder, a model that integrates leading
industry practices to achieve state-of-the-art performance on the
Fill-in-the-Middle (FIM) code completion task. In specific, we first construct
a diverse dataset by combining Abstract Syntax Tree (AST) node extraction with
heuristics that simulate developer behavior. Then we enrich our training corpus
with cross-file contextual information using the BM25 algorithm and call
graphs, enhancing the model's ability to perform code completion in both
file-level and repository-level scenarios. As the last step, we employ a
two-stage training process using the Seed-Coder-8B-Base as the base model.
First, we fine-tune the model using Curriculum Learning technology. Following
this, we perform alignment using Direct Preference Optimization (DPO) with
preference pairs generated through Rejection Sampling. Experimental results
demonstrate that our final model excels on mainstream repository-level code
completion benchmarks, including aiXcoder, ExecRepoBench, CrossCodeEval, and
CoLT. Furthermore, our carefully curated training set effectively mitigates the
model's tendency to just repeat existing code, a common issue existing in
various code completion models.

</details>


### [123] [Towards the Assessment of Task-based Chatbots: From the TOFU-R Snapshot to the BRASATO Curated Dataset](https://arxiv.org/abs/2508.15496)
*Elena Masserini,Diego Clerissi,Daniela Micucci,João R. Campos,Leonardo Mariani*

Main category: cs.SE

TL;DR: 本文提出两个数据集和工具，解决任务型聊天机器人评估中数据不足的问题，促进可靠性研究。


<details>
  <summary>Details</summary>
Motivation: 任务型聊天机器人的可靠性、安全性和鲁棒性评估因缺乏大规模高质量数据集而受限，现有评估技术常依赖有限或过时的样本。

Method: 通过收集GitHub上的Rasa聊天机器人构建TOFU-R数据集，并基于对话复杂性、功能复杂性和实用性筛选出BRASATO数据集，同时提供工具支持。

Result: 创建了两个数据集（TOFU-R和BRASATO）及配套工具，为聊天机器人评估提供了高质量资源。

Conclusion: 本文提出了两个数据集（TOFU-R和BRASATO）及相关工具，旨在解决任务型聊天机器人评估中缺乏大规模高质量数据集的问题，促进聊天机器人可靠性的研究。

Abstract: Task-based chatbots are increasingly being used to deliver real services, yet
assessing their reliability, security, and robustness remains underexplored,
also due to the lack of large-scale, high-quality datasets. The emerging
automated quality assessment techniques targeting chatbots often rely on
limited pools of subjects, such as custom-made toy examples, or outdated, no
longer available, or scarcely popular agents, complicating the evaluation of
such techniques. In this paper, we present two datasets and the tool support
necessary to create and maintain these datasets. The first dataset is RASA
TASK-BASED CHATBOTS FROM GITHUB (TOFU-R), which is a snapshot of the Rasa
chatbots available on GitHub, representing the state of the practice in
open-source chatbot development with Rasa. The second dataset is BOT RASA
COLLECTION (BRASATO), a curated selection of the most relevant chatbots for
dialogue complexity, functional complexity, and utility, whose goal is to ease
reproducibility and facilitate research on chatbot reliability.

</details>


### [124] [Evaluation Guidelines for Empirical Studies in Software Engineering involving LLMs](https://arxiv.org/abs/2508.15503)
*Sebastian Baltes,Florian Angermeir,Chetan Arora,Marvin Muñoz Barón,Chunyang Chen,Lukas Böhme,Fabio Calefato,Neil Ernst,Davide Falessi,Brian Fitzgerald,Davide Fucci,Marcos Kalinowski,Stefano Lambiase,Daniel Russo,Mircea Lungu,Lutz Prechelt,Paul Ralph,Christoph Treude,Stefan Wagner*

Main category: cs.SE

TL;DR: 本文为涉及LLM的实证研究提供了八项透明度和可重复性指南，以应对LLM特有挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程研究和实践中的应用日益增多，但其不确定性、不透明的训练数据和不断演变的架构使得实证研究的重复和复制变得复杂。

Method: 通过社区努力，引入LLM研究的分类法，并制定设计及报告实证研究的八项指南。

Result: 提出了八项指南，包括声明LLM使用、报告模型版本和配置、记录工具架构等，以促进研究的透明度和可重复性。

Conclusion: 本文提出了八项指南，旨在提高涉及大型语言模型（LLM）的实证研究的透明度和可重复性，以克服LLM特有的开放科学障碍。

Abstract: Large language models (LLMs) are increasingly being integrated into software
engineering (SE) research and practice, yet their non-determinism, opaque
training data, and evolving architectures complicate the reproduction and
replication of empirical studies. We present a community effort to scope this
space, introducing a taxonomy of LLM-based study types together with eight
guidelines for designing and reporting empirical studies involving LLMs. The
guidelines present essential (must) criteria as well as desired (should)
criteria and target transparency throughout the research process. Our
recommendations, contextualized by our study types, are: (1) to declare LLM
usage and role; (2) to report model versions, configurations, and fine-tuning;
(3) to document tool architectures; (4) to disclose prompts and interaction
logs; (5) to use human validation; (6) to employ an open LLM as a baseline; (7)
to report suitable baselines, benchmarks, and metrics; and (8) to openly
articulate limitations and mitigations. Our goal is to enable reproducibility
and replicability despite LLM-specific barriers to open science. We maintain
the study types and guidelines online as a living resource for the community to
use and shape (llm-guidelines.org).

</details>


### [125] [QUPER-MAn: Benchmark-Guided Target Setting for Maintainability Requirements](https://arxiv.org/abs/2508.15512)
*Markus Borg,Martin Larsson,Philip Breid,Nadim Hagatulah*

Main category: cs.SE

TL;DR: 本文提出QUPER-MAn模型，旨在通过需求工程提升软件可维护性，研究发现当前行业实践中可维护性仍被忽视。


<details>
  <summary>Details</summary>
Motivation: 可维护性在软件开发中常被忽视，需求工程可以通过促进讨论和负责任地设定目标来弥补这一差距。

Method: 采用设计科学方法开发了QUPER-MAn模型，该模型整合了可维护性基准并支持目标设定。

Result: 研究发现，可维护性仍然是次要的质量关注点，现有工具通常仅用于与工程实践相关的隐含需求。

Conclusion: QUPER-MAn模型有望将可维护性从被忽视的开发后果转变为由知情和负责任的工程决策驱动的积极管理目标。

Abstract: Maintainable source code is essential for sustainable development in any
software organization. Unfortunately, many studies show that maintainability
often receives less attention than its importance warrants. We argue that
requirements engineering can address this gap the problem by fostering
discussions and setting appropriate targets in a responsible manner. In this
preliminary work, we conducted an exploratory study of industry practices
related to requirements engineering for maintainability. Our findings confirm
previous studies: maintainability remains a second-class quality concern.
Explicit requirements often make sweeping references to coding conventions.
Tools providing maintainability proxies are common but typically only used in
implicit requirements related to engineering practices. To address this, we
propose QUPER-MAn, a maintainability adaption of the QUPER model, which was
originally developed to help organizations set targets for performance
requirements. Developed using a design science approach, QUPER-MAn, integrates
maintainability benchmarks and supports target setting. We posit that it can
shift maintainability from an overlooked development consequence to an actively
managed goal driven by informed and responsible engineering decisions.

</details>


### [126] [A Novel Mutation Based Method for Detecting FPGA Logic Synthesis Tool Bugs](https://arxiv.org/abs/2508.15536)
*Yi Zhang,He Jiang,Xiaochen Li,Shikai Guo,Peiyu Zou,Zun Wang*

Main category: cs.SE

TL;DR: VERMEI是一种新的FPGA逻辑综合工具测试方法，通过预处理、等效变异和错误识别模块，提高了测试的复杂性，成功识别并报告了多个新错误。


<details>
  <summary>Details</summary>
Motivation: FPGA逻辑综合工具中的缺陷可能导致意外行为和安全风险，现有测试方法在测试程序的语义和逻辑复杂性方面不足，因此需要一种更有效的方法来加强这些工具的测试。

Method: VERMEI包含三个模块：预处理模块通过模拟和覆盖率分析识别种子程序中的僵尸逻辑；等效变异模块通过贝叶斯采样从历史Verilog设计中提取逻辑片段，生成具有复杂控制流和结构的等效变异程序；错误识别模块基于差分测试比较种子和变异程序的综合输出以识别错误。

Result: 在Yosys、Vivado和Quartus上的实验表明，VERMEI优于现有方法，在五个月内报告了15个错误，其中9个被确认为新错误。

Conclusion: VERMEI是一种有效的方法，用于测试FPGA逻辑综合工具，通过其三个模块（预处理、等效变异和错误识别）显著提高了测试的语义和逻辑复杂性，成功识别并报告了多个新错误。

Abstract: FPGA (Field-Programmable Gate Array) logic synthesis tools are key components
in the EDA (Electronic Design Automation) toolchain. They convert hardware
designs written in description languages such as Verilog into gate-level
representations for FPGAs. However, defects in these tools may lead to
unexpected behaviors and pose security risks. Therefore, it is crucial to
harden these tools through testing. Although several methods have been proposed
to automatically test FPGA logic synthesis tools, the challenge remains of
insufficient semantic and logical complexity in test programs. In this paper,
we propose VERMEI, a new method for testing FPGA logic synthesis tools. VERMEI
consists of three modules: preprocessing, equivalent mutation, and bug
identification. The preprocessing module identifies zombie logic (inactive code
with no impact on the circuit output) in seed programs through simulation and
coverage analysis. The equivalent mutation module generates equivalent variants
of seed programs by pruning or inserting logic fragments in zombie areas. It
uses Bayesian sampling to extract logic fragments from historical Verilog
designs, making the generated variants have complex control flows and
structures. The bug identification module, based on differential testing,
compares the synthesized outputs of seed and variant programs to identify bugs.
Experiments on Yosys, Vivado, and Quartus demonstrate that VERMEI outperforms
the state-of-the-art methods. Within five months, VERMEI reported 15 bugs to
vendors, 9 of which were confirmed as new.

</details>


### [127] [Establishing Technical Debt Management -- A Five-Step Workshop Approach and an Action Research Study](https://arxiv.org/abs/2508.15570)
*Marion Wiese,Kamila Serwa,Anastasia Besier,Ariane S. Marion-Jetten,Eva Bittner*

Main category: cs.SE

TL;DR: 本研究通过行动研究法在IT团队中实施技术债务管理（TDM）流程，发现研讨会方法可行且能带来可持续变革。实践者偏好基于成本和系统演进的TD偿还，待办事项中的提醒能有效提升TD意识。


<details>
  <summary>Details</summary>
Motivation: 技术债务（TD）管理（TDM）在研究中频繁探讨，但在实践中很少被采用。本研究旨在基于预定义的研讨会概念，在IT公司中建立TDM流程，并分析实践者在每个TD活动中采用的研究方法以及TDM对技术债务意识的长期影响。

Method: 采用行动研究法（16个月内进行五个行动周期），与一个开发信号处理IT解决方案的IT团队合作。通过（1）分析每次研讨会完成的问卷，（2）观察团队会议，（3）采用心理学中的TD-SAGAT方法测量决策情境中的意识，（4）评估待办事项数据，来检验技术债务意识。

Result: 实践者倾向于基于系统演进和成本计算的TD偿还和优先级排序，即偿还所谓的'低垂果实'。待办事项中的提醒（如复选框或文本模板）可持续提升TD意识。

Conclusion: 研究表明，基于研讨会的方法是可行的，并能带来可持续的流程变革。适用于其他IT团队的新技术债务管理（TDM）思路应运而生，例如使用重新提交日期、'已讨论技术债务'复选框以及技术债务优先级的可视化。

Abstract: Context. Technical debt (TD) items are constructs in a software system
providing short-term benefits but hindering future changes. TD management (TDM)
is frequently researched but rarely adopted in practice. Goal. This study aimed
to establish a TDM process in an IT company based on a predefined workshop
concept. We analyzed which research approaches practitioners adopted for each
TD activity and the TDM's long-term effect on TD awareness. Method. We used
action research (five action cycles in 16 months) with an IT team that creates
IT solutions for signal processing. To examine TD awareness, we (1) analyzed
questionnaires completed during each workshop, (2) observed team meetings, (3)
adopted a method from psychology for measuring awareness in decision-making
situations called TD-SAGAT, and (4) evaluated the backlog data. Results.
Practitioners preferred TD repayment and prioritization based on the system's
evolution and cost calculations, i.e., repayment of so-called low-hanging
fruits. Reminders in the backlog items, such as checkboxes or text templates,
led to a sustainable rise in TD awareness. Conclusions. We showed that a
workshop-based approach is feasible and leads to sustainable process changes.
New ideas for TDM applicable to other IT teams emerged, e.g., using a
re-submission date, using a Talked about TD checkbox, and using visualizations
for TD prioritization.

</details>


### [128] [From PREVENTion to REACTion: Enhancing Failure Resolution in Naval Systems](https://arxiv.org/abs/2508.15584)
*Maria Teresa Rossi,Leonardo Mariani,Oliviero Riganelli*

Main category: cs.SE

TL;DR: 本文介绍了PREVENT和REACT方法在海军系统中的应用，展示了异常检测与故障排除的集成，并分享了可推广的工业经验。


<details>
  <summary>Details</summary>
Motivation: 复杂大型工业系统常因磨损、误用或故障而表现异常，及时检测、定位问题源并实施适当对策至关重要。

Method: 本文报告了使用最先进的故障预测方法PREVENT及其扩展故障排除模块REACT在Fincantieri开发的海军系统中的实践经验。

Result: 结果表明，如何将异常检测与故障排除程序有效集成。

Conclusion: 本文讨论了如何将异常检测与故障排除程序集成，并分享了部署和扩展这些分析到其他工业产品的经验教训。

Abstract: Complex and large industrial systems often misbehave, for instance, due to
wear, misuse, or faults. To cope with these incidents, it is important to
timely detect their occurrences, localize the sources of the problems, and
implement the appropriate countermeasures. This paper reports our experience
with a state-of-the-art failure prediction method, PREVENT, and its extension
with a troubleshooting module, REACT, applied to naval systems developed by
Fincantieri. Our results show how to integrate anomaly detection with
troubleshooting procedures. We conclude by discussing a lesson learned, which
may help deploy and extend these analyses to other industrial products.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [129] [Mitigating context switching in densely packed Linux clusters with Latency-Aware Group Scheduling](https://arxiv.org/abs/2508.15703)
*Al Amjad Tawfiq Isstaif,Evangelia Kalyvianaki,Richard Mortier*

Main category: cs.OS

TL;DR: 论文通过修改Linux内核调度器，减少上下文切换开销，实现在更小集群规模下保持性能。


<details>
  <summary>Details</summary>
Motivation: 在密集打包的工作负载（如无服务器应用）中，CPU上下文切换开销会导致节点性能严重下降，即使编排器放置理论上合理。

Method: 提出并评估了对标准Linux内核调度器的修改，以减少上下文切换的开销。

Result: 实现了在减少28%集群规模的情况下保持相同性能的效果。

Conclusion: 通过修改标准Linux内核调度器，优先考虑任务完成而非低级别的每任务公平性，可以在减少28%集群规模的情况下实现相同的性能效果。

Abstract: Cluster orchestrators such as Kubernetes depend on accurate estimates of node
capacity and job requirements. Inaccuracies in either lead to poor placement
decisions and degraded cluster performance. In this paper, we show that in
densely packed workloads, such as serverless applications, CPU context
switching overheads can become so significant that a node's performance is
severely degraded, even when the orchestrator placement is theoretically sound.
In practice this issue is typically mitigated by over-provisioning the cluster,
leading to wasted resources.
  We show that these context switching overhead arise from both an increase in
the average cost of an individual context switch and a higher rate of context
switching, which together amplify overhead multiplicatively when managing large
numbers of concurrent cgroups, Linux's group scheduling mechanism for managing
multi-threaded colocated workloads. We propose and evaluate modifications to
the standard Linux kernel scheduler that mitigate these effects, achieving the
same effective performance with a 28% smaller cluster size. The key insight
behind our approach is to prioritise task completion over low-level per-task
fairness, enabling the scheduler to drain contended CPU run queues more rapidly
and thereby reduce time spent on context switching.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [130] [A Vision-Based Shared-Control Teleoperation Scheme for Controlling the Robotic Arm of a Four-Legged Robot](https://arxiv.org/abs/2508.14994)
*Murilo Vinicius da Silva,Matheus Hipolito Carvalho,Juliano Negri,Thiago Segreto,Gustavo J. G. Lahr,Ricardo V. Godoy,Marcelo Becker*

Main category: cs.RO

TL;DR: 提出一种基于视觉姿态估计的直观遥操作方法，通过手腕动作映射控制四足机器人机械臂，结合轨迹规划确保安全，适用于高风险工业环境。


<details>
  <summary>Details</summary>
Motivation: 在危险和远程环境中，四足机器人机械臂的遥操作面临障碍物检测不足和控制方法不直观的挑战，导致碰撞风险高且操作复杂。

Method: 利用基于外部摄像头和机器学习模型的视觉姿态估计管道，检测操作者手腕位置，并将其映射为机械臂的实时控制命令，结合轨迹规划器避免碰撞。

Result: 系统在真实机器人上验证，展示了实时控制的鲁棒性能，为工业应用提供了安全、精确且易用的解决方案。

Conclusion: 该研究提出了一种直观的远程控制方法，通过视觉姿态估计和轨迹规划，实现了四足机器人机械臂的安全、精确和易用控制，适用于高风险工业环境。

Abstract: In hazardous and remote environments, robotic systems perform critical tasks
demanding improved safety and efficiency. Among these, quadruped robots with
manipulator arms offer mobility and versatility for complex operations.
However, teleoperating quadruped robots is challenging due to the lack of
integrated obstacle detection and intuitive control methods for the robotic
arm, increasing collision risks in confined or dynamically changing workspaces.
Teleoperation via joysticks or pads can be non-intuitive and demands a high
level of expertise due to its complexity, culminating in a high cognitive load
on the operator. To address this challenge, a teleoperation approach that
directly maps human arm movements to the robotic manipulator offers a simpler
and more accessible solution. This work proposes an intuitive remote control by
leveraging a vision-based pose estimation pipeline that utilizes an external
camera with a machine learning-based model to detect the operator's wrist
position. The system maps these wrist movements into robotic arm commands to
control the robot's arm in real-time. A trajectory planner ensures safe
teleoperation by detecting and preventing collisions with both obstacles and
the robotic arm itself. The system was validated on the real robot,
demonstrating robust performance in real-time control. This teleoperation
approach provides a cost-effective solution for industrial applications where
safety, precision, and ease of use are paramount, ensuring reliable and
intuitive robotic control in high-risk environments.

</details>


### [131] [GraspQP: Differentiable Optimization of Force Closure for Diverse and Robust Dexterous Grasping](https://arxiv.org/abs/2508.15002)
*René Zurbrügg,Andrei Cramariuc,Marco Hutter*

Main category: cs.RO

TL;DR: 提出一种合成多样化物理可行抓取的方法，通过QP和MALA*优化提升性能，并发布DexGraspNet数据集。


<details>
  <summary>Details</summary>
Motivation: 现有抓取数据集生成方法通常依赖采样算法或简化的力闭合分析，导致抓取类型有限且多为强力抓取，无法满足多样化需求。

Method: 通过引入严格的、可微分的力闭合能量公式（基于二次规划QP）和调整的优化方法（MALA*），动态拒绝梯度步骤以提升性能。

Result: 实验证明该方法在抓取多样性和最终抓取预测稳定性方面有显著提升，并生成了包含5,700个对象、五种夹持器和三种抓取类型的大规模数据集。

Conclusion: 本研究提出了一种合成大规模、多样化且物理可行的抓取方法，显著提升了抓取多样性和稳定性，并提供了一个新的大规模抓取数据集DexGraspNet。

Abstract: Dexterous robotic hands enable versatile interactions due to the flexibility
and adaptability of multi-fingered designs, allowing for a wide range of
task-specific grasp configurations in diverse environments. However, to fully
exploit the capabilities of dexterous hands, access to diverse and high-quality
grasp data is essential -- whether for developing grasp prediction models from
point clouds, training manipulation policies, or supporting high-level task
planning with broader action options. Existing approaches for dataset
generation typically rely on sampling-based algorithms or simplified
force-closure analysis, which tend to converge to power grasps and often
exhibit limited diversity. In this work, we propose a method to synthesize
large-scale, diverse, and physically feasible grasps that extend beyond simple
power grasps to include refined manipulations, such as pinches and tri-finger
precision grasps. We introduce a rigorous, differentiable energy formulation of
force closure, implicitly defined through a Quadratic Program (QP).
Additionally, we present an adjusted optimization method (MALA*) that improves
performance by dynamically rejecting gradient steps based on the distribution
of energy values across all samples. We extensively evaluate our approach and
demonstrate significant improvements in both grasp diversity and the stability
of final grasp predictions. Finally, we provide a new, large-scale grasp
dataset for 5,700 objects from DexGraspNet, comprising five different grippers
and three distinct grasp types.
  Dataset and Code:https://graspqp.github.io/

</details>


### [132] [In-Context Iterative Policy Improvement for Dynamic Manipulation](https://arxiv.org/abs/2508.15021)
*Mark Van der Merwe,Devesh Jha*

Main category: cs.RO

TL;DR: 本文研究了基于预训练语言模型的上下文学习在动态操作中的应用，提出了一种迭代方法，并在低数据量情况下验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 研究基于预训练语言模型的上下文学习在动态操作中的应用，解决高维度、复杂动力学和部分可观测性等挑战。

Method: 采用迭代方法，将上下文学习问题表述为基于先前交互的预测参数策略调整。

Result: 实验表明，上下文学习方法在低数据量情况下表现优于其他方法。

Conclusion: 在模拟和物理机器人实验中，利用上下文学习的方法在低数据量情况下优于其他方法。

Abstract: Attention-based architectures trained on internet-scale language data have
demonstrated state of the art reasoning ability for various language-based
tasks, such as logic problems and textual reasoning. Additionally, these Large
Language Models (LLMs) have exhibited the ability to perform few-shot
prediction via in-context learning, in which input-output examples provided in
the prompt are generalized to new inputs. This ability furthermore extends
beyond standard language tasks, enabling few-shot learning for general
patterns. In this work, we consider the application of in-context learning with
pre-trained language models for dynamic manipulation. Dynamic manipulation
introduces several crucial challenges, including increased dimensionality,
complex dynamics, and partial observability. To address this, we take an
iterative approach, and formulate our in-context learning problem to predict
adjustments to a parametric policy based on previous interactions. We show
across several tasks in simulation and on a physical robot that utilizing
in-context learning outperforms alternative methods in the low data regime.
Video summary of this work and experiments can be found
https://youtu.be/2inxpdrq74U?si=dAdDYsUEr25nZvRn.

</details>


### [133] [Decentralized Vision-Based Autonomous Aerial Wildlife Monitoring](https://arxiv.org/abs/2508.15038)
*Makram Chahine,William Yang,Alaa Maalouf,Justin Siriska,Ninad Jadhav,Daniel Vogt,Stephanie Gil,Robert Wood,Daniela Rus*

Main category: cs.RO

TL;DR: 提出了一种分散式多旋翼系统，用于野生动物监测，具有可扩展性和低带宽需求，实验验证了其可靠性。


<details>
  <summary>Details</summary>
Motivation: 野生动物野外操作需要高效的并行部署方法来识别和交互特定个体，同时进行集体行为分析及健康与安全干预。现有机器人解决方案要么从群体角度出发，要么是手动操作且规模有限。

Method: 开发了新颖的基于视觉的协调和跟踪算法，适用于动态、非结构化环境，无需依赖集中式通信或控制。

Result: 通过实际野外实验验证了系统在多样化环境中的可靠部署。

Conclusion: 该论文提出了一种基于视觉的分散式多旋翼系统，用于野生动物监测，该系统具有可扩展性、低带宽需求和最小化传感器配置（单机载RGB摄像头），在实际野外实验中验证了其可靠性。

Abstract: Wildlife field operations demand efficient parallel deployment methods to
identify and interact with specific individuals, enabling simultaneous
collective behavioral analysis, and health and safety interventions. Previous
robotics solutions approach the problem from the herd perspective, or are
manually operated and limited in scale. We propose a decentralized vision-based
multi-quadrotor system for wildlife monitoring that is scalable, low-bandwidth,
and sensor-minimal (single onboard RGB camera). Our approach enables robust
identification and tracking of large species in their natural habitat. We
develop novel vision-based coordination and tracking algorithms designed for
dynamic, unstructured environments without reliance on centralized
communication or control. We validate our system through real-world
experiments, demonstrating reliable deployment in diverse field conditions.

</details>


### [134] [Neural Robot Dynamics](https://arxiv.org/abs/2508.15755)
*Jie Xu,Eric Heiden,Iretiayo Akinola,Dieter Fox,Miles Macklin,Yashraj Narang*

Main category: cs.RO

TL;DR: NeRD是一种通用的神经机器人动力学模拟器，能够高效预测关节刚体的动态行为，并泛化到新任务和环境，还能通过真实数据微调。


<details>
  <summary>Details</summary>
Motivation: 现代机器人具有高自由度和复杂机制，传统分析模拟器难以高效模拟其动态行为。现有神经模拟器通常需要特定应用训练，且因全局状态表示不足而难以泛化到新任务或环境。

Method: 提出NeRD模型，替代传统分析模拟器中的低层动力学和接触求解器，采用机器人中心且空间不变的模拟状态表示。

Result: 实验表明，NeRD模拟器在数千次模拟步骤中保持稳定和准确；能够跨任务和环境配置泛化；支持在神经引擎中学习策略；并能通过真实数据微调。

Conclusion: NeRD（Neural Robot Dynamics）作为神经模拟器，能够稳定、准确地预测关节刚体在接触约束下的未来状态，并在任务和环境配置中展现出良好的泛化能力。此外，NeRD能够通过真实世界数据进行微调，缩小模拟与现实的差距。

Abstract: Accurate and efficient simulation of modern robots remains challenging due to
their high degrees of freedom and intricate mechanisms. Neural simulators have
emerged as a promising alternative to traditional analytical simulators,
capable of efficiently predicting complex dynamics and adapting to real-world
data; however, existing neural simulators typically require
application-specific training and fail to generalize to novel tasks and/or
environments, primarily due to inadequate representations of the global state.
In this work, we address the problem of learning generalizable neural
simulators for robots that are structured as articulated rigid bodies. We
propose NeRD (Neural Robot Dynamics), learned robot-specific dynamics models
for predicting future states for articulated rigid bodies under contact
constraints. NeRD uniquely replaces the low-level dynamics and contact solvers
in an analytical simulator and employs a robot-centric and spatially-invariant
simulation state representation. We integrate the learned NeRD models as an
interchangeable backend solver within a state-of-the-art robotics simulator. We
conduct extensive experiments to show that the NeRD simulators are stable and
accurate over a thousand simulation steps; generalize across tasks and
environment configurations; enable policy learning exclusively in a neural
engine; and, unlike most classical simulators, can be fine-tuned from
real-world data to bridge the gap between simulation and reality.

</details>


### [135] [Hardware Implementation of a Zero-Prior-Knowledge Approach to Lifelong Learning in Kinematic Control of Tendon-Driven Quadrupeds](https://arxiv.org/abs/2508.15160)
*Hesam Azadjou,Suraj Chakravarthi Raja,Ali Marjaninejad,Francisco J. Valero-Cuevas*

Main category: cs.RO

TL;DR: G2P算法让肌腱驱动四足机器人在几分钟内学会适应性运动控制，模仿哺乳动物的探索-利用学习模式。


<details>
  <summary>Details</summary>
Motivation: 机器人需在不完全了解自身结构和环境的情况下快速学习和适应，类似于哺乳动物的学习过程。

Method: 采用生物启发的G2P学习算法，分为5分钟的广义运动探索和15次每次20秒的细化训练，逐步优化控制策略。

Result: 系统在几分钟内学会了控制冗余肌腱驱动四足机器人，实现了功能性和自适应的周期性非凸运动。

Conclusion: 该研究通过G2P算法成功实现了肌腱驱动四足机器人的快速学习和适应性控制，为机器人在动态环境中的自主运动控制提供了新思路。

Abstract: Like mammals, robots must rapidly learn to control their bodies and interact
with their environment despite incomplete knowledge of their body structure and
surroundings. They must also adapt to continuous changes in both. This work
presents a bio-inspired learning algorithm, General-to-Particular (G2P),
applied to a tendon-driven quadruped robotic system developed and fabricated
in-house. Our quadruped robot undergoes an initial five-minute phase of
generalized motor babbling, followed by 15 refinement trials (each lasting 20
seconds) to achieve specific cyclical movements. This process mirrors the
exploration-exploitation paradigm observed in mammals. With each refinement,
the robot progressively improves upon its initial "good enough" solution. Our
results serve as a proof-of-concept, demonstrating the hardware-in-the-loop
system's ability to learn the control of a tendon-driven quadruped with
redundancies in just a few minutes to achieve functional and adaptive cyclical
non-convex movements. By advancing autonomous control in robotic locomotion,
our approach paves the way for robots capable of dynamically adjusting to new
environments, ensuring sustained adaptability and performance.

</details>


### [136] [Survey of Vision-Language-Action Models for Embodied Manipulation](https://arxiv.org/abs/2508.15201)
*Haoran Li,Yuhui Chen,Wenbo Cui,Weiheng Liu,Kai Liu,Mingcai Zhou,Zhengtao Zhang,Dongbin Zhao*

Main category: cs.RO

TL;DR: 本文综述了VLA模型在具身智能中的应用，分析了其架构、训练方法及评估，总结了挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨VLA模型如何通过增强智能体与环境交互能力，推动具身智能系统的发展，并扩展其应用场景。

Method: 通过全面回顾VLA模型的架构发展、训练数据集、预训练与后训练方法及模型评估，详细分析了当前研究的五个关键维度。

Result: VLA模型作为通用机器人控制框架，显著提升了具身智能系统的交互能力，并拓宽了应用范围。

Conclusion: 本文总结了VLA模型在具身智能系统中的关键挑战和未来研究方向，强调了其在扩展应用场景中的潜力。

Abstract: Embodied intelligence systems, which enhance agent capabilities through
continuous environment interactions, have garnered significant attention from
both academia and industry. Vision-Language-Action models, inspired by
advancements in large foundation models, serve as universal robotic control
frameworks that substantially improve agent-environment interaction
capabilities in embodied intelligence systems. This expansion has broadened
application scenarios for embodied AI robots. This survey comprehensively
reviews VLA models for embodied manipulation. Firstly, it chronicles the
developmental trajectory of VLA architectures. Subsequently, we conduct a
detailed analysis of current research across 5 critical dimensions: VLA model
structures, training datasets, pre-training methods, post-training methods, and
model evaluation. Finally, we synthesize key challenges in VLA development and
real-world deployment, while outlining promising future research directions.

</details>


### [137] [Mag-Match: Magnetic Vector Field Features for Map Matching and Registration](https://arxiv.org/abs/2508.15300)
*William McDonald,Cedric Le Gentil,Jennifer Wakulicz,Teresa Vidal-Calleja*

Main category: cs.RO

TL;DR: Mag-Match利用磁场高阶导数特征实现无需重力对齐的地图匹配，适用于恶劣环境。


<details>
  <summary>Details</summary>
Motivation: 传统依赖摄像头或LiDAR的方法在恶劣环境下表现不佳，而磁力计能捕捉其他传感器无法检测的特征，且在此类环境中仍保持稳定。

Method: 基于物理信息的高斯过程进行磁场的递归概率推断，提取高阶导数作为特征描述符。

Result: 在仿真和真实实验中，Mag-Match相比基于SIFT的方法表现出更高的准确性，支持地图间、机器人间及机器人与地图间的精确转换。

Conclusion: Mag-Match提供了一种在恶劣环境下（如烟雾或灰尘）仍能可靠工作的地图匹配和注册方法，通过利用磁场的物理特性实现了无需重力对齐的高效匹配。

Abstract: Map matching and registration are essential tasks in robotics for
localisation and integration of multi-session or multi-robot data. Traditional
methods rely on cameras or LiDARs to capture visual or geometric information
but struggle in challenging conditions like smoke or dust. Magnetometers, on
the other hand, detect magnetic fields, revealing features invisible to other
sensors and remaining robust in such environments. In this paper, we introduce
Mag-Match, a novel method for extracting and describing features in 3D magnetic
vector field maps to register different maps of the same area. Our feature
descriptor, based on higher-order derivatives of magnetic field maps, is
invariant to global orientation, eliminating the need for gravity-aligned
mapping. To obtain these higher-order derivatives map-wide given point-wise
magnetometer data, we leverage a physics-informed Gaussian Process to perform
efficient and recursive probabilistic inference of both the magnetic field and
its derivatives. We evaluate Mag-Match in simulated and real-world experiments
against a SIFT-based approach, demonstrating accurate map-to-map, robot-to-map,
and robot-to-robot transformations - even without initial gravitational
alignment.

</details>


### [138] [Sensing, Social, and Motion Intelligence in Embodied Navigation: A Comprehensive Survey](https://arxiv.org/abs/2508.15354)
*Chaoran Xiong,Yulong Huang,Fangwen Yu,Changhao Chen,Yue Wang,Songpengchen Xia,Ling Pei*

Main category: cs.RO

TL;DR: 该调查提出了TOFRA框架，总结了EN的研究现状，并指出了未来挑战。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖显式定位和预定义地图，而EN通过自我中心感知和类人交互策略，实现了更复杂的任务。

Method: 通过五个阶段（Transition, Observation, Fusion, Reward-policy construction, Action）的TOFRA框架，对现有研究进行了综合分析和批判性评估。

Result: 提出了一个全面的EN框架，并评估了相关平台和指标，同时明确了未来研究方向。

Conclusion: 该调查提出了TOFRA框架，总结了当前研究现状，并指出了关键的开放研究挑战。

Abstract: Embodied navigation (EN) advances traditional navigation by enabling robots
to perform complex egocentric tasks through sensing, social, and motion
intelligence. In contrast to classic methodologies that rely on explicit
localization and pre-defined maps, EN leverages egocentric perception and
human-like interaction strategies. This survey introduces a comprehensive EN
formulation structured into five stages: Transition, Observation, Fusion,
Reward-policy construction, and Action (TOFRA). The TOFRA framework serves to
synthesize the current state of the art, provide a critical review of relevant
platforms and evaluation metrics, and identify critical open research
challenges. A list of studies is available at
https://github.com/Franky-X/Awesome-Embodied-Navigation.

</details>


### [139] [Lang2Lift: A Framework for Language-Guided Pallet Detection and Pose Estimation Integrated in Autonomous Outdoor Forklift Operation](https://arxiv.org/abs/2508.15427)
*Huy Hoang Nguyen,Johannes Huemer,Markus Murschitz,Tobias Glueck,Minh Nhat Vu,Andreas Kugi*

Main category: cs.RO

TL;DR: Lang2Lift利用基础模型实现自然语言引导的托盘检测和姿态估计，解决了户外复杂环境中的自动化托盘搬运问题，验证了其可行性和效率。


<details>
  <summary>Details</summary>
Motivation: 劳动力短缺、安全问题和手动托盘搬运的低效是研究的动机，尤其是在户外环境中托盘质量、尺寸不一致且环境非结构化的挑战。

Method: Lang2Lift整合了Florence-2和SAM-2进行语言引导的分割，以及FoundationPose进行姿态估计，结合运动规划模块实现全自动叉车操作。

Result: 在ADAPT自动叉车平台上验证，Lang2Lift实现了0.76 mIoU的托盘分割精度，并通过时间和错误分析证明了系统的鲁棒性和部署可行性。

Conclusion: Lang2Lift框架通过自然语言引导的托盘检测和6D姿态估计，成功实现了在复杂户外环境中的自动化托盘搬运，验证了其在物流和建筑行业中的可行性和鲁棒性。

Abstract: The logistics and construction industries face persistent challenges in
automating pallet handling, especially in outdoor environments with variable
payloads, inconsistencies in pallet quality and dimensions, and unstructured
surroundings. In this paper, we tackle automation of a critical step in pallet
transport: the pallet pick-up operation. Our work is motivated by labor
shortages, safety concerns, and inefficiencies in manually locating and
retrieving pallets under such conditions. We present Lang2Lift, a framework
that leverages foundation models for natural language-guided pallet detection
and 6D pose estimation, enabling operators to specify targets through intuitive
commands such as "pick up the steel beam pallet near the crane." The perception
pipeline integrates Florence-2 and SAM-2 for language-grounded segmentation
with FoundationPose for robust pose estimation in cluttered, multi-pallet
outdoor scenes under variable lighting. The resulting poses feed into a motion
planning module for fully autonomous forklift operation. We validate Lang2Lift
on the ADAPT autonomous forklift platform, achieving 0.76 mIoU pallet
segmentation accuracy on a real-world test dataset. Timing and error analysis
demonstrate the system's robustness and confirm its feasibility for deployment
in operational logistics and construction environments. Video demonstrations
are available at https://eric-nguyen1402.github.io/lang2lift.github.io/

</details>


### [140] [LLM-Driven Self-Refinement for Embodied Drone Task Planning](https://arxiv.org/abs/2508.15501)
*Deyu Zhang,Xicheng Zhang,Jiahao Li,Tingting Long,Xunhua Dai,Yongjian Fu,Jinrui Zhang,Ju Ren,Yaoxue Zhang*

Main category: cs.RO

TL;DR: SRDrone是一个用于工业无人机自我细化任务规划的新系统，通过连续状态评估和分层行为树修改，显著提高了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 为了解决工业级无人机在连续、动态操作中传统单帧最终状态评估方法的不足，设计了一个自我细化任务规划系统。

Method: SRDrone采用连续状态评估方法和分层行为树修改模型，结合多级行为树计划分析和受限策略空间，实现结构化反思学习。

Result: 实验结果显示，SRDrone在成功率上比基线方法提高了44.87%，并通过迭代自我优化在实际部署中达到了96.25%的成功率。

Conclusion: SRDrone通过将自适应任务细化能力嵌入工业级行为树规划框架，成功将大型语言模型的通用推理智能与无人机严格的物理执行约束相结合。

Abstract: We introduce SRDrone, a novel system designed for self-refinement task
planning in industrial-grade embodied drones. SRDrone incorporates two key
technical contributions: First, it employs a continuous state evaluation
methodology to robustly and accurately determine task outcomes and provide
explanatory feedback. This approach supersedes conventional reliance on
single-frame final-state assessment for continuous, dynamic drone operations.
Second, SRDrone implements a hierarchical Behavior Tree (BT) modification
model. This model integrates multi-level BT plan analysis with a constrained
strategy space to enable structured reflective learning from experience.
Experimental results demonstrate that SRDrone achieves a 44.87% improvement in
Success Rate (SR) over baseline methods. Furthermore, real-world deployment
utilizing an experience base optimized through iterative self-refinement
attains a 96.25% SR. By embedding adaptive task refinement capabilities within
an industrial-grade BT planning framework, SRDrone effectively integrates the
general reasoning intelligence of Large Language Models (LLMs) with the
stringent physical execution constraints inherent to embodied drones. Code is
available at https://github.com/ZXiiiC/SRDrone.

</details>


### [141] [Mind and Motion Aligned: A Joint Evaluation IsaacSim Benchmark for Task Planning and Low-Level Policies in Mobile Manipulation](https://arxiv.org/abs/2508.15663)
*Nikita Kachaev,Andrei Spiridonov,Andrey Gorodetsky,Kirill Muravyev,Nikita Oskolkov,Aditya Narendra,Vlad Shakhuro,Dmitry Makarov,Aleksandr I. Panov,Polina Fedotova,Alexey K. Kovalev*

Main category: cs.RO

TL;DR: Kitchen-R是一个新型基准测试，通过模拟厨房环境统一评估任务规划和低级控制，填补了现有基准测试的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在高层次语言指令跟随和低级机器人控制之间存在脱节，无法全面评估任务规划和物理执行都至关重要的集成系统。

Method: 提出了Kitchen-R基准测试，结合了Isaac Sim模拟器构建的数字孪生厨房环境，包含500多个复杂语言指令，支持移动机械臂机器人。提供了基线方法，包括基于视觉语言模型的任务规划策略和基于扩散策略的低级控制策略，以及轨迹收集系统。

Result: Kitchen-R提供了一个灵活的框架，支持三种评估模式：独立评估规划模块、独立评估控制策略以及关键的整体系统集成评估。

Conclusion: Kitchen-R作为一个新型基准测试，填补了具身AI研究中的关键空白，实现了对语言引导机器人代理更全面和现实的评估。

Abstract: Benchmarks are crucial for evaluating progress in robotics and embodied AI.
However, a significant gap exists between benchmarks designed for high-level
language instruction following, which often assume perfect low-level execution,
and those for low-level robot control, which rely on simple, one-step commands.
This disconnect prevents a comprehensive evaluation of integrated systems where
both task planning and physical execution are critical. To address this, we
propose Kitchen-R, a novel benchmark that unifies the evaluation of task
planning and low-level control within a simulated kitchen environment. Built as
a digital twin using the Isaac Sim simulator and featuring more than 500
complex language instructions, Kitchen-R supports a mobile manipulator robot.
We provide baseline methods for our benchmark, including a task-planning
strategy based on a vision-language model and a low-level control policy based
on diffusion policy. We also provide a trajectory collection system. Our
benchmark offers a flexible framework for three evaluation modes: independent
assessment of the planning module, independent assessment of the control
policy, and, crucially, an integrated evaluation of the whole system. Kitchen-R
bridges a key gap in embodied AI research, enabling more holistic and realistic
benchmarking of language-guided robotic agents.

</details>


### [142] [Exploiting Policy Idling for Dexterous Manipulation](https://arxiv.org/abs/2508.15669)
*Annie S. Chen,Philemon Brakel,Antonia Bronars,Annie Xie,Sandy Huang,Oliver Groth,Maria Bauza,Markus Wulfmeier,Nicolas Heess,Dushyant Rao*

Main category: cs.RO

TL;DR: PIP方法通过扰动策略闲置状态，提升学习策略的鲁棒性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 学习到的策略在达到某些状态时会出现闲置现象，影响可靠性和鲁棒性。现有方法（如过滤训练数据或调整控制频率）可能对策略性能产生负面影响。

Method: 提出Pause-Induced Perturbations (PIP)方法，通过在检测到的闲置状态施加扰动，帮助策略逃离问题区域。

Result: 在模拟双臂任务和真实世界插入任务中，PIP方法显著提升了测试性能（绝对成功率提高15-35%），且无需额外监督或训练。

Conclusion: Pause-Induced Perturbations (PIP)方法通过检测和扰动闲置状态，有效提升了策略的鲁棒性和测试性能，特别是在需要高精度操作的任务中。

Abstract: Learning-based methods for dexterous manipulation have made notable progress
in recent years. However, learned policies often still lack reliability and
exhibit limited robustness to important factors of variation. One failure
pattern that can be observed across many settings is that policies idle, i.e.
they cease to move beyond a small region of states when they reach certain
states. This policy idling is often a reflection of the training data. For
instance, it can occur when the data contains small actions in areas where the
robot needs to perform high-precision motions, e.g., when preparing to grasp an
object or object insertion. Prior works have tried to mitigate this phenomenon
e.g. by filtering the training data or modifying the control frequency.
However, these approaches can negatively impact policy performance in other
ways. As an alternative, we investigate how to leverage the detectability of
idling behavior to inform exploration and policy improvement. Our approach,
Pause-Induced Perturbations (PIP), applies perturbations at detected idling
states, thus helping it to escape problematic basins of attraction. On a range
of challenging simulated dual-arm tasks, we find that this simple approach can
already noticeably improve test-time performance, with no additional
supervision or training. Furthermore, since the robot tends to idle at critical
points in a movement, we also find that learning from the resulting episodes
leads to better iterative policy improvement compared to prior approaches. Our
perturbation strategy also leads to a 15-35% improvement in absolute success
rate on a real-world insertion task that requires complex multi-finger
manipulation.

</details>


### [143] [Understanding and Utilizing Dynamic Coupling in Free-Floating Space Manipulators for On-Orbit Servicing](https://arxiv.org/abs/2508.15732)
*Gargi Das,Daegyun Choi,Donghoon Kim*

Main category: cs.RO

TL;DR: 本研究提出了一种动态耦合感知的轨迹优化算法，利用动态耦合改进自由漂浮空间机械臂系统的轨迹规划，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 先前研究主要关注最小化动态耦合，而忽视了其潜在优势。本研究探讨如何利用动态耦合改进轨迹规划，以更高效地操作自由漂浮空间机械臂系统。

Method: 采用动态耦合矩阵的奇异值分解（SVD）来识别主导耦合行为的分量，并制定量化指标以表征耦合的强度和方向性，将其整合到轨迹优化框架中。为了评估优化轨迹的可行性，设计了基于滑模控制的跟踪控制器以生成所需的关节扭矩输入。

Result: 仿真结果表明，在轨迹规划中明确考虑动态耦合可以实现更明智且可能更高效的操作。

Conclusion: 通过将动态耦合纳入轨迹优化框架，本研究展示了如何利用动态耦合改善自由漂浮空间机械臂系统的轨迹规划，为控制系统提供了新的方向。

Abstract: This study proposes a dynamic coupling-informed trajectory optimization
algorithm for free-floating space manipulator systems (SMSs). Dynamic coupling
between the base and the manipulator arms plays a critical role in influencing
the system's behavior. While prior research has predominantly focused on
minimizing this coupling, often overlooking its potential advantages, this work
investigates how dynamic coupling can instead be leveraged to improve
trajectory planning. Singular value decomposition (SVD) of the dynamic coupling
matrix is employed to identify the dominant components governing coupling
behavior. A quantitative metric is then formulated to characterize the strength
and directionality of the coupling and is incorporated into a trajectory
optimization framework. To assess the feasibility of the optimized trajectory,
a sliding mode control-based tracking controller is designed to generate the
required joint torque inputs. Simulation results demonstrate that explicitly
accounting for dynamic coupling in trajectory planning enables more informed
and potentially more efficient operation, offering new directions for the
control of free-floating SMSs.

</details>
