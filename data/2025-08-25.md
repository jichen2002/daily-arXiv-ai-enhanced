<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 55]
- [cs.SE](#cs.SE) [Total: 17]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.DC](#cs.DC) [Total: 2]
- [q-bio.NC](#q-bio.NC) [Total: 1]
- [cs.RO](#cs.RO) [Total: 11]
- [cs.NI](#cs.NI) [Total: 11]
- [cs.AI](#cs.AI) [Total: 20]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DS](#cs.DS) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Text-Driven 3D Hand Motion Generation from Sign Language Data](https://arxiv.org/abs/2508.15902)
*Léore Bensabath,Mathis Petrovich,Gül Varol*

Main category: cs.CV

TL;DR: 通过自动标注和LLM翻译构建大规模手部动作-文本对，训练文本条件扩散模型HandMDM，实现跨领域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 目标是训练一个生成模型，能够根据自然语言描述生成3D手部动作，以支持手语和非手语手部动作的研究。

Method: 利用大规模手语视频数据集和伪标注的符号类别，通过LLM将其转换为手部动作描述，并训练文本条件手部动作扩散模型HandMDM。

Result: HandMDM在未见过的符号类别、不同手语及非手语手部动作中表现出鲁棒性。

Conclusion: 通过自动构建大规模3D手部动作与文本标签对，并训练文本条件手部动作扩散模型HandMDM，该模型在跨领域场景中表现出鲁棒性，为未来研究提供了新的数据和模型支持。

Abstract: Our goal is to train a generative model of 3D hand motions, conditioned on
natural language descriptions specifying motion characteristics such as
handshapes, locations, finger/hand/arm movements. To this end, we automatically
build pairs of 3D hand motions and their associated textual labels with
unprecedented scale. Specifically, we leverage a large-scale sign language
video dataset, along with noisy pseudo-annotated sign categories, which we
translate into hand motion descriptions via an LLM that utilizes a dictionary
of sign attributes, as well as our complementary motion-script cues. This data
enables training a text-conditioned hand motion diffusion model HandMDM, that
is robust across domains such as unseen sign categories from the same sign
language, but also signs from another sign language and non-sign hand
movements. We contribute extensive experimental investigation of these
scenarios and will make our trained models and data publicly available to
support future research in this relatively new field.

</details>


### [2] [VT-LVLM-AR: A Video-Temporal Large Vision-Language Model Adapter for Fine-Grained Action Recognition in Long-Term Videos](https://arxiv.org/abs/2508.15903)
*Kaining Li,Shuwei He,Zihan Xu*

Main category: cs.CV

TL;DR: VT-LVLM-AR框架通过视频到事件映射和LVLM适配，解决了长期视频动作识别的挑战，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 长期视频中的复杂背景和细微动作差异对传统深度学习模型构成挑战，而LVLMs在多模态理解和推理方面表现优异，但直接应用于连续视频流的细粒度动作识别仍存在问题。

Method: VT-LVLM-AR框架包含视频到事件映射器（VTEM）和基于LVLM的动作推理模块，采用轻量级时空特征提取、自适应时间池化和概念量化生成视觉事件序列，并通过参数高效的Prompt Tuning（P-Tuning v2）适配LLaVA-1.5模型进行分类。

Result: 在NTU RGB+D和NTU RGB+D 120数据集上的评估显示，VT-LVLM-AR性能优于现有方法（如NTU RGB+D X-Sub上94.1%准确率），消融研究验证了VTEM组件和Prompt Tuning的有效性。

Conclusion: 本研究通过VT-LVLM-AR框架展示了LVLMs在视频动作识别中的巨大潜力，通过高效的视频到语言转换和模型适配，实现了鲁棒且可解释的动作理解。

Abstract: Human action recognition in long-term videos, characterized by complex
backgrounds and subtle action differences, poses significant challenges for
traditional deep learning models due to computational overhead, difficulty in
capturing long-range temporal dependencies, and limited semantic understanding.
While Large Language Models (LLMs) and Large Vision-Language Models (LVLMs)
have shown remarkable capabilities in multi-modal understanding and reasoning,
their direct application to continuous video streams for fine-grained action
recognition remains an open problem. This paper introduces VT-LVLM-AR
(Video-Temporal Large Vision-Language Model Adapter for Action Recognition), a
novel framework designed to bridge this gap. VT-LVLM-AR comprises a
Video-to-Event Mapper (VTEM) that efficiently transforms raw video into
compact, semantically rich, and temporally coherent "visual event sequences"
through lightweight spatio-temporal feature extraction, adaptive temporal
pooling, and conceptual quantization with an event coherence bias. These visual
event sequences are then fed into an LVLM-based Action Reasoning module,
specifically a frozen LLaVA-1.5 model, adapted using parameter-efficient Prompt
Tuning (P-Tuning v2) for action classification. Comprehensive evaluations on
the NTU RGB+D and NTU RGB+D 120 datasets demonstrate that VT-LVLM-AR
consistently achieves state-of-the-art performance, surpassing existing methods
(e.g., 94.1% accuracy on NTU RGB+D X-Sub). Ablation studies confirm the
critical contributions of VTEM's components and the efficacy of Prompt Tuning,
while human evaluations underscore the interpretability of our visual event
representations. This work highlights the immense potential of leveraging LVLMs
for robust and interpretable video action understanding through effective
video-to-language translation and efficient model adaptation.

</details>


### [3] [Boosting Pathology Foundation Models via Few-shot Prompt-tuning for Rare Cancer Subtyping](https://arxiv.org/abs/2508.15904)
*Dexuan He,Xiao Zhou,Wenbin Guan,Liyuan Zhang,Xiaoman Zhang,Sinuo Xu,Ge Wang,Lifeng Wang,Xiaojun Yuan,Xin Sun,Yanfeng Wang,Kun Sun,Ya Zhang,Weidi Xie*

Main category: cs.CV

TL;DR: PathPT是一种新型视觉语言病理学框架，通过空间感知和任务特定提示，显著提升罕见癌症诊断的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 罕见癌症占所有恶性肿瘤的20-25%，但由于专家资源有限（尤其在儿科肿瘤学中占70%以上），诊断面临重大挑战。现有方法仅依赖视觉特征，忽略了跨模态知识，影响了罕见癌症诊断的可解释性。

Method: PathPT框架通过利用视觉语言病理学基础模型的零样本能力，将WSI级监督转化为细粒度的tile级指导，保留了癌变区域的定位，并通过与组织病理学语义对齐的提示实现跨模态推理。

Result: 在八个罕见癌症数据集和三个常见癌症数据集上的评估表明，PathPT在亚型分类准确性和癌变区域定位能力上均显著优于现有方法。

Conclusion: PathPT通过空间感知的视觉聚合和任务特定的提示调整，显著提高了罕见癌症亚型分类的准确性和癌变区域的定位能力，为AI辅助诊断提供了可扩展的解决方案。

Abstract: Rare cancers comprise 20-25% of all malignancies but face major diagnostic
challenges due to limited expert availability-especially in pediatric oncology,
where they represent over 70% of cases. While pathology vision-language (VL)
foundation models show promising zero-shot capabilities for common cancer
subtyping, their clinical performance for rare cancers remains limited.
Existing multi-instance learning (MIL) methods rely only on visual features,
overlooking cross-modal knowledge and compromising interpretability critical
for rare cancer diagnosis. To address this limitation, we propose PathPT, a
novel framework that fully exploits the potential of vision-language pathology
foundation models through spatially-aware visual aggregation and task-specific
prompt tuning. Unlike conventional MIL, PathPT converts WSI-level supervision
into fine-grained tile-level guidance by leveraging the zero-shot capabilities
of VL models, thereby preserving localization on cancerous regions and enabling
cross-modal reasoning through prompts aligned with histopathological semantics.
We benchmark PathPT on eight rare cancer datasets(four adult and four
pediatric) spanning 56 subtypes and 2,910 WSIs, as well as three common cancer
datasets, evaluating four state-of-the-art VL models and four MIL frameworks
under three few-shot settings. Results show that PathPT consistently delivers
superior performance, achieving substantial gains in subtyping accuracy and
cancerous region grounding ability. This work advances AI-assisted diagnosis
for rare cancers, offering a scalable solution for improving subtyping accuracy
in settings with limited access to specialized expertise.

</details>


### [4] [Semantic-Aware Ship Detection with Vision-Language Integration](https://arxiv.org/abs/2508.15930)
*Jiahao Li,Jiancheng Pan,Yuze Sun,Xiaomeng Huang*

Main category: cs.CV

TL;DR: 提出VLM结合多尺度滑动窗口的船舶检测框架，引入ShipSem-VL数据集，显著提升复杂场景下的细粒度检测效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉细粒度语义信息，限制了复杂场景下的检测效果。

Method: 采用视觉语言模型（VLMs）与多尺度自适应滑动窗口策略相结合的方法，并引入ShipSem-VL数据集以捕获细粒度船舶属性。

Result: 通过三项明确定义的任务评估，验证了框架在提升语义感知船舶检测（SASD）性能方面的有效性。

Conclusion: 论文提出了一种结合视觉语言模型（VLMs）和多尺度自适应滑动窗口策略的新型检测框架，显著提升了复杂场景下的细粒度语义感知船舶检测性能。

Abstract: Ship detection in remote sensing imagery is a critical task with wide-ranging
applications, such as maritime activity monitoring, shipping logistics, and
environmental studies. However, existing methods often struggle to capture
fine-grained semantic information, limiting their effectiveness in complex
scenarios. To address these challenges, we propose a novel detection framework
that combines Vision-Language Models (VLMs) with a multi-scale adaptive sliding
window strategy. To facilitate Semantic-Aware Ship Detection (SASD), we
introduce ShipSem-VL, a specialized Vision-Language dataset designed to capture
fine-grained ship attributes. We evaluate our framework through three
well-defined tasks, providing a comprehensive analysis of its performance and
demonstrating its effectiveness in advancing SASD from multiple perspectives.

</details>


### [5] [Automatic Retrieval of Specific Cows from Unlabeled Videos](https://arxiv.org/abs/2508.15945)
*Jiawen Lyu,Manu Ramesh,Madison Simonds,Jacquelyn P. Boerman,Amy R. Reibman*

Main category: cs.CV

TL;DR: 开发了一套自动化视频系统，用于奶牛的自动分类和识别，无需深度学习即可在连续视频流中识别个体奶牛。


<details>
  <summary>Details</summary>
Motivation: 现有公开文献中缺乏自动化视频系统用于奶牛的无接触分类和识别，因此开发了本系统以填补这一技术空白。

Method: 系统由AutoCattloger、eidetic cow recognizer和CowFinder三部分组成，分别负责构建奶牛目录、无深度学习识别奶牛和连续视频流中的奶牛识别。

Result: 系统成功在未标记、未分割的视频中识别出自由行走的奶牛个体，展示了其实际应用价值。

Conclusion: 该系统通过自动化视频分析实现了奶牛的无接触识别和分类，为畜牧业提供了高效的技术支持。

Abstract: Few automated video systems are described in the open literature that enable
hands-free cataloging and identification (ID) of cows in a dairy herd. In this
work, we describe our system, composed of an AutoCattloger, which builds a
Cattlog of dairy cows in a herd with a single input video clip per cow, an
eidetic cow recognizer which uses no deep learning to ID cows, and a CowFinder,
which IDs cows in a continuous stream of video. We demonstrate its value in
finding individuals in unlabeled, unsegmented videos of cows walking
unconstrained through the holding area of a milking parlor.

</details>


### [6] [Investigating Different Geo Priors for Image Classification](https://arxiv.org/abs/2508.15946)
*Angela Zhu,Christian Lange,Max Hamilton*

Main category: cs.CV

TL;DR: 研究评估了SINR模型作为地理先验在iNaturalist观测中的视觉物种分类效果，发现其有效性因素与范围地图制作不同。


<details>
  <summary>Details</summary>
Motivation: 利用物种分布模型作为视觉分类的先验，以提高分类准确性。

Method: 评估了各种SINR模型作为地理先验的有效性，探索了不同模型配置的影响，并调整了对未包含在Geo Prior训练中的物种预测的处理方式。

Result: 分析了影响SINR模型作为Geo Priors有效性的因素，这些因素可能与制作准确范围地图的考量不同。

Conclusion: 研究揭示了SINR模型作为地理先验在视觉物种分类中的有效性，并指出了与制作精确范围地图不同的因素。

Abstract: Species distribution models encode spatial patterns of species occurrence
making them effective priors for vision-based species classification when
location information is available. In this study, we evaluate various SINR
(Spatial Implicit Neural Representations) models as a geographical prior for
visual classification of species from iNaturalist observations. We explore the
impact of different model configurations and adjust how we handle predictions
for species not included in Geo Prior training. Our analysis reveals factors
that contribute to the effectiveness of these models as Geo Priors, factors
that may differ from making accurate range maps.

</details>


### [7] [Representation Learning with Adaptive Superpixel Coding](https://arxiv.org/abs/2508.15959)
*Mahmoud Khalil,Ahmad Khalil,Alioune Ngom*

Main category: cs.CV

TL;DR: 提出自适应超像素编码（ASC）模型，通过动态调整超像素层克服传统Vision Transformers的局限性，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉模型通常针对特定模态设计，依赖领域特定假设（如网格结构），传统Vision Transformers依赖固定大小和非自适应补丁划分，存在局限性。

Method: 提出了一种基于Transformers的自监督模型，称为自适应超像素编码（ASC），利用自适应超像素层动态调整图像内容。

Result: ASC方法在标准图像下游任务基准测试中表现优于广泛使用的替代方法。

Conclusion: ASC模型通过自适应超像素层克服了传统Vision Transformers的局限性，在标准图像下游任务基准测试中表现优于广泛使用的替代方法。

Abstract: Deep learning vision models are typically tailored for specific modalities
and often rely on domain-specific assumptions, such as the grid structures used
by nearly all existing vision models. In this work, we propose a
self-supervised model based on Transformers, which we call Adaptive Superpixel
Coding (ASC). The key insight of our model is to overcome the limitations of
traditional Vision Transformers, which depend on fixed-size and non-adaptive
patch partitioning. Instead, ASC employs adaptive superpixel layers that
dynamically adjust to the underlying image content. We analyze key properties
of the approach that make it effective, and find that our method outperforms
widely-used alternatives on standard image downstream task benchmarks.

</details>


### [8] [Glo-VLMs: Leveraging Vision-Language Models for Fine-Grained Diseased Glomerulus Classification](https://arxiv.org/abs/2508.15960)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 研究探索了视觉语言模型在少样本情况下对肾小球亚型分类的适应性，提出Glo-VLMs框架并展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 肾小球亚型分类因形态学差异细微且视觉模式与临床术语对齐困难，使得自动化诊断具有挑战性，探索VLMs在此任务中的适应性。

Method: 引入Glo-VLMs框架，结合病理图像和临床文本提示进行联合图像-文本表示学习，评估不同VLM架构和适应策略在少样本学习范式下的表现。

Result: 在每类仅8个样本的情况下，微调VLMs取得了0.7416的准确率、0.9045的宏AUC和0.5277的F1分数。

Conclusion: 大型预训练的视觉语言模型（VLMs）即使在监督数据极少的情况下，也能有效适应细粒度的医学图像分类任务，如肾小球亚型分类。

Abstract: Vision-language models (VLMs) have shown considerable potential in digital
pathology, yet their effectiveness remains limited for fine-grained,
disease-specific classification tasks such as distinguishing between glomerular
subtypes. The subtle morphological variations among these subtypes, combined
with the difficulty of aligning visual patterns with precise clinical
terminology, make automated diagnosis in renal pathology particularly
challenging. In this work, we explore how large pretrained VLMs can be
effectively adapted to perform fine-grained glomerular classification, even in
scenarios where only a small number of labeled examples are available. In this
work, we introduce Glo-VLMs, a systematic framework designed to explore the
adaptation of VLMs to fine-grained glomerular classification in
data-constrained settings. Our approach leverages curated pathology images
alongside clinical text prompts to facilitate joint image-text representation
learning for nuanced renal pathology subtypes. By assessing various VLMs
architectures and adaptation strategies under a few-shot learning paradigm, we
explore how both the choice of method and the amount of labeled data impact
model performance in clinically relevant scenarios. To ensure a fair
comparison, we evaluate all models using standardized multi-class metrics,
aiming to clarify the practical requirements and potential of large pretrained
models for specialized clinical research applications. As a result, fine-tuning
the VLMs achieved 0.7416 accuracy, 0.9045 macro-AUC, and 0.5277 F1-score with
only 8 shots per class, demonstrating that even with highly limited
supervision, foundation models can be effectively adapted for fine-grained
medical image classification.

</details>


### [9] [Contributions to Label-Efficient Learning in Computer Vision and Remote Sensing](https://arxiv.org/abs/2508.15973)
*Minh-Tan Pham*

Main category: cs.CV

TL;DR: 本文总结了标签高效学习在计算机视觉和遥感中的方法与应用，包括弱监督、多任务、对比和少样本学习，展示了实验结果并展望了未来方向。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发能够从有限或部分标注数据中有效学习，并利用大量未标注数据的方法，以应对实际应用中的挑战。

Method: 研究方法包括弱监督学习、多任务学习、自监督和监督对比学习以及少样本学习，针对遥感数据的多模态、空间分辨率变异性和场景异质性等独特挑战进行了调整。

Result: 通过广泛的自然和遥感数据集实验，验证了方法在对象发现、检测、语义分割和场景分类等任务中的有效性。

Conclusion: 本文总结了标签高效学习在计算机视觉和遥感领域的贡献，并概述了未来研究方向，重点是扩展和增强实际应用中的标签高效学习。

Abstract: This manuscript presents a series of my selected contributions to the topic
of label-efficient learning in computer vision and remote sensing. The central
focus of this research is to develop and adapt methods that can learn
effectively from limited or partially annotated data, and can leverage abundant
unlabeled data in real-world applications. The contributions span both
methodological developments and domain-specific adaptations, in particular
addressing challenges unique to Earth observation data such as multi-modality,
spatial resolution variability, and scene heterogeneity. The manuscript is
organized around four main axes including (1) weakly supervised learning for
object discovery and detection based on anomaly-aware representations learned
from large amounts of background images; (2) multi-task learning that jointly
trains on multiple datasets with disjoint annotations to improve performance on
object detection and semantic segmentation; (3) self-supervised and supervised
contrastive learning with multimodal data to enhance scene classification in
remote sensing; and (4) few-shot learning for hierarchical scene classification
using both explicit and implicit modeling of class hierarchies. These
contributions are supported by extensive experimental results across natural
and remote sensing datasets, reflecting the outcomes of several collaborative
research projects. The manuscript concludes by outlining ongoing and future
research directions focused on scaling and enhancing label-efficient learning
for real-world applications.

</details>


### [10] [Panoptic Segmentation of Environmental UAV Images : Litter Beach](https://arxiv.org/abs/2508.15985)
*Ousmane Youme,Jean Marie Dembélé,Eugene C. Ezin,Christophe Cambier*

Main category: cs.CV

TL;DR: 论文提出了一种结合实例分割和全景分割的CNN方法，用于提高海洋垃圾监测的准确性，尤其在沙地异质环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于沙地的异质性，传统CNN模型在监测海洋垃圾时容易受到沙色反射、人类足迹、阴影等多种因素的干扰，需要更鲁棒的解决方案。

Method: 采用了基于实例的分割方法和全景分割方法，仅需少量样本即可实现高精度。

Result: 提出的方法在少量样本下表现出良好的准确性和鲁棒性，有效减少了误判。

Conclusion: 该论文提出了一种基于实例分割和全景分割的方法，用于解决CNN在海洋垃圾监测中因沙地异质性导致的误判问题，展示了较高的准确性和鲁棒性。

Abstract: Convolutional neural networks (CNN) have been used efficiently in several
fields, including environmental challenges. In fact, CNN can help with the
monitoring of marine litter, which has become a worldwide problem. UAVs have
higher resolution and are more adaptable in local areas than satellite images,
making it easier to find and count trash. Since the sand is heterogeneous, a
basic CNN model encounters plenty of inferences caused by reflections of sand
color, human footsteps, shadows, algae present, dunes, holes, and tire tracks.
For these types of images, other CNN models, such as CNN-based segmentation
methods, may be more appropriate. In this paper, we use an instance-based
segmentation method and a panoptic segmentation method that show good accuracy
with just a few samples. The model is more robust and less

</details>


### [11] [Automated Multi-label Classification of Eleven Retinal Diseases: A Benchmark of Modern Architectures and a Meta-Ensemble on a Large Synthetic Dataset](https://arxiv.org/abs/2508.15986)
*Jerry Cao-Xue,Tien Comlekoglu,Keyi Xue,Guanliang Wang,Jiang Li,Gordon Laurie*

Main category: cs.CV

TL;DR: 研究利用合成数据集SynFundus-1M训练多种深度学习模型，构建了高性能集成模型，并在真实临床数据上验证了其泛化能力，为眼科AI发展提供了新基准。


<details>
  <summary>Details</summary>
Motivation: 由于患者隐私和高成本，大规模专家标注的临床数据集稀缺，阻碍了多标签深度学习模型在视网膜疾病分类中的发展。SynFundus-1M这一高保真合成数据集的发布为克服这些障碍提供了新机会。

Method: 开发了一个端到端的深度学习管道，训练了六种现代架构（ConvNeXtV2、SwinV2、ViT、ResNet、EfficientNetV2和RETFound基础模型），采用5折多标签分层交叉验证策略，并进一步通过XGBoost分类器堆叠折外预测构建了元集成模型。

Result: 最终集成模型在内部验证集上表现最佳，宏平均AUC为0.9973。模型在三个真实临床数据集上表现出强泛化能力，联合DR数据集的AUC为0.7972，AIROGS青光眼数据集的AUC为0.9126，多标签RFMiD数据集的宏AUC为0.8800。

Conclusion: 该研究为未来大规模合成数据集的研究提供了坚实基准，并证明仅用合成数据训练的模型能准确分类多种病理，并有效泛化到真实临床图像，为加速眼科全面AI系统的发展提供了可行途径。

Abstract: The development of multi-label deep learning models for retinal disease
classification is often hindered by the scarcity of large, expertly annotated
clinical datasets due to patient privacy concerns and high costs. The recent
release of SynFundus-1M, a high-fidelity synthetic dataset with over one
million fundus images, presents a novel opportunity to overcome these barriers.
To establish a foundational performance benchmark for this new resource, we
developed an end-to-end deep learning pipeline, training six modern
architectures (ConvNeXtV2, SwinV2, ViT, ResNet, EfficientNetV2, and the
RETFound foundation model) to classify eleven retinal diseases using a 5-fold
multi-label stratified cross-validation strategy. We further developed a
meta-ensemble model by stacking the out-of-fold predictions with an XGBoost
classifier. Our final ensemble model achieved the highest performance on the
internal validation set, with a macro-average Area Under the Receiver Operating
Characteristic Curve (AUC) of 0.9973. Critically, the models demonstrated
strong generalization to three diverse, real-world clinical datasets, achieving
an AUC of 0.7972 on a combined DR dataset, an AUC of 0.9126 on the AIROGS
glaucoma dataset and a macro-AUC of 0.8800 on the multi-label RFMiD dataset.
This work provides a robust baseline for future research on large-scale
synthetic datasets and establishes that models trained exclusively on synthetic
data can accurately classify multiple pathologies and generalize effectively to
real clinical images, offering a viable pathway to accelerate the development
of comprehensive AI systems in ophthalmology.

</details>


### [12] [CoVeRaP: Cooperative Vehicular Perception through mmWave FMCW Radars](https://arxiv.org/abs/2508.16030)
*Jinyue Song,Hansol Ku,Jayneel Vora,Nelson Lee,Ahmad Kamari,Prasant Mohapatra,Parth Pathak*

Main category: cs.CV

TL;DR: CoVeRaP数据集和协同感知框架提升了多车FMCW雷达的3D物体检测性能，中期融合效果显著。


<details>
  <summary>Details</summary>
Motivation: 尽管汽车FMCW雷达在雨雪和强光下可靠，但其稀疏、嘈杂的点云限制了3D物体检测，因此需要多车协同感知来提升性能。

Method: 提出了一种统一的协同感知框架，包含中晚期融合选项，其基线网络采用多分支PointNet风格编码器，并增强自注意力机制，融合空间、多普勒和强度线索到共同潜在空间。

Result: 实验表明，带有强度编码的中期融合在IoU 0.9时平均精度提升高达9倍，并持续优于单车基线。

Conclusion: CoVeRaP数据集和提出的协同感知框架为多车FMCW雷达感知建立了首个可复现的基准，证明了经济实惠的雷达共享显著提高了检测鲁棒性。

Abstract: Automotive FMCW radars remain reliable in rain and glare, yet their sparse,
noisy point clouds constrain 3-D object detection. We therefore release
CoVeRaP, a 21 k-frame cooperative dataset that time-aligns radar, camera, and
GPS streams from multiple vehicles across diverse manoeuvres. Built on this
data, we propose a unified cooperative-perception framework with middle- and
late-fusion options. Its baseline network employs a multi-branch PointNet-style
encoder enhanced with self-attention to fuse spatial, Doppler, and intensity
cues into a common latent space, which a decoder converts into 3-D bounding
boxes and per-point depth confidence. Experiments show that middle fusion with
intensity encoding boosts mean Average Precision by up to 9x at IoU 0.9 and
consistently outperforms single-vehicle baselines. CoVeRaP thus establishes the
first reproducible benchmark for multi-vehicle FMCW-radar perception and
demonstrates that affordable radar sharing markedly improves detection
robustness. Dataset and code are publicly available to encourage further
research.

</details>


### [13] [NeuralMeshing: Complete Object Mesh Extraction from Casual Captures](https://arxiv.org/abs/2508.16026)
*Floris Erich,Naoya Chiba,Abdullah Mustafa,Ryo Hanai,Noriaki Ando,Yusuke Yoshiyasu,Yukiyasu Domae*

Main category: cs.CV

TL;DR: 提出了一种基于多视频的自动化系统，利用结构从运动技术生成完整物体网格，无需商业3D扫描仪。


<details>
  <summary>Details</summary>
Motivation: 解决日常环境中无法使用商业3D扫描仪时，如何高效获取物体完整几何模型的问题。

Method: 使用结构从运动（Structure-from-Motion）技术，通过多个视频中的已知点（如棋盘或AR标记）自动定位帧，并合并结果以生成完整网格。

Result: 成功开发了一个自动化系统，能从多个视频中生成完整的物体网格模型，无需依赖孔填充技术。

Conclusion: 该系统通过从多个视频中自动提取和合并几何模型，无需依赖商业3D扫描仪，即可生成完整的物体网格模型。

Abstract: How can we extract complete geometric models of objects that we encounter in
our daily life, without having access to commercial 3D scanners? In this paper
we present an automated system for generating geometric models of objects from
two or more videos. Our system requires the specification of one known point in
at least one frame of each video, which can be automatically determined using a
fiducial marker such as a checkerboard or Augmented Reality (AR) marker. The
remaining frames are automatically positioned in world space by using
Structure-from-Motion techniques. By using multiple videos and merging results,
a complete object mesh can be generated, without having to rely on hole
filling. Code for our system is available from
https://github.com/FlorisE/NeuralMeshing.

</details>


### [14] [Diverse Signer Avatars with Manual and Non-Manual Feature Modelling for Sign Language Production](https://arxiv.org/abs/2508.15988)
*Mohamed Ilyes Lakhal,Richard Bowden*

Main category: cs.CV

TL;DR: 论文提出基于LDM的手语生成方法，通过显式建模非手动和手动特征，显著提升多样性和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有手语生成模型难以在保持视觉质量的同时捕捉多样性和非手动属性（如情感），因此需要一种新方法来解决这一问题。

Method: 采用潜在扩散模型（LDM）合成逼真数字化身，并设计了一个显式建模非手动特征（如面部）和手动特征（如手部）的手语特征聚合模块。

Result: 在YouTube-SL-25数据集上的实验表明，该方法在视觉质量上优于现有技术，并在感知指标上有显著提升。

Conclusion: 论文提出的基于潜在扩散模型（LDM）的新型手语生成方法，结合显式建模非手动特征和手动特征的模块，显著提升了视觉质量，并在感知指标上优于现有方法。

Abstract: The diversity of sign representation is essential for Sign Language
Production (SLP) as it captures variations in appearance, facial expressions,
and hand movements. However, existing SLP models are often unable to capture
diversity while preserving visual quality and modelling non-manual attributes
such as emotions. To address this problem, we propose a novel approach that
leverages Latent Diffusion Model (LDM) to synthesise photorealistic digital
avatars from a generated reference image. We propose a novel sign feature
aggregation module that explicitly models the non-manual features
(\textit{e.g.}, the face) and the manual features (\textit{e.g.}, the hands).
We show that our proposed module ensures the preservation of linguistic content
while seamlessly using reference images with different ethnic backgrounds to
ensure diversity. Experiments on the YouTube-SL-25 sign language dataset show
that our pipeline achieves superior visual quality compared to state-of-the-art
methods, with significant improvements on perceptual metrics.

</details>


### [15] [DRespNeT: A UAV Dataset and YOLOv8-DRN Model for Aerial Instance Segmentation of Building Access Points for Post-Earthquake Search-and-Rescue Missions](https://arxiv.org/abs/2508.16016)
*Aykut Sirma,Angelos Plastropoulos,Argyrios Zolotas,Gilbert Tang*

Main category: cs.CV

TL;DR: DRespNeT是一个高分辨率数据集，用于地震后环境的实例分割，结合优化的YOLOv8-DRN模型，显著提升了搜救行动的效率和实时性。


<details>
  <summary>Details</summary>
Motivation: 地震后快速评估城市环境中的可进入点和结构障碍对搜救行动至关重要，现有数据集依赖卫星图像或粗粒度标注，无法满足需求。

Method: 引入DRespNeT高分辨率数据集，提供详细的实例分割标注，并基于YOLOv8-seg模型进行优化，开发了YOLOv8-DRN模型。

Result: YOLOv8-DRN模型在RTX-4090 GPU上实现了92.7%的mAP50和27 FPS的推理速度，满足实时操作需求。

Conclusion: DRespNeT数据集和优化的YOLOv8-DRN模型显著提升了地震后环境中的实时态势感知和决策能力，支持搜救团队和机器人系统，从而改善应急响应和幸存者生存率。

Abstract: Recent advancements in computer vision and deep learning have enhanced
disaster-response capabilities, particularly in the rapid assessment of
earthquake-affected urban environments. Timely identification of accessible
entry points and structural obstacles is essential for effective
search-and-rescue (SAR) operations. To address this need, we introduce
DRespNeT, a high-resolution dataset specifically developed for aerial instance
segmentation of post-earthquake structural environments. Unlike existing
datasets, which rely heavily on satellite imagery or coarse semantic labeling,
DRespNeT provides detailed polygon-level instance segmentation annotations
derived from high-definition (1080p) aerial footage captured in disaster zones,
including the 2023 Turkiye earthquake and other impacted regions. The dataset
comprises 28 operationally critical classes, including structurally compromised
buildings, access points such as doors, windows, and gaps, multiple debris
levels, rescue personnel, vehicles, and civilian visibility. A distinctive
feature of DRespNeT is its fine-grained annotation detail, enabling
differentiation between accessible and obstructed areas, thereby improving
operational planning and response efficiency. Performance evaluations using
YOLO-based instance segmentation models, specifically YOLOv8-seg, demonstrate
significant gains in real-time situational awareness and decision-making. Our
optimized YOLOv8-DRN model achieves 92.7% mAP50 with an inference speed of 27
FPS on an RTX-4090 GPU for multi-target detection, meeting real-time
operational requirements. The dataset and models support SAR teams and robotic
systems, providing a foundation for enhancing human-robot collaboration,
streamlining emergency response, and improving survivor outcomes.

</details>


### [16] [HOSt3R: Keypoint-free Hand-Object 3D Reconstruction from RGB images](https://arxiv.org/abs/2508.16465)
*Anilkumar Swamy,Vincent Leroy,Philippe Weinzaepfel,Jean-Sébastien Franco,Grégory Rogez*

Main category: cs.CV

TL;DR: HOSt3R是一种无需关键点检测器的手-物体3D重建方法，解决了现有技术在处理多样几何和遮挡时的局限性，在SHOWMe和HO3D数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于关键点检测技术（如SfM和手关键点优化），在处理多样物体几何、弱纹理和手-物体相互遮挡时表现不佳，限制了可扩展性和泛化能力。

Method: 提出了一种无关键点检测器的鲁棒方法，用于从单目运动视频/图像中估计手-物体3D变换，并与多视图重建管道集成以恢复3D形状。

Result: 在SHOWMe基准测试中达到最先进性能，并在HO3D数据集上展示了泛化能力。

Conclusion: HOSt3R方法在SHOWMe基准测试中实现了最先进的性能，能够泛化到未见过的物体类别，验证了其鲁棒性和通用性。

Abstract: Hand-object 3D reconstruction has become increasingly important for
applications in human-robot interaction and immersive AR/VR experiences. A
common approach for object-agnostic hand-object reconstruction from RGB
sequences involves a two-stage pipeline: hand-object 3D tracking followed by
multi-view 3D reconstruction. However, existing methods rely on keypoint
detection techniques, such as Structure from Motion (SfM) and hand-keypoint
optimization, which struggle with diverse object geometries, weak textures, and
mutual hand-object occlusions, limiting scalability and generalization. As a
key enabler to generic and seamless, non-intrusive applicability, we propose in
this work a robust, keypoint detector-free approach to estimating hand-object
3D transformations from monocular motion video/images. We further integrate
this with a multi-view reconstruction pipeline to accurately recover
hand-object 3D shape. Our method, named HOSt3R, is unconstrained, does not rely
on pre-scanned object templates or camera intrinsics, and reaches
state-of-the-art performance for the tasks of object-agnostic hand-object 3D
transformation and shape estimation on the SHOWMe benchmark. We also experiment
on sequences from the HO3D dataset, demonstrating generalization to unseen
object categories.

</details>


### [17] [Wavelet-Enhanced PaDiM for Industrial Anomaly Detection](https://arxiv.org/abs/2508.16034)
*Cory Gardner,Byungseok Min,Tae-Hyuk Ahn*

Main category: cs.CV

TL;DR: WE-PaDiM结合小波变换和CNN特征，替代随机选择，显著提升了工业图像异常检测和定位的性能。


<details>
  <summary>Details</summary>
Motivation: PaDiM通过随机通道选择降低维度，可能丢失结构化信息。WE-PaDiM旨在通过小波变换提供一种基于频率内容的特征选择方法，以更有效地检测和定位异常。

Method: WE-PaDiM通过离散小波变换（DWT）分析多层CNN特征，选择特定频率子带（如LL、LH、HL），进行空间对齐和通道级拼接，并在PaDiM的多变量高斯框架中建模。

Result: 在MVTec AD数据集上，WE-PaDiM在15个类别中实现了99.32%的Image-AUC和92.10%的Pixel-AUC，表现出优异的异常检测和定位性能。

Conclusion: WE-PaDiM提供了一种基于频率内容的结构化特征选择方法，替代了PaDiM中的随机选择，在工业图像异常检测和定位中表现出色，同时保持了可解释性和高效性。

Abstract: Anomaly detection and localization in industrial images are essential for
automated quality inspection. PaDiM, a prominent method, models the
distribution of normal image features extracted by pre-trained Convolutional
Neural Networks (CNNs) but reduces dimensionality through random channel
selection, potentially discarding structured information. We propose
Wavelet-Enhanced PaDiM (WE-PaDiM), which integrates Discrete Wavelet Transform
(DWT) analysis with multi-layer CNN features in a structured manner. WE-PaDiM
applies 2D DWT to feature maps from multiple backbone layers, selects specific
frequency subbands (e.g., LL, LH, HL), spatially aligns them, and concatenates
them channel-wise before modeling with PaDiM's multivariate Gaussian framework.
This DWT-before-concatenation strategy provides a principled method for feature
selection based on frequency content relevant to anomalies, leveraging
multi-scale wavelet information as an alternative to random selection. We
evaluate WE-PaDiM on the challenging MVTec AD dataset with multiple backbones
(ResNet-18 and EfficientNet B0-B6). The method achieves strong performance in
anomaly detection and localization, yielding average results of 99.32%
Image-AUC and 92.10% Pixel-AUC across 15 categories with per-class optimized
configurations. Our analysis shows that wavelet choices affect performance
trade-offs: simpler wavelets (e.g., Haar) with detail subbands (HL or LH/HL/HH)
often enhance localization, while approximation bands (LL) improve image-level
detection. WE-PaDiM thus offers a competitive and interpretable alternative to
random feature selection in PaDiM, achieving robust results suitable for
industrial inspection with comparable efficiency.

</details>


### [18] [Expandable Residual Approximation for Knowledge Distillation](https://arxiv.org/abs/2508.16050)
*Zhaoyi Yan,Binghui Chen,Yunfan Liu,Qixiang Ye*

Main category: cs.CV

TL;DR: ERA是一种新的知识蒸馏方法，通过分步逼近残差知识和重用教师模型头部权重，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 由于教师模型和学生模型之间的学习能力差距，知识转移不足，需要新的方法来解决这一问题。

Method: 提出了Expandable Residual Approximation (ERA)方法，包括Multi-Branched Residual Network (MBRNet)和Teacher Weight Integration (TWI)策略。

Result: 在ImageNet分类任务中Top-1准确率提升1.41%，在MS COCO目标检测任务中AP提升1.40。

Conclusion: ERA方法通过分步逼近残差知识和重用教师模型头部权重，显著提升了知识蒸馏的效果，在多个计算机视觉任务中取得了领先性能。

Abstract: Knowledge distillation (KD) aims to transfer knowledge from a large-scale
teacher model to a lightweight one, significantly reducing computational and
storage requirements. However, the inherent learning capacity gap between the
teacher and student often hinders the sufficient transfer of knowledge,
motivating numerous studies to address this challenge. Inspired by the
progressive approximation principle in the Stone-Weierstrass theorem, we
propose Expandable Residual Approximation (ERA), a novel KD method that
decomposes the approximation of residual knowledge into multiple steps,
reducing the difficulty of mimicking the teacher's representation through a
divide-and-conquer approach. Specifically, ERA employs a Multi-Branched
Residual Network (MBRNet) to implement this residual knowledge decomposition.
Additionally, a Teacher Weight Integration (TWI) strategy is introduced to
mitigate the capacity disparity by reusing the teacher's head weights.
Extensive experiments show that ERA improves the Top-1 accuracy on the ImageNet
classification benchmark by 1.41% and the AP on the MS COCO object detection
benchmark by 1.40, as well as achieving leading performance across computer
vision tasks. Codes and models are available at
https://github.com/Zhaoyi-Yan/ERA.

</details>


### [19] [Advances and Trends in the 3D Reconstruction of the Shape and Motion of Animals](https://arxiv.org/abs/2508.16062)
*Ziqi Li,Abderraouf Amrani,Shri Rai,Hamid Laga*

Main category: cs.CV

TL;DR: 该论文综述了基于深度学习的动物3D重建技术，分类讨论了现有方法，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统3D扫描技术在动物几何、姿态和运动重建中存在侵入性、成本高且难以在自然环境中部署的问题，促使研究者探索基于深度学习的非侵入性方法。

Method: 该论文通过分类和讨论现有方法，基于输入模态、3D几何和运动表示方式、重建技术类型以及训练机制，对最新研究进行了全面分析。

Result: 论文分析了关键方法的性能，总结了它们的优缺点，并提出了当前挑战和未来研究方向。

Conclusion: 该论文总结了动物3D重建技术的最新进展，并讨论了当前方法的优势和局限性，同时指出了未来的研究方向。

Abstract: Reconstructing the 3D geometry, pose, and motion of animals is a
long-standing problem, which has a wide range of applications, from biology,
livestock management, and animal conservation and welfare to content creation
in digital entertainment and Virtual/Augmented Reality (VR/AR). Traditionally,
3D models of real animals are obtained using 3D scanners. These, however, are
intrusive, often prohibitively expensive, and difficult to deploy in the
natural environment of the animals. In recent years, we have seen a significant
surge in deep learning-based techniques that enable the 3D reconstruction, in a
non-intrusive manner, of the shape and motion of dynamic objects just from
their RGB image and/or video observations. Several papers have explored their
application and extension to various types of animals. This paper surveys the
latest developments in this emerging and growing field of research. It
categorizes and discusses the state-of-the-art methods based on their input
modalities, the way the 3D geometry and motion of animals are represented, the
type of reconstruction techniques they use, and the training mechanisms they
adopt. It also analyzes the performance of some key methods, discusses their
strengths and limitations, and identifies current challenges and directions for
future research.

</details>


### [20] [A Unified Voxel Diffusion Module for Point Cloud 3D Object Detection](https://arxiv.org/abs/2508.16069)
*Qifeng Liu,Dawei Zhao,Yabo Dong,Linzhi Shang,Liang Xiao,Juan Wang,Kunkong Zhao,Dongming Lu,Qi Zhu*

Main category: cs.CV

TL;DR: VDM模块通过增强体素扩散和表示能力，显著提升了点云目标检测模型的性能，在多个数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Transformer和SSM的点云目标检测模型由于体素表示的串行处理限制了空间扩散能力，影响了检测精度。

Method: 提出了一种新颖的体素扩散模块（VDM），由稀疏3D卷积、子流形稀疏卷积和残差连接组成，输出特征图下采样至原始输入分辨率的四分之一。

Result: VDM在多个基准数据集上显著提升了检测精度，如Waymo（74.7 mAPH）、nuScenes（72.9 NDS）、Argoverse 2（42.3 mAP）和ONCE（67.6 mAP）。

Conclusion: VDM通过增强体素级表示和扩散能力，显著提升了基于Transformer和SSM的点云目标检测模型的性能，并在多个基准数据集上实现了最先进的检测精度。

Abstract: Recent advances in point cloud object detection have increasingly adopted
Transformer-based and State Space Models (SSMs), demonstrating strong
performance. However, voxelbased representations in these models require strict
consistency in input and output dimensions due to their serialized processing,
which limits the spatial diffusion capability typically offered by
convolutional operations. This limitation significantly affects detection
accuracy. Inspired by CNN-based object detection architectures, we propose a
novel Voxel Diffusion Module (VDM) to enhance voxel-level representation and
diffusion in point cloud data. VDM is composed of sparse 3D convolutions,
submanifold sparse convolutions, and residual connections. To ensure
computational efficiency, the output feature maps are downsampled to one-fourth
of the original input resolution. VDM serves two primary functions: (1)
diffusing foreground voxel features through sparse 3D convolutions to enrich
spatial context, and (2) aggregating fine-grained spatial information to
strengthen voxelwise feature representation. The enhanced voxel features
produced by VDM can be seamlessly integrated into mainstream Transformer- or
SSM-based detection models for accurate object classification and localization,
highlighting the generalizability of our method. We evaluate VDM on several
benchmark datasets by embedding it into both Transformerbased and SSM-based
models. Experimental results show that our approach consistently improves
detection accuracy over baseline models. Specifically, VDM-SSMs achieve 74.7
mAPH (L2) on Waymo, 72.9 NDS on nuScenes, 42.3 mAP on Argoverse 2, and 67.6 mAP
on ONCE, setting new stateof-the-art performance across all datasets. Our code
will be made publicly available.

</details>


### [21] [Ensemble learning of foundation models for precision oncology](https://arxiv.org/abs/2508.16085)
*Xiangde Luo,Xiyue Wang,Feyisope Eweje,Xiaoming Zhang,Sen Yang,Ryan Quinton,Jinxi Xiang,Yuchen Li,Yuanfeng Ji,Zhe Li,Yijiang Chen,Colin Bergstrom,Ted Kim,Francesca Maria Olguin,Kelley Yuan,Matthew Abikenari,Andrew Heider,Sierra Willens,Sanjeeth Rajaram,Robert West,Joel Neal,Maximilian Diehn,Ruijiang Li*

Main category: cs.CV

TL;DR: ELF通过集成五种病理基础模型，提升了AI在病理学中的性能和泛化能力，尤其在数据有限的临床场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的病理基础模型因训练数据和策略的差异导致性能不一致和泛化能力有限，ELF旨在通过集成学习解决这些问题。

Method: ELF框架利用集成学习方法，从五种不同的病理基础模型中捕获互补信息，同时在53,699张全切片图像上进行高效训练，覆盖20个解剖部位。

Result: 在疾病分类、生物标志物检测和抗癌治疗反应预测等多种临床应用中，ELF均优于所有组成模型和现有幻灯片级模型。

Conclusion: ELF框架通过集成学习整合了五种最先进的病理基础模型，展现出在多种临床应用中优于现有模型的性能和鲁棒性，为AI辅助的精准肿瘤学提供了可扩展和通用的解决方案。

Abstract: Histopathology is essential for disease diagnosis and treatment
decision-making. Recent advances in artificial intelligence (AI) have enabled
the development of pathology foundation models that learn rich visual
representations from large-scale whole-slide images (WSIs). However, existing
models are often trained on disparate datasets using varying strategies,
leading to inconsistent performance and limited generalizability. Here, we
introduce ELF (Ensemble Learning of Foundation models), a novel framework that
integrates five state-of-the-art pathology foundation models to generate
unified slide-level representations. Trained on 53,699 WSIs spanning 20
anatomical sites, ELF leverages ensemble learning to capture complementary
information from diverse models while maintaining high data efficiency. Unlike
traditional tile-level models, ELF's slide-level architecture is particularly
advantageous in clinical contexts where data are limited, such as therapeutic
response prediction. We evaluated ELF across a wide range of clinical
applications, including disease classification, biomarker detection, and
response prediction to major anticancer therapies, cytotoxic chemotherapy,
targeted therapy, and immunotherapy, across multiple cancer types. ELF
consistently outperformed all constituent foundation models and existing
slide-level models, demonstrating superior accuracy and robustness. Our results
highlight the power of ensemble learning for pathology foundation models and
suggest ELF as a scalable and generalizable solution for advancing AI-assisted
precision oncology.

</details>


### [22] [Two-flow Feedback Multi-scale Progressive Generative Adversarial Network](https://arxiv.org/abs/2508.16089)
*Sun Weikai,Song Shijie,Chi Wenjie*

Main category: cs.CV

TL;DR: 本文提出了一种新型 GAN 模型 MSPG-SEN，通过多尺度渐进结构和动态注意力机制，显著提升了图像生成质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在图像生成领域取得了进展，但 GAN 因其独特优势仍有发展空间。本文旨在提升 GAN 模型的图像质量、训练稳定性和效率。

Method: 提出了一种新型的双流反馈多尺度渐进生成对抗网络（MSPG-SEN），包括自适应感知-行为反馈循环（APFL）、全局连接的双流动态残差网络和动态嵌入式注意力机制（DEMA）。

Result: 在五个数据集上实现了高生成质量（INKK 89.7%、AWUN 78.3%、IONJ 85.5%、POKL 88.7%、OPIN 96.4%），并显著降低了计算资源需求。

Conclusion: MSPG-SEN 在五个数据集上实现了最先进的生成结果，显著提升了图像质量和人类视觉感知，同时简化了训练过程并降低了成本。

Abstract: Although diffusion model has made good progress in the field of image
generation, GAN\cite{huang2023adaptive} still has a large development space due
to its unique advantages, such as WGAN\cite{liu2021comparing},
SSGAN\cite{guibas2021adaptive} \cite{zhang2022vsa} \cite{zhou2024adapt} and so
on. In this paper, we propose a novel two-flow feedback multi-scale progressive
generative adversarial network (MSPG-SEN) for GAN models. This paper has four
contributions: 1) : We propose a two-flow feedback multi-scale progressive
Generative Adversarial network (MSPG-SEN), which not only improves image
quality and human visual perception on the basis of retaining the advantages of
the existing GAN model, but also simplifies the training process and reduces
the training cost of GAN networks. Our experimental results show that, MSPG-SEN
has achieved state-of-the-art generation results on the following five
datasets,INKK The dataset is 89.7\%,AWUN The dataset is 78.3\%,IONJ The dataset
is 85.5\%,POKL The dataset is 88.7\%,OPIN The dataset is 96.4\%. 2) : We
propose an adaptive perception-behavioral feedback loop (APFL), which
effectively improves the robustness and training stability of the model and
reduces the training cost. 3) : We propose a globally connected two-flow
dynamic residual network(). After ablation experiments, it can effectively
improve the training efficiency and greatly improve the generalization ability,
with stronger flexibility. 4) : We propose a new dynamic embedded attention
mechanism (DEMA). After experiments, the attention can be extended to a variety
of image processing tasks, which can effectively capture global-local
information, improve feature separation capability and feature expression
capabilities, and requires minimal computing resources only 88.7\% with INJK
With strong cross-task capability.

</details>


### [23] [Domain Adaptation via Feature Refinement](https://arxiv.org/abs/2508.16124)
*Savvas Karatsiolis,Andreas Kamilaris*

Main category: cs.CV

TL;DR: DAFR2是一种简单有效的无监督领域适应框架，通过批归一化统计适应、特征蒸馏和假设转移，实现跨领域特征对齐，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了解决无监督领域适应中分布偏移的问题，DAFR2旨在通过简单有效的框架实现跨领域的特征对齐，无需依赖目标标签或复杂设计。

Method: DAFR2结合了三个关键组件：利用未标记目标数据调整批归一化统计、从源训练模型进行特征蒸馏以及假设转移，通过统计和表示层面的特征分布对齐，生成鲁棒且领域不变的特征空间。

Result: 在CIFAR10-C、CIFAR100-C、MNIST-C和PatchCamelyon-C等基准数据集上的实验表明，DAFR2在抗干扰性方面优于现有方法，同时实现了更好的特征对齐、领域间互信息增加以及对输入扰动的敏感度降低。

Conclusion: DAFR2通过结合批归一化统计适应、特征蒸馏和假设转移，成功实现了无需目标标签、复杂架构或复杂训练目标的跨领域特征对齐，提升了模型在分布偏移下的鲁棒性和泛化能力。

Abstract: We propose Domain Adaptation via Feature Refinement (DAFR2), a simple yet
effective framework for unsupervised domain adaptation under distribution
shift. The proposed method synergistically combines three key components:
adaptation of Batch Normalization statistics using unlabeled target data,
feature distillation from a source-trained model and hypothesis transfer. By
aligning feature distributions at the statistical and representational levels,
DAFR2 produces robust and domain-invariant feature spaces that generalize
across similar domains without requiring target labels, complex architectures
or sophisticated training objectives. Extensive experiments on benchmark
datasets, including CIFAR10-C, CIFAR100-C, MNIST-C and PatchCamelyon-C,
demonstrate that the proposed algorithm outperforms prior methods in robustness
to corruption. Theoretical and empirical analyses further reveal that our
method achieves improved feature alignment, increased mutual information
between the domains and reduced sensitivity to input perturbations.

</details>


### [24] [4D Virtual Imaging Platform for Dynamic Joint Assessment via Uni-Plane X-ray and 2D-3D Registration](https://arxiv.org/abs/2508.16138)
*Hao Tang,Rongxi Yi,Lei Li,Kaiyi Cao,Jiapeng Zhao,Yihan Xiao,Minghai Shi,Peng Yuan,Yan Xi,Hui Tang,Wei Li,Zhan Wu,Yixin Zhou*

Main category: cs.CV

TL;DR: 提出了一种新型4D CBCT平台，结合双机械臂系统和深度学习，实现低剂量、高精度的动态关节成像，适用于生物力学研究和个性化骨科护理。


<details>
  <summary>Details</summary>
Motivation: 传统CT无法捕捉动态负重关节运动，现有4D成像方法存在辐射过高或空间信息不完整的问题。

Method: 结合了（1）双机械臂锥形束CT系统，具有可编程、无龙门架轨迹，优化直立扫描；（2）混合成像流程，通过深度学习预处理、3D-2D投影和迭代优化融合静态3D CBCT与动态2D X射线；（3）临床验证的定量运动学评估框架。

Result: 模拟研究显示，该方法达到亚体素精度（0.235毫米），成功率99.18%，优于传统和最先进的配准方法。临床评估进一步验证了对TKA患者胫骨平台运动和内外侧差异的准确量化。

Conclusion: 该4D CBCT平台实现了快速、准确且低剂量的动态关节成像，为生物力学研究、精准诊断和个性化骨科护理提供了新机会。

Abstract: Conventional computed tomography (CT) lacks the ability to capture dynamic,
weight-bearing joint motion. Functional evaluation, particularly after surgical
intervention, requires four-dimensional (4D) imaging, but current methods are
limited by excessive radiation exposure or incomplete spatial information from
2D techniques. We propose an integrated 4D joint analysis platform that
combines: (1) a dual robotic arm cone-beam CT (CBCT) system with a
programmable, gantry-free trajectory optimized for upright scanning; (2) a
hybrid imaging pipeline that fuses static 3D CBCT with dynamic 2D X-rays using
deep learning-based preprocessing, 3D-2D projection, and iterative
optimization; and (3) a clinically validated framework for quantitative
kinematic assessment. In simulation studies, the method achieved sub-voxel
accuracy (0.235 mm) with a 99.18 percent success rate, outperforming
conventional and state-of-the-art registration approaches. Clinical evaluation
further demonstrated accurate quantification of tibial plateau motion and
medial-lateral variance in post-total knee arthroplasty (TKA) patients. This 4D
CBCT platform enables fast, accurate, and low-dose dynamic joint imaging,
offering new opportunities for biomechanical research, precision diagnostics,
and personalized orthopedic care.

</details>


### [25] [High-Precision Mixed Feature Fusion Network Using Hypergraph Computation for Cervical Abnormal Cell Detection](https://arxiv.org/abs/2508.16140)
*Jincheng Li,Danyang Dong,Menglin Zheng,Jingbo Zhang,Yueqin Hang,Lichi Zhang,Lili Zhao*

Main category: cs.CV

TL;DR: 提出一种基于超图的细胞检测网络，融合空间相关和深度判别特征，显著提升宫颈异常细胞检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有算法未能有效建模视觉特征的相关性，且缺乏融合细胞间相关特征和细胞内判别特征的策略。

Method: 使用多级融合子网络（MLF-SNet）增强特征提取能力，并引入带有超图计算的跨级特征融合策略（CLFFS-HC）来整合混合特征。

Result: 在三个公开数据集上的实验结果表明，该方法显著提高了宫颈异常细胞检测的性能。

Conclusion: 本文提出的基于超图的细胞检测网络通过融合空间相关特征和深度判别特征，显著提升了宫颈异常细胞检测的性能。

Abstract: Automatic detection of abnormal cervical cells from Thinprep Cytologic Test
(TCT) images is a critical component in the development of intelligent
computer-aided diagnostic systems. However, existing algorithms typically fail
to effectively model the correlations of visual features, while these spatial
correlation features actually contain critical diagnostic information.
Furthermore, no detection algorithm has the ability to integrate
inter-correlation features of cells with intra-discriminative features of
cells, lacking a fusion strategy for the end-to-end detection model. In this
work, we propose a hypergraph-based cell detection network that effectively
fuses different types of features, combining spatial correlation features and
deep discriminative features. Specifically, we use a Multi-level Fusion
Sub-network (MLF-SNet) to enhance feature extractioncapabilities. Then we
introduce a Cross-level Feature Fusion Strategy with Hypergraph Computation
module (CLFFS-HC), to integrate mixed features. Finally, we conducted
experiments on three publicly available datasets, and the results demonstrate
that our method significantly improves the performance of cervical abnormal
cell detection.

</details>


### [26] [Beyond Human-prompting: Adaptive Prompt Tuning with Semantic Alignment for Anomaly Detection](https://arxiv.org/abs/2508.16157)
*Pi-Wei Chen,Jerry Chun-Wei Lin,Wei-Han Chen,Jia Ji,Zih-Ching Chen,Feng-Hao Yeh,Chao-Chun Chen*

Main category: cs.CV

TL;DR: APT是一种无需先验知识的少样本异常检测框架，通过自生成异常样本和噪声扰动训练提示，结合SMGS方案实现高性能检测。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的视觉语言模型在异常检测中存在依赖人工设计提示和缺乏异常样本的问题，导致上下文特定的异常理解不足。

Method: 提出APT框架，利用自生成异常样本和噪声扰动训练可学习提示，并引入SMGS方案迭代优化提示与通用异常语义的对齐。

Result: APT在多个基准数据集上实现了最先进的性能，且无需先验知识设计提示。

Conclusion: APT通过自生成异常样本和噪声扰动训练可学习提示，结合SMGS方案，无需先验知识即可在多基准数据集上实现最先进的异常检测性能，为实际应用提供了鲁棒且通用的解决方案。

Abstract: Pre-trained Vision-Language Models (VLMs) have recently shown promise in
detecting anomalies. However, previous approaches are fundamentally limited by
their reliance on human-designed prompts and the lack of accessible anomaly
samples, leading to significant gaps in context-specific anomaly understanding.
In this paper, we propose \textbf{A}daptive \textbf{P}rompt \textbf{T}uning
with semantic alignment for anomaly detection (APT), a groundbreaking prior
knowledge-free, few-shot framework and overcomes the limitations of traditional
prompt-based approaches. APT uses self-generated anomaly samples with noise
perturbations to train learnable prompts that capture context-dependent
anomalies in different scenarios. To prevent overfitting to synthetic noise, we
propose a Self-Optimizing Meta-prompt Guiding Scheme (SMGS) that iteratively
aligns the prompts with general anomaly semantics while incorporating diverse
synthetic anomaly. Our system not only advances pixel-wise anomaly detection,
but also achieves state-of-the-art performance on multiple benchmark datasets
without requiring prior knowledge for prompt crafting, establishing a robust
and versatile solution for real-world anomaly detection.

</details>


### [27] [RAGSR: Regional Attention Guided Diffusion for Image Super-Resolution](https://arxiv.org/abs/2508.16158)
*Haodong He,Yancheng Bai,Rui Lan,Xu Duan,Lei Sun,Xiangxiang Chu,Gui-Song Xia*

Main category: cs.CV

TL;DR: RAGSR通过区域注意力机制和细粒度区域描述，显著提升了多对象场景下的单图像超分辨率效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成清晰准确的区域细节方面存在不足，尤其是在多对象场景中，主要由于缺乏细粒度区域描述和模型对复杂提示的捕捉能力不足。

Method: 提出了一种区域注意力引导的超分辨率（RAGSR）方法，通过提取局部细粒度信息并利用区域注意力机制编码，有效整合文本与图像信息。

Result: 在基准数据集上的实验表明，RAGSR在生成感知真实的视觉细节和保持上下文一致性方面优于现有方法。

Conclusion: RAGSR方法通过区域注意力机制显著提升了单图像超分辨率（SISR）的细节生成能力，尤其在多对象场景中表现出色，实验证明了其优越性。

Abstract: The rich textual information of large vision-language models (VLMs) combined
with the powerful generative prior of pre-trained text-to-image (T2I) diffusion
models has achieved impressive performance in single-image super-resolution
(SISR). However, existing methods still face significant challenges in
generating clear and accurate regional details, particularly in scenarios
involving multiple objects. This challenge primarily stems from a lack of
fine-grained regional descriptions and the models' insufficient ability to
capture complex prompts. To address these limitations, we propose a Regional
Attention Guided Super-Resolution (RAGSR) method that explicitly extracts
localized fine-grained information and effectively encodes it through a novel
regional attention mechanism, enabling both enhanced detail and overall
visually coherent SR results. Specifically, RAGSR localizes object regions in
an image and assigns fine-grained caption to each region, which are formatted
as region-text pairs as textual priors for T2I models. A regional guided
attention is then leveraged to ensure that each region-text pair is properly
considered in the attention process while preventing unwanted interactions
between unrelated region-text pairs. By leveraging this attention mechanism,
our approach offers finer control over the integration of text and image
information, thereby effectively overcoming limitations faced by traditional
SISR techniques. Experimental results on benchmark datasets demonstrate that
our approach exhibits superior performance in generating perceptually authentic
visual details while maintaining contextual consistency compared to existing
approaches.

</details>


### [28] [Through the Looking Glass: A Dual Perspective on Weakly-Supervised Few-Shot Segmentation](https://arxiv.org/abs/2508.16159)
*Jiaqi Ma,Guo-Sen Xie,Fang Zhao,Zechao Li*

Main category: cs.CV

TL;DR: TLG通过异构网络设计在弱监督少样本语义分割任务中显著提升性能，参数效率高，并首次在相同架构下超越全监督模型。


<details>
  <summary>Details</summary>
Motivation: 解决元学习中因相同网络架构导致的过语义同质化问题，提出异构网络设计以提升模型性能。

Method: 提出了一种同源但异构的网络，通过异构视觉聚合（HA）模块增强互补性，同时保留语义共性。设计了异构转移（HT）模块以减少语义噪声并放大异构语义的独特性，并引入异构CLIP（HC）文本信息以增强多模态模型的泛化能力。

Result: TLG在Pascal-5i上提升13.2%，在COCO-20i上提升9.7%，且参数仅为现有最优模型的1/24。

Conclusion: TLG模型在弱监督少样本语义分割任务中表现出色，仅用现有最先进模型1/24的参数，便在Pascal-5i和COCO-20i上分别实现了13.2%和9.7%的提升。此外，TLG是首个在相同骨干架构下超越全监督模型的弱监督模型。

Abstract: Meta-learning aims to uniformly sample homogeneous support-query pairs,
characterized by the same categories and similar attributes, and extract useful
inductive biases through identical network architectures. However, this
identical network design results in over-semantic homogenization. To address
this, we propose a novel homologous but heterogeneous network. By treating
support-query pairs as dual perspectives, we introduce heterogeneous visual
aggregation (HA) modules to enhance complementarity while preserving semantic
commonality. To further reduce semantic noise and amplify the uniqueness of
heterogeneous semantics, we design a heterogeneous transfer (HT) module.
Finally, we propose heterogeneous CLIP (HC) textual information to enhance the
generalization capability of multimodal models. In the weakly-supervised
few-shot semantic segmentation (WFSS) task, with only 1/24 of the parameters of
existing state-of-the-art models, TLG achieves a 13.2\% improvement on
Pascal-5\textsuperscript{i} and a 9.7\% improvement on
COCO-20\textsuperscript{i}. To the best of our knowledge, TLG is also the first
weakly supervised (image-level) model that outperforms fully supervised
(pixel-level) models under the same backbone architectures. The code is
available at https://github.com/jarch-ma/TLG.

</details>


### [29] [FTIO: Frequent Temporally Integrated Objects](https://arxiv.org/abs/2508.16183)
*Mohammad Mohammadzadeh Kalati,Farhad Maleki,Ian McQuillan*

Main category: cs.CV

TL;DR: FTIO框架通过改进对象选择和时间一致性修正，在无监督视频对象分割中表现优异。


<details>
  <summary>Details</summary>
Motivation: 无监督视频对象分割面临初始分割不确定性及时间不一致性的挑战，特别是对象小或结构复杂时。

Method: 提出了一个后处理框架FTIO，包含两个关键组件：改进对象选择标准和三阶段方法修正时间不一致性。

Result: 实验结果表明FTIO在多对象无监督视频对象分割中达到了最先进的性能。

Conclusion: FTIO框架通过改进对象选择标准和修正时间不一致性，在无监督视频对象分割任务中实现了最先进的性能。

Abstract: Predicting and tracking objects in real-world scenarios is a critical
challenge in Video Object Segmentation (VOS) tasks. Unsupervised VOS (UVOS) has
the additional challenge of finding an initial segmentation of salient objects,
which affects the entire process and keeps a permanent uncertainty about the
object proposals. Moreover, deformation and fast motion can lead to temporal
inconsistencies. To address these problems, we propose Frequent Temporally
Integrated Objects (FTIO), a post-processing framework with two key components.
First, we introduce a combined criterion to improve object selection,
mitigating failures common in UVOS--particularly when objects are small or
structurally complex--by extracting frequently appearing salient objects.
Second, we present a three-stage method to correct temporal inconsistencies by
integrating missing object mask regions. Experimental results demonstrate that
FTIO achieves state-of-the-art performance in multi-object UVOS. Code is
available at: https://github.com/MohammadMohammadzadehKalati/FTIO

</details>


### [30] [SpecVLM: Enhancing Speculative Decoding of Video LLMs via Verifier-Guided Token Pruning](https://arxiv.org/abs/2508.16201)
*Yicheng Ji,Jun Zhang,Heming Xia,Jinpeng Chen,Lidan Shou,Gang Chen,Huan Li*

Main category: cs.CV

TL;DR: SpecVLM是一个无需训练的推测解码框架，通过两阶段视频令牌修剪显著加速视频大语言模型的解码过程，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有视频大语言模型依赖密集视频令牌表示，导致内存和计算开销大，且现有视频令牌减少方法存在信息丢失问题。

Method: SpecVLM采用两阶段视频令牌修剪方法：第一阶段根据验证器的注意力信号选择高信息量令牌，第二阶段以空间均匀方式修剪冗余令牌。

Result: 实验表明，SpecVLM在四个视频理解基准测试中表现优异，解码速度提升最高达2.68倍（LLaVA-OneVision-72B）和2.11倍（Qwen2.5-VL-32B）。

Conclusion: SpecVLM通过两阶段视频令牌修剪和推测解码框架，显著提升了视频大语言模型的解码速度，同时保持了准确性。

Abstract: Video large language models (Vid-LLMs) have shown strong capabilities in
understanding video content. However, their reliance on dense video token
representations introduces substantial memory and computational overhead in
both prefilling and decoding. To mitigate the information loss of recent video
token reduction methods and accelerate the decoding stage of Vid-LLMs
losslessly, we introduce SpecVLM, a training-free speculative decoding (SD)
framework tailored for Vid-LLMs that incorporates staged video token pruning.
Building on our novel finding that the draft model's speculation exhibits low
sensitivity to video token pruning, SpecVLM prunes up to 90% of video tokens,
enabling efficient speculation without sacrificing accuracy. To achieve this,
it performs a two-stage pruning process: Stage I selects highly informative
tokens guided by attention signals from the verifier (target model), while
Stage II prunes remaining redundant ones in a spatially uniform manner.
Extensive experiments on four video understanding benchmarks demonstrate the
effectiveness and robustness of SpecVLM, which achieves up to 2.68$\times$
decoding speedup for LLaVA-OneVision-72B and 2.11$\times$ speedup for
Qwen2.5-VL-32B.

</details>


### [31] [\textsc{T-Mask}: Temporal Masking for Probing Foundation Models across Camera Views in Driver Monitoring](https://arxiv.org/abs/2508.16207)
*Thinesh Thiyakesan Ponbagavathi,Kunyu Peng,Alina Roitberg*

Main category: cs.CV

TL;DR: T-Mask是一种新型图像到视频探测方法，通过时间令牌掩码提升驾驶员监控的跨视角性能，尤其在低数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 驾驶员监控中相机视角变化是一个常见挑战，尽管深度学习和预训练基础模型通过轻量级适应（探测）显示出强大的泛化潜力，但对未见视角的鲁棒性仍未被充分探索。

Method: 研究通过线性探测、高级探测策略以及参数高效微调（PEFT）和全微调的比较，评估了两种基础模型（DINOv2和CLIP）的性能。并提出了T-Mask方法，一种利用时间令牌掩码并强调动态视频区域的图像到视频探测方法。

Result: 在公开的Drive&Act数据集上，T-Mask在跨视角top-1准确率上比强探测基线提高了1.23%，比PEFT方法提高了8.0%，且未增加任何参数。对于代表性不足的次要活动，T-Mask在训练视角下识别率提高了5.42%，在跨视角设置下提高了1.36%。

Conclusion: 本研究通过提出T-Mask方法，展示了轻量级探测方法在驾驶员监控中的潜力，特别是在跨视角和低数据场景下。结果表明，在利用基础模型构建鲁棒的驾驶员监控系统时，时间令牌选择的重要性。

Abstract: Changes of camera perspective are a common obstacle in driver monitoring.
While deep learning and pretrained foundation models show strong potential for
improved generalization via lightweight adaptation of the final layers
('probing'), their robustness to unseen viewpoints remains underexplored. We
study this challenge by adapting image foundation models to driver monitoring
using a single training view, and evaluating them directly on unseen
perspectives without further adaptation. We benchmark simple linear probes,
advanced probing strategies, and compare two foundation models (DINOv2 and
CLIP) against parameter-efficient fine-tuning (PEFT) and full fine-tuning.
Building on these insights, we introduce \textsc{T-Mask} -- a new
image-to-video probing method that leverages temporal token masking and
emphasizes more dynamic video regions. Benchmarked on the public Drive\&Act
dataset, \textsc{T-Mask} improves cross-view top-1 accuracy by $+1.23\%$ over
strong probing baselines and $+8.0\%$ over PEFT methods, without adding any
parameters. It proves particularly effective for underrepresented secondary
activities, boosting recognition by $+5.42\%$ under the trained view and
$+1.36\%$ under cross-view settings. This work provides encouraging evidence
that adapting foundation models with lightweight probing methods like
\textsc{T-Mask} has strong potential in fine-grained driver observation,
especially in cross-view and low-data settings. These results highlight the
importance of temporal token selection when leveraging foundation models to
build robust driver monitoring systems. Code and models will be made available
at https://github.com/th-nesh/T-MASK to support ongoing research.

</details>


### [32] [Forecast then Calibrate: Feature Caching as ODE for Efficient Diffusion Transformers](https://arxiv.org/abs/2508.16211)
*Shikang Zheng,Liang Feng,Xinyu Wang,Qinming Zhou,Peiliang Cai,Chang Zou,Jiacheng Liu,Yuqi Lin,Junjie Chen,Yue Ma,Linfeng Zhang*

Main category: cs.CV

TL;DR: FoCa 通过 ODE 视角优化特征缓存，显著提升高加速比下的生成质量，实现高效加速。


<details>
  <summary>Details</summary>
Motivation: 当前的特征缓存技术在加速比过高时难以维持生成质量，预测误差因长步预测的不稳定性而急剧增加。

Method: 采用常微分方程（ODE）视角对隐藏特征序列建模，提出 Forecast-then-Calibrate (FoCa) 方法，将特征缓存转化为特征-ODE 求解问题。

Result: FoCa 在图像合成、视频生成和超分辨率任务中表现优异，尤其是在高加速比下，实现了 5.50 倍（FLUX）、6.45 倍（HunyuanVideo）、3.17 倍（Inf-DiT）和 4.53 倍（DiT）的近乎无损加速。

Conclusion: FoCa 方法通过将特征缓存视为特征-ODE 求解问题，显著提升了高加速比下的生成质量，实现了近乎无损的加速效果。

Abstract: Diffusion Transformers (DiTs) have demonstrated exceptional performance in
high-fidelity image and video generation. To reduce their substantial
computational costs, feature caching techniques have been proposed to
accelerate inference by reusing hidden representations from previous timesteps.
However, current methods often struggle to maintain generation quality at high
acceleration ratios, where prediction errors increase sharply due to the
inherent instability of long-step forecasting. In this work, we adopt an
ordinary differential equation (ODE) perspective on the hidden-feature
sequence, modeling layer representations along the trajectory as a feature-ODE.
We attribute the degradation of existing caching strategies to their inability
to robustly integrate historical features under large skipping intervals. To
address this, we propose FoCa (Forecast-then-Calibrate), which treats feature
caching as a feature-ODE solving problem. Extensive experiments on image
synthesis, video generation, and super-resolution tasks demonstrate the
effectiveness of FoCa, especially under aggressive acceleration. Without
additional training, FoCa achieves near-lossless speedups of 5.50 times on
FLUX, 6.45 times on HunyuanVideo, 3.17 times on Inf-DiT, and maintains high
quality with a 4.53 times speedup on DiT.

</details>


### [33] [OmniCache: A Trajectory-Oriented Global Perspective on Training-Free Cache Reuse for Diffusion Transformer Models](https://arxiv.org/abs/2508.16212)
*Huanpeng Chu,Wei Wu,Guanyu Fen,Yutao Zhang*

Main category: cs.CV

TL;DR: OmniCache是一种无需训练的扩散模型加速方法，通过全局缓存复用和动态噪声过滤，显著提升采样效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成任务中表现优异，但高计算成本限制了其实时部署，需要一种高效加速方法。

Method: 提出OmniCache，一种无需训练的加速方法，通过分析采样轨迹并全局分布缓存复用，动态估计并过滤噪声。

Result: 实验表明，OmniCache在保持生成质量的同时显著加速采样过程。

Conclusion: OmniCache通过全局视角优化缓存策略，有效加速扩散模型的采样过程，同时保持生成质量，为实时部署提供了实用解决方案。

Abstract: Diffusion models have emerged as a powerful paradigm for generative tasks
such as image synthesis and video generation, with Transformer architectures
further enhancing performance. However, the high computational cost of
diffusion Transformers-stemming from a large number of sampling steps and
complex per-step computations-presents significant challenges for real-time
deployment. In this paper, we introduce OmniCache, a training-free acceleration
method that exploits the global redundancy inherent in the denoising process.
Unlike existing methods that determine caching strategies based on inter-step
similarities and tend to prioritize reusing later sampling steps, our approach
originates from the sampling perspective of DIT models. We systematically
analyze the model's sampling trajectories and strategically distribute cache
reuse across the entire sampling process. This global perspective enables more
effective utilization of cached computations throughout the diffusion
trajectory, rather than concentrating reuse within limited segments of the
sampling procedure.In addition, during cache reuse, we dynamically estimate the
corresponding noise and filter it out to reduce its impact on the sampling
direction.Extensive experiments demonstrate that our approach accelerates the
sampling process while maintaining competitive generative quality, offering a
promising and practical solution for efficient deployment of diffusion-based
generative models.

</details>


### [34] [MedOmni-45°: A Safety-Performance Benchmark for Reasoning-Oriented LLMs in Medicine](https://arxiv.org/abs/2508.16213)
*Kaiyuan Ji,Yijin Guo,Zicheng Zhang,Xiangyang Zhu,Yuan Tian,Ning Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: MedOmni-45 Degrees是一个专注于评估医疗大语言模型（LLMs）推理可靠性的基准和工作流程，通过量化安全性和性能的权衡来揭示模型的潜在风险。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在医疗决策支持中的广泛应用，评估其推理的可靠性（如Chain-of-Thought忠实性和反奉承性）变得至关重要。现有基准往往将这些问题简化为单一准确率评分，无法全面反映模型的安全性和性能。

Method: 研究团队开发了MedOmni-45 Degrees基准，包含1,804个涵盖六种专业和三种任务类型的医疗问题，每个问题配以七种操纵性提示和无提示基线，共产生约27K输入。评估了七种LLM，结合准确性、CoT忠实性和反奉承性三个指标，形成综合评分并通过45度图可视化。

Result: 结果显示所有模型均存在安全性与性能的权衡，开源模型QwQ-32B表现最佳（43.81度），但仍未同时领先于安全性和准确性。

Conclusion: MedOmni-45 Degrees为揭示医疗LLM的推理漏洞和指导更安全的模型开发提供了针对性的评估工具。

Abstract: With the increasing use of large language models (LLMs) in medical
decision-support, it is essential to evaluate not only their final answers but
also the reliability of their reasoning. Two key risks are Chain-of-Thought
(CoT) faithfulness -- whether reasoning aligns with responses and medical facts
-- and sycophancy, where models follow misleading cues over correctness.
Existing benchmarks often collapse such vulnerabilities into single accuracy
scores. To address this, we introduce MedOmni-45 Degrees, a benchmark and
workflow designed to quantify safety-performance trade-offs under manipulative
hint conditions. It contains 1,804 reasoning-focused medical questions across
six specialties and three task types, including 500 from MedMCQA. Each question
is paired with seven manipulative hint types and a no-hint baseline, producing
about 27K inputs. We evaluate seven LLMs spanning open- vs. closed-source,
general-purpose vs. medical, and base vs. reasoning-enhanced models, totaling
over 189K inferences. Three metrics -- Accuracy, CoT-Faithfulness, and
Anti-Sycophancy -- are combined into a composite score visualized with a 45
Degrees plot. Results show a consistent safety-performance trade-off, with no
model surpassing the diagonal. The open-source QwQ-32B performs closest (43.81
Degrees), balancing safety and accuracy but not leading in both. MedOmni-45
Degrees thus provides a focused benchmark for exposing reasoning
vulnerabilities in medical LLMs and guiding safer model development.

</details>


### [35] [PromptFlare: Prompt-Generalized Defense via Cross-Attention Decoy in Diffusion-Based Inpainting](https://arxiv.org/abs/2508.16217)
*Hohyun Na,Seunghoo Hong,Simon S. Woo*

Main category: cs.CV

TL;DR: PromptFlare是一种新型对抗保护方法，通过利用交叉注意力机制和注入对抗性噪声，有效防止扩散模型对图像的恶意修改，同时在性能和效率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的高质量图像修改能力引发了对其可能被恶意使用的担忧，现有方法主要依赖图像层面的不一致性，无法有效应对文本提示的影响。

Method: 该方法利用交叉注意力机制，针对提示嵌入的固有特性，通过识别和攻击共享的、不变且语义无信息的标记，注入对抗性噪声以抑制采样过程。

Result: 在EditBench数据集上的广泛实验表明，PromptFlare在各种指标上均达到了最先进的性能。

Conclusion: PromptFlare被证明是一种高效且鲁棒的方法，能够有效防止基于扩散模型的未经授权图像修改，同时显著降低计算开销和GPU内存使用。

Abstract: The success of diffusion models has enabled effortless, high-quality image
modifications that precisely align with users' intentions, thereby raising
concerns about their potential misuse by malicious actors. Previous studies
have attempted to mitigate such misuse through adversarial attacks. However,
these approaches heavily rely on image-level inconsistencies, which pose
fundamental limitations in addressing the influence of textual prompts. In this
paper, we propose PromptFlare, a novel adversarial protection method designed
to protect images from malicious modifications facilitated by diffusion-based
inpainting models. Our approach leverages the cross-attention mechanism to
exploit the intrinsic properties of prompt embeddings. Specifically, we
identify and target shared token of prompts that is invariant and semantically
uninformative, injecting adversarial noise to suppress the sampling process.
The injected noise acts as a cross-attention decoy, diverting the model's focus
away from meaningful prompt-image alignments and thereby neutralizing the
effect of prompt. Extensive experiments on the EditBench dataset demonstrate
that our method achieves state-of-the-art performance across various metrics
while significantly reducing computational overhead and GPU memory usage. These
findings highlight PromptFlare as a robust and efficient protection against
unauthorized image manipulations. The code is available at
https://github.com/NAHOHYUN-SKKU/PromptFlare.

</details>


### [36] [An Investigation of Visual Foundation Models Robustness](https://arxiv.org/abs/2508.16225)
*Sandeep Gupta,Roberto Passerone*

Main category: cs.CV

TL;DR: 本文探讨了视觉基础模型（VFMs）在网络鲁棒性方面的挑战，并提供了评估方法和指标。


<details>
  <summary>Details</summary>
Motivation: 视觉基础模型（VFMs）在计算机视觉任务中广泛应用，但其在安全敏感领域（如生物识别验证、自动驾驶感知和医学图像分析）中的鲁棒性至关重要，需要增强以应对动态环境中的挑战。

Method: 文章研究了计算机视觉系统中适应动态环境所需的网络鲁棒性要求，并探讨了常见的经验防御和鲁棒训练方法。

Result: 研究分析了防御机制相关的挑战，包括网络属性和组件，以指导消融研究和基准测试。

Conclusion: 本文全面分析了视觉基础模型（VFMs）在网络鲁棒性方面的挑战，并提供了指导消融研究和基准测试的指标，以评估网络鲁棒性。

Abstract: Visual Foundation Models (VFMs) are becoming ubiquitous in computer vision,
powering systems for diverse tasks such as object detection, image
classification, segmentation, pose estimation, and motion tracking. VFMs are
capitalizing on seminal innovations in deep learning models, such as LeNet-5,
AlexNet, ResNet, VGGNet, InceptionNet, DenseNet, YOLO, and ViT, to deliver
superior performance across a range of critical computer vision applications.
These include security-sensitive domains like biometric verification,
autonomous vehicle perception, and medical image analysis, where robustness is
essential to fostering trust between technology and the end-users. This article
investigates network robustness requirements crucial in computer vision systems
to adapt effectively to dynamic environments influenced by factors such as
lighting, weather conditions, and sensor characteristics. We examine the
prevalent empirical defenses and robust training employed to enhance vision
network robustness against real-world challenges such as distributional shifts,
noisy and spatially distorted inputs, and adversarial attacks. Subsequently, we
provide a comprehensive analysis of the challenges associated with these
defense mechanisms, including network properties and components to guide
ablation studies and benchmarking metrics to evaluate network robustness.

</details>


### [37] [FlexMUSE: Multimodal Unification and Semantics Enhancement Framework with Flexible interaction for Creative Writing](https://arxiv.org/abs/2508.16230)
*Jiahao Chen,Zhiyong Ma,Wenbiao Du,Qingyuan Chuai*

Main category: cs.CV

TL;DR: FlexMUSE是一个创新的多模态创意写作框架，通过语义对齐和创造性优化，解决了现有方法的不足，并在新数据集ArtMUSE上取得了良好效果。


<details>
  <summary>Details</summary>
Motivation: MMCW是一个全新的、更抽象的挑战，现有方法存在语义不一致和高成本问题，因此需要一种更经济和灵活的方法。

Method: 提出了FlexMUSE框架，包含T2I模块、msaGate、基于注意力的跨模态融合和mscDPO，以增强语义对齐和创造性。

Result: FlexMUSE实现了令人满意的结果，ArtMUSE数据集的发布也推动了MMCW领域的发展。

Conclusion: FlexMUSE在MMCW任务中展示了良好的表现，证明了其在一致性、创造性和连贯性方面的优势。

Abstract: Multi-modal creative writing (MMCW) aims to produce illustrated articles.
Unlike common multi-modal generative (MMG) tasks such as storytelling or
caption generation, MMCW is an entirely new and more abstract challenge where
textual and visual contexts are not strictly related to each other. Existing
methods for related tasks can be forcibly migrated to this track, but they
require specific modality inputs or costly training, and often suffer from
semantic inconsistencies between modalities. Therefore, the main challenge lies
in economically performing MMCW with flexible interactive patterns, where the
semantics between the modalities of the output are more aligned. In this work,
we propose FlexMUSE with a T2I module to enable optional visual input. FlexMUSE
promotes creativity and emphasizes the unification between modalities by
proposing the modality semantic alignment gating (msaGate) to restrict the
textual input. Besides, an attention-based cross-modality fusion is proposed to
augment the input features for semantic enhancement. The modality semantic
creative direct preference optimization (mscDPO) within FlexMUSE is designed by
extending the rejected samples to facilitate the writing creativity. Moreover,
to advance the MMCW, we expose a dataset called ArtMUSE which contains with
around 3k calibrated text-image pairs. FlexMUSE achieves promising results,
demonstrating its consistency, creativity and coherence.

</details>


### [38] [UniEM-3M: A Universal Electron Micrograph Dataset for Microstructural Segmentation and Generation](https://arxiv.org/abs/2508.16239)
*Nan wang,Zhiyi Xia,Yiming Li,Shi Tang,Zuxin Fan,Xi Fang,Haoyi Tao,Xiaochen Cai,Guolin Ke,Linfeng Zhang,Yanhui Hong*

Main category: cs.CV

TL;DR: UniEM-3M是一个大规模多模态电子显微图像数据集，附带生成模型和基准测试，旨在推动材料分析的自动化。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在电子显微图像表征中因大规模、多样化和专家标注数据集稀缺而受阻的问题。

Method: 引入了UniEM-3M数据集，包含5,091张高分辨率电子显微图像、约300万个实例分割标签和图像级属性解耦的文本描述。同时发布了一个文本到图像的扩散模型作为数据增强工具和数据分布代理。

Result: 实验表明，基于流的UniEM-Net模型在挑战性基准测试中优于其他先进方法。

Conclusion: UniEM-3M数据集、生成模型和基准测试的发布将显著加速材料分析的自动化进程。

Abstract: Quantitative microstructural characterization is fundamental to materials
science, where electron micrograph (EM) provides indispensable high-resolution
insights. However, progress in deep learning-based EM characterization has been
hampered by the scarcity of large-scale, diverse, and expert-annotated
datasets, due to acquisition costs, privacy concerns, and annotation
complexity. To address this issue, we introduce UniEM-3M, the first large-scale
and multimodal EM dataset for instance-level understanding. It comprises 5,091
high-resolution EMs, about 3 million instance segmentation labels, and
image-level attribute-disentangled textual descriptions, a subset of which will
be made publicly available. Furthermore, we are also releasing a text-to-image
diffusion model trained on the entire collection to serve as both a powerful
data augmentation tool and a proxy for the complete data distribution. To
establish a rigorous benchmark, we evaluate various representative instance
segmentation methods on the complete UniEM-3M and present UniEM-Net as a strong
baseline model. Quantitative experiments demonstrate that this flow-based model
outperforms other advanced methods on this challenging benchmark. Our
multifaceted release of a partial dataset, a generative model, and a
comprehensive benchmark -- available at huggingface -- will significantly
accelerate progress in automated materials analysis.

</details>


### [39] [Structuring GUI Elements through Vision Language Models: Towards Action Space Generation](https://arxiv.org/abs/2508.16271)
*Yi Xu,Yesheng Zhang,jiajia Liu,Jingdong Chen*

Main category: cs.CV

TL;DR: 本文提出IAML训练范式，通过IoU数据增强和新型训练方法提升MLLMs在GUI元素坐标生成中的精确性。


<details>
  <summary>Details</summary>
Motivation: MLLMs在生成UI元素坐标时因语义空白和传统训练方法的暴露偏差问题而表现不佳。

Method: 提出了一种IoU增强的最大似然（IAML）训练范式，包括基于IoU的坐标采样新流程，用于增强训练数据。

Result: 实验证明IAML方法在性能上优于传统训练范式。

Conclusion: IAML训练范式在提升MLLMs生成UI元素坐标的精确性方面表现出色，优于传统训练方法。

Abstract: Multimodal large language models (MLLMs) have emerged as pivotal tools in
enhancing human-computer interaction. In this paper we focus on the application
of MLLMs in the field of graphical user interface (GUI) elements structuring,
where they assist in processing user instructions based on screen contents.
Despite the promise of MLLMs, their performance in precisely generating UI
element coordinates, a critical aspect of GUI understanding, is hindered by the
nature of next-token prediction training. This challenge arises from the
semantic void surrounding numerical UI coordinates in language representation
spaces, necessitating a substantial and diverse dataset to bolster visual
module capabilities. To address these limitations, we introduce an
IoU-Augmented Maximum Likelihood (IAML) training paradigm. Specifically, our
approach involves a novel pipeline for IoU-based coordinate sampling to augment
the training data, which considers the proximity to ground truth coordinates.
This data augmentation strategy is then employed to fine-tune MLLMs under the
IAML paradigm, which is designed to mitigate the exposure bias problem inherent
in traditional maximum likelihood estimation. Through extensive experiments, we
demonstrate the superior performance of our IAML training approach over
traditional training paradigms.

</details>


### [40] [IRSAMap:Towards Large-Scale, High-Resolution Land Cover Map Vectorization](https://arxiv.org/abs/2508.16272)
*Yu Meng,Ligao Deng,Zhihao Xi,Jiansheng Chen,Jingbo Chen,Anzhi Yue,Diyou Liu,Kai Li,Chenhao Wang,Kaiyu Li,Yupeng Deng,Xian Sun*

Main category: cs.CV

TL;DR: IRSAMap是一个全球遥感数据集，支持大规模、高分辨率、多特征土地覆盖矢量制图，解决了现有数据集的局限性，并推动了地理特征自动化和数字孪生构建。


<details>
  <summary>Details</summary>
Motivation: 随着遥感图像分辨率的提高和深度学习的快速发展，土地覆盖制图正从像素级分割转向基于对象的矢量建模，这要求深度学习模型具备精确的对象边界和拓扑一致性。现有数据集面临类注释有限、数据规模小和缺乏空间结构信息等挑战。

Method: 引入IRSAMap，这是首个用于大规模、高分辨率、多特征土地覆盖矢量制图的全球遥感数据集，具有全面的矢量注释系统、智能注释工作流程、全球覆盖和多任务适应性。

Result: IRSAMap提供了超过180万个实例的10种典型对象（如建筑物、道路、河流）的全面矢量注释系统，全球覆盖6大洲的79个区域，总长度超过1000公里，并支持像素级分类、建筑物轮廓提取、道路中心线提取和全景分割等多任务。

Conclusion: IRSAMap数据集为从像素级分割转向基于对象的矢量建模提供了标准化基准，推动了地理特征自动化和协作建模的发展，对全球地理信息更新和数字孪生构建具有重要价值。

Abstract: With the enhancement of remote sensing image resolution and the rapid
advancement of deep learning, land cover mapping is transitioning from
pixel-level segmentation to object-based vector modeling. This shift demands
more from deep learning models, requiring precise object boundaries and
topological consistency. However, existing datasets face three main challenges:
limited class annotations, small data scale, and lack of spatial structural
information. To overcome these issues, we introduce IRSAMap, the first global
remote sensing dataset for large-scale, high-resolution, multi-feature land
cover vector mapping. IRSAMap offers four key advantages: 1) a comprehensive
vector annotation system with over 1.8 million instances of 10 typical objects
(e.g., buildings, roads, rivers), ensuring semantic and spatial accuracy; 2) an
intelligent annotation workflow combining manual and AI-based methods to
improve efficiency and consistency; 3) global coverage across 79 regions in six
continents, totaling over 1,000 km; and 4) multi-task adaptability for tasks
like pixel-level classification, building outline extraction, road centerline
extraction, and panoramic segmentation. IRSAMap provides a standardized
benchmark for the shift from pixel-based to object-based approaches, advancing
geographic feature automation and collaborative modeling. It is valuable for
global geographic information updates and digital twin construction. The
dataset is publicly available at https://github.com/ucas-dlg/IRSAMap

</details>


### [41] [Robust Small Methane Plume Segmentation in Satellite Imagery](https://arxiv.org/abs/2508.16282)
*Khai Duc Minh Tran,Hoa Van Nguyen,Aimuni Binti Muhammad Rawi,Hareeshrao Athinarayanarao,Ba-Ngu Vo*

Main category: cs.CV

TL;DR: 提出一种结合U-Net和ResNet34的深度学习方法，利用双光谱增强技术，显著提升小规模甲烷羽流检测性能（F1分数78.39%）。


<details>
  <summary>Details</summary>
Motivation: 解决传统遥感技术在检测小规模甲烷羽流（温室气体）方面的局限性，以应对快速气候变化的挑战。

Method: 采用U-Net架构与ResNet34编码器，结合Varon比和Sanchez回归的双光谱增强技术，优化输入特征以提高检测灵敏度。

Result: 在验证集上达到78.39%的F1分数，能够检测小至400平方米的羽流（单像素20米分辨率），在敏感性和精确度上优于现有远程传感技术。

Conclusion: 该论文提出了一种基于U-Net和ResNet34编码器的新型深度学习方法，结合双光谱增强技术，显著提升了甲烷羽流的检测能力，尤其是对小规模羽流的检测效果优于传统方法。

Abstract: This paper tackles the challenging problem of detecting methane plumes, a
potent greenhouse gas, using Sentinel-2 imagery. This contributes to the
mitigation of rapid climate change. We propose a novel deep learning solution
based on U-Net with a ResNet34 encoder, integrating dual spectral enhancement
techniques (Varon ratio and Sanchez regression) to optimise input features for
heightened sensitivity. A key achievement is the ability to detect small plumes
down to 400 m2 (i.e., for a single pixel at 20 m resolution), surpassing
traditional methods limited to larger plumes. Experiments show our approach
achieves a 78.39% F1-score on the validation set, demonstrating superior
performance in sensitivity and precision over existing remote sensing
techniques for automated methane monitoring, especially for small plumes.

</details>


### [42] [EdgeDoc: Hybrid CNN-Transformer Model for Accurate Forgery Detection and Localization in ID Documents](https://arxiv.org/abs/2508.16284)
*Anjith George,Sebastien Marcel*

Main category: cs.CV

TL;DR: EdgeDoc是一种新型文档伪造检测方法，结合轻量级卷积Transformer和辅助噪声特征，在ICCV 2025 DeepID挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 数字文档伪造工具的普及对KYC流程和远程入职系统构成严重威胁，需有效检测伪造以保障服务安全。

Method: 结合轻量级卷积Transformer和从图像中提取的辅助噪声特征，提升对细微篡改的检测能力。

Result: 在FantasyID数据集上超越基线方法，并在ICCV 2025 DeepID挑战中排名第三。

Conclusion: EdgeDoc在真实场景中表现出色，为文档伪造检测提供了有效解决方案。

Abstract: The widespread availability of tools for manipulating images and documents
has made it increasingly easy to forge digital documents, posing a serious
threat to Know Your Customer (KYC) processes and remote onboarding systems.
Detecting such forgeries is essential to preserving the integrity and security
of these services. In this work, we present EdgeDoc, a novel approach for the
detection and localization of document forgeries. Our architecture combines a
lightweight convolutional transformer with auxiliary noiseprint features
extracted from the images, enhancing its ability to detect subtle
manipulations. EdgeDoc achieved third place in the ICCV 2025 DeepID Challenge,
demonstrating its competitiveness. Experimental results on the FantasyID
dataset show that our method outperforms baseline approaches, highlighting its
effectiveness in realworld scenarios. Project page : https://www.idiap.
ch/paper/edgedoc/

</details>


### [43] [A Multimodal-Multitask Framework with Cross-modal Relation and Hierarchical Interactive Attention for Semantic Comprehension](https://arxiv.org/abs/2508.16300)
*Mohammad Zia Ur Rehman,Devraj Raghuvanshi,Umang Jain,Shubhi Bansal,Nagendra Kumar*

Main category: cs.CV

TL;DR: MM-ORIENT框架通过跨模态关系图和HIMA机制减少噪声影响，提升多任务学习效果。


<details>
  <summary>Details</summary>
Motivation: 多模态学习中存在模态内噪声，且传统融合技术可能忽略单模态内的有价值信息。

Method: 提出了跨模态关系图来重建单模态特征以获取多模态表示，并设计了分层交互单模态注意力（HIMA）来聚焦单模态内的关键信息。

Result: 在三个数据集上的实验证明，该方法能有效理解多模态内容并适用于多任务。

Conclusion: MM-ORIENT框架通过跨模态关系图和分层交互注意力机制，有效减少了模态间噪声的影响，并在多任务学习中表现出色。

Abstract: A major challenge in multimodal learning is the presence of noise within
individual modalities. This noise inherently affects the resulting multimodal
representations, especially when these representations are obtained through
explicit interactions between different modalities. Moreover, the multimodal
fusion techniques while aiming to achieve a strong joint representation, can
neglect valuable discriminative information within the individual modalities.
To this end, we propose a Multimodal-Multitask framework with crOss-modal
Relation and hIErarchical iNteractive aTtention (MM-ORIENT) that is effective
for multiple tasks. The proposed approach acquires multimodal representations
cross-modally without explicit interaction between different modalities,
reducing the noise effect at the latent stage. To achieve this, we propose
cross-modal relation graphs that reconstruct monomodal features to acquire
multimodal representations. The features are reconstructed based on the node
neighborhood, where the neighborhood is decided by the features of a different
modality. We also propose Hierarchical Interactive Monomadal Attention (HIMA)
to focus on pertinent information within a modality. While cross-modal relation
graphs help comprehend high-order relationships between two modalities, HIMA
helps in multitasking by learning discriminative features of individual
modalities before late-fusing them. Finally, extensive experimental evaluation
on three datasets demonstrates that the proposed approach effectively
comprehends multimodal content for multiple tasks.

</details>


### [44] [Learning Long-Range Action Representation by Two-Stream Mamba Pyramid Network for Figure Skating Assessment](https://arxiv.org/abs/2508.16291)
*Fengshun Wang,Qiurui Wang,Peilin Zhao*

Main category: cs.CV

TL;DR: 论文提出双流Mamba金字塔网络，分别评估TES和PCS，解决了现有方法的三大挑战，并在FineFS基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在花样滑冰评分中面临三大挑战：未考虑评分标准、未单独评估动作元素、难以处理长视频上下文。

Method: 采用双流Mamba金字塔网络，分别处理基于视觉特征的TES评估流和基于视听特征的PCS评估流，引入多级融合机制和多尺度Mamba金字塔。

Result: 在FineFS基准测试中实现了最先进的性能。

Conclusion: 论文提出的双流Mamba金字塔网络在FineFS基准测试中达到了最先进的性能，有效解决了花样滑冰评分中的三大挑战。

Abstract: Technical Element Score (TES) and Program Component Score (PCS) evaluations
in figure skating demand precise assessment of athletic actions and artistic
interpretation, respectively. Existing methods face three major challenges.
Firstly, video and audio cues are regarded as common features for both TES and
PCS predictions in previous works without considering the prior evaluation
criterion of figure skating. Secondly, action elements in competitions are
separated in time, TES should be derived from each element's score, but
existing methods try to give an overall TES prediction without evaluating each
action element. Thirdly, lengthy competition videos make it difficult and
inefficient to handle long-range contexts. To address these challenges, we
propose a two-stream Mamba pyramid network that aligns with actual judging
criteria to predict TES and PCS by separating visual-feature based TES
evaluation stream from audio-visual-feature based PCS evaluation stream. In the
PCS evaluation stream, we introduce a multi-level fusion mechanism to guarantee
that video-based features remain unaffected when assessing TES, and enhance PCS
estimation by fusing visual and auditory cues across each contextual level of
the pyramid. In the TES evaluation stream, the multi-scale Mamba pyramid and
TES head we proposed effectively address the challenges of localizing and
evaluating action elements with various temporal scales and give score
predictions. With Mamba's superior ability to capture long-range dependencies
and its linear computational complexity, our method is ideal for handling
lengthy figure skating videos. Comprehensive experimentation demonstrates that
our framework attains state-of-the-art performance on the FineFS benchmark. Our
source code is available at
https://github.com/ycwfs/Figure-Skating-Action-Quality-Assessment.

</details>


### [45] [Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers](https://arxiv.org/abs/2508.16311)
*Lucas Maisonnave,Karim Haroun,Tom Pegeot*

Main category: cs.CV

TL;DR: EAM通过量化低熵注意力头减少计算和内存需求，保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 分析注意力头的信息冗余，发现低熵注意力头贡献较少信息，从而提出针对性压缩策略。

Method: 提出Entropy Attention Maps (EAM)模型，通过量化低熵注意力头来减少冗余计算。

Result: 在ImageNet-1k上验证，EAM在注意力图稀疏度≤20%时保持或提升精度，对DeiT和Swin Transformer模型表现竞争性。

Conclusion: EAM模型通过冻结低熵注意力头并进行低精度量化，有效减少了计算和内存需求，同时保持了模型性能。

Abstract: Transformer models rely on Multi-Head Self-Attention (MHSA) mechanisms, where
each attention head contributes to the final representation. However, their
computational complexity and high memory demands due to MHSA hinders their
deployment at the edge. In this work, we analyze and exploit information
redundancy in attention maps to accelerate model inference. By quantifying the
information captured by each attention head using Shannon entropy, our analysis
reveals that attention heads with lower entropy, i.e., exhibiting more
deterministic behavior, tend to contribute less information, motivating
targeted compression strategies. Relying on these insights, we propose Entropy
Attention Maps (EAM), a model that freezes the weights of low-entropy attention
maps and quantizes these values to low precision to avoid redundant
re-computation. Empirical validation on ImageNet-1k shows that EAM achieves
similar or higher accuracy at $\leq$20\% sparsity in attention maps and
competitive performance beyond this level for the DeiT and Swin Transformer
models.

</details>


### [46] [Enhanced Hybrid Technique for Efficient Digitization of Handwritten Marksheets](https://arxiv.org/abs/2508.16295)
*Junaid Ahmed Sifat,Abir Chowdhury,Hasnat Md. Imtiaz,Md. Irtiza Hossain,Md. Imran Bin Azad*

Main category: cs.CV

TL;DR: 该论文提出了一种结合OpenCV和PaddleOCR的混合方法，用于手写成绩单的数字化，改进版YOLOv8表现最佳，准确率达92.72%。


<details>
  <summary>Details</summary>
Motivation: 手写成绩单等文档的数字化面临手写风格多样和表格结构复杂的挑战，需要高效且准确的解决方案。

Method: 提出了一种混合方法，结合OpenCV进行表格检测，PaddleOCR和YOLOv8（包括改进版）进行手写文本识别。

Result: 改进版YOLOv8在自定义数据集上达到92.72%的准确率，优于PaddleOCR（91.37%）和原始YOLOv8（88.91%）。

Conclusion: 该研究为手写文档理解领域提供了可操作且可靠的方法，通过集成和优化技术，实现了高效、准确的数字化解决方案。

Abstract: The digitization of handwritten marksheets presents huge challenges due to
the different styles of handwriting and complex table structures in such
documents like marksheets. This work introduces a hybrid method that integrates
OpenCV for table detection and PaddleOCR for recognizing sequential handwritten
text. The image processing capabilities of OpenCV efficiently detects rows and
columns which enable computationally lightweight and accurate table detection.
Additionally, YOLOv8 and Modified YOLOv8 are implemented for handwritten text
recognition within the detected table structures alongside PaddleOCR which
further enhance the system's versatility. The proposed model achieves high
accuracy on our custom dataset which is designed to represent different and
diverse handwriting styles and complex table layouts. Experimental results
demonstrate that YOLOv8 Modified achieves an accuracy of 92.72 percent,
outperforming PaddleOCR 91.37 percent and the YOLOv8 model 88.91 percent. This
efficiency reduces the necessity for manual work which makes this a practical
and fast solution for digitizing academic as well as administrative documents.
This research serves the field of document automation, particularly handwritten
document understanding, by providing operational and reliable methods to scale,
enhance, and integrate the technologies involved.

</details>


### [47] [A Lightweight Group Multiscale Bidirectional Interactive Network for Real-Time Steel Surface Defect Detection](https://arxiv.org/abs/2508.16397)
*Yong Zhang,Cunjian Chen,Qiang Gao,Yi Wang,Bin Fang*

Main category: cs.CV

TL;DR: GMBINet通过创新的GMBI模块解决了现有方法在实时表面缺陷检测中的计算复杂度和速度问题，实现了高准确率和实时性能，并展示了强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在钢铁制造行业的实时表面缺陷检测中存在计算复杂度高和推理速度慢的问题，限制了其在资源受限的工业环境中的部署。

Method: 提出了GMBINet框架，采用Group Multiscale Bidirectional Interactive (GMBI)模块，结合Bidirectional Progressive Feature Interactor (BPFI)和参数自由的Element-Wise Multiplication-Summation (EWMS)操作，以增强多尺度特征提取和交互。

Result: 在SD-Saliency-900和NRSD-MN数据集上，GMBINet在512分辨率下实现了1048 FPS（GPU）和16.53 FPS（CPU）的实时速度，仅使用0.19 M参数。在NEU-CLS缺陷分类数据集上的进一步评估验证了其泛化能力。

Conclusion: GMBINet在保持实时速度的同时，提供了竞争力的准确率，并在多个数据集上展示了其强大的泛化能力，具有广泛的工业视觉应用潜力。

Abstract: Real-time surface defect detection is critical for maintaining product
quality and production efficiency in the steel manufacturing industry. Despite
promising accuracy, existing deep learning methods often suffer from high
computational complexity and slow inference speeds, which limit their
deployment in resource-constrained industrial environments. Recent lightweight
approaches adopt multibranch architectures based on depthwise separable
convolution (DSConv) to capture multiscale contextual information. However,
these methods often suffer from increased computational overhead and lack
effective cross-scale feature interaction, limiting their ability to fully
leverage multiscale representations. To address these challenges, we propose
GMBINet, a lightweight framework that enhances multiscale feature extraction
and interaction through novel Group Multiscale Bidirectional Interactive (GMBI)
modules. The GMBI adopts a group-wise strategy for multiscale feature
extraction, ensuring scale-agnostic computational complexity. It further
integrates a Bidirectional Progressive Feature Interactor (BPFI) and a
parameter-free Element-Wise Multiplication-Summation (EWMS) operation to
enhance cross-scale interaction without introducing additional computational
overhead. Experiments on SD-Saliency-900 and NRSD-MN datasets demonstrate that
GMBINet delivers competitive accuracy with real-time speeds of 1048 FPS on GPU
and 16.53 FPS on CPU at 512 resolution, using only 0.19 M parameters.
Additional evaluations on the NEU-CLS defect classification dataset further
confirm the strong generalization ability of our method, demonstrating its
potential for broader industrial vision applications beyond surface defect
detection. The dataset and code are publicly available at:
https://github.com/zhangyongcode/GMBINet.

</details>


### [48] [Vision encoders should be image size agnostic and task driven](https://arxiv.org/abs/2508.16317)
*Nedyalko Prisadnikov,Danda Pani Paudel,Yuqian Fu,Luc Van Gool*

Main category: cs.CV

TL;DR: 论文主张下一代视觉编码器应具备图像大小无关性和任务驱动性，借鉴生物视觉的效率行为，提出并验证了一种动态计算方案。


<details>
  <summary>Details</summary>
Motivation: 现代视觉编码器在效率上不及生物视觉，尤其是在处理大量视觉数据时，生物能根据任务动态调整关注点。论文旨在推动视觉编码器向这一方向发展。

Method: 通过借鉴生物视觉的行为特征——效率，提出了一种动态计算复杂度取决于任务而非图像大小的概念验证方案。

Result: 论文提出的方法在图像分类任务中验证了其可行性和潜力，尽管分类任务并不能完全代表其目标。

Conclusion: 该立场论文认为，下一代视觉编码器应具备图像大小无关性和任务驱动性，其概念验证方案在图像分类任务中展示了可行性和前景。

Abstract: This position paper argues that the next generation of vision encoders should
be image size agnostic and task driven. The source of our inspiration is
biological. Not a structural aspect of biological vision, but a behavioral
trait -- efficiency. We focus on a couple of ways in which vision in nature is
efficient, but modern vision encoders not. We -- humans and animals -- deal
with vast quantities of visual data, and need to be smart where we focus our
limited energy -- it depends on the task. It is our belief that vision encoders
should be dynamic and the computational complexity should depend on the task at
hand rather than the size of the image. We, also, provide concrete first steps
towards our vision -- a proof-of-concept solution for image classification.
Despite classification being not very representative for what we are trying to
achieve, it shows that our approach is feasible and promising.

</details>


### [49] [Towards Open World Detection: A Survey](https://arxiv.org/abs/2508.16527)
*Andrei-Stefan Bulzan,Cosmin Cernazanu-Glavan*

Main category: cs.CV

TL;DR: 本文提出Open World Detection（OWD）作为统一视觉领域检测模型的术语，探讨了视觉子领域的历史、现状和未来融合趋势。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉的初始局限性导致了高度专业化领域的发展。随着各任务的成功和研究进展，越来越复杂的感知任务出现。本文旨在探讨这些任务的融合趋势，并引入OWD作为统一术语。

Method: 文章从视觉子领域的历史出发，涵盖了从早期显著性检测、前景/背景分离、分布外检测到开放世界目标检测、零样本检测和视觉大语言模型（VLLMs）的关键概念、方法论和数据集。

Result: 文章展示了视觉子领域之间的重叠、它们日益增长的融合趋势，以及未来可能统一为一个感知领域的潜力。

Conclusion: 本文提出了Open World Detection（OWD）作为一个统一术语，旨在整合视觉领域中的类别无关和普遍适用的检测模型。文章探讨了视觉子领域的历史、关键概念、方法论和数据集，并展望了这些子领域未来可能融合为一个统一的感知领域。

Abstract: For decades, Computer Vision has aimed at enabling machines to perceive the
external world. Initial limitations led to the development of highly
specialized niches. As success in each task accrued and research progressed,
increasingly complex perception tasks emerged. This survey charts the
convergence of these tasks and, in doing so, introduces Open World Detection
(OWD), an umbrella term we propose to unify class-agnostic and generally
applicable detection models in the vision domain. We start from the history of
foundational vision subdomains and cover key concepts, methodologies and
datasets making up today's state-of-the-art landscape. This traverses topics
starting from early saliency detection, foreground/background separation, out
of distribution detection and leading up to open world object detection,
zero-shot detection and Vision Large Language Models (VLLMs). We explore the
overlap between these subdomains, their increasing convergence, and their
potential to unify into a singular domain in the future, perception.

</details>


### [50] [Attention Mechanism in Randomized Time Warping](https://arxiv.org/abs/2508.16366)
*Yutaro Hiraoka,Kazuya Okamura,Kota Suto,Kazuhiro Fukui*

Main category: cs.CV

TL;DR: RTW可视为一种自注意力机制，其全局操作优于Transformer的局部操作，性能提升5%。


<details>
  <summary>Details</summary>
Motivation: 揭示RTW与Transformer自注意力机制的相似性，并展示RTW在全局操作上的优势。

Method: 将RTW解释为一种自注意力机制，并通过比较RTW与Transformer自注意力的权重模式来验证其相似性。

Result: RTW与Transformer自注意力的权重模式高度相似（平均相关性0.80），但RTW在全局操作上更高效，性能提升5%。

Conclusion: RTW与Transformer的自注意力机制在功能上相似，但RTW通过全局操作在性能上优于Transformer，在Something-Something V2数据集上实现了5%的性能提升。

Abstract: This paper reveals that we can interpret the fundamental function of
Randomized Time Warping (RTW) as a type of self-attention mechanism, a core
technology of Transformers in motion recognition. The self-attention is a
mechanism that enables models to identify and weigh the importance of different
parts of an input sequential pattern. On the other hand, RTW is a general
extension of Dynamic Time Warping (DTW), a technique commonly used for matching
and comparing sequential patterns. In essence, RTW searches for optimal
contribution weights for each element of the input sequential patterns to
produce discriminative features. Although the two approaches look different,
these contribution weights can be interpreted as self-attention weights. In
fact, the two weight patterns look similar, producing a high average
correlation of 0.80 across the ten smallest canonical angles. However, they
work in different ways: RTW attention operates on an entire input sequential
pattern, while self-attention focuses on only a local view which is a subset of
the input sequential pattern because of the computational costs of the
self-attention matrix. This targeting difference leads to an advantage of RTW
against Transformer, as demonstrated by the 5\% performance improvement on the
Something-Something V2 dataset.

</details>


### [51] [MV-RAG: Retrieval Augmented Multiview Diffusion](https://arxiv.org/abs/2508.16577)
*Yosef Dayani,Omer Benishu,Sagie Benaim*

Main category: cs.CV

TL;DR: MV-RAG通过检索相关2D图像并训练多视角扩散模型，显著提升了文本到3D生成在OOD/罕见概念上的表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到3D生成方法在处理OOD或罕见概念时产生不一致或不准确结果的问题。

Method: 提出了一种新颖的混合训练策略，结合结构化多视角数据和多样化的2D图像集合，通过增强条件视图模拟检索方差进行视图特定重建，并使用独特的保留视图预测目标训练模型。

Result: 实验表明，MV-RAG在OOD/罕见概念上显著优于现有文本到3D、图像到3D和个性化基线方法。

Conclusion: MV-RAG显著提高了OOD/罕见概念的3D一致性、照片真实性和文本遵循性，同时在标准基准测试中保持竞争力。

Abstract: Text-to-3D generation approaches have advanced significantly by leveraging
pretrained 2D diffusion priors, producing high-quality and 3D-consistent
outputs. However, they often fail to produce out-of-domain (OOD) or rare
concepts, yielding inconsistent or inaccurate results. To this end, we propose
MV-RAG, a novel text-to-3D pipeline that first retrieves relevant 2D images
from a large in-the-wild 2D database and then conditions a multiview diffusion
model on these images to synthesize consistent and accurate multiview outputs.
Training such a retrieval-conditioned model is achieved via a novel hybrid
strategy bridging structured multiview data and diverse 2D image collections.
This involves training on multiview data using augmented conditioning views
that simulate retrieval variance for view-specific reconstruction, alongside
training on sets of retrieved real-world 2D images using a distinctive held-out
view prediction objective: the model predicts the held-out view from the other
views to infer 3D consistency from 2D data. To facilitate a rigorous OOD
evaluation, we introduce a new collection of challenging OOD prompts.
Experiments against state-of-the-art text-to-3D, image-to-3D, and
personalization baselines show that our approach significantly improves 3D
consistency, photorealism, and text adherence for OOD/rare concepts, while
maintaining competitive performance on standard benchmarks.

</details>


### [52] [SAMFusion: Sensor-Adaptive Multimodal Fusion for 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2508.16408)
*Edoardo Palladin,Roland Dietze,Praveen Narayanan,Mario Bijelic,Felix Heide*

Main category: cs.CV

TL;DR: 提出了一种新型多模态传感器融合方法，专为恶劣天气设计，融合多种传感器数据并通过注意力机制优化检测，显著提升自动驾驶车辆在挑战性天气条件下的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有融合方法在恶劣天气（如浓雾、雪或污染）下表现不佳，需要一种能够适应这些条件的多模态传感器融合方法。

Method: 通过基于注意力的深度混合方案和鸟类视角（BEV）平面上的学习细化，融合RGB、LiDAR、NIR门控相机和雷达模态数据，并使用变压器解码器根据距离和可见性加权模态进行检测预测。

Result: 在长距离和挑战性雾天场景中，对易受伤害行人的检测平均精度（AP）提高了17.2 AP，优于其他方法。

Conclusion: 该方法在恶劣天气条件下显著提升了多模态传感器融合的可靠性，填补了理想条件与现实边缘案例之间的差距。

Abstract: Multimodal sensor fusion is an essential capability for autonomous robots,
enabling object detection and decision-making in the presence of failing or
uncertain inputs. While recent fusion methods excel in normal environmental
conditions, these approaches fail in adverse weather, e.g., heavy fog, snow, or
obstructions due to soiling. We introduce a novel multi-sensor fusion approach
tailored to adverse weather conditions. In addition to fusing RGB and LiDAR
sensors, which are employed in recent autonomous driving literature, our sensor
fusion stack is also capable of learning from NIR gated camera and radar
modalities to tackle low light and inclement weather. We fuse multimodal sensor
data through attentive, depth-based blending schemes, with learned refinement
on the Bird's Eye View (BEV) plane to combine image and range features
effectively. Our detections are predicted by a transformer decoder that weighs
modalities based on distance and visibility. We demonstrate that our method
improves the reliability of multimodal sensor fusion in autonomous vehicles
under challenging weather conditions, bridging the gap between ideal conditions
and real-world edge cases. Our approach improves average precision by 17.2 AP
compared to the next best method for vulnerable pedestrians in long distances
and challenging foggy scenes. Our project page is available at
https://light.princeton.edu/samfusion/

</details>


### [53] [HAMSt3R: Human-Aware Multi-view Stereo 3D Reconstruction](https://arxiv.org/abs/2508.16433)
*Sara Rojas,Matthieu Armando,Bernard Ghamen,Philippe Weinzaepfel,Vincent Leroy,Gregory Rogez*

Main category: cs.CV

TL;DR: HAMSt3R是一种新方法，通过结合场景和人类理解，从稀疏未校准图像中实现高效的人类和场景3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在人类中心场景中的不足，如DUSt3R和MASt3R主要针对静态户外场景，难以处理人类中心环境。

Method: 利用DUNE图像编码器，结合MASt3R和multi-HMR的编码器，通过额外的网络头部分割人类、估计密集对应关系（DensePose）和预测深度，生成富含人类语义信息的3D密集点图。

Result: 在EgoHumans和EgoExo4D等挑战性基准测试中表现优异，同时在传统多视角立体重建和姿态回归任务中验证了其泛化能力。

Conclusion: HAMSt3R成功地在稀疏、未校准的多视角图像中实现了人类和场景的联合3D重建，同时在传统多视角立体重建和姿态回归任务中保持了强大性能，弥合了人类与场景理解之间的鸿沟。

Abstract: Recovering the 3D geometry of a scene from a sparse set of uncalibrated
images is a long-standing problem in computer vision. While recent
learning-based approaches such as DUSt3R and MASt3R have demonstrated
impressive results by directly predicting dense scene geometry, they are
primarily trained on outdoor scenes with static environments and struggle to
handle human-centric scenarios. In this work, we introduce HAMSt3R, an
extension of MASt3R for joint human and scene 3D reconstruction from sparse,
uncalibrated multi-view images. First, we exploit DUNE, a strong image encoder
obtained by distilling, among others, the encoders from MASt3R and from a
state-of-the-art Human Mesh Recovery (HMR) model, multi-HMR, for a better
understanding of scene geometry and human bodies. Our method then incorporates
additional network heads to segment people, estimate dense correspondences via
DensePose, and predict depth in human-centric environments, enabling a more
comprehensive 3D reconstruction. By leveraging the outputs of our different
heads, HAMSt3R produces a dense point map enriched with human semantic
information in 3D. Unlike existing methods that rely on complex optimization
pipelines, our approach is fully feed-forward and efficient, making it suitable
for real-world applications. We evaluate our model on EgoHumans and EgoExo4D,
two challenging benchmarks con taining diverse human-centric scenarios.
Additionally, we validate its generalization to traditional multi-view stereo
and multi-view pose regression tasks. Our results demonstrate that our method
can reconstruct humans effectively while preserving strong performance in
general 3D reconstruction tasks, bridging the gap between human and scene
understanding in 3D vision.

</details>


### [54] [Arbitrary-Scale 3D Gaussian Super-Resolution](https://arxiv.org/abs/2508.16467)
*Huimin Zeng,Yue Bai,Yun Fu*

Main category: cs.CV

TL;DR: 该论文提出了一种支持任意比例因子3D高斯超分辨率渲染的集成框架，结合尺度感知和生成先验优化，实现了高质量实时渲染。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅（3DGS）超分辨率方法通常仅支持固定比例因子的高分辨率（HR）渲染，限制了其在资源受限场景的实用性。直接渲染任意比例的HR视图会因缺乏尺度感知能力而产生锯齿伪影，而添加后处理上采样器会增加框架复杂度并降低渲染效率。

Method: 通过结合尺度感知渲染、生成先验引导优化和渐进式超分辨率技术，构建了一个支持整数和非整数比例渲染的单一3D模型。

Result: 实验证明，该方法在渲染高质量任意比例HR视图方面表现优异（比3DGS提高6.59 dB PSNR），同时保持与低分辨率（LR）视图的结构一致性，并支持不同比例之间的渲染一致性。

Conclusion: 该论文提出了一种集成框架，能够实现任意比例因子的3D高斯超分辨率渲染，且保持实时渲染速度（1080p下85 FPS）。

Abstract: Existing 3D Gaussian Splatting (3DGS) super-resolution methods typically
perform high-resolution (HR) rendering of fixed scale factors, making them
impractical for resource-limited scenarios. Directly rendering arbitrary-scale
HR views with vanilla 3DGS introduces aliasing artifacts due to the lack of
scale-aware rendering ability, while adding a post-processing upsampler for
3DGS complicates the framework and reduces rendering efficiency. To tackle
these issues, we build an integrated framework that incorporates scale-aware
rendering, generative prior-guided optimization, and progressive
super-resolving to enable 3D Gaussian super-resolution of arbitrary scale
factors with a single 3D model. Notably, our approach supports both integer and
non-integer scale rendering to provide more flexibility. Extensive experiments
demonstrate the effectiveness of our model in rendering high-quality
arbitrary-scale HR views (6.59 dB PSNR gain over 3DGS) with a single model. It
preserves structural consistency with LR views and across different scales,
while maintaining real-time rendering speed (85 FPS at 1080p).

</details>


### [55] [Seeing Clearly, Forgetting Deeply: Revisiting Fine-Tuned Video Generators for Driving Simulation](https://arxiv.org/abs/2508.16512)
*Chun-Peng Chang,Chen-Yu Wang,Julian Schmidt,Holger Caesar,Alain Pagani*

Main category: cs.CV

TL;DR: 研究发现微调视频生成模型在驾驶场景中可能牺牲动态准确性以提升视觉质量，持续学习策略可平衡两者。


<details>
  <summary>Details</summary>
Motivation: 视频生成模型在自动驾驶等应用中具有潜力，但现有微调方法可能导致动态元素的空间准确性下降，因此需要探索平衡视觉质量与动态准确性的方法。

Method: 研究探讨了现有微调视频生成方法对结构化驾驶数据集的影响，并分析了视觉质量与动态理解目标之间的对齐变化。通过实验验证了持续学习策略的有效性。

Result: 微调方法在驾驶场景中虽提升视觉质量，但可能降低动态元素的空间准确性。持续学习策略（如多样域回放）能够平衡两者。

Conclusion: 研究发现，在驾驶场景中，微调视频生成模型可能会在视觉保真度和动态元素的空间准确性之间产生权衡。通过简单的持续学习策略（如多样域回放）可以在保持视觉质量的同时平衡空间准确性。

Abstract: Recent advancements in video generation have substantially improved visual
quality and temporal coherence, making these models increasingly appealing for
applications such as autonomous driving, particularly in the context of driving
simulation and so-called "world models". In this work, we investigate the
effects of existing fine-tuning video generation approaches on structured
driving datasets and uncover a potential trade-off: although visual fidelity
improves, spatial accuracy in modeling dynamic elements may degrade. We
attribute this degradation to a shift in the alignment between visual quality
and dynamic understanding objectives. In datasets with diverse scene structures
within temporal space, where objects or perspective shift in varied ways, these
objectives tend to highly correlated. However, the very regular and repetitive
nature of driving scenes allows visual quality to improve by modeling dominant
scene motion patterns, without necessarily preserving fine-grained dynamic
behavior. As a result, fine-tuning encourages the model to prioritize
surface-level realism over dynamic accuracy. To further examine this
phenomenon, we show that simple continual learning strategies, such as replay
from diverse domains, can offer a balanced alternative by preserving spatial
accuracy while maintaining strong visual quality.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [56] [A Systematic Literature Review of Machine Learning Approaches for Migrating Monolithic Systems to Microservices](https://arxiv.org/abs/2508.15941)
*Imen Trabelsi,Brahim Mahmoudi,Jean Baptiste Minani,Naouel Moha,Yann-Gaël Guéhéneuc*

Main category: cs.SE

TL;DR: 论文通过系统性文献综述总结了机器学习在单体系统向微服务迁移中的应用，发现部分迁移阶段研究充分而其他阶段未探索，并指出了数据、工具和标准化等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于单体系统向微服务迁移的复杂性和资源密集性，机器学习（ML）可以自动化部分迁移阶段，但如何选择合适的ML方法仍缺乏系统性研究。

Method: 采用系统性文献综述（SLR）方法，遵循PRISMA声明，对81项主要研究进行数据提取和分析，回答研究问题（RQs），并形成分类框架。

Result: 研究发现微服务迁移的某些阶段（如监控和服务识别）已有较多研究，而其他阶段（如微服务打包）尚未探索；同时指出了数据不足、可扩展性限制、工具支持不足和缺乏标准化基准等挑战。

Conclusion: 论文通过系统性文献综述（SLR）总结了2015年至2024年间81项主要研究中使用的机器学习方法，揭示了微服务迁移过程中不同阶段的研究现状和挑战，强调了需要更全面的解决方案。

Abstract: Scalability and maintainability challenges in monolithic systems have led to
the adoption of microservices, which divide systems into smaller, independent
services. However, migrating existing monolithic systems to microservices is a
complex and resource-intensive task, which can benefit from machine learning
(ML) to automate some of its phases. Choosing the right ML approach for
migration remains challenging for practitioners. Previous works studied
separately the objectives, artifacts, techniques, tools, and benefits and
challenges of migrating monolithic systems to microservices. No work has yet
investigated systematically existing ML approaches for this migration to
understand the \revised{automated migration phases}, inputs used, ML techniques
applied, evaluation processes followed, and challenges encountered. We present
a systematic literature review (SLR) that aggregates, synthesises, and
discusses the approaches and results of 81 primary studies (PSs) published
between 2015 and 2024. We followed the Preferred Reporting Items for Systematic
Review and Meta-Analysis (PRISMA) statement to report our findings and answer
our research questions (RQs). We extract and analyse data from these PSs to
answer our RQs. We synthesise the findings in the form of a classification that
shows the usage of ML techniques in migrating monolithic systems to
microservices. The findings reveal that some phases of the migration process,
such as monitoring and service identification, are well-studied, while others,
like packaging microservices, remain unexplored. Additionally, the findings
highlight key challenges, including limited data availability, scalability and
complexity constraints, insufficient tool support, and the absence of
standardized benchmarking, emphasizing the need for more holistic solutions.

</details>


### [57] [Breaking Barriers in Software Testing: The Power of AI-Driven Automation](https://arxiv.org/abs/2508.16025)
*Saba Naqvi,Mohammad Baqar*

Main category: cs.SE

TL;DR: AI驱动的测试框架结合NLP和RL，自动化生成和优化测试用例，显著提升测试效率和软件质量。


<details>
  <summary>Details</summary>
Motivation: 传统软件测试方法速度慢、成本高且覆盖范围存在漏洞，亟需一种更高效、可靠的方法来提升测试效率和软件质量。

Method: 本文提出了一种结合自然语言处理（NLP）、强化学习（RL）和预测模型的AI驱动框架，通过策略驱动的信任和公平模型，自动化生成和验证测试用例。

Result: 案例研究表明，该框架在缺陷检测、减少测试工作量和加快发布周期方面取得了显著成效，证明了AI增强测试在效率和可靠性上的双重提升。

Conclusion: 该框架通过解决集成和可扩展性挑战，展示了AI如何将测试从被动、手动过程转变为主动、自适应系统，从而在日益复杂的环境中增强软件质量。

Abstract: Software testing remains critical for ensuring reliability, yet traditional
approaches are slow, costly, and prone to gaps in coverage. This paper presents
an AI-driven framework that automates test case generation and validation using
natural language processing (NLP), reinforcement learning (RL), and predictive
models, embedded within a policy-driven trust and fairness model. The approach
translates natural language requirements into executable tests, continuously
optimizes them through learning, and validates outcomes with real-time analysis
while mitigating bias. Case studies demonstrate measurable gains in defect
detection, reduced testing effort, and faster release cycles, showing that
AI-enhanced testing improves both efficiency and reliability. By addressing
integration and scalability challenges, the framework illustrates how AI can
shift testing from a reactive, manual process to a proactive, adaptive system
that strengthens software quality in increasingly complex environments.

</details>


### [58] [Measuring the effectiveness of code review comments in GitHub repositories: A machine learning approach](https://arxiv.org/abs/2508.16053)
*Shadikur Rahman,Umme Ayman Koana,Hasibul Karim Shanto,Mahmuda Akter,Chitra Roy,Aras M. Ismael*

Main category: cs.SE

TL;DR: 本研究比较了七种机器学习算法在分类GitHub代码审查评论情感极性中的表现，发现线性SVC准确率最高，有助于减少开发中的误解。


<details>
  <summary>Details</summary>
Motivation: 代码审查是软件开发中的重要环节，准确分类代码审查评论的情感极性有助于避免误解和错误，提高开发效率。

Method: 研究使用了七种机器学习算法对来自GitHub三个开源项目的13557条代码审查评论进行分类，并比较了这些算法的性能。

Result: 线性支持向量分类器（SVC）在分类代码审查文本情感极性时表现最佳，准确率高于其他六种算法。

Conclusion: 本研究通过实证分析，证明了线性支持向量分类器（SVC）在分类代码审查文本情感极性时具有较高的准确性，有助于程序员基于代码审查做出更准确的决策。

Abstract: This paper illustrates an empirical study of the working efficiency of
machine learning techniques in classifying code review text by semantic
meaning. The code review comments from the source control repository in GitHub
were extracted for development activity from the existing year for three
open-source projects. Apart from that, programmers need to be aware of their
code and point out their errors. In that case, it is a must to classify the
sentiment polarity of the code review comments to avoid an error. We manually
labelled 13557 code review comments generated by three open source projects in
GitHub during the existing year. In order to recognize the sentiment polarity
(or sentiment orientation) of code reviews, we use seven machine learning
algorithms and compare those results to find the better ones. Among those
Linear Support Vector Classifier(SVC) classifier technique achieves higher
accuracy than others. This study will help programmers to make any solution
based on code reviews by avoiding misconceptions.

</details>


### [59] [From Benchmark Data To Applicable Program Repair: An Experience Report](https://arxiv.org/abs/2508.16071)
*Mahinthan Chandramohan,Jovan Jancic,Yuntong Zhang,Padmanabhan Krishnan*

Main category: cs.SE

TL;DR: 该论文提出了一种自动化程序修复方法，结合多种技术并在标准基准测试中表现良好，但对实际工业缺陷效果有限。形式规范有助于提升复杂代码的单元测试质量，但实际应用仍面临挑战。


<details>
  <summary>Details</summary>
Motivation: 自动化程序修复在标准基准测试中表现良好，但在实际工业缺陷中的应用有限，因此需要探索更有效的修复方法。

Method: 结合文献中的多种技术，通过用形式规范增强代码，使LLMs能够生成更高质量的单位测试，特别是针对复杂的生产代码，提高了边缘情况和异常处理的覆盖率。

Result: 实验表明，该方法在标准基准测试上优于其他技术，但对实际工业缺陷的效果有限。形式规范对复杂代码的单元测试质量有提升，但对常见错误（如空指针、索引越界）帮助不大。

Conclusion: 尽管自动化程序修复在标准基准测试中表现良好，但在实际工业缺陷中的应用仍然有限。当前挑战包括JML规范语言的表达能力不足，需要更先进的验证工具和更丰富的谓词。正在进行的工作探索合同自动机、示例编程和测试用例修复，重点关注集成人类反馈和测量生产力提升，突显了学术基准与实际工业需求之间的差距。

Abstract: This paper describes our approach to automated program repair. We combine
various techniques from the literature to achieve this. Our experiments show
that our approach performs better than other techniques on standard benchmarks.
However, on closer inspection, none of these techniques work on realistic
defects that we see in industry.
  We find that augmenting code with formal specifications enables LLMs to
generate higher-quality unit tests, especially for complex production code with
improved coverage of edge cases and exception handling. However, specifications
add little value for well-understood errors (e.g., null pointer, index out of
bounds), but are beneficial for logic and string manipulation errors. Despite
encouraging benchmark results, real-world adoption is limited since passing
tests do not guarantee correct patches. Current challenges include insufficient
expressiveness of the JML specification language, necessitating advanced
verification tools and richer predicates. Our ongoing work is exploring
contract automata, programming by example, and testcase repair, with a focus on
integrating human feedback and measuring productivity gains - highlighting the
gap between academic benchmarks and practical industry needs

</details>


### [60] [Validating Terrain Models in Digital Twins for Trustworthy sUAS Operations](https://arxiv.org/abs/2508.16104)
*Arturo Miguel Russell Bernal,Maureen Petterson,Pedro Antonio Alarcon Granadeno,Michael Murphy,James Mason,Jane Cleland-Huang*

Main category: cs.SE

TL;DR: 本文提出了一种三维验证流程，用于验证环境数字孪生中的地形模型，并通过多sUAS平台展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着小型无人飞行系统（sUAS）在复杂环境中的部署增加，环境数字孪生（EDT）的准确性对飞行安全和高级功能（如地理定位）至关重要。然而，现实部署中的不确定性需要强大的验证流程。

Method: 采用三维验证流程，结合软件工程原则，通过多粒度测试、模拟到真实世界的过渡以及简单到边缘条件的分析，验证地形模型。

Result: 通过多sUAS平台验证了地形模型的准确性，展示了该方法在现实条件下的适用性。

Conclusion: 本文提出了一种基于软件工程原则的三维验证流程，用于验证环境数字孪生（EDT）中的地形模型，并通过多sUAS平台展示了该方法的有效性。

Abstract: With the increasing deployment of small Unmanned Aircraft Systems (sUAS) in
unfamiliar and complex environments, Environmental Digital Twins (EDT) that
comprise weather, airspace, and terrain data are critical for safe flight
planning and for maintaining appropriate altitudes during search and
surveillance operations. With the expansion of sUAS capabilities through edge
and cloud computing, accurate EDT are also vital for advanced sUAS
capabilities, like geolocation. However, real-world sUAS deployment introduces
significant sources of uncertainty, necessitating a robust validation process
for EDT components. This paper focuses on the validation of terrain models, one
of the key components of an EDT, for real-world sUAS tasks. These models are
constructed by fusing U.S. Geological Survey (USGS) datasets and satellite
imagery, incorporating high-resolution environmental data to support mission
tasks. Validating both the terrain models and their operational use by sUAS
under real-world conditions presents significant challenges, including limited
data granularity, terrain discontinuities, GPS and sensor inaccuracies, visual
detection uncertainties, as well as onboard resources and timing constraints.
We propose a 3-Dimensions validation process grounded in software engineering
principles, following a workflow across granularity of tests, simulation to
real world, and the analysis of simple to edge conditions. We demonstrate our
approach using a multi-sUAS platform equipped with a Terrain-Aware Digital
Shadow.

</details>


### [61] [The Fools are Certain; the Wise are Doubtful: Exploring LLM Confidence in Code Completion](https://arxiv.org/abs/2508.16131)
*Zoe Kotti,Konstantina Dritsa,Diomidis Spinellis,Panos Louridas*

Main category: cs.SE

TL;DR: 研究了LLM在代码补全中的置信度，发现强类型语言困惑度低，动态类型高；Perl高，Java低；困惑度受LLM影响，与数据集无关；注释增加困惑度但不影响语言排名。


<details>
  <summary>Details</summary>
Motivation: 下游指标虽然用于评估模型的实用性，但可能不可靠且需要复杂的计算和领域特定知识。相比之下，内在指标（如困惑度、熵和互信息）简单、通用，可以作为LLM生成代码功能正确性和幻觉风险的代理。

Method: 我们通过测量不同编程语言、模型和数据集上的代码困惑度，评估了LLM在生成代码时的置信度。使用了多种LLM和来自657个GitHub项目的1008个文件样本。

Result: 发现强类型语言比动态类型语言表现出更低的困惑度。脚本语言也表现出更高的困惑度。Perl普遍困惑度高，而Java困惑度低。代码困惑度取决于使用的LLM，但与代码数据集无关。代码注释通常会增加困惑度，但对语言排名影响不大。

Conclusion: LLM研究人员、开发者和用户可以利用我们的发现，根据语言、模型选择和代码特性如何影响模型置信度，来评估特定软件项目中基于LLM的代码补全的益处和适用性。

Abstract: Code completion entails the task of providing missing tokens given a
surrounding context. It can boost developer productivity while providing a
powerful code discovery tool. Following the Large Language Model (LLM) wave,
code completion has been approached with diverse LLMs fine-tuned on code (code
LLMs). The performance of code LLMs can be assessed with downstream and
intrinsic metrics. Downstream metrics are usually employed to evaluate the
practical utility of a model, but can be unreliable and require complex
calculations and domain-specific knowledge. In contrast, intrinsic metrics such
as perplexity, entropy, and mutual information, which measure model confidence
or uncertainty, are simple, versatile, and universal across LLMs and tasks, and
can serve as proxies for functional correctness and hallucination risk in
LLM-generated code. Motivated by this, we evaluate the confidence of LLMs when
generating code by measuring code perplexity across programming languages,
models, and datasets using various LLMs, and a sample of 1008 files from 657
GitHub projects. We find that strongly-typed languages exhibit lower perplexity
than dynamically typed languages. Scripting languages also demonstrate higher
perplexity. Perl appears universally high in perplexity, whereas Java appears
low. Code perplexity depends on the employed LLM, but not on the code dataset.
Although code comments often increase perplexity, the language ranking based on
perplexity is barely affected by their presence. LLM researchers, developers,
and users can employ our findings to assess the benefits and suitability of
LLM-based code completion in specific software projects based on how language,
model choice, and code characteristics impact model confidence.

</details>


### [62] [Towards Recommending Usability Improvements with Multimodal Large Language Models](https://arxiv.org/abs/2508.16165)
*Sebastian Lubos,Alexander Felfernig,Gerhard Leitner,Julian Schwazer*

Main category: cs.SE

TL;DR: 多模态LLMs能部分自动化可用性评估，提供快速、低成本的解决方案，尤其适合资源有限的小型组织。


<details>
  <summary>Details</summary>
Motivation: 传统可用性评估方法（如测试和检查）资源密集且需要专家参与，限制了小型组织的可及性。多模态LLMs的进步为部分自动化这一过程提供了可能。

Method: 将可用性评估制定为推荐任务，通过多模态LLMs对软件界面的文本、视觉和结构方面进行分析，并生成按严重程度排序的可用性问题推荐。

Result: 初步概念验证研究表明，LLM生成的可用性改进建议与专家评估具有一致性，表明其可作为专家资源有限时的实用替代方案。

Conclusion: 多模态LLMs在可用性评估中展现出潜力，能够提供快速且成本效益高的解决方案，尤其是在专家资源有限的环境中。

Abstract: Usability describes a set of essential quality attributes of user interfaces
(UI) that influence human-computer interaction. Common evaluation methods, such
as usability testing and inspection, are effective but resource-intensive and
require expert involvement. This makes them less accessible for smaller
organizations. Recent advances in multimodal LLMs offer promising opportunities
to automate usability evaluation processes partly by analyzing textual, visual,
and structural aspects of software interfaces. To investigate this possibility,
we formulate usability evaluation as a recommendation task, where multimodal
LLMs rank usability issues by severity. We conducted an initial
proof-of-concept study to compare LLM-generated usability improvement
recommendations with usability expert assessments. Our findings indicate the
potential of LLMs to enable faster and more cost-effective usability
evaluation, which makes it a practical alternative in contexts with limited
expert resources.

</details>


### [63] [LLM-Assisted Semantic Alignment and Integration in Collaborative Model-Based Systems Engineering Using SysML v2](https://arxiv.org/abs/2508.16181)
*Zirui Li,Stephan Husung,Haoze Wang*

Main category: cs.SE

TL;DR: 论文提出了一种基于GPT的SysML v2模型语义对齐方法，通过结构化提示和迭代验证，展示了其在测量系统中的可行性和局限性。


<details>
  <summary>Details</summary>
Motivation: 跨组织协作在MBSE中面临语义对齐的挑战，SysML v2的增强模块化和正式语义为互操作性建模提供了基础，而GPT大语言模型为模型理解和集成提供了新能力。

Method: 采用结构化提示驱动的方法，结合模型提取、语义匹配和验证步骤，利用SysML v2的别名、导入和元数据扩展等特性。

Result: 通过测量系统的示例验证了方法的可行性，并讨论了其优势和局限性。

Conclusion: 该论文提出了一种基于GPT大语言模型的SysML v2模型语义对齐方法，通过迭代开发和对齐验证，展示了其在测量系统中的可行性和局限性。

Abstract: Cross-organizational collaboration in Model-Based Systems Engineering (MBSE)
faces many challenges in achieving semantic alignment across independently
developed system models. SysML v2 introduces enhanced structural modularity and
formal semantics, offering a stronger foundation for interoperable modeling.
Meanwhile, GPT-based Large Language Models (LLMs) provide new capabilities for
assisting model understanding and integration. This paper proposes a
structured, prompt-driven approach for LLM-assisted semantic alignment of SysML
v2 models. The core contribution lies in the iterative development of an
alignment approach and interaction prompts, incorporating model extraction,
semantic matching, and verification. The approach leverages SysML v2 constructs
such as alias, import, and metadata extensions to support traceable, soft
alignment integration. It is demonstrated with a GPT-based LLM through an
example of a measurement system. Benefits and limitations are discussed.

</details>


### [64] [A Systematic Mapping Study on Smart Cities Modeling Approaches](https://arxiv.org/abs/2508.16273)
*Maria Teresa Rossi,Martina De Sanctis,Ludovico Iovino,Manuel Wimmer*

Main category: cs.SE

TL;DR: 本文通过系统映射研究分析了智慧城市建模方法，发现智慧治理是最受关注的维度，多数技术未经验证，研究结果为未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 探索智慧城市设计与建模的现状，以了解不同研究社区在该领域的贡献和趋势，并为未来研究提供方向。

Method: 遵循Petersen等人提出的系统映射研究指南，分析了智慧城市建模相关的出版物，识别了研究趋势和未来方向。

Result: 发现智慧治理是最受关注的维度，商业、架构和本体建模方法应用最广泛，但多数技术尚未在实际环境中验证。

Conclusion: 本文通过系统映射研究分析了智慧城市建模方法的现状，揭示了智慧治理是最受关注和建模的维度，同时指出了现有技术大多未在实际环境中验证的问题。研究结果为理解智慧城市建模的最新进展提供了基础，并对模型驱动工程社区具有重要影响。

Abstract: The Smart City concept was introduced to define an idealized city
characterized by automation and connection. It then evolved rapidly by
including further aspects, such as economy, environment. Since then, many
publications have explored various aspects of Smart Cities across different
application domains and research communities, acknowledging the
interdisciplinary nature of this subject. In particular, our interest focuses
on how smart cities are designed and modeled, as a whole or as regards with
their subsystems, when dealing with the accomplishment of the research goals in
this complex and heterogeneous domain. To this aim, we performed a systematic
mapping study on smart cities modeling approaches identifying the relevant
contributions (i) to get an overview of existing research approaches, (ii) to
identify whether there are any publication trends, and (iii) to identify
possible future research directions. We followed the guidelines for conducting
systematic mapping studies by Petersen et al. to analyze smart cities modeling
publications. Our analysis revealed the following main findings: (i) smart
governance is the most investigated and modeled smart city dimension; (ii) the
most used modeling approaches are business, architectural, and ontological
modeling approaches, spanning multiple application fields; (iii) the great
majority of existing technologies for modeling smart cities are not yet proven
in operational environments; (iv) diverse research communities publish their
results in a multitude of different venues which further motivates the
presented literature study. Researchers can use our results for better
understanding the state-of-the-art in modeling smart cities, and as a
foundation for further analysis of specific approaches about smart cities
modeling. Lastly, we also discuss the impact of our analysis for the
Model-Driven Engineering community.

</details>


### [65] [Metamorphic Coverage](https://arxiv.org/abs/2508.16307)
*Jinsheng Ba,Yuancheng Jiang,Manuel Rigger*

Main category: cs.SE

TL;DR: MC是一种新的覆盖率指标，能更有效地评估蜕变测试方法，发现更多bug且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 现有的代码覆盖率无法准确衡量代码验证程度，而突变测试计算成本高。因此，需要一种更有效的指标来评估蜕变测试方法。

Method: 提出了Metamorphic Coverage (MC)这一覆盖率指标，通过分析蜕变测试中测试输入对执行的差异代码来评估测试效果，并在五种广泛使用的蜕变测试方法上进行了系统评估。

Result: MC与64个bug中的50个修复位置重叠，且与bug数量的正相关性比行覆盖率更强。MC的敏感性是行覆盖率的4倍，计算时间比突变测试少359倍，且在反馈指导下能多发现41%的bug。

Conclusion: MC作为一种新的覆盖率指标，在评估蜕变测试方法时表现出色，不仅能更敏感地区分测试方法的有效性，还能显著减少计算时间，同时在实际应用中发现了更多的bug。

Abstract: Metamorphic testing is a widely used methodology that examines an expected
relation between pairs of executions to automatically find bugs, such as
correctness bugs. We found that code coverage cannot accurately measure the
extent to which code is validated and mutation testing is computationally
expensive for evaluating metamorphic testing methods. In this work, we propose
Metamorphic Coverage (MC), a coverage metric that examines the distinct code
executed by pairs of test inputs within metamorphic testing. Our intuition is
that, typically, a bug can be observed if the corresponding code is executed
when executing either test input but not the other one, so covering more
differential code covered by pairs of test inputs might be more likely to
expose bugs. While most metamorphic testing methods have been based on this
general intuition, our work defines and systematically evaluates MC on five
widely used metamorphic testing methods for testing database engines,
compilers, and constraint solvers. The code measured by MC overlaps with the
bug-fix locations of 50 of 64 bugs found by metamorphic testing methods, and MC
has a stronger positive correlation with bug numbers than line coverage. MC is
4x more sensitive than line coverage in distinguishing testing methods'
effectiveness, and the average value of MC is 6x smaller than line coverage
while still capturing the part of the program that is being tested. MC required
359x less time than mutation testing. Based on a case study for an automated
database system testing approach, we demonstrate that when used for feedback
guidance, MC significantly outperforms code coverage, by finding 41\% more
bugs. Consequently, this work might have broad applications for assessing
metamorphic testing methods and improving test-case generation.

</details>


### [66] [SATORI: Static Test Oracle Generation for REST APIs](https://arxiv.org/abs/2508.16318)
*Juan C. Alonso,Alberto Martin-Lopez,Sergio Segura,Gabriele Bavota,Antonio Ruiz-Cortés*

Main category: cs.SE

TL;DR: SATORI是一种静态API测试预言推断工具，通过分析OpenAPI规范自动生成测试预言，表现优于动态方法，并发现了多个API中的漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有的REST API测试工具在测试预言支持方面存在局限，通常仅限于崩溃、回归和API规范的非合规性。

Method: SATORI是一种黑盒方法，通过分析OpenAPI规范，利用大型语言模型推断API的预期行为，特别是响应字段的名称和描述。

Result: SATORI在17个操作和12个工业API上的评估显示，每个操作可自动生成数百个有效测试预言，F1分数为74.3%，优于动态方法AGORA+（69.3%）。

Conclusion: SATORI展示了静态API测试预言推断的有效性，能够自动生成大量有效的测试预言，并与动态方法AGORA+互补，共同覆盖了90%的真实预言数据集。此外，SATORI还发现了多个流行API中的18个漏洞。

Abstract: REST API test case generation tools are evolving rapidly, with growing
capabilities for the automated generation of complex tests. However, despite
their strengths in test data generation, these tools are constrained by the
types of test oracles they support, often limited to crashes, regressions, and
noncompliance with API specifications or design standards. This paper
introduces SATORI (Static API Test ORacle Inference), a black-box approach for
generating test oracles for REST APIs by analyzing their OpenAPI Specification.
SATORI uses large language models to infer the expected behavior of an API by
analyzing the properties of the response fields of its operations, such as
their name and descriptions. To foster its adoption, we extended the
PostmanAssertify tool to automatically convert the test oracles reported by
SATORI into executable assertions. Evaluation results on 17 operations from 12
industrial APIs show that SATORI can automatically generate up to hundreds of
valid test oracles per operation. SATORI achieved an F1-score of 74.3%,
outperforming the state-of-the-art dynamic approach AGORA+ (69.3%)-which
requires executing the API-when generating comparable oracle types. Moreover,
our findings show that static and dynamic oracle inference methods are
complementary: together, SATORI and AGORA+ found 90% of the oracles in our
annotated ground-truth dataset. Notably, SATORI uncovered 18 bugs in popular
APIs (Amadeus Hotel, Deutschebahn, FDIC, GitLab, Marvel, OMDb and Vimeo)
leading to documentation updates by the API maintainers.

</details>


### [67] [The (C)omprehensive (A)rchitecture (P)attern (I)ntegration method: Navigating the sea of technology](https://arxiv.org/abs/2508.16341)
*Sebastian Copei,Oliver Hohlfeld,Jens Kosiol*

Main category: cs.SE

TL;DR: CAPI是一种通过决策树推荐架构模式的方法，旨在简化技术选择和架构设计，用户研究证实其有效性。


<details>
  <summary>Details</summary>
Motivation: 技术变化迅速，单个开发者难以掌握所有趋势和工具，导致大型软件系统的工具选择和架构设计决策复杂化。

Method: 引入CAPI（全面架构模式集成方法），使用诊断决策树根据用户需求推荐架构模式，并通过迭代开发和小规模研究评估其可理解性和可用性。

Result: 用户研究表明，技术选择通常通过试错进行，CAPI被普遍认为有帮助，并能复现参与者的生产架构环境。

Conclusion: CAPI方法通过诊断决策树推荐架构模式，有效降低了技术选择和架构设计的复杂性，并在用户研究中被一致认为是有帮助的。

Abstract: The technological landscape changes daily, making it nearly impossible for a
single person to be aware of all trends or available tools that may or may not
be suitable for their software project. This makes tool selection and
architectural design decisions a complex problem, especially for large-scale
software systems. To tackle this issue, we introduce CAPI, the Comprehensive
Architecture Pattern Integration method that uses a diagnostic decision tree to
suggest architectural patterns depending on user needs. By suggesting patterns
instead of tools, the overall complexity for further decisions is lower as
there are fewer architectural patterns than tools due to the abstract nature of
patterns. Moreover, since tools implement patterns, each non-proposed pattern
reduces the number of tools to choose from, reducing complexity. We iteratively
developed CAPI, evaluating its understandability and usability in small studies
with academic participants. When satisfied with the outcome, we performed a
user-study with industry representatives to investigate the state-of-the-art in
technology selection and the effectiveness of our proposed method. We find that
technology selection is largely performed via trial and error, that CAPI is
uniformly perceived as helpful, and that CAPI is able to reproduce the
productive architectural environments of our participants.

</details>


### [68] [AetherCode: Evaluating LLMs' Ability to Win In Premier Programming Competitions](https://arxiv.org/abs/2508.16402)
*Zihan Wang,Jiaze Chen,Zhicheng Liu,Markus Mak,Yidi Du,Geonsik Moon,Luoqi Xu,Aaron Tua,Kunshuo Peng,Jiayi Lu,Mingfei Xia,Boqian Zou,Chenyang Ran,Guang Tian,Shoutai Zhu,Yeheng Duan,Zhenghui Kang,Zhenxing Lin,Shangshu Li,Qiang Luo,Qingshen Long,Zhiyong Chen,Yihan Xiao,Yurong Wu,Daoguang Zan,Yuyi Fu,Mingxuan Wang,Ming Ding*

Main category: cs.SE

TL;DR: AetherCode是一个新的基准测试，通过高难度编程竞赛问题和专家验证测试套件，更准确地评估LLM的代码推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估高估了LLM的熟练度，掩盖了LLM与精英人类程序员之间的巨大差距，主要由于基准问题难度不足和低质量测试用例导致的评估偏差。

Method: AetherCode从IOI和ICPC等顶级编程竞赛中选取问题，提供更广的覆盖范围和更高的难度，并结合自动生成和人工筛选的专家验证测试套件。

Result: AetherCode通过挑战性问题和严格评估，更真实地衡量了LLM的能力。

Conclusion: AetherCode通过结合高难度问题和全面的测试套件，为LLM的代码推理能力提供了更准确的评估，并设定了未来研究的新标准。

Abstract: Competitive programming has emerged as a critical benchmark for evaluating
the reasoning and coding capabilities of Large Language Models (LLMs). Despite
impressive progress on existing benchmarks, we argue that current evaluations
overstate model proficiency, masking a substantial gap between LLMs and elite
human programmers. This gap arises from two key limitations: insufficient
difficulty and scope of benchmark problems, and evaluation bias from
low-quality test cases. To address these shortcomings, we present AetherCode, a
new benchmark that draws problems from premier programming competitions such as
IOI and ICPC, offering broader coverage and higher difficulty. AetherCode
further incorporates comprehensive, expert-validated test suites built through
a hybrid of automated generation and human curation, ensuring rigorous and
reliable assessment. By combining challenging problem design with robust
evaluation, AetherCode provides a more faithful measure of LLM capabilities and
sets a new standard for future research in code reasoning.

</details>


### [69] [LLM-GUARD: Large Language Model-Based Detection and Repair of Bugs and Security Vulnerabilities in C++ and Python](https://arxiv.org/abs/2508.16419)
*Akshay Mhatre,Noujoud Nader,Patrick Diehl,Deepti Gupta*

Main category: cs.SE

TL;DR: 研究评估了三种主流 LLMs 在检测软件漏洞中的表现，发现它们在简单问题上表现优异，但在复杂场景中表现受限。


<details>
  <summary>Details</summary>
Motivation: 探究主流 LLMs（如 ChatGPT-4、Claude 3 和 LLaMA 4）在检测多样化软件漏洞，尤其是复杂安全相关漏洞方面的实际效果。

Method: 采用系统性实证评估，使用包含基础编程错误、经典安全漏洞和高级生产级错误的基准数据集，通过多阶段、上下文感知的提示协议模拟真实调试场景，并使用分级评分标准衡量检测准确性、推理深度和修复质量。

Result: 所有模型在识别语法和语义问题上表现优异，但在复杂安全漏洞和大规模生产代码中表现下降，ChatGPT-4 和 Claude 3 通常提供比 LLaMA 4 更细致的上下文分析。

Conclusion: LLMs 在识别语法和语义问题上表现出色，适合教育用途和自动化代码审计的初步审查，但在处理复杂安全漏洞和大规模生产代码时表现受限，显示出其作为可靠代码分析工具的潜力和当前限制。

Abstract: Large Language Models (LLMs) such as ChatGPT-4, Claude 3, and LLaMA 4 are
increasingly embedded in software/application development, supporting tasks
from code generation to debugging. Yet, their real-world effectiveness in
detecting diverse software bugs, particularly complex, security-relevant
vulnerabilities, remains underexplored. This study presents a systematic,
empirical evaluation of these three leading LLMs using a benchmark of
foundational programming errors, classic security flaws, and advanced,
production-grade bugs in C++ and Python. The dataset integrates real code from
SEED Labs, OpenSSL (via the Suresoft GLaDOS database), and PyBugHive, validated
through local compilation and testing pipelines. A novel multi-stage,
context-aware prompting protocol simulates realistic debugging scenarios, while
a graded rubric measures detection accuracy, reasoning depth, and remediation
quality. Our results show that all models excel at identifying syntactic and
semantic issues in well-scoped code, making them promising for educational use
and as first-pass reviewers in automated code auditing. Performance diminishes
in scenarios involving complex security vulnerabilities and large-scale
production code, with ChatGPT-4 and Claude 3 generally providing more nuanced
contextual analyses than LLaMA 4. This highlights both the promise and the
present constraints of LLMs in serving as reliable code analysis tools.

</details>


### [70] [Using LLMs and Essence to Support Software Practice Adoption](https://arxiv.org/abs/2508.16445)
*Sonia Nicoletti,Paolo Ciancarini*

Main category: cs.SE

TL;DR: 研究结合Essence框架与LLMs开发了一个RAG增强的聊天机器人，显著提升领域特定任务表现，为软件工程实践的应用提供支持。


<details>
  <summary>Details</summary>
Motivation: 尽管NLP和AI研究在代码生成等任务上取得了进展，但在自动化支持最佳实践采纳、工作方式演变和过程健康监测方面的关注较少。本研究旨在填补这一空白。

Method: 研究开发了一个采用检索增强生成（RAG）系统的聊天机器人，从精选知识库中检索相关上下文信息。使用了四种不同的LLM创建多个聊天机器人配置，并分别评估了基础模型和RAG增强模型的性能。

Result: 比较分析表明，提出的系统在特定领域任务中始终优于基线模型。通过促进对结构化软件工程知识的访问，该系统有助于缩小理论框架与实际应用之间的差距。

Conclusion: 该研究通过结合Essence框架与大型语言模型（LLMs），开发了一个专用聊天机器人，显著提升了在特定领域任务中的表现，为软件工程实践的理论框架与实际应用之间架起了桥梁。尽管需要进一步的用户研究验证，但结果表明基于LLM的自动化有潜力提升软件工程中的学习和决策。

Abstract: Recent advancements in natural language processing (NLP) have enabled the
development of automated tools that support various domains, including software
engineering. However, while NLP and artificial intelligence (AI) research has
extensively focused on tasks such as code generation, less attention has been
given to automating support for the adoption of best practices, the evolution
of ways of working, and the monitoring of process health. This study addresses
this gap by exploring the integration of Essence, a standard and thinking
framework for managing software engineering practices, with large language
models (LLMs). To this end, a specialised chatbot was developed to assist
students and professionals in understanding and applying Essence. The chatbot
employs a retrieval-augmented generation (RAG) system to retrieve relevant
contextual information from a curated knowledge base. Four different LLMs were
used to create multiple chatbot configurations, each evaluated both as a base
model and augmented with the RAG system. The system performance was evaluated
through both the relevance of retrieved context and the quality of generated
responses. Comparative analysis against the general-purpose LLMs demonstrated
that the proposed system consistently outperforms its baseline counterpart in
domain-specific tasks. By facilitating access to structured software
engineering knowledge, this work contributes to bridging the gap between
theoretical frameworks and practical application, potentially improving process
management and the adoption of software development practices. While further
validation through user studies is required, these findings highlight the
potential of LLM-based automation to enhance learning and decision-making in
software engineering.

</details>


### [71] [How Small is Enough? Empirical Evidence of Quantized Small Language Models for Automated Program Repair](https://arxiv.org/abs/2508.16499)
*Kazuki Kusama,Honglin Shu,Masanari Kondo,Yasutaka Kamei*

Main category: cs.SE

TL;DR: SLMs在APR任务中表现与LLMs相当，量化技术进一步提升了效率，是低资源环境下的理想选择。


<details>
  <summary>Details</summary>
Motivation: 评估SLMs在有限计算资源下是否能达到与LLMs相当的APR任务性能。

Method: 在QuixBugs基准测试上进行了实验，比较了SLMs和LLMs的bug修复准确性，并分析了int8量化对APR性能的影响。

Result: 最新的SLMs能够与LLMs一样甚至更准确地修复bug；int8量化对APR准确性影响极小，同时显著降低了内存需求。

Conclusion: SLMs是LLMs在自动程序修复（APR）中的可行替代方案，提供竞争性准确性且计算成本更低，量化技术在不影响效果的前提下进一步提升了效率。

Abstract: Background: Large language models (LLMs) have greatly improved the accuracy
of automated program repair (APR) methods. However, LLMs are constrained by
high computational resource requirements. Aims: We focus on small language
models (SLMs), which perform well even with limited computational resources
compared to LLMs. We aim to evaluate whether SLMs can achieve competitive
performance in APR tasks. Method: We conducted experiments on the QuixBugs
benchmark to compare the bug-fixing accuracy of SLMs and LLMs. We also analyzed
the impact of int8 quantization on APR performance. Results: The latest SLMs
can fix bugs as accurately as--or even more accurately than--LLMs. Also, int8
quantization had minimal effect on APR accuracy while significantly reducing
memory requirements. Conclusions: SLMs present a viable alternative to LLMs for
APR, offering competitive accuracy with lower computational costs, and
quantization can further enhance their efficiency without compromising
effectiveness.

</details>


### [72] [ARSP: Automated Repair of Verilog Designs via Semantic Partitioning](https://arxiv.org/abs/2508.16517)
*Bingkun Yao,Ning Wang,Xiangfeng Liu,Yuxin Du,Yuchen Hu,Hong Gao,Zhe Jiang,Nan Guan*

Main category: cs.SE

TL;DR: ARSP通过语义分段提升Verilog调试效率，显著优于现有工具。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于LLM的自动化调试方法在工业规模模块上表现不佳的问题，主要原因是长上下文中错误信号被稀释。

Method: ARSP采用两阶段系统：Partition LLM将模块分割为语义紧密的片段，Repair LLM修补每个片段，最后合并编辑而不影响无关逻辑。此外，利用合成数据框架生成片段级训练对以监督模型。

Result: ARSP在实验中达到77.92% pass@1和83.88% pass@5，优于主流商业LLM和SOTA自动化Verilog调试工具。语义分割使pass@1和pass@5分别提升11.6%和10.2%。

Conclusion: ARSP系统通过语义引导的分段方法显著提升了基于LLM的Verilog调试效率，验证了分段范围缩小在调试中的有效性。

Abstract: Debugging functional Verilog bugs consumes a significant portion of front-end
design time. While Large Language Models (LLMs) have demonstrated great
potential in mitigating this effort, existing LLM-based automated debugging
methods underperform on industrial-scale modules. A major reason for this is
bug signal dilution in long contexts, where a few bug-relevant tokens are
overwhelmed by hundreds of unrelated lines, diffusing the model's attention. To
address this issue, we introduce ARSP, a two-stage system that mitigates
dilution via semantics-guided fragmentation. A Partition LLM splits a module
into semantically tight fragments; a Repair LLM patches each fragment; edits
are merged without altering unrelated logic. A synthetic data framework
generates fragment-level training pairs spanning bug types, design styles, and
scales to supervise both models. Experiments show that ARSP achieves 77.92%
pass@1 and 83.88% pass@5, outperforming mainstream commercial LLMs including
Claude-3.7 and SOTA automated Verilog debugging tools Strider and MEIC. Also,
semantic partitioning improves pass@1 by 11.6% and pass@5 by 10.2% over
whole-module debugging, validating the effectiveness of fragment-level scope
reduction in LLM-based Verilog debugging.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [73] [CXLAimPod: CXL Memory is all you need in AI era](https://arxiv.org/abs/2508.15980)
*Yiwei Yang,Yusheng Zheng,Yiqi Chen,Zheng Liang,Kexin Chu,Zhe Zhou,Andi Quinn,Wei Zhang*

Main category: cs.OS

TL;DR: CXLAimPod是一个自适应调度框架，通过全双工感知调度显著提升CXL性能，适用于混合读写工作负载。


<details>
  <summary>Details</summary>
Motivation: 传统半双工架构（如DDR5）在混合读写模式下存在总线转向开销，而CXL的全双工潜力未被现有软件栈充分利用。

Method: 提出了CXLAimPod框架，结合cgroup-based提示机制和多种调度策略，通过eBPF在Linux内核中高效实现。

Result: CXL系统在平衡读写比例下带宽提升55-61%，CXLAimPod在不同工作负载中表现优异（如Redis提升7.4%，LLM文本生成提升71.6%）。

Conclusion: CXLAimPod框架通过全双工架构感知的调度策略显著提升了CXL系统的性能，证明了其在混合读写工作负载中的有效性。

Abstract: The proliferation of data-intensive applications, ranging from large language
models to key-value stores, increasingly stresses memory systems with mixed
read-write access patterns. Traditional half-duplex architectures such as DDR5
are ill-suited for such workloads, suffering bus turnaround penalties that
reduce their effective bandwidth under mixed read-write patterns. Compute
Express Link (CXL) offers a breakthrough with its full-duplex channels, yet
this architectural potential remains untapped as existing software stacks are
oblivious to this capability. This paper introduces CXLAimPod, an adaptive
scheduling framework designed to bridge this software-hardware gap through
system support, including cgroup-based hints for application-aware
optimization. Our characterization quantifies the opportunity, revealing that
CXL systems achieve 55-61% bandwidth improvement at balanced read-write ratios
compared to flat DDR5 performance, demonstrating the benefits of full-duplex
architecture. To realize this potential, the CXLAimPod framework integrates
multiple scheduling strategies with a cgroup-based hint mechanism to navigate
the trade-offs between throughput, latency, and overhead. Implemented
efficiently within the Linux kernel via eBPF, CXLAimPod delivers significant
performance improvements over default CXL configurations. Evaluation on diverse
workloads shows 7.4% average improvement for Redis (with up to 150% for
specific sequential patterns), 71.6% improvement for LLM text generation, and
9.1% for vector databases, demon-strating that duplex-aware scheduling can
effectively exploit CXL's architectural advantages.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [74] [HyperFlexis: Joint Design of Algorithms and Systems for Multi-SLO Serving and Fast Scaling](https://arxiv.org/abs/2508.15919)
*Zahra Yousefijamarani,Xinglu Wang,Qian Wang,Morgan Lindsay Heisler,Taha Shabani,Niloofar Gholipour,Parham Yassini,Hong Chang,Kan Chen,Qiantao Zhang,Xiaolong Bai,Jiannan Wang,Ying Xiong,Yong Zhang,Zhenan Fan*

Main category: cs.DC

TL;DR: HyperFlexis是一个统一的LLM服务系统，通过多SLO感知调度和D2D权重传输优化，显著提升了性能和成本效益。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型（LLM）服务系统面临多样化请求长度、优先级和阶段特定SLO的挑战，需要实时调度、快速扩展和成本效益。

Method: 提出了一种多SLO感知调度器，利用预算估计和请求优先级确保主动SLO合规；支持P/D解耦架构和KV缓存传输；引入了D2D权重传输机制以减少冷启动延迟。

Result: 系统实现了高达4.44倍的SLO达成率提升、65.82%的请求延迟降低，并在成本上与现有最佳基线持平。

Conclusion: HyperFlexis通过算法和系统级创新，在多种SLO下联合优化调度和扩展，显著提升了SLO达成率和请求延迟，同时保持成本竞争力。

Abstract: Modern large language model (LLM) serving systems face challenges from highly
variable requests with diverse lengths, priorities, and stage-specific
service-level objectives (SLOs). Meeting these requires real-time scheduling,
rapid and cost-effective scaling, and support for both collocated and
disaggregated Prefill/Decode (P/D) architectures.
  We present \textbf{HyperFlexis}, a unified LLM serving system that integrates
algorithmic and system-level innovations to jointly optimize scheduling and
scaling under multiple SLOs. It features a multi-SLO-aware scheduler that
leverages budget estimation and request prioritization to ensure proactive SLO
compliance for both new and ongoing requests. The system supports prefill- and
decode-stage multi-SLO scheduling for P/D-disaggregated architectures and KV
cache transfers. It also enables cost-effective scaling decisions,
prefill-decode instance linking during scaling, and rapid P/D role transitions.
To accelerate scaling and reduce cold-start latency, a device-to-device (D2D)
weight transfer mechanism is proposed that lowers weight loading overhead by up
to \textbf{19.39$\times$}. These optimizations allow the system to achieve up
to \textbf{4.44$\times$} higher SLO attainment, \textbf{65.82\%} lower request
latency, and cost parity with state-of-the-art baselines. The code will be
released soon.

</details>


### [75] [Generalizing Brooks' theorem via Partial Coloring is Hard Classically and Locally](https://arxiv.org/abs/2508.16308)
*Jan Bok,Avinandan Das,Anna Gujgiczer,Nikola Jedličková*

Main category: cs.DC

TL;DR: 研究发现$k$-partial $k$-coloring问题在颜色数量减少时复杂度显著增加，经典NP完全且分布式需$\Omega(n)$轮。


<details>
  <summary>Details</summary>
Motivation: 解决Das等人提出的关于$k$-partial $k$-coloring分布式复杂度状态的开放问题。

Method: 通过构造复杂的图结构和不可区分性论证，证明了问题的复杂度下界。

Result: 证明了$k$-partial $k$-coloring在经典和分布式模型中的复杂度显著高于$(k+1)$-coloring。

Conclusion: 研究发现，当颜色数量从$k+1$减少到$k$时，$k$-partial $k$-coloring问题在经典和分布式计算中的复杂度显著增加。在经典设置中，该问题对所有$k \geq 3$均为NP完全问题；在分布式LOCAL模型中，存在$\Omega(n)$轮的下界。

Abstract: We investigate the classical and distributed complexity of \emph{$k$-partial
$c$-coloring} where $c=k$, a natural generalization of Brooks' theorem where
each vertex should be colored from the palette $\{1,\ldots,c\} =
\{1,\ldots,k\}$ such that it must have at least $\min\{k, \deg(v)\}$ neighbors
colored differently. Das, Fraigniaud, and Ros{\'{e}}n~[OPODIS 2023] showed that
the problem of $k$-partial $(k+1)$-coloring admits efficient centralized and
distributed algorithms and posed an open problem about the status of the
distributed complexity of $k$-partial $k$-coloring. We show that the problem
becomes significantly harder when the number of colors is reduced from $k+1$ to
$k$ for every constant $k\geq 3$.
  In the classical setting, we prove that deciding whether a graph admits a
$k$-partial $k$-coloring is NP-complete for every constant $k \geq 3$,
revealing a sharp contrast with the linear-time solvable $(k+1)$-color case.
For the distributed LOCAL model, we establish an $\Omega(n)$-round lower bound
for computing $k$-partial $k$-colorings, even when the graph is guaranteed to
be $k$-partial $k$-colorable. This demonstrates an exponential separation from
the $O(\log^2 k \cdot \log n)$-round algorithms known for $(k+1)$-colorings.
  Our results leverage novel structural characterizations of ``hard instances''
where partial coloring reduces to proper coloring, and we construct intricate
graph gadgets to prove lower bounds via indistinguishability arguments.

</details>


<div id='q-bio.NC'></div>

# q-bio.NC [[Back]](#toc)

### [76] [NeuroKoop: Neural Koopman Fusion of Structural-Functional Connectomes for Identifying Prenatal Drug Exposure in Adolescents](https://arxiv.org/abs/2508.16414)
*Badhan Mazumder,Aline Kotoski,Vince D. Calhoun,Dong Hye Ye*

Main category: q-bio.NC

TL;DR: NeuroKoop是一种基于图神经网络的框架，通过Koopman算子融合结构和功能脑网络，提升了对产前药物暴露状态的分类和理解。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法充分捕捉结构和功能连接组中的互补特征，限制了生物洞察和预测性能。

Method: 提出NeuroKoop框架，利用神经Koopman算子驱动的潜在空间融合，整合源基于形态测量（SBM）和功能网络连接（FNC）的脑图节点嵌入。

Result: 在ABCD数据集的大规模青少年队列中，NeuroKoop优于相关基线方法，并揭示了显著的结构-功能连接。

Conclusion: NeuroKoop框架通过整合结构和功能脑网络，显著提升了对产前药物暴露（PDE）状态的分类性能，并揭示了关键的神经发育影响。

Abstract: Understanding how prenatal exposure to psychoactive substances such as
cannabis shapes adolescent brain organization remains a critical challenge,
complicated by the complexity of multimodal neuroimaging data and the
limitations of conventional analytic methods. Existing approaches often fail to
fully capture the complementary features embedded within structural and
functional connectomes, constraining both biological insight and predictive
performance. To address this, we introduced NeuroKoop, a novel graph neural
network-based framework that integrates structural and functional brain
networks utilizing neural Koopman operator-driven latent space fusion. By
leveraging Koopman theory, NeuroKoop unifies node embeddings derived from
source-based morphometry (SBM) and functional network connectivity (FNC) based
brain graphs, resulting in enhanced representation learning and more robust
classification of prenatal drug exposure (PDE) status. Applied to a large
adolescent cohort from the ABCD dataset, NeuroKoop outperformed relevant
baselines and revealed salient structural-functional connections, advancing our
understanding of the neurodevelopmental impact of PDE.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [77] [Spatial Policy: Guiding Visuomotor Robotic Manipulation with Spatial-Aware Modeling and Reasoning](https://arxiv.org/abs/2508.15874)
*Yijun Liu,Yuwei Liu,Yuan Meng,Jieheng Zhang,Yuwei Zhou,Ye Li,Jiacheng Jiang,Kangye Ji,Shijia Ge,Zhi Wang,Wenwu Zhu*

Main category: cs.RO

TL;DR: SP是一个空间感知的视觉运动机器人操作框架，通过显式空间建模和推理显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉中心具身模型缺乏空间感知能力，限制了其在复杂环境中将视觉计划转化为可执行控制的效果。

Method: SP框架包括三个模块：空间条件具身视频生成模块、基于空间的动作预测模块和空间推理反馈策略。

Result: SP在11项多样化任务中平均成功率高达86.7%，较最佳基线平均提升33.0%。

Conclusion: SP通过显式空间建模和推理，显著提升了具身模型在机器人控制应用中的实用性，平均成功率高达86.7%。

Abstract: Vision-centric hierarchical embodied models have demonstrated strong
potential for long-horizon robotic control. However, existing methods lack
spatial awareness capabilities, limiting their effectiveness in bridging visual
plans to actionable control in complex environments. To address this problem,
we propose Spatial Policy (SP), a unified spatial-aware visuomotor robotic
manipulation framework via explicit spatial modeling and reasoning.
Specifically, we first design a spatial-conditioned embodied video generation
module to model spatially guided predictions through a spatial plan table.
Then, we propose a spatial-based action prediction module to infer executable
actions with coordination. Finally, we propose a spatial reasoning feedback
policy to refine the spatial plan table via dual-stage replanning. Extensive
experiments show that SP significantly outperforms state-of-the-art baselines,
achieving a 33.0% average improvement over the best baseline. With an 86.7%
average success rate across 11 diverse tasks, SP substantially enhances the
practicality of embodied models for robotic control applications. Code and
checkpoints are maintained at
https://plantpotatoonmoon.github.io/SpatialPolicy/.

</details>


### [78] [UnPose: Uncertainty-Guided Diffusion Priors for Zero-Shot Pose Estimation](https://arxiv.org/abs/2508.15972)
*Zhaodong Jiang,Ashish Sinha,Tongtong Cao,Yuan Ren,Bingbing Liu,Binbin Xu*

Main category: cs.RO

TL;DR: UnPose是一个无需CAD模型的零样本6D物体姿态估计和重建框架，利用扩散模型的3D先验和不确定性估计，逐步优化3D重建和姿态估计。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖CAD模型的问题，避免获取模型的成本和不切实际性，同时减少现有方法对额外训练或产生幻觉几何的需求。

Method: UnPose利用预训练的扩散模型的3D先验和不确定性估计，从单视角RGB-D帧开始，通过多视角扩散模型估计初始3D模型（使用3D高斯溅射表示），并逐步融合新视角以优化模型。

Result: 实验表明，UnPose在6D姿态估计精度和3D重建质量上均显著优于现有方法。

Conclusion: UnPose在6D姿态估计和3D重建质量上显著优于现有方法，并展示了在实际机器人操作任务中的实用性。

Abstract: Estimating the 6D pose of novel objects is a fundamental yet challenging
problem in robotics, often relying on access to object CAD models. However,
acquiring such models can be costly and impractical. Recent approaches aim to
bypass this requirement by leveraging strong priors from foundation models to
reconstruct objects from single or multi-view images, but typically require
additional training or produce hallucinated geometry. To this end, we propose
UnPose, a novel framework for zero-shot, model-free 6D object pose estimation
and reconstruction that exploits 3D priors and uncertainty estimates from a
pre-trained diffusion model. Specifically, starting from a single-view RGB-D
frame, UnPose uses a multi-view diffusion model to estimate an initial 3D model
using 3D Gaussian Splatting (3DGS) representation, along with pixel-wise
epistemic uncertainty estimates. As additional observations become available,
we incrementally refine the 3DGS model by fusing new views guided by the
diffusion model's uncertainty, thereby continuously improving the pose
estimation accuracy and 3D reconstruction quality. To ensure global
consistency, the diffusion prior-generated views and subsequent observations
are further integrated in a pose graph and jointly optimized into a coherent
3DGS field. Extensive experiments demonstrate that UnPose significantly
outperforms existing approaches in both 6D pose estimation accuracy and 3D
reconstruction quality. We further showcase its practical applicability in
real-world robotic manipulation tasks.

</details>


### [79] [GelSLAM: A Real-time, High-Fidelity, and Robust 3D Tactile SLAM System](https://arxiv.org/abs/2508.15990)
*Hung-Jui Huang,Mohammad Amin Mirzaee,Michael Kaess,Wenzhen Yuan*

Main category: cs.RO

TL;DR: GelSLAM是一种基于触觉感知的实时3D SLAM系统，用于高精度物体姿态估计和形状重建。


<details>
  <summary>Details</summary>
Motivation: 触觉感知在精确性和抗遮挡方面优于视觉方法，适用于高精度操作任务。

Method: GelSLAM利用触觉感知的表面法线和曲率进行鲁棒跟踪和闭环检测，实时跟踪物体运动并重建形状。

Result: GelSLAM能够实时跟踪物体运动，误差低且漂移小，形状重建精度达亚毫米级。

Conclusion: GelSLAM通过触觉感知实现了高精度的物体姿态估计和形状重建，为精确操作任务提供了新基础。

Abstract: Accurately perceiving an object's pose and shape is essential for precise
grasping and manipulation. Compared to common vision-based methods, tactile
sensing offers advantages in precision and immunity to occlusion when tracking
and reconstructing objects in contact. This makes it particularly valuable for
in-hand and other high-precision manipulation tasks. In this work, we present
GelSLAM, a real-time 3D SLAM system that relies solely on tactile sensing to
estimate object pose over long periods and reconstruct object shapes with high
fidelity. Unlike traditional point cloud-based approaches, GelSLAM uses
tactile-derived surface normals and curvatures for robust tracking and loop
closure. It can track object motion in real time with low error and minimal
drift, and reconstruct shapes with submillimeter accuracy, even for low-texture
objects such as wooden tools. GelSLAM extends tactile sensing beyond local
contact to enable global, long-horizon spatial perception, and we believe it
will serve as a foundation for many precise manipulation tasks involving
interaction with objects in hand. The video demo is available on our website:
https://joehjhuang.github.io/gelslam.

</details>


### [80] [Self-Aligning EPM Connector: A Versatile Solution for Adaptive and Multi-Modal Interfaces](https://arxiv.org/abs/2508.16008)
*Bingchao Wang,Adam A. Stokes*

Main category: cs.RO

TL;DR: 一种基于电永磁技术的多功能连接器，集成自对齐、流体传输和数据通信，适用于多种工业应用。


<details>
  <summary>Details</summary>
Motivation: 为满足模块化机器人、电动汽车充电等领域对多功能、高灵活性连接器的需求，开发一种集成多种功能的紧凑型连接器。

Method: 通过SLA-3D打印技术制造紧凑结构，集成电子控制实现自对齐、流体传输和数据通信功能，并测试其在轴向、角度和侧向偏差下的性能。

Result: 实验结果表明，该连接器能可靠自对齐、高效传输流体（单环和双通道模式），并实现稳健的数据传输，同时适应多种偏差且能耗低。

Conclusion: 该论文提出了一种基于电永磁（EPM）技术的多功能连接器，集成自对齐、机械耦合、流体传输和数据通信功能，适用于模块化机器人、电动汽车充电、家用机器人平台和航空航天对接等多种应用。

Abstract: This paper presents a multifunctional connector based on electro-permanent
magnet (EPM) technology, integrating self-alignment, mechanical coupling, fluid
transfer, and data communication within a compact SLA-3D printed structure.
Experimental results demonstrate reliable self-alignment, efficient fluid
transfer in single-loop and dual-channel modes, and robust data transmission
via integrated electronic control. The connector exhibits high flexibility in
accommodating axial, angular, and lateral misalignments while maintaining low
energy consumption. These features make it highly suitable for modular
robotics, electric vehicle charging, household robotic platforms, and aerospace
docking applications.

</details>


### [81] [Take That for Me: Multimodal Exophora Resolution with Interactive Questioning for Ambiguous Out-of-View Instructions](https://arxiv.org/abs/2508.16143)
*Akira Oyama,Shoichi Hasegawa,Akira Taniguchi,Yoshinobu Hagiwara,Tadahiro Taniguchi*

Main category: cs.RO

TL;DR: MIEL是一个多模态外指消解框架，结合声音定位、语义映射和GPT-4o交互，显著提升机器人在用户或物体不可见时的指令理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有外指消解方法主要依赖视觉数据，无法处理用户或物体不可见的现实场景。MIEL旨在通过多模态交互解决这一问题。

Method: MIEL框架整合了声音源定位（SSL）、语义映射、视觉语言模型（VLMs）和GPT-4o的交互提问。首先构建环境语义图，结合用户骨骼数据估计候选物体；利用SSL定位用户方向；在存在歧义时，主动与用户交互生成澄清问题。

Result: 实验表明，MIEL在用户可见时性能提升约1.3倍，不可见时提升约2.0倍。

Conclusion: MIEL框架通过结合声音源定位、语义映射、视觉语言模型和GPT-4o的交互提问，显著提高了机器人对模糊指令的理解能力，尤其是在用户或物体不可见的情况下。

Abstract: Daily life support robots must interpret ambiguous verbal instructions
involving demonstratives such as ``Bring me that cup,'' even when objects or
users are out of the robot's view. Existing approaches to exophora resolution
primarily rely on visual data and thus fail in real-world scenarios where the
object or user is not visible. We propose Multimodal Interactive Exophora
resolution with user Localization (MIEL), which is a multimodal exophora
resolution framework leveraging sound source localization (SSL), semantic
mapping, visual-language models (VLMs), and interactive questioning with
GPT-4o. Our approach first constructs a semantic map of the environment and
estimates candidate objects from a linguistic query with the user's skeletal
data. SSL is utilized to orient the robot toward users who are initially
outside its visual field, enabling accurate identification of user gestures and
pointing directions. When ambiguities remain, the robot proactively interacts
with the user, employing GPT-4o to formulate clarifying questions. Experiments
in a real-world environment showed results that were approximately 1.3 times
better when the user was visible to the robot and 2.0 times better when the
user was not visible to the robot, compared to the methods without SSL and
interactive questioning. The project website is
https://emergentsystemlabstudent.github.io/MIEL/.

</details>


### [82] [GPL-SLAM: A Laser SLAM Framework with Gaussian Process Based Extended Landmarks](https://arxiv.org/abs/2508.16459)
*Ali Emre Balcı,Erhan Ege Keyvan,Emre Özkan*

Main category: cs.RO

TL;DR: 提出一种基于高斯过程的SLAM方法，通过对象轮廓表示环境，实现高效内存使用和语义信息提取，实验验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法如网格地图或点云注册在处理环境表示时缺乏语义信息，且内存效率不高。本文旨在通过对象级的高斯过程表示解决这些问题。

Method: 采用高斯过程（GP）基于轮廓的表示方法，通过递归方案在线更新环境中的对象轮廓，并在完全贝叶斯框架下联合推断机器人位姿和基于对象的地图。

Result: 实验表明，该方法在多样化的结构化环境中能够实现准确的定位和建图性能，并提供对象形状的置信边界。

Conclusion: 该论文提出的基于高斯过程的SLAM方法在合成和真实世界实验中验证了其准确性和高效性，能够提供语义信息并支持下游任务。

Abstract: We present a novel Simultaneous Localization and Mapping (SLAM) method that
employs Gaussian Process (GP) based landmark (object) representations. Instead
of conventional grid maps or point cloud registration, we model the environment
on a per object basis using GP based contour representations. These contours
are updated online through a recursive scheme, enabling efficient memory usage.
The SLAM problem is formulated within a fully Bayesian framework, allowing
joint inference over the robot pose and object based map. This representation
provides semantic information such as the number of objects and their areas,
while also supporting probabilistic measurement to object associations.
Furthermore, the GP based contours yield confidence bounds on object shapes,
offering valuable information for downstream tasks like safe navigation and
exploration. We validate our method on synthetic and real world experiments,
and show that it delivers accurate localization and mapping performance across
diverse structured environments.

</details>


### [83] [Swarming Without an Anchor (SWA): Robot Swarms Adapt Better to Localization Dropouts Then a Single Robot](https://arxiv.org/abs/2508.16460)
*Jiri Horyna,Roland Jung,Stephan Weiss,Eliseo Ferrante,Martin Saska*

Main category: cs.RO

TL;DR: SWA方法通过分散状态估计和相互感知，维持无人机群在定位失效时的状态感知，验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决无人机群在定位失效时如何维持准确状态感知的挑战，提升多无人机系统的可靠性和韧性。

Method: 提出SWA方法，结合分散状态估计、鲁棒相互感知和机载传感器数据，解决无人机群在定位失效时的状态估计问题。

Result: 方法能维持无人机群的凝聚力，实现速度共识，并衰减除整体平移漂移外的所有干扰和性能下降。

Conclusion: SWA方法通过融合分散状态估计、鲁棒相互感知和机载传感器数据，有效维持了无人机群在定位失效时的状态感知能力，并在模拟和实际实验中验证了其有效性。

Abstract: In this paper, we present the Swarming Without an Anchor (SWA) approach to
state estimation in swarms of Unmanned Aerial Vehicles (UAVs) experiencing
ego-localization dropout, where individual agents are laterally stabilized
using relative information only. We propose to fuse decentralized state
estimation with robust mutual perception and onboard sensor data to maintain
accurate state awareness despite intermittent localization failures. Thus, the
relative information used to estimate the lateral state of UAVs enables the
identification of the unambiguous state of UAVs with respect to the local
constellation. The resulting behavior reaches velocity consensus, as this task
can be referred to as the double integrator synchronization problem. All
disturbances and performance degradations except a uniform translation drift of
the swarm as a whole is attenuated which is enabling new opportunities in using
tight cooperation for increasing reliability and resilience of multi-UAV
systems. Simulations and real-world experiments validate the effectiveness of
our approach, demonstrating its capability to sustain cohesive swarm behavior
in challenging conditions of unreliable or unavailable primary localization.

</details>


### [84] [Terrain Classification for the Spot Quadrupedal Mobile Robot Using Only Proprioceptive Sensing](https://arxiv.org/abs/2508.16504)
*Sophie Villemure,Jefferson Silveira,Joshua A. Marshall*

Main category: cs.RO

TL;DR: 该论文提出了一种基于波士顿动力Spot机器人本体感受信号的地形分类器，通过降维和分类技术准确识别地形，准确率达97%，用于安全路径规划。


<details>
  <summary>Details</summary>
Motivation: 四足移动机器人在复杂地形上容易出现下沉和打滑等不良行为，需要一种地形分类器来创建可穿越性地图，以规划更安全的导航路径。

Method: 结合降维技术从Spot机器人提供的100多个本体感受信号中提取相关信息，并应用分类技术根据地形的可穿越性进行区分。

Result: 在代表性实地测试中，地形分类器能够以约97%的准确率识别三种不同地形类型。

Conclusion: 该研究成功开发了一种地形分类器，能够通过波士顿动力Spot机器人的本体感受信号准确识别不同地形类型，准确率约97%，为机器人导航提供了更安全的路径规划。

Abstract: Quadrupedal mobile robots can traverse a wider range of terrain types than
their wheeled counterparts but do not perform the same on all terrain types.
These robots are prone to undesirable behaviours like sinking and slipping on
challenging terrains. To combat this issue, we propose a terrain classifier
that provides information on terrain type that can be used in robotic systems
to create a traversability map to plan safer paths for the robot to navigate.
The work presented here is a terrain classifier developed for a Boston Dynamics
Spot robot. Spot provides over 100 measured proprioceptive signals describing
the motions of the robot and its four legs (e.g., foot penetration, forces,
joint angles, etc.). The developed terrain classifier combines dimensionality
reduction techniques to extract relevant information from the signals and then
applies a classification technique to differentiate terrain based on
traversability. In representative field testing, the resulting terrain
classifier was able to identify three different terrain types with an accuracy
of approximately 97%

</details>


### [85] [On Kinodynamic Global Planning in a Simplicial Complex Environment: A Mixed Integer Approach](https://arxiv.org/abs/2508.16511)
*Otobong Jerome,Alexandr Klimchik,Alexander Maloletov,Geesara Kulathunga*

Main category: cs.RO

TL;DR: 该研究提出了一种优化车辆运动轨迹和速度剖面的方法，通过混合整数线性规划显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 解决车辆在复杂地形中的运动规划问题，避免局部最优并满足速度和加速度的边界条件。

Method: 将问题初始化为混合整数分数规划，并通过变量转换和McCormick包络松弛为混合整数线性规划。

Result: 相比MPPI和log-MPPI，该方法生成解决方案的速度提高了104倍。

Conclusion: 该方法通过混合整数线性规划优化了车辆的运动轨迹和速度剖面，显著提高了计算效率，同时严格满足边界条件。

Abstract: This work casts the kinodynamic planning problem for car-like vehicles as an
optimization task to compute a minimum-time trajectory and its associated
velocity profile, subject to boundary conditions on velocity, acceleration, and
steering. The approach simultaneously optimizes both the spatial path and the
sequence of acceleration and steering controls, ensuring continuous motion from
a specified initial position and velocity to a target end position and
velocity.The method analyzes the admissible control space and terrain to avoid
local minima. The proposed method operates efficiently in simplicial complex
environments, a preferred terrain representation for capturing intricate 3D
landscapes. The problem is initially posed as a mixed-integer fractional
program with quadratic constraints, which is then reformulated into a
mixed-integer bilinear objective through a variable transformation and
subsequently relaxed to a mixed-integer linear program using McCormick
envelopes. Comparative simulations against planners such as MPPI and log-MPPI
demonstrate that the proposed approach generates solutions 104 times faster
while strictly adhering to the specified constraints

</details>


### [86] [Comparative Analysis of UAV Path Planning Algorithms for Efficient Navigation in Urban 3D Environments](https://arxiv.org/abs/2508.16515)
*Hichem Cheriet,Khellat Kihel Badra,Chouraqui Samira*

Main category: cs.RO

TL;DR: A*算法在无人机3D路径规划中表现最佳，PSO适合密集环境，RRT*表现均衡。


<details>
  <summary>Details</summary>
Motivation: 解决无人机路径规划和避障的关键挑战，评估现有算法的有效性和效率。

Method: 在3D城市环境中设计了三个实验，每个实验包含两种场景，测试A*、RRT*和PSO算法的性能。实验考虑了不同地图大小、高度、障碍物密度和大小。

Result: A*算法在计算效率和路径质量上优于其他算法，PSO在密集环境和急转弯中表现良好，RRT*因其随机化方法在所有实验中表现均衡。

Conclusion: A*算法在计算效率和路径质量上表现最佳，PSO适用于密集环境和急转弯，RRT*因其随机化方法在所有实验中表现均衡。

Abstract: The most crucial challenges for UAVs are planning paths and avoiding
obstacles in their way. In recent years, a wide variety of path-planning
algorithms have been developed. These algorithms have successfully solved
path-planning problems; however, they suffer from multiple challenges and
limitations. To test the effectiveness and efficiency of three widely used
algorithms, namely A*, RRT*, and Particle Swarm Optimization (PSO), this paper
conducts extensive experiments in 3D urban city environments cluttered with
obstacles. Three experiments were designed with two scenarios each to test the
aforementioned algorithms. These experiments consider different city map sizes,
different altitudes, and varying obstacle densities and sizes in the
environment. According to the experimental results, the A* algorithm
outperforms the others in both computation efficiency and path quality. PSO is
especially suitable for tight turns and dense environments, and RRT* offers a
balance and works well across all experiments due to its randomized approach to
finding solutions.

</details>


### [87] [Hierarchical Decision-Making for Autonomous Navigation: Integrating Deep Reinforcement Learning and Fuzzy Logic in Four-Wheel Independent Steering and Driving Systems](https://arxiv.org/abs/2508.16574)
*Yizhi Wang,Degang Xu,Yongfang Xie,Shuzhong Tan,Xianan Zhou,Peng Chen*

Main category: cs.RO

TL;DR: 分层决策框架结合DRL和模糊逻辑，优化4WISD系统的导航性能，适用于复杂工业环境。


<details>
  <summary>Details</summary>
Motivation: 解决4WISD系统在动态工业环境中导航时面临的机械应变和轮滑问题，同时提升训练效率和稳定性。

Method: 提出了一种分层决策框架，结合深度强化学习（DRL）进行高层导航和模糊逻辑进行低层控制，以确保任务性能和物理可行性。

Result: 仿真实验表明该框架优于传统导航方法，具有更高的训练效率和稳定性，减少了纯DRL解决方案的不稳定行为。实际验证进一步证实了框架在动态工业环境中的安全有效导航能力。

Conclusion: 本文为四轮独立转向和驱动（4WISD）系统提供了一种可扩展且可靠的解决方案，适用于复杂现实场景中的移动机器人部署。

Abstract: This paper presents a hierarchical decision-making framework for autonomous
navigation in four-wheel independent steering and driving (4WISD) systems. The
proposed approach integrates deep reinforcement learning (DRL) for high-level
navigation with fuzzy logic for low-level control to ensure both task
performance and physical feasibility. The DRL agent generates global motion
commands, while the fuzzy logic controller enforces kinematic constraints to
prevent mechanical strain and wheel slippage. Simulation experiments
demonstrate that the proposed framework outperforms traditional navigation
methods, offering enhanced training efficiency and stability and mitigating
erratic behaviors compared to purely DRL-based solutions. Real-world
validations further confirm the framework's ability to navigate safely and
effectively in dynamic industrial settings. Overall, this work provides a
scalable and reliable solution for deploying 4WISD mobile robots in complex,
real-world scenarios.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [88] [Task Offloading and Resource Allocation for MEC-assisted Consumer Internet of Vehicle Systems](https://arxiv.org/abs/2508.15795)
*Yanheng Liu,Dalin Li,Hao Wu,Zemin Sun,Weihong Qin,Jun Li,Hongyang Du,Geng Sun*

Main category: cs.NI

TL;DR: 本文提出了一种基于AI的任务卸载和资源分配方法（JTOCRA），用于MEC辅助的车联网系统，通过MADDPG算法优化系统成本，仿真显示其性能优越且可扩展性强。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）辅助的车联网（IoV）面临资源有限与计算需求严格、难以捕捉系统复杂特征以及需要实时处理和高效资源管理的挑战。

Method: 设计了一种联合任务卸载和计算资源分配方法（JTOCRA），应用了多智能体深度确定性策略梯度（MADDPG）算法。

Result: 提出的JTOCRA方法在系统成本和性能上表现优异。

Conclusion: 仿真结果表明，所提出的JTOCRA方法在系统性能上优于其他替代方法，并展现出更好的可扩展性。

Abstract: Mobile edge computing (MEC)-assisted internet of vehicle (IoV) is emerging as
a promising paradigm to provide computing services for vehicles. However,
meeting the computing-sensitive and computation-intensive demands of vehicles
poses several challenges, including the discrepancy between the limited
resource provision and stringent computing requirement, the difficulty in
capturing and integrating the intricate features of the MEC-assisted IoV system
into the problem formulation, and the need for real-time processing and
efficient resource management in the dynamic environment. In this work, we
explore the AI-enabled task offloading and resource allocation for MEC-assisted
consumer IoV systems. Specifically, we first present a multi-MEC-assisted
consumer IoV architecture that leverages the computational resources of MEC
servers to provide offloading services close to vehicles. Subsequently, we
formulate a system cost minimization optimization problem (SCMOP) by
integrating the service delay and energy consumption. To efficiently solve this
problem, we design a joint task offloading and computing resource allocation
approach (JTOCRA) by applying the multi-agent deep deterministic policy
gradient (MADDPG) algorithm. Finally, simulation results demonstrate that the
proposed JTOCRA can achieve superior system performances and exhibits better
scalability compared to other alternative approaches.

</details>


### [89] [Better Together: Leveraging Multiple Digital Twins for Deployment Optimization of Airborne Base Stations](https://arxiv.org/abs/2508.15816)
*Mauro Belgiovine,Chris Dick,Kaushik Chowdhury*

Main category: cs.NI

TL;DR: 本文提出了一种数字孪生引导的方法，通过软件桥和算法设计优化无人机基站部署，并在大规模场景中验证了其性能，同时提出了弹性覆盖机制。


<details>
  <summary>Details</summary>
Motivation: 无人机基站（ABSs）能够灵活分配网络资源，并在自然灾害时快速部署备用连接方案。由于无人机飞行时间有限，需要通过数字孪生技术确定最佳部署位置，避免耗时的实地试验。

Method: 1. 实现两个开源数字孪生平台（NVIDIA的Sionna和Aerial Omniverse Digital Twin）之间的交互式软件桥；2. 在Sionna中设计基于反向传播的算法，快速收敛于无人机物理位置、天线方向和发射功率；3. 在AODT中进行大规模网络场景的数值评估。

Result: 1. 通过软件桥实现了两个数字孪生平台的高保真场景评估；2. 设计的算法能够快速优化无人机位置、天线方向和发射功率；3. 在大规模网络场景中验证了环境条件对性能结果的影响；4. 提出了针对关键任务设备的弹性覆盖机制。

Conclusion: 本文提出了一种基于数字孪生的方法，通过软件桥和算法设计，实现了无人机基站的高效部署和覆盖优化，并在大规模网络场景中验证了其性能。

Abstract: Airborne Base Stations (ABSs) allow for flexible geographical allocation of
network resources with dynamically changing load as well as rapid deployment of
alternate connectivity solutions during natural disasters. Since the radio
infrastructure is carried by unmanned aerial vehicles (UAVs) with limited
flight time, it is important to establish the best location for the ABS without
exhaustive field trials. This paper proposes a digital twin (DT)-guided
approach to achieve this through the following key contributions: (i)
Implementation of an interactive software bridge between two open-source DTs
such that the same scene is evaluated with high fidelity across NVIDIA's Sionna
and Aerial Omniverse Digital Twin (AODT), highlighting the unique features of
each of these platforms for this allocation problem, (ii) Design of a
back-propagation-based algorithm in Sionna for rapidly converging on the
physical location of the UAVs, orientation of the antennas and transmit power
to ensure efficient coverage across the swarm of the UAVs, and (iii) numerical
evaluation in AODT for large network scenarios (50 UEs, 10 ABS) that identifies
the environmental conditions in which there is agreement or divergence of
performance results between these twins. Finally, (iv) we propose a resilience
mechanism to provide consistent coverage to mission-critical devices and
demonstrate a use case for bi-directional flow of information between the two
DTs.

</details>


### [90] [Agent Communications toward Agentic AI at Edge -- A Case Study of the Agent2Agent Protocol](https://arxiv.org/abs/2508.15819)
*Qiang Duan,Zhihui Lu*

Main category: cs.NI

TL;DR: 本文评估了A2A协议在边缘计算中的有效性，指出了当前代理通信技术的不足，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前代理通信协议设计时未充分考虑边缘计算的特殊挑战，且其在边缘环境中的有效性尚未得到充分验证。本文旨在评估代理通信技术在边缘计算挑战下的能力。

Method: 本文首先讨论了代理通信的核心功能，概述了代理通信协议的现状，并识别了边缘计算带来的主要挑战。然后，以A2A协议为例，研究了其在边缘计算环境中满足通信需求的关键技术。

Result: 研究发现A2A协议在边缘计算环境中存在局限性，并提出了未来研究的方向以解决这些挑战。

Conclusion: 本文通过评估A2A协议在边缘计算环境中的有效性，指出了当前代理通信技术的局限性，并提出了未来研究的方向，以解决这些开放性问题。

Abstract: The current evolution of artificial intelligence introduces a paradigm shift
toward agentic AI built upon multi-agent systems (MAS). Agent communications
serve as a key to effective agent interactions in MAS and thus have a
significant impact on the performance of agentic AI applications. The recent
research on agent communications has made exciting rapid progress that leads to
a variety of protocol designs, among which the Agent2Agent (A2A) protocol is
considered the most representative one. Simultaneously, the rise of edge
intelligence is expected to enable agentic AI at the network edge. However, the
current agent communication protocols are designed without sufficient
consideration of the special challenges of edge computing, and their
effectiveness in the edge environment is largely unexamined. In this paper, we
attempt to assess the abilities of agent communication technologies to face the
challenges of edge computing using the A2A protocol as a representative case.
We first discuss the core functionalities of agent communications, present a
landscape of agent communication protocols, and identify the main challenges
introduced by edge computing. Then, we conduct a case study on the A2A protocol
to examine the key technologies leveraged in the protocol for their
effectiveness in meeting the requirements of agent communications in edge
computing. Based on the insights obtained from this assessment, we identify
open issues in the current agent communication technologies and discuss
directions for future research to address these issues.

</details>


### [91] [Towards Integrated Energy-Communication-Transportation Hub: A Base-Station-Centric Design in 5G and Beyond](https://arxiv.org/abs/2508.15833)
*Linfeng Shen,Guanzhen Wu,Cong Zhang,Xiaoyi Fan,Jiangchuan Liu*

Main category: cs.NI

TL;DR: 本文提出了一种基于深度强化学习的ECT-Hub模型，通过智能调度基站电池和可再生能源，有效优化能源利用并降低运营成本，特别是在电动汽车充电方面表现突出。


<details>
  <summary>Details</summary>
Motivation: 随着5G基站的广泛部署，能源消耗问题日益突出。工业界对利用储能系统存储非高峰时段的过剩能源表现出浓厚兴趣，以降低成本并参与需求响应。本文旨在探索基站作为能源-通信-交通（ECT）枢纽的潜力，特别是在电动汽车充电方面的应用。

Method: 本文采用了一种基于深度强化学习的电池调度方法，并结合激励机制设置充电价格，考虑了基站流量状况、天气和电动汽车充电行为等多种因素。

Result: 实验结果表明，ECT-Hub模型在优化剩余能源利用和降低运营成本方面具有显著效果，特别是在通过电动汽车充电创收方面。

Conclusion: 本文提出的ECT-Hub模型通过智能调度基站电池和可再生能源，有效优化了剩余能源利用并降低了运营成本，特别是在通过电动汽车充电创收方面表现突出。

Abstract: The rise of 5G communication has transformed the telecom industry for
critical applications. With the widespread deployment of 5G base stations comes
a significant concern about energy consumption. Key industrial players have
recently shown strong interest in incorporating energy storage systems to store
excess energy during off-peak hours, reducing costs and participating in demand
response. The fast development of batteries opens up new possibilities, such as
the transportation area. An effective method is needed to maximize base station
battery utilization and reduce operating costs. In this trend towards
next-generation smart and integrated energy-communication-transportation (ECT)
infrastructure, base stations are believed to play a key role as service hubs.
By exploring the overlap between base station distribution and electric vehicle
charging infrastructure, we demonstrate the feasibility of efficiently charging
EVs using base station batteries and renewable power plants at the Hub. Our
model considers various factors, including base station traffic conditions,
weather, and EV charging behavior. This paper introduces an incentive mechanism
for setting charging prices and employs a deep reinforcement learning-based
method for battery scheduling. Experimental results demonstrate the
effectiveness of our proposed ECT-Hub in optimizing surplus energy utilization
and reducing operating costs, particularly through revenue-generating EV
charging.

</details>


### [92] [Self-Healing Network of Interconnected Edge Devices Empowered by Infrastructure-as-Code and LoRa Communication](https://arxiv.org/abs/2508.16268)
*Rob Carson,Mohamed Chahine Ghanem,Feriel Bouakkaz*

Main category: cs.NI

TL;DR: 论文提出了一种基于树莓派和LoRa的自愈自动化网络，通过容器化IaC和故障转移机制解决带宽和节点故障问题，实验证明有效但仍需优化碰撞和干扰问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在传统网络不可用场景下的网络部署挑战，特别是针对LoRa协议的局限性（如带宽限制和碰撞问题）以及节点故障的恢复需求。

Method: 论文采用容器化架构在树莓派集群中部署IaC原则，适应了LoRa的包基系统与传统IaC工具的不兼容性。通过数据包分片和重传机制缓解了LoRa的吞吐量和包大小限制，并集成了自动故障转移机制。

Result: 实验结果表明，数据包分片和重传机制有效缓解了LoRa的吞吐量限制，自动故障转移机制能在1秒内重新部署无响应的服务，展现了系统的韧性。但仍存在碰撞和视线干扰等问题。

Conclusion: 该论文提出了一种基于树莓派的自愈自动化网络，适用于传统网络不可用的场景。通过结合LoRa协议的低功耗长距离特性和基础设施即代码（IaC）方法，解决了带宽限制、数据碰撞和节点故障等问题。未来研究方向包括集成网状网络以增强覆盖范围、开发更先进的调度算法以及采用最新的LPWAN技术。

Abstract: This Paper proposes a self-healing, automated network of Raspberry Pi devices
designed for deployment in scenarios where traditional networking is
unavailable. Leveraging the low-power, long-range capabilities of the LoRa
(Long Range) protocol alongside Infrastructure as Code (IaC) methodologies, the
research addresses challenges such as limited bandwidth, data collisions, and
node failures. Given that LoRa's packet-based system is incompatible with
conventional IaC tools like Ansible and Terraform, which rely on TCP/IP
networking, the research adapts IaC principles within a containerised
architecture deployed across a Raspberry Pi cluster. Evaluation experiments
indicate that fragmenting data packets and retransmitting any missed fragments
can mitigate LoRa's inherent throughput and packet size limitations, although
issues such as collisions and line-of-sight interference persist. An automated
failover mechanism was integrated into the architecture, enabling unresponsive
services to be redeployed to alternative nodes within one second, demonstrating
the system's resilience in maintaining operational continuity despite node or
service failures. The paper also identifies practical challenges, including the
necessity for time-slotting transmissions to prevent data packet overlap and
collisions. Future research should explore the integration of mesh networking
to enhance range, develop more advanced scheduling algorithms, and adopt
cutting-edge low-power wide-area network (LPWAN) techniques.

</details>


### [93] [Safeguarding ISAC Performance in Low-Altitude Wireless Networks Under Channel Access Attack](https://arxiv.org/abs/2508.15838)
*Jiacheng Wang,Jialing He,Geng Sun,Zehui Xiong,Dusit Niyato,Shiwen Mao,Dong In Kim,Tao Xiang*

Main category: cs.NI

TL;DR: 本文提出了一种基于Stackelberg博弈的框架，通过逆向归纳算法优化LAWNs中的ISAC性能，有效缓解了恶意攻击的影响。


<details>
  <summary>Details</summary>
Motivation: 低空空域的开放性使得LAWNs易受恶意攻击，影响ISAC性能，因此需要开发一种框架来缓解这种影响。

Method: 首先推导了攻击条件下通信数据的信干噪比和感知数据的信息年龄表达式，作为服务质量指标。随后将ISAC性能优化问题建模为Stackelberg博弈，并设计了一种逆向归纳算法以实现均衡。

Result: 仿真结果表明，所提算法优于现有基线和静态纳什均衡基准，确保了LAWNs能为低空应用提供可靠服务。同时证明了均衡的存在性和唯一性。

Conclusion: 本文通过提出一种基于博弈论的框架，成功缓解了低空无线网络（LAWNs）中恶意攻击对集成感知与通信（ISAC）性能的影响，并通过仿真验证了算法的优越性。

Abstract: The increasing saturation of terrestrial resources has driven the exploration
of low-altitude applications such as air taxis. Low altitude wireless networks
(LAWNs) serve as the foundation for these applications, and integrated sensing
and communication (ISAC) constitutes one of the core technologies within LAWNs.
However, the openness nature of low-altitude airspace makes LAWNs vulnerable to
malicious channel access attacks, which degrade the ISAC performance.
Therefore, this paper develops a game-based framework to mitigate the influence
of the attacks on LAWNs. Concretely, we first derive expressions of
communication data's signal-to-interference-plus-noise ratio and the age of
information of sensing data under attack conditions, which serve as quality of
service metrics. Then, we formulate the ISAC performance optimization problem
as a Stackelberg game, where the attacker acts as the leader, and the
legitimate drone and the ground ISAC base station act as second and first
followers, respectively. On this basis, we design a backward induction
algorithm that achieves the Stackelberg equilibrium while maximizing the
utilities of all participants, thereby mitigating the attack-induced
degradation of ISAC performance in LAWNs. We further prove the existence and
uniqueness of the equilibrium. Simulation results show that the proposed
algorithm outperforms existing baselines and a static Nash equilibrium
benchmark, ensuring that LAWNs can provide reliable service for low-altitude
applications.

</details>


### [94] [xDiff: Online Diffusion Model for Collaborative Inter-Cell Interference Management in 5G O-RAN](https://arxiv.org/abs/2508.15843)
*Peihao Yan,Huacheng Zeng,Y. Thomas Hou*

Main category: cs.NI

TL;DR: xDiff是一种基于扩散模型的强化学习框架，用于O-RAN中的小区间干扰管理，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: O-RAN作为5G及未来网络的关键架构，需要智能高效的资源管理方案；扩散模型在图像和视频生成中的表现使其成为网络优化的潜在工具。

Method: 提出xDiff框架，将扩散模型整合到强化学习中，用于近实时策略生成，并引入偏好值作为策略表示以指导资源分配。

Result: 在由三个小区和一组智能手机组成的5G测试平台上，xDiff在两种小蜂窝场景中优于现有ICIM方法。

Conclusion: xDiff框架通过将扩散模型与强化学习结合，显著提升了O-RAN中的小区间干扰管理性能，展示了扩散模型在网络优化中的潜力。

Abstract: Open Radio Access Network (O-RAN) is a key architectural paradigm for 5G and
beyond cellular networks, enabling the adoption of intelligent and efficient
resource management solutions. Meanwhile, diffusion models have demonstrated
remarkable capabilities in image and video generation, making them attractive
for network optimization tasks. In this paper, we propose xDiff, a
diffusion-based reinforcement learning(RL) framework for inter-cell
interference management (ICIM) in O-RAN. We first formulate ICIM as a resource
allocation optimization problem aimed at maximizing a user-defined reward
function and then develop an online learning solution by integrating a
diffusion model into an RL framework for near-real-time policy generation.
Particularly, we introduce a novel metric, preference values, as the policy
representation to enable efficient policy-guided resource allocation within
O-RAN distributed units (DUs). We implement xDiff on a 5G testbed consisting of
three cells and a set of smartphones in two small-cell scenarios. Experimental
results demonstrate that xDiff outperforms state-of-the-art ICIM approaches,
highlighting the potential of diffusion models for online optimization of
O-RAN. Source code is available on GitHub [1].

</details>


### [95] [Time Series Based Network Intrusion Detection using MTF-Aided Transformer](https://arxiv.org/abs/2508.16035)
*Poorvi Joshi,Mohan Gurusamy*

Main category: cs.NI

TL;DR: 该论文提出了一种MTF辅助的Transformer模型，用于SDN时间序列分类，在数据受限环境中表现优异且高效。


<details>
  <summary>Details</summary>
Motivation: 针对SDN应用中常见的数据受限环境，设计一个能够高效分类时间序列的模型。

Method: 提出了一种结合马尔可夫转移场（MTF）和Transformer架构的新方法，专门用于软件定义网络（SDN）的时间序列分类。

Result: 在InSDN数据集上评估表明，该模型优于基线分类模型，尤其在数据受限环境中表现更佳，同时保持了竞争力的训练和推理时间。

Conclusion: 该研究确立了MTF辅助的Transformer在解决SDN时间序列分类挑战中的潜力，为稀疏数据场景下的可靠和可扩展分析提供了有前景的路径。

Abstract: This paper introduces a novel approach to time series classification using a
Markov Transition Field (MTF)-aided Transformer model, specifically designed
for Software-Defined Networks (SDNs). The proposed model integrates the
temporal dependency modeling strengths of MTFs with the sophisticated pattern
recognition capabilities of Transformer architectures. We evaluate the model's
performance using the InSDN dataset, demonstrating that our model outperforms
baseline classification models, particularly in data-constrained environments
commonly encountered in SDN applications. We also highlight the relationship
between the MTF and Transformer components, which leads to better performance,
even with limited data. Furthermore, our approach achieves competitive training
and inference times, making it an efficient solution for real-world SDN
applications. These findings establish the potential of MTF-aided Transformers
to address the challenges of time series classification in SDNs, offering a
promising path for reliable and scalable analysis in scenarios with sparse
data.

</details>


### [96] [Congestion Control System Optimization with Large Language Models](https://arxiv.org/abs/2508.16074)
*Zhiyuan He,Aashish Gottipati,Lili Qiu,Yuqing Yang,Francis Y. Yan*

Main category: cs.NI

TL;DR: 论文提出利用LLMs自动优化拥塞控制算法，通过结构化生成和评估方法，成功实现性能提升高达27%。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量研究，现有拥塞控制算法在不同网络环境中仍表现不佳，因此需要一种新方法来优化这些算法。

Method: 论文提出了一种结构化算法生成过程、基于仿真的广泛网络条件评估流水线，以及统计指导的方法以显著减少评估时间。

Result: 通过四种不同的LLMs验证，该方法有效识别出性能提升显著的算法，其中在QUIC实现中性能提升高达27%。

Conclusion: 该论文展示了利用大型语言模型（LLMs）自动优化拥塞控制算法的潜力，成功识别出在QUIC实现中性能提升高达27%的算法，为网络系统设计开辟了新途径。

Abstract: Congestion control is a fundamental component of Internet infrastructure, and
researchers have dedicated considerable effort to developing improved
congestion control algorithms. However, despite extensive study, existing
algorithms continue to exhibit suboptimal performance across diverse network
environments. In this paper, we introduce a novel approach that automatically
optimizes congestion control algorithms using large language models (LLMs). Our
framework consists of a structured algorithm generation process, an
emulation-based evaluation pipeline covering a broad range of network
conditions, and a statistically guided method to substantially reduce
evaluation time. Empirical results from four distinct LLMs validate the
effectiveness of our approach. We successfully identify algorithms that achieve
up to 27% performance improvements over the original BBR algorithm in a
production QUIC implementation. Our work demonstrates the potential of LLMs to
accelerate the design of high-performance network algorithms and paves the way
for broader applications in networking systems.

</details>


### [97] [ANSC: Probabilistic Capacity Health Scoring for Datacenter-Scale Reliability](https://arxiv.org/abs/2508.16119)
*Madhava Gaikwad,Abhishek Gandhi*

Main category: cs.NI

TL;DR: ANSC是一个概率容量健康评分框架，通过颜色编码评分系统帮助运营商优先处理关键风险，减少噪音。


<details>
  <summary>Details</summary>
Motivation: 现有警报系统无法捕捉级联容量短缺的总体风险，ANSC旨在填补这一空白，通过概率评估提升风险预警的准确性。

Method: ANSC采用概率模型，结合当前剩余容量和额外故障概率，提供颜色编码的评分系统。

Result: ANSC在400多个数据中心和60个区域中成功应用，帮助运营商优先处理关键风险。

Conclusion: ANSC框架通过概率容量健康评分系统，有效帮助运营商优先处理最关键的风险，减少噪音并优化SRE资源分配。

Abstract: We present ANSC, a probabilistic capacity health scoring framework for
hyperscale datacenter fabrics. While existing alerting systems detect
individual device or link failures, they do not capture the aggregate risk of
cascading capacity shortfalls. ANSC provides a color-coded scoring system that
indicates the urgency of issues \emph{not solely by current impact, but by the
probability of imminent capacity violations}. Our system accounts for both
current residual capacity and the probability of additional failures,
normalized at datacenter and regional level. We demonstrate that ANSC enables
operators to prioritize remediation across more than 400 datacenters and 60
regions, reducing noise and aligning SRE focus on the most critical risks.

</details>


### [98] [Joint Cache Placement and Routing in Satellite-Terrestrial Edge Computing Network: A GNN-Enabled DRL Approach](https://arxiv.org/abs/2508.16184)
*Yuhao Zheng,Ting You,Kejia Peng,Chang Liu*

Main category: cs.NI

TL;DR: 论文提出GNN与DRL结合的框架，优化卫星-地面边缘计算网络的内容缓存和路由，显著提升交付成功率并降低通信成本。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决低地球轨道（LEO）卫星拓扑动态性和内容需求异构性带来的挑战，提升地理分布用户的内容缓存服务。

Method: 论文采用图神经网络（GNN）与深度强化学习（DRL）结合的框架，将卫星网络表示为动态图，并通过马尔可夫决策过程（MDP）和软演员-评论家（SAC）算法优化缓存策略。

Result: 仿真结果表明，该方法显著提高了交付成功率并降低了通信流量成本。

Conclusion: 该论文提出的学习框架结合GNN和DRL，显著提升了卫星-地面边缘计算网络中的内容缓存和路由效率，提高了交付成功率并降低了通信流量成本。

Abstract: In this letter, we investigate the problem of joint content caching and
routing in satellite-terrestrial edge computing networks (STECNs) to improve
caching service for geographically distributed users. To handle the challenges
arising from dynamic low Earth orbit (LEO) satellite topologies and
heterogeneous content demands, we propose a learning-based framework that
integrates graph neural networks (GNNs) with deep reinforcement learning (DRL).
The satellite network is represented as a dynamic graph, where GNNs are
embedded within the DRL agent to capture spatial and topological dependencies
and support routing-aware decision-making. The caching strategy is optimized by
formulating the problem as a Markov decision process (MDP) and applying soft
actor-critic (SAC) algorithm. Simulation results demonstrate that our approach
significantly improves the delivery success rate and reduces communication
traffic cost.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [99] [T-ILR: a Neurosymbolic Integration for LTLf](https://arxiv.org/abs/2508.15943)
*Riccardo Andreoni,Andrei Buliga,Alessandro Daniele,Chiara Ghidini,Marco Montali,Massimiliano Ronzani*

Main category: cs.AI

TL;DR: 提出T-ILR框架，直接整合LTLf到深度学习，提升时序任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于显式有限状态自动机表示，无法高效处理时序逻辑规范，因此需要一种直接整合LTLf的框架。

Method: 通过扩展迭代局部细化（ILR）神经符号算法，并利用模糊LTLf解释，设计了T-ILR方法。

Result: 在图像序列分类任务中，T-ILR相比现有方法表现出更高的准确性和计算效率。

Conclusion: 本文提出了一种名为T-ILR的神经符号框架，成功将线性时序逻辑（LTLf）直接整合到深度学习架构中，显著提升了时序任务的准确性和计算效率。

Abstract: State-of-the-art approaches for integrating symbolic knowledge with deep
learning architectures have demonstrated promising results in static domains.
However, methods to handle temporal logic specifications remain underexplored.
The only existing approach relies on an explicit representation of a
finite-state automaton corresponding to the temporal specification. Instead, we
aim at proposing a neurosymbolic framework designed to incorporate temporal
logic specifications, expressed in Linear Temporal Logic over finite traces
(LTLf), directly into deep learning architectures for sequence-based tasks. We
extend the Iterative Local Refinement (ILR) neurosymbolic algorithm, leveraging
the recent introduction of fuzzy LTLf interpretations. We name this proposed
method Temporal Iterative Local Refinement (T-ILR). We assess T-ILR on an
existing benchmark for temporal neurosymbolic architectures, consisting of the
classification of image sequences in the presence of temporal knowledge. The
results demonstrate improved accuracy and computational efficiency compared to
the state-of-the-art method.

</details>


### [100] [CoFE: A Framework Generating Counterfactual ECG for Explainable Cardiac AI-Diagnostics](https://arxiv.org/abs/2508.16033)
*Jong-Hwan Jang,Junho Song,Yong-Yeon Jo*

Main category: cs.AI

TL;DR: 该论文提出了一种名为CoFE的框架，通过生成反事实ECG信号增强AI-ECG模型的可解释性，并通过两个案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI-ECG模型在临床实践中成功集成的可解释性问题，作者提出了CoFE框架，旨在阐明ECG信号中有效特征的位置及其对模型预测的影响。

Method: 引入了一个名为CoFE的框架，生成反事实ECG信号，以展示特定特征（如振幅和间隔）如何影响模型的预测决策。通过心房颤动分类和钾水平回归模型的两个案例研究验证了CoFE的适用性。

Result: CoFE揭示了与现有临床知识一致的ECG信号特征变化，明确了有效特征在ECG中的位置及其对模型预测的影响。

Conclusion: 该论文提出的CoFE框架通过生成反事实ECG信号，增强了AI-ECG模型的可解释性，有望支持更有效的临床决策。

Abstract: Recognizing the need for explainable AI (XAI) approaches to enable the
successful integration of AI-based ECG prediction models (AI-ECG) into clinical
practice, we introduce a framework generating \textbf{Co}unter\textbf{F}actual
\textbf{E}CGs (i,e., named CoFE) to illustrate how specific features, such as
amplitudes and intervals, influence the model's predictive decisions. To
demonstrate the applicability of the CoFE, we present two case studies: atrial
fibrillation classification and potassium level regression models. The CoFE
reveals feature changes in ECG signals that align with the established clinical
knowledge. By clarifying both \textbf{where valid features appear} in the ECG
and \textbf{how they influence the model's predictions}, we anticipate that our
framework will enhance the interpretability of AI-ECG models and support more
effective clinical decision-making. Our demonstration video is available at:
https://www.youtube.com/watch?v=YoW0bNBPglQ.

</details>


### [101] [MMAPG: A Training-Free Framework for Multimodal Multi-hop Question Answering via Adaptive Planning Graphs](https://arxiv.org/abs/2508.16051)
*Yiheng Hu,Xiaoyang Wang,Qing Liu,Xiwei Xu,Qian Fu,Wenjie Zhang,Liming Zhu*

Main category: cs.AI

TL;DR: 提出了一种基于自适应规划图的训练免费框架，用于多模态多跳问答，无需训练即可优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态多跳问答方法通常依赖顺序检索和推理，这种单一路径范式容易因误导性中间步骤而产生错误，且多模态模型的开发通常计算成本高昂。

Method: 通过规划、检索和推理模块组成的自适应规划图，实现动态灵活的推理路径探索，并设计了针对不同数据类型的模态特定策略。

Result: 在MultimodalQA和WebQA上的实验结果显示，该方法无需训练即可匹配或超越依赖训练的现有模型。

Conclusion: 该论文提出的基于自适应规划图的训练免费框架在MultimodalQA和WebQA上的实验表明，其表现与或优于依赖训练的现有模型。

Abstract: Multimodal Multi-hop question answering requires integrating information from
diverse sources, such as images and texts, to derive answers. Existing methods
typically rely on sequential retrieval and reasoning, where each step builds on
the previous output. However, this single-path paradigm makes them vulnerable
to errors due to misleading intermediate steps. Moreover, developing multimodal
models can be computationally expensive, often requiring extensive training. To
address these limitations, we propose a training-free framework guided by an
Adaptive Planning Graph, which consists of planning, retrieval and reasoning
modules. The planning module analyzes the current state of the Adaptive
Planning Graph, determines the next action and where to expand the graph, which
enables dynamic and flexible exploration of reasoning paths. To handle
retrieval of text to unspecified target modalities, we devise modality-specific
strategies that dynamically adapt to distinct data types. Our approach
preserves the characteristics of multimodal information without costly
task-specific training, enabling seamless integration with up-to-date models.
Finally, the experiments on MultimodalQA and WebQA show that our approach
matches or outperforms existing models that rely on training.

</details>


### [102] [Generative Foundation Model for Structured and Unstructured Electronic Health Records](https://arxiv.org/abs/2508.16054)
*Sonish Sivarajkumar,Hang Zhang,Yuelyu Ji,Maneesh Bilalpur,Xizhi Wu,Chenyu Li,Min Gu Kwak,Shyam Visweswaran,Yanshan Wang*

Main category: cs.AI

TL;DR: GDP是一种多模态基础模型，能同时处理结构化EHR时间序列和非结构化临床笔记，通过两阶段训练实现临床预测和叙述生成，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 电子健康记录（EHRs）是丰富的临床数据源，但包含复杂异构数据。利用这种异构性对改善患者结局至关重要。当前方法通常将数值EHR数据序列化为文本，可能丢失时间和定量细节。

Method: GDP采用两阶段训练：(1)生成预训练，学习从原始患者时间线生成临床叙述，同时进行掩码特征预测（MFP）和下一时间步预测（NTP）以捕捉时间动态；(2)多任务微调，用于临床有意义的预测（如心衰、2型糖尿病、30天再入院）。

Result: 在临床预测中，GDP在MIMIC-IV上表现优异：心衰AUROC=0.923，2型糖尿病AUROC=0.817，30天再入院AUROC=0.627。在叙述生成中，ROUGE-L=0.135，BERTScore-F1=0.545。盲评中GDP-Instruct在忠实性、流畅性和临床实用性上得分最高。

Conclusion: 研究结果表明，单一的多模态基础模型不仅能预测临床可操作事件，还能生成高质量的临床叙述。此外，GDP的灵活架构可扩展到其他模态。

Abstract: Electronic health records (EHRs) are rich clinical data sources but complex
repositories of patient data, spanning structured elements (demographics,
vitals, lab results, codes), unstructured clinical notes and other modalities
of data. Harnessing this heterogeneity is critical for improving patient
outcomes. Recent advances in large language models (LLMs) have enabled
foundation models that can learn from multiple data modalities and support
clinical tasks. However, most current approaches simply serialize numeric EHR
data into text, which risks losing temporal and quantitative detail. We
introduce Generative Deep Patient (GDP), a multimodal foundation model that
natively encodes structured EHR time-series via a CNN-Transformer encoder and
fuses it with unstructured EHRs through cross-modal attention into a
LLaMA-based decoder. GDP is trained in two stages: (1) generative pretraining,
where it learns to produce clinical narratives from raw patient timelines while
also performing masked feature prediction (MFP) and next time-step prediction
(NTP) to capture temporal dynamics; and (2) multi-task fine-tuning for
clinically meaningful predictions (e.g., heart failure, type 2 diabetes, 30-day
readmission). In clinical prediction, GDP demonstrated superior performance on
MIMIC-IV: heart failure AUROC = 0.923, type 2 diabetes AUROC = 0.817, and
30-day readmission AUROC = 0.627. For narrative generation, GDP achieved
ROUGE-L = 0.135 and BERTScore-F1 = 0.545. In a blinded human evaluation,
GDP-Instruct scored highest on faithfulness, fluency, and overall clinical
utility, suggesting reduced hospital documentation workload without sacrificing
accuracy. Our results demonstrate that a single multimodal foundation model can
both predict clinically actionable events and generate high-quality clinical
narratives. Furthermore, GDP's flexible architecture can be extended to
additional modalities.

</details>


### [103] [Urban Comfort Assessment in the Era of Digital Planning: A Multidimensional, Data-driven, and AI-assisted Framework](https://arxiv.org/abs/2508.16057)
*Sijie Yang,Binyu Lei,Filip Biljecki*

Main category: cs.AI

TL;DR: 该研究探讨了数字规划中城市舒适度的理论和方法论评估，提出了多维分析、数据支持和AI辅助三个关键维度。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量研究使用计算方法评估城市舒适度相关因素，但城市舒适度的明确定义和综合评估框架仍不明确。本研究旨在填补这一空白。

Method: 研究采用了理论解释和评估方法论的探索，重点关注多维分析、数据支持和AI辅助三个维度。

Result: 研究提出了在数字规划中评估城市舒适度的理论和方法论框架，强调了多维分析、数据支持和AI辅助的重要性。

Conclusion: 该研究强调了在数字规划中评估城市舒适度的理论解释和方法论，提出了多维分析、数据支持和AI辅助三个关键维度，为城市舒适度的综合评估框架提供了新的视角。

Abstract: Ensuring liveability and comfort is one of the fundamental objectives of
urban planning. Numerous studies have employed computational methods to assess
and quantify factors related to urban comfort such as greenery coverage,
thermal comfort, and walkability. However, a clear definition of urban comfort
and its comprehensive evaluation framework remain elusive. Our research
explores the theoretical interpretations and methodologies for assessing urban
comfort within digital planning, emphasising three key dimensions:
multidimensional analysis, data support, and AI assistance.

</details>


### [104] [Integrating Time Series into LLMs via Multi-layer Steerable Embedding Fusion for Enhanced Forecasting](https://arxiv.org/abs/2508.16059)
*Zhuomin Chen,Dan Li,Jiahui Zhou,Shunyu Wu,Haozheng Ye,Jian Lou,See-Kiong Ng*

Main category: cs.AI

TL;DR: MSEF框架通过多层融合TS信息，解决了LLM在时间序列预测中信息丢失的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将LLM应用于时间序列预测时，TS信息在深层逐渐消失，导致文本嵌入与TS表示之间的适应效果不佳。

Method: MSEF利用现成的时间序列基础模型提取语义丰富的嵌入，并通过层特定引导向量将其与LLM中间文本表示融合。

Result: 在七个基准测试中，MSEF相比基线方法表现出显著的性能提升。

Conclusion: MSEF框架通过多层可引导嵌入融合，显著提升了大型语言模型在时间序列预测中的性能，平均MSE降低了31.8%。

Abstract: Time series (TS) data are ubiquitous across various application areas,
rendering time series forecasting (TSF) a fundamental task. With the astounding
advances in large language models (LLMs), a variety of methods have been
developed to adapt LLMs for time series forecasting. Despite unlocking the
potential of LLMs in comprehending TS data, existing methods are inherently
constrained by their shallow integration of TS information, wherein LLMs
typically access TS representations at shallow layers, primarily at the input
layer. This causes the influence of TS representations to progressively fade in
deeper layers and eventually leads to ineffective adaptation between textual
embeddings and TS representations. In this paper, we propose the Multi-layer
Steerable Embedding Fusion (MSEF), a novel framework that enables LLMs to
directly access time series patterns at all depths, thereby mitigating the
progressive loss of TS information in deeper layers. Specifically, MSEF
leverages off-the-shelf time series foundation models to extract semantically
rich embeddings, which are fused with intermediate text representations across
LLM layers via layer-specific steering vectors. These steering vectors are
designed to continuously optimize the alignment between time series and textual
modalities and facilitate a layer-specific adaptation mechanism that ensures
efficient few-shot learning capabilities. Experimental results on seven
benchmarks demonstrate significant performance improvements by MSEF compared
with baselines, with an average reduction of 31.8% in terms of MSE. The code is
available at https://github.com/One1sAll/MSEF.

</details>


### [105] [InMind: Evaluating LLMs in Capturing and Applying Individual Human Reasoning Styles](https://arxiv.org/abs/2508.16072)
*Zizhen Li,Chuanhao Li,Yibin Wang,Qi Chen,Diping Song,Yukang Feng,Jianwen Sun,Jiaxin Ai,Fanrui Zhang,Mingzhu Sun,Kaipeng Zhang*

Main category: cs.AI

TL;DR: InMind框架评估LLMs在社交演绎游戏中捕捉和应用个性化推理风格的能力，发现通用LLMs表现有限，而推理增强的LLMs展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 现有评估往往忽视了个性化推理风格对人们在社交情境中解释和行动的影响，而社交演绎游戏（SDGs）为评估这种个性化推理风格提供了天然测试平台。

Method: InMind框架通过增强结构化游戏数据（包括回合级策略追踪和赛后反思），在Observer和Participant模式下收集数据，支持四项认知驱动的任务，评估静态对齐和动态适应性。

Result: 通用LLMs（如GPT-4o）常依赖词汇线索，难以在时间游戏中锚定反思或适应策略演变；而增强推理的LLMs（如DeepSeek-R1）显示出风格敏感推理的早期迹象。

Conclusion: InMind框架揭示了当前LLMs在个性化、适应性推理能力上的关键限制，并为认知对齐的人机交互迈出了重要一步。

Abstract: LLMs have shown strong performance on human-centric reasoning tasks. While
previous evaluations have explored whether LLMs can infer intentions or detect
deception, they often overlook the individualized reasoning styles that
influence how people interpret and act in social contexts. Social deduction
games (SDGs) provide a natural testbed for evaluating individualized reasoning
styles, where different players may adopt diverse but contextually valid
reasoning strategies under identical conditions. To address this, we introduce
InMind, a cognitively grounded evaluation framework designed to assess whether
LLMs can capture and apply personalized reasoning styles in SDGs. InMind
enhances structured gameplay data with round-level strategy traces and
post-game reflections, collected under both Observer and Participant modes. It
supports four cognitively motivated tasks that jointly evaluate both static
alignment and dynamic adaptation. As a case study, we apply InMind to the game
Avalon, evaluating 11 state-of-the-art LLMs. General-purpose LLMs, even GPT-4o
frequently rely on lexical cues, struggling to anchor reflections in temporal
gameplay or adapt to evolving strategies. In contrast, reasoning-enhanced LLMs
like DeepSeek-R1 exhibit early signs of style-sensitive reasoning. These
findings reveal key limitations in current LLMs' capacity for individualized,
adaptive reasoning, and position InMind as a step toward cognitively aligned
human-AI interaction.

</details>


### [106] [IR-Agent: Expert-Inspired LLM Agents for Structure Elucidation from Infrared Spectra](https://arxiv.org/abs/2508.16112)
*Heewoong Noh,Namkyeong Lee,Gyoung S. Na,Kibum Kim,Chanyoung Park*

Main category: cs.AI

TL;DR: IR-Agent是一个模拟专家分析的多智能体框架，通过互补角色提高红外光谱解析的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能反映专家分析过程且缺乏灵活性，无法有效整合多样化的化学知识。

Method: 提出IR-Agent，一个多智能体框架，每个智能体专注于红外光谱解析的特定方面，通过互补角色实现集成推理。

Result: 实验表明，IR-Agent不仅提高了实验红外光谱的基线性能，还显示出对各种化学信息的强适应性。

Conclusion: IR-Agent作为一种新颖的多智能体框架，能够有效模拟专家驱动的红外分析过程，并通过集成推理提高结构解析的准确性。

Abstract: Spectral analysis provides crucial clues for the elucidation of unknown
materials. Among various techniques, infrared spectroscopy (IR) plays an
important role in laboratory settings due to its high accessibility and low
cost. However, existing approaches often fail to reflect expert analytical
processes and lack flexibility in incorporating diverse types of chemical
knowledge, which is essential in real-world analytical scenarios. In this
paper, we propose IR-Agent, a novel multi-agent framework for molecular
structure elucidation from IR spectra. The framework is designed to emulate
expert-driven IR analysis procedures and is inherently extensible. Each agent
specializes in a specific aspect of IR interpretation, and their complementary
roles enable integrated reasoning, thereby improving the overall accuracy of
structure elucidation. Through extensive experiments, we demonstrate that
IR-Agent not only improves baseline performance on experimental IR spectra but
also shows strong adaptability to various forms of chemical information.

</details>


### [107] [Extending FKG.in: Towards a Food Claim Traceability Network](https://arxiv.org/abs/2508.16117)
*Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain*

Main category: cs.AI

TL;DR: 本文提出了一种食物声明追踪网络（FCN），扩展了现有的印度食物知识图谱（FKG.in），旨在通过结构化和可验证的方式追踪和验证食物相关声明，以提升食物知识的透明度和可信度。


<details>
  <summary>Details</summary>
Motivation: 全球食物领域存在大量科学、文化和商业声明，但追踪和验证这些声明的设施仍不完善。本文旨在通过构建一个结构化的食物声明追踪网络，提升食物知识的透明度和可信度。

Method: 提出了FCN作为FKG.in的扩展，设计了本体结构，并开发了半自动知识管理流程，利用Reddit数据和大型语言模型构建了概念验证。

Result: 开发了FCN的原型，集成了结构化数据输入、模式设计和溯源感知的管道，用于食物声明的提取和验证。

Conclusion: FCN为食物声明提供了一个结构化和可验证的模型，有助于提升食物知识生态系统的透明度和可信度，支持研究者、政策制定者和消费者更好地应对食物相关声明。

Abstract: The global food landscape is rife with scientific, cultural, and commercial
claims about what foods are, what they do, what they should not do, or should
not do. These range from rigorously studied health benefits (probiotics improve
gut health) and misrepresentations (soaked almonds make one smarter) to vague
promises (superfoods boost immunity) and culturally rooted beliefs (cold foods
cause coughs). Despite their widespread influence, the infrastructure for
tracing, verifying, and contextualizing these claims remains fragmented and
underdeveloped. In this paper, we propose a Food Claim-Traceability Network
(FCN) as an extension of FKG.in, a knowledge graph of Indian food that we have
been incrementally building. We also present the ontology design and the
semi-automated knowledge curation workflow that we used to develop a proof of
concept of FKG.in-FCN using Reddit data and Large Language Models. FCN
integrates curated data inputs, structured schemas, and provenance-aware
pipelines for food-related claim extraction and validation. While directly
linked to the Indian food knowledge graph as an application, our methodology
remains application-agnostic and adaptable to other geographic, culinary, or
regulatory settings. By modeling food claims and their traceability in a
structured, verifiable, and explainable way, we aim to contribute to more
transparent and accountable food knowledge ecosystems, supporting researchers,
policymakers, and most importantly, everyday consumers in navigating a world
saturated with dietary assertions.

</details>


### [108] [Bridging the Gap in Ophthalmic AI: MM-Retinal-Reason Dataset and OphthaReason Model toward Dynamic Multimodal Reasoning](https://arxiv.org/abs/2508.16129)
*Ruiqi Wu,Yuang Yao,Tengfei Ma,Chenran Zhang,Na Su,Tao Zhou,Geng Chen,Wen Fan,Yi Zhou*

Main category: cs.AI

TL;DR: 提出首个眼科多模态数据集MM-Retinal-Reason及模型OphthaReason，通过UADT方法动态调整推理深度，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗多模态模型多局限于基础推理，无法满足临床诊断中对异构信息与多模态数据整合的需求。

Method: 提出了Uncertainty-Aware Dynamic Thinking (UADT)方法，通过熵估计样本级不确定性，并动态调整模型探索深度。

Result: 在基础与复杂推理任务上，模型性能分别至少提升24.92%和15.00%，优于通用及专用MLLMs。

Conclusion: OphthaReason模型在基础与复杂推理任务上均表现出色，显著优于现有模型，展示了其在眼科多模态推理中的潜力。

Abstract: Multimodal large language models (MLLMs) have recently demonstrated
remarkable reasoning abilities with reinforcement learning paradigm. Although
several multimodal reasoning models have been explored in the medical domain,
most of them focus exclusively on basic reasoning, which refers to shallow
inference based on visual feature matching. However, real-world clinical
diagnosis extends beyond basic reasoning, demanding reasoning processes that
integrate heterogeneous clinical information (such as chief complaints and
medical history) with multimodal medical imaging data. To bridge this gap, we
introduce MM-Retinal-Reason, the first ophthalmic multimodal dataset with the
full spectrum of perception and reasoning. It encompasses both basic reasoning
tasks and complex reasoning tasks, aiming to enhance visual-centric fundamental
reasoning capabilities and emulate realistic clinical thinking patterns.
Building upon MM-Retinal-Reason, we propose OphthaReason, the first
ophthalmology-specific multimodal reasoning model with step-by-step reasoning
traces. To enable flexible adaptation to both basic and complex reasoning
tasks, we specifically design a novel method called Uncertainty-Aware Dynamic
Thinking (UADT), which estimates sample-level uncertainty via entropy and
dynamically modulates the model's exploration depth using a shaped advantage
mechanism. Comprehensive experiments demonstrate that our model achieves
state-of-the-art performance on both basic and complex reasoning tasks,
outperforming general-purpose MLLMs, medical MLLMs, RL-based medical MLLMs, and
ophthalmic MLLMs by at least 24.92\%, 15.00\%, 21.20\%, and 17.66\%. Project
Page: \href{https://github.com/lxirich/OphthaReason}{link}.

</details>


### [109] [Graph RAG as Human Choice Model: Building a Data-Driven Mobility Agent with Preference Chain](https://arxiv.org/abs/2508.16172)
*Kai Hu,Parfait Atchade-Adelomou,Carlo Adornetto,Adrian Mora-Carrero,Luis Alonso-Pastor,Ariel Noyman,Yubo Liu,Kent Larson*

Main category: cs.AI

TL;DR: 本文提出偏好链方法，结合图RAG与LLM，提升交通系统中人类行为的模拟准确性，实验显示其优于标准LLM，并展示了在数据稀缺环境下的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 在城市科学中，理解人类行为至关重要，但尤其是在新开发区域，收集准确的行为数据面临巨大挑战。现有基于LLM的生成代理方法在生成一致、上下文敏感且现实的行为输出方面存在不足。

Method: 本文介绍了偏好链（Preference Chain），一种结合图检索增强生成（RAG）与大语言模型（LLMs）的新方法，以增强交通系统中人类行为的上下文感知模拟。

Result: 在Replica数据集上的实验表明，偏好链在模拟真实世界交通模式选择方面优于标准LLM。开发的移动代理（Mobility Agent）展示了该方法在新兴城市移动建模、个性化旅行行为分析和动态交通预测中的潜在应用。

Conclusion: 尽管存在推理速度慢和幻觉风险等限制，该方法为在数据稀缺环境中模拟复杂人类行为提供了一个有前景的框架，尤其在传统数据驱动模型因数据有限而难以应对的情况下。

Abstract: Understanding human behavior in urban environments is a crucial field within
city sciences. However, collecting accurate behavioral data, particularly in
newly developed areas, poses significant challenges. Recent advances in
generative agents, powered by Large Language Models (LLMs), have shown promise
in simulating human behaviors without relying on extensive datasets.
Nevertheless, these methods often struggle with generating consistent,
context-sensitive, and realistic behavioral outputs. To address these
limitations, this paper introduces the Preference Chain, a novel method that
integrates Graph Retrieval-Augmented Generation (RAG) with LLMs to enhance
context-aware simulation of human behavior in transportation systems.
Experiments conducted on the Replica dataset demonstrate that the Preference
Chain outperforms standard LLM in aligning with real-world transportation mode
choices. The development of the Mobility Agent highlights potential
applications of proposed method in urban mobility modeling for emerging cities,
personalized travel behavior analysis, and dynamic traffic forecasting. Despite
limitations such as slow inference and the risk of hallucination, the method
offers a promising framework for simulating complex human behavior in
data-scarce environments, where traditional data-driven models struggle due to
limited data availability.

</details>


### [110] [Competition and Attraction Improve Model Fusion](https://arxiv.org/abs/2508.16204)
*João Abrantes,Robert Tjarko Lange,Yujin Tang*

Main category: cs.AI

TL;DR: M2N2是一种进化算法，通过动态调整合并边界和多样性保护机制，高效合并模型并实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型合并方法需要手动分区模型参数，限制了潜在组合的探索和性能提升。

Method: 提出了一种名为M2N2的进化算法，具备动态调整合并边界、多样性保护机制和启发式吸引力度量三个关键特征。

Result: M2N2在从零演化MNIST分类器时性能与CMA-ES相当但计算效率更高，同时在合并专业语言和图像生成模型时达到最先进性能。

Conclusion: M2N2通过动态调整合并边界、多样性保护机制和启发式吸引力度量，成功实现了从零开始演化模型，并在合并专业模型时表现出色，展现了其鲁棒性和多功能性。

Abstract: Model merging is a powerful technique for integrating the specialized
knowledge of multiple machine learning models into a single model. However,
existing methods require manually partitioning model parameters into fixed
groups for merging, which restricts the exploration of potential combinations
and limits performance. To overcome these limitations, we propose Model Merging
of Natural Niches (M2N2), an evolutionary algorithm with three key features:
(1) dynamic adjustment of merging boundaries to progressively explore a broader
range of parameter combinations; (2) a diversity preservation mechanism
inspired by the competition for resources in nature, to maintain a population
of diverse, high-performing models that are particularly well-suited for
merging; and (3) a heuristicbased attraction metric to identify the most
promising pairs of models for fusion. Our experimental results demonstrate, for
the first time, that model merging can be used to evolve models entirely from
scratch. Specifically, we apply M2N2 to evolve MNIST classifiers from scratch
and achieve performance comparable to CMA-ES, while being computationally more
efficient. Furthermore, M2N2 scales to merge specialized language and image
generation models, achieving state-of-the-art performance. Notably, it
preserves crucial model capabilities beyond those explicitly optimized by the
fitness function, highlighting its robustness and versatility. Our code is
available at https://github.com/SakanaAI/natural_niches

</details>


### [111] [The next question after Turing's question: Introducing the Grow-AI test](https://arxiv.org/abs/2508.16277)
*Alexandru Tugui*

Main category: cs.AI

TL;DR: GROW-AI框架通过多游戏评估和统一日志，实现对AI实体“成长”水平的连贯评估，捕捉其向成熟发展的路径。


<details>
  <summary>Details</summary>
Motivation: 研究旨在扩展评估人工智能的框架GROW-AI，回答“机器能否成长？”这一问题，作为图灵测试的自然延续。

Method: 基于六个主要标准（C1-C6）的系统，每个标准通过特定“游戏”评估，分为四个领域探索人类维度及其在AI中的转置。使用专家先验方法确定初始权重，全局得分——成长指数——计算为六个分数的算术平均值，并根据成熟度阈值进行解释。

Result: 结果显示，该方法允许对AI实体的“成长”水平进行连贯且可比较的评估，多游戏结构突出了优势和脆弱区域，统一日志保证了评估的可追溯性和可复制性。

Conclusion: GROW-AI框架通过多游戏结构和统一日志，实现了对AI实体“成长”水平的连贯且可比较的评估，无论其类型如何。该方法不仅衡量性能，还捕捉AI实体向成熟发展的进化路径。

Abstract: This study aims to extend the framework for assessing artificial
intelligence, called GROW-AI (Growth and Realization of Autonomous Wisdom),
designed to answer the question "Can machines grow up?" -- a natural successor
to the Turing Test. The methodology applied is based on a system of six primary
criteria (C1-C6), each assessed through a specific "game", divided into four
arenas that explore both the human dimension and its transposition into AI. All
decisions and actions of the entity are recorded in a standardized AI Journal,
the primary source for calculating composite scores. The assessment uses the
prior expert method to establish initial weights, and the global score -- Grow
Up Index -- is calculated as the arithmetic mean of the six scores, with
interpretation on maturity thresholds. The results show that the methodology
allows for a coherent and comparable assessment of the level of "growth" of AI
entities, regardless of their type (robots, software agents, LLMs). The
multi-game structure highlights strengths and vulnerable areas, and the use of
a unified journal guarantees traceability and replicability in the evaluation.
The originality of the work lies in the conceptual transposition of the process
of "growing" from the human world to that of artificial intelligence, in an
integrated testing format that combines perspectives from psychology, robotics,
computer science, and ethics. Through this approach, GROW-AI not only measures
performance but also captures the evolutionary path of an AI entity towards
maturity.

</details>


### [112] [AgentScope 1.0: A Developer-Centric Framework for Building Agentic Applications](https://arxiv.org/abs/2508.16279)
*Dawei Gao,Zitao Li,Yuexiang Xie,Weirui Kuang,Liuyi Yao,Bingchen Qian,Zhijian Ma,Yue Cui,Haohao Luo,Shen Li,Lu Yi,Yi Yu,Shiqi He,Zhiling Luo,Wenmeng Zhou,Zhicheng Zhang,Xuguang He,Ziqian Chen,Weikai Liao,Farruh Isakulovich Kushnazarov,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: AgentScope 1.0 是一个支持工具驱动型智能体交互的框架，通过统一接口、异步设计和内置智能体等功能，提升开发效率和应用性能。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的快速发展，智能体能够结合内在知识与动态工具使用，从而更好地解决现实任务。AgentScope旨在全面支持灵活高效的工具驱动型智能体-环境交互，推动智能体应用的开发。

Method: 抽象了智能体应用的基础组件，提供统一的接口和可扩展模块；基于ReAct范式设计智能体行为，采用系统化的异步设计；集成特定场景的内置智能体，并提供开发者友好的工程支持。

Result: AgentScope 1.0 提供了统一的开发接口、可扩展模块、异步设计、内置智能体、可视化评估模块和运行时沙盒，显著提升了智能体应用的开发效率和执行安全性。

Conclusion: AgentScope 1.0 提供了一个实用的基础，用于构建可扩展、自适应且高效的多智能体应用，通过统一的接口、可扩展的模块和先进的异步设计，显著提升了智能体与环境的交互能力。

Abstract: Driven by rapid advancements of Large Language Models (LLMs), agents are
empowered to combine intrinsic knowledge with dynamic tool use, greatly
enhancing their capacity to address real-world tasks. In line with such an
evolution, AgentScope introduces major improvements in a new version (1.0),
towards comprehensively supporting flexible and efficient tool-based
agent-environment interactions for building agentic applications. Specifically,
we abstract foundational components essential for agentic applications and
provide unified interfaces and extensible modules, enabling developers to
easily leverage the latest progress, such as new models and MCPs. Furthermore,
we ground agent behaviors in the ReAct paradigm and offer advanced agent-level
infrastructure based on a systematic asynchronous design, which enriches both
human-agent and agent-agent interaction patterns while improving execution
efficiency. Building on this foundation, we integrate several built-in agents
tailored to specific practical scenarios. AgentScope also includes robust
engineering support for developer-friendly experiences. We provide a scalable
evaluation module with a visual studio interface, making the development of
long-trajectory agentic applications more manageable and easier to trace. In
addition, AgentScope offers a runtime sandbox to ensure safe agent execution
and facilitates rapid deployment in production environments. With these
enhancements, AgentScope provides a practical foundation for building scalable,
adaptive, and effective agentic applications.

</details>


### [113] [Do What? Teaching Vision-Language-Action Models to Reject the Impossible](https://arxiv.org/abs/2508.16292)
*Wen-Han Hsieh,Elvis Hsieh,Dantong Niu,Trevor Darrell,Roei Herzig,David M. Chan*

Main category: cs.AI

TL;DR: IVA框架通过结构化语言提示和半合成数据集训练，显著提升了VLA模型对错误前提指令的识别和响应能力。


<details>
  <summary>Details</summary>
Motivation: 研究VLA模型如何识别、解释和响应错误前提指令，即引用环境中不存在对象或条件的自然语言命令。

Method: 提出Instruct-Verify-and-Act (IVA)框架，通过结构化语言提示和大规模指令调优训练VLA模型，利用半合成数据集增强检测和自然语言纠正能力。

Result: IVA在错误前提检测准确率上比基线提高了97.56%，在错误前提场景下的成功响应率提高了50.78%。

Conclusion: IVA框架显著提高了对错误前提指令的检测准确性，并提升了在错误前提场景下的成功响应率。

Abstract: Recently, Vision-Language-Action (VLA) models have demonstrated strong
performance on a range of robotic tasks. These models rely on multimodal
inputs, with language instructions playing a crucial role -- not only in
predicting actions, but also in robustly interpreting user intent, even when
the requests are impossible to fulfill. In this work, we investigate how VLAs
can recognize, interpret, and respond to false-premise instructions: natural
language commands that reference objects or conditions absent from the
environment. We propose Instruct-Verify-and-Act (IVA), a unified framework that
(i) detects when an instruction cannot be executed due to a false premise, (ii)
engages in language-based clarification or correction, and (iii) grounds
plausible alternatives in perception and action. Towards this end, we construct
a large-scale instruction tuning setup with structured language prompts and
train a VLA model capable of handling both accurate and erroneous requests. Our
approach leverages a contextually augmented, semi-synthetic dataset containing
paired positive and false-premise instructions, enabling robust detection and
natural language correction. Our experiments show that IVA improves false
premise detection accuracy by 97.56% over baselines, while increasing
successful responses in false-premise scenarios by 50.78%.

</details>


### [114] [Causal Beam Selection for Reliable Initial Access in AI-driven Beam Management](https://arxiv.org/abs/2508.16352)
*Nasir Khan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil,Sinem Coleri*

Main category: cs.AI

TL;DR: 论文提出了一种因果感知的深度学习框架，通过两阶段因果波束选择算法，显著减少波束对准开销，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的波束对准方法忽视了输入与输出之间的因果关系，导致可解释性差、泛化能力弱及不必要的波束扫描开销。

Method: 提出了一种两阶段因果波束选择算法，结合因果发现和深度学习分类器，以识别最小相关输入集。

Result: 仿真结果表明，该方法在保持性能的同时，将输入选择时间减少了94.4%，波束扫描开销降低了59.4%。

Conclusion: 论文提出了一种因果感知的深度学习框架，显著减少了毫米波MIMO系统中的波束对准开销，同时保持了与传统方法相当的性能。

Abstract: Efficient and reliable beam alignment is a critical requirement for mmWave
multiple-input multiple-output (MIMO) systems, especially in 6G and beyond,
where communication must be fast, adaptive, and resilient to real-world
uncertainties. Existing deep learning (DL)-based beam alignment methods often
neglect the underlying causal relationships between inputs and outputs, leading
to limited interpretability, poor generalization, and unnecessary beam sweeping
overhead. In this work, we propose a causally-aware DL framework that
integrates causal discovery into beam management pipeline. Particularly, we
propose a novel two-stage causal beam selection algorithm to identify a minimal
set of relevant inputs for beam prediction. First, causal discovery learns a
Bayesian graph capturing dependencies between received power inputs and the
optimal beam. Then, this graph guides causal feature selection for the DL-based
classifier. Simulation results reveal that the proposed causal beam selection
matches the performance of conventional methods while drastically reducing
input selection time by 94.4% and beam sweeping overhead by 59.4% by focusing
only on causally relevant features.

</details>


### [115] [GLARE: Agentic Reasoning for Legal Judgment Prediction](https://arxiv.org/abs/2508.16383)
*Xinyu Yang,Chenlong Deng,Zhicheng Dou*

Main category: cs.AI

TL;DR: GLARE框架通过动态获取法律知识解决了现有LLM在法律判决预测中推理不足的问题，实验证明其有效且具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型因缺乏法律知识导致推理不足，影响了法律判决预测的效果。

Method: 引入GLARE，一个动态调用不同模块以获取关键法律知识的代理法律推理框架。

Result: 在真实世界数据集上的实验验证了GLARE框架的有效性。

Conclusion: GLARE框架通过动态获取关键法律知识，显著提升了法律判决预测的推理广度和深度，并通过生成的推理链增强了可解释性，为实际应用提供了可能。

Abstract: Legal judgment prediction (LJP) has become increasingly important in the
legal field. In this paper, we identify that existing large language models
(LLMs) have significant problems of insufficient reasoning due to a lack of
legal knowledge. Therefore, we introduce GLARE, an agentic legal reasoning
framework that dynamically acquires key legal knowledge by invoking different
modules, thereby improving the breadth and depth of reasoning. Experiments
conducted on the real-world dataset verify the effectiveness of our method.
Furthermore, the reasoning chain generated during the analysis process can
increase interpretability and provide the possibility for practical
applications.

</details>


### [116] [Modular Embedding Recomposition for Incremental Learning](https://arxiv.org/abs/2508.16463)
*Aniello Panariello,Emanuele Frascaroli,Pietro Buzzega,Lorenzo Bonicelli,Angelo Porrello,Simone Calderara*

Main category: cs.AI

TL;DR: MoDER通过模块化框架增强VLM的零样本能力，在持续学习中表现优异。


<details>
  <summary>Details</summary>
Motivation: 预训练VLM的零样本分类能力在持续学习中表现优异，但当下游任务与预训练领域差异较大时仍需微调。现有方法主要关注保持VLM的零样本能力，而本研究旨在将其提升为增强能力。

Method: 提出MoDular Embedding Recomposition（MoDER）方法，训练多个文本专家（每个专家专注于一个已知类别）并存储在基础中心，推理时通过组合检索到的专家合成改进的原型。

Result: 在Class-IL和MTIL两种零样本增量协议（共14个数据集）上验证了MoDER的有效性。

Conclusion: MoDER通过模块化框架显著增强了预训练视觉语言模型（VLM）的零样本分类能力，适用于持续学习（CL）任务。

Abstract: The advent of pre-trained Vision-Language Models (VLMs) has significantly
transformed Continual Learning (CL), mainly due to their zero-shot
classification abilities. Such proficiency makes VLMs well-suited for
real-world applications, enabling robust performance on novel unseen classes
without requiring adaptation. However, fine-tuning remains essential when
downstream tasks deviate significantly from the pre-training domain. Prior CL
approaches primarily focus on preserving the zero-shot capabilities of VLMs
during incremental fine-tuning on a downstream task. We take a step further by
devising an approach that transforms preservation into enhancement of the
zero-shot capabilities of VLMs. Our approach, named MoDular Embedding
Recomposition (MoDER), introduces a modular framework that trains multiple
textual experts, each specialized in a single seen class, and stores them in a
foundational hub. At inference time, for each unseen class, we query the hub
and compose the retrieved experts to synthesize a refined prototype that
improves classification. We show the effectiveness of our method across two
popular zero-shot incremental protocols, Class-IL and MTIL, comprising a total
of 14 datasets. The codebase is available at
https://github.com/aimagelab/mammoth.

</details>


### [117] [Constraints-Guided Diffusion Reasoner for Neuro-Symbolic Learning](https://arxiv.org/abs/2508.16524)
*Xuan Zhang,Zhijian Zhou,Weidi Xu,Yanting Miao,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: 扩散模型结合强化学习，实现神经网络的高效符号推理，实验验证了其在复杂逻辑任务中的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决神经网络在复杂逻辑约束和符号推理任务中的学习难题，弥合神经与符号方法之间的差距。

Method: 采用两阶段训练策略：第一阶段培养基本推理能力，第二阶段通过马尔可夫决策过程和改进的近端策略优化算法，强制神经网络输出符合硬约束。

Result: 在数独、迷宫、路径规划和偏好学习等经典符号推理基准测试中，该方法表现出色，准确性和逻辑一致性显著优于其他神经网络方法。

Conclusion: 该论文通过扩散模型和强化学习的结合，成功实现了神经网络在复杂逻辑约束下的符号推理，显著提高了准确性和逻辑一致性。

Abstract: Enabling neural networks to learn complex logical constraints and fulfill
symbolic reasoning is a critical challenge. Bridging this gap often requires
guiding the neural network's output distribution to move closer to the symbolic
constraints. While diffusion models have shown remarkable generative capability
across various domains, we employ the powerful architecture to perform
neuro-symbolic learning and solve logical puzzles. Our diffusion-based pipeline
adopts a two-stage training strategy: the first stage focuses on cultivating
basic reasoning abilities, while the second emphasizes systematic learning of
logical constraints. To impose hard constraints on neural outputs in the second
stage, we formulate the diffusion reasoner as a Markov decision process and
innovatively fine-tune it with an improved proximal policy optimization
algorithm. We utilize a rule-based reward signal derived from the logical
consistency of neural outputs and adopt a flexible strategy to optimize the
diffusion reasoner's policy. We evaluate our methodology on some classical
symbolic reasoning benchmarks, including Sudoku, Maze, pathfinding and
preference learning. Experimental results demonstrate that our approach
achieves outstanding accuracy and logical consistency among neural networks.

</details>


### [118] [LLM-Based Agents for Competitive Landscape Mapping in Drug Asset Due Diligence](https://arxiv.org/abs/2508.16571)
*Alisa Vinogradova,Vlad Vinogradov,Dmitrii Radkevich,Ilya Yasny,Dmitry Kobyzev,Ivan Izmailov,Katsiaryna Yanchanka,Andrey Doronichev*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的竞争药物发现系统，显著提高了检索效率和准确性，并在实际应用中大幅缩短了分析时间。


<details>
  <summary>Details</summary>
Motivation: 当前的基于LLM的AI系统无法可靠检索所有竞争药物名称，且缺乏公认的公共基准。

Method: 使用基于LLM的代理将五年多模态、非结构化的尽职调查备忘录转化为结构化评估语料库，并引入一个验证代理以过滤假阳性。

Result: 竞争发现代理的召回率达到83%，优于OpenAI Deep Research（65%）和Perplexity Labs（60%）。

Conclusion: 该系统在竞争药物发现任务中表现出色，显著提高了分析师的工作效率，将竞争分析时间从2.5天缩短至约3小时。

Abstract: In this paper, we describe and benchmark a competitor-discovery component
used within an agentic AI system for fast drug asset due diligence. A
competitor-discovery AI agent, given an indication, retrieves all drugs
comprising the competitive landscape of that indication and extracts canonical
attributes for these drugs. The competitor definition is investor-specific, and
data is paywalled/licensed, fragmented across registries, ontology-mismatched
by indication, alias-heavy for drug names, multimodal, and rapidly changing.
Although considered the best tool for this problem, the current LLM-based AI
systems aren't capable of reliably retrieving all competing drug names, and
there is no accepted public benchmark for this task. To address the lack of
evaluation, we use LLM-based agents to transform five years of multi-modal,
unstructured diligence memos from a private biotech VC fund into a structured
evaluation corpus mapping indications to competitor drugs with normalized
attributes. We also introduce a competitor validating LLM-as-a-judge agent that
filters out false positives from the list of predicted competitors to maximize
precision and suppress hallucinations. On this benchmark, our
competitor-discovery agent achieves 83% recall, exceeding OpenAI Deep Research
(65%) and Perplexity Labs (60%). The system is deployed in production with
enterprise users; in a case study with a biotech VC investment fund, analyst
turnaround time dropped from 2.5 days to $\sim$3 hours ($\sim$20x) for the
competitive analysis.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [119] [Wavelet-Space Super-Resolution for Real-Time Rendering](https://arxiv.org/abs/2508.16024)
*Prateek Poudel,Prashant Aryal,Kirtan Kunwar,Navin Nepal,Dinesh Bania Kshatri*

Main category: cs.GR

TL;DR: 该论文提出了一种基于小波域的神经超分辨率方法，通过SWT提升感知质量，实验证明其有效性和实时性。


<details>
  <summary>Details</summary>
Motivation: 研究小波空间特征分解在神经超分辨率渲染中的应用，旨在更好地保留精细纹理同时保持结构一致性。

Method: 基于DFASR框架，引入小波域表示，利用平稳小波变换（SWT）避免空间下采样，确保子带对齐并保持平移不变性。模型预测基于空间G缓冲和时间扭曲历史帧的小波系数，然后通过逆小波合成重新组合。

Result: 通过全面的消融研究，发现SWT的引入使PSNR提升高达1.5 dB，LPIPS平均降低17%，计算开销比基线DFASR增加约24 ms。

Conclusion: 小波域表示是一种原则性且有效的方法，可以提升图形应用中神经上采样的感知质量。

Abstract: We investigate the use of wavelet-space feature decomposition in neural
super-resolution for rendering pipelines. Building on the DFASR framework, we
introduce a wavelet-domain representation that separates low- and
high-frequency details before reconstruction, enabling the network to better
preserve fine textures while maintaining structural consistency. Unlike
RGB-space regression, our approach leverages the stationary wavelet transform
(SWT) to avoid spatial down-sampling, ensuring alignment across subbands and
preserving shift invariance. The model predicts wavelet coefficients
conditioned on spatial G-buffers and temporally warped history frames, which
are then recombined through inverse wavelet synthesis. We conduct a
comprehensive ablation study across wavelet families, transform types, and
architectural variants, showing that incorporating SWT improves PSNR by up to
1.5 dB and reduces LPIPS by 17% on average, at a computational overhead of
roughly +24 ms compared to out DFASR baseline. While absolute runtimes on our
RTX 3050 mobile GPU are higher ( 141ms) than the original DFASR report on RTX
4090( 11ms), the relative overhead remains modest, suggesting that on
higher-end GPUs our method would also remain real-time capable. Taken together,
our results suggest that wavelet-domain representations are a principled and
effective way to enhance perceptual quality in neural upscaling for graphics
applications.

</details>


### [120] [Audio2Face-3D: Audio-driven Realistic Facial Animation For Digital Avatars](https://arxiv.org/abs/2508.16401)
*NVIDIA,:,Chaeyeon Chung,Ilya Fedorov,Michael Huang,Aleksey Karmanov,Dmitry Korobchenko,Roger Ribera,Yeongho Seol*

Main category: cs.GR

TL;DR: NVIDIA Audio2Face-3D 是一个音频驱动的面部动画系统，开源了工具和数据集，支持游戏角色实时动画生成。


<details>
  <summary>Details</summary>
Motivation: 音频驱动的面部动画为数字角色动画提供了一种有效解决方案，旨在促进游戏角色面部动画的创作。

Method: 论文详细介绍了 NVIDIA Audio2Face-3D 的技术方面，包括数据采集、网络架构、重定向方法、评估指标和使用案例。

Result: Audio2Face-3D 系统实现了人类用户与交互式角色之间的实时交互，并开源了相关资源以支持开发者。

Conclusion: NVIDIA Audio2Face-3D 系统通过开源其网络、SDK、训练框架和示例数据集，为数字角色创作者和游戏开发者提供了生成逼真面部动画的工具，促进了实时交互。

Abstract: Audio-driven facial animation presents an effective solution for animating
digital avatars. In this paper, we detail the technical aspects of NVIDIA
Audio2Face-3D, including data acquisition, network architecture, retargeting
methodology, evaluation metrics, and use cases. Audio2Face-3D system enables
real-time interaction between human users and interactive avatars, facilitating
facial animation authoring for game characters. To assist digital avatar
creators and game developers in generating realistic facial animations, we have
open-sourced Audio2Face-3D networks, SDK, training framework, and example
dataset.

</details>


### [121] [Real-time 3D Light-field Viewing with Eye-tracking on Conventional Displays](https://arxiv.org/abs/2508.16535)
*Trung Hieu Pham,Chanh Minh Tran,Eiji Kamioka,Xuan Tan Phan*

Main category: cs.GR

TL;DR: 提出了一种低成本系统，利用标准2D显示器、RGB摄像头和红青立体眼镜实现实时3D光场观看，适用于教育和数字媒体等领域。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D可视化技术因昂贵和专用硬件而难以普及的问题。

Method: 集成实时眼动追踪和轻量级渲染管线，从预捕获的光场数据中选择和合成立体视图。

Result: 系统在普通消费级硬件上稳定运行30 FPS，证实了其可行性。

Conclusion: 该系统通过低成本硬件实现了实时3D光场观看，为交互式3D应用提供了一个可访问的平台。

Abstract: Creating immersive 3D visual experiences typically requires expensive and
specialized hardware such as VR headsets, autostereoscopic displays, or active
shutter glasses. These constraints limit the accessibility and everyday use of
3D visualization technologies in resource-constrained settings. To address
this, we propose a low-cost system that enables real-time 3D light-field
viewing using only a standard 2D monitor, a conventional RGB webcam, and
red-cyan anaglyph glasses. The system integrates real-time eye-tracking to
dynamically adapt the displayed light-field image to the user's head position
with a lightweight rendering pipeline that selects and composites stereoscopic
views from pre-captured light-field data. The resulting anaglyph image is
updated in real-time, creating a more immersive and responsive 3D experience.
The system operates entirely on CPU and maintains a stable frame rate of 30
FPS, confirming its feasibility on typical consumer-grade hardware. All of
these highlight the potential of our approach as an accessible platform for
interactive 3D applications in education, digital media, and beyond.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [122] [Constructing Long Paths in Graph Streams](https://arxiv.org/abs/2508.16022)
*Christian Konrad,Chhaya Trehan*

Main category: cs.DS

TL;DR: 论文研究了单次流式模型中的最长路径问题，为无向图和有向图提供了算法和空间下限的结果，揭示了不同模型下路径构造的可行性及其限制。


<details>
  <summary>Details</summary>
Motivation: 在流式图计算模型中，许多算法需要多次遍历来扩展路径，这引发了是否可以通过单次遍历构造非平凡长度路径的问题。

Method: 论文研究了单次流式模型中的最长路径问题，针对无向图和有向图分别提出了算法和空间下限的证明。

Result: 对于无向图，论文展示了在插入和插入-删除模型中，存在半流式算法可以高概率计算长度至少为平均度数三分之一的路径。对于有向图，即使在插入模型中，计算(n^{1 - o(1)})-近似最长路径也需要Ω(n^2)空间。

Conclusion: 该论文通过研究单次流式模型中的最长路径问题，为无向图和有向图提供了算法和空间下限的结果，揭示了在不同模型下构造非平凡长度路径的可行性及其限制。

Abstract: In the graph stream model of computation, an algorithm processes the edges of
an input graph in one or more sequential passes while using a memory sublinear
in the input size. This model poses significant challenges for constructing
long paths. Many known algorithms tasked with extending an existing path as a
subroutine require an entire pass to add a single additional edge. This raises
a fundamental question: Are multiple passes inherently necessary to construct
paths of non-trivial lengths, or can a single pass suffice? To address this
question, we study the Longest Path problem in the one-pass streaming model. In
this problem, given a desired approximation factor $\alpha$, the objective is
to compute a path of length at least $\lp(G) / \alpha$, where $\lp(G)$ is the
length of a longest path in the input graph. We give algorithms as well as
space lower bounds for both undirected and directed graphs. Our results
include: We show that for undirected graphs, in both the insertion-only and the
insertion-deletion models, there are semi-streaming algorithms, that compute a
path of length at least $d /3$ with high probability, where $d$ is the average
degree of the graph. These algorithms can also yield an $\alpha$-approximation
to Longest Path using space $\tilde{O}(n^2 / \alpha)$. Next, we show that such
a result cannot be achieved for directed graphs, even in the insertion-only
model. We show that computing a $(n^{1 - o(1)})$-approximation to Longest Path
in directed graphs in the insertion-only model requires space $\Omega(n^2)$. We
further show two additional lower bounds. First, we show that semi-streaming
space is insufficient for small constant factor approximations to Longest Path
for undirected graphs in the insertion-only model. Last, in undirected graphs
in the insertion-deletion model, we show that computing an
$\alpha$-approximation requires space $\Omega(n^2 / \alpha^3)$.

</details>


### [123] [PIPQ: Strict Insert-Optimized Concurrent Priority Queue](https://arxiv.org/abs/2508.16023)
*Olivia Grimes,Ahmed Hassan,Panagiota Fatourou,Roberto Palmieri*

Main category: cs.DS

TL;DR: PIPQ是一种新型并发优先级队列，通过优化插入操作的并行性，在插入密集型工作负载中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统并发优先级队列设计主要关注加速删除最小操作，而PIPQ的创新点在于专注于插入操作的并行性，以满足不同工作负载需求。

Method: PIPQ的设计包括两个层次：工作层和领导层。工作层提供每线程数据结构以实现快速并行插入，领导层包含优先级队列中的最高优先级元素以支持删除最小操作。

Result: 评估表明，PIPQ在不同数据访问模式、操作混合、运行时设置以及图基应用中的集成表现优于竞争对手，特别是在插入密集型工作负载中。

Conclusion: PIPQ作为一种严格且可线性化的并发优先级队列，通过专注于插入操作的并行性而非传统的删除最小操作加速，在多种情况下，尤其是插入密集型工作负载中，表现优于竞争对手。

Abstract: This paper presents PIPQ, a strict and linearizable concurrent priority queue
whose design differs from existing solutions in literature because it focuses
on enabling parallelism of insert operations as opposed to accelerating
delete-min operations, as traditionally done. In a nutshell, PIPQ's structure
includes two levels: the worker level and the leader level. The worker level
provides per-thread data structures enabling fast and parallel insertions. The
leader level contains the highest priority elements in the priority queue and
can thus serve delete-min operations. Our evaluation, which includes an
exploration of different data access patterns, operation mixes, runtime
settings, and an integration into a graph-based application, shows that PIPQ
outperforms competitors in a variety of cases, especially with insert-dominant
workloads.

</details>


### [124] [On the number of MUSs crossing a position](https://arxiv.org/abs/2508.16092)
*Hiroto Fujimaru,Takuya Mieno,Shunsuke Inenaga*

Main category: cs.DS

TL;DR: 本文证明了字符串中特定位置的最小唯一子串数量上下界均为Θ(√n)。


<details>
  <summary>Details</summary>
Motivation: 研究MUS在字符串中的分布特性，特别是围绕特定位置的MUS数量，有助于更深入理解字符串的唯一子串结构。

Method: 通过理论分析和构造性证明，作者展示了包含位置i的MUS数量的上限和下限均为Θ(√n)。

Result: 对于长度为n的字符串T，包含位置i的MUS数量的上下界均为Θ(√n)。

Conclusion: 本文证明了在长度为n的字符串T中，包含特定位置i的最小唯一子串（MUS）数量的上下界均为Θ(√n)。

Abstract: A string $w$ is said to be a minimal unique substring (MUS) of a string $T$
if $w$ occurs exactly once in $T$, and any proper substring of $w$ occurs at
least twice in $T$. It is known that the number of MUSs in a string $T$ of
length $n$ is at most $n$, and that the set $MUS(T)$ of all MUSs in $T$ can be
computed in $O(n)$ time [Ilie and Smyth, 2011]. Let $MUS(T,i)$ denote the set
of MUSs that contain a position $i$ in a string $T$. In this short paper, we
present matching $\Theta(\sqrt{n})$ upper and lower bounds for the number
$|MUS(T,i)|$ of MUSs containing a position $i$ in a string $T$ of length $n$.

</details>


### [125] [Symmetry-breaking symmetry in directed spectral partitioning](https://arxiv.org/abs/2508.16173)
*Dimosthenis Pasadakis,Raphael S. Steiner,Pál András Papp,Toni Böhnlein,Albert-Jan N. Yzelman*

Main category: cs.DS

TL;DR: 通过非对称谱二分法优化有向图分割，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统谱二分法在处理有向图时存在对称性问题，影响局部性和排序效率。

Method: 采用非对称谱二分法激励有向边的对齐，生成无环二分和拓扑顺序。

Result: 新方法在总重用距离和最小线性排列上比Gorder算法提升高达17倍。

Conclusion: 新方法通过打破传统谱二分法的对称性，显著提升了有向无环图的局部性和排序效率。

Abstract: We break the symmetry in classical spectral bi-partitioning in order to
incentivise the alignment of directed cut edges. We use this to generate
acyclic bi-partitions and furthermore topological orders of directed acyclic
graphs with superb locality. The new approach outperforms the state-of-the-art
Gorder algorithm by up to $17\times$ on total reuse distance and minimum linear
arrangement.

</details>


### [126] [Linear Layouts Revisited: Stacks, Queues, and Exact Algorithms](https://arxiv.org/abs/2508.16319)
*Thomas Depian,Simon D. Fink,Robert Ganian,Vaishali Surianarayanan*

Main category: cs.DS

TL;DR: 本文提出三种新算法，显著扩展了对堆栈和队列布局复杂性的理解，包括固定参数算法和改进的1页队列布局计算。


<details>
  <summary>Details</summary>
Motivation: 尽管堆栈和队列布局已被广泛研究，但许多基本问题仍未解决，尤其是在计算复杂性方面。本文旨在填补这些空白。

Method: 1. 使用固定参数算法计算最小页数的堆栈和队列布局，基于顶点完整性。2. 提出n^(O(q * l))算法，避免双重指数依赖。3. 开发2^(O(n))算法改进1页队列布局计算。

Result: 1. 基于顶点完整性的固定参数算法。2. 避免双重指数依赖的n^(O(q * l))算法。3. 改进的2^(O(n))算法用于1页队列布局。

Conclusion: 本文通过三种新算法显著扩展了对堆栈和队列布局复杂性的理解，包括固定参数算法、避免双重指数依赖的算法以及改进的1页队列布局算法。

Abstract: In spite of the extensive study of stack and queue layouts, many fundamental
questions remain open concerning the complexity-theoretic frontiers for
computing stack and queue layouts. A stack (resp. queue) layout places vertices
along a line and assigns edges to pages so that no two edges on the same page
are crossing (resp. nested). We provide three new algorithms which together
substantially expand our understanding of these problems:
  (1) A fixed-parameter algorithm for computing minimum-page stack and queue
layouts w.r.t. the vertex integrity of an n-vertex graph G. This result is
motivated by an open question in the literature and generalizes the previous
algorithms parameterizing by the vertex cover number of G. The proof relies on
a newly developed Ramsey pruning technique. Vertex integrity intuitively
measures the vertex deletion distance to a subgraph with only small connected
components.
  (2) An n^(O(q * l)) algorithm for computing l-page stack and queue layouts of
page width at most q. This is the first algorithm avoiding a double-exponential
dependency on the parameters. The page width of a layout measures the maximum
number of edges one needs to cross on any page to reach the outer face.
  (3) A 2^(O(n)) algorithm for computing 1-page queue layouts. This improves
upon the previously fastest n^(O(n)) algorithm and can be seen as a counterpart
to the recent subexponential algorithm for computing 2-page stack layouts
[ICALP'24], but relies on an entirely different technique.

</details>


### [127] [Going Beyond Twin-width? CSPs with Unbounded Domain and Few Variables](https://arxiv.org/abs/2508.16389)
*Peter Jonsson,Victor Lagerkvist,Jorke M. de Vlas,Magnus Wahlström*

Main category: cs.DS

TL;DR: 该研究通过代数理论分析了udCSP框架的复杂性，发现无限制映射为W[1]-难问题，one-hot映射与布尔加权CSP的FPT二分法一致，单调映射的复杂性取决于有序多态性，尤其是"connector"多态性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于近期关于MinCSP的FPT算法工作，这些算法通常与k变量udCSP相关。通过开发udCSP框架的代数理论，旨在更系统地理解其参数化复杂性，并为未来研究提供理论工具。

Method: 研究采用代数理论，特别是基于部分多函数的Galois连接，来分析udCSP(Γ,M)的复杂性。针对三种映射类型（无限制、one-hot、单调）分别进行了研究，并通过有序多态性和twin-width等概念来探讨复杂性。

Result: 研究发现，无限制映射在所有非平凡情况下均为W[1]-难问题；one-hot映射的复杂性与Marx的布尔加权CSP的FPT二分法一致；单调映射的复杂性取决于有序多态性，尤其是"connector"多态性的存在与否，可能导致FPT或W[1]-难问题。

Conclusion: 该研究通过Galois连接和部分多函数理论，为udCSP框架开发了代数理论，并针对不同类型的映射（无限制、one-hot、单调）进行了复杂性分析。研究发现，单调映射的复杂性取决于有序多态性，尤其是"connector"多态性的存在与否，可能是FPT边界的决定性因素。

Abstract: We study a model of constraint satisfaction problems geared towards instances
with few variables but with domain of unbounded size (udCSP). Our model is
inspired by recent work on FPT algorithms for MinCSP where frequently both
upper and lower bounds on the parameterized complexity of a problem correspond
to $k$-variable udCSPs; e.g., the FPT algorithms for Boolean MinCSP (Kim et
al., SODA 2023) and Directed Multicut with three cut requests (Hatzel et al.,
SODA 2023) both reduce to k-variable udCSPs, and the canonical W[1]-hardness
construction in the area, Paired Min Cut by Marx and Razgon (IPL 2009), is
effectively a k-variable udCSP.
  The udCSP framework represents constraints with unbounded domains via a
collection $\mathcal{M}$ of unary maps into a finite-domain base language
$\Gamma$. We develop an algebraic theory for studying the complexity of
udCSP$(\Gamma,\mathcal{M})$ with a Galois connection based on partial
multifunctions.
  We study three types of maps: unrestricted, one-hot, and monotone. For
unrestricted maps, the problem is W[1]-hard for all but trivial cases, and for
one-hot maps, the characterization coincides with Marx' FPT dichotomy for
Boolean Weighted CSPs (Computational Complexity 2005). For the case of monotone
maps Mo, we show that the complexity depends on restricted identifies we call
ordered polymorphisms; we identify the "connector" polymorphism as the likely
FPT boundary. We show that its absence implies that udCSP($\Gamma$,Mo) defines
all permutations, and the problem is W[1]-hard; while its presence for a binary
language implies bounded twin-width, and the problem is FPT (Twin-Width IV;
Bonnet et al., JACM 2024). For non-binary languages, where twin-width does not
apply, the polymorphism coincides with a notion of bounded projected grid-rank;
however, we leave the FPT question for this case open.

</details>


### [128] [Quality control in sublinear time: a case study via random graphs](https://arxiv.org/abs/2508.16531)
*Cassandra Marcussen,Ronitt Rubinfeld,Madhu Sudan*

Main category: cs.DS

TL;DR: 本文提出“质量控制问题”并展示其在随机图场景下的高效解决方案，通过子线性算法显著提升测试效率。


<details>
  <summary>Details</summary>
Motivation: 传统算法设计通常关注输入的平均性能，但实际应用中需要确保算法在任意输入下的可靠性。因此，本文旨在解决如何高效区分高质量和低质量输入的问题。

Method: 本文采用子线性算法方法，通过有限的查询和时间来解决质量控制问题，特别针对随机图和特定质量函数（如k-团计数）进行了分析。

Result: 研究表明，在随机图（G_{n,p}）和k-团计数函数的背景下，质量控制问题可以在p^{-O(k)}的查询和时间复杂度内解决，显著优于传统测试方法。

Conclusion: 本文提出了一个名为“质量控制问题”的新算法问题类别，旨在高效区分高质量和低质量输入。通过以随机图为例，展示了在特定条件下，质量控制问题可以比传统测试方法更高效地解决。

Abstract: Many algorithms are designed to work well on average over inputs. When
running such an algorithm on an arbitrary input, we must ask: Can we trust the
algorithm on this input? We identify a new class of algorithmic problems
addressing this, which we call "Quality Control Problems." These problems are
specified by a (positive, real-valued) "quality function" $\rho$ and a
distribution $D$ such that, with high probability, a sample drawn from $D$ is
"high quality," meaning its $\rho$-value is near $1$. The goal is to accept
inputs $x \sim D$ and reject potentially adversarially generated inputs $x$
with $\rho(x)$ far from $1$. The objective of quality control is thus weaker
than either component problem: testing for "$\rho(x) \approx 1$" or testing if
$x \sim D$, and offers the possibility of more efficient algorithms.
  In this work, we consider the sublinear version of the quality control
problem, where $D \in \Delta(\{0,1\}^N)$ and the goal is to solve the $(D
,\rho)$-quality problem with $o(N)$ queries and time. As a case study, we
consider random graphs, i.e., $D = G_{n,p}$ (and $N = \binom{n}2$), and the
$k$-clique count function $\rho_k := C_k(G)/\mathbb{E}_{G' \sim
G_{n,p}}[C_k(G')]$, where $C_k(G)$ is the number of $k$-cliques in $G$. Testing
if $G \sim G_{n,p}$ with one sample, let alone with sublinear query access to
the sample, is of course impossible. Testing if $\rho_k(G)\approx 1$ requires
$p^{-\Omega(k^2)}$ samples. In contrast, we show that the quality control
problem for $G_{n,p}$ (with $n \geq p^{-ck}$ for some constant $c$) with
respect to $\rho_k$ can be tested with $p^{-O(k)}$ queries and time, showing
quality control is provably superpolynomially more efficient in this setting.
More generally, for a motif $H$ of maximum degree $\Delta(H)$, the respective
quality control problem can be solved with $p^{-O(\Delta(H))}$ queries and
running time.

</details>
