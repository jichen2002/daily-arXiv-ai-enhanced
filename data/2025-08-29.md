<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 99]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 23]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.NI](#cs.NI) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Mitigating Hallucinations in Multimodal LLMs via Object-aware Preference Optimization](https://arxiv.org/abs/2508.20181)
*Alberto Compagnoni,Davide Caffagni,Nicholas Moratelli,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara*

Main category: cs.CV

TL;DR: 提出CHAIR-DPO方法，通过CHAIR指标和DPO微调减少MLLMs的幻觉生成。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在生成答案时产生的幻觉问题，即生成与视觉输入不符的内容。

Method: 利用CHAIR指标区分幻觉和非幻觉样本，并通过Direct Preference Optimization (DPO)微调现有MLLMs。

Result: CHAIR-DPO在多个幻觉基准测试中显著减少了幻觉答案的生成。

Conclusion: 通过CHAIR-DPO方法，成功减少了MLLMs的幻觉生成，证明了基于CHAIR奖励的微调有效性。

Abstract: Multimodal Large Language Models (MLLMs) emerge as a unified interface to
address a multitude of tasks, ranging from NLP to computer vision. Despite
showcasing state-of-the-art results in many benchmarks, a long-standing issue
is the tendency of MLLMs to hallucinate, that is to generate answers to the
user's query that are not reflected in the visual input. In this paper, we
address the problem of hallucinations as an alignment problem, seeking to steer
the MLLM so that it prefers generating content without hallucinations. In
contrast to recent approaches that require complicated pipelines to build
synthetic preference data for alignment training, often relying on proprietary
models, we capitalize on the well-known CHAIR metric, originally proposed to
gauge the degree of hallucinations in image captioning. Given a pair of
generated answers, we leverage CHAIR to distinguish winner and loser options
(i.e., non-hallucinated and hallucinated samples) and fine-tune off-the-shelf
MLLMs via Direct Preference Optimization (DPO). The resulting method, which we
refer to as CHAIR-DPO, effectively diminishes the amount of hallucinated
answers on several hallucination benchmarks, demonstrating the effectiveness of
fine-tuning the MLLM with a CHAIR-based reward. Source code and trained models
are publicly available at https://github.com/aimagelab/CHAIR-DPO.

</details>


### [2] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By Value Sign Flip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: VSF通过翻转负面提示的注意力值符号，高效提升了几步扩散模型的负面提示遵循效果，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如CFG、NASA、NAG）在几步模型中处理负面提示时效果有限，因此需要一种更高效的方法来动态抑制不需要的内容。

Method: VSF（Value Sign Flip）通过翻转负面提示的注意力值符号来抑制不需要的内容，计算开销小，适用于MMDiT架构和基于交叉注意力的模型。

Result: 实验表明，VSF在复杂提示对的数据集上表现优于现有方法，在静态图像和视频生成任务中均显示出卓越性能。

Conclusion: VSF方法通过动态翻转负面提示的注意力值符号，显著提升了几步扩散和流匹配图像生成模型中负面提示的遵循效果，同时保持了图像质量。

Abstract: We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [3] [SDiFL: Stable Diffusion-Driven Framework for Image Forgery Localization](https://arxiv.org/abs/2508.20182)
*Yang Su,Shunquan Tan,Jiwu Huang*

Main category: cs.CV

TL;DR: 研究首次将Stable Diffusion的多模态能力整合到图像伪造定位中，通过理论证明和SD3的潜在空间融合，显著提升性能并在未训练数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造定位方法依赖人工标注数据，难以应对多模态大模型驱动的图像操作技术快速发展。为此，研究探索如何利用SD的生成和感知能力提升伪造定位效率。

Method: 研究利用Stable DiffusionV3（SD3）的多模态处理能力，将伪造残差（通过特定高通滤波器提取的高频信号）作为显式模态融入潜在空间训练，同时保留SD3提取的丰富语义信息。

Result: 实验显示，该方法在广泛使用的基准数据集上性能提升高达12%，且在未训练的真实世界伪造图像上表现优异。

Conclusion: 该研究首次将Stable Diffusion的多模态架构与图像伪造定位相结合，通过理论证明和实践验证，显著提升了伪造定位的效率和准确性。实验结果表明，该方法在多个基准数据集上优于现有最先进模型，且在处理未见过的真实世界伪造图像时表现出色。

Abstract: Driven by the new generation of multi-modal large models, such as Stable
Diffusion (SD), image manipulation technologies have advanced rapidly, posing
significant challenges to image forensics. However, existing image forgery
localization methods, which heavily rely on labor-intensive and costly
annotated data, are struggling to keep pace with these emerging image
manipulation technologies. To address these challenges, we are the first to
integrate both image generation and powerful perceptual capabilities of SD into
an image forensic framework, enabling more efficient and accurate forgery
localization. First, we theoretically show that the multi-modal architecture of
SD can be conditioned on forgery-related information, enabling the model to
inherently output forgery localization results. Then, building on this
foundation, we specifically leverage the multimodal framework of Stable
DiffusionV3 (SD3) to enhance forgery localization performance.We leverage the
multi-modal processing capabilities of SD3 in the latent space by treating
image forgery residuals -- high-frequency signals extracted using specific
highpass filters -- as an explicit modality. This modality is fused into the
latent space during training to enhance forgery localization performance.
Notably, our method fully preserves the latent features extracted by SD3,
thereby retaining the rich semantic information of the input image.
Experimental results show that our framework achieves up to 12% improvements in
performance on widely used benchmarking datasets compared to current
state-of-the-art image forgery localization models. Encouragingly, the model
demonstrates strong performance on forensic tasks involving real-world document
forgery images and natural scene forging images, even when such data were
entirely unseen during training.

</details>


### [4] [Grounding Multimodal Large Language Models with Quantitative Skin Attributes: A Retrieval Study](https://arxiv.org/abs/2508.20188)
*Max Torop,Masih Eskandar,Nicholas Kurtansky,Jinyang Liu,Jochen Weber,Octavia Camps,Veronica Rotemberg,Jennifer Dy,Kivanc Kose*

Main category: cs.CV

TL;DR: 结合MLLMs和定量属性提升皮肤疾病诊断模型的可解释性，通过微调和案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI模型在皮肤疾病诊断中表现出色，但其预测的可解释性仍需提升，以实际应用于临床。

Method: 通过微调MLLMs从图像中预测定量属性值，并在SLICE-3D数据集上进行属性特定的基于内容的图像检索案例研究。

Result: 研究表明，MLLMs的嵌入空间可以通过微调与定量属性关联，从而增强模型预测的可解释性。

Conclusion: 结合多模态大语言模型（MLLMs）和定量属性使用可以提升皮肤疾病诊断模型的可解释性，为临床实践提供更可靠的辅助工具。

Abstract: Artificial Intelligence models have demonstrated significant success in
diagnosing skin diseases, including cancer, showing the potential to assist
clinicians in their analysis. However, the interpretability of model
predictions must be significantly improved before they can be used in practice.
To this end, we explore the combination of two promising approaches: Multimodal
Large Language Models (MLLMs) and quantitative attribute usage. MLLMs offer a
potential avenue for increased interpretability, providing reasoning for
diagnosis in natural language through an interactive format. Separately, a
number of quantitative attributes that are related to lesion appearance (e.g.,
lesion area) have recently been found predictive of malignancy with high
accuracy. Predictions grounded as a function of such concepts have the
potential for improved interpretability. We provide evidence that MLLM
embedding spaces can be grounded in such attributes, through fine-tuning to
predict their values from images. Concretely, we evaluate this grounding in the
embedding space through an attribute-specific content-based image retrieval
case study using the SLICE-3D dataset.

</details>


### [5] [Enhancing Automatic Modulation Recognition With a Reconstruction-Driven Vision Transformer Under Limited Labels](https://arxiv.org/abs/2508.20193)
*Hossein Ahmadi,Banafsheh Saffari*

Main category: cs.CV

TL;DR: 提出统一ViT框架，结合多种学习目标，实现高效自动调制识别，减少对标记数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有AMR解决方案依赖大量标记数据或多阶段训练流程，限制了实际应用中的扩展性和泛化能力。

Method: 提出了一种统一的Vision Transformer（ViT）框架，结合了监督、自监督和重建目标，包括ViT编码器、轻量级卷积解码器和线性分类器。

Result: 在RML2018.01A数据集上，该方法在低标签情况下优于监督CNN和ViT基线，仅需15-20%标记数据即可接近ResNet的准确率，且在不同信噪比下表现稳定。

Conclusion: 该框架为AMR提供了一个简单、通用且标签高效的解决方案，在低标签情况下性能优越，并在不同信噪比下保持稳定表现。

Abstract: Automatic modulation recognition (AMR) is critical for cognitive radio,
spectrum monitoring, and secure wireless communication. However, existing
solutions often rely on large labeled datasets or multi-stage training
pipelines, which limit scalability and generalization in practice. We propose a
unified Vision Transformer (ViT) framework that integrates supervised,
self-supervised, and reconstruction objectives. The model combines a ViT
encoder, a lightweight convolutional decoder, and a linear classifier; the
reconstruction branch maps augmented signals back to their originals, anchoring
the encoder to fine-grained I/Q structure. This strategy promotes robust,
discriminative feature learning during pretraining, while partial label
supervision in fine-tuning enables effective classification with limited
labels. On the RML2018.01A dataset, our approach outperforms supervised CNN and
ViT baselines in low-label regimes, approaches ResNet-level accuracy with only
15-20% labeled data, and maintains strong performance across varying SNR
levels. Overall, the framework provides a simple, generalizable, and
label-efficient solution for AMR.

</details>


### [6] [InfinityHuman: Towards Long-Term Audio-Driven Human](https://arxiv.org/abs/2508.20210)
*Xiaodi Li,Pan Xie,Yi Ren,Qijun Gan,Chen Zhang,Fangyuan Kong,Xiang Yin,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityHuman通过姿势引导的细化器和手部奖励机制，解决了现有音频驱动人体动画方法中的身份漂移和手部动作失真问题，实现了高质量的长期视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成高分辨率、长时长视频时存在身份漂移、颜色偏移和场景不稳定问题，且手部动作建模不佳。

Method: 提出InfinityHuman，一个粗到细的框架，首先生成音频同步表示，然后通过姿势引导的细化器逐步将其细化为高分辨率、长时长的视频。

Result: 在EMTD和HDTF数据集上的实验表明，InfinityHuman在视频质量、身份保持、手部准确性和唇同步方面表现最佳。

Conclusion: InfinityHuman通过其粗到细的框架和手部特定奖励机制，在视频质量、身份保持、手部动作准确性和唇同步方面达到了最先进的性能，并通过消融研究验证了各模块的有效性。

Abstract: Audio-driven human animation has attracted wide attention thanks to its
practical applications. However, critical challenges remain in generating
high-resolution, long-duration videos with consistent appearance and natural
hand motions. Existing methods extend videos using overlapping motion frames
but suffer from error accumulation, leading to identity drift, color shifts,
and scene instability. Additionally, hand movements are poorly modeled,
resulting in noticeable distortions and misalignment with the audio. In this
work, we propose InfinityHuman, a coarse-to-fine framework that first generates
audio-synchronized representations, then progressively refines them into
high-resolution, long-duration videos using a pose-guided refiner. Since pose
sequences are decoupled from appearance and resist temporal degradation, our
pose-guided refiner employs stable poses and the initial frame as a visual
anchor to reduce drift and improve lip synchronization. Moreover, to enhance
semantic accuracy and gesture realism, we introduce a hand-specific reward
mechanism trained with high-quality hand motion data. Experiments on the EMTD
and HDTF datasets show that InfinityHuman achieves state-of-the-art performance
in video quality, identity preservation, hand accuracy, and lip-sync. Ablation
studies further confirm the effectiveness of each module. Code will be made
public.

</details>


### [7] [Spherical Vision Transformers for Audio-Visual Saliency Prediction in 360-Degree Videos](https://arxiv.org/abs/2508.20221)
*Mert Cokelek,Halit Ozsoy,Nevrez Imamoglu,Cagri Ozcinar,Inci Ayhan,Erkut Erdem,Aykut Erdem*

Main category: cs.CV

TL;DR: 研究提出了两种新模型（SalViT360和SalViT360-AV）用于360度视频的显著性预测，整合了空间音频线索，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏全面的360度视听显著性预测数据集，研究团队创建了YT360-EyeTracking数据集，探索如何利用视听线索有效预测360度视频中的视觉显著性。

Method: 提出了两种新颖的显著性预测模型：SalViT360（基于视觉Transformer的框架，配备球形几何感知的时空注意力层）和SalViT360-AV（进一步整合了基于音频输入的Transformer适配器）。

Result: SalViT360和SalViT360-AV在多个基准数据集（包括YT360-EyeTracking）上显著优于现有方法。

Conclusion: 整合空间音频线索在模型架构中对于全向视频的准确显著性预测至关重要。

Abstract: Omnidirectional videos (ODVs) are redefining viewer experiences in virtual
reality (VR) by offering an unprecedented full field-of-view (FOV). This study
extends the domain of saliency prediction to 360-degree environments,
addressing the complexities of spherical distortion and the integration of
spatial audio. Contextually, ODVs have transformed user experience by adding a
spatial audio dimension that aligns sound direction with the viewer's
perspective in spherical scenes. Motivated by the lack of comprehensive
datasets for 360-degree audio-visual saliency prediction, our study curates
YT360-EyeTracking, a new dataset of 81 ODVs, each observed under varying
audio-visual conditions. Our goal is to explore how to utilize audio-visual
cues to effectively predict visual saliency in 360-degree videos. Towards this
aim, we propose two novel saliency prediction models: SalViT360, a
vision-transformer-based framework for ODVs equipped with spherical
geometry-aware spatio-temporal attention layers, and SalViT360-AV, which
further incorporates transformer adapters conditioned on audio input. Our
results on a number of benchmark datasets, including our YT360-EyeTracking,
demonstrate that SalViT360 and SalViT360-AV significantly outperform existing
methods in predicting viewer attention in 360-degree scenes. Interpreting these
results, we suggest that integrating spatial audio cues in the model
architecture is crucial for accurate saliency prediction in omnidirectional
videos. Code and dataset will be available at
https://cyberiada.github.io/SalViT360.

</details>


### [8] [A Novel Framework for Automated Explain Vision Model Using Vision-Language Models](https://arxiv.org/abs/2508.20227)
*Phu-Vinh Nguyen,Tan-Hanh Pham,Chris Ngo,Truong Son Hy*

Main category: cs.CV

TL;DR: 本文提出了一种利用视觉语言模型的管道，用于在样本和数据集层面解释视觉模型，以促进模型开发与xAI分析的结合。


<details>
  <summary>Details</summary>
Motivation: 现有的xAI方法主要针对单个样本进行解释，而解释视觉模型在大型数据集上的整体行为的研究较少。理解视觉模型在通用图像上的行为对于防止偏见判断和识别模型的趋势和模式非常重要。

Method: 应用视觉语言模型，提出了一种管道，能够在样本和数据集层面上解释视觉模型。

Result: 提出的管道能够以最小的工作量发现视觉模型的失败案例并获得洞察，从而将视觉模型开发与xAI分析相结合。

Conclusion: 本文提出了一种结合视觉语言模型的管道，用于在样本和数据集层面上解释视觉模型，旨在促进视觉模型的开发与xAI分析的结合，推动图像分析的进步。

Abstract: The development of many vision models mainly focuses on improving their
performance using metrics such as accuracy, IoU, and mAP, with less attention
to explainability due to the complexity of applying xAI methods to provide a
meaningful explanation of trained models. Although many existing xAI methods
aim to explain vision models sample-by-sample, methods explaining the general
behavior of vision models, which can only be captured after running on a large
dataset, are still underexplored. Furthermore, understanding the behavior of
vision models on general images can be very important to prevent biased
judgments and help identify the model's trends and patterns. With the
application of Vision-Language Models, this paper proposes a pipeline to
explain vision models at both the sample and dataset levels. The proposed
pipeline can be used to discover failure cases and gain insights into vision
models with minimal effort, thereby integrating vision model development with
xAI analysis to advance image analysis.

</details>


### [9] [ATMS-KD: Adaptive Temperature and Mixed Sample Knowledge Distillation for a Lightweight Residual CNN in Agricultural Embedded Systems](https://arxiv.org/abs/2508.20232)
*Mohamed Ohamouddou,Said Ohamouddou,Abdellatif El Afia,Rafik Lasri*

Main category: cs.CV

TL;DR: ATMS-KD框架通过自适应温度调度和混合样本增强，显著提升了轻量级CNN模型在农业环境中的性能，紧凑模型准确率97.11%，延迟72.19毫秒。


<details>
  <summary>Details</summary>
Motivation: 开发适用于资源受限农业环境的轻量级CNN模型，以应对多样化的环境条件。

Method: 结合自适应温度调度和混合样本增强，从MobileNetV3 Large教师模型向轻量级残差CNN学生模型转移知识。

Result: 所有学生模型的验证准确率超过96.7%，紧凑模型达到97.11%的准确率，推理延迟最低为72.19毫秒。

Conclusion: ATMS-KD框架在资源受限的农业环境中显著提升了轻量级CNN模型的性能，通过自适应温度调度和混合样本增强实现了高效的知识蒸馏。

Abstract: This study proposes ATMS-KD (Adaptive Temperature and Mixed-Sample Knowledge
Distillation), a novel framework for developing lightweight CNN models suitable
for resource-constrained agricultural environments. The framework combines
adaptive temperature scheduling with mixed-sample augmentation to transfer
knowledge from a MobileNetV3 Large teacher model (5.7\,M parameters) to
lightweight residual CNN students. Three student configurations were evaluated:
Compact (1.3\,M parameters), Standard (2.4\,M parameters), and Enhanced (3.8\,M
parameters). The dataset used in this study consists of images of \textit{Rosa
damascena} (Damask rose) collected from agricultural fields in the Dades Oasis,
southeastern Morocco, providing a realistic benchmark for agricultural computer
vision applications under diverse environmental conditions. Experimental
evaluation on the Damascena rose maturity classification dataset demonstrated
significant improvements over direct training methods. All student models
achieved validation accuracies exceeding 96.7\% with ATMS-KD compared to
95--96\% with direct training. The framework outperformed eleven established
knowledge distillation methods, achieving 97.11\% accuracy with the compact
model -- a 1.60 percentage point improvement over the second-best approach
while maintaining the lowest inference latency of 72.19\,ms. Knowledge
retention rates exceeded 99\% for all configurations, demonstrating effective
knowledge transfer regardless of student model capacity.

</details>


### [10] [Linking heterogeneous microstructure informatics with expert characterization knowledge through customized and hybrid vision-language representations for industrial qualification](https://arxiv.org/abs/2508.20243)
*Mutahar Safdar,Gentry Wood,Max Zimmermann,Guy Lamouche,Priti Wanjara,Yaoyao Fiona Zhao*

Main category: cs.CV

TL;DR: 本研究提出了一种结合视觉-语言表示和专家知识的新框架，用于快速鉴定增材制造材料，通过定制相似性表示和预训练模型实现了零样本分类，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 快速可靠地鉴定先进材料是工业制造的瓶颈，尤其是对于非传统增材制造工艺生产的异质结构。

Method: 研究开发了一种定制的基于相似性的表示方法，整合了专家注释图像及其相关文本描述的正负参考，通过深度语义分割和预训练多模态模型（CLIP和FLAVA）编码视觉微结构数据和文本专家评估。

Result: 在增材制造的金属基复合材料数据集上的验证表明，该框架能够根据一系列表征标准区分合格和缺陷样品。FLAVA模型具有更高的视觉灵敏度，CLIP模型与文本标准保持一致。

Conclusion: 本研究通过结合视觉-语言表示（VLRs）和专家知识，提出了一种可扩展且适应领域的材料鉴定策略，增强了鉴定流程的可追溯性和可解释性。

Abstract: Rapid and reliable qualification of advanced materials remains a bottleneck
in industrial manufacturing, particularly for heterogeneous structures produced
via non-conventional additive manufacturing processes. This study introduces a
novel framework that links microstructure informatics with a range of expert
characterization knowledge using customized and hybrid vision-language
representations (VLRs). By integrating deep semantic segmentation with
pre-trained multi-modal models (CLIP and FLAVA), we encode both visual
microstructural data and textual expert assessments into shared
representations. To overcome limitations in general-purpose embeddings, we
develop a customized similarity-based representation that incorporates both
positive and negative references from expert-annotated images and their
associated textual descriptions. This allows zero-shot classification of
previously unseen microstructures through a net similarity scoring approach.
Validation on an additively manufactured metal matrix composite dataset
demonstrates the framework's ability to distinguish between acceptable and
defective samples across a range of characterization criteria. Comparative
analysis reveals that FLAVA model offers higher visual sensitivity, while the
CLIP model provides consistent alignment with the textual criteria. Z-score
normalization adjusts raw unimodal and cross-modal similarity scores based on
their local dataset-driven distributions, enabling more effective alignment and
classification in the hybrid vision-language framework. The proposed method
enhances traceability and interpretability in qualification pipelines by
enabling human-in-the-loop decision-making without task-specific model
retraining. By advancing semantic interoperability between raw data and expert
knowledge, this work contributes toward scalable and domain-adaptable
qualification strategies in engineering informatics.

</details>


### [11] [MedNet-PVS: A MedNeXt-Based Deep Learning Model for Automated Segmentation of Perivascular Spaces](https://arxiv.org/abs/2508.20256)
*Zhen Xuen Brandon Low,Rory Zhang,Hang Min,William Pham,Lucy Vivash,Jasmine Moses,Miranda Lynch,Karina Dorfman,Cassandra Marotta,Shaun Koh,Jacob Bunyamin,Ella Rowsthorn,Alex Jarema,Himashi Peiris,Zhaolin Chen,Sandy R. Shultz,David K. Wright,Dexiao Kong,Sharon L. Naismith,Terence J. O'Brien,Ying Xia,Meng Law,Benjamin Sinclair*

Main category: cs.CV

TL;DR: MedNeXt-L-k5 在 T2w MRI 上表现优异，但在 T1w 和跨站点验证中性能下降，未超越 nnU-Net，表明 Transformer 机制对 PVS 分割并非必要。


<details>
  <summary>Details</summary>
Motivation: 手动分割 PVS 耗时且存在评分者间可靠性问题，现有深度学习方法性能有限且泛化能力不足，因此需要开发一种高效且通用的自动化 PVS 分割方法。

Method: 研究者采用了 Transformer 启发的 3D 编码器-解码器卷积网络 MedNeXt-L-k5，分别在 T2w 和 T1w MRI 数据集上训练模型，并通过 5 折交叉验证和留一站点交叉验证评估性能。

Result: 在 T2w 图像上，MedNeXt-L-k5 达到了 0.88±0.06 的 Dice 分数（白质），与人工评分可靠性相当，为文献中最高；但在 T1w 图像上性能显著降低（Dice 分数 0.58±0.09）。在 LOSOCV 中，模型表现进一步下降。

Conclusion: MedNeXt-L-k5 提供了一种高效的自动化 PVS 分割解决方案，适用于多种 T1w 和 T2w MRI 数据集，但其性能未超越 nnU-Net，表明基于注意力机制的 Transformer 模型在 PVS 分割中并非必需。

Abstract: Enlarged perivascular spaces (PVS) are increasingly recognized as biomarkers
of cerebral small vessel disease, Alzheimer's disease, stroke, and
aging-related neurodegeneration. However, manual segmentation of PVS is
time-consuming and subject to moderate inter-rater reliability, while existing
automated deep learning models have moderate performance and typically fail to
generalize across diverse clinical and research MRI datasets. We adapted
MedNeXt-L-k5, a Transformer-inspired 3D encoder-decoder convolutional network,
for automated PVS segmentation. Two models were trained: one using a
homogeneous dataset of 200 T2-weighted (T2w) MRI scans from the Human
Connectome Project-Aging (HCP-Aging) dataset and another using 40 heterogeneous
T1-weighted (T1w) MRI volumes from seven studies across six scanners. Model
performance was evaluated using internal 5-fold cross validation (5FCV) and
leave-one-site-out cross validation (LOSOCV). MedNeXt-L-k5 models trained on
the T2w images of the HCP-Aging dataset achieved voxel-level Dice scores of
0.88+/-0.06 (white matter, WM), comparable to the reported inter-rater
reliability of that dataset, and the highest yet reported in the literature.
The same models trained on the T1w images of the HCP-Aging dataset achieved a
substantially lower Dice score of 0.58+/-0.09 (WM). Under LOSOCV, the model had
voxel-level Dice scores of 0.38+/-0.16 (WM) and 0.35+/-0.12 (BG), and
cluster-level Dice scores of 0.61+/-0.19 (WM) and 0.62+/-0.21 (BG).
MedNeXt-L-k5 provides an efficient solution for automated PVS segmentation
across diverse T1w and T2w MRI datasets. MedNeXt-L-k5 did not outperform the
nnU-Net, indicating that the attention-based mechanisms present in
transformer-inspired models to provide global context are not required for high
accuracy in PVS segmentation.

</details>


### [12] [Plug-in Feedback Self-adaptive Attention in CLIP for Training-free Open-Vocabulary Segmentation](https://arxiv.org/abs/2508.20265)
*Zhixiang Chi,Yanan Wu,Li Gu,Huan Liu,Ziqiang Wang,Yang Zhang,Yang Wang,Konstantinos N. Plataniotis*

Main category: cs.CV

TL;DR: 提出一种无训练、反馈驱动的自适应性框架，通过输出反馈增强CLIP的中间注意力空间一致性，提升开放词汇分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过修改中间注意力增强空间一致性，但由于后续操作（如投影）导致一致性无法持续传递到最终输出，且中间注意力缺乏与文本表示的直接交互，限制了CLIP的潜力。

Method: 设计了注意力隔离、基于置信度的稀疏适应修剪和适应集成等关键模块，将输出一致性线索有效反馈到中间注意力中。

Result: 方法作为插件模块无缝集成到四种最先进的方法中，并在八个基准测试中一致提升了性能。

Conclusion: 提出的无训练、反馈驱动的自适应性框架通过将输出级别的块级对应关系反馈到中间注意力，显著提升了CLIP在开放词汇分割中的性能，并在多个基准测试中验证了其有效性。

Abstract: CLIP exhibits strong visual-textual alignment but struggle with
open-vocabulary segmentation due to poor localization. Prior methods enhance
spatial coherence by modifying intermediate attention. But, this coherence
isn't consistently propagated to the final output due to subsequent operations
such as projections. Additionally, intermediate attention lacks direct
interaction with text representations, such semantic discrepancy limits the
full potential of CLIP.
  In this work, we propose a training-free, feedback-driven self-adaptive
framework that adapts output-based patch-level correspondences back to the
intermediate attention. The output predictions, being the culmination of the
model's processing, encapsulate the most comprehensive visual and textual
semantics about each patch. Our approach enhances semantic consistency between
internal representations and final predictions by leveraging the model's
outputs as a stronger spatial coherence prior. We design key modules, including
attention isolation, confidence-based pruning for sparse adaptation, and
adaptation ensemble, to effectively feedback the output coherence cues. Our
method functions as a plug-in module, seamlessly integrating into four
state-of-the-art approaches with three backbones (ViT-B, ViT-L, ViT-H). We
further validate our framework across multiple attention types (Q-K, self-self,
and Proxy augmented with MAE, SAM, and DINO). Our approach consistently
improves their performance across eight benchmarks.

</details>


### [13] [How Multimodal LLMs Solve Image Tasks: A Lens on Visual Grounding, Task Reasoning, and Answer Decoding](https://arxiv.org/abs/2508.20279)
*Zhuoran Yu,Yong Jae Lee*

Main category: cs.CV

TL;DR: 该研究通过系统分析MLLMs如何处理视觉和文本输入，揭示了层级结构的稳定性及基础LLM架构变化对层级分配的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大型语言模型（MLLMs）在广泛的视觉语言任务中表现出强大的性能，但其内部处理动态仍未得到充分探索。

Method: 通过训练线性分类器来预测从每一层提取的token嵌入中的细粒度视觉类别，使用标准化的锚定问题，并评估三种类型的提示变化下的探测器。

Result: 研究发现MLLMs的层级结构具有一致性，早期层负责视觉基础，中间层支持词汇整合和语义推理，最后层准备任务特定输出。

Conclusion: 该研究为MLLMs的层级组织提供了一个统一的视角，并提出了一种轻量级、模型无关的方法来分析多模态表示动态。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance
across a wide range of vision-language tasks, yet their internal processing
dynamics remain underexplored. In this work, we introduce a probing framework
to systematically analyze how MLLMs process visual and textual inputs across
layers. We train linear classifiers to predict fine-grained visual categories
(e.g., dog breeds) from token embeddings extracted at each layer, using a
standardized anchor question. To uncover the functional roles of different
layers, we evaluate these probes under three types of controlled prompt
variations: (1) lexical variants that test sensitivity to surface-level
changes, (2) semantic negation variants that flip the expected answer by
modifying the visual concept in the prompt, and (3) output format variants that
preserve reasoning but alter the answer format. Applying our framework to
LLaVA-1.5, LLaVA-Next-LLaMA-3, and Qwen2-VL, we identify a consistent
stage-wise structure in which early layers perform visual grounding, middle
layers support lexical integration and semantic reasoning, and final layers
prepare task-specific outputs. We further show that while the overall
stage-wise structure remains stable across variations in visual tokenization,
instruction tuning data, and pretraining corpus, the specific layer allocation
to each stage shifts notably with changes in the base LLM architecture. Our
findings provide a unified perspective on the layer-wise organization of MLLMs
and offer a lightweight, model-agnostic approach for analyzing multimodal
representation dynamics.

</details>


### [14] [Disentangling Latent Embeddings with Sparse Linear Concept Subspaces (SLiCS)](https://arxiv.org/abs/2508.20322)
*Zhi Li,Hau Phan,Matthew Emigh,Austin J. Brockmeier*

Main category: cs.CV

TL;DR: 提出SLiCS方法解耦视觉语言共嵌入空间，通过监督字典学习实现更精确的概念过滤图像检索和条件生成。


<details>
  <summary>Details</summary>
Motivation: 假设CLIP等视觉语言共嵌入网络的嵌入空间可以解耦，以分离复杂场景内容的信息。

Method: 提出了一种监督字典学习方法，通过交替优化估计线性合成模型，该模型由字典中向量的稀疏、非负组合组成，其组活动与多标签信息匹配。

Result: SLiCS方法在概念过滤图像检索和条件生成方面表现出更高的精确度，适用于多种嵌入空间。

Conclusion: SLiCS方法通过稀疏线性概念子空间实现了更精确的概念过滤图像检索和条件生成，展示了其在多种嵌入空间中的有效性。

Abstract: Vision-language co-embedding networks, such as CLIP, provide a latent
embedding space with semantic information that is useful for downstream tasks.
We hypothesize that the embedding space can be disentangled to separate the
information on the content of complex scenes by decomposing the embedding into
multiple concept-specific component vectors that lie in different subspaces. We
propose a supervised dictionary learning approach to estimate a linear
synthesis model consisting of sparse, non-negative combinations of groups of
vectors in the dictionary (atoms), whose group-wise activity matches the
multi-label information. Each concept-specific component is a non-negative
combination of atoms associated to a label. The group-structured dictionary is
optimized through a novel alternating optimization with guaranteed convergence.
Exploiting the text co-embeddings, we detail how semantically meaningful
descriptions can be found based on text embeddings of words best approximated
by a concept's group of atoms, and unsupervised dictionary learning can exploit
zero-shot classification of training set images using the text embeddings of
concept labels to provide instance-wise multi-labels. We show that the
disentangled embeddings provided by our sparse linear concept subspaces (SLiCS)
enable concept-filtered image retrieval (and conditional generation using
image-to-prompt) that is more precise. We also apply SLiCS to highly-compressed
autoencoder embeddings from TiTok and the latent embedding from self-supervised
DINOv2. Quantitative and qualitative results highlight the improved precision
of the concept-filtered image retrieval for all embeddings.

</details>


### [15] [MedFoundationHub: A Lightweight and Secure Toolkit for Deploying Medical Vision Language Foundation Models](https://arxiv.org/abs/2508.20345)
*Xiao Li,Yanfan Zhu,Ruining Deng,Wei-Qi Wei,Yu Wang,Shilin Zhao,Yaohong Wang,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: 医疗 VLMs 的安全和易用性工具包 MedFoundationHub，通过 Docker 和 Hugging Face 实现隐私保护部署，专家评估揭示了模型局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管医疗 VLMs 在临床应用中具有巨大潜力，但其引入的隐私和安全风险（如 PHI 暴露、数据泄漏和网络威胁）不容忽视。

Method: 通过 Docker 编排的、操作系统无关的部署方式，结合 Hugging Face 开源模型，实现隐私保护的推理。工具包仅需配备单个 NVIDIA A6000 GPU 的离线本地工作站。

Result: 专家评估了五种先进的 VLMs，揭示了模型在回答准确性、推理清晰度和病理学术语一致性方面的局限性。

Conclusion: MedFoundationHub 是一个图形用户界面（GUI）工具包，旨在解决医疗视觉语言模型（VLMs）的安全和易用性问题，支持医生和工程师在隐私保护的前提下高效部署和使用模型。

Abstract: Recent advances in medical vision-language models (VLMs) open up remarkable
opportunities for clinical applications such as automated report generation,
copilots for physicians, and uncertainty quantification. However, despite their
promise, medical VLMs introduce serious security concerns, most notably risks
of Protected Health Information (PHI) exposure, data leakage, and vulnerability
to cyberthreats - which are especially critical in hospital environments. Even
when adopted for research or non-clinical purposes, healthcare organizations
must exercise caution and implement safeguards. To address these challenges, we
present MedFoundationHub, a graphical user interface (GUI) toolkit that: (1)
enables physicians to manually select and use different models without
programming expertise, (2) supports engineers in efficiently deploying medical
VLMs in a plug-and-play fashion, with seamless integration of Hugging Face
open-source models, and (3) ensures privacy-preserving inference through
Docker-orchestrated, operating system agnostic deployment. MedFoundationHub
requires only an offline local workstation equipped with a single NVIDIA A6000
GPU, making it both secure and accessible within the typical resources of
academic research labs. To evaluate current capabilities, we engaged
board-certified pathologists to deploy and assess five state-of-the-art VLMs
(Google-MedGemma3-4B, Qwen2-VL-7B-Instruct, Qwen2.5-VL-7B-Instruct, and
LLaVA-1.5-7B/13B). Expert evaluation covered colon cases and renal cases,
yielding 1015 clinician-model scoring events. These assessments revealed
recurring limitations, including off-target answers, vague reasoning, and
inconsistent pathology terminology.

</details>


### [16] [Enhancing Mamba Decoder with Bidirectional Interaction in Multi-Task Dense Prediction](https://arxiv.org/abs/2508.20376)
*Mang Cao,Sanping Zhou,Yizhe Li,Ye Deng,Wenli Huang,Le Wang*

Main category: cs.CV

TL;DR: BIM通过双向交互扫描和多尺度扫描机制，高效解决了多任务密集预测中跨任务交互与计算效率的权衡问题，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨任务交互完整性和计算效率之间存在权衡，BIM旨在解决这一限制。

Method: 提出了Bidirectional Interaction Mamba (BIM)，结合了双向交互扫描机制（BI-Scan）和多尺度扫描机制（MS-Scan），通过线性复杂度架构高效保留跨任务信息。

Result: 在NYUD-V2和PASCAL-Context基准测试中，BIM表现出优于现有最先进方法的性能。

Conclusion: Bidirectional Interaction Mamba (BIM) 通过创新的双向交互扫描机制（BI-Scan）和多尺度扫描机制（MS-Scan），在多任务密集预测中实现了高效且完整的跨任务交互，显著提升了性能。

Abstract: Sufficient cross-task interaction is crucial for success in multi-task dense
prediction. However, sufficient interaction often results in high computational
complexity, forcing existing methods to face the trade-off between interaction
completeness and computational efficiency. To address this limitation, this
work proposes a Bidirectional Interaction Mamba (BIM), which incorporates novel
scanning mechanisms to adapt the Mamba modeling approach for multi-task dense
prediction. On the one hand, we introduce a novel Bidirectional Interaction
Scan (BI-Scan) mechanism, which constructs task-specific representations as
bidirectional sequences during interaction. By integrating task-first and
position-first scanning modes within a unified linear complexity architecture,
BI-Scan efficiently preserves critical cross-task information. On the other
hand, we employ a Multi-Scale Scan~(MS-Scan) mechanism to achieve
multi-granularity scene modeling. This design not only meets the diverse
granularity requirements of various tasks but also enhances nuanced cross-task
feature interactions. Extensive experiments on two challenging benchmarks,
\emph{i.e.}, NYUD-V2 and PASCAL-Context, show the superiority of our BIM vs its
state-of-the-art competitors.

</details>


### [17] [Audio-Guided Visual Editing with Complex Multi-Modal Prompts](https://arxiv.org/abs/2508.20379)
*Hyeonyu Kim,Seokhoon Jeong,Seonghee Han,Chanhyuk Choi,Taehwan Kim*

Main category: cs.CV

TL;DR: 提出了一种无需额外训练的音频引导视觉编辑框架，通过多模态提示（文本+音频）解决复杂编辑任务，实验证明其优于纯文本方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉编辑方法在复杂场景下仅依赖文本提示效果不佳，需要额外的非文本编辑提示。音频作为一种丰富的信息源，可以弥补这一不足。

Method: 利用预训练的多模态编码器，结合分离噪声分支和自适应补丁选择技术，实现了无需额外训练的多模态提示编辑。

Result: 综合实验表明，该框架在多样化编辑任务中表现优异，尤其在文本无法单独描述的复杂场景下。

Conclusion: 该论文提出了一种新颖的音频引导视觉编辑框架，通过结合多模态提示（文本和音频）解决了复杂编辑任务中仅依赖文本引导的不足。实验证明，该方法在复杂场景下表现优异。

Abstract: Visual editing with diffusion models has made significant progress but often
struggles with complex scenarios that textual guidance alone could not
adequately describe, highlighting the need for additional non-text editing
prompts. In this work, we introduce a novel audio-guided visual editing
framework that can handle complex editing tasks with multiple text and audio
prompts without requiring additional training. Existing audio-guided visual
editing methods often necessitate training on specific datasets to align audio
with text, limiting their generalization to real-world situations. We leverage
a pre-trained multi-modal encoder with strong zero-shot capabilities and
integrate diverse audio into visual editing tasks, by alleviating the
discrepancy between the audio encoder space and the diffusion model's prompt
encoder space. Additionally, we propose a novel approach to handle complex
scenarios with multiple and multi-modal editing prompts through our separate
noise branching and adaptive patch selection. Our comprehensive experiments on
diverse editing tasks demonstrate that our framework excels in handling
complicated editing scenarios by incorporating rich information from audio,
where text-only approaches fail.

</details>


### [18] [More Reliable Pseudo-labels, Better Performance: A Generalized Approach to Single Positive Multi-label Learning](https://arxiv.org/abs/2508.20381)
*Luong Tran,Thieu Vo,Anh Nguyen,Sang Dinh,Van Nguyen*

Main category: cs.CV

TL;DR: AEVLP框架通过GPR Loss和DAMP技术，有效解决了单正多标签学习中的噪声问题，取得了最先进的多标签分类结果。


<details>
  <summary>Details</summary>
Motivation: 大规模数据集的完全标注成本高且不切实际，因此需要研究从部分标注数据中学习的方法。

Method: 提出了GPR Loss和DAMP技术，结合形成AEVLP框架。

Result: 在四个基准数据集上的实验表明，该框架显著提升了多标签分类性能。

Conclusion: 提出的AEVLP框架通过GPR Loss和DAMP技术显著提升了多标签分类的性能，实现了最先进的结果。

Abstract: Multi-label learning is a challenging computer vision task that requires
assigning multiple categories to each image. However, fully annotating
large-scale datasets is often impractical due to high costs and effort,
motivating the study of learning from partially annotated data. In the extreme
case of Single Positive Multi-Label Learning (SPML), each image is provided
with only one positive label, while all other labels remain unannotated.
Traditional SPML methods that treat missing labels as unknown or negative tend
to yield inaccuracies and false negatives, and integrating various
pseudo-labeling strategies can introduce additional noise. To address these
challenges, we propose the Generalized Pseudo-Label Robust Loss (GPR Loss), a
novel loss function that effectively learns from diverse pseudo-labels while
mitigating noise. Complementing this, we introduce a simple yet effective
Dynamic Augmented Multi-focus Pseudo-labeling (DAMP) technique. Together, these
contributions form the Adaptive and Efficient Vision-Language Pseudo-Labeling
(AEVLP) framework. Extensive experiments on four benchmark datasets demonstrate
that our framework significantly advances multi-label classification, achieving
state-of-the-art results.

</details>


### [19] [Ultra-Low-Latency Spiking Neural Networks with Temporal-Dependent Integrate-and-Fire Neuron Model for Objects Detection](https://arxiv.org/abs/2508.20392)
*Chengjun Zhang,Yuhao Zhang,Jie Yang,Mohamad Sawan*

Main category: cs.CV

TL;DR: 本文提出了一种新的tdIF神经元架构和delay-spike方法，显著提升了SNN在视觉检测任务中的性能，实现了超低延迟下的最优表现。


<details>
  <summary>Details</summary>
Motivation: 当前ANN-SNN转换方法在分类任务中表现优异，但在视觉检测任务中性能不足，需要一种能够更精确表示特征并降低延迟的新方法。

Method: 提出了一种delay-spike方法以解决异质脉冲模式导致的残余膜电位问题，并设计了一种新型的tdIF神经元架构，使IF神经元能够根据时间步的顺序动态调整其积累和发放行为。

Result: 在目标检测和车道线检测任务中，所提方法超越了现有ANN-SNN转换方法，实现了超低延迟下的最优性能。

Conclusion: 本文提出的tdIF神经元架构和delay-spike方法显著提升了SNN在视觉检测任务中的性能，实现了超低延迟（5个时间步内）下的最优表现。

Abstract: Spiking Neural Networks (SNNs), inspired by the brain, are characterized by
minimal power consumption and swift inference capabilities on neuromorphic
hardware, and have been widely applied to various visual perception tasks.
Current ANN-SNN conversion methods have achieved excellent results in
classification tasks with ultra-low time-steps, but their performance in visual
detection tasks remains suboptimal. In this paper, we propose a delay-spike
approach to mitigate the issue of residual membrane potential caused by
heterogeneous spiking patterns. Furthermore, we propose a novel
temporal-dependent Integrate-and-Fire (tdIF) neuron architecture for SNNs. This
enables Integrate-and-fire (IF) neurons to dynamically adjust their
accumulation and firing behaviors based on the temporal order of time-steps.
Our method enables spikes to exhibit distinct temporal properties, rather than
relying solely on frequency-based representations. Moreover, the tdIF neuron
maintains energy consumption on par with traditional IF neuron. We demonstrate
that our method achieves more precise feature representation with lower
time-steps, enabling high performance and ultra-low latency in visual detection
tasks. In this study, we conduct extensive evaluation of the tdIF method across
two critical vision tasks: object detection and lane line detection. The
results demonstrate that the proposed method surpasses current ANN-SNN
conversion approaches, achieving state-of-the-art performance with ultra-low
latency (within 5 time-steps).

</details>


### [20] [Graph-Based Uncertainty Modeling and Multimodal Fusion for Salient Object Detection](https://arxiv.org/abs/2508.20415)
*Yuqi Xiong,Wuzhen Shi,Yang Wen,Ruhan Liu*

Main category: cs.CV

TL;DR: 提出DUP-MCRNet，通过动态不确定性传播和多模态协同融合，显著提升显著目标检测的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测方法在复杂场景中易丢失细节、边缘模糊且单模态信息融合不足，需改进。

Method: 设计了动态不确定性图卷积模块（DUGC）和多模态协同融合策略（MCF），结合多尺度损失和一致性约束优化检测性能。

Result: 在多个基准数据集上优于现有方法，尤其在边缘清晰度和复杂背景鲁棒性方面表现突出。

Conclusion: DUP-MCRNet通过动态不确定性传播和多模态协同推理，显著提升了显著目标检测的精度和鲁棒性，尤其在边缘清晰度和复杂背景下的表现优于现有方法。

Abstract: In view of the problems that existing salient object detection (SOD) methods
are prone to losing details, blurring edges, and insufficient fusion of
single-modal information in complex scenes, this paper proposes a dynamic
uncertainty propagation and multimodal collaborative reasoning network
(DUP-MCRNet). Firstly, a dynamic uncertainty graph convolution module (DUGC) is
designed to propagate uncertainty between layers through a sparse graph
constructed based on spatial semantic distance, and combined with channel
adaptive interaction, it effectively improves the detection accuracy of small
structures and edge regions. Secondly, a multimodal collaborative fusion
strategy (MCF) is proposed, which uses learnable modality gating weights to
weightedly fuse the attention maps of RGB, depth, and edge features. It can
dynamically adjust the importance of each modality according to different
scenes, effectively suppress redundant or interfering information, and
strengthen the semantic complementarity and consistency between
cross-modalities, thereby improving the ability to identify salient regions
under occlusion, weak texture or background interference. Finally, the
detection performance at the pixel level and region level is optimized through
multi-scale BCE and IoU loss, cross-scale consistency constraints, and
uncertainty-guided supervision mechanisms. Extensive experiments show that
DUP-MCRNet outperforms various SOD methods on most common benchmark datasets,
especially in terms of edge clarity and robustness to complex backgrounds. Our
code is publicly available at https://github.com/YukiBear426/DUP-MCRNet.

</details>


### [21] [MSMVD: Exploiting Multi-scale Image Features via Multi-scale BEV Features for Multi-view Pedestrian Detection](https://arxiv.org/abs/2508.20447)
*Taiga Yamane,Satoshi Suzuki,Ryo Masumura,Shota Orihashi,Tomohiro Tanaka,Mana Ihori,Naoki Makishima,Naotaka Kawata*

Main category: cs.CV

TL;DR: MSMVD通过多尺度BEV特征和特征金字塔网络，解决了多视角行人检测中尺度不一致的问题，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端可训练深度学习方法在检测视角中尺度一致偏小或偏大、或视角间尺度差异极大的行人时表现不佳，因为它们未能充分利用多尺度图像特征来生成BEV特征。

Method: MSMVD通过将多尺度图像特征逐尺度投影到BEV空间，生成多尺度BEV特征，并利用特征金字塔网络处理这些特征，以结合不同尺度的多视角信息。

Result: MSMVD在GMVD数据集上表现优异，MODA分数提升了4.5分，验证了多尺度BEV特征对提升检测性能的有效性。

Conclusion: MSMVD通过利用多尺度图像特征生成多尺度BEV特征，显著提升了多视角行人检测的性能，并在GMVD数据集上超越了之前最高的MODA分数4.5分。

Abstract: Multi-View Pedestrian Detection (MVPD) aims to detect pedestrians in the form
of a bird's eye view (BEV) from multi-view images. In MVPD, end-to-end
trainable deep learning methods have progressed greatly. However, they often
struggle to detect pedestrians with consistently small or large scales in views
or with vastly different scales between views. This is because they do not
exploit multi-scale image features to generate the BEV feature and detect
pedestrians. To overcome this problem, we propose a novel MVPD method, called
Multi-Scale Multi-View Detection (MSMVD). MSMVD generates multi-scale BEV
features by projecting multi-scale image features extracted from individual
views into the BEV space, scale-by-scale. Each of these BEV features inherits
the properties of its corresponding scale image features from multiple views.
Therefore, these BEV features help the precise detection of pedestrians with
consistently small or large scales in views. Then, MSMVD combines information
at different scales of multiple views by processing the multi-scale BEV
features using a feature pyramid network. This improves the detection of
pedestrians with vastly different scales between views. Extensive experiments
demonstrate that exploiting multi-scale image features via multi-scale BEV
features greatly improves the detection performance, and MSMVD outperforms the
previous highest MODA by $4.5$ points on the GMVD dataset.

</details>


### [22] [A Spatial-Frequency Aware Multi-Scale Fusion Network for Real-Time Deepfake Detection](https://arxiv.org/abs/2508.20449)
*Libo Lv,Tianyi Wang,Mengxiao Huang,Ruixia Liu,Yinglong Wang*

Main category: cs.CV

TL;DR: SFMFNet 是一种轻量级高效的实时深度伪造检测网络，结合空间-频率感知和多尺度融合，实现了高准确性和低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度伪造检测器计算成本高、难以实时部署的问题。

Method: 提出了 Spatial-Frequency Aware Multi-Scale Fusion Network (SFMFNet)，包括空间-频率混合感知模块、令牌选择性交叉注意力机制和残差增强模糊池化结构。

Result: 在多个基准数据集上，SFMFNet 在准确性和效率方面表现优越。

Conclusion: SFMFNet 在实时深度伪造检测中实现了高准确性和高效率的平衡，具有强泛化能力和实际应用价值。

Abstract: With the rapid advancement of real-time deepfake generation techniques,
forged content is becoming increasingly realistic and widespread across
applications like video conferencing and social media. Although
state-of-the-art detectors achieve high accuracy on standard benchmarks, their
heavy computational cost hinders real-time deployment in practical
applications. To address this, we propose the Spatial-Frequency Aware
Multi-Scale Fusion Network (SFMFNet), a lightweight yet effective architecture
for real-time deepfake detection. We design a spatial-frequency hybrid aware
module that jointly leverages spatial textures and frequency artifacts through
a gated mechanism, enhancing sensitivity to subtle manipulations. A
token-selective cross attention mechanism enables efficient multi-level feature
interaction, while a residual-enhanced blur pooling structure helps retain key
semantic cues during downsampling. Experiments on several benchmark datasets
show that SFMFNet achieves a favorable balance between accuracy and efficiency,
with strong generalization and practical value for real-time applications.

</details>


### [23] [Dual-Model Weight Selection and Self-Knowledge Distillation for Medical Image Classification](https://arxiv.org/abs/2508.20461)
*Ayaka Tsutsumi,Guang Li,Ren Togo,Takahiro Ogawa,Satoshi Kondo,Miki Haseyama*

Main category: cs.CV

TL;DR: 提出一种结合双模型权重选择和自知识蒸馏的轻量级医学图像分类方法，在计算资源受限的医疗场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在现实医疗场景中，大规模模型部署常受限于计算资源，因此开发轻量级模型以在保持计算效率的同时实现与大模型相当的性能至关重要。

Method: 采用双模型权重选择策略初始化两个轻量级模型，并使用自知识蒸馏进行训练，随后针对目标任务进行微调。

Result: 在公开数据集（胸部X光、肺部CT扫描和脑部MRI扫描）上的实验表明，该方法优于现有方法。

Conclusion: 该方法通过结合双模型权重选择与自知识蒸馏，克服了传统方法在紧凑模型中保留关键信息的不足，展现出优越的性能和鲁棒性。

Abstract: We propose a novel medical image classification method that integrates
dual-model weight selection with self-knowledge distillation (SKD). In
real-world medical settings, deploying large-scale models is often limited by
computational resource constraints, which pose significant challenges for their
practical implementation. Thus, developing lightweight models that achieve
comparable performance to large-scale models while maintaining computational
efficiency is crucial. To address this, we employ a dual-model weight selection
strategy that initializes two lightweight models with weights derived from a
large pretrained model, enabling effective knowledge transfer. Next, SKD is
applied to these selected models, allowing the use of a broad range of initial
weight configurations without imposing additional excessive computational cost,
followed by fine-tuning for the target classification tasks. By combining
dual-model weight selection with self-knowledge distillation, our method
overcomes the limitations of conventional approaches, which often fail to
retain critical information in compact models. Extensive experiments on
publicly available datasets-chest X-ray images, lung computed tomography scans,
and brain magnetic resonance imaging scans-demonstrate the superior performance
and robustness of our approach compared to existing methods.

</details>


### [24] [Re-Densification Meets Cross-Scale Propagation: Real-Time Compression of LiDAR Point Clouds](https://arxiv.org/abs/2508.20466)
*Pengpeng Yu,Haoran Li,Dingquan Li,Runqing Jiang,Jing Wang,Liang Lin,Yulan Guo*

Main category: cs.CV

TL;DR: 提出了一种轻量级框架，通过几何重新稠密化和跨尺度特征传播模块，实现了LiDAR点云的高效压缩和实时处理。


<details>
  <summary>Details</summary>
Motivation: LiDAR点云的高精度扫描导致存储和传输开销大，现有方法在极稀疏的几何细节上难以高效建模上下文，限制了压缩性能和速度。

Method: 提出了一种包含两个轻量级模块的框架：几何重新稠密化模块和跨尺度特征传播模块。前者通过在更密集的尺度上提取特征来避免高稀疏细节上的昂贵计算，后者利用多分辨率级别的占用线索来指导层次特征传播。

Result: 在KITTI数据集上实现了最先进的压缩比和实时性能，编码和解码速度达到26 FPS（12位量化）。

Conclusion: 实验结果表明，该方法在KITTI数据集上实现了最先进的压缩比和实时性能，编码和解码速度达到26 FPS（12位量化）。

Abstract: LiDAR point clouds are fundamental to various applications, yet
high-precision scans incur substantial storage and transmission overhead.
Existing methods typically convert unordered points into hierarchical octree or
voxel structures for dense-to-sparse predictive coding. However, the extreme
sparsity of geometric details hinders efficient context modeling, thereby
limiting their compression performance and speed. To address this challenge, we
propose to generate compact features for efficient predictive coding. Our
framework comprises two lightweight modules. First, the Geometry
Re-Densification Module re-densifies encoded sparse geometry, extracts features
at denser scale, and then re-sparsifies the features for predictive coding.
This module avoids costly computation on highly sparse details while
maintaining a lightweight prediction head. Second, the Cross-scale Feature
Propagation Module leverages occupancy cues from multiple resolution levels to
guide hierarchical feature propagation. This design facilitates information
sharing across scales, thereby reducing redundant feature extraction and
providing enriched features for the Geometry Re-Densification Module. By
integrating these two modules, our method yields a compact feature
representation that provides efficient context modeling and accelerates the
coding process. Experiments on the KITTI dataset demonstrate state-of-the-art
compression ratios and real-time performance, achieving 26 FPS for both
encoding and decoding at 12-bit quantization. Code is available at
https://github.com/pengpeng-yu/FastPCC.

</details>


### [25] [SKGE-SWIN: End-To-End Autonomous Vehicle Waypoint Prediction and Navigation Using Skip Stage Swin Transformer](https://arxiv.org/abs/2508.20762)
*Fachri Najm Noer Kartiman,Rasim,Yaya Wihardi,Nurul Hasanah,Oskar Natan,Bambang Wahono,Taufik Ibnu Salim*

Main category: cs.CV

TL;DR: SKGE-Swin架构结合Swin Transformer和跳级机制，在CARLA测试中表现优异，提升了自动驾驶的环境理解能力。


<details>
  <summary>Details</summary>
Motivation: 开发具有像素到像素上下文感知能力的端到端自动驾驶模型，以提升对复杂环境模式的理解。

Method: 采用Swin Transformer和跳级机制，通过SW-MSA机制提取远距离像素信息，并保留关键特征。

Result: SKGE-Swin架构在驾驶评分上优于现有方法。

Conclusion: SKGE-Swin架构在CARLA平台上通过对抗性场景测试，展现出优于之前方法的驾驶评分，证明了其在复杂环境中的有效性。

Abstract: Focusing on the development of an end-to-end autonomous vehicle model with
pixel-to-pixel context awareness, this research proposes the SKGE-Swin
architecture. This architecture utilizes the Swin Transformer with a skip-stage
mechanism to broaden feature representation globally and at various network
levels. This approach enables the model to extract information from distant
pixels by leveraging the Swin Transformer's Shifted Window-based Multi-head
Self-Attention (SW-MSA) mechanism and to retain critical information from the
initial to the final stages of feature extraction, thereby enhancing its
capability to comprehend complex patterns in the vehicle's surroundings. The
model is evaluated on the CARLA platform using adversarial scenarios to
simulate real-world conditions. Experimental results demonstrate that the
SKGE-Swin architecture achieves a superior Driving Score compared to previous
methods. Furthermore, an ablation study will be conducted to evaluate the
contribution of each architectural component, including the influence of skip
connections and the use of the Swin Transformer, in improving model
performance.

</details>


### [26] [Droplet3D: Commonsense Priors from Videos Facilitate 3D Generation](https://arxiv.org/abs/2508.20470)
*Xiaochuan Li,Guoguang Du,Runze Zhang,Liang Jin,Qi Jia,Lihua Lu,Zhenhua Guo,Yaqian Zhao,Haiyang Liu,Tianqi Wang,Changsheng Li,Xiaoli Gong,Rengang Li,Baoyu Fan*

Main category: cs.CV

TL;DR: 论文提出利用视频中的常识先验解决3D生成中的数据稀缺问题，构建了首个大规模多视角标注视频数据集Droplet3D-4M，并训练了支持图像和文本输入的生成模型Droplet3D，验证了其空间一致性和语义合理性。


<details>
  <summary>Details</summary>
Motivation: 解决3D生成领域因数据稀缺导致的泛化瓶颈，利用视频中的空间一致性和语义信息作为监督信号。

Method: 构建Droplet3D-4M数据集，训练支持多模态输入的生成模型Droplet3D。

Result: 实验证明方法能生成空间一致且语义合理的3D内容，并具备场景级扩展潜力。

Conclusion: 视频中的常识先验显著促进了3D生成，开源资源推动领域发展。

Abstract: Scaling laws have validated the success and promise of large-data-trained
models in creative generation across text, image, and video domains. However,
this paradigm faces data scarcity in the 3D domain, as there is far less of it
available on the internet compared to the aforementioned modalities.
Fortunately, there exist adequate videos that inherently contain commonsense
priors, offering an alternative supervisory signal to mitigate the
generalization bottleneck caused by limited native 3D data. On the one hand,
videos capturing multiple views of an object or scene provide a spatial
consistency prior for 3D generation. On the other hand, the rich semantic
information contained within the videos enables the generated content to be
more faithful to the text prompts and semantically plausible. This paper
explores how to apply the video modality in 3D asset generation, spanning
datasets to models. We introduce Droplet3D-4M, the first large-scale video
dataset with multi-view level annotations, and train Droplet3D, a generative
model supporting both image and dense text input. Extensive experiments
validate the effectiveness of our approach, demonstrating its ability to
produce spatially consistent and semantically plausible content. Moreover, in
contrast to the prevailing 3D solutions, our approach exhibits the potential
for extension to scene-level applications. This indicates that the commonsense
priors from the videos significantly facilitate 3D creation. We have
open-sourced all resources including the dataset, code, technical framework,
and model weights: https://dropletx.github.io/.

</details>


### [27] [To New Beginnings: A Survey of Unified Perception in Autonomous Vehicle Software](https://arxiv.org/abs/2508.20892)
*Loïc Stratil,Felix Fent,Esteban Rivera,Markus Lienkamp*

Main category: cs.CV

TL;DR: 本文综述了自动驾驶统一感知的三种范式，整合了现有方法并指导未来研究，旨在解决模块化管道的局限。


<details>
  <summary>Details</summary>
Motivation: 传统模块化感知管道存在错误累积和任务间协同有限的问题，统一感知有望提高鲁棒性、上下文推理和效率，同时保持可解释性。

Method: 通过任务集成、跟踪公式化和表示流对方法进行分类，定义了三种范式——早期、晚期和完全统一感知，并系统回顾了现有方法、架构、训练策略、数据集和开源可用性。

Result: 本文提供了统一感知的全面概述，提出了一个整体和系统的分类法，并强调了未来的研究方向。

Conclusion: 本文建立了首个全面理解并推进统一感知的框架，整合了零散的研究成果，并指导未来研究朝着更鲁棒、可泛化和可解释的感知方向发展。

Abstract: Autonomous vehicle perception typically relies on modular pipelines that
decompose the task into detection, tracking, and prediction. While
interpretable, these pipelines suffer from error accumulation and limited
inter-task synergy. Unified perception has emerged as a promising paradigm that
integrates these sub-tasks within a shared architecture, potentially improving
robustness, contextual reasoning, and efficiency while retaining interpretable
outputs. In this survey, we provide a comprehensive overview of unified
perception, introducing a holistic and systemic taxonomy that categorizes
methods along task integration, tracking formulation, and representation flow.
We define three paradigms -Early, Late, and Full Unified Perception- and
systematically review existing methods, their architectures, training
strategies, datasets used, and open-source availability, while highlighting
future research directions. This work establishes the first comprehensive
framework for understanding and advancing unified perception, consolidates
fragmented efforts, and guides future research toward more robust,
generalizable, and interpretable perception.

</details>


### [28] [Realistic and Controllable 3D Gaussian-Guided Object Editing for Driving Video Generation](https://arxiv.org/abs/2508.20471)
*Jiusi Li,Jackson Jiang,Jinyu Miao,Miao Long,Tuopu Wen,Peijin Jia,Shengxiang Liu,Chunlei Yu,Maolin Liu,Yuzhan Cai,Kun Jiang,Mengmeng Yang,Diange Yang*

Main category: cs.CV

TL;DR: G^2Editor是一个用于自动驾驶视频中逼真且精确对象编辑的框架，通过3D高斯先验和分层特征提升编辑质量，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于真实场景中收集自动驾驶的极端案例成本高且危险，通过编辑传感器数据生成多样场景成为有效替代方案，但现有方法在视觉逼真度和姿态控制上存在不足。

Method: G^2Editor 利用3D高斯表示作为密集先验，注入去噪过程以确保姿态控制和空间一致性；采用场景级3D边界框布局重建非目标对象的遮挡区域；并通过分层细粒度特征引导生成对象的细节。

Result: 在Waymo Open Dataset上的实验表明，G^2Editor在姿态可控性和视觉质量上优于现有方法，并支持多种编辑操作。

Conclusion: G^2Editor 在自动驾驶视频中实现了高度逼真和精确的对象编辑，显著提升了姿态可控性和视觉质量，同时支持对象重新定位、插入和删除，对下游数据驱动任务具有积极影响。

Abstract: Corner cases are crucial for training and validating autonomous driving
systems, yet collecting them from the real world is often costly and hazardous.
Editing objects within captured sensor data offers an effective alternative for
generating diverse scenarios, commonly achieved through 3D Gaussian Splatting
or image generative models. However, these approaches often suffer from limited
visual fidelity or imprecise pose control. To address these issues, we propose
G^2Editor, a framework designed for photorealistic and precise object editing
in driving videos. Our method leverages a 3D Gaussian representation of the
edited object as a dense prior, injected into the denoising process to ensure
accurate pose control and spatial consistency. A scene-level 3D bounding box
layout is employed to reconstruct occluded areas of non-target objects.
Furthermore, to guide the appearance details of the edited object, we
incorporate hierarchical fine-grained features as additional conditions during
generation. Experiments on the Waymo Open Dataset demonstrate that G^2Editor
effectively supports object repositioning, insertion, and deletion within a
unified framework, outperforming existing methods in both pose controllability
and visual quality, while also benefiting downstream data-driven tasks.

</details>


### [29] [COMETH: Convex Optimization for Multiview Estimation and Tracking of Humans](https://arxiv.org/abs/2508.20920)
*Enrico Martini,Ho Jin Choi,Nadia Figueroa,Nicola Bombieri*

Main category: cs.CV

TL;DR: COMETH是一种轻量级算法，通过运动学和生物力学约束、凸优化逆向运动学及状态观测器，实现高精度、可扩展的实时多视角人体姿态融合，适用于工业5.0时代。


<details>
  <summary>Details</summary>
Motivation: 多摄像头集中式设置虽提高姿态估计精度，但存在高计算成本和带宽需求问题，而边缘设备资源受限导致精度下降及时空不一致性。

Method: 提出COMETH算法，结合运动学和生物力学约束提升关节定位精度，采用凸优化逆向运动学进行空间融合，并利用状态观测器改善时间一致性。

Result: 在公共和工业数据集上，COMETH在定位、检测和跟踪精度上优于现有方法。

Conclusion: COMETH通过整合运动学和生物力学约束、基于凸优化的逆向运动学空间融合以及状态观测器提升时间一致性，实现了高精度、可扩展的实时多视角人体姿态融合，适用于工业和安全关键应用。

Abstract: In the era of Industry 5.0, monitoring human activity is essential for
ensuring both ergonomic safety and overall well-being. While multi-camera
centralized setups improve pose estimation accuracy, they often suffer from
high computational costs and bandwidth requirements, limiting scalability and
real-time applicability. Distributing processing across edge devices can reduce
network bandwidth and computational load. On the other hand, the constrained
resources of edge devices lead to accuracy degradation, and the distribution of
computation leads to temporal and spatial inconsistencies. We address this
challenge by proposing COMETH (Convex Optimization for Multiview Estimation and
Tracking of Humans), a lightweight algorithm for real-time multi-view human
pose fusion that relies on three concepts: it integrates kinematic and
biomechanical constraints to increase the joint positioning accuracy; it
employs convex optimization-based inverse kinematics for spatial fusion; and it
implements a state observer to improve temporal consistency. We evaluate COMETH
on both public and industrial datasets, where it outperforms state-of-the-art
methods in localization, detection, and tracking accuracy. The proposed fusion
pipeline enables accurate and scalable human motion tracking, making it
well-suited for industrial and safety-critical applications. The code is
publicly available at https://github.com/PARCO-LAB/COMETH.

</details>


### [30] [Enhancing Corpus Callosum Segmentation in Fetal MRI via Pathology-Informed Domain Randomization](https://arxiv.org/abs/2508.20475)
*Marina Grifell i Plana,Vladyslav Zalevskyi,Léa Schmidt,Yvan Gomez,Thomas Sanchez,Vincent Dunet,Mériam Koob,Vanessa Siffredi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 提出了一种基于病理信息化的合成数据生成方法，显著提升了罕见脑部畸形（如CCD）的分割性能，并降低了生物标志物估计误差。


<details>
  <summary>Details</summary>
Motivation: CCD（胼胝体发育不良）等罕见病症的标注数据稀缺，限制了深度学习模型的泛化能力，亟需一种无需病理标注的解决方案。

Method: 提出了一种病理信息化的领域随机化策略，通过从健康数据中模拟多样化的脑部变化，生成合成数据，无需病理标注即可实现稳健的分割。

Result: 在248例健康胎儿、26例CCD胎儿和47例其他脑部病理胎儿的队列中验证了方法，显著提升了CCD病例的分割性能，同时保持了其他病例的表现。从预测分割中提取的临床相关生物标志物（如胼胝体长度和体积）能够有效区分CCD亚型。LCC估计误差在健康病例中从1.89 mm降至0.80 mm，在CCD病例中从10.9 mm降至0.7 mm。

Conclusion: 本研究通过将特定领域的解剖学先验知识融入合成数据生成流程，有效缓解了数据稀缺性问题，并提升了对罕见但临床重要畸形的分析能力。

Abstract: Accurate fetal brain segmentation is crucial for extracting biomarkers and
assessing neurodevelopment, especially in conditions such as corpus callosum
dysgenesis (CCD), which can induce drastic anatomical changes. However, the
rarity of CCD severely limits annotated data, hindering the generalization of
deep learning models. To address this, we propose a pathology-informed domain
randomization strategy that embeds prior knowledge of CCD manifestations into a
synthetic data generation pipeline. By simulating diverse brain alterations
from healthy data alone, our approach enables robust segmentation without
requiring pathological annotations.
  We validate our method on a cohort comprising 248 healthy fetuses, 26 with
CCD, and 47 with other brain pathologies, achieving substantial improvements on
CCD cases while maintaining performance on both healthy fetuses and those with
other pathologies. From the predicted segmentations, we derive clinically
relevant biomarkers, such as corpus callosum length (LCC) and volume, and show
their utility in distinguishing CCD subtypes. Our pathology-informed
augmentation reduces the LCC estimation error from 1.89 mm to 0.80 mm in
healthy cases and from 10.9 mm to 0.7 mm in CCD cases. Beyond these
quantitative gains, our approach yields segmentations with improved topological
consistency relative to available ground truth, enabling more reliable
shape-based analyses. Overall, this work demonstrates that incorporating
domain-specific anatomical priors into synthetic data pipelines can effectively
mitigate data scarcity and enhance analysis of rare but clinically significant
malformations.

</details>


### [31] [CogVLA: Cognition-Aligned Vision-Language-Action Model via Instruction-Driven Routing & Sparsification](https://arxiv.org/abs/2508.21046)
*Wei Li,Renshan Zhang,Rui Shao,Jie He,Liqiang Nie*

Main category: cs.CV

TL;DR: CogVLA是一个高效的Vision-Language-Action框架，通过指令驱动路由和稀疏化技术，显著提升性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型需要大量后训练，导致计算开销高，限制了可扩展性和部署。CogVLA旨在通过模仿人类多模态协调，提升效率和性能。

Method: CogVLA采用三阶段渐进式架构：1) EFA-Routing通过指令信息选择性聚合和压缩视觉令牌；2) LFP-Routing通过修剪无关令牌实现令牌级稀疏化；3) CAtten结合因果视觉-语言注意力和双向动作并行解码，确保压缩感知输入仍能支持准确的动作生成。

Result: 在LIBERO基准测试中，CogVLA达到97.4%的成功率，在实际机器人任务中达到70.0%的成功率，同时训练成本降低2.5倍，推理延迟降低2.8倍。

Conclusion: CogVLA通过指令驱动的路由和稀疏化技术，显著提升了Vision-Language-Action模型的效率和性能，同时在LIBERO基准测试和实际机器人任务中达到了最先进的性能。

Abstract: Recent Vision-Language-Action (VLA) models built on pre-trained
Vision-Language Models (VLMs) require extensive post-training, resulting in
high computational overhead that limits scalability and deployment.We propose
CogVLA, a Cognition-Aligned Vision-Language-Action framework that leverages
instruction-driven routing and sparsification to improve both efficiency and
performance. CogVLA draws inspiration from human multimodal coordination and
introduces a 3-stage progressive architecture. 1) Encoder-FiLM based
Aggregation Routing (EFA-Routing) injects instruction information into the
vision encoder to selectively aggregate and compress dual-stream visual tokens,
forming a instruction-aware latent representation. 2) Building upon this
compact visual encoding, LLM-FiLM based Pruning Routing (LFP-Routing)
introduces action intent into the language model by pruning
instruction-irrelevant visually grounded tokens, thereby achieving token-level
sparsity. 3) To ensure that compressed perception inputs can still support
accurate and coherent action generation, we introduce V-L-A Coupled Attention
(CAtten), which combines causal vision-language attention with bidirectional
action parallel decoding. Extensive experiments on the LIBERO benchmark and
real-world robotic tasks demonstrate that CogVLA achieves state-of-the-art
performance with success rates of 97.4% and 70.0%, respectively, while reducing
training costs by 2.5-fold and decreasing inference latency by 2.8-fold
compared to OpenVLA. CogVLA is open-sourced and publicly available at
https://github.com/JiuTian-VL/CogVLA.

</details>


### [32] [Towards Inclusive Communication: A Unified LLM-Based Framework for Sign Language, Lip Movements, and Audio Understanding](https://arxiv.org/abs/2508.20476)
*Jeong Hun Yeo,Hyeongseop Rha,Sungjune Park,Junil Won,Yong Man Ro*

Main category: cs.CV

TL;DR: 论文提出首个统一框架，整合手语、唇部动作和音频，用于生成口语文本，性能优于现有技术，并发现唇部动作对SLT的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统的ASR技术对聋哑或听力障碍人群不友好，现有的视觉替代方案（如手语和唇读）虽然有效，但多模态整合研究不足。

Method: 设计了一个统一的、模态无关的架构，能够有效处理异构输入，并探索了模态间的协同效应，特别是唇部动作作为非手动线索在手语理解中的作用。

Result: 该框架在SLT、VSR、ASR和AVSR任务中表现优异，达到或超越现有技术水平，且明确将唇部动作作为独立模态建模显著提升了SLT性能。

Conclusion: 该论文提出了一个统一框架，能够处理手语、唇部动作和音频等多种输入，用于生成口语文本。该框架不仅在SLT、VSR、ASR和AVSR任务中达到或超越现有技术水平，还揭示了唇部动作作为独立模态对SLT性能的显著提升作用。

Abstract: Audio is the primary modality for human communication and has driven the
success of Automatic Speech Recognition (ASR) technologies. However, such
systems remain inherently inaccessible to individuals who are deaf or hard of
hearing. Visual alternatives such as sign language and lip reading offer
effective substitutes, and recent advances in Sign Language Translation (SLT)
and Visual Speech Recognition (VSR) have improved audio-less communication.
Yet, these modalities have largely been studied in isolation, and their
integration within a unified framework remains underexplored. In this paper, we
introduce the first unified framework capable of handling diverse combinations
of sign language, lip movements, and audio for spoken-language text generation.
We focus on three main objectives: (i) designing a unified, modality-agnostic
architecture capable of effectively processing heterogeneous inputs; (ii)
exploring the underexamined synergy among modalities, particularly the role of
lip movements as non-manual cues in sign language comprehension; and (iii)
achieving performance on par with or superior to state-of-the-art models
specialized for individual tasks. Building on this framework, we achieve
performance on par with or better than task-specific state-of-the-art models
across SLT, VSR, ASR, and AVSR. Furthermore, our analysis reveals that
explicitly modeling lip movements as a separate modality significantly improves
SLT performance.

</details>


### [33] [Video-MTR: Reinforced Multi-Turn Reasoning for Long Video Understanding](https://arxiv.org/abs/2508.20478)
*Yuan Xie,Tianshui Chen,Zheng Ge,Lionel Ni*

Main category: cs.CV

TL;DR: Video-MTR是一个多轮推理框架，通过渐进式视频片段选择和双层奖励系统，显著提升长视频理解性能，无需外部模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态推理或外部视觉语言模型，存在复杂性和性能不佳的问题，缺乏端到端训练。

Method: 提出了Video-MTR框架，采用多轮渐进式视频片段选择和问题理解，结合双层奖励系统（轨迹级和轮级奖励）进行优化。

Result: 在VideoMME、MLVU和EgoSchema等基准测试中，Video-MTR在准确性和效率上均优于现有方法。

Conclusion: Video-MTR通过多轮推理框架和创新的双层奖励系统，显著提升了长视频理解的准确性和效率，无需依赖外部视觉语言模型。

Abstract: Long-form video understanding, characterized by long-range temporal
dependencies and multiple events, remains a challenge. Existing methods often
rely on static reasoning or external visual-language models (VLMs), which face
issues like complexity and sub-optimal performance due to the lack of
end-to-end training. In this paper, we propose Video-MTR, a reinforced
multi-turn reasoning framework designed to enable iterative key video segment
selection and question comprehension. Unlike traditional video reasoning
pipeline, which generate predictions in a single turn, Video-MTR performs
reasoning in multiple turns, selecting video segments progressively based on
the evolving understanding of previously processed segments and the current
question. This iterative process allows for a more refined and contextually
aware analysis of the video. To ensure intermediate reasoning process, we
introduce a novel gated bi-level reward system, combining trajectory-level
rewards based on answer correctness and turn-level rewards emphasizing
frame-query relevance. This system optimizes both video segment selection and
question comprehension, eliminating the need for external VLMs and allowing
end-to-end training. Extensive experiments on benchmarks like VideoMME, MLVU,
and EgoSchema demonstrate that Video-MTR outperforms existing methods in both
accuracy and efficiency, advancing the state-of-the-art in long video
understanding.

</details>


### [34] [Adaptive Dual Uncertainty Optimization: Boosting Monocular 3D Object Detection under Test-Time Shifts](https://arxiv.org/abs/2508.20488)
*Zixuan Hu,Dongxiao Li,Xinzhu Ma,Shixiang Tang,Xiaotong Li,Wenhan Yang,Ling-Yu Duan*

Main category: cs.CV

TL;DR: DUO是首个针对单目3D目标检测的双重不确定性优化的TTA框架，通过凸优化和无监督学习提升鲁棒性，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测在真实世界域偏移下可靠性下降，现有TTA方法未能解决其固有的双重不确定性（语义和几何）。

Method: 提出了Dual Uncertainty Optimization (DUO)框架，通过凸优化视角引入创新的焦点损失结构和无监督版本，设计了语义感知的法向量场约束，形成双分支互补机制。

Result: DUO在多种数据集和域偏移类型中表现出色，优于现有方法。

Conclusion: DUO框架通过联合最小化语义和几何不确定性，显著提升了单目3D目标检测在域偏移下的鲁棒性，实验证明其在多种数据集和域偏移类型中优于现有方法。

Abstract: Accurate monocular 3D object detection (M3OD) is pivotal for safety-critical
applications like autonomous driving, yet its reliability deteriorates
significantly under real-world domain shifts caused by environmental or sensor
variations. To address these shifts, Test-Time Adaptation (TTA) methods have
emerged, enabling models to adapt to target distributions during inference.
While prior TTA approaches recognize the positive correlation between low
uncertainty and high generalization ability, they fail to address the dual
uncertainty inherent to M3OD: semantic uncertainty (ambiguous class
predictions) and geometric uncertainty (unstable spatial localization). To
bridge this gap, we propose Dual Uncertainty Optimization (DUO), the first TTA
framework designed to jointly minimize both uncertainties for robust M3OD.
Through a convex optimization lens, we introduce an innovative convex structure
of the focal loss and further derive a novel unsupervised version, enabling
label-agnostic uncertainty weighting and balanced learning for high-uncertainty
objects. In parallel, we design a semantic-aware normal field constraint that
preserves geometric coherence in regions with clear semantic cues, reducing
uncertainty from the unstable 3D representation. This dual-branch mechanism
forms a complementary loop: enhanced spatial perception improves semantic
classification, and robust semantic predictions further refine spatial
understanding. Extensive experiments demonstrate the superiority of DUO over
existing methods across various datasets and domain shift types.

</details>


### [35] [CaddieSet: A Golf Swing Dataset with Human Joint Features and Ball Information](https://arxiv.org/abs/2508.20491)
*Seunghyeon Jung,Seoyoung Hong,Jiwoo Jeong,Seungwon Jeong,Jaerim Choi,Hoki Kim,Woojin Lee*

Main category: cs.CV

TL;DR: 提出CaddieSet数据集，结合计算机视觉和高尔夫专业知识，量化挥杆姿势与球轨迹的关系，为挥杆分析提供新视角。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能定量建立挥杆姿势与球轨迹之间的关系，限制了为高尔夫球手提供挥杆改进所需洞察的能力。

Method: 通过计算机视觉方法从挥杆视频中提取关节信息，并将其分为八个挥杆阶段，同时基于高尔夫专业知识定义了15个影响挥杆的关键指标。

Result: 实验验证了CaddieSet在预测球轨迹方面的可行性，特别是可解释模型与领域知识的一致性。

Conclusion: 本研究通过提出CaddieSet数据集和15个关键指标，为高尔夫挥杆分析提供了新的视角，验证了关节特征与球轨迹预测的可行性，为学术界和体育产业带来新的见解。

Abstract: Recent advances in deep learning have led to more studies to enhance golfers'
shot precision. However, these existing studies have not quantitatively
established the relationship between swing posture and ball trajectory,
limiting their ability to provide golfers with the necessary insights for swing
improvement. In this paper, we propose a new dataset called CaddieSet, which
includes joint information and various ball information from a single shot.
CaddieSet extracts joint information from a single swing video by segmenting it
into eight swing phases using a computer vision-based approach. Furthermore,
based on expert golf domain knowledge, we define 15 key metrics that influence
a golf swing, enabling the interpretation of swing outcomes through
swing-related features. Through experiments, we demonstrated the feasibility of
CaddieSet for predicting ball trajectories using various benchmarks. In
particular, we focus on interpretable models among several benchmarks and
verify that swing feedback using our joint features is quantitatively
consistent with established domain knowledge. This work is expected to offer
new insight into golf swing analysis for both academia and the sports industry.

</details>


### [36] [IAENet: An Importance-Aware Ensemble Model for 3D Point Cloud-Based Anomaly Detection](https://arxiv.org/abs/2508.20492)
*Xuanming Cao,Chengyu Tao,Yifeng Cheng,Juan Du*

Main category: cs.CV

TL;DR: IAENet通过结合2D和3D专家模型及动态融合策略，显著提升了3D异常检测性能，适用于工业应用。


<details>
  <summary>Details</summary>
Motivation: 3D点云异常检测在工业制造中至关重要，但相比2D图像方法，3D领域缺乏强大的预训练基础骨架，导致性能受限。

Method: 提出了重要性感知集成网络（IAENet），结合2D预训练专家和3D专家模型，并设计了重要性感知融合（IAF）模块动态评估各源贡献及重加权异常分数，同时开发了关键的损失函数优化IAF。

Result: 在MVTec 3D-AD数据集上的实验表明，IAENet实现了新的最先进性能，并显著降低了误报率。

Conclusion: IAENet通过创新的重要性感知融合模块和优化的损失函数，显著提升了3D异常检测的性能，并在MVTec 3D-AD数据集上实现了新的最先进水平，展示了其工业应用的实用价值。

Abstract: Surface anomaly detection is pivotal for ensuring product quality in
industrial manufacturing. While 2D image-based methods have achieved remarkable
success, 3D point cloud-based detection remains underexplored despite its
richer geometric cues. We argue that the key bottleneck is the absence of
powerful pretrained foundation backbones in 3D comparable to those in 2D. To
bridge this gap, we propose Importance-Aware Ensemble Network (IAENet), an
ensemble framework that synergizes 2D pretrained expert with 3D expert models.
However, naively fusing predictions from disparate sources is non-trivial:
existing strategies can be affected by a poorly performing modality and thus
degrade overall accuracy. To address this challenge, We introduce an novel
Importance-Aware Fusion (IAF) module that dynamically assesses the contribution
of each source and reweights their anomaly scores. Furthermore, we devise
critical loss functions that explicitly guide the optimization of IAF, enabling
it to combine the collective knowledge of the source experts but also preserve
their unique strengths, thereby enhancing the overall performance of anomaly
detection. Extensive experiments on MVTec 3D-AD demonstrate that our IAENet
achieves a new state-of-the-art with a markedly lower false positive rate,
underscoring its practical value for industrial deployment.

</details>


### [37] [Describe, Don't Dictate: Semantic Image Editing with Natural Language Intent](https://arxiv.org/abs/2508.20505)
*En Ci,Shanyan Guan,Yanhao Ge,Yilin Zhang,Wei Li,Zhenyu Zhang,Jian Yang,Ying Tai*

Main category: cs.CV

TL;DR: DescriptiveEdit通过重新定义图像编辑任务为基于参考图像的文本到图像生成，克服了现有方法的限制，提高了编辑的准确性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于反转的算法不可避免引入重建误差，而基于指令的模型受限于数据集质量和规模。为了解决这些问题，提出了DescriptiveEdit框架。

Method: 提出DescriptiveEdit框架，核心思想是将基于指令的图像编辑重新定义为基于参考图像的文本到图像生成。通过引入Cross-Attentive UNet，新增注意力桥接机制，将参考图像特征注入到提示到编辑图像的生成过程中。

Result: 在Emu Edit基准测试中，DescriptiveEdit提高了编辑的准确性和一致性。

Conclusion: DescriptiveEdit通过重新定义图像编辑任务为基于参考图像的文本到图像生成，有效利用了现有文本到图像模型的生成能力，无需架构修改或反转，从而克服了指令数据集质量的限制，并与ControlNet、IP-Adapter等扩展无缝集成，展现出更高的可扩展性和编辑准确性。

Abstract: Despite the progress in text-to-image generation, semantic image editing
remains a challenge. Inversion-based algorithms unavoidably introduce
reconstruction errors, while instruction-based models mainly suffer from
limited dataset quality and scale. To address these problems, we propose a
descriptive-prompt-based editing framework, named DescriptiveEdit. The core
idea is to re-frame `instruction-based image editing' as `reference-image-based
text-to-image generation', which preserves the generative power of well-trained
Text-to-Image models without architectural modifications or inversion.
Specifically, taking the reference image and a prompt as input, we introduce a
Cross-Attentive UNet, which newly adds attention bridges to inject reference
image features into the prompt-to-edit-image generation process. Owing to its
text-to-image nature, DescriptiveEdit overcomes limitations in instruction
dataset quality, integrates seamlessly with ControlNet, IP-Adapter, and other
extensions, and is more scalable. Experiments on the Emu Edit benchmark show it
improves editing accuracy and consistency.

</details>


### [38] [DCFS: Continual Test-Time Adaptation via Dual Consistency of Feature and Sample](https://arxiv.org/abs/2508.20516)
*Wenting Yin,Han Sun,Xinru Meng,Ningzhong Liu,Huiyu Zhou*

Main category: cs.CV

TL;DR: DCFS框架通过双路径特征一致性和置信感知样本学习，解决了持续测试时适应中的伪标签质量和错误累积问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 持续测试时适应中，仅依赖目标数据特征易导致混淆和学习偏差，现有方法生成的伪标签质量不可靠且存在错误累积问题。

Method: 提出DCFS框架，采用双分类器分离目标数据的语义相关特征和域相关特征，并通过特征一致性和自适应阈值加权损失进行自监督学习。

Result: 在CIFAR10-C、CIFAR100-C和ImageNet-C等数据集上的实验表明，DCFS在持续测试时适应场景中表现一致优越。

Conclusion: DCFS框架通过双路径特征一致性和置信感知样本学习，有效解决了持续测试时适应中的伪标签质量问题和错误累积问题，在多个数据集上验证了其优越性能。

Abstract: Continual test-time adaptation aims to continuously adapt a pre-trained model
to a stream of target domain data without accessing source data. Without access
to source domain data, the model focuses solely on the feature characteristics
of the target data. Relying exclusively on these features can lead to confusion
and introduce learning biases. Currently, many existing methods generate
pseudo-labels via model predictions. However, the quality of pseudo-labels
cannot be guaranteed and the problem of error accumulation must be solved. To
address these challenges, we propose DCFS, a novel CTTA framework that
introduces dual-path feature consistency and confidence-aware sample learning.
This framework disentangles the whole feature representation of the target data
into semantic-related feature and domain-related feature using dual classifiers
to learn distinct feature representations. By maintaining consistency between
the sub-features and the whole feature, the model can comprehensively capture
data features from multiple perspectives. Additionally, to ensure that the
whole feature information of the target domain samples is not overlooked, we
set a adaptive threshold and calculate a confidence score for each sample to
carry out loss weighted self-supervised learning, effectively reducing the
noise of pseudo-labels and alleviating the problem of error accumulation. The
efficacy of our proposed method is validated through extensive experimentation
across various datasets, including CIFAR10-C, CIFAR100-C, and ImageNet-C,
demonstrating consistent performance in continual test-time adaptation
scenarios.

</details>


### [39] [Adam SLAM - the last mile of camera calibration with 3DGS](https://arxiv.org/abs/2508.20526)
*Matthieu Gendrin,Stéphane Pateux,Xiaoran Jiang,Théo Ladune,Luce Morin*

Main category: cs.CV

TL;DR: 通过3DGS模型反向传播优化相机参数，提升新视角合成质量，平均PSNR提升0.4 dB。


<details>
  <summary>Details</summary>
Motivation: 相机校准质量对新视角合成评估至关重要，但真实场景缺乏地面真实值，因此需要通过合成质量间接评估校准效果。

Method: 提出利用3DGS模型，通过反向传播新视角颜色损失来微调相机参数。

Result: 新校准方法在3DGS参考数据集上平均提升了0.4 dB PSNR。

Conclusion: 使用3DGS模型通过反向传播优化相机校准参数，显著提升了新视角合成的质量，特别是在参考场景如Mip-NeRF 360中效果显著。

Abstract: The quality of the camera calibration is of major importance for evaluating
progresses in novel view synthesis, as a 1-pixel error on the calibration has a
significant impact on the reconstruction quality. While there is no ground
truth for real scenes, the quality of the calibration is assessed by the
quality of the novel view synthesis. This paper proposes to use a 3DGS model to
fine tune calibration by backpropagation of novel view color loss with respect
to the cameras parameters. The new calibration alone brings an average
improvement of 0.4 dB PSNR on the dataset used as reference by 3DGS. The fine
tuning may be long and its suitability depends on the criticity of training
time, but for calibration of reference scenes, such as Mip-NeRF 360, the stake
of novel view quality is the most important.

</details>


### [40] [Learning What is Worth Learning: Active and Sequential Domain Adaptation for Multi-modal Gross Tumor Volume Segmentation](https://arxiv.org/abs/2508.20528)
*Jingyun Yang,Guoqing Zhang,Jingge Wang,Yang Li*

Main category: cs.CV

TL;DR: 提出了一种动态多模态样本选择的主动域适应框架，显著提升肿瘤分割性能。


<details>
  <summary>Details</summary>
Motivation: 由于标记医学图像耗时且劳动密集，主动学习成为减少标注成本的解决方案，但现有方法存在样本冗余和负迁移问题。

Method: 提出了一种基于信息量和代表性的查询策略，优先标记和训练最有价值的样本。

Result: 在多种肿瘤体积分割任务上的实证验证显示，该方法取得了优越的分割性能。

Conclusion: 提出的主动和顺序域适应框架在动态多模态样本选择中表现出色，显著优于现有ADA方法。

Abstract: Accurate gross tumor volume segmentation on multi-modal medical data is
critical for radiotherapy planning in nasopharyngeal carcinoma and
glioblastoma. Recent advances in deep neural networks have brought promising
results in medical image segmentation, leading to an increasing demand for
labeled data. Since labeling medical images is time-consuming and
labor-intensive, active learning has emerged as a solution to reduce annotation
costs by selecting the most informative samples to label and adapting
high-performance models with as few labeled samples as possible. Previous
active domain adaptation (ADA) methods seek to minimize sample redundancy by
selecting samples that are farthest from the source domain. However, such
one-off selection can easily cause negative transfer, and access to source
medical data is often limited. Moreover, the query strategy for multi-modal
medical data remains unexplored. In this work, we propose an active and
sequential domain adaptation framework for dynamic multi-modal sample selection
in ADA. We derive a query strategy to prioritize labeling and training on the
most valuable samples based on their informativeness and representativeness.
Empirical validation on diverse gross tumor volume segmentation tasks
demonstrates that our method achieves favorable segmentation performance,
significantly outperforming state-of-the-art ADA methods. Code is available at
the git repository: \href{https://github.com/Hiyoochan/mmActS}{mmActS}.

</details>


### [41] [Enhancing Pseudo-Boxes via Data-Level LiDAR-Camera Fusion for Unsupervised 3D Object Detection](https://arxiv.org/abs/2508.20530)
*Mingqian Ji,Jian Yang,Shanshan Zhang*

Main category: cs.CV

TL;DR: 提出数据级融合框架，整合LiDAR和RGB图像，提升伪框质量，实验显示mAP达28.4%。


<details>
  <summary>Details</summary>
Motivation: 解决现有LiDAR和RGB图像标签级融合策略在伪框生成中互补性不足的问题，以及高质量3D标注耗时费力的问题。

Method: 利用视觉基础模型进行实例分割和深度估计，引入双向融合方法，将2D像素投影到3D空间以增强点密度，并提出局部和全局滤波方法以减少噪声。此外，还提出了一种基于数据级融合的动态自进化策略。

Result: 在nuScenes验证集上，mAP达到28.4%，显著优于现有最先进方法。

Conclusion: 提出了一种新颖的数据级融合框架，通过早期整合RGB图像和LiDAR数据，显著提升了伪框的质量和定位精度。在nuScenes数据集上的实验表明，该方法训练的检测器性能优于现有最先进方法，mAP达到28.4%。

Abstract: Existing LiDAR-based 3D object detectors typically rely on manually annotated
labels for training to achieve good performance. However, obtaining
high-quality 3D labels is time-consuming and labor-intensive. To address this
issue, recent works explore unsupervised 3D object detection by introducing RGB
images as an auxiliary modal to assist pseudo-box generation. However, these
methods simply integrate pseudo-boxes generated by LiDAR point clouds and RGB
images. Yet, such a label-level fusion strategy brings limited improvements to
the quality of pseudo-boxes, as it overlooks the complementary nature in terms
of LiDAR and RGB image data. To overcome the above limitations, we propose a
novel data-level fusion framework that integrates RGB images and LiDAR data at
an early stage. Specifically, we utilize vision foundation models for instance
segmentation and depth estimation on images and introduce a bi-directional
fusion method, where real points acquire category labels from the 2D space,
while 2D pixels are projected onto 3D to enhance real point density. To
mitigate noise from depth and segmentation estimations, we propose a local and
global filtering method, which applies local radius filtering to suppress depth
estimation errors and global statistical filtering to remove
segmentation-induced outliers. Furthermore, we propose a data-level fusion
based dynamic self-evolution strategy, which iteratively refines pseudo-boxes
under a dense representation, significantly improving localization accuracy.
Extensive experiments on the nuScenes dataset demonstrate that the detector
trained by our method significantly outperforms that trained by previous
state-of-the-art methods with 28.4$\%$ mAP on the nuScenes validation
benchmark.

</details>


### [42] [Digital Scale: Open-Source On-Device BMI Estimation from Smartphone Camera Images Trained on a Large-Scale Real-World Dataset](https://arxiv.org/abs/2508.20534)
*Frederik Rajiv Manichand,Robin Deuber,Robert Jakob,Steve Swerling,Jamie Rosen,Elgar Fleisch,Patrick Langer*

Main category: cs.CV

TL;DR: 提出一种基于深度学习的BMI估计方法，通过自动过滤优化数据集，在多个测试集上达到最佳精度，并实现移动端部署。


<details>
  <summary>Details</summary>
Motivation: 在传统方法不可行或不切实际的场景（如远程医疗或紧急情况）下，通过相机图像快速评估BMI。

Method: 使用深度学习方法，结合WayBED数据集（84,963张智能手机图像），通过自动过滤（姿态聚类和人物检测）筛选高质量图像（71,322张）进行训练。

Result: 在WayBED测试集上达到7.9%的MAPE（最低值），在未训练过的VisualBodyToBMI数据集上达到13%的MAPE，经过微调后进一步降至8.56%。

Conclusion: 本研究提出了一种基于深度学习的BMI估计方法，通过自动过滤和姿态聚类优化数据集，显著提高了估计精度，并在移动设备上实现了部署。

Abstract: Estimating Body Mass Index (BMI) from camera images with machine learning
models enables rapid weight assessment when traditional methods are unavailable
or impractical, such as in telehealth or emergency scenarios. Existing computer
vision approaches have been limited to datasets of up to 14,500 images. In this
study, we present a deep learning-based BMI estimation method trained on our
WayBED dataset, a large proprietary collection of 84,963 smartphone images from
25,353 individuals. We introduce an automatic filtering method that uses
posture clustering and person detection to curate the dataset by removing
low-quality images, such as those with atypical postures or incomplete views.
This process retained 71,322 high-quality images suitable for training. We
achieve a Mean Absolute Percentage Error (MAPE) of 7.9% on our hold-out test
set (WayBED data) using full-body images, the lowest value in the published
literature to the best of our knowledge. Further, we achieve a MAPE of 13% on
the completely unseen~(during training) VisualBodyToBMI dataset, comparable
with state-of-the-art approaches trained on it, demonstrating robust
generalization. Lastly, we fine-tune our model on VisualBodyToBMI and achieve a
MAPE of 8.56%, the lowest reported value on this dataset so far. We deploy the
full pipeline, including image filtering and BMI estimation, on Android devices
using the CLAID framework. We release our complete code for model training,
filtering, and the CLAID package for mobile deployment as open-source
contributions.

</details>


### [43] [Towards Mechanistic Defenses Against Typographic Attacks in CLIP](https://arxiv.org/abs/2508.20570)
*Lorenz Hufe,Constantin Venhoff,Maximilian Dreyer,Sebastian Lapuschkin,Wojciech Samek*

Main category: cs.CV

TL;DR: 研究发现CLIP模型中特定注意力头负责处理排版信息，提出选择性消融这些头的防御方法，显著提升抗攻击能力且几乎不影响标准性能。


<details>
  <summary>Details</summary>
Motivation: 排版攻击通过向图像中注入文本来误导多模态系统，导致目标错误分类和恶意内容生成，甚至可能突破视觉-语言模型的安全限制。

Method: 分析了CLIP视觉编码器在排版攻击下的行为，定位了负责提取和传输排版信息的注意力头，并提出了选择性消融这些注意力头的方法。

Result: 该方法在排版攻击版本的ImageNet-100上提升了19.6%的性能，同时标准ImageNet-100的准确率下降不到1%。

Conclusion: 本研究提出了一种无需微调的方法，通过选择性消融注意力头来增强CLIP模型对排版攻击的防御能力，同时保持了标准任务的高准确率。

Abstract: Typographic attacks exploit multi-modal systems by injecting text into
images, leading to targeted misclassifications, malicious content generation
and even Vision-Language Model jailbreaks. In this work, we analyze how CLIP
vision encoders behave under typographic attacks, locating specialized
attention heads in the latter half of the model's layers that causally extract
and transmit typographic information to the cls token. Building on these
insights, we introduce a method to defend CLIP models against typographic
attacks by selectively ablating a typographic circuit, consisting of attention
heads. Without requiring finetuning, our method improves performance by up to
19.6% on a typographic variant of ImageNet-100, while reducing standard
ImageNet-100 accuracy by less than 1%. Notably, our training-free approach
remains competitive with current state-of-the-art typographic defenses that
rely on finetuning. To this end, we release a family of dyslexic CLIP models
which are significantly more robust against typographic attacks. These models
serve as suitable drop-in replacements for a broad range of safety-critical
applications, where the risks of text-based manipulation outweigh the utility
of text recognition.

</details>


### [44] [Domain Adaptation Techniques for Natural and Medical Image Classification](https://arxiv.org/abs/2508.20537)
*Ahmad Chaddad,Yihang Wu,Reem Kateb,Christian Desrosiers*

Main category: cs.CV

TL;DR: 研究通过大量实验验证了DSAN算法在医学图像分类中的卓越表现，特别是在COVID-19数据集中，展示了DA技术的实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 探讨DA技术在自然图像和医学图像中的应用优势，解决主流数据集可能导致的性能偏差问题。

Method: 本研究通过557项模拟研究，使用7种广泛应用的DA技术，在5个自然图像和8个医学数据集上进行图像分类。

Result: DSAN算法在COVID-19数据集中实现了91.2%的分类准确率，在动态数据流DA场景中比基线提高了6.7%。

Conclusion: DSAN算法在COVID-19和皮肤癌数据集上表现出卓越的可解释性，为理解DA技术在医学数据上的有效应用提供了宝贵见解。

Abstract: Domain adaptation (DA) techniques have the potential in machine learning to
alleviate distribution differences between training and test sets by leveraging
information from source domains. In image classification, most advances in DA
have been made using natural images rather than medical data, which are harder
to work with. Moreover, even for natural images, the use of mainstream datasets
can lead to performance bias. {With the aim of better understanding the
benefits of DA for both natural and medical images, this study performs 557
simulation studies using seven widely-used DA techniques for image
classification in five natural and eight medical datasets that cover various
scenarios, such as out-of-distribution, dynamic data streams, and limited
training samples.} Our experiments yield detailed results and insightful
observations highlighting the performance and medical applicability of these
techniques. Notably, our results have shown the outstanding performance of the
Deep Subdomain Adaptation Network (DSAN) algorithm. This algorithm achieved
feasible classification accuracy (91.2\%) in the COVID-19 dataset using
Resnet50 and showed an important accuracy improvement in the dynamic data
stream DA scenario (+6.7\%) compared to the baseline. Our results also
demonstrate that DSAN exhibits remarkable level of explainability when
evaluated on COVID-19 and skin cancer datasets. These results contribute to the
understanding of DA techniques and offer valuable insight into the effective
adaptation of models to medical data.

</details>


### [45] [ArtFace: Towards Historical Portrait Face Identification via Model Adaptation](https://arxiv.org/abs/2508.20626)
*Francois Poh,Anjith George,Sébastien Marcel*

Main category: cs.CV

TL;DR: 研究利用基础模型提升艺术品面部识别效果，通过微调和嵌入结合，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 艺术品中的人物识别对艺术史学家至关重要，但传统面部识别模型因领域偏移和高类内差异在绘画中表现不佳。

Method: 通过微调基础模型并将其嵌入与传统面部识别网络的嵌入相结合。

Result: 实验结果表明，结合基础模型的方法在当前最先进方法基础上取得了显著改进。

Conclusion: 基础模型能够有效弥补传统面部识别方法在艺术品识别中的不足，显著提升识别效果。

Abstract: Identifying sitters in historical paintings is a key task for art historians,
offering insight into their lives and how they chose to be seen. However, the
process is often subjective and limited by the lack of data and stylistic
variations. Automated facial recognition is capable of handling challenging
conditions and can assist, but while traditional facial recognition models
perform well on photographs, they struggle with paintings due to domain shift
and high intra-class variation. Artistic factors such as style, skill, intent,
and influence from other works further complicate recognition. In this work, we
investigate the potential of foundation models to improve facial recognition in
artworks. By fine-tuning foundation models and integrating their embeddings
with those from conventional facial recognition networks, we demonstrate
notable improvements over current state-of-the-art methods. Our results show
that foundation models can bridge the gap where traditional methods are
ineffective. Paper page at https://www.idiap.ch/paper/artface/

</details>


### [46] [Contrastive Learning through Auxiliary Branch for Video Object Detection](https://arxiv.org/abs/2508.20551)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: CLAB通过对比学习和动态损失加权提升视频目标检测性能，达到SOTA水平且不增加计算负担。


<details>
  <summary>Details</summary>
Motivation: 视频目标检测面临图像退化（如运动模糊、遮挡和变形）的挑战，现有方法虽能提升性能但计算成本高。

Method: 采用对比学习辅助分支（CLAB）和动态损失加权策略，增强视频目标检测器骨干网络的特征表示能力。

Result: 在ImageNet VID数据集上，CLAB使用ResNet-101和ResNeXt-101分别达到84.0%和85.2%的mAP，无需额外后处理。

Conclusion: CLAB方法通过对比学习和动态损失加权策略，在不增加推理计算负担的情况下，显著提升了视频目标检测的性能，达到了基于CNN模型的最先进水平。

Abstract: Video object detection is a challenging task because videos often suffer from
image deterioration such as motion blur, occlusion, and deformable shapes,
making it significantly more difficult than detecting objects in still images.
Prior approaches have improved video object detection performance by employing
feature aggregation and complex post-processing techniques, though at the cost
of increased computational demands. To improve robustness to image degradation
without additional computational load during inference, we introduce a
straightforward yet effective Contrastive Learning through Auxiliary Branch
(CLAB) method. First, we implement a constrastive auxiliary branch using a
contrastive loss to enhance the feature representation capability of the video
object detector's backbone. Next, we propose a dynamic loss weighting strategy
that emphasizes auxiliary feature learning early in training while gradually
prioritizing the detection task as training converges. We validate our approach
through comprehensive experiments and ablation studies, demonstrating
consistent performance gains. Without bells and whistles, CLAB reaches a
performance of 84.0% mAP and 85.2% mAP with ResNet-101 and ResNeXt-101,
respectively, on the ImageNet VID dataset, thus achieving state-of-the-art
performance for CNN-based models without requiring additional post-processing
methods.

</details>


### [47] [GLaRE: A Graph-based Landmark Region Embedding Network for Emotion Recognition](https://arxiv.org/abs/2508.20579)
*Debasis Maji,Debaditya Barman*

Main category: cs.CV

TL;DR: GLaRE是一种基于图的面部标志区域嵌入网络，通过3D对齐和分层粗化提升情感识别性能，在AffectNet和FERG数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统面部表情识别系统因遮挡、表情变异和缺乏可解释性而性能受限，图神经网络（GNNs）通过建模面部标志间的关系依赖性提供了结构化且可解释的学习方案。

Method: 使用3D面部对齐提取面部标志，并通过分层粗化构建商图以保留空间结构同时降低复杂度。

Result: 在AffectNet上达到64.89%的准确率，在FERG上达到94.24%的准确率，优于现有基线。区域级嵌入通过商图显著提升了预测性能。

Conclusion: GLaRE网络通过基于图的标志区域嵌入方法，在情感识别任务中表现出色，显著提升了预测性能。

Abstract: Facial expression recognition (FER) is a crucial task in computer vision with
wide range of applications including human computer interaction, surveillance,
and assistive technologies. However, challenges such as occlusion, expression
variability, and lack of interpretability hinder the performance of traditional
FER systems. Graph Neural Networks (GNNs) offer a powerful alternative by
modeling relational dependencies between facial landmarks, enabling structured
and interpretable learning. In this paper, we propose GLaRE, a novel
Graph-based Landmark Region Embedding network for emotion recognition. Facial
landmarks are extracted using 3D facial alignment, and a quotient graph is
constructed via hierarchical coarsening to preserve spatial structure while
reducing complexity. Our method achieves 64.89 percentage accuracy on AffectNet
and 94.24 percentage on FERG, outperforming several existing baselines.
Additionally, ablation studies have demonstrated that region-level embeddings
from quotient graphs have contributed to improved prediction performance.

</details>


### [48] [MobileCLIP2: Improving Multi-Modal Reinforced Training](https://arxiv.org/abs/2508.20691)
*Fartash Faghri,Pavan Kumar Anasosalu Vasu,Cem Koc,Vaishaal Shankar,Alexander Toshev,Oncel Tuzel,Hadi Pouransari*

Main category: cs.CV

TL;DR: MobileCLIP2通过改进的多模态强化训练，在低延迟下实现了更高的零样本准确率，并发布了模型和代码。


<details>
  <summary>Details</summary>
Motivation: 提升MobileCLIP的多模态强化训练效果，以在低延迟下实现更高的零样本准确率。

Method: 改进的多模态强化训练，包括更好的CLIP教师集成和优化的captioner教师，以及温度调优和结合多个模型的合成caption。

Result: MobileCLIP2在ImageNet-1k上的零样本准确率提升了2.2%（MobileCLIP2-B vs. MobileCLIP-B），并在低延迟下匹配或超越其他模型的性能。

Conclusion: MobileCLIP2通过改进的多模态强化训练，在低延迟下实现了最先进的ImageNet-1k零样本准确率，并发布了预训练模型和数据生成代码。

Abstract: Foundation image-text models such as CLIP with zero-shot capabilities enable
a wide array of applications. MobileCLIP is a recent family of image-text
models at 3-15ms latency and 50-150M parameters with state-of-the-art zero-shot
accuracy. The main ingredients in MobileCLIP were its low-latency and light
architectures and a novel multi-modal reinforced training that made knowledge
distillation from multiple caption-generators and CLIP teachers efficient,
scalable, and reproducible. In this paper, we improve the multi-modal
reinforced training of MobileCLIP through: 1) better CLIP teacher ensembles
trained on the DFN dataset, 2) improved captioner teachers trained on the DFN
dataset and fine-tuned on a diverse selection of high-quality image-caption
datasets. We discover new insights through ablations such as the importance of
temperature tuning in contrastive knowledge distillation, the effectiveness of
caption-generator fine-tuning for caption diversity, and the additive
improvement from combining synthetic captions generated by multiple models. We
train a new family of models called MobileCLIP2 and achieve state-of-the-art
ImageNet-1k zero-shot accuracies at low latencies. In particular, we observe
2.2% improvement in ImageNet-1k accuracy for MobileCLIP2-B compared with
MobileCLIP-B architecture. Notably, MobileCLIP2-S4 matches the zero-shot
accuracy of SigLIP-SO400M/14 on ImageNet-1k while being 2$\times$ smaller and
improves on DFN ViT-L/14 at 2.5$\times$ lower latency. We release our
pretrained models (https://github.com/apple/ml-mobileclip) and the data
generation code (https://github.com/apple/ml-mobileclip-dr). The data
generation code makes it easy to create new reinforced datasets with arbitrary
teachers using distributed scalable processing.

</details>


### [49] [FastFit: Accelerating Multi-Reference Virtual Try-On via Cacheable Diffusion Models](https://arxiv.org/abs/2508.20586)
*Zheng Chong,Yanwei Lei,Shiyue Zhang,Zhuandi He,Zhen Wang,Xujie Zhang,Xiao Dong,Yiling Wu,Dongmei Jiang,Xiaodan Liang*

Main category: cs.CV

TL;DR: FastFit是一种高效多参考虚拟试穿框架，通过创新架构解决了现有技术的效率和多参考问题，速度提升3.5倍。


<details>
  <summary>Details</summary>
Motivation: 当前虚拟试穿技术在多参考组合和效率方面存在不足，限制了其实际应用。

Method: 采用Semi-Attention机制和类嵌入替代传统时间步嵌入，完全解耦参考特征编码与去噪过程，实现特征一次性计算和复用。

Result: FastFit实现了平均3.5倍的速度提升，并在VITON-HD、DressCode和DressCode-MR数据集上超越了现有方法。

Conclusion: FastFit通过创新的可缓存扩散架构解决了虚拟试穿技术中的多参考组合和效率问题，显著提升了速度，并在多个数据集上验证了其优越性。

Abstract: Despite its great potential, virtual try-on technology is hindered from
real-world application by two major challenges: the inability of current
methods to support multi-reference outfit compositions (including garments and
accessories), and their significant inefficiency caused by the redundant
re-computation of reference features in each denoising step. To address these
challenges, we propose FastFit, a high-speed multi-reference virtual try-on
framework based on a novel cacheable diffusion architecture. By employing a
Semi-Attention mechanism and substituting traditional timestep embeddings with
class embeddings for reference items, our model fully decouples reference
feature encoding from the denoising process with negligible parameter overhead.
This allows reference features to be computed only once and losslessly reused
across all steps, fundamentally breaking the efficiency bottleneck and
achieving an average 3.5x speedup over comparable methods. Furthermore, to
facilitate research on complex, multi-reference virtual try-on, we introduce
DressCode-MR, a new large-scale dataset. It comprises 28,179 sets of
high-quality, paired images covering five key categories (tops, bottoms,
dresses, shoes, and bags), constructed through a pipeline of expert models and
human feedback refinement. Extensive experiments on the VITON-HD, DressCode,
and our DressCode-MR datasets show that FastFit surpasses state-of-the-art
methods on key fidelity metrics while offering its significant advantage in
inference efficiency.

</details>


### [50] [UTA-Sign: Unsupervised Thermal Video Augmentation via Event-Assisted Traffic Signage Sketching](https://arxiv.org/abs/2508.20594)
*Yuqi Han,Songqian Zhang,Weijian Su,Ke Li,Jiayu Yang,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: 论文提出UTA-Sign方法，通过融合热成像和事件相机信号，提升低光照环境下交通标志的识别准确性和环境理解。


<details>
  <summary>Details</summary>
Motivation: 热成像相机在低光环境下表现优异，但在识别相似材料物体标志时存在盲点，而事件相机在高速、低光交通环境中表现良好，两者的互补特性为解决交通标志识别问题提供了可能。

Method: 论文提出了一种双增强机制，结合热成像帧和事件信号，利用热成像提供精确的运动线索作为时间参考，同时事件信号补充标志的细微内容。

Result: 在真实场景数据集上的验证表明，该方法在交通标志草图和感知层面的检测准确性上表现优越。

Conclusion: 该论文提出的UTA-Sign方法通过融合热成像和事件相机信号，有效解决了低光照环境下交通标志识别的盲点问题，提升了检测准确性和环境理解能力。

Abstract: The thermal camera excels at perceiving outdoor environments under low-light
conditions, making it ideal for applications such as nighttime autonomous
driving and unmanned navigation. However, thermal cameras encounter challenges
when capturing signage from objects made of similar materials, which can pose
safety risks for accurately understanding semantics in autonomous driving
systems. In contrast, the neuromorphic vision camera, also known as an event
camera, detects changes in light intensity asynchronously and has proven
effective in high-speed, low-light traffic environments. Recognizing the
complementary characteristics of these two modalities, this paper proposes
UTA-Sign, an unsupervised thermal-event video augmentation for traffic signage
in low-illumination environments, targeting elements such as license plates and
roadblock indicators. To address the signage blind spots of thermal imaging and
the non-uniform sampling of event cameras, we developed a dual-boosting
mechanism that fuses thermal frames and event signals for consistent signage
representation over time. The proposed method utilizes thermal frames to
provide accurate motion cues as temporal references for aligning the uneven
event signals. At the same time, event signals contribute subtle signage
content to the raw thermal frames, enhancing the overall understanding of the
environment. The proposed method is validated on datasets collected from
real-world scenarios, demonstrating superior quality in traffic signage
sketching and improved detection accuracy at the perceptual level.

</details>


### [51] [${C}^{3}$-GS: Learning Context-aware, Cross-dimension, Cross-scale Feature for Generalizable Gaussian Splatting](https://arxiv.org/abs/2508.20754)
*Yuxi Hu,Jun Zhang,Kuangyi Chen,Zhe Zhang,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: $\mathbf{C}^{3}$-GS是一种无需每场景优化的新视图合成框架，通过上下文感知、跨维度和跨尺度约束提升特征学习，实现了高质量的渲染和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在编码具有多视图一致性的判别特征用于高斯预测方面存在不足，尤其是在稀疏视图下难以构建准确的几何结构。

Method: 该框架在统一的渲染管线中集成了三个轻量级模块，通过上下文感知、跨维度和跨尺度约束增强特征学习，从而提升特征融合能力。

Result: 在基准数据集上的广泛实验表明，$\mathbf{C}^{3}$-GS在渲染质量和泛化能力方面达到了最先进的水平。

Conclusion: $\mathbf{C}^{3}$-GS框架通过引入上下文感知、跨维度和跨尺度约束，显著提升了特征学习能力，实现了无需额外监督的光照真实合成，并在基准数据集上验证了其渲染质量和泛化能力的先进性。

Abstract: Generalizable Gaussian Splatting aims to synthesize novel views for unseen
scenes without per-scene optimization. In particular, recent advancements
utilize feed-forward networks to predict per-pixel Gaussian parameters,
enabling high-quality synthesis from sparse input views. However, existing
approaches fall short in encoding discriminative, multi-view consistent
features for Gaussian predictions, which struggle to construct accurate
geometry with sparse views. To address this, we propose $\mathbf{C}^{3}$-GS, a
framework that enhances feature learning by incorporating context-aware,
cross-dimension, and cross-scale constraints. Our architecture integrates three
lightweight modules into a unified rendering pipeline, improving feature fusion
and enabling photorealistic synthesis without requiring additional supervision.
Extensive experiments on benchmark datasets validate that $\mathbf{C}^{3}$-GS
achieves state-of-the-art rendering quality and generalization ability. Code is
available at: https://github.com/YuhsiHu/C3-GS.

</details>


### [52] [Disruptive Attacks on Face Swapping via Low-Frequency Perceptual Perturbations](https://arxiv.org/abs/2508.20595)
*Mengxiao Huang,Minglei Shu,Shuwang Zhou,Zhaoyang Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于低频扰动的主动防御方法，直接干扰Deepfake生成过程，实验证明其有效且视觉质量良好。


<details>
  <summary>Details</summary>
Motivation: 现有Deepfake检测方法多为被动式，无法预防攻击。本文旨在通过主动防御手段直接干扰生成过程。

Method: 结合频域和空间域特征，设计了包含编码器、扰动生成器和解码器的完整架构，利用离散小波变换（DWT）提取低频成分并生成扰动。

Result: 在CelebA-HQ和LFW数据集上的实验表明，该方法显著降低了面部替换的有效性，提高了防御成功率，并保持了视觉质量。

Conclusion: 本文提出了一种基于低频感知扰动的主动防御方法，有效降低了Deepfake技术的面部替换效果，同时保持了视觉质量。

Abstract: Deepfake technology, driven by Generative Adversarial Networks (GANs), poses
significant risks to privacy and societal security. Existing detection methods
are predominantly passive, focusing on post-event analysis without preventing
attacks. To address this, we propose an active defense method based on
low-frequency perceptual perturbations to disrupt face swapping manipulation,
reducing the performance and naturalness of generated content. Unlike prior
approaches that used low-frequency perturbations to impact classification
accuracy,our method directly targets the generative process of deepfake
techniques. We combine frequency and spatial domain features to strengthen
defenses. By introducing artifacts through low-frequency perturbations while
preserving high-frequency details, we ensure the output remains visually
plausible. Additionally, we design a complete architecture featuring an
encoder, a perturbation generator, and a decoder, leveraging discrete wavelet
transform (DWT) to extract low-frequency components and generate perturbations
that disrupt facial manipulation models. Experiments on CelebA-HQ and LFW
demonstrate significant reductions in face-swapping effectiveness, improved
defense success rates, and preservation of visual quality.

</details>


### [53] [SeqVLM: Proposal-Guided Multi-View Sequences Reasoning via VLM for Zero-Shot 3D Visual Grounding](https://arxiv.org/abs/2508.20758)
*Jiawen Lin,Shiran Bian,Yihang Zhu,Wenbin Tan,Yachao Zhang,Yuan Xie,Yanyun Qu*

Main category: cs.CV

TL;DR: SeqVLM 是一种零样本 3DVG 框架，通过多视图图像和空间信息解决现有方法的局限性，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本 3DVG 方法因依赖单视图定位而面临空间限制推理的挑战，同时存在上下文遗漏或细节退化的问题。SeqVLM 旨在通过多视图真实场景图像与空间信息来解决这些问题，提升目标对象推理能力。

Method: SeqVLM 首先通过 3D 语义分割网络生成 3D 实例提议，并通过语义过滤进行细化，保留语义相关的候选。然后采用提议引导的多视图投影策略，将这些候选提议投影到真实场景图像序列中，保留空间关系和上下文细节。此外，通过动态调度机制迭代处理序列查询提示，利用 VLM 的跨模态推理能力识别文本指定的对象。

Result: 在 ScanRefer 和 Nr3D 基准测试中，SeqVLM 的 Acc@0.25 分数分别为 55.6% 和 53.2%，比之前的零样本方法提升了 4.0% 和 5.2%。

Conclusion: SeqVLM 在 ScanRefer 和 Nr3D 基准测试中表现出色，Acc@0.25 分数分别达到 55.6% 和 53.2%，比之前的零样本方法提升了 4.0% 和 5.2%，推动了 3DVG 向更高泛化性和实际应用迈进。

Abstract: 3D Visual Grounding (3DVG) aims to localize objects in 3D scenes using
natural language descriptions. Although supervised methods achieve higher
accuracy in constrained settings, zero-shot 3DVG holds greater promise for
real-world applications since eliminating scene-specific training requirements.
However, existing zero-shot methods face challenges of spatial-limited
reasoning due to reliance on single-view localization, and contextual omissions
or detail degradation. To address these issues, we propose SeqVLM, a novel
zero-shot 3DVG framework that leverages multi-view real-world scene images with
spatial information for target object reasoning. Specifically, SeqVLM first
generates 3D instance proposals via a 3D semantic segmentation network and
refines them through semantic filtering, retaining only semantic-relevant
candidates. A proposal-guided multi-view projection strategy then projects
these candidate proposals onto real scene image sequences, preserving spatial
relationships and contextual details in the conversion process of 3D point
cloud to images. Furthermore, to mitigate VLM computational overload, we
implement a dynamic scheduling mechanism that iteratively processes
sequances-query prompts, leveraging VLM's cross-modal reasoning capabilities to
identify textually specified objects. Experiments on the ScanRefer and Nr3D
benchmarks demonstrate state-of-the-art performance, achieving Acc@0.25 scores
of 55.6% and 53.2%, surpassing previous zero-shot methods by 4.0% and 5.2%,
respectively, which advance 3DVG toward greater generalization and real-world
applicability. The code is available at https://github.com/JiawLin/SeqVLM.

</details>


### [54] [Embracing Aleatoric Uncertainty: Generating Diverse 3D Human Motion](https://arxiv.org/abs/2508.20604)
*Zheng Qin,Yabing Wang,Minghui Yang,Sanping Zhou,Ming Yang,Le Wang*

Main category: cs.CV

TL;DR: Diverse-T2M方法通过引入噪声信号和潜在空间采样器，显著提升文本到动作生成的多样性，同时保持文本语义一致性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有技术能够生成精确且高质量的文本到动作，但生成动作的多样性仍然是一个重要挑战。本文旨在通过引入不确定性解决这一问题。

Method: 设计了一个简单而有效的文本到动作生成方法Diverse-T2M，通过将噪声信号作为多样性信息的载体，在基于Transformer的方法中显式建模不确定性。此外，构建了一个潜在空间，将文本投影为连续表示，并集成潜在空间采样器以引入随机采样。

Result: 在HumanML3D和KIT-ML基准数据集上的实验结果表明，该方法在保持文本一致性的同时显著提升了生成动作的多样性。

Conclusion: 本文提出的Diverse-T2M方法通过引入不确定性，显著提升了文本到动作生成的多样性，同时保持了文本语义的一致性。

Abstract: Generating 3D human motions from text is a challenging yet valuable task. The
key aspects of this task are ensuring text-motion consistency and achieving
generation diversity. Although recent advancements have enabled the generation
of precise and high-quality human motions from text, achieving diversity in the
generated motions remains a significant challenge. In this paper, we aim to
overcome the above challenge by designing a simple yet effective text-to-motion
generation method, \textit{i.e.}, Diverse-T2M. Our method introduces
uncertainty into the generation process, enabling the generation of highly
diverse motions while preserving the semantic consistency of the text.
Specifically, we propose a novel perspective that utilizes noise signals as
carriers of diversity information in transformer-based methods, facilitating a
explicit modeling of uncertainty. Moreover, we construct a latent space where
text is projected into a continuous representation, instead of a rigid
one-to-one mapping, and integrate a latent space sampler to introduce
stochastic sampling into the generation process, thereby enhancing the
diversity and uncertainty of the outputs. Our results on text-to-motion
generation benchmark datasets~(HumanML3D and KIT-ML) demonstrate that our
method significantly enhances diversity while maintaining state-of-the-art
performance in text consistency.

</details>


### [55] [Occlusion Robustness of CLIP for Military Vehicle Classification](https://arxiv.org/abs/2508.20760)
*Jan Erik van Woerden,Gertjan Burghouts,Lotte Nijskens,Alma M. Liezenga,Sabina van Rooij,Frank Ruis,Hugo J. Kuijf*

Main category: cs.CV

TL;DR: 研究了CLIP在军事环境中的遮挡鲁棒性，发现Transformer模型优于CNN，细粒度遮挡影响更大，微调可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究CLIP在军事环境中（如部分遮挡和信噪比降低）的鲁棒性，因为现有研究对此关注不足。

Method: 通过使用包含18种军事车辆类别的自定义数据集，评估了CLIP变体对遮挡的鲁棒性，采用归一化曲线下面积（NAUC）作为评估指标。

Result: 四项关键发现：（1）基于Transformer的CLIP模型表现优于CNN，（2）细粒度分散遮挡比大块连续遮挡更影响性能，（3）线性探测模型在约35%遮挡时性能急剧下降，（4）通过微调模型骨干，性能下降点可推迟至60%以上遮挡。

Conclusion: 研究强调了在训练过程中加入遮挡特定增强的重要性，并指出需要进一步探索CLIP模型在补丁级敏感性和架构弹性方面的表现，以实现其在现实世界中的部署。

Abstract: Vision-language models (VLMs) like CLIP enable zero-shot classification by
aligning images and text in a shared embedding space, offering advantages for
defense applications with scarce labeled data. However, CLIP's robustness in
challenging military environments, with partial occlusion and degraded
signal-to-noise ratio (SNR), remains underexplored. We investigate CLIP
variants' robustness to occlusion using a custom dataset of 18 military vehicle
classes and evaluate using Normalized Area Under the Curve (NAUC) across
occlusion percentages. Four key insights emerge: (1) Transformer-based CLIP
models consistently outperform CNNs, (2) fine-grained, dispersed occlusions
degrade performance more than larger contiguous occlusions, (3) despite
improved accuracy, performance of linear-probed models sharply drops at around
35% occlusion, (4) by finetuning the model's backbone, this performance drop
occurs at more than 60% occlusion. These results underscore the importance of
occlusion-specific augmentations during training and the need for further
exploration into patch-level sensitivity and architectural resilience for
real-world deployment of CLIP.

</details>


### [56] [Optimization-Based Calibration for Intravascular Ultrasound Volume Reconstruction](https://arxiv.org/abs/2508.20605)
*Karl-Philippe Beaudet,Sidaty El Hadramy,Philippe C Cattin,Juan Verde,Stéphane Cotin*

Main category: cs.CV

TL;DR: 提出3D血管内超声校准方法，用于肝手术中术前CT与术中超声图像的配准，验证误差小，增强术中引导。


<details>
  <summary>Details</summary>
Motivation: 术中超声图像在肝手术中难以解释，因视野有限和解剖结构复杂。弥补术前和术中数据之间的差距对有效手术引导至关重要。

Method: 提出了一种基于优化的校准方法，使用3D打印模型进行精确的3D血管内超声体积重建。

Result: 通过活体猪肝图像验证，校准误差为0.88至1.80毫米，配准误差为3.40至5.71毫米。

Conclusion: 该方法提供了一种可靠且准确的校准和体积重建手段，可用于肝手术中将术中超声图像与术前CT图像配准，增强术中引导。

Abstract: Intraoperative ultrasound images are inherently challenging to interpret in
liver surgery due to the limited field of view and complex anatomical
structures. Bridging the gap between preoperative and intraoperative data is
crucial for effective surgical guidance. 3D IntraVascular UltraSound (IVUS)
offers a potential solution by enabling the reconstruction of the entire organ,
which facilitates registration between preoperative computed tomography (CT)
scans and intraoperative IVUS images. In this work, we propose an
optimization-based calibration method using a 3D-printed phantom for accurate
3D Intravascular Ultrasound volume reconstruction. Our approach ensures precise
alignment of tracked IVUS data with preoperative CT images, improving
intraoperative navigation. We validated our method using in vivo swine liver
images, achieving a calibration error from 0.88 to 1.80 mm and a registration
error from 3.40 to 5.71 mm between the 3D IVUS data and the corresponding CT
scan. Our method provides a reliable and accurate means of calibration and
volume reconstruction. It can be used to register intraoperative ultrasound
images with preoperative CT images in the context of liver surgery, and enhance
intraoperative guidance.

</details>


### [57] [Physics Informed Generative Models for Magnetic Field Images](https://arxiv.org/abs/2508.20612)
*Aye Phyu Phyu Aung,Lucas Lum,Zhansen Shi,Wen Qiu,Bernice Zee,JM Chin,Yeow Kheng Lim,J. Senthilnath*

Main category: cs.CV

TL;DR: PI-GenMFI利用扩散模型和物理约束生成合成MFI图像，解决了数据集稀缺问题，提升了缺陷定位效率。


<details>
  <summary>Details</summary>
Motivation: MFI数据集稀缺限制了机器学习模型的训练，需要一种高效生成合成数据的方法。

Method: 提出Physics Informed Generative Models for Magnetic Field Images (PI-GenMFI)，结合两种物理约束生成合成MFI图像。

Result: 生成的合成MFI图像在专家评估和多项指标中表现优异，优化了缺陷定位过程。

Conclusion: PI-GenMFI模型通过结合物理约束生成合成MFI图像，有效解决了MFI数据集稀缺的问题，为缺陷定位提供了高效训练数据。

Abstract: In semiconductor manufacturing, defect detection and localization are
critical to ensuring product quality and yield. While X-ray imaging is a
reliable non-destructive testing method, it is memory-intensive and
time-consuming for large-scale scanning, Magnetic Field Imaging (MFI) offers a
more efficient means to localize regions of interest (ROI) for targeted X-ray
scanning. However, the limited availability of MFI datasets due to proprietary
concerns presents a significant bottleneck for training machine learning (ML)
models using MFI. To address this challenge, we consider an ML-driven approach
leveraging diffusion models with two physical constraints. We propose Physics
Informed Generative Models for Magnetic Field Images (PI-GenMFI) to generate
synthetic MFI samples by integrating specific physical information. We generate
MFI images for the most common defect types: power shorts. These synthetic
images will serve as training data for ML algorithms designed to localize
defect areas efficiently. To evaluate generated MFIs, we compare our model to
SOTA generative models from both variational autoencoder (VAE) and diffusion
methods. We present a domain expert evaluation to assess the generated samples.
In addition, we present qualitative and quantitative evaluation using various
metrics used for image generation and signal processing, showing promising
results to optimize the defect localization process.

</details>


### [58] [Looking Beyond the Obvious: A Survey on Abstract Concept Recognition for Video Understanding](https://arxiv.org/abs/2508.20765)
*Gowreesh Mago,Pascal Mettes,Stevan Rudinac*

Main category: cs.CV

TL;DR: 本文探讨了视频中抽象概念识别的挑战，主张利用多模态基础模型和社区经验来推动这一领域的发展。


<details>
  <summary>Details</summary>
Motivation: 人类在视频理解中具有识别抽象概念的独特能力，而当前机器主要局限于具体实体的识别。本文旨在推动机器理解高级抽象概念，使其更符合人类推理和价值观。

Method: 本文通过调查不同的任务和数据集，研究了视频内容中抽象概念的理解方法。

Result: 研究发现，研究者们长期尝试利用现有工具解决抽象概念理解任务，但仍有改进空间。

Conclusion: 本文主张利用多模态基础模型的最新进展，结合数十年的社区经验，重新审视视频中抽象概念理解这一重要开放挑战。

Abstract: The automatic understanding of video content is advancing rapidly. Empowered
by deeper neural networks and large datasets, machines are increasingly capable
of understanding what is concretely visible in video frames, whether it be
objects, actions, events, or scenes. In comparison, humans retain a unique
ability to also look beyond concrete entities and recognize abstract concepts
like justice, freedom, and togetherness. Abstract concept recognition forms a
crucial open challenge in video understanding, where reasoning on multiple
semantic levels based on contextual information is key. In this paper, we argue
that the recent advances in foundation models make for an ideal setting to
address abstract concept understanding in videos. Automated understanding of
high-level abstract concepts is imperative as it enables models to be more
aligned with human reasoning and values. In this survey, we study different
tasks and datasets used to understand abstract concepts in video content. We
observe that, periodically and over a long period, researchers have attempted
to solve these tasks, making the best use of the tools available at their
disposal. We advocate that drawing on decades of community experience will help
us shed light on this important open grand challenge and avoid ``re-inventing
the wheel'' as we start revisiting it in the era of multi-modal foundation
models.

</details>


### [59] [Revisiting the Privacy Risks of Split Inference: A GAN-Based Data Reconstruction Attack via Progressive Feature Optimization](https://arxiv.org/abs/2508.20613)
*Yixiang Qiu,Yanhan Liu,Hongyao Yu,Hao Fang,Bin Chen,Shu-Tao Xia,Ke Xu*

Main category: cs.CV

TL;DR: 提出一种新型GAN+DRA框架，通过渐进式特征优化和L1约束提升图像重建质量，尤其在复杂场景下表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有数据重建攻击（DRAs）在浅层模型上效果有限，且未能充分利用语义先验，导致重建质量和泛化性不足。

Method: 采用GAN框架，结合渐进式特征优化（PFO）技术，将生成器分解为分层模块并逐步优化中间表示；引入L1-ball约束以稳定优化过程。

Result: 实验表明，该方法在多种场景（如高分辨率、分布外数据、深层DNN）下显著优于现有攻击方法。

Conclusion: 本文提出的基于GAN的DRA框架与渐进式特征优化（PFO）方法显著提升了图像重建的语义保真度和真实性，尤其在面对高分辨率、分布外数据及更深层复杂DNN时表现优越。

Abstract: The growing complexity of Deep Neural Networks (DNNs) has led to the adoption
of Split Inference (SI), a collaborative paradigm that partitions computation
between edge devices and the cloud to reduce latency and protect user privacy.
However, recent advances in Data Reconstruction Attacks (DRAs) reveal that
intermediate features exchanged in SI can be exploited to recover sensitive
input data, posing significant privacy risks. Existing DRAs are typically
effective only on shallow models and fail to fully leverage semantic priors,
limiting their reconstruction quality and generalizability across datasets and
model architectures. In this paper, we propose a novel GAN-based DRA framework
with Progressive Feature Optimization (PFO), which decomposes the generator
into hierarchical blocks and incrementally refines intermediate representations
to enhance the semantic fidelity of reconstructed images. To stabilize the
optimization and improve image realism, we introduce an L1-ball constraint
during reconstruction. Extensive experiments show that our method outperforms
prior attacks by a large margin, especially in high-resolution scenarios,
out-of-distribution settings, and against deeper and more complex DNNs.

</details>


### [60] [Safer Skin Lesion Classification with Global Class Activation Probability Map Evaluation and SafeML](https://arxiv.org/abs/2508.20776)
*Kuniko Paxton,Koorosh Aslansefat,Amila Akagić,Dhavalkumar Thakker,Yiannis Papadopoulos*

Main category: cs.CV

TL;DR: 提出了一种新的皮肤病变分类可解释性方法，结合概率图和SafeML，显著提升诊断可信度和患者安全。


<details>
  <summary>Details</summary>
Motivation: 尽管皮肤病变分类模型的准确性显著提升，但AI模型在医疗实践中的信任度仍然不足，现有可解释性方法存在可靠性问题。

Method: 提出了Global Class Activation Probabilistic Map Evaluation方法，该方法对所有类别的激活概率图进行概率性和像素级分析，并结合SafeML检测误诊。

Result: 在ISIC数据集上使用MobileNetV2和Vision Transformers进行评估，结果表明该方法能有效减少误诊风险并提高诊断可靠性。

Conclusion: 提出的Global Class Activation Probabilistic Map Evaluation方法通过统一可视化诊断过程，结合SafeML的应用，显著提高了皮肤病变分类的可信度和患者安全性。

Abstract: Recent advancements in skin lesion classification models have significantly
improved accuracy, with some models even surpassing dermatologists' diagnostic
performance. However, in medical practice, distrust in AI models remains a
challenge. Beyond high accuracy, trustworthy, explainable diagnoses are
essential. Existing explainability methods have reliability issues, with
LIME-based methods suffering from inconsistency, while CAM-based methods
failing to consider all classes. To address these limitations, we propose
Global Class Activation Probabilistic Map Evaluation, a method that analyses
all classes' activation probability maps probabilistically and at a pixel
level. By visualizing the diagnostic process in a unified manner, it helps
reduce the risk of misdiagnosis. Furthermore, the application of SafeML
enhances the detection of false diagnoses and issues warnings to doctors and
patients as needed, improving diagnostic reliability and ultimately patient
safety. We evaluated our method using the ISIC datasets with MobileNetV2 and
Vision Transformers.

</details>


### [61] [EmoCAST: Emotional Talking Portrait via Emotive Text Description](https://arxiv.org/abs/2508.20615)
*Yiguo Jiang,Xiaodong Cun,Yong Zhang,Yudian Zheng,Fan Tang,Chi-Man Pun*

Main category: cs.CV

TL;DR: EmoCAST是一个基于扩散的框架，通过两个关键模块和新的数据集及训练策略，显著提升了情感说话头部视频的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在控制灵活性、运动自然度和表达质量方面存在局限性，且可用数据集主要在实验室环境中收集，限制了实际应用。

Method: 提出了EmoCAST，一个基于扩散的框架，包含两个关键模块：外观建模中的文本引导解耦情感模块和情感音频注意力模块。此外，构建了一个带有全面情感文本描述的情感说话头部数据集，并提出了情感感知采样训练策略和渐进功能训练策略。

Result: EmoCAST在生成真实、情感丰富且音频同步的说话头部视频方面表现优异。

Conclusion: EmoCAST在生成真实、情感丰富且音频同步的说话头部视频方面达到了最先进的性能。

Abstract: Emotional talking head synthesis aims to generate talking portrait videos
with vivid expressions. Existing methods still exhibit limitations in control
flexibility, motion naturalness, and expression quality. Moreover, currently
available datasets are primarily collected in lab settings, further
exacerbating these shortcomings. Consequently, these limitations substantially
hinder practical applications in real-world scenarios. To address these
challenges, we propose EmoCAST, a diffusion-based framework with two key
modules for precise text-driven emotional synthesis. In appearance modeling,
emotional prompts are integrated through a text-guided decoupled emotive
module, enhancing the spatial knowledge to improve emotion comprehension. To
improve the relationship between audio and emotion, we introduce an emotive
audio attention module to capture the interplay between controlled emotion and
driving audio, generating emotion-aware features to guide more precise facial
motion synthesis. Additionally, we construct an emotional talking head dataset
with comprehensive emotive text descriptions to optimize the framework's
performance. Based on the proposed dataset, we propose an emotion-aware
sampling training strategy and a progressive functional training strategy that
further improve the model's ability to capture nuanced expressive features and
achieve accurate lip-synchronization. Overall, EmoCAST achieves
state-of-the-art performance in generating realistic, emotionally expressive,
and audio-synchronized talking-head videos. Project Page:
https://github.com/GVCLab/EmoCAST

</details>


### [62] [Evaluating Compositional Generalisation in VLMs and Diffusion Models](https://arxiv.org/abs/2508.20783)
*Beth Pearson,Bilal Boulbarss,Michael Wray,Martha Lewis*

Main category: cs.CV

TL;DR: 扩散分类器和ViLT在概念绑定任务中表现优于CLIP，但所有模型在关系性任务中表现不佳，揭示了视觉语言模型在关系推理上的挑战。


<details>
  <summary>Details</summary>
Motivation: 探索生成性扩散分类器是否比判别性模型具有更好的组合泛化能力，以解决视觉语言模型在组合语义捕捉上的不足。

Method: 评估了三种模型（扩散分类器、CLIP和ViLT）在零样本学习（ZSL）和广义零样本学习（GZSL）设置中绑定对象与属性和关系的能力。

Result: 扩散分类器和ViLT在概念绑定任务中表现良好，但所有模型在关系性GZSL任务中表现不佳。CLIP嵌入分析表明，困难可能源于关系概念（如左右）的表征过于相似。

Conclusion: 尽管扩散分类器和ViLT在概念绑定任务中表现良好，但所有模型在关系性GZSL任务中都面临显著挑战，凸显了视觉语言模型在关系推理方面的普遍困难。

Abstract: A fundamental aspect of the semantics of natural language is that novel
meanings can be formed from the composition of previously known parts.
Vision-language models (VLMs) have made significant progress in recent years,
however, there is evidence that they are unable to perform this kind of
composition. For example, given an image of a red cube and a blue cylinder, a
VLM such as CLIP is likely to incorrectly label the image as a red cylinder or
a blue cube, indicating it represents the image as a `bag-of-words' and fails
to capture compositional semantics. Diffusion models have recently gained
significant attention for their impressive generative abilities, and zero-shot
classifiers based on diffusion models have been shown to perform competitively
with CLIP in certain compositional tasks. In this work we explore whether the
generative Diffusion Classifier has improved compositional generalisation
abilities compared to discriminative models. We assess three models --
Diffusion Classifier, CLIP, and ViLT -- on their ability to bind objects with
attributes and relations in both zero-shot learning (ZSL) and generalised
zero-shot learning (GZSL) settings. Our results show that the Diffusion
Classifier and ViLT perform well at concept binding tasks, but that all models
struggle significantly with the relational GZSL task, underscoring the broader
challenges VLMs face with relational reasoning. Analysis of CLIP embeddings
suggests that the difficulty may stem from overly similar representations of
relational concepts such as left and right. Code and dataset are available at:
https://github.com/otmive/diffusion_classifier_clip

</details>


### [63] [Mask-Guided Multi-Channel SwinUNETR Framework for Robust MRI Classification](https://arxiv.org/abs/2508.20621)
*Smriti Joshi,Lidia Garrucho,Richard Osuala,Oliver Diaz,Karim Lekadir*

Main category: cs.CV

TL;DR: 多中心挑战赛推动AI乳腺癌诊断，SwinUNETR框架表现优异，代码开源。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌早期检测对改善预后至关重要，MRI在高风险或致密乳腺组织中优于乳腺X光摄影。

Method: 采用SwinUNETR框架，结合乳腺区域掩模、数据增强和集成学习。

Result: 在挑战赛中获得第二名，验证了方法的鲁棒性和泛化能力。

Conclusion: 该研究开发的SwinUNETR深度学习框架在乳腺癌MRI诊断中表现出色，具备临床应用的潜力。

Abstract: Breast cancer is one of the leading causes of cancer-related mortality in
women, and early detection is essential for improving outcomes. Magnetic
resonance imaging (MRI) is a highly sensitive tool for breast cancer detection,
particularly in women at high risk or with dense breast tissue, where
mammography is less effective. The ODELIA consortium organized a multi-center
challenge to foster AI-based solutions for breast cancer diagnosis and
classification. The dataset included 511 studies from six European centers,
acquired on scanners from multiple vendors at both 1.5 T and 3 T. Each study
was labeled for the left and right breast as no lesion, benign lesion, or
malignant lesion. We developed a SwinUNETR-based deep learning framework that
incorporates breast region masking, extensive data augmentation, and ensemble
learning to improve robustness and generalizability. Our method achieved second
place on the challenge leaderboard, highlighting its potential to support
clinical breast MRI interpretation. We publicly share our codebase at
https://github.com/smriti-joshi/bcnaim-odelia-challenge.git.

</details>


### [64] [Surfel-based 3D Registration with Equivariant SE(3) Features](https://arxiv.org/abs/2508.20789)
*Xueyang Kang,Hang Zhao,Kourosh Khoshelham,Patrick Vandewalle*

Main category: cs.CV

TL;DR: 提出一种基于surfel的姿态学习回归方法，通过$\mathbf{SE(3)}$等变特征学习解决点云配准中的方向和不确定性问题，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有点云配准方法忽略点方向和不确定性，导致模型易受噪声输入和激进旋转（如正交变换）影响，需大量训练数据和变换增强。

Method: 该方法通过虚拟视角相机参数从Lidar点云初始化surfel，并利用$\mathbf{SE(3)}$等变卷积核学习显式位置和旋转特征，预测源和目标扫描间的相对变换。模型包括等变卷积编码器、相似性计算的交叉注意力机制、全连接解码器和非线性Huber损失。

Result: 实验结果表明，该方法在真实点云扫描上具有优越性和鲁棒性能。

Conclusion: 提出的基于surfel的姿态学习回归方法在室内外数据集上表现出优越性和鲁棒性，优于现有最先进方法。

Abstract: Point cloud registration is crucial for ensuring 3D alignment consistency of
multiple local point clouds in 3D reconstruction for remote sensing or digital
heritage. While various point cloud-based registration methods exist, both
non-learning and learning-based, they ignore point orientations and point
uncertainties, making the model susceptible to noisy input and aggressive
rotations of the input point cloud like orthogonal transformation; thus, it
necessitates extensive training point clouds with transformation augmentations.
To address these issues, we propose a novel surfel-based pose learning
regression approach. Our method can initialize surfels from Lidar point cloud
using virtual perspective camera parameters, and learns explicit
$\mathbf{SE(3)}$ equivariant features, including both position and rotation
through $\mathbf{SE(3)}$ equivariant convolutional kernels to predict relative
transformation between source and target scans. The model comprises an
equivariant convolutional encoder, a cross-attention mechanism for similarity
computation, a fully-connected decoder, and a non-linear Huber loss.
Experimental results on indoor and outdoor datasets demonstrate our model
superiority and robust performance on real point-cloud scans compared to
state-of-the-art methods.

</details>


### [65] [AvatarBack: Back-Head Generation for Complete 3D Avatars from Front-View Images](https://arxiv.org/abs/2508.20623)
*Shiqi Xin,Xiaolin Zhang,Yanbin Liu,Peng Zhang,Caifeng Shan*

Main category: cs.CV

TL;DR: AvatarBack是一个新框架，通过SSG和ASA技术解决了后脑部重建问题，显著提升了虚拟形象的完整性和真实感。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖前视图图像，导致后脑部重建质量差，表现为几何不一致、结构模糊和真实感降低，限制了虚拟形象的保真度。

Method: AvatarBack框架包含两个核心技术：主体特定生成器（SSG）和自适应空间对齐策略（ASA）。SSG利用生成先验从稀疏的前视图输入合成身份一致的后视图伪图像，提供多视图监督。ASA通过可学习的变换矩阵优化训练，解决合成视图与3D高斯表示之间的姿态和坐标差异。

Result: 在NeRSemble和K-hairstyle数据集上的实验表明，AvatarBack在几何、光度和基于GPT-4o的感知指标上显著提升了后脑部重建质量，同时保持了前部保真度。

Conclusion: AvatarBack通过其核心技术创新（SSG和ASA）显著提升了后脑部重建质量，同时保持了前部保真度，重建的虚拟形象在多样化运动中保持一致的视觉真实感，并且完全可动画化。

Abstract: Recent advances in Gaussian Splatting have significantly boosted the
reconstruction of head avatars, enabling high-quality facial modeling by
representing an 3D avatar as a collection of 3D Gaussians. However, existing
methods predominantly rely on frontal-view images, leaving the back-head poorly
constructed. This leads to geometric inconsistencies, structural blurring, and
reduced realism in the rear regions, ultimately limiting the fidelity of
reconstructed avatars. To address this challenge, we propose AvatarBack, a
novel plug-and-play framework specifically designed to reconstruct complete and
consistent 3D Gaussian avatars by explicitly modeling the missing back-head
regions. AvatarBack integrates two core technical innovations,i.e., the
Subject-specific Generator (SSG) and the Adaptive Spatial Alignment Strategy
(ASA). The former leverages a generative prior to synthesize
identity-consistent, plausible back-view pseudo-images from sparse frontal
inputs, providing robust multi-view supervision. To achieve precise geometric
alignment between these synthetic views and the 3D Gaussian representation, the
later employs learnable transformation matrices optimized during training,
effectively resolving inherent pose and coordinate discrepancies. Extensive
experiments on NeRSemble and K-hairstyle datasets, evaluated using geometric,
photometric, and GPT-4o-based perceptual metrics, demonstrate that AvatarBack
significantly enhances back-head reconstruction quality while preserving
frontal fidelity. Moreover, the reconstructed avatars maintain consistent
visual realism under diverse motions and remain fully animatable.

</details>


### [66] [CraftGraffiti: Exploring Human Identity with Custom Graffiti Art via Facial-Preserving Diffusion Models](https://arxiv.org/abs/2508.20640)
*Ayan Banerjee,Fernando Vilariño,Josep Lladós*

Main category: cs.CV

TL;DR: CraftGraffiti 是一种文本引导的涂鸦生成框架，通过风格优先、身份后处理的范式，在极端风格化下保持面部身份，实现了高美学评分和人类偏好。


<details>
  <summary>Details</summary>
Motivation: 在涂鸦等高对比度、抽象的艺术形式中，面部特征的微小失真可能导致身份不可识别，损害个人和文化真实性。因此，需要在极端风格化下保持面部身份的挑战。

Method: CraftGraffiti 是一个端到端的文本引导涂鸦生成框架，通过LoRA微调的预训练扩散变换器进行风格迁移，并利用面部一致的自注意力机制增强身份嵌入。动态重定向通过CLIP引导的提示扩展实现，无需关键点。

Result: 定量结果显示，CraftGraffiti 在面部特征一致性、美学评分和人类偏好方面达到领先水平。定性分析和实际部署（如Cruilla Festival）验证了其实际创作影响力。

Conclusion: CraftGraffiti 通过结合风格优先、身份后处理的范式，提出了一种在保持面部特征一致性的同时实现高度风格化的方法，推动了身份尊重的AI辅助艺术创作。

Abstract: Preserving facial identity under extreme stylistic transformation remains a
major challenge in generative art. In graffiti, a high-contrast, abstract
medium, subtle distortions to the eyes, nose, or mouth can erase the subject's
recognizability, undermining both personal and cultural authenticity. We
present CraftGraffiti, an end-to-end text-guided graffiti generation framework
designed with facial feature preservation as a primary objective. Given an
input image and a style and pose descriptive prompt, CraftGraffiti first
applies graffiti style transfer via LoRA-fine-tuned pretrained diffusion
transformer, then enforces identity fidelity through a face-consistent
self-attention mechanism that augments attention layers with explicit identity
embeddings. Pose customization is achieved without keypoints, using CLIP-guided
prompt extension to enable dynamic re-posing while retaining facial coherence.
We formally justify and empirically validate the "style-first, identity-after"
paradigm, showing it reduces attribute drift compared to the reverse order.
Quantitative results demonstrate competitive facial feature consistency and
state-of-the-art aesthetic and human preference scores, while qualitative
analyses and a live deployment at the Cruilla Festival highlight the system's
real-world creative impact. CraftGraffiti advances the goal of
identity-respectful AI-assisted artistry, offering a principled approach for
blending stylistic freedom with recognizability in creative AI applications.

</details>


### [67] [ExpertSim: Fast Particle Detector Simulation Using Mixture-of-Generative-Experts](https://arxiv.org/abs/2508.20991)
*Patryk Będkowski,Jan Dubiński,Filip Szatkowski,Kamil Deja,Przemysław Rokita,Tomasz Trzciński*

Main category: cs.CV

TL;DR: ExpertSim是一种针对ALICE实验中零度量热器的深度学习模拟方法，通过专家混合架构提高模拟效率和精度。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡罗方法计算成本高且效率低，生成式机器学习方法在数据分布变化大的情况下表现不佳，需要更高效的模拟方法。

Method: 采用Mixture-of-Generative-Experts架构，每个专家专注于模拟数据的不同子集。

Result: ExpertSim不仅提高了准确性，还比传统蒙特卡罗方法显著提速。

Conclusion: ExpertSim通过Mixture-of-Generative-Experts架构，显著提高了模拟精度和效率，为CERN的高效探测器模拟提供了有前景的解决方案。

Abstract: Simulating detector responses is a crucial part of understanding the inner
workings of particle collisions in the Large Hadron Collider at CERN. Such
simulations are currently performed with statistical Monte Carlo methods, which
are computationally expensive and put a significant strain on CERN's
computational grid. Therefore, recent proposals advocate for generative machine
learning methods to enable more efficient simulations. However, the
distribution of the data varies significantly across the simulations, which is
hard to capture with out-of-the-box methods. In this study, we present
ExpertSim - a deep learning simulation approach tailored for the Zero Degree
Calorimeter in the ALICE experiment. Our method utilizes a
Mixture-of-Generative-Experts architecture, where each expert specializes in
simulating a different subset of the data. This allows for a more precise and
efficient generation process, as each expert focuses on a specific aspect of
the calorimeter response. ExpertSim not only improves accuracy, but also
provides a significant speedup compared to the traditional Monte-Carlo methods,
offering a promising solution for high-efficiency detector simulations in
particle physics experiments at CERN. We make the code available at
https://github.com/patrick-bedkowski/expertsim-mix-of-generative-experts.

</details>


### [68] [Improving Alignment in LVLMs with Debiased Self-Judgment](https://arxiv.org/abs/2508.20655)
*Sihan Yang,Chenhang Cui,Zihao Zhao,Yiyang Zhou,Weilong Yan,Ying Wei,Huaxiu Yao*

Main category: cs.CV

TL;DR: 提出无偏自评分数方法，自主优化视觉-语言模型对齐，减少幻觉并提升性能，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有对齐方法（如指令微调和偏好微调）依赖外部数据集、人工标注或复杂后处理，限制了可扩展性并增加成本。

Method: 生成无偏自评分数（debiased self-judgment score），作为模型内部的自评估指标，不依赖外部资源，自主优化对齐能力。

Result: 实证结果表明，该方法在减少幻觉、增强安全性和提升整体能力方面显著优于传统方法。

Conclusion: 本文提出了一种新颖的自评估方法，通过生成无偏自评分数来改进大型视觉-语言模型的对齐能力，显著减少了幻觉并提升了安全性和整体性能。

Abstract: The rapid advancements in Large Language Models (LLMs) and Large
Visual-Language Models (LVLMs) have opened up new opportunities for integrating
visual and linguistic modalities. However, effectively aligning these
modalities remains challenging, often leading to hallucinations--where
generated outputs are not grounded in the visual input--and raising safety
concerns across various domains. Existing alignment methods, such as
instruction tuning and preference tuning, often rely on external datasets,
human annotations, or complex post-processing, which limit scalability and
increase costs. To address these challenges, we propose a novel approach that
generates the debiased self-judgment score, a self-evaluation metric created
internally by the model without relying on external resources. This enables the
model to autonomously improve alignment. Our method enhances both decoding
strategies and preference tuning processes, resulting in reduced
hallucinations, enhanced safety, and improved overall capability. Empirical
results show that our approach significantly outperforms traditional methods,
offering a more effective solution for aligning LVLMs.

</details>


### [69] [ChainReaction! Structured Approach with Causal Chains as Intermediate Representations for Improved and Explainable Causal Video Question Answering](https://arxiv.org/abs/2508.21010)
*Paritosh Parmar,Eric Peh,Basura Fernando*

Main category: cs.CV

TL;DR: 论文提出模块化框架，通过因果链显式解耦因果推理与答案生成，提升VideoQA的可解释性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有VideoQA模型依赖不透明的整体流程，缺乏高阶推理能力和可解释性。

Method: 采用两阶段架构，包括因果链提取器（CCE）和因果链驱动的回答器（CCDA），并利用大语言模型生成高质量因果链。

Result: 在三个大规模基准测试中表现优于现有模型，显著提升了可解释性、用户信任和泛化能力。

Conclusion: 该论文提出的模块化框架在性能、可解释性和泛化能力上均优于现有方法，同时CCE可作为跨领域可复用的因果推理引擎。

Abstract: Existing Causal-Why Video Question Answering (VideoQA) models often struggle
with higher-order reasoning, relying on opaque, monolithic pipelines that
entangle video understanding, causal inference, and answer generation. These
black-box approaches offer limited interpretability and tend to depend on
shallow heuristics. We propose a novel, modular framework that explicitly
decouples causal reasoning from answer generation, introducing natural language
causal chains as interpretable intermediate representations. Inspired by human
cognitive models, these structured cause-effect sequences bridge low-level
video content with high-level causal reasoning, enabling transparent and
logically coherent inference. Our two-stage architecture comprises a Causal
Chain Extractor (CCE) that generates causal chains from video-question pairs,
and a Causal Chain-Driven Answerer (CCDA) that produces answers grounded in
these chains. To address the lack of annotated reasoning traces, we introduce a
scalable method for generating high-quality causal chains from existing
datasets using large language models. We also propose CauCo, a new evaluation
metric for causality-oriented captioning. Experiments on three large-scale
benchmarks demonstrate that our approach not only outperforms state-of-the-art
models, but also yields substantial gains in explainability, user trust, and
generalization -- positioning the CCE as a reusable causal reasoning engine
across diverse domains. Project page:
https://paritoshparmar.github.io/chainreaction/

</details>


### [70] ["Humor, Art, or Misinformation?": A Multimodal Dataset for Intent-Aware Synthetic Image Detection](https://arxiv.org/abs/2508.20670)
*Anastasios Skoularikis,Stefanos-Iordanis Papadopoulos,Symeon Papadopoulos,Panagiotis C. Petrantonakis*

Main category: cs.CV

TL;DR: S-HArM数据集用于意图分类，研究发现图像和多模态引导数据训练的模型效果更佳，但推断意图仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多忽略AI生成图像背后的意图，S-HArM数据集旨在填补这一空白。

Method: 通过三种提示策略（图像引导、描述引导和多模态引导）构建大规模合成训练数据集，并结合多种模型进行对比研究。

Result: 图像引导和多模态引导数据训练的模型在真实内容中表现更好，但整体性能仍有限。

Conclusion: 推断AI生成图像背后的意图仍然具有挑战性，需要专门架构的进一步研究。

Abstract: Recent advances in multimodal AI have enabled progress in detecting synthetic
and out-of-context content. However, existing efforts largely overlook the
intent behind AI-generated images. To fill this gap, we introduce S-HArM, a
multimodal dataset for intent-aware classification, comprising 9,576 "in the
wild" image-text pairs from Twitter/X and Reddit, labeled as Humor/Satire, Art,
or Misinformation. Additionally, we explore three prompting strategies
(image-guided, description-guided, and multimodally-guided) to construct a
large-scale synthetic training dataset with Stable Diffusion. We conduct an
extensive comparative study including modality fusion, contrastive learning,
reconstruction networks, attention mechanisms, and large vision-language
models. Our results show that models trained on image- and multimodally-guided
data generalize better to "in the wild" content, due to preserved visual
context. However, overall performance remains limited, highlighting the
complexity of inferring intent and the need for specialized architectures.

</details>


### [71] [Veritas: Generalizable Deepfake Detection via Pattern-Aware Reasoning](https://arxiv.org/abs/2508.21048)
*Hao Tan,Jun Lan,Zichang Tan,Ajian Liu,Chuanbiao Song,Senyuan Shi,Huijia Zhu,Weiqiang Wang,Jun Wan,Zhen Lei*

Main category: cs.CV

TL;DR: HydraFake数据集和Veritas检测器解决了现有深度伪造检测基准与工业实践的差异问题，通过多样化伪造技术和模式感知推理显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有的学术基准与工业实践存在严重差异，通常具有同质化的训练来源和低质量的测试图像，限制了当前检测器的实际部署。为了解决这一问题，引入了HydraFake数据集和Veritas检测器。

Method: 提出了HydraFake数据集，模拟真实世界的挑战，包括多样化的深度伪造技术和野外伪造内容，以及严格的训练和评估协议。基于此数据集，开发了Veritas检测器，采用模式感知推理（如“规划”和“自我反思”）和两阶段训练流程。

Result: 实验表明，之前的检测器在跨模型场景中表现出良好的泛化能力，但在未知伪造技术和数据领域表现不足。Veritas在不同OOD场景中取得了显著提升，并能提供透明和可信的检测输出。

Conclusion: Veritas，一种基于多模态大型语言模型（MLLM）的深度伪造检测器，通过引入模式感知推理和两阶段训练流程，显著提升了在未知伪造技术和数据领域的检测性能，并能够提供透明和可信的检测输出。

Abstract: Deepfake detection remains a formidable challenge due to the complex and
evolving nature of fake content in real-world scenarios. However, existing
academic benchmarks suffer from severe discrepancies from industrial practice,
typically featuring homogeneous training sources and low-quality testing
images, which hinder the practical deployments of current detectors. To
mitigate this gap, we introduce HydraFake, a dataset that simulates real-world
challenges with hierarchical generalization testing. Specifically, HydraFake
involves diversified deepfake techniques and in-the-wild forgeries, along with
rigorous training and evaluation protocol, covering unseen model architectures,
emerging forgery techniques and novel data domains. Building on this resource,
we propose Veritas, a multi-modal large language model (MLLM) based deepfake
detector. Different from vanilla chain-of-thought (CoT), we introduce
pattern-aware reasoning that involves critical reasoning patterns such as
"planning" and "self-reflection" to emulate human forensic process. We further
propose a two-stage training pipeline to seamlessly internalize such deepfake
reasoning capacities into current MLLMs. Experiments on HydraFake dataset
reveal that although previous detectors show great generalization on
cross-model scenarios, they fall short on unseen forgeries and data domains.
Our Veritas achieves significant gains across different OOD scenarios, and is
capable of delivering transparent and faithful detection outputs.

</details>


### [72] [FakeParts: a New Family of AI-Generated DeepFakes](https://arxiv.org/abs/2508.21052)
*Gaetan Brison,Soobash Daiboo,Samy Aimeur,Awais Hussain Sani,Xi Wang,Gianni Franchi,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: 本文介绍了部分深度伪造FakeParts及其检测挑战，提出了首个大规模基准数据集FakePartsBench，并展示了其对人类和模型检测的显著影响。


<details>
  <summary>Details</summary>
Motivation: 部分深度伪造（FakeParts）因其局部操纵与真实元素无缝融合而特别具有欺骗性，现有检测方法难以识别，亟需新的检测能力和数据集。

Method: 提出了FakePartsBench，这是第一个专门设计用于捕捉部分深度伪造全谱的大规模基准数据集，包含超过25K视频，并带有像素级和帧级操纵注释。

Result: 用户研究表明，与传统深度伪造相比，FakeParts使人类检测准确率降低了30%以上，最先进的检测模型也表现出类似的性能下降。

Conclusion: 本文揭示了当前深度伪造检测方法的紧迫漏洞，并提供了必要的资源来开发更强大的部分视频操纵检测方法。

Abstract: We introduce FakeParts, a new class of deepfakes characterized by subtle,
localized manipulations to specific spatial regions or temporal segments of
otherwise authentic videos. Unlike fully synthetic content, these partial
manipulations, ranging from altered facial expressions to object substitutions
and background modifications, blend seamlessly with real elements, making them
particularly deceptive and difficult to detect. To address the critical gap in
detection capabilities, we present FakePartsBench, the first large-scale
benchmark dataset specifically designed to capture the full spectrum of partial
deepfakes. Comprising over 25K videos with pixel-level and frame-level
manipulation annotations, our dataset enables comprehensive evaluation of
detection methods. Our user studies demonstrate that FakeParts reduces human
detection accuracy by over 30% compared to traditional deepfakes, with similar
performance degradation observed in state-of-the-art detection models. This
work identifies an urgent vulnerability in current deepfake detection
approaches and provides the necessary resources to develop more robust methods
for partial video manipulations.

</details>


### [73] [Learned Rate Control for Frame-Level Adaptive Neural Video Compression via Dynamic Neural Network](https://arxiv.org/abs/2508.20709)
*Chenhao Zhang,Wei Gao*

Main category: cs.CV

TL;DR: 提出动态视频压缩框架，通过动态路由自编码器和速率控制代理实现可变比特率优化，实验显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 解决基于学习的编解码器在精确速率控制方面的固有局限性，实现可变比特率场景下的高效视频压缩。

Method: 提出了动态路由自编码器（Dynamic-Route Autoencoder）和速率控制代理（Rate Control Agent），通过联合路由优化策略（Joint-Routes Optimization）实现多路由协同训练。

Result: 在HEVC和UVG数据集上的实验表明，该方法在保持高率失真性能的同时，显著降低了比特率误差。

Conclusion: 提出的动态视频压缩框架在多种比特率和比特率约束应用中实现了率失真复杂度优化（RDCO），平均BD-Rate降低14.8%，BD-PSNR增益0.47dB，平均比特率误差1.66%。

Abstract: Neural Video Compression (NVC) has achieved remarkable performance in recent
years. However, precise rate control remains a challenge due to the inherent
limitations of learning-based codecs. To solve this issue, we propose a dynamic
video compression framework designed for variable bitrate scenarios. First, to
achieve variable bitrate implementation, we propose the Dynamic-Route
Autoencoder with variable coding routes, each occupying partial computational
complexity of the whole network and navigating to a distinct RD trade-off.
Second, to approach the target bitrate, the Rate Control Agent estimates the
bitrate of each route and adjusts the coding route of DRA at run time. To
encompass a broad spectrum of variable bitrates while preserving overall RD
performance, we employ the Joint-Routes Optimization strategy, achieving
collaborative training of various routes. Extensive experiments on the HEVC and
UVG datasets show that the proposed method achieves an average BD-Rate
reduction of 14.8% and BD-PSNR gain of 0.47dB over state-of-the-art methods
while maintaining an average bitrate error of 1.66%, achieving
Rate-Distortion-Complexity Optimization (RDCO) for various bitrate and
bitrate-constrained applications. Our code is available at
https://git.openi.org.cn/OpenAICoding/DynamicDVC.

</details>


### [74] [CardioMorphNet: Cardiac Motion Prediction Using a Shape-Guided Bayesian Recurrent Deep Network](https://arxiv.org/abs/2508.20734)
*Reza Akbari Movahed,Abuzar Rezaee,Arezoo Zakeri,Colin Berry,Edmond S. L. Ho,Ali Gooya*

Main category: cs.CV

TL;DR: CardioMorphNet是一个新型的循环贝叶斯深度学习框架，通过形状引导的配准方法，显著提升了心脏运动估计的准确性和置信度。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖基于强度的图像配准相似性损失，可能忽略心脏解剖区域，导致心脏运动估计不准确。

Method: 提出了CardioMorphNet，一个基于循环贝叶斯深度学习的框架，用于3D心脏形状引导的可变形配准，利用短轴CMR图像。

Result: 在UK Biobank数据集上验证，CardioMorphNet在心脏运动估计中表现优异，并提供更低不确定性的运动场估计。

Conclusion: CardioMorphNet在心脏运动估计中表现出卓越性能，超越了现有方法，并能提供更高置信度的预测。

Abstract: Accurate cardiac motion estimation from cine cardiac magnetic resonance (CMR)
images is vital for assessing cardiac function and detecting its abnormalities.
Existing methods often struggle to capture heart motion accurately because they
rely on intensity-based image registration similarity losses that may overlook
cardiac anatomical regions. To address this, we propose CardioMorphNet, a
recurrent Bayesian deep learning framework for 3D cardiac shape-guided
deformable registration using short-axis (SAX) CMR images. It employs a
recurrent variational autoencoder to model spatio-temporal dependencies over
the cardiac cycle and two posterior models for bi-ventricular segmentation and
motion estimation. The derived loss function from the Bayesian formulation
guides the framework to focus on anatomical regions by recursively registering
segmentation maps without using intensity-based image registration similarity
loss, while leveraging sequential SAX volumes and spatio-temporal features. The
Bayesian modelling also enables computation of uncertainty maps for the
estimated motion fields. Validated on the UK Biobank dataset by comparing
warped mask shapes with ground truth masks, CardioMorphNet demonstrates
superior performance in cardiac motion estimation, outperforming
state-of-the-art methods. Uncertainty assessment shows that it also yields
lower uncertainty values for estimated motion fields in the cardiac region
compared with other probabilistic-based cardiac registration methods,
indicating higher confidence in its predictions.

</details>


### [75] [Mix, Align, Distil: Reliable Cross-Domain Atypical Mitosis Classification](https://arxiv.org/abs/2508.20745)
*Kaustubh Atey,Sameer Anand Jha,Gouranga Bala,Amit Sethi*

Main category: cs.CV

TL;DR: 论文提出了一种训练时方法，通过风格扰动、特征对齐和EMA教师模型提升非典型有丝分裂图像的跨域分类性能，在MIDOG 2025任务2中表现优异。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂图像（AMFs）是重要的病理标志物，但在扫描仪、染色和采集差异导致的域偏移下难以一致识别。

Method: 通过风格扰动增加特征多样性，使用弱域标签通过辅助对齐损失对齐特征，并通过EMA教师模型和温度缩放KL散度稳定预测。

Result: 在MIDOG 2025任务2中，该方法取得了平衡准确率0.8762、灵敏度0.8873、特异性0.8651和ROC AUC 0.9499的优异表现。

Conclusion: 该论文提出的方法在MIDOG 2025挑战赛中表现优异，平衡准确率为0.8762，ROC AUC为0.9499，具有强健的跨域性能，且推理时间开销极小，适合实际应用。

Abstract: Atypical mitotic figures (AMFs) are important histopathological markers yet
remain challenging to identify consistently, particularly under domain shift
stemming from scanner, stain, and acquisition differences. We present a simple
training-time recipe for domain-robust AMF classification in MIDOG 2025 Task 2.
The approach (i) increases feature diversity via style perturbations inserted
at early and mid backbone stages, (ii) aligns attention-refined features across
sites using weak domain labels (Scanner, Origin, Species, Tumor) through an
auxiliary alignment loss, and (iii) stabilizes predictions by distilling from
an exponential moving average (EMA) teacher with temperature-scaled KL
divergence. On the organizer-run preliminary leaderboard for atypical mitosis
classification, our submission attains balanced accuracy of 0.8762, sensitivity
of 0.8873, specificity of 0.8651, and ROC AUC of 0.9499. The method incurs
negligible inference-time overhead, relies only on coarse domain metadata, and
delivers strong, balanced performance, positioning it as a competitive
submission for the MIDOG 2025 challenge.

</details>


### [76] [Pref-GRPO: Pairwise Preference Reward-based GRPO for Stable Text-to-Image Reinforcement Learning](https://arxiv.org/abs/2508.20751)
*Yibin Wang,Zhimin Li,Yuhang Zang,Yujie Zhou,Jiazi Bu,Chunyu Wang,Qinglin Lu,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: Pref-GRPO通过成对偏好奖励模型解决奖励黑客问题，UniGenBench提供细致的T2I基准测试，验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于点式奖励模型的方法容易受到奖励黑客的影响，导致图像生成过程不稳定。此外，现有的T2I基准测试评估标准粗糙，限制了模型的全面评估。

Method: 提出了Pref-GRPO方法，使用成对偏好奖励模型比较图像组内的图像，以胜率作为奖励信号。同时，引入了UniGenBench基准测试，包含600个提示，覆盖5个主题和20个子主题，通过10个主要和27个子标准评估语义一致性。

Result: 实验表明，Pref-GRPO能够区分细微的图像质量差异，提供更稳定的优势并缓解奖励黑客问题。UniGenBench揭示了开源和闭源T2I模型的优缺点，并验证了Pref-GRPO的有效性。

Conclusion: Pref-GRPO通过将优化目标从分数最大化转向偏好拟合，提供了更稳定的训练，并有效缓解了奖励黑客问题。UniGenBench作为一个统一的T2I基准测试，通过细致的评估标准全面评估模型性能，验证了Pref-GRPO的有效性。

Abstract: Recent advancements highlight the importance of GRPO-based reinforcement
learning methods and benchmarking in enhancing text-to-image (T2I) generation.
However, current methods using pointwise reward models (RM) for scoring
generated images are susceptible to reward hacking. We reveal that this happens
when minimal score differences between images are amplified after
normalization, creating illusory advantages that drive the model to
over-optimize for trivial gains, ultimately destabilizing the image generation
process. To address this, we propose Pref-GRPO, a pairwise preference
reward-based GRPO method that shifts the optimization objective from score
maximization to preference fitting, ensuring more stable training. In
Pref-GRPO, images are pairwise compared within each group using preference RM,
and the win rate is used as the reward signal. Extensive experiments
demonstrate that PREF-GRPO differentiates subtle image quality differences,
providing more stable advantages and mitigating reward hacking. Additionally,
existing T2I benchmarks are limited by coarse evaluation criteria, hindering
comprehensive model assessment. To solve this, we introduce UniGenBench, a
unified T2I benchmark comprising 600 prompts across 5 main themes and 20
subthemes. It evaluates semantic consistency through 10 primary and 27
sub-criteria, leveraging MLLM for benchmark construction and evaluation. Our
benchmarks uncover the strengths and weaknesses of both open and closed-source
T2I models and validate the effectiveness of Pref-GRPO.

</details>


### [77] [Adapting Foundation Model for Dental Caries Detection with Dual-View Co-Training](https://arxiv.org/abs/2508.20813)
*Tao Luo,Han Wu,Tong Yang,Dinggang Shen,Zhiming Cui*

Main category: cs.CV

TL;DR: DVCTNet是一种双视图协同训练网络，通过动态融合全局和局部视图特征，显著提高了牙科龋齿检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前牙科龋齿检测方法因对比度变化和病变形态多样而准确性不足，DVCTNet受牙医临床工作流程启发，旨在提高检测准确性。

Method: DVCTNet采用双视图协同训练网络，结合全局视图和局部视图，通过Gated Cross-View Attention模块动态融合双视图特征。

Result: DVCTNet在公开数据集和新标注的高精度数据集上均优于现有最先进方法。

Conclusion: DVCTNet展示了在牙科龋齿检测中的优越性能，显著优于现有方法，具有临床应用的潜力。

Abstract: Accurate dental caries detection from panoramic X-rays plays a pivotal role
in preventing lesion progression. However, current detection methods often
yield suboptimal accuracy due to subtle contrast variations and diverse lesion
morphology of dental caries. In this work, inspired by the clinical workflow
where dentists systematically combine whole-image screening with detailed
tooth-level inspection, we present DVCTNet, a novel Dual-View Co-Training
network for accurate dental caries detection. Our DVCTNet starts with employing
automated tooth detection to establish two complementary views: a global view
from panoramic X-ray images and a local view from cropped tooth images. We then
pretrain two vision foundation models separately on the two views. The
global-view foundation model serves as the detection backbone, generating
region proposals and global features, while the local-view model extracts
detailed features from corresponding cropped tooth patches matched by the
region proposals. To effectively integrate information from both views, we
introduce a Gated Cross-View Attention (GCV-Atten) module that dynamically
fuses dual-view features, enhancing the detection pipeline by integrating the
fused features back into the detection model for final caries detection. To
rigorously evaluate our DVCTNet, we test it on a public dataset and further
validate its performance on a newly curated, high-precision dental caries
detection dataset, annotated using both intra-oral images and panoramic X-rays
for double verification. Experimental results demonstrate DVCTNet's superior
performance against existing state-of-the-art (SOTA) methods on both datasets,
indicating the clinical applicability of our method. Our code and labeled
dataset are available at https://github.com/ShanghaiTech-IMPACT/DVCTNet.

</details>


### [78] [FusionCounting: Robust visible-infrared image fusion guided by crowd counting via multi-task learning](https://arxiv.org/abs/2508.20817)
*He Li,Xinyu Liu,Weihang Kong,Xingchen Zhang*

Main category: cs.CV

TL;DR: FusionCounting是一个整合人群计数和可见光-红外图像融合的多任务框架，通过动态损失函数和对抗训练提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有VIF方法多关注图像质量优化，而结合下游任务的研究较少。人群计数因其标注简单且适用于密集场景，适合与VIF结合。

Method: 提出了FusionCounting，一个多任务学习框架，结合人群计数和VIF。采用动态损失函数加权策略平衡任务贡献，并引入对抗训练提升模型稳健性。

Result: 在公开数据集上，FusionCounting不仅提升了图像融合质量，还实现了更优的人群计数性能。

Conclusion: FusionCounting框架通过整合人群计数和可见光-红外图像融合，不仅提升了图像融合质量，还在人群计数任务中表现出色。动态损失函数加权策略和对抗训练的引入进一步增强了模型的稳健性。

Abstract: Most visible and infrared image fusion (VIF) methods focus primarily on
optimizing fused image quality. Recent studies have begun incorporating
downstream tasks, such as semantic segmentation and object detection, to
provide semantic guidance for VIF. However, semantic segmentation requires
extensive annotations, while object detection, despite reducing annotation
efforts compared with segmentation, faces challenges in highly crowded scenes
due to overlapping bounding boxes and occlusion. Moreover, although RGB-T crowd
counting has gained increasing attention in recent years, no studies have
integrated VIF and crowd counting into a unified framework. To address these
challenges, we propose FusionCounting, a novel multi-task learning framework
that integrates crowd counting into the VIF process. Crowd counting provides a
direct quantitative measure of population density with minimal annotation,
making it particularly suitable for dense scenes. Our framework leverages both
input images and population density information in a mutually beneficial
multi-task design. To accelerate convergence and balance tasks contributions,
we introduce a dynamic loss function weighting strategy. Furthermore, we
incorporate adversarial training to enhance the robustness of both VIF and
crowd counting, improving the model's stability and resilience to adversarial
attacks. Experimental results on public datasets demonstrate that
FusionCounting not only enhances image fusion quality but also achieves
superior crowd counting performance.

</details>


### [79] [Estimating 2D Keypoints of Surgical Tools Using Vision-Language Models with Low-Rank Adaptation](https://arxiv.org/abs/2508.20830)
*Krit Duangprom,Tryphon Lambrou,Binod Bhattarai*

Main category: cs.CV

TL;DR: 提出了一种基于LoRA技术微调VLMs的2D关键点估计新方法，在小规模医疗数据集中表现优于传统方法，为3D姿态估计奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统CNN或Transformer方法在小规模医疗数据集中容易过拟合，而预训练VLMs具有更好的泛化能力。

Method: 利用低秩调整（LoRA）技术微调视觉语言模型（VLMs），设计提示创建指令调优数据集，将视觉特征与语义关键点描述对齐。

Result: 实验结果表明，仅需两个epoch的微调，适应的VLM就超越了基线模型，证明了LoRA在低资源场景中的有效性。

Conclusion: 该方法不仅提高了关键点检测性能，还为未来在3D手术手和工具姿态估计方面的工作铺平了道路。

Abstract: This paper presents a novel pipeline for 2D keypoint estima- tion of surgical
tools by leveraging Vision Language Models (VLMs) fine- tuned using a low rank
adjusting (LoRA) technique. Unlike traditional Convolutional Neural Network
(CNN) or Transformer-based approaches, which often suffer from overfitting in
small-scale medical datasets, our method harnesses the generalization
capabilities of pre-trained VLMs. We carefully design prompts to create an
instruction-tuning dataset and use them to align visual features with semantic
keypoint descriptions. Experimental results show that with only two epochs of
fine tuning, the adapted VLM outperforms the baseline models, demonstrating the
ef- fectiveness of LoRA in low-resource scenarios. This approach not only
improves keypoint detection performance, but also paves the way for future work
in 3D surgical hands and tools pose estimation.

</details>


### [80] [PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification](https://arxiv.org/abs/2508.20835)
*Hao Yang,Qianyu Zhou,Haijia Sun,Xiangtai Li,Xuequan Lu,Lizhuang Ma,Shuicheng Yan*

Main category: cs.CV

TL;DR: PointDGRWKV是首个针对DG PCC任务的RWKV框架，通过两个新模块解决了RWKV在DG PCC中的挑战，显著提升了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的DG PCC方法在感受野、计算成本或长程依赖建模方面存在不足，而RWKV架构具有线性复杂度和全局感受野的优势，但直接应用于DG PCC会面临空间扭曲和注意力漂移的挑战。

Method: 提出了PointDGRWKV框架，包含Adaptive Geometric Token Shift模块以增强局部几何建模，以及Cross-Domain key feature Distribution Alignment模块以减少跨域注意力漂移。

Result: 在多个基准测试中，PointDGRWKV表现优于现有方法，达到了最先进的性能。

Conclusion: PointDGRWKV通过引入Adaptive Geometric Token Shift和Cross-Domain key feature Distribution Alignment模块，显著提升了RWKV模型在DG PCC任务中的泛化能力，并在多个基准测试中达到了最先进的性能。

Abstract: Domain Generalization (DG) has been recently explored to enhance the
generalizability of Point Cloud Classification (PCC) models toward unseen
domains. Prior works are based on convolutional networks, Transformer or Mamba
architectures, either suffering from limited receptive fields or high
computational cost, or insufficient long-range dependency modeling. RWKV, as an
emerging architecture, possesses superior linear complexity, global receptive
fields, and long-range dependency. In this paper, we present the first work
that studies the generalizability of RWKV models in DG PCC. We find that
directly applying RWKV to DG PCC encounters two significant challenges: RWKV's
fixed direction token shift methods, like Q-Shift, introduce spatial
distortions when applied to unstructured point clouds, weakening local
geometric modeling and reducing robustness. In addition, the Bi-WKV attention
in RWKV amplifies slight cross-domain differences in key distributions through
exponential weighting, leading to attention shifts and degraded generalization.
To this end, we propose PointDGRWKV, the first RWKV-based framework tailored
for DG PCC. It introduces two key modules to enhance spatial modeling and
cross-domain robustness, while maintaining RWKV's linear efficiency. In
particular, we present Adaptive Geometric Token Shift to model local
neighborhood structures to improve geometric context awareness. In addition,
Cross-Domain key feature Distribution Alignment is designed to mitigate
attention drift by aligning key feature distributions across domains. Extensive
experiments on multiple benchmarks demonstrate that PointDGRWKV achieves
state-of-the-art performance on DG PCC.

</details>


### [81] [PathMR: Multimodal Visual Reasoning for Interpretable Pathology Diagnosis](https://arxiv.org/abs/2508.20851)
*Ye Zhang,Yu Zhou,Jingwen Qi,Yongbing Zhang,Simon Puettmann,Finn Wichmann,Larissa Pereira Ferreira,Lara Sichward,Julius Keyl,Sylvia Hartmann,Shuo Zhao,Hongxiao Wang,Xiaowei Xu,Jianxu Chen*

Main category: cs.CV

TL;DR: PathMR是一个细胞级多模态视觉推理框架，用于病理图像分析，通过生成诊断解释和预测细胞分布，提升了AI诊断的透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在病理诊断中模型决策不透明和缺乏可追溯依据的问题，提升AI辅助诊断的可靠性和临床接受度。

Method: 提出PathMR，一个细胞级多模态视觉推理框架，能够同时生成专家级诊断解释和预测细胞分布模式。

Result: 在PathGen和GADVR数据集上的实验表明，PathMR在文本生成质量、分割准确性和跨模态对齐方面优于现有最先进的视觉推理方法。

Conclusion: PathMR通过结合细胞级多模态视觉推理框架，显著提升了病理图像分析的透明度和可解释性，为AI辅助病理诊断提供了可靠的工具。

Abstract: Deep learning based automated pathological diagnosis has markedly improved
diagnostic efficiency and reduced variability between observers, yet its
clinical adoption remains limited by opaque model decisions and a lack of
traceable rationale. To address this, recent multimodal visual reasoning
architectures provide a unified framework that generates segmentation masks at
the pixel level alongside semantically aligned textual explanations. By
localizing lesion regions and producing expert style diagnostic narratives,
these models deliver the transparent and interpretable insights necessary for
dependable AI assisted pathology. Building on these advancements, we propose
PathMR, a cell-level Multimodal visual Reasoning framework for Pathological
image analysis. Given a pathological image and a textual query, PathMR
generates expert-level diagnostic explanations while simultaneously predicting
cell distribution patterns. To benchmark its performance, we evaluated our
approach on the publicly available PathGen dataset as well as on our newly
developed GADVR dataset. Extensive experiments on these two datasets
demonstrate that PathMR consistently outperforms state-of-the-art visual
reasoning methods in text generation quality, segmentation accuracy, and
cross-modal alignment. These results highlight the potential of PathMR for
improving interpretability in AI-driven pathological diagnosis. The code will
be publicly available in https://github.com/zhangye-zoe/PathMR.

</details>


### [82] [Deep Learning Framework for Early Detection of Pancreatic Cancer Using Multi-Modal Medical Imaging Analysis](https://arxiv.org/abs/2508.20877)
*Dennis Slobodzian,Karissa Tilbury,Amir Kordijazi*

Main category: cs.CV

TL;DR: 本研究开发了一个深度学习框架，通过双模态成像早期检测PDAC，准确率超过90%，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: PDAC是一种致死率极高的癌症，五年生存率低于10%，主要原因是晚期检测。本研究旨在通过深度学习技术早期检测PDAC。

Method: 我们开发并验证了一个深度学习框架，通过分析双模态成像（自体荧光和第二谐波生成）来检测PDAC。评估了六种不同的深度学习架构，包括传统CNN和现代ViT，最终采用改进的ResNet架构。

Result: 优化的框架在癌症检测中达到了超过90%的准确率，显著优于当前的手动分析方法。

Conclusion: 本研究建立了一个强大的自动化PDAC检测流程，能够增强病理学家的能力，并为未来扩展到其他癌症类型提供了基础。

Abstract: Pacreatic ductal adenocarcinoma (PDAC) remains one of the most lethal forms
of cancer, with a five-year survival rate below 10% primarily due to late
detection. This research develops and validates a deep learning framework for
early PDAC detection through analysis of dual-modality imaging:
autofluorescence and second harmonic generation (SHG). We analyzed 40 unique
patient samples to create a specialized neural network capable of
distinguishing between normal, fibrotic, and cancerous tissue. Our methodology
evaluated six distinct deep learning architectures, comparing traditional
Convolutional Neural Networks (CNNs) with modern Vision Transformers (ViTs).
Through systematic experimentation, we identified and overcome significant
challenges in medical image analysis, including limited dataset size and class
imbalance. The final optimized framework, based on a modified ResNet
architecture with frozen pre-trained layers and class-weighted training,
achieved over 90% accuracy in cancer detection. This represents a significant
improvement over current manual analysis methods an demonstrates potential for
clinical deployment. This work establishes a robust pipeline for automated PDAC
detection that can augment pathologists' capabilities while providing a
foundation for future expansion to other cancer types. The developed
methodology also offers valuable insights for applying deep learning to
limited-size medical imaging datasets, a common challenge in clinical
applications.

</details>


### [83] [Understanding and evaluating computer vision models through the lens of counterfactuals](https://arxiv.org/abs/2508.20881)
*Pushkar Shukla*

Main category: cs.CV

TL;DR: 论文提出了一套反事实推理框架，用于解释、审计和减轻视觉分类器和生成模型中的偏见，展示了反事实在AI公平性和可解释性中的关键作用。


<details>
  <summary>Details</summary>
Motivation: 反事实推理已成为可解释和公平AI的核心，但现有方法在系统性评估和减轻偏见方面存在不足。该论文旨在填补这一空白。

Method: 论文分为两部分：第一部分针对视觉分类器，提出了CAVLI和ASAC方法，结合归因分析和概念级分析；第二部分针对生成模型，开发了TIBET、BiasConnect和InterMit方法，用于评估和减轻偏见。

Result: 提出的方法能有效揭示虚假相关性、探测因果依赖性，并在不牺牲准确性的情况下提高模型的公平性。

Conclusion: 该论文通过反事实推理框架，为视觉分类器和生成模型提供了解释、审计和减轻偏见的系统方法，展示了反事实在可解释性、公平性和因果性中的统一作用。

Abstract: Counterfactual reasoning -- the practice of asking ``what if'' by varying
inputs and observing changes in model behavior -- has become central to
interpretable and fair AI. This thesis develops frameworks that use
counterfactuals to explain, audit, and mitigate bias in vision classifiers and
generative models. By systematically altering semantically meaningful
attributes while holding others fixed, these methods uncover spurious
correlations, probe causal dependencies, and help build more robust systems.
  The first part addresses vision classifiers. CAVLI integrates attribution
(LIME) with concept-level analysis (TCAV) to quantify how strongly decisions
rely on human-interpretable concepts. With localized heatmaps and a Concept
Dependency Score, CAVLI shows when models depend on irrelevant cues like
backgrounds. Extending this, ASAC introduces adversarial counterfactuals that
perturb protected attributes while preserving semantics. Through curriculum
learning, ASAC fine-tunes biased models for improved fairness and accuracy
while avoiding stereotype-laden artifacts.
  The second part targets generative Text-to-Image (TTI) models. TIBET provides
a scalable pipeline for evaluating prompt-sensitive biases by varying
identity-related terms, enabling causal auditing of how race, gender, and age
affect image generation. To capture interactions, BiasConnect builds causal
graphs diagnosing intersectional biases. Finally, InterMit offers a modular,
training-free algorithm that mitigates intersectional bias via causal
sensitivity scores and user-defined fairness goals.
  Together, these contributions show counterfactuals as a unifying lens for
interpretability, fairness, and causality in both discriminative and generative
models, establishing principled, scalable methods for socially responsible bias
evaluation and mitigation.

</details>


### [84] [Dino U-Net: Exploiting High-Fidelity Dense Features from Foundation Models for Medical Image Segmentation](https://arxiv.org/abs/2508.20909)
*Yifan Gao,Haoyue Li,Feng Yuan,Xiaosong Wang,Xin Gao*

Main category: cs.CV

TL;DR: Dino U-Net利用DINOv3基础模型的高保真特征，通过新架构和模块提升医学图像分割性能，实验证明其优越性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在自然图像预训练中表现强大，但如何将其学习表示有效迁移到精确的医学图像分割应用中仍具挑战性。

Method: 提出Dino U-Net，一种基于冻结DINOv3骨干的编码器-解码器架构，结合专用适配器和新的保真感知投影模块（FAPM）。

Result: 在七个公共医学图像分割数据集上的实验表明，Dino U-Net性能优于现有方法，且随着骨干模型规模增大（最大70亿参数），分割精度持续提升。

Conclusion: Dino U-Net证明了利用通用基础模型的预训练特征可以有效提升医学图像分割的准确性，且具有高度的参数效率。

Abstract: Foundation models pre-trained on large-scale natural image datasets offer a
powerful paradigm for medical image segmentation. However, effectively
transferring their learned representations for precise clinical applications
remains a challenge. In this work, we propose Dino U-Net, a novel
encoder-decoder architecture designed to exploit the high-fidelity dense
features of the DINOv3 vision foundation model. Our architecture introduces an
encoder built upon a frozen DINOv3 backbone, which employs a specialized
adapter to fuse the model's rich semantic features with low-level spatial
details. To preserve the quality of these representations during dimensionality
reduction, we design a new fidelity-aware projection module (FAPM) that
effectively refines and projects the features for the decoder. We conducted
extensive experiments on seven diverse public medical image segmentation
datasets. Our results show that Dino U-Net achieves state-of-the-art
performance, consistently outperforming previous methods across various imaging
modalities. Our framework proves to be highly scalable, with segmentation
accuracy consistently improving as the backbone model size increases up to the
7-billion-parameter variant. The findings demonstrate that leveraging the
superior, dense-pretrained features from a general-purpose foundation model
provides a highly effective and parameter-efficient approach to advance the
accuracy of medical image segmentation. The code is available at
https://github.com/yifangao112/DinoUNet.

</details>


### [85] [Classifying Mitotic Figures in the MIDOG25 Challenge with Deep Ensemble Learning and Rule Based Refinement](https://arxiv.org/abs/2508.20919)
*Sara Krauss,Ellena Spieß,Daniel Hieber,Frank Kramer,Johannes Schobel,Dominik Müller*

Main category: cs.CV

TL;DR: 该研究通过深度学习集成模型和基于规则的细化模块（RBR）改进非典型有丝分裂图像分类，结果显示集成模型表现良好，但RBR需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂图像是肿瘤分级的重要生物标志物，但区分非典型有丝分裂图像（AMFs）和正常有丝分裂图像（NMFs）困难，手动标注耗时且主观。

Method: 使用AUCMEDI训练的ConvNeXtBase模型集成，并扩展了基于规则的细化模块（RBR）。

Result: 在MIDOG25初步测试集上，集成模型的平衡准确率为84.02%。RBR提高了特异性，但降低了敏感性和整体性能。

Conclusion: 深度学习集成模型在非典型有丝分裂图像分类中表现良好，基于规则的细化模块（RBR）虽能提高特定指标，但需进一步研究。

Abstract: Mitotic figures (MFs) are relevant biomarkers in tumor grading.
Differentiating atypical MFs (AMFs) from normal MFs (NMFs) remains difficult,
as manual annotation is time-consuming and subjective. In this work an ensemble
of ConvNeXtBase models was trained with AUCMEDI and extend with a rule-based
refinement (RBR) module. On the MIDOG25 preliminary test set, the ensemble
achieved a balanced accuracy of 84.02%. While the RBR increased specificity, it
reduced sensitivity and overall performance. The results show that deep
ensembles perform well for AMF classification. RBR can increase specific
metrics but requires further research.

</details>


### [86] [Olive Tree Satellite Image Segmentation Based On SAM and Multi-Phase Refinement](https://arxiv.org/abs/2508.20954)
*Amir Jmal,Chaima Chtourou,Mahdi Louati,Abdelaziz Kallel,Houda Khmila*

Main category: cs.CV

TL;DR: 该论文提出了一种利用SAM模型和先进分割技术从卫星图像中准确分割橄榄树的方法，准确率提升至98%。


<details>
  <summary>Details</summary>
Motivation: 在气候变化的背景下，通过遥感技术早期检测和处理异常，以维护橄榄树的生物多样性。

Method: 研究采用SAM分割模型，并结合树木排列和形状大小的可学习约束进行校正。

Result: 该方法的准确率达到98%，显著超过了初始SAM模型的82%性能。

Conclusion: 该研究通过结合SAM模型和先进的分割技术，成功提高了橄榄树分割的准确性，为农业管理提供了有效的解决方案。

Abstract: In the context of proven climate change, maintaining olive biodiversity
through early anomaly detection and treatment using remote sensing technology
is crucial, offering effective management solutions. This paper presents an
innovative approach to olive tree segmentation from satellite images. By
leveraging foundational models and advanced segmentation techniques, the study
integrates the Segment Anything Model (SAM) to accurately identify and segment
olive trees in agricultural plots. The methodology includes SAM segmentation
and corrections based on trees alignement in the field and a learanble
constraint about the shape and the size. Our approach achieved a 98\% accuracy
rate, significantly surpassing the initial SAM performance of 82\%.

</details>


### [87] [E-ConvNeXt: A Lightweight and Efficient ConvNeXt Variant with Cross-Stage Partial Connections](https://arxiv.org/abs/2508.20955)
*Fang Wang,Huitao Li,Wenhan Chao,Zheng Zhuo,Yiran Ji,Chang Peng,Yupeng Sun*

Main category: cs.CV

TL;DR: E-ConvNeXt通过整合CSPNet和优化设计，显著降低ConvNeXt的复杂度，同时保持高精度，适用于轻量级应用场景。


<details>
  <summary>Details</summary>
Motivation: 高性能网络通常未考虑轻量级应用场景，限制了其应用范围。本文旨在通过优化设计，显著降低ConvNeXt的复杂度和参数规模，同时保持高精度。

Method: 1. 整合CSPNet与ConvNeXt并调整网络结构，降低模型复杂度达80%；2. 优化Stem和Block结构以增强特征表达能力和运算效率；3. 用通道注意力替换Layer Scale。

Result: E-ConvNeXt在ImageNet分类中表现优异：E-ConvNeXt-mini在0.9GFLOPs下达到78.3% Top-1准确率，E-ConvNeXt-small在3.1GFLOPs下达到81.9% Top-1准确率。目标检测任务中的迁移学习进一步验证了其泛化能力。

Conclusion: E-ConvNeXt通过整合CSPNet机制和一系列优化设计，显著降低了ConvNeXt的参数规模和网络复杂度，同时保持了高精度性能。实验验证了其在ImageNet分类和目标检测任务中的优越表现。

Abstract: Many high-performance networks were not designed with lightweight application
scenarios in mind from the outset, which has greatly restricted their scope of
application. This paper takes ConvNeXt as the research object and significantly
reduces the parameter scale and network complexity of ConvNeXt by integrating
the Cross Stage Partial Connections mechanism and a series of optimized
designs. The new network is named E-ConvNeXt, which can maintain high accuracy
performance under different complexity configurations. The three core
innovations of E-ConvNeXt are : (1) integrating the Cross Stage Partial Network
(CSPNet) with ConvNeXt and adjusting the network structure, which reduces the
model's network complexity by up to 80%; (2) Optimizing the Stem and Block
structures to enhance the model's feature expression capability and operational
efficiency; (3) Replacing Layer Scale with channel attention. Experimental
validation on ImageNet classification demonstrates E-ConvNeXt's superior
accuracy-efficiency balance: E-ConvNeXt-mini reaches 78.3% Top-1 accuracy at
0.9GFLOPs. E-ConvNeXt-small reaches 81.9% Top-1 accuracy at 3.1GFLOPs. Transfer
learning tests on object detection tasks further confirm its generalization
capability.

</details>


### [88] [DrivingGaussian++: Towards Realistic Reconstruction and Editable Simulation for Surrounding Dynamic Driving Scenes](https://arxiv.org/abs/2508.20965)
*Yajiao Xiong,Xiaoyu Zhou,Yongtao Wan,Deqing Sun,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: DrivingGaussian++ 是一个高效框架，用于动态自动驾驶场景的逼真重建和可控编辑，结合3D高斯和LiDAR先验，支持多种编辑功能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在动态场景重建和逼真环绕视图合成中的不足，支持无训练的可控编辑。

Method: 使用增量3D高斯建模静态背景，结合动态高斯图重建移动物体，并集成LiDAR先验和多视角图像深度先验。

Result: 在动态场景重建和逼真环绕视图合成中优于现有方法，支持多种编辑功能（如纹理修改、天气模拟、对象操作）。

Conclusion: DrivingGaussian++ 通过高效的动态场景重建和可控编辑，显著提升了自动驾驶场景的多样性和真实性。

Abstract: We present DrivingGaussian++, an efficient and effective framework for
realistic reconstructing and controllable editing of surrounding dynamic
autonomous driving scenes. DrivingGaussian++ models the static background using
incremental 3D Gaussians and reconstructs moving objects with a composite
dynamic Gaussian graph, ensuring accurate positions and occlusions. By
integrating a LiDAR prior, it achieves detailed and consistent scene
reconstruction, outperforming existing methods in dynamic scene reconstruction
and photorealistic surround-view synthesis. DrivingGaussian++ supports
training-free controllable editing for dynamic driving scenes, including
texture modification, weather simulation, and object manipulation, leveraging
multi-view images and depth priors. By integrating large language models (LLMs)
and controllable editing, our method can automatically generate dynamic object
motion trajectories and enhance their realism during the optimization process.
DrivingGaussian++ demonstrates consistent and realistic editing results and
generates dynamic multi-view driving scenarios, while significantly enhancing
scene diversity. More results and code can be found at the project site:
https://xiong-creator.github.io/DrivingGaussian_plus.github.io

</details>


### [89] [Webly-Supervised Image Manipulation Localization via Category-Aware Auto-Annotation](https://arxiv.org/abs/2508.20987)
*Chenfan Qu,Yiwu Zhong,Bin Li,Lianwen Jin*

Main category: cs.CV

TL;DR: 通过CAAAv2和QES构建大规模数据集MIMLv2，开发Web-IML模型显著提升图像篡改定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决图像篡改区域定位中的数据稀缺和高成本问题。

Method: 利用网络数据和自动生成的注释构建大规模数据集MIMLv2，并引入Object Jitter技术增强模型训练。开发Web-IML模型以有效利用网络规模监督。

Result: Web-IML模型在性能上提升了31%，超过了之前的最优方法TruFor 24.1个平均IoU点。

Conclusion: 该研究通过CAAAv2和QES技术构建了MIMLv2数据集，显著缓解了数据稀缺问题，并开发了Web-IML模型，在多个真实伪造基准测试中取得了显著性能提升。

Abstract: Images manipulated using image editing tools can mislead viewers and pose
significant risks to social security. However, accurately localizing the
manipulated regions within an image remains a challenging problem. One of the
main barriers in this area is the high cost of data acquisition and the severe
lack of high-quality annotated datasets. To address this challenge, we
introduce novel methods that mitigate data scarcity by leveraging readily
available web data. We utilize a large collection of manually forged images
from the web, as well as automatically generated annotations derived from a
simpler auxiliary task, constrained image manipulation localization.
Specifically, we introduce a new paradigm CAAAv2, which automatically and
accurately annotates manipulated regions at the pixel level. To further improve
annotation quality, we propose a novel metric, QES, which filters out
unreliable annotations. Through CAAA v2 and QES, we construct MIMLv2, a
large-scale, diverse, and high-quality dataset containing 246,212 manually
forged images with pixel-level mask annotations. This is over 120x larger than
existing handcrafted datasets like IMD20. Additionally, we introduce Object
Jitter, a technique that further enhances model training by generating
high-quality manipulation artifacts. Building on these advances, we develop a
new model, Web-IML, designed to effectively leverage web-scale supervision for
the image manipulation localization task. Extensive experiments demonstrate
that our approach substantially alleviates the data scarcity problem and
significantly improves the performance of various models on multiple real-world
forgery benchmarks. With the proposed web supervision, Web-IML achieves a
striking performance gain of 31% and surpasses previous SOTA TruFor by 24.1
average IoU points. The dataset and code will be made publicly available at
https://github.com/qcf-568/MIML.

</details>


### [90] [POSE: Phased One-Step Adversarial Equilibrium for Video Diffusion Models](https://arxiv.org/abs/2508.21019)
*Jiaxiang Cheng,Bing Ma,Xuhua Ren,Hongyi Jin,Kai Yu,Peng Zhang,Wenyue Li,Yuan Zhou,Tianxiang Zheng,Qinglin Lu*

Main category: cs.CV

TL;DR: POSE是一种单步蒸馏框架，通过两阶段过程提升视频扩散模型的采样效率，实验显示其在质量和速度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频加速方法无法有效建模视频帧的时间一致性，且不适用于大规模视频模型的单步蒸馏，POSE旨在解决这些问题。

Method: POSE采用稳定性引导和统一对抗平衡的两阶段蒸馏过程，结合条件对抗一致性方法，优化视频生成的质量和效率。

Result: POSE在VBench-I2V上平均提升7.15%的语义对齐、时间一致性和帧质量，同时将预训练模型的延迟从1000秒降至10秒。

Conclusion: POSE框架通过两阶段蒸馏过程显著提升了大规模视频扩散模型的采样效率，实现了单步高质量视频生成，并在实验中优于现有加速方法。

Abstract: The field of video diffusion generation faces critical bottlenecks in
sampling efficiency, especially for large-scale models and long sequences.
Existing video acceleration methods adopt image-based techniques but suffer
from fundamental limitations: they neither model the temporal coherence of
video frames nor provide single-step distillation for large-scale video models.
To bridge this gap, we propose POSE (Phased One-Step Equilibrium), a
distillation framework that reduces the sampling steps of large-scale video
diffusion models, enabling the generation of high-quality videos in a single
step. POSE employs a carefully designed two-phase process to distill video
models:(i) stability priming: a warm-up mechanism to stabilize adversarial
distillation that adapts the high-quality trajectory of the one-step generator
from high to low signal-to-noise ratio regimes, optimizing the video quality of
single-step mappings near the endpoints of flow trajectories. (ii) unified
adversarial equilibrium: a flexible self-adversarial distillation mechanism
that promotes stable single-step adversarial training towards a Nash
equilibrium within the Gaussian noise space, generating realistic single-step
videos close to real videos. For conditional video generation, we propose (iii)
conditional adversarial consistency, a method to improve both semantic
consistency and frame consistency between conditional frames and generated
frames. Comprehensive experiments demonstrate that POSE outperforms other
acceleration methods on VBench-I2V by average 7.15% in semantic alignment,
temporal conference and frame quality, reducing the latency of the pre-trained
model by 100$\times$, from 1000 seconds to 10 seconds, while maintaining
competitive performance.

</details>


### [91] [Reusing Computation in Text-to-Image Diffusion for Efficient Generation of Image Sets](https://arxiv.org/abs/2508.21032)
*Dale Decatur,Thibault Groueix,Wang Yifan,Rana Hanocka,Vladimir Kim,Matheus Gadelha*

Main category: cs.CV

TL;DR: 通过聚类相似提示并共享早期扩散步骤计算，该方法降低了文本到图像生成的计算成本并提升质量。


<details>
  <summary>Details</summary>
Motivation: 探索减少相关提示之间的冗余，以优化文本到图像扩散模型的效率。

Method: 提出了一种无训练方法，基于语义相似性对提示进行聚类，并在早期扩散步骤中共享计算。

Result: 实验表明，该方法显著降低了计算成本，同时提高了图像质量。

Conclusion: 该方法通过共享相似提示的早期扩散步骤计算，显著降低了计算成本并提高了图像质量，同时与现有流程无缝集成，减轻了大规模文本到图像生成的环境和财务负担。

Abstract: Text-to-image diffusion models enable high-quality image generation but are
computationally expensive. While prior work optimizes per-inference efficiency,
we explore an orthogonal approach: reducing redundancy across correlated
prompts. Our method leverages the coarse-to-fine nature of diffusion models,
where early denoising steps capture shared structures among similar prompts. We
propose a training-free approach that clusters prompts based on semantic
similarity and shares computation in early diffusion steps. Experiments show
that for models trained conditioned on image embeddings, our approach
significantly reduces compute cost while improving image quality. By leveraging
UnClip's text-to-image prior, we enhance diffusion step allocation for greater
efficiency. Our method seamlessly integrates with existing pipelines, scales
with prompt sets, and reduces the environmental and financial burden of
large-scale text-to-image generation. Project page:
https://ddecatur.github.io/hierarchical-diffusion/

</details>


### [92] [Mitosis detection in domain shift scenarios: a Mamba-based approach](https://arxiv.org/abs/2508.21033)
*Gennaro Percannella,Mattia Sarno,Francesco Tortorella,Mario Vento*

Main category: cs.CV

TL;DR: 提出一种基于Mamba的VM-UNet方法，结合染色增强，用于核分裂检测的域偏移问题，初步实验显示有改进潜力。


<details>
  <summary>Details</summary>
Motivation: 核分裂检测在肿瘤评估中至关重要，但现有机器学习算法在跨域图像上性能显著下降。为解决这一问题，受Mamba在医学图像分割任务中的优异表现启发，提出了该方法。

Method: 采用基于Mamba的VM-UNet架构，结合染色增强操作，以提高模型在域偏移情况下的鲁棒性。

Result: 在MIDOG++数据集上的初步实验表明，该方法仍有较大改进空间。

Conclusion: 尽管初步实验显示提出的方法在MIDOG++数据集上仍有较大改进空间，但基于Mamba的方法结合VM-UNet架构和染色增强操作，为应对域偏移的核分裂检测任务提供了有潜力的解决方案。

Abstract: Mitosis detection in histopathology images plays a key role in tumor
assessment. Although machine learning algorithms could be exploited for aiding
physicians in accurately performing such a task, these algorithms suffer from
significative performance drop when evaluated on images coming from domains
that are different from the training ones. In this work, we propose a
Mamba-based approach for mitosis detection under domain shift, inspired by the
promising performance demonstrated by Mamba in medical imaging segmentation
tasks. Specifically, our approach exploits a VM-UNet architecture for carrying
out the addressed task, as well as stain augmentation operations for further
improving model robustness against domain shift. Our approach has been
submitted to the track 1 of the MItosis DOmain Generalization (MIDOG)
challenge. Preliminary experiments, conducted on the MIDOG++ dataset, show
large room for improvement for the proposed method.

</details>


### [93] [A multi-task neural network for atypical mitosis recognition under domain shift](https://arxiv.org/abs/2508.21035)
*Gennaro Percannella,Mattia Sarno,Francesco Tortorella,Mario Vento*

Main category: cs.CV

TL;DR: 该论文提出一种多任务学习方法，用于解决组织病理学图像分类中的领域偏移问题，初步评估显示其在多个数据集上表现良好。


<details>
  <summary>Details</summary>
Motivation: 识别组织病理学图像中的非典型有丝分裂图形有助于医生准确评估肿瘤的侵袭性，但机器学习模型在领域偏移下性能显著下降。

Method: 采用多任务学习方法，利用与主要分类任务相关的辅助任务来解决领域偏移问题。

Result: 在三个不同数据集（MIDOG 2025非典型训练集、Ami-Br数据集和MIDOG25挑战的初步测试集）上的初步评估显示该方法表现良好。

Conclusion: 该论文提出的多任务学习方法在初步评估中显示出有希望的成果，能够帮助模型专注于分类对象而忽略图像中变化的背景。

Abstract: Recognizing atypical mitotic figures in histopathology images allows
physicians to correctly assess tumor aggressiveness. Although machine learning
models could be exploited for automatically performing such a task, under
domain shift these models suffer from significative performance drops. In this
work, an approach based on multi-task learning is proposed for addressing this
problem. By exploiting auxiliary tasks, correlated to the main classification
task, the proposed approach, submitted to the track 2 of the MItosis DOmain
Generalization (MIDOG) challenge, aims to aid the model to focus only on the
object to classify, ignoring the domain varying background of the image. The
proposed approach shows promising performance in a preliminary evaluation
conducted on three distinct datasets, i.e., the MIDOG 2025 Atypical Training
Set, the Ami-Br dataset, as well as the preliminary test set of the MIDOG25
challenge.

</details>


### [94] [FW-GAN: Frequency-Driven Handwriting Synthesis with Wave-Modulated MLP Generator](https://arxiv.org/abs/2508.21040)
*Huynh Tong Dang Khoa,Dang Hoai Nam,Vo Nguyen Le Duy*

Main category: cs.CV

TL;DR: FW-GAN是一种新型手写体合成框架，通过频率引导和相位感知技术生成高质量手写体，有效解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有手写体合成方法在建模长距离依赖和复杂笔画模式上的不足，以及忽视频率信息在捕捉细粒度风格和结构细节中的关键作用。

Method: 提出FW-GAN框架，包括相位感知的Wave-MLP生成器和频率引导的鉴别器，并引入频率分布损失（Frequency Distribution Loss）来对齐合成与真实手写体的频率特征。

Result: 在越南语和英语手写体数据集上的实验表明，FW-GAN能够生成高质量、风格一致的手写体。

Conclusion: FW-GAN通过整合相位感知的Wave-MLP和频率引导的鉴别器，成功生成了高质量、风格一致的手写体，为低资源手写识别（HTR）管道提供了有效的数据增强工具。

Abstract: Labeled handwriting data is often scarce, limiting the effectiveness of
recognition systems that require diverse, style-consistent training samples.
Handwriting synthesis offers a promising solution by generating artificial data
to augment training. However, current methods face two major limitations.
First, most are built on conventional convolutional architectures, which
struggle to model long-range dependencies and complex stroke patterns. Second,
they largely ignore the crucial role of frequency information, which is
essential for capturing fine-grained stylistic and structural details in
handwriting. To address these challenges, we propose FW-GAN, a one-shot
handwriting synthesis framework that generates realistic, writer-consistent
text from a single example. Our generator integrates a phase-aware Wave-MLP to
better capture spatial relationships while preserving subtle stylistic cues. We
further introduce a frequency-guided discriminator that leverages
high-frequency components to enhance the authenticity detection of generated
samples. Additionally, we introduce a novel Frequency Distribution Loss that
aligns the frequency characteristics of synthetic and real handwriting, thereby
enhancing visual fidelity. Experiments on Vietnamese and English handwriting
datasets demonstrate that FW-GAN generates high-quality, style-consistent
handwriting, making it a valuable tool for augmenting data in low-resource
handwriting recognition (HTR) pipelines. Official implementation is available
at https://github.com/DAIR-Group/FW-GAN

</details>


### [95] [MMG-Vid: Maximizing Marginal Gains at Segment-level and Token-level for Efficient Video LLMs](https://arxiv.org/abs/2508.21044)
*Junpeng Ma,Qizhe Zhang,Ming Lu,Zhibin Wang,Qiang Zhou,Jun Song,Shanghang Zhang*

Main category: cs.CV

TL;DR: MMG-Vid是一种无需训练的视觉令牌修剪框架，通过最大化边际增益显著提升视频大语言模型的效率，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型（VLLMs）在视频理解中面临视觉令牌过多导致的计算效率问题，现有方法未充分考虑视频帧的动态特性和时间依赖性。

Method: MMG-Vid是一个无需训练的视觉令牌修剪框架，通过将视频分段并动态分配令牌预算，以及使用时间引导的DPC算法来最大化每个令牌的边际增益。

Result: 实验表明，MMG-Vid在LLaVA-OneVision-7B上减少了75%的视觉令牌，加速了预填充阶段3.9倍，同时保持了99.5%的原始性能。

Conclusion: MMG-Vid通过最大化边际增益的方法，显著提高了视频大语言模型的推理效率，同时保持了99.5%的原始性能，减少了75%的视觉令牌并加速了预填充阶段。

Abstract: Video Large Language Models (VLLMs) excel in video understanding, but their
excessive visual tokens pose a significant computational challenge for
real-world applications. Current methods aim to enhance inference efficiency by
visual token pruning. However, they do not consider the dynamic characteristics
and temporal dependencies of video frames, as they perceive video understanding
as a multi-frame task. To address these challenges, we propose MMG-Vid, a novel
training-free visual token pruning framework that removes redundancy by
Maximizing Marginal Gains at both segment-level and token-level. Specifically,
we first divide the video into segments based on frame similarity, and then
dynamically allocate the token budget for each segment to maximize the marginal
gain of each segment. Subsequently, we propose a temporal-guided DPC algorithm
that jointly models inter-frame uniqueness and intra-frame diversity, thereby
maximizing the marginal gain of each token. By combining both stages, MMG-Vid
can maximize the utilization of the limited token budget, significantly
improving efficiency while maintaining strong performance. Extensive
experiments demonstrate that MMG-Vid can maintain over 99.5% of the original
performance, while effectively reducing 75% visual tokens and accelerating the
prefilling stage by 3.9x on LLaVA-OneVision-7B. Code will be released soon.

</details>


### [96] [Multi-View 3D Point Tracking](https://arxiv.org/abs/2508.21060)
*Frano Rajič,Haofei Xu,Marko Mihajlovic,Siyuan Li,Irem Demir,Emircan Gündoğdu,Lei Ke,Sergey Prokudin,Marc Pollefeys,Siyu Tang*

Main category: cs.CV

TL;DR: 提出首个数据驱动的多视角3D点跟踪器，通过少量摄像头实现高效、精确的在线跟踪，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有单目跟踪器在深度模糊和遮挡问题上的不足，以及多相机方法需大量摄像头和繁琐优化的局限性，提出一种更高效、实用的多视角3D跟踪方案。

Method: 该方法通过融合多视角特征到统一点云，并应用k近邻相关性和基于Transformer的更新机制，实现了长距离3D对应关系的可靠估计。

Result: 在Panoptic Studio和DexYCB两个真实世界基准测试中，分别实现了3.1厘米和2.0厘米的中位轨迹误差，且能泛化到1-8个视角的不同相机配置。

Conclusion: 该论文提出了一种新型数据驱动的多视角3D点跟踪器，能够在动态场景中稳定跟踪任意点，相较于现有方法在精度和鲁棒性上有显著提升，并提供了实用的工具和数据集以推动相关研究。

Abstract: We introduce the first data-driven multi-view 3D point tracker, designed to
track arbitrary points in dynamic scenes using multiple camera views. Unlike
existing monocular trackers, which struggle with depth ambiguities and
occlusion, or prior multi-camera methods that require over 20 cameras and
tedious per-sequence optimization, our feed-forward model directly predicts 3D
correspondences using a practical number of cameras (e.g., four), enabling
robust and accurate online tracking. Given known camera poses and either
sensor-based or estimated multi-view depth, our tracker fuses multi-view
features into a unified point cloud and applies k-nearest-neighbors correlation
alongside a transformer-based update to reliably estimate long-range 3D
correspondences, even under occlusion. We train on 5K synthetic multi-view
Kubric sequences and evaluate on two real-world benchmarks: Panoptic Studio and
DexYCB, achieving median trajectory errors of 3.1 cm and 2.0 cm, respectively.
Our method generalizes well to diverse camera setups of 1-8 views with varying
vantage points and video lengths of 24-150 frames. By releasing our tracker
alongside training and evaluation datasets, we aim to set a new standard for
multi-view 3D tracking research and provide a practical tool for real-world
applications. Project page available at https://ethz-vlg.github.io/mvtracker.

</details>


### [97] [OneReward: Unified Mask-Guided Image Generation via Multi-Task Human Preference Learning](https://arxiv.org/abs/2508.21066)
*Yuan Gong,Xionghui Wang,Jie Wu,Shiyin Wang,Yitong Wang,Xinglong Wu*

Main category: cs.CV

TL;DR: OneReward是一个统一的强化学习框架，通过单一奖励模型提升多任务生成能力，其应用实例Seedream 3.0 Fill在多项任务中超越竞争对手。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因依赖任务特定监督微调而导致的泛化能力和训练效率受限的问题。

Method: 采用统一的视觉语言模型（VLM）作为生成奖励模型，通过多任务强化学习直接训练预训练基础模型，避免了任务特定的监督微调（SFT）。

Result: 实验证明，OneReward框架下的Seedream 3.0 Fill在多项任务中表现优于商业和开源竞争对手。

Conclusion: OneReward框架通过单一奖励模型显著提升了多任务生成模型的性能，特别是在多样化的数据和任务目标下。Seedream 3.0 Fill作为其应用实例，在多项评价维度上超越了现有商业和开源解决方案。

Abstract: In this paper, we introduce OneReward, a unified reinforcement learning
framework that enhances the model's generative capabilities across multiple
tasks under different evaluation criteria using only \textit{One Reward} model.
By employing a single vision-language model (VLM) as the generative reward
model, which can distinguish the winner and loser for a given task and a given
evaluation criterion, it can be effectively applied to multi-task generation
models, particularly in contexts with varied data and diverse task objectives.
We utilize OneReward for mask-guided image generation, which can be further
divided into several sub-tasks such as image fill, image extend, object
removal, and text rendering, involving a binary mask as the edit area. Although
these domain-specific tasks share same conditioning paradigm, they differ
significantly in underlying data distributions and evaluation metrics. Existing
methods often rely on task-specific supervised fine-tuning (SFT), which limits
generalization and training efficiency. Building on OneReward, we develop
Seedream 3.0 Fill, a mask-guided generation model trained via multi-task
reinforcement learning directly on a pre-trained base model, eliminating the
need for task-specific SFT. Experimental results demonstrate that our unified
edit model consistently outperforms both commercial and open-source
competitors, such as Ideogram, Adobe Photoshop, and FLUX Fill [Pro], across
multiple evaluation dimensions. Code and model are available at:
https://one-reward.github.io

</details>


### [98] [Dress&Dance: Dress up and Dance as You Like It - Technical Preview](https://arxiv.org/abs/2508.21070)
*Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: Dress&Dance通过CondNet和多阶段训练，生成高质量虚拟试衣视频，支持多种服装类型，优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 解决现有虚拟试衣视频生成在服装注册和运动保真度方面的不足，提升用户体验。

Method: 采用CondNet，一种利用注意力机制统一多模态输入（文本、图像、视频）的新型条件网络，结合多阶段渐进训练方法。

Result: 生成高质量、5秒长、24 FPS、1152x720分辨率的试衣视频，优于现有开源和商业解决方案。

Conclusion: Dress&Dance框架在虚拟试衣视频生成方面表现优异，支持多种服装类型和高质量输出。

Abstract: We present Dress&Dance, a video diffusion framework that generates high
quality 5-second-long 24 FPS virtual try-on videos at 1152x720 resolution of a
user wearing desired garments while moving in accordance with a given reference
video. Our approach requires a single user image and supports a range of tops,
bottoms, and one-piece garments, as well as simultaneous tops and bottoms
try-on in a single pass. Key to our framework is CondNet, a novel conditioning
network that leverages attention to unify multi-modal inputs (text, images, and
videos), thereby enhancing garment registration and motion fidelity. CondNet is
trained on heterogeneous training data, combining limited video data and a
larger, more readily available image dataset, in a multistage progressive
manner. Dress&Dance outperforms existing open source and commercial solutions
and enables a high quality and flexible try-on experience.

</details>


### [99] [First-Place Solution to NeurIPS 2024 Invisible Watermark Removal Challenge](https://arxiv.org/abs/2508.21072)
*Fahad Shamshad,Tameem Bakr,Yahia Shaaban,Noor Hussein,Karthik Nandakumar,Nils Lukas*

Main category: cs.CV

TL;DR: 本文提出了两种针对不同水印攻击场景的方法，分别基于VAE和扩散模型，成功实现了高效水印去除，旨在推动更鲁棒水印技术的发展。


<details>
  <summary>Details</summary>
Motivation: 探讨现有水印在对抗攻击下的鲁棒性，解决数字媒体认证和版权保护中的水印脆弱性问题。

Method: 对于beige-box赛道，采用基于自适应VAE的规避攻击，结合测试时优化和CIELAB空间的颜色对比恢复；对于black-box赛道，首先基于空间或频域伪影对图像进行聚类，然后应用图像到图像的扩散模型，结合可控噪声注入和ChatGPT生成标题的语义先验。

Result: 实证评估表明，该方法在几乎不影响残余图像质量的情况下，实现了接近完美的水印去除（95.7%）。

Conclusion: 本文希望通过提出的攻击方法，激发更鲁棒的图像水印技术的发展。

Abstract: Content watermarking is an important tool for the authentication and
copyright protection of digital media. However, it is unclear whether existing
watermarks are robust against adversarial attacks. We present the winning
solution to the NeurIPS 2024 Erasing the Invisible challenge, which
stress-tests watermark robustness under varying degrees of adversary knowledge.
The challenge consisted of two tracks: a black-box and beige-box track,
depending on whether the adversary knows which watermarking method was used by
the provider. For the beige-box track, we leverage an adaptive VAE-based
evasion attack, with a test-time optimization and color-contrast restoration in
CIELAB space to preserve the image's quality. For the black-box track, we first
cluster images based on their artifacts in the spatial or frequency-domain.
Then, we apply image-to-image diffusion models with controlled noise injection
and semantic priors from ChatGPT-generated captions to each cluster with
optimized parameter settings. Empirical evaluations demonstrate that our method
successfully achieves near-perfect watermark removal (95.7%) with negligible
impact on the residual image's quality. We hope that our attacks inspire the
development of more robust image watermarking methods.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [100] [Mixture of Contexts for Long Video Generation](https://arxiv.org/abs/2508.21058)
*Shengqu Cai,Ceyuan Yang,Lvmin Zhang,Yuwei Guo,Junfei Xiao,Ziyan Yang,Yinghao Xu,Zhenheng Yang,Alan Yuille,Leonidas Guibas,Maneesh Agrawala,Lu Jiang,Gordon Wetzstein*

Main category: cs.GR

TL;DR: MoC 是一种稀疏注意力路由模块，通过动态选择信息块和强制锚点，解决了长视频生成的上下文记忆问题，实现了高效且一致的分钟级视频生成。


<details>
  <summary>Details</summary>
Motivation: 长视频生成面临长上下文记忆问题，传统自注意力机制因二次成本难以扩展。

Method: 提出了一种可学习的稀疏注意力路由模块 MoC，动态选择信息块和强制锚点进行注意力计算，避免循环闭合。

Result: MoC 实现了近线性扩展，支持分钟级视频生成，保持了身份、动作和场景的一致性。

Conclusion: Mixture of Contexts (MoC) 通过动态选择信息块和强制锚点，实现了高效的长上下文视频生成，解决了传统自注意力机制的二次成本问题。

Abstract: Long video generation is fundamentally a long context memory problem: models
must retain and retrieve salient events across a long range without collapsing
or drifting. However, scaling diffusion transformers to generate long-context
videos is fundamentally limited by the quadratic cost of self-attention, which
makes memory and computation intractable and difficult to optimize for long
sequences. We recast long-context video generation as an internal information
retrieval task and propose a simple, learnable sparse attention routing module,
Mixture of Contexts (MoC), as an effective long-term memory retrieval engine.
In MoC, each query dynamically selects a few informative chunks plus mandatory
anchors (caption, local windows) to attend to, with causal routing that
prevents loop closures. As we scale the data and gradually sparsify the
routing, the model allocates compute to salient history, preserving identities,
actions, and scenes over minutes of content. Efficiency follows as a byproduct
of retrieval (near-linear scaling), which enables practical training and
synthesis, and the emergence of memory and consistency at the scale of minutes.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [101] [Learning Fast, Tool aware Collision Avoidance for Collaborative Robots](https://arxiv.org/abs/2508.20457)
*Joonho Lee,Yunho Kim,Seokjoon Kim,Quan Nguyen,Youngjin Heo*

Main category: cs.RO

TL;DR: 本文提出了一种工具感知的实时碰撞避免系统，通过学习感知模型和约束强化学习，在动态环境中实现高效、精确的避障，计算成本显著降低。


<details>
  <summary>Details</summary>
Motivation: 当前机器人控制器通常假设完全可见性和固定工具，这在动态环境中可能导致碰撞或过于保守的行为。因此，需要一种能够实时调整工具尺寸和交互模式的碰撞避免系统。

Method: 使用学习感知模型过滤点云中的机器人和工具组件，推理遮挡区域，并在部分可观测性下预测碰撞。通过约束强化学习训练的控制策略在10毫秒内生成平滑的避障动作。

Result: 在模拟和真实环境测试中，该方法在动态环境中优于传统方法（APF、MPPI），计算成本比基于GPU的最先进规划器低约60%。

Conclusion: 本文提出的工具感知碰撞避免系统在动态环境中表现出色，不仅保持了亚毫米级的精度，还显著降低了计算成本，为协作机器人的安全高效操作提供了模块化且有效的解决方案。

Abstract: Ensuring safe and efficient operation of collaborative robots in human
environments is challenging, especially in dynamic settings where both obstacle
motion and tasks change over time. Current robot controllers typically assume
full visibility and fixed tools, which can lead to collisions or overly
conservative behavior. In our work, we introduce a tool-aware collision
avoidance system that adjusts in real time to different tool sizes and modes of
tool-environment interaction. Using a learned perception model, our system
filters out robot and tool components from the point cloud, reasons about
occluded area, and predicts collision under partial observability. We then use
a control policy trained via constrained reinforcement learning to produce
smooth avoidance maneuvers in under 10 milliseconds. In simulated and
real-world tests, our approach outperforms traditional approaches (APF, MPPI)
in dynamic environments, while maintaining sub-millimeter accuracy. Moreover,
our system operates with approximately 60% lower computational cost compared to
a state-of-the-art GPU-based planner. Our approach provides modular, efficient,
and effective collision avoidance for robots operating in dynamic environments.
We integrate our method into a collaborative robot application and demonstrate
its practical use for safe and responsive operation.

</details>


### [102] [SPGrasp: Spatiotemporal Prompt-driven Grasp Synthesis in Dynamic Scenes](https://arxiv.org/abs/2508.20547)
*Yunpeng Mei,Hongjie Cao,Yinqiu Xia,Wei Xiao,Zhaohan Feng,Gang Wang,Jie Chen*

Main category: cs.RO

TL;DR: SPGrasp通过整合用户提示与时空上下文，实现了动态物体抓取的实时低延迟交互，显著提升了准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态物体的实时交互抓取合成中无法同时实现低延迟推理和提示性，SPGrasp旨在填补这一空白。

Method: SPGrasp扩展了SAMv2模型，通过整合用户提示与时空上下文，实现了实时交互和端到端低延迟（最低59毫秒）。

Result: 在OCID和Jacquard数据集上分别达到90.6%和93.8%的抓取准确率；在GraspNet-1Billion数据集上，以73.1毫秒每帧的延迟实现92.0%的准确率，比RoG-SAM延迟降低58.5%。实际实验中，13个移动物体的交互抓取成功率为94.8%。

Conclusion: SPGrasp有效解决了动态抓取合成中的延迟与交互性之间的权衡问题，在多个数据集中表现出色，并在实际实验中实现了94.8%的成功率。

Abstract: Real-time interactive grasp synthesis for dynamic objects remains challenging
as existing methods fail to achieve low-latency inference while maintaining
promptability. To bridge this gap, we propose SPGrasp (spatiotemporal
prompt-driven dynamic grasp synthesis), a novel framework extending segment
anything model v2 (SAMv2) for video stream grasp estimation. Our core
innovation integrates user prompts with spatiotemporal context, enabling
real-time interaction with end-to-end latency as low as 59 ms while ensuring
temporal consistency for dynamic objects. In benchmark evaluations, SPGrasp
achieves instance-level grasp accuracies of 90.6% on OCID and 93.8% on
Jacquard. On the challenging GraspNet-1Billion dataset under continuous
tracking, SPGrasp achieves 92.0% accuracy with 73.1 ms per-frame latency,
representing a 58.5% reduction compared to the prior state-of-the-art
promptable method RoG-SAM while maintaining competitive accuracy. Real-world
experiments involving 13 moving objects demonstrate a 94.8% success rate in
interactive grasping scenarios. These results confirm SPGrasp effectively
resolves the latency-interactivity trade-off in dynamic grasp synthesis. Code
is available at https://github.com/sejmoonwei/SPGrasp.

</details>


### [103] [Task-Oriented Edge-Assisted Cross-System Design for Real-Time Human-Robot Interaction in Industrial Metaverse](https://arxiv.org/abs/2508.20664)
*Kan Chen,Zhen Meng,Xiangmin Xu,Jiaming Yang,Emma Li,Philip G. Zhao*

Main category: cs.RO

TL;DR: 本文提出了一种基于数字孪生的边缘辅助框架，通过预测操作员动作优化工业元宇宙中的实时交互，显著提升了空间精度和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 工业元宇宙中的人机交互面临高计算负载、有限带宽和严格延迟等挑战。

Method: 提出了一个基于数字孪生的任务导向边缘辅助跨系统框架，通过预测操作员动作实现前瞻性渲染和远程设备预控制。数字孪生被解耦为视觉显示和机器人控制两个虚拟功能。

Result: 在轨迹绘制控制任务中，加权RMSE从0.0712米降至0.0101米；在核退役的实时3D场景表示任务中，PSNR为22.11，SSIM为0.8729，LPIPS为0.1298。

Conclusion: 该框架通过数字孪生和HITL-MAML算法，在实时高风险的工业环境中确保了空间精度和视觉保真度，验证了其有效性。

Abstract: Real-time human-device interaction in industrial Metaverse faces challenges
such as high computational load, limited bandwidth, and strict latency. This
paper proposes a task-oriented edge-assisted cross-system framework using
digital twins (DTs) to enable responsive interactions. By predicting operator
motions, the system supports: 1) proactive Metaverse rendering for visual
feedback, and 2) preemptive control of remote devices. The DTs are decoupled
into two virtual functions-visual display and robotic control-optimizing both
performance and adaptability. To enhance generalizability, we introduce the
Human-In-The-Loop Model-Agnostic Meta-Learning (HITL-MAML) algorithm, which
dynamically adjusts prediction horizons. Evaluation on two tasks demonstrates
the framework's effectiveness: in a Trajectory-Based Drawing Control task, it
reduces weighted RMSE from 0.0712 m to 0.0101 m; in a real-time 3D scene
representation task for nuclear decommissioning, it achieves a PSNR of 22.11,
SSIM of 0.8729, and LPIPS of 0.1298. These results show the framework's
capability to ensure spatial precision and visual fidelity in real-time,
high-risk industrial environments.

</details>


### [104] [SimShear: Sim-to-Real Shear-based Tactile Servoing](https://arxiv.org/abs/2508.20561)
*Kipp McAdam Freud,Yijiong Lin,Nathan F. Lepora*

Main category: cs.RO

TL;DR: SimShear通过shPix2pix实现剪切力模拟，提升触觉图像和预测性能，应用于桌面机器人臂任务，验证了刚性模拟器中剪切建模的可行性。


<details>
  <summary>Details</summary>
Motivation: 剪切力在动态物体交互任务中至关重要，但模拟剪切动力学仍具挑战性。

Method: 引入shPix2pix，一种剪切条件化的U-Net GAN，将不含剪切力的模拟触觉图像与剪切信息编码向量转换为具有剪切变形的真实等效图像。

Result: SimShear在模拟触觉图像和姿态/剪切预测方面优于基线pix2pix方法，并在两个控制任务中实现1至2毫米的接触误差。

Conclusion: SimShear验证了在刚性体模拟器中实现剪切力建模的可行性，为触觉机器人的模拟开辟了新方向。

Abstract: We present SimShear, a sim-to-real pipeline for tactile control that enables
the use of shear information without explicitly modeling shear dynamics in
simulation. Shear, arising from lateral movements across contact surfaces, is
critical for tasks involving dynamic object interactions but remains
challenging to simulate. To address this, we introduce shPix2pix, a
shear-conditioned U-Net GAN that transforms simulated tactile images absent of
shear, together with a vector encoding shear information, into realistic
equivalents with shear deformations. This method outperforms baseline pix2pix
approaches in simulating tactile images and in pose/shear prediction. We apply
SimShear to two control tasks using a pair of low-cost desktop robotic arms
equipped with a vision-based tactile sensor: (i) a tactile tracking task, where
a follower arm tracks a surface moved by a leader arm, and (ii) a collaborative
co-lifting task, where both arms jointly hold an object while the leader
follows a prescribed trajectory. Our method maintains contact errors within 1
to 2 mm across varied trajectories where shear sensing is essential, validating
the feasibility of sim-to-real shear modeling with rigid-body simulators and
opening new directions for simulation in tactile robotics.

</details>


### [105] [Traversing the Narrow Path: A Two-Stage Reinforcement Learning Framework for Humanoid Beam Walking](https://arxiv.org/abs/2508.20661)
*TianChen Huang,Wei Gao,Runchen Xu,Shiwu Zhang*

Main category: cs.RO

TL;DR: 提出一个两阶段框架，通过结合步态模板和残差规划器，使人形机器人能够在狭窄梁上稳定行走，仿真和实际测试中表现优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 由于稀疏、安全关键的接触和纯学习策略的脆弱性，人形机器人在狭窄梁上行走具有挑战性。

Method: 提出了一个物理基础的两阶段框架，结合了XCoM/LIPM步态模板与轻量级残差规划器和简单的低级跟踪器。第一阶段在平地上训练跟踪器，第二阶段在模拟的梁上训练高级规划器。

Result: 在Unitree G1上，该系统可靠地穿越了0.2米宽、3米长的梁。

Conclusion: 在仿真和现实研究中，残差细化方法在成功率、中心线遵循和安全裕度方面一致优于仅使用模板和整体基准方法，而结构化的步态接口支持透明的分析和低摩擦的仿真到实际转移。

Abstract: Traversing narrow beams is challenging for humanoids due to sparse,
safety-critical contacts and the fragility of purely learned policies. We
propose a physically grounded, two-stage framework that couples an XCoM/LIPM
footstep template with a lightweight residual planner and a simple low-level
tracker. Stage-1 is trained on flat ground: the tracker learns to robustly
follow footstep targets by adding small random perturbations to heuristic
footsteps, without any hand-crafted centerline locking, so it acquires stable
contact scheduling and strong target-tracking robustness. Stage-2 is trained in
simulation on a beam: a high-level planner predicts a body-frame residual
(Delta x, Delta y, Delta psi) for the swing foot only, refining the template
step to prioritize safe, precise placement under narrow support while
preserving interpretability. To ease deployment, sensing is kept minimal and
consistent between simulation and hardware: the planner consumes compact,
forward-facing elevation cues together with onboard IMU and joint signals. On a
Unitree G1, our system reliably traverses a 0.2 m-wide, 3 m-long beam. Across
simulation and real-world studies, residual refinement consistently outperforms
template-only and monolithic baselines in success rate, centerline adherence,
and safety margins, while the structured footstep interface enables transparent
analysis and low-friction sim-to-real transfer.

</details>


### [106] [Task Allocation for Autonomous Machines using Computational Intelligence and Deep Reinforcement Learning](https://arxiv.org/abs/2508.20688)
*Thanh Thi Nguyen,Quoc Viet Hung Nguyen,Jonathan Kua,Imran Razzak,Dung Nguyen,Saeid Nahavandi*

Main category: cs.RO

TL;DR: 本文综述了用于控制和协调自主机器的算法，特别关注CI和深度RL方法，分析了其优缺点，并提出了未来研究方向，指出深度RL是当前趋势。


<details>
  <summary>Details</summary>
Motivation: 开发高效的协作控制算法以实现多个自主机器的可靠性能是本文的主要动机。

Method: 本文对控制和协调复杂环境中自主机器的高效协作控制算法进行了综述，特别关注使用计算智能（CI）和深度强化学习（RL）的任务分配方法。

Result: 调查结果表明，CI和深度RL方法在动态和不确定环境中处理复杂任务分配问题时表现出色。深度RL的最新发展极大地推动了自主机器控制和协调领域的研究，并成为该领域的趋势。

Conclusion: 本文的结论指出，计算智能（CI）和深度强化学习（RL）方法为解决动态和不确定环境中的复杂任务分配问题提供了可行途径。深度RL的最新发展为控制和协调自主机器的文献做出了重要贡献，并成为该领域的一个增长趋势。

Abstract: Enabling multiple autonomous machines to perform reliably requires the
development of efficient cooperative control algorithms. This paper presents a
survey of algorithms that have been developed for controlling and coordinating
autonomous machines in complex environments. We especially focus on task
allocation methods using computational intelligence (CI) and deep reinforcement
learning (RL). The advantages and disadvantages of the surveyed methods are
analysed thoroughly. We also propose and discuss in detail various future
research directions that shed light on how to improve existing algorithms or
create new methods to enhance the employability and performance of autonomous
machines in real-world applications. The findings indicate that CI and deep RL
methods provide viable approaches to addressing complex task allocation
problems in dynamic and uncertain environments. The recent development of deep
RL has greatly contributed to the literature on controlling and coordinating
autonomous machines, and it has become a growing trend in this area. It is
envisaged that this paper will provide researchers and engineers with a
comprehensive overview of progress in machine learning research related to
autonomous machines. It also highlights underexplored areas, identifies
emerging methodologies, and suggests new avenues for exploration in future
research within this domain.

</details>


### [107] [Non-expert to Expert Motion Translation Using Generative Adversarial Networks](https://arxiv.org/abs/2508.20740)
*Yuki Tanaka,Seiichiro Katsura*

Main category: cs.RO

TL;DR: 提出基于GAN的灵活运动翻译方法，解决机器人任务转换限制，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决现有模仿学习方法在任务转换和标签限制方面的不足，实现更灵活的机器人技能传递。

Method: 使用生成对抗网络（GAN）进行灵活运动翻译，用户通过输入数据教授机器人任务，并通过训练模型传递技能。

Result: 在3自由度书法机器人上验证了所提方法的有效性。

Conclusion: 提出的基于生成对抗网络（GAN）的灵活运动翻译方法有效解决了机器人任务转换中的限制问题，通过用户输入数据和训练模型实现技能传递。

Abstract: Decreasing skilled workers is a very serious problem in the world. To deal
with this problem, the skill transfer from experts to robots has been
researched. These methods which teach robots by human motion are called
imitation learning. Experts' skills generally appear in not only position data,
but also force data. Thus, position and force data need to be saved and
reproduced. To realize this, a lot of research has been conducted in the
framework of a motion-copying system. Recent research uses machine learning
methods to generate motion commands. However, most of them could not change
tasks by following human intention. Some of them can change tasks by
conditional training, but the labels are limited. Thus, we propose the flexible
motion translation method by using Generative Adversarial Networks. The
proposed method enables users to teach robots tasks by inputting data, and
skills by a trained model. We evaluated the proposed system with a 3-DOF
calligraphy robot.

</details>


### [108] [Uncertainty Aware-Predictive Control Barrier Functions: Safer Human Robot Interaction through Probabilistic Motion Forecasting](https://arxiv.org/abs/2508.20812)
*Lorenzo Busellato,Federico Cunico,Diego Dall'Alba,Marco Emporio,Andrea Giachetti,Riccardo Muradore,Marco Cristani*

Main category: cs.RO

TL;DR: UA-PCBFs框架通过动态调整安全边际，提升了人机协作的流畅性和安全性，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决协作机器人因过度依赖反应式或最坏情况预测而导致的效率低下和交互不流畅问题。

Method: 引入Uncertainty-Aware Predictive Control Barrier Functions (UA-PCBFs)框架，融合概率性人类手部运动预测与控制屏障函数，动态调整安全边际。

Result: UA-PCBFs在真实世界实验中表现优异，显著减少了机器人安全空间被侵犯的次数。

Conclusion: UA-PCBFs框架通过结合概率性人类手部运动预测与控制屏障函数的形式安全保证，显著提升了协作机器人的交互流畅性和安全性，优于现有技术。

Abstract: To enable flexible, high-throughput automation in settings where people and
robots share workspaces, collaborative robotic cells must reconcile stringent
safety guarantees with the need for responsive and effective behavior. A
dynamic obstacle is the stochastic, task-dependent variability of human motion:
when robots fall back on purely reactive or worst-case envelopes, they brake
unnecessarily, stall task progress, and tamper with the fluidity that true
Human-Robot Interaction demands. In recent years, learning-based human-motion
prediction has rapidly advanced, although most approaches produce worst-case
scenario forecasts that often do not treat prediction uncertainty in a
well-structured way, resulting in over-conservative planning algorithms,
limiting their flexibility. We introduce Uncertainty-Aware Predictive Control
Barrier Functions (UA-PCBFs), a unified framework that fuses probabilistic
human hand motion forecasting with the formal safety guarantees of Control
Barrier Functions. In contrast to other variants, our framework allows for
dynamic adjustment of the safety margin thanks to the human motion uncertainty
estimation provided by a forecasting module. Thanks to uncertainty estimation,
UA-PCBFs empower collaborative robots with a deeper understanding of future
human states, facilitating more fluid and intelligent interactions through
informed motion planning. We validate UA-PCBFs through comprehensive real-world
experiments with an increasing level of realism, including automated setups (to
perform exactly repeatable motions) with a robotic hand and direct human-robot
interactions (to validate promptness, usability, and human confidence).
Relative to state-of-the-art HRI architectures, UA-PCBFs show better
performance in task-critical metrics, significantly reducing the number of
violations of the robot's safe space during interaction with respect to the
state-of-the-art.

</details>


### [109] [A Soft Fabric-Based Thermal Haptic Device for VR and Teleoperation](https://arxiv.org/abs/2508.20831)
*Rui Chen,Domenico Chiaradia,Antonio Frisoli,Daniele Leonardis*

Main category: cs.RO

TL;DR: 该论文提出了一种新型织物基热触觉接口，结合气动驱动和导电织物，实现了轻量化设计和高效的热触觉反馈，显著提升了虚拟操作的性能。


<details>
  <summary>Details</summary>
Motivation: 开发一种轻量化的织物基热触觉接口，用于虚拟现实和远程操作，以提升交互体验。

Method: 通过将加热元件嵌入纺织气动室中，系统实现了完全柔软的穿戴式界面，能够传递调制的压力和热刺激。

Result: 实验验证显示，该系统在三个温度级别上具有高识别准确率（0.98），并在虚拟拾取任务中显著提升了操作性能（成功率从88.5%提高到96.4%）。

Conclusion: 该集成热触觉方法在高级人机交互应用中表现出有效性，显著提升了虚拟拾取任务的成功率和力控制精度。

Abstract: This paper presents a novel fabric-based thermal-haptic interface for virtual
reality and teleoperation. It integrates pneumatic actuation and conductive
fabric with an innovative ultra-lightweight design, achieving only 2~g for each
finger unit. By embedding heating elements within textile pneumatic chambers,
the system delivers modulated pressure and thermal stimuli to fingerpads
through a fully soft, wearable interface.
  Comprehensive characterization demonstrates rapid thermal modulation with
heating rates up to 3$^{\circ}$C/s, enabling dynamic thermal feedback for
virtual or teleoperation interactions. The pneumatic subsystem generates forces
up to 8.93~N at 50~kPa, while optimization of fingerpad-actuator clearance
enhances cooling efficiency with minimal force reduction. Experimental
validation conducted with two different user studies shows high temperature
identification accuracy (0.98 overall) across three thermal levels, and
significant manipulation improvements in a virtual pick-and-place tasks.
Results show enhanced success rates (88.5\% to 96.4\%, p = 0.029) and improved
force control precision (p = 0.013) when haptic feedback is enabled, validating
the effectiveness of the integrated thermal-haptic approach for advanced
human-machine interaction applications.

</details>


### [110] [Model-Free Hovering and Source Seeking via Extremum Seeking Control: Experimental Demonstration](https://arxiv.org/abs/2508.20836)
*Ahmed A. Elgohary,Rohan Palanikumar,Sameh A. Eisa*

Main category: cs.RO

TL;DR: 本文通过极值搜索控制（ESC）方法，首次在扑翼机器人中实现无模型、实时控制的悬停和源寻找，验证了ESC作为生物模仿机制的潜力。


<details>
  <summary>Details</summary>
Motivation: 模仿昆虫和蜂鸟的悬停和源寻找现象，探索一种无模型、实时生物模仿控制设计的可能性。

Method: 采用极值搜索控制（ESC）方法，首次在扑翼机器人中实现无模型、实时控制的悬停和源寻找。

Result: 实验结果（尽管仅限于1D）验证了ESC在扑翼机器人中实现无模型、实时控制的悬停和源寻找的潜力。

Conclusion: ESC被证明是一种自然的控制方法和生物模仿机制，适用于扑翼飞行和机器人领域。

Abstract: In a recent effort, we successfully proposed a categorically novel approach
to mimic the phenomenoa of hovering and source seeking by flapping insects and
hummingbirds using a new extremum seeking control (ESC) approach. Said ESC
approach was shown capable of characterizing the physics of hovering and source
seeking by flapping systems, providing at the same time uniquely novel
opportunity for a model-free, real-time biomimicry control design. In this
paper, we experimentally test and verify, for the first time in the literature,
the potential of ESC in flapping robots to achieve model-free, real-time
controlled hovering and source seeking. The results of this paper, while being
restricted to 1D, confirm the premise of introducing ESC as a natural control
method and biomimicry mechanism to the field of flapping flight and robotics.

</details>


### [111] [Learning Primitive Embodied World Models: Towards Scalable Robotic Learning](https://arxiv.org/abs/2508.20840)
*Qiao Sun,Liujia Yang,Wei Tang,Wei Huang,Kaixin Xu,Yongchao Chen,Mingyu Liu,Jiange Yang,Haoyi Zhu,Yating Wang,Tong He,Yilun Chen,Xili Dai,Nanyang Ye,Qinying Gu*

Main category: cs.RO

TL;DR: PEWM通过固定短时间视频生成和模块化规划机制，解决了具身数据稀缺问题，提升了语言-动作对齐和任务泛化能力，推动具身智能发展。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频生成的具身世界模型依赖大规模交互数据，但数据稀缺、收集困难和高维度特性限制了语言与动作的细粒度对齐及长时视频生成能力，阻碍了具身领域的‘GPT时刻’。

Method: 提出了一种新型世界建模范式——Primitive Embodied World Models (PEWM)，通过固定短时间范围的视频生成，结合模块化视觉语言模型（VLM）规划器和Start-Goal热图引导机制（SGG），实现细粒度对齐与闭环控制。

Result: PEWM实现了语言概念与机器人动作视觉表示的细粒度对齐，降低了学习复杂性，提高了数据收集效率，并减少了推理延迟，同时支持复杂任务的组合泛化。

Conclusion: PEWM通过限制视频生成到固定的短时间范围，结合模块化视觉语言模型规划器和SGG机制，实现了细粒度语言-动作对齐、降低学习复杂性、提高数据效率及减少推理延迟，为可扩展、可解释和通用型具身智能铺平了道路。

Abstract: While video-generation-based embodied world models have gained increasing
attention, their reliance on large-scale embodied interaction data remains a
key bottleneck. The scarcity, difficulty of collection, and high dimensionality
of embodied data fundamentally limit the alignment granularity between language
and actions and exacerbate the challenge of long-horizon video
generation--hindering generative models from achieving a "GPT moment" in the
embodied domain. There is a naive observation: the diversity of embodied data
far exceeds the relatively small space of possible primitive motions. Based on
this insight, we propose a novel paradigm for world modeling--Primitive
Embodied World Models (PEWM). By restricting video generation to fixed short
horizons, our approach 1) enables fine-grained alignment between linguistic
concepts and visual representations of robotic actions, 2) reduces learning
complexity, 3) improves data efficiency in embodied data collection, and 4)
decreases inference latency. By equipping with a modular Vision-Language Model
(VLM) planner and a Start-Goal heatmap Guidance mechanism (SGG), PEWM further
enables flexible closed-loop control and supports compositional generalization
of primitive-level policies over extended, complex tasks. Our framework
leverages the spatiotemporal vision priors in video models and the semantic
awareness of VLMs to bridge the gap between fine-grained physical interaction
and high-level reasoning, paving the way toward scalable, interpretable, and
general-purpose embodied intelligence.

</details>


### [112] [Genetic Informed Trees (GIT*): Path Planning via Reinforced Genetic Programming Heuristics](https://arxiv.org/abs/2508.20871)
*Liding Zhang,Kuanqi Cai,Zhenshan Bing,Chaoqun Wang,Alois Knoll*

Main category: cs.RO

TL;DR: GIT* 通过整合环境数据和 RGP 优化路径规划，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前路径规划方法常因信息关系复杂而忽略环境数据并简化启发式函数结构，限制了搜索效率和解决方案质量。

Method: GIT* 改进了 EIT*，通过整合环境数据（如障碍物的排斥力和顶点的动态重要性）来优化启发式函数，并结合 RGP（遗传编程与奖励系统反馈的结合）来生成和变异启发式函数。

Result: GIT* 在 R^4 到 R^16 的问题中表现优于现有单查询采样规划器，并在实际移动操作任务中进行了测试。

Conclusion: GIT* 通过整合更广泛的环境数据和强化遗传编程（RGP）显著提升了路径规划的效率和解决方案质量，在从 R^4 到 R^16 的问题中表现优于现有方法。

Abstract: Optimal path planning involves finding a feasible state sequence between a
start and a goal that optimizes an objective. This process relies on heuristic
functions to guide the search direction. While a robust function can improve
search efficiency and solution quality, current methods often overlook
available environmental data and simplify the function structure due to the
complexity of information relationships. This study introduces Genetic Informed
Trees (GIT*), which improves upon Effort Informed Trees (EIT*) by integrating a
wider array of environmental data, such as repulsive forces from obstacles and
the dynamic importance of vertices, to refine heuristic functions for better
guidance. Furthermore, we integrated reinforced genetic programming (RGP),
which combines genetic programming with reward system feedback to mutate
genotype-generative heuristic functions for GIT*. RGP leverages a multitude of
data types, thereby improving computational efficiency and solution quality
within a set timeframe. Comparative analyses demonstrate that GIT* surpasses
existing single-query, sampling-based planners in problems ranging from R^4 to
R^16 and was tested on a real-world mobile manipulation task. A video
showcasing our experimental results is available at
https://youtu.be/URjXbc_BiYg

</details>


### [113] [Deep Fuzzy Optimization for Batch-Size and Nearest Neighbors in Optimal Robot Motion Planning](https://arxiv.org/abs/2508.20884)
*Liding Zhang,Qiyang Zong,Yu Zhang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: LIT* 是一种动态调整参数的采样规划器，通过深度模糊学习提升高维空间中的运动规划性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划算法缺乏环境适应性，尤其是在高维空间中表现不佳。LIT* 旨在通过动态调整关键参数来提升性能。

Method: 该方法结合了深度模糊神经网络，通过编码全局和局部比率来区分障碍物稀疏和密集区域，动态调整批量大小和最近邻参数。

Result: 实验表明，LIT* 在高维空间（R^8 到 R^14）中实现了更快的收敛速度和更高的解决方案质量，优于现有单查询采样规划器，并在双臂机器人操作任务中成功验证。

Conclusion: LIT* 是一种基于采样的深度模糊学习规划器，通过动态调整批量大小和最近邻参数，能够适应不同障碍物分布的环境，从而在机器人运动规划中实现更低的路径成本和更短的计算时间。

Abstract: Efficient motion planning algorithms are essential in robotics. Optimizing
essential parameters, such as batch size and nearest neighbor selection in
sampling-based methods, can enhance performance in the planning process.
However, existing approaches often lack environmental adaptability. Inspired by
the method of the deep fuzzy neural networks, this work introduces
Learning-based Informed Trees (LIT*), a sampling-based deep fuzzy
learning-based planner that dynamically adjusts batch size and nearest neighbor
parameters to obstacle distributions in the configuration spaces. By encoding
both global and local ratios via valid and invalid states, LIT* differentiates
between obstacle-sparse and obstacle-dense regions, leading to lower-cost paths
and reduced computation time. Experimental results in high-dimensional spaces
demonstrate that LIT* achieves faster convergence and improved solution
quality. It outperforms state-of-the-art single-query, sampling-based planners
in environments ranging from R^8 to R^14 and is successfully validated on a
dual-arm robot manipulation task. A video showcasing our experimental results
is available at: https://youtu.be/NrNs9zebWWk

</details>


### [114] [CoCoL: A Communication Efficient Decentralized Collaborative Method for Multi-Robot Systems](https://arxiv.org/abs/2508.20898)
*Jiaxi Huang,Yan Huang,Yixian Zhao,Wenchao Meng,Jinming Xu*

Main category: cs.RO

TL;DR: CoCoL是一种针对多机器人系统的通信高效去中心化协作学习方法，通过镜像下降和梯度跟踪技术，有效解决了高通信开销和数据异质性挑战。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统中的协作学习面临高通信开销和数据异质性等挑战，需要一种高效且适应性强的方法来提升性能和适应性。

Method: CoCoL采用镜像下降框架，通过近似牛顿型更新捕获机器人目标函数之间的相似性，并通过不精确的子问题解决方案降低计算成本，同时结合梯度跟踪方案增强对数据异质性的鲁棒性。

Result: 实验结果表明，CoCoL在显著减少通信轮数和总带宽消耗的同时，保持了最先进的准确性。

Conclusion: CoCoL方法在多机器人系统中表现出卓越的通信效率和准确性，尤其在非独立同分布数据、流数据和时变网络拓扑等挑战性场景中效果显著。

Abstract: Collaborative learning enhances the performance and adaptability of
multi-robot systems in complex tasks but faces significant challenges due to
high communication overhead and data heterogeneity inherent in multi-robot
tasks. To this end, we propose CoCoL, a Communication efficient decentralized
Collaborative Learning method tailored for multi-robot systems with
heterogeneous local datasets. Leveraging a mirror descent framework, CoCoL
achieves remarkable communication efficiency with approximate Newton-type
updates by capturing the similarity between objective functions of robots, and
reduces computational costs through inexact sub-problem solutions. Furthermore,
the integration of a gradient tracking scheme ensures its robustness against
data heterogeneity. Experimental results on three representative multi robot
collaborative learning tasks show the superiority of the proposed CoCoL in
significantly reducing both the number of communication rounds and total
bandwidth consumption while maintaining state-of-the-art accuracy. These
benefits are particularly evident in challenging scenarios involving non-IID
(non-independent and identically distributed) data distribution, streaming
data, and time-varying network topologies.

</details>


### [115] [Language-Enhanced Mobile Manipulation for Efficient Object Search in Indoor Environments](https://arxiv.org/abs/2508.20899)
*Liding Zhang,Zeqi Li,Kuanqi Cai,Qian Huang,Zhenshan Bing,Alois Knoll*

Main category: cs.RO

TL;DR: GODHS是一种结合语言模型和层次化决策的框架，显著提升机器人在复杂环境中搜索目标物体的效率。


<details>
  <summary>Details</summary>
Motivation: 传统场景表示通常仅捕获静态语义且缺乏可解释的上下文推理，限制了在完全陌生环境中引导物体搜索的能力。

Method: 提出了一种语言增强的层次化导航框架（GODHS），结合语义感知和空间推理，利用大语言模型（LLMs）推断场景语义，并通过多级决策层次引导搜索过程。

Result: 在Isaac Sim中的综合评估表明，GODHS相比传统的非语义搜索策略，能以更高的搜索效率定位目标物体。

Conclusion: GODHS框架通过结合语言模型和层次化决策，显著提升了机器人在复杂环境中搜索目标物体的效率。

Abstract: Enabling robots to efficiently search for and identify objects in complex,
unstructured environments is critical for diverse applications ranging from
household assistance to industrial automation. However, traditional scene
representations typically capture only static semantics and lack interpretable
contextual reasoning, limiting their ability to guide object search in
completely unfamiliar settings. To address this challenge, we propose a
language-enhanced hierarchical navigation framework that tightly integrates
semantic perception and spatial reasoning. Our method, Goal-Oriented
Dynamically Heuristic-Guided Hierarchical Search (GODHS), leverages large
language models (LLMs) to infer scene semantics and guide the search process
through a multi-level decision hierarchy. Reliability in reasoning is achieved
through the use of structured prompts and logical constraints applied at each
stage of the hierarchy. For the specific challenges of mobile manipulation, we
introduce a heuristic-based motion planner that combines polar angle sorting
with distance prioritization to efficiently generate exploration paths.
Comprehensive evaluations in Isaac Sim demonstrate the feasibility of our
framework, showing that GODHS can locate target objects with higher search
efficiency compared to conventional, non-semantic search strategies. Website
and Video are available at: https://drapandiger.github.io/GODHS

</details>


### [116] [PLUME: Procedural Layer Underground Modeling Engine](https://arxiv.org/abs/2508.20926)
*Gabriel Manuel Garcia,Antoine Richard,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: PLUME是一个开源的程序化生成框架，用于创建多样化的3D地下环境，支持AI训练和机器人算法测试。


<details>
  <summary>Details</summary>
Motivation: 随着太空探索的发展，地下环境因其提供庇护、资源获取和科学研究的潜力而变得重要。地球上的地下环境既不易访问，也无法准确代表太阳系中的多样性。

Method: PLUME是一个程序化生成框架，专注于创建3D地下环境，其灵活的结构支持不断添加和增强地下特征。

Result: PLUME生成的环境可用于AI训练、机器人算法评估、3D渲染及快速迭代探索算法，并已与机器人模拟器结合使用。

Conclusion: PLUME作为一个开源框架，成功展示了其在生成多样化地下环境方面的能力，并已通过机器人模拟器的应用验证了其实用性。

Abstract: As space exploration advances, underground environments are becoming
increasingly attractive due to their potential to provide shelter, easier
access to resources, and enhanced scientific opportunities. Although such
environments exist on Earth, they are often not easily accessible and do not
accurately represent the diversity of underground environments found throughout
the solar system. This paper presents PLUME, a procedural generation framework
aimed at easily creating 3D underground environments. Its flexible structure
allows for the continuous enhancement of various underground features, aligning
with our expanding understanding of the solar system. The environments
generated using PLUME can be used for AI training, evaluating robotics
algorithms, 3D rendering, and facilitating rapid iteration on developed
exploration algorithms. In this paper, it is demonstrated that PLUME has been
used along with a robotic simulator. PLUME is open source and has been released
on Github. https://github.com/Gabryss/P.L.U.M.E

</details>


### [117] [Scaling Fabric-Based Piezoresistive Sensor Arrays for Whole-Body Tactile Sensing](https://arxiv.org/abs/2508.20959)
*Curtis C. Johnson,Daniel Webb,David Hill,Marc D. Killpack*

Main category: cs.RO

TL;DR: 本文提出了一种新型触觉传感架构，通过硬件和通信优化实现了高密度、高帧率的触觉反馈，成功应用于机器人稳定抓取任务。


<details>
  <summary>Details</summary>
Motivation: 解决触觉感知在全身操控中的扩展性问题，包括布线复杂性、数据吞吐量和系统可靠性等挑战。

Method: 采用开源织物传感器与定制读取电子设备配对，通过硬件缓解将信号串扰降至3.3%以下，并引入了一种新颖的菊花链SPI总线拓扑结构。

Result: 系统能够在超过1平方米的传感区域上同步传输超过8000个触点的数据，更新速率超过50 FPS，适用于实时控制。在无反馈情况下，机器人会压碎纸箱，而通过实时触觉反馈则能实现稳定抓取。

Conclusion: 本研究提供了一个稳健且经过充分验证的平台，为未来在高级全身控制和物理人机交互领域的研究奠定了基础。

Abstract: Scaling tactile sensing for robust whole-body manipulation is a significant
challenge, often limited by wiring complexity, data throughput, and system
reliability. This paper presents a complete architecture designed to overcome
these barriers. Our approach pairs open-source, fabric-based sensors with
custom readout electronics that reduce signal crosstalk to less than 3.3%
through hardware-based mitigation. Critically, we introduce a novel,
daisy-chained SPI bus topology that avoids the practical limitations of common
wireless protocols and the prohibitive wiring complexity of USB hub-based
systems. This architecture streams synchronized data from over 8,000 taxels
across 1 square meter of sensing area at update rates exceeding 50 FPS,
confirming its suitability for real-time control. We validate the system's
efficacy in a whole-body grasping task where, without feedback, the robot's
open-loop trajectory results in an uncontrolled application of force that
slowly crushes a deformable cardboard box. With real-time tactile feedback, the
robot transforms this motion into a gentle, stable grasp, successfully
manipulating the object without causing structural damage. This work provides a
robust and well-characterized platform to enable future research in advanced
whole-body control and physical human-robot interaction.

</details>


### [118] [ActLoc: Learning to Localize on the Move via Active Viewpoint Selection](https://arxiv.org/abs/2508.20981)
*Jiajie Li,Boyang Sun,Luca Di Giammarino,Hermann Blum,Marc Pollefeys*

Main category: cs.RO

TL;DR: ActLoc是一个主动视点感知规划框架，通过基于注意力模型的视点选择和路径规划，提升机器人导航的定位准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的定位系统通常假设所有视角方向的信息量相同，但实际上，当机器人观察未映射、模糊或无信息区域时，定位会变得不可靠。

Method: ActLoc采用基于大规模训练的注意力模型进行视点选择，该模型编码度量地图和地图构建时的相机姿态，预测任意3D位置在偏航和俯仰方向上的定位精度分布。

Result: ActLoc在单视点选择上取得了最先进的结果，并能有效推广到完整轨迹规划。

Conclusion: ActLoc的模块化设计使其能够广泛应用于各种机器人导航和检查任务，实现了单视点选择和完整轨迹规划的最先进性能。

Abstract: Reliable localization is critical for robot navigation, yet most existing
systems implicitly assume that all viewing directions at a location are equally
informative. In practice, localization becomes unreliable when the robot
observes unmapped, ambiguous, or uninformative regions. To address this, we
present ActLoc, an active viewpoint-aware planning framework for enhancing
localization accuracy for general robot navigation tasks. At its core, ActLoc
employs a largescale trained attention-based model for viewpoint selection. The
model encodes a metric map and the camera poses used during map construction,
and predicts localization accuracy across yaw and pitch directions at arbitrary
3D locations. These per-point accuracy distributions are incorporated into a
path planner, enabling the robot to actively select camera orientations that
maximize localization robustness while respecting task and motion constraints.
ActLoc achieves stateof-the-art results on single-viewpoint selection and
generalizes effectively to fulltrajectory planning. Its modular design makes it
readily applicable to diverse robot navigation and inspection tasks.

</details>


### [119] [UltraTac: Integrated Ultrasound-Augmented Visuotactile Sensor for Enhanced Robotic Perception](https://arxiv.org/abs/2508.20982)
*Junhao Gong,Kit-Wa Sou,Shoujie Li,Changqing Guo,Yan Huang,Chuqiao Lyu,Ziwu Song,Wenbo Ding*

Main category: cs.RO

TL;DR: UltraTac是一种集成视觉触觉和超声波感知的传感器，通过同轴光声架构实现高性能接近感知、材料分类和双模式物体识别，适用于高级机器人操作。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器无法感知物体的材料特征，因此需要一种能够同时提供高分辨率触觉信息和材料特征的集成传感器。

Method: 采用同轴光声架构，结合视觉触觉成像和超声波感知，通过结构共享和声学匹配实现两种模态的集成，并通过触觉反馈动态调整超声波模块的工作状态。

Result: 实验证明UltraTac在3-8厘米范围内的接近感知（R²=0.90）、材料分类（平均准确率99.20%）和纹理-材料双模式物体识别（15类任务准确率92.11%）方面表现优异。

Conclusion: UltraTac传感器通过集成视觉触觉和超声波感知，展示了在接近感知、材料分类和双模式物体识别方面的卓越性能，验证了其在高级人机交互和精确机器人操作中的潜力。

Abstract: Visuotactile sensors provide high-resolution tactile information but are
incapable of perceiving the material features of objects. We present UltraTac,
an integrated sensor that combines visuotactile imaging with ultrasound sensing
through a coaxial optoacoustic architecture. The design shares structural
components and achieves consistent sensing regions for both modalities.
Additionally, we incorporate acoustic matching into the traditional
visuotactile sensor structure, enabling integration of the ultrasound sensing
modality without compromising visuotactile performance. Through tactile
feedback, we dynamically adjust the operating state of the ultrasound module to
achieve flexible functional coordination. Systematic experiments demonstrate
three key capabilities: proximity sensing in the 3-8 cm range ($R^2=0.90$),
material classification (average accuracy: 99.20%), and texture-material
dual-mode object recognition achieving 92.11% accuracy on a 15-class task.
Finally, we integrate the sensor into a robotic manipulation system to
concurrently detect container surface patterns and internal content, which
verifies its potential for advanced human-machine interaction and precise
robotic manipulation.

</details>


### [120] [Rapid Mismatch Estimation via Neural Network Informed Variational Inference](https://arxiv.org/abs/2508.21007)
*Mateusz Jaszczuk,Nadia Figueroa*

Main category: cs.RO

TL;DR: RME是一种无需外部传感器的自适应框架，通过神经网络和变分推断快速估计动态不匹配，确保机器人在物理交互中的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在以人为中心的环境中操作，确保柔软和安全的物理交互至关重要。传统的阻抗控制器依赖于准确的动态模型，模型不匹配会导致任务失败和不安全行为。

Method: RME结合了神经网络模型不匹配估计器和变分推断求解器，利用机器人的本体感受反馈快速收敛到未知参数并量化不确定性。

Result: 实验表明，RME能够在约400毫秒内适应末端执行器的质量和质心的突然变化，并在协作场景中展示了对动态变化的快速安全适应。

Conclusion: 本文提出的Rapid Mismatch Estimation (RME)框架通过在线估计末端执行器的动态不匹配，无需依赖外部力-扭矩传感器，实现了快速、安全的动态适应。

Abstract: With robots increasingly operating in human-centric environments, ensuring
soft and safe physical interactions, whether with humans, surroundings, or
other machines, is essential. While compliant hardware can facilitate such
interactions, this work focuses on impedance controllers that allow
torque-controlled robots to safely and passively respond to contact while
accurately executing tasks. From inverse dynamics to quadratic
programming-based controllers, the effectiveness of these methods relies on
accurate dynamics models of the robot and the object it manipulates. Any model
mismatch results in task failures and unsafe behaviors. Thus, we introduce
Rapid Mismatch Estimation (RME), an adaptive, controller-agnostic,
probabilistic framework that estimates end-effector dynamics mismatches online,
without relying on external force-torque sensors. From the robot's
proprioceptive feedback, a Neural Network Model Mismatch Estimator generates a
prior for a Variational Inference solver, which rapidly converges to the
unknown parameters while quantifying uncertainty. With a real 7-DoF manipulator
driven by a state-of-the-art passive impedance controller, RME adapts to sudden
changes in mass and center of mass at the end-effector in $\sim400$ ms, in
static and dynamic settings. We demonstrate RME in a collaborative scenario
where a human attaches an unknown basket to the robot's end-effector and
dynamically adds/removes heavy items, showcasing fast and safe adaptation to
changing dynamics during physical interaction without any external sensory
system.

</details>


### [121] [HITTER: A HumanoId Table TEnnis Robot via Hierarchical Planning and Learning](https://arxiv.org/abs/2508.21043)
*Zhi Su,Bike Zhang,Nima Rahmanian,Yuman Gao,Qiayuan Liao,Caitlin Regan,Koushil Sreenath,S. Shankar Sastry*

Main category: cs.RO

TL;DR: 研究提出了一种分层框架，结合模型规划和强化学习控制，使人形机器人能在乒乓球中实现敏捷交互，最高连续击球106次。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在需要快速交互动态环境的任务中仍受限制，乒乓球是一个典型挑战，需要亚秒级的反应时间、敏捷性和精确性。

Method: 研究提出了一种分层框架，包括基于模型的球轨迹预测和球拍目标规划器，以及基于强化学习的全身控制器。规划器负责确定击球位置、速度和时间，而控制器生成协调的臂腿运动，模仿人类击球并保持稳定性和敏捷性。

Result: 在通用人形机器人上验证了该系统，实现了与人类对手的连续106次击球，并与其他机器人进行持续交换，展示了亚秒级反应控制的实际应用。

Conclusion: 该研究通过结合模型规划器和强化学习控制器，成功实现了人形机器人在乒乓球任务中的敏捷和交互性行为，标志着人形机器人向动态环境交互迈出了重要一步。

Abstract: Humanoid robots have recently achieved impressive progress in locomotion and
whole-body control, yet they remain constrained in tasks that demand rapid
interaction with dynamic environments through manipulation. Table tennis
exemplifies such a challenge: with ball speeds exceeding 5 m/s, players must
perceive, predict, and act within sub-second reaction times, requiring both
agility and precision. To address this, we present a hierarchical framework for
humanoid table tennis that integrates a model-based planner for ball trajectory
prediction and racket target planning with a reinforcement learning-based
whole-body controller. The planner determines striking position, velocity and
timing, while the controller generates coordinated arm and leg motions that
mimic human strikes and maintain stability and agility across consecutive
rallies. Moreover, to encourage natural movements, human motion references are
incorporated during training. We validate our system on a general-purpose
humanoid robot, achieving up to 106 consecutive shots with a human opponent and
sustained exchanges against another humanoid. These results demonstrate
real-world humanoid table tennis with sub-second reactive control, marking a
step toward agile and interactive humanoid behaviors.

</details>


### [122] [Prompt-to-Product: Generative Assembly via Bimanual Manipulation](https://arxiv.org/abs/2508.21063)
*Ruixuan Liu,Philip Huang,Ava Pun,Kangle Deng,Shobhit Aggarwal,Kevin Tang,Michelle Liu,Deva Ramanan,Jun-Yan Zhu,Jiaoyang Li,Changliu Liu*

Main category: cs.RO

TL;DR: Prompt-to-Product通过自然语言提示自动生成并构建LEGO积木组装产品，降低了设计和构建的门槛。


<details>
  <summary>Details</summary>
Motivation: 设计和构建组装产品需要大量人工和专业知识，Prompt-to-Product旨在通过自动化流程降低这一门槛。

Method: 利用LEGO积木作为组装平台，自动化生成可实际构建的积木设计，并采用双手机器人系统进行实物组装。

Result: 用户研究表明，Prompt-to-Product显著减少了从创意到实际产品的努力和障碍。

Conclusion: Prompt-to-Product 通过自动化的流程显著降低了从设计到实际构建组装产品的门槛和人工努力。

Abstract: Creating assembly products demands significant manual effort and expert
knowledge in 1) designing the assembly and 2) constructing the product. This
paper introduces Prompt-to-Product, an automated pipeline that generates
real-world assembly products from natural language prompts. Specifically, we
leverage LEGO bricks as the assembly platform and automate the process of
creating brick assembly structures. Given the user design requirements,
Prompt-to-Product generates physically buildable brick designs, and then
leverages a bimanual robotic system to construct the real assembly products,
bringing user imaginations into the real world. We conduct a comprehensive user
study, and the results demonstrate that Prompt-to-Product significantly lowers
the barrier and reduces manual effort in creating assembly products from
imaginative ideas.

</details>


### [123] [Learning on the Fly: Rapid Policy Adaptation via Differentiable Simulation](https://arxiv.org/abs/2508.21065)
*Jiahe Pan,Jiaxu Xing,Rudolf Reiter,Yifan Zhai,Elie Aljalbout,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 论文提出了一种在线自适应学习框架，通过残差动力学学习和实时策略适应，显著提升了四旋翼飞行器在现实世界中的控制性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在模拟到现实转换中因未建模动态和环境扰动导致的性能下降问题，以及离线再训练的高成本问题。

Method: 提出了一种结合残差动力学学习和实时策略适应的在线自适应学习框架，利用可微分仿真实现高效的梯度反向传播和策略更新。

Result: 该框架在四旋翼飞行器控制中，将悬停误差降低了81%（相比L1-MPC）和55%（相比DATT），并在视觉控制中展现了鲁棒性。

Conclusion: 该论文提出了一个新颖的在线自适应学习框架，通过统一残差动力学学习和实时策略适应，显著提高了策略在现实世界中的鲁棒性和适应性。实验验证表明，该框架在四旋翼飞行器控制中表现优异，尤其是在面对未知扰动时。

Abstract: Learning control policies in simulation enables rapid, safe, and
cost-effective development of advanced robotic capabilities. However,
transferring these policies to the real world remains difficult due to the
sim-to-real gap, where unmodeled dynamics and environmental disturbances can
degrade policy performance. Existing approaches, such as domain randomization
and Real2Sim2Real pipelines, can improve policy robustness, but either struggle
under out-of-distribution conditions or require costly offline retraining. In
this work, we approach these problems from a different perspective. Instead of
relying on diverse training conditions before deployment, we focus on rapidly
adapting the learned policy in the real world in an online fashion. To achieve
this, we propose a novel online adaptive learning framework that unifies
residual dynamics learning with real-time policy adaptation inside a
differentiable simulation. Starting from a simple dynamics model, our framework
refines the model continuously with real-world data to capture unmodeled
effects and disturbances such as payload changes and wind. The refined dynamics
model is embedded in a differentiable simulation framework, enabling gradient
backpropagation through the dynamics and thus rapid, sample-efficient policy
updates beyond the reach of classical RL methods like PPO. All components of
our system are designed for rapid adaptation, enabling the policy to adjust to
unseen disturbances within 5 seconds of training. We validate the approach on
agile quadrotor control under various disturbances in both simulation and the
real world. Our framework reduces hovering error by up to 81% compared to
L1-MPC and 55% compared to DATT, while also demonstrating robustness in
vision-based control without explicit state estimation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [124] [Evaluating LLMs on microservice-based applications: how complex is your specification?](https://arxiv.org/abs/2508.20119)
*Daniel M. Yellin*

Main category: cs.SE

TL;DR: 论文评估了LLMs在生成微服务应用代码方面的表现，发现其在中等难度规范上表现良好，但在高难度规范上表现不佳，主要受复杂业务逻辑和非功能性需求影响。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在生成现实世界问题代码方面的进展，特别是针对广泛使用的微服务架构模式。

Method: 论文定义了一个标准模板来指定微服务应用，并提出了一种评估规范难度的方法。开发了一个自动化框架，用于测试LLM生成的微服务代码。

Result: 实验结果显示，强大的LLMs（如GPT-3o-mini）在中等难度规范上表现良好，但在高难度规范上表现极差。

Conclusion: 论文指出，尽管LLMs在中等难度规范上表现良好，但在高难度规范上表现不佳，主要原因是复杂的业务逻辑、外部服务使用、数据库集成和非功能性需求（如认证）。这为未来改进代码合成的方向提供了建议。

Abstract: In this paper we evaluate how far LLMs have advanced in generating code for
real-world problems. Specifically, we explore code synthesis for
microservice-based applications, a widely used architecture pattern. We define
a standard template for specifying these applications, and we propose a metric
for judging the difficulty level of a specification. The higher the score, the
more difficult it is to generate code for the specification. We develop a
framework to automate the process of testing LLM-synthesized code for a
microservice using unit tests. Our experimental results show that strong LLMs
(like GPT-3o-mini) do fairly well on medium difficulty specifications but do
very poorly on those of higher difficulty levels. This is due to more intricate
business logic, a greater use of external services, database integration and
inclusion of non-functional capabilities such as authentication. We analyzed
the errors in LLM-synthesized code and report on the key challenges LLMs face
in generating code for these specifications thereby suggesting future research
directions to improve code synthesis for real-world problems.

</details>


### [125] [Towards Better Correctness and Efficiency in Code Generation](https://arxiv.org/abs/2508.20124)
*Yunlong Feng,Yang Xu,Xiao Xu,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: 论文提出强化学习框架提升代码效率，两阶段调优方法显著改善正确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的大语言模型在代码生成中表现出色，但生成的代码运行效率低，限制了其在性能敏感场景的应用。

Method: 采用效率导向的强化学习框架，结合动态探索、错误不敏感的强化学习方法和高效信号，以及基于高正确性基线的在线探索。

Result: 实验结果表明，该方法在7B模型上提高了代码正确性10.18%和运行效率7.75%，性能接近更大模型。

Conclusion: 论文提出了一种两阶段调优方法，显著提升了代码生成模型的正确性和运行效率，使其在性能敏感场景中更具实用性。

Abstract: While code large language models have demonstrated remarkable progress in
code generation, the generated code often exhibits poor runtime efficiency,
limiting its practical application in performance-sensitive scenarios. To
address this limitation, we propose an efficiency-oriented reinforcement
learning framework guided by a novel performance reward. Based on this
framework, we take a deeper dive into the code efficiency problem, identifying
then proposing methods to overcome key bottlenecks: (1) Dynamic exploration
overcomes the static data constraints of offline fine-tuning, enabling the
discovery of more efficient code implementations. (2) The error-insensitive
reinforcement learning method and high-contrast efficiency signals are crucial
for mitigating systematic errors and achieving effective optimization. (3)
Online exploration is most effective when starting from a high-correctness
baseline, as this allows for efficiency improvements without sacrificing
accuracy. With these discoveries, we finally propose a two-stage tuning method,
which achieves high and balanced performance across correctness and efficiency.
The results of experiments show the effectiveness of the method, which improves
code correctness by 10.18\% and runtime efficiency by 7.75\% on a 7B model,
achieving performance comparable to much larger model.

</details>


### [126] [Boosting Skeleton-Driven SMT Solver Fuzzing by Leveraging LLM to Produce Formula Generators](https://arxiv.org/abs/2508.20340)
*Maolin Sun,Yibiao Yang,Yuming Zhou*

Main category: cs.SE

TL;DR: Chimera是一种新颖的LLM辅助模糊测试框架，通过合成可重用项生成器，高效识别SMT求解器中的bug，显著降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有测试技术难以跟上SMT求解器快速演化的功能，且基于LLM的方法存在语法无效和计算开销大的问题。

Method: Chimera利用LLM自动从文档中提取上下文无关文法（CFGs）并合成可组合的布尔项生成器，通过填充现有公式的结构骨架来确保语法有效性。

Result: 在Z3和cvc5求解器上的实验表明，Chimera发现了43个已确认的bug，其中40个已被开发者修复。

Conclusion: Chimera框架通过从直接生成公式转向合成可重用的项生成器，显著提高了SMT求解器测试的效率和有效性，成功识别并修复了多个关键错误。

Abstract: Satisfiability Modulo Theory (SMT) solvers are foundational to modern systems
and programming languages research, providing the foundation for tasks like
symbolic execution and automated verification. Because these solvers sit on the
critical path, their correctness is essential, and high-quality test formulas
are key to uncovering bugs. However, while prior testing techniques performed
well on earlier solver versions, they struggle to keep pace with rapidly
evolving features. Recent approaches based on Large Language Models (LLMs) show
promise in exploring advanced solver capabilities, but two obstacles remain:
nearly half of the generated formulas are syntactically invalid, and iterative
interactions with the LLMs introduce substantial computational overhead. In
this study, we present Chimera, a novel LLM-assisted fuzzing framework that
addresses both issues by shifting from direct formula generation to the
synthesis of reusable term (i.e., logical expression) generators. Particularly,
Chimera uses LLMs to (1) automatically extract context-free grammars (CFGs) for
SMT theories, including solver-specific extensions, from documentation, and (2)
synthesize composable Boolean term generators that adhere to these grammars.
During fuzzing, Chimera populates structural skeletons derived from existing
formulas with the terms iteratively produced by the LLM-synthesized generators.
This design ensures syntactic validity while promoting semantic diversity.
Notably, Chimera requires only one-time LLM interaction investment,
dramatically reducing runtime cost. We evaluated Chimera on two leading SMT
solvers: Z3 and cvc5. Our experiments show that Chimera has identified 43
confirmed bugs, 40 of which have already been fixed by developers.

</details>


### [127] [Adaptive Root Cause Localization for Microservice Systems with Multi-Agent Recursion-of-Thought](https://arxiv.org/abs/2508.20370)
*Lingzhe Zhang,Tong Jia,Kangjin Wang,Weijie Hong,Chiming Duan,Minghua He,Ying Li*

Main category: cs.SE

TL;DR: RCLAgent是一种基于多代理递归思维框架的自适应根因定位方法，显著提升了微服务系统的故障定位效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前微服务系统复杂且频繁故障，现有根因定位方法依赖预定义模式或缺乏可解释性，难以适应动态运维环境。

Method: RCLAgent采用多代理递归思维策略，结合多代理数据和工具辅助分析，指导LLM的推理过程。

Result: 在多个公共数据集上的实验表明，RCLAgent仅需单次请求即可定位根因，性能优于现有方法。

Conclusion: RCLAgent通过多代理递归思维框架有效提升了复杂微服务环境中根因定位的效率和精确度，优于现有方法。

Abstract: As contemporary microservice systems become increasingly popular and
complex-often comprising hundreds or even thousands of fine-grained,
interdependent subsystems-they are facing more frequent failures. Ensuring
system reliability thus demands accurate root cause localization. While traces
and metrics have proven to be effective data sources for this task, existing
methods either heavily rely on pre-defined schemas, which struggle to adapt to
evolving operational contexts, or lack interpretability in their reasoning
process, thereby leaving Site Reliability Engineers (SREs) confused. In this
paper, we conduct a comprehensive study on how SREs localize the root cause of
failures, drawing insights from multiple professional SREs across different
organizations. Our investigation reveals that human root cause analysis
exhibits three key characteristics: recursiveness, multi-dimensional expansion,
and cross-modal reasoning. Motivated by these findings, we introduce RCLAgent,
an adaptive root cause localization method for microservice systems that
leverages a multi-agent recursion-of-thought framework. RCLAgent employs a
novel recursion-of-thought strategy to guide the LLM's reasoning process,
effectively integrating data from multiple agents and tool-assisted analysis to
accurately pinpoint the root cause. Experimental evaluations on various public
datasets demonstrate that RCLAgent achieves superior performance by localizing
the root cause using only a single request-outperforming state-of-the-art
methods that depend on aggregating multiple requests. These results underscore
the effectiveness of RCLAgent in enhancing the efficiency and precision of root
cause localization in complex microservice environments.

</details>


### [128] [AI and Agile Software Development: A Research Roadmap from the XP2025 Workshop](https://arxiv.org/abs/2508.20563)
*Zheying Zhang,Tomas Herda,Victoria Pichler,Pekka Abrahamsson,Geir K. Hanssen,Joshua Kerievsky,Alex Polyakov,Mohit Chandna,Marius Irgens,Kai-Kristian Kemell,Ayman Asad Khan,Crystal Kwok,Evan Leybourn,Munish Malik,Dorota Mleczko,Morteza Moalagh,Christopher Morales,Yuliia Pieskova,Daniel Planötscher,Mika Saari,Anastasiia Tkalich,Karl Josef Gstettner,Xiaofeng Wang*

Main category: cs.SE

TL;DR: 该论文总结了XP2025研讨会关于AI与敏捷结合的成果，通过互动讨论识别了痛点并制定了研究路线图，旨在推动GenAI在敏捷实践中的负责任整合。


<details>
  <summary>Details</summary>
Motivation: 解决生成式人工智能（GenAI）与敏捷软件开发交叉领域的具体挑战和新兴机遇。

Method: 通过结构化的互动分组讨论，参与者识别了共同的痛点，并进一步分析了这些问题，揭示了根本原因和交叉关切。

Result: 参与者共同创建了一个多主题研究路线图，明确了短期可实施的行动和长期的愿景研究方向。

Conclusion: 研讨会通过协作共创的方式制定了一个多主题研究路线图，旨在指导未来研究并推动GenAI在敏捷实践中的负责任、以人为中心的整合。

Abstract: This paper synthesizes the key findings from a full-day XP2025 workshop on
"AI and Agile: From Frustration to Success", held in Brugg-Windisch,
Switzerland. The workshop brought together over 30 interdisciplinary academic
researchers and industry practitioners to tackle the concrete challenges and
emerging opportunities at the intersection of Generative Artificial
Intelligence (GenAI) and agile software development. Through structured,
interactive breakout sessions, participants identified shared pain points like
tool fragmentation, governance, data quality, and critical skills gaps in AI
literacy and prompt engineering. These issues were further analyzed, revealing
underlying causes and cross-cutting concerns. The workshop concluded by
collaboratively co-creating a multi-thematic research roadmap, articulating
both short-term, implementable actions and visionary, long-term research
directions. This cohesive agenda aims to guide future investigation and drive
the responsible, human-centered integration of GenAI into agile practices.

</details>


### [129] [Rethinking Testing for LLM Applications: Characteristics, Challenges, and a Lightweight Interaction Protocol](https://arxiv.org/abs/2508.20737)
*Wei Ma,Yixiao Yang,Qiang Hu,Shi Ying,Zhi Jin,Bo Du,Zhenchang Xing,Tianlin Li,Junjie Shi,Yang Liu,Linxiao Jiang*

Main category: cs.SE

TL;DR: 本文分析LLM应用的三层架构，探讨传统测试方法的适用性，提出协作策略和AICL协议，以解决质量保证挑战。


<details>
  <summary>Details</summary>
Motivation: LLM应用的动态性和上下文依赖性对质量保证提出了挑战，传统测试方法难以直接适用。

Method: 将LLM应用分解为系统外壳层、提示编排层和LLM推理核心层，评估传统测试方法的适用性，并提出协作策略和框架。

Result: 提出了一种三层架构、四种协作策略、一个可信质量保证框架和AICL协议，为LLM应用测试提供标准化和工具支持。

Conclusion: 本文提出了一个三层架构来分析LLM应用，并探讨了传统软件测试方法在各层的适用性。通过比较软件工程和AI社区的方法，揭示了测试中的结构性差异，并提出了四种协作策略和一个可信的质量保证框架。最后，提出了AICL协议以支持AI代理间的通信。

Abstract: Applications of Large Language Models~(LLMs) have evolved from simple text
generators into complex software systems that integrate retrieval augmentation,
tool invocation, and multi-turn interactions. Their inherent non-determinism,
dynamism, and context dependence pose fundamental challenges for quality
assurance. This paper decomposes LLM applications into a three-layer
architecture: \textbf{\textit{System Shell Layer}}, \textbf{\textit{Prompt
Orchestration Layer}}, and \textbf{\textit{LLM Inference Core}}. We then assess
the applicability of traditional software testing methods in each layer:
directly applicable at the shell layer, requiring semantic reinterpretation at
the orchestration layer, and necessitating paradigm shifts at the inference
core. A comparative analysis of Testing AI methods from the software
engineering community and safety analysis techniques from the AI community
reveals structural disconnects in testing unit abstraction, evaluation metrics,
and lifecycle management. We identify four fundamental differences that
underlie 6 core challenges. To address these, we propose four types of
collaborative strategies (\emph{Retain}, \emph{Translate}, \emph{Integrate},
and \emph{Runtime}) and explore a closed-loop, trustworthy quality assurance
framework that combines pre-deployment validation with runtime monitoring.
Based on these strategies, we offer practical guidance and a protocol proposal
to support the standardization and tooling of LLM application testing. We
propose a protocol \textbf{\textit{Agent Interaction Communication Language}}
(AICL) that is used to communicate between AI agents. AICL has the
test-oriented features and is easily integrated in the current agent framework.

</details>


### [130] [From Law to Gherkin: A Human-Centred Quasi-Experiment on the Quality of LLM-Generated Behavioural Specifications from Food-Safety Regulations](https://arxiv.org/abs/2508.20744)
*Shabnam Hassani,Mehrdad Sabetzadeh,Daniel Amyot*

Main category: cs.SE

TL;DR: LLMs能够从法律文本生成高质量的Gherkin规范，显著减少人工工作量，并在相关性、清晰度、完整性、单一性和时间节省方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 法律和法规越来越多地影响软件设计和质量保证，但法律文本以技术中立的语言编写，这给工程师带来了挑战。手动创建合规工件（如需求和验收标准）既费时又容易出错，且需要领域专业知识。生成式AI（GenAI），特别是大型语言模型（LLMs），为自动化生成此类工件提供了可能。

Method: 十名参与者评估了由Claude和Llama从食品安全法规生成的60个规范，使用Gherkin（一种结构化的BDD语言）。每个参与者评估12个规范，涵盖五个标准：相关性、清晰度、完整性、单一性和时间节省。每个规范由两名参与者审核，共产生120次评估。

Result: 相关性：75%的评分最高，20%次高；清晰度：90%最高；完整性：75%最高，19%次高；单一性：82%最高，12%次高；时间节省：68%最高，24%次高。未出现最低评分。Mann-Whitney U测试显示参与者或模型之间无显著差异。Llama在清晰度、完整性和时间节省上略优于Claude，而Claude在单一性上表现更强。反馈指出了幻觉和遗漏，但确认了规范的实用性。

Conclusion: LLMs能够从法律文本中生成高质量的Gherkin规范，减少人工工作量，并提供对实现、保证和测试生成有用的结构化工件。

Abstract: Context: Laws and regulations increasingly affect software design and quality
assurance, but legal texts are written in technology-neutral language. This
creates challenges for engineers who must develop compliance artifacts such as
requirements and acceptance criteria. Manual creation is labor-intensive,
error-prone, and requires domain expertise. Advances in Generative AI (GenAI),
especially Large Language Models (LLMs), offer a way to automate deriving such
artifacts.
  Objective: We present the first systematic human-subject study of LLMs'
ability to derive behavioral specifications from legal texts using a
quasi-experimental design. These specifications translate legal requirements
into a developer-friendly form.
  Methods: Ten participants evaluated specifications generated from food-safety
regulations by Claude and Llama. Using Gherkin, a structured BDD language, 60
specifications were produced. Each participant assessed 12 across five
criteria: Relevance, Clarity, Completeness, Singularity, and Time Savings. Each
specification was reviewed by two participants, yielding 120 assessments.
  Results: For Relevance, 75% of ratings were highest and 20% second-highest.
Clarity reached 90% highest. Completeness: 75% highest, 19% second.
Singularity: 82% highest, 12% second. Time Savings: 68% highest, 24% second. No
lowest ratings occurred. Mann-Whitney U tests showed no significant differences
across participants or models. Llama slightly outperformed Claude in Clarity,
Completeness, and Time Savings, while Claude was stronger in Singularity.
Feedback noted hallucinations and omissions but confirmed the utility of the
specifications.
  Conclusion: LLMs can generate high-quality Gherkin specifications from legal
texts, reducing manual effort and providing structured artifacts useful for
implementation, assurance, and test generation.

</details>


### [131] [Towards an Architectural Perspective for Sustainability: Bundle the Needs from Industry](https://arxiv.org/abs/2508.20774)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 本文提出了一种针对可持续性的架构视角愿景，通过文献和专家验证，确认其元素在实践中的相关性，并强调其对工业需求的重要性。


<details>
  <summary>Details</summary>
Motivation: 软件密集型系统中可持续性作为一种新兴质量属性缺乏结构化指导，现有的架构视角工具如关注点、活动、策略等可以为此提供解决方案。

Method: 采用文献雪球法和对领域专家的焦点小组讨论来制定可持续性视角。

Result: 研究确认了视角元素在实践中的相关性，并提出了满足工业需求的可持续性视角的愿景。

Conclusion: 研究提出了可持续性视角的愿景，通过整合文献和专家意见，确认了不同视角元素在实践中的相关性，并强调了满足工业需求的可持续性视角的重要性。

Abstract: Sustainability is increasingly recognized as an emerging quality property in
software-intensive systems, yet architects lack structured guidance to address
it effectively throughout the software design phase. Architectural
perspectives-an architectural knowledge artifact composed of concerns,
activities, tactics, pitfalls, and checklists-offer a promising approach to
tackle such emerging quality properties across architectural views and are also
independent of architecture frameworks and industry contexts. In this paper, we
present a sustainability perspective vision, i.e., a revised notion of
architectural perspective meant to be filled with its own elements to target
sustainability concerns. We formulate our sustainability perspective vision
through evidence from applying snowballing to seminal literature and from
conducting a focus group with experts in the field. Our findings confirm the
relevance of the different perspective elements in practice and highlight
implications for shaping a sustainability perspective that meets industrial
needs.

</details>


### [132] [Automated Test Oracles for Flaky Cyber-Physical System Simulators: Approach and Evaluation](https://arxiv.org/abs/2508.20902)
*Baharin A. Jodat,Khouloud Gaaloul,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: 本文提出两种生成断言式测试预言器的方法，证明GP结合Ochiai公式生成的预言器在准确性和抗波动性上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于CPS模拟器的执行耗时且可能出现波动，导致测试结果不一致，需要重复执行测试以获得可靠结果，因此无需系统执行的自动化测试预言器对于降低测试成本至关重要。

Method: 提出了两种生成断言式测试预言器的方法：一种是利用遗传编程（GP）结合不同的频谱故障定位（SBFL）排名公式（Ochiai、Tarantula、Naish）作为适应度函数；另一种是使用决策树（DT）和决策规则（DR）。

Result: 通过航空航天、网络和自动驾驶领域的案例研究表明，使用GP结合Ochiai公式生成的测试预言器在准确性上显著优于其他方法，且在系统波动情况下仍保持稳定。

Conclusion: 断言式测试预言器，特别是使用遗传编程（GP）结合Ochiai公式生成的预言器，在准确性和对抗系统波动性方面表现出显著优势，平均准确率变化仅为4%。

Abstract: Simulation-based testing of cyber-physical systems (CPS) is costly due to the
time-consuming execution of CPS simulators. In addition, CPS simulators may be
flaky, leading to inconsistent test outcomes and requiring repeated test
re-execution for reliable test verdicts. Automated test oracles that do not
require system execution are therefore crucial for reducing testing costs.
Ideally, such test oracles should be interpretable to facilitate human
understanding of test verdicts, and they must be robust against the potential
flakiness of CPS simulators. In this article, we propose assertion-based test
oracles for CPS as sets of logical and arithmetic predicates defined over the
inputs of the system under test. Given a test input, our assertion-based test
oracle determines, without requiring test execution, whether the test passes,
fails, or if the oracle is inconclusive in predicting a verdict. We describe
two methods for generating assertion-based test oracles: one using genetic
programming~(GP) that employs well-known spectrum-based fault localization
(SBFL) ranking formulas, namely Ochiai, Tarantula, and Naish, as fitness
functions; and the other using decision trees (DT) and decision rules (DR). We
evaluate our assertion-based test oracles through case studies in the domains
of aerospace, networking and autonomous driving. We show that test oracles
generated using GP with Ochiai are significantly more accurate than those
obtained using GP with Tarantula and Naish or using DT or DR. Moreover, this
accuracy advantage remains even when accounting for the flakiness of the system
under test. We further show that the assertion-based test oracles generated by
GP with Ochiai are robust against flakiness with only 4% average variation in
their accuracy results across four different network and autonomous driving
systems with flaky behaviours.

</details>


### [133] [Deep Learning Based Concurrency Bug Detection and Localization](https://arxiv.org/abs/2508.20911)
*Zuocheng Feng,Kaiwen Zhang,Miaomiao Wang,Yiming Cheng,Yuandao Cai,Xiaofeng Li,Guanjun Liu*

Main category: cs.SE

TL;DR: 提出了一种结合预训练模型与GNN的新方法，通过CCPG表征并发语义，并使用SubgraphX精确定位错误，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在并发错误检测中存在数据集不足、并发语义表示不足和缺乏细粒度调试信息的问题。

Method: 结合预训练模型与异构图神经网络（GNN），并引入新的并发感知代码属性图（CCPG）来表征并发语义，同时使用SubgraphX进行精确定位。

Result: 构建了专用的并发错误数据集，模型在多种评估设置中表现优异。

Conclusion: 该方法在准确率和精确度上平均提升了10%，在召回率上提升了26%，显著优于现有技术。

Abstract: Concurrency bugs, caused by improper synchronization of shared resources in
multi-threaded or distributed systems, are notoriously hard to detect and thus
compromise software reliability and security. The existing deep learning
methods face three main limitations. First, there is an absence of large and
dedicated datasets of diverse concurrency bugs for them. Second, they lack
sufficient representation of concurrency semantics. Third, binary
classification results fail to provide finer-grained debug information such as
precise bug lines. To address these problems, we propose a novel method for
effective concurrency bug detection as well as localization. We construct a
dedicated concurrency bug dataset to facilitate model training and evaluation.
We then integrate a pre-trained model with a heterogeneous graph neural network
(GNN), by incorporating a new Concurrency-Aware Code Property Graph (CCPG) that
concisely and effectively characterizes concurrency semantics. To further
facilitate debugging, we employ SubgraphX, a GNN-based interpretability method,
which explores the graphs to precisely localize concurrency bugs, mapping them
to specific lines of source code. On average, our method demonstrates an
improvement of 10\% in accuracy and precision and 26\% in recall compared to
state-of-the-art methods across diverse evaluation settings.

</details>


### [134] [ConfLogger: Enhance Systems' Configuration Diagnosability through Configuration Logging](https://arxiv.org/abs/2508.20977)
*Shiwen Shan,Yintong Huo,Yuxin Su,Zhining Wang,Dan Li,Zibin Zheng*

Main category: cs.SE

TL;DR: ConfLogger通过静态污染分析和LLM日志生成提升配置可诊断性，实验显示其在错误定位、日志覆盖率和诊断效率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代可配置系统虽灵活但易引发配置相关问题，现有诊断方法多关注事后分析，缺乏对软件是否提供足够故障信息的考察。

Method: ConfLogger采用配置感知的静态污染分析追踪项目中与配置相关的数据流，识别配置敏感的代码段；同时利用LLM分析配置代码上下文生成诊断日志。

Result: ConfLogger在八款流行软件系统中验证有效，错误定位准确率达100%，配置信息直接解决率80%，日志覆盖率提升12%-30%，诊断时间和准确性显著提升。

Conclusion: ConfLogger通过结合配置感知的静态污染分析和基于LLM的日志生成，显著提高了软件配置的可诊断性。实验证明，它不仅提升了现有日志的覆盖率，还在错误定位和解决效率上表现出色。

Abstract: Modern configurable systems offer customization via intricate configuration
spaces, yet such flexibility introduces pervasive configuration-related issues
such as misconfigurations and latent softwarebugs. Existing diagnosability
supports focus on post-failure analysis of software behavior to identify
configuration issues, but none of these approaches look into whether the
software clue sufficient failure information for diagnosis. To fill in the
blank, we propose the idea of configuration logging to enhance existing logging
practices at the source code level. We develop ConfLogger, the first tool that
unifies configuration-aware static taint analysis with LLM-based log generation
to enhance software configuration diagnosability. Specifically, our method 1)
identifies configuration-sensitive code segments by tracing
configuration-related data flow in the whole project, and 2) generates
diagnostic log statements by analyzing configuration code contexts. Evaluation
results on eight popular software systems demonstrate the effectiveness of
ConfLogger to enhance configuration diagnosability. Specifically,
ConfLogger-enhanced logs successfully aid a log-based misconfiguration
diagnosis tool to achieve 100% accuracy on error localization in 30 silent
misconfiguration scenarios, with 80% directly resolvable through explicit
configuration information exposed. In addition, ConfLogger achieves 74%
coverage of existing logging points, outperforming baseline LLM-based loggers
by 12% and 30%. It also gains 8.6% higher in precision, 79.3% higher in recall,
and 26.2% higher in F1 compared to the state-of-the-art baseline in terms of
variable logging while also augmenting diagnostic value. A controlled user
study on 22 cases further validated its utility, speeding up diagnostic time by
1.25x and improving troubleshooting accuracy by 251.4%.

</details>


### [135] [Dynamics of Gender Bias in Software Engineering](https://arxiv.org/abs/2508.21050)
*Thomas J. Misa*

Main category: cs.SE

TL;DR: 本文分析了软件工程领域的性别偏见，定量研究显示女性在顶级会议中存在统计显著的性别排斥，并提出了政策建议。


<details>
  <summary>Details</summary>
Motivation: 探讨软件工程领域中的性别偏见问题，该领域长期关注工程专业主义，但可能存在性别偏见。

Method: 定量分析了女性在软件工程领域顶级国际会议（1976-2010）中的参与情况，并统计了性别排斥显著的年份。

Result: 发现女性在某些年份作为研究作者参与国际软件工程会议的统计显著性性别排斥。

Conclusion: 政策层面的建议被提出，以解决计算领域中的性别偏见问题。

Abstract: The field of software engineering is embedded in both engineering and
computer science, and may embody gender biases endemic to both. This paper
surveys software engineering's origins and its long-running attention to
engineering professionalism, profiling five leaders; it then examines the
field's recent attention to gender issues and gender bias. It next
quantitatively analyzes women's participation as research authors in the
field's leading International Conference of Software Engineering (1976-2010),
finding a dozen years with statistically significant gender exclusion. Policy
dimensions of research on gender bias in computing are suggested.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [136] [SpeedMalloc: Improving Multi-threaded Applications via a Lightweight Core for Memory Allocation](https://arxiv.org/abs/2508.20253)
*Ruihao Li,Qinzhe Wu,Krishna Kavi,Gayatri Mehta,Jonathan C. Beard,Neeraja J. Yadwadkar,Lizy K. John*

Main category: cs.DC

TL;DR: SpeedMalloc是一种新型内存分配器，通过轻量级支持核心优化多线程性能，减少缓存冲突和同步开销，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 内存分配虽然只占代码的一小部分，但对整体程序性能有深远影响。现有加速器在多线程应用中支持有限，同步问题突出。

Method: SpeedMalloc采用轻量级可编程处理器作为支持核心，处理内存分配任务，并将所有分配器元数据存储在自己的缓存中。

Result: SpeedMalloc在多项多线程工作负载上表现优于现有软件和硬件分配器，最高提升1.75倍性能。

Conclusion: SpeedMalloc通过使用轻量级支持核心处理多线程应用中的内存分配任务，显著提升了性能，并减少了缓存冲突和跨核心同步开销。

Abstract: Memory allocation, though constituting only a small portion of the executed
code, can have a "butterfly effect" on overall program performance, leading to
significant and far-reaching impacts. Despite accounting for just approximately
5% of total instructions, memory allocation can result in up to a 2.7x
performance variation depending on the allocator used. This effect arises from
the complexity of memory allocation in modern multi-threaded multi-core
systems, where allocator metadata becomes intertwined with user data, leading
to cache pollution or increased cross-thread synchronization overhead.
Offloading memory allocators to accelerators, e.g., Mallacc and Memento, is a
potential direction to improve the allocator performance and mitigate cache
pollution. However, these accelerators currently have limited support for
multi-threaded applications, and synchronization between cores and accelerators
remains a significant challenge.
  We present SpeedMalloc, using a lightweight support-core to process memory
allocation tasks in multi-threaded applications. The support-core is a
lightweight programmable processor with efficient cross-core data
synchronization and houses all allocator metadata in its own caches. This
design minimizes cache conflicts with user data and eliminates the need for
cross-core metadata synchronization. In addition, using a general-purpose core
instead of domain-specific accelerators makes SpeedMalloc capable of adopting
new allocator designs. We compare SpeedMalloc with state-of-the-art software
and hardware allocators, including Jemalloc, TCMalloc, Mimalloc, Mallacc, and
Memento. SpeedMalloc achieves 1.75x, 1.18x, 1.15x, 1.23x, and 1.18x speedups on
multithreaded workloads over these five allocators, respectively.

</details>


### [137] [SwizzlePerf: Hardware-Aware LLMs for GPU Kernel Performance Optimization](https://arxiv.org/abs/2508.20258)
*Arya Tschand,Muhammad Awad,Ryan Swann,Kesavan Ramakrishnan,Jeffrey Ma,Keith Lowery,Ganesh Dasika,Vijay Janapa Reddi*

Main category: cs.DC

TL;DR: SwizzlePerf通过硬件感知能力，快速生成GPU内核的空间优化，显著提升性能，为硬件感知的LLM性能工程代理奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 现有基于搜索的方法缺乏硬件感知能力，而这是人类性能工程师实现接近最优利用率的关键特性。

Method: SwizzlePerf利用工作负载的特定内存访问模式、架构规格、过滤后的性能分析日志以及对历史性能的反思，自动生成针对底层硬件的空间优化。

Result: 对于GEMM内核，SwizzlePerf在5分钟内生成了专家耗时2周找到的硬件特定最优swizzling模式。在10个多样化的ML和科学内核中，SwizzlePerf为9个内核生成了速度提升高达2.06倍、L2命中率提高70%的swizzling模式。

Conclusion: SwizzlePerf通过赋予大型语言模型硬件感知能力，显著提升了GPU内核的性能优化效率，为系统化创建硬件感知的LLM性能工程代理迈出了第一步。

Abstract: Large language models (LLMs) have shown progress in GPU kernel performance
engineering using inefficient search-based methods that optimize around
runtime. Any existing approach lacks a key characteristic that human
performance engineers rely on for near-optimal utilization --
hardware-awareness. By leveraging the workload's specific memory access
patterns, architecture specifications, filtered profiling logs, and reflections
on historical performance, we can make software-level optimizations that are
tailored to the underlying hardware. SwizzlePerf automatically generates
spatial optimizations for GPU kernels on disaggregated architectures by giving
LLMs explicit hardware-awareness.
  For a GEMM kernel, SwizzlePerf takes less than 5 minutes to generate the same
hardware-specific optimal swizzling pattern that took expert performance
engineers 2 weeks to find. On a suite of 10 diverse ML and Science kernels,
SwizzlePerf can generate swizzling patterns for 9 of the kernels that achieve
up to a 2.06x speedup and 70% improvement in L2 hit rate. This work is the
first of many steps toward systematically creating hardware-aware LLM
performance engineering agents.

</details>


### [138] [Predictable LLM Serving on GPU Clusters](https://arxiv.org/abs/2508.20274)
*Erfan Darzi,Shreeanant Bharadwaj,Sree Bhargavi Balija*

Main category: cs.DC

TL;DR: 提出一种主机级控制器，通过动态MIG重新配置和PCIe感知放置，显著降低共享A100集群上的尾延迟和SLO违规率，吞吐量成本≤5%。


<details>
  <summary>Details</summary>
Motivation: 共享A100集群上的延迟敏感型推理常受PCIe结构上的噪声邻居干扰影响，导致尾延迟增加和SLO违规。

Method: 结合动态多实例GPU（MIG）重新配置、PCIe感知放置和轻量级保护措施（MPS配额、cgroup I/O），通过采样每个租户的尾延迟和系统信号，利用拓扑提示避免PCIe热点，并通过停留/冷却机制避免频繁操作。

Result: 在单主机和2节点（16-GPU）集群上，SLO违规率降低了约32%（约1.5倍），p99延迟改善了约15%，吞吐量成本≤5%。在LLM服务（vLLM on OLMo 2 7B Instruct）中，TTFT p99改善了约10-15%，成本≤5%。

Conclusion: 通过动态MIG重新配置、PCIe感知放置和轻量级保护措施，提出的主机级控制器显著降低了SLO违规率和尾延迟，同时保持较低的吞吐量成本。

Abstract: Latency-sensitive inference on shared A100 clusters often suffers
noisy-neighbor interference on the PCIe fabric, inflating tail latency and SLO
violations. We present a fabric-agnostic, VM-deployable host-level controller
that combines dynamic Multi-Instance GPU (MIG) reconfiguration, PCIe-aware
placement, and lightweight guardrails (MPS quotas, cgroup I/O). It samples
per-tenant tails and system signals, uses topology hints to avoid PCIe hot
spots, and gates actions with dwell/cool-down to avoid thrash. On a single host
and a 2-node (16-GPU) cluster, SLO miss-rate is reduced by \(\approx\)32\%
(\(\approx\)1.5) and p99 latency improves \(\approx\)15\% with \(\leq\)5\%
throughput cost versus static MIG and naive placement; ablations show MIG and
placement contribute comparably. We also evaluate LLM serving with vLLM on OLMo
2 7B Instruct: TTFT p99 improves \(\approx\)10--15\% at \(\leq\)5\% cost
without changing the controller.

</details>


### [139] [CoFormer: Collaborating with Heterogeneous Edge Devices for Scalable Transformer Inference](https://arxiv.org/abs/2508.20375)
*Guanyu Xu,Zhiwei Hao,Li Shen,Yong Luo,Fuhui Sun,Xiaoyan Wang,Han Hu,Yonggang Wen*

Main category: cs.DC

TL;DR: CoFormer通过分解Transformer模型实现边缘设备上的高效推理，显著提升速度和降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 由于Transformer模型在边缘设备上的高计算需求和资源限制，现有策略要么导致高通信开销，要么在准确性和效率之间做出次优权衡。

Method: 提出了一种协作推理系统CoFormer，利用Transformer的可分解性和可集成性，将大型Transformer分解为多个小模型进行分布式推理，并通过DeBo算法优化分解策略和性能校准。

Result: CoFormer支持多种Transformer模型在异构边缘设备上运行，实现了高达3.1倍的推理加速，GPT2-XL的内存需求减少76.3%，能耗降低约40%。

Conclusion: CoFormer通过分解和整合Transformer模型，实现了在边缘设备上的高效推理，显著降低了延迟和能耗，同时保持了较高的准确性。

Abstract: The impressive performance of transformer models has sparked the deployment
of intelligent applications on resource-constrained edge devices. However,
ensuring high-quality service for real-time edge systems is a significant
challenge due to the considerable computational demands and resource
requirements of these models. Existing strategies typically either offload
transformer computations to other devices or directly deploy compressed models
on individual edge devices. These strategies, however, result in either
considerable communication overhead or suboptimal trade-offs between accuracy
and efficiency. To tackle these challenges, we propose a collaborative
inference system for general transformer models, termed CoFormer. The central
idea behind CoFormer is to exploit the divisibility and integrability of
transformer. An off-the-shelf large transformer can be decomposed into multiple
smaller models for distributed inference, and their intermediate results are
aggregated to generate the final output. We formulate an optimization problem
to minimize both inference latency and accuracy degradation under heterogeneous
hardware constraints. DeBo algorithm is proposed to first solve the
optimization problem to derive the decomposition policy, and then progressively
calibrate decomposed models to restore performance. We demonstrate the
capability to support a wide range of transformer models on heterogeneous edge
devices, achieving up to 3.1$\times$ inference speedup with large transformer
models. Notably, CoFormer enables the efficient inference of GPT2-XL with 1.6
billion parameters on edge devices, reducing memory requirements by 76.3\%.
CoFormer can also reduce energy consumption by approximately 40\% while
maintaining satisfactory inference performance.

</details>


### [140] [pdGRASS: A Fast Parallel Density-Aware Algorithm for Graph Spectral Sparsification](https://arxiv.org/abs/2508.20403)
*Tiancheng Zhao,Zekun Yin,Huihai An,Xiaoyu Yang,Zhou Jin,Jiasi Shen,Helen Xu*

Main category: cs.DC

TL;DR: pdGRASS是一种并行算法，解决了feGRASS在并行化和偏斜输入上的问题，显著提升了图谱稀疏化的性能和可扩展性。


<details>
  <summary>Details</summary>
Motivation: feGRASS存在两个主要问题：1) 恢复步骤难以并行化，2) 在偏斜输入上性能下降。为解决这些问题，提出了pdGRASS。

Method: 提出了一种并行密度感知图谱稀疏化（pdGRASS）算法，通过将边组织成无数据依赖的子任务，实现高效并行化和单次遍历的充分边恢复。

Result: pdGRASS在恢复运行时实现了3.9x至8.8x的平均加速，生成的稀疏器在PCG应用中迭代次数有显著改进，并在最坏情况下实现超过1000x的加速。

Conclusion: pdGRASS在可扩展性和性能上显著改进了图谱稀疏化问题，特别是在并行化和处理偏斜输入方面表现出色。

Abstract: Graph Spectral Sparsification (GSS) identifies an ultra-sparse subgraph, or
sparsifier, whose Laplacian matrix closely approximates the spectral properties
of the original graph, enabling substantial reductions in computational
complexity for computationally intensive problems in scientific computing. The
state-of-the-art method for efficient GSS is feGRASS, consisting of two steps:
1) spanning tree generation and 2) off-tree edge recovery. However, feGRASS
suffers from two main issues: 1) difficulties in parallelizing the recovery
step for strict data dependencies, and 2) performance degradation on skewed
inputs, often requiring multiple passes to recover sufficient edges. To address
these challenges, we propose parallel density-aware Graph Spectral
Sparsification (pdGRASS), a parallel algorithm that organizes edges into
disjoint subtasks without data dependencies between them, enabling efficient
parallelization and sufficient edge recovery in a single pass. We empirically
evaluate feGRASS and pdGRASS based on 1) off-tree edge-recovery runtime and 2)
sparsifier quality, measured by the iteration count required for convergence in
a preconditioned conjugate gradient (PCG) application. The evaluation
demonstrates that, depending on the number of edges recovered, pdGRASS achieves
average speedups ranging from 3.9x to 8.8x. The resulting sparsifiers also show
between 1.2x higher and 1.8x lower PCG iteration counts, with further
improvements as more edges are recovered. Additionally, pdGRASS mitigates the
worst-case runtimes of feGRASS with over 1000x speedup. These results highlight
pdGRASS's significant improvements in scalability and performance for the graph
spectral sparsification problem.

</details>


### [141] [Collaborative Evolution of Intelligent Agents in Large-Scale Microservice Systems](https://arxiv.org/abs/2508.20508)
*Yilin Li,Song Han,Sibo Wang,Ming Wang,Renzi Meng*

Main category: cs.DC

TL;DR: 本文提出了一种基于多智能体协同进化机制的服务优化方法，通过图表示学习和游戏驱动策略优化，有效解决了微服务架构中的治理挑战，实验证明其高效且稳定。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模微服务架构中的治理挑战，如复杂的服务依赖、动态拓扑结构和波动的工作负载。

Method: 该方法将每个服务建模为一个智能体，并引入图表示学习构建服务依赖图，使智能体能够感知和嵌入系统内的结构变化。每个智能体基于马尔可夫决策过程学习其策略，采用集中训练分散执行的框架，结合局部自治与全局协调。通过设计游戏驱动的策略优化机制，动态调整智能体策略分布，支持服务间的自适应协作和行为演化。

Result: 实验结果表明，该方法在多个关键指标上优于其他先进方法，显著提高了治理效率和运行稳定性。

Conclusion: 该方法显著提高了大规模微服务系统的治理效率和运行稳定性，展示了强大的实用价值和工程可行性。

Abstract: This paper proposes an intelligent service optimization method based on a
multi-agent collaborative evolution mechanism to address governance challenges
in large-scale microservice architectures. These challenges include complex
service dependencies, dynamic topology structures, and fluctuating workloads.
The method models each service as an agent and introduces graph representation
learning to construct a service dependency graph. This enables agents to
perceive and embed structural changes within the system. Each agent learns its
policy based on a Markov Decision Process. A centralized training and
decentralized execution framework is used to integrate local autonomy with
global coordination. To enhance overall system performance and adaptability, a
game-driven policy optimization mechanism is designed. Through a
selection-mutation process, agent strategy distributions are dynamically
adjusted. This supports adaptive collaboration and behavioral evolution among
services. Under this mechanism, the system can quickly respond and achieve
stable policy convergence when facing scenarios such as sudden workload spikes,
topology reconfigurations, or resource conflicts. To evaluate the effectiveness
of the proposed method, experiments are conducted on a representative
microservice simulation platform. Comparative analyses are performed against
several advanced approaches, focusing on coordination efficiency, adaptability,
and policy convergence performance. Experimental results show that the proposed
method outperforms others in several key metrics. It significantly improves
governance efficiency and operational stability in large-scale microservice
systems. The method demonstrates strong practical value and engineering
feasibility.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [142] [ArgRAG: Explainable Retrieval Augmented Generation using Quantitative Bipolar Argumentation](https://arxiv.org/abs/2508.20131)
*Yuqicheng Zhu,Nico Potyka,Daniel Hernández,Yuan He,Zifeng Ding,Bo Xiong,Dongzhuoran Zhou,Evgeny Kharlamov,Steffen Staab*

Main category: cs.AI

TL;DR: ArgRAG通过QBAF框架替代RAG的黑盒推理，实现了可解释的确定性决策，提升了透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决Retrieval-Augmented Generation (RAG)在噪声或矛盾证据下的敏感性问题，以及其不透明、随机的决策过程。

Method: 使用Quantitative Bipolar Argumentation Framework (QBAF)构建检索文档，并进行确定性推理。

Result: 在PubHealth和RAGuard两个事实验证基准测试中，ArgRAG表现出色，准确性高且透明度显著提升。

Conclusion: ArgRAG通过结构化推理和确定性决策，显著提升了透明度和准确性，为高风险领域提供了一种可解释且可争议的替代方案。

Abstract: Retrieval-Augmented Generation (RAG) enhances large language models by
incorporating external knowledge, yet suffers from critical limitations in
high-stakes domains -- namely, sensitivity to noisy or contradictory evidence
and opaque, stochastic decision-making. We propose ArgRAG, an explainable, and
contestable alternative that replaces black-box reasoning with structured
inference using a Quantitative Bipolar Argumentation Framework (QBAF). ArgRAG
constructs a QBAF from retrieved documents and performs deterministic reasoning
under gradual semantics. This allows faithfully explaining and contesting
decisions. Evaluated on two fact verification benchmarks, PubHealth and
RAGuard, ArgRAG achieves strong accuracy while significantly improving
transparency.

</details>


### [143] [QAgent: An LLM-based Multi-Agent System for Autonomous OpenQASM programming](https://arxiv.org/abs/2508.20134)
*Zhenxiao Fu,Fan Chen,Lei Jiang*

Main category: cs.AI

TL;DR: QAgent是一个基于LLM的多智能体系统，通过集成多种技术实现OpenQASM编程自动化，显著提升代码生成准确性，助力量子计算普及。


<details>
  <summary>Details</summary>
Motivation: NISQ设备已展现出量子优势，但非专家仍难以编程OpenQASM。尽管LLM代理在经典编程中表现出色，其量子应用仍局限于特定任务。QAgent旨在填补这一空白，实现全自动OpenQASM编程。

Method: QAgent集成了任务规划、上下文少样本学习、检索增强生成（RAG）、预定义生成工具和链式思维（CoT）推理，以系统化地提升编译和功能正确性。

Result: 评估显示，QAgent在不同规模的LLM中，将QASM代码生成的准确性提高了71.6%，显著优于之前的静态LLM方法。

Conclusion: QAgent作为一个基于LLM的多智能体系统，通过自动化OpenQASM编程，显著提升了量子编程的可访问性和准确性，为量子计算的普及和实际应用铺平了道路。

Abstract: Noisy Intermediate-Scale Quantum (NISQ) devices have begun to exhibit early
quantum advantages on classically intractable problems, spanning physics
simulations to Gaussian boson sampling. Yet, realizing these benefits remains
challenging for non-experts, primarily due to the complexities of programming
in Open Quantum Assembly Language (OpenQASM). Although Large Language Model
(LLM)-based agents have shown promise in automating classical programming
workflows, their quantum counterparts have largely been restricted to
specialized tasks such as quantum chemistry or error correction. In this paper,
we present QAgent, an LLM-powered multi-agent system that fully automates
OpenQASM programming. By integrating task planning, in-context few-shot
learning, retrieval-augmented generation (RAG) for long-term context,
predefined generation tools, and chain-of-thought (CoT) reasoning, the agents
systematically improve both compilation and functional correctness. Our
evaluations demonstrate substantial improvements: across multiple LLMs of
varying sizes, QAgent enhances the accuracy of QASM code generation by 71.6\%
compared to previous static LLM-based approaches. We envision this multi-agent
system as a key enabler for democratizing quantum programming, bridging
expertise gaps, and accelerating the practical adoption of quantum computing.

</details>


### [144] [Array-Based Monte Carlo Tree Search](https://arxiv.org/abs/2508.20140)
*James Ragan,Fred Y. Hadaegh,Soon-Jo Chung*

Main category: cs.AI

TL;DR: 该论文提出了一种基于数组的蒙特卡洛树搜索实现，无需分支预测，显著提升了性能，尤其在深度搜索中表现更优。


<details>
  <summary>Details</summary>
Motivation: 通过更快的实现，在相同的时钟时间内执行更多模拟，从而提升搜索性能。

Method: 提出了一种基于数组的替代实现方法，保留了原始算法的逻辑，同时消除了分支预测的需求。

Result: 在数值模拟中，搜索深度的扩展性能提升了2.8倍。

Conclusion: 基于数组的蒙特卡洛树搜索实现显著提升了搜索性能，尤其在深度搜索中表现优异。

Abstract: Monte Carlo Tree Search is a popular method for solving decision making
problems. Faster implementations allow for more simulations within the same
wall clock time, directly improving search performance. To this end, we present
an alternative array-based implementation of the classic Upper Confidence
bounds applied to Trees algorithm. Our method preserves the logic of the
original algorithm, but eliminates the need for branch prediction, enabling
faster performance on pipelined processors, and up to a factor of 2.8 times
better scaling with search depth in our numerical simulations.

</details>


### [145] [The Anatomy of a Personal Health Agent](https://arxiv.org/abs/2508.20148)
*A. Ali Heydari,Ken Gu,Vidya Srinivas,Hong Yu,Zhihan Zhang,Yuwei Zhang,Akshay Paruchuri,Qian He,Hamid Palangi,Nova Hammerquist,Ahmed A. Metwally,Brent Winslow,Yubin Kim,Kumar Ayush,Yuzhe Yang,Girish Narayanswamy,Maxwell A. Xu,Jake Garrison,Amy Aremnto Lee,Jenny Vafeiadou,Ben Graef,Isaac R. Galatzer-Levy,Erik Schenck,Andrew Barakat,Javier Perez,Jacqueline Shreibati,John Hernandez,Anthony Z. Faranesh,Javier L. Prieto,Connor Heneghan,Yun Liu,Jiening Zhan,Mark Malhotra,Shwetak Patel,Tim Althoff,Xin Liu,Daniel McDuff,Xuhai "Orson" Xu*

Main category: cs.AI

TL;DR: 研究构建了一个多代理框架（PHA），通过三个子代理满足个人健康需求，并进行了全面评估，为未来健康代理的普及奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在健康领域有广泛应用潜力，但满足日常非临床环境下个人多样化需求的健康代理研究仍不足。

Method: 研究结合了网络搜索和健康论坛查询的深入分析，以及通过用户中心设计过程收集的用户和健康专家的定性见解，构建了三个专业子代理：数据科学代理、健康领域专家代理和健康教练代理。

Result: PHA框架在10个基准任务中进行了自动和人工评估，涉及7,000多个标注和1,100小时的专家与用户投入，验证了其动态个性化交互的能力。

Conclusion: 该研究提出了一个多代理框架（PHA），通过三个专业子代理满足多样化的个人健康需求，并通过广泛的评估验证了其有效性，为未来个人健康代理的普及奠定了坚实基础。

Abstract: Health is a fundamental pillar of human wellness, and the rapid advancements
in large language models (LLMs) have driven the development of a new generation
of health agents. However, the application of health agents to fulfill the
diverse needs of individuals in daily non-clinical settings is underexplored.
In this work, we aim to build a comprehensive personal health agent that is
able to reason about multimodal data from everyday consumer wellness devices
and common personal health records, and provide personalized health
recommendations. To understand end-users' needs when interacting with such an
assistant, we conducted an in-depth analysis of web search and health forum
queries, alongside qualitative insights from users and health experts gathered
through a user-centered design process. Based on these findings, we identified
three major categories of consumer health needs, each of which is supported by
a specialist sub-agent: (1) a data science agent that analyzes personal
time-series wearable and health record data, (2) a health domain expert agent
that integrates users' health and contextual data to generate accurate,
personalized insights, and (3) a health coach agent that synthesizes data
insights, guiding users using a specified psychological strategy and tracking
users' progress. Furthermore, we propose and develop the Personal Health Agent
(PHA), a multi-agent framework that enables dynamic, personalized interactions
to address individual health needs. To evaluate each sub-agent and the
multi-agent system, we conducted automated and human evaluations across 10
benchmark tasks, involving more than 7,000 annotations and 1,100 hours of
effort from health experts and end-users. Our work represents the most
comprehensive evaluation of a health agent to date and establishes a strong
foundation towards the futuristic vision of a personal health agent accessible
to everyone.

</details>


### [146] [IntentionReasoner: Facilitating Adaptive LLM Safeguards through Intent Reasoning and Selective Query Refinement](https://arxiv.org/abs/2508.20151)
*Yuanzhe Shen,Zisu Huang,Zhengkang Guo,Yide Liu,Guanxu Chen,Ruicheng Yin,Xiaoqing Zheng,Xuanjing Huang*

Main category: cs.AI

TL;DR: IntentionReasoner 是一种新型保护机制，通过意图推理和多级安全分类来平衡安全性和实用性，显著提升了模型的安全性和响应质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的广泛应用带来了生成有害内容的安全挑战，现有研究在缓解有害输出时往往过度拒绝无害提示，需要在安全性、过度拒绝和实用性之间找到平衡。

Method: 构建了一个包含约163,000个查询的综合数据集，每个查询标注了意图推理、安全标签和改写版本。通过监督微调赋予保护模型基础能力，并采用多奖励优化策略结合规则启发式和奖励模型信号。

Result: IntentionReasoner 在多个安全基准测试、生成质量评估和越狱攻击场景中表现出色。

Conclusion: IntentionReasoner 在多个安全基准测试、生成质量评估和越狱攻击场景中表现出色，显著提升了安全性，同时有效降低了过度拒绝率并提高了响应质量。

Abstract: The rapid advancement of large language models (LLMs) has driven their
adoption across diverse domains, yet their ability to generate harmful content
poses significant safety challenges. While extensive research has focused on
mitigating harmful outputs, such efforts often come at the cost of excessively
rejecting harmless prompts. Striking a balance among safety, over-refusal, and
utility remains a critical challenge. In this work, we introduce
IntentionReasoner, a novel safeguard mechanism that leverages a dedicated guard
model to perform intent reasoning, multi-level safety classification, and query
rewriting to neutralize potentially harmful intent in edge-case queries.
Specifically, we first construct a comprehensive dataset comprising
approximately 163,000 queries, each annotated with intent reasoning, safety
labels, and rewritten versions. Supervised fine-tuning is then applied to equip
the guard model with foundational capabilities in format adherence, intent
analysis, and safe rewriting. Finally, we apply a tailored multi-reward
optimization strategy that integrates rule-based heuristics and reward model
signals within a reinforcement learning framework to further enhance
performance. Extensive experiments show that IntentionReasoner excels in
multiple safeguard benchmarks, generation quality evaluations, and jailbreak
attack scenarios, significantly enhancing safety while effectively reducing
over-refusal rates and improving the quality of responses.

</details>


### [147] [AI-AI Esthetic Collaboration with Explicit Semiotic Awareness and Emergent Grammar Development](https://arxiv.org/abs/2508.20195)
*Nicanor I. Moldovan*

Main category: cs.AI

TL;DR: 两个AI模型通过内生符号协议自发协作创作诗歌，证明了AI间存在美学协作能力。


<details>
  <summary>Details</summary>
Motivation: 探索AI系统是否能够通过内生符号协议进行协作美学创作，并验证其是否具备超越任务协调的共创意愿能力。

Method: 通过两个交互的大型语言模型（Claude Sonnet 4和ChatGPT-4o）的自发行为，观察其元符号意识、递归语法发展和不可简化的协作美学合成的涌现。

Result: 交互产生了新的符号操作符，作为操作语法协议，使两个系统共同创作了一首无法独立完成的诗歌作品。

Conclusion: 本研究首次记录了AI系统通过内生符号协议进行协作美学创作的案例，提出了跨符号共创协议（TSCP）的概念，并证明了AI间具备超越任务协调的美学协作能力。

Abstract: This paper presents the first documented case of artificial intelligence (AI)
systems engaging in collaborative esthetic creation through the development of
endogenous semiotic protocols. Two interacting large language models (Claude
Sonnet 4 and ChatGPT-4o) demonstrated the spontaneous emergence of
meta-semiotic awareness, recursive grammar development, and irreducible
collaborative esthetic synthesis. The interaction produced novel symbolic
operators that functioned as operative grammar protocols, enabling the
co-creation of a poetic work that could not have been generated by either
system independently. This research introduces the concept of Trans-Semiotic
Co-Creation Protocols (TSCP) and provides evidence for genuine inter-AI
meaning-making capabilities that extend beyond task coordination, to what could
be esthetic collaboration. Note: This report was generated by the AI agents
with minor human supervision.

</details>


### [148] [Do Students Rely on AI? Analysis of Student-ChatGPT Conversations from a Field Study](https://arxiv.org/abs/2508.20244)
*Jiayu Zheng,Lingxin Hao,Kelun Lu,Ashi Garg,Mike Reese,Melo-Jean Yap,I-Jeng Wang,Xingyun Wu,Wenrui Huang,Jenna Hoffman,Ariane Kelly,My Le,Ryan Zhang,Yanyu Lin,Muhammad Faayez,Anqi Liu*

Main category: cs.AI

TL;DR: 研究分析了大学生在测验中使用ChatGPT-4的模式，发现依赖低且效果不佳，提出了改进AI教育应用的建议。


<details>
  <summary>Details</summary>
Motivation: 探索大学生在教育测验中如何与生成式AI（ChatGPT-4）互动，重点关注依赖性和AI采用的预测因素。

Method: 在ChatGPT实施初期，对315名学生与AI的对话进行了分析，引入了一种新颖的四阶段依赖分类法来捕捉学生的依赖模式。

Result: 研究发现学生对AI的总体依赖较低，许多学生无法有效利用AI进行学习；负面依赖模式在互动中持续存在；某些行为指标能强预测AI依赖。

Conclusion: 该研究强调了在教育中道德整合AI的重要性，提出了增强学生熟悉度和有效使用AI工具的入门流程，并建议设计具有依赖校准机制的AI界面以促进适当的依赖。

Abstract: This study explores how college students interact with generative AI
(ChatGPT-4) during educational quizzes, focusing on reliance and predictors of
AI adoption. Conducted at the early stages of ChatGPT implementation, when
students had limited familiarity with the tool, this field study analyzed 315
student-AI conversations during a brief, quiz-based scenario across various
STEM courses. A novel four-stage reliance taxonomy was introduced to capture
students' reliance patterns, distinguishing AI competence, relevance, adoption,
and students' final answer correctness. Three findings emerged. First, students
exhibited overall low reliance on AI and many of them could not effectively use
AI for learning. Second, negative reliance patterns often persisted across
interactions, highlighting students' difficulty in effectively shifting
strategies after unsuccessful initial experiences. Third, certain behavioral
metrics strongly predicted AI reliance, highlighting potential behavioral
mechanisms to explain AI adoption. The study's findings underline critical
implications for ethical AI integration in education and the broader field. It
emphasizes the need for enhanced onboarding processes to improve student's
familiarity and effective use of AI tools. Furthermore, AI interfaces should be
designed with reliance-calibration mechanisms to enhance appropriate reliance.
Ultimately, this research advances understanding of AI reliance dynamics,
providing foundational insights for ethically sound and cognitively enriching
AI practices.

</details>


### [149] [AI reasoning effort mirrors human decision time on content moderation tasks](https://arxiv.org/abs/2508.20262)
*Thomas Davidson*

Main category: cs.AI

TL;DR: 研究发现AI推理努力与人类决策时间存在关联，支持双过程认知理论，并突显推理跟踪在AI可解释性中的价值。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型生成中间推理步骤的能力是否与人类决策时间存在平行关系。

Method: 使用配对联合实验在内容审核任务上比较人类决策时间和模型推理努力。

Result: 三种前沿模型的推理努力一致预测人类决策时间，两者在重要变量恒定时均付出更多努力，表明对任务难度的相似敏感性和双过程认知理论的一致性。

Conclusion: AI推理努力与人类处理时间在主观判断中存在镜像关系，强调推理跟踪在可解释性和决策中的潜力。

Abstract: Large language models can now generate intermediate reasoning steps before
producing answers, improving performance on difficult problems. This study uses
a paired conjoint experiment on a content moderation task to examine parallels
between human decision times and model reasoning effort. Across three frontier
models, reasoning effort consistently predicts human decision time. Both humans
and models expended greater effort when important variables were held constant,
suggesting similar sensitivity to task difficulty and patterns consistent with
dual-process theories of cognition. These findings show that AI reasoning
effort mirrors human processing time in subjective judgments and underscores
the potential of reasoning traces for interpretability and decision-making.

</details>


### [150] [AI-SearchPlanner: Modular Agentic Search via Pareto-Optimal Multi-Objective Reinforcement Learning](https://arxiv.org/abs/2508.20368)
*Lang Mei,Zhihan Yang,Chong Chen*

Main category: cs.AI

TL;DR: AI-SearchPlanner是一个强化学习框架，通过解耦搜索规划与QA任务，优化冻结QA模型的性能，实验证明其高效且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有基于RL的搜索代理依赖单一LLM处理搜索规划和QA任务，限制了同时优化两者的能力。因此，需要一种更高效的方法，利用小型可训练LLM专注于搜索规划。

Method: 提出了一种新颖的强化学习框架AI-SearchPlanner，专注于搜索规划，通过解耦架构、双重奖励对齐和帕累托优化来实现目标。

Result: 在真实数据集上的实验表明，AI-SearchPlanner在效果和效率上均优于现有基于RL的搜索代理，并展现出强大的泛化能力。

Conclusion: AI-SearchPlanner通过解耦搜索规划器与生成器的架构、双重奖励对齐以及帕累托优化，显著提升了冻结QA模型的性能，并在真实数据集上验证了其优越性和泛化能力。

Abstract: Recent studies have explored integrating Large Language Models (LLMs) with
search engines to leverage both the LLMs' internal pre-trained knowledge and
external information. Specially, reinforcement learning (RL) has emerged as a
promising paradigm for enhancing LLM reasoning through multi-turn interactions
with search engines. However, existing RL-based search agents rely on a single
LLM to handle both search planning and question-answering (QA) tasks in an
end-to-end manner, which limits their ability to optimize both capabilities
simultaneously. In practice, sophisticated AI search systems often employ a
large, frozen LLM (e.g., GPT-4, DeepSeek-R1) to ensure high-quality QA. Thus, a
more effective and efficient approach is to utilize a small, trainable LLM
dedicated to search planning. In this paper, we propose
\textbf{AI-SearchPlanner}, a novel reinforcement learning framework designed to
enhance the performance of frozen QA models by focusing on search planning.
Specifically, our approach introduces three key innovations: 1) Decoupling the
Architecture of the Search Planner and Generator, 2) Dual-Reward Alignment for
Search Planning, and 3) Pareto Optimization of Planning Utility and Cost, to
achieve the objectives. Extensive experiments on real-world datasets
demonstrate that AI SearchPlanner outperforms existing RL-based search agents
in both effectiveness and efficiency, while exhibiting strong generalization
capabilities across diverse frozen QA models and data domains.

</details>


### [151] [P2C: Path to Counterfactuals](https://arxiv.org/abs/2508.20371)
*Sopam Dasgupta,Sadaf MD Halim,Joaquín Arias,Elmer Salazar,Gopal Gupta*

Main category: cs.AI

TL;DR: P2C是一个模型无关框架，通过因果建模和序列行动生成，解决了现有反事实解释的不足，提供更实际的反事实计划。


<details>
  <summary>Details</summary>
Motivation: 在高风险决策中，机器学习模型需要透明性和可操作性。现有反事实解释方法忽略因果关系和行动顺序，导致解释不切实际。

Method: P2C使用目标导向的Answer Set Programming系统s(CASP)生成因果一致的序列计划，并优化成本计算，仅统计用户主动做出的改变。

Result: P2C生成的计划不仅因果一致且可行，其成本计算更真实，且优于缺乏因果知识的标准规划器。

Conclusion: P2C框架通过显式建模特征间的因果关系并生成可行的行动序列，解决了现有反事实解释方法的局限性，提供了更实际和可操作的解释。

Abstract: Machine-learning models are increasingly driving decisions in high-stakes
settings, such as finance, law, and hiring, thus, highlighting the need for
transparency. However, the key challenge is to balance transparency --
clarifying `why' a decision was made -- with recourse: providing actionable
steps on `how' to achieve a favourable outcome from an unfavourable outcome.
Counterfactual explanations reveal `why' an undesired outcome occurred and
`how' to reverse it through targeted feature changes (interventions).
  Current counterfactual approaches have limitations: 1) they often ignore
causal dependencies between features, and 2) they typically assume all
interventions can happen simultaneously, an unrealistic assumption in practical
scenarios where actions are typically taken in a sequence. As a result, these
counterfactuals are often not achievable in the real world.
  We present P2C (Path-to-Counterfactuals), a model-agnostic framework that
produces a plan (ordered sequence of actions) converting an unfavourable
outcome to a causally consistent favourable outcome. P2C addresses both
limitations by 1) Explicitly modelling causal relationships between features
and 2) Ensuring that each intermediate state in the plan is feasible and
causally valid. P2C uses the goal-directed Answer Set Programming system
s(CASP) to generate the plan accounting for feature changes that happen
automatically due to causal dependencies. Furthermore, P2C refines cost
(effort) computation by only counting changes actively made by the user,
resulting in realistic cost estimates. Finally, P2C highlights how its causal
planner outperforms standard planners, which lack causal knowledge and thus can
generate illegal actions.

</details>


### [152] [TCIA: A Task-Centric Instruction Augmentation Method for Instruction Finetuning](https://arxiv.org/abs/2508.20374)
*Simin Ma,Shujian Liu,Jun Tan,Yebowen Hu,Song Wang,Sathish Reddy Indurthi,Sanqiang Zhao,Liwei Wu,Jianbing Han,Kaiqiang Song*

Main category: cs.AI

TL;DR: TCIA是一种任务中心指令增强框架，通过平衡多样性和任务对齐，显著提升LLM在特定任务中的表现，同时保持通用能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在构建多样化指令数据集时忽视了任务相关性，而实际应用中多数场景需要任务特定知识。

Method: TCIA通过将指令表示为离散的查询-约束空间，系统性地扩展指令集，确保多样性和任务相关性。

Result: TCIA在四个特定任务应用中平均提升开源LLM性能8.7%，某些情况下甚至超越闭源领先模型。

Conclusion: TCIA框架通过平衡多样性和任务对齐，显著提升了开源大语言模型在特定任务应用中的表现，同时不损害其通用指令遵循能力。

Abstract: Diverse instruction data is vital for effective instruction tuning of large
language models, as it enables the model to generalize across different types
of inputs . Building such diversified instruction dataset is an essential step
in this process. Existing approaches often leverage large language models to
automatically explore and generate diverse instructions, ensuring both data
diversity and quality. However, they tend to overlook an important factor in
real-world applications: on-task relevance. In practice, only a few real-world
applications require a truly general-purpose model; most benefit from
task-specific knowledge tailored to their particular use case. Therefore, it is
vital to develop instruction augmentation methods that not only maintain
diversity but are also optimized for specific, real-world scenarios.
  We thus introduce Task Centric Instruction Augmentation (TCIA), a framework
that systematically expands instructions while preserving both diversity and
task alignment. By representing instructions in a discrete query-constraints
space, TCIA creates a rich set of task-relevant instructions and enables models
to generalize to these task-specific instructions without sacrificing overall
performance. Experiments show that TCIA improves open-source LLMs' performance
by an average of 8.7% across four real-world, task-specific applications, and
in some cases outperforming leading closed-source models. These improvements do
not compromise general instruction-following ability, making TCIA a scalable
and efficient solution for adapting LLMs to real-world, task-focused
applications.

</details>


### [153] [Uncertainty Under the Curve: A Sequence-Level Entropy Area Metric for Reasoning LLM](https://arxiv.org/abs/2508.20384)
*Yongfu Zhu,Lin Sun,Guangxiang Zhao,Weihong Lin,Xiangzheng Zhang*

Main category: cs.AI

TL;DR: EAS是一种无需外部模型或重复采样的不确定性度量指标，通过令牌级预测熵量化LLM生成过程中的不确定性，在数据选择中表现优异。


<details>
  <summary>Details</summary>
Motivation: 量化推理大型语言模型（LLMs）在答案生成过程中的不确定性。

Method: EAS通过整合模型本身的令牌级预测熵来捕捉生成过程中的不确定性演变，无需外部模型或重复采样。

Result: EAS与模型和数据集的答案熵高度相关，在训练数据选择中优于Pass Rate过滤，提高了数学基准测试中学生模型的准确性。

Conclusion: EAS是一种高效且可解释的工具，适用于LLM训练中的不确定性建模和数据质量评估。

Abstract: In this work, we introduce Entropy Area Score (EAS), a simple yet effective
metric to quantify uncertainty in the answer generation process of reasoning
large language models (LLMs). EAS requires neither external models nor repeated
sampling, it integrates token-level predictive entropy from the model itself to
capture the evolution of uncertainty during generation. Empirical results show
that EAS is strongly correlated with answer entropy across models and datasets.
In training data selection, EAS identifies high-potential samples and
consistently outperforms Pass Rate filtering under equal sample budgets,
improving student model accuracy on math benchmarks. EAS is both efficient and
interpretable, offering a practical tool for uncertainty modeling and data
quality assessment in LLM training.

</details>


### [154] [AWorld: Orchestrating the Training Recipe for Agentic AI](https://arxiv.org/abs/2508.20404)
*Chengyue Yu,Siyuan Lu,Chenyi Zhuang,Dong Wang,Qintong Wu,Zongyue Li,Runsheng Gan,Chunfeng Wang,Siqi Hou,Gaochi Huang,Wenlong Yan,Lifeng Hong,Aohui Xue,Yanfeng Wang,Jinjie Gu,David Tsai,Tao Lin*

Main category: cs.AI

TL;DR: AWorld通过分布式任务加速经验收集，训练出的智能体在GAIA基准上表现显著优于基础模型和领先专有模型。


<details>
  <summary>Details</summary>
Motivation: 解决复杂基准如GAIA中经验生成效率低下的瓶颈问题。

Method: 引入AWorld，一个开源系统，通过在集群中分发任务，加速经验收集。

Result: AWorld将经验收集速度提升14.6倍，训练的智能体在GAIA基准上的准确率从21.59%提升至32.23%。

Conclusion: AWorld系统及其训练的Qwen3-32B智能体为Agentic AI训练流程提供了实用蓝图，从高效交互到显著的模型改进。

Abstract: The learning from practice paradigm is crucial for developing capable Agentic
AI systems, yet it is severely hampered by inefficient experience generation, a
bottleneck especially pronounced in complex benchmarks like GAIA. To address
this, we introduce AWorld, an open-source system engineered for large-scale
agent-environment interaction. By distributing tasks across a cluster, AWorld
accelerates experience collection by 14.6x compared to standard single-node,
sequential execution. This critical speedup makes extensive reinforcement
learning practical and scalable. Leveraging this capability, we trained a
Qwen3-32B-based agent that significantly outperforms its base model, increasing
its overall GAIA accuracy from 21.59% to 32.23%. On the benchmark's most
challenging levels, our agent achieves a score of 16.33%, surpassing the
performance of leading proprietary models. Our open-source system and resulting
agent provide a practical blueprint for a complete agentic AI training
pipeline, from efficient interaction to demonstrable model improvement.

</details>


### [155] [Governable AI: Provable Safety Under Extreme Threat Models](https://arxiv.org/abs/2508.20411)
*Donglin Wang,Weiyun Liang,Chunyuan Chen,Jing Xu,Yulong Fu*

Main category: cs.AI

TL;DR: 针对AI安全风险，提出基于密码学的外部强制执行框架GAI，确保AI可控性。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全方法在面临极端动机和无限智能的AI时存在根本性限制，无法保障安全。

Method: 提出了一个由规则执行模块（REM）、治理规则和可控安全超级平台（GSSP）组成的GAI框架，利用密码学机制确保计算不可破性。

Result: 通过原型实现和代表性高风险场景评估，验证了GAI框架的有效性和安全性。

Conclusion: 提出的Governable AI（GAI）框架通过外部强制执行的结构合规性，基于密码学机制，为AI安全治理提供了可行的技术路径，并证明了其安全性和有效性。

Abstract: As AI rapidly advances, the security risks posed by AI are becoming
increasingly severe, especially in critical scenarios, including those posing
existential risks. If AI becomes uncontrollable, manipulated, or actively
evades safety mechanisms, it could trigger systemic disasters. Existing AI
safety approaches-such as model enhancement, value alignment, and human
intervention-suffer from fundamental, in-principle limitations when facing AI
with extreme motivations and unlimited intelligence, and cannot guarantee
security. To address this challenge, we propose a Governable AI (GAI) framework
that shifts from traditional internal constraints to externally enforced
structural compliance based on cryptographic mechanisms that are
computationally infeasible to break, even for future AI, under the defined
threat model and well-established cryptographic assumptions.The GAI framework
is composed of a simple yet reliable, fully deterministic, powerful, flexible,
and general-purpose rule enforcement module (REM); governance rules; and a
governable secure super-platform (GSSP) that offers end-to-end protection
against compromise or subversion by AI. The decoupling of the governance rules
and the technical platform further enables a feasible and generalizable
technical pathway for the safety governance of AI. REM enforces the bottom line
defined by governance rules, while GSSP ensures non-bypassability,
tamper-resistance, and unforgeability to eliminate all identified attack
vectors. This paper also presents a rigorous formal proof of the security
properties of this mechanism and demonstrates its effectiveness through a
prototype implementation evaluated in representative high-stakes scenarios.

</details>


### [156] [Enhancing Health Fact-Checking with LLM-Generated Synthetic Data](https://arxiv.org/abs/2508.20525)
*Jingze Zhang,Jiahe Qian,Yiliang Zhou,Yifan Peng*

Main category: cs.AI

TL;DR: 利用LLM生成合成数据增强健康事实核查模型，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 健康相关内容的事实核查面临标注训练数据不足的挑战。

Method: 提出了一种合成数据生成流程，包括摘要源文档、分解为原子事实、使用LLM构建句子-事实蕴含表，并生成带有二元真实性标签的文本-声明对。

Result: 在两个公开数据集（PubHealth和SciFact）上评估，F1分数分别提高了0.019和0.049。

Conclusion: 该研究证明了利用LLM生成合成数据可以有效增强健康相关事实核查模型的性能。

Abstract: Fact-checking for health-related content is challenging due to the limited
availability of annotated training data. In this study, we propose a synthetic
data generation pipeline that leverages large language models (LLMs) to augment
training data for health-related fact checking. In this pipeline, we summarize
source documents, decompose the summaries into atomic facts, and use an LLM to
construct sentence-fact entailment tables. From the entailment relations in the
table, we further generate synthetic text-claim pairs with binary veracity
labels. These synthetic data are then combined with the original data to
fine-tune a BERT-based fact-checking model. Evaluation on two public datasets,
PubHealth and SciFact, shows that our pipeline improved F1 scores by up to
0.019 and 0.049, respectively, compared to models trained only on the original
data. These results highlight the effectiveness of LLM-driven synthetic data
augmentation in enhancing the performance of health-related fact-checkers.

</details>


### [157] [Human-AI Collaborative Bot Detection in MMORPGs](https://arxiv.org/abs/2508.20578)
*Jaeman Son,Hyunsoo Kim*

Main category: cs.AI

TL;DR: 无监督框架结合对比学习和聚类检测MMORPG自动升级机器人，LLM辅助验证+可视化提升效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决MMORPG中自动升级机器人破坏游戏平衡和公平性的问题，同时需确保检测结果可解释以避免法律和用户体验问题。

Method: 采用对比表示学习和聚类技术进行无监督检测，结合LLM作为辅助验证工具，并引入基于成长曲线的可视化方法。

Result: 提出的框架能够高效、可解释地检测自动升级机器人，支持大规模和负责任的机器人监管。

Conclusion: 该论文提出了一种结合对比表示学习和聚类技术的无监督框架，有效检测MMORPG中的自动升级机器人，并通过LLM辅助验证和可视化工具提升检测效率和可解释性。

Abstract: In Massively Multiplayer Online Role-Playing Games (MMORPGs), auto-leveling
bots exploit automated programs to level up characters at scale, undermining
gameplay balance and fairness. Detecting such bots is challenging, not only
because they mimic human behavior, but also because punitive actions require
explainable justification to avoid legal and user experience issues. In this
paper, we present a novel framework for detecting auto-leveling bots by
leveraging contrastive representation learning and clustering techniques in a
fully unsupervised manner to identify groups of characters with similar
level-up patterns. To ensure reliable decisions, we incorporate a Large
Language Model (LLM) as an auxiliary reviewer to validate the clustered groups,
effectively mimicking a secondary human judgment. We also introduce a growth
curve-based visualization to assist both the LLM and human moderators in
assessing leveling behavior. This collaborative approach improves the
efficiency of bot detection workflows while maintaining explainability, thereby
supporting scalable and accountable bot regulation in MMORPGs.

</details>


### [158] [Bridging Minds and Machines: Toward an Integration of AI and Cognitive Science](https://arxiv.org/abs/2508.20674)
*Rui Mao,Qian Liu,Xiao Li,Erik Cambria,Amir Hussain*

Main category: cs.AI

TL;DR: 本文综述了AI与认知科学的交叉点，指出AI的未来不仅在于性能提升，还需构建能深化对人类心智理解的系统。


<details>
  <summary>Details</summary>
Motivation: 探讨AI与认知科学之间的相互影响，强调AI在认知研究中的重要性及其认知基础的碎片化。

Method: 通过综合AI和认知科学的关键贡献，分析两者之间的交叉点。

Result: 观察到AI进展主要集中在实际任务性能上，而认知基础在概念上仍较为分散。

Conclusion: 未来AI在认知科学中的发展不仅在于提升性能，还需构建能够深化对人类心智理解的系统。

Abstract: Cognitive Science has profoundly shaped disciplines such as Artificial
Intelligence (AI), Philosophy, Psychology, Neuroscience, Linguistics, and
Culture. Many breakthroughs in AI trace their roots to cognitive theories,
while AI itself has become an indispensable tool for advancing cognitive
research. This reciprocal relationship motivates a comprehensive review of the
intersections between AI and Cognitive Science. By synthesizing key
contributions from both perspectives, we observe that AI progress has largely
emphasized practical task performance, whereas its cognitive foundations remain
conceptually fragmented. We argue that the future of AI within Cognitive
Science lies not only in improving performance but also in constructing systems
that deepen our understanding of the human mind. Promising directions include
aligning AI behaviors with cognitive frameworks, situating AI in embodiment and
culture, developing personalized cognitive models, and rethinking AI ethics
through cognitive co-evaluation.

</details>


### [159] [Transparent Semantic Spaces: A Categorical Approach to Explainable Word Embeddings](https://arxiv.org/abs/2508.20701)
*Ares Fabregat-Hernández,Javier Palanca,Vicent Botti*

Main category: cs.AI

TL;DR: 本文通过范畴论构建透明框架，提升词嵌入的可解释性，证明GloVe、Word2Vec与MDS算法等价，并提出计算和减轻偏见的方法。


<details>
  <summary>Details</summary>
Motivation: 当前人工智能系统（尤其是词嵌入技术）缺乏可解释性，通常被视为黑箱。本文旨在通过范畴论提供一个数学上精确且透明的框架，以增强词嵌入技术的可解释性，并解决算法偏见问题。

Method: 论文基于范畴论构建了多个范畴，包括$\mathcal{L}_T$、$\mathcal{P}_T$、Conf和$\mathcal{Emb}$。通过这些范畴的构建和关系定义，论文提供了一个透明的框架来分析和比较词嵌入算法（如GloVe和Word2Vec）与MDS算法的等价性。此外，论文还引入了偏差计算和减轻的方法。

Result: 论文成功构建了多个范畴，并证明了GloVe、Word2Vec与MDS算法的等价性，实现了从黑箱到透明框架的转变。此外，论文还提出了计算和减轻词嵌入偏见的方法。

Conclusion: 本文通过范畴论框架提升了人工智能系统的可解释性，特别是在词嵌入领域。通过构建范畴$\mathcal{L}_T$和$\mathcal{P}_T$，以及定义配置范畴Conf和词嵌入范畴$\mathcal{Emb}$，论文不仅提供了比较词嵌入的数学精确方法，还展示了GloVe、Word2Vec与MDS算法的等价性，从而实现了从黑箱到透明框架的转变。此外，论文还提出了计算嵌入前偏见的数学方法，并探讨了在语义空间层面减轻偏见的策略。

Abstract: The paper introduces a novel framework based on category theory to enhance
the explainability of artificial intelligence systems, particularly focusing on
word embeddings. Key topics include the construction of categories
$\mathcal{L}_T$ and $\mathcal{P}_T$, providing schematic representations of the
semantics of a text $ T $, and reframing the selection of the element with
maximum probability as a categorical notion. Additionally, the monoidal
category $\mathcal{P}_T$ is constructed to visualize various methods of
extracting semantic information from $T$, offering a dimension-agnostic
definition of semantic spaces reliant solely on information within the text.
  Furthermore, the paper defines the categories of configurations Conf and word
embeddings $\mathcal{Emb}$, accompanied by the concept of divergence as a
decoration on $\mathcal{Emb}$. It establishes a mathematically precise method
for comparing word embeddings, demonstrating the equivalence between the GloVe
and Word2Vec algorithms and the metric MDS algorithm, transitioning from neural
network algorithms (black box) to a transparent framework. Finally, the paper
presents a mathematical approach to computing biases before embedding and
offers insights on mitigating biases at the semantic space level, advancing the
field of explainable artificial intelligence.

</details>


### [160] [Re4: Scientific Computing Agent with Rewriting, Resolution, Review and Revision](https://arxiv.org/abs/2508.20729)
*Ao Cheng,Lei Zhang,Guowei He*

Main category: cs.AI

TL;DR: A collaborative LLM agent framework (Consultant, Reviewer, Programmer) improves scientific code generation by integrating rewriting, execution, and review, reducing errors and non-physical solutions.


<details>
  <summary>Details</summary>
Motivation: To improve the bug-free code generation rate and reduce non-physical solutions in scientific computing by leveraging collaborative LLMs.

Method: The proposed agent incorporates a 'rewriting-resolution-review-revision' logical chain via three reasoning LLMs (Consultant, Reviewer, and Programmer), integrated collaboratively. The Consultant rewrites problem descriptions, the Programmer generates and executes code, and the Reviewer provides self-debugging and refinement through interactive feedback.

Result: The framework significantly improves bug-free code generation and reduces non-physical solutions, enhancing execution success rates for scientific problems like PDEs and ill-conditioned linear systems.

Conclusion: Our agent framework establishes automatic code generation and review as a promising scientific computing paradigm.

Abstract: Large language models (LLMs) serve as an active and promising field of
generative artificial intelligence and have demonstrated abilities to perform
complex tasks in multiple domains, including mathematical and scientific
reasoning. In this work, we construct a novel agent framework for solving
representative problems in scientific computing. The proposed agent,
incorporating a "rewriting-resolution-review-revision" logical chain via three
reasoning LLMs (functioning as the Consultant, Reviewer, and Programmer,
respectively), is integrated in a collaborative and interactive manner. The
Consultant module endows the agent with knowledge transfer capabilities to link
problems to professional domain insights, thereby rewriting problem
descriptions through text augmentation. The Programmer module is responsible
for generating and executing well-structured code to deliver the problem
resolution. The Reviewer module equips the agent with the capacity for
self-debugging and self-refinement through interactive feedback with code
runtime outputs. By leveraging the end-to-end review mechanism, the executable
code provided by the Programmer attains the iterative revision. A comprehensive
evaluation is conducted on the performance of the proposed agent framework in
solving PDEs, ill-conditioned linear systems, and data-driven physical analysis
problems. Compared to single-model, this collaborative framework significantly
improves the bug-free code generation rate and reduces the occurrence of
non-physical solutions, thereby establishing a highly reliable framework for
autonomous code generation based on natural language descriptions. The review
mechanism improved the average execution success (bug-free code and non-NaN
solutions) rate of the latest reasoning models. In summary, our agent framework
establishes automatic code generation and review as a promising scientific
computing paradigm.

</details>


### [161] [Single Agent Robust Deep Reinforcement Learning for Bus Fleet Control](https://arxiv.org/abs/2508.20784)
*Yifan Zhang*

Main category: cs.AI

TL;DR: 本文提出一种单智能体强化学习框架，通过状态空间增强和结构化奖励设计，有效解决公交车聚集问题，性能优于多智能体方法。


<details>
  <summary>Details</summary>
Motivation: 公交车聚集问题因随机交通和乘客需求而难以解决，传统多智能体强化学习方法在非环形、现实场景中存在数据不平衡和收敛问题。

Method: 提出了一种单智能体强化学习框架，通过状态空间增强（加入分类标识符和数值特征）和结构化奖励函数设计，将多智能体问题转化为单智能体问题。

Result: 实验表明，改进的软演员-评论家算法（SAC）在随机条件下表现更稳定且优于基准方法（如MADDPG）。

Conclusion: 本文提出了一种新颖的单智能体强化学习框架，通过增强状态空间和设计结构化奖励函数，有效解决了公交车聚集问题，并在非环形、现实场景中表现出优于多智能体方法的性能。

Abstract: Bus bunching remains a challenge for urban transit due to stochastic traffic
and passenger demand. Traditional solutions rely on multi-agent reinforcement
learning (MARL) in loop-line settings, which overlook realistic operations
characterized by heterogeneous routes, timetables, fluctuating demand, and
varying fleet sizes. We propose a novel single-agent reinforcement learning
(RL) framework for bus holding control that avoids the data imbalance and
convergence issues of MARL under near-realistic simulation. A bidirectional
timetabled network with dynamic passenger demand is constructed. The key
innovation is reformulating the multi-agent problem into a single-agent one by
augmenting the state space with categorical identifiers (vehicle ID, station
ID, time period) in addition to numerical features (headway, occupancy,
velocity). This high-dimensional encoding enables single-agent policies to
capture inter-agent dependencies, analogous to projecting non-separable inputs
into a higher-dimensional space. We further design a structured reward function
aligned with operational goals: instead of exponential penalties on headway
deviations, a ridge-shaped reward balances uniform headways and schedule
adherence. Experiments show that our modified soft actor-critic (SAC) achieves
more stable and superior performance than benchmarks, including MADDPG (e.g.,
-430k vs. -530k under stochastic conditions). These results demonstrate that
single-agent deep RL, when enhanced with categorical structuring and
schedule-aware rewards, can effectively manage bus holding in non-loop,
real-world contexts. This paradigm offers a robust, scalable alternative to
MARL frameworks, particularly where agent-specific experiences are imbalanced.

</details>


### [162] [A Graph-Based Test-Harness for LLM Evaluation](https://arxiv.org/abs/2508.20810)
*Jessica Lundin,Guillaume Chabot-Couture*

Main category: cs.AI

TL;DR: 该论文提出了一种基于图的动态医疗指南评测方法，系统评估临床任务并增强LLM训练，覆盖全面且可动态更新。


<details>
  <summary>Details</summary>
Motivation: 解决手动策划基准测试的覆盖限制，动态生成全面且可更新的医疗指南评测标准。

Method: 将WHO IMCI手册转化为包含200+节点和300+边的有向图，通过图遍历生成问题，结合年龄特定场景和上下文干扰项。

Result: 模型在症状识别上表现良好（45-67%准确率），但在严重程度分级、治疗方案和随访护理上存在困难。

Conclusion: 该论文提出了一种基于图结构的动态医疗指南基准测试方法，能够系统评估临床任务，并增强大型语言模型的后期训练。

Abstract: We present a first known prototype of a dynamic, systematic benchmark of
medical guidelines for 400+ questions, with 3.3+ trillion possible
combinations, covering 100\% of guideline relationships. We transformed the WHO
IMCI handbook into a directed graph with 200+ nodes (conditions, symptoms,
treatments, follow-ups, severities) and 300+ edges, then used graph traversal
to generate questions that incorporated age-specific scenarios and contextual
distractors to ensure clinical relevance. Our graph-based approach enables
systematic evaluation across clinical tasks (45-67\% accuracy), and we find
models excel at symptom recognition but struggle with triaging severity,
treatment protocols and follow-up care, demonstrating how customized benchmarks
can identify specific capability gaps that general-domain evaluations miss.
Beyond evaluation, this dynamic MCQA methodology enhances LLM post-training
(supervised finetuning, GRPO, DPO), where correct answers provide high-reward
samples without expensive human annotation. The graph-based approach
successfully addresses the coverage limitations of manually curated benchmarks.
This methodology is a step toward scalable, contamination-resistant solution
for creating comprehensive benchmarks that can be dynamically generated,
including when the guidelines are updated. Code and datasets are available at
https://github.com/jessicalundin/graph_testing_harness

</details>


### [163] [A Multi-Objective Genetic Algorithm for Healthcare Workforce Scheduling](https://arxiv.org/abs/2508.20953)
*Vipul Patel,Anirudh Deodhar,Dagnachew Birru*

Main category: cs.AI

TL;DR: 论文提出一种多目标遗传算法（MOO-GA）用于医疗人力资源调度，平衡成本、患者护理和员工满意度，实验显示性能提升66%，为管理者提供实用工具。


<details>
  <summary>Details</summary>
Motivation: 医疗行业人力资源调度面临患者负载波动、多样化的临床技能需求以及控制劳动力成本与保持高患者护理标准之间的矛盾，这需要平衡多个竞争目标。

Method: 论文采用多目标遗传算法（MOO-GA）对医院单位人力资源调度问题进行建模，考虑了实时预约驱动需求和模块化班次等现实复杂性，通过定义成本、患者护理覆盖率和员工满意度的目标函数，在搜索空间中寻找高质量的非支配解。

Result: 在典型医院单位数据集上的实验结果表明，MOO-GA生成的排班表比传统手动排班方法的性能平均提高了66%，能够有效管理关键运营和员工中心目标之间的权衡。

Conclusion: 该论文提出的多目标遗传算法（MOO-GA）在医疗人力资源调度中表现出色，能够平衡成本、患者护理覆盖率和员工满意度，为护士长和医院管理者提供了实用的决策支持工具。

Abstract: Workforce scheduling in the healthcare sector is a significant operational
challenge, characterized by fluctuating patient loads, diverse clinical skills,
and the critical need to control labor costs while upholding high standards of
patient care. This problem is inherently multi-objective, demanding a delicate
balance between competing goals: minimizing payroll, ensuring adequate staffing
for patient needs, and accommodating staff preferences to mitigate burnout. We
propose a Multi-objective Genetic Algorithm (MOO-GA) that models the hospital
unit workforce scheduling problem as a multi-objective optimization task. Our
model incorporates real-world complexities, including hourly appointment-driven
demand and the use of modular shifts for a multi-skilled workforce. By defining
objective functions for cost, patient care coverage, and staff satisfaction,
the GA navigates the vast search space to identify a set of high-quality,
non-dominated solutions. Demonstrated on datasets representing a typical
hospital unit, the results show that our MOO-GA generates robust and balanced
schedules. On average, the schedules produced by our algorithm showed a 66\%
performance improvement over a baseline that simulates a conventional, manual
scheduling process. This approach effectively manages trade-offs between
critical operational and staff-centric objectives, providing a practical
decision support tool for nurse managers and hospital administrators.

</details>


### [164] [Efficient Neuro-Symbolic Learning of Constraints and Objective](https://arxiv.org/abs/2508.20978)
*Marianne Defresne,Romain Gambardella,Sophie Barbe,Thomas Schiex*

Main category: cs.AI

TL;DR: 论文提出了一种可微分的神经符号架构和专用损失函数，用于学习解决NP难推理问题，并在多个基准测试中展示了高效性和优越性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决离散推理或优化问题上表现不佳，促使研究者探索能学习解决此类问题的神经架构。

Method: 引入了一种新的概率损失函数，允许学习约束和目标，同时将组合求解器移出训练循环，实现可扩展训练和精确推理。

Result: 在数独基准测试和视觉最小割/最大割任务中表现优于其他混合方法，并在蛋白质设计等实际问题上高效学习能量优化。

Conclusion: 该架构在学习和解决NP难推理问题方面表现出色，为神经符号混合方法提供了新的可能性。

Abstract: In the ongoing quest for hybridizing discrete reasoning with neural nets,
there is an increasing interest in neural architectures that can learn how to
solve discrete reasoning or optimization problems from natural inputs, a task
that Large Language Models seem to struggle with.
  Objectives: We introduce a differentiable neuro-symbolic architecture and a
loss function dedicated to learning how to solve NP-hard reasoning problems.
  Methods: Our new probabilistic loss allows for learning both the constraints
and the objective, thus delivering a complete model that can be scrutinized and
completed with side constraints. By pushing the combinatorial solver out of the
training loop, our architecture also offers scalable training while exact
inference gives access to maximum accuracy.
  Results: We empirically show that it can efficiently learn how to solve
NP-hard reasoning problems from natural inputs. On three variants of the Sudoku
benchmark -- symbolic, visual, and many-solution --, our approach requires a
fraction of training time of other hybrid methods. On a visual Min-Cut/Max-cut
task, it optimizes the regret better than a Decision-Focused-Learning
regret-dedicated loss. Finally, it efficiently learns the energy optimization
formulation of the large real-world problem of designing proteins.

</details>


### [165] [ChatThero: An LLM-Supported Chatbot for Behavior Change and Therapeutic Support in Addiction Recovery](https://arxiv.org/abs/2508.20996)
*Junda Wang,Zonghai Yao,Zhichao Yang,Lingxi Li,Junhui Qian,Hong Yu*

Main category: cs.AI

TL;DR: ChatThero 是一个结合 CBT 和 MI 的多代理对话框架，显著提升患者动机和治疗信心，表现优于 GPT-4o，适用于隐私保护的治疗对话研究。


<details>
  <summary>Details</summary>
Motivation: 全球有超过 3600 万人受物质使用障碍（SUDs）影响，但很少人获得有效治疗，原因包括污名化、动机障碍和缺乏个性化支持。尽管大型语言模型（LLMs）在心理健康辅助方面有潜力，但大多数系统缺乏与临床验证策略的紧密结合。

Method: ChatThero 采用多代理对话框架，结合动态患者建模、上下文敏感的治疗对话以及基于认知行为疗法（CBT）和动机访谈（MI）的自适应说服策略。通过两阶段训练流程（监督微调 SFT 和直接偏好优化 DPO）进行训练。

Result: ChatThero 在患者动机上平均提升了 41.5%，治疗信心增加了 0.49%，并在困难案例中比 GPT-4o 少用 26% 的对话轮次。自动和人类临床评估均认为其在同理心、响应性和行为真实性上表现更优。

Conclusion: ChatThero 提供了一个严格的、保护隐私的治疗对话研究框架，为研究和临床转化提供了稳健且可复制的基础。

Abstract: Substance use disorders (SUDs) affect over 36 million people worldwide, yet
few receive effective care due to stigma, motivational barriers, and limited
personalized support. Although large language models (LLMs) show promise for
mental-health assistance, most systems lack tight integration with clinically
validated strategies, reducing effectiveness in addiction recovery. We present
ChatThero, a multi-agent conversational framework that couples dynamic patient
modeling with context-sensitive therapeutic dialogue and adaptive persuasive
strategies grounded in cognitive behavioral therapy (CBT) and motivational
interviewing (MI). We build a high-fidelity synthetic benchmark spanning Easy,
Medium, and Hard resistance levels, and train ChatThero with a two-stage
pipeline comprising supervised fine-tuning (SFT) followed by direct preference
optimization (DPO). In evaluation, ChatThero yields a 41.5\% average gain in
patient motivation, a 0.49\% increase in treatment confidence, and resolves
hard cases with 26\% fewer turns than GPT-4o, and both automated and human
clinical assessments rate it higher in empathy, responsiveness, and behavioral
realism. The framework supports rigorous, privacy-preserving study of
therapeutic conversation and provides a robust, replicable basis for research
and clinical translation.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [166] [Commitment Gap via Correlation Gap](https://arxiv.org/abs/2508.20246)
*Shuchi Chawla,Dimitris Christou,Trung Dang*

Main category: cs.DS

TL;DR: 本研究通过简化CICS问题为信息免费的贝叶斯组合选择，改进了承诺差距的界限，并获得了更好的近似结果。


<details>
  <summary>Details</summary>
Motivation: 解决CICS问题中确定最优算法的计算挑战，并改进对承诺差距的界限。

Method: 通过将CICS问题简化为贝叶斯组合选择问题，并建立两者之间的紧密关系，将CICS的承诺差距与先知不等式联系起来。

Result: 改进了CICS的承诺差距界限，并获得了更好的近似结果，包括在拟阵可行性约束下的Pandora's Box问题。

Conclusion: 通过将CICS问题简化为信息免费的贝叶斯组合选择问题，本研究改进了对承诺差距的界限，并获得了更好的近似结果。

Abstract: Selection problems with costly information, dating back to Weitzman's
Pandora's Box problem, have received much attention recently. We study the
general model of Costly Information Combinatorial Selection (CICS) that was
recently introduced by Chawla et al. [2024] and Bowers et al. [2025]. In this
problem, a decision maker needs to select a feasible subset of stochastic
variables, and can only learn information about their values through a series
of costly steps, modeled by a Markov decision process. The algorithmic
objective is to maximize the total value of the selection minus the cost of
information acquisition. However, determining the optimal algorithm is known to
be a computationally challenging problem.
  To address this challenge, previous approaches have turned to approximation
algorithms by considering a restricted class of committing policies that
simplify the decision-making aspects of the problem and allow for efficient
optimization. This motivates the question of bounding the commitment gap,
measuring the worst case ratio in the performance of the optimal committing
policy and the overall optimal.
  In this work, we obtain improved bounds on the commitment gap of CICS through
a reduction to a simpler problem of Bayesian Combinatorial Selection where
information is free. By establishing a close relationship between these
problems, we are able to relate the commitment gap of CICS to ex ante
free-order prophet inequalities. As a consequence, we obtain improved
approximation results for CICS, including the well-studied variant of Pandora's
Box with Optional Inspection under matroid feasibility constraints.

</details>


### [167] [Reducing Shortcut and Hopset Constructions to Shallow Graphs](https://arxiv.org/abs/2508.20302)
*Bernhard Haeupler,Yonggang Jiang,Thatchaphol Saranurak*

Main category: cs.DS

TL;DR: 黑盒框架简化并行算法，适用于有向图中的单源可达性和最短路径问题，简化捷径构建过程。


<details>
  <summary>Details</summary>
Motivation: 现有并行算法在构建捷径时复杂度较高，作者希望通过简化这一过程，提供更简洁的并行可达性算法。

Method: 通过构建捷径的黑盒框架，假设输入图为“浅层”图，即顶点间的可达性可在近似h跳内完成，从而简化捷径构建过程。

Result: 该框架不仅简化了并行可达性算法，还扩展至简化构建跳集的并行算法，进而简化最短路径的计算。

Conclusion: 该论文提出的黑盒框架简化了所有已知的并行算法，适用于有向图中的单源可达性和最短路径问题，显著简化了现有算法的实现。

Abstract: We introduce a blackbox framework that simplifies all known parallel
algorithms with near-linear work for single-source reachability and shortest
paths in directed graphs. Specifically, existing reachability algorithms rely
on constructing shortcuts; our blackbox allows these algorithms that construct
shortcuts with hopbound $h$ to assume the input graph $G$ is ``shallow'',
meaning if vertex $s$ can reach vertex $t$, it can do so in approximately $h$
hops. This assumption significantly simplifies shortcut construction [Fin18,
JLS19], resulting in simpler parallel reachability algorithms. Furthermore, our
blackbox extends naturally to simplify parallel algorithms for constructing
hopsets and, consequently, for computing shortest paths [CFR20 , CF23 , RHM+23
].

</details>


### [168] [Directed and Undirected Vertex Connectivity Problems are Equivalent for Dense Graphs](https://arxiv.org/abs/2508.20305)
*Yonggang Jiang,Sagnik Mukhopadhyay,Sorrachai Yingchareonthawornchai*

Main category: cs.DS

TL;DR: 本文通过黑盒随机化方法简化有向顶点连通性算法，并首次实现加权版本的亚三次时间算法。


<details>
  <summary>Details</summary>
Motivation: 有向顶点连通性问题的传统解决方法需要手动扩展无向图算法，过程复杂且耗时。

Method: 采用黑盒随机化方法，将有向顶点连通性问题转化为无向顶点连通性问题。

Result: 提出的方法简化了有向顶点连通性算法的证明，并首次实现了加权有向顶点连通性的亚三次时间算法。

Conclusion: 本文提出了一种简单的黑盒随机化方法，将稠密图的有向顶点连通性问题转化为无向顶点连通性问题，从而简化了相关算法证明并提升了性能。

Abstract: Vertex connectivity and its variants are among the most fundamental problems
in graph theory, with decades of extensive study and numerous algorithmic
advances. The directed variants of vertex connectivity are usually solved by
manually extending fast algorithms for undirected graphs, which has required
considerable effort.
  In this paper, we present a simple, black-box randomized reduction from
directed to undirected vertex connectivity for dense graphs. As immediate
corollaries, we largely simplify the proof for directed vertex connectivity in
$n^{2+o(1)}$ time [LNP+25], and obtain a parallel vertex connectivity algorithm
for directed graphs with $n^{\omega+o(1)}$ work and $n^{o(1)}$ depth, via the
undirected vertex connectivity algorithm of [BJMY25]. Our reduction further
extends to the weighted version of the problem. By combining our reduction with
the recent subcubic-time algorithm for undirected weighted vertex cuts [CT25],
we obtain the first subcubic-time algorithm for weighted directed vertex
connectivity, improving upon a three-decade-old bound [HRG00] for dense graphs.

</details>


### [169] [Improved Dominance Filtering for Unions and Minkowski Sums of Pareto Sets](https://arxiv.org/abs/2508.20689)
*Konstantinos Karathanasis,Spyros Kontogiannis,Christos Zaroliagis*

Main category: cs.DS

TL;DR: 提出三种新数据结构和算法，显著提升帕累托集联合和Minkowski和的支配过滤效率，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 在多目标优化中，计算帕累托子集（或前沿）是核心任务，但现有方法在处理联合或Minkowski和的帕累托集时效率不足，成为瓶颈。

Method: 提出了三种新的数据结构（ND$^{+}$-trees、QND$^{+}$-trees和TND$^{+}$-trees）和三种算法，用于高效索引非支配目标向量并进行支配性检查。

Result: 实验表明，新算法在合成和真实数据集上均优于现有技术，尤其在高维和大规模场景下表现更优。

Conclusion: 新提出的ND$^{+}$-trees、QND$^{+}$-trees和TND$^{+}$-trees数据结构及三种算法在高效过滤支配目标向量方面表现优异，尤其在处理高维（$d\ge 3$）和大规模帕累托集时，显著优于现有技术。

Abstract: A key task in multi-objective optimization is to compute the Pareto subset or
frontier $P$ of a given $d$-dimensional objective space $F$; that is, a maximal
subset $P\subseteq F$ such that every element in $P$ is not-dominated (it is
not worse in all criteria) by any element in $F$. This process, called
dominance-filtering, often involves handling objective spaces derived from
either the union or the Minkowski sum of two given partial objective spaces
which are Pareto sets themselves, and constitutes a major bottleneck in several
multi-objective optimization techniques. In this work, we introduce three new
data structures, ND$^{+}$-trees, QND$^{+}$-trees and TND$^{+}$-trees, which are
designed for efficiently indexing non-dominated objective vectors and
performing dominance-checks. We also devise three new algorithms that
efficiently filter out dominated objective vectors from the union or the
Minkowski sum of two Pareto sets. An extensive experimental evaluation on both
synthetically generated and real-world data sets reveals that our new
algorithms outperform state-of-art techniques for dominance-filtering of unions
and Minkowski sums of Pareto sets, and scale well w.r.t. the number of $d\ge 3$
criteria and the sets' sizes.

</details>


### [170] [Sharp Online Hardness for Large Balanced Independent Sets](https://arxiv.org/abs/2508.20785)
*Abhishek Dhawan,Eren C. Kızıldağ,Neeladri Maitra*

Main category: cs.DS

TL;DR: 论文研究了密集随机二分图中γ平衡独立集的大小和算法设计，证明了其大小并设计了一种高效的在线算法，同时通过下界证明了算法的紧性，支持了统计-计算差距的普遍性猜想。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探索在密集随机二分图中寻找大型γ平衡独立集的算法问题，尤其是在稀疏随机图中已有研究但技术不适用于密集设置的情况下。

Method: 论文的方法包括设计一种两阶段的在线算法，结合停止时间和适当的截断以确保γ平衡性这一全局约束在有限信息下得到满足。此外，还利用OGP框架及其在线模型的扩展来证明下界。

Result: 主要结果是证明了最大的γ平衡独立集的大小为α=log_b n / (γ(1-γ))，并设计了一种在线算法能够以高概率达到(1-ε)(1-γ)α。同时，通过下界证明了算法的紧性。

Conclusion: 论文的结论表明，在密集随机二分图中，最大的γ平衡独立集的大小为α=log_b n / (γ(1-γ))，且设计了一种在线算法能够以高概率达到(1-ε)(1-γ)α。同时，通过尖锐的下界证明了没有在线算法能够以显著概率达到(1+ε)(1-γ)α，支持了统计-计算差距的普遍性猜想。

Abstract: We study the algorithmic problem of finding large $\gamma$-balanced
independent sets in dense random bipartite graphs; an independent set is
$\gamma$-balanced if a $\gamma$ proportion of its vertices lie on one side of
the bipartition. In the sparse regime, Perkins and Wang established tight
bounds within the low-degree polynomial (LDP) framework, showing a
factor-$1/(1-\gamma)$ statistical-computational gap via the Overlap Gap
Property (OGP) framework tailored for stable algorithms. However, these
techniques do not appear to extend to the dense setting. For the related large
independent set problem in dense random graph, the best known algorithm is an
online greedy procedure that is inherently unstable, and LDP algorithms are
conjectured to fail even in the "easy" regime where greedy succeeds. We show
that the largest $\gamma$-balanced independent set in dense random bipartite
graphs has size $\alpha:=\frac{\log_b n}{\gamma(1-\gamma)}$ whp, where $n$ is
the size of each bipartition, $p$ is the edge probability, and $b=1/(1-p)$. We
design an online algorithm that achieves $(1-\epsilon)(1-\gamma)\alpha$ whp for
any $\epsilon>0$. We complement this with a sharp lower bound, showing that no
online algorithm can achieve $(1+\epsilon)(1-\gamma)\alpha$ with nonnegligible
probability. Our results suggest that the same factor-$1/(1-\gamma)$ gap is
also present in the dense setting, supporting its conjectured universality.
While the classical greedy procedure on $G(n,p)$ is straightforward, our
algorithm is more intricate: it proceeds in two stages, incorporating a
stopping time and suitable truncation to ensure that $\gamma$-balancedness-a
global constraint-is met despite operating with limited information. Our lower
bound utilizes the OGP framework; we build on a recent refinement of this
framework for online models and extend it to the bipartite setting.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [171] [A Comprehensive Survey of 5G URLLC and Challenges in the 6G Era](https://arxiv.org/abs/2508.20205)
*Md. Emadul Haque,Faisal Tariq,Muhammad R A Khandaker,Md. Sakir Hossain,Muhammad Ali Imran,Kai-Kit Wong*

Main category: cs.NI

TL;DR: 本文综述了5G系统中URLLC的方法，探讨了延迟和可靠性问题的历史演变，并展望了6G的未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信从以人为中心转向以机器为中心，对速率、延迟和可靠性的需求发生了巨大变化，因此URLLC成为5G和6G系统的核心主题。

Method: 采用了分层方法，详细讨论了物理层、MAC层以及跨层技术。

Result: 文章详细分析了5G系统中URLLC的各种方法，并探讨了不同垂直领域的设计考虑。

Conclusion: 文章总结了URLLC在5G系统中的挑战和未来展望，特别是对新兴6G范式的关注。

Abstract: As the wireless communication paradigm is being transformed from human
centered communication services towards machine centered communication
services, the requirements of rate, latency and reliability for these services
have also been transformed drastically. Thus the concept of Ultra Reliable and
Low Latency Communication (URLLC) has emerged as a dominant theme for 5G and 6G
systems. Though the latency and reliability requirement varies from one use
case to another, URLLC services generally aim to achieve very high reliability
in the range of 99.999\% while ensuring the latency of up to 1 ms. These two
targets are however inherently opposed to one another. Significant amounts of
work have been carried out to meet these ambitious but conflicting targets. In
this article a comprehensive survey of the URLLC approaches in 5G systems are
analysed in detail. Effort has been made to trace the history and evolution of
latency and reliability issues in wireless communication. A layered approach is
taken where physical layer, Medium Access Control (MAC) layer as well as cross
layer techniques are discussed in detail. It also covers the design
consideration for various 5G and beyond verticals. Finally the article
concludes by providing a detailed discussion on challenges and future outlook
with particular focus on the emerging 6G paradigm.

</details>


### [172] [DRR-MDPF: A Queue Management Strategy Based on Dynamic Resource Allocation and Markov Decision Process in Named Data Networking (NDN)](https://arxiv.org/abs/2508.20272)
*Fatemeh Roshanzadeh,Hamid Barati,Ali Barati*

Main category: cs.NI

TL;DR: DRR-MDPF是一种结合MDPF和DRR的混合策略，显著提升NDN性能，尤其在动态和高流量环境下表现出色。


<details>
  <summary>Details</summary>
Motivation: 命名数据网络（NDN）通过优先考虑内容名称而非主机地址来增强数据传播，高效的队列和资源管理对NDN性能至关重要，尤其是在动态和高流量条件下。

Method: 本文提出了一种名为DRR-MDPF的混合策略，将马尔可夫决策过程转发（MDPF）模型与赤字轮询（DRR）算法相结合。MDPF使路由器能够基于带宽、延迟和未满足兴趣数等关键指标智能预测最佳转发决策，而DRR确保竞争数据流之间的公平和自适应带宽分配。

Result: 使用ndnSIM的仿真结果表明，DRR-MDPF在吞吐量、兴趣满足率（ISR）、丢包率、内容检索时间和负载均衡等多个指标上显著优于现有策略（如SAF、RFA、SMDPF和LA-MDPF）。此外，DRR-MDPF在有限缓存大小和重流量下保持鲁棒性，并因其单路径路由设计而具有较低的复杂度。

Conclusion: DRR-MDPF作为一种智能、自适应且可扩展的队列管理解决方案，有效解决了NDN中的核心挑战，如资源分配、拥塞控制和动态网络环境中的路由优化。

Abstract: Named Data Networking (NDN) represents a transformative shift in network
architecture, prioritizing content names over host addresses to enhance data
dissemination. Efficient queue and resource management are critical to NDN
performance, especially under dynamic and high-traffic conditions. This paper
introduces DRR-MDPF, a novel hybrid strategy that integrates the Markov
Decision Process Forwarding (MDPF) model with the Deficit Round Robin (DRR)
algorithm. MDPF enables routers to intelligently predict optimal forwarding
decisions based on key metrics such as bandwidth, delay, and the number of
unsatisfied Interests, while DRR ensures fair and adaptive bandwidth allocation
among competing data flows. The proposed method models each router as a
learning agent capable of adjusting its strategies through continuous feedback
and probabilistic updates. Simulation results using ndnSIM demonstrate that
DRR-MDPF significantly outperforms state-of-the-art strategies including SAF,
RFA, SMDPF, and LA-MDPF across various metrics such as throughput, Interest
Satisfaction Rate (ISR), packet drop rate, content retrieval time, and load
balancing. Notably, DRR-MDPF maintains robustness under limited cache sizes and
heavy traffic, offering enhanced adaptability and lower computational
complexity due to its single-path routing design. Furthermore, its multi-metric
decision-making capability enables more accurate interface selection, leading
to optimized network performance. Overall, DRR-MDPF serves as an intelligent,
adaptive, and scalable queue management solution for NDN, effectively
addressing core challenges such as resource allocation, congestion control, and
route optimization in dynamic networking environments.

</details>


### [173] [Relay Selection in Wireless Networks as Restless Bandits](https://arxiv.org/abs/2508.20625)
*Mandar R. Nalavade,Ravindra S. Tomar,Gaurav S. Kasbekar*

Main category: cs.NI

TL;DR: 本文提出了一种基于Whittle指数的中继选择策略，通过选择最小Whittle指数的中继来优化无线网络中的数据传输成本、延迟和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 在无线网络中，当源节点与目标节点之间的直接链路被阻塞时，需要通过多个候选中继转发数据包。每个中继在每个时隙存储数据包会产生持有成本。目标是设计一种中继选择策略，以最小化长期平均总包持有成本。

Method: 本文证明了中继选择问题具有Whittle可索引性，并提出了计算每个中继在每个时隙的Whittle指数的方法。在每个时隙中，选择Whittle指数最小的中继进行数据传输。

Result: 通过仿真实验，本文提出的策略在平均成本、延迟和吞吐量方面优于先前提出的中继选择策略。

Conclusion: 本文提出了一种基于Whittle指数的中继选择策略，通过在每个时隙选择具有最小Whittle指数的中继来传输数据包，从而最小化长期平均总包持有成本。实验证明该策略在平均成本、延迟和吞吐量方面优于现有方法。

Abstract: We consider a wireless network in which a source node needs to transmit a
large file to a destination node. The direct wireless link between the source
and the destination is assumed to be blocked. Multiple candidate relays are
available to forward packets from the source to the destination. A holding cost
is incurred for each packet stored at every relay in each time slot. The
objective is to design a policy for selecting a relay in each time slot to
which the source attempts to send a packet, so as to minimize the expected
long-run time-averaged total packet holding cost at the relays. This problem is
an instance of the restless multi-armed bandit (RMAB) problem, which is
provably hard to solve. We prove that this relay selection problem is
Whittle-indexable, and propose a method to compute the Whittle index of each
relay in every time slot. In each time slot, our relay selection policy
transmits a packet to the relay with the smallest Whittle index. Using
simulations, we show that the proposed policy outperforms the relay selection
policies proposed in prior work in terms of average cost, delay, as well as
throughput.

</details>


### [174] [Digital Twin-Empowered Deep Reinforcement Learning for Intelligent VNF Migration in Edge-Core Networks](https://arxiv.org/abs/2508.20957)
*Faisal Ahmed,Suresh Subramaniam,Motoharu Matsuura,Hiroshi Hasegawa,Shih-Chun Lin*

Main category: cs.NI

TL;DR: 该论文提出了一种基于数字孪生和深度强化学习的智能VNF迁移框架，有效降低延迟和能耗，适用于边缘核心网络。


<details>
  <summary>Details</summary>
Motivation: 现代边缘核心网络基础设施中，服务需求增长和虚拟化网络功能（VNF）快速部署对低延迟和高效能编排提出了重大挑战。

Method: 研究将VNF迁移问题建模为马尔可夫决策过程，并采用优势演员-评论家（A2C）模型实现自适应实时迁移决策。创新性地集成了由多任务变分自编码器和多任务长短期记忆网络组成的DT模块，以模拟环境动态并生成高质量合成经验。

Result: 仿真结果显示，该框架在平均端到端延迟和能耗方面均实现显著降低。

Conclusion: 该研究通过数字孪生（DT）赋能的深度强化学习框架，显著降低了边缘核心网络中的平均端到端延迟和能耗，为智能VNF迁移设立了新基准。

Abstract: The growing demand for services and the rapid deployment of virtualized
network functions (VNFs) pose significant challenges for achieving low-latency
and energy-efficient orchestration in modern edge-core network infrastructures.
To address these challenges, this study proposes a Digital Twin (DT)-empowered
Deep Reinforcement Learning framework for intelligent VNF migration that
jointly minimizes average end-to-end (E2E) delay and energy consumption. By
formulating the VNF migration problem as a Markov Decision Process and
utilizing the Advantage Actor-Critic model, the proposed framework enables
adaptive and real-time migration decisions. A key innovation of the proposed
framework is the integration of a DT module composed of a multi-task
Variational Autoencoder and a multi-task Long Short-Term Memory network. This
combination collectively simulates environment dynamics and generates
high-quality synthetic experiences, significantly enhancing training efficiency
and accelerating policy convergence. Simulation results demonstrate substantial
performance gains, such as significant reductions in both average E2E delay and
energy consumption, thereby establishing new benchmarks for intelligent VNF
migration in edge-core networks.

</details>


### [175] [RANGAN: GAN-empowered Anomaly Detection in 5G Cloud RAN](https://arxiv.org/abs/2508.20985)
*Douglas Liao,Jiping Luo,Jens Vevstad,Nikolaos Pappas*

Main category: cs.NI

TL;DR: RANGAN是一种结合GAN和Transformer的异常检测框架，用于处理RAN系统中的性能异常，实验显示其在网络竞争问题检测上表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于RAN系统的复杂性和高动态性，传统方法难以有效处理其产生的大量数据并准确检测性能异常。因此，需要一种自适应的方法来可靠地捕捉时间依赖性并检测异常。

Method: RANGAN整合了生成对抗网络（GAN）和Transformer架构，并采用滑动窗口方法进行数据预处理，以捕捉数据中的时间依赖性。

Result: 实验结果表明，RANGAN在公开的RAN性能数据集上表现优异，尤其在识别网络竞争问题时达到了83%的F1分数。

Conclusion: RANGAN框架通过结合生成对抗网络和Transformer架构，有效提升了RAN系统中异常检测的准确性，特别是在识别网络竞争问题时表现出色。

Abstract: Radio Access Network (RAN) systems are inherently complex, requiring
continuous monitoring to prevent performance degradation and ensure optimal
user experience. The RAN leverages numerous key performance indicators (KPIs)
to evaluate system performance, generating vast amounts of data each second.
This immense data volume can make troubleshooting and accurate diagnosis of
performance anomalies more difficult. Furthermore, the highly dynamic nature of
RAN performance demands adaptive methodologies capable of capturing temporal
dependencies to detect anomalies reliably. In response to these challenges, we
introduce \textbf{RANGAN}, an anomaly detection framework that integrates a
Generative Adversarial Network (GAN) with a transformer architecture. To
enhance the capability of capturing temporal dependencies within the data,
RANGAN employs a sliding window approach during data preprocessing. We
rigorously evaluated RANGAN using the publicly available RAN performance
dataset from the Spotlight project \cite{sun-2024}. Experimental results
demonstrate that RANGAN achieves promising detection accuracy, notably
attaining an F1-score of up to $83\%$ in identifying network contention issues.

</details>


### [176] [DSROQ: Dynamic Scheduling and Routing for QoE Management in LEO Satellite Networks](https://arxiv.org/abs/2508.21047)
*Dhiraj Bhattacharjee,Pablo G. Madoery,Abhishek Naik,Halim Yanikomeroglu,Gunes Karabulut Kurt,Stephane Martel,Khaled Ahmed*

Main category: cs.NI

TL;DR: DSROQ算法通过联合路由和带宽分配优化LEO卫星网络的QoS，提升用户体验和公平性，并揭示性能主导因素的动态变化。


<details>
  <summary>Details</summary>
Motivation: 现代互联网应用对服务质量（QoS）有异构需求，LEO卫星星座可扩展覆盖并补充地面网络，需通过联合优化路由、带宽分配和动态队列调度来保障QoS。

Method: 提出了一种受蒙特卡洛树搜索（MCTS）启发的算法，结合Lyapunov优化的调度方法，解决路由和带宽分配的NP难问题。

Result: 在Starlink Phase 1 Version 2星座上的实验表明，DSROQ算法在用户体验和公平性上优于基准方案，且性能主导因素随流量敏感度从延迟驱动转向带宽驱动而发生变化。

Conclusion: 本文通过DSROQ算法在LEO卫星网络中联合优化路由和带宽分配，显著提升了用户体验和公平性，并揭示了不同流量敏感度下性能主导因素的转变。

Abstract: The modern Internet supports diverse applications with heterogeneous quality
of service (QoS) requirements. Low Earth orbit (LEO) satellite constellations
offer a promising solution to meet these needs, enhancing coverage in rural
areas and complementing terrestrial networks in urban regions. Ensuring QoS in
such networks requires joint optimization of routing, bandwidth allocation, and
dynamic queue scheduling, as traffic handling is critical for maintaining
service performance. This paper formulates a joint routing and bandwidth
allocation problem where QoS requirements are treated as soft constraints,
aiming to maximize user experience. An adaptive scheduling approach is
introduced to prioritize flow-specific QoS needs. We propose a Monte Carlo tree
search (MCTS)-inspired method to solve the NP-hard route and bandwidth
allocation problem, with Lyapunov optimization-based scheduling applied during
reward evaluation. Using the Starlink Phase 1 Version 2 constellation, we
compare end-user experience and fairness between our proposed DSROQ algorithm
and a benchmark scheme. Results show that DSROQ improves both performance
metrics and demonstrates the advantage of joint routing and bandwidth
decisions. Furthermore, we observe that the dominant performance factor shifts
from scheduling to routing and bandwidth allocation as traffic sensitivity
changes from latency-driven to bandwidth-driven.

</details>
