<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 59]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.NI](#cs.NI) [Total: 2]
- [cs.RO](#cs.RO) [Total: 19]
- [cs.GR](#cs.GR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving](https://arxiv.org/abs/2508.21080)
*Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult*

Main category: cs.CV

TL;DR: 2COOOL工作坊聚焦自动驾驶中的新场景挑战，通过多方合作推动技术创新。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶算法虽然不断进步，但在处理新场景时仍存在挑战，这是实现完全安全自动驾驶的关键障碍。

Method: 工作坊将通过学术和行业专家的参与，结合异常检测、开放集识别、开放词汇建模和领域适应等方法，推动新颖性处理技术的进展。

Result: 2COOOL工作坊旨在激发新算法和系统的开发，以应对自动驾驶中的危险避免问题。

Conclusion: 论文强调了在自动驾驶领域解决新场景（包括分布外危险检测和视觉语言模型等）的重要性，并介绍了2COOOL工作坊的目标和活动安排。

Abstract: As the computer vision community advances autonomous driving algorithms,
integrating vision-based insights with sensor data remains essential for
improving perception, decision making, planning, prediction, simulation, and
control. Yet we must ask: Why don't we have entirely safe self-driving cars
yet? A key part of the answer lies in addressing novel scenarios, one of the
most critical barriers to real-world deployment. Our 2COOOL workshop provides a
dedicated forum for researchers and industry experts to push the state of the
art in novelty handling, including out-of-distribution hazard detection,
vision-language models for hazard understanding, new benchmarking and
methodologies, and safe autonomous driving practices. The 2nd Workshop on the
Challenge of Out-of-Label Hazards in Autonomous Driving (2COOOL) will be held
at the International Conference on Computer Vision (ICCV) 2025 in Honolulu,
Hawaii, on October 19, 2025. We aim to inspire the development of new
algorithms and systems for hazard avoidance, drawing on ideas from anomaly
detection, open-set recognition, open-vocabulary modeling, domain adaptation,
and related fields. Building on the success of its inaugural edition at the
Winter Conference on Applications of Computer Vision (WACV) 2025, the workshop
will feature a mix of academic and industry participation.

</details>


### [2] [Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images](https://arxiv.org/abs/2508.21088)
*Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni*

Main category: cs.CV

TL;DR: 研究评估了三种深度学习方法用于全景X射线图像中牙科病症的自动分类，混合CNN随机森林模型表现最佳，准确率达85.4%，为自动化牙科诊断提供了实用路径。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索深度学习在全景X射线图像中自动分类牙科病症的应用，以提供高效可靠的诊断支持。

Method: 研究评估了三种方法：自定义卷积神经网络（CNN）、结合CNN特征提取与传统分类器的混合模型，以及微调的预训练架构。实验采用5折交叉验证，以准确率、精确率、召回率和F1分数作为评估指标。

Result: 混合CNN随机森林模型表现最佳，准确率达到85.4%，超过了自定义CNN基线模型的74.3%。在预训练模型中，VGG16表现最佳，准确率为82.3%，其次是Xception和ResNet50。

Conclusion: 结合CNN特征提取与集成分类器的方法为自动化牙科诊断支持提供了一条实用路径，同时也指出了需要更大数据集和进一步临床验证的必要性。

Abstract: This study investigates deep learning methods for automated classification of
dental conditions in panoramic X-ray images. A dataset of 1,512 radiographs
with 11,137 expert-verified annotations across four conditions fillings,
cavities, implants, and impacted teeth was used. After preprocessing and class
balancing, three approaches were evaluated: a custom convolutional neural
network (CNN), hybrid models combining CNN feature extraction with traditional
classifiers, and fine-tuned pre-trained architectures. Experiments employed 5
fold cross validation with accuracy, precision, recall, and F1 score as
evaluation metrics. The hybrid CNN Random Forest model achieved the highest
performance with 85.4% accuracy, surpassing the custom CNN baseline of 74.3%.
Among pre-trained models, VGG16 performed best at 82.3% accuracy, followed by
Xception and ResNet50. Results show that hybrid models improve discrimination
of morphologically similar conditions and provide efficient, reliable
performance. These findings suggest that combining CNN-based feature extraction
with ensemble classifiers offers a practical path toward automated dental
diagnostic support, while also highlighting the need for larger datasets and
further clinical validation.

</details>


### [3] [Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment](https://arxiv.org/abs/2508.21090)
*Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu*

Main category: cs.CV

TL;DR: Q-Align通过Query-Query对齐等技术解决了零样本外观迁移中的注意力泄漏问题，显著提升了语义对齐和外观保真度。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模图像生成模型在零样本外观迁移中存在注意力泄漏问题，这是由于Query-Key对齐捕获的语义映射不足导致的。

Method: Q-Align引入了三个核心贡献：(1) Query-Query对齐，实现图像间精细的空间语义映射；(2) Key-Value重排，通过重新对齐增强特征对应；(3) 使用重排后的键和值进行注意力细化，保持语义一致性。

Result: Q-Align在实验中表现出色，在外观保真度上优于现有方法，同时在结构保持上保持竞争力。

Conclusion: Q-Align通过Query-Query对齐、Key-Value重排和注意力细化，显著提升了零样本外观迁移的语义对齐和外观保真度，并在结构保持上表现优异。

Abstract: We observe that zero-shot appearance transfer with large-scale image
generation models faces a significant challenge: Attention Leakage. This
challenge arises when the semantic mapping between two images is captured by
the Query-Key alignment. To tackle this issue, we introduce Q-Align, utilizing
Query-Query alignment to mitigate attention leakage and improve the semantic
alignment in zero-shot appearance transfer. Q-Align incorporates three core
contributions: (1) Query-Query alignment, facilitating the sophisticated
spatial semantic mapping between two images; (2) Key-Value rearrangement,
enhancing feature correspondence through realignment; and (3) Attention
refinement using rearranged keys and values to maintain semantic consistency.
We validate the effectiveness of Q-Align through extensive experiments and
analysis, and Q-Align outperforms state-of-the-art methods in appearance
fidelity while maintaining competitive structure preservation.

</details>


### [4] [ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion](https://arxiv.org/abs/2508.21091)
*Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin*

Main category: cs.CV

TL;DR: ERTACache 是一种缓存框架，通过分析误差并动态调整，实现扩散模型的高效推理加速，保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型因迭代推理过程导致计算开销大，现有缓存策略的重用会导致质量下降。

Method: 通过离线残差分析识别可重用步骤，动态调整积分间隔，并通过闭合形式的残差线性化模型近似缓存引入的误差。

Result: ERTACache 在标准图像和视频生成基准上实现了高达2倍的推理加速，且视觉质量保持一致或提升。

Conclusion: ERTACache 提出了一种有效的缓存框架，显著加速了扩散模型的推理过程，同时保持或提升了生成质量。

Abstract: Diffusion models suffer from substantial computational overhead due to their
inherently iterative inference process. While feature caching offers a
promising acceleration strategy by reusing intermediate outputs across
timesteps, naive reuse often incurs noticeable quality degradation. In this
work, we formally analyze the cumulative error introduced by caching and
decompose it into two principal components: feature shift error, caused by
inaccuracies in cached outputs, and step amplification error, which arises from
error propagation under fixed timestep schedules. To address these issues, we
propose ERTACache, a principled caching framework that jointly rectifies both
error types. Our method employs an offline residual profiling stage to identify
reusable steps, dynamically adjusts integration intervals via a
trajectory-aware correction coefficient, and analytically approximates
cache-induced errors through a closed-form residual linearization model.
Together, these components enable accurate and efficient sampling under
aggressive cache reuse. Extensive experiments across standard image and video
generation benchmarks show that ERTACache achieves up to 2x inference speedup
while consistently preserving or even improving visual quality. Notably, on the
state-of-the-art Wan2.1 video diffusion model, ERTACache delivers 2x
acceleration with minimal VBench degradation, effectively maintaining baseline
fidelity while significantly improving efficiency. The code is available at
https://github.com/bytedance/ERTACache.

</details>


### [5] [Video-LLMs with Temporal Visual Screening](https://arxiv.org/abs/2508.21094)
*Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.,Fung,Manling Li,Heng Ji*

Main category: cs.CV

TL;DR: TVS improves Video-LLMs by screening critical temporal segments, enhancing training and inference performance.


<details>
  <summary>Details</summary>
Motivation: Current Video-LLMs struggle with fine-grained temporal semantics due to sparse frame sampling and insufficient inter-frame reasoning supervision. TVS addresses this by aligning queries with focus-critical visual information.

Method: Proposes TVS, a modular front-end adapter task that pre-processes video question answering and instruction tuning data by retaining focus-critical segments, reconstructing queries, and maintaining answer consistency. Introduces ReSimplifyIt as a baseline.

Result: TVS outperforms prior approaches by 0.47 in F-1 score on video trimming and achieves competitive query rewriting performance.

Conclusion: Incorporating Temporal Visual Screening (TVS) significantly improves video-language understanding, as evidenced by relative gains of 7.33% during training and 34.6% during inference.

Abstract: Humans naturally perform temporal screening by dragging the progress bar and
focusing on salient temporal segments, but current Video Large Language Models
(Video-LLMs) struggle to capture fine-grained temporal semantics due to sparse
frame sampling and insufficient inter-frame reasoning supervision during their
training. To address this, Inspired by well-established cognitive science
principles, we propose Temporal Visual Screening (TVS), a new task that
universally pre-processes video question answering and instruction tuning data
by: (1) retaining focus-critical video segments, (2) synchronously
reconstructing queries to their most direct form while preserving answer
consistency, and (3) keeping the invariance and consistency for any possible
answer. TVS is formulated as a modular front-end adapter task that can be
seamlessly integrated into both Video Instruction Tuning (training) and Video
Question Answering (inference) pipelines. TVS optimizes distribution of
reasoning burden and cognitive load; during training, it aligns queries with
focus-critical visual information; at inference, it enables query-aware segment
focus and streamlined query representations. In particular, we curate the first
benchmark for TVS and propose ReSimplifyIt, a baseline outperforming prior
approaches on seemingly similar tasks by 0.47 in F-1 score on video trimming
while achieving competitive query rewriting performance. Experiments
demonstrate that incorporating TVS yields relative gains of 7.33% (training)
and 34.6% (inference), demonstrating the effectiveness of temporal information
screening for improving video-language understanding.

</details>


### [6] [ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments](https://arxiv.org/abs/2508.21096)
*Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren*

Main category: cs.CV

TL;DR: 论文提出骨骼姿态注释作为手术工具的高效标注方法，发布ROBUST-MIPS数据集和基准模型，验证其有效性并促进采用。


<details>
  <summary>Details</summary>
Motivation: 解决基于深度学习的手术工具定位方法受限于多样化标注数据可用性的问题，提出骨骼姿态注释作为一种更高效的标注方式。

Method: 通过ROBUST-MIPS数据集（源自ROBUST-MIS数据集）结合工具姿态和实例分割标注，建立简单基准并使用流行的姿态估计方法进行验证。

Result: 观察到姿态注释在手术工具定位任务中表现高质量，验证了其适用性。

Conclusion: 作者提出骨骼姿态注释是一种更高效的手术工具标注方法，并通过ROBUST-MIPS数据集和基准模型验证了其有效性，同时发布了标注软件以促进采用。

Abstract: Localisation of surgical tools constitutes a foundational building block for
computer-assisted interventional technologies. Works in this field typically
focus on training deep learning models to perform segmentation tasks.
Performance of learning-based approaches is limited by the availability of
diverse annotated data. We argue that skeletal pose annotations are a more
efficient annotation approach for surgical tools, striking a balance between
richness of semantic information and ease of annotation, thus allowing for
accelerated growth of available annotated data. To encourage adoption of this
annotation style, we present, ROBUST-MIPS, a combined tool pose and tool
instance segmentation dataset derived from the existing ROBUST-MIS dataset. Our
enriched dataset facilitates the joint study of these two annotation styles and
allow head-to-head comparison on various downstream tasks. To demonstrate the
adequacy of pose annotations for surgical tool localisation, we set up a simple
benchmark using popular pose estimation methods and observe high-quality
results. To ease adoption, together with the dataset, we release our benchmark
models and custom tool pose annotation software.

</details>


### [7] [Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models](https://arxiv.org/abs/2508.21099)
*Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo*

Main category: cs.CV

TL;DR: Safe-Control是一种即插即用安全补丁，有效减少T2I模型的不安全内容生成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有T2I模型的安全机制易受分布偏移规避或需大量模型特定调整，无法有效应对滥用风险。

Method: 采用数据驱动策略和安全感知条件，将安全控制信号注入锁定的T2I模型中，以类似补丁的方式更新。开发者可构建多种安全补丁，灵活合并为统一补丁。

Result: 在六种不同T2I模型上评估显示，Safe-Control将不安全内容生成概率降至7%，而基线方法约为20%，且在对抗攻击下表现优异。

Conclusion: Safe-Control作为一种创新的即插即用安全补丁，显著降低了T2I模型中的不安全内容生成，同时保持了良性图像的质量和文本对齐，优于现有的七种最先进安全机制。

Abstract: Despite the advancements in Text-to-Image (T2I) generation models, their
potential for misuse or even abuse raises serious safety concerns. Model
developers have made tremendous efforts to introduce safety mechanisms that can
address these concerns in T2I models. However, the existing safety mechanisms,
whether external or internal, either remain susceptible to evasion under
distribution shifts or require extensive model-specific adjustments. To address
these limitations, we introduce Safe-Control, an innovative plug-and-play
safety patch designed to mitigate unsafe content generation in T2I models.
Using data-driven strategies and safety-aware conditions, Safe-Control injects
safety control signals into the locked T2I model, acting as an update in a
patch-like manner. Model developers can also construct various safety patches
to meet the evolving safety requirements, which can be flexibly merged into a
single, unified patch. Its plug-and-play design further ensures adaptability,
making it compatible with other T2I models of similar denoising architecture.
We conduct extensive evaluations on six diverse and public T2I models.
Empirical results highlight that Safe-Control is effective in reducing unsafe
content generation across six diverse T2I models with similar generative
architectures, yet it successfully maintains the quality and text alignment of
benign images. Compared to seven state-of-the-art safety mechanisms, including
both external and internal defenses, Safe-Control significantly outperforms all
baselines in reducing unsafe content generation. For example, it reduces the
probability of unsafe content generation to 7%, compared to approximately 20%
for most baseline methods, under both unsafe prompts and the latest adversarial
attacks.

</details>


### [8] [GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions](https://arxiv.org/abs/2508.21102)
*Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura*

Main category: cs.CV

TL;DR: GENNAV通过预测目标存在和生成分割掩码，解决了stuff型目标区域的识别问题，在基准测试和真实实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 处理stuff型目标区域（边界模糊）以及不存在或多目标的情况是现有方法的短板。

Method: 提出GENNAV方法，预测目标存在并生成多个stuff型目标区域的分割掩码。

Result: GENNAV在GRiN-Drive基准测试中表现优异，并在真实世界实验中验证了其零样本迁移性能。

Conclusion: GENNAV在标准评估指标上优于基线方法，并在真实世界的零样本迁移实验中展现了其鲁棒性。

Abstract: We focus on the task of identifying the location of target regions from a
natural language instruction and a front camera image captured by a mobility.
This task is challenging because it requires both existence prediction and
segmentation, particularly for stuff-type target regions with ambiguous
boundaries. Existing methods often underperform in handling stuff-type target
regions, in addition to absent or multiple targets. To overcome these
limitations, we propose GENNAV, which predicts target existence and generates
segmentation masks for multiple stuff-type target regions. To evaluate GENNAV,
we constructed a novel benchmark called GRiN-Drive, which includes three
distinct types of samples: no-target, single-target, and multi-target. GENNAV
achieved superior performance over baseline methods on standard evaluation
metrics. Furthermore, we conducted real-world experiments with four automobiles
operated in five geographically distinct urban areas to validate its zero-shot
transfer performance. In these experiments, GENNAV outperformed baseline
methods and demonstrated its robustness across diverse real-world environments.
The project page is available at https://gennav.vercel.app/.

</details>


### [9] [R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning](https://arxiv.org/abs/2508.21113)
*Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng*

Main category: cs.CV

TL;DR: R-4B是一种自适应思考的多模态大语言模型，通过双模式策略优化在简单和复杂问题上均表现出色，计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态大语言模型在简单问题上不必要的思考过程冗余问题。

Method: 采用双模式退火（bi-mode annealing）和双模式策略优化（BPO）技术，结合改进的GRPO框架进行训练。

Result: R-4B在25个挑战性基准测试中表现优异，超越Qwen2.5-VL-7B，并在计算成本更低的情况下达到与Kimi-VL-A3B-Thinking-2506（16B）相当的推理性能。

Conclusion: R-4B通过自适应决定何时启用思考过程，显著提升了多模态大语言模型在简单和复杂问题上的效率与性能。

Abstract: Multimodal Large Language Models (MLLMs) equipped with step-by-step thinking
capabilities have demonstrated remarkable performance on complex reasoning
problems. However, this thinking process is redundant for simple problems
solvable without complex reasoning. To address this inefficiency, we propose
R-4B, an auto-thinking MLLM, which can adaptively decide when to think based on
problem complexity. The central idea of R-4B is to empower the model with both
thinking and non-thinking capabilities using bi-mode annealing, and apply
Bi-mode Policy Optimization~(BPO) to improve the model's accuracy in
determining whether to activate the thinking process. Specifically, we first
train the model on a carefully curated dataset spanning various topics, which
contains samples from both thinking and non-thinking modes. Then it undergoes a
second phase of training under an improved GRPO framework, where the policy
model is forced to generate responses from both modes for each input query.
Experimental results show that R-4B achieves state-of-the-art performance
across 25 challenging benchmarks. It outperforms Qwen2.5-VL-7B in most tasks
and achieves performance comparable to larger models such as
Kimi-VL-A3B-Thinking-2506 (16B) on reasoning-intensive benchmarks with lower
computational cost.

</details>


### [10] [HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection](https://arxiv.org/abs/2508.21135)
*Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed*

Main category: cs.CV

TL;DR: HiddenObject是一种融合RGB、热成像和深度数据的Mamba-based框架，能在复杂条件下更有效地检测隐蔽或伪装目标，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB的检测方法在遮挡、伪装和光照变化等不利条件下表现不佳，因此需要更鲁棒、模态无关的方法。

Method: 提出了HiddenObject，一种融合RGB、热成像和深度数据的Mamba-based融合机制框架，通过捕获跨模态的互补信号来增强对隐蔽或伪装目标的检测。

Result: 在多个基准数据集上验证了HiddenObject的性能，展示了其与现有方法相比的先进或竞争性表现。

Conclusion: 研究结果表明，基于Mamba的融合架构可以显著推动多模态物体检测领域的发展，尤其是在视觉退化或复杂条件下。

Abstract: Detecting hidden or partially concealed objects remains a fundamental
challenge in multimodal environments, where factors like occlusion, camouflage,
and lighting variations significantly hinder performance. Traditional RGB-based
detection methods often fail under such adverse conditions, motivating the need
for more robust, modality-agnostic approaches. In this work, we present
HiddenObject, a fusion framework that integrates RGB, thermal, and depth data
using a Mamba-based fusion mechanism. Our method captures complementary signals
across modalities, enabling enhanced detection of obscured or camouflaged
targets. Specifically, the proposed approach identifies modality-specific
features and fuses them in a unified representation that generalizes well
across challenging scenarios. We validate HiddenObject across multiple
benchmark datasets, demonstrating state-of-the-art or competitive performance
compared to existing methods. These results highlight the efficacy of our
fusion design and expose key limitations in current unimodal and na\"ive fusion
strategies. More broadly, our findings suggest that Mamba-based fusion
architectures can significantly advance the field of multimodal object
detection, especially under visually degraded or complex conditions.

</details>


### [11] [RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration](https://arxiv.org/abs/2508.21154)
*Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou*

Main category: cs.CV

TL;DR: RadGS-Reg通过联合3D放射高斯重建和3D/3D注册，解决了CT/X射线注册中的高精度和实时性问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法因空间信息丢失和领域差距而难以满足高精度和实时性要求，而现有3D重建方法受限于密集视图需求和噪声处理能力。

Method: RadGS-Reg采用基于学习的放射高斯重建方法，结合反事实注意力学习机制，专注于噪声X射线中的脊椎区域，并通过患者特定的预训练策略从模拟数据逐步适应真实数据。

Result: 在内部数据集上的实验表明，RadGS-Reg在两项任务中均达到最先进性能。

Conclusion: RadGS-Reg框架在CT/X射线注册中表现出色，通过结合3D放射高斯重建和3D/3D注册，显著提升了准确性和实时性能，超越了现有方法。

Abstract: Computed Tomography (CT)/X-ray registration in image-guided navigation
remains challenging because of its stringent requirements for high accuracy and
real-time performance. Traditional "render and compare" methods, relying on
iterative projection and comparison, suffer from spatial information loss and
domain gap. 3D reconstruction from biplanar X-rays supplements spatial and
shape information for 2D/3D registration, but current methods are limited by
dense-view requirements and struggles with noisy X-rays. To address these
limitations, we introduce RadGS-Reg, a novel framework for vertebral-level
CT/X-ray registration through joint 3D Radiative Gaussians (RadGS)
reconstruction and 3D/3D registration. Specifically, our biplanar X-rays
vertebral RadGS reconstruction module explores learning-based RadGS
reconstruction method with a Counterfactual Attention Learning (CAL) mechanism,
focusing on vertebral regions in noisy X-rays. Additionally, a patient-specific
pre-training strategy progressively adapts the RadGS-Reg from simulated to real
data while simultaneously learning vertebral shape prior knowledge. Experiments
on in-house datasets demonstrate the state-of-the-art performance for both
tasks, surpassing existing methods. The code is available at:
https://github.com/shenao1995/RadGS_Reg.

</details>


### [12] [SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4](https://arxiv.org/abs/2508.21169)
*Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer*

Main category: cs.CV

TL;DR: SYNBUILD-3D是一个大规模合成3D建筑数据集，支持多模态表示，旨在推动自动化生成高精度3D建筑模型的研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模公开标注数据集，自动生成精确且语义丰富的3D建筑模型仍具挑战性。

Method: 引入SYNBUILD-3D数据集，包含620万合成3D住宅建筑，提供三种模态表示：LoD 4的3D线框图、平面图图像和LiDAR式屋顶点云。

Result: SYNBUILD-3D通过三模态表示，支持开发新型生成式AI算法，实现LoD 4级3D建筑模型的自动化生成。

Conclusion: SYNBUILD-3D数据集为自动化生成高精度、语义丰富的3D建筑模型提供了重要资源，支持未来在生成式AI算法上的创新研究。

Abstract: 3D building models are critical for applications in architecture, energy
simulation, and navigation. Yet, generating accurate and semantically rich 3D
buildings automatically remains a major challenge due to the lack of
large-scale annotated datasets in the public domain. Inspired by the success of
synthetic data in computer vision, we introduce SYNBUILD-3D, a large, diverse,
and multi-modal dataset of over 6.2 million synthetic 3D residential buildings
at Level of Detail (LoD) 4. In the dataset, each building is represented
through three distinct modalities: a semantically enriched 3D wireframe graph
at LoD 4 (Modality I), the corresponding floor plan images (Modality II), and a
LiDAR-like roof point cloud (Modality III). The semantic annotations for each
building wireframe are derived from the corresponding floor plan images and
include information on rooms, doors, and windows. Through its tri-modal nature,
future work can use SYNBUILD-3D to develop novel generative AI algorithms that
automate the creation of 3D building models at LoD 4, subject to predefined
floor plan layouts and roof geometries, while enforcing semantic-geometric
consistency. Dataset and code samples are publicly available at
https://github.com/kdmayer/SYNBUILD-3D.

</details>


### [13] [Radially Distorted Homographies, Revisited](https://arxiv.org/abs/2508.21190)
*Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt*

Main category: cs.CV

TL;DR: 本文提出了一种统一方法，用于同时解决三种径向畸变配置下的单应性估计问题，新求解器速度更快且准确性相当。


<details>
  <summary>Details</summary>
Motivation: 真实图像常因镜头几何畸变（尤其是径向畸变）而影响单应性估计的准确性，过去的方法分别处理不同畸变配置，缺乏统一解决方案。

Method: 通过统一的方法处理三种径向畸变配置（单图像畸变、相同畸变和独立畸变），并构建了快速、稳定且准确的最小求解器。

Result: 在包括鱼眼相机图像在内的基准测试中，所提出的求解器在速度上优于现有技术，同时保持相似的准确性。

Conclusion: 本文提出了一种新颖的统一方法，用于同时解决三种径向畸变配置下的单应性估计问题，所提出的求解器在速度上优于现有技术，同时保持相似的准确性。

Abstract: Homographies are among the most prevalent transformations occurring in
geometric computer vision and projective geometry, and homography estimation is
consequently a crucial step in a wide assortment of computer vision tasks. When
working with real images, which are often afflicted with geometric distortions
caused by the camera lens, it may be necessary to determine both the homography
and the lens distortion-particularly the radial component, called radial
distortion-simultaneously to obtain anything resembling useful estimates. When
considering a homography with radial distortion between two images, there are
three conceptually distinct configurations for the radial distortion; (i)
distortion in only one image, (ii) identical distortion in the two images, and
(iii) independent distortion in the two images. While these cases have been
addressed separately in the past, the present paper provides a novel and
unified approach to solve all three cases. We demonstrate how the proposed
approach can be used to construct new fast, stable, and accurate minimal
solvers for radially distorted homographies. In all three cases, our proposed
solvers are faster than the existing state-of-the-art solvers while maintaining
similar accuracy. The solvers are tested on well-established benchmarks
including images taken with fisheye cameras. The source code for our solvers
will be made available in the event our paper is accepted for publication.

</details>


### [14] [GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability](https://arxiv.org/abs/2508.21197)
*Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang*

Main category: cs.CV

TL;DR: GCAV通过统一CAV到一个语义一致的表示，解决了跨层概念不一致的问题，提高了概念归因的稳定性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决独立计算在不同层的CAV通常表现出不一致性，导致跨层比较不可靠的问题。

Method: 提出的全局概念激活向量（GCAV）框架利用对比学习对齐跨层的概念表示，并采用基于注意力的融合机制构建全局集成的CAV。

Result: 实验表明，GCAV有效减少了TCAV分数的方差，同时保持了概念相关性，增强了概念定位，并提高了对抗扰动的鲁棒性。

Conclusion: 通过整合跨层信息到一个连贯的框架中，GCAV方法提供了对深度学习模型如何编码人类定义概念的更全面和可解释的理解。

Abstract: Concept Activation Vectors (CAVs) provide a powerful approach for
interpreting deep neural networks by quantifying their sensitivity to
human-defined concepts. However, when computed independently at different
layers, CAVs often exhibit inconsistencies, making cross-layer comparisons
unreliable. To address this issue, we propose the Global Concept Activation
Vector (GCAV), a novel framework that unifies CAVs into a single, semantically
consistent representation. Our method leverages contrastive learning to align
concept representations across layers and employs an attention-based fusion
mechanism to construct a globally integrated CAV. By doing so, our method
significantly reduces the variance in TCAV scores while preserving concept
relevance, ensuring more stable and reliable concept attributions. To evaluate
the effectiveness of GCAV, we introduce Testing with Global Concept Activation
Vectors (TGCAV) as a method to apply TCAV to GCAV-based representations. We
conduct extensive experiments on multiple deep neural networks, demonstrating
that our method effectively mitigates concept inconsistency across layers,
enhances concept localization, and improves robustness against adversarial
perturbations. By integrating cross-layer information into a coherent
framework, our method offers a more comprehensive and interpretable
understanding of how deep learning models encode human-defined concepts. Code
and models are available at https://github.com/Zhenghao-He/GCAV.

</details>


### [15] [Generalizable Object Re-Identification via Visual In-Context Prompting](https://arxiv.org/abs/2508.21222)
*Zhizhong Huang,Xiaoming Liu*

Main category: cs.CV

TL;DR: VICP框架通过上下文提示和LLM-VFM协同，无需重新训练即可实现跨类别对象重识别，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前对象重识别方法缺乏泛化能力且需要昂贵的标注数据，而自监督学习难以捕捉身份敏感特征。

Method: 提出Visual In-Context Prompting (VICP)框架，利用上下文示例作为提示，结合LLMs推断语义身份规则，并指导视觉基础模型提取ID区分性特征。

Result: 在ShopID10K和多个ReID基准测试中，VICP在新类别上的表现显著优于基线方法。

Conclusion: VICP框架通过结合LLMs和视觉基础模型，无需参数调整即可推广到新类别，显著提升了跨类别对象重识别的性能。

Abstract: Current object re-identification (ReID) methods train domain-specific models
(e.g., for persons or vehicles), which lack generalization and demand costly
labeled data for new categories. While self-supervised learning reduces
annotation needs by learning instance-wise invariance, it struggles to capture
\textit{identity-sensitive} features critical for ReID. This paper proposes
Visual In-Context Prompting~(VICP), a novel framework where models trained on
seen categories can directly generalize to unseen novel categories using only
\textit{in-context examples} as prompts, without requiring parameter
adaptation. VICP synergizes LLMs and vision foundation models~(VFM): LLMs infer
semantic identity rules from few-shot positive/negative pairs through
task-specific prompting, which then guides a VFM (\eg, DINO) to extract
ID-discriminative features via \textit{dynamic visual prompts}. By aligning
LLM-derived semantic concepts with the VFM's pre-trained prior, VICP enables
generalization to novel categories, eliminating the need for dataset-specific
retraining. To support evaluation, we introduce ShopID10K, a dataset of 10K
object instances from e-commerce platforms, featuring multi-view images and
cross-domain testing. Experiments on ShopID10K and diverse ReID benchmarks
demonstrate that VICP outperforms baselines by a clear margin on unseen
categories. Code is available at https://github.com/Hzzone/VICP.

</details>


### [16] [Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg](https://arxiv.org/abs/2508.21227)
*Keshav Jha,William Sharp,Dominic LaBella*

Main category: cs.CV

TL;DR: 研究使用SegResNet模型在MRI胰腺肿瘤分割任务中表现一般，但展示了自动化潜力，需更大标准化数据集提升性能。


<details>
  <summary>Details</summary>
Motivation: 胰腺肿瘤的准确分割对诊断、治疗计划和结果评估至关重要，但由于解剖变异性和数据集有限，自动化分割仍然具有挑战性。

Method: 使用SegResNet模型（Auto3DSeg架构的一部分），在两项MRI胰腺肿瘤分割任务上进行训练和评估，采用5折交叉验证和STAPLE集成方法，专注于解剖相关感兴趣区域。

Result: 任务1的DSC为0.56，5 mm DSC为0.73，HD95为41.1 mm；任务2的DSC为0.33，5 mm DSC为0.50，HD95为20.1 mm。结果表明MRI序列差异对分割性能的影响。

Conclusion: 尽管性能一般，但研究结果表明了自动化分割的潜力，并强调了需要更大、标准化的MRI数据集以提高模型的稳健性和临床实用性。

Abstract: Accurate delineation of pancreatic tumors is critical for diagnosis,
treatment planning, and outcome assessment, yet automated segmentation remains
challenging due to anatomical variability and limited dataset availability. In
this study, SegResNet models, as part of the Auto3DSeg architecture, were
trained and evaluated on two MRI-based pancreatic tumor segmentation tasks as
part of the 2025 PANTHER Challenge. Algorithm methodology included 5-fold
cross-validation with STAPLE ensembling after focusing on an anatomically
relevant region-of-interest. The Pancreatic Tumor Segmentation on Diagnostic
MRI task 1 training set included 91 T1-weighted arterial contrast-enhanced MRI
with expert annotated pancreas and tumor labels. The Pancreatic Tumor
Segmentation on MR-Linac task 2 training set used 50 T2-weighted MR-Linac cases
with expert annotated pancreas and tumor labels. Algorithm-automated
segmentation performance of pancreatic tumor was assessed using Dice Similarity
Coefficient (DSC), 5 mm DSC, 95th percentile Hausdorff Distance (HD95), Mean
Average Surface Distance (MASD), and Root Mean Square Error (RMSE). For Task 1,
the algorithm achieved a DSC of 0.56, 5 mm DSC of 0.73, HD95 of 41.1 mm, MASD
of 26.0 mm, and RMSE of 5164 mm. For Task 2, performance decreased, with a DSC
of 0.33, 5 mm DSC of 0.50, HD95 of 20.1 mm, MASD of 7.2 mm, and RMSE of 17,203
mm. These findings illustrate the challenges of MRI-based pancreatic tumor
segmentation with small datasets, highlighting variability introduced by
different MRI sequences. Despite modest performance, the results demonstrate
potential for automated delineation and emphasize the need for larger,
standardized MRI datasets to improve model robustness and clinical utility.

</details>


### [17] [Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation](https://arxiv.org/abs/2508.21254)
*Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao*

Main category: cs.CV

TL;DR: 提出了一种物理驱动的数据增强方法Reverse Imaging，通过逆向推断自旋属性解决心脏MRI分割的泛化问题，显著提升了模型在不同成像协议下的表现。


<details>
  <summary>Details</summary>
Motivation: 心脏MRI图像对比度因成像协议不同而变化，导致预训练分割模型泛化能力不足。由于所有图像均由相同的自旋属性（质子密度、T1、T2值）控制，因此希望通过物理驱动的方法解决泛化问题。

Method: 提出了一种名为Reverse Imaging的新方法，通过逆向推断底层的自旋属性来解决非线性逆问题，并利用扩散模型学习自旋属性的先验分布。

Result: Reverse Imaging能够从MRI图像中估计自旋属性，生成任意新序列的图像，显著提高了分割模型在不同图像对比和协议下的准确性。

Conclusion: Reverse Imaging 通过物理驱动的方式解决了心脏MRI分割模型的泛化问题，实现了跨不同图像对比和成像协议的高精度分割。

Abstract: Pretrained segmentation models for cardiac magnetic resonance imaging (MRI)
struggle to generalize across different imaging sequences due to significant
variations in image contrast. These variations arise from changes in imaging
protocols, yet the same fundamental spin properties, including proton density,
T1, and T2 values, govern all acquired images. With this core principle, we
introduce Reverse Imaging, a novel physics-driven method for cardiac MRI data
augmentation and domain adaptation to fundamentally solve the generalization
problem. Our method reversely infers the underlying spin properties from
observed cardiac MRI images, by solving ill-posed nonlinear inverse problems
regularized by the prior distribution of spin properties. We acquire this "spin
prior" by learning a generative diffusion model from the multiparametric
SAturation-recovery single-SHot acquisition sequence (mSASHA) dataset, which
offers joint cardiac T1 and T2 maps. Our method enables approximate but
meaningful spin-property estimates from MR images, which provide an
interpretable "latent variable" that lead to highly flexible image synthesis of
arbitrary novel sequences. We show that Reverse Imaging enables highly accurate
segmentation across vastly different image contrasts and imaging protocols,
realizing wide-spectrum generalization of cardiac MRI segmentation.

</details>


### [18] [PHD: Personalized 3D Human Body Fitting with Point Diffusion](https://arxiv.org/abs/2508.21257)
*Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang*

Main category: cs.CV

TL;DR: PHD提出个性化3D人体网格恢复方法，通过体型校准和条件化姿态先验提升姿态估计精度，无需真实数据训练，兼容现有系统。


<details>
  <summary>Details</summary>
Motivation: 传统HMR方法因忽视用户特定体型和3D姿态合理性，导致3D精度不足。PHD旨在通过个性化体型校准和姿态拟合提升精度。

Method: PHD采用点扩散变换器（Point Diffusion Transformer）实现的体型条件化3D姿态先验，通过点蒸馏采样损失迭代指导姿态拟合，减少对2D约束的过度依赖。

Result: PHD不仅提升了骨盆对齐姿态精度，还显著改善了绝对姿态精度，且仅需合成数据训练，可作为现有3D姿态估计器的即插即用模块。

Conclusion: PHD方法通过解耦用户特定体型校准和个性化姿态拟合过程，显著提高了3D人体姿态估计的准确性，尤其在绝对姿态精度方面表现突出，且具有高效的数据利用率和模块化特性。

Abstract: We introduce PHD, a novel approach for personalized 3D human mesh recovery
(HMR) and body fitting that leverages user-specific shape information to
improve pose estimation accuracy from videos. Traditional HMR methods are
designed to be user-agnostic and optimized for generalization. While these
methods often refine poses using constraints derived from the 2D image to
improve alignment, this process compromises 3D accuracy by failing to jointly
account for person-specific body shapes and the plausibility of 3D poses. In
contrast, our pipeline decouples this process by first calibrating the user's
body shape and then employing a personalized pose fitting process conditioned
on that shape. To achieve this, we develop a body shape-conditioned 3D pose
prior, implemented as a Point Diffusion Transformer, which iteratively guides
the pose fitting via a Point Distillation Sampling loss. This learned 3D pose
prior effectively mitigates errors arising from an over-reliance on 2D
constraints. Consequently, our approach improves not only pelvis-aligned pose
accuracy but also absolute pose accuracy -- an important metric often
overlooked by prior work. Furthermore, our method is highly data-efficient,
requiring only synthetic data for training, and serves as a versatile
plug-and-play module that can be seamlessly integrated with existing 3D pose
estimators to enhance their performance. Project page:
https://phd-pose.github.io/

</details>


### [19] [Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning](https://arxiv.org/abs/2508.21363)
*Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang*

Main category: cs.CV

TL;DR: 通过分层时间剪枝策略HTP，论文在降低计算成本的同时提升3D人体姿态估计性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成高保真3D人体姿态方面表现出色，但其迭代性和多假设需求导致计算成本高昂。

Method: 1. Temporal Correlation-Enhanced Pruning (TCEP)通过自适应时间图构建分析帧间运动相关性；2. Sparse-Focused Temporal MHSA (SFT MHSA)利用帧级稀疏性减少注意力计算；3. Mask-Guided Pose Token Pruner (MGPTP)通过聚类进行细粒度语义剪枝。

Result: HTP将训练MACs减少38.5%，推理MACs减少56.8%，推理速度平均提升81.1%，并在性能上达到最优。

Conclusion: 提出的HTP策略通过分层时间剪枝有效降低了计算成本，同时保持了运动动态的关键信息，实现了在Human3.6M和MPI-INF-3DHP数据集上的最优性能。

Abstract: Diffusion models have demonstrated strong capabilities in generating
high-fidelity 3D human poses, yet their iterative nature and multi-hypothesis
requirements incur substantial computational cost. In this paper, we propose an
Efficient Diffusion-Based 3D Human Pose Estimation framework with a
Hierarchical Temporal Pruning (HTP) strategy, which dynamically prunes
redundant pose tokens across both frame and semantic levels while preserving
critical motion dynamics. HTP operates in a staged, top-down manner: (1)
Temporal Correlation-Enhanced Pruning (TCEP) identifies essential frames by
analyzing inter-frame motion correlations through adaptive temporal graph
construction; (2) Sparse-Focused Temporal MHSA (SFT MHSA) leverages the
resulting frame-level sparsity to reduce attention computation, focusing on
motion-relevant tokens; and (3) Mask-Guided Pose Token Pruner (MGPTP) performs
fine-grained semantic pruning via clustering, retaining only the most
informative pose tokens. Experiments on Human3.6M and MPI-INF-3DHP show that
HTP reduces training MACs by 38.5\%, inference MACs by 56.8\%, and improves
inference speed by an average of 81.1\% compared to prior diffusion-based
methods, while achieving state-of-the-art performance.

</details>


### [20] [Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image](https://arxiv.org/abs/2508.21371)
*Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang*

Main category: cs.CV

TL;DR: Print2Volume通过合成OCT指纹数据解决数据稀缺问题，显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: OCT数据获取成本高且耗时，导致大规模公共数据集稀缺，阻碍了先进算法的发展。

Method: 框架分为三个阶段：2D风格转换模块、3D结构扩展网络和基于3D GAN的OCT真实性细化器。

Result: 生成420,000个合成样本，预训练模型后，在ZJUT-EIFD基准上EER从15.62%降至2.50%。

Conclusion: Print2Volume框架通过生成高质量的合成OCT指纹数据，显著提升了生物识别性能，证明了其在克服数据稀缺问题上的有效性。

Abstract: Optical Coherence Tomography (OCT) enables the acquisition of
high-resolution, three-dimensional fingerprint data, capturing rich subsurface
structures for robust biometric recognition. However, the high cost and
time-consuming nature of OCT data acquisition have led to a scarcity of
large-scale public datasets, significantly hindering the development of
advanced algorithms, particularly data-hungry deep learning models. To address
this critical bottleneck, this paper introduces Print2Volume, a novel framework
for generating realistic, synthetic OCT-based 3D fingerprints from 2D
fingerprint image. Our framework operates in three sequential stages: (1) a 2D
style transfer module that converts a binary fingerprint into a grayscale
images mimicking the style of a Z-direction mean-projected OCT scan; (2) a 3D
Structure Expansion Network that extrapolates the 2D im-age into a plausible 3D
anatomical volume; and (3) an OCT Realism Refiner, based on a 3D GAN, that
renders the structural volume with authentic textures, speckle noise, and other
imaging characteristics. Using Print2Volume, we generated a large-scale
synthetic dataset of 420,000 samples. Quantitative experiments demonstrate the
high quality of our synthetic data and its significant impact on recognition
performance. By pre-training a recognition model on our synthetic data and
fine-tuning it on a small real-world dataset, we achieved a remarkable
reduction in the Equal Error Rate (EER) from 15.62% to 2.50% on the ZJUT-EIFD
benchmark, proving the effectiveness of our approach in overcoming data
scarcity.

</details>


### [21] [GLENDA: Gynecologic Laparoscopy Endometriosis Dataset](https://arxiv.org/abs/2508.21398)
*Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein*

Main category: cs.CV

TL;DR: 本文发布了首个妇科腹腔镜子宫内膜异位症数据集GLENDA，旨在解决医疗领域样本数据稀缺问题，支持计算机视觉和机器学习在手术录像分析中的应用。


<details>
  <summary>Details</summary>
Motivation: 当前手动分析手术录像的过程耗时且低效，需要更先进的计算机视觉和机器学习方法，但这些方法依赖大量样本数据，而医疗领域数据稀缺。

Method: 通过与领先的医学专家合作，创建了包含子宫内膜异位症区域注释的图像数据集。

Result: 发布了首个妇科腹腔镜子宫内膜异位症数据集GLENDA，包含区域注释。

Conclusion: 本文发布了首个针对子宫内膜异位症的妇科腹腔镜图像数据集GLENDA，填补了该领域样本数据的空白，为计算机视觉和机器学习在医疗领域的应用提供了重要资源。

Abstract: Gynecologic laparoscopy as a type of minimally invasive surgery (MIS) is
performed via a live feed of a patient's abdomen surveying the insertion and
handling of various instruments for conducting treatment. Adopting this kind of
surgical intervention not only facilitates a great variety of treatments, the
possibility of recording said video streams is as well essential for numerous
post-surgical activities, such as treatment planning, case documentation and
education. Nonetheless, the process of manually analyzing surgical recordings,
as it is carried out in current practice, usually proves tediously
time-consuming. In order to improve upon this situation, more sophisticated
computer vision as well as machine learning approaches are actively developed.
Since most of such approaches heavily rely on sample data, which especially in
the medical field is only sparsely available, with this work we publish the
Gynecologic Laparoscopy ENdometriosis DAtaset (GLENDA) - an image dataset
containing region-based annotations of a common medical condition named
endometriosis, i.e. the dislocation of uterine-like tissue. The dataset is the
first of its kind and it has been created in collaboration with leading medical
experts in the field.

</details>


### [22] [Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation](https://arxiv.org/abs/2508.21399)
*Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein*

Main category: cs.CV

TL;DR: 研究评估了基于区域的全卷积网络在腹腔镜妇科手术视频中分割和识别手术器械的性能，结果显示器械分割精度高，但器械类型识别仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 手术视频记录的普及使得自动内容索引成为医学视频档案中基于内容搜索的基础，但由于视频内容的特殊性，这仍是一个巨大挑战。

Method: 使用基于区域的全卷积网络进行实例感知的（1）器械分割和（2）器械识别，评估其在腹腔镜妇科手术视频中的性能。

Result: 即使训练样本数量较少，器械区域的定位和分割精度较高，但特定器械的识别因器械间高度相似性而仍具挑战性。

Conclusion: 尽管手术器械的高相似性使得特定器械的识别仍然具有挑战性，但即使训练样本数量较少，研究仍能以较高精度定位和分割器械区域。

Abstract: Recorded videos from surgeries have become an increasingly important
information source for the field of medical endoscopy, since the recorded
footage shows every single detail of the surgery. However, while video
recording is straightforward these days, automatic content indexing - the basis
for content-based search in a medical video archive - is still a great
challenge due to the very special video content. In this work, we investigate
segmentation and recognition of surgical instruments in videos recorded from
laparoscopic gynecology. More precisely, we evaluate the achievable performance
of segmenting surgical instruments from their background by using a
region-based fully convolutional network for instance-aware (1) instrument
segmentation as well as (2) instrument recognition. While the first part
addresses only binary segmentation of instances (i.e., distinguishing between
instrument or background) we also investigate multi-class instrument
recognition (i.e., identifying the type of instrument). Our evaluation results
show that even with a moderately low number of training examples, we are able
to localize and segment instrument regions with a pretty high accuracy.
However, the results also reveal that determining the particular instrument is
still very challenging, due to the inherently high similarity of surgical
instruments.

</details>


### [23] [SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing](https://arxiv.org/abs/2508.21402)
*Jakub Straka,Ivan Gruber*

Main category: cs.CV

TL;DR: SatDINO是一种基于DINO的自监督学习模型，针对遥感图像设计，表现优于MAE方法，并在多个基准测试中取得竞争性结果。研究还提出了GSD编码和自适应视图采样等增强方法。


<details>
  <summary>Details</summary>
Motivation: 遥感领域存在大量未标记数据，自监督学习成为有效工具。研究旨在探索DINO方法在遥感图像中的应用，并提出针对卫星图像的表示学习模型SatDINO。

Method: 研究采用了DINO（一种对比自监督方法）进行遥感图像的预训练，并提出了SatDINO模型。通过多个数据集和测试设置的广泛实验，验证了模型的有效性。此外，还进行了严格的消融研究，评估了SatDINO的各个组件。

Result: SatDINO在多个测试设置中表现优于基于MAE的最先进方法，并在多个基准测试中取得了竞争性结果。消融研究和增强方法的提出进一步验证了模型的有效性和灵活性。

Conclusion: SatDINO模型在遥感图像表示学习中表现出色，超越了基于掩码自编码器（MAE）的最先进方法，并在多个基准测试中取得了竞争性结果。同时，研究提出的增强方法（如GSD编码和自适应视图采样）可以独立应用于SatDINO模型。

Abstract: Self-supervised learning has emerged as a powerful tool for remote sensing,
where large amounts of unlabeled data are available. In this work, we
investigate the use of DINO, a contrastive self-supervised method, for
pretraining on remote sensing imagery. We introduce SatDINO, a model tailored
for representation learning in satellite imagery. Through extensive experiments
on multiple datasets in multiple testing setups, we demonstrate that SatDINO
outperforms other state-of-the-art methods based on much more common masked
autoencoders (MAE) and achieves competitive results in multiple benchmarks.
  We also provide a rigorous ablation study evaluating SatDINO's individual
components. Finally, we propose a few novel enhancements, such as a new way to
incorporate ground sample distance (GSD) encoding and adaptive view sampling.
These enhancements can be used independently on our SatDINO model. Our code and
trained models are available at: https://github.com/strakaj/SatDINO.

</details>


### [24] [Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives](https://arxiv.org/abs/2508.21418)
*Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub*

Main category: cs.CV

TL;DR: 提出一个通用框架，通过生成2D索引地图和分层组织信息，解决WSI元数据缺失问题，提升AI算法开发效率。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏WSI元数据的标准，导致大规模WSI集合的内容筛选依赖人工，效率低下。

Method: 提出了一个通用框架，用于生成WSI的2D索引地图，并设计了特定应用领域的分析机制。框架包含三层组织：来源、组织类型和病理变化。

Result: 框架在临床病理学中验证有效，通过通用语法和语义实现不同目录间的互操作性，提升了WSI在ML和图表示中的应用。

Conclusion: 提出的框架通过生成详细的2D索引地图和特定应用领域的分析机制，显著提高了WSI内容的可访问性和利用率，尤其在临床病理学中表现出色。

Abstract: A Whole Slide Image (WSI) is a high-resolution digital image created by
scanning an entire glass slide containing a biological specimen, such as tissue
sections or cell samples, at multiple magnifications. These images can be
viewed, analyzed, shared digitally, and are used today for Artificial
Intelligence (AI) algorithm development. WSIs are used in a variety of fields,
including pathology for diagnosing diseases and oncology for cancer research.
They are also utilized in neurology, veterinary medicine, hematology,
microbiology, dermatology, pharmacology, toxicology, immunology, and forensic
science.
  When assembling cohorts for the training or validation of an AI algorithm, it
is essential to know what is present on such a WSI. However, there is currently
no standard for this metadata, so such selection has mainly been done through
manual inspection, which is not suitable for large collections with several
million objects.
  We propose a general framework to generate a 2D index map for WSI and a
profiling mechanism for specific application domains. We demonstrate this
approach in the field of clinical pathology, using common syntax and semantics
to achieve interoperability between different catalogs.
  Our approach augments each WSI collection with a detailed tissue map that
provides fine-grained information about the WSI content. The tissue map is
organized into three layers: source, tissue type, and pathological alterations,
with each layer assigning segments of the WSI to specific classes.
  We illustrate the advantages and applicability of the proposed standard
through specific examples in WSI catalogs, Machine Learning (ML), and
graph-based WSI representations.

</details>


### [25] [Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels](https://arxiv.org/abs/2508.21424)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: ICPL是一种无监督增量学习方法，通过置信度伪标签从未标注数据学习新类，性能优于现有方法5%以上。


<details>
  <summary>Details</summary>
Motivation: 现有的类增量学习方法（CIL）假设增量数据集完全标注，这在现实中不切实际。因此，需要一种能够从未标注数据中学习新类的方法。

Method: 提出了一种基于置信度伪标签的无监督增量学习方法（ICPL），该方法用伪标签替代人工标注，实现了从未标注数据集的增量学习。

Result: ICPL在CIFAR100和ImageNet100上评估了性能下降，并在细粒度数据集上验证了其实际应用性。其计算复杂度也适合资源受限环境。

Conclusion: ICPL方法在无监督增量学习方面取得了与监督方法相竞争的结果，并在最终准确率上超过了最先进的class-iNCD方法5%以上。

Abstract: Deep learning models have achieved state-of-the-art performance in many
computer vision tasks. However, in real-world scenarios, novel classes that
were unseen during training often emerge, requiring models to acquire new
knowledge incrementally. Class-Incremental Learning (CIL) methods enable a
model to learn novel classes while retaining knowledge of previous classes.
However, these methods make the strong assumption that the incremental dataset
is fully labeled, which is unrealistic in practice. In this work, we propose an
unsupervised Incremental Learning method using Confidence-based Pseudo-labels
(ICPL), which replaces human annotations with pseudo-labels, enabling
incremental learning from unlabeled datasets. We integrate these pseudo-labels
into various CIL methods with confidence-based selection and evaluate
performance degradation on CIFAR100 and ImageNet100. Then, we compare our
approach to popular Class Incremental Novel Category Discovery (class-iNCD)
methods addressing similar challenges. Additionally, we apply our method to
fine-grained datasets to demonstrate its real-world practicality and measure
its computational complexity to validate its suitability for
resource-constrained environments. ICPL achieves competitive results compared
to supervised methods and outperforms state-of-the-art class-iNCD methods by
more than 5% in final accuracy.

</details>


### [26] [Complete Gaussian Splats from a Single Image with Denoising Diffusion Models](https://arxiv.org/abs/2508.21542)
*Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman*

Main category: cs.CV

TL;DR: 论文提出了一种潜在扩散模型，从单张图像生成完整3D高斯喷溅场景，解决了传统方法在遮挡和未观察区域重建中的模糊和多解性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在重建遮挡和未观察区域时，通常采用基于回归的单一模式预测，导致模糊、不合理或无法捕捉多解性。本文旨在通过生成式方法解决这一问题，实现高质量的全景渲染。

Method: 提出了一种生成式框架，结合变分自重构器（Variational AutoReconstructor）和扩散模型，从2D图像中自监督学习潜在空间，并在此基础上训练扩散模型，以生成多样的3D高斯喷溅表示。

Result: 该方法能够生成忠实且多样的重建结果，成功完成遮挡表面的重建，支持高质量的360度渲染。

Conclusion: 该论文提出了一种基于潜在扩散模型的方法，能够从单张输入图像中生成完整的3D高斯喷溅场景，包括遮挡部分，显著提高了场景重建的完整性和多样性。

Abstract: Gaussian splatting typically requires dense observations of the scene and can
fail to reconstruct occluded and unobserved areas. We propose a latent
diffusion model to reconstruct a complete 3D scene with Gaussian splats,
including the occluded parts, from only a single image during inference.
Completing the unobserved surfaces of a scene is challenging due to the
ambiguity of the plausible surfaces. Conventional methods use a
regression-based formulation to predict a single "mode" for occluded and
out-of-frustum surfaces, leading to blurriness, implausibility, and failure to
capture multiple possible explanations. Thus, they often address this problem
partially, focusing either on objects isolated from the background,
reconstructing only visible surfaces, or failing to extrapolate far from the
input views. In contrast, we propose a generative formulation to learn a
distribution of 3D representations of Gaussian splats conditioned on a single
input image. To address the lack of ground-truth training data, we propose a
Variational AutoReconstructor to learn a latent space only from 2D images in a
self-supervised manner, over which a diffusion model is trained. Our method
generates faithful reconstructions and diverse samples with the ability to
complete the occluded surfaces for high-quality 360-degree renderings.

</details>


### [27] [MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation](https://arxiv.org/abs/2508.21435)
*Francisco Caetano,Christiaan Viviers,Peter H. H. de With,Fons van der Sommen*

Main category: cs.CV

TL;DR: MedShift 是一种用于合成和真实 X 射线图像跨域翻译的生成模型，基于 Flow Matching 和 Schrodinger Bridges，支持高保真度的无配对翻译，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 合成医学数据虽然为训练鲁棒模型提供了可扩展的解决方案，但由于显著的领域差距，其泛化到真实临床环境的能力有限。本文旨在解决合成和真实头部 X 射线图像之间的跨域翻译挑战。

Method: MedShift 是一种基于 Flow Matching 和 Schrodinger Bridges 的类条件生成模型，通过学习共享的域无关潜在空间，支持在训练期间见过的任何域对之间无缝翻译。

Result: 实验结果表明，尽管 MedShift 的模型规模小于基于扩散的方法，但其性能强劲，且在推理时具有灵活性，可以调整以优先考虑感知保真度或结构一致性。

Conclusion: MedShift 提出了一种基于 Flow Matching 和 Schrodinger Bridges 的统一类条件生成模型，能够实现高保真度的无配对图像跨域翻译，为医学成像中的域适应提供了可扩展和通用的解决方案。

Abstract: Synthetic medical data offers a scalable solution for training robust models,
but significant domain gaps limit its generalizability to real-world clinical
settings. This paper addresses the challenge of cross-domain translation
between synthetic and real X-ray images of the head, focusing on bridging
discrepancies in attenuation behavior, noise characteristics, and soft tissue
representation. We propose MedShift, a unified class-conditional generative
model based on Flow Matching and Schrodinger Bridges, which enables
high-fidelity, unpaired image translation across multiple domains. Unlike prior
approaches that require domain-specific training or rely on paired data,
MedShift learns a shared domain-agnostic latent space and supports seamless
translation between any pair of domains seen during training. We introduce
X-DigiSkull, a new dataset comprising aligned synthetic and real skull X-rays
under varying radiation doses, to benchmark domain translation models.
Experimental results demonstrate that, despite its smaller model size compared
to diffusion-based approaches, MedShift offers strong performance and remains
flexible at inference time, as it can be tuned to prioritize either perceptual
fidelity or structural consistency, making it a scalable and generalizable
solution for domain adaptation in medical imaging. The code and dataset are
available at https://caetas.github.io/medshift.html

</details>


### [28] [Trees as Gaussians: Large-Scale Individual Tree Mapping](https://arxiv.org/abs/2508.21437)
*Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt*

Main category: cs.CV

TL;DR: 本研究提出了一种基于深度学习的全球高分辨率树木检测方法，利用高斯核模拟树冠，训练数据来自机载激光雷达，表现优于现有方法，适用于未来卫星任务。


<details>
  <summary>Details</summary>
Motivation: 树木是陆地生物圈的关键组成部分，在生态系统功能、气候调节和生物经济中发挥着重要作用。然而，大尺度个体树木监测仍受限于不充分的建模。现有的全球产品主要关注二值树冠覆盖或冠层高度，无法在个体层次上明确识别树木。

Method: 本研究提出了一种深度学习方法来检测3米分辨率的PlanetScope影像中的大型个体树木。通过使用可伸缩大小的高斯核模拟树冠，从而提取树冠中心并生成二进制树冠覆盖图。训练基于从机载激光雷达数据中自动提取的数十亿个点。

Result: 与现有的树冠覆盖图和机载激光雷达相比，该方法表现出最先进的性能（与航空激光雷达相比，分数覆盖R²=0.81），在不同生物群落中报告了平衡的检测指标，并展示了如何通过手动标记的微调进一步提高检测效果。

Conclusion: 该方法提供了一个可扩展的框架，用于全球高分辨率树木监测，并适用于未来提供改进影像的卫星任务。

Abstract: Trees are key components of the terrestrial biosphere, playing vital roles in
ecosystem function, climate regulation, and the bioeconomy. However,
large-scale monitoring of individual trees remains limited by inadequate
modelling. Available global products have focused on binary tree cover or
canopy height, which do not explicitely identify trees at individual level. In
this study, we present a deep learning approach for detecting large individual
trees in 3-m resolution PlanetScope imagery at a global scale. We simulate tree
crowns with Gaussian kernels of scalable size, allowing the extraction of crown
centers and the generation of binary tree cover maps. Training is based on
billions of points automatically extracted from airborne lidar data, enabling
the model to successfully identify trees both inside and outside forests. We
compare against existing tree cover maps and airborne lidar with
state-of-the-art performance (fractional cover R$^2 = 0.81$ against aerial
lidar), report balanced detection metrics across biomes, and demonstrate how
detection can be further improved through fine-tuning with manual labels. Our
method offers a scalable framework for global, high-resolution tree monitoring,
and is adaptable to future satellite missions offering improved imagery.

</details>


### [29] [Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content](https://arxiv.org/abs/2508.21444)
*Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang*

Main category: cs.CV

TL;DR: \M~是一种高效的可扩展高斯溅射框架，通过分层高斯组织和自适应策略优化动态场景训练。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射在动态场景中因密集高斯数据量和长训练时间而受限的问题。

Method: 采用基于锚点的分层高斯球组织，结合混合变形和生成策略建模帧间运动，并通过双向自适应掩码机制优化训练。

Result: 实验表明，\M~在显著减少训练时间的同时，实现了优于现有方法的视觉质量。

Conclusion: \M~框架通过分层组织高斯球、混合变形与生成策略以及双向自适应掩码机制，显著提升了动态场景下的训练效率和视觉质量。

Abstract: 3D Gaussian Splatting (3DGS) enables high-fidelity real-time rendering, a key
requirement for immersive applications. However, the extension of 3DGS to
dynamic scenes remains limitations on the substantial data volume of dense
Gaussians and the prolonged training time required for each frame. This paper
presents \M, a scalable Gaussian Splatting framework designed for efficient
training in streaming tasks. Specifically, Gaussian spheres are hierarchically
organized by scale within an anchor-based structure. Coarser-level Gaussians
represent the low-resolution structure of the scene, while finer-level
Gaussians, responsible for detailed high-fidelity rendering, are selectively
activated by the coarser-level Gaussians. To further reduce computational
overhead, we introduce a hybrid deformation and spawning strategy that models
motion of inter-frame through Gaussian deformation and triggers Gaussian
spawning to characterize wide-range motion. Additionally, a bidirectional
adaptive masking mechanism enhances training efficiency by removing static
regions and prioritizing informative viewpoints. Extensive experiments
demonstrate that \M~ achieves superior visual quality while significantly
reducing training time compared to state-of-the-art methods.

</details>


### [30] [One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist](https://arxiv.org/abs/2508.21451)
*Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo*

Main category: cs.CV

TL;DR: 论文提出轻量级图像描述模型，通过改进视觉注意力机制解决视觉盲区，性能媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在本地设备上部署的高计算需求问题，同时保持性能。

Method: 首先探索基于125M参数语言模型的轻量级描述模型，并通过Sharp-Eyed Refinement框架改进视觉注意力机制和视觉表示。

Result: 轻量级模型性能与大型多模态通用模型相当，Sharp-Eyed Refinement框架显著提升了描述质量。

Conclusion: 该论文提出了一种轻量级图像描述模型，通过Sharp-Eyed Refinement框架解决了视觉盲区问题，实验证明其在小模型和大模型上的优越性和有效性。

Abstract: Image captioning is fundamental for applications like video instruction
systems and exploration robots, yet deploying such models on local devices is
challenging due to the high computational demands of multimodal large language
models (MLLMs). To address this, we first explore lightweight captioning by
implementing a specialist based on a 125M-parameter language model, 56 times
smaller than LLaMA-7B, and evaluating its performance on both single-sentence
and detailed captioning tasks. Surprisingly, we find that our model can achieve
performance comparable to large multimodal generalists, suggesting its
potential to serve as a strong visual specialist for on-device applications.
While promising, our model also exhibits a limitation: like other MLLMs, it
suffers from visual blindness, occasionally resulting in semantic captioning
errors. We carry out toy experiments and investigate the underlying causes,
where we observe that the problems arise from ineffective attention mechanisms
and limited visual representations. To alleviate them, we develop a novel
captioning framework, Sharp-Eyed Refinement, which enhances caption quality
through improved visual grounding. At its core, our DeepLens extracts detailed
visual representations by concentrating on informative regions identified
during the initial glance. Our experiments confirm both the advantages of our
specialist over prior small captioning models and large generalists and the
effectiveness of our framework.

</details>


### [31] [Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification](https://arxiv.org/abs/2508.21458)
*Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron*

Main category: cs.CV

TL;DR: 本研究评估了联邦学习中基础模型调优的关键设计选择，发现分类头架构影响大，冻结编码器效果佳，高级聚合方法更优，为临床部署提供了指导。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在基于AI的痴呆诊断中具有强大潜力，但将其整合到联邦学习系统中的研究仍不足。

Method: 通过系统评估分类头架构、微调策略和聚合方法等关键设计选择，使用脑MRI数据对联邦基础模型调优的性能和效率进行了基准测试。

Result: 研究发现分类头架构对性能有显著影响，冻结基础模型编码器与完全微调效果相当，高级聚合方法优于标准联邦平均。

Conclusion: 研究结果为在分散式临床环境中部署基础模型提供了实用见解，并强调了应指导未来方法开发的权衡。

Abstract: While foundation models (FMs) offer strong potential for AI-based dementia
diagnosis, their integration into federated learning (FL) systems remains
underexplored. In this benchmarking study, we systematically evaluate the
impact of key design choices: classification head architecture, fine-tuning
strategy, and aggregation method, on the performance and efficiency of
federated FM tuning using brain MRI data. Using a large multi-cohort dataset,
we find that the architecture of the classification head substantially
influences performance, freezing the FM encoder achieves comparable results to
full fine-tuning, and advanced aggregation methods outperform standard
federated averaging. Our results offer practical insights for deploying FMs in
decentralized clinical settings and highlight trade-offs that should guide
future method development.

</details>


### [32] [Multi-Method Ensemble for Out-of-Distribution Detection](https://arxiv.org/abs/2508.21463)
*Lucas Rakotoarivony*

Main category: cs.CV

TL;DR: 论文提出了一种结合特征截断和评分函数的MME方法，显著提升了OOD检测性能，尤其在ImageNet-1K上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法通常只关注单一技术或特定类型的OOD数据集，忽略了结合多种现有解决方案的潜力。论文通过理论和实证研究，证明了结合多种技术的有效性。

Method: 论文提出了一种名为MME（Multi-Method Ensemble）的新方法，该方法结合了现有的特征截断和评分函数技术，并通过聚合多个评分函数来增强对不同类型OOD样本的鲁棒性。

Result: 在多个基准测试中，MME显著优于现有方法。使用BiT模型时，MME在ImageNet-1K上的平均FPR95为27.57%，比最佳基线方法提升了6%。

Conclusion: 该论文提出了一种名为MME（Multi-Method Ensemble）的新方法，通过结合现有的特征截断和评分函数技术，显著提升了OOD检测的性能。实验证明，MME在多个基准测试中均优于现有方法，尤其在ImageNet-1K上表现突出。

Abstract: Detecting out-of-distribution (OOD) samples is essential for neural networks
operating in open-world settings, particularly in safety-critical applications.
Existing methods have improved OOD detection by leveraging two main techniques:
feature truncation, which increases the separation between in-distribution (ID)
and OOD samples, and scoring functions, which assign scores to distinguish
between ID and OOD data. However, most approaches either focus on a single
family of techniques or evaluate their effectiveness on a specific type of OOD
dataset, overlooking the potential of combining multiple existing solutions.
Motivated by this observation, we theoretically and empirically demonstrate
that state-of-the-art feature truncation and scoring functions can be
effectively combined. Moreover, we show that aggregating multiple scoring
functions enhances robustness against various types of OOD samples. Based on
these insights, we propose the Multi-Method Ensemble (MME) score, which unifies
state-of-the-art OOD detectors into a single, more effective scoring function.
Extensive experiments on both large-scale and small-scale benchmarks, covering
near-OOD and far-OOD scenarios, show that MME significantly outperforms recent
state-of-the-art methods across all benchmarks. Notably, using the BiT model,
our method achieves an average FPR95 of 27.57% on the challenging ImageNet-1K
benchmark, improving performance by 6% over the best existing baseline.

</details>


### [33] [Adversarial Patch Attack for Ship Detection via Localized Augmentation](https://arxiv.org/abs/2508.21472)
*Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang*

Main category: cs.CV

TL;DR: 论文提出一种针对远程感知图像中船只检测的局部增强方法，通过仅增强目标区域来减少背景干扰，提高对抗补丁攻击的成功率和迁移性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于DNN的船只检测技术易受对抗补丁攻击影响，且传统的数据增强方法可能因过度增强背景或非目标区域而引入干扰。

Method: 提出局部增强方法，仅对目标区域进行增强，避免影响非目标区域，从而减少背景干扰。

Result: 在HRSC2016数据集上的实验表明，该方法显著提高了对抗补丁攻击的成功率和迁移性。

Conclusion: 局部增强方法有效减少了背景干扰，使对抗补丁攻击更专注于目标区域，从而提升了攻击效果。

Abstract: Current ship detection techniques based on remote sensing imagery primarily
rely on the object detection capabilities of deep neural networks (DNNs).
However, DNNs are vulnerable to adversarial patch attacks, which can lead to
misclassification by the detection model or complete evasion of the targets.
Numerous studies have demonstrated that data transformation-based methods can
improve the transferability of adversarial examples. However, excessive
augmentation of image backgrounds or irrelevant regions may introduce
unnecessary interference, resulting in false detections of the object detection
model. These errors are not caused by the adversarial patches themselves but
rather by the over-augmentation of background and non-target areas. This paper
proposes a localized augmentation method that applies augmentation only to the
target regions, avoiding any influence on non-target areas. By reducing
background interference, this approach enables the loss function to focus more
directly on the impact of the adversarial patch on the detection model, thereby
improving the attack success rate. Experiments conducted on the HRSC2016
dataset demonstrate that the proposed method effectively increases the success
rate of adversarial patch attacks and enhances their transferability.

</details>


### [34] [ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding](https://arxiv.org/abs/2508.21496)
*Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu*

Main category: cs.CV

TL;DR: 论文提出首个长视频幻觉基准ELV-Halluc，研究语义聚合幻觉（SAH），发现其与语义复杂性相关，并通过位置编码和DPO策略有效缓解SAH。


<details>
  <summary>Details</summary>
Motivation: 尽管视频多模态大语言模型在视频理解方面取得了显著进展，但仍存在幻觉问题，尤其是长视频中的语义聚合幻觉（SAH）。现有研究主要关注短视频，且对幻觉原因的简化导致SAH未被充分研究。

Method: 论文提出ELV-Halluc基准，用于系统研究长视频中的SAH。通过分析语义复杂性和语义快速变化对SAH的影响，采用位置编码策略和DPO策略来增强模型区分事件内和事件间语义的能力。

Result: 实验证实SAH的存在，并发现其随语义复杂性增加而加剧。模型在语义快速变化时更容易产生SAH。通过位置编码和DPO策略，SAH比例显著降低27.7%。

Conclusion: 该论文通过引入ELV-Halluc基准，首次系统研究了长视频中的语义聚合幻觉（SAH），并提出位置编码策略和DPO策略来缓解SAH，实验证明这些方法能显著减少SAH比例。

Abstract: Video multimodal large language models (Video-MLLMs) have achieved remarkable
progress in video understanding. However, they remain vulnerable to
hallucination-producing content inconsistent with or unrelated to video inputs.
Previous video hallucination benchmarks primarily focus on short-videos. They
attribute hallucinations to factors such as strong language priors, missing
frames, or vision-language biases introduced by the visual encoder. While these
causes indeed account for most hallucinations in short videos, they still
oversimplify the cause of hallucinations. Sometimes, models generate incorrect
outputs but with correct frame-level semantics. We refer to this type of
hallucination as Semantic Aggregation Hallucination (SAH), which arises during
the process of aggregating frame-level semantics into event-level semantic
groups. Given that SAH becomes particularly critical in long videos due to
increased semantic complexity across multiple events, it is essential to
separate and thoroughly investigate the causes of this type of hallucination.
To address the above issues, we introduce ELV-Halluc, the first benchmark
dedicated to long-video hallucination, enabling a systematic investigation of
SAH. Our experiments confirm the existence of SAH and show that it increases
with semantic complexity. Additionally, we find that models are more prone to
SAH on rapidly changing semantics. Moreover, we discuss potential approaches to
mitigate SAH. We demonstrate that positional encoding strategy contributes to
alleviating SAH, and further adopt DPO strategy to enhance the model's ability
to distinguish semantics within and across events. To support this, we curate a
dataset of 8K adversarial data pairs and achieve improvements on both
ELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.

</details>


### [35] [Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation](https://arxiv.org/abs/2508.21529)
*Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper*

Main category: cs.CV

TL;DR: 通过卷积神经网络上采样基础模型特征，显著提升显微图像分割效率和质量，减少标签需求。


<details>
  <summary>Details</summary>
Motivation: 解决基于补丁的特征描述子在显微图像中难以捕捉细微特征和大图像尺寸处理效率低的问题。

Method: 训练一个卷积神经网络，用于上采样低分辨率的基础模型特征，参考输入图像进行优化。

Result: 应用上采样网络在多种显微图像（如植物细胞、锂离子电池阴极、有机晶体）上实现了高效的特征提取和分割，尤其对难以分割的相（如发丝裂纹）表现出色。

Conclusion: 通过训练卷积神经网络上采样低分辨率的基础模型特征，结合输入图像，该方法能够高效地处理显微图像，实现高质量的交互式分割，显著减少标签需求和时间成本。

Abstract: Feature foundation models - usually vision transformers - offer rich semantic
descriptors of images, useful for downstream tasks such as (interactive)
segmentation and object detection. For computational efficiency these
descriptors are often patch-based, and so struggle to represent the fine
features often present in micrographs; they also struggle with the large image
sizes present in materials and biological image analysis. In this work, we
train a convolutional neural network to upsample low-resolution (i.e, large
patch size) foundation model features with reference to the input image. We
apply this upsampler network (without any further training) to efficiently
featurise and then segment a variety of microscopy images, including plant
cells, a lithium-ion battery cathode and organic crystals. The richness of
these upsampled features admits separation of hard to segment phases, like
hairline cracks. We demonstrate that interactive segmentation with these deep
features produces high-quality segmentations far faster and with far fewer
labels than training or finetuning a more traditional convolutional network.

</details>


### [36] [HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones](https://arxiv.org/abs/2508.21539)
*Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li*

Main category: cs.CV

TL;DR: HCCM框架通过区域-全局对比学习和匹配学习，解决了无人机场景中视觉-语言理解的挑战，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 无人机场景中的宽视场和复杂组合语义对视觉-语言理解提出了挑战。现有的视觉-语言模型（VLMs）缺乏细粒度语义，而分层方法依赖于精确的实体划分和严格包含，限制了在动态环境中的有效性。因此，需要一种新的框架来解决这些问题。

Method: HCCM框架包含两个主要组件：(1) 区域-全局图像-文本对比学习（RG-ITC），通过对比局部视觉区域与全局文本来捕获层次化的局部到全局语义；(2) 区域-全局图像-文本匹配（RG-ITM），通过评估全局跨模态表示中的局部语义一致性来增强组合推理能力。此外，HCCM还引入了动量对比和蒸馏（MCD）机制以提高对齐的鲁棒性。

Result: 在GeoText-1652数据集上，HCCM实现了28.8%的图像检索Recall@1和14.7%的文本检索Recall@1。在未见的ERA数据集上，HCCM展示了强大的零样本泛化能力，平均召回率（mR）达到39.93%，优于微调的基线方法。

Conclusion: HCCM框架通过其区域-全局图像-文本对比学习和匹配学习组件，显著提升了无人机场景下的视觉-语言理解能力，特别是在动态环境中。实验结果表明，HCCM在GeoText-1652和ERA数据集上均取得了优异的性能，展示了其在零样本泛化方面的强大能力。

Abstract: Natural Language-Guided Drones (NLGD) provide a novel paradigm for tasks such
as target matching and navigation. However, the wide field of view and complex
compositional semantics in drone scenarios pose challenges for vision-language
understanding. Mainstream Vision-Language Models (VLMs) emphasize global
alignment while lacking fine-grained semantics, and existing hierarchical
methods depend on precise entity partitioning and strict containment, limiting
effectiveness in dynamic environments. To address this, we propose the
Hierarchical Cross-Granularity Contrastive and Matching learning (HCCM)
framework with two components: (1) Region-Global Image-Text Contrastive
Learning (RG-ITC), which avoids precise scene partitioning and captures
hierarchical local-to-global semantics by contrasting local visual regions with
global text and vice versa; (2) Region-Global Image-Text Matching (RG-ITM),
which dispenses with rigid constraints and instead evaluates local semantic
consistency within global cross-modal representations, enhancing compositional
reasoning. Moreover, drone text descriptions are often incomplete or ambiguous,
destabilizing alignment. HCCM introduces a Momentum Contrast and Distillation
(MCD) mechanism to improve robustness. Experiments on GeoText-1652 show HCCM
achieves state-of-the-art Recall@1 of 28.8% (image retrieval) and 14.7% (text
retrieval). On the unseen ERA dataset, HCCM demonstrates strong zero-shot
generalization with 39.93% mean recall (mR), outperforming fine-tuned
baselines.

</details>


### [37] [EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting](https://arxiv.org/abs/2508.21550)
*Yujin Park,Haejun Chung,Ikbeom Jang*

Main category: cs.CV

TL;DR: EZ-Sort通过CLIP预排序和不确定性采样，显著减少成对排序的人工标注成本。


<details>
  <summary>Details</summary>
Motivation: 成对比较在主观或困难标注任务中更可靠，但传统方法需要大量标注（O(n^2)），近期工作通过主动采样降低了负担（O(n log n)）。本文旨在进一步提高标注效率。

Method: 1. 使用CLIP模型进行零样本预排序；2. 初始化带桶感知的Elo分数；3. 运行不确定性引导的人机交互MergeSort。

Result: EZ-Sort在多个数据集上验证，相比穷尽成对比较减少了90.5%的人工标注成本，相比先前工作减少了19.8%（n=100时），同时保持或提高了评分者间可靠性。

Conclusion: EZ-Sort结合CLIP先验和不确定性感知采样，提供了高效且可扩展的成对排序解决方案。

Abstract: Pairwise comparison is often favored over absolute rating or ordinal
classification in subjective or difficult annotation tasks due to its improved
reliability. However, exhaustive comparisons require a massive number of
annotations (O(n^2)). Recent work has greatly reduced the annotation burden
(O(n log n)) by actively sampling pairwise comparisons using a sorting
algorithm. We further improve annotation efficiency by (1) roughly pre-ordering
items using the Contrastive Language-Image Pre-training (CLIP) model
hierarchically without training, and (2) replacing easy, obvious human
comparisons with automated comparisons. The proposed EZ-Sort first produces a
CLIP-based zero-shot pre-ordering, then initializes bucket-aware Elo scores,
and finally runs an uncertainty-guided human-in-the-loop MergeSort. Validation
was conducted using various datasets: face-age estimation (FGNET), historical
image chronology (DHCI), and retinal image quality assessment (EyePACS). It
showed that EZ-Sort reduced human annotation cost by 90.5% compared to
exhaustive pairwise comparisons and by 19.8% compared to prior work (when n =
100), while improving or maintaining inter-rater reliability. These results
demonstrate that combining CLIP-based priors with uncertainty-aware sampling
yields an efficient and scalable solution for pairwise ranking.

</details>


### [38] [ECHO: Ego-Centric modeling of Human-Object interactions](https://arxiv.org/abs/2508.21556)
*Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll*

Main category: cs.CV

TL;DR: ECHO是一个统一的框架，首次从最小观测（头部和手腕跟踪）中恢复人-物交互的三种模态（人体姿态、物体运动、接触），采用Diffusion Transformer和三变量扩散过程，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于可穿戴设备（如智能眼镜和手表）的普及，从第一人称视角建模人-物交互（HOI）是一个重要但尚未充分探索的问题。本研究探讨了仅通过头部和手腕跟踪能恢复多少交互信息。

Method: ECHO采用Diffusion Transformer架构和独特的三变量扩散过程，联合建模人体运动、物体轨迹和接触序列，支持灵活的输入配置。方法在头中心规范空间中操作，增强了对全局方向的鲁棒性。

Result: ECHO在广泛的评估中表现优于现有方法，提供了更高的灵活性，并在第一人称HOI重建中达到了最先进的水平。

Conclusion: ECHO 提出了一种统一的框架，首次从最小观测中恢复三种模态：人体姿态、物体运动和接触。该方法在头戴式设备视角下表现出色，为HOI重建设定了新的技术标准。

Abstract: Modeling human-object interactions (HOI) from an egocentric perspective is a
largely unexplored yet important problem due to the increasing adoption of
wearable devices, such as smart glasses and watches. We investigate how much
information about interaction can be recovered from only head and wrists
tracking. Our answer is ECHO (Ego-Centric modeling of Human-Object
interactions), which, for the first time, proposes a unified framework to
recover three modalities: human pose, object motion, and contact from such
minimal observation. ECHO employs a Diffusion Transformer architecture and a
unique three-variate diffusion process, which jointly models human motion,
object trajectory, and contact sequence, allowing for flexible input
configurations. Our method operates in a head-centric canonical space,
enhancing robustness to global orientation. We propose a conveyor-based
inference, which progressively increases the diffusion timestamp with the frame
position, allowing us to process sequences of any length. Through extensive
evaluation, we demonstrate that ECHO outperforms existing methods that do not
offer the same flexibility, setting a state-of-the-art in egocentric HOI
reconstruction.

</details>


### [39] [How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images](https://arxiv.org/abs/2508.21565)
*Juneyoung Ro,Namwoo Kim,Yoonjin Yoon*

Main category: cs.CV

TL;DR: 研究比较了三款现成的视觉语言模型在城市场景中的空间推理能力，发现微调合成的链式思考监督数据集能显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索当前在通用场景上预训练的视觉语言模型（VLMs）在城市领域中的空间推理能力转移效果。

Method: 通过从街景图像的分割、深度和物体检测预测中构建一个合成的视觉问答（VQA）数据集，并为每个问题配以LLM生成的链式思考（CoT）答案，用于逐步推理监督。

Result: 结果表明，虽然VLMs在零样本设置下表现合理，但使用合成的CoT监督数据集进行微调能显著提升性能，尤其是在否定和反事实等挑战性问题类型上。

Conclusion: 本研究将城市空间推理作为视觉语言模型（VLMs）的新挑战，并展示了合成数据集构建作为通用模型适应专业领域的实用路径。

Abstract: Effectively understanding urban scenes requires fine-grained spatial
reasoning about objects, layouts, and depth cues. However, how well current
vision-language models (VLMs), pretrained on general scenes, transfer these
abilities to urban domain remains underexplored. To address this gap, we
conduct a comparative study of three off-the-shelf VLMs-BLIP-2, InstructBLIP,
and LLaVA-1.5-evaluating both zero-shot performance and the effects of
fine-tuning with a synthetic VQA dataset specific to urban scenes. We construct
such dataset from segmentation, depth, and object detection predictions of
street-view images, pairing each question with LLM-generated Chain-of-Thought
(CoT) answers for step-by-step reasoning supervision. Results show that while
VLMs perform reasonably well in zero-shot settings, fine-tuning with our
synthetic CoT-supervised dataset substantially boosts performance, especially
for challenging question types such as negation and counterfactuals. This study
introduces urban spatial reasoning as a new challenge for VLMs and demonstrates
synthetic dataset construction as a practical path for adapting general-purpose
models to specialized domains.

</details>


### [40] [Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging](https://arxiv.org/abs/2508.21580)
*Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: TFM是一种新的生成轨迹方法，用于4D医学图像预测，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在医学影像中的时间动态理解有限，通常仅考虑单一时间上下文或专注于分类/回归任务，无法进行细粒度空间预测。

Method: TFM是一种生成轨迹方法，能够学习潜在的时间分布，支持3D体积、多个先验扫描和不规则采样。

Result: 在三个公共纵向数据集上的广泛基准测试表明，TFM始终优于自然成像中的时空方法。

Conclusion: TFM提出了一种统一的生成轨迹方法，在4D医学图像预测中建立了新的最先进和稳健的基线。

Abstract: Understanding temporal dynamics in medical imaging is crucial for
applications such as disease progression modeling, treatment planning and
anatomical development tracking. However, most deep learning methods either
consider only single temporal contexts, or focus on tasks like classification
or regression, limiting their ability for fine-grained spatial predictions.
While some approaches have been explored, they are often limited to single
timepoints, specific diseases or have other technical restrictions. To address
this fundamental gap, we introduce Temporal Flow Matching (TFM), a unified
generative trajectory method that (i) aims to learn the underlying temporal
distribution, (ii) by design can fall back to a nearest image predictor, i.e.
predicting the last context image (LCI), as a special case, and (iii) supports
$3D$ volumes, multiple prior scans, and irregular sampling. Extensive
benchmarks on three public longitudinal datasets show that TFM consistently
surpasses spatio-temporal methods from natural imaging, establishing a new
state-of-the-art and robust baseline for $4D$ medical image prediction.

</details>


### [41] [Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer](https://arxiv.org/abs/2508.21581)
*Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado*

Main category: cs.CV

TL;DR: 该研究通过整合术前CT和术后病理WSI，开发了一个多模态复发预测模型，显示病理学在预后中的优势，并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 为了改进ccRCC的复发风险估计，当前广泛使用的Leibovich评分在患者水平分辨率有限且未包含影像信息。

Method: 研究采用模块化深度学习框架，结合预训练的编码器和基于Cox的生存模型，测试了单模态、晚期融合和中期融合的设置。

Result: 在真实世界的ccRCC队列中，基于WSI的模型始终优于仅CT的模型，中期融合进一步提升了性能，最佳模型（TITAN-CONCH with ResNet-18）接近调整后的Leibovich评分。

Conclusion: 该研究展示了基于基础模型的多模态整合在个性化ccRCC风险预测中的可行性，并建议未来探索更具表达力的融合策略、更大的多模态数据集和通用的CT编码器。

Abstract: Recurrence risk estimation in clear cell renal cell carcinoma (ccRCC) is
essential for guiding postoperative surveillance and treatment. The Leibovich
score remains widely used for stratifying distant recurrence risk but offers
limited patient-level resolution and excludes imaging information. This study
evaluates multimodal recurrence prediction by integrating preoperative computed
tomography (CT) and postoperative histopathology whole-slide images (WSIs). A
modular deep learning framework with pretrained encoders and Cox-based survival
modeling was tested across unimodal, late fusion, and intermediate fusion
setups. In a real-world ccRCC cohort, WSI-based models consistently
outperformed CT-only models, underscoring the prognostic strength of pathology.
Intermediate fusion further improved performance, with the best model
(TITAN-CONCH with ResNet-18) approaching the adjusted Leibovich score. Random
tie-breaking narrowed the gap between the clinical baseline and learned models,
suggesting discretization may overstate individualized performance. Using
simple embedding concatenation, radiology added value primarily through fusion.
These findings demonstrate the feasibility of foundation model-based multimodal
integration for personalized ccRCC risk prediction. Future work should explore
more expressive fusion strategies, larger multimodal datasets, and
general-purpose CT encoders to better match pathology modeling capacity.

</details>


### [42] [Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation](https://arxiv.org/abs/2508.21657)
*Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan*

Main category: cs.CV

TL;DR: 提出DUN网络，通过ABPM和PCD模块解决CGH重建问题，实现高PSNR和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端网络忽视物理关系、CNN模型感受野有限、ASM模型局限于近场，导致重建精度和稳定性不足。

Method: 提出了一种深度展开网络(DUN)，将梯度下降分解为自适应带宽保持模型(ABPM)和相位域复数去噪器(PCD)，ABPM支持更宽的工作距离，PCD通过复数可变形自注意力模块捕获全局特征。

Result: 在模拟和真实数据实验中，DUN实现了PSNR超过35 dB的先进性能。

Conclusion: 提出的Deep Unfolding Network (DUN)通过ABPM和PCD模块，在计算机生成全息术(CGH)中实现了更高的灵活性和性能，PSNR超过35 dB，实验证明了其先进性能。

Abstract: Computer-generated holography (CGH) has gained wide attention with deep
learning-based algorithms. However, due to its nonlinear and ill-posed nature,
challenges remain in achieving accurate and stable reconstruction.
Specifically, ($i$) the widely used end-to-end networks treat the
reconstruction model as a black box, ignoring underlying physical
relationships, which reduces interpretability and flexibility. ($ii$) CNN-based
CGH algorithms have limited receptive fields, hindering their ability to
capture long-range dependencies and global context. ($iii$) Angular spectrum
method (ASM)-based models are constrained to finite near-fields.In this paper,
we propose a Deep Unfolding Network (DUN) that decomposes gradient descent into
two modules: an adaptive bandwidth-preserving model (ABPM) and a phase-domain
complex-valued denoiser (PCD), providing more flexibility. ABPM allows for
wider working distances compared to ASM-based methods. At the same time, PCD
leverages its complex-valued deformable self-attention module to capture global
features and enhance performance, achieving a PSNR over 35 dB. Experiments on
simulated and real data show state-of-the-art results.

</details>


### [43] [Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models](https://arxiv.org/abs/2508.21680)
*Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 研究扩展了nnU-Net框架以支持交互式分割，通过EDT编码用户点击提示，显著提升了PET/CT病灶分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决PET/CT中由于示踪剂异质性、生理摄取和多中心变异性导致的病灶分割不准确问题，同时探索保持人工参与的交互式分割方法。

Method: 在nnU-Net框架基础上扩展可提示功能，通过编码用户提供的前景和背景点击作为额外输入通道，并系统比较了空间提示的不同表示方式。

Result: EDT编码在空间提示表示中表现最佳，提出的模型集成在交叉验证中表现最强，显著减少了假阳性和假阴性。

Conclusion: 研究结果表明，基于EDT编码的可提示模型在PET/CT多中心和多样本场景中，能够显著减少假阳性和假阴性，提升分割效率。

Abstract: Whole-body PET/CT is a cornerstone of oncological imaging, yet accurate
lesion segmentation remains challenging due to tracer heterogeneity,
physiological uptake, and multi-center variability. While fully automated
methods have advanced substantially, clinical practice benefits from approaches
that keep humans in the loop to efficiently refine predicted masks. The
autoPET/CT IV challenge addresses this need by introducing interactive
segmentation tasks based on simulated user prompts. In this work, we present
our submission to Task 1. Building on the winning autoPET III nnU-Net pipeline,
we extend the framework with promptable capabilities by encoding user-provided
foreground and background clicks as additional input channels. We
systematically investigate representations for spatial prompts and demonstrate
that Euclidean Distance Transform (EDT) encodings consistently outperform
Gaussian kernels. Furthermore, we propose online simulation of user
interactions and a custom point sampling strategy to improve robustness under
realistic prompting conditions. Our ensemble of EDT-based models, trained with
and without external data, achieves the strongest cross-validation performance,
reducing both false positives and false negatives compared to baseline models.
These results highlight the potential of promptable models to enable efficient,
user-guided segmentation workflows in multi-tracer, multi-center PET/CT. Code
is publicly available at https://github.com/MIC-DKFZ/autoPET-interactive

</details>


### [44] [Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR](https://arxiv.org/abs/2508.21693)
*Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora*

Main category: cs.CV

TL;DR: 本文提出行级别OCR方法，绕过单词分割错误并利用更大上下文，实验显示准确率提升5.4%，效率提升4倍。


<details>
  <summary>Details</summary>
Motivation: 传统OCR技术在字符分割和识别中容易出错，且缺乏利用语言模型的上下文。现代技术转向单词级别OCR，但瓶颈转向单词分割。因此，提出行级别OCR以进一步提升准确率和效率。

Method: 提出从单词级别OCR到行级别OCR的自然逻辑演进方法，绕过单词检测错误，并利用更大的句子上下文来更好地利用语言模型。

Result: 实验显示端到端准确率提升5.4%，效率比单词级别OCR提升4倍。

Conclusion: 过渡到行级别OCR不仅能提高准确率，还能提升效率，尤其在文档图像处理中具有显著优势。随着大型语言模型的持续进步，该方法还有进一步优化的潜力。

Abstract: Conventional optical character recognition (OCR) techniques segmented each
character and then recognized. This made them prone to error in character
segmentation, and devoid of context to exploit language models. Advances in
sequence to sequence translation in last decade led to modern techniques first
detecting words and then inputting one word at a time to a model to directly
output full words as sequence of characters. This allowed better utilization of
language models and bypass error-prone character segmentation step. We observe
that the above transition in style has moved the bottleneck in accuracy to word
segmentation. Hence, in this paper, we propose a natural and logical
progression from word level OCR to line-level OCR. The proposal allows to
bypass errors in word detection, and provides larger sentence context for
better utilization of language models. We show that the proposed technique not
only improves the accuracy but also efficiency of OCR. Despite our thorough
literature survey, we did not find any public dataset to train and benchmark
such shift from word to line-level OCR. Hence, we also contribute a
meticulously curated dataset of 251 English page images with line-level
annotations. Our experimentation revealed a notable end-to-end accuracy
improvement of 5.4%, underscoring the potential benefits of transitioning
towards line-level OCR, especially for document images. We also report a 4
times improvement in efficiency compared to word-based pipelines. With
continuous improvements in large language models, our methodology also holds
potential to exploit such advances. Project Website:
https://nishitanand.github.io/line-level-ocr-website

</details>


### [45] [Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping](https://arxiv.org/abs/2508.21689)
*Fatih Erdoğan,Merve Rabia Barın,Fatma Güney*

Main category: cs.CV

TL;DR: 研究提出了一种基于几何映射和置信度评分的概率投影机制，显著提升了HD地图构建的准确性和泛化性，尤其在长感知范围中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有HD地图构建方法在准确性和泛化性上存在不足，常产生虚假道路元素。研究旨在通过几何映射和自适应场景调整，提升映射精度和HD地图质量。

Method: 提出了一种新颖的概率投影机制，结合几何映射和置信度评分，以优化从图像空间到BEV空间的映射，并过滤无关元素。同时改进了时间处理，通过置信度评分选择性积累可靠信息。

Result: 在新划分的nuScenes和Argoverse2数据集上，所提方法在性能上优于现有技术，尤其在长感知范围中表现更优。

Conclusion: 通过提出的概率投影机制和置信度评分，研究在nuScenes和Argoverse2数据集上实现了优于现有方法的性能，特别是在长感知范围挑战中表现显著。

Abstract: Constructing high-definition (HD) maps from sensory input requires accurately
mapping the road elements in image space to the Bird's Eye View (BEV) space.
The precision of this mapping directly impacts the quality of the final
vectorized HD map. Existing HD mapping approaches outsource the projection to
standard mapping techniques, such as attention-based ones. However, these
methods struggle with accuracy due to generalization problems, often
hallucinating non-existent road elements. Our key idea is to start with a
geometric mapping based on camera parameters and adapt it to the scene to
extract relevant map information from camera images. To implement this, we
propose a novel probabilistic projection mechanism with confidence scores to
(i) refine the mapping to better align with the scene and (ii) filter out
irrelevant elements that should not influence HD map generation. In addition,
we improve temporal processing by using confidence scores to selectively
accumulate reliable information over time. Experiments on new splits of the
nuScenes and Argoverse2 datasets demonstrate improved performance over
state-of-the-art approaches, indicating better generalization. The improvements
are particularly pronounced on nuScenes and in the challenging long perception
range. Our code and model checkpoints are available at
https://github.com/Fatih-Erdogan/mapping-like-skeptic .

</details>


### [46] [Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks](https://arxiv.org/abs/2508.21715)
*Amirhossein Nazeri,Wael Hafez*

Main category: cs.CV

TL;DR: 研究发现CNN激活熵能有效检测对抗性扰动，无需修改模型即可实现高准确率检测。


<details>
  <summary>Details</summary>
Motivation: 尽管卷积神经网络（CNNs）在图像识别任务中表现出色，但它们对对抗性扰动（即导致错误分类的微小输入修改）仍存在脆弱性。现有检测方法通常需要昂贵的重新训练、修改网络架构或降低对干净输入的性能。

Method: 使用并行熵监测方法在VGG-16上监测对抗性输入对CNN激活熵的影响。

Result: 对抗性输入在早期卷积层中一致地将激活熵偏移7%，实现了90%的检测准确率，假阳性和假阴性率低于20%。清洁和对抗性熵分布完全分离表明，CNNs在激活模式中固有地编码了分布偏移。

Conclusion: 该研究确立了通过激活熵单独评估CNN可靠性的方法，实现了无需修改原始模型即可实时检测对抗性输入的自诊断视觉系统的实际部署。

Abstract: Convolutional Neural Networks (CNNs) have become the foundation of modern
computer vision, achieving unprecedented accuracy across diverse image
recognition tasks. While these networks excel on in-distribution data, they
remain vulnerable to adversarial perturbations imperceptible input
modifications that cause misclassification with high confidence. However,
existing detection methods either require expensive retraining, modify network
architecture, or degrade performance on clean inputs. Here we show that
adversarial perturbations create immediate, detectable entropy signatures in
CNN activations that can be monitored without any model modification. Using
parallel entropy monitoring on VGG-16, we demonstrate that adversarial inputs
consistently shift activation entropy by 7% in early convolutional layers,
enabling 90% detection accuracy with false positives and false negative rates
below 20%. The complete separation between clean and adversarial entropy
distributions reveals that CNNs inherently encode distribution shifts in their
activation patterns. This work establishes that CNN reliability can be assessed
through activation entropy alone, enabling practical deployment of
self-diagnostic vision systems that detect adversarial inputs in real-time
without compromising original model performance.

</details>


### [47] [CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models](https://arxiv.org/abs/2508.21732)
*João Valente,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: CAD2DMD-SET工具通过合成数据提升LVLMs在复杂场景中读取DMDs的能力，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决LVLMs在真实场景中读取数字测量设备（DMDs）时的性能不足问题。

Method: 利用3D CAD模型、高级渲染和高保真图像合成技术生成合成数据集，并构建DMDBench验证集。

Result: 通过CAD2DMD-SET微调的LVLMs（如InternVL）性能提升200%，且不影响其他任务。

Conclusion: CAD2DMD-SET工具显著提升了LVLMs在复杂条件下的性能，未来将开源以支持社区扩展。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have demonstrated
impressive capabilities across various multimodal tasks. They continue,
however, to struggle with trivial scenarios such as reading values from Digital
Measurement Devices (DMDs), particularly in real-world conditions involving
clutter, occlusions, extreme viewpoints, and motion blur; common in
head-mounted cameras and Augmented Reality (AR) applications. Motivated by
these limitations, this work introduces CAD2DMD-SET, a synthetic data
generation tool designed to support visual question answering (VQA) tasks
involving DMDs. By leveraging 3D CAD models, advanced rendering, and
high-fidelity image composition, our tool produces diverse, VQA-labelled
synthetic DMD datasets suitable for fine-tuning LVLMs. Additionally, we present
DMDBench, a curated validation set of 1,000 annotated real-world images
designed to evaluate model performance under practical constraints.
Benchmarking three state-of-the-art LVLMs using Average Normalised Levenshtein
Similarity (ANLS) and further fine-tuning LoRA's of these models with
CAD2DMD-SET's generated dataset yielded substantial improvements, with InternVL
showcasing a score increase of 200% without degrading on other tasks. This
demonstrates that the CAD2DMD-SET training dataset substantially improves the
robustness and performance of LVLMs when operating under the previously stated
challenging conditions. The CAD2DMD-SET tool is expected to be released as
open-source once the final version of this manuscript is prepared, allowing the
community to add different measurement devices and generate their own datasets.

</details>


### [48] [FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA](https://arxiv.org/abs/2508.21712)
*Alvaro Patricio,Atabak Dehban,Rodrigo Ventura*

Main category: cs.CV

TL;DR: FLORA是一种轻量级合成数据生成方法，通过LoRA微调显著降低计算需求，仅需10%的数据和少量计算成本，即可超越现有性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的生成模型在数据增强方面表现出巨大潜力，但资源密集型全微调限制了其实际应用。FLORA旨在通过轻量级管道解决这一问题。

Method: FLORA采用Flux 1.1 Dev扩散模型，通过低秩适应（LoRA）进行微调，显著降低了计算需求。

Result: 在七个不同目标检测数据集上，仅使用500张FLORA生成的合成图像训练的检测器，性能优于使用5000张ODGEN基线图像训练的模型，mAP@.50:.95提升高达21.3%。

Conclusion: FLORA展示了在合成数据生成中，质量与效率并重的策略比暴力生成更有效，使得高级合成数据创建在实际应用中更加实用和可访问。

Abstract: Recent advances in diffusion-based generative models have demonstrated
significant potential in augmenting scarce datasets for object detection tasks.
Nevertheless, most recent models rely on resource-intensive full fine-tuning of
large-scale diffusion models, requiring enterprise-grade GPUs (e.g., NVIDIA
V100) and thousands of synthetic images. To address these limitations, we
propose Flux LoRA Augmentation (FLORA), a lightweight synthetic data generation
pipeline. Our approach uses the Flux 1.1 Dev diffusion model, fine-tuned
exclusively through Low-Rank Adaptation (LoRA). This dramatically reduces
computational requirements, enabling synthetic dataset generation with a
consumer-grade GPU (e.g., NVIDIA RTX 4090). We empirically evaluate our
approach on seven diverse object detection datasets. Our results demonstrate
that training object detectors with just 500 synthetic images generated by our
approach yields superior detection performance compared to models trained on
5000 synthetic images from the ODGEN baseline, achieving improvements of up to
21.3% in mAP@.50:.95. This work demonstrates that it is possible to surpass
state-of-the-art performance with far greater efficiency, as FLORA achieves
superior results using only 10% of the data and a fraction of the computational
cost. This work demonstrates that a quality and efficiency-focused approach is
more effective than brute-force generation, making advanced synthetic data
creation more practical and accessible for real-world scenarios.

</details>


### [49] [Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering](https://arxiv.org/abs/2508.21773)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 提出了一种无监督视频持续学习方法，利用KDE和动态内存扩展，显著提升了模型在连续学习任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 视频作为一种复杂且丰富的时空媒体信息，在无监督持续学习领域尚未得到充分探索，现有研究主要依赖标签和任务边界，而获取标注数据成本高且不实用。

Method: 提出了一种基于无监督视频Transformer网络提取的深度嵌入视频特征的核密度估计（KDE）的非参数概率表示方法，并引入了一种新颖性检测标准来动态扩展内存集群。

Result: 在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上的深入评估表明，该方法显著提升了性能。

Conclusion: 所提出的无监督视频持续学习方法显著提升了模型在连续学习多个任务时的性能，特别是在不使用任何标签或类别边界的情况下。

Abstract: We propose a realistic scenario for the unsupervised video learning where
neither task boundaries nor labels are provided when learning a succession of
tasks. We also provide a non-parametric learning solution for the
under-explored problem of unsupervised video continual learning. Videos
represent a complex and rich spatio-temporal media information, widely used in
many applications, but which have not been sufficiently explored in
unsupervised continual learning. Prior studies have only focused on supervised
continual learning, relying on the knowledge of labels and task boundaries,
while having labeled data is costly and not practical. To address this gap, we
study the unsupervised video continual learning (uVCL). uVCL raises more
challenges due to the additional computational and memory requirements of
processing videos when compared to images. We introduce a general benchmark
experimental protocol for uVCL by considering the learning of unstructured
video data categories during each task. We propose to use the Kernel Density
Estimation (KDE) of deep embedded video features extracted by unsupervised
video transformer networks as a non-parametric probabilistic representation of
the data. We introduce a novelty detection criterion for the incoming new task
data, dynamically enabling the expansion of memory clusters, aiming to capture
new knowledge when learning a succession of tasks. We leverage the use of
transfer learning from the previous tasks as an initial state for the knowledge
transfer to the current learning task. We found that the proposed methodology
substantially enhances the performance of the model when successively learning
many tasks. We perform in-depth evaluations on three standard video action
recognition datasets, including UCF101, HMDB51, and Something-to-Something V2,
without using any labels or class boundaries.

</details>


### [50] [Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight](https://arxiv.org/abs/2508.21777)
*Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz*

Main category: cs.CV

TL;DR: GPT-5在放射肿瘤学中表现优异，但需专家监督以确保临床应用的准确性。


<details>
  <summary>Details</summary>
Motivation: 评估GPT-5在临床决策支持中的潜力，尤其是在放射肿瘤学领域的应用。

Method: 通过两个基准测试评估GPT-5：ACR放射肿瘤学培训和60个真实病例的情景评估。

Result: GPT-5在TXIT基准测试中准确率达92.8%，情景评估中正确性和全面性评分较高，但仍有改进空间。

Conclusion: GPT-5在放射肿瘤学中的表现优于早期版本，但其生成的建议仍需专家严格监督。

Abstract: Introduction: Large language models (LLM) have shown great potential in
clinical decision support. GPT-5 is a novel LLM system that has been
specifically marketed towards oncology use.
  Methods: Performance was assessed using two complementary benchmarks: (i) the
ACR Radiation Oncology In-Training Examination (TXIT, 2021), comprising 300
multiple-choice items, and (ii) a curated set of 60 authentic radiation
oncologic vignettes representing diverse disease sites and treatment
indications. For the vignette evaluation, GPT-5 was instructed to generate
concise therapeutic plans. Four board-certified radiation oncologists rated
correctness, comprehensiveness, and hallucinations. Inter-rater reliability was
quantified using Fleiss' \k{appa}.
  Results: On the TXIT benchmark, GPT-5 achieved a mean accuracy of 92.8%,
outperforming GPT-4 (78.8%) and GPT-3.5 (62.1%). Domain-specific gains were
most pronounced in Dose and Diagnosis. In the vignette evaluation, GPT-5's
treatment recommendations were rated highly for correctness (mean 3.24/4, 95%
CI: 3.11-3.38) and comprehensiveness (3.59/4, 95% CI: 3.49-3.69).
Hallucinations were rare with no case reaching majority consensus for their
presence. Inter-rater agreement was low (Fleiss' \k{appa} 0.083 for
correctness), reflecting inherent variability in clinical judgment. Errors
clustered in complex scenarios requiring precise trial knowledge or detailed
clinical adaptation.
  Discussion: GPT-5 clearly outperformed prior model variants on the radiation
oncology multiple-choice benchmark. Although GPT-5 exhibited favorable
performance in generating real-world radiation oncology treatment
recommendations, correctness ratings indicate room for further improvement.
While hallucinations were infrequent, the presence of substantive errors
underscores that GPT-5-generated recommendations require rigorous expert
oversight before clinical implementation.

</details>


### [51] [TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank](https://arxiv.org/abs/2508.21795)
*Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan*

Main category: cs.CV

TL;DR: TMUAD通过三记忆库框架统一检测结构和逻辑异常，在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 由于正常数据有限，现有方法难以有效检测异常，尤其是逻辑性异常。

Method: 提出了一个Three-Memory框架（TMUAD），包括类级文本记忆库、对象级图像记忆库和补丁级记忆库，用于多层次的异常检测。

Result: TMUAD在工业和医疗领域的七个公开数据集上表现优异。

Conclusion: TMUAD通过整合结构性和逻辑性异常检测，在七个公开数据集上实现了最先进的性能。

Abstract: Anomaly detection, which aims to identify anomalies deviating from normal
patterns, is challenging due to the limited amount of normal data available.
Unlike most existing unified methods that rely on carefully designed image
feature extractors and memory banks to capture logical relationships between
objects, we introduce a text memory bank to enhance the detection of logical
anomalies. Specifically, we propose a Three-Memory framework for Unified
structural and logical Anomaly Detection (TMUAD). First, we build a class-level
text memory bank for logical anomaly detection by the proposed logic-aware text
extractor, which can capture rich logical descriptions of objects from input
images. Second, we construct an object-level image memory bank that preserves
complete object contours by extracting features from segmented objects. Third,
we employ visual encoders to extract patch-level image features for
constructing a patch-level memory bank for structural anomaly detection. These
three complementary memory banks are used to retrieve and compare normal images
that are most similar to the query image, compute anomaly scores at multiple
levels, and fuse them into a final anomaly score. By unifying structural and
logical anomaly detection through collaborative memory banks, TMUAD achieves
state-of-the-art performance across seven publicly available datasets involving
industrial and medical domains. The model and code are available at
https://github.com/SIA-IDE/TMUAD.

</details>


### [52] [Learning from Silence and Noise for Visual Sound Source Localization](https://arxiv.org/abs/2508.21761)
*Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro*

Main category: cs.CV

TL;DR: 论文提出新训练策略、指标和数据集，改进自监督模型SSL-SaN，在声音定位和跨模态检索中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前方法在低音频-视觉语义对应（如静音、噪声和屏幕外声音）情况下表现不佳，且评估仅限于单一可见声源的场景。

Method: 提出了一个结合静音和噪声的新训练策略，改进了自监督模型SSL-SaN，并引入了新指标和扩展数据集IS3+。

Result: SSL-SaN在声音定位和跨模态检索任务中表现优异，新指标有效量化了正负音频-视觉对的特征对齐和分离性。

Conclusion: 论文提出的SSL-SaN模型在声音定位和跨模态检索任务中达到了最先进的性能，并通过新训练策略、新指标和扩展数据集解决了现有方法的不足。

Abstract: Visual sound source localization is a fundamental perception task that aims
to detect the location of sounding sources in a video given its audio. Despite
recent progress, we identify two shortcomings in current methods: 1) most
approaches perform poorly in cases with low audio-visual semantic
correspondence such as silence, noise, and offscreen sounds, i.e. in the
presence of negative audio; and 2) most prior evaluations are limited to
positive cases, where both datasets and metrics convey scenarios with a single
visible sound source in the scene. To address this, we introduce three key
contributions. First, we propose a new training strategy that incorporates
silence and noise, which improves performance in positive cases, while being
more robust against negative sounds. Our resulting self-supervised model,
SSL-SaN, achieves state-of-the-art performance compared to other
self-supervised models, both in sound localization and cross-modal retrieval.
Second, we propose a new metric that quantifies the trade-off between alignment
and separability of auditory and visual features across positive and negative
audio-visual pairs. Third, we present IS3+, an extended and improved version of
the IS3 synthetic dataset with negative audio.
  Our data, metrics and code are available on the
https://xavijuanola.github.io/SSL-SaN/.

</details>


### [53] [The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning](https://arxiv.org/abs/2508.21816)
*Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin*

Main category: cs.CV

TL;DR: 本文揭示了动词分类的多标签本质，提出SPMLL方法和GE-VerbMLP模型，实验显示其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法将动词分类视为单标签问题，但实证分析表明这种处理方式无法解决视觉事件识别中的固有模糊性。

Method: 提出了Graph Enhanced Verb Multilayer Perceptron（GE-VerbMLP），结合图神经网络捕捉标签相关性和对抗训练优化决策边界。

Result: 在真实数据集上，GE-VerbMLP实现了超过3%的MAP提升，同时在传统top-1和top-5准确率指标上保持竞争力。

Conclusion: 本文通过实证分析揭示了动词分类本质上是一个多标签问题，并提出了一种新的单正多标签学习（SPMLL）方法。设计的GE-VerbMLP模型在真实数据集上表现优异，实现了超过3%的MAP提升，同时在传统指标上保持竞争力。

Abstract: Context recognition (SR) is a fundamental task in computer vision that aims
to extract structured semantic summaries from images by identifying key events
and their associated entities. Specifically, given an input image, the model
must first classify the main visual events (verb classification), then identify
the participating entities and their semantic roles (semantic role labeling),
and finally localize these entities in the image (semantic role localization).
Existing methods treat verb classification as a single-label problem, but we
show through a comprehensive analysis that this formulation fails to address
the inherent ambiguity in visual event recognition, as multiple verb categories
may reasonably describe the same image. This paper makes three key
contributions: First, we reveal through empirical analysis that verb
classification is inherently a multi-label problem due to the ubiquitous
semantic overlap between verb categories. Second, given the impracticality of
fully annotating large-scale datasets with multiple labels, we propose to
reformulate verb classification as a single positive multi-label learning
(SPMLL) problem - a novel perspective in SR research. Third, we design a
comprehensive multi-label evaluation benchmark for SR that is carefully
designed to fairly evaluate model performance in a multi-label setting. To
address the challenges of SPMLL, we futher develop the Graph Enhanced Verb
Multilayer Perceptron (GE-VerbMLP), which combines graph neural networks to
capture label correlations and adversarial training to optimize decision
boundaries. Extensive experiments on real-world datasets show that our approach
achieves more than 3\% MAP improvement while remaining competitive on
traditional top-1 and top-5 accuracy metrics.

</details>


### [54] [UItron: Foundational GUI Agent with Advanced Perception and Planning](https://arxiv.org/abs/2508.21767)
*Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma*

Main category: cs.CV

TL;DR: UItron是一个开源的基础模型，专注于GUI代理的自动化操作，通过系统数据工程和交互基础设施提升性能，特别在中文应用场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: GUI代理的自动化操作对实现通用人工智能至关重要，但现有解决方案在操作轨迹稀缺、交互基础设施不足和基础模型初始能力有限等方面存在挑战。

Method: UItron采用监督微调处理各种GUI场景的感知和规划任务，并开发了一个课程强化学习框架以支持在线环境中的复杂推理和探索。

Result: UItron在GUI感知、基础和规划任务中表现优异，尤其是在中文应用场景中展现出卓越的交互能力。

Conclusion: UItron在GUI感知、基础和规划基准测试中表现出色，特别是在中文移动应用场景中取得了显著进展，推动了GUI代理向实际应用迈进一步。

Abstract: GUI agent aims to enable automated operations on Mobile/PC devices, which is
an important task toward achieving artificial general intelligence. The rapid
advancement of VLMs accelerates the development of GUI agents, owing to their
powerful capabilities in visual understanding and task planning. However,
building a GUI agent remains a challenging task due to the scarcity of
operation trajectories, the availability of interactive infrastructure, and the
limitation of initial capabilities in foundation models. In this work, we
introduce UItron, an open-source foundational model for automatic GUI agents,
featuring advanced GUI perception, grounding, and planning capabilities. UItron
highlights the necessity of systemic data engineering and interactive
infrastructure as foundational components for advancing GUI agent development.
It not only systematically studies a series of data engineering strategies to
enhance training effects, but also establishes an interactive environment
connecting both Mobile and PC devices. In training, UItron adopts supervised
finetuning over perception and planning tasks in various GUI scenarios, and
then develop a curriculum reinforcement learning framework to enable complex
reasoning and exploration for online environments. As a result, UItron achieves
superior performance in benchmarks of GUI perception, grounding, and planning.
In particular, UItron highlights the interaction proficiency with top-tier
Chinese mobile APPs, as we identified a general lack of Chinese capabilities
even in state-of-the-art solutions. To this end, we manually collect over one
million steps of operation trajectories across the top 100 most popular apps,
and build the offline and online agent evaluation environments. Experimental
results demonstrate that UItron achieves significant progress in Chinese app
scenarios, propelling GUI agents one step closer to real-world application.

</details>


### [55] [Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations](https://arxiv.org/abs/2508.21769)
*Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu*

Main category: cs.CV

TL;DR: CLIP-DCA通过增强域感知并解耦域特征，显著提升了CLIP在更具挑战性的OOD数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前领域泛化（DG）评估可能无法充分挑战CLIP等基础模型，因为它们的大规模预训练数据可能覆盖了许多现有基准。为了更真实地评估CLIP在野外DG场景中的性能，需要测试更具挑战性的未见数据。

Method: CLIP-DCA通过使用单独的域头和合成生成的多样域数据来增强域感知，并通过解耦域特征来实现域不变分类。

Result: CLIP-DCA在更具OOD特性的数据集上表现显著优于现有方法。

Conclusion: CLIP-DCA通过增强域感知并同时鼓励域不变分类，显著提升了CLIP在更具挑战性的OOD数据集上的性能。

Abstract: Evaluating domain generalization (DG) for foundational models like CLIP is
challenging, as web-scale pretraining data potentially covers many existing
benchmarks. Consequently, current DG evaluation may neither be sufficiently
challenging nor adequately test genuinely unseen data scenarios. To better
assess the performance of CLIP on DG in-the-wild, a scenario where CLIP
encounters challenging unseen data, we consider two approaches: (1) evaluating
on 33 diverse datasets with quantified out-of-distribution (OOD) scores after
fine-tuning CLIP on ImageNet, and (2) using unlearning to make CLIP `forget'
some domains as an approximation. We observe that CLIP's performance
deteriorates significantly on more OOD datasets. To address this, we present
CLIP-DCA (Disentangling Classification from enhanced domain Aware
representations). Our approach is motivated by the observation that while
standard domain invariance losses aim to make representations domain-invariant,
this can be harmful to foundation models by forcing the discarding of
domain-aware representations beneficial for generalization. We instead
hypothesize that enhancing domain awareness is a prerequisite for effective
domain-invariant classification in foundation models. CLIP-DCA identifies and
enhances domain awareness within CLIP's encoders using a separate domain head
and synthetically generated diverse domain data. Simultaneously, it encourages
domain-invariant classification through disentanglement from the domain
features. CLIP-DCA shows significant improvements within this challenging
evaluation compared to existing methods, particularly on datasets that are more
OOD.

</details>


### [56] [What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos](https://arxiv.org/abs/2508.21770)
*Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao*

Main category: cs.CV

TL;DR: 研究发现非典型视频数据在开放世界学习中能显著提升模型性能，特别是在OOD检测、NCD和ZSAR任务中。


<details>
  <summary>Details</summary>
Motivation: 探索非典型视频在开放世界学习中的潜在价值，特别是在OOD检测、NCD和ZSAR任务中。

Method: 收集了一个包含各种非典型视频的新数据集，并将其用于模型训练过程中的表示学习。

Result: 实验结果表明，即使是简单的学习方法，使用非典型数据也能在不同任务中显著提升性能。

Conclusion: 本文揭示了非典型视频在开放世界视觉表示学习中的益处，并提出了新的数据集，鼓励未来在此方向的研究。

Abstract: Humans usually show exceptional generalisation and discovery ability in the
open world, when being shown uncommon new concepts. Whereas most existing
studies in the literature focus on common typical data from closed sets,
open-world novel discovery is under-explored in videos. In this paper, we are
interested in asking: \textit{What if atypical unusual videos are exposed in
the learning process?} To this end, we collect a new video dataset consisting
of various types of unusual atypical data (\eg sci-fi, animation, \etc). To
study how such atypical data may benefit open-world learning, we feed them into
the model training process for representation learning. Focusing on three key
tasks in open-world learning: out-of-distribution (OOD) detection, novel
category discovery (NCD), and zero-shot action recognition (ZSAR), we found
that even straightforward learning approaches with atypical data consistently
improve performance across various settings. Furthermore, we found that
increasing the categorical diversity of the atypical samples further boosts OOD
detection performance. Additionally, in the NCD task, using a smaller yet more
semantically diverse set of atypical samples leads to better performance
compared to using a larger but more typical dataset. In the ZSAR setting, the
semantic diversity of atypical videos helps the model generalise better to
unseen action classes. These observations in our extensive experimental
evaluations reveal the benefits of atypical videos for visual representation
learning in the open world, together with the newly proposed dataset,
encouraging further studies in this direction.

</details>


### [57] [A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI](https://arxiv.org/abs/2508.21775)
*Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein*

Main category: cs.CV

TL;DR: 本文提出了一种基于nnU-Net的多阶段预训练和定制集成策略，显著提升了PDAC MRI分割性能，尤其在有限数据条件下。


<details>
  <summary>Details</summary>
Motivation: 解决胰腺导管腺癌（PDAC）MRI自动分割中肿瘤组织对比度差和标注数据稀缺的问题。

Method: 采用nnU-Net框架，结合深度多阶段级联预训练策略，从通用解剖基础模型开始，逐步微调CT胰腺病变数据集和目标MRI模态。通过五折交叉验证评估数据增强方案和训练计划。

Result: 在Task 1中实现了体积准确性和边界精度的最佳平衡（MASD为5.46 mm，HD95为17.33 mm），并在Task 1和Task 2中分别获得了0.661和0.523的顶级交叉验证肿瘤Dice分数。

Conclusion: 本文提出了一种基于nnU-Net框架的多阶段级联预训练策略，并通过定制异构专家模型集成，在有限数据和复杂医学影像任务中实现了高性能。

Abstract: Automated segmentation of Pancreatic Ductal Adenocarcinoma (PDAC) from MRI is
critical for clinical workflows but is hindered by poor tumor-tissue contrast
and a scarcity of annotated data. This paper details our submission to the
PANTHER challenge, addressing both diagnostic T1-weighted (Task 1) and
therapeutic T2-weighted (Task 2) segmentation. Our approach is built upon the
nnU-Net framework and leverages a deep, multi-stage cascaded pre-training
strategy, starting from a general anatomical foundation model and sequentially
fine-tuning on CT pancreatic lesion datasets and the target MRI modalities.
Through extensive five-fold cross-validation, we systematically evaluated data
augmentation schemes and training schedules. Our analysis revealed a critical
trade-off, where aggressive data augmentation produced the highest volumetric
accuracy, while default augmentations yielded superior boundary precision
(achieving a state-of-the-art MASD of 5.46 mm and HD95 of 17.33 mm for Task 1).
For our final submission, we exploited this finding by constructing custom,
heterogeneous ensembles of specialist models, essentially creating a mix of
experts. This metric-aware ensembling strategy proved highly effective,
achieving a top cross-validation Tumor Dice score of 0.661 for Task 1 and 0.523
for Task 2. Our work presents a robust methodology for developing specialized,
high-performance models in the context of limited data and complex medical
imaging tasks (Team MIC-DKFZ).

</details>


### [58] [VoCap: Video Object Captioning and Segmentation from Any Prompt](https://arxiv.org/abs/2508.21809)
*Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid*

Main category: cs.CV

TL;DR: VoCap模型通过多模态提示生成视频对象掩码和字幕，利用伪字幕标注数据集，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视频中对象的细粒度定位掩码和详细语义属性理解任务，同时应对提示性视频对象分割、参考表达式分割和对象字幕生成。

Method: 提出VoCap模型，通过多模态提示（文本、框或掩码）生成时空掩码和对象中心字幕，并利用伪对象字幕标注SAV数据集。

Result: 在参考表达式视频对象分割任务中取得最先进结果，在半监督视频对象分割中具有竞争力，并为视频对象字幕生成建立了基准。

Conclusion: VoCap模型在视频对象分割和字幕生成任务中表现出色，并在SAV-Caption数据集上取得了最先进的结果。

Abstract: Understanding objects in videos in terms of fine-grained localization masks
and detailed semantic properties is a fundamental task in video understanding.
In this paper, we propose VoCap, a flexible video model that consumes a video
and a prompt of various modalities (text, box or mask), and produces a
spatio-temporal masklet with a corresponding object-centric caption. As such
our model addresses simultaneously the tasks of promptable video object
segmentation, referring expression segmentation, and object captioning. Since
obtaining data for this task is tedious and expensive, we propose to annotate
an existing large-scale segmentation dataset (SAV) with pseudo object captions.
We do so by preprocessing videos with their ground-truth masks to highlight the
object of interest and feed this to a large Vision Language Model (VLM). For an
unbiased evaluation, we collect manual annotations on the validation set. We
call the resulting dataset SAV-Caption. We train our VoCap model at scale on a
SAV-Caption together with a mix of other image and video datasets. Our model
yields state-of-the-art results on referring expression video object
segmentation, is competitive on semi-supervised video object segmentation, and
establishes a benchmark for video object captioning. Our dataset will be made
available at https://github.com/google-deepmind/vocap.

</details>


### [59] [DriveQA: Passing the Driving Knowledge Test](https://arxiv.org/abs/2508.21824)
*Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar*

Main category: cs.CV

TL;DR: DriveQA基准测试揭示了LLMs和MLLMs在驾驶知识测试中的局限性，通过微调和预训练可显著提升性能，特别是在交通标志识别和复杂场景决策方面。


<details>
  <summary>Details</summary>
Motivation: 探讨当前大型语言模型和多模态语言模型是否具备通过驾驶知识测试的能力，以及如何通过特定基准测试提升其性能。

Method: 通过DriveQA和DriveQA-V基准测试，评估了LLMs和MLLMs在交通规则、交通标志、空间布局等方面的理解能力，并进行了微调和预训练实验。

Result: 实验表明，现有模型在基本交通规则上表现良好，但在数值推理、复杂优先权场景和交通标志变体等方面存在显著弱点。通过DriveQA的微调和预训练，模型在多个类别上的准确性得到提升，特别是在交通标志识别和交叉口决策方面。

Conclusion: DriveQA作为一个全面的开源基准测试，不仅揭示了当前LLMs和MLLMs在驾驶知识测试中的局限性，还展示了通过微调和预训练可以显著提升模型在交通规则理解和复杂场景决策中的表现。

Abstract: If a Large Language Model (LLM) were to take a driving knowledge test today,
would it pass? Beyond standard spatial and visual question-answering (QA) tasks
on current autonomous driving benchmarks, driving knowledge tests require a
complete understanding of all traffic rules, signage, and right-of-way
principles. To pass this test, human drivers must discern various edge cases
that rarely appear in real-world datasets. In this work, we present DriveQA, an
extensive open-source text and vision-based benchmark that exhaustively covers
traffic regulations and scenarios. Through our experiments using DriveQA, we
show that (1) state-of-the-art LLMs and Multimodal LLMs (MLLMs) perform well on
basic traffic rules but exhibit significant weaknesses in numerical reasoning
and complex right-of-way scenarios, traffic sign variations, and spatial
layouts, (2) fine-tuning on DriveQA improves accuracy across multiple
categories, particularly in regulatory sign recognition and intersection
decision-making, (3) controlled variations in DriveQA-V provide insights into
model sensitivity to environmental factors such as lighting, perspective,
distance, and weather conditions, and (4) pretraining on DriveQA enhances
downstream driving task performance, leading to improved results on real-world
datasets such as nuScenes and BDD, while also demonstrating that models can
internalize text and synthetic traffic knowledge to generalize effectively
across downstream QA tasks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [60] [Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding](https://arxiv.org/abs/2508.21204)
*Vanessa Figueiredo*

Main category: cs.AI

TL;DR: 研究通过符号支架和短期记忆机制提升LLMs在苏格拉底式辅导中的结构化推理能力，实验证明架构性支架能有效塑造其教学策略。


<details>
  <summary>Details</summary>
Motivation: 探讨架构性归纳偏差如何影响大型语言模型（LLMs）在指导性对话中的认知行为。

Method: 通过五种系统变体的对照消融实验，使用专家设计的评分标准评估模型输出，包括支架、响应性、符号推理和对话记忆。

Result: 完整系统在初步结果中始终优于基线变体。移除记忆或符号结构会削弱关键认知行为，如抽象、适应性探测和概念连续性。

Conclusion: 研究结果表明，架构性支架能够可靠地塑造大型语言模型（LLMs）中涌现的教学策略，支持处理层面的解释。

Abstract: We study how architectural inductive biases influence the cognitive behavior
of large language models (LLMs) in instructional dialogue. We introduce a
symbolic scaffolding mechanism paired with a short-term memory schema designed
to promote adaptive, structured reasoning in Socratic tutoring. Using
controlled ablation across five system variants, we evaluate model outputs via
expert-designed rubrics covering scaffolding, responsiveness, symbolic
reasoning, and conversational memory. We present preliminary results using an
LLM-based evaluation framework aligned to a cognitively grounded rubric. This
enables scalable, systematic comparisons across architectural variants in
early-stage experimentation. The preliminary results show that our full system
consistently outperforms baseline variants. Analysis reveals that removing
memory or symbolic structure degrades key cognitive behaviors, including
abstraction, adaptive probing, and conceptual continuity. These findings
support a processing-level account in which architectural scaffolds can
reliably shape emergent instructional strategies in LLMs.

</details>


### [61] [Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs](https://arxiv.org/abs/2508.21238)
*Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman*

Main category: cs.AI

TL;DR: GraphRAG通过整合领域知识提升LLM回答质量，尤其在阿尔茨海默病领域表现优于标准模型。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在科学研究中应用时存在的幻觉、领域知识不足和回答不可追溯等问题。

Method: 研究通过构建一个包含50篇论文和70个专家问题的阿尔茨海默病数据库，使用GraphRAG知识库和GPT-4o模型生成回答，并对比标准GPT-4o模型的回答质量。

Result: GraphRAG在回答质量和可追溯性方面优于标准GPT-4o模型。

Conclusion: GraphRAG展示了在特定领域（如阿尔茨海默病）中提升LLM回答质量和可追溯性的潜力，为研究者提供了一个易于使用的测试平台。

Abstract: In the past two years, large language model (LLM)-based chatbots, such as
ChatGPT, have revolutionized various domains by enabling diverse task
completion and question-answering capabilities. However, their application in
scientific research remains constrained by challenges such as hallucinations,
limited domain-specific knowledge, and lack of explainability or traceability
for the response. Graph-based Retrieval-Augmented Generation (GraphRAG) has
emerged as a promising approach to improving chatbot reliability by integrating
domain-specific contextual information before response generation, addressing
some limitations of standard LLMs. Despite its potential, there are only
limited studies that evaluate GraphRAG on specific domains that require
intensive knowledge, like Alzheimer's disease or other biomedical domains. In
this paper, we assess the quality and traceability of two popular GraphRAG
systems. We compile a database of 50 papers and 70 expert questions related to
Alzheimer's disease, construct a GraphRAG knowledge base, and employ GPT-4o as
the LLM for answering queries. We then compare the quality of responses
generated by GraphRAG with those from a standard GPT-4o model. Additionally, we
discuss and evaluate the traceability of several Retrieval-Augmented Generation
(RAG) and GraphRAG systems. Finally, we provide an easy-to-use interface with a
pre-built Alzheimer's disease database for researchers to test the performance
of both standard RAG and GraphRAG.

</details>


### [62] [MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems](https://arxiv.org/abs/2508.21307)
*Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala*

Main category: cs.AI

TL;DR: MultiFluxAI是一个利用生成式AI等技术管理异构数据源的AI平台，旨在提升用户参与度。


<details>
  <summary>Details</summary>
Motivation: 解决产品工程中管理异构数据源的挑战，并增强用户在数字生态系统中的参与度。

Method: 利用生成式AI、向量化和代理编排等先进AI技术，提供动态且上下文感知的响应。

Result: 开发了MultiFluxAI平台，能够动态响应复杂用户查询。

Conclusion: MultiFluxAI通过先进的AI技术解决了产品工程中管理异构数据源的挑战，提升了用户在数字生态系统中的参与度。

Abstract: MultiFluxAI is an innovative AI platform developed to address the challenges
of managing and integrating vast, disparate data sources in product engineering
across application domains. It addresses both current and new service related
queries that enhance user engagement in the digital ecosystem. This platform
leverages advanced AI techniques, such as Generative AI, vectorization, and
agentic orchestration to provide dynamic and context-aware responses to complex
user queries.

</details>


### [63] [Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation](https://arxiv.org/abs/2508.21320)
*Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao*

Main category: cs.AI

TL;DR: LINKO是一个LLM增强的多本体学习框架，通过双轴知识传播提升医学概念表示学习，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多局限于单一或多本体系统的孤立学习，缺乏跨本体连接的统一学习结构。LINKO旨在通过整合多本体系统和双轴知识传播，弥补这一不足。

Method: LINKO采用LLM增强的初始化方法，通过工程化提示（包括概念描述和本体上下文）生成概念嵌入。随后，通过双轴知识传播（垂直和水平）在多本体系统中联合学习医学概念。

Result: 实验验证了LINKO在公共数据集上的优越性能，尤其在数据有限和罕见疾病预测场景中表现突出。

Conclusion: LINKO通过整合多本体系统并利用双轴知识传播，显著提升了医学概念表示学习的效果，尤其在数据有限和罕见疾病预测场景中表现出更强的鲁棒性。

Abstract: Medical ontology graphs map external knowledge to medical codes in electronic
health records via structured relationships. By leveraging domain-approved
connections (e.g., parent-child), predictive models can generate richer medical
concept representations by incorporating contextual information from related
concepts. However, existing literature primarily focuses on incorporating
domain knowledge from a single ontology system, or from multiple ontology
systems (e.g., diseases, drugs, and procedures) in isolation, without
integrating them into a unified learning structure. Consequently, concept
representation learning often remains limited to intra-ontology relationships,
overlooking cross-ontology connections. In this paper, we propose LINKO, a
large language model (LLM)-augmented integrative ontology learning framework
that leverages multiple ontology graphs simultaneously by enabling dual-axis
knowledge propagation both within and across heterogeneous ontology systems to
enhance medical concept representation learning. Specifically, LINKO first
employs LLMs to provide a graph-retrieval-augmented initialization for ontology
concept embedding, through an engineered prompt that includes concept
descriptions, and is further augmented with ontology context. Second, our
method jointly learns the medical concepts in diverse ontology graphs by
performing knowledge propagation in two axes: (1) intra-ontology vertical
propagation across hierarchical ontology levels and (2) inter-ontology
horizontal propagation within every level in parallel. Last, through extensive
experiments on two public datasets, we validate the superior performance of
LINKO over state-of-the-art baselines. As a plug-in encoder compatible with
existing EHR predictive models, LINKO further demonstrates enhanced robustness
in scenarios involving limited data availability and rare disease prediction.

</details>


### [64] [Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models](https://arxiv.org/abs/2508.21365)
*Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang*

Main category: cs.AI

TL;DR: TiG框架通过语言建模任务将LLMs与游戏环境交互，弥合了陈述性知识与程序性知识的差距，降低了数据需求并提高了决策透明性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在复杂推理任务中表现出色，但在简单交互任务中表现不佳，突显了陈述性知识与程序性知识之间的差距。传统强化学习（RL）方法虽能获取程序性知识，但需要大量数据且缺乏透明性。

Method: TiG将基于强化学习的决策重新表述为语言建模任务，通过语言引导的策略生成，并基于环境反馈进行迭代优化。

Result: 实验结果表明，TiG在保持低数据和计算需求的同时，实现了与常规RL方法竞争的性能，并通过自然语言解释提高了决策的透明性。

Conclusion: TiG框架成功弥合了陈述性知识与程序性知识之间的差距，显著降低了数据需求和计算成本，同时通过自然语言解释提高了决策的透明度和可解释性。

Abstract: Large language models (LLMs) excel at complex reasoning tasks such as
mathematics and coding, yet they frequently struggle with simple interactive
tasks that young children perform effortlessly. This discrepancy highlights a
critical gap between declarative knowledge (knowing about something) and
procedural knowledge (knowing how to do something). Although traditional
reinforcement learning (RL) agents can acquire procedural knowledge through
environmental interaction, they often operate as black boxes and require
substantial training data. In contrast, LLMs possess extensive world knowledge
and reasoning capabilities, but are unable to effectively convert this static
knowledge into dynamic decision-making in interactive settings. To address this
challenge, we propose Think in Games (TiG), a novel framework that empowers
LLMs to develop procedural understanding through direct interaction with game
environments, while retaining their inherent reasoning and explanatory
abilities. Specifically, TiG reformulates RL-based decision-making as a
language modeling task: LLMs generate language-guided policies, which are
refined iteratively through online reinforcement learning based on
environmental feedback. Our experimental results show that TiG successfully
bridges the gap between declarative and procedural knowledge, achieving
competitive performance with dramatically lower data and computational demands
compared to conventional RL methods. Moreover, TiG provides step-by-step
natural language explanations for its decisions, greatly improving transparency
and interpretability in complex interactive tasks.

</details>


### [65] [AHELM: A Holistic Evaluation of Audio-Language Models](https://arxiv.org/abs/2508.21376)
*Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang*

Main category: cs.AI

TL;DR: AHELM 是一个新的 ALMs 基准测试，全面评估 10 个关键方面，发现 Gemini 2.5 Pro 表现最佳但存在公平性问题，基准系统表现意外良好。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化的 ALMs 评估基准，且现有基准多限于少数能力或忽略公平性、安全性等重要方面。AHELM 旨在填补这一空白。

Method: AHELM 通过聚合多个数据集（包括新合成的 PARADE 和 CoRe-Bench）并标准化提示、推理参数和评估指标，实现对 ALMs 的全面评估。

Result: Gemini 2.5 Pro 在 10 个方面中的 5 个表现最佳，但存在群体不公平问题（p=0.01）。基准系统表现良好，其中一个排名第五。所有数据公开以促进透明度。

Conclusion: AHELM 是一个综合性基准测试，旨在全面评估音频-语言模型（ALMs）的多个重要方面，包括公平性、安全性等。尽管 Gemini 2.5 Pro 在多个方面表现最佳，但仍存在群体不公平问题。基准系统表现良好，显示了其潜力。

Abstract: Evaluations of audio-language models (ALMs) -- multimodal models that take
interleaved audio and text as input and output text -- are hindered by the lack
of standardized benchmarks; most benchmarks measure only one or two
capabilities and omit evaluative aspects such as fairness or safety.
Furthermore, comparison across models is difficult as separate evaluations test
a limited number of models and use different prompting methods and inference
parameters. To address these shortfalls, we introduce AHELM, a benchmark that
aggregates various datasets -- including 2 new synthetic audio-text datasets
called PARADE, which evaluates the ALMs on avoiding stereotypes, and
CoRe-Bench, which measures reasoning over conversational audio through
inferential multi-turn question answering -- to holistically measure the
performance of ALMs across 10 aspects we have identified as important to the
development and usage of ALMs: audio perception, knowledge, reasoning, emotion
detection, bias, fairness, multilinguality, robustness, toxicity, and safety.
We also standardize the prompts, inference parameters, and evaluation metrics
to ensure equitable comparisons across models. We test 14 open-weight and
closed-API ALMs from 3 developers and 3 additional simple baseline systems each
consisting of an automatic speech recognizer and a language model. Our results
show that while Gemini 2.5 Pro ranks top in 5 out of 10 aspects, it exhibits
group unfairness ($p=0.01$) on ASR tasks whereas most of the other models do
not. We also find that the baseline systems perform reasonably well on AHELM,
with one ranking 5th overall despite having only speech-to-text capabilities.
For transparency, all raw prompts, model generations, and outputs are available
on our website at https://crfm.stanford.edu/helm/audio/v1.0.0. AHELM is
intended to be a living benchmark and new datasets and models will be added
over time.

</details>


### [66] [AI Compute Architecture and Evolution Trends](https://arxiv.org/abs/2508.21394)
*Bor-Sung Liang*

Main category: cs.AI

TL;DR: 本文提出七层AI计算架构模型，分析各层技术演变与挑战，并预测AI未来发展，涵盖技术到经济层面。


<details>
  <summary>Details</summary>
Motivation: AI发展从学术研究转向实际应用，面临多层面挑战，需系统分析其机遇与挑战。

Method: 采用结构化方法，提出七层模型（物理层、链路层、神经网络层、上下文层、代理层、编排层和应用层），并分阶段分析大语言模型（LLMs）的演变。

Result: 详细描述了每层的发展轨迹与关键技术，探讨了Scale-Up/Scale-Out策略、LLMs发展路径、上下文记忆、AI代理趋势及生态问题，并预测了AI未来轨迹。

Conclusion: 本文通过七层模型分析了AI计算的架构演变，并探讨了从技术到经济层面的挑战与机遇，为AI未来发展提供了预测和见解。

Abstract: The focus of AI development has shifted from academic research to practical
applications. However, AI development faces numerous challenges at various
levels. This article will attempt to analyze the opportunities and challenges
of AI from several different perspectives using a structured approach. This
article proposes a seven-layer model for AI compute architecture, including
Physical Layer, Link Layer, Neural Network Layer, Context Layer, Agent Layer,
Orchestrator Layer, and Application Layer, from bottom to top. It also explains
how AI computing has evolved into this 7-layer architecture through the
three-stage evolution on large-scale language models (LLMs). For each layer, we
describe the development trajectory and key technologies. In Layers 1 and 2 we
discuss AI computing issues and the impact of Scale-Up and Scale-Out strategies
on computing architecture. In Layer 3 we explore two different development
paths for LLMs. In Layer 4 we discuss the impact of contextual memory on LLMs
and compares it to traditional processor memory. In Layers 5 to 7 we discuss
the trends of AI agents and explore the issues in evolution from a single AI
agent to an AI-based ecosystem, and their impact on the AI industry.
Furthermore, AI development involves not only technical challenges but also the
economic issues to build self-sustainable ecosystem. This article analyzes the
internet industry to provide predictions on the future trajectory of AI
development.

</details>


### [67] [CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN](https://arxiv.org/abs/2508.21411)
*Leonard Frank Neis,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: CARJAN是一个基于AJAN和CARLA的工具，用于半自动化生成和模拟包含多种交互代理的交通场景，通过可视化界面和SPARQL行为树实现智能决策。


<details>
  <summary>Details</summary>
Motivation: 城市交通场景中不同类型交互代理的建模和虚拟仿真仍具挑战性。

Method: 基于多代理工程框架AJAN和驾驶模拟器CARLA，CARJAN通过可视化用户界面建模、存储和维护交通场景布局，并利用基于SPARQL行为树的决策制定和交互来实现动态场景模拟。

Result: CARJAN成功实现了半自动化的交通场景生成和模拟，支持智能代理的交互式仿真。

Conclusion: CARJAN提供了一个集成方法，用于在CARLA中交互式、智能地生成和模拟虚拟交通场景，解决了不同类型交互代理（如行人、骑行者、自动驾驶车辆）的建模和仿真挑战。

Abstract: User-friendly modeling and virtual simulation of urban traffic scenarios with
different types of interacting agents such as pedestrians, cyclists and
autonomous vehicles remains a challenge. We present CARJAN, a novel tool for
semi-automated generation and simulation of such scenarios based on the
multi-agent engineering framework AJAN and the driving simulator CARLA. CARJAN
provides a visual user interface for the modeling, storage and maintenance of
traffic scenario layouts, and leverages SPARQL Behavior Tree-based
decision-making and interactions for agents in dynamic scenario simulations in
CARLA. CARJAN provides a first integrated approach for interactive, intelligent
agent-based generation and simulation of virtual traffic scenarios in CARLA.

</details>


### [68] [A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions](https://arxiv.org/abs/2508.21441)
*Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald*

Main category: cs.AI

TL;DR: 本文从认知角度研究遗忘操作，提出五种通用类型和七种具体操作，并通过公理体系评估，为遗忘算子提供新视角。


<details>
  <summary>Details</summary>
Motivation: 探索遗忘在认知背景下的含义，将已知和新颖的遗忘操作提升到认知层面，以填补现有文献中的空白。

Method: 采用认知视角，研究具有丰富语义结构但明确链接到命题逻辑的认知状态中的遗忘操作，提出并实例化五种通用类型和七种具体遗忘操作。

Result: 提出了五种通用类型的认知遗忘操作，并实例化为七种具体操作，通过公理体系评估这些操作，提供了全面的比较和总结。

Conclusion: 本文通过研究认知状态中的遗忘操作，提出了五种通用类型和七种具体操作，并通过丰富的公理体系评估这些操作，为遗忘算子提供了全面的新视角。

Abstract: Forgetting as a knowledge management operation deliberately ignores parts of
the knowledge and beliefs of an agent, for various reasons. Forgetting has many
facets, one may want to forget parts of the syntax, a proposition, or a
conditional. In the literature, two main operators suitable for performing
forgetting have been proposed and investigated in depth: First, variable
elimination is a syntactical method that blends out certain atomic variables to
focus on the rest of the language. It has been mainly used in the area of logic
programming and answer set programming. Second, contraction in AGM belief
revision theory effectively removes propositions from belief sets under logical
deduction. Both operations rely mainly on classical logics. In this article, we
take an epistemic perspective and study forgetting operations in epistemic
states with richer semantic structures, but with clear links to propositional
logic. This allows us to investigate what forgetting in the epistemic
background means, thereby lifting well-known and novel forgetting operations to
the epistemic level. We present five general types of epistemic forgetting and
instantiate them with seven concrete forgetting operations for Spohn's ranking
functions. We take inspiration from postulates of forgetting both from logic
programming and AGM theory to propose a rich landscape of axioms for evaluating
forgetting operations. Finally, we evaluate all concrete forgetting operations
according to all postulates, leading to a novel comprehensive overview
highlighting differences and commonalities among the forgetting operators.

</details>


### [69] [Learning Lifted Action Models From Traces of Incomplete Actions and States](https://arxiv.org/abs/2508.21449)
*Niklas Jansen,Jonas Gösgens,Hector Geffner*

Main category: cs.AI

TL;DR: 本文提出STRIPS+和SYNTH算法，用于在部分可观察状态下学习STRIPS模型，验证了其正确性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决在部分可观察状态（如缺少空白位置信息）和动作（如缺少完整参数）的情况下学习STRIPS模型的挑战。

Method: 引入STRIPS+变体，允许动作参数在前提条件中隐式存在，并提出SYNTH算法，通过构造分层的预处理表达式序列来学习STRIPS+模型。

Result: SYNTH算法能够正确且高效地从STRIPS+状态-动作轨迹中学习模型，并在现有STRIPS领域上验证了其可扩展性。

Conclusion: 本文提出了一种名为STRIPS+的变体，用于解决在部分可观察状态下学习STRIPS模型的问题，并开发了SYNTH算法来学习这种模型。实验验证了SYNTH的正确性和可扩展性。

Abstract: Consider the problem of learning a lifted STRIPS model of the sliding-tile
puzzle from random state-action traces where the states represent the location
of the tiles only, and the actions are the labels up, down, left, and right,
with no arguments. Two challenges are involved in this problem. First, the
states are not full STRIPS states, as some predicates are missing, like the
atoms representing the position of the ``blank''. Second, the actions are not
full STRIPS either, as they do not reveal all the objects involved in the
actions effects and preconditions. Previous approaches have addressed different
versions of this model learning problem, but most assume that actions in the
traces are full STRIPS actions or that the domain predicates are all
observable. The new setting considered in this work is more ``realistic'', as
the atoms observed convey the state of the world but not full STRIPS states,
and the actions reveal the arguments needed for selecting the action but not
the ones needed for modeling it in STRIPS. For formulating and addressing the
learning problem, we introduce a variant of STRIPS, which we call STRIPS+,
where certain STRIPS action arguments can be left implicit in preconditions
which can also involve a limited form of existential quantification. The
learning problem becomes the problem of learning STRIPS+ models from STRIPS+
state-action traces. For this, the proposed learning algorithm, called SYNTH,
constructs a stratified sequence (conjunction) of precondition expressions or
``queries'' for each action, that denote unique objects in the state and ground
the implicit action arguments in STRIPS+. The correctness and completeness of
SYNTH is established, and its scalability is tested on state-action traces
obtained from STRIPS+ models derived from existing STRIPS domains.

</details>


### [70] [MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents](https://arxiv.org/abs/2508.21475)
*Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong*

Main category: cs.AI

TL;DR: MMSearch-Plus是一个多模态理解基准，揭示了当前模型在视觉推理和长时程任务上的不足，最强模型准确率仅36%。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态浏览基准大多可以通过浅层、固定的工作流程解决，掩盖了真正的多模态挑战。

Method: 通过空间-时间外推法（Spatial-Temporal Extrapolation）构建任务，要求模型从空间线索（微文本、局部外观、布局、标志）和时间痕迹（广播覆盖、季节背景）中推断出图像外的事实（如事件、日期、地点）。

Result: 最强模型（o3）在无搜索时准确率为15.1%，在框架下展开搜索后提升至36.0%；开源模型（Qwen-2.5-VL-72B-Instruct）无搜索时准确率为0.0%，20轮搜索后为6.9%。

Conclusion: MMSearch-Plus是一个强调多模态理解的基准测试，揭示了当前多模态语言模型在细粒度视觉推理、来源验证和长时程工具使用方面的不足。

Abstract: Large multimodal language models (MLLMs) are increasingly deployed as web
agents, yet many multimodal browsing benchmarks can be solved by shallow, fixed
workflows that lean on high-recall image search and nearby text-masking the
genuinely multimodal challenges of fine-grained visual reasoning, provenance
verification, and long-horizon tool use. We introduce MMSearch-Plus, a
benchmark of 311 tasks that highly demand multimodal understanding while
preserving the difficulty profile of strong text-only browsing suites. Each
item is constructed to contain multiple weak, localized visual signals that
must be extracted, propagated through iterative text-image search, and
cross-validated under retrieval noise before answering. Our curation procedure,
Spatial-Temporal Extrapolation, seeds questions whose answers require
extrapolating from spatial cues (micro-text, part-level appearance, layouts,
signage) and temporal traces (broadcast overlays, seasonal context) to
out-of-image facts such as events, dates, and venues. We provide a
model-agnostic agent framework with browsing tools and evaluate a range of
closed and open MLLMs. The strongest agent (o3) attains 15.1% without search
and 36.0% accuracy with rollout under our framework, while a strong open-source
model (Qwen-2.5-VL-72B-Instruct) achieves 0.0% without search and 6.9% after 20
rounds of search. Beyond answer accuracy, we assess bounding-box production and
cropped-image search, and conduct an error analysis that surfaces failures in
source verification, part-based reasoning, and long-horizon planning.

</details>


### [71] [Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis](https://arxiv.org/abs/2508.21517)
*Sweta Kaman,Ankita Sharma,Romi Banerjee*

Main category: cs.AI

TL;DR: 研究提出了一种基于模糊推理系统和Z数的智慧测量方法，能更好地反映智慧的多维性和不确定性，适用于心理学和AI领域。


<details>
  <summary>Details</summary>
Motivation: 当前智慧测量依赖自报告，缺乏反映智慧推理中固有谦逊和不确定性的方法，需要一个考虑多维性和信心的计算框架来改进心理科学并实现人性化AI。

Method: 研究使用模糊推理系统结合Z数（智慧分数和信心分数），通过21条规则和基于高斯核密度估计的隶属函数调谐，对100名参与者在文化中性图画道德困境任务中的语言反应进行映射和分析。

Result: 概念验证研究中，系统产生的双属性智慧表征与现有量表有适度但显著的相关性，与无关特质关系可忽略，支持了收敛和发散效度。

Conclusion: 该研究通过模糊推理系统和Z数形式化智慧为一个多维、不确定性感知的建构，为心理学测量和AI系统提供了可解释、信心敏感的推理方法。

Abstract: Background: Wisdom is a superordinate construct that embraces perspective
taking, reflectiveness, prosocial orientation, reflective empathetic action,
and intellectual humility. Unlike conventional models of reasoning that are
rigidly bound by binary thinking, wisdom unfolds in shades of ambiguity,
requiring both graded evaluation and self-reflective humility. Current measures
depend on self-reports and seldom reflect the humility and uncertainty inherent
in wise reasoning. A computational framework that takes into account both
multidimensionality and confidence has the potential to improve psychological
science and allow humane AI. Method: We present a fuzzy inference system with Z
numbers, each of the decisions being expressed in terms of a wisdom score
(restriction) and confidence score (certainty). As part of this study,
participants (N = 100) were exposed to culturally neutral pictorial moral
dilemma tasks to which they generated think-aloud linguistic responses, which
were mapped into five theoretically based components of wisdom. The scores of
each individual component were combined using a base of 21 rules, with
membership functions tuned via Gaussian kernel density estimation. Results: In
a proof of concept study, the system produced dual attribute wisdom
representations that correlated modestly but significantly with established
scales while showing negligible relations with unrelated traits, supporting
convergent and divergent validity. Contribution: The contribution is to
formalize wisdom as a multidimensional, uncertainty-conscious construct,
operationalized in the form of Z-numbers. In addition to progressing
measurement in psychology, it calculates how fuzzy Z numbers can provide AI
systems with interpretable, confidence-sensitive reasoning that affords a safe,
middle ground between rigorous computation and human-like judgment.

</details>


### [72] [Counterfactual Scenarios for Automated Planning](https://arxiv.org/abs/2508.21521)
*Nicola Gigante,Francesco Leofante,Andrea Micheli*

Main category: cs.AI

TL;DR: 本文提出了一种基于反事实场景的新解释方法，用于识别规划问题的最小修改以生成符合特定性质的计划，并证明其计算可行性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有的反事实解释（CEs）虽然有助于诊断故障和推理计划特性，但未能捕捉问题的更高层次特性，因此需要一种新的解释范式来弥补这一不足。

Method: 提出了两种基于明确量化必须满足特定性质计划的定性反事实场景实例，并分析了允许对规划问题进行不同类型修改时的计算复杂性。

Result: 研究表明，生成反事实场景的计算成本通常与为规划问题计算一个计划相当，验证了该方法的实际可行性。

Conclusion: 本文提出了一种基于反事实场景的新解释范式，能够识别对规划问题的最小修改，从而生成符合特定性质的计划，并展示了其计算复杂性和实际可行性。

Abstract: Counterfactual Explanations (CEs) are a powerful technique used to explain
Machine Learning models by showing how the input to a model should be minimally
changed for the model to produce a different output. Similar proposals have
been made in the context of Automated Planning, where CEs have been
characterised in terms of minimal modifications to an existing plan that would
result in the satisfaction of a different goal. While such explanations may
help diagnose faults and reason about the characteristics of a plan, they fail
to capture higher-level properties of the problem being solved. To address this
limitation, we propose a novel explanation paradigm that is based on
counterfactual scenarios. In particular, given a planning problem $P$ and an
\ltlf formula $\psi$ defining desired properties of a plan, counterfactual
scenarios identify minimal modifications to $P$ such that it admits plans that
comply with $\psi$. In this paper, we present two qualitative instantiations of
counterfactual scenarios based on an explicit quantification over plans that
must satisfy $\psi$. We then characterise the computational complexity of
generating such counterfactual scenarios when different types of changes are
allowed on $P$. We show that producing counterfactual scenarios is often only
as expensive as computing a plan for $P$, thus demonstrating the practical
viability of our proposal and ultimately providing a framework to construct
practical algorithms in this area.

</details>


### [73] [HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining](https://arxiv.org/abs/2508.21540)
*Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi*

Main category: cs.AI

TL;DR: HealthProcessAI框架结合LLM模型，简化医疗流程挖掘应用，提升可访问性，验证显示高性能和实用价值。


<details>
  <summary>Details</summary>
Motivation: 流程挖掘在医疗领域的应用面临技术复杂性、缺乏标准化方法和培训资源有限等障碍，亟需简化工具提升可访问性。

Method: 引入HealthProcessAI框架，围绕现有Python（PM4PY）和R（bupaR）库构建，集成多个LLM模型进行自动流程图解释和报告生成，并通过OpenRouter平台验证其性能。

Result: 框架在四个概念验证场景中成功处理脓毒症数据，技术性能稳健。LLM评估显示Claude Sonnet-4和Gemini 2.5-Pro一致性最高（3.79/4.0和3.65/4.0）。

Conclusion: HealthProcessAI框架通过整合多个大型语言模型（LLMs）自动解释和生成报告，显著提升了流程挖掘在医疗领域的可访问性和实用性，为复杂分析结果转化为可操作见解提供了新方法。

Abstract: Process mining has emerged as a powerful analytical technique for
understanding complex healthcare workflows. However, its application faces
significant barriers, including technical complexity, a lack of standardized
approaches, and limited access to practical training resources. We introduce
HealthProcessAI, a GenAI framework designed to simplify process mining
applications in healthcare and epidemiology by providing a comprehensive
wrapper around existing Python (PM4PY) and R (bupaR) libraries. To address
unfamiliarity and improve accessibility, the framework integrates multiple
Large Language Models (LLMs) for automated process map interpretation and
report generation, helping translate technical analyses into outputs that
diverse users can readily understand. We validated the framework using sepsis
progression data as a proof-of-concept example and compared the outputs of five
state-of-the-art LLM models through the OpenRouter platform. To test its
functionality, the framework successfully processed sepsis data across four
proof-of-concept scenarios, demonstrating robust technical performance and its
capability to generate reports through automated LLM analysis. LLM evaluation
using five independent LLMs as automated evaluators revealed distinct model
strengths: Claude Sonnet-4 and Gemini 2.5-Pro achieved the highest consistency
scores (3.79/4.0 and 3.65/4.0) when evaluated by automated LLM assessors. By
integrating multiple Large Language Models (LLMs) for automated interpretation
and report generation, the framework addresses widespread unfamiliarity with
process mining outputs, making them more accessible to clinicians, data
scientists, and researchers. This structured analytics and AI-driven
interpretation combination represents a novel methodological advance in
translating complex process mining results into potentially actionable insights
for healthcare applications.

</details>


### [74] [Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances](https://arxiv.org/abs/2508.21564)
*Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt*

Main category: cs.AI

TL;DR: A new framework learns generalized landmarks from solved instances, using state functions to create a landmark graph for planning. It improves heuristic performance, especially with repetitive subplans, and works across domain sizes.


<details>
  <summary>Details</summary>
Motivation: Traditional landmark extraction algorithms fall short in planning problems where intermediate goals need to be generalized across a domain. The proposed framework aims to address this limitation by discovering landmarks that automatically generalize across a domain.

Method: The framework learns generalized landmarks from a set of solved instances, using state functions independent of specific problem objects to construct a directed generalized landmark graph. This graph includes loop possibilities for repetitive subplans and is used in a heuristic to solve new problem instances.

Result: Generalized landmark graphs learned from small instances are effective for larger instances in the same domain, with significant heuristic performance improvement when loops indicating repetition are identified.

Conclusion: Generalized landmarks capture domain information that is interpretable and useful to an automated planner, and can be discovered from a small set of plans for the same domain.

Abstract: We propose a new framework for discovering landmarks that automatically
generalize across a domain. These generalized landmarks are learned from a set
of solved instances and describe intermediate goals for planning problems where
traditional landmark extraction algorithms fall short. Our generalized
landmarks extend beyond the predicates of a domain by using state functions
that are independent of the objects of a specific problem and apply to all
similar objects, thus capturing repetition. Based on these functions, we
construct a directed generalized landmark graph that defines the landmark
progression, including loop possibilities for repetitive subplans. We show how
to use this graph in a heuristic to solve new problem instances of the same
domain. Our results show that the generalized landmark graphs learned from a
few small instances are also effective for larger instances in the same domain.
If a loop that indicates repetition is identified, we see a significant
improvement in heuristic performance over the baseline. Generalized landmarks
capture domain information that is interpretable and useful to an automated
planner. This information can be discovered from a small set of plans for the
same domain.

</details>


### [75] [Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics](https://arxiv.org/abs/2508.21595)
*Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes*

Main category: cs.AI

TL;DR: 提出了Det-Dec-POMDPs类及IDPP方法，优化大规模确定性多智能体规划问题求解。


<details>
  <summary>Details</summary>
Motivation: 针对多智能体规划问题（如多机器人导航和路径规划）中确定性动作和观测的有效建模需求，当前Dec-POMDP求解器无法高效处理大规模问题。

Method: 基于经典的Joint Equilibrium Search for Policies框架，提出了Iterative Deterministic POMDP Planning (IDPP)方法，专门优化处理大规模Det-Dec-POMDPs。

Result: IDPP方法能够高效处理大规模Det-Dec-POMDPs，解决了当前Dec-POMDP求解器的局限性。

Conclusion: 本研究通过引入Det-Dec-POMDPs类，并提出IDPP方法，为大规模确定性多智能体规划问题提供了高效解决方案。

Abstract: Many high-level multi-agent planning problems, including multi-robot
navigation and path planning, can be effectively modeled using deterministic
actions and observations.
  In this work, we focus on such domains and introduce the class of
Deterministic Decentralized POMDPs (Det-Dec-POMDPs). This is a subclass of
Dec-POMDPs characterized by deterministic transitions and observations
conditioned on the state and joint actions.
  We then propose a practical solver called Iterative Deterministic POMDP
Planning (IDPP). This method builds on the classic Joint Equilibrium Search for
Policies framework and is specifically optimized to handle large-scale
Det-Dec-POMDPs that current Dec-POMDP solvers are unable to address
efficiently.

</details>


### [76] [Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study](https://arxiv.org/abs/2508.21622)
*Saravanan Venkatachalam*

Main category: cs.AI

TL;DR: 论文提出一个结合传统优化与LLM的框架，用于供应链规划，通过自然语言和可视化提升决策支持，案例显示其有效性，未来计划扩展AI技术。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合复杂的运筹学输出与业务利益相关者理解之间的差距，通过生成自然语言摘要、上下文可视化和定制化的关键绩效指标（KPIs）来实现。

Method: 研究采用混合整数规划作为核心优化模型，处理多周期和多物品的战术库存再分配问题。技术架构包含AI代理、RESTful API和动态用户界面，支持实时交互、配置更新和基于模拟的洞察。

Result: 案例研究表明，该系统通过防止缺货、降低成本和维持服务水平，改善了规划结果。

Conclusion: 论文提出了一个结合传统网络优化模型与大型语言模型的集成框架，以提供交互式、可解释和角色感知的决策支持。未来计划通过集成私有LLM、迁移学习、强化学习和贝叶斯神经网络来增强系统的可解释性、适应性和实时决策能力。

Abstract: This paper presents an integrated framework that combines traditional network
optimization models with large language models (LLMs) to deliver interactive,
explainable, and role-aware decision support for supply chain planning. The
proposed system bridges the gap between complex operations research outputs and
business stakeholder understanding by generating natural language summaries,
contextual visualizations, and tailored key performance indicators (KPIs). The
core optimization model addresses tactical inventory redistribution across a
network of distribution centers for multi-period and multi-item, using a
mixed-integer formulation. The technical architecture incorporates AI agents,
RESTful APIs, and a dynamic user interface to support real-time interaction,
configuration updates, and simulation-based insights. A case study demonstrates
how the system improves planning outcomes by preventing stockouts, reducing
costs, and maintaining service levels. Future extensions include integrating
private LLMs, transfer learning, reinforcement learning, and Bayesian neural
networks to enhance explainability, adaptability, and real-time
decision-making.

</details>


### [77] [A-MHA*: Anytime Multi-Heuristic A*](https://arxiv.org/abs/2508.21637)
*Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev*

Main category: cs.AI

TL;DR: A-MHA*是MHA*的随时改进版本，结合ARA*思想，快速生成初始解并持续优化，保留原始算法的次优性和完备性保证。


<details>
  <summary>Details</summary>
Motivation: MHA*虽然能够利用多个不完全启发式函数快速生成次优解，但其一次性算法特性无法随时间改进解，限制了其应用灵活性。

Method: 提出了一种基于MHA*的改进算法A-MHA*，通过引入ARA*的思想，使其能够在找到初始可行解后持续优化。

Result: 在3-D路径规划和滑动拼图实验中，A-MHA*表现优于MHA*和其他随时算法。

Conclusion: 通过将ARA*的概念精确适配到MHA*框架中，A-MHA*不仅保留了原始MHA*的次优性和完备性保证，还实现了随时改进解的能力。

Abstract: Designing good heuristic functions for graph search requires adequate domain
knowledge. It is often easy to design heuristics that perform well and
correlate with the underlying true cost-to-go values in certain parts of the
search space but these may not be admissible throughout the domain thereby
affecting the optimality guarantees of the search. Bounded suboptimal search
using several such partially good but inadmissible heuristics was developed in
Multi-Heuristic A* (MHA*). Although MHA* leverages multiple inadmissible
heuristics to potentially generate a faster suboptimal solution, the original
version does not improve the solution over time. It is a one shot algorithm
that requires careful setting of inflation factors to obtain a desired one time
solution. In this work, we tackle this issue by extending MHA* to an anytime
version that finds a feasible suboptimal solution quickly and continually
improves it until time runs out. Our work is inspired from the Anytime
Repairing A* (ARA*) algorithm. We prove that our precise adaptation of ARA*
concepts in the MHA* framework preserves the original suboptimal and
completeness guarantees and enhances MHA* to perform in an anytime fashion.
Furthermore, we report the performance of A-MHA* in 3-D path planning domain
and sliding tiles puzzle and compare against MHA* and other anytime algorithms.

</details>


### [78] [Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI](https://arxiv.org/abs/2508.21648)
*Farhad Abtahi,Mehdi Astaraki,Fernando Seoane*

Main category: cs.AI

TL;DR: MEDLEY框架通过保留AI模型的多样性输出，将偏见和幻觉视为资源，增强了医疗推理的透明度和临床监督。


<details>
  <summary>Details</summary>
Motivation: 传统观点认为医疗AI中的偏见是需要消除的缺陷，但人类推理中的偏见可能不可避免且有价值。

Method: 开发了一个概念框架MEDLEY，协调多个AI模型，保留其多样输出而非达成共识。使用超过30个大型语言模型构建了一个概念验证演示器。

Result: 概念验证演示器在合成案例中保留了共识和少数观点，使诊断不确定性和潜在偏见对临床监督透明。

Conclusion: MEDLEY通过将AI的不完美视为资源，提供了一个范式转变，为开发可信赖的医疗AI系统开辟了新的监管、伦理和创新途径。

Abstract: Bias in medical artificial intelligence is conventionally viewed as a defect
requiring elimination. However, human reasoning inherently incorporates biases
shaped by education, culture, and experience, suggesting their presence may be
inevitable and potentially valuable. We propose MEDLEY (Medical Ensemble
Diagnostic system with Leveraged diversitY), a conceptual framework that
orchestrates multiple AI models while preserving their diverse outputs rather
than collapsing them into a consensus. Unlike traditional approaches that
suppress disagreement, MEDLEY documents model-specific biases as potential
strengths and treats hallucinations as provisional hypotheses for clinician
verification. A proof-of-concept demonstrator was developed using over 30 large
language models, creating a minimum viable product that preserved both
consensus and minority views in synthetic cases, making diagnostic uncertainty
and latent biases transparent for clinical oversight. While not yet a validated
clinical tool, the demonstration illustrates how structured diversity can
enhance medical reasoning under clinician supervision. By reframing AI
imperfection as a resource, MEDLEY offers a paradigm shift that opens new
regulatory, ethical, and innovation pathways for developing trustworthy medical
AI systems.

</details>


### [79] [PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation](https://arxiv.org/abs/2508.21720)
*Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim*

Main category: cs.AI

TL;DR: PosterForest是一种无需训练的科学海报生成框架，通过Poster Tree和多智能体协作优化逻辑一致性、内容忠实度和视觉连贯性，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法忽视科学文档的层次结构和视觉与文本元素语义整合的问题。

Method: 引入了Poster Tree这一分层中间表示，联合编码文档结构和视觉-文本关系，并采用多智能体协作策略进行内容摘要和布局规划的迭代协调。

Result: 在多学术领域的实验中，PosterForest在定性和定量评估上均优于现有基线。

Conclusion: PosterForest框架在科学海报生成方面表现出色，其质量接近专家设计的地面真实，并在信息保留、结构清晰度和用户偏好方面优于现有基线。

Abstract: We present a novel training-free framework, \textit{PosterForest}, for
automated scientific poster generation. Unlike prior approaches, which largely
neglect the hierarchical structure of scientific documents and the semantic
integration of textual and visual elements, our method addresses both
challenges directly. We introduce the \textit{Poster Tree}, a hierarchical
intermediate representation that jointly encodes document structure and
visual-textual relationships at multiple levels. Our framework employs a
multi-agent collaboration strategy, where agents specializing in content
summarization and layout planning iteratively coordinate and provide mutual
feedback. This approach enables the joint optimization of logical consistency,
content fidelity, and visual coherence. Extensive experiments on multiple
academic domains show that our method outperforms existing baselines in both
qualitative and quantitative evaluations. The resulting posters achieve quality
closest to expert-designed ground truth and deliver superior information
preservation, structural clarity, and user preference.

</details>


### [80] [Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem](https://arxiv.org/abs/2508.21730)
*Fabrizio Fagiolo,Nicolo' Vescera*

Main category: cs.AI

TL;DR: 论文提出一种结合紧凑编码和优化-冻结-重用策略的变分算法，用于TSP问题，在中等规模问题上表现优异，但7城市时成功率显著下降。


<details>
  <summary>Details</summary>
Motivation: 解决旅行商问题（TSP）在NISQ硬件上的实现难题，减少测试中的结构研究成本。

Method: 结合紧凑排列编码和优化-冻结-重用策略，通过模拟退火优化电路拓扑后冻结并重用于新实例，仅快速重新优化电路参数。

Result: 在4-7城市的随机对称实例上，4城市最优解采样概率达100%，5城市90%，6城市80%，7城市降至~20%。

Conclusion: 该论文提出的方法在中等规模问题上表现出强大的泛化能力，并展示了冻结Ansatz可以显著减少解决时间而不降低解的质量。同时，论文讨论了方法的可扩展性限制以及对更复杂问题的扩展前景。

Abstract: In this paper we present a variational algorithm for the Traveling Salesman
Problem (TSP) that combines (i) a compact encoding of permutations, which
reduces the qubit requirement too, (ii) an optimize-freeze-reuse strategy:
where the circuit topology (``Ansatz'') is first optimized on a training
instance by Simulated Annealing (SA), then ``frozen'' and re-used on novel
instances, limited to a rapid re-optimization of only the circuit parameters.
This pipeline eliminates costly structural research in testing, making the
procedure immediately implementable on NISQ hardware.
  On a set of $40$ randomly generated symmetric instances that span $4 - 7$
cities, the resulting Ansatz achieves an average optimal trip sampling
probability of $100\%$ for 4 city cases, $90\%$ for 5 city cases and $80\%$ for
6 city cases. With 7 cities the success rate drops markedly to an average of
$\sim 20\%$, revealing the onset of scalability limitations of the proposed
method.
  The results show robust generalization ability for moderate problem sizes and
indicate how freezing the Ansatz can dramatically reduce time-to-solution
without degrading solution quality. The paper also discusses scalability
limitations, the impact of ``warm-start'' initialization of parameters, and
prospects for extension to more complex problems, such as Vehicle Routing and
Job-Shop Scheduling.

</details>


### [81] [Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions](https://arxiv.org/abs/2508.21742)
*Timothée Loranchet,Charles K. Assaad*

Main category: cs.AI

TL;DR: 论文提出了利用宏观因果图指导微观时间变量边定向的理论条件，强化了专家知识在因果推断中的作用。


<details>
  <summary>Details</summary>
Motivation: 时间序列分析中，专家常能提供宏观因果图（SCG）抽象主要因果关系，但微观边定向的理论保证尚不明确。

Method: 提出了在忠实且因果充分的分布假设下，利用宏观因果图（SCG）指导微观边定向的条件。

Result: 即使在宏观层面存在循环或双向边，微观边的定向仍可得到理论保证。

Conclusion: 本研究提供了在给定宏观因果图背景下，微观层面时间变量间边定向的理论保证，展示了专家知识在改进时间序列数据因果推断中的价值。

Abstract: Understanding causal relations between temporal variables is a central
challenge in time series analysis, particularly when the full causal structure
is unknown. Even when the full causal structure cannot be fully specified,
experts often succeed in providing a high-level abstraction of the causal
graph, known as a summary causal graph, which captures the main causal
relations between different time series while abstracting away micro-level
details. In this work, we present conditions that guarantee the orientability
of micro-level edges between temporal variables given the background knowledge
encoded in a summary causal graph and assuming having access to a faithful and
causally sufficient distribution with respect to the true unknown graph. Our
results provide theoretical guarantees for edge orientation at the micro-level,
even in the presence of cycles or bidirected edges at the macro-level. These
findings offer practical guidance for leveraging SCGs to inform causal
discovery in complex temporal systems and highlight the value of incorporating
expert knowledge to improve causal inference from observational time series
data.

</details>


### [82] [Tree-Guided Diffusion Planner](https://arxiv.org/abs/2508.21800)
*Hyeonseong Jeon,Cheolhong Min,Jaesik Park*

Main category: cs.AI

TL;DR: TDP是一种零样本测试时规划框架，通过双层采样平衡探索与利用，解决了梯度引导的局限性，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准梯度引导在非凸、非可微和多奖励结构的现实场景中效果有限，且现有监督规划方法需要任务特定训练或价值估计器，限制了测试时的灵活性和零样本泛化能力。

Method: TDP采用双层采样过程：1）通过无训练粒子引导生成多样化的父轨迹以促进广泛探索；2）通过任务目标指导的快速条件去噪优化子轨迹。

Result: TDP在迷宫金币收集、机器人手臂块操作和AntMaze多目标探索三个任务中均优于最先进方法。

Conclusion: TDP（Tree-guided Diffusion Planner）作为零样本测试时规划框架，通过结构化的轨迹生成在多个任务中表现优于现有方法，解决了梯度引导在非凸、非可微和多奖励结构中的局限性。

Abstract: Planning with pretrained diffusion models has emerged as a promising approach
for solving test-time guided control problems. However, standard gradient
guidance typically performs optimally under convex and differentiable reward
landscapes, showing substantially reduced effectiveness in real-world scenarios
involving non-convex objectives, non-differentiable constraints, and
multi-reward structures. Furthermore, recent supervised planning approaches
require task-specific training or value estimators, which limits test-time
flexibility and zero-shot generalization. We propose a Tree-guided Diffusion
Planner (TDP), a zero-shot test-time planning framework that balances
exploration and exploitation through structured trajectory generation. We frame
test-time planning as a tree search problem using a bi-level sampling process:
(1) diverse parent trajectories are produced via training-free particle
guidance to encourage broad exploration, and (2) sub-trajectories are refined
through fast conditional denoising guided by task objectives. TDP addresses the
limitations of gradient guidance by exploring diverse trajectory regions and
harnessing gradient information across this expanded solution space using only
pretrained models and test-time reward signals. We evaluate TDP on three
diverse tasks: maze gold-picking, robot arm block manipulation, and AntMaze
multi-goal exploration. TDP consistently outperforms state-of-the-art
approaches on all tasks. The project page can be found at:
tree-diffusion-planner.github.io.

</details>


### [83] [Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture](https://arxiv.org/abs/2508.21803)
*Yeawon Lee,Xiaoyang Wang,Christopher C. Yang*

Main category: cs.AI

TL;DR: 论文提出了一种协作多代理系统，模拟临床团队进行诊断推理，显著提高了临床叙述解释的准确性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 临床叙述的准确解释对患者护理至关重要，但单模型方法在高风险临床任务中缺乏稳健性。

Method: 引入了一个协作多代理系统（MAS），该系统模拟临床咨询团队，由Manager代理动态分配专家代理团队，通过分层迭代辩论达成共识。

Result: 在420份MIMIC-III笔记的精选数据集上，动态多代理配置在识别充血性心力衰竭、急性肾损伤和败血症方面表现持续改善。

Conclusion: 通过模拟临床团队的推理过程，该系统为更准确、稳健且可解释的临床决策支持工具提供了一条有前景的路径。

Abstract: Accurate interpretation of clinical narratives is critical for patient care,
but the complexity of these notes makes automation challenging. While Large
Language Models (LLMs) show promise, single-model approaches can lack the
robustness required for high-stakes clinical tasks. We introduce a
collaborative multi-agent system (MAS) that models a clinical consultation team
to address this gap. The system is tasked with identifying clinical problems by
analyzing only the Subjective (S) and Objective (O) sections of SOAP notes,
simulating the diagnostic reasoning process of synthesizing raw data into an
assessment. A Manager agent orchestrates a dynamically assigned team of
specialist agents who engage in a hierarchical, iterative debate to reach a
consensus. We evaluated our MAS against a single-agent baseline on a curated
dataset of 420 MIMIC-III notes. The dynamic multi-agent configuration
demonstrated consistently improved performance in identifying congestive heart
failure, acute kidney injury, and sepsis. Qualitative analysis of the agent
debates reveals that this structure effectively surfaces and weighs conflicting
evidence, though it can occasionally be susceptible to groupthink. By modeling
a clinical team's reasoning process, our system offers a promising path toward
more accurate, robust, and interpretable clinical decision support tools.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [84] [Fast and Scalable Mixed Precision Euclidean Distance Calculations Using GPU Tensor Cores](https://arxiv.org/abs/2508.21230)
*Brian Curless,Michael Gowanlock*

Main category: cs.DC

TL;DR: FaSTED算法利用FP16-32张量核心优化欧氏距离计算，性能提升显著且精度损失极小。


<details>
  <summary>Details</summary>
Motivation: 利用GPU张量核心（TCs）的高计算吞吐量优化欧氏距离计算，适用于数据分析应用。

Method: 设计了FaSTED算法，通过分层数据重用和最大化内存利用率（全局内存、共享内存和寄存器）实现高计算吞吐量。

Result: 在四个真实高维数据集上，混合精度方法比SOTA算法快2.5-51倍。

Conclusion: FaSTED算法在混合精度（FP16-32）下显著提升了欧氏距离计算的性能，同时保持了高精度（误差<0.06%）。

Abstract: Modern GPUs are equipped with tensor cores (TCs) that are commonly used for
matrix multiplication in artificial intelligence workloads. However, because
they have high computational throughput, they can lead to significant
performance gains in other algorithms if they can be successfully exploited. We
examine using TCs to compute Euclidean distance calculations, which are used in
many data analytics applications. Prior work has only investigated using 64 bit
floating point (FP64) data for computation; however, TCs can operate on lower
precision floating point data (i.e., 16 bit matrix multiplication and 32 bit
accumulation), which we refer to as FP16-32. FP16-32 TC peak throughput is so
high that TCs are easily starved of data. We propose a Fast and Scalable Tensor
core Euclidean Distance (FaSTED) algorithm. To achieve high computational
throughput, we design FaSTED for significant hierarchical reuse of data and
maximize memory utilization at every level (global memory, shared memory, and
registers). We apply FaSTED to the application of similarity searches, which
typically employ an indexing data structure to eliminate superfluous Euclidean
distance calculations. We compare to the state-of-the-art (SOTA) TC Euclidean
distance algorithm in the literature that employs FP64, as well as to two
single precision (FP32) CUDA core algorithms that both employ an index. We find
that across four real-world high-dimensional datasets spanning 128-960
dimensions, the mixed-precision brute force approach achieves a speedup over
the SOTA algorithms of 2.5-51x. We also quantify the accuracy loss of our mixed
precision algorithm to be less than <0.06% when compared to the FP64 baseline.

</details>


### [85] [Decentralized Federated Averaging via Random Walk](https://arxiv.org/abs/2508.21286)
*Changheng Wang,Zhiqing Wei,Lizhe Liu,Qiao Deng,Yingda Wu,Yangyang Niu,Yashan Pang,Zhiyong Feng*

Main category: cs.DC

TL;DR: DFedRW通过随机走和量化技术优化去中心化联邦学习，显著提升异构数据下的收敛速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习在异构和不平衡数据下收敛慢或次优模型的问题，同时避免中心化范式的单点故障和隐私风险。

Method: 提出了基于随机走的去中心化联邦平均（DFedRW）及其量化版本，通过部分随机走更新和量化技术优化通信效率和收敛性。

Result: DFedRW在凸条件下达到$\mathcal{O}(\frac{1}{k^{1-q}})$的收敛上界，量化版本在高异构性下测试准确率提升38.3%和37.5%。

Conclusion: DFedRW及其量化版本在异构数据环境下显著提升了联邦学习的收敛速度和准确性，验证了其优于传统FedAvg方法的性能。

Abstract: Federated Learning (FL) is a communication-efficient distributed machine
learning method that allows multiple devices to collaboratively train models
without sharing raw data. FL can be categorized into centralized and
decentralized paradigms. The centralized paradigm relies on a central server to
aggregate local models, potentially resulting in single points of failure,
communication bottlenecks, and exposure of model parameters. In contrast, the
decentralized paradigm, which does not require a central server, provides
improved robustness and privacy. The essence of federated learning lies in
leveraging multiple local updates for efficient communication. However, this
approach may result in slower convergence or even convergence to suboptimal
models in the presence of heterogeneous and imbalanced data. To address this
challenge, we study decentralized federated averaging via random walk (DFedRW),
which replaces multiple local update steps on a single device with random walk
updates. Traditional Federated Averaging (FedAvg) and its decentralized
versions commonly ignore stragglers, which reduces the amount of training data
and introduces sampling bias. Therefore, we allow DFedRW to aggregate partial
random walk updates, ensuring that each computation contributes to the model
update. To further improve communication efficiency, we also propose a
quantized version of DFedRW. We demonstrate that (quantized) DFedRW achieves
convergence upper bound of order $\mathcal{O}(\frac{1}{k^{1-q}})$ under convex
conditions. Furthermore, we propose a sufficient condition that reveals when
quantization balances communication and convergence. Numerical analysis
indicates that our proposed algorithms outperform (decentralized) FedAvg in
both convergence rate and accuracy, achieving a 38.3\% and 37.5\% increase in
test accuracy under high levels of heterogeneities.

</details>


### [86] [Addressing Reproducibility Challenges in HPC with Continuous Integration](https://arxiv.org/abs/2508.21289)
*Valérie Hayot-Sasson,Nathaniel Hudson,André Bauer,Maxime Gonthier,Ian Foster,Kyle Chard*

Main category: cs.DC

TL;DR: 论文提出CORRECT工具，通过GitHub Action支持远程HPC资源测试，提升HPC应用复现性，解决了现有倡议的局限性。


<details>
  <summary>Details</summary>
Motivation: HPC社区虽鼓励可复现性研究，但因基础设施与软件的独特性及严格访问限制，许多论文难以满足复现性要求。作者认为，在资源访问受限情况下，持续集成（CI）与完整的溯源信息可作为替代方案。

Method: 作者提出了一个名为CORRECT的GitHub Action工具，支持在远程HPC资源上安全执行测试，并通过三类HPC应用评估其可用性。

Result: CORRECT在三类HPC应用中展现了其自动化与文档化复现性评估的有效性。

Conclusion: CORRECT这一GitHub Action工具通过支持在远程HPC资源上安全执行测试，有效提升了HPC应用的复现性评估自动化与文档化，解决了现有复现性倡议的局限性。

Abstract: The high-performance computing (HPC) community has adopted incentive
structures to motivate reproducible research, with major conferences awarding
badges to papers that meet reproducibility requirements. Yet, many papers do
not meet such requirements. The uniqueness of HPC infrastructure and software,
coupled with strict access requirements, may limit opportunities for
reproducibility. In the absence of resource access, we believe that regular
documented testing, through continuous integration (CI), coupled with complete
provenance information, can be used as a substitute. Here, we argue that better
HPC-compliant CI solutions will improve reproducibility of applications. We
present a survey of reproducibility initiatives and describe the barriers to
reproducibility in HPC. To address existing limitations, we present a GitHub
Action, CORRECT, that enables secure execution of tests on remote HPC
resources. We evaluate CORRECT's usability across three different types of HPC
applications, demonstrating the effectiveness of using CORRECT for automating
and documenting reproducibility evaluations.

</details>


### [87] [A Knowledge Distillation-empowered Adaptive Federated Reinforcement Learning Framework for Multi-Domain IoT Applications Scheduling](https://arxiv.org/abs/2508.21328)
*Zhiyu Wang,Mohammad Goudarzi,Mingming Gong,Rajkumar Buyya*

Main category: cs.DC

TL;DR: KD-AFRL通过知识蒸馏和自适应联邦强化学习优化异构IoT调度，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决异构Cloud-Edge-IoT环境中分布式调度优化的挑战，包括固定神经网络架构的不兼容性、非IID数据分布和跨域协作机制不足。

Method: 提出KD-AFRL框架，包括资源感知的混合架构生成机制、隐私保护的环境聚类联邦学习方法和环境导向的跨架构知识蒸馏机制。

Result: 实验表明，KD-AFRL在收敛速度、完成时间、能耗和加权成本方面显著优于基线方法，并且在扩展性上表现更好。

Conclusion: KD-AFRL框架通过资源感知的混合架构生成、隐私保护的环境聚类联邦学习以及环境导向的跨架构知识蒸馏，显著提升了异构Cloud-Edge-IoT环境中的分布式调度优化性能。

Abstract: The rapid proliferation of Internet of Things (IoT) applications across
heterogeneous Cloud-Edge-IoT environments presents significant challenges in
distributed scheduling optimization. Existing approaches face issues, including
fixed neural network architectures that are incompatible with computational
heterogeneity, non-Independent and Identically Distributed (non-IID) data
distributions across IoT scheduling domains, and insufficient cross-domain
collaboration mechanisms. This paper proposes KD-AFRL, a Knowledge
Distillation-empowered Adaptive Federated Reinforcement Learning framework that
addresses multi-domain IoT application scheduling through three core
innovations. First, we develop a resource-aware hybrid architecture generation
mechanism that creates dual-zone neural networks enabling heterogeneous devices
to participate in collaborative learning while maintaining optimal resource
utilization. Second, we propose a privacy-preserving environment-clustered
federated learning approach that utilizes differential privacy and K-means
clustering to address non-IID challenges and facilitate effective collaboration
among compatible domains. Third, we introduce an environment-oriented
cross-architecture knowledge distillation mechanism that enables efficient
knowledge transfer between heterogeneous models through temperature-regulated
soft targets. Comprehensive experiments with real Cloud-Edge-IoT infrastructure
demonstrate KD-AFRL's effectiveness using diverse IoT applications. Results
show significant improvements over the best baseline, with 21% faster
convergence and 15.7%, 10.8%, and 13.9% performance gains in completion time,
energy consumption, and weighted cost, respectively. Scalability experiments
reveal that KD-AFRL achieves 3-5 times better performance retention compared to
existing solutions as the number of domains increases.

</details>


### [88] [Unpacking Maximum Extractable Value on Polygon: A Study on Atomic Arbitrage](https://arxiv.org/abs/2508.21473)
*Daniil Vostrikov,Yash Madhwal,Andrey Seoev,Anastasiia Smirnova,Yury Yanovich,Alexey Smirnov,Vladimir Gorgadze*

Main category: cs.DC

TL;DR: 本文研究了Polygon区块链上的MEV，特别是原子套利（AA）交易。通过分析搜索者行为、竞价动态和代币使用等关键因素，发现基于拍卖的策略更有利可图，强调了稳健交易排序机制的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨区块链技术从加密货币去中心化账本到更广泛应用（如去中心化金融）的演变，以及由此带来的新挑战，如最大可提取价值（MEV）。

Method: 利用覆盖23百万个区块、历时22个月的数据集，分析了MEV动态，重点关注基于垃圾邮件和基于拍卖的回溯策略。

Result: 研究发现，虽然基于垃圾邮件的交易更为普遍，但基于拍卖的交易表现出更高的盈利能力。

Conclusion: 研究强调了在区块链网络中建立稳健的交易排序机制的必要性，并突出了新兴MEV策略对区块链网络的影响。

Abstract: The evolution of blockchain technology, from its origins as a decentralized
ledger for cryptocurrencies to its broader applications in areas like
decentralized finance (DeFi), has significantly transformed financial
ecosystems while introducing new challenges such as Maximum Extractable Value
(MEV). This paper explores MEV on the Polygon blockchain, with a particular
focus on Atomic Arbitrage (AA) transactions. We establish criteria for
identifying AA transactions and analyze key factors such as searcher behavior,
bidding dynamics, and token usage. Utilizing a dataset spanning 22 months and
covering 23 million blocks, we examine MEV dynamics with a focus on Spam-based
and Auction-based backrunning strategies. Our findings reveal that while
Spam-based transactions are more prevalent, Auction-based transactions
demonstrate greater profitability. Through detailed examples and analysis, we
investigate the interactions between network architecture, transaction
sequencing, and MEV extraction, offering comprehensive insights into the
evolution and challenges of MEV in decentralized ecosystems. These results
emphasize the need for robust transaction ordering mechanisms and highlight the
implications of emerging MEV strategies for blockchain networks.

</details>


### [89] [Odyssey: Adaptive Policy Selection for Resilient Distributed Training](https://arxiv.org/abs/2508.21613)
*Yuhang Zhou,Zhibin Wang,Peng Jiang,Haoran Xia,Junhe Lu,Qianyu Jiang,Rong Gu,Hengxi Xu,Xinjing Huang,Guanghuan Fang,Zhiheng Hu,Jingyi Zhang,Yongjin Cai,Jian He,Chen Tian*

Main category: cs.DC

TL;DR: Odyssey是一种自适应容错系统，通过智能选择恢复策略，显著提升了大型语言模型训练的容错性和性能。


<details>
  <summary>Details</summary>
Motivation: 训练大型语言模型常因各种故障中断，现有无备份方法（如冗余计算、动态并行和数据重路由）各自存在性能损失。

Method: Odyssey通过统一的性能模型、快速执行计划搜索、准确的性能估计和高效的通信优化，智能选择最佳恢复策略。

Result: 实验表明，Odyssey的平均吞吐量比Oobleck和Recycle分别高出1.229倍和1.355倍。

Conclusion: Odyssey系统在32卡集群上表现出色，恢复后与无故障训练的性能差距保持在11.00%以内，同时保持了模型收敛性和高效内存使用。

Abstract: Training large language models faces frequent interruptions due to various
faults, demanding robust fault-tolerance. Existing backup-free methods, such as
redundant computation, dynamic parallelism, and data rerouting, each incur
performance penalties, whether from ongoing overhead, lengthy reconfigurations,
or post-recovery inefficiencies. We propose Odyssey, an adaptive fault-tolerant
system that intelligently selects optimal recovery strategies when a failure
occurs. Odyssey achieves this through a unified performance model, expedient
execution plan search, accurate performance estimation, and efficient
communication optimizations. Experiments on a 32-card cluster show that Odyssey
maintains a performance gap of within 11.00% between post-recovery and
failure-free training, while preserving model convergence and efficient memory
usage. Compared to state-of-the-art methods, Odyssey achieves up to 1.229x and
1.355x higher average throughput than Oobleck and Recycle, respectively.

</details>


### [90] [Accelerating Mixture-of-Experts Inference by Hiding Offloading Latency with Speculative Decoding](https://arxiv.org/abs/2508.21706)
*Zhibin Wang,Zhonghui Zhang,Yuhang Zhou,Zibo Wang,Mo Zhou,Peng Jiang,Weilin Cai,Chengying Huan,Rong Gu,Sheng Zhong,Chen Tian*

Main category: cs.DC

TL;DR: SpecMoEOff利用推测解码优化MoE模型推理，提升硬件利用率，解码吞吐量提升2.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有MoE卸载技术因I/O瓶颈和稀疏计算导致硬件利用率低，需要更高效的解决方案来充分利用硬件资源。

Method: 提出了SpecMoEOff，结合推测解码技术、GPU和CPU的协同调度，以及专用的CPU分块注意力验证内核，最小化额外开销，并通过优化器自动调整超参数。

Result: 实验结果表明，SpecMoEOff比现有最先进的MoE卸载技术提升了高达2.5倍的解码吞吐量。

Conclusion: SpecMoEOff通过推测解码技术和硬件资源优化，显著提升了MoE模型的推理效率，实现了比现有技术高2.5倍的解码吞吐量。

Abstract: Recent advancements in Mixture of Experts (MoE) models have significantly
increased their parameter scale as well as model performance. Extensive
offloading techniques have been proposed to address the GPU memory limitations
of MoE inference. However, due to the I/O bottleneck and sparse computation of
MoE models, existing offloading techniques still suffer from low hardware
utilization. To fully utilize the hardware resources, we propose SpecMoEOff,
which employs the speculative decoding technique to enlarge the workload of
each expert. SpecMoEOff orchestrates the GPU and CPU by both theoretical and
empirical roofline analysis. In addition, we develop a dedicated CPU chunked
attention verification kernel to fit the speculative decoding in offloading
scenarios as well as minimizing the additional overhead led by draft models.
SpecMoEOff further integrates an optimizer to automatically tune the
hyperparameters of speculative decoding under given hardware and workload.
Experimental results show that SpecMoEOff achieves up to 2.5x decode throughput
improvement over the state-of-the-art MoE offloading techniques.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [91] [Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation](https://arxiv.org/abs/2508.21097)
*Nazanin Siavash,Armin Moin*

Main category: cs.SE

TL;DR: 本文提出结合LLM与RAG管道，优化量子代码生成，实验显示提示词工程可显著提升代码质量。


<details>
  <summary>Details</summary>
Motivation: 针对量子软件系统开发中平台异构性和开发者技能不足的问题，探索模型驱动方法以降低成本和风险。

Method: 通过部署RAG管道，结合公开GitHub仓库中的Qiskit代码样本，生成基于UML模型实例的Python代码。实验采用精心设计的提示词，以提升CodeBLEU分数。

Result: 实验表明，优化后的提示词可将CodeBLEU分数提升至四倍，生成更准确、一致的量子代码。

Conclusion: 本文提出了一种利用LLM和RAG管道的新型研究方向，尤其在量子及混合量子-经典软件系统中展现出潜力。未来研究可进一步探索模型实例作为RAG信息源的可行性，以及LLM在代码转换中的应用。

Abstract: This paper introduces a novel research direction for model-to-text/code
transformations by leveraging Large Language Models (LLMs) that can be enhanced
with Retrieval-Augmented Generation (RAG) pipelines. The focus is on quantum
and hybrid quantum-classical software systems, where model-driven approaches
can help reduce the costs and mitigate the risks associated with the
heterogeneous platform landscape and lack of developers' skills. We validate
one of the proposed ideas regarding generating code out of UML model instances
of software systems. This Python code uses a well-established library, called
Qiskit, to execute on gate-based or circuit-based quantum computers. The RAG
pipeline that we deploy incorporates sample Qiskit code from public GitHub
repositories. Experimental results show that well-engineered prompts can
improve CodeBLEU scores by up to a factor of four, yielding more accurate and
consistent quantum code. However, the proposed research direction can go beyond
this through further investigation in the future by conducting experiments to
address our other research questions and ideas proposed here, such as deploying
software system model instances as the source of information in the RAG
pipelines, or deploying LLMs for code-to-code transformations, for instance,
for transpilation use cases.

</details>


### [92] [Learning to Generate Unit Test via Adversarial Reinforcement Learning](https://arxiv.org/abs/2508.21107)
*Dongjun Lee,Changho Hwang,Kimin Lee*

Main category: cs.SE

TL;DR: UTR框架通过对抗性强化学习训练LLM生成高质量单元测试，效果优于传统方法及前沿模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练LLM生成高质量单元测试方面研究不足，需探索更有效的方法。

Method: 提出UTR框架，通过对抗性强化学习迭代训练两个LLM（单元测试生成器和代码生成器），分别优化歧视奖励和代码奖励。

Result: 实验表明，UTR训练的Qwen3-4B生成的单元测试质量更高，代码评估更接近人工编写标准，且优于GPT-4.1等前沿模型。

Conclusion: UTR框架通过对抗性强化学习训练LLM生成高质量单元测试，其效果优于监督微调方法，并在某些情况下超越前沿模型如GPT-4.1。

Abstract: Unit testing is a core practice in programming, enabling systematic
evaluation of programs produced by human developers or large language models
(LLMs). Given the challenges in writing comprehensive unit tests, LLMs have
been employed to automate test generation, yet methods for training LLMs to
produce high-quality tests remain underexplored. In this work, we propose UTRL,
a novel reinforcement learning framework that trains an LLM to generate
high-quality unit tests given a programming instruction. Our key idea is to
iteratively train two LLMs, the unit test generator and the code generator, in
an adversarial manner via reinforcement learning. The unit test generator is
trained to maximize a discrimination reward, which reflects its ability to
produce tests that expose faults in the code generator's solutions, and the
code generator is trained to maximize a code reward, which reflects its ability
to produce solutions that pass the unit tests generated by the test generator.
In our experiments, we demonstrate that unit tests generated by Qwen3-4B
trained via UTRL show higher quality compared to unit tests generated by the
same model trained via supervised fine-tuning on human-written ground-truth
unit tests, yielding code evaluations that more closely align with those
induced by the ground-truth tests. Moreover, Qwen3-4B trained with UTRL
outperforms frontier models such as GPT-4.1 in generating high-quality unit
tests, highlighting the effectiveness of UTRL in training LLMs for this task.

</details>


### [93] [Automated Bug Triaging using Instruction-Tuned Large Language Models](https://arxiv.org/abs/2508.21156)
*Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan*

Main category: cs.SE

TL;DR: 论文提出了一种基于指令调优LLM的轻量级框架，用于高效Bug分派，表现出色且具实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 大型项目中，Bug分派任务通常缓慢且不一致，需要一种更高效的解决方案。

Method: 提出了一个轻量级框架，通过LoRA适配器对指令调优的LLM进行优化，并使用候选约束解码确保有效分配。

Result: 在EclipseJDT和Mozilla数据集上测试，模型表现出色（Hit at 10高达0.753），尽管Top-1精确度一般。最新快照中准确率显著提升，显示出框架在实际人机协作分派中的潜力。

Conclusion: 指令调优的大型语言模型（LLM）为成本高昂的特征工程和基于图的方法提供了实用替代方案。

Abstract: Bug triaging, the task of assigning new issues to developers, is often slow
and inconsistent in large projects. We present a lightweight framework that
instruction-tuned large language model (LLM) with LoRA adapters and uses
candidate-constrained decoding to ensure valid assignments. Tested on
EclipseJDT and Mozilla datasets, the model achieves strong shortlist quality
(Hit at 10 up to 0.753) despite modest exact Top-1 accuracy. On recent
snapshots, accuracy rises sharply, showing the framework's potential for
real-world, human-in-the-loop triaging. Our results suggest that
instruction-tuned LLMs offer a practical alternative to costly feature
engineering and graph-based methods.

</details>


### [94] [The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management](https://arxiv.org/abs/2508.21433)
*Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov*

Main category: cs.SE

TL;DR: 研究发现，在SWE-agent中，简单的观察掩码策略比复杂的LLM摘要更高效且成本更低，同时保持或略微提高任务解决率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在处理复杂任务时会产生长而昂贵的上下文历史，现有方法（如LLM摘要）可能增加复杂性而不一定带来性能优势。本文旨在探索更简单、高效的替代方案。

Method: 本研究通过系统比较不同上下文管理策略（如原始代理、LLM摘要和观察掩码）在五种不同模型配置下的表现，评估了它们在SWE-agent上的效果。

Result: 观察掩码策略将成本降低一半，同时与LLM摘要策略相比，解决问题的成功率相当或略高。例如，使用Qwen3-Coder 480B时，掩码策略将解决率从53.8%提升至54.8%。

Conclusion: 研究表明，在SWE-agent和SWE-bench Verified环境中，最简单的上下文管理策略（如观察掩码）不仅能降低成本，还能保持或略微提高解决问题的成功率。

Abstract: Large Language Model (LLM)-based agents solve complex tasks through iterative
reasoning, exploration, and tool-use, a process that can result in long,
expensive context histories. While state-of-the-art Software Engineering ( SE)
agents like OpenHands or Cursor use LLM-based summarization to tackle this
issue, it is unclear whether the increased complexity offers tangible
performance benefits compared to simply omitting older observations. We present
a systematic comparison of these strategies within SWE-agent on SWE-bench
Verified across five diverse model configurations. We find that a simple
observation-masking strategy halves cost relative to a raw agent while
matching, and sometimes slightly exceeding, the solve rate of LLM
summarization. For example, with Qwen3-Coder 480B, masking improves solve rate
from 53.8% (raw agent) to 54.8%, while remaining competitive with summarization
at a lower cost. These results suggest that, at least within SWE-agent on
SWE-bench Verified, the most effective and efficient context management can be
the simplest. We release code and data for reproducibility

</details>


### [95] [Enhancing Semantic Understanding in Pointer Analysis using Large Language Models](https://arxiv.org/abs/2508.21454)
*Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen*

Main category: cs.SE

TL;DR: LMPA利用LLMs改进指针分析，减少错误传播并提升分析效率。


<details>
  <summary>Details</summary>
Motivation: 现有指针分析框架因对代码语义理解不足，导致对用户定义函数的处理过于保守，从而传播错误事实。LLMs的最新进展为弥补这一差距提供了新机会。

Method: LMPA识别类似系统API的用户定义函数并相应建模，同时通过推断初始点集和引入增强的自然语言摘要策略来改进基于摘要的分析。

Result: LMPA通过LLMs增强指针分析，减少了错误的跨调用上下文传播，并提升了摘要分析的效率。

Conclusion: LMPA通过整合大型语言模型（LLMs）到指针分析中，提出了一个增强精度和可扩展性的新视角，并讨论了实现这一愿景的关键挑战。

Abstract: Pointer analysis has been studied for over four decades. However, existing
frameworks continue to suffer from the propagation of incorrect facts. A major
limitation stems from their insufficient semantic understanding of code,
resulting in overly conservative treatment of user-defined functions. Recent
advances in large language models (LLMs) present new opportunities to bridge
this gap. In this paper, we propose LMPA (LLM-enhanced Pointer Analysis), a
vision that integrates LLMs into pointer analysis to enhance both precision and
scalability. LMPA identifies user-defined functions that resemble system APIs
and models them accordingly, thereby mitigating erroneous cross-calling-context
propagation. Furthermore, it enhances summary-based analysis by inferring
initial points-to sets and introducing a novel summary strategy augmented with
natural language. Finally, we discuss the key challenges involved in realizing
this vision.

</details>


### [96] [Reusable Test Suites for Reinforcement Learning](https://arxiv.org/abs/2508.21553)
*Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker*

Main category: cs.SE

TL;DR: MPTCS是一种多策略测试案例选择方法，旨在生成通用且高效的测试套件，以揭示RL智能体的典型缺陷。


<details>
  <summary>Details</summary>
Motivation: 验证强化学习（RL）智能体策略的可靠性和性能存在挑战，现有测试方法生成的测试套件难以通用。

Method: 提出Multi-Policy Test Case Selection (MPTCS)方法，基于可解性、多样性和通用难度从候选池中选择测试案例。

Result: MPTCS通过多策略选择生成多样化的测试案例，能够有效覆盖状态空间并触发策略的故障行为。

Conclusion: MPTCS方法通过多策略测试案例选择，提供了一种通用且高效的测试套件生成方式，能够有效揭示智能体行为的典型缺陷。

Abstract: Reinforcement learning (RL) agents show great promise in solving sequential
decision-making tasks. However, validating the reliability and performance of
the agent policies' behavior for deployment remains challenging. Most
reinforcement learning policy testing methods produce test suites tailored to
the agent policy being tested, and their relevance to other policies is
unclear. This work presents Multi-Policy Test Case Selection (MPTCS), a novel
automated test suite selection method for RL environments, designed to extract
test cases generated by any policy testing framework based on their
solvability, diversity, and general difficulty. MPTCS uses a set of policies to
select a diverse collection of reusable policy-agnostic test cases that reveal
typical flaws in the agents' behavior. The set of policies selects test cases
from a candidate pool, which can be generated by any policy testing method,
based on a difficulty score. We assess the effectiveness of the difficulty
score and how the method's effectiveness and cost depend on the number of
policies in the set. Additionally, a method for promoting diversity in the test
suite, a discretized general test case descriptor surface inspired by
quality-diversity algorithms, is examined to determine how it covers the state
space and which policies it triggers to produce faulty behaviors.

</details>


### [97] [Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity](https://arxiv.org/abs/2508.21634)
*Domenico Cotroneo,Cristina Improta,Pietro Liguori*

Main category: cs.SE

TL;DR: 研究比较了人类和AI生成的代码质量，发现AI代码更简单但安全风险更高，人类代码更复杂但可维护性较差。


<details>
  <summary>Details</summary>
Motivation: 随着AI代码助手在软件开发中的广泛应用，了解其代码与人类编写代码的差异对确保可靠性、可维护性和安全性至关重要。

Method: 通过对50万份Python和Java代码样本进行大规模比较，使用正交缺陷分类和通用弱点枚举来评估代码缺陷和安全漏洞。

Result: AI生成的代码通常更简单、重复性更高，但更容易出现未使用的构造和硬编码调试；人类编写的代码结构复杂度更高，可维护性问题更集中。此外，AI生成的代码包含更多高风险安全漏洞。

Conclusion: AI生成的代码与人类编写的代码在缺陷、安全漏洞和结构复杂性方面存在显著差异，需要针对AI辅助编程制定专门的质量保证措施。

Abstract: As AI code assistants become increasingly integrated into software
development workflows, understanding how their code compares to human-written
programs is critical for ensuring reliability, maintainability, and security.
In this paper, we present a large-scale comparison of code authored by human
developers and three state-of-the-art LLMs, i.e., ChatGPT, DeepSeek-Coder, and
Qwen-Coder, on multiple dimensions of software quality: code defects, security
vulnerabilities, and structural complexity. Our evaluation spans over 500k code
samples in two widely used languages, Python and Java, classifying defects via
Orthogonal Defect Classification and security vulnerabilities using the Common
Weakness Enumeration. We find that AI-generated code is generally simpler and
more repetitive, yet more prone to unused constructs and hardcoded debugging,
while human-written code exhibits greater structural complexity and a higher
concentration of maintainability issues. Notably, AI-generated code also
contains more high-risk security vulnerabilities. These findings highlight the
distinct defect profiles of AI- and human-authored code and underscore the need
for specialized quality assurance practices in AI-assisted programming.

</details>


### [98] [The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry](https://arxiv.org/abs/2508.21811)
*Ashley Hourigan,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 研究探讨了敏捷与DevOps在IT行业中的结合，通过访谈和主题分析，提出了两者相互关系的新理解。


<details>
  <summary>Details</summary>
Motivation: IT行业对快速软件交付的需求显著增加，强调需要更快的软件产品和服务发布以满足客户期望。敏捷和DevOps方法因此受到重视。

Method: 通过11次半结构化访谈，对IT行业中不同领域的敏捷和DevOps从业者进行调查，并采用主题分析提取了51个独特代码，综合成19个主题。

Result: 研究发现并讨论了敏捷方法在DevOps实践中的互操作性，为研究目标提供了新的见解。

Conclusion: 研究提出了对敏捷方法在DevOps实践中相互关系的新理解，满足了研究目标。

Abstract: The demand for rapid software delivery in the Information Technology (IT)
industry has significantly intensified, emphasising the need for faster
software products and service releases with enhanced features to meet customer
expectations. Agile methodologies are replacing traditional approaches such as
Waterfall, where flexibility, iterative development and adaptation to change
are favoured over rigid planning and execution. DevOps, a subsequent evolution
from Agile, emphasises collaborative efforts in development and operations
teams, focusing on continuous integration and deployment to deliver resilient
and high-quality software products and services. This study aims to critically
assess both Agile and DevOps practices in the IT industry to identify the
feasibility and applicability of Agile methods in DevOps practices. Eleven
semi-structured interviews were conducted with Agile and DevOps practitioners
in varying capacities across several sectors within the IT industry. Through
thematic analysis, 51 unique codes were extracted and synthesised into 19
themes that reported on each phase of the DevOps lifecycle, specifically
regarding the integration and implementation of Agile methods into DevOps
practices. Based on the findings, a new understanding detailing the
interrelationship of Agile methods in DevOps practices was discussed that met
the research objectives.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [99] [Faster Linear Algebra Algorithms with Structured Random Matrices](https://arxiv.org/abs/2508.21189)
*Chris Camaño,Ethan N. Epperly,Raphael A. Meyer,Joel A. Tropp*

Main category: cs.DS

TL;DR: 论文提出OSI属性作为结构化降维的新框架，证明了多种随机矩阵满足OSI，显著加速线性代数任务，并通过实验验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决结构化随机矩阵在随机线性代数算法设计和分析中的基本问题，以提升低秩近似和最小二乘回归等任务的效率。

Method: 论文采用OSI（无意识子空间注入）属性作为分析框架，将算法分析与随机矩阵性质分离，首先在OSI假设下分析标准随机算法，然后验证多种随机矩阵模型满足OSI属性。

Result: 理论分析表明，结构化随机矩阵能显著加速线性代数任务，实验验证了其在合成问题和实际科学应用中的优异性能。

Conclusion: 该论文通过引入OSI属性，为结构化降维提供了新的理论基础，并展示了多种OSI实例，证明了结构化随机矩阵在加速线性代数任务中的有效性。

Abstract: To achieve the greatest possible speed, practitioners regularly implement
randomized algorithms for low-rank approximation and least-squares regression
with structured dimension reduction maps. Despite significant research effort,
basic questions remain about the design and analysis of randomized linear
algebra algorithms that employ structured random matrices.
  This paper develops a new perspective on structured dimension reduction,
based on the oblivious subspace injection (OSI) property. The OSI property is a
relatively weak assumption on a random matrix that holds when the matrix
preserves the length of vectors on average and, with high probability, does not
annihilate any vector in a low-dimensional subspace. With the OSI abstraction,
the analysis of a randomized linear algebra algorithm factors into two parts:
(i) proving that the algorithm works when implemented with an OSI; and (ii)
proving that a given random matrix model has the OSI property.
  This paper develops both parts of the program. First, it analyzes standard
randomized algorithms for low-rank approximation and least-squares regression
under the OSI assumption. Second, it identifies many examples of OSIs,
including random sparse matrices, randomized trigonometric transforms, and
random matrices with tensor product structure. These theoretical results imply
faster, near-optimal runtimes for several fundamental linear algebra tasks. The
paper also provides guidance on implementation, along with empirical evidence
that structured random matrices offer exemplary performance for a range of
synthetic problems and contemporary scientific applications.

</details>


### [100] [$Δ$-Motif: Subgraph Isomorphism at Scale via Data-Centric](https://arxiv.org/abs/2508.21287)
*Yulun Wang,Esteban Ginez,Jamie Friel,Yuval Baum,Jin-Sung Kim,Alex Shih,Oded Green*

Main category: cs.DS

TL;DR: $\Delta$-Motif是一种基于数据库操作的GPU加速子图同构算法，通过表格化表示和并行化操作，性能提升显著，适用于量子计算等领域。


<details>
  <summary>Details</summary>
Motivation: 传统回溯算法（如VF2）存在并行瓶颈，无法充分利用现代硬件。$\Delta$-Motif旨在通过数据库操作重新定义子图同构，提升性能并简化编程。

Method: $\Delta$-Motif将数据和模式图表示为表格形式，利用数据库操作（如连接、排序、合并和过滤）进行子图同构。通过分解图为小模块（motif）并系统组合，结合NVIDIA RAPIDS和Pandas框架实现并行化。

Result: $\Delta$-Motif在GPU上实现了高达$595\\times$的加速，显著优于VF2等传统算法，并在量子电路编译中验证了其实际应用价值。

Conclusion: $\Delta$-Motif通过将子图同构问题转化为数据库操作，显著提升了性能，并在量子电路编译等应用中展示了其价值，为高性能图处理提供了可访问的解决方案。

Abstract: Subgraph isomorphism is a fundamental problem in graph analysis that seeks to
find all instances of a pattern graph within a larger data graph while
preserving structural relationships. This NP-complete problem is central to
domains such as biological network analysis, social network mining, and quantum
circuit optimization. Traditional approaches rely on backtracking algorithms
like VF2, which suffer from sequential bottlenecks that limit their ability to
exploit modern parallel hardware. In this work, we introduce $\Delta$-Motif, a
GPU-accelerated subgraph isomorphism algorithm that reformulates the task
through the lens of database operations. Our key insight is to represent both
data and pattern graphs in tabular form, turning subgraph isomorphism into
database primitives including joins, sorts, merges, and filters. $\Delta$-Motif
decomposes graphs into small building blocks called motifs and systematically
combines them using scalable relational operations. By leveraging mature,
optimized libraries from the NVIDIA RAPIDS ecosystem and Pandas framework, our
solution achieves massive parallelism while remaining portable across systems
supporting standard relational primitives. Benchmarks show that $\Delta$-Motif
outperforms established algorithms like VF2, achieving speedups of up to
$595\times$ on GPUs. We further demonstrate its impact by applying it to
quantum circuit compilation, addressing a critical bottleneck in quantum
computing and enabling scaling to near- and medium-term devices. Our approach
democratizes high-performance graph processing by exposing it through familiar
database abstractions, eliminating the need for low-level programming while
delivering exceptional computational efficiency.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [101] [A Combined Push-Pull Access Framework for Digital Twin Alignment and Anomaly Reporting](https://arxiv.org/abs/2508.21516)
*Federico Chiariotti,Fabio Saggese,Andrea Munari,Leonardo Badia,Petar Popovski*

Main category: cs.NI

TL;DR: 提出推拉调度器（PPS）框架，优化数字孪生同步资源分配，显著降低信息过时并提升异常检测效率。


<details>
  <summary>Details</summary>
Motivation: 数字孪生的准确性依赖于与物理系统的实时同步，但现有方法在资源分配和异常检测效率上存在不足。

Method: 设计了推拉调度器（PPS）媒体访问框架，动态分配用于拉更新和推更新的通信资源。

Result: PPS框架将信息过时（AoII）降低了20%以上，并在1毫秒平均漂移AoII约束下，将最坏情况异常检测AoII从70毫秒降至20毫秒。

Conclusion: 本文提出的推拉调度器（PPS）框架在数字孪生（DT）同步中有效平衡了资源使用和信息准确性，显著降低了信息过时（AoII）并优化了异常检测性能。

Abstract: A digital twin (DT) contains a set of virtual models of real systems and
processes that are synchronized to their physical counterparts. This enables
experimentation and examination of counterfactuals, simulating the consequences
of decisions in real time. However, the DT accuracy relies on timely updates
that maintain alignment with the real system. We can distinguish between: (i)
pull-updates, which follow a request from the DT to the sensors, to decrease
its drift from the physical state; (ii) push-updates, which are sent directly
by the sensors since they represent urgent information, such as anomalies. In
this work, we devise a push-pull scheduler (PPS) medium access framework, which
dynamically allocates the communication resources used for these two types of
updates. Our scheme strikes a balance in the trade-off between DT alignment in
normal conditions and anomaly reporting, optimizing resource usage and reducing
the drift age of incorrect information (AoII) by over 20% with respect to
state-of-the-art solutions, while maintaining the same anomaly detection
guarantees, as well as reducing the worst-case anomaly detection AoII from 70
ms to 20 ms when considering a 1 ms average drift AoII constraint.

</details>


### [102] [QoS-Aware Proportional Fairness Scheduling for Multi-Flow 5G UEs: A Smart Factory Perspective](https://arxiv.org/abs/2508.21783)
*Mohamed Seliem,Utz Roedig,Cormac Sreenan,Dirk Pesch*

Main category: cs.NI

TL;DR: 扩展Simu5G支持每QFI建模，提出QoS-PF调度器优化资源分配，提升智能工厂中的QoS表现。


<details>
  <summary>Details</summary>
Motivation: 现有模拟框架缺乏在QFI级别建模多流行为的能力，而智能工厂中的设备需要处理具有不同QoS要求的并发流量。

Method: 扩展Simu5G以支持每QFI建模，并设计QoS-PF调度器，动态平衡延迟、GBR和优先级指标。

Result: 在智能工厂场景中，QoS-PF调度器提高了截止时间遵守率和公平性，同时不影响吞吐量。

Conclusion: 本文通过扩展Simu5G以支持每QFI建模，并引入新型QoS-PF调度器，为工业5G部署中高级QoS策略的模拟和分析提供了方法论和架构基础。

Abstract: Private 5G networks are emerging as key enablers for smart factories, where a
single device often handles multiple concurrent traffic flows with distinct
Quality of Service (QoS) requirements. Existing simulation frameworks, however,
lack the fidelity to model such multi-flow behavior at the QoS Flow Identifier
(QFI) level. This paper addresses this gap by extending Simu5G to support
per-QFI modeling and by introducing a novel QoS-aware Proportional Fairness
(QoS-PF) scheduler. The scheduler dynamically balances delay, Guaranteed Bit
Rate (GBR), and priority metrics to optimize resource allocation across
heterogeneous flows. We evaluate the proposed approach in a realistic smart
factory scenario featuring edge-hosted machine vision, real-time control loops,
and bulk data transfer. Results show that QoS-PF improves deadline adherence
and fairness without compromising throughput. All extensions are implemented in
a modular and open-source manner to support future research. Our work provides
both a methodological and architectural foundation for simulating and analyzing
advanced QoS policies in industrial 5G deployments.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [103] [EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control](https://arxiv.org/abs/2508.21112)
*Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang*

Main category: cs.RO

TL;DR: EO-Robotics introduces EO-1, a unified embodied model, and EO-Data1.5M, achieving superior multimodal reasoning and robot control through interleaved training.


<details>
  <summary>Details</summary>
Motivation: To bridge the gap between current vision-language-action models and human-level flexibility in interleaved reasoning and interaction.

Method: EO-1 employs a unified architecture for multimodal inputs (image, text, video, action) and is trained via auto-regressive decoding and flow matching denoising on the EO-Data1.5M dataset.

Result: EO-1 achieves seamless robot action generation and multimodal embodied reasoning, validated through diverse long-horizon and dexterous manipulation tasks.

Conclusion: EO-Robotics, consisting of the EO-1 model and EO-Data1.5M dataset, demonstrates superior performance in multimodal embodied reasoning and robot control through interleaved vision-text-action pre-training, offering insights for advanced embodied foundation models.

Abstract: The human ability to seamlessly perform multimodal reasoning and physical
interaction in the open world is a core goal for general-purpose embodied
intelligent systems. Recent vision-language-action (VLA) models, which are
co-trained on large-scale robot and visual-text data, have demonstrated notable
progress in general robot control. However, they still fail to achieve
human-level flexibility in interleaved reasoning and interaction. In this work,
introduce EO-Robotics, consists of EO-1 model and EO-Data1.5M dataset. EO-1 is
a unified embodied foundation model that achieves superior performance in
multimodal embodied reasoning and robot control through interleaved
vision-text-action pre-training. The development of EO-1 is based on two key
pillars: (i) a unified architecture that processes multimodal inputs
indiscriminately (image, text, video, and action), and (ii) a massive,
high-quality multimodal embodied reasoning dataset, EO-Data1.5M, which contains
over 1.5 million samples with emphasis on interleaved vision-text-action
comprehension. EO-1 is trained through synergies between auto-regressive
decoding and flow matching denoising on EO-Data1.5M, enabling seamless robot
action generation and multimodal embodied reasoning. Extensive experiments
demonstrate the effectiveness of interleaved vision-text-action learning for
open-world understanding and generalization, validated through a variety of
long-horizon, dexterous manipulation tasks across multiple embodiments. This
paper details the architecture of EO-1, the data construction strategy of
EO-Data1.5M, and the training methodology, offering valuable insights for
developing advanced embodied foundation models.

</details>


### [104] [Observer Design for Optical Flow-Based Visual-Inertial Odometry with Almost-Global Convergence](https://arxiv.org/abs/2508.21163)
*Tarek Bouazza,Soulaimane Berkane,Minh-Duc Hua,Tarek Hamel*

Main category: cs.RO

TL;DR: 论文提出了一种结合光流和IMU的级联观测器架构，用于连续单目VIO，通过梯度下降算法提取速度方向，仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决连续单目视觉-惯性里程计中的速度和重力方向估计问题，通过融合光学流和IMU数据，提升估计精度和稳定性。

Method: 论文开发了一种梯度下降算法，用于从稀疏光流数据中提取速度方向，解决了单位球面上的约束最小化问题。此外，设计了一个互补观测器用于姿态估计。

Result: 仿真结果验证了所提算法的有效性，级联观测器架构表现出几乎全局渐近稳定性。

Conclusion: 该论文提出了一种新型级联观测器架构，通过结合光流和IMU测量，实现了连续单目视觉-惯性里程计（VIO）。该方案在全局指数稳定Riccati观测器下，通过融合光流测量中的速度方向信息与陀螺仪和加速度计数据，同时估计了体坐标系中的速度和重力方向。

Abstract: This paper presents a novel cascaded observer architecture that combines
optical flow and IMU measurements to perform continuous monocular
visual-inertial odometry (VIO). The proposed solution estimates body-frame
velocity and gravity direction simultaneously by fusing velocity direction
information from optical flow measurements with gyro and accelerometer data.
This fusion is achieved using a globally exponentially stable Riccati observer,
which operates under persistently exciting translational motion conditions. The
estimated gravity direction in the body frame is then employed, along with an
optional magnetometer measurement, to design a complementary observer on
$\mathbf{SO}(3)$ for attitude estimation. The resulting interconnected observer
architecture is shown to be almost globally asymptotically stable. To extract
the velocity direction from sparse optical flow data, a gradient descent
algorithm is developed to solve a constrained minimization problem on the unit
sphere. The effectiveness of the proposed algorithms is validated through
simulation results.

</details>


### [105] [Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)](https://arxiv.org/abs/2508.21205)
*Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham*

Main category: cs.RO

TL;DR: 提出了一种基于最优传输和模型预测控制的多机器人路径规划方法，确保非重叠轨迹并高效处理动态问题。


<details>
  <summary>Details</summary>
Motivation: 多机器人在共享空间中导航时，传统方法可能导致路径重叠和死锁，因此需要一种能同时优化路径分配和避免冲突的方法。

Method: 通过将空间离散化为K个单元，并应用最优传输理论，计算最优且非重叠的单元转移路径。对于不可避免的重叠轨迹和机器人动力学问题，引入了重新规划和模型预测控制。

Result: 提出的方法在最坏情况下需要O(K^3 log K)计算量，对于良好行为问题则为O(K^2 log K)，并能有效处理动态和重叠轨迹问题。

Conclusion: 本文提出了一种基于最优传输理论和模型预测控制的多机器人路径规划与调度新方法，确保了非重叠轨迹的计算效率。

Abstract: In this paper, we propose a novel methodology for path planning and
scheduling for multi-robot navigation that is based on optimal transport theory
and model predictive control. We consider a setup where $N$ robots are tasked
to navigate to $M$ targets in a common space with obstacles. Mapping robots to
targets first and then planning paths can result in overlapping paths that lead
to deadlocks. We derive a strategy based on optimal transport that not only
provides minimum cost paths from robots to targets but also guarantees
non-overlapping trajectories. We achieve this by discretizing the space of
interest into $K$ cells and by imposing a ${K\times K}$ cost structure that
describes the cost of transitioning from one cell to another. Optimal transport
then provides \textit{optimal and non-overlapping} cell transitions for the
robots to reach the targets that can be readily deployed without any scheduling
considerations. The proposed solution requires $\unicode{x1D4AA}(K^3\log K)$
computations in the worst-case and $\unicode{x1D4AA}(K^2\log K)$ for
well-behaved problems. To further accommodate potentially overlapping
trajectories (unavoidable in certain situations) as well as robot dynamics, we
show that a temporal structure can be integrated into optimal transport with
the help of \textit{replans} and \textit{model predictive control}.

</details>


### [106] [Uncertainty-Aware Ankle Exoskeleton Control](https://arxiv.org/abs/2508.21221)
*Fatima Mumtaza Tourk,Bishoy Galoaa,Sanat Shajan,Aaron J. Young,Michael Everett,Max K. Shepherd*

Main category: cs.RO

TL;DR: 提出了一种不确定性感知控制框架，使踝关节外骨骼能够安全地适应多样化场景，通过自动脱离不熟悉的运动来实现。


<details>
  <summary>Details</summary>
Motivation: 当前外骨骼控制器的设计局限于受控环境中的离散预定义动作，限制了其在现实世界的适用性。

Method: 使用不确定性估计器对运动进行分类，评估了三种架构（模型集成、自动编码器和生成对抗网络），并在在线测试中验证了最佳架构（步态相位估计器集成）。

Result: 在线测试表明，不确定性估计器能够根据用户在分布内和分布外任务之间的切换来开启和关闭辅助功能（F1: 89.2）。

Conclusion: 新的控制框架为外骨骼在非结构化日常环境中安全自主地支持人类运动提供了路径。

Abstract: Lower limb exoskeletons show promise to assist human movement, but their
utility is limited by controllers designed for discrete, predefined actions in
controlled environments, restricting their real-world applicability. We present
an uncertainty-aware control framework that enables ankle exoskeletons to
operate safely across diverse scenarios by automatically disengaging when
encountering unfamiliar movements. Our approach uses an uncertainty estimator
to classify movements as similar (in-distribution) or different
(out-of-distribution) relative to actions in the training set. We evaluated
three architectures (model ensembles, autoencoders, and generative adversarial
networks) on an offline dataset and tested the strongest performing
architecture (ensemble of gait phase estimators) online. The online test
demonstrated the ability of our uncertainty estimator to turn assistance on and
off as the user transitioned between in-distribution and out-of-distribution
tasks (F1: 89.2). This new framework provides a path for exoskeletons to safely
and autonomously support human movement in unstructured, everyday environments.

</details>


### [107] [Remarks on stochastic cloning and delayed-state filtering](https://arxiv.org/abs/2508.21260)
*Tara Mina,Lindsey Marinello,John Christian*

Main category: cs.RO

TL;DR: 本文证明延迟状态卡尔曼滤波器在不扩展状态的情况下，能实现与随机克隆相同的效果，且计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 许多机器人和导航中的估计问题涉及依赖于先前状态的测量，如里程计。准确处理这些延迟状态测量需要捕获它们与先前状态估计的关联。

Method: 本文重新审视了一种长期存在但经常被忽视的替代方法——延迟状态卡尔曼滤波器，并展示了其在不需状态扩展的情况下，能够产生与随机克隆（SC）相同的状态和协方差更新。

Result: 研究发现，正确推导的延迟状态卡尔曼滤波器不仅计算效率更高，还能减少高维状态的内存需求。

Conclusion: 本文澄清了一个常见的误解，即卡尔曼滤波器变体本质上无法处理相关的延迟状态测量，证明了通过替代公式可以更高效地实现相同的结果。

Abstract: Many estimation problems in robotics and navigation involve measurements that
depend on prior states. A prominent example is odometry, which measures the
relative change between states over time. Accurately handling these
delayed-state measurements requires capturing their correlations with prior
state estimates, and a widely used approach is stochastic cloning (SC), which
augments the state vector to account for these correlations.
  This work revisits a long-established but often overlooked alternative--the
delayed-state Kalman filter--and demonstrates that a properly derived filter
yields exactly the same state and covariance update as SC, without requiring
state augmentation. Moreover, the generalized Kalman filter formulation
provides computational advantages, while also reducing memory requirements for
higher-dimensional states.
  Our findings clarify a common misconception that Kalman filter variants are
inherently unable to handle correlated delayed-state measurements,
demonstrating that an alternative formulation achieves the same results more
efficiently.

</details>


### [108] [Mini Autonomous Car Driving based on 3D Convolutional Neural Networks](https://arxiv.org/abs/2508.21271)
*Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando*

Main category: cs.RO

TL;DR: 本文提出了一种基于3D CNN的自动驾驶方法，在模拟环境中优于RNN，尤其在任务完成和驾驶一致性方面表现更佳。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶应用在汽车行业中的重要性日益增加，但开发可靠系统面临高复杂性、长训练周期和不确定性等挑战。

Method: 基于RGB-D信息和三维卷积神经网络（3D CNN）的方法，用于Mini Autonomous Cars（MACs）的自动驾驶。

Result: 3D CNN在模拟赛道上表现出比RNN更好的泛化能力和车辆控制性能。

Conclusion: 提出的3D CNN方法在模拟环境中表现出比RNN更好的性能，尤其在任务完成成功率、圈速和驾驶一致性方面。

Abstract: Autonomous driving applications have become increasingly relevant in the
automotive industry due to their potential to enhance vehicle safety,
efficiency, and user experience, thereby meeting the growing demand for
sophisticated driving assistance features. However, the development of reliable
and trustworthy autonomous systems poses challenges such as high complexity,
prolonged training periods, and intrinsic levels of uncertainty. Mini
Autonomous Cars (MACs) are used as a practical testbed, enabling validation of
autonomous control methodologies on small-scale setups. This simplified and
cost-effective environment facilitates rapid evaluation and comparison of
machine learning models, which is particularly useful for algorithms requiring
online training. To address these challenges, this work presents a methodology
based on RGB-D information and three-dimensional convolutional neural networks
(3D CNNs) for MAC autonomous driving in simulated environments. We evaluate the
proposed approach against recurrent neural networks (RNNs), with architectures
trained and tested on two simulated tracks with distinct environmental
features. Performance was assessed using task completion success, lap-time
metrics, and driving consistency. Results highlight how architectural
modifications and track complexity influence the models' generalization
capability and vehicle control performance. The proposed 3D CNN demonstrated
promising results when compared with RNNs.

</details>


### [109] [Learning to Assemble the Soma Cube with Legal-Action Masked DQN and Safe ZYZ Regrasp on a Doosan M0609](https://arxiv.org/abs/2508.21272)
*Jaehong Oh,Seungjun Jung,Sawoong Kim*

Main category: cs.RO

TL;DR: 首次将约束感知强化学习与奇点安全运动规划结合，采用法律行动掩码DQN和课程学习，显著提升协作机器人在Soma立方体组装任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决机器人操作中的组合动作空间爆炸、不安全运动规划和系统组装策略学习等关键挑战。

Method: 采用法律行动掩码深度Q网络（DQN）与层次架构，将Q函数估计分解为方向和位置组件，从而降低计算复杂度。同时，结合机器人友好的奖励函数和渐进式难度级别的课程学习。

Result: 在三个渐进难度级别（2块、3块、7块）上取得了显著训练效率：1级500次训练后成功率100%，2级92.9%，3级39.9%。

Conclusion: 该论文成功展示了将约束感知强化学习与奇点安全运动规划相结合的方法，显著提高了协作机器人在自主组装Soma立方体任务中的效率和成功率。

Abstract: This paper presents the first comprehensive application of legal-action
masked Deep Q-Networks with safe ZYZ regrasp strategies to an underactuated
gripper-equipped 6-DOF collaborative robot for autonomous Soma cube assembly
learning. Our approach represents the first systematic integration of
constraint-aware reinforcement learning with singularity-safe motion planning
on a Doosan M0609 collaborative robot. We address critical challenges in
robotic manipulation: combinatorial action space explosion, unsafe motion
planning, and systematic assembly strategy learning. Our system integrates a
legal-action masked DQN with hierarchical architecture that decomposes
Q-function estimation into orientation and position components, reducing
computational complexity from $O(3,132)$ to $O(116) + O(27)$ while maintaining
solution completeness. The robot-friendly reward function encourages
ground-first, vertically accessible assembly sequences aligned with
manipulation constraints. Curriculum learning across three progressive
difficulty levels (2-piece, 3-piece, 7-piece) achieves remarkable training
efficiency: 100\% success rate for Level 1 within 500 episodes, 92.9\% for
Level 2, and 39.9\% for Level 3 over 105,300 total training episodes.

</details>


### [110] [Observability-driven Assignment of Heterogeneous Sensors for Multi-Target Tracking](https://arxiv.org/abs/2508.21309)
*Seyed Ali Rakhshan,Mehdi Golestani,He Kong*

Main category: cs.RO

TL;DR: 提出了一种基于拟阵理论的贪婪算法，用于异构传感器对多目标的动态分配，优化跟踪质量并验证其性能接近最优。


<details>
  <summary>Details</summary>
Motivation: 解决异构传感器（具有不同感知能力的机器人）在多目标跟踪中的分配挑战，优化跟踪质量。

Method: 利用拟阵理论，提出了一种动态分配机器人到目标的贪婪算法，以最大化跟踪质量。

Result: 算法在任意跟踪质量函数下具有1/3的近似保证，对于子模函数具有1/2的近似保证，且保持了多项式时间复杂度。仿真结果验证了算法的有效性和鲁棒性。

Conclusion: 该论文提出了一种基于拟阵理论的贪婪分配算法，能够有效优化异构传感器（机器人）对多目标的跟踪质量，并通过仿真验证了其接近最优分配的性能。

Abstract: This paper addresses the challenge of assigning heterogeneous sensors (i.e.,
robots with varying sensing capabilities) for multi-target tracking. We
classify robots into two categories: (1) sufficient sensing robots, equipped
with range and bearing sensors, capable of independently tracking targets, and
(2) limited sensing robots, which are equipped with only range or bearing
sensors and need to at least form a pair to collaboratively track a target. Our
objective is to optimize tracking quality by minimizing uncertainty in target
state estimation through efficient robot-to-target assignment. By leveraging
matroid theory, we propose a greedy assignment algorithm that dynamically
allocates robots to targets to maximize tracking quality. The algorithm
guarantees constant-factor approximation bounds of 1/3 for arbitrary tracking
quality functions and 1/2 for submodular functions, while maintaining
polynomial-time complexity. Extensive simulations demonstrate the algorithm's
effectiveness in accurately estimating and tracking targets over extended
periods. Furthermore, numerical results confirm that the algorithm's
performance is close to that of the optimal assignment, highlighting its
robustness and practical applicability.

</details>


### [111] [Robust Real-Time Coordination of CAVs: A Distributed Optimization Framework under Uncertainty](https://arxiv.org/abs/2508.21322)
*Haojie Bai,Yang Wang,Cong Guo,Xiongwei Zhao,Hai Zhu*

Main category: cs.RO

TL;DR: 该论文提出了一种新型车辆协调框架，通过直接控制轨迹分布、ADMM-DTN算法和交互注意力机制，显著提升了安全性和实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态和不确定环境中车辆协调的安全性和实时性能挑战。

Method: 提出了一个新颖的协调框架，包括直接控制车辆轨迹分布、ADMM-DTN算法和交互注意力机制。

Result: 仿真和实际实验表明，框架在安全性（碰撞率降低40.79%）和实时性能上表现优异，计算需求减少14.1%。

Conclusion: 该框架在安全和实时性能上显著优于现有方法，并在复杂环境中展示了强大的协调能力。

Abstract: Achieving both safety guarantees and real-time performance in cooperative
vehicle coordination remains a fundamental challenge, particularly in dynamic
and uncertain environments. This paper presents a novel coordination framework
that resolves this challenge through three key innovations: 1) direct control
of vehicles' trajectory distributions during coordination, formulated as a
robust cooperative planning problem with adaptive enhanced safety constraints,
ensuring a specified level of safety regarding the uncertainty of the
interactive trajectory, 2) a fully parallel ADMM-based distributed trajectory
negotiation (ADMM-DTN) algorithm that efficiently solves the optimization
problem while allowing configurable negotiation rounds to balance solution
quality and computational resources, and 3) an interactive attention mechanism
that selectively focuses on critical interactive participants to further
enhance computational efficiency. Both simulation results and practical
experiments demonstrate that our framework achieves significant advantages in
safety (reducing collision rates by up to 40.79\% in various scenarios) and
real-time performance compared to state-of-the-art methods, while maintaining
strong scalability with increasing vehicle numbers. The proposed interactive
attention mechanism further reduces the computational demand by 14.1\%. The
framework's effectiveness is further validated through real-world experiments
with unexpected dynamic obstacles, demonstrating robust coordination in complex
environments. The experiment demo could be found at
https://youtu.be/4PZwBnCsb6Q.

</details>


### [112] [Multi-Modal Model Predictive Path Integral Control for Collision Avoidance](https://arxiv.org/abs/2508.21364)
*Alberto Bertipaglia,Dariu M. Gavrila,Barys Shyrokau*

Main category: cs.RO

TL;DR: 该论文提出了一种多模态模型预测路径积分控制算法，用于自动驾驶车辆的路径规划和决策，通过多样化轨迹探索和摩擦圆约束，显著提高了避障能力和车辆稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶车辆在复杂环境中的路径规划和决策问题，避免单一解决方案的局限性，提高避障能力和车辆稳定性。

Method: 采用多模态模型预测路径积分控制算法，结合Sobol序列采样和碰撞避免的解析解，探索多样化轨迹（如绕过障碍物或安全停车）。使用非线性单轨车辆模型和Fiala轮胎作为预测模型，并强制执行摩擦圆内的轮胎力约束。

Result: 在高保真模拟环境中，该算法成功避免了障碍物，在高低摩擦路面和移动障碍物遮挡场景下保持车辆稳定，尤其在双车道变换操作中表现优异。

Conclusion: 该论文提出的多模态模型预测路径积分控制算法在自动驾驶车辆的路径规划和决策中表现出色，能够有效避免障碍物并保持车辆稳定性，优于标准模型预测路径积分方法。

Abstract: This paper proposes a novel approach to motion planning and decision-making
for automated vehicles, using a multi-modal Model Predictive Path Integral
control algorithm. The method samples with Sobol sequences around the prior
input and incorporates analytical solutions for collision avoidance. By
leveraging multiple modes, the multi-modal control algorithm explores diverse
trajectories, such as manoeuvring around obstacles or stopping safely before
them, mitigating the risk of sub-optimal solutions. A non-linear single-track
vehicle model with a Fiala tyre serves as the prediction model, and tyre force
constraints within the friction circle are enforced to ensure vehicle stability
during evasive manoeuvres. The optimised steering angle and longitudinal
acceleration are computed to generate a collision-free trajectory and to
control the vehicle. In a high-fidelity simulation environment, we demonstrate
that the proposed algorithm can successfully avoid obstacles, keeping the
vehicle stable while driving a double lane change manoeuvre on high and
low-friction road surfaces and occlusion scenarios with moving obstacles,
outperforming a standard Model Predictive Path Integral approach.

</details>


### [113] [Dynamics-Compliant Trajectory Diffusion for Super-Nominal Payload Manipulation](https://arxiv.org/abs/2508.21375)
*Anuj Pasricha,Joewie Koh,Jay Vakil,Alessandro Roncone*

Main category: cs.RO

TL;DR: 本文提出了一种基于去噪扩散模型的轨迹生成方法，显著提高了机器人在高载荷下的工作空间利用率，实验证明可达标称容量3倍且67.6%工作空间可访问。


<details>
  <summary>Details</summary>
Motivation: 传统方法基于最坏情况配置推导有效载荷额定值，导致机器人能力未被充分利用。本文旨在通过更细致地考虑有效载荷动态，提高机器人的操作能力。

Method: 使用去噪扩散模型生成动态可行的关节空间轨迹，直接在物理硬件上执行，无需后处理。与传统采样、优化或运动规划方法相比，该方法在恒定时间内生成轨迹。

Result: 实验验证表明，在7自由度Franka Emika Panda机器人上，即使有效载荷超过标称容量3倍，仍有67.6%的工作空间可访问。

Conclusion: 本文提出了一种新的轨迹生成方法，通过去噪扩散模型将有效载荷约束纳入规划过程，显著提高了机器人在工作空间中的操作能力。实验证明，即使在有效载荷超过标称容量3倍的情况下，仍有67.6%的工作空间可访问。

Abstract: Nominal payload ratings for articulated robots are typically derived from
worst-case configurations, resulting in uniform payload constraints across the
entire workspace. This conservative approach severely underutilizes the robot's
inherent capabilities -- our analysis demonstrates that manipulators can safely
handle payloads well above nominal capacity across broad regions of their
workspace while staying within joint angle, velocity, acceleration, and torque
limits. To address this gap between assumed and actual capability, we propose a
novel trajectory generation approach using denoising diffusion models that
explicitly incorporates payload constraints into the planning process. Unlike
traditional sampling-based methods that rely on inefficient trial-and-error,
optimization-based methods that are prohibitively slow, or kinodynamic planners
that struggle with problem dimensionality, our approach generates dynamically
feasible joint-space trajectories in constant time that can be directly
executed on physical hardware without post-processing. Experimental validation
on a 7 DoF Franka Emika Panda robot demonstrates that up to 67.6% of the
workspace remains accessible even with payloads exceeding 3 times the nominal
capacity. This expanded operational envelope highlights the importance of a
more nuanced consideration of payload dynamics in motion planning algorithms.

</details>


### [114] [RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation](https://arxiv.org/abs/2508.21378)
*Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu*

Main category: cs.RO

TL;DR: RoboInspector analyzes and improves reliability in LLM-generated robotic policy code, identifying key failure behaviors and boosting performance by 35%.


<details>
  <summary>Details</summary>
Motivation: Achieving reliable policy code generation in LLM-enabled robotic manipulation is challenging due to diverse real-world task requirements and varying user instructions.

Method: Design of RoboInspector, a pipeline to analyze unreliability from task complexity and instruction granularity perspectives, with comprehensive experiments across 168 task, instruction, and LLM combinations.

Result: Identified four main unreliable behaviors leading to manipulation failure, characterized their causes, and demonstrated a refinement approach improving reliability by up to 35%.

Conclusion: RoboInspector successfully identifies and characterizes unreliable behaviors in policy code generation for LLM-enabled robotic manipulation, offering a refinement approach that improves reliability by up to 35%.

Abstract: Large language models (LLMs) demonstrate remarkable capabilities in reasoning
and code generation, enabling robotic manipulation to be initiated with just a
single instruction. The LLM carries out various tasks by generating policy code
required to control the robot. Despite advances in LLMs, achieving reliable
policy code generation remains a significant challenge due to the diverse
requirements of real-world tasks and the inherent complexity of user
instructions. In practice, different users may provide distinct instructions to
drive the robot for the same task, which may cause the unreliability of policy
code generation. To bridge this gap, we design RoboInspector, a pipeline to
unveil and characterize the unreliability of the policy code for LLM-enabled
robotic manipulation from two perspectives: the complexity of the manipulation
task and the granularity of the instruction. We perform comprehensive
experiments with 168 distinct combinations of tasks, instructions, and LLMs in
two prominent frameworks. The RoboInspector identifies four main unreliable
behaviors that lead to manipulation failure. We provide a detailed
characterization of these behaviors and their underlying causes, giving insight
for practical development to reduce unreliability. Furthermore, we introduce a
refinement approach guided by failure policy code feedback that improves the
reliability of policy code generation by up to 35% in LLM-enabled robotic
manipulation, evaluated in both simulation and real-world environments.

</details>


### [115] [Assessing Human Cooperation for Enhancing Social Robot Navigation](https://arxiv.org/abs/2508.21455)
*Hariharan Arunachalam,Phani Teja Singamaneni,Rachid Alami*

Main category: cs.RO

TL;DR: 研究提出通过几何分析和人类合作性评估，在机器人导航中实现适时沟通，以解决交互中的意图不明问题。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航中因人类行为意外或意图不明导致的交互困难，提升机器人与人类在导航场景中的协作效率。

Method: 基于几何分析和人类合作性评估，提出了一种评估方法论和评价指标，并展示了如何利用几何推理生成适当的语言回应或机器人动作。

Result: 提出了一套评估人类合作性的方法和评价指标，以及基于几何推理的沟通策略，有效改善了机器人导航中的交互问题。

Conclusion: 通过几何分析和人类合作性评估，本研究提出了一种在机器人导航中适时有效沟通的方法，以解决因意图不明导致的交互问题。

Abstract: Socially aware robot navigation is a planning paradigm where the robot
navigates in human environments and tries to adhere to social constraints while
interacting with the humans in the scene. These navigation strategies were
further improved using human prediction models, where the robot takes the
potential future trajectory of humans while computing its own. Though these
strategies significantly improve the robot's behavior, it faces difficulties
from time to time when the human behaves in an unexpected manner. This happens
as the robot fails to understand human intentions and cooperativeness, and the
human does not have a clear idea of what the robot is planning to do. In this
paper, we aim to address this gap through effective communication at an
appropriate time based on a geometric analysis of the context and human
cooperativeness in head-on crossing scenarios. We provide an assessment
methodology and propose some evaluation metrics that could distinguish a
cooperative human from a non-cooperative one. Further, we also show how
geometric reasoning can be used to generate appropriate verbal responses or
robot actions.

</details>


### [116] [Few-Shot Neuro-Symbolic Imitation Learning for Long-Horizon Planning and Acting](https://arxiv.org/abs/2508.21501)
*Pierrick Lorang,Hong Lu,Johannes Huemer,Patrik Zips,Matthias Scheutz*

Main category: cs.RO

TL;DR: 提出了一种神经符号框架，结合符号抽象和扩散策略模仿学习，显著提升模仿学习在长视野任务和泛化中的表现，仅需少量演示即可高效学习。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法在长视野任务、跨任务泛化和数据效率方面存在局限，需要一种更高效且通用的方法。

Method: 该方法将高级任务结构抽象为图，通过Answer Set Programming求解器发现符号规则，并使用扩散策略模仿学习训练低级控制器。高层筛选器聚焦于最小化的观察和动作空间。

Result: 在六个领域（包括四个机械臂环境和两个自动化叉车环境）中验证，仅需五个技能演示即可实现高数据效率、强零样本和少样本泛化能力，以及可解释的决策。

Conclusion: 该论文提出的神经符号框架通过结合符号域抽象和连续控制策略，显著提高了模仿学习在长视野任务和跨任务泛化中的表现。

Abstract: Imitation learning enables intelligent systems to acquire complex behaviors
with minimal supervision. However, existing methods often focus on
short-horizon skills, require large datasets, and struggle to solve
long-horizon tasks or generalize across task variations and distribution
shifts. We propose a novel neuro-symbolic framework that jointly learns
continuous control policies and symbolic domain abstractions from a few skill
demonstrations. Our method abstracts high-level task structures into a graph,
discovers symbolic rules via an Answer Set Programming solver, and trains
low-level controllers using diffusion policy imitation learning. A high-level
oracle filters task-relevant information to focus each controller on a minimal
observation and action space. Our graph-based neuro-symbolic framework enables
capturing complex state transitions, including non-spatial and temporal
relations, that data-driven learning or clustering techniques often fail to
discover in limited demonstration datasets. We validate our approach in six
domains that involve four robotic arms, Stacking, Kitchen, Assembly, and Towers
of Hanoi environments, and a distinct Automated Forklift domain with two
environments. The results demonstrate high data efficiency with as few as five
skill demonstrations, strong zero- and few-shot generalizations, and
interpretable decision making.

</details>


### [117] [Estimated Informed Anytime Search for Sampling-Based Planning via Adaptive Sampler](https://arxiv.org/abs/2508.21549)
*Liding Zhang,Kuanqi Cai,Yu Zhang,Zhenshan Bing,Chaoqun Wang,Fan Wu,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: MIT*是一种新型路径规划器，通过估计信息集和自适应采样策略，提高了路径规划的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的信息采样规划器在未找到解时需要重新采样整个配置空间，耗时且计算成本高。

Method: MIT*采用自适应采样器和长度相关的自适应稀疏碰撞检查，动态调整采样策略并指导懒惰反向搜索。

Result: 通过仿真和实际实验验证，MIT*在R^4到R^16的问题上优于现有单查询采样规划器，并成功应用于实际机器人操作任务。

Conclusion: MIT*是一种新型路径规划器，通过构建基于先验可接受解成本的估计信息集，显著提高了初始收敛速度，并在受限场景中保持了高成功率。

Abstract: Path planning in robotics often involves solving continuously valued,
high-dimensional problems. Popular informed approaches include graph-based
searches, such as A*, and sampling-based methods, such as Informed RRT*, which
utilize informed set and anytime strategies to expedite path optimization
incrementally. Informed sampling-based planners define informed sets as subsets
of the problem domain based on the current best solution cost. However, when no
solution is found, these planners re-sample and explore the entire
configuration space, which is time-consuming and computationally expensive.
This article introduces Multi-Informed Trees (MIT*), a novel planner that
constructs estimated informed sets based on prior admissible solution costs
before finding the initial solution, thereby accelerating the initial
convergence rate. Moreover, MIT* employs an adaptive sampler that dynamically
adjusts the sampling strategy based on the exploration process. Furthermore,
MIT* utilizes length-related adaptive sparse collision checks to guide lazy
reverse search. These features enhance path cost efficiency and computation
times while ensuring high success rates in confined scenarios. Through a series
of simulations and real-world experiments, it is confirmed that MIT*
outperforms existing single-query, sampling-based planners for problems in R^4
to R^16 and has been successfully applied to real-world robot manipulation
tasks. A video showcasing our experimental results is available at:
https://youtu.be/30RsBIdexTU

</details>


### [118] [Learning Agile Gate Traversal via Analytical Optimal Policy Gradient](https://arxiv.org/abs/2508.21592)
*Tianchen Sun,Bingheng Wang,Longbin Tang,Yichao Gao,Lin Zhao*

Main category: cs.RO

TL;DR: 提出混合框架，通过离线训练神经网络在线调整MPC参数，显著提升四旋翼门框穿越效率和样本效率。


<details>
  <summary>Details</summary>
Motivation: 传统模块化自主飞行堆栈需要大量设计和参数调优，而端到端强化学习方法样本效率低且可解释性有限，因此需要一种更高效且可解释的解决方案。

Method: 提出了一种新颖的混合框架，通过离线训练的神经网络在线自适应调整模型预测控制（MPC）参数，结合参考姿态和成本函数权重的联合预测，以及优化的门框穿越检测模块。

Result: 硬件实验表明，该方法能够在受限环境中实现快速准确的四旋翼门框穿越，样本效率相比端到端强化学习方法提升了数个数量级。

Conclusion: 该方法通过在线自适应调整MPC参数，结合神经网络预测，显著提高了四旋翼飞行器在狭窄门框中的穿越效率和精度，相比传统端到端强化学习方法，样本效率提升了数个数量级。

Abstract: Traversing narrow gates presents a significant challenge and has become a
standard benchmark for evaluating agile and precise quadrotor flight.
Traditional modularized autonomous flight stacks require extensive design and
parameter tuning, while end-to-end reinforcement learning (RL) methods often
suffer from low sample efficiency and limited interpretability. In this work,
we present a novel hybrid framework that adaptively fine-tunes model predictive
control (MPC) parameters online using outputs from a neural network (NN)
trained offline. The NN jointly predicts a reference pose and cost-function
weights, conditioned on the coordinates of the gate corners and the current
drone state. To achieve efficient training, we derive analytical policy
gradients not only for the MPC module but also for an optimization-based gate
traversal detection module. Furthermore, we introduce a new formulation of the
attitude tracking error that admits a simplified representation, facilitating
effective learning with bounded gradients. Hardware experiments demonstrate
that our method enables fast and accurate quadrotor traversal through narrow
gates in confined environments. It achieves several orders of magnitude
improvement in sample efficiency compared to naive end-to-end RL approaches.

</details>


### [119] [The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics](https://arxiv.org/abs/2508.21635)
*Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire*

Main category: cs.RO

TL;DR: 该研究发布了一个多模态农业机器人数据集，用于支持SLAM算法在复杂农业环境中的开发与测试，并展示了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 农业机器人环境中的自然光照变化、运动模糊、崎岖地形和长序列感知混叠等挑战需要多模态数据集来支持算法开发和基准测试。

Method: 使用多模态传感器（如立体红外相机、彩色相机、加速度计、陀螺仪、磁力计、GNSS和车轮里程计）收集数据，并设计平台和数据收集系统以满足多模态SLAM系统的评估需求。

Result: 在数据集上运行了多模态SLAM方法，展示了其在农业环境中的局限性。数据集和工具已公开。

Conclusion: 该数据集通过解决农业环境中的复杂问题，支持了农业机器人定位、建图、感知和导航算法的开发与基准测试。

Abstract: We present a multi-modal dataset collected in a soybean crop field,
comprising over two hours of recorded data from sensors such as stereo infrared
camera, color camera, accelerometer, gyroscope, magnetometer, GNSS (Single
Point Positioning, Real-Time Kinematic and Post-Processed Kinematic), and wheel
odometry. This dataset captures key challenges inherent to robotics in
agricultural environments, including variations in natural lighting, motion
blur, rough terrain, and long, perceptually aliased sequences. By addressing
these complexities, the dataset aims to support the development and
benchmarking of advanced algorithms for localization, mapping, perception, and
navigation in agricultural robotics. The platform and data collection system is
designed to meet the key requirements for evaluating multi-modal SLAM systems,
including hardware synchronization of sensors, 6-DOF ground truth and loops on
long trajectories.
  We run multimodal state-of-the art SLAM methods on the dataset, showcasing
the existing limitations in their application on agricultural settings. The
dataset and utilities to work with it are released on
https://cifasis.github.io/rosariov2/.

</details>


### [120] [Robust Convex Model Predictive Control with collision avoidance guarantees for robot manipulators](https://arxiv.org/abs/2508.21677)
*Bernhard Wullt,Johannes Köhler,Per Mattsson,Mikeal Norrlöf,Thomas B. Schön*

Main category: cs.RO

TL;DR: 提出了一种新型MPC解决方案，结合鲁棒管状MPC和走廊规划算法，实现了在模型不确定性环境下的快速安全运动规划，性能优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 工业机械臂在杂乱环境中运行时，模型不确定性增加了安全运动规划的难度，现有方法通常通过限制速度来减少干扰影响，但缺乏既能保证安全又能快速执行的控制方法。

Method: 采用鲁棒管状MPC和走廊规划算法，构建了一个凸优化的MPC问题，确保快速求解。

Result: 在模拟环境中，使用6自由度工业机器人在模型参数不确定的杂乱环境中测试，该方法在模型不确定性和运动速度方面均优于基准方法。

Conclusion: 本文提出了一种结合鲁棒管状MPC和走廊规划算法的新型模型预测控制（MPC）解决方案，能够在模型不确定性较高的环境中实现快速且安全的运动规划。

Abstract: Industrial manipulators are normally operated in cluttered environments,
making safe motion planning important. Furthermore, the presence of
model-uncertainties make safe motion planning more difficult. Therefore, in
practice the speed is limited in order to reduce the effect of disturbances.
There is a need for control methods that can guarantee safe motions that can be
executed fast. We address this need by suggesting a novel model predictive
control (MPC) solution for manipulators, where our two main components are a
robust tube MPC and a corridor planning algorithm to obtain collision-free
motion. Our solution results in a convex MPC, which we can solve fast, making
our method practically useful. We demonstrate the efficacy of our method in a
simulated environment with a 6 DOF industrial robot operating in cluttered
environments with uncertainties in model parameters. We outperform benchmark
methods, both in terms of being able to work under higher levels of model
uncertainties, while also yielding faster motion.

</details>


### [121] [Can a mobile robot learn from a pedestrian model to prevent the sidewalk salsa?](https://arxiv.org/abs/2508.21690)
*Olger Siebinga,David Abbink*

Main category: cs.RO

TL;DR: 研究利用强化学习代理与行人模型交互，以改进机器人行为设计，结果显示RL代理能有效降低风险并改善沟通。


<details>
  <summary>Details</summary>
Motivation: 研究行人之间的‘人行道萨尔萨舞’现象，以理解隐式沟通的失败机制，并将其应用于设计安全且可接受的机器人行为。

Method: 采用强化学习（RL）代理与基于Communication-Enabled Interaction（CEI）框架的行人模型进行交互。

Result: 基本RL代理成功学会了与CEI模型交互，而风险规避型RL代理通过动作有效传达了意图，显著降低了感知风险。

Conclusion: 通过强化学习（RL）代理与行人行为模型的交互，研究表明这是一种有前景的方法，能够有效降低感知风险并改善行人意图的沟通。

Abstract: Pedestrians approaching each other on a sidewalk sometimes end up in an
awkward interaction known as the "sidewalk salsa": they both (repeatedly)
deviate to the same side to avoid a collision. This provides an interesting use
case to study interactions between pedestrians and mobile robots because, in
the vast majority of cases, this phenomenon is avoided through a negotiation
based on implicit communication. Understanding how it goes wrong and how
pedestrians end up in the sidewalk salsa will therefore provide insight into
the implicit communication. This understanding can be used to design safe and
acceptable robotic behaviour. In a previous attempt to gain this understanding,
a model of pedestrian behaviour based on the Communication-Enabled Interaction
(CEI) framework was developed that can replicate the sidewalk salsa. However,
it is unclear how to leverage this model in robotic planning and
decision-making since it violates the assumptions of game theory, a much-used
framework in planning and decision-making. Here, we present a proof-of-concept
for an approach where a Reinforcement Learning (RL) agent leverages the model
to learn how to interact with pedestrians. The results show that a basic RL
agent successfully learned to interact with the CEI model. Furthermore, a
risk-averse RL agent that had access to the perceived risk of the CEI model
learned how to effectively communicate its intention through its motion and
thereby substantially lowered the perceived risk, and displayed effort by the
modelled pedestrian. These results show this is a promising approach and
encourage further exploration.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [122] [ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes](https://arxiv.org/abs/2508.21095)
*Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi*

Main category: cs.GR

TL;DR: 提出了一种无需骨骼、数据驱动的新框架，用于预测和转移未注册表面网格的运动，通过耦合运动嵌入网络和顶点特征场生成时空变形场。


<details>
  <summary>Details</summary>
Motivation: 未注册的表面网格（如原始3D扫描）由于缺乏点对应关系和存在噪声，导致自动计算合理变形具有挑战性。

Method: 结合鲁棒的运动嵌入网络和学习的顶点特征场，生成时空变形场以驱动网格变形。

Result: 在行走和跑步等任务上的定量基准和定性视觉评估证明了该方法的有效性和通用性。

Conclusion: 该方法在挑战性的未注册网格上展现了高效性和多功能性。

Abstract: Unregistered surface meshes, especially raw 3D scans, present significant
challenges for automatic computation of plausible deformations due to the lack
of established point-wise correspondences and the presence of noise in the
data. In this paper, we propose a new, rig-free, data-driven framework for
motion prediction and transfer on such body meshes. Our method couples a robust
motion embedding network with a learned per-vertex feature field to generate a
spatio-temporal deformation field, which drives the mesh deformation. Extensive
evaluations, including quantitative benchmarks and qualitative visuals on tasks
such as walking and running, demonstrate the effectiveness and versatility of
our approach on challenging unregistered meshes.

</details>


### [123] [ARGS: Advanced Regularization on Aligning Gaussians over the Surface](https://arxiv.org/abs/2508.21344)
*Jeong Uk Lee,Sung Hee Choi*

Main category: cs.GR

TL;DR: 该论文提出两种正则化策略（有效秩和神经SDF），以提升3D高斯泼溅数据的重建质量，生成更准确和连贯的3D视觉效果。


<details>
  <summary>Details</summary>
Motivation: 尽管现有模型（如SuGaR）在渲染方面提供了有效解决方案，但在视觉保真度和场景一致性方面仍有提升空间。本研究旨在通过改进高斯基元的形状和整体表面的连贯性，进一步提升3DGS数据的重建质量。

Method: 该研究在SuGaR模型基础上，提出了两种正则化策略：有效秩正则化和神经符号距离函数（SDF）正则化。前者通过鼓励更平衡的“盘状”高斯形状来避免极端各向异性，后者通过Eikonal损失保持SDF的距离特性，提供全局表面先验。

Result: 最终模型能够从3DGS数据生成更准确和连贯的视觉效果。

Conclusion: 通过引入两种互补的正则化策略，该研究显著提升了从3D高斯泼溅（3DGS）数据重建高质量3D网格和视觉效果的准确性和一致性。

Abstract: Reconstructing high-quality 3D meshes and visuals from 3D Gaussian
Splatting(3DGS) still remains a central challenge in computer graphics.
Although existing models such as SuGaR offer effective solutions for rendering,
there is is still room to improve improve both visual fidelity and scene
consistency. This work builds upon SuGaR by introducing two complementary
regularization strategies that address common limitations in both the shape of
individual Gaussians and the coherence of the overall surface. The first
strategy introduces an effective rank regularization, motivated by recent
studies on Gaussian primitive structures. This regularization discourages
extreme anisotropy-specifically, "needle-like" shapes-by favoring more
balanced, "disk-like" forms that are better suited for stable surface
reconstruction. The second strategy integrates a neural Signed Distance
Function (SDF) into the optimization process. The SDF is regularized with an
Eikonal loss to maintain proper distance properties and provides a continuous
global surface prior, guiding Gaussians toward better alignment with the
underlying geometry. These two regularizations aim to improve both the fidelity
of individual Gaussian primitives and their collective surface behavior. The
final model can make more accurate and coherent visuals from 3DGS data.

</details>
