<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 57]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.AI](#cs.AI) [Total: 15]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.SE](#cs.SE) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [2nd Place Solution for CVPR2024 E2E Challenge: End-to-End Autonomous Driving Using Vision Language Model](https://arxiv.org/abs/2509.02659)
*Zilong Guo,Yi Luo,Long Sha,Dongxu Wang,Panqu Wang,Chenyang Xu,Yi Yang*

Main category: cs.CV

TL;DR: 结合端到端设计和视觉语言模型（VLM）的自动驾驶方法，仅用单一摄像头即在驾驶任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLM），尤其是多模态视觉语言模型（VLM）是否能提升端到端驾驶任务的性能。

Method: 使用单一摄像头和视觉语言模型（VLM）构建端到端架构。

Result: 该方法在排行榜上表现最佳，成为仅使用摄像头的最佳解决方案。

Conclusion: 结合端到端架构设计和知识丰富的视觉语言模型（VLM）在驾驶任务中表现出色，证明了基于视觉的驾驶方法的有效性及其在端到端驾驶任务中的潜力。

Abstract: End-to-end autonomous driving has drawn tremendous attention recently. Many
works focus on using modular deep neural networks to construct the end-to-end
archi-tecture. However, whether using powerful large language models (LLM),
especially multi-modality Vision Language Models (VLM) could benefit the
end-to-end driving tasks remain a question. In our work, we demonstrate that
combining end-to-end architectural design and knowledgeable VLMs yield
impressive performance on the driving tasks. It is worth noting that our method
only uses a single camera and is the best camera-only solution across the
leaderboard, demonstrating the effectiveness of vision-based driving approach
and the potential for end-to-end driving tasks.

</details>


### [2] [PixFoundation 2.0: Do Video Multi-Modal LLMs Use Motion in Visual Grounding?](https://arxiv.org/abs/2509.02807)
*Mennatullah Siam*

Main category: cs.CV

TL;DR: 论文研究了视频MLLMs在像素级视觉定位中对运动的利用，提出MoCentric-Bench基准和适应技术，挑战未来模型的改进方向。


<details>
  <summary>Details</summary>
Motivation: 研究视频多模态大语言模型（MLLMs）是否能基于自然语言表达描述的运动模式分割对象，并识别当前基准的不足。

Method: 引入了四种针对视觉定位任务的运动中心探测技术，并建立了强大的单图像基线。

Result: 提出的运动中心适应技术在MoCentric-Bench上达到了最先进的性能。

Conclusion: 论文提出了MoCentric-Bench基准，挑战未来模型在视频中改进密集时空定位和像素级理解的能力。

Abstract: Multi-modal large language models (MLLMs) have shown impressive
generalization across tasks using images and text modalities. While their
extension to video has enabled tasks such as video question answering and video
captioning, their pixel-level visual grounding abilities are less studied. In
this work, we raise the pertinent question of whether motion is used in
pixel-level visual grounding and whether video MLLMs can segment objects based
on natural language expressions describing their motion patterns. We identify
the shortcomings in the current benchmarks, where we show that a single frame
can often suffice for capturing the motion referring expression without any
temporal reasoning. To address this, we introduce four motion-centric probing
techniques, particularly designed for the visual grounding task, to study video
MLLMs' ability to identify true motion from a fake one and their ability to
grasp the motion order. Consequently, we provide a motion-centric benchmark,
MoCentric-Bench. It ensures that video MLLMs are evaluated towards leveraging
the interaction between motion and language rather than being dominated by
static appearance cues emphasized in existing visual grounding datasets. We
further establish strong single-image baselines that are on par with or
outperform prior methods. Finally, we explore simple motion-centric adaptation
techniques that provide state-of-the-art performance on our MoCentric-Bench.
Our motion-centric benchmark, evaluation and findings challenge future models
to improve dense spatiotemporal grounding and pixel-level understanding within
videos. Code and datasets will be made publicly available at
https://github.com/MSiam/PixFoundation-2.0.git.

</details>


### [3] [Multi-Scale Deep Learning for Colon Histopathology: A Hybrid Graph-Transformer Approach](https://arxiv.org/abs/2509.02851)
*Sadra Saremi,Amirhossein Ahmadkhan Kordbacheh*

Main category: cs.CV

TL;DR: 本研究提出HG-TNet模型，结合Transformer和CNN的优势，在结肠癌分类任务中表现优异，提升了准确率并保留了空间信息。


<details>
  <summary>Details</summary>
Motivation: 结肠癌早期检测对防止病情恶化至关重要。现有方法在捕获多尺度特征和空间信息方面存在不足，因此需要更先进的分类模型。

Method: 采用混合多尺度深度学习架构，结合胶囊网络、图注意力机制、Transformer模块和残差学习，提出HG-TNet模型。该模型通过Transformer分支提取全局上下文信息，CNN分支捕捉局部细节，并结合自监督旋转预测目标。

Result: 模型在LC25000数据集上表现优于标准架构，不仅在准确率和损失函数上有所提升，还通过胶囊网络保留了空间顺序。

Conclusion: 本研究提出的HG-TNet模型通过结合Transformer和CNN的优势，在结肠癌分类任务中表现出色，不仅提升了准确率，还通过胶囊网络保留了空间信息。

Abstract: Colon cancer also known as Colorectal cancer, is one of the most malignant
types of cancer worldwide. Early-stage detection of colon cancer is highly
crucial to prevent its deterioration. This research presents a hybrid
multi-scale deep learning architecture that synergizes capsule networks, graph
attention mechanisms, transformer modules, and residual learning to advance
colon cancer classification on the Lung and Colon Cancer Histopathological
Image Dataset (LC25000) dataset. The proposed model in this paper utilizes the
HG-TNet model that introduces a hybrid architecture that joins strength points
in transformers and convolutional neural networks to capture multi-scale
features in histopathological images. Mainly, a transformer branch extracts
global contextual bonds by partitioning the image into patches by
convolution-based patch embedding and then processing these patches through a
transformer encoder. Analogously, a dedicated CNN branch captures fine-grained,
local details through successive Incorporation these diverse features, combined
with a self-supervised rotation prediction objective, produce a robust
diagnostic representation that surpasses standard architectures in performance.
Results show better performance not only in accuracy or loss function but also
in these algorithms by utilizing capsule networks to preserve spatial orders
and realize how each element individually combines and forms whole structures.

</details>


### [4] [PRECISE-AS: Personalized Reinforcement Learning for Efficient Point-of-Care Echocardiography in Aortic Stenosis Diagnosis](https://arxiv.org/abs/2509.02898)
*Armin Saadat,Nima Hashemi,Hooman Vaseli,Michael Y. Tsang,Christina Luong,Michiel Van de Panne,Teresa S. M. Tsang,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 利用强化学习动态选择超声心动图视频，提高主动脉狭窄诊断效率，准确率80.6%，视频需求减少53%。


<details>
  <summary>Details</summary>
Motivation: 主动脉狭窄是一种危及生命的疾病，但超声心动图（诊断金标准）在资源有限地区难以普及。点式护理超声虽更易获取，但受限于操作者专业知识和相关视图选择。

Method: 提出了一种基于强化学习的主动视频采集框架，动态选择每位患者最具信息量的超声心动图视频。

Result: 在2,572名患者数据上测试，该方法分类准确率达80.6%，且仅需47%的超声心动图视频（相比完整采集）。

Conclusion: 该方法通过强化学习驱动的主动视频采集框架，显著提高了主动脉狭窄诊断的效率和准确性，同时减少了所需的超声心动图视频数量。

Abstract: Aortic stenosis (AS) is a life-threatening condition caused by a narrowing of
the aortic valve, leading to impaired blood flow. Despite its high prevalence,
access to echocardiography (echo), the gold-standard diagnostic tool, is often
limited due to resource constraints, particularly in rural and underserved
areas. Point-of-care ultrasound (POCUS) offers a more accessible alternative
but is restricted by operator expertise and the challenge of selecting the most
relevant imaging views. To address this, we propose a reinforcement learning
(RL)-driven active video acquisition framework that dynamically selects each
patient's most informative echo videos. Unlike traditional methods that rely on
a fixed set of videos, our approach continuously evaluates whether additional
imaging is needed, optimizing both accuracy and efficiency. Tested on data from
2,572 patients, our method achieves 80.6% classification accuracy while using
only 47% of the echo videos compared to a full acquisition. These results
demonstrate the potential of active feature acquisition to enhance AS
diagnosis, making echocardiographic assessments more efficient, scalable, and
personalized. Our source code is available at:
https://github.com/Armin-Saadat/PRECISE-AS.

</details>


### [5] [LiGuard: A Streamlined Open-Source Framework for Rapid & Interactive Lidar Research](https://arxiv.org/abs/2509.02902)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: LiGuard 是一个开源框架，简化激光雷达数据处理，减少重复工作，支持代码共享和调整。


<details>
  <summary>Details</summary>
Motivation: 激光雷达数据处理中，研究人员常为特定应用开发定制代码，导致重复工作和难以应对数据或算法的微小变化。

Method: LiGuard 提供了一个内置支持数据 I/O、预处理/后处理和常用算法的框架，允许研究人员快速开发代码，并支持交互式调整算法和参数。

Result: LiGuard 通过案例研究证明了其有效性，能够简化代码开发、调整和可视化，并支持项目共享。

Conclusion: LiGuard 是一个有效的开源软件框架，能够显著减少激光雷达数据处理中的重复工作，并促进研究人员之间的协作和代码共享。

Abstract: There is a growing interest in the development of lidar-based autonomous
mobility and Intelligent Transportation Systems (ITS). To operate and research
on lidar data, researchers often develop code specific to application niche.
This approach leads to duplication of efforts across studies that, in many
cases, share multiple methodological steps such as data input/output (I/O),
pre/post processing, and common algorithms in multi-stage solutions. Moreover,
slight changes in data, algorithms, and/or research focus may force major
revisions in the code. To address these challenges, we present LiGuard, an
open-source software framework that allows researchers to: 1) rapidly develop
code for their lidar-based projects by providing built-in support for data I/O,
pre/post processing, and commonly used algorithms, 2) interactively
add/remove/reorder custom algorithms and adjust their parameters, and 3)
visualize results for classification, detection, segmentation, and tracking
tasks. Moreover, because it creates all the code files in structured
directories, it allows easy sharing of entire projects or even the individual
components to be reused by other researchers. The effectiveness of LiGuard is
demonstrated via case studies.

</details>


### [6] [PercepTwin: Modeling High-Fidelity Digital Twins for Sim2Real LiDAR-based Perception for Intelligent Transportation Systems](https://arxiv.org/abs/2509.02903)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: 本文介绍了一种利用高保真数字孪生创建合成数据集的方法，解决了LiDAR感知系统在智能交通系统中数据集创建成本高和可扩展性差的问题。


<details>
  <summary>Details</summary>
Motivation: 由于LiDAR感知系统在智能交通系统中依赖大规模标注数据集，而数据集的创建成本高、耗时长且需人工参与，这限制了系统的可扩展性。Sim2Real学习虽提供了可扩展的替代方案，但其效果依赖于模拟源对现实世界的保真度。

Method: 通过静态几何建模、道路基础设施复制和动态交通场景生成，结合开源资源（如卫星影像和OpenStreetMap数据）及特定传感器配置，构建稳健的合成环境。

Result: 提出的工作流程为生成可扩展、经济高效且多样化的数据集提供了实用且详细的指导，从而支持稳健的Sim2Real学习。

Conclusion: 本文提出了一种利用高保真数字孪生（HiFi DTs）创建大规模、高质量合成数据集的严谨且可复现的方法论，为Sim2Real学习提供了可靠的基础。

Abstract: LiDAR-based perception in intelligent transportation systems (ITS), for tasks
such as object detection, tracking, and semantic and instance segmentation, is
predominantly solved by deep neural network models which often require
large-scale labeled datasets during training to achieve generalization.
However, creating these datasets is costly. time consuming and require human
labor before the datasets are ready for training models. This hinders
scalability of the LiDAR-based perception systems in ITS. Sim2Real learning
offers scalable alternative, however, its effectiveness is dependent on the
fidelity of the source simulation(s) to real-world, in terms of environment
structure, actor dynamics, and sensor emulations. In response, this paper
introduces a rigorous and reproducible methodology for creating large-scale,
high-quality synthetic datasets using High-Fidelity Digital Twins (HiFi DTs).
The proposed workflow outlines the steps, tools, and best practices for
digitally replicating real-world environments, encompassing static geometry
modeling, road infrastructure replication, and dynamic traffic scenario
generation. Leveraging open-source and readily available resources such as
satellite imagery and OpenStreetMap data, alongside specific sensor
configurations, this paper provides practical, detailed guidance for
constructing robust synthetic environments. These environments subsequently
facilitate scalable, cost-effective, and diverse dataset generation, forming a
reliable foundation for robust Sim2Real learning.

</details>


### [7] [High-Fidelity Digital Twins for Bridging the Sim2Real Gap in LiDAR-Based ITS Perception](https://arxiv.org/abs/2509.02904)
*Muhammad Shahbaz,Shaurya Agarwal*

Main category: cs.CV

TL;DR: HiFi DT框架通过高保真仿真数据减少Sim2Real领域偏移，提升LiDAR感知模型在真实世界的性能4.8%。


<details>
  <summary>Details</summary>
Motivation: 解决Sim2Real领域转移问题，提升仿真训练的LiDAR感知模型在真实世界数据上的性能。

Method: 提出了一种高保真数字孪生（HiFi DT）框架，整合了真实世界的背景几何、车道级道路拓扑及传感器特定配置。通过系统化方法构建仿真环境，生成领域内合成数据，并量化合成与真实数据间的分布对齐。

Result: 实验表明，基于HiFi DT合成数据训练的模型性能优于真实数据训练的模型4.8%，且多种分布对齐指标验证了HiFi DT显著减少领域偏移。

Conclusion: HiFi DT框架显著减少了Sim2Real领域转移，提升了模型在真实世界ITS应用中的泛化能力，验证了数字孪生在LiDAR感知中的重要作用。

Abstract: Sim2Real domain transfer offers a cost-effective and scalable approach for
developing LiDAR-based perception (e.g., object detection, tracking,
segmentation) in Intelligent Transportation Systems (ITS). However, perception
models trained in simulation often under perform on real-world data due to
distributional shifts. To address this Sim2Real gap, this paper proposes a
high-fidelity digital twin (HiFi DT) framework that incorporates real-world
background geometry, lane-level road topology, and sensor-specific
specifications and placement. We formalize the domain adaptation challenge
underlying Sim2Real learning and present a systematic method for constructing
simulation environments that yield in-domain synthetic data. An off-the-shelf
3D object detector is trained on HiFi DT-generated synthetic data and evaluated
on real data. Our experiments show that the DT-trained model outperforms the
equivalent model trained on real data by 4.8%. To understand this gain, we
quantify distributional alignment between synthetic and real data using
multiple metrics, including Chamfer Distance (CD), Maximum Mean Discrepancy
(MMD), Earth Mover's Distance (EMD), and Fr'echet Distance (FD), at both
raw-input and latent-feature levels. Results demonstrate that HiFi DTs
substantially reduce domain shift and improve generalization across diverse
evaluation scenarios. These findings underscore the significant role of digital
twins in enabling reliable, simulation-based LiDAR perception for real-world
ITS applications.

</details>


### [8] [Single Domain Generalization in Diabetic Retinopathy: A Neuro-Symbolic Learning Approach](https://arxiv.org/abs/2509.02918)
*Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta*

Main category: cs.CV

TL;DR: KG-DG框架通过神经符号整合显著提升了糖尿病视网膜病变分类的跨域泛化能力，实验证明其优于纯神经方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像中模型在真实世界分布变化下泛化能力不足的问题，特别是在糖尿病视网膜病变分类任务中。

Method: 提出KG-DG框架，结合视觉Transformer和专家引导的符号推理，通过结构化规则特征和视网膜血管分割，融合深度视觉表示，并采用KL散度最小化策略对齐高层临床语义。

Result: 在四个公共数据集（APTOS、EyePACS、Messidor-1、Messidor-2）上，KG-DG框架在跨域设置中实现了最高5.2%的准确率提升，符号模型在MDG中达到63.67%的平均准确率，神经符号整合在SDG中表现最佳。

Conclusion: 神经符号整合（KG-DG框架）为构建临床稳健且领域不变的医学AI系统提供了一种有前景的范式，显著提升了糖尿病视网膜病变分类的跨域泛化能力。

Abstract: Domain generalization remains a critical challenge in medical imaging, where
models trained on single sources often fail under real-world distribution
shifts. We propose KG-DG, a neuro-symbolic framework for diabetic retinopathy
(DR) classification that integrates vision transformers with expert-guided
symbolic reasoning to enable robust generalization across unseen domains. Our
approach leverages clinical lesion ontologies through structured, rule-based
features and retinal vessel segmentation, fusing them with deep visual
representations via a confidence-weighted integration strategy. The framework
addresses both single-domain generalization (SDG) and multi-domain
generalization (MDG) by minimizing the KL divergence between domain embeddings,
thereby enforcing alignment of high-level clinical semantics. Extensive
experiments across four public datasets (APTOS, EyePACS, Messidor-1,
Messidor-2) demonstrate significant improvements: up to a 5.2% accuracy gain in
cross-domain settings and a 6% improvement over baseline ViT models. Notably,
our symbolic-only model achieves a 63.67% average accuracy in MDG, while the
complete neuro-symbolic integration achieves the highest accuracy compared to
existing published baselines and benchmarks in challenging SDG scenarios.
Ablation studies reveal that lesion-based features (84.65% accuracy)
substantially outperform purely neural approaches, confirming that symbolic
components act as effective regularizers beyond merely enhancing
interpretability. Our findings establish neuro-symbolic integration as a
promising paradigm for building clinically robust, and domain-invariant medical
AI systems.

</details>


### [9] [A Data-Driven RetinaNet Model for Small Object Detection in Aerial Images](https://arxiv.org/abs/2509.02928)
*Zhicheng Tang,Jinwen Tang,Yi Shang*

Main category: cs.CV

TL;DR: DDR-Net是一种数据驱动的深度学习模型，通过创新技术提升小物体检测能力，适用于环境监测、城市设计等多个领域，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 在环境监测、城市设计和危机管理等应用中，检测小物体的能力至关重要。DDR-Net旨在解决现有模型在小物体检测上的不足。

Method: DDR-Net采用了数据驱动的深度学习模型，引入了新颖的技术来自动确定最佳特征图和锚点估计，并开发了一种创新的采样技术以在有限数据条件下提高模型效率。

Result: 在多种空中鸟类图像数据集上的实证评估表明，DDR-Net显著优于RetinaNet和其他当代模型。

Conclusion: DDR-Net显著提升了空中图像中小物体的检测能力，减少了数据收集和训练的成本与时间，为农业、安全和考古等多个领域带来了广泛影响。

Abstract: In the realm of aerial imaging, the ability to detect small objects is
pivotal for a myriad of applications, encompassing environmental surveillance,
urban design, and crisis management. Leveraging RetinaNet, this work unveils
DDR-Net: a data-driven, deep-learning model devised to enhance the detection of
diminutive objects. DDR-Net introduces novel, data-driven techniques to
autonomously ascertain optimal feature maps and anchor estimations, cultivating
a tailored and proficient training process while maintaining precision.
Additionally, this paper presents an innovative sampling technique to bolster
model efficacy under limited data training constraints. The model's enhanced
detection capabilities support critical applications including wildlife and
habitat monitoring, traffic flow optimization, and public safety improvements
through accurate identification of small objects like vehicles and pedestrians.
DDR-Net significantly reduces the cost and time required for data collection
and training, offering efficient performance even with limited data. Empirical
assessments over assorted aerial avian imagery datasets demonstrate that
DDR-Net markedly surpasses RetinaNet and alternative contemporary models. These
innovations advance current aerial image analysis technologies and promise
wide-ranging impacts across multiple sectors including agriculture, security,
and archaeology.

</details>


### [10] [STAR: A Fast and Robust Rigid Registration Framework for Serial Histopathological Images](https://arxiv.org/abs/2509.02952)
*Zeyu Liu,Shengwei Ding*

Main category: cs.CV

TL;DR: STAR是一个快速、稳健的开源框架，用于多全切片组织图像的刚性配准，适用于多种染色方案，并显著降低了计算负担。


<details>
  <summary>Details</summary>
Motivation: 连续切片的全切片组织图像配准对于直接比较不同染色和准备人工智能工作流程中的配对数据集至关重要，但现有方法通常计算密集且难以复现，轻量级刚性框架仍不完善。

Method: STAR集成了染色条件预处理、分层粗到细相关策略、自适应核缩放和内置质量控制，实现了跨异质组织类型和染色方案的可靠刚性配准。

Result: 在ANHIR 2019和ACROBAT 2022数据集上的评估表明，STAR能在几分钟内稳定对齐切片，对跨染色变异性和部分组织重叠具有鲁棒性。

Conclusion: STAR提供了一个快速、稳健的开源框架，用于多全切片组织图像的刚性配准，降低了临床应用的障碍，并为下一代计算病理学的大规模配对数据准备提供了可能。

Abstract: Registration of serial whole-slide histopathological images (WSIs) is
critical for enabling direct comparison across diverse stains and for preparing
paired datasets in artificial intelligence (AI) workflows such as virtual
staining and biomarker prediction. While existing methods often rely on complex
deformable or deep learning approaches that are computationally intensive and
difficult to reproduce, lightweight rigid frameworks-sufficient for many
consecutive-section scenarios-remain underdeveloped. We introduce STAR (Serial
Tissue Alignment for Rigid registration), a fast and robust open-source
framework for multi-WSI alignment. STAR integrates stain-conditioned
preprocessing with a hierarchical coarse-to-fine correlation strategy, adaptive
kernel scaling, and built-in quality control, achieving reliable rigid
registration across heterogeneous tissue types and staining protocols,
including hematoxylin-eosin (H&E), special histochemical stains (e.g., PAS,
PASM, Masson's), and immunohistochemical (IHC) markers (e.g., CD31, KI67).
Evaluated on the ANHIR 2019 and ACROBAT 2022 datasets spanning multiple organs
and scanning conditions, STAR consistently produced stable alignments within
minutes per slide, demonstrating robustness to cross-stain variability and
partial tissue overlap. Beyond benchmarks, we present case studies on H&E-IHC
alignment, construction of multi-IHC panels, and typical failure modes,
underscoring both utility and limitations. Released as an open and lightweight
tool, STAR provides a reproducible baseline that lowers the barrier for
clinical adoption and enables large-scale paired data preparation for
next-generation computational pathology.

</details>


### [11] [Resilient Multimodal Industrial Surface Defect Detection with Uncertain Sensors Availability](https://arxiv.org/abs/2509.02962)
*Shuai Jiang,Yunfeng Ma,Jingyu Zhou,Yuan Bian,Yaonan Wang,Min Liu*

Main category: cs.CV

TL;DR: 提出跨模态提示学习和对称对比学习，解决工业表面缺陷检测中的模态缺失问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决工业表面缺陷检测中因传感器不确定性导致的模态缺失问题，包括学习模式转换和信息空缺。

Method: 提出了跨模态提示学习（包括跨模态一致性提示、模态特定提示和缺失感知提示）和对称对比学习（利用文本模态作为桥梁融合双视觉模态）。

Result: 实验结果显示，该方法在RGB和3D模态总缺失率为0.7时，达到73.83% I-AUROC和93.05% P-AUROC，优于现有方法3.84%和5.58%。

Conclusion: 本文提出的跨模态提示学习和对称对比学习方法在工业表面缺陷检测中显著提升了性能，尤其在模态缺失情况下表现优异。

Abstract: Multimodal industrial surface defect detection (MISDD) aims to identify and
locate defect in industrial products by fusing RGB and 3D modalities. This
article focuses on modality-missing problems caused by uncertain sensors
availability in MISDD. In this context, the fusion of multiple modalities
encounters several troubles, including learning mode transformation and
information vacancy. To this end, we first propose cross-modal prompt learning,
which includes: i) the cross-modal consistency prompt serves the establishment
of information consistency of dual visual modalities; ii) the modality-specific
prompt is inserted to adapt different input patterns; iii) the missing-aware
prompt is attached to compensate for the information vacancy caused by dynamic
modalities-missing. In addition, we propose symmetric contrastive learning,
which utilizes text modality as a bridge for fusion of dual vision modalities.
Specifically, a paired antithetical text prompt is designed to generate binary
text semantics, and triple-modal contrastive pre-training is offered to
accomplish multimodal learning. Experiment results show that our proposed
method achieves 73.83% I-AUROC and 93.05% P-AUROC with a total missing rate 0.7
for RGB and 3D modalities (exceeding state-of-the-art methods 3.84% and 5.58%
respectively), and outperforms existing approaches to varying degrees under
different missing types and rates. The source code will be available at
https://github.com/SvyJ/MISDD-MM.

</details>


### [12] [EdgeAttNet: Towards Barb-Aware Filament Segmentation](https://arxiv.org/abs/2509.02964)
*Victor Solomon,Piet Martens,Jingyu Liu,Rafal Angryk*

Main category: cs.CV

TL;DR: EdgeAttNet是一种改进的U-Net架构，通过引入可学习的边缘图增强细丝分割效果，特别在倒钩识别上表现优异，且推理速度快。


<details>
  <summary>Details</summary>
Motivation: 现有的太阳细丝分割方法在捕捉细尺度结构（尤其是倒钩）方面表现不佳，主要原因是难以建模长距离依赖和空间细节。

Method: EdgeAttNet是一种基于U-Net的分割架构，通过直接从输入图像中提取可学习的边缘图，并将其线性变换为注意力机制的Key和Query矩阵，从而在网络的瓶颈处引导自注意力机制更有效地捕捉细丝边界和倒钩。

Result: 在MAGFILO数据集上，EdgeAttNet在分割准确性和倒钩识别方面优于U-Net和其他基于U-Net的transformer基线，同时推理速度更快。

Conclusion: EdgeAttNet通过引入可学习的边缘图，显著提高了太阳细丝分割的准确性，特别是在识别细丝边缘和倒钩方面，同时减少了可训练参数的数量，适合实际部署。

Abstract: Accurate segmentation of solar filaments in H-alpha observations is critical
for determining filament chirality, a key factor in the behavior of Coronal
Mass Ejections (CMEs). However, existing methods often fail to capture
fine-scale filament structures, particularly barbs, due to a limited ability to
model long-range dependencies and spatial detail.
  We propose EdgeAttNet, a segmentation architecture built on a U-Net backbone
by introducing a novel, learnable edge map derived directly from the input
image. This edge map is incorporated into the model by linearly transforming
the attention Key and Query matrices with the edge information, thereby guiding
the self-attention mechanism at the network's bottleneck to more effectively
capture filament boundaries and barbs. By explicitly integrating this
structural prior into the attention computations, EdgeAttNet enhances spatial
sensitivity and segmentation accuracy while reducing the number of trainable
parameters.
  Trained end-to-end, EdgeAttNet outperforms U-Net and other U-Net-based
transformer baselines on the MAGFILO dataset. It achieves higher segmentation
accuracy and significantly better recognition of filament barbs, with faster
inference performance suitable for practical deployment.

</details>


### [13] [KEPT: Knowledge-Enhanced Prediction of Trajectories from Consecutive Driving Frames with Vision-Language Models](https://arxiv.org/abs/2509.02966)
*Yujin Wang,Tianyi Wang,Quanfeng Liu,Wenxian Fan,Junfeng Jiao,Christian Claudel,Yunbing Yan,Bingzhao Gao,Jianqiang Wang,Hong Chen*

Main category: cs.CV

TL;DR: KEPT是一种知识增强的视觉语言模型框架，通过融合视频编码和检索技术，显著提升了自动驾驶的短视域轨迹预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在短视域轨迹预测中难以有效基于场景动态和领域知识进行推理，KEPT旨在解决这一挑战。

Method: KEPT框架结合了时间频率-空间融合视频编码器、自监督学习和硬负例挖掘，以及可扩展的k-means + HNSW检索堆栈。通过三重微调阶段逐步对齐语言头部与空间线索、物理可行运动和时序条件的前视规划。

Result: 在nuScenes数据集上，KEPT在开环协议下表现最佳：NoAvg下平均L2为0.70米，碰撞率为0.21%；TemAvg下平均L2为0.31米，碰撞率为0.07%。

Conclusion: KEPT框架通过结合知识增强的视觉语言模型和检索增强的链式思维提示，为自动驾驶提供了可解释且可信的短视域轨迹预测。

Abstract: Accurate short-horizon trajectory prediction is pivotal for safe and reliable
autonomous driving, yet existing vision-language models (VLMs) often fail to
effectively ground their reasoning in scene dynamics and domain knowledge. To
address this challenge, this paper introduces KEPT, a knowledge-enhanced VLM
framework that predicts ego trajectories directly from consecutive front-view
driving frames. KEPT couples a temporal frequency-spatial fusion (TFSF) video
encoder, trained via self-supervised learning with hard-negative mining, with a
scalable k-means + HNSW retrieval stack that supplies scene-aligned exemplars.
Retrieved priors are embedded into chain-of-thought (CoT) prompts with explicit
planning constraints, while a triple-stage fine-tuning schedule incrementally
aligns the language head to metric spatial cues, physically feasible motion,
and temporally conditioned front-view planning. Evaluated on nuScenes dataset,
KEPT achieves state-of-the-art performance across open-loop protocols: under
NoAvg, it achieves 0.70m average L2 with a 0.21\% collision rate; under TemAvg
with lightweight ego status, it attains 0.31m average L2 and a 0.07\% collision
rate. Ablation studies show that all three fine-tuning stages contribute
complementary benefits, and that using Top-2 retrieved exemplars yields the
best accuracy-safety trade-off. The k-means-clustered HNSW index delivers
sub-millisecond retrieval latency, supporting practical deployment. These
results indicate that retrieval-augmented, CoT-guided VLMs offer a promising,
data-efficient pathway toward interpretable and trustworthy autonomous driving.

</details>


### [14] [VQualA 2025 Challenge on Engagement Prediction for Short Videos: Methods and Results](https://arxiv.org/abs/2509.02969)
*Dasong Li,Sizhuo Ma,Hang Hua,Wenjie Li,Jian Wang,Chris Wei Zhou,Fengbin Guan,Xin Li,Zihao Yu,Yiting Lu,Ru-Ling Liao,Yan Ye,Zhibo Chen,Wei Sun,Linhan Cao,Yuqin Cao,Weixia Zhang,Wen Wen,Kaiwei Zhang,Zijian Chen,Fangfang Lu,Xiongkuo Min,Guangtao Zhai,Erjia Xiao,Lingfeng Zhang,Zhenjie Su,Hao Cheng,Yu Liu,Renjing Xu,Long Chen,Xiaoshuai Hao,Zhenpeng Zeng,Jianqin Wu,Xuxu Wang,Qian Yu,Bo Hu,Weiwei Wang,Pinxin Liu,Yunlong Tang,Luchuan Song,Jinxi He,Jiaru Wu,Hanjia Lyu*

Main category: cs.CV

TL;DR: VQualA 2025挑战赛聚焦短视频用户参与度预测，通过多模态特征分析推动领域进展。


<details>
  <summary>Details</summary>
Motivation: 理解并建模社交媒体平台上用户生成内容（UGC）短视频的受欢迎程度。

Method: 参与者探索了多种多模态特征，包括视觉内容、音频和创作者提供的元数据。

Result: 挑战赛使用了新的短形式UGC数据集，并显著推动了短形式UGC视频参与度预测的进展。

Conclusion: VQualA 2025挑战赛成功促进了短视频用户参与度预测领域的进展，吸引了97名参与者并收到15份有效测试提交。

Abstract: This paper presents an overview of the VQualA 2025 Challenge on Engagement
Prediction for Short Videos, held in conjunction with ICCV 2025. The challenge
focuses on understanding and modeling the popularity of user-generated content
(UGC) short videos on social media platforms. To support this goal, the
challenge uses a new short-form UGC dataset featuring engagement metrics
derived from real-world user interactions. This objective of the Challenge is
to promote robust modeling strategies that capture the complex factors
influencing user engagement. Participants explored a variety of multi-modal
features, including visual content, audio, and metadata provided by creators.
The challenge attracted 97 participants and received 15 valid test submissions,
contributing significantly to progress in short-form UGC video engagement
prediction.

</details>


### [15] [InstaDA: Augmenting Instance Segmentation Data with Dual-Agent System](https://arxiv.org/abs/2509.02973)
*Xianbao Hou,Yonghao He,Zeyd Boukhers,John See,Hu Su,Wei Sui,Cong Yang*

Main category: cs.CV

TL;DR: InstaDA是一种训练免费的双代理系统，通过LLM与扩散模型的协作和实例生成增强实例分割数据集，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中LLM与扩散模型协作不足及训练数据信息利用不充分的问题。

Method: 提出InstaDA，一种训练免费的双代理系统，包括Text-Agent（T-Agent）和Image-Agent（I-Agent），分别通过LLM与扩散模型的协作和基于训练图像的实例生成来增强数据集。

Result: 在LVIS 1.0验证集上，InstaDA相比基线在box AP和mask AP上分别提升了+4.0和+3.3，并优于领先模型DiverGen。

Conclusion: InstaDA通过双代理系统显著提升了实例分割数据集的多样性和质量，实验结果表明其在多个指标上优于现有方法。

Abstract: Acquiring high-quality instance segmentation data is challenging due to the
labor-intensive nature of the annotation process and significant class
imbalances within datasets. Recent studies have utilized the integration of
Copy-Paste and diffusion models to create more diverse datasets. However, these
studies often lack deep collaboration between large language models (LLMs) and
diffusion models, and underutilize the rich information within the existing
training data. To address these limitations, we propose InstaDA, a novel,
training-free Dual-Agent system designed to augment instance segmentation
datasets. First, we introduce a Text-Agent (T-Agent) that enhances data
diversity through collaboration between LLMs and diffusion models. This agent
features a novel Prompt Rethink mechanism, which iteratively refines prompts
based on the generated images. This process not only fosters collaboration but
also increases image utilization and optimizes the prompts themselves.
Additionally, we present an Image-Agent (I-Agent) aimed at enriching the
overall data distribution. This agent augments the training set by generating
new instances conditioned on the training images. To ensure practicality and
efficiency, both agents operate as independent and automated workflows,
enhancing usability. Experiments conducted on the LVIS 1.0 validation set
indicate that InstaDA achieves significant improvements, with an increase of
+4.0 in box average precision (AP) and +3.3 in mask AP compared to the
baseline. Furthermore, it outperforms the leading model, DiverGen, by +0.3 in
box AP and +0.1 in mask AP, with a notable +0.7 gain in box AP on common
categories and mask AP gains of +0.2 on common categories and +0.5 on frequent
categories.

</details>


### [16] [SPENet: Self-guided Prototype Enhancement Network for Few-shot Medical Image Segmentation](https://arxiv.org/abs/2509.02993)
*Chao Fan,Xibin Jia,Anqi Xiao,Hongyuan Yu,Zhenghan Yang,Dawei Yang,Hui Xu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: SPENet通过多级原型生成和查询引导的局部原型增强，解决了少样本医学图像分割中类内差异问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有原型方法在少样本医学图像分割中通常仅生成单一全局原型，忽略了类内差异，导致匹配不准确。

Method: 提出了自引导原型增强网络（SPENet），包括多级原型生成模块（MPG）和查询引导局部原型增强模块（QLPE）。MPG生成全局和局部原型以实现多粒度匹配，QLPE通过查询图像指导优化局部原型以减少支持与查询图像间的差异影响。

Result: 在三个公共医学数据集上的实验表明，SPENet性能优于现有最先进方法。

Conclusion: SPENet通过结合全局和局部原型，并利用查询图像指导局部原型增强，显著提升了少样本医学图像分割的性能，超越了现有最先进方法。

Abstract: Few-Shot Medical Image Segmentation (FSMIS) aims to segment novel classes of
medical objects using only a few labeled images. Prototype-based methods have
made significant progress in addressing FSMIS. However, they typically generate
a single global prototype for the support image to match with the query image,
overlooking intra-class variations. To address this issue, we propose a
Self-guided Prototype Enhancement Network (SPENet). Specifically, we introduce
a Multi-level Prototype Generation (MPG) module, which enables
multi-granularity measurement between the support and query images by
simultaneously generating a global prototype and an adaptive number of local
prototypes. Additionally, we observe that not all local prototypes in the
support image are beneficial for matching, especially when there are
substantial discrepancies between the support and query images. To alleviate
this issue, we propose a Query-guided Local Prototype Enhancement (QLPE)
module, which adaptively refines support prototypes by incorporating guidance
from the query image, thus mitigating the negative effects of such
discrepancies. Extensive experiments on three public medical datasets
demonstrate that SPENet outperforms existing state-of-the-art methods,
achieving superior performance.

</details>


### [17] [SOPSeg: Prompt-based Small Object Instance Segmentation in Remote Sensing Imagery](https://arxiv.org/abs/2509.03002)
*Chenhao Wang,Yingrui Ji,Yu Meng,Yunjian Zhang,Yao Zhu*

Main category: cs.CV

TL;DR: SOPSeg是一个专为遥感图像小目标分割设计的提示框架，通过区域自适应放大和定制解码器提升性能，并构建了首个专用数据集。


<details>
  <summary>Details</summary>
Motivation: 遥感图像中的小目标实例分割研究不足，缺乏专用数据集，且现有方法如SAM在特征分辨率不足时性能显著下降。

Method: 提出了SOPSeg框架，包含区域自适应放大策略以保留细节，定制化解码器整合边缘预测和渐进细化以精确边界勾勒，以及针对定向边界框的新型提示机制。

Result: SOPSeg在小目标分割任务中优于现有方法，并基于SODA-A构建了全面的小目标实例分割数据集。

Conclusion: SOPSeg框架在遥感图像中的小目标分割任务中表现优异，并支持高效的数据集构建，未来将公开发布模型和数据集以促进相关研究。

Abstract: Extracting small objects from remote sensing imagery plays a vital role in
various applications, including urban planning, environmental monitoring, and
disaster management. While current research primarily focuses on small object
detection, instance segmentation for small objects remains underexplored, with
no dedicated datasets available. This gap stems from the technical challenges
and high costs of pixel-level annotation for small objects. While the Segment
Anything Model (SAM) demonstrates impressive zero-shot generalization, its
performance on small-object segmentation deteriorates significantly, largely
due to the coarse 1/16 feature resolution that causes severe loss of fine
spatial details. To this end, we propose SOPSeg, a prompt-based framework
specifically designed for small object segmentation in remote sensing imagery.
It incorporates a region-adaptive magnification strategy to preserve
fine-grained details, and employs a customized decoder that integrates edge
prediction and progressive refinement for accurate boundary delineation.
Moreover, we introduce a novel prompting mechanism tailored to the oriented
bounding boxes widely adopted in remote sensing applications. SOPSeg
outperforms existing methods in small object segmentation and facilitates
efficient dataset construction for remote sensing tasks. We further construct a
comprehensive small object instance segmentation dataset based on SODA-A, and
will release both the model and dataset to support future research.

</details>


### [18] [Enhancing Robustness in Post-Processing Watermarking: An Ensemble Attack Network Using CNNs and Transformers](https://arxiv.org/abs/2509.03006)
*Tzuhsuan Huang,Cheng Yu Yeo,Tsai-Ling Huang,Hong-Han Shuai,Wen-Huang Cheng,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: 本研究提出了一种基于集成攻击网络的后处理水印方法，结合CNN和Transformer在空间和频域的优势，显著提高了水印的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 后处理水印比处理中水印更灵活，适用于任何生成模型，且允许为单个图像嵌入独特水印。

Method: 通过集成攻击网络（CNN和Transformer在空间和频域的不同组合）训练，增强后处理水印的鲁棒性。

Result: 在WAVES基准测试中，使用平均比特准确率作为指标，集成攻击网络显著提升了基线水印方法的鲁棒性，特别是在Regeneration Attack中提升了StegaStamp 18.743%。

Conclusion: 结合CNN在空间域和Transformer在频域的攻击网络，显著提高了水印模型的鲁棒性，特别是在WAVES基准测试中表现优异。

Abstract: Recent studies on deep watermarking have predominantly focused on
in-processing watermarking, which integrates the watermarking process into
image generation. However, post-processing watermarking, which embeds
watermarks after image generation, offers more flexibility. It can be applied
to outputs from any generative model (e.g. GANs, diffusion models) without
needing access to the model's internal structure. It also allows users to embed
unique watermarks into individual images. Therefore, this study focuses on
post-processing watermarking and enhances its robustness by incorporating an
ensemble attack network during training. We construct various versions of
attack networks using CNN and Transformer in both spatial and frequency domains
to investigate how each combination influences the robustness of the
watermarking model. Our results demonstrate that combining a CNN-based attack
network in the spatial domain with a Transformer-based attack network in the
frequency domain yields the highest robustness in watermarking models.
Extensive evaluation on the WAVES benchmark, using average bit accuracy as the
metric, demonstrates that our ensemble attack network significantly enhances
the robustness of baseline watermarking methods under various stress tests. In
particular, for the Regeneration Attack defined in WAVES, our method improves
StegaStamp by 18.743%. The code is released
at:https://github.com/aiiu-lab/DeepRobustWatermark.

</details>


### [19] [Lesion-Aware Visual-Language Fusion for Automated Image Captioning of Ulcerative Colitis Endoscopic Examinations](https://arxiv.org/abs/2509.03011)
*Alexis Ivan Lopez Escamilla,Gilberto Ochoa,Sharib Al*

Main category: cs.CV

TL;DR: 提出一种结合视觉与临床数据的UC图像描述框架，提升描述质量与分类准确性。


<details>
  <summary>Details</summary>
Motivation: 旨在生成与临床实践一致的结构化、可解释的描述，并同时提供MES分类和病变标签，以改进内窥镜报告。

Method: 模型整合了ResNet嵌入、Grad-CAM热图、CBAM增强注意力与T5解码器，并通过自然语言提示注入临床元数据（如MES评分、血管模式等）以指导描述生成。

Result: 与基线相比，该方法在描述质量和MES分类准确性上均有提升。

Conclusion: 该论文提出了一种针对溃疡性结肠炎的病变感知图像描述框架，显著提升了描述质量和MES分类准确性，支持可靠的内窥镜报告。

Abstract: We present a lesion-aware image captioning framework for ulcerative colitis
(UC). The model integrates ResNet embeddings, Grad-CAM heatmaps, and
CBAM-enhanced attention with a T5 decoder. Clinical metadata (MES score 0-3,
vascular pattern, bleeding, erythema, friability, ulceration) is injected as
natural-language prompts to guide caption generation. The system produces
structured, interpretable descriptions aligned with clinical practice and
provides MES classification and lesion tags. Compared with baselines, our
approach improves caption quality and MES classification accuracy, supporting
reliable endoscopic reporting.

</details>


### [20] [Unveiling the Response of Large Vision-Language Models to Visually Absent Tokens](https://arxiv.org/abs/2509.03025)
*Sohee Kim,Soohyun Ryu,Joonhyung Park,Eunho Yang*

Main category: cs.CV

TL;DR: 研究发现LVLMs中特定的VA神经元可检测文本是否视觉基础，基于此开发的模块能有效减少模型错误，提高响应准确性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在联合解释视觉和文本输入时，常错误地将缺乏视觉证据的文本输入视为图像的一部分，导致错误响应。研究旨在探索LVLMs是否具备内部能力来判断文本概念是否基于图像。

Method: 通过识别特定的前馈网络（FFN）神经元子集（VA神经元），开发了一个检测模块，用于分类输入令牌是否视觉基础。基于检测结果，重新解释问题提示或在生成过程中替换检测到的缺失令牌。

Result: 实验证明，该方法有效减少了模型对文本输入视觉存在的错误假设，且在不同LVLMs中具有通用性。

Conclusion: 研究发现并利用视觉缺失感知（VA）神经元，开发了一种检测模块，有效减少了大型视觉语言模型（LVLMs）对文本输入视觉存在的错误假设，提高了模型的准确性。

Abstract: Large Vision-Language Models (LVLMs) generate contextually relevant responses
by jointly interpreting visual and textual inputs. However, our finding reveals
they often mistakenly perceive text inputs lacking visual evidence as being
part of the image, leading to erroneous responses. In light of this finding, we
probe whether LVLMs possess an internal capability to determine if textual
concepts are grounded in the image, and discover a specific subset of
Feed-Forward Network (FFN) neurons, termed Visual Absence-aware (VA) neurons,
that consistently signal the visual absence through a distinctive activation
pattern. Leveraging these patterns, we develop a detection module that
systematically classifies whether an input token is visually grounded. Guided
by its prediction, we propose a method to refine the outputs by reinterpreting
question prompts or replacing the detected absent tokens during generation.
Extensive experiments show that our method effectively mitigates the models'
tendency to falsely presume the visual presence of text input and its
generality across various LVLMs.

</details>


### [21] [MedLiteNet: Lightweight Hybrid Medical Image Segmentation Model](https://arxiv.org/abs/2509.03041)
*Pengyang Yu,Haoquan Wang,Gerard Marks,Tahar Kechadi,Laurence T. Yang,Sahraoui Dhelim,Nyothiri Aung*

Main category: cs.CV

TL;DR: 提出MedLiteNet，一种轻量级混合模型，结合CNN和Transformer优势，解决皮肤病变分割中的长距离依赖和小样本问题。


<details>
  <summary>Details</summary>
Motivation: 解决卷积神经网络因有限感受野而难以建模长距离依赖，以及Vision Transformers因二次复杂性和大参数预算而难以在小样本医学数据集上应用的问题。

Method: 模型编码器堆叠深度可分离的Mobile Inverted Bottleneck块以减少计算量，插入跨尺度令牌混合单元以在分辨率间交换信息，并嵌入边界感知自注意力模块以锐化病变轮廓。

Result: MedLiteNet在皮肤病变分割任务中实现了高精度。

Conclusion: MedLiteNet是一种轻量级CNN-Transformer混合模型，专为皮肤镜分割设计，通过分层特征提取和多尺度上下文聚合实现高精度。

Abstract: Accurate skin-lesion segmentation remains a key technical challenge for
computer-aided diagnosis of skin cancer. Convolutional neural networks, while
effective, are constrained by limited receptive fields and thus struggle to
model long-range dependencies. Vision Transformers capture global context, yet
their quadratic complexity and large parameter budgets hinder use on the
small-sample medical datasets common in dermatology. We introduce the
MedLiteNet, a lightweight CNN Transformer hybrid tailored for dermoscopic
segmentation that achieves high precision through hierarchical feature
extraction and multi-scale context aggregation. The encoder stacks depth-wise
Mobile Inverted Bottleneck blocks to curb computation, inserts a
bottleneck-level cross-scale token-mixing unit to exchange information between
resolutions, and embeds a boundary-aware self-attention module to sharpen
lesion contours.

</details>


### [22] [Background Matters Too: A Language-Enhanced Adversarial Framework for Person Re-Identification](https://arxiv.org/abs/2509.03032)
*Kaicong Huang,Talha Azfar,Jack M. Reilly,Thomas Guggisberg,Ruimin Ke*

Main category: cs.CV

TL;DR: 本文提出了一种结合前景和背景信息的双分支跨模态ReID框架，通过语义对齐和对抗学习策略提升性能，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 受人类感知启发，认为在ReID中背景语义与前景语义同样重要，因为人类倾向于消除背景干扰同时关注目标外观。

Method: 提出了一种端到端框架，通过双分支跨模态特征提取管道联合建模前景和背景信息，并采用类内语义对齐和类间语义对抗学习策略。

Result: 该方法在实验中表现出色，能够有效抑制噪声背景区域并增强对身份相关前景线索的关注。

Conclusion: 在两种整体和两种遮挡ReID基准测试上的全面实验证明了所提出方法的有效性和通用性，其结果与当前最先进方法相匹配或超越。

Abstract: Person re-identification faces two core challenges: precisely locating the
foreground target while suppressing background noise and extracting
fine-grained features from the target region. Numerous visual-only approaches
address these issues by partitioning an image and applying attention modules,
yet they rely on costly manual annotations and struggle with complex
occlusions. Recent multimodal methods, motivated by CLIP, introduce semantic
cues to guide visual understanding. However, they focus solely on foreground
information, but overlook the potential value of background cues. Inspired by
human perception, we argue that background semantics are as important as the
foreground semantics in ReID, as humans tend to eliminate background
distractions while focusing on target appearance. Therefore, this paper
proposes an end-to-end framework that jointly models foreground and background
information within a dual-branch cross-modal feature extraction pipeline. To
help the network distinguish between the two domains, we propose an
intra-semantic alignment and inter-semantic adversarial learning strategy.
Specifically, we align visual and textual features that share the same
semantics across domains, while simultaneously penalizing similarity between
foreground and background features to enhance the network's discriminative
power. This strategy drives the model to actively suppress noisy background
regions and enhance attention toward identity-relevant foreground cues.
Comprehensive experiments on two holistic and two occluded ReID benchmarks
demonstrate the effectiveness and generality of the proposed method, with
results that match or surpass those of current state-of-the-art approaches.

</details>


### [23] [DCDB: Dynamic Conditional Dual Diffusion Bridge for Ill-posed Multi-Tasks](https://arxiv.org/abs/2509.03044)
*Chengjie Huang,Jiafeng Yan,Jing Li,Lu Bai*

Main category: cs.CV

TL;DR: 提出动态条件双扩散桥训练范式，解决多任务中条件扩散模型的局限性，显著提升ill-posed任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态条件控制在多任务场景中难以适应动态演变的特性，而数据分布路径的构建方式也限制了任务间内在相关性的利用。

Method: 通过解耦扩散和条件生成过程，并利用动态条件逐步调整统计特性，嵌入时间相关信息，降低网络学习难度。

Result: 在去雾和可见光-红外融合等典型ill-posed多任务场景中，该方法在多个公共数据集上取得了最佳性能。

Conclusion: 作者提出了一种动态条件双扩散桥训练范式，有效解决了多任务场景中条件扩散模型的局限性，特别是在数据不足的ill-posed任务中表现优异。

Abstract: Conditional diffusion models have made impressive progress in the field of
image processing, but the characteristics of constructing data distribution
pathways make it difficult to exploit the intrinsic correlation between tasks
in multi-task scenarios, which is even worse in ill-posed tasks with a lack of
training data. In addition, traditional static condition control makes it
difficult for networks to learn in multi-task scenarios with its dynamically
evolving characteristics. To address these challenges, we propose a dynamic
conditional double diffusion bridge training paradigm to build a general
framework for ill-posed multi-tasks. Firstly, this paradigm decouples the
diffusion and condition generation processes, avoiding the dependence of the
diffusion model on supervised data in ill-posed tasks. Secondly, generated by
the same noise schedule, dynamic conditions are used to gradually adjust their
statistical characteristics, naturally embed time-related information, and
reduce the difficulty of network learning. We analyze the learning objectives
of the network under different conditional forms in the single-step denoising
process and compare the changes in its attention weights in the network,
demonstrating the superiority of our dynamic conditions. Taking dehazing and
visible-infrared fusion as typical ill-posed multi-task scenarios, we achieve
the best performance in multiple indicators on public datasets. The code has
been publicly released at: https://anonymous.4open.science/r/DCDB-D3C2.

</details>


### [24] [Information transmission: Inferring change area from change moment in time series remote sensing images](https://arxiv.org/abs/2509.03112)
*Jialu Li,Chen Wu,Meiqi Hu*

Main category: cs.CV

TL;DR: CAIM-Net是一种时间序列变化检测网络，通过从变化时刻推断变化区域，确保结果一致性，包含差异提取、粗/精细变化时刻提取三个步骤。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法将变化区域检测和变化时刻识别视为独立任务，忽略了二者之间的内在联系。CAIM-Net旨在通过从变化时刻推断变化区域，确保结果一致性。

Method: CAIM-Net包含三个关键步骤：差异提取与增强、粗变化时刻提取、精细变化时刻提取与变化区域推断。采用轻量级编码器和边界增强卷积提取差异特征，通过时空相关性分析确定粗变化时刻，最后利用多尺度时间CAM模块加权变化时刻并推断变化区域。

Result: CAIM-Net通过差异特征增强和多尺度时间CAM模块，有效提升了变化检测的准确性，实现了变化区域与变化时刻的一致性推断。

Conclusion: CAIM-Net通过整合时间序列分析和空间变化检测的内在关系，实现了变化区域与变化时刻结果的一致性，为生态系统动态监测提供了一种高效方法。

Abstract: Time series change detection is a critical task for exploring ecosystem
dynamics using time series remote sensing images, because it can simultaneously
indicate where and when change occur. While deep learning has shown excellent
performance in this domain, it continues to approach change area detection and
change moment identification as distinct tasks. Given that change area can be
inferred from change moment, we propose a time series change detection network,
named CAIM-Net (Change Area Inference from Moment Network), to ensure
consistency between change area and change moment results. CAIM-Net infers
change area from change moment based on the intrinsic relationship between time
series analysis and spatial change detection. The CAIM-Net comprises three key
steps: Difference Extraction and Enhancement, Coarse Change Moment Extraction,
and Fine Change Moment Extraction and Change Area Inference. In the Difference
Extraction and Enhancement, a lightweight encoder with batch dimension stacking
is designed to rapidly extract difference features. Subsequently, boundary
enhancement convolution is applied to amplify these difference features. In the
Coarse Change Moment Extraction, the enhanced difference features from the
first step are used to spatiotemporal correlation analysis, and then two
distinct methods are employed to determine coarse change moments. In the Fine
Change Moment Extraction and Change Area Inference, a multiscale temporal Class
Activation Mapping (CAM) module first increases the weight of the
change-occurring moment from coarse change moments. Then the weighted change
moment is used to infer change area based on the fact that pixels with the
change moment must have undergone a change.

</details>


### [25] [Isolated Bangla Handwritten Character Classification using Transfer Learning](https://arxiv.org/abs/2509.03061)
*Abdul Karim,S M Rafiuddin,Jahidul Islam Razin,Tahira Alam*

Main category: cs.CV

TL;DR: 通过迁移学习和多种深度神经网络技术，该研究实现了孟加拉语手写字符的高精度分类，准确率超99%。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语包含50个基本字符和多个复合字符，现有研究对手写字符识别仍有改进空间。

Method: 采用迁移学习避免梯度消失问题，并结合3DCNN、ResNet和MobileNet等深度神经网络技术，构建端到端分类模型。

Result: 模型在Bangla Lekha Isolated数据集上表现优异，分类准确率显著高于现有方法。

Conclusion: 该研究提出的模型在孟加拉语手写字符分类中表现出色，训练和测试准确率分别达到99.82%和99.46%，优于现有基准方法。

Abstract: Bangla language consists of fifty distinct characters and many compound
characters. Several notable studies have been performed to recognize Bangla
characters, both handwritten and optical. Our approach uses transfer learning
to classify the basic, distinct, as well as compound Bangla handwritten
characters while avoiding the vanishing gradient problem. Deep Neural Network
techniques such as 3D Convolutional Neural Network (3DCNN), Residual Neural
Network (ResNet), and MobileNet are applied to generate an end-to-end
classification of all possible standard formations of handwritten characters in
the Bangla language. The Bangla Lekha Isolated dataset, which contains 166,105
Bangla character image samples categorized into 84 distinct classes, is used
for this classification model. The model achieved 99.82% accuracy on training
data and 99.46% accuracy on test data. Comparisons with various
state-of-the-art benchmarks of Bangla handwritten character classification show
that the proposed model achieves better accuracy in classifying the data.

</details>


### [26] [AutoDetect: Designing an Autoencoder-based Detection Method for Poisoning Attacks on Object Detection Applications in the Military Domain](https://arxiv.org/abs/2509.03179)
*Alma M. Liezenga,Stefan Wijnja,Puck de Haan,Niels W. T. Brink,Jip J. van Stijn,Yori Kamphuis,Klamer Schutte*

Main category: cs.CV

TL;DR: 本文研究了军事目标检测器中中毒攻击的影响及检测方法，提出了AutoDetect方法，优于现有方法，并强调需要更多军事领域数据集以进一步评估风险。


<details>
  <summary>Details</summary>
Motivation: 军事领域中，人工智能系统的安全性和鲁棒性面临中毒攻击的日益严重威胁。然而，对于目标检测系统中毒攻击的应用和检测研究有限，这在军事领域尤其成问题，因为攻击可能带来严重后果。

Method: 研究通过实施修改版的BadDet攻击（一种基于补丁的中毒攻击）来探索军事目标检测器对中毒攻击的脆弱性，并评估其影响。同时，测试了专门的中毒检测方法和视觉工业检测领域的异常检测方法，最终提出了自己的补丁检测方法AutoDetect。

Result: 研究发现，虽然可以实现正的攻击成功率，但需要大量数据被中毒，这对其实际应用提出了疑问。在检测方面，现有的两类方法均不足，而作者提出的AutoDetect方法在分离干净和中毒样本方面表现出色，且时间和内存消耗较低。

Conclusion: 作者呼吁在军事领域需要更大、更具代表性的数据集来进一步评估中毒攻击的风险和补丁检测的机会。

Abstract: Poisoning attacks pose an increasing threat to the security and robustness of
Artificial Intelligence systems in the military domain. The widespread use of
open-source datasets and pretrained models exacerbates this risk. Despite the
severity of this threat, there is limited research on the application and
detection of poisoning attacks on object detection systems. This is especially
problematic in the military domain, where attacks can have grave consequences.
In this work, we both investigate the effect of poisoning attacks on military
object detectors in practice, and the best approach to detect these attacks. To
support this research, we create a small, custom dataset featuring military
vehicles: MilCivVeh. We explore the vulnerability of military object detectors
for poisoning attacks by implementing a modified version of the BadDet attack:
a patch-based poisoning attack. We then assess its impact, finding that while a
positive attack success rate is achievable, it requires a substantial portion
of the data to be poisoned -- raising questions about its practical
applicability. To address the detection challenge, we test both specialized
poisoning detection methods and anomaly detection methods from the visual
industrial inspection domain. Since our research shows that both classes of
methods are lacking, we introduce our own patch detection method: AutoDetect, a
simple, fast, and lightweight autoencoder-based method. Our method shows
promising results in separating clean from poisoned samples using the
reconstruction error of image slices, outperforming existing methods, while
being less time- and memory-intensive. We urge that the availability of large,
representative datasets in the military domain is a prerequisite to further
evaluate risks of poisoning attacks and opportunities patch detection.

</details>


### [27] [High Cursive Complex Character Recognition using GAN External Classifier](https://arxiv.org/abs/2509.03062)
*S M Rafiuddin*

Main category: cs.CV

TL;DR: 提出ADA-GAN模型，通过GAN生成伪造字符图像增强数据，提高复杂和草书字符的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 由于草书字符的复杂性和多样性，传统卷积神经网络（CNN）的分类准确率下降，需要更鲁棒的分类方法。

Method: 结合外部分类器和生成对抗网络（GAN），生成伪造的手写字符图像，并通过添加对抗性扰动噪声来增强训练数据。

Result: 实验结果表明，ADA-GAN在复杂和草书字符分类中比传统CNN更有效。

Conclusion: ADA-GAN模型在复杂和草书字符分类中表现出更强的鲁棒性和有效性。

Abstract: Handwritten characters can be trickier to classify due to their complex and
cursive nature compared to simple and non-cursive characters. We present an
external classifier along with a Generative Adversarial Network that can
classify highly cursive and complex characters. The generator network produces
fake handwritten character images, which are then used to augment the training
data after adding adversarially perturbed noise and achieving a confidence
score above a threshold with the discriminator network. The results show that
the accuracy of convolutional neural networks decreases as character complexity
increases, but our proposed model, ADA-GAN, remains more robust and effective
for both cursive and complex characters.

</details>


### [28] [LGBP-OrgaNet: Learnable Gaussian Band Pass Fusion of CNN and Transformer Features for Robust Organoid Segmentation and Tracking](https://arxiv.org/abs/2509.03221)
*Jing Zhang,Siying Tao,Jiao Li,Tianhe Wang,Junchen Wu,Ruqian Hao,Xiaohui Du,Ruirong Tan,Rui Li*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的无损器官分割和追踪方法LGBP-OrgaNet，通过特征融合和多尺度解码实现了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统荧光标记方法可能损害器官结构，因此需要一种自动、无损的器官分割和追踪方法。

Method: 采用深度学习方法，结合CNN和Transformer模块提取互补信息，并引入Learnable Gaussian Band Pass Fusion模块进行特征融合。解码器部分采用Bidirectional Cross Fusion Block融合多尺度特征，最终通过渐进式连接和上采样完成解码。

Result: SROrga在器官分割数据集上表现出令人满意的分割精度和鲁棒性。

Conclusion: 论文提出的LGBP-OrgaNet系统在器官分割和追踪方面表现出色，为器官研究提供了强有力的工具。

Abstract: Organoids replicate organ structure and function, playing a crucial role in
fields such as tumor treatment and drug screening. Their shape and size can
indicate their developmental status, but traditional fluorescence labeling
methods risk compromising their structure. Therefore, this paper proposes an
automated, non-destructive approach to organoid segmentation and tracking. We
introduced the LGBP-OrgaNet, a deep learning-based system proficient in
accurately segmenting, tracking, and quantifying organoids. The model leverages
complementary information extracted from CNN and Transformer modules and
introduces the innovative feature fusion module, Learnable Gaussian Band Pass
Fusion, to merge data from two branches. Additionally, in the decoder, the
model proposes a Bidirectional Cross Fusion Block to fuse multi-scale features,
and finally completes the decoding through progressive concatenation and
upsampling. SROrga demonstrates satisfactory segmentation accuracy and
robustness on organoids segmentation datasets, providing a potent tool for
organoid research.

</details>


### [29] [TRELLIS-Enhanced Surface Features for Comprehensive Intracranial Aneurysm Analysis](https://arxiv.org/abs/2509.03095)
*Clément Hervé,Paul Garnier,Jonathan Viquerat,Elie Hachem*

Main category: cs.CV

TL;DR: 该论文提出了一种跨域特征迁移方法，利用生成模型TRELLIS的潜在几何嵌入增强动脉瘤分析，显著提升了分类、分割和血流预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 颅内动脉瘤具有显著的临床风险，但由于缺乏标注的3D数据，其检测、描绘和建模存在困难。

Method: 提出了一种跨域特征迁移方法，利用TRELLIS（一种在大规模非医学3D数据集上训练的生成模型）学习的潜在几何嵌入，来增强神经网络在动脉瘤分析中的应用。通过用TRELLIS表面特征替代传统的点法线或网格描述符，系统地提升了三个下游任务：动脉瘤与健康血管的分类、3D网格上的动脉瘤和血管区域分割，以及使用图神经网络预测时间演化的血流场。

Result: 实验表明，引入TRELLIS特征在准确性、F1分数和分割质量上均优于现有基线方法，并将模拟误差降低了15%。

Conclusion: 该研究展示了从通用生成模型迁移3D表示到专业医学任务的广泛潜力，提升了动脉瘤分析的准确性、F1分数和分割质量，并减少了15%的模拟误差。

Abstract: Intracranial aneurysms pose a significant clinical risk yet are difficult to
detect, delineate and model due to limited annotated 3D data. We propose a
cross-domain feature-transfer approach that leverages the latent geometric
embeddings learned by TRELLIS, a generative model trained on large-scale
non-medical 3D datasets, to augment neural networks for aneurysm analysis. By
replacing conventional point normals or mesh descriptors with TRELLIS surface
features, we systematically enhance three downstream tasks: (i) classifying
aneurysms versus healthy vessels in the Intra3D dataset, (ii) segmenting
aneurysm and vessel regions on 3D meshes, and (iii) predicting time-evolving
blood-flow fields using a graph neural network on the AnXplore dataset. Our
experiments show that the inclusion of these features yields strong gains in
accuracy, F1-score and segmentation quality over state-of-the-art baselines,
and reduces simulation error by 15\%. These results illustrate the broader
potential of transferring 3D representations from general-purpose generative
models to specialized medical tasks.

</details>


### [30] [Heatmap Guided Query Transformers for Robust Astrocyte Detection across Immunostains and Resolutions](https://arxiv.org/abs/2509.03323)
*Xizhe Zhang,Jiayang Zhu*

Main category: cs.CV

TL;DR: 提出混合CNN-Transformer模型，显著提升星形胶质细胞检测性能。


<details>
  <summary>Details</summary>
Motivation: 星形胶质细胞的复杂分支和染色依赖性变异使得组织学图像的自动检测极具挑战性。

Method: 提出了一种混合CNN-Transformer检测器，结合局部特征提取和全局上下文推理，采用热图引导的查询机制生成空间锚点，并利用轻量级Transformer模块提升密集簇中的区分能力。

Result: 在ALDH1L1和GFAP染色的星形胶质细胞数据集上，该模型在FROC分析中表现优于Faster R-CNN、YOLOv11和DETR，具有更高的敏感性和更少的假阳性。

Conclusion: 该研究展示了混合CNN-Transformer架构在星形胶质细胞检测中的潜力，为高级计算病理学工具奠定了基础。

Abstract: Astrocytes are critical glial cells whose altered morphology and density are
hallmarks of many neurological disorders. However, their intricate branching
and stain dependent variability make automated detection of histological images
a highly challenging task. To address these challenges, we propose a hybrid CNN
Transformer detector that combines local feature extraction with global
contextual reasoning. A heatmap guided query mechanism generates spatially
grounded anchors for small and faint astrocytes, while a lightweight
Transformer module improves discrimination in dense clusters. Evaluated on
ALDH1L1 and GFAP stained astrocyte datasets, the model consistently
outperformed Faster R-CNN, YOLOv11 and DETR, achieving higher sensitivity with
fewer false positives, as confirmed by FROC analysis. These results highlight
the potential of hybrid CNN Transformer architectures for robust astrocyte
detection and provide a foundation for advanced computational pathology tools.

</details>


### [31] [Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods](https://arxiv.org/abs/2509.03108)
*Shota Iwamatsu,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 本文提出了一种后门投毒攻击方法，通过嵌入欺骗攻击特征到真实人脸图像中，成功绕过现有检测系统，揭示了其潜在威胁。


<details>
  <summary>Details</summary>
Motivation: 为了防止欺骗攻击，现有的人脸反欺骗检测方法大多依赖深度学习，但需要大量训练数据，若训练数据被恶意注入，可能导致特定欺骗攻击被错误分类为真实。

Method: 提出了一种新颖的后门投毒攻击方法，通过将欺骗攻击的人脸图像特征嵌入到真实人脸图像中，而不引起视觉上的明显变化。

Result: 通过在公共数据集上的实验，证明了该方法对现有欺骗攻击检测系统的实际威胁。

Conclusion: 本文提出的后门投毒攻击方法揭示了人脸反欺骗检测中潜在的威胁，通过实验证明了该方法对现有系统的实际威胁。

Abstract: Face recognition systems are robust against environmental changes and noise,
and thus may be vulnerable to illegal authentication attempts using user face
photos, such as spoofing attacks. To prevent such spoofing attacks, it is
crucial to discriminate whether the input image is a live user image or a
spoofed image prior to the face recognition process. Most existing spoofing
attack detection methods utilize deep learning, which necessitates a
substantial amount of training data. Consequently, if malicious data is
injected into a portion of the training dataset, a specific spoofing attack may
be erroneously classified as live, leading to false positives.In this paper, we
propose a novel backdoor poisoning attack method to demonstrate the latent
threat of backdoor poisoning within face anti-spoofing detection. The proposed
method enables certain spoofing attacks to bypass detection by embedding
features extracted from the spoofing attack's face image into a live face image
without inducing any perceptible visual alterations.Through experiments
conducted on public datasets, we demonstrate that the proposed method
constitutes a realistic threat to existing spoofing attack detection systems.

</details>


### [32] [TinyDrop: Tiny Model Guided Token Dropping for Vision Transformers](https://arxiv.org/abs/2509.03379)
*Guoxin Wang,Qingyuan Wang,Binhua Huang,Shaowu Chen,Deepu John*

Main category: cs.CV

TL;DR: TinyDrop是一种无需训练的token dropping框架，通过轻量级模型指导选择性丢弃token，显著降低ViTs计算成本，保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在不牺牲准确性的前提下降低大型ViTs的推理成本。

Method: 提出了TinyDrop，一种无需训练的token dropping框架，由轻量级视觉模型指导，选择性丢弃低重要性token以减少计算量。

Result: 在标准图像分类基准测试中，FLOPs减少了高达80%，且准确性下降极小。

Conclusion: TinyDrop框架通过轻量级视觉模型指导，在不影响准确性的情况下显著降低了ViTs的计算成本，展示了其在高效ViT分类中的实用性和泛化能力。

Abstract: Vision Transformers (ViTs) achieve strong performance in image classification
but incur high computational costs from processing all image tokens. To reduce
inference costs in large ViTs without compromising accuracy, we propose
TinyDrop, a training-free token dropping framework guided by a lightweight
vision model. The guidance model estimates the importance of tokens while
performing inference, thereby selectively discarding low-importance tokens if
large vit models need to perform attention calculations. The framework operates
plug-and-play, requires no architectural modifications, and is compatible with
diverse ViT architectures. Evaluations on standard image classification
benchmarks demonstrate that our framework reduces FLOPs by up to 80% for ViTs
with minimal accuracy degradation, highlighting its generalization capability
and practical utility for efficient ViT-based classification.

</details>


### [33] [Mitigating Multimodal Hallucinations via Gradient-based Self-Reflection](https://arxiv.org/abs/2509.03113)
*Shan Wang,Maying Shen,Nadine Chang,Chuong Nguyen,Hongdong Li,Jose M. Alvarez*

Main category: cs.CV

TL;DR: 本文提出一种梯度自反射方法量化token影响，并集成到影响感知解码框架中，无需额外资源即可有效减少多模态大语言模型中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型中的幻觉主要由文本-视觉偏差和共现偏差引起。现有方法启发式地解决这些偏差，但未理解实例间偏差水平的波动。本文旨在通过量化token影响并提出一个统一的解码框架来同时解决这两种偏差。

Method: 本文首先提出使用梯度自反射方法来估计不同类型token（视觉、提示和先前输出）的影响，进而检测与对象相关的视觉token，并将其集成到一个影响感知的对比解码框架中。

Result: 实验结果表明，该方法能有效减少幻觉，在LLaVA-QA90上实现了高达92%的准确率提升。

Conclusion: 本文提出了一种基于梯度自反射的方法来估计不同类型token（视觉、提示和先前输出）的影响，进而检测与对象相关的视觉token，并将其集成到一个影响感知的对比解码框架中，以同时减轻文本-视觉偏差和共现偏差。该方法无需额外资源，如昂贵的微调、额外模型或数据统计，实验证明其能有效减少幻觉，在LLaVA-QA90上实现了高达92%的准确率提升。

Abstract: Hallucinations in multimodal large language model are caused by the
text-visual bias and the co-occurrence bias. The former reflects an
over-reliance on text information in the decision-making process, while the
latter arises from the statistical object-pairing patterns abstracted from the
training data. Existing mitigation methods heuristically address these biases
without understanding the fluctuating bias level across the instances. We first
propose estimating the influence of respective token types (visual, prompt, and
previous outputs) using a gradient-based self-reflection method. The estimated
token influence further enables the detection of object-related visual tokens
and their integration into an influence-aware contrastive decoding framework to
mitigate both types of biases simultaneously. Our method operates without the
need for additional resources, such as costly fine-tuning, extra models, or
data statistics. Extensive experiments show it effectively reduces
hallucinations, achieving up to a 92% accuracy increase on LLaVA-QA90.

</details>


### [34] [Strefer: Empowering Video LLMs with Space-Time Referring and Reasoning via Synthetic Instruction Data](https://arxiv.org/abs/2509.03501)
*Honglu Zhou,Xiangyu Peng,Shrikant Kendre,Michael S. Ryoo,Silvio Savarese,Caiming Xiong,Juan Carlos Niebles*

Main category: cs.CV

TL;DR: Strefer 是一种合成指令数据生成框架，通过伪标注视频元数据提升视频 LLM 的时空推理能力，实验证明其效果优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频大型语言模型在细粒度的时空推理上表现不足，尤其是当用户查询依赖时间事件参考或手势线索时。Strefer 旨在填补这一关键空白。

Method: Strefer 是一个合成指令数据生成框架，通过伪标注密集的时间细粒度视频元数据，捕获丰富的时空信息，包括主体、对象、位置（masklets）、动作描述和时间线。

Result: 实验评估显示，使用 Strefer 生成数据训练的模型在需要时空消歧的任务上优于基线模型，并展现出更强的时空感知推理能力。

Conclusion: Strefer 框架通过生成合成指令数据，显著提升了视频大型语言模型在时空参考和推理方面的能力，为现实世界 AI 伴侣提供了更强大的基础。

Abstract: Next-generation AI companions must go beyond general video understanding to
resolve spatial and temporal references in dynamic, real-world environments.
Existing Video Large Language Models (Video LLMs), while capable of
coarse-level comprehension, struggle with fine-grained, spatiotemporal
reasoning, especially when user queries rely on time-based event references for
temporal anchoring, or gestural cues for spatial anchoring to clarify object
references and positions. To bridge this critical gap, we introduce Strefer, a
synthetic instruction data generation framework designed to equip Video LLMs
with spatiotemporal referring and reasoning capabilities. Strefer produces
diverse instruction-tuning data using a data engine that pseudo-annotates
temporally dense, fine-grained video metadata, capturing rich spatial and
temporal information in a structured manner, including subjects, objects, their
locations as masklets, and their action descriptions and timelines. Our
approach enhances the ability of Video LLMs to interpret spatial and temporal
references, fostering more versatile, space-time-aware reasoning essential for
real-world AI companions. Without using proprietary models, costly human
annotation, or the need to annotate large volumes of new videos, experimental
evaluations show that models trained with data produced by Strefer outperform
baselines on tasks requiring spatial and temporal disambiguation. Additionally,
these models exhibit enhanced space-time-aware reasoning, establishing a new
foundation for perceptually grounded, instruction-tuned Video LLMs.

</details>


### [35] [Towards Realistic Hand-Object Interaction with Gravity-Field Based Diffusion Bridge](https://arxiv.org/abs/2509.03114)
*Miao Xu,Xiangyu Zhu,Xusheng Liang,Zidu Wang,Jinlin Wu,Zhen Lei*

Main category: cs.CV

TL;DR: GravityDB通过引力场模拟手-物体交互，解决了互穿和变形捕捉问题，结合语义信息提升交互效果，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有手-物体姿态估计方法在复杂几何形状下易产生互穿或接触间隙，且难以捕捉手部变形。GravityDB旨在解决这些问题，实现更真实的交互表现。

Method: 提出了一种基于引力场的扩散桥（GravityDB）方法，模拟可变形手表面与刚性物体之间的相互作用，结合文本语义信息构建引力场，生成物理合理的交互状态。

Result: 在多个数据集上的实验表明，GravityDB能生成无互穿、稳定抓取且包含真实手部变形的交互状态，优于现有方法。

Conclusion: GravityDB方法通过模拟可变形手表面与刚性物体之间的吸引力驱动过程，有效解决了现有方法中的互穿、接触间隙和手部变形捕捉问题，并利用文本语义信息指导引力场构建，实现了物理合理且语义丰富的交互效果。

Abstract: Existing reconstruction or hand-object pose estimation methods are capable of
producing coarse interaction states. However, due to the complex and diverse
geometry of both human hands and objects, these approaches often suffer from
interpenetration or leave noticeable gaps in regions that are supposed to be in
contact. Moreover, the surface of a real human hand undergoes non-negligible
deformations during interaction, which are difficult to capture and represent
with previous methods. To tackle these challenges, we formulate hand-object
interaction as an attraction-driven process and propose a Gravity-Field Based
Diffusion Bridge (GravityDB) to simulate interactions between a deformable hand
surface and rigid objects. Our approach effectively resolves the aforementioned
issues by generating physically plausible interactions that are free of
interpenetration, ensure stable grasping, and capture realistic hand
deformations. Furthermore, we incorporate semantic information from textual
descriptions to guide the construction of the gravitational field, enabling
more semantically meaningful interaction regions. Extensive qualitative and
quantitative experiments on multiple datasets demonstrate the effectiveness of
our method.

</details>


### [36] [Temporally-Aware Diffusion Model for Brain Progression Modelling with Bidirectional Temporal Regularisation](https://arxiv.org/abs/2509.03141)
*Mattia Litrico,Francesco Guarnera,Mario Valerio Giuffrida,Daniele Ravì,Sebastiano Battiato*

Main category: cs.CV

TL;DR: TADM-3D是一种3D时间感知扩散模型，通过BAE和BITR提高了MRI时间序列预测的准确性，适用于临床脑部疾病进展分析。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉结构变化与时间间隔关系、生成具有临床实用性的未来病理进展图像以及利用3D解剖上下文方面存在不足。

Method: 提出了3D Temporally-Aware Diffusion Model (TADM-3D)，利用预训练的Brain-Age Estimator (BAE)和Back-In-Time Regularisation (BITR)来增强时间感知能力。

Result: 在OASIS-3数据集上训练和评估TADM-3D，并在NACC数据集上验证了其泛化性能，结果显示模型能生成更准确的时间序列MRI。

Conclusion: TADM-3D通过结合Brain-Age Estimator和Back-In-Time Regularisation，显著提高了MRI时间序列预测的准确性，为临床提供了更可靠的脑部疾病进展分析工具。

Abstract: Generating realistic MRIs to accurately predict future changes in the
structure of brain is an invaluable tool for clinicians in assessing clinical
outcomes and analysing the disease progression at the patient level. However,
current existing methods present some limitations: (i) some approaches fail to
explicitly capture the relationship between structural changes and time
intervals, especially when trained on age-imbalanced datasets; (ii) others rely
only on scan interpolation, which lack clinical utility, as they generate
intermediate images between timepoints rather than future pathological
progression; and (iii) most approaches rely on 2D slice-based architectures,
thereby disregarding full 3D anatomical context, which is essential for
accurate longitudinal predictions. We propose a 3D Temporally-Aware Diffusion
Model (TADM-3D), which accurately predicts brain progression on MRI volumes. To
better model the relationship between time interval and brain changes, TADM-3D
uses a pre-trained Brain-Age Estimator (BAE) that guides the diffusion model in
the generation of MRIs that accurately reflect the expected age difference
between baseline and generated follow-up scans. Additionally, to further
improve the temporal awareness of TADM-3D, we propose the Back-In-Time
Regularisation (BITR), by training TADM-3D to predict bidirectionally from the
baseline to follow-up (forward), as well as from the follow-up to baseline
(backward). Although predicting past scans has limited clinical applications,
this regularisation helps the model generate temporally more accurate scans. We
train and evaluate TADM-3D on the OASIS-3 dataset, and we validate the
generalisation performance on an external test set from the NACC dataset. The
code will be available upon acceptance.

</details>


### [37] [Preserving instance continuity and length in segmentation through connectivity-aware loss computation](https://arxiv.org/abs/2509.03154)
*Karol Szustakowski,Luk Frank,Julia Esser,Jan Gründemann,Marie Piraud*

Main category: cs.CV

TL;DR: 提出两种新型损失函数（Negative Centerline Loss和Simplified Topology Loss），通过优化CNN训练和实验设计，显著提升生物医学细长结构分割的连续性，尤其在信号丢失区域表现优异。


<details>
  <summary>Details</summary>
Motivation: 在生物医学分割任务中，保持细长结构的连续性和长度比体素级精度更为重要。现有方法在信号丢失区域易产生不连续分割，影响下游应用。

Method: 采用卷积神经网络（CNNs）并结合两种新型损失函数（Negative Centerline Loss和Simplified Topology Loss），同时优化实验设计（如降采样和间距校正）以获取连续的分割掩码。

Result: 在3D光片荧光显微镜数据集（axon initial segments, AIS）上的实验表明，相比标准CNNs和现有拓扑感知损失，新方法减少了每个实例的分割不连续性，尤其在信号丢失区域，提升了下游应用中实例长度计算的准确性。

Conclusion: 本研究提出的两种新型损失函数（Negative Centerline Loss和Simplified Topology Loss）通过嵌入结构先验，显著提升了生物医学分割任务的可靠性，特别是在保持细长结构连续性方面。

Abstract: In many biomedical segmentation tasks, the preservation of elongated
structure continuity and length is more important than voxel-wise accuracy. We
propose two novel loss functions, Negative Centerline Loss and Simplified
Topology Loss, that, applied to Convolutional Neural Networks (CNNs), help
preserve connectivity of output instances. Moreover, we discuss characteristics
of experiment design, such as downscaling and spacing correction, that help
obtain continuous segmentation masks. We evaluate our approach on a 3D
light-sheet fluorescence microscopy dataset of axon initial segments (AIS), a
task prone to discontinuity due to signal dropout. Compared to standard CNNs
and existing topology-aware losses, our methods reduce the number of
segmentation discontinuities per instance, particularly in regions with missing
input signal, resulting in improved instance length calculation in downstream
applications. Our findings demonstrate that structural priors embedded in the
loss design can significantly enhance the reliability of segmentation for
biological applications.

</details>


### [38] [Count2Density: Crowd Density Estimation without Location-level Annotations](https://arxiv.org/abs/2509.03170)
*Mattia Litrico,Feng Chen,Michael Pound,Sotirios A Tsaftaris,Sebastiano Battiato,Mario Valerio Giuffrida*

Main category: cs.CV

TL;DR: Count2Density 是一种新方法，仅需计数级注释即可生成密度图，通过历史地图库和自监督学习提升性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 减少对细粒度位置级注释的依赖，解决标注耗时且难以扩展的问题。

Method: Count2Density 利用历史地图库生成伪密度图，结合无监督显著性估计器和EMA更新策略，并通过超几何分布采样和自监督对比空间正则化增强空间感知。

Result: 实验结果表明，Count2Density 在多个数据集上表现优异，能够有效从计数级注释中提取空间信息，并实现准确的子区域计数。

Conclusion: Count2Density 通过仅使用计数级注释训练，成功生成了有意义的密度图，显著优于跨域适应方法，并在半监督设置中超越了现有最先进方法。

Abstract: Crowd density estimation is a well-known computer vision task aimed at
estimating the density distribution of people in an image. The main challenge
in this domain is the reliance on fine-grained location-level annotations,
(i.e. points placed on top of each individual) to train deep networks.
Collecting such detailed annotations is both tedious, time-consuming, and poses
a significant barrier to scalability for real-world applications. To alleviate
this burden, we present Count2Density: a novel pipeline designed to predict
meaningful density maps containing quantitative spatial information using only
count-level annotations (i.e., total number of people) during training. To
achieve this, Count2Density generates pseudo-density maps leveraging past
predictions stored in a Historical Map Bank, thereby reducing confirmation
bias. This bank is initialised using an unsupervised saliency estimator to
provide an initial spatial prior and is iteratively updated with an EMA of
predicted density maps. These pseudo-density maps are obtained by sampling
locations from estimated crowd areas using a hypergeometric distribution, with
the number of samplings determined by the count-level annotations. To further
enhance the spatial awareness of the model, we add a self-supervised
contrastive spatial regulariser to encourage similar feature representations
within crowded regions while maximising dissimilarity with background regions.
Experimental results demonstrate that our approach significantly outperforms
cross-domain adaptation methods and achieves better results than recent
state-of-the-art approaches in semi-supervised settings across several
datasets. Additional analyses validate the effectiveness of each individual
component of our pipeline, confirming the ability of Count2Density to
effectively retrieve spatial information from count-level annotations and
enabling accurate subregion counting.

</details>


### [39] [PPORLD-EDNetLDCT: A Proximal Policy Optimization-Based Reinforcement Learning Framework for Adaptive Low-Dose CT Denoising](https://arxiv.org/abs/2509.03185)
*Debopom Sutradhar,Ripon Kumar Debnath,Mohaimenul Azam Khan Raiaan,Yan Zhang,Reem E. Mohamed,Sami Azam*

Main category: cs.CV

TL;DR: PPORLD-EDNetLDCT是一种基于强化学习的LDCT去噪方法，显著提升了图像质量和分类准确性。


<details>
  <summary>Details</summary>
Motivation: LDCT在减少辐射剂量的同时会引入噪声和降低图像质量，传统去噪方法效果不佳。

Method: 提出了一种基于强化学习的Encoder-Decoder方法（PPORLD-EDNetLDCT），采用动态RL方法和PPO算法实时优化去噪策略。

Result: 在多个数据集上，PPORLD-EDNetLDCT在PSNR、SSIM和RMSE指标上优于传统和其他DL方法，并在COVID-19 LDCT数据集上提升了分类准确率至94%。

Conclusion: PPORLD-EDNetLDCT方法为LDCT成像提供了更安全、更准确的解决方案，显著提升了图像质量和分类准确性。

Abstract: Low-dose computed tomography (LDCT) is critical for minimizing radiation
exposure, but it often leads to increased noise and reduced image quality.
Traditional denoising methods, such as iterative optimization or supervised
learning, often fail to preserve image quality. To address these challenges, we
introduce PPORLD-EDNetLDCT, a reinforcement learning-based (RL) approach with
Encoder-Decoder for LDCT. Our method utilizes a dynamic RL-based approach in
which an advanced posterior policy optimization (PPO) algorithm is used to
optimize denoising policies in real time, based on image quality feedback,
trained via a custom gym environment. The experimental results on the low dose
CT image and projection dataset demonstrate that the proposed PPORLD-EDNetLDCT
model outperforms traditional denoising techniques and other DL-based methods,
achieving a peak signal-to-noise ratio of 41.87, a structural similarity index
measure of 0.9814 and a root mean squared error of 0.00236. Moreover, in
NIH-AAPM-Mayo Clinic Low Dose CT Challenge dataset our method achived a PSNR of
41.52, SSIM of 0.9723 and RMSE of 0.0051. Furthermore, we validated the quality
of denoising using a classification task in the COVID-19 LDCT dataset, where
the images processed by our method improved the classification accuracy to
94\%, achieving 4\% higher accuracy compared to denoising without RL-based
denoising. This method offers a promising solution for safer and more accurate
LDCT imaging.

</details>


### [40] [AIVA: An AI-based Virtual Companion for Emotion-aware Interaction](https://arxiv.org/abs/2509.03212)
*Chenxi Li*

Main category: cs.CV

TL;DR: 该研究提出了一种整合多模态情感感知的AI框架（\ours），通过MSPN和情感感知提示工程，实现了情感对齐的人机交互，并在多个领域展示了应用潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型（LLMs）在自然语言理解和生成方面取得了显著进展，但其仅限于单模态文本处理，无法解读非语言信号中的情感线索，限制了更沉浸式和共情的交互。

Method: 研究提出了多模态情感感知网络（MSPN），采用跨模态融合变换器和监督对比学习来捕捉情感线索，并结合情感感知提示工程策略、TTS系统和动画化头像模块，实现表达性交互。

Result: 通过整合多模态情感感知，\ours能够生成情感对齐的响应，并通过TTS和动画化头像实现表达性交互，为情感感知代理提供了框架。

Conclusion: 该研究提出了一个名为\ours的情感感知AI框架，通过整合多模态情感感知和提示工程，为更沉浸式和共情的人机交互提供了解决方案，并在伴侣机器人、社会关怀等领域展示了应用潜力。

Abstract: Recent advances in Large Language Models (LLMs) have significantly improved
natural language understanding and generation, enhancing Human-Computer
Interaction (HCI). However, LLMs are limited to unimodal text processing and
lack the ability to interpret emotional cues from non-verbal signals, hindering
more immersive and empathetic interactions. This work explores integrating
multimodal sentiment perception into LLMs to create emotion-aware agents. We
propose \ours, an AI-based virtual companion that captures multimodal sentiment
cues, enabling emotionally aligned and animated HCI. \ours introduces a
Multimodal Sentiment Perception Network (MSPN) using a cross-modal fusion
transformer and supervised contrastive learning to provide emotional cues.
Additionally, we develop an emotion-aware prompt engineering strategy for
generating empathetic responses and integrate a Text-to-Speech (TTS) system and
animated avatar module for expressive interactions. \ours provides a framework
for emotion-aware agents with applications in companion robotics, social care,
mental health, and human-centered AI.

</details>


### [41] [RTGMFF: Enhanced fMRI-based Brain Disorder Diagnosis via ROI-driven Text Generation and Multimodal Feature Fusion](https://arxiv.org/abs/2509.03214)
*Junhao Jia,Yifei Sun,Yunyou Liu,Cheng Yang,Changmiao Wang,Feiwei Qin,Yong Peng,Wenwen Min*

Main category: cs.CV

TL;DR: RTGMFF通过文本生成和多模态特征融合，提升了fMRI脑部疾病诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有fMRI诊断方法受限于低信噪比、个体间差异及模型频率感知不足，且缺乏文本注释来辅助理解脑区激活模式。

Method: RTGMFF包含三个关键组件：(i) ROI驱动的fMRI文本生成；(ii) 混合频率-空间编码器；(iii) 自适应语义对齐模块。

Result: 在ADHD-200和ABIDE基准测试中，RTGMFF在诊断准确性、敏感性和特异性方面均优于现有方法。

Conclusion: RTGMFF框架通过结合ROI驱动的文本生成、混合频率-空间编码器和自适应语义对齐模块，显著提升了脑部疾病诊断的准确性和鲁棒性，超越了现有方法。

Abstract: Functional magnetic resonance imaging (fMRI) is a powerful tool for probing
brain function, yet reliable clinical diagnosis is hampered by low
signal-to-noise ratios, inter-subject variability, and the limited frequency
awareness of prevailing CNN- and Transformer-based models. Moreover, most fMRI
datasets lack textual annotations that could contextualize regional activation
and connectivity patterns. We introduce RTGMFF, a framework that unifies
automatic ROI-level text generation with multimodal feature fusion for
brain-disorder diagnosis. RTGMFF consists of three components: (i) ROI-driven
fMRI text generation deterministically condenses each subject's activation,
connectivity, age, and sex into reproducible text tokens; (ii) Hybrid
frequency-spatial encoder fuses a hierarchical wavelet-mamba branch with a
cross-scale Transformer encoder to capture frequency-domain structure alongside
long-range spatial dependencies; and (iii) Adaptive semantic alignment module
embeds the ROI token sequence and visual features in a shared space, using a
regularized cosine-similarity loss to narrow the modality gap. Extensive
experiments on the ADHD-200 and ABIDE benchmarks show that RTGMFF surpasses
current methods in diagnostic accuracy, achieving notable gains in sensitivity,
specificity, and area under the ROC curve. Code is available at
https://github.com/BeistMedAI/RTGMFF.

</details>


### [42] [PI3DETR: Parametric Instance Detection of 3D Point Cloud Edges with a Geometry-Aware 3DETR](https://arxiv.org/abs/2509.03262)
*Fabio F. Oberweger,Michael Schwingshackl,Vanessa Staderini*

Main category: cs.CV

TL;DR: PI3DETR是一个端到端框架，直接从点云预测3D参数化曲线实例，简化流程并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖中间表示和多阶段处理的问题，提升对噪声和不同采样密度的鲁棒性，适用于真实世界的LiDAR和3D感知场景。

Method: 扩展3DETR，引入几何感知匹配策略和专用损失函数，支持在一次前向传递中统一检测不同类型的参数化曲线，如三次Bézier曲线、线段、圆和弧。

Result: 在ABC数据集上达到新的最先进水平，并能有效泛化到真实传感器数据。

Conclusion: PI3DETR通过端到端框架直接预测3D参数化曲线实例，简化了流程并提升了鲁棒性，在ABC数据集上实现了新的最先进性能，并能有效泛化到真实传感器数据。

Abstract: We present PI3DETR, an end-to-end framework that directly predicts 3D
parametric curve instances from raw point clouds, avoiding the intermediate
representations and multi-stage processing common in prior work. Extending
3DETR, our model introduces a geometry-aware matching strategy and specialized
loss functions that enable unified detection of differently parameterized curve
types, including cubic B\'ezier curves, line segments, circles, and arcs, in a
single forward pass. Optional post-processing steps further refine predictions
without adding complexity. This streamlined design improves robustness to noise
and varying sampling densities, addressing critical challenges in real world
LiDAR and 3D sensing scenarios. PI3DETR sets a new state-of-the-art on the ABC
dataset and generalizes effectively to real sensor data, offering a simple yet
powerful solution for 3D edge and curve estimation.

</details>


### [43] [SynBT: High-quality Tumor Synthesis for Breast Tumor Segmentation by 3D Diffusion Model](https://arxiv.org/abs/2509.03267)
*Hongxu Yang,Edina Timko,Levente Lippenszky,Vanda Czipczer,Lehel Ferenczi*

Main category: cs.CV

TL;DR: SynBT是一种3D医学扩散模型，通过高分辨率乳腺肿瘤合成提升MRI图像分割性能，Dice分数提高2-3%。


<details>
  <summary>Details</summary>
Motivation: 现有肿瘤合成方法在大空间体积（如MRI大视场中的乳腺肿瘤）上表现不佳，而常用方法基于小patch，限制了分割性能的提升。

Method: 提出了一种3D医学扩散模型SynBT，结合了patch-to-volume自编码器和掩码条件扩散模型，用于在选定乳腺组织区域合成高分辨率乳腺肿瘤。

Result: SynBT生成的肿瘤外观逼真，显著提升了肿瘤分割模型的性能，Dice分数提高了2-3%。

Conclusion: 提出的SynBT方法通过高质量的乳腺肿瘤合成，显著提升了MRI图像中肿瘤分割的性能，Dice分数提高了2-3%。

Abstract: Synthetic tumors in medical images offer controllable characteristics that
facilitate the training of machine learning models, leading to an improved
segmentation performance. However, the existing methods of tumor synthesis
yield suboptimal performances when tumor occupies a large spatial volume, such
as breast tumor segmentation in MRI with a large field-of-view (FOV), while
commonly used tumor generation methods are based on small patches. In this
paper, we propose a 3D medical diffusion model, called SynBT, to generate
high-quality breast tumor (BT) in contrast-enhanced MRI images. The proposed
model consists of a patch-to-volume autoencoder, which is able to compress the
high-resolution MRIs into compact latent space, while preserving the resolution
of volumes with large FOV. Using the obtained latent space feature vector, a
mask-conditioned diffusion model is used to synthesize breast tumors within
selected regions of breast tissue, resulting in realistic tumor appearances. We
evaluated the proposed method for a tumor segmentation task, which demonstrated
the proposed high-quality tumor synthesis method can facilitate the common
segmentation models with performance improvement of 2-3% Dice Score on a large
public dataset, and therefore provides benefits for tumor segmentation in MRI
images.

</details>


### [44] [PointAD+: Learning Hierarchical Representations for Zero-shot 3D Anomaly Detection](https://arxiv.org/abs/2509.03277)
*Qihang Zhou,Shibo He,Jiangtao Yan,Wenchao Meng,Jiming Chen*

Main category: cs.CV

TL;DR: 提出PointAD+框架，结合隐式和显式3D表示，通过分层学习和跨层次对齐，实现高效3D异常检测。


<details>
  <summary>Details</summary>
Motivation: 将CLIP的2D泛化能力迁移到3D异常检测中，以识别具有高度多样性的未见对象的3D异常。

Method: 提出PointAD和PointAD+框架，分别利用点-像素对应关系和空间异常关系来检测3D异常。PointAD+通过分层表示学习和跨层次对比对齐，结合渲染和几何信息。

Result: 实验证明PointAD+在未见对象上实现了全面的3D异常检测，性能优异。

Conclusion: PointAD+通过结合隐式和显式3D表示，以及跨层次对比对齐，实现了对3D异常的全面检测和分割，尤其在未见对象上表现出色。

Abstract: In this paper, we aim to transfer CLIP's robust 2D generalization
capabilities to identify 3D anomalies across unseen objects of highly diverse
class semantics. To this end, we propose a unified framework to comprehensively
detect and segment 3D anomalies by leveraging both point- and pixel-level
information. We first design PointAD, which leverages point-pixel
correspondence to represent 3D anomalies through their associated rendering
pixel representations. This approach is referred to as implicit 3D
representation, as it focuses solely on rendering pixel anomalies but neglects
the inherent spatial relationships within point clouds. Then, we propose
PointAD+ to further broaden the interpretation of 3D anomalies by introducing
explicit 3D representation, emphasizing spatial abnormality to uncover abnormal
spatial relationships. Hence, we propose G-aggregation to involve geometry
information to enable the aggregated point representations spatially aware. To
simultaneously capture rendering and spatial abnormality, PointAD+ proposes
hierarchical representation learning, incorporating implicit and explicit
anomaly semantics into hierarchical text prompts: rendering prompts for the
rendering layer and geometry prompts for the geometry layer. A cross-hierarchy
contrastive alignment is further introduced to promote the interaction between
the rendering and geometry layers, facilitating mutual anomaly learning.
Finally, PointAD+ integrates anomaly semantics from both layers to capture the
generalized anomaly semantics. During the test, PointAD+ can integrate RGB
information in a plug-and-play manner and further improve its detection
performance. Extensive experiments demonstrate the superiority of PointAD+ in
ZS 3D anomaly detection across unseen objects with highly diverse class
semantics, achieving a holistic understanding of abnormality.

</details>


### [45] [Empowering Lightweight MLLMs with Reasoning via Long CoT SFT](https://arxiv.org/abs/2509.03321)
*Linyu Ou*

Main category: cs.CV

TL;DR: 长链思维数据通过SFT显著提升轻量级MLLMs的推理能力，后续RL阶段可进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习与可验证奖励已提升大规模语言模型（LLMs）的推理能力，但其对参数少于70亿的轻量级多模态语言模型（MLLMs）的效果尚未充分研究。

Method: 研究通过监督微调（SFT）和后续的强化学习（RL）阶段，探索长链思维数据对轻量级MLLMs推理能力的提升效果。

Result: 研究发现，使用长CoT数据进行SFT显著提升MLLMs的推理能力，且后续RL阶段可进一步带来性能增益。

Conclusion: SFT阶段使用长链思维（long CoT）数据是开发轻量级多模态语言模型（MLLMs）推理能力的关键前提。

Abstract: While Reinforcement Learning with Verifiable Rewards has enhanced the
reasoning of large-scale language models (LLMs), its efficacy for lightweight
multimodal language models (MLLMs) with fewer than seven billion parameters
remains underexplored. This paper investigates the role of long
Chain-of-Thought (long CoT) data in enhancing the reasoning abilities of such
MLLMs. Our findings demonstrate that Supervised Fine-Tuning (SFT) with long CoT
data significantly improves MLLM reasoning. Furthermore, we observe that after
this initial SFT phase, MLLMs can achieve additional performance gains through
a subsequent RL stage. We conclude that a SFT stage with long CoT data is a
critical prerequisite for developing the reasoning capabilities of lightweight
MLLMs.

</details>


### [46] [InfraDiffusion: zero-shot depth map restoration with diffusion models and prompted segmentation from sparse infrastructure point clouds](https://arxiv.org/abs/2509.03324)
*Yixiong Jing,Cheng Zhang,Haibing Wu,Guangming Wang,Olaf Wysocki,Brian Sheil*

Main category: cs.CV

TL;DR: InfraDiffusion通过点云转深度图并恢复，提升砖块级分割效果，适用于低光环境下的砖石结构检测。


<details>
  <summary>Details</summary>
Motivation: 在低光环境下获取高分辨率图像不切实际，而点云虽对暗光环境鲁棒，但通常非结构化、稀疏且有噪声，限制了细粒度分割。

Method: 提出InfraDiffusion框架，利用虚拟相机将砖石点云投影为深度图，并通过DDNM进行恢复，无需任务特定训练。

Result: 在砖石桥梁和隧道点云数据集上的实验表明，使用SAM进行砖块级分割有显著改进。

Conclusion: InfraDiffusion通过将点云投影为深度图并利用DDNM进行恢复，显著提升了砖块级分割的效果，展示了其在砖石结构自动检测中的潜力。

Abstract: Point clouds are widely used for infrastructure monitoring by providing
geometric information, where segmentation is required for downstream tasks such
as defect detection. Existing research has automated semantic segmentation of
structural components, while brick-level segmentation (identifying defects such
as spalling and mortar loss) has been primarily conducted from RGB images.
However, acquiring high-resolution images is impractical in low-light
environments like masonry tunnels. Point clouds, though robust to dim lighting,
are typically unstructured, sparse, and noisy, limiting fine-grained
segmentation. We present InfraDiffusion, a zero-shot framework that projects
masonry point clouds into depth maps using virtual cameras and restores them by
adapting the Denoising Diffusion Null-space Model (DDNM). Without task-specific
training, InfraDiffusion enhances visual clarity and geometric consistency of
depth maps. Experiments on masonry bridge and tunnel point cloud datasets show
significant improvements in brick-level segmentation using the Segment Anything
Model (SAM), underscoring its potential for automated inspection of masonry
assets. Our code and data is available at
https://github.com/Jingyixiong/InfraDiffusion-official-implement.

</details>


### [47] [Transformer-Guided Content-Adaptive Graph Learning for Hyperspectral Unmixing](https://arxiv.org/abs/2509.03376)
*Hui Chen,Liangyu Liu,Xianchao Xiu,Wanquan Liu*

Main category: cs.CV

TL;DR: T-CAGU框架结合Transformer和图神经网络，有效平衡高光谱解混中的全局与局部特征，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在高光谱解混中难以同时表征全局依赖和局部一致性，导致长距离相互作用和边界细节难以兼顾。

Method: 提出了一种新颖的Transformer引导的内容自适应图解混框架（T-CAGU），利用Transformer捕获全局依赖，并通过内容自适应图神经网络增强局部关系。此外，整合了多种传播顺序以动态学习图结构，并采用图残差机制保留全局信息和稳定训练。

Result: 实验结果表明，T-CAGU在性能上优于现有最先进方法。

Conclusion: T-CAGU框架通过结合Transformer和内容自适应图神经网络，成功解决了高光谱解混中全局依赖和局部一致性的平衡问题，并在实验中表现出优于现有方法的性能。

Abstract: Hyperspectral unmixing (HU) targets to decompose each mixed pixel in remote
sensing images into a set of endmembers and their corresponding abundances.
Despite significant progress in this field using deep learning, most methods
fail to simultaneously characterize global dependencies and local consistency,
making it difficult to preserve both long-range interactions and boundary
details. This letter proposes a novel transformer-guided content-adaptive graph
unmixing framework (T-CAGU), which overcomes these challenges by employing a
transformer to capture global dependencies and introducing a content-adaptive
graph neural network to enhance local relationships. Unlike previous work,
T-CAGU integrates multiple propagation orders to dynamically learn the graph
structure, ensuring robustness against noise. Furthermore, T-CAGU leverages a
graph residual mechanism to preserve global information and stabilize training.
Experimental results demonstrate its superiority over the state-of-the-art
methods. Our code is available at https://github.com/xianchaoxiu/T-CAGU.

</details>


### [48] [Human Preference-Aligned Concept Customization Benchmark via Decomposed Evaluation](https://arxiv.org/abs/2509.03385)
*Reina Ishikawa,Ryo Fujii,Hideo Saito,Ryo Hachiuma*

Main category: cs.CV

TL;DR: 本文提出D-GPTScore，一种基于多模态大语言模型的人类偏好对齐评估方法，显著优于现有方法，并发布CC-AlignBench基准。


<details>
  <summary>Details</summary>
Motivation: 评估概念定制具有挑战性，现有指标往往过于狭窄或泛化，与人类偏好不一致。

Method: 提出Decomposed GPT Score (D-GPTScore)，通过将评估标准分解为更细的方面，并利用多模态大语言模型（MLLM）进行逐方面评估。

Result: D-GPTScore在CC-AlignBench基准上显著优于现有方法，与人类偏好相关性更高。

Conclusion: 本文提出了一种新的评估方法D-GPTScore，显著优于现有方法，并与人类偏好有更高相关性，为概念定制评估设立了新标准。

Abstract: Evaluating concept customization is challenging, as it requires a
comprehensive assessment of fidelity to generative prompts and concept images.
Moreover, evaluating multiple concepts is considerably more difficult than
evaluating a single concept, as it demands detailed assessment not only for
each individual concept but also for the interactions among concepts. While
humans can intuitively assess generated images, existing metrics often provide
either overly narrow or overly generalized evaluations, resulting in
misalignment with human preference. To address this, we propose Decomposed GPT
Score (D-GPTScore), a novel human-aligned evaluation method that decomposes
evaluation criteria into finer aspects and incorporates aspect-wise assessments
using Multimodal Large Language Model (MLLM). Additionally, we release Human
Preference-Aligned Concept Customization Benchmark (CC-AlignBench), a benchmark
dataset containing both single- and multi-concept tasks, enabling stage-wise
evaluation across a wide difficulty range -- from individual actions to
multi-person interactions. Our method significantly outperforms existing
approaches on this benchmark, exhibiting higher correlation with human
preferences. This work establishes a new standard for evaluating concept
customization and highlights key challenges for future research. The benchmark
and associated materials are available at
https://github.com/ReinaIshikawa/D-GPTScore.

</details>


### [49] [Scalable and Loosely-Coupled Multimodal Deep Learning for Breast Cancer Subtyping](https://arxiv.org/abs/2509.03408)
*Mohammed Amer,Mohamed A. Suliman,Tu Bui,Nuria Garcia,Serban Georgescu*

Main category: cs.CV

TL;DR: 该研究提出了一种可扩展的多模态框架，用于乳腺癌分子分型，通过双重WSI表示和新融合策略，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医疗应用本质上是多模态的，但临床环境中可用的模态因地点和患者而异。乳腺癌分子分型是一个重要的临床任务，可以从多模态整合中获益。

Method: 研究引入了一种基于双重的全切片图像（WSI）表示方法，结合了传统的基于图像和基于图的WSI表示，并提出了一种新的多模态融合策略。

Result: 综合结果表明，将双重的WSI表示与CNV和临床健康记录整合，结合研究提出的流程和融合策略，在乳腺癌分子分型中优于现有方法。

Conclusion: 该研究提出的可扩展、松散耦合的多模态框架在乳腺癌分子分型中表现出色，优于现有方法，并具有应用于其他癌症类型的潜力。

Abstract: Healthcare applications are inherently multimodal, benefiting greatly from
the integration of diverse data sources. However, the modalities available in
clinical settings can vary across different locations and patients. A key area
that stands to gain from multimodal integration is breast cancer molecular
subtyping, an important clinical task that can facilitate personalized
treatment and improve patient prognosis. In this work, we propose a scalable
and loosely-coupled multimodal framework that seamlessly integrates data from
various modalities, including copy number variation (CNV), clinical records,
and histopathology images, to enhance breast cancer subtyping. While our
primary focus is on breast cancer, our framework is designed to easily
accommodate additional modalities, offering the flexibility to scale up or down
with minimal overhead without requiring re-training of existing modalities,
making it applicable to other types of cancers as well. We introduce a
dual-based representation for whole slide images (WSIs), combining traditional
image-based and graph-based WSI representations. This novel dual approach
results in significant performance improvements. Moreover, we present a new
multimodal fusion strategy, demonstrating its ability to enhance performance
across a range of multimodal conditions. Our comprehensive results show that
integrating our dual-based WSI representation with CNV and clinical health
records, along with our pipeline and fusion strategy, outperforms
state-of-the-art methods in breast cancer subtyping.

</details>


### [50] [Time-Scaling State-Space Models for Dense Video Captioning](https://arxiv.org/abs/2509.03426)
*AJ Piergiovanni,Ganesh Satish Mallya,Dahun Kim,Anelia Angelova*

Main category: cs.CV

TL;DR: Proposes State-Space Models with Transfer State for online dense video captioning, reducing FLOPs by 7x and enabling real-time processing.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with long videos due to computational complexity and memory limitations, and cannot process videos online. The proposed method aims to address these challenges.

Method: The approach combines the long-sequence and recurrent properties of SSMs, introducing a Transfer State to sustain state for very long contexts.

Result: The model scales well with video lengths, uses 7x fewer FLOPs, and enables on-the-fly caption generation without full video processing.

Conclusion: State-Space Models with Transfer State effectively scales SSMs further in time, making them suitable for online dense video captioning with reduced computational costs.

Abstract: Dense video captioning is a challenging video understanding task which aims
to simultaneously segment the video into a sequence of meaningful consecutive
events and to generate detailed captions to accurately describe each event.
Existing methods often encounter difficulties when working with the long videos
associated with dense video captioning, due to the computational complexity and
memory limitations. Furthermore, traditional approaches require the entire
video as input, in order to produce an answer, which precludes online
processing of the video. We address these challenges by time-scaling
State-Space Models (SSMs) to even longer sequences than before. Our approach,
State-Space Models with Transfer State, combines both the long-sequence and
recurrent properties of SSMs and addresses the main limitation of SSMs which
are otherwise not able to sustain their state for very long contexts,
effectively scaling SSMs further in time. The proposed model is particularly
suitable for generating captions on-the-fly, in an online or streaming manner,
without having to wait for the full video to be processed, which is more
beneficial in practice. When applied to dense video captioning, our approach
scales well with video lengths and uses 7x fewer FLOPs.

</details>


### [51] [Decoding Visual Neural Representations by Multimodal with Dynamic Balancing](https://arxiv.org/abs/2509.03433)
*Kaili sun,Xingyu Miao,Bing Zhai,Haoran Duan,Yang Long*

Main category: cs.CV

TL;DR: 提出整合EEG、图像和文本的多模态框架，通过文本增强语义对应，优化特征对齐与融合，显著提升解码准确率。


<details>
  <summary>Details</summary>
Motivation: 解决低信噪比EEG信号解码视觉神经表示的挑战，利用文本模态提升语义对应，优化跨模态特征融合。

Method: 通过引入文本模态增强EEG信号与视觉内容的语义对应，提出适配器模块优化跨模态特征对齐与融合，并采用MCDB策略动态平衡模态贡献权重，以及SPR项增强模型泛化能力。

Result: 在ThingsEEG数据集上，Top-1和Top-5准确率分别提升2.0%和4.7%，优于现有方法。

Conclusion: 提出的创新框架在ThingsEEG数据集上表现优异，Top-1和Top-5准确率分别提升2.0%和4.7%，验证了方法的有效性。

Abstract: In this work, we propose an innovative framework that integrates EEG, image,
and text data, aiming to decode visual neural representations from low
signal-to-noise ratio EEG signals. Specifically, we introduce text modality to
enhance the semantic correspondence between EEG signals and visual content.
With the explicit semantic labels provided by text, image and EEG features of
the same category can be more closely aligned with the corresponding text
representations in a shared multimodal space. To fully utilize pre-trained
visual and textual representations, we propose an adapter module that
alleviates the instability of high-dimensional representation while
facilitating the alignment and fusion of cross-modal features. Additionally, to
alleviate the imbalance in multimodal feature contributions introduced by the
textual representations, we propose a Modal Consistency Dynamic Balance (MCDB)
strategy that dynamically adjusts the contribution weights of each modality. We
further propose a stochastic perturbation regularization (SPR) term to enhance
the generalization ability of semantic perturbation-based models by introducing
dynamic Gaussian noise in the modality optimization process. The evaluation
results on the ThingsEEG dataset show that our method surpasses previous
state-of-the-art methods in both Top-1 and Top-5 accuracy metrics, improving by
2.0\% and 4.7\% respectively.

</details>


### [52] [Joint Training of Image Generator and Detector for Road Defect Detection](https://arxiv.org/abs/2509.03465)
*Kuan-Chuan Peng*

Main category: cs.CV

TL;DR: JTGD通过联合训练生成器和检测器，在资源受限的边缘设备上实现了高效的道路缺陷检测。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备资源有限的问题，避免使用集成方法或测试时增强（TTA）。

Method: 提出联合训练图像生成器和检测器（JTGD），设计双判别器以提高合成图像质量，并使用CLIP-based Fréchet Inception Distance损失。

Result: JTGD在无需集成和TTA的情况下，性能优于现有方法，且参数量少于基线的20%。

Conclusion: JTGD方法在RDD2022道路缺陷检测基准测试中表现优异，适用于边缘设备部署。

Abstract: Road defect detection is important for road authorities to reduce the vehicle
damage caused by road defects. Considering the practical scenarios where the
defect detectors are typically deployed on edge devices with limited memory and
computational resource, we aim at performing road defect detection without
using ensemble-based methods or test-time augmentation (TTA). To this end, we
propose to Jointly Train the image Generator and Detector for road defect
detection (dubbed as JTGD). We design the dual discriminators for the
generative model to enforce both the synthesized defect patches and overall
images to look plausible. The synthesized image quality is improved by our
proposed CLIP-based Fr\'echet Inception Distance loss. The generative model in
JTGD is trained jointly with the detector to encourage the generative model to
synthesize harder examples for the detector. Since harder synthesized images of
better quality caused by the aforesaid design are used in the data
augmentation, JTGD outperforms the state-of-the-art method in the RDD2022 road
defect detection benchmark across various countries under the condition of no
ensemble and TTA. JTGD only uses less than 20% of the number of parameters
compared with the competing baseline, which makes it more suitable for
deployment on edge devices in practice.

</details>


### [53] [Parameter-Efficient Adaptation of mPLUG-Owl2 via Pixel-Level Visual Prompts for NR-IQA](https://arxiv.org/abs/2509.03494)
*Yahya Benmahane,Mohammed El Hassouni*

Main category: cs.CV

TL;DR: 提出了一种高效的视觉提示方法，仅微调少量参数，在NR-IQA任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决全微调多模态大语言模型（MLLMs）在NR-IQA任务中的高计算成本问题，同时保持高性能。

Method: 提出了一种参数高效的适配方法，仅训练最多60万个参数（<0.01%的基础模型参数），同时保持基础模型完全冻结。推理时，视觉提示通过加法与图像结合，并由mPLUG-Owl2处理文本查询“评估图像的技术质量”。

Result: 在KADID-10k、KonIQ-10k和AGIQA-3k等数据集上，针对合成、真实和AI生成等失真类型，表现优于全微调方法和专用NR-IQA模型，KADID-10k上的SRCC达到0.93。

Conclusion: 本研究首次利用像素空间视觉提示进行无参考图像质量评估（NR-IQA），为低层视觉任务提供了高效的多模态大语言模型（MLLM）适配方法。

Abstract: In this paper, we propose a novel parameter-efficient adaptation method for
No- Reference Image Quality Assessment (NR-IQA) using visual prompts optimized
in pixel-space. Unlike full fine-tuning of Multimodal Large Language Models
(MLLMs), our approach trains only 600K parameters at most (< 0.01% of the base
model), while keeping the underlying model fully frozen. During inference,
these visual prompts are combined with images via addition and processed by
mPLUG-Owl2 with the textual query "Rate the technical quality of the image."
Evaluations across distortion types (synthetic, realistic, AI-generated) on
KADID- 10k, KonIQ-10k, and AGIQA-3k demonstrate competitive performance against
full finetuned methods and specialized NR-IQA models, achieving 0.93 SRCC on
KADID-10k. To our knowledge, this is the first work to leverage pixel-space
visual prompts for NR-IQA, enabling efficient MLLM adaptation for low-level
vision tasks. The source code is publicly available at https: // github. com/
yahya-ben/ mplug2-vp-for-nriqa .

</details>


### [54] [OneCAT: Decoder-Only Auto-Regressive Model for Unified Understanding and Generation](https://arxiv.org/abs/2509.03498)
*Han Li,Xinyu Peng,Yaoming Wang,Zelin Peng,Xin Chen,Rongxiang Weng,Jingang Wang,Xunliang Cai,Wenrui Dai,Hongkai Xiong*

Main category: cs.CV

TL;DR: OneCAT 是一种纯解码器架构的统一多模态模型，通过MoE结构和多尺度视觉自回归机制，高效支持理解、生成和编辑任务，性能超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 旨在创建一个无需外部组件（如ViT或视觉分词器）的高效统一多模态模型，支持动态分辨率并提升性能。

Method: 通过模态特定的混合专家（MoE）结构和单一自回归目标训练，结合多尺度视觉自回归机制，显著减少了解码步骤。

Result: OneCAT 在多项基准测试中表现优异，显著提升了效率并保持了最先进的性能。

Conclusion: OneCAT 展示了纯自回归模型作为统一多模态智能基础的强大潜力，并在多模态生成、编辑和理解任务中超越了现有开源统一多模态模型。

Abstract: We introduce OneCAT, a unified multimodal model that seamlessly integrates
understanding, generation, and editing within a novel, pure decoder-only
transformer architecture. Our framework uniquely eliminates the need for
external components such as Vision Transformers (ViT) or vision tokenizer
during inference, leading to significant efficiency gains, especially for
high-resolution inputs. This is achieved through a modality-specific
Mixture-of-Experts (MoE) structure trained with a single autoregressive (AR)
objective, which also natively supports dynamic resolutions. Furthermore, we
pioneer a multi-scale visual autoregressive mechanism within the Large Language
Model (LLM) that drastically reduces decoding steps compared to diffusion-based
methods while maintaining state-of-the-art performance. Our findings
demonstrate the powerful potential of pure autoregressive modeling as a
sufficient and elegant foundation for unified multimodal intelligence. As a
result, OneCAT sets a new performance standard, outperforming existing
open-source unified multimodal models across benchmarks for multimodal
generation, editing, and understanding.

</details>


### [55] [DeepSea MOT: A benchmark dataset for multi-object tracking on deep-sea video](https://arxiv.org/abs/2509.03499)
*Kevin Barnard,Elaine Liu,Kristine Walz,Brian Schlining,Nancy Jacobsen Stout,Lonny Lundsten*

Main category: cs.CV

TL;DR: 首个公开的深海视频多目标跟踪基准数据集，包含四个视频序列，用于评估目标检测和跟踪器性能，采用高阶跟踪准确性指标，提供数据和计算工具。


<details>
  <summary>Details</summary>
Motivation: 基准测试多目标跟踪和目标检测模型的性能是机器学习模型开发的关键步骤，它使研究人员能够在人类生成的“测试”数据上评估模型检测和跟踪器性能，促进模型和跟踪器之间的一致比较并帮助优化性能。

Method: 开发了一个新颖的基准视频数据集，用于评估多个蒙特雷湾水族馆研究所的目标检测模型和FathomNet单类目标检测模型及多个跟踪器的性能。数据集包含四个代表中水和底栖深海栖息地的视频序列。性能评估采用高阶跟踪准确性（Higher Order Tracking Accuracy）指标，平衡了检测、定位和关联准确性。

Result: 研究结果表明，该基准数据集能够有效评估多目标跟踪和目标检测模型的性能，为深海视频分析提供了首个公开的基准。

Conclusion: 本研究提供了首个公开的深海视频多目标跟踪基准数据集，包括基准数据、生成额外基准视频的清晰文档化工作流程以及计算指标的示例Python笔记本。

Abstract: Benchmarking multi-object tracking and object detection model performance is
an essential step in machine learning model development, as it allows
researchers to evaluate model detection and tracker performance on
human-generated 'test' data, facilitating consistent comparisons between models
and trackers and aiding performance optimization. In this study, a novel
benchmark video dataset was developed and used to assess the performance of
several Monterey Bay Aquarium Research Institute object detection models and a
FathomNet single-class object detection model together with several trackers.
The dataset consists of four video sequences representing midwater and benthic
deep-sea habitats. Performance was evaluated using Higher Order Tracking
Accuracy, a metric that balances detection, localization, and association
accuracy. To the best of our knowledge, this is the first publicly available
benchmark for multi-object tracking in deep-sea video footage. We provide the
benchmark data, a clearly documented workflow for generating additional
benchmark videos, as well as example Python notebooks for computing metrics.

</details>


### [56] [A comprehensive Persian offline handwritten database for investigating the effects of heritability and family relationships on handwriting](https://arxiv.org/abs/2509.03510)
*Abbas Zohrevand,Javad Sadri,Zahra Imani*

Main category: cs.CV

TL;DR: 该论文建立了一个手写遗产数据库，研究遗传对手写的影响，发现家庭成员间手写相似性，数据库免费开放。


<details>
  <summary>Details</summary>
Motivation: 探讨手写是否存在遗传成分、是否可遗传以及家庭关系是否影响手写。目前缺乏此类数据库。

Method: 收集了210个家庭的手写样本（包括数字、字母、形状和自由段落），并记录家庭关系。通过比较家庭成员的手写特征，检测相似性和写作风格。

Result: 创建了一个独特的手写遗产数据库，发现家庭成员间手写特征和风格的相似性。

Conclusion: 该论文建立了一个全面的手写遗产数据库，以研究遗传对手写的影响，并发现家庭成员间手写特征的相似性。数据库对模式识别社区免费开放。

Abstract: This paper introduces a comprehensive database for research and investigation
on the effects of inheritance on handwriting. A database has been created that
can be used to answer questions such as: Is there a genetic component to
handwriting? Is handwriting inherited? Do family relationships affect
handwriting? Varieties of samples of handwritten components such as: digits,
letters, shapes and free paragraphs of 210 families including (grandparents,
parents, uncles, aunts, siblings, cousins, nephews and nieces) have been
collected using specially designed forms, and family relationships of all
writers are captured. To the best of our knowledge, no such database is
presently available. Based on comparisons and investigation of features of
handwritings of family members, similarities among their features and writing
styles are detected. Our database is freely available to the pattern
recognition community and hope it will pave the way for investigations on the
effects of inheritance and family relationships on handwritings.

</details>


### [57] [Easier Painting Than Thinking: Can Text-to-Image Models Set the Stage, but Not Direct the Play?](https://arxiv.org/abs/2509.03516)
*Ouxiang Li,Yuan Wang,Xinting Hu,Huijuan Huang,Rui Chen,Jiarong Ou,Xin Tao,Pengfei Wan,Fuli Feng*

Main category: cs.CV

TL;DR: T2I-CoReBench是一个新基准测试，用于评估T2I模型的组合和推理能力。实验表明，当前模型在复杂场景中表现不佳，尤其是推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在全面评估T2I模型的组合和推理能力方面存在局限性，且无法应对复杂提示。T2I-CoReBench旨在填补这一空白。

Method: 通过构建围绕场景图元素（实例、属性和关系）的组合和基于哲学推理框架（演绎、归纳和溯因）的推理，提出了一个12维评估分类法。每个提示都具有高组合密度和多步推理，并配有检查清单以独立评估每个元素。

Result: 基准测试包含1,080个挑战性提示和约13,500个检查清单问题。实验显示，当前模型在复杂场景中的组合能力有限，推理能力尤为薄弱。

Conclusion: T2I-CoReBench 是一个全面且复杂的基准测试，旨在评估文本到图像（T2I）模型的组合和推理能力。实验结果表明，当前模型在复杂高密度场景中的组合能力仍有限，推理能力更是瓶颈。

Abstract: Text-to-image (T2I) generation aims to synthesize images from textual
prompts, which jointly specify what must be shown and imply what can be
inferred, thereby corresponding to two core capabilities: composition and
reasoning. However, with the emerging advances of T2I models in reasoning
beyond composition, existing benchmarks reveal clear limitations in providing
comprehensive evaluations across and within these capabilities. Meanwhile,
these advances also enable models to handle more complex prompts, whereas
current benchmarks remain limited to low scene density and simplified
one-to-one reasoning. To address these limitations, we propose T2I-CoReBench, a
comprehensive and complex benchmark that evaluates both composition and
reasoning capabilities of T2I models. To ensure comprehensiveness, we structure
composition around scene graph elements (instance, attribute, and relation) and
reasoning around the philosophical framework of inference (deductive,
inductive, and abductive), formulating a 12-dimensional evaluation taxonomy. To
increase complexity, driven by the inherent complexities of real-world
scenarios, we curate each prompt with high compositional density for
composition and multi-step inference for reasoning. We also pair each prompt
with a checklist that specifies individual yes/no questions to assess each
intended element independently to facilitate fine-grained and reliable
evaluation. In statistics, our benchmark comprises 1,080 challenging prompts
and around 13,500 checklist questions. Experiments across 27 current T2I models
reveal that their composition capability still remains limited in complex
high-density scenarios, while the reasoning capability lags even further behind
as a critical bottleneck, with all models struggling to infer implicit elements
from prompts. Our project page: https://t2i-corebench.github.io/.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [58] [A Novel IaaS Tax Model as Leverage Towards Green Cloud Computing](https://arxiv.org/abs/2509.02767)
*Benedikt Pittl,Werner Mach,Erich Schikuta*

Main category: cs.DC

TL;DR: 通过经济税收模型GreenCloud，激励高效数据中心，惩罚低效中心，从而降低能耗，模拟验证有效。


<details>
  <summary>Details</summary>
Motivation: 随着数据中心能耗持续上升，需要创新的方法来提高能源效率。经济手段如税收可激励能源高效的数据中心，同时惩罚低效者。

Method: 开发并实施了GreenCloud税收模型，利用CloudSim模拟环境，结合SPEC基准发布的真实数据集进行仿真评估。

Result: GreenCloud税收模型成功地将工作负载从能源低效数据中心转移到高效数据中心，降低了整体能源消耗。

Conclusion: GreenCloud税收模型通过经济激励和惩罚机制，有效促进了数据中心向能源高效方向的转变，从而降低了整体能源消耗。

Abstract: The cloud computing technology uses datacenters, which require energy. Recent
trends show that the required energy for these datacenters will rise over time,
or at least remain constant. Hence, the scientific community developed
different algorithms, architectures, and approaches for improving the energy
efficiency of cloud datacenters, which are summarized under the umbrella term
Green Cloud computing. In this paper, we use an economic approach - taxes - for
reducing the energy consumption of datacenters. We developed a tax model called
GreenCloud tax, which penalizes energy-inefficient datacenters while fostering
datacenters that are energy-efficient. Hence, providers running
energy-efficient datacenters are able to offer cheaper prices to consumers,
which consequently leads to a shift of workloads from energy-inefficient
datacenters to energy-efficient datacenters. The GreenCloud tax approach was
implemented using the simulation environment CloudSim. We applied real data
sets published in the SPEC benchmark for the executed simulation scenarios,
which we used for evaluating the GreenCloud tax.

</details>


### [59] [Mycroft: Tracing Dependencies in Collective Communication Towards Reliable LLM Training](https://arxiv.org/abs/2509.03018)
*Yangtao Deng,Lei Zhang,Qinlong Wang,Xiaoyun Zhi,Xinlei Zhang,Zhuo Jiang,Haohan Xu,Lei Wang,Zuquan Song,Gaohong Liu,Yang Bai,Shuguang Wang,Wencong Xiao,Jianxi Ye,Minlan Yu,Hong Xu*

Main category: cs.DC

TL;DR: Mycroft 是一个针对LLM训练中集体通信可靠性问题的追踪与根因分析系统，能快速检测和诊断问题，已在实际部署中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 当前集体通信库作为黑箱运行，缺乏有效根因分析所需的关键信息，导致LLM训练中资源浪费和性能下降。

Method: Mycroft 通过追踪集体通信状态并利用内部控制和数据依赖关系来诊断和解决可靠性问题。

Result: Mycroft 在90%的案例中15秒内检测到异常，60%的案例中20秒内确定根因，并通过广泛的故障注入实验验证了其能力与效率。

Conclusion: Mycroft 是一个轻量级的分布式追踪和根因分析系统，有效解决了LLM训练中集体通信的可靠性问题，已在字节跳动成功部署并展示了高效的问题检测和诊断能力。

Abstract: Reliability is essential for ensuring efficiency in LLM training. However,
many real-world reliability issues remain difficult to resolve, resulting in
wasted resources and degraded model performance. Unfortunately, today's
collective communication libraries operate as black boxes, hiding critical
information needed for effective root cause analysis. We propose Mycroft, a
lightweight distributed tracing and root cause analysis system designed to
address previously hidden reliability issues in collective communication.
Mycroft's key idea is to trace collective communication states and leverage
internal control and data dependencies to resolve reliability problems in LLM
training. Mycroft has been deployed at ByteDance for over six months to debug
collective communication related issues at runtime. It detected anomalies
within 15 seconds in 90% of cases and identified the root cause within 20
seconds in 60% of cases. We also conducted extensive fault injection
experiments to demonstrate Mycroft's capability and efficiency.

</details>


### [60] [FlashRecovery: Fast and Low-Cost Recovery from Failures for Large-Scale Training of LLMs](https://arxiv.org/abs/2509.03047)
*Haijun Zhang,Jinxiang Wang,Zhenhua Yu,Yanyong Zhang,Xuejie Ji,Kaining Mao,Jun Zhang,Yaqing Zhang,Ting Wu,Fei Jie,Xiemin Huang,Zhifang Cai,Junhua Cheng,Shuwei Wang,Wei Li,Xiaoming Bao,Hua Xu,Shixiong Zhao,Jun Li,Hongwei Sun,Ziyang Zhang,Yi Xiong,Chunsheng Li*

Main category: cs.DC

TL;DR: FlashRecovery是一个快速低成本的故障恢复系统，通过三个核心模块显著提升大规模语言模型训练的可靠性，实验证明其高效性。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型训练过程中，硬件和软件故障导致训练时间大量损失，亟需一种快速且低成本的故障恢复系统。

Method: FlashRecovery系统包含三个核心模块：(1) 主动实时的故障检测；(2) 规模无关的任务重启；(3) 一步内无需检查点的恢复机制。

Result: 实验结果表明，FlashRecovery系统能在150秒内恢复4800个设备的训练集群，且故障恢复时间在不同规模任务中保持接近一致。

Conclusion: FlashRecovery系统通过其三个核心模块显著提升了大规模语言模型训练的可靠性和效率，实现了快速且低成本的故障恢复。

Abstract: Large language models (LLMs) have made a profound impact across various
fields due to their advanced capabilities. However, training these models at
unprecedented scales requires extensive AI accelerator clusters and
sophisticated parallelism strategies, which pose significant challenges in
maintaining system reliability over prolonged training periods. A major concern
is the substantial loss of training time caused by inevitable hardware and
software failures. To address these challenges, we present FlashRecovery, a
fast and low-cost failure recovery system comprising three core modules: (1)
Active and real-time failure detection. This module performs continuous
training state monitoring, enabling immediate identification of hardware and
software failures within seconds, thus ensuring rapid incident response; (2)
Scale-independent task restart. By employing different recovery strategies for
normal and faulty nodes, combined with an optimized communication group
reconstruction protocol, our approach ensures that the recovery time remains
nearly constant, regardless of cluster scale; (3) Checkpoint-free recovery
within one step. Our novel recovery mechanism enables single-step restoration,
completely eliminating dependence on traditional checkpointing methods and
their associated overhead. Collectively, these innovations enable FlashRecovery
to achieve optimal Recovery Time Objective (RTO) and Recovery Point Objective
(RPO), substantially improving the reliability and efficiency of long-duration
LLM training. Experimental results demonstrate that FlashRecovery system can
achieve training restoration on training cluster with 4, 800 devices in 150
seconds. We also verify that the time required for failure recovery is nearly
consistent for different scales of training tasks.

</details>


### [61] [The High Cost of Keeping Warm: Characterizing Overhead in Serverless Autoscaling Policies](https://arxiv.org/abs/2509.03104)
*Leonid Kondrashov,Boxi Zhou,Hancheng Wang,Dmitrii Ustiugov*

Main category: cs.DC

TL;DR: 该研究通过设计一个近似商业无服务器平台的系统，揭示了其性能与成本效率的权衡，并指出了当前自动扩展策略的不足。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏开放的跨平台基准测试和详细的系统分析，无服务器计算的性能与成本权衡尚未被充分理解。

Method: 设计了一个近似商业提供商（如AWS Lambda和Google Cloud Run）扩展行为的无服务器系统，并通过重放真实工作负载和调整关键自动扩展参数，系统比较了同步和异步自动扩展策略的性能和成本效率。

Result: 研究发现，无服务器系统存在显著的CPU开销（相当于请求处理的10-40%），内存分配过高（2-10倍于实际使用量），且降低这些开销通常会导致性能下降。

Conclusion: 当前的无服务器系统在性能和成本效率之间存在显著权衡，需要开发新的、更高效的自动扩展策略。

Abstract: Serverless computing is transforming cloud application development, but the
performance-cost trade-offs of control plane designs remain poorly understood
due to a lack of open, cross-platform benchmarks and detailed system analyses.
In this work, we address these gaps by designing a serverless system that
approximates the scaling behaviors of commercial providers, including AWS
Lambda and Google Cloud Run. We systematically compare the performance and
cost-efficiency of both synchronous and asynchronous autoscaling policies by
replaying real-world workloads and varying key autoscaling parameters.
  We demonstrate that our open-source systems can closely replicate the
operational characteristics of commercial platforms, enabling reproducible and
transparent experimentation. By evaluating how autoscaling parameters affect
latency, memory usage, and CPU overhead, we reveal several key findings. First,
we find that serverless systems exhibit significant computational overhead due
to instance churn equivalent to 10-40% of the CPU cycles spent on request
handling, primarily originating from worker nodes. Second, we observe high
memory allocation due to scaling policy: 2-10 times more than actively used.
Finally, we demonstrate that reducing these overheads typically results in
significant performance degradation in the current systems, underscoring the
need for new, cost-efficient autoscaling strategies. Additionally, we employ a
hybrid methodology that combines real control plane deployments with
large-scale simulation to extend our evaluation closer to a production scale,
thereby bridging the gap between small research clusters and real-world
environments.

</details>


### [62] [Efficient and Secure Sleepy Model for BFT Consensus](https://arxiv.org/abs/2509.03145)
*Pengkun Ren,Hai Dong,Zahir Tari,Pengcheng Zhang*

Main category: cs.DC

TL;DR: 该论文提出了一种结合PVSS的BFT协议，减少通信轮次至4Δ，抗1/2敌手，提升效率与安全性，实验验证其优于传统协议。


<details>
  <summary>Details</summary>
Motivation: 动态可用系统中的BFT共识协议面临延迟与安全性平衡的挑战，现有解决方案多轮投票导致高延迟或抗敌行为能力有限。

Method: 该协议将PVSS集成到消息传输中，通过将用户身份与其消息绑定，减少了通信轮次。

Result: 理论分析表明协议对拜占庭攻击具有鲁棒性，实验评估显示该协议显著减少分叉并提升链稳定性，同时在中等参与波动下保持低延迟。

Conclusion: 该论文提出的BFT协议通过整合预提交机制和公开可验证秘密共享（PVSS），在动态可用系统中实现了低延迟和高安全性的平衡。

Abstract: Byzantine Fault Tolerant (BFT) consensus protocols for dynamically available
systems face a critical challenge: balancing latency and security in
fluctuating node participation. Existing solutions often require multiple
rounds of voting per decision, leading to high latency or limited resilience to
adversarial behavior. This paper presents a BFT protocol integrating a
pre-commit mechanism with publicly verifiable secret sharing (PVSS) into
message transmission. By binding users' identities to their messages through
PVSS, our approach reduces communication rounds. Compared to other
state-of-the-art methods, our protocol typically requires only four network
delays (4$\Delta$) in common scenarios while being resilient to up to 1/2
adversarial participants. This integration enhances the efficiency and security
of the protocol without compromising integrity. Theoretical analysis
demonstrates the robustness of the protocol against Byzantine attacks.
Experimental evaluations show that, compared to traditional BFT protocols, our
protocol significantly prevents fork occurrences and improves chain stability.
Furthermore, compared to longest-chain protocol, our protocol maintains
stability and lower latency in scenarios with moderate participation
fluctuations.

</details>


### [63] [CloudFormer: An Attention-based Performance Prediction for Public Clouds with Unknown Workload](https://arxiv.org/abs/2509.03394)
*Amirhossein Shahbazinia,Darong Huang,Luis Costero,David Atienza*

Main category: cs.DC

TL;DR: CloudFormer是一种双分支Transformer模型，用于预测云环境中VM的性能退化，显著提升了预测准确性并表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在多租户云环境中，虚拟机的共享资源竞争导致性能退化，而现有管理技术因黑盒VM和高动态负载的挑战难以准确预测性能。

Method: 提出CloudFormer，一种基于双分支Transformer的模型，用于预测黑盒环境中的VM性能退化。该模型联合建模时间动态和系统级交互，利用206个系统指标（一秒分辨率）在静态和动态场景下进行预测。

Result: 实验结果表明，CloudFormer在多个评估指标上始终优于现有基线方法，平均绝对误差（MAE）仅为7.8%，比现有方法至少提升了28%。

Conclusion: CloudFormer通过双分支Transformer模型有效预测了黑盒环境中的VM性能退化，显著提升了预测准确性，并在多样化和未见过的负载上表现出强大的泛化能力。

Abstract: Cloud platforms are increasingly relied upon to host diverse,
resource-intensive workloads due to their scalability, flexibility, and
cost-efficiency. In multi-tenant cloud environments, virtual machines are
consolidated on shared physical servers to improve resource utilization. While
virtualization guarantees resource partitioning for CPU, memory, and storage,
it cannot ensure performance isolation. Competition for shared resources such
as last-level cache, memory bandwidth, and network interfaces often leads to
severe performance degradation. Existing management techniques, including VM
scheduling and resource provisioning, require accurate performance prediction
to mitigate interference. However, this remains challenging in public clouds
due to the black-box nature of VMs and the highly dynamic nature of workloads.
To address these limitations, we propose CloudFormer, a dual-branch
Transformer-based model designed to predict VM performance degradation in
black-box environments. CloudFormer jointly models temporal dynamics and
system-level interactions, leveraging 206 system metrics at one-second
resolution across both static and dynamic scenarios. This design enables the
model to capture transient interference effects and adapt to varying workload
conditions without scenario-specific tuning. Complementing the methodology, we
provide a fine-grained dataset that significantly expands the temporal
resolution and metric diversity compared to existing benchmarks. Experimental
results demonstrate that CloudFormer consistently outperforms state-of-the-art
baselines across multiple evaluation metrics, achieving robust generalization
across diverse and previously unseen workloads. Notably, CloudFormer attains a
mean absolute error (MAE) of just 7.8%, representing a substantial improvement
in predictive accuracy and outperforming existing methods at least by 28%.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [64] [Safe Sharing of Fast Kernel-Bypass I/O Among Nontrusting Applications](https://arxiv.org/abs/2509.02899)
*Alan Beadle,Michael L. Scott,John Criswell*

Main category: cs.OS

TL;DR: 本文提出改进的受保护库模型，解决互不信任应用共享内核旁路服务的安全与性能问题，原型DDS实现显著优于商业方案。


<details>
  <summary>Details</summary>
Motivation: 实现互不信任应用之间安全共享内核旁路服务，同时优化性能和安全性。

Method: 解决了受保护库设计中的未解决问题，包括有限时间完成、降低延迟、防止缓冲区解除映射攻击，以及通过可信守护进程处理异步事件。

Result: 原型DDS通信服务展示了比商业FastDDS实现更低延迟（约50%）和更高吞吐量（最高7倍），且CPU利用率更低。

Conclusion: 本研究通过扩展和改进受保护库模型，提出了一种结合内核旁路和微内核优势的新型操作系统服务架构，并提供了安全性和性能指南。

Abstract: Protected user-level libraries have been proposed as a way to allow mutually
distrusting applications to safely share kernel-bypass services. In this paper,
we identify and solve several previously unaddressed obstacles to realizing
this design and identify several optimization opportunities. First, to preserve
the kernel's ability to reclaim failed processes, protected library functions
must complete in modest, bounded time. We show how to move unbounded waits
outside the library itself, enabling synchronous interaction among processes
without the need for polling. Second, we show how the bounded time requirement
can be leveraged to achieve lower and more stable latency for inter-process
interactions. Third, we observe that prior work on protected libraries is
vulnerable to a buffer unmapping attack; we prevent this attack by preventing
applications from removing pages that they share with the protected library.
Fourth, we show how a trusted daemon can respond to asynchronous events and
dynamically divide work with application threads in a protected library.
  By extending and improving the protected library model, our work provides a
new way to structure OS services, combining the advantages of kernel bypass and
microkernels. We present a set of safety and performance guidelines for
developers of protected libraries, and a set of recommendations for developers
of future protected library operating systems. We demonstrate the convenience
and performance of our approach with a prototype version of the DDS
communication service. To the best of our knowledge, this prototype represents
the first successful sharing of a kernel-bypass NIC among mutually untrusting
applications. Relative to the commercial FastDDS implementation, we achieve
approximately 50\% lower latency and up to 7x throughput, with lower CPU
utilization.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [65] [Sorting with constraints](https://arxiv.org/abs/2509.02616)
*A. Manas*

Main category: cs.DS

TL;DR: 论文研究了广义排序问题，通过图的团数和色数参数化算法，提出了一种在Erdős–Rényi图中高效确定偏序的算法。


<details>
  <summary>Details</summary>
Motivation: 研究广义排序问题，其中仅允许部分元素比较，探讨从禁止对形成的图的角度出发的算法参数化。

Method: 通过参数化禁止对形成的图的团数和色数，研究广义排序问题，并扩展至输入图不一定可排序的情况。

Result: 开发了一种算法，在Erdős–Rényi图中以$O(n^{3/2} \log n)$次探测确定偏序关系。

Conclusion: 论文提出了一种针对广义排序问题的简单算法，能够在Erdős–Rényi图中以$O(n^{3/2} \log n)$次探测确定潜在偏序关系。

Abstract: In this work, we study the generalized sorting problem, where we are given a
set of $n$ elements to be sorted, but only a subset of all possible pairwise
element comparisons is allowed. We look at the problem from the perspective of
the graph formed by the ``forbidden'' pairs, and we parameterize algorithms
using the clique number and the chromatic number of this graph. We also extend
these results to the class of problems where the input graph is not necessarily
sortable, and one is only interested in discovering the partial order. We use
our results to develop a simple algorithm that always determines the underlying
partial order in $O(n^{3/2} \log n)$ probes, when the input graph is an
Erd\H{o}s--R\'enyi graph.

</details>


### [66] [Efficient Dynamic Rank Aggregation](https://arxiv.org/abs/2509.02885)
*Morteza Alimi,Hourie Mehrabiun,Alireza Zarei*

Main category: cs.DS

TL;DR: 本文提出了一种高效的动态排名聚合算法，结合LR-Aggregation和Pick-A-Perm，实现了接近线性时间的运行性能，并兼具理论保证和优异实际表现。


<details>
  <summary>Details</summary>
Motivation: 动态环境中，新排名随时间不断到达，需要高效更新聚合排名。

Method: 开发了基于LR-tree数据结构的LR-Aggregation算法，并结合Pick-A-Perm算法，通过新设计的数据结构实现高效动态更新。

Result: 实验证明LR-Aggregation接近最优解，Pick-A-Perm具有理论最坏情况近似保证为2，两种算法组合运行时间为O(n log n)。

Conclusion: 本文提出了一种快速、理论上和实践上高效的动态排名聚合算法，首次在动态环境中实现了接近线性时间的排名聚合，并兼具理论保证和优异实际性能。

Abstract: The rank aggregation problem, which has many real-world applications, refers
to the process of combining multiple input rankings into a single aggregated
ranking. In dynamic settings, where new rankings arrive over time, efficiently
updating the aggregated ranking is essential. This paper develops a fast,
theoretically and practically efficient dynamic rank aggregation algorithm.
First, we develop the LR-Aggregation algorithm, built on top of the LR-tree
data structure, which is itself modeled on the LR-distance, a novel and
equivalent take on the classical Spearman's footrule distance. We then analyze
the theoretical efficiency of the Pick-A-Perm algorithm, and show how it can be
combined with the LR-aggregation algorithm using another data structure that we
develop. We demonstrate through experimental evaluations that LR-Aggregation
produces close to optimal solutions in practice. We show that Pick-A-Perm has a
theoretical worst case approximation guarantee of 2. We also show that both the
LR-Aggregation and Pick-A-Perm algorithms, as well as the methodology for
combining them can be run in $O(n \log n)$ time. To the best of our knowledge,
this is the first fast, near linear time rank aggregation algorithm in the
dynamic setting, having both a theoretical approximation guarantee, and
excellent practical performance (much better than the theoretical guarantee).

</details>


### [67] [Fast approximation algorithms for the 1-median problem on real-world large graphs](https://arxiv.org/abs/2509.03052)
*Keisuke Ueta,Wei Wu,Mutsunori Yagiura*

Main category: cs.DS

TL;DR: 论文针对大规模图上的1-中位数问题，提出了三种高效近似算法，理论分析和实验验证了其性能和准确性。


<details>
  <summary>Details</summary>
Motivation: 在大规模图上，精确解决1-中位数问题的计算成本过高，尤其是在客户节点数量较少且空间集中的情况下，完全图探索既低效又不必要。

Method: 提出了三种基于提前终止Dijkstra算法的近似算法，并进行了理论分析。

Result: 实验证明，所提算法在运行时显著优于基线精确方法，且在千万级节点的网格图上能在1毫秒内获得所有最优解。

Conclusion: 该论文提出了三种近似算法，显著提高了大规模图上1-中位数问题的计算效率，同时保持了接近最优的准确性。

Abstract: The 1-median problem (1MP) on undirected weighted graphs seeks to find a
facility location minimizing the total weighted distance to all customer nodes.
Although the 1MP can be solved exactly by computing the single-source shortest
paths from each customer node, such approaches become computationally expensive
on large-scale graphs with millions of nodes. In many real-world applications,
such as recommendation systems based on large-scale knowledge graphs, the
number of nodes (i.e., potential facility locations) is enormous, whereas the
number of customer nodes is relatively small and spatially concentrated. In
such cases, exhaustive graph exploration is not only inefficient but also
unnecessary. Leveraging this observation, we propose three approximation
algorithms that reduce computation by terminating Dijkstra's algorithm early.
We provide theoretical analysis showing that one of the proposed algorithms
guarantees an approximation ratio of 2, whereas the other two improve this
ratio to 1.618. We demonstrate that the lower bound of the approximation ratio
is 1.2 by presenting a specific instance. Moreover, we show that all proposed
algorithms return optimal solutions when the number of customer nodes is less
than or equal to three. Extensive experiments demonstrate that our algorithms
significantly outperform baseline exact methods in runtime while maintaining
near-optimal accuracy across all tested graph types. Notably, on grid graphs
with 10 million nodes, our algorithms obtains all optimal solutions within 1
millisecond, whereas the baseline exact method requires over 70 seconds on
average.

</details>


### [68] [Triangle Detection in Worst-Case Sparse Graphs via Local Sketching](https://arxiv.org/abs/2509.03215)
*Hongyi Duan,Jian'an Zhang*

Main category: cs.DS

TL;DR: 提出了一种高效的三角形检测算法，适用于稀疏图，运行时间和空间复杂度均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决稀疏图中三角形检测的高效性和局部性保持问题，避免全局代数卷积带来的计算复杂性。

Method: 算法通过$O(\log n)$独立层处理图，将入射边划分为基于前缀的类别，每类在素数域上维护1-稀疏三元组。通过PK对齐检测潜在候选，并通过三阶段零假阳性流水线验证。

Result: 算法总运行时间为$O(m\log^2 n)$，峰值空间为$O(m\log n)$，均以高概率实现，并生成了可验证的Seeds+Logs结果。

Conclusion: 该论文提出了一种非代数、保持局部性的三角形检测框架，在稀疏图中实现了高效的最坏情况检测，并探讨了可能的改进路径。

Abstract: We present a non-algebraic, locality-preserving framework for triangle
detection in worst-case sparse graphs. Our algorithm processes the graph in
$O(\log n)$ independent layers and partitions incident edges into prefix-based
classes where each class maintains a 1-sparse triple over a prime field.
Potential witnesses are surfaced by pair-key (PK) alignment, and every
candidate is verified by a three-stage, zero-false-positive pipeline: a
class-level 1-sparse consistency check, two slot-level decodings, and a final
adjacency confirmation. \textbf{To obtain single-run high-probability coverage,
we further instantiate $R=c_G\log n$ independent PK groups per class (each
probing a constant number of complementary buckets), which amplifies the
per-layer hit rate from $\Theta(1/\log n)$ to $1-n^{-\Omega(1)}$ without
changing the accounting.} A one-shot pairing discipline and class-term
triggering yield a per-(layer,level) accounting bound of $O(m)$, while
keep-coin concentration ensures that each vertex retains only $O(d^+(x))$ keys
with high probability. Consequently, the total running time is $O(m\log^2 n)$
and the peak space is $O(m\log n)$, both with high probability. The algorithm
emits a succinct Seeds+Logs artifact that enables a third party to replay all
necessary checks and certify a NO-instance in $\tilde O(m\log n)$ time. We also
prove a $\Theta(1/\log n)$ hit-rate lower bound for any single PK family under
a constant-probe local model (via Yao)--motivating the use of $\Theta(\log n)$
independent groups--and discuss why global algebraic convolutions would break
near-linear accounting or run into fine-grained barriers. We outline measured
paths toward Las Vegas $O(m\log n)$ and deterministic near-linear variants.

</details>


### [69] [Compressed Dictionary Matching on Run-Length Encoded Strings](https://arxiv.org/abs/2509.03265)
*Philip Bille,Inge Li Gørtz,Simon J. Puglisi,Simon R. Tarnow*

Main category: cs.DS

TL;DR: 提出了一种在压缩字符串上进行字典匹配的高效算法，时间和空间复杂度均优化。


<details>
  <summary>Details</summary>
Motivation: 研究压缩字符串（游程编码）上的字典匹配问题，旨在不进行解压缩的情况下高效解决该问题。

Method: 引入了几种新技术，包括经典的Aho-Corasick自动机的新压缩表示和一种支持快速查询的新型高效字符串索引。

Result: 算法实现了$O( (\overline{m} + \overline{n})\log \log m + \mathrm{occ})$的预期时间复杂度和$O(\overline{m})$的空间复杂度。

Conclusion: 本文提出了一种在压缩字符串（使用游程编码）上进行字典匹配的非平凡解决方案，时间复杂度和空间复杂度均优于现有方法。

Abstract: Given a set of pattern strings $\mathcal{P}=\{P_1, P_2,\ldots P_k\}$ and a
text string $S$, the classic dictionary matching problem is to report all
occurrences of each pattern in $S$. We study the dictionary problem in the
compressed setting, where the pattern strings and the text string are
compressed using run-length encoding, and the goal is to solve the problem
without decompression and achieve efficient time and space in the size of the
compressed strings. Let $m$ and $n$ be the total length of the patterns
$\mathcal{P}$ and the length of the text string $S$, respectively, and let
$\overline{m}$ and $\overline{n}$ be the total number of runs in the run-length
encoding of the patterns in $\mathcal{P}$ and $S$, respectively. Our main
result is an algorithm that achieves $O( (\overline{m} + \overline{n})\log \log
m + \mathrm{occ})$ expected time, and $O(\overline{m})$ space, where
$\mathrm{occ}$ is the total number of occurrences of patterns in $S$. This is
the first non-trivial solution to the problem. Since any solution must read the
input, our time bound is optimal within an $\log \log m$ factor. We introduce
several new techniques to achieve our bounds, including a new compressed
representation of the classic Aho-Corasick automaton and a new efficient string
index that supports fast queries in run-length encoded strings.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [70] [Can Media Act as a Soft Regulator of Safe AI Development? A Game Theoretical Analysis](https://arxiv.org/abs/2509.02650)
*Henrique Correia da Fonseca,António Fernandes,Zhao Song,Theodor Cimpeanu,Nataliya Balabanova,Adeela Bashir,Paolo Bova,Alessio Buscemi,Alessandro Di Stefano,Manh Hong Duong,Elias Fernandez Domingos,Ndidi Bianca Ogbo,Simon T. Powers,Daniele Proverbio,Zia Ush Shamszaman,Fernando P. Santos,The Anh Han,Marcus Krellner*

Main category: cs.AI

TL;DR: 媒体通过塑造公众认知和问责机制，可以促进AI产品的安全性，但需要信息可靠和成本适中。


<details>
  <summary>Details</summary>
Motivation: 探讨媒体是否能够推动AI创造者生产安全产品，从而促进AI技术的广泛应用。

Method: 通过创建自利的创造者和用户的人工群体，并利用进化博弈论进行研究。

Result: 研究发现，媒体确实能够促进创造者和用户之间的合作，但前提是媒体提供的信息质量足够可靠，且访问媒体或确保安全的成本不能过高。

Conclusion: 媒体可以作为软性监管者，通过塑造公众认知和追究开发者责任来引导AI安全，即使在缺乏正式政府监管的情况下。

Abstract: When developers of artificial intelligence (AI) products need to decide
between profit and safety for the users, they likely choose profit.
Untrustworthy AI technology must come packaged with tangible negative
consequences. Here, we envisage those consequences as the loss of reputation
caused by media coverage of their misdeeds, disseminated to the public. We
explore whether media coverage has the potential to push AI creators into the
production of safe products, enabling widespread adoption of AI technology. We
created artificial populations of self-interested creators and users and
studied them through the lens of evolutionary game theory. Our results reveal
that media is indeed able to foster cooperation between creators and users, but
not always. Cooperation does not evolve if the quality of the information
provided by the media is not reliable enough, or if the costs of either
accessing media or ensuring safety are too high. By shaping public perception
and holding developers accountable, media emerges as a powerful soft regulator
-- guiding AI safety even in the absence of formal government oversight.

</details>


### [71] [The Future of Artificial Intelligence and the Mathematical and Physical Sciences (AI+MPS)](https://arxiv.org/abs/2509.02661)
*Andrew Ferguson,Marisa LaFleur,Lars Ruthotto,Jesse Thaler,Yuan-Sen Ting,Pratyush Tiwary,Soledad Villar,E. Paulo Alves,Jeremy Avigad,Simon Billinge,Camille Bilodeau,Keith Brown,Emmanuel Candes,Arghya Chattopadhyay,Bingqing Cheng,Jonathan Clausen,Connor Coley,Andrew Connolly,Fred Daum,Sijia Dong,Chrisy Xiyu Du,Cora Dvorkin,Cristiano Fanelli,Eric B. Ford,Luis Manuel Frutos,Nicolás García Trillos,Cecilia Garraffo,Robert Ghrist,Rafael Gomez-Bombarelli,Gianluca Guadagni,Sreelekha Guggilam,Sergei Gukov,Juan B. Gutiérrez,Salman Habib,Johannes Hachmann,Boris Hanin,Philip Harris,Murray Holland,Elizabeth Holm,Hsin-Yuan Huang,Shih-Chieh Hsu,Nick Jackson,Olexandr Isayev,Heng Ji,Aggelos Katsaggelos,Jeremy Kepner,Yannis Kevrekidis,Michelle Kuchera,J. Nathan Kutz,Branislava Lalic,Ann Lee,Matt LeBlanc,Josiah Lim,Rebecca Lindsey,Yongmin Liu,Peter Y. Lu,Sudhir Malik,Vuk Mandic,Vidya Manian,Emeka P. Mazi,Pankaj Mehta,Peter Melchior,Brice Ménard,Jennifer Ngadiuba,Stella Offner,Elsa Olivetti,Shyue Ping Ong,Christopher Rackauckas,Philippe Rigollet,Chad Risko,Philip Romero,Grant Rotskoff,Brett Savoie,Uros Seljak,David Shih,Gary Shiu,Dima Shlyakhtenko,Eva Silverstein,Taylor Sparks,Thomas Strohmer,Christopher Stubbs,Stephen Thomas,Suriyanarayanan Vaikuntanathan,Rene Vidal,Francisco Villaescusa-Navarro,Gregory Voth,Benjamin Wandelt,Rachel Ward,Melanie Weber,Risa Wechsler,Stephen Whitelam,Olaf Wiest,Mike Williams,Zhuoran Yang,Yaroslava G. Yingling,Bin Yu,Shuwen Yue,Ann Zabludoff,Huimin Zhao,Tong Zhang*

Main category: cs.AI

TL;DR: 该社区论文总结了MPS社区对AI未来的视角，提出了双向研究、跨学科社区建设和教育发展的战略重点，以加强AI与科学的联系。


<details>
  <summary>Details</summary>
Motivation: 探讨MPS领域（天文学、化学、材料研究、数学科学和物理学）如何最好地利用AI的未来并为其做出贡献。

Method: 提出活动和战略重点，包括双向AI+MPS研究、建立跨学科AI+MPS研究社区以及促进MPS研究者和学生的AI教育和劳动力发展。

Result: 强调AI与MPS之间的联系日益紧密，现在是加强AI与科学联系的关键时刻。

Conclusion: 建议资助机构、教育机构和个人研究者采取优先措施，以帮助MPS社区在AI+MPS的变革潜力中成为领导者并充分利用。

Abstract: This community paper developed out of the NSF Workshop on the Future of
Artificial Intelligence (AI) and the Mathematical and Physics Sciences (MPS),
which was held in March 2025 with the goal of understanding how the MPS domains
(Astronomy, Chemistry, Materials Research, Mathematical Sciences, and Physics)
can best capitalize on, and contribute to, the future of AI. We present here a
summary and snapshot of the MPS community's perspective, as of Spring/Summer
2025, in a rapidly developing field. The link between AI and MPS is becoming
increasingly inextricable; now is a crucial moment to strengthen the link
between AI and Science by pursuing a strategy that proactively and thoughtfully
leverages the potential of AI for scientific discovery and optimizes
opportunities to impact the development of AI by applying concepts from
fundamental science. To achieve this, we propose activities and strategic
priorities that: (1) enable AI+MPS research in both directions; (2) build up an
interdisciplinary community of AI+MPS researchers; and (3) foster education and
workforce development in AI for MPS researchers and students. We conclude with
a summary of suggested priorities for funding agencies, educational
institutions, and individual researchers to help position the MPS community to
be a leader in, and take full advantage of, the transformative potential of
AI+MPS.

</details>


### [72] [Planning with Reasoning using Vision Language World Model](https://arxiv.org/abs/2509.02722)
*Delong Chen,Theo Moutakanni,Willy Chung,Yejin Bang,Ziwei Ji,Allen Bolourchi,Pascale Fung*

Main category: cs.AI

TL;DR: VLWM是一种基于语言的世界模型，通过视觉观察推断目标并预测行动轨迹，结合自优化和树状字幕技术，在视觉规划任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 高层世界模型在语义和时间抽象上的理解和推理能力不足，限制了有效规划的潜力。

Method: VLWM通过推断整体目标达成情况并预测由交替行动和世界状态变化组成的轨迹，结合LLM自优化和树状字幕表示的未来观测，学习行动策略和动态模型。

Result: VLWM在基准评估和PlannerArena人类评估中表现优异，系统-2比系统-1提升了27%的Elo分数，并在RoboVQA和WorldPrediction基准上超越了强基线。

Conclusion: VLWM模型在视觉规划辅助（VPA）任务中实现了最先进的性能，并在PlannerArena人类评估中显著提升了Elo分数。

Abstract: Effective planning requires strong world models, but high-level world models
that can understand and reason about actions with semantic and temporal
abstraction remain largely underdeveloped. We introduce the Vision Language
World Model (VLWM), a foundation model trained for language-based world
modeling on natural videos. Given visual observations, the VLWM first infers
the overall goal achievements then predicts a trajectory composed of
interleaved actions and world state changes. Those targets are extracted by
iterative LLM Self-Refine conditioned on compressed future observations
represented by Tree of Captions. The VLWM learns both an action policy and a
dynamics model, which respectively facilitates reactive system-1 plan decoding
and reflective system-2 planning via cost minimization. The cost evaluates the
semantic distance between the hypothetical future states given by VLWM
roll-outs and the expected goal state, and is measured by a critic model that
we trained in a self-supervised manner. The VLWM achieves state-of-the-art
Visual Planning for Assistance (VPA) performance on both benchmark evaluations
and our proposed PlannerArena human evaluations, where system-2 improves the
Elo score by +27% upon system-1. The VLWM models also outperforms strong VLM
baselines on RoboVQA and WorldPrediction benchmark.

</details>


### [73] [Deep Research is the New Analytics System: Towards Building the Runtime for AI-Driven Analytics](https://arxiv.org/abs/2509.02751)
*Matthew Russo,Tim Kraska*

Main category: cs.AI

TL;DR: 论文提出结合语义操作符优化与深度研究系统灵活性的原型，显著提升AI分析性能与效率。


<details>
  <summary>Details</summary>
Motivation: 当前AI驱动分析中，语义操作符执行成本高且不适合交互式任务，而深度研究系统缺乏查询计划优化。因此，需要一种结合两者优势的运行时系统。

Method: 论文提出了一种原型系统，使深度研究代理能够编写和执行优化的语义操作符程序。通过结合两种方法的优势，实现了更高效的查询执行。

Result: 原型系统在两种基本查询上表现优于手工优化的语义操作符程序和开放深度研究系统，F1分数提升高达1.95倍，成本和运行时分别节省高达76.8%和72.7%。

Conclusion: 该论文得出结论，结合优化的语义操作符执行与深度研究系统的灵活性和动态执行，可以显著提升AI驱动分析的效果。原型系统在性能和成本上均优于传统方法。

Abstract: With advances in large language models (LLMs), researchers are creating new
systems that can perform AI-driven analytics over large unstructured datasets.
Recent work has explored executing such analytics queries using semantic
operators -- a declarative set of AI-powered data transformations with natural
language specifications. However, even when optimized, these operators can be
expensive to execute on millions of records and their iterator execution
semantics make them ill-suited for interactive data analytics tasks. In another
line of work, Deep Research systems have demonstrated an ability to answer
natural language question(s) over large datasets. These systems use one or more
LLM agent(s) to plan their execution, process the dataset(s), and iteratively
refine their answer. However, these systems do not explicitly optimize their
query plans which can lead to poor plan execution. In order for AI-driven
analytics to excel, we need a runtime which combines the optimized execution of
semantic operators with the flexibility and more dynamic execution of Deep
Research systems. As a first step towards this vision, we build a prototype
which enables Deep Research agents to write and execute optimized semantic
operator programs. We evaluate our prototype and demonstrate that it can
outperform a handcrafted semantic operator program and open Deep Research
systems on two basic queries. Compared to a standard open Deep Research agent,
our prototype achieves up to 1.95x better F1-score. Furthermore, even if we
give the agent access to semantic operators as tools, our prototype still
achieves cost and runtime savings of up to 76.8% and 72.7% thanks to its
optimized execution.

</details>


### [74] [Do LLM Modules Generalize? A Study on Motion Generation for Autonomous Driving](https://arxiv.org/abs/2509.02754)
*Mingyi Wang,Jingke Wang,Tengju Ye,Junbo Chen,Kaicheng Yu*

Main category: cs.AI

TL;DR: 研究评估了五大LLM模块在自动驾驶运动生成中的可迁移性，发现适当调整后能显著提升性能，并分析了成功与失败的技术原因。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的突破启发了其在结构相似领域的应用，如自动驾驶运动生成。然而，哪些LLM模块真正可迁移尚缺乏系统理解。

Method: 在Waymo Sim Agents基准上进行了广泛实验，评估了五个关键LLM模块（分词器设计、位置嵌入、预训练范式、后训练策略和测试时计算）在自动驾驶运动生成中的表现。

Result: 在Sim Agents任务中取得了竞争性结果，证明了适当调整后的LLM模块能显著提升自动驾驶运动生成的性能。

Conclusion: 通过系统评估五个关键LLM模块在自动驾驶运动生成中的应用，研究发现适当调整后这些模块能显著提升性能，并识别了哪些技术可有效迁移，分析了其他技术失败的原因，讨论了自动驾驶场景所需的特定调整。

Abstract: Recent breakthroughs in large language models (LLMs) have not only advanced
natural language processing but also inspired their application in domains with
structurally similar problems--most notably, autonomous driving motion
generation. Both domains involve autoregressive sequence modeling, token-based
representations, and context-aware decision making, making the transfer of LLM
components a natural and increasingly common practice. However, despite
promising early attempts, a systematic understanding of which LLM modules are
truly transferable remains lacking. In this paper, we present a comprehensive
evaluation of five key LLM modules--tokenizer design, positional embedding,
pre-training paradigms, post-training strategies, and test-time
computation--within the context of motion generation for autonomous driving.
Through extensive experiments on the Waymo Sim Agents benchmark, we demonstrate
that, when appropriately adapted, these modules can significantly improve
performance for autonomous driving motion generation. In addition, we identify
which techniques can be effectively transferred, analyze the potential reasons
for the failure of others, and discuss the specific adaptations needed for
autonomous driving scenarios. We evaluate our method on the Sim Agents task and
achieve competitive results.

</details>


### [75] [Plan Verification for LLM-Based Embodied Task Completion Agents](https://arxiv.org/abs/2509.02761)
*Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur*

Main category: cs.AI

TL;DR: 该论文提出了一种迭代验证框架，利用LLM批评和修订动作序列，显著提升了具身AI任务计划的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 基于大型语言模型（LLM）的任务计划和人类演示可能存在噪声，如不必要的动作、冗余导航和逻辑错误，从而降低策略质量。

Method: 提出了一个迭代验证框架，其中Judge LLM对动作序列进行批评，Planner LLM应用修订，逐步生成更清晰、空间更一致的轨迹。

Result: 在TEACh具身AI数据集上，该框架在四种最先进的LLM（GPT o4-mini、DeepSeek-R1、Gemini 2.5、LLaMA 4 Scout）上实现了高达90%的召回率和100%的精确度。96.5%的序列最多需要三次迭代即可收敛，同时提升了时间效率和空间动作组织。

Conclusion: 该方法为具身AI的模仿学习提供了一条可扩展的路径，通过建立计划验证作为可靠的LLM能力，显著提升了训练数据的质量。

Abstract: Large language model (LLM) based task plans and corresponding human
demonstrations for embodied AI may be noisy, with unnecessary actions,
redundant navigation, and logical errors that reduce policy quality. We propose
an iterative verification framework in which a Judge LLM critiques action
sequences and a Planner LLM applies the revisions, yielding progressively
cleaner and more spatially coherent trajectories. Unlike rule-based approaches,
our method relies on natural language prompting, enabling broad generalization
across error types including irrelevant actions, contradictions, and missing
steps. On a set of manually annotated actions from the TEACh embodied AI
dataset, our framework achieves up to 90% recall and 100% precision across four
state-of-the-art LLMs (GPT o4-mini, DeepSeek-R1, Gemini 2.5, LLaMA 4 Scout).
The refinement loop converges quickly, with 96.5% of sequences requiring at
most three iterations, while improving both temporal efficiency and spatial
action organization. Crucially, the method preserves human error-recovery
patterns rather than collapsing them, supporting future work on robust
corrective behavior. By establishing plan verification as a reliable LLM
capability for spatial planning and action refinement, we provide a scalable
path to higher-quality training data for imitation learning in embodied AI.

</details>


### [76] [app.build: A Production Framework for Scaling Agentic Prompt-to-App Generation with Environment Scaffolding](https://arxiv.org/abs/2509.03310)
*Evgenii Kniazev,Arseny Kravchenko,Igor Rekun,James Broadhead,Nikita Shamgunov,Pranav Sah,Pratik Nichite,Ivan Yamshchikov*

Main category: cs.AI

TL;DR: app.build是一个开源框架，通过系统验证和结构化环境提升LLM应用生成，验证显示高可行率和质量，开放模型性能接近封闭模型。


<details>
  <summary>Details</summary>
Motivation: 通过系统验证和结构化环境改进基于LLM的应用程序生成。

Method: 结合多层验证管道、特定堆栈的编排和模型无关的架构，并在三个参考堆栈中实现。

Result: 在30个生成任务中，全面验证实现了73.3%的可行率，30%达到完美质量分数；开放权重模型在结构化环境中达到封闭模型性能的80.8%。

Conclusion: 该研究表明，扩展可靠的AI代理需要扩展环境而不仅仅是模型，为面向生产的代理系统提供了实证见解和完整的参考实现。

Abstract: We present app.build (https://github.com/appdotbuild/agent/), an open-source
framework that improves LLM-based application generation through systematic
validation and structured environments. Our approach combines multi-layered
validation pipelines, stack-specific orchestration, and model-agnostic
architecture, implemented across three reference stacks. Through evaluation on
30 generation tasks, we demonstrate that comprehensive validation achieves
73.3% viability rate with 30% reaching perfect quality scores, while
open-weights models achieve 80.8% of closed-model performance when provided
structured environments. The open-source framework has been adopted by the
community, with over 3,000 applications generated to date. This work
demonstrates that scaling reliable AI agents requires scaling environments, not
just models -- providing empirical insights and complete reference
implementations for production-oriented agent systems.

</details>


### [77] [Key Principles in Cross-Domain Hyper-Heuristic Performance](https://arxiv.org/abs/2509.02782)
*Václav Sobotka,Lucas Kletzander,Nysret Musliu,Hana Rudová*

Main category: cs.AI

TL;DR: 研究通过战略性变换低层启发式算法集合，展示了简单随机选择机制超越现有最先进超启发式算法的潜力，并在多个实际领域中取得了显著成果。


<details>
  <summary>Details</summary>
Motivation: 现有选择超启发式算法主要关注从预定义集中自适应选择低层启发式算法，而本研究聚焦于该集合的构成及其战略性变换。

Method: 系统分析了基于三个关键原则的变换：解接受、LLH重复和扰动强度。

Result: 研究结果表明，适当构建的变换使得简单方法在三个实际领域中优于所有现有最先进的超启发式算法，并发现了11个新的最佳解。

Conclusion: 通过战略性的低层启发式算法（LLH）集合变换，研究展示了即使是简单的随机选择机制也能超越现有最先进的超启发式算法，并在多个实际领域中发现了11个新的最佳解。

Abstract: Cross-domain selection hyper-heuristics aim to distill decades of research on
problem-specific heuristic search algorithms into adaptable general-purpose
search strategies. In this respect, existing selection hyper-heuristics
primarily focus on an adaptive selection of low-level heuristics (LLHs) from a
predefined set. In contrast, we concentrate on the composition of this set and
its strategic transformations. We systematically analyze transformations based
on three key principles: solution acceptance, LLH repetitions, and perturbation
intensity, i.e., the proportion of a solution affected by a perturbative LLH.
We demonstrate the raw effects of our transformations on a trivial unbiased
random selection mechanism. With an appropriately constructed transformation,
this trivial method outperforms all available state-of-the-art hyper-heuristics
on three challenging real-world domains and finds 11 new best-known solutions.
The same method is competitive with the winner of the CHeSC competition,
commonly used as the standard cross-domain benchmark. Moreover, we accompany
several recent hyper-heuristics with such strategic transformations. Using this
approach, we outperform the current state-of-the-art methods on both the CHeSC
benchmark and real-world domains while often simplifying their designs.

</details>


### [78] [Learning General Policies From Examples](https://arxiv.org/abs/2509.02794)
*Blai Bonet,Hector Geffner*

Main category: cs.AI

TL;DR: 提出一种基于击中集算法的符号化学习方法，显著提升组合策略学习的可扩展性，适用于大规模问题。


<details>
  <summary>Details</summary>
Motivation: 现有组合方法虽能生成可理解且正确的策略，但无法扩展到大规模问题（仅能处理少量状态和特征）。

Method: 基于采样计划泛化的符号化学习方法，采用击中集算法而非传统的SAT/ASP方法，确保结构终止和无环性。

Result: 实验证明，该方法在多个基准测试中展现出卓越的可扩展性，能处理百万级状态和数十万特征。

Conclusion: 该论文提出了一种新的符号化学习方法，能够有效处理数百万状态和数十万特征的大规模问题，显著提升了组合方法的可扩展性。

Abstract: Combinatorial methods for learning general policies that solve large
collections of planning problems have been recently developed. One of their
strengths, in relation to deep learning approaches, is that the resulting
policies can be understood and shown to be correct. A weakness is that the
methods do not scale up and learn only from small training instances and
feature pools that contain a few hundreds of states and features at most. In
this work, we propose a new symbolic method for learning policies based on the
generalization of sampled plans that ensures structural termination and hence
acyclicity. The proposed learning approach is not based on SAT/ASP, as previous
symbolic methods, but on a hitting set algorithm that can effectively handle
problems with millions of states, and pools with hundreds of thousands of
features. The formal properties of the approach are analyzed, and its
scalability is tested on a number of benchmarks.

</details>


### [79] [Uncertainty-driven Adaptive Exploration](https://arxiv.org/abs/2509.03219)
*Leonidas Bakopoulos,Georgios Chalkiadakis*

Main category: cs.AI

TL;DR: 提出基于不确定性的自适应探索框架，实验证明其在复杂任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决在需要学习长且复杂动作序列的领域中，如何确定在探索和利用之间切换的适当时机这一关键问题。

Method: 采用不确定性测量机制，结合内在动机或认知不确定性为基础的探索方法，构建自适应探索框架。

Result: 实验结果表明，该框架生成的适应探索策略在多个MuJoCo环境中优于标准策略。

Conclusion: 本文提出了一个通用的自适应探索框架，通过利用不确定性来在探索和利用之间进行切换，实验证明该框架在多个MuJoCo环境中优于标准方法。

Abstract: Adaptive exploration methods propose ways to learn complex policies via
alternating between exploration and exploitation. An important question for
such methods is to determine the appropriate moment to switch between
exploration and exploitation and vice versa. This is critical in domains that
require the learning of long and complex sequences of actions. In this work, we
present a generic adaptive exploration framework that employs uncertainty to
address this important issue in a principled manner. Our framework includes
previous adaptive exploration approaches as special cases. Moreover, we can
incorporate in our framework any uncertainty-measuring mechanism of choice, for
instance mechanisms used in intrinsic motivation or epistemic uncertainty-based
exploration methods. We experimentally demonstrate that our framework gives
rise to adaptive exploration strategies that outperform standard ones across
several MuJoCo environments.

</details>


### [80] [Accountability Framework for Healthcare AI Systems: Towards Joint Accountability in Decision Making](https://arxiv.org/abs/2509.03286)
*Prachi Bagave,Marcus Westberg,Marijn Janssen,Aaron Yi Ding*

Main category: cs.AI

TL;DR: 本文提出医疗AI系统的问责框架和三层次结构，解决‘如何’问责的问题，强调协作和解释性的重要性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI的决策需要问责，但现有指南模糊且缺乏具体实施方法，导致不同领域的参与者对问责的理解和处理方式存在差异。

Method: 通过分析问责概念、制定问责框架，并提供一个三层次结构来处理不同的问责机制。

Result: 提出了一个问责框架和三层次结构，帮助医疗AI系统的参与者根据行为分类机制，并强调了协作和解释性的作用。

Conclusion: 本文通过提出一个问责框架和三层次结构，弥合了医疗AI系统中‘什么’和‘如何’问责之间的知识鸿沟，强调了协作和解释性在问责中的重要性。

Abstract: AI is transforming the healthcare domain and is increasingly helping
practitioners to make health-related decisions. Therefore, accountability
becomes a crucial concern for critical AI-driven decisions. Although regulatory
bodies, such as the EU commission, provide guidelines, they are highlevel and
focus on the ''what'' that should be done and less on the ''how'', creating a
knowledge gap for actors. Through an extensive analysis, we found that the term
accountability is perceived and dealt with in many different ways, depending on
the actor's expertise and domain of work. With increasing concerns about AI
accountability issues and the ambiguity around this term, this paper bridges
the gap between the ''what'' and ''how'' of AI accountability, specifically for
AI systems in healthcare. We do this by analysing the concept of
accountability, formulating an accountability framework, and providing a
three-tier structure for handling various accountability mechanisms. Our
accountability framework positions the regulations of healthcare AI systems and
the mechanisms adopted by the actors under a consistent accountability regime.
Moreover, the three-tier structure guides the actors of the healthcare AI
system to categorise the mechanisms based on their conduct. Through our
framework, we advocate that decision-making in healthcare AI holds shared
dependencies, where accountability should be dealt with jointly and should
foster collaborations. We highlight the role of explainability in instigating
communication and information sharing between the actors to further facilitate
the collaborative process.

</details>


### [81] [Language Models Do Not Follow Occam's Razor: A Benchmark for Inductive and Abductive Reasoning](https://arxiv.org/abs/2509.03345)
*Yunxin Sun,Abulhair Saparov*

Main category: cs.AI

TL;DR: 研究评估了LLMs的归纳和溯因推理能力，发现其在简单场景中有效，但在复杂模型中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 大多数工作仅关注演绎推理，而其他类型的推理在解决现实问题中同样重要，但较少被探索。因此，本研究聚焦于评估LLMs的归纳和溯因推理能力。

Method: 引入了一个可编程和合成的数据集InAbHyD，每个推理示例包含一个不完整的世界模型和一组观察。智能代理的任务是在不完整的世界模型下生成假设来解释观察。提出了基于奥卡姆剃刀的新指标来评估假设质量。

Result: LLMs在简单场景中能够进行归纳和溯因推理，但在复杂世界模型和生成高质量假设方面表现不佳。

Conclusion: LLMs能够处理简单场景下的归纳和溯因推理，但在复杂世界模型中生成高质量假设方面存在困难，即使使用了流行的推理增强技术如上下文学习和RLVR。

Abstract: Reasoning is a core capability in artificial intelligence systems, for which
large language models (LLMs) have recently shown remarkable progress. However,
most work focuses exclusively on deductive reasoning, which is problematic
since other types of reasoning are also essential in solving real-world
problems, and they are less explored. This work focuses on evaluating LLMs'
inductive and abductive reasoning capabilities. We introduce a programmable and
synthetic dataset, InAbHyD (pronounced in-a-bid), where each reasoning example
consists of an incomplete world model and a set of observations. The task for
the intelligent agent is to produce hypotheses to explain observations under
the incomplete world model to solve each reasoning example. We propose a new
metric to evaluate the quality of hypotheses based on Occam's Razor. We
evaluate and analyze some state-of-the-art LLMs. Our analysis shows that LLMs
can perform inductive and abductive reasoning in simple scenarios, but struggle
with complex world models and producing high-quality hypotheses, even with
popular reasoning-enhancing techniques such as in-context learning and RLVR.

</details>


### [82] [Situating AI Agents in their World: Aspective Agentic AI for Dynamic Partially Observable Information Systems](https://arxiv.org/abs/2509.03380)
*Peter J. Bentley,Soo Ling Lim,Fuyuki Ishikawa*

Main category: cs.AI

TL;DR: 本文提出了一种新型AI代理框架，通过环境触发行为和‘方面’概念实现零信息泄露，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前AI代理通常只是自主聊天机器人，行为受不可靠的脚本控制，信息泄露率高。

Method: 引入了一个自下而上的框架，将AI代理置于其环境中，所有行为由环境变化触发，并提出了‘方面’概念，类似于‘umwelt’，使不同代理感知环境的方式各异，从而实现更清晰的信息控制。

Result: 相比典型架构（信息泄露率高达83%），‘方面’代理AI实现了零信息泄露。

Conclusion: 专用AI代理在各自信息生态中高效工作的概念，有望在安全性和效率方面带来改进。

Abstract: Agentic LLM AI agents are often little more than autonomous chatbots: actors
following scripts, often controlled by an unreliable director. This work
introduces a bottom-up framework that situates AI agents in their environment,
with all behaviors triggered by changes in their environments. It introduces
the notion of aspects, similar to the idea of umwelt, where sets of agents
perceive their environment differently to each other, enabling clearer control
of information. We provide an illustrative implementation and show that
compared to a typical architecture, which leaks up to 83% of the time,
aspective agentic AI enables zero information leakage. We anticipate that this
concept of specialist agents working efficiently in their own information
niches can provide improvements to both security and efficiency.

</details>


### [83] [ANNIE: Be Careful of Your Robots](https://arxiv.org/abs/2509.03383)
*Yiyang Huang,Zixuan Wang,Zishen Wan,Yapeng Tian,Haobo Xu,Yinhe Han,Yiming Gan*

Main category: cs.AI

TL;DR: 该研究首次系统研究了具身AI系统中的对抗性安全攻击，提出了安全分类法、评估基准和攻击框架，揭示了高攻击成功率和实际影响，强调了安全防御的紧迫性。


<details>
  <summary>Details</summary>
Motivation: 具身AI系统引入了新的安全风险，传统机器学习的安全定义和方法已不足以应对这些风险。研究旨在系统研究具身AI系统中的对抗性安全攻击。

Method: 研究提出了一个基于物理约束（如分离距离、速度和碰撞边界）的安全违规分类法（关键、危险、风险），并引入了ANNIEBench基准和ANNIE-Attack框架，用于评估和攻击具身AI系统的安全性。

Result: 评估结果显示，攻击成功率在所有安全类别中均超过50%，并通过物理机器人实验验证了实际影响。

Conclusion: 该研究揭示了在具身AI系统中未被充分探索但影响重大的安全攻击面，强调了在物理AI时代迫切需要安全驱动的防御措施。

Abstract: The integration of vision-language-action (VLA) models into embodied AI (EAI)
robots is rapidly advancing their ability to perform complex, long-horizon
tasks in humancentric environments. However, EAI systems introduce critical
security risks: a compromised VLA model can directly translate adversarial
perturbations on sensory input into unsafe physical actions. Traditional safety
definitions and methodologies from the machine learning community are no longer
sufficient. EAI systems raise new questions, such as what constitutes safety,
how to measure it, and how to design effective attack and defense mechanisms in
physically grounded, interactive settings. In this work, we present the first
systematic study of adversarial safety attacks on embodied AI systems, grounded
in ISO standards for human-robot interactions. We (1) formalize a principled
taxonomy of safety violations (critical, dangerous, risky) based on physical
constraints such as separation distance, velocity, and collision boundaries;
(2) introduce ANNIEBench, a benchmark of nine safety-critical scenarios with
2,400 video-action sequences for evaluating embodied safety; and (3)
ANNIE-Attack, a task-aware adversarial framework with an attack leader model
that decomposes long-horizon goals into frame-level perturbations. Our
evaluation across representative EAI models shows attack success rates
exceeding 50% across all safety categories. We further demonstrate sparse and
adaptive attack strategies and validate the real-world impact through physical
robot experiments. These results expose a previously underexplored but highly
consequential attack surface in embodied AI systems, highlighting the urgent
need for security-driven defenses in the physical AI era. Code is available at
https://github.com/RLCLab/Annie.

</details>


### [84] [sam-llm: interpretable lane change trajectoryprediction via parametric finetuning](https://arxiv.org/abs/2509.03462)
*Zhuo Cao,Yunxiao Shi,Min Xu*

Main category: cs.AI

TL;DR: SAM-LLM是一种结合LLM和运动学模型的混合架构，用于自动驾驶中的可解释车道变换轨迹预测，性能优越且高效。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶中车道变换轨迹预测的可解释性和物理精度问题，SAM-LLM旨在结合LLMs的上下文推理能力和运动学模型的物理精度。

Method: 通过微调LLM输出轨迹模型的核心物理参数而非原始坐标，SAM-LLM在车道保持场景中预测离散坐标，在车道变换操作中生成增强的正弦加速度模型（SAM）参数，包括横向位移、操作持续时间、初始横向速度和纵向速度变化。

Result: SAM-LLM实现了98.73%的整体意图预测准确率，输出大小相比基于坐标的方法减少了80%，同时提供了连续、物理合理且可解释的轨迹模型。

Conclusion: SAM-LLM 是一种新型混合架构，结合了大型语言模型（LLMs）的上下文推理能力和运动学车道变换模型的物理精度，为自动驾驶提供了可解释的车道变换轨迹预测。该架构在保持与传统LLM预测器相当性能的同时，显著提高了可解释性和资源效率。

Abstract: This work introduces SAM-LLM, a novel hybrid architecture that bridges the
gap between the contextual reasoning of Large Language Models (LLMs) and the
physical precision of kinematic lane change models for autonomous driving. The
system is designed for interpretable lane change trajectory prediction by
finetuning an LLM to output the core physical parameters of a trajectory model
instead of raw coordinates. For lane-keeping scenarios, the model predicts
discrete coordinates, but for lane change maneuvers, it generates the
parameters for an enhanced Sinusoidal Acceleration Model (SAM), including
lateral displacement, maneuver duration, initial lateral velocity, and
longitudinal velocity change. This parametric approach yields a complete,
continuous, and physically plausible trajectory model that is inherently
interpretable and computationally efficient, achieving an 80% reduction in
output size compared to coordinate-based methods. The SAM-LLM achieves a
state-of-the-art overall intention prediction accuracy of 98.73%, demonstrating
performance equivalent to traditional LLM predictors while offering significant
advantages in explainability and resource efficiency.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [85] [Acrobotics: A Generalist Approahc To Quadrupedal Robots' Parkour](https://arxiv.org/abs/2509.02727)
*Guillaume Gagné-Labelle,Vassil Atanassov,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 提出一种通用强化学习算法，使四足机器人在动态场景中高效学习运动控制，性能媲美专家策略，训练成本更低。


<details>
  <summary>Details</summary>
Motivation: 四足机器人在复杂地形中具有优势，但传统建模方法难以应对其运动中的不确定性，如打滑和绊倒。

Method: 采用强化学习方法，通过试错实现最优控制，避免了传统建模方法的复杂性。

Result: 学习到的策略在性能上与专家策略相当，且训练效率更高。

Conclusion: 该论文提出了一种通用的强化学习算法，用于四足机器人在动态运动场景中的控制，其性能可与专家策略相媲美，同时训练所需的智能体数量仅需25%。

Abstract: Climbing, crouching, bridging gaps, and walking up stairs are just a few of
the advantages that quadruped robots have over wheeled robots, making them more
suitable for navigating rough and unstructured terrain. However, executing such
manoeuvres requires precise temporal coordination and complex agent-environment
interactions. Moreover, legged locomotion is inherently more prone to slippage
and tripping, and the classical approach of modeling such cases to design a
robust controller thus quickly becomes impractical. In contrast, reinforcement
learning offers a compelling solution by enabling optimal control through trial
and error. We present a generalist reinforcement learning algorithm for
quadrupedal agents in dynamic motion scenarios. The learned policy rivals
state-of-the-art specialist policies trained using a mixture of experts
approach, while using only 25% as many agents during training. Our experiments
also highlight the key components of the generalist locomotion policy and the
primary factors contributing to its success.

</details>


### [86] [The Impact of Adaptive Emotional Alignment on Mental State Attribution and User Empathy in HRI](https://arxiv.org/abs/2509.02749)
*Giorgia Buracchio,Ariele Callegari,Massimo Donini,Cristina Gena,Antonio Lieto,Alberto Lillo,Claudio Mattutino,Alessandro Mazzei,Linda Pigureddu,Manuel Striani,Fabiana Vernero*

Main category: cs.RO

TL;DR: 研究发现情感对齐虽不影响用户沟通或说服效果，但显著提升用户对机器人心理状态和共情的感知。


<details>
  <summary>Details</summary>
Motivation: 探讨情感对齐作为共情沟通前提在HRI中的作用，特别是在说服效果、用户沟通风格及对机器人心理状态和共情能力感知方面的影响。

Method: 使用NAO机器人进行实验，比较中性沟通与情感对齐沟通两种条件，共42名参与者参与。

Result: 情感对齐对用户沟通风格和说服效果无显著影响，但显著增强了用户对机器人心理状态和共情能力的感知。

Conclusion: 情感对齐在HRI中虽未显著影响用户沟通风格或说服效果，但显著提升了用户对机器人心理状态和共情能力的感知。

Abstract: The paper presents an experiment on the effects of adaptive emotional
alignment between agents, considered a prerequisite for empathic communication,
in Human-Robot Interaction (HRI). Using the NAO robot, we investigate the
impact of an emotionally aligned, empathic, dialogue on these aspects: (i) the
robot's persuasive effectiveness, (ii) the user's communication style, and
(iii) the attribution of mental states and empathy to the robot. In an
experiment with 42 participants, two conditions were compared: one with neutral
communication and another where the robot provided responses adapted to the
emotions expressed by the users. The results show that emotional alignment does
not influence users' communication styles or have a persuasive effect. However,
it significantly influences attribution of mental states to the robot and its
perceived empathy

</details>


### [87] [A Digital Twin for Robotic Post Mortem Tissue Sampling using Virtual Reality](https://arxiv.org/abs/2509.02760)
*Maximilian Neidhardt,Ludwig Bosse,Vidas Raudonis,Kristina Allgoewer,Axel Heinemann,Benjamin Ondruschka,Alexander Schlaefer*

Main category: cs.RO

TL;DR: 研究提出了一种基于虚拟现实和数字孪生的机器人尸检活检系统，通过可用性测试和临床验证，证明其直观、精确且低风险。


<details>
  <summary>Details</summary>
Motivation: 传统尸检活检虽为金标准，但存在破坏性大和感染风险高的问题。机器人辅助活检可降低感染风险，但需高效且易用的规划和控制系统。

Method: 研究探索了虚拟现实设置与数字孪生技术，实现了机器人尸检活检的远程规划和控制。通过可用性研究评估了三种交互方法，并在三具人体尸体上进行了临床可行性测试。

Result: 完成了132次针头插入，离轴针放置误差为5.30±3.25 mm。组织样本成功活检并经组织病理学验证。用户反馈针放置方法非常直观。

Conclusion: 该研究提出的虚拟现实系统结合数字孪生技术，为机器人辅助尸检活检提供了一种直观、精确且低风险的替代方案，显示出临床应用潜力。

Abstract: Studying tissue samples obtained during autopsies is the gold standard when
diagnosing the cause of death and for understanding disease pathophysiology.
Recently, the interest in post mortem minimally invasive biopsies has grown
which is a less destructive approach in comparison to an open autopsy and
reduces the risk of infection. While manual biopsies under ultrasound guidance
are more widely performed, robotic post mortem biopsies have been recently
proposed. This approach can further reduce the risk of infection for
physicians. However, planning of the procedure and control of the robot need to
be efficient and usable. We explore a virtual reality setup with a digital twin
to realize fully remote planning and control of robotic post mortem biopsies.
The setup is evaluated with forensic pathologists in a usability study for
three interaction methods. Furthermore, we evaluate clinical feasibility and
evaluate the system with three human cadavers. Overall, 132 needle insertions
were performed with an off-axis needle placement error of 5.30+-3.25 mm. Tissue
samples were successfully biopsied and histopathologically verified. Users
reported a very intuitive needle placement approach, indicating that the system
is a promising, precise, and low-risk alternative to conventional approaches.

</details>


### [88] [Improving the Resilience of Quadrotors in Underground Environments by Combining Learning-based and Safety Controllers](https://arxiv.org/abs/2509.02808)
*Isaac Ronald Ward,Mark Paral,Kristopher Riordan,Mykel J. Kochenderfer*

Main category: cs.RO

TL;DR: 提出一种基于归一化流的混合控制器，用于四旋翼在大型地下环境中的自主导航，兼顾速度与安全性。


<details>
  <summary>Details</summary>
Motivation: 学习型控制器在自主控制中具有吸引力，但在未训练过的分布外环境中表现不佳，需要一种能保证安全性的解决方案。

Method: 通过训练一个基于归一化流的环境先验，实时监测四旋翼是否处于分布外环境，并根据监测结果在学习型控制器和安全控制器之间切换。

Result: 在基于真实世界点云数据的3D洞穴模拟环境中进行点对点导航任务测试，结果表明混合控制器兼具学习型控制器的快速性和安全控制器的安全性。

Conclusion: 结合学习型控制器和安全控制器的混合方案在大型地下环境中表现出色，既保证了任务的快速完成，又确保了安全性。

Abstract: Autonomously controlling quadrotors in large-scale subterranean environments
is applicable to many areas such as environmental surveying, mining operations,
and search and rescue. Learning-based controllers represent an appealing
approach to autonomy, but are known to not generalize well to
`out-of-distribution' environments not encountered during training. In this
work, we train a normalizing flow-based prior over the environment, which
provides a measure of how far out-of-distribution the quadrotor is at any given
time. We use this measure as a runtime monitor, allowing us to switch between a
learning-based controller and a safe controller when we are sufficiently
out-of-distribution. Our methods are benchmarked on a point-to-point navigation
task in a simulated 3D cave environment based on real-world point cloud data
from the DARPA Subterranean Challenge Final Event Dataset. Our experimental
results show that our combined controller simultaneously possesses the liveness
of the learning-based controller (completing the task quickly) and the safety
of the safety controller (avoiding collision).

</details>


### [89] [Multi-Embodiment Locomotion at Scale with extreme Embodiment Randomization](https://arxiv.org/abs/2509.02815)
*Nico Bohlinger,Jan Peters*

Main category: cs.RO

TL;DR: 通过改进架构和课程训练，单一策略成功适应多种机器人形态并实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 探索如何训练单一策略以适应多样化的腿式机器人形态。

Method: 结合改进的URMAv2架构和基于性能的极端形态随机化课程训练。

Result: 策略学会控制数百万种形态变化，并在未见过的真实机器人上实现零样本迁移。

Conclusion: 提出的通用运动策略能够通过零样本迁移控制未见过的真实世界人形和四足机器人。

Abstract: We present a single, general locomotion policy trained on a diverse
collection of 50 legged robots. By combining an improved embodiment-aware
architecture (URMAv2) with a performance-based curriculum for extreme
Embodiment Randomization, our policy learns to control millions of
morphological variations. Our policy achieves zero-shot transfer to unseen
real-world humanoid and quadruped robots.

</details>


### [90] [Robotic 3D Flower Pose Estimation for Small-Scale Urban Farms](https://arxiv.org/abs/2509.02870)
*Harsh Muriki,Hong Ray Teo,Ved Sengupta,Ai-Ping Hu*

Main category: cs.RO

TL;DR: 利用FarmBot和定制算法，论文实现了草莓花朵姿态的自动估计，误差7.7度，适用于机器人授粉，代码开源。


<details>
  <summary>Details</summary>
Motivation: 利用低成本机器人和城市农场的小规模特性，为植物表型分析提供可访问的平台，特别是针对草莓花朵的机器人授粉需求。

Method: 使用FarmBot机器人配备定制摄像头末端执行器，通过新颖算法将3D点云模型转换为2D图像，利用2D目标检测模型识别花朵的3D点云，并通过拟合三种形状进行姿态估计。

Result: 该方法成功识别约80%的花朵，平均姿态误差为7.7度，性能媲美之前的研究。

Conclusion: 该论文的方法成功实现了草莓花朵姿态的自动估计，平均误差为7.7度，适用于机器人授粉，且代码已开源。

Abstract: The small scale of urban farms and the commercial availability of low-cost
robots (such as the FarmBot) that automate simple tending tasks enable an
accessible platform for plant phenotyping. We have used a FarmBot with a custom
camera end-effector to estimate strawberry plant flower pose (for robotic
pollination) from acquired 3D point cloud models. We describe a novel algorithm
that translates individual occupancy grids along orthogonal axes of a point
cloud to obtain 2D images corresponding to the six viewpoints. For each image,
2D object detection models for flowers are used to identify 2D bounding boxes
which can be converted into the 3D space to extract flower point clouds. Pose
estimation is performed by fitting three shapes (superellipsoids, paraboloids
and planes) to the flower point clouds and compared with manually labeled
ground truth. Our method successfully finds approximately 80% of flowers
scanned using our customized FarmBot platform and has a mean flower pose error
of 7.7 degrees, which is sufficient for robotic pollination and rivals previous
results. All code will be made available at
https://github.com/harshmuriki/flowerPose.git.

</details>


### [91] [Generalizable Skill Learning for Construction Robots with Crowdsourced Natural Language Instructions, Composable Skills Standardization, and Large Language Model](https://arxiv.org/abs/2509.02876)
*Hongrui Yu,Vineet R. Kamat,Carol C. Menassa*

Main category: cs.RO

TL;DR: 论文提出了一种基于LLM和分层建模的通用学习架构，通过在线自然语言指令直接教授机器人多任务技能，显著减少重新编程工作量，并通过实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 由于建筑工作的准重复性和机器人技能的不可迁移性，广泛采用建筑机器人面临挑战。现有方法需要大量重新编程，限制了机器人的通用性。

Method: 采用大型语言模型（LLM）、标准化和模块化的分层建模方法，以及建筑信息模型-机器人语义数据管道，解决多任务技能迁移问题。

Result: 通过长周期干墙安装实验验证，提出的框架实现了多任务重新编程的最小化努力和高质量执行。

Conclusion: 论文提出的技能标准化方案和基于LLM的分层技能学习框架显著减少了重新编程的工作量，实现了多任务的高效学习与高质量执行。

Abstract: The quasi-repetitive nature of construction work and the resulting lack of
generalizability in programming construction robots presents persistent
challenges to the broad adoption of robots in the construction industry. Robots
cannot achieve generalist capabilities as skills learnt from one domain cannot
readily transfer to another work domain or be directly used to perform a
different set of tasks. Human workers have to arduously reprogram their
scene-understanding, path-planning, and manipulation components to enable the
robots to perform alternate work tasks. The methods presented in this paper
resolve a significant proportion of such reprogramming workload by proposing a
generalizable learning architecture that directly teaches robots versatile
task-performance skills through crowdsourced online natural language
instructions. A Large Language Model (LLM), a standardized and modularized
hierarchical modeling approach, and Building Information Modeling-Robot sematic
data pipeline are developed to address the multi-task skill transfer problem.
The proposed skill standardization scheme and LLM-based hierarchical skill
learning framework were tested with a long-horizon drywall installation
experiment using a full-scale industrial robotic manipulator. The resulting
robot task learning scheme achieves multi-task reprogramming with minimal
effort and high quality.

</details>


### [92] [IL-SLAM: Intelligent Line-assisted SLAM Based on Feature Awareness for Dynamic Environments](https://arxiv.org/abs/2509.02972)
*Haolan Zhang,Thanh Nguyen Canh,Chenghao Li,Ruidong Yang,Yonghoon Ji,Nak Young Chong*

Main category: cs.RO

TL;DR: 提出特征感知机制动态引入线特征，减少计算开销和低质量特征，实验证明性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法基于静态环境假设，难以处理动态环境。现有动态SLAM系统通过引入额外线/面特征补充点特征，但可能带来不必要的计算开销和低质量特征累积问题。

Method: 提出了一种特征感知机制，动态评估当前特征是否足够，以决定是否激活线特征支持。线特征仅在必要时引入，且不参与全局优化以避免长期过程中的负面影响。

Result: 在TUM数据集上的实验表明，该方法在ATE和RPE指标上显著优于ORB-SLAM3基线和其他动态SLAM方法。

Conclusion: 本文提出了一种特征感知机制，仅在必要时引入线特征，显著降低了计算复杂度并减少了低质量特征的引入。实验证明，该方法在TUM数据集上相比ORB-SLAM3基线和其他动态SLAM方法有显著改进。

Abstract: Visual Simultaneous Localization and Mapping (SLAM) plays a crucial role in
autonomous systems. Traditional SLAM methods, based on static environment
assumptions, struggle to handle complex dynamic environments. Recent dynamic
SLAM systems employ geometric constraints and deep learning to remove dynamic
features, yet this creates a new challenge: insufficient remaining point
features for subsequent SLAM processes. Existing solutions address this by
continuously introducing additional line and plane features to supplement point
features, achieving robust tracking and pose estimation. However, current
methods continuously introduce additional features regardless of necessity,
causing two problems: unnecessary computational overhead and potential
performance degradation from accumulated low-quality additional features and
noise. To address these issues, this paper proposes a feature-aware mechanism
that evaluates whether current features are adequate to determine if line
feature support should be activated. This decision mechanism enables the system
to introduce line features only when necessary, significantly reducing
computational complexity of additional features while minimizing the
introduction of low-quality features and noise. In subsequent processing, the
introduced line features assist in obtaining better initial camera poses
through tracking, local mapping, and loop closure, but are excluded from global
optimization to avoid potential negative impacts from low-quality additional
features in long-term process. Extensive experiments on TUM datasets
demonstrate substantial improvements in both ATE and RPE metrics compared to
ORB-SLAM3 baseline and superior performance over other dynamic SLAM and
multi-feature methods.

</details>


### [93] [DUViN: Diffusion-Based Underwater Visual Navigation via Knowledge-Transferred Depth Features](https://arxiv.org/abs/2509.02983)
*Jinghe Yang,Minh-Quan Le,Mingming Gong,Ye Pu*

Main category: cs.RO

TL;DR: DUViN是一种基于扩散模型的视觉导航策略，通过两阶段训练实现水下自主导航，无需预建地图，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 水下导航因感知能力受限和环境地图构建困难而具有挑战性，DUViN旨在不依赖预建地图的情况下实现自主导航。

Method: 提出了一种基于扩散模型的视觉导航策略，结合预训练深度特征提取器和两阶段训练框架（先在空气中训练，再在水下深度估计任务中微调）。

Result: 在模拟和真实水下环境中的实验验证了DUViN的有效性和泛化能力。

Conclusion: DUViN通过知识转移的深度特征实现了未知水下环境中视觉自主导航，有效避障并保持安全高度，实验验证了其有效性和泛化能力。

Abstract: Autonomous underwater navigation remains a challenging problem due to limited
sensing capabilities and the difficulty of constructing accurate maps in
underwater environments. In this paper, we propose a Diffusion-based Underwater
Visual Navigation policy via knowledge-transferred depth features, named DUViN,
which enables vision-based end-to-end 4-DoF motion control for underwater
vehicles in unknown environments. DUViN guides the vehicle to avoid obstacles
and maintain a safe and perception awareness altitude relative to the terrain
without relying on pre-built maps. To address the difficulty of collecting
large-scale underwater navigation datasets, we propose a method that ensures
robust generalization under domain shifts from in-air to underwater
environments by leveraging depth features and introducing a novel model
transfer strategy. Specifically, our training framework consists of two phases:
we first train the diffusion-based visual navigation policy on in-air datasets
using a pre-trained depth feature extractor. Secondly, we retrain the extractor
on an underwater depth estimation task and integrate the adapted extractor into
the trained navigation policy from the first step. Experiments in both
simulated and real-world underwater environments demonstrate the effectiveness
and generalization of our approach. The experimental videos are available at
https://www.youtube.com/playlist?list=PLqt2s-RyCf1gfXJgFzKjmwIqYhrP4I-7Y.

</details>


### [94] [CTBC: Contact-Triggered Blind Climbing for Wheeled Bipedal Robots with Instruction Learning and Reinforcement Learning](https://arxiv.org/abs/2509.02986)
*Rankun Li,Hao Wang,Qi Li,Zhuo Han,Yifei Chu,Linqi Ye,Wende Xie,Wenlong Liao*

Main category: cs.RO

TL;DR: CTBC框架通过触发行走动作提升轮式双足机器人在复杂地形中的通过能力。


<details>
  <summary>Details</summary>
Motivation: 解决轮式双足机器人在复杂环境（如楼梯）中性能不足的问题。

Method: 利用强引导的前馈轨迹，触发腿部抬升动作以克服障碍。

Result: 实验验证了Tron1机器人能够可靠攀爬超出轮半径的障碍物。

Conclusion: 提出的CTBC框架显著提升了轮式双足机器人在复杂环境中的通过能力，仅依赖本体感知反馈即可可靠攀爬超出轮半径的障碍物。

Abstract: In recent years, wheeled bipedal robots have gained increasing attention due
to their advantages in mobility, such as high-speed locomotion on flat terrain.
However, their performance on complex environments (e.g., staircases) remains
inferior to that of traditional legged robots. To overcome this limitation, we
propose a general contact-triggered blind climbing (CTBC) framework for wheeled
bipedal robots. Upon detecting wheel-obstacle contact, the robot triggers a
leg-lifting motion to overcome the obstacle. By leveraging a strongly-guided
feedforward trajectory, our method enables the robot to rapidly acquire agile
leg-lifting skills, significantly enhancing its capability to traverse
unstructured terrains. The approach has been experimentally validated and
successfully deployed on LimX Dynamics' wheeled bipedal robot, Tron1.
Real-world tests demonstrate that Tron1 can reliably climb obstacles well
beyond its wheel radius using only proprioceptive feedback.

</details>


### [95] [Uncertainty-aware Test-Time Training (UT$^3$) for Efficient On-the-fly Domain Adaptive Dense Regression](https://arxiv.org/abs/2509.03012)
*Uddeshya Upadhyay*

Main category: cs.RO

TL;DR: UT$^3$框架通过不确定性感知的自监督任务优化测试时训练，减少推理时间，适用于资源受限的自主系统。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在自主系统中应用广泛，但在面对持续演化的环境时，其泛化能力不足，且现有测试时训练方法导致推理时间大幅增加，不适合资源受限的硬件。

Method: 提出了一种不确定性感知的自监督任务，用于高效的测试时训练，通过量化不确定性选择性应用训练。

Result: UT$^3$框架在保持性能的同时显著减少了推理时间，适用于单目深度估计等密集回归任务。

Conclusion: 论文提出了一种名为UT$^3$的新框架，通过基于不确定性的自监督任务选择性应用测试时训练，显著减少了推理时间，同时保持了与标准测试时训练协议相当的性能。

Abstract: Deep neural networks (DNNs) are increasingly being used in autonomous
systems. However, DNNs do not generalize well to domain shift. Adapting to a
continuously evolving environment is a safety-critical challenge inevitably
faced by all autonomous systems deployed to the real world. Recent work on
test-time training proposes methods that adapt to a new test distribution on
the fly by optimizing the DNN model for each test input using self-supervision.
However, these techniques result in a sharp increase in inference time as
multiple forward and backward passes are required for a single test sample (for
test-time training) before finally making the prediction based on the
fine-tuned features. This is undesirable for real-world robotics applications
where these models may be deployed to resource constraint hardware with strong
latency requirements. In this work, we propose a new framework (called UT$^3$)
that leverages test-time training for improved performance in the presence of
continuous domain shift while also decreasing the inference time, making it
suitable for real-world applications. Our method proposes an uncertainty-aware
self-supervision task for efficient test-time training that leverages the
quantified uncertainty to selectively apply the training leading to sharp
improvements in the inference time while performing comparably to standard
test-time training protocol. Our proposed protocol offers a continuous setting
to identify the selected keyframes, allowing the end-user to control how often
to apply test-time training. We demonstrate the efficacy of our method on a
dense regression task - monocular depth estimation.

</details>


### [96] [Forbal: Force Balanced 2-5 Degree of Freedom Robot Manipulator Built from a Five Bar Linkage](https://arxiv.org/abs/2509.03119)
*Yash Vyas,Matteo Bottin*

Main category: cs.RO

TL;DR: 本文设计并验证了两种力平衡机械臂变体，显著减少了反作用力矩和关节扭矩，适用于高精度应用。


<details>
  <summary>Details</summary>
Motivation: 开发一种力平衡机械臂设计，以减少关节扭矩和反作用力/力矩，同时最大化工作空间。

Method: 基于闭合链平面五杆机构设计并实验验证了两种变体（Forbal-2和Forbal-5），讨论了满足力平衡条件的几何、运动学和动力学设计考虑，并推导了逆运动学。

Result: 平衡配置使平均反作用力矩减少高达66%，平均关节扭矩减少高达79%（Forbal-2）和84%（Forbal-5），并显著减少位置误差。

Conclusion: 实验验证表明，平衡设计的机械臂适用于需要减少关节扭矩和反作用力/力矩以实现毫米级精度的应用。

Abstract: A force balanced manipulator design based on the closed chain planar five bar
linkage is developed and experimentally validated. We present 2 variants as a
modular design: Forbal-2, a planar 2-DOF manipulator, and its extension to
5-DOF spatial motion called Forbal-5. The design considerations in terms of
geometric, kinematic, and dynamic design that fulfill the force balance
conditions while maximizing workspace are discussed. Then, the inverse
kinematics of both variants are derived from geometric principles.
  We validate the improvements from force balancing the manipulator through
comparative experiments with counter mass balanced and unbalanced
configurations. The results show how the balanced configuration yields a
reduction in the average reaction moments of up to 66\%, a reduction of average
joint torques of up to 79\%, as well as a noticeable reduction in position
error for Forbal-2. For Forbal-5, which has a higher end effector payload mass,
the joint torques are reduced up to 84\% for the balanced configuration.
Experimental results validate that the balanced manipulator design is suitable
for applications where the reduction of joint torques and reaction
forces/moments helps achieve millimeter level precision.

</details>


### [97] [Efficient Active Training for Deep LiDAR Odometry](https://arxiv.org/abs/2509.03211)
*Beibei Zhou,Zhiyuan Zhang,Zhenbo Song,Jianhui Guo,Hui Kong*

Main category: cs.RO

TL;DR: 提出了一种主动训练框架，通过选择性提取多样化环境的训练数据，减少训练负担并提升模型泛化能力，实验证明仅需52%数据即可达到全数据集性能。


<details>
  <summary>Details</summary>
Motivation: 深度LiDAR里程计模型需要大量多样化的训练数据以适应不同环境，这导致效率低下。为了解决这一问题，我们引入了主动训练框架，旨在从多样化环境中选择性提取训练数据，从而减少训练负担并增强模型泛化能力。

Method: 我们的框架基于两个关键策略：初始训练集选择（ITSS）和主动增量选择（AIS）。ITSS通过将一般天气下的运动序列分解为节点和边进行详细轨迹分析，优先选择多样化的序列以形成丰富的初始训练数据集。对于难以分析的复杂序列（尤其是雪天条件），AIS利用场景重建和预测不一致性迭代选择训练样本，以优化模型应对各种现实场景。

Result: 实验验证了我们的方法的有效性。值得注意的是，我们的方法仅使用52%的序列量即可达到全数据集训练的性能，证明了主动训练范式的训练效率和鲁棒性。

Conclusion: 通过优化训练过程，我们的方法为更灵活和可靠的LiDAR里程计系统奠定了基础，能够在多样化的环境条件下以更高的精度进行导航。

Abstract: Robust and efficient deep LiDAR odometry models are crucial for accurate
localization and 3D reconstruction, but typically require extensive and diverse
training data to adapt to diverse environments, leading to inefficiencies. To
tackle this, we introduce an active training framework designed to selectively
extract training data from diverse environments, thereby reducing the training
load and enhancing model generalization. Our framework is based on two key
strategies: Initial Training Set Selection (ITSS) and Active Incremental
Selection (AIS). ITSS begins by breaking down motion sequences from general
weather into nodes and edges for detailed trajectory analysis, prioritizing
diverse sequences to form a rich initial training dataset for training the base
model. For complex sequences that are difficult to analyze, especially under
challenging snowy weather conditions, AIS uses scene reconstruction and
prediction inconsistency to iteratively select training samples, refining the
model to handle a wide range of real-world scenarios. Experiments across
datasets and weather conditions validate our approach's effectiveness. Notably,
our method matches the performance of full-dataset training with just 52\% of
the sequence volume, demonstrating the training efficiency and robustness of
our active training paradigm. By optimizing the training process, our approach
sets the stage for more agile and reliable LiDAR odometry systems, capable of
navigating diverse environmental conditions with greater precision.

</details>


### [98] [The Role of Embodiment in Intuitive Whole-Body Teleoperation for Mobile Manipulation](https://arxiv.org/abs/2509.03222)
*Sophia Bianchi Moyen,Rickmer Krohn,Sophie Lueth,Kay Pompetzki,Jan Peters,Vignesh Prasad,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: 研究比较了耦合与解耦机器人控制范式及VR与传统视觉反馈，发现VR增加操作负担，耦合操作在模仿学习上表现更优，为大规模高质量数据收集提供了见解。


<details>
  <summary>Details</summary>
Motivation: 直观的远程操作界面对于移动操作机器人至关重要，以确保高质量数据收集同时减少操作员工作负担。强化的体现感和最小的物理与认知需求不仅提升用户体验，还有助于在长时间内保持数据质量。

Method: 通过比较两种机器人控制范式（耦合体现与解耦体现）和两种视觉反馈机制（沉浸式虚拟现实与传统屏幕可视化），在复杂的多阶段任务序列中进行了系统评估。

Result: 研究发现，使用虚拟现实作为反馈方式会增加任务完成时间、认知负荷和感知操作员努力；耦合操作与导航对用户的工作负荷与解耦体现相当，但初步实验表明耦合远程操作获取的数据在模仿学习性能上更优。

Conclusion: 论文提供了关于直观远程操作界面的全面视角，强调了在考虑人类操作员的情况下收集高质量、高维度移动操作数据的重要性。

Abstract: Intuitive Teleoperation interfaces are essential for mobile manipulation
robots to ensure high quality data collection while reducing operator workload.
A strong sense of embodiment combined with minimal physical and cognitive
demands not only enhances the user experience during large-scale data
collection, but also helps maintain data quality over extended periods. This
becomes especially crucial for challenging long-horizon mobile manipulation
tasks that require whole-body coordination. We compare two distinct robot
control paradigms: a coupled embodiment integrating arm manipulation and base
navigation functions, and a decoupled embodiment treating these systems as
separate control entities. Additionally, we evaluate two visual feedback
mechanisms: immersive virtual reality and conventional screen-based
visualization of the robot's field of view. These configurations were
systematically assessed across a complex, multi-stage task sequence requiring
integrated planning and execution. Our results show that the use of VR as a
feedback modality increases task completion time, cognitive workload, and
perceived effort of the teleoperator. Coupling manipulation and navigation
leads to a comparable workload on the user as decoupling the embodiments, while
preliminary experiments suggest that data acquired by coupled teleoperation
leads to better imitation learning performance. Our holistic view on intuitive
teleoperation interfaces provides valuable insight into collecting
high-quality, high-dimensional mobile manipulation data at scale with the human
operator in mind. Project
website:https://sophiamoyen.github.io/role-embodiment-wbc-moma-teleop/

</details>


### [99] [Exploring persuasive Interactions with generative social robots: An experimental framework](https://arxiv.org/abs/2509.03231)
*Stephan Vonschallen,Larissa Julia Corina Finsler,Theresa Schmiedel,Friederike Eyssel*

Main category: cs.RO

TL;DR: 研究表明，生成式社交机器人能通过自然沟通影响用户决策，效果受沟通细节和上下文影响，建议进一步优化框架以研究说服动态。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨将生成式AI（如大型语言模型）集成到社交机器人中，以提升其自然、类似人类的沟通能力，并检验其说服能力。

Method: 我们设计了一个专注于决策制定的实验框架，并在一个试点中测试了机器人外观和自我知识的变化。通过定性分析，我们评估了交互质量、说服效果以及机器人的沟通策略。

Result: 参与者普遍对交互体验持积极态度，认为机器人能力、友好且支持性强，但也指出了延迟响应和偶尔的语音识别错误等实际限制。说服效果高度依赖于上下文和机器人行为。

Conclusion: 生成式社交机器人能够影响用户决策，但其效果取决于沟通的细微差别和上下文相关性。我们提出了框架的改进建议，以进一步研究机器人与人类用户之间的说服动态。

Abstract: Integrating generative AI such as large language models into social robots
has improved their ability to engage in natural, human-like communication. This
study presents a method to examine their persuasive capabilities. We designed
an experimental framework focused on decision making and tested it in a pilot
that varied robot appearance and self-knowledge. Using qualitative analysis, we
evaluated interaction quality, persuasion effectiveness, and the robot's
communicative strategies. Participants generally experienced the interaction
positively, describing the robot as competent, friendly, and supportive, while
noting practical limits such as delayed responses and occasional
speech-recognition errors. Persuasiveness was highly context dependent and
shaped by robot behavior: participants responded well to polite, reasoned
suggestions and expressive gestures, but emphasized the need for more
personalized, context-aware arguments and clearer social roles. These findings
suggest that generative social robots can influence user decisions, but their
effectiveness depends on communicative nuance and contextual relevance. We
propose refinements to the framework to further study persuasive dynamics
between robots and human users.

</details>


### [100] [Vibration Damping in Underactuated Cable-suspended Artwork -- Flying Belt Motion Control](https://arxiv.org/abs/2509.03238)
*Martin Goubej,Lauria Clarke,Martin Hrabačka,David Tolar*

Main category: cs.RO

TL;DR: The paper details upgrades to an interactive art installation, using advanced control algorithms to improve belt movement and audience interaction.


<details>
  <summary>Details</summary>
Motivation: The original system's oscillatory dynamics limited rotational speed and interactive responsiveness, prompting the need for upgrades to enhance performance.

Method: The refurbishment included hardware upgrades and advanced motion control algorithms, featuring a detailed mathematical model of the belt system and an input shaping method formulated as a convex optimization problem.

Result: Experimental results showed significant improvements in system performance and audience interaction, with smoother and faster belt movements.

Conclusion: This work successfully integrates robotics, control engineering, and interactive art, providing innovative solutions for real-time motion control and vibration damping in large-scale kinetic installations.

Abstract: This paper presents a comprehensive refurbishment of the interactive robotic
art installation Standards and Double Standards by Rafael Lozano-Hemmer. The
installation features an array of belts suspended from the ceiling, each
actuated by stepper motors and dynamically oriented by a vision-based tracking
system that follows the movements of exhibition visitors. The original system
was limited by oscillatory dynamics, resulting in torsional and pendulum-like
vibrations that constrained rotational speed and reduced interactive
responsiveness. To address these challenges, the refurbishment involved
significant upgrades to both hardware and motion control algorithms. A detailed
mathematical model of the flying belt system was developed to accurately
capture its dynamic behavior, providing a foundation for advanced control
design. An input shaping method, formulated as a convex optimization problem,
was implemented to effectively suppress vibrations, enabling smoother and
faster belt movements. Experimental results demonstrate substantial
improvements in system performance and audience interaction. This work
exemplifies the integration of robotics, control engineering, and interactive
art, offering new solutions to technical challenges in real-time motion control
and vibration damping for large-scale kinetic installations.

</details>


### [101] [Parallel-Constraint Model Predictive Control: Exploiting Parallel Computation for Improving Safety](https://arxiv.org/abs/2509.03261)
*Elias Fontanari,Gianni Lunardi,Matteo Saveriano,Andrea Del Prete*

Main category: cs.RO

TL;DR: 通过并行计算优化MPC安全集约束，提升机器人臂的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 确保非线性系统和约束下的安全性是机器人平台等安全关键系统的核心需求。

Method: 提出并行解决多个MPC问题的方法，每个问题在预测时域的不同时间步实例化安全集约束，并根据用户定义的标准选择最佳解。

Result: 在3关节机器人臂的仿真中验证了方法的有效性，即使使用4个计算核心也能显著提升安全和性能。

Conclusion: 通过并行计算改进MPC中的安全集约束，显著提高了机器人臂的安全性和性能。

Abstract: Ensuring constraint satisfaction is a key requirement for safety-critical
systems, which include most robotic platforms. For example, constraints can be
used for modeling joint position/velocity/torque limits and collision
avoidance. Constrained systems are often controlled using Model Predictive
Control, because of its ability to naturally handle constraints, relying on
numerical optimization. However, ensuring constraint satisfaction is
challenging for nonlinear systems/constraints. A well-known tool to make
controllers safe is the so-called control-invariant set (a.k.a. safe set). In
our previous work, we have shown that safety can be improved by letting the
safe-set constraint recede along the MPC horizon. In this paper, we push that
idea further by exploiting parallel computation to improve safety. We solve
several MPC problems at the same time, where each problem instantiates the
safe-set constraint at a different time step along the horizon. Finally, the
controller can select the best solution according to some user-defined
criteria. We validated this idea through extensive simulations with a 3-joint
robotic arm, showing that significant improvements can be achieved in terms of
safety and performance, even using as little as 4 computational cores.

</details>


### [102] [Cost-Optimized Systems Engineering for IoT-Enabled Robot Nurse in Infectious Pandemic Management](https://arxiv.org/abs/2509.03436)
*Md Mhamud Hussen Sifat,Md Maruf,Md Rokunuzzaman*

Main category: cs.RO

TL;DR: 护士机器人通过物联网控制，在疫情中自动化评估患者健康并管理药物，有效降低感染风险，提升医疗效果。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行加剧了对自动化医疗辅助设备的需求，尤其是能够减少感染风险并提升医疗效果的机器人技术。

Method: 本研究通过一个测试案例，评估了由物联网（IoT）控制的护士机器人在药物管理、健康状态监测和生命周期考虑方面的系统性能。

Result: 护士机器人在药物管理、健康状态监测和生命周期考虑方面表现出色，证明了其在医疗自动化中的潜力。

Conclusion: 研究表明，护士机器人能够有效评估患者健康状况并采取相应行动，同时在药物管理、健康状态监测和生命周期考虑方面表现良好，有助于降低感染风险并改善疫情环境下的医疗效果。

Abstract: The utilization of robotic technology has gained traction in healthcare
facilities due to progress in the field that enables time and cost savings,
minimizes waste, and improves patient care. Digital healthcare technologies
that leverage automation, such as robotics and artificial intelligence, have
the potential to enhance the sustainability and profitability of healthcare
systems in the long run. However, the recent COVID-19 pandemic has amplified
the need for cyber-physical robots to automate check-ups and medication
administration. A robot nurse is controlled by the Internet of Things (IoT) and
can serve as an automated medical assistant while also allowing supervisory
control based on custom commands. This system helps reduce infection risk and
improves outcomes in pandemic settings. This research presents a test case with
a nurse robot that can assess a patient's health status and take action
accordingly. We also evaluate the system's performance in medication
administration, health-status monitoring, and life-cycle considerations.

</details>


### [103] [Real-Time Instrument Planning and Perception for Novel Measurements of Dynamic Phenomena](https://arxiv.org/abs/2509.03500)
*Itai Zilberstein,Alberto Candela,Steve Chien*

Main category: cs.RO

TL;DR: 该论文提出了一种自动化工作流程，结合动态事件检测和自主轨迹规划，显著提升了高分辨率仪器的观测效率，特别是在火山羽流观测中。


<details>
  <summary>Details</summary>
Motivation: 利用先进的边缘计算能力，实现对动态科学现象的罕见、瞬态和精确测量，特别是在火山羽流观测中的应用。

Method: 提出了一个自动化工作流程，结合了动态事件检测（使用传统机器学习算法和卷积神经网络）与自主轨迹规划算法，以跟踪火山羽流的形态特征。

Result: 模拟结果显示，与基线相比，高分辨率仪器的效用回报提高了一个数量级。

Conclusion: 该工作流程通过整合动态事件检测与自主轨迹规划，显著提高了高分辨率仪器的效用回报，同时保持高效运行时间。

Abstract: Advancements in onboard computing mean remote sensing agents can employ
state-of-the-art computer vision and machine learning at the edge. These
capabilities can be leveraged to unlock new rare, transient, and pinpoint
measurements of dynamic science phenomena. In this paper, we present an
automated workflow that synthesizes the detection of these dynamic events in
look-ahead satellite imagery with autonomous trajectory planning for a
follow-up high-resolution sensor to obtain pinpoint measurements. We apply this
workflow to the use case of observing volcanic plumes. We analyze
classification approaches including traditional machine learning algorithms and
convolutional neural networks. We present several trajectory planning
algorithms that track the morphological features of a plume and integrate these
algorithms with the classifiers. We show through simulation an order of
magnitude increase in the utility return of the high-resolution instrument
compared to baselines while maintaining efficient runtimes.

</details>


### [104] [Can the Waymo Open Motion Dataset Support Realistic Behavioral Modeling? A Validation Study with Naturalistic Trajectories](https://arxiv.org/abs/2509.03515)
*Yanlin Zhang,Sungyong Chung,Nachuan Li,Dana Monzer,Hani S. Mahmassani,Samer H. Hamdar,Alireza Talebpour*

Main category: cs.RO

TL;DR: 研究发现Waymo Open Motion Dataset (WOMD)未能准确反映真实自动驾驶操作中的行为动态和交互，特别是在短车头时距和急减速行为方面表现不足，提示仅依赖WOMD校准的行为模型可能低估实际驾驶的复杂性和风险。


<details>
  <summary>Details</summary>
Motivation: Waymo Open Motion Dataset (WOMD)已成为自动驾驶车辆（AVs）行为数据驱动建模的热门资源，但其在行为分析中的有效性因专有后处理、缺乏误差量化以及轨迹被分割为20秒片段而存疑。本研究旨在验证WOMD是否准确捕捉了真实世界AV操作中的动态和交互。

Method: 研究利用从凤凰城（PHX）Level 4自动驾驶操作中独立收集的自然数据集，对三种典型城市驾驶场景（信号灯交叉口排队、跟车和变道行为）进行了比较分析。针对排队场景，通过手动提取航拍视频中的车头时距以确保测量误差最小；针对跟车和变道场景，应用Simulation-Extrapolation (SIMEX)方法处理PHX数据中的估计误差，并使用Dynamic Time Warping (DTW)距离量化行为差异。

Result: 所有场景的分析结果一致表明，PHX中的行为落在WOMD的行为范围之外。特别是，WOMD低估了短车头时距和急减速行为。

Conclusion: 研究结果表明，仅基于WOMD校准的行为模型可能系统性低估自然驾驶的变异性、风险和复杂性。因此，在使用WOMD进行行为建模时，若未针对独立收集的数据进行适当验证，需谨慎行事。

Abstract: The Waymo Open Motion Dataset (WOMD) has become a popular resource for
data-driven modeling of autonomous vehicles (AVs) behavior. However, its
validity for behavioral analysis remains uncertain due to proprietary
post-processing, the absence of error quantification, and the segmentation of
trajectories into 20-second clips. This study examines whether WOMD accurately
captures the dynamics and interactions observed in real-world AV operations.
Leveraging an independently collected naturalistic dataset from Level 4 AV
operations in Phoenix, Arizona (PHX), we perform comparative analyses across
three representative urban driving scenarios: discharging at signalized
intersections, car-following, and lane-changing behaviors. For the discharging
analysis, headways are manually extracted from aerial video to ensure
negligible measurement error. For the car-following and lane-changing cases, we
apply the Simulation-Extrapolation (SIMEX) method to account for empirically
estimated error in the PHX data and use Dynamic Time Warping (DTW) distances to
quantify behavioral differences. Results across all scenarios consistently show
that behavior in PHX falls outside the behavioral envelope of WOMD. Notably,
WOMD underrepresents short headways and abrupt decelerations. These findings
suggest that behavioral models calibrated solely on WOMD may systematically
underestimate the variability, risk, and complexity of naturalistic driving.
Caution is therefore warranted when using WOMD for behavior modeling without
proper validation against independently collected data.

</details>


### [105] [Large VLM-based Vision-Language-Action Models for Robotic Manipulation: A Survey](https://arxiv.org/abs/2508.13073)
*Rui Shao,Wei Li,Lingsen Zhang,Renshan Zhang,Zhiyang Liu,Ran Chen,Liqiang Nie*

Main category: cs.RO

TL;DR: 该论文首次系统综述了基于大型VLM的VLA模型在机器人操作中的应用，分析了其架构、集成领域及未来方向，填补了研究空白。


<details>
  <summary>Details</summary>
Motivation: 传统基于规则的方法在非结构化、新颖环境中难以扩展或泛化，而基于大型VLM的VLA模型为解决这一问题提供了新范式。

Method: 通过定义大型VLM-based VLA模型并划分两种主要架构范式（整体模型和分层模型），深入分析了其与高级领域的集成、特性综合及未来方向。

Result: 该调查整合了近期进展，解决了现有分类不一致问题，并通过系统性整合研究填补了大型VLM与机器人操作交叉领域的空白。

Conclusion: 该调查首次系统性地综述了基于大型视觉语言模型（VLM）的视觉语言动作（VLA）模型在机器人操作中的应用，并提出了未来研究方向，如记忆机制、4D感知等。

Abstract: Robotic manipulation, a key frontier in robotics and embodied AI, requires
precise motor control and multimodal understanding, yet traditional rule-based
methods fail to scale or generalize in unstructured, novel environments. In
recent years, Vision-Language-Action (VLA) models, built upon Large
Vision-Language Models (VLMs) pretrained on vast image-text datasets, have
emerged as a transformative paradigm. This survey provides the first
systematic, taxonomy-oriented review of large VLM-based VLA models for robotic
manipulation. We begin by clearly defining large VLM-based VLA models and
delineating two principal architectural paradigms: (1) monolithic models,
encompassing single-system and dual-system designs with differing levels of
integration; and (2) hierarchical models, which explicitly decouple planning
from execution via interpretable intermediate representations. Building on this
foundation, we present an in-depth examination of large VLM-based VLA models:
(1) integration with advanced domains, including reinforcement learning,
training-free optimization, learning from human videos, and world model
integration; (2) synthesis of distinctive characteristics, consolidating
architectural traits, operational strengths, and the datasets and benchmarks
that support their development; (3) identification of promising directions,
including memory mechanisms, 4D perception, efficient adaptation, multi-agent
cooperation, and other emerging capabilities. This survey consolidates recent
advances to resolve inconsistencies in existing taxonomies, mitigate research
fragmentation, and fill a critical gap through the systematic integration of
studies at the intersection of large VLMs and robotic manipulation. We provide
a regularly updated project page to document ongoing progress:
https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [106] [BISCAY: Practical Radio KPI Driven Congestion Control for Mobile Networks](https://arxiv.org/abs/2509.02806)
*Jon Larrea,Tanya Shreedhar,Mahesh K. Marina*

Main category: cs.NI

TL;DR: Biscay 是一种基于无线电 KPI 的拥塞控制系统，通过 OpenDiag 动态调整拥塞窗口，显著降低延迟并保持高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 移动应用性能严重依赖底层传输的拥塞控制设计，而蜂窝链路带宽的快速波动成为瓶颈。通过利用移动设备芯片组的无线电 KPI 测量，可以精确及时地测量蜂窝链路的可用带宽。

Method: Biscay 利用 OpenDiag（一种内核实时无线电 KPI 提取工具）和基于 KPI 的精确带宽确定层，动态调整拥塞窗口。

Result: Biscay 在 4G 和 5G 场景下显著降低了平均和尾部延迟（通常超过 90%），同时提供相似或更好的吞吐量。OpenDiag 的无线电 KPI 测量粒度比现有方案（如 MobileInsight）提高了 100%。

Conclusion: Biscay 是一种实用的、基于无线电 KPI 的拥塞控制系统设计，通过动态调整拥塞窗口来优化可用带宽，同时最小化延迟。实验证明其在 4G 和 5G 场景下显著降低了平均和尾部延迟（通常超过 90%），同时提供相似或更好的吞吐量。

Abstract: Mobile application performance relies heavily on the congestion control
design of the underlying transport, which is typically bottlenecked by cellular
link and has to cope with rapid cellular link bandwidth fluctuations. We
observe that radio KPI measurements from the mobile device chipset can be
exploited for precise and timely measurement of available bandwidth on the
cellular link. Building on this insight, we propose Biscay, a practical and
radio KPI-driven congestion control system design for mobile networks. Biscay
leverages OpenDiag, the in-kernel real-time radio KPI extraction tool we
introduce in this paper, along with our KPI-based accurate bandwidth
determination layer towards dynamically adjusting the congestion window to
optimally use the available bandwidth while keeping delay to the minimum. Our
solution is practical and deployable, as shown through our implementation of
Biscay and OpenDiag on unrooted Android 5G phones. We extensively evaluate
Biscay against different state-of-the-art congestion control designs including
BBR and CUBIC with emulations driven by real measurement traces as well as
real-world experiments spanning diverse 4G and 5G scenarios, and show that it
provides significant average and tail delay improvements (typically over 90%
reduction) while yielding better or similar throughput. These gains are enabled
by 100% improvement in the granularity of on-device radio KPI measurements with
OpenDiag compared to existing alternatives like MobileInsight.

</details>


### [107] [Performance Evaluation of LoRa for IoT Applications in Non-Terrestrial Networks via ns-3](https://arxiv.org/abs/2509.02811)
*Alessandro Traspadini,Michele Zorzi,Marco Giordani*

Main category: cs.NI

TL;DR: 本文探讨了LoRa通过LEO卫星网关支持大规模物联网连接的可行性，开发了新的仿真模块并证实其有效性，但需优化以减少碰撞。


<details>
  <summary>Details</summary>
Motivation: 研究LoRa在通过LEO卫星网关支持大规模物联网连接的可行性和性能，特别是在地面基础设施有限或不可用的偏远地区。

Method: 开发了一个新的ns3-LoRa-NTN仿真模块，结合并扩展了ns3-LoRa和ns3-NTN模块，以实现LoRa网络中卫星通信的端到端全栈仿真。

Result: 结果表明，LoRa在平均数据速率和包接收率（PRR）方面表现良好，但需要优化网络以减少碰撞概率。

Conclusion: LoRa可以有效支持从地面到LEO卫星的直接通信，但需要通过网络优化来降低相同扩频因子（SF）在长距离使用时导致的碰撞概率。

Abstract: The integration of Internet of Things (IoT) and Non-Terrestrial Networks
(NTNs) has emerged as a key paradigm to provide connectivity for sensors and
actuators via satellite gateways in remote areas where terrestrial
infrastructure is limited or unavailable. Among other Low-Power Wide-Area
Network (LPWAN) technologies for IoT, Long Range (LoRa) holds great potential
given its long range, energy efficiency, and flexibility. In this paper, we
explore the feasibility and performance of LoRa to support large-scale IoT
connectivity through Low Earth Orbit (LEO) satellite gateways. To do so, we
developed a new ns3-LoRa-NTN simulation module, which integrates and extends
the ns3-LoRa and ns3-NTN modules, to enable full-stack end-to-end simulation of
satellite communication in LoRa networks. Our results, given in terms of
average data rate and Packet Reception Ratio (PRR), confirm that LoRa can
effectively support direct communication from the ground to LEO satellites, but
network optimization is required to mitigate collision probability when end
nodes use the same Spreading Factors (SFs) over long distances.

</details>


### [108] [GPS Spoofing Attacks on Automated Frequency Coordination System in Wi-Fi 6E and Beyond](https://arxiv.org/abs/2509.02824)
*Yilu Dong,Tianchang Yang,Arupjyoti Bhuyan,Syed Rafiul Hussain*

Main category: cs.NI

TL;DR: 研究发现GPS位置欺骗可绕过AFC系统，揭示安全漏洞，需加强位置完整性保护。


<details>
  <summary>Details</summary>
Motivation: 6 GHz频谱的未授权使用可能干扰关键任务系统，AFC系统依赖GPS报告位置，但存在被欺骗的风险。

Method: 在实验室环境中使用商用AP和AFC系统进行GPS位置欺骗攻击的验证。

Result: 通过廉价设备成功实现GPS位置欺骗，攻击者可操纵AP行为、获取未授权频谱或完全禁用AP。

Conclusion: 论文揭示了AFC系统在位置完整性保护方面的关键安全漏洞，强调了加强防护措施的必要性。

Abstract: The 6 GHz spectrum, recently opened for unlicensed use under Wi-Fi 6E and
Wi-Fi 7, overlaps with frequencies used by mission-critical incumbent systems
such as public safety communications and utility infrastructure. To prevent
interference, the FCC mandates the use of Automated Frequency Coordination
(AFC) systems, which assign safe frequency and power levels based on Wi-Fi
Access Point (AP)-reported locations. In this work, we demonstrate that
GPS-based location reporting, which Wi-Fi APs use, can be spoofed using
inexpensive, off-the-shelf radio equipment. This enables attackers to
manipulate AP behavior, gain unauthorized spectrum access, cause harmful
interference, or disable APs entirely by spoofing them into foreign locations.
We validate these attacks in a controlled lab setting against a commercial AP
and evaluate a commercial AFC system under spoofed scenarios. Our findings
highlight critical gaps in the security assumptions of AFC and motivate the
need for stronger location integrity protections.

</details>


### [109] [Closing the Visibility Gap: A Monitoring Framework for Verifiable Open RAN Operations](https://arxiv.org/abs/2509.03000)
*Hexuan Yu,Md Mohaimin Al Barat,Yang Xiao,Y. Thomas Hou,Wenjing Lou*

Main category: cs.NI

TL;DR: 论文针对Open RAN的安全挑战，提出了一种监控框架，主动验证配置和行为，增强信任。实施结果显示其高效且实用。


<details>
  <summary>Details</summary>
Motivation: Open RAN的开放性和多厂商互操作性带来了新的安全挑战，尤其是在多运营商共享组件的部署中。现有的零信任架构假设认证组件会遵守操作政策，但这一假设存在盲点，即配置错误或受损组件可能无声地违反政策。

Method: 论文提出了一种监控框架，用于验证配置状态和控制行为是否符合租户定义的政策。该框架在标准化O-RAN配置中实施，并评估了其处理延迟。

Result: 实施和评估表明，该框架的总处理延迟约为200毫秒，证明了其在多运营商部署中及时执行政策和合规审计的效率和实用性。

Conclusion: 该论文提出了一个监控框架，用于在低信任度的O-RAN环境中主动验证配置状态和控制行为，以增强透明度和信任。通过标准化O-RAN配置的实施和评估，证明了该框架的效率和实用性。

Abstract: Open Radio Access Network (Open RAN) is reshaping mobile network architecture
by promoting openness, disaggregation, and cross-vendor interoperability.
However, this architectural flexibility introduces new security challenges,
especially in deployments where multiple mobile network operators (MNOs)
jointly operate shared components. Existing Zero Trust Architectures (ZTA) in
O-RAN, as defined by governmental and industry standards, implicitly assume
that authenticated components will comply with operational policies. However,
this assumption creates a critical blind spot: misconfigured or compromised
components can silently violate policies, misuse resources, or corrupt
downstream processes (e.g., ML-based RIC xApps).
  To address this critical gap, we propose a monitoring framework for low-trust
O-RAN environments that proactively verifies configuration state and control
behavior against tenant-defined policies. Our system provides scalable,
verifiable oversight to enhance transparency and trust in O-RAN operations. We
implement and evaluate the framework using standardized O-RAN configurations,
with total processing latency of approximately 200 ms, demonstrating its
efficiency and practicality for timely policy enforcement and compliance
auditing in multi-MNO deployments.

</details>


### [110] [Multi-layer Digital Twin System for Future Mobile Metaverse](https://arxiv.org/abs/2509.03049)
*Gaosheng Zhao,Dong In Kim*

Main category: cs.NI

TL;DR: 本文提出多层DT系统，协调本地、边缘和云DT，以支持6G网络的主动适应和元宇宙应用。


<details>
  <summary>Details</summary>
Motivation: 6G时代的通信网络将面临前所未有的复杂性和动态性挑战，需要从被动响应转变为主动适应。DT技术因其数字化能力，有望成为实现这一转变的关键。

Method: 提出一个多层DT系统，协调本地DT、边缘DT和云DT，以实现未来网络架构和功能。

Result: 多层DT系统能够实现实时数据驱动的决策和数字代理功能，并以分布式、移动、分层的方式支持未来元宇宙应用。

Conclusion: 数字孪生（DT）技术在6G时代具有巨大潜力，能够帮助通信网络从被动响应转变为主动适应。本文提出的多层DT系统不仅能够实现实时数据驱动的决策和数字代理功能，还能以分布式、移动、分层的方式支持未来元宇宙应用。

Abstract: In the upcoming 6G era, the communication networks are expected to face
unprecedented challenges in terms of complexity and dynamics. Digital Twin (DT)
technology, with its various digital capabilities, holds great potential to
facilitate the transformation of the communication network from passive
responding to proactive adaptation. Thus, in this paper, we propose a
multi-layer DT system that coordinates local DT, edge DT, and cloud DT for
future network architecture and functions. In our vision, the proposed DT
system will not only achieve real-time data-driven decision-making and digital
agent functions previously handled by centralized DT, but will do so in a more
distributed, mobile, layer-by-layer manner. Moreover, it will supply essential
data, pre-trained models, and open interfaces for future metaverse
applications, enabling creators and users to efficiently develop and experience
metaverse services.

</details>


### [111] [Machine Learning-Driven Anomaly Detection for 5G O-RAN Performance Metrics](https://arxiv.org/abs/2509.03290)
*Babak Azkaei,Kishor Chandra Joshi,George Exarchakos*

Main category: cs.NI

TL;DR: 本文利用Open RAN优势，开发了两种异常检测算法，有效减少UE吞吐量下降和切换后失败，为6G自愈网络铺路。


<details>
  <summary>Details</summary>
Motivation: 随着关键服务对网络基础设施的依赖不断增加，以及5G/6G网络操作复杂性的提升，需要主动和自动化的网络故障管理。Open RAN规范为AI/ML集成到网络架构中提供了可能性，促进了主动网络健康监控和异常检测。

Method: 提出了两种针对实际部署的异常检测算法：第一种通过分析关键性能指标（如资源块利用率和信号质量指标）识别有严重吞吐量下降风险的UE，第二种通过评估邻居小区无线电覆盖质量过滤掉信号强度或干扰水平异常的细胞。

Result: 第二种算法平均减少了41.27%的切换候选目标，两种算法共同有效减少了切换后失败和吞吐量下降问题，且运行速度远快于近实时延迟约束。

Conclusion: 本文提出的两种异常检测算法有效减少了切换后失败和吞吐量下降的问题，为自愈式6G网络奠定了基础。

Abstract: The ever-increasing reliance of critical services on network infrastructure
coupled with the increased operational complexity of beyond-5G/6G networks
necessitate the need for proactive and automated network fault management. The
provision for open interfaces among different radio access network\,(RAN)
elements and the integration of AI/ML into network architecture enabled by the
Open RAN\,(O-RAN) specifications bring new possibilities for active network
health monitoring and anomaly detection. In this paper we leverage these
advantages and develop an anomaly detection framework that proactively detect
the possible throughput drops for a UE and minimize the post-handover failures.
We propose two actionable anomaly detection algorithms tailored for real-world
deployment. The first algorithm identifies user equipment (UE) at risk of
severe throughput degradation by analyzing key performance indicators (KPIs)
such as resource block utilization and signal quality metrics, enabling
proactive handover initiation. The second algorithm evaluates neighbor cell
radio coverage quality, filtering out cells with anomalous signal strength or
interference levels. This reduces candidate targets for handover by 41.27\% on
average. Together, these methods mitigate post-handover failures and throughput
drops while operating much faster than the near-real-time latency constraints.
This paves the way for self-healing 6G networks.

</details>


### [112] [Dependency Chain Analysis of ROS 2 DDS QoS Policies: From Lifecycle Tutorial to Static Verification](https://arxiv.org/abs/2509.03381)
*Sanghoon Lee,Junha Kang,Kyung-Joon Park*

Main category: cs.NI

TL;DR: ROS 2用户缺乏QoS策略组合的明确指导，导致试错和运行时故障。本文分析了DDS通信生命周期，提供了QoS策略教程和依赖链，并开发了QoS Guard工具，用于静态验证配置文件，提高系统可靠性。


<details>
  <summary>Details</summary>
Motivation: ROS 2依赖DDS的20多种QoS策略，但缺乏明确的策略组合指导和验证流程，导致用户常需试错调整和面临意外运行时故障。

Method: 分析DDS Publisher-Subscriber通信的生命周期（发现、数据交换、解关联），提供用户教程解释16个QoS策略在各阶段的操作，并推导QoS依赖链，分类41个依赖违规规则。

Result: 开发了QoS Guard，一个ROS 2包，可离线静态验证DDS XML配置文件，标记冲突，支持安全的预部署调整。

Conclusion: ROS 2用户现在可以通过QoS Guard工具在部署前静态验证DDS XML配置文件，从而早期发现配置错误，提高系统的可靠性和资源效率。

Abstract: Robot Operating System 2 (ROS 2) relies on the Data Distribution Service
(DDS), which offers more than 20 Quality of Service (QoS) policies governing
availability, reliability, and resource usage. Yet ROS 2 users lack clear
guidance on safe policy combinations and validation processes prior to
deployment, which often leads to trial-and-error tuning and unexpected runtime
failures. To address these challenges, we analyze DDS Publisher-Subscriber
communication over a life cycle divided into Discovery, Data Exchange, and
Disassociation, and provide a user oriented tutorial explaining how 16 QoS
policies operate in each phase. Building on this analysis, we derive a QoS
dependency chain that formalizes inter-policy relationships and classifies 41
dependency violation rules, capturing constraints that commonly cause
communication failures in practice. Finally, we introduce QoS Guard, a ROS 2
package that statically validates DDS XML profiles offline, flags conflicts,
and enables safe, predeployment tuning without establishing a live ROS 2
session. Together, these contributions give ROS 2 users both conceptual insight
and a concrete tool that enables early detection of misconfigurations,
improving the reliability and resource efficiency of ROS 2 based robotic
systems.

</details>


### [113] [Hierarchical Low-Altitude Wireless Network Empowered Air Traffic Management](https://arxiv.org/abs/2509.03386)
*Ziye Jia,Jia He,Yuanhao Cui,Qiuming Zhu,Ligang Yuan,Fuhui Zhou,Qihui Wu,Dusit Niyato,Zhu Han*

Main category: cs.NI

TL;DR: 本文提出HLWN框架，通过三维空间离散化和无线监控设计低空空域走廊，并开发多维风险评估以实现动态碰撞避免，探讨了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 随着低空飞行器的快速发展，低空网络的合理设计直接影响空中安全和资源利用。

Method: 提出了一个分层的低空无线网络（HLWN）框架，通过三维空间离散化和集成的无线监控机制设计低空空域走廊，并开发了多维飞行风险评估方法。

Result: 设计的低空空域走廊保证了安全运行和优化，多维飞行风险评估实现了异构飞行器的动态碰撞避免。

Conclusion: 本文探讨了低空网络设计的开放问题及未来发展方向，为HLAN的发展提供了见解。

Abstract: As the increasing development of low-altitude aircrafts, the rational design
of low-altitude networks directly impacts the aerial safety and resource
utilization. To address the challenges of environmental complexity and aircraft
diversity in the traffic management, we propose a hierarchical low-altitude
wireless network (HLWN) framework. Empowered by the threedimensional spatial
discretization and integrated wireless monitoring mechanisms in HLWN, we design
low-altitude air corridors to guarantee safe operation and optimization.
Besides, we develop the multi-dimensional flight risk assessment through
conflict detection and probabilistic collision analysis, facilitating dynamic
collision avoidance for heterogeneous aircrafts. Finally, the open issues and
future directions are investigated to provide insights into HLAN development.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [114] [Vision: An Extensible Methodology for Formal Software Verification in Microservice Systems](https://arxiv.org/abs/2509.02860)
*Connor Wojtak,Darek Gajewski,Tomas Cerny*

Main category: cs.SE

TL;DR: 论文提出了一种静态重构微服务源代码为形式化模型的方法，通过SMT约束集进行验证，以提高系统可靠性和可维护性。


<details>
  <summary>Details</summary>
Motivation: 微服务系统的分散开发和持续演进可能导致沟通不畅和实现不兼容，影响系统的可维护性和可靠性。

Method: 该方法将微服务源代码静态重构为形式化系统模型，并从中导出SMT约束集以进行形式化验证。

Result: 该方法支持跨多个横切关注点的软件验证，并重点验证了系统架构关注点的正确性和适用性。

Conclusion: 论文提出了一种新颖的方法，通过静态重构微服务源代码为形式化系统模型，并利用SMT约束集进行形式化验证，以提高系统的可维护性和可靠性。未来研究方向包括扩展和评估该方法。

Abstract: Microservice systems are becoming increasingly adopted due to their
scalability, decentralized development, and support for continuous integration
and delivery (CI/CD). However, this decentralized development by separate teams
and continuous evolution can introduce miscommunication and incompatible
implementations, undermining system maintainability and reliability across
aspects from security policy to system architecture. We propose a novel
methodology that statically reconstructs microservice source code into a formal
system model. From this model, a Satisfiability Modulo Theories (SMT)
constraint set can be derived, enabling formal verification. Our methodology is
extensible, supporting software verification across multiple cross-cutting
concerns. We focus on applying the methodology to verify the system
architecture concern, presenting formal reasoning to validate the methodology's
correctness and applicability for this concern. Additional concerns such as
security policy implementation are considered. Future directions are
established to extend and evaluate the methodology.

</details>


### [115] [Are We SOLID Yet? An Empirical Study on Prompting LLMs to Detect Design Principle Violations](https://arxiv.org/abs/2509.03093)
*Fatih Pehlivan,Arçin Ülkü Ergüzen,Sahand Moslemi Yengejeh,Mayasah Lami,Anil Koyuncu*

Main category: cs.SE

TL;DR: 本文提出了一种利用提示工程评估LLMs检测多语言SOLID原则违反的方法，构建了新基准数据集并测试了四种提示策略。结果显示GPT-4o Mini表现最佳，提示策略对准确性影响显著，但需根据具体设计上下文选择合适策略。


<details>
  <summary>Details</summary>
Motivation: 传统静态分析方法难以检测需要深刻理解面向对象设计模式和原则的语义设计缺陷，如SOLID原则违反。现有解决方案通常仅关注单个SOLID原则或特定编程语言，缺乏跨所有五个原则和多语言代码库的检测能力。

Method: 提出了一种利用定制提示工程评估LLMs检测多语言代码库中SOLID原则违反能力的方法论，构建了包含240个手动验证代码示例的新基准数据集，并测试了四种不同的提示策略。

Result: 结果显示模型之间存在明显层次结构，GPT-4o Mini表现最佳，但在DIP等挑战性原则仍表现不佳。提示策略对检测准确性有显著影响，但无单一策略普遍最优。检测准确性受语言特性和代码复杂度影响较大。

Conclusion: 有效的AI驱动设计分析不仅需要最佳模型，还需要根据特定设计上下文匹配合适的模型和提示策略，凸显了LLMs通过AI辅助代码分析支持可维护性的潜力。

Abstract: Traditional static analysis methods struggle to detect semantic design flaws,
such as violations of the SOLID principles, which require a strong
understanding of object-oriented design patterns and principles. Existing
solutions typically focus on individual SOLID principles or specific
programming languages, leaving a gap in the ability to detect violations across
all five principles in multi-language codebases. This paper presents a new
approach: a methodology that leverages tailored prompt engineering to assess
LLMs on their ability to detect SOLID violations across multiple languages. We
present a benchmark of four leading LLMs-CodeLlama, DeepSeekCoder, QwenCoder,
and GPT-4o Mini-on their ability to detect violations of all five SOLID
principles. For this evaluation, we construct a new benchmark dataset of 240
manually validated code examples. Using this dataset, we test four distinct
prompt strategies inspired by established zero-shot, few-shot, and
chain-of-thought techniques to systematically measure their impact on detection
accuracy. Our emerging results reveal a stark hierarchy among models, with
GPT-4o Mini decisively outperforming others, yet even struggles with
challenging principles like DIP. Crucially, we show that prompt strategy has a
dramatic impact, but no single strategy is universally best; for instance, a
deliberative ENSEMBLE prompt excels at OCP detection while a hint-based EXAMPLE
prompt is superior for DIP violations. Across all experiments, detection
accuracy is heavily influenced by language characteristics and degrades sharply
with increasing code complexity. These initial findings demonstrate that
effective, AI-driven design analysis requires not a single best model, but a
tailored approach that matches the right model and prompt to the specific
design context, highlighting the potential of LLMs to support maintainability
through AI-assisted code analysis.

</details>


### [116] [AI Safety Assurance in Electric Vehicles: A Case Study on AI-Driven SOC Estimation](https://arxiv.org/abs/2509.03270)
*Martin Skoglund,Fredrik Warg,Aria Mirzai,Anders Thorsen,Karl Lundgren,Peter Folkesson,Bastian Havers-zulka*

Main category: cs.SE

TL;DR: 论文探讨了结合ISO 26262与ISO/PAS 8800标准评估电动汽车中AI组件安全性的方法，并通过故障注入实验验证了其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法无法有效评估基于AI的功能，需要结合新标准如ISO/PAS 8800来应对AI在电动汽车中的安全挑战。

Method: 采用故障注入实验对AI组件进行鲁棒性测试，通过系统性地引入扰动传感器输入来评估组件对输入变化的弹性。

Result: 研究识别了独立评估扩展方法的关键特性，并通过AI驱动的电池状态估计示例验证了方法的可行性。

Conclusion: 结合ISO 26262与ISO/PAS 8800标准，可以独立评估电动汽车中AI组件的安全性，为AI在汽车功能安全中的应用提供了新方法。

Abstract: Integrating Artificial Intelligence (AI) technology in electric vehicles (EV)
introduces unique challenges for safety assurance, particularly within the
framework of ISO 26262, which governs functional safety in the automotive
domain. Traditional assessment methodologies are not geared toward evaluating
AI-based functions and require evolving standards and practices. This paper
explores how an independent assessment of an AI component in an EV can be
achieved when combining ISO 26262 with the recently released ISO/PAS 8800,
whose scope is AI safety for road vehicles. The AI-driven State of Charge (SOC)
battery estimation exemplifies the process. Key features relevant to the
independent assessment of this extended evaluation approach are identified. As
part of the evaluation, robustness testing of the AI component is conducted
using fault injection experiments, wherein perturbed sensor inputs are
systematically introduced to assess the component's resilience to input
variance.

</details>


### [117] [VulnRepairEval: An Exploit-Based Evaluation Framework for Assessing Large Language Model Vulnerability Repair Capabilities](https://arxiv.org/abs/2509.03331)
*Weizhe Wang,Wei Ma,Qiang Hu,Yao Zhang,Jianfei Sun,Bin Wu,Yang Liu,Guangquan Xu,Lingxiao Jiang*

Main category: cs.SE

TL;DR: VulnRepairEval框架揭示LLMs在漏洞修复中表现不佳（仅21.7%成功率），需更严格的真实场景评估。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞修复评估数据集依赖表面验证，导致性能高估，需基于真实漏洞场景的严格评估。

Method: 通过VulnRepairEval框架，利用功能性PoC漏洞验证，对12种流行LLMs进行测试。

Result: 最佳模型仅修复5/23漏洞（21.7%），失败主因包括漏洞识别不准确和补丁语法/语义错误。

Conclusion: 本研究提出了VulnRepairEval评估框架，揭示了当前LLMs在软件漏洞修复中的局限性，强调了基于真实漏洞场景评估的重要性。

Abstract: The adoption of Large Language Models (LLMs) for automated software
vulnerability patching has shown promising outcomes on carefully curated
evaluation sets. Nevertheless, existing datasets predominantly rely on
superficial validation methods rather than exploit-based verification, leading
to overestimated performance in security-sensitive applications. This paper
introduces VulnRepairEval, an evaluation framework anchored in functional
Proof-of-Concept (PoC) exploits. Our framework delivers a comprehensive,
containerized evaluation pipeline that enables reproducible differential
assessment, where repair success requires the original exploit to fail
execution against the modified code. The benchmark construction involved
extensive data curation: we processed over 400 CVEs and approximately 2,500
potential sources to extract a collection of authentic vulnerability instances
(23 Python CVEs) amenable to automated testing with working PoCs. Through
VulnRepairEval, we conduct a comprehensive evaluation of 12 popular LLMs and
observe a significant performance deficit: even the top-performing model
successfully addresses merely 5/23 instances (about 21.7%), exposing critical
weaknesses in security-focused applications. Our failure analysis reveals that
most unsuccessful attempts stem from imprecise vulnerability identification and
patches containing syntactic or semantic errors. Enhanced prompting strategies
and multi-agent approaches yield minimal improvements, with overall
effectiveness remaining largely unaffected. This work contributes a stringent,
practical evaluation framework for LLM-driven vulnerability remediation and
underscores the necessity for assessment protocols that authentically reflect
real-world exploitation scenarios.

</details>


### [118] [The Impact of Critique on LLM-Based Model Generation from Natural Language: The Case of Activity Diagrams](https://arxiv.org/abs/2509.03463)
*Parham Khamsepour,Mark Cole,Ish Ashraf,Sandeep Puri,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: LADEX通过LLM驱动的批评-精炼循环从自然语言生成活动图，结合算法和LLM检查实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 探索利用大型语言模型（LLMs）从自然语言描述中自动生成模型的潜力，特别是解决结构正确性和语义对齐的问题。

Method: LADEX管道通过生成-批评-精炼循环从自然语言过程描述中提取活动图，结构检查可通过算法或LLM完成，语义对齐检查则由LLM执行。设计了五种变体以研究不同检查方式的影响。

Result: 实验表明，批评-精炼循环提高了结构有效性、正确性和完整性；算法结构检查比仅使用LLM检查提高了正确率17.81%和完整性13.24%；结合算法和LLM检查的性能最优。

Conclusion: 结合算法结构检查和基于LLM的语义检查的LADEX管道在性能上表现最佳，平均正确率高达86.37%，完整性达88.56%，且平均需要少于五次LLM调用。

Abstract: Large Language Models (LLMs) show strong potential for automating the
generation of models from natural-language descriptions. A common approach is
an iterative generate-critique-refine loop, where candidate models are
produced, evaluated, and updated based on detected issues. This process needs
to address: (1) structural correctness - compliance with well-formedness rules
- and (2) semantic alignment - accurate reflection of the intended meaning in
the source text. We present LADEX (LLM-based Activity Diagram Extractor), a
pipeline for deriving activity diagrams from natural-language process
descriptions using an LLM-driven critique-refine process. Structural checks in
LADEX can be performed either algorithmically or by an LLM, while alignment
checks are always performed by an LLM. We design five ablated variants of LADEX
to study: (i) the impact of the critique-refine loop itself, (ii) the role of
LLM-based semantic checks, and (iii) the comparative effectiveness of
algorithmic versus LLM-based structural checks.
  To evaluate LADEX, we compare the generated activity diagrams with
expert-created ground truths using trace-based operational semantics. This
enables automated measurement of correctness and completeness. Experiments on
two datasets indicate that: (1) the critique-refine loop improves structural
validity, correctness, and completeness compared to single-pass generation; (2)
algorithmic structural checks eliminate inconsistencies that LLM-based checks
fail to detect, improving correctness by an average of 17.81% and completeness
by 13.24% over LLM-only checks; and (3) combining algorithmic structural checks
with LLM-based semantic checks, implemented using the reasoning-focused O4
Mini, achieves the best overall performance - yielding average correctness of
up to 86.37% and average completeness of up to 88.56% - while requiring fewer
than five LLM calls on average.

</details>
