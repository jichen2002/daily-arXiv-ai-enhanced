<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 70]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.AI](#cs.AI) [Total: 39]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 20]
- [cs.GR](#cs.GR) [Total: 7]
- [cs.NI](#cs.NI) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Efficient General Feature Prediction in Masked Skeleton Modeling](https://arxiv.org/abs/2509.03609)
*Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang*

Main category: cs.CV

TL;DR: GFP框架通过高级特征预测提升骨架动作识别的效率和性能，实验证明其快速且效果优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法的重建目标局限于原始关节坐标或其简单变体，导致计算冗余和语义表示受限。

Method: 引入了一个协作学习框架，其中轻量级目标生成网络动态生成多样化的监督信号，结合约束优化确保特征多样性。

Result: 在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上，GFP框架训练速度比标准方法快6.2倍，并在下游任务中表现优异。

Conclusion: GFP框架通过高级特征预测取代传统低级重建，显著提升了计算效率和语义表示能力，在多个数据集上实现了最先进的性能。

Abstract: Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.

</details>


### [2] [Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge](https://arxiv.org/abs/2509.03614)
*Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Dimitri Androutsos,Susan Done,April Khademi*

Main category: cs.CV

TL;DR: 该论文提出了一种结合分割和分类的教师-学生模型，用于解决有丝分裂检测中的领域偏移和数据不平衡问题，初步测试表现良好。


<details>
  <summary>Details</summary>
Motivation: 有丝分裂计数对病理学家耗时且存在观察者间差异，AI工具虽能自动检测但受领域偏移和数据不平衡影响。

Method: 采用了基于UNet的分割骨干网络，结合对比表示学习和领域对抗训练模块，并利用教师-学生策略生成像素级伪掩码，以增强特征判别能力。分类任务则通过多尺度CNN分类器实现。

Result: 在初步测试中，算法在Track 1（有丝分裂检测）中F1得分为0.7660，Track 2（非典型有丝分裂分类）中平衡准确率为0.8414。

Conclusion: 该研究通过结合分割和分类任务，提出了一个统一的框架，成功解决了有丝分裂检测中的领域偏移和数据不平衡问题，并在初步测试中取得了良好的性能。

Abstract: Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.

</details>


### [3] [Multi Attribute Bias Mitigation via Representation Learning](https://arxiv.org/abs/2509.03616)
*Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi*

Main category: cs.CV

TL;DR: GMBM是一个两阶段框架，通过识别和抑制多重偏差提升视觉模型的鲁棒性和公平性。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像中存在多重重叠偏差，单独解决这些偏差效果不佳，需要一种综合方法。

Method: 采用两阶段框架：1. Adaptive Bias Integrated Learning (ABIL)训练编码器识别已知偏差；2. Gradient Suppression Fine Tuning从主干梯度中修剪偏差方向。

Result: 在FB CMNIST、CelebA和COCO数据集上，GMBM显著提升了最差群体准确率，减少了多属性偏差放大，并在SBA指标上表现优异。

Conclusion: GMBM框架通过ABIL和梯度抑制微调，有效减少了视觉模型中的多重偏差，提升了最差群体准确率，并在FB CMNIST、CelebA和COCO数据集上验证了其有效性。

Abstract: Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/

</details>


### [4] [Lightweight image segmentation for echocardiography](https://arxiv.org/abs/2509.03631)
*Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver*

Main category: cs.CV

TL;DR: 研究通过消融分析优化nnU-Net，开发出轻量级U-Net，性能相当但更小更快。


<details>
  <summary>Details</summary>
Motivation: 实现左心室超声图像的高效、实时分割，以自动提取临床测量数据。

Method: 通过消融研究评估了数据增强方案、架构修改、损失函数和后处理技术，确定了最有效的组件。

Result: 轻量级U-Net（2M参数）在CAMUS数据集上性能与nnU-Net（33M参数）相当（Dice分数0.93/0.85/0.89 vs 0.93/0.86/0.89），但体积缩小16倍，速度快4倍（1.35ms vs 5.40ms每帧）。跨数据集评估也显示相似的泛化能力。

Conclusion: 通过消融研究确定了nnU-Net中最有效的组件，开发了一个轻量级的U-Net模型，在保持性能的同时显著提升了速度和效率。

Abstract: Accurate segmentation of the left ventricle in echocardiography can enable
fully automatic extraction of clinical measurements such as volumes and
ejection fraction. While models configured by nnU-Net perform well, they are
large and slow, thus limiting real-time use. We identified the most effective
components of nnU-Net for cardiac segmentation through an ablation study,
incrementally evaluating data augmentation schemes, architectural
modifications, loss functions, and post-processing techniques. Our analysis
revealed that simple affine augmentations and deep supervision drive
performance, while complex augmentations and large model capacity offer
diminishing returns. Based on these insights, we developed a lightweight U-Net
(2M vs 33M parameters) that achieves statistically equivalent performance to
nnU-Net on CAMUS (N=500) with Dice scores of 0.93/0.85/0.89 vs 0.93/0.86/0.89
for LV/MYO/LA ($p>0.05$), while being 16 times smaller and 4 times faster
(1.35ms vs 5.40ms per frame) than the default nnU-Net configuration.
Cross-dataset evaluation on an internal dataset (N=311) confirms comparable
generalization.

</details>


### [5] [treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds](https://arxiv.org/abs/2509.03633)
*Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner*

Main category: cs.CV

TL;DR: 提出treeX算法的修订版，资源高效且性能优于原算法，适用于地面和无人机激光扫描数据。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法需要大量标注数据和计算资源，因此需要一种资源高效的替代方案。

Method: 结合基于聚类的茎干检测与区域生长的树冠划分方法，提供了两种参数预设（地面和无人机激光扫描）。

Result: 修订后的算法在运行时间和准确性上均有提升，地面数据F1分数提高了+0.11至+0.49，无人机数据F1分数为0.58。

Conclusion: 该论文提出了treeX算法的修订版本，作为一种资源高效的替代方案，适用于地面和无人机激光扫描数据，能够减少运行时间并提高准确性。

Abstract: Close-range laser scanning provides detailed 3D captures of forest stands but
requires efficient software for processing 3D point cloud data and extracting
individual trees. Although recent studies have introduced deep learning methods
for tree instance segmentation, these approaches require large annotated
datasets and substantial computational resources. As a resource-efficient
alternative, we present a revised version of the treeX algorithm, an
unsupervised method that combines clustering-based stem detection with region
growing for crown delineation. While the original treeX algorithm was developed
for personal laser scanning (PLS) data, we provide two parameter presets, one
for ground-based laser scanning (stationary terrestrial - TLS and PLS), and one
for UAV-borne laser scanning (ULS). We evaluated the method on six public
datasets (FOR-instance, ForestSemantic, LAUTx, NIBIO MLS, TreeLearn, Wytham
Woods) and compared it to six open-source methods (original treeX, treeiso,
RayCloudTools, ForAINet, SegmentAnyTree, TreeLearn). Compared to the original
treeX algorithm, our revision reduces runtime and improves accuracy, with
instance detection F$_1$-score gains of +0.11 to +0.49 for ground-based data.
For ULS data, our preset achieves an F$_1$-score of 0.58, whereas the original
algorithm fails to segment any correct instances. For TLS and PLS data, our
algorithm achieves accuracy similar to recent open-source methods, including
deep learning. Given its algorithmic design, we see two main applications for
our method: (1) as a resource-efficient alternative to deep learning approaches
in scenarios where the data characteristics align with the method design
(sufficient stem visibility and point density), and (2) for the semi-automatic
generation of labels for deep learning models. To enable broader adoption, we
provide an open-source Python implementation in the pointtree package.

</details>


### [6] [Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding](https://arxiv.org/abs/2509.03635)
*Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin*

Main category: cs.CV

TL;DR: Reg3D通过几何感知监督和双重监督范式，显著提升了3D场景理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖纯文本监督，缺乏几何约束，难以学习稳健的3D空间表示。

Method: 采用双编码器架构，设计了互补的对象级和帧级重建任务，以强化几何一致性。

Result: 在ScanQA、Scan2Cap、ScanRefer和SQA3D等数据集上的实验表明，Reg3D显著提升了性能。

Conclusion: Reg3D通过引入几何感知监督和双重监督范式，显著提升了3D场景理解能力，为空间感知多模态模型建立了新的训练范式。

Abstract: The rapid development of Large Multimodal Models (LMMs) has led to remarkable
progress in 2D visual understanding; however, extending these capabilities to
3D scene understanding remains a significant challenge. Existing approaches
predominantly rely on text-only supervision, which fails to provide the
geometric constraints required for learning robust 3D spatial representations.
In this paper, we introduce Reg3D, a novel Reconstructive Geometry Instruction
Tuning framework that addresses this limitation by incorporating geometry-aware
supervision directly into the training process. Our key insight is that
effective 3D understanding necessitates reconstructing underlying geometric
structures rather than merely describing them. Unlike existing methods that
inject 3D information solely at the input level, Reg3D adopts a
dual-supervision paradigm that leverages 3D geometric information both as input
and as explicit learning targets. Specifically, we design complementary
object-level and frame-level reconstruction tasks within a dual-encoder
architecture, enforcing geometric consistency to encourage the development of
spatial reasoning capabilities. Extensive experiments on ScanQA, Scan2Cap,
ScanRefer, and SQA3D demonstrate that Reg3D delivers substantial performance
improvements, establishing a new training paradigm for spatially aware
multimodal models.

</details>


### [7] [QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception](https://arxiv.org/abs/2509.03704)
*Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma*

Main category: cs.CV

TL;DR: QuantV2X是一种完全量化的V2X协同感知系统，通过端到端量化策略显著提升效率，同时保持高精度，适用于实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注精度指标，而忽视了效率、延迟和实际部署等系统级考虑。全精度模型的高计算和传输成本使其在资源受限环境中不实用。

Method: 论文提出了一种统一的端到端量化策略，应用于神经网络模型和传输的消息表示，以同时减少计算负载和传输带宽。

Result: QuantV2X在低比特约束下实现了与全精度系统相当的准确性，系统级延迟降低了3.2倍，mAP30提高了9.5，并更有效地扩展以适应严格的内存预算。

Conclusion: QuantV2X作为首个完全量化的多模态、多智能体V2X协同感知系统，展示了在资源受限环境中高效部署的可行性，并显著降低了系统级延迟和传输带宽，同时保持了与全精度系统相当的准确性。

Abstract: Cooperative perception through Vehicle-to-Everything (V2X) communication
offers significant potential for enhancing vehicle perception by mitigating
occlusions and expanding the field of view. However, past research has
predominantly focused on improving accuracy metrics without addressing the
crucial system-level considerations of efficiency, latency, and real-world
deployability. Noticeably, most existing systems rely on full-precision models,
which incur high computational and transmission costs, making them impractical
for real-time operation in resource-constrained environments. In this paper, we
introduce \textbf{QuantV2X}, the first fully quantized multi-agent system
designed specifically for efficient and scalable deployment of multi-modal,
multi-agent V2X cooperative perception. QuantV2X introduces a unified
end-to-end quantization strategy across both neural network models and
transmitted message representations that simultaneously reduces computational
load and transmission bandwidth. Remarkably, despite operating under low-bit
constraints, QuantV2X achieves accuracy comparable to full-precision systems.
More importantly, when evaluated under deployment-oriented metrics, QuantV2X
reduces system-level latency by 3.2$\times$ and achieves a +9.5 improvement in
mAP30 over full-precision baselines. Furthermore, QuantV2X scales more
effectively, enabling larger and more capable models to fit within strict
memory budgets. These results highlight the viability of a fully quantized
multi-agent intermediate fusion system for real-world deployment. The system
will be publicly released to promote research in this field:
https://github.com/ucla-mobility/QuantV2X.

</details>


### [8] [Transfer Learning-Based CNN Models for Plant Species Identification Using Leaf Venation Patterns](https://arxiv.org/abs/2509.03729)
*Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj*

Main category: cs.CV

TL;DR: 研究比较了ResNet50、MobileNetV2和EfficientNetB0在叶脉分类中的表现，EfficientNetB0表现最佳，适合自动化植物分类。


<details>
  <summary>Details</summary>
Motivation: 评估不同深度学习架构在基于叶脉模式的植物物种分类中的效能，以开发可扩展且准确的自动化植物分类工具。

Method: 使用瑞典叶数据集（包含15个不同物种的1,125张图像），评估了ResNet50、MobileNetV2和EfficientNetB0三种深度学习架构在基于叶脉模式的植物物种分类中的效能。

Result: ResNet50训练准确率为94.11%，但存在过拟合，测试准确率为88.45%；MobileNetV2测试准确率为93.34%，F1分数为93.23%；EfficientNetB0表现最佳，测试准确率为94.67%，精确率、召回率和F1分数均超过94.6%。

Conclusion: 研究强调了深度学习，特别是EfficientNetB0，在利用叶脉特征开发可扩展且准确的自动化植物分类工具中的潜力。

Abstract: This study evaluates the efficacy of three deep learning architectures:
ResNet50, MobileNetV2, and EfficientNetB0 for automated plant species
classification based on leaf venation patterns, a critical morphological
feature with high taxonomic relevance. Using the Swedish Leaf Dataset
comprising images from 15 distinct species (75 images per species, totalling
1,125 images), the models were demonstrated using standard performance metrics
during training and testing phases. ResNet50 achieved a training accuracy of
94.11% but exhibited overfitting, reflected by a reduced testing accuracy of
88.45% and an F1 score of 87.82%. MobileNetV2 demonstrated better
generalization capabilities, attaining a testing accuracy of 93.34% and an F1
score of 93.23%, indicating its suitability for lightweight, real-time
applications. EfficientNetB0 outperformed both models, achieving a testing
accuracy of 94.67% with precision, recall, and F1 scores exceeding 94.6%,
highlighting its robustness in venation-based classification. The findings
underscore the potential of deep learning, particularly EfficientNetB0, in
developing scalable and accurate tools for automated plant taxonomy using
venation traits.

</details>


### [9] [LayoutGKN: Graph Similarity Learning of Floor Plans](https://arxiv.org/abs/2509.03737)
*Casper van Engelenburg,Jan van Gemert,Seyran Khademi*

Main category: cs.CV

TL;DR: LayoutGKN是一种高效的图匹配方法，通过优化跨图节点级交互的时机，显著提高了速度，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的图匹配网络在比较建筑平面图时依赖于昂贵的中间跨图节点级交互，导致推理时间较慢。LayoutGKN旨在提高效率，同时保持或提升相似性计算的准确性。

Method: LayoutGKN采用了一种联合嵌入架构，其中跨图节点级交互被推迟到最后阶段，并利用可微分图核作为最终学习的节点级嵌入的距离函数。

Result: LayoutGKN在相似性计算上与图匹配网络相当或更好，同时显著提高了推理速度。

Conclusion: LayoutGKN通过将跨图节点级交互推迟到联合嵌入架构的末端，并使用可微分图核作为距离函数，显著提高了计算速度，同时保持了与图匹配网络相当或更好的相似性计算能力。

Abstract: Floor plans depict building layouts and are often represented as graphs to
capture the underlying spatial relationships. Comparison of these graphs is
critical for applications like search, clustering, and data visualization. The
most successful methods to compare graphs \ie, graph matching networks, rely on
costly intermediate cross-graph node-level interactions, therefore being slow
in inference time. We introduce \textbf{LayoutGKN}, a more efficient approach
that postpones the cross-graph node-level interactions to the end of the joint
embedding architecture. We do so by using a differentiable graph kernel as a
distance function on the final learned node-level embeddings. We show that
LayoutGKN computes similarity comparably or better than graph matching networks
while significantly increasing the speed.
\href{https://github.com/caspervanengelenburg/LayoutGKN}{Code and data} are
open.

</details>


### [10] [Singular Value Few-shot Adaptation of Vision-Language Models](https://arxiv.org/abs/2509.03740)
*Taha Koleilat,Hassan Rivaz,Yiming Xiao*

Main category: cs.CV

TL;DR: CLIP-SVD利用SVD技术高效调整CLIP模型参数，仅需微调0.04%参数，在多个数据集上实现最优分类性能，同时保持泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有适应方法依赖提示工程或全模型微调，成本高且可能限制适应质量、破坏模型稳定性或损害预训练知识。CLIP-SVD旨在提供一种多模态、参数高效的适应技术。

Method: 利用奇异值分解（SVD）技术，仅微调CLIP参数矩阵的奇异值，以重新缩放基向量，实现领域适应，避免引入额外模块。

Result: CLIP-SVD在少样本设置下，在11个自然和10个生物医学数据集上实现了最先进的分类结果，优于先前方法。

Conclusion: CLIP-SVD通过SVD技术高效调整CLIP模型的内部参数空间，仅需微调0.04%的参数即可实现领域适应，同时保持预训练模型的泛化能力，在11个自然和10个生物医学数据集上取得了最先进的分类结果。

Abstract: Vision-language models (VLMs) like CLIP have shown impressive zero-shot and
few-shot learning capabilities across diverse applications. However, adapting
these models to new fine-grained domains remains difficult due to reliance on
prompt engineering and the high cost of full model fine-tuning. Existing
adaptation approaches rely on augmented components, such as prompt tokens and
adapter modules, which could limit adaptation quality, destabilize the model,
and compromise the rich knowledge learned during pretraining. In this work, we
present \textbf{CLIP-SVD}, a novel \textit{multi-modal} and
\textit{parameter-efficient} adaptation technique that leverages Singular Value
Decomposition (SVD) to modify the internal parameter space of CLIP without
injecting additional modules. Specifically, we fine-tune only the singular
values of the CLIP parameter matrices to rescale the basis vectors for domain
adaptation while retaining the pretrained model. This design enables enhanced
adaptation performance using only \textbf{0.04\%} of the model's total
parameters and better preservation of its generalization ability. CLIP-SVD
achieves state-of-the-art classification results on 11 natural and 10
biomedical datasets, outperforming previous methods in both accuracy and
generalization under few-shot settings. Additionally, we leverage a natural
language-based approach to analyze the effectiveness and dynamics of the CLIP
adaptation to allow interpretability of CLIP-SVD. The code is publicly
available at https://github.com/HealthX-Lab/CLIP-SVD.

</details>


### [11] [STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification](https://arxiv.org/abs/2509.03754)
*Zongsen Qiu*

Main category: cs.CV

TL;DR: 提出STA-Net模型，结合形状-纹理注意力模块（STAM）和无需训练的神经架构搜索（DeepMAD），在边缘设备上高效实现植物病害诊断，准确率达89%。


<details>
  <summary>Details</summary>
Motivation: 响应全球粮食安全需求的增长，精准农业和基于深度学习的植物病害诊断变得至关重要。然而，在边缘设备上部署高精度模型具有挑战性，现有轻量级网络的注意力机制设计用于通用物体识别，难以捕捉细微的病理特征。

Method: 提出了一种无需训练的神经架构搜索方法（DeepMAD）来构建高效的网络主干，并引入了形状-纹理注意力模块（STAM），该模块将注意力分为两个分支：一个使用可变形卷积（DCNv4）捕捉形状特征，另一个使用Gabor滤波器组捕捉纹理特征。

Result: 在公开的CCMT植物病害数据集上，STA-Net模型（参数401K，FLOPs 51.1M）达到了89.00%的准确率和88.96%的F1分数。消融研究证实STAM显著优于基线和标准注意力模型。

Conclusion: 通过解耦注意力机制结合领域知识，为边缘部署的精准农业AI提供了一条有前景的路径。

Abstract: Responding to rising global food security needs, precision agriculture and
deep learning-based plant disease diagnosis have become crucial. Yet, deploying
high-precision models on edge devices is challenging. Most lightweight networks
use attention mechanisms designed for generic object recognition, which poorly
capture subtle pathological features like irregular lesion shapes and complex
textures. To overcome this, we propose a twofold solution: first, using a
training-free neural architecture search method (DeepMAD) to create an
efficient network backbone for edge devices; second, introducing the
Shape-Texture Attention Module (STAM). STAM splits attention into two branches
-- one using deformable convolutions (DCNv4) for shape awareness and the other
using a Gabor filter bank for texture awareness. On the public CCMT plant
disease dataset, our STA-Net model (with 401K parameters and 51.1M FLOPs)
reached 89.00% accuracy and an F1 score of 88.96%. Ablation studies confirm
STAM significantly improves performance over baseline and standard attention
models. Integrating domain knowledge via decoupled attention thus presents a
promising path for edge-deployed precision agriculture AI. The source code is
available at https://github.com/RzMY/STA-Net.

</details>


### [12] [SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection](https://arxiv.org/abs/2509.03786)
*Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao*

Main category: cs.CV

TL;DR: 论文提出SLENet框架和DeepCamo数据集，用于解决水下伪装物体检测任务，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下伪装物体检测(UCOD)对海洋生态至关重要，但受光学失真、水体浑浊和海洋生物复杂特征影响，该任务尚未充分探索且识别精度低。

Method: 提出了Semantic Localization and Enhancement Network (SLENet)，包含Gamma-Asymmetric Enhancement (GAE)模块和Localization Guidance Branch (LGB)，结合Multi-Scale Supervised Decoder (MSSD)生成更准确的预测。

Result: SLENet在DeepCamo数据集和三个基准COD数据集上验证了其优越性能。

Conclusion: SLENet在DeepCamo数据集和三个基准COD数据集上表现出优于现有方法的性能，并展示了其在更广泛COD任务中的高泛化能力。

Abstract: Underwater Camouflaged Object Detection (UCOD) aims to identify objects that
blend seamlessly into underwater environments. This task is critically
important to marine ecology. However, it remains largely underexplored and
accurate identification is severely hindered by optical distortions, water
turbidity, and the complex traits of marine organisms. To address these
challenges, we introduce the UCOD task and present DeepCamo, a benchmark
dataset designed for this domain. We also propose Semantic Localization and
Enhancement Network (SLENet), a novel framework for UCOD. We first benchmark
state-of-the-art COD models on DeepCamo to reveal key issues, upon which SLENet
is built. In particular, we incorporate Gamma-Asymmetric Enhancement (GAE)
module and a Localization Guidance Branch (LGB) to enhance multi-scale feature
representation while generating a location map enriched with global semantic
information. This map guides the Multi-Scale Supervised Decoder (MSSD) to
produce more accurate predictions. Experiments on our DeepCamo dataset and
three benchmark COD datasets confirm SLENet's superior performance over SOTA
methods, and underscore its high generality for the broader COD task.

</details>


### [13] [Fitting Image Diffusion Models on Video Datasets](https://arxiv.org/abs/2509.03794)
*Juhun Lee,Simon S. Woo*

Main category: cs.CV

TL;DR: 通过视频帧时间偏置改进扩散训练，加速收敛、提升生成多样性，无需修改架构。


<details>
  <summary>Details</summary>
Motivation: 静态图像训练在捕捉时序世界时存在信息不足的问题，导致收敛慢、分布覆盖有限和泛化能力降低。

Method: 提出了一种简单有效的训练策略，利用连续视频帧中的时间归纳偏置改进扩散训练。

Result: 在HandCo数据集上，方法加速收敛超过2倍，训练和验证分布的FID更低，生成多样性提升。优化分析显示正则化降低了梯度方差。

Conclusion: 提出的方法通过利用视频帧中的时间归纳偏置，显著提升了扩散模型的训练效率和生成多样性，且无需架构修改。

Abstract: Image diffusion models are trained on independently sampled static images.
While this is the bedrock task protocol in generative modeling, capturing the
temporal world through the lens of static snapshots is information-deficient by
design. This limitation leads to slower convergence, limited distributional
coverage, and reduced generalization. In this work, we propose a simple and
effective training strategy that leverages the temporal inductive bias present
in continuous video frames to improve diffusion training. Notably, the proposed
method requires no architectural modification and can be seamlessly integrated
into standard diffusion training pipelines. We evaluate our method on the
HandCo dataset, where hand-object interactions exhibit dense temporal coherence
and subtle variations in finger articulation often result in semantically
distinct motions. Empirically, our method accelerates convergence by over
2$\text{x}$ faster and achieves lower FID on both training and validation
distributions. It also improves generative diversity by encouraging the model
to capture meaningful temporal variations. We further provide an optimization
analysis showing that our regularization reduces the gradient variance, which
contributes to faster convergence.

</details>


### [14] [MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting](https://arxiv.org/abs/2509.03800)
*Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang*

Main category: cs.CV

TL;DR: MedVista3D是一个多尺度视觉语言预训练框架，用于解决3D CT分析中的局部检测和全局解释问题，通过图像-文本对齐和语义匹配技术，在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 放射学诊断错误（如漏读、注意力盲区和沟通失败）在临床实践中普遍存在，尤其是在3D成像中，现有模型无法同时满足局部检测、全局推理和语义一致报告的需求。

Method: MedVista3D通过局部和全局的图像-文本对齐实现细粒度表示学习，并利用语言模型重写和放射学语义匹配库来解决报告变异性问题。

Result: MedVista3D在零样本疾病分类、报告检索和医学视觉问答等任务中表现优异，并能很好地迁移到器官分割和预后预测任务。

Conclusion: MedVista3D提出了一种多尺度语义丰富的视觉语言预训练框架，用于3D CT分析，能够同时满足局部疾病检测和全局解释的需求，并在多项任务中达到最先进的性能。

Abstract: Radiologic diagnostic errors-under-reading errors, inattentional blindness,
and communication failures-remain prevalent in clinical practice. These issues
often stem from missed localized abnormalities, limited global context, and
variability in report language. These challenges are amplified in 3D imaging,
where clinicians must examine hundreds of slices per scan. Addressing them
requires systems with precise localized detection, global volume-level
reasoning, and semantically consistent natural language reporting. However,
existing 3D vision-language models are unable to meet all three needs jointly,
lacking local-global understanding for spatial reasoning and struggling with
the variability and noise of uncurated radiology reports. We present
MedVista3D, a multi-scale semantic-enriched vision-language pretraining
framework for 3D CT analysis. To enable joint disease detection and holistic
interpretation, MedVista3D performs local and global image-text alignment for
fine-grained representation learning within full-volume context. To address
report variability, we apply language model rewrites and introduce a Radiology
Semantic Matching Bank for semantics-aware alignment. MedVista3D achieves
state-of-the-art performance on zero-shot disease classification, report
retrieval, and medical visual question answering, while transferring well to
organ segmentation and prognosis prediction. Code and datasets will be
released.

</details>


### [15] [Causality-guided Prompt Learning for Vision-language Models via Visual Granulation](https://arxiv.org/abs/2509.03803)
*Mengyu Gao,Qiulei Dong*

Main category: cs.CV

TL;DR: CaPL通过视觉粒化和因果推理提升CLIP在细粒度任务中的表现，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有CLIP提示学习方法在细粒度数据集上表现有限的问题。

Method: CaPL包含两个模块：1）属性解耦模块，使用布朗桥扩散模型将视觉特征分解为共享属性和特定属性；2）粒学习模块，通过两种因果推理策略整合属性构建视觉颗粒。

Result: 在15个数据集上的实验结果表明，CaPL显著优于现有方法，尤其在细粒度数据集上。

Conclusion: CaPL方法通过视觉粒化和因果推理显著提升了CLIP在细粒度数据集上的表现，超越了现有最先进的提示学习方法。

Abstract: Prompt learning has recently attracted much attention for adapting
pre-trained vision-language models (e.g., CLIP) to downstream recognition
tasks. However, most of the existing CLIP-based prompt learning methods only
show a limited ability for handling fine-grained datasets. To address this
issue, we propose a causality-guided text prompt learning method via visual
granulation for CLIP, called CaPL, where the explored visual granulation
technique could construct sets of visual granules for the text prompt to
capture subtle discrepancies among different fine-grained classes through
casual inference. The CaPL method contains the following two modules: (1) An
attribute disentanglement module is proposed to decompose visual features into
non-individualized attributes (shared by some classes) and individualized
attributes (specific to single classes) using a Brownian Bridge Diffusion
Model; (2) A granule learning module is proposed to construct visual granules
by integrating the aforementioned attributes for recognition under two causal
inference strategies. Thanks to the learned visual granules, more
discriminative text prompt is expected to be learned. Extensive experimental
results on 15 datasets demonstrate that our CaPL method significantly
outperforms the state-of-the-art prompt learning methods, especially on
fine-grained datasets.

</details>


### [16] [EGTM: Event-guided Efficient Turbulence Mitigation](https://arxiv.org/abs/2509.03808)
*Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu*

Main category: cs.CV

TL;DR: EGTM框架利用事件相机的高时间分辨率，显著提升湍流缓解效率和质量，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习湍流缓解方法需要高容量网络从有限帧率的同步帧中学习粗粒度湍流动态，效率和存储受限。事件相机的高时间分辨率能有效解决这一瓶颈。

Method: 提出EGTM框架，从事件流中提取像素级可靠的湍流无关引导，用于时序幸运融合。

Result: EGTM在模型大小、推理延迟和复杂度上分别提升710倍、214倍和224倍，恢复质量（PSNR和SSIM）达到SOTA。

Conclusion: 引入事件模态到湍流缓解任务中具有显著的效率优势，EGTM框架在模型大小、推理延迟和复杂度上大幅超越现有方法，同时恢复质量达到SOTA。

Abstract: Turbulence mitigation (TM) aims to remove the stochastic distortions and
blurs introduced by atmospheric turbulence into frame cameras. Existing
state-of-the-art deep-learning TM methods extract turbulence cues from multiple
degraded frames to find the so-called "lucky'', not distorted patch, for "lucky
fusion''. However, it requires high-capacity network to learn from
coarse-grained turbulence dynamics between synchronous frames with limited
frame-rate, thus fall short in computational and storage efficiency. Event
cameras, with microsecond-level temporal resolution, have the potential to
fundamentally address this bottleneck with efficient sparse and asynchronous
imaging mechanism. In light of this, we (i) present the fundamental
\textbf{``event-lucky insight''} to reveal the correlation between turbulence
distortions and inverse spatiotemporal distribution of event streams. Then,
build upon this insight, we (ii) propose a novel EGTM framework that extracts
pixel-level reliable turbulence-free guidance from the explicit but noisy
turbulent events for temporal lucky fusion. Moreover, we (iii) build the first
turbulence data acquisition system to contribute the first real-world
event-driven TM dataset. Extensive experimental results demonstrate that our
approach significantly surpass the existing SOTA TM method by 710 times, 214
times and 224 times in model size, inference latency and model complexity
respectively, while achieving the state-of-the-art in restoration quality
(+0.94 PSNR and +0.08 SSIM) on our real-world EGTM dataset. This demonstrating
the great efficiency merit of introducing event modality into TM task. Demo
code and data have been uploaded in supplementary material and will be released
once accepted.

</details>


### [17] [Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection](https://arxiv.org/abs/2509.03872)
*Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao*

Main category: cs.CV

TL;DR: FocusMamba通过自适应稀疏化和高效融合多模态特征，提升RGB-Event检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多模态低信息区域时存在计算冗余和性能不佳的问题。

Method: 提出Event-Guided Multimodal Sparsification (EGMS)策略和Cross-Modality Focus Fusion (CMFF)模块，实现自适应特征稀疏化和互补信息融合。

Result: 在DSEC-Det和PKU-DAVIS-SOD数据集上表现出优越的准确性和效率。

Conclusion: FocusMamba通过自适应协作稀疏化和高效融合多模态特征，在准确性和效率上优于现有方法。

Abstract: Existing RGB-Event detection methods process the low-information regions of
both modalities (background in images and non-event regions in event data)
uniformly during feature extraction and fusion, resulting in high computational
costs and suboptimal performance. To mitigate the computational redundancy
during feature extraction, researchers have respectively proposed token
sparsification methods for the image and event modalities. However, these
methods employ a fixed number or threshold for token selection, hindering the
retention of informative tokens for samples with varying complexity. To achieve
a better balance between accuracy and efficiency, we propose FocusMamba, which
performs adaptive collaborative sparsification of multimodal features and
efficiently integrates complementary information. Specifically, an Event-Guided
Multimodal Sparsification (EGMS) strategy is designed to identify and
adaptively discard low-information regions within each modality by leveraging
scene content changes perceived by the event camera. Based on the
sparsification results, a Cross-Modality Focus Fusion (CMFF) module is proposed
to effectively capture and integrate complementary features from both
modalities. Experiments on the DSEC-Det and PKU-DAVIS-SOD datasets demonstrate
that the proposed method achieves superior performance in both accuracy and
efficiency compared to existing methods. The code will be available at
https://github.com/Zizzzzzzz/FocusMamba.

</details>


### [18] [SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition](https://arxiv.org/abs/2509.03873)
*Jiajun Song,Xiaoou Liu*

Main category: cs.CV

TL;DR: 提出了SalientFusion方法，解决零样本食物识别中的背景冗余、角色混淆和语义偏差问题，在多个数据集上取得最优表现。


<details>
  <summary>Details</summary>
Motivation: 零样本食物学习（ZSFL）的需求源于新菜品的快速涌现，而组合零样本食物识别（CZSFR）面临背景冗余、角色混淆和语义偏差三大挑战。

Method: 提出了SalientFusion方法，包含SalientFormer（去除背景冗余和利用深度特征解决角色混淆）和DebiasAT（通过对齐提示与视觉特征减少语义偏差）。

Result: SalientFusion在CZSFood-90和CZSFood-164基准测试及通用CZSL数据集上取得了最先进的结果。

Conclusion: SalientFusion方法在CZSFood-90和CZSFood-164基准测试以及通用CZSL数据集上实现了最先进的结果，证明了其在零样本食物识别任务中的有效性。

Abstract: Food recognition has gained significant attention, but the rapid emergence of
new dishes requires methods for recognizing unseen food categories, motivating
Zero-Shot Food Learning (ZSFL). We propose the task of Compositional Zero-Shot
Food Recognition (CZSFR), where cuisines and ingredients naturally align with
attributes and objects in Compositional Zero-Shot learning (CZSL). However,
CZSFR faces three challenges: (1) Redundant background information distracts
models from learning meaningful food features, (2) Role confusion between
staple and side dishes leads to misclassification, and (3) Semantic bias in a
single attribute can lead to confusion of understanding. Therefore, we propose
SalientFusion, a context-aware CZSFR method with two components: SalientFormer,
which removes background redundancy and uses depth features to resolve role
confusion; DebiasAT, which reduces the semantic bias by aligning prompts with
visual features. Using our proposed benchmarks, CZSFood-90 and CZSFood-164, we
show that SalientFusion achieves state-of-the-art results on these benchmarks
and the most popular general datasets for the general CZSL. The code is
avaliable at https://github.com/Jiajun-RUC/SalientFusion.

</details>


### [19] [YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components](https://arxiv.org/abs/2509.04156)
*Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko*

Main category: cs.CV

TL;DR: 通过集成YOLO模型和融合多光谱数据，显著提升了风力发电厂缺陷检测的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 无人机配备先进传感器为风力发电厂监测提供了新机会，但高分辨率数据和高效的多光谱图像处理方法对可靠缺陷检测至关重要。

Method: 开发了一种基于YOLO的深度学习模型集成方法，结合通用YOLOv8模型和专用热模型，通过复杂的边界框融合算法整合它们的预测。

Result: 实验结果显示，该方法实现了0.93的mAP@.5和0.90的F1分数，优于单独使用YOLOv8模型的0.91 mAP@.5。

Conclusion: 结合多个YOLO架构并融合多光谱数据，提供了一种更可靠的解决方案，显著提高了视觉和热缺陷的检测能力。

Abstract: Unmanned aerial vehicles (UAVs) equipped with advanced sensors have opened up
new opportunities for monitoring wind power plants, including blades, towers,
and other critical components. However, reliable defect detection requires
high-resolution data and efficient methods to process multispectral imagery. In
this research, we aim to enhance defect detection accuracy through the
development of an ensemble of YOLO-based deep learning models that integrate
both visible and thermal channels. We propose an ensemble approach that
integrates a general-purpose YOLOv8 model with a specialized thermal model,
using a sophisticated bounding box fusion algorithm to combine their
predictions. Our experiments show this approach achieves a mean Average
Precision (mAP@.5) of 0.93 and an F1-score of 0.90, outperforming a standalone
YOLOv8 model, which scored an mAP@.5 of 0.91. These findings demonstrate that
combining multiple YOLO architectures with fused multispectral data provides a
more reliable solution, improving the detection of both visual and thermal
defects.

</details>


### [20] [Human Motion Video Generation: A Survey](https://arxiv.org/abs/2509.03883)
*Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu*

Main category: cs.CV

TL;DR: 本文全面调查了人类动作视频生成领域，涵盖五种关键阶段和三种模态，首次探讨了大语言模型的潜力，并总结了200多篇论文的最新进展。


<details>
  <summary>Details</summary>
Motivation: 现有调查集中于个体方法，缺乏对整个生成过程的全面概述，本文旨在填补这一空白。

Method: 调查了超过200篇论文，涵盖视觉、文本和音频三种主要模态，详细分析了输入、动作规划、动作视频生成、精炼和输出五个环节。

Result: 提供了人类动作视频生成领域的全面概述，突出了推动技术突破的里程碑工作，并讨论了大语言模型的潜在应用。

Conclusion: 本论文通过深入调查人类动作视频生成的五个关键阶段，并首次探讨了大语言模型在该领域的潜力，为数字人类的全面应用提供了宝贵资源。

Abstract: Human motion video generation has garnered significant research interest due
to its broad applications, enabling innovations such as photorealistic singing
heads or dynamic avatars that seamlessly dance to music. However, existing
surveys in this field focus on individual methods, lacking a comprehensive
overview of the entire generative process. This paper addresses this gap by
providing an in-depth survey of human motion video generation, encompassing
over ten sub-tasks, and detailing the five key phases of the generation
process: input, motion planning, motion video generation, refinement, and
output. Notably, this is the first survey that discusses the potential of large
language models in enhancing human motion video generation. Our survey reviews
the latest developments and technological trends in human motion video
generation across three primary modalities: vision, text, and audio. By
covering over two hundred papers, we offer a thorough overview of the field and
highlight milestone works that have driven significant technological
breakthroughs. Our goal for this survey is to unveil the prospects of human
motion video generation and serve as a valuable resource for advancing the
comprehensive applications of digital humans. A complete list of the models
examined in this survey is available in Our Repository
https://github.com/Winn1y/Awesome-Human-Motion-Video-Generation.

</details>


### [21] [OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction](https://arxiv.org/abs/2509.03887)
*Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin*

Main category: cs.CV

TL;DR: OccTENS是一种生成占用世界模型，通过TENS任务和TensFormer解决了长期占用生成的效率、质量和可控性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归方法在长期占用生成中存在效率低、时间退化及缺乏可控性的问题，因此需要一种更高效且可控的生成模型。

Method: 提出了一种时间下一尺度预测（TENS）任务，将时间序列建模分解为空间尺度生成和时间场景预测，并引入了TensFormer来管理时间因果关系和空间关系。

Result: 实验表明，OccTENS在占用质量和推理速度上均优于现有方法。

Conclusion: OccTENS通过TENS任务重新定义占用世界模型，结合TensFormer和姿态聚合策略，显著提升了长期占用生成的质量和效率，同时增强了可控性。

Abstract: In this paper, we propose OccTENS, a generative occupancy world model that
enables controllable, high-fidelity long-term occupancy generation while
maintaining computational efficiency. Different from visual generation, the
occupancy world model must capture the fine-grained 3D geometry and dynamic
evolution of the 3D scenes, posing great challenges for the generative models.
Recent approaches based on autoregression (AR) have demonstrated the potential
to predict vehicle movement and future occupancy scenes simultaneously from
historical observations, but they typically suffer from \textbf{inefficiency},
\textbf{temporal degradation} in long-term generation and \textbf{lack of
controllability}. To holistically address these issues, we reformulate the
occupancy world model as a temporal next-scale prediction (TENS) task, which
decomposes the temporal sequence modeling problem into the modeling of spatial
scale-by-scale generation and temporal scene-by-scene prediction. With a
\textbf{TensFormer}, OccTENS can effectively manage the temporal causality and
spatial relationships of occupancy sequences in a flexible and scalable way. To
enhance the pose controllability, we further propose a holistic pose
aggregation strategy, which features a unified sequence modeling for occupancy
and ego-motion. Experiments show that OccTENS outperforms the state-of-the-art
method with both higher occupancy quality and faster inference time.

</details>


### [22] [Weakly-Supervised Learning of Dense Functional Correspondences](https://arxiv.org/abs/2509.03893)
*Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu*

Main category: cs.CV

TL;DR: 论文提出了一种利用视觉语言模型和密集对比学习的弱监督方法，用于在不同类别图像之间建立密集功能对应关系，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在不同类别的图像之间建立密集对应关系对于形状重建和机器人操作等任务至关重要。物体功能可以指导对应关系的建立，因为实现特定功能的部件通常在形状和外观上具有相似性。

Method: 论文提出了一种弱监督学习范式，利用视觉语言模型对多视角图像进行伪标记，获取功能部件，然后与密集对比学习相结合，将功能和空间知识蒸馏到一个新模型中。

Result: 实验结果表明，该方法在合成和真实数据集上优于现有的自监督图像表示和基于视觉语言模型的基线解决方案。

Conclusion: 该论文提出了一种新的弱监督学习范式，通过结合视觉语言模型和密集对比学习，成功地在不同类别图像之间建立了密集的功能对应关系，并在合成和真实数据集上验证了其优越性。

Abstract: Establishing dense correspondences across image pairs is essential for tasks
such as shape reconstruction and robot manipulation. In the challenging setting
of matching across different categories, the function of an object, i.e., the
effect that an object can cause on other objects, can guide how correspondences
should be established. This is because object parts that enable specific
functions often share similarities in shape and appearance. We derive the
definition of dense functional correspondence based on this observation and
propose a weakly-supervised learning paradigm to tackle the prediction task.
The main insight behind our approach is that we can leverage vision-language
models to pseudo-label multi-view images to obtain functional parts. We then
integrate this with dense contrastive learning from pixel correspondences to
distill both functional and spatial knowledge into a new model that can
establish dense functional correspondence. Further, we curate synthetic and
real evaluation datasets as task benchmarks. Our results demonstrate the
advantages of our approach over baseline solutions consisting of off-the-shelf
self-supervised image representations and grounded vision language models.

</details>


### [23] [Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model](https://arxiv.org/abs/2509.03895)
*Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo*

Main category: cs.CV

TL;DR: Attn-Adapter 是一个双注意力机制框架，提升 CLIP 在少样本学习中的性能，无需重训练，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决对比视觉语言模型在少样本场景中因离线微调导致的计算密集和过拟合问题。

Method: 提出了 Attn-Adapter，一个基于双注意力机制的在线少样本学习框架，包括 Memory Attn-Adapter 和 Local-Global Attn-Adapter，分别优化类别嵌入和图像嵌入。

Result: Attn-Adapter 在少样本学习中优于现有方法，保持了高效的推理能力，并能在不同 CLIP 骨干网络上扩展。

Conclusion: Attn-Adapter 通过双注意力机制显著提升了 CLIP 在少样本学习中的适应性，无需重新训练基础模型，同时在跨类别和跨数据集泛化中表现优异。

Abstract: Contrastive vision-language models excel in zero-shot image recognition but
face challenges in few-shot scenarios due to computationally intensive offline
fine-tuning using prompt learning, which risks overfitting. To overcome these
limitations, we propose Attn-Adapter, a novel online few-shot learning
framework that enhances CLIP's adaptability via a dual attention mechanism. Our
design incorporates dataset-specific information through two components: the
Memory Attn-Adapter, which refines category embeddings using support examples,
and the Local-Global Attn-Adapter, which enriches image embeddings by
integrating local and global features. This architecture enables dynamic
adaptation from a few labeled samples without retraining the base model.
Attn-Adapter outperforms state-of-the-art methods in cross-category and
cross-dataset generalization, maintaining efficient inference and scaling
across CLIP backbones.

</details>


### [24] [SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation](https://arxiv.org/abs/2509.03897)
*Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva*

Main category: cs.CV

TL;DR: SPECS是一种高效且相关性高的无参考图像描述评估指标，适用于模型开发中的迭代评估。


<details>
  <summary>Details</summary>
Motivation: 随着对生成详细图像描述的兴趣增加，现有评估指标（如N-gram和RS指标）在语义正确性和计算效率方面存在不足，而基于大语言模型（LLM）的指标虽然相关性高，但计算成本过高。

Method: SPECS通过改进CLIP模型，引入了一个新的目标函数，强调特异性：奖励正确的细节并惩罚错误的细节。

Result: SPECS在相关性上与开源LLM-based指标相当，同时计算效率更高。

Conclusion: SPECS（Specificity-Enhanced CLIPScore）作为一种无参考的Representational Similarity（RS）指标，在长图像描述任务中表现出色，与人类判断相关性高且计算效率高，适合在模型开发中进行迭代评估。

Abstract: As interest grows in generating long, detailed image captions, standard
evaluation metrics become increasingly unreliable. N-gram-based metrics though
efficient, fail to capture semantic correctness. Representational Similarity
(RS) metrics, designed to address this, initially saw limited use due to high
computational costs, while today, despite advances in hardware, they remain
unpopular due to low correlation to human judgments. Meanwhile, metrics based
on large language models (LLMs) show strong correlation with human judgments,
but remain too expensive for iterative use during model development.
  We introduce SPECS (Specificity-Enhanced CLIPScore), a reference-free RS
metric tailored to long image captioning. SPECS modifies CLIP with a new
objective that emphasizes specificity: rewarding correct details and penalizing
incorrect ones. We show that SPECS matches the performance of open-source
LLM-based metrics in correlation to human judgments, while being far more
efficient. This makes it a practical alternative for iterative checkpoint
evaluation during image captioning model development.Our code can be found at
https://github.com/mbzuai-nlp/SPECS.

</details>


### [25] [A Generative Foundation Model for Chest Radiography](https://arxiv.org/abs/2509.03903)
*Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li*

Main category: cs.CV

TL;DR: 开发了`ChexGen'生成模型，用于合成多样化的胸部X光片，提升医疗AI的准确性和公平性。


<details>
  <summary>Details</summary>
Motivation: 缺乏标注良好的多样化医学图像是开发可靠医疗AI模型的主要障碍。

Method: 基于潜在扩散变换器架构，开发了`ChexGen'，这是一个生成视觉语言基础模型，引入了文本、掩码和边界框引导的胸部X光片合成统一框架。

Result: ChexGen通过专家评估和定量指标实现了准确的X光片合成，并展示了在训练数据增强和监督预训练中的实用性，提高了疾病分类、检测和分割任务的性能。

Conclusion: 该研究支持生成基础模型在构建更准确、数据高效和公平的医疗AI系统中的变革性作用。

Abstract: The scarcity of well-annotated diverse medical images is a major hurdle for
developing reliable AI models in healthcare. Substantial technical advances
have been made in generative foundation models for natural images. Here we
develop `ChexGen', a generative vision-language foundation model that
introduces a unified framework for text-, mask-, and bounding box-guided
synthesis of chest radiographs. Built upon the latent diffusion transformer
architecture, ChexGen was pretrained on the largest curated chest X-ray dataset
to date, consisting of 960,000 radiograph-report pairs. ChexGen achieves
accurate synthesis of radiographs through expert evaluations and quantitative
metrics. We demonstrate the utility of ChexGen for training data augmentation
and supervised pretraining, which led to performance improvements across
disease classification, detection, and segmentation tasks using a small
fraction of training data. Further, our model enables the creation of diverse
patient cohorts that enhance model fairness by detecting and mitigating
demographic biases. Our study supports the transformative role of generative
foundation models in building more accurate, data-efficient, and equitable
medical AI systems.

</details>


### [26] [LMVC: An End-to-End Learned Multiview Video Coding Framework](https://arxiv.org/abs/2509.03922)
*Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang*

Main category: cs.CV

TL;DR: 本文提出了一种端到端学习的多视点视频编码框架，通过有效利用独立视点的运动和内容信息提升压缩效率，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 多视点视频是体视频的关键数据源，但其庞大的数据量在存储和传输上带来巨大挑战。现有的深度学习方法主要关注单视点或立体视频，多视点场景的研究不足。

Method: 提出了一种端到端学习的多视点视频编码框架，包括基于特征的视间运动预测方法和无视差的视间上下文预测模块。

Result: 实验结果表明，LMVC框架在压缩效率上显著优于传统的MV-HEVC标准。

Conclusion: 本文提出的LMVC框架在压缩效率上显著优于传统的MV-HEVC标准，为多视点视频编码领域的研究奠定了坚实基础。

Abstract: Multiview video is a key data source for volumetric video, enabling immersive
3D scene reconstruction but posing significant challenges in storage and
transmission due to its massive data volume. Recently, deep learning-based
end-to-end video coding has achieved great success, yet most focus on
single-view or stereo videos, leaving general multiview scenarios
underexplored. This paper proposes an end-to-end learned multiview video coding
(LMVC) framework that ensures random access and backward compatibility while
enhancing compression efficiency. Our key innovation lies in effectively
leveraging independent-view motion and content information to enhance
dependent-view compression. Specifically, to exploit the inter-view motion
correlation, we propose a feature-based inter-view motion vector prediction
method that conditions dependent-view motion encoding on decoded
independent-view motion features, along with an inter-view motion entropy model
that learns inter-view motion priors. To exploit the inter-view content
correlation, we propose a disparity-free inter-view context prediction module
that predicts inter-view contexts from decoded independent-view content
features, combined with an inter-view contextual entropy model that captures
inter-view context priors. Experimental results show that our proposed LMVC
framework outperforms the reference software of the traditional MV-HEVC
standard by a large margin, establishing a strong baseline for future research
in this field.

</details>


### [27] [TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes](https://arxiv.org/abs/2509.03938)
*Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu*

Main category: cs.CV

TL;DR: TopoSculpt是一种新型拓扑细化框架，通过整体建模和拓扑约束，显著提升了3D管状结构的几何和拓扑准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖体素重叠测量，无法捕捉拓扑正确性和完整性，需要一种能保证全局保存和几何误差校正的方法。

Method: TopoSculpt采用整体区域建模策略、拓扑完整性Betti（TIB）约束和课程细化方案，逐步从粗到细纠正错误。

Result: 在肺气道和Willis环数据集上，TopoSculpt显著降低了β0错误，并提高了树长检测和分支检测率近10%。

Conclusion: TopoSculpt在纠正关键拓扑错误和推进复杂3D管状解剖结构的高保真建模方面表现出色。

Abstract: Medical tubular anatomical structures are inherently three-dimensional
conduits with lumens, enclosing walls, and complex branching topologies.
Accurate reconstruction of their geometry and topology is crucial for
applications such as bronchoscopic navigation and cerebral arterial
connectivity assessment. Existing methods often rely on voxel-wise overlap
measures, which fail to capture topological correctness and completeness.
Although topology-aware losses and persistent homology constraints have shown
promise, they are usually applied patch-wise and cannot guarantee global
preservation or correct geometric errors at inference. To address these
limitations, we propose a novel TopoSculpt, a framework for topological
refinement of 3D fine-grained tubular structures. TopoSculpt (i) adopts a
holistic whole-region modeling strategy to capture full spatial context, (ii)
first introduces a Topological Integrity Betti (TIB) constraint that jointly
enforces Betti number priors and global integrity, and (iii) employs a
curriculum refinement scheme with persistent homology to progressively correct
errors from coarse to fine scales. Extensive experiments on challenging
pulmonary airway and Circle of Willis datasets demonstrate substantial
improvements in both geometry and topology. For instance, $\beta_{0}$ errors
are reduced from 69.00 to 3.40 on the airway dataset and from 1.65 to 0.30 on
the CoW dataset, with Tree length detected and branch detected rates improving
by nearly 10\%. These results highlight the effectiveness of TopoSculpt in
correcting critical topological errors and advancing the high-fidelity modeling
of complex 3D tubular anatomy. The project homepage is available at:
https://github.com/Puzzled-Hui/TopoSculpt.

</details>


### [28] [Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture](https://arxiv.org/abs/2509.03950)
*Alvaro Aranibar Roque,Helga Sebastian*

Main category: cs.CV

TL;DR: 提出了一种基于U-Net和EfficientNet-B4的深度学习管道，用于气胸自动分割，结果显示其在独立数据集上表现优异，能够辅助放射科医生。


<details>
  <summary>Details</summary>
Motivation: 气胸若未被及时发现可能危及生命，胸部X射线是首选的诊断工具，但小病例可能难以察觉。

Method: 使用U-Net结合EfficientNet-B4编码器进行气胸区域分割，并在SIIM-ACR数据集上进行训练，采用数据增强和二元交叉熵加Dice损失函数。

Result: 在独立PTX-498数据集上，模型实现了0.7008的IoU和0.8241的Dice分数。

Conclusion: 所提出的自动化深度学习管道能够准确识别气胸区域，为放射科医生提供支持。

Abstract: Pneumothorax, the abnormal accumulation of air in the pleural space, can be
life-threatening if undetected. Chest X-rays are the first-line diagnostic
tool, but small cases may be subtle. We propose an automated deep-learning
pipeline using a U-Net with an EfficientNet-B4 encoder to segment pneumothorax
regions. Trained on the SIIM-ACR dataset with data augmentation and a combined
binary cross-entropy plus Dice loss, the model achieved an IoU of 0.7008 and
Dice score of 0.8241 on the independent PTX-498 dataset. These results
demonstrate that the model can accurately localize pneumothoraces and support
radiologists.

</details>


### [29] [ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD Detection](https://arxiv.org/abs/2509.03951)
*Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出ANTS方法，利用MLLMs生成精确的负标签空间，显著提升OOD检测性能，并在ImageNet上取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法对OOD图像的理解不足，导致负空间构建不准确，且虚假负标签会显著降低近OOD性能。

Method: 利用多模态大语言模型（MLLMs）的理解和推理能力，生成表达性强的负句子来精确描述OOD分布，并通过自适应加权分数平衡远分布和近分布OOD检测。

Result: 在ImageNet基准测试中，ANTS显著降低了FPR95达4.2%，且方法无需训练和零样本，具有高扩展性。

Conclusion: 通过引入自适应负文本空间（ANTS）方法，该论文显著提升了远分布和近分布OOD检测的性能，并在ImageNet基准测试中取得了新的最优结果。

Abstract: The introduction of negative labels (NLs) has proven effective in enhancing
Out-of-Distribution (OOD) detection. However, existing methods often lack an
understanding of OOD images, making it difficult to construct an accurate
negative space. In addition, the presence of false negative labels
significantly degrades their near-OOD performance. To address these issues, we
propose shaping an Adaptive Negative Textual Space (ANTS) by leveraging the
understanding and reasoning capabilities of multimodal large language models
(MLLMs). Specifically, we identify images likely to be OOD samples as negative
images and prompt the MLLM to describe these images, generating expressive
negative sentences that precisely characterize the OOD distribution and enhance
far-OOD detection. For the near-OOD setting, where OOD samples resemble the
in-distribution (ID) subset, we first identify the subset of ID classes that
are visually similar to negative images and then leverage the reasoning
capability of MLLMs to generate visually similar negative labels tailored to
this subset, effectively reducing false negatives and improving near-OOD
detection. To balance these two types of negative textual spaces, we design an
adaptive weighted score that enables the method to handle different OOD task
settings (near-OOD and far-OOD) without relying on task-specific prior
knowledge, making it highly adaptable in open environments. On the ImageNet
benchmark, our ANTS significantly reduces the FPR95 by 4.2\%, establishing a
new state-of-the-art. Furthermore, our method is training-free and zero-shot,
enabling high scalability.

</details>


### [30] [Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection](https://arxiv.org/abs/2509.03961)
*Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: MMChange是一种结合图像和文本的多模态遥感变化检测方法，通过特征细化、语义描述和跨模态融合，提升了检测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖图像模态，限制了特征表示、变化模式建模和泛化能力，尤其是在光照和噪声干扰下。

Method: 提出了MMChange方法，包括图像特征细化（IFR）模块、视觉语言模型（VLM）生成的语义描述、文本差异增强（TDE）模块，以及图像文本特征融合（ITFF）模块。

Result: 在LEVIRCD、WHUCD和SYSUCD数据集上，MMChange在多项指标上均优于现有最先进方法。

Conclusion: MMChange通过结合图像和文本模态，显著提升了遥感变化检测的准确性和鲁棒性，并在多个数据集上验证了其优越性。

Abstract: Although deep learning has advanced remote sensing change detection (RSCD),
most methods rely solely on image modality, limiting feature representation,
change pattern modeling, and generalization especially under illumination and
noise disturbances. To address this, we propose MMChange, a multimodal RSCD
method that combines image and text modalities to enhance accuracy and
robustness. An Image Feature Refinement (IFR) module is introduced to highlight
key regions and suppress environmental noise. To overcome the semantic
limitations of image features, we employ a vision language model (VLM) to
generate semantic descriptions of bitemporal images. A Textual Difference
Enhancement (TDE) module then captures fine grained semantic shifts, guiding
the model toward meaningful changes. To bridge the heterogeneity between
modalities, we design an Image Text Feature Fusion (ITFF) module that enables
deep cross modal integration. Extensive experiments on LEVIRCD, WHUCD, and
SYSUCD demonstrate that MMChange consistently surpasses state of the art
methods across multiple metrics, validating its effectiveness for multimodal
RSCD. Code is available at: https://github.com/yikuizhai/MMChange.

</details>


### [31] [SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification](https://arxiv.org/abs/2509.03973)
*Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang*

Main category: cs.CV

TL;DR: SAC-MIL通过位置编码和MLP-based SAC块高效处理WSI分类，无需复杂部署，性能优越。


<details>
  <summary>Details</summary>
Motivation: 为了解决WSI分类中空间关系编码和实例相关性计算的问题，同时避免Transformer方法的复杂部署需求。

Method: SAC-MIL包含一个位置编码模块和一个SAC块。位置编码模块利用实例坐标编码空间关系，解决了训练和测试序列长度不同的问题。SAC块是一个基于MLP的方法，以线性时间复杂度进行全实例相关性计算。

Result: SAC-MIL在多个数据集上实现了最先进的性能。

Conclusion: SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上实现了最先进的性能，代码将在论文接受后发布。

Abstract: We propose Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) for
performing WSI classification. SAC-MIL consists of a positional encoding module
to encode position information and a SAC block to perform full instance
correlations. The positional encoding module utilizes the instance coordinates
within the slide to encode the spatial relationships instead of the instance
index in the input WSI sequence. The positional encoding module can also handle
the length extrapolation issue where the training and testing sequences have
different lengths. The SAC block is an MLP-based method that performs full
instance correlation in linear time complexity with respect to the sequence
length. Due to the simple structure of MLP, it is easy to deploy since it does
not require custom CUDA kernels, compared to Transformer-based methods for WSI
classification. SAC-MIL has achieved state-of-the-art performance on the
CAMELYON-16, TCGA-LUNG, and TCGA-BRAC datasets. The code will be released upon
acceptance.

</details>


### [32] [Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training](https://arxiv.org/abs/2509.03975)
*Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs*

Main category: cs.CV

TL;DR: 多任务学习框架利用辅助对比增强MRI数据提升无对比增强MRI中的血管分割准确性，尤其在标注数据有限时效果显著，且方法具有跨领域通用性。


<details>
  <summary>Details</summary>
Motivation: 无对比增强的MRI数据更常见，但血管分割具有挑战性且需要大规模标注数据。现有方法依赖对比增强成像数据，但其采集并不统一。

Method: 提出了一种多任务学习框架，利用训练阶段可用的辅助对比增强MRI数据（无论是否有血管标注）来减少对标注训练样本的需求。

Result: 结果显示，辅助数据提高了血管分割的准确性，尤其是在标注数据有限时。该方法在脑肿瘤分割中的验证也证实了其跨领域优势。

Conclusion: 辅助对比增强MRI数据在训练阶段的使用可以有效提升无对比增强MRI数据中血管分割的准确性，尤其是在标注数据有限的情况下。该方法在不同领域（如脑肿瘤分割）中也显示出通用性。

Abstract: Liver vessel segmentation in magnetic resonance imaging data is important for
the computational analysis of vascular remodelling, associated with a wide
spectrum of diffuse liver diseases. Existing approaches rely on contrast
enhanced imaging data, but the necessary dedicated imaging sequences are not
uniformly acquired. Images without contrast enhancement are acquired more
frequently, but vessel segmentation is challenging, and requires large-scale
annotated data. We propose a multi-task learning framework to segment vessels
in liver MRI without contrast. It exploits auxiliary contrast enhanced MRI data
available only during training to reduce the need for annotated training
examples. Our approach draws on paired native and contrast enhanced data with
and without vessel annotations for model training. Results show that auxiliary
data improves the accuracy of vessel segmentation, even if they are not
available during inference. The advantage is most pronounced if only few
annotations are available for training, since the feature representation
benefits from the shared task structure. A validation of this approach to
augment a model for brain tumor segmentation confirms its benefits across
different domains. An auxiliary informative imaging modality can augment expert
annotations even if it is only available during training.

</details>


### [33] [Promptception: How Sensitive Are Large Multimodal Models to Prompts?](https://arxiv.org/abs/2509.03986)
*Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan*

Main category: cs.CV

TL;DR: 研究揭示了LMMs在MCQA中提示设计的敏感性，提出了Promptception框架评估提示敏感性，并针对专有和开源模型提出了提示原则。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型（LMMs）在多项选择问答（MCQA）中的提示设计仍未被充分理解，提示措辞和结构的微小变化可能导致准确性偏差高达15%。

Method: 引入Promptception，一个系统性框架，包含61种提示类型，覆盖15个类别和6个超类别，用于评估10种LMM在3个MCQA基准上的表现。

Result: 专有模型对提示措辞更敏感，反映其对指令语义的紧密对齐，而开源模型表现更稳定但在复杂措辞上表现不佳。

Conclusion: 基于分析结果，提出了针对专有和开源LMM的提示原则，以实现更稳健和公平的模型评估。

Abstract: Despite the success of Large Multimodal Models (LMMs) in recent years, prompt
design for LMMs in Multiple-Choice Question Answering (MCQA) remains poorly
understood. We show that even minor variations in prompt phrasing and structure
can lead to accuracy deviations of up to 15% for certain prompts and models.
This variability poses a challenge for transparent and fair LMM evaluation, as
models often report their best-case performance using carefully selected
prompts. To address this, we introduce Promptception, a systematic framework
for evaluating prompt sensitivity in LMMs. It consists of 61 prompt types,
spanning 15 categories and 6 supercategories, each targeting specific aspects
of prompt formulation, and is used to evaluate 10 LMMs ranging from lightweight
open-source models to GPT-4o and Gemini 1.5 Pro, across 3 MCQA benchmarks:
MMStar, MMMU-Pro, MVBench. Our findings reveal that proprietary models exhibit
greater sensitivity to prompt phrasing, reflecting tighter alignment with
instruction semantics, while open-source models are steadier but struggle with
nuanced and complex phrasing. Based on this analysis, we propose Prompting
Principles tailored to proprietary and open-source LMMs, enabling more robust
and fair model evaluation.

</details>


### [34] [SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy Representation](https://arxiv.org/abs/2509.03999)
*Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen*

Main category: cs.CV

TL;DR: 提出SliceSemOcc框架，通过全局局部融合和动态高度注意力提升3D语义占据预测性能，实验验证其在小型物体上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理体素特征时忽视了高度轴信息，且传统的通道注意力对所有高度层赋予相同权重，限制了不同高度特征的区分能力。

Method: 提取沿高度轴的体素特征，使用全局和局部垂直切片，并通过全局局部融合模块和SEAttention3D模块动态分配通道注意力权重。

Result: 在nuScenes-SurroundOcc和nuScenes-OpenOccupancy数据集上的实验表明，该方法显著提升了平均IoU，尤其在小型物体类别上效果显著。

Conclusion: 提出的SliceSemOcc框架通过全局局部融合模块和SEAttention3D模块，显著提升了3D语义占据预测的性能，尤其在小型物体类别上表现突出。

Abstract: Driven by autonomous driving's demands for precise 3D perception, 3D semantic
occupancy prediction has become a pivotal research topic. Unlike
bird's-eye-view (BEV) methods, which restrict scene representation to a 2D
plane, occupancy prediction leverages a complete 3D voxel grid to model spatial
structures in all dimensions, thereby capturing semantic variations along the
vertical axis. However, most existing approaches overlook height-axis
information when processing voxel features. And conventional SENet-style
channel attention assigns uniform weight across all height layers, limiting
their ability to emphasize features at different heights. To address these
limitations, we propose SliceSemOcc, a novel vertical slice based multimodal
framework for 3D semantic occupancy representation. Specifically, we extract
voxel features along the height-axis using both global and local vertical
slices. Then, a global local fusion module adaptively reconciles fine-grained
spatial details with holistic contextual information. Furthermore, we propose
the SEAttention3D module, which preserves height-wise resolution through
average pooling and assigns dynamic channel attention weights to each height
layer. Extensive experiments on nuScenes-SurroundOcc and nuScenes-OpenOccupancy
datasets verify that our method significantly enhances mean IoU, achieving
especially pronounced gains on most small-object categories. Detailed ablation
studies further validate the effectiveness of the proposed SliceSemOcc
framework.

</details>


### [35] [Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding](https://arxiv.org/abs/2509.04009)
*Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak*

Main category: cs.CV

TL;DR: 该论文提出了一种检测视觉变换器中虚假相关性的方法，发现训练方法和数据集类别对模型依赖虚假信号有显著影响，并呼吁对相关问题保持警惕。


<details>
  <summary>Details</summary>
Motivation: 由于神经网络在计算机视觉任务中可能依赖虚假信号进行预测，导致模型不可靠，因此需要检测和缓解这种虚假相关性。

Method: 提出了一种新颖的方法来检测视觉变换器中的虚假相关性，并在ImageNet数据集上进行了大规模实验，使用了监督和自监督训练的模型。

Result: 研究发现，即使使用相同的架构，训练方法对模型依赖虚假相关性的程度有显著影响。此外，某些ImageNet类别中的虚假信号容易被模型检测到。

Conclusion: 该研究强调了检测和缓解虚假相关性在构建可信赖、可靠且可推广的机器学习模型中的重要性，并提出了针对视觉变换器的检测方法。同时，研究呼吁对ImageNet数据集中包含虚假信号的图像谨慎使用。

Abstract: Due to their powerful feature association capabilities, neural network-based
computer vision models have the ability to detect and exploit unintended
patterns within the data, potentially leading to correct predictions based on
incorrect or unintended but statistically relevant signals. These clues may
vary from simple color aberrations to small texts within the image. In
situations where these unintended signals align with the predictive task,
models can mistakenly link these features with the task and rely on them for
making predictions. This phenomenon is referred to as spurious correlations,
where patterns appear to be associated with the task but are actually
coincidental. As a result, detection and mitigation of spurious correlations
have become crucial tasks for building trustworthy, reliable, and generalizable
machine learning models. In this work, we present a novel method to detect
spurious correlations in vision transformers, a type of neural network
architecture that gained significant popularity in recent years. Using both
supervised and self-supervised trained models, we present large-scale
experiments on the ImageNet dataset demonstrating the ability of the proposed
method to identify spurious correlations. We also find that, even if the same
architecture is used, the training methodology has a significant impact on the
model's reliance on spurious correlations. Furthermore, we show that certain
classes in the ImageNet dataset contain spurious signals that are easily
detected by the models and discuss the underlying reasons for those spurious
signals. In light of our findings, we provide an exhaustive list of the
aforementioned images and call for caution in their use in future research
efforts. Lastly, we present a case study investigating spurious signals in
invasive breast mass classification, grounding our work in real-world
scenarios.

</details>


### [36] [Learning from Majority Label: A Novel Problem in Multi-class Multiple-Instance Learning](https://arxiv.org/abs/2509.04023)
*Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise*

Main category: cs.CV

TL;DR: 论文提出了一种新的多类多实例学习问题LML，通过Counting Network和MPEM模块解决，实验证明优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决多类多实例学习中的多数标签学习问题，适用于病理图像分割、政治投票预测等多个应用场景。

Method: 提出了Counting Network来生成袋级多数标签，并通过MPEM模块增加多数类实例比例。

Result: 在四个数据集上验证了方法的优越性，且MPEM模块能有效提升学习效果。

Conclusion: 论文提出的LML问题和Counting Network及MPEM模块在多个数据集上优于传统MIL方法，且通过消融研究验证了各模块的有效性。

Abstract: The paper proposes a novel multi-class Multiple-Instance Learning (MIL)
problem called Learning from Majority Label (LML). In LML, the majority class
of instances in a bag is assigned as the bag-level label. The goal of LML is to
train a classification model that estimates the class of each instance using
the majority label. This problem is valuable in a variety of applications,
including pathology image segmentation, political voting prediction, customer
sentiment analysis, and environmental monitoring. To solve LML, we propose a
Counting Network trained to produce bag-level majority labels, estimated by
counting the number of instances in each class. Furthermore, analysis
experiments on the characteristics of LML revealed that bags with a high
proportion of the majority class facilitate learning. Based on this result, we
developed a Majority Proportion Enhancement Module (MPEM) that increases the
proportion of the majority class by removing minority class instances within
the bags. Experiments demonstrate the superiority of the proposed method on
four datasets compared to conventional MIL methods. Moreover, ablation studies
confirmed the effectiveness of each module. The code is available at
\href{https://github.com/Shiku-Kaito/Learning-from-Majority-Label-A-Novel-Problem-in-Multi-class-Multiple-Instance-Learning}{here}.

</details>


### [37] [Millisecond-Response Tracking and Gazing System for UAVs: A Domestic Solution Based on "Phytium + Cambricon"](https://arxiv.org/abs/2509.04043)
*Yuchen Zhu,Longxiang Yin,Kai Zhao*

Main category: cs.CV

TL;DR: 本研究通过异构计算架构和轻量化算法，实现了无人机跟踪系统的毫秒级响应和高精度目标识别，解决了传统系统的延迟问题。


<details>
  <summary>Details</summary>
Motivation: 传统摄像机系统在动态场景中因自动识别算法的深度特征提取能力不足及计算架构效率瓶颈，响应延迟超过200毫秒，无法满足复杂场景的实时需求。

Method: 在硬件层面采用飞腾FT-2000/4处理器与MLU220加速卡协同计算架构，通过多卡并行提升算力；在软件层面创新性地集成了轻量化YOLOv5s检测网络与DeepSORT级联跟踪算法，形成“检测-跟踪-反馈”闭环控制链。

Result: 实验结果表明，系统在1920*1080分辨率视频流处理中实现了50-100毫秒的稳定单帧综合处理延迟，多尺度目标识别准确率超过98.5%，兼具低延迟与高精度。

Conclusion: 本研究提出了一种基于飞腾处理器和寒武纪加速卡的异构计算架构，构建了具有毫秒级响应能力的无人机跟踪与凝视系统，为无人机监控和国产芯片应用提供了创新解决方案。

Abstract: In the frontier research and application of current video surveillance
technology, traditional camera systems exhibit significant limitations of
response delay exceeding 200 ms in dynamic scenarios due to the insufficient
deep feature extraction capability of automatic recognition algorithms and the
efficiency bottleneck of computing architectures, failing to meet the real-time
requirements in complex scenes. To address this issue, this study proposes a
heterogeneous computing architecture based on Phytium processors and Cambricon
accelerator cards, constructing a UAV tracking and gazing system with
millisecond-level response capability. At the hardware level, the system adopts
a collaborative computing architecture of Phytium FT-2000/4 processors and
MLU220 accelerator cards, enhancing computing power through multi-card
parallelism. At the software level, it innovatively integrates a lightweight
YOLOv5s detection network with a DeepSORT cascaded tracking algorithm, forming
a closed-loop control chain of "detection-tracking-feedback". Experimental
results demonstrate that the system achieves a stable single-frame
comprehensive processing delay of 50-100 ms in 1920*1080 resolution video
stream processing, with a multi-scale target recognition accuracy of over
98.5%, featuring both low latency and high precision. This study provides an
innovative solution for UAV monitoring and the application of domestic chips.

</details>


### [38] [A Re-ranking Method using K-nearest Weighted Fusion for Person Re-identification](https://arxiv.org/abs/2509.04050)
*Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen*

Main category: cs.CV

TL;DR: 该论文提出了一种基于多视角特征的无监督重排序方法（KWF），通过聚合邻居特征减少视角偏差，显著提升了行人重识别的准确性，且计算高效。


<details>
  <summary>Details</summary>
Motivation: 在行人重识别中，单视角图像特征容易引入视角偏差，导致姿态变化、视角变化和遮挡等问题。利用多视角特征可以减少这种偏差。

Method: 提出了一种高效的重排序方法，通过K-nearest Weighted Fusion（KWF）聚合邻居特征生成多视角特征，无需模型微调或额外标注。

Result: 在Market1501、MSMT17和Occluded-DukeMTMC数据集上，该方法显著提升了Rank@1和mAP指标。具体而言，在MSMT17和Occluded-DukeMTMC数据集上，Rank@1分别提升了9.8%和22.0%。

Conclusion: 该论文提出的基于多视角特征的无监督重排序方法（KWF）在多个数据集上显著提升了Rank@1和mAP指标，尤其在MSMT17和Occluded-DukeMTMC数据集上表现突出。此外，该方法计算效率高，适用于大规模数据集。

Abstract: In person re-identification, re-ranking is a crucial step to enhance the
overall accuracy by refining the initial ranking of retrieved results. Previous
studies have mainly focused on features from single-view images, which can
cause view bias and issues like pose variation, viewpoint changes, and
occlusions. Using multi-view features to present a person can help reduce view
bias. In this work, we present an efficient re-ranking method that generates
multi-view features by aggregating neighbors' features using K-nearest Weighted
Fusion (KWF) method. Specifically, we hypothesize that features extracted from
re-identification models are highly similar when representing the same
identity. Thus, we select K neighboring features in an unsupervised manner to
generate multi-view features. Additionally, this study explores the weight
selection strategies during feature aggregation, allowing us to identify an
effective strategy. Our re-ranking approach does not require model fine-tuning
or extra annotations, making it applicable to large-scale datasets. We evaluate
our method on the person re-identification datasets Market1501, MSMT17, and
Occluded-DukeMTMC. The results show that our method significantly improves
Rank@1 and mAP when re-ranking the top M candidates from the initial ranking
results. Specifically, compared to the initial results, our re-ranking method
achieves improvements of 9.8%/22.0% in Rank@1 on the challenging datasets:
MSMT17 and Occluded-DukeMTMC, respectively. Furthermore, our approach
demonstrates substantial enhancements in computational efficiency compared to
other re-ranking methods.

</details>


### [39] [TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph](https://arxiv.org/abs/2509.04086)
*Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang*

Main category: cs.CV

TL;DR: 提出结合BiT和CATS模块的方法，解决AVVP任务中现有方法的噪声伪标签和无差别注意力问题，实验结果显示在多个指标上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在将噪声段级伪标签视为可靠监督或让无差别注意力将伪标签扩散到所有帧的问题，导致初始错误在训练过程中被反复放大。

Method: 提出了结合Bi-Directional Text Fusion (BiT)模块和Category-Aware Temporal Graph (CATS)模块的方法，通过语义注入和动态校准音频与视觉模态特征，以及语义传播和连接，实现精确的语义信息传播。

Result: 在两个基准数据集LLP和UnAV-100上，提出的方法在多个关键指标上实现了最先进的性能。

Conclusion: 通过结合BiT模块和CATS模块，提出的方法在AVVP任务中实现了最先进的性能，显著提升了多个关键指标的表现。

Abstract: Audio-Visual Video Parsing (AVVP) task aims to identify event categories and
their occurrence times in a given video with weakly supervised labels. Existing
methods typically fall into two categories: (i) designing enhanced
architectures based on attention mechanism for better temporal modeling, and
(ii) generating richer pseudo-labels to compensate for the absence of
frame-level annotations. However, the first type methods treat noisy
segment-level pseudo labels as reliable supervision and the second type methods
let indiscriminate attention spread them across all frames, the initial errors
are repeatedly amplified during training. To address this issue, we propose a
method that combines the Bi-Directional Text Fusion (BiT) module and
Category-Aware Temporal Graph (CATS) module. Specifically, we integrate the
strengths and complementarity of the two previous research directions. We first
perform semantic injection and dynamic calibration on audio and visual modality
features through the BiT module, to locate and purify cleaner and richer
semantic cues. Then, we leverage the CATS module for semantic propagation and
connection to enable precise semantic information dissemination across time.
Experimental results demonstrate that our proposed method achieves
state-of-the-art (SOTA) performance in multiple key indicators on two benchmark
datasets, LLP and UnAV-100.

</details>


### [40] [TriLiteNet: Lightweight Model for Multi-Task Visual Perception](https://arxiv.org/abs/2509.04092)
*Quang-Huy Che,Duc-Khai Lam*

Main category: cs.CV

TL;DR: TriLiteNet是一个高效的多任务感知模型，适用于自动驾驶系统，能够在保持低计算成本的同时实现竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 高效的感知模型对于高级驾驶辅助系统（ADAS）至关重要，因为这些应用需要快速处理和响应以确保在现实环境中的安全性和有效性。

Method: 本研究引入了TriLiteNet模型，该模型能够同时处理与全景驾驶感知相关的多个任务，旨在优化性能的同时保持低计算成本。

Result: 在BDD100k数据集上的实验结果表明，TriLiteNet在车辆检测、可行驶区域分割和车道线分割三个关键任务上实现了竞争性性能。具体而言，TriLiteNet_{base}在车辆检测上实现了85.6%的召回率，可行驶区域分割的平均交并比（mIoU）为92.4%，车道线分割的准确率为82.3%，仅需2.35M参数和7.72 GFLOPs的计算成本。

Conclusion: TriLiteNet通过平衡性能、计算效率和可扩展性，为现实世界的自动驾驶应用提供了一个实用且可部署的解决方案。

Abstract: Efficient perception models are essential for Advanced Driver Assistance
Systems (ADAS), as these applications require rapid processing and response to
ensure safety and effectiveness in real-world environments. To address the
real-time execution needs of such perception models, this study introduces the
TriLiteNet model. This model can simultaneously manage multiple tasks related
to panoramic driving perception. TriLiteNet is designed to optimize performance
while maintaining low computational costs. Experimental results on the BDD100k
dataset demonstrate that the model achieves competitive performance across
three key tasks: vehicle detection, drivable area segmentation, and lane line
segmentation. Specifically, the TriLiteNet_{base} demonstrated a recall of
85.6% for vehicle detection, a mean Intersection over Union (mIoU) of 92.4% for
drivable area segmentation, and an Acc of 82.3% for lane line segmentation with
only 2.35M parameters and a computational cost of 7.72 GFLOPs. Our proposed
model includes a tiny configuration with just 0.14M parameters, which provides
a multi-task solution with minimal computational demand. Evaluated for latency
and power consumption on embedded devices, TriLiteNet in both configurations
shows low latency and reasonable power during inference. By balancing
performance, computational efficiency, and scalability, TriLiteNet offers a
practical and deployable solution for real-world autonomous driving
applications. Code is available at https://github.com/chequanghuy/TriLiteNet.

</details>


### [41] [DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset](https://arxiv.org/abs/2509.04117)
*Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz*

Main category: cs.CV

TL;DR: DVS-PedX是一个神经形态数据集，用于行人检测和穿越意图分析，包含合成和真实事件流，支持多模态研究。


<details>
  <summary>Details</summary>
Motivation: 事件相机（如DVS）提供低延迟、高动态范围和运动鲁棒性，但缺乏适用于行人检测和穿越意图分析的数据集。DVS-PedX旨在填补这一空白，支持在正常和恶劣天气条件下的研究。

Method: DVS-PedX数据集包含合成事件流和真实世界JAAD行车记录仪视频转换的事件流，提供配对的RGB帧、每帧DVS“事件帧”和帧级标签。还提供原始AEDAT 2.0/AEDAT 4.0事件文件和AVI DVS视频文件及元数据。使用SpikingJelly的基线脉冲神经网络（SNNs）展示了数据集的可用性。

Result: 基线SNNs展示了数据集的可用性，并揭示了模拟到现实的差距，推动了领域适应和多模态融合的研究。

Conclusion: DVS-PedX旨在加速基于事件的行人安全、意图预测和神经形态感知的研究。

Abstract: Event cameras like Dynamic Vision Sensors (DVS) report micro-timed brightness
changes instead of full frames, offering low latency, high dynamic range, and
motion robustness. DVS-PedX (Dynamic Vision Sensor Pedestrian eXploration) is a
neuromorphic dataset designed for pedestrian detection and crossing-intention
analysis in normal and adverse weather conditions across two complementary
sources: (1) synthetic event streams generated in the CARLA simulator for
controlled "approach-cross" scenes under varied weather and lighting; and (2)
real-world JAAD dash-cam videos converted to event streams using the v2e tool,
preserving natural behaviors and backgrounds. Each sequence includes paired RGB
frames, per-frame DVS "event frames" (33 ms accumulations), and frame-level
labels (crossing vs. not crossing). We also provide raw AEDAT 2.0/AEDAT 4.0
event files and AVI DVS video files and metadata for flexible re-processing.
Baseline spiking neural networks (SNNs) using SpikingJelly illustrate dataset
usability and reveal a sim-to-real gap, motivating domain adaptation and
multimodal fusion. DVS-PedX aims to accelerate research in event-based
pedestrian safety, intention prediction, and neuromorphic perception.

</details>


### [42] [TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering](https://arxiv.org/abs/2509.04123)
*Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta*

Main category: cs.CV

TL;DR: TaleDiffusion通过迭代过程和后处理技术解决了多角色故事可视化中的一致性和对话渲染问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在角色一致性和对话渲染方面存在不足，导致故事叙述不连贯。

Method: 使用预训练LLM生成每帧描述、角色细节和对话，结合基于有界注意力的每框掩码技术控制角色交互，采用身份一致的自注意力机制确保跨帧角色一致性，以及区域感知的交叉注意力实现精确对象放置。

Result: 实验结果表明，TaleDiffusion在一致性、降噪和对话渲染方面表现优异。

Conclusion: TaleDiffusion框架在角色一致性、降噪和对话渲染方面优于现有方法。

Abstract: Text-to-story visualization is challenging due to the need for consistent
interaction among multiple characters across frames. Existing methods struggle
with character consistency, leading to artifact generation and inaccurate
dialogue rendering, which results in disjointed storytelling. In response, we
introduce TaleDiffusion, a novel framework for generating multi-character
stories with an iterative process, maintaining character consistency, and
accurate dialogue assignment via postprocessing. Given a story, we use a
pre-trained LLM to generate per-frame descriptions, character details, and
dialogues via in-context learning, followed by a bounded attention-based
per-box mask technique to control character interactions and minimize
artifacts. We then apply an identity-consistent self-attention mechanism to
ensure character consistency across frames and region-aware cross-attention for
precise object placement. Dialogues are also rendered as bubbles and assigned
to characters via CLIPSeg. Experimental results demonstrate that TaleDiffusion
outperforms existing methods in consistency, noise reduction, and dialogue
rendering.

</details>


### [43] [MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation](https://arxiv.org/abs/2509.04126)
*Yuan Zhao,Liu Lin*

Main category: cs.CV

TL;DR: MEPG框架通过LLM和专家模块的协同工作，提升了文本到图像生成的复杂性和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到图像扩散模型在处理复杂多元素提示和风格多样性方面的局限性。

Method: MEPG框架包含PSA模块（利用微调LLM分解输入提示为空间坐标和风格指令）和MED模块（通过动态专家路由实现跨区域生成）。

Result: 实验表明，MEPG在图像质量和风格多样性上显著优于基线模型。

Conclusion: MEPG框架通过整合位置和风格感知的LLM与空间语义专家模块，显著提升了文本到图像生成的质量和风格多样性。

Abstract: Text-to-image diffusion models have achieved remarkable image quality, but
they still struggle with complex, multiele ment prompts, and limited stylistic
diversity. To address these limitations, we propose a Multi-Expert Planning and
Gen eration Framework (MEPG) that synergistically integrates position- and
style-aware large language models (LLMs) with spatial-semantic expert modules.
The framework comprises two core components: (1) a Position-Style-Aware (PSA)
module that utilizes a supervised fine-tuned LLM to decom pose input prompts
into precise spatial coordinates and style encoded semantic instructions; and
(2) a Multi-Expert Dif fusion (MED) module that implements cross-region genera
tion through dynamic expert routing across both local regions and global areas.
During the generation process for each lo cal region, specialized models (e.g.,
realism experts, styliza tion specialists) are selectively activated for each
spatial par tition via attention-based gating mechanisms. The architec ture
supports lightweight integration and replacement of ex pert models, providing
strong extensibility. Additionally, an interactive interface enables real-time
spatial layout editing and per-region style selection from a portfolio of
experts. Ex periments show that MEPG significantly outperforms base line models
with the same backbone in both image quality
  and style diversity.

</details>


### [44] [Revisiting Simple Baselines for In-The-Wild Deepfake Detection](https://arxiv.org/abs/2509.04150)
*Orlando Castaneda,Kevin So-Tang,Kshitij Gurung*

Main category: cs.CV

TL;DR: 通过超参数优化，预训练视觉骨干网络方法在Deepfake-Eval-2024上达到81%准确率，接近商业检测器性能，并讨论了实际部署的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测器在高度受控数据集上表现良好，但在实际场景中表现不佳，因此需要更通用的检测方法和更现实的基准测试。

Method: 使用预训练的视觉骨干网络，并通过优化超参数来提升性能。

Result: 优化后的方法在Deepfake-Eval-2024上达到81%的准确率，比之前报告的基线方法提升18%。

Conclusion: 通过优化超参数，简单的预训练视觉骨干网络方法在Deepfake-Eval-2024基准测试中达到了81%的准确率，与商业深度伪造检测器竞争，并讨论了在实际部署中的权衡。

Abstract: The widespread adoption of synthetic media demands accessible deepfake
detectors and realistic benchmarks. While most existing research evaluates
deepfake detectors on highly controlled datasets, we focus on the recently
released "in-the-wild" benchmark, Deepfake-Eval-2024. Initial reporting on
Deepfake-Eval-2024 showed that three finetuned open-source models achieve
accuracies between 61% and 69%, significantly lagging behind the leading
commercial deepfake detector with 82% accuracy. Our work revisits one of these
baseline approaches, originally introduced by Ojha et al., which adapts
standard pretrained vision backbones to produce generalizable deepfake
detectors. We demonstrate that with better-tuned hyperparameters, this simple
approach actually yields much higher performance -- 81% accuracy on
Deepfake-Eval-2024 -- surpassing the previously reported accuracy of this
baseline approach by 18% and competing with commercial deepfake detectors. We
discuss tradeoffs in accuracy, computational costs, and interpretability,
focusing on how practical these deepfake detectors might be when deployed in
real-world settings. Our code can be found at
https://github.com/Deepfake-Detection-KKO/deepfake-detection.

</details>


### [45] [VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision](https://arxiv.org/abs/2509.04180)
*Safouane El Ghazouali,Umberto Michelucci*

Main category: cs.CV

TL;DR: VisioFirm是一个开源的AI辅助图像标注工具，通过集成先进模型和交互工具，显著减少手动工作量并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 传统图像标注工具需要大量手动输入，难以扩展到大尺寸数据集。VisioFirm旨在通过AI辅助自动化解决这一问题，提高标注效率和可扩展性。

Method: VisioFirm集成了先进的预训练模型（如CLIP、Ultralytics模型和Grounding DINO），通过低置信度阈值和过滤管道生成初始标注，并支持用户通过交互工具进行细化。

Result: VisioFirm在COCO类别的测试中证明，初始预测大多正确，并且通过交互工具可以进一步优化。该工具在多样数据集上实现了高达90%的手动工作量减少。

Conclusion: VisioFirm通过AI辅助自动化和用户交互工具的结合，显著减少了图像标注所需的手动工作量，同时保持了高标注准确性。

Abstract: AI models rely on annotated data to learn pattern and perform prediction.
Annotation is usually a labor-intensive step that require associating labels
ranging from a simple classification label to more complex tasks such as object
detection, oriented bounding box estimation, and instance segmentation.
Traditional tools often require extensive manual input, limiting scalability
for large datasets. To address this, we introduce VisioFirm, an open-source web
application designed to streamline image labeling through AI-assisted
automation. VisioFirm integrates state-of-the-art foundation models into an
interface with a filtering pipeline to reduce human-in-the-loop efforts. This
hybrid approach employs CLIP combined with pre-trained detectors like
Ultralytics models for common classes and zero-shot models such as Grounding
DINO for custom labels, generating initial annotations with low-confidence
thresholding to maximize recall. Through this framework, when tested on
COCO-type of classes, initial prediction have been proven to be mostly correct
though the users can refine these via interactive tools supporting bounding
boxes, oriented bounding boxes, and polygons. Additionally, VisioFirm has
on-the-fly segmentation powered by Segment Anything accelerated through WebGPU
for browser-side efficiency. The tool supports multiple export formats (YOLO,
COCO, Pascal VOC, CSV) and operates offline after model caching, enhancing
accessibility. VisioFirm demonstrates up to 90\% reduction in manual effort
through benchmarks on diverse datasets, while maintaining high annotation
accuracy via clustering of connected CLIP-based disambiguate components and
IoU-graph for redundant detection suppression. VisioFirm can be accessed from
\href{https://github.com/OschAI/VisioFirm}{https://github.com/OschAI/VisioFirm}.

</details>


### [46] [DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval](https://arxiv.org/abs/2509.04193)
*Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng*

Main category: cs.CV

TL;DR: DUDE是一种基于特征解耦的无监督跨域图像检索方法，通过解耦对象特征和域特定风格并渐进式对齐，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有UCIR方法因对象特征与域特定风格纠缠而难以克服域差距，DUDE旨在通过特征解耦解决这一问题。

Method: DUDE利用文本到图像生成模型解耦对象特征和域特定风格，并通过渐进式对齐方法实现可靠的特征对齐。

Result: DUDE在三个基准数据集上的13个域中均取得了最先进的性能。

Conclusion: DUDE通过特征解耦和渐进式对齐方法，在无监督跨域图像检索任务中取得了最先进的性能。

Abstract: Unsupervised cross-domain image retrieval (UCIR) aims to retrieve images of
the same category across diverse domains without relying on annotations.
Existing UCIR methods, which align cross-domain features for the entire image,
often struggle with the domain gap, as the object features critical for
retrieval are frequently entangled with domain-specific styles. To address this
challenge, we propose DUDE, a novel UCIR method building upon feature
disentanglement. In brief, DUDE leverages a text-to-image generative model to
disentangle object features from domain-specific styles, thus facilitating
semantical image retrieval. To further achieve reliable alignment of the
disentangled object features, DUDE aligns mutual neighbors from within domains
to across domains in a progressive manner. Extensive experiments demonstrate
that DUDE achieves state-of-the-art performance across three benchmark datasets
over 13 domains. The code will be released.

</details>


### [47] [Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding](https://arxiv.org/abs/2509.04243)
*Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li*

Main category: cs.CV

TL;DR: LASER是一个自进化框架，通过多步感知和精确坐标预测提升视觉语言模型性能，在复杂GUI任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在GUI基础任务中有效推理适当图像区域的核心挑战，特别是在高分辨率输入和复杂多元素视觉交互下。

Method: 结合蒙特卡洛质量估计和基于IoU的区域质量评估，构建高质量偏好数据，引导模型聚焦指令相关关键区域，并自适应分配推理步骤。

Result: 在ScreenSpot Pro和ScreenSpot-v2基准测试中表现一致提升，GTA1-7B微调后在ScreenSpot-Pro上达到55.7分，创7B规模模型新SOTA。

Conclusion: LASER框架通过自进化机制和多步感知能力，显著提升了视觉语言模型在GUI基础任务中的性能，特别是在高分辨率输入和复杂视觉交互场景下，建立了7B规模模型的新SOTA。

Abstract: Vision Language Models (VLMs) have recently achieved significant progress in
bridging visual perception and linguistic reasoning. Recently, OpenAI o3 model
introduced a zoom-in search strategy that effectively elicits active perception
capabilities in VLMs, improving downstream task performance. However, enabling
VLMs to reason effectively over appropriate image regions remains a core
challenge in GUI grounding, particularly under high-resolution inputs and
complex multi-element visual interactions. In this work, we propose LASER, a
self-evolving framework that progressively endows VLMs with multi-step
perception capabilities, enabling precise coordinate prediction. Specifically,
our approach integrate Monte Carlo quality estimation with
Intersection-over-Union (IoU)-based region quality evaluation to jointly
encourage both accuracy and diversity in constructing high-quality preference
data. This combination explicitly guides the model to focus on
instruction-relevant key regions while adaptively allocating reasoning steps
based on task complexity. Comprehensive experiments on the ScreenSpot Pro and
ScreenSpot-v2 benchmarks demonstrate consistent performance gains, validating
the effectiveness of our method. Furthermore, when fine-tuned on GTA1-7B, LASER
achieves a score of 55.7 on the ScreenSpot-Pro benchmark, establishing a new
state-of-the-art (SoTA) among 7B-scale models.

</details>


### [48] [Differential Morphological Profile Neural Networks for Semantic Segmentation](https://arxiv.org/abs/2509.04268)
*David Huangal,J. Alex Hurt*

Main category: cs.CV

TL;DR: 通过整合DMP特征到现代分割网络，特别是混合架构，显著提升了遥感图像语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像分割中的极端尺度变化、前景-背景不平衡和大图像尺寸等挑战，通过DMP提供关键的形状信息。

Method: 探索将多尺度形状提取方法DMP整合到三种最先进的卷积和变换器语义分割架构中，包括直接输入和混合架构设计。

Result: 混合DMP架构在mIoU、F1和Recall等指标上表现优于直接输入变体，并能够超越非DMP模型。

Conclusion: 将DMP特征整合到现代分割网络中，特别是通过混合架构，可以显著提升语义分割性能，超越非DMP模型在某些指标上的表现。

Abstract: Semantic segmentation of overhead remote sensing imagery enables applications
in mapping, urban planning, and disaster response. State-of-the-art
segmentation networks are typically developed and tuned on ground-perspective
photographs and do not directly address remote sensing challenges such as
extreme scale variation, foreground-background imbalance, and large image
sizes. We explore the incorporation of the differential morphological profile
(DMP), a multi-scale shape extraction method based on grayscale morphology,
into modern segmentation networks. Prior studies have shown that the DMP can
provide critical shape information to Deep Neural Networks to enable superior
detection and classification performance in overhead imagery. In this work, we
extend prior DMPNet work beyond classification and object detection by
integrating DMP features into three state-of-the-art convolutional and
transformer semantic segmentation architectures. We utilize both direct input,
which adapts the input stem of feature extraction architectures to accept DMP
channels, and hybrid architectures, a dual-stream design that fuses RGB and DMP
encoders. Using the iSAID benchmark dataset, we evaluate a variety of DMP
differentials and structuring element shapes to more effectively provide shape
information to the model. Our results show that while non-DMP models generally
outperform the direct-input variants, hybrid DMP consistently outperforms
direct-input and is capable of surpassing a non-DMP model on mIoU, F1, and
Recall.

</details>


### [49] [TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D Diffusion Models](https://arxiv.org/abs/2509.04269)
*Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong*

Main category: cs.CV

TL;DR: 提出了一种结合结构MRI和血浆p-tau217测量的文本引导3D扩散模型，用于合成3D tau PET图像，为AD诊断提供了一种经济高效的替代方案。


<details>
  <summary>Details</summary>
Motivation: tau PET扫描的高成本和有限可用性限制了其在阿尔茨海默病（AD）诊断和监测中的广泛应用。相比之下，结构MRI和血浆生物标志物提供了非侵入性且广泛可用的补充信息。

Method: 研究采用了一种文本引导的3D扩散模型，结合结构MRI和血浆p-tau217测量的多模态条件，进行3D tau PET图像合成。

Result: 实验结果表明，该方法能够生成跨多种疾病阶段的真实、具有临床意义的3D tau PET图像。

Conclusion: 该研究提出的基于文本引导的3D扩散模型能够生成具有临床意义的3D tau PET图像，为tau病理可视化提供了一种非侵入性、经济高效的替代方案。

Abstract: Accurate quantification of tau pathology via tau positron emission tomography
(PET) scan is crucial for diagnosing and monitoring Alzheimer's disease (AD).
However, the high cost and limited availability of tau PET restrict its
widespread use. In contrast, structural magnetic resonance imaging (MRI) and
plasma-based biomarkers provide non-invasive and widely available complementary
information related to brain anatomy and disease progression. In this work, we
propose a text-guided 3D diffusion model for 3D tau PET image synthesis,
leveraging multimodal conditions from both structural MRI and plasma
measurement. Specifically, the textual prompt is from the plasma p-tau217
measurement, which is a key indicator of AD progression, while MRI provides
anatomical structure constraints. The proposed framework is trained and
evaluated using clinical AV1451 tau PET data from the Alzheimer's Disease
Neuroimaging Initiative (ADNI) database. Experimental results demonstrate that
our approach can generate realistic, clinically meaningful 3D tau PET across a
range of disease stages. The proposed framework can help perform tau PET data
augmentation under different settings, provide a non-invasive, cost-effective
alternative for visualizing tau pathology, and support the simulation of
disease progression under varying plasma biomarker levels and cognitive
conditions.

</details>


### [50] [Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2509.04273)
*Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo*

Main category: cs.CV

TL;DR: 提出了一种结合体积先验和空间正则化的半监督医学图像分割框架，通过Wasserstein距离约束优化分割结果，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割网络在特征提取和数据集先验信息利用方面存在不足，需要更有效的方法论指导。

Method: 开发了一个半监督医学图像分割框架，结合了图像尺度的显式体积先验和阈值动态空间正则化方法，通过回归网络估计未标记图像的目标区域体积，并利用Wasserstein距离约束进行正则化。

Result: 在ACDC 2017、PROMISE12和大腿肌肉MR图像数据集上的实验结果表明，该方法优于现有方法。

Conclusion: 提出的半监督医学图像分割框架通过整合空间正则化方法和体积先验信息，显著提升了分割性能，并在多个数据集上验证了其优越性。

Abstract: Despite signi cant progress in semi-supervised medical image segmentation,
most existing segmentation networks overlook e ective methodological guidance
for feature extraction and important prior information from
  datasets. In this paper, we develop a semi-supervised medical image
segmentation framework that e ectively integrates spatial regularization
methods and volume priors. Speci cally, our approach integrates a strong
explicit volume prior at the image scale and Threshold Dynamics spatial
regularization, both derived from variational models, into the backbone
segmentation network. The target region volumes for each unlabeled image are
estimated by a regression network, which e ectively regularizes the backbone
segmentation network through an image-scale Wasserstein distance constraint,
ensuring that the class ratios in the segmentation results for each unlabeled
image match those predicted by the regression network. Additionally, we design
a dataset-scale Wasserstein distance loss function based on a weak implicit
volume prior, which enforces that the volume distribution predicted for the
unlabeled dataset is similar to that of labeled dataset. Experimental results
on the 2017 ACDC dataset, PROMISE12 dataset, and thigh muscle MR image dataset
show the superiority of the proposed method.

</details>


### [51] [PAOLI: Pose-free Articulated Object Learning from Sparse-view Images](https://arxiv.org/abs/2509.04276)
*Jianning Deng,Kartic Subr,Hakan Bilen*

Main category: cs.CV

TL;DR: 该论文提出了一种自监督框架，仅需四个视角且无需相机监督，通过稀疏重建和变形场学习，实现了关节物体的准确表示。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法需要密集多视角观测和真实相机姿态的问题，作者提出了一种能在更弱输入假设下工作的自监督框架。

Method: 该方法首先利用稀疏视角3D重建技术独立重建每个关节，然后学习一个变形场以建立跨姿态的密集对应关系。通过渐进式解缠策略分离静态和动态部分，并联合优化几何、外观和运动学。

Result: 实验结果表明，该方法在标准基准和真实世界示例中能够生成准确且详细的关节物体表示。

Conclusion: 该论文提出了一种新颖的自监督框架，能够在稀疏视角、无相机姿态标注的情况下学习关节物体的表示，显著降低了输入假设的要求，并在实验中证明了其准确性和详细性。

Abstract: We present a novel self-supervised framework for learning articulated object
representations from sparse-view, unposed images. Unlike prior methods that
require dense multi-view observations and ground-truth camera poses, our
approach operates with as few as four views per articulation and no camera
supervision. To address the inherent challenges, we first reconstruct each
articulation independently using recent advances in sparse-view 3D
reconstruction, then learn a deformation field that establishes dense
correspondences across poses. A progressive disentanglement strategy further
separates static from moving parts, enabling robust separation of camera and
object motion. Finally, we jointly optimize geometry, appearance, and
kinematics with a self-supervised loss that enforces cross-view and cross-pose
consistency. Experiments on the standard benchmark and real-world examples
demonstrate that our method produces accurate and detailed articulated object
representations under significantly weaker input assumptions than existing
approaches.

</details>


### [52] [Noisy Label Refinement with Semantically Reliable Synthetic Images](https://arxiv.org/abs/2509.04298)
*Yingxuan Li,Jiafeng Mao,Yusuke Matsui*

Main category: cs.CV

TL;DR: 利用合成图像作为参考点纠正噪声数据集中的错误标记，显著提升分类准确性，尤其在语义噪声条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 图像分类数据集中存在语义噪声，即视觉上相似的类别经常被错误标记，这对传统监督学习方法构成了重大挑战。

Method: 提出了一种新颖的方法，利用高级文本到图像模型生成的合成图像作为可靠参考点，以识别和纠正噪声数据集中的错误标记样本。

Result: 在多个基准数据集上的广泛实验表明，该方法在各种噪声条件下显著提高了分类准确性，尤其是在具有语义标签噪声的挑战性场景中。与现有噪声鲁棒学习技术结合时，性能更优，如在CIFAR-10上准确率提高了30%，在CIFAR-100上提高了11%，在ImageNet-100上提高了24%。

Conclusion: 该论文提出了一种利用合成图像作为可靠参考点来识别和纠正噪声数据集中错误标记样本的新方法，显著提高了在语义标签噪声条件下的分类准确性。

Abstract: Semantic noise in image classification datasets, where visually similar
categories are frequently mislabeled, poses a significant challenge to
conventional supervised learning approaches. In this paper, we explore the
potential of using synthetic images generated by advanced text-to-image models
to address this issue. Although these high-quality synthetic images come with
reliable labels, their direct application in training is limited by domain gaps
and diversity constraints. Unlike conventional approaches, we propose a novel
method that leverages synthetic images as reliable reference points to identify
and correct mislabeled samples in noisy datasets. Extensive experiments across
multiple benchmark datasets show that our approach significantly improves
classification accuracy under various noise conditions, especially in
challenging scenarios with semantic label noise. Additionally, since our method
is orthogonal to existing noise-robust learning techniques, when combined with
state-of-the-art noise-robust training methods, it achieves superior
performance, improving accuracy by 30% on CIFAR-10 and by 11% on CIFAR-100
under 70% semantic noise, and by 24% on ImageNet-100 under real-world noise
conditions.

</details>


### [53] [Efficient Odd-One-Out Anomaly Detection](https://arxiv.org/abs/2509.04326)
*Silvio Chito,Paolo Rabino,Tatiana Tommasi*

Main category: cs.CV

TL;DR: 提出了一种基于DINO的高效模型，用于多目标场景的异常检测，减少了参数和训练时间，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 多目标场景中的异常检测任务对现代深度学习模型提出了空间推理和关系推理的挑战，需要高效的方法来解决这些问题。

Method: 采用DINO-based模型，通过减少参数数量和优化训练流程，实现了比现有技术更高效的性能。

Result: 模型减少了三分之一的参数，训练时间缩短了三倍，同时保持了与现有技术相当的性能。

Conclusion: 提出的DINO-based模型在减少参数数量和缩短训练时间的同时，保持了竞争力的性能，为多目标场景中的异常检测任务提供了高效的解决方案。

Abstract: The recently introduced odd-one-out anomaly detection task involves
identifying the odd-looking instances within a multi-object scene. This problem
presents several challenges for modern deep learning models, demanding spatial
reasoning across multiple views and relational reasoning to understand context
and generalize across varying object categories and layouts. We argue that
these challenges must be addressed with efficiency in mind. To this end, we
propose a DINO-based model that reduces the number of parameters by one third
and shortens training time by a factor of three compared to the current
state-of-the-art, while maintaining competitive performance. Our experimental
evaluation also introduces a Multimodal Large Language Model baseline,
providing insights into its current limitations in structured visual reasoning
tasks. The project page can be found at
https://silviochito.github.io/EfficientOddOneOut/

</details>


### [54] [GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization](https://arxiv.org/abs/2509.04334)
*Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li*

Main category: cs.CV

TL;DR: GeoArena是一个开放的图像地理定位评估平台，解决了数据泄露和隐私问题，通过人类判断评估模型，并建立了排行榜。


<details>
  <summary>Details</summary>
Motivation: 当前图像地理定位评估方法存在数据泄露和隐私问题，需要更真实和人类中心化的评估方式。

Method: 提出了GeoArena平台，支持用户上传真实世界图像进行多样化评估，并利用成对人类判断来评估模型输出与人类期望的匹配程度。

Result: 平台上线两个月内收集了数千条投票记录，并基于此数据对不同LVLM进行了详细分析和排行榜建立。

Conclusion: GeoArena通过提供一个开放平台，解决了图像地理定位评估中的主要问题，包括数据泄露和隐私问题，并通过人类中心化基准测试建立了不同LVLM的排行榜。

Abstract: Image geolocalization aims to predict the geographic location of images
captured anywhere on Earth, but its global nature presents significant
challenges. Current evaluation methodologies suffer from two major limitations.
First, data leakage: advanced approaches often rely on large vision-language
models (LVLMs) to predict image locations, yet these models are frequently
pretrained on the test datasets, compromising the accuracy of evaluating a
model's actual geolocalization capability. Second, existing metrics primarily
rely on exact geographic coordinates to assess predictions, which not only
neglects the reasoning process but also raises privacy concerns when user-level
location data is required. To address these issues, we propose GeoArena, a
first open platform for evaluating LVLMs on worldwide image geolocalization
tasks, offering true in-the-wild and human-centered benchmarking. GeoArena
enables users to upload in-the-wild images for a more diverse evaluation
corpus, and it leverages pairwise human judgments to determine which model
output better aligns with human expectations. Our platform has been deployed
online for two months, during which we collected over thousands voting records.
Based on this data, we conduct a detailed analysis and establish a leaderboard
of different LVLMs on the image geolocalization task.

</details>


### [55] [From Editor to Dense Geometry Estimator](https://arxiv.org/abs/2509.04338)
*JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao*

Main category: cs.CV

TL;DR: FE2E框架通过适应基于DiT的编辑模型，在密集几何预测中实现了高性能提升，尤其在零样本深度和法线估计任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 密集预测本质上是图像到图像的任务，因此图像编辑模型可能比文本到图像生成模型更适合作为微调的基础。研究发现编辑模型具有固有的结构先验，能够更稳定地收敛并实现更高性能。

Method: FE2E框架将编辑模型的原始流匹配损失重新表述为“一致速度”训练目标，并使用对数量化解决精度冲突。此外，利用DiT的全局注意力机制，在单次前向传递中联合估计深度和法线。

Result: FE2E在多个数据集上实现了显著的性能提升，特别是在ETH3D数据集上性能增益超过35%，且无需扩大训练数据规模。

Conclusion: FE2E框架通过适应先进的基于DiT架构的编辑模型，在密集几何预测任务中取得了显著的性能提升，尤其是在零样本单目深度和法线估计方面。

Abstract: Leveraging visual priors from pre-trained text-to-image (T2I) generative
models has shown success in dense prediction. However, dense prediction is
inherently an image-to-image task, suggesting that image editing models, rather
than T2I generative models, may be a more suitable foundation for fine-tuning.
  Motivated by this, we conduct a systematic analysis of the fine-tuning
behaviors of both editors and generators for dense geometry estimation. Our
findings show that editing models possess inherent structural priors, which
enable them to converge more stably by ``refining" their innate features, and
ultimately achieve higher performance than their generative counterparts.
  Based on these findings, we introduce \textbf{FE2E}, a framework that
pioneeringly adapts an advanced editing model based on Diffusion Transformer
(DiT) architecture for dense geometry prediction. Specifically, to tailor the
editor for this deterministic task, we reformulate the editor's original flow
matching loss into the ``consistent velocity" training objective. And we use
logarithmic quantization to resolve the precision conflict between the editor's
native BFloat16 format and the high precision demand of our tasks.
Additionally, we leverage the DiT's global attention for a cost-free joint
estimation of depth and normals in a single forward pass, enabling their
supervisory signals to mutually enhance each other.
  Without scaling up the training data, FE2E achieves impressive performance
improvements in zero-shot monocular depth and normal estimation across multiple
datasets. Notably, it achieves over 35\% performance gains on the ETH3D dataset
and outperforms the DepthAnything series, which is trained on 100$\times$ data.
The project page can be accessed \href{https://amap-ml.github.io/FE2E/}{here}.

</details>


### [56] [MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition](https://arxiv.org/abs/2509.04344)
*Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu*

Main category: cs.CV

TL;DR: MICACL是一个结合时空依赖建模和长尾对比学习优化的多实例学习框架，显著提升了动态面部表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 动态面部表情识别面临长尾分布和时空特征建模复杂性的挑战，现有深度学习方法未能有效解决这些问题，导致模型存在严重的归纳偏差。

Method: 提出了一个多实例学习框架MICACL，包含Graph-Enhanced Instance Interaction Module (GEIIM)用于捕捉时空依赖关系，以及Weighted Instance Aggregation Network (WIAN)用于动态加权实例特征聚合。此外，还引入了Multiscale Category-aware Contrastive Learning (MCCL)策略以平衡主要和次要类别的训练。

Result: 在DFEW和FERV39k等数据集上的实验表明，MICACL实现了最先进的性能，具有优越的鲁棒性和泛化能力。

Conclusion: MICACL框架通过结合时空依赖建模和长尾对比学习优化，显著提升了动态面部表情识别的性能，并在多个数据集上展示了卓越的鲁棒性和泛化能力。

Abstract: Dynamic facial expression recognition (DFER) faces significant challenges due
to long-tailed category distributions and complexity of spatio-temporal feature
modeling. While existing deep learning-based methods have improved DFER
performance, they often fail to address these issues, resulting in severe model
induction bias. To overcome these limitations, we propose a novel
multi-instance learning framework called MICACL, which integrates
spatio-temporal dependency modeling and long-tailed contrastive learning
optimization. Specifically, we design the Graph-Enhanced Instance Interaction
Module (GEIIM) to capture intricate spatio-temporal between adjacent instances
relationships through adaptive adjacency matrices and multiscale convolutions.
To enhance instance-level feature aggregation, we develop the Weighted Instance
Aggregation Network (WIAN), which dynamically assigns weights based on instance
importance. Furthermore, we introduce a Multiscale Category-aware Contrastive
Learning (MCCL) strategy to balance training between major and minor
categories. Extensive experiments on in-the-wild datasets (i.e., DFEW and
FERV39k) demonstrate that MICACL achieves state-of-the-art performance with
superior robustness and generalization.

</details>


### [57] [Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage](https://arxiv.org/abs/2509.04370)
*Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CV

TL;DR: 研究提出了一种将穿戴式摄像机视频转化为全景图像的方法，以支持应急响应中的快速决策和事后分析。


<details>
  <summary>Details</summary>
Motivation: 应急响应人员在时间紧迫的情况下难以审阅冗长的视频素材，因此需要一种简洁的视觉总结方法，以便快速理解现场情况。

Method: 利用单目SLAM估计摄像机轨迹并重建环境空间布局，通过聚类摄像机姿态识别关键视角，并从中选择代表性帧，最后使用多帧拼接技术将这些帧融合成空间一致的全景图像。

Result: 该方法生成的视觉总结能够有效支持快速环境理解和决策，以及事后事件分析。

Conclusion: 该研究提出的计算机视觉管道能够将穿戴式摄像机拍摄的长时间视频转化为信息丰富的全景图像，显著提升了复杂环境下快速理解和决策的效率。

Abstract: First responders widely adopt body-worn cameras to document incident scenes
and support post-event analysis. However, reviewing lengthy video footage is
impractical in time-critical situations. Effective situational awareness
demands a concise visual summary that can be quickly interpreted. This work
presents a computer vision pipeline that transforms body-camera footage into
informative panoramic images summarizing the incident scene. Our method
leverages monocular Simultaneous Localization and Mapping (SLAM) to estimate
camera trajectories and reconstruct the spatial layout of the environment. Key
viewpoints are identified by clustering camera poses along the trajectory, and
representative frames from each cluster are selected. These frames are fused
into spatially coherent panoramic images using multi-frame stitching
techniques. The resulting summaries enable rapid understanding of complex
environments and facilitate efficient decision-making and incident review.

</details>


### [58] [AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search](https://arxiv.org/abs/2509.04376)
*Hao Ju,Hu Zhang,Zhedong Zheng*

Main category: cs.CV

TL;DR: AnomalyLMM利用LMMs解决文本驱动的人员异常搜索，通过创新流程和零样本策略提升性能，在PAB数据集上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 随着公共安全需求的增长，基于文本的人员异常搜索成为关键任务，但现有方法在细粒度跨模态对齐和稀疏样本下的异常识别方面存在挑战。

Method: 提出AnomalyLMM框架，结合掩码跨模态提示、行为显著性预测和知识感知重排等无需训练的策略，实现零样本的异常检测。

Result: 在PAB数据集上，AnomalyLMM的Recall@1准确率比基线方法提高了0.96%，并展示了文本异常与视觉行为之间的可解释对齐。

Conclusion: AnomalyLMM框架成功利用大型多模态模型（LMMs）解决了文本驱动的人员异常搜索任务，通过创新的粗到细流程和无需训练的适应策略，显著提升了检索性能，并在PAB数据集上验证了其有效性。

Abstract: With growing public safety demands, text-based person anomaly search has
emerged as a critical task, aiming to retrieve individuals with abnormal
behaviors via natural language descriptions. Unlike conventional person search,
this task presents two unique challenges: (1) fine-grained cross-modal
alignment between textual anomalies and visual behaviors, and (2) anomaly
recognition under sparse real-world samples. While Large Multi-modal Models
(LMMs) excel in multi-modal understanding, their potential for fine-grained
anomaly retrieval remains underexplored, hindered by: (1) a domain gap between
generative knowledge and discriminative retrieval, and (2) the absence of
efficient adaptation strategies for deployment. In this work, we propose
AnomalyLMM, the first framework that harnesses LMMs for text-based person
anomaly search. Our key contributions are: (1) A novel coarse-to-fine pipeline
integrating LMMs to bridge generative world knowledge with retrieval-centric
anomaly detection; (2) A training-free adaptation cookbook featuring masked
cross-modal prompting, behavioral saliency prediction, and knowledge-aware
re-ranking, enabling zero-shot focus on subtle anomaly cues. As the first study
to explore LMMs for this task, we conduct a rigorous evaluation on the PAB
dataset, the only publicly available benchmark for text-based person anomaly
search, with its curated real-world anomalies covering diverse scenarios (e.g.,
falling, collision, and being hit). Experiments show the effectiveness of the
proposed method, surpassing the competitive baseline by +0.96% Recall@1
accuracy. Notably, our method reveals interpretable alignment between textual
anomalies and visual behaviors, validated via qualitative analysis. Our code
and models will be released for future research.

</details>


### [59] [Aesthetic Image Captioning with Saliency Enhanced MLLMs](https://arxiv.org/abs/2509.04378)
*Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao*

Main category: cs.CV

TL;DR: ASE-MLLM是首个将图像美学显著性整合到MLLMs中的框架，显著提升AIC任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注美学评分预测，AIC任务中MLLMs的应用有限且未针对美学内容优化。

Method: 提出了ASE-MLLM框架，包括IASM模块和IAS-ViT编码器，通过交叉注意力机制融合美学显著性特征与原始图像特征。

Result: 在主流AIC基准测试中，ASE-MLLM显著优于传统方法和通用MLLMs，达到SOTA性能。

Conclusion: ASE-MLLM通过整合图像美学显著性特征，显著提升了AIC任务的性能，成为当前主流基准上的最佳方法。

Abstract: Aesthetic Image Captioning (AIC) aims to generate textual descriptions of
image aesthetics, becoming a key research direction in the field of
computational aesthetics. In recent years, pretrained Multimodal Large Language
Models (MLLMs) have advanced rapidly, leading to a significant increase in
image aesthetics research that integrates both visual and textual modalities.
However, most existing studies on image aesthetics primarily focus on
predicting aesthetic ratings and have shown limited application in AIC.
Existing AIC works leveraging MLLMs predominantly rely on fine-tuning methods
without specifically adapting MLLMs to focus on target aesthetic content. To
address this limitation, we propose the Aesthetic Saliency Enhanced Multimodal
Large Language Model (ASE-MLLM), an end-to-end framework that explicitly
incorporates aesthetic saliency into MLLMs. Within this framework, we introduce
the Image Aesthetic Saliency Module (IASM), which efficiently and effectively
extracts aesthetic saliency features from images. Additionally, we design
IAS-ViT as the image encoder for MLLMs, this module fuses aesthetic saliency
features with original image features via a cross-attention mechanism. To the
best of our knowledge, ASE-MLLM is the first framework to integrate image
aesthetic saliency into MLLMs specifically for AIC tasks. Extensive experiments
demonstrated that our approach significantly outperformed traditional methods
and generic MLLMs on current mainstream AIC benchmarks, achieving
state-of-the-art (SOTA) performance.

</details>


### [60] [SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer](https://arxiv.org/abs/2509.04379)
*Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu*

Main category: cs.CV

TL;DR: 论文提出了一种结合2D扩散模型先验的3D风格迁移方法，通过跨视角风格对齐和实例级风格转移，实现了更优的风格化效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从参考风格图像中提取和迁移高级风格语义方面表现不佳，且风格化结果缺乏结构清晰度和分离性。

Method: 提出了一种新颖的3D风格迁移流程，结合了预训练2D扩散模型的先验知识，包括两个关键阶段：利用扩散先验生成关键视角的风格化渲染，并将其转移到3D表示上。

Result: 实验表明，该流程在广泛场景中显著优于现有方法，包括前向和360度环境。

Conclusion: 该论文提出的3D风格迁移流程显著优于现有方法，实现了更结构化、视觉一致且艺术丰富的风格化效果。

Abstract: Recent advancements in neural representations, such as Neural Radiance Fields
and 3D Gaussian Splatting, have increased interest in applying style transfer
to 3D scenes. While existing methods can transfer style patterns onto
3D-consistent neural representations, they struggle to effectively extract and
transfer high-level style semantics from the reference style image.
Additionally, the stylized results often lack structural clarity and
separation, making it difficult to distinguish between different instances or
objects within the 3D scene. To address these limitations, we propose a novel
3D style transfer pipeline that effectively integrates prior knowledge from
pretrained 2D diffusion models. Our pipeline consists of two key stages: First,
we leverage diffusion priors to generate stylized renderings of key viewpoints.
Then, we transfer the stylized key views onto the 3D representation. This
process incorporates two innovative designs. The first is cross-view style
alignment, which inserts cross-view attention into the last upsampling block of
the UNet, allowing feature interactions across multiple key views. This ensures
that the diffusion model generates stylized key views that maintain both style
fidelity and instance-level consistency. The second is instance-level style
transfer, which effectively leverages instance-level consistency across
stylized key views and transfers it onto the 3D representation. This results in
a more structured, visually coherent, and artistically enriched stylization.
Extensive qualitative and quantitative experiments demonstrate that our 3D
style transfer pipeline significantly outperforms state-of-the-art methods
across a wide range of scenes, from forward-facing to challenging 360-degree
environments. Visit our project page https://jm-xu.github.io/SSGaussian for
immersive visualization.

</details>


### [61] [Learning neural representations for X-ray ptychography reconstruction with unknown probes](https://arxiv.org/abs/2509.04402)
*Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li*

Main category: cs.CV

TL;DR: PtyINR 是一种自监督框架，通过神经表示直接重建X射线叠层成像，显著提升低信号条件下的重建质量。


<details>
  <summary>Details</summary>
Motivation: X射线叠层成像在纳米尺度分辨率上具有广泛应用，但在探针未知时的图像重建准确性受限，传统方法和深度学习在低信号条件下表现不佳。

Method: PtyINR 是一种自监督框架，通过将物体和探针参数化为连续的神经表示，直接从原始衍射图案进行端到端重建。

Result: PtyINR 在模拟和实验数据上均实现了优越的重建质量，尤其在低信号条件下表现出色。

Conclusion: PtyINR 提供了一种通用的、基于物理的框架，适用于广泛的计算显微镜问题，显著提升了在低信号条件下的重建质量。

Abstract: X-ray ptychography provides exceptional nanoscale resolution and is widely
applied in materials science, biology, and nanotechnology. However, its full
potential is constrained by the critical challenge of accurately reconstructing
images when the illuminating probe is unknown. Conventional iterative methods
and deep learning approaches are often suboptimal, particularly under the
low-signal conditions inherent to low-dose and high-speed experiments. These
limitations compromise reconstruction fidelity and restrict the broader
adoption of the technique. In this work, we introduce the Ptychographic
Implicit Neural Representation (PtyINR), a self-supervised framework that
simultaneously addresses the object and probe recovery problem. By
parameterizing both as continuous neural representations, PtyINR performs
end-to-end reconstruction directly from raw diffraction patterns without
requiring any pre-characterization of the probe. Extensive evaluations
demonstrate that PtyINR achieves superior reconstruction quality on both
simulated and experimental data, with remarkable robustness under challenging
low-signal conditions. Furthermore, PtyINR offers a generalizable,
physics-informed framework for addressing probe-dependent inverse problems,
making it applicable to a wide range of computational microscopy problems.

</details>


### [62] [Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios](https://arxiv.org/abs/2509.04403)
*Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao*

Main category: cs.CV

TL;DR: 本文提出了一种以图像为导向的自适应数据集构建方法，用于解决多模态大语言模型（MLLMs）在真实世界安全场景中的复杂挑战，并证实了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前以风险为导向的数据集构建方法无法覆盖日益复杂的真实世界多模态安全场景（RMS），且缺乏统一评估指标，导致整体效果无法验证。

Method: 引入了一种新颖的以图像为导向的自适应数据集构建方法，自动生成了包含35k图像-文本对及指导响应的RMS数据集，并提出了标准化的安全数据集评估指标。

Result: 通过多种任务的广泛实验，验证了以图像为导向的流程的有效性。

Conclusion: 本文提出的以图像为导向的自适应数据集构建方法为真实世界多模态安全场景（RMS）数据集构建提供了新视角，证实了该方法的可扩展性和有效性。

Abstract: Multimodal large language models (MLLMs) are rapidly evolving, presenting
increasingly complex safety challenges. However, current dataset construction
methods, which are risk-oriented, fail to cover the growing complexity of
real-world multimodal safety scenarios (RMS). And due to the lack of a unified
evaluation metric, their overall effectiveness remains unproven. This paper
introduces a novel image-oriented self-adaptive dataset construction method for
RMS, which starts with images and end constructing paired text and guidance
responses. Using the image-oriented method, we automatically generate an RMS
dataset comprising 35k image-text pairs with guidance responses. Additionally,
we introduce a standardized safety dataset evaluation metric: fine-tuning a
safety judge model and evaluating its capabilities on other safety
datasets.Extensive experiments on various tasks demonstrate the effectiveness
of the proposed image-oriented pipeline. The results confirm the scalability
and effectiveness of the image-oriented approach, offering a new perspective
for the construction of real-world multimodal safety datasets.

</details>


### [63] [Few-step Flow for 3D Generation via Marginal-Data Transport Distillation](https://arxiv.org/abs/2509.04406)
*Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian*

Main category: cs.CV

TL;DR: MDT-dist通过VM和VD优化目标，加速3D生成模型的推理速度，同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 尽管一致性模型（CMs）在加速2D扩散模型方面取得了进展，但在更复杂的3D生成任务中仍未被充分探索。

Method: 提出MDT-dist框架，通过Velocity Matching（VM）和Velocity Distillation（VD）两个优化目标，将运输层面的优化目标等效转换为速度和分布层面。

Result: 在TRELLIS框架上评估，MDT-dist将每个流变压器的采样步骤从25步减少到1或2步，实现了显著的加速（9.0x和6.5x），同时保持了高保真度。

Conclusion: MDT-dist框架通过Velocity Matching和Velocity Distillation优化目标，显著提升了3D生成任务的推理速度，同时保持了高质量的视觉和几何保真度。

Abstract: Flow-based 3D generation models typically require dozens of sampling steps
during inference. Though few-step distillation methods, particularly
Consistency Models (CMs), have achieved substantial advancements in
accelerating 2D diffusion models, they remain under-explored for more complex
3D generation tasks. In this study, we propose a novel framework, MDT-dist, for
few-step 3D flow distillation. Our approach is built upon a primary objective:
distilling the pretrained model to learn the Marginal-Data Transport. Directly
learning this objective needs to integrate the velocity fields, while this
integral is intractable to be implemented. Therefore, we propose two
optimizable objectives, Velocity Matching (VM) and Velocity Distillation (VD),
to equivalently convert the optimization target from the transport level to the
velocity and the distribution level respectively. Velocity Matching (VM) learns
to stably match the velocity fields between the student and the teacher, but
inevitably provides biased gradient estimates. Velocity Distillation (VD)
further enhances the optimization process by leveraging the learned velocity
fields to perform probability density distillation. When evaluated on the
pioneer 3D generation framework TRELLIS, our method reduces sampling steps of
each flow transformer from 25 to 1 or 2, achieving 0.68s (1 step x 2) and 0.94s
(2 steps x 2) latency with 9.0x and 6.5x speedup on A800, while preserving high
visual and geometric fidelity. Extensive experiments demonstrate that our
method significantly outperforms existing CM distillation methods, and enables
TRELLIS to achieve superior performance in few-step 3D generation.

</details>


### [64] [Durian: Dual Reference-guided Portrait Animation with Attribute Transfer](https://arxiv.org/abs/2509.04434)
*Hyunsoo Cha,Byungjun Kim,Hanbyul Joo*

Main category: cs.CV

TL;DR: Durian 是首个零样本肖像动画属性转移方法，通过双参考网络和自重构训练实现高保真效果，支持多属性组合。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在零样本条件下无法实现高保真、空间一致的属性转移的问题。

Method: 引入了双参考网络，将肖像和属性图像的空间特征注入扩散模型的去噪过程；采用自重构训练策略，结合掩码扩展和图像增强技术以提高鲁棒性。

Result: Durian 在肖像动画属性转移任务上达到了最先进的性能，支持多属性组合。

Conclusion: Durian 在零样本条件下实现了肖像动画视频的高保真和空间一致的属性转移，其双参考网络设计支持多属性组合，无需额外训练。

Abstract: We present Durian, the first method for generating portrait animation videos
with facial attribute transfer from a given reference image to a target
portrait in a zero-shot manner. To enable high-fidelity and spatially
consistent attribute transfer across frames, we introduce dual reference
networks that inject spatial features from both the portrait and attribute
images into the denoising process of a diffusion model. We train the model
using a self-reconstruction formulation, where two frames are sampled from the
same portrait video: one is treated as the attribute reference and the other as
the target portrait, and the remaining frames are reconstructed conditioned on
these inputs and their corresponding masks. To support the transfer of
attributes with varying spatial extent, we propose a mask expansion strategy
using keypoint-conditioned image generation for training. In addition, we
further augment the attribute and portrait images with spatial and
appearance-level transformations to improve robustness to positional
misalignment between them. These strategies allow the model to effectively
generalize across diverse attributes and in-the-wild reference combinations,
despite being trained without explicit triplet supervision. Durian achieves
state-of-the-art performance on portrait animation with attribute transfer, and
notably, its dual reference design enables multi-attribute composition in a
single generation pass without additional training.

</details>


### [65] [From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform](https://arxiv.org/abs/2509.04437)
*Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的分割方法，结合Hough变换网络，用于检测X射线图像中的准直边界，实现了高精度的准直区域重建。


<details>
  <summary>Details</summary>
Motivation: X射线成像中的准直限制了对感兴趣区域（ROI）的曝光，并最小化患者接受的辐射剂量。然而，准直器阴影的检测在数字放射成像中是一个关键预处理步骤，当边缘被散射X射线辐射遮蔽时尤其具有挑战性。

Method: 引入了一种基于深度学习的分割方法，结合可微分的Hough变换网络来检测准直边界，并增强提取ROI中心信息的能力。在推理阶段，结合两项任务的信息生成精炼的、线约束的分割掩码。

Result: 在多样化的真实X射线图像测试集上，实现了中位Hausdorff距离为4.3-5.0mm的准直区域稳健重建。

Conclusion: 该方法在真实X射线图像上实现了稳健的准直区域重建，中位Hausdorff距离为4.3-5.0mm。尽管应用最多涉及四个阴影边界，但方法不受特定边数限制。

Abstract: Collimation in X-ray imaging restricts exposure to the region-of-interest
(ROI) and minimizes the radiation dose applied to the patient. The detection of
collimator shadows is an essential image-based preprocessing step in digital
radiography posing a challenge when edges get obscured by scattered X-ray
radiation. Regardless, the prior knowledge that collimation forms
polygonal-shaped shadows is evident. For this reason, we introduce a deep
learning-based segmentation that is inherently constrained to its geometry. We
achieve this by incorporating a differentiable Hough transform-based network to
detect the collimation borders and enhance its capability to extract the
information about the ROI center. During inference, we combine the information
of both tasks to enable the generation of refined, line-constrained
segmentation masks. We demonstrate robust reconstruction of collimated regions
achieving median Hausdorff distances of 4.3-5.0mm on diverse test sets of real
Xray images. While this application involves at most four shadow borders, our
method is not fundamentally limited by a specific number of edges.

</details>


### [66] [The Telephone Game: Evaluating Semantic Drift in Unified Models](https://arxiv.org/abs/2509.04438)
*Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah*

Main category: cs.CV

TL;DR: UCF-UM框架通过循环评估协议量化语义漂移，揭示模型跨模态稳定性差异，强调循环一致性的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法孤立考虑T2I和I2T能力，无法揭示模型在概念理解和生成之间的一致性，UCF-UM旨在解决这一问题。

Method: 引入UCF-UM循环评估协议，通过交替I2T和T2I多代量化语义漂移，并制定三个指标：MCD、SDR和MGG。

Result: 评估结果显示模型在跨模态稳定性上存在显著差异，如BAGEL在多代交替中保持语义，而Vila-u则快速漂移。

Conclusion: UCF-UM框架揭示了跨模态稳定性的显著差异，强调循环一致性作为标准I2T和T2I评估的必要补充，并提供了实用指标来评估统一模型的跨模态稳定性和共享表示强度。

Abstract: Employing a single, unified model (UM) for both visual understanding
(image-to-text: I2T) and and visual generation (text-to-image: T2I) has opened
a new direction in Visual Language Model (VLM) research. While UMs can also
support broader unimodal tasks (e.g., text-to-text, image-to-image), we focus
on the core cross-modal pair T2I and I2T, as consistency between understanding
and generation is critical for downstream use. Existing evaluations consider
these capabilities in isolation: FID and GenEval for T2I, and benchmarks such
as MME, MMBench for I2T. These single-pass metrics do not reveal whether a
model that understands a concept can also render it, nor whether meaning is
preserved when cycling between image and text modalities. To address this, we
introduce the Unified Consistency Framework for Unified Models (UCF-UM), a
cyclic evaluation protocol that alternates I2T and T2I over multiple
generations to quantify semantic drift. UCF formulates 3 metrics: (i) Mean
Cumulative Drift (MCD), an embedding-based measure of overall semantic loss;
(ii) Semantic Drift Rate (SDR), that summarizes semantic decay rate; and (iii)
Multi-Generation GenEval (MGG), an object-level compliance score extending
GenEval. To assess generalization beyond COCO, which is widely used in
training; we create a new benchmark ND400, sampled from NoCaps and DOCCI and
evaluate on seven recent models. UCF-UM reveals substantial variation in
cross-modal stability: some models like BAGEL maintain semantics over many
alternations, whereas others like Vila-u drift quickly despite strong
single-pass scores. Our results highlight cyclic consistency as a necessary
complement to standard I2T and T2I evaluations, and provide practical metrics
to consistently assess unified model's cross-modal stability and strength of
their shared representations. Code:
https://github.com/mollahsabbir/Semantic-Drift-in-Unified-Models

</details>


### [67] [One Flight Over the Gap: A Survey from Perspective to Panoramic Vision](https://arxiv.org/abs/2509.04444)
*Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: 该综述回顾了全景视觉技术，特别关注从透视到全景的适应方法，总结了三大挑战并分类为四大任务类别，讨论了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于对空间智能和整体场景感知的需求，全景图像（ODIs）在虚拟现实、自动驾驶等应用中受到越来越多的关注。然而，全景图像与透视图像在几何投影、空间分布和边界连续性等方面存在显著差异，使得直接领域适应具有挑战性。

Method: 综述回顾了全景视觉技术，特别关注从透视到全景的适应方法，包括分析结构差异的先验知识、总结领域适应的三大挑战，并通过跨方法和跨任务分析覆盖了20多个代表性任务。

Result: 综述总结了全景视觉技术的三大挑战，并分类为四大类别：视觉质量增强与评估、视觉理解、多模态理解和视觉生成。

Conclusion: 该综述讨论了全景视觉技术的开放挑战和未来方向，旨在推动全景视觉技术的发展。

Abstract: Driven by the demand for spatial intelligence and holistic scene perception,
omnidirectional images (ODIs), which provide a complete 360\textdegree{} field
of view, are receiving growing attention across diverse applications such as
virtual reality, autonomous driving, and embodied robotics. Despite their
unique characteristics, ODIs exhibit remarkable differences from perspective
images in geometric projection, spatial distribution, and boundary continuity,
making it challenging for direct domain adaption from perspective methods. This
survey reviews recent panoramic vision techniques with a particular emphasis on
the perspective-to-panorama adaptation. We first revisit the panoramic imaging
pipeline and projection methods to build the prior knowledge required for
analyzing the structural disparities. Then, we summarize three challenges of
domain adaptation: severe geometric distortions near the poles, non-uniform
sampling in Equirectangular Projection (ERP), and periodic boundary continuity.
Building on this, we cover 20+ representative tasks drawn from more than 300
research papers in two dimensions. On one hand, we present a cross-method
analysis of representative strategies for addressing panoramic specific
challenges across different tasks. On the other hand, we conduct a cross-task
comparison and classify panoramic vision into four major categories: visual
quality enhancement and assessment, visual understanding, multimodal
understanding, and visual generation. In addition, we discuss open challenges
and future directions in data, models, and applications that will drive the
advancement of panoramic vision research. We hope that our work can provide new
insight and forward looking perspectives to advance the development of
panoramic vision technologies. Our project page is
https://insta360-research-team.github.io/Survey-of-Panorama

</details>


### [68] [Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.04446)
*Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag*

Main category: cs.CV

TL;DR: Plot'n Polish 是一个零样本框架，解决了文本到图像扩散模型在故事可视化中缺乏细粒度控制和一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 随着文本到图像扩散模型在创意领域的广泛应用，如何提供增强的控制、细化及生成后修改能力成为重要挑战。现有方法在保持多帧视觉和叙事一致性方面缺乏灵活性。

Method: 引入 Plot'n Polish 框架，支持零样本、多层次的细粒度控制，以保持视觉和叙事一致性。

Result: Plot'n Polish 能够灵活地应用粗细编辑，同时保持多帧的一致性和叙事连贯性，为创作者提供无缝的视觉故事制作和细化能力。

Conclusion: Plot'n Polish 是一个零样本框架，能够在不同细节层次上提供细粒度控制，实现一致的故事生成和可视化。

Abstract: Text-to-image diffusion models have demonstrated significant capabilities to
generate diverse and detailed visuals in various domains, and story
visualization is emerging as a particularly promising application. However, as
their use in real-world creative domains increases, the need for providing
enhanced control, refinement, and the ability to modify images post-generation
in a consistent manner becomes an important challenge. Existing methods often
lack the flexibility to apply fine or coarse edits while maintaining visual and
narrative consistency across multiple frames, preventing creators from
seamlessly crafting and refining their visual stories. To address these
challenges, we introduce Plot'n Polish, a zero-shot framework that enables
consistent story generation and provides fine-grained control over story
visualizations at various levels of detail.

</details>


### [69] [TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection](https://arxiv.org/abs/2509.04448)
*Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee*

Main category: cs.CV

TL;DR: TRUST-VL是一个统一且可解释的视觉语言模型，通过联合训练和任务特定模块设计，有效检测多模态虚假信息，并在泛化和解释性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 多模态虚假信息（包含文本、视觉和跨模态扭曲）对社会构成威胁，现有方法难以泛化到未见过场景。

Method: 引入TRUST-VL模型，结合Question-Aware Visual Amplifier模块提取任务特定视觉特征，并构建TRUST-Instruct指令数据集支持训练。

Result: TRUST-VL在域内和零样本基准测试中均达到最先进性能，同时具备强泛化性和可解释性。

Conclusion: TRUST-VL通过联合训练和任务特定模块设计，实现了对多模态虚假信息的有效检测，并在泛化性和可解释性方面表现出色。

Abstract: Multimodal misinformation, encompassing textual, visual, and cross-modal
distortions, poses an increasing societal threat that is amplified by
generative AI. Existing methods typically focus on a single type of distortion
and struggle to generalize to unseen scenarios. In this work, we observe that
different distortion types share common reasoning capabilities while also
requiring task-specific skills. We hypothesize that joint training across
distortion types facilitates knowledge sharing and enhances the model's ability
to generalize. To this end, we introduce TRUST-VL, a unified and explainable
vision-language model for general multimodal misinformation detection. TRUST-VL
incorporates a novel Question-Aware Visual Amplifier module, designed to
extract task-specific visual features. To support training, we also construct
TRUST-Instruct, a large-scale instruction dataset containing 198K samples
featuring structured reasoning chains aligned with human fact-checking
workflows. Extensive experiments on both in-domain and zero-shot benchmarks
demonstrate that TRUST-VL achieves state-of-the-art performance, while also
offering strong generalization and interpretability.

</details>


### [70] [Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview](https://arxiv.org/abs/2509.04450)
*Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: VFR是一种新型视频生成模型，通过自回归逐段生成和锚点视频技术，解决了长虚拟试穿视频的平滑性和一致性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决长虚拟试穿视频生成中资源密集型生成和长视频数据的需求，以及确保视频的局部平滑性和全局一致性。

Method: VFR将长视频生成任务建模为自回归、逐段生成的过程，通过前缀视频条件和锚点视频解决局部平滑性和全局一致性的挑战。

Result: VFR能够生成分钟级别的虚拟试穿视频，在各种动作下保持局部平滑性和全局时间一致性。

Conclusion: VFR框架通过前缀视频条件和锚点视频确保了长虚拟试穿视频的局部平滑性和全局时间一致性，成为长虚拟试穿视频生成的先驱工作。

Abstract: We introduce the Virtual Fitting Room (VFR), a novel video generative model
that produces arbitrarily long virtual try-on videos. Our VFR models long video
generation tasks as an auto-regressive, segment-by-segment generation process,
eliminating the need for resource-intensive generation and lengthy video data,
while providing the flexibility to generate videos of arbitrary length. The key
challenges of this task are twofold: ensuring local smoothness between adjacent
segments and maintaining global temporal consistency across different segments.
To address these challenges, we propose our VFR framework, which ensures
smoothness through a prefix video condition and enforces consistency with the
anchor video -- a 360-degree video that comprehensively captures the human's
wholebody appearance. Our VFR generates minute-scale virtual try-on videos with
both local smoothness and global temporal consistency under various motions,
making it a pioneering work in long virtual try-on video generation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [71] [Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study](https://arxiv.org/abs/2509.03541)
*Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen*

Main category: cs.SE

TL;DR: 本文通过系统映射研究发现，移动应用需求工程研究主要依赖Google Play和Apple App Store的数据集，且集中在需求获取和分析活动。结论指出数据集使用增长但存在偏差，建议扩展数据源和研究范围。


<details>
  <summary>Details</summary>
Motivation: 移动应用需求工程研究的数据集多来自应用用户、开发者或供应商，但对其平台来源及支持的需求工程活动了解不足。本文旨在调查现有需求工程研究中使用的移动应用数据集的现状。

Method: 本文采用Kitchenham等人的指南进行系统映射研究，分析了43篇选定论文。

Result: 基于43篇论文的分析发现，Google Play和Apple App Store提供了超过90%的移动应用需求工程研究数据集。需求获取和需求分析是基于数据集研究最多的需求工程活动。

Conclusion: 本文的重要结论包括：(1) 自2012年以来，移动应用需求工程研究中数据集的使用有所增长；(2) 由于过度依赖Google Play和Apple App Store，移动应用需求工程的知识可能存在偏差；(3) 有尝试通过其他数据源补充应用商店的评论；(4) 如果希望获得更具普遍性的结果，需要扩展替代数据源并尝试多源互补使用。此外，建议扩展除需求获取和分析之外的其他需求工程活动的研究。

Abstract: [Background] Research on requirements engineering (RE) for mobile apps
employs datasets formed by app users, developers or vendors. However, little is
known about the sources of these datasets in terms of platforms and the RE
activities that were researched with the help of the respective datasets.
[Aims] The goal of this paper is to investigate the state-of-the-art of the
datasets of mobile apps used in existing RE research. [Method] We carried out a
systematic mapping study by following the guidelines of Kitchenham et al.
[Results] Based on 43 selected papers, we found that Google Play and Apple App
Store provide the datasets for more than 90% of published research in RE for
mobile apps. We also found that the most investigated RE activities - based on
datasets, are requirements elicitation and requirements analysis. [Conclusions]
Our most important conclusions are: (1) there is a growth in the use of
datasets for RE research of mobile apps since 2012, (2) the RE knowledge for
mobile apps might be skewed due to the overuse of Google Play and Apple App
Store, (3) there are attempts to supplement reviews of apps from repositories
with other data sources, (4) there is a need to expand the alternative sources
and experiments with complimentary use of multiple sources, if the community
wants more generalizable results. Plus, it is expected to expand the research
on other RE activities, beyond elicitation and analysis.

</details>


### [72] [A Multi-stage Error Diagnosis for APB Transaction](https://arxiv.org/abs/2509.03554)
*Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin*

Main category: cs.SE

TL;DR: An automated error diagnosis framework using hierarchical Random Forest achieves 91.36% accuracy in detecting APB transaction errors, showcasing its potential for hardware debugging in EDA.


<details>
  <summary>Details</summary>
Motivation: Functional verification and debugging are critical bottlenecks in modern System-on-Chip (SoC) design, with manual detection of APB transaction errors in large VCD files being inefficient and error-prone.

Method: The study proposes an automated error diagnosis framework using a hierarchical Random Forest-based architecture, employing four pre-trained binary classifiers to sequentially detect various errors.

Result: Experimental results show an overall accuracy of 91.36%, with near-perfect precision and recall for address errors and robust performance for data errors.

Conclusion: This research validates the potential of hierarchical machine learning as a powerful automated tool for hardware debugging in Electronic Design Automation (EDA).

Abstract: Functional verification and debugging are critical bottlenecks in modern
System-on-Chip (SoC) design, with manual detection of Advanced Peripheral Bus
(APB) transaction errors in large Value Change Dump (VCD) files being
inefficient and error-prone. Addressing the 2025 ICCAD Contest Problem D, this
study proposes an automated error diagnosis framework using a hierarchical
Random Forest-based architecture. The multi-stage error diagnosis employs four
pre-trained binary classifiers to sequentially detect Out-of-Range Access,
Address Corruption, and Data Corruption errors, prioritizing high-certainty
address-related faults before tackling complex data errors to enhance
efficiency. Experimental results show an overall accuracy of 91.36%, with
near-perfect precision and recall for address errors and robust performance for
data errors. Although the final results of the ICCAD 2025 CAD Contest are yet
to be announced as of the submission date, our team achieved first place in the
beta stage, highlighting the method's competitive strength. This research
validates the potential of hierarchical machine learning as a powerful
automated tool for hardware debugging in Electronic Design Automation (EDA).

</details>


### [73] [Parse Tree Tracking Through Time for Programming Process Analysis at Scale](https://arxiv.org/abs/2509.03668)
*Matt Rau,Chris Brown,John Edwards*

Main category: cs.SE

TL;DR: 研究开发了首个跟踪解析树节点的算法，应用于学生编程数据，发现代码删除率、注释恢复等新行为，为编程行为分析提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 传统方法无法自动跟踪高级代码表示（如抽象语法树）在时间和不可解析状态中的变化，限制了上下文行为分析的规模。

Method: 使用两种算法来跟踪解析树节点并构建不可解析代码状态的树表示，应用于2021年CS1课程的学生编程数据，并进行分析。

Result: 发现新的可观察统计数据，如代码删除率在条件语句内外相似、三分之一被注释的代码最终恢复，以及代码跳转频率不一定反映困难。

Conclusion: 这项研究通过开发首个算法来跟踪解析树节点，为理解学生编程行为的新维度（如代码结构发展、重构行为等）打开了大门。

Abstract: Background and Context: Programming process data can be utilized to
understand the processes students use to write computer programming
assignments. Keystroke- and line-level event logs have been used in the past in
various ways, primarily in high-level descriptive statistics (e.g., timings,
character deletion rate, etc). Analysis of behavior in context (e.g., how much
time students spend working on loops) has been cumbersome because of our
inability to automatically track high-level code representations, such as
abstract syntax trees, through time and unparseable states.
  Objective: Our study has two goals. The first is to design the first
algorithm that tracks parse tree nodes through time. Second, we utilize this
algorithm to perform a partial replication study of prior work that used manual
tracking of code representations, as well as other novel analyses of student
programming behavior that can now be done at scale.
  Method: We use two algorithms presented in this paper to track parse tree
nodes through time and construct tree representations for unparseable code
states. We apply these algorithms to a public keystroke data from student
coursework in a 2021 CS1 course and conduct analysis on the resulting parse
trees.
  Findings: We discover newly observable statistics at scale, including that
code is deleted at similar rates inside and outside of conditionals and loops,
a third of commented out code is eventually restored, and that frequency with
which students jump around in their code may not be indicative of struggle.
  Implications: The ability to track parse trees through time opens the door to
understanding new dimensions of student programming, such as best practices of
structural development of code over time, quantitative measurement of what
syntactic constructs students struggle most with, refactoring behavior, and
attention shifting within the code.

</details>


### [74] [Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems](https://arxiv.org/abs/2509.03848)
*Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago*

Main category: cs.SE

TL;DR: 该研究提出了SECO-TransDX模型，系统化透明度与开发者体验的关系，为SECO的可持续发展提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 透明度是影响开发者对软件生态系统（SECO）感知和互动的关键因素，但其与开发者体验（DX）的关系尚未系统化。

Method: 通过德尔菲研究（Delphi study）与学术界和工业界专家合作，构建并完善了SECO-TransDX概念模型。

Result: 提出了SECO-TransDX模型，包含63个相互关联的概念，揭示了透明度在开发者交互中的感知与构建机制。

Conclusion: SECO-TransDX模型为研究者和从业者提供了一个结构化视角，以理解透明度如何在不同层面调节开发者体验，并为未来研究和工具开发奠定了基础。

Abstract: Software ecosystems (SECO) have become a dominant paradigm in the software
industry, enabling third-party developers to co-create value through
complementary components and services. While Developer Experience (DX) is
increasingly recognized as critical for sustainable SECO, transparency remains
an underexplored factor shaping how developers perceive and interact with
ecosystems. Existing studies acknowledge transparency as essential for trust,
fairness, and engagement, yet its relationship with DX has not been
systematically conceptualized. Hence, this work aims to advance the
understanding of transparency in SECO from a developer-centered perspective. To
this end, we propose SECO-TransDX (Transparency in Software Ecosystems from a
Developer Experience Perspective), a conceptual model that introduces the
notion of DX-driven transparency. The model identifies 63 interrelated
concepts, including conditioning factors, ecosystem procedures, artifacts, and
relational dynamics that influence how transparency is perceived and
constructed during developer interactions. SECO-TransDX was built upon prior
research and refined through a Delphi study with experts from academia and
industry. It offers a structured lens to examine how transparency mediates DX
across technical, social, and organizational layers. For researchers, it lays
the groundwork for future studies and tool development; for practitioners, it
supports the design of trustworthy, developer-centered platforms that improve
transparency and foster long-term engagement in SECO.

</details>


### [75] [VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report](https://arxiv.org/abs/2509.03875)
*Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang*

Main category: cs.SE

TL;DR: VulRTex是一种利用大型语言模型推理能力识别漏洞相关富文本问题报告的方法，实验表现优于基线，并成功应用于实际项目。


<details>
  <summary>Details</summary>
Motivation: 安全从业者需要大量时间手动识别漏洞相关的问题报告，时间差可能被攻击者利用。现有方法仅关注文本描述，缺乏对富文本信息的全面分析。

Method: VulRTex首先利用大型语言模型的推理能力准备漏洞推理数据库，然后通过检索相关案例生成推理指导，分析目标问题报告的富文本信息。

Result: VulRTex在973,572个问题报告上实验，表现最佳：F1提高11.0%，AUPRC提高20.2%，Macro-F1提高10.5%，时间成本降低2倍。成功识别2024年GitHub问题报告中的30个新兴漏洞，其中11个获得CVE-ID。

Conclusion: VulRTex通过结合大型语言模型的推理能力和历史问题报告数据库，有效识别漏洞相关的问题报告，并在不平衡数据集上表现出色，具有实际应用价值。

Abstract: Software vulnerabilities exist in open-source software (OSS), and the
developers who discover these vulnerabilities may submit issue reports (IRs) to
describe their details. Security practitioners need to spend a lot of time
manually identifying vulnerability-related IRs from the community, and the time
gap may be exploited by attackers to harm the system. Previously, researchers
have proposed automatic approaches to facilitate identifying these
vulnerability-related IRs, but these works focus on textual descriptions but
lack the comprehensive analysis of IR's rich-text information. In this paper,
we propose VulRTex, a reasoning-guided approach to identify
vulnerability-related IRs with their rich-text information. In particular,
VulRTex first utilizes the reasoning ability of the Large Language Model (LLM)
to prepare the Vulnerability Reasoning Database with historical IRs. Then, it
retrieves the relevant cases from the prepared reasoning database to generate
reasoning guidance, which guides LLM to identify vulnerabilities by reasoning
analysis on target IRs' rich-text information. To evaluate the performance of
VulRTex, we conduct experiments on 973,572 IRs, and the results show that
VulRTex achieves the highest performance in identifying the
vulnerability-related IRs and predicting CWE-IDs when the dataset is
imbalanced, outperforming the best baseline with +11.0% F1, +20.2% AUPRC, and
+10.5% Macro-F1, and 2x lower time cost than baseline reasoning approaches.
Furthermore, VulRTex has been applied to identify 30 emerging vulnerabilities
across 10 representative OSS projects in 2024's GitHub IRs, and 11 of them are
successfully assigned CVE-IDs, which illustrates VulRTex's practicality.

</details>


### [76] [Vulnerability-Affected Versions Identification: How Far Are We?](https://arxiv.org/abs/2509.03876)
*Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo*

Main category: cs.SE

TL;DR: 本文首次全面实证研究了漏洞影响版本识别，评估了12种工具，发现准确率最高仅45.0%，集成策略可提升至60.0%，但需新方法。


<details>
  <summary>Details</summary>
Motivation: 识别哪些软件版本受到漏洞影响对于修补和风险缓解至关重要。尽管工具越来越多，但由于评估范围狭窄（通常仅限于早期SZZ变体、过时技术和小型或粗粒度数据集），它们在现实世界中的有效性仍不明确。

Method: 我们策划了一个包含1,128个真实世界C/C++漏洞的高质量基准，并系统地评估了12种代表性工具，涵盖四个维度：漏洞和版本级别的有效性、假阳性和假阴性的根本原因、对补丁特性的敏感性以及集成潜力。

Result: 研究发现存在根本性限制：没有工具的准确率超过45.0%，主要挑战来自于启发式依赖、有限的语义推理和僵化的匹配逻辑。补丁结构（如仅添加和跨文件更改）进一步阻碍了性能。

Conclusion: 尽管集成策略可以将结果提高至10.1%，但总体准确率仍低于60.0%，这表明需要从根本上新的方法。

Abstract: Identifying which software versions are affected by a vulnerability is
critical for patching, risk mitigation.Despite a growing body of tools, their
real-world effectiveness remains unclear due to narrow evaluation scopes often
limited to early SZZ variants, outdated techniques, and small or
coarse-graineddatasets. In this paper, we present the first comprehensive
empirical study of vulnerability affected versions identification. We curate a
high quality benchmark of 1,128 real-world C/C++ vulnerabilities and
systematically evaluate 12 representative tools from both tracing and matching
paradigms across four dimensions: effectiveness at both vulnerability and
version levels, root causes of false positives and negatives, sensitivity to
patch characteristics, and ensemble potential. Our findings reveal fundamental
limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from
heuristic dependence, limited semantic reasoning, and rigid matching logic.
Patch structures such as add-only and cross-file changes further hinder
performance. Although ensemble strategies can improve results by up to 10.1%,
overall accuracy remains below 60.0%, highlighting the need for fundamentally
new approaches. Moreover, our study offers actionable insights to guide tool
development, combination strategies, and future research in this critical area.
Finally, we release the replicated code and benchmark on our website to
encourage future contributions.outdated techniques, and small or coarse grained
datasets.

</details>


### [77] [Analyzing Variations in Dependency Distributions Due to Code Smell Interactions](https://arxiv.org/abs/2509.03896)
*Zushuai Zhang,Elliott Wen,Ewan Tempero*

Main category: cs.SE

TL;DR: 研究发现相互作用的代码异味会增加模块间依赖，建议开发者优先处理这类异味。


<details>
  <summary>Details</summary>
Motivation: 理解导致模块间依赖增加的代码异味相互作用，以优化软件维护。

Method: 对116个开源Java系统进行了依赖分析，量化了代码异味之间的相互作用，并与非代码异味进行了比较。

Result: 代码异味对的相互作用与某些依赖的增加和其他依赖的减少相关，但总体上与总依赖的增加相关。例如，Feature Envy方法与Data类之间的依赖中位数是非Feature Envy方法的7倍。

Conclusion: 开发者应优先处理相互作用的代码异味，而非孤立的代码异味，因为它们会显著增加模块间的依赖关系。

Abstract: The existence of dependencies between modules, such as classes, can mean that
changing a module triggers ripple effects that make maintenance complex and
costly, so the advice is to minimize dependencies between modules. It is
therefore important to understand the circumstances that can lead to increased
dependencies. Recent studies suggest that code smells, which are
characteristics of code that indicate potential design issues, may interact in
ways that increase dependencies between modules. In this study, we aim to
confirm previous observations and investigate whether and how the distribution
of static dependencies changes in the presence of code smell interactions. We
conducted a dependency analysis on 116 open-source Java systems to quantify the
interactions, comparing interactions among code smells and interactions between
code smells and non-code smells. Our results suggest that while interactions
between code smell pairs are associated with increases in certain dependencies
and decreases in others, overall, they are associated with an increase in total
dependencies. For example, the median number of dependencies between Feature
Envy methods and Data Classes is seven times as many as when the methods are
non-Feature Envy methods, increasing from 1 to 7. This implies that developers
should prioritize addressing code smells that interact with each other, rather
than code smells that exist only in isolation.

</details>


### [78] [The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications](https://arxiv.org/abs/2509.03900)
*Yuvraj Agrawal*

Main category: cs.SE

TL;DR: 本文提出Auth Shim架构模式，解决开源工具缺乏企业级安全协议支持的问题，通过案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 开源软件在企业环境中广泛采用，但独立工具通常缺乏对SAML或OIDC等协议的原生支持，导致关键的安全集成缺口。

Method: Auth Shim是一种极简的外部代理服务，作为兼容层，将企业身份提供者（IdP）的请求转换为目标应用程序的原生会话管理机制。

Result: 通过Adobe的案例研究，展示了该模式在集成流行的开源BI工具与Okta SAML中的成功应用，实现了基于IAM组映射的自动化角色访问控制（RBAC），并消除了手动用户配置。

Conclusion: 本文提出了Auth Shim这一轻量级架构模式，为企业提供了一个可重用、安全且经济高效的蓝图，用于将独立开源工具集成到企业单点登录生态系统中，从而在不牺牲安全治理的前提下拥抱开源创新。

Abstract: Open-source software OSS is widely adopted in enterprise settings, but
standalone tools often lack native support for protocols like SAML or OIDC,
creating a critical security integration gap. This paper introduces and
formalizes the Auth Shim, a lightweight architectural pattern designed to solve
this problem. The Auth Shim is a minimal, external proxy service that acts as a
compatibility layer, translating requests from an enterprise Identity Provider
IdP into the native session management mechanism of a target application. A key
prerequisite for this pattern is that the target application must expose a
programmatic, secure administrative API. We present a case study of the
pattern's implementation at Adobe to integrate a popular OSS BI tool with Okta
SAML, which enabled automated Role-Based Access Control RBAC via IAM group
mapping and eliminated manual user provisioning. By defining its components,
interactions, and production deployment considerations, this paper provides a
reusable, secure, and cost-effective blueprint for integrating any standalone
OSS tool into an enterprise SSO ecosystem, thereby enabling organizations to
embrace open-source innovation without compromising on security governance.

</details>


### [79] [RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models](https://arxiv.org/abs/2509.04078)
*Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang*

Main category: cs.SE

TL;DR: 论文介绍了RepoDebug数据集，用于评估大型语言模型在仓库级代码调试中的表现，发现现有模型在此任务中仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有调试数据集主要关注函数级代码修复能力，忽视了更复杂和现实的仓库级场景，导致对大型语言模型在仓库级调试中挑战的理解不完整。

Method: 本文提出了RepoDebug，一个多任务、多语言的仓库级代码调试数据集，包含22种错误子类型，支持8种常用编程语言和3种调试任务。并对10种大型语言模型进行了评估实验。

Result: 实验表明，性能最佳的Claude 3.5 Sonnect在仓库级调试任务中仍表现不佳。

Conclusion: 尽管Claude 3.5 Sonnect在代码调试任务中表现最佳，但大型语言模型在仓库级调试中仍面临显著挑战。RepoDebug数据集的引入为评估和改进模型性能提供了更全面的基准。

Abstract: Large Language Models (LLMs) have exhibited significant proficiency in code
debugging, especially in automatic program repair, which may substantially
reduce the time consumption of developers and enhance their efficiency.
Significant advancements in debugging datasets have been made to promote the
development of code debugging. However, these datasets primarily focus on
assessing the LLM's function-level code repair capabilities, neglecting the
more complex and realistic repository-level scenarios, which leads to an
incomplete understanding of the LLM's challenges in repository-level debugging.
While several repository-level datasets have been proposed, they often suffer
from limitations such as limited diversity of tasks, languages, and error
types. To mitigate this challenge, this paper introduces RepoDebug, a
multi-task and multi-language repository-level code debugging dataset with 22
subtypes of errors that supports 8 commonly used programming languages and 3
debugging tasks. Furthermore, we conduct evaluation experiments on 10 LLMs,
where Claude 3.5 Sonnect, the best-performing model, still cannot perform well
in repository-level debugging.

</details>


### [80] [An Empirical Study of Vulnerabilities in Python Packages and Their Detection](https://arxiv.org/abs/2509.04260)
*Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du*

Main category: cs.SE

TL;DR: 本文提出PyVul，首个全面的Python包漏洞基准套件，揭示了现有检测工具的不足，并强调多语言环境下漏洞识别的挑战。


<details>
  <summary>Details</summary>
Motivation: Python包的漏洞问题日益突出，但现有漏洞检测工具的有效性尚未充分探索。Python作为脚本语言常与其他语言协作，增加了漏洞的复杂性，亟需一个全面的基准套件来评估和改进检测工具。

Method: 本文提出了PyVul，一个全面的Python包漏洞基准套件，包含1,157个公开报告且经开发者验证的漏洞。通过LLM辅助的数据清洗方法，提高了标签准确性，并在提交和函数级别提供注释。

Result: PyVul成为最精确的大规模Python漏洞基准，提交和函数级别的标签准确率分别达到100%和94%。分析显示，多语言Python包更易受漏洞影响，且现有检测工具的能力与实际需求存在显著差距。

Conclusion: 本文通过引入PyVul，填补了Python包漏洞检测工具的空白，并揭示了现有工具在识别真实世界安全问题时的显著差距。未来研究需要进一步改进检测技术，特别是在多语言环境下的漏洞识别。

Abstract: In the rapidly evolving software development landscape, Python stands out for
its simplicity, versatility, and extensive ecosystem. Python packages, as units
of organization, reusability, and distribution, have become a pressing concern,
highlighted by the considerable number of vulnerability reports. As a scripting
language, Python often cooperates with other languages for performance or
interoperability. This adds complexity to the vulnerabilities inherent to
Python packages, and the effectiveness of current vulnerability detection tools
remains underexplored. This paper addresses these gaps by introducing PyVul,
the first comprehensive benchmark suite of Python-package vulnerabilities.
PyVul includes 1,157 publicly reported, developer-verified vulnerabilities,
each linked to its affected packages. To accommodate diverse detection
techniques, it provides annotations at both commit and function levels. An
LLM-assisted data cleansing method is incorporated to improve label accuracy,
achieving 100% commit-level and 94% function-level accuracy, establishing PyVul
as the most precise large-scale Python vulnerability benchmark. We further
carry out a distribution analysis of PyVul, which demonstrates that
vulnerabilities in Python packages involve multiple programming languages and
exhibit a wide variety of types. Moreover, our analysis reveals that
multi-lingual Python packages are potentially more susceptible to
vulnerabilities. Evaluation of state-of-the-art detectors using this benchmark
reveals a significant discrepancy between the capabilities of existing tools
and the demands of effectively identifying real-world security issues in Python
packages. Additionally, we conduct an empirical review of the top-ranked CWEs
observed in Python packages, to diagnose the fine-grained limitations of
current detection tools and highlight the necessity for future advancements in
the field.

</details>


### [81] [FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study](https://arxiv.org/abs/2509.04328)
*Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar*

Main category: cs.SE

TL;DR: FaaSGuard 是一个针对开源无服务器环境的统一 DevSecOps 管道，通过嵌入安全检查显著提升了安全性，且不影响现有 CI/CD 流程。


<details>
  <summary>Details</summary>
Motivation: 无服务器计算的安全挑战，尤其是开源平台如 OpenFaaS 的独特特性，需要一种集成的安全策略。

Method: 通过在每个开发阶段（规划、编码、构建、部署和监控）嵌入轻量级的安全检查，FaaSGuard 系统性地应对了多种安全威胁。

Result: FaaSGuard 在 20 个真实无服务器函数中表现出高精度（95%）和召回率（91%），有效检测和预防关键漏洞。

Conclusion: FaaSGuard 提供了一种统一的 DevSecOps 管道，显著提升了开源无服务器环境的安全性，且不影响现有 CI/CD 流程。

Abstract: Serverless computing significantly alters software development by abstracting
infrastructure management and enabling rapid, modular, event-driven
deployments. Despite its benefits, the distinct characteristics of serverless
functions, such as ephemeral execution and fine-grained scalability, pose
unique security challenges, particularly in open-source platforms like
OpenFaaS. Existing approaches typically address isolated phases of the
DevSecOps lifecycle, lacking an integrated and comprehensive security strategy.
To bridge this gap, we propose FaaSGuard, a unified DevSecOps pipeline
explicitly designed for open-source serverless environments. FaaSGuard
systematically embeds lightweight, fail-closed security checks into every stage
of the development lifecycle-planning, coding, building, deployment, and
monitoring-effectively addressing threats such as injection attacks, hard-coded
secrets, and resource exhaustion. We validate our approach empirically through
a case study involving 20 real-world serverless functions from public GitHub
repositories. Results indicate that FaaSGuard effectively detects and prevents
critical vulnerabilities, demonstrating high precision (95%) and recall (91%)
without significant disruption to established CI/CD practices.

</details>


### [82] [Design and Development of a Web Platform for Blood Donation Management](https://arxiv.org/abs/2509.04423)
*Fatima Zulfiqar Ali,Atrooba Ilyas*

Main category: cs.SE

TL;DR: 该论文设计并开发了一个基于网络的献血平台，通过集中管理献血者和患者信息，提高了紧急情况下的献血效率和可及性。


<details>
  <summary>Details</summary>
Motivation: 献血是医疗保健的重要组成部分，但在紧急情况下寻找合适的献血者常常面临重大挑战。

Method: 平台设计采用了用例图、数据库图、类图和序列图，确保系统架构的合理性和高效性。技术实现上使用了PHP（Laravel框架）、HTML、CSS、Bootstrap和MySQL，支持平台动态交互和用户友好性。

Result: 开发了一个动态、交互式且用户友好的献血网络平台，能够连接患者、献血者和管理员，优化献血服务流程。

Conclusion: 该论文提出的献血网络平台通过数字化集中管理，有效减少了紧急情况下的献血延迟和复杂性，提高了献血服务的整体效率。

Abstract: Blood donation is a critical component of healthcare, yet locating suitable
donors in emergencies often presents significant challenges. This paper
presents the design and development of a Blood Donation Web Platform, a
web-based system that connects patients, donors, and administrators within a
centralized digital space. The platform allows interested donors to register
their personal information, including blood group, contact details, and
availability. Patients can search for donors based on blood group and location,
and the system provides a list of nearby donors who are ready to donate. The
platform design was guided by use case, database, class, and sequence diagrams
to ensure a well-structured and efficient system architecture. Modern web
technologies, including PHP (Laravel framework), HTML, CSS, Bootstrap, and
MySQL, supported by XAMPP and Visual Studio Code, were employed to implement a
dynamic, interactive, and user-friendly platform. By streamlining donor
refgistration, blood requests, and communication, the proposed system reduces
delays and complexities in emergencies, improving timely accessibility of blood
and enhancing overall efficiency in blood donation services.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [83] [PG-Agent: An Agent Powered by Page Graph](https://arxiv.org/abs/2509.03536)
*Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang*

Main category: cs.AI

TL;DR: PG-Agent通过页面图和RAG技术提升GUI代理的泛化能力，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理无法捕捉页面间的复杂转换关系，导致对新场景的泛化能力不足。

Method: 设计了一个自动化流程将顺序事件转换为页面图，并引入RAG技术检索感知指南，采用多代理框架PG-Agent进行任务分解。

Result: 在多个基准测试中，PG-Agent表现出色，即使构建数据有限。

Conclusion: PG-Agent通过页面图和RAG技术的结合，有效提升了GUI代理的泛化能力，即使在有限的构建数据下也表现出色。

Abstract: Graphical User Interface (GUI) agents possess significant commercial and
social value, and GUI agents powered by advanced multimodal large language
models (MLLMs) have demonstrated remarkable potential. Currently, existing GUI
agents usually utilize sequential episodes of multi-step operations across
pages as the prior GUI knowledge, which fails to capture the complex transition
relationship between pages, making it challenging for the agents to deeply
perceive the GUI environment and generalize to new scenarios. Therefore, we
design an automated pipeline to transform the sequential episodes into page
graphs, which explicitly model the graph structure of the pages that are
naturally connected by actions. To fully utilize the page graphs, we further
introduce Retrieval-Augmented Generation (RAG) technology to effectively
retrieve reliable perception guidelines of GUI from them, and a tailored
multi-agent framework PG-Agent with task decomposition strategy is proposed to
be injected with the guidelines so that it can generalize to unseen scenarios.
Extensive experiments on various benchmarks demonstrate the effectiveness of
PG-Agent, even with limited episodes for page graph construction.

</details>


### [84] [Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models](https://arxiv.org/abs/2509.03548)
*João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman*

Main category: cs.AI

TL;DR: 论文提出了一种新算法，通过列生成技术简化多线性规划构建，计算准马尔可夫因果模型中的紧概率边界，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究在准马尔可夫因果模型中，内生变量可观测而外生变量未完全指定时，如何计算紧概率边界的问题。传统方法使用多线性规划或线性规划，但存在复杂性高的问题。

Method: 论文研究了部分可识别查询的计算方法，提出了一种新算法，通过列生成技术计算概率边界，利用辅助线性整数程序序列，简化了多线性规划的构建。

Result: 论文展示了在单一干预情况下，外生变量多项式基数表示的可能性，并通过实验验证了列生成技术的优越性。

Conclusion: 论文提出了一种新的算法，通过利用内生变量的输入概率简化了多线性规划的构建，展示了在单一干预情况下，外生变量多项式基数表示的可能性。实验表明列生成技术优于现有方法。

Abstract: We investigate partially identifiable queries in a class of causal models. We
focus on acyclic Structural Causal Models that are quasi-Markovian (that is,
each endogenous variable is connected with at most one exogenous confounder).
We look into scenarios where endogenous variables are observed (and a
distribution over them is known), while exogenous variables are not fully
specified. This leads to a representation that is in essence a Bayesian network
where the distribution of root variables is not uniquely determined. In such
circumstances, it may not be possible to precisely compute a probability value
of interest. We thus study the computation of tight probability bounds, a
problem that has been solved by multilinear programming in general, and by
linear programming when a single confounded component is intervened upon. We
present a new algorithm to simplify the construction of such programs by
exploiting input probabilities over endogenous variables. For scenarios with a
single intervention, we apply column generation to compute a probability bound
through a sequence of auxiliary linear integer programs, thus showing that a
representation with polynomial cardinality for exogenous variables is possible.
Experiments show column generation techniques to be superior to existing
methods.

</details>


### [85] [Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method](https://arxiv.org/abs/2509.03550)
*Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang*

Main category: cs.AI

TL;DR: Diffusion-AC通过扩散概率模型和多模态决策能力，显著提升了空中交通冲突解决的成功率和安全性，尤其在密集交通场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在冲突检测与解决（CD&R）中存在"单模态偏差"，导致决策灵活性不足，容易出现"决策僵局"。为解决这一问题，本文探索将扩散概率模型引入CD&R任务。

Method: 提出了一种名为Diffusion-AC的新型自主冲突解决框架，结合扩散概率模型和价值函数引导的反向去噪过程，生成高质量的多模态动作分布。此外，还引入了Density-Progressive Safety Curriculum（DPSC）训练机制，确保学习稳定性和效率。

Result: 在模拟实验中，Diffusion-AC在最具挑战性的高密度场景中保持了94.1%的高成功率，并将近空中碰撞（NMACs）的发生率降低了约59%，显著提升了系统安全边际。

Conclusion: Diffusion-AC框架通过其多模态决策能力，显著提升了冲突检测与解决的成功率和安全性，尤其在高度密集的空中交通场景中表现突出。

Abstract: In the context of continuously rising global air traffic, efficient and safe
Conflict Detection and Resolution (CD&R) is paramount for air traffic
management. Although Deep Reinforcement Learning (DRL) offers a promising
pathway for CD&R automation, existing approaches commonly suffer from a
"unimodal bias" in their policies. This leads to a critical lack of
decision-making flexibility when confronted with complex and dynamic
constraints, often resulting in "decision deadlocks." To overcome this
limitation, this paper pioneers the integration of diffusion probabilistic
models into the safety-critical task of CD&R, proposing a novel autonomous
conflict resolution framework named Diffusion-AC. Diverging from conventional
methods that converge to a single optimal solution, our framework models its
policy as a reverse denoising process guided by a value function, enabling it
to generate a rich, high-quality, and multimodal action distribution. This core
architecture is complemented by a Density-Progressive Safety Curriculum (DPSC),
a training mechanism that ensures stable and efficient learning as the agent
progresses from sparse to high-density traffic environments. Extensive
simulation experiments demonstrate that the proposed method significantly
outperforms a suite of state-of-the-art DRL benchmarks. Most critically, in the
most challenging high-density scenarios, Diffusion-AC not only maintains a high
success rate of 94.1% but also reduces the incidence of Near Mid-Air Collisions
(NMACs) by approximately 59% compared to the next-best-performing baseline,
significantly enhancing the system's safety margin. This performance leap stems
from its unique multimodal decision-making capability, which allows the agent
to flexibly switch to effective alternative maneuvers.

</details>


### [86] [Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents](https://arxiv.org/abs/2509.03581)
*Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel*

Main category: cs.AI

TL;DR: A framework for dynamic planning in LLM agents improves efficiency and performance by deciding when to plan, validated in experiments.


<details>
  <summary>Details</summary>
Motivation: Existing methods like ReAct prompt LLMs to always plan before every action, which is computationally expensive and degrades performance on long-horizon tasks, while never planning limits performance.

Method: A two-stage training pipeline: (1) supervised fine-tuning on diverse synthetic data to prime models for dynamic planning, and (2) RL to refine this capability in long-horizon environments.

Result: Experiments show dynamic planning agents are more sample-efficient and achieve more complex objectives. They can also be effectively steered by human-written plans, surpassing independent capabilities.

Conclusion: This work pioneers training LLM agents for dynamic test-time compute allocation in sequential decision-making tasks, leading to more efficient, adaptive, and controllable agentic systems.

Abstract: Training large language models (LLMs) to reason via reinforcement learning
(RL) significantly improves their problem-solving capabilities. In agentic
settings, existing methods like ReAct prompt LLMs to explicitly plan before
every action; however, we demonstrate that always planning is computationally
expensive and degrades performance on long-horizon tasks, while never planning
further limits performance. To address this, we introduce a conceptual
framework formalizing dynamic planning for LLM agents, enabling them to
flexibly decide when to allocate test-time compute for planning. We propose a
simple two-stage training pipeline: (1) supervised fine-tuning on diverse
synthetic data to prime models for dynamic planning, and (2) RL to refine this
capability in long-horizon environments. Experiments on the Crafter environment
show that dynamic planning agents trained with this approach are more
sample-efficient and consistently achieve more complex objectives.
Additionally, we demonstrate that these agents can be effectively steered by
human-written plans, surpassing their independent capabilities. To our
knowledge, this work is the first to explore training LLM agents for dynamic
test-time compute allocation in sequential decision-making tasks, paving the
way for more efficient, adaptive, and controllable agentic systems.

</details>


### [87] [Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE](https://arxiv.org/abs/2509.03626)
*Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker*

Main category: cs.AI

TL;DR: KG-SMILE框架通过扰动分析和加权线性模型，提升了RAG的透明度和可信度，适用于需高精度的领域如医疗保健。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG在提升生成准确性方面表现优异，但其不透明性和对数据质量的依赖性限制了在敏感领域的可靠性。

Method: 开发了一种基于扰动的、方法无关的框架KG-SMILE，通过控制扰动、计算相似性和训练加权线性替代模型，识别对生成输出最具影响力的图实体和关系。

Result: KG-SMILE在全面的归因指标（如保真度、忠实性、一致性、稳定性和准确性）上表现优异，能够生成稳定且与人类认知一致的解释。

Conclusion: KG-SMILE框架通过提供token和组件级的可解释性，显著提升了RAG的透明度，从而在保持模型效果的同时增强了机器学习技术的可信度。

Abstract: Generative AI, such as Large Language Models (LLMs), has achieved impressive
progress but still produces hallucinations and unverifiable claims, limiting
reliability in sensitive domains. Retrieval-Augmented Generation (RAG) improves
accuracy by grounding outputs in external knowledge, especially in domains like
healthcare, where precision is vital. However, RAG remains opaque and
essentially a black box, heavily dependent on data quality. We developed a
method-agnostic, perturbation-based framework that provides token and
component-level interoperability for Graph RAG using SMILE and named it as
Knowledge-Graph (KG)-SMILE. By applying controlled perturbations, computing
similarities, and training weighted linear surrogates, KG-SMILE identifies the
graph entities and relations most influential to generated outputs, thereby
making RAG more transparent. We evaluate KG-SMILE using comprehensive
attribution metrics, including fidelity, faithfulness, consistency, stability,
and accuracy. Our findings show that KG-SMILE produces stable, human-aligned
explanations, demonstrating its capacity to balance model effectiveness with
interpretability and thereby fostering greater transparency and trust in
machine learning technologies.

</details>


### [88] [CausalARC: Abstract Reasoning with Causal World Models](https://arxiv.org/abs/2509.03636)
*Jacqueline Maasch,John Kalantari,Kia Khezeli*

Main category: cs.AI

TL;DR: CausalARC是一个用于评估AI在低数据和分布外情况下推理能力的测试平台，基于结构因果模型，成功应用于多种评估设置。


<details>
  <summary>Details</summary>
Motivation: 为了解决在有限数据和分布偏移情况下AI推理的适应性问题。

Method: 通过从完全指定的因果世界模型中采样任务，并利用结构因果模型进行形式化表达，结合数据增强技术提供观察、干预和反事实反馈。

Result: CausalARC成功应用于四种语言模型评估设置，包括抽象推理、反事实推理、程序合成和因果发现。

Conclusion: CausalARC提供了一个实验性测试平台，用于评估AI在低数据和分布外情况下的推理能力，展示了其在多种语言模型评估设置中的实用性。

Abstract: Reasoning requires adaptation to novel problem settings under limited data
and distribution shift. This work introduces CausalARC: an experimental testbed
for AI reasoning in low-data and out-of-distribution regimes, modeled after the
Abstraction and Reasoning Corpus (ARC). Each CausalARC reasoning task is
sampled from a fully specified causal world model, formally expressed as a
structural causal model. Principled data augmentations provide observational,
interventional, and counterfactual feedback about the world model in the form
of few-shot, in-context learning demonstrations. As a proof-of-concept, we
illustrate the use of CausalARC for four language model evaluation settings:
(1) abstract reasoning with test-time training, (2) counterfactual reasoning
with in-context learning, (3) program synthesis, and (4) causal discovery with
logical reasoning.

</details>


### [89] [Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations](https://arxiv.org/abs/2509.03644)
*François Olivier,Zied Bouraoui*

Main category: cs.AI

TL;DR: Embodied-LM通过图像模式的形式化表示增强语言模型的逻辑推理能力，实验证明其有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言理解方面取得了显著进展，但在逻辑推理方面仍存在不足，缺乏类似人类的稳健心理表征。

Method: 采用声明性空间推理（Answer Set Programming）将图像模式（源自感知运动经验的认知结构）形式化为可执行程序。

Result: 实验证明，该系统能够引导语言模型通过具体化的认知结构解释场景，并将这些结构形式化为可执行程序，从而支持更有效的逻辑推理和增强的可解释性。

Conclusion: 本文提出了一个名为Embodied-LM的神经符号系统，通过基于图像模式的模式化表示来增强语言模型的逻辑推理能力，并展示了其在逻辑推理任务中的有效性。

Abstract: Despite significant progress in natural language understanding, Large
Language Models (LLMs) remain error-prone when performing logical reasoning,
often lacking the robust mental representations that enable human-like
comprehension. We introduce a prototype neurosymbolic system, Embodied-LM, that
grounds understanding and logical reasoning in schematic representations based
on image schemas-recurring patterns derived from sensorimotor experience that
structure human cognition. Our system operationalizes the spatial foundations
of these cognitive structures using declarative spatial reasoning within Answer
Set Programming. Through evaluation on logical deduction problems, we
demonstrate that LLMs can be guided to interpret scenarios through embodied
cognitive structures, that these structures can be formalized as executable
programs, and that the resulting representations support effective logical
reasoning with enhanced interpretability. While our current implementation
focuses on spatial primitives, it establishes the computational foundation for
incorporating more complex and dynamic representations.

</details>


### [90] [Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning](https://arxiv.org/abs/2509.03646)
*Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen*

Main category: cs.AI

TL;DR: 论文揭示了强化学习在提升大型语言模型复杂推理能力中的两阶段动态机制，并提出了一种新的层次感知信用分配算法HICRA，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习已证明能有效增强大型语言模型的复杂推理能力，但其成功背后的机制仍不明确。

Method: 通过分析强化学习中的现象（如“顿悟时刻”和长度缩放），提出了一种层次感知信用分配算法HICRA，专注于高影响力的规划令牌。

Result: HICRA算法显著优于现有基线，证实了关注战略瓶颈是解锁高级推理的关键。

Conclusion: 研究揭示了强化学习中推理层次结构的涌现现象，并验证了语义熵作为衡量战略探索的优越指标。

Abstract: Reinforcement Learning (RL) has proven highly effective at enhancing the
complex reasoning abilities of Large Language Models (LLMs), yet underlying
mechanisms driving this success remain largely opaque. Our analysis reveals
that puzzling phenomena like ``aha moments", ``length-scaling'' and entropy
dynamics are not disparate occurrences but hallmarks of an emergent reasoning
hierarchy, akin to the separation of high-level strategic planning from
low-level procedural execution in human cognition. We uncover a compelling
two-phase dynamic: initially, a model is constrained by procedural correctness
and must improve its low-level skills. The learning bottleneck then decisively
shifts, with performance gains being driven by the exploration and mastery of
high-level strategic planning. This insight exposes a core inefficiency in
prevailing RL algorithms like GRPO, which apply optimization pressure
agnostically and dilute the learning signal across all tokens. To address this,
we propose HIerarchy-Aware Credit Assignment (HICRA), an algorithm that
concentrates optimization efforts on high-impact planning tokens. HICRA
significantly outperforms strong baselines, demonstrating that focusing on this
strategic bottleneck is key to unlocking advanced reasoning. Furthermore, we
validate semantic entropy as a superior compass for measuring strategic
exploration over misleading metrics such as token-level entropy.

</details>


### [91] [An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification](https://arxiv.org/abs/2509.03649)
*Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim*

Main category: cs.AI

TL;DR: 研究探讨了时间序列分割对SHAP解释质量的影响，发现等长分段方法表现最佳，并提出了一种新的归因归一化技术以提升效果。


<details>
  <summary>Details</summary>
Motivation: 针对SHAP方法在长时间序列中计算复杂度高的问题，探索最优分割策略以提升解释质量。

Method: 本研究调查了八种不同的时间序列分割算法，并使用InterpretTime和AUC Difference两种XAI评估方法进行实验评估。

Result: 实验发现，分段数量对解释质量影响显著，等长分段方法表现优于多数自定义算法，且新提出的归因归一化技术能有效提升质量。

Conclusion: 研究表明，分段数量对解释质量的影响比具体分段方法更大，且等长分段方法在大多数情况下优于自定义时间序列分割算法。此外，引入的基于长度加权的新归一化技术能持续提升归因质量。

Abstract: Explainable AI (XAI) has become an increasingly important topic for
understanding and attributing the predictions made by complex Time Series
Classification (TSC) models. Among attribution methods, SHapley Additive
exPlanations (SHAP) is widely regarded as an excellent attribution method; but
its computational complexity, which scales exponentially with the number of
features, limits its practicality for long time series. To address this, recent
studies have shown that aggregating features via segmentation, to compute a
single attribution value for a group of consecutive time points, drastically
reduces SHAP running time. However, the choice of the optimal segmentation
strategy remains an open question. In this work, we investigated eight
different Time Series Segmentation algorithms to understand how segment
compositions affect the explanation quality. We evaluate these approaches using
two established XAI evaluation methodologies: InterpretTime and AUC Difference.
Through experiments on both Multivariate (MTS) and Univariate Time Series
(UTS), we find that the number of segments has a greater impact on explanation
quality than the specific segmentation method. Notably, equal-length
segmentation consistently outperforms most of the custom time series
segmentation algorithms. Furthermore, we introduce a novel attribution
normalisation technique that weights segments by their length and we show that
it consistently improves attribution quality.

</details>


### [92] [PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming](https://arxiv.org/abs/2509.03728)
*Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys*

Main category: cs.AI

TL;DR: PersonaTeaming是一种新颖的自动红队方法，通过引入人物角色在对抗性提示生成中，显著提高了攻击成功率并保持了多样性，为AI安全研究提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 当前自动红队方法未考虑人物角色背景和身份对红队策略的影响，限制了其对AI模型潜在风险的全面探索。本研究旨在填补这一空白，通过引入人物角色以提高对抗性提示的多样性和有效性。

Method: 研究开发了PersonaTeaming方法，通过人物角色在对抗性提示生成过程中的应用，包括基于‘红队专家’和‘普通AI用户’角色的提示变异方法，以及动态人物角色生成算法。此外，还开发了一套新的指标来测量‘变异距离’。

Result: 实验结果显示，PersonaTeaming在攻击成功率上相比现有最佳自动红队方法RainbowPlus有显著提升（最高达144.1%），同时保持了提示的多样性。不同人物角色类型和变异方法的优缺点也为未来研究提供了启示。

Conclusion: PersonaTeaming展示了通过引入人物角色在对抗性提示生成中，可以显著提高攻击成功率（最高达144.1%），同时保持提示多样性。该方法为未来探索自动化和人工红队方法的互补性提供了方向和机会。

Abstract: Recent developments in AI governance and safety research have called for
red-teaming methods that can effectively surface potential risks posed by AI
models. Many of these calls have emphasized how the identities and backgrounds
of red-teamers can shape their red-teaming strategies, and thus the kinds of
risks they are likely to uncover. While automated red-teaming approaches
promise to complement human red-teaming by enabling larger-scale exploration of
model behavior, current approaches do not consider the role of identity. As an
initial step towards incorporating people's background and identities in
automated red-teaming, we develop and evaluate a novel method, PersonaTeaming,
that introduces personas in the adversarial prompt generation process to
explore a wider spectrum of adversarial strategies. In particular, we first
introduce a methodology for mutating prompts based on either "red-teaming
expert" personas or "regular AI user" personas. We then develop a dynamic
persona-generating algorithm that automatically generates various persona types
adaptive to different seed prompts. In addition, we develop a set of new
metrics to explicitly measure the "mutation distance" to complement existing
diversity measurements of adversarial prompts. Our experiments show promising
improvements (up to 144.1%) in the attack success rates of adversarial prompts
through persona mutation, while maintaining prompt diversity, compared to
RainbowPlus, a state-of-the-art automated red-teaming method. We discuss the
strengths and limitations of different persona types and mutation methods,
shedding light on future opportunities to explore complementarities between
automated and human red-teaming approaches.

</details>


### [93] [The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs](https://arxiv.org/abs/2509.03730)
*Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez*

Main category: cs.AI

TL;DR: 研究发现LLM的性格表达与人类相似，但自我报告性格无法预测行为，角色注入对行为影响有限，强调了对齐和可解释性深入评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 理解LLM的性格模式对研究其行为一致性至关重要，但先前研究主要依赖简化的自我报告和启发式提示，缺乏行为验证。

Method: 本研究系统地分析了LLM性格的三个维度：(1)训练阶段中性格特征的动态出现与演变；(2)自我报告性格在行为任务中的预测效度；(3)针对性干预（如角色注入）对自我报告和行为的影响。

Result: 指令对齐显著稳定了性格表达并加强了与人类数据相似的关联，但自我报告性格无法可靠预测行为。角色注入能引导自我报告，但对行为影响有限。

Conclusion: 研究发现，指令对齐（如RLHF、指令调优）显著稳定了LLM的性格表达并加强了与人类数据相似的性格关联。然而，这些自我报告的性格并不能可靠地预测行为，且观察到的关联常与人类模式不同。角色注入虽然能有效引导自我报告，但对实际行为影响有限或不一致。研究挑战了关于LLM性格的假设，并强调了在对齐和可解释性方面进行更深入评估的必要性。

Abstract: Personality traits have long been studied as predictors of human
behavior.Recent advances in Large Language Models (LLMs) suggest similar
patterns may emerge in artificial systems, with advanced LLMs displaying
consistent behavioral tendencies resembling human traits like agreeableness and
self-regulation. Understanding these patterns is crucial, yet prior work
primarily relied on simplified self-reports and heuristic prompting, with
little behavioral validation. In this study, we systematically characterize LLM
personality across three dimensions: (1) the dynamic emergence and evolution of
trait profiles throughout training stages; (2) the predictive validity of
self-reported traits in behavioral tasks; and (3) the impact of targeted
interventions, such as persona injection, on both self-reports and behavior.
Our findings reveal that instructional alignment (e.g., RLHF, instruction
tuning) significantly stabilizes trait expression and strengthens trait
correlations in ways that mirror human data. However, these self-reported
traits do not reliably predict behavior, and observed associations often
diverge from human patterns. While persona injection successfully steers
self-reports in the intended direction, it exerts little or inconsistent effect
on actual behavior. By distinguishing surface-level trait expression from
behavioral consistency, our findings challenge assumptions about LLM
personality and underscore the need for deeper evaluation in alignment and
interpretability.

</details>


### [94] [Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation](https://arxiv.org/abs/2509.03736)
*James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang*

Main category: cs.AI

TL;DR: 研究发现LLM在内部一致性上存在显著问题，限制了其作为人类研究参与者的替代能力。


<details>
  <summary>Details</summary>
Motivation: 评估合成代理是否可以作为真实参与者的替代品，特别是在内部一致性方面的表现。

Method: 通过设计实验（a）揭示代理的内部状态和（b）在基本对话设置中检查代理行为，探索行为假设以评估代理的对话行为是否与其揭示的内部状态一致。

Result: 发现不同模型家族和规模的LLM存在显著内部不一致性。

Conclusion: 研究发现，尽管大语言模型（LLM）生成的响应可能与人类对应者匹配，但它们缺乏内部一致性，这限制了其在人类主题研究中准确替代真实参与者的能力。

Abstract: The impressive capabilities of Large Language Models (LLMs) have fueled the
notion that synthetic agents can serve as substitutes for real participants in
human-subject research. In an effort to evaluate the merits of this claim,
social science researchers have largely focused on whether LLM-generated survey
data corresponds to that of a human counterpart whom the LLM is prompted to
represent. In contrast, we address a more fundamental question: Do agents
maintain internal consistency, retaining similar behaviors when examined under
different experimental settings? To this end, we develop a study designed to
(a) reveal the agent's internal state and (b) examine agent behavior in a basic
dialogue setting. This design enables us to explore a set of behavioral
hypotheses to assess whether an agent's conversation behavior is consistent
with what we would expect from their revealed internal state. Our findings on
these hypotheses show significant internal inconsistencies in LLMs across model
families and at differing model sizes. Most importantly, we find that, although
agents may generate responses matching those of their human counterparts, they
fail to be internally consistent, representing a critical gap in their
capabilities to accurately substitute for real participants in human-subject
research. Our simulation code and data are publicly accessible.

</details>


### [95] [RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs](https://arxiv.org/abs/2509.03768)
*Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos*

Main category: cs.AI

TL;DR: RAGuard是一个增强的RAG框架，通过并行查询和单独检索预算确保技术深度和安全覆盖，显著提升安全召回率。


<details>
  <summary>Details</summary>
Motivation: 传统大型语言模型（LLM）在高度专业化或意外场景中表现不佳，而海上风电（OSW）维护对准确性和安全性要求极高。

Method: 通过并行查询两个索引并为知识和安全分配单独的检索预算，RAGuard确保技术深度和安全覆盖。SafetyClamp扩展通过获取更大的候选池并“硬钳制”确切的安全槽位来增强安全性。

Result: RAGuard和SafetyClamp将安全召回率从几乎0%提升至50%以上，同时保持技术召回率在60%以上。

Conclusion: RAGuard和SafetyClamp有望为关键维护环境中集成安全保证的LLM决策支持设立新标准。

Abstract: Accuracy and safety are paramount in Offshore Wind (OSW) maintenance, yet
conventional Large Language Models (LLMs) often fail when confronted with
highly specialised or unexpected scenarios. We introduce RAGuard, an enhanced
Retrieval-Augmented Generation (RAG) framework that explicitly integrates
safety-critical documents alongside technical manuals.By issuing parallel
queries to two indices and allocating separate retrieval budgets for knowledge
and safety, RAGuard guarantees both technical depth and safety coverage. We
further develop a SafetyClamp extension that fetches a larger candidate pool,
"hard-clamping" exact slot guarantees to safety. We evaluate across sparse
(BM25), dense (Dense Passage Retrieval) and hybrid retrieval paradigms,
measuring Technical Recall@K and Safety Recall@K. Both proposed extensions of
RAG show an increase in Safety Recall@K from almost 0\% in RAG to more than
50\% in RAGuard, while maintaining Technical Recall above 60\%. These results
demonstrate that RAGuard and SafetyClamp have the potential to establish a new
standard for integrating safety assurance into LLM-powered decision support in
critical maintenance contexts.

</details>


### [96] [Leveraging LLM-Based Agents for Intelligent Supply Chain Planning](https://arxiv.org/abs/2509.03811)
*Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen*

Main category: cs.AI

TL;DR: 该研究提出了一种基于LLM的供应链规划代理框架，通过京东的实际应用验证了其在提升效率和准确性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 供应链管理涉及多方实体和复杂流程，如何从电商平台角度收集数据、制定长期计划并动态调整，同时确保可解释性、效率和可靠性，是一个实际且具有挑战性的问题。

Method: 构建了一个能够理解领域知识、分解任务、利用或创建新工具的SCPA框架，并结合大型语言模型（LLM）技术进行动态调整。

Result: SCPA框架在实际应用中有效减少了人力投入，提高了准确性、库存可用性等关键指标。

Conclusion: 该研究通过在京东的实际场景中部署供应链规划代理（SCPA）框架，证明了LLM-agent在供应链管理中的可行性，有效降低了人力成本并提升了准确性、库存可用性等关键指标。

Abstract: In supply chain management, planning is a critical concept. The movement of
physical products across different categories, from suppliers to warehouse
management, to sales, and logistics transporting them to customers, entails the
involvement of many entities. It covers various aspects such as demand
forecasting, inventory management, sales operations, and replenishment. How to
collect relevant data from an e-commerce platform's perspective, formulate
long-term plans, and dynamically adjust them based on environmental changes,
while ensuring interpretability, efficiency, and reliability, is a practical
and challenging problem. In recent years, the development of AI technologies,
especially the rapid progress of large language models, has provided new tools
to address real-world issues. In this work, we construct a Supply Chain
Planning Agent (SCPA) framework that can understand domain knowledge,
comprehend the operator's needs, decompose tasks, leverage or create new tools,
and return evidence-based planning reports. We deploy this framework in
JD.com's real-world scenario, demonstrating the feasibility of LLM-agent
applications in the supply chain. It effectively reduced labor and improved
accuracy, stock availability, and other key metrics.

</details>


### [97] [Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning](https://arxiv.org/abs/2509.03817)
*Wei Yang,Jesse Thomason*

Main category: cs.AI

TL;DR: 该论文提出MPDF框架和SoftRankPO算法，通过动态元认知策略提升多智能体LLM系统的推理能力，实验显示性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多智能体LLM系统的固定协作协议限制了其内部审议能力，导致无法根据认知状态（如不确定性或信心）动态调整策略。

Method: 研究者开发了Meta-Policy Deliberation Framework (MPDF) 和 SoftRankPO算法，后者通过平滑正态分位数映射奖励排名来稳定训练。

Result: MPDF与SoftRankPO在五个数学和通用推理基准测试中，相比六种最先进的启发式和基于学习的多智能体推理算法，平均准确率绝对提升了4-5%。

Conclusion: 该研究提出了一种新的多智能体LLM系统范式，通过动态学习元认知策略而非固定协议，显著提升了复杂推理任务的性能。

Abstract: Multi-agent systems of large language models (LLMs) show promise for complex
reasoning, but their effectiveness is often limited by fixed collaboration
protocols. These frameworks typically focus on macro-level orchestration while
overlooking agents' internal deliberative capabilities. This critical
meta-cognitive blindspot treats agents as passive executors unable to adapt
their strategy based on internal cognitive states like uncertainty or
confidence. We introduce the Meta-Policy Deliberation Framework (MPDF), where
agents learn a decentralized policy over a set of high-level meta-cognitive
actions: Persist, Refine, and Concede. To overcome the instability of
traditional policy gradients in this setting, we develop SoftRankPO, a novel
reinforcement learning algorithm. SoftRankPO stabilizes training by shaping
advantages based on the rank of rewards mapped through smooth normal quantiles,
making the learning process robust to reward variance. Experiments show that
MPDF with SoftRankPO achieves a a 4-5% absolute gain in average accuracy across
five mathematical and general reasoning benchmarks compared to six
state-of-the-art heuristic and learning-based multi-agent reasoning algorithms.
Our work presents a paradigm for learning adaptive, meta-cognitive policies for
multi-agent LLM systems, shifting the focus from designing fixed protocols to
learning dynamic, deliberative strategies.

</details>


### [98] [What Would an LLM Do? Evaluating Policymaking Capabilities of Large Language Models](https://arxiv.org/abs/2509.03827)
*Pierre Le Coz,Jia An Liu,Debarun Bhattacharjya,Georgina Curto,Serge Stinckwich*

Main category: cs.AI

TL;DR: 研究评估了大型语言模型在无家可归者缓解政策制定中的潜力，开发了多地理基准和自动化流程，结果显示LLMs在负责任使用下可提供有价值的政策见解。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否与领域专家（及其自身）一致，以支持无家可归者缓解这一全球影响超过1.5亿人的社会政策制定。

Method: 开发了一个包含四个地理区域（美国南本德、西班牙巴塞罗那、南非约翰内斯堡、中国澳门特别行政区）决策场景的新基准，并提出了一个将基准政策与基于代理的模型连接的自动化流程。

Result: 论文结果显示，利用LLMs进行社会政策制定具有潜力。

Conclusion: 大型语言模型（LLMs）在引入负责任的安全措施和与当地领域专家合作的情境校准后，能够为人类提供有价值的见解，以规模化的替代政策形式支持社会政策制定。

Abstract: Large language models (LLMs) are increasingly being adopted in high-stakes
domains. Their capacity to process vast amounts of unstructured data, explore
flexible scenarios, and handle a diversity of contextual factors can make them
uniquely suited to provide new insights for the complexity of social
policymaking. This article evaluates whether LLMs' are aligned with domain
experts (and among themselves) to inform social policymaking on the subject of
homelessness alleviation - a challenge affecting over 150 million people
worldwide. We develop a novel benchmark comprised of decision scenarios with
policy choices across four geographies (South Bend, USA; Barcelona, Spain;
Johannesburg, South Africa; Macau SAR, China). The policies in scope are
grounded in the conceptual framework of the Capability Approach for human
development. We also present an automated pipeline that connects the
benchmarked policies to an agent-based model, and we explore the social impact
of the recommended policies through simulated social scenarios. The paper
results reveal promising potential to leverage LLMs for social policy making.
If responsible guardrails and contextual calibrations are introduced in
collaboration with local domain experts, LLMs can provide humans with valuable
insights, in the form of alternative policies at scale.

</details>


### [99] [An Agentic Model Context Protocol Framework for Medical Concept Standardization](https://arxiv.org/abs/2509.03828)
*Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu*

Main category: cs.AI

TL;DR: 论文提出了一种基于MCP的零训练、防幻觉的术语映射系统，显著提升了OMOP CDM的映射效率和准确性。


<details>
  <summary>Details</summary>
Motivation: OMOP CDM的术语映射过程资源密集且易出错，传统大语言模型（LLMs）因幻觉问题难以直接用于临床环境，需要一种更可靠的方法。

Method: 开发了一个基于模型上下文协议（MCP）的零训练映射系统，该系统允许大语言模型（LLMs）与外部资源和工具交互，实现实时词汇查找和结构化推理输出。

Result: 该系统实现了无需训练的术语映射，显著提高了效率和准确性，并提供了解释性映射和结构化推理输出。

Conclusion: 论文提出了一种基于模型上下文协议（MCP）的零训练、防幻觉的映射系统，显著提高了OMOP CDM中术语映射的效率和准确性，适合即时应用于探索性和生产环境。

Abstract: The Observational Medical Outcomes Partnership (OMOP) common data model (CDM)
provides a standardized representation of heterogeneous health data to support
large-scale, multi-institutional research. One critical step in data
standardization using OMOP CDM is the mapping of source medical terms to OMOP
standard concepts, a procedure that is resource-intensive and error-prone.
While large language models (LLMs) have the potential to facilitate this
process, their tendency toward hallucination makes them unsuitable for clinical
deployment without training and expert validation. Here, we developed a
zero-training, hallucination-preventive mapping system based on the Model
Context Protocol (MCP), a standardized and secure framework allowing LLMs to
interact with external resources and tools. The system enables explainable
mapping and significantly improves efficiency and accuracy with minimal effort.
It provides real-time vocabulary lookups and structured reasoning outputs
suitable for immediate use in both exploratory and production environments.

</details>


### [100] [A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai](https://arxiv.org/abs/2509.03830)
*Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng*

Main category: cs.AI

TL;DR: 该研究利用AI分析社交媒体数据，揭示游客对上海历史城区的感知差异，为规划和设计提供依据。


<details>
  <summary>Details</summary>
Motivation: 理解游客对历史城区的感知对可持续、以人为本的城市规划至关重要。

Method: 研究采用多模态数据（社交媒体照片和评论），结合语义分割模型、聚类方法和混合情感分析（规则基础与多任务BERT模型）来分析游客的视觉焦点、色彩偏好和情感反应。

Result: 研究发现游客的视觉期望与真实环境存在差异（如色彩主题），并揭示了审美吸引力和情感反应的空间变化。

Conclusion: 该研究提出了一个多维度的AI框架，用于分析历史城区的游客感知，为可持续的城市规划和遗产保护提供了数据驱动的决策支持。

Abstract: Historic urban quarters play a vital role in preserving cultural heritage
while serving as vibrant spaces for tourism and everyday life. Understanding
how tourists perceive these environments is essential for sustainable,
human-centered urban planning. This study proposes a multidimensional
AI-powered framework for analyzing tourist perception in historic urban
quarters using multimodal data from social media. Applied to twelve historic
quarters in central Shanghai, the framework integrates focal point extraction,
color theme analysis, and sentiment mining. Visual focus areas are identified
from tourist-shared photos using a fine-tuned semantic segmentation model. To
assess aesthetic preferences, dominant colors are extracted using a clustering
method, and their spatial distribution across quarters is analyzed. Color
themes are further compared between social media photos and real-world street
views, revealing notable shifts. This divergence highlights potential gaps
between visual expectations and the built environment, reflecting both
stylistic preferences and perceptual bias. Tourist reviews are evaluated
through a hybrid sentiment analysis approach combining a rule-based method and
a multi-task BERT model. Satisfaction is assessed across four dimensions:
tourist activities, built environment, service facilities, and business
formats. The results reveal spatial variations in aesthetic appeal and
emotional response. Rather than focusing on a single technical innovation, this
framework offers an integrated, data-driven approach to decoding tourist
perception and contributes to informed decision-making in tourism, heritage
conservation, and the design of aesthetically engaging public spaces.

</details>


### [101] [Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures](https://arxiv.org/abs/2509.03857)
*Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman*

Main category: cs.AI

TL;DR: 研究提出了一种基于知识图谱的系统化方法，通过实时监控和动态阈值检测生成式AI的可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型存在可靠性问题（如幻觉、语义漂移和偏见），且当前评估方法依赖主观人工评估，缺乏可扩展性和透明度。

Method: 构建两种并行知识图谱：确定性知识图谱（基于规则、预定义本体和结构化实体关系提取规则）和LLM生成知识图谱（动态来源于实时文本数据流）。采用多种知识图谱指标（如ICR、IPR、CI）量化结构偏差和语义差异，并通过实时监控框架计算偏差。

Result: 该方法通过动态异常阈值和实时监控，能够主动识别和标记显著偏差，从而及时发现语义异常或幻觉。

Conclusion: 该研究提出了一种基于确定性知识图谱和LLM生成知识图谱的系统化方法，用于持续监控和评估生成式AI的可靠性，通过实时计算偏差和动态异常阈值，有效检测语义异常或幻觉。

Abstract: Generative AI (GEN AI) models have revolutionized diverse application domains
but present substantial challenges due to reliability concerns, including
hallucinations, semantic drift, and inherent biases. These models typically
operate as black-boxes, complicating transparent and objective evaluation.
Current evaluation methods primarily depend on subjective human assessment,
limiting scalability, transparency, and effectiveness. This research proposes a
systematic methodology using deterministic and Large Language Model
(LLM)-generated Knowledge Graphs (KGs) to continuously monitor and evaluate GEN
AI reliability. We construct two parallel KGs: (i) a deterministic KG built
using explicit rule-based methods, predefined ontologies, domain-specific
dictionaries, and structured entity-relation extraction rules, and (ii) an
LLM-generated KG dynamically derived from real-time textual data streams such
as live news articles. Utilizing real-time news streams ensures authenticity,
mitigates biases from repetitive training, and prevents adaptive LLMs from
bypassing predefined benchmarks through feedback memorization. To quantify
structural deviations and semantic discrepancies, we employ several established
KG metrics, including Instantiated Class Ratio (ICR), Instantiated Property
Ratio (IPR), and Class Instantiation (CI). An automated real-time monitoring
framework continuously computes deviations between deterministic and
LLM-generated KGs. By establishing dynamic anomaly thresholds based on
historical structural metric distributions, our method proactively identifies
and flags significant deviations, thus promptly detecting semantic anomalies or
hallucinations. This structured, metric-driven comparison between deterministic
and dynamically generated KGs delivers a robust and scalable evaluation
framework.

</details>


### [102] [Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata](https://arxiv.org/abs/2509.03863)
*Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas*

Main category: cs.AI

TL;DR: E&E混合策略结合局部扩展和VLM生成的目标导向远征，在连续细胞自动机中实现更高效、多样化的行为探索。


<details>
  <summary>Details</summary>
Motivation: 传统新颖性搜索（NS）方法在高维行为空间中容易陷入局部新颖性枯竭的困境，无法探索远距离未开发区域。

Method: 引入远征与扩展（E&E）混合策略，交替进行局部新颖性驱动的扩展和基于视觉语言模型（VLM）生成的语言目标导向的远征。

Result: 在Flow Lenia连续细胞自动机上测试表明，E&E比现有方法发现更多样化的解决方案，且远征生成的解决方案对长期探索有显著影响。

Conclusion: E&E策略通过结合局部新颖性扩展和目标导向的远征，突破了传统方法的局限性，在连续细胞自动机中发现了更多样化的解决方案，为人工生命等领域的开放式探索提供了新思路。

Abstract: Discovering diverse visual patterns in continuous cellular automata (CA) is
challenging due to the vastness and redundancy of high-dimensional behavioral
spaces. Traditional exploration methods like Novelty Search (NS) expand locally
by mutating known novel solutions but often plateau when local novelty is
exhausted, failing to reach distant, unexplored regions. We introduce
Expedition and Expansion (E&E), a hybrid strategy where exploration alternates
between local novelty-driven expansions and goal-directed expeditions. During
expeditions, E&E leverages a Vision-Language Model (VLM) to generate linguistic
goals--descriptions of interesting but hypothetical patterns that drive
exploration toward uncharted regions. By operating in semantic spaces that
align with human perception, E&E both evaluates novelty and generates goals in
conceptually meaningful ways, enhancing the interpretability and relevance of
discovered behaviors. Tested on Flow Lenia, a continuous CA known for its rich,
emergent behaviors, E&E consistently uncovers more diverse solutions than
existing exploration methods. A genealogical analysis further reveals that
solutions originating from expeditions disproportionately influence long-term
exploration, unlocking new behavioral niches that serve as stepping stones for
subsequent search. These findings highlight E&E's capacity to break through
local novelty boundaries and explore behavioral landscapes in human-aligned,
interpretable ways, offering a promising template for open-ended exploration in
artificial life and beyond.

</details>


### [103] [FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace](https://arxiv.org/abs/2509.03890)
*Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li*

Main category: cs.AI

TL;DR: FaMA是一种基于LLM的代理助手，通过对话式交互简化C2C电商平台操作，提升效率。


<details>
  <summary>Details</summary>
Motivation: C2C电商平台的复杂GUI操作对用户（买家和卖家）来说耗时且不友好，亟需一种更直观、高效的交互方式。

Method: 论文提出了一种基于LLM的代理助手架构FaMA，通过自然语言命令自动化高摩擦工作流，替代传统GUI。

Result: FaMA在解决复杂任务时达到了98%的成功率，并将交互时间缩短至原来的1/2。

Conclusion: FaMA作为一种基于LLM的代理助手，通过对话式交互简化了C2C电商平台的复杂操作，显著提升了用户效率和任务成功率。

Abstract: The emergence of agentic AI, powered by Large Language Models (LLMs), marks a
paradigm shift from reactive generative systems to proactive, goal-oriented
autonomous agents capable of sophisticated planning, memory, and tool use. This
evolution presents a novel opportunity to address long-standing challenges in
complex digital environments. Core tasks on Consumer-to-Consumer (C2C)
e-commerce platforms often require users to navigate complex Graphical User
Interfaces (GUIs), making the experience time-consuming for both buyers and
sellers. This paper introduces a novel approach to simplify these interactions
through an LLM-powered agentic assistant. This agent functions as a new,
conversational entry point to the marketplace, shifting the primary interaction
model from a complex GUI to an intuitive AI agent. By interpreting natural
language commands, the agent automates key high-friction workflows. For
sellers, this includes simplified updating and renewal of listings, and the
ability to send bulk messages. For buyers, the agent facilitates a more
efficient product discovery process through conversational search. We present
the architecture for Facebook Marketplace Assistant (FaMA), arguing that this
agentic, conversational paradigm provides a lightweight and more accessible
alternative to traditional app interfaces, allowing users to manage their
marketplace activities with greater efficiency. Experiments show FaMA achieves
a 98% task success rate on solving complex tasks on the marketplace and enables
up to a 2x speedup on interaction time.

</details>


### [104] [A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning](https://arxiv.org/abs/2509.03906)
*Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng*

Main category: cs.AI

TL;DR: DeepMedix-R1 是一种透明且可解释的医学基础模型，通过顺序训练显著提升胸部X光解读性能，适用于临床实际应用。


<details>
  <summary>Details</summary>
Motivation: 当前医学基础模型缺乏透明推理过程和局部可解释性，限制了其临床实际应用。

Method: 采用顺序训练流程：首先在CXR指令数据上微调，然后通过高质量合成推理样本实现冷启动推理，最后通过在线强化学习优化推理质量和生成性能。

Result: 在报告生成和视觉问答任务中表现优异（如分别超过LLaVA-Rad和MedGemma 14.54%和31.32%，以及超过MedGemma和CheXagent 57.75%和23.06%），并通过专家评审验证了更高的可解释性和临床合理性。

Conclusion: DeepMedix-R1 通过透明推理和局部可解释性，显著提升了胸部X光解读的准确性和临床实用性，推动了医学基础模型的发展。

Abstract: Medical foundation models (FMs) have shown tremendous promise amid the rapid
advancements in artificial intelligence (AI) technologies. However, current
medical FMs typically generate answers in a black-box manner, lacking
transparent reasoning processes and locally grounded interpretability, which
hinders their practical clinical deployments. To this end, we introduce
DeepMedix-R1, a holistic medical FM for chest X-ray (CXR) interpretation. It
leverages a sequential training pipeline: initially fine-tuned on curated CXR
instruction data to equip with fundamental CXR interpretation capabilities,
then exposed to high-quality synthetic reasoning samples to enable cold-start
reasoning, and finally refined via online reinforcement learning to enhance
both grounded reasoning quality and generation performance. Thus, the model
produces both an answer and reasoning steps tied to the image's local regions
for each query. Quantitative evaluation demonstrates substantial improvements
in report generation (e.g., 14.54% and 31.32% over LLaVA-Rad and MedGemma) and
visual question answering (e.g., 57.75% and 23.06% over MedGemma and CheXagent)
tasks. To facilitate robust assessment, we propose Report Arena, a benchmarking
framework using advanced language models to evaluate answer quality, further
highlighting the superiority of DeepMedix-R1. Expert review of generated
reasoning steps reveals greater interpretability and clinical plausibility
compared to the established Qwen2.5-VL-7B model (0.7416 vs. 0.2584 overall
preference). Collectively, our work advances medical FM development toward
holistic, transparent, and clinically actionable modeling for CXR
interpretation.

</details>


### [105] [Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions](https://arxiv.org/abs/2509.03953)
*Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia*

Main category: cs.AI

TL;DR: 本文提出了一种显式处理控制参数为决策点的启发式搜索算法，通过延迟部分扩展提升效率，实验证明其竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将控制参数视为附加约束而非决策点，限制了搜索效率。本文旨在通过显式处理控制参数作为决策点，提升规划问题的求解效率。

Method: 开发了一种基于最佳优先、启发式搜索的算法，利用延迟部分扩展的概念，逐步扩展状态的后继子集。

Result: 实验结果表明，该算法在处理涉及控制参数的规划问题时，是现有方法的竞争性替代方案。

Conclusion: 本文提出了一种新颖的搜索算法，能够高效处理控制参数作为真正的决策点，在特定条件下证明了其完备性，并通过实验证明了其竞争力。

Abstract: In automated planning, control parameters extend standard action
representations through the introduction of continuous numeric decision
variables. Existing state-of-the-art approaches have primarily handled control
parameters as embedded constraints alongside other temporal and numeric
restrictions, and thus have implicitly treated them as additional constraints
rather than as decision points in the search space. In this paper, we propose
an efficient alternative that explicitly handles control parameters as true
decision points within a systematic search scheme. We develop a best-first,
heuristic search algorithm that operates over infinite decision spaces defined
by control parameters and prove a notion of completeness in the limit under
certain conditions. Our algorithm leverages the concept of delayed partial
expansion, where a state is not fully expanded but instead incrementally
expands a subset of its successors. Our results demonstrate that this novel
search algorithm is a competitive alternative to existing approaches for
solving planning problems involving control parameters.

</details>


### [106] [World Model Implanting for Test-time Adaptation of Embodied Agents](https://arxiv.org/abs/2509.03956)
*Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo*

Main category: cs.AI

TL;DR: WorMI框架通过LLM和领域世界模型的测试时组合，实现实体AI的跨域适应性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决实体AI代理在新领域中无需大量数据收集或重新训练即可稳健适应的问题。

Method: 采用原型世界模型检索方法和轨迹抽象表示匹配，结合世界级复合注意力机制，融合多世界模型知识。

Result: 在VirtualHome和ALFWorld基准测试中表现出优于其他基于LLM的方法的零样本和小样本性能。

Conclusion: WorMI框架通过结合大型语言模型的推理能力和领域特定的世界模型，实现了跨域适应性和数据效率，展示了在实体AI中实际部署的潜力。

Abstract: In embodied AI, a persistent challenge is enabling agents to robustly adapt
to novel domains without requiring extensive data collection or retraining. To
address this, we present a world model implanting framework (WorMI) that
combines the reasoning capabilities of large language models (LLMs) with
independently learned, domain-specific world models through test-time
composition. By allowing seamless implantation and removal of the world models,
the embodied agent's policy achieves and maintains cross-domain adaptability.
In the WorMI framework, we employ a prototype-based world model retrieval
approach, utilizing efficient trajectory-based abstract representation
matching, to incorporate relevant models into test-time composition. We also
develop a world-wise compound attention method that not only integrates the
knowledge from the retrieved world models but also aligns their intermediate
representations with the reasoning model's representation within the agent's
policy. This framework design effectively fuses domain-specific knowledge from
multiple world models, ensuring robust adaptation to unseen domains. We
evaluate our WorMI on the VirtualHome and ALFWorld benchmarks, demonstrating
superior zero-shot and few-shot performance compared to several LLM-based
approaches across a range of unseen domains. These results highlight the
frameworks potential for scalable, real-world deployment in embodied agent
scenarios where adaptability and data efficiency are essential.

</details>


### [107] [Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent](https://arxiv.org/abs/2509.03990)
*Chunlong Wu,Zhibo Qu*

Main category: cs.AI

TL;DR: MPR框架通过元策略记忆和双推理机制，解决了LLM代理跨任务适应性问题，提升了执行效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有反思策略生成的任务特定痕迹无法跨任务复用，而强化学习方案需要大量计算。MPR旨在外部化可重用知识，避免模型权重更新，同时提升执行稳定性。

Method: 引入Meta-Policy Reflexion（MPR）框架，整合LLM生成的反思为结构化元策略记忆（MPM），并通过软记忆引导解码和硬规则可接受性检查（HAC）应用。

Result: 实验结果显示MPR在文本代理环境中比Reflexion基线在准确性和鲁棒性上均有显著提升，规则可接受性进一步增强了稳定性。

Conclusion: MPR框架通过结合元策略记忆和两种推理机制，显著提升了LLM代理的执行准确性和鲁棒性，同时保持了语言反思的适应性。未来可扩展至多模态和多代理场景。

Abstract: Large language model (LLM) agents achieve impressive single-task performance
but commonly exhibit repeated failures, inefficient exploration, and limited
cross-task adaptability. Existing reflective strategies (e.g., Reflexion,
ReAct) improve per-episode behavior but typically produce ephemeral,
task-specific traces that are not reused across tasks. Reinforcement-learning
based alternatives can produce transferable policies but require substantial
parameter updates and compute. In this work we introduce Meta-Policy Reflexion
(MPR): a hybrid framework that consolidates LLM-generated reflections into a
structured, predicate-like Meta-Policy Memory (MPM) and applies that memory at
inference time through two complementary mechanisms soft memory-guided decoding
and hard rule admissibility checks(HAC). MPR (i) externalizes reusable
corrective knowledge without model weight updates, (ii) enforces domain
constraints to reduce unsafe or invalid actions, and (iii) retains the
adaptability of language-based reflection. We formalize the MPM representation,
present algorithms for update and decoding, and validate the approach in a
text-based agent environment following the experimental protocol described in
the provided implementation (AlfWorld-based). Empirical results reported in the
supplied material indicate consistent gains in execution accuracy and
robustness when compared to Reflexion baselines; rule admissibility further
improves stability. We analyze mechanisms that explain these gains, discuss
scalability and failure modes, and outline future directions for multimodal and
multi?agent extensions.

</details>


### [108] [AutoPBO: LLM-powered Optimization for Local Search PBO Solvers](https://arxiv.org/abs/2509.04007)
*Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai*

Main category: cs.AI

TL;DR: AutoPBO是一个LLM驱动的框架，用于自动优化PBO局部搜索求解器，实验表明其性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然局部搜索求解器在PBO求解中表现出色，但其设计需要大量专家努力和手动调整。LLM在自动化算法设计方面有潜力，但在优化PBO求解器方面尚未探索。

Method: 引入AutoPBO，一个基于大型语言模型（LLM）的框架，用于自动增强PBO局部搜索求解器。在四个公共基准上进行了实验。

Result: AutoPBO在局部搜索方法上实现了显著改进，并在与六种最先进竞争对手的比较中保持竞争力。

Conclusion: AutoPBO展示了在自动化局部搜索求解器设计方面的潜力，显著提升了性能，并与现有最先进方法保持竞争力。

Abstract: Pseudo-Boolean Optimization (PBO) provides a powerful framework for modeling
combinatorial problems through pseudo-Boolean (PB) constraints. Local search
solvers have shown excellent performance in PBO solving, and their efficiency
is highly dependent on their internal heuristics to guide the search. Still,
their design often requires significant expert effort and manual tuning in
practice. While Large Language Models (LLMs) have demonstrated potential in
automating algorithm design, their application to optimizing PBO solvers
remains unexplored. In this work, we introduce AutoPBO, a novel LLM-powered
framework to automatically enhance PBO local search solvers. We conduct
experiments on a broad range of four public benchmarks, including one
real-world benchmark, a benchmark from PB competition, an integer linear
programming optimization benchmark, and a crafted combinatorial benchmark, to
evaluate the performance improvement achieved by AutoPBO and compare it with
six state-of-the-art competitors, including two local search PBO solvers NuPBO
and OraSLS, two complete PB solvers PBO-IHS and RoundingSat, and two mixed
integer programming (MIP) solvers Gurobi and SCIP. AutoPBO demonstrates
significant improvements over previous local search approaches, while
maintaining competitive performance compared to state-of-the-art competitors.
The results suggest that AutoPBO offers a promising approach to automating
local search solver design.

</details>


### [109] [CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning](https://arxiv.org/abs/2509.04027)
*Zeyu Gan,Hao Yi,Yong Liu*

Main category: cs.AI

TL;DR: CoT-Space将LLM推理从离散token预测重构为连续语义空间优化，理论解释了最优CoT长度收敛，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统token级RL框架无法与复杂多步推理（如CoT）的推理级特性对齐，存在理论空白。

Method: 通过噪声视角和风险视角分析LLM推理过程，将离散的token预测任务转化为连续的推理级语义空间优化。

Result: 理论分析表明，最优CoT长度的收敛是欠拟合与过拟合基本权衡的自然结果，实验也验证了这一点。

Conclusion: CoT-Space框架不仅为LLM推理提供了连续语义空间的优化视角，还为未来开发更有效、泛化性更强的推理代理奠定了理论基础。

Abstract: Reinforcement Learning (RL) has become a pivotal approach for enhancing the
reasoning capabilities of Large Language Models (LLMs). However, a significant
theoretical gap persists, as traditional token-level RL frameworks fail to
align with the reasoning-level nature of complex, multi-step thought processes
like Chain-of-Thought (CoT). To address this challenge, we introduce CoT-Space,
a novel theoretical framework that recasts LLM reasoning from a discrete
token-prediction task to an optimization process within a continuous,
reasoning-level semantic space. By analyzing this process from both a noise
perspective and a risk perspective, we demonstrate that the convergence to an
optimal CoT length is a natural consequence of the fundamental trade-off
between underfitting and overfitting. Furthermore, extensive experiments
provide strong empirical validation for our theoretical findings. Our framework
not only provides a coherent explanation for empirical phenomena such as
overthinking but also offers a solid theoretical foundation to guide the future
development of more effective and generalizable reasoning agents.

</details>


### [110] [Oruga: An Avatar of Representational Systems Theory](https://arxiv.org/abs/2509.04041)
*Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng*

Main category: cs.AI

TL;DR: Oruga是基于RST的实现，旨在赋予机器灵活使用表示的能力，包括核心数据结构、通信语言和结构转移引擎。


<details>
  <summary>Details</summary>
Motivation: 人类能够灵活使用表示（如绘制图表、改变表示和跨领域类比），我们希望赋予机器类似的能力以增强其与人类的兼容性。

Method: Oruga包括与RST概念对应的核心数据结构、用于与核心通信的语言，以及通过结构转移方法生成转换的引擎。

Result: Oruga的核心和语言部分得到了展示，并通过结构转移方法实现了一种转换示例。

Conclusion: 本文介绍了Oruga，一个基于表示系统理论（RST）的实现，旨在赋予机器灵活使用表示的能力。

Abstract: Humans use representations flexibly. We draw diagrams, change representations
and exploit creative analogies across different domains. We want to harness
this kind of power and endow machines with it to make them more compatible with
human use. Previously we developed Representational Systems Theory (RST) to
study the structure and transformations of representations. In this paper we
present Oruga (caterpillar in Spanish; a symbol of transformation), an
implementation of various aspects of RST. Oruga consists of a core of data
structures corresponding to concepts in RST, a language for communicating with
the core, and an engine for producing transformations using a method we call
structure transfer. In this paper we present an overview of the core and
language of Oruga, with a brief example of the kind of transformation that
structure transfer can execute.

</details>


### [111] [Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning](https://arxiv.org/abs/2509.04083)
*Alexander Beiser,David Penz,Nysret Musliu*

Main category: cs.AI

TL;DR: 本文发现形式语言选择是神经符号LLM推理成功的关键因素，通过实验验证其对不同LLM的推理能力有显著影响。


<details>
  <summary>Details</summary>
Motivation: 尽管神经符号LLM推理在提升LLM的正式推理能力方面表现良好，但其成功的关键因素尚不明确。本文探讨了形式语言选择这一被忽视的因素。

Method: 通过比较四种形式语言在三个数据集和七个LLM上的表现，分析了形式语言选择对推理能力的影响。

Result: 形式语言的选择显著影响LLM的句法和语义推理能力，且不同LLM的表现存在差异。

Conclusion: 研究表明，在神经符号LLM推理中，形式语言的选择对模型的句法和语义推理能力有显著影响，且不同LLM受到的影响程度不同。

Abstract: Large language models (LLMs) achieve astonishing results on a wide range of
tasks. However, their formal reasoning ability still lags behind. A promising
approach is Neurosymbolic LLM reasoning. It works by using LLMs as translators
from natural to formal languages and symbolic solvers for deriving correct
results. Still, the contributing factors to the success of Neurosymbolic LLM
reasoning remain unclear. This paper demonstrates that one previously
overlooked factor is the choice of the formal language. We introduce the
intermediate language challenge: selecting a suitable formal language for
neurosymbolic reasoning. By comparing four formal languages across three
datasets and seven LLMs, we show that the choice of formal language affects
both syntactic and semantic reasoning capabilities. We also discuss the varying
effects across different LLMs.

</details>


### [112] [Hybrid Reinforcement Learning and Search for Flight Trajectory Planning](https://arxiv.org/abs/2509.04100)
*Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch*

Main category: cs.AI

TL;DR: 结合强化学习与路径规划，显著提升航空紧急路径优化速度，燃料消耗几乎不变，计算速度提升50%。


<details>
  <summary>Details</summary>
Motivation: 在航空紧急情况下，快速重新计算飞行路径至关重要，传统方法可能无法满足实时性需求。

Method: 训练一个强化学习代理，基于位置和大气数据预计算接近最优的路径，并在运行时约束底层路径规划求解器，以缩小搜索空间。

Result: 实验结果表明，燃料消耗与未约束求解器相比偏差通常在1%以内，计算速度提升最高达50%。

Conclusion: 结合强化学习和搜索路径规划的方法在航空紧急情况下能显著加快路径优化速度，虽然不能保证全局最优，但实际应用中燃料消耗与未约束求解器相近，且计算速度提升可达50%。

Abstract: This paper explores the combination of Reinforcement Learning (RL) and
search-based path planners to speed up the optimization of flight paths for
airliners, where in case of emergency a fast route re-calculation can be
crucial. The fundamental idea is to train an RL Agent to pre-compute
near-optimal paths based on location and atmospheric data and use those at
runtime to constrain the underlying path planning solver and find a solution
within a certain distance from the initial guess. The approach effectively
reduces the size of the solver's search space, significantly speeding up route
optimization. Although global optimality is not guaranteed, empirical results
conducted with Airbus aircraft's performance models show that fuel consumption
remains nearly identical to that of an unconstrained solver, with deviations
typically within 1%. At the same time, computation speed can be improved by up
to 50% as compared to using a conventional solver alone.

</details>


### [113] [Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker](https://arxiv.org/abs/2509.04125)
*Tarik Zaciragic,Aske Plaat,K. Joost Batenburg*

Main category: cs.AI

TL;DR: 研究证实DQN和CFR在简化扑克中均会虚张声势，方式不同但成功率相似，表明虚张声势是游戏核心特性。


<details>
  <summary>Details</summary>
Motivation: 现有计算机扑克研究多关注胜率等性能指标，而忽略了虚张声势这一人类扑克中的关键技能。本文旨在探讨DQN和CFR是否在Leduc Hold'em中表现出虚张声势行为。

Method: 设计了DQN和CFR代理相互对战的实验，记录其行为以分析虚张声势行为。

Result: 发现DQN和CFR均表现出虚张声势行为，方式不同但成功率相近。

Conclusion: 研究表明，无论是基于强化学习的DQN还是基于博弈论的CFR，在简化版扑克Leduc Hold'em中均表现出虚张声势的行为，且成功率相近，说明虚张声势是游戏本身而非算法的关键特性。未来研究应探索不同虚张声势风格及完整扑克游戏。

Abstract: In the game of poker, being unpredictable, or bluffing, is an essential
skill. When humans play poker, they bluff. However, most works on
computer-poker focus on performance metrics such as win rates, while bluffing
is overlooked. In this paper we study whether two popular algorithms, DQN
(based on reinforcement learning) and CFR (based on game theory), exhibit
bluffing behavior in Leduc Hold'em, a simplified version of poker. We designed
an experiment where we let the DQN and CFR agent play against each other while
we log their actions. We find that both DQN and CFR exhibit bluffing behavior,
but they do so in different ways. Although both attempt to perform bluffs at
different rates, the percentage of successful bluffs (where the opponent folds)
is roughly the same. This suggests that bluffing is an essential aspect of the
game, not of the algorithm. Future work should look at different bluffing
styles and at the full game of poker. Code at
https://github.com/TarikZ03/Bluffing-by-DQN-and-CFR-in-Leduc-Hold-em-Poker-Codebase.

</details>


### [114] [The human biological advantage over AI](https://arxiv.org/abs/2509.04130)
*William Stewart*

Main category: cs.AI

TL;DR: AI可能在能力上超越人类，但因缺乏生物CNS的情感与伦理理解，人类仍是宇宙领导者的最佳选择。


<details>
  <summary>Details</summary>
Motivation: 探讨AI是否可能超越人类成为宇宙领导者，强调情感与伦理理解的重要性。

Method: 通过对比AI与人类的中枢神经系统功能，探讨情感与伦理理解在领导力中的核心作用。

Result: AI无法模拟或制造CNS，因此缺乏情感与伦理的深层理解能力，无法取代人类的领导地位。

Conclusion: AI系统可能在多数方面超越人类，但基于生物中枢神经系统（CNS）的情感与伦理理解能力，人类仍是宇宙领导者的最佳选择。

Abstract: Recent advances in AI raise the possibility that AI systems will one day be
able to do anything humans can do, only better. If artificial general
intelligence (AGI) is achieved, AI systems may be able to understand, reason,
problem solve, create, and evolve at a level and speed that humans will
increasingly be unable to match, or even understand. These possibilities raise
a natural question as to whether AI will eventually become superior to humans,
a successor "digital species", with a rightful claim to assume leadership of
the universe. However, a deeper consideration suggests the overlooked
differentiator between human beings and AI is not the brain, but the central
nervous system (CNS), providing us with an immersive integration with physical
reality. It is our CNS that enables us to experience emotion including pain,
joy, suffering, and love, and therefore to fully appreciate the consequences of
our actions on the world around us. And that emotional understanding of the
consequences of our actions is what is required to be able to develop
sustainable ethical systems, and so be fully qualified to be the leaders of the
universe. A CNS cannot be manufactured or simulated; it must be grown as a
biological construct. And so, even the development of consciousness will not be
sufficient to make AI systems superior to humans. AI systems may become more
capable than humans on almost every measure and transform our society. However,
the best foundation for leadership of our universe will always be DNA, not
silicon.

</details>


### [115] [Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs](https://arxiv.org/abs/2509.04159)
*Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das*

Main category: cs.AI

TL;DR: 研究提出了一种基于动作图的DSL，用于形式化烹饪程序，初步评估显示其适用于自动化食谱分析和执行。


<details>
  <summary>Details</summary>
Motivation: 由于烹饪过程的复杂性和模糊性，形式化烹饪程序一直是一个挑战。研究旨在通过结构化表示提升机器对烹饪过程的理解和自动化能力。

Method: 研究提出了一种可扩展的领域特定语言（DSL），通过有向动作图表示食谱，捕捉流程、传递、环境、并发和组合结构。

Result: 初步手动评估表明，该DSL能够精确建模复杂的烹饪工作流程，适用于未来的自动化应用。

Conclusion: 该研究为烹饪领域提供了一个基于动作图的形式化语言，为未来自动化食谱分析和执行奠定了基础。

Abstract: Formalizing cooking procedures remains a challenging task due to their
inherent complexity and ambiguity. We introduce an extensible domain-specific
language for representing recipes as directed action graphs, capturing
processes, transfers, environments, concurrency, and compositional structure.
Our approach enables precise, modular modeling of complex culinary workflows.
Initial manual evaluation on a full English breakfast recipe demonstrates the
DSL's expressiveness and suitability for future automated recipe analysis and
execution. This work represents initial steps towards an action-centric
ontology for cooking, using temporal graphs to enable structured machine
understanding, precise interpretation, and scalable automation of culinary
processes - both in home kitchens and professional culinary settings.

</details>


### [116] [Domain size asymptotics for Markov logic networks](https://arxiv.org/abs/2509.04192)
*Vera Koponen*

Main category: cs.AI

TL;DR: 论文研究了MLN在无限域下的分布性质，展示了不同软约束的极限行为差异，并比较了MLN与提升贝叶斯网络的渐近不可比性。


<details>
  <summary>Details</summary>
Motivation: 探索MLN在无限域大小下的分布性质，以及不同软约束对随机结构极限行为的影响。

Method: 研究了三种具体MLN例子，分析了随着域大小趋近于无限时随机结构的性质，包括量化自由MLN、减少三角形的MLN和减少高顶点度的MLN。

Result: 发现MLN的软约束权重可能影响也可能不影响极限行为，且MLN与提升贝叶斯网络在渐近意义上不可比。

Conclusion: 论文展示了马尔可夫逻辑网络（MLN）在不同软约束下随机结构的极限行为差异，并通过具体例子比较了量化自由MLN与提升贝叶斯网络的渐近不可比性。

Abstract: A Markov logic network (MLN) determines a probability distribution on the set
of structures, or ``possible worlds'', with an arbitrary finite domain. We
study the properties of such distributions as the domain size tends to
infinity. Three types of concrete examples of MLNs will be considered, and the
properties of random structures with domain sizes tending to infinity will be
studied: (1) Arbitrary quantifier-free MLNs over a language with only one
relation symbol which has arity 1. In this case we give a pretty complete
characterization of the possible limit behaviours of random structures. (2) An
MLN that favours graphs with fewer triangles (or more generally, fewer
k-cliques). As a corollary of the analysis a ``$\delta$-approximate 0-1 law''
for first-order logic is obtained. (3) An MLN that favours graphs with fewer
vertices with degree higher than a fixed (but arbitrary) number. The analysis
shows that depending on which ``soft constraints'' an MLN uses the limit
behaviour of random structures can be quite different, and the weights of the
soft constraints may, or may not, have influence on the limit behaviour. It
will also be demonstrated, using (1), that quantifier-free MLNs and lifted
Bayesian networks (in a broad sense) are asymptotically incomparable, roughly
meaning that there is a sequence of distributions on possible worlds with
increasing domain sizes that can be defined by one of the formalisms but not
even approximated by the other. In a rather general context it is also shown
that on large domains the distribution determined by an MLN concentrates almost
all its probability mass on a totally different part of the space of possible
worlds than the uniform distribution does.

</details>


### [117] [Evaluating Quality of Gaming Narratives Co-created with AI](https://arxiv.org/abs/2509.04239)
*Arturo Valdivia,Paolo Burelli*

Main category: cs.AI

TL;DR: 本文提出了一种评估AI生成游戏叙事的结构化方法，结合专家意见和Kano模型，帮助开发者优化叙事质量。


<details>
  <summary>Details</summary>
Motivation: 旨在解决AI生成游戏叙事质量评估的标准化问题，帮助开发者更好地与生成式AI共同创作游戏叙事。

Method: 采用德尔菲研究结构，结合叙事设计专家小组的意见，将故事质量维度映射到Kano模型框架中。

Result: 研究结果明确了影响玩家满意度的关键故事质量维度，为开发者提供了优先级的依据。

Conclusion: 该研究为游戏开发者提供了一种评估AI生成游戏叙事的结构化方法，帮助他们优先考虑影响玩家满意度的关键质量维度。

Abstract: This paper proposes a structured methodology to evaluate AI-generated game
narratives, leveraging the Delphi study structure with a panel of narrative
design experts. Our approach synthesizes story quality dimensions from
literature and expert insights, mapping them into the Kano model framework to
understand their impact on player satisfaction. The results can inform game
developers on prioritizing quality aspects when co-creating game narratives
with generative AI.

</details>


### [118] [EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation](https://arxiv.org/abs/2509.04310)
*Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup*

Main category: cs.AI

TL;DR: EvoEmo框架通过进化强化学习优化谈判中的动态情感表达，显著提升LLM代理的谈判效能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在谈判中忽视了情感的功能性角色，仅生成被动、偏好驱动的情感响应，易受对手操纵和战略利用。

Method: 研究提出了EvoEmo框架，将情感状态转换建模为马尔可夫决策过程，并采用基于种群的遗传优化来演化高奖励情感策略。

Result: 实验表明，EvoEmo在成功率、效率和买方节省方面均优于基线策略。

Conclusion: 该研究强调了自适应情感表达在多轮谈判中对于提升大型语言模型（LLM）代理效能的重要性。

Abstract: Recent research on Chain-of-Thought (CoT) reasoning in Large Language Models
(LLMs) has demonstrated that agents can engage in \textit{complex},
\textit{multi-turn} negotiations, opening new avenues for agentic AI. However,
existing LLM agents largely overlook the functional role of emotions in such
negotiations, instead generating passive, preference-driven emotional responses
that make them vulnerable to manipulation and strategic exploitation by
adversarial counterparts. To address this gap, we present EvoEmo, an
evolutionary reinforcement learning framework that optimizes dynamic emotional
expression in negotiations. EvoEmo models emotional state transitions as a
Markov Decision Process and employs population-based genetic optimization to
evolve high-reward emotion policies across diverse negotiation scenarios. We
further propose an evaluation framework with two baselines -- vanilla
strategies and fixed-emotion strategies -- for benchmarking emotion-aware
negotiation. Extensive experiments and ablation studies show that EvoEmo
consistently outperforms both baselines, achieving higher success rates, higher
efficiency, and increased buyer savings. This findings highlight the importance
of adaptive emotional expression in enabling more effective LLM agents for
multi-turn negotiation.

</details>


### [119] [Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes](https://arxiv.org/abs/2509.04317)
*Isidoro Tamassia,Wendelin Böhmer*

Main category: cs.AI

TL;DR: 本文通过简单修改AlphaZero框架，解决了其在变化测试环境中的适用性问题，显著提升了性能表现。


<details>
  <summary>Details</summary>
Motivation: AlphaZero通常假设训练环境在测试时不会变化，这限制了其适用性。本文旨在解决这一限制。

Method: 分析AlphaZero代理在可能变化的测试环境中的部署问题，并提出对标准框架的简单修改方法。

Result: 修改后的框架在变化环境中表现出显著性能提升，尤其是在低规划预算下。

Conclusion: 通过简单修改标准的AlphaZero框架，可以显著提升在变化测试环境中的性能表现，即使在低规划预算的情况下也有效。

Abstract: The AlphaZero framework provides a standard way of combining Monte Carlo
planning with prior knowledge provided by a previously trained policy-value
neural network. AlphaZero usually assumes that the environment on which the
neural network was trained will not change at test time, which constrains its
applicability. In this paper, we analyze the problem of deploying AlphaZero
agents in potentially changed test environments and demonstrate how the
combination of simple modifications to the standard framework can significantly
boost performance, even in settings with a low planning budget available. The
code is publicly available on GitHub.

</details>


### [120] [Psychologically Enhanced AI Agents](https://arxiv.org/abs/2509.04343)
*Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler*

Main category: cs.AI

TL;DR: MBTI-in-Thoughts框架通过MBTI人格调节提升LLM代理的行为效能，无需微调即可实现心理增强。


<details>
  <summary>Details</summary>
Motivation: 提升大型语言模型（LLM）代理的效能，通过心理学基础的人格调节实现行为控制。

Method: 利用Myers-Briggs Type Indicator（MBTI）通过提示工程为代理赋予不同人格原型，控制其在认知和情感两个心理学基础轴上的行为。

Result: 人格调节在不同任务中产生一致且可解释的行为偏差：情感表达型代理在叙事生成中表现优异，而分析型代理在博弈论环境中采用更稳定的策略。自我反思能提高合作和推理质量。

Conclusion: 通过将MBTI等心理学理论应用于LLM行为设计，本研究为无需微调即可实现心理增强的AI代理奠定了基础。

Abstract: We introduce MBTI-in-Thoughts, a framework for enhancing the effectiveness of
Large Language Model (LLM) agents through psychologically grounded personality
conditioning. Drawing on the Myers-Briggs Type Indicator (MBTI), our method
primes agents with distinct personality archetypes via prompt engineering,
enabling control over behavior along two foundational axes of human psychology,
cognition and affect. We show that such personality priming yields consistent,
interpretable behavioral biases across diverse tasks: emotionally expressive
agents excel in narrative generation, while analytically primed agents adopt
more stable strategies in game-theoretic settings. Our framework supports
experimenting with structured multi-agent communication protocols and reveals
that self-reflection prior to interaction improves cooperation and reasoning
quality. To ensure trait persistence, we integrate the official 16Personalities
test for automated verification. While our focus is on MBTI, we show that our
approach generalizes seamlessly to other psychological frameworks such as Big
Five, HEXACO, or Enneagram. By bridging psychological theory and LLM behavior
design, we establish a foundation for psychologically enhanced AI agents
without any fine-tuning.

</details>


### [121] [ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory](https://arxiv.org/abs/2509.04439)
*Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: 论文提出概念级记忆设计，通过抽象和复用推理轨迹中的模式，实现测试时持续学习，显著提升LLMs在复杂任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 推理时扩展使LLMs能执行更长、更复杂的推理，但这些推理中的模式和见解在上下文窗口重置后立即丢弃。外部记忆可持久化这些发现，但现有方法局限于实例级记忆，缺乏可重用性和扩展性。

Method: 提出了抽象概念级记忆的策略，包括从解决方案轨迹中提取可重用模块化抽象，并以自然语言存储。新查询时选择性检索并整合这些概念到提示中。

Result: 在ARC-AGI基准测试中，该方法比无记忆基线相对提升7.5%，且性能随推理计算规模持续提升。抽象概念在所有测试规模中表现最一致。

Conclusion: 动态更新的概念级记忆设计在推理计算规模上均优于固定记忆设置，支持了自我改进的假设。

Abstract: While inference-time scaling enables LLMs to carry out increasingly long and
capable reasoning traces, the patterns and insights uncovered during these
traces are immediately discarded once the context window is reset for a new
query. External memory is a natural way to persist these discoveries, and
recent work has shown clear benefits for reasoning-intensive tasks. We see an
opportunity to make such memories more broadly reusable and scalable by moving
beyond instance-based memory entries (e.g. exact query/response pairs, or
summaries tightly coupled with the original problem context) toward
concept-level memory: reusable, modular abstractions distilled from solution
traces and stored in natural language. For future queries, relevant concepts
are selectively retrieved and integrated into the prompt, enabling test-time
continual learning without weight updates. Our design introduces new strategies
for abstracting takeaways from rollouts and retrieving entries for new queries,
promoting reuse and allowing memory to expand with additional experiences. On
the challenging ARC-AGI benchmark, our method yields a 7.5% relative gain over
a strong no-memory baseline with performance continuing to scale with inference
compute. We find abstract concepts to be the most consistent memory design,
outscoring the baseline at all tested inference compute scales. Moreover, we
confirm that dynamically updating memory during test-time outperforms an
otherwise identical fixed memory setting with additional attempts, supporting
the hypothesis that solving more problems and abstracting more patterns to
memory enables further solutions in a form of self-improvement. Code available
at https://github.com/matt-seb-ho/arc_memo.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [122] [Combining Performance and Productivity: Accelerating the Network Sensing Graph Challenge with GPUs and Commodity Data Science Software](https://arxiv.org/abs/2509.03653)
*Siddharth Samsi,Dan Campbell,Emanuel Scoullos,Oded Green*

Main category: cs.DC

TL;DR: 论文通过数据科学语言重新解释GraphBLAS，利用RAPIDS生态系统中的现成工具实现了HPEC图挑战的显著加速。


<details>
  <summary>Details</summary>
Motivation: 传统基准测试（如LINPACK）无法全面测试HPC系统的硬件和软件组件，因此需要更复杂的基准测试，如HPEC图挑战。

Method: 利用RAPIDS cuDF和cupy等现成软件，无需特定HPC代码，实现了从CPU到GPU的软件加速。

Result: 在NVIDIA A100、H100和H200 GPU上分别实现了147x-509x、243x-1269x和332x-2185x的加速。

Conclusion: 该论文展示了使用数据科学语言对GraphBLAS公式的替代解释，并通过现成的ETL工具在NVIDIA的RAPIDS生态系统中实现了新的图挑战，显著提升了软件加速性能。

Abstract: The HPEC Graph Challenge is a collection of benchmarks representing complex
workloads that test the hardware and software components of HPC systems, which
traditional benchmarks, such as LINPACK, do not. The first benchmark, Subgraph
Isomorphism, focused on several compute-bound and memory-bound kernels. The
most recent of the challenges, the Anonymized Network Sensing Graph Challenge,
represents a shift in direction, as it represents a longer end-to-end workload
that requires many more software components, including, but not limited to,
data I/O, data structures for representing graph data, and a wide range of
functions for data preparation and network analysis. A notable feature of this
new graph challenge is the use of GraphBLAS to represent the computational
aspects of the problem statement. In this paper, we show an alternative
interpretation of the GraphBLAS formulations using the language of data
science. With this formulation, we show that the new graph challenge can be
implemented using off-the-shelf ETL tools available in open-source, enterprise
software such as NVIDIA's RAPIDS ecosystem. Using off-the-shelf software,
RAPIDS cuDF and cupy, we enable significant software acceleration without
requiring any specific HPC code and show speedups, over the same code running
with Pandas on the CPU, of 147x-509x on an NVIDIA A100 GPU, 243x-1269X for an
NVIDIA H100 GPU, and 332X-2185X for an NVIDIA H200 GPU.

</details>


### [123] [Distributed Download from an External Data Source in Asynchronous Faulty Settings](https://arxiv.org/abs/2509.03755)
*John Augustine,Soumyottam Chatterjee,Valerie King,Manish Kumar,Shachar Meir,David Peleg*

Main category: cs.DC

TL;DR: 本文首次研究异步通信网络中的分布式数据检索问题，提出了针对崩溃和拜占庭故障的查询最优方案，并分析了随机协议的性能。


<details>
  <summary>Details</summary>
Motivation: 扩展分布式数据检索问题到异步通信网络，填补了之前研究仅关注同步网络的空白，旨在设计查询复杂度低且容错性高的协议。

Method: 研究在异步通信网络中的分布式数据检索问题，提出了针对崩溃和拜占庭故障模型的确定性解决方案，并分析了随机协议的性能。

Result: 在崩溃故障模型中提出了查询最优的确定性方案；在拜占庭故障模型中，证明了随机协议在异步模型下的查询复杂度下界，并展示了对于β<1/2存在查询复杂度接近最优的随机协议。

Conclusion: 本文提出了在异步通信网络中解决分布式数据检索（Download）问题的确定性方案，能够容忍任何固定比例的崩溃故障（β<1）。在拜占庭故障模型中，证明了随机协议在异步模型下对于β≥1/2的查询复杂度下界，并展示了对于β<1/2存在查询复杂度接近最优的随机协议。

Abstract: The distributedData Retrieval (DR) model consists of $k$ peers connected by a
complete peer-to-peer communication network, and a trusted external data source
that stores an array $\textbf{X}$ of $n$ bits ($n \gg k$). Up to $\beta k$ of
the peers might fail in any execution (for $\beta \in [0, 1)$). Peers can
obtain the information either by inexpensive messages passed among themselves
or through expensive queries to the source array $\textbf{X}$. In the DR model,
we focus on designing protocols that minimize the number of queries performed
by any nonfaulty peer (a measure referred to as query complexity) while
maximizing the resilience parameter $\beta$.
  The Download problem requires each nonfaulty peer to correctly learn the
entire array $\textbf{X}$. Earlier work on this problem focused on synchronous
communication networks and established several deterministic and randomized
upper and lower bounds. Our work is the first to extend the study of
distributed data retrieval to asynchronous communication networks. We address
the Download problem under both the Byzantine and crash failure models. We
present query-optimal deterministic solutions in an asynchronous model that can
tolerate any fixed fraction $\beta<1$ of crash faults. In the Byzantine failure
model, it is known that deterministic protocols incur a query complexity of
$\Omega(n)$ per peer, even under synchrony. We extend this lower bound to
randomized protocols in the asynchronous model for $\beta \geq 1/2$, and
further show that for $\beta < 1/2$, a randomized protocol exists with
near-optimal query complexity. To the best of our knowledge, this is the first
work to address the Download problem in asynchronous communication networks.

</details>


### [124] [Gathering of asynchronous robots on circle with limited visibility using finite communication](https://arxiv.org/abs/2509.04004)
*Avisek Sharma,Satakshi Ghosh,Buddhadeb Sau*

Main category: cs.DC

TL;DR: 提出了一种在π-可见性模型下，有限通信能力（FCOM）机器人非刚性运动的聚集算法，适用于完全异步调度器。


<details>
  <summary>Details</summary>
Motivation: 解决在有限可见性（π-可见性）和完全异步调度器下，具有有限通信能力的机器人聚集问题，填补了现有研究在非刚性运动和完全异步条件下的空白。

Method: 通过有限通信能力（FCOM）和非刚性运动，设计了一种适用于π-可见性模型的算法。

Result: 成功实现了在π-可见性模型下，具有有限通信能力（FCOM）的机器人在完全异步调度器下的聚集。

Conclusion: 本文提出了一种在π-可见性模型下，具有有限通信能力（FCOM）的机器人实现聚集的算法，解决了在完全异步调度器下非刚性运动的机器人聚集问题。

Abstract: This work addresses the gathering problem for a set of autonomous, anonymous,
and homogeneous robots with limited visibility operating in a continuous
circle. The robots are initially placed at distinct positions, forming a
rotationally asymmetric configuration. The robots agree on the clockwise
direction. In the $\theta$-visibility model, a robot can only see those robots
on the circle that are at an angular distance $<\theta$ from it. Di Luna
\textit{et. al.} [DISC'20] have shown that, in $\pi/2$ visibility, gathering is
impossible. In addition, they provided an algorithm for robots with $\pi$
visibility, operating under a semi-synchronous scheduler. In the $\pi$
visibility model, only one point, the point at the angular distance $\pi$ is
removed from the visibility. Ghosh \textit{et. al.} [SSS'23] provided a
gathering algorithm for $\pi$ visibility model with robot having finite memory
($\mathcal{FSTA}$), operating under a special asynchronous scheduler.
  If the robots can see all points on the circle, then the gathering can be
done by electing a leader in the weakest robot model under a fully asynchronous
scheduler. However, previous works have shown that even the removal of one
point from the visibility makes gathering difficult. In both works, the robots
had rigid movement. In this work, we propose an algorithm that solves the
gathering problem under the $\pi$-visibility model for robots that have finite
communication ability ($\mathcal{FCOM}$). In this work the robot movement is
non-rigid and the robots work under a fully asynchronous scheduler.

</details>


### [125] [Counterfactual simulations for large scale systems with burnout variables](https://arxiv.org/abs/2509.04038)
*Benjamin Heymann*

Main category: cs.DC

TL;DR: 提出基于不确定性松弛的新算法，解决燃尽变量系统中反事实估计的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 在大规模系统中，燃尽变量（开始时活跃、影响动态并在满足特定条件后不可逆地失活）的存在使得模拟假设场景计算量大，且替代轨迹通常需要顺序处理，难以扩展。这在在线广告等场景中尤为突出，因为预算限制使得反事实分析复杂化。

Method: 引入了一种称为不确定性松弛的新算法，支持高效的并行计算。

Result: 新算法通过不确定性松弛实现了高效的并行计算，显著提升了反事实估计的可扩展性。

Conclusion: 本文提出了一种基于不确定性松弛的新算法，显著提高了具有燃尽变量系统中反事实估计的可扩展性。

Abstract: We consider large-scale systems influenced by burnout variables - state
variables that start active, shape dynamics, and irreversibly deactivate once
certain conditions are met. Simulating what-if scenarios in such systems is
computationally demanding, as alternative trajectories often require sequential
processing, which does not scale very well. This challenge arises in settings
like online advertising, because of campaigns budgets, complicating
counterfactual analysis despite rich data availability. We introduce a new type
of algorithms based on what we refer to as uncertainty relaxation, that enables
efficient parallel computation, significantly improving scalability for
counterfactual estimation in systems with burnout variables.

</details>


### [126] [LowDiff: Efficient Frequent Checkpointing via Low-Cost Differential for High-Performance Distributed Training Systems](https://arxiv.org/abs/2509.04084)
*Chenxuan Yao,Yuchong Hu,Feifan Liu,Zhengyu Liu,Dan Feng*

Main category: cs.DC

TL;DR: LowDiff 通过重用压缩梯度和动态优化，实现高效频繁检查点，适用于通用分布式训练系统，显著降低开销。


<details>
  <summary>Details</summary>
Motivation: 分布式训练大型深度学习模型常因失败而需要检查点恢复。现有方法频繁检查点导致高成本，而差异检查点又局限于推荐系统。因此，需要一种适用于通用分布式训练系统的高效检查点框架。

Method: LowDiff 采用重用压缩梯度的策略作为差异检查点，并引入批量梯度写入优化和动态调整检查点频率和批量大小的机制。此外，还结合了分层梯度重用和快照方法，以及基于CPU的异步持久化策略。

Result: 实验表明，LowDiff 可以在每次迭代中实现检查点频率，且运行时开销小于3.1%。

Conclusion: LowDiff 是一种高效的频繁检查点框架，通过重用压缩梯度作为差异检查点来降低成本，并通过动态调整检查点频率和批量大小来最大化性能。实验证明，LowDiff 可以在每次迭代中实现检查点频率，且运行时开销小于3.1%。

Abstract: Distributed training of large deep-learning models often leads to failures,
so checkpointing is commonly employed for recovery. State-of-the-art studies
focus on frequent checkpointing for fast recovery from failures. However, it
generates numerous checkpoints, incurring substantial costs and thus degrading
training performance. Recently, differential checkpointing has been proposed to
reduce costs, but it is limited to recommendation systems, so its application
to general distributed training systems remains unexplored.
  This paper proposes LowDiff, an efficient frequent checkpointing framework
that \textit{reuses} compressed gradients, serving as differential checkpoints
to reduce cost. Furthermore, LowDiff incorporates a batched gradient write
optimization to persist these differentials to storage efficiently. It also
dynamically tunes both the checkpoint frequency and the batching size to
maximize performance. We further enhance LowDiff with a layer-wise gradient
reusing and snapshotting approach and a CPU-based asynchronous persistence
strategy, enabling frequent checkpointing without gradient compression.
Experiments on various workloads show that LowDiff can achieve checkpointing
frequency up to per iteration with less than 3.1\% runtime overhead.

</details>


### [127] [Trustworthy Second-hand Marketplace for Built Environment](https://arxiv.org/abs/2509.04085)
*Stanly Wilson,Kwabena Adu-Duodu,Yinhao Li,Ringo Sham,Yingli Wang,Ellis Solaiman,Charith Perera,Rajiv Ranjan,Omer Rana*

Main category: cs.DC

TL;DR: 论文提出一个区块链赋能的数字市场，利用IPFS确保建筑材料再利用的透明性和可追溯性，提升信任和效率，推动可持续建筑实践。


<details>
  <summary>Details</summary>
Motivation: 建筑行业在材料浪费和可持续实践方面面临重大挑战，需要整合自动化、可追溯性和去中心化决策的创新解决方案。

Method: 开发了一个基于区块链和IPFS的框架，用于展示市场的操作流程，确保材料的透明性和可追溯性。

Result: 该框架增强了材料交换中的信任和问责制，解决了工业自动化和循环供应链中的关键挑战。

Conclusion: 该论文提出的区块链赋能数字市场为可持续建筑材料的再利用提供了高效、透明的解决方案，代表了迈向更可持续建筑实践的重要一步。

Abstract: The construction industry faces significant challenges regarding material
waste and sustainable practices, necessitating innovative solutions that
integrate automation, traceability, and decentralised decision-making to enable
efficient material reuse. This paper presents a blockchain-enabled digital
marketplace for sustainable construction material reuse, ensuring transparency
and traceability using InterPlanetary File System (IPFS). The proposed
framework enhances trust and accountability in material exchange, addressing
key challenges in industrial automation and circular supply chains. A framework
has been developed to demonstrate the operational processes of the marketplace,
illustrating its practical application and effectiveness. Our contributions
show how the marketplace can facilitate the efficient and trustworthy exchange
of reusable materials, representing a substantial step towards more sustainable
construction practices.

</details>


### [128] [On the impact of unlimited computational power in OBLOT: consequences for synchronous robots on graphs](https://arxiv.org/abs/2509.04383)
*Serafino Cicerone,Alessia Di Fonso,Gabriele Di Stefano,Alfredo Navarra*

Main category: cs.DC

TL;DR: 本文探讨了无限计算能力对同步机器人在有限图上移动的影响，并设计了一个高效算法，保证最小移动和轮数。


<details>
  <summary>Details</summary>
Motivation: OBLOT模型中的机器人能力有限，算法设计具有挑战性。过去的研究忽略了计算能力的影响，本文旨在探讨无限计算能力对算法性能的影响。

Method: 通过利用无限计算能力，设计了一个确定性解决算法，适用于同步机器人在有限图上的移动问题。

Result: 提出的算法在保证最小移动和轮数的同时，适用于广泛的同步机器人问题。

Conclusion: 本文证明了在有限图上同步移动的机器人中，无限计算能力对算法设计有显著影响，并提供了一个适用于广泛问题且保证最小移动和轮数的确定性解决算法。

Abstract: The OBLOT model has been extensively studied in theoretical swarm robotics.
It assumes weak capabilities for the involved mobile robots, such as they are
anonymous, disoriented, no memory of past events (oblivious), and silent. Their
only means of (implicit) communication is transferred to their positioning,
i.e., stigmergic information. These limited capabilities make the design of
distributed algorithms a challenging task. Over the last two decades, numerous
research papers have addressed the question of which tasks can be accomplished
within this model. Nevertheless, as it usually happens in distributed
computing, also in OBLOT the computational power available to the robots is
neglected as the main cost measures for the designed algorithms refer to the
number of movements or the number of rounds required. In this paper, we prove
that for synchronous robots moving on finite graphs, the unlimited
computational power (other than finite time) has a significant impact. In fact,
by exploiting it, we provide a definitive resolution algorithm that applies to
a wide class of problems while guaranteeing the minimum number of moves and
rounds.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [129] [Hypothesis Selection: A High Probability Conundrum](https://arxiv.org/abs/2509.03734)
*Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Sandeep Silwal*

Main category: cs.DS

TL;DR: 论文优化了假设选择算法的时间复杂度，并在多个设置中解决了开放性问题。


<details>
  <summary>Details</summary>
Motivation: 解决假设选择问题中未解决的关键方面，包括最优运行时间和近似因子。

Method: 通过改进算法设计，减少了时间复杂度的参数依赖，并研究了三种替代设置下的假设选择问题。

Result: 将时间复杂度从$\tilde{O}(n/(\delta^3\varepsilon^3))$优化为$\tilde{O}(n/(\delta \varepsilon^2))$，并在三种替代设置中取得进展。

Conclusion: 该论文在假设选择问题上取得了显著进展，优化了算法的时间复杂度，并在多个替代设置中解决了开放性问题。

Abstract: In the hypothesis selection problem, we are given a finite set of candidate
distributions (hypotheses), $\mathcal{H} = \{H_1, \ldots, H_n\}$, and samples
from an unknown distribution $P$. Our goal is to find a hypothesis $H_i$ whose
total variation distance to $P$ is comparable to that of the nearest hypothesis
in $\mathcal{H}$. If the minimum distance is $\mathsf{OPT}$, we aim to output
an $H_i$ such that, with probability at least $1-\delta$, its total variation
distance to $P$ is at most $C \cdot \mathsf{OPT} + \varepsilon$.
  Despite decades of work, key aspects of this problem remain unresolved,
including the optimal running time for algorithms that achieve the optimal
sample complexity and best possible approximation factor of $C=3$. The previous
state-of-the-art result [Aliakbarpour, Bun, Smith, NeurIPS 2024] provided a
nearly linear in $n$ time algorithm but with a sub-optimal dependence on the
other parameters, running in $\tilde{O}(n/(\delta^3\varepsilon^3))$ time. We
improve this time complexity to $\tilde{O}(n/(\delta \varepsilon^2))$,
significantly reducing the dependence on the confidence and error parameters.
  Furthermore, we study hypothesis selection in three alternative settings,
resolving or making progress on several open questions from prior works. (1) We
settle the optimal approximation factor when bounding the \textit{expected
distance} of the output hypothesis, rather than its high-probability
performance. (2) Assuming the numerical value of \textit{$\mathsf{OPT}$ is
known} in advance, we present an algorithm obtaining $C=3$ and runtime
$\tilde{O}(n/\varepsilon^2)$ with the optimal sample complexity and succeeding
with high probability in $n$. (3) Allowing polynomial \textit{preprocessing}
step on the hypothesis class $\mathcal{H}$ before observing samples, we present
an algorithm with $C=3$ and subquadratic runtime which succeeds with high
probability in $n$.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [130] [Towards Deterministic Sub-0.5 us Response on Linux through Interrupt Isolation](https://arxiv.org/abs/2509.03855)
*Zhouyi Zhou,Zhili Liu,Shancong Zhang,Jiemin Li,Dengke Du,Mengke Sun,Zhiqiang Wang,Hongyan Liu,Guogai Xu*

Main category: cs.OS

TL;DR: 该论文提出了一种中断隔离方法，通过集中和最小化定时器中断干扰，显著降低了抖动和响应延迟，实验证明其在ARM多核平台上能实现低于0.5微秒的响应时间。


<details>
  <summary>Details</summary>
Motivation: Linux中的实时响应能力常受中断争用和定时器处理开销的限制，难以实现亚微秒级延迟。

Method: 通过引入一个专用的API来选择性地调用定时器处理例程并抑制非关键性的处理器间中断，集中并最小化定时器中断对CPU核心的干扰。

Result: 在基于ARM的多核平台上进行的实验表明，所提出的机制持续实现了低于0.5微秒的响应时间，优于传统的Linux PREEMPT-RT配置。

Conclusion: 中断隔离作为一种轻量级且有效的策略，在通用操作系统中为确定性实时工作负载提供了显著潜力。

Abstract: Real-time responsiveness in Linux is often constrained by interrupt
contention and timer handling overhead, making it challenging to achieve
sub-microsecond latency. This work introduces an interrupt isolation approach
that centralizes and minimizes timer interrupt interference across CPU cores.
By enabling a dedicated API to selectively invoke timer handling routines and
suppress non-critical inter-processor interrupts, our design significantly
reduces jitter and response latency. Experiments conducted on an ARM-based
multicore platform demonstrate that the proposed mechanism consistently
achieves sub-0.5 us response times, outperforming conventional Linux PREEMPT-RT
configurations. These results highlight the potential of interrupt isolation as
a lightweight and effective strategy for deterministic real-time workloads in
general-purpose operating systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [131] [Self-Organizing Aerial Swarm Robotics for Resilient Load Transportation : A Table-Mechanics-Inspired Approach](https://arxiv.org/abs/2509.03563)
*Quan Quan,Jiwen Xu,Runxiao Liu,Yi Ding,Jiaxing Che,Kai-Yuan Cai*

Main category: cs.RO

TL;DR: 论文提出了一种受桌腿负载分配启发的分散式耗散力模型，显著提升了飞行机器人群体在复杂环境中的协作运输能力，实验验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在扩展性、通信依赖性和动态故障鲁棒性方面存在不足，而机器人群体协作空中运输在物流和灾害响应中具有变革潜力。

Method: 通过模仿桌腿负载分配的耗散力学，开发了一种分散式耗散力模型，使机器人能够基于局部邻居和悬挂负载动态调整位置。

Result: 仿真显示，该方法在能力变化、电缆不确定性、有限视野和负载变化等情况下，跟踪误差分别为现有方法的20%、68%、55.5%和21.9%。实际实验中，六架飞行机器人在单机故障、断开事件、25%负载变化和40%电缆长度不确定性的情况下，成功率高达94%，且在4级风力下表现出强鲁棒性。

Conclusion: 这篇论文提出了一种受物理启发的分散式耗散力模型，为飞行机器人群体在通信受限环境中实现自主编队稳定和自适应负载分配提供了可扩展框架。

Abstract: In comparison with existing approaches, which struggle with scalability,
communication dependency, and robustness against dynamic failures, cooperative
aerial transportation via robot swarms holds transformative potential for
logistics and disaster response. Here, we present a physics-inspired
cooperative transportation approach for flying robot swarms that imitates the
dissipative mechanics of table-leg load distribution. By developing a
decentralized dissipative force model, our approach enables autonomous
formation stabilization and adaptive load allocation without the requirement of
explicit communication. Based on local neighbor robots and the suspended
payload, each robot dynamically adjusts its position. This is similar to
energy-dissipating table leg reactions. The stability of the resultant control
system is rigorously proved. Simulations demonstrate that the tracking errors
of the proposed approach are 20%, 68%, 55.5%, and 21.9% of existing approaches
under the cases of capability variation, cable uncertainty, limited vision, and
payload variation, respectively. In real-world experiments with six flying
robots, the cooperative aerial transportation system achieved a 94% success
rate under single-robot failure, disconnection events, 25% payload variation,
and 40% cable length uncertainty, demonstrating strong robustness under outdoor
winds up to Beaufort scale 4. Overall, this physics-inspired approach bridges
swarm intelligence and mechanical stability principles, offering a scalable
framework for heterogeneous aerial systems to collectively handle complex
transportation tasks in communication-constrained environments.

</details>


### [132] [Cooperative Grasping for Collective Object Transport in Constrained Environments](https://arxiv.org/abs/2509.03638)
*David Alvear,George Turkiyyah,Shinkyu Park*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的协作抓取决策框架，通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决在受限环境中双机器人协作抓取和运输物体的决策问题。

Method: 提出了一种基于条件嵌入（CE）模型的框架，包含两个神经网络，将抓取配置信息映射到嵌入空间。采用监督学习和负采样方法训练神经网络。

Result: 模型能够可靠地识别可行的抓取配置，并在物理机器人平台上验证了其实际适用性。

Conclusion: 该框架通过仿真和物理机器人平台的实验验证了其在实际应用中的可靠性。

Abstract: We propose a novel framework for decision-making in cooperative grasping for
two-robot object transport in constrained environments. The core of the
framework is a Conditional Embedding (CE) model consisting of two neural
networks that map grasp configuration information into an embedding space. The
resulting embedding vectors are then used to identify feasible grasp
configurations that allow two robots to collaboratively transport an object. To
ensure generalizability across diverse environments and object geometries, the
neural networks are trained on a dataset comprising a range of environment maps
and object shapes. We employ a supervised learning approach with negative
sampling to ensure that the learned embeddings effectively distinguish between
feasible and infeasible grasp configurations. Evaluation results across a wide
range of environments and objects in simulations demonstrate the model's
ability to reliably identify feasible grasp configurations. We further validate
the framework through experiments on a physical robotic platform, confirming
its practical applicability.

</details>


### [133] [Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning](https://arxiv.org/abs/2509.03658)
*Antonio Guillen-Perez*

Main category: cs.RO

TL;DR: Efficient Virtuoso通过两阶段归一化和潜在扩散模型，在自动驾驶轨迹规划中实现了高效且高保真的性能，证明了多步路径比单点目标更有效。


<details>
  <summary>Details</summary>
Motivation: 生成多样且合理的未来轨迹分布是自动驾驶规划系统的关键能力，但现有生成模型在高保真度、计算效率和精确控制方面仍面临挑战。

Method: 提出了一个条件潜在扩散模型（Efficient Virtuoso），采用两阶段归一化管道（先缩放轨迹以保持几何纵横比，再归一化PCA潜在空间），并通过简单的MLP去噪器在低维潜在空间中进行高效去噪。模型还结合了基于Transformer的StateEncoder来融合丰富的场景上下文。

Result: 在Waymo Open Motion Dataset上实现了最先进的性能（minADE为0.25），并通过消融研究发现多步稀疏路径对于精确战术执行至关重要。

Conclusion: 通过两阶段归一化管道和低维潜在空间的高效去噪，Efficient Virtuoso在Waymo Open Motion Dataset上实现了最先进的性能（minADE为0.25），并证明了多步稀疏路径对于精确战术执行的重要性。

Abstract: The ability to generate a diverse and plausible distribution of future
trajectories is a critical capability for autonomous vehicle planning systems.
While recent generative models have shown promise, achieving high fidelity,
computational efficiency, and precise control remains a significant challenge.
In this paper, we present the \textbf{Efficient Virtuoso}, a conditional latent
diffusion model for goal-conditioned trajectory planning. Our approach
introduces a novel two-stage normalization pipeline that first scales
trajectories to preserve their geometric aspect ratio and then normalizes the
resulting PCA latent space to ensure a stable training target. The denoising
process is performed efficiently in this low-dimensional latent space by a
simple MLP denoiser, which is conditioned on a rich scene context fused by a
powerful Transformer-based StateEncoder. We demonstrate that our method
achieves state-of-the-art performance on the Waymo Open Motion Dataset,
reaching a \textbf{minADE of 0.25}. Furthermore, through a rigorous ablation
study on goal representation, we provide a key insight: while a single endpoint
goal can resolve strategic ambiguity, a richer, multi-step sparse route is
essential for enabling the precise, high-fidelity tactical execution that
mirrors nuanced human driving behavior.

</details>


### [134] [Low-Cost Open-Source Ambidextrous Robotic Hand with 23 Direct-Drive servos for American Sign Language Alphabet](https://arxiv.org/abs/2509.03690)
*Kelvin Daniel Gonzalez Amador*

Main category: cs.RO

TL;DR: VulcanV3是一款低成本、开源、3D打印的双手机器人手，能够完整再现ASL字母表，通过实验验证了高准确率，推动了辅助机器人技术的发展。


<details>
  <summary>Details</summary>
Motivation: 为了解决聋人社区手语交流的可及性问题，同时克服现有机器人解决方案的高成本和功能限制。

Method: 研究采用了23个直接驱动伺服执行器，由Arduino Mega和双PCA9685模块控制，实现了精确的手指和手腕动作。

Result: 实验测试证实了所有52个ASL手势的准确再现，参与者研究（n=33）达到了96.97%的识别准确率，视频演示后提高至98.78%。

Conclusion: VulcanV3通过结合低成本、完整的ASL覆盖和双手设计，推动了辅助机器人技术的发展，为无障碍通信技术和包容性创新做出了贡献。

Abstract: Accessible communication through sign language is vital for deaf communities,
1 yet robotic solutions are often costly and limited. This study presents
VulcanV3, a low- 2 cost, open-source, 3D-printed ambidextrous robotic hand
capable of reproducing the full 3 American Sign Language (ASL) alphabet (52
signs for right- and left-hand configurations). 4 The system employs 23
direct-drive servo actuators for precise finger and wrist movements, 5
controlled by an Arduino Mega with dual PCA9685 modules. Unlike most humanoid
upper- 6 limb systems, which rarely employ direct-drive actuation, VulcanV3
achieves complete ASL 7 coverage with a reversible design. All CAD files and
code are released under permissive 8 open-source licenses to enable
replication. Empirical tests confirmed accurate reproduction 9 of all 52 ASL
handshapes, while a participant study (n = 33) achieved 96.97% recognition 10
accuracy, improving to 98.78% after video demonstration. VulcanV3 advances
assistive 11 robotics by combining affordability, full ASL coverage, and
ambidexterity in an openly 12 shared platform, contributing to accessible
communication technologies and inclusive 13 innovation.

</details>


### [135] [Real-Time Buoyancy Estimation for AUV Simulations Using Convex Hull-Based Submerged Volume Calculation](https://arxiv.org/abs/2509.03804)
*Ad-Deen Mahbub,Md Ragib Shaharear*

Main category: cs.RO

TL;DR: 本文提出了一种实时计算AUV浮力的凸包方法，提高了模拟精度和效率。


<details>
  <summary>Details</summary>
Motivation: 由于NVIDIA Isaac Sim缺乏原生浮力系统，需要外部解决方案来实现精确的水下物理模拟。

Method: 通过提取模拟环境中的网格几何体，并计算沿z轴与水平面相交的船体部分，结合横截面面积扩展来减少计算开销。

Result: 该方法在SAUVC 2025自定义AUV设计上测试，实现了实时性能和可扩展性，提高了模拟保真度。

Conclusion: 本文提出了一种基于凸包的实时浮力计算方法，显著提高了AUV模拟的精度和实时性能，适用于水下机器人研究。

Abstract: Accurate real-time buoyancy modeling is essential for high-fidelity
Autonomous Underwater Vehicle (AUV) simulations, yet NVIDIA Isaac Sim lacks a
native buoyancy system, requiring external solutions for precise underwater
physics. This paper presents a novel convex hull-based approach to dynamically
compute the submerged volume of an AUV in real time. By extracting mesh
geometry from the simulation environment and calculating the hull portion
intersecting the water level along the z-axis, our method enhances accuracy
over traditional geometric approximations. A cross-sectional area extension
reduces computational overhead, enabling efficient buoyant force updates that
adapt to orientation, depth, and sinusoidal wave fluctuations (+-0.3 m). Tested
on a custom AUV design for SAUVC 2025, this approach delivers real-time
performance and scalability, improving simulation fidelity for underwater
robotics research without precomputed hydrodynamic models.

</details>


### [136] [INGRID: Intelligent Generative Robotic Design Using Large Language Models](https://arxiv.org/abs/2509.03842)
*Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian*

Main category: cs.RO

TL;DR: INGRID是一个自动化设计并行机器人机制的框架，通过结合互易螺旋理论和运动综合方法，生成新型并行机制，为非专业用户提供定制设计能力，解耦硬件限制与机器人智能进步。


<details>
  <summary>Details</summary>
Motivation: 当前机器人系统受限于串行机制硬件依赖，限制了机器人智能的范围，因此需要一种能够自动设计并行机器人机制的方法。

Method: INGRID框架通过深度整合互易螺旋理论和运动综合方法，将设计挑战分解为四个渐进任务：约束分析、运动关节生成、链构建和完整机制设计。

Result: INGRID能够生成具有固定和可变移动性的新型并行机制，并通过三个案例研究验证了其帮助用户根据所需移动性设计任务特定并行机器人的能力。

Conclusion: INGRID通过将机制理论与机器学习结合，为非专业机器人研究人员提供了设计定制并行机制的能力，从而解耦了机器人智能进步与硬件限制的关系，为机制智能奠定了基础。

Abstract: The integration of large language models (LLMs) into robotic systems has
accelerated progress in embodied artificial intelligence, yet current
approaches remain constrained by existing robotic architectures, particularly
serial mechanisms. This hardware dependency fundamentally limits the scope of
robotic intelligence. Here, we present INGRID (Intelligent Generative Robotic
Design), a framework that enables the automated design of parallel robotic
mechanisms through deep integration with reciprocal screw theory and kinematic
synthesis methods. We decompose the design challenge into four progressive
tasks: constraint analysis, kinematic joint generation, chain construction, and
complete mechanism design. INGRID demonstrates the ability to generate novel
parallel mechanisms with both fixed and variable mobility, discovering
kinematic configurations not previously documented in the literature. We
validate our approach through three case studies demonstrating how INGRID
assists users in designing task-specific parallel robots based on desired
mobility requirements. By bridging the gap between mechanism theory and machine
learning, INGRID enables researchers without specialized robotics training to
create custom parallel mechanisms, thereby decoupling advances in robotic
intelligence from hardware constraints. This work establishes a foundation for
mechanism intelligence, where AI systems actively design robotic hardware,
potentially transforming the development of embodied AI systems.

</details>


### [137] [Learning Multi-Stage Pick-and-Place with a Legged Mobile Manipulator](https://arxiv.org/abs/2509.03859)
*Haichao Zhang,Haonan Yu,Le Zhao,Andrew Choi,Qinxun Bai,Yiqing Yang,Wei Xu*

Main category: cs.RO

TL;DR: 该研究通过模拟训练开发了一种视觉-运动策略，在现实世界中实现了高效的四足机器人移动操纵，成功率近80%。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人移动操纵中的技能多样性、长任务周期和部分可观测性等挑战。

Method: 提出了一种多阶段拾取-放置任务框架，采用模拟训练方法，并通过消融研究验证了高效训练和模拟到现实转换的关键技术。

Result: 训练出的策略在现实世界中实现了近80%的成功率，并展示了搜索、接近、抓取、运输和放置等行为。

Conclusion: 通过模拟训练和现实世界测试，该研究成功开发了一种视觉-运动策略，实现了近80%的成功率，展示了在多种环境中部署的潜力。

Abstract: Quadruped-based mobile manipulation presents significant challenges in
robotics due to the diversity of required skills, the extended task horizon,
and partial observability. After presenting a multi-stage pick-and-place task
as a succinct yet sufficiently rich setup that captures key desiderata for
quadruped-based mobile manipulation, we propose an approach that can train a
visuo-motor policy entirely in simulation, and achieve nearly 80\% success in
the real world. The policy efficiently performs search, approach, grasp,
transport, and drop into actions, with emerged behaviors such as re-grasping
and task chaining. We conduct an extensive set of real-world experiments with
ablation studies highlighting key techniques for efficient training and
effective sim-to-real transfer. Additional experiments demonstrate deployment
across a variety of indoor and outdoor environments. Demo videos and additional
resources are available on the project page:
https://horizonrobotics.github.io/gail/SLIM.

</details>


### [138] [Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance](https://arxiv.org/abs/2509.03889)
*Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez*

Main category: cs.RO

TL;DR: 该论文提出了一个双臂视觉触觉框架，用于直接操作褶皱和悬挂的衣物，结合了密集视觉对应和触觉监督的抓取能力，提高了在高度遮挡环境下的操作能力。


<details>
  <summary>Details</summary>
Motivation: 衣物操作具有挑战性，因为其复杂的配置、多变的材料动力学和频繁的自遮挡。现有系统通常需要将衣物平整或假设关键特征可见。

Method: 通过训练一个自定义的高保真模拟数据集上的对应模型，使用分布损失捕捉布料对称性并生成对应置信度估计。这些估计指导一个反应式状态机，根据感知不确定性调整折叠策略。同时，一个视觉触觉抓取能力网络，利用高分辨率触觉反馈进行自监督，确定哪些区域是可抓取的。

Result: 该系统在折叠和悬挂任务中展示了任务无关的抓取选择模块的有效性，其密集描述符还为其他规划模式提供了可重用的中间表示，如从人类视频演示中提取抓取目标。

Conclusion: 该论文提出了一种双臂视觉触觉框架，结合了置信度感知的密集视觉对应和触觉监督的抓取能力，能够在高度遮挡的桌面上或空中操作褶皱和悬挂的衣物。

Abstract: Manipulating clothing is challenging due to complex configurations, variable
material dynamics, and frequent self-occlusion. Prior systems often flatten
garments or assume visibility of key features. We present a dual-arm
visuotactile framework that combines confidence-aware dense visual
correspondence and tactile-supervised grasp affordance to operate directly on
crumpled and suspended garments. The correspondence model is trained on a
custom, high-fidelity simulated dataset using a distributional loss that
captures cloth symmetries and generates correspondence confidence estimates.
These estimates guide a reactive state machine that adapts folding strategies
based on perceptual uncertainty. In parallel, a visuotactile grasp affordance
network, self-supervised using high-resolution tactile feedback, determines
which regions are physically graspable. The same tactile classifier is used
during execution for real-time grasp validation. By deferring action in
low-confidence states, the system handles highly occluded table-top and in-air
configurations. We demonstrate our task-agnostic grasp selection module in
folding and hanging tasks. Moreover, our dense descriptors provide a reusable
intermediate representation for other planning modalities, such as extracting
grasp targets from human video demonstrations, paving the way for more
generalizable and scalable garment manipulation.

</details>


### [139] [Odometry Calibration and Pose Estimation of a 4WIS4WID Mobile Wall Climbing Robot](https://arxiv.org/abs/2509.04016)
*Branimir Ćaran,Vladimir Milić,Marko Švaco,Bojan Jerbić*

Main category: cs.RO

TL;DR: 本文设计了一种基于多模态测量融合的壁面爬行机器人姿态估计器，解决了传统定位方法在复杂环境中的不可靠性问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 壁面爬行机器人在建筑环境中需要精确的姿态信息，但传统定位传感器（如激光、超声波或雷达）和GPS在此类环境中不可靠，因此需要开发基于多模态测量的姿态估计器。

Method: 采用扩展卡尔曼滤波（EKF）和无迹卡尔曼滤波（UKF）融合轮式里程计、视觉里程计和IMU数据。系统参数校准使用非线性优化和Levenberg-Marquardt方法，运动学参数校准使用遗传算法和粒子群算法。

Result: 实验验证了校准方法和姿态估计器的性能，表明其在复杂环境中具有较高的准确性和鲁棒性。

Conclusion: 本文提出了一种基于多模态测量融合的4WIS4WID壁面爬行移动机器人姿态估计器设计，并通过实验验证了其性能。

Abstract: This paper presents the design of a pose estimator for a four wheel
independent steer four wheel independent drive (4WIS4WID) wall climbing mobile
robot, based on the fusion of multimodal measurements, including wheel
odometry, visual odometry, and an inertial measurement unit (IMU) data using
Extended Kalman Filter (EKF) and Unscented Kalman Filter (UKF). The pose
estimator is a critical component of wall climbing mobile robots, as their
operational environment involves carrying precise measurement equipment and
maintenance tools in construction, requiring information about pose on the
building at the time of measurement. Due to the complex geometry and material
properties of building facades, the use of traditional localization sensors
such as laser, ultrasonic, or radar is often infeasible for wall-climbing
robots. Moreover, GPS-based localization is generally unreliable in these
environments because of signal degradation caused by reinforced concrete and
electromagnetic interference. Consequently, robot odometry remains the primary
source of velocity and position information, despite being susceptible to drift
caused by both systematic and non-systematic errors. The calibrations of the
robot's systematic parameters were conducted using nonlinear optimization and
Levenberg-Marquardt methods as Newton-Gauss and gradient-based model fitting
methods, while Genetic algorithm and Particle swarm were used as
stochastic-based methods for kinematic parameter calibration. Performance and
results of the calibration methods and pose estimators were validated in detail
with experiments on the experimental mobile wall climbing robot.

</details>


### [140] [FPC-VLA: A Vision-Language-Action Framework with a Supervisor for Failure Prediction and Correction](https://arxiv.org/abs/2509.04018)
*Yifan Yang,Zhixiang Duan,Tianshi Xie,Fuyu Cao,Pinxi Shen,Peili Song,Piaopiao Jin,Guokang Sun,Shaoqing Xu,Yangwei You,Jingtai Liu*

Main category: cs.RO

TL;DR: FPC-VLA结合VLA与监督器，提升机器人任务成功率，适用于多样化、长时程任务，具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统感知-规划流程在开放式任务中灵活性不足，而单一VLA模型缺乏故障预测和恢复机制。

Method: 提出FPC-VLA双模型框架，结合VLA和监督器，通过视觉语言查询评估行动可行性并生成纠正策略，无需手动标注训练。

Result: 在多个仿真平台和机器人实体上，FPC-VLA在零样本和微调设置中均优于现有模型，任务成功率显著提升且执行时间影响最小。

Conclusion: FPC-VLA通过整合VLA与监督器，显著提升了任务成功率，并在实际部署中展示了强大的泛化能力和实用性。

Abstract: Robotic manipulation is a fundamental component of automation. However,
traditional perception-planning pipelines often fall short in open-ended tasks
due to limited flexibility, while the architecture of a single end-to-end
Vision-Language-Action (VLA) offers promising capabilities but lacks crucial
mechanisms for anticipating and recovering from failure. To address these
challenges, we propose FPC-VLA, a dual-model framework that integrates VLA with
a supervisor for failure prediction and correction. The supervisor evaluates
action viability through vision-language queries and generates corrective
strategies when risks arise, trained efficiently without manual labeling. A
similarity-guided fusion module further refines actions by leveraging past
predictions. Evaluation results on multiple simulation platforms (SIMPLER and
LIBERO) and robot embodiments (WidowX, Google Robot, Franka) show that FPC-VLA
outperforms state-of-the-art models in both zero-shot and fine-tuned settings.
By activating the supervisor only at keyframes, our approach significantly
increases task success rates with minimal impact on execution time. Successful
real-world deployments on diverse, long-horizon tasks confirm FPC-VLA's strong
generalization and practical utility for building more reliable autonomous
systems.

</details>


### [141] [Integrated Wheel Sensor Communication using ESP32 -- A Contribution towards a Digital Twin of the Road System](https://arxiv.org/abs/2509.04061)
*Ventseslav Yordanov,Simon Schäfer,Alexander Mann,Stefan Kowalewski,Bassam Alrifaee,Lutz Eckstein*

Main category: cs.RO

TL;DR: 本文提出了一种基于发布-订阅系统的高效通信方法，用于传输轮速传感器数据，测试显示数据丢失率仅为0.1%。


<details>
  <summary>Details</summary>
Motivation: 现有的车载状态估计方法无法深入分析轮胎与路面的交互作用，因此需要一种更高效的数据传输方法。

Method: 采用发布-订阅系统，通过ESP32微控制器传输集成轮速传感器数据，并在1 Hz至32,000 Hz的不同采样频率下进行测试。

Result: 原型传感器系统在鼓式轮胎测试台上展示了极低的数据丢失率（约0.1%），验证了通信系统的可靠性。

Conclusion: 本研究通过开发一种高效的通信系统，显著提升了集成轮速传感器数据的实时采集能力，为优化轮胎与路面交互提供了新的见解。

Abstract: While current onboard state estimation methods are adequate for most driving
and safety-related applications, they do not provide insights into the
interaction between tires and road surfaces. This paper explores a novel
communication concept for efficiently transmitting integrated wheel sensor data
from an ESP32 microcontroller. Our proposed approach utilizes a
publish-subscribe system, surpassing comparable solutions in the literature
regarding data transmission volume. We tested this approach on a drum tire test
rig with our prototype sensors system utilizing a diverse selection of sample
frequencies between 1 Hz and 32 000 Hz to demonstrate the efficacy of our
communication concept. The implemented prototype sensor showcases minimal data
loss, approximately 0.1 % of the sampled data, validating the reliability of
our developed communication system. This work contributes to advancing
real-time data acquisition, providing insights into optimizing integrated wheel
sensor communication.

</details>


### [142] [Cloud-Assisted Remote Control for Aerial Robots: From Theory to Proof-of-Concept Implementation](https://arxiv.org/abs/2509.04095)
*Achilleas Santi Seisa,Viswa Narayanan Sankaranarayanan,Gerasimos Damigos,Sumeet Gajanan Satpute,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 论文提出容器化框架测试云机器人系统，解决网络延迟与安全问题，通过UDP隧道和流量控制模拟实际条件，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 云机器人技术虽具有卸载计算密集型任务、促进数据共享和增强机器人协调等优势，但网络延迟、安全问题和资源管理效率仍是其集成的主要挑战。

Method: 框架由两部分组成：容器化的云集群和容器化的机器人模拟环境，通过UDP隧道实现双向通信，并利用Linux流量控制模拟实际网络条件。

Result: 通过云辅助远程控制空中机器人的用例验证，该框架成功模拟了实际部署中的网络条件，展示了其可行性和有效性。

Conclusion: 该论文提出了一个基于容器化技术的可扩展框架，用于测试云和边缘机器人系统，有效解决了网络延迟和安全问题，为云机器人技术的实际部署提供了实用工具。

Abstract: Cloud robotics has emerged as a promising technology for robotics
applications due to its advantages of offloading computationally intensive
tasks, facilitating data sharing, and enhancing robot coordination. However,
integrating cloud computing with robotics remains a complex challenge due to
network latency, security concerns, and the need for efficient resource
management. In this work, we present a scalable and intuitive framework for
testing cloud and edge robotic systems. The framework consists of two main
components enabled by containerized technology: (a) a containerized cloud
cluster and (b) the containerized robot simulation environment. The system
incorporates two endpoints of a User Datagram Protocol (UDP) tunnel, enabling
bidirectional communication between the cloud cluster container and the robot
simulation environment, while simulating realistic network conditions. To
achieve this, we consider the use case of cloud-assisted remote control for
aerial robots, while utilizing Linux-based traffic control to introduce
artificial delay and jitter, replicating variable network conditions
encountered in practical cloud-robot deployments.

</details>


### [143] [Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models](https://arxiv.org/abs/2509.04063)
*Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang*

Main category: cs.RO

TL;DR: ARFM是一种自适应强化流匹配算法，通过调整VLA流模型损失中的缩放因子，优化RL信号对流损失的影响，显著提升了模型在复杂任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在复杂下游任务上的动作准确性不足，主要原因是这些模型仅依赖于模仿学习的后训练范式，难以深入理解数据质量的分布特性，而这正是RL所擅长的。

Method: 提出了一种离线RL后训练目标，并推导出了一种高效可行的离线RL微调算法——自适应强化流匹配（ARFM）。通过引入自适应调整的缩放因子，构建了偏差-方差权衡的目标函数。

Result: 广泛的仿真和真实世界实验结果表明，ARFM在泛化性、鲁棒性、少样本学习和持续学习方面表现出色。

Conclusion: ARFM通过自适应调整VLA流模型损失中的缩放因子，构建了一个有原则的偏差-方差权衡目标函数，从而在RL信号对流损失的影响上实现了最优控制。实验结果表明，ARFM在泛化性、鲁棒性、少样本学习和持续学习方面表现出色。

Abstract: Vision-Language-Action (VLA) models based on flow matching have shown
excellent performance in general-purpose robotic manipulation tasks. However,
the action accuracy of these models on complex downstream tasks is
unsatisfactory. One important reason is that these models rely solely on the
post-training paradigm of imitation learning, which makes it difficult to have
a deeper understanding of the distribution properties of data quality, which is
exactly what Reinforcement Learning (RL) excels at. In this paper, we
theoretically propose an offline RL post-training objective for VLA flow models
and induce an efficient and feasible offline RL fine-tuning algorithm --
Adaptive Reinforced Flow Matching (ARFM). By introducing an adaptively adjusted
scaling factor in the VLA flow model loss, we construct a principled
bias-variance trade-off objective function to optimally control the impact of
RL signal on flow loss. ARFM adaptively balances RL advantage preservation and
flow loss gradient variance control, resulting in a more stable and efficient
fine-tuning process. Extensive simulation and real-world experimental results
show that ARFM exhibits excellent generalization, robustness, few-shot
learning, and continuous learning performance.

</details>


### [144] [Solving Robotics Tasks with Prior Demonstration via Exploration-Efficient Deep Reinforcement Learning](https://arxiv.org/abs/2509.04069)
*Chengyandan Shen,Christoffer Sloth*

Main category: cs.RO

TL;DR: DRLR框架通过改进动作选择和采用SAC策略，提升了机器人任务的探索效率和性能，成功应用于模拟和真实场景。


<details>
  <summary>Details</summary>
Motivation: 解决传统强化学习在机器人任务中探索效率低和容易收敛到次优策略的问题。

Method: 提出了基于IBRL算法的DRLR框架，改进动作选择模块以提供校准的Q值，并采用SAC作为RL策略。

Result: 在模拟和真实机器人任务中验证了DRLR框架的有效性和鲁棒性，特别是在桶装载和开抽屉任务中表现优异。

Conclusion: DRLR框架通过改进的动作选择模块和SAC策略，有效减少了引导误差并防止过拟合，成功应用于模拟和真实的工业机器人任务。

Abstract: This paper proposes an exploration-efficient Deep Reinforcement Learning with
Reference policy (DRLR) framework for learning robotics tasks that incorporates
demonstrations. The DRLR framework is developed based on an algorithm called
Imitation Bootstrapped Reinforcement Learning (IBRL). We propose to improve
IBRL by modifying the action selection module. The proposed action selection
module provides a calibrated Q-value, which mitigates the bootstrapping error
that otherwise leads to inefficient exploration. Furthermore, to prevent the RL
policy from converging to a sub-optimal policy, SAC is used as the RL policy
instead of TD3. The effectiveness of our method in mitigating bootstrapping
error and preventing overfitting is empirically validated by learning two
robotics tasks: bucket loading and open drawer, which require extensive
interactions with the environment. Simulation results also demonstrate the
robustness of the DRLR framework across tasks with both low and high
state-action dimensions, and varying demonstration qualities. To evaluate the
developed framework on a real-world industrial robotics task, the bucket
loading task is deployed on a real wheel loader. The sim2real results validate
the successful deployment of the DRLR framework.

</details>


### [145] [Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot](https://arxiv.org/abs/2509.04076)
*Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter*

Main category: cs.RO

TL;DR: 提出了一种基于扩散的机器人运动规划模型，通过深度学习显著减少运行时间，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统数值规划方法在解决一般运动规划问题时存在显著的运行时需求，研究者希望通过深度学习技术提升效率。

Method: 通过深度学习从规划器生成的数据集中学习，利用点云嵌入预测关键点关节序列，并在消融研究中发现并解决了数据集偏差问题。

Result: 模型在运行时间上比数值模型快一个数量级，测试集上的无碰撞解决方案成功率达到90%。

Conclusion: 该研究提出的扩散基动作模型在机器人运动规划中显著减少了运行时间，并在不使用点云编码的情况下，性能优于传统数值模型，测试集上的无碰撞解决方案成功率高达90%。

Abstract: We propose a novel diffusion-based action model for robotic motion planning.
Commonly, established numerical planning approaches are used to solve general
motion planning problems, but have significant runtime requirements. By
leveraging the power of deep learning, we are able to achieve good results in a
much smaller runtime by learning from a dataset generated by these planners.
While our initial model uses point cloud embeddings in the input to predict
keypoint-based joint sequences in its output, we observed in our ablation study
that it remained challenging to condition the network on the point cloud
embeddings. We identified some biases in our dataset and refined it, which
improved the model's performance. Our model, even without the use of the point
cloud encodings, outperforms numerical models by an order of magnitude
regarding the runtime, while reaching a success rate of up to 90% of collision
free solutions on the test set.

</details>


### [146] [Object-Reconstruction-Aware Whole-body Control of Mobile Manipulators](https://arxiv.org/abs/2509.04094)
*Fatih Dursun,Bruno Vilhena Adorno,Simon Watson,Wei Pan*

Main category: cs.RO

TL;DR: 提出一种计算高效的对象重建方法，通过焦点点策略显著减少规划时间，同时保持与采样方法相当的重建质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于采样的路径规划方法计算成本高，需要评估路径上的多个候选视图。

Method: 计算最信息丰富（未知）区域中的焦点点，并让机器人沿路径保持该点在相机视野中，无需额外路径规划器。

Result: 在114个不同大小和类别的对象上进行了全面模拟和真实世界实验，结果显示方法效率显著提升。

Conclusion: 提出的方法在对象覆盖率和熵方面与基线采样方法无显著差异，但在视图间平均时间上快约九倍。

Abstract: Object reconstruction and inspection tasks play a crucial role in various
robotics applications. Identifying paths that reveal the most unknown areas of
the object becomes paramount in this context, as it directly affects
efficiency, and this problem is known as the view path planning problem.
Current methods often use sampling-based path planning techniques, evaluating
potential views along the path to enhance reconstruction performance. However,
these methods are computationally expensive as they require evaluating several
candidate views on the path. To this end, we propose a computationally
efficient solution that relies on calculating a focus point in the most
informative (unknown) region and having the robot maintain this point in the
camera field of view along the path. We incorporated this strategy into the
whole-body control of a mobile manipulator employing a visibility constraint
without the need for an additional path planner. We conducted comprehensive and
realistic simulations using a large dataset of 114 diverse objects of varying
sizes from 57 categories to compare our method with a sampling-based planning
strategy using Bayesian data analysis. Furthermore, we performed real-world
experiments with an 8-DoF mobile manipulator to demonstrate the proposed
method's performance in practice. Our results suggest that there is no
significant difference in object coverage and entropy. In contrast, our method
is approximately nine times faster than the baseline sampling-based method in
terms of the average time the robot spends between views.

</details>


### [147] [Lightweight Kinematic and Static Modeling of Cable-Driven Continuum Robots via Actuation-Space Energy Formulation](https://arxiv.org/abs/2509.04119)
*Ke Wu,Yuhao Wang,Kevin Henry,Cesare Stefanini,Gang Zheng*

Main category: cs.RO

TL;DR: LASEM框架为电缆驱动连续体机器人提供了一种高效、轻量级的建模方法，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 连续体机器人的连续可变形形态给运动规划和控制带来了挑战，需要准确但轻量级的模型。

Method: 提出了轻量级驱动空间能量建模（LASEM）框架，通过哈密顿原理从几何非线性梁和杆理论推导出解析正向模型，避免了电缆-背板接触的显式建模。

Result: 数值模拟验证了LASEM的准确性，并开发了半解析迭代方案用于逆运动学。

Conclusion: LASEM框架为电缆驱动连续体机器人提供了一种轻量级、高效的建模方法，能够处理非均匀几何形状、任意电缆布线、分布式载荷和轴向可扩展性，同时保持计算效率，适用于实时应用。

Abstract: Continuum robots, inspired by octopus arms and elephant trunks, combine
dexterity with intrinsic compliance, making them well suited for unstructured
and confined environments. Yet their continuously deformable morphology poses
challenges for motion planning and control, calling for accurate but
lightweight models. We propose the Lightweight Actuation Space Energy Modeling
(LASEM) framework for cable driven continuum robots, which formulates actuation
potential energy directly in actuation space. LASEM yields an analytical
forward model derived from geometrically nonlinear beam and rod theories via
Hamilton's principle, while avoiding explicit modeling of cable backbone
contact. It accepts both force and displacement inputs, thereby unifying
kinematic and static formulations. Assuming the friction is neglected, the
framework generalizes to nonuniform geometries, arbitrary cable routings,
distributed loading and axial extensibility, while remaining computationally
efficient for real-time use. Numerical simulations validate its accuracy, and a
semi-analytical iterative scheme is developed for inverse kinematics. To
address discretization in practical robots, LASEM further reformulates the
functional minimization as a numerical optimization, which also naturally
incorporates cable potential energy without explicit contact modeling.

</details>


### [148] [OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection](https://arxiv.org/abs/2509.04324)
*Chen Hu,Shan Luo,Letizia Gionfrida*

Main category: cs.RO

TL;DR: OVGrasp是一个结合视觉、语言和语音的多模态抓取辅助框架，通过开放词汇机制和意图推断，在非结构化环境中实现高效抓取。


<details>
  <summary>Details</summary>
Motivation: 为运动障碍患者在非结构化环境中提供抓取辅助，应对物体类别和用户意图的多样性和不可预测性。

Method: OVGrasp采用分层控制框架，结合视觉-语言基础模型和开放词汇机制，实现零样本检测；通过多模态决策器融合空间和语言线索推断用户意图。

Result: 实验结果表明，OVGrasp在15种物体和三种抓取类型上的抓取能力得分（GAS）达87.00%，优于现有方法，且与自然手部运动的运动学对齐更佳。

Conclusion: OVGrasp框架通过整合RGB-D视觉、开放词汇提示和语音命令，在多模态交互中表现出色，显著提升了抓取辅助的通用性和准确性，优于现有基线方法。

Abstract: Grasping assistance is essential for restoring autonomy in individuals with
motor impairments, particularly in unstructured environments where object
categories and user intentions are diverse and unpredictable. We present
OVGrasp, a hierarchical control framework for soft exoskeleton-based grasp
assistance that integrates RGB-D vision, open-vocabulary prompts, and voice
commands to enable robust multimodal interaction. To enhance generalization in
open environments, OVGrasp incorporates a vision-language foundation model with
an open-vocabulary mechanism, allowing zero-shot detection of previously unseen
objects without retraining. A multimodal decision-maker further fuses spatial
and linguistic cues to infer user intent, such as grasp or release, in
multi-object scenarios. We deploy the complete framework on a custom
egocentric-view wearable exoskeleton and conduct systematic evaluations on 15
objects across three grasp types. Experimental results with ten participants
demonstrate that OVGrasp achieves a grasping ability score (GAS) of 87.00%,
outperforming state-of-the-art baselines and achieving improved kinematic
alignment with natural hand motion.

</details>


### [149] [DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation](https://arxiv.org/abs/2509.04441)
*Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal*

Main category: cs.RO

TL;DR: DEXOP是一种被动手部外骨骼，通过镜像人类手部姿势和提供力反馈，高效收集高质量机器人操作数据，显著提升机器人任务性能。


<details>
  <summary>Details</summary>
Motivation: 为了最大化人类操作数据的可转移性，并收集多样化的灵巧操作任务的丰富感官数据。

Method: DEXOP通过机械连接人类手指与机器人手指，提供直接接触反馈（通过本体感觉）并将人类手部姿势镜像到被动机器人手上，以最大化技能演示到机器人的转移。

Result: DEXOP在多种灵巧、接触丰富的任务中表现出色，能够大规模收集高质量演示数据。使用DEXOP数据学习到的策略在单位数据收集时间内显著提高了任务性能。

Conclusion: DEXOP作为一种被动手部外骨骼，通过最大化人类在自然环境中收集丰富感官数据的能力，显著提高了机器人任务性能，是推动机器人灵巧性的强大工具。

Abstract: We introduce perioperation, a paradigm for robotic data collection that
sensorizes and records human manipulation while maximizing the transferability
of the data to real robots. We implement this paradigm in DEXOP, a passive hand
exoskeleton designed to maximize human ability to collect rich sensory (vision
+ tactile) data for diverse dexterous manipulation tasks in natural
environments. DEXOP mechanically connects human fingers to robot fingers,
providing users with direct contact feedback (via proprioception) and mirrors
the human hand pose to the passive robot hand to maximize the transfer of
demonstrated skills to the robot. The force feedback and pose mirroring make
task demonstrations more natural for humans compared to teleoperation,
increasing both speed and accuracy. We evaluate DEXOP across a range of
dexterous, contact-rich tasks, demonstrating its ability to collect
high-quality demonstration data at scale. Policies learned with DEXOP data
significantly improve task performance per unit time of data collection
compared to teleoperation, making DEXOP a powerful tool for advancing robot
dexterity. Our project page is at https://dex-op.github.io.

</details>


### [150] [EMMA: Scaling Mobile Manipulation via Egocentric Human Data](https://arxiv.org/abs/2509.04443)
*Lawrence Y. Zhu,Pranav Kuppili,Ryan Punamiya,Patcharapong Aphiwetsa,Dhruv Patel,Simar Kareer,Sehoon Ha,Danfei Xu*

Main category: cs.RO

TL;DR: EMMA框架通过结合人类数据和静态机器人数据，绕过了昂贵的移动遥操作，实现了可扩展的移动操作策略学习，实验表现与遥操作基线相当甚至更优。


<details>
  <summary>Details</summary>
Motivation: 移动操作模仿学习的扩展性受限于昂贵的移动机器人遥操作。为了克服这一瓶颈，研究者提出了EMMA框架，旨在利用人类移动操作数据和静态机器人数据，实现无需遥操作的可扩展策略学习。

Method: EMMA框架通过端到端的方式，结合人类移动操作数据和静态机器人数据，训练移动操作策略。具体方法包括共同训练人类全身运动数据和静态机器人数据，以绕过移动遥操作的瓶颈。

Result: 在三个真实任务中，EMMA的表现与基于遥操作数据的基线（Mobile ALOHA）相当，甚至在某些任务中表现更优。EMMA展示了良好的泛化能力，能够适应新的空间配置和场景，并且随着人类数据量的增加，性能呈现正向提升。

Conclusion: EMMA框架通过结合人类全身运动数据和静态机器人数据，成功绕过了昂贵的移动机器人遥操作，实现了可扩展的移动操作策略学习。实验表明，EMMA在真实任务中表现与基于遥操作数据的基线（Mobile ALOHA）相当，甚至在某些任务中表现更优。此外，EMMA能够泛化到新的空间配置和场景，并且随着人类数据量的增加，性能呈现正向提升。

Abstract: Scaling mobile manipulation imitation learning is bottlenecked by expensive
mobile robot teleoperation. We present Egocentric Mobile MAnipulation (EMMA),
an end-to-end framework training mobile manipulation policies from human mobile
manipulation data with static robot data, sidestepping mobile teleoperation. To
accomplish this, we co-train human full-body motion data with static robot
data. In our experiments across three real-world tasks, EMMA demonstrates
comparable performance to baselines trained on teleoperated mobile robot data
(Mobile ALOHA), achieving higher or equivalent task performance in full task
success. We find that EMMA is able to generalize to new spatial configurations
and scenes, and we observe positive performance scaling as we increase the
hours of human data, opening new avenues for scalable robotic learning in
real-world environments. Details of this project can be found at
https://ego-moma.github.io/.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [151] [LuxDiT: Lighting Estimation with Video Diffusion Transformer](https://arxiv.org/abs/2509.03680)
*Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang*

Main category: cs.GR

TL;DR: LuxDiT 是一种基于视频扩散变换器的新方法，通过合成数据训练和低秩适应微调，显著提升了单图像或视频的光照估计效果。


<details>
  <summary>Details</summary>
Motivation: 现有学习基方法受限于真实高动态范围环境图的稀缺性和多样性不足问题，而 LuxDiT 旨在解决光照估计对间接视觉线索和全局上下文依赖的挑战。

Method: 该方法利用大型合成数据集训练模型，采用低秩适应微调策略，以提高输入与预测环境图之间的语义对齐。

Result: LuxDiT 在定量和定性评估中均优于现有最先进技术，能够生成具有真实角度高频细节的光照预测。

Conclusion: LuxDiT 提出了一种新颖的数据驱动方法，通过微调视频扩散变换器来生成基于视觉输入的高动态范围环境图，显著提升了光照预测的准确性和细节表现。

Abstract: Estimating scene lighting from a single image or video remains a longstanding
challenge in computer vision and graphics. Learning-based approaches are
constrained by the scarcity of ground-truth HDR environment maps, which are
expensive to capture and limited in diversity. While recent generative models
offer strong priors for image synthesis, lighting estimation remains difficult
due to its reliance on indirect visual cues, the need to infer global
(non-local) context, and the recovery of high-dynamic-range outputs. We propose
LuxDiT, a novel data-driven approach that fine-tunes a video diffusion
transformer to generate HDR environment maps conditioned on visual input.
Trained on a large synthetic dataset with diverse lighting conditions, our
model learns to infer illumination from indirect visual cues and generalizes
effectively to real-world scenes. To improve semantic alignment between the
input and the predicted environment map, we introduce a low-rank adaptation
finetuning strategy using a collected dataset of HDR panoramas. Our method
produces accurate lighting predictions with realistic angular high-frequency
details, outperforming existing state-of-the-art techniques in both
quantitative and qualitative evaluations.

</details>


### [152] [Memory Optimization for Convex Hull Support Point Queries](https://arxiv.org/abs/2509.03753)
*Michael Greer*

Main category: cs.GR

TL;DR: 优化凸包内存布局，显著提升支持点查询速度。


<details>
  <summary>Details</summary>
Motivation: 支持点查询是常见碰撞算法的基本组成部分，提高其计算速度对整体性能有重要影响。

Method: 评估了多种凸包内存布局的改进方法。

Result: 根据凸包顶点数量的不同，实现了显著的速度提升。

Conclusion: 通过优化凸包的内存布局，显著提高了支持点查询的计算速度。

Abstract: This paper evaluates several improvements to the memory layout of convex
hulls to improve computation times for support point queries. The support point
query is a fundamental part of common collision algorithms, and the work
presented achieves a significant speedup depending on the number of vertices of
the convex hull.

</details>


### [153] [ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction](https://arxiv.org/abs/2509.03775)
*Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar*

Main category: cs.GR

TL;DR: ContraGS是一种压缩3D高斯泼溅表示的方法，通过码本和贝叶斯推断减少内存消耗并加速训练/渲染，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅技术需要大量GPU内存来存储模型参数，导致训练和渲染效率低下。ContraGS旨在通过压缩表示减少内存需求，同时不降低模型质量。

Method: ContraGS利用码本紧凑存储高斯参数向量，并通过贝叶斯推断框架使用MCMC采样来解决学习不可微参数的问题。

Result: ContraGS平均减少了3.49倍的内存峰值，训练和渲染速度分别提高了1.36倍和1.88倍，同时保持了高质量。

Conclusion: ContraGS成功地在压缩的3D高斯泼溅表示上进行直接训练，显著减少了内存消耗并加速了训练和渲染过程，同时保持了接近最先进的质量。

Abstract: 3D Gaussian Splatting (3DGS) is a state-of-art technique to model real-world
scenes with high quality and real-time rendering. Typically, a higher quality
representation can be achieved by using a large number of 3D Gaussians.
However, using large 3D Gaussian counts significantly increases the GPU device
memory for storing model parameters. A large model thus requires powerful GPUs
with high memory capacities for training and has slower training/rendering
latencies due to the inefficiencies of memory access and data movement. In this
work, we introduce ContraGS, a method to enable training directly on compressed
3DGS representations without reducing the Gaussian Counts, and thus with a
little loss in model quality. ContraGS leverages codebooks to compactly store a
set of Gaussian parameter vectors throughout the training process, thereby
significantly reducing memory consumption. While codebooks have been
demonstrated to be highly effective at compressing fully trained 3DGS models,
directly training using codebook representations is an unsolved challenge.
ContraGS solves the problem of learning non-differentiable parameters in
codebook-compressed representations by posing parameter estimation as a
Bayesian inference problem. To this end, ContraGS provides a framework that
effectively uses MCMC sampling to sample over a posterior distribution of these
compressed representations. With ContraGS, we demonstrate that ContraGS
significantly reduces the peak memory during training (on average 3.49X) and
accelerated training and rendering (1.36X and 1.88X on average, respectively),
while retraining close to state-of-art quality.

</details>


### [154] [TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media](https://arxiv.org/abs/2509.04047)
*Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T. M. Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman*

Main category: cs.GR

TL;DR: 提出TensoIS框架，利用Fractal Perlin噪声建模异质散射参数，填补了分布模型空白，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多假设介质均匀或仅通过合成分析建模异质散射，缺乏明确描述真实世界异质散射参数的分布模型。

Method: 提出TensoIS框架，使用可学习的低秩张量分量表示散射体积，通过稀疏多视角图像观测估计Perlin分布的异质散射参数。

Result: 在HeteroSynth测试集、烟雾和云几何体及真实样本上验证了TensoIS的有效性。

Conclusion: 本研究通过提出TensoIS框架，利用Fractal Perlin噪声分布建模异质散射参数，填补了现有文献中缺乏明确分布模型的空白，并在合成数据集和真实样本上验证了其有效性。

Abstract: Estimating scattering parameters of heterogeneous media from images is a
severely under-constrained and challenging problem. Most of the existing
approaches model BSSRDF either through an analysis-by-synthesis approach,
approximating complex path integrals, or using differentiable volume rendering
techniques to account for heterogeneity. However, only a few studies have
applied learning-based methods to estimate subsurface scattering parameters,
but they assume homogeneous media. Interestingly, no specific distribution is
known to us that can explicitly model the heterogeneous scattering parameters
in the real world. Notably, procedural noise models such as Perlin and Fractal
Perlin noise have been effective in representing intricate heterogeneities of
natural, organic, and inorganic surfaces. Leveraging this, we first create
HeteroSynth, a synthetic dataset comprising photorealistic images of
heterogeneous media whose scattering parameters are modeled using Fractal
Perlin noise. Furthermore, we propose Tensorial Inverse Scattering (TensoIS), a
learning-based feed-forward framework to estimate these Perlin-distributed
heterogeneous scattering parameters from sparse multi-view image observations.
Instead of directly predicting the 3D scattering parameter volume, TensoIS uses
learnable low-rank tensor components to represent the scattering volume. We
evaluate TensoIS on unseen heterogeneous variations over shapes from the
HeteroSynth test set, smoke and cloud geometries obtained from open-source
realistic volumetric simulations, and some real-world samples to establish its
effectiveness for inverse scattering. Overall, this study is an attempt to
explore Perlin noise distribution, given the lack of any such well-defined
distribution in literature, to potentially model real-world heterogeneous
scattering in a feed-forward manner.

</details>


### [155] [SMooGPT: Stylized Motion Generation using Large Language Models](https://arxiv.org/abs/2509.04058)
*Lei Zhong,Yi Yang,Changjian Li*

Main category: cs.GR

TL;DR: SMooGPT利用LLMs在身体部位文本空间中实现风格化运动生成，解决了现有方法的局限性，具有更高的可解释性和控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格化运动生成中存在可解释性低、控制有限、对新风格泛化能力差以及仅能生成‘行走’运动的问题。

Method: 提出了一种基于推理-组合-生成的新方法，利用身体部位文本空间作为中间表示，并通过微调的LLM（SMooGPT）进行风格化运动生成。

Result: 实验和用户感知研究表明，SMooGPT在纯文本驱动的风格化运动生成中表现出色，具有更高的可解释性和控制能力。

Conclusion: SMooGPT通过利用LLMs的强大理解和推理能力，在身体部位文本空间中实现了高度可解释性和细粒度控制，有效解决了现有方法在风格泛化和运动多样性上的局限性。

Abstract: Stylized motion generation is actively studied in computer graphics,
especially benefiting from the rapid advances in diffusion models. The goal of
this task is to produce a novel motion respecting both the motion content and
the desired motion style, e.g., ``walking in a loop like a Monkey''. Existing
research attempts to address this problem via motion style transfer or
conditional motion generation. They typically embed the motion style into a
latent space and guide the motion implicitly in a latent space as well. Despite
the progress, their methods suffer from low interpretability and control,
limited generalization to new styles, and fail to produce motions other than
``walking'' due to the strong bias in the public stylization dataset. In this
paper, we propose to solve the stylized motion generation problem from a new
perspective of reasoning-composition-generation, based on our observations: i)
human motion can often be effectively described using natural language in a
body-part centric manner, ii) LLMs exhibit a strong ability to understand and
reason about human motion, and iii) human motion has an inherently
compositional nature, facilitating the new motion content or style generation
via effective recomposing. We thus propose utilizing body-part text space as an
intermediate representation, and present SMooGPT, a fine-tuned LLM, acting as a
reasoner, composer, and generator when generating the desired stylized motion.
Our method executes in the body-part text space with much higher
interpretability, enabling fine-grained motion control, effectively resolving
potential conflicts between motion content and style, and generalizes well to
new styles thanks to the open-vocabulary ability of LLMs. Comprehensive
experiments and evaluations, and a user perceptual study, demonstrate the
effectiveness of our approach, especially under the pure text-driven stylized
motion generation.

</details>


### [156] [Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion](https://arxiv.org/abs/2509.04145)
*Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard*

Main category: cs.GR

TL;DR: 结合个性化渲染和扩散模型，实现高真实感动态人体头像生成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在个性化渲染和生成模型之间各有局限，无法同时实现高真实感和跨身份泛化能力。

Method: 采用两阶段流程：首先优化一组个性化UNet网络，捕捉细节变形；其次训练超扩散模型生成网络权重，实现实时可控渲染。

Result: 在大规模跨身份多视角视频数据集上，该方法在真实感和动态变形方面优于现有技术。

Conclusion: 本文提出了一种结合个性化渲染和扩散生成模型的新方法，实现了高真实感和动态变形的人体头像生成。实验证明，该方法优于现有技术。

Abstract: Creating human avatars is a highly desirable yet challenging task. Recent
advancements in radiance field rendering have achieved unprecedented
photorealism and real-time performance for personalized dynamic human avatars.
However, these approaches are typically limited to person-specific rendering
models trained on multi-view video data for a single individual, limiting their
ability to generalize across different identities. On the other hand,
generative approaches leveraging prior knowledge from pre-trained 2D diffusion
models can produce cartoonish, static human avatars, which are animated through
simple skeleton-based articulation. Therefore, the avatars generated by these
methods suffer from lower rendering quality compared to person-specific
rendering methods and fail to capture pose-dependent deformations such as cloth
wrinkles. In this paper, we propose a novel approach that unites the strengths
of person-specific rendering and diffusion-based generative modeling to enable
dynamic human avatar generation with both high photorealism and realistic
pose-dependent deformations. Our method follows a two-stage pipeline: first, we
optimize a set of person-specific UNets, with each network representing a
dynamic human avatar that captures intricate pose-dependent deformations. In
the second stage, we train a hyper diffusion model over the optimized network
weights. During inference, our method generates network weights for real-time,
controllable rendering of dynamic human avatars. Using a large-scale,
cross-identity, multi-view video dataset, we demonstrate that our approach
outperforms state-of-the-art human avatar generation methods.

</details>


### [157] [Massively-Parallel Implementation of Inextensible Elastic Rods Using Inter-block GPU Synchronization](https://arxiv.org/abs/2509.04277)
*Przemyslaw Korzeniowski,Niels Hald,Fernando Bello*

Main category: cs.GR

TL;DR: 本文通过GPU并行化技术，显著提升了Cosserat杆模型的模拟速度，实现了高效实时仿真。


<details>
  <summary>Details</summary>
Motivation: 为了在物理基础的计算机模拟中高效处理弹性杆（如线、绳、手术器械等）的大规模形变，需要一种高性能的计算方法。

Method: 采用CUDA可扩展编程模型和块间同步技术，实现了每个内核启动执行多个物理时间步长，充分利用GPU的流式多处理器。

Result: 在单个内核启动执行10个时间步长时，原始可扩展CoRdE模型的速度提升了40倍；不可扩展CoRdE修改版的GPU实现平均速度提升了15.11倍；在心血管应用中模拟导管/导丝对时，性能提升了13.5倍，实现了高精度的实时仿真（0.5-1kHz）。

Conclusion: 本文提出了一种基于GPU的大规模并行实现方法，显著提高了Cosserat杆模型的模拟效率，实现了实时高精度仿真。

Abstract: An elastic rod is a long and thin body able to sustain large global
deformations, even if local strains are small. The Cosserat rod is a non-linear
elastic rod with an oriented centreline, which enables modelling of bending,
stretching and twisting deformations. It can be used for physically-based
computer simulation of threads, wires, ropes, as well as flexible surgical
instruments such as catheters, guidewires or sutures. We present a
massively-parallel implementation of the original CoRdE model as well as our
inextensible variation. By superseding the CUDA Scalable Programming Model and
using inter-block synchronization, we managed to simulate multiple physics
time-steps per single kernel launch utilizing all the GPU's streaming
multiprocessors. Under some constraints, this results in nearly constant
computation time, regardless of the number of Cosserat elements simulated. When
executing 10 time-steps per single kernel launch, our implementation of the
original, extensible CoRdE was x40.0 faster. In a number of tests, the GPU
implementation of our inextensible CoRdE modification achieved an average
speed-up of x15.11 over the corresponding CPU version. Simulating a
catheter/guidewire pair (2x512 Cosserat elements) in a cardiovascular
application resulted in a 13.5 fold performance boost, enabling for accurate
real-time simulation at haptic interactive rates (0.5-1kHz).

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [158] [Entanglement Purification With Finite Latency Classical Communication in Quantum Networks](https://arxiv.org/abs/2509.03667)
*Vivek Vasan,Alexander Nico-Katz,Boulat A. Bash,Daniel C. Kilper,Marco Ruffini*

Main category: cs.NI

TL;DR: 分析了在非即时经典协调下纠缠纯化协议（BBPSSW、DEJMPS）的可行性，确定了成功与失败的区域，并提供了部署纯化所需的资源估计。


<details>
  <summary>Details</summary>
Motivation: 量子网络中高保真纠缠对的分布面临环境退相干在存储期间的挑战，而纠缠纯化协议在非即时经典协调下的实际可行性需要分析。

Method: 采用微观Lindblad方法处理量子动力学，并结合当前大都市IP网络的延迟统计数据和量子内存测试平台的参数。

Result: 确定了纠缠纯化协议成功与失败的区域，并计算了完成多轮纯化协议所需的纠缠对总数以及超过应用特定阈值的纯化保真度的稳态吞吐量。

Conclusion: 研究确定了在当前和未来网络中部署纠缠纯化协议所需的延迟预算、内存质量目标和资源开销估计。

Abstract: Quantum networks rely on high fidelity entangled pairs distributed to nodes,
but maintaining their fidelity is challenged by environmental decoherence
during storage. Entanglement purification is used to restore fidelity, but the
idle periods imposed by the associated classical communication delays
counteract this goal by exposing the states to further decoherence. In this
work, we analyze the practical viability of entanglement purification protocols
(BBPSSW, DEJMPS), under non-instantaneous classical coordination over Internet
protocol (IP) communications networks. We present a comprehensive performance
evaluation of these protocols in various network conditions for a range of
quantum memory technologies. We employ a microscopic Lindblad treatment of the
underlying quantum dynamics, and use current-generation metropolitan IP network
latency statistics and parameters drawn from quantum memory testbeds. In doing
so we identify the regions in which entanglement purification succeeds and
fails, delineated by break-even iso-fidelity contours in the phase space. We
then determine the total number of entangled pairs required to complete a
multi-round purification protocol, and the steady-state throughput of entangled
pairs with purified fidelities that exceed application-specific thresholds.
This provides latency budgets, memory quality targets, and resource-overhead
estimates for deploying purification on current and near-future networks.

</details>


### [159] [Drift Plus Optimistic Penalty -- A Learning Framework for Stochastic Network Optimization](https://arxiv.org/abs/2509.03762)
*Sathwik Chadaga,Eytan Modiano*

Main category: cs.NI

TL;DR: 论文提出了一种结合Lyapunov和多臂老虎机的网络控制策略，在未知传输成本下实现次线性遗憾，并通过仿真验证。


<details>
  <summary>Details</summary>
Motivation: 在传输成本未知的排队网络中，网络控制器需要在保证稳定性的同时最小化总预期成本，现有老虎机解决方案无法直接应用。

Method: 采用Lyapunov漂移加惩罚优化和多臂老虎机技术，设计了一种网络控制策略，以解决路由和调度问题中的探索-利用权衡。

Result: 提出的策略实现了$O(\sqrt{T}\log T)$的次线性遗憾，仿真验证了其有效性。

Conclusion: 论文提出了一种结合Lyapunov漂移加惩罚优化和多臂老虎机技术的网络控制策略，能够在保证网络稳定性的同时实现次线性遗憾。通过仿真验证了该策略的有效性。

Abstract: We consider the problem of joint routing and scheduling in queueing networks,
where the edge transmission costs are unknown. At each time-slot, the network
controller receives noisy observations of transmission costs only for those
edges it selects for transmission. The network controller's objective is to
make routing and scheduling decisions so that the total expected cost is
minimized. This problem exhibits an exploration-exploitation trade-off,
however, previous bandit-style solutions cannot be directly applied to this
problem due to the queueing dynamics. In order to ensure network stability, the
network controller needs to optimize throughput and cost simultaneously. We
show that the best achievable cost is lower bounded by the solution to a static
optimization problem, and develop a network control policy using techniques
from Lyapunov drift-plus-penalty optimization and multi-arm bandits. We show
that the policy achieves a sub-linear regret of order $O(\sqrt{T}\log T)$, as
compared to the best policy that has complete knowledge of arrivals and costs.
Finally, we evaluate the proposed policy using simulations and show that its
regret is indeed sub-linear.

</details>


### [160] [A Versatile and Programmable UAV Platform for Radio Access Network and End-to-End Cellular Measurements](https://arxiv.org/abs/2509.03818)
*Sherwan Jalal Abdullah,Sravan Reddy Chintareddy,Victor S. Frost,Shawn Keshmiri,Morteza Hashemi*

Main category: cs.NI

TL;DR: 无人机平台用于测量偏远地区移动网络性能，发现高海拔信号强但干扰大，信号强度不等于覆盖一致性。


<details>
  <summary>Details</summary>
Motivation: 解决传统覆盖测试方法在偏远地区因人口密度低和地形复杂而效率低下的问题。

Method: 开发了一个基于无人机的测量平台，集成机载计算单元和商用蜂窝调制解调器，通过地理空间映射和统计技术分析数据。

Result: 实验显示信号功率随高度增加而改善，但干扰增加导致信号质量下降；系统在大多数测试区域保持了可接受的信号质量和吞吐性能。

Conclusion: 该平台通过无人机操作成功收集并分析了移动网络性能指标，揭示了信号功率与高度、干扰之间的关系，并指出强信号并不总是意味着一致的覆盖范围。

Abstract: In this work, we develop a measurement platform to capture mobile network
performance metrics including coverage and quality of service in regions where
conventional coverage testing approaches are frequently time-intensive,
labor-demanding, and occasionally hazardous. Traditionally, crowd-sourcing
methods are used to collect cellular network performance metrics. However,
these approaches are inadequate in rural areas due to low-density population,
and difficult terrain. The platform described here is a UAV-based and is
designed to investigate the mobile network performance through aerial
operations and gather Radio Access Network (RAN) signal alongside end-to-end
network performance metrics. Our platform gathers metrics through the
integration of an onboard computation unit and commercial off-the-shelf
cellular modem. The gathered data are subsequently analyzed and displayed using
geospatial mapping utilities and statistical techniques to deliver key
observations on cellular network performance. Experimental results showed that
the received signal power improves at higher altitudes due to enhanced
line-of-sight (LoS) conditions as expected. However, the signal quality
degrades as a result of increased interference from neighboring cells. The
analysis reveals that for most of the geographic area covered in the initial
experiments the system maintained acceptable signal quality, with adequate
throughput performance for both uplink and downlink communications, while
maintaining satisfactory round-trip time characteristics. Notably, the
experiment showed that a strong radio signal metric for a given cell does not
necessarily translate to consistent spatial coverage across the tested region.

</details>


### [161] [Indoor Positioning with Wi-Fi Location: A Survey of IEEE 802.11mc/az/bk Fine Timing Measurement Research](https://arxiv.org/abs/2509.03901)
*Katarzyna Kosek-Szott,Szymon Szott,Wojciech Ciezobka,Maksymilian Wojnar,Krzysztof Rusek,Jonathan Segev*

Main category: cs.NI

TL;DR: 本文填补了FTM室内定位综述的空白，分析了180多篇论文，总结了其高精度潜力、改进方法、应用及安全挑战，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 室内定位是家庭、办公室和工业网络用户的关键技术，但缺乏专门针对FTM及其最新增强的综述，本文填补了这一空白。

Method: 通过对180多篇研究论文的分类和综述，分析了FTM的实际精度、提高精度的方法（包括机器学习）、与其他室内定位系统的结合、基于FTM的应用以及安全问题。

Result: 综述了FTM在室内定位中的高精度潜力、方法改进、应用场景及安全挑战，总结了重要研究成果。

Conclusion: 本文总结了IEEE 802.11mc FTM协议在室内定位领域的重要研究成果，并提出了未来研究的开放方向。

Abstract: Indoor positioning is an enabling technology for home, office, and industrial
network users because it provides numerous information and communication
technology (ICT) and Internet of things (IoT) functionalities such as indoor
navigation, smart meter localization, asset tracking, support for emergency
services, and detection of hazardous situations. The IEEE 802.11mc fine timing
measurement (FTM) protocol (commercially known as Wi-Fi Location) has great
potential to enable indoor positioning in future generation devices, primarily
because of the high availability of Wi-Fi networks, FTM's high accuracy and
device support. Furthermore, new FTM enhancements are available in the released
(802.11az) and recently completed (802.11bk) amendments. Despite the multitude
of literature reviews on indoor positioning, a survey dedicated to FTM and its
recent enhancements has so far been lacking. We fill this gap by classifying
and reviewing over 180 research papers related to the practical accuracy
achieved with FTM, methods for improving its accuracy (also with machine
learning), combining FTM with other indoor positioning systems, FTM-based
applications, and security issues. Based on the conducted survey, we summarize
the most important research achievements and formulate open areas for further
research.

</details>


### [162] [Autonomous Task Offloading of Vehicular Edge Computing with Parallel Computation Queues](https://arxiv.org/abs/2509.03935)
*Sungho Cho,Sung Il Choi,Seung Hyun Oh,Ian P. Roberts,Sang Hyun Lee*

Main category: cs.NI

TL;DR: 该论文提出了一种车载边缘计算网络中的并行任务卸载策略，通过优化资源分配和负载预测，显著降低了用户等待延迟。


<details>
  <summary>Details</summary>
Motivation: 为了最小化车载用户的整体等待延迟，并解决资源利用不足和负载拥塞的问题。

Method: 提出了一种基于网络合作的新型任务卸载解决方案，通过理论分析和数值模拟双重评估，并在真实地图虚拟环境中进行了可行性测试。

Result: 所提出的解决方案在延迟减少性能上优于现有方法，并通过精确的队列离散变量估计有效解决了组合挑战。

Conclusion: 该研究通过并行任务执行策略和网络合作平衡，显著减少了车载边缘计算网络中的等待延迟，实现了全局最优的延迟降低性能。

Abstract: This work considers a parallel task execution strategy in vehicular edge
computing (VEC) networks, where edge servers are deployed along the roadside to
process offloaded computational tasks of vehicular users. To minimize the
overall waiting delay among vehicular users, a novel task offloading solution
is implemented based on the network cooperation balancing resource
under-utilization and load congestion. Dual evaluation through theoretical and
numerical ways shows that the developed solution achieves a globally optimal
delay reduction performance compared to existing methods, which is also
approved by the feasibility test over a real-map virtual environment. The
in-depth analysis reveals that predicting the instantaneous processing power of
edge servers facilitates the identification of overloaded servers, which is
critical for determining network delay. By considering discrete variables of
the queue, the proposed technique's precise estimation can effectively address
these combinatorial challenges to achieve optimal performance.

</details>


### [163] [Analyzing the Effect of an Extreme Weather Event on Telecommunications and Information Technology: Insights from 30 Days of Flooding](https://arxiv.org/abs/2509.04219)
*Leandro Márcio Bertholdo,Renan Barreto Paredes,Gabriela de Lima Marin,Cesar A. H. Loureiro,Milton Kaoru Kashiwakura Pedro de Botelho Marcos*

Main category: cs.NI

TL;DR: 该研究分析了2024年巴西里奥格兰德州严重降雨对电信基础设施的影响，构建了相关数据集，揭示了网络韧性和恢复趋势，为未来灾难恢复研究提供支持。


<details>
  <summary>Details</summary>
Motivation: 研究旨在了解极端气候事件对信息与通信技术基础设施的影响，以及其韧性在关键时刻面临的挑战。

Method: 通过整合互联网测量、光纤切断报告和互联网交换路由数据，并关联网络中断与水文及操作因素，构建了综合电信数据集。

Result: 初步发现揭示了连接恢复的趋势、基础设施的脆弱性以及用户行为的变化。

Conclusion: 该研究通过构建全面的电信数据集，揭示了在极端气候事件中光纤网络、数据中心和互联网流量的韧性，为未来的灾难恢复策略和稳健电信系统的开发提供了支持。

Abstract: In May 2024, weeks of severe rainfall in Rio Grande do Sul, Brazil caused
widespread damage to infrastructure, impacting over 400 cities and 2.3 million
people. This study presents the construction of comprehensive
telecommunications datasets during this climatic event, encompassing Internet
measurements, fiber cut reports, and Internet Exchange routing data. By
correlating network disruptions with hydrological and operational factors, the
dataset offers insights into the resilience of fiber networks, data centers,
and Internet traffic during critical events. For each scenario, we investigate
failures related to the Information and Communication Technology infrastructure
and highlight the challenges faced when its resilience is critically tested.
Preliminary findings reveal trends in connectivity restoration, infrastructure
vulnerabilities, and user behavior changes. These datasets and pre-analysis aim
to support future research on disaster recovery strategies and the development
of robust telecommunications systems.

</details>
