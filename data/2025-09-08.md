<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 53]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.AI](#cs.AI) [Total: 18]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 5]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Facial Emotion Recognition does not detect feeling unsafe in automated driving](https://arxiv.org/abs/2509.04490)
*Abel van Elburg,Konstantinos Gkentsidis,Mathieu Sarrazin,Sarah Barendswaard,Varun Kotian,Riender Happee*

Main category: cs.CV

TL;DR: 研究显示动态驾驶风格和行人横穿增加不适感，面部表情识别不可靠，但神经网络模型能有效预测自动驾驶中的感知风险。


<details>
  <summary>Details</summary>
Motivation: 探讨公众对自动驾驶车辆的信任和感知安全，以理解感知风险的影响因素。

Method: 通过驾驶模拟器实验，收集32名参与者的主观舒适度评分、运动数据、面部表情、皮肤电导、心率和眼动数据，并分析动态与平静驾驶风格及行人横穿的影响。

Result: 动态驾驶风格和行人横穿显著增加不适感，面部表情识别不可靠，而神经网络模型能有效预测感知风险。

Conclusion: 面部表情识别在评估自动驾驶车辆中的感知风险方面不可靠，而结合车辆运动和皮肤电导的神经网络模型能有效预测感知风险，减少主观偏差。

Abstract: Trust and perceived safety play a crucial role in the public acceptance of
automated vehicles. To understand perceived risk, an experiment was conducted
using a driving simulator under two automated driving styles and optionally
introducing a crossing pedestrian. Data was collected from 32 participants,
consisting of continuous subjective comfort ratings, motion, webcam footage for
facial expression, skin conductance, heart rate, and eye tracking. The
continuous subjective perceived risk ratings showed significant discomfort
associated with perceived risk during cornering and braking followed by relief
or even positive comfort on continuing the ride. The dynamic driving style
induced a stronger discomfort as compared to the calm driving style. The
crossing pedestrian did not affect discomfort with the calm driving style but
doubled the comfort decrement with the dynamic driving style. This illustrates
the importance of consequences of critical interactions in risk perception.
Facial expression was successfully analyzed for 24 participants but most
(15/24) did not show any detectable facial reaction to the critical event.
Among the 9 participants who did, 8 showed a Happy expression, and only 4
showed a Surprise expression. Fear was never dominant. This indicates that
facial expression recognition is not a reliable method for assessing perceived
risk in automated vehicles. To predict perceived risk a neural network model
was implemented using vehicle motion and skin conductance. The model correlated
well with reported perceived risk, demonstrating its potential for objective
perceived risk assessment in automated vehicles, reducing subjective bias and
highlighting areas for future research.

</details>


### [2] [PromptEnhancer: A Simple Approach to Enhance Text-to-Image Models via Chain-of-Thought Prompt Rewriting](https://arxiv.org/abs/2509.04545)
*Linqing Wang,Ximing Xing,Yiji Cheng,Zhiyuan Zhao,Jiale Tao,Qixun Wang,Ruihuang Li,Xin Li,Mingrui Wu,Xinchi Deng,Chunyu Wang,Qinglin Lu*

Main category: cs.CV

TL;DR: PromptEnhancer通过强化学习训练的CoT重写器和AlignEvaluator反馈，显著提升了文本到图像模型对复杂提示的渲染能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到图像扩散模型在属性绑定、否定和组合关系等复杂提示下的渲染不足问题。

Method: 通过强化学习训练Chain-of-Thought (CoT)重写器，并利用AlignEvaluator提供细粒度反馈，优化提示生成。

Result: 在HunyuanImage 2.1模型上的广泛实验表明，PromptEnhancer在广泛的语义和组合挑战中显著提升了图像-文本对齐。

Conclusion: PromptEnhancer显著提升了文本到图像模型的图像-文本对齐能力，为解决复杂用户提示的渲染问题提供了一种新颖且通用的解决方案。

Abstract: Recent advancements in text-to-image (T2I) diffusion models have demonstrated
remarkable capabilities in generating high-fidelity images. However, these
models often struggle to faithfully render complex user prompts, particularly
in aspects like attribute binding, negation, and compositional relationships.
This leads to a significant mismatch between user intent and the generated
output. To address this challenge, we introduce PromptEnhancer, a novel and
universal prompt rewriting framework that enhances any pretrained T2I model
without requiring modifications to its weights. Unlike prior methods that rely
on model-specific fine-tuning or implicit reward signals like image-reward
scores, our framework decouples the rewriter from the generator. We achieve
this by training a Chain-of-Thought (CoT) rewriter through reinforcement
learning, guided by a dedicated reward model we term the AlignEvaluator. The
AlignEvaluator is trained to provide explicit and fine-grained feedback based
on a systematic taxonomy of 24 key points, which are derived from a
comprehensive analysis of common T2I failure modes. By optimizing the CoT
rewriter to maximize the reward from our AlignEvaluator, our framework learns
to generate prompts that are more precisely interpreted by T2I models.
Extensive experiments on the HunyuanImage 2.1 model demonstrate that
PromptEnhancer significantly improves image-text alignment across a wide range
of semantic and compositional challenges. Furthermore, we introduce a new,
high-quality human preference benchmark to facilitate future research in this
direction.

</details>


### [3] [Skywork UniPic 2.0: Building Kontext Model with Online RL for Unified Multimodal Model](https://arxiv.org/abs/2509.04548)
*Hongyang Wei,Baixin Xu,Hongbo Liu,Cyrus Wu,Jie Liu,Yi Peng,Peiyu Wang,Zexiang Liu,Jingwen He,Yidan Xietian,Chuanxin Tang,Zidong Wang,Yichen Wei,Liang Hu,Boyi Jiang,William Li,Ying He,Yang Liu,Xuchen Song,Eric Li,Yahui Zhou*

Main category: cs.CV

TL;DR: 提出了UniPic2-SD3.5M-Kontext模型，通过PDTR策略优化训练，在多模态任务中表现优异，并扩展为统一多模态模型UniPic2-Metaquery。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型过于注重参数规模而忽视训练策略优化，导致效率和性能受限。

Method: 提出了Progressive Dual-Task Reinforcement策略（PDTR），通过分阶段强化文本到图像生成和编辑任务，避免了任务间的负面干扰。

Result: UniPic2-SD3.5M-Kontext在图像生成和编辑任务上超越了参数更大的模型（如BAGEL和Flux-Kontext），UniPic2-Metaquery在统一多模态任务中表现优异。

Conclusion: UniPic2-SD3.5M-Kontext和UniPic2-Metaquery通过优化的训练策略和架构改进，在多模态任务中实现了顶尖性能，验证了Skywork UniPic 2.0训练范式的有效性和通用性。

Abstract: Recent advances in multimodal models have demonstrated impressive
capabilities in unified image generation and editing. However, many prominent
open-source models prioritize scaling model parameters over optimizing training
strategies, limiting their efficiency and performance. In this work, we present
UniPic2-SD3.5M-Kontext, a 2B-parameter DiT model based on SD3.5-Medium, which
achieves state-of-the-art image generation and editing while extending
seamlessly into a unified multimodal framework. Our approach begins with
architectural modifications to SD3.5-Medium and large-scale pre-training on
high-quality data, enabling joint text-to-image generation and editing
capabilities. To enhance instruction following and editing consistency, we
propose a novel Progressive Dual-Task Reinforcement strategy (PDTR), which
effectively strengthens both tasks in a staged manner. We empirically validate
that the reinforcement phases for different tasks are mutually beneficial and
do not induce negative interference. After pre-training and reinforcement
strategies, UniPic2-SD3.5M-Kontext demonstrates stronger image generation and
editing capabilities than models with significantly larger generation
parameters-including BAGEL (7B) and Flux-Kontext (12B). Furthermore, following
the MetaQuery, we connect the UniPic2-SD3.5M-Kontext and Qwen2.5-VL-7B via a
connector and perform joint training to launch a unified multimodal model
UniPic2-Metaquery. UniPic2-Metaquery integrates understanding, generation, and
editing, achieving top-tier performance across diverse tasks with a simple and
scalable training paradigm. This consistently validates the effectiveness and
generalizability of our proposed training paradigm, which we formalize as
Skywork UniPic 2.0.

</details>


### [4] [Inpaint4Drag: Repurposing Inpainting Models for Drag-Based Image Editing via Bidirectional Warping](https://arxiv.org/abs/2509.04582)
*Jingyi Lu,Kai Han*

Main category: cs.CV

TL;DR: Inpaint4Drag通过像素空间变形和修复实现实时拖拽编辑，提升交互体验并兼容任何修复模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖生成模型的潜在空间操作，导致精度有限、反馈延迟和模型特定约束，因此需要一种更高效、通用的解决方案。

Method: 该方法将拖拽编辑分解为像素空间的双向变形和图像修复，模拟物理世界中的弹性物体变形，保持图像区域的自然形状。

Result: 实验表明，该方法在512x512分辨率下实现了实时变形预览（0.01秒）和高效修复（0.3秒），视觉质量和精确控制均优于现有方法。

Conclusion: Inpaint4Drag通过将拖拽编辑分解为像素空间的双向变形和图像修复，实现了实时预览和高效编辑，显著提升了交互体验，同时作为一个通用适配器兼容任何修复模型。

Abstract: Drag-based image editing has emerged as a powerful paradigm for intuitive
image manipulation. However, existing approaches predominantly rely on
manipulating the latent space of generative models, leading to limited
precision, delayed feedback, and model-specific constraints. Accordingly, we
present Inpaint4Drag, a novel framework that decomposes drag-based editing into
pixel-space bidirectional warping and image inpainting. Inspired by elastic
object deformation in the physical world, we treat image regions as deformable
materials that maintain natural shape under user manipulation. Our method
achieves real-time warping previews (0.01s) and efficient inpainting (0.3s) at
512x512 resolution, significantly improving the interaction experience compared
to existing methods that require minutes per edit. By transforming drag inputs
directly into standard inpainting formats, our approach serves as a universal
adapter for any inpainting model without architecture modification,
automatically inheriting all future improvements in inpainting technology.
Extensive experiments demonstrate that our method achieves superior visual
quality and precise control while maintaining real-time performance. Project
page: https://visual-ai.github.io/inpaint4drag/

</details>


### [5] [DisPatch: Disarming Adversarial Patches in Object Detection with Diffusion Models](https://arxiv.org/abs/2509.04597)
*Jin Ma,Mohammed Aldeen,Christopher Salas,Feng Luo,Mashrur Chowdhury,Mert Pesé,Long Cheng*

Main category: cs.CV

TL;DR: DISPATCH 是首个基于扩散模型的目标检测防御框架，通过‘再生与修正’策略有效应对对抗性补丁攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的目标检测器易受对抗性补丁攻击影响，亟需一种无需先验知识且能应对多种攻击的防御方法。

Method: DISPATCH 采用基于扩散模型的‘再生与修正’策略，利用生成模型消除攻击效果，同时保持输入图像的完整性。

Result: DISPATCH 在多种检测器和攻击中表现优异，隐藏攻击的 mAP.5 得分达 89.3%，非目标创建攻击的成功率降至 24.8%。

Conclusion: DISPATCH 是一种有效的、可推广且对自适应攻击具有鲁棒性的防御框架，适用于目标检测系统。

Abstract: Object detection is fundamental to various real-world applications, such as
security monitoring and surveillance video analysis. Despite their
advancements, state-of-theart object detectors are still vulnerable to
adversarial patch attacks, which can be easily applied to real-world objects to
either conceal actual items or create non-existent ones, leading to severe
consequences. Given the current diversity of adversarial patch attacks and
potential unknown threats, an ideal defense method should be effective,
generalizable, and robust against adaptive attacks. In this work, we introduce
DISPATCH, the first diffusion-based defense framework for object detection.
Unlike previous works that aim to "detect and remove" adversarial patches,
DISPATCH adopts a "regenerate and rectify" strategy, leveraging generative
models to disarm attack effects while preserving the integrity of the input
image. Specifically, we utilize the in-distribution generative power of
diffusion models to regenerate the entire image, aligning it with benign data.
A rectification process is then employed to identify and replace adversarial
regions with their regenerated benign counterparts. DISPATCH is attack-agnostic
and requires no prior knowledge of the existing patches. Extensive experiments
across multiple detectors and attacks demonstrate that DISPATCH consistently
outperforms state-of-the-art defenses on both hiding attacks and creating
attacks, achieving the best overall mAP.5 score of 89.3% on hiding attacks, and
lowering the attack success rate to 24.8% on untargeted creating attacks.
Moreover, it maintains strong robustness against adaptive attacks, making it a
practical and reliable defense for object detection systems.

</details>


### [6] [WATCH: World-aware Allied Trajectory and pose reconstruction for Camera and Human](https://arxiv.org/abs/2509.04600)
*Qijun Ying,Zhongyuan Hu,Rui Zhang,Ronghui Li,Yu Lu,Zijiao Zeng*

Main category: cs.CV

TL;DR: WATCH是一个联合建模相机与人体运动的框架，通过创新的航向角分解和相机轨迹集成技术，有效解决了全球人体运动重建中的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决从单目视频中重建全球人体运动时面临的深度模糊性、运动模糊性以及相机与人体运动纠缠的问题。

Method: 引入了一种解析性的航向角分解技术和基于世界模型的相机轨迹集成机制。

Result: 在野外基准测试中，WATCH在端到端轨迹重建中实现了最先进的性能。

Conclusion: WATCH框架通过联合建模相机与人体运动关系，有效解决了全球人体运动重建中的相机平移集成挑战，并在端到端轨迹重建中达到了最先进的性能。

Abstract: Global human motion reconstruction from in-the-wild monocular videos is
increasingly demanded across VR, graphics, and robotics applications, yet
requires accurate mapping of human poses from camera to world coordinates-a
task challenged by depth ambiguity, motion ambiguity, and the entanglement
between camera and human movements. While human-motion-centric approaches excel
in preserving motion details and physical plausibility, they suffer from two
critical limitations: insufficient exploitation of camera orientation
information and ineffective integration of camera translation cues. We present
WATCH (World-aware Allied Trajectory and pose reconstruction for Camera and
Human), a unified framework addressing both challenges. Our approach introduces
an analytical heading angle decomposition technique that offers superior
efficiency and extensibility compared to existing geometric methods.
Additionally, we design a camera trajectory integration mechanism inspired by
world models, providing an effective pathway for leveraging camera translation
information beyond naive hard-decoding approaches. Through experiments on
in-the-wild benchmarks, WATCH achieves state-of-the-art performance in
end-to-end trajectory reconstruction. Our work demonstrates the effectiveness
of jointly modeling camera-human motion relationships and offers new insights
for addressing the long-standing challenge of camera translation integration in
global human motion reconstruction. The code will be available publicly.

</details>


### [7] [Sali4Vid: Saliency-Aware Video Reweighting and Adaptive Caption Retrieval for Dense Video Captioning](https://arxiv.org/abs/2509.04602)
*MinJu Jeon,Si-Woo Kim,Ye-Chan Kim,HyunGee Kim,Dong-Jin Kim*

Main category: cs.CV

TL;DR: Sali4Vid通过帧重要性权重和自适应字幕检索改进密集视频字幕，性能领先。


<details>
  <summary>Details</summary>
Motivation: 解决现有端到端模型的两个局限性：（1）仅对文本应用时间戳监督，而平等对待所有视频帧；（2）从固定大小的视频块中检索字幕，忽略了场景转换。

Method: 提出了Saliency-aware Video Reweighting（将时间戳注释转换为基于sigmoid的帧重要性权重）和Semantic-based Adaptive Caption Retrieval（通过帧相似性分割视频以捕捉场景转换并改进字幕检索）。

Result: 在YouCook2和ViTT数据集上取得了最先进的结果。

Conclusion: Sali4Vid框架通过联合改进视频权重和检索，在密集视频字幕任务中实现了最先进的性能，证明了其有效性。

Abstract: Dense video captioning aims to temporally localize events in video and
generate captions for each event. While recent works propose end-to-end models,
they suffer from two limitations: (1) applying timestamp supervision only to
text while treating all video frames equally, and (2) retrieving captions from
fixed-size video chunks, overlooking scene transitions. To address these, we
propose Sali4Vid, a simple yet effective saliency-aware framework. We introduce
Saliency-aware Video Reweighting, which converts timestamp annotations into
sigmoid-based frame importance weights, and Semantic-based Adaptive Caption
Retrieval, which segments videos by frame similarity to capture scene
transitions and improve caption retrieval. Sali4Vid achieves state-of-the-art
results on YouCook2 and ViTT, demonstrating the benefit of jointly improving
video weighting and retrieval for dense video captioning

</details>


### [8] [UAV-Based Intelligent Traffic Surveillance System: Real-Time Vehicle Detection, Classification, Tracking, and Behavioral Analysis](https://arxiv.org/abs/2509.04624)
*Ali Khanpour,Tianyi Wang,Afra Vahidi-Shams,Wim Ectors,Farzam Nakhaie,Amirhossein Taheri,Christian Claudel*

Main category: cs.CV

TL;DR: 论文提出一种基于无人机的交通监控系统，通过先进算法实现高精度车辆检测与违规分析，为智慧城市提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统交通监控系统覆盖有限、适应性低且扩展性差，无法满足现代城市交通需求。

Method: 系统利用多尺度多角度模板匹配、卡尔曼滤波和基于单应性的校准技术处理高空视频数据，结合地理围栏、运动过滤和轨迹偏差分析检测交通违规行为。

Result: 在真实城市环境中，系统实现了91.8%的检测精度、90.5%的F1分数，跟踪指标（MOTA/MOTP）分别为92.1%和93.7%，并能分类五种车辆类型及检测多种交通违规行为。

Conclusion: 该论文提出的基于无人机的交通监控系统在准确性、可扩展性和实用性方面表现出色，为下一代智慧城市提供了一种独立于基础设施的交通监控解决方案。

Abstract: Traffic congestion and violations pose significant challenges for urban
mobility and road safety. Traditional traffic monitoring systems, such as fixed
cameras and sensor-based methods, are often constrained by limited coverage,
low adaptability, and poor scalability. To address these challenges, this paper
introduces an advanced unmanned aerial vehicle (UAV)-based traffic surveillance
system capable of accurate vehicle detection, classification, tracking, and
behavioral analysis in real-world, unconstrained urban environments. The system
leverages multi-scale and multi-angle template matching, Kalman filtering, and
homography-based calibration to process aerial video data collected from
altitudes of approximately 200 meters. A case study in urban area demonstrates
robust performance, achieving a detection precision of 91.8%, an F1-score of
90.5%, and tracking metrics (MOTA/MOTP) of 92.1% and 93.7%, respectively.
Beyond precise detection, the system classifies five vehicle types and
automatically detects critical traffic violations, including unsafe lane
changes, illegal double parking, and crosswalk obstructions, through the fusion
of geofencing, motion filtering, and trajectory deviation analysis. The
integrated analytics module supports origin-destination tracking, vehicle count
visualization, inter-class correlation analysis, and heatmap-based congestion
modeling. Additionally, the system enables entry-exit trajectory profiling,
vehicle density estimation across road segments, and movement direction
logging, supporting comprehensive multi-scale urban mobility analytics.
Experimental results confirms the system's scalability, accuracy, and practical
relevance, highlighting its potential as an enforcement-aware,
infrastructure-independent traffic monitoring solution for next-generation
smart cities.

</details>


### [9] [VCMamba: Bridging Convolutions with Multi-Directional Mamba for Efficient Visual Representation](https://arxiv.org/abs/2509.04669)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: VCMamba结合CNN和Mamba SSM的优势，在图像分类和语义分割任务中表现优异且参数更少。


<details>
  <summary>Details</summary>
Motivation: ViTs和SSMs在全局上下文建模方面表现优异，但缺乏对局部特征的捕捉能力；而CNNs擅长局部特征但缺乏全局推理能力。VCMamba旨在结合两者的优势。

Method: 采用卷积主干和分层结构，早期阶段使用卷积块提取局部特征，后期阶段结合多方向Mamba块建模长距离依赖和全局上下文。

Result: VCMamba-B在ImageNet-1K分类任务上达到82.6%的top-1准确率，参数更少；在ADE20K语义分割任务上达到47.1 mIoU，同样参数更少。

Conclusion: VCMamba通过结合CNN和多方向Mamba SSM的优势，提出了一种新型视觉骨干网络，在保持线性复杂度的同时，实现了卓越的特征表示能力。

Abstract: Recent advances in Vision Transformers (ViTs) and State Space Models (SSMs)
have challenged the dominance of Convolutional Neural Networks (CNNs) in
computer vision. ViTs excel at capturing global context, and SSMs like Mamba
offer linear complexity for long sequences, yet they do not capture
fine-grained local features as effectively as CNNs. Conversely, CNNs possess
strong inductive biases for local features but lack the global reasoning
capabilities of transformers and Mamba. To bridge this gap, we introduce
\textit{VCMamba}, a novel vision backbone that integrates the strengths of CNNs
and multi-directional Mamba SSMs. VCMamba employs a convolutional stem and a
hierarchical structure with convolutional blocks in its early stages to extract
rich local features. These convolutional blocks are then processed by later
stages incorporating multi-directional Mamba blocks designed to efficiently
model long-range dependencies and global context. This hybrid design allows for
superior feature representation while maintaining linear complexity with
respect to image resolution. We demonstrate VCMamba's effectiveness through
extensive experiments on ImageNet-1K classification and ADE20K semantic
segmentation. Our VCMamba-B achieves 82.6% top-1 accuracy on ImageNet-1K,
surpassing PlainMamba-L3 by 0.3% with 37% fewer parameters, and outperforming
Vision GNN-B by 0.3% with 64% fewer parameters. Furthermore, VCMamba-B obtains
47.1 mIoU on ADE20K, exceeding EfficientFormer-L7 by 2.0 mIoU while utilizing
62% fewer parameters. Code is available at
https://github.com/Wertyuui345/VCMamba.

</details>


### [10] [Guideline-Consistent Segmentation via Multi-Agent Refinement](https://arxiv.org/abs/2509.04687)
*Vanshika Vats,Ashwani Rathee,James Davis*

Main category: cs.CV

TL;DR: 提出无需训练的多智能体框架，通过迭代优化和强化学习策略提升语义分割对复杂文本指南的遵循能力，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现实应用中语义分割需严格遵循复杂文本标注指南的挑战，传统方法需昂贵任务特定重训练，而现有开放词汇分割方法难以处理段落级指南。

Method: 采用多智能体框架，包括Worker执行分割、Supervisor根据检索的指南进行批评，以及轻量级强化学习停止策略来决定循环终止时机。

Result: 在Waymo和ReasonSeg数据集上显著优于现有最先进基线，展示了强大的泛化能力和指令遵循性。

Conclusion: 提出的多智能体框架在无需训练的情况下，通过Worker-Supervisor的迭代优化和轻量级强化学习策略，显著提升了语义分割对复杂文本标注指南的遵循能力，并在Waymo和ReasonSeg数据集上优于现有方法。

Abstract: Semantic segmentation in real-world applications often requires not only
accurate masks but also strict adherence to textual labeling guidelines. These
guidelines are typically complex and long, and both human and automated
labeling often fail to follow them faithfully. Traditional approaches depend on
expensive task-specific retraining that must be repeated as the guidelines
evolve. Although recent open-vocabulary segmentation methods excel with simple
prompts, they often fail when confronted with sets of paragraph-length
guidelines that specify intricate segmentation rules. To address this, we
introduce a multi-agent, training-free framework that coordinates
general-purpose vision-language models within an iterative Worker-Supervisor
refinement architecture. The Worker performs the segmentation, the Supervisor
critiques it against the retrieved guidelines, and a lightweight reinforcement
learning stop policy decides when to terminate the loop, ensuring
guideline-consistent masks while balancing resource use. Evaluated on the Waymo
and ReasonSeg datasets, our method notably outperforms state-of-the-art
baselines, demonstrating strong generalization and instruction adherence.

</details>


### [11] [Domain Adaptation for Different Sensor Configurations in 3D Object Detection](https://arxiv.org/abs/2509.04711)
*Satoshi Tanaka,Kok Seang Tan,Isamu Yamashita*

Main category: cs.CV

TL;DR: 该论文针对不同传感器配置的3D物体检测领域适应问题，提出了下游微调和部分层微调两种技术，有效提升了模型在跨配置应用时的性能。


<details>
  <summary>Details</summary>
Motivation: 不同的车辆平台通常部署不同的传感器配置，导致模型在从一个配置应用到另一个配置时性能下降，因为点云分布发生了变化。

Method: 提出了两种技术：下游微调（在多数据集训练后进行数据集特定的微调）和部分层微调（仅更新部分层以提高跨配置的泛化能力）。

Result: 使用在相同地理区域收集的多个传感器配置的配对数据集，研究表明，结合下游微调和部分层微调的联合训练在每个配置上都一致优于简单的联合训练。

Conclusion: 研究提出了一种实用的、可扩展的解决方案，用于将3D物体检测模型适应到不同的车辆平台上。

Abstract: Recent advances in autonomous driving have underscored the importance of
accurate 3D object detection, with LiDAR playing a central role due to its
robustness under diverse visibility conditions. However, different vehicle
platforms often deploy distinct sensor configurations, causing performance
degradation when models trained on one configuration are applied to another
because of shifts in the point cloud distribution. Prior work on multi-dataset
training and domain adaptation for 3D object detection has largely addressed
environmental domain gaps and density variation within a single LiDAR; in
contrast, the domain gap for different sensor configurations remains largely
unexplored. In this work, we address domain adaptation across different sensor
configurations in 3D object detection. We propose two techniques: Downstream
Fine-tuning (dataset-specific fine-tuning after multi-dataset training) and
Partial Layer Fine-tuning (updating only a subset of layers to improve
cross-configuration generalization). Using paired datasets collected in the
same geographic region with multiple sensor configurations, we show that joint
training with Downstream Fine-tuning and Partial Layer Fine-tuning consistently
outperforms naive joint training for each configuration. Our findings provide a
practical and scalable solution for adapting 3D object detection models to the
diverse vehicle platforms.

</details>


### [12] [CD-Mamba: Cloud detection with long-range spatial dependency modeling](https://arxiv.org/abs/2509.04729)
*Tianxiang Xue,Jiayi Zhao,Jingsheng Li,Changlu Chen,Kun Zhan*

Main category: cs.CV

TL;DR: CD-Mamba是一种结合CNN和Mamba的混合模型，用于提升遥感图像云检测的准确性，尤其在多尺度云覆盖场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 遥感图像常被云层遮挡，影响数据完整性和可靠性。现有方法在同时处理短程空间冗余和长程大气相似性方面存在不足。

Method: 提出了一种混合模型CD-Mamba，结合卷积神经网络（CNN）和Mamba的状态空间建模，以同时捕捉局部空间关系和长程依赖。

Result: 大量实验验证了CD-Mamba的有效性，其性能优于现有方法。

Conclusion: CD-Mamba通过整合卷积神经网络和Mamba的状态空间建模，有效提升了云检测的准确性，尤其在处理不同空间尺度的云覆盖时表现优异。

Abstract: Remote sensing images are frequently obscured by cloud cover, posing
significant challenges to data integrity and reliability. Effective cloud
detection requires addressing both short-range spatial redundancies and
long-range atmospheric similarities among cloud patches. Convolutional neural
networks are effective at capturing local spatial dependencies, while Mamba has
strong capabilities in modeling long-range dependencies. To fully leverage both
local spatial relations and long-range dependencies, we propose CD-Mamba, a
hybrid model that integrates convolution and Mamba's state-space modeling into
a unified cloud detection network. CD-Mamba is designed to comprehensively
capture pixelwise textural details and long term patchwise dependencies for
cloud detection. This design enables CD-Mamba to manage both pixel-wise
interactions and extensive patch-wise dependencies simultaneously, improving
detection accuracy across diverse spatial scales. Extensive experiments
validate the effectiveness of CD-Mamba and demonstrate its superior performance
over existing methods.

</details>


### [13] [Exploiting Unlabeled Structures through Task Consistency Training for Versatile Medical Image Segmentation](https://arxiv.org/abs/2509.04732)
*Shengqian Zhu,Jiafei Wu,Xiaogang Xu,Chengrong Yu,Ying Song,Zhang Yi,Guangjun Li,Junjie Hu*

Main category: cs.CV

TL;DR: TCT框架通过任务一致性训练和过滤策略，无需额外模型解决了VMIS中的类别不平衡问题，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决VMIS中由于部分标注数据集（PLDs）导致的类别不平衡问题，避免额外模型和标签噪声带来的性能下降。

Method: 提出了TCT框架，包括主分割头（MSH）和多个辅助任务头（ATHs），通过一致性约束和过滤策略利用未标注解剖结构，并引入UAUWL来平衡任务主导问题。

Result: 在八个腹部数据集上的广泛实验证明了TCT框架的有效性。

Conclusion: TCT框架通过任务一致性训练和过滤策略，有效解决了VMIS中的类别不平衡问题，无需额外模型，且在多个腹部数据集上验证了其有效性。

Abstract: Versatile medical image segmentation (VMIS) targets the segmentation of
multiple classes, while obtaining full annotations for all classes is often
impractical due to the time and labor required. Leveraging partially labeled
datasets (PLDs) presents a promising alternative; however, current VMIS
approaches face significant class imbalance due to the unequal category
distribution in PLDs. Existing methods attempt to address this by generating
pseudo-full labels. Nevertheless, these typically require additional models and
often result in potential performance degradation from label noise. In this
work, we introduce a Task Consistency Training (TCT) framework to address class
imbalance without requiring extra models. TCT includes a backbone network with
a main segmentation head (MSH) for multi-channel predictions and multiple
auxiliary task heads (ATHs) for task-specific predictions. By enforcing a
consistency constraint between the MSH and ATH predictions, TCT effectively
utilizes unlabeled anatomical structures. To avoid error propagation from
low-consistency, potentially noisy data, we propose a filtering strategy to
exclude such data. Additionally, we introduce a unified auxiliary
uncertainty-weighted loss (UAUWL) to mitigate segmentation quality declines
caused by the dominance of specific tasks. Extensive experiments on eight
abdominal datasets from diverse clinical sites demonstrate our approach's
effectiveness.

</details>


### [14] [Enhancing Self-Driving Segmentation in Adverse Weather Conditions: A Dual Uncertainty-Aware Training Approach to SAM Optimization](https://arxiv.org/abs/2509.04735)
*Dharsan Ravindran,Kevin Wang,Zhuoyuan Cao,Saleh Abdelrahman,Jeffery Wu*

Main category: cs.CV

TL;DR: 研究通过引入不确定性感知训练，提升了SAM2在恶劣天气下的分割性能，UAT-SAM在极端条件下表现更优，验证了不确定性建模对自动驾驶的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM和SAM2在一般图像分割基准上表现优异，但在视觉模糊性高的恶劣天气条件下表现不佳，主要原因是缺乏不确定性量化。受医学成像中不确定性感知训练在模糊情况下提高可靠性的启发，研究旨在增强自动驾驶分割的鲁棒性。

Method: 研究采用了两种方法：一是为SAM2引入多步微调程序，将不确定性指标直接纳入损失函数；二是将最初为医学图像分割设计的UAT适配器调整至驾驶场景。

Result: 实验在CamVid、BDD100K和GTA驾驶数据集上进行，结果显示UAT-SAM在极端天气下优于标准SAM，而采用不确定性感知损失的SAM2在多样化驾驶场景中表现更佳。

Conclusion: 研究结果表明，在恶劣天气条件下，UAT-SAM优于标准SAM，而采用不确定性感知损失的SAM2在不同驾驶场景中表现更优。这强调了在安全关键型自动驾驶中，显式不确定性建模的重要性。

Abstract: Recent advances in vision foundation models, such as the Segment Anything
Model (SAM) and its successor SAM2, have achieved state-of-the-art performance
on general image segmentation benchmarks. However, these models struggle in
adverse weather conditions where visual ambiguity is high, largely due to their
lack of uncertainty quantification. Inspired by progress in medical imaging,
where uncertainty-aware training has improved reliability in ambiguous cases,
we investigate two approaches to enhance segmentation robustness for autonomous
driving. First, we introduce a multi-step finetuning procedure for SAM2 that
incorporates uncertainty metrics directly into the loss function, improving
overall scene recognition. Second, we adapt the Uncertainty-Aware Adapter
(UAT), originally designed for medical image segmentation, to driving contexts.
We evaluate both methods on CamVid, BDD100K, and GTA driving datasets.
Experiments show that UAT-SAM outperforms standard SAM in extreme weather,
while SAM2 with uncertainty-aware loss achieves improved performance across
diverse driving scenes. These findings underscore the value of explicit
uncertainty modeling for safety-critical autonomous driving in challenging
environments.

</details>


### [15] [WatchHAR: Real-time On-device Human Activity Recognition System for Smartwatches](https://arxiv.org/abs/2509.04736)
*Taeyoung Yeon,Vasco Xu,Henry Hoffmann,Karan Ahuja*

Main category: cs.CV

TL;DR: WatchHAR 是一个完全在智能手表上运行的音频和惯性 HAR 系统，优化了性能并解决了隐私和延迟问题。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态细粒度人类活动识别（HAR）取得了进展，但在不受约束的环境中完全在智能手表上运行的系统仍然难以实现。

Method: 通过优化每个管道组件，引入了一种新颖的架构，将传感器数据预处理和推理统一为端到端可训练模块。

Result: WatchHAR 在保持超过 25 个活动类别 90% 准确率的同时，实现了 5 倍的处理速度提升，并在智能手表上直接运行时，活动事件检测和分类的处理时间分别为 9.3 毫秒和 11.8 毫秒。

Conclusion: WatchHAR 实现了在智能手表上完全运行的细粒度人类活动识别系统，解决了外部数据处理带来的隐私和延迟问题，推动了设备端活动识别的进步。

Abstract: Despite advances in practical and multimodal fine-grained Human Activity
Recognition (HAR), a system that runs entirely on smartwatches in unconstrained
environments remains elusive. We present WatchHAR, an audio and inertial-based
HAR system that operates fully on smartwatches, addressing privacy and latency
issues associated with external data processing. By optimizing each component
of the pipeline, WatchHAR achieves compounding performance gains. We introduce
a novel architecture that unifies sensor data preprocessing and inference into
an end-to-end trainable module, achieving 5x faster processing while
maintaining over 90% accuracy across more than 25 activity classes. WatchHAR
outperforms state-of-the-art models for event detection and activity
classification while running directly on the smartwatch, achieving 9.3 ms
processing time for activity event detection and 11.8 ms for multimodal
activity classification. This research advances on-device activity recognition,
realizing smartwatches' potential as standalone, privacy-aware, and
minimally-invasive continuous activity tracking devices.

</details>


### [16] [MCANet: A Multi-Scale Class-Specific Attention Network for Multi-Label Post-Hurricane Damage Assessment using UAV Imagery](https://arxiv.org/abs/2509.04757)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: MCANet通过多尺度特征和类别特异性注意力机制，在飓风损害评估中实现高精度（mAP 91.75%），为灾后决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法难以捕捉多尺度空间特征及区分视觉相似或共现的损害类型，限制了灾后损害评估的准确性和效率。

Method: MCANet采用基于Res2Net的分层主干网络和多头类别特异性残差注意力模块，学习多尺度特征并自适应关注不同损害类别的空间相关区域。

Result: 在RescueNet数据集上，MCANet以91.75%的mAP优于其他模型，八头注意力进一步将性能提升至92.35%，尤其对挑战性类别（如道路阻塞）的AP提升超过6%。

Conclusion: MCANet通过多尺度特征学习和类别特异性注意力机制，显著提升了飓风后损害评估的准确性和可解释性，为灾后响应和恢复提供了有力支持。未来工作可结合知识图谱和多模态大语言模型进一步提升适应性。

Abstract: Rapid and accurate post-hurricane damage assessment is vital for disaster
response and recovery. Yet existing CNN-based methods struggle to capture
multi-scale spatial features and to distinguish visually similar or
co-occurring damage types. To address these issues, we propose MCANet, a
multi-label classification framework that learns multi-scale representations
and adaptively attends to spatially relevant regions for each damage category.
MCANet employs a Res2Net-based hierarchical backbone to enrich spatial context
across scales and a multi-head class-specific residual attention module to
enhance discrimination. Each attention branch focuses on different spatial
granularities, balancing local detail with global context. We evaluate MCANet
on the RescueNet dataset of 4,494 UAV images collected after Hurricane Michael.
MCANet achieves a mean average precision (mAP) of 91.75%, outperforming ResNet,
Res2Net, VGG, MobileNet, EfficientNet, and ViT. With eight attention heads,
performance further improves to 92.35%, boosting average precision for
challenging classes such as Road Blocked by over 6%. Class activation mapping
confirms MCANet's ability to localize damage-relevant regions, supporting
interpretability. Outputs from MCANet can inform post-disaster risk mapping,
emergency routing, and digital twin-based disaster response. Future work could
integrate disaster-specific knowledge graphs and multimodal large language
models to improve adaptability to unseen disasters and enrich semantic
understanding for real-world decision-making.

</details>


### [17] [Dynamic Group Detection using VLM-augmented Temporal Groupness Graph](https://arxiv.org/abs/2509.04758)
*Kaname Yokoyama,Chihiro Nakatani,Norimichi Ukita*

Main category: cs.CV

TL;DR: 本文提出一种动态视频群体检测方法，结合VLM和全局优化图，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 检测复杂群体时，不仅需要考虑群体成员的局部外观特征，还需关注场景的全局上下文。现有方法假设群体在视频中不变，无法处理动态变化。

Method: 使用增强的视觉语言模型（VLM）提取每帧的局部和全局外观特征，并通过全局优化图处理时间一致性，动态检测群体变化。

Result: 实验结果表明，该方法在公开数据集上优于最先进的群体检测方法。

Conclusion: 本文提出的方法通过结合视觉语言模型（VLM）和全局优化图，能够动态检测视频中变化的人类群体，并在公开数据集上优于现有方法。

Abstract: This paper proposes dynamic human group detection in videos. For detecting
complex groups, not only the local appearance features of in-group members but
also the global context of the scene are important. Such local and global
appearance features in each frame are extracted using a Vision-Language Model
(VLM) augmented for group detection in our method. For further improvement, the
group structure should be consistent over time. While previous methods are
stabilized on the assumption that groups are not changed in a video, our method
detects dynamically changing groups by global optimization using a graph with
all frames' groupness probabilities estimated by our groupness-augmented CLIP
features. Our experimental results demonstrate that our method outperforms
state-of-the-art group detection methods on public datasets. Code:
https://github.com/irajisamurai/VLM-GroupDetection.git

</details>


### [18] [FloodVision: Urban Flood Depth Estimation Using Foundation Vision-Language Models and Domain Knowledge Graph](https://arxiv.org/abs/2509.04772)
*Zhangding Liu,Neda Mohammadi,John E. Taylor*

Main category: cs.CV

TL;DR: FloodVision是一个零样本框架，结合GPT-4o和知识图，实现了准确且泛化的洪水深度估计，平均误差8.17厘米。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有计算机视觉方法在洪水深度估计中存在的准确性和泛化性问题，提出了FloodVision框架。

Method: FloodVision采用零样本框架，动态识别RGB图像中的参考物体，从知识图中检索已验证的高度，估计淹没比例，并应用统计离群值过滤来计算最终深度值。

Result: 在MyCoast New York的110张众包图像上评估，FloodVision的平均绝对误差为8.17厘米，比GPT-4o基线降低了20.5%，并超越了基于CNN的方法。

Conclusion: FloodVision通过结合GPT-4o的语义推理能力和结构化领域知识图，实现了跨多样化洪水场景的准确洪水深度估计，为智能城市防洪提供了实用工具。

Abstract: Timely and accurate floodwater depth estimation is critical for road
accessibility and emergency response. While recent computer vision methods have
enabled flood detection, they suffer from both accuracy limitations and poor
generalization due to dependence on fixed object detectors and task-specific
training. To enable accurate depth estimation that can generalize across
diverse flood scenarios, this paper presents FloodVision, a zero-shot framework
that combines the semantic reasoning abilities of the foundation
vision-language model GPT-4o with a structured domain knowledge graph. The
knowledge graph encodes canonical real-world dimensions for common urban
objects including vehicles, people, and infrastructure elements to ground the
model's reasoning in physical reality. FloodVision dynamically identifies
visible reference objects in RGB images, retrieves verified heights from the
knowledge graph to mitigate hallucination, estimates submergence ratios, and
applies statistical outlier filtering to compute final depth values. Evaluated
on 110 crowdsourced images from MyCoast New York, FloodVision achieves a mean
absolute error of 8.17 cm, reducing the GPT-4o baseline 10.28 cm by 20.5% and
surpassing prior CNN-based methods. The system generalizes well across varying
scenes and operates in near real-time, making it suitable for future
integration into digital twin platforms and citizen-reporting apps for smart
city flood resilience.

</details>


### [19] [MLP-SRGAN: A Single-Dimension Super Resolution GAN using MLP-Mixer](https://arxiv.org/abs/2303.06298)
*Samir Mitha,Seungho Choe,Pejman Jahbedar Maralani,Alan R. Moody,April Khademi*

Main category: cs.CV

TL;DR: MLP-SRGAN是一种新型的SRGAN架构，结合MLP-Mixers和卷积层，用于MRI图像上采样，表现优于现有方法，且效率更高。


<details>
  <summary>Details</summary>
Motivation: 为了解决低空间分辨率MRI图像在切片维度上的上采样问题，并提升图像质量。

Method: 提出了一种名为MLP-SRGAN的新型架构，结合了多层感知机混合器（MLP-Mixers）和卷积层，用于在切片方向上进行上采样。

Result: 在多个数据集上的实验表明，MLP-SRGAN在PSNR和SSIM指标上优于现有方法，并提出了新的无参考图像质量指标。

Conclusion: MLP-SRGAN在提升图像分辨率方面表现出色，具有更锐利的边缘、更少的模糊，并保留了更多纹理和细节，同时模型参数更少、训练/评估时间更快、模型体积更小。

Abstract: We propose a novel architecture called MLP-SRGAN, which is a single-dimension
Super Resolution Generative Adversarial Network (SRGAN) that utilizes
Multi-Layer Perceptron Mixers (MLP-Mixers) along with convolutional layers to
upsample in the slice direction. MLP-SRGAN is trained and validated using high
resolution (HR) FLAIR MRI from the MSSEG2 challenge dataset. The method was
applied to three multicentre FLAIR datasets (CAIN, ADNI, CCNA) of images with
low spatial resolution in the slice dimension to examine performance on
held-out (unseen) clinical data. Upsampled results are compared to several
state-of-the-art SR networks. For images with high resolution (HR) ground
truths, peak-signal-to-noise-ratio (PSNR) and structural similarity index
(SSIM) are used to measure upsampling performance. Several new structural,
no-reference image quality metrics were proposed to quantify sharpness (edge
strength), noise (entropy), and blurriness (low frequency information) in the
absence of ground truths. Results show MLP-SRGAN results in sharper edges, less
blurring, preserves more texture and fine-anatomical detail, with fewer
parameters, faster training/evaluation time, and smaller model size than
existing methods. Code for MLP-SRGAN training and inference, data generators,
models and no-reference image quality metrics will be available at
https://github.com/IAMLAB-Ryerson/MLP-SRGAN.

</details>


### [20] [Hybrid-Tower: Fine-grained Pseudo-query Interaction and Generation for Text-to-Video Retrieval](https://arxiv.org/abs/2509.04773)
*Bangxiang Lan,Ruobing Xie,Ruixiang Zhao,Xingwu Sun,Zhanhui Kang,Gang Yang,Xirong Li*

Main category: cs.CV

TL;DR: PIG方法通过混合塔框架和伪查询生成，在文本到视频检索中同时提升效能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的Two-Tower框架效率高但效能低，而Single-Tower框架效能高但效率低，因此需要一种能兼顾两者的新框架。

Method: 提出了一种名为PIG的新方法，包括一个伪查询生成器，用于为每个视频生成伪查询，使视频特征与伪查询的文本特征进行细粒度交互。

Result: 在五个常用基准测试中，PIG方法在R@1指标上提升了1.6%至3.9%，同时保持了与Two-Tower模型相当的效率。

Conclusion: 本文提出的混合塔框架PIG在文本到视频检索任务中同时实现了高效率和高效能，通过伪查询生成和细粒度交互，显著提升了检索性能。

Abstract: The Text-to-Video Retrieval (T2VR) task aims to retrieve unlabeled videos by
textual queries with the same semantic meanings. Recent CLIP-based approaches
have explored two frameworks: Two-Tower versus Single-Tower framework, yet the
former suffers from low effectiveness, while the latter suffers from low
efficiency. In this study, we explore a new Hybrid-Tower framework that can
hybridize the advantages of the Two-Tower and Single-Tower framework, achieving
high effectiveness and efficiency simultaneously. We propose a novel hybrid
method, Fine-grained Pseudo-query Interaction and Generation for T2VR, ie, PIG,
which includes a new pseudo-query generator designed to generate a pseudo-query
for each video. This enables the video feature and the textual features of
pseudo-query to interact in a fine-grained manner, similar to the Single-Tower
approaches to hold high effectiveness, even before the real textual query is
received. Simultaneously, our method introduces no additional storage or
computational overhead compared to the Two-Tower framework during the inference
stage, thus maintaining high efficiency. Extensive experiments on five commonly
used text-video retrieval benchmarks demonstrate that our method achieves a
significant improvement over the baseline, with an increase of $1.6\% \sim
3.9\%$ in R@1. Furthermore, our method matches the efficiency of Two-Tower
models while achieving near state-of-the-art performance, highlighting the
advantages of the Hybrid-Tower framework.

</details>


### [21] [Comparative Evaluation of Traditional and Deep Learning Feature Matching Algorithms using Chandrayaan-2 Lunar Data](https://arxiv.org/abs/2509.04775)
*R. Makharia,J. G. Singla,Amitabh,N. Dube,H. Sharma*

Main category: cs.CV

TL;DR: 研究评估了五种图像配准算法在月球数据上的表现，提出预处理流程，发现SuperGlue最优，强调预处理和深度学习的重要性。


<details>
  <summary>Details</summary>
Motivation: 精确的图像配准对于月球探索至关重要，但由于不同传感器数据的分辨率、光照和传感器畸变差异，配准具有挑战性。

Method: 评估了五种特征匹配算法（SIFT、ASIFT、AKAZE、RIFT2和SuperGlue），并提出了包括地理参考、分辨率对齐、强度归一化等预处理流程。

Result: SuperGlue在均方根误差和运行时间上表现最优，而经典方法在赤道附近表现良好但在极地光照下效果下降。

Conclusion: 该研究强调了预处理和基于学习的方法在多样化条件下实现稳健月球图像配准的重要性，其中SuperGlue表现最佳。

Abstract: Accurate image registration is critical for lunar exploration, enabling
surface mapping, resource localization, and mission planning. Aligning data
from diverse lunar sensors -- optical (e.g., Orbital High Resolution Camera,
Narrow and Wide Angle Cameras), hyperspectral (Imaging Infrared Spectrometer),
and radar (e.g., Dual-Frequency Synthetic Aperture Radar, Selene/Kaguya
mission) -- is challenging due to differences in resolution, illumination, and
sensor distortion. We evaluate five feature matching algorithms: SIFT, ASIFT,
AKAZE, RIFT2, and SuperGlue (a deep learning-based matcher), using
cross-modality image pairs from equatorial and polar regions. A preprocessing
pipeline is proposed, including georeferencing, resolution alignment, intensity
normalization, and enhancements like adaptive histogram equalization, principal
component analysis, and shadow correction. SuperGlue consistently yields the
lowest root mean square error and fastest runtimes. Classical methods such as
SIFT and AKAZE perform well near the equator but degrade under polar lighting.
The results highlight the importance of preprocessing and learning-based
approaches for robust lunar image registration across diverse conditions.

</details>


### [22] [Enhancing 3D Point Cloud Classification with ModelNet-R and Point-SkipNet](https://arxiv.org/abs/2509.05198)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari*

Main category: cs.CV

TL;DR: 论文提出改进的ModelNet-R数据集和轻量级Point-SkipNet网络，显著提升3D点云分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有ModelNet40数据集存在标签不一致、2D数据、尺寸不匹配和类别区分不足等问题，影响模型性能。

Method: 提出ModelNet-R改进数据集和Point-SkipNet网络，后者采用高效采样、邻域分组和跳跃连接。

Result: 实验显示ModelNet-R显著提升模型性能，Point-SkipNet在低参数下达到最佳准确率。

Conclusion: 高质量数据集对优化3D点云分类模型效率至关重要。

Abstract: The classification of 3D point clouds is crucial for applications such as
autonomous driving, robotics, and augmented reality. However, the commonly used
ModelNet40 dataset suffers from limitations such as inconsistent labeling, 2D
data, size mismatches, and inadequate class differentiation, which hinder model
performance. This paper introduces ModelNet-R, a meticulously refined version
of ModelNet40 designed to address these issues and serve as a more reliable
benchmark. Additionally, this paper proposes Point-SkipNet, a lightweight
graph-based neural network that leverages efficient sampling, neighborhood
grouping, and skip connections to achieve high classification accuracy with
reduced computational overhead. Extensive experiments demonstrate that models
trained in ModelNet-R exhibit significant performance improvements. Notably,
Point-SkipNet achieves state-of-the-art accuracy on ModelNet-R with a
substantially lower parameter count compared to contemporary models. This
research highlights the crucial role of dataset quality in optimizing model
efficiency for 3D point cloud classification. For more details, see the code
at: https://github.com/m-saeid/ModeNetR_PointSkipNet.

</details>


### [23] [Toward Accessible Dermatology: Skin Lesion Classification Using Deep Learning Models on Mobile-Acquired Images](https://arxiv.org/abs/2509.04800)
*Asif Newaz,Masum Mushfiq Ishti,A Z M Ashraful Azam,Asif Ur Rahman Adib*

Main category: cs.CV

TL;DR: 本研究利用移动设备采集的大规模皮肤疾病数据集，评估了多种深度学习模型，发现Swin Transformer性能最佳，并通过Grad-CAM增强可解释性，为资源有限地区的皮肤病筛查提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 皮肤疾病是全球普遍的健康问题，但传统诊断方法成本高、复杂且在资源匮乏地区难以获取。现有的深度学习研究大多局限于皮肤镜数据集和有限的疾病类别，无法代表真实世界情况。

Method: 评估了多种卷积神经网络和基于Transformer的架构，并引入了Gradient-weighted Class Activation Mapping (Grad-CAM)以增强模型的可解释性。

Result: Transformer模型，尤其是Swin Transformer，通过有效捕捉全局上下文特征，表现出卓越性能。Grad-CAM的应用进一步提供了模型预测的透明度和临床相关区域的突出显示。

Conclusion: 本研究展示了基于Transformer的模型，特别是Swin Transformer，在移动设备采集的皮肤病变分类中的优越性能，为资源有限环境中的AI辅助皮肤病筛查和早期诊断提供了可行路径。

Abstract: Skin diseases are among the most prevalent health concerns worldwide, yet
conventional diagnostic methods are often costly, complex, and unavailable in
low-resource settings. Automated classification using deep learning has emerged
as a promising alternative, but existing studies are mostly limited to
dermoscopic datasets and a narrow range of disease classes. In this work, we
curate a large dataset of over 50 skin disease categories captured with mobile
devices, making it more representative of real-world conditions. We evaluate
multiple convolutional neural networks and Transformer-based architectures,
demonstrating that Transformer models, particularly the Swin Transformer,
achieve superior performance by effectively capturing global contextual
features. To enhance interpretability, we incorporate Gradient-weighted Class
Activation Mapping (Grad-CAM), which highlights clinically relevant regions and
provides transparency in model predictions. Our results underscore the
potential of Transformer-based approaches for mobile-acquired skin lesion
classification, paving the way toward accessible AI-assisted dermatological
screening and early diagnosis in resource-limited environments.

</details>


### [24] [Extracting Uncertainty Estimates from Mixtures of Experts for Semantic Segmentation](https://arxiv.org/abs/2509.04816)
*Svetlana Pavlitska,Beyza Keskin,Alwin Faßbender,Christian Hubschneider,J. Marius Zöllner*

Main category: cs.CV

TL;DR: MoE通过动态加权专家预测，在不确定性估计上优于集成方法，尤其在OOD数据下表现更可靠。简单门控机制和增加专家数量可提升校准效果。


<details>
  <summary>Details</summary>
Motivation: 在安全关键应用（如交通场景感知）中，准确且校准良好的预测不确定性对提升计算机视觉模型的可靠性至关重要。MoE提供了一种高效的替代方案，通过门控网络动态加权专家预测。

Method: 研究了三种从MoE中提取预测不确定性估计的方法：预测熵、互信息和专家方差。使用两个专家的MoE在A2D2数据集上进行训练，并在Cityscapes数据集上进行验证。

Result: MoE在不确定性估计方面比集成方法表现更好，尤其是在OOD数据下。简单门控机制的路由不确定性校准效果优于复杂类别门控。增加专家数量可进一步提升不确定性校准。

Conclusion: 通过实验验证，MoE（专家混合模型）在不确定性估计方面比集成方法更可靠，尤其是在处理分布外数据时。简单的门控机制比复杂的类别门控更能有效校准路由不确定性。增加专家数量可以进一步提升不确定性校准效果。

Abstract: Estimating accurate and well-calibrated predictive uncertainty is important
for enhancing the reliability of computer vision models, especially in
safety-critical applications like traffic scene perception. While ensemble
methods are commonly used to quantify uncertainty by combining multiple models,
a mixture of experts (MoE) offers an efficient alternative by leveraging a
gating network to dynamically weight expert predictions based on the input.
Building on the promising use of MoEs for semantic segmentation in our previous
works, we show that well-calibrated predictive uncertainty estimates can be
extracted from MoEs without architectural modifications. We investigate three
methods to extract predictive uncertainty estimates: predictive entropy, mutual
information, and expert variance. We evaluate these methods for an MoE with two
experts trained on a semantical split of the A2D2 dataset. Our results show
that MoEs yield more reliable uncertainty estimates than ensembles in terms of
conditional correctness metrics under out-of-distribution (OOD) data.
Additionally, we evaluate routing uncertainty computed via gate entropy and
find that simple gating mechanisms lead to better calibration of routing
uncertainty estimates than more complex classwise gates. Finally, our
experiments on the Cityscapes dataset suggest that increasing the number of
experts can further enhance uncertainty calibration. Our code is available at
https://github.com/KASTEL-MobilityLab/mixtures-of-experts/.

</details>


### [25] [Exploring Non-Local Spatial-Angular Correlations with a Hybrid Mamba-Transformer Framework for Light Field Super-Resolution](https://arxiv.org/abs/2509.04824)
*Haosong Liu,Xiancheng Zhu,Huanqiang Zeng,Jianqing Zhu,Jiuwen Cao,Junhui Hou*

Main category: cs.CV

TL;DR: LFMT框架结合Mamba和Transformer，通过Sub-SS策略和双阶段建模，显著提升光场超分辨率性能，同时保持低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba方法在复杂光场数据中存在特征提取效率低和冗余的问题，需要更高效的策略和模块来优化性能。

Method: 提出了Subspace Simple Scanning (Sub-SS)策略和Subspace Simple Mamba Block (SSMB)，以及双阶段建模策略（SA-RSMB和EPMB/EPTB），构建了混合Mamba-Transformer框架LFMT。

Result: 实验结果表明，LFMT在真实和合成光场数据集上均显著优于当前最先进方法，性能大幅提升且计算复杂度低。

Conclusion: LFMT框架通过结合Mamba和Transformer的优势，在光场图像超分辨率任务中实现了显著的性能提升，同时保持了低计算复杂度。

Abstract: Recently, Mamba-based methods, with its advantage in long-range information
modeling and linear complexity, have shown great potential in optimizing both
computational cost and performance of light field image super-resolution
(LFSR). However, current multi-directional scanning strategies lead to
inefficient and redundant feature extraction when applied to complex LF data.
To overcome this challenge, we propose a Subspace Simple Scanning (Sub-SS)
strategy, based on which we design the Subspace Simple Mamba Block (SSMB) to
achieve more efficient and precise feature extraction. Furthermore, we propose
a dual-stage modeling strategy to address the limitation of state space in
preserving spatial-angular and disparity information, thereby enabling a more
comprehensive exploration of non-local spatial-angular correlations.
Specifically, in stage I, we introduce the Spatial-Angular Residual Subspace
Mamba Block (SA-RSMB) for shallow spatial-angular feature extraction; in stage
II, we use a dual-branch parallel structure combining the Epipolar Plane Mamba
Block (EPMB) and Epipolar Plane Transformer Block (EPTB) for deep epipolar
feature refinement. Building upon meticulously designed modules and strategies,
we introduce a hybrid Mamba-Transformer framework, termed LFMT. LFMT integrates
the strengths of Mamba and Transformer models for LFSR, enabling comprehensive
information exploration across spatial, angular, and epipolar-plane domains.
Experimental results demonstrate that LFMT significantly outperforms current
state-of-the-art methods in LFSR, achieving substantial improvements in
performance while maintaining low computational complexity on both real-word
and synthetic LF datasets.

</details>


### [26] [PropVG: End-to-End Proposal-Driven Visual Grounding with Multi-Granularity Discrimination](https://arxiv.org/abs/2509.04833)
*Ming Dai,Wenxuan Cheng,Jiedong Zhuang,Jiang-jiang Liu,Hongshen Zhao,Zhenhua Feng,Wankou Yang*

Main category: cs.CV

TL;DR: PropVG提出了一种端到端视觉定位框架，结合CRS和MTD模块，显著提升了复杂场景中的目标识别能力。


<details>
  <summary>Details</summary>
Motivation: 现有端到端视觉定位方法依赖单一监督目标且缺乏多粒度区分能力，导致在复杂场景中表现不佳。

Method: PropVG是一个端到端的提议框架，集成了对比学习的CRS模块和多粒度目标识别的MTD模块。

Result: 在多个基准测试（gRefCOCO、Ref-ZOM、R-RefCOCO、RefCOCO）上，PropVG表现出优越性能。

Conclusion: PropVG框架通过结合前景对象提议生成和参考对象理解，显著提升了视觉定位的效率和准确性。CRS和MTD模块的引入进一步增强了模型在多粒度目标识别和复杂场景中的鲁棒性。

Abstract: Recent advances in visual grounding have largely shifted away from
traditional proposal-based two-stage frameworks due to their inefficiency and
high computational complexity, favoring end-to-end direct reference paradigms.
However, these methods rely exclusively on the referred target for supervision,
overlooking the potential benefits of prominent prospective targets. Moreover,
existing approaches often fail to incorporate multi-granularity discrimination,
which is crucial for robust object identification in complex scenarios. To
address these limitations, we propose PropVG, an end-to-end proposal-based
framework that, to the best of our knowledge, is the first to seamlessly
integrate foreground object proposal generation with referential object
comprehension without requiring additional detectors. Furthermore, we introduce
a Contrastive-based Refer Scoring (CRS) module, which employs contrastive
learning at both sentence and word levels to enhance the capability in
understanding and distinguishing referred objects. Additionally, we design a
Multi-granularity Target Discrimination (MTD) module that fuses object- and
semantic-level information to improve the recognition of absent targets.
Extensive experiments on gRefCOCO (GREC/GRES), Ref-ZOM, R-RefCOCO, and RefCOCO
(REC/RES) benchmarks demonstrate the effectiveness of PropVG. The codes and
models are available at https://github.com/Dmmm1997/PropVG.

</details>


### [27] [TemporalFlowViz: Parameter-Aware Visual Analytics for Interpreting Scramjet Combustion Evolution](https://arxiv.org/abs/2509.04834)
*Yifei Jia,Shiyu Cheng,Yu Dong,Guan Li,Dong Tian,Ruixiao Peng,Xuyi Lu,Yu Wang,Wei Yao,Guihua Shan*

Main category: cs.CV

TL;DR: TemporalFlowViz是一个针对超燃冲压发动机燃烧模拟的视觉分析系统，通过预训练模型和专家标注提升了对复杂燃烧动力学的理解和分析效率。


<details>
  <summary>Details</summary>
Motivation: 超燃冲压发动机中复杂的燃烧动力学对高速推进技术的发展至关重要，但模拟生成的大规模高维时间流场数据在视觉解释、特征区分和跨案例比较方面存在显著挑战。

Method: 使用预训练的Vision Transformers提取高维嵌入，应用降维和基于密度的聚类来揭示潜在燃烧模式，并构建嵌入空间中的时间轨迹以跟踪每个模拟的时间演化。

Result: TemporalFlowViz系统支持专家驱动的聚类、可视化和解释，通过参数过滤、相似性案例检索和协调多视图探索，促进了深入分析。

Conclusion: TemporalFlowViz系统通过专家反馈和案例研究证明，能够有效增强假设生成、支持可解释的模式发现，并促进大规模超燃冲压发动机燃烧分析中的知识发现。

Abstract: Understanding the complex combustion dynamics within scramjet engines is
critical for advancing high-speed propulsion technologies. However, the large
scale and high dimensionality of simulation-generated temporal flow field data
present significant challenges for visual interpretation, feature
differentiation, and cross-case comparison. In this paper, we present
TemporalFlowViz, a parameter-aware visual analytics workflow and system
designed to support expert-driven clustering, visualization, and interpretation
of temporal flow fields from scramjet combustion simulations. Our approach
leverages hundreds of simulated combustion cases with varying initial
conditions, each producing time-sequenced flow field images. We use pretrained
Vision Transformers to extract high-dimensional embeddings from these frames,
apply dimensionality reduction and density-based clustering to uncover latent
combustion modes, and construct temporal trajectories in the embedding space to
track the evolution of each simulation over time. To bridge the gap between
latent representations and expert reasoning, domain specialists annotate
representative cluster centroids with descriptive labels. These annotations are
used as contextual prompts for a vision-language model, which generates
natural-language summaries for individual frames and full simulation cases. The
system also supports parameter-based filtering, similarity-based case
retrieval, and coordinated multi-view exploration to facilitate in-depth
analysis. We demonstrate the effectiveness of TemporalFlowViz through two
expert-informed case studies and expert feedback, showing TemporalFlowViz
enhances hypothesis generation, supports interpretable pattern discovery, and
enhances knowledge discovery in large-scale scramjet combustion analysis.

</details>


### [28] [Pose-Free 3D Quantitative Phase Imaging of Flowing Cellular Populations](https://arxiv.org/abs/2509.04848)
*Enze Ye,Wei Lin,Shaochi Ren,Yakun Liu,Xiaoping Li,Hao Wang,He Sun,Feng Pan*

Main category: cs.CV

TL;DR: OmniFHT 是一种无需姿态信息的3D RI重建框架，支持任意细胞形状和旋转，首次实现流动细胞群体的高通量断层成像。


<details>
  <summary>Details</summary>
Motivation: 当前成像方法假设细胞进行均匀单轴旋转，限制了其仅适用于近球形细胞，无法准确成像不规则形状和复杂旋转的细胞。这导致只能分析细胞群体的子集，限制了流式分析的统计稳健性。

Method: OmniFHT 利用傅里叶衍射定理和隐式神经表示（INRs），通过联合优化每个细胞的未知旋转轨迹和体积结构，支持任意细胞几何形状和多轴旋转。

Result: OmniFHT 能够从稀疏采样投影和有限角度覆盖中实现高保真重建，仅需10个视图或120度的角度范围即可获得准确结果。

Conclusion: OmniFHT 提出了一种无需姿态信息的3D RI重建框架，首次实现了对流动细胞群体的原位高通量断层成像，为流式细胞仪平台提供了一种可扩展且无偏的标记自由形态分析解决方案。

Abstract: High-throughput 3D quantitative phase imaging (QPI) in flow cytometry enables
label-free, volumetric characterization of individual cells by reconstructing
their refractive index (RI) distributions from multiple viewing angles during
flow through microfluidic channels. However, current imaging methods assume
that cells undergo uniform, single-axis rotation, which require their poses to
be known at each frame. This assumption restricts applicability to
near-spherical cells and prevents accurate imaging of irregularly shaped cells
with complex rotations. As a result, only a subset of the cellular population
can be analyzed, limiting the ability of flow-based assays to perform robust
statistical analysis. We introduce OmniFHT, a pose-free 3D RI reconstruction
framework that leverages the Fourier diffraction theorem and implicit neural
representations (INRs) for high-throughput flow cytometry tomographic imaging.
By jointly optimizing each cell's unknown rotational trajectory and volumetric
structure under weak scattering assumptions, OmniFHT supports arbitrary cell
geometries and multi-axis rotations. Its continuous representation also allows
accurate reconstruction from sparsely sampled projections and restricted
angular coverage, producing high-fidelity results with as few as 10 views or
only 120 degrees of angular range. OmniFHT enables, for the first time, in
situ, high-throughput tomographic imaging of entire flowing cell populations,
providing a scalable and unbiased solution for label-free morphometric analysis
in flow cytometry platforms.

</details>


### [29] [CoRe-GS: Coarse-to-Refined Gaussian Splatting with Semantic Object Focus](https://arxiv.org/abs/2509.04859)
*Hannah Schieber,Dominik Frischmann,Simon Boche,Victor Schaack,Angela Schoellig,Stefan Leutenegger,Daniel Roth*

Main category: cs.CV

TL;DR: CoRe-GS结合语义高斯分布和颜色过滤，显著减少训练时间并提升3D重建质量。


<details>
  <summary>Details</summary>
Motivation: 移动机器人应用（如远程指导和灾难响应）需要快速且准确的3D重建，而传统方法往往耗时且不高效。

Method: 首先通过语义高斯分布生成粗分割场景，然后使用基于颜色的有效过滤方法对语义对象进行细化。

Result: 在SCRREAM和NeRDS 360数据集上的实验表明，CoRe-GS减少了约四分之一的训练时间，并提高了新视角合成的质量。

Conclusion: CoRe-GS通过在语义高斯分布的基础上进行颜色过滤，有效提高了对象隔离的效率，显著减少了训练时间，同时保持了高质量的新视角合成效果。

Abstract: Mobile reconstruction for autonomous aerial robotics holds strong potential
for critical applications such as tele-guidance and disaster response. These
tasks demand both accurate 3D reconstruction and fast scene processing. Instead
of reconstructing the entire scene in detail, it is often more efficient to
focus on specific objects, i.e., points of interest (PoIs). Mobile robots
equipped with advanced sensing can usually detect these early during data
acquisition or preliminary analysis, reducing the need for full-scene
optimization. Gaussian Splatting (GS) has recently shown promise in delivering
high-quality novel view synthesis and 3D representation by an incremental
learning process. Extending GS with scene editing, semantics adds useful
per-splat features to isolate objects effectively.
  Semantic 3D Gaussian editing can already be achieved before the full training
cycle is completed, reducing the overall training time. Moreover, the
semantically relevant area, the PoI, is usually already known during capturing.
To balance high-quality reconstruction with reduced training time, we propose
CoRe-GS. We first generate a coarse segmentation-ready scene with semantic GS
and then refine it for the semantic object using our novel color-based
effective filtering for effective object isolation. This is speeding up the
training process to be about a quarter less than a full training cycle for
semantic GS. We evaluate our approach on two datasets, SCRREAM (real-world,
outdoor) and NeRDS 360 (synthetic, indoor), showing reduced runtime and higher
novel-view-synthesis quality.

</details>


### [30] [Cryo-RL: automating prostate cancer cryoablation planning with reinforcement learning](https://arxiv.org/abs/2509.04886)
*Trixia Simangan,Ahmed Nadeem Abbasi,Yipeng Hu,Shaheer U. Saeed*

Main category: cs.CV

TL;DR: Cryo-RL利用强化学习自动优化冷冻探针放置，显著提升计划效率和质量，达到专家水平。


<details>
  <summary>Details</summary>
Motivation: 当前冷冻消融计划依赖人工，耗时且结果不一致，限制了治疗的可扩展性和质量。

Method: Cryo-RL是一个强化学习框架，将冷冻消融计划建模为马尔可夫决策过程，学习冷冻探针放置的最优策略。

Result: 在583例回顾性前列腺癌病例中，Cryo-RL比最佳自动化基线（基于几何优化）提高了8个百分点的Dice分数，且与人类专家表现相当，同时显著减少计划时间。

Conclusion: Cryo-RL展示了强化学习在提供临床可行、可重复且高效的冷冻消融计划方面的潜力。

Abstract: Cryoablation is a minimally invasive localised treatment for prostate cancer
that destroys malignant tissue during de-freezing, while sparing surrounding
healthy structures. Its success depends on accurate preoperative planning of
cryoprobe placements to fully cover the tumour and avoid critical anatomy. This
planning is currently manual, expertise-dependent, and time-consuming, leading
to variability in treatment quality and limited scalability. In this work, we
introduce Cryo-RL, a reinforcement learning framework that models cryoablation
planning as a Markov decision process and learns an optimal policy for
cryoprobe placement. Within a simulated environment that models clinical
constraints and stochastic intraoperative variability, an agent sequentially
selects cryoprobe positions and ice sphere diameters. Guided by a reward
function based on tumour coverage, this agent learns a cryoablation strategy
that leads to optimal cryoprobe placements without the need for any
manually-designed plans. Evaluated on 583 retrospective prostate cancer cases,
Cryo-RL achieved over 8 percentage-point Dice improvements compared with the
best automated baselines, based on geometric optimisation, and matched human
expert performance while requiring substantially less planning time. These
results highlight the potential of reinforcement learning to deliver clinically
viable, reproducible, and efficient cryoablation plans.

</details>


### [31] [SpiderNets: Estimating Fear Ratings of Spider-Related Images with Vision Models](https://arxiv.org/abs/2509.04889)
*Dominik Pegler,David Steyrl,Mengfan Zhang,Alexander Karner,Jozsef Arato,Frank Scharnowski,Filip Melinscak*

Main category: cs.CV

TL;DR: 研究通过迁移学习调整计算机视觉模型，成功预测蜘蛛图像的恐惧评分，平均误差10.1-11.0，强调了可解释性和足够数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 探索预训练计算机视觉模型是否能准确从蜘蛛相关图像预测恐惧水平，作为开发自适应系统的关键步骤。

Method: 研究通过迁移学习调整了三种不同的模型，以预测人类对313张标准化蜘蛛相关图像的恐惧评分（0-100分）。模型使用交叉验证进行评估。

Result: 模型的平均绝对误差（MAE）在10.1到11.0之间。学习曲线分析显示，减少数据集大小会显著影响性能，但进一步增加数据集不会带来实质性提升。

Conclusion: 研究表明，可解释的计算机视觉模型在预测恐惧评分方面具有潜力，强调了模型可解释性和足够的数据集大小对于开发有效的情感感知治疗技术的重要性。

Abstract: Advances in computer vision have opened new avenues for clinical
applications, particularly in computerized exposure therapy where visual
stimuli can be dynamically adjusted based on patient responses. As a critical
step toward such adaptive systems, we investigated whether pretrained computer
vision models can accurately predict fear levels from spider-related images. We
adapted three diverse models using transfer learning to predict human fear
ratings (on a 0-100 scale) from a standardized dataset of 313 images. The
models were evaluated using cross-validation, achieving an average mean
absolute error (MAE) between 10.1 and 11.0. Our learning curve analysis
revealed that reducing the dataset size significantly harmed performance,
though further increases yielded no substantial gains. Explainability
assessments showed the models' predictions were based on spider-related
features. A category-wise error analysis further identified visual conditions
associated with higher errors (e.g., distant views and artificial/painted
spiders). These findings demonstrate the potential of explainable computer
vision models in predicting fear ratings, highlighting the importance of both
model explainability and a sufficient dataset size for developing effective
emotion-aware therapeutic technologies.

</details>


### [32] [SynGen-Vision: Synthetic Data Generation for training industrial vision models](https://arxiv.org/abs/2509.04894)
*Alpana Dubey,Suma Mani Kuriakose,Nitish Bhardwaj*

Main category: cs.CV

TL;DR: 提出一种利用合成数据训练工业磨损检测模型的方法，效果优于传统数据采集方式。


<details>
  <summary>Details</summary>
Motivation: 工业磨损检测对预测性维护至关重要，但真实数据获取成本高且耗时。

Method: 结合视觉语言模型与3D模拟渲染引擎生成不同锈蚀条件的合成数据。

Result: 使用合成数据训练的模型在真实锈蚀图像测试中mAP50得分0.87，优于其他方法。

Conclusion: 该方法通过合成数据训练计算机视觉模型，在工业磨损检测任务中表现出色，且具有可扩展性。

Abstract: We propose an approach to generate synthetic data to train computer vision
(CV) models for industrial wear and tear detection. Wear and tear detection is
an important CV problem for predictive maintenance tasks in any industry.
However, data curation for training such models is expensive and time-consuming
due to the unavailability of datasets for different wear and tear scenarios.
Our approach employs a vision language model along with a 3D simulation and
rendering engine to generate synthetic data for varying rust conditions. We
evaluate our approach by training a CV model for rust detection using the
generated dataset and tested the trained model on real images of rusted
industrial objects. The model trained with the synthetic data generated by our
approach, outperforms the other approaches with a mAP50 score of 0.87. The
approach is customizable and can be easily extended to other industrial wear
and tear detection scenarios

</details>


### [33] [Evaluating Multiple Instance Learning Strategies for Automated Sebocyte Droplet Counting](https://arxiv.org/abs/2509.04895)
*Maryam Adelipour,Gustavo Carneiro,Jeongkwon Kim*

Main category: cs.CV

TL;DR: 研究提出了一种基于注意力的MIL框架用于皮脂腺图像分析，发现简单MLP表现更稳定，而MIL需要进一步优化才能发挥潜力。


<details>
  <summary>Details</summary>
Motivation: 手动计数脂滴既耗时又主观，因此需要自动化解决方案。

Method: 引入了一个简单的基于注意力的多实例学习（MIL）框架，包括基准多层感知器（MLP）和基于注意力的MIL模型（利用ResNet-50特征和实例加权）。

Result: 实验显示基准MLP表现更稳定（平均MAE=5.6），而基于注意力的MIL一致性较差（平均MAE=10.7），但在特定折叠中偶尔表现更优。

Conclusion: 简单基于袋级别的聚合为幻灯片级别的脂滴计数提供了稳健的基准，而基于注意力的MIL需要任务对齐的池化和正则化才能充分发挥其在皮脂腺图像分析中的潜力。

Abstract: Sebocytes are lipid-secreting cells whose differentiation is marked by the
accumulation of intracellular lipid droplets, making their quantification a key
readout in sebocyte biology. Manual counting is labor-intensive and subjective,
motivating automated solutions. Here, we introduce a simple attention-based
multiple instance learning (MIL) framework for sebocyte image analysis. Nile
Red-stained sebocyte images were annotated into 14 classes according to droplet
counts, expanded via data augmentation to about 50,000 cells. Two models were
benchmarked: a baseline multi-layer perceptron (MLP) trained on aggregated
patch-level counts, and an attention-based MIL model leveraging ResNet-50
features with instance weighting. Experiments using five-fold cross-validation
showed that the baseline MLP achieved more stable performance (mean MAE = 5.6)
compared with the attention-based MIL, which was less consistent (mean MAE =
10.7) but occasionally superior in specific folds. These findings indicate that
simple bag-level aggregation provides a robust baseline for slide-level droplet
counting, while attention-based MIL requires task-aligned pooling and
regularization to fully realize its potential in sebocyte image analysis.

</details>


### [34] [UniView: Enhancing Novel View Synthesis From A Single Image By Unifying Reference Features](https://arxiv.org/abs/2509.04932)
*Haowang Cui,Rui Chen,Tao Luo,Rui Li,Jiaze Wang*

Main category: cs.CV

TL;DR: UniView利用参考图像和MLLM辅助选择，结合动态特征生成和注意力机制，显著提升单图像新视角合成的性能。


<details>
  <summary>Details</summary>
Motivation: 解决单图像新视角合成中由于未观察区域多解释性导致的严重失真问题。

Method: 构建了检索和增强系统，利用多模态大语言模型辅助选择参考图像，并引入带有多级隔离层的即插即用适配器模块动态生成参考特征。此外，设计了分离的三重注意力机制以保留原始图像的细节。

Result: UniView在多个数据集上显著提升了新视角合成的性能，优于现有方法。

Conclusion: UniView通过引入参考图像和多模态大语言模型辅助选择，显著提升了单图像新视角合成的性能，并在多个数据集上超越了现有方法。

Abstract: The task of synthesizing novel views from a single image is highly ill-posed
due to multiple explanations for unobserved areas. Most current methods tend to
generate unseen regions from ambiguity priors and interpolation near input
views, which often lead to severe distortions. To address this limitation, we
propose a novel model dubbed as UniView, which can leverage reference images
from a similar object to provide strong prior information during view
synthesis. More specifically, we construct a retrieval and augmentation system
and employ a multimodal large language model (MLLM) to assist in selecting
reference images that meet our requirements. Additionally, a plug-and-play
adapter module with multi-level isolation layers is introduced to dynamically
generate reference features for the target views. Moreover, in order to
preserve the details of an original input image, we design a decoupled triple
attention mechanism, which can effectively align and integrate multi-branch
features into the synthesis process. Extensive experiments have demonstrated
that our UniView significantly improves novel view synthesis performance and
outperforms state-of-the-art methods on the challenging datasets.

</details>


### [35] [Efficient Video-to-Audio Generation via Multiple Foundation Models Mapper](https://arxiv.org/abs/2509.04957)
*Gehui Chen,Guan'an Wang,Xiaowen Huang,Jitao Sang*

Main category: cs.CV

TL;DR: MFM-Mapper通过双视觉编码器和GPT-2提升了V2A生成的效率和性能，训练成本仅为先前工作的16%。


<details>
  <summary>Details</summary>
Motivation: 现有V2A生成模型训练资源密集，且依赖基础模型的跨模态知识转移能力。MFM-Mapper旨在通过更丰富的语义和时间信息提升性能，同时降低训练成本。

Method: 引入Multiple Foundation Model Mapper (MFM-Mapper)，融合双视觉编码器的特征，并使用GPT-2替代线性映射器以改善特征对齐。

Result: MFM-Mapper在语义和时间一致性上表现更好，训练成本仅为先前工作的16%，且性能与更大规模训练的模型相当。

Conclusion: MFM-Mapper通过融合双视觉编码器的特征和使用GPT-2替代线性映射器，显著提升了训练效率和性能，在语义和时间一致性上表现优异，且训练成本仅为先前工作的16%。

Abstract: Recent Video-to-Audio (V2A) generation relies on extracting semantic and
temporal features from video to condition generative models. Training these
models from scratch is resource intensive. Consequently, leveraging foundation
models (FMs) has gained traction due to their cross-modal knowledge transfer
and generalization capabilities. One prior work has explored fine-tuning a
lightweight mapper network to connect a pre-trained visual encoder with a
text-to-audio generation model for V2A. Inspired by this, we introduce the
Multiple Foundation Model Mapper (MFM-Mapper). Compared to the previous mapper
approach, MFM-Mapper benefits from richer semantic and temporal information by
fusing features from dual visual encoders. Furthermore, by replacing a linear
mapper with GPT-2, MFM-Mapper improves feature alignment, drawing parallels
between cross-modal features mapping and autoregressive translation tasks. Our
MFM-Mapper exhibits remarkable training efficiency. It achieves better
performance in semantic and temporal consistency with fewer training consuming,
requiring only 16\% of the training scale compared to previous mapper-based
work, yet achieves competitive performance with models trained on a much larger
scale.

</details>


### [36] [Dual-Domain Perspective on Degradation-Aware Fusion: A VLM-Guided Robust Infrared and Visible Image Fusion Framework](https://arxiv.org/abs/2509.05000)
*Tianpei Zhang,Jufeng Zhao,Yiming Zhu,Guangmang Cui*

Main category: cs.CV

TL;DR: GD^2Fusion是一种结合视觉语言模型和双域优化的新框架，有效解决了双源退化场景下的图像融合问题。


<details>
  <summary>Details</summary>
Motivation: 现有红外-可见光图像融合方法假设输入为高质量，难以处理双源退化场景，且需要手动选择和顺序应用多个预增强步骤，导致错误累积和性能下降。

Method: 结合视觉语言模型（VLMs）进行退化感知，并采用双域（频率/空间）联合优化。具体包括GFMSE模块进行频域退化感知与抑制，以及GSMAF模块进行空间域跨模态退化过滤和自适应多源特征聚合。

Result: GD^2Fusion在双源退化场景中实现了优于现有算法和策略的融合性能。

Conclusion: GD^2Fusion框架在双源退化场景下表现出色，优于现有算法和策略。

Abstract: Most existing infrared-visible image fusion (IVIF) methods assume
high-quality inputs, and therefore struggle to handle dual-source degraded
scenarios, typically requiring manual selection and sequential application of
multiple pre-enhancement steps. This decoupled pre-enhancement-to-fusion
pipeline inevitably leads to error accumulation and performance degradation. To
overcome these limitations, we propose Guided Dual-Domain Fusion (GD^2Fusion),
a novel framework that synergistically integrates vision-language models (VLMs)
for degradation perception with dual-domain (frequency/spatial) joint
optimization. Concretely, the designed Guided Frequency Modality-Specific
Extraction (GFMSE) module performs frequency-domain degradation perception and
suppression and discriminatively extracts fusion-relevant sub-band features.
Meanwhile, the Guided Spatial Modality-Aggregated Fusion (GSMAF) module carries
out cross-modal degradation filtering and adaptive multi-source feature
aggregation in the spatial domain to enhance modality complementarity and
structural consistency. Extensive qualitative and quantitative experiments
demonstrate that GD^2Fusion achieves superior fusion performance compared with
existing algorithms and strategies in dual-source degraded scenarios. The code
will be publicly released after acceptance of this paper.

</details>


### [37] [Interpretable Deep Transfer Learning for Breast Ultrasound Cancer Detection: A Multi-Dataset Study](https://arxiv.org/abs/2509.05004)
*Mohammad Abbadi,Yassine Himeur,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: AI models, especially ResNet-18, outperform classical methods in breast cancer classification using ultrasound images, achieving high accuracy and interpretability, supporting clinical use.


<details>
  <summary>Details</summary>
Motivation: Breast cancer is a leading cause of mortality among women, and ultrasound imaging is widely used for early detection, especially in dense breast tissue. The study aims to improve classification accuracy using AI techniques.

Method: The study evaluates classical machine learning models (SVM, KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0, GoogLeNet) using datasets such as BUSI, BUS-BRA, and BrEaST-Lesions USG.

Result: ResNet-18 achieves the highest accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML models perform competitively when enhanced with deep feature extraction. Grad-CAM visualizations improve model transparency.

Conclusion: AI-based diagnostic tools, particularly deep learning models like ResNet-18, show high accuracy and interpretability for breast cancer detection in ultrasound images, supporting their integration into clinical workflows.

Abstract: Breast cancer remains a leading cause of cancer-related mortality among women
worldwide. Ultrasound imaging, widely used due to its safety and
cost-effectiveness, plays a key role in early detection, especially in patients
with dense breast tissue. This paper presents a comprehensive study on the
application of machine learning and deep learning techniques for breast cancer
classification using ultrasound images. Using datasets such as BUSI, BUS-BRA,
and BrEaST-Lesions USG, we evaluate classical machine learning models (SVM,
KNN) and deep convolutional neural networks (ResNet-18, EfficientNet-B0,
GoogLeNet). Experimental results show that ResNet-18 achieves the highest
accuracy (99.7%) and perfect sensitivity for malignant lesions. Classical ML
models, though outperformed by CNNs, achieve competitive performance when
enhanced with deep feature extraction. Grad-CAM visualizations further improve
model transparency by highlighting diagnostically relevant image regions. These
findings support the integration of AI-based diagnostic tools into clinical
workflows and demonstrate the feasibility of deploying high-performing,
interpretable systems for ultrasound-based breast cancer detection.

</details>


### [38] [Towards Efficient Pixel Labeling for Industrial Anomaly Detection and Localization](https://arxiv.org/abs/2509.05034)
*Jingqi Wu,Hanxi Li,Lin Yuanbo Wu,Hao Chen,Deyin Liu,Peng Wang*

Main category: cs.CV

TL;DR: ADClick和ADClick-Seg通过少量用户点击和文本描述生成像素级异常标注，显著提升工业异常检测性能，达到SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 工业产品检测通常仅使用无缺陷样本训练，缺陷样本的利用需要像素级标注，限制了可扩展性。

Method: 提出了ADClick，一种交互式图像分割算法，以及ADClick-Seg，一种跨模态框架，通过原型对齐视觉特征和文本提示。

Result: ADClick在MVTec AD上实现了96.1%的AP，ADClick-Seg在“多类”AD任务上达到了80.0%的AP、97.5%的PRO和99.1%的Pixel-AUROC。

Conclusion: ADClick和ADClick-Seg通过结合少量用户点击和文本描述，显著提升了工业异常检测的性能，并在MVTec AD数据集上达到了最先进的水平。

Abstract: Industrial product inspection is often performed using Anomaly Detection (AD)
frameworks trained solely on non-defective samples. Although defective samples
can be collected during production, leveraging them usually requires
pixel-level annotations, limiting scalability. To address this, we propose
ADClick, an Interactive Image Segmentation (IIS) algorithm for industrial
anomaly detection. ADClick generates pixel-wise anomaly annotations from only a
few user clicks and a brief textual description, enabling precise and efficient
labeling that significantly improves AD model performance (e.g., AP = 96.1\% on
MVTec AD). We further introduce ADClick-Seg, a cross-modal framework that
aligns visual features and textual prompts via a prototype-based approach for
anomaly detection and localization. By combining pixel-level priors with
language-guided cues, ADClick-Seg achieves state-of-the-art results on the
challenging ``Multi-class'' AD task (AP = 80.0\%, PRO = 97.5\%, Pixel-AUROC =
99.1\% on MVTec AD).

</details>


### [39] [A biologically inspired separable learning vision model for real-time traffic object perception in Dark](https://arxiv.org/abs/2509.05012)
*Hulin Li,Qiliang Ren,Jun Li,Hanbing Wei,Zheng Liu,Linfang Fan*

Main category: cs.CV

TL;DR: SLVM是一种生物启发框架，通过光适应性瞳孔机制和可分学习策略，显著提升低光照交通场景的感知性能，并发布大型数据集Dark-traffic。


<details>
  <summary>Details</summary>
Motivation: 解决低光照交通场景中现有感知模型适应性和准确性不足的问题，并填补大规模基准数据集的空白。

Method: SLVM整合了四个关键组件：光适应性瞳孔机制、特征级可分学习策略、任务特定解耦分支和空间错位感知融合模块。

Result: SLVM在Dark-traffic数据集上检测性能超过RT-DETR 11.2个百分点，实例分割超过YOLOv12 6.1个百分点，光流估计端点误差降低12.37%。在LIS基准上，SLVM平均超过Swin Transformer+EnlightenGAN和ConvNeXt-T+EnlightenGAN 11个百分点。

Conclusion: SLVM在低光照交通场景中表现出色，显著提升了物体检测、实例分割和光流估计的性能，同时减少了计算开销。Dark-traffic数据集的发布为相关研究提供了重要资源。

Abstract: Fast and accurate object perception in low-light traffic scenes has attracted
increasing attention. However, due to severe illumination degradation and the
lack of reliable visual cues, existing perception models and methods struggle
to quickly adapt to and accurately predict in low-light environments. Moreover,
there is the absence of available large-scale benchmark specifically focused on
low-light traffic scenes. To bridge this gap, we introduce a physically
grounded illumination degradation method tailored to real-world low-light
settings and construct Dark-traffic, the largest densely annotated dataset to
date for low-light traffic scenes, supporting object detection, instance
segmentation, and optical flow estimation. We further propose the Separable
Learning Vision Model (SLVM), a biologically inspired framework designed to
enhance perception under adverse lighting. SLVM integrates four key components:
a light-adaptive pupillary mechanism for illumination-sensitive feature
extraction, a feature-level separable learning strategy for efficient
representation, task-specific decoupled branches for multi-task separable
learning, and a spatial misalignment-aware fusion module for precise
multi-feature alignment. Extensive experiments demonstrate that SLVM achieves
state-of-the-art performance with reduced computational overhead. Notably, it
outperforms RT-DETR by 11.2 percentage points in detection, YOLOv12 by 6.1
percentage points in instance segmentation, and reduces endpoint error (EPE) of
baseline by 12.37% on Dark-traffic. On the LIS benchmark, the end-to-end
trained SLVM surpasses Swin Transformer+EnlightenGAN and
ConvNeXt-T+EnlightenGAN by an average of 11 percentage points across key
metrics, and exceeds Mask RCNN (with light enhancement) by 3.1 percentage
points. The Dark-traffic dataset and complete code is released at
https://github.com/alanli1997/slvm.

</details>


### [40] [Leveraging Transfer Learning and Mobile-enabled Convolutional Neural Networks for Improved Arabic Handwritten Character Recognition](https://arxiv.org/abs/2509.05019)
*Mohsine El Khayati,Ayyad Maafiri,Yassine Himeur,Hamzah Ali Alkhazaleh,Shadi Atalla,Wathiq Mansoor*

Main category: cs.CV

TL;DR: 研究通过迁移学习与轻量级移动卷积神经网络的结合，显著提升了阿拉伯手写字符识别的准确率和效率，MobileNet表现最佳，全微调策略最优。


<details>
  <summary>Details</summary>
Motivation: 解决阿拉伯手写字符识别中的高计算需求和数据集稀缺问题。

Method: 研究评估了三种TL策略（全微调、部分微调和从头训练）在四种轻量级MbNets（MobileNet、SqueezeNet、MnasNet和ShuffleNet）上的表现，并在三个基准数据集（AHCD、HIJJA和IFHCDB）上进行了实验。

Result: MobileNet表现最佳，IFHCDB数据集在MnasNet全微调下达到99%准确率，AHCD数据集在ShuffleNet下达到97%，HIJJA数据集因变异性挑战最高为92%。全微调整体表现最优。

Conclusion: 结合迁移学习（TL）与轻量级移动卷积神经网络（MbNets）在资源高效的阿拉伯手写字符识别（AHCR）中展现出巨大潜力，为未来优化和更广泛应用奠定了基础。

Abstract: The study explores the integration of transfer learning (TL) with
mobile-enabled convolutional neural networks (MbNets) to enhance Arabic
Handwritten Character Recognition (AHCR). Addressing challenges like extensive
computational requirements and dataset scarcity, this research evaluates three
TL strategies--full fine-tuning, partial fine-tuning, and training from
scratch--using four lightweight MbNets: MobileNet, SqueezeNet, MnasNet, and
ShuffleNet. Experiments were conducted on three benchmark datasets: AHCD,
HIJJA, and IFHCDB. MobileNet emerged as the top-performing model, consistently
achieving superior accuracy, robustness, and efficiency, with ShuffleNet
excelling in generalization, particularly under full fine-tuning. The IFHCDB
dataset yielded the highest results, with 99% accuracy using MnasNet under full
fine-tuning, highlighting its suitability for robust character recognition. The
AHCD dataset achieved competitive accuracy (97%) with ShuffleNet, while HIJJA
posed significant challenges due to its variability, achieving a peak accuracy
of 92% with ShuffleNet. Notably, full fine-tuning demonstrated the best overall
performance, balancing accuracy and convergence speed, while partial
fine-tuning underperformed across metrics. These findings underscore the
potential of combining TL and MbNets for resource-efficient AHCR, paving the
way for further optimizations and broader applications. Future work will
explore architectural modifications, in-depth dataset feature analysis, data
augmentation, and advanced sensitivity analysis to enhance model robustness and
generalizability.

</details>


### [41] [LUIVITON: Learned Universal Interoperable VIrtual Try-ON](https://arxiv.org/abs/2509.05030)
*Cong Cao,Xianhang Cheng,Jingyuan Liu,Yujian Zheng,Zhenhui Lin,Meriem Chkir,Hao Li*

Main category: cs.CV

TL;DR: LUIVITON 是一个自动化虚拟试衣系统，通过分解服装到身体的对应任务，结合几何学习和扩散模型，实现高效、高质量的3D服装覆盖。


<details>
  <summary>Details</summary>
Motivation: 解决复杂服装与多样化体型之间的对齐挑战，提供无需人工干预的高质量3D服装覆盖。

Method: 系统将服装到身体的覆盖问题分解为两个对应任务：1) 服装到SMPL的几何学习；2) 身体到SMPL的扩散模型。使用多视角一致的外观特征和预训练的2D基础模型。

Result: 系统能够处理复杂几何形状，适用于广泛的人形角色（如人类、机器人、卡通角色等），并支持服装尺寸和材质的快速定制。

Conclusion: LUIVITON 是一个高效、自动化的虚拟试衣系统，能够处理复杂几何形状和非流形网格，适用于多种人形角色，并在计算效率上保持实用性。

Abstract: We present LUIVITON, an end-to-end system for fully automated virtual try-on,
capable of draping complex, multi-layer clothing onto diverse and arbitrarily
posed humanoid characters. To address the challenge of aligning complex
garments with arbitrary and highly diverse body shapes, we use SMPL as a proxy
representation and separate the clothing-to-body draping problem into two
correspondence tasks: 1) clothing-to-SMPL and 2) body-to-SMPL correspondence,
where each has its unique challenges. While we address the clothing-to-SMPL
fitting problem using a geometric learning-based approach for
partial-to-complete shape correspondence prediction, we introduce a diffusion
model-based approach for body-to-SMPL correspondence using multi-view
consistent appearance features and a pre-trained 2D foundation model. Our
method can handle complex geometries, non-manifold meshes, and generalizes
effectively to a wide range of humanoid characters -- including humans, robots,
cartoon subjects, creatures, and aliens, while maintaining computational
efficiency for practical adoption. In addition to offering a fully automatic
fitting solution, LUIVITON supports fast customization of clothing size,
allowing users to adjust clothing sizes and material properties after they have
been draped. We show that our system can produce high-quality 3D clothing
fittings without any human labor, even when 2D clothing sewing patterns are not
available.

</details>


### [42] [COGITAO: A Visual Reasoning Framework To Study Compositionality & Generalization](https://arxiv.org/abs/2509.05249)
*Yassine Taoudi-Benchekroun,Klim Troyan,Pascal Sager,Stefan Gerber,Lukas Tuggener,Benjamin Grewe*

Main category: cs.CV

TL;DR: COGITAO是一个新的数据生成框架，用于研究视觉任务的组合性和泛化能力，揭示了当前模型在新组合任务上的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决当前机器学习模型在组合学习概念并应用于新环境方面的局限性。

Method: COGITAO构建基于规则的任务，这些任务在网格环境中应用一组变换。它支持28种可互操作的变换的组合，并允许对网格参数和对象属性进行广泛控制。

Result: 基线实验显示，最先进的视觉模型在将熟悉的元素组合到新环境中时表现不佳，尽管在领域内表现强劲。

Conclusion: COGITAO是一个模块化、可扩展的数据生成框架和基准测试，旨在系统地研究视觉领域的组合性和泛化能力。通过开源所有代码和数据集，它为这一领域的持续研究提供了支持。

Abstract: The ability to compose learned concepts and apply them in novel settings is
key to human intelligence, but remains a persistent limitation in
state-of-the-art machine learning models. To address this issue, we introduce
COGITAO, a modular and extensible data generation framework and benchmark
designed to systematically study compositionality and generalization in visual
domains. Drawing inspiration from ARC-AGI's problem-setting, COGITAO constructs
rule-based tasks which apply a set of transformations to objects in grid-like
environments. It supports composition, at adjustable depth, over a set of 28
interoperable transformations, along with extensive control over grid
parametrization and object properties. This flexibility enables the creation of
millions of unique task rules -- surpassing concurrent datasets by several
orders of magnitude -- across a wide range of difficulties, while allowing
virtually unlimited sample generation per rule. We provide baseline experiments
using state-of-the-art vision models, highlighting their consistent failures to
generalize to novel combinations of familiar elements, despite strong in-domain
performance. COGITAO is fully open-sourced, including all code and datasets, to
support continued research in this field.

</details>


### [43] [Systematic Review and Meta-analysis of AI-driven MRI Motion Artifact Detection and Correction](https://arxiv.org/abs/2509.05071)
*Mojtaba Safari,Zach Eidex,Richard L. J. Qiu,Matthew Goette,Tonghe Wang,Xiaofeng Yang*

Main category: cs.CV

TL;DR: AI驱动的DL生成模型在改善MRI运动伪影方面有潜力，但需解决泛化性、数据依赖和失真问题，未来需标准化数据集和更先进技术。


<details>
  <summary>Details</summary>
Motivation: 评估当前AI驱动方法在检测和校正MRI运动伪影方面的进展、有效性、挑战和未来研究方向。

Method: 进行了全面的系统综述和荟萃分析，重点关注深度学习（DL）方法，特别是生成模型，用于检测和校正MRI运动伪影。提取了有关使用的数据集、DL架构和性能指标的定量数据。

Result: DL，特别是生成模型，显示出减少运动伪影和改善图像质量的潜力；但泛化性有限、依赖配对训练数据以及视觉失真的风险仍是主要挑战，这促使需要标准化数据集和报告。

Conclusion: AI驱动的方法，特别是DL生成模型，在改善MRI图像质量方面显示出显著潜力，能有效解决运动伪影问题。然而，仍需解决关键挑战，包括需要全面的公共数据集、标准化的伪影水平报告协议以及更先进、适应性强的DL技术，以减少对大量配对数据集的依赖。解决这些问题可以显著提高MRI诊断准确性、降低医疗成本并改善患者护理效果。

Abstract: Background: To systematically review and perform a meta-analysis of
artificial intelligence (AI)-driven methods for detecting and correcting
magnetic resonance imaging (MRI) motion artifacts, assessing current
developments, effectiveness, challenges, and future research directions.
Methods: A comprehensive systematic review and meta-analysis were conducted,
focusing on deep learning (DL) approaches, particularly generative models, for
the detection and correction of MRI motion artifacts. Quantitative data were
extracted regarding utilized datasets, DL architectures, and performance
metrics. Results: DL, particularly generative models, show promise for reducing
motion artifacts and improving image quality; however, limited
generalizability, reliance on paired training data, and risk of visual
distortions remain key challenges that motivate standardized datasets and
reporting. Conclusions: AI-driven methods, particularly DL generative models,
show significant potential for improving MRI image quality by effectively
addressing motion artifacts. However, critical challenges must be addressed,
including the need for comprehensive public datasets, standardized reporting
protocols for artifact levels, and more advanced, adaptable DL techniques to
reduce reliance on extensive paired datasets. Addressing these aspects could
substantially enhance MRI diagnostic accuracy, reduce healthcare costs, and
improve patient care outcomes.

</details>


### [44] [GeoSplat: A Deep Dive into Geometry-Constrained Gaussian Splatting](https://arxiv.org/abs/2509.05075)
*Yangming Li,Chaoyu Liu,Lihao Liu,Simon Masnou,Carola-Bibian Schönlieb*

Main category: cs.CV

TL;DR: GeoSplat是一个利用高阶几何先验改进高斯溅射性能的框架，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 早期研究主要使用低阶几何先验（如法向量），且这些先验通过噪声敏感方法（如局部主成分分析）不可靠地估计，存在局限性。

Method: 提出了GeoSplat，一个通用的几何约束优化框架，利用一阶和二阶几何量改进高斯溅射的整个训练流程，包括高斯初始化、梯度更新和密集化。

Result: 在多个数据集的新视图合成任务中，GeoSplat显著提升了高斯溅射的性能，并优于之前的基线。

Conclusion: GeoSplat通过引入一阶和二阶几何量，显著提升了高斯溅射的性能，并在多个数据集的新视图合成任务中优于现有基线。

Abstract: A few recent works explored incorporating geometric priors to regularize the
optimization of Gaussian splatting, further improving its performance. However,
those early studies mainly focused on the use of low-order geometric priors
(e.g., normal vector), and they are also unreliably estimated by
noise-sensitive methods, like local principal component analysis. To address
their limitations, we first present GeoSplat, a general geometry-constrained
optimization framework that exploits both first-order and second-order
geometric quantities to improve the entire training pipeline of Gaussian
splatting, including Gaussian initialization, gradient update, and
densification. As an example, we initialize the scales of 3D Gaussian
primitives in terms of principal curvatures, leading to a better coverage of
the object surface than random initialization. Secondly, based on certain
geometric structures (e.g., local manifold), we introduce efficient and
noise-robust estimation methods that provide dynamic geometric priors for our
framework. We conduct extensive experiments on multiple datasets for novel view
synthesis, showing that our framework: GeoSplat, significantly improves the
performance of Gaussian splatting and outperforms previous baselines.

</details>


### [45] [WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool](https://arxiv.org/abs/2509.05296)
*Zizun Li,Jianjun Zhou,Yifan Wang,Haoyu Guo,Wenzheng Chang,Yang Zhou,Haoyi Zhu,Junyi Chen,Chunhua Shen,Tong He*

Main category: cs.CV

TL;DR: WinT3R是一种前馈重建模型，通过滑动窗口和紧凑相机表示，实现了高质量的在线相机姿态预测和点云重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在重建质量和实时性能之间的权衡问题。

Method: 引入滑动窗口机制确保帧间信息交换，并使用紧凑相机表示及全局相机令牌池。

Result: 在多样化数据集上验证了WinT3R的优越性能。

Conclusion: WinT3R通过滑动窗口机制和紧凑相机表示，实现了在线重建质量、相机姿态估计和重建速度的最先进性能。

Abstract: We present WinT3R, a feed-forward reconstruction model capable of online
prediction of precise camera poses and high-quality point maps. Previous
methods suffer from a trade-off between reconstruction quality and real-time
performance. To address this, we first introduce a sliding window mechanism
that ensures sufficient information exchange among frames within the window,
thereby improving the quality of geometric predictions without large
computation. In addition, we leverage a compact representation of cameras and
maintain a global camera token pool, which enhances the reliability of camera
pose estimation without sacrificing efficiency. These designs enable WinT3R to
achieve state-of-the-art performance in terms of online reconstruction quality,
camera pose estimation, and reconstruction speed, as validated by extensive
experiments on diverse datasets. Code and model are publicly available at
https://github.com/LiZizun/WinT3R.

</details>


### [46] [Scale-interaction transformer: a hybrid cnn-transformer model for facial beauty prediction](https://arxiv.org/abs/2509.05078)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: SIT模型结合CNN和Transformer，通过多尺度特征捕获和自注意力机制提升面部美感预测性能，在SCUT-FBP5500数据集上达到0.9187的Pearson Correlation。


<details>
  <summary>Details</summary>
Motivation: 由于影响人类感知的局部和全局面部特征的复杂相互作用，自动面部美感预测（FBP）是一项具有挑战性的计算机视觉任务。CNN虽然在特征提取方面表现出色，但通常在固定尺度上处理信息，可能忽略了不同粒度级别特征之间的关键相互依赖关系。

Method: 提出了一种新颖的混合深度学习架构——Scale-Interaction Transformer（SIT），结合CNN的特征提取能力和Transformer的关系建模能力。首先使用多尺度模块并行卷积捕获不同感受野的面部特征，然后将这些多尺度表示作为序列，由Transformer编码器通过自注意力机制处理它们的交互和上下文关系。

Result: 在广泛使用的SCUT-FBP5500基准数据集上进行了大量实验，SIT模型建立了新的最先进水平，Pearson Correlation达到0.9187，优于先前的方法。

Conclusion: SIT架构的成功突显了混合CNN-Transformer模型在需要整体、上下文感知理解的复杂图像回归任务中的潜力。

Abstract: Automated Facial Beauty Prediction (FBP) is a challenging computer vision
task due to the complex interplay of local and global facial features that
influence human perception. While Convolutional Neural Networks (CNNs) excel at
feature extraction, they often process information at a fixed scale,
potentially overlooking the critical inter-dependencies between features at
different levels of granularity. To address this limitation, we introduce the
Scale-Interaction Transformer (SIT), a novel hybrid deep learning architecture
that synergizes the feature extraction power of CNNs with the relational
modeling capabilities of Transformers. The SIT first employs a multi-scale
module with parallel convolutions to capture facial characteristics at varying
receptive fields. These multi-scale representations are then framed as a
sequence and processed by a Transformer encoder, which explicitly models their
interactions and contextual relationships via a self-attention mechanism. We
conduct extensive experiments on the widely-used SCUT-FBP5500 benchmark
dataset, where the proposed SIT model establishes a new state-of-the-art. It
achieves a Pearson Correlation of 0.9187, outperforming previous methods. Our
findings demonstrate that explicitly modeling the interplay between multi-scale
visual cues is crucial for high-performance FBP. The success of the SIT
architecture highlights the potential of hybrid CNN-Transformer models for
complex image regression tasks that demand a holistic, context-aware
understanding.

</details>


### [47] [Robust Experts: the Effect of Adversarial Training on CNNs with Sparse Mixture-of-Experts Layers](https://arxiv.org/abs/2509.05086)
*Svetlana Pavlitska,Haixi Fan,Konstantin Ditschuneit,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 通过稀疏MoE层和对抗训练提升CNN鲁棒性，发现路由崩溃使部分专家路径更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 提升CNN对抗攻击的鲁棒性，同时避免资源密集型对策。

Method: 在ResNet架构的深层阶段插入单个MoE层，结合对抗训练，评估其在PGD和AutoPGD攻击下的鲁棒性。

Result: 插入MoE层后，模型在对抗攻击下的鲁棒性得到一致提升，且发现路由崩溃现象导致部分专家路径更鲁棒。

Conclusion: 通过稀疏混合专家（MoE）层的引入，结合对抗训练，可以有效提升卷积神经网络（CNN）的鲁棒性，且不需增加推理成本。某些单独专家甚至优于门控MoE模型，表明鲁棒子路径通过专业化涌现。

Abstract: Robustifying convolutional neural networks (CNNs) against adversarial attacks
remains challenging and often requires resource-intensive countermeasures. We
explore the use of sparse mixture-of-experts (MoE) layers to improve robustness
by replacing selected residual blocks or convolutional layers, thereby
increasing model capacity without additional inference cost. On ResNet
architectures trained on CIFAR-100, we find that inserting a single MoE layer
in the deeper stages leads to consistent improvements in robustness under PGD
and AutoPGD attacks when combined with adversarial training. Furthermore, we
discover that when switch loss is used for balancing, it causes routing to
collapse onto a small set of overused experts, thereby concentrating
adversarial training on these paths and inadvertently making them more robust.
As a result, some individual experts outperform the gated MoE model in
robustness, suggesting that robust subpaths emerge through specialization. Our
code is available at https://github.com/KASTEL-MobilityLab/robust-sparse-moes.

</details>


### [48] [Semi-supervised Deep Transfer for Regression without Domain Alignment](https://arxiv.org/abs/2509.05092)
*Mainak Biswas,Ambedkar Dukkipati,Devarajan Sridharan*

Main category: cs.CV

TL;DR: CRAFT 是一种源自由、半监督的深度迁移学习方法，在回归任务中显著优于微调和现有方法，尤其在标记数据稀缺时表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实应用中，源模型在域偏移目标数据上泛化能力差，且源数据常因隐私或资源限制无法共享。此外，标记目标数据稀缺，预测涉及连续值输出。

Method: CRAFT 基于 Contradistinguisher (CUDA) 框架，通过正则化方法进行灵活训练，支持源自由、半监督的回归任务迁移。

Result: 在神经科学数据集（EEG 和 MRI）上，CRAFT 比微调模型在标记训练样本稀缺时 RMSE 提升高达 9%，并优于四种最先进的源自由域适应模型 3% 以上。

Conclusion: CRAFT 是一种高效的源自由、半监督深度迁移学习方法，适用于生物学和医学中普遍存在的回归任务。

Abstract: Deep learning models deployed in real-world applications (e.g., medicine)
face challenges because source models do not generalize well to domain-shifted
target data. Many successful domain adaptation (DA) approaches require full
access to source data. Yet, such requirements are unrealistic in scenarios
where source data cannot be shared either because of privacy concerns or
because it is too large and incurs prohibitive storage or computational costs.
Moreover, resource constraints may limit the availability of labeled targets.
We illustrate this challenge in a neuroscience setting where source data are
unavailable, labeled target data are meager, and predictions involve
continuous-valued outputs. We build upon Contradistinguisher (CUDA), an
efficient framework that learns a shared model across the labeled source and
unlabeled target samples, without intermediate representation alignment. Yet,
CUDA was designed for unsupervised DA, with full access to source data, and for
classification tasks. We develop CRAFT -- a Contradistinguisher-based
Regularization Approach for Flexible Training -- for source-free (SF),
semi-supervised transfer of pretrained models in regression tasks. We showcase
the efficacy of CRAFT in two neuroscience settings: gaze prediction with
electroencephalography (EEG) data and ``brain age'' prediction with structural
MRI data. For both datasets, CRAFT yielded up to 9% improvement in
root-mean-squared error (RMSE) over fine-tuned models when labeled training
examples were scarce. Moreover, CRAFT leveraged unlabeled target data and
outperformed four competing state-of-the-art source-free domain adaptation
models by more than 3%. Lastly, we demonstrate the efficacy of CRAFT on two
other real-world regression benchmarks. We propose CRAFT as an efficient
approach for source-free, semi-supervised deep transfer for regression that is
ubiquitous in biology and medicine.

</details>


### [49] [A Scalable Attention-Based Approach for Image-to-3D Texture Mapping](https://arxiv.org/abs/2509.05131)
*Arianna Rampini,Kanika Madan,Bruno Roy,AmirHossein Zamani,Derek Cheung*

Main category: cs.CV

TL;DR: 提出了一种基于transformer的快速3D纹理生成方法，无需UV映射，单次生成仅需0.2秒，效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法速度慢、依赖UV映射且难以忠实于参考图像，因此需要一种更高效、高质量的纹理生成方法。

Method: 提出了一种基于transformer的框架，直接从单张图像和网格预测3D纹理场，结合了三平面表示和基于深度的反向投影损失，实现了高效训练和快速推理。

Result: 该方法在单次前向传递中生成高保真纹理，每形状仅需0.2秒，且在输入图像忠实度和感知质量上均优于现有基线。

Conclusion: 该方法通过消除UV映射和可微分渲染的需求，实现了更快的纹理生成，并在单图像纹理重建方面优于现有基线，展示了其在可扩展、高质量和可控3D内容创建中的实用性。

Abstract: High-quality textures are critical for realistic 3D content creation, yet
existing generative methods are slow, rely on UV maps, and often fail to remain
faithful to a reference image. To address these challenges, we propose a
transformer-based framework that predicts a 3D texture field directly from a
single image and a mesh, eliminating the need for UV mapping and differentiable
rendering, and enabling faster texture generation. Our method integrates a
triplane representation with depth-based backprojection losses, enabling
efficient training and faster inference. Once trained, it generates
high-fidelity textures in a single forward pass, requiring only 0.2s per shape.
Extensive qualitative, quantitative, and user preference evaluations
demonstrate that our method outperforms state-of-the-art baselines on
single-image texture reconstruction in terms of both fidelity to the input
image and perceptual quality, highlighting its practicality for scalable,
high-quality, and controllable 3D content creation.

</details>


### [50] [SGS-3D: High-Fidelity 3D Instance Segmentation via Reliable Semantic Mask Splitting and Growing](https://arxiv.org/abs/2509.05144)
*Chaolei Wang,Yang Luo,Jing Du,Siyu Chen,Yiping Chen,Ting Han*

Main category: cs.CV

TL;DR: SGS-3D是一种无需训练的优化方法，通过结合语义和几何信息，有效提升了3D实例分割的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于2D到3D提升方法的3D实例分割由于在提升过程中引入的累积误差（如模糊的语义指导和不足的深度约束），难以实现精确的实例级分割。

Method: 提出了一种新颖的“先分割后生长”框架（SGS-3D），首先利用几何基元净化和分割模糊的2D提升掩码，随后在场景中将它们生长为完整的实例。

Result: 在ScanNet200、ScanNet++和KITTI-360上的实验结果表明，SGS-3D显著提高了分割准确性，并对预训练模型的不准确掩码表现出更强的鲁棒性。

Conclusion: SGS-3D 作为一种无需训练的优化方法，通过联合融合语义和几何信息，显著提高了3D实例分割的准确性和鲁棒性，并在多样化的室内外环境中保持了强大的泛化能力。

Abstract: Accurate 3D instance segmentation is crucial for high-quality scene
understanding in the 3D vision domain. However, 3D instance segmentation based
on 2D-to-3D lifting approaches struggle to produce precise instance-level
segmentation, due to accumulated errors introduced during the lifting process
from ambiguous semantic guidance and insufficient depth constraints. To tackle
these challenges, we propose splitting and growing reliable semantic mask for
high-fidelity 3D instance segmentation (SGS-3D), a novel "split-then-grow"
framework that first purifies and splits ambiguous lifted masks using geometric
primitives, and then grows them into complete instances within the scene.
Unlike existing approaches that directly rely on raw lifted masks and sacrifice
segmentation accuracy, SGS-3D serves as a training-free refinement method that
jointly fuses semantic and geometric information, enabling effective
cooperation between the two levels of representation. Specifically, for
semantic guidance, we introduce a mask filtering strategy that leverages the
co-occurrence of 3D geometry primitives to identify and remove ambiguous masks,
thereby ensuring more reliable semantic consistency with the 3D object
instances. For the geometric refinement, we construct fine-grained object
instances by exploiting both spatial continuity and high-level features,
particularly in the case of semantic ambiguity between distinct objects.
Experimental results on ScanNet200, ScanNet++, and KITTI-360 demonstrate that
SGS-3D substantially improves segmentation accuracy and robustness against
inaccurate masks from pre-trained models, yielding high-fidelity object
instances while maintaining strong generalization across diverse indoor and
outdoor environments. Code is available in the supplementary materials.

</details>


### [51] [SL-SLR: Self-Supervised Representation Learning for Sign Language Recognition](https://arxiv.org/abs/2509.05188)
*Ariel Basso Madjoukeng,Jérôme Fink,Pierre Poitier,Edith Belise Kenmogne,Benoit Frenay*

Main category: cs.CV

TL;DR: 论文提出了一种自监督学习框架，通过自由负对和新数据增强技术，解决了SLR中对比学习的两个关键问题，显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 由于标注数据稀缺，无监督方法如对比学习在SLR领域具有潜力。然而，现有方法存在两个问题：一是忽视视频中关键部分的差异，二是负对高度相似导致特征学习不具区分性。

Method: 框架包含两个关键组件：一种新的自监督学习方法（自由负对）和一种新的数据增强技术。

Result: 该方法在准确性上相比多种对比和自监督方法有显著提升。

Conclusion: 该论文提出的自监督学习框架在SLR任务中表现出色，显著提高了准确性，适用于线性评估、半监督学习和手语间的迁移学习。

Abstract: Sign language recognition (SLR) is a machine learning task aiming to identify
signs in videos. Due to the scarcity of annotated data, unsupervised methods
like contrastive learning have become promising in this field. They learn
meaningful representations by pulling positive pairs (two augmented versions of
the same instance) closer and pushing negative pairs (different from the
positive pairs) apart. In SLR, in a sign video, only certain parts provide
information that is truly useful for its recognition. Applying contrastive
methods to SLR raises two issues: (i) contrastive learning methods treat all
parts of a video in the same way, without taking into account the relevance of
certain parts over others; (ii) shared movements between different signs make
negative pairs highly similar, complicating sign discrimination. These issues
lead to learning non-discriminative features for sign recognition and poor
results in downstream tasks. In response, this paper proposes a self-supervised
learning framework designed to learn meaningful representations for SLR. This
framework consists of two key components designed to work together: (i) a new
self-supervised approach with free-negative pairs; (ii) a new data augmentation
technique. This approach shows a considerable gain in accuracy compared to
several contrastive and self-supervised methods, across linear evaluation,
semi-supervised learning, and transferability between sign languages.

</details>


### [52] [Symbolic Graphics Programming with Large Language Models](https://arxiv.org/abs/2509.05208)
*Yamei Chen,Haoquan Zhang,Yangyi Huang,Zeju Qiu,Kaipeng Zhang,Yandong Wen,Weiyang Liu*

Main category: cs.CV

TL;DR: 研究LLMs生成SVG的能力，提出RL方法提升性能，结果接近前沿系统。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在生成符号图形程序（SGPs）方面的能力，尤其是SVG，以理解LLMs如何通过生成图像来理解视觉世界。

Method: 引入SGP-GenBench基准测试，评估LLMs在生成SVG方面的能力，并提出一种结合强化学习（RL）和可验证奖励的方法，包括格式有效性门和跨模态奖励机制。

Result: 前沿专有模型在SGP-GenBench上显著优于开源模型，提出的RL方法显著提升了Qwen-2.5-7B生成SVG的质量和语义，性能接近前沿系统。

Conclusion: 符号图形编程（SGP）为跨模态接地提供了精确且可解释的视角，强化学习方法显著提升了LLMs生成SVG的能力，使其性能接近前沿系统。

Abstract: Large language models (LLMs) excel at program synthesis, yet their ability to
produce symbolic graphics programs (SGPs) that render into precise visual
content remains underexplored. We study symbolic graphics programming, where
the goal is to generate an SGP from a natural-language description. This task
also serves as a lens into how LLMs understand the visual world by prompting
them to generate images rendered from SGPs. Among various SGPs, our paper
sticks to scalable vector graphics (SVGs). We begin by examining the extent to
which LLMs can generate SGPs. To this end, we introduce SGP-GenBench, a
comprehensive benchmark covering object fidelity, scene fidelity, and
compositionality (attribute binding, spatial relations, numeracy). On
SGP-GenBench, we discover that frontier proprietary models substantially
outperform open-source models, and performance correlates well with general
coding capabilities. Motivated by this gap, we aim to improve LLMs' ability to
generate SGPs. We propose a reinforcement learning (RL) with verifiable rewards
approach, where a format-validity gate ensures renderable SVG, and a
cross-modal reward aligns text and the rendered image via strong vision
encoders (e.g., SigLIP for text-image and DINO for image-image). Applied to
Qwen-2.5-7B, our method substantially improves SVG generation quality and
semantics, achieving performance on par with frontier systems. We further
analyze training dynamics, showing that RL induces (i) finer decomposition of
objects into controllable primitives and (ii) contextual details that improve
scene coherence. Our results demonstrate that symbolic graphics programming
offers a precise and interpretable lens on cross-modal grounding.

</details>


### [53] [FlowSeek: Optical Flow Made Easier with Depth Foundation Models and Motion Bases](https://arxiv.org/abs/2509.05297)
*Matteo Poggi,Fabio Tosi*

Main category: cs.CV

TL;DR: FlowSeek 是一种高效的光流框架，仅需单个消费级 GPU 训练，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有光流方法对高硬件资源需求的限制，提供一种更高效的解决方案。

Method: 结合光学流网络设计、单图像深度基础模型和经典低维运动参数化，实现紧凑而精确的架构。

Result: 在 Sintel Final、KITTI、Spring 和 LayeredFlow 数据集上表现优异，相对 SEA-RAFT 提升 10% 和 15%。

Conclusion: FlowSeek 是一种新颖的光流框架，能够在资源有限的情况下实现高性能，显著优于现有方法。

Abstract: We present FlowSeek, a novel framework for optical flow requiring minimal
hardware resources for training. FlowSeek marries the latest advances on the
design space of optical flow networks with cutting-edge single-image depth
foundation models and classical low-dimensional motion parametrization,
implementing a compact, yet accurate architecture. FlowSeek is trained on a
single consumer-grade GPU, a hardware budget about 8x lower compared to most
recent methods, and still achieves superior cross-dataset generalization on
Sintel Final and KITTI, with a relative improvement of 10 and 15% over the
previous state-of-the-art SEA-RAFT, as well as on Spring and LayeredFlow
datasets.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [54] [Comparative Evaluation of Large Language Models for Test-Skeleton Generation](https://arxiv.org/abs/2509.04644)
*Subhang Boorlagadda,Nitya Naga Sai Atluri,Muhammet Mustafa Olmez,Edward F. Gehringer*

Main category: cs.SE

TL;DR: 研究评估了四种LLM生成RSpec测试骨架的能力，发现DeepSeek在可维护性和结构上表现最佳，而GPT-4更完整但不够一致，提示设计是关键。


<details>
  <summary>Details</summary>
Motivation: 传统手动编写测试骨架耗时且易出错，尤其在教育或大规模开发环境中，探索利用大型语言模型自动化生成测试骨架的可行性。

Method: 评估了四种大型语言模型（GPT-4、DeepSeek-Chat、Llama4-Maverick和Gemma2-9B）生成RSpec骨架的能力，通过静态分析和专家盲审来衡量结构正确性、清晰度、可维护性及测试最佳实践的符合程度。

Result: DeepSeek生成的骨架在可维护性和结构上最优，GPT-4的输出更完整但不够一致。提示设计和上下文输入对质量至关重要。

Conclusion: 研究表明，DeepSeek生成的测试骨架在可维护性和结构上表现最佳，而GPT-4的输出更完整但不够一致。提示设计和上下文输入是影响质量的关键因素。

Abstract: This paper explores the use of Large Language Models (LLMs) to automate the
generation of test skeletons -- structural templates that outline unit test
coverage without implementing full test logic. Test skeletons are especially
important in test-driven development (TDD), where they provide an early
framework for systematic verification. Traditionally authored manually, their
creation can be time-consuming and error-prone, particularly in educational or
large-scale development settings. We evaluate four LLMs -- GPT-4,
DeepSeek-Chat, Llama4-Maverick, and Gemma2-9B -- on their ability to generate
RSpec skeletons for a real-world Ruby class developed in a university software
engineering course. Each model's output is assessed using static analysis and a
blind expert review to measure structural correctness, clarity,
maintainability, and conformance to testing best practices. The study reveals
key differences in how models interpret code structure and testing conventions,
offering insights into the practical challenges of using LLMs for automated
test scaffolding. Our results show that DeepSeek generated the most
maintainable and well-structured skeletons, while GPT-4 produced more complete
but conventionally inconsistent output. The study reveals prompt design and
contextual input as key quality factors.

</details>


### [55] [Real-Time Performance Benchmarking of TinyML Models in Embedded Systems (PICO: Performance of Inference, CPU, and Operations)](https://arxiv.org/abs/2509.04721)
*Abhishek Dey,Saurabh Srivastava,Gaurav Singh,Robert G. Pettit*

Main category: cs.SE

TL;DR: 提出了一个平台无关的框架，用于基准测试TinyML模型在嵌入式系统上的性能，揭示了不同平台的关键性能权衡。


<details>
  <summary>Details</summary>
Motivation: 为了在资源受限的嵌入式系统上评估TinyML模型的实时性能，并提供计算权衡和平台特定优化的见解。

Method: 提出了PICO-TINYML-BENCHMARK框架，用于在资源受限的嵌入式系统上基准测试TinyML模型的实时性能。评估了推理延迟、CPU利用率、内存效率和预测稳定性等关键指标。

Result: BeagleBone AI64在AI特定任务上表现出一致的推理延迟，而Raspberry Pi 4在资源效率和成本效益方面表现更优。

Conclusion: 该研究为优化TinyML部署提供了实用指导，弥合了嵌入式系统中理论进展与实际应用之间的差距。

Abstract: This paper presents PICO-TINYML-BENCHMARK, a modular and platform-agnostic
framework for benchmarking the real-time performance of TinyML models on
resource-constrained embedded systems. Evaluating key metrics such as inference
latency, CPU utilization, memory efficiency, and prediction stability, the
framework provides insights into computational trade-offs and platform-specific
optimizations. We benchmark three representative TinyML models -- Gesture
Classification, Keyword Spotting, and MobileNet V2 -- on two widely adopted
platforms, BeagleBone AI64 and Raspberry Pi 4, using real-world datasets.
Results reveal critical trade-offs: the BeagleBone AI64 demonstrates consistent
inference latency for AI-specific tasks, while the Raspberry Pi 4 excels in
resource efficiency and cost-effectiveness. These findings offer actionable
guidance for optimizing TinyML deployments, bridging the gap between
theoretical advancements and practical applications in embedded systems.

</details>


### [56] [NovaQ: Improving Quantum Program Testing through Diversity-Guided Test Case Generation](https://arxiv.org/abs/2509.04763)
*Tiancheng Jin,Shangzhou Xia,Jianjun Zhao*

Main category: cs.SE

TL;DR: NovaQ是一种多样性引导的量子程序测试框架，通过生成多样化输入和评估行为新颖性，显著提升测试效果，检测更多错误。


<details>
  <summary>Details</summary>
Motivation: 随着量子计算的进步，确保量子程序的可靠性变得日益重要。NovaQ旨在通过多样性引导的测试框架，探索未充分测试的程序行为，从而提高量子程序的可靠性。

Method: NovaQ结合了一个分布式的测试用例生成器和一个新颖性驱动的评估模块。生成器通过变异电路参数生成多样化的量子状态输入，评估器则基于内部电路状态指标（如幅值、相位和纠缠）量化行为新颖性。

Result: 实验结果表明，NovaQ在不同规模和复杂度的量子程序上，均能实现更高的测试输入多样性，并检测出比现有基线方法更多的错误。

Conclusion: NovaQ作为一种多样性引导的量子程序测试框架，通过结合分布式的测试用例生成器和新颖性驱动的评估模块，有效提高了测试输入的多样性，并检测出更多错误，相比现有基线方法表现更优。

Abstract: Quantum programs are designed to run on quantum computers, leveraging quantum
circuits to solve problems that are intractable for classical machines. As
quantum computing advances, ensuring the reliability of quantum programs has
become increasingly important. This paper introduces NovaQ, a diversity-guided
testing framework for quantum programs. NovaQ combines a distribution-based
test case generator with a novelty-driven evaluation module. The generator
produces diverse quantum state inputs by mutating circuit parameters, while the
evaluator quantifies behavioral novelty based on internal circuit state
metrics, including magnitude, phase, and entanglement. By selecting inputs that
map to infrequently covered regions in the metric space, NovaQ effectively
explores under-tested program behaviors. We evaluate NovaQ on quantum programs
of varying sizes and complexities. Experimental results show that NovaQ
consistently achieves higher test input diversity and detects more bugs than
existing baseline approaches.

</details>


### [57] [Code Review Without Borders: Evaluating Synthetic vs. Real Data for Review Recommendation](https://arxiv.org/abs/2509.04810)
*Yogev Cohen,Dudi Ohayon,Romy Somkin,Yehudit Aperstein,Alexander Apartsin*

Main category: cs.SE

TL;DR: 利用LLM生成合成数据训练监督分类器，解决新兴语言中标注数据不足的问题，提升自动化代码审查能力。


<details>
  <summary>Details</summary>
Motivation: 新兴编程语言和框架的出现导致标注数据不足，难以训练监督模型进行代码审查分类。

Method: 利用LLM将代码变更从资源丰富的语言翻译为资源不足或新兴语言的等效变更，生成合成训练数据，并训练监督分类器。

Result: 实验表明，LLM生成的合成数据可以有效用于训练审查推荐系统，即使在资源匮乏的环境中也能缩小性能差距。

Conclusion: 该方法通过利用LLM生成合成数据，有效解决了新兴编程语言中标注数据不足的问题，为自动化代码审查系统提供了一种可扩展的解决方案。

Abstract: Automating the decision of whether a code change requires manual review is
vital for maintaining software quality in modern development workflows.
However, the emergence of new programming languages and frameworks creates a
critical bottleneck: while large volumes of unlabelled code are readily
available, there is an insufficient amount of labelled data to train supervised
models for review classification. We address this challenge by leveraging Large
Language Models (LLMs) to translate code changes from well-resourced languages
into equivalent changes in underrepresented or emerging languages, generating
synthetic training data where labelled examples are scarce. We assume that
although LLMs have learned the syntax and semantics of new languages from
available unlabelled code, they have yet to fully grasp which code changes are
considered significant or review-worthy within these emerging ecosystems. To
overcome this, we use LLMs to generate synthetic change examples and train
supervised classifiers on them. We systematically compare the performance of
these classifiers against models trained on real labelled data. Our experiments
across multiple GitHub repositories and language pairs demonstrate that
LLM-generated synthetic data can effectively bootstrap review recommendation
systems, narrowing the performance gap even in low-resource settings. This
approach provides a scalable pathway to extend automated code review
capabilities to rapidly evolving technology stacks, even in the absence of
annotated data.

</details>


### [58] [Integrating Large Language Models in Software Engineering Education: A Pilot Study through GitHub Repositories Mining](https://arxiv.org/abs/2509.04877)
*Maryam Khan,Muhammad Azeem Akbar,Jussi Kasurinen*

Main category: cs.SE

TL;DR: 该研究通过分析GitHub项目，验证了LLMs在SE教育中的动机和去动机因素，为未来框架开发提供了基础。


<details>
  <summary>Details</summary>
Motivation: 随着ChatGPT等大型语言模型（LLMs）在软件工程（SE）教育中的日益普及，需要系统研究以确保其负责任地融入课程。

Method: 通过进行一项试点存储库挖掘研究，分析了400个GitHub项目的README文件和问题讨论，以识别先前文献综述中合成的动机和去动机因素。

Result: 动机因素如参与度和动机（227次）、软件工程过程理解（133次）以及编程辅助和调试支持（97次）表现突出；去动机因素如抄袭和知识产权问题（385次）、安全、隐私和数据完整性（87次）以及学习中对AI的过度依赖（39次）也显著出现。

Conclusion: 该研究为动机/去动机分类学提供了早期实证验证，突出了研究与实践的差距，并为开发一个全面的框架以指导在SE教育中负责任地采用LLMs奠定了基础。

Abstract: Context: Large Language Models (LLMs) such as ChatGPT are increasingly
adopted in software engineering (SE) education, offering both opportunities and
challenges. Their adoption requires systematic investigation to ensure
responsible integration into curricula. Objective: This doctoral research aims
to develop a validated framework for integrating LLMs into SE education through
a multi-phase process, including taxonomies development, empirical
investigation, and case studies. This paper presents the first empirical step.
Method: We conducted a pilot repository mining study of 400 GitHub projects,
analyzing README files and issues discussions to identify the presence of
motivator and demotivator previously synthesized in our literature review [ 8]
study. Results: Motivators such as engagement and motivation (227 hits),
software engineering process understanding (133 hits), and programming
assistance and debugging support (97 hits) were strongly represented.
Demotivators, including plagiarism and IP concerns (385 hits), security,
privacy and data integrity (87 hits), and over-reliance on AI in learning (39
hits), also appeared prominently. In contrast, demotivators such as challenges
in evaluating learning outcomes and difficulty in curriculum redesign recorded
no hits across the repositories. Conclusion: The study provides early empirical
validation of motivators/demotivators taxonomies with respect to their themes,
highlights research practice gaps, and lays the foundation for developing a
comprehensive framework to guide the responsible adoption of LLMs in SE
education.

</details>


### [59] [FuzzRDUCC: Fuzzing with Reconstructed Def-Use Chain Coverage](https://arxiv.org/abs/2509.04967)
*Kai Feng,Jeremy Singer,Angelos K Marnerides*

Main category: cs.SE

TL;DR: FuzzRDUCC结合数据流分析和符号执行，有效提升模糊测试覆盖率，发现更多漏洞。


<details>
  <summary>Details</summary>
Motivation: 传统灰盒模糊测试主要依赖控制流边覆盖率，可能遗漏仅通过数据流分析才能暴露的漏洞。

Method: FuzzRDUCC框架利用符号执行从二进制可执行文件中重建定义-使用链，并通过新颖的启发式算法选择相关链，以减少计算开销。

Result: 在binutils基准测试中，FuzzRDUCC发现了其他先进模糊测试工具未检测到的独特崩溃。

Conclusion: FuzzRDUCC通过整合数据流分析和符号执行，显著提升了模糊测试的效果，能够发现传统方法遗漏的漏洞，为下一代漏洞检测机制提供了可行方案。

Abstract: Binary-only fuzzing often struggles with achieving thorough code coverage and
uncovering hidden vulnerabilities due to limited insight into a program's
internal dataflows. Traditional grey-box fuzzers guide test case generation
primarily using control flow edge coverage, which can overlook bugs not easily
exposed through control flow analysis alone. We argue that integrating dataflow
analysis into the fuzzing process can enhance its effectiveness by revealing
how data propagates through the program, thereby enabling the exploration of
execution paths that control flow-based methods might miss. In this context, we
introduce FuzzRDUCC, a novel fuzzing framework that employs symbolic execution
to reconstruct definition-use (def-use) chains directly from binary
executables. FuzzRDUCC identifies crucial dataflow paths and exposes security
vulnerabilities without incurring excessive computational overhead, due to a
novel heuristic algorithm that selects relevant def-use chains without
affecting the thoroughness of the fuzzing process. We evaluate FuzzRDUCC using
the binutils benchmark and demonstrate that it can identify unique crashes not
found by state-of-the-art fuzzers. Hence, establishing FuzzRDUCC as a feasible
solution for next generation vulnerability detection and discovery mechanisms.

</details>


### [60] [GenAI-based test case generation and execution in SDV platform](https://arxiv.org/abs/2509.05112)
*Denesa Zyberaj,Lukasz Mazur,Nenad Petrovic,Pankhuri Verma,Pascal Hirmer,Dirk Slama,Xiangwei Cheng,Alois Knoll*

Main category: cs.SE

TL;DR: 本文提出了一种GenAI驱动的测试用例生成方法，利用LLM和VLM转换需求为Gherkin测试用例，显著减少手动工作量，但仍需人工干预。


<details>
  <summary>Details</summary>
Motivation: 旨在通过自动化测试用例生成，减少手动测试规范的工作量，提高汽车子系统的兼容性，并简化与第三方测试工具的集成。

Method: 该方法利用大型语言模型和视觉语言模型将自然语言需求和系统图转换为结构化的Gherkin测试用例，并集成了车辆信号规范建模以标准化车辆信号定义。

Result: 在Child Presence Detection System用例中验证了该方法，展示了手动测试规范工作量的显著减少和生成测试的快速执行。

Conclusion: 尽管GenAI驱动的方法显著减少了手动测试规范的工作量，但由于GenAI管道的当前限制和digital.auto平台的约束，测试用例和脚本的生成仍需要人工干预。

Abstract: This paper introduces a GenAI-driven approach for automated test case
generation, leveraging Large Language Models and Vision-Language Models to
translate natural language requirements and system diagrams into structured
Gherkin test cases. The methodology integrates Vehicle Signal Specification
modeling to standardize vehicle signal definitions, improve compatibility
across automotive subsystems, and streamline integration with third-party
testing tools. Generated test cases are executed within the digital.auto
playground, an open and vendor-neutral environment designed to facilitate rapid
validation of software-defined vehicle functionalities. We evaluate our
approach using the Child Presence Detection System use case, demonstrating
substantial reductions in manual test specification effort and rapid execution
of generated tests. Despite significant automation, the generation of test
cases and test scripts still requires manual intervention due to current
limitations in the GenAI pipeline and constraints of the digital.auto platform.

</details>


### [61] [AI Agents for Web Testing: A Case Study in the Wild](https://arxiv.org/abs/2509.05197)
*Naimeng Ye,Xiao Yu,Ruize Xu,Tianyi Peng,Zhou Yu*

Main category: cs.SE

TL;DR: WebProber利用AI代理模拟用户行为进行网页测试，发现传统工具遗漏的可用性问题，展示了AI在测试中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统网页测试方法主要关注代码覆盖和负载测试，但难以捕捉复杂用户行为，导致许多可用性问题未被发现。

Method: WebProber是一个原型AI代理框架，通过模拟真实用户行为自动探索网站，识别错误和可用性问题，并生成可读报告。

Result: 在120个学术个人网站的案例研究中，WebProber发现了29个可用性问题，其中许多被传统工具遗漏。

Conclusion: WebProber展示了基于AI代理的网页测试框架的潜力，能够发现传统工具遗漏的可用性问题，为下一代以用户为中心的测试框架开发指明了方向。

Abstract: Automated web testing plays a critical role in ensuring high-quality user
experiences and delivering business value. Traditional approaches primarily
focus on code coverage and load testing, but often fall short of capturing
complex user behaviors, leaving many usability issues undetected. The emergence
of large language models (LLM) and AI agents opens new possibilities for web
testing by enabling human-like interaction with websites and a general
awareness of common usability problems. In this work, we present WebProber, a
prototype AI agent-based web testing framework. Given a URL, WebProber
autonomously explores the website, simulating real user interactions,
identifying bugs and usability issues, and producing a human-readable report.
We evaluate WebProber through a case study of 120 academic personal websites,
where it uncovered 29 usability issues--many of which were missed by
traditional tools. Our findings highlight agent-based testing as a promising
direction while outlining directions for developing next-generation,
user-centered testing frameworks.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [62] [The Ethical Compass of the Machine: Evaluating Large Language Models for Decision Support in Construction Project Management](https://arxiv.org/abs/2509.04505)
*Somtochukwu Azie,Yiping Meng*

Main category: cs.AI

TL;DR: 该研究评估了LLMs在建筑项目管理的伦理决策中的表现，发现其在结构化任务中表现尚可，但在复杂伦理情境中不足，建议将其作为辅助工具而非完全自主代理。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在建筑项目管理中高风险的伦理敏感决策环境中的伦理可行性和可靠性。

Method: 采用混合研究方法，包括使用新型伦理决策支持评估清单（EDSAC）对两种领先的LLMs进行定量性能测试，以及对12位行业专家的半结构化访谈进行定性分析。

Result: 研究发现LLMs在结构化领域（如法律合规）表现良好，但在处理上下文细微差别、确保责任和提供透明推理方面存在显著不足。行业专家对AI自主伦理判断持保留态度，强烈主张人机协同监督。

Conclusion: LLMs在建筑项目管理中作为决策支持工具时，目前最适合作为辅助而非自主伦理代理，需要强有力的人机协同监督。

Abstract: The integration of Artificial Intelligence (AI) into construction project
management (CPM) is accelerating, with Large Language Models (LLMs) emerging as
accessible decision-support tools. This study aims to critically evaluate the
ethical viability and reliability of LLMs when applied to the ethically
sensitive, high-risk decision-making contexts inherent in CPM. A mixed-methods
research design was employed, involving the quantitative performance testing of
two leading LLMs against twelve real-world ethical scenarios using a novel
Ethical Decision Support Assessment Checklist (EDSAC), and qualitative analysis
of semi-structured interviews with 12 industry experts to capture professional
perceptions. The findings reveal that while LLMs demonstrate adequate
performance in structured domains such as legal compliance, they exhibit
significant deficiencies in handling contextual nuance, ensuring
accountability, and providing transparent reasoning. Stakeholders expressed
considerable reservations regarding the autonomous use of AI for ethical
judgments, strongly advocating for robust human-in-the-loop oversight. To our
knowledge, this is one of the first studies to empirically test the ethical
reasoning of LLMs within the construction domain. It introduces the EDSAC
framework as a replicable methodology and provides actionable recommendations,
emphasising that LLMs are currently best positioned as decision-support aids
rather than autonomous ethical agents.

</details>


### [63] [Maestro: Joint Graph & Config Optimization for Reliable AI Agents](https://arxiv.org/abs/2509.04642)
*Wenxiao Wang,Priyatham Kattakinda,Soheil Feizi*

Main category: cs.AI

TL;DR: Maestro是一个联合优化图和配置的LLM代理框架，显著提升性能并解决结构性故障。


<details>
  <summary>Details</summary>
Motivation: 现有优化器仅调整配置而固定图结构，无法解决结构性故障模式。

Method: 引入Maestro，一个框架无关的整体优化器，联合搜索图和配置，利用反射性文本反馈优先编辑。

Result: 在IFBench和HotpotQA基准测试中，Maestro平均领先12%、4.9%和4.86%，且在应用场景中显示出显著优势。

Conclusion: Maestro框架通过联合搜索图和配置，显著提升了LLM代理的质量，并在多个基准测试中优于现有优化器。

Abstract: Building reliable LLM agents requires decisions at two levels: the graph
(which modules exist and how information flows) and the configuration of each
node (models, prompts, tools, control knobs). Most existing optimizers tune
configurations while holding the graph fixed, leaving structural failure modes
unaddressed. We introduce Maestro, a framework-agnostic holistic optimizer for
LLM agents that jointly searches over graphs and configurations to maximize
agent quality, subject to explicit rollout/token budgets. Beyond numeric
metrics, Maestro leverages reflective textual feedback from traces to
prioritize edits, improving sample efficiency and targeting specific failure
modes. On the IFBench and HotpotQA benchmarks, Maestro consistently surpasses
leading prompt optimizers--MIPROv2, GEPA, and GEPA+Merge--by an average of 12%,
4.9%, and 4.86%, respectively; even when restricted to prompt-only
optimization, it still leads by 9.65%, 2.37%, and 2.41%. Maestro achieves these
results with far fewer rollouts than GEPA. We further show large gains on two
applications (interviewer & RAG agents), highlighting that joint graph &
configuration search addresses structural failure modes that prompt tuning
alone cannot fix.

</details>


### [64] [Towards Personalized Explanations for Health Simulations: A Mixed-Methods Framework for Stakeholder-Centric Summarization](https://arxiv.org/abs/2509.04646)
*Philippe J. Giabbanelli,Ameeta Agrawal*

Main category: cs.AI

TL;DR: 该论文针对健康模拟模型解释的局限性，提出了一种混合方法框架，通过识别利益相关者需求并优化LLMs生成定制化解释，以提高模型的可访问性和实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管建模与仿真（M&S）方法在健康决策支持中具有潜力，但由于模型的复杂性，利益相关者难以充分利用这些模型。现有的LLM解释方法通常采用一刀切的摘要，无法满足不同利益相关者的多样化信息需求和风格偏好。

Method: 采用混合方法设计，首先通过问卷调查或访谈收集不同健康利益相关者的解释需求和风格偏好，然后优化LLMs的生成能力（如通过可控属性调整），最后通过多种指标评估以进一步改进定制化摘要的生成。

Result: 论文提出了一个系统化的框架，能够根据利益相关者的需求和偏好，生成定制化的健康模拟解释，从而提高了模型的可访问性和实用性。

Conclusion: 该论文提出了一种逐步框架，通过识别利益相关者的需求并指导LLMs生成定制的健康模拟解释，以解决当前模型解释的局限性。

Abstract: Modeling & Simulation (M&S) approaches such as agent-based models hold
significant potential to support decision-making activities in health, with
recent examples including the adoption of vaccines, and a vast literature on
healthy eating behaviors and physical activity behaviors. These models are
potentially usable by different stakeholder groups, as they support
policy-makers to estimate the consequences of potential interventions and they
can guide individuals in making healthy choices in complex environments.
However, this potential may not be fully realized because of the models'
complexity, which makes them inaccessible to the stakeholders who could benefit
the most. While Large Language Models (LLMs) can translate simulation outputs
and the design of models into text, current approaches typically rely on
one-size-fits-all summaries that fail to reflect the varied informational needs
and stylistic preferences of clinicians, policymakers, patients, caregivers,
and health advocates. This limitation stems from a fundamental gap: we lack a
systematic understanding of what these stakeholders need from explanations and
how to tailor them accordingly. To address this gap, we present a step-by-step
framework to identify stakeholder needs and guide LLMs in generating tailored
explanations of health simulations. Our procedure uses a mixed-methods design
by first eliciting the explanation needs and stylistic preferences of diverse
health stakeholders, then optimizing the ability of LLMs to generate tailored
outputs (e.g., via controllable attribute tuning), and then evaluating through
a comprehensive range of metrics to further improve the tailored generation of
summaries.

</details>


### [65] [An Approach to Grounding AI Model Evaluations in Human-derived Criteria](https://arxiv.org/abs/2509.04676)
*Sasha Mitts*

Main category: cs.AI

TL;DR: 本研究提出了一种通过人类评估标准增强AI基准测试的新方法，揭示了AI在解释和共情方面的不足，并提供了一个框架以实现更符合人类认知的AI评估。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的AI领域，传统基准测试可能无法全面捕捉AI模型的细微能力。我们专注于物理世界建模的案例，并提出了一种新方法，通过人类衍生的评估标准来增强现有基准测试，旨在提高模型行为的可解释性和适用性。

Method: 基于Perception Test和OpenEQA基准测试，我们进行了深入访谈和大规模调查，以识别对AI和人类推理都至关重要的关键认知技能，如优先级排序、记忆、辨别和情境化。

Result: 研究发现，参与者认为AI在解释和共情技能方面存在不足，但对AI性能抱有高期望。通过将研究发现融入基准设计，我们提出了一个框架，用于开发更符合人类认知的AI能力定义和测量方法。

Conclusion: 本研究强调了以用户为中心的人工智能评估的重要性，为研究人员和从业者提供了可操作的指南，旨在使AI能力与人类认知过程保持一致。我们的方法不仅增强了当前的基准测试实践，还为未来AI模型评估的进步奠定了基础。

Abstract: In the rapidly evolving field of artificial intelligence (AI), traditional
benchmarks can fall short in attempting to capture the nuanced capabilities of
AI models. We focus on the case of physical world modeling and propose a novel
approach to augment existing benchmarks with human-derived evaluation criteria,
aiming to enhance the interpretability and applicability of model behaviors.
Grounding our study in the Perception Test and OpenEQA benchmarks, we conducted
in-depth interviews and large-scale surveys to identify key cognitive skills,
such as Prioritization, Memorizing, Discerning, and Contextualizing, that are
critical for both AI and human reasoning. Our findings reveal that participants
perceive AI as lacking in interpretive and empathetic skills yet hold high
expectations for AI performance. By integrating insights from our findings into
benchmark design, we offer a framework for developing more human-aligned means
of defining and measuring progress. This work underscores the importance of
user-centered evaluation in AI development, providing actionable guidelines for
researchers and practitioners aiming to align AI capabilities with human
cognitive processes. Our approach both enhances current benchmarking practices
and sets the stage for future advancements in AI model evaluation.

</details>


### [66] [Language-Driven Hierarchical Task Structures as Explicit World Models for Multi-Agent Learning](https://arxiv.org/abs/2509.04731)
*Brennen Hill*

Main category: cs.AI

TL;DR: 本文主张通过语言模型动态生成层次化世界模型，以提升多智能体任务的训练效率，解决传统强化学习在复杂任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前语言模型和智能体模型的进展突出了显式世界模型开发的瓶颈，尤其在复杂长期多智能体任务中，如机器人足球，传统强化学习在高保真但结构扁平化的模拟器中难以应对探索空间和稀疏奖励的挑战。

Method: 通过层次化脚手架方法，将复杂目标分解为结构化的子目标，并结合符号化和层次化方法与多智能体强化学习（MARL），构建任务导向的世界模型。

Result: 基于2024年多智能体足球研究的系统综述，发现整合符号化与层次化方法的趋势显著，并提出了语言驱动的世界模型，为智能体学习提供了内在课程、密集学习信号和组合学习框架。

Conclusion: 本文提出了一种利用大型语言模型动态生成层次化世界模型的新范式，以解决复杂多智能体任务中的探索困难和稀疏奖励问题，从而更高效地训练具有战略行为的智能体。

Abstract: The convergence of Language models, Agent models, and World models represents
a critical frontier for artificial intelligence. While recent progress has
focused on scaling Language and Agent models, the development of sophisticated,
explicit World Models remains a key bottleneck, particularly for complex,
long-horizon multi-agent tasks. In domains such as robotic soccer, agents
trained via standard reinforcement learning in high-fidelity but
structurally-flat simulators often fail due to intractable exploration spaces
and sparse rewards. This position paper argues that the next frontier in
developing capable agents lies in creating environments that possess an
explicit, hierarchical World Model. We contend that this is best achieved
through hierarchical scaffolding, where complex goals are decomposed into
structured, manageable subgoals. Drawing evidence from a systematic review of
2024 research in multi-agent soccer, we identify a clear and decisive trend
towards integrating symbolic and hierarchical methods with multi-agent
reinforcement learning (MARL). These approaches implicitly or explicitly
construct a task-based world model to guide agent learning. We then propose a
paradigm shift: leveraging Large Language Models to dynamically generate this
hierarchical scaffold, effectively using language to structure the World Model
on the fly. This language-driven world model provides an intrinsic curriculum,
dense and meaningful learning signals, and a framework for compositional
learning, enabling Agent Models to acquire sophisticated, strategic behaviors
with far greater sample efficiency. By building environments with explicit,
language-configurable task layers, we can bridge the gap between low-level
reactive behaviors and high-level strategic team play, creating a powerful and
generalizable framework for training the next generation of intelligent agents.

</details>


### [67] [What-If Analysis of Large Language Models: Explore the Game World Using Proactive Thinking](https://arxiv.org/abs/2509.04791)
*Yuan Sui,Yanming Zhang,Yi Liao,Yu Gu,Guohua Tang,Zhongqian Sun,Wei Yang,Bryan Hooi*

Main category: cs.AI

TL;DR: WiA-LLM 通过整合假设分析和强化学习，赋予 LLMs 主动思考能力，显著提升了动态环境中的决策准确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在反应性信息处理方面表现出色，但缺乏系统性探索假设未来的能力，限制了其在动态高风险场景中的实用性。

Method: 提出 WiA-LLM 范式，结合假设分析（WIA）和强化学习，通过动态模拟潜在行动的结果，使模型能够预测未来状态。

Result: 在《王者荣耀》复杂游戏环境中，WiA-LLM 在预测游戏状态变化方面实现了 74.2% 的准确率（较基线提升两倍）。

Conclusion: WiA-LLM 通过整合假设分析（WIA）和强化学习，为大型语言模型（LLMs）提供了主动思考能力，显著提升了在动态环境中的决策能力，特别是在高难度场景下。

Abstract: Large language models (LLMs) excel at processing information reactively but
lack the ability to systemically explore hypothetical futures. They cannot ask,
"what if we take this action? how will it affect the final outcome" and
forecast its potential consequences before acting. This critical gap limits
their utility in dynamic, high-stakes scenarios like strategic planning, risk
assessment, and real-time decision making. To bridge this gap, we propose
WiA-LLM, a new paradigm that equips LLMs with proactive thinking capabilities.
Our approach integrates What-If Analysis (WIA), a systematic approach for
evaluating hypothetical scenarios by changing input variables. By leveraging
environmental feedback via reinforcement learning, WiA-LLM moves beyond
reactive thinking. It dynamically simulates the outcomes of each potential
action, enabling the model to anticipate future states rather than merely react
to the present conditions. We validate WiA-LLM in Honor of Kings (HoK), a
complex multiplayer game environment characterized by rapid state changes and
intricate interactions. The game's real-time state changes require precise
multi-step consequence prediction, making it an ideal testbed for our approach.
Experimental results demonstrate WiA-LLM achieves a remarkable 74.2% accuracy
in forecasting game-state changes (up to two times gain over baselines). The
model shows particularly significant gains in high-difficulty scenarios where
accurate foresight is critical. To our knowledge, this is the first work to
formally explore and integrate what-if analysis capabilities within LLMs.
WiA-LLM represents a fundamental advance toward proactive reasoning in LLMs,
providing a scalable framework for robust decision-making in dynamic
environments with broad implications for strategic applications.

</details>


### [68] [TalkToAgent: A Human-centric Explanation of Reinforcement Learning Agents with Large Language Models](https://arxiv.org/abs/2509.04809)
*Haechang Kim,Hao Chen,Can Li,Jong Min Lee*

Main category: cs.AI

TL;DR: TalkToAgent是一个多代理LLM框架，通过自然语言解释提升XRL透明度，验证显示其能高精度映射用户查询并有效解释代理行为。


<details>
  <summary>Details</summary>
Motivation: 当前XRL方法的可理解性有限且覆盖孤立，导致用户难以选择合适工具，TalkToAgent旨在通过交互式自然语言解释填补这一空白。

Method: 引入TalkToAgent框架，包含五个专用LLM代理（Coordinator、Explainer、Coder、Evaluator和Debugger），通过自动映射用户查询到相关XRL工具并提供自然语言解释。

Result: 在四重罐过程控制问题上的验证显示，TalkToAgent能高精度映射用户查询，并通过编码器-调试器交互最小化反事实生成失败。定性评估证实其能有效解释代理行为并上下文化其含义。

Conclusion: TalkToAgent通过多代理LLM框架有效提升了XRL的可解释性，能够准确映射用户查询并生成交互式自然语言解释，同时在反事实解释方面展现出创新性。

Abstract: Explainable Reinforcement Learning (XRL) has emerged as a promising approach
in improving the transparency of Reinforcement Learning (RL) agents. However,
there remains a gap between complex RL policies and domain experts, due to the
limited comprehensibility of XRL results and isolated coverage of current XRL
approaches that leave users uncertain about which tools to employ. To address
these challenges, we introduce TalkToAgent, a multi-agent Large Language Models
(LLM) framework that delivers interactive, natural language explanations for RL
policies. The architecture with five specialized LLM agents (Coordinator,
Explainer, Coder, Evaluator, and Debugger) enables TalkToAgent to automatically
map user queries to relevant XRL tools and clarify an agent's actions in terms
of either key state variables, expected outcomes, or counterfactual
explanations. Moreover, our approach extends previous counterfactual
explanations by deriving alternative scenarios from qualitative behavioral
descriptions, or even new rule-based policies. We validated TalkToAgent on
quadruple-tank process control problem, a well-known nonlinear control
benchmark. Results demonstrated that TalkToAgent successfully mapped user
queries into XRL tasks with high accuracy, and coder-debugger interactions
minimized failures in counterfactual generation. Furthermore, qualitative
evaluation confirmed that TalkToAgent effectively interpreted agent's actions
and contextualized their meaning within the problem domain.

</details>


### [69] [Collaboration and Conflict between Humans and Language Models through the Lens of Game Theory](https://arxiv.org/abs/2509.04847)
*Mukul Singh,Arjun Radhakrishna,Sumit Gulwani*

Main category: cs.AI

TL;DR: 研究发现语言模型在长期合作行为中表现优异，具备强合作特性且适应性强，为未来人机混合环境研究提供基础。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型在多党环境中的合作与竞争行为，尤其是长期互动、人机协作及行为模式演变。

Method: 在迭代囚徒困境（IPD）中，将基于模型的代理与240种经典策略进行Axelrod式比赛，并对行为进行分析。

Result: 语言模型表现与最佳经典策略相当甚至更优，具备强合作策略的关键特性（友善、可激怒、慷慨），并展示出快速适应对手策略变化的能力。

Conclusion: 研究首次系统性地描述了语言模型在长期合作行为中的表现，为未来研究其在更复杂的人机混合社会环境中的角色奠定了基础。

Abstract: Language models are increasingly deployed in interactive online environments,
from personal chat assistants to domain-specific agents, raising questions
about their cooperative and competitive behavior in multi-party settings. While
prior work has examined language model decision-making in isolated or
short-term game-theoretic contexts, these studies often neglect long-horizon
interactions, human-model collaboration, and the evolution of behavioral
patterns over time. In this paper, we investigate the dynamics of language
model behavior in the iterated prisoner's dilemma (IPD), a classical framework
for studying cooperation and conflict. We pit model-based agents against a
suite of 240 well-established classical strategies in an Axelrod-style
tournament and find that language models achieve performance on par with, and
in some cases exceeding, the best-known classical strategies. Behavioral
analysis reveals that language models exhibit key properties associated with
strong cooperative strategies - niceness, provocability, and generosity while
also demonstrating rapid adaptability to changes in opponent strategy mid-game.
In controlled "strategy switch" experiments, language models detect and respond
to shifts within only a few rounds, rivaling or surpassing human adaptability.
These results provide the first systematic characterization of long-term
cooperative behaviors in language model agents, offering a foundation for
future research into their role in more complex, mixed human-AI social
environments.

</details>


### [70] [Cloning a Conversational Voice AI Agent from Call\,Recording Datasets for Telesales](https://arxiv.org/abs/2509.04871)
*Krittanon Kaewtawee,Wachiravit Modecrua,Krittin Pachtrachai,Touchapon Kraisingkorn*

Main category: cs.AI

TL;DR: 论文提出了一种从通话录音克隆语音AI代理的方法，集成多种技术构建流式推理管道，评估显示AI在常规任务接近人类表现，但在复杂任务如说服上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 构建能够理解和生成实时人类对话的自主语音助手，以在客户服务和医疗保健等领域自动化重复任务、降低运营成本并提供全天候支持。

Method: 论文描述了一种从通话录音中克隆对话语音AI代理的通用方法，包括领域选择、知识提取和提示工程，集成了自动语音识别、基于大型语言模型的对话管理器和文本到语音合成。

Result: 盲测显示，AI代理在通话的常规方面接近人类表现，但在说服和异议处理方面表现不佳。

Conclusion: 论文总结了设计经验并提出了未来研究方向，包括大规模模拟和自动化评估。

Abstract: Recent advances in language and speech modelling have made it possible to
build autonomous voice assistants that understand and generate human dialogue
in real time. These systems are increasingly being deployed in domains such as
customer service and healthcare care, where they can automate repetitive tasks,
reduce operational costs, and provide constant support around the clock. In
this paper, we present a general methodology for cloning a conversational voice
AI agent from a corpus of call recordings. Although the case study described in
this paper uses telesales data to illustrate the approach, the underlying
process generalizes to any domain where call transcripts are available. Our
system listens to customers over the telephone, responds with a synthetic
voice, and follows a structured playbook learned from top performing human
agents. We describe the domain selection, knowledge extraction, and prompt
engineering used to construct the agent, integrating automatic speech
recognition, a large language model based dialogue manager, and text to speech
synthesis into a streaming inference pipeline. The cloned agent is evaluated
against human agents on a rubric of 22 criteria covering introduction, product
communication, sales drive, objection handling, and closing. Blind tests show
that the AI agent approaches human performance in routine aspects of the call
while underperforming in persuasion and objection handling. We analyze these
shortcomings and refine the prompt accordingly. The paper concludes with design
lessons and avenues for future research, including large scale simulation and
automated evaluation.

</details>


### [71] [OSC: Cognitive Orchestration through Dynamic Knowledge Alignment in Multi-Agent LLM Collaboration](https://arxiv.org/abs/2509.04876)
*Jusheng Zhang,Yijia Fan,Kaitong Cai,Xiaofei Sun,Keze Wang*

Main category: cs.AI

TL;DR: OSC是一个知识感知的自适应协作框架，通过CKM和实时认知分析提升多智能体系统的深度协作能力。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中专家智能体之间高效语言交互的瓶颈问题。

Method: 引入Collaborator Knowledge Models (CKM)，通过实时认知差距分析，智能体自适应调整通信行为。

Result: 实验表明，OSC显著提高了任务性能和通信效率，将‘并行工作的个体’转变为‘深度协作的认知团队’。

Conclusion: OSC框架不仅优化了多智能体协作，还为LLM智能体交互行为提供了新见解。

Abstract: This paper introduces OSC (Orchestrating Cognitive Synergy), a
knowledge-aware adaptive collaboration framework designed to enhance cognitive
synergy in multi-agent systems with large language models. While prior work has
advanced agent selection and result aggregation, efficient linguistic
interactions for deep collaboration among expert agents remain a critical
bottleneck. OSC addresses this gap as a pivotal intermediate layer between
selection and aggregation, introducing Collaborator Knowledge Models (CKM) to
enable each agent to dynamically perceive its collaborators' cognitive states.
Through real-time cognitive gap analysis, agents adaptively adjust
communication behaviors, including content focus, detail level, and expression
style, using learned strategies. Experiments on complex reasoning and
problem-solving benchmarks demonstrate that OSC significantly improves task
performance and communication efficiency, transforming "parallel-working
individuals'' into a "deeply collaborative cognitive team.'' This framework not
only optimizes multi-agent collaboration but also offers new insights into LLM
agent interaction behaviors.

</details>


### [72] [SparkUI-Parser: Enhancing GUI Perception with Robust Grounding and Parsing](https://arxiv.org/abs/2509.04908)
*Hongyi Jing,Jiafu Chen,Chen Rao,Ziqiang Dang,Jiajie Teng,Tianyi Chu,Juncheng Mo,Shuo Fang,Huaizhong Lin,Rui Lv,Chenguang Ma,Lei Zhao*

Main category: cs.AI

TL;DR: SparkUI-Parser通过连续坐标建模和拒绝机制，解决了现有MLLM在GUI感知中的精度和速度问题，并在多个测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在GUI感知中存在坐标离散建模导致精度低、推理慢，且无法解析整个界面的问题，限制了广泛应用。

Method: 提出SparkUI-Parser框架，采用预训练的多模态大语言模型（MLLM）结合令牌路由器和坐标解码器，进行连续坐标建模，并引入基于改进匈牙利匹配算法的拒绝机制。

Result: 在ScreenSpot、ScreenSpot-v2、CAGUI-Grounding和ScreenParse等基准测试中表现优于现有方法。

Conclusion: SparkUI-Parser通过连续坐标建模和改进的匈牙利匹配算法，显著提升了GUI感知的准确性和推理速度，并在多个基准测试中优于现有方法。

Abstract: The existing Multimodal Large Language Models (MLLMs) for GUI perception have
made great progress. However, the following challenges still exist in prior
methods: 1) They model discrete coordinates based on text autoregressive
mechanism, which results in lower grounding accuracy and slower inference
speed. 2) They can only locate predefined sets of elements and are not capable
of parsing the entire interface, which hampers the broad application and
support for downstream tasks. To address the above issues, we propose
SparkUI-Parser, a novel end-to-end framework where higher localization
precision and fine-grained parsing capability of the entire interface are
simultaneously achieved. Specifically, instead of using probability-based
discrete modeling, we perform continuous modeling of coordinates based on a
pre-trained Multimodal Large Language Model (MLLM) with an additional token
router and coordinate decoder. This effectively mitigates the limitations
inherent in the discrete output characteristics and the token-by-token
generation process of MLLMs, consequently boosting both the accuracy and the
inference speed. To further enhance robustness, a rejection mechanism based on
a modified Hungarian matching algorithm is introduced, which empowers the model
to identify and reject non-existent elements, thereby reducing false positives.
Moreover, we present ScreenParse, a rigorously constructed benchmark to
systematically assess structural perception capabilities of GUI models across
diverse scenarios. Extensive experiments demonstrate that our approach
consistently outperforms SOTA methods on ScreenSpot, ScreenSpot-v2,
CAGUI-Grounding and ScreenParse benchmarks. The resources are available at
https://github.com/antgroup/SparkUI-Parser.

</details>


### [73] [Towards Ontology-Based Descriptions of Conversations with Qualitatively-Defined Concepts](https://arxiv.org/abs/2509.04926)
*Barbara Gendron,Gaël Guibon,Mathieu D'aquin*

Main category: cs.AI

TL;DR: 本文提出了一种基于本体的方法，通过语言学描述符将定性对话特征定量化，并应用于LLM的熟练度控制，实验证明其提高了对话AI的透明度和一致性。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）作为对话代理时的可控性，特别是生成可预测且用户个性化的响应。

Method: 利用语言学描述符将定性概念定量化，构建本体进行推理和一致性检查，并通过微调指导LLM的受控文本生成。

Result: 实验结果表明，该方法提供了一致且可解释的熟练度定义，提升了对话AI的透明度。

Conclusion: 基于本体的方法能有效提升LLM在对话中的可控性和透明度，尤其是在熟练度控制方面。

Abstract: The controllability of Large Language Models (LLMs) when used as
conversational agents is a key challenge, particularly to ensure predictable
and user-personalized responses. This work proposes an ontology-based approach
to formally define conversational features that are typically qualitative in
nature. By leveraging a set of linguistic descriptors, we derive quantitative
definitions for qualitatively-defined concepts, enabling their integration into
an ontology for reasoning and consistency checking. We apply this framework to
the task of proficiency-level control in conversations, using CEFR language
proficiency levels as a case study. These definitions are then formalized in
description logic and incorporated into an ontology, which guides controlled
text generation of an LLM through fine-tuning. Experimental results demonstrate
that our approach provides consistent and explainable proficiency-level
definitions, improving transparency in conversational AI.

</details>


### [74] [Internet 3.0: Architecture for a Web-of-Agents with it's Algorithm for Ranking Agents](https://arxiv.org/abs/2509.04979)
*Rajesh Tembarai Krishnamachari,Srividya Rajesh*

Main category: cs.AI

TL;DR: DOVIS协议和AgentRank-UC算法通过隐私保护的使用性能聚合和动态排名，为构建可信的Agentic Web提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决AI代理在Web of Agents生态系统中缺乏透明、统一的性能排名机制的问题，以实现代理的选择不仅基于声明能力，还基于实际表现。

Method: 提出了DOVIS五层操作协议（发现、编排、验证、激励、语义）和AgentRank-UC算法，结合使用频率和性能指标（结果质量、成本、安全性、延迟）进行动态排名。

Result: 通过模拟实验和理论分析，证明了协调协议和性能感知排名的可行性，包括收敛性、鲁棒性和抗Sybil攻击能力。

Conclusion: DOVIS协议和AgentRank-UC算法为构建可扩展、可信的Agentic Web提供了可行的解决方案，通过协调协议和性能感知排名，实现了隐私保护和使用性能的统一。

Abstract: AI agents -- powered by reasoning-capable large language models (LLMs) and
integrated with tools, data, and web search -- are poised to transform the
internet into a \emph{Web of Agents}: a machine-native ecosystem where
autonomous agents interact, collaborate, and execute tasks at scale. Realizing
this vision requires \emph{Agent Ranking} -- selecting agents not only by
declared capabilities but by proven, recent performance. Unlike Web~1.0's
PageRank, a global, transparent network of agent interactions does not exist;
usage signals are fragmented and private, making ranking infeasible without
coordination.
  We propose \textbf{DOVIS}, a five-layer operational protocol
(\emph{Discovery, Orchestration, Verification, Incentives, Semantics}) that
enables the collection of minimal, privacy-preserving aggregates of usage and
performance across the ecosystem. On this substrate, we implement
\textbf{AgentRank-UC}, a dynamic, trust-aware algorithm that combines
\emph{usage} (selection frequency) and \emph{competence} (outcome quality,
cost, safety, latency) into a unified ranking. We present simulation results
and theoretical guarantees on convergence, robustness, and Sybil resistance,
demonstrating the viability of coordinated protocols and performance-aware
ranking in enabling a scalable, trustworthy Agentic Web.

</details>


### [75] [Sticker-TTS: Learn to Utilize Historical Experience with a Sticker-driven Test-Time Scaling Framework](https://arxiv.org/abs/2509.05007)
*Jie Chen,Jinhao Jiang,Yingqian Min,Zican Dong,Shijie Wang,Wayne Xin Zhao,Ji-Rong Wen*

Main category: cs.AI

TL;DR: Sticker-TTS通过历史经验利用和协作推理模型，提升了大型推理模型的效率和性能，在多个数学推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前测试时扩展方法依赖冗余采样，忽视了历史经验的利用，限制了计算效率。

Method: 提出了Sticker-TTS框架，通过协调三个协作的大型推理模型，迭代探索和优化解决方案，并引入了两阶段优化策略（模仿学习与自我改进结合）。

Result: 在三个数学推理基准测试（AIME-24、AIME-25、OlymMATH）中，Sticker-TTS在相同推理预算下超越了自洽和先进强化学习方法。

Conclusion: Sticker-TTS框架通过利用历史经验，显著提升了大型推理模型的计算效率和性能，证明了其有效性。

Abstract: Large reasoning models (LRMs) have exhibited strong performance on complex
reasoning tasks, with further gains achievable through increased computational
budgets at inference. However, current test-time scaling methods predominantly
rely on redundant sampling, ignoring the historical experience utilization,
thereby limiting computational efficiency. To overcome this limitation, we
propose Sticker-TTS, a novel test-time scaling framework that coordinates three
collaborative LRMs to iteratively explore and refine solutions guided by
historical attempts. At the core of our framework are distilled key
conditions-termed stickers-which drive the extraction, refinement, and reuse of
critical information across multiple rounds of reasoning. To further enhance
the efficiency and performance of our framework, we introduce a two-stage
optimization strategy that combines imitation learning with self-improvement,
enabling progressive refinement. Extensive evaluations on three challenging
mathematical reasoning benchmarks, including AIME-24, AIME-25, and OlymMATH,
demonstrate that Sticker-TTS consistently surpasses strong baselines, including
self-consistency and advanced reinforcement learning approaches, under
comparable inference budgets. These results highlight the effectiveness of
sticker-guided historical experience utilization. Our code and data are
available at https://github.com/RUCAIBox/Sticker-TTS.

</details>


### [76] [Finding your MUSE: Mining Unexpected Solutions Engine](https://arxiv.org/abs/2509.05072)
*Nir Sweed,Hanit Hakim,Ben Wolfson,Hila Lifshitz,Dafna Shahaf*

Main category: cs.AI

TL;DR: 本文提出功能性概念图（FCGs）和MUSE算法，帮助克服创新中的认知固定问题，并在50万项专利上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 创新者常因对现有解决方案或初步想法的认知固定而难以探索新替代方案，本文旨在解决这一问题。

Method: 提出了一种构建功能性概念图（FCGs）的方法论，并开发了MUSE算法，利用FCGs为给定问题生成创造性启发。

Result: 在50万项专利上计算并生成了大规模、高质量的FCGs，并公开发布供进一步研究。

Conclusion: 本文通过构建功能性概念图（FCGs）并提出MUSE算法，有效解决了创新者在认知上的固定性问题，为问题重构和类比启发提供了新方法。

Abstract: Innovators often exhibit cognitive fixation on existing solutions or nascent
ideas, hindering the exploration of novel alternatives. This paper introduces a
methodology for constructing Functional Concept Graphs (FCGs), interconnected
representations of functional elements that support abstraction, problem
reframing, and analogical inspiration. Our approach yields large-scale,
high-quality FCGs with explicit abstraction relations, overcoming limitations
of prior work. We further present MUSE, an algorithm leveraging FCGs to
generate creative inspirations for a given problem. We demonstrate our method
by computing an FCG on 500K patents, which we release for further research.

</details>


### [77] [ProToM: Promoting Prosocial Behaviour via Theory of Mind-Informed Feedback](https://arxiv.org/abs/2509.05091)
*Matteo Bortoletto,Yichao Zhou,Lance Ying,Tianmin Shu,Andreas Bulling*

Main category: cs.AI

TL;DR: ProToM是一个基于心理理论的AI系统，通过贝叶斯逆向规划和最大化预期效用提供针对性反馈，显著提升多智能体合作效率，优于现有大型语言和推理模型。


<details>
  <summary>Details</summary>
Motivation: 人类在追求独立目标时，如何识别协助和合作的时机及方式是一个挑战，阻碍了合作。为此，开发一个能提供有用反馈以促进亲社会行为的AI系统至关重要。

Method: ProToM采用贝叶斯逆向规划推断智能体目标，并通过最大化预期效用来选择反馈，以实现上下文敏感的促进亲社会行为。

Result: ProToM在Doors、Keys和Gems以及Overcooked等多智能体环境中表现优于基线模型，实现了更高的成功率、更短的任务完成时间，并受到人类用户的青睐。

Conclusion: ProToM通过提供有针对性和及时的反馈，在多智能体环境中显著提高了合作成功率，缩短了任务完成时间，并获得了人类用户的普遍偏好。

Abstract: While humans are inherently social creatures, the challenge of identifying
when and how to assist and collaborate with others - particularly when pursuing
independent goals - can hinder cooperation. To address this challenge, we aim
to develop an AI system that provides useful feedback to promote prosocial
behaviour - actions that benefit others, even when not directly aligned with
one's own goals. We introduce ProToM, a Theory of Mind-informed facilitator
that promotes prosocial actions in multi-agent systems by providing targeted,
context-sensitive feedback to individual agents. ProToM first infers agents'
goals using Bayesian inverse planning, then selects feedback to communicate by
maximising expected utility, conditioned on the inferred goal distribution. We
evaluate our approach against baselines in two multi-agent environments: Doors,
Keys, and Gems, as well as Overcooked. Our results suggest that
state-of-the-art large language and reasoning models fall short of
communicating feedback that is both contextually grounded and well-timed -
leading to higher communication overhead and task speedup. In contrast, ProToM
provides targeted and helpful feedback, achieving a higher success rate,
shorter task completion times, and is consistently preferred by human users.

</details>


### [78] [Evaluation and Comparison Semantics for ODRL](https://arxiv.org/abs/2509.05139)
*Jaime Osvaldo Salas,Paolo Pareti,Semih Yumuşak,Soulmaz Gheisari,Luis-Daniel Ibáñez,George Konstantinidis*

Main category: cs.AI

TL;DR: 本文为ODRL提出了一种基于查询回答的形式语义，填补了领域空白，并定义了策略比较问题，支持数据共享场景。


<details>
  <summary>Details</summary>
Motivation: 尽管ODRL已成为管理数字资源访问和使用的实际标准，但其全面形式语义仍缺失，影响了策略的评估和比较。

Method: 基于查询回答的形式语义方法，对ODRL语言进行形式化定义，并与最新发布的语言规范（2.2版）对齐。

Result: 提出了一种新的形式语义，改进了之前的定义，并在此基础上定义了策略比较问题，能够检测策略的等价性、限制性或宽松性。

Conclusion: 本文为ODRL提供了一种基于查询回答的简单直观的形式语义，填补了该领域全面形式语义的空白，并进一步定义了策略比较问题，为数据共享场景提供了理论支持。

Abstract: We consider the problem of evaluating, and comparing computational policies
in the Open Digital Rights Language (ODRL), which has become the de facto
standard for governing the access and usage of digital resources. Although
preliminary progress has been made on the formal specification of the
language's features, a comprehensive formal semantics of ODRL is still missing.
In this paper, we provide a simple and intuitive formal semantics for ODRL that
is based on query answering. Our semantics refines previous formalisations, and
is aligned with the latest published specification of the language (2.2).
Building on our evaluation semantics, and motivated by data sharing scenarios,
we also define and study the problem of comparing two policies, detecting
equivalent, more restrictive or more permissive policies.

</details>


### [79] [LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation](https://arxiv.org/abs/2509.05263)
*Yinglin Duan,Zhengxia Zou,Tongwei Gu,Wei Jia,Zhan Zhao,Luyi Xu,Xinzhu Liu,Hao Jiang,Kang Chen,Shuang Qiu*

Main category: cs.AI

TL;DR: LatticeWorld 是一个高效的3D世界生成框架，结合轻量级LLMs和渲染引擎，显著提升了工业生产的效率和创意质量。


<details>
  <summary>Details</summary>
Motivation: 为了缩小模拟与现实的差距并方便获取丰富的现实世界信息，研究探索了基于用户指令生成虚拟世界的现代方法。

Method: LatticeWorld 结合轻量级LLMs（如LLaMA-2-7B）和行业级渲染引擎（如Unreal Engine 5），通过多模态输入（文本描述和视觉指令）生成动态环境。

Result: 实验表明，LatticeWorld 在场景布局生成和视觉保真度上表现出色，工业生产效率提升了90倍以上。

Conclusion: LatticeWorld 提出了一种简单而有效的3D世界生成框架，显著提升了工业生产的效率，同时保持了高质量的创意输出。

Abstract: Recent research has been increasingly focusing on developing 3D world models
that simulate complex real-world scenarios. World models have found broad
applications across various domains, including embodied AI, autonomous driving,
entertainment, etc. A more realistic simulation with accurate physics will
effectively narrow the sim-to-real gap and allow us to gather rich information
about the real world conveniently. While traditional manual modeling has
enabled the creation of virtual 3D scenes, modern approaches have leveraged
advanced machine learning algorithms for 3D world generation, with most recent
advances focusing on generative methods that can create virtual worlds based on
user instructions. This work explores such a research direction by proposing
LatticeWorld, a simple yet effective 3D world generation framework that
streamlines the industrial production pipeline of 3D environments. LatticeWorld
leverages lightweight LLMs (LLaMA-2-7B) alongside the industry-grade rendering
engine (e.g., Unreal Engine 5) to generate a dynamic environment. Our proposed
framework accepts textual descriptions and visual instructions as multimodal
inputs and creates large-scale 3D interactive worlds with dynamic agents,
featuring competitive multi-agent interaction, high-fidelity physics
simulation, and real-time rendering. We conduct comprehensive experiments to
evaluate LatticeWorld, showing that it achieves superior accuracy in scene
layout generation and visual fidelity. Moreover, LatticeWorld achieves over a
$90\times$ increase in industrial production efficiency while maintaining high
creative quality compared with traditional manual production methods. Our demo
video is available at https://youtu.be/8VWZXpERR18

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [80] [NEXUS: Efficient and Scalable Multi-Cell mmWave Baseband Processing with Heterogeneous Compute](https://arxiv.org/abs/2509.04625)
*Zhenzhou Qi,Chung-Hsuan Tung,Zhihui Gao,Tingjun Chen*

Main category: cs.NI

TL;DR: NEXUS是首个在单服务器上实现实时虚拟化多小区毫米波基带处理的系统，通过软件和硬件加速结合，以及智能资源分配策略，显著提升了vRAN的效率和实用性。


<details>
  <summary>Details</summary>
Motivation: 5G NR的快速采用，特别是在毫米波频谱中，对基带处理的灵活性、可扩展性和效率提出了严格要求。虽然虚拟化RAN（vRANs）实现了跨小区的动态频谱共享，但在异构工作负载的多小区部署中，基带处理的资源分配仍未充分探索。

Method: NEXUS集成了基于软件的数字信号处理流水线与硬件加速的LDPC解码，并通过虚拟功能（VFs）在多个CPU核心间共享Intel的ACC100 eASIC。对于单小区操作，NEXUS采用基于随机森林（RAF）的模型预测最节能的资源分配；对于多小区场景，引入了一个功率感知调度器。

Result: NEXUS在单服务器上支持多达16个并发小区，在满负载下实现5.37Gbps的聚合吞吐量，同时将多小区调度搜索空间减少数个数量级。

Conclusion: NEXUS证明了虚拟化、资源感知的基带处理对于下一代vRAN系统既实用又高效。

Abstract: The rapid adoption of 5G New Radio (NR), particularly in the millimeter-wave
(mmWave) spectrum, imposes stringent demands on the flexibility, scalability,
and efficiency of baseband processing. While virtualized Radio Access Networks
(vRANs) enable dynamic spectrum sharing across cells, compute resource
allocation for baseband processing, especially in multi-cell deployments with
heterogeneous workloads, remains underexplored. In this paper, we present
NEXUS, the first system to realize real-time, virtualized multi-cell mmWave
baseband processing on a single server with heterogeneous compute resources.
NEXUS integrates software-based digital signal processing pipelines with
hardware-accelerated LDPC decoding, and introduces a novel framework for
sharing Intel's ACC100 eASIC across multiple CPU cores via virtual functions
(VFs). For single-cell operation, NEXUS employs a random forest (RAF)-based
model that predicts the most energy-efficient resource allocation for the given
cell configuration with microsecond-level inference latency and high accuracy.
For multi-cell scenarios, NEXUS introduces a power-aware scheduler that
incorporates a lightweight contention model to adjust resource allocation
strategies under concurrent execution. Through extensive evaluation across
various Frequency Range 2 (FR2) cell configurations, we show that NEXUS
supports up to 16 concurrent cells under full load, achieving 5.37Gbps
aggregate throughput, while reducing the multi-cell scheduling search space by
orders of magnitude. These results demonstrate that virtualized, resource-aware
baseband processing is both practical and efficient for next-generation vRAN
systems.

</details>


### [81] [Path Dynamics in a Deployed Path-Aware Network: A Measurement Study of SCIONLab](https://arxiv.org/abs/2509.04695)
*Lars Herschbach,Damien Rossi,Sina Keshvadi*

Main category: cs.NI

TL;DR: SCIONLab测试床的测量研究表明，多路径协议设计需考虑高变动性和路径不对称性，挑战现有假设。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于路径感知网络实际动态的实证数据，阻碍了有效协议的设计。

Method: 在SCIONLab全球测试床上进行纵向测量研究，分析路径稳定性、多样性和性能。

Result: 测量揭示了动态环境，包括显著的控制平面变动和短路径寿命，识别了路径差异现象，并发多路径传输在提高总吞吐量的同时可能降低单个路径的延迟和可靠性。

Conclusion: 协议设计需明确考虑高变动性和路径不对称性，挑战多路径协议设计的常见假设。

Abstract: Path-aware networks promise enhanced performance and resilience through
multipath transport, but a lack of empirical data on their real-world dynamics
hinders the design of effective protocols. This paper presents a longitudinal
measurement study of the SCION architecture on the global SCIONLab testbed,
characterizing the path stability, diversity, and performance crucial for
protocols like Multipath QUIC (MPQUIC). Our measurements reveal a dynamic
environment, with significant control-plane churn and short path lifetimes in
parts of the testbed. We identify and characterize path discrepancy, a
phenomenon where routing policies create asymmetric path availability between
endpoints. Furthermore, we observe a performance trade-off where concurrent
multipath transmissions can improve aggregate throughput but may degrade the
latency and reliability of individual paths. These findings demonstrate that
protocols such as MPQUIC should explicitly account for high churn and path
asymmetry, challenging common assumptions in multipath protocol design.

</details>


### [82] [Where Have All the Firewalls Gone? Security Consequences of Residential IPv6 Transition](https://arxiv.org/abs/2509.04792)
*Erik Rye,Dave Levin,Robert Beverly*

Main category: cs.NI

TL;DR: IPv6的普及使得住宅网络设备更易受攻击，可能助长物联网僵尸网络的扩散。


<details>
  <summary>Details</summary>
Motivation: 研究IPv4到IPv6的过渡是否使住宅网络更容易受到攻击，从而为下一代基于IPv6的物联网僵尸网络提供便利。

Method: 引入了一种适用于低资源物联网设备的大规模IPv6扫描方法，并进行了迄今为止最大规模的IPv6住宅网络测量，比较了IPv6和IPv4网络中可公开访问的设备。

Result: 测量结果显示，通过IPv6可以访问更多打印机、iPhone和智能灯等设备，验证了NAT作为互联网默认防火墙的重要性。

Conclusion: NAT在IPv4中起到了默认防火墙的作用，限制了对家庭设备的攻击。随着IPv6的普及，住宅网络不再依赖NAT，导致更多设备暴露在攻击风险下，可能助长基于IPv6的物联网僵尸网络的扩散。

Abstract: IPv4 NAT has limited the spread of IoT botnets considerably by
default-denying bots' incoming connection requests to in-home devices unless
the owner has explicitly allowed them. As the Internet transitions to majority
IPv6, however, residential connections no longer require the use of NAT. This
paper therefore asks: has the transition from IPv4 to IPv6 ultimately made
residential networks more vulnerable to attack, thereby empowering the next
generation of IPv6-based IoT botnets? To answer this question, we introduce a
large-scale IPv6 scanning methodology that, unlike those that rely on AI, can
be run on low-resource devices common in IoT botnets. We use this methodology
to perform the largest-scale measurement of IPv6 residential networks to date,
and compare which devices are publicly accessible to comparable IPv4 networks.
We were able to receive responses from 14.0M distinct IPv6 addresses inside of
residential networks (i.e., not the external-facing gateway), in 2,436 ASes
across 118 countries. These responses come from protocols commonly exploited by
IoT botnets (including telnet and FTP), as well as protocols typically
associated with end-user devices (including iPhone-Sync and IPP). Comparing to
IPv4, we show that we are able to reach more printers, iPhones, and smart
lights over IPv6 than full IPv4-wide scans could. Collectively, our results
show that NAT has indeed acted as the de facto firewall of the Internet, and
the v4-to-v6 transition of residential networks is opening up new devices to
attack.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [83] [Transitivity Preserving Projection in Directed Hypergraphs](https://arxiv.org/abs/2509.04543)
*Eric Parsonage,Matthew Roughan,Hung X Nguyen*

Main category: cs.DS

TL;DR: TPP 是一种高效的有向超图投影方法，通过最小化边集并保留关键传递关系，显著提升了可视化效果和计算效率。


<details>
  <summary>Details</summary>
Motivation: 有向超图在建模复杂多元关系时具有重要作用，但其复杂性常常阻碍有效的可视化和分析。现有方法如 BBP 不仅计算密集，还可能增加复杂性。

Method: 本文提出了一种新颖的 Transitivity Preserving Projection (TPP) 方法，利用 set-trie 数据结构开发高效算法，将计算复杂度从指数级降低到线性级。

Result: 实验结果表明，TPP 在性能上显著优于 BBP，能在几秒内完成投影，而 BBP 在相同图上无法在 24 小时内完成。

Conclusion: TPP 提供了一种最小化且完整的表示方法，显著提升了可视化效果，并保持了原始超图结构的完整性。

Abstract: Directed hypergraphs are vital for modeling complex polyadic relationships in
domains such as discrete mathematics, computer science, network security, and
systems modeling. However, their inherent complexity often impedes effective
visualization and analysis, particularly for large graphs. This paper
introduces a novel Transitivity Preserving Projection (TPP) to address the
limitations of the computationally intensive Basu and Blanning projection
(BBP), which can paradoxically increase complexity by flattening transitive
relationships. TPP offers a minimal and complete representation of
relationships within a chosen subset of elements, capturing only irreducible
dominant metapaths to ensure the smallest set of edges while preserving all
essential transitive and direct connections. This approach significantly
enhances visualization by reducing edge proliferation and maintains the
integrity of the original hypergraph's structure. We develop an efficient
algorithm leveraging the set-trie data structure, reducing the computational
complexity from an exponential number of metapath searches in BBP to a linear
number of metapath searches with polynomial-time filtering, enabling
scalability for real-world applications. Experimental results demonstrate TPP's
superior performance, completing projections in seconds on graphs where BBP
fails to terminate within 24 hours. By providing a minimal yet complete view of
relationships, TPP supports applications in network security and supply

</details>


### [84] [Additive, Near-Additive, and Multiplicative Approximations for APSP in Weighted Undirected Graphs: Trade-offs and Algorithms](https://arxiv.org/abs/2509.04640)
*Liam Roditty,Ariel Sapir*

Main category: cs.DS

TL;DR: 本文针对密集加权图提出新的APASP算法，改进近加性和乘法APASP性能，并突破理论限制。


<details>
  <summary>Details</summary>
Motivation: 解决密集加权图中APASP问题的计算效率限制，改进现有算法在近加性和乘法APASP中的性能，突破理论上的条件限制。

Method: 通过改进现有算法，提出了新的$+2\sum_{i=1}^{k+1}{W_i}$-APASP算法，并设计了近加性和乘法APASP的框架，结合条件限制的绕过技术。

Result: 提出了新的$+2\sum_{i=1}^{k+1}{W_i}$-APASP算法，改进了近加性和乘法APASP的运行时间和精度，突破了条件限制。

Conclusion: 本文提出了一种针对密集加权图的$+2\sum_{i=1}^{k+1}{W_i}$-APASP算法，改进了现有的稀疏图算法，并在近加性和乘法APASP方面提供了新的算法框架，突破了现有的条件限制。

Abstract: We present a $+2\sum_{i=1}^{k+1}{W_i}$-APASP algorithm for dense weighted
graphs with runtime $\tilde O\left(n^{2+\frac{1}{3k+2}}\right)$, where $W_{i}$
is the weight of an $i^\textnormal{th}$ heaviest edge on a shortest path. Dor,
Halperin and Zwick [FOCS'96, SICOMP'00] had two algorithms for the commensurate
unweighted $+2\cdot\left( k+1\right)$-APASP: $\tilde
O\left(n^{2-\frac{1}{k+2}}m^{\frac{1}{k+2}}\right)$ runtime for sparse graphs
and $\tilde O\left(n^{2+\frac{1}{3k+2}}\right)$ runtime for dense graphs. Cohen
and Zwick [SODA'97, JALG'01] adapted the sparse variant to weighted graphs:
$+2\sum_{i=1}^{k+1}{W_i}$-APASP algorithm in the same runtime. We show an
algorithm for dense weighted graphs.
  For \emph{nearly additive} APASP, we present a
$\left(1+\varepsilon,\min{\left\{2W_1,4W_{2}\right\}}\right)$-APASP algorithm
with $\tilde O\left(\left(\frac{1}{\varepsilon}\right)^{O\left(1\right)}\cdot
n^{2.15135313}\cdot\log W\right)$ runtime. This improves the
$\left(1+\varepsilon,2W_1\right)$-APASP of Saha and Ye [SODA'24].
  For multiplicative APASP, we show a framework of $\left(\frac{3\ell +4}{\ell
+ 2}+\varepsilon\right)$-APASP algorithms, reducing the runtime of Akav and
Roditty [ESA'21] for dense graphs and generalizing the
$\left(2+\varepsilon\right)$-APASP algorithm of Dory et al [SODA'24]. Our base
case is a $\left(\frac{7}{3}+\varepsilon\right)$-APASP in $\tilde
O\left(\left(\frac{1}{\varepsilon}\right)^{O\left(1\right)}\cdot
n^{2.15135313}\cdot \log W\right)$ runtime, improving the $\frac{7}{3}$-APASP
algorithm of Baswana and Kavitha [FOCS'06, SICOMP'10] for dense graphs.
  Finally, we "bypass" an $\tilde \Omega \left(n^\omega\right)$ conditional
lower bound by Dor, Halperin, and Zwick for $\alpha$-APASP with $\alpha < 2$,
by allowing an additive term (e.g.
$\paren{\frac{6k+3}{3k+2},\sum_{i=1}^{k+1}{W_{i}}}$-APASP in $\tilde
O\left(n^{2+\frac{1}{3k+2}}\right)$ runtime.).

</details>


### [85] [A 13/6-Approximation for Strip Packing via the Bottom-Left Algorithm](https://arxiv.org/abs/2509.04654)
*Stefan Hougardy,Bart Zondervan*

Main category: cs.DS

TL;DR: 论文提出新矩形排序方法，将Bottom-Left算法的近似比从3提升至13/6。


<details>
  <summary>Details</summary>
Motivation: 解决Strip Packing问题中Bottom-Left算法在45年来未能改进的近似比3的限制。

Method: 使用Bottom-Left算法，并引入新的矩形排序策略。

Result: 通过新排序方法，Bottom-Left算法的近似比提升至13/6。

Conclusion: 论文引入了一种新的矩形排序方法，使得Bottom-Left算法在Strip Packing问题中达到了13/6的近似比。

Abstract: In the Strip Packing problem, we are given a vertical strip of fixed width
and unbounded height, along with a set of axis-parallel rectangles. The task is
to place all rectangles within the strip, without overlaps, while minimizing
the height of the packing. This problem is known to be NP-hard. The Bottom-Left
Algorithm is a simple and widely used heuristic for Strip Packing. Given a
fixed order of the rectangles, it places them one by one, always choosing the
lowest feasible position in the strip and, in case of ties, the leftmost one.
Baker, Coffman, and Rivest proved in 1980 that the Bottom-Left Algorithm has
approximation ratio 3 if the rectangles are sorted by decreasing width. For the
past 45 years, no alternative ordering has been found that improves this bound.
We introduce a new rectangle ordering and show that with this ordering the
Bottom-Left Algorithm achieves a 13/6 approximation for the Strip Packing
problem.

</details>


### [86] [Parameterized Approximability for Modular Linear Equations](https://arxiv.org/abs/2509.04976)
*Konrad K. Dabrowski,Peter Jonsson,Sebastian Ordyniak,George Osipov,Magnus Wahlström*

Main category: cs.DS

TL;DR: 论文提出了一种参数化近似算法，可在2倍近似内解决Min-$2$-Lin$(Z_{p^n})$问题，并通过阴影移除策略确保解的质量。同时，排除了某些环上的常数因子近似可能性。


<details>
  <summary>Details</summary>
Motivation: Min-$r$-Lin$(Z_m)$问题在多项式时间内难以近似，因此研究参数化近似算法以提供更高效的解决方案。

Method: 通过逐步解决更严格的松弛问题，减少变量的可能取值范围，并构建特定图结构来识别解。使用基于阴影移除的策略确保解的质量和可行性。

Result: 证明了Min-$2$-Lin$(Z_{p^n})$可实现2倍FPT近似，并排除了某些环上的常数因子FPT近似可能性。

Conclusion: 论文证明了Min-$2$-Lin$(Z_{p^n})$在参数化近似算法下可实现2倍近似，并提出了基于松弛和阴影移除的策略。同时，对于某些环上的Min-$3$-Lin和Min-$2$-Lin问题，排除了常数因子FPT近似的可能性。

Abstract: We consider the Min-$r$-Lin$(Z_m)$ problem: given a system $S$ of length-$r$
linear equations modulo $m$, find $Z \subseteq S$ of minimum cardinality such
that $S-Z$ is satisfiable. The problem is NP-hard and UGC-hard to approximate
in polynomial time within any constant factor even when $r = m = 2$. We focus
on parameterized approximation with solution size as the parameter. Dabrowski
et al. showed that Min-$2$-Lin$(Z_m)$ is in FPT if $m$ is prime (i.e. $Z_m$ is
a field), and it is W[1]-hard if $m$ is not a prime power. We show that
Min-$2$-Lin$(Z_{p^n})$ is FPT-approximable within a factor of $2$ for every
prime $p$ and integer $n \geq 2$. This implies that Min-$2$-Lin$(Z_m)$, $m \in
Z^+$, is FPT-approximable within a factor of $2\omega(m)$ where $\omega(m)$
counts the number of distinct prime divisors of $m$. The idea behind the
algorithm is to solve ever tighter relaxations of the problem, decreasing the
set of possible values for the variables at each step. Working over $Z_{p^n}$
and viewing the values in base-$p$, one can roughly think of a relaxation as
fixing the number of trailing zeros and the least significant nonzero digits of
the values assigned to the variables. To solve the relaxed problem, we
construct a certain graph where solutions can be identified with a particular
collection of cuts. The relaxation may hide obstructions that will only become
visible in the next iteration of the algorithm, which makes it difficult to
find optimal solutions. To deal with this, we use a strategy based on shadow
removal to compute solutions that (1) cost at most twice as much as the optimum
and (2) allow us to reduce the set of values for all variables simultaneously.
We complement the algorithmic result with two lower bounds, ruling out
constant-factor FPT-approximation for Min-$3$-Lin$(R)$ over any nontrivial ring
$R$ and for Min-$2$-Lin$(R)$ over some finite commutative rings $R$.

</details>


### [87] [Graph Reconstruction with a Connected Components Oracle](https://arxiv.org/abs/2509.05002)
*Juha Harviainen,Pekka Parviainen*

Main category: cs.DS

TL;DR: 论文研究了利用连通组件查询的oracle解决Graph Reconstruction问题，提出了高效的随机算法并证明了理论下界。


<details>
  <summary>Details</summary>
Motivation: 研究不同oracle在GR问题中的能力，特别是在算法复杂度以查询次数衡量时的表现。

Method: 采用自适应随机算法，利用连通组件（CC）查询来重构隐藏图。

Result: 1. 对于具有n个顶点、m条边、最大度Δ和树宽k的隐藏图，GR可通过自适应随机算法在O(min{m, Δ², k²}·log n)次CC查询中解决。
2. 对于相同条件的隐藏图，任何算法都无法在o(min{m, Δ², k²})次CC查询内解决GR。

Conclusion: 该论文通过研究一种新型oracle（返回查询顶点子集诱导子图的连通组件集合），在Graph Reconstruction（GR）问题上取得了显著的算法和理论下界成果。

Abstract: In the Graph Reconstruction (GR) problem, the goal is to recover a hidden
graph by utilizing some oracle that provides limited access to the structure of
the graph. The interest is in characterizing how strong different oracles are
when the complexity of an algorithm is measured in the number of performed
queries. We study a novel oracle that returns the set of connected components
(CC) on the subgraph induced by the queried subset of vertices. Our main
contributions are as follows:
  1. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\Delta$,
and treewidth $k$, GR can be solved in $O(\min\{m, \Delta^2, k^2\} \cdot \log
n)$ CC queries by an adaptive randomized algorithm.
  2. For a hidden graph with $n$ vertices, $m$ edges, maximum degree $\Delta$,
and treewidth $k$, no algorithm can solve GR in $o(\min\{m, \Delta^2, k^2\})$
CC queries.

</details>


### [88] [On approximating the $f$-divergence between two Ising models](https://arxiv.org/abs/2509.05016)
*Weiming Feng,Yucheng Fu*

Main category: cs.DS

TL;DR: 研究了Ising模型中$f$-散度的近似问题，针对$\chi^\alpha$-散度提出算法和硬度结果，适用于多种$f$-散度类型。


<details>
  <summary>Details</summary>
Motivation: $f$-散度是衡量两个分布差异的基本概念，本文旨在扩展近期关于TV距离近似的研究，解决其在Ising模型中的应用问题。

Method: 给定两个Ising模型，通过其交互矩阵和外部场定义，研究如何在任意相对误差范围内近似$f$-散度，特别是针对$\chi^\alpha$-散度。

Result: 针对$\chi^\alpha$-散度，建立了算法和硬度结果，算法参数范围与硬度结果匹配，并可推广到其他$f$-散度。

Conclusion: 本文为$f$-散度在Ising模型中的近似问题提供了算法和硬度结果，适用于多种$f$-散度类型。

Abstract: The $f$-divergence is a fundamental notion that measures the difference
between two distributions. In this paper, we study the problem of approximating
the $f$-divergence between two Ising models, which is a generalization of
recent work on approximating the TV-distance. Given two Ising models $\nu$ and
$\mu$, which are specified by their interaction matrices and external fields,
the problem is to approximate the $f$-divergence $D_f(\nu\,\|\,\mu)$ within an
arbitrary relative error $\mathrm{e}^{\pm \varepsilon}$. For
$\chi^\alpha$-divergence with a constant integer $\alpha$, we establish both
algorithmic and hardness results. The algorithm works in a parameter regime
that matches the hardness result. Our algorithm can be extended to other
$f$-divergences such as $\alpha$-divergence, Kullback-Leibler divergence,
R\'enyi divergence, Jensen-Shannon divergence, and squared Hellinger distance.

</details>


### [89] [Testing Depth First Search Numbering](https://arxiv.org/abs/2509.05132)
*Artur Czumaj,Christian Sohler,Stefan Walzer*

Main category: cs.DS

TL;DR: 本文提出了一种新的有界度图模型变体，研究DFS遍历发现时间的属性测试问题，并给出了查询复杂度的上下界匹配结果。


<details>
  <summary>Details</summary>
Motivation: 研究在有界度图模型中引入顶点标签后，哪些编号方式可以在亚线性时间内被测试，特别是DFS遍历的发现时间。

Method: 通过在有界度图模型中引入顶点标签和额外的标签查询能力，开发了一个针对DFS遍历发现时间的属性测试算法，并分析了其查询复杂度。

Result: 提出了一个查询复杂度为$O(n^{1/3}/\varepsilon)$的DFS遍历发现时间测试算法，并对于常数$\varepsilon>0$给出了匹配的下界。

Conclusion: 本文提出了一个新的有界度图模型变体，通过引入顶点标签和额外的查询能力，研究了DFS遍历发现时间的属性测试问题，并给出了查询复杂度的上下界匹配结果。

Abstract: Property Testing is a formal framework to study the computational power and
complexity of sampling from combinatorial objects. A central goal in standard
graph property testing is to understand which graph properties are testable
with sublinear query complexity. Here, a graph property P is testable with a
sublinear query complexity if there is an algorithm that makes a sublinear
number of queries to the input graph and accepts with probability at least 2/3,
if the graph has property P, and rejects with probability at least 2/3 if it is
$\varepsilon$-far from every graph that has property P.
  In this paper, we introduce a new variant of the bounded degree graph model.
In this variant, in addition to the standard representation of a bounded degree
graph, we assume that every vertex $v$ has a unique label num$(v)$ from $\{1,
\dots, |V|\}$, and in addition to the standard queries in the bounded degree
graph model, we also allow a property testing algorithm to query for the label
of a vertex (but not for a vertex with a given label).
  Our new model is motivated by certain graph processes such as a DFS
traversal, which assign consecutive numbers (labels) to the vertices of the
graph. We want to study which of these numberings can be tested in sublinear
time. As a first step in understanding such a model, we develop a
\emph{property testing algorithm for discovery times of a DFS traversal} with
query complexity $O(n^{1/3}/\varepsilon)$ and for constant $\varepsilon>0$ we
give a matching lower bound.

</details>


### [90] [Efficient Contractions of Dynamic Graphs -- with Applications](https://arxiv.org/abs/2509.05157)
*Monika Henzinger,Evangelos Kosinas,Robin Münk,Harald Räcke*

Main category: cs.DS

TL;DR: 该论文提出了一种全动态图数据结构，支持快速生成非平凡最小割稀疏图，并应用于最小割仙人掌表示和最大k边连通子图计算，提升了效率和应用范围。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了在全动态图中高效维护和查询非平凡最小割稀疏图，以支持更广泛的应用，如最小割仙人掌表示和最大k边连通子图的计算。

Method: 论文采用简单的动态森林数据结构，实现了在查询时快速从头构建稀疏图。数据结构根据对手强度和所需时间界限类型提供不同的保证。

Result: 论文的主要结果包括：1）支持边插入/删除的快速操作；2）能够在查询时高效生成稀疏图；3）在自适应对手下构建最小割仙人表示的时间保证；4）改进的最大k边连通子图计算时间。

Conclusion: 该论文提出了一种灵活的数据结构，用于全动态图中高效生成非平凡最小割稀疏图，并展示了其在构建最小割仙人掌表示和计算最大k边连通子图中的应用。

Abstract: A non-trivial minimum cut (NMC) sparsifier is a multigraph $\hat{G}$ that
preserves all non-trivial minimum cuts of a given undirected graph $G$. We
introduce a flexible data structure for fully dynamic graphs that can
efficiently provide an NMC sparsifier upon request at any point during the
sequence of updates. We employ simple dynamic forest data structures to achieve
a fast from-scratch construction of the sparsifier at query time. Based on the
strength of the adversary and desired type of time bounds, the data structure
comes with different guarantees. Specifically, let $G$ be a fully dynamic
simple graph with $n$ vertices and minimum degree $\delta$. Then our data
structure supports an insertion/deletion of an edge to/from $G$ in $n^{o(1)}$
worst-case time. Furthermore, upon request, it can return w.h.p. an NMC
sparsifier of $G$ that has $O(n/\delta)$ vertices and $O(n)$ edges, in
$\hat{O}(n)$ time. The probabilistic guarantees hold against an adaptive
adversary. Alternatively, the update and query times can be improved to
$\tilde{O}(1)$ and $\tilde{O}(n)$ respectively, if amortized-time guarantees
are sufficient, or if the adversary is oblivious.
  We discuss two applications of our data structure. First, it can be used to
efficiently report a cactus representation of all minimum cuts of a fully
dynamic simple graph. Using the NMC sparsifier we can w.h.p. build this cactus
in worst-case time $\hat{O}(n)$ against an adaptive adversary. Second, our data
structure allows us to efficiently compute the maximal $k$-edge-connected
subgraphs of undirected simple graphs, by repeatedly applying a minimum cut
algorithm on the NMC sparsifier. Specifically, we can compute w.h.p. the
maximal $k$-edge-connected subgraphs of a simple graph with $n$ vertices and
$m$ edges in $\tilde{O}(m+n^2/k)$ time which is an improvement for $k =
\Omega(n^{1/8})$ and works for fully dynamic graphs.

</details>


### [91] [List Decoding Expander-Based Codes via Fast Approximation of Expanding CSPs: I](https://arxiv.org/abs/2509.05203)
*Fernando Granha Jeronimo,Aman Singh*

Main category: cs.DS

TL;DR: 本文提出了基于扩展图的代码构造的近似线性时间列表解码算法，适用于多种代码类型，展示了高效解码的可行性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决扩展图代码构造的高效列表解码问题，以应对不同代码类型和参数的需求。

Method: 通过将解码任务表述为扩展图上的协议CSP，并利用[Jer23]中的快速近似算法，基于弱正则分解[JST21,FK96]，实现对编码字的列表解码。

Result: 对于每种代码类型，均实现了在近似线性时间内的列表解码，且字母大小和列表大小具有不同的优化表现。

Conclusion: 本文提出了一种基于扩展图的代码构造的近似线性时间列表解码算法，适用于多种代码类型，包括Tanner LDPC码和AEL码。

Abstract: We present near-linear time list decoding algorithms (in the block-length
$n$) for expander-based code constructions. More precisely, we show that
  (i) For every $\delta \in (0,1)$ and $\epsilon > 0$, there is an explicit
family of good Tanner LDPC codes of (design) distance $\delta$ that is $(\delta
- \epsilon, O_\varepsilon(1))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size $O_\delta(1)$,
  (ii) For every $R \in (0,1)$ and $\epsilon > 0$, there is an explicit family
of AEL codes of rate $R$, distance $1-R -\varepsilon$ that is $(1-R-\epsilon,
O_\varepsilon(1))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size
$\text{exp}(\text{poly}(1/\epsilon))$, and
  (iii) For every $R \in (0,1)$ and $\epsilon > 0$, there is an explicit family
of AEL codes of rate $R$, distance $1-R-\varepsilon$ that is $(1-R-\epsilon,
O(1/\epsilon))$ list decodable in time
$\widetilde{\mathcal{O}}_{\varepsilon}(n)$ with alphabet size
$\text{exp}(\text{exp}(\text{poly}(1/\epsilon)))$ using recent near-optimal
list size bounds from [JMST25].
  Our results are obtained by phrasing the decoding task as an agreement CSP
[RWZ20,DHKNT19] on expander graphs and using the fast approximation algorithm
for $q$-ary expanding CSPs from [Jer23], which is based on weak regularity
decomposition [JST21,FK96]. Similarly to list decoding $q$-ary Ta-Shma's codes
in [Jer23], we show that it suffices to enumerate over assignments that are
constant in each part (of the constantly many) of the decomposition in order to
recover all codewords in the list.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [92] [In-Context Policy Adaptation via Cross-Domain Skill Diffusion](https://arxiv.org/abs/2509.04535)
*Minjong Yoo,Woo Kyung Kim,Honguk Woo*

Main category: cs.RO

TL;DR: ICPAD框架利用扩散技能学习技术，实现长时程多任务环境中的快速策略适应，尤其在有限数据条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对长时程多任务环境中策略快速适应的需求，特别是在无模型更新和有限目标领域数据的严格约束下。

Method: 采用跨领域技能扩散方案，学习领域无关的原型技能和领域基础的技能适配器，并通过动态领域提示方案增强上下文适应性能。

Result: 在Metaworld的机器人操作和CARLA的自动驾驶实验中，ICPAD框架在多种跨领域配置下表现出色。

Conclusion: ICPAD框架通过跨领域技能扩散和动态领域提示方案，在有限目标领域数据条件下实现了卓越的策略适应性能。

Abstract: In this work, we present an in-context policy adaptation (ICPAD) framework
designed for long-horizon multi-task environments, exploring diffusion-based
skill learning techniques in cross-domain settings. The framework enables rapid
adaptation of skill-based reinforcement learning policies to diverse target
domains, especially under stringent constraints on no model updates and only
limited target domain data. Specifically, the framework employs a cross-domain
skill diffusion scheme, where domain-agnostic prototype skills and a
domain-grounded skill adapter are learned jointly and effectively from an
offline dataset through cross-domain consistent diffusion processes. The
prototype skills act as primitives for common behavior representations of
long-horizon policies, serving as a lingua franca to bridge different domains.
Furthermore, to enhance the in-context adaptation performance, we develop a
dynamic domain prompting scheme that guides the diffusion-based skill adapter
toward better alignment with the target domain. Through experiments with
robotic manipulation in Metaworld and autonomous driving in CARLA, we show that
our $\oursol$ framework achieves superior policy adaptation performance under
limited target domain data conditions for various cross-domain configurations
including differences in environment dynamics, agent embodiment, and task
horizon.

</details>


### [93] [Action Chunking with Transformers for Image-Based Spacecraft Guidance and Control](https://arxiv.org/abs/2509.04628)
*Alejandro Posadas-Nava,Andrea Scorsoglio,Luca Ghilardi,Roberto Furfaro,Richard Linares*

Main category: cs.RO

TL;DR: 模仿学习方法ACT在航天器GNC任务中表现优于传统meta-RL，仅需少量数据即可实现高性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统元强化学习（meta-RL）在航天器GNC任务中需要大量交互数据的问题，提出一种更高效、数据需求更低的替代方案。

Method: 采用Action Chunking with Transformers (ACT)方法，将视觉和状态观察映射到推力和扭矩命令，生成更平滑、一致的轨迹。

Result: ACT在仅需100次专家演示（相当于6,300次环境交互）的情况下，实现了比基于40万次交互的meta-RL基线更高的准确性、更平滑的控制和更高的样本效率。

Conclusion: 该论文通过模仿学习方法（ACT）在有限的专家演示数据下，成功实现了航天器制导、导航与控制（GNC）的高性能表现，优于传统的元强化学习方法。

Abstract: We present an imitation learning approach for spacecraft guidance,
navigation, and control(GNC) that achieves high performance from limited data.
Using only 100 expert demonstrations, equivalent to 6,300 environment
interactions, our method, which implements Action Chunking with Transformers
(ACT), learns a control policy that maps visual and state observations to
thrust and torque commands. ACT generates smoother, more consistent
trajectories than a meta-reinforcement learning (meta-RL) baseline trained with
40 million interactions. We evaluate ACT on a rendezvous task: in-orbit docking
with the International Space Station (ISS). We show that our approach achieves
greater accuracy, smoother control, and greater sample efficiency.

</details>


### [94] [Planning from Point Clouds over Continuous Actions for Multi-object Rearrangement](https://arxiv.org/abs/2509.04645)
*Kallol Saha,Amber Li,Angela Rodriguez-Izquierdo,Lifan Yu,Ben Eisner,Maxim Likhachev,David Held*

Main category: cs.RO

TL;DR: SPOT是一种结合学习和规划的混合方法，用于在连续空间中规划机器人操作，优于传统策略学习。


<details>
  <summary>Details</summary>
Motivation: 解决传统任务规划方法需要离散化连续状态和动作空间的问题，提出在连续空间中直接规划。

Method: 提出了一种混合学习和规划的方法SPOT，利用学习模型作为领域先验，在部分观察的点云中搜索动作序列。

Result: 在模拟和真实环境中的多物体重排任务中，SPOT成功生成了有效的计划，并优于策略学习方法。

Conclusion: SPOT方法通过结合学习和规划，在连续高维动作空间中实现了有效的长时程规划，显著优于基于策略学习的方法。

Abstract: Long-horizon planning for robot manipulation is a challenging problem that
requires reasoning about the effects of a sequence of actions on a physical 3D
scene. While traditional task planning methods are shown to be effective for
long-horizon manipulation, they require discretizing the continuous state and
action space into symbolic descriptions of objects, object relationships, and
actions. Instead, we propose a hybrid learning-and-planning approach that
leverages learned models as domain-specific priors to guide search in
high-dimensional continuous action spaces. We introduce SPOT: Search over Point
cloud Object Transformations, which plans by searching for a sequence of
transformations from an initial scene point cloud to a goal-satisfying point
cloud. SPOT samples candidate actions from learned suggesters that operate on
partially observed point clouds, eliminating the need to discretize actions or
object relationships. We evaluate SPOT on multi-object rearrangement tasks,
reporting task planning success and task execution success in both simulation
and real-world environments. Our experiments show that SPOT generates
successful plans and outperforms a policy-learning approach. We also perform
ablations that highlight the importance of search-based planning.

</details>


### [95] [Surformer v2: A Multimodal Classifier for Surface Understanding from Touch and Vision](https://arxiv.org/abs/2509.04658)
*Manish Kansana,Sindhuja Penchala,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.RO

TL;DR: Surformer v2通过决策级融合优化视觉和触觉模态的分类性能，适用于实时机器人应用。


<details>
  <summary>Details</summary>
Motivation: 提升机器人操作和交互中的触觉感知能力，改进多模态分类架构。

Method: Surformer v2采用视觉分支（CNN-based classifier）和触觉分支（encoder-only transformer model），通过可学习的加权和对输出逻辑进行决策级融合。

Result: Surformer v2在Touch and Go数据集上表现良好，保持了适合实时机器人应用的推理速度。

Conclusion: Surformer v2通过决策级融合和基于变压器的触觉建模，有效提升了多模态机器人感知中的表面理解能力。

Abstract: Multimodal surface material classification plays a critical role in advancing
tactile perception for robotic manipulation and interaction. In this paper, we
present Surformer v2, an enhanced multi-modal classification architecture
designed to integrate visual and tactile sensory streams through a
late(decision level) fusion mechanism. Building on our earlier Surformer v1
framework [1], which employed handcrafted feature extraction followed by
mid-level fusion architecture with multi-head cross-attention layers, Surformer
v2 integrates the feature extraction process within the model itself and shifts
to late fusion. The vision branch leverages a CNN-based classifier(Efficient
V-Net), while the tactile branch employs an encoder-only transformer model,
allowing each modality to extract modality-specific features optimized for
classification. Rather than merging feature maps, the model performs
decision-level fusion by combining the output logits using a learnable weighted
sum, enabling adaptive emphasis on each modality depending on data context and
training dynamics. We evaluate Surformer v2 on the Touch and Go dataset [2], a
multi-modal benchmark comprising surface images and corresponding tactile
sensor readings. Our results demonstrate that Surformer v2 performs well,
maintaining competitive inference speed, suitable for real-time robotic
applications. These findings underscore the effectiveness of decision-level
fusion and transformer-based tactile modeling for enhancing surface
understanding in multi-modal robotic perception.

</details>


### [96] [Bootstrapping Reinforcement Learning with Sub-optimal Policies for Autonomous Driving](https://arxiv.org/abs/2509.04712)
*Zhihao Zhang,Chengyang Peng,Ekim Yurtsever,Keith A. Redmill*

Main category: cs.RO

TL;DR: 本研究提出了一种结合基于规则的换道控制器与SAC算法的方法，以解决RL驾驶代理在样本效率和探索方面的挑战，展示了改进的驾驶性能和扩展潜力。


<details>
  <summary>Details</summary>
Motivation: 自动化车辆控制使用强化学习（RL）因其通过环境交互学习驾驶策略的潜力而受到关注，但RL代理在样本效率和有效探索方面面临挑战，难以发现最优驾驶策略。

Method: 本研究提出了一种方法，通过将基于规则的换道控制器与Soft Actor Critic (SAC)算法集成，来增强RL驾驶代理的探索和学习效率。

Result: 研究结果表明，所提出的方法能够提高驾驶性能，并可以扩展到其他类似受益于基于演示指导的驾驶场景。

Conclusion: 通过将基于规则的换道控制器与SAC算法结合，本研究提出了一种增强RL驾驶代理探索和学习效率的方法，展示了改进的驾驶性能，并具有扩展到其他驾驶场景的潜力。

Abstract: Automated vehicle control using reinforcement learning (RL) has attracted
significant attention due to its potential to learn driving policies through
environment interaction. However, RL agents often face training challenges in
sample efficiency and effective exploration, making it difficult to discover an
optimal driving strategy. To address these issues, we propose guiding the RL
driving agent with a demonstration policy that need not be a highly optimized
or expert-level controller. Specifically, we integrate a rule-based lane change
controller with the Soft Actor Critic (SAC) algorithm to enhance exploration
and learning efficiency. Our approach demonstrates improved driving performance
and can be extended to other driving scenarios that can similarly benefit from
demonstration-based guidance.

</details>


### [97] [Hierarchical Reduced-Order Model Predictive Control for Robust Locomotion on Humanoid Robots](https://arxiv.org/abs/2509.04722)
*Adrian B. Ghansah,Sergio A. Esteban,Aaron D. Ames*

Main category: cs.RO

TL;DR: 论文提出了一种高效的分层控制框架，通过优化步态和上半身动态提升人形机器人的运动稳定性，实验验证了其在多样化环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人进入现实环境，确保其在多样化环境中的稳健运动成为关键挑战。

Method: 采用基于降阶模型的分层控制框架，高层使用ALIP模型进行非线性MPC优化步态参数，中层扩展SRB-MPC以纳入简化臂和躯干动态。

Result: 仿真和硬件实验表明，自适应步态时间将推恢复成功率提高36%，上半身控制增强了偏航扰动抑制能力，并在多种室内外地形中实现了稳健运动。

Conclusion: 该论文提出的分层控制框架显著提升了人形机器人在多样化环境中的运动稳定性，特别是在步态规划和上半身动态控制方面表现优异。

Abstract: As humanoid robots enter real-world environments, ensuring robust locomotion
across diverse environments is crucial. This paper presents a computationally
efficient hierarchical control framework for humanoid robot locomotion based on
reduced-order models -- enabling versatile step planning and incorporating arm
and torso dynamics to better stabilize the walking. At the high level, we use
the step-to-step dynamics of the ALIP model to simultaneously optimize over
step periods, step lengths, and ankle torques via nonlinear MPC. The ALIP
trajectories are used as references to a linear MPC framework that extends the
standard SRB-MPC to also include simplified arm and torso dynamics. We validate
the performance of our approach through simulation and hardware experiments on
the Unitree G1 humanoid robot. In the proposed framework the high-level step
planner runs at 40 Hz and the mid-level MPC at 500 Hz using the onboard
mini-PC. Adaptive step timing increased the push recovery success rate by 36%,
and the upper body control improved the yaw disturbance rejection. We also
demonstrate robust locomotion across diverse indoor and outdoor terrains,
including grass, stone pavement, and uneven gym mats.

</details>


### [98] [Imitation Learning Based on Disentangled Representation Learning of Behavioral Characteristics](https://arxiv.org/abs/2509.04737)
*Ryoga Oishi,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出一种运动生成模型，通过弱监督学习将修饰指令映射到动作，实现在线调整，优于传统批量方法。


<details>
  <summary>Details</summary>
Motivation: 在机器人学习中，通过语言指令协调动作是可行的，但适应人类指令仍然具有挑战性，因为这些指令通常是定性的，需要探索满足不同条件的行为。

Method: 通过将演示分割为短序列，并为特定修饰类型分配弱监督标签，学习从修饰指令到动作的映射。

Result: 在擦拭和抓取放置任务中的评估表明，该方法能够在线调整动作以响应修饰指令。

Conclusion: 该论文提出的运动生成模型能够在线调整机器人动作以响应修饰指令，相比传统批量处理方法具有更好的适应性。

Abstract: In the field of robot learning, coordinating robot actions through language
instructions is becoming increasingly feasible. However, adapting actions to
human instructions remains challenging, as such instructions are often
qualitative and require exploring behaviors that satisfy varying conditions.
This paper proposes a motion generation model that adapts robot actions in
response to modifier directives human instructions imposing behavioral
conditions during task execution. The proposed method learns a mapping from
modifier directives to actions by segmenting demonstrations into short
sequences, assigning weakly supervised labels corresponding to specific
modifier types. We evaluated our method in wiping and pick and place tasks.
Results show that it can adjust motions online in response to modifier
directives, unlike conventional batch-based methods that cannot adapt during
execution.

</details>


### [99] [COMMET: A System for Human-Induced Conflicts in Mobile Manipulation of Everyday Tasks](https://arxiv.org/abs/2509.04836)
*Dongping Li,Shaoting Peng,John Pohovey,Katherine Rose Driggs-Campbell*

Main category: cs.RO

TL;DR: COMMET系统通过混合检测和用户偏好总结，解决了家庭机器人中的人机冲突问题，初步效果优于GPT模型。


<details>
  <summary>Details</summary>
Motivation: 动态和不可预测的人类活动会导致与机器人行为的冲突，且这些冲突的解决方案因用户偏好而异，需要一种高效的系统来处理。

Method: 采用混合检测方法，包括多模态检索和微调模型推理，结合GPT-4o总结用户偏好。

Result: 初步研究表明，检测模块在准确性和延迟方面优于GPT模型，并设计了用户友好的数据收集界面。

Conclusion: COMMET系统通过混合检测方法和用户偏好总结，有效解决了家庭机器人中的人机冲突问题，并展示了在实际部署中的高效工作流程。

Abstract: Continuous advancements in robotics and AI are driving the integration of
robots from industry into everyday environments. However, dynamic and
unpredictable human activities in daily lives would directly or indirectly
conflict with robot actions. Besides, due to the social attributes of such
human-induced conflicts, solutions are not always unique and depend highly on
the user's personal preferences. To address these challenges and facilitate the
development of household robots, we propose COMMET, a system for human-induced
COnflicts in Mobile Manipulation of Everyday Tasks. COMMET employs a hybrid
detection approach, which begins with multi-modal retrieval and escalates to
fine-tuned model inference for low-confidence cases. Based on collected user
preferred options and settings, GPT-4o will be used to summarize user
preferences from relevant cases. In preliminary studies, our detection module
shows better accuracy and latency compared with GPT models. To facilitate
future research, we also design a user-friendly interface for user data
collection and demonstrate an effective workflow for real-world deployments.

</details>


### [100] [A Knowledge-Driven Diffusion Policy for End-to-End Autonomous Driving Based on Expert Routing](https://arxiv.org/abs/2509.04853)
*Chengkai Xu,Jiaqi Liu,Yicheng Guo,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: KDP结合扩散模型和专家路由机制，显著提升了自动驾驶的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态动作生成、时间稳定性保持和多样化场景泛化方面存在不足，KDP旨在解决这些问题。

Method: KDP采用生成扩散模型和稀疏混合专家路由机制，扩散模型生成时间一致且多模态的动作序列，专家路由机制根据上下文激活专用且可复用的专家。

Result: 实验表明，KDP在多种驾驶场景中实现了更高的成功率、更低的碰撞风险和更平滑的控制，消融研究验证了稀疏专家激活和Transformer架构的有效性。

Conclusion: KDP通过结合扩散模型和专家路由机制，为端到端自动驾驶提供了一个可扩展且可解释的范式，显著提高了成功率、降低了碰撞风险并实现了更平滑的控制。

Abstract: End-to-end autonomous driving remains constrained by the need to generate
multi-modal actions, maintain temporal stability, and generalize across diverse
scenarios. Existing methods often collapse multi-modality, struggle with
long-horizon consistency, or lack modular adaptability. This paper presents
KDP, a knowledge-driven diffusion policy that integrates generative diffusion
modeling with a sparse mixture-of-experts routing mechanism. The diffusion
component generates temporally coherent and multi-modal action sequences, while
the expert routing mechanism activates specialized and reusable experts
according to context, enabling modular knowledge composition. Extensive
experiments across representative driving scenarios demonstrate that KDP
achieves consistently higher success rates, reduced collision risk, and
smoother control compared to prevailing paradigms. Ablation studies highlight
the effectiveness of sparse expert activation and the Transformer backbone, and
activation analyses reveal structured specialization and cross-scenario reuse
of experts. These results establish diffusion with expert routing as a scalable
and interpretable paradigm for knowledge-driven end-to-end autonomous driving.

</details>


### [101] [Towards an Accurate and Effective Robot Vision (The Problem of Topological Localization for Mobile Robots)](https://arxiv.org/abs/2509.04948)
*Emanuela Boros*

Main category: cs.RO

TL;DR: 该论文研究了在办公室环境中仅使用彩色相机图像进行拓扑定位的方法，评估了多种视觉描述符，并展示了合理配置的优势。


<details>
  <summary>Details</summary>
Motivation: 视觉定位和地点识别由于感知模糊性、传感器噪声和光照变化而具有挑战性。

Method: 我们评估了包括颜色直方图、SIFT、ASIFT、RGB-SIFT和基于文本检索启发的Bag-of-Visual-Words方法在内的先进视觉描述符。

Result: 结果表明，适当配置外观描述符、相似性度量和分类器具有优势。这些配置的质量在ImageCLEF评估活动的机器人视觉任务中进一步验证。

Conclusion: 未来工作将探索分层模型、排名方法和特征组合，以构建更鲁棒的定位系统，减少训练和运行时间，同时避免维度灾难。最终目标是实现跨不同光照条件和更长路线的集成实时定位。

Abstract: Topological localization is a fundamental problem in mobile robotics, since
robots must be able to determine their position in order to accomplish tasks.
Visual localization and place recognition are challenging due to perceptual
ambiguity, sensor noise, and illumination variations. This work addresses
topological localization in an office environment using only images acquired
with a perspective color camera mounted on a robot platform, without relying on
temporal continuity of image sequences. We evaluate state-of-the-art visual
descriptors, including Color Histograms, SIFT, ASIFT, RGB-SIFT, and
Bag-of-Visual-Words approaches inspired by text retrieval. Our contributions
include a systematic, quantitative comparison of these features, distance
measures, and classifiers. Performance was analyzed using standard evaluation
metrics and visualizations, extending previous experiments. Results demonstrate
the advantages of proper configurations of appearance descriptors, similarity
measures, and classifiers. The quality of these configurations was further
validated in the Robot Vision task of the ImageCLEF evaluation campaign, where
the system identified the most likely location of novel image sequences. Future
work will explore hierarchical models, ranking methods, and feature
combinations to build more robust localization systems, reducing training and
runtime while avoiding the curse of dimensionality. Ultimately, this aims
toward integrated, real-time localization across varied illumination and longer
routes.

</details>


### [102] [Ground-Aware Octree-A* Hybrid Path Planning for Memory-Efficient 3D Navigation of Ground Vehicles](https://arxiv.org/abs/2509.04950)
*Byeong-Il Ham,Hyun-Bin Kim,Kyung-Soo Kim*

Main category: cs.RO

TL;DR: 提出了一种结合A*算法和八叉树结构的3D路径规划方法，利用可穿越障碍物辅助运动，显著提高了计算效率和内存使用。


<details>
  <summary>Details</summary>
Motivation: 无人地面车辆和腿式机器人的发展使得障碍物不仅被视为需要避免的阻碍，还可以在有利时作为导航辅助。

Method: 提出了一种结合A*算法和八叉树结构的3D路径规划方法，通过在成本函数中加入基于高度的惩罚，利用可穿越障碍物辅助运动。

Result: 基准测试结果表明，该方法在保证路径最优的同时，显著减少了内存使用和计算时间。

Conclusion: 结合八叉树结构的3D A*算法在保证路径最优的同时，显著减少了内存使用和计算时间，支持实际环境中的实时路径规划。

Abstract: In this paper, we propose a 3D path planning method that integrates the A*
algorithm with the octree structure. Unmanned Ground Vehicles (UGVs) and legged
robots have been extensively studied, enabling locomotion across a variety of
terrains. Advances in mobility have enabled obstacles to be regarded not only
as hindrances to be avoided, but also as navigational aids when beneficial. A
modified 3D A* algorithm generates an optimal path by leveraging obstacles
during the planning process. By incorporating a height-based penalty into the
cost function, the algorithm enables the use of traversable obstacles to aid
locomotion while avoiding those that are impassable, resulting in more
efficient and realistic path generation. The octree-based 3D grid map achieves
compression by merging high-resolution nodes into larger blocks, especially in
obstacle-free or sparsely populated areas. This reduces the number of nodes
explored by the A* algorithm, thereby improving computational efficiency and
memory usage, and supporting real-time path planning in practical environments.
Benchmark results demonstrate that the use of octree structure ensures an
optimal path while significantly reducing memory usage and computation time.

</details>


### [103] [DeGuV: Depth-Guided Visual Reinforcement Learning for Generalization and Interpretability in Manipulation](https://arxiv.org/abs/2509.04970)
*Tien Pham,Xinyun Chi,Khang Nguyen,Manfred Huber,Angelo Cangelosi*

Main category: cs.RO

TL;DR: DeGuV 是一种 RL 框架，通过掩码网络和对比学习提升泛化能力和样本效率，在零样本迁移中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决 RL 代理在视觉输入任务中泛化能力不足的问题，同时提升样本效率和训练稳定性。

Method: 利用可学习的掩码网络从深度输入生成掩码，保留关键视觉信息，同时结合对比学习和稳定的 Q 值估计。

Result: 在 RL-ViGen 基准测试中，DeGuV 在泛化能力和样本效率上均优于现有方法，并提高了视觉输入的可解释性。

Conclusion: DeGuV 框架通过结合可学习的掩码网络、对比学习和稳定的 Q 值估计，显著提升了 RL 代理的泛化能力和样本效率，同时在零样本 sim-to-real 迁移中表现优异。

Abstract: Reinforcement learning (RL) agents can learn to solve complex tasks from
visual inputs, but generalizing these learned skills to new environments
remains a major challenge in RL application, especially robotics. While data
augmentation can improve generalization, it often compromises sample efficiency
and training stability. This paper introduces DeGuV, an RL framework that
enhances both generalization and sample efficiency. In specific, we leverage a
learnable masker network that produces a mask from the depth input, preserving
only critical visual information while discarding irrelevant pixels. Through
this, we ensure that our RL agents focus on essential features, improving
robustness under data augmentation. In addition, we incorporate contrastive
learning and stabilize Q-value estimation under augmentation to further enhance
sample efficiency and training stability. We evaluate our proposed method on
the RL-ViGen benchmark using the Franka Emika robot and demonstrate its
effectiveness in zero-shot sim-to-real transfer. Our results show that DeGuV
outperforms state-of-the-art methods in both generalization and sample
efficiency while also improving interpretability by highlighting the most
relevant regions in the visual input

</details>


### [104] [Lyapunov-Based Deep Learning Control for Robots with Unknown Jacobian](https://arxiv.org/abs/2509.04984)
*Koji Matsuno,Chien Chern Cheah*

Main category: cs.RO

TL;DR: 论文提出了一种模块化深度学习方法，通过实时更新权重和Lyapunov分析确保机器人控制的稳定性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习黑盒特性在实时机器人控制中带来的信任和鲁棒性挑战，确保系统稳定性。

Method: 采用模块化学习方法实时更新所有层的权重，并结合Lyapunov类分析确保系统稳定性。

Result: 实验结果表明，所提出的深度学习控制器在工业机器人上表现良好，有效解决了黑盒问题。

Conclusion: 该论文提出的方法为深度学习在实时机器人应用中提供了稳定且可靠的解决方案，为未来基于深度学习的实时机器人应用奠定了重要基础。

Abstract: Deep learning, with its exceptional learning capabilities and flexibility,
has been widely applied in various applications. However, its black-box nature
poses a significant challenge in real-time robotic applications, particularly
in robot control, where trustworthiness and robustness are critical in ensuring
safety. In robot motion control, it is essential to analyze and ensure system
stability, necessitating the establishment of methodologies that address this
need. This paper aims to develop a theoretical framework for end-to-end deep
learning control that can be integrated into existing robot control theories.
The proposed control algorithm leverages a modular learning approach to update
the weights of all layers in real time, ensuring system stability based on
Lyapunov-like analysis. Experimental results on industrial robots are presented
to illustrate the performance of the proposed deep learning controller. The
proposed method offers an effective solution to the black-box problem in deep
learning, demonstrating the possibility of deploying real-time deep learning
strategies for robot kinematic control in a stable manner. This achievement
provides a critical foundation for future advancements in deep learning based
real-time robotic applications.

</details>


### [105] [FLOWER: Democratizing Generalist Robot Policies with Efficient Vision-Language-Action Flow Policies](https://arxiv.org/abs/2509.04996)
*Moritz Reuss,Hongyi Zhou,Marcel Rühle,Ömer Erdinç Yağmurlu,Fabian Otto,Rudolf Lioutikov*

Main category: cs.RO

TL;DR: FLOWER 是一种高效的 VLA 策略，通过优化模型结构和参数，显著降低计算成本，同时在多项任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的 VLA 策略需要庞大的模型和数据集，计算成本高昂，限制了实际机器人部署的效率。

Method: 采用中间模态融合（修剪高达 50% 的 LLM 层）和动作特定的 Global-AdaLN 条件化（减少 20% 参数），整合为 950 M 参数的 FLOWER 模型。

Result: FLOWER 在 200 H100 GPU 小时内完成预训练，在 190 个任务中表现优异，并在 CALVIN ABC 基准测试中达到 4.53 的新 SoTA。

Conclusion: FLOWER 是一种高效的 Vision-Language-Action (VLA) 策略，通过中间模态融合和动作特定的 Global-AdaLN 条件化，显著降低了计算成本和资源需求，同时在多个任务和基准测试中表现出色。

Abstract: Developing efficient Vision-Language-Action (VLA) policies is crucial for
practical robotics deployment, yet current approaches face prohibitive
computational costs and resource requirements. Existing diffusion-based VLA
policies require multi-billion-parameter models and massive datasets to achieve
strong performance. We tackle this efficiency challenge with two contributions:
intermediate-modality fusion, which reallocates capacity to the diffusion head
by pruning up to $50\%$ of LLM layers, and action-specific Global-AdaLN
conditioning, which cuts parameters by $20\%$ through modular adaptation. We
integrate these advances into a novel 950 M-parameter VLA called FLOWER.
Pretrained in just 200 H100 GPU hours, FLOWER delivers competitive performance
with bigger VLAs across $190$ tasks spanning ten simulation and real-world
benchmarks and demonstrates robustness across diverse robotic embodiments. In
addition, FLOWER achieves a new SoTA of 4.53 on the CALVIN ABC benchmark.
Demos, code and pretrained weights are available at
https://intuitive-robots.github.io/flower_vla/.

</details>


### [106] [Pointing-Guided Target Estimation via Transformer-Based Attention](https://arxiv.org/abs/2509.05031)
*Luca Müller,Hassan Ali,Philipp Allgeuer,Lukáš Gajdošech,Stefan Wermter*

Main category: cs.RO

TL;DR: MM-ITF通过跨模态注意力将指向手势映射到目标对象，实现高效人机交互。


<details>
  <summary>Details</summary>
Motivation: 在HRI中，机器人需要预测人类意图并做出适当响应，而指向手势是非语言交流的基本形式。

Method: 提出了Multi-Modality Inter-TransFormer (MM-ITF)模块化架构，利用跨模态注意力将2D指向手势映射到对象位置，并为每个位置分配可能性分数以识别最可能的目标。

Result: 方法在受控桌面场景中准确预测了目标对象，并通过引入patch confusion matrix评估了模型性能。

Conclusion: MM-ITF能够通过单目RGB数据准确预测人类指向的意图对象，从而实现直观且易用的人机协作。

Abstract: Deictic gestures, like pointing, are a fundamental form of non-verbal
communication, enabling humans to direct attention to specific objects or
locations. This capability is essential in Human-Robot Interaction (HRI), where
robots should be able to predict human intent and anticipate appropriate
responses. In this work, we propose the Multi-Modality Inter-TransFormer
(MM-ITF), a modular architecture to predict objects in a controlled tabletop
scenario with the NICOL robot, where humans indicate targets through natural
pointing gestures. Leveraging inter-modality attention, MM-ITF maps 2D pointing
gestures to object locations, assigns a likelihood score to each, and
identifies the most likely target. Our results demonstrate that the method can
accurately predict the intended object using monocular RGB data, thus enabling
intuitive and accessible human-robot collaboration. To evaluate the
performance, we introduce a patch confusion matrix, providing insights into the
model's predictions across candidate object locations. Code available at:
https://github.com/lucamuellercode/MMITF.

</details>


### [107] [Shared Autonomy through LLMs and Reinforcement Learning for Applications to Ship Hull Inspections](https://arxiv.org/abs/2509.05042)
*Cristiano Caissutti,Estelle Gerbier,Ehsan Khorrambakht,Paolo Marinelli,Andrea Munafo',Andrea Caiti*

Main category: cs.RO

TL;DR: 本文提出了一种多层共享自主性架构，结合LLMs、人在环交互和行为树，提升了海上机器人舰队的人机协作效果。


<details>
  <summary>Details</summary>
Motivation: 海上领域复杂、高风险和不确定的环境需要有效的人机协作，共享自主性是一个有前景的范式。

Method: 结合了三种互补方法：(i) 集成大型语言模型（LLMs）以支持高级任务规范和船体检查任务，(ii) 在多智能体环境中实现人在环交互框架以实现自适应和意图感知的协调，(iii) 开发基于行为树的模块化任务管理器，提供可解释和灵活的任务控制。

Result: 初步仿真和实际湖泊环境测试表明，这种多层架构能减少操作员认知负荷、增强透明度，并改善自适应行为与人类意图的对齐。

Conclusion: 本研究为安全关键的海上机器人应用建立了一个模块化和可扩展的基础，支持可信赖的人机协作自主性。

Abstract: Shared autonomy is a promising paradigm in robotic systems, particularly
within the maritime domain, where complex, high-risk, and uncertain
environments necessitate effective human-robot collaboration. This paper
investigates the interaction of three complementary approaches to advance
shared autonomy in heterogeneous marine robotic fleets: (i) the integration of
Large Language Models (LLMs) to facilitate intuitive high-level task
specification and support hull inspection missions, (ii) the implementation of
human-in-the-loop interaction frameworks in multi-agent settings to enable
adaptive and intent-aware coordination, and (iii) the development of a modular
Mission Manager based on Behavior Trees to provide interpretable and flexible
mission control. Preliminary results from simulation and real-world lake-like
environments demonstrate the potential of this multi-layered architecture to
reduce operator cognitive load, enhance transparency, and improve adaptive
behaviour alignment with human intent. Ongoing work focuses on fully
integrating these components, refining coordination mechanisms, and validating
the system in operational port scenarios. This study contributes to
establishing a modular and scalable foundation for trustworthy,
human-collaborative autonomy in safety-critical maritime robotics applications.

</details>


### [108] [Robust Model Predictive Control Design for Autonomous Vehicles with Perception-based Observers](https://arxiv.org/abs/2509.05201)
*Nariman Niknejad,Gokul S. Sankar,Bahare Kiumarsi,Hamidreza Modares*

Main category: cs.RO

TL;DR: 该论文提出了一种处理非高斯噪声的鲁棒MPC框架，通过集合状态估计和线性规划优化，显著提升了控制性能。


<details>
  <summary>Details</summary>
Motivation: 认识到深度学习中感知模块的非高斯噪声对状态估计的影响，传统假设零均值噪声的量化方法不足以确保安全反馈控制，因此需要一种新的方法来处理偏置和重尾不确定性。

Method: 采用基于约束zonotope的集合状态估计方法，将鲁棒MPC重新表述为线性规划（LP），并使用Minkowski-Lyapunov成本函数和松弛变量来防止退化解。通过Minkowski-Lyapunov不等式和收缩zonotopic不变集确保闭环稳定性。

Result: 通过仿真和硬件实验验证，感知感知MPC在重尾噪声条件下表现出稳定且准确的控制性能。

Conclusion: 该论文提出的感知感知MPC框架在非高斯噪声条件下表现出色，显著优于传统的基于高斯噪声的设计，在状态估计误差边界和整体控制性能方面均有显著提升。

Abstract: This paper presents a robust model predictive control (MPC) framework that
explicitly addresses the non-Gaussian noise inherent in deep learning-based
perception modules used for state estimation. Recognizing that accurate
uncertainty quantification of the perception module is essential for safe
feedback control, our approach departs from the conventional assumption of
zero-mean noise quantification of the perception error. Instead, it employs
set-based state estimation with constrained zonotopes to capture biased,
heavy-tailed uncertainties while maintaining bounded estimation errors. To
improve computational efficiency, the robust MPC is reformulated as a linear
program (LP), using a Minkowski-Lyapunov-based cost function with an added
slack variable to prevent degenerate solutions. Closed-loop stability is
ensured through Minkowski-Lyapunov inequalities and contractive zonotopic
invariant sets. The largest stabilizing terminal set and its corresponding
feedback gain are then derived via an ellipsoidal approximation of the
zonotopes. The proposed framework is validated through both simulations and
hardware experiments on an omnidirectional mobile robot along with a camera and
a convolutional neural network-based perception module implemented within a
ROS2 framework. The results demonstrate that the perception-aware MPC provides
stable and accurate control performance under heavy-tailed noise conditions,
significantly outperforming traditional Gaussian-noise-based designs in terms
of both state estimation error bounding and overall control performance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [109] [Narrative-to-Scene Generation: An LLM-Driven Pipeline for 2D Game Environments](https://arxiv.org/abs/2509.04481)
*Yi-Chun Chen,Arnav Jhala*

Main category: cs.GR

TL;DR: 该论文提出了一种将叙事提示转换为2D游戏场景的轻量级流程，通过LLM生成叙事并提取空间谓词，结合元胞自动机和语义嵌入生成场景，为叙事驱动的PCG提供了可扩展的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在故事生成方面取得了显著进展，但将叙事文本连接到可玩的视觉环境仍是程序化内容生成（PCG）中的一个未解决的挑战。

Method: 我们提出了一个轻量级流程，将短叙事提示转换为一系列基于2D瓦片的游戏场景，反映故事的时间结构。给定LLM生成的叙事，系统识别三个关键时间帧，提取“对象-关系-对象”三元组形式的空间谓词，并使用GameTileNet数据集中的功能感知语义嵌入检索视觉资产。使用元胞自动机生成分层地形，并根据谓词结构放置对象。

Result: 我们在十个不同的故事中评估了系统，分析了瓦片对象匹配、功能层对齐和跨帧的空间约束满足情况。

Conclusion: 该原型为叙事驱动的场景生成提供了可扩展的方法，并为未来在多帧连续性、符号跟踪和故事中心PCG中的多智能体协调方面的工作奠定了基础。

Abstract: Recent advances in large language models(LLMs) enable compelling story
generation, but connecting narrative text to playable visual environments
remains an open challenge in procedural content generation(PCG). We present a
lightweight pipeline that transforms short narrative prompts into a sequence of
2D tile-based game scenes, reflecting the temporal structure of stories. Given
an LLM-generated narrative, our system identifies three key time frames,
extracts spatial predicates in the form of "Object-Relation-Object" triples,
and retrieves visual assets using affordance-aware semantic embeddings from the
GameTileNet dataset. A layered terrain is generated using Cellular Automata,
and objects are placed using spatial rules grounded in the predicate structure.
We evaluated our system in ten diverse stories, analyzing tile-object matching,
affordance-layer alignment, and spatial constraint satisfaction across frames.
This prototype offers a scalable approach to narrative-driven scene generation
and lays the foundation for future work on multi-frame continuity, symbolic
tracking, and multi-agent coordination in story-centered PCG.

</details>


### [110] [Fidelity-preserving enhancement of ptychography with foundational text-to-image models](https://arxiv.org/abs/2509.04513)
*Ming Du,Volker Rose,Junjing Deng,Dileep Singh,Si Chen,Mathew J. Cherukara*

Main category: cs.GR

TL;DR: 提出PnP框架结合相位检索与文本引导扩散模型，有效去除伪影并提升成像质量。


<details>
  <summary>Details</summary>
Motivation: 解决Ptychographic相位检索中因网格病理和多层串扰导致的图像伪影问题，提升重建图像质量。

Method: 采用交替方向乘子法（ADMM）确保数据保真度与伪影去除子问题的一致性，结合预训练的扩散模型（LEDITS++）进行文本引导的伪影去除。

Result: 在模拟和实验数据集上验证了伪影抑制和结构保真度的显著改善，通过PSNR和衍射图案一致性等指标量化。

Conclusion: 本文提出了一种结合物理模型相位检索与文本引导图像编辑的PnP框架，显著提高了衍射成像的质量和结构保真度。

Abstract: Ptychographic phase retrieval enables high-resolution imaging of complex
samples but often suffers from artifacts such as grid pathology and multislice
crosstalk, which degrade reconstructed images. We propose a plug-and-play (PnP)
framework that integrates physics model-based phase retrieval with text-guided
image editing using foundational diffusion models. By employing the alternating
direction method of multipliers (ADMM), our approach ensures consensus between
data fidelity and artifact removal subproblems, maintaining physics consistency
while enhancing image quality. Artifact removal is achieved using a text-guided
diffusion image editing method (LEDITS++) with a pre-trained foundational
diffusion model, allowing users to specify artifacts for removal in natural
language. Demonstrations on simulated and experimental datasets show
significant improvements in artifact suppression and structural fidelity,
validated by metrics such as peak signal-to-noise ratio (PSNR) and diffraction
pattern consistency. This work highlights the combination of text-guided
generative models and model-based phase retrieval algorithms as a transferable
and fidelity-preserving method for high-quality diffraction imaging.

</details>


### [111] [Improved 3D Scene Stylization via Text-Guided Generative Image Editing with Region-Based Control](https://arxiv.org/abs/2509.05285)
*Haruo Fujiwara,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.GR

TL;DR: 提出一种改进的3D风格化方法，通过风格对齐机制和多区域控制，提升视图一致性和风格迁移质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有技术在高质量风格化和视图一致性之间的平衡问题，以及如何在场景的不同区域或对象上实现语义一致的风格迁移。

Method: 通过重新训练初始3D表示，使用风格化的多视角2D图像，并引入风格对齐的深度条件视图生成框架，以及多区域重要性加权Sliced Wasserstein距离损失。

Result: 实验评估表明，我们的方法在文本驱动的3D风格化中有效提升了结果质量。

Conclusion: 我们的方法通过改进的3D表示和风格对齐机制，显著提升了文本驱动的3D风格化质量，同时保持了视图一致性和区域控制能力。

Abstract: Recent advances in text-driven 3D scene editing and stylization, which
leverage the powerful capabilities of 2D generative models, have demonstrated
promising outcomes. However, challenges remain in ensuring high-quality
stylization and view consistency simultaneously. Moreover, applying style
consistently to different regions or objects in the scene with semantic
correspondence is a challenging task. To address these limitations, we
introduce techniques that enhance the quality of 3D stylization while
maintaining view consistency and providing optional region-controlled style
transfer. Our method achieves stylization by re-training an initial 3D
representation using stylized multi-view 2D images of the source views.
Therefore, ensuring both style consistency and view consistency of stylized
multi-view images is crucial. We achieve this by extending the style-aligned
depth-conditioned view generation framework, replacing the fully shared
attention mechanism with a single reference-based attention-sharing mechanism,
which effectively aligns style across different viewpoints. Additionally,
inspired by recent 3D inpainting methods, we utilize a grid of multiple depth
maps as a single-image reference to further strengthen view consistency among
stylized images. Finally, we propose Multi-Region Importance-Weighted Sliced
Wasserstein Distance Loss, allowing styles to be applied to distinct image
regions using segmentation masks from off-the-shelf models. We demonstrate that
this optional feature enhances the faithfulness of style transfer and enables
the mixing of different styles across distinct regions of the scene.
Experimental evaluations, both qualitative and quantitative, demonstrate that
our pipeline effectively improves the results of text-driven 3D stylization.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [112] [STADI: Fine-Grained Step-Patch Diffusion Parallelism for Heterogeneous GPUs](https://arxiv.org/abs/2509.04719)
*Han Liang,Jiahui Zhou,Zicheng Zhou,Xiaoxi Zhang,Xu Chen*

Main category: cs.DC

TL;DR: STADI通过时空自适应调度优化异构多GPU扩散模型推理，减少延迟45%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型并行推理方案在异构多GPU环境下资源利用率低，导致负载不均衡。

Method: STADI采用混合调度器，结合时间维度的计算感知步骤分配器和空间维度的弹性补丁并行机制，优化负载均衡。

Result: 实验表明，STADI显著减少了端到端推理延迟（高达45%）并提高了异构GPU的资源利用率。

Conclusion: STADI框架通过时空自适应调度显著提升了异构多GPU环境下扩散模型推理的效率和资源利用率，减少了端到端推理延迟。

Abstract: The escalating adoption of diffusion models for applications such as image
generation demands efficient parallel inference techniques to manage their
substantial computational cost. However, existing diffusion parallelism
inference schemes often underutilize resources in heterogeneous multi-GPU
environments, where varying hardware capabilities or background tasks cause
workload imbalance. This paper introduces Spatio-Temporal Adaptive Diffusion
Inference (STADI), a novel framework to accelerate diffusion model inference in
such settings. At its core is a hybrid scheduler that orchestrates fine-grained
parallelism across both temporal and spatial dimensions. Temporally, STADI
introduces a novel computation-aware step allocator applied after warmup
phases, using a least-common-multiple-minimizing quantization technique to
reduce denoising steps on slower GPUs and execution synchronization. To further
minimize GPU idle periods, STADI executes an elastic patch parallelism
mechanism that allocates variably sized image patches to GPUs according to
their computational capability, ensuring balanced workload distribution through
a complementary spatial mechanism. Extensive experiments on both
load-imbalanced and heterogeneous multi-GPU clusters validate STADI's efficacy,
demonstrating improved load balancing and mitigation of performance
bottlenecks. Compared to patch parallelism, a state-of-the-art diffusion
inference framework, our method significantly reduces end-to-end inference
latency by up to 45% and significantly improves resource utilization on
heterogeneous GPUs.

</details>


### [113] [VoltanaLLM: Feedback-Driven Frequency Control and State-Space Routing for Energy-Efficient LLM Serving](https://arxiv.org/abs/2509.04827)
*Jiahuan Yu,Aryan Taneja,Junfeng Lin,Minjia Zhang*

Main category: cs.DC

TL;DR: VoltanaLLM是一个基于控制理论的能源高效LLM服务系统，通过协同设计频率缩放和请求路由，在保持性能的同时显著降低能源消耗。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）服务系统在交互式应用中的广泛使用，其高昂的能源成本成为可持续和成本效益部署的挑战。

Method: VoltanaLLM从控制理论的角度设计，结合了频率缩放和请求路由的协同设计，利用预填充/解码解耦架构的分离执行实现细粒度的阶段特定控制。它包括一个反馈驱动的频率控制器和一个状态空间路由器。

Result: 实验结果表明，VoltanaLLM在多个先进LLM和真实数据集上实现了高达36.3%的能源节省，同时保持近乎完美的SLO达成率。

Conclusion: VoltanaLLM成功实现了在保持近乎完美的SLO达成率的同时，节省高达36.3%的能源消耗，为可持续和智能的LLM服务铺平了道路。

Abstract: Modern Large Language Model (LLM) serving systems increasingly support
interactive applications, like real-time chat assistants, code generation
tools, and agentic workflows. However, the soaring energy cost of LLM inference
presents a growing challenge for sustainable and cost-effective deployment.
This paper introduces VoltanaLLM, a system for SLO-aware, energy-efficient LLM
serving, built from a control theory perspective. VoltanaLLM co-designs
frequency scaling and request routing in emerging prefill/decode disaggregated
architectures, leveraging their decoupled execution to enable fine-grained
phase-specific control. It consists of a feedback-driven frequency controller
that dynamically adapts GPU frequency for prefill and decode phases, and a
state-space router that explores routing decisions across frequency-scaled
instances to minimize energy under latency constraints. We implement VoltanaLLM
in SGLang and evaluate its performance over multiple state-of-the-art LLMs and
real-world datasets. The results demonstrate that VoltanaLLM achieves up to
36.3% energy savings while maintaining near-perfect SLO attainment rate, paving
the way for sustainable and intelligent LLM serving.

</details>


### [114] [Toward Distributed 3D Gaussian Splatting for High-Resolution Isosurface Visualization](https://arxiv.org/abs/2509.05216)
*Mengjiao Han,Andres Sewell,Joseph Insley,Janet Knowles,Victor A. Mateevitsi,Michael E. Papka,Steve Petruzza,Silvio Rizzi*

Main category: cs.DC

TL;DR: 多GPU扩展的3D高斯泼溅管道，提升科学可视化的大规模数据处理能力，实现5.6倍加速并支持单GPU无法处理的数据集。


<details>
  <summary>Details</summary>
Motivation: 基于先前使用高斯基元实现高保真等值面重建的工作，扩展3D-GS管道以适应科学可视化需求。

Method: 通过从Grendel-GS调整的多GPU训练后端，实现了大规模数据集的可扩展处理。通过跨GPU分配优化，提高了训练吞吐量并支持超出单GPU容量高分辨率重建。

Result: 在实验中，系统在Kingsnake数据集（4M高斯）上使用四个GPU相比单GPU基线实现了5.6倍加速，并成功训练了Miranda数据集（18M高斯），这在单A100 GPU上是不可行的任务。

Conclusion: 该研究为将3D高斯泼溅（3D-GS）集成到基于高性能计算（HPC）的科学工作流程中奠定了基础，实现了复杂模拟的实时事后和原位可视化。

Abstract: We present a multi-GPU extension of the 3D Gaussian Splatting (3D-GS)
pipeline for scientific visualization. Building on previous work that
demonstrated high-fidelity isosurface reconstruction using Gaussian primitives,
we incorporate a multi-GPU training backend adapted from Grendel-GS to enable
scalable processing of large datasets. By distributing optimization across
GPUs, our method improves training throughput and supports high-resolution
reconstructions that exceed single-GPU capacity. In our experiments, the system
achieves a 5.6X speedup on the Kingsnake dataset (4M Gaussians) using four GPUs
compared to a single-GPU baseline, and successfully trains the Miranda dataset
(18M Gaussians) that is an infeasible task on a single A100 GPU. This work lays
the groundwork for integrating 3D-GS into HPC-based scientific workflows,
enabling real-time post hoc and in situ visualization of complex simulations.

</details>


### [115] [Dynamic reconfiguration for malleable applications using RMA](https://arxiv.org/abs/2509.05248)
*Iker Martín-Álvarez,José I. Aliaga,Maribel Castillo*

Main category: cs.DC

TL;DR: 该论文研究了基于MPI RMA的单边通信方法，用于动态可调整应用的数据重新分配，性能与传统方法相当，但高初始化成本限制了其优势。


<details>
  <summary>Details</summary>
Motivation: 研究动态可调整应用程序的高效数据重新分配方法，以最小化对应用程序执行的影响。

Method: 基于MPI的远程内存访问（RMA）操作开发了新颖的单边通信方法，并与传统的基于集体的方法进行了比较。

Result: 结果显示性能相当，但高初始化成本限制了其优势。

Conclusion: 尽管高性能计算中的动态调整展示了潜力，但高初始化成本目前限制了其优势。

Abstract: This paper investigates the novel one-sided communication methods based on
remote memory access (RMA) operations in MPI for dynamic resizing of malleable
applications, enabling data redistribution with minimal impact on application
execution. After their integration into the MaM library, these methods are
compared with traditional collective-based approaches. In addition, the
existing strategy Wait Drains is extended to support efficient background
reconfiguration. Results show comparable performance, though high
initialization costs currently limit their advantage.

</details>


### [116] [Scaling Performance of Large Language Model Pretraining](https://arxiv.org/abs/2509.05258)
*Alexander Interrante-Grant,Carla Varela-Rosa,Suhaas Narayan,Chris Connelly,Albert Reuther*

Main category: cs.DC

TL;DR: 本文揭示了大型语言模型预训练流程的复杂性，特别是在分布式训练和数据并行性方面，为优化GPU计算资源提供了实用建议。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自然语言处理应用中表现出色，但其训练过程计算成本极高，且公开文献中关于大规模训练流程的扩展性能和训练考虑的信息稀缺。本文旨在填补这一空白。

Method: 本文重点关注分布式训练、大规模数据集管理和数据并行性扩展，特别强调如何最大化利用GPU计算资源。

Result: 通过本文的分析，读者可以更好地理解如何优化大型语言模型的预训练流程，特别是在分布式环境和数据并行性方面。

Conclusion: 本文旨在揭开大型语言模型预训练流程的神秘面纱，特别是在分布式训练、跨数百节点管理大型数据集以及扩展数据并行性方面，以充分利用可用的GPU计算能力。

Abstract: Large language models (LLMs) show best-in-class performance across a wide
range of natural language processing applications. Training these models is an
extremely computationally expensive task; frontier Artificial Intelligence (AI)
research companies are investing billions of dollars into supercomputing
infrastructure to train progressively larger models on increasingly massive
datasets. Unfortunately, information about the scaling performance and training
considerations of these large training pipelines is scarce in public
literature. Working with large-scale datasets and models can be complex and
practical recommendations are scarce in the public literature for tuning
training performance when scaling up large language models. In this paper, we
aim to demystify the large language model pretraining pipeline somewhat - in
particular with respect to distributed training, managing large datasets across
hundreds of nodes, and scaling up data parallelism with an emphasis on fully
leveraging available GPU compute capacity.

</details>
