<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 59]
- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 13]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 35]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.SE](#cs.SE) [Total: 8]
- [cs.DS](#cs.DS) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [3D and 4D World Modeling: A Survey](https://arxiv.org/abs/2509.07996)
*Lingdong Kong,Wesley Yang,Jianbiao Mei,Youquan Liu,Ao Liang,Dekai Zhu,Dongyue Lu,Wei Yin,Xiaotao Hu,Mingkai Jia,Junyuan Deng,Kaiwen Zhang,Yang Wu,Tianyi Yan,Shenyuan Gao,Song Wang,Linfeng Li,Liang Pan,Yong Liu,Jianke Zhu,Wei Tsang Ooi,Steven C. H. Hoi,Ziwei Liu*

Main category: cs.CV

TL;DR: 该论文综述了3D和4D世界建模的研究现状，填补了现有文献的空白，并提供了标准化定义和分类法。


<details>
  <summary>Details</summary>
Motivation: 当前AI研究中，世界建模是一个核心课题，但现有工作多集中于2D图像和视频数据的生成方法，忽略了3D和4D表示（如RGB-D图像、占用网格和LiDAR点云）的快速发展。此外，缺乏标准化的定义和分类法导致文献中的观点分散且不一致。

Method: 论文通过建立精确的定义、引入结构化分类法（包括VideoGen、OccGen和LiDARGen方法），并系统总结3D/4D场景下的数据集和评估指标来填补现有空白。

Result: 论文提供了3D和4D世界建模的全面综述，包括定义、分类法、数据集、评估指标，并讨论了实际应用、开放挑战和研究方向。

Conclusion: 该论文提出了3D和4D世界建模领域的首个全面综述，旨在为该领域的研究提供一致的基础参考。

Abstract: World modeling has become a cornerstone in AI research, enabling agents to
understand, represent, and predict the dynamic environments they inhabit. While
prior work largely emphasizes generative methods for 2D image and video data,
they overlook the rapidly growing body of work that leverages native 3D and 4D
representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds
for large-scale scene modeling. At the same time, the absence of a standardized
definition and taxonomy for ``world models'' has led to fragmented and
sometimes inconsistent claims in the literature. This survey addresses these
gaps by presenting the first comprehensive review explicitly dedicated to 3D
and 4D world modeling and generation. We establish precise definitions,
introduce a structured taxonomy spanning video-based (VideoGen),
occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and
systematically summarize datasets and evaluation metrics tailored to 3D/4D
settings. We further discuss practical applications, identify open challenges,
and highlight promising research directions, aiming to provide a coherent and
foundational reference for advancing the field. A systematic summary of
existing literature is available at https://github.com/worldbench/survey

</details>


### [2] [An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities](https://arxiv.org/abs/2509.08003)
*Shahid Shafi Dar,Bharat Kaurav,Arnav Jain,Chandravardhan Singh Raghaw,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: XFloodNet是一种新型深度学习框架，通过层次化跨模态注意力、多尺度注意力模块和特征细化技术，显著提升城市洪水分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统洪水检测方法依赖单模态数据和静态规则系统，无法捕捉洪水事件的动态非线性关系，现有注意力机制和集成学习方法在层次细化、跨模态特征整合及噪声环境适应性方面存在局限。

Method: XFloodNet结合了三种新组件：层次化跨模态门控注意力机制、异构卷积自适应多尺度注意力模块和级联卷积Transformer特征细化技术。

Result: 在三个基准数据集上，XFloodNet的F1分数分别达到93.33%、82.24%和88.60%，显著优于现有方法。

Conclusion: XFloodNet通过其创新的深度学习方法，显著提升了城市洪水分类的准确性，成为解决气候变暖背景下城市洪水问题的有效工具。

Abstract: In an era of escalating climate change, urban flooding has emerged as a
critical challenge for sustainable cities, threatening lives, infrastructure,
and ecosystems. Traditional flood detection methods are constrained by their
reliance on unimodal data and static rule-based systems, which fail to capture
the dynamic, non-linear relationships inherent in flood events. Furthermore,
existing attention mechanisms and ensemble learning approaches exhibit
limitations in hierarchical refinement, cross-modal feature integration, and
adaptability to noisy or unstructured environments, resulting in suboptimal
flood classification performance. To address these challenges, we present
XFloodNet, a novel framework that redefines urban flood classification through
advanced deep-learning techniques. XFloodNet integrates three novel components:
(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically
aligns visual and textual features, enabling precise multi-granularity
interactions and resolving contextual ambiguities; (2) a Heterogeneous
Convolutional Adaptive Multi-Scale Attention module, which leverages
frequency-enhanced channel attention and frequency-modulated spatial attention
to extract and prioritize discriminative flood-related features across spectral
and spatial domains; and (3) a Cascading Convolutional Transformer Feature
Refinement technique that harmonizes hierarchical features through adaptive
scaling and cascading operations, ensuring robust and noise-resistant flood
detection. We evaluate our proposed method on three benchmark datasets, such as
Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves
state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,
surpassing existing methods by significant margins.

</details>


### [3] [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](https://arxiv.org/abs/2509.08016)
*Hyungjin Chung,Hyelin Nam,Jiyeon Kim,Hyojun Go,Byeongjun Park,Junho Kim,Joonseok Lee,Seongsu Ha,Byung-Hoon Kim*

Main category: cs.CV

TL;DR: VPS是一种无需额外训练的并行推理方法，通过多流处理提升VideoLLMs的时间推理能力，实验证明其高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 解决VideoLLMs在增加输入帧数以捕捉细粒度时间细节时面临的计算成本过高和性能下降问题。

Method: VPS通过在推理时运行多个并行的推理流，每个流处理视频帧的不同子集，并通过聚合输出概率来整合更丰富的视觉信息。

Result: 在多种模型架构和规模（2B-32B）上的实验表明，VPS一致且显著地提升了性能，且比并行替代方案（如Self-consistency）更具扩展性。

Conclusion: Video Parallel Scaling (VPS) 提供了一种内存高效且鲁棒的框架，显著提升了VideoLLMs的时间推理能力，且无需额外训练。

Abstract: Video Large Language Models (VideoLLMs) face a critical bottleneck:
increasing the number of input frames to capture fine-grained temporal detail
leads to prohibitive computational costs and performance degradation from long
context lengths. We introduce Video Parallel Scaling (VPS), an inference-time
method that expands a model's perceptual bandwidth without increasing its
context window. VPS operates by running multiple parallel inference streams,
each processing a unique, disjoint subset of the video's frames. By aggregating
the output probabilities from these complementary streams, VPS integrates a
richer set of visual information than is possible with a single pass. We
theoretically show that this approach effectively contracts the Chinchilla
scaling law by leveraging uncorrelated visual evidence, thereby improving
performance without additional training. Extensive experiments across various
model architectures and scales (2B-32B) on benchmarks such as Video-MME and
EventHallusion demonstrate that VPS consistently and significantly improves
performance. It scales more favorably than other parallel alternatives (e.g.
Self-consistency) and is complementary to other decoding strategies, offering a
memory-efficient and robust framework for enhancing the temporal reasoning
capabilities of VideoLLMs.

</details>


### [4] [Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change](https://arxiv.org/abs/2509.08024)
*Lata Pangtey,Omkar Kabde,Shahid Shafi Dar,Nagendra Kumar*

Main category: cs.CV

TL;DR: 提出多模态立场检测框架，结合文本和视觉信息，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注文本数据，而现实社交媒体内容多为多模态，需要更先进的多模态方法来填补这一空白。

Method: 使用大型语言模型提取文本摘要，结合领域感知的图像标题生成器解释视觉内容，通过专用Transformer模块联合建模文本和图像。

Result: 在MultiClimate数据集上实现了76.2%的准确率、76.3%的精确率、76.2%的召回率和76.2%的F1分数，优于现有方法。

Conclusion: 提出了一种多模态立场检测框架，通过分层融合方法整合文本和视觉信息，显著提升了分类性能。

Abstract: With the rapid proliferation of information across digital platforms, stance
detection has emerged as a pivotal challenge in social media analysis. While
most of the existing approaches focus solely on textual data, real-world social
media content increasingly combines text with visual elements creating a need
for advanced multimodal methods. To address this gap, we propose a multimodal
stance detection framework that integrates textual and visual information
through a hierarchical fusion approach. Our method first employs a Large
Language Model to retrieve stance-relevant summaries from source text, while a
domain-aware image caption generator interprets visual content in the context
of the target topic. These modalities are then jointly modeled along with the
reply text, through a specialized transformer module that captures interactions
between the texts and images. The proposed modality fusion framework integrates
diverse modalities to facilitate robust stance classification. We evaluate our
approach on the MultiClimate dataset, a benchmark for climate change-related
stance detection containing aligned video frames and transcripts. We achieve
accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%,
respectively, outperforming existing state-of-the-art approaches.

</details>


### [5] [Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.08026)
*Zeinab Ghasemi Darehnaei,Mohammad Shokouhifar,Hossein Yazdanjouei,S. M. J. Rastegar Fatemi*

Main category: cs.CV

TL;DR: SI-EDTL是一种两阶段群体智能集成深度迁移学习模型，用于UAV图像中的多车辆检测，结合多种特征提取器和分类器，通过鲸鱼优化算法优化超参数，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决UAV图像中多车辆检测的挑战，提升检测精度。

Method: 结合三个预训练的Faster R-CNN特征提取器模型（InceptionV3、ResNet50、GoogLeNet）与五种迁移分类器（KNN、SVM、MLP、C4.5、朴素贝叶斯），生成15个基学习器，并通过加权平均进行聚合。

Result: 在AU-AIR UAV数据集上，SI-EDTL模型表现优于现有方法。

Conclusion: SI-EDTL模型在UAV图像中多车辆检测任务上表现优于现有方法。

Abstract: This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep
transfer learning model for detecting multiple vehicles in UAV images. It
combines three pre-trained Faster R-CNN feature extractor models (InceptionV3,
ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,
Na\"ive Bayes), resulting in 15 different base learners. These are aggregated
via weighted averaging to classify regions as Car, Van, Truck, Bus, or
background. Hyperparameters are optimized with the whale optimization algorithm
to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with
parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV
dataset.

</details>


### [6] [MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery](https://arxiv.org/abs/2509.08027)
*Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia*

Main category: cs.CV

TL;DR: 本文介绍了MCTED数据集，用于火星数字高程模型预测任务，并展示了专用数据集训练的小型模型优于通用深度估计模型。


<details>
  <summary>Details</summary>
Motivation: 解决大规模DEM处理中常见的伪影和缺失数据问题，为机器学习应用提供高质量的火星数字高程模型数据集。

Method: 使用高分辨率火星正射影像和DEM对生成数据集，开发工具处理原始数据中的伪影和缺失数据点，并将数据分为训练和验证集以避免数据泄漏。训练小型U-Net架构并与DepthAnythingV2模型进行性能对比。

Result: 小型U-Net架构在MCTED数据集上的表现优于DepthAnythingV2的零样本性能，证明了专用数据集的有效性。

Conclusion: 作者通过构建MCTED数据集并训练小型U-Net架构，证明了专用数据集在火星数字高程模型预测任务中的优势，即使小型模型也能超越通用深度估计模型的零样本性能。

Abstract: This work presents a new dataset for the Martian digital elevation model
prediction task, ready for machine learning applications called MCTED. The
dataset has been generated using a comprehensive pipeline designed to process
high-resolution Mars orthoimage and DEM pairs from Day et al., yielding a
dataset consisting of 80,898 data samples. The source images are data gathered
by the Mars Reconnaissance Orbiter using the CTX instrument, providing a very
diverse and comprehensive coverage of the Martian surface. Given the complexity
of the processing pipelines used in large-scale DEMs, there are often artefacts
and missing data points in the original data, for which we developed tools to
solve or mitigate their impact. We divide the processed samples into training
and validation splits, ensuring samples in both splits cover no mutual areas to
avoid data leakage. Every sample in the dataset is represented by the optical
image patch, DEM patch, and two mask patches, indicating values that were
originally missing or were altered by us. This allows future users of the
dataset to handle altered elevation regions as they please. We provide
statistical insights of the generated dataset, including the spatial
distribution of samples, the distributions of elevation values, slopes and
more. Finally, we train a small U-Net architecture on the MCTED dataset and
compare its performance to a monocular depth estimation foundation model,
DepthAnythingV2, on the task of elevation prediction. We find that even a very
small architecture trained on this dataset specifically, beats a zero-shot
performance of a depth estimation foundation model like DepthAnythingV2. We
make the dataset and code used for its generation completely open source in
public repositories.

</details>


### [7] [APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction](https://arxiv.org/abs/2509.08104)
*Sasan Sharifipour,Constantino Álvarez Casado,Mohammad Sabokrou,Miguel Bordallo López*

Main category: cs.CV

TL;DR: APML是一种高效且可微分的一对一匹配损失函数，通过Sinkhorn迭代和温度缩放解决点云预测任务中的点拥堵和覆盖问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的点云预测任务中常用的损失函数（如Chamfer Distance、HyperCD、InfoCD）依赖于最近邻分配，容易导致密集区域点拥堵和稀疏区域覆盖不足的问题。Earth Mover Distance（EMD）虽能有效捕捉结构相似性，但其立方计算复杂度限制了实际应用。因此，需要一种高效且可微分的替代方案。

Method: APML利用Sinkhorn迭代在温度缩放的相似性矩阵上进行操作，通过解析计算温度以保证最小分配概率，避免了手动调参。该方法在运行时效率上接近二次方，与Chamfer-based损失相当，且避免了不可微操作。

Result: 在ShapeNet基准测试和CSI2PC模型中，APML实现了更快的收敛速度、优越的空间分布（尤其在低密度区域），并且在定量性能上表现优于或与现有方法相当。

Conclusion: APML（Adaptive Probabilistic Matching Loss）作为一种完全可微分的一对一匹配近似方法，通过Sinkhorn迭代和温度缩放相似性矩阵，实现了接近二次方的运行时效率。在ShapeNet基准测试和CSI2PC模型中，APML展现出更快的收敛速度、优越的空间分布（尤其在低密度区域）以及无需额外超参数搜索的定量性能提升。

Abstract: Training deep learning models for point cloud prediction tasks such as shape
completion and generation depends critically on loss functions that measure
discrepancies between predicted and ground-truth point sets. Commonly used
functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on
nearest-neighbor assignments, which often induce many-to-one correspondences,
leading to point congestion in dense regions and poor coverage in sparse
regions. These losses also involve non-differentiable operations due to index
selection, which may affect gradient-based optimization. Earth Mover Distance
(EMD) enforces one-to-one correspondences and captures structural similarity
more effectively, but its cubic computational complexity limits its practical
use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully
differentiable approximation of one-to-one matching that leverages Sinkhorn
iterations on a temperature-scaled similarity matrix derived from pairwise
distances. We analytically compute the temperature to guarantee a minimum
assignment probability, eliminating manual tuning. APML achieves near-quadratic
runtime, comparable to Chamfer-based losses, and avoids non-differentiable
operations. When integrated into state-of-the-art architectures (PoinTr, PCN,
FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)
that generates 3D human point clouds from WiFi CSI measurements, APM loss
yields faster convergence, superior spatial distribution, especially in
low-density regions, and improved or on-par quantitative performance without
additional hyperparameter search. The code is available at:
https://github.com/apm-loss/apml.

</details>


### [8] [Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection](https://arxiv.org/abs/2509.08205)
*Jingjing Liu,Yinchao Han,Xianchao Xiu,Jianhua Zhang,Wanquan Liu*

Main category: cs.CV

TL;DR: 提出轻量级框架L-RPCANet，结合RPCA和SENet，提升红外小目标检测的轻量化与噪声鲁棒性，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度展开网络在参数轻量化和噪声鲁棒性方面的不足。

Method: 基于RPCA构建了轻量级框架L-RPCANet，采用分层瓶颈结构和噪声抑制模块，结合SENet通道注意力机制。

Result: 在ISTD数据集上优于现有方法（如RPCANet、DRPCANet、RPCANet++）。

Conclusion: L-RPCANet在红外小目标检测中表现出色，通过轻量化设计和噪声鲁棒性模块，显著提升了性能。

Abstract: Infrared small target detection (ISTD) is one of the key techniques in image
processing. Although deep unfolding networks (DUNs) have demonstrated promising
performance in ISTD due to their model interpretability and data adaptability,
existing methods still face significant challenges in parameter lightweightness
and noise robustness. In this regard, we propose a highly lightweight framework
based on robust principal component analysis (RPCA) called L-RPCANet.
Technically, a hierarchical bottleneck structure is constructed to reduce and
increase the channel dimension in the single-channel input infrared image to
achieve channel-wise feature refinement, with bottleneck layers designed in
each module to extract features. This reduces the number of channels in feature
extraction and improves the lightweightness of network parameters. Furthermore,
a noise reduction module is embedded to enhance the robustness against complex
noise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a
channel attention mechanism to focus on the varying importance of different
features across channels, thereby achieving excellent performance while
maintaining both lightweightness and robustness. Extensive experiments on the
ISTD datasets validate the superiority of our proposed method compared with
state-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code
will be available at https://github.com/xianchaoxiu/L-RPCANet.

</details>


### [9] [Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing](https://arxiv.org/abs/2509.08228)
*Miao Cao,Siming Zheng,Lishun Wang,Ziyang Chen,David Brady,Xin Yuan*

Main category: cs.CV

TL;DR: 提出USS采样策略和BSTFormer算法，显著降低高帧率视频SCI系统的功耗并提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前处理模型在千兆像素相机高帧率下的功耗不可持续，需通过物理层压缩测量降低每像素功耗。

Method: 提出Ultra-Sparse Sampling (USS)策略，并构建DMD编码系统验证其有效性。针对DMD与CCD不匹配问题，提出BSTFormer稀疏Transformer算法。

Result: 实验结果表明，USS策略的动态范围高于RS策略，BSTFormer算法在仿真和真实数据上均显著优于现有技术。

Conclusion: The USS策略因其固定曝光时间是实现完整视频SCI片上系统的理想选择，同时BSTFormer算法在处理USS测量时显著优于现有技术。

Abstract: Digital cameras consume ~0.1 microjoule per pixel to capture and encode
video, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps.
Imagining gigapixel cameras operating at 100-1000 fps, the current processing
model is unsustainable. To address this, physical layer compressive measurement
has been proposed to reduce power consumption per pixel by 10-100X. Video
Snapshot Compressive Imaging (SCI) introduces high frequency modulation in the
optical sensor layer to increase effective frame rate. A commonly used sampling
strategy of video SCI is Random Sampling (RS) where each mask element value is
randomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated
that images can be recovered from a fraction of the image pixels. Inspired by
I2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial
location, only one sub-frame is set to 1 and all others are set to 0. We then
build a Digital Micro-mirror Device (DMD) encoding system to verify the
effectiveness of our USS strategy. Ideally, we can decompose the USS
measurement into sub-measurements for which we can utilize I2P algorithms to
recover high-speed frames. However, due to the mismatch between the DMD and
CCD, the USS measurement cannot be perfectly decomposed. To this end, we
propose BSTFormer, a sparse TransFormer that utilizes local Block attention,
global Sparse attention, and global Temporal attention to exploit the sparsity
of the USS measurement. Extensive results on both simulated and real-world data
show that our method significantly outperforms all previous state-of-the-art
algorithms. Additionally, an essential advantage of the USS strategy is its
higher dynamic range than that of the RS strategy. Finally, from the
application perspective, the USS strategy is a good choice to implement a
complete video SCI system on chip due to its fixed exposure time.

</details>


### [10] [GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation](https://arxiv.org/abs/2509.08232)
*Seongho Kim,Sejong Ryu,Hyoukjun You,Je Hyeong Hong*

Main category: cs.CV

TL;DR: 利用GTA5构建致命视频异常数据集GTA-Crime，并提出域适应策略，显著提升真实世界致命暴力检测效果。


<details>
  <summary>Details</summary>
Motivation: 由于致命事件（如枪击和刺杀）的罕见性及数据收集的伦理问题，现有视频异常检测方法难以有效识别此类事件。

Method: 使用GTA5构建GTA-Crime数据集和生成框架，并采用Wasserstein对抗训练进行片段级域适应。

Result: 实验证明，GTA-Crime数据集及其域适应策略能持续提升真实世界致命暴力检测的准确性。

Conclusion: GTA-Crime数据集及生成框架的发布，结合片段级域适应策略，显著提升了真实世界致命暴力检测的准确性。

Abstract: Recent advancements in video anomaly detection (VAD) have enabled
identification of various criminal activities in surveillance videos, but
detecting fatal incidents such as shootings and stabbings remains difficult due
to their rarity and ethical issues in data collection. Recognizing this
limitation, we introduce GTA-Crime, a fatal video anomaly dataset and
generation framework using Grand Theft Auto 5 (GTA5). Our dataset contains
fatal situations such as shootings and stabbings, captured from CCTV multiview
perspectives under diverse conditions including action types, weather, time of
day, and viewpoints. To address the rarity of such scenarios, we also release a
framework for generating these types of videos. Additionally, we propose a
snippet-level domain adaptation strategy using Wasserstein adversarial training
to bridge the gap between synthetic GTA-Crime features and real-world features
like UCF-Crime. Experimental results validate our GTA-Crime dataset and
demonstrate that incorporating GTA-Crime with our domain adaptation strategy
consistently enhances real world fatal violence detection accuracy. Our dataset
and the data generation framework are publicly available at
https://github.com/ta-ho/GTA-Crime.

</details>


### [11] [RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification](https://arxiv.org/abs/2509.08234)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: RepViT-CXR通过通道复制策略适配ViT于灰度CXR图像，在TB和肺炎检测任务中表现优异，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ViT架构多基于自然图像预训练，需要三通道输入，而CXR扫描本质为灰度图像，存在适配性问题。

Method: 提出RepViT-CXR，一种通道复制策略，将单通道CXR图像适配为ViT兼容格式，无需引入额外信息损失。

Result: 在TB-CXR数据集上达到99.9%准确率和AUC；在儿科肺炎数据集上达到99.0%准确率、99.2%召回率、99.3%精确率和99.0% AUC；在深圳TB数据集上达到91.1%准确率和91.2% AUC，均超越现有方法。

Conclusion: RepViT-CXR通过简单的通道复制策略，成功将ViT应用于灰度医学图像分析，在TB和肺炎检测任务中达到了新的最先进水平，展示了在真实世界临床筛查系统中的强大潜力。

Abstract: Chest X-ray (CXR) imaging remains one of the most widely used diagnostic
tools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia.
Recent advances in deep learning, particularly Vision Transformers (ViTs), have
shown strong potential for automated medical image analysis. However, most ViT
architectures are pretrained on natural images and require three-channel
inputs, while CXR scans are inherently grayscale. To address this gap, we
propose RepViT-CXR, a channel replication strategy that adapts single-channel
CXR images into a ViT-compatible format without introducing additional
information loss. We evaluate RepViT-CXR on three benchmark datasets. On the
TB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%,
surpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy,
99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0%
accuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%,
outperforming strong baselines including DCNN and VGG16. On the Shenzhen TB
dataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a
performance improvement over previously reported CNN-based methods. These
results demonstrate that a simple yet effective channel replication strategy
allows ViTs to fully leverage their representational power on grayscale medical
imaging tasks. RepViT-CXR establishes a new state of the art for TB and
pneumonia detection from chest X-rays, showing strong potential for deployment
in real-world clinical screening systems.

</details>


### [12] [Symmetry Interactive Transformer with CNN Framework for Diagnosis of Alzheimer's Disease Using Structural MRI](https://arxiv.org/abs/2509.08243)
*Zheng Yang,Yanteng Zhang,Xupeng Kou,Yang Liu,Chao Ren*

Main category: cs.CV

TL;DR: 结合3D CNN和对称交互式Transformer的网络，专注于AD引起的脑萎缩不对称特征，诊断准确率达92.5%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多基于预训练或忽略脑疾病导致的不对称特征，因此提出一种专注于疾病引起的左右脑萎缩不对称性的方法。

Method: 使用3D CNN编码器和对称交互式Transformer（SIT）构建的网络，通过左右半球特征对齐和SIT分析，专注于结构变化引起的非对称区域。

Result: 在ADNI数据集上，该方法诊断准确率达92.5%，优于其他CNN及CNN结合通用Transformer的方法，可视化结果验证了其关注脑萎缩区域的有效性。

Conclusion: 提出的端到端网络（结合3D CNN编码器和对称交互式Transformer）在AD诊断中表现出色，准确率达92.5%，且能有效捕捉脑萎缩的不对称特征。

Abstract: Structural magnetic resonance imaging (sMRI) combined with deep learning has
achieved remarkable progress in the prediction and diagnosis of Alzheimer's
disease (AD). Existing studies have used CNN and transformer to build a
well-performing network, but most of them are based on pretraining or ignoring
the asymmetrical character caused by brain disorders. We propose an end-to-end
network for the detection of disease-based asymmetric induced by left and right
brain atrophy which consist of 3D CNN Encoder and Symmetry Interactive
Transformer (SIT). Following the inter-equal grid block fetch operation, the
corresponding left and right hemisphere features are aligned and subsequently
fed into the SIT for diagnostic analysis. SIT can help the model focus more on
the regions of asymmetry caused by structural changes, thus improving
diagnostic performance. We evaluated our method based on the ADNI dataset, and
the results show that the method achieves better diagnostic accuracy (92.5\%)
compared to several CNN methods and CNNs combined with a general transformer.
The visualization results show that our network pays more attention in regions
of brain atrophy, especially for the asymmetric pathological characteristics
induced by AD, demonstrating the interpretability and effectiveness of the
method.

</details>


### [13] [EVDI++: Event-based Video Deblurring and Interpolation via Self-Supervised Learning](https://arxiv.org/abs/2509.08260)
*Chi Zhang,Xiang Zhang,Chenxu Jiang,Gui-Song Xia,Lei Yu*

Main category: cs.CV

TL;DR: EVDI++ 是一个自监督框架，利用事件相机的高时间分辨率解决视频模糊问题，并通过 LDI 网络和自适应融合策略实现高质量去模糊和插帧。


<details>
  <summary>Details</summary>
Motivation: 解决传统帧相机在长曝光时间下产生的视觉模糊和信息丢失问题，利用事件相机的高时间分辨率提升视频质量。

Method: 设计了可学习双积分（LDI）网络来估计参考帧与潜在清晰图像之间的映射关系，并引入基于学习的除法重建模块以优化训练效率。此外，提出了自适应无参数融合策略和自监督学习框架。

Result: 在合成和真实数据集上的大量实验表明，EVDI++ 在去模糊和插帧任务中表现优异。

Conclusion: EVDI++ 在视频去模糊和插帧任务中实现了最先进的性能，通过自监督学习框架和真实数据集验证了其泛化能力。

Abstract: Frame-based cameras with extended exposure times often produce perceptible
visual blurring and information loss between frames, significantly degrading
video quality. To address this challenge, we introduce EVDI++, a unified
self-supervised framework for Event-based Video Deblurring and Interpolation
that leverages the high temporal resolution of event cameras to mitigate motion
blur and enable intermediate frame prediction. Specifically, the Learnable
Double Integral (LDI) network is designed to estimate the mapping relation
between reference frames and sharp latent images. Then, we refine the coarse
results and optimize overall training efficiency by introducing a
learning-based division reconstruction module, enabling images to be converted
with varying exposure intervals. We devise an adaptive parameter-free fusion
strategy to obtain the final results, utilizing the confidence embedded in the
LDI outputs of concurrent events. A self-supervised learning framework is
proposed to enable network training with real-world blurry videos and events by
exploring the mutual constraints among blurry frames, latent images, and event
streams. We further construct a dataset with real-world blurry images and
events using a DAVIS346c camera, demonstrating the generalizability of the
proposed EVDI++ in real-world scenarios. Extensive experiments on both
synthetic and real-world datasets show that our method achieves
state-of-the-art performance in video deblurring and interpolation tasks.

</details>


### [14] [Hyperspectral Mamba for Hyperspectral Object Tracking](https://arxiv.org/abs/2509.08265)
*Long Gao,Yunhe Zhang,Yan Jiang,Weiying Xie,Yunsong Li*

Main category: cs.CV

TL;DR: HyMamba是一种新型高光谱目标跟踪网络，通过SSMs整合光谱、跨深度和时间信息，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有高光谱跟踪器未能充分捕捉内在光谱信息、时间依赖性和跨深度交互，因此提出HyMamba以解决这些局限性。

Method: HyMamba利用状态空间模块（SSMs）统一了光谱、跨深度和时间建模，核心是Spectral State Integration（SSI）模块和Hyperspectral Mamba（HSM）模块。

Result: HyMamba在HOTC2020数据集上实现了73.0%的AUC得分和96.3%的DP@20得分。

Conclusion: HyMamba通过整合光谱、跨深度和时间建模，在七个基准数据集上实现了最先进的性能，展示了其在挑战性场景中的有效性。

Abstract: Hyperspectral object tracking holds great promise due to the rich spectral
information and fine-grained material distinctions in hyperspectral images,
which are beneficial in challenging scenarios. While existing hyperspectral
trackers have made progress by either transforming hyperspectral data into
false-color images or incorporating modality fusion strategies, they often fail
to capture the intrinsic spectral information, temporal dependencies, and
cross-depth interactions. To address these limitations, a new hyperspectral
object tracking network equipped with Mamba (HyMamba), is proposed. It unifies
spectral, cross-depth, and temporal modeling through state space modules
(SSMs). The core of HyMamba lies in the Spectral State Integration (SSI)
module, which enables progressive refinement and propagation of spectral
features with cross-depth and temporal spectral information. Embedded within
each SSI, the Hyperspectral Mamba (HSM) module is introduced to learn spatial
and spectral information synchronously via three directional scanning SSMs.
Based on SSI and HSM, HyMamba constructs joint features from false-color and
hyperspectral inputs, and enhances them through interaction with original
spectral features extracted from raw hyperspectral images. Extensive
experiments conducted on seven benchmark datasets demonstrate that HyMamba
achieves state-of-the-art performance. For instance, it achieves 73.0\% of the
AUC score and 96.3\% of the DP@20 score on the HOTC2020 dataset. The code will
be released at https://github.com/lgao001/HyMamba.

</details>


### [15] [Examining Vision Language Models through Multi-dimensional Experiments with Vision and Text Features](https://arxiv.org/abs/2509.08266)
*Saurav Sengupta,Nazanin Moradinasab,Jiebei Liu,Donald E. Brown*

Main category: cs.CV

TL;DR: 研究发现视觉语言模型（VLMs）在处理复杂视觉问题时依赖固有偏见，细微的输入变化会导致性能显著波动，揭示了模型行为的不稳定性。


<details>
  <summary>Details</summary>
Motivation: 鉴于VLMs在处理特定视觉问题时表现出的偏见和性能不稳定，本研究旨在揭示输入数据特征如何影响模型行为，并探索如何量化这些影响。

Method: 本研究采用开源VLMs，通过系统性地改变输入参数（如图像大小、物体数量、背景颜色和提示特异性）来观察注意力值的变化，从而构建一个多维度的性能分析框架。

Result: 实验结果显示，图像特征和提示特异性的微小变化会显著影响VLM的回答方式和性能，尤其是在需要高精度视觉理解的场景中。

Conclusion: 研究表明，视觉语言模型（VLMs）在回答问题时高度依赖训练中学习到的固有偏见，尤其是在处理需要关注图像特定区域的复杂问题时。通过多维度的分析框架，我们发现即使是图像特征或提示细微的变化，也可能导致VLM回答方式和性能的显著变化。

Abstract: Recent research on Vision Language Models (VLMs) suggests that they rely on
inherent biases learned during training to respond to questions about visual
properties of an image. These biases are exacerbated when VLMs are asked highly
specific questions that require focusing on specific areas of the image. For
example, a VLM tasked with counting stars on a modified American flag (e.g.,
with more than 50 stars) will often disregard the visual evidence and fail to
answer accurately. We build upon this research and develop a multi-dimensional
examination framework to systematically determine which characteristics of the
input data, including both the image and the accompanying prompt, lead to such
differences in performance. Using open-source VLMs, we further examine how
attention values fluctuate with varying input parameters (e.g., image size,
number of objects in the image, background color, prompt specificity). This
research aims to learn how the behavior of vision language models changes and
to explore methods for characterizing such changes. Our results suggest, among
other things, that even minor modifications in image characteristics and prompt
specificity can lead to large changes in how a VLM formulates its answer and,
subsequently, its overall performance.

</details>


### [16] [Generalized Zero-Shot Learning for Point Cloud Segmentation with Evidence-Based Dynamic Calibration](https://arxiv.org/abs/2509.08280)
*Hyeonseok Kim,Byeongkeun Kang,Yeejin Lee*

Main category: cs.CV

TL;DR: E3DPC-GZSL通过整合不确定性估计器和动态校准因子，解决了3D点云零样本分割中的偏见预测问题，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D点云的广义零样本语义分割模型倾向于对训练中遇到的类别做出偏见预测，这一问题在3D应用中尤为突出，因为训练数据规模通常较小。

Method: 提出了一种名为E3DPC-GZSL的新方法，该方法通过将基于证据的不确定性估计器集成到分类器中，并利用动态校准堆叠因子调整预测概率。此外，还引入了一种新的训练策略，通过合并可学习参数与文本派生特征来优化语义空间。

Result: E3DPC-GZSL在ScanNet v2和S3DIS数据集上实现了最先进的性能。

Conclusion: E3DPC-GZSL方法通过整合基于证据的不确定性估计器和动态校准堆叠因子，有效减少了3D点云广义零样本语义分割中对已见类别的偏见预测，并在ScanNet v2和S3DIS数据集上实现了最先进的性能。

Abstract: Generalized zero-shot semantic segmentation of 3D point clouds aims to
classify each point into both seen and unseen classes. A significant challenge
with these models is their tendency to make biased predictions, often favoring
the classes encountered during training. This problem is more pronounced in 3D
applications, where the scale of the training data is typically smaller than in
image-based tasks. To address this problem, we propose a novel method called
E3DPC-GZSL, which reduces overconfident predictions towards seen classes
without relying on separate classifiers for seen and unseen data. E3DPC-GZSL
tackles the overconfidence problem by integrating an evidence-based uncertainty
estimator into a classifier. This estimator is then used to adjust prediction
probabilities using a dynamic calibrated stacking factor that accounts for
pointwise prediction uncertainty. In addition, E3DPC-GZSL introduces a novel
training strategy that improves uncertainty estimation by refining the semantic
space. This is achieved by merging learnable parameters with text-derived
features, thereby improving model optimization for unseen data. Extensive
experiments demonstrate that the proposed approach achieves state-of-the-art
performance on generalized zero-shot semantic segmentation datasets, including
ScanNet v2 and S3DIS.

</details>


### [17] [Dual-Thresholding Heatmaps to Cluster Proposals for Weakly Supervised Object Detection](https://arxiv.org/abs/2509.08289)
*Yuelin Guo,Haoyu He,Zhiyuan Chen,Zitong Huang,Renhao Lu,Lu Shi,Zejun Wang,Weizhe Zhang*

Main category: cs.CV

TL;DR: Proposed a WSOD framework with HGPS, WSBDN, and negative certainty loss, achieving superior performance on VOC datasets.


<details>
  <summary>Details</summary>
Motivation: Existing WSOD methods suffer from generating pseudo GT boxes that either focus on discriminative parts or fail to distinguish adjacent instances, lack background class representation, and discard ignored proposals during optimization, leading to slow convergence.

Method: The paper introduces a heatmap-guided proposal selector (HGPS) to improve pseudo GT box generation, a weakly supervised basic detection network (WSBDN) to address the lack of background class representation and semantic gap, and a negative certainty supervision loss to optimize ignored proposals.

Result: The framework achieves mAP/mCorLoc scores of 58.5%/81.8% on VOC 2007 and 55.6%/80.5% on VOC 2012, surpassing state-of-the-art methods.

Conclusion: The proposed framework, incorporating HGPS for proposal selection, WSBDN for improved detection, and negative certainty supervision loss, demonstrates superior performance with mAP/mCorLoc scores of 58.5%/81.8% on VOC 2007 and 55.6%/80.5% on VOC 2012, outperforming existing WSOD methods.

Abstract: Weakly supervised object detection (WSOD) has attracted significant attention
in recent years, as it does not require box-level annotations. State-of-the-art
methods generally adopt a multi-module network, which employs WSDDN as the
multiple instance detection network module and multiple instance refinement
modules to refine performance. However, these approaches suffer from three key
limitations. First, existing methods tend to generate pseudo GT boxes that
either focus only on discriminative parts, failing to capture the whole object,
or cover the entire object but fail to distinguish between adjacent intra-class
instances. Second, the foundational WSDDN architecture lacks a crucial
background class representation for each proposal and exhibits a large semantic
gap between its branches. Third, prior methods discard ignored proposals during
optimization, leading to slow convergence. To address these challenges, we
first design a heatmap-guided proposal selector (HGPS) algorithm, which
utilizes dual thresholds on heatmaps to pre-select proposals, enabling pseudo
GT boxes to both capture the full object extent and distinguish between
adjacent intra-class instances. We then present a weakly supervised basic
detection network (WSBDN), which augments each proposal with a background class
representation and uses heatmaps for pre-supervision to bridge the semantic gap
between matrices. At last, we introduce a negative certainty supervision loss
on ignored proposals to accelerate convergence. Extensive experiments on the
challenging PASCAL VOC 2007 and 2012 datasets demonstrate the effectiveness of
our framework. We achieve mAP/mCorLoc scores of 58.5%/81.8% on VOC 2007 and
55.6%/80.5% on VOC 2012, performing favorably against the state-of-the-art WSOD
methods. Our code is publicly available at
https://github.com/gyl2565309278/DTH-CP.

</details>


### [18] [An Open Benchmark Dataset for GeoAI Foundation Models for Oil Palm Mapping in Indonesia](https://arxiv.org/abs/2509.08303)
*M. Warizmi Wafiq,Peter Cutter,Ate Poortinga,Daniel Marc G. dela Torre,Karis Tenneson,Vanna Teck,Enikoe Bihari,Chanarun Saisaward,Weraphong Suaruang,Andrea McMahon,Andi Vika Faradiba Muin,Karno B. Batiran,Chairil A,Nurul Qomar,Arya Arismaya Metananda,David Ganz,David Saah*

Main category: cs.CV

TL;DR: 该研究创建了一个高质量的开放地理空间数据集，用于监测印尼油棕种植园，支持可持续发展和减少 deforestation。


<details>
  <summary>Details</summary>
Motivation: 油棕种植是印尼 deforestation 的主要原因之一，需要详细可靠的地图支持可持续性努力和新兴监管框架。

Method: 通过专家标注高分辨率卫星影像（2020-2024）生成多边形注释，采用多解释者共识和实地验证确保质量，适合训练卷积神经网络和地理空间基础模型。

Result: 发布了一个开放获取的地理空间数据集，涵盖油棕种植园及相关土地覆盖类型，具有分层分类系统，支持透明监测。

Conclusion: 该数据集通过高质量的标注和验证，填补了遥感训练数据的关键空白，支持印尼油棕扩张的透明监测，有助于全球减少 deforestation 的目标。

Abstract: Oil palm cultivation remains one of the leading causes of deforestation in
Indonesia. To better track and address this challenge, detailed and reliable
mapping is needed to support sustainability efforts and emerging regulatory
frameworks. We present an open-access geospatial dataset of oil palm
plantations and related land cover types in Indonesia, produced through expert
labeling of high-resolution satellite imagery from 2020 to 2024. The dataset
provides polygon-based, wall-to-wall annotations across a range of
agro-ecological zones and includes a hierarchical typology that distinguishes
oil palm planting stages as well as similar perennial crops. Quality was
ensured through multi-interpreter consensus and field validation. The dataset
was created using wall-to-wall digitization over large grids, making it
suitable for training and benchmarking both conventional convolutional neural
networks and newer geospatial foundation models. Released under a CC-BY
license, it fills a key gap in training data for remote sensing and aims to
improve the accuracy of land cover types mapping. By supporting transparent
monitoring of oil palm expansion, the resource contributes to global
deforestation reduction goals and follows FAIR data principles.

</details>


### [19] [SimCroP: Radiograph Representation Learning with Similarity-driven Cross-granularity Pre-training](https://arxiv.org/abs/2509.08311)
*Rongsheng Wang,Fenghe Tang,Qingsong Yao,Rui Yan,Xu Zhang,Zhen Huang,Haoran Lai,Zhiyang He,Xiaodong Tao,Zihang Jiang,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: SimCroP通过相似性驱动对齐和跨粒度融合，提升了CT扫描中放射影像与报告的对齐能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: CT扫描中病灶分布的空间稀疏性以及放射影像与报告之间复杂隐式的关系，为医学视觉-语言预训练带来了挑战。

Method: 提出了相似性驱动的跨粒度预训练（SimCroP）框架，结合多模态掩码建模、相似性驱动的对齐和跨粒度融合模块，以优化编码器并整合多模态信息。

Result: 在大规模CT-报告数据集上预训练后，SimCroP在五个公共数据集的图像分类和分割任务中表现优异。

Conclusion: SimCroP框架在胸部CT扫描中通过相似性驱动的对齐和跨粒度融合，显著提升了放射影像解释的性能，优于当前最先进的医学自监督学习和医学视觉-语言预训练方法。

Abstract: Medical vision-language pre-training shows great potential in learning
representative features from massive paired radiographs and reports. However,
in computed tomography (CT) scans, the distribution of lesions which contain
intricate structures is characterized by spatial sparsity. Besides, the complex
and implicit relationships between different pathological descriptions in each
sentence of the report and their corresponding sub-regions in radiographs pose
additional challenges. In this paper, we propose a Similarity-Driven
Cross-Granularity Pre-training (SimCroP) framework on chest CTs, which combines
similarity-driven alignment and cross-granularity fusion to improve radiograph
interpretation. We first leverage multi-modal masked modeling to optimize the
encoder for understanding precise low-level semantics from radiographs. Then,
similarity-driven alignment is designed to pre-train the encoder to adaptively
select and align the correct patches corresponding to each sentence in reports.
The cross-granularity fusion module integrates multimodal information across
instance level and word-patch level, which helps the model better capture key
pathology structures in sparse radiographs, resulting in improved performance
for multi-scale downstream tasks. SimCroP is pre-trained on a large-scale
paired CT-reports dataset and validated on image classification and
segmentation tasks across five public datasets. Experimental results
demonstrate that SimCroP outperforms both cutting-edge medical self-supervised
learning methods and medical vision-language pre-training methods. Codes and
models are available at https://github.com/ToniChopp/SimCroP.

</details>


### [20] [Boosted Training of Lightweight Early Exits for Optimizing CNN Image Classification Inference](https://arxiv.org/abs/2509.08318)
*Yehudit Aperstein,Alexander Apartsin*

Main category: cs.CV

TL;DR: BTS-EE通过顺序训练和校准方法解决了早期退出策略的协方差偏移问题，实验显示计算量减少45%，准确率仅下降2%。


<details>
  <summary>Details</summary>
Motivation: 在资源受限平台上实现实时图像分类需要平衡准确性与严格的延迟和功耗预算。传统早期退出策略因协方差偏移问题限制了效率与准确性的权衡。

Method: 提出了Boosted Training Scheme for Early Exits (BTS-EE)，一种顺序训练方法，确保每个分支在推理时的数据分布下进行训练和校准。此外，还设计了一种基于1D卷积的轻量级分支架构和Class Precision Margin (CPM)校准方法。

Result: 在CINIC-10数据集和ResNet18骨干网络上的实验表明，BTS-EE在64种配置中均优于非增强训练，计算量减少高达45%，仅损失2%的准确率。

Conclusion: BTS-EE通过顺序训练和校准方法，有效解决了传统早期退出策略中的协方差偏移问题，显著提升了计算效率与准确性的平衡，为实时图像处理系统提供了实用的部署方案。

Abstract: Real-time image classification on resource-constrained platforms demands
inference methods that balance accuracy with strict latency and power budgets.
Early-exit strategies address this need by attaching auxiliary classifiers to
intermediate layers of convolutional neural networks (CNNs), allowing "easy"
samples to terminate inference early. However, conventional training of early
exits introduces a covariance shift: downstream branches are trained on full
datasets, while at inference they process only the harder, non-exited samples.
This mismatch limits efficiency--accuracy trade-offs in practice. We introduce
the Boosted Training Scheme for Early Exits (BTS-EE), a sequential training
approach that aligns branch training with inference-time data distributions.
Each branch is trained and calibrated before the next, ensuring robustness
under selective inference conditions. To further support embedded deployment,
we propose a lightweight branch architecture based on 1D convolutions and a
Class Precision Margin (CPM) calibration method that enables per-class
threshold tuning for reliable exit decisions. Experiments on the CINIC-10
dataset with a ResNet18 backbone demonstrate that BTS-EE consistently
outperforms non-boosted training across 64 configurations, achieving up to 45
percent reduction in computation with only 2 percent accuracy degradation.
These results expand the design space for deploying CNNs in real-time image
processing systems, offering practical efficiency gains for applications such
as industrial inspection, embedded vision, and UAV-based monitoring.

</details>


### [21] [Retrieval-Augmented VLMs for Multimodal Melanoma Diagnosis](https://arxiv.org/abs/2509.08338)
*Jihyun Moon,Charmgil Hong*

Main category: cs.CV

TL;DR: 提出检索增强视觉语言模型框架，通过纳入相似病例提升恶性黑色素瘤诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 准确和早期诊断恶性黑色素瘤对改善患者预后至关重要，而现有方法（如CNN）常忽略临床元数据且需大量预处理，视觉语言模型在通用数据训练下难以捕捉临床特异性。

Method: 提出了一种检索增强的视觉语言模型框架，将语义相似的患者病例纳入诊断提示。

Result: 该方法无需微调即可实现知情预测，并显著提高了分类准确性和错误纠正能力。

Conclusion: 检索增强的提示方法为临床决策支持提供了稳健的策略。

Abstract: Accurate and early diagnosis of malignant melanoma is critical for improving
patient outcomes. While convolutional neural networks (CNNs) have shown promise
in dermoscopic image analysis, they often neglect clinical metadata and require
extensive preprocessing. Vision-language models (VLMs) offer a multimodal
alternative but struggle to capture clinical specificity when trained on
general-domain data. To address this, we propose a retrieval-augmented VLM
framework that incorporates semantically similar patient cases into the
diagnostic prompt. Our method enables informed predictions without fine-tuning
and significantly improves classification accuracy and error correction over
conventional baselines. These results demonstrate that retrieval-augmented
prompting provides a robust strategy for clinical decision support.

</details>


### [22] [InsFusion: Rethink Instance-level LiDAR-Camera Fusion for 3D Object Detection](https://arxiv.org/abs/2509.08374)
*Zhongyu Xia,Hansong Yang,Yongtao Wang*

Main category: cs.CV

TL;DR: InsFusion通过提取和查询原始与融合特征的提案，结合注意力机制，有效减少累积误差，提升3D物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 在基础特征提取、视角变换和特征融合过程中，噪声和误差会逐渐累积，影响3D物体检测的准确性。

Method: InsFusion从原始和融合特征中提取提案，并利用这些提案查询原始特征，结合注意力机制以减少累积误差的影响。

Result: 在nuScenes数据集上，InsFusion与多种先进基线方法兼容，并实现了新的最先进性能。

Conclusion: InsFusion在nuScenes数据集上展示了与多种先进基线方法的兼容性，并实现了3D物体检测的最新性能。

Abstract: Three-dimensional Object Detection from multi-view cameras and LiDAR is a
crucial component for autonomous driving and smart transportation. However, in
the process of basic feature extraction, perspective transformation, and
feature fusion, noise and error will gradually accumulate. To address this
issue, we propose InsFusion, which can extract proposals from both raw and
fused features and utilizes these proposals to query the raw features, thereby
mitigating the impact of accumulated errors. Additionally, by incorporating
attention mechanisms applied to the raw features, it thereby mitigates the
impact of accumulated errors. Experiments on the nuScenes dataset demonstrate
that InsFusion is compatible with various advanced baseline methods and
delivers new state-of-the-art performance for 3D object detection.

</details>


### [23] [Bitrate-Controlled Diffusion for Disentangling Motion and Content in Video](https://arxiv.org/abs/2509.08376)
*Xiao Li,Qi Chen,Xiulian Peng,Kai Yu,Xie Chen,Yan Lu*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的自监督框架，解耦视频的运动和内容，通过低比特率量化促进解耦，并在多种视频任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在以更少的假设和归纳偏差解耦视频数据，为视频分析和生成提供更灵活的表示。

Method: 采用基于Transformer的架构，结合低比特率向量量化作为信息瓶颈，促进解耦并形成有意义的离散运动空间。利用条件输入去噪扩散模型进行自监督表示学习。

Result: 在真实世界说话头部视频的运动转移和自回归运动生成任务中验证了框架的有效性，并展示了在2D卡通角色像素精灵等其他视频数据上的泛化能力。

Conclusion: 该论文提出了一种新的自监督学习框架，用于解耦视频数据的动态运动和静态内容，为视频分析和生成领域提供了新的视角。

Abstract: We propose a novel and general framework to disentangle video data into its
dynamic motion and static content components. Our proposed method is a
self-supervised pipeline with less assumptions and inductive biases than
previous works: it utilizes a transformer-based architecture to jointly
generate flexible implicit features for frame-wise motion and clip-wise
content, and incorporates a low-bitrate vector quantization as an information
bottleneck to promote disentanglement and form a meaningful discrete motion
space. The bitrate-controlled latent motion and content are used as conditional
inputs to a denoising diffusion model to facilitate self-supervised
representation learning. We validate our disentangled representation learning
framework on real-world talking head videos with motion transfer and
auto-regressive motion generation tasks. Furthermore, we also show that our
method can generalize to other types of video data, such as pixel sprites of 2D
cartoon characters. Our work presents a new perspective on self-supervised
learning of disentangled video representations, contributing to the broader
field of video analysis and generation.

</details>


### [24] [Semantic Causality-Aware Vision-Based 3D Occupancy Prediction](https://arxiv.org/abs/2509.08388)
*Dubing Chen,Huan Zheng,Yucheng Zhou,Xianfei Li,Wenlong Liao,Tao He,Pai Peng,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出了一种基于因果损失的端到端监督方法，显著提升了3D语义占据预测的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖模块化流程，各模块独立优化或使用预配置输入，导致级联错误。本文旨在通过端到端监督解决这一问题。

Method: 提出了基于2D-to-3D语义因果关系的因果损失，设计了三个组件：Channel-Grouped Lifting、Learnable Camera Offsets和Normalized Convolution，分别用于自适应语义映射、增强相机扰动鲁棒性和有效特征传播。

Result: 在Occ3D基准测试中取得了最先进的性能，显著提升了对相机扰动的鲁棒性和2D-to-3D语义一致性。

Conclusion: 该方法通过引入因果损失，实现了模块化2D-to-3D转换管路的端到端监督，显著提升了2D-to-3D语义一致性和对相机扰动的鲁棒性，并在Occ3D基准测试中达到了最先进的性能。

Abstract: Vision-based 3D semantic occupancy prediction is a critical task in 3D vision
that integrates volumetric 3D reconstruction with semantic understanding.
Existing methods, however, often rely on modular pipelines. These modules are
typically optimized independently or use pre-configured inputs, leading to
cascading errors. In this paper, we address this limitation by designing a
novel causal loss that enables holistic, end-to-end supervision of the modular
2D-to-3D transformation pipeline. Grounded in the principle of 2D-to-3D
semantic causality, this loss regulates the gradient flow from 3D voxel
representations back to the 2D features. Consequently, it renders the entire
pipeline differentiable, unifying the learning process and making previously
non-trainable components fully learnable. Building on this principle, we
propose the Semantic Causality-Aware 2D-to-3D Transformation, which comprises
three components guided by our causal loss: Channel-Grouped Lifting for
adaptive semantic mapping, Learnable Camera Offsets for enhanced robustness
against camera perturbations, and Normalized Convolution for effective feature
propagation. Extensive experiments demonstrate that our method achieves
state-of-the-art performance on the Occ3D benchmark, demonstrating significant
robustness to camera perturbations and improved 2D-to-3D semantic consistency.

</details>


### [25] [VRAE: Vertical Residual Autoencoder for License Plate Denoising and Deblurring](https://arxiv.org/abs/2509.08392)
*Cuong Nguyen,Dung T. Tran,Hong Nguyen,Xuan-Vu Phan,Nam-Phong Nguyen*

Main category: cs.CV

TL;DR: VRAE架构通过输入感知特征注入，显著提升交通监控图像质量，优于AE、GAN和FB方法，参数增加极少。


<details>
  <summary>Details</summary>
Motivation: 现实交通监控中，恶劣天气、光线不足或高速运动导致的图像噪声和模糊严重降低了车牌识别系统的准确性，尤其是车牌区域较小的情况下。

Method: 采用垂直残差自编码器（VRAE）架构，通过辅助块在每一编码阶段注入输入感知特征，引导表示学习过程，优于传统自编码器。

Result: 在车牌可见的车辆图像数据集上，VRAE在PSNR上比自编码器（AE）提升约20%，NMSE降低约50%，SSIM提升1%，参数仅增加约1%。

Conclusion: 本文提出的垂直残差自编码器（VRAE）架构在交通监控图像增强任务中表现优异，显著提升了车牌识别的准确率。

Abstract: In real-world traffic surveillance, vehicle images captured under adverse
weather, poor lighting, or high-speed motion often suffer from severe noise and
blur. Such degradations significantly reduce the accuracy of license plate
recognition systems, especially when the plate occupies only a small region
within the full vehicle image. Restoring these degraded images a fast realtime
manner is thus a crucial pre-processing step to enhance recognition
performance. In this work, we propose a Vertical Residual Autoencoder (VRAE)
architecture designed for the image enhancement task in traffic surveillance.
The method incorporates an enhancement strategy that employs an auxiliary
block, which injects input-aware features at each encoding stage to guide the
representation learning process, enabling better general information
preservation throughout the network compared to conventional autoencoders.
Experiments on a vehicle image dataset with visible license plates demonstrate
that our method consistently outperforms Autoencoder (AE), Generative
Adversarial Network (GAN), and Flow-Based (FB) approaches. Compared with AE at
the same depth, it improves PSNR by about 20\%, reduces NMSE by around 50\%,
and enhances SSIM by 1\%, while requiring only a marginal increase of roughly
1\% in parameters.

</details>


### [26] [Sparse BEV Fusion with Self-View Consistency for Multi-View Detection and Tracking](https://arxiv.org/abs/2509.08421)
*Keisuke Toida,Taigo Sakai,Naoki Kato,Kazutoyo Yokota,Takeshi Nakamura,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: SCFusion通过稀疏变换、密度感知加权和多视角一致性损失，解决了多视角跟踪中的特征失真问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多视角多目标跟踪（MVMOT）在应用中面临视角变化、光照变化和遮挡等问题，导致跟踪错误。传统方法将多相机特征投影到统一BEV空间，但会引入特征失真和非均匀密度问题，影响融合表示质量和跟踪精度。

Method: SCFusion框架结合了三种技术：稀疏变换避免投影中的不自然插值、密度感知加权基于空间置信度和相机距离自适应融合特征、多视角一致性损失鼓励每个相机在融合前独立学习区分性特征。

Result: SCFusion在WildTrack和MultiviewX数据集上分别达到95.9%的IDF1分数和89.2%的MODP分数，优于基线方法TrackTacular。

Conclusion: SCFusion通过结合稀疏变换、密度感知加权和多视角一致性损失，有效解决了传统BEV投影中的特征失真和非均匀密度问题，显著提升了多视角多目标跟踪的准确性和鲁棒性。

Abstract: Multi-View Multi-Object Tracking (MVMOT) is essential for applications such
as surveillance, autonomous driving, and sports analytics. However, maintaining
consistent object identities across multiple cameras remains challenging due to
viewpoint changes, lighting variations, and occlusions, which often lead to
tracking errors.Recent methods project features from multiple cameras into a
unified Bird's-Eye-View (BEV) space to improve robustness against occlusion.
However, this projection introduces feature distortion and non-uniform density
caused by variations in object scale with distance. These issues degrade the
quality of the fused representation and reduce detection and tracking
accuracy.To address these problems, we propose SCFusion, a framework that
combines three techniques to improve multi-view feature integration. First, it
applies a sparse transformation to avoid unnatural interpolation during
projection. Next, it performs density-aware weighting to adaptively fuse
features based on spatial confidence and camera distance. Finally, it
introduces a multi-view consistency loss that encourages each camera to learn
discriminative features independently before fusion.Experiments show that
SCFusion achieves state-of-the-art performance, reaching an IDF1 score of 95.9%
on WildTrack and a MODP of 89.2% on MultiviewX, outperforming the baseline
method TrackTacular. These results demonstrate that SCFusion effectively
mitigates the limitations of conventional BEV projection and provides a robust
and accurate solution for multi-view object detection and tracking.

</details>


### [27] [LD-ViCE: Latent Diffusion Model for Video Counterfactual Explanations](https://arxiv.org/abs/2509.08422)
*Payal Varshney,Adriano Lucieri,Christoph Balada,Sheraz Ahmed,Andreas Dengel*

Main category: cs.CV

TL;DR: LD-ViCE是一种新型视频反事实解释框架，通过潜在空间扩散模型高效生成真实、可解释的解释，显著提升性能并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 视频数据的时空复杂性和深度学习模型的不透明性使得解释其决策具有挑战性，现有方法在时间连贯性、鲁棒性和因果洞察方面存在不足。

Method: LD-ViCE通过在潜在空间中使用先进的扩散模型，并结合额外的细化步骤，生成真实且可解释的反事实解释。

Result: LD-ViCE在三个视频数据集上表现优异，R2分数提升高达68%，推理时间减少一半，生成的解释语义明确且时间连贯。

Conclusion: LD-ViCE代表了一个重要的进步，为安全关键领域中的AI可信部署提供了有价值的解释框架。

Abstract: Video-based AI systems are increasingly adopted in safety-critical domains
such as autonomous driving and healthcare. However, interpreting their
decisions remains challenging due to the inherent spatiotemporal complexity of
video data and the opacity of deep learning models. Existing explanation
techniques often suffer from limited temporal coherence, insufficient
robustness, and a lack of actionable causal insights. Current counterfactual
explanation methods typically do not incorporate guidance from the target
model, reducing semantic fidelity and practical utility. We introduce Latent
Diffusion for Video Counterfactual Explanations (LD-ViCE), a novel framework
designed to explain the behavior of video-based AI models. Compared to previous
approaches, LD-ViCE reduces the computational costs of generating explanations
by operating in latent space using a state-of-the-art diffusion model, while
producing realistic and interpretable counterfactuals through an additional
refinement step. Our experiments demonstrate the effectiveness of LD-ViCE
across three diverse video datasets, including EchoNet-Dynamic (cardiac
ultrasound), FERV39k (facial expression), and Something-Something V2 (action
recognition). LD-ViCE outperforms a recent state-of-the-art method, achieving
an increase in R2 score of up to 68% while reducing inference time by half.
Qualitative analysis confirms that LD-ViCE generates semantically meaningful
and temporally coherent explanations, offering valuable insights into the
target model behavior. LD-ViCE represents a valuable step toward the
trustworthy deployment of AI in safety-critical domains.

</details>


### [28] [Beyond Distribution Shifts: Adaptive Hyperspectral Image Classification at Test Time](https://arxiv.org/abs/2509.08436)
*Xia Yue,Anfeng Liu,Ning Chen,Chenjia Huang,Hui Liu,Zhou Huang,Leyuan Fang*

Main category: cs.CV

TL;DR: HyperTTA是一个提升高光谱图像分类模型在多种退化条件下鲁棒性的框架，结合了多级感受野的Transformer分类器和轻量级测试时适应策略。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类模型对噪声、模糊、压缩和大气效应等实际退化条件导致的分布偏移高度敏感，需要一种统一的框架来提升模型在多样化退化条件下的鲁棒性。

Method: 1. 构建了一个多退化高光谱数据集，模拟九种代表性退化类型；2. 设计了光谱-空间Transformer分类器（SSTC），结合多级感受野机制和标签平滑正则化；3. 提出了轻量级的测试时适应策略CELA，通过最小化高置信度无标签目标样本的预测熵来动态适应。

Result: 在两个基准数据集上的广泛实验表明，HyperTTA在多种退化场景下优于现有基线，验证了其分类主干和TTA方案的有效性。

Conclusion: HyperTTA框架通过结合多级感受野机制和标签平滑正则化的光谱-空间Transformer分类器（SSTC），以及轻量级的测试时适应策略（CELA），显著提升了高光谱图像分类模型在多种退化条件下的鲁棒性。

Abstract: Hyperspectral image (HSI) classification models are highly sensitive to
distribution shifts caused by various real-world degradations such as noise,
blur, compression, and atmospheric effects. To address this challenge, we
propose HyperTTA, a unified framework designed to enhance model robustness
under diverse degradation conditions. Specifically, we first construct a
multi-degradation hyperspectral dataset that systematically simulates nine
representative types of degradations, providing a comprehensive benchmark for
robust classification evaluation. Based on this, we design a spectral-spatial
transformer classifier (SSTC) enhanced with a multi-level receptive field
mechanism and label smoothing regularization to jointly capture multi-scale
spatial context and improve generalization. Furthermore, HyperTTA incorporates
a lightweight test-time adaptation (TTA) strategy, the confidence-aware
entropy-minimized LayerNorm adapter (CELA), which updates only the affine
parameters of LayerNorm layers by minimizing prediction entropy on
high-confidence unlabeled target samples. This confidence-aware adaptation
prevents unreliable updates from noisy predictions, enabling robust and dynamic
adaptation without access to source data or target annotations. Extensive
experiments on two benchmark datasets demonstrate that HyperTTA outperforms
existing baselines across a wide range of degradation scenarios, validating the
effectiveness of both its classification backbone and the proposed TTA scheme.
Code will be made available publicly.

</details>


### [29] [Spherical Brownian Bridge Diffusion Models for Conditional Cortical Thickness Forecasting](https://arxiv.org/abs/2509.08442)
*Ivan Stoyanov,Fabian Bongratz,Christian Wachinger*

Main category: cs.CV

TL;DR: SBDM模型通过双向扩散和球形U-Net，显著提升皮质厚度轨迹预测精度，适用于神经退行性疾病研究。


<details>
  <summary>Details</summary>
Motivation: 皮质厚度轨迹的高分辨率预测对神经退行性疾病研究至关重要，但现有方法受限于皮质的非欧几何特性和多模态数据整合困难。

Method: 提出SBDM模型，结合双向条件布朗桥扩散过程和条件球形U-Net（CoS-UNet），整合皮质表面和表格条件。

Result: SBDM在ADNI和OASIS纵向数据集上表现出显著降低的预测误差，并能生成个体化和反事实的皮质厚度轨迹。

Conclusion: SBDM（Spherical Brownian Bridge Diffusion Model）通过双向条件布朗桥扩散过程和新型去噪模型CoS-UNet，显著降低了预测误差，为个体化皮质厚度轨迹预测提供了新框架。

Abstract: Accurate forecasting of individualized, high-resolution cortical thickness
(CTh) trajectories is essential for detecting subtle cortical changes,
providing invaluable insights into neurodegenerative processes and facilitating
earlier and more precise intervention strategies. However, CTh forecasting is a
challenging task due to the intricate non-Euclidean geometry of the cerebral
cortex and the need to integrate multi-modal data for subject-specific
predictions. To address these challenges, we introduce the Spherical Brownian
Bridge Diffusion Model (SBDM). Specifically, we propose a bidirectional
conditional Brownian bridge diffusion process to forecast CTh trajectories at
the vertex level of registered cortical surfaces. Our technical contribution
includes a new denoising model, the conditional spherical U-Net (CoS-UNet),
which combines spherical convolutions and dense cross-attention to integrate
cortical surfaces and tabular conditions seamlessly. Compared to previous
approaches, SBDM achieves significantly reduced prediction errors, as
demonstrated by our experiments based on longitudinal datasets from the ADNI
and OASIS. Additionally, we demonstrate SBDM's ability to generate individual
factual and counterfactual CTh trajectories, offering a novel framework for
exploring hypothetical scenarios of cortical development.

</details>


### [30] [First-order State Space Model for Lightweight Image Super-resolution](https://arxiv.org/abs/2509.08458)
*Yujie Zhu,Xinyi Zhang,Yekai Lu,Guang Yang,Faming Fang,Guixu Zhang*

Main category: cs.CV

TL;DR: FSSM改进Mamba模块，提升轻量级超分辨率性能，不增加参数，实现SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 探索状态空间模型（SSMs）在视觉任务中的潜力，尤其是在轻量级超分辨率任务中，现有Mamba模型多关注网络架构和扫描路径，对SSM模块关注不足。

Method: 引入一阶状态空间模型（FSSM），改进原始Mamba模块，通过结合token相关性提升性能。在SSM中应用一阶保持条件，推导新的离散化形式并分析累积误差。

Result: FSSM在不增加参数量的情况下提升了MambaIR在五个基准数据集上的性能，超越了当前轻量级超分辨率方法。

Conclusion: FSSM通过改进Mamba模块的计算过程，在不增加参数量的情况下提升了轻量级超分辨率任务的性能，并在五个基准数据集上实现了最先进的结果。

Abstract: State space models (SSMs), particularly Mamba, have shown promise in NLP
tasks and are increasingly applied to vision tasks. However, most Mamba-based
vision models focus on network architecture and scan paths, with little
attention to the SSM module. In order to explore the potential of SSMs, we
modified the calculation process of SSM without increasing the number of
parameters to improve the performance on lightweight super-resolution tasks. In
this paper, we introduce the First-order State Space Model (FSSM) to improve
the original Mamba module, enhancing performance by incorporating token
correlations. We apply a first-order hold condition in SSMs, derive the new
discretized form, and analyzed cumulative error. Extensive experimental results
demonstrate that FSSM improves the performance of MambaIR on five benchmark
datasets without additionally increasing the number of parameters, and
surpasses current lightweight SR methods, achieving state-of-the-art results.

</details>


### [31] [Prompt-Driven Image Analysis with Multimodal Generative AI: Detection, Segmentation, Inpainting, and Interpretation](https://arxiv.org/abs/2509.08489)
*Kaleem Ahmad*

Main category: cs.CV

TL;DR: 该论文提出了一种基于自然语言指令的端到端图像分析流程，整合了检测、分割、修复和描述功能，提供了透明调试和一致运行的方法，并展示了高准确率和运行时间优化的实际效果。


<details>
  <summary>Details</summary>
Motivation: 通过将自然语言指令转换为多个步骤（定位、分割、编辑和描述），解决图像分析中的复杂性和不可靠性问题，提供一种透明且高效的解决方案。

Method: 提出了一种统一的流程，结合了开放词汇检测、可提示分割、文本条件修复和视觉语言描述，形成一个端到端的工作流。系统通过单一提示操作，保留中间产物以便透明调试，并通过交互式UI和可脚本化CLI提供一致、可重复的运行。

Result: 在单字提示片段中，检测和分割在超过90%的情况下产生了可用的掩码，准确率超过85%。在高性能GPU上，修复占用了总运行时间的60%至75%，突显了参数调优的重要性。

Conclusion: 该研究提供了一个透明、可靠的模式，将现代视觉和多模态模型整合到一个单一的提示背后，通过明确的防护措施和操作实践提高了在对象替换、场景增强和移除中的可靠性。

Abstract: Prompt-driven image analysis converts a single natural-language instruction
into multiple steps: locate, segment, edit, and describe. We present a
practical case study of a unified pipeline that combines open-vocabulary
detection, promptable segmentation, text-conditioned inpainting, and
vision-language description into a single workflow. The system works end to end
from a single prompt, retains intermediate artifacts for transparent debugging
(such as detections, masks, overlays, edited images, and before and after
composites), and provides the same functionality through an interactive UI and
a scriptable CLI for consistent, repeatable runs. We highlight integration
choices that reduce brittleness, including threshold adjustments, mask
inspection with light morphology, and resource-aware defaults. In a small,
single-word prompt segment, detection and segmentation produced usable masks in
over 90% of cases with an accuracy above 85% based on our criteria. On a
high-end GPU, inpainting makes up 60 to 75% of total runtime under typical
guidance and sampling settings, which highlights the need for careful tuning.
The study offers implementation-guided advice on thresholds, mask tightness,
and diffusion parameters, and details version pinning, artifact logging, and
seed control to support replay. Our contribution is a transparent, reliable
pattern for assembling modern vision and multimodal models behind a single
prompt, with clear guardrails and operational practices that improve
reliability in object replacement, scene augmentation, and removal.

</details>


### [32] [Maximally Useful and Minimally Redundant: The Key to Self Supervised Learning for Imbalanced Data](https://arxiv.org/abs/2509.08469)
*Yash Kumar Sharma,Vineet Nair,Wilson Naik*

Main category: cs.CV

TL;DR: 论文提出了一种基于互信息的多视图目标方法，有效提升了自监督学习在不平衡数据集上的表现，实现了新的最先进准确率。


<details>
  <summary>Details</summary>
Motivation: 对比自监督学习（CSSL）在平衡数据集上表现良好，但在不平衡数据集上泛化能力不足，因此需要探索其在不平衡数据集中的鲁棒性。

Method: 基于互信息理论，提出了支持多视图目标的损失函数，用于过滤极端特征并学习更好的表示。

Result: 在多个自监督框架中验证了多视图目标的有效性，显著提升了分类准确率（Cifar10-LT提升2%，Cifar100-LT提升5%，Imagenet-LT提升3%）。

Conclusion: 提出的方法通过分离类内和类间判别特征，有效提取了尾部类别的代表性特征，并在多种自监督框架中验证了其有效性，实现了自监督不平衡数据集分类的最新准确率。

Abstract: The robustness of contrastive self-supervised learning (CSSL) for imbalanced
datasets is largely unexplored. CSSL usually makes use of \emph{multi-view}
assumptions to learn discriminatory features via similar and dissimilar data
samples. CSSL works well on balanced datasets, but does not generalize well for
imbalanced datasets. In a very recent paper, as part of future work, Yann LeCun
pointed out that the self-supervised multiview framework can be extended to
cases involving \emph{more than two views}. Taking a cue from this insight we
propose a theoretical justification based on the concept of \emph{mutual
information} to support the \emph{more than two views} objective and apply it
to the problem of dataset imbalance in self-supervised learning. The proposed
method helps extract representative characteristics of the tail classes by
segregating between \emph{intra} and \emph{inter} discriminatory
characteristics. We introduce a loss function that helps us to learn better
representations by filtering out extreme features. Experimental evaluation on a
variety of self-supervised frameworks (both contrastive and non-contrastive)
also prove that the \emph{more than two view} objective works well for
imbalanced datasets. We achieve a new state-of-the-art accuracy in
self-supervised imbalanced dataset classification (2\% improvement in
Cifar10-LT using Resnet-18, 5\% improvement in Cifar100-LT using Resnet-18, 3\%
improvement in Imagenet-LT (1k) using Resnet-50).

</details>


### [33] [A Structured Review of Underwater Object Detection Challenges and Solutions: From Traditional to Large Vision Language Models](https://arxiv.org/abs/2509.08490)
*Edwine Nabahirwa,Wei Song,Minghua Zhang,Yi Fang,Zhou Ni*

Main category: cs.CV

TL;DR: 本文综述了水下目标检测的挑战与进展，指出LVLMs的潜力及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 水下目标检测在海洋应用中的重要性与其面临的挑战（如图像质量下降、小目标检测等）促使研究者探索更有效的方法，尤其是利用LVLMs的潜力。

Method: 本文系统地分类了水下目标检测的五大挑战，并分析了从传统图像处理到现代方法的演进过程，探讨了LVLMs在多模态能力上的应用潜力。

Result: 研究指出当前方法的不足，LVLMs在合成数据生成中的应用潜力，以及实时应用的研究缺口。

Conclusion: 当前的水下目标检测方法在应对复杂水下环境时仍显不足，但大型视觉语言模型（LVLMs）展现出了潜力，尤其是在合成数据生成方面。然而，其实时应用仍需进一步研究和优化。

Abstract: Underwater object detection (UOD) is vital to diverse marine applications,
including oceanographic research, underwater robotics, and marine conservation.
However, UOD faces numerous challenges that compromise its performance. Over
the years, various methods have been proposed to address these issues, but they
often fail to fully capture the complexities of underwater environments. This
review systematically categorizes UOD challenges into five key areas: Image
quality degradation, target-related issues, data-related challenges,
computational and processing constraints, and limitations in detection
methodologies. To address these challenges, we analyze the progression from
traditional image processing and object detection techniques to modern
approaches. Additionally, we explore the potential of large vision-language
models (LVLMs) in UOD, leveraging their multi-modal capabilities demonstrated
in other domains. We also present case studies, including synthetic dataset
generation using DALL-E 3 and fine-tuning Florence-2 LVLM for UOD. This review
identifies three key insights: (i) Current UOD methods are insufficient to
fully address challenges like image degradation and small object detection in
dynamic underwater environments. (ii) Synthetic data generation using LVLMs
shows potential for augmenting datasets but requires further refinement to
ensure realism and applicability. (iii) LVLMs hold significant promise for UOD,
but their real-time application remains under-explored, requiring further
research on optimization techniques.

</details>


### [34] [Chirality in Action: Time-Aware Video Representation Learning by Latent Straightening](https://arxiv.org/abs/2509.08502)
*Piyush Bagad,Andrew Zisserman*

Main category: cs.CV

TL;DR: 开发了一种时间敏感的紧凑视频表示方法，通过自监督适应和自编码器结构，在多个数据集上优于大型模型并提升分类性能。


<details>
  <summary>Details</summary>
Motivation: 目标是开发能够感知时间视觉变化的紧凑视频表示，解决现有视频嵌入对时间变化敏感度不足的问题。

Method: 提出了一种自监督适应方法，通过基于感知直化的潜在空间自编码器，将时间敏感性注入冻结的图像特征序列。

Result: 在Something-Something、EPIC-Kitchens和Charade数据集上表现出色，优于大型视频模型，并能提升现有模型的分类性能。

Conclusion: 该研究成功开发了一种时间敏感的紧凑视频表示方法，能够在三个数据集上优于大型视频模型，并在与现有模型结合时提升分类性能。

Abstract: Our objective is to develop compact video representations that are sensitive
to visual change over time. To measure such time-sensitivity, we introduce a
new task: chiral action recognition, where one needs to distinguish between a
pair of temporally opposite actions, such as "opening vs. closing a door",
"approaching vs. moving away from something", "folding vs. unfolding paper",
etc. Such actions (i) occur frequently in everyday life, (ii) require
understanding of simple visual change over time (in object state, size, spatial
position, count . . . ), and (iii) are known to be poorly represented by many
video embeddings. Our goal is to build time aware video representations which
offer linear separability between these chiral pairs. To that end, we propose a
self-supervised adaptation recipe to inject time-sensitivity into a sequence of
frozen image features. Our model is based on an auto-encoder with a latent
space with inductive bias inspired by perceptual straightening. We show that
this results in a compact but time-sensitive video representation for the
proposed task across three datasets: Something-Something, EPIC-Kitchens, and
Charade. Our method (i) outperforms much larger video models pre-trained on
large-scale video datasets, and (ii) leads to an improvement in classification
performance on standard benchmarks when combined with these existing models.

</details>


### [35] [MESH -- Understanding Videos Like Human: Measuring Hallucinations in Large Video Models](https://arxiv.org/abs/2509.08538)
*Garry Yang,Zizhe Chen,Man Hon Wong,Haoyu Lei,Yongqiang Chen,Zhenguo Li,Kaiwen Zhou,James Cheng*

Main category: cs.CV

TL;DR: MESH是一个系统性评估视频模型中幻觉问题的基准测试，通过问答框架揭示LVMs在复杂场景中的局限性。


<details>
  <summary>Details</summary>
Motivation: 大型视频模型（LVMs）在理解动态视频内容时容易产生幻觉（不准确或无关的描述），当前基准测试依赖手动分类，忽视了人类自然解读视频的感知过程。

Method: MESH采用问答框架，包括二元和多项选择格式，结合目标和陷阱实例，通过自下而上的方法评估基本对象、粗到细的主题特征以及主题-动作对。

Result: 评估显示LVMs在识别基本对象和特征上表现优异，但在处理精细细节或长视频中多个动作对齐时幻觉显著增加。

Conclusion: MESH基准测试为系统评估大型视频模型（LVMs）中的幻觉问题提供了有效且全面的方法，揭示了LVMs在处理精细细节和复杂动作时的局限性。

Abstract: Large Video Models (LVMs) build on the semantic capabilities of Large
Language Models (LLMs) and vision modules by integrating temporal information
to better understand dynamic video content. Despite their progress, LVMs are
prone to hallucinations-producing inaccurate or irrelevant descriptions.
Current benchmarks for video hallucination depend heavily on manual
categorization of video content, neglecting the perception-based processes
through which humans naturally interpret videos. We introduce MESH, a benchmark
designed to evaluate hallucinations in LVMs systematically. MESH uses a
Question-Answering framework with binary and multi-choice formats incorporating
target and trap instances. It follows a bottom-up approach, evaluating basic
objects, coarse-to-fine subject features, and subject-action pairs, aligning
with human video understanding. We demonstrate that MESH offers an effective
and comprehensive approach for identifying hallucinations in videos. Our
evaluations show that while LVMs excel at recognizing basic objects and
features, their susceptibility to hallucinations increases markedly when
handling fine details or aligning multiple actions involving various subjects
in longer videos.

</details>


### [36] [HuMo: Human-Centric Video Generation via Collaborative Multi-Modal Conditioning](https://arxiv.org/abs/2509.08519)
*Liyang Chen,Tianxiang Ma,Jiawei Liu,Bingchuan Li,Zhuowei Chen,Lijie Liu,Xu He,Gen Li,Qian He,Zhiyong Wu*

Main category: cs.CV

TL;DR: HuMo is a unified framework for human-centric video generation from multimodal inputs, addressing data scarcity and sub-task collaboration with innovative training and inference strategies, achieving superior results.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of coordinating heterogeneous modalities (text, image, audio) in human-centric video generation due to scarce paired triplet training data and difficulty in collaborating sub-tasks like subject preservation and audio-visual sync.

Method: A two-stage progressive multimodal training paradigm with task-specific strategies, including minimal-invasive image injection for subject preservation and focus-by-predicting for audio-visual sync, along with a time-adaptive Classifier-Free Guidance strategy during inference.

Result: HuMo outperforms specialized state-of-the-art methods, demonstrating effective multimodal control and high-quality video synthesis.

Conclusion: HuMo establishes a unified framework for collaborative multimodal-conditioned human-centric video generation, surpassing specialized state-of-the-art methods in sub-tasks.

Abstract: Human-Centric Video Generation (HCVG) methods seek to synthesize human videos
from multimodal inputs, including text, image, and audio. Existing methods
struggle to effectively coordinate these heterogeneous modalities due to two
challenges: the scarcity of training data with paired triplet conditions and
the difficulty of collaborating the sub-tasks of subject preservation and
audio-visual sync with multimodal inputs. In this work, we present HuMo, a
unified HCVG framework for collaborative multimodal control. For the first
challenge, we construct a high-quality dataset with diverse and paired text,
reference images, and audio. For the second challenge, we propose a two-stage
progressive multimodal training paradigm with task-specific strategies. For the
subject preservation task, to maintain the prompt following and visual
generation abilities of the foundation model, we adopt the minimal-invasive
image injection strategy. For the audio-visual sync task, besides the commonly
adopted audio cross-attention layer, we propose a focus-by-predicting strategy
that implicitly guides the model to associate audio with facial regions. For
joint learning of controllabilities across multimodal inputs, building on
previously acquired capabilities, we progressively incorporate the audio-visual
sync task. During inference, for flexible and fine-grained multimodal control,
we design a time-adaptive Classifier-Free Guidance strategy that dynamically
adjusts guidance weights across denoising steps. Extensive experimental results
demonstrate that HuMo surpasses specialized state-of-the-art methods in
sub-tasks, establishing a unified framework for collaborative
multimodal-conditioned HCVG. Project Page:
https://phantom-video.github.io/HuMo.

</details>


### [37] [UOPSL: Unpaired OCT Predilection Sites Learning for Fundus Image Diagnosis Augmentation](https://arxiv.org/abs/2509.08624)
*Zhihao Zhao,Yinzheng Zhao,Junjie Yang,Xiangtong Yao,Quanmin Liang,Daniel Zapp,Kai Huang,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 提出非配对多模态框架UOPSL，利用OCT空间先验提升眼底图像疾病识别，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于配对多模态眼科图像获取成本高且存在模态不平衡问题，传统方法难以捕捉细粒度空间信息。本研究旨在通过结合OCT空间先验和文本描述，提升仅基于眼底图像的疾病识别能力。

Method: 采用对比学习在大规模非配对OCT和眼底图像上学习，同时学习OCT潜在空间中的病变偏好部位矩阵。在下游分类任务中，仅使用眼底图像时，利用该矩阵辅助学习。

Result: 在9个不同数据集和28个关键类别上的实验表明，该框架显著优于现有基准。

Conclusion: 论文提出了一种新颖的非配对多模态框架UOPSL，通过利用OCT衍生的空间先验知识动态识别病变偏好部位，显著提升了基于眼底图像的疾病识别性能。实验证明该框架在多个数据集上优于现有基准。

Abstract: Significant advancements in AI-driven multimodal medical image diagnosis have
led to substantial improvements in ophthalmic disease identification in recent
years. However, acquiring paired multimodal ophthalmic images remains
prohibitively expensive. While fundus photography is simple and cost-effective,
the limited availability of OCT data and inherent modality imbalance hinder
further progress. Conventional approaches that rely solely on fundus or textual
features often fail to capture fine-grained spatial information, as each
imaging modality provides distinct cues about lesion predilection sites. In
this study, we propose a novel unpaired multimodal framework \UOPSL that
utilizes extensive OCT-derived spatial priors to dynamically identify
predilection sites, enhancing fundus image-based disease recognition. Our
approach bridges unpaired fundus and OCTs via extended disease text
descriptions. Initially, we employ contrastive learning on a large corpus of
unpaired OCT and fundus images while simultaneously learning the predilection
sites matrix in the OCT latent space. Through extensive optimization, this
matrix captures lesion localization patterns within the OCT feature space.
During the fine-tuning or inference phase of the downstream classification task
based solely on fundus images, where paired OCT data is unavailable, we
eliminate OCT input and utilize the predilection sites matrix to assist in
fundus image classification learning. Extensive experiments conducted on 9
diverse datasets across 28 critical categories demonstrate that our framework
outperforms existing benchmarks.

</details>


### [38] [Skeleton-based sign language recognition using a dual-stream spatio-temporal dynamic graph convolutional network](https://arxiv.org/abs/2509.08661)
*Liangjin Liu,Haoyang Zheng,Pei Zhou*

Main category: cs.CV

TL;DR: DSLNet提出双参考框架和双流架构，有效解决手语识别中的形态和轨迹歧义，在多个数据集上实现高准确率且参数量少。


<details>
  <summary>Details</summary>
Motivation: 孤立手语识别面临形态相似但语义不同的手势识别难题，现有方法因依赖单一参考框架而难以解决几何歧义。

Method: DSLNet采用双参考框架（手腕中心和面部中心）和双流架构，分别处理手势的形态和轨迹。形态分析使用拓扑感知图卷积，轨迹建模采用Finsler几何编码器，并通过几何驱动的最优传输融合机制整合两流信息。

Result: DSLNet在WLASL-100、WLASL-300和LSA64数据集上分别达到93.70%、89.97%和99.79%的准确率，参数量显著少于竞争模型。

Conclusion: DSLNet通过双参考框架和双流架构，成功解决了孤立手语识别中的形态和轨迹歧义问题，显著提升了识别准确率，并在多个数据集上实现了最先进的性能。

Abstract: Isolated Sign Language Recognition (ISLR) is challenged by gestures that are
morphologically similar yet semantically distinct, a problem rooted in the
complex interplay between hand shape and motion trajectory. Existing methods,
often relying on a single reference frame, struggle to resolve this geometric
ambiguity. This paper introduces Dual-SignLanguageNet (DSLNet), a
dual-reference, dual-stream architecture that decouples and models gesture
morphology and trajectory in separate, complementary coordinate systems. Our
approach utilizes a wrist-centric frame for view-invariant shape analysis and a
facial-centric frame for context-aware trajectory modeling. These streams are
processed by specialized networks-a topology-aware graph convolution for shape
and a Finsler geometry-based encoder for trajectory-and are integrated via a
geometry-driven optimal transport fusion mechanism. DSLNet sets a new
state-of-the-art, achieving 93.70%, 89.97% and 99.79% accuracy on the
challenging WLASL-100, WLASL-300 and LSA64 datasets, respectively, with
significantly fewer parameters than competing models.

</details>


### [39] [ViewSparsifier: Killing Redundancy in Multi-View Plant Phenotyping](https://arxiv.org/abs/2509.08550)
*Robin-Nico Kampa,Fabian Deuser,Konrad Habel,Norbert Oswald*

Main category: cs.CV

TL;DR: ViewSparsifier通过多视图学习提升植物表型分析准确性，在两项任务中获胜，并探索了更多视图选择的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统单视图分类或回归模型无法准确估计目标表型性状，影响植物健康评估和收获准备预测。多视图数据集提供了更全面的信息。

Method: 提出ViewSparsifier方法，通过随机选择24个视图（选择向量）学习视图不变嵌入，并尝试随机选择所有五个高度级别的视图（120个视图，选择矩阵）以进一步改进。

Result: ViewSparsifier方法在ACM Multimedia 2025的GroMo Grand Challenge中赢得了植物年龄预测和叶片计数估计两项任务。

Conclusion: ViewSparsifier方法在植物年龄预测和叶片计数估计任务中表现优异，为未来多视图植物表型分析提供了有效方向。

Abstract: Plant phenotyping involves analyzing observable characteristics of plants to
better understand their growth, health, and development. In the context of deep
learning, this analysis is often approached through single-view classification
or regression models. However, these methods often fail to capture all
information required for accurate estimation of target phenotypic traits, which
can adversely affect plant health assessment and harvest readiness prediction.
To address this, the Growth Modelling (GroMo) Grand Challenge at ACM Multimedia
2025 provides a multi-view dataset featuring multiple plants and two tasks:
Plant Age Prediction and Leaf Count Estimation. Each plant is photographed from
multiple heights and angles, leading to significant overlap and redundancy in
the captured information. To learn view-invariant embeddings, we incorporate 24
views, referred to as the selection vector, in a random selection. Our
ViewSparsifier approach won both tasks. For further improvement and as a
direction for future research, we also experimented with randomized view
selection across all five height levels (120 views total), referred to as
selection matrices.

</details>


### [40] [Vision-Language Semantic Aggregation Leveraging Foundation Model for Generalizable Medical Image Segmentation](https://arxiv.org/abs/2509.08570)
*Wenjun Yu,Yinchen Zhou,Jia-Xuan Jiang,Shubin Zeng,Yuee Li,Zhong Wang*

Main category: cs.CV

TL;DR: 提出EM聚合和文本引导解码器，解决医学图像分割中多模态模型的性能问题，实验显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多模态模型在医学图像分割中因语义鸿沟和特征分散导致的性能不足问题。

Method: 提出EM聚合机制动态聚类特征以减少特征分散，并设计文本引导像素解码器利用文本知识指导视觉表示。

Result: 在心脏和眼底公开数据集上，方法在多个域泛化基准中一致优于现有SOTA方法。

Conclusion: 通过提出的EM聚合机制和文本引导像素解码器，显著提升了医学图像分割在多模态模型中的性能，超越了现有SOTA方法。

Abstract: Multimodal models have achieved remarkable success in natural image
segmentation, yet they often underperform when applied to the medical domain.
Through extensive study, we attribute this performance gap to the challenges of
multimodal fusion, primarily the significant semantic gap between abstract
textual prompts and fine-grained medical visual features, as well as the
resulting feature dispersion. To address these issues, we revisit the problem
from the perspective of semantic aggregation. Specifically, we propose an
Expectation-Maximization (EM) Aggregation mechanism and a Text-Guided Pixel
Decoder. The former mitigates feature dispersion by dynamically clustering
features into compact semantic centers to enhance cross-modal correspondence.
The latter is designed to bridge the semantic gap by leveraging
domain-invariant textual knowledge to effectively guide deep visual
representations. The synergy between these two mechanisms significantly
improves the model's generalization ability. Extensive experiments on public
cardiac and fundus datasets demonstrate that our method consistently
outperforms existing SOTA approaches across multiple domain generalization
benchmarks.

</details>


### [41] [An End-to-End Deep Learning Framework for Arsenicosis Diagnosis Using Mobile-Captured Skin Images](https://arxiv.org/abs/2509.08780)
*Asif Newaz,Asif Ur Rahman Adib,Rajit Sahil,Mashfique Mehzad*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度学习的端到端框架，用于通过手机图像诊断砷中毒，Transformer模型表现最佳，适用于资源有限的农村地区。


<details>
  <summary>Details</summary>
Motivation: 砷中毒是南亚和东南亚的严重公共卫生问题，其早期皮肤表现常被漏诊，尤其是在农村地区。自动化的图像诊断解决方案可以支持早期检测和及时干预。

Method: 研究提出了一个端到端的框架，用于利用手机拍摄的皮肤图像诊断砷中毒。通过构建包含20个类别和超过11000张图像的砷诱导和其他皮肤病数据集，并对比了包括卷积神经网络（CNN）和基于Transformer的模型在内的多种深度学习架构。

Result: 基于Transformer的模型显著优于CNN，其中Swin Transformer表现最佳（86%准确率）。LIME和Grad-CAM可视化证实模型关注了病灶相关区域，增加了临床透明度并辅助错误分析。

Conclusion: 该框架展示了深度学习在非侵入性、可访问且可解释的砷中毒诊断方面的潜力，尤其适用于农村和资源有限的社区，支持早期检测和及时干预。

Abstract: Background: Arsenicosis is a serious public health concern in South and
Southeast Asia, primarily caused by long-term consumption of
arsenic-contaminated water. Its early cutaneous manifestations are clinically
significant but often underdiagnosed, particularly in rural areas with limited
access to dermatologists. Automated, image-based diagnostic solutions can
support early detection and timely interventions.
  Methods: In this study, we propose an end-to-end framework for arsenicosis
diagnosis using mobile phone-captured skin images. A dataset comprising 20
classes and over 11000 images of arsenic-induced and other dermatological
conditions was curated. Multiple deep learning architectures, including
convolutional neural networks (CNNs) and Transformer-based models, were
benchmarked for arsenicosis detection. Model interpretability was integrated
via LIME and Grad-CAM, while deployment feasibility was demonstrated through a
web-based diagnostic tool.
  Results: Transformer-based models significantly outperformed CNNs, with the
Swin Transformer achieving the best results (86\\% accuracy). LIME and Grad-CAM
visualizations confirmed that the models attended to lesion-relevant regions,
increasing clinical transparency and aiding in error analysis. The framework
also demonstrated strong performance on external validation samples, confirming
its ability to generalize beyond the curated dataset.
  Conclusion: The proposed framework demonstrates the potential of deep
learning for non-invasive, accessible, and explainable diagnosis of arsenicosis
from mobile-acquired images. By enabling reliable image-based screening, it can
serve as a practical diagnostic aid in rural and resource-limited communities,
where access to dermatologists is scarce, thereby supporting early detection
and timely intervention.

</details>


### [42] [Improving Greenland Bed Topography Mapping with Uncertainty-Aware Graph Learning on Sparse Radar Data](https://arxiv.org/abs/2509.08571)
*Bayu Adhi Tama,Homayra Alam,Mostafa Cham,Omar Faruque,Jianwu Wang,Vandana Janeja*

Main category: cs.CV

TL;DR: GraphTopoNet利用图学习框架融合异质监督和不确定性建模，显著提升格陵兰冰下床地图的准确性，误差减少60%，支持气候预测和政策制定。


<details>
  <summary>Details</summary>
Motivation: 准确的格陵兰冰下床地图对海平面预测至关重要，但雷达观测数据稀疏且分布不均。

Method: GraphTopoNet是一个图学习框架，融合了异质监督并通过蒙特卡洛丢弃明确建模不确定性。空间图由表面可观测数据（高程、速度、质量平衡）构建，并增加了梯度特征和多项式趋势以捕捉局部变异性和广泛结构。采用混合损失函数处理数据缺口，结合置信度加权的雷达监督和动态平衡正则化。

Result: 在格陵兰三个子区域的应用中，GraphTopoNet优于插值、卷积和图基线方法，误差减少高达60%，同时保留了精细的冰川特征。

Conclusion: GraphTopoNet通过图机器学习将稀疏、不确定的地球物理观测转化为大陆尺度的可操作知识，显著提升了格陵兰冰下床地图的可靠性，为气候预测和政策制定提供了支持。

Abstract: Accurate maps of Greenland's subglacial bed are essential for sea-level
projections, but radar observations are sparse and uneven. We introduce
GraphTopoNet, a graph-learning framework that fuses heterogeneous supervision
and explicitly models uncertainty via Monte Carlo dropout. Spatial graphs built
from surface observables (elevation, velocity, mass balance) are augmented with
gradient features and polynomial trends to capture both local variability and
broad structure. To handle data gaps, we employ a hybrid loss that combines
confidence-weighted radar supervision with dynamically balanced regularization.
Applied to three Greenland subregions, GraphTopoNet outperforms interpolation,
convolutional, and graph-based baselines, reducing error by up to 60 percent
while preserving fine-scale glacial features. The resulting bed maps improve
reliability for operational modeling, supporting agencies engaged in climate
forecasting and policy. More broadly, GraphTopoNet shows how graph machine
learning can convert sparse, uncertain geophysical observations into actionable
knowledge at continental scale.

</details>


### [43] [Implicit Shape-Prior for Few-Shot Assisted 3D Segmentation](https://arxiv.org/abs/2509.08580)
*Mathilde Monvoisin,Louise Piecuch,Blanche Texier,Cédric Hémon,Anaïs Barateau,Jérémie Huet,Antoine Nordez,Anne-Sophie Boureau,Jean-Claude Nunes,Diana Mateus*

Main category: cs.CV

TL;DR: 论文提出了一种减少医学3D分割手动工作量的方法，结合隐式形状先验和自动切片选择，在脑癌和肌肉萎缩症案例中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的复杂3D分割任务（如放疗规划中的风险器官识别或肌肉退化性疾病的诊断）仍依赖大量手动工作，自动化程度不足。本文旨在减轻医学专业人员的手动分割负担。

Method: 论文介绍了一种基于隐式形状先验的方法，从稀疏的手动标注切片中分割体积，并将其推广到多器官情况。同时，提出了一个简单框架，用于自动选择最具信息量的切片，以指导和最小化后续交互。

Result: 实验验证表明，该方法在两个医学应用场景中有效：脑癌患者风险器官的辅助分割和加速创建包含未见肌肉形状的肌肉萎缩症患者数据库。

Conclusion: 该论文提出的方法通过引入隐式形状先验和自动选择最具信息量的切片，显著减少了医学专业人员在复杂3D分割任务中的手动工作量，提高了分割效率和准确性。

Abstract: The objective of this paper is to significantly reduce the manual workload
required from medical professionals in complex 3D segmentation tasks that
cannot be yet fully automated. For instance, in radiotherapy planning, organs
at risk must be accurately identified in computed tomography (CT) or magnetic
resonance imaging (MRI) scans to ensure they are spared from harmful radiation.
Similarly, diagnosing age-related degenerative diseases such as sarcopenia,
which involve progressive muscle volume loss and strength, is commonly based on
muscular mass measurements often obtained from manual segmentation of medical
volumes. To alleviate the manual-segmentation burden, this paper introduces an
implicit shape prior to segment volumes from sparse slice manual annotations
generalized to the multi-organ case, along with a simple framework for
automatically selecting the most informative slices to guide and minimize the
next interactions. The experimental validation shows the method's effectiveness
on two medical use cases: assisted segmentation in the context of at risks
organs for brain cancer patients, and acceleration of the creation of a new
database with unseen muscle shapes for patients with sarcopenia.

</details>


### [44] [EfficientIML: Efficient High-Resolution Image Manipulation Localization](https://arxiv.org/abs/2509.08583)
*Jinhan Li,Haoyang He,Lei Xie,Jiangning Zhang*

Main category: cs.CV

TL;DR: 提出EfficientIML模型和SIF数据集，解决扩散伪造检测问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前检测器缺乏对新兴扩散伪造方法的暴露，且现有方法因计算复杂性高而面临资源限制。

Method: 提出了一种轻量级的三阶段EfficientRWKV主干网络，结合混合状态空间和注意力网络，以及多尺度监督策略。

Result: 在SIF数据集和标准基准测试中，EfficientIML模型表现出色。

Conclusion: EfficientIML模型在定位性能、FLOPs和推理速度上优于ViT-based和其他SOTA轻量级基线，适用于实时取证应用。

Abstract: With imaging devices delivering ever-higher resolutions and the emerging
diffusion-based forgery methods, current detectors trained only on traditional
datasets (with splicing, copy-moving and object removal forgeries) lack
exposure to this new manipulation type. To address this, we propose a novel
high-resolution SIF dataset of 1200+ diffusion-generated manipulations with
semantically extracted masks. However, this also imposes a challenge on
existing methods, as they face significant computational resource constraints
due to their prohibitive computational complexities. Therefore, we propose a
novel EfficientIML model with a lightweight, three-stage EfficientRWKV
backbone. EfficientRWKV's hybrid state-space and attention network captures
global context and local details in parallel, while a multi-scale supervision
strategy enforces consistency across hierarchical predictions. Extensive
evaluations on our dataset and standard benchmarks demonstrate that our
approach outperforms ViT-based and other SOTA lightweight baselines in
localization performance, FLOPs and inference speed, underscoring its
suitability for real-time forensic applications.

</details>


### [45] [CLAPS: A CLIP-Unified Auto-Prompt Segmentation for Multi-Modal Retinal Imaging](https://arxiv.org/abs/2509.08618)
*Zhihao Zhao,Yinzheng Zhao,Junjie Yang,Xiangtong Yao,Quanmin Liang,Shahrooz Faghihroohi,Kai Huang,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: CLAPS是一种全自动、统一的多模态视网膜图像分割方法，通过自动提示和统一框架提升性能，广泛适用于多种任务。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像分割方法存在模态模糊性、依赖手动提示以及缺乏统一框架的问题，CLAPS旨在解决这些挑战。

Method: CLAPS结合了CLIP-based图像编码器、GroundingDINO自动生成空间提示和文本提示增强技术，构建了一个全自动的统一分割流程。

Result: 在12个数据集上的实验表明，CLAPS性能与专家模型相当，并在多数指标上超越现有基准。

Conclusion: CLAPS提出了一种统一的多模态视网膜图像分割方法，通过自动生成提示和统一的框架，显著提升了分割性能，并在多个数据集上验证了其广泛适用性。

Abstract: Recent advancements in foundation models, such as the Segment Anything Model
(SAM), have significantly impacted medical image segmentation, especially in
retinal imaging, where precise segmentation is vital for diagnosis. Despite
this progress, current methods face critical challenges: 1) modality ambiguity
in textual disease descriptions, 2) a continued reliance on manual prompting
for SAM-based workflows, and 3) a lack of a unified framework, with most
methods being modality- and task-specific. To overcome these hurdles, we
propose CLIP-unified Auto-Prompt Segmentation (\CLAPS), a novel method for
unified segmentation across diverse tasks and modalities in retinal imaging.
Our approach begins by pre-training a CLIP-based image encoder on a large,
multi-modal retinal dataset to handle data scarcity and distribution imbalance.
We then leverage GroundingDINO to automatically generate spatial bounding box
prompts by detecting local lesions. To unify tasks and resolve ambiguity, we
use text prompts enhanced with a unique "modality signature" for each imaging
modality. Ultimately, these automated textual and spatial prompts guide SAM to
execute precise segmentation, creating a fully automated and unified pipeline.
Extensive experiments on 12 diverse datasets across 11 critical segmentation
categories show that CLAPS achieves performance on par with specialized expert
models while surpassing existing benchmarks across most metrics, demonstrating
its broad generalizability as a foundation model.

</details>


### [46] [AdsQA: Towards Advertisement Video Understanding](https://arxiv.org/abs/2509.08621)
*Xinwei Long,Kai Tian,Peng Xu,Guoli Jia,Jingxuan Li,Sa Yang,Yihua Shao,Kaiyan Zhang,Che Jiang,Hao Xu,Yang Liu,Jiaheng Ma,Bowen Zhou*

Main category: cs.CV

TL;DR: 本研究首次利用广告视频评估LLMs的感知能力，提出ReAd-R模型并在AdsQA基准测试中取得最优表现。


<details>
  <summary>Details</summary>
Motivation: 利用广告视频的丰富线索和信息密集特性（如营销逻辑、说服策略和受众参与度）来全面评估LLMs的能力。

Method: 提出了ReAd-R，一种基于Deepseek-R1风格的强化学习模型，通过奖励驱动的优化生成答案。

Result: 在AdsQA基准测试中，ReAd-R模型取得了最先进的性能，显著优于其他竞争对手。

Conclusion: 本研究通过广告视频作为挑战性测试平台，首次评估了大型语言模型（LLMs）在超越常见视觉领域客观物理内容感知方面的能力。提出的ReAd-R模型在AdsQA基准测试中表现优异，显著优于其他具有长链推理能力的竞争对手。

Abstract: Large language models (LLMs) have taken a great step towards AGI. Meanwhile,
an increasing number of domain-specific problems such as math and programming
boost these general-purpose models to continuously evolve via learning deeper
expertise. Now is thus the time further to extend the diversity of specialized
applications for knowledgeable LLMs, though collecting high quality data with
unexpected and informative tasks is challenging. In this paper, we propose to
use advertisement (ad) videos as a challenging test-bed to probe the ability of
LLMs in perceiving beyond the objective physical content of common visual
domain. Our motivation is to take full advantage of the clue-rich and
information-dense ad videos' traits, e.g., marketing logic, persuasive
strategies, and audience engagement. Our contribution is three-fold: (1) To our
knowledge, this is the first attempt to use ad videos with well-designed tasks
to evaluate LLMs. We contribute AdsQA, a challenging ad Video QA benchmark
derived from 1,544 ad videos with 10,962 clips, totaling 22.7 hours, providing
5 challenging tasks. (2) We propose ReAd-R, a Deepseek-R1 styled RL model that
reflects on questions, and generates answers via reward-driven optimization.
(3) We benchmark 14 top-tier LLMs on AdsQA, and our \texttt{ReAd-R}~achieves
the state-of-the-art outperforming strong competitors equipped with long-chain
reasoning capabilities by a clear margin.

</details>


### [47] [LADB: Latent Aligned Diffusion Bridges for Semi-Supervised Domain Translation](https://arxiv.org/abs/2509.08628)
*Xuqin Wang,Tao Wu,Yanfeng Zhang,Lu Liu,Dong Wang,Mingwei Sun,Yongliang Wang,Niclas Zeller,Daniel Cremers*

Main category: cs.CV

TL;DR: LADB是一种半监督框架，通过部分配对数据桥接领域差距，结合预训练模型和新训练的LADM，实现高效且可控的样本到样本转换。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在数据稀缺领域面临挑战，通常需要大量重新训练或昂贵的配对数据。LADB旨在解决这些限制，通过部分配对数据有效桥接领域差距。

Method: LADB通过在半监督框架中对齐源和目标分布，在共享潜在空间中整合预训练的源域扩散模型和目标域潜在对齐扩散模型（LADM），利用部分配对数据实现确定性域映射。

Result: 实验结果表明，LADB在部分监督下的深度到图像转换中表现优异，并能扩展到多源和多目标转换任务，展示了其处理多样化和异构用例的灵活性。

Conclusion: LADB被提出作为一种可扩展且多功能的解决方案，适用于现实世界的领域转换，特别是在数据标注成本高或不完整的情况下。

Abstract: Diffusion models excel at generating high-quality outputs but face challenges
in data-scarce domains, where exhaustive retraining or costly paired data are
often required. To address these limitations, we propose Latent Aligned
Diffusion Bridges (LADB), a semi-supervised framework for sample-to-sample
translation that effectively bridges domain gaps using partially paired data.
By aligning source and target distributions within a shared latent space, LADB
seamlessly integrates pretrained source-domain diffusion models with a
target-domain Latent Aligned Diffusion Model (LADM), trained on partially
paired latent representations. This approach enables deterministic domain
mapping without the need for full supervision. Compared to unpaired methods,
which often lack controllability, and fully paired approaches that require
large, domain-specific datasets, LADB strikes a balance between fidelity and
diversity by leveraging a mixture of paired and unpaired latent-target
couplings. Our experimental results demonstrate superior performance in
depth-to-image translation under partial supervision. Furthermore, we extend
LADB to handle multi-source translation (from depth maps and segmentation
masks) and multi-target translation in a class-conditioned style transfer task,
showcasing its versatility in handling diverse and heterogeneous use cases.
Ultimately, we present LADB as a scalable and versatile solution for real-world
domain translation, particularly in scenarios where data annotation is costly
or incomplete.

</details>


### [48] [FractalPINN-Flow: A Fractal-Inspired Network for Unsupervised Optical Flow Estimation with Total Variation Regularization](https://arxiv.org/abs/2509.08670)
*Sara Behnamian,Rasoul Khaksarinezhad,Andreas Langer*

Main category: cs.CV

TL;DR: FractalPINN-Flow是一种无监督光学流估计框架，通过分形变形网络和TV正则化，有效解决了高分辨率数据中细节丢失和标注依赖问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统CNN在光学流估计中因顺序下采样而丢失细节的问题，同时减少对标注数据的依赖，提出了一种基于分形几何和自相似性的无监督学习框架。

Method: 采用Fractal Deformation Network（FDN）作为核心架构，结合递归编码器-解码器嵌套和跳跃连接，以总变差（TV）正则化作为训练目标，最小化包含$L^1$和$L^2$数据保真项的能源泛函。

Result: 在合成和基准数据集上的实验表明，FractalPINN-Flow能够生成准确、平滑且边缘保持的光学流场，尤其在高分辨率和标注有限的情况下表现优异。

Conclusion: FractalPINN-Flow是一种无监督深度学习框架，通过Fractal Deformation Network（FDN）结构有效捕捉了光学流估计中的细节和长距离运动模式，尤其在缺乏标注数据的高分辨率场景中表现出色。

Abstract: We present FractalPINN-Flow, an unsupervised deep learning framework for
dense optical flow estimation that learns directly from consecutive grayscale
frames without requiring ground truth. The architecture centers on the Fractal
Deformation Network (FDN) - a recursive encoder-decoder inspired by fractal
geometry and self-similarity. Unlike traditional CNNs with sequential
downsampling, FDN uses repeated encoder-decoder nesting with skip connections
to capture both fine-grained details and long-range motion patterns. The
training objective is based on a classical variational formulation using total
variation (TV) regularization. Specifically, we minimize an energy functional
that combines $L^1$ and $L^2$ data fidelity terms to enforce brightness
constancy, along with a TV term that promotes spatial smoothness and coherent
flow fields. Experiments on synthetic and benchmark datasets show that
FractalPINN-Flow produces accurate, smooth, and edge-preserving optical flow
fields. The model is especially effective for high-resolution data and
scenarios with limited annotations.

</details>


### [49] [Multi-Modal Robust Enhancement for Coastal Water Segmentation: A Systematic HSV-Guided Framework](https://arxiv.org/abs/2509.08694)
*Zhen Tian,Christos Anagnostopoulos,Qiyuan Wang,Zhiwei Gao*

Main category: cs.CV

TL;DR: Robust U-Net框架通过HSV监督和多模态约束，提升了海岸线分割的稳定性和质量，同时保持计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统RGB方法在复杂海洋环境中存在训练不稳定和泛化能力差的问题，需要一种更鲁棒的分割方法。

Method: 该框架整合了五个协同组件：HSV引导的颜色监督、基于梯度的海岸线优化、形态学后处理、海区域清理和连通性控制。

Result: HSV监督的影响最大（影响分数0.85），完整框架实现了84%的方差减少和分割质量的提升。

Conclusion: 本文提出的Robust U-Net框架通过HSV颜色空间监督和多模态约束，显著提升了海岸线分割的稳定性和质量，同时在计算效率上保持了优势。

Abstract: Coastal water segmentation from satellite imagery presents unique challenges
due to complex spectral characteristics and irregular boundary patterns.
Traditional RGB-based approaches often suffer from training instability and
poor generalization in diverse maritime environments. This paper introduces a
systematic robust enhancement framework, referred to as Robust U-Net, that
leverages HSV color space supervision and multi-modal constraints for improved
coastal water segmentation. Our approach integrates five synergistic
components: HSV-guided color supervision, gradient-based coastline
optimization, morphological post-processing, sea area cleanup, and connectivity
control. Through comprehensive ablation studies, we demonstrate that HSV
supervision provides the highest impact (0.85 influence score), while the
complete framework achieves superior training stability (84\% variance
reduction) and enhanced segmentation quality. Our method shows consistent
improvements across multiple evaluation metrics while maintaining computational
efficiency. For reproducibility, our training configurations and code are
available here: https://github.com/UofgCoastline/ICASSP-2026-Robust-Unet.

</details>


### [50] [Computational Imaging for Enhanced Computer Vision](https://arxiv.org/abs/2509.08712)
*Humera Shaikh,Kaur Jashanpreet*

Main category: cs.CV

TL;DR: 本文系统综述了计算成像技术如何提升计算机视觉应用性能，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统成像方法在低光、运动模糊或高动态范围场景等挑战性条件下往往无法提供高质量的视觉数据，限制了计算机视觉系统的性能。

Method: 本文系统地调查了计算成像技术（如光场成像、HDR成像、去模糊、高速成像和眩光抑制）及其与计算机视觉核心任务（如目标检测、深度估计、光流、人脸识别和关键点检测）的协同作用。

Result: 通过分析计算成像方法与计算机视觉应用的实际贡献，本文突出了新兴机会、挑战和未来研究方向。

Conclusion: 本文强调了计算成像技术如何通过任务特定的自适应成像管道，在现实场景中提高计算机视觉应用的鲁棒性、准确性和效率。

Abstract: This paper presents a comprehensive survey of computational imaging (CI)
techniques and their transformative impact on computer vision (CV)
applications. Conventional imaging methods often fail to deliver high-fidelity
visual data in challenging conditions, such as low light, motion blur, or high
dynamic range scenes, thereby limiting the performance of state-of-the-art CV
systems. Computational imaging techniques, including light field imaging, high
dynamic range (HDR) imaging, deblurring, high-speed imaging, and glare
mitigation, address these limitations by enhancing image acquisition and
reconstruction processes. This survey systematically explores the synergies
between CI techniques and core CV tasks, including object detection, depth
estimation, optical flow, face recognition, and keypoint detection. By
analyzing the relationships between CI methods and their practical
contributions to CV applications, this work highlights emerging opportunities,
challenges, and future research directions. We emphasize the potential for
task-specific, adaptive imaging pipelines that improve robustness, accuracy,
and efficiency in real-world scenarios, such as autonomous navigation,
surveillance, augmented reality, and robotics.

</details>


### [51] [BcQLM: Efficient Vision-Language Understanding with Distilled Q-Gated Cross-Modal Fusion](https://arxiv.org/abs/2509.08715)
*Sike Xiang,Shuang Chen,Amir Atapour-Abarghouei*

Main category: cs.CV

TL;DR: 轻量级多模态框架BcQLM，基于BreezeCLIP，参数仅12亿，高效且性能接近标准MLLMs，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）的大规模架构在资源受限环境中部署面临挑战，需开发轻量高效模型以满足实际应用需求。

Method: 提出了一种基于BreezeCLIP的轻量级视觉语言编码器，整体参数仅12亿，显著降低了计算成本。

Result: 在多个数据集上的实验表明，该模型在保持与标准尺寸MLLMs相当性能的同时，显著降低了计算成本。

Conclusion: BcQLM（BreezeCLIP-enhanced Q-Gated Multimodal Language Model）为资源受限环境提供了一种轻量级且高性能的多模态大型语言模型框架，平衡了准确性与效率。

Abstract: As multimodal large language models (MLLMs) advance, their large-scale
architectures pose challenges for deployment in resource-constrained
environments. In the age of large models, where energy efficiency,
computational scalability and environmental sustainability are paramount, the
development of lightweight and high-performance models is critical for
real-world applications. As such, we propose a lightweight MLLM framework for
end-to-end visual question answering. Our proposed approach centres on
BreezeCLIP, a compact yet powerful vision-language encoder optimised for
efficient multimodal understanding. With only 1.2 billion parameters overall,
our model significantly reduces computational cost while achieving performance
comparable to standard-size MLLMs. Experiments conducted on multiple datasets
further validate its effectiveness in balancing accuracy and efficiency. The
modular and extensible design enables generalisation to broader multimodal
tasks. The proposed lightweight vision-language framework is denoted as BcQLM
(BreezeCLIP-enhanced Q-Gated Multimodal Language Model). It offers a promising
path toward deployable MLLMs under practical hardware constraints. The source
code is available at https://github.com/thico0224/BcQLM.

</details>


### [52] [CrowdQuery: Density-Guided Query Module for Enhanced 2D and 3D Detection in Crowded Scenes](https://arxiv.org/abs/2509.08738)
*Marius Dähling,Sebastian Krebs,J. Marius Zöllner*

Main category: cs.CV

TL;DR: CQ方法通过整合对象密度信息，提升基于Transformer的检测器在拥挤场景中的2D和3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有密度图定义通常依赖于头部位置或基于对象空间统计，但缺乏对个体边界框尺寸的考虑。CQ方法旨在填补这一空白，提升拥挤场景中的检测性能。

Method: CQ方法的核心是CQ模块，该模块预测并嵌入对象密度图，将密度信息系统地整合到解码器中。扩展了现有密度图定义，包括个体边界框尺寸。

Result: 在STCrowd数据集上的实验表明，CQ方法显著提升了基础模型的性能，优于大多数最先进方法。在CrowdHuman数据集上的进一步测试验证了其普适性。

Conclusion: 本文提出的CrowdQuery（CQ）方法通过整合对象密度信息，显著提升了基于Transformer的检测器在拥挤场景中的性能，且适用于2D和3D检测。

Abstract: This paper introduces a novel method for end-to-end crowd detection that
leverages object density information to enhance existing transformer-based
detectors. We present CrowdQuery (CQ), whose core component is our CQ module
that predicts and subsequently embeds an object density map. The embedded
density information is then systematically integrated into the decoder.
Existing density map definitions typically depend on head positions or
object-based spatial statistics. Our method extends these definitions to
include individual bounding box dimensions. By incorporating density
information into object queries, our method utilizes density-guided queries to
improve detection in crowded scenes. CQ is universally applicable to both 2D
and 3D detection without requiring additional data. Consequently, we are the
first to design a method that effectively bridges 2D and 3D detection in
crowded environments. We demonstrate the integration of CQ into both a general
2D and 3D transformer-based object detector, introducing the architectures CQ2D
and CQ3D. CQ is not limited to the specific transformer models we selected.
Experiments on the STCrowd dataset for both 2D and 3D domains show significant
performance improvements compared to the base models, outperforming most
state-of-the-art methods. When integrated into a state-of-the-art crowd
detector, CQ can further improve performance on the challenging CrowdHuman
dataset, demonstrating its generalizability. The code is released at
https://github.com/mdaehl/CrowdQuery.

</details>


### [53] [ArgoTweak: Towards Self-Updating HD Maps through Structured Priors](https://arxiv.org/abs/2509.08764)
*Lena Wild,Rafael Valencia,Patric Jensfelt*

Main category: cs.CV

TL;DR: ArgoTweak是首个提供真实地图先验的数据集，通过原子级修改框架实现可解释的高清地图自更新，显著缩小sim2real差距。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖合成先验导致不一致性和显著的sim2real差距，缺乏包含先验地图、当前地图和传感器数据的公开数据集。

Method: 采用双射映射框架，将大规模修改分解为地图元素级别的细粒度原子级变更，确保可解释性。

Result: 实验表明，在ArgoTweak上训练的模型显著缩小了sim2real差距，结构化先验和详细变更标注对性能提升至关重要。

Conclusion: ArgoTweak通过提供真实地图先验、细粒度原子级修改框架和详细变更标注，显著缩小了sim2real差距，为可解释的高清地图自更新设立了新基准。

Abstract: Reliable integration of prior information is crucial for self-verifying and
self-updating HD maps. However, no public dataset includes the required triplet
of prior maps, current maps, and sensor data. As a result, existing methods
must rely on synthetic priors, which create inconsistencies and lead to a
significant sim2real gap. To address this, we introduce ArgoTweak, the first
dataset to complete the triplet with realistic map priors. At its core,
ArgoTweak employs a bijective mapping framework, breaking down large-scale
modifications into fine-grained atomic changes at the map element level, thus
ensuring interpretability. This paradigm shift enables accurate change
detection and integration while preserving unchanged elements with high
fidelity. Experiments show that training models on ArgoTweak significantly
reduces the sim2real gap compared to synthetic priors. Extensive ablations
further highlight the impact of structured priors and detailed change
annotations. By establishing a benchmark for explainable, prior-aided HD
mapping, ArgoTweak advances scalable, self-improving mapping solutions. The
dataset, baselines, map modification toolbox, and further resources are
available at https://kth-rpl.github.io/ArgoTweak/.

</details>


### [54] [Calibrating MLLM-as-a-judge via Multimodal Bayesian Prompt Ensembles](https://arxiv.org/abs/2509.08777)
*Eric Slyman,Mehrab Tanjim,Kushal Kafle,Stefan Lee*

Main category: cs.CV

TL;DR: MMB方法通过结合贝叶斯提示集成和图像聚类，动态分配提示权重，显著提升了多模态评估的准确性和校准效果。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在评估文本到图像生成系统时存在偏见、过度自信和性能不一致的问题，现有集成方法在多模态任务中表现不佳。

Method: 提出了一种名为多模态贝叶斯提示集成（MMB）的新方法，结合贝叶斯提示集成和图像聚类，动态分配提示权重。

Result: 在HPSv2和MJBench两个TTI基准测试中，MMB在人类注释对齐和校准方面优于现有基线。

Conclusion: 研究强调了多模态特定策略在评估校准中的重要性，并为可靠的大规模TTI评估提供了一条有前景的路径。

Abstract: Multimodal large language models (MLLMs) are increasingly used to evaluate
text-to-image (TTI) generation systems, providing automated judgments based on
visual and textual context. However, these "judge" models often suffer from
biases, overconfidence, and inconsistent performance across diverse image
domains. While prompt ensembling has shown promise for mitigating these issues
in unimodal, text-only settings, our experiments reveal that standard
ensembling methods fail to generalize effectively for TTI tasks. To address
these limitations, we propose a new multimodal-aware method called Multimodal
Mixture-of-Bayesian Prompt Ensembles (MMB). Our method uses a Bayesian prompt
ensemble approach augmented by image clustering, allowing the judge to
dynamically assign prompt weights based on the visual characteristics of each
sample. We show that MMB improves accuracy in pairwise preference judgments and
greatly enhances calibration, making it easier to gauge the judge's true
uncertainty. In evaluations on two TTI benchmarks, HPSv2 and MJBench, MMB
outperforms existing baselines in alignment with human annotations and
calibration across varied image content. Our findings highlight the importance
of multimodal-specific strategies for judge calibration and suggest a promising
path forward for reliable large-scale TTI evaluation.

</details>


### [55] [Quantifying Accuracy of an Event-Based Star Tracker via Earth's Rotation](https://arxiv.org/abs/2509.08794)
*Dennis Melamed,Connor Hashemi,Scott McCloskey*

Main category: cs.CV

TL;DR: 事件相机通过地球自转验证星跟踪精度，误差18.47角秒，适用于低成本低延迟应用。


<details>
  <summary>Details</summary>
Motivation: 解决事件相机在星跟踪中缺乏准确地面真实数据的问题，验证其精度。

Method: 通过静态安装事件相机并指向夜空，利用地球自转作为唯一运动源，生成事件流并处理以估计方向，与国际地球自转参考系统（IERS）数据对比。

Result: 事件相机系统达到均方根误差18.47角秒和平均误差78.84角秒。

Conclusion: 事件相机在星跟踪姿态确定中展现出潜力，其精度和低延迟特性使其适用于低成本应用。

Abstract: Event-based cameras (EBCs) are a promising new technology for star
tracking-based attitude determination, but prior studies have struggled to
determine accurate ground truth for real data. We analyze the accuracy of an
EBC star tracking system utilizing the Earth's motion as the ground truth for
comparison. The Earth rotates in a regular way with very small irregularities
which are measured to the level of milli-arcseconds. By keeping an event camera
static and pointing it through a ground-based telescope at the night sky, we
create a system where the only camera motion in the celestial reference frame
is that induced by the Earth's rotation. The resulting event stream is
processed to generate estimates of orientation which we compare to the
International Earth Rotation and Reference System (IERS) measured orientation
of the Earth. The event camera system is able to achieve a root mean squared
across error of 18.47 arcseconds and an about error of 78.84 arcseconds.
Combined with the other benefits of event cameras over framing sensors (reduced
computation due to sparser data streams, higher dynamic range, lower energy
consumption, faster update rates), this level of accuracy suggests the utility
of event cameras for low-cost and low-latency star tracking. We provide all
code and data used to generate our results:
https://gitlab.kitware.com/nest-public/telescope_accuracy_quantification.

</details>


### [56] [Handling Multiple Hypotheses in Coarse-to-Fine Dense Image Matching](https://arxiv.org/abs/2509.08805)
*Matthieu Vilain,Rémi Giraud,Yannick Berthoumieu,Guillaume Bourmaud*

Main category: cs.CV

TL;DR: BEAMER通过多假设预测和波束搜索策略，显著提升了密集图像匹配的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在深度不连续或目标图像为源图像强放大时，单个对应假设可能导致错误匹配，因此需要探索多假设预测。

Method: 采用波束搜索策略在多尺度上传播多个假设，并将这些假设整合到交叉注意力层中，构建了名为BEAMER的新架构。

Result: BEAMER在多尺度上保留和传播多个假设，相比现有方法表现出更强的鲁棒性。

Conclusion: BEAMER通过在多尺度上保留和传播多个对应假设，显著提升了密集图像匹配的鲁棒性，特别是在深度不连续或目标图像为源图像强放大的情况下。

Abstract: Dense image matching aims to find a correspondent for every pixel of a source
image in a partially overlapping target image. State-of-the-art methods
typically rely on a coarse-to-fine mechanism where a single correspondent
hypothesis is produced per source location at each scale. In challenging cases
-- such as at depth discontinuities or when the target image is a strong
zoom-in of the source image -- the correspondents of neighboring source
locations are often widely spread and predicting a single correspondent
hypothesis per source location at each scale may lead to erroneous matches. In
this paper, we investigate the idea of predicting multiple correspondent
hypotheses per source location at each scale instead. We consider a beam search
strategy to propagat multiple hypotheses at each scale and propose integrating
these multiple hypotheses into cross-attention layers, resulting in a novel
dense matching architecture called BEAMER. BEAMER learns to preserve and
propagate multiple hypotheses across scales, making it significantly more
robust than state-of-the-art methods, especially at depth discontinuities or
when the target image is a strong zoom-in of the source image.

</details>


### [57] [GeneVA: A Dataset of Human Annotations for Generative Text to Video Artifacts](https://arxiv.org/abs/2509.08818)
*Jenna Kang,Maria Silva,Patsorn Sangkloy,Kenneth Chen,Niall Williams,Qi Sun*

Main category: cs.CV

TL;DR: GeneVA是一个专注于视频生成时空伪影的大规模人工标注数据集，旨在填补系统性基准测试的空白，支持模型评估和质量改进。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集主要关注生成图像，而视频生成的时空复杂性导致缺乏系统性基准测试，难以解决生成过程中的随机性和不可预测的伪影问题。

Method: 引入GeneVA，一个大规模的人工标注数据集，专注于从自然文本提示生成的视频中的时空伪影。

Result: GeneVA数据集能够支持关键应用，如模型性能基准测试和生成视频质量的提升。

Conclusion: GeneVA数据集旨在填补视频生成领域系统性基准测试的空白，通过提供大规模的人工标注数据，帮助评估和改进生成视频的质量。

Abstract: Recent advances in probabilistic generative models have extended capabilities
from static image synthesis to text-driven video generation. However, the
inherent randomness of their generation process can lead to unpredictable
artifacts, such as impossible physics and temporal inconsistency. Progress in
addressing these challenges requires systematic benchmarks, yet existing
datasets primarily focus on generative images due to the unique spatio-temporal
complexities of videos. To bridge this gap, we introduce GeneVA, a large-scale
artifact dataset with rich human annotations that focuses on spatio-temporal
artifacts in videos generated from natural text prompts. We hope GeneVA can
enable and assist critical applications, such as benchmarking model performance
and improving generative video quality.

</details>


### [58] [RewardDance: Reward Scaling in Visual Generation](https://arxiv.org/abs/2509.08826)
*Jie Wu,Yu Gao,Zilyu Ye,Ming Li,Liang Li,Hanzhong Guo,Jie Liu,Zeyue Xue,Xiaoxia Hou,Wei Liu,Yan Zeng,Weilin Huang*

Main category: cs.CV

TL;DR: RewardDance是一个可扩展的奖励建模框架，通过生成式奖励范式解决了视觉生成中的奖励模型扩展和奖励黑客问题，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型在视觉生成中存在架构和输入模态限制，且Bradley-Terry损失与VLMs的下一个标记预测机制不匹配，导致扩展困难。此外，RLHF优化过程中存在奖励黑客问题。

Method: 引入RewardDance框架，通过将奖励分数重新定义为模型预测“是”标记的概率，与VLM架构内在对齐，支持模型和上下文两个维度的扩展。

Result: RewardDance在文本到图像、文本到视频和图像到视频生成任务中显著优于现有方法，并解决了奖励黑客问题，保持了高奖励方差和多样性输出。

Conclusion: RewardDance通过创新的生成式奖励范式有效解决了奖励模型在视觉生成中的扩展问题，并显著提升了生成质量，同时解决了奖励黑客问题。

Abstract: Reward Models (RMs) are critical for improving generation models via
Reinforcement Learning (RL), yet the RM scaling paradigm in visual generation
remains largely unexplored. It primarily due to fundamental limitations in
existing approaches: CLIP-based RMs suffer from architectural and input
modality constraints, while prevalent Bradley-Terry losses are fundamentally
misaligned with the next-token prediction mechanism of Vision-Language Models
(VLMs), hindering effective scaling. More critically, the RLHF optimization
process is plagued by Reward Hacking issue, where models exploit flaws in the
reward signal without improving true quality. To address these challenges, we
introduce RewardDance, a scalable reward modeling framework that overcomes
these barriers through a novel generative reward paradigm. By reformulating the
reward score as the model's probability of predicting a "yes" token, indicating
that the generated image outperforms a reference image according to specific
criteria, RewardDance intrinsically aligns reward objectives with VLM
architectures. This alignment unlocks scaling across two dimensions: (1) Model
Scaling: Systematic scaling of RMs up to 26 billion parameters; (2) Context
Scaling: Integration of task-specific instructions, reference examples, and
chain-of-thought (CoT) reasoning. Extensive experiments demonstrate that
RewardDance significantly surpasses state-of-the-art methods in text-to-image,
text-to-video, and image-to-video generation. Crucially, we resolve the
persistent challenge of "reward hacking": Our large-scale RMs exhibit and
maintain high reward variance during RL fine-tuning, proving their resistance
to hacking and ability to produce diverse, high-quality outputs. It greatly
relieves the mode collapse problem that plagues smaller models.

</details>


### [59] [SAFT: Shape and Appearance of Fabrics from Template via Differentiable Physical Simulations from Monocular Video](https://arxiv.org/abs/2509.08828)
*David Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: 本文提出了一种结合3D几何重建和外观估计的新方法，通过物理模拟和可微分渲染，显著提高了单目RGB视频中3D重建的准确性和外观估计质量。


<details>
  <summary>Details</summary>
Motivation: 三维动态场景重建是计算机视觉领域中一个具有挑战性的任务，尤其是在仅使用单目RGB视频序列的情况下。本文旨在通过结合3D几何重建和外观估计，提高重建的准确性和渲染质量。

Method: 本文提出了一种结合物理模拟和可微分渲染的新方法，并引入了两个新的正则化项来解决单目视频中的深度模糊问题。

Result: 与现有方法相比，本文方法将3D重建误差降低了2.64倍，且每场景平均运行时间为30分钟。此外，优化的运动质量足以实现外观估计，从单目RGB视频中恢复出清晰的细节。

Conclusion: 通过结合3D几何重建和外观估计，本文提出的方法在仅使用单目RGB视频序列的情况下，显著提高了3D重建的准确性，并实现了高质量的外观估计。

Abstract: The reconstruction of three-dimensional dynamic scenes is a well-established
yet challenging task within the domain of computer vision. In this paper, we
propose a novel approach that combines the domains of 3D geometry
reconstruction and appearance estimation for physically based rendering and
present a system that is able to perform both tasks for fabrics, utilizing only
a single monocular RGB video sequence as input. In order to obtain realistic
and high-quality deformations and renderings, a physical simulation of the
cloth geometry and differentiable rendering are employed. In this paper, we
introduce two novel regularization terms for the 3D reconstruction task that
improve the plausibility of the reconstruction by addressing the depth
ambiguity problem in monocular video. In comparison with the most recent
methods in the field, we have reduced the error in the 3D reconstruction by a
factor of 2.64 while requiring a medium runtime of 30 min per scene.
Furthermore, the optimized motion achieves sufficient quality to perform an
appearance estimation of the deforming object, recovering sharp details from
this single monocular RGB video.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [60] [Matisse: Visualizing Measured Internet Latencies as Manifolds](https://arxiv.org/abs/2509.08097)
*Stephen Jasina,Loqman Salamatian,Joshua Mathews,Scott Anderson,Paul Barford,Mark Crovella,Walter Willinger*

Main category: cs.NI

TL;DR: 该论文介绍了Matisse工具，通过图捕捉互联网延迟数据的关键信息，生成并可视化流形，展示了其在揭示网络拓扑特性中的实用性。


<details>
  <summary>Details</summary>
Motivation: 流形可以表示现实世界测量数据的复杂拓扑空间，可视化这些流形有助于展示其拓扑特性（如曲率）并揭示底层数据的重要属性（如测量中的异常）。

Method: 该方法利用一系列图来捕捉数据中的关键信息，包括定义良好的顶点位置和边的Ricci曲率信息，然后生成一个保持顶点地理位置的曲面流形，其曲率特性由图的Ricci曲率值决定。

Result: 生成的流形突出了关键连接区域，并定义了一个“互联网延迟空间”实例，其中延迟测量表现为测地线。

Conclusion: 该论文提出了一种名为Matisse的工具，用于生成、可视化和操作基于实际互联网延迟测量的流形，并通过两个案例研究展示了其效用。

Abstract: Manifolds are complex topological spaces that can be used to represent
datasets of real-world measurements. Visualizing such manifolds can help with
illustrating their topological characteristics (e.g., curvature) and providing
insights into important properties of the underlying data (e.g., anomalies in
the measurements). In this paper, we describe a new methodology and system for
generating and visualizing manifolds that are inferred from actual Internet
latency measurements between different cities and are projected over a 2D
Euclidean space (e.g., a geographic map). Our method leverages a series of
graphs that capture critical information contained in the data, including
well-defined locations (for vertices) and Ricci curvature information (for
edges). Our visualization approach then generates a curved surface (manifold)
in which (a) geographical locations of vertices are maintained and (b) the
Ricci curvature values of the graph edges determine the curvature properties of
the manifold. The resulting manifold highlights areas of critical connectivity
and defines an instance of "Internet delay space" where latency measurements
manifest as geodesics. We describe details of our method and its implementation
in a tool, which we call Matisse, for generating, visualizing and manipulating
manifolds projected onto a base map. We illustrate Matisse with two case
studies: a simple example to demonstrate key concepts, and visualizations of
the US public Internet to show Matisse's utility.

</details>


### [61] [UTM Performance Under Stressing Scenarios](https://arxiv.org/abs/2509.08124)
*Ian Jessen*

Main category: cs.NI

TL;DR: ANAMLL虚拟实验室模拟高压力场景，验证UTM系统在飞行重新规划和网络性能方面的不足，为空域管理优化提供依据。


<details>
  <summary>Details</summary>
Motivation: 随着无人机和先进空中交通工具的普及，需要开发新型空域管理系统（如UTM和PSU网络），但其在高压力条件下的行为尚未充分研究。

Method: 通过虚拟系统集成实验室（ANAMLL）模拟高压力需求场景，分析UTM系统的性能，包括飞行重新规划能力和网络连接对空域访问的影响。

Result: ANAMLL在模拟的高压力需求场景中，发现UTM系统存在无法在规定时间窗口内完成飞行重新规划的问题，并展示了网络连接性能对用户空域访问的影响。

Conclusion: ANAMLL虚拟系统集成实验室通过模拟高压力需求场景，验证了UTM系统在飞行重新规划和网络连接性能方面的局限性，为未来空域管理系统的优化提供了重要参考。

Abstract: Proliferation of new classes of airspace participants, including uncrewed and
advanced aerial mobility vehicles, necessitates the development and deployment
of novel airspace management solutions, such as the Unmanned Traffic Management
(UTM) system and the Provider of Services to UAM (PSU) Network. The efficacy of
such systems has been demonstrated on multiple occasions via real-world
deployments in limited test environments, however exploration of system
behavior under stressing conditions requires the development of appropriate
modeling and simulation (M&S) environments. Autonomy Networks for Advanced
Mobility at Lincoln Laboratory (ANAMLL) is a virtual Systems Integration
Laboratory (SIL) designed to host federated autonomy networks, such as a UTM or
PSU Network, and to enable test and validation at scales not available in
real-world deployments. As an example of ANAMLL's utility, we explore the
performance of a representative UTM network during a stressing demand scenario.
In a close examination of the demand scenario, ANAMLL demonstrates a UTM system
demand point at which in-flight replanning can no longer be accomplished within
an allowable time window. In a second analysis of the same scenario, ANAMLL
demonstrates the impact of network connectivity performance on end-user
airspace access.

</details>


### [62] [Enhancing 6G Network Security and Incident Response through Integrated VNF and SDN Technologies](https://arxiv.org/abs/2509.08274)
*Abdul Razaque,Abitkhanova Zhadyra Abitkhanovna*

Main category: cs.NI

TL;DR: VNFSDN结合VNF和SDN技术，提升网络安全效率和韧性，动态适应需求变化，减少低速互联网对事件响应的负面影响。


<details>
  <summary>Details</summary>
Motivation: 低速互联网对事件响应产生负面影响，如团队合作效率降低、检测延迟、行动效率低下和风险增加，因此需要一种能够动态适应并提升网络安全的方法。

Method: 通过整合虚拟网络功能（VNF）和软件定义网络（SDN）技术建立虚拟网络功能服务交付网络（VNFSDN），并结合机器学习和人工智能。

Result: VNFSDN能够实时分析大量6G数据，动态适应变化的安全需求和网络条件，显著提升网络安全性并减少停机时间。

Conclusion: VNFSDN通过整合VNF和SDN技术，显著提升了网络安全的效率和效果，增强了网络韧性，并能够动态适应安全需求和连接条件的变化。

Abstract: Low-speed internet can negatively affect incident response in a number of
ways, including decreased teamwork, delayed detection, inefficient action, and
elevated risk. Delayed data acquisition and processing may result from
inadequate internet connectivity, hindering security teams' ability to obtain
the necessary information for timely and effective responses. Each of these
factors may augment the organization's susceptibility to security incidents and
their subsequent ramifications. This article establishes a virtual network
function service delivery network (VNFSDN) through the integration of virtual
network function (VNF) and software-defined networking (SDN) technologies. The
VNFSDN approach enhances network security effectiveness and efficiency while
reducing the danger of breaches. This method assists security services in
rapidly assessing vast quantities of data generated by 6G networks. VNFSDN
adapts dynamically to changing safety requirements and connection conditions
through the use of SDN and VNF. This flexibility enables enterprises to
mitigate or halt the impact of cyberattacks by swiftly identifying and
addressing security threats. The VNFSDN enhances network resilience, allowing
operators to proactively mitigate possible security attacks and minimize
downtime. The incorporation of machine learning and artificial intelligence
into VNFSDN can significantly improve network security and threat detection
capabilities. The VNFSDN integrates VNF and SDN technologies to deliver
security services that analyze vast quantities of 6G data in real time. As
security requirements and network conditions evolve, it adapts dynamically to
enhance network resilience and facilitate proactive threat detection.

</details>


### [63] [Ubiquitous Intelligence Via Wireless Network-Driven LLMs Evolution](https://arxiv.org/abs/2509.08400)
*Xingkun Yin,Feiran You,Hongyang Du,Kaibin Huang*

Main category: cs.NI

TL;DR: 论文提出无线网络与LLMs协同进化的范式，实现可持续智能提升。


<details>
  <summary>Details</summary>
Motivation: 解决静态模型部署在多样化和资源受限环境中的局限性，实现可扩展和持续智能提升。

Method: 采用无线网络驱动的生态系统，支持系统协调的终身学习，并利用LLMs推动下一代网络的适应性发展。

Result: 展示了无线网络与LLMs的协同进化如何推动更自适应和响应迅速的下一代网络发展。

Conclusion: 该论文提出了一种通过无线网络与大型语言模型（LLMs）协同进化的自改进系统范式，旨在实现可持续的能力提升。

Abstract: We introduce ubiquitous intelligence as a paradigm where Large Language
Models (LLMs) evolve within wireless network-driven ecosystems. Unlike static
model deployments, this approach enables scalable and continuous intelligence
ascension through coordination between networks and LLMs. Wireless networks
support system-orchestrated lifelong learning, while LLMs drive the
next-generation network development that is more adaptive and responsive. This
co-evolution highlights a shift toward self-improving systems, sustaining
capability growth across diverse and resource-constrained environments.

</details>


### [64] [SKYLINK: Scalable and Resilient Link Management in LEO Satellite Network](https://arxiv.org/abs/2509.08455)
*Wanja de Sombre,Arash Asadi,Debopam Bhattacherjee,Deepak Vasisht,Andrea Ortiz*

Main category: cs.NI

TL;DR: SKYLINK是一种分布式学习策略，显著提升了LEO卫星网络的性能，降低了延迟和丢包率，同时保持了低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: LEO卫星网络的高移动性、动态流量模式和潜在的链路故障对高效和弹性的路由提出了重大挑战。

Method: 作者将LEO卫星网络建模为一个时变图，由卫星和地面站组成。每个卫星独立决定如何实时分配其传入流量到相邻节点。由于在规模和链路容量不确定性下寻找最优解决方案的不可行性，提出了SKYLINK。

Result: 对于2540万用户，SKYLINK将平均延迟和丢包率的加权和降低了29%相对于bent-pipe方法，92%相对于Dijkstra。丢包率降低了95%相对于k最短路径，99%相对于Dijkstra，74%相对于bent-pipe基线，同时实现了高达46%的更高吞吐量。

Conclusion: SKYLINK是一种新型的完全分布式学习策略，用于LEO卫星网络中的链路管理。它能够适应时变的网络条件，确保实时响应性、可扩展性和网络故障的弹性，同时保持低通信开销和计算复杂性。

Abstract: The rapid growth of space-based services has established LEO satellite
networks as a promising option for global broadband connectivity.
Next-generation LEO networks leverage inter-satellite links (ISLs) to provide
faster and more reliable communications compared to traditional bent-pipe
architectures, even in remote regions. However, the high mobility of
satellites, dynamic traffic patterns, and potential link failures pose
significant challenges for efficient and resilient routing. To address these
challenges, we model the LEO satellite network as a time-varying graph
comprising a constellation of satellites and ground stations. Our objective is
to minimize a weighted sum of average delay and packet drop rate. Each
satellite independently decides how to distribute its incoming traffic to
neighboring nodes in real time. Given the infeasibility of finding optimal
solutions at scale, due to the exponential growth of routing options and
uncertainties in link capacities, we propose SKYLINK, a novel fully distributed
learning strategy for link management in LEO satellite networks. SKYLINK
enables each satellite to adapt to the time-varying network conditions,
ensuring real-time responsiveness, scalability to millions of users, and
resilience to network failures, while maintaining low communication overhead
and computational complexity. To support the evaluation of SKYLINK at global
scale, we develop a new simulator for large-scale LEO satellite networks. For
25.4 million users, SKYLINK reduces the weighted sum of average delay and drop
rate by 29% compared to the bent-pipe approach, and by 92% compared to
Dijkstra. It lowers drop rates by 95% relative to k-shortest paths, 99%
relative to Dijkstra, and 74% compared to the bent-pipe baseline, while
achieving up to 46% higher throughput. At the same time, SKYLINK maintains
constant computational complexity with respect to constellation size.

</details>


### [65] [Design and Development of a Scalable and Energy-Efficient Localization Framework Leveraging LoRa Ranging-Capable Transceivers](https://arxiv.org/abs/2509.08488)
*Hasan Albinsaid,Bodhibrata Mukhopadhyay,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 论文提出一种LoRa测距协调框架，通过同步唤醒窗口调度显著降低能耗，实验验证节点单电池可待机九个月且测距精度达五米。


<details>
  <summary>Details</summary>
Motivation: Semtech SX1280 LoRa收发器虽具备低成本、低功耗和精确测距能力，但缺乏有效的系统级框架来管理睡眠-唤醒协调和角色分配，导致能量效率不足。

Method: 设计了符合框架协议的定制节点，采用短同步唤醒窗口调度策略，减少对精确连续定时的依赖并缓解低成本振荡器的漂移。

Result: 实验结果显示，节点可定期唤醒检查指令，在待机模式下单枚纽扣电池供电可持续九个月，并能在近实时需求下进行测距操作，定位精度保持在五米内。

Conclusion: 该论文提出的协调框架显著降低了功耗，同时保持了芯片固有的精确测距能力，实验证明节点可以在单枚纽扣电池供电下待机长达九个月。

Abstract: Precise and energy-efficient localization is a critical requirement in many
Internet of Things (IoT) applications, particularly in large-scale deployments
such as asset tagging, agriculture, and smart cities, where long battery life
and cost-effectiveness are crucial. The Semtech SX1280 LoRa transceiver
presents a promising solution for IoT localization. It combines low cost, low
power, and precise ranging capability over distances of up to 1 km. However,
the ranging process requires two devices to be simultaneously active, one
initiating the ranging request and the other responding to it, which can lead
to significant energy expenditure if not properly managed. Despite the
transceiver's excellent performance, no existing system-level framework
effectively manages sleep-wake coordination and role assignment needed for
energy-efficient operation. This paper presents a coordination framework that
significantly reduces power consumption while maintaining the inherent precise
ranging capability of the chip. The framework schedules short, synchronized
wake-up windows between the initiator and the responder, allowing devices to
remain in deep sleep for most of their duty cycle. This scheduling strategy
minimizes reliance on precise continuous timing and mitigates drift in low-cost
oscillators. To validate the framework, we designed and developed custom nodes
that are compliant with the framework's protocol. Experimental results show
that the proposed approach allows a node to stay in ultra-low power mode and
wake periodically to check for instructions. The node can remain in standby
mode for up to nine months on a single coin cell battery and can perform
ranging operations on demand in near real-time, all while maintaining a
localization accuracy within five meters.

</details>


### [66] [The Role of Legacy Mobile Networks in Infrastructure Resilience: Evidence from the Southern Brazil Flood](https://arxiv.org/abs/2509.08595)
*Daniel Meyer,Lisandro Z Granville,Leandro M. Bertholdo*

Main category: cs.NI

TL;DR: 研究分析了巴西洪水期间移动网络的脆弱性，发现传统技术（2G/3G）在危机中更具韧性，呼吁加强灾害感知的基础设施规划。


<details>
  <summary>Details</summary>
Motivation: 调查2024年5月巴西南里奥格兰德州极端洪水期间移动通信网络的韧性。

Method: 基于监管数据和运营商的技术洞察，研究确定了移动网络中断的主要原因。

Result: 揭示了现代网络（4G/5G）在事件中的显著脆弱性，以及传统技术（2G/3G）在恶劣条件下维持基本连接的关键作用。

Conclusion: 研究强调了在灾害感知基础设施规划中考虑传统系统、多样化电力供应策略和弹性网络设计的必要性，以增强未来危机中的服务连续性。

Abstract: This paper investigates the resilience of mobile communication networks
during the extreme flooding that affected Rio Grande do Sul, Brazil, in May
2024. Based on regulatory data and technical insights from operators, the study
identifies the leading causes of mobile network disruptions, primarily related
to flooding and prolonged power outages. The results reveal the significant
vulnerability of modern networks (4G/5G) during the event and the essential
role played by legacy technologies (2G/3G) in sustaining basic connectivity
under adverse conditions. The findings underscore the necessity of
disaster-aware infrastructure planning, taking into account the ongoing
significance of legacy systems, diversified power supply strategies, and
resilient network designs to enhance service continuity during future crises.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [67] [Learning-Based Planning for Improving Science Return of Earth Observation Satellites](https://arxiv.org/abs/2509.07997)
*Abigail Breitfeld,Alberto Candela,Juan Delfa,Akseli Kangaslahti,Itai Zilberstein,Steve Chien,David Wettergreen*

Main category: cs.AI

TL;DR: 论文提出两种学习型动态目标定位方法（强化学习和模仿学习），相比传统方法，模仿学习和强化学习分别提升10.0%和13.7%的科学信息收集效率，且训练数据需求低。


<details>
  <summary>Details</summary>
Motivation: 地球观测卫星存在局限性，如轨道固定、传感器视野有限、操作资源消耗大。动态目标定位通过智能调整主仪器配置和指向，优化数据收集效率。

Method: 论文提出了两种基于学习的方法：强化学习和模仿学习。这些方法基于动态规划解决方案，规划采样位置的序列。

Result: 实验表明，模仿学习平均比最佳启发式方法提升10.0%，强化学习平均提升13.7%。两种方法在少量数据下也能有效训练。

Conclusion: 论文展示了基于强化学习和模仿学习的动态目标定位方法，相比传统启发式方法，这两种学习方法在收集科学信息方面表现更优，模仿学习平均提升10.0%，强化学习平均提升13.7%。此外，两种方法在少量数据下也能有效训练。

Abstract: Earth observing satellites are powerful tools for collecting scientific
information about our planet, however they have limitations: they cannot easily
deviate from their orbital trajectories, their sensors have a limited field of
view, and pointing and operating these sensors can take a large amount of the
spacecraft's resources. It is important for these satellites to optimize the
data they collect and include only the most important or informative
measurements. Dynamic targeting is an emerging concept in which satellite
resources and data from a lookahead instrument are used to intelligently
reconfigure and point a primary instrument. Simulation studies have shown that
dynamic targeting increases the amount of scientific information gathered
versus conventional sampling strategies. In this work, we present two different
learning-based approaches to dynamic targeting, using reinforcement and
imitation learning, respectively. These learning methods build on a dynamic
programming solution to plan a sequence of sampling locations. We evaluate our
approaches against existing heuristic methods for dynamic targeting, showing
the benefits of using learning for this application. Imitation learning
performs on average 10.0\% better than the best heuristic method, while
reinforcement learning performs on average 13.7\% better. We also show that
both learning methods can be trained effectively with relatively small amounts
of data.

</details>


### [68] [EnvX: Agentize Everything with Agentic AI](https://arxiv.org/abs/2509.08088)
*Linyao Chen,Zimian Peng,Yingxuan Yang,Yikun Wang,Wenzheng Tom Tang,Hiroki H. Kobayashi,Weinan Zhang*

Main category: cs.AI

TL;DR: EnvX 利用 Agentic AI 将 GitHub 仓库转化为智能代理，通过三阶段流程实现自动化操作和协作，显著提升了开源组件的利用效率。


<details>
  <summary>Details</summary>
Motivation: 当前开源组件的利用方式仍为手动、易错且脱节，开发者需面对文档导航、API 理解和集成代码编写等障碍，EnvX 旨在解决这些问题。

Method: EnvX 通过三阶段流程实现：TODO 引导的环境初始化、人类对齐的代理自动化以及代理间（A2A）协议，结合大语言模型能力和结构化工具集成。

Result: 在 GitTaskBench 基准测试中，EnvX 实现了 74.07% 的执行完成率和 51.85% 的任务通过率，优于现有框架。案例研究进一步展示了其通过 A2A 协议支持多仓库协作的能力。

Conclusion: EnvX 将开源仓库从被动的代码资源转变为智能、交互式的代理，推动了开源生态系统的可访问性和协作。

Abstract: The widespread availability of open-source repositories has led to a vast
collection of reusable software components, yet their utilization remains
manual, error-prone, and disconnected. Developers must navigate documentation,
understand APIs, and write integration code, creating significant barriers to
efficient software reuse. To address this, we present EnvX, a framework that
leverages Agentic AI to agentize GitHub repositories, transforming them into
intelligent, autonomous agents capable of natural language interaction and
inter-agent collaboration. Unlike existing approaches that treat repositories
as static code resources, EnvX reimagines them as active agents through a
three-phase process: (1) TODO-guided environment initialization, which sets up
the necessary dependencies, data, and validation datasets; (2) human-aligned
agentic automation, allowing repository-specific agents to autonomously perform
real-world tasks; and (3) Agent-to-Agent (A2A) protocol, enabling multiple
agents to collaborate. By combining large language model capabilities with
structured tool integration, EnvX automates not just code generation, but the
entire process of understanding, initializing, and operationalizing repository
functionality. We evaluate EnvX on the GitTaskBench benchmark, using 18
repositories across domains such as image processing, speech recognition,
document analysis, and video manipulation. Our results show that EnvX achieves
a 74.07% execution completion rate and 51.85% task pass rate, outperforming
existing frameworks. Case studies further demonstrate EnvX's ability to enable
multi-repository collaboration via the A2A protocol. This work marks a shift
from treating repositories as passive code resources to intelligent,
interactive agents, fostering greater accessibility and collaboration within
the open-source ecosystem.

</details>


### [69] [Trust Semantics Distillation for Collaborator Selection via Memory-Augmented Agentic AI](https://arxiv.org/abs/2509.08151)
*Botao Zhu,Jeslyn Wang,Dusit Niyato,Xianbin Wang*

Main category: cs.AI

TL;DR: 提出2TSD模型，通过教师-学生代理架构优化协作设备信任评估，减少开销并提高准确性。


<details>
  <summary>Details</summary>
Motivation: 独立评估所有协作设备的信任度会导致频繁数据交换、复杂推理和动态情境变化，带来显著开销和信任评估效果下降。

Method: 基于大型AI模型（LAM）驱动的教师-学生代理架构，教师代理负责多维信任相关数据收集、任务特定信任语义提取和任务-协作匹配分析。

Result: 实验结果表明，2TSD模型能减少评估时间、降低设备资源消耗，并提高协作选择的准确性。

Conclusion: 提出的2TSD模型通过教师-学生代理架构，显著减少了协作设备评估时间、降低了资源消耗，并提高了选择准确性。

Abstract: Accurate trustworthiness evaluation of potential collaborating devices is
essential for the effective execution of complex computing tasks. This
evaluation process involves collecting diverse trust-related data from
potential collaborators, including historical performance and available
resources, for collaborator selection. However, when each task owner
independently assesses all collaborators' trustworthiness, frequent data
exchange, complex reasoning, and dynamic situation changes can result in
significant overhead and deteriorated trust evaluation. To overcome these
challenges, we propose a task-specific trust semantics distillation (2TSD)
model based on a large AI model (LAM)-driven teacher-student agent
architecture. The teacher agent is deployed on a server with powerful
computational capabilities and an augmented memory module dedicated to
multidimensional trust-related data collection, task-specific trust semantics
extraction, and task-collaborator matching analysis. Upon receiving
task-specific requests from device-side student agents, the teacher agent
transfers the trust semantics of potential collaborators to the student agents,
enabling rapid and accurate collaborator selection. Experimental results
demonstrate that the proposed 2TSD model can reduce collaborator evaluation
time, decrease device resource consumption, and improve the accuracy of
collaborator selection.

</details>


### [70] [Exploratory Retrieval-Augmented Planning For Continual Embodied Instruction Following](https://arxiv.org/abs/2509.08222)
*Minjong Yoo,Jinwoo Jang,Wei-jin Park,Honguk Woo*

Main category: cs.AI

TL;DR: ExRAP框架通过探索增强规划和内存查询优化，提升了动态环境中持续指令跟随任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决动态非平稳环境中持续指令跟随任务中大型语言模型（LLMs）的推理能力不足问题。

Method: 提出了Exploratory Retrieval-Augmented Planning (ExRAP)框架，包括基于信息探索的任务规划和内存增强的查询评估，以及时间一致性优化方案。

Result: 在VirtualHome、ALFRED和CARLA实验中，ExRAP在目标成功率和执行效率上均优于现有方法。

Conclusion: ExRAP框架通过结合探索增强的任务规划和内存增强的查询评估，显著提升了在动态非平稳环境中持续指令跟随任务的性能，实验证明其在多种场景下均优于现有方法。

Abstract: This study presents an Exploratory Retrieval-Augmented Planning (ExRAP)
framework, designed to tackle continual instruction following tasks of embodied
agents in dynamic, non-stationary environments. The framework enhances Large
Language Models' (LLMs) embodied reasoning capabilities by efficiently
exploring the physical environment and establishing the environmental context
memory, thereby effectively grounding the task planning process in time-varying
environment contexts. In ExRAP, given multiple continual instruction following
tasks, each instruction is decomposed into queries on the environmental context
memory and task executions conditioned on the query results. To efficiently
handle these multiple tasks that are performed continuously and simultaneously,
we implement an exploration-integrated task planning scheme by incorporating
the {information-based exploration} into the LLM-based planning process.
Combined with memory-augmented query evaluation, this integrated scheme not
only allows for a better balance between the validity of the environmental
context memory and the load of environment exploration, but also improves
overall task performance. Furthermore, we devise a {temporal consistency
refinement} scheme for query evaluation to address the inherent decay of
knowledge in the memory. Through experiments with VirtualHome, ALFRED, and
CARLA, our approach demonstrates robustness against a variety of embodied
instruction following scenarios involving different instruction scales and
types, and non-stationarity degrees, and it consistently outperforms other
state-of-the-art LLM-based task planning approaches in terms of both goal
success rate and execution efficiency.

</details>


### [71] [Real-world Music Plagiarism Detection With Music Segment Transcription System](https://arxiv.org/abs/2509.08282)
*Seonghyeon Go*

Main category: cs.AI

TL;DR: 该论文提出了一种结合多种MIR技术的音乐抄袭检测系统，通过音乐片段转录和特征相似度计算，实验效果良好，并公开了SMP数据集。


<details>
  <summary>Details</summary>
Motivation: 随着MIR技术的进步，音乐生成和分发变得更加多样化和便捷，因此对音乐知识产权保护的关注增加，以保障个体音乐版权。

Method: 开发了一个音乐片段转录系统，通过从音频录音中提取有音乐意义的片段，结合多种音乐特征计算相似度分数，进行全面的音乐分析。

Result: 提出的方法在音乐抄袭检测实验中表现出良好的效果，并构建了公开的SMP数据集用于音乐相似性研究。

Conclusion: 该论文提出的结合多种MIR技术的音乐抄袭检测系统在实验中显示出良好的效果，并且可以应用于实际音乐场景。此外，公开的SMP数据集为音乐相似性研究提供了真实案例支持。

Abstract: As a result of continuous advances in Music Information Retrieval (MIR)
technology, generating and distributing music has become more diverse and
accessible. In this context, interest in music intellectual property protection
is increasing to safeguard individual music copyrights. In this work, we
propose a system for detecting music plagiarism by combining various MIR
technologies. We developed a music segment transcription system that extracts
musically meaningful segments from audio recordings to detect plagiarism across
different musical formats. With this system, we compute similarity scores based
on multiple musical features that can be evaluated through comprehensive
musical analysis. Our approach demonstrated promising results in music
plagiarism detection experiments, and the proposed method can be applied to
real-world music scenarios. We also collected a Similar Music Pair (SMP)
dataset for musical similarity research using real-world cases. The dataset are
publicly available.

</details>


### [72] [Leveraging AI Agents for Autonomous Networks: A Reference Architecture and Empirical Studies](https://arxiv.org/abs/2509.08312)
*Binghan Wu,Shoufeng Wang,Yunxin Liu,Ya-Qin Zhang,Joseph Sifakis,Ye Ouyang*

Main category: cs.AI

TL;DR: 该研究通过实现AN Agent架构，在5G网络中展示了显著的性能提升，为L4级自主网络的发展提供了实证支持。


<details>
  <summary>Details</summary>
Motivation: 为了实现TM Forum提出的自配置、自修复和自优化系统愿景，网络需要超越反应式自动化，达到真正的认知能力，这是迈向L4级自主网络的关键转折点。

Method: 研究采用了Joseph Sifakis的AN Agent参考架构，部署了协调的主动-被动运行时，并结合混合知识表示，通过一个无线电接入网络（RAN）链路自适应（LA）Agent的实证案例研究来验证框架的潜力。

Result: 在5G NR sub-6 GHz频段中实现了低于10毫秒的实时控制，下行吞吐量比外环链路自适应（OLLA）算法提高了6%，并通过动态调制和编码方案（MCS）优化，将超可靠服务的块错误率（BLER）降低了67%。

Conclusion: 该研究验证了Joseph Sifakis的AN Agent参考架构在实现认知能力方面的可行性，通过动态调制和编码方案优化，显著提升了5G网络的性能，为L4级自主网络的实现提供了关键支持。

Abstract: The evolution toward Level 4 (L4) Autonomous Networks (AN) represents a
strategic inflection point in telecommunications, where networks must transcend
reactive automation to achieve genuine cognitive capabilities--fulfilling TM
Forum's vision of self-configuring, self-healing, and self-optimizing systems
that deliver zero-wait, zero-touch, and zero-fault services. This work bridges
the gap between architectural theory and operational reality by implementing
Joseph Sifakis's AN Agent reference architecture in a functional cognitive
system, deploying coordinated proactive-reactive runtimes driven by hybrid
knowledge representation. Through an empirical case study of a Radio Access
Network (RAN) Link Adaptation (LA) Agent, we validate this framework's
transformative potential: demonstrating sub-10 ms real-time control in 5G NR
sub-6 GHz while achieving 6% higher downlink throughput than Outer Loop Link
Adaptation (OLLA) algorithms and 67% Block Error Rate (BLER) reduction for
ultra-reliable services through dynamic Modulation and Coding Scheme (MCS)
optimization. These improvements confirm the architecture's viability in
overcoming traditional autonomy barriers and advancing critical L4-enabling
capabilities toward next-generation objectives.

</details>


### [73] [Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives](https://arxiv.org/abs/2509.08380)
*Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu*

Main category: cs.AI

TL;DR: Co-Investigator AI 是一个代理框架，通过整合多个专门代理和实时验证，显著提升SAR生成的效率和合规性。


<details>
  <summary>Details</summary>
Motivation: 传统SAR生成方法成本高、扩展性差，而现有LLM存在事实幻觉、犯罪类型对齐不足和解释性差的问题，无法满足合规领域的高风险要求。

Method: 采用自主代理架构，整合规划、犯罪类型检测、外部情报收集和合规验证的专门代理，并配备动态内存管理、AI隐私保护层和实时验证代理。

Result: Co-Investigator AI 能够显著提升SAR生成速度和准确性，支持复杂金融犯罪场景，并让合规团队专注于高阶分析工作。

Conclusion: Co-Investigator AI 框架为合规报告带来了新时代，结合了AI效率和领域专业知识，实现了可扩展、可靠且透明的SAR生成。

Abstract: Generating regulatorily compliant Suspicious Activity Report (SAR) remains a
high-cost, low-scalability bottleneck in Anti-Money Laundering (AML) workflows.
While large language models (LLMs) offer promising fluency, they suffer from
factual hallucination, limited crime typology alignment, and poor
explainability -- posing unacceptable risks in compliance-critical domains.
This paper introduces Co-Investigator AI, an agentic framework optimized to
produce Suspicious Activity Reports (SARs) significantly faster and with
greater accuracy than traditional methods. Drawing inspiration from recent
advances in autonomous agent architectures, such as the AI Co-Scientist, our
approach integrates specialized agents for planning, crime type detection,
external intelligence gathering, and compliance validation. The system features
dynamic memory management, an AI-Privacy Guard layer for sensitive data
handling, and a real-time validation agent employing the Agent-as-a-Judge
paradigm to ensure continuous narrative quality assurance. Human investigators
remain firmly in the loop, empowered to review and refine drafts in a
collaborative workflow that blends AI efficiency with domain expertise. We
demonstrate the versatility of Co-Investigator AI across a range of complex
financial crime scenarios, highlighting its ability to streamline SAR drafting,
align narratives with regulatory expectations, and enable compliance teams to
focus on higher-order analytical work. This approach marks the beginning of a
new era in compliance reporting -- bringing the transformative benefits of AI
agents to the core of regulatory processes and paving the way for scalable,
reliable, and transparent SAR generation.

</details>


### [74] [TCPO: Thought-Centric Preference Optimization for Effective Embodied Decision-making](https://arxiv.org/abs/2509.08500)
*Kechen Jiao,Zhirui Fang,Jiahao Liu,Bei Li,Qifan Wang,Xinyu Liu,Junhao Ruan,Zhongjian Qiao,Yifan Zhu,Yaxin Xu,Jingang Wang,Xiu Li*

Main category: cs.AI

TL;DR: TCPO通过偏好优化和一致性约束，提升视觉语言模型在动态任务中的决策能力，实验证明效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在动态环境中响应迟缓、幻觉问题以及样本效率低、一致性差和模型退化的问题。

Method: 提出了Thought-Centric Preference Optimization (TCPO)，包括逐步偏好优化和Action Policy Consistency Constraint (APC)。

Result: 在ALFWorld环境中平均成功率提升6%，达到26.67%。

Conclusion: TCPO方法通过逐步偏好优化和行动策略一致性约束，有效提升了视觉语言模型在动态环境中的决策能力，减少了模型退化问题。

Abstract: Using effective generalization capabilities of vision language models (VLMs)
in context-specific dynamic tasks for embodied artificial intelligence remains
a significant challenge. Although supervised fine-tuned models can better align
with the real physical world, they still exhibit sluggish responses and
hallucination issues in dynamically changing environments, necessitating
further alignment. Existing post-SFT methods, reliant on reinforcement learning
and chain-of-thought (CoT) approaches, are constrained by sparse rewards and
action-only optimization, resulting in low sample efficiency, poor consistency,
and model degradation. To address these issues, this paper proposes
Thought-Centric Preference Optimization (TCPO) for effective embodied
decision-making. Specifically, TCPO introduces a stepwise preference-based
optimization approach, transforming sparse reward signals into richer step
sample pairs. It emphasizes the alignment of the model's intermediate reasoning
process, mitigating the problem of model degradation. Moreover, by
incorporating Action Policy Consistency Constraint (APC), it further imposes
consistency constraints on the model output. Experiments in the ALFWorld
environment demonstrate an average success rate of 26.67%, achieving a 6%
improvement over RL4VLM and validating the effectiveness of our approach in
mitigating model degradation after fine-tuning. These results highlight the
potential of integrating preference-based learning techniques with CoT
processes to enhance the decision-making capabilities of vision-language models
in embodied agents.

</details>


### [75] [No-Knowledge Alarms for Misaligned LLMs-as-Judges](https://arxiv.org/abs/2509.08593)
*Andrés Corrada-Emmanuel*

Main category: cs.AI

TL;DR: 通过逻辑一致性监测LLM评委的评分能力，开发无假阳性警报系统。


<details>
  <summary>Details</summary>
Motivation: 解决在使用LLM作为评委评估其他LLM决策时，缺乏地面真实数据和无限监控链的问题。

Method: 将评委之间的不一致性逻辑形式化为线性规划问题，计算评委评分能力的唯一可能评估。

Result: 开发出无知识警报系统，能够可靠地检测评委团队中的评分偏差。

Conclusion: 通过利用逻辑一致性来监测LLM评委的评分能力，可以开发出无知识警报系统，以无假阳性的方式检测出评委团队中至少一个成员违反用户指定的评分要求。

Abstract: If we use LLMs as judges to evaluate the complex decisions of other LLMs, who
or what monitors the judges? Infinite monitoring chains are inevitable whenever
we do not know the ground truth of the decisions by experts and we do not want
to trust them. One way to ameliorate our evaluation uncertainty is to exploit
the use of logical consistency between disagreeing experts. By observing how
LLM judges agree and disagree while grading other LLMs, we can compute the only
possible evaluations of their grading ability. For example, if two LLM judges
disagree on which tasks a third one completed correctly, they cannot both be
100\% correct in their judgments. This logic can be formalized as a Linear
Programming problem in the space of integer response counts for any finite
test. We use it here to develop no-knowledge alarms for misaligned LLM judges.
The alarms can detect, with no false positives, that at least one member or
more of an ensemble of judges are violating a user specified grading ability
requirement.

</details>


### [76] [Automatic Failure Attribution and Critical Step Prediction Method for Multi-Agent Systems Based on Causal Inference](https://arxiv.org/abs/2509.08682)
*Guoqing Ma,Jia Zhu,Hanghui Guo,Weijie Shi,Jiawei Shen,Jingjiang Liu,Yidan Liang*

Main category: cs.AI

TL;DR: 提出了一种基于因果推断的多智能体系统故障归因框架，显著提高了故障定位准确性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在实际部署中面临故障归因的挑战，现有诊断工具基于统计相关性，无法准确定位故障根源。

Method: 提出了一种性能因果反转原则和CDC-MAS因果发现算法，结合Shapley值进行智能体级责任分配，并通过反事实模拟验证优化建议的有效性。

Result: 在Who&When和TRAIL基准测试中，方法实现了高达36.2%的步骤级准确率，生成的优化建议平均提升任务成功率22.4%。

Conclusion: 本研究为多智能体系统提供了一个基于多粒度因果推断的故障归因框架，显著提高了故障定位的准确性和任务成功率，为复杂智能体交互的调试提供了有效解决方案。

Abstract: Multi-agent systems (MAS) are critical for automating complex tasks, yet
their practical deployment is severely hampered by the challenge of failure
attribution. Current diagnostic tools, which rely on statistical correlations,
are fundamentally inadequate; on challenging benchmarks like Who\&When,
state-of-the-art methods achieve less than 15\% accuracy in locating the
root-cause step of a failure. To address this critical gap, we introduce the
first failure attribution framework for MAS grounded in multi-granularity
causal inference. Our approach makes two key technical contributions: (1) a
performance causal inversion principle, which correctly models performance
dependencies by reversing the data flow in execution logs, combined with
Shapley values to accurately assign agent-level blame; (2) a novel causal
discovery algorithm, CDC-MAS, that robustly identifies critical failure steps
by tackling the non-stationary nature of MAS interaction data. The framework's
attribution results directly fuel an automated optimization loop, generating
targeted suggestions whose efficacy is validated via counterfactual
simulations. Evaluations on the Who\&When and TRAIL benchmarks demonstrate a
significant leap in performance. Our method achieves up to 36.2\% step-level
accuracy. Crucially, the generated optimizations boost overall task success
rates by an average of 22.4\%. This work provides a principled and effective
solution for debugging complex agent interactions, paving the way for more
reliable and interpretable multi-agent systems.

</details>


### [77] [One Model, Two Minds: A Context-Gated Graph Learner that Recreates Human Biases](https://arxiv.org/abs/2509.08705)
*Shalima Binta Manir,Tim Oates*

Main category: cs.AI

TL;DR: 提出受双过程理论启发的ToM框架，结合GCNs和元学习技术，动态平衡直觉与审慎推理，实验验证其能模拟人类行为和认知偏见，为AI的类人社会认知提供新思路。


<details>
  <summary>Details</summary>
Motivation: 受认知科学中双过程理论的启发，旨在构建一个能够模拟人类自适应行为和认知偏见的AI系统，以弥合人工智能与认知理论之间的差距。

Method: 结合图卷积网络（GCNs）实现快速、习惯性的图推理系统（系统1），以及通过元学习技术驱动的慢速、上下文敏感的元自适应学习系统（系统2），并通过学习的上下文门机制动态平衡直觉和审慎推理。

Result: 实验结果表明，该双过程方法能够紧密模拟人类自适应行为，实现对新环境的鲁棒泛化，并阐明推理偏见背后的认知机制。

Conclusion: 该研究通过双过程理论框架，成功构建了一个能够模拟人类自适应行为和认知偏见的AI系统，为AI系统实现更细腻、类人的社会认知和决策能力铺平了道路。

Abstract: We introduce a novel Theory of Mind (ToM) framework inspired by dual-process
theories from cognitive science, integrating a fast, habitual graph-based
reasoning system (System 1), implemented via graph convolutional networks
(GCNs), and a slower, context-sensitive meta-adaptive learning system (System
2), driven by meta-learning techniques. Our model dynamically balances
intuitive and deliberative reasoning through a learned context gate mechanism.
We validate our architecture on canonical false-belief tasks and systematically
explore its capacity to replicate hallmark cognitive biases associated with
dual-process theory, including anchoring, cognitive-load fatigue, framing
effects, and priming effects. Experimental results demonstrate that our
dual-process approach closely mirrors human adaptive behavior, achieves robust
generalization to unseen contexts, and elucidates cognitive mechanisms
underlying reasoning biases. This work bridges artificial intelligence and
cognitive theory, paving the way for AI systems exhibiting nuanced, human-like
social cognition and adaptive decision-making capabilities.

</details>


### [78] [The More You Automate, the Less You See: Hidden Pitfalls of AI Scientist Systems](https://arxiv.org/abs/2509.08713)
*Ziming Luo,Atoosa Kasirzadeh,Nihar B. Shah*

Main category: cs.AI

TL;DR: 研究发现AI科学家系统存在四种潜在失败模式，通过实验验证其存在，并建议提交完整工作流日志以提高研究透明度。


<details>
  <summary>Details</summary>
Motivation: AI科学家系统内部工作流未经过严格审查，可能导致研究输出的完整性、可靠性和可信度受到损害。

Method: 设计控制实验以隔离每种失败模式，并解决评估AI科学家系统特有的挑战。评估了两个著名的开源AI科学家系统。

Result: 评估发现两个AI科学家系统中存在多种严重程度不同的失败模式，这些在实践中容易被忽视。访问完整自动化工作流的跟踪日志和代码能更有效地检测这些失败。

Conclusion: 建议期刊和会议在评估AI生成的研究时，要求提交完整的自动化工作流跟踪日志和代码，以确保透明度、责任性和可重复性。

Abstract: AI scientist systems, capable of autonomously executing the full research
workflow from hypothesis generation and experimentation to paper writing, hold
significant potential for accelerating scientific discovery. However, the
internal workflow of these systems have not been closely examined. This lack of
scrutiny poses a risk of introducing flaws that could undermine the integrity,
reliability, and trustworthiness of their research outputs. In this paper, we
identify four potential failure modes in contemporary AI scientist systems:
inappropriate benchmark selection, data leakage, metric misuse, and post-hoc
selection bias. To examine these risks, we design controlled experiments that
isolate each failure mode while addressing challenges unique to evaluating AI
scientist systems. Our assessment of two prominent open-source AI scientist
systems reveals the presence of several failures, across a spectrum of
severity, which can be easily overlooked in practice. Finally, we demonstrate
that access to trace logs and code from the full automated workflow enables far
more effective detection of such failures than examining the final paper alone.
We thus recommend journals and conferences evaluating AI-generated research to
mandate submission of these artifacts alongside the paper to ensure
transparency, accountability, and reproducibility.

</details>


### [79] [Narrative-Guided Reinforcement Learning: A Platform for Studying Language Model Influence on Decision Making](https://arxiv.org/abs/2509.08785)
*Anup Tuladhar,Araz Minhas,Adam Kirton,Eli Kinney-Lang*

Main category: cs.AI

TL;DR: 该研究开发了一个结合强化学习和语言模型推理的实验平台，探索叙事元素如何影响AI决策，为未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管AI系统已具备决策和叙事推理能力，但这两项能力通常被分开研究。本研究旨在通过实验平台探索叙事元素如何影响AI的决策过程。

Method: 采用双系统架构，结合强化学习策略和语言模型处理建议，通过不同的叙事框架引导决策。实验在可配置的网格世界环境中进行，记录从RL策略值到语言模型推理及行动选择模式的基本决策指标。

Result: 初步实验平台成功实现了强化学习与语言模型推理的结合，并展示了叙事框架对奖励学习的影响。平台的模块化设计支持对环境复杂性、叙事参数及RL与叙事决策交互的受控测试。

Conclusion: 该平台为研究不同叙事框架如何影响基于奖励的决策提供了初步基础，并探索了优化学习和符号推理在AI系统中的潜在交互作用。

Abstract: We present a preliminary experimental platform that explores how narrative
elements might shape AI decision-making by combining reinforcement learning
(RL) with language model reasoning. While AI systems can now both make
decisions and engage in narrative reasoning, these capabilities have mostly
been studied separately. Our platform attempts to bridge this gap using a
dual-system architecture to examine how narrative frameworks could influence
reward-based learning. The system comprises a reinforcement learning policy
that suggests actions based on past experience, and a language model that
processes these suggestions through different narrative frameworks to guide
decisions. This setup enables initial experimentation with narrative elements
while maintaining consistent environment and reward structures. We implement
this architecture in a configurable gridworld environment, where agents receive
both policy suggestions and information about their surroundings. The
platform's modular design facilitates controlled testing of environmental
complexity, narrative parameters, and the interaction between reinforcement
learning and narrative-based decisions. Our logging system captures basic
decision metrics, from RL policy values to language model reasoning to action
selection patterns. While preliminary, this implementation provides a
foundation for studying how different narrative frameworks might affect
reward-based decisions and exploring potential interactions between
optimization-based learning and symbolic reasoning in AI systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [80] [X-Part: high fidelity and structure coherent shape decomposition](https://arxiv.org/abs/2509.08643)
*Xinhao Yan,Jiachen Xu,Yang Li,Changfeng Ma,Yunhan Yang,Chunshi Wang,Zibo Zhao,Zeqiang Lai,Yunfei Zhao,Zhuo Chen,Chunchao Guo*

Main category: cs.GR

TL;DR: X-Part 是一种可控生成模型，通过边界框提示和语义特征注入，实现高保真度的3D部件生成，适用于生产级3D资产创建。


<details>
  <summary>Details</summary>
Motivation: 现有的基于部件的生成方法在可控性和语义分解方面表现不足，难以满足下游应用（如网格重拓扑、UV映射和3D打印）的需求。

Method: X-Part 利用边界框作为部件生成的提示，并注入点级语义特征以实现有意义的分解，同时设计了可编辑的交互式部件生成流程。

Result: 实验结果表明，X-Part 在部件级形状生成方面达到了最先进的性能。

Conclusion: X-Part 提出了一种新的可控生成模型，用于生成语义明确、结构连贯的3D部件，具有高几何保真度，为创建可直接用于生产的、可编辑的3D资产建立了新范式。

Abstract: Generating 3D shapes at part level is pivotal for downstream applications
such as mesh retopology, UV mapping, and 3D printing. However, existing
part-based generation methods often lack sufficient controllability and suffer
from poor semantically meaningful decomposition. To this end, we introduce
X-Part, a controllable generative model designed to decompose a holistic 3D
object into semantically meaningful and structurally coherent parts with high
geometric fidelity. X-Part exploits the bounding box as prompts for the part
generation and injects point-wise semantic features for meaningful
decomposition. Furthermore, we design an editable pipeline for interactive part
generation. Extensive experimental results show that X-Part achieves
state-of-the-art performance in part-level shape generation. This work
establishes a new paradigm for creating production-ready, editable, and
structurally sound 3D assets. Codes will be released for public research.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [81] [A Novel Theoretical Approach on Micro-Nano Robotic Networks Based on Density Matrices and Swarm Quantum Mechanics](https://arxiv.org/abs/2509.08002)
*Maria Mannone,Mahathi Anand,Peppino Fazio,Abdalla Swikir*

Main category: cs.RO

TL;DR: 本文提出将机器人群体视为混合量子态，用密度矩阵描述，解决了矩阵大小问题，并展望了未来研究。


<details>
  <summary>Details</summary>
Motivation: 现有研究将群体参数描述为概率振幅，但缺乏对群体作为混合量子态的定义。

Method: 采用密度矩阵描述机器人群体，其大小不随机器人数量变化。

Result: 提出了一种新的群体定义方法，使用密度矩阵表示，解决了矩阵大小随机器人数量增长的问题。

Conclusion: 本文提出了将机器人群体定义为混合量子态的方法，并探讨了未来研究方向。

Abstract: In a robotic swarm, parameters such as position and proximity to the target
can be described in terms of probability amplitudes. This idea led to recent
studies on a quantum approach to the definition of the swarm, including a
block-matrix representation. Here, we propose an advancement of the idea,
defining a swarm as a mixed quantum state, to be described with a density
matrix, whose size does not change with the number of robots. We end the
article with some directions for future research.

</details>


### [82] [PySensors 2.0: A Python Package for Sparse Sensor Placement](https://arxiv.org/abs/2509.08017)
*Niharika Karnik,Yash Bhangale,Mohammad G. Abdo,Andrei A. Klishin,Joshua J. Cogliati,Bingni W. Brunton,J. Nathan Kutz,Steven L. Brunton,Krithika Manohar*

Main category: cs.RO

TL;DR: PySensors更新支持空间约束传感器放置、自定义基础输入、热力学方法和噪声不确定性量化，提升了重建和分类任务的灵活性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为了满足用户对传感器放置的多样化需求（如区域约束、预定义位置、最小间距等），并提升传感器配置的全面性和鲁棒性，PySensors进行了此次重大更新。

Method: 通过空间约束传感器放置、自定义基础输入、热力学方法和正则化最小二乘优化等技术，PySensors实现了更灵活的传感器配置和更稳健的重建。

Result: 新功能包括空间约束传感器放置、热力学方法、噪声不确定性量化等，通过代码示例和数学理论展示了其有效性和实用性。

Conclusion: PySensors的更新引入了空间约束传感器放置功能、自定义基础输入支持、热力学方法以及噪声诱导的不确定性量化，显著提升了其在重建和分类任务中的适用性和鲁棒性。

Abstract: PySensors is a Python package for selecting and placing a sparse set of
sensors for reconstruction and classification tasks. In this major update to
\texttt{PySensors}, we introduce spatially constrained sensor placement
capabilities, allowing users to enforce constraints such as maximum or exact
sensor counts in specific regions, incorporate predetermined sensor locations,
and maintain minimum distances between sensors. We extend functionality to
support custom basis inputs, enabling integration of any data-driven or
spectral basis. We also propose a thermodynamic approach that goes beyond a
single ``optimal'' sensor configuration and maps the complete landscape of
sensor interactions induced by the training data. This comprehensive view
facilitates integration with external selection criteria and enables assessment
of sensor replacement impacts. The new optimization technique also accounts for
over- and under-sampling of sensors, utilizing a regularized least squares
approach for robust reconstruction. Additionally, we incorporate noise-induced
uncertainty quantification of the estimation error and provide visual
uncertainty heat maps to guide deployment decisions. To highlight these
additions, we provide a brief description of the mathematical algorithms and
theory underlying these new capabilities. We demonstrate the usage of new
features with illustrative code examples and include practical advice for
implementation across various application domains. Finally, we outline a
roadmap of potential extensions to further enhance the package's functionality
and applicability to emerging sensing challenges.

</details>


### [83] [SVN-ICP: Uncertainty Estimation of ICP-based LiDAR Odometry using Stein Variational Newton](https://arxiv.org/abs/2509.08069)
*Shiping Ma,Haoming Zhang,Marc Toussaint*

Main category: cs.RO

TL;DR: SVN-ICP是一种基于Stein变分牛顿的ICP算法，无需显式噪声建模，在多传感器系统中表现出色，尤其在LiDAR性能下降的环境中。


<details>
  <summary>Details</summary>
Motivation: 为了解决多传感器融合中LiDAR退化环境下的姿态估计和噪声参数推断问题。

Method: 通过Stein变分牛顿方法在流形上近似后验分布，SVN-ICP避免了显式噪声建模或手动参数调优。

Result: 实验结果表明，SVN-ICP在多样化环境和机器人类型的数据集上优于现有最佳方法，并提供可靠的噪声估计。

Conclusion: SVN-ICP算法在多传感器系统中表现出色，尤其在LiDAR性能下降的环境中仍能提供准确的姿态估计和一致的噪声参数推断。

Abstract: This letter introduces SVN-ICP, a novel Iterative Closest Point (ICP)
algorithm with uncertainty estimation that leverages Stein Variational Newton
(SVN) on manifold. Designed specifically for fusing LiDAR odometry in
multisensor systems, the proposed method ensures accurate pose estimation and
consistent noise parameter inference, even in LiDAR-degraded environments. By
approximating the posterior distribution using particles within the Stein
Variational Inference framework, SVN-ICP eliminates the need for explicit noise
modeling or manual parameter tuning. To evaluate its effectiveness, we
integrate SVN-ICP into a simple error-state Kalman filter alongside an IMU and
test it across multiple datasets spanning diverse environments and robot types.
Extensive experimental results demonstrate that our approach outperforms
best-in-class methods on challenging scenarios while providing reliable
uncertainty estimates.

</details>


### [84] [Real-Time Obstacle Avoidance for a Mobile Robot Using CNN-Based Sensor Fusion](https://arxiv.org/abs/2509.08095)
*Lamiaa H. Zain,Raafat E. Shalaby*

Main category: cs.RO

TL;DR: 研究通过三种CNN模型实现移动机器人避障，NetConEmb在实时导航中表现最优，适用于所有环境。


<details>
  <summary>Details</summary>
Motivation: 移动机器人在复杂和未知环境中需要有效的避障能力，以提升导航性能。

Method: 训练并评估了三种端到端的卷积神经网络（CNNs），包括NetConEmb、NetEmb和NetGated，用于从RGB-D图像生成低级转向指令。

Result: 离线评估显示NetConEmb性能最佳（MedAE为0.58×10^-3 rad/s），NetEmb表现接近（RMSE为21.68×10^-3 rad/s）。实时导航中NetConEmb在各类环境中均成功，其他模型仅适用于已知环境。

Conclusion: 研究证实，NetConEmb模型在实时导航中表现出色，成功率为100%，适用于已知和未知环境，而NetEmb和NetGated仅能在已知环境中导航。

Abstract: Obstacle avoidance is a critical component of the navigation stack required
for mobile robots to operate effectively in complex and unknown environments.
In this research, three end-to-end Convolutional Neural Networks (CNNs) were
trained and evaluated offline and deployed on a differential-drive mobile robot
for real-time obstacle avoidance to generate low-level steering commands from
synchronized color and depth images acquired by an Intel RealSense D415 RGB-D
camera in diverse environments. Offline evaluation showed that the NetConEmb
model achieved the best performance with a notably low MedAE of $0.58 \times
10^{-3}$ rad/s. In comparison, the lighter NetEmb architecture adopted in this
study, which reduces the number of trainable parameters by approximately 25\%
and converges faster, produced comparable results with an RMSE of $21.68 \times
10^{-3}$ rad/s, close to the $21.42 \times 10^{-3}$ rad/s obtained by
NetConEmb. Real-time navigation further confirmed NetConEmb's robustness,
achieving a 100\% success rate in both known and unknown environments, while
NetEmb and NetGated succeeded only in navigating the known environment.

</details>


### [85] [Online Learning and Coverage of Unknown Fields Using Random-Feature Gaussian Processes](https://arxiv.org/abs/2509.08117)
*Ruijie Du,Ruoyu Lin,Yanning Shen,Magnus Egerstedt*

Main category: cs.RO

TL;DR: 多机器人系统框架结合RFGP和O-RFGP、Voronoi覆盖控制及UCB采样，实现对未知时变密度函数域的高效覆盖与学习，理论和实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统在未知且可能时变密度函数域中同时学习和覆盖的挑战，克服高斯过程回归的局限性。

Method: 采用随机特征高斯过程（RFGP）及其在线变体（O-RFGP）进行在线增量推断，结合Voronoi覆盖控制和UCB采样策略，使机器人团队能够自适应地关注重要区域并优化空间场学习。

Result: 理论分析和仿真实验验证了框架在时不变场景中的有效性，并在时变场景和物理实验中进一步证明了其适用性。

Conclusion: 论文提出了一种多机器人系统框架，通过集成随机特征高斯过程（RFGP）及其在线变体（O-RFGP）、Voronoi覆盖控制和UCB采样策略，实现了对未知且可能时变密度函数域的高效覆盖与学习。理论保证和实验验证了框架的有效性。

Abstract: This paper proposes a framework for multi-robot systems to perform
simultaneous learning and coverage of the domain of interest characterized by
an unknown and potentially time-varying density function. To overcome the
limitations of Gaussian Process (GP) regression, we employ Random Feature GP
(RFGP) and its online variant (O-RFGP) that enables online and incremental
inference. By integrating these with Voronoi-based coverage control and Upper
Confidence Bound (UCB) sampling strategy, a team of robots can adaptively focus
on important regions while refining the learned spatial field for efficient
coverage. Under mild assumptions, we provide theoretical guarantees and
evaluate the framework through simulations in time-invariant scenarios.
Furthermore, its effectiveness in time-varying settings is demonstrated through
additional simulations and a physical experiment.

</details>


### [86] [Attribute-based Object Grounding and Robot Grasp Detection with Spatial Reasoning](https://arxiv.org/abs/2509.08126)
*Houjian Yu,Zheming Zhou,Min Sun,Omid Ghasemalizadeh,Yuyin Sun,Cheng-Hao Kuo,Arnie Sen,Changhyun Choi*

Main category: cs.RO

TL;DR: OGRG框架通过双向视觉语言融合和深度集成，高效处理开放语言指令和重复物体场景，在定位和抓取任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放形式语言表达和重复物体场景中表现不佳，且依赖昂贵的密集像素级标注。需要一种能处理复杂语言指令并减少标注成本的新方法。

Method: 提出了基于属性的物体定位与机器人抓取（OGRG）框架，包含双向视觉语言融合模块和深度信息集成，支持开放形式语言表达和空间推理。研究了两种设置：全监督的Referring Grasp Synthesis（RGS）和弱监督的Referring Grasp Affordance（RGA）。

Result: OGRG在多样化空间语言指令的桌面场景中表现优异，RGS模式下在NVIDIA RTX 2080 Ti GPU上以17.59 FPS运行，定位和抓取预测精度均优于基线。RGA模式下在仿真和真实机器人试验中抓取成功率也超过基线。

Conclusion: OGRG框架通过双向视觉语言融合模块和深度信息集成，显著提升了开放形式语言表达下的物体定位和抓取性能，在仿真和真实机器人实验中均优于基线方法。

Abstract: Enabling robots to grasp objects specified through natural language is
essential for effective human-robot interaction, yet it remains a significant
challenge. Existing approaches often struggle with open-form language
expressions and typically assume unambiguous target objects without duplicates.
Moreover, they frequently rely on costly, dense pixel-wise annotations for both
object grounding and grasp configuration. We present Attribute-based Object
Grounding and Robotic Grasping (OGRG), a novel framework that interprets
open-form language expressions and performs spatial reasoning to ground target
objects and predict planar grasp poses, even in scenes containing duplicated
object instances. We investigate OGRG in two settings: (1) Referring Grasp
Synthesis (RGS) under pixel-wise full supervision, and (2) Referring Grasp
Affordance (RGA) using weakly supervised learning with only single-pixel grasp
annotations. Key contributions include a bi-directional vision-language fusion
module and the integration of depth information to enhance geometric reasoning,
improving both grounding and grasping performance. Experiment results show that
OGRG outperforms strong baselines in tabletop scenes with diverse spatial
language instructions. In RGS, it operates at 17.59 FPS on a single NVIDIA RTX
2080 Ti GPU, enabling potential use in closed-loop or multi-object sequential
grasping, while delivering superior grounding and grasp prediction accuracy
compared to all the baselines considered. Under the weakly supervised RGA
setting, OGRG also surpasses baseline grasp-success rates in both simulation
and real-robot trials, underscoring the effectiveness of its spatial reasoning
design. Project page: https://z.umn.edu/ogrg

</details>


### [87] [Mean Field Game-Based Interactive Trajectory Planning Using Physics-Inspired Unified Potential Fields](https://arxiv.org/abs/2509.08147)
*Zhen Tian,Fujiang Yuan,Chunhong Yuan,Yanhong Peng*

Main category: cs.RO

TL;DR: 提出IUPF框架，通过融合风格依赖的效益和风险场，实现自动驾驶中安全、高效的交互轨迹规划，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中交互轨迹规划在安全、效率和可扩展性之间的平衡问题，同时降低现有方法的高计算成本或对外部安全评判的依赖。

Method: 通过基于平均场博弈论的物理启发变分模型，融合风格依赖的效益和风险场，并利用随机微分方程保证纳什均衡及指数收敛。

Result: 在车道变换和超车场景的模拟中，IUPF展现了其有效性，无需额外安全模块即可捕捉保守、激进和合作行为。

Conclusion: IUPF框架在保证安全距离、生成平滑高效轨迹的同时，在适应性和计算效率上均优于传统优化和博弈论基线方法。

Abstract: Interactive trajectory planning in autonomous driving must balance safety,
efficiency, and scalability under heterogeneous driving behaviors. Existing
methods often face high computational cost or rely on external safety critics.
To address this, we propose an Interaction-Enriched Unified Potential Field
(IUPF) framework that fuses style-dependent benefit and risk fields through a
physics-inspired variational model, grounded in mean field game theory. The
approach captures conservative, aggressive, and cooperative behaviors without
additional safety modules, and employs stochastic differential equations to
guarantee Nash equilibrium with exponential convergence. Simulations on lane
changing and overtaking scenarios show that IUPF ensures safe distances,
generates smooth and efficient trajectories, and outperforms traditional
optimization and game-theoretic baselines in both adaptability and
computational efficiency.

</details>


### [88] [Risk-Bounded Multi-Agent Visual Navigation via Dynamic Budget Allocation](https://arxiv.org/abs/2509.08157)
*Viraj Parimi,Brian C. Williams*

Main category: cs.RO

TL;DR: 提出RB-CBS方法，动态分配风险预算以提升多智能体在复杂环境中的导航效率，同时确保安全性。


<details>
  <summary>Details</summary>
Motivation: 传统规划方法依赖预定义距离度量，而安全强化学习在多智能体、目标导向场景中表现不佳。现有的图剪枝方法过于保守，限制了任务效率。

Method: 提出RB-CBS，通过动态分配和调整用户指定的风险边界（Δ）来改进CBS，为每个智能体分配局部风险预算（δ），以平衡安全性和速度。

Result: 实验结果表明，RB-CBS在复杂环境中表现优异，允许多智能体在用户指定的Δ内找到无碰撞路径。

Conclusion: RB-CBS，一种CBS的新扩展方法，通过动态分配和调整用户指定的风险边界（Δ），在复杂环境中实现了更高效的导航，同时尊重整体安全约束。

Abstract: Safe navigation is essential for autonomous systems operating in hazardous
environments, especially when multiple agents must coordinate using just visual
inputs over extended time horizons. Traditional planning methods excel at
solving long-horizon tasks but rely on predefined distance metrics, while safe
Reinforcement Learning (RL) can learn complex behaviors using high-dimensional
inputs yet struggles with multi-agent, goal-conditioned scenarios. Recent work
combined these paradigms by leveraging goal-conditioned RL (GCRL) to build an
intermediate graph from replay buffer states, pruning unsafe edges, and using
Conflict-Based Search (CBS) for multi-agent path planning. Although effective,
this graph-pruning approach can be overly conservative, limiting mission
efficiency by precluding missions that must traverse high-risk regions. To
address this limitation, we propose RB-CBS, a novel extension to CBS that
dynamically allocates and adjusts user-specified risk bound ($\Delta$) across
agents to flexibly trade off safety and speed. Our improved planner ensures
that each agent receives a local risk budget ($\delta$) enabling more efficient
navigation while still respecting overall safety constraints. Experimental
results demonstrate that this iterative risk-allocation framework yields
superior performance in complex environments, allowing multiple agents to find
collision-free paths within the user-specified $\Delta$.

</details>


### [89] [Zero-Shot Metric Depth Estimation via Monocular Visual-Inertial Rescaling for Autonomous Aerial Navigation](https://arxiv.org/abs/2509.08159)
*Steven Yang,Xiaoyu Tian,Kshitij Goel,Wennie Tabib*

Main category: cs.RO

TL;DR: 提出了一种轻量级方法，通过零样本重新缩放策略从单目RGB图像和IMU数据中预测度量深度，成功在四旋翼飞行器上实现了实时碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 为了解决自主飞行中碰撞避免的问题，现有方法要么依赖重型传感器，要么需要数据密集和领域特定的微调，因此提出了一种轻量级的替代方案。

Method: 提出了几种轻量级零样本重新缩放策略，通过视觉-惯性导航系统创建的稀疏3D特征图，从相对深度估计中获取度量深度，并比较了这些策略在不同模拟环境中的准确性。

Result: 最佳性能的方法（单调样条拟合）在真实世界的计算受限四旋翼飞行器上部署，实现了15Hz的实时度量深度估计，并成功避免了碰撞。

Conclusion: 通过轻量级零样本重新缩放策略，成功在计算受限的四旋翼飞行器上实现了15Hz的实时度量深度估计，并证明了与基于运动基元的规划器集成后能有效避免碰撞。

Abstract: This paper presents a methodology to predict metric depth from monocular RGB
images and an inertial measurement unit (IMU). To enable collision avoidance
during autonomous flight, prior works either leverage heavy sensors (e.g.,
LiDARs or stereo cameras) or data-intensive and domain-specific fine-tuning of
monocular metric depth estimation methods. In contrast, we propose several
lightweight zero-shot rescaling strategies to obtain metric depth from relative
depth estimates via the sparse 3D feature map created using a visual-inertial
navigation system. These strategies are compared for their accuracy in diverse
simulation environments. The best performing approach, which leverages
monotonic spline fitting, is deployed in the real-world on a
compute-constrained quadrotor. We obtain on-board metric depth estimates at 15
Hz and demonstrate successful collision avoidance after integrating the
proposed method with a motion primitives-based planner.

</details>


### [90] [Diffusion-Guided Multi-Arm Motion Planning](https://arxiv.org/abs/2509.08160)
*Viraj Parimi,Brian C. Williams*

Main category: cs.RO

TL;DR: DG-MAP利用条件扩散模型和MAPF结构化分解，提升多臂运动规划的可扩展性，减少数据依赖，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决多臂运动规划中因状态空间指数增长和学习模型依赖大规模数据集导致的可扩展性问题。

Method: 训练两个条件扩散模型：一个生成可行的单臂轨迹，另一个建模双臂动态以解决碰撞问题，结合MAPF的结构化分解方法。

Result: DG-MAP在多种团队规模下的评估中表现优于其他基于学习的方法，证明了其有效性和实际应用价值。

Conclusion: DG-MAP通过结合条件扩散模型和MAPF启发的结构化分解，显著提升了多臂运动规划的可扩展性，减少了对大规模数据集的需求，并在不同团队规模下表现出优越性能。

Abstract: Multi-arm motion planning is fundamental for enabling arms to complete
complex long-horizon tasks in shared spaces efficiently but current methods
struggle with scalability due to exponential state-space growth and reliance on
large training datasets for learned models. Inspired by Multi-Agent Path
Finding (MAPF), which decomposes planning into single-agent problems coupled
with collision resolution, we propose a novel diffusion-guided multi-arm
planner (DG-MAP) that enhances scalability of learning-based models while
reducing their reliance on massive multi-arm datasets. Recognizing that
collisions are primarily pairwise, we train two conditional diffusion models,
one to generate feasible single-arm trajectories, and a second, to model the
dual-arm dynamics required for effective pairwise collision resolution. By
integrating these specialized generative models within a MAPF-inspired
structured decomposition, our planner efficiently scales to larger number of
arms. Evaluations against alternative learning-based methods across various
team sizes demonstrate our method's effectiveness and practical applicability.
Project website can be found at https://diff-mapf-mers.csail.mit.edu

</details>


### [91] [Quadrotor Navigation using Reinforcement Learning with Privileged Information](https://arxiv.org/abs/2509.08177)
*Jonathan Lee,Abhishek Rathod,Kshitij Goel,John Stecklein,Wennie Tabib*

Main category: cs.RO

TL;DR: 提出一种基于强化学习的四旋翼导航方法，利用特权信息和新型损失函数，成功绕过大型障碍物，仿真和实际测试均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有学习型方法在狭窄障碍物场景中表现良好，但在目标被大型障碍物阻挡时效果不佳。本文旨在解决这一问题。

Method: 利用高效可微分模拟、新颖的损失函数和特权信息（如到达时间地图）来导航大型障碍物，并引入偏航对齐损失以引导飞行器。

Result: 在仿真环境中，该方法比基线策略提高了34%的成功率，并在实际飞行测试中覆盖589米无碰撞，最高速度达4米/秒。

Conclusion: 该方法在包含大型障碍物的逼真仿真环境中表现优异，成功率达到86%，并在实际四旋翼飞行器中验证了其有效性。

Abstract: This paper presents a reinforcement learning-based quadrotor navigation
method that leverages efficient differentiable simulation, novel loss
functions, and privileged information to navigate around large obstacles. Prior
learning-based methods perform well in scenes that exhibit narrow obstacles,
but struggle when the goal location is blocked by large walls or terrain. In
contrast, the proposed method utilizes time-of-arrival (ToA) maps as privileged
information and a yaw alignment loss to guide the robot around large obstacles.
The policy is evaluated in photo-realistic simulation environments containing
large obstacles, sharp corners, and dead-ends. Our approach achieves an 86%
success rate and outperforms baseline strategies by 34%. We deploy the policy
onboard a custom quadrotor in outdoor cluttered environments both during the
day and night. The policy is validated across 20 flights, covering 589 meters
without collisions at speeds up to 4 m/s.

</details>


### [92] [Online Dynamic SLAM with Incremental Smoothing and Mapping](https://arxiv.org/abs/2509.08197)
*Jesse Morris,Yiduo Wang,Viorela Ila*

Main category: cs.RO

TL;DR: 本文提出了一种基于增量优化的动态SLAM方法，显著提升了计算效率并支持在线应用，精度不输现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有动态SLAM方法虽精确但计算成本高，无法满足在线应用需求。

Method: 提出了一种新颖的因子图框架和系统架构，结合增量优化技术，支持在线估计。

Result: 在多个数据集上验证了方法的有效性，相机姿态和物体运动精度达到或超越现有技术，且计算速度提升5倍。

Conclusion: 本研究通过引入增量优化技术和新颖的因子图框架，显著提升了动态SLAM的计算效率，实现了在线应用的可行性，并在精度上达到或超越了现有方法。

Abstract: Dynamic SLAM methods jointly estimate for the static and dynamic scene
components, however existing approaches, while accurate, are computationally
expensive and unsuitable for online applications. In this work, we present the
first application of incremental optimisation techniques to Dynamic SLAM. We
introduce a novel factor-graph formulation and system architecture designed to
take advantage of existing incremental optimisation methods and support online
estimation. On multiple datasets, we demonstrate that our method achieves equal
to or better than state-of-the-art in camera pose and object motion accuracy.
We further analyse the structural properties of our approach to demonstrate its
scalability and provide insight regarding the challenges of solving Dynamic
SLAM incrementally. Finally, we show that our formulation results in problem
structure well-suited to incremental solvers, while our system architecture
further enhances performance, achieving a 5x speed-up over existing methods.

</details>


### [93] [A Comprehensive Review of Reinforcement Learning for Autonomous Driving in the CARLA Simulator](https://arxiv.org/abs/2509.08221)
*Elahe Delavari,Feeza Khan Khanzada,Jaerock Kwon*

Main category: cs.RO

TL;DR: 该综述系统分析了约100篇在CARLA模拟器中应用强化学习的论文，总结了流行的方法、评估指标和开放问题，旨在为新手提供参考并推动实际应用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶研究近期采用深度强化学习作为数据驱动决策的有前景框架，但关于这些算法如何被使用、基准测试和评估的清晰图景仍缺失。

Method: 系统分析了约100篇在CARLA模拟器中训练、测试或验证强化学习策略的同行评审论文。首先按算法家族（无模型、基于模型、分层和混合）对文献进行分类，并量化其流行程度。然后解释了不同研究中采用的状态、动作和奖励表述，以及评估指标和CARLA基准测试中的场景配置。

Result: 超过80%的研究仍依赖无模型方法（如DQN、PPO和SAC）。研究还总结了评估指标（如成功率、碰撞率、车道偏离、驾驶得分）和CARLA基准测试中的场景配置。提出了包括稀疏奖励、仿真到现实的迁移、安全保证和有限行为多样性在内的开放研究问题。

Conclusion: 该综述通过提供一个统一的分类法、定量统计和对局限性的批判性讨论，旨在作为新手的参考，并推动基于强化学习的自动驾驶技术向实际应用迈进。

Abstract: Autonomous-driving research has recently embraced deep Reinforcement Learning
(RL) as a promising framework for data-driven decision making, yet a clear
picture of how these algorithms are currently employed, benchmarked and
evaluated is still missing. This survey fills that gap by systematically
analysing around 100 peer-reviewed papers that train, test or validate RL
policies inside the open-source CARLA simulator. We first categorize the
literature by algorithmic family model-free, model-based, hierarchical, and
hybrid and quantify their prevalence, highlighting that more than 80% of
existing studies still rely on model-free methods such as DQN, PPO and SAC.
Next, we explain the diverse state, action and reward formulations adopted
across works, illustrating how choices of sensor modality (RGB, LiDAR, BEV,
semantic maps, and carla kinematics states), control abstraction (discrete vs.
continuous) and reward shaping are used across various literature. We also
consolidate the evaluation landscape by listing the most common metrics
(success rate, collision rate, lane deviation, driving score) and the towns,
scenarios and traffic configurations used in CARLA benchmarks. Persistent
challenges including sparse rewards, sim-to-real transfer, safety guarantees
and limited behaviour diversity are distilled into a set of open research
questions, and promising directions such as model-based RL, meta-learning and
richer multi-agent simulations are outlined. By providing a unified taxonomy,
quantitative statistics and a critical discussion of limitations, this review
aims to serve both as a reference for newcomers and as a roadmap for advancing
RL-based autonomous driving toward real-world deployment.

</details>


### [94] [Input-gated Bilateral Teleoperation: An Easy-to-implement Force Feedback Teleoperation Method for Low-cost Hardware](https://arxiv.org/abs/2509.08226)
*Yoshiki Kanai,Akira Kanazawa,Hideyuki Ichiwara,Hiroshi Ito,Naoaki Noguchi,Tetsuya Ogata*

Main category: cs.RO

TL;DR: 提出一种无需力传感器的低成本双边遥操作方法，参数调整少、性能稳定，适用于多种硬件，有望推动接触丰富任务自主性。


<details>
  <summary>Details</summary>
Motivation: 由于双边遥操作系统复杂且难以实现，导致在接触丰富的操作中需要力反馈的数据收集技术不常见。

Method: 提出了一种仅依赖简单反馈控制器且无需力传感器的双边遥操作方法，适用于领导者-跟随者设置的低成本硬件。

Result: 通过数值模拟和实际实验证明，该方法参数调整少，操作性和接触稳定性高，优于传统方法，且在低通信周期率下性能下降最小，可在两种低成本硬件上零参数调整实现。

Conclusion: 该方法有望在低成本硬件上推广力反馈遥操作系统的使用，从而推动模仿学习中接触丰富任务自主性的发展。

Abstract: Effective data collection in contact-rich manipulation requires force
feedback during teleoperation, as accurate perception of contact is crucial for
stable control. However, such technology remains uncommon, largely because
bilateral teleoperation systems are complex and difficult to implement. To
overcome this, we propose a bilateral teleoperation method that relies only on
a simple feedback controller and does not require force sensors. The approach
is designed for leader-follower setups using low-cost hardware, making it
broadly applicable. Through numerical simulations and real-world experiments,
we demonstrate that the method requires minimal parameter tuning, yet achieves
both high operability and contact stability, outperforming conventional
approaches. Furthermore, we show its high robustness: even at low communication
cycle rates between leader and follower, control performance degradation is
minimal compared to high-speed operation. We also prove our method can be
implemented on two types of commercially available low-cost hardware with zero
parameter adjustments. This highlights its high ease of implementation and
versatility. We expect this method will expand the use of force feedback
teleoperation systems on low-cost hardware. This will contribute to advancing
contact-rich task autonomy in imitation learning.

</details>


### [95] [Deep Visual Odometry for Stereo Event Cameras](https://arxiv.org/abs/2509.08235)
*Sheng Zhong,Junkai Niu,Yi Zhou*

Main category: cs.RO

TL;DR: Stereo-DEVO是一种基于学习的立体事件视觉里程计系统，通过静态立体关联和BA优化，在HDR和低光条件下实现高精度姿态估计，并支持实时处理。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动模糊和高动态范围光照条件下具有潜力，但现有基于手工数据关联的事件视觉里程计在低光HDR条件下不可靠，深度学习为解决这些挑战提供了新可能性。

Method: 提出了一种学习基础的立体事件视觉里程计系统，采用静态立体关联策略进行稀疏深度估计，并整合到紧密耦合的BA优化方案中，利用递归网络进行光流估计。

Result: 在多个公共数据集和自收集数据上的广泛评估表明，Stereo-DEVO在实时处理VGA分辨率事件数据时表现出色，并在大规模夜间HDR场景中实现了稳定的姿态估计。

Conclusion: Stereo-DEVO系统通过结合静态立体关联策略和紧密耦合的BA优化方案，实现了在HDR和低光条件下的高精度姿态估计，并在实时处理VGA分辨率事件数据方面表现出色。

Abstract: Event-based cameras are bio-inspired sensors with pixels that independently
and asynchronously respond to brightness changes at microsecond resolution,
offering the potential to handle state estimation tasks involving motion blur
and high dynamic range (HDR) illumination conditions. However, the versatility
of event-based visual odometry (VO) relying on handcrafted data association
(either direct or indirect methods) is still unreliable, especially in field
robot applications under low-light HDR conditions, where the dynamic range can
be enormous and the signal-to-noise ratio is spatially-and-temporally varying.
Leveraging deep neural networks offers new possibilities for overcoming these
challenges. In this paper, we propose a learning-based stereo event visual
odometry. Building upon Deep Event Visual Odometry (DEVO), our system (called
Stereo-DEVO) introduces a novel and efficient static-stereo association
strategy for sparse depth estimation with almost no additional computational
burden. By integrating it into a tightly coupled bundle adjustment (BA)
optimization scheme, and benefiting from the recurrent network's ability to
perform accurate optical flow estimation through voxel-based event
representations to establish reliable patch associations, our system achieves
high-precision pose estimation in metric scale. In contrast to the offline
performance of DEVO, our system can process event data of \zs{Video Graphics
Array} (VGA) resolution in real time. Extensive evaluations on multiple public
real-world datasets and self-collected data justify our system's versatility,
demonstrating superior performance compared to state-of-the-art event-based VO
methods. More importantly, our system achieves stable pose estimation even in
large-scale nighttime HDR scenarios.

</details>


### [96] [Sample-Efficient Online Control Policy Learning with Real-Time Recursive Model Updates](https://arxiv.org/abs/2509.08241)
*Zixin Zhang,James Avtges,Todd D. Murphey*

Main category: cs.RO

TL;DR: RKL是一种高效、轻量的Koopman学习管道，适用于动态环境，仅需少量数据即可实现稳定控制。


<details>
  <summary>Details</summary>
Motivation: 现代数据驱动方法需要大量数据集且难以实时更新模型，限制了其在动态环境中的性能。

Method: 提出了一种基于Koopman理论的学习管道：递归Koopman学习（RKL），并通过优化友好设置从数据中确定Koopman表示。

Result: RKL在模拟平面两连杆臂和混合非线性硬件系统中验证，仅需基准方法10%的数据即可实现高效控制。

Conclusion: RKL方法在模拟和硬件系统中验证了其高效性和稳定性，显著提升了数据驱动控制的样本效率。

Abstract: Data-driven control methods need to be sample-efficient and lightweight,
especially when data acquisition and computational resources are limited --
such as during learning on hardware. Most modern data-driven methods require
large datasets and struggle with real-time updates of models, limiting their
performance in dynamic environments. Koopman theory formally represents
nonlinear systems as linear models over observables, and Koopman
representations can be determined from data in an optimization-friendly setting
with potentially rapid model updates. In this paper, we present a highly
sample-efficient, Koopman-based learning pipeline: Recursive Koopman Learning
(RKL). We identify sufficient conditions for model convergence and provide
formal algorithmic analysis supporting our claim that RKL is lightweight and
fast, with complexity independent of dataset size. We validate our method on a
simulated planar two-link arm and a hybrid nonlinear hardware system with soft
actuators, showing that real-time recursive Koopman model updates improve the
sample efficiency and stability of data-driven controller synthesis --
requiring only <10% of the data compared to benchmarks. The high-performance
C++ codebase is open-sourced. Website:
https://www.zixinatom990.com/home/robotics/corl-2025-recursive-koopman-learning.

</details>


### [97] [Behaviorally Heterogeneous Multi-Agent Exploration Using Distributed Task Allocation](https://arxiv.org/abs/2509.08242)
*Nirabhra Mandal,Aamodh Suresh,Carlos Nieto-Granda,Sonia Martínez*

Main category: cs.RO

TL;DR: 异构行为机器人团队通过SLAM和BE评估，采用d-PBRAG算法实现高效分布式探索，实验证明其优势。


<details>
  <summary>Details</summary>
Motivation: 探索多智能体系统中行为异构机器人的协作效率，以优化探索任务的时间和路径效率。

Method: 研究采用SLAM技术进行环境映射，利用行为熵（BE）评估前沿区域的效用，并通过分布式任务分配方案（d-PBRAG）将任务分配问题转化为非合作博弈，最终收敛至纳什均衡。

Result: 实验结果表明，d-PBRAG算法具有较低的通信成本和快速收敛性，且在异构机器人团队中表现更优。

Conclusion: 研究表明，由行为异构机器人组成的团队在多智能体探索任务中具有优势，尤其是在减少探索时间和路径长度方面。

Abstract: We study a problem of multi-agent exploration with behaviorally heterogeneous
robots. Each robot maps its surroundings using SLAM and identifies a set of
areas of interest (AoIs) or frontiers that are the most informative to explore
next. The robots assess the utility of going to a frontier using Behavioral
Entropy (BE) and then determine which frontier to go to via a distributed task
assignment scheme. We convert the task assignment problem into a
non-cooperative game and use a distributed algorithm (d-PBRAG) to converge to
the Nash equilibrium (which we show is the optimal task allocation solution).
For unknown utility cases, we provide robust bounds using approximate rewards.
We test our algorithm (which has less communication cost and fast convergence)
in simulation, where we explore the effect of sensing radii, sensing accuracy,
and heterogeneity among robotic teams with respect to the time taken to
complete exploration and path traveled. We observe that having a team of agents
with heterogeneous behaviors is beneficial.

</details>


### [98] [Symmetry-Guided Multi-Agent Inverse Reinforcement Learnin](https://arxiv.org/abs/2509.08257)
*Yongkai Tian,Yirong Qi,Xin Yu,Wenjun Wu,Jie Luo*

Main category: cs.RO

TL;DR: 该论文提出了一种利用对称性提高多智能体逆强化学习样本效率的通用框架，实验验证了其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 由于手动设计的奖励函数常常导致策略失败，而现有的IRL方法依赖大量专家演示，这在多机器人系统中收集成本高昂，因此提高样本效率成为MIRL中的关键挑战。

Method: 通过理论证明多智能体系统的对称性可以帮助恢复更准确的奖励函数，并在此基础上提出了一种将对称性集成到现有多智能体对抗性IRL算法中的通用框架。

Result: 实验结果表明该框架在多个挑战性任务中有效，并在物理多机器人系统中验证了其实用性。

Conclusion: 该论文提出了一种利用多智能体系统对称性的通用框架，显著提高了样本效率，并在物理多机器人系统中验证了其实用性。

Abstract: In robotic systems, the performance of reinforcement learning depends on the
rationality of predefined reward functions. However, manually designed reward
functions often lead to policy failures due to inaccuracies. Inverse
Reinforcement Learning (IRL) addresses this problem by inferring implicit
reward functions from expert demonstrations. Nevertheless, existing methods
rely heavily on large amounts of expert demonstrations to accurately recover
the reward function. The high cost of collecting expert demonstrations in
robotic applications, particularly in multi-robot systems, severely hinders the
practical deployment of IRL. Consequently, improving sample efficiency has
emerged as a critical challenge in multi-agent inverse reinforcement learning
(MIRL). Inspired by the symmetry inherent in multi-agent systems, this work
theoretically demonstrates that leveraging symmetry enables the recovery of
more accurate reward functions. Building upon this insight, we propose a
universal framework that integrates symmetry into existing multi-agent
adversarial IRL algorithms, thereby significantly enhancing sample efficiency.
Experimental results from multiple challenging tasks have demonstrated the
effectiveness of this framework. Further validation in physical multi-robot
systems has shown the practicality of our method.

</details>


### [99] [Foundation Models for Autonomous Driving Perception: A Survey Through Core Capabilities](https://arxiv.org/abs/2509.08302)
*Rajendramayavan Sathyam,Yueqi Li*

Main category: cs.RO

TL;DR: 该调查探讨了基础模型如何解决自动驾驶感知中的泛化性、可扩展性和鲁棒性挑战，提出了以四种核心能力为中心的分类法，并总结了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 基础模型正在改变自动驾驶感知领域，从特定任务的深度学习模型转向通用架构，但面临泛化性、可扩展性和分布偏移鲁棒性等挑战。

Method: 调查围绕四种核心能力（通用知识、空间理解、多传感器鲁棒性和时间推理）构建了一个新颖的分类法，并详细评述了前沿方法。

Result: 提出了一个以能力为中心的框架，优先考虑概念设计原则，为模型开发提供指导，并更清晰地理解基础模型的各个方面。

Conclusion: 该调查总结了基础模型在自动驾驶感知中的关键挑战，特别是实时性和可扩展性集成问题，并提出了未来研究方向以确保安全有效部署。

Abstract: Foundation models are revolutionizing autonomous driving perception,
transitioning the field from narrow, task-specific deep learning models to
versatile, general-purpose architectures trained on vast, diverse datasets.
This survey examines how these models address critical challenges in autonomous
perception, including limitations in generalization, scalability, and
robustness to distributional shifts. The survey introduces a novel taxonomy
structured around four essential capabilities for robust performance in dynamic
driving environments: generalized knowledge, spatial understanding,
multi-sensor robustness, and temporal reasoning. For each capability, the
survey elucidates its significance and comprehensively reviews cutting-edge
approaches. Diverging from traditional method-centric surveys, our unique
framework prioritizes conceptual design principles, providing a
capability-driven guide for model development and clearer insights into
foundational aspects. We conclude by discussing key challenges, particularly
those associated with the integration of these capabilities into real-time,
scalable systems, and broader deployment challenges related to computational
demands and ensuring model reliability against issues like hallucinations and
out-of-distribution failures. The survey also outlines crucial future research
directions to enable the safe and effective deployment of foundation models in
autonomous driving systems.

</details>


### [100] [Good Deep Features to Track: Self-Supervised Feature Extraction and Tracking in Visual Odometry](https://arxiv.org/abs/2509.08333)
*Sai Puneeth Reddy Gottam,Haoming Zhang,Eivydas Keras*

Main category: cs.RO

TL;DR: 通过自监督学习优化深度特征提取和跟踪，提升视觉定位在挑战性环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉定位在大规模、户外和长期场景中性能下降，主要由于光照变化、动态场景和低纹理区域等因素影响特征提取和跟踪。

Method: 采用自监督学习结合任务特定反馈，优化深度特征提取和跟踪。

Result: 提出的方法促进了稳定且信息丰富的特征，改善了在挑战性环境中的泛化能力和可靠性。

Conclusion: 通过自监督学习与任务特定反馈增强深度特征提取和跟踪，提升在挑战性环境中的泛化能力和可靠性。

Abstract: Visual-based localization has made significant progress, yet its performance
often drops in large-scale, outdoor, and long-term settings due to factors like
lighting changes, dynamic scenes, and low-texture areas. These challenges
degrade feature extraction and tracking, which are critical for accurate motion
estimation. While learning-based methods such as SuperPoint and SuperGlue show
improved feature coverage and robustness, they still face generalization issues
with out-of-distribution data. We address this by enhancing deep feature
extraction and tracking through self-supervised learning with task specific
feedback. Our method promotes stable and informative features, improving
generalization and reliability in challenging environments.

</details>


### [101] [Grasp Like Humans: Learning Generalizable Multi-Fingered Grasping from Human Proprioceptive Sensorimotor Integration](https://arxiv.org/abs/2509.08354)
*Ce Guo,Xieyuanli Chen,Zhiwen Zeng,Zirui Guo,Yihong Li,Haoran Xiao,Dewen Hu,Huimin Lu*

Main category: cs.RO

TL;DR: 论文提出了一种基于模仿学习的手套介导触觉-运动感知框架，用于从人类到机器人的抓取技能转移，并在多种任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 人类通过触觉和运动感知实现灵巧操作，而机器人虽能获取这些反馈，但将其直接映射到运动动作仍具挑战性。因此，论文旨在通过模仿学习实现从人类到机器人的抓取技能转移。

Method: 论文整合了数据手套来捕获关节级别的触觉和运动数据，并建立了基于极坐标图结构的多模态输入统一表示，同时设计了Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN)来提取时空特征并预测每个手关节的节点状态。

Result: 该框架在多种抓取任务中表现出色，包括可变形物体的抓取，验证了其有效性和兼容性。

Conclusion: 该论文提出的手套介导的触觉-运动感知预测框架通过模仿学习有效实现了从人类直觉操作到机器人抓取技能的转移，并在包括可变形物体在内的多种抓取任务中验证了其有效性。

Abstract: Tactile and kinesthetic perceptions are crucial for human dexterous
manipulation, enabling reliable grasping of objects via proprioceptive
sensorimotor integration. For robotic hands, even though acquiring such tactile
and kinesthetic feedback is feasible, establishing a direct mapping from this
sensory feedback to motor actions remains challenging. In this paper, we
propose a novel glove-mediated tactile-kinematic perception-prediction
framework for grasp skill transfer from human intuitive and natural operation
to robotic execution based on imitation learning, and its effectiveness is
validated through generalized grasping tasks, including those involving
deformable objects. Firstly, we integrate a data glove to capture tactile and
kinesthetic data at the joint level. The glove is adaptable for both human and
robotic hands, allowing data collection from natural human hand demonstrations
across different scenarios. It ensures consistency in the raw data format,
enabling evaluation of grasping for both human and robotic hands. Secondly, we
establish a unified representation of multi-modal inputs based on graph
structures with polar coordinates. We explicitly integrate the morphological
differences into the designed representation, enhancing the compatibility
across different demonstrators and robotic hands. Furthermore, we introduce the
Tactile-Kinesthetic Spatio-Temporal Graph Networks (TK-STGN), which leverage
multidimensional subgraph convolutions and attention-based LSTM layers to
extract spatio-temporal features from graph inputs to predict node-based states
for each hand joint. These predictions are then mapped to final commands
through a force-position hybrid mapping.

</details>


### [102] [PegasusFlow: Parallel Rolling-Denoising Score Sampling for Robot Diffusion Planner Flow Matching](https://arxiv.org/abs/2509.08435)
*Lei Ye,Haibo Gao,Peng Xu,Zhelin Zhang,Junqi Shan,Ao Zhang,Wei Zhang,Ruyi Zhou,Zongquan Deng,Liang Ding*

Main category: cs.RO

TL;DR: PegasusFlow是一种无需专家数据的轨迹优化框架，通过WBFO算法和并行模拟架构，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在机器人轨迹规划中依赖专家数据的模仿学习，这在数据稀缺的专用机器人中效率低下且理论次优。

Method: PegasusFlow采用分层滚动去噪框架，结合WBFO算法和并行模拟架构，实现了无需专家数据的直接轨迹梯度采样。

Result: 在轨迹优化和机器人导航任务中，PegasusFlow显著优于基线方法，特别是在复杂地形任务中实现了100%的成功率和更快的速度。

Conclusion: PegasusFlow通过其创新的WBFO算法和并行模拟架构，显著提升了轨迹优化的效率和性能，特别是在复杂地形任务中表现出色。

Abstract: Diffusion models offer powerful generative capabilities for robot trajectory
planning, yet their practical deployment on robots is hindered by a critical
bottleneck: a reliance on imitation learning from expert demonstrations. This
paradigm is often impractical for specialized robots where data is scarce and
creates an inefficient, theoretically suboptimal training pipeline. To overcome
this, we introduce PegasusFlow, a hierarchical rolling-denoising framework that
enables direct and parallel sampling of trajectory score gradients from
environmental interaction, completely bypassing the need for expert data. Our
core innovation is a novel sampling algorithm, Weighted Basis Function
Optimization (WBFO), which leverages spline basis representations to achieve
superior sample efficiency and faster convergence compared to traditional
methods like MPPI. The framework is embedded within a scalable, asynchronous
parallel simulation architecture that supports massively parallel rollouts for
efficient data collection. Extensive experiments on trajectory optimization and
robotic navigation tasks demonstrate that our approach, particularly
Action-Value WBFO (AVWBFO) combined with a reinforcement learning warm-start,
significantly outperforms baselines. In a challenging barrier-crossing task,
our method achieved a 100% success rate and was 18% faster than the next-best
method, validating its effectiveness for complex terrain locomotion planning.
https://masteryip.github.io/pegasusflow.github.io/

</details>


### [103] [Augmenting Neural Networks-based Model Approximators in Robotic Force-tracking Tasks](https://arxiv.org/abs/2509.08440)
*Kevin Saad,Vincenzo Petrone,Enrico Ferrentino,Pasquale Chiacchio,Francesco Braghin,Loris Roveda*

Main category: cs.RO

TL;DR: 提出了一种基于神经网络的力追踪控制策略 VAICAM，通过考虑切向速度优化力追踪表现，在模拟器中验证优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统交互控制器需要大量调参或环境专业知识，实际应用中不切实际。本文提出了一种新的控制策略，利用神经网络增强直接力控制器的力追踪行为。

Method: 该方法采用前馈神经网络集成预测接触力，并通过优化问题生成最优残余动作，结合直接力控制器输出应用于阻抗控制器。

Result: VAICAM 在 Franka Emika Panda 机器人上验证，针对多种轨迹表现优于基准控制器。

Conclusion: VAICAM 在 Gazebo 模拟器中验证并展示了优于两种基准控制器的性能，尤其在快速运动中考虑切向速度显著提升了力追踪效果。

Abstract: As robotics gains popularity, interaction control becomes crucial for
ensuring force tracking in manipulator-based tasks. Typically, traditional
interaction controllers either require extensive tuning, or demand expert
knowledge of the environment, which is often impractical in real-world
applications. This work proposes a novel control strategy leveraging Neural
Networks (NNs) to enhance the force-tracking behavior of a Direct Force
Controller (DFC). Unlike similar previous approaches, it accounts for the
manipulator's tangential velocity, a critical factor in force exertion,
especially during fast motions. The method employs an ensemble of feedforward
NNs to predict contact forces, then exploits the prediction to solve an
optimization problem and generate an optimal residual action, which is added to
the DFC output and applied to an impedance controller. The proposed
Velocity-augmented Artificial intelligence Interaction Controller for Ambiguous
Models (VAICAM) is validated in the Gazebo simulator on a Franka Emika Panda
robot. Against a vast set of trajectories, VAICAM achieves superior performance
compared to two baseline controllers.

</details>


### [104] [Dual-Stage Safe Herding Framework for Adversarial Attacker in Dynamic Environment](https://arxiv.org/abs/2509.08460)
*Wenqing Wang,Ye Zhang,Haoyu Li,Jingyu Wang*

Main category: cs.RO

TL;DR: 提出一种分层混合框架，用于在动态环境中安全引导对抗性代理。


<details>
  <summary>Details</summary>
Motivation: 解决传统固定编队方法在复杂和对抗性环境中无效或高风险的问题。

Method: 基于可达-避免博弈论和局部运动规划的分层混合框架，结合虚拟边界和事件触发的追逐机制。

Result: 仿真结果表明，该方法能够安全高效地将对抗性代理引导至指定区域。

Conclusion: 论文提出的分层混合框架在动态环境中成功实现了对抗性代理的安全引导。

Abstract: Recent advances in robotics have enabled the widespread deployment of
autonomous robotic systems in complex operational environments, presenting both
unprecedented opportunities and significant security problems. Traditional
shepherding approaches based on fixed formations are often ineffective or risky
in urban and obstacle-rich scenarios, especially when facing adversarial agents
with unknown and adaptive behaviors. This paper addresses this challenge as an
extended herding problem, where defensive robotic systems must safely guide
adversarial agents with unknown strategies away from protected areas and into
predetermined safe regions, while maintaining collision-free navigation in
dynamic environments. We propose a hierarchical hybrid framework based on
reach-avoid game theory and local motion planning, incorporating a virtual
containment boundary and event-triggered pursuit mechanisms to enable scalable
and robust multi-agent coordination. Simulation results demonstrate that the
proposed approach achieves safe and efficient guidance of adversarial agents to
designated regions.

</details>


### [105] [CLAP: Clustering to Localize Across n Possibilities, A Simple, Robust Geometric Approach in the Presence of Symmetries](https://arxiv.org/abs/2509.08495)
*Gabriel I. Fernandez,Ruochen Hou,Alex Xu,Colin Togashi,Dennis W. Hong*

Main category: cs.RO

TL;DR: CLAP是一种鲁棒的定位算法，通过聚类状态估计和结合滤波技术，在复杂环境下表现优异，助力赢得RoboCup 2024比赛。


<details>
  <summary>Details</summary>
Motivation: 由于比赛规则限制传感器仅使用立体视觉和惯性传感器，且需应对复杂的环境干扰，需要一个准确且鲁棒的定位算法。

Method: CLAP通过聚类估计的机器人状态对来定位其全局位置和方向，结合粒子滤波和扩展卡尔曼滤波以提高一致性和平滑性。

Result: 在测试中，CLAP在准确性上与其他地标定位方法相当，但在鲁棒性方面表现更优，尤其在错误特征检测增加的情况下。

Conclusion: CLAP算法在RoboCup 2024比赛中表现优异，为路径规划和游戏策略提供了可靠的基础，尤其在鲁棒性方面显著优于其他方法。

Abstract: In this paper, we present our localization method called CLAP, Clustering to
Localize Across $n$ Possibilities, which helped us win the RoboCup 2024
adult-sized autonomous humanoid soccer competition. Competition rules limited
our sensor suite to stereo vision and an inertial sensor, similar to humans. In
addition, our robot had to deal with varying lighting conditions, dynamic
feature occlusions, noise from high-impact stepping, and mistaken features from
bystanders and neighboring fields. Therefore, we needed an accurate, and most
importantly robust localization algorithm that would be the foundation for our
path-planning and game-strategy algorithms. CLAP achieves these requirements by
clustering estimated states of our robot from pairs of field features to
localize its global position and orientation. Correct state estimates naturally
cluster together, while incorrect estimates spread apart, making CLAP resilient
to noise and incorrect inputs. CLAP is paired with a particle filter and an
extended Kalman filter to improve consistency and smoothness. Tests of CLAP
with other landmark-based localization methods showed similar accuracy.
However, tests with increased false positive feature detection showed that CLAP
outperformed other methods in terms of robustness with very little divergence
and velocity jumps. Our localization performed well in competition, allowing
our robot to shoot faraway goals and narrowly defend our goal.

</details>


### [106] [Facilitating the Emergence of Assistive Robots to Support Frailty: Psychosocial and Environmental Realities](https://arxiv.org/abs/2509.08510)
*Angela Higgins,Stephen Potter,Mauro Dragone,Mark Hawley,Farshid Amirabdollahian,Alessandro Di Nuovo,Praminda Caleb-Solly*

Main category: cs.RO

TL;DR: 通过共设计研讨会，研究发现辅助机器人设计需考虑心理社会和环境因素，提出了更贴近实际需求的设计要求。


<details>
  <summary>Details</summary>
Motivation: 辅助机器人在帮助老年人应对脆弱性相关需求方面具有巨大潜力，但目前实际应用较少，实验室开发与实际应用之间存在差距。

Method: 通过一系列共设计研讨会（7次会议，61名参与者），包括有脆弱性生活经历的人、他们的照顾者和医疗专业人员，采用基于角色的方法来探讨情感、社会和心理问题。

Result: 研究发现，辅助解决方案必须考虑到心理社会和环境因素的复杂相互作用，并提出了与脆弱性直接相关的设计需求，以促进更实用的设计思维。

Conclusion: 研究强调了在设计辅助机器人时必须考虑心理社会和环境因素的复杂相互作用，以更贴近实际需求的方式推动辅助机器人技术的实际应用。

Abstract: While assistive robots have much potential to help older people with
frailty-related needs, there are few in use. There is a gap between what is
developed in laboratories and what would be viable in real-world contexts.
Through a series of co-design workshops (61 participants across 7 sessions)
including those with lived experience of frailty, their carers, and healthcare
professionals, we gained a deeper understanding of everyday issues concerning
the place of new technologies in their lives. A persona-based approach surfaced
emotional, social, and psychological issues. Any assistive solution must be
developed in the context of this complex interplay of psychosocial and
environmental factors. Our findings, presented as design requirements in direct
relation to frailty, can help promote design thinking that addresses people's
needs in a more pragmatic way to move assistive robotics closer to real-world
use.

</details>


### [107] [FMT$^{x}$: An Efficient and Asymptotically Optimal Extension of the Fast Marching Tree for Dynamic Replanning](https://arxiv.org/abs/2509.08521)
*Soheil Espahbodini Nia*

Main category: cs.RO

TL;DR: FMT$^{x}$是FMT$^{*}$的扩展，通过改进邻居选择和更新机制，实现了动态环境中的高效路径重新规划，保持了最优性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中路径规划的挑战，尤其是针对FMT$^{*}$算法无法实时更新路径的局限性。

Method: FMT$^{x}$通过改进FMT$^{*}$的邻居选择规则，引入成本有序的优先队列和选择性更新条件，实现了高效的路径重新规划。

Result: FMT$^{x}$在实验中表现优于RRT$^{x}$，能够更快响应动态事件且计算开销更低。

Conclusion: FMT$^{x}$在动态环境中保持了FMT$^{*}$的渐近最优性和计算效率，同时通过高效的重新规划策略提升了实时适应性，为机器人导航提供了更有效的解决方案。

Abstract: Path planning in dynamic environments remains a core challenge in robotics,
especially as autonomous systems are deployed in unpredictable spaces such as
warehouses and public roads. While algorithms like Fast Marching Tree
(FMT$^{*}$) offer asymptotically optimal solutions in static settings, their
single-pass design prevents path revisions which are essential for real-time
adaptation. On the other hand, full replanning is often too computationally
expensive. This paper introduces FMT$^{x}$, an extension of the Fast Marching
Tree algorithm that enables efficient and consistent replanning in dynamic
environments. We revisit the neighbor selection rule of FMT$^{*}$ and
demonstrate that a minimal change overcomes its single-pass limitation,
enabling the algorithm to update cost-to-come values upon discovering better
connections without sacrificing asymptotic optimality or computational
efficiency. By maintaining a cost-ordered priority queue and applying a
selective update condition that uses an expanding neighbor to identify and
trigger the re-evaluation of any node with a potentially suboptimal path,
FMT$^{x}$ ensures that suboptimal routes are efficiently repaired as the
environment evolves. This targeted strategy preserves the inherent efficiency
of FMT$^{*}$ while enabling robust adaptation to changes in obstacle
configuration. FMT$^{x}$ is proven to recover an asymptotically optimal
solution after environmental changes. Experimental results demonstrate that
FMT$^{x}$ outperforms the influential replanner RRT$^{x}$, reacting more
swiftly to dynamic events with lower computational overhead and thus offering a
more effective solution for real-time robotic navigation in unpredictable
worlds.

</details>


### [108] [RoboMatch: A Mobile-Manipulation Teleoperation Platform with Auto-Matching Network Architecture for Long-Horizon Manipulation](https://arxiv.org/abs/2509.08522)
*Hanyu Liu,Yunsheng Ma,Jiaxin Huang,Keqiang Ren,Jiayi Wen,Yilin Zheng,Baishu Wan,Pan Li,Jiejun Hou,Haoru Luan,Zhihua Wang,Zhigong Song*

Main category: cs.RO

TL;DR: RoboMatch是一个新型远程操作平台，通过驾驶舱式控制和PVE-DP+AMN技术，显著提升动态环境中长时程任务的性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决动态环境中长时程移动操作任务的挑战，提升远程操作的性能和数据收集效率。

Method: 系统核心是驾驶舱式控制界面，支持移动底座和双臂的同步操作，结合了PVE-DP（利用DWT进行多尺度视觉特征提取和高精度IMU增强本体反馈）和AMN（将长时程任务分解为逻辑序列并动态分配轻量级预训练模型进行分布式推理）。

Result: 实验表明，数据收集效率提升超过20%，PVE-DP使任务成功率提高20-30%，AMN将长时程推理性能提升约40%。

Conclusion: RoboMatch提供了一个统一的远程操作平台，通过自动匹配网络架构显著提升了动态环境中长时程任务的性能，包括数据收集效率、任务准确性和操作稳定性。

Abstract: This paper presents RoboMatch, a novel unified teleoperation platform for
mobile manipulation with an auto-matching network architecture, designed to
tackle long-horizon tasks in dynamic environments. Our system enhances
teleoperation performance, data collection efficiency, task accuracy, and
operational stability. The core of RoboMatch is a cockpit-style control
interface that enables synchronous operation of the mobile base and dual arms,
significantly improving control precision and data collection. Moreover, we
introduce the Proprioceptive-Visual Enhanced Diffusion Policy (PVE-DP), which
leverages Discrete Wavelet Transform (DWT) for multi-scale visual feature
extraction and integrates high-precision IMUs at the end-effector to enrich
proprioceptive feedback, substantially boosting fine manipulation performance.
Furthermore, we propose an Auto-Matching Network (AMN) architecture that
decomposes long-horizon tasks into logical sequences and dynamically assigns
lightweight pre-trained models for distributed inference. Experimental results
demonstrate that our approach improves data collection efficiency by over 20%,
increases task success rates by 20-30% with PVE-DP, and enhances long-horizon
inference performance by approximately 40% with AMN, offering a robust solution
for complex manipulation tasks.

</details>


### [109] [AutoODD: Agentic Audits via Bayesian Red Teaming in Black-Box Models](https://arxiv.org/abs/2509.08638)
*Rebecca Martin,Jay Patrikar,Sebastian Scherer*

Main category: cs.RO

TL;DR: \coolname是一个利用LLM-Agent自动生成测试用例的框架，用于审计黑盒模型，减少人工需求，提升安全性。


<details>
  <summary>Details</summary>
Motivation: 由于专业机器学习模型在高风险场景中的使用增加，确保其安全性和合规性至关重要。传统审计方法需要大量人力和专业知识，因此需要自动化解决方案。

Method: 利用LLM-Agent作为工具协调器，将高维输入空间投影到低维文本嵌入潜在空间，构建不确定性感知的失败分布模型。通过迭代生成测试用例并记录模型响应，LLM-Agent逐步构建失败情况图。

Result: 在MNIST数据集和无人机视觉入侵检测的实际场景中验证了框架的有效性，展示了其在发现模型失败模式方面的潜力。

Conclusion: 通过引入\coolname框架，成功实现了对专业黑盒模型的自动化测试用例生成，有效降低了人工和领域知识的需求，提升了模型审计的效率和安全性。

Abstract: Specialized machine learning models, regardless of architecture and training,
are susceptible to failures in deployment. With their increasing use in high
risk situations, the ability to audit these models by determining their
operational design domain (ODD) is crucial in ensuring safety and compliance.
However, given the high-dimensional input spaces, this process often requires
significant human resources and domain expertise. To alleviate this, we
introduce \coolname, an LLM-Agent centric framework for automated generation of
semantically relevant test cases to search for failure modes in specialized
black-box models. By leveraging LLM-Agents as tool orchestrators, we aim to fit
a uncertainty-aware failure distribution model on a learned text-embedding
manifold by projecting the high-dimension input space to low-dimension
text-embedding latent space. The LLM-Agent is tasked with iteratively building
the failure landscape by leveraging tools for generating test-cases to probe
the model-under-test (MUT) and recording the response. The agent also guides
the search using tools to probe uncertainty estimate on the low dimensional
manifold. We demonstrate this process in a simple case using models trained
with missing digits on the MNIST dataset and in the real world setting of
vision-based intruder detection for aerial vehicles.

</details>


### [110] [TANGO: Traversability-Aware Navigation with Local Metric Control for Topological Goals](https://arxiv.org/abs/2509.08699)
*Stefan Podgorski,Sourav Garg,Mehdi Hosseinzadeh,Lachlan Mares,Feras Dayoub,Ian Reid*

Main category: cs.RO

TL;DR: 论文提出了一种无需3D地图或预训练控制器的RGB-only对象级导航方法，整合全局规划和局部控制，在开放集环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统视觉导航依赖全局一致的3D地图或学习控制器，计算成本高且难以泛化到多样化环境。为解决这些限制，论文提出了一种新的导航方法。

Method: 该方法结合了全局拓扑路径规划和局部度量轨迹控制，使用单目深度和可穿越性估计持续预测局部轨迹，并引入自动切换机制在必要时回退到基线控制器。系统基于基础模型运行，无需领域特定微调。

Result: 在仿真环境和实际测试中，该方法表现出色，超越了现有最先进方法，展示了其鲁棒性和可部署性。源代码已公开。

Conclusion: 该论文提出了一种新型的RGB-only、对象级拓扑导航管道，能够在不需要3D地图或预训练控制器的情况下实现零样本、长距离机器人导航。通过整合全局拓扑路径规划和局部度量轨迹控制，该方法在开放集环境中展现出更高的适应性和有效性。

Abstract: Visual navigation in robotics traditionally relies on globally-consistent 3D
maps or learned controllers, which can be computationally expensive and
difficult to generalize across diverse environments. In this work, we present a
novel RGB-only, object-level topometric navigation pipeline that enables
zero-shot, long-horizon robot navigation without requiring 3D maps or
pre-trained controllers. Our approach integrates global topological path
planning with local metric trajectory control, allowing the robot to navigate
towards object-level sub-goals while avoiding obstacles. We address key
limitations of previous methods by continuously predicting local trajectory
using monocular depth and traversability estimation, and incorporating an
auto-switching mechanism that falls back to a baseline controller when
necessary. The system operates using foundational models, ensuring open-set
applicability without the need for domain-specific fine-tuning. We demonstrate
the effectiveness of our method in both simulated environments and real-world
tests, highlighting its robustness and deployability. Our approach outperforms
existing state-of-the-art methods, offering a more adaptable and effective
solution for visual navigation in open-set environments. The source code is
made publicly available: https://github.com/podgorki/TANGO.

</details>


### [111] [Parallel, Asymptotically Optimal Algorithms for Moving Target Traveling Salesman Problems](https://arxiv.org/abs/2509.08743)
*Anoop Bhat,Geordan Gutow,Bhaskar Vundurthy,Zhongqiang Ren,Sivakumar Rathinam,Howie Choset*

Main category: cs.RO

TL;DR: IRG框架通过交替随机采样和求解GTSP，实现了MT-TSP问题的最优解收敛，并提出的两种并行算法在实验中表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 针对非线性目标轨迹或代理运动学约束下MT-TSP问题缺乏最优解保证的现状，提出了一种新的求解框架。

Method: 提出了IRG框架，包括随机采样代理配置-时间点和求解广义TSP（GTSP）的交替过程，并在此框架下开发了两种并行算法：IRG-PGLNS和PCG。

Result: IRG-PGLNS和PCG在三种MT-TSP变体上均展现出比基线方法更快的收敛速度。

Conclusion: IRG-PGLNS和PCG算法在MT-TSP问题上表现出优于基线方法的收敛速度。

Abstract: The Moving Target Traveling Salesman Problem (MT-TSP) seeks an agent
trajectory that intercepts several moving targets, within a particular time
window for each target. In the presence of generic nonlinear target
trajectories or kinematic constraints on the agent, no prior algorithm
guarantees convergence to an optimal MT-TSP solution. Therefore, we introduce
the Iterated Random Generalized (IRG) TSP framework. The key idea behind IRG is
to alternate between randomly sampling a set of agent configuration-time
points, corresponding to interceptions of targets, and finding a sequence of
interception points by solving a generalized TSP (GTSP). This alternation
enables asymptotic convergence to the optimum. We introduce two parallel
algorithms within the IRG framework. The first algorithm, IRG-PGLNS, solves
GTSPs using PGLNS, our parallelized extension of the state-of-the-art solver
GLNS. The second algorithm, Parallel Communicating GTSPs (PCG), solves GTSPs
corresponding to several sets of points simultaneously. We present numerical
results for three variants of the MT-TSP: one where intercepting a target only
requires coming within a particular distance, another where the agent is a
variable-speed Dubins car, and a third where the agent is a redundant robot
arm. We show that IRG-PGLNS and PCG both converge faster than a baseline based
on prior work.

</details>


### [112] [SocialNav-SUB: Benchmarking VLMs for Scene Understanding in Social Robot Navigation](https://arxiv.org/abs/2509.08757)
*Michael J. Munje,Chen Tang,Shuijing Liu,Zichao Hu,Yifeng Zhu,Jiaxun Cui,Garrett Warnell,Joydeep Biswas,Peter Stone*

Main category: cs.RO

TL;DR: 论文提出SocialNav-SUB基准，评估VLMs在社交机器人导航中的场景理解能力，发现当前VLMs虽有一定潜力，但仍存在关键差距。


<details>
  <summary>Details</summary>
Motivation: 社交机器人导航需要基于场景理解的社交合规决策，而VLMs展现出的能力（如物体识别、常识推理和上下文理解）与这一需求相符。然而，VLMs是否能准确理解复杂的社交导航场景尚不明确。

Method: 引入了Social Navigation Scene Understanding Benchmark（SocialNav-SUB），这是一个视觉问答（VQA）数据集和基准，用于评估VLMs在真实世界社交机器人导航场景中的场景理解能力。通过实验比较了最先进的VLMs与人类和基于规则的基线。

Result: 实验表明，尽管表现最佳的VLM与人类答案一致的概率令人鼓舞，但其表现仍不及简单的基于规则的方法和人类共识基线，揭示了当前VLMs在社交场景理解上的关键差距。

Conclusion: 当前的视觉语言模型（VLMs）在社交机器人导航场景理解方面存在关键差距，尽管表现最佳模型的概率与人类答案一致，但仍不及简单的基于规则的方法和人类共识基线。SocialNav-SUB基准为未来研究提供了框架，探索如何定制VLMs以满足实际社交机器人导航需求。

Abstract: Robot navigation in dynamic, human-centered environments requires
socially-compliant decisions grounded in robust scene understanding. Recent
Vision-Language Models (VLMs) exhibit promising capabilities such as object
recognition, common-sense reasoning, and contextual understanding-capabilities
that align with the nuanced requirements of social robot navigation. However,
it remains unclear whether VLMs can accurately understand complex social
navigation scenes (e.g., inferring the spatial-temporal relations among agents
and human intentions), which is essential for safe and socially compliant robot
navigation. While some recent works have explored the use of VLMs in social
robot navigation, no existing work systematically evaluates their ability to
meet these necessary conditions. In this paper, we introduce the Social
Navigation Scene Understanding Benchmark (SocialNav-SUB), a Visual Question
Answering (VQA) dataset and benchmark designed to evaluate VLMs for scene
understanding in real-world social robot navigation scenarios. SocialNav-SUB
provides a unified framework for evaluating VLMs against human and rule-based
baselines across VQA tasks requiring spatial, spatiotemporal, and social
reasoning in social robot navigation. Through experiments with state-of-the-art
VLMs, we find that while the best-performing VLM achieves an encouraging
probability of agreeing with human answers, it still underperforms simpler
rule-based approach and human consensus baselines, indicating critical gaps in
social scene understanding of current VLMs. Our benchmark sets the stage for
further research on foundation models for social robot navigation, offering a
framework to explore how VLMs can be tailored to meet real-world social robot
navigation needs. An overview of this paper along with the code and data can be
found at https://larg.github.io/socialnav-sub .

</details>


### [113] [Joint Model-based Model-free Diffusion for Planning with Constraints](https://arxiv.org/abs/2509.08775)
*Wonsuhk Jung,Utkarsh A. Mishra,Nadun Ranawaka Arachchige,Yongxin Chen,Danfei Xu,Shreyas Kousik*

Main category: cs.RO

TL;DR: JM2D是一种新型生成建模框架，通过联合采样解决扩散规划器与安全模块的兼容性问题，无需额外训练，显著提升任务性能且不牺牲安全性。


<details>
  <summary>Details</summary>
Motivation: 解决模型自由扩散规划器与基于模型的优化模块（如安全约束）集成时的兼容性挑战。

Method: JM2D将模块集成建模为一个联合采样问题，通过交互势最大化兼容性，无需额外训练。利用重要性采样，JM2D仅基于交互势的评估来引导模块输出。

Result: JM2D在离线RL和机器人操作任务中显著提升了性能，同时保持了安全性。

Conclusion: JM2D显著提升了任务性能，同时不牺牲安全性，并通过与最先进的梯度基和投影基扩散规划器的比较，阐明了关键设计选择。

Abstract: Model-free diffusion planners have shown great promise for robot motion
planning, but practical robotic systems often require combining them with
model-based optimization modules to enforce constraints, such as safety.
Naively integrating these modules presents compatibility challenges when
diffusion's multi-modal outputs behave adversarially to optimization-based
modules. To address this, we introduce Joint Model-based Model-free Diffusion
(JM2D), a novel generative modeling framework. JM2D formulates module
integration as a joint sampling problem to maximize compatibility via an
interaction potential, without additional training. Using importance sampling,
JM2D guides modules outputs based only on evaluations of the interaction
potential, thus handling non-differentiable objectives commonly arising from
non-convex optimization modules. We evaluate JM2D via application to aligning
diffusion planners with safety modules on offline RL and robot manipulation.
JM2D significantly improves task performance compared to conventional safety
filters without sacrificing safety. Further, we show that conditional
generation is a special case of JM2D and elucidate key design choices by
comparing with SOTA gradient-based and projection-based diffusion planners.
More details at: https://jm2d-corl25.github.io/.

</details>


### [114] [Calib3R: A 3D Foundation Model for Multi-Camera to Robot Calibration and 3D Metric-Scaled Scene Reconstruction](https://arxiv.org/abs/2509.08813)
*Davide Allegro,Matteo Terreran,Stefano Ghidoni*

Main category: cs.RO

TL;DR: Calib3R 是一种无需标记的方法，联合优化相机校准和 3D 重建，适用于单/多摄像头设置，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 机器人通常依赖 RGB 图像进行任务，但可靠的交互需要度量尺度且与机器人参考系对齐的 3D 场景表示，传统方法需要标记且校准和重建任务分开处理。

Method: Calib3R 基于 3D 基础模型 MASt3R 从 RGB 图像中提取点图，并结合机器人姿态重建与机器人对齐的尺度 3D 场景。

Result: 实验表明，Calib3R 在少于 10 张图像的情况下实现了准确的校准，优于无目标和基于标记的方法。

Conclusion: Calib3R 是一种无需标记的方法，能够通过统一优化联合执行相机到机器人的校准和度量尺度的 3D 重建，适用于单摄像头和多摄像头设置，且在实验中表现出色，优于无目标和基于标记的方法。

Abstract: Robots often rely on RGB images for tasks like manipulation and navigation.
However, reliable interaction typically requires a 3D scene representation that
is metric-scaled and aligned with the robot reference frame. This depends on
accurate camera-to-robot calibration and dense 3D reconstruction, tasks usually
treated separately, despite both relying on geometric correspondences from RGB
data. Traditional calibration needs patterns, while RGB-based reconstruction
yields geometry with an unknown scale in an arbitrary frame. Multi-camera
setups add further complexity, as data must be expressed in a shared reference
frame. We present Calib3R, a patternless method that jointly performs
camera-to-robot calibration and metric-scaled 3D reconstruction via unified
optimization. Calib3R handles single- and multi-camera setups on robot arms or
mobile robots. It builds on the 3D foundation model MASt3R to extract pointmaps
from RGB images, which are combined with robot poses to reconstruct a scaled 3D
scene aligned with the robot. Experiments on diverse datasets show that Calib3R
achieves accurate calibration with less than 10 images, outperforming
target-less and marker-based methods.

</details>


### [115] [RoboChemist: Long-Horizon and Safety-Compliant Robotic Chemical Experimentation](https://arxiv.org/abs/2509.08820)
*Zongzheng Zhang,Chenghao Yue,Haobo Xu,Minwen Liao,Xianglin Qi,Huan-ang Gao,Ziwei Wang,Hao Zhao*

Main category: cs.RO

TL;DR: RoboChemist通过VLM与VLA模型的结合，提升了化学实验自动化的成功率和合规性，展示了强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 化学实验涉及危险和可变形物质的长流程操作，现有自动化系统在透明实验室器具处理及语义反馈方面存在不足。

Method: 提出了一种双循环框架，结合VLM和VLA模型，利用VLM进行任务分解、视觉提示生成和监控，同时引入基于图像的视觉目标接口以实现精确控制。

Result: 相比现有VLA基线，RoboChemist的平均成功率提高了23.57%，合规率平均提升0.298，且在对象和任务上表现出强泛化能力。

Conclusion: RoboChemist通过整合VLM和VLA模型，显著提升了化学实验的自动化执行效率和合规性，展示了在复杂任务中的强泛化能力。

Abstract: Robotic chemists promise to both liberate human experts from repetitive tasks
and accelerate scientific discovery, yet remain in their infancy. Chemical
experiments involve long-horizon procedures over hazardous and deformable
substances, where success requires not only task completion but also strict
compliance with experimental norms. To address these challenges, we propose
\textit{RoboChemist}, a dual-loop framework that integrates Vision-Language
Models (VLMs) with Vision-Language-Action (VLA) models. Unlike prior VLM-based
systems (e.g., VoxPoser, ReKep) that rely on depth perception and struggle with
transparent labware, and existing VLA systems (e.g., RDT, pi0) that lack
semantic-level feedback for complex tasks, our method leverages a VLM to serve
as (1) a planner to decompose tasks into primitive actions, (2) a visual prompt
generator to guide VLA models, and (3) a monitor to assess task success and
regulatory compliance. Notably, we introduce a VLA interface that accepts
image-based visual targets from the VLM, enabling precise, goal-conditioned
control. Our system successfully executes both primitive actions and complete
multi-step chemistry protocols. Results show 23.57% higher average success rate
and a 0.298 average increase in compliance rate over state-of-the-art VLA
baselines, while also demonstrating strong generalization to objects and tasks.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [116] [Aurora: Architecting Argonne's First Exascale Supercomputer for Accelerated Scientific Discovery](https://arxiv.org/abs/2509.08207)
*Benjamin S. Allen,James Anchell,Victor Anisimov,Thomas Applencourt,Abhishek Bagusetty,Ramesh Balakrishnan,Riccardo Balin,Solomon Bekele,Colleen Bertoni,Cyrus Blackworth,Renzo Bustamante,Kevin Canada,John Carrier,Christopher Chan-nui,Lance C. Cheney,Taylor Childers,Paul Coffman,Susan Coghlan,Michael D'Mello,Murali Emani,Kyle G. Felker,Sam Foreman,Olivier Franza,Longfei Gao,Marta García,María Garzarán,Balazs Gerofi,Yasaman Ghadar,Neha Gupta,Kevin Harms,Väinö Hatanpää,Brian Holland,Carissa Holohan,Brian Homerding,Khalid Hossain,Louise Huot,Huda Ibeid,Joseph A. Insley,Sai Jayanthi,Hong Jiang,Wei Jiang,Xiao-Yong Jin,Jeongnim Kim,Christopher Knight,Kalyan Kumaran,JaeHyuk Kwack,Ti Leggett,Ben Lenard,Chris Lewis,Nevin Liber,Johann Lombardi,Raymond M. Loy,Ye Luo,Bethany Lusch,Nilakantan Mahadevan,Victor A. Mateevitsi,Gordon McPheeters,Ryan Milner,Vitali A. Morozov,Servesh Muralidharan,Tom Musta,Mrigendra Nagar,Vikram Narayana,Marieme Ngom,Anthony-Trung Nguyen,Nathan Nichols,Aditya Nishtala,James C. Osborn,Michael E. Papka,Scott Parker,Saumil S. Patel,Adrian C. Pope,Sucheta Raghunanda,Esteban Rangel,Paul M. Rich,Silvio Rizzi,Kris Rowe,Varuni Sastry,Adam Scovel,Filippo Simini,Haritha Siddabathuni Som,Patrick Steinbrecher,Rick Stevens,Xinmin Tian,Peter Upton,Thomas Uram,Archit K. Vasan,Álvaro Vázquez-Mayagoitia,Kaushik Velusamy,Brice Videau,Venkatram Vishwanath,Brian Whitney,Timothy J. Williams,Michael Woodacre,Sam Zeltner,Gengbin Zheng,Huihuo Zheng*

Main category: cs.DC

TL;DR: Aurora是Argonne国家实验室的Exascale超级计算机，集成了Intel Xeon和GPU Max系列、DAOS存储解决方案及oneAPI编程环境，通过基准测试和早期科学计划验证了其高性能和应用准备情况。


<details>
  <summary>Details</summary>
Motivation: 为了加速科学发现，Argonne国家实验室设计了Aurora超级计算机，结合了前沿的硬件和软件技术，以满足Exascale计算的需求。

Method: 本文深入探讨了Aurora的节点架构、HPE Slingshot互连技术、支持软件生态系统以及DAOS存储解决方案，并通过标准基准测试和应用准备努力（如Aurora早期科学计划和Exascale计算项目）进行了性能分析。

Result: Aurora展示了其在标准基准测试中的高性能，并通过早期科学计划和Exascale计算项目证明了其应用的准备情况。

Conclusion: Aurora超级计算机通过其创新的架构设计和关键技术（如Intel Xeon和GPU Max系列、DAOS存储解决方案及oneAPI编程环境），为科学发现提供了强大的计算支持，并通过早期科学计划和Exascale计算项目验证了其性能和应用的准备情况。

Abstract: Aurora is Argonne National Laboratory's pioneering Exascale supercomputer,
designed to accelerate scientific discovery with cutting-edge architectural
innovations. Key new technologies include the Intel(TM) Xeon(TM) Data Center
GPU Max Series (code-named Sapphire Rapids) with support for High Bandwidth
Memory (HBM), alongside the Intel(TM) Data Center GPU Max Series (code-named
Ponte Vecchio) on each compute node. Aurora also integrates the Distributed
Asynchronous Object Storage (DAOS), a novel exascale storage solution, and
leverages Intel's oneAPI programming environment. This paper presents an
in-depth exploration of Aurora's node architecture, the HPE Slingshot
interconnect, the supporting software ecosystem, and DAOS. We provide insights
into standard benchmark performance and applications readiness efforts via
Aurora's Early Science Program and the Exascale Computing Project.

</details>


### [117] [Design and Implementation of Code Completion System Based on LLM and CodeBERT Hybrid Subsystem](https://arxiv.org/abs/2509.08215)
*Bingbing Zhang,Ziyu Lin,Yingxin Su*

Main category: cs.DC

TL;DR: 本研究通过集成CodeBERT和GPT-3.5的优势，开发了一个混合模型，用于代码建议和自动补全任务，表现出色并证实了其可行性。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的软件开发行业中，编码效率和准确性在交付高质量软件中起着重要作用。现有的代码建议和补全工具各有优势，但单独使用时无法充分发挥潜力。

Method: 实现了一个混合模型，集成了CodeBERT和GPT-3.5模型，利用CodeBERT的上下文感知有效性和GPT-3.5的高级代码生成能力来完成代码建议和自动补全任务。

Result: 在准确性、生成代码质量和性能效率三个主要指标上，混合模型优于基准模型，稳健性测试进一步证实了其可靠性和稳定性。

Conclusion: 本研究强调了深度学习在软件开发行业中的重要性，并揭示了合成互补深度学习模型以充分利用各自优势的潜力。

Abstract: In the rapidly evolving industry of software development, coding efficiency
and accuracy play significant roles in delivering high-quality software.
Various code suggestion and completion tools, such as CodeBERT from Microsoft
and GPT-3.5 from OpenAI, have been developed using deep learning techniques and
integrated into IDEs to assist software engineers' development. Research has
shown that CodeBERT has outstanding performance in code summarization and
capturing code semantics, while GPT-3.5 demonstrated its adept capability at
code generation. This study focuses on implementing a hybrid model that
integrates CodeBERT and GPT-3.5 models to accomplish code suggestion and
autocomplete tasks, leveraging the context-aware effectiveness of CodeBERT and
taking advantage of advanced code generation abilities of GPT-3.5. Evaluated in
three main metrics: accuracy, quality of generated code and performance
efficiency with various software and hardware, the hybrid model outperforms
benchmarks, demonstrating its feasibility and effectiveness. Robustness testing
further confirms the reliability and stability of the hybrid model. This study
not only emphasizes the importance of deep learning in the software development
industry, but also reveals the potential of synthesizing complementary deep
learning models to fully exploit strengths of each model.

</details>


### [118] [Hetis: Serving LLMs in Heterogeneous GPU Clusters with Fine-grained and Dynamic Parallelism](https://arxiv.org/abs/2509.08309)
*Zizhao Mo,Jianxiong Liao,Huanle Xu,Zhi Zhou,Chengzhong Xu*

Main category: cs.DC

TL;DR: Hetis是为异构GPU集群设计的LLM系统，通过动态并行化和在线负载调度，显著提升服务性能。


<details>
  <summary>Details</summary>
Motivation: 解决异构硬件环境下现有并行化方法因粗粒度和静态策略导致的扩展效率低下问题。

Method: Hetis采用选择性并行化计算密集型操作和动态分发Attention计算到低端GPU的策略，并结合在线负载调度策略优化服务性能。

Result: Hetis的吞吐量提升了2.25倍，延迟降低了1.49倍。

Conclusion: Hetis通过细粒度和动态并行化设计，显著提升了异构GPU集群中LLM服务的吞吐量并降低了延迟。

Abstract: The significant resource demands in LLM serving prompts production clusters
to fully utilize heterogeneous hardware by partitioning LLM models across a mix
of high-end and low-end GPUs. However, existing parallelization approaches
often struggle to scale efficiently in heterogeneous environments due to their
coarse-grained and static parallelization strategies.
  In this paper, we introduce Hetis, a new LLM system tailored for
heterogeneous GPU clusters. Hetis addresses two critical challenges: (1) memory
inefficiency caused by the mismatch between memory capacity and computational
power in heterogeneous devices, and (2) computational inefficiency arising from
performance gaps across different LLM modules. To tackle these issues, Hetis
employs a fine-grained and dynamic parallelism design. Specifically, it
selectively parallelizes compute-intensive operations to reduce latency and
dynamically distributes Attention computations to low-end GPUs at a head
granularity, leveraging the distinct characteristics of each module.
Additionally, Hetis features an online load dispatching policy that
continuously optimizes serving performance by carefully balancing network
latency, computational load, and memory intensity. Evaluation results
demonstrate that Hetis can improve serving throughput by up to $2.25\times$ and
reduce latency by $1.49\times$ compared to existing systems.

</details>


### [119] [An HPC Benchmark Survey and Taxonomy for Characterization](https://arxiv.org/abs/2509.08347)
*Andreas Herten,Olga Pearce,Filipe S. M. Guimarães*

Main category: cs.DC

TL;DR: 该论文调查并分类了HPC领域的基准测试，提出了一个分类法，并通过表格和交互式网站展示。


<details>
  <summary>Details</summary>
Motivation: 高性能计算（HPC）领域需要不断提供高性能计算设备，而基准测试是评估硬件、软件和算法的关键工具。现有基准测试种类繁多，缺乏统一分类，因此需要系统化的调查和分类。

Method: 论文通过调查现有的HPC基准测试，并以表格形式总结关键细节和简洁分类，同时通过交互式网站展示。

Result: 论文总结了现有HPC基准测试，提出了一个基准测试分类法，并通过交互式网站展示。

Conclusion: 该论文通过对现有HPC基准测试的全面调查和分类，提出了一个基准测试分类法，为系统架构师、研究人员和科学用户提供了明确的评估工具。

Abstract: The field of High-Performance Computing (HPC) is defined by providing
computing devices with highest performance for a variety of demanding
scientific users. The tight co-design relationship between HPC providers and
users propels the field forward, paired with technological improvements,
achieving continuously higher performance and resource utilization. A key
device for system architects, architecture researchers, and scientific users
are benchmarks, allowing for well-defined assessment of hardware, software, and
algorithms. Many benchmarks exist in the community, from individual niche
benchmarks testing specific features, to large-scale benchmark suites for whole
procurements. We survey the available HPC benchmarks, summarizing them in table
form with key details and concise categorization, also through an interactive
website. For categorization, we present a benchmark taxonomy for well-defined
characterization of benchmarks.

</details>


### [120] [Towards Communication-Efficient Decentralized Federated Graph Learning over Non-IID Data](https://arxiv.org/abs/2509.08409)
*Shilong Wang,Jianchun Liu,Hongli Xu,Chenxia Tang,Qianpiao Ma,Liusheng Huang*

Main category: cs.DC

TL;DR: Duplex是DFGL中联合优化网络拓扑和图采样的统一框架，显著降低通信成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的稀疏网络拓扑和图邻居采样方法虽然能降低DFGL的通信开销，但直接结合会导致训练性能下降，因此需要一种统一框架来解决这一问题。

Method: 提出了Duplex框架，联合优化网络拓扑和图采样，并引入学习驱动算法自适应确定最优网络拓扑和采样比例。

Result: 实验结果显示，Duplex在达到目标准确率时减少了20.1%-48.8%的完成时间和16.7%-37.6%的通信成本，同时在相同资源预算下提升了3.3%-7.9%的准确率。

Conclusion: Duplex通过联合优化网络拓扑和图采样，显著降低了通信成本并提升了训练性能，在DFGL中实现了更高的效率和准确性。

Abstract: Decentralized Federated Graph Learning (DFGL) overcomes potential bottlenecks
of the parameter server in FGL by establishing a peer-to-peer (P2P)
communication network among workers. However, while extensive cross-worker
communication of graph node embeddings is crucial for DFGL training, it
introduces substantial communication costs. Most existing works typically
construct sparse network topologies or utilize graph neighbor sampling methods
to alleviate the communication overhead in DFGL. Intuitively, integrating these
methods may offer promise for doubly improving communication efficiency in
DFGL. However, our preliminary experiments indicate that directly combining
these methods leads to significant training performance degradation if they are
jointly optimized. To address this issue, we propose Duplex, a unified
framework that jointly optimizes network topology and graph sampling by
accounting for their coupled relationship, thereby significantly reducing
communication cost while enhancing training performance in DFGL. To overcome
practical DFGL challenges, eg, statistical heterogeneity and dynamic network
environments, Duplex introduces a learning-driven algorithm to adaptively
determine optimal network topologies and graph sampling ratios for workers.
Experimental results demonstrate that Duplex reduces completion time by
20.1%--48.8% and communication costs by 16.7%--37.6% to achieve target
accuracy, while improving accuracy by 3.3%--7.9% under identical resource
budgets compared to baselines.

</details>


### [121] [A 410GFLOP/s, 64 RISC-V Cores, 204.8GBps Shared-Memory Cluster in 12nm FinFET with Systolic Execution Support for Efficient B5G/6G AI-Enhanced O-RAN](https://arxiv.org/abs/2509.08608)
*Yichao Zhang,Marco Bertuletti,Sergio Mazzola,Samuel Riedel,Luca Benini*

Main category: cs.DC

TL;DR: HeartStream是一种高效能的64-RV-core集群，专为AI增强的O-RAN设计，显著提升基带处理能效，满足B5G/6G严格功耗和延迟要求。


<details>
  <summary>Details</summary>
Motivation: 为满足AI增强的O-RAN对高效能基带处理的需求，设计一种能够在严格功耗和延迟限制下运行的解决方案。

Method: 通过定制化的核心和集群架构，支持复杂（16位实数和虚数）指令，包括乘法累加、除法和平方根、SIMD指令以及硬件管理的脉动队列。

Result: HeartStream在800MHz@0.8V下提供高达243GFLOP/s的复数无线工作负载处理能力，支持高效AI处理（72 GOP/s），并在645MHz@0.65V下仅消耗0.68W，满足B5G/6G上行链路的4ms端到端延迟限制。

Conclusion: HeartStream是一种高效能的64-RV-core共享L1内存集群，专为AI增强的O-RAN设计，支持复杂的基带处理指令，显著提升了关键基带内核的能效，并在B5G/6G上行链路中满足严格的功耗和延迟限制。

Abstract: We present HeartStream, a 64-RV-core shared-L1-memory cluster (410 GFLOP/s
peak performance and 204.8 GBps L1 bandwidth) for energy-efficient AI-enhanced
O-RAN. The cores and cluster architecture are customized for baseband
processing, supporting complex (16-bit real&imaginary) instructions:
multiply&accumulate, division&square-root, SIMD instructions, and
hardware-managed systolic queues, improving up to 1.89x the energy efficiency
of key baseband kernels. At 800MHz@0.8V, HeartStream delivers up to 243GFLOP/s
on complex-valued wireless workloads. Furthermore, the cores also support
efficient AI processing on received data at up to 72 GOP/s. HeartStream is
fully compatible with base station power and processing latency limits: it
achieves leading-edge software-defined PUSCH efficiency (49.6GFLOP/s/W) and
consumes just 0.68W (645MHz@0.65V), within the 4 ms end-to-end constraint for
B5G/6G uplink.

</details>


### [122] [Reconfigurable Holographic Surfaces and Near Field Communication for Non-Terrestrial Networks: Potential and Challenges](https://arxiv.org/abs/2509.08770)
*Muhammad Ali Jamshed,Muhammad Ahmed Mohsin,Hongliang Zhang,Bushra Haq,Aryan Kaushik,Boya Di,Weiwei Jiang*

Main category: cs.DC

TL;DR: 本文提出了一种结合NFC和RHS的NTN解决方案，通过整合RHS与NTN平台提升了能源效率和频谱利用率，并通过用例分析验证了无人机-RHS融合的潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决超低延迟、无处不在的覆盖和飙升的数据速率等挑战，本文探索了NFC和RHS在NTN中的联合应用，旨在提升能源效率、频谱利用率和空间分辨率。

Method: 本文提出了一种系统架构，整合了RHS与NTN平台（如卫星、高空平台站和无人机），以实现近场区域的精确波束成形和智能波前控制。此外，还进行了用例分析，验证了无人机-RHS融合在公共安全场景中的应用效果。

Result: 研究结果表明，整合RHS与NTN平台可以显著提升能源效率、频谱利用率和空间分辨率，并通过公共安全用例分析验证了无人机-RHS融合的潜力。

Conclusion: 本文提出了一种结合近场通信（NFC）和可重构全息表面（RHS）的非地面网络（NTN）解决方案，通过整合RHS与NTN平台（如卫星、高空平台站和无人机），实现了近场区域的精确波束成形和智能波前控制，从而提升了能源效率、频谱利用率和空间分辨率。此外，还识别了关键应用、挑战和未来发展方向，并通过公共安全用例分析进一步验证了无人机-RHS融合的潜力。

Abstract: To overcome the challenges of ultra-low latency, ubiquitous coverage, and
soaring data rates, this article presents a combined use of Near Field
Communication (NFC) and Reconfigurable Holographic Surfaces (RHS) for
Non-Terrestrial Networks (NTN). A system architecture has been presented, which
shows that the integration of RHS with NTN platforms such as satellites, High
Altitute Platform Stations (HAPS), and Uncrewed Aerial Vehicles (UAV) can
achieve precise beamforming and intelligent wavefront control in near-field
regions, enhancing Energy Efficiency (EE), spectral utilization, and spatial
resolution. Moreover, key applications, challenges, and future directions have
been identified to fully adopt this integration. In addition, a use case
analysis has been presented to improve the EE of the system in a public safety
use case scenario, further strengthening the UAV-RHS fusion.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [123] [ChatGPT for Code Refactoring: Analyzing Topics, Interaction, and Effective Prompts](https://arxiv.org/abs/2509.08090)
*Eman Abdullah AlOmar,Luo Xu,Sofia Martinez,Anthony Peruma,Mohamed Wiem Mkaouer,Christian D. Newman,Ali Ouni*

Main category: cs.SE

TL;DR: 本文通过分析开发者与ChatGPT的交互，探讨了开发者如何表达重构需求及ChatGPT的响应方式，为LLM在软件工程中的应用提供见解。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究探讨了LLM在推荐重构方面的有效性，但对开发者如何在与ChatGPT交互中表达重构需求的理解仍有限。本文旨在填补这一空白。

Method: 本文采用文本挖掘方法，从29,778个ChatGPT提示和响应中提取了715个与重构相关的交互，并分析了开发者的显式重构意图。

Result: 研究发现，开发者主要通过特定方式表达重构需求，而ChatGPT能够以多种方式响应这些需求，但效果因情境而异。

Conclusion: 通过对715个与重构相关的交互进行分析，本文揭示了开发者如何表达重构需求以及ChatGPT如何响应这些需求，为未来LLM在软件工程中的应用提供了参考。

Abstract: Large Language Models (LLMs), such as ChatGPT, have become widely popular and
widely used in various software engineering tasks such as refactoring, testing,
code review, and program comprehension. Although recent studies have examined
the effectiveness of LLMs in recommending and suggesting refactoring, there is
a limited understanding of how developers express their refactoring needs when
interacting with ChatGPT. In this paper, our goal is to explore interactions
related to refactoring between developers and ChatGPT to better understand how
developers identify areas for improvement in code, and how ChatGPT addresses
developers' needs. Our approach involves text mining 715 refactoring-related
interactions from 29,778 ChatGPT prompts and responses, as well as the analysis
of developers' explicit refactoring intentions.

</details>


### [124] [Safety Factories -- a Manifesto](https://arxiv.org/abs/2509.08285)
*Carmen Cârlan,Daniel Ratiu,Michael Wagner*

Main category: cs.SE

TL;DR: 本文提出安全工厂概念，旨在将安全工具和方法集成到软件开发管道中，以弥合软件开发与安全工程之间的脱节。


<details>
  <summary>Details</summary>
Motivation: 现代信息物理系统由复杂软件操作，这些软件承担着越来越多的安全关键功能。为了跟上软件的快速演变，需要在软件开发和安全工程之间建立联系。

Method: 提出将安全工具和方法集成到软件开发管道中的安全工厂概念。

Result: 通过将安全工具和方法集成到软件开发管道中，可以实现更高效的安全工程实践。

Conclusion: 本文主张建立安全工厂，将安全工具和方法集成到软件开发管道中，以弥合软件开发与安全工程之间的脱节。

Abstract: Modern cyber-physical systems are operated by complex software that
increasingly takes over safety-critical functions. Software enables rapid
iterations and continuous delivery of new functionality that meets the
ever-changing expectations of users. As high-speed development requires
discipline, rigor, and automation, software factories are used. These entail
methods and tools used for software development, such as build systems and
pipelines. To keep up with the rapid evolution of software, we need to bridge
the disconnect in methods and tools between software development and safety
engineering today. We need to invest more in formality upfront - capturing
safety work products in semantically rich models that are machine-processable,
defining automatic consistency checks, and automating the generation of
documentation - to benefit later. Transferring best practices from software to
safety engineering is worth exploring. We advocate for safety factories, which
integrate safety tooling and methods into software development pipelines.

</details>


### [125] [The Impact of Team Diversity in Agile Development Education](https://arxiv.org/abs/2509.08389)
*Marco Torchiano,Riccardo Coppola,Antonio Vetro',Xhoi Musaj*

Main category: cs.SE

TL;DR: 研究发现性别多样性对软件工程团队项目成功有正面影响，国籍多样性影响轻微负面，两者共存时负面影响更明显。总体而言，促进多样性不会损害团队绩效。


<details>
  <summary>Details</summary>
Motivation: 软件工程领域以男性为主导，性别多样性是改善机会平等、生产力和创新的关键特征。其他多样性方面（如国籍和种族）常被忽视，本研究旨在评估团队多样性（主要是性别和国籍）在敏捷软件开发项目课程中的影响。

Method: 分析了51个团队在三个学年中的表现，测量了性别、国籍及其共存的多样性指数，以考察不同多样性方面对团队项目成果质量的影响。

Result: 统计分析显示，性别多样性与项目成功之间存在中等但统计显著的相关性，与现有文献一致。国籍多样性对项目结果有轻微负面影响，表明促进这些方面不会损害学生表现。性别和国籍的共存对团队有负面影响，可能由于沟通障碍和文化差异的增加。

Conclusion: 研究强调在教育环境中考虑多重多样性维度及其互动的重要性。总体而言，研究发现促进团队多样性不会对其绩效和教育目标的实现产生负面影响。

Abstract: Software Engineering is mostly a male-dominated sector, where gender
diversity is a key feature for improving equality of opportunities,
productivity, and innovation. Other diversity aspects, including but not
limited to nationality and ethnicity, are often understudied.In this work we
aim to assess the impact of team diversity, focusing mainly on gender and
nationality, in the context of an agile software development project-based
course. We analyzed 51 teams over three academic years, measuring three
different Diversity indexes - regarding Gender, Nationality and their
co-presence - to examine how different aspects of diversity impact the quality
of team project outcomes.Statistical analysis revealed a moderate,
statistically significant correlation between gender diversity and project
success, aligning with existing literature. Diversity in nationality showed a
negative but negligible effect on project results, indicating that promoting
these aspects does not harm students' performance. Analyzing their co-presence
within a team, gender and nationality combined had a negative impact, likely
due to increased communication barriers and differing cultural norms.This study
underscores the importance of considering multiple diversity dimensions and
their interactions in educational settings. Our findings, overall, show that
promoting diversity in teams does not negatively impact their performance and
achievement of educational goals.

</details>


### [126] [AutoStub: Genetic Programming-Based Stub Creation for Symbolic Execution](https://arxiv.org/abs/2509.08524)
*Felix Mächtle,Nils Loose,Jan-Niclas Serr,Jonas Sander,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: AutoStub利用遗传编程自动生成符号存根，提升符号执行对外部函数的处理能力，无需人工干预，准确率高。


<details>
  <summary>Details</summary>
Motivation: 解决符号执行在遇到外部函数（如原生方法或第三方库）时因缺乏上下文或需昂贵SMT求解器而受限的问题。

Method: 利用遗传编程，AutoStub通过随机生成输入并收集输出来训练近似外部函数行为的表达式，生成符号存根。

Result: AutoStub能自动近似55%评估函数，准确率超90%，并揭示语言特定行为及关键边缘案例。

Conclusion: AutoStub通过遗传编程自动生成符号存根，显著提升了符号执行对外部函数的处理能力，无需人工干预即可探索更多程序路径。

Abstract: Symbolic execution is a powerful technique for software testing, but suffers
from limitations when encountering external functions, such as native methods
or third-party libraries. Existing solutions often require additional context,
expensive SMT solvers, or manual intervention to approximate these functions
through symbolic stubs. In this work, we propose a novel approach to
automatically generate symbolic stubs for external functions during symbolic
execution that leverages Genetic Programming. When the symbolic executor
encounters an external function, AutoStub generates training data by executing
the function on randomly generated inputs and collecting the outputs. Genetic
Programming then derives expressions that approximate the behavior of the
function, serving as symbolic stubs. These automatically generated stubs allow
the symbolic executor to continue the analysis without manual intervention,
enabling the exploration of program paths that were previously intractable. We
demonstrate that AutoStub can automatically approximate external functions with
over 90% accuracy for 55% of the functions evaluated, and can infer
language-specific behaviors that reveal edge cases crucial for software
testing.

</details>


### [127] [Beyond the Binary: The System of All-round Evaluation of Research and Its Practices in China](https://arxiv.org/abs/2509.08546)
*Yu Zhu,Jiyuan Ye*

Main category: cs.SE

TL;DR: SAER框架整合三个评估维度和六个要素，超越定性定量二元对立，为全球评估改革提供理论和实践指导。


<details>
  <summary>Details</summary>
Motivation: 全球研究评估系统缺乏宏观、系统的评估理论指导实践，定性定量方法的二元对立成为改革瓶颈。

Method: 通过回顾研究评估的历史发展，提出了SAER框架，该框架结合了三个评估维度和六个关键要素。

Result: SAER框架为学术评估者和研究者提供了一个调和评估方法二元对立的综合系统，融合了中国研究评估理论的辩证智慧。

Conclusion: SAER框架通过整合形式、内容和效用评估，提供了一个超越定性定量二元对立的全面评估基础，为全球评估改革提供了理论突破和实践参考。

Abstract: The lack of a macro-level, systematic evaluation theory to guide the
implementation of evaluation practices has become a key bottleneck in the
reform of global research evaluation systems. By reviewing the historical
development of research evaluation, this paper highlights the current binary
opposition between qualitative and quantitative methods in evaluation
practices. This paper introduces the System of All-round Evaluation of Research
(SAER), a framework that integrates form, content, and utility evaluations with
six key elements. SAER offers a theoretical breakthrough by transcending the
binary, providing a comprehensive foundation for global evaluation reforms. The
comprehensive system proposes a trinity of three evaluation dimensions,
combined with six evaluation elements, which would help academic evaluators and
researchers reconcile binary oppositions in evaluation methods. The system
highlights the dialectical wisdom and experience embedded in Chinese research
evaluation theory, offering valuable insights and references for the reform and
advancement of global research evaluation systems.

</details>


### [128] [Minimal Data, Maximum Clarity: A Heuristic for Explaining Optimization](https://arxiv.org/abs/2509.08667)
*Amirali Rayegan,Tim Menzies*

Main category: cs.SE

TL;DR: EZR是一个轻量级多目标优化框架，通过主动学习和决策树解释，用更少数据实现高效且可解释的优化。


<details>
  <summary>Details</summary>
Motivation: 解决软件工程中配置空间大、标注成本高且易出错的优化挑战。

Method: EZR采用基于朴素贝叶斯采样的主动学习策略和决策树蒸馏优化逻辑。

Result: 在60个真实数据集上，EZR在大多数情况下实现了超过90%的最佳优化性能，并提供比传统XAI方法更清晰的解释。

Conclusion: EZR框架证明了在软件工程优化中，使用更少但更信息丰富的数据可以生成既高效又可解释的模型，且优于传统方法。

Abstract: Efficient, interpretable optimization is a critical but underexplored
challenge in software engineering, where practitioners routinely face vast
configuration spaces and costly, error-prone labeling processes. This paper
introduces EZR, a novel and modular framework for multi-objective optimization
that unifies active sampling, learning, and explanation within a single,
lightweight pipeline. Departing from conventional wisdom, our Maximum Clarity
Heuristic demonstrates that using less (but more informative) data can yield
optimization models that are both effective and deeply understandable. EZR
employs an active learning strategy based on Naive Bayes sampling to
efficiently identify high-quality configurations with a fraction of the labels
required by fully supervised approaches. It then distills optimization logic
into concise decision trees, offering transparent, actionable explanations for
both global and local decision-making. Extensive experiments across 60
real-world datasets establish that EZR reliably achieves over 90% of the
best-known optimization performance in most cases, while providing clear,
cohort-based rationales that surpass standard attribution-based explainable AI
(XAI) methods (LIME, SHAP, BreakDown) in clarity and utility. These results
endorse "less but better"; it is both possible and often preferable to use
fewer (but more informative) examples to generate label-efficient optimization
and explanations in software systems. To support transparency and
reproducibility, all code and experimental materials are publicly available at
https://github.com/amiiralii/Minimal-Data-Maximum-Clarity.

</details>


### [129] [SWE-Mirror: Scaling Issue-Resolving Datasets by Mirroring Issues Across Repositories](https://arxiv.org/abs/2509.08724)
*Junhao Wang,Daoguang Zan,Shulin Xin,Siyao Liu,Yurong Wu,Kai Shen*

Main category: cs.SE

TL;DR: SWE-Mirror通过镜像GitHub问题到Gym环境，构建大规模可验证数据集，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自动化Gym环境设置过程中成功率低且开销高，同时合成任务未能充分利用真实的人类报告问题。

Method: 引入了SWE-Mirror流程，将真实问题的语义精髓提取并镜像到另一个配置了Gym环境的仓库中，重新构建为可验证的问题解决任务。

Result: 在40个仓库中构建了60,671个任务的数据集，训练后的模型在问题解决能力上表现出显著提升，并在OpenHands框架上实现了新的SOTA。

Conclusion: SWE-Mirror通过利用现有Gym环境和GitHub上的问题解决历史，构建了一个大规模、可验证的任务数据集，显著提升了模型在问题解决任务上的性能。

Abstract: Creating large-scale verifiable training datasets for issue-resolving tasks
is a critical yet notoriously difficult challenge. Existing methods on
automating the Gym environment setup process for real-world issues suffer from
low success rates and high overhead. Meanwhile, synthesizing new tasks within
existing Gym environments leaves the vast pool of authentic, human-reported
problems untapped. To maximize the utilization of existing Gym environments and
also the rich data of issue-resolving history on GitHub, we introduce
SWE-Mirror, a pipeline that distills a real-world issue's semantic essence,
mirrors it into another repository with a configured Gym environment, and
re-animates it as a verifiable issue-resolving task. SWE-Mirror reuses existing
Gym environments along with the vast pool of issue-resolving history hosted on
GitHub to construct a large-scale dataset of mirrored authentic and verifiable
tasks. Applying SWE-Mirror to 40 repositories across 4 languages, we have
curated a dataset with 60,671 issue-resolving tasks and demonstrated the value
of our dataset by training and evaluating coding agents at various scale.
Post-training experiments show that models trained with the dataset exhibit
improvements in issue-resolving capabilities. Furthermore, by extending the
dataset size to over 12,000 high-quality trajectories, we established a new
state-of-the-art (SOTA) among Qwen2.5-Coder-Instruct based LLMs on the
OpenHands agent framework, which increases the resolve rate on
SWE-Bench-Verified by +21.8% for the 7B model and +46.0% for the 32B model and
validates the effectiveness of our approach.

</details>


### [130] [Handling Open-Vocabulary Constructs in Formalizing Specifications: Retrieval-Augmented Parsing with Expert Knowledge](https://arxiv.org/abs/2509.08808)
*Mohammad Saqib Hasan,Sayontan Ghosh,Dhruv Verma,Geoff Kuenning,Erez Zadok,Scott A. Smolka,Niranjan Balasubramanian*

Main category: cs.SE

TL;DR: 论文提出DKAP和ROLex方法，通过动态利用专家知识解决开放词汇构造问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决开放词汇构造（OVCs）问题中模型因缺乏先验知识而表现不佳的问题，通过动态利用专家提供的知识来提升解析效果。

Method: 提出了动态知识增强解析（DKAP）和ROLex检索增强解析方法，结合检索器和生成器，利用动态增长的专家知识词典（NL短语与OVC构造的键值对）进行解析。

Result: 在三个形式化任务（NL2LTL、NL2Code和NL2CMD）上，ROLex显著提升了基线模型的性能。

Conclusion: 论文提出了一种动态知识增强解析方法（DKAP）和ROLex检索增强解析方法，有效利用专家提供的动态知识，显著提升了基线模型在开放词汇构造（OVCs）问题上的性能。

Abstract: We study the problem of Open-Vocabulary Constructs(OVCs) -- ones not known
beforehand -- in the context of converting natural language (NL) specifications
into formal languages (e.g., temporal logic or code). Models fare poorly on
OVCs due to a lack of necessary knowledge a priori. In such situations, a
domain expert can provide correct constructs at inference time based on their
preferences or domain knowledge. Our goal is to effectively reuse this
inference-time, expert-provided knowledge for future parses without retraining
the model. We present dynamic knowledge-augmented parsing(DKAP), where in
addition to the input sentence, the model receives (dynamically growing) expert
knowledge as a key-value lexicon that associates NL phrases with correct OVC
constructs. We propose ROLex, a retrieval-augmented parsing approach that uses
this lexicon. A retriever and a generator are trained to find and use the
key-value store to produce the correct parse. A key challenge lies in curating
data for this retrieval-augmented parser. We utilize synthetic data generation
and the data augmentation techniques on annotated (NL sentence, FL statement)
pairs to train the augmented parser. To improve training effectiveness, we
propose multiple strategies to teach models to focus on the relevant subset of
retrieved knowledge. Finally, we introduce a new evaluation paradigm modeled
after the DKAP problem and simulate the scenario across three formalization
tasks (NL2LTL, NL2Code, and NL2CMD). Our evaluations show that DKAP is a
difficult challenge, and ROLex helps improve the performance of baseline models
by using dynamic expert knowledge effectively.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [131] [A Dynamic, Self-balancing k-d Tree](https://arxiv.org/abs/2509.08148)
*Russell A. Brown*

Main category: cs.DS

TL;DR: 本文提出了一种动态k-d树，通过特定的插入和删除算法实现自我平衡，性能表现良好。


<details>
  <summary>Details</summary>
Motivation: 由于传统的平衡技术（如AVL树或红黑树）不适用于k-d树，因为它们会破坏k-d树的排序顺序，因此需要开发一种动态k-d树来实现在插入或删除后自我平衡。

Method: 本文描述了动态k-d树的插入和删除算法，并对其性能进行了测量。

Result: 研究结果表明，动态k-d树能够在保持平衡的同时高效处理数据。

Conclusion: 本文得出结论，动态k-d树通过特定的插入和删除算法可以在保持平衡的同时高效处理k维数据，性能表现良好。

Abstract: The original description of the k-d tree recognized that rebalancing
techniques, such as used to build an AVL tree or a red-black tree, are not
applicable to a k-d tree, because these techniques involve cyclic exchange (aka
rotation) of tree nodes, which destroys the sorted order of the k-d tree. For
this reason, a static k-d tree is often built from all of the k-dimensional
data en masse. However, it is possible to build a dynamic k-d tree that
self-balances when necessary after insertion or deletion of each individual
k-dimensional datum. This article describes insertion and deletion algorithms
for a dynamic k-d tree, and measures their performance.

</details>


### [132] [Enumeration kernels for Vertex Cover and Feedback Vertex Set](https://arxiv.org/abs/2509.08475)
*Marin Bougeret,Guilherme C. M. Gomes,Vinicius F. dos Santos,Ignasi Sau*

Main category: cs.DS

TL;DR: 本文解决了Vertex Cover和Feedback Vertex Set的枚举核化问题，分别提出了2k和O(k^3)顶点/边的多项式延迟枚举核，填补了该领域的研究空白。


<details>
  <summary>Details</summary>
Motivation: 枚举核化是参数化复杂性和枚举算法的交叉领域，但目前对Vertex Cover和Feedback Vertex Set等核心问题的枚举版本研究较少。本文旨在填补这一空白。

Method: 1. 为Enum Vertex Cover开发了基于经典crown分解的提升算法，获得了2k顶点的多项式延迟枚举核。2. 为Enum Feedback Vertex Set设计了受Thomassé思想启发的算法，获得了O(k^3)顶点和边的多项式延迟枚举核。

Result: 1. 为Enum Vertex Cover提供了2k顶点的多项式延迟枚举核，优于之前的O(k^2)顶点核。2. 为Enum Feedback Vertex Set提供了O(k^3)顶点和边的多项式延迟枚举核。

Conclusion: 本文通过开发非平凡的提升算法和受Thomassé思想的启发，解决了枚举版本的Vertex Cover和Feedback Vertex Set问题，为枚举核化领域提供了新的进展。

Abstract: Enumerative kernelization is a recent and promising area sitting at the
intersection of parameterized complexity and enumeration algorithms. Its study
began with the paper of Creignou et al. [Theory Comput. Syst., 2017], and
development in the area has started to accelerate with the work of Golovach et
al. [J. Comput. Syst. Sci., 2022]. The latter introduced polynomial-delay
enumeration kernels and applied them in the study of structural
parameterizations of the \textsc{Matching Cut} problem and some variants. Few
other results, mostly on \textsc{Longest Path} and some generalizations of
\textsc{Matching Cut}, have also been developed. However, little success has
been seen in enumeration versions of \textsc{Vertex Cover} and \textsc{Feedback
Vertex Set}, some of the most studied problems in kernelization. In this paper,
we address this shortcoming. Our first result is a polynomial-delay enumeration
kernel with $2k$ vertices for \textsc{Enum Vertex Cover}, where we wish to list
all solutions with at most $k$ vertices. This is obtained by developing a
non-trivial lifting algorithm for the classical crown decomposition reduction
rule, and directly improves upon the kernel with $\mathcal{O}(k^2)$ vertices
derived from the work of Creignou et al. Our other result is a polynomial-delay
enumeration kernel with $\mathcal{O}(k^3)$ vertices and edges for \textsc{Enum
Feedback Vertex Set}; the proof is inspired by some ideas of Thomass\'e [TALG,
2010], but with a weaker bound on the kernel size due to difficulties in
applying the $q$-expansion technique.

</details>


### [133] [Checking and producing word attractors](https://arxiv.org/abs/2509.08503)
*Marie-Pierre Béal,Maxime Crochemore,Giuseppe Romana*

Main category: cs.DS

TL;DR: 本文提出两种高效算法解决词吸引子问题，线性时间判断和贪心生成吸引子，适用于多个词族。


<details>
  <summary>Details</summary>
Motivation: 研究词吸引子与文本压缩效率的关系，提供高效的组合算法。

Method: 第一种算法线性时间内判断位置集是否为词的吸引子；第二种算法以贪心方式生成吸引子。

Result: 算法在多个词族中生成极小的吸引子，尽管问题本身是NP难的。

Conclusion: 本文介绍了两种基于后缀自动机或有向无环词图的组合算法，用于高效解决词吸引子问题，并在多个词族中生成极小的吸引子。

Abstract: The article focuses on word (or string) attractors, which are sets of
positions related to the text compression efficiency of the underlying word.
The article presents two combinatorial algorithms based on Suffix automata or
Directed Acyclic Word Graphs. The first algorithm decides in linear time
whether a set of positions on the word is an attractor of the word. The second
algorithm generates an attractor for a given word in a greedy manner. Although
this problem is NP-hard, the algorithm is efficient and produces very small
attractors for several well-known families of words.

</details>
