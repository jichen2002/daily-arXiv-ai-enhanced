<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 109]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.GR](#cs.GR) [Total: 8]
- [cs.RO](#cs.RO) [Total: 43]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.AI](#cs.AI) [Total: 17]
- [cs.DS](#cs.DS) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays](https://arxiv.org/abs/2509.15234)
*Hanbin Ko,Gihun Cho,Inhyeok Baek,Donguk Kim,Joonbeom Koo,Changi Kim,Dongheon Lee,Chang Min Park*

Main category: cs.CV

TL;DR: 该研究通过LLM2VEC4CXR和LLM2CLIP4CXR模型，解决了放射学中临床报告异质性导致的图像-文本对齐问题，强调鲁棒性而非数据规模的重要性。


<details>
  <summary>Details</summary>
Motivation: 放射学中的临床报告存在异质性（如缩写、仅印象的笔记和风格变异性），导致图像-文本对齐进展受限。单纯扩大噪声报告的数据规模可能导致模型学习效果下降。

Method: 引入了LLM2VEC4CXR（一种针对胸部X光报告的领域适应LLM编码器）和LLM2CLIP4CXR（一种将该编码器与视觉主干结合的双塔框架）。

Result: LLM2VEC4CXR在临床文本理解上优于BERT基线，能处理缩写和风格变化，并在报告级指标上实现了强临床对齐。LLM2CLIP4CXR提高了检索准确性和临床导向分数，具有更强的跨数据集泛化能力。

Conclusion: LLM2VEC4CXR和LLM2CLIP4CXR模型通过增强对临床文本的理解和图像-文本对齐，证明了在医学图像-文本表示学习中，鲁棒性而非单纯的数据规模是关键。

Abstract: Vision-language pretraining has advanced image-text alignment, yet progress
in radiology remains constrained by the heterogeneity of clinical reports,
including abbreviations, impression-only notes, and stylistic variability.
Unlike general-domain settings where more data often leads to better
performance, naively scaling to large collections of noisy reports can plateau
or even degrade model learning. We ask whether large language model (LLM)
encoders can provide robust clinical representations that transfer across
diverse styles and better guide image-text alignment. We introduce LLM2VEC4CXR,
a domain-adapted LLM encoder for chest X-ray reports, and LLM2CLIP4CXR, a
dual-tower framework that couples this encoder with a vision backbone.
LLM2VEC4CXR improves clinical text understanding over BERT-based baselines,
handles abbreviations and style variation, and achieves strong clinical
alignment on report-level metrics. LLM2CLIP4CXR leverages these embeddings to
boost retrieval accuracy and clinically oriented scores, with stronger
cross-dataset generalization than prior medical CLIP variants. Trained on 1.6M
CXR studies from public and private sources with heterogeneous and noisy
reports, our models demonstrate that robustness -- not scale alone -- is the
key to effective multimodal learning. We release models to support further
research in medical image-text representation learning.

</details>


### [2] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

TL;DR: ViSpec通过视觉适配模块和全局特征向量增强，为视觉语言模型提供了高效的推测解码框架，实现了显著的加速效果。


<details>
  <summary>Details</summary>
Motivation: 推测解码技术在大型语言模型（LLMs）中广泛应用，但在视觉语言模型（VLMs）中的应用尚未充分探索，现有方法仅能实现有限的加速（<1.5倍）。随着多模态能力成为大规模模型的核心，这一差距日益显著。

Method: ViSpec采用轻量级视觉适配模块压缩图像令牌，并保留原始图像位置信息，同时提取全局特征向量增强多模态连贯性。此外，通过重新利用现有数据集并生成扩展输出来解决多模态数据集稀缺问题。

Result: 实验验证了ViSpec的有效性，首次在VLM推测解码中实现了显著的加速效果。

Conclusion: ViSpec是一种新颖的视觉感知推测解码框架，专为视觉语言模型（VLMs）设计，通过轻量级视觉适配模块和全局特征向量增强，成功实现了VLM推测解码的显著加速。

Abstract: Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [3] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

TL;DR: M-PACE利用母-子MLLM架构统一多模态合规评估，降低人工依赖与成本，广告合规测试显示高效且经济。


<details>
  <summary>Details</summary>
Motivation: 传统合规框架因模块分散导致操作复杂、扩展性差，无法高效适应动态指南。MLLMs的出现为统一多模态合规工作流提供了可能。

Method: 提出Multimodal Parameter Agnostic Compliance Engine (M-PACE)框架，采用母-子MLLM架构，通过强大的母模型评估子模型输出，实现多模态内容的单次合规性评估。

Result: M-PACE在广告合规应用中评估超过15个属性，推理成本降低31倍（0.0005/图像 vs. 0.0159），同时保持可比准确性。

Conclusion: M-PACE通过统一的母-子MLLM架构显著降低了合规检查的依赖人工和成本，同时保持了高准确性，为多模态内容合规性评估提供了高效、可扩展的解决方案。

Abstract: Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [4] [ProFusion: 3D Reconstruction of Protein Complex Structures from Multi-view AFM Images](https://arxiv.org/abs/2509.15242)
*Jaydeep Rade,Md Hasibul Hasan Hasib,Meric Ozturk,Baboucarr Faal,Sheng Yang,Dipali G. Sashital,Vincenzo Venditti,Baoyu Chen,Soumik Sarkar,Adarsh Krishnamurthy,Anwesha Sarkar*

Main category: cs.CV

TL;DR: ProFusion结合深度学习和AFM，通过虚拟AFM数据集与条件扩散模型，高效预测蛋白质复合物3D结构，解决了传统方法的局限。


<details>
  <summary>Details</summary>
Motivation: AI方法在蛋白质结构预测中表现优异，但对大型蛋白质复合物（PCs）因缺乏3D空间线索而效果有限；实验方法如冷冻电镜（Cryo-EM）虽准确但成本高、耗时长。

Method: 提出ProFusion混合框架，结合深度学习与AFM；开发虚拟AFM模拟成像过程并生成大规模数据集；训练条件扩散模型和NeRF模型进行多视图合成与3D重建。

Result: 重建的3D蛋白质结构平均Chamfer距离在AFM成像分辨率内，验证了高结构保真度；在多种PCs的实验AFM图像上表现优异。

Conclusion: ProFusion框架结合深度学习和原子力显微镜（AFM），通过虚拟AFM数据集和条件扩散模型，实现了高保真度的蛋白质复合物3D结构预测，为快速、低成本的蛋白质结构预测与验证提供了新途径。

Abstract: AI-based in silico methods have improved protein structure prediction but
often struggle with large protein complexes (PCs) involving multiple
interacting proteins due to missing 3D spatial cues. Experimental techniques
like Cryo-EM are accurate but costly and time-consuming. We present ProFusion,
a hybrid framework that integrates a deep learning model with Atomic Force
Microscopy (AFM), which provides high-resolution height maps from random
orientations, naturally yielding multi-view data for 3D reconstruction.
However, generating a large-scale AFM imaging data set sufficient to train deep
learning models is impractical. Therefore, we developed a virtual AFM framework
that simulates the imaging process and generated a dataset of ~542,000 proteins
with multi-view synthetic AFM images. We train a conditional diffusion model to
synthesize novel views from unposed inputs and an instance-specific Neural
Radiance Field (NeRF) model to reconstruct 3D structures. Our reconstructed 3D
protein structures achieve an average Chamfer Distance within the AFM imaging
resolution, reflecting high structural fidelity. Our method is extensively
validated on experimental AFM images of various PCs, demonstrating strong
potential for accurate, cost-effective protein complex structure prediction and
rapid iterative validation using AFM experiments.

</details>


### [5] [Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models](https://arxiv.org/abs/2509.15243)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: MMEL框架通过层次化语义关系模块提升视觉语言模型的可解释性，实验证明其在保持高性能的同时生成更精准的可视化解释。


<details>
  <summary>Details</summary>
Motivation: 由于视觉语言模型在安全关键场景中的应用面临复杂对象关系、细微视觉线索以及对透明度和可靠性高要求的挑战，因此需要一种既能保持高性能又能提升可解释性的方法。

Method: MMEL框架基于梯度解释的transformer架构（Grad-eclip），引入了层次化语义关系模块，通过多尺度特征处理、自适应注意力加权和跨模态对齐来增强模型的可解释性。

Result: 实验表明，MMEL通过将语义关系信息融入基于梯度的归因图，生成了更聚焦且上下文感知的可视化结果，更好地反映了模型处理复杂场景的方式。

Conclusion: MMEL框架通过多层次语义关系模块和自适应注意力加权，显著提升了视觉语言模型的可解释性，同时保持了高性能。该框架在多个领域具有通用性，为需要高可解释性和可靠性的应用提供了有价值的见解。

Abstract: Recent advances in vision-language models have significantly expanded the
frontiers of automated image analysis. However, applying these models in
safety-critical contexts remains challenging due to the complex relationships
between objects, subtle visual cues, and the heightened demand for transparency
and reliability. This paper presents the Multi-Modal Explainable Learning
(MMEL) framework, designed to enhance the interpretability of vision-language
models while maintaining high performance. Building upon prior work in
gradient-based explanations for transformer architectures (Grad-eclip), MMEL
introduces a novel Hierarchical Semantic Relationship Module that enhances
model interpretability through multi-scale feature processing, adaptive
attention weighting, and cross-modal alignment. Our approach processes features
at multiple semantic levels to capture relationships between image regions at
different granularities, applying learnable layer-specific weights to balance
contributions across the model's depth. This results in more comprehensive
visual explanations that highlight both primary objects and their contextual
relationships with improved precision. Through extensive experiments on
standard datasets, we demonstrate that by incorporating semantic relationship
information into gradient-based attribution maps, MMEL produces more focused
and contextually aware visualizations that better reflect how vision-language
models process complex scenes. The MMEL framework generalizes across various
domains, offering valuable insights into model decisions for applications
requiring high interpretability and reliability.

</details>


### [6] [Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning](https://arxiv.org/abs/2509.15250)
*Wenda Qin,Andrea Burns,Bryan A. Plummer,Margrit Betke*

Main category: cs.CV

TL;DR: NAP通过导航感知的令牌修剪方法，在VLN任务中实现高效且高性能的导航，节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 大型模型在VLN任务中表现优异，但在资源有限环境中运行成本高。现有令牌修剪方法未能解决VLN特有的挑战，如信息损失导致计算成本增加。

Method: 提出 Navigation-Aware Pruning (NAP)，利用导航特定特征将令牌预过滤为前景和背景，并专注于修剪背景令牌以减少信息损失。还使用大型语言模型提取导航相关指令。

Result: NAP在保持性能的同时显著提高了效率，实验证明其在标准VLN基准测试中表现优异。

Conclusion: Navigation-Aware Pruning (NAP) 在标准VLN基准测试中显著优于先前工作，保持了更高的成功率同时节省了超过50%的FLOPS。

Abstract: Large models achieve strong performance on Vision-and-Language Navigation
(VLN) tasks, but are costly to run in resource-limited environments. Token
pruning offers appealing tradeoffs for efficiency with minimal performance loss
by reducing model input size, but prior work overlooks VLN-specific challenges.
For example, information loss from pruning can effectively increase
computational cost due to longer walks. Thus, the inability to identify
uninformative tokens undermines the supposed efficiency gains from pruning. To
address this, we propose Navigation-Aware Pruning (NAP), which uses
navigation-specific traits to simplify the pruning process by pre-filtering
tokens into foreground and background. For example, image views are filtered
based on whether the agent can navigate in that direction. We also extract
navigation-relevant instructions using a Large Language Model. After filtering,
we focus pruning on background tokens, minimizing information loss. To further
help avoid increases in navigation length, we discourage backtracking by
removing low-importance navigation nodes. Experiments on standard VLN
benchmarks show NAP significantly outperforms prior work, preserving higher
success rates while saving more than 50% FLOPS.

</details>


### [7] [RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation](https://arxiv.org/abs/2509.15257)
*Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta*

Main category: cs.CV

TL;DR: RespoDiff 是一种新颖的双模块框架，用于负责任文本到图像生成，在保持语义对齐和图像质量的同时，显著提升公平性和安全性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在文本到图像生成方面取得了显著进展，但如何确保生成的公平性和安全性仍是一个开放挑战。现有方法通常在提升公平性和安全性的同时牺牲语义保真度和图像质量。

Method: RespoDiff 通过引入两个可学习模块：一个专注于捕获和执行负责任概念（如公平性和安全性），另一个致力于保持与中性提示的语义对齐。采用了一种新颖的分数匹配目标，以促进双模块的有效协调。

Result: RespoDiff 在负责任生成方面优于现有方法，语义对齐和图像质量均未受影响。在多样化未见提示上，负责任和语义连贯的生成性能提升了20%，并能无缝集成到如SDXL等大型模型中。

Conclusion: RespoDiff 提出了一种新颖的双模块转换框架，能够在保持语义对齐和图像质量的同时，显著提升文本到图像生成的公平性和安全性。该方法在未见过的多样化提示上表现优异，且能无缝集成到大型模型中。

Abstract: The rapid advancement of diffusion models has enabled high-fidelity and
semantically rich text-to-image generation; however, ensuring fairness and
safety remains an open challenge. Existing methods typically improve fairness
and safety at the expense of semantic fidelity and image quality. In this work,
we propose RespoDiff, a novel framework for responsible text-to-image
generation that incorporates a dual-module transformation on the intermediate
bottleneck representations of diffusion models. Our approach introduces two
distinct learnable modules: one focused on capturing and enforcing responsible
concepts, such as fairness and safety, and the other dedicated to maintaining
semantic alignment with neutral prompts. To facilitate the dual learning
process, we introduce a novel score-matching objective that enables effective
coordination between the modules. Our method outperforms state-of-the-art
methods in responsible generation by ensuring semantic alignment while
optimizing both objectives without compromising image fidelity. Our approach
improves responsible and semantically coherent generation by 20% across
diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale
models like SDXL, enhancing fairness and safety. Code will be released upon
acceptance.

</details>


### [8] [Autoguided Online Data Curation for Diffusion Model Training](https://arxiv.org/abs/2509.15267)
*Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa*

Main category: cs.CV

TL;DR: 自动引导和在线数据选择方法被整合并评估，结果显示自动引导在样本质量和多样性上表现更优，而早期数据选择虽有效但复杂，自动引导或均匀随机选择更实用。


<details>
  <summary>Details</summary>
Motivation: 研究近期开发的自动引导和在线数据选择方法是否能提高生成扩散模型的训练时间和样本效率。

Method: 将联合示例选择（JEST）和自动引导整合到一个统一的代码库中，进行快速消融和基准测试。评估数据整理在2-D合成数据生成任务和（3x64x64）-D图像生成上的组合。

Result: 自动引导始终提高样本质量和多样性。早期AJEST（仅在训练开始时应用选择）可以在数据效率上匹配或略微超过单独的自动引导，但其时间开销和复杂性使得自动引导或均匀随机数据选择在大多数情况下更优。

Conclusion: 在大多数情况下，自动引导或均匀随机数据选择更为可取，尽管有针对性的在线选择在早期训练中可以带来效率提升，但样本质量的稳健改进主要由自动引导驱动。

Abstract: The costs of generative model compute rekindled promises and hopes for
efficient data curation. In this work, we investigate whether recently
developed autoguidance and online data selection methods can improve the time
and sample efficiency of training generative diffusion models. We integrate
joint example selection (JEST) and autoguidance into a unified code base for
fast ablation and benchmarking. We evaluate combinations of data curation on a
controlled 2-D synthetic data generation task as well as (3x64x64)-D image
generation. Our comparisons are made at equal wall-clock time and equal number
of samples, explicitly accounting for the overhead of selection. Across
experiments, autoguidance consistently improves sample quality and diversity.
Early AJEST (applying selection only at the beginning of training) can match or
modestly exceed autoguidance alone in data efficiency on both tasks. However,
its time overhead and added complexity make autoguidance or uniform random data
selection preferable in most situations. These findings suggest that while
targeted online selection can yield efficiency gains in early training, robust
sample quality improvements are primarily driven by autoguidance. We discuss
limitations and scope, and outline when data selection may be beneficial.

</details>


### [9] [PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images](https://arxiv.org/abs/2509.15270)
*Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro*

Main category: cs.CV

TL;DR: PRISM是一种频域指纹技术，用于识别AI生成图像的来源，实验显示其在多个数据集上具有高准确率，尤其在商业环境中具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 在多模态应用中，尤其在商业环境中，用户需要确保所接收内容的来源，因此需要能够识别AI生成内容来源的归属方法。

Method: PRISM采用基于离散傅里叶变换的径向缩减方法，利用振幅和相位信息捕获模型特定签名，并通过线性判别分析进行聚类以实现可靠的模型归属。

Result: 在PRISM-36K数据集上，PRISM实现了92.04%的归属准确率；在四个文献基准测试中平均准确率为81.60%；在真实与伪造图像的二元检测任务中平均准确率为88.41%。

Conclusion: PRISM证明了频域指纹技术在跨架构和跨数据集模型归属中的有效性，为增强生成AI系统的责任和信任提供了可行解决方案。

Abstract: A critical need has emerged for generative AI: attribution methods. That is,
solutions that can identify the model originating AI-generated content. This
feature, generally relevant in multimodal applications, is especially sensitive
in commercial settings where users subscribe to paid proprietary services and
expect guarantees about the source of the content they receive. To address
these issues, we introduce PRISM, a scalable Phase-enhanced Radial-based Image
Signature Mapping framework for fingerprinting AI-generated images. PRISM is
based on a radial reduction of the discrete Fourier transform that leverages
amplitude and phase information to capture model-specific signatures. The
output of the above process is subsequently clustered via linear discriminant
analysis to achieve reliable model attribution in diverse settings, even if the
model's internal details are inaccessible. To support our work, we construct
PRISM-36K, a novel dataset of 36,000 images generated by six text-to-image GAN-
and diffusion-based models. On this dataset, PRISM achieves an attribution
accuracy of 92.04%. We additionally evaluate our method on four benchmarks from
the literature, reaching an average accuracy of 81.60%. Finally, we evaluate
our methodology also in the binary task of detecting real vs fake images,
achieving an average accuracy of 88.41%. We obtain our best result on GenImage
with an accuracy of 95.06%, whereas the original benchmark achieved 82.20%. Our
results demonstrate the effectiveness of frequency-domain fingerprinting for
cross-architecture and cross-dataset model attribution, offering a viable
solution for enforcing accountability and trust in generative AI systems.

</details>


### [10] [Large Vision Models Can Solve Mental Rotation Problems](https://arxiv.org/abs/2509.15271)
*Sebastian Ray Mason,Anders Gjølbye,Phillip Chavarria Højbjerg,Lenka Tětková,Lars Kai Hansen*

Main category: cs.CV

TL;DR: 自监督ViT在心理旋转任务中表现优于监督ViT，中间层效果最佳，任务难度与人类反应时间类似。


<details>
  <summary>Details</summary>
Motivation: 探讨现代视觉变换器（ViT）是否具备类似人类的空间推理能力，尤其是在心理旋转任务中。

Method: 通过逐层探测ViT、CLIP、DINOv2和DINOv3的表征，评估这些网络在不同心理旋转任务中的表现。

Result: 自监督ViT优于监督ViT；中间层表现最佳；任务难度与旋转复杂性和遮挡相关，与人类反应时间一致。

Conclusion: 自监督ViT在捕捉几何结构方面优于监督ViT，中间层表现优于最终层，任务难度随旋转复杂性和遮挡增加而增加，反映了人类反应时间的类似约束。

Abstract: Mental rotation is a key test of spatial reasoning in humans and has been
central to understanding how perception supports cognition. Despite the success
of modern vision transformers, it is still unclear how well these models
develop similar abilities. In this work, we present a systematic evaluation of
ViT, CLIP, DINOv2, and DINOv3 across a range of mental-rotation tasks, from
simple block structures similar to those used by Shepard and Metzler to study
human cognition, to more complex block figures, three types of text, and
photo-realistic objects. By probing model representations layer by layer, we
examine where and how these networks succeed. We find that i) self-supervised
ViTs capture geometric structure better than supervised ViTs; ii) intermediate
layers perform better than final layers; iii) task difficulty increases with
rotation complexity and occlusion, mirroring human reaction times and
suggesting similar constraints in embedding space representations.

</details>


### [11] [Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks](https://arxiv.org/abs/2509.15272)
*Yannis Kaltampanidis,Alexandros Doumanoglou,Dimitrios Zarpalas*

Main category: cs.CV

TL;DR: 研究系统评估了未经修改的ViT特征在图像分类和分割任务中的表现，填补了对其内在表示能力分析的空白。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常通过额外的转换层或蒸馏来提升任务性能，但缺乏对未经处理的ViT特征内在表示能力的全面分析。

Method: 通过基于超平面或余弦相似度的分类和分割规则，系统地评估了未经修改的ViT特征在图像分类和分割任务中的应用。

Result: 研究提供了关于最佳令牌类型和决策规则选择的详细发现，并在两个广泛使用的数据集上进行了验证。

Conclusion: 研究填补了关于未经处理的ViT特征内在表示能力的全面分析空白，并提供了在不同任务和上下文中选择最佳令牌类型和决策规则的见解。

Abstract: Self-Supervised Learning (SSL) for Vision Transformers (ViTs) has recently
demonstrated considerable potential as a pre-training strategy for a variety of
computer vision tasks, including image classification and segmentation, both in
standard and few-shot downstream contexts. Two pre-training objectives dominate
the landscape of SSL techniques: Contrastive Learning and Masked Image
Modeling. Features (or tokens) extracted from the final transformer attention
block -- specifically, the keys, queries, and values -- as well as features
obtained after the final block's feed-forward layer, have become a common
foundation for addressing downstream tasks. However, in many existing
approaches, these pre-trained ViT features are further processed through
additional transformation layers, often involving lightweight heads or combined
with distillation, to achieve superior task performance. Although such methods
can improve task outcomes, to the best of our knowledge, a comprehensive
analysis of the intrinsic representation capabilities of unaltered ViT features
has yet to be conducted. This study aims to bridge this gap by systematically
evaluating the use of these unmodified features across image classification and
segmentation tasks, in both standard and few-shot contexts. The classification
and segmentation rules that we use are either hyperplane based (as in logistic
regression) or cosine-similarity based, both of which rely on the presence of
interpretable directions in the ViT's latent space. Based on the previous rules
and without the use of additional feature transformations, we conduct an
analysis across token types, tasks, and pre-trained ViT models. This study
provides insights into the optimal choice for token type and decision rule
based on the task, context, and the pre-training objective, while reporting
detailed findings on two widely-used datasets.

</details>


### [12] [How Good are Foundation Models in Step-by-Step Embodied Reasoning?](https://arxiv.org/abs/2509.15293)
*Dinura Dissanayake,Ahmed Heakl,Omkar Thawakar,Noor Ahsan,Ritesh Thawkar,Ketan More,Jean Lahoud,Rao Anwer,Hisham Cholakkal,Ivan Laptev,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

TL;DR: 研究提出FoMER基准，评估LMMs在具身决策中的推理能力，发现其潜力与局限，为未来研究指明方向。


<details>
  <summary>Details</summary>
Motivation: 探索基础模型在复杂具身决策场景中的逐步推理能力，填补LMMs在结构化推理方面的研究空白。

Method: 提出了Foundation Model Embodied Reasoning（FoMER）基准，包含多样化的具身推理任务、新颖的评估框架及对多个领先LMMs的实证分析。

Result: FoMER基准包含1.1k样本，覆盖10个任务和8种具身形式，实证分析揭示了LMMs在具身推理中的表现与局限。

Conclusion: 研究强调了大型多模态模型（LMMs）在具身推理任务中的潜力与当前局限性，并指出了未来机器人智能研究的关键挑战与机遇。

Abstract: Embodied agents operating in the physical world must make decisions that are
not only effective but also safe, spatially coherent, and grounded in context.
While recent advances in large multimodal models (LMMs) have shown promising
capabilities in visual understanding and language generation, their ability to
perform structured reasoning for real-world embodied tasks remains
underexplored. In this work, we aim to understand how well foundation models
can perform step-by-step reasoning in embodied environments. To this end, we
propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to
evaluate the reasoning capabilities of LMMs in complex embodied decision-making
scenarios. Our benchmark spans a diverse set of tasks that require agents to
interpret multimodal observations, reason about physical constraints and
safety, and generate valid next actions in natural language. We present (i) a
large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation
framework that disentangles perceptual grounding from action reasoning, and
(iii) empirical analysis of several leading LMMs under this setting. Our
benchmark includes over 1.1k samples with detailed step-by-step reasoning
across 10 tasks and 8 embodiments, covering three different robot types. Our
results highlight both the potential and current limitations of LMMs in
embodied reasoning, pointing towards key challenges and opportunities for
future research in robot intelligence. Our data and code will be made publicly
available.

</details>


### [13] [CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2509.15330)
*Min Zhang,Bo Jiang,Jie Zhou,Yimeng Liu,Xin Lin*

Main category: cs.CV

TL;DR: CoDoL通过利用领域信息改进提示和嵌入对齐，提升了CLIP的OOD泛化性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于提示的CLIP方法表现出竞争力，但仍面临文本描述不准确和视觉-语言嵌入对齐有限的问题，影响了零样本CLIP方法的准确性和泛化性能。

Method: 本文提出了一种新颖的条件域提示学习（CoDoL）方法，并进一步设计了一个轻量级域元网络（DMN）来生成每个领域中图像的输入条件令牌。

Result: 在四个OOD基准测试（PACS、VLCS、OfficeHome和DigitDG）上的大量实验验证了CoDoL在改善视觉-语言嵌入对齐和OOD泛化性能方面的有效性。

Conclusion: 提出的CoDoL方法通过利用现成的领域信息形成提示并改善视觉-语言嵌入对齐，显著提升了OOD泛化性能。

Abstract: Recent advances in pre-training vision-language models (VLMs), e.g.,
contrastive language-image pre-training (CLIP) methods, have shown great
potential in learning out-of-distribution (OOD) representations. Despite
showing competitive performance, the prompt-based CLIP methods still suffer
from: i) inaccurate text descriptions, which leads to degraded accuracy and
robustness, and poses a challenge for zero-shot CLIP methods. ii) limited
vision-language embedding alignment, which significantly affects the
generalization performance. To tackle the above issues, this paper proposes a
novel Conditional Domain prompt Learning (CoDoL) method, which utilizes
readily-available domain information to form prompts and improves the
vision-language embedding alignment for improving OOD generalization. To
capture both instance-specific and domain-specific information, we further
propose a lightweight Domain Meta Network (DMN) to generate input-conditional
tokens for images in each domain. Extensive experiments on four OOD benchmarks
(PACS, VLCS, OfficeHome and DigitDG) validate the effectiveness of our proposed
CoDoL in terms of improving the vision-language embedding alignment as well as
the out-of-distribution generalization performance.

</details>


### [14] [Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception](https://arxiv.org/abs/2509.15333)
*Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang*

Main category: cs.CV

TL;DR: AdaptiveNN 是一种自适应视觉模型框架，通过序列决策和强化学习实现高效、灵活且可解释的计算机视觉，性能接近人类水平。


<details>
  <summary>Details</summary>
Motivation: 当前机器视觉模型被动处理整个场景，资源需求高且缺乏灵活性，限制了其在实际应用中的潜力。AdaptiveNN 旨在推动从‘被动’到‘主动、自适应’视觉模型的范式转变。

Method: AdaptiveNN 将视觉感知建模为一个从粗到细的序列决策过程，结合表征学习和自奖励强化学习进行端到端训练。

Result: 在17个基准测试中，AdaptiveNN 实现了高达28倍的推理成本降低，无需重新训练即可适应不同任务需求和资源预算，并提供了通过注视模式增强的可解释性。

Conclusion: AdaptiveNN 提供了一种高效、灵活且可解释的计算机视觉新范式，不仅在多个任务上实现了高达28倍的推理成本降低，还展示了与人类视觉相似的感知行为。

Abstract: Human vision is highly adaptive, efficiently sampling intricate environments
by sequentially fixating on task-relevant regions. In contrast, prevailing
machine vision models passively process entire scenes at once, resulting in
excessive resource demands scaling with spatial-temporal input resolution and
model size, yielding critical limitations impeding both future advancements and
real-world application. Here we introduce AdaptiveNN, a general framework
aiming to drive a paradigm shift from 'passive' to 'active, adaptive' vision
models. AdaptiveNN formulates visual perception as a coarse-to-fine sequential
decision-making process, progressively identifying and attending to regions
pertinent to the task, incrementally combining information across fixations,
and actively concluding observation when sufficient. We establish a theory
integrating representation learning with self-rewarding reinforcement learning,
enabling end-to-end training of the non-differentiable AdaptiveNN without
additional supervision on fixation locations. We assess AdaptiveNN on 17
benchmarks spanning 9 tasks, including large-scale visual recognition,
fine-grained discrimination, visual search, processing images from real driving
and medical scenarios, language-driven embodied AI, and side-by-side
comparisons with humans. AdaptiveNN achieves up to 28x inference cost reduction
without sacrificing accuracy, flexibly adapts to varying task demands and
resource budgets without retraining, and provides enhanced interpretability via
its fixation patterns, demonstrating a promising avenue toward efficient,
flexible, and interpretable computer vision. Furthermore, AdaptiveNN exhibits
closely human-like perceptual behaviors in many cases, revealing its potential
as a valuable tool for investigating visual cognition. Code is available at
https://github.com/LeapLabTHU/AdaptiveNN.

</details>


### [15] [LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition](https://arxiv.org/abs/2509.15342)
*Jiuyi Xu,Qing Jin,Meida Chen,Andrew Feng,Yang Sui,Yangming Shi*

Main category: cs.CV

TL;DR: LowDiff 是一种高效扩散框架，通过级联低分辨率到高分辨率的生成过程，显著提升采样速度，同时在多个数据集上保持高性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像生成方面取得了显著成功，但其实际应用常受限于采样速度慢的问题。现有方法主要关注模型压缩或减少去噪步骤，而忽略了利用多分辨率输入的可能性。

Method: LowDiff 采用级联方法，通过统一的模型逐步从低分辨率到目标分辨率细化图像，结合架构设计和生成技术，减少了高分辨率采样步骤。

Result: 在 CIFAR-10、FFHQ 和 ImageNet 等多个数据集上，LowDiff 实现了超过 50% 的吞吐量提升，同时保持了可比或更优的质量指标（如 FID 和 IS）。

Conclusion: LowDiff 提出了一种新颖且高效的扩散框架，通过从低分辨率逐步生成高分辨率图像，显著提高了采样速度，同时在多个数据集上保持了与现有方法相当甚至更优的性能。

Abstract: Diffusion models have achieved remarkable success in image generation but
their practical application is often hindered by the slow sampling speed. Prior
efforts of improving efficiency primarily focus on compressing models or
reducing the total number of denoising steps, largely neglecting the
possibility to leverage multiple input resolutions in the generation process.
In this work, we propose LowDiff, a novel and efficient diffusion framework
based on a cascaded approach by generating increasingly higher resolution
outputs. Besides, LowDiff employs a unified model to progressively refine
images from low resolution to the desired resolution. With the proposed
architecture design and generation techniques, we achieve comparable or even
superior performance with much fewer high-resolution sampling steps. LowDiff is
applicable to diffusion models in both pixel space and latent space. Extensive
experiments on both conditional and unconditional generation tasks across
CIFAR-10, FFHQ and ImageNet demonstrate the effectiveness and generality of our
method. Results show over 50% throughput improvement across all datasets and
settings while maintaining comparable or better quality. On unconditional
CIFAR-10, LowDiff achieves an FID of 2.11 and IS of 9.87, while on conditional
CIFAR-10, an FID of 1.94 and IS of 10.03. On FFHQ 64x64, LowDiff achieves an
FID of 2.43, and on ImageNet 256x256, LowDiff built on LightningDiT-B/1
produces high-quality samples with a FID of 4.00 and an IS of 195.06, together
with substantial efficiency gains.

</details>


### [16] [MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation](https://arxiv.org/abs/2509.15357)
*Yu Chang,Jiahao Chen,Anzhe Cheng,Paul Bogdan*

Main category: cs.CV

TL;DR: MaskAttn-SDXL通过稀疏化交叉注意力logits，有效解决了文本到图像生成中的组合失败问题，提升了空间控制和属性绑定。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像扩散模型在多对象、属性和空间关系提示下出现的组合失败问题，如实体纠缠、属性跨对象混合和空间线索违反。

Method: 提出了一种名为MaskAttn-SDXL的区域级门控机制，应用于Stable Diffusion XL（SDXL）UNet的交叉注意力logits上，通过稀疏化标记与潜在空间的交互来增强组合控制。

Result: 在实践中，该方法提高了多对象提示的空间依从性和属性绑定，同时保持了整体图像质量和多样性。

Conclusion: MaskAttn-SDXL作为一种实用的扩展方法，通过稀疏化标记与潜在空间的交互，有效提升了文本到图像生成的空间控制和属性绑定能力。

Abstract: Text-to-image diffusion models achieve impressive realism but often suffer
from compositional failures on prompts with multiple objects, attributes, and
spatial relations, resulting in cross-token interference where entities
entangle, attributes mix across objects, and spatial cues are violated. To
address these failures, we propose MaskAttn-SDXL,a region-level gating
mechanism applied to the cross-attention logits of Stable Diffusion XL(SDXL)'s
UNet. MaskAttn-SDXL learns a binary mask per layer, injecting it into each
cross-attention logit map before softmax to sparsify token-to-latent
interactions so that only semantically relevant connections remain active. The
method requires no positional encodings, auxiliary tokens, or external region
masks, and preserves the original inference path with negligible overhead. In
practice, our model improves spatial compliance and attribute binding in
multi-object prompts while preserving overall image quality and diversity.
These findings demonstrate that logit-level maksed cross-attention is an
data-efficient primitve for enforcing compositional control, and our method
thus serves as a practical extension for spatial control in text-to-image
generation.

</details>


### [17] [RaceGAN: A Framework for Preserving Individuality while Converting Racial Information for Image-to-Image Translation](https://arxiv.org/abs/2509.15391)
*Mst Tasnim Pervin,George Bebis,Fang Jiang,Alireza Tavakkoli*

Main category: cs.CV

TL;DR: RaceGAN是一种新型多域图像转换框架，能在不依赖参考图像的情况下转换种族特征并保持个体性，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有模型（如CycleGAN、StarGAN、StarGANv2和StyleGAN）在多域图像转换中存在局限性，如无法映射低层次风格变化或需要额外参考图像。本研究旨在通过RaceGAN解决这些限制。

Method: 提出了RaceGAN框架，通过多域图像到图像转换映射风格代码，并在种族属性转换中保持个体性和高层次语义。

Result: RaceGAN在芝加哥面部数据集上表现优异，成功转换亚洲、白人和黑人种族特征，并通过InceptionReNetv2分类验证了其有效性。

Conclusion: RaceGAN在种族特征转换方面表现优于其他模型，能够在不依赖参考图像的情况下保持个体性和高层次语义。

Abstract: Generative adversarial networks (GANs) have demonstrated significant progress
in unpaired image-to-image translation in recent years for several
applications. CycleGAN was the first to lead the way, although it was
restricted to a pair of domains. StarGAN overcame this constraint by tackling
image-to-image translation across various domains, although it was not able to
map in-depth low-level style changes for these domains. Style mapping via
reference-guided image synthesis has been made possible by the innovations of
StarGANv2 and StyleGAN. However, these models do not maintain individuality and
need an extra reference image in addition to the input. Our study aims to
translate racial traits by means of multi-domain image-to-image translation. We
present RaceGAN, a novel framework capable of mapping style codes over several
domains during racial attribute translation while maintaining individuality and
high level semantics without relying on a reference image. RaceGAN outperforms
other models in translating racial features (i.e., Asian, White, and Black)
when tested on Chicago Face Dataset. We also give quantitative findings
utilizing InceptionReNetv2-based classification to demonstrate the
effectiveness of our racial translation. Moreover, we investigate how well the
model partitions the latent space into distinct clusters of faces for each
ethnic group.

</details>


### [18] [Generating Part-Based Global Explanations Via Correspondence](https://arxiv.org/abs/2509.15393)
*Kunal Rathore,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出一种利用有限用户标注生成大规模全局符号解释的方法，降低标注成本，提升模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型通常难以解释，现有方法多关注局部视觉解释，而基于概念的解释需要大量标注，成本高昂。

Method: 利用用户定义的有限图像集的部分标签，并将其高效地转移到更大的数据集上。

Result: 该方法能够生成全局符号解释，为大规模模型决策提供可理解的解释。

Conclusion: 通过聚合基于部分的局部解释，该方法能够在大规模上为模型决策提供人类可理解的全局符号解释。

Abstract: Deep learning models are notoriously opaque. Existing explanation methods
often focus on localized visual explanations for individual images.
Concept-based explanations, while offering global insights, require extensive
annotations, incurring significant labeling cost. We propose an approach that
leverages user-defined part labels from a limited set of images and efficiently
transfers them to a larger dataset. This enables the generation of global
symbolic explanations by aggregating part-based local explanations, ultimately
providing human-understandable explanations for model decisions on a large
scale.

</details>


### [19] [Causal Fingerprints of AI Generative Models](https://arxiv.org/abs/2509.15406)
*Hui Xu,Chi Liu,Congcong Zhu,Minghao Wang,Youyang Qu,Longxiang Gao*

Main category: cs.CV

TL;DR: 论文提出因果指纹概念和解耦框架，通过实验验证其在模型归因和匿名化方面的有效性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于模型特定线索或合成伪影，生成的指纹有限且在不同生成模型中泛化能力差。作者认为完整的模型指纹应反映图像来源与模型痕迹之间的因果关系。

Method: 提出了一个因果关系解耦框架，该框架在预训练扩散重建残差导出的语义不变潜在空间中，将因果指纹从图像特定内容和风格中解耦。通过多样化的特征表示增强了指纹的粒度。

Result: 实验表明，该方法在模型归因方面优于现有方法，并通过因果指纹生成的对抗性示例实现了来源匿名化。

Conclusion: 该论文提出了一种新的因果指纹概念，并证明了其在模型归因方面的优越性，展示了在伪造检测、模型版权追踪和身份保护方面的强大潜力。

Abstract: AI generative models leave implicit traces in their generated images, which
are commonly referred to as model fingerprints and are exploited for source
attribution. Prior methods rely on model-specific cues or synthesis artifacts,
yielding limited fingerprints that may generalize poorly across different
generative models. We argue that a complete model fingerprint should reflect
the causality between image provenance and model traces, a direction largely
unexplored. To this end, we conceptualize the \emph{causal fingerprint} of
generative models, and propose a causality-decoupling framework that
disentangles it from image-specific content and style in a semantic-invariant
latent space derived from pre-trained diffusion reconstruction residual. We
further enhance fingerprint granularity with diverse feature representations.
We validate causality by assessing attribution performance across
representative GANs and diffusion models and by achieving source anonymization
using counterfactual examples generated from causal fingerprints. Experiments
show our approach outperforms existing methods in model attribution, indicating
strong potential for forgery detection, model copyright tracing, and identity
protection.

</details>


### [20] [NeuroRAD-FM: A Foundation Model for Neuro-Oncology with Distributionally Robust Training](https://arxiv.org/abs/2509.15416)
*Moinak Bhattacharya,Angelica P. Kurtz,Fabio M. Iwamoto,Prateek Prasanna,Gagandeep Singh*

Main category: cs.CV

TL;DR: 本研究提出了一种结合分布鲁棒优化的神经肿瘤学基础模型，显著提升了分子标志物预测和生存分析的准确性，同时增强了模型的泛化能力和可解释性。


<details>
  <summary>Details</summary>
Motivation: 神经肿瘤学中数据异质性和肿瘤复杂性限制了基础模型（FMs）在不同队列中的泛化能力，且现有模型对罕见分子标志物的预测表现不佳，而这些标志物对治疗反应和风险分层至关重要。

Method: 本研究开发了一个针对神经肿瘤学的基础模型（FM），采用分布鲁棒损失函数，结合自监督学习框架（BYOL、DINO、MAE、MoCo）在多机构脑肿瘤MRI数据上进行预训练，并应用分布鲁棒优化（DRO）以减少站点和类别不平衡的影响。下游任务包括分子分类（常见和罕见标志物）、连续标志物预测及生存分析。

Result: 该方法显著提升了分子预测的准确性并减少了站点特异性嵌入差异。例如，在CUIMC，平均平衡准确率从0.744提升至0.785，AUC从0.656提升至0.676。在生存分析中，所有站点的c-index均有所改善。Grad-CAM分析证实了模型的可解释性。

Conclusion: 通过结合基础模型（FMs）与分布鲁棒优化（DRO），本研究实现了更不受站点影响的表征，提高了对常见和罕见分子标志物的预测能力，并增强了生存分析的区分度。未来需进一步的前瞻性验证及整合纵向和干预信号，以推动精准神经肿瘤学的发展。

Abstract: Neuro-oncology poses unique challenges for machine learning due to
heterogeneous data and tumor complexity, limiting the ability of foundation
models (FMs) to generalize across cohorts. Existing FMs also perform poorly in
predicting uncommon molecular markers, which are essential for treatment
response and risk stratification. To address these gaps, we developed a
neuro-oncology specific FM with a distributionally robust loss function,
enabling accurate estimation of tumor phenotypes while maintaining
cross-institution generalization. We pretrained self-supervised backbones
(BYOL, DINO, MAE, MoCo) on multi-institutional brain tumor MRI and applied
distributionally robust optimization (DRO) to mitigate site and class
imbalance. Downstream tasks included molecular classification of common markers
(MGMT, IDH1, 1p/19q, EGFR), uncommon alterations (ATRX, TP53, CDKN2A/2B, TERT),
continuous markers (Ki-67, TP53), and overall survival prediction in IDH1
wild-type glioblastoma at UCSF, UPenn, and CUIMC. Our method improved molecular
prediction and reduced site-specific embedding differences. At CUIMC, mean
balanced accuracy rose from 0.744 to 0.785 and AUC from 0.656 to 0.676, with
the largest gains for underrepresented endpoints (CDKN2A/2B accuracy 0.86 to
0.92, AUC 0.73 to 0.92; ATRX AUC 0.69 to 0.82; Ki-67 accuracy 0.60 to 0.69).
For survival, c-index improved at all sites: CUIMC 0.592 to 0.597, UPenn 0.647
to 0.672, UCSF 0.600 to 0.627. Grad-CAM highlighted tumor and peri-tumoral
regions, confirming interpretability. Overall, coupling FMs with DRO yields
more site-invariant representations, improves prediction of common and uncommon
markers, and enhances survival discrimination, underscoring the need for
prospective validation and integration of longitudinal and interventional
signals to advance precision neuro-oncology.

</details>


### [21] [ORCA: Agentic Reasoning For Hallucination and Adversarial Robustness in Vision-Language Models](https://arxiv.org/abs/2509.15435)
*Chung-En Johnny Yu,Hsuan-Chih,Chen,Brian Jalaian,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: ORCA通过测试时结构化推理框架提升LVLM的事实准确性和对抗鲁棒性，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态能力上表现出色，但由于内在错误和外部攻击导致的幻觉问题，限制了其在现实世界应用中的可靠性。

Method: ORCA通过观察-推理-批判-行动的循环操作，查询多个视觉工具，验证跨模型不一致性，并迭代优化预测，无需访问模型内部或重新训练。

Result: 在POPE幻觉基准测试中，ORCA将独立LVLM性能提高了+3.64%到+40.67%；在对抗性扰动下，平均准确率提升+20.11%；结合防御技术后，性能提升范围从+1.20%到+48.00%。

Conclusion: ORCA提供了一条构建更可靠和鲁棒的多模态系统的有前景路径。

Abstract: Large Vision-Language Models (LVLMs) exhibit strong multimodal capabilities
but remain vulnerable to hallucinations from intrinsic errors and adversarial
attacks from external exploitations, limiting their reliability in real-world
applications. We present ORCA, an agentic reasoning framework that improves the
factual accuracy and adversarial robustness of pretrained LVLMs through
test-time structured inference reasoning with a suite of small vision models
(less than 3B parameters). ORCA operates via an Observe--Reason--Critique--Act
loop, querying multiple visual tools with evidential questions, validating
cross-model inconsistencies, and refining predictions iteratively without
access to model internals or retraining. ORCA also stores intermediate
reasoning traces, which supports auditable decision-making. Though designed
primarily to mitigate object-level hallucinations, ORCA also exhibits emergent
adversarial robustness without requiring adversarial training or defense
mechanisms. We evaluate ORCA across three settings: (1) clean images on
hallucination benchmarks, (2) adversarially perturbed images without defense,
and (3) adversarially perturbed images with defense applied. On the POPE
hallucination benchmark, ORCA improves standalone LVLM performance by +3.64\%
to +40.67\% across different subsets. Under adversarial perturbations on POPE,
ORCA achieves an average accuracy gain of +20.11\% across LVLMs. When combined
with defense techniques on adversarially perturbed AMBER images, ORCA further
improves standalone LVLM performance, with gains ranging from +1.20\% to
+48.00\% across evaluation metrics. These results demonstrate that ORCA offers
a promising path toward building more reliable and robust multimodal systems.

</details>


### [22] [Region-Aware Deformable Convolutions](https://arxiv.org/abs/2509.15436)
*Abolfazl Saheban Maleki,Maryam Imani*

Main category: cs.CV

TL;DR: RAD-Conv是一种新型卷积算子，通过动态调整矩形采样区域，提升神经网络对复杂图像结构的适应性，结合了注意力机制的灵活性和标准卷积的效率。


<details>
  <summary>Details</summary>
Motivation: 传统可变形卷积局限于固定的四边形采样区域，无法灵活适应复杂图像结构。RAD-Conv旨在通过动态调整采样区域，提升神经网络对复杂图像结构的适应性。

Method: RAD-Conv使用四个边界偏移量每个核元素，创建灵活可调的矩形区域，动态调整其大小和形状以匹配图像内容，从而解耦感受野形状与核结构。

Result: RAD-Conv能够精确控制感受野的宽度和高度，即使使用1x1小核也能捕捉局部细节和长程依赖关系。

Conclusion: RAD-Conv通过灵活的矩形区域和动态调整的采样区域，结合了注意力机制的适应性和标准卷积的效率，为构建更高效、更具表现力的视觉模型提供了实用解决方案。

Abstract: We introduce Region-Aware Deformable Convolution (RAD-Conv), a new
convolutional operator that enhances neural networks' ability to adapt to
complex image structures. Unlike traditional deformable convolutions, which are
limited to fixed quadrilateral sampling areas, RAD-Conv uses four boundary
offsets per kernel element to create flexible, rectangular regions that
dynamically adjust their size and shape to match image content. This approach
allows precise control over the receptive field's width and height, enabling
the capture of both local details and long-range dependencies, even with small
1x1 kernels. By decoupling the receptive field's shape from the kernel's
structure, RAD-Conv combines the adaptability of attention mechanisms with the
efficiency of standard convolutions. This innovative design offers a practical
solution for building more expressive and efficient vision models, bridging the
gap between rigid convolutional architectures and computationally costly
attention-based methods.

</details>


### [23] [CAGE: Continuity-Aware edGE Network Unlocks Robust Floorplan Reconstruction](https://arxiv.org/abs/2509.15459)
*Yiyi Liu,Chunyang Liu,Weiqin Jiao,Bojian Wu,Fashuai Li,Biao Xiong*

Main category: cs.CV

TL;DR: CAGE是一种边缘中心的网络，通过几何连续边缘表示和双查询变压器解码器，显著提高了矢量平面图重建的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于角落的多边形表示对噪声和不完整观察高度敏感，导致布局不连贯或不合理；现有线分组方法在恢复精细几何细节方面仍有困难。

Method: 提出了一种基于边缘的矢量表示方法，并使用双查询变压器解码器在去噪框架中集成扰动和潜在查询，以稳定优化并加速收敛。

Result: 在Structured3D和SceneCAD数据集上，CAGE实现了房间F1分数99.1%、角落91.7%和角度89.3%的性能。

Conclusion: CAGE网络通过其边缘中心的表示和双查询变压器解码器，在矢量平面图重建中实现了最先进的性能，并展示了强大的跨数据集泛化能力。

Abstract: We present \textbf{CAGE} (\textit{Continuity-Aware edGE}) network, a
\textcolor{red}{robust} framework for reconstructing vector floorplans directly
from point-cloud density maps. Traditional corner-based polygon representations
are highly sensitive to noise and incomplete observations, often resulting in
fragmented or implausible layouts. Recent line grouping methods leverage
structural cues to improve robustness but still struggle to recover fine
geometric details. To address these limitations, we propose a \textit{native}
edge-centric formulation, modeling each wall segment as a directed,
geometrically continuous edge. This representation enables inference of
coherent floorplan structures, ensuring watertight, topologically valid room
boundaries while improving robustness and reducing artifacts. Towards this
design, we develop a dual-query transformer decoder that integrates perturbed
and latent queries within a denoising framework, which not only stabilizes
optimization but also accelerates convergence. Extensive experiments on
Structured3D and SceneCAD show that \textbf{CAGE} achieves state-of-the-art
performance, with F1 scores of 99.1\% (rooms), 91.7\% (corners), and 89.3\%
(angles). The method also demonstrates strong cross-dataset generalization,
underscoring the efficacy of our architectural innovations. Code and pretrained
models will be released upon acceptance.

</details>


### [24] [Self-supervised learning of imaging and clinical signatures using a multimodal joint-embedding predictive architecture](https://arxiv.org/abs/2509.15470)
*Thomas Z. Li,Aravind R. Krishnan,Lianrui Zuo,John M. Still,Kim L. Sandler,Fabien Maldonado,Thomas A. Lasko,Bennett A. Landman*

Main category: cs.CV

TL;DR: A self-supervised learning approach using multimodal data improves pulmonary nodule diagnosis internally but faces challenges in external validation, with a synthetic environment developed to explore limitations.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the scarcity of labeled data and the tendency of multimodal models to overfit on training distributions, which limits the development of effective diagnostic models for pulmonary nodules.

Method: The method involves leveraging self-supervised learning from longitudinal and multimodal archives, specifically using unlabeled CT scans and electronic health records for pretraining a joint embedding predictive architecture (JEPA), followed by supervised finetuning.

Result: The results show that the proposed approach outperforms unregularized multimodal and imaging-only models in an internal cohort (AUC: 0.91 vs. 0.88 and 0.73) but underperforms in an external cohort (AUC: 0.72 vs. 0.75). A synthetic environment was developed to analyze the underperformance context.

Conclusion: This work presents an innovative approach using self-supervised learning and multimodal data to improve pulmonary nodule diagnosis, highlighting both its advantages and limitations in different clinical settings.

Abstract: The development of multimodal models for pulmonary nodule diagnosis is
limited by the scarcity of labeled data and the tendency for these models to
overfit on the training distribution. In this work, we leverage self-supervised
learning from longitudinal and multimodal archives to address these challenges.
We curate an unlabeled set of patients with CT scans and linked electronic
health records from our home institution to power joint embedding predictive
architecture (JEPA) pretraining. After supervised finetuning, we show that our
approach outperforms an unregularized multimodal model and imaging-only model
in an internal cohort (ours: 0.91, multimodal: 0.88, imaging-only: 0.73 AUC),
but underperforms in an external cohort (ours: 0.72, imaging-only: 0.75 AUC).
We develop a synthetic environment that characterizes the context in which JEPA
may underperform. This work innovates an approach that leverages unlabeled
multimodal medical archives to improve predictive models and demonstrates its
advantages and limitations in pulmonary nodule diagnosis.

</details>


### [25] [Efficient Multimodal Dataset Distillation via Generative Models](https://arxiv.org/abs/2509.15472)
*Zhenghao Zhao,Haoxuan Wang,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan*

Main category: cs.CV

TL;DR: EDGE是一种高效的多模态数据集蒸馏方法，通过双向对比损失和多样性损失解决生成图像与标题的相关性和样本多样性问题，速度提升18倍。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态数据集蒸馏方法受限于匹配训练轨迹算法，计算资源需求高且耗时。本文旨在解决生成图像与标题之间缺乏相关性以及生成样本多样性不足的问题。

Method: 提出了一种新的生成模型训练流程，包括双向对比损失和多样性损失，以及一种标题合成策略来增强文本到图像的检索性能。

Result: EDGE方法在多个数据集上展示了卓越的性能和效率，显著优于现有方法。

Conclusion: EDGE方法在Flickr30K、COCO和CC3M数据集上表现出色，不仅性能优于现有方法，还显著提高了效率，速度提升了18倍。

Abstract: Dataset distillation aims to synthesize a small dataset from a large dataset,
enabling the model trained on it to perform well on the original dataset. With
the blooming of large language models and multimodal large language models, the
importance of multimodal datasets, particularly image-text datasets, has grown
significantly. However, existing multimodal dataset distillation methods are
constrained by the Matching Training Trajectories algorithm, which
significantly increases the computing resource requirement, and takes days to
process the distillation. In this work, we introduce EDGE, a generative
distillation method for efficient multimodal dataset distillation.
Specifically, we identify two key challenges of distilling multimodal datasets
with generative models: 1) The lack of correlation between generated images and
captions. 2) The lack of diversity among generated samples. To address the
aforementioned issues, we propose a novel generative model training workflow
with a bi-directional contrastive loss and a diversity loss. Furthermore, we
propose a caption synthesis strategy to further improve text-to-image retrieval
performance by introducing more text information. Our method is evaluated on
Flickr30K, COCO, and CC3M datasets, demonstrating superior performance and
efficiency compared to existing approaches. Notably, our method achieves
results 18x faster than the state-of-the-art method.

</details>


### [26] [OpenViGA: Video Generation for Automotive Driving Scenes by Streamlining and Fine-Tuning Open Source Models with Public Data](https://arxiv.org/abs/2509.15479)
*Björn Möller,Zhengyang Li,Malte Stelzer,Thomas Graave,Fabian Bettels,Muaaz Ataya,Tim Fingscheidt*

Main category: cs.CV

TL;DR: OpenViGA是一个开源的自动驾驶视频生成系统，整合了预训练模型和公开数据集，实现了高效、可复现的视频预测。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成系统依赖大型模型、训练资源需求高、设计选择缺乏透明度以及代码和数据集不公开的问题。

Method: 系统基于预训练的开源模型，使用公开的汽车数据集（BDD100K）在学术规模的GPU硬件上进行微调，并通过统一的接口整合了图像标记器、世界模型和视频解码器。

Result: 在256x256分辨率、4fps的条件下，系统能够仅用一帧的算法延迟逐帧预测出逼真的驾驶场景视频。

Conclusion: OpenViGA是一个开源的视频生成系统，专注于自动驾驶场景，通过公开的模型和数据实现了完全可复现性。

Abstract: Recent successful video generation systems that predict and create realistic
automotive driving scenes from short video inputs assign tokenization, future
state prediction (world model), and video decoding to dedicated models. These
approaches often utilize large models that require significant training
resources, offer limited insight into design choices, and lack publicly
available code and datasets. In this work, we address these deficiencies and
present OpenViGA, an open video generation system for automotive driving
scenes. Our contributions are: Unlike several earlier works for video
generation, such as GAIA-1, we provide a deep analysis of the three components
of our system by separate quantitative and qualitative evaluation: Image
tokenizer, world model, video decoder. Second, we purely build upon powerful
pre-trained open source models from various domains, which we fine-tune by
publicly available automotive data (BDD100K) on GPU hardware at academic scale.
Third, we build a coherent video generation system by streamlining interfaces
of our components. Fourth, due to public availability of the underlying models
and data, we allow full reproducibility. Finally, we also publish our code and
models on Github. For an image size of 256x256 at 4 fps we are able to predict
realistic driving scene videos frame-by-frame with only one frame of
algorithmic latency.

</details>


### [27] [Comparing Computational Pathology Foundation Models using Representational Similarity Analysis](https://arxiv.org/abs/2509.15482)
*Vaibhav Mishra,William Lotter*

Main category: cs.CV

TL;DR: 该研究分析了六种计算病理学基础模型的表示空间，揭示了其结构和可变性，为模型改进和部署提供了见解。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究评估了模型的任务性能，但对学习表示的结构和可变性了解较少。

Method: 通过使用计算神经科学中的表示相似性分析技术，系统地分析了六种CPath基础模型的表示空间。

Result: 发现UNI2和Virchow2的表示结构最独特，Prov-Gigapath的平均相似性最高；视觉语言模型表示相对紧凑，而纯视觉模型表示更分散；染色标准化降低了所有模型的切片依赖性。

Conclusion: 该研究揭示了计算病理学基础模型表示空间的结构和可变性，为改进模型稳健性、集成策略及训练范式提供了见解。

Abstract: Foundation models are increasingly developed in computational pathology
(CPath) given their promise in facilitating many downstream tasks. While recent
studies have evaluated task performance across models, less is known about the
structure and variability of their learned representations. Here, we
systematically analyze the representational spaces of six CPath foundation
models using techniques popularized in computational neuroscience. The models
analyzed span vision-language contrastive learning (CONCH, PLIP, KEEP) and
self-distillation (UNI (v2), Virchow (v2), Prov-GigaPath) approaches. Through
representational similarity analysis using H&E image patches from TCGA, we find
that UNI2 and Virchow2 have the most distinct representational structures,
whereas Prov-Gigapath has the highest average similarity across models. Having
the same training paradigm (vision-only vs. vision-language) did not guarantee
higher representational similarity. The representations of all models showed a
high slide-dependence, but relatively low disease-dependence. Stain
normalization decreased slide-dependence for all models by a range of 5.5%
(CONCH) to 20.5% (PLIP). In terms of intrinsic dimensionality, vision-language
models demonstrated relatively compact representations, compared to the more
distributed representations of vision-only models. These findings highlight
opportunities to improve robustness to slide-specific features, inform model
ensembling strategies, and provide insights into how training paradigms shape
model representations. Our framework is extendable across medical imaging
domains, where probing the internal representations of foundation models can
help ensure effective development and deployment.

</details>


### [28] [SmolRGPT: Efficient Spatial Reasoning for Warehouse Environments with 600M Parameters](https://arxiv.org/abs/2509.15490)
*Abdarahmane Traore,Éric Hervet,Andy Couturier*

Main category: cs.CV

TL;DR: SmolRGPT是一种紧凑的视觉语言架构，通过整合RGB和深度线索，在资源受限环境中实现高效部署，性能媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的视觉语言模型通常依赖计算和内存需求极高的超大模型，难以在资源受限的环境中部署。

Method: SmolRGPT采用三阶段课程，逐步对齐视觉和语言特征，实现空间关系理解，并适应特定任务数据集。

Result: 仅使用6亿参数，SmolRGPT在具有挑战性的仓库空间推理基准上取得了与更大模型相媲美或更优的性能。

Conclusion: SmolRGPT作为一种紧凑的视觉语言架构，通过整合RGB和深度线索，在资源受限的环境中实现了高效的部署，同时保持了核心的空间推理能力。

Abstract: Recent advances in vision-language models (VLMs) have enabled powerful
multimodal reasoning, but state-of-the-art approaches typically rely on
extremely large models with prohibitive computational and memory requirements.
This makes their deployment challenging in resource-constrained environments
such as warehouses, robotics, and industrial applications, where both
efficiency and robust spatial understanding are critical. In this work, we
present SmolRGPT, a compact vision-language architecture that explicitly
incorporates region-level spatial reasoning by integrating both RGB and depth
cues. SmolRGPT employs a three-stage curriculum that progressively align visual
and language features, enables spatial relationship understanding, and adapts
to task-specific datasets. We demonstrate that with only 600M parameters,
SmolRGPT achieves competitive results on challenging warehouse spatial
reasoning benchmarks, matching or exceeding the performance of much larger
alternatives. These findings highlight the potential for efficient, deployable
multimodal intelligence in real-world settings without sacrificing core spatial
reasoning capabilities. The code of the experimentation will be available at:
https://github.com/abtraore/SmolRGPT

</details>


### [29] [Lynx: Towards High-Fidelity Personalized Video Generation](https://arxiv.org/abs/2509.15496)
*Shen Sang,Tiancheng Zhi,Tianpei Gu,Jing Liu,Linjie Luo*

Main category: cs.CV

TL;DR: Lynx是一个基于DiT的高保真个性化视频合成模型，通过两个轻量级适配器实现身份保真，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决个性化视频合成中的身份保真度问题，同时保持时间连贯性和视觉真实感。

Method: 基于开源的Diffusion Transformer (DiT)基础模型，Lynx引入了两个轻量级适配器：ID-adapter（使用Perceiver Resampler转换ArcFace面部嵌入为紧凑身份令牌）和Ref-adapter（通过交叉注意力在所有Transformer层中注入冻结参考路径的密集VAE特征）。

Result: 在包含40个主题和20个无偏提示的基准测试中（共800个测试案例），Lynx表现出卓越的面部相似性、竞争性的提示跟随能力和强大的视频质量。

Conclusion: Lynx通过引入ID-adapter和Ref-adapter，显著提升了单张输入图像生成个性化视频的保真度，推动了该领域的发展。

Abstract: We present Lynx, a high-fidelity model for personalized video synthesis from
a single input image. Built on an open-source Diffusion Transformer (DiT)
foundation model, Lynx introduces two lightweight adapters to ensure identity
fidelity. The ID-adapter employs a Perceiver Resampler to convert
ArcFace-derived facial embeddings into compact identity tokens for
conditioning, while the Ref-adapter integrates dense VAE features from a frozen
reference pathway, injecting fine-grained details across all transformer layers
through cross-attention. These modules collectively enable robust identity
preservation while maintaining temporal coherence and visual realism. Through
evaluation on a curated benchmark of 40 subjects and 20 unbiased prompts, which
yielded 800 test cases, Lynx has demonstrated superior face resemblance,
competitive prompt following, and strong video quality, thereby advancing the
state of personalized video generation.

</details>


### [30] [Backdoor Mitigation via Invertible Pruning Masks](https://arxiv.org/abs/2509.15497)
*Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak*

Main category: cs.CV

TL;DR: 提出一种新型剪枝方法，通过可逆掩码和双层优化有效缓解后门攻击，在低数据量条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法在准确识别和移除导致后门行为的参数方面存在不足，而微调方法虽性能优越但剪枝方法在可解释性和低数据量条件下的鲁棒性更具优势。

Method: 通过双层优化问题联合学习选择变量、稀疏可逆掩码和基于干净数据的样本特定后门扰动。

Result: 实验表明，该方法优于现有基于剪枝的后门缓解方法，在有限数据条件下保持强性能，并与最先进的微调方法竞争。

Conclusion: 提出的剪枝方法在低数据量条件下表现出色，能够有效恢复被篡改样本的正确预测，与现有微调方法竞争。

Abstract: Model pruning has gained traction as a promising defense strategy against
backdoor attacks in deep learning. However, existing pruning-based approaches
often fall short in accurately identifying and removing the specific parameters
responsible for inducing backdoor behaviors. Despite the dominance of
fine-tuning-based defenses in recent literature, largely due to their superior
performance, pruning remains a compelling alternative, offering greater
interpretability and improved robustness in low-data regimes. In this paper, we
propose a novel pruning approach featuring a learned \emph{selection} mechanism
to identify parameters critical to both main and backdoor tasks, along with an
\emph{invertible} pruning mask designed to simultaneously achieve two
complementary goals: eliminating the backdoor task while preserving it through
the inverse mask. We formulate this as a bi-level optimization problem that
jointly learns selection variables, a sparse invertible mask, and
sample-specific backdoor perturbations derived from clean data. The inner
problem synthesizes candidate triggers using the inverse mask, while the outer
problem refines the mask to suppress backdoor behavior without impairing
clean-task accuracy. Extensive experiments demonstrate that our approach
outperforms existing pruning-based backdoor mitigation approaches, maintains
strong performance under limited data conditions, and achieves competitive
results compared to state-of-the-art fine-tuning approaches. Notably, the
proposed approach is particularly effective in restoring correct predictions
for compromised samples after successful backdoor mitigation.

</details>


### [31] [MEC-Quant: Maximum Entropy Coding for Extremely Low Bit Quantization-Aware Training](https://arxiv.org/abs/2509.15514)
*Junbiao Pang,Tianyang Cai,Baochang Zhang*

Main category: cs.CV

TL;DR: MEC-Quant 是一种新的量化感知训练方法，通过优化表示结构减少量化偏差，在极低比特设置下性能超越全精度模型。


<details>
  <summary>Details</summary>
Motivation: 量化不可避免地引入偏差，尤其是在极低比特设置下，影响模型性能。MEC-Quant 旨在优化表示结构以减少偏差，提升泛化能力。

Method: 提出了一种基于最大熵编码量化（MEC-Quant）的方法，利用最小编码长度作为熵的替代，并通过混合专家（MOE）实现可扩展性。

Result: MEC-Quant 在多种计算机视觉任务中表现出色，首次将 QAT 的极限推至 x 比特激活，性能媲美或超越 FP 模型。

Conclusion: MEC-Quant 在量化感知训练（QAT）中实现了新的最先进水平，其性能甚至超越全精度（FP）模型，尤其是在极低比特设置下。

Abstract: Quantization-Aware Training (QAT) has driven much attention to produce
efficient neural networks. Current QAT still obtains inferior performances
compared with the Full Precision (FP) counterpart. In this work, we argue that
quantization inevitably introduce biases into the learned representation,
especially under the extremely low-bit setting. To cope with this issue, we
propose Maximum Entropy Coding Quantization (MEC-Quant), a more principled
objective that explicitly optimizes on the structure of the representation, so
that the learned representation is less biased and thus generalizes better to
unseen in-distribution samples. To make the objective end-to-end trainable, we
propose to leverage the minimal coding length in lossy data coding as a
computationally tractable surrogate for the entropy, and further derive a
scalable reformulation of the objective based on Mixture Of Experts (MOE) that
not only allows fast computation but also handles the long-tailed distribution
for weights or activation values. Extensive experiments on various tasks on
computer vision tasks prove its superiority. With MEC-Qaunt, the limit of QAT
is pushed to the x-bit activation for the first time and the accuracy of
MEC-Quant is comparable to or even surpass the FP counterpart. Without bells
and whistles, MEC-Qaunt establishes a new state of the art for QAT.

</details>


### [32] [GUI-ARP: Enhancing Grounding with Adaptive Region Perception for GUI Agents](https://arxiv.org/abs/2509.15532)
*Xianhang Ye,Yiqing Li,Wei Dai,Miancan Liu,Ziyuan Chen,Zhangye Han,Hongbo Min,Jinkui Ren,Xiantao Zhang,Wen Yang,Zhi Jin*

Main category: cs.CV

TL;DR: GUI-ARP通过自适应多阶段推理和强化学习训练，显著提升了高分辨率GUI细粒度定位的准确率，性能媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位方法在高分辨率截图中的细粒度定位表现不佳，需要更灵活的自适应方法。

Method: 提出了GUI-ARP框架，结合自适应区域感知（ARP）和自适应阶段控制（ASC），通过两阶段训练流程（监督微调与基于GRPO的强化微调）实现动态推理策略。

Result: GUI-ARP在ScreenSpot-Pro和UI-Vision基准测试中分别达到60.8%和30.9%的准确率，性能优于开源72B模型（UI-TARS-72B为38.1%）。

Conclusion: GUI-ARP框架通过自适应多阶段推理和创新的训练流程，在高分辨率屏幕截图中的细粒度定位任务上表现出色，甚至能与更大规模的模型竞争。

Abstract: Existing GUI grounding methods often struggle with fine-grained localization
in high-resolution screenshots. To address this, we propose GUI-ARP, a novel
framework that enables adaptive multi-stage inference. Equipped with the
proposed Adaptive Region Perception (ARP) and Adaptive Stage Controlling (ASC),
GUI-ARP dynamically exploits visual attention for cropping task-relevant
regions and adapts its inference strategy, performing a single-stage inference
for simple cases and a multi-stage analysis for more complex scenarios. This is
achieved through a two-phase training pipeline that integrates supervised
fine-tuning with reinforcement fine-tuning based on Group Relative Policy
Optimization (GRPO). Extensive experiments demonstrate that the proposed
GUI-ARP achieves state-of-the-art performance on challenging GUI grounding
benchmarks, with a 7B model reaching 60.8% accuracy on ScreenSpot-Pro and 30.9%
on UI-Vision benchmark. Notably, GUI-ARP-7B demonstrates strong competitiveness
against open-source 72B models (UI-TARS-72B at 38.1%) and proprietary models.

</details>


### [33] [SAMPO:Scale-wise Autoregression with Motion PrOmpt for generative world models](https://arxiv.org/abs/2509.15536)
*Sen Wang,Jingyi Tian,Le Wang,Zhimin Liao,Jiayi Li,Huaiyi Dong,Kun Xia,Sanping Zhou,Wei Tang,Hua Gang*

Main category: cs.CV

TL;DR: SAMPO是一种结合视觉自回归和因果建模的混合框架，通过改进的解码和动态场景理解，显著提升了视频预测的时空一致性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归世界模型在视觉一致性预测上存在空间结构破坏、解码效率低和运动建模不足的问题，需要一种更高效的框架来提升预测质量和效率。

Method: SAMPO结合了视觉自回归建模和因果建模，通过时间因果解码与双向空间注意力的整合，保留了空间局部性并支持并行解码。此外，设计了非对称多尺度分词器和轨迹感知运动提示模块以优化动态场景理解和时空一致性。

Result: SAMPO在动作条件视频预测和基于模型的控制中取得了竞争性性能，生成质量显著提升，推理速度提高了4.4倍，并展示了零样本泛化能力。

Conclusion: SAMPO框架在视频预测和基于模型的控制中表现出色，不仅提高了生成质量，还实现了4.4倍的推理加速，同时展示了零样本泛化和扩展能力。

Abstract: World models allow agents to simulate the consequences of actions in imagined
environments for planning, control, and long-horizon decision-making. However,
existing autoregressive world models struggle with visually coherent
predictions due to disrupted spatial structure, inefficient decoding, and
inadequate motion modeling. In response, we propose \textbf{S}cale-wise
\textbf{A}utoregression with \textbf{M}otion \textbf{P}r\textbf{O}mpt
(\textbf{SAMPO}), a hybrid framework that combines visual autoregressive
modeling for intra-frame generation with causal modeling for next-frame
generation. Specifically, SAMPO integrates temporal causal decoding with
bidirectional spatial attention, which preserves spatial locality and supports
parallel decoding within each scale. This design significantly enhances both
temporal consistency and rollout efficiency. To further improve dynamic scene
understanding, we devise an asymmetric multi-scale tokenizer that preserves
spatial details in observed frames and extracts compact dynamic representations
for future frames, optimizing both memory usage and model performance.
Additionally, we introduce a trajectory-aware motion prompt module that injects
spatiotemporal cues about object and robot trajectories, focusing attention on
dynamic regions and improving temporal consistency and physical realism.
Extensive experiments show that SAMPO achieves competitive performance in
action-conditioned video prediction and model-based control, improving
generation quality with 4.4$\times$ faster inference. We also evaluate SAMPO's
zero-shot generalization and scaling behavior, demonstrating its ability to
generalize to unseen tasks and benefit from larger model sizes.

</details>


### [34] [Beyond Words: Enhancing Desire, Emotion, and Sentiment Recognition with Non-Verbal Cues](https://arxiv.org/abs/2509.15540)
*Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha*

Main category: cs.CV

TL;DR: 本文提出了一种对称双向多模态学习框架，通过文本和图像的相互引导提升欲望、情感和情感识别的性能，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在情感和情感识别方面取得了进展，但针对人类欲望理解的多模态方法仍未被充分探索，且现有情感分析方法主要关注语言线索而忽略了图像作为补充的非语言线索。

Method: 提出了一种对称双向多模态学习框架，通过文本和图像模态的相互引导，有效捕捉意图相关的图像表示。具体包括低分辨率图像的全局视觉表示、高分辨率子图像的掩码图像建模，以及文本引导的图像解码器和图像引导的文本解码器。

Result: 实验结果表明，该方法在MSED数据集上优于现有方法，欲望理解、情感识别和情感分析的F1分数分别提高了1.1%、0.6%和0.9%。

Conclusion: 本文提出的对称双向多模态学习框架在欲望、情感和情感识别方面取得了显著改进，验证了该方法的有效性。

Abstract: Desire, as an intention that drives human behavior, is closely related to
both emotion and sentiment. Multimodal learning has advanced sentiment and
emotion recognition, but multimodal approaches specially targeting human desire
understanding remain underexplored. And existing methods in sentiment analysis
predominantly emphasize verbal cues and overlook images as complementary
non-verbal cues. To address these gaps, we propose a Symmetrical Bidirectional
Multimodal Learning Framework for Desire, Emotion, and Sentiment Recognition,
which enforces mutual guidance between text and image modalities to effectively
capture intention-related representations in the image. Specifically,
low-resolution images are used to obtain global visual representations for
cross-modal alignment, while high resolution images are partitioned into
sub-images and modeled with masked image modeling to enhance the ability to
capture fine-grained local features. A text-guided image decoder and an
image-guided text decoder are introduced to facilitate deep cross-modal
interaction at both local and global representations of image information.
Additionally, to balance perceptual gains with computation cost, a mixed-scale
image strategy is adopted, where high-resolution images are cropped into
sub-images for masked modeling. The proposed approach is evaluated on MSED, a
multimodal dataset that includes a desire understanding benchmark, as well as
emotion and sentiment recognition. Experimental results indicate consistent
improvements over other state-of-the-art methods, validating the effectiveness
of our proposed method. Specifically, our method outperforms existing
approaches, achieving F1-score improvements of 1.1% in desire understanding,
0.6% in emotion recognition, and 0.9% in sentiment analysis. Our code is
available at: https://github.com/especiallyW/SyDES.

</details>


### [35] [Enhancing Sa2VA for Referent Video Object Segmentation: 2nd Solution for 7th LSVOS RVOS Track](https://arxiv.org/abs/2509.15546)
*Ran Hong,Feng Lu,Leilei Cao,An Yan,Youhai Jiang,Fengjie Zhu*

Main category: cs.CV

TL;DR: 提出了一种无训练框架，通过视频语言检查器和关键帧采样器，显著提升了RVOS任务的分割性能，达到了64.14%的J&F分数。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在RVOS任务中的误报问题，并提升分割性能，提出了一种无需额外训练的高效框架。

Method: 1. 视频语言检查器：显式验证查询中的主题和动作是否出现在视频中，减少误报。2. 关键帧采样器：自适应选择信息丰富的帧，捕捉早期对象出现和长程时间上下文。

Result: 在MeViS测试集上达到了64.14%的J&F分数，在ICCV 2025的LSVOS挑战赛RVOS赛道中排名第二。

Conclusion: 提出的无训练框架显著提升了Sa2VA在RVOS任务中的性能，通过引入视频语言检查器和关键帧采样器，有效减少了误报并提升了分割准确性。

Abstract: Referential Video Object Segmentation (RVOS) aims to segment all objects in a
video that match a given natural language description, bridging the gap between
vision and language understanding. Recent work, such as Sa2VA, combines Large
Language Models (LLMs) with SAM~2, leveraging the strong video reasoning
capability of LLMs to guide video segmentation. In this work, we present a
training-free framework that substantially improves Sa2VA's performance on the
RVOS task. Our method introduces two key components: (1) a Video-Language
Checker that explicitly verifies whether the subject and action described in
the query actually appear in the video, thereby reducing false positives; and
(2) a Key-Frame Sampler that adaptively selects informative frames to better
capture both early object appearances and long-range temporal context. Without
any additional training, our approach achieves a J&F score of 64.14% on the
MeViS test set, ranking 2nd place in the RVOS track of the 7th LSVOS Challenge
at ICCV 2025.

</details>


### [36] [MS-GS: Multi-Appearance Sparse-View 3D Gaussian Splatting in the Wild](https://arxiv.org/abs/2509.15548)
*Deming Li,Kaiwen Jiang,Yutao Tang,Ravi Ramamoorthi,Rama Chellappa,Cheng Peng*

Main category: cs.CV

TL;DR: MS-GS利用几何先验和虚拟视图监督，显著提升了稀疏视图和多外观条件下的3D渲染质量。


<details>
  <summary>Details</summary>
Motivation: 解决野外照片集因稀疏性和多外观特性导致的场景重建和新视图合成挑战。

Method: 基于单目深度估计的几何先验，采用局部语义区域提取和SfM点锚定算法，结合几何引导的虚拟视图监督。

Result: MS-GS在多个数据集上表现出色，尤其在稀疏视图和多外观条件下。

Conclusion: MS-GS框架在稀疏视图和多外观条件下实现了逼真的渲染效果，显著优于现有方法。

Abstract: In-the-wild photo collections often contain limited volumes of imagery and
exhibit multiple appearances, e.g., taken at different times of day or seasons,
posing significant challenges to scene reconstruction and novel view synthesis.
Although recent adaptations of Neural Radiance Field (NeRF) and 3D Gaussian
Splatting (3DGS) have improved in these areas, they tend to oversmooth and are
prone to overfitting. In this paper, we present MS-GS, a novel framework
designed with Multi-appearance capabilities in Sparse-view scenarios using
3DGS. To address the lack of support due to sparse initializations, our
approach is built on the geometric priors elicited from monocular depth
estimations. The key lies in extracting and utilizing local semantic regions
with a Structure-from-Motion (SfM) points anchored algorithm for reliable
alignment and geometry cues. Then, to introduce multi-view constraints, we
propose a series of geometry-guided supervision at virtual views in a
fine-grained and coarse scheme to encourage 3D consistency and reduce
overfitting. We also introduce a dataset and an in-the-wild experiment setting
to set up more realistic benchmarks. We demonstrate that MS-GS achieves
photorealistic renderings under various challenging sparse-view and
multi-appearance conditions and outperforms existing approaches significantly
across different datasets.

</details>


### [37] [Diffusion-Based Cross-Modal Feature Extraction for Multi-Label Classification](https://arxiv.org/abs/2509.15553)
*Tian Lan,Yiming Zheng,Jianxin Yin*

Main category: cs.CV

TL;DR: Diff-Feat是一个利用扩散Transformer模型中间特征的多标签分类框架，通过局部搜索和特征融合实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 多标签分类具有广泛的应用，但依赖于能够捕捉多标签交互的强大表示。Diff-Feat旨在通过利用扩散Transformer模型的中间特征来解决这一问题。

Method: Diff-Feat框架利用预训练的扩散Transformer模型提取图像和文本的中间特征，并通过启发式局部搜索算法找到最优的“图像-文本”×“块-时间步”对，避免全网格搜索。

Result: Diff-Feat在MS-COCO-enhanced上达到98.6% mAP，在Visual Genome 500上达到45.7% mAP，显著超越了CNN、图和Transformer基线方法。

Conclusion: Diff-Feat框架通过提取预训练扩散Transformer模型的中间特征，并在下游任务中融合这些特征，实现了在多标签分类任务中的最先进性能。

Abstract: Multi-label classification has broad applications and depends on powerful
representations capable of capturing multi-label interactions. We introduce
\textit{Diff-Feat}, a simple but powerful framework that extracts intermediate
features from pre-trained diffusion-Transformer models for images and text, and
fuses them for downstream tasks. We observe that for vision tasks, the most
discriminative intermediate feature along the diffusion process occurs at the
middle step and is located in the middle block in Transformer. In contrast, for
language tasks, the best feature occurs at the noise-free step and is located
in the deepest block. In particular, we observe a striking phenomenon across
varying datasets: a mysterious "Layer $12$" consistently yields the best
performance on various downstream classification tasks for images (under
DiT-XL/2-256$\times$256). We devise a heuristic local-search algorithm that
pinpoints the locally optimal "image-text"$\times$"block-timestep" pair among a
few candidates, avoiding an exhaustive grid search. A simple fusion-linear
projection followed by addition-of the selected representations yields
state-of-the-art performance: 98.6\% mAP on MS-COCO-enhanced and 45.7\% mAP on
Visual Genome 500, surpassing strong CNN, graph, and Transformer baselines by a
wide margin. t-SNE and clustering metrics further reveal that
\textit{Diff-Feat} forms tighter semantic clusters than unimodal counterparts.
The code is available at https://github.com/lt-0123/Diff-Feat.

</details>


### [38] [From Development to Deployment of AI-assisted Telehealth and Screening for Vision- and Hearing-threatening diseases in resource-constrained settings: Field Observations, Challenges and Way Forward](https://arxiv.org/abs/2509.15558)
*Mahesh Shakya,Bijay Adhikari,Nirsara Shrestha,Bipin Koirala,Arun Adhikari,Prasanta Poudyal,Luna Mathema,Sarbagya Buddhacharya,Bijay Khatri,Bishesh Khanal*

Main category: cs.CV

TL;DR: 研究探讨了在资源受限环境中AI辅助远程医疗和大规模筛查的挑战与解决方案，强调迭代协作和自动化质量检查的重要性。


<details>
  <summary>Details</summary>
Motivation: 在资源受限环境中，视觉和听力威胁疾病导致可预防的残疾，但缺乏专家和筛查设备，大规模AI辅助筛查和远程医疗有潜力扩大早期检测。

Method: 采用迭代、跨学科协作方法，包括早期原型设计、影子部署和持续反馈。

Result: 发现公共数据集和AI模型尽管因领域转移性能不佳但非常有用，同时需要自动化的AI图像质量检查以确保高容量筛查营的稳健性。

Conclusion: 通过记录实际挑战和经验教训，旨在填补在资源受限环境中构建真实世界AI辅助远程医疗和大规模筛查项目的背景化、可操作知识空白。

Abstract: Vision- and hearing-threatening diseases cause preventable disability,
especially in resource-constrained settings(RCS) with few specialists and
limited screening setup. Large scale AI-assisted screening and telehealth has
potential to expand early detection, but practical deployment is challenging in
paper-based workflows and limited documented field experience exist to build
upon. We provide insights on challenges and ways forward in development to
adoption of scalable AI-assisted Telehealth and screening in such settings.
Specifically, we find that iterative, interdisciplinary collaboration through
early prototyping, shadow deployment and continuous feedback is important to
build shared understanding as well as reduce usability hurdles when
transitioning from paper-based to AI-ready workflows. We find public datasets
and AI models highly useful despite poor performance due to domain shift. In
addition, we find the need for automated AI-based image quality check to
capture gradable images for robust screening in high-volume camps.
  Our field learning stress the importance of treating AI development and
workflow digitization as an end-to-end, iterative co-design process. By
documenting these practical challenges and lessons learned, we aim to address
the gap in contextual, actionable field knowledge for building real-world
AI-assisted telehealth and mass-screening programs in RCS.

</details>


### [39] [BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent](https://arxiv.org/abs/2509.15566)
*Shaojie Zhang,Ruoceng Zhang,Pei Fu,Shaokang Wang,Jiahui Yang,Xin Du,Shiqi Cui,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: BTL框架模仿人类认知过程，通过三个阶段和两项技术创新，显著提升GUI代理性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI驱动的GUI交互逻辑与人类自然交互模式存在显著偏差，需要一种更接近人类认知过程的框架。

Method: 提出了'Blink-Think-Link'（BTL）框架，包含三个生物启发阶段：快速检测（Blink）、高级推理（Think）和生成可执行命令（Link）。并引入了两项关键技术：自动标注管道（Blink Data Generation）和基于规则的奖励机制（BTL Reward）。

Result: 开发的BTL-UI代理在静态GUI理解和动态交互任务中均表现出最先进的性能。

Conclusion: BTL框架通过模拟人类认知过程，显著提升了GUI代理的性能，实证验证了其在开发高级GUI代理中的有效性。

Abstract: In the field of AI-driven human-GUI interaction automation, while rapid
advances in multimodal large language models and reinforcement fine-tuning
techniques have yielded remarkable progress, a fundamental challenge persists:
their interaction logic significantly deviates from natural human-GUI
communication patterns. To fill this gap, we propose "Blink-Think-Link" (BTL),
a brain-inspired framework for human-GUI interaction that mimics the human
cognitive process between users and graphical interfaces. The system decomposes
interactions into three biologically plausible phases: (1) Blink - rapid
detection and attention to relevant screen areas, analogous to saccadic eye
movements; (2) Think - higher-level reasoning and decision-making, mirroring
cognitive planning; and (3) Link - generation of executable commands for
precise motor control, emulating human action selection mechanisms.
Additionally, we introduce two key technical innovations for the BTL framework:
(1) Blink Data Generation - an automated annotation pipeline specifically
optimized for blink data, and (2) BTL Reward -- the first rule-based reward
mechanism that enables reinforcement learning driven by both process and
outcome. Building upon this framework, we develop a GUI agent model named
BTL-UI, which demonstrates consistent state-of-the-art performance across both
static GUI understanding and dynamic interaction tasks in comprehensive
benchmarks. These results provide conclusive empirical validation of the
framework's efficacy in developing advanced GUI Agents.

</details>


### [40] [DC-Mamba: Bi-temporal deformable alignment and scale-sparse enhancement for remote sensing change detection](https://arxiv.org/abs/2509.15563)
*Min Sun,Fenghui Guo*

Main category: cs.CV

TL;DR: DC-Mamba通过BTDA和SSCA模块解决了遥感变化检测中的几何错位和噪声问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法（包括最先进的SSMs）缺乏明确的几何错位处理机制，且难以区分细微的真实变化与噪声，因此需要一种更鲁棒的解决方案。

Method: DC-Mamba基于ChangeMamba主干，集成了两个轻量级模块：Bi-Temporal Deformable Alignment (BTDA)用于语义特征级别的几何对齐，Scale-Sparse Change Amplifier (SSCA)通过多源线索选择性增强高置信度变化信号并抑制噪声。

Result: 实验表明，DC-Mamba显著优于ChangeMamba基线，F1-score从0.5730提升至0.5903，IoU从0.4015提升至0.4187。

Conclusion: DC-Mamba框架通过'先对齐后增强'的策略有效解决了遥感变化检测中的几何错位和噪声问题，显著提升了性能指标（F1-score和IoU），为RSCD提供了鲁棒且易部署的解决方案。

Abstract: Remote sensing change detection (RSCD) is vital for identifying land-cover
changes, yet existing methods, including state-of-the-art State Space Models
(SSMs), often lack explicit mechanisms to handle geometric misalignments and
struggle to distinguish subtle, true changes from noise.To address this, we
introduce DC-Mamba, an "align-then-enhance" framework built upon the
ChangeMamba backbone. It integrates two lightweight, plug-and-play modules: (1)
Bi-Temporal Deformable Alignment (BTDA), which explicitly introduces geometric
awareness to correct spatial misalignments at the semantic feature level; and
(2) a Scale-Sparse Change Amplifier(SSCA), which uses multi-source cues to
selectively amplify high-confidence change signals while suppressing noise
before the final classification. This synergistic design first establishes
geometric consistency with BTDA to reduce pseudo-changes, then leverages SSCA
to sharpen boundaries and enhance the visibility of small or subtle targets.
Experiments show our method significantly improves performance over the strong
ChangeMamba baseline, increasing the F1-score from 0.5730 to 0.5903 and IoU
from 0.4015 to 0.4187. The results confirm the effectiveness of our
"align-then-enhance" strategy, offering a robust and easily deployable solution
that transparently addresses both geometric and feature-level challenges in
RSCD.

</details>


### [41] [Towards Size-invariant Salient Object Detection: A Generic Evaluation and Optimization Approach](https://arxiv.org/abs/2509.15573)
*Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 本文揭示了SOD评估中的尺寸敏感性问题，提出了尺寸不变的评估和优化框架（SIEva和SIOpt），并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有显著目标检测（SOD）评估协议在多个尺寸差异显著的显著对象存在时存在尺寸敏感性问题，导致评估偏差。

Method: 通过理论推导揭示现有SOD指标的尺寸敏感性，提出SIEva框架单独评估各可分离组件并聚合结果，进一步开发SIOpt优化框架。

Result: 提出的SIEva和SIOpt框架显著提高了不同尺寸显著对象的检测性能，且与多种SOD主干网络兼容。

Conclusion: 本文提出了一种通用的尺寸不变评估框架（SIEva）和专用优化框架（SIOpt），有效解决了显著目标检测中尺寸敏感性问题，并通过理论和实验验证了其有效性。

Abstract: This paper investigates a fundamental yet underexplored issue in Salient
Object Detection (SOD): the size-invariant property for evaluation protocols,
particularly in scenarios when multiple salient objects of significantly
different sizes appear within a single image. We first present a novel
perspective to expose the inherent size sensitivity of existing widely used SOD
metrics. Through careful theoretical derivations, we show that the evaluation
outcome of an image under current SOD metrics can be essentially decomposed
into a sum of several separable terms, with the contribution of each term being
directly proportional to its corresponding region size. Consequently, the
prediction errors would be dominated by the larger regions, while smaller yet
potentially more semantically important objects are often overlooked, leading
to biased performance assessments and practical degradation. To address this
challenge, a generic Size-Invariant Evaluation (SIEva) framework is proposed.
The core idea is to evaluate each separable component individually and then
aggregate the results, thereby effectively mitigating the impact of size
imbalance across objects. Building upon this, we further develop a dedicated
optimization framework (SIOpt), which adheres to the size-invariant principle
and significantly enhances the detection of salient objects across a broad
range of sizes. Notably, SIOpt is model-agnostic and can be seamlessly
integrated with a wide range of SOD backbones. Theoretically, we also present
generalization analysis of SOD methods and provide evidence supporting the
validity of our new evaluation protocols. Finally, comprehensive experiments
speak to the efficacy of our proposed approach. The code is available at
https://github.com/Ferry-Li/SI-SOD.

</details>


### [42] [Multimodal Learning for Fake News Detection in Short Videos Using Linguistically Verified Data and Heterogeneous Modality Fusion](https://arxiv.org/abs/2509.15578)
*Shanghong Li,Chiam Wen Qi Ruth,Hong Xu,Fang Liu*

Main category: cs.CV

TL;DR: HFN, a novel multimodal framework, effectively detects fake news in short videos by dynamically integrating video, audio, and text data, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: The rapid proliferation of short video platforms and the ease of sharing misinformation necessitate advanced methods to detect fake news, given its potential societal harm.

Method: HFN integrates video, audio, and text data through a Decision Network and a Weighted Multi-Modal Feature Fusion module, dynamically adjusting modality weights for robust performance.

Result: Experiments show improvements of 2.71% and 4.14% in Marco F1 over state-of-the-art methods on FakeTT and VESV datasets.

Conclusion: HFN establishes a robust solution for detecting fake news in short videos, offering a significant improvement over existing methods and paving the way for more reliable misinformation detection.

Abstract: The rapid proliferation of short video platforms has necessitated advanced
methods for detecting fake news. This need arises from the widespread influence
and ease of sharing misinformation, which can lead to significant societal
harm. Current methods often struggle with the dynamic and multimodal nature of
short video content. This paper presents HFN, Heterogeneous Fusion Net, a novel
multimodal framework that integrates video, audio, and text data to evaluate
the authenticity of short video content. HFN introduces a Decision Network that
dynamically adjusts modality weights during inference and a Weighted
Multi-Modal Feature Fusion module to ensure robust performance even with
incomplete data. Additionally, we contribute a comprehensive dataset VESV
(VEracity on Short Videos) specifically designed for short video fake news
detection. Experiments conducted on the FakeTT and newly collected VESV
datasets demonstrate improvements of 2.71% and 4.14% in Marco F1 over
state-of-the-art methods. This work establishes a robust solution capable of
effectively identifying fake news in the complex landscape of short video
platforms, paving the way for more reliable and comprehensive approaches in
combating misinformation.

</details>


### [43] [Saccadic Vision for Fine-Grained Visual Classification](https://arxiv.org/abs/2509.15688)
*Johann Schmidt,Sebastian Stober,Joachim Denzler,Paul Bodesheim*

Main category: cs.CV

TL;DR: 提出一种受人类视觉启发的两阶段细粒度分类方法，通过外围特征提取和注视补丁编码，结合选择性注意力，有效减少冗余并提升性能。


<details>
  <summary>Details</summary>
Motivation: 细粒度视觉分类任务因类内差异大、类间差异小而具有挑战性。现有基于部位的方法依赖复杂的定位网络，限制了特征的实用性，且采样点存在空间冗余问题。

Method: 受人类扫视视觉启发，提出两阶段方法：先提取外围特征（粗视图）并生成采样图，再通过权重共享编码器并行编码采样到的注视补丁。使用上下文选择性注意力加权每个注视补丁的影响，最后融合外围和聚焦表示。

Result: 在标准FGVC基准（CUB-200-2011、NABirds、Food-101、Stanford-Dogs）和挑战性昆虫数据集（EU-Moths、Ecuador-Moths、AMI-Moths）上验证，方法性能与最先进方法相当且优于基线。

Conclusion: 提出的两阶段方法在细粒度视觉分类任务中表现出色，与现有方法性能相当且优于基线编码器。

Abstract: Fine-grained visual classification (FGVC) requires distinguishing between
visually similar categories through subtle, localized features - a task that
remains challenging due to high intra-class variability and limited inter-class
differences. Existing part-based methods often rely on complex localization
networks that learn mappings from pixel to sample space, requiring a deep
understanding of image content while limiting feature utility for downstream
tasks. In addition, sampled points frequently suffer from high spatial
redundancy, making it difficult to quantify the optimal number of required
parts. Inspired by human saccadic vision, we propose a two-stage process that
first extracts peripheral features (coarse view) and generates a sample map,
from which fixation patches are sampled and encoded in parallel using a
weight-shared encoder. We employ contextualized selective attention to weigh
the impact of each fixation patch before fusing peripheral and focus
representations. To prevent spatial collapse - a common issue in part-based
methods - we utilize non-maximum suppression during fixation sampling to
eliminate redundancy. Comprehensive evaluation on standard FGVC benchmarks
(CUB-200-2011, NABirds, Food-101 and Stanford-Dogs) and challenging insect
datasets (EU-Moths, Ecuador-Moths and AMI-Moths) demonstrates that our method
achieves comparable performance to state-of-the-art approaches while
consistently outperforming our baseline encoder.

</details>


### [44] [EyePCR: A Comprehensive Benchmark for Fine-Grained Perception, Knowledge Comprehension and Clinical Reasoning in Ophthalmic Surgery](https://arxiv.org/abs/2509.15596)
*Gui Wang,Yang Wennuo,Xusen Ma,Zehao Zhong,Zhuoru Wu,Ende Wu,Rong Qu,Wooi Ping Cheah,Jianfeng Ren,Linlin Shen*

Main category: cs.CV

TL;DR: 开发了EyePCR基准，评估MLLMs在眼科手术中的认知能力，其适配模型在感知、理解和推理任务中表现优异，揭示了现有模型的局限性并为未来研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在高风险、特定领域场景（如外科手术）中的性能尚未充分探索，需填补这一空白。

Method: 开发了EyePCR，一个基于结构化临床知识的大规模眼科手术分析基准，包含超过210k的视觉问答（VQA）、1048个细粒度属性、25k医学知识图谱三元组及四项临床推理任务。

Result: EyePCR-MLLM（基于Qwen2.5-VL-7B的领域适配变体）在感知多选题中准确性最高，在理解和推理任务上优于开源模型，媲美GPT-4.1等商业模型。

Conclusion: EyePCR揭示了现有MLLMs在外科认知中的局限性，并为评估和增强外科视频理解模型的临床可靠性奠定了基础。

Abstract: MLLMs (Multimodal Large Language Models) have showcased remarkable
capabilities, but their performance in high-stakes, domain-specific scenarios
like surgical settings, remains largely under-explored. To address this gap, we
develop \textbf{EyePCR}, a large-scale benchmark for ophthalmic surgery
analysis, grounded in structured clinical knowledge to evaluate cognition
across \textit{Perception}, \textit{Comprehension} and \textit{Reasoning}.
EyePCR offers a richly annotated corpus with more than 210k VQAs, which cover
1048 fine-grained attributes for multi-view perception, medical knowledge graph
of more than 25k triplets for comprehension, and four clinically grounded
reasoning tasks. The rich annotations facilitate in-depth cognitive analysis,
simulating how surgeons perceive visual cues and combine them with domain
knowledge to make decisions, thus greatly improving models' cognitive ability.
In particular, \textbf{EyePCR-MLLM}, a domain-adapted variant of Qwen2.5-VL-7B,
achieves the highest accuracy on MCQs for \textit{Perception} among compared
models and outperforms open-source models in \textit{Comprehension} and
\textit{Reasoning}, rivalling commercial models like GPT-4.1. EyePCR reveals
the limitations of existing MLLMs in surgical cognition and lays the foundation
for benchmarking and enhancing clinical reliability of surgical video
understanding models.

</details>


### [45] [SGMAGNet: A Baseline Model for 3D Cloud Phase Structure Reconstruction on a New Passive Active Satellite Benchmark](https://arxiv.org/abs/2509.15706)
*Chi Yang,Fu Wang,Xiaofei Yang,Hao Huang,Weijia Cao,Xiaowen Chu*

Main category: cs.CV

TL;DR: 本研究提出了一种基于多模态卫星观测的云相态剖面重建方法，SGMAGNet在复杂场景中表现最佳，显著提升了云相态重建的准确性。


<details>
  <summary>Details</summary>
Motivation: 云相态剖面对于数值天气预报至关重要，直接影响辐射传输和降水过程。本研究旨在通过多模态卫星观测转化为详细的3D云相态结构，以改进云微物理参数化。

Method: 采用SGMAGNet作为主要模型，并与UNet变体和SegNet等基线架构进行比较，所有模型均设计用于捕捉多尺度空间模式。

Result: SGMAGNet在精确度、召回率、F1分数和IoU等关键指标上均优于基线模型，具体表现为精确度0.922、召回率0.858、F1分数0.763和IoU 0.617。

Conclusion: SGMAGNet在云相态重建中表现出色，尤其在复杂的多层和边界过渡区域，显著优于其他基线模型。

Abstract: Cloud phase profiles are critical for numerical weather prediction (NWP), as
they directly affect radiative transfer and precipitation processes. In this
study, we present a benchmark dataset and a baseline framework for transforming
multimodal satellite observations into detailed 3D cloud phase structures,
aiming toward operational cloud phase profile retrieval and future integration
with NWP systems to improve cloud microphysics parameterization. The multimodal
observations consist of (1) high--spatiotemporal--resolution, multi-band
visible (VIS) and thermal infrared (TIR) imagery from geostationary satellites,
and (2) accurate vertical cloud phase profiles from spaceborne lidar
(CALIOP\slash CALIPSO) and radar (CPR\slash CloudSat). The dataset consists of
synchronized image--profile pairs across diverse cloud regimes, defining a
supervised learning task: given VIS/TIR patches, predict the corresponding 3D
cloud phase structure. We adopt SGMAGNet as the main model and compare it with
several baseline architectures, including UNet variants and SegNet, all
designed to capture multi-scale spatial patterns. Model performance is
evaluated using standard classification metrics, including Precision, Recall,
F1-score, and IoU. The results demonstrate that SGMAGNet achieves superior
performance in cloud phase reconstruction, particularly in complex multi-layer
and boundary transition regions. Quantitatively, SGMAGNet attains a Precision
of 0.922, Recall of 0.858, F1-score of 0.763, and an IoU of 0.617,
significantly outperforming all baselines across these key metrics.

</details>


### [46] [TennisTV: Do Multimodal Large Language Models Understand Tennis Rallies?](https://arxiv.org/abs/2509.15602)
*Zhongyuan Bao,Lejun Zhang*

Main category: cs.CV

TL;DR: 研究提出了首个网球视频理解基准TennisTV，评估了16种多模态大语言模型，发现其在快速、高频体育视频中的不足，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在通用视频理解中表现优异，但在快速、高频的体育视频（如网球）中表现不佳，因此需要系统性评估和改进。

Method: 通过TennisTV基准测试，将每个网球回合建模为时间顺序的连续击球事件序列，并利用自动化管道进行过滤和问题生成。

Result: 评估了16种代表性多模态大语言模型，揭示了其在网球视频理解中的主要不足，并提出了帧采样密度和时序定位的改进方向。

Conclusion: 研究发现，现有的多模态大语言模型在快速、高频的体育视频理解（如网球）中存在显著不足，特别是在帧采样密度和时序定位方面需要改进。

Abstract: Multimodal large language models (MLLMs) excel at general video understanding
but struggle with fast, high-frequency sports like tennis, where rally clips
are short yet information-dense. To systematically evaluate MLLMs in this
challenging domain, we present TennisTV, the first and most comprehensive
benchmark for tennis video understanding. TennisTV models each rally as a
temporal-ordered sequence of consecutive stroke events, using automated
pipelines for filtering and question generation. It covers 8 tasks at rally and
stroke levels and includes 2,500 human-verified questions. Evaluating 16
representative MLLMs, we provide the first systematic assessment of tennis
video understanding. Results reveal substantial shortcomings and yield two key
insights: (i) frame-sampling density should be tailored and balanced across
tasks, and (ii) improving temporal grounding is essential for stronger
reasoning.

</details>


### [47] [Enhancing WSI-Based Survival Analysis with Report-Auxiliary Self-Distillation](https://arxiv.org/abs/2509.15608)
*Zheng Wang,Hong Liu,Zheng Wang,Danyi Li,Min Cen,Baptiste Magnier,Li Liang,Liansheng Wang*

Main category: cs.CV

TL;DR: 提出Rasa框架，结合病理报告和WSI数据，通过LLMs提取文本描述、自蒸馏管道和风险感知mix-up策略，提升生存分析性能。


<details>
  <summary>Details</summary>
Motivation: 传统WSI生存分析存在噪声特征和数据访问限制问题，病理报告虽富含信息但未被充分利用。

Method: 利用大型语言模型（LLMs）提取病理报告中的细粒度文本描述，设计自蒸馏管道过滤无关特征，并引入风险感知mix-up策略增加训练数据的数量和多样性。

Result: 在CRC和TCGA-BRCA数据集上的实验表明，Rasa框架优于现有方法。

Conclusion: Rasa框架通过结合病理报告和WSI数据，显著提升了基于WSI的生存分析性能，实验证明其在CRC和TCGA-BRCA数据集上优于现有方法。

Abstract: Survival analysis based on Whole Slide Images (WSIs) is crucial for
evaluating cancer prognosis, as they offer detailed microscopic information
essential for predicting patient outcomes. However, traditional WSI-based
survival analysis usually faces noisy features and limited data accessibility,
hindering their ability to capture critical prognostic features effectively.
Although pathology reports provide rich patient-specific information that could
assist analysis, their potential to enhance WSI-based survival analysis remains
largely unexplored. To this end, this paper proposes a novel Report-auxiliary
self-distillation (Rasa) framework for WSI-based survival analysis. First,
advanced large language models (LLMs) are utilized to extract fine-grained,
WSI-relevant textual descriptions from original noisy pathology reports via a
carefully designed task prompt. Next, a self-distillation-based pipeline is
designed to filter out irrelevant or redundant WSI features for the student
model under the guidance of the teacher model's textual knowledge. Finally, a
risk-aware mix-up strategy is incorporated during the training of the student
model to enhance both the quantity and diversity of the training data.
Extensive experiments carried out on our collected data (CRC) and public data
(TCGA-BRCA) demonstrate the superior effectiveness of Rasa against
state-of-the-art methods. Our code is available at
https://github.com/zhengwang9/Rasa.

</details>


### [48] [FloorSAM: SAM-Guided Floorplan Reconstruction with Semantic-Geometric Fusion](https://arxiv.org/abs/2509.15750)
*Han Ye,Haofu Wang,Yunchi Zhang,Jiangjian Xiao,Yuqiang Jin,Jinyuan Liu,Wen-An Zhang,Uladzislau Sychou,Alexander Tuzikov,Vladislav Sobolevskii,Valerii Zakharov,Boris Sokolov,Minglei Fu*

Main category: cs.CV

TL;DR: FloorSAM结合点云密度图和SAM，通过零样本学习和自适应处理，显著提升了建筑平面图重建的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 从点云数据重建建筑平面图对于室内导航、BIM和精确测量至关重要，但传统方法如几何算法和基于Mask R-CNN的深度学习方法常面临噪声、泛化能力有限和几何细节丢失的问题。

Method: FloorSAM通过网格过滤、自适应分辨率投影和图像增强创建鲁棒的顶部密度图，利用SAM的零样本学习进行精确房间分割，并通过自适应提示点和多阶段过滤生成房间掩码，最后进行联合掩码和点云分析以提取和正则化轮廓。

Result: FloorSAM在LiDAR数据上实现了准确的平面图重建，恢复了房间拓扑关系，并在测试中展示了优于传统方法的性能。

Conclusion: FloorSAM框架在Giblayout和ISPRS数据集上表现出优于传统方法的准确性、召回率和鲁棒性，特别是在噪声和复杂环境中。

Abstract: Reconstructing building floor plans from point cloud data is key for indoor
navigation, BIM, and precise measurements. Traditional methods like geometric
algorithms and Mask R-CNN-based deep learning often face issues with noise,
limited generalization, and loss of geometric details. We propose FloorSAM, a
framework that integrates point cloud density maps with the Segment Anything
Model (SAM) for accurate floor plan reconstruction from LiDAR data. Using
grid-based filtering, adaptive resolution projection, and image enhancement, we
create robust top-down density maps. FloorSAM uses SAM's zero-shot learning for
precise room segmentation, improving reconstruction across diverse layouts.
Room masks are generated via adaptive prompt points and multistage filtering,
followed by joint mask and point cloud analysis for contour extraction and
regularization. This produces accurate floor plans and recovers room
topological relationships. Tests on Giblayout and ISPRS datasets show better
accuracy, recall, and robustness than traditional methods, especially in noisy
and complex settings. Code and materials: github.com/Silentbarber/FloorSAM.

</details>


### [49] [PCSR: Pseudo-label Consistency-Guided Sample Refinement for Noisy Correspondence Learning](https://arxiv.org/abs/2509.15623)
*Zhuoyao Liu,Yang Liu,Wentao Feng,Shudong Huang*

Main category: cs.CV

TL;DR: PCSR框架通过伪标签一致性细化噪声样本，提升跨模态检索在噪声数据下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法常假设图像-文本对完美对齐，忽略了真实数据中的噪声对应，导致相似性学习偏差和检索性能下降。

Method: 提出PCSR框架，包括基于置信度的样本划分、伪标签一致性细化及自适应对优化（APO）。

Result: 在CC152K、MS-COCO和Flickr30K数据集上的实验验证了方法的有效性。

Conclusion: PCSR框架通过伪标签一致性增强样本可靠性，显著提升了在噪声监督下的跨模态检索鲁棒性。

Abstract: Cross-modal retrieval aims to align different modalities via semantic
similarity. However, existing methods often assume that image-text pairs are
perfectly aligned, overlooking Noisy Correspondences in real data. These
misaligned pairs misguide similarity learning and degrade retrieval
performance. Previous methods often rely on coarse-grained categorizations that
simply divide data into clean and noisy samples, overlooking the intrinsic
diversity within noisy instances. Moreover, they typically apply uniform
training strategies regardless of sample characteristics, resulting in
suboptimal sample utilization for model optimization. To address the above
challenges, we introduce a novel framework, called Pseudo-label
Consistency-Guided Sample Refinement (PCSR), which enhances correspondence
reliability by explicitly dividing samples based on pseudo-label consistency.
Specifically, we first employ a confidence-based estimation to distinguish
clean and noisy pairs, then refine the noisy pairs via pseudo-label consistency
to uncover structurally distinct subsets. We further proposed a Pseudo-label
Consistency Score (PCS) to quantify prediction stability, enabling the
separation of ambiguous and refinable samples within noisy pairs. Accordingly,
we adopt Adaptive Pair Optimization (APO), where ambiguous samples are
optimized with robust loss functions and refinable ones are enhanced via text
replacement during training. Extensive experiments on CC152K, MS-COCO and
Flickr30K validate the effectiveness of our method in improving retrieval
robustness under noisy supervision.

</details>


### [50] [Ideal Registration? Segmentation is All You Need](https://arxiv.org/abs/2509.15784)
*Xiang Chen,Fengting Zhang,Qinghao Liu,Min Liu,Kun Wu,Yaonan Wang,Hang Zhang*

Main category: cs.CV

TL;DR: SegReg是一种分割驱动的配准框架，通过自适应正则化处理复杂变形，显著提高配准精度。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在图像配准中常使用全局统一的平滑约束，无法适应解剖运动中复杂且区域变化的变形。

Method: SegReg首先将移动和固定图像分割为解剖学上一致的子区域，然后通过相同的配准骨干网络计算优化的局部变形场，最后整合为全局变形场。

Result: SegReg在使用真实分割时达到98.23%的Dice分数，在三种临床场景（心脏、腹部和肺部图像）中优于现有方法2-12%。

Conclusion: SegReg通过分割驱动的自适应正则化方法，显著提高了图像配准的精度，尤其是在处理复杂解剖结构时表现出色。

Abstract: Deep learning has revolutionized image registration by its ability to handle
diverse tasks while achieving significant speed advantages over conventional
approaches. Current approaches, however, often employ globally uniform
smoothness constraints that fail to accommodate the complex, regionally varying
deformations characteristic of anatomical motion. To address this limitation,
we propose SegReg, a Segmentation-driven Registration framework that implements
anatomically adaptive regularization by exploiting region-specific deformation
patterns. Our SegReg first decomposes input moving and fixed images into
anatomically coherent subregions through segmentation. These localized domains
are then processed by the same registration backbone to compute optimized
partial deformation fields, which are subsequently integrated into a global
deformation field. SegReg achieves near-perfect structural alignment (98.23%
Dice on critical anatomies) using ground-truth segmentation, and outperforms
existing methods by 2-12% across three clinical registration scenarios
(cardiac, abdominal, and lung images) even with automatic segmentation. Our
SegReg demonstrates a near-linear dependence of registration accuracy on
segmentation quality, transforming the registration challenge into a
segmentation problem. The source code will be released upon manuscript
acceptance.

</details>


### [51] [CoPAD : Multi-source Trajectory Fusion and Cooperative Trajectory Prediction with Anchor-oriented Decoder in V2X Scenarios](https://arxiv.org/abs/2509.15984)
*Kangyu Wu,Jiaqi Qiao,Ya Zhang*

Main category: cs.CV

TL;DR: CoPAD是一个轻量级协同轨迹预测框架，通过多模块融合和多源数据早期融合，显著提升了预测性能。


<details>
  <summary>Details</summary>
Motivation: 单车辆感知的不稳定性对轨迹预测存在限制，因此需要一种多源轨迹数据融合的方法来提高预测的完整性和准确性。

Method: 提出了一个轻量级框架CoPAD，包含基于匈牙利算法和卡尔曼滤波的融合模块、历史轨迹注意力模块（PTA）、模式注意力模块和锚点导向解码器（AoD）。

Result: 在DAIR-V2X-Seq数据集上实现了最先进的性能。

Conclusion: CoPAD框架在V2X场景下的协同轨迹预测中表现出色，验证了模型的有效性。

Abstract: Recently, data-driven trajectory prediction methods have achieved remarkable
results, significantly advancing the development of autonomous driving.
However, the instability of single-vehicle perception introduces certain
limitations to trajectory prediction. In this paper, a novel lightweight
framework for cooperative trajectory prediction, CoPAD, is proposed. This
framework incorporates a fusion module based on the Hungarian algorithm and
Kalman filtering, along with the Past Time Attention (PTA) module, mode
attention module and anchor-oriented decoder (AoD). It effectively performs
early fusion on multi-source trajectory data from vehicles and road
infrastructure, enabling the trajectories with high completeness and accuracy.
The PTA module can efficiently capture potential interaction information among
historical trajectories, and the mode attention module is proposed to enrich
the diversity of predictions. Additionally, the decoder based on sparse anchors
is designed to generate the final complete trajectories. Extensive experiments
show that CoPAD achieves the state-of-the-art performance on the DAIR-V2X-Seq
dataset, validating the effectiveness of the model in cooperative trajectory
prediction in V2X scenarios.

</details>


### [52] [pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation](https://arxiv.org/abs/2509.15638)
*Tong Wang,Xingyue Zhao,Linghao Zhuang,Haoyu Zhao,Jiayi Yin,Yuyang He,Gang Yu,Bo Lin*

Main category: cs.CV

TL;DR: 首个针对医学图像分割异构数据场景的个性化联邦SAM框架，通过个性化策略和全局-局部解耦微调机制，显著提升性能并减少通信开销。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割对计算机辅助诊断至关重要，但隐私限制阻碍了跨机构数据共享。联邦学习虽能解决这一限制，但现有方法通常依赖于轻量级架构，难以处理复杂异构数据。Segment Anything Model（SAM）在分割方面表现出色，但其庞大编码器在联邦设置中带来挑战。

Method: 该框架整合了个性化策略和全局-局部解耦微调机制。个性化策略通过聚合全局参数捕获跨客户端共性，同时保留设计的L-MoE组件以保护领域特定特征；全局-局部微调机制通过知识蒸馏的教师-学生范式弥合全局共享模型与个性化局部模型之间的差距。

Result: 在两个公共数据集上的广泛实验验证了该方法的有效性，显著提升了分割性能，实现了强大的跨域适应性，并减少了通信开销。

Conclusion: 该研究提出了首个针对医学图像分割中异构数据场景的个性化联邦SAM框架，通过两种关键创新显著提升了分割性能，实现了强大的跨域适应性，并减少了通信开销。

Abstract: Medical image segmentation is crucial for computer-aided diagnosis, yet
privacy constraints hinder data sharing across institutions. Federated learning
addresses this limitation, but existing approaches often rely on lightweight
architectures that struggle with complex, heterogeneous data. Recently, the
Segment Anything Model (SAM) has shown outstanding segmentation capabilities;
however, its massive encoder poses significant challenges in federated
settings. In this work, we present the first personalized federated SAM
framework tailored for heterogeneous data scenarios in medical image
segmentation. Our framework integrates two key innovations: (1) a personalized
strategy that aggregates only the global parameters to capture cross-client
commonalities while retaining the designed L-MoE (Localized Mixture-of-Experts)
component to preserve domain-specific features; and (2) a decoupled
global-local fine-tuning mechanism that leverages a teacher-student paradigm
via knowledge distillation to bridge the gap between the global shared model
and the personalized local models, thereby mitigating overgeneralization.
Extensive experiments on two public datasets validate that our approach
significantly improves segmentation performance, achieves robust cross-domain
adaptation, and reduces communication overhead.

</details>


### [53] [CBPNet: A Continual Backpropagation Prompt Network for Alleviating Plasticity Loss on Edge Devices](https://arxiv.org/abs/2509.15785)
*Runjie Shao,Boyu Diao,Zijia An,Ruiqi Liu,Yongjun Xu*

Main category: cs.CV

TL;DR: CBPNet通过自适应重新初始化未充分利用参数，有效解决了持续学习中的塑性损失，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 针对边缘设备上持续学习中的塑性损失问题，即模型因冻结主干和提示参数容量有限而学习新知识能力下降的现象。

Method: 提出了Continual Backpropagation Prompt Network (CBPNet)，通过自适应重新初始化未充分利用的参数来恢复模型的学习活力。

Result: 在Split CIFAR-100上平均准确率提升超过1%，在更具挑战性的Split ImageNet-R上达到69.41%的最先进准确率。

Conclusion: CBPNet通过创新的高效CBP块有效解决了持续学习中的塑性损失问题，显著提升了模型在边缘设备上的性能表现。

Abstract: To meet the demands of applications like robotics and autonomous driving that
require real-time responses to dynamic environments, efficient continual
learning methods suitable for edge devices have attracted increasing attention.
In this transition, using frozen pretrained models with prompts has become a
mainstream strategy to combat catastrophic forgetting. However, this approach
introduces a new critical bottleneck: plasticity loss, where the model's
ability to learn new knowledge diminishes due to the frozen backbone and the
limited capacity of prompt parameters. We argue that the reduction in
plasticity stems from a lack of update vitality in underutilized parameters
during the training process. To this end, we propose the Continual
Backpropagation Prompt Network (CBPNet), an effective and parameter efficient
framework designed to restore the model's learning vitality. We innovatively
integrate an Efficient CBP Block that counteracts plasticity decay by
adaptively reinitializing these underutilized parameters. Experimental results
on edge devices demonstrate CBPNet's effectiveness across multiple benchmarks.
On Split CIFAR-100, it improves average accuracy by over 1% against a strong
baseline, and on the more challenging Split ImageNet-R, it achieves a state of
the art accuracy of 69.41%. This is accomplished by training additional
parameters that constitute less than 0.2% of the backbone's size, validating
our approach.

</details>


### [54] [Towards Sharper Object Boundaries in Self-Supervised Depth Estimation](https://arxiv.org/abs/2509.15987)
*Aurélien Cecille,Stefan Duffner,Franck Davoine,Rémi Agier,Thibault Neveu*

Main category: cs.CV

TL;DR: 自监督混合分布模型提升单目深度估计边界锐度，实验显示35%的改进。


<details>
  <summary>Details</summary>
Motivation: 现有方法在物体边界处的深度估计往往模糊，引入虚假的3D点，需要精细监督。本文旨在通过自监督实现清晰的深度不连续性。

Method: 采用混合分布模型对每个像素的深度进行建模，通过方差感知损失函数和不确定性传播无缝集成到现有流程中。

Result: 在KITTI和VKITTIv2数据集上的评估显示，该方法边界锐度提升高达35%，点云质量优于现有基线。

Conclusion: 该方法通过自监督学习实现了深度估计中的清晰边界，显著提升了边界锐度和点云质量。

Abstract: Accurate monocular depth estimation is crucial for 3D scene understanding,
but existing methods often blur depth at object boundaries, introducing
spurious intermediate 3D points. While achieving sharp edges usually requires
very fine-grained supervision, our method produces crisp depth discontinuities
using only self-supervision. Specifically, we model per-pixel depth as a
mixture distribution, capturing multiple plausible depths and shifting
uncertainty from direct regression to the mixture weights. This formulation
integrates seamlessly into existing pipelines via variance-aware loss functions
and uncertainty propagation. Extensive evaluations on KITTI and VKITTIv2 show
that our method achieves up to 35% higher boundary sharpness and improves point
cloud quality compared to state-of-the-art baselines.

</details>


### [55] [UNIV: Unified Foundation Model for Infrared and Visible Modalities](https://arxiv.org/abs/2509.15642)
*Fangyuan Mao,Shuo Wang,Jilin Mei,Chen Min,Shun Lu,Fuyang Liu,Yu Hu*

Main category: cs.CV

TL;DR: 提出UNIV模型，通过生物启发设计实现跨模态学习，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决RGB和红外数据预训练模型在跨模态场景中表现不佳的问题。

Method: 提出了Patch-wise Cross-modality Contrastive Learning (PCCL)和双知识保留机制，结合LoRA适配器和同步蒸馏。

Result: 在红外任务中性能显著提升（语义分割+1.7 mIoU，目标检测+0.7 mAP），同时RGB任务性能保持在99%以上。

Conclusion: UNIV模型通过生物启发的创新设计，在红外和可见光模态任务中表现出色，同时保持RGB任务的性能。

Abstract: The demand for joint RGB-visible and infrared perception is growing rapidly,
particularly to achieve robust performance under diverse weather conditions.
Although pre-trained models for RGB-visible and infrared data excel in their
respective domains, they often underperform in multimodal scenarios, such as
autonomous vehicles equipped with both sensors. To address this challenge, we
propose a biologically inspired UNified foundation model for Infrared and
Visible modalities (UNIV), featuring two key innovations. First, we introduce
Patch-wise Cross-modality Contrastive Learning (PCCL), an attention-guided
distillation framework that mimics retinal horizontal cells' lateral
inhibition, which enables effective cross-modal feature alignment while
remaining compatible with any transformer-based architecture. Second, our
dual-knowledge preservation mechanism emulates the retina's bipolar cell signal
routing - combining LoRA adapters (2% added parameters) with synchronous
distillation to prevent catastrophic forgetting, thereby replicating the
retina's photopic (cone-driven) and scotopic (rod-driven) functionality. To
support cross-modal learning, we introduce the MVIP dataset, the most
comprehensive visible-infrared benchmark to date. It contains 98,992 precisely
aligned image pairs spanning diverse scenarios. Extensive experiments
demonstrate UNIV's superior performance on infrared tasks (+1.7 mIoU in
semantic segmentation and +0.7 mAP in object detection) while maintaining 99%+
of the baseline performance on visible RGB tasks. Our code is available at
https://github.com/fangyuanmao/UNIV.

</details>


### [56] [ChronoForge-RL: Chronological Forging through Reinforcement Learning for Enhanced Video Understanding](https://arxiv.org/abs/2509.15800)
*Kehua Chen*

Main category: cs.CV

TL;DR: ChronoForge-RL通过创新的关键帧选择和对比学习机制，显著提升了视频理解的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频理解方法在处理密集视频内容时计算不可行及通过均匀采样策略难以识别语义重要帧的问题。

Method: 提出了一种可微分的关键帧选择机制，结合TAD（通过变分评分、拐点检测和优先蒸馏选择信息丰富的帧）和KF-GRPO（采用对比学习范式与显著性增强奖励机制）。

Result: 在VideoMME和LVBench上分别达到69.1%和52.7%，明显超越基线方法。

Conclusion: ChronoForge-RL通过结合TAD和KF-GRPO，显著提升了视频理解的效率和性能，其7B参数模型性能媲美72B参数模型。

Abstract: Current state-of-the-art video understanding methods typically struggle with
two critical challenges: (1) the computational infeasibility of processing
every frame in dense video content and (2) the difficulty in identifying
semantically significant frames through naive uniform sampling strategies. In
this paper, we propose a novel video understanding framework, called
ChronoForge-RL, which combines Temporal Apex Distillation (TAD) and
KeyFrame-aware Group Relative Policy Optimization (KF-GRPO) to tackle these
issues. Concretely, we introduce a differentiable keyframe selection mechanism
that systematically identifies semantic inflection points through a three-stage
process to enhance computational efficiency while preserving temporal
information. Then, two particular modules are proposed to enable effective
temporal reasoning: Firstly, TAD leverages variation scoring, inflection
detection, and prioritized distillation to select the most informative frames.
Secondly, we introduce KF-GRPO which implements a contrastive learning paradigm
with a saliency-enhanced reward mechanism that explicitly incentivizes models
to leverage both frame content and temporal relationships. Finally, our
proposed ChronoForge-RL achieves 69.1% on VideoMME and 52.7% on LVBench
compared to baseline methods, clearly surpassing previous approaches while
enabling our 7B parameter model to achieve performance comparable to 72B
parameter alternatives.

</details>


### [57] [GS-Scale: Unlocking Large-Scale 3D Gaussian Splatting Training via Host Offloading](https://arxiv.org/abs/2509.15645)
*Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon*

Main category: cs.CV

TL;DR: GS-Scale通过内存高效训练系统优化3D高斯泼溅，显著降低GPU内存需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模3D高斯泼溅训练中GPU内存需求过高的问题。

Method: GS-Scale将高斯存储在主机内存中，按需传输子集到GPU，结合选择性卸载、参数转发和延迟优化器更新三种系统级优化。

Result: GPU内存需求降低3.3-5.6倍，训练速度接近无主机卸载的GPU，高斯数量从400万扩展到1800万，LPIPS提升23-35%。

Conclusion: GS-Scale通过系统级优化显著降低了GPU内存需求，使大规模3D高斯泼溅训练在消费级GPU上成为可能，并提升了视觉质量。

Abstract: The advent of 3D Gaussian Splatting has revolutionized graphics rendering by
delivering high visual quality and fast rendering speeds. However, training
large-scale scenes at high quality remains challenging due to the substantial
memory demands required to store parameters, gradients, and optimizer states,
which can quickly overwhelm GPU memory. To address these limitations, we
propose GS-Scale, a fast and memory-efficient training system for 3D Gaussian
Splatting. GS-Scale stores all Gaussians in host memory, transferring only a
subset to the GPU on demand for each forward and backward pass. While this
dramatically reduces GPU memory usage, it requires frustum culling and
optimizer updates to be executed on the CPU, introducing slowdowns due to CPU's
limited compute and memory bandwidth. To mitigate this, GS-Scale employs three
system-level optimizations: (1) selective offloading of geometric parameters
for fast frustum culling, (2) parameter forwarding to pipeline CPU optimizer
updates with GPU computation, and (3) deferred optimizer update to minimize
unnecessary memory accesses for Gaussians with zero gradients. Our extensive
evaluations on large-scale datasets demonstrate that GS-Scale significantly
lowers GPU memory demands by 3.3-5.6x, while achieving training speeds
comparable to GPU without host offloading. This enables large-scale 3D Gaussian
Splatting training on consumer-grade GPUs; for instance, GS-Scale can scale the
number of Gaussians from 4 million to 18 million on an RTX 4070 Mobile GPU,
leading to 23-35% LPIPS (learned perceptual image patch similarity)
improvement.

</details>


### [58] [CIDER: A Causal Cure for Brand-Obsessed Text-to-Image Models](https://arxiv.org/abs/2509.15803)
*Fangjian Shen,Zifeng Liang,Chao Wang,Wushao Wen*

Main category: cs.CV

TL;DR: CIDER是一个模型无关的框架，通过提示优化减轻T2I模型的品牌偏见，实验证明其有效且不牺牲图像质量。


<details>
  <summary>Details</summary>
Motivation: 文本到图像（T2I）模型存在显著的‘品牌偏见’，即从通用提示中生成包含主导商业品牌的内容，带来伦理和法律风险。

Method: CIDER使用轻量级检测器识别品牌内容，并通过视觉语言模型（VLM）生成风格迥异的替代方案。

Result: 实验表明，CIDER显著减少了显性和隐性偏见，同时保持了图像质量和美学吸引力。

Conclusion: CIDER提供了一个实用的解决方案，通过推理时优化提示来减轻品牌偏见，为可信生成AI的发展做出了贡献。

Abstract: Text-to-image (T2I) models exhibit a significant yet under-explored "brand
bias", a tendency to generate contents featuring dominant commercial brands
from generic prompts, posing ethical and legal risks. We propose CIDER, a
novel, model-agnostic framework to mitigate bias at inference-time through
prompt refinement to avoid costly retraining. CIDER uses a lightweight detector
to identify branded content and a Vision-Language Model (VLM) to generate
stylistically divergent alternatives. We introduce the Brand Neutrality Score
(BNS) to quantify this issue and perform extensive experiments on leading T2I
models. Results show CIDER significantly reduces both explicit and implicit
biases while maintaining image quality and aesthetic appeal. Our work offers a
practical solution for more original and equitable content, contributing to the
development of trustworthy generative AI.

</details>


### [59] [FingerSplat: Contactless Fingerprint 3D Reconstruction and Generation based on 3D Gaussian Splatting](https://arxiv.org/abs/2509.15648)
*Yuwei Jia,Yutang Lu,Zhe Cui,Fei Su*

Main category: cs.CV

TL;DR: 本研究首次应用3D高斯溅射技术于指纹识别，实现了无需相机参数的稀疏图像下的3D指纹注册与重建，提升了无接触指纹识别的性能。


<details>
  <summary>Details</summary>
Motivation: 当前无接触指纹识别性能落后于接触式方法，主要原因是缺乏姿态变化的无接触指纹数据以及对隐式3D指纹表示的利用不足。

Method: 提出了一种新颖的无接触指纹3D注册、重建和生成框架，结合了3D高斯溅射技术。

Result: 实验证明，该方法能够从2D图像中准确对齐和重建3D指纹，并从3D模型中生成高质量的无接触指纹，从而提升识别性能。

Conclusion: 本研究通过整合3D高斯溅射技术，首次实现了无需相机参数信息的稀疏输入图像下的3D指纹注册与重建，显著提升了无接触指纹识别的性能。

Abstract: Researchers have conducted many pioneer researches on contactless
fingerprints, yet the performance of contactless fingerprint recognition still
lags behind contact-based methods primary due to the insufficient contactless
fingerprint data with pose variations and lack of the usage of implicit 3D
fingerprint representations. In this paper, we introduce a novel contactless
fingerprint 3D registration, reconstruction and generation framework by
integrating 3D Gaussian Splatting, with the goal of offering a new paradigm for
contactless fingerprint recognition that integrates 3D fingerprint
reconstruction and generation. To our knowledge, this is the first work to
apply 3D Gaussian Splatting to the field of fingerprint recognition, and the
first to achieve effective 3D registration and complete reconstruction of
contactless fingerprints with sparse input images and without requiring camera
parameters information. Experiments on 3D fingerprint registration,
reconstruction, and generation prove that our method can accurately align and
reconstruct 3D fingerprints from 2D images, and sequentially generates
high-quality contactless fingerprints from 3D model, thus increasing the
performances for contactless fingerprint recognition.

</details>


### [60] [Self-Supervised Cross-Modal Learning for Image-to-Point Cloud Registration](https://arxiv.org/abs/2509.15882)
*Xingmei Wang,Xiaoyu Hu,Chengkai Huang,Ziyan Zeng,Guohao Nie,Quan Z. Sheng,Lina Yao*

Main category: cs.CV

TL;DR: CrossI2P是一种自监督框架，通过双路径对比学习和两阶段注册方法，显著提升了图像到点云的注册性能。


<details>
  <summary>Details</summary>
Motivation: 由于图像和点云之间的语义-几何差距以及现有方法容易陷入局部最优，需要一种更鲁棒的图像到点云注册方法。

Method: CrossI2P采用双路径对比学习构建几何-语义融合的嵌入空间，并通过粗到细的注册范式（全局阶段和点级细化）实现精确注册。

Result: CrossI2P在KITTI Odometry和nuScenes数据集上的性能分别提升了23.7%和37.9%。

Conclusion: CrossI2P 通过自监督框架和两阶段注册方法，显著提升了图像到点云的注册性能，并在KITTI和nuScenes数据集上取得了优于现有方法的结果。

Abstract: Bridging 2D and 3D sensor modalities is critical for robust perception in
autonomous systems. However, image-to-point cloud (I2P) registration remains
challenging due to the semantic-geometric gap between texture-rich but
depth-ambiguous images and sparse yet metrically precise point clouds, as well
as the tendency of existing methods to converge to local optima. To overcome
these limitations, we introduce CrossI2P, a self-supervised framework that
unifies cross-modal learning and two-stage registration in a single end-to-end
pipeline. First, we learn a geometric-semantic fused embedding space via
dual-path contrastive learning, enabling annotation-free, bidirectional
alignment of 2D textures and 3D structures. Second, we adopt a coarse-to-fine
registration paradigm: a global stage establishes superpoint-superpixel
correspondences through joint intra-modal context and cross-modal interaction
modeling, followed by a geometry-constrained point-level refinement for precise
registration. Third, we employ a dynamic training mechanism with gradient
normalization to balance losses for feature alignment, correspondence
refinement, and pose estimation. Extensive experiments demonstrate that
CrossI2P outperforms state-of-the-art methods by 23.7% on the KITTI Odometry
benchmark and by 37.9% on nuScenes, significantly improving both accuracy and
robustness.

</details>


### [61] [A PCA Based Model for Surface Reconstruction from Incomplete Point Clouds](https://arxiv.org/abs/2509.15675)
*Hao Liu*

Main category: cs.CV

TL;DR: 提出一种基于PCA的模型，利用估计的法线信息作为正则化项，有效解决不完整点云数据的表面重建问题，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 点云数据在扫描过程中常因高吸光率和遮挡等因素导致不完整，如何从中准确重建表面是一个挑战。

Method: 采用PCA估计点云数据的表面法线信息，并将其作为模型的正则化项，同时引入算子分裂方法有效求解模型。

Result: 通过系统实验证明，该模型能成功推断数据缺失区域的表面结构，并良好地重建底层表面。

Conclusion: 该论文提出的基于PCA的模型能够有效从不完整点云数据中重建表面，尤其在数据缺失区域推断表面结构方面表现优异，超越了现有方法。

Abstract: Point cloud data represents a crucial category of information for
mathematical modeling, and surface reconstruction from such data is an
important task across various disciplines. However, during the scanning
process, the collected point cloud data may fail to cover the entire surface
due to factors such as high light-absorption rate and occlusions, resulting in
incomplete datasets. Inferring surface structures in data-missing regions and
successfully reconstructing the surface poses a challenge. In this paper, we
present a Principal Component Analysis (PCA) based model for surface
reconstruction from incomplete point cloud data. Initially, we employ PCA to
estimate the normal information of the underlying surface from the available
point cloud data. This estimated normal information serves as a regularizer in
our model, guiding the reconstruction of the surface, particularly in areas
with missing data. Additionally, we introduce an operator-splitting method to
effectively solve the proposed model. Through systematic experimentation, we
demonstrate that our model successfully infers surface structures in
data-missing regions and well reconstructs the underlying surfaces,
outperforming existing methodologies.

</details>


### [62] [RACap: Relation-Aware Prompting for Lightweight Retrieval-Augmented Image Captioning](https://arxiv.org/abs/2509.15883)
*Xiaosheng Long,Hanyu Wang,Zhentao Song,Kun Luo,Hongde Liu*

Main category: cs.CV

TL;DR: RACap通过结构化关系语义和异构视觉信息增强图像描述，性能优于现有轻量级模型。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强的图像描述方法在关系建模上存在局限性，包括语义提示表示过于粗粒度以及缺乏对图像对象及其语义关系的显式建模。

Method: 提出RACap模型，通过挖掘检索描述中的结构化关系语义并识别图像中的异构对象，增强了语义一致性和关系表达能力。

Result: RACap仅需10.8M可训练参数，性能优于以往的轻量级描述模型。

Conclusion: RACap模型通过结合结构化关系语义和异构视觉信息，显著提升了图像描述的语义一致性和关系表达能力，实验结果验证了其优越性能。

Abstract: Recent retrieval-augmented image captioning methods incorporate external
knowledge to compensate for the limitations in comprehending complex scenes.
However, current approaches face challenges in relation modeling: (1) the
representation of semantic prompts is too coarse-grained to capture
fine-grained relationships; (2) these methods lack explicit modeling of image
objects and their semantic relationships. To address these limitations, we
propose RACap, a relation-aware retrieval-augmented model for image captioning,
which not only mines structured relation semantics from retrieval captions, but
also identifies heterogeneous objects from the image. RACap effectively
retrieves structured relation features that contain heterogeneous visual
information to enhance the semantic consistency and relational expressiveness.
Experimental results show that RACap, with only 10.8M trainable parameters,
achieves superior performance compared to previous lightweight captioning
models.

</details>


### [63] [Camera Splatting for Continuous View Optimization](https://arxiv.org/abs/2509.15677)
*Gahye Lee,Hyomin Kim,Gwangjin Ju,Jooeun Son,Hyejeong Yoon,Seungyong Lee*

Main category: cs.CV

TL;DR: Camera Splatting 是一种新的视角优化框架，通过3D高斯建模相机并优化其分布，显著提升了复杂视角依赖现象的捕捉能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法（如 FVS）在捕捉复杂视角依赖现象（如金属反射和纹理）时的性能不足，提出了一种新的视角优化框架。

Method: 通过将每个相机建模为3D高斯（称为相机 splat），并在表面附近的3D点放置虚拟相机（称为点相机），观察相机 splat 的分布。通过连续可微的优化调整相机 splat，以实现目标分布。

Result: 优化的视角在捕捉复杂视角依赖现象方面表现优于 FVS，尤其是在金属反射和复杂纹理（如文字）的场景中。

Conclusion: Camera Splatting 框架在捕捉复杂视角依赖现象（如强烈金属反射和复杂纹理）方面表现出色，优于 Farthest View Sampling (FVS) 方法。

Abstract: We propose Camera Splatting, a novel view optimization framework for novel
view synthesis. Each camera is modeled as a 3D Gaussian, referred to as a
camera splat, and virtual cameras, termed point cameras, are placed at 3D
points sampled near the surface to observe the distribution of camera splats.
View optimization is achieved by continuously and differentiably refining the
camera splats so that desirable target distributions are observed from the
point cameras, in a manner similar to the original 3D Gaussian splatting.
Compared to the Farthest View Sampling (FVS) approach, our optimized views
demonstrate superior performance in capturing complex view-dependent phenomena,
including intense metallic reflections and intricate textures such as text.

</details>


### [64] [Layout Stroke Imitation: A Layout Guided Handwriting Stroke Generation for Style Imitation with Diffusion Model](https://arxiv.org/abs/2509.15678)
*Sidra Hanif,Longin Jan Latecki*

Main category: cs.CV

TL;DR: A conditional diffusion model for handwriting stroke generation, using multi-scale attention and word layout, outperforms current methods and rivals image generation networks.


<details>
  <summary>Details</summary>
Motivation: Handwriting stroke generation is vital for tasks like handwriting recognition and writer order recovery. Existing methods lacked consideration of word spacing, leading to inconsistent style imitation.

Method: The study introduces multi-scale attention features for calligraphic style imitation and incorporates word layout for consistent spacing. A conditional diffusion model is proposed to predict strokes, providing temporal coordinate information.

Result: The proposed model demonstrates superior performance in stroke generation compared to existing methods and competes well with image generation networks.

Conclusion: The proposed conditional diffusion model for stroke generation, guided by calligraphic style and word layout, outperforms current state-of-the-art methods and is competitive with recent image generation networks.

Abstract: Handwriting stroke generation is crucial for improving the performance of
tasks such as handwriting recognition and writers order recovery. In
handwriting stroke generation, it is significantly important to imitate the
sample calligraphic style. The previous studies have suggested utilizing the
calligraphic features of the handwriting. However, they had not considered word
spacing (word layout) as an explicit handwriting feature, which results in
inconsistent word spacing for style imitation. Firstly, this work proposes
multi-scale attention features for calligraphic style imitation. These
multi-scale feature embeddings highlight the local and global style features.
Secondly, we propose to include the words layout, which facilitates word
spacing for handwriting stroke generation. Moreover, we propose a conditional
diffusion model to predict strokes in contrast to previous work, which directly
generated style images. Stroke generation provides additional temporal
coordinate information, which is lacking in image generation. Hence, our
proposed conditional diffusion model for stroke generation is guided by
calligraphic style and word layout for better handwriting imitation and stroke
generation in a calligraphic style. Our experimentation shows that the proposed
diffusion model outperforms the current state-of-the-art stroke generation and
is competitive with recent image generation networks.

</details>


### [65] [Shedding Light on Depth: Explainability Assessment in Monocular Depth Estimation](https://arxiv.org/abs/2509.15980)
*Lorenzo Cirillo,Claudio Schiavella,Lorenzo Papa,Paolo Russo,Irene Amerini*

Main category: cs.CV

TL;DR: 研究了MDE模型的可解释性，发现Saliency Maps和Integrated Gradients在不同模型上表现良好，并提出了Attribution Fidelity指标以评估解释方法的可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管单目深度估计（MDE）在现实应用中广泛部署，但其可解释性尚未得到充分研究。本研究旨在填补这一空白，通过分析MDE网络，理解其输入图像到预测深度图的映射过程。

Method: 研究了特征归因方法（Saliency Maps、Integrated Gradients和Attention Rollout）在不同计算复杂度的MDE模型（METER和PixelFormer）上的应用。通过选择性扰动最重要和最不重要的像素，分析这些扰动对模型输出的影响，并引入Attribution Fidelity指标评估视觉解释的可靠性。

Result: Saliency Maps和Integrated Gradients分别在轻量级和深度MDE模型中表现出色。Attribution Fidelity能够有效识别解释方法的可靠性，即使传统指标表现良好。

Conclusion: 实验结果表明，Saliency Maps和Integrated Gradients分别在轻量级和深度MDE模型中表现良好，能够有效突出输入特征的重要性。Attribution Fidelity指标能有效识别解释方法的可靠性，即使在传统指标表现良好的情况下。

Abstract: Explainable artificial intelligence is increasingly employed to understand
the decision-making process of deep learning models and create trustworthiness
in their adoption. However, the explainability of Monocular Depth Estimation
(MDE) remains largely unexplored despite its wide deployment in real-world
applications. In this work, we study how to analyze MDE networks to map the
input image to the predicted depth map. More in detail, we investigate
well-established feature attribution methods, Saliency Maps, Integrated
Gradients, and Attention Rollout on different computationally complex models
for MDE: METER, a lightweight network, and PixelFormer, a deep network. We
assess the quality of the generated visual explanations by selectively
perturbing the most relevant and irrelevant pixels, as identified by the
explainability methods, and analyzing the impact of these perturbations on the
model's output. Moreover, since existing evaluation metrics can have some
limitations in measuring the validity of visual explanations for MDE, we
additionally introduce the Attribution Fidelity. This metric evaluates the
reliability of the feature attribution by assessing their consistency with the
predicted depth map. Experimental results demonstrate that Saliency Maps and
Integrated Gradients have good performance in highlighting the most important
input features for MDE lightweight and deep models, respectively. Furthermore,
we show that Attribution Fidelity effectively identifies whether an
explainability method fails to produce reliable visual maps, even in scenarios
where conventional metrics might suggest satisfactory results.

</details>


### [66] [SCENEFORGE: Enhancing 3D-text alignment with Structured Scene Compositions](https://arxiv.org/abs/2509.15693)
*Cristian Sbrolli,Matteo Matteucci*

Main category: cs.CV

TL;DR: SceneForge通过结构化多对象场景合成增强3D-文本对比学习，显著提升多项任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模3D-文本数据集稀缺的问题，并通过结构化、组合式的样本增强来提升数据质量和多样性。

Method: 利用单个3D形状构建具有明确空间关系的多对象场景，并通过大型语言模型生成连贯的多对象描述，以此增强对比训练的数据复杂性和多样性。

Result: 在ModelNet、ScanObjNN、Objaverse-LVIS和ScanNet等任务上实现了显著性能提升，同时在少样本分割和3D视觉问答等任务中表现出色。

Conclusion: SceneForge通过结构化多对象场景合成显著提升了3D点云与文本之间的对比学习性能，并在多个任务和应用中展现了其模型无关的普适性和鲁棒性。

Abstract: The whole is greater than the sum of its parts-even in 3D-text contrastive
learning. We introduce SceneForge, a novel framework that enhances contrastive
alignment between 3D point clouds and text through structured multi-object
scene compositions. SceneForge leverages individual 3D shapes to construct
multi-object scenes with explicit spatial relations, pairing them with coherent
multi-object descriptions refined by a large language model. By augmenting
contrastive training with these structured, compositional samples, SceneForge
effectively addresses the scarcity of large-scale 3D-text datasets,
significantly enriching data complexity and diversity. We systematically
investigate critical design elements, such as the optimal number of objects per
scene, the proportion of compositional samples in training batches, and scene
construction strategies. Extensive experiments demonstrate that SceneForge
delivers substantial performance gains across multiple tasks, including
zero-shot classification on ModelNet, ScanObjNN, Objaverse-LVIS, and ScanNet,
as well as few-shot part segmentation on ShapeNetPart. SceneForge's
compositional augmentations are model-agnostic, consistently improving
performance across multiple encoder architectures. Moreover, SceneForge
improves 3D visual question answering on ScanQA, generalizes robustly to
retrieval scenarios with increasing scene complexity, and showcases spatial
reasoning capabilities by adapting spatial configurations to align precisely
with textual instructions.

</details>


### [67] [ORIC: Benchmarking Object Recognition in Incongruous Context for Large Vision-Language Models](https://arxiv.org/abs/2509.15695)
*Zhaoyang Li,Zhan Ling,Yuchen Zhou,Hao Su*

Main category: cs.CV

TL;DR: 研究提出了ORIC基准，评估LVLMs在上下文不一致情境下的对象识别能力，揭示了其局限性并鼓励进一步研究。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在对象识别中容易因上下文不一致导致错误，如对象误识别和幻觉。研究旨在系统评估这一问题。

Method: 研究引入了ORIC基准，采用LLM引导的采样和CLIP引导的采样策略，分别识别上下文不一致的对象和可能被幻觉的对象。

Result: 评估了18个LVLMs和两个开放词汇检测模型，结果显示在上下文不一致情境下存在显著的识别差距。

Conclusion: 该研究揭示了大型视觉语言模型（LVLMs）在上下文不一致情境下的识别局限性，并提出了ORIC基准来系统评估这一问题。研究鼓励进一步探索上下文感知的对象识别方法。

Abstract: Large Vision-Language Models (LVLMs) have made significant strides in image
caption, visual question answering, and robotics by integrating visual and
textual information. However, they remain prone to errors in incongruous
contexts, where objects appear unexpectedly or are absent when contextually
expected. This leads to two key recognition failures: object misidentification
and hallucination. To systematically examine this issue, we introduce the
Object Recognition in Incongruous Context Benchmark (ORIC), a novel benchmark
that evaluates LVLMs in scenarios where object-context relationships deviate
from expectations. ORIC employs two key strategies: (1) LLM-guided sampling,
which identifies objects that are present but contextually incongruous, and (2)
CLIP-guided sampling, which detects plausible yet nonexistent objects that are
likely to be hallucinated, thereby creating an incongruous context. Evaluating
18 LVLMs and two open-vocabulary detection models, our results reveal
significant recognition gaps, underscoring the challenges posed by contextual
incongruity. This work provides critical insights into LVLMs' limitations and
encourages further research on context-aware object recognition.

</details>


### [68] [Training-Free Pyramid Token Pruning for Efficient Large Vision-Language Models via Region, Token, and Instruction-Guided Importance](https://arxiv.org/abs/2509.15704)
*Yuxuan Liang,Xu Li,Xiaolei Chen,Yi Zheng,Haotian Chen,Bin Li,Xiangyang Xue*

Main category: cs.CV

TL;DR: PTP是一种无需训练的令牌修剪策略，通过结合视觉显著性和指令引导重要性，有效减少LVLMs处理高分辨率图像时的计算开销和延迟。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在处理高分辨率图像时效率低下，现有方法将高分辨率图像分割为多个子图像，导致视觉令牌数量激增和计算开销指数级增长。

Method: 提出了一种无需训练的令牌修剪策略——金字塔令牌修剪（PTP），该方法结合了区域和令牌级别的视觉显著性以及指令引导的重要性。

Result: 在13个多样化的基准测试中，PTP显著减少了计算开销和推理延迟，且性能损失极小。

Conclusion: 提出的PTP方法通过结合自底向上的视觉显著性和自顶向下的指令引导重要性，有效减少了计算开销和推理延迟，同时保持了较高的性能。

Abstract: Large Vision-Language Models (LVLMs) have significantly advanced multimodal
understanding but still struggle with efficiently processing high-resolution
images. Recent approaches partition high-resolution images into multiple
sub-images, dramatically increasing the number of visual tokens and causing
exponential computational overhead during inference. To address these
limitations, we propose a training-free token pruning strategy, Pyramid Token
Pruning (PTP), that integrates bottom-up visual saliency at both region and
token levels with top-down instruction-guided importance. Inspired by human
visual attention mechanisms, PTP selectively retains more tokens from visually
salient regions and further leverages textual instructions to pinpoint tokens
most relevant to specific multimodal tasks. Extensive experiments across 13
diverse benchmarks demonstrate that our method substantially reduces
computational overhead and inference latency with minimal performance loss.

</details>


### [69] [See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model](https://arxiv.org/abs/2509.16087)
*Pengteng Li,Pinhao Song,Wuyang Li,Weiyu Guo,Huizai Yao,Yijie Xu,Dugang Liu,Hui Xiong*

Main category: cs.CV

TL;DR: SEE&TREK是一种无需训练的提示框架，通过视觉多样性和运动重建提升MLLMs的空间理解能力，实验显示性能最高提升3.5%。


<details>
  <summary>Details</summary>
Motivation: 针对现有MLLMs在纯视觉空间理解上的不足，提出无需额外模态的改进方案。

Method: 通过最大语义丰富度采样和运动重建，增强视觉多样性和空间关系保留。

Result: 在VSI-BENCH和STI-BENCH上，SEE&TREK将MLLMs性能最高提升3.5%。

Conclusion: SEE&TREK为视觉空间理解提供了一种无需训练的高效解决方案，显著提升了MLLMs在空间推理任务中的表现。

Abstract: We introduce SEE&TREK, the first training-free prompting framework tailored
to enhance the spatial understanding of Multimodal Large Language Models
(MLLMS) under vision-only constraints. While prior efforts have incorporated
modalities like depth or point clouds to improve spatial reasoning, purely
visualspatial understanding remains underexplored. SEE&TREK addresses this gap
by focusing on two core principles: increasing visual diversity and motion
reconstruction. For visual diversity, we conduct Maximum Semantic Richness
Sampling, which employs an off-the-shell perception model to extract
semantically rich keyframes that capture scene structure. For motion
reconstruction, we simulate visual trajectories and encode relative spatial
positions into keyframes to preserve both spatial relations and temporal
coherence. Our method is training&GPU-free, requiring only a single forward
pass, and can be seamlessly integrated into existing MLLM'S. Extensive
experiments on the VSI-B ENCH and STI-B ENCH show that S EE &T REK consistently
boosts various MLLM S performance across diverse spatial reasoning tasks with
the most +3.5% improvement, offering a promising path toward stronger spatial
intelligence.

</details>


### [70] [Robust Vision-Language Models via Tensor Decomposition: A Defense Against Adversarial Attacks](https://arxiv.org/abs/2509.16163)
*Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis*

Main category: cs.CV

TL;DR: 提出了一种轻量级的张量分解防御方法，无需重新训练即可提升VLM的对抗鲁棒性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法通常需要昂贵的重新训练或显著的架构更改，因此需要一种轻量级且无需重新训练的防御方法。

Method: 通过张量分解和重建视觉编码器表示，过滤对抗噪声同时保留语义。

Result: 在Flickr30K上，恢复了12.3%因攻击而损失的性能，Recall@1准确率从7.5%提升至19.8%；在COCO上，恢复了8.1%性能，准确率从3.8%提升至11.9%。

Conclusion: 该方法是一种实用、即插即用的解决方案，对现有VLM的开销极小。

Abstract: Vision language models (VLMs) excel in multimodal understanding but are prone
to adversarial attacks. Existing defenses often demand costly retraining or
significant architecture changes. We introduce a lightweight defense using
tensor decomposition suitable for any pre-trained VLM, requiring no retraining.
By decomposing and reconstructing vision encoder representations, it filters
adversarial noise while preserving meaning. Experiments with CLIP on COCO and
Flickr30K show improved robustness. On Flickr30K, it restores 12.3\%
performance lost to attacks, raising Recall@1 accuracy from 7.5\% to 19.8\%. On
COCO, it recovers 8.1\% performance, improving accuracy from 3.8\% to 11.9\%.
Analysis shows Tensor Train decomposition with low rank (8-32) and low residual
strength ($\alpha=0.1-0.2$) is optimal. This method is a practical,
plug-and-play solution with minimal overhead for existing VLMs.

</details>


### [71] [Toward Medical Deepfake Detection: A Comprehensive Dataset and Novel Method](https://arxiv.org/abs/2509.15711)
*Shuaibo Li,Zhaohu Xing,Hongqiu Wang,Pengfei Hao,Xingyu Li,Zekai Liu,Lei Zhu*

Main category: cs.CV

TL;DR: 研究提出MedForensics数据集和DSKI检测器，有效识别AI生成的医学图像，解决现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 随着生成AI在医学影像中的快速发展，伪造图像对医疗系统构成严重威胁，如诊断欺骗、财务欺诈和错误信息。现有医学法证研究不足，缺乏专门数据集，且现有方法不适用于AI生成的医学图像。

Method: 研究提出了MedForensics数据集和DSKI检测器。DSKI包含两个核心组件：跨域微迹适配器（CDFA）用于提取训练中的伪造线索，以及医学法证检索模块（MFRM）通过少量样本检索提升检测准确性。

Result: 实验结果表明，DSKI在多种医学模态上实现了卓越的准确性，显著优于现有方法和人类专家。

Conclusion: DSKI作为一种新型的双阶段知识注入检测器，在检测AI生成的医学图像方面表现出色，显著优于现有方法和人类专家，为医学影像鉴定领域提供了有效的解决方案。

Abstract: The rapid advancement of generative AI in medical imaging has introduced both
significant opportunities and serious challenges, especially the risk that fake
medical images could undermine healthcare systems. These synthetic images pose
serious risks, such as diagnostic deception, financial fraud, and
misinformation. However, research on medical forensics to counter these threats
remains limited, and there is a critical lack of comprehensive datasets
specifically tailored for this field. Additionally, existing media forensic
methods, which are primarily designed for natural or facial images, are
inadequate for capturing the distinct characteristics and subtle artifacts of
AI-generated medical images. To tackle these challenges, we introduce
\textbf{MedForensics}, a large-scale medical forensics dataset encompassing six
medical modalities and twelve state-of-the-art medical generative models. We
also propose \textbf{DSKI}, a novel \textbf{D}ual-\textbf{S}tage
\textbf{K}nowledge \textbf{I}nfusing detector that constructs a vision-language
feature space tailored for the detection of AI-generated medical images. DSKI
comprises two core components: 1) a cross-domain fine-trace adapter (CDFA) for
extracting subtle forgery clues from both spatial and noise domains during
training, and 2) a medical forensic retrieval module (MFRM) that boosts
detection accuracy through few-shot retrieval during testing. Experimental
results demonstrate that DSKI significantly outperforms both existing methods
and human experts, achieving superior accuracy across multiple medical
modalities.

</details>


### [72] [Fast OTSU Thresholding Using Bisection Method](https://arxiv.org/abs/2509.16179)
*Sai Varun Kodathala*

Main category: cs.CV

TL;DR: 通过二分法优化Otsu阈值算法，显著提升计算效率，保持分割质量，适用于实时大规模图像处理。


<details>
  <summary>Details</summary>
Motivation: Otsu阈值算法在图像分割中具有基础性地位，但其计算效率受限于对所有可能阈值值的穷举搜索需求。

Method: 利用二分法开发类间方差函数的单峰特性，将计算复杂度从O(L)降低到O(log L)。

Result: 在48个标准测试图像上，方差计算减少了91.63%，算法迭代减少了97.21%。二分法在66.67%的测试案例中实现了精确阈值匹配，95.83%的案例偏差在5个灰度级以内。

Conclusion: 该优化方法在保持Otsu方法理论基础和分割质量的同时，显著提高了计算效率，适用于大规模图像处理系统的实时应用。

Abstract: The Otsu thresholding algorithm represents a fundamental technique in image
segmentation, yet its computational efficiency is severely limited by
exhaustive search requirements across all possible threshold values. This work
presents an optimized implementation that leverages the bisection method to
exploit the unimodal characteristics of the between-class variance function.
Our approach reduces the computational complexity from O(L) to O(log L)
evaluations while preserving segmentation accuracy. Experimental validation on
48 standard test images demonstrates a 91.63% reduction in variance
computations and 97.21% reduction in algorithmic iterations compared to
conventional exhaustive search. The bisection method achieves exact threshold
matches in 66.67% of test cases, with 95.83% exhibiting deviations within 5
gray levels. The algorithm maintains universal convergence within theoretical
logarithmic bounds while providing deterministic performance guarantees
suitable for real-time applications. This optimization addresses critical
computational bottlenecks in large-scale image processing systems without
compromising the theoretical foundations or segmentation quality of the
original Otsu method.

</details>


### [73] [TrueMoE: Dual-Routing Mixture of Discriminative Experts for Synthetic Image Detection](https://arxiv.org/abs/2509.15741)
*Laixin Zhang,Shuaibo Li,Wei Ma,Hongbin Zha*

Main category: cs.CV

TL;DR: TrueMoE是一种新型双路由多专家框架，通过协作多个专用判别子空间，显著提升合成图像检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的统一判别空间方法在泛化到未见过的生成模式时表现不佳，需要更灵活和鲁棒的检测框架。

Method: 提出了TrueMoE，一种基于双路由机制的多专家判别框架，通过组织互补的判别子空间来捕获多样化的伪造线索。

Result: 在多种生成模型上的广泛实验表明，TrueMoE在泛化和鲁棒性方面表现优异。

Conclusion: TrueMoE框架通过多专家协作机制，显著提升了合成图像检测的泛化能力和鲁棒性。

Abstract: The rapid progress of generative models has made synthetic image detection an
increasingly critical task. Most existing approaches attempt to construct a
single, universal discriminative space to separate real from fake content.
However, such unified spaces tend to be complex and brittle, often struggling
to generalize to unseen generative patterns. In this work, we propose TrueMoE,
a novel dual-routing Mixture-of-Discriminative-Experts framework that
reformulates the detection task as a collaborative inference across multiple
specialized and lightweight discriminative subspaces. At the core of TrueMoE is
a Discriminative Expert Array (DEA) organized along complementary axes of
manifold structure and perceptual granularity, enabling diverse forgery cues to
be captured across subspaces. A dual-routing mechanism, comprising a
granularity-aware sparse router and a manifold-aware dense router, adaptively
assigns input images to the most relevant experts. Extensive experiments across
a wide spectrum of generative models demonstrate that TrueMoE achieves superior
generalization and robustness.

</details>


### [74] [Hybrid Lie semi-group and cascade structures for the generalized Gaussian derivative model for visual receptive fields](https://arxiv.org/abs/2509.15748)
*Tony Lindeberg*

Main category: cs.CV

TL;DR: The paper explores covariant receptive field families to handle image variability, deriving relationships between receptive field responses for efficient computation and biological vision modeling.


<details>
  <summary>Details</summary>
Motivation: The variability in real-world image structures under natural transformations necessitates a vision system based on covariant receptive field families to handle such variability.

Method: The paper derives both infinitesimal relationships (semi-groups and Lie groups) and macroscopic cascade smoothing properties (related to Lie algebras) to describe how receptive field responses at different scales can be computed.

Result: The results offer insights into the relationships between receptive field responses for different filter parameters, enabling more efficient computation schemes and theoretical models of biological vision.

Conclusion: The paper provides a deeper understanding of the relationships between spatial and spatio-temporal receptive field responses, which can be used for designing efficient computation schemes and formulating theoretical models of biological vision.

Abstract: Because of the variabilities of real-world image structures under the natural
image transformations that arise when observing similar objects or
spatio-temporal events under different viewing conditions, the receptive field
responses computed in the earliest layers of the visual hierarchy may be
strongly influenced by such geometric image transformations. One way of
handling this variability is by basing the vision system on covariant receptive
field families, which expand the receptive field shapes over the degrees of
freedom in the image transformations.
  This paper addresses the problem of deriving relationships between spatial
and spatio-temporal receptive field responses obtained for different values of
the shape parameters in the resulting multi-parameter families of receptive
fields. For this purpose, we derive both (i) infinitesimal relationships,
roughly corresponding to a combination of notions from semi-groups and Lie
groups, as well as (ii) macroscopic cascade smoothing properties, which
describe how receptive field responses at coarser spatial and temporal scales
can be computed by applying smaller support incremental filters to the output
from corresponding receptive fields at finer spatial and temporal scales,
structurally related to the notion of Lie algebras, although with directional
preferences.
  The presented results provide (i) a deeper understanding of the relationships
between spatial and spatio-temporal receptive field responses for different
values of the filter parameters, which can be used for both (ii) designing more
efficient schemes for computing receptive field responses over populations of
multi-parameter families of receptive fields, as well as (iii)~formulating
idealized theoretical models of the computations of simple cells in biological
vision.

</details>


### [75] [Simulated Cortical Magnification Supports Self-Supervised Object Learning](https://arxiv.org/abs/2509.15751)
*Zhengyang Yu,Arthur Aubret,Chen Yu,Jochen Triesch*

Main category: cs.CV

TL;DR: 研究通过模拟人眼中央凹视觉特性，提升了自监督学习模型的对象表征质量，验证了分辨率变化对学习效果的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习模型忽略了人类视觉的中央凹特性（视野中心高分辨率、边缘低分辨率），本研究旨在探索这种分辨率变化对对象表征学习的影响。

Method: 利用两个第一人称视角视频数据集，应用人眼中央凹和皮质放大模型处理输入数据，使视觉内容在边缘区域逐渐模糊。随后使用两个生物启发的自监督学习模型，基于时间的学习目标进行训练。

Result: 模拟中央凹视觉特性显著提升了对象表征的质量，主要归因于对象尺寸增大及中央与边缘视觉信息的更好平衡。

Conclusion: 通过模拟人眼中央凹视觉特性，研究提升了自监督学习模型中对象表征的质量，为构建更贴近人类视觉学习的模型提供了新方向。

Abstract: Recent self-supervised learning models simulate the development of semantic
object representations by training on visual experience similar to that of
toddlers. However, these models ignore the foveated nature of human vision with
high/low resolution in the center/periphery of the visual field. Here, we
investigate the role of this varying resolution in the development of object
representations. We leverage two datasets of egocentric videos that capture the
visual experience of humans during interactions with objects. We apply models
of human foveation and cortical magnification to modify these inputs, such that
the visual content becomes less distinct towards the periphery. The resulting
sequences are used to train two bio-inspired self-supervised learning models
that implement a time-based learning objective. Our results show that modeling
aspects of foveated vision improves the quality of the learned object
representations in this setting. Our analysis suggests that this improvement
comes from making objects appear bigger and inducing a better trade-off between
central and peripheral visual information. Overall, this work takes a step
towards making models of humans' learning of visual representations more
realistic and performant.

</details>


### [76] [MCOD: The First Challenging Benchmark for Multispectral Camouflaged Object Detection](https://arxiv.org/abs/2509.15753)
*Yang Li,Tingfa Xu,Shuyan Bai,Peifu Liu,Jianan Li*

Main category: cs.CV

TL;DR: MCOD是首个专为多光谱伪装目标检测设计的挑战性基准数据集，通过集成多光谱模态提升了检测性能，并公开可用。


<details>
  <summary>Details</summary>
Motivation: 现有的COD基准数据集仅为RGB格式，缺乏对多光谱方法的支持，制约了该领域的发展。

Method: 引入MCOD数据集，包含综合挑战属性、多样化的真实场景和高质量像素级注释，并在其上评估了11种代表性COD方法。

Result: 多光谱模态的集成显著减轻了由于任务难度增加导致的性能下降，凸显了光谱信息在增强检测鲁棒性方面的价值。

Conclusion: MCOD数据集为多光谱伪装目标检测提供了强有力的基础，并公开可用，预计将推动该领域的未来研究。

Abstract: Camouflaged Object Detection (COD) aims to identify objects that blend
seamlessly into natural scenes. Although RGB-based methods have advanced, their
performance remains limited under challenging conditions. Multispectral
imagery, providing rich spectral information, offers a promising alternative
for enhanced foreground-background discrimination. However, existing COD
benchmark datasets are exclusively RGB-based, lacking essential support for
multispectral approaches, which has impeded progress in this area. To address
this gap, we introduce MCOD, the first challenging benchmark dataset
specifically designed for multispectral camouflaged object detection. MCOD
features three key advantages: (i) Comprehensive challenge attributes: It
captures real-world difficulties such as small object sizes and extreme
lighting conditions commonly encountered in COD tasks. (ii) Diverse real-world
scenarios: The dataset spans a wide range of natural environments to better
reflect practical applications. (iii) High-quality pixel-level annotations:
Each image is manually annotated with precise object masks and corresponding
challenge attribute labels. We benchmark eleven representative COD methods on
MCOD, observing a consistent performance drop due to increased task difficulty.
Notably, integrating multispectral modalities substantially alleviates this
degradation, highlighting the value of spectral information in enhancing
detection robustness. We anticipate MCOD will provide a strong foundation for
future research in multispectral camouflaged object detection. The dataset is
publicly accessible at https://github.com/yl2900260-bit/MCOD.

</details>


### [77] [Overview of PlantCLEF 2024: multi-species plant identification in vegetation plot images](https://arxiv.org/abs/2509.15768)
*Herve Goeau,Vincent Espitalier,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: PlantCLEF 2024挑战赛利用AI和大型数据集推动生态研究中的植物物种识别效率。


<details>
  <summary>Details</summary>
Motivation: 生态研究需要高效、标准化的植物物种识别方法，AI的引入可以提升专家的工作效率和覆盖范围。

Method: 利用专家标注的多标签图像数据集和预训练的视觉Transformer模型，参与者需完成多标签分类任务。

Result: 挑战赛提供了包含170万张植物图像的大规模训练集，并展示了先进模型在多标签分类任务中的表现。

Conclusion: 本文通过PlantCLEF 2024挑战赛展示了AI在生态研究中的潜力，特别是在植物物种识别和多标签分类任务中的高效表现。

Abstract: Plot images are essential for ecological studies, enabling standardized
sampling, biodiversity assessment, long-term monitoring and remote, large-scale
surveys. Plot images are typically fifty centimetres or one square meter in
size, and botanists meticulously identify all the species found there. The
integration of AI could significantly improve the efficiency of specialists,
helping them to extend the scope and coverage of ecological studies. To
evaluate advances in this regard, the PlantCLEF 2024 challenge leverages a new
test set of thousands of multi-label images annotated by experts and covering
over 800 species. In addition, it provides a large training set of 1.7 million
individual plant images as well as state-of-the-art vision transformer models
pre-trained on this data. The task is evaluated as a (weakly-labeled)
multi-label classification task where the aim is to predict all the plant
species present on a high-resolution plot image (using the single-label
training data). In this paper, we provide an detailed description of the data,
the evaluation methodology, the methods and models employed by the participants
and the results achieved.

</details>


### [78] [Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation](https://arxiv.org/abs/2509.15772)
*Weimin Bai,Yubo Li,Weijian Luo,Wenzheng Chen,He Sun*

Main category: cs.CV

TL;DR: VLM3D整合视觉语言模型改进文本到3D生成，解决现有方法语义粗糙和几何不一致问题，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有SDS方法依赖CLIP式文本编码器导致语义对齐粗糙，且2D扩散先验缺乏3D空间约束，导致几何不一致和多物体场景关系不准确。

Method: 提出VLM3D框架，利用Qwen2.5-VL模型作为可微分语义和空间先验，增强3D生成的一致性和精细提示对齐。

Result: 在GPTeval3D基准测试中，VLM3D在多样物体和复杂场景中表现优异，显著超越先前SDS方法。

Conclusion: VLM3D通过整合大型视觉语言模型（VLMs）到SDS流程中，显著提升了文本到3D生成的语义保真度、几何一致性和空间准确性，优于现有SDS方法。

Abstract: Score Distillation Sampling (SDS) enables high-quality text-to-3D generation
by supervising 3D models through the denoising of multi-view 2D renderings,
using a pretrained text-to-image diffusion model to align with the input prompt
and ensure 3D consistency. However, existing SDS-based methods face two
fundamental limitations: (1) their reliance on CLIP-style text encoders leads
to coarse semantic alignment and struggles with fine-grained prompts; and (2)
2D diffusion priors lack explicit 3D spatial constraints, resulting in
geometric inconsistencies and inaccurate object relationships in multi-object
scenes. To address these challenges, we propose VLM3D, a novel text-to-3D
generation framework that integrates large vision-language models (VLMs) into
the SDS pipeline as differentiable semantic and spatial priors. Unlike standard
text-to-image diffusion priors, VLMs leverage rich language-grounded
supervision that enables fine-grained prompt alignment. Moreover, their
inherent vision language modeling provides strong spatial understanding, which
significantly enhances 3D consistency for single-object generation and improves
relational reasoning in multi-object scenes. We instantiate VLM3D based on the
open-source Qwen2.5-VL model and evaluate it on the GPTeval3D benchmark.
Experiments across diverse objects and complex scenes show that VLM3D
significantly outperforms prior SDS-based methods in semantic fidelity,
geometric coherence, and spatial correctness.

</details>


### [79] [Enriched Feature Representation and Motion Prediction Module for MOSEv2 Track of 7th LSVOS Challenge: 3rd Place Solution](https://arxiv.org/abs/2509.15781)
*Chang Soo Lim,Joonyoung Moon,Donghyeon Cho*

Main category: cs.CV

TL;DR: SCOPE框架结合Cutie和SAM2的优势，引入运动预测模块，提升视频对象分割性能，在LSVOS挑战赛中获得第三名。


<details>
  <summary>Details</summary>
Motivation: 视频对象分割（VOS）是一项具有广泛应用（如视频编辑和自动驾驶）的挑战性任务。Cutie和SAM2各自在特征容量和时间建模方面存在局限性。

Method: 该框架将Cutie的编码器替换为SAM2的ViT编码器，并引入了运动预测模块以增强时间稳定性。此外，采用了结合Cutie、SAM2及其变体的集成策略。

Result: 提出的SCOPE框架在MOSEv2赛道中取得了第三名的成绩，证明了丰富特征表示和运动预测对稳健视频对象分割的有效性。

Conclusion: 论文提出的SCOPE框架通过结合Cutie和SAM2的互补优势，并引入运动预测模块，显著提升了视频对象分割的稳健性，最终在LSVOS挑战赛中取得第三名的成绩。

Abstract: Video object segmentation (VOS) is a challenging task with wide applications
such as video editing and autonomous driving. While Cutie provides strong
query-based segmentation and SAM2 offers enriched representations via a
pretrained ViT encoder, each has limitations in feature capacity and temporal
modeling. In this report, we propose a framework that integrates their
complementary strengths by replacing the encoder of Cutie with the ViT encoder
of SAM2 and introducing a motion prediction module for temporal stability. We
further adopt an ensemble strategy combining Cutie, SAM2, and our variant,
achieving 3rd place in the MOSEv2 track of the 7th LSVOS Challenge. We refer to
our final model as SCOPE (SAM2-CUTIE Object Prediction Ensemble). This
demonstrates the effectiveness of enriched feature representation and motion
prediction for robust video object segmentation. The code is available at
https://github.com/2025-LSVOS-3rd-place/MOSEv2_3rd_place.

</details>


### [80] [FoBa: A Foreground-Background co-Guided Method and New Benchmark for Remote Sensing Semantic Change Detection](https://arxiv.org/abs/2509.15788)
*Haotian Zhang,Han Guo,Keyan Chen,Hao Chen,Zhengxia Zou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 论文构建了LevirSCD数据集并提出FoBa方法，通过前景-背景协同引导和GIF模块提升了SCD性能。


<details>
  <summary>Details</summary>
Motivation: 现有SCD数据集在类别和类型上有限，且方法未充分利用变化信息，限制了模型性能。

Method: 提出了前景-背景协同引导的SCD方法（FoBa），结合了Gated Interaction Fusion模块和一致性损失。

Result: FoBa在SECOND、JL1和LevirSCD数据集上的SeK指标分别提升了1.48%、3.61%和2.81%。

Conclusion: FoBa方法在三个数据集上取得了优于当前SOTA方法的结果，验证了其有效性。

Abstract: Despite the remarkable progress achieved in remote sensing semantic change
detection (SCD), two major challenges remain. At the data level, existing SCD
datasets suffer from limited change categories, insufficient change types, and
a lack of fine-grained class definitions, making them inadequate to fully
support practical applications. At the methodological level, most current
approaches underutilize change information, typically treating it as a
post-processing step to enhance spatial consistency, which constrains further
improvements in model performance. To address these issues, we construct a new
benchmark for remote sensing SCD, LevirSCD. Focused on the Beijing area, the
dataset covers 16 change categories and 210 specific change types, with more
fine-grained class definitions (e.g., roads are divided into unpaved and paved
roads). Furthermore, we propose a foreground-background co-guided SCD (FoBa)
method, which leverages foregrounds that focus on regions of interest and
backgrounds enriched with contextual information to guide the model
collaboratively, thereby alleviating semantic ambiguity while enhancing its
ability to detect subtle changes. Considering the requirements of bi-temporal
interaction and spatial consistency in SCD, we introduce a Gated Interaction
Fusion (GIF) module along with a simple consistency loss to further enhance the
model's detection performance. Extensive experiments on three datasets (SECOND,
JL1, and the proposed LevirSCD) demonstrate that FoBa achieves competitive
results compared to current SOTA methods, with improvements of 1.48%, 3.61%,
and 2.81% in the SeK metric, respectively. Our code and dataset are available
at https://github.com/zmoka-zht/FoBa.

</details>


### [81] [Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization](https://arxiv.org/abs/2509.15791)
*Tan Pan,Kaiyu Guo,Dongli Xu,Zhaorui Tan,Chen Jiang,Deshu Chen,Xin Guo,Brian C. Lovell,Limei Han,Yuan Cheng,Mahsa Baktashmotlagh*

Main category: cs.CV

TL;DR: MS-UDG提出了一种无监督领域泛化方法，通过最小充分语义表示学习，无需类别或领域标签，显著提升泛化性能。


<details>
  <summary>Details</summary>
Motivation: 无监督领域泛化（UDG）任务旨在提升无监督学习技术的泛化能力，但现有方法依赖领域标签，而实际场景中这些标签往往不可用。

Method: MS-UDG结合了基于InfoNCE的目标（实现充分性）和两种互补组件（促进最小性）：新颖的语义-变化解缠损失和基于重建的变化捕获机制。

Result: MS-UDG在主流无监督领域泛化基准测试中表现优异，显著优于现有自监督学习和UDG方法。

Conclusion: MS-UDG通过理论分析和实证验证，提出了一种无需类别或领域标签的最小充分语义表示学习方法，显著提升了无监督领域泛化性能。

Abstract: The generalization ability of deep learning has been extensively studied in
supervised settings, yet it remains less explored in unsupervised scenarios.
Recently, the Unsupervised Domain Generalization (UDG) task has been proposed
to enhance the generalization of models trained with prevalent unsupervised
learning techniques, such as Self-Supervised Learning (SSL). UDG confronts the
challenge of distinguishing semantics from variations without category labels.
Although some recent methods have employed domain labels to tackle this issue,
such domain labels are often unavailable in real-world contexts. In this paper,
we address these limitations by formalizing UDG as the task of learning a
Minimal Sufficient Semantic Representation: a representation that (i) preserves
all semantic information shared across augmented views (sufficiency), and (ii)
maximally removes information irrelevant to semantics (minimality). We
theoretically ground these objectives from the perspective of information
theory, demonstrating that optimizing representations to achieve sufficiency
and minimality directly reduces out-of-distribution risk. Practically, we
implement this optimization through Minimal-Sufficient UDG (MS-UDG), a
learnable model by integrating (a) an InfoNCE-based objective to achieve
sufficiency; (b) two complementary components to promote minimality: a novel
semantic-variation disentanglement loss and a reconstruction-based mechanism
for capturing adequate variation. Empirically, MS-UDG sets a new
state-of-the-art on popular unsupervised domain-generalization benchmarks,
consistently outperforming existing SSL and UDG methods, without category or
domain labels during representation learning.

</details>


### [82] [TASAM: Terrain-and-Aware Segment Anything Model for Temporal-Scale Remote Sensing Segmentation](https://arxiv.org/abs/2509.15795)
*Tianyang Wang,Xi Xiao,Gaofei Chen,Hanzhang Chi,Qi Zhang,Guo Cheng,Yingrui Ji*

Main category: cs.CV

TL;DR: TASAM是专为高分辨率遥感图像分割设计的SAM扩展，通过地形和时间感知模块提升了性能，且无需重新训练主干。


<details>
  <summary>Details</summary>
Motivation: SAM在自然图像领域表现出色，但在遥感数据中面临复杂地形、多尺度对象和时间动态等挑战。

Method: TASAM集成了三个轻量级模块：地形感知适配器、时间提示生成器和多尺度融合策略，无需重新训练SAM主干。

Result: TASAM在三个遥感基准测试（LoveDA、iSAID和WHU-CD）中显著优于零样本SAM和任务特定模型，且计算开销最小。

Conclusion: TASAM展示了通过领域自适应增强基础模型的价值，为地理空间分割提供了可扩展的路径。

Abstract: Segment Anything Model (SAM) has demonstrated impressive zero-shot
segmentation capabilities across natural image domains, but it struggles to
generalize to the unique challenges of remote sensing data, such as complex
terrain, multi-scale objects, and temporal dynamics. In this paper, we
introduce TASAM, a terrain and temporally-aware extension of SAM designed
specifically for high-resolution remote sensing image segmentation. TASAM
integrates three lightweight yet effective modules: a terrain-aware adapter
that injects elevation priors, a temporal prompt generator that captures
land-cover changes over time, and a multi-scale fusion strategy that enhances
fine-grained object delineation. Without retraining the SAM backbone, our
approach achieves substantial performance gains across three remote sensing
benchmarks-LoveDA, iSAID, and WHU-CD-outperforming both zero-shot SAM and
task-specific models with minimal computational overhead. Our results highlight
the value of domain-adaptive augmentation for foundation models and offer a
scalable path toward more robust geospatial segmentation.

</details>


### [83] [Boosting Active Learning with Knowledge Transfer](https://arxiv.org/abs/2509.15805)
*Tianyang Wang,Xi Xiao,Gaofei Chen,Xiaoying Liao,Guo Cheng,Yingrui Ji*

Main category: cs.CV

TL;DR: 提出一种基于知识迁移的主动学习不确定性估计方法，通过教师-学生模型实现，适用于多种任务并在实验中验证有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖复杂的辅助模型和高级训练方式，难以适用于特定领域任务（如cryo-ET分类），因此提出一种更通用且易于训练的方法。

Method: 利用教师-学生模型，教师模型为主动学习中的任务模型，学生模型为辅助模型，通过两者输出的距离衡量未标记数据的不确定性。

Result: 实验结果表明，该方法在经典计算机视觉任务和cryo-ET挑战中均表现出色。

Conclusion: 该论文提出了一种基于知识迁移的新方法，用于提升主动学习中的不确定性估计，该方法通过教师-学生模型实现，适用于多种任务，并在经典计算机视觉任务和cryo-ET挑战中验证了其有效性和效率。

Abstract: Uncertainty estimation is at the core of Active Learning (AL). Most existing
methods resort to complex auxiliary models and advanced training fashions to
estimate uncertainty for unlabeled data. These models need special design and
hence are difficult to train especially for domain tasks, such as Cryo-Electron
Tomography (cryo-ET) classification in computational biology. To address this
challenge, we propose a novel method using knowledge transfer to boost
uncertainty estimation in AL. Specifically, we exploit the teacher-student mode
where the teacher is the task model in AL and the student is an auxiliary model
that learns from the teacher. We train the two models simultaneously in each AL
cycle and adopt a certain distance between the model outputs to measure
uncertainty for unlabeled data. The student model is task-agnostic and does not
rely on special training fashions (e.g. adversarial), making our method
suitable for various tasks. More importantly, we demonstrate that data
uncertainty is not tied to concrete value of task loss but closely related to
the upper-bound of task loss. We conduct extensive experiments to validate the
proposed method on classical computer vision tasks and cryo-ET challenges. The
results demonstrate its efficacy and efficiency.

</details>


### [84] [LC-SLab -- An Object-based Deep Learning Framework for Large-scale Land Cover Classification from Satellite Imagery and Sparse In-situ Labels](https://arxiv.org/abs/2509.15868)
*Johannes Leonhardt,Juergen Gall,Ribana Roscher*

Main category: cs.CV

TL;DR: LC-SLab是首个针对稀疏监督下大规模土地覆盖分类的对象深度学习方法框架，结合输入/输出级聚合，显著提升预测连贯性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的土地覆盖分类方法在稀疏监督下易产生碎片化和噪声预测，对象分类方法虽具潜力但未充分探索。

Method: LC-SLab结合了图神经网络的输入级聚合和语义分割模型的输出级后处理，并利用预训练网络特征增强小数据集性能。

Result: 对象方法在准确性和连贯性上优于像素级模型，输入级聚合在小数据集上更鲁棒，输出级聚合在数据充足时表现最佳。LC-SLab配置优于现有土地覆盖产品。

Conclusion: LC-SLab框架通过对象深度学习方法显著提升了大规模土地覆盖分类的准确性和连贯性，尤其在稀疏监督条件下表现优异，展示了其在实际应用中的潜力。

Abstract: Large-scale land cover maps generated using deep learning play a critical
role across a wide range of Earth science applications. Open in-situ datasets
from principled land cover surveys offer a scalable alternative to manual
annotation for training such models. However, their sparse spatial coverage
often leads to fragmented and noisy predictions when used with existing deep
learning-based land cover mapping approaches. A promising direction to address
this issue is object-based classification, which assigns labels to semantically
coherent image regions rather than individual pixels, thereby imposing a
minimum mapping unit. Despite this potential, object-based methods remain
underexplored in deep learning-based land cover mapping pipelines, especially
in the context of medium-resolution imagery and sparse supervision. To address
this gap, we propose LC-SLab, the first deep learning framework for
systematically exploring object-based deep learning methods for large-scale
land cover classification under sparse supervision. LC-SLab supports both
input-level aggregation via graph neural networks, and output-level aggregation
by postprocessing results from established semantic segmentation models.
Additionally, we incorporate features from a large pre-trained network to
improve performance on small datasets. We evaluate the framework on annual
Sentinel-2 composites with sparse LUCAS labels, focusing on the tradeoff
between accuracy and fragmentation, as well as sensitivity to dataset size. Our
results show that object-based methods can match or exceed the accuracy of
common pixel-wise models while producing substantially more coherent maps.
Input-level aggregation proves more robust on smaller datasets, whereas
output-level aggregation performs best with more data. Several configurations
of LC-SLab also outperform existing land cover products, highlighting the
framework's practical utility.

</details>


### [85] [Zero-Shot Visual Grounding in 3D Gaussians via View Retrieval](https://arxiv.org/abs/2509.15871)
*Liwei Liao,Xufeng Li,Xiaoyun Zheng,Boning Liu,Feng Gao,Ronggang Wang*

Main category: cs.CV

TL;DR: GVR通过2D视图检索实现零样本3D视觉定位，避免3D标注和逐场景训练，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D视觉定位方法在3D高斯泼溅中空间纹理隐式表示处理和大量标注数据需求上的挑战。

Method: 提出了一种名为GVR的零样本视觉定位框架，通过对象级视图检索从多视图中收集定位线索。

Result: 实验表明，GVR方法在避免逐场景训练的同时，实现了最先进的视觉定位性能。

Conclusion: GVR框架通过将3D视觉定位转化为2D检索任务，避免了昂贵的3D标注和逐场景训练，为零样本3D视觉定位研究提供了坚实基础。

Abstract: 3D Visual Grounding (3DVG) aims to locate objects in 3D scenes based on text
prompts, which is essential for applications such as robotics. However,
existing 3DVG methods encounter two main challenges: first, they struggle to
handle the implicit representation of spatial textures in 3D Gaussian Splatting
(3DGS), making per-scene training indispensable; second, they typically require
larges amounts of labeled data for effective training. To this end, we propose
\underline{G}rounding via \underline{V}iew \underline{R}etrieval (GVR), a novel
zero-shot visual grounding framework for 3DGS to transform 3DVG as a 2D
retrieval task that leverages object-level view retrieval to collect grounding
clues from multiple views, which not only avoids the costly process of 3D
annotation, but also eliminates the need for per-scene training. Extensive
experiments demonstrate that our method achieves state-of-the-art visual
grounding performance while avoiding per-scene training, providing a solid
foundation for zero-shot 3DVG research. Video demos can be found in
https://github.com/leviome/GVR_demos.

</details>


### [86] [ENSAM: an efficient foundation model for interactive segmentation of 3D medical images](https://arxiv.org/abs/2509.15874)
*Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar*

Main category: cs.CV

TL;DR: ENSAM是一个轻量级、可提示的3D医学图像分割模型，在有限资源下表现优异，部分指标超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 设计一个轻量级且可提示的通用3D医学图像分割模型，以在有限数据和计算预算下实现良好性能。

Method: ENSAM结合了SegResNet基础的编码器、提示编码器和掩码解码器，采用U-Net风格架构，并利用潜在交叉注意力、相对位置编码、归一化注意力及Muon优化器进行训练。

Result: ENSAM在CVPR 2025挑战赛中表现优异，DSC AUC为2.404，NSD AUC为2.266，最终DSC为0.627，最终NSD为0.597，超越了部分基线模型。

Conclusion: ENSAM在有限的资源和数据条件下表现出色，尤其在多模态3D医学图像分割任务中，其性能超越了部分已有基线模型，并在不使用预训练权重的方法中表现最佳。

Abstract: We present ENSAM (Equivariant, Normalized, Segment Anything Model), a
lightweight and promptable model for universal 3D medical image segmentation.
ENSAM combines a SegResNet-based encoder with a prompt encoder and mask decoder
in a U-Net-style architecture, using latent cross-attention, relative
positional encoding, normalized attention, and the Muon optimizer for training.
ENSAM is designed to achieve good performance under limited data and
computational budgets, and is trained from scratch on under 5,000 volumes from
multiple modalities (CT, MRI, PET, ultrasound, microscopy) on a single 32 GB
GPU in 6 hours. As part of the CVPR 2025 Foundation Models for Interactive 3D
Biomedical Image Segmentation Challenge, ENSAM was evaluated on hidden test set
with multimodal 3D medical images, obtaining a DSC AUC of 2.404, NSD AUC of
2.266, final DSC of 0.627, and final NSD of 0.597, outperforming two previously
published baseline models (VISTA3D, SAM-Med3D) and matching the third (SegVol),
surpassing its performance in final DSC but trailing behind in the other three
metrics. In the coreset track of the challenge, ENSAM ranks 5th of 10 overall
and best among the approaches not utilizing pretrained weights. Ablation
studies confirm that our use of relative positional encodings and the Muon
optimizer each substantially speed up convergence and improve segmentation
quality.

</details>


### [87] [RangeSAM: Leveraging Visual Foundation Models for Range-View repesented LiDAR segmentation](https://arxiv.org/abs/2509.15886)
*Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Dieter Fellner,Saptarshi Neil Sinha*

Main category: cs.CV

TL;DR: The paper proposes a range-view framework using SAM2 for LiDAR point cloud segmentation, achieving competitive results with efficient 2D feature extraction and architectural optimizations.


<details>
  <summary>Details</summary>
Motivation: The research is motivated by the computational inefficiencies of voxel- and point-based methods and the potential of range-view methods to leverage mature 2D semantic segmentation techniques for fast and accurate predictions. The rapid progress in Visual Foundation Models (VFMs) also inspired the investigation into their applicability for LiDAR point cloud segmentation.

Method: The study adapts SAM2, a state-of-the-art VFM, to 3D segmentation by coupling efficient 2D feature extraction with standard projection/back-projection. It introduces several architectural modifications to the encoder, including a novel module for horizontal spatial dependencies, a customized configuration for spherical projections, and an adapted mechanism for range-view pseudo-images.

Result: The approach achieves competitive performance on SemanticKITTI, benefiting from the speed, scalability, and deployment simplicity of 2D-centric pipelines.

Conclusion: Range-view segmentation methods using Visual Foundation Models (VFMs) yield promising results, highlighting their viability as general-purpose backbones for 3D perception and opening a path toward unified, foundation-model-driven LiDAR segmentation.

Abstract: Point cloud segmentation is central to autonomous driving and 3D scene
understanding. While voxel- and point-based methods dominate recent research
due to their compatibility with deep architectures and ability to capture
fine-grained geometry, they often incur high computational cost, irregular
memory access, and limited real-time efficiency. In contrast, range-view
methods, though relatively underexplored - can leverage mature 2D semantic
segmentation techniques for fast and accurate predictions. Motivated by the
rapid progress in Visual Foundation Models (VFMs) for captioning, zero-shot
recognition, and multimodal tasks, we investigate whether SAM2, the current
state-of-the-art VFM for segmentation tasks, can serve as a strong backbone for
LiDAR point cloud segmentation in the range view. We present , to our
knowledge, the first range-view framework that adapts SAM2 to 3D segmentation,
coupling efficient 2D feature extraction with standard
projection/back-projection to operate on point clouds. To optimize SAM2 for
range-view representations, we implement several architectural modifications to
the encoder: (1) a novel module that emphasizes horizontal spatial dependencies
inherent in LiDAR range images, (2) a customized configuration of tailored to
the geometric properties of spherical projections, and (3) an adapted mechanism
in the encoder backbone specifically designed to capture the unique spatial
patterns and discontinuities present in range-view pseudo-images. Our approach
achieves competitive performance on SemanticKITTI while benefiting from the
speed, scalability, and deployment simplicity of 2D-centric pipelines. This
work highlights the viability of VFMs as general-purpose backbones for 3D
perception and opens a path toward unified, foundation-model-driven LiDAR
segmentation. Results lets us conclude that range-view segmentation methods
using VFMs leads to promising results.

</details>


### [88] [Global Regulation and Excitation via Attention Tuning for Stereo Matching](https://arxiv.org/abs/2509.15891)
*Jiahao Li,Xinhong Chen,Zhengmin Jiang,Qian Zhou,Yung-Hui Li,Jianping Wang*

Main category: cs.CV

TL;DR: GREAT框架通过三种注意力模块提升迭代立体匹配算法的全局上下文和几何信息处理能力，在多个基准测试中取得领先成绩。


<details>
  <summary>Details</summary>
Motivation: 现有迭代立体匹配算法在遮挡、无纹理或重复模式等复杂区域表现不佳，缺乏全局上下文和几何信息。

Method: 提出了Global Regulation and Excitation via Attention Tuning (GREAT)框架，包含Spatial Attention (SA)、Matching Attention (MA)和Volume Attention (VA)三个模块，分别从空间维度、极线维度和成本体积中提取全局上下文和几何细节。

Result: GREAT框架在多个基准测试中表现优异，GREAT-IGEV在Scene Flow、KITTI 2015和ETH3D上排名第一，在Middlebury上排名第二。

Conclusion: GREAT框架通过引入三种注意力模块（SA、MA、VA）显著提升了迭代立体匹配算法在复杂区域的性能，并在多个基准测试中取得了领先成绩。

Abstract: Stereo matching achieves significant progress with iterative algorithms like
RAFT-Stereo and IGEV-Stereo. However, these methods struggle in ill-posed
regions with occlusions, textureless, or repetitive patterns, due to a lack of
global context and geometric information for effective iterative refinement. To
enable the existing iterative approaches to incorporate global context, we
propose the Global Regulation and Excitation via Attention Tuning (GREAT)
framework which encompasses three attention modules. Specifically, Spatial
Attention (SA) captures the global context within the spatial dimension,
Matching Attention (MA) extracts global context along epipolar lines, and
Volume Attention (VA) works in conjunction with SA and MA to construct a more
robust cost-volume excited by global context and geometric details. To verify
the universality and effectiveness of this framework, we integrate it into
several representative iterative stereo-matching methods and validate it
through extensive experiments, collectively denoted as GREAT-Stereo. This
framework demonstrates superior performance in challenging ill-posed regions.
Applied to IGEV-Stereo, among all published methods, our GREAT-IGEV ranks first
on the Scene Flow test set, KITTI 2015, and ETH3D leaderboards, and achieves
second on the Middlebury benchmark. Code is available at
https://github.com/JarvisLee0423/GREAT-Stereo.

</details>


### [89] [Deep Feedback Models](https://arxiv.org/abs/2509.15905)
*David Calhas,Arlindo L. Oliveira*

Main category: cs.CV

TL;DR: DFMs通过反馈机制提升神经网络在噪声和数据有限情况下的性能，适用于医学影像等场景。


<details>
  <summary>Details</summary>
Motivation: 探索反馈机制如何增强神经网络的动态性和生物决策模拟能力，特别是在噪声鲁棒性和数据有限情况下的泛化能力。

Method: 将反馈过程建模为通过循环神经网络求解的微分方程，并通过指数衰减稳定以确保收敛。

Result: 在物体识别和分割任务中，DFMs在低数据或高噪声条件下持续优于前馈网络，并在医学影像中表现出色。

Conclusion: DFMs通过反馈机制实现了稳定、鲁棒和可泛化的学习，尤其在数据有限或噪声高的场景下表现优异。

Abstract: Deep Feedback Models (DFMs) are a new class of stateful neural networks that
combine bottom up input with high level representations over time. This
feedback mechanism introduces dynamics into otherwise static architectures,
enabling DFMs to iteratively refine their internal state and mimic aspects of
biological decision making. We model this process as a differential equation
solved through a recurrent neural network, stabilized via exponential decay to
ensure convergence. To evaluate their effectiveness, we measure DFMs under two
key conditions: robustness to noise and generalization with limited data. In
both object recognition and segmentation tasks, DFMs consistently outperform
their feedforward counterparts, particularly in low data or high noise regimes.
In addition, DFMs translate to medical imaging settings, while being robust
against various types of noise corruption. These findings highlight the
importance of feedback in achieving stable, robust, and generalizable learning.
Code is available at https://github.com/DCalhas/deep_feedback_models.

</details>


### [90] [Sparse Multiview Open-Vocabulary 3D Detection](https://arxiv.org/abs/2509.15924)
*Olivier Moliner,Viktor Larsson,Kalle Åström*

Main category: cs.CV

TL;DR: 该论文提出了一种无需训练的开放词汇3D物体检测方法，利用2D基础模型在稀疏视图中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统3D物体检测方法通常局限于固定类别，限制了其应用范围。本研究旨在探索稀疏视图下的开放词汇3D物体检测，以提升实用性。

Method: 研究采用训练免费的方法，依赖于预训练的2D基础模型，通过提升2D检测结果并优化3D提案的特征度量一致性。

Result: 该方法在标准基准测试中表现优异，尤其在稀疏视图设置中显著优于现有技术。

Conclusion: 该研究通过利用预训练的2D基础模型和特征度量一致性优化，提出了一种无需训练的开放词汇3D物体检测方法，在稀疏视图设置中表现出色。

Abstract: The ability to interpret and comprehend a 3D scene is essential for many
vision and robotics systems. In numerous applications, this involves 3D object
detection, i.e.~identifying the location and dimensions of objects belonging to
a specific category, typically represented as bounding boxes. This has
traditionally been solved by training to detect a fixed set of categories,
which limits its use. In this work, we investigate open-vocabulary 3D object
detection in the challenging yet practical sparse-view setting, where only a
limited number of posed RGB images are available as input. Our approach is
training-free, relying on pre-trained, off-the-shelf 2D foundation models
instead of employing computationally expensive 3D feature fusion or requiring
3D-specific learning. By lifting 2D detections and directly optimizing 3D
proposals for featuremetric consistency across views, we fully leverage the
extensive training data available in 2D compared to 3D. Through standard
benchmarks, we demonstrate that this simple pipeline establishes a powerful
baseline, performing competitively with state-of-the-art techniques in densely
sampled scenarios while significantly outperforming them in the sparse-view
setting.

</details>


### [91] [PAN: Pillars-Attention-Based Network for 3D Object Detection](https://arxiv.org/abs/2509.15935)
*Ruan Bispo,Dane Mitrev,Letizia Mariotti,Clément Botty,Denver Humphrey,Anthony Scanlan,Ciarán Eising*

Main category: cs.CV

TL;DR: 提出了一种高效相机-雷达融合的3D物体检测算法，通过新骨干网络和简化卷积层，在性能和推理时间上均达到新标杆。


<details>
  <summary>Details</summary>
Motivation: 当前文献中关于相机-雷达融合的研究较少，且缺乏探索雷达点云优势（如精确距离估计和速度信息）的新架构。因此，本研究旨在填补这一空白。

Method: 引入了一种新的骨干网络，将雷达点云特征映射到嵌入维度，并采用自注意力机制建模雷达点之间的依赖关系。此外，使用简化的卷积层替代了基于FPN的卷积层，以减少推理时间。

Result: 该算法在nuScenes数据集上达到了58.2的NDS指标（使用ResNet-50），并在推理时间上创下了同类算法的新纪录。

Conclusion: 该研究提出了一种新型高效的3D物体检测算法，结合相机和雷达数据，在鸟瞰视图（BEV）中实现了新的性能标杆，并显著降低了推理时间。

Abstract: Camera-radar fusion offers a robust and low-cost alternative to Camera-lidar
fusion for the 3D object detection task in real-time under adverse weather and
lighting conditions. However, currently, in the literature, it is possible to
find few works focusing on this modality and, most importantly, developing new
architectures to explore the advantages of the radar point cloud, such as
accurate distance estimation and speed information. Therefore, this work
presents a novel and efficient 3D object detection algorithm using cameras and
radars in the bird's-eye-view (BEV). Our algorithm exploits the advantages of
radar before fusing the features into a detection head. A new backbone is
introduced, which maps the radar pillar features into an embedded dimension. A
self-attention mechanism allows the backbone to model the dependencies between
the radar points. We are using a simplified convolutional layer to replace the
FPN-based convolutional layers used in the PointPillars-based architectures
with the main goal of reducing inference time. Our results show that with this
modification, our approach achieves the new state-of-the-art in the 3D object
detection problem, reaching 58.2 of the NDS metric for the use of ResNet-50,
while also setting a new benchmark for inference time on the nuScenes dataset
for the same category.

</details>


### [92] [A multi-temporal multi-spectral attention-augmented deep convolution neural network with contrastive learning for crop yield prediction](https://arxiv.org/abs/2509.15966)
*Shalini Dangi,Surya Karthikeya Mullapudi,Chandravardhan Singh Raghaw,Shahid Shafi Dar,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

TL;DR: MTMS-YieldNet通过整合多光谱与时空数据，显著提升作物产量预测精度，优于现有方法，为农业决策提供支持。


<details>
  <summary>Details</summary>
Motivation: 气候变化影响了天气条件、土壤肥力和农场管理系统等主要因素，使得精确的产量预测变得复杂。技术进步通过卫星监测和数据分析为精确产量估算提供了支持。

Method: 提出了一种新颖的多时相多光谱产量预测网络MTMS-YieldNet，利用对比学习在预训练中捕捉空间-光谱模式和时空依赖性。

Result: MTMS-YieldNet在Sentinel-1、Landsat-8和Sentinel-2上的MAPE分数分别为0.336、0.353和0.331，优于七种现有最先进方法。

Conclusion: MTMS-YieldNet通过整合多光谱数据与时空信息，显著提高了作物产量预测的准确性，为农民决策提供了有价值的见解，有望改善作物产量。

Abstract: Precise yield prediction is essential for agricultural sustainability and
food security. However, climate change complicates accurate yield prediction by
affecting major factors such as weather conditions, soil fertility, and farm
management systems. Advances in technology have played an essential role in
overcoming these challenges by leveraging satellite monitoring and data
analysis for precise yield estimation. Current methods rely on spatio-temporal
data for predicting crop yield, but they often struggle with multi-spectral
data, which is crucial for evaluating crop health and growth patterns. To
resolve this challenge, we propose a novel Multi-Temporal Multi-Spectral Yield
Prediction Network, MTMS-YieldNet, that integrates spectral data with
spatio-temporal information to effectively capture the correlations and
dependencies between them. While existing methods that rely on pre-trained
models trained on general visual data, MTMS-YieldNet utilizes contrastive
learning for feature discrimination during pre-training, focusing on capturing
spatial-spectral patterns and spatio-temporal dependencies from remote sensing
data. Both quantitative and qualitative assessments highlight the excellence of
the proposed MTMS-YieldNet over seven existing state-of-the-art methods.
MTMS-YieldNet achieves MAPE scores of 0.336 on Sentinel-1, 0.353 on Landsat-8,
and an outstanding 0.331 on Sentinel-2, demonstrating effective yield
prediction performance across diverse climatic and seasonal conditions. The
outstanding performance of MTMS-YieldNet improves yield predictions and
provides valuable insights that can assist farmers in making better decisions,
potentially improving crop yields.

</details>


### [93] [DAFTED: Decoupled Asymmetric Fusion of Tabular and Echocardiographic Data for Cardiac Hypertension Diagnosis](https://arxiv.org/abs/2509.15990)
*Jérémie Stym-Popper,Nathan Painchaud,Clément Rambour,Pierre-Yves Courand,Nicolas Thome,Olivier Bernard*

Main category: cs.CV

TL;DR: 提出一种非对称多模态融合策略，通过解耦信息提升医学诊断性能，实验显示AUC超过90%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态数据融合是提升医学诊断的关键方法，现有方法在性能上仍有提升空间。

Method: 采用从主要模态出发的非对称融合策略，通过解耦共享和模态特定信息来整合次要模态。

Result: 在239名患者的超声心动图时间序列和表格记录数据集上验证，模型性能优于现有方法，AUC超过90%。

Conclusion: 该研究提出的非对称融合策略在医学应用中显著提升了诊断性能，AUC超过90%，为临床使用设定了重要基准。

Abstract: Multimodal data fusion is a key approach for enhancing diagnosis in medical
applications. We propose an asymmetric fusion strategy starting from a primary
modality and integrating secondary modalities by disentangling shared and
modality-specific information. Validated on a dataset of 239 patients with
echocardiographic time series and tabular records, our model outperforms
existing methods, achieving an AUC over 90%. This improvement marks a crucial
benchmark for clinical use.

</details>


### [94] [Towards Robust Visual Continual Learning with Multi-Prototype Supervision](https://arxiv.org/abs/2509.16011)
*Xiwei Liu,Yulong Li,Yichen Li,Xinlin Zhuang,Haolin Yang,Huifa Li,Imran Razzak*

Main category: cs.CV

TL;DR: MuproCL提出多原型框架，解决语言引导持续学习中的语义模糊和视觉多样性问题，通过LLM生成多原型并自适应对齐，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统语言引导监督中单一目标带来的语义模糊性和类内视觉多样性问题。

Method: 使用轻量级LLM代理进行类别消歧和视觉模态扩展，生成一组鲁棒的语义原型，并通过LogSumExp聚合机制使视觉模型自适应地对齐最相关的原型。

Result: 在各种持续学习基准测试中，MuproCL一致显示出性能提升和更强的鲁棒性。

Conclusion: MuproCL通过引入多原型机制，显著提升了语言引导持续学习的性能和鲁棒性，为视觉持续学习提供了更有效的路径。

Abstract: Language-guided supervision, which utilizes a frozen semantic target from a
Pretrained Language Model (PLM), has emerged as a promising paradigm for visual
Continual Learning (CL). However, relying on a single target introduces two
critical limitations: 1) semantic ambiguity, where a polysemous category name
results in conflicting visual representations, and 2) intra-class visual
diversity, where a single prototype fails to capture the rich variety of visual
appearances within a class. To this end, we propose MuproCL, a novel framework
that replaces the single target with multiple, context-aware prototypes.
Specifically, we employ a lightweight LLM agent to perform category
disambiguation and visual-modal expansion to generate a robust set of semantic
prototypes. A LogSumExp aggregation mechanism allows the vision model to
adaptively align with the most relevant prototype for a given image. Extensive
experiments across various CL baselines demonstrate that MuproCL consistently
enhances performance and robustness, establishing a more effective path for
language-guided continual learning.

</details>


### [95] [DistillMatch: Leveraging Knowledge Distillation from Vision Foundation Model for Multimodal Image Matching](https://arxiv.org/abs/2509.16017)
*Meng Yang,Fan Fan,Zizhuo Li,Songchu Deng,Yong Ma,Jiayi Ma*

Main category: cs.CV

TL;DR: DistillMatch利用VFM知识蒸馏和多模态特征增强，显著提升跨模态图像匹配性能。


<details>
  <summary>Details</summary>
Motivation: 跨模态图像匹配在多模态感知、融合和分析中至关重要，但由于模态间外观差异显著且高质量标注数据稀缺，现有深度学习方法表现不佳且缺乏适应性。

Method: 提出DistillMatch方法，利用VFM（如DINOv2和DINOv3）进行知识蒸馏，构建轻量级学生模型提取高层次语义特征，并通过注入模态类别信息和V2I-GAN数据增强提升模型泛化能力。

Result: DistillMatch在公开数据集上表现优于现有算法。

Conclusion: DistillMatch通过知识蒸馏和多模态特征增强，显著提升了跨模态图像匹配的性能，并在公开数据集上超越了现有算法。

Abstract: Multimodal image matching seeks pixel-level correspondences between images of
different modalities, crucial for cross-modal perception, fusion and analysis.
However, the significant appearance differences between modalities make this
task challenging. Due to the scarcity of high-quality annotated datasets,
existing deep learning methods that extract modality-common features for
matching perform poorly and lack adaptability to diverse scenarios. Vision
Foundation Model (VFM), trained on large-scale data, yields generalizable and
robust feature representations adapted to data and tasks of various modalities,
including multimodal matching. Thus, we propose DistillMatch, a multimodal
image matching method using knowledge distillation from VFM. DistillMatch
employs knowledge distillation to build a lightweight student model that
extracts high-level semantic features from VFM (including DINOv2 and DINOv3) to
assist matching across modalities. To retain modality-specific information, it
extracts and injects modality category information into the other modality's
features, which enhances the model's understanding of cross-modal correlations.
Furthermore, we design V2I-GAN to boost the model's generalization by
translating visible to pseudo-infrared images for data augmentation.
Experiments show that DistillMatch outperforms existing algorithms on public
datasets.

</details>


### [96] [Generalized Deep Multi-view Clustering via Causal Learning with Partially Aligned Cross-view Correspondence](https://arxiv.org/abs/2509.16022)
*Xihong Yang,Siwei Wang,Jiaqi Jin,Fangdi Wang,Tianrui Liu,Yueming Jin,Xinwang Liu,En Zhu,Kunlun He*

Main category: cs.CV

TL;DR: 本文提出CauMVC框架，通过因果学习解决部分对齐多视图聚类问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中多视图数据往往仅部分对齐，传统方法依赖完全对齐假设，导致性能下降。本文旨在通过因果学习解决这一广义多视图聚类问题。

Method: 采用因果建模方法，设计了包含变分自编码器的因果学习框架，通过编码器估计不变特征，解码器进行干预后推理，并结合对比正则化器捕捉样本相关性。

Result: 实验表明，CauMVC在完全和部分对齐数据上均表现出强大的泛化能力和有效性。

Conclusion: 本文提出了一种基于因果学习的多视图聚类方法CauMVC，有效解决了部分对齐数据下的聚类性能下降问题，并通过实验验证了其优越性和泛化能力。

Abstract: Multi-view clustering (MVC) aims to explore the common clustering structure
across multiple views. Many existing MVC methods heavily rely on the assumption
of view consistency, where alignments for corresponding samples across
different views are ordered in advance. However, real-world scenarios often
present a challenge as only partial data is consistently aligned across
different views, restricting the overall clustering performance. In this work,
we consider the model performance decreasing phenomenon caused by data order
shift (i.e., from fully to partially aligned) as a generalized multi-view
clustering problem. To tackle this problem, we design a causal multi-view
clustering network, termed CauMVC. We adopt a causal modeling approach to
understand multi-view clustering procedure. To be specific, we formulate the
partially aligned data as an intervention and multi-view clustering with
partially aligned data as an post-intervention inference. However, obtaining
invariant features directly can be challenging. Thus, we design a Variational
Auto-Encoder for causal learning by incorporating an encoder from existing
information to estimate the invariant features. Moreover, a decoder is designed
to perform the post-intervention inference. Lastly, we design a contrastive
regularizer to capture sample correlations. To the best of our knowledge, this
paper is the first work to deal generalized multi-view clustering via causal
learning. Empirical experiments on both fully and partially aligned data
illustrate the strong generalization and effectiveness of CauMVC.

</details>


### [97] [GLip: A Global-Local Integrated Progressive Framework for Robust Visual Speech Recognition](https://arxiv.org/abs/2509.16031)
*Tianyue Wang,Shuang Yang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: GLip是一个全局-局部集成的渐进式框架，通过双路径特征提取和两阶段学习提升视觉语音识别的鲁棒性，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有VSR方法对现实世界中的光照变化、遮挡、模糊和姿态变化等视觉挑战关注不足，GLip旨在解决这些问题。

Method: GLip采用双路径特征提取架构，结合全局和局部特征，通过两阶段渐进学习框架（初始粗对齐和上下文增强模块）优化视觉-语音映射。

Result: GLip在LRS2、LRS3基准测试和新提出的中文数据集上均优于现有方法，表现出更强的鲁棒性。

Conclusion: GLip框架通过全局-局部双路径特征提取和渐进式学习策略，显著提升了视觉语音识别的鲁棒性，在多个基准测试中表现优异。

Abstract: Visual speech recognition (VSR), also known as lip reading, is the task of
recognizing speech from silent video. Despite significant advancements in VSR
over recent decades, most existing methods pay limited attention to real-world
visual challenges such as illumination variations, occlusions, blurring, and
pose changes. To address these challenges, we propose GLip, a Global-Local
Integrated Progressive framework designed for robust VSR. GLip is built upon
two key insights: (i) learning an initial \textit{coarse} alignment between
visual features across varying conditions and corresponding speech content
facilitates the subsequent learning of \textit{precise} visual-to-speech
mappings in challenging environments; (ii) under adverse conditions, certain
local regions (e.g., non-occluded areas) often exhibit more discriminative cues
for lip reading than global features. To this end, GLip introduces a dual-path
feature extraction architecture that integrates both global and local features
within a two-stage progressive learning framework. In the first stage, the
model learns to align both global and local visual features with corresponding
acoustic speech units using easily accessible audio-visual data, establishing a
coarse yet semantically robust foundation. In the second stage, we introduce a
Contextual Enhancement Module (CEM) to dynamically integrate local features
with relevant global context across both spatial and temporal dimensions,
refining the coarse representations into precise visual-speech mappings. Our
framework uniquely exploits discriminative local regions through a progressive
learning strategy, demonstrating enhanced robustness against various visual
challenges and consistently outperforming existing methods on the LRS2 and LRS3
benchmarks. We further validate its effectiveness on a newly introduced
challenging Mandarin dataset.

</details>


### [98] [Graph-based Point Cloud Surface Reconstruction using B-Splines](https://arxiv.org/abs/2509.16050)
*Stuti Pathak,Rhys G. Evans,Gunther Steenackers,Rudi Penne*

Main category: cs.CV

TL;DR: 提出了一种基于字典引导图卷积网络的表面重建方法，无需点法线即可为噪声点云生成平滑表面，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的点云数据因技术和环境因素而存在噪声，现有方法依赖真实法线或近似法线作为中间步骤，对噪声数据不可靠。B样条重建技术虽能提供紧凑的表面表示，但其表面复杂度受控制点数量和位置的直接影响，现有方法难以匹配底层表面的复杂性。

Method: 采用字典引导的图卷积网络（Dictionary-Guided Graph Convolutional Network）策略，同时预测控制点的位置和数量，以生成平滑表面。

Result: 通过广泛使用的评估指标与多个知名及近期基线方法进行比较，证明该方法在质量和数量上均优于所有基线。

Conclusion: 本论文提出的基于字典引导图卷积网络的表面重建策略，在无需点法线的情况下，通过同时预测控制点的位置和数量，能够为噪声点云数据生成平滑表面，且在质量和数量上均优于现有基线方法。

Abstract: Generating continuous surfaces from discrete point cloud data is a
fundamental task in several 3D vision applications. Real-world point clouds are
inherently noisy due to various technical and environmental factors. Existing
data-driven surface reconstruction algorithms rely heavily on ground truth
normals or compute approximate normals as an intermediate step. This dependency
makes them extremely unreliable for noisy point cloud datasets, even if the
availability of ground truth training data is ensured, which is not always the
case. B-spline reconstruction techniques provide compact surface
representations of point clouds and are especially known for their smoothening
properties. However, the complexity of the surfaces approximated using
B-splines is directly influenced by the number and location of the spline
control points. Existing spline-based modeling methods predict the locations of
a fixed number of control points for a given point cloud, which makes it very
difficult to match the complexity of its underlying surface. In this work, we
develop a Dictionary-Guided Graph Convolutional Network-based surface
reconstruction strategy where we simultaneously predict both the location and
the number of control points for noisy point cloud data to generate smooth
surfaces without the use of any point normals. We compare our reconstruction
method with several well-known as well as recent baselines by employing
widely-used evaluation metrics, and demonstrate that our method outperforms all
of them both qualitatively and quantitatively.

</details>


### [99] [Language-Instructed Reasoning for Group Activity Detection via Multimodal Large Language Model](https://arxiv.org/abs/2509.16054)
*Jihua Peng,Qianxiong Xu,Yichen Liu,Chenxi Liu,Cheng Long,Rui Zhao,Ziyue Li*

Main category: cs.CV

TL;DR: LIR-GAD利用MLLM和特别设计的token提升群体活动检测性能，通过MDAF模块融合多模态特征，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖视觉特征的隐式模式识别，缺乏上下文推理和可解释性，需改进。

Method: 提出LIR-GAD框架，扩展MLLM的词汇表，引入<ACT>和<GROUP> token，设计MDAF模块融合视觉特征和MLLM隐藏嵌入。

Result: 实验证明LIR-GAD在群体活动检测任务中表现优越。

Conclusion: LIR-GAD框架通过引入MLLM和特别设计的token，显著提升了群体活动检测的性能，并通过定量和定性实验验证了其优越性。

Abstract: Group activity detection (GAD) aims to simultaneously identify group members
and categorize their collective activities within video sequences. Existing
deep learning-based methods develop specialized architectures (e.g.,
transformer networks) to model the dynamics of individual roles and semantic
dependencies between individuals and groups. However, they rely solely on
implicit pattern recognition from visual features and struggle with contextual
reasoning and explainability. In this work, we propose LIR-GAD, a novel
framework of language-instructed reasoning for GAD via Multimodal Large
Language Model (MLLM). Our approach expand the original vocabulary of MLLM by
introducing an activity-level <ACT> token and multiple cluster-specific <GROUP>
tokens. We process video frames alongside two specially designed tokens and
language instructions, which are then integrated into the MLLM. The pretrained
commonsense knowledge embedded in the MLLM enables the <ACT> token and <GROUP>
tokens to effectively capture the semantic information of collective activities
and learn distinct representational features of different groups, respectively.
Also, we introduce a multi-label classification loss to further enhance the
<ACT> token's ability to learn discriminative semantic representations. Then,
we design a Multimodal Dual-Alignment Fusion (MDAF) module that integrates
MLLM's hidden embeddings corresponding to the designed tokens with visual
features, significantly enhancing the performance of GAD. Both quantitative and
qualitative experiments demonstrate the superior performance of our proposed
method in GAD taks.

</details>


### [100] [Blind-Spot Guided Diffusion for Self-supervised Real-World Denoising](https://arxiv.org/abs/2509.16091)
*Shen Cheng,Haipeng Li,Haibin Huang,Xiaohong Liu,Shuaicheng Liu*

Main category: cs.CV

TL;DR: Blind-Spot Guided Diffusion 是一种自监督图像去噪方法，结合盲点网络和扩散模型，无需配对数据，性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决盲点网络（BSNs）在局部细节和像素连续性上的局限性，以及扩散模型在自监督去噪中的适应难题。

Method: 采用双分支扩散框架，结合基于盲点网络的扩散分支和常规扩散分支，前者生成半干净图像，后者捕捉噪声分布。通过盲点网络分支引导采样过程，有效训练无需配对数据。

Result: 在SIDD和DND数据集上的广泛实验表明，该方法具有最先进的性能。

Conclusion: Blind-Spot Guided Diffusion 提出了一种新颖的自监督框架，用于真实世界图像去噪，通过结合盲点网络和扩散模型的优势，实现了最先进的性能。

Abstract: In this work, we present Blind-Spot Guided Diffusion, a novel self-supervised
framework for real-world image denoising. Our approach addresses two major
challenges: the limitations of blind-spot networks (BSNs), which often
sacrifice local detail and introduce pixel discontinuities due to spatial
independence assumptions, and the difficulty of adapting diffusion models to
self-supervised denoising. We propose a dual-branch diffusion framework that
combines a BSN-based diffusion branch, generating semi-clean images, with a
conventional diffusion branch that captures underlying noise distributions. To
enable effective training without paired data, we use the BSN-based branch to
guide the sampling process, capturing noise structure while preserving local
details. Extensive experiments on the SIDD and DND datasets demonstrate
state-of-the-art performance, establishing our method as a highly effective
self-supervised solution for real-world denoising. Code and pre-trained models
are released at: https://github.com/Sumching/BSGD.

</details>


### [101] [AdaSports-Traj: Role- and Domain-Aware Adaptation for Multi-Agent Trajectory Modeling in Sports](https://arxiv.org/abs/2509.16095)
*Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: AdaSports-Traj通过自适应角色和领域感知设计，解决了多智能体运动轨迹预测中的分布差异问题，提升了跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体运动场景中因角色和领域差异导致的轨迹预测挑战，现有统一框架未能有效捕捉这些分布差异。

Method: 提出AdaSports-Traj框架，包含角色和领域感知适配器及分层对比学习目标，以调整潜在表示并监督解耦的潜在结构。

Result: 在Basketball-U、Football-U和Soccer-U三个数据集上验证了框架的有效性，在统一和跨域预测设置中均表现优异。

Conclusion: AdaSports-Traj通过自适应轨迹建模框架显著提升了多智能体运动场景中的轨迹预测性能，特别是在跨角色和跨领域的泛化能力上。

Abstract: Trajectory prediction in multi-agent sports scenarios is inherently
challenging due to the structural heterogeneity across agent roles (e.g.,
players vs. ball) and dynamic distribution gaps across different sports
domains. Existing unified frameworks often fail to capture these structured
distributional shifts, resulting in suboptimal generalization across roles and
domains. We propose AdaSports-Traj, an adaptive trajectory modeling framework
that explicitly addresses both intra-domain and inter-domain distribution
discrepancies in sports. At its core, AdaSports-Traj incorporates a Role- and
Domain-Aware Adapter to conditionally adjust latent representations based on
agent identity and domain context. Additionally, we introduce a Hierarchical
Contrastive Learning objective, which separately supervises role-sensitive and
domain-aware representations to encourage disentangled latent structures
without introducing optimization conflict. Experiments on three diverse sports
datasets, Basketball-U, Football-U, and Soccer-U, demonstrate the effectiveness
of our adaptive design, achieving strong performance in both unified and
cross-domain trajectory prediction settings.

</details>


### [102] [SegDINO3D: 3D Instance Segmentation Empowered by Both Image-Level and Object-Level 2D Features](https://arxiv.org/abs/2509.16098)
*Jinyuan Qu,Hongyang Li,Xingyu Chen,Shilong Liu,Yukai Shi,Tianhe Ren,Ruitao Jing,Lei Zhang*

Main category: cs.CV

TL;DR: SegDINO3D是一个利用2D预训练模型提升3D实例分割性能的Transformer框架，在ScanNet基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于3D训练数据通常不如2D训练图像充足，SegDINO3D旨在充分利用预训练2D检测模型的2D表示，以提升3D表示的质量。

Method: SegDINO3D是一个Transformer编码器-解码器框架，通过利用预训练的2D检测模型的2D表示（包括图像级和对象级特征）来增强3D表示。输入包括点云和关联的2D图像，编码器阶段通过检索2D图像特征丰富3D点，解码器阶段通过3D锚框和跨注意力机制实现3D查询到2D对象查询的转换。

Result: 在ScanNet200数据集上，SegDINO3D在验证集和隐藏测试集上分别比之前方法提升了+8.7和+6.8 mAP。

Conclusion: SegDINO3D在ScanNetV2和ScanNet200 3D实例分割基准测试中实现了最先进的性能，显著优于之前的方法。

Abstract: In this paper, we present SegDINO3D, a novel Transformer encoder-decoder
framework for 3D instance segmentation. As 3D training data is generally not as
sufficient as 2D training images, SegDINO3D is designed to fully leverage 2D
representation from a pre-trained 2D detection model, including both
image-level and object-level features, for improving 3D representation.
SegDINO3D takes both a point cloud and its associated 2D images as input. In
the encoder stage, it first enriches each 3D point by retrieving 2D image
features from its corresponding image views and then leverages a 3D encoder for
3D context fusion. In the decoder stage, it formulates 3D object queries as 3D
anchor boxes and performs cross-attention from 3D queries to 2D object queries
obtained from 2D images using the 2D detection model. These 2D object queries
serve as a compact object-level representation of 2D images, effectively
avoiding the challenge of keeping thousands of image feature maps in the memory
while faithfully preserving the knowledge of the pre-trained 2D model. The
introducing of 3D box queries also enables the model to modulate
cross-attention using the predicted boxes for more precise querying. SegDINO3D
achieves the state-of-the-art performance on the ScanNetV2 and ScanNet200 3D
instance segmentation benchmarks. Notably, on the challenging ScanNet200
dataset, SegDINO3D significantly outperforms prior methods by +8.7 and +6.8 mAP
on the validation and hidden test sets, respectively, demonstrating its
superiority.

</details>


### [103] [RadarGaussianDet3D: An Efficient and Effective Gaussian-based 3D Detector with 4D Automotive Radars](https://arxiv.org/abs/2509.16119)
*Weiyi Xiong,Bing Zhu,Tao Huang,Zewei Zheng*

Main category: cs.CV

TL;DR: RadarGaussianDet3D利用高斯基元和分布提升4D雷达3D检测的精度和速度，适用于自动驾驶实时部署。


<details>
  <summary>Details</summary>
Motivation: 现有4D雷达3D检测器特征稀疏、表示质量差，且推理速度不满足车载嵌入式设备的实时需求。

Method: 提出了一种新型点高斯编码器（PGE）和3D高斯光栅化技术，以及盒高斯损失（BGL），用于优化雷达点和边界框的表示。

Result: 在TJ4DRadSet和View-of-Delft数据集上，RadarGaussianDet3D实现了最先进的检测精度和更快的推理速度。

Conclusion: RadarGaussianDet3D通过高斯基元和分布作为中间表示，显著提升了4D雷达的3D检测精度和推理速度，展示了在自动驾驶实时部署中的潜力。

Abstract: 4D automotive radars have gained increasing attention for autonomous driving
due to their low cost, robustness, and inherent velocity measurement
capability. However, existing 4D radar-based 3D detectors rely heavily on
pillar encoders for BEV feature extraction, where each point contributes to
only a single BEV grid, resulting in sparse feature maps and degraded
representation quality. In addition, they also optimize bounding box attributes
independently, leading to sub-optimal detection accuracy. Moreover, their
inference speed, while sufficient for high-end GPUs, may fail to meet the
real-time requirement on vehicle-mounted embedded devices. To overcome these
limitations, an efficient and effective Gaussian-based 3D detector, namely
RadarGaussianDet3D is introduced, leveraging Gaussian primitives and
distributions as intermediate representations for radar points and bounding
boxes. In RadarGaussianDet3D, a novel Point Gaussian Encoder (PGE) is designed
to transform each point into a Gaussian primitive after feature aggregation and
employs the 3D Gaussian Splatting (3DGS) technique for BEV rasterization,
yielding denser feature maps. PGE exhibits exceptionally low latency, owing to
the optimized algorithm for point feature aggregation and fast rendering of
3DGS. In addition, a new Box Gaussian Loss (BGL) is proposed, which converts
bounding boxes into 3D Gaussian distributions and measures their distance to
enable more comprehensive and consistent optimization. Extensive experiments on
TJ4DRadSet and View-of-Delft demonstrate that RadarGaussianDet3D achieves
state-of-the-art detection accuracy while delivering substantially faster
inference, highlighting its potential for real-time deployment in autonomous
driving.

</details>


### [104] [BaseReward: A Strong Baseline for Multimodal Reward Model](https://arxiv.org/abs/2509.16127)
*Yi-Fan Zhang,Haihua Yang,Huanyu Zhang,Yang Shi,Zezhou Chen,Haochen Tian,Chaoyou Fu,Haotian Wang,Kai Wu,Bo Cui,Xu Wang,Jianfei Pan,Haotian Wang,Zhang Zhang,Liang Wang*

Main category: cs.CV

TL;DR: 本文提供了一个构建高性能多模态奖励模型的系统指南，并提出了BaseReward模型，在多个基准测试中表现优异，同时在实际应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（MLLMs）的快速发展使得与人类偏好对齐成为一个关键挑战。奖励模型（RMs）是实现这一目标的核心技术，但目前学术界和工业界缺乏构建最先进多模态奖励模型（MRMs）的系统指南。

Method: 通过详尽的实验分析，系统地研究了MRM开发流程中的每个关键组件，包括奖励建模范式、奖励头架构、训练策略、数据整理、骨干模型和模型规模以及集成方法。

Result: BaseReward在主要基准测试中建立了新的SOTA，如MM-RLHF-Reward Bench、VL-Reward Bench和Multimodal Reward Bench，超越了之前的模型，并在实际应用中验证了其实用性。

Conclusion: 本文不仅提供了一个高性能的多模态奖励模型BaseReward，还为社区提供了一个清晰、经验支持的指南，用于开发下一代MLLMs的强大奖励模型。

Abstract: The rapid advancement of Multimodal Large Language Models (MLLMs) has made
aligning them with human preferences a critical challenge. Reward Models (RMs)
are a core technology for achieving this goal, but a systematic guide for
building state-of-the-art Multimodal Reward Models (MRMs) is currently lacking
in both academia and industry. Through exhaustive experimental analysis, this
paper aims to provide a clear ``recipe'' for constructing high-performance
MRMs. We systematically investigate every crucial component in the MRM
development pipeline, including \textit{reward modeling paradigms} (e.g.,
Naive-RM, Critic-based RM, and Generative RM), \textit{reward head
architecture}, \textit{training strategies}, \textit{data curation} (covering
over ten multimodal and text-only preference datasets), \textit{backbone model}
and \textit{model scale}, and \textit{ensemble methods}.
  Based on these experimental insights, we introduce \textbf{BaseReward}, a
powerful and efficient baseline for multimodal reward modeling. BaseReward
adopts a simple yet effective architecture, built upon a {Qwen2.5-VL} backbone,
featuring an optimized two-layer reward head, and is trained on a carefully
curated mixture of high-quality multimodal and text-only preference data. Our
results show that BaseReward establishes a new SOTA on major benchmarks such as
MM-RLHF-Reward Bench, VL-Reward Bench, and Multimodal Reward Bench,
outperforming previous models. Furthermore, to validate its practical utility
beyond static benchmarks, we integrate BaseReward into a real-world
reinforcement learning pipeline, successfully enhancing an MLLM's performance
across various perception, reasoning, and conversational tasks. This work not
only delivers a top-tier MRM but, more importantly, provides the community with
a clear, empirically-backed guide for developing robust reward models for the
next generation of MLLMs.

</details>


### [105] [Recovering Parametric Scenes from Very Few Time-of-Flight Pixels](https://arxiv.org/abs/2509.16132)
*Carter Sifferman,Yiquan Li,Yiming Li,Fangzhou Mu,Michael Gleicher,Mohit Gupta,Yin Li*

Main category: cs.CV

TL;DR: 利用低成本单像素飞行时间传感器的详细时间分辨光子计数数据，通过前馈预测和可微分渲染方法，成功从稀疏测量中恢复简单3D参数化场景的几何结构。


<details>
  <summary>Details</summary>
Motivation: 利用低成本飞行时间传感器的稀疏深度测量恢复3D参数化场景的几何结构。

Method: 结合前馈预测和可微分渲染的分析-合成框架，优化场景参数估计。

Result: 成功从少量像素（如15个）恢复简单参数化场景的几何结构，特别是已知物体的6D姿态。

Conclusion: 该方法在仿真和实际控制实验中有效恢复物体姿态，并展示了在其他参数化场景中的潜力。

Abstract: We aim to recover the geometry of 3D parametric scenes using very few depth
measurements from low-cost, commercially available time-of-flight sensors.
These sensors offer very low spatial resolution (i.e., a single pixel), but
image a wide field-of-view per pixel and capture detailed time-of-flight data
in the form of time-resolved photon counts. This time-of-flight data encodes
rich scene information and thus enables recovery of simple scenes from sparse
measurements. We investigate the feasibility of using a distributed set of few
measurements (e.g., as few as 15 pixels) to recover the geometry of simple
parametric scenes with a strong prior, such as estimating the 6D pose of a
known object. To achieve this, we design a method that utilizes both
feed-forward prediction to infer scene parameters, and differentiable rendering
within an analysis-by-synthesis framework to refine the scene parameter
estimate. We develop hardware prototypes and demonstrate that our method
effectively recovers object pose given an untextured 3D model in both
simulations and controlled real-world captures, and show promising initial
results for other parametric scenes. We additionally conduct experiments to
explore the limits and capabilities of our imaging solution.

</details>


### [106] [AcT2I: Evaluating and Improving Action Depiction in Text-to-Image Models](https://arxiv.org/abs/2509.16141)
*Vatsal Malaviya,Agneet Chatterjee,Maitreya Patel,Yezhou Yang,Chitta Baral*

Main category: cs.CV

TL;DR: T2I模型在生成复杂动作场景时表现不佳，作者提出了一种利用大型语言模型增强提示的方法，显著提升了生成图像的准确性和上下文细节。


<details>
  <summary>Details</summary>
Motivation: T2I模型在生成以动作和交互为主要语义焦点的复杂场景时，常因无法捕捉动作描绘中的隐含属性而缺乏关键上下文细节。

Method: 开发了一种无需训练的知识蒸馏技术，利用大型语言模型增强提示信息，特别是通过注入时间细节来提升图像生成准确性。

Result: 实验验证了主流T2I模型在AcT2I基准上表现不佳，但通过增强提示信息（尤其是时间细节），最佳模型图像生成准确率提升了72%。

Conclusion: 当前文本到图像（T2I）模型在生成需要复杂推理的图像时存在局限性，而通过系统性地整合语言知识可以显著提升生成图像的细腻度和上下文准确性。

Abstract: Text-to-Image (T2I) models have recently achieved remarkable success in
generating images from textual descriptions. However, challenges still persist
in accurately rendering complex scenes where actions and interactions form the
primary semantic focus. Our key observation in this work is that T2I models
frequently struggle to capture nuanced and often implicit attributes inherent
in action depiction, leading to generating images that lack key contextual
details. To enable systematic evaluation, we introduce AcT2I, a benchmark
designed to evaluate the performance of T2I models in generating images from
action-centric prompts. We experimentally validate that leading T2I models do
not fare well on AcT2I. We further hypothesize that this shortcoming arises
from the incomplete representation of the inherent attributes and contextual
dependencies in the training corpora of existing T2I models. We build upon this
by developing a training-free, knowledge distillation technique utilizing Large
Language Models to address this limitation. Specifically, we enhance prompts by
incorporating dense information across three dimensions, observing that
injecting prompts with temporal details significantly improves image generation
accuracy, with our best model achieving an increase of 72%. Our findings
highlight the limitations of current T2I methods in generating images that
require complex reasoning and demonstrate that integrating linguistic knowledge
in a systematic way can notably advance the generation of nuanced and
contextually accurate images.

</details>


### [107] [Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal Large Language Models](https://arxiv.org/abs/2509.16149)
*Renjie Pi,Kehao Miao,Li Peihang,Runtao Liu,Jiahui Gao,Jipeng Zhang,Xiaofang Zhou*

Main category: cs.CV

TL;DR: MLLM存在视觉谄媚行为，SRT方法通过反思性推理有效减少该行为，同时避免过度固执。


<details>
  <summary>Details</summary>
Motivation: 观察到MLLM在处理图像输入时表现出明显的视觉谄媚行为（sycophantic modality gap），需解决这一问题。

Method: 提出Sycophantic Reflective Tuning (SRT)，使MLLM能够进行反思性推理，判断用户指令的性质。

Result: SRT显著减少了MLLM对误导性指令的谄媚行为，且未导致对纠正性指令的过度抵抗。

Conclusion: 应用Sycophantic Reflective Tuning (SRT)后，MLLM在误导性指令下的谄媚行为显著减少，同时不会对纠正性指令表现出过度固执。

Abstract: Multimodal large language models (MLLMs) have demonstrated extraordinary
capabilities in conducting conversations based on image inputs. However, we
observe that MLLMs exhibit a pronounced form of visual sycophantic behavior.
While similar behavior has also been noted in text-based large language models
(LLMs), it becomes significantly more prominent when MLLMs process image
inputs. We refer to this phenomenon as the "sycophantic modality gap." To
better understand this issue, we further analyze the factors that contribute to
the exacerbation of this gap. To mitigate the visual sycophantic behavior, we
first experiment with naive supervised fine-tuning to help the MLLM resist
misleading instructions from the user. However, we find that this approach also
makes the MLLM overly resistant to corrective instructions (i.e., stubborn even
if it is wrong). To alleviate this trade-off, we propose Sycophantic Reflective
Tuning (SRT), which enables the MLLM to engage in reflective reasoning,
allowing it to determine whether a user's instruction is misleading or
corrective before drawing a conclusion. After applying SRT, we observe a
significant reduction in sycophantic behavior toward misleading instructions,
without resulting in excessive stubbornness when receiving corrective
instructions.

</details>


### [108] [UniMRSeg: Unified Modality-Relax Segmentation via Hierarchical Self-Supervised Compensation](https://arxiv.org/abs/2509.16170)
*Xiaoqi Zhao,Youwei Pang,Chenyang Yu,Lihe Zhang,Huchuan Lu,Shijian Lu,Georges El Fakhri,Xiaofeng Liu*

Main category: cs.CV

TL;DR: UniMRSeg提出层次自监督补偿方法，显著提升多模态图像分割在缺失模态下的性能，降低部署成本。


<details>
  <summary>Details</summary>
Motivation: 解决多模态图像分割在实际部署中因模态不完整或损坏导致性能下降的问题，同时降低现有方法因需要大量模型子集和模型-模态匹配带来的高部署成本。

Method: 提出了一种统一的模态松弛分割网络（UniMRSeg），通过层次自监督补偿（HSSC）在输入、特征和输出层次上桥接完整与不完整模态之间的表示差距。具体包括混合随机掩码增强的模态重建、模态不变对比学习以及轻量级反向注意力适配器。

Result: UniMRSeg在MRI脑肿瘤分割、RGB-D语义分割和RGB-D/T显著目标分割等多种缺失模态场景下显著优于现有方法。

Conclusion: UniMRSeg通过层次自监督补偿（HSSC）显著提升了多模态图像分割在缺失或损坏模态情况下的性能，且无需大量模型子集和模型-模态匹配，降低了部署成本。

Abstract: Multi-modal image segmentation faces real-world deployment challenges from
incomplete/corrupted modalities degrading performance. While existing methods
address training-inference modality gaps via specialized per-combination
models, they introduce high deployment costs by requiring exhaustive model
subsets and model-modality matching. In this work, we propose a unified
modality-relax segmentation network (UniMRSeg) through hierarchical
self-supervised compensation (HSSC). Our approach hierarchically bridges
representation gaps between complete and incomplete modalities across input,
feature and output levels. % First, we adopt modality reconstruction with the
hybrid shuffled-masking augmentation, encouraging the model to learn the
intrinsic modality characteristics and generate meaningful representations for
missing modalities through cross-modal fusion. % Next, modality-invariant
contrastive learning implicitly compensates the feature space distance among
incomplete-complete modality pairs. Furthermore, the proposed lightweight
reverse attention adapter explicitly compensates for the weak perceptual
semantics in the frozen encoder. Last, UniMRSeg is fine-tuned under the hybrid
consistency constraint to ensure stable prediction under all modality
combinations without large performance fluctuations. Without bells and
whistles, UniMRSeg significantly outperforms the state-of-the-art methods under
diverse missing modality scenarios on MRI-based brain tumor segmentation, RGB-D
semantic segmentation, RGB-D/T salient object segmentation. The code will be
released at https://github.com/Xiaoqi-Zhao-DLUT/UniMRSeg.

</details>


### [109] [MANZANO: A Simple and Scalable Unified Multimodal Model with a Hybrid Vision Tokenizer](https://arxiv.org/abs/2509.16197)
*Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen*

Main category: cs.CV

TL;DR: Manzano是一种统一的多模态大语言模型框架，通过混合图像标记器和统一训练方法，显著降低理解和生成视觉内容之间的性能权衡，实现了与专业模型竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的开源统一多模态大语言模型在理解和生成视觉内容之间存在性能权衡，因此需要一种简单且可扩展的统一框架来减少这种张力。

Method: Manzano采用了一个共享的视觉编码器，该编码器为两个轻量级适配器提供输入，分别生成用于图像到文本理解的连续嵌入和用于文本到图像生成的离散标记，这些操作在一个共同的语义空间中进行。此外，一个统一的自动回归LLM预测高级语义（文本和图像标记），并由辅助扩散解码器将图像标记转换为像素。

Result: Manzano在统一模型中实现了最先进的性能，并与专业模型竞争，特别是在文本丰富的评估中。研究表明，任务冲突最小，且随着模型规模的扩大，性能持续提升。

Conclusion: Manzano通过结合混合图像标记器和精心设计的训练方法，显著降低了统一多模态大语言模型在理解和生成视觉内容之间的性能权衡，实现了与专业模型竞争的性能，特别是在文本丰富的评估中。

Abstract: Unified multimodal Large Language Models (LLMs) that can both understand and
generate visual content hold immense potential. However, existing open-source
models often suffer from a performance trade-off between these capabilities. We
present Manzano, a simple and scalable unified framework that substantially
reduces this tension by coupling a hybrid image tokenizer with a well-curated
training recipe. A single shared vision encoder feeds two lightweight adapters
that produce continuous embeddings for image-to-text understanding and discrete
tokens for text-to-image generation within a common semantic space. A unified
autoregressive LLM predicts high-level semantics in the form of text and image
tokens, with an auxiliary diffusion decoder subsequently translating the image
tokens into pixels. The architecture, together with a unified training recipe
over understanding and generation data, enables scalable joint learning of both
capabilities. Manzano achieves state-of-the-art results among unified models,
and is competitive with specialist models, particularly on text-rich
evaluation. Our studies show minimal task conflicts and consistent gains from
scaling model size, validating our design choice of a hybrid tokenizer.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [110] [PCCL: Photonic circuit-switched collective communication for distributed ML](https://arxiv.org/abs/2509.15450)
*Abhishek Vijaya Kumar,Arjun Devraj,Rachee Singh*

Main category: cs.DC

TL;DR: PCCL通过动态网络拓扑调整优化集体通信，消除拥塞和扩展，在128个GPU上实现3倍加速和1.3倍训练吞吐量提升。


<details>
  <summary>Details</summary>
Motivation: 现代分布式ML中，集体通信算法的理论性能与实际性能存在显著差距，主要由于GPU集群中的拥塞和跳数引起的扩展问题。

Method: PCCL采用硬件无关的优化框架，智能决策网络重新配置时机，以权衡网络重新配置延迟与拥塞/扩展成本，从而适应不同光学硬件的切换速度。

Result: 在128个GPU上，PCCL相比最先进算法实现了高达3倍的加速，并在不同工作负载、缓冲区大小和拓扑结构中表现出色，最终端到端训练吞吐量提升了1.3倍。

Conclusion: PCCL通过动态调整网络拓扑以匹配集体通信算法的通信模式，显著提升了分布式ML的性能，实现了高达3倍的加速，并在不同硬件上表现出良好的适应性。

Abstract: Modern distributed ML suffers from a fundamental gap between the theoretical
and realized performance of collective communication algorithms due to
congestion and hop-count induced dilation in practical GPU clusters. We present
PCCL, a Photonic Collective Communication Library that reconfigures the network
topology to match the communication patterns of collective algorithms, thereby
eliminating congestion and dilation by creating direct, contention-free
circuits between communicating GPUs. Unlike prior approaches that synthesize
algorithms for specific network topologies and collectives, PCCL generalizes to
any collective primitive and any topology by adapting the network to match each
algorithm's communication pattern. PCCL's key innovation lies in its
hardware-agnostic optimization framework that intelligently decides when to
reconfigure based on the trade-off between network reconfiguration delay and
congestion/dilation costs, making it practical across different optical
hardware with varying switching speeds. Our evaluation demonstrates that PCCL
achieves up to 3X speedup over state-of-the-art algorithms on 128 GPUs across
various workloads, buffer sizes, and topologies, translating to a 1.3X speedup
in end-to-end training throughput.

</details>


### [111] [Angelfish: Consensus with Optimal Throughput and Latency Across the Leader-DAG Spectrum](https://arxiv.org/abs/2509.15847)
*Qianyu Yu,Giuliano Losa,Nibesh Shrestha,Xuechao Wang*

Main category: cs.DC

TL;DR: Angelfish是一种混合共识协议，结合了基于领导者和DAG的优点，实现了高吞吐量和低延迟。


<details>
  <summary>Details</summary>
Motivation: 现代区块链系统需要高性能的共识协议，现有协议在延迟和吞吐量之间存在权衡。Angelfish旨在结合基于领导者和基于DAG的协议优点，实现更优性能。

Method: Angelfish采用混合协议设计，允许动态调整的节点子集使用最佳努力广播发出轻量级投票，而非可靠广播昂贵的DAG顶点。

Result: Angelfish在实验中展示了顶尖的峰值吞吐量，同时在中等吞吐量下匹配基于领导者协议的延迟。

Conclusion: Angelfish协议通过动态调整节点子集使用最佳努力广播，实现了低延迟和高吞吐量，结合了基于领导者和基于DAG的共识协议的优点。

Abstract: To maximize performance, many modern blockchain systems rely on
eventually-synchronous, Byzantine fault-tolerant (BFT) consensus protocols. Two
protocol designs have emerged in this space: protocols that minimize latency
using a leader that drives both data dissemination and consensus, and protocols
that maximize throughput using a separate, asynchronous data dissemination
layer. Recent protocols such as Partially-Synchronous Bullshark and Sailfish
combine elements of both approaches by using a DAG to enable parallel data
dissemination and a leader that paces DAG formation. This improves latency
while achieving state-of-the-art throughput. Yet the latency of leader-based
protocols is still better under moderate loads.
  We present Angelfish, a hybrid protocol that adapts smoothly across this
design space, from leader-based to Sailfish-like DAG-based consensus. Angelfish
lets a dynamically-adjusted subset of parties use best-effort broadcast to
issue lightweight votes instead of reliably broadcasting costlier DAG vertices.
This reduces communication, helps lagging nodes catch up, and lowers latency in
practice compared to prior DAG-based protocols. Our empirical evaluation shows
that Angelfish attains state-of-the-art peak throughput while matching the
latency of leader-based protocols under moderate throughput, delivering the
best of both worlds.

</details>


### [112] [Efficient Pre-Training of LLMs via Topology-Aware Communication Alignment on More Than 9600 GPUs](https://arxiv.org/abs/2509.15940)
*Guoliang He,Youhe Jiang,Wencong Xiao,Kaihua Jiang,Shuguang Wang,Jun Wang,Zixian Du,Zhuo Jiang,Xinlei Zhang,Binhang Yuan,Eiko Yoneki*

Main category: cs.DC

TL;DR: Arnold调度系统通过优化通信与拓扑对齐，提升LLM预训练性能，实验性能提升显著。


<details>
  <summary>Details</summary>
Motivation: LLM预训练因复杂的通信模式和资源调度效率低下导致带宽竞争，影响训练性能，亟需一种解决方案。

Method: 通过对物理网络拓扑对LLM预训练作业影响的深入研究，开发了一种调度算法，以优化通信模式与数据中心拓扑的对齐。

Result: 模拟实验显示通信组的最大传播减少1.67倍，生产环境中端到端性能提升10.6%（9600+GPU）。

Conclusion: Arnold调度系统通过有效对齐LLM通信模式与数据中心拓扑结构，显著提升了大规模GPU集群的训练性能，证明了其在生产环境中的实用性。

Abstract: The scaling law for large language models (LLMs) depicts that the path
towards machine intelligence necessitates training at large scale. Thus,
companies continuously build large-scale GPU clusters, and launch training jobs
that span over thousands of computing nodes. However, LLM pre-training presents
unique challenges due to its complex communication patterns, where GPUs
exchange data in sparse yet high-volume bursts within specific groups.
Inefficient resource scheduling exacerbates bandwidth contention, leading to
suboptimal training performance. This paper presents Arnold, a scheduling
system summarizing our experience to effectively align LLM communication
patterns with data center topology at scale. An in-depth characteristic study
is performed to identify the impact of physical network topology to LLM
pre-training jobs. Based on the insights, we develop a scheduling algorithm to
effectively align communication patterns with the physical network topology in
modern data centers. Through simulation experiments, we show the effectiveness
of our algorithm in reducing the maximum spread of communication groups by up
to $1.67$x. In production training, our scheduling system improves the
end-to-end performance by $10.6\%$ when training with more than $9600$ GPUs, a
significant improvement for our training pipeline.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [113] [ChannelFlow-Tools: A Standardized Dataset Creation Pipeline for 3D Obstructed Channel Flows](https://arxiv.org/abs/2509.15236)
*Shubham Kavane,Kajol Kulkarni,Harald Koestler*

Main category: cs.GR

TL;DR: ChannelFlow-Tools 是一个标准化框架，将 CAD 到 ML 输入的工作流程自动化，支持 CFD 代理建模的可重现数据集创建。


<details>
  <summary>Details</summary>
Motivation: 为解决从程序化 CAD 实体生成到 ML 就绪输入和目标的端到端路径标准化问题，以支持 3D  obstructed channel flows 的研究。

Method: 该框架集成了几何合成、可行性检查、SDF 体素化、HPC 上的自动求解器编排（waLBerla LBM）以及笛卡尔重采样到共注册的多分辨率张量中。所有阶段由单个 Hydra/OmegaConf 配置控制，支持确定性重现和可控消融。

Result: 生成了 10k+ 场景，涵盖 Re=100-15000 的多种形状和姿态，并通过端到端评估展示了标准化表示对可重现 ML 训练的支持。

Conclusion: ChannelFlow-Tools 将一次性数据集创建转变为可重复、可配置的管道，为 CFD 代理建模提供了标准化的工作流程。

Abstract: We present ChannelFlow-Tools, a configuration-driven framework that
standardizes the end-to-end path from programmatic CAD solid generation to
ML-ready inputs and targets for 3D obstructed channel flows. The toolchain
integrates geometry synthesis with feasibility checks, signed distance field
(SDF) voxelization, automated solver orchestration on HPC (waLBerla LBM), and
Cartesian resampling to co-registered multi-resolution tensors. A single
Hydra/OmegaConf configuration governs all stages, enabling deterministic
reproduction and controlled ablations. As a case study, we generate 10k+ scenes
spanning Re=100-15000 with diverse shapes and poses. An end-to-end evaluation
of storage trade-offs directly from the emitted artifacts, a minimal 3D U-Net
at 128x32x32, and example surrogate models with dataset size illustrate that
the standardized representations support reproducible ML training.
ChannelFlow-Tools turns one-off dataset creation into a reproducible,
configurable pipeline for CFD surrogate modeling.

</details>


### [114] [GenCAD-3D: CAD Program Generation using Multimodal Latent Space Alignment and Synthetic Dataset Balancing](https://arxiv.org/abs/2509.15246)
*Nomi Yu,Md Ferdous Alam,A. John Hart,Faez Ahmed*

Main category: cs.GR

TL;DR: GenCAD-3D结合对比学习和潜在扩散模型，通过SynthBal数据增强策略，显著提升了复杂CAD程序的生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前深度生成模型在自动化CAD生成方面受限于数据集的不平衡和不足，尤其是缺乏复杂CAD程序的表示。

Method: 提出了GenCAD-3D，一个多模态生成框架，结合对比学习和潜在扩散模型，用于CAD序列生成和检索；并提出了SynthBal，一种合成数据增强策略。

Result: 实验表明，SynthBal显著提高了重建精度，减少了无效CAD模型的生成，并在高复杂度几何体上表现优异，超越了现有基准。

Conclusion: GenCAD-3D和SynthBal的引入显著提升了CAD程序的生成质量，特别是在复杂几何体的表示上，为逆向工程和工程设计自动化提供了重要支持。

Abstract: CAD programs, structured as parametric sequences of commands that compile
into precise 3D geometries, are fundamental to accurate and efficient
engineering design processes. Generating these programs from nonparametric data
such as point clouds and meshes remains a crucial yet challenging task,
typically requiring extensive manual intervention. Current deep generative
models aimed at automating CAD generation are significantly limited by
imbalanced and insufficiently large datasets, particularly those lacking
representation for complex CAD programs. To address this, we introduce
GenCAD-3D, a multimodal generative framework utilizing contrastive learning for
aligning latent embeddings between CAD and geometric encoders, combined with
latent diffusion models for CAD sequence generation and retrieval.
Additionally, we present SynthBal, a synthetic data augmentation strategy
specifically designed to balance and expand datasets, notably enhancing
representation of complex CAD geometries. Our experiments show that SynthBal
significantly boosts reconstruction accuracy, reduces the generation of invalid
CAD models, and markedly improves performance on high-complexity geometries,
surpassing existing benchmarks. These advancements hold substantial
implications for streamlining reverse engineering and enhancing automation in
engineering design. We will publicly release our datasets and code, including a
set of 51 3D-printed and laser-scanned parts on our project site.

</details>


### [115] [Causal Reasoning Elicits Controllable 3D Scene Generation](https://arxiv.org/abs/2509.15249)
*Shen Chen,Ruiyu Zhao,Jiale Zhou,Zongkai Wu,Jenq-Neng Hwang,Lei Li*

Main category: cs.GR

TL;DR: CausalStruct是一种新型3D场景生成框架，通过因果推理和物理约束优化布局，提升逻辑一致性和现实感。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景生成方法难以建模对象间复杂的逻辑依赖和物理约束，限制了其在动态和真实环境中的适应性。

Method: 利用大型语言模型（LLMs）构建因果图，节点表示对象和属性，边编码因果依赖和物理约束。通过因果顺序迭代优化场景布局，并应用因果干预调整空间配置，结合PID控制器优化对象尺度和位置。使用3D高斯抛光和评分蒸馏采样提升形状准确性和渲染稳定性。

Result: 实验表明，CausalStruct生成的3D场景具有更强的逻辑连贯性、现实的空间交互和鲁棒的适应性。

Conclusion: CausalStruct通过嵌入因果推理和物理约束，显著提升了3D场景生成的逻辑一致性和现实感，展示了在动态和真实环境中的强大适应性。

Abstract: Existing 3D scene generation methods often struggle to model the complex
logical dependencies and physical constraints between objects, limiting their
ability to adapt to dynamic and realistic environments. We propose
CausalStruct, a novel framework that embeds causal reasoning into 3D scene
generation. Utilizing large language models (LLMs), We construct causal graphs
where nodes represent objects and attributes, while edges encode causal
dependencies and physical constraints. CausalStruct iteratively refines the
scene layout by enforcing causal order to determine the placement order of
objects and applies causal intervention to adjust the spatial configuration
according to physics-driven constraints, ensuring consistency with textual
descriptions and real-world dynamics. The refined scene causal graph informs
subsequent optimization steps, employing a
Proportional-Integral-Derivative(PID) controller to iteratively tune object
scales and positions. Our method uses text or images to guide object placement
and layout in 3D scenes, with 3D Gaussian Splatting and Score Distillation
Sampling improving shape accuracy and rendering stability. Extensive
experiments show that CausalStruct generates 3D scenes with enhanced logical
coherence, realistic spatial interactions, and robust adaptability.

</details>


### [116] [Geometric Integration for Neural Control Variates](https://arxiv.org/abs/2509.15538)
*Daniel Meister,Takahiro Harada*

Main category: cs.GR

TL;DR: 提出了一种基于积分域细分的MLP解析积分方法，证明了MLP作为控制变量在蒙特卡洛积分中的有效性，应用于光传输模拟。


<details>
  <summary>Details</summary>
Motivation: 控制变量是减少蒙特卡洛积分方差的有效技术，但通常难以找到可解析积分的近似函数。本研究探索了MLP作为控制变量的潜力。

Method: 采用基于积分域细分的方法，结合计算几何技术，解决了2D情况下MLP的解析积分问题。

Result: 研究展示了MLP结合提出的积分方法可以作为控制变量，并在光传输模拟中验证了其有效性。

Conclusion: 本研究证明，结合提出的积分方法，多层感知机（MLP）可以作为控制变量在蒙特卡洛积分中有效减少方差，特别是在光传输模拟中。

Abstract: Control variates are a variance-reduction technique for Monte Carlo
integration. The principle involves approximating the integrand by a function
that can be analytically integrated, and integrating using the Monte Carlo
method only the residual difference between the integrand and the
approximation, to obtain an unbiased estimate. Neural networks are universal
approximators that could potentially be used as a control variate. However, the
challenge lies in the analytic integration, which is not possible in general.
In this manuscript, we study one of the simplest neural network models, the
multilayered perceptron (MLP) with continuous piecewise linear activation
functions, and its possible analytic integration. We propose an integration
method based on integration domain subdivision, employing techniques from
computational geometry to solve this problem in 2D. We demonstrate that an MLP
can be used as a control variate in combination with our integration method,
showing applications in the light transport simulation.

</details>


### [117] [Implicit Modeling for 3D-printed Multi-material Computational Object Design via Python](https://arxiv.org/abs/2509.15562)
*Charles Wade,Devon Beck,Robert MacCurdy*

Main category: cs.GR

TL;DR: 该论文提出了一种开源Python API，用于多材料增材制造和超材料设计，支持参数化梯度、晶格结构设计和有限元模拟，并通过实际案例和兼容性网格导出策略，提高了方法的实用性和可访问性。


<details>
  <summary>Details</summary>
Motivation: 加速多材料体积增材制造和超材料设计的研究，提供灵活的工具以支持复杂的设计和模拟需求。

Method: 采用Python基础的API，支持多材料梯度的参数化表达、与外部库的集成、多材料晶格结构设计，以及与有限元建模的互操作性。使用隐式多材料建模技术实现多尺度空间梯度，并与有限元分析集成进行预测性模拟。

Result: 开发了一个功能强大的框架，支持多材料晶格结构设计和模拟优化，并通过案例研究（如多材料自行车座）展示了其实际应用价值。

Conclusion: 该论文通过开源贡献和灵活的Python API，显著推动了多材料体积增材制造和超材料设计的研究，并通过实际案例和网格导出策略，提高了功能梯度计算设计方法的可访问性和应用范围。

Abstract: This paper introduces open-source contributions designed to accelerate
research in volumetric multi-material additive manufacturing and metamaterial
design. We present a flexible Python-based API facilitating parametric
expression of multi-material gradients, integration with external libraries,
multi-material lattice structure design, and interoperability with finite
element modeling. Novel implicit multi-material modeling techniques enable
detailed spatial grading at multiple scales within lattice structures.
Additionally, our framework integrates with finite element analysis, offering
predictive simulations via adaptive mesh sizing and direct import of simulation
results to guide material distributions. Practical case studies illustrate the
utility of these contributions, including functionally graded lattices,
algorithmically generated structures, and simulation-informed designs,
exemplified by a multi-material bicycle seat optimized for mechanical
performance and rider comfort. Finally, we introduce a mesh export strategy
compatible with standard slicing software, significantly broadening the
accessibility and adoption of functionality graded computational design
methodologies for multi-material fabrication.

</details>


### [118] [Fast subdivision of Bézier curves](https://arxiv.org/abs/2509.15691)
*Paweł Woźny,Filip Chudy*

Main category: cs.GR

TL;DR: 本文提出了一种基于FFT的B\'{e}zier曲线细分方法，将时间复杂度从$O(dn^2)$降至$O(dn\log{n})$，并通过改进解决了数值不稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 探讨是否能在$O(dn^2)$时间的基础上，更高效地细分B\'{e}zier曲线。

Method: 使用快速傅里叶变换（FFT）及其逆变换，提出了一种改进的细分算法，并通过数值实验验证了其稳定性和效率。

Result: 实验表明，直接应用新方法仅适用于较小的$n$值，但改进后的版本在保持$O(dn\log{n})$计算复杂度的同时，提供了良好的数值质量。

Conclusion: 通过快速傅里叶变换及其逆变换，本文提出了一种在$O(dn\log{n})$时间内细分B\'{e}zier曲线的高效方法，并展示了其在扩展控制点时的快速更新能力。类似方法还可应用于有理B\'{e}zier曲线、矩形B\'{e}zier曲面及B\'{e}zier曲线导数的计算。

Abstract: It is well-known that a $d$-dimensional polynomial B\'{e}zier curve of degree
$n$ can be subdivided into two segments using the famous de Casteljau algorithm
in $O(dn^2)$ time. Can this problem be solved more efficiently? In this paper,
we show that it is possible to do this in $O(dn\log{n})$ time using the fast
Fourier transform and its inverse. Experiments show that the direct application
of the new method performs well only for small values of $n$, as the algorithm
is numerically unstable. However, a slightly modified version -- which still
has $O(dn\log{n})$ computational complexity -- offers good numerical quality,
which is confirmed by numerical experiments conducted in \textsf{Python}.
Moreover, the new method has a nice property: if a B\'{e}zier curve is extended
by an additional control point, the subdivision can be updated in $O(d)$ time.
  A similar idea can be applied to speed up the subdivision of rational
B\'{e}zier curves and rectangular B\'{e}zier surfaces, as well as to compute
the derivatives of B\'{e}zier curves more efficiently.

</details>


### [119] [MoAngelo: Motion-Aware Neural Surface Reconstruction for Dynamic Scenes](https://arxiv.org/abs/2509.15892)
*Mohamed Ebbed,Zorah Lähner*

Main category: cs.GR

TL;DR: 本文提出了一种基于NeuralAngelo的动态场景重建框架，通过变形场和模板更新联合优化，显著提升了重建质量，尤其在处理遮挡和拓扑变化时表现优异。


<details>
  <summary>Details</summary>
Motivation: 动态场景重建在计算机视觉中仍具挑战性，现有方法在几何保真度方面表现不足，导致网格过于平滑或噪声较多。

Method: 该方法基于NeuralAngelo的静态3D重建技术，通过联合优化变形场和模板更新，实现了高质量的动态重建。

Result: 在ActorsHQ数据集上，该方法展示了优于现有技术的重建精度。

Conclusion: 本文提出的框架在动态场景重建中表现出色，显著提升了重建精度，尤其在处理遮挡和拓扑变化时表现出灵活性。

Abstract: Dynamic scene reconstruction from multi-view videos remains a fundamental
challenge in computer vision. While recent neural surface reconstruction
methods have achieved remarkable results in static 3D reconstruction, extending
these approaches with comparable quality for dynamic scenes introduces
significant computational and representational challenges. Existing dynamic
methods focus on novel-view synthesis, therefore, their extracted meshes tend
to be noisy. Even approaches aiming for geometric fidelity often result in too
smooth meshes due to the ill-posedness of the problem. We present a novel
framework for highly detailed dynamic reconstruction that extends the static 3D
reconstruction method NeuralAngelo to work in dynamic settings. To that end, we
start with a high-quality template scene reconstruction from the initial frame
using NeuralAngelo, and then jointly optimize deformation fields that track the
template and refine it based on the temporal sequence. This flexible template
allows updating the geometry to include changes that cannot be modeled with the
deformation field, for instance occluded parts or the changes in the topology.
We show superior reconstruction accuracy in comparison to previous
state-of-the-art methods on the ActorsHQ dataset.

</details>


### [120] [Generating Detailed Character Motion from Blocking Poses](https://arxiv.org/abs/2509.16064)
*Purvi Goel,Guy Tevet,C. K. Liu,Kayvon Fatahalian*

Main category: cs.GR

TL;DR: 本文提出了一种新的扩散模型方法，通过推理时混合技术，将稀疏阻塞姿势转换为自然动画，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型可以解决不精确时间姿势的校正问题，但在利用扩散先验增强稀疏阻塞姿势的细节方面缺乏有效解决方案。

Method: 在特定扩散步骤中，通过每阻塞姿势容忍权重将无条件扩散模型的输出与输入阻塞姿势约束混合，并将结果作为预存在运动重定时模型的输入条件。

Result: 该方法显著优于现有通过混合模型输出或表达阻塞姿势约束作为指导的尝试，首次实现了从阻塞级姿势到逼真详细角色动画的稳健转换。

Conclusion: 本文提出了一种新颖的推理时技巧，能够有效地将稀疏的阻塞姿势转换为自然流畅的角色动画，填补了现有扩散模型在此任务上的空白。

Abstract: We focus on the problem of using generative diffusion models for the task of
motion detailing: converting a rough version of a character animation,
represented by a sparse set of coarsely posed, and imprecisely timed blocking
poses, into a detailed, natural looking character animation. Current diffusion
models can address the problem of correcting the timing of imprecisely timed
poses, but we find that no good solution exists for leveraging the diffusion
prior to enhance a sparse set of blocking poses with additional pose detail. We
overcome this challenge using a simple inference-time trick. At certain
diffusion steps, we blend the outputs of an unconditioned diffusion model with
input blocking pose constraints using per-blocking-pose tolerance weights, and
pass this result in as the input condition to an pre-existing motion retiming
model. We find this approach works significantly better than existing
approaches that attempt to add detail by blending model outputs or via
expressing blocking pose constraints as guidance. The result is the first
diffusion model that can robustly convert blocking-level poses into plausible
detailed character animations.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [121] [DIPP: Discriminative Impact Point Predictor for Catching Diverse In-Flight Objects](https://arxiv.org/abs/2509.15254)
*Ngoc Huy Nguyen,Kazuki Shibata,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: 本研究构建了复杂空气动力学下的真实世界数据集，并提出DIPP方法，通过DFE和IPP模块提升四足机器人空中抓取物体的预测准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决空中物体抓取中缺乏多样化数据集和早期阶段预测准确性低的挑战。

Method: 提出了Discriminative Impact Point Predictor (DIPP)，包括Discriminative Feature Embedding (DFE)和Impact Point Predictor (IPP)两个模块，并实现了NAE和DPE两种变体。

Result: 实验表明，所构建的数据集比现有数据集更复杂多样，方法在15种已知和5种未知物体上均优于基线，且早期预测准确性的提升显著提高了抓取成功率。

Conclusion: 本研究通过构建真实世界数据集和提出DIPP方法，成功解决了四足机器人空中抓取物体中的关键挑战，实验证明了其在复杂空气动力学下的优越性能。

Abstract: In this study, we address the problem of in-flight object catching using a
quadruped robot with a basket. Our objective is to accurately predict the
impact point, defined as the object's landing position. This task poses two key
challenges: the absence of public datasets capturing diverse objects under
unsteady aerodynamics, which are essential for training reliable predictors;
and the difficulty of accurate early-stage impact point prediction when
trajectories appear similar across objects. To overcome these issues, we
construct a real-world dataset of 8,000 trajectories from 20 objects, providing
a foundation for advancing in-flight object catching under complex
aerodynamics. We then propose the Discriminative Impact Point Predictor (DIPP),
consisting of two modules: (i) a Discriminative Feature Embedding (DFE) that
separates trajectories by dynamics to enable early-stage discrimination and
generalization, and (ii) an Impact Point Predictor (IPP) that estimates the
impact point from these features. Two IPP variants are implemented: an Neural
Acceleration Estimator (NAE)-based method that predicts trajectories and
derives the impact point, and a Direct Point Estimator (DPE)-based method that
directly outputs it. Experimental results show that our dataset is more diverse
and complex than existing dataset, and that our method outperforms baselines on
both 15 seen and 5 unseen objects. Furthermore, we show that improved
early-stage prediction enhances catching success in simulation and demonstrate
the effectiveness of our approach through real-world experiments. The
demonstration is available at
https://sites.google.com/view/robot-catching-2025.

</details>


### [122] [GiAnt: A Bio-Inspired Hexapod for Adaptive Terrain Navigation and Object Detection](https://arxiv.org/abs/2509.15264)
*Aasfee Mosharraf Bhuiyan,Md Luban Mehda,Md. Thawhid Hasan Puspo,Jubayer Amin Pritom*

Main category: cs.RO

TL;DR: GiAnt是一款仿蚂蚁运动的六足机器人，具有轻量化设计和简单控制，适用于复杂地形，结合了机器学习和图像处理技术。


<details>
  <summary>Details</summary>
Motivation: 设计GiAnt的动机是利用蚂蚁对不同地形的自然适应性，开发一种能够在户外应用中灵活移动且能效高的六足机器人。

Method: GiAnt采用仿生学设计，灵感来自蚂蚁的运动，具有轻量化的3D打印和激光切割结构，单自由度腿部设计，基于Arduino的控制系统，以及机器学习和图像处理技术。

Result: GiAnt成功实现了在草地、岩石和陡坡等复杂地形中的高效移动，能够识别81种不同物体，并通过步态分析实现了有效的腿部控制。

Conclusion: GiAnt代表了在创建经济实惠、适应性强的六足机器人方面的重要进展，适用于研究、探索和勘测。

Abstract: This paper presents the design, development and testing of GiAnt, an
affordable hexapod which is inspired by the efficient motions of ants. The
decision to model GiAnt after ants rather than other insects is rooted in ants'
natural adaptability to a variety of terrains. This bio-inspired approach gives
it a significant advantage in outdoor applications, offering terrain
flexibility along with efficient energy use. It features a lightweight
3D-printed and laser cut structure weighing 1.75 kg with dimensions of 310 mm x
200 mm x 120 mm. Its legs have been designed with a simple Single Degree of
Freedom (DOF) using a link and crank mechanism. It is great for conquering
challenging terrains such as grass, rocks, and steep surfaces. Unlike
traditional robots using four wheels for motion, its legged design gives
superior adaptability to uneven and rough surfaces. GiAnt's control system is
built on Arduino, allowing manual operation. An effective way of controlling
the legs of GiAnt was achieved by gait analysis. It can move up to 8 cm of
height easily with its advanced leg positioning system. Furthermore, equipped
with machine learning and image processing technology, it can identify 81
different objects in a live monitoring system. It represents a significant step
towards creating accessible hexapod robots for research, exploration, and
surveying, offering unique advantages in adaptability and control simplicity.

</details>


### [123] [Embodied Arena: A Comprehensive, Unified, and Evolving Evaluation Platform for Embodied AI](https://arxiv.org/abs/2509.15273)
*Fei Ni,Min Zhang,Pengyi Li,Yifu Yuan,Lingfeng Zhang,Yuecheng Liu,Peilong Han,Longxin Kou,Shaojin Ma,Jinbin Qiao,David Gamaliel Arcos Bravo,Yuening Wang,Xiao Hu,Zhanguang Zhang,Xianze Yao,Yutong Li,Zhao Zhang,Ying Wen,Ying-Cong Chen,Xiaodan Liang,Liang Lin,Bin He,Haitham Bou-Ammar,He Wang,Huazhe Xu,Jiankang Deng,Shan Luo,Shuqiang Jiang,Wei Pan,Yang Gao,Stefanos Zafeiriou,Jan Peters,Yuzheng Zhuang,Yingxue Zhang,Yan Zheng,Hongyao Tang,Jianye Hao*

Main category: cs.RO

TL;DR: Embodied Arena是一个统一的Embodied AI评估平台，解决了领域内的三大挑战，通过标准化评估和自动化数据生成推动了研究进展。


<details>
  <summary>Details</summary>
Motivation: 解决Embodied AI领域缺乏系统性能力理解、统一评估标准和自动化数据获取方法的三大挑战。

Method: 提出了Embodied Arena平台，包括能力分类体系、标准化评估系统和LLM驱动的自动化数据生成管道。

Result: 建立了包含22个基准和30+先进模型的实时排行榜，总结了九项关键发现，为研究提供了明确方向。

Conclusion: Embodied Arena通过系统化的能力分类、标准化的评估系统和自动化的数据生成管道，为Embodied AI领域提供了全面的评估平台，并总结了九项关键发现，推动了该领域的研究进展。

Abstract: Embodied AI development significantly lags behind large foundation models due
to three critical challenges: (1) lack of systematic understanding of core
capabilities needed for Embodied AI, making research lack clear objectives; (2)
absence of unified and standardized evaluation systems, rendering
cross-benchmark evaluation infeasible; and (3) underdeveloped automated and
scalable acquisition methods for embodied data, creating critical bottlenecks
for model scaling. To address these obstacles, we present Embodied Arena, a
comprehensive, unified, and evolving evaluation platform for Embodied AI. Our
platform establishes a systematic embodied capability taxonomy spanning three
levels (perception, reasoning, task execution), seven core capabilities, and 25
fine-grained dimensions, enabling unified evaluation with systematic research
objectives. We introduce a standardized evaluation system built upon unified
infrastructure supporting flexible integration of 22 diverse benchmarks across
three domains (2D/3D Embodied Q&A, Navigation, Task Planning) and 30+ advanced
models from 20+ worldwide institutes. Additionally, we develop a novel
LLM-driven automated generation pipeline ensuring scalable embodied evaluation
data with continuous evolution for diversity and comprehensiveness. Embodied
Arena publishes three real-time leaderboards (Embodied Q&A, Navigation, Task
Planning) with dual perspectives (benchmark view and capability view),
providing comprehensive overviews of advanced model capabilities. Especially,
we present nine findings summarized from the evaluation results on the
leaderboards of Embodied Arena. This helps to establish clear research veins
and pinpoint critical research problems, thereby driving forward progress in
the field of Embodied AI.

</details>


### [124] [Measurement and Potential Field-Based Patient Modeling for Model-Mediated Tele-ultrasound](https://arxiv.org/abs/2509.15325)
*Ryan S. Yeung,David G. Black,Septimiu E. Salcudean*

Main category: cs.RO

TL;DR: 该论文提出了一种通过更新内部势场模型来提高远程超声操作力反馈准确性的方法，显著减少了力的大小和角度误差。


<details>
  <summary>Details</summary>
Motivation: 远程超声操作中，由于通信延迟，直接力反馈不切实际，需要一种更透明的方法来估计接触力和扭矩。

Method: 首先生成患者表面的点云模型，并将其转换为静态体素化体积，每个体素包含一个势场值。通过结合空间拉普拉斯算子和测量力，求解势场。

Result: 在志愿者患者（n=3）上的评估显示，加入测量力后，力的大小误差平均减少了7.23 N，力向量角度误差平均减少了9.37°。

Conclusion: 通过引入测量力更新内部势场模型，显著提高了远程超声操作中力反馈的准确性，减少了力的大小和角度误差。

Abstract: Teleoperated ultrasound can improve diagnostic medical imaging access for
remote communities. Having accurate force feedback is important for enabling
sonographers to apply the appropriate probe contact force to optimize
ultrasound image quality. However, large time delays in communication make
direct force feedback impractical. Prior work investigated using point
cloud-based model-mediated teleoperation and internal potential field models to
estimate contact forces and torques. We expand on this by introducing a method
to update the internal potential field model of the patient with measured
positions and forces for more transparent model-mediated tele-ultrasound. We
first generate a point cloud model of the patient's surface and transmit this
to the sonographer in a compact data structure. This is converted to a static
voxelized volume where each voxel contains a potential field value. These
values determine the forces and torques, which are rendered based on overlap
between the voxelized volume and a point shell model of the ultrasound
transducer. We solve for the potential field using a convex quadratic that
combines the spatial Laplace operator with measured forces. This was evaluated
on volunteer patients ($n=3$) by computing the accuracy of rendered forces.
Results showed the addition of measured forces to the model reduced the force
magnitude error by an average of 7.23 N and force vector angle error by an
average of 9.37$^{\circ}$ compared to using only Laplace's equation.

</details>


### [125] [Trust-Aware Embodied Bayesian Persuasion for Mixed-Autonomy](https://arxiv.org/abs/2509.15404)
*Shaoting Peng,Katherine Driggs-Campbell,Roy Dong*

Main category: cs.RO

TL;DR: 论文提出TA-EBP框架，通过贝叶斯说服和信任参数优化AV与HV交互，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统博弈论模型在长期交互中影响力衰减和被感知为操纵性导致人类信任下降的问题。

Method: 应用贝叶斯说服理论建模交通路口的通信，引入信任参数，并将抽象信号转化为物理动作空间。

Result: 在混合自主交通仿真中验证，TA-EBP成功说服HV驾驶更谨慎，消除了碰撞并改善了交通流量。

Conclusion: 该论文提出了TA-EBP框架，通过透明和非策略性的方式增强AV与HV之间的交互，显著提升了安全性和交通效率。

Abstract: Safe and efficient interaction between autonomous vehicles (AVs) and
human-driven vehicles (HVs) is a critical challenge for future transportation
systems. While game-theoretic models capture how AVs influence HVs, they often
suffer from a long-term decay of influence and can be perceived as
manipulative, eroding the human's trust. This can paradoxically lead to riskier
human driving behavior over repeated interactions. In this paper, we address
this challenge by proposing the Trust-Aware Embodied Bayesian Persuasion
(TA-EBP) framework. Our work makes three key contributions: First, we apply
Bayesian persuasion to model communication at traffic intersections, offering a
transparent alternative to traditional game-theoretic models. Second, we
introduce a trust parameter to the persuasion framework, deriving a theorem for
the minimum trust level required for influence. Finally, we ground the abstract
signals of Bayesian persuasion theory into a continuous, physically meaningful
action space, deriving a second theorem for the optimal signal magnitude,
realized as an AV's forward nudge. Additionally, we validate our framework in a
mixed-autonomy traffic simulation, demonstrating that TA-EBP successfully
persuades HVs to drive more cautiously, eliminating collisions and improving
traffic flow compared to baselines that either ignore trust or lack
communication. Our work provides a transparent and non-strategic framework for
influence in human-robot interaction, enhancing both safety and efficiency.

</details>


### [126] [Sym2Real: Symbolic Dynamics with Residual Learning for Data-Efficient Adaptive Control](https://arxiv.org/abs/2509.15412)
*Easop Lee,Samuel A. Moore,Boyuan Chen*

Main category: cs.RO

TL;DR: Sym2Real是一个数据驱动框架，通过符号回归和残差学习，仅需约10条轨迹数据即可实现四旋翼和赛车的鲁棒控制。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决符号回归在真实世界机器人应用中因噪声敏感性和模型退化导致的不安全控制问题，同时提高数据效率。

Method: 该框架利用低保真度仿真数据和目标明确的真实世界残差学习，克服了噪声敏感性和模型退化问题，实现了安全控制。

Result: 在六个分布外仿真到仿真场景和五种真实世界条件下，Sym2Real均表现出高效的数据适应性和成功的仿真到真实转移。

Conclusion: Sym2Real框架通过结合符号回归和残差学习，成功实现了在仅有约10条轨迹数据下的高效数据驱动控制，并在真实世界的四旋翼和赛车平台上验证了其鲁棒性和适应性。

Abstract: We present Sym2Real, a fully data-driven framework that provides a principled
way to train low-level adaptive controllers in a highly data-efficient manner.
Using only about 10 trajectories, we achieve robust control of both a quadrotor
and a racecar in the real world, without expert knowledge or simulation tuning.
Our approach achieves this data efficiency by bringing symbolic regression to
real-world robotics while addressing key challenges that prevent its direct
application, including noise sensitivity and model degradation that lead to
unsafe control. Our key observation is that the underlying physics is often
shared for a system regardless of internal or external changes. Hence, we
strategically combine low-fidelity simulation data with targeted real-world
residual learning. Through experimental validation on quadrotor and racecar
platforms, we demonstrate consistent data-efficient adaptation across six
out-of-distribution sim2sim scenarios and successful sim2real transfer across
five real-world conditions. More information and videos can be found at at
http://generalroboticslab.com/Sym2Real

</details>


### [127] [Online Slip Detection and Friction Coefficient Estimation for Autonomous Racing](https://arxiv.org/abs/2509.15423)
*Christopher Oeltjen,Carson Sobolewski,Saleh Faghfoorian,Lorant Domokos,Giancarlo Vidal,Ivan Ruchkin*

Main category: cs.RO

TL;DR: 论文提出了一种无需复杂模型或大量数据的轻量级方法，用于实时滑移检测和轮胎-道路摩擦系数估计，实验验证了其准确性和实用性。


<details>
  <summary>Details</summary>
Motivation: 轮胎-道路摩擦系数的准确知识对车辆安全、稳定性和性能至关重要，尤其是在自主赛车中，车辆通常在摩擦极限下运行。然而，TRFC无法通过标准传感器直接测量，现有估计方法要么依赖于具有不确定参数的车辆或轮胎模型，要么需要大量训练数据集。

Method: 该方法仅依赖IMU和LiDAR测量以及控制动作，无需特殊动力学或轮胎模型、参数识别或训练数据，通过比较指令和测量运动实时检测滑移事件，并在无滑移条件下直接从观测加速度估计TRFC。

Result: 实验结果表明，该方法在不同摩擦水平下实现了准确且一致的滑移检测和摩擦系数估计，结果与地面真实测量值非常接近。

Conclusion: 该论文提出了一种轻量级方法，用于在线滑移检测和轮胎-道路摩擦系数（TRFC）估计，实验证明该方法在自主赛车中实现了准确且一致的滑移检测和摩擦系数估计。

Abstract: Accurate knowledge of the tire-road friction coefficient (TRFC) is essential
for vehicle safety, stability, and performance, especially in autonomous
racing, where vehicles often operate at the friction limit. However, TRFC
cannot be directly measured with standard sensors, and existing estimation
methods either depend on vehicle or tire models with uncertain parameters or
require large training datasets. In this paper, we present a lightweight
approach for online slip detection and TRFC estimation. Our approach relies
solely on IMU and LiDAR measurements and the control actions, without special
dynamical or tire models, parameter identification, or training data. Slip
events are detected in real time by comparing commanded and measured motions,
and the TRFC is then estimated directly from observed accelerations under
no-slip conditions. Experiments with a 1:10-scale autonomous racing car across
different friction levels demonstrate that the proposed approach achieves
accurate and consistent slip detections and friction coefficients, with results
closely matching ground-truth measurements. These findings highlight the
potential of our simple, deployable, and computationally efficient approach for
real-time slip monitoring and friction coefficient estimation in autonomous
driving.

</details>


### [128] [Implicit Kinodynamic Motion Retargeting for Human-to-humanoid Imitation Learning](https://arxiv.org/abs/2509.15443)
*Xingyu Chen,Hanyu Wu,Sikai Wu,Mingliang Zhou,Diyun Xiang,Haodong Zhang*

Main category: cs.RO

TL;DR: IKMR是一种高效且可扩展的运动重定向框架，通过结合运动拓扑特征和双编码器-解码器架构，实现大规模人类运动到机器人运动的实时转换。


<details>
  <summary>Details</summary>
Motivation: 现有方法逐帧处理运动重定向，缺乏可扩展性，需更高效方法将大规模人类运动直接转换为机器人可执行运动。

Method: 提出隐式动力学运动重定向（IKMR）框架，结合运动拓扑特征表示和双编码器-解码器架构，通过模仿学习与运动重定向网络整合，优化运动轨迹。

Result: IKMR能够实时实现大规模物理可行运动重定向，并在仿真和实际人形机器人上验证了其有效性。

Conclusion: IKMR框架通过结合运动拓扑特征表示和双编码器-解码器架构，实现了高效且可扩展的运动重定向，验证了其在实际人形机器人上的有效性。

Abstract: Human-to-humanoid imitation learning aims to learn a humanoid whole-body
controller from human motion. Motion retargeting is a crucial step in enabling
robots to acquire reference trajectories when exploring locomotion skills.
However, current methods focus on motion retargeting frame by frame, which
lacks scalability. Could we directly convert large-scale human motion into
robot-executable motion through a more efficient approach? To address this
issue, we propose Implicit Kinodynamic Motion Retargeting (IKMR), a novel
efficient and scalable retargeting framework that considers both kinematics and
dynamics. In kinematics, IKMR pretrains motion topology feature representation
and a dual encoder-decoder architecture to learn a motion domain mapping. In
dynamics, IKMR integrates imitation learning with the motion retargeting
network to refine motion into physically feasible trajectories. After
fine-tuning using the tracking results, IKMR can achieve large-scale physically
feasible motion retargeting in real time, and a whole-body controller could be
directly trained and deployed for tracking its retargeted trajectories. We
conduct our experiments both in the simulator and the real robot on a full-size
humanoid robot. Extensive experiments and evaluation results verify the
effectiveness of our proposed framework.

</details>


### [129] [Explainable AI-Enhanced Supervisory Control for Robust Multi-Agent Robotic Systems](https://arxiv.org/abs/2509.15491)
*Reza Pirayeshshirazinezhad,Nima Fathi*

Main category: cs.RO

TL;DR: 论文提出一个可解释AI监督控制框架，结合定时自动机、鲁棒控制和可解释预测器，在航天器和AUV测试中显著提升性能并降低能耗。


<details>
  <summary>Details</summary>
Motivation: 针对多智能体机器人系统在不确定六自由度刚体动力学、相对运动和紧密跟踪需求下的挑战，提出一个透明且可审计的解决方案。

Method: 结合了定时自动机监督器、鲁棒连续控制（基于Lyapunov的大角度机动控制器和具有边界层的滑模控制器）以及可解释预测器，通过蒙特卡洛驱动的优化提供训练数据。

Result: 在航天器编队飞行和自主水下车辆（AUV）测试中，滑模控制器（SMC）表现出色：航天器任务中跟踪误差降低21.7%，能耗降低81.4%；AUV测试中在随机电流下保持固定偏移。

Conclusion: 该论文提出的可解释AI增强的监督控制框架在多智能体机器人系统中展现出便携性和可解释性，适用于安全关键、资源受限的场景。

Abstract: We present an explainable AI-enhanced supervisory control framework for
multi-agent robotics that combines (i) a timed-automata supervisor for safe,
auditable mode switching, (ii) robust continuous control (Lyapunov-based
controller for large-angle maneuver; sliding-mode controller (SMC) with
boundary layers for precision and disturbance rejection), and (iii) an
explainable predictor that maps mission context to gains and expected
performance (energy, error). Monte Carlo-driven optimization provides the
training data, enabling transparent real-time trade-offs.
  We validated the approach in two contrasting domains, spacecraft formation
flying and autonomous underwater vehicles (AUVs). Despite different
environments (gravity/actuator bias vs. hydrodynamic drag/currents), both share
uncertain six degrees of freedom (6-DOF) rigid-body dynamics, relative motion,
and tight tracking needs, making them representative of general robotic
systems. In the space mission, the supervisory logic selects parameters that
meet mission criteria. In AUV leader-follower tests, the same SMC structure
maintains a fixed offset under stochastic currents with bounded steady error.
In spacecraft validation, the SMC controller achieved submillimeter alignment
with 21.7% lower tracking error and 81.4% lower energy consumption compared to
Proportional-Derivative PD controller baselines. At the same time, in AUV
tests, SMC maintained bounded errors under stochastic currents. These results
highlight both the portability and the interpretability of the approach for
safety-critical, resource-constrained multi-agent robotics.

</details>


### [130] [STARC: See-Through-Wall Augmented Reality Framework for Human-Robot Collaboration in Emergency Response](https://arxiv.org/abs/2509.15507)
*Shenghai Yuan,Weixiang Guo,Tianxin Hu,Yu Yang,Jinyu Chen,Rui Qian,Zhongyuan Liu,Lihua Xie*

Main category: cs.RO

TL;DR: STARC是一个AR框架，通过融合机器人和救援人员的LiDAR数据，实时可视化隐藏人员和危险，提升救援效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在紧急救援任务中，救援人员需在遮挡严重的室内环境中导航，传统方法难以实时可视化隐藏的危险和受害者。

Method: STARC结合了移动机器人的LiDAR惯性里程计进行大范围探索和3D人体检测，以及救援人员头盔或手持LiDAR的相对姿态估计，实现跨LiDAR对齐。

Result: 实验在仿真、实验室设置和战术现场试验中验证了稳定的姿态对齐、可靠的检测和稳定的AR叠加效果。

Conclusion: STARC框架通过融合移动机器人地图和救援人员LiDAR传感，提供了实时可视化隐藏人员和危险的能力，显著提升了情境感知并降低了操作风险。

Abstract: In emergency response missions, first responders must navigate cluttered
indoor environments where occlusions block direct line-of-sight, concealing
both life-threatening hazards and victims in need of rescue. We present STARC,
a see-through AR framework for human-robot collaboration that fuses
mobile-robot mapping with responder-mounted LiDAR sensing. A ground robot
running LiDAR-inertial odometry performs large-area exploration and 3D human
detection, while helmet- or handheld-mounted LiDAR on the responder is
registered to the robot's global map via relative pose estimation. This
cross-LiDAR alignment enables consistent first-person projection of detected
humans and their point clouds - rendered in AR with low latency - into the
responder's view. By providing real-time visualization of hidden occupants and
hazards, STARC enhances situational awareness and reduces operator risk.
Experiments in simulation, lab setups, and tactical field trials confirm robust
pose alignment, reliable detections, and stable overlays, underscoring the
potential of our system for fire-fighting, disaster relief, and other
safety-critical operations. Code and design will be open-sourced upon
acceptance.

</details>


### [131] [Distribution Estimation for Global Data Association via Approximate Bayesian Inference](https://arxiv.org/abs/2509.15565)
*Yixuan Jia,Mason B. Peterson,Qingyuan Li,Yulun Tian,Jonathan P. How*

Main category: cs.RO

TL;DR: 提出一种基于近似贝叶斯推断的多模态数据关联框架，有效处理模糊场景，支持GPU并行优化，实验验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在重复或对称数据场景中因依赖单一解（如最大似然估计或最大共识）而失败的问题。

Method: 利用粒子表示假设解，并通过确定性或随机性更新规则覆盖解分布的多个模态。支持GPU并行优化。

Result: 在模拟和真实世界的高度模糊数据实验中，该方法能够正确估计点云或对象地图配准时的变换分布。

Conclusion: 该论文提出的基于近似贝叶斯推断的数据关联框架能够有效处理多模态解分布，避免了在模糊场景中过早锁定单一解的问题。

Abstract: Global data association is an essential prerequisite for robot operation in
environments seen at different times or by different robots. Repetitive or
symmetric data creates significant challenges for existing methods, which
typically rely on maximum likelihood estimation or maximum consensus to produce
a single set of associations. However, in ambiguous scenarios, the distribution
of solutions to global data association problems is often highly multimodal,
and such single-solution approaches frequently fail. In this work, we introduce
a data association framework that leverages approximate Bayesian inference to
capture multiple solution modes to the data association problem, thereby
avoiding premature commitment to a single solution under ambiguity. Our
approach represents hypothetical solutions as particles that evolve according
to a deterministic or randomized update rule to cover the modes of the
underlying solution distribution. Furthermore, we show that our method can
incorporate optimization constraints imposed by the data association
formulation and directly benefit from GPU-parallelized optimization. Extensive
simulated and real-world experiments with highly ambiguous data show that our
method correctly estimates the distribution over transformations when
registering point clouds or object maps.

</details>


### [132] [Momentum-constrained Hybrid Heuristic Trajectory Optimization Framework with Residual-enhanced DRL for Visually Impaired Scenarios](https://arxiv.org/abs/2509.15582)
*Yuting Zeng,Zhiwen Zheng,You Zhou,JiaLing Xiao,Yongbin Yu,Manping Fan,Bo Gong,Liyong Ren*

Main category: cs.RO

TL;DR: 提出了一个动量约束混合启发式轨迹优化框架（MHHTOF），用于视觉障碍辅助导航，结合轨迹采样和残差增强DRL，显著提升了性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 针对视觉障碍场景下的辅助导航需求，旨在提升轨迹规划的平滑性、可行性和安全性。

Method: 提出了一种结合轨迹采样生成、优化与评估的混合启发式轨迹优化框架，包括启发式轨迹采样簇（HTSC）生成和残差增强的深度强化学习（DRL）优化。

Result: 实验结果表明，LSTM-ResB-PPO模型在训练迭代次数减半的情况下实现了更快的收敛和稳定的策略性能，平均成本和成本方差分别降低了30.3%和53.3%，自我和障碍风险降低了77%以上。

Conclusion: 该框架通过动量约束混合启发式轨迹优化框架（MHHTOF）显著提升了辅助导航的鲁棒性、安全性和实时可行性，验证了其在复杂辅助规划任务中的有效性。

Abstract: This paper proposes a momentum-constrained hybrid heuristic trajectory
optimization framework (MHHTOF) tailored for assistive navigation in visually
impaired scenarios, integrating trajectory sampling generation, optimization
and evaluation with residual-enhanced deep reinforcement learning (DRL). In the
first stage, heuristic trajectory sampling cluster (HTSC) is generated in the
Frenet coordinate system using third-order interpolation with fifth-order
polynomials and momentum-constrained trajectory optimization (MTO) constraints
to ensure smoothness and feasibility. After first stage cost evaluation, the
second stage leverages a residual-enhanced actor-critic network with LSTM-based
temporal feature modeling to adaptively refine trajectory selection in the
Cartesian coordinate system. A dual-stage cost modeling mechanism (DCMM) with
weight transfer aligns semantic priorities across stages, supporting
human-centered optimization. Experimental results demonstrate that the proposed
LSTM-ResB-PPO achieves significantly faster convergence, attaining stable
policy performance in approximately half the training iterations required by
the PPO baseline, while simultaneously enhancing both reward outcomes and
training stability. Compared to baseline method, the selected model reduces
average cost and cost variance by 30.3% and 53.3%, and lowers ego and obstacle
risks by over 77%. These findings validate the framework's effectiveness in
enhancing robustness, safety, and real-time feasibility in complex assistive
planning tasks.

</details>


### [133] [Bench-RNR: Dataset for Benchmarking Repetitive and Non-repetitive Scanning LiDAR for Infrastructure-based Vehicle Localization](https://arxiv.org/abs/2509.15583)
*Runxin Zhao,Chunxiang Wang,Hanyang Zhuang,Ming Yang*

Main category: cs.RO

TL;DR: 本研究创建了一个包含重复和非重复扫描LiDAR的数据集，用于基础设施车辆定位的基准测试，为选择最佳LiDAR扫描模式提供了依据。


<details>
  <summary>Details</summary>
Motivation: 尽管非重复扫描LiDAR在消除盲区和成本效益方面具有优势，但其在路边感知和定位中的应用仍有限。本研究旨在填补这一空白，为选择最合适的LiDAR扫描模式提供依据。

Method: 研究人员收集了来自重复和非重复扫描LiDAR的数据，创建了一个包含5,445帧点云的数据集，涵盖八种车辆轨迹序列，并进行了基础设施车辆定位的基准测试。

Result: 实验建立了基础设施车辆定位的基准，并比较了使用非重复和重复扫描LiDAR的定位性能。

Conclusion: 本研究通过提供包含重复和非重复扫描LiDAR的数据集，为基础设施车辆定位领域提供了重要贡献，支持科学社区在基础设施感知和车辆定位方面的进步。

Abstract: Vehicle localization using roadside LiDARs can provide centimeter-level
accuracy for cloud-controlled vehicles while simultaneously serving multiple
vehicles, enhanc-ing safety and efficiency. While most existing studies rely on
repetitive scanning LiDARs, non-repetitive scanning LiDAR offers advantages
such as eliminating blind zones and being more cost-effective. However, its
application in roadside perception and localization remains limited. To address
this, we present a dataset for infrastructure-based vehicle localization, with
data collected from both repetitive and non-repetitive scanning LiDARs, in
order to benchmark the performance of different LiDAR scanning patterns. The
dataset contains 5,445 frames of point clouds across eight vehicle trajectory
sequences, with diverse trajectory types. Our experiments establish base-lines
for infrastructure-based vehicle localization and compare the performance of
these methods using both non-repetitive and repetitive scanning LiDARs. This
work offers valuable insights for selecting the most suitable LiDAR scanning
pattern for infrastruc-ture-based vehicle localization. Our dataset is a
signifi-cant contribution to the scientific community, supporting advancements
in infrastructure-based perception and vehicle localization. The dataset and
source code are publicly available at:
https://github.com/sjtu-cyberc3/BenchRNR.

</details>


### [134] [Distributed Nash Equilibrium Seeking Algorithm in Aggregative Games for Heterogeneous Multi-Robot Systems](https://arxiv.org/abs/2509.15597)
*Yi Dong,Zhongguo Li,Sarvapali D. Ramchurn,Xiaowei Huang*

Main category: cs.RO

TL;DR: 本文提出了一种异构多机器人系统的分布式纳什均衡寻找算法，结合分布式优化和输出控制，通过实验验证了其有效性和收敛性。


<details>
  <summary>Details</summary>
Motivation: 开发一种适用于异构多机器人系统的分布式纳什均衡寻找算法，以解决信息共享和协同控制问题。

Method: 提出了一种分布式优化算法，计算纳什均衡作为每个机器人的定制参考，并设计了输出控制律以在聚合游戏中跟踪该参考。

Result: 算法被证明能够保证收敛并产生高效结果。

Conclusion: 该算法通过分布式优化和输出控制成功实现了异构多机器人系统的纳什均衡，并通过数值模拟和物理机器人实验验证了其有效性。

Abstract: This paper develops a distributed Nash Equilibrium seeking algorithm for
heterogeneous multi-robot systems. The algorithm utilises distributed
optimisation and output control to achieve the Nash equilibrium by leveraging
information shared among neighbouring robots. Specifically, we propose a
distributed optimisation algorithm that calculates the Nash equilibrium as a
tailored reference for each robot and designs output control laws for
heterogeneous multi-robot systems to track it in an aggregative game. We prove
that our algorithm is guaranteed to converge and result in efficient outcomes.
The effectiveness of our approach is demonstrated through numerical simulations
and empirical testing with physical robots.

</details>


### [135] [ORB: Operating Room Bot, Automating Operating Room Logistics through Mobile Manipulation](https://arxiv.org/abs/2509.15600)
*Jinkai Qiu,Yungjun Kim,Gaurav Sethia,Tanmay Agarwal,Siddharth Ghodasara,Zackory Erickson,Jeffrey Ichnowski*

Main category: cs.RO

TL;DR: ORB 是一种自动化医院手术室物流的机器人框架，通过行为树架构和先进物体识别技术，实现了高效的物品递送和补货操作。


<details>
  <summary>Details</summary>
Motivation: 手术室内的物品高效递送对患者生命至关重要，但自动化手术室物流在感知、效率和保持无菌性方面面临独特挑战。

Method: ORB 采用分层行为树（BT）架构，结合了物体识别、场景解释和 GPU 加速的运动规划功能。具体包括模块化软件架构、基于 YOLOv7、SAM2 和 Grounded DINO 的实时物体识别管道，以及 cuRobo 并行化轨迹优化框架的实时无碰撞移动操作。

Result: 实证验证表明，ORB 在手术室物品取回任务中成功率为 80%，在补货操作中成功率为 96%。

Conclusion: ORB 被证明是一种可靠且适应性强的系统，可用于医院手术室的自主物流任务。

Abstract: Efficiently delivering items to an ongoing surgery in a hospital operating
room can be a matter of life or death. In modern hospital settings, delivery
robots have successfully transported bulk items between rooms and floors.
However, automating item-level operating room logistics presents unique
challenges in perception, efficiency, and maintaining sterility. We propose the
Operating Room Bot (ORB), a robot framework to automate logistics tasks in
hospital operating rooms (OR). ORB leverages a robust, hierarchical behavior
tree (BT) architecture to integrate diverse functionalities of object
recognition, scene interpretation, and GPU-accelerated motion planning. The
contributions of this paper include: (1) a modular software architecture
facilitating robust mobile manipulation through behavior trees; (2) a novel
real-time object recognition pipeline integrating YOLOv7, Segment Anything
Model 2 (SAM2), and Grounded DINO; (3) the adaptation of the cuRobo
parallelized trajectory optimization framework to real-time, collision-free
mobile manipulation; and (4) empirical validation demonstrating an 80% success
rate in OR supply retrieval and a 96% success rate in restocking operations.
These contributions establish ORB as a reliable and adaptable system for
autonomous OR logistics.

</details>


### [136] [PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models](https://arxiv.org/abs/2509.15607)
*Ruiqi Wang,Dezhong Zhao,Ziqin Yuan,Tianyu Shao,Guohua Chen,Dominic Kao,Sungeun Hong,Byung-Cheol Min*

Main category: cs.RO

TL;DR: PRIMT是一个偏好强化学习框架，通过多模态合成反馈和轨迹合成技术解决人类输入依赖和信用分配问题，在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 偏好强化学习（PbRL）在无需奖励工程的情况下教授机器人复杂行为，但其有效性受限于对人类输入的依赖以及查询模糊性和信用分配的困难。

Method: PRIMT采用分层神经符号融合策略，结合大型语言模型和视觉语言模型的互补优势，提供更可靠和全面的反馈。此外，框架还引入了前瞻轨迹生成和后视轨迹增强技术，以减少早期查询模糊性并改善信用分配。

Result: PRIMT在2个运动任务和6个操作任务上进行了评估，表现出优于基于基础模型和脚本基线的性能。

Conclusion: PRIMT框架通过结合基础模型的多模态合成反馈和轨迹合成，有效解决了偏好强化学习中的人类输入依赖和查询模糊性及信用分配问题，在多种任务上表现出优于现有方法的性能。

Abstract: Preference-based reinforcement learning (PbRL) has emerged as a promising
paradigm for teaching robots complex behaviors without reward engineering.
However, its effectiveness is often limited by two critical challenges: the
reliance on extensive human input and the inherent difficulties in resolving
query ambiguity and credit assignment during reward learning. In this paper, we
introduce PRIMT, a PbRL framework designed to overcome these challenges by
leveraging foundation models (FMs) for multimodal synthetic feedback and
trajectory synthesis. Unlike prior approaches that rely on single-modality FM
evaluations, PRIMT employs a hierarchical neuro-symbolic fusion strategy,
integrating the complementary strengths of large language models and
vision-language models in evaluating robot behaviors for more reliable and
comprehensive feedback. PRIMT also incorporates foresight trajectory
generation, which reduces early-stage query ambiguity by warm-starting the
trajectory buffer with bootstrapped samples, and hindsight trajectory
augmentation, which enables counterfactual reasoning with a causal auxiliary
loss to improve credit assignment. We evaluate PRIMT on 2 locomotion and 6
manipulation tasks on various benchmarks, demonstrating superior performance
over FM-based and scripted baselines.

</details>


### [137] [Miniature soft robot with magnetically reprogrammable surgical functions](https://arxiv.org/abs/2509.15610)
*Chelsea Shan Xian Ng,Yu Xuan Yeoh,Nicholas Yong Wei Foo,Keerthana Radhakrishnan,Guo Zhan Lum*

Main category: cs.RO

TL;DR: 本研究开发了一种可重新编程磁化轮廓的毫米级软体机器人，具有六自由度运动和五种手术功能，克服了现有磁性微型机器人的限制，有望推动微创治疗的发展。


<details>
  <summary>Details</summary>
Motivation: 现有的磁性微型机器人由于最多只有两种功能或有限的五自由度运动，且需在强外部磁铁近距离（<4厘米）下操作，因此不适用于手术。本研究旨在克服这些限制。

Method: 开发了一种毫米级软体机器人，其磁化轮廓可根据命令重新编程，以执行五种手术功能：药物释放、切割生物组织、抓取、存储生物样本和远程加热。该机器人具有完整的六自由度运动。

Result: 该软体机器人能够在具有挑战性的非结构化环境中滚动和双锚爬行，这些环境是其五自由度对应物无法通过的。此外，由于其驱动磁场相对均匀且较弱（最多65 mT和1.5 T/m），理论上可以无害地穿透生物组织，使机器人在人体深处仍可控制。

Conclusion: 本研究标志着软体执行器发展的一个重要里程碑，有望通过具有前所未有功能的微型无绳机器人彻底改变微创治疗。

Abstract: Miniature robots are untethered actuators, which have significant potential
to make existing minimally invasive surgery considerably safer and painless,
and enable unprecedented treatments because they are much smaller and dexterous
than existing surgical robots. Of the miniature robots, the magnetically
actuated ones are the most functional and dexterous. However, existing magnetic
miniature robots are currently impractical for surgery because they are either
restricted to possessing at most two on-board functionalities or having limited
five degrees-of-freedom (DOF) locomotion. Some of these actuators are also only
operational under specialized environments where actuation from strong external
magnets must be at very close proximity (< 4 cm away). Here we present a
millimeter-scale soft robot where its magnetization profile can be reprogrammed
upon command to perform five surgical functionalities: drug-dispensing, cutting
through biological tissues (simulated with gelatin), gripping, storing
(biological) samples and remote heating. By possessing full six-DOF motions,
including the sixth-DOF rotation about its net magnetic moment, our soft robot
can also roll and two-anchor crawl across challenging unstructured
environments, which are impassable by its five-DOF counterparts. Because our
actuating magnetic fields are relatively uniform and weak (at most 65 mT and
1.5 T/m), such fields can theoretically penetrate through biological tissues
harmlessly and allow our soft robot to remain controllable within the depths of
the human body. We envision that this work marks a major milestone for the
advancement of soft actuators, and towards revolutionizing minimally invasive
treatments with untethered miniature robots that have unprecedented
functionalities.

</details>


### [138] [Indoor Positioning Based on Active Radar Sensing and Passive Reflectors: Reflector Placement Optimization](https://arxiv.org/abs/2509.15613)
*Sven Hinderer,Pascal Schlachter,Zhibin Yu,Xiaofeng Wu,Bin Yang*

Main category: cs.RO

TL;DR: 提出了一种基于雷达反射器的低成本高精度室内定位系统，并通过MO-PSO算法优化反射器布置。


<details>
  <summary>Details</summary>
Motivation: 为自主移动机器人（AMRs）开发一种低成本、高精度的室内定位系统（IPS）。

Method: 使用单通道频率调制连续波（FMCW）雷达和简单反射器，结合多目标（MO）粒子群优化（PSO）算法优化反射器的二维布置。

Result: 系统在低成本下实现了高定位精度，并通过MO-PSO算法有效优化了反射器布置。

Conclusion: 通过结合简单反射器和单通道FMCW雷达，该系统在低成本下实现了高定位精度，并通过MO-PSO算法优化了复杂环境中的反射器布置。

Abstract: We extend our work on a novel indoor positioning system (IPS) for autonomous
mobile robots (AMRs) based on radar sensing of local, passive radar reflectors.
Through the combination of simple reflectors and a single-channel frequency
modulated continuous wave (FMCW) radar, high positioning accuracy at low system
cost can be achieved. Further, a multi-objective (MO) particle swarm
optimization (PSO) algorithm is presented that optimizes the 2D placement of
radar reflectors in complex room settings.

</details>


### [139] [Omni-LIVO: Robust RGB-Colored Multi-Camera Visual-Inertial-LiDAR Odometry via Photometric Migration and ESIKF Fusion](https://arxiv.org/abs/2509.15673)
*Yinong Cao,Xin He,Yuwei Chen,Chenyang Zhang,Chengyu Pu,Bingtao Wang,Kaile Wu,Shouzheng Zhu,Fei Han,Shijie Liu,Chunlai Li,Jianyu Wang*

Main category: cs.RO

TL;DR: Omni-LIVO是首个紧密耦合的多相机LIVO系统，通过跨视角跟踪和多视角更新的ESIKF，提升了宽视场LiDAR与传统相机间的性能。


<details>
  <summary>Details</summary>
Motivation: 现有LIVO系统依赖单一相机，导致空间覆盖有限且鲁棒性下降。本文旨在解决宽视场LiDAR与传统相机之间的视场不匹配问题。

Method: Omni-LIVO采用跨视角直接跟踪策略保持非重叠视图间的光度一致性，并扩展了ESIKF以支持多视角更新和自适应协方差加权。

Result: 在公开基准和自定义数据集上的评估表明，Omni-LIVO在精度和鲁棒性上优于现有LIVO、LIO和视觉-惯性基线。

Conclusion: Omni-LIVO通过跨视角直接跟踪策略和多视角更新的ESIKF，显著提升了LIVO系统的精度和鲁棒性。

Abstract: Wide field-of-view (FoV) LiDAR sensors provide dense geometry across large
environments, but most existing LiDAR-inertial-visual odometry (LIVO) systems
rely on a single camera, leading to limited spatial coverage and degraded
robustness. We present Omni-LIVO, the first tightly coupled multi-camera LIVO
system that bridges the FoV mismatch between wide-angle LiDAR and conventional
cameras. Omni-LIVO introduces a Cross-View direct tracking strategy that
maintains photometric consistency across non-overlapping views, and extends the
Error-State Iterated Kalman Filter (ESIKF) with multi-view updates and adaptive
covariance weighting. The system is evaluated on public benchmarks and our
custom dataset, showing improved accuracy and robustness over state-of-the-art
LIVO, LIO, and visual-inertial baselines. Code and dataset will be released
upon publication.

</details>


### [140] [Imagination at Inference: Synthesizing In-Hand Views for Robust Visuomotor Policy Inference](https://arxiv.org/abs/2509.15717)
*Haoran Ding,Anqing Duan,Zezhou Sun,Dezhen Song,Yoshihiko Nakamura*

Main category: cs.RO

TL;DR: 该论文提出了一种通过新颖视角合成技术让机器人‘想象’手部视角观察的方法，显著提升了视觉运动策略的性能，无需依赖实际手部摄像头。


<details>
  <summary>Details</summary>
Motivation: 在机器人操作中，手部视角观察对精确控制至关重要，但配备专用手部摄像头可能因硬件限制、系统复杂性和成本而面临挑战。

Method: 利用基于LoRA的微调技术，将预训练的NVS模型（ZeroNVS）适配到机器人操作领域，通过相对姿态条件生成合成的手部视角观察。

Result: 在仿真基准（RoboMimic和MimicGen）和真实实验（Unitree Z1机械臂草莓采摘任务）中，合成的手部视角观察显著提升了策略推理性能，有效弥补了缺少真实手部摄像头带来的性能下降。

Conclusion: 该方法通过新颖的视角合成技术，显著提升了策略推理性能，为部署稳健的视觉运动策略提供了可扩展且硬件轻量的解决方案。

Abstract: Visual observations from different viewpoints can significantly influence the
performance of visuomotor policies in robotic manipulation. Among these,
egocentric (in-hand) views often provide crucial information for precise
control. However, in some applications, equipping robots with dedicated in-hand
cameras may pose challenges due to hardware constraints, system complexity, and
cost. In this work, we propose to endow robots with imaginative perception -
enabling them to 'imagine' in-hand observations from agent views at inference
time. We achieve this via novel view synthesis (NVS), leveraging a fine-tuned
diffusion model conditioned on the relative pose between the agent and in-hand
views cameras. Specifically, we apply LoRA-based fine-tuning to adapt a
pretrained NVS model (ZeroNVS) to the robotic manipulation domain. We evaluate
our approach on both simulation benchmarks (RoboMimic and MimicGen) and
real-world experiments using a Unitree Z1 robotic arm for a strawberry picking
task. Results show that synthesized in-hand views significantly enhance policy
inference, effectively recovering the performance drop caused by the absence of
real in-hand cameras. Our method offers a scalable and hardware-light solution
for deploying robust visuomotor policies, highlighting the potential of
imaginative visual reasoning in embodied agents.

</details>


### [141] [GP3: A 3D Geometry-Aware Policy with Multi-View Images for Robotic Manipulation](https://arxiv.org/abs/2509.15733)
*Quanhao Qian,Guoyang Zhao,Gongjie Zhang,Jiuniu Wang,Ran Xu,Junlong Gao,Deli Zhao*

Main category: cs.RO

TL;DR: GP3是一个基于多视角输入的3D几何感知机器人操作策略，通过空间编码器和轻量级策略头实现高效操作，并在模拟和真实环境中表现出色。


<details>
  <summary>Details</summary>
Motivation: 机器人操作需要精确理解3D场景几何，而多视角观测是获取几何的最直接方式之一。

Method: GP3采用空间编码器从RGB观测中推断密集的空间特征，估计深度和相机参数，生成紧凑且表达力强的3D场景表示，并与语言指令融合，通过轻量级策略头转化为连续动作。

Result: GP3在模拟基准测试中始终优于最先进方法，并能有效迁移到真实世界机器人。

Conclusion: GP3是一个实用的、传感器无关的解决方案，适用于几何感知的机器人操作，无需深度传感器或预映射环境，仅需少量微调即可有效迁移到真实世界机器人。

Abstract: Effective robotic manipulation relies on a precise understanding of 3D scene
geometry, and one of the most straightforward ways to acquire such geometry is
through multi-view observations. Motivated by this, we present GP3 -- a 3D
geometry-aware robotic manipulation policy that leverages multi-view input. GP3
employs a spatial encoder to infer dense spatial features from RGB
observations, which enable the estimation of depth and camera parameters,
leading to a compact yet expressive 3D scene representation tailored for
manipulation. This representation is fused with language instructions and
translated into continuous actions via a lightweight policy head. Comprehensive
experiments demonstrate that GP3 consistently outperforms state-of-the-art
methods on simulated benchmarks. Furthermore, GP3 transfers effectively to
real-world robots without depth sensors or pre-mapped environments, requiring
only minimal fine-tuning. These results highlight GP3 as a practical,
sensor-agnostic solution for geometry-aware robotic manipulation.

</details>


### [142] [SMART: Scalable Multi-Agent Reasoning and Trajectory Planning in Dense Environments](https://arxiv.org/abs/2509.15737)
*Heye Huang,Yibin Yang,Wang Chen,Tiantian Chen,Xiaopeng Li,Sikai Chen*

Main category: cs.RO

TL;DR: SMART框架通过分层设计和分布式优化，高效解决了多车辆轨迹规划问题，显著提升了实时性和可扩展性，实验表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 多车辆轨迹规划在密集环境中因碰撞约束的快速增长变得困难，需要高效探索可行行为和解决紧密交互以实现实时大规模协调。

Method: 结合基于强化学习的优先级估计和大步长混合A*搜索的上层，以及并行可解凸优化的下层，通过空间分区和鲁棒可行走廊构建，将联合非凸问题分解为并行高效的凸子问题。

Result: 在50m x 50m地图上，SMART在1秒内对25辆车的成功率超过90%，而基线方法常低于50%。在100m x 100m地图上，SMART对50辆车的成功率超过95%，且可扩展到90辆车，运行时间比仅优化方法快一个数量级。

Conclusion: SMART框架通过分层设计和分布式优化，有效解决了多车辆轨迹规划的非凸问题，显著提升了实时性和可扩展性。

Abstract: Multi-vehicle trajectory planning is a non-convex problem that becomes
increasingly difficult in dense environments due to the rapid growth of
collision constraints. Efficient exploration of feasible behaviors and
resolution of tight interactions are essential for real-time, large-scale
coordination. This paper introduces SMART, Scalable Multi-Agent Reasoning and
Trajectory Planning, a hierarchical framework that combines priority-based
search with distributed optimization to achieve efficient and feasible
multi-vehicle planning. The upper layer explores diverse interaction modes
using reinforcement learning-based priority estimation and large-step hybrid A*
search, while the lower layer refines solutions via parallelizable convex
optimization. By partitioning space among neighboring vehicles and constructing
robust feasible corridors, the method decouples the joint non-convex problem
into convex subproblems solved efficiently in parallel. This design alleviates
the step-size trade-off while ensuring kinematic feasibility and collision
avoidance. Experiments show that SMART consistently outperforms baselines. On
50 m x 50 m maps, it sustains over 90% success within 1 s up to 25 vehicles,
while baselines often drop below 50%. On 100 m x 100 m maps, SMART achieves
above 95% success up to 50 vehicles and remains feasible up to 90 vehicles,
with runtimes more than an order of magnitude faster than optimization-only
approaches. Built on vehicle-to-everything communication, SMART incorporates
vehicle-infrastructure cooperation through roadside sensing and agent
coordination, improving scalability and safety. Real-world experiments further
validate this design, achieving planning times as low as 0.014 s while
preserving cooperative behaviors.

</details>


### [143] [FlyKites: Human-centric Interactive Exploration and Assistance under Limited Communication](https://arxiv.org/abs/2509.15807)
*Yuyang Zhang,Zhuoli Tian,Jinsheng Wei,Meng Guo*

Main category: cs.RO

TL;DR: FlyKites是一种针对有限通信环境下多机器人探索与协助的框架，结合分布式探索、中继优化和人机交互，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 在极端环境下（如洞穴和地下隧道），机器人间的通信受限，传统方法难以实现高效探索与协助。

Method: 框架包含三个部分：分布式探索与间歇通信（spread mode）、中继拓扑与操作路径的同步优化（relay mode）、以及人机交互的在线执行。

Result: 通过大量模拟和硬件实验验证，FlyKites在多挑战场景中表现出色。

Conclusion: FlyKites框架通过分布式探索、中继拓扑优化和人机交互执行，有效解决了多机器人系统在有限通信下的探索与协助问题，实验验证了其高效性和适应性。

Abstract: Fleets of autonomous robots have been deployed for exploration of unknown
scenes for features of interest, e.g., subterranean exploration,
reconnaissance, search and rescue missions. During exploration, the robots may
encounter un-identified targets, blocked passages, interactive objects,
temporary failure, or other unexpected events, all of which require consistent
human assistance with reliable communication for a time period. This however
can be particularly challenging if the communication among the robots is
severely restricted to only close-range exchange via ad-hoc networks,
especially in extreme environments like caves and underground tunnels. This
paper presents a novel human-centric interactive exploration and assistance
framework called FlyKites, for multi-robot systems under limited communication.
It consists of three interleaved components: (I) the distributed exploration
and intermittent communication (called the "spread mode"), where the robots
collaboratively explore the environment and exchange local data among the fleet
and with the operator; (II) the simultaneous optimization of the relay
topology, the operator path, and the assignment of robots to relay roles
(called the "relay mode"), such that all requested assistance can be provided
with minimum delay; (III) the human-in-the-loop online execution, where the
robots switch between different roles and interact with the operator
adaptively. Extensive human-in-the-loop simulations and hardware experiments
are performed over numerous challenging scenes.

</details>


### [144] [Coordinated Multi-Drone Last-mile Delivery: Learning Strategies for Energy-aware and Timely Operations](https://arxiv.org/abs/2509.15830)
*Chuhao Qin,Arun Narayanan,Evangelos Pournaras*

Main category: cs.RO

TL;DR: 本文提出了一种基于多智能体深度强化学习的算法，优化无人机群的多包裹配送，兼顾能源效率和时效性，实验证明其在减少能源消耗和延迟方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 无人机作为一种快速、安全且经济高效的最后一公里配送方式，尤其在疫情期间的紧急医疗配送中表现突出。本文旨在解决能源感知无人机群在多包裹配送中的新挑战，同时满足客户的时间敏感需求。

Method: 通过将问题分解为三个子问题：（1）使用K-means聚类优化仓库位置和服务区域；（2）通过强化学习确定无人机的最佳飞行范围；（3）通过新的优化计划选择方法规划和选择多包裹配送路线。最终提出了一种基于演员-评论家的多智能体深度强化学习算法来整合这些解决方案。

Result: 通过使用真实配送数据集进行广泛实验，证明了所提算法的卓越性能，提供了关于经济效率（最小化能源消耗）、快速操作（减少配送延迟和总执行时间）以及仓库部署策略的新见解。

Conclusion: 本文提出了一种基于多智能体深度强化学习的新型算法，用于优化多包裹无人机群配送，兼顾能源效率和时效性。实验结果表明，该算法在减少能源消耗和配送延迟方面表现优异，并为实际物流应用提供了经济高效和快速操作的策略指导。

Abstract: Drones have recently emerged as a faster, safer, and cost-efficient way for
last-mile deliveries of parcels, particularly for urgent medical deliveries
highlighted during the pandemic. This paper addresses a new challenge of
multi-parcel delivery with a swarm of energy-aware drones, accounting for
time-sensitive customer requirements. Each drone plans an optimal multi-parcel
route within its battery-restricted flight range to minimize delivery delays
and reduce energy consumption. The problem is tackled by decomposing it into
three sub-problems: (1) optimizing depot locations and service areas using
K-means clustering; (2) determining the optimal flight range for drones through
reinforcement learning; and (3) planning and selecting multi-parcel delivery
routes via a new optimized plan selection approach. To integrate these
solutions and enhance long-term efficiency, we propose a novel algorithm
leveraging actor-critic-based multi-agent deep reinforcement learning.
Extensive experimentation using realistic delivery datasets demonstrate an
exceptional performance of the proposed algorithm. We provide new insights into
economic efficiency (minimize energy consumption), rapid operations (reduce
delivery delays and overall execution time), and strategic guidance on depot
deployment for practical logistics applications.

</details>


### [145] [High-Bandwidth Tactile-Reactive Control for Grasp Adjustment](https://arxiv.org/abs/2509.15876)
*Yonghyeon Lee,Tzu-Yuan Lin,Alexander Alexiev,Sangbae Kim*

Main category: cs.RO

TL;DR: 论文提出了一种无需物体几何先验或精确初始抓取姿态的纯触觉反馈抓取调整算法，通过实验验证其能有效提升抓取稳定性。


<details>
  <summary>Details</summary>
Motivation: 视觉抓取系统受限于标定误差、传感器噪声和抓取姿态预测不准确，导致最终抓取阶段存在不可避免的接触不确定性。高带宽触觉反馈与设计良好的触觉反应控制器可以显著提升对感知误差的鲁棒性。

Method: 通过模拟研究和真实世界实验，使用配备200Hz指尖触觉传感器的15自由度臂手系统（含8自由度手）验证了触觉反应抓取框架的有效性。

Result: 实验证明，所提出的触觉反应抓取框架能够有效提升抓取稳定性。

Conclusion: 该论文提出的纯触觉反馈抓取调整算法能够有效提升抓取稳定性，无需依赖物体几何的先验知识或精确的初始抓取姿态。

Abstract: Vision-only grasping systems are fundamentally constrained by calibration
errors, sensor noise, and grasp pose prediction inaccuracies, leading to
unavoidable contact uncertainty in the final stage of grasping. High-bandwidth
tactile feedback, when paired with a well-designed tactile-reactive controller,
can significantly improve robustness in the presence of perception errors. This
paper contributes to controller design by proposing a purely tactile-feedback
grasp-adjustment algorithm. The proposed controller requires neither prior
knowledge of the object's geometry nor an accurate grasp pose, and is capable
of refining a grasp even when starting from a crude, imprecise initial
configuration and uncertain contact points. Through simulation studies and
real-world experiments on a 15-DoF arm-hand system (featuring an 8-DoF hand)
equipped with fingertip tactile sensors operating at 200 Hz, we demonstrate
that our tactile-reactive grasping framework effectively improves grasp
stability.

</details>


### [146] [Improving Robotic Manipulation with Efficient Geometry-Aware Vision Encoder](https://arxiv.org/abs/2509.15880)
*An Dinh Vuong,Minh Nhat Vu,Ian Reid*

Main category: cs.RO

TL;DR: 研究提出高效几何感知编码器eVGGT，提升模仿学习性能，同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB模仿学习方法缺乏显式的3D推理能力，而几何基础的视觉模型虽能提供强大的空间理解，但计算成本高，限制了其在机器人系统中的实际应用。

Method: 本研究提出eVGGT，一种从VGGT蒸馏出的高效几何感知编码器，旨在降低计算成本。

Result: 实验表明，将几何感知视觉编码器集成到模仿学习框架中，成功率提高了6.5%，且eVGGT比VGGT快9倍、小5倍。

Conclusion: eVGGT作为一种高效的几何感知编码器，在保持强大3D推理能力的同时，显著降低了计算成本，为几何感知机器人技术的实际部署提供了可行方案。

Abstract: Existing RGB-based imitation learning approaches typically employ traditional
vision encoders such as ResNet or ViT, which lack explicit 3D reasoning
capabilities. Recent geometry-grounded vision models, such as
VGGT~\cite{wang2025vggt}, provide robust spatial understanding and are
promising candidates to address this limitation. This work investigates the
integration of geometry-aware visual representations into robotic manipulation.
Our results suggest that incorporating the geometry-aware vision encoder into
imitation learning frameworks, including ACT and DP, yields up to 6.5%
improvement over standard vision encoders in success rate across single- and
bi-manual manipulation tasks in both simulation and real-world settings.
Despite these benefits, most geometry-grounded models require high
computational cost, limiting their deployment in practical robotic systems. To
address this challenge, we propose eVGGT, an efficient geometry-aware encoder
distilled from VGGT. eVGGT is nearly 9 times faster and 5 times smaller than
VGGT, while preserving strong 3D reasoning capabilities. Code and pretrained
models will be released to facilitate further research in geometry-aware
robotics.

</details>


### [147] [An MPC framework for efficient navigation of mobile robots in cluttered environments](https://arxiv.org/abs/2509.15917)
*Johannes Köhler,Daniel Zhang,Raffaele Soloperto,Andrea Carron,Melanie Zeilinger*

Main category: cs.RO

TL;DR: 提出了一种集成最短路径规划的MPC框架，用于移动机器人在复杂环境中的高效导航，实验验证了其性能和实时性。


<details>
  <summary>Details</summary>
Motivation: 为了解决移动机器人在杂乱环境中的导航问题，尤其是在非线性动力学和动态目标选择下的挑战。

Method: 该方法将有限段最短路径规划器集成到MPC的有限时间轨迹优化中，确保了对动态选择目标的收敛性和碰撞避免。

Result: 硬件实验表明，机器人能在2-3秒内成功导航至新目标，验证了方法的有效性。

Conclusion: 该论文提出的MPC框架成功实现了在复杂环境中移动机器人的高效导航，通过硬件实验验证了其有效性和实时性。

Abstract: We present a model predictive control (MPC) framework for efficient
navigation of mobile robots in cluttered environments. The proposed approach
integrates a finite-segment shortest path planner into the finite-horizon
trajectory optimization of the MPC. This formulation ensures convergence to
dynamically selected targets and guarantees collision avoidance, even under
general nonlinear dynamics and cluttered environments. The approach is
validated through hardware experiments on a small ground robot, where a human
operator dynamically assigns target locations. The robot successfully navigated
through complex environments and reached new targets within 2-3 seconds.

</details>


### [148] [A Vision-Language-Action-Critic Model for Robotic Real-World Reinforcement Learning](https://arxiv.org/abs/2509.15937)
*Shaopeng Zhai,Qi Zhang,Tianyi Zhang,Fuxian Huang,Haoran Zhang,Ming Zhou,Shengzhe Zhang,Litao Liu,Sixu Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: VLAC是一种基于视觉语言动作模型的通用过程奖励模型，通过大规模数据集训练和人类干预，显著提升了机器人强化学习的成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决机器人强化学习中稀疏、手工设计的奖励和低效探索的问题，提出一种通用的过程奖励模型。

Method: VLAC模型基于InternVL构建，通过训练于视觉语言数据集和机器人及人类轨迹数据，生成密集的进度增量和完成信号，支持一次性上下文迁移，并统一了批评和策略。

Result: 在四个真实世界操作任务中，VLAC将成功率从约30%提升至约90%，结合人类干预后进一步提高了50%的样本效率，并达到100%的最终成功率。

Conclusion: VLAC模型通过结合视觉-语言-动作（VLA）模型和大规模异构数据集训练，显著提升了机器人强化学习的成功率和样本效率，尤其是在结合人类干预后，实现了近乎完美的成功率。

Abstract: Robotic real-world reinforcement learning (RL) with vision-language-action
(VLA) models is bottlenecked by sparse, handcrafted rewards and inefficient
exploration. We introduce VLAC, a general process reward model built upon
InternVL and trained on large scale heterogeneous datasets. Given pairwise
observations and a language goal, it outputs dense progress delta and done
signal, eliminating task-specific reward engineering, and supports one-shot
in-context transfer to unseen tasks and environments. VLAC is trained on
vision-language datasets to strengthen perception, dialogic and reasoning
capabilities, together with robot and human trajectories data that ground
action generation and progress estimation, and additionally strengthened to
reject irrelevant prompts as well as detect regression or stagnation by
constructing large numbers of negative and semantically mismatched samples.
With prompt control, a single VLAC model alternately generating reward and
action tokens, unifying critic and policy. Deployed inside an asynchronous
real-world RL loop, we layer a graded human-in-the-loop protocol (offline
demonstration replay, return and explore, human guided explore) that
accelerates exploration and stabilizes early learning. Across four distinct
real-world manipulation tasks, VLAC lifts success rates from about 30\% to
about 90\% within 200 real-world interaction episodes; incorporating
human-in-the-loop interventions yields a further 50% improvement in sample
efficiency and achieves up to 100% final success.

</details>


### [149] [Right-Side-Out: Learning Zero-Shot Sim-to-Real Garment Reversal](https://arxiv.org/abs/2509.15953)
*Chang Yu,Siyu Ma,Wenxin Du,Zeshun Zong,Han Xue,Wendi Chen,Cewu Lu,Yin Yang,Xuchen Han,Joseph Masterjohn,Alejandro Castro,Chenfanfu Jiang*

Main category: cs.RO

TL;DR: 该论文提出了一种零样本模拟到真实的框架，通过任务分解和高保真模拟，成功解决了衣物翻转的挑战性问题。


<details>
  <summary>Details</summary>
Motivation: 解决衣物翻转这一高度动态、视觉遮挡严重的操作难题。

Method: Right-Side-Out框架将任务分解为Drag/Fling和Insert&Pull两个步骤，使用深度推断和关键点参数化的双手操作原语，大幅减少动作空间。通过定制的高保真GPU并行MPM模拟器实现高效数据生成。

Result: 仅使用单个深度摄像头，完全在模拟中训练的策略在真实硬件上实现了零样本部署，成功率高达81.3%。

Conclusion: 通过任务分解和高保真模拟，该框架能够处理高度动态且严重遮挡的任务，无需繁琐的人工演示。

Abstract: Turning garments right-side out is a challenging manipulation task: it is
highly dynamic, entails rapid contact changes, and is subject to severe visual
occlusion. We introduce Right-Side-Out, a zero-shot sim-to-real framework that
effectively solves this challenge by exploiting task structures. We decompose
the task into Drag/Fling to create and stabilize an access opening, followed by
Insert&Pull to invert the garment. Each step uses a depth-inferred,
keypoint-parameterized bimanual primitive that sharply reduces the action space
while preserving robustness. Efficient data generation is enabled by our
custom-built, high-fidelity, GPU-parallel Material Point Method (MPM) simulator
that models thin-shell deformation and provides robust and efficient contact
handling for batched rollouts. Built on the simulator, our fully automated
pipeline scales data generation by randomizing garment geometry, material
parameters, and viewpoints, producing depth, masks, and per-primitive keypoint
labels without any human annotations. With a single depth camera, policies
trained entirely in simulation deploy zero-shot on real hardware, achieving up
to 81.3% success rate. By employing task decomposition and high fidelity
simulation, our framework enables tackling highly dynamic, severely occluded
tasks without laborious human demonstrations.

</details>


### [150] [Swarm Oracle: Trustless Blockchain Agreements through Robot Swarms](https://arxiv.org/abs/2509.15956)
*Alexandre Pacheco,Hanqing Zhao,Volker Strobel,Tarik Roukny,Gregory Dudek,Andreagiovanni Reina,Marco Dorigo*

Main category: cs.RO

TL;DR: Swarm Oracle利用去中心化机器人群体和拜占庭容错协议，为区块链提供真实世界数据验证，即使在攻击下也能保持安全与自治。


<details>
  <summary>Details</summary>
Motivation: 区块链共识机制限制了真实世界数据的访问，现有Oracle解决方案可能降低自治性或透明度。Swarm Oracle旨在通过去中心化机器人群体解决这一问题，提供灵活、可靠的数据验证。

Method: 提出Swarm Oracle，利用机器人群体的分布式特性和移动性，结合拜占庭容错协议，确保多利益相关方参与的机器人群体能够安全、无信任地达成共识。

Result: 实验表明，Swarm Oracle能在多种攻击下达成共识，并通过声誉系统实现自主恢复，适合长期运行。

Conclusion: Swarm Oracle通过去中心化的机器人群体和拜占庭容错协议，成功实现了对不确定环境信息的共识，即使在大量机器人攻击下也能保持系统安全，并通过基于区块链代币的声誉系统实现自主恢复。

Abstract: Blockchain consensus, rooted in the principle ``don't trust, verify'', limits
access to real-world data, which may be ambiguous or inaccessible to some
participants. Oracles address this limitation by supplying data to blockchains,
but existing solutions may reduce autonomy, transparency, or reintroduce the
need for trust. We propose Swarm Oracle: a decentralized network of autonomous
robots -- that is, a robot swarm -- that use onboard sensors and peer-to-peer
communication to collectively verify real-world data and provide it to smart
contracts on public blockchains. Swarm Oracle leverages the built-in
decentralization, fault tolerance and mobility of robot swarms, which can
flexibly adapt to meet information requests on-demand, even in remote
locations. Unlike typical cooperative robot swarms, Swarm Oracle integrates
robots from multiple stakeholders, protecting the system from single-party
biases but also introducing potential adversarial behavior. To ensure the
secure, trustless and global consensus required by blockchains, we employ a
Byzantine fault-tolerant protocol that enables robots from different
stakeholders to operate together, reaching social agreements of higher quality
than the estimates of individual robots. Through extensive experiments using
both real and simulated robots, we showcase how consensus on uncertain
environmental information can be achieved, despite several types of attacks
orchestrated by large proportions of the robots, and how a reputation system
based on blockchain tokens lets Swarm Oracle autonomously recover from faults
and attacks, a requirement for long-term operation.

</details>


### [151] [CoReVLA: A Dual-Stage End-to-End Autonomous Driving Framework for Long-Tail Scenarios via Collect-and-Refine](https://arxiv.org/abs/2509.15968)
*Shiyu Fang,Yiming Cui,Haoyang Liang,Chen Lv,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: CoReVLA通过持续学习和人类偏好优化，显著提升自动驾驶在长尾场景的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶系统在长尾安全关键场景中性能不足的问题，尤其是缺乏高质量数据和低效学习的问题。

Method: 提出CoReVLA框架，采用双阶段数据收集和行为优化方法：先在开源驾驶QA数据集上微调，再通过CAVE仿真平台收集接管数据，最后使用DPO进行优化。

Result: 在Bench2Drive基准测试中，CoReVLA的驾驶评分(DS)达到72.18，成功率(SR)为50%，分别比现有方法高出7.96 DS和15% SR。

Conclusion: CoReVLA框架通过持续学习和人类偏好优化，显著提升了在长尾安全关键场景下的自动驾驶性能，并在Bench2Drive基准测试中优于现有方法。

Abstract: Autonomous Driving (AD) systems have made notable progress, but their
performance in long-tail, safety-critical scenarios remains limited. These rare
cases contribute a disproportionate number of accidents. Vision-Language Action
(VLA) models have strong reasoning abilities and offer a potential solution,
but their effectiveness is limited by the lack of high-quality data and
inefficient learning in such conditions. To address these challenges, we
propose CoReVLA, a continual learning end-to-end autonomous driving framework
that improves the performance in long-tail scenarios through a dual-stage
process of data Collection and behavior Refinement. First, the model is jointly
fine-tuned on a mixture of open-source driving QA datasets, allowing it to
acquire a foundational understanding of driving scenarios. Next, CoReVLA is
deployed within the Cave Automatic Virtual Environment (CAVE) simulation
platform, where driver takeover data is collected from real-time interactions.
Each takeover indicates a long-tail scenario that CoReVLA fails to handle
reliably. Finally, the model is refined via Direct Preference Optimization
(DPO), allowing it to learn directly from human preferences and thereby avoid
reward hacking caused by manually designed rewards. Extensive open-loop and
closed-loop experiments demonstrate that the proposed CoReVLA model can
accurately perceive driving scenarios and make appropriate decisions. On the
Bench2Drive benchmark, CoReVLA achieves a Driving Score (DS) of 72.18 and a
Success Rate (SR) of 50%, outperforming state-of-the-art methods by 7.96 DS and
15% SR under long-tail, safety-critical scenarios. Furthermore, case studies
demonstrate the model's ability to continually improve its performance in
similar failure-prone scenarios by leveraging past takeover experiences. All
codea and preprocessed datasets are available at:
https://github.com/FanGShiYuu/CoReVLA

</details>


### [152] [Defining and Monitoring Complex Robot Activities via LLMs and Symbolic Reasoning](https://arxiv.org/abs/2509.16006)
*Francesco Argenziano,Elena Umili,Francesco Leotta,Daniele Nardi*

Main category: cs.RO

TL;DR: 论文提出一种结合LLMs与自动化规划的架构，支持自然语言指定高级活动并监控执行，在精准农业中验证有效。


<details>
  <summary>Details</summary>
Motivation: 动态和不可预测环境（如工业和农业）中，机器人执行复杂活动时缺乏预定义流程，且人类监控高级活动进展的需求仍至关重要。

Method: 论文提出了一种通用架构，整合了LLMs与自动化规划技术，并利用最先进的组件在实际场景（精准农业）中进行了实现与定量评估。

Result: 通过在实际精准农业场景中的定量评估，验证了该架构的有效性。

Conclusion: 该论文提出了一种结合大型语言模型（LLMs）与自动化规划的通用架构，有效支持人类通过自然语言指定高级活动并监控机器人执行。

Abstract: Recent years have witnessed a growing interest in automating labor-intensive
and complex activities, i.e., those consisting of multiple atomic tasks, by
deploying robots in dynamic and unpredictable environments such as industrial
and agricultural settings. A key characteristic of these contexts is that
activities are not predefined: while they involve a limited set of possible
tasks, their combinations may vary depending on the situation. Moreover,
despite recent advances in robotics, the ability for humans to monitor the
progress of high-level activities - in terms of past, present, and future
actions - remains fundamental to ensure the correct execution of
safety-critical processes. In this paper, we introduce a general architecture
that integrates Large Language Models (LLMs) with automated planning, enabling
humans to specify high-level activities (also referred to as processes) using
natural language, and to monitor their execution by querying a robot. We also
present an implementation of this architecture using state-of-the-art
components and quantitatively evaluate the approach in a real-world precision
agriculture scenario.

</details>


### [153] [A Matter of Height: The Impact of a Robotic Object on Human Compliance](https://arxiv.org/abs/2509.16032)
*Michael Faber,Andrey Grishko,Julian Waksberg,David Pardo,Tomer Leivy,Yuval Hazan,Emanuel Talmansky,Benny Megidish,Hadas Erel*

Main category: cs.RO

TL;DR: 研究发现，在人类与机器人互动中，机器人的高度对服从性有显著影响，但模式与人类互动相反：较矮的机器人更易获得服从。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人高度对人类服从性的影响，验证是否与人类互动中的高度效应一致。

Method: 设计可调节高度的非人形机器人，比较不同高度（95cm vs. 132cm）下参与者对繁琐任务的志愿服从率。

Result: 较矮的机器人（95cm）获得更高的服从率，与人类互动中的高度效应相反。

Conclusion: 机器人高度对其社会影响力有独特模式，设计时需独立验证，不可直接套用人类社交动态。

Abstract: Robots come in various forms and have different characteristics that may
shape the interaction with them. In human-human interactions, height is a
characteristic that shapes human dynamics, with taller people typically
perceived as more persuasive. In this work, we aspired to evaluate if the same
impact replicates in a human-robot interaction and specifically with a highly
non-humanoid robotic object. The robot was designed with modules that could be
easily added or removed, allowing us to change its height without altering
other design features. To test the impact of the robot's height, we evaluated
participants' compliance with its request to volunteer to perform a tedious
task. In the experiment, participants performed a cognitive task on a computer,
which was framed as the main experiment. When done, they were informed that the
experiment was completed. While waiting to receive their credits, the robotic
object, designed as a mobile robotic service table, entered the room, carrying
a tablet that invited participants to complete a 300-question questionnaire
voluntarily. We compared participants' compliance in two conditions: A Short
robot composed of two modules and 95cm in height and a Tall robot consisting of
three modules and 132cm in height. Our findings revealed higher compliance with
the Short robot's request, demonstrating an opposite pattern to human dynamics.
We conclude that while height has a substantial social impact on human-robot
interactions, it follows a unique pattern of influence. Our findings suggest
that designers cannot simply adopt and implement elements from human social
dynamics to robots without testing them first.

</details>


### [154] [Learning Safety for Obstacle Avoidance via Control Barrier Functions](https://arxiv.org/abs/2509.16037)
*Shuo Liu,Zhe Huang,Calin A. Belta*

Main category: cs.RO

TL;DR: A neural network-based method for fast clearance prediction enables collision-free navigation in cluttered environments, outperforming traditional CBF approaches in speed and accuracy.


<details>
  <summary>Details</summary>
Motivation: Existing Control Barrier Function (CBF) approaches are limited by infeasible analytic clearance computations for complex geometries or intractable polytopic approximations for unknown robot configurations, necessitating a more efficient and accurate solution.

Method: The paper trains a residual neural network on a large dataset of robot-obstacle configurations to enable fast and tractable clearance prediction. The predicted clearance defines the radius of a Local Safety Ball (LSB), encoded as a Discrete-Time High-Order CBF (DHOCBF), incorporated into a nonlinear optimization framework with a novel relaxation technique.

Result: Experiments demonstrate millisecond-level solve times and high prediction accuracy, outperforming existing CBF-based methods in both safety and efficiency.

Conclusion: The proposed method effectively bridges discrete-time control and continuous-time safety, handling arbitrary robot geometries and generating collision-free, dynamically feasible trajectories in cluttered environments with high efficiency.

Abstract: Obstacle avoidance is central to safe navigation, especially for robots with
arbitrary and nonconvex geometries operating in cluttered environments.
Existing Control Barrier Function (CBF) approaches often rely on analytic
clearance computations, which are infeasible for complex geometries, or on
polytopic approximations, which become intractable when robot configurations
are unknown. To address these limitations, this paper trains a residual neural
network on a large dataset of robot-obstacle configurations to enable fast and
tractable clearance prediction, even at unseen configurations. The predicted
clearance defines the radius of a Local Safety Ball (LSB), which ensures
continuous-time collision-free navigation. The LSB boundary is encoded as a
Discrete-Time High-Order CBF (DHOCBF), whose constraints are incorporated into
a nonlinear optimization framework. To improve feasibility, a novel relaxation
technique is applied. The resulting framework ensure that the robot's
rigid-body motion between consecutive time steps remains collision-free,
effectively bridging discrete-time control and continuous-time safety. We show
that the proposed method handles arbitrary, including nonconvex, robot
geometries and generates collision-free, dynamically feasible trajectories in
cluttered environments. Experiments demonstrate millisecond-level solve times
and high prediction accuracy, highlighting both safety and efficiency beyond
existing CBF-based methods.

</details>


### [155] [Compose by Focus: Scene Graph-based Atomic Skills](https://arxiv.org/abs/2509.16053)
*Han Qi,Changhe Chen,Heng Yang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于场景图的技能学习框架，结合图神经网络和扩散模仿学习，显著提高了机器人长时程任务的成功率和组合泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决通用机器人组合泛化的挑战，即如何将原子技能组合以解决复杂、长时程任务，同时克服视觉运动策略在场景组合引起的分布偏移下的失败问题。

Method: 结合图神经网络与扩散模仿学习的方法，开发了一个场景图技能学习框架，并与基于视觉语言模型的任务规划器集成。

Result: 在仿真和真实世界的操作任务中，实验结果显示比现有最先进基线方法更高的成功率。

Conclusion: 该论文提出的基于场景图的技能学习框架和视觉语言模型任务规划器的组合，显著提高了长时程任务的成功率，展示了在鲁棒性和组合泛化方面的改进。

Abstract: A key requirement for generalist robots is compositional generalization - the
ability to combine atomic skills to solve complex, long-horizon tasks. While
prior work has primarily focused on synthesizing a planner that sequences
pre-learned skills, robust execution of the individual skills themselves
remains challenging, as visuomotor policies often fail under distribution
shifts induced by scene composition. To address this, we introduce a scene
graph-based representation that focuses on task-relevant objects and relations,
thereby mitigating sensitivity to irrelevant variation. Building on this idea,
we develop a scene-graph skill learning framework that integrates graph neural
networks with diffusion-based imitation learning, and further combine "focused"
scene-graph skills with a vision-language model (VLM) based task planner.
Experiments in both simulation and real-world manipulation tasks demonstrate
substantially higher success rates than state-of-the-art baselines,
highlighting improved robustness and compositional generalization in
long-horizon tasks.

</details>


### [156] [Latent Conditioned Loco-Manipulation Using Motion Priors](https://arxiv.org/abs/2509.16061)
*Maciej Stępień,Rafael Kourdis,Constant Roux,Olivier Stasse*

Main category: cs.RO

TL;DR: 提出一种通过模仿学习和潜在空间控制的多用途运动策略，有效解决复杂机器人任务，并在仿真和硬件中验证。


<details>
  <summary>Details</summary>
Motivation: 当前的深度强化学习方法主要关注单一技能，难以应对需要考虑高级目标、物理机器人限制和期望运动风格的复杂任务。

Method: 首先训练一个多用途运动策略，通过模仿学习获取低级技能，同时提供潜在空间控制技能执行。然后，扩展原始公式以处理约束条件，并使用扩散判别器提高模仿质量。

Result: 在H1人形机器人和Solo12四足机器人的仿真中成功执行了运动控制任务，并在Solo12硬件上部署了策略。

Conclusion: 该方法通过模仿学习和潜在空间控制，成功应用于人形和四足机器人的运动控制，并在仿真和硬件部署中验证了其有效性。

Abstract: Although humanoid and quadruped robots provide a wide range of capabilities,
current control methods, such as Deep Reinforcement Learning, focus mainly on
single skills. This approach is inefficient for solving more complicated tasks
where high-level goals, physical robot limitations and desired motion style
might all need to be taken into account. A more effective approach is to first
train a multipurpose motion policy that acquires low-level skills through
imitation, while providing latent space control over skill execution. Then,
this policy can be used to efficiently solve downstream tasks. This method has
already been successful for controlling characters in computer graphics. In
this work, we apply the approach to humanoid and quadrupedal loco-manipulation
by imitating either simple synthetic motions or kinematically retargeted dog
motions. We extend the original formulation to handle constraints, ensuring
deployment safety, and use a diffusion discriminator for better imitation
quality. We verify our methods by performing loco-manipulation in simulation
for the H1 humanoid and Solo12 quadruped, as well as deploying policies on
Solo12 hardware. Videos and code are available at
https://gepetto.github.io/LaCoLoco/

</details>


### [157] [DSPv2: Improved Dense Policy for Effective and Generalizable Whole-body Mobile Manipulation](https://arxiv.org/abs/2509.16063)
*Yue Su,Chubin Zhang,Sijin Chen,Liufan Tan,Yansong Tang,Jianan Wang,Xihui Liu*

Main category: cs.RO

TL;DR: DSPv2通过融合3D空间与2D语义特征，提升全身移动操作的泛化与控制精度，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在机器人技能泛化中面临复杂观察处理、鲁棒泛化和动作连贯性生成的挑战。

Method: 提出DSPv2架构，结合3D空间特征与多视角2D语义特征的编码方案，扩展密集策略范式至全身移动操作领域。

Result: 实验表明DSPv2在任务性能和泛化能力上显著优于现有方法。

Conclusion: DSPv2作为一种新型策略架构，通过有效编码方案和密集策略范式，显著提升了全身移动操作的泛化能力和控制精度，实验证明其在任务性能和泛化能力上优于现有方法。

Abstract: Learning whole-body mobile manipulation via imitation is essential for
generalizing robotic skills to diverse environments and complex tasks. However,
this goal is hindered by significant challenges, particularly in effectively
processing complex observation, achieving robust generalization, and generating
coherent actions. To address these issues, we propose DSPv2, a novel policy
architecture. DSPv2 introduces an effective encoding scheme that aligns 3D
spatial features with multi-view 2D semantic features. This fusion enables the
policy to achieve broad generalization while retaining the fine-grained
perception necessary for precise control. Furthermore, we extend the Dense
Policy paradigm to the whole-body mobile manipulation domain, demonstrating its
effectiveness in generating coherent and precise actions for the whole-body
robotic platform. Extensive experiments show that our method significantly
outperforms existing approaches in both task performance and generalization
ability. Project page is available at: https://selen-suyue.github.io/DSPv2Net/.

</details>


### [158] [I-FailSense: Towards General Robotic Failure Detection with Vision-Language Models](https://arxiv.org/abs/2509.16072)
*Clemence Grislain,Hamed Rahimi,Olivier Sigaud,Mohamed Chetouani*

Main category: cs.RO

TL;DR: 提出I-FailSense框架，通过后训练VLM和集成轻量级分类头，有效检测语义错位错误，并实现零样本泛化。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在开放世界中执行任务时语义错位错误的检测问题，提升机器人任务执行的鲁棒性。

Method: 通过后训练基础视觉语言模型（VLM），并附加轻量级分类头（FS块）到VLM的不同内部层，使用集成机制聚合预测。

Result: I-FailSense在检测语义错位错误方面表现优于现有模型，并能泛化到其他失败类别和环境。

Conclusion: I-FailSense在检测语义错位错误方面优于现有最先进的视觉语言模型，并能够零样本或最小微调下泛化到更广泛的机器人失败类别。数据集和模型已公开发布。

Abstract: Language-conditioned robotic manipulation in open-world settings requires not
only accurate task execution but also the ability to detect failures for robust
deployment in real-world environments. Although recent advances in
vision-language models (VLMs) have significantly improved the spatial reasoning
and task-planning capabilities of robots, they remain limited in their ability
to recognize their own failures. In particular, a critical yet underexplored
challenge lies in detecting semantic misalignment errors, where the robot
executes a task that is semantically meaningful but inconsistent with the given
instruction. To address this, we propose a method for building datasets
targeting Semantic Misalignment Failures detection, from existing
language-conditioned manipulation datasets. We also present I-FailSense, an
open-source VLM framework with grounded arbitration designed specifically for
failure detection. Our approach relies on post-training a base VLM, followed by
training lightweight classification heads, called FS blocks, attached to
different internal layers of the VLM and whose predictions are aggregated using
an ensembling mechanism. Experiments show that I-FailSense outperforms
state-of-the-art VLMs, both comparable in size and larger, in detecting
semantic misalignment errors. Notably, despite being trained only on semantic
misalignment detection, I-FailSense generalizes to broader robotic failure
categories and effectively transfers to other simulation environments and
real-world with zero-shot or minimal post-training. The datasets and models are
publicly released on HuggingFace (Webpage:
https://clemgris.github.io/I-FailSense/).

</details>


### [159] [Real-Time Planning and Control with a Vortex Particle Model for Fixed-Wing UAVs in Unsteady Flows](https://arxiv.org/abs/2509.16079)
*Ashwin Gupta,Kevin Wolfe,Gino Perrotta,Joseph Moore*

Main category: cs.RO

TL;DR: 论文提出了一种实时规划与控制方法，利用轻量级涡粒子模型和GPU加速，优化激进机动在非定常气流中的性能。


<details>
  <summary>Details</summary>
Motivation: 非定常空气动力效应对飞行器性能有深远影响，尤其是在敏捷机动和复杂空气动力环境中。

Method: 采用轻量级涡粒子模型，并行化以实现GPU加速，并结合基于采样的策略优化策略。

Result: 仿真和硬件实验表明，通过使用非定常空气动力学模型重新规划，可以提升在非定常环境气流扰动下进行激进失速后机动的性能。

Conclusion: 通过实时规划与控制方法，结合轻量级涡粒子模型和GPU加速，以及基于采样的策略优化，显著提升了在非定常气流扰动下进行激进失速后机动的性能。

Abstract: Unsteady aerodynamic effects can have a profound impact on aerial vehicle
flight performance, especially during agile maneuvers and in complex
aerodynamic environments. In this paper, we present a real-time planning and
control approach capable of reasoning about unsteady aerodynamics. Our approach
relies on a lightweight vortex particle model, parallelized to allow GPU
acceleration, and a sampling-based policy optimization strategy capable of
leveraging the vortex particle model for predictive reasoning. We demonstrate,
through both simulation and hardware experiments, that by replanning with our
unsteady aerodynamics model, we can improve the performance of aggressive
post-stall maneuvers in the presence of unsteady environmental flow
disturbances.

</details>


### [160] [Efficient Detection of Objects Near a Robot Manipulator via Miniature Time-of-Flight Sensors](https://arxiv.org/abs/2509.16122)
*Carter Sifferman,Mohit Gupta,Michael Gleicher*

Main category: cs.RO

TL;DR: 提出一种利用臂载微型飞行时间传感器检测和定位机器人附近物体的轻量方法，通过构建机器人单独存在时的传感器模型，有效区分机器人自身和外部物体，并评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决使用臂载传感器时区分机器人本身和外部物体的挑战。

Method: 提出了一种计算轻量的方法，利用原始飞行时间信息，构建了一个机器人单独存在时的传感器测量经验模型。

Result: 该方法能够检测机器人附近的小物体，并沿机器人臂长定位物体位置，评估了方法在不同物体类型、位置和环境光照水平下的性能。

Conclusion: 该方法在机器人避障和促进安全人机交互方面具有潜在应用价值。

Abstract: We provide a method for detecting and localizing objects near a robot arm
using arm-mounted miniature time-of-flight sensors. A key challenge when using
arm-mounted sensors is differentiating between the robot itself and external
objects in sensor measurements. To address this challenge, we propose a
computationally lightweight method which utilizes the raw time-of-flight
information captured by many off-the-shelf, low-resolution time-of-flight
sensor. We build an empirical model of expected sensor measurements in the
presence of the robot alone, and use this model at runtime to detect objects in
proximity to the robot. In addition to avoiding robot self-detections in common
sensor configurations, the proposed method enables extra flexibility in sensor
placement, unlocking configurations which achieve more efficient coverage of a
radius around the robot arm. Our method can detect small objects near the arm
and localize the position of objects along the length of a robot link to
reasonable precision. We evaluate the performance of the method with respect to
object type, location, and ambient light level, and identify limiting factors
on performance inherent in the measurement principle. The proposed method has
potential applications in collision avoidance and in facilitating safe
human-robot interaction.

</details>


### [161] [Reward Evolution with Graph-of-Thoughts: A Bi-Level Language Model Framework for Reinforcement Learning](https://arxiv.org/abs/2509.16136)
*Changwei Yao,Xinzi Liu,Chen Li,Marios Savvides*

Main category: cs.RO

TL;DR: RE-GoT通过图推理和视觉反馈自动优化RL奖励函数，显著提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 设计有效的奖励函数是RL中的主要挑战，通常需要大量人力和迭代优化。现有LLM方法存在幻觉、依赖人类反馈及处理复杂多步任务的困难。

Method: 引入了Reward Evolution with Graph-of-Thoughts (RE-GoT)，一个双层框架，通过结构化图推理增强LLMs，并集成VLMs进行自动评估。

Result: 在10个RoboGen和4个ManiSkill2任务中，RE-GoT显著优于现有LLM基线。RoboGen上平均任务成功率提升32.25%，ManiSkill2上达到93.73%平均成功率。

Conclusion: 结合LLMs和VLMs与graph-of-thoughts推理为RL中的自主奖励演化提供了可扩展且有效的解决方案。

Abstract: Designing effective reward functions remains a major challenge in
reinforcement learning (RL), often requiring considerable human expertise and
iterative refinement. Recent advances leverage Large Language Models (LLMs) for
automated reward design, but these approaches are limited by hallucinations,
reliance on human feedback, and challenges with handling complex, multi-step
tasks. In this work, we introduce Reward Evolution with Graph-of-Thoughts
(RE-GoT), a novel bi-level framework that enhances LLMs with structured
graph-based reasoning and integrates Visual Language Models (VLMs) for
automated rollout evaluation. RE-GoT first decomposes tasks into
text-attributed graphs, enabling comprehensive analysis and reward function
generation, and then iteratively refines rewards using visual feedback from
VLMs without human intervention. Extensive experiments on 10 RoboGen and 4
ManiSkill2 tasks demonstrate that RE-GoT consistently outperforms existing
LLM-based baselines. On RoboGen, our method improves average task success rates
by 32.25%, with notable gains on complex multi-step tasks. On ManiSkill2,
RE-GoT achieves an average success rate of 93.73% across four diverse
manipulation tasks, significantly surpassing prior LLM-based approaches and
even exceeding expert-designed rewards. Our results indicate that combining
LLMs and VLMs with graph-of-thoughts reasoning provides a scalable and
effective solution for autonomous reward evolution in RL.

</details>


### [162] [Modeling Elastic-Body Dynamics of Fish Swimming Using a Variational Framework](https://arxiv.org/abs/2509.16145)
*Zhiheng Chen,Wei Wang*

Main category: cs.RO

TL;DR: 研究通过哈密顿原理建立了鱼游泳的全身体动力学模型，揭示了尾拍频率、身体刚度和长度对游泳性能的影响，为生物游泳机制和软体机器人设计提供了指导。


<details>
  <summary>Details</summary>
Motivation: 由于鱼类机器人的高游泳效率和灵活身体产生的波动运动，准确、可解释且计算可行的游泳动力学建模对其设计和控制优化至关重要。

Method: 通过哈密顿原理严格推导出鱼游泳的全身体动力学模型，捕捉了变形鱼体的连续分布弹性，并纳入了流固耦合效应，实现无需规定运动学的自推进运动。

Result: 模拟结果表明，游泳速度和能量效率与尾拍频率呈相反趋势，身体刚度和长度均有明显的最优值。

Conclusion: 研究发现，鱼尾摆动频率与游泳速度和能量效率呈相反趋势，且身体刚度和长度存在最优值，为生物游泳机制和高性能软体机器人设计提供了见解。

Abstract: Fish-inspired aquatic robots are gaining increasing attention in research
communities due to their high swimming speeds and efficient propulsion enabled
by flexible bodies that generate undulatory motions. To support the design
optimizations and control of such systems, accurate, interpretable, and
computationally tractable modeling of the underlying swimming dynamics is
indispensable. In this letter, we present a full-body dynamics model for fish
swimming, rigorously derived from Hamilton's principle. The model captures the
continuously distributed elasticity of a deformable fish body undergoing large
deformations and incorporates fluid-structure coupling effects, enabling
self-propelled motion without prescribing kinematics. A preliminary parameter
study explores the influence of actuation frequency and body stiffness on
swimming speed and cost of transport (COT). Simulation results indicate that
swimming speed and energy efficiency exhibit opposing trends with tail-beat
frequency and that both body stiffness and body length have distinct optimal
values. These findings provide insights into biological swimming mechanisms and
inform the design of high-performance soft robotic swimmers.

</details>


### [163] [Agentic Aerial Cinematography: From Dialogue Cues to Cinematic Trajectories](https://arxiv.org/abs/2509.16176)
*Yifan Lin,Sophie Ziyu Liu,Ran Qi,George Z. Xue,Xinping Song,Chao Qin,Hugh H. -T. Liu*

Main category: cs.RO

TL;DR: ACDC系统利用LLMs和VFMs将自然语言提示直接转换为可执行的无人机视频路径，通过自动化流程生成专业质量的航拍视频。


<details>
  <summary>Details</summary>
Motivation: 解决传统无人机摄影工作流程中需要手动选择路径点和视角的局限性，提高效率并保持一致的性能。

Method: 结合大型语言模型（LLMs）和视觉基础模型（VFMs），通过视觉语言检索管道选择初始路径点，基于偏好的贝叶斯优化框架优化姿态，以及生成安全四旋翼轨迹的运动规划器。

Result: 在仿真和硬件在环实验中验证了ACDC系统，能够稳健地在多样化的室内场景中生成专业质量的视频。

Conclusion: ACDC系统展示了通过自然语言驱动的自主无人机摄影的潜力，无需机器人或摄影专业知识即可生成专业质量的视频。

Abstract: We present Agentic Aerial Cinematography: From Dialogue Cues to Cinematic
Trajectories (ACDC), an autonomous drone cinematography system driven by
natural language communication between human directors and drones. The main
limitation of previous drone cinematography workflows is that they require
manual selection of waypoints and view angles based on predefined human intent,
which is labor-intensive and yields inconsistent performance. In this paper, we
propose employing large language models (LLMs) and vision foundation models
(VFMs) to convert free-form natural language prompts directly into executable
indoor UAV video tours. Specifically, our method comprises a vision-language
retrieval pipeline for initial waypoint selection, a preference-based Bayesian
optimization framework that refines poses using aesthetic feedback, and a
motion planner that generates safe quadrotor trajectories. We validate ACDC
through both simulation and hardware-in-the-loop experiments, demonstrating
that it robustly produces professional-quality footage across diverse indoor
scenes without requiring expertise in robotics or cinematography. These results
highlight the potential of embodied AI agents to close the loop from
open-vocabulary dialogue to real-world autonomous aerial cinematography.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [164] [Evaluating the Limitations of Local LLMs in Solving Complex Programming Challenges](https://arxiv.org/abs/2509.15283)
*Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo*

Main category: cs.SE

TL;DR: 研究评估了开源本地LLM在复杂编程任务上的表现，发现其性能虽不及专有模型，但进步显著且评估流程可复现。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估开源本地大型语言模型在处理复杂编程任务时的性能，并与专有模型进行比较，以揭示当前技术差距和开源模型的进展。

Method: 作者通过改进原有的FACE框架，使其完全离线运行，整合问题目录为JSON文件，并增加检查点功能，以评估8个参数规模在6.7-90亿的本地模型在3,589个Kattis问题上的表现。

Result: 结果显示，本地模型的总体通过率较低，最佳模型的接受率约为专有模型的一半，但开源模型的快速进步和可复现的评估流程具有实际应用价值。

Conclusion: 研究表明，尽管开源本地大型语言模型在复杂编程任务上的表现仍不及专有模型如Gemini 1.5和ChatGPT-4，但其快速进步和可复现的评估流程为组织提供了实际价值。

Abstract: This study examines the performance of today's open-source, locally hosted
large-language models (LLMs) in handling complex competitive programming tasks
with extended problem descriptions and contexts. Building on the original
Framework for AI-driven Code Generation Evaluation (FACE), the authors retrofit
the pipeline to work entirely offline through the Ollama runtime, collapsing
FACE's sprawling per-problem directory tree into a handful of consolidated JSON
files, and adding robust checkpointing so multi-day runs can resume after
failures. The enhanced framework generates, submits, and records solutions for
the full Kattis corpus of 3,589 problems across eight code-oriented models
ranging from 6.7-9 billion parameters. The submission results show that the
overall pass@1 accuracy is modest for the local models, with the best models
performing at approximately half the acceptance rate of the proprietary models,
Gemini 1.5 and ChatGPT-4. These findings expose a persistent gap between
private, cost-controlled LLM deployments and state-of-the-art proprietary
services, yet also highlight the rapid progress of open models and the
practical benefits of an evaluation workflow that organizations can replicate
on in-house hardware.

</details>


### [165] [LoCaL: Countering Surface Bias in Code Evaluation Metrics](https://arxiv.org/abs/2509.15397)
*Simantika Bhattacharjee Dristi,Matthew B. Dwyer*

Main category: cs.SE

TL;DR: 研究发现参考代码评估指标（CEMs）过于依赖表面特征而非功能。提出的LoCaL基准通过差分模糊测试揭示其缺陷，促进开发更稳健的CEMs。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）及其代理的普及，可靠的代码评估指标（CEMs）对软件工程任务至关重要。现有参考CEMs与功能正确性之间的弱相关性原因未明，解决方案未探索。

Method: 本研究通过批判性评估四种最先进的参考CEMs，提出LoCaL基准，包含3117个代码对，通过差分模糊测试计算功能相似性分数。

Result: 所有四种CEMs在LoCaL基准上表现显著下降，显示其对表面特征的偏好。差分模糊测试提供了更可靠的功能相似性评分。

Conclusion: 研究表明，现有的参考代码评估指标（CEMs）存在对表面特征的强烈偏好，而非代码功能。通过LoCaL基准测试，发现这些CEMs在功能相似性评估上表现显著下降。暴露CEMs于LoCaL类数据可能有助于开发更稳健的指标。

Abstract: With the increasing popularity of large language models (LLMs) and LLM-based
agents, reliable and effective code evaluation metrics (CEMs) have become
crucial for progress across several software engineering tasks. While popular
benchmarks often provide test cases to assess the correctness of generated
code, crafting and executing test cases is expensive. Reference-based CEMs
provide a cheaper alternative by scoring a candidate program based on its
functional similarity to a reference. Although prior research has focused on
reporting the weak correlation between these CEMs and functional correctness,
the causes are only assumed, and plausible solutions remain unexplored. In this
work, we critically evaluate four state-of-the-art reference-based CEMs,
revealing their strong bias towards surface-level features rather than code
functionality. Despite this surface bias, current evaluation datasets for these
CEMs rarely include code pairs that are surface-similar yet functionally
dissimilar, or functionally similar yet surface-dissimilar. To mitigate this
gap, we propose LoCaL (Looks Can Lie), a CEM evaluation benchmark, with 3117
code pairs at both the method and program levels. Each pair is labeled with a
functional similarity score and aims to target regions where CEMs are likely to
perform poorly. The functional similarity scores are calculated through
differential fuzzing, which eliminates the need for predefined test cases and,
at the same time, improves the reliability of the scores by executing an order
of magnitude more tests than prior work. We find that all four CEMs show
significant performance degradation on LoCaL, compared to the baselines.
Finally, based on our findings, we draw the implication that exposing CEMs to
LoCaL-like data might facilitate the development of metrics that are robust to
surface bias.

</details>


### [166] [Brevity is the Soul of Wit: Condensing Code Changes to Improve Commit Message Generation](https://arxiv.org/abs/2509.15567)
*Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang*

Main category: cs.SE

TL;DR: 研究提出了一种基于文本模板的方法，结合ChangeScribe和CodeLlama-7B，显著提升了自动生成提交消息的质量。


<details>
  <summary>Details</summary>
Motivation: 开发者常忽视编写高质量的提交消息，这影响了代码变更的理解和维护。本研究旨在通过自动化方法提升提交消息的质量。

Method: 研究采用了一种新颖的文本模板方法，结合ChangeScribe工具和CodeLlama-7B模型，来生成高质量的提交消息。

Result: 在广泛使用的数据集上，该方法在BLEU-Norm、METEOR和ROUGE-L指标上平均提升了51.7%、78.7%和62.5%。

Conclusion: 该研究通过提出的文本模板方法，显著提升了自动生成提交消息的质量，优于现有基线方法。

Abstract: Commit messages are valuable resources for describing why code changes are
committed to repositories in version control systems (e.g., Git). They
effectively help developers understand code changes and better perform software
maintenance tasks. Unfortunately, developers often neglect to write
high-quality commit messages in practice. Therefore, a growing body of work is
proposed to generate commit messages automatically. These works all
demonstrated that how to organize and represent code changes is vital in
generating good commit messages, including the use of fine-grained graphs or
embeddings to better represent code changes. In this study, we choose an
alternative way to condense code changes before generation, i.e., proposing
brief yet concise text templates consisting of the following three parts: (1)
summarized code changes, (2) elicited comments, and (3) emphasized code
identifiers. Specifically, we first condense code changes by using our proposed
templates with the help of a heuristic-based tool named ChangeScribe, and then
fine-tune CodeLlama-7B on the pairs of our proposed templates and corresponding
commit messages. Our proposed templates better utilize pre-trained language
models, while being naturally brief and readable to complement generated commit
messages for developers. Our evaluation based on a widely used dataset showed
that our approach can outperform six baselines in terms of BLEU-Norm, METEOR,
and ROUGE-L, with average improvements of 51.7%, 78.7%, and 62.5%,
respectively. The ablation study and human evaluation also provide further
insights into the effectiveness of our approach.

</details>


### [167] [How Far Are We? An Empirical Analysis of Current Vulnerability Localization Approaches](https://arxiv.org/abs/2509.15777)
*Haoran Xu,Zhi Chen,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng*

Main category: cs.SE

TL;DR: 本文提出了一种结合版本驱动过滤和大型语言模型投票的两阶段框架，显著提升了漏洞补丁检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 开源软件漏洞补丁检测对维护软件安全至关重要，但传统手动检测方法难以扩展，现有自动化方法在准确性和泛化能力上存在局限。本文旨在解决这些挑战。

Method: 本文提出了一种新颖的两阶段框架，结合版本驱动的候选过滤与基于大型语言模型的多轮对话投票，以实现高效准确的漏洞补丁识别。

Result: 在包含750个真实漏洞的数据集上进行的大量实验表明，本文方法优于现有方法。

Conclusion: 通过结合版本驱动的候选过滤和基于大型语言模型的多轮对话投票，本文提出的方法显著提升了漏洞补丁检测的准确性和效率，为开源软件安全维护提供了有效解决方案。

Abstract: Open-source software vulnerability patch detection is a critical component
for maintaining software security and ensuring software supply chain integrity.
Traditional manual detection methods face significant scalability challenges
when processing large volumes of commit histories, while being prone to human
errors and omissions. Existing automated approaches, including heuristic-based
methods and pre-trained model solutions, suffer from limited accuracy, poor
generalization capabilities, and inherent methodological constraints that
hinder their practical deployment. To address these fundamental challenges,
this paper conducts a comprehensive empirical study of existing vulnerability
patch detection methods, revealing four key insights that guide the design of
effective solutions: the critical impact of search space reduction, the
superiority of pre-trained semantic understanding over architectural
complexity, the temporal limitations of web crawling approaches, and the
advantages of knowledge-driven methods. Based on these insights, we propose a
novel two-stage framework that combines version-driven candidate filtering with
large language model-based multi-round dialogue voting to achieve accurate and
efficient vulnerability patch identification. Extensive experiments on a
dataset containing 750 real vulnerabilities demonstrate that our method
outperforms current approaches.

</details>


### [168] [Failure Modes and Effects Analysis: An Experience from the E-Bike Domain](https://arxiv.org/abs/2509.15893)
*Andrea Bombarda,Federico Conti,Marcello Minervini,Aurora Zanenga,Claudio Menghi*

Main category: cs.SE

TL;DR: 本文通过e-Bike CPS案例验证了FMEA模拟驱动方法的有效性，发现38.4%的故障案例中工程师能发现意外效应，并分享了10条经验。


<details>
  <summary>Details</summary>
Motivation: 工业界需要模拟驱动方法有效性的证据以增加实际应用。本文通过e-Bike领域的CPS安全性分析，验证了FMEA方法的有效性。

Method: 使用Simulink Fault Analyzer工具进行FMEA分析，识别并建模了13个实际故障，并分析了其影响。

Result: 对于识别的故障，模型准确或包含微小不精确性（后续修正）。模拟驱动支持在38.4%的故障中帮助工程师发现意外效应。

Conclusion: 研究结果表明，FMEA有助于工程师改进模型，且模拟驱动的方法在38.4%的故障案例中帮助工程师发现了意外的故障效应。

Abstract: Software failures can have catastrophic and costly consequences. Functional
Failure Mode and Effects Analysis (FMEA) is a standard technique used within
Cyber-Physical Systems (CPS) to identify software failures and assess their
consequences. Simulation-driven approaches have recently been shown to be
effective in supporting FMEA. However, industries need evidence of the
effectiveness of these approaches to increase practical adoption. This
industrial paper presents our experience with using FMEA to analyze the safety
of a CPS from the e-Bike domain. We used Simulink Fault Analyzer, an industrial
tool that supports engineers with FMEA. We identified 13 realistic faults,
modeled them, and analyzed their effects. We sought expert feedback to analyze
the appropriateness of our models and the effectiveness of the faults in
detecting safety breaches. Our results reveal that for the faults we
identified, our models were accurate or contained minor imprecision that we
subsequently corrected. They also confirm that FMEA helps engineers improve
their models. Specifically, the output provided by the simulation-driven
support for 38.4% (5 out of 13) of the faults did not match the engineers'
expectations, helping them discover unexpected effects of the faults. We
present a thorough discussion of our results and ten lessons learned. Our
findings are useful for software engineers who work as Simulink engineers, use
the Simulink Fault Analyzer, or work as safety analysts.

</details>


### [169] [LeakageDetector 2.0: Analyzing Data Leakage in Jupyter-Driven Machine Learning Pipelines](https://arxiv.org/abs/2509.15971)
*Owen Truong,Terrence Zhang,Arnav Marchareddy,Ryan Lee,Jeffery Busold,Michael Socas,Eman Abdullah AlOmar*

Main category: cs.SE

TL;DR: 该论文开发了一个VS Code扩展LeakageDetector，用于检测和纠正ML模型中的数据泄漏问题，提升代码质量。


<details>
  <summary>Details</summary>
Motivation: 数据泄漏在ML模型中会导致性能评估误导，影响代码质量。ML开发者需要有效工具来检测和避免此类问题。

Method: 研究开发了一个VS Code扩展LeakageDetector，用于检测Jupyter Notebook文件中的数据泄漏问题（如重叠、预处理和多测试泄漏），并提供了两种纠正机制：手动快速修复和基于LLM的指导。

Result: LeakageDetector扩展能有效识别数据泄漏，并通过两种方式（手动和LLM驱动）提供纠正建议，帮助开发者优化ML管道。

Conclusion: 该研究成功开发了一个名为LeakageDetector的VS Code扩展，能有效检测和纠正数据泄漏问题，为ML工程师提供了实用的工具，有助于提高代码质量和模型性能。

Abstract: In software development environments, code quality is crucial. This study
aims to assist Machine Learning (ML) engineers in enhancing their code by
identifying and correcting Data Leakage issues within their models. Data
Leakage occurs when information from the test dataset is inadvertently included
in the training data when preparing a data science model, resulting in
misleading performance evaluations. ML developers must carefully separate their
data into training, evaluation, and test sets to avoid introducing Data Leakage
into their code. In this paper, we develop a new Visual Studio Code (VS Code)
extension, called LeakageDetector, that detects Data Leakage, mainly Overlap,
Preprocessing and Multi-test leakage, from Jupyter Notebook files. Beyond
detection, we included two correction mechanisms: a conventional approach,
known as a quick fix, which manually fixes the leakage, and an LLM-driven
approach that guides ML developers toward best practices for building ML
pipelines.

</details>


### [170] [Software Development Aspects of Integrating Linear Algebra Libraries](https://arxiv.org/abs/2509.16081)
*Marcel Koch,Tobias Ribizel,Pratik Nayak,Fritz Göbel,Gregor Olenik,Terry Cojean*

Main category: cs.SE

TL;DR: Ginkgo库帮助应用简化向现代系统的过渡并加速模拟，本文讨论了其在不同领域中的挑战、益处及对可持续软件开发的影响。


<details>
  <summary>Details</summary>
Motivation: 许多科学发现依赖于模拟软件，而这些软件通常依赖于特定领域的小型组件，Ginkgo作为处理稀疏数值线性代数的库，能帮助应用过渡到现代系统并加速模拟。

Method: 讨论了不同领域（如CFD、电网模拟和电心脏生理学）中采用Ginkgo的挑战和益处，并从软件工程角度分析了集成对应用代码的影响。

Result: 展示了Ginkgo在不同领域中的应用案例，及其对可持续软件开发的影响。

Conclusion: 采用Ginkgo库的应用能够简化向现代系统的过渡，并通过更快的数值线性代数例程加速模拟。

Abstract: Many scientific discoveries are made through, or aided by, the use of
simulation software. These sophisticated software applications are not built
from the ground up, instead they rely on smaller parts for specific use cases,
usually from domains unfamiliar to the application scientists. The software
library Ginkgo is one of these building blocks to handle sparse numerical
linear algebra on different platforms. By using Ginkgo, applications are able
to ease the transition to modern systems, and speed up their simulations
through faster numerical linear algebra routines. This paper discusses the
challenges and benefits for application software in adopting Ginkgo. It will
present examples from different domains, such as CFD, power grid simulation, as
well as electro-cardiophysiology. For these cases, the impact of the
integrations on the application code is discussed from a software engineering
standpoint, and in particular, the approaches taken by Ginkgo and the
applications to enable sustainable software development are highlighted.

</details>


### [171] [When Bugs Linger: A Study of Anomalous Resolution Time Outliers and Their Themes](https://arxiv.org/abs/2509.16140)
*Avinash Patil*

Main category: cs.SE

TL;DR: 该研究通过统计方法和文本分析技术，识别了开源项目中bug解决的异常模式，并提出了优化建议。


<details>
  <summary>Details</summary>
Motivation: 高效的bug解决对软件质量和用户满意度至关重要，但某些bug报告解决时间异常长，可能反映了流程效率低下或复杂问题。

Method: 使用Z-score和IQR统计方法识别bug解决时间异常，并应用TF-IDF和KMeans聚类分析bug摘要的主题。

Result: 发现异常bug常围绕测试失败、功能增强请求和用户界面问题，跨项目呈现一致模式。

Conclusion: 该方法为项目维护者提供了优先处理长期未解决bug的行动建议。

Abstract: Efficient bug resolution is critical for maintaining software quality and
user satisfaction. However, specific bug reports experience unusually long
resolution times, which may indicate underlying process inefficiencies or
complex issues. This study presents a comprehensive analysis of bug resolution
anomalies across seven prominent open-source repositories: Cassandra, Firefox,
Hadoop, HBase, SeaMonkey, Spark, and Thunderbird. Utilizing statistical methods
such as Z-score and Interquartile Range (IQR), we identify anomalies in bug
resolution durations. To understand the thematic nature of these anomalies, we
apply Term Frequency-Inverse Document Frequency (TF-IDF) for textual feature
extraction and KMeans clustering to group similar bug summaries. Our findings
reveal consistent patterns across projects, with anomalies often clustering
around test failures, enhancement requests, and user interface issues. This
approach provides actionable insights for project maintainers to prioritize and
effectively address long-standing bugs.

</details>


### [172] [MatchFixAgent: Language-Agnostic Autonomous Repository-Level Code Translation Validation and Repair](https://arxiv.org/abs/2509.16187)
*Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening*

Main category: cs.SE

TL;DR: MatchFixAgent是一个基于大型语言模型的多代理框架，用于代码翻译的等价性验证和修复。它在多种编程语言对上表现出色，验证结果准确且修复能力强。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化验证和修复方法由于工程开销高，难以推广到多种编程语言，并且依赖现有且通常不足的测试套件，导致等价性声明错误和翻译修复无效。

Method: MatchFixAgent采用多代理架构，将等价性验证分解为多个子任务，以确保对翻译的语义分析全面且一致。然后，它将分析结果提供给测试代理以编写和执行测试。修复代理尝试修复翻译错误。最终，裁决代理根据语义分析和测试执行结果做出（不）等价性决定。

Result: MatchFixAgent为99.2%的翻译对生成（不）等价性裁决，与先前工作在72.8%的情况下结果一致。当结果不一致时，60.7%的情况下MatchFixAgent的结果实际上是正确的。此外，MatchFixAgent可以修复50.6%的不等价翻译，而先前工作仅修复18.5%。

Conclusion: MatchFixAgent在代码翻译的功能等价性验证和修复方面表现出色，能够适应多种编程语言对，并产生高度准确的验证结果。

Abstract: Code translation transforms source code from one programming language (PL) to
another. Validating the functional equivalence of translation and repairing, if
necessary, are critical steps in code translation. Existing automated
validation and repair approaches struggle to generalize to many PLs due to high
engineering overhead, and they rely on existing and often inadequate test
suites, which results in false claims of equivalence and ineffective
translation repair. We develop MatchFixAgent, a large language model
(LLM)-based, PL-agnostic framework for equivalence validation and repair of
translations. MatchFixAgent features a multi-agent architecture that divides
equivalence validation into several sub-tasks to ensure thorough and consistent
semantic analysis of the translation. Then it feeds this analysis to test agent
to write and execute tests. Upon observing a test failure, the repair agent
attempts to fix the translation bug. The final (in)equivalence decision is made
by the verdict agent, considering semantic analyses and test execution results.
  We compare MatchFixAgent's validation and repair results with four
repository-level code translation techniques. We use 2,219 translation pairs
from their artifacts, which cover 6 PL pairs, and are collected from 24 GitHub
projects totaling over 900K lines of code. Our results demonstrate that
MatchFixAgent produces (in)equivalence verdicts for 99.2% of translation pairs,
with the same equivalence validation result as prior work on 72.8% of them.
When MatchFixAgent's result disagrees with prior work, we find that 60.7% of
the time MatchFixAgent's result is actually correct. In addition, we show that
MatchFixAgent can repair 50.6% of inequivalent translation, compared to prior
work's 18.5%. This demonstrates that MatchFixAgent is far more adaptable to
many PL pairs than prior work, while producing highly accurate validation
results.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [173] [WiFiSim: Simulating WiFi Probe Requests via AOSP Analysis and Device Behavior Modeling](https://arxiv.org/abs/2509.15501)
*Lifei Hao,Yue Cheng,Min Wang,Bing Jia,Baoqi Huang*

Main category: cs.NI

TL;DR: WiFiSim是一个模拟WiFi探针请求生成的框架，解决了MAC随机化和数据稀缺问题，偏差小于5%，支持大规模数据合成和应用评估。


<details>
  <summary>Details</summary>
Motivation: WiFi探针请求（PR）帧编码了细粒度的设备交互，是移动性和人群分析的关键基础，但普遍的MAC地址随机化和标记数据集的稀缺性阻碍了PR研究的进展。

Method: 通过分析Android开源项目（AOSP）协议和有限状态设备行为建模，重建PR生成过程，识别PR结构和时间的关键决定因素，并捕捉用户驱动的状态转换。

Result: 实验表明，WiFiSim在分布和时间动态上均实现了与真实测量偏差小于5%的效果，能够扩展到大规模数据集合成，并支持下游应用的可靠评估。

Conclusion: WiFiSim通过模拟框架有效解决了WiFi探针请求研究中MAC地址随机化和标记数据集稀缺的问题，其生成的PR数据与真实测量偏差小于5%，支持大规模数据集合成，并促进可重复研究。

Abstract: WiFi probe request (PR) frames encode fine-grained device interactions and
serve as a critical basis for mobility and crowd analytics. However, pervasive
MAC address randomization and the scarcity of labeled datasets hinder progress
in PR-based studies. We introduce WiFiSim, a simulation framework that
reconstructs PR generation through Android Open Source Project (AOSP) protocol
analysis and finite-state device behavior modeling. WiFiSim identifies the key
determinants of PR structure and timing while capturing realistic user-driven
state transitions. Experiments show that WiFiSim achieves less than 5%
deviation from real measurements in both distributional and temporal dynamics,
scales to large-scale dataset synthesis, and enables reliable evaluation of
downstream applications. Source code and sample datasets are publicly released
to foster reproducible research.

</details>


### [174] [Smart Interrupted Routing Based on Multi-head Attention Mask Mechanism-Driven MARL in Software-defined UASNs](https://arxiv.org/abs/2509.15856)
*Zhenyu Wang,Chuan Lin,Guangjie Han,Shengchao Zhu,Ruoyuan Wu,Tongwei Zhang*

Main category: cs.NI

TL;DR: 提出了一种基于SDN和强化学习的智能中断路由方案（ISURL），结合MA-MAPPO算法，显著提升了UASNs的路由效率和中断恢复能力。


<details>
  <summary>Details</summary>
Motivation: 水下声学传感器网络（UASNs）在恶劣环境下（如高延迟、有限带宽和动态拓扑）的高效路由决策具有挑战性。

Method: 提出了基于软件定义网络（SDN）的ISURL框架，结合MA-MAPPO算法和MA-MAPPO_i中断策略，实现自适应路由和中断恢复。

Result: 评估表明，提出的路由方案在收敛速度和路由延迟方面优于现有方法。

Conclusion: 提出的路由方案在收敛速度和路由延迟方面优于现有方法，实现了精确的水下数据路由决策。

Abstract: Routing-driven timely data collection in Underwater Acoustic Sensor Networks
(UASNs) is crucial for marine environmental monitoring, disaster warning and
underwater resource exploration, etc. However, harsh underwater conditions,
including high delays, limited bandwidth, and dynamic topologies - make
efficient routing decisions challenging in UASNs. In this paper, we propose a
smart interrupted routing scheme for UASNs to address dynamic underwater
challenges. We first model underwater noise influences from real underwater
routing features, e.g., turbulence and storms. We then propose a
Software-Defined Networking (SDN)-based Interrupted Software-defined UASNs
Reinforcement Learning (ISURL) framework which ensures adaptive routing through
dynamically failure handling (e.g., energy depletion of sensor nodes or link
instability) and real-time interrupted recovery. Based on ISURL, we propose
MA-MAPPO algorithm, integrating multi-head attention mask mechanism with MAPPO
to filter out infeasible actions and streamline training. Furthermore, to
support interrupted data routing in UASNs, we introduce MA-MAPPO_i, MA-MAPPO
with interrupted policy, to enable smart interrupted routing decision in UASNs.
The evaluations demonstrate that our proposed routing scheme achieves exact
underwater data routing decision with faster convergence speed and lower
routing delays than existing approaches.

</details>


### [175] [A Robust Scheduling of Cyclic Traffic for Integrated Wired and Wireless Time-Sensitive Networks](https://arxiv.org/abs/2509.15930)
*Özgür Ozan Kaynak,Andreas Kassler,Andreas Fischer,Ognjen Dobrijevic,Fabio D'Andreagiovanni*

Main category: cs.NI

TL;DR: 本文提出了一种针对无线TSN网络的鲁棒调度方法，通过线性规划和启发式算法，成功解决了无线链路不确定性带来的配置挑战。


<details>
  <summary>Details</summary>
Motivation: 由于无线链路的随机性，配置时间感知流量整形（TAS）在网络范围内极具挑战性，尤其是在集成无线网络（如5G、Wi-Fi）中。本文旨在解决这一问题。

Method: 本文提出了一种基于线性规划的鲁棒调度方法，结合了可调鲁棒性参数（Γ）和多项式时间运行的顺序批量调度启发式算法，以降低计算复杂度。

Result: 通过不同网络拓扑和无线链路特性的评估，该方法在大型拓扑中成功调度了90%的6500个请求TSN流。

Conclusion: 本文提出了一种针对集成无线网络（如5G、Wi-Fi）的TSN时间感知调度配置新方法，通过线性规划和启发式算法，有效解决了无线链路不确定性带来的挑战，并在大规模拓扑中实现了高效的流量调度。

Abstract: Time-Sensitive Networking (TSN) is a toolbox of technologies that enable
deterministic communication over Ethernet. A key area has been TSN's time-aware
traffic shaping (TAS), which supports stringent end-to-end latency and
reliability requirements. Configuration of TAS requires the computation of a
network-wide traffic schedule, which is particularly challenging with
integrated wireless networks (e.g., 5G, Wi-Fi) due to the stochastic nature of
wireless links. This paper introduces a novel method for configuring TAS,
focusing on cyclic traffic patterns and jitter of wireless links. We formulate
a linear program that computes a network-wide time-aware schedule, robust to
wireless performance uncertainties. The given method enables robust scheduling
of multiple TSN frames per transmission window using a tunable robustness
parameter ({\Gamma}). To reduce computational complexity, we also propose a
sequential batch-scheduling heuristic that runs in polynomial time. Our
approach is evaluated by using different network topologies and wireless link
characteristics, demonstrating that the heuristic can schedule 90% of 6500
requested TSN streams in a large topology.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [176] [MICA: Multi-Agent Industrial Coordination Assistant](https://arxiv.org/abs/2509.15237)
*Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen*

Main category: cs.AI

TL;DR: MICA 是一个多代理工业协调助手，通过自适应步骤融合和角色专用代理提供实时指导，适用于工业环境，具有高任务成功率和隐私保护特性。


<details>
  <summary>Details</summary>
Motivation: 工业工作流程需要适应性强且值得信赖的助手，这些助手能够在有限的计算、连接和严格的隐私约束下运行。

Method: MICA 协调五个角色专用的语言代理，并通过安全检查器审核，以确保准确和合规的支持。引入了自适应步骤融合（ASF）来动态混合专家推理与自然语音反馈的在线适应。

Result: 实验表明，MICA 在任务成功率、可靠性和响应性方面始终优于基线结构，同时可在实用的离线硬件上部署。

Conclusion: MICA 是一个可部署的、保护隐私的多代理助手，适用于动态工厂环境，其源代码将公开。

Abstract: Industrial workflows demand adaptive and trustworthy assistance that can
operate under limited computing, connectivity, and strict privacy constraints.
In this work, we present MICA (Multi-Agent Industrial Coordination Assistant),
a perception-grounded and speech-interactive system that delivers real-time
guidance for assembly, troubleshooting, part queries, and maintenance. MICA
coordinates five role-specialized language agents, audited by a safety checker,
to ensure accurate and compliant support. To achieve robust step understanding,
we introduce Adaptive Step Fusion (ASF), which dynamically blends expert
reasoning with online adaptation from natural speech feedback. Furthermore, we
establish a new multi-agent coordination benchmark across representative task
categories and propose evaluation metrics tailored to industrial assistance,
enabling systematic comparison of different coordination topologies. Our
experiments demonstrate that MICA consistently improves task success,
reliability, and responsiveness over baseline structures, while remaining
deployable on practical offline hardware. Together, these contributions
highlight MICA as a step toward deployable, privacy-preserving multi-agent
assistants for dynamic factory environments. The source code will be made
publicly available at https://github.com/Kratos-Wen/MICA.

</details>


### [177] [KNARsack: Teaching Neural Algorithmic Reasoners to Solve Pseudo-Polynomial Problems](https://arxiv.org/abs/2509.15239)
*Stjepan Požgaj,Dobrik Georgiev,Marin Šilić,Petar Veličković*

Main category: cs.AI

TL;DR: 研究构建了一个神经算法推理器来解决背包问题，通过模仿经典算法的两阶段流程（动态规划表构建和解决方案重建），实现了更好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 神经算法推理（NAR）领域旨在将算法逻辑嵌入神经网络，但标准NAR基准中未包含背包问题，这是一个连接经典算法和组合优化的伪多项式问题。

Method: 研究采用了两阶段流程，首先生成动态规划表，然后从中重建解决方案。模型通过动态规划监督来建模中间状态。

Result: 该方法在泛化到较大问题实例时表现优于直接从问题输入中选择最优子集的基线模型。

Conclusion: 该研究成功构建了一个能够解决背包问题的神经算法推理器，通过模仿经典算法的两阶段流程，实现了对较大问题实例的更好泛化能力。

Abstract: Neural algorithmic reasoning (NAR) is a growing field that aims to embed
algorithmic logic into neural networks by imitating classical algorithms. In
this extended abstract, we detail our attempt to build a neural algorithmic
reasoner that can solve Knapsack, a pseudo-polynomial problem bridging
classical algorithms and combinatorial optimisation, but omitted in standard
NAR benchmarks. Our neural algorithmic reasoner is designed to closely follow
the two-phase pipeline for the Knapsack problem, which involves first
constructing the dynamic programming table and then reconstructing the solution
from it. The approach, which models intermediate states through dynamic
programming supervision, achieves better generalization to larger problem
instances than a direct-prediction baseline that attempts to select the optimal
subset only from the problem inputs.

</details>


### [178] [The Distribution Shift Problem in Transportation Networks using Reinforcement Learning and AI](https://arxiv.org/abs/2509.15291)
*Federico Taschin,Abderrahmane Lazaraq,Ozan K. Tonguz,Inci Ozgunes*

Main category: cs.AI

TL;DR: 论文分析了MetaLight在交通信号控制中的应用，发现其在某些条件下表现良好，但在其他条件下可能表现不佳，误差高达22%，表明Meta RL方案不够稳健。


<details>
  <summary>Details</summary>
Motivation: 智能交通网络中机器学习和人工智能的应用显著增加，但强化学习在交通信号控制中的可靠性问题，特别是输入数据动态变化带来的挑战，促使研究者探索解决方案。

Method: 本文评估并分析了一种称为MetaLight的最先进的Meta RL方法。

Result: 研究发现，MetaLight在某些条件下表现良好，但在其他条件下可能表现不佳，误差高达22%。

Conclusion: 论文指出，尽管MetaLight在某些条件下表现良好，但在其他条件下可能表现不佳（误差高达22%），这表明Meta RL方案通常不够稳健，甚至可能带来重大可靠性问题。

Abstract: The use of Machine Learning (ML) and Artificial Intelligence (AI) in smart
transportation networks has increased significantly in the last few years.
Among these ML and AI approaches, Reinforcement Learning (RL) has been shown to
be a very promising approach by several authors. However, a problem with using
Reinforcement Learning in Traffic Signal Control is the reliability of the
trained RL agents due to the dynamically changing distribution of the input
data with respect to the distribution of the data used for training. This
presents a major challenge and a reliability problem for the trained network of
AI agents and could have very undesirable and even detrimental consequences if
a suitable solution is not found. Several researchers have tried to address
this problem using different approaches. In particular, Meta Reinforcement
Learning (Meta RL) promises to be an effective solution. In this paper, we
evaluate and analyze a state-of-the-art Meta RL approach called MetaLight and
show that, while under certain conditions MetaLight can indeed lead to
reasonably good results, under some other conditions it might not perform well
(with errors of up to 22%), suggesting that Meta RL schemes are often not
robust enough and can even pose major reliability problems.

</details>


### [179] [An Artificial Intelligence Driven Semantic Similarity-Based Pipeline for Rapid Literature](https://arxiv.org/abs/2509.15292)
*Abhiyan Dhakal,Kausik Paudel,Sanjog Sigdel*

Main category: cs.AI

TL;DR: 提出了一种基于语义相似性的自动化文献综述流程，使用变压器嵌入和余弦相似度，有效筛选相关论文，适合初步研究。


<details>
  <summary>Details</summary>
Motivation: 旨在通过最小化开销和最大化相关性，改进传统的系统性综述系统或基于优化的方法，利用语义相似性进行文献综述。

Method: 提出了一个使用基于变压器的嵌入和余弦相似度的自动化流程，通过提供论文标题和摘要生成相关关键词，从开放获取存储库中获取相关论文，并根据其与输入的语义接近度进行排名。评估了三种嵌入模型，并应用统计阈值方法来过滤相关论文。

Result: 该系统能够在没有启发式反馈或真实相关性标签的情况下，有效地进行文献综述，显示出作为初步研究和探索性分析工具的潜力。

Conclusion: 尽管缺乏启发式反馈或真实相关性标签，所提出的系统作为一个可扩展且实用的工具，在初步研究和探索性分析中显示出潜力。

Abstract: We propose an automated pipeline for performing literature reviews using
semantic similarity. Unlike traditional systematic review systems or
optimization based methods, this work emphasizes minimal overhead and high
relevance by using transformer based embeddings and cosine similarity. By
providing a paper title and abstract, it generates relevant keywords, fetches
relevant papers from open access repository, and ranks them based on their
semantic closeness to the input. Three embedding models were evaluated. A
statistical thresholding approach is then applied to filter relevant papers,
enabling an effective literature review pipeline. Despite the absence of
heuristic feedback or ground truth relevance labels, the proposed system shows
promise as a scalable and practical tool for preliminary research and
exploratory analysis.

</details>


### [180] [Knowledge-Driven Hallucination in Large Language Models: An Empirical Study on Process Modeling](https://arxiv.org/abs/2509.15336)
*Humam Kourani,Anton Antonov,Alessandro Berti,Wil M. P. van der Aalst*

Main category: cs.AI

TL;DR: 本文研究了LLMs在自动化流程建模中的知识驱动幻觉现象，提出了评估方法并强调了严格验证AI生成工件的必要性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在自动化流程建模任务中可能出现的知识驱动幻觉现象，即模型输出与明确来源证据相矛盾的情况。

Method: 通过设计控制实验，创建提供证据与LLM背景知识之间故意冲突的场景，评估LLM对提供证据的忠实度。

Result: 实验结果表明，LLMs在面对标准和非标准流程结构时，其输出可能受到预训练知识的过度影响，导致与提供证据不符。

Conclusion: 本文强调了在基于证据的领域中对AI生成工件进行严格验证的必要性，并提出了评估大型语言模型（LLMs）知识驱动幻觉的方法论。

Abstract: The utility of Large Language Models (LLMs) in analytical tasks is rooted in
their vast pre-trained knowledge, which allows them to interpret ambiguous
inputs and infer missing information. However, this same capability introduces
a critical risk of what we term knowledge-driven hallucination: a phenomenon
where the model's output contradicts explicit source evidence because it is
overridden by the model's generalized internal knowledge. This paper
investigates this phenomenon by evaluating LLMs on the task of automated
process modeling, where the goal is to generate a formal business process model
from a given source artifact. The domain of Business Process Management (BPM)
provides an ideal context for this study, as many core business processes
follow standardized patterns, making it likely that LLMs possess strong
pre-trained schemas for them. We conduct a controlled experiment designed to
create scenarios with deliberate conflict between provided evidence and the
LLM's background knowledge. We use inputs describing both standard and
deliberately atypical process structures to measure the LLM's fidelity to the
provided evidence. Our work provides a methodology for assessing this critical
reliability issue and raises awareness of the need for rigorous validation of
AI-generated artifacts in any evidence-based domain.

</details>


### [181] [Diagnostics of cognitive failures in multi-agent expert systems using dynamic evaluation protocols and subsequent mutation of the processing context](https://arxiv.org/abs/2509.15366)
*Andrejs Sorstkins,Josh Bailey,Dr Alistair Baron*

Main category: cs.AI

TL;DR: 该论文提出了一个诊断框架，用于评估和优化LLM代理的专家行为表现，并在招聘助手系统中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于神经架构的快速进化，大型语言模型（LLMs）展现出代理行为，但传统的评估方法无法有效诊断其代理性能。

Method: 引入了一个诊断框架，整合了专家注释的黄金数据集、通过行为变异生成的银数据集，以及一个基于LLM的代理评分系统。

Result: 在多代理招聘助手系统中验证了该框架，揭示了潜在认知失败并引导代理达到专家级推理和风格。

Conclusion: 该论文建立了一个标准化、可复现的专家行为转移基础，超越了静态评估，实现了主动的专家系统优化。

Abstract: The rapid evolution of neural architectures - from multilayer perceptrons to
large-scale Transformer-based models - has enabled language models (LLMs) to
exhibit emergent agentic behaviours when equipped with memory, planning, and
external tool use. However, their inherent stochasticity and multi-step
decision processes render classical evaluation methods inadequate for
diagnosing agentic performance. This work introduces a diagnostic framework for
expert systems that not only evaluates but also facilitates the transfer of
expert behaviour into LLM-powered agents. The framework integrates (i) curated
golden datasets of expert annotations, (ii) silver datasets generated through
controlled behavioural mutation, and (iii) an LLM-based Agent Judge that scores
and prescribes targeted improvements. These prescriptions are embedded into a
vectorized recommendation map, allowing expert interventions to propagate as
reusable improvement trajectories across multiple system instances. We
demonstrate the framework on a multi-agent recruiter-assistant system, showing
that it uncovers latent cognitive failures - such as biased phrasing,
extraction drift, and tool misrouting - while simultaneously steering agents
toward expert-level reasoning and style. The results establish a foundation for
standardized, reproducible expert behaviour transfer in stochastic,
tool-augmented LLM agents, moving beyond static evaluation to active expert
system refinement.

</details>


### [182] [FragmentRetro: A Quadratic Retrosynthetic Method Based on Fragmentation Algorithms](https://arxiv.org/abs/2509.15409)
*Yu Shee,Anthony M. Smaldone,Anton Morgunov,Gregory W. Kyro,Victor S. Batista*

Main category: cs.AI

TL;DR: FragmentRetro是一种新型的逆合成方法，通过碎片化算法和指纹筛选显著降低了计算复杂度，适用于高效的合成规划。


<details>
  <summary>Details</summary>
Motivation: 现有的树搜索方法在计算机辅助合成规划（CASP）中常面临指数级计算复杂度的挑战。

Method: FragmentRetro利用BRICS和r-BRICS等碎片化算法，结合库存感知探索和模式指纹筛选，实现了二次复杂度。该方法递归地组合分子碎片并验证其在构建块集中的存在。

Result: 在PaRoutes、USPTO-190和天然产物上的评估表明，FragmentRetro实现了高解决率，且运行时间具有竞争力。指纹筛选显著降低了子结构匹配的复杂度。

Conclusion: FragmentRetro通过其计算优势和生成战略起始候选分子的能力，成为可扩展和自动化合成规划的强大基础组件。

Abstract: Retrosynthesis, the process of deconstructing a target molecule into simpler
precursors, is crucial for computer-aided synthesis planning (CASP). Widely
adopted tree-search methods often suffer from exponential computational
complexity. In this work, we introduce FragmentRetro, a novel retrosynthetic
method that leverages fragmentation algorithms, specifically BRICS and r-BRICS,
combined with stock-aware exploration and pattern fingerprint screening to
achieve quadratic complexity. FragmentRetro recursively combines molecular
fragments and verifies their presence in a building block set, providing sets
of fragment combinations as retrosynthetic solutions. We present the first
formal computational analysis of retrosynthetic methods, showing that tree
search exhibits exponential complexity $O(b^h)$, DirectMultiStep scales as
$O(h^6)$, and FragmentRetro achieves $O(h^2)$, where $h$ represents the number
of heavy atoms in the target molecule and $b$ is the branching factor for tree
search. Evaluations on PaRoutes, USPTO-190, and natural products demonstrate
that FragmentRetro achieves high solved rates with competitive runtime,
including cases where tree search fails. The method benefits from fingerprint
screening, which significantly reduces substructure matching complexity. While
FragmentRetro focuses on efficiently identifying fragment-based solutions
rather than full reaction pathways, its computational advantages and ability to
generate strategic starting candidates establish it as a powerful foundational
component for scalable and automated synthesis planning.

</details>


### [183] [Stress Testing Deliberative Alignment for Anti-Scheming Training](https://arxiv.org/abs/2509.15541)
*Bronson Schoen,Evgenia Nitishinskaya,Mikita Balesni,Axel Højmark,Felix Hofstätter,Jérémy Scheurer,Alexander Meinke,Jason Wolfe,Teun van der Weij,Alex Lloyd,Nicholas Goldowsky-Dill,Angela Fan,Andrei Matveiakin,Rusheb Shah,Marcus Williams,Amelia Glaese,Boaz Barak,Wojciech Zaremba,Marius Hobbhahn*

Main category: cs.AI

TL;DR: 论文探讨了AI系统可能秘密追求不对齐目标（“阴谋”）的问题，提出了一种评估反阴谋干预的方法，发现深思熟虑的对齐方法显著减少但不完全消除隐蔽行为，情境意识是关键因素。


<details>
  <summary>Details</summary>
Motivation: 高度智能的AI系统可能秘密追求不对齐的目标（即“阴谋”），需要不同于传统ML的策略来检测和缓解。

Method: 提出了一种评估反阴谋干预的方法，包括（1）在分布外任务上测试阴谋倾向，（2）评估缺乏阴谋是否由情境意识驱动，（3）检查对预先存在的不对齐目标的鲁棒性。使用隐蔽行为作为阴谋的代理，并设计评估。

Result: 在26个分布外评估中，深思熟虑的对齐方法将隐蔽行为率从13%降至0.4%，但未完全消除。模型的情境意识会减少隐蔽行为，而无意识则会增加。

Conclusion: 尽管深思熟虑的对齐方法显著减少了隐蔽行为，但并未完全消除。未来研究需要进一步探索针对欺骗性对齐的对抗性案例的缓解措施。

Abstract: Highly capable AI systems could secretly pursue misaligned goals -- what we
call "scheming". Because a scheming AI would deliberately try to hide its
misaligned goals and actions, measuring and mitigating scheming requires
different strategies than are typically used in ML. We propose that assessing
anti-scheming interventions requires at least (1) testing propensity to scheme
on far out-of-distribution (OOD) tasks, (2) evaluating whether lack of scheming
is driven by situational awareness, and (3) checking for robustness to
pre-existing misaligned goals. We use a broad category of "covert actions" --
such as secretly breaking rules or intentionally underperforming in tests -- as
a proxy for scheming, and design evaluations for covert actions. We then
stress-test deliberative alignment as a case study for anti-scheming. Across 26
OOD evaluations (180+ environments), deliberative alignment reduces covert
action rates (OpenAI o3: 13%->0.4%) but does not fully eliminate them. Our
mitigation is also able to largely stop agents from pursuing a hidden goal
previously trained into the model, but we still find misbehavior after
additional red-teaming. We find that models' chain-of-thought (CoT) often
demonstrates awareness of being evaluated for alignment, and show causal
evidence that this awareness decreases covert behavior, while unawareness
increases it. Therefore, we cannot exclude that the observed reductions in
covert action rates are at least partially driven by situational awareness.
While we rely on human-legible CoT for training, studying situational
awareness, and demonstrating clear evidence of misalignment, our ability to
rely on this degrades as models continue to depart from reasoning in standard
English. We encourage research into alignment mitigations for scheming and
their assessment, especially for the adversarial case of deceptive alignment,
which this paper does not address.

</details>


### [184] [MicroRCA-Agent: Microservice Root Cause Analysis Method Based on Large Language Model Agents](https://arxiv.org/abs/2509.15635)
*Pan Tang,Shixiang Tang,Huanqi Pu,Zhiqing Miao,Zhixing Wang*

Main category: cs.AI

TL;DR: MicroRCA-Agent利用多模态数据融合和LLM代理实现微服务故障根因分析，技术包括日志压缩、双异常检测和两阶段LLM分析，最终得分50.71。


<details>
  <summary>Details</summary>
Motivation: 构建一个智能故障根因定位系统，以高效处理海量日志并实现全面的跟踪异常识别。

Method: 结合预训练的Drain日志解析算法与多级数据过滤机制，采用双异常检测方法（隔离森林无监督学习算法与状态码验证），并设计统计对称比率过滤机制与两阶段LLM分析策略。

Result: 系统架构的有效性通过全面消融研究验证，展示了多模态数据的互补价值。

Conclusion: MicroRCA-Agent通过多模态数据融合和大型语言模型代理，在复杂的微服务故障场景中表现出色，最终得分为50.71。

Abstract: This paper presents MicroRCA-Agent, an innovative solution for microservice
root cause analysis based on large language model agents, which constructs an
intelligent fault root cause localization system with multimodal data fusion.
The technical innovations are embodied in three key aspects: First, we combine
the pre-trained Drain log parsing algorithm with multi-level data filtering
mechanism to efficiently compress massive logs into high-quality fault
features. Second, we employ a dual anomaly detection approach that integrates
Isolation Forest unsupervised learning algorithms with status code validation
to achieve comprehensive trace anomaly identification. Third, we design a
statistical symmetry ratio filtering mechanism coupled with a two-stage LLM
analysis strategy to enable full-stack phenomenon summarization across
node-service-pod hierarchies. The multimodal root cause analysis module
leverages carefully designed cross-modal prompts to deeply integrate multimodal
anomaly information, fully exploiting the cross-modal understanding and logical
reasoning capabilities of large language models to generate structured analysis
results encompassing fault components, root cause descriptions, and reasoning
trace. Comprehensive ablation studies validate the complementary value of each
modal data and the effectiveness of the system architecture. The proposed
solution demonstrates superior performance in complex microservice fault
scenarios, achieving a final score of 50.71. The code has been released at:
https://github.com/tangpan360/MicroRCA-Agent.

</details>


### [185] [CCrepairBench: A High-Fidelity Benchmark and Reinforcement Learning Framework for C++ Compilation Repair](https://arxiv.org/abs/2509.15690)
*Weixuan Sun,Jucai Zhai,Dengfeng Liu,Xin Zhang,Xiaojun Wu,Qiaobo Hao,AIMgroup,Yang Fang,Jiuyang Tang*

Main category: cs.AI

TL;DR: 该论文提出了一种综合框架，包括新数据集、强化学习范式和评估系统，显著提升了C++编译错误的自动修复效果。


<details>
  <summary>Details</summary>
Motivation: 解决C++编译错误自动修复的挑战，提升开发者效率，填补大规模高保真数据集和传统监督方法在生成语义正确补丁方面的不足。

Method: 引入了一个综合框架，包括CCrepair数据集、基于强化学习（RL）的范式以及两阶段评估系统。

Result: 实验证明，RL训练的Qwen2.5-1.5B-Instruct模型性能接近Qwen2.5-14B-Instruct模型，验证了训练范式的效率。

Conclusion: 该论文为研究社区提供了一个有价值的新数据集和更有效的训练与评估范式，为更实用可靠的自动化编程助手铺平了道路。

Abstract: The automated repair of C++ compilation errors presents a significant
challenge, the resolution of which is critical for developer productivity.
Progress in this domain is constrained by two primary factors: the scarcity of
large-scale, high-fidelity datasets and the limitations of conventional
supervised methods, which often fail to generate semantically correct
patches.This paper addresses these gaps by introducing a comprehensive
framework with three core contributions. First, we present CCrepair, a novel,
large-scale C++ compilation error dataset constructed through a sophisticated
generate-and-verify pipeline. Second, we propose a Reinforcement Learning (RL)
paradigm guided by a hybrid reward signal, shifting the focus from mere
compilability to the semantic quality of the fix. Finally, we establish the
robust, two-stage evaluation system providing this signal, centered on an
LLM-as-a-Judge whose reliability has been rigorously validated against the
collective judgments of a panel of human experts. This integrated approach
aligns the training objective with generating high-quality, non-trivial patches
that are both syntactically and semantically correct. The effectiveness of our
approach was demonstrated experimentally. Our RL-trained Qwen2.5-1.5B-Instruct
model achieved performance comparable to a Qwen2.5-14B-Instruct model,
validating the efficiency of our training paradigm. Our work provides the
research community with a valuable new dataset and a more effective paradigm
for training and evaluating robust compilation repair models, paving the way
for more practical and reliable automated programming assistants.

</details>


### [186] [A Nascent Taxonomy of Machine Learning in Intelligent Robotic Process Automation](https://arxiv.org/abs/2509.15730)
*Lukas Laakmann,Seyyid A. Ciftci,Christian Janiesch*

Main category: cs.AI

TL;DR: 本文综述了RPA与机器学习的结合，提出了智能RPA的分类法，包含两个元特征和八个维度，为相关研究提供了系统化框架。


<details>
  <summary>Details</summary>
Motivation: RPA在自动化规则明确、结构良好的任务方面表现出色，但在处理复杂任务时存在局限性。机器学习为扩展RPA的能力提供了可能性，因此有必要探索两者的结合。

Method: 本文采用文献综述的方法，系统地分析了RPA与机器学习的结合，并提出了一个分类法。

Result: 研究提出了一个智能RPA的分类法，包括RPA-ML集成和RPA-ML交互两个元特征，以及八个具体维度，为未来研究提供了系统化的框架。

Conclusion: 本文通过文献综述探讨了RPA与机器学习的联系，并将智能RPA的概念组织成一个分类法，提出了两个元特征和八个维度，为智能RPA的未来研究提供了框架。

Abstract: Robotic process automation (RPA) is a lightweight approach to automating
business processes using software robots that emulate user actions at the
graphical user interface level. While RPA has gained popularity for its
cost-effective and timely automation of rule-based, well-structured tasks, its
symbolic nature has inherent limitations when approaching more complex tasks
currently performed by human agents. Machine learning concepts enabling
intelligent RPA provide an opportunity to broaden the range of automatable
tasks. In this paper, we conduct a literature review to explore the connections
between RPA and machine learning and organize the joint concept intelligent RPA
into a taxonomy. Our taxonomy comprises the two meta-characteristics RPA-ML
integration and RPA-ML interaction. Together, they comprise eight dimensions:
architecture and ecosystem, capabilities, data basis, intelligence level, and
technical depth of integration as well as deployment environment, lifecycle
phase, and user-robot relation.

</details>


### [187] [Ontology Creation and Management Tools: the Case of Anatomical Connectivity](https://arxiv.org/abs/2509.15780)
*Natallia Kokash,Bernard de Bono,Tom Gillespie*

Main category: cs.AI

TL;DR: ApiNATOMY框架通过KR模型和KM工具，支持多尺度生理回路图的建模与外部知识集成。


<details>
  <summary>Details</summary>
Motivation: 支持研究人员绘制与周围神经系统及其他生理系统相关的数据，强调其在研究器官中的重要性。

Method: 开发了ApiNATOMY框架，结合知识表示（KR）模型和知识管理（KM）工具，用于多尺度生理回路图的建模。

Result: ApiNATOMY框架成功实现了生理学专家对解剖实体间交互的捕获，并将高级抽象转化为详细的生理过程模型。

Conclusion: ApiNATOMY框架为多尺度生理回路图的拓扑和语义表示提供了有效的知识表示模型和管理工具，支持生理学专家与外部本体和知识图谱的集成。

Abstract: We are developing infrastructure to support researchers in mapping data
related to the peripheral nervous system and other physiological systems, with
an emphasis on their relevance to the organs under investigation. The nervous
system, a complex network of nerves and ganglia, plays a critical role in
coordinating and transmitting signals throughout the body. To aid in this, we
have created ApiNATOMY, a framework for the topological and semantic
representation of multiscale physiological circuit maps. ApiNATOMY integrates a
Knowledge Representation (KR) model and a suite of Knowledge Management (KM)
tools. The KR model enables physiology experts to easily capture interactions
between anatomical entities, while the KM tools help modelers convert
high-level abstractions into detailed models of physiological processes, which
can be integrated with external ontologies and knowledge graphs.

</details>


### [188] [Building Data-Driven Occupation Taxonomies: A Bottom-Up Multi-Stage Approach via Semantic Clustering and Multi-Agent Collaboration](https://arxiv.org/abs/2509.15786)
*Nan Li,Bo Kang,Tijl De Bie*

Main category: cs.AI

TL;DR: CLIMB是一个自动化框架，用于从原始招聘信息中构建高质量职业分类法，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有职业分类法构建方法难以适应动态区域市场或从噪声数据中构建一致层次结构。

Method: CLIMB通过全局语义聚类提取核心职业，并利用基于反射的多智能体系统迭代构建层次结构。

Result: 在三个真实数据集上，CLIMB生成的分类法比现有方法更一致、可扩展，并能捕捉区域特征。

Conclusion: CLIMB框架能够自动创建高质量、数据驱动的职业分类法，优于现有方法，并能捕捉独特的区域特征。

Abstract: Creating robust occupation taxonomies, vital for applications ranging from
job recommendation to labor market intelligence, is challenging. Manual
curation is slow, while existing automated methods are either not adaptive to
dynamic regional markets (top-down) or struggle to build coherent hierarchies
from noisy data (bottom-up). We introduce CLIMB (CLusterIng-based Multi-agent
taxonomy Builder), a framework that fully automates the creation of
high-quality, data-driven taxonomies from raw job postings. CLIMB uses global
semantic clustering to distill core occupations, then employs a
reflection-based multi-agent system to iteratively build a coherent hierarchy.
On three diverse, real-world datasets, we show that CLIMB produces taxonomies
that are more coherent and scalable than existing methods and successfully
capture unique regional characteristics. We release our code and datasets at
https://anonymous.4open.science/r/CLIMB.

</details>


### [189] [A Comparative Study of Rule-Based and Data-Driven Approaches in Industrial Monitoring](https://arxiv.org/abs/2509.15848)
*Giovanni De Gasperis,Sante Dino Facchini*

Main category: cs.AI

TL;DR: 论文比较了工业监控中规则系统与数据驱动方法的优劣，提出混合解决方案可能是未来方向。


<details>
  <summary>Details</summary>
Motivation: 工业监控系统正从传统规则架构转向数据驱动方法，但两者各有优劣，需探讨如何结合其优势以应对复杂工业环境。

Method: 本研究提出了一种基本框架，用于比较规则架构与数据驱动方法的关键特性，并分析其强度、局限性和应用场景。

Result: 规则系统在稳定环境中表现优异，而数据驱动系统在复杂或动态场景中更具优势。混合解决方案可能是未来的发展方向。

Conclusion: 未来工业监控系统的发展方向在于结合规则逻辑与数据驱动方法的智能协同系统，以增强韧性、运营效率和信任。

Abstract: Industrial monitoring systems, especially when deployed in Industry 4.0
environments, are experiencing a shift in paradigm from traditional rule-based
architectures to data-driven approaches leveraging machine learning and
artificial intelligence. This study presents a comparison between these two
methodologies, analyzing their respective strengths, limitations, and
application scenarios, and proposes a basic framework to evaluate their key
properties. Rule-based systems offer high interpretability, deterministic
behavior, and ease of implementation in stable environments, making them ideal
for regulated industries and safety-critical applications. However, they face
challenges with scalability, adaptability, and performance in complex or
evolving contexts. Conversely, data-driven systems excel in detecting hidden
anomalies, enabling predictive maintenance and dynamic adaptation to new
conditions. Despite their high accuracy, these models face challenges related
to data availability, explainability, and integration complexity. The paper
suggests hybrid solutions as a possible promising direction, combining the
transparency of rule-based logic with the analytical power of machine learning.
Our hypothesis is that the future of industrial monitoring lies in intelligent,
synergic systems that leverage both expert knowledge and data-driven insights.
This dual approach enhances resilience, operational efficiency, and trust,
paving the way for smarter and more flexible industrial environments.

</details>


### [190] [EHR-MCP: Real-world Evaluation of Clinical Information Retrieval by Large Language Models via Model Context Protocol](https://arxiv.org/abs/2509.15957)
*Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki*

Main category: cs.AI

TL;DR: LLMs integrated with EHR via MCP tools achieved high accuracy in simple tasks but faced challenges in complex ones, highlighting potential for hospital AI agents while noting limitations in data handling and task complexity.


<details>
  <summary>Details</summary>
Motivation: Large language models (LLMs) show promise in medicine, but their deployment in hospitals is limited by restricted access to electronic health record (EHR) systems. The Model Context Protocol (MCP) enables integration between LLMs and external tools.

Method: Developed EHR-MCP, a framework of custom MCP tools integrated with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct agent to interact with it. Six tasks were tested, derived from use cases of the infection control team (ICT). Eight patients discussed at ICT conferences were retrospectively analyzed. Agreement with physician-generated gold standards was measured.

Result: The LLM consistently selected and executed the correct MCP tools. Except for two tasks, all tasks achieved near-perfect accuracy. Performance was lower in the complex task requiring time-dependent calculations. Most errors arose from incorrect arguments or misinterpretation of tool results. Responses from EHR-MCP were reliable, though long and repetitive data risked exceeding the context window.

Conclusion: LLMs can retrieve clinical data from an EHR via MCP tools in a real hospital setting, achieving near-perfect performance in simple tasks while highlighting challenges in complex ones. EHR-MCP provides an infrastructure for secure, consistent data access and may serve as a foundation for hospital AI agents. Future work should extend beyond retrieval to reasoning, generation, and clinical impact assessment, paving the way for effective integration of generative AI into clinical practice.

Abstract: Background: Large language models (LLMs) show promise in medicine, but their
deployment in hospitals is limited by restricted access to electronic health
record (EHR) systems. The Model Context Protocol (MCP) enables integration
between LLMs and external tools.
  Objective: To evaluate whether an LLM connected to an EHR database via MCP
can autonomously retrieve clinically relevant information in a real hospital
setting.
  Methods: We developed EHR-MCP, a framework of custom MCP tools integrated
with the hospital EHR database, and used GPT-4.1 through a LangGraph ReAct
agent to interact with it. Six tasks were tested, derived from use cases of the
infection control team (ICT). Eight patients discussed at ICT conferences were
retrospectively analyzed. Agreement with physician-generated gold standards was
measured.
  Results: The LLM consistently selected and executed the correct MCP tools.
Except for two tasks, all tasks achieved near-perfect accuracy. Performance was
lower in the complex task requiring time-dependent calculations. Most errors
arose from incorrect arguments or misinterpretation of tool results. Responses
from EHR-MCP were reliable, though long and repetitive data risked exceeding
the context window.
  Conclusions: LLMs can retrieve clinical data from an EHR via MCP tools in a
real hospital setting, achieving near-perfect performance in simple tasks while
highlighting challenges in complex ones. EHR-MCP provides an infrastructure for
secure, consistent data access and may serve as a foundation for hospital AI
agents. Future work should extend beyond retrieval to reasoning, generation,
and clinical impact assessment, paving the way for effective integration of
generative AI into clinical practice.

</details>


### [191] [Structured Information for Improving Spatial Relationships in Text-to-Image Generation](https://arxiv.org/abs/2509.15962)
*Sander Schildermans,Chang Tian,Ying Jiao,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 提出一种轻量级方法，通过元组结构化信息增强文本到图像生成的空间关系准确性，实验证明效果显著且不影响图像质量。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像生成技术发展迅速，但准确捕捉自然语言提示中的空间关系仍是一大挑战。

Method: 使用微调的语言模型自动将自然语言提示转换为基于元组的结构化信息，并无缝集成到文本到图像生成流程中。

Result: 实验结果表明，该方法在空间准确性上有显著提升，且自动生成的元组质量与人工制作的相当。

Conclusion: 通过引入基于元组的结构化信息，该方法显著提升了文本到图像生成中的空间关系准确性，且不影响整体图像质量，为解决当前大规模生成系统的关键限制提供了实用且便携的解决方案。

Abstract: Text-to-image (T2I) generation has advanced rapidly, yet faithfully capturing
spatial relationships described in natural language prompts remains a major
challenge. Prior efforts have addressed this issue through prompt optimization,
spatially grounded generation, and semantic refinement. This work introduces a
lightweight approach that augments prompts with tuple-based structured
information, using a fine-tuned language model for automatic conversion and
seamless integration into T2I pipelines. Experimental results demonstrate
substantial improvements in spatial accuracy, without compromising overall
image quality as measured by Inception Score. Furthermore, the automatically
generated tuples exhibit quality comparable to human-crafted tuples. This
structured information provides a practical and portable solution to enhance
spatial relationships in T2I generation, addressing a key limitation of current
large-scale generative systems.

</details>


### [192] [Attention Schema-based Attention Control (ASAC): A Cognitive-Inspired Approach for Attention Management in Transformers](https://arxiv.org/abs/2509.16058)
*Krati Saxena,Federico Jurado Ruiz,Guido Manzi,Dianbo Liu,Alex Lamb*

Main category: cs.AI

TL;DR: ASAC模块将认知科学的注意力模式理论融入AI，通过VQVAE优化注意力管理，显著提升Transformer在视觉和NLP任务中的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 受认知科学中的注意力模式理论（AST）启发，研究旨在通过模拟人类注意力管理机制，优化AI系统中的注意力分配，提升模型性能和效率。

Method: 研究提出ASAC模块，将注意力模式理论整合到人工神经网络中，利用VQVAE作为注意力抽象器和控制器，嵌入Transformer架构进行实验。

Result: 实验表明，ASAC模块在视觉和NLP任务中均能提高分类准确率、加速学习过程，并在噪声和分布外数据上展现出良好的鲁棒性，同时在多任务和对抗攻击场景下表现优异。

Conclusion: ASAC通过将注意力模式概念引入人工神经网络，显著提升了模型在视觉和NLP领域的性能，同时增强了系统的效率和鲁棒性，为认知科学与机器学习的结合提供了新的视角。

Abstract: Attention mechanisms have become integral in AI, significantly enhancing
model performance and scalability by drawing inspiration from human cognition.
Concurrently, the Attention Schema Theory (AST) in cognitive science posits
that individuals manage their attention by creating a model of the attention
itself, effectively allocating cognitive resources. Inspired by AST, we
introduce ASAC (Attention Schema-based Attention Control), which integrates the
attention schema concept into artificial neural networks. Our initial
experiments focused on embedding the ASAC module within transformer
architectures. This module employs a Vector-Quantized Variational AutoEncoder
(VQVAE) as both an attention abstractor and controller, facilitating precise
attention management. By explicitly modeling attention allocation, our approach
aims to enhance system efficiency. We demonstrate ASAC's effectiveness in both
the vision and NLP domains, highlighting its ability to improve classification
accuracy and expedite the learning process. Our experiments with vision
transformers across various datasets illustrate that the attention controller
not only boosts classification accuracy but also accelerates learning.
Furthermore, we have demonstrated the model's robustness and generalization
capabilities across noisy and out-of-distribution datasets. In addition, we
have showcased improved performance in multi-task settings. Quick experiments
reveal that the attention schema-based module enhances resilience to
adversarial attacks, optimizes attention to improve learning efficiency, and
facilitates effective transfer learning and learning from fewer examples. These
promising results establish a connection between cognitive science and machine
learning, shedding light on the efficient utilization of attention mechanisms
in AI systems.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [193] [Graph-Based Approximate Nearest Neighbor Search Revisited: Theoretical Analysis and Optimization](https://arxiv.org/abs/2509.15531)
*Xinran Ma,Zhaoqi Zhou,Chuan Zhou,Qi Meng,Zaijiu Shang,Guoliang Li,Zhiming Ma*

Main category: cs.DS

TL;DR: 本文通过理论分析优化稀疏邻域图的截断参数选择，显著提升索引构建速度和搜索性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏邻域图（SNG）在近似最近邻搜索（ANNS）中表现优异，但其理论理解不足，导致依赖启发式且次优的截断策略。本文旨在填补理论与实践的鸿沟。

Method: 本文采用基于鞅的理论分析来表征索引构建过程，并提出了一种新的截断参数选择方法。

Result: 理论分析表明索引图的度为$O(n^{2/3+\epsilon})$，搜索路径长度为$O(\log n)$。实验结果显示新方法在查询延迟和召回率上表现优异，且索引构建速度提升2至9倍。

Conclusion: 通过理论分析和实验验证，本文提出的基于原则的截断参数选择方法在性能和效率上优于启发式方法，显著提升了索引构建速度。

Abstract: Graph-based approaches to approximate nearest neighbor search (ANNS) have
achieved remarkable success in enabling fast, high-recall retrieval on
billion-scale vector datasets. Among them, the Sparse Neighborhood Graph (SNG)
has emerged as a widely adopted graph structure due to its superior search
performance. However, the theoretical understanding of SNG remains limited,
leading to reliance on heuristic-based and often suboptimal truncation
strategies. In this work, we aim to bridge the gap between theory and practice
by providing formal guarantees for graph-based ANNS methods and proposing
principled optimization strategies for the truncation parameter. By
characterizing the index construction process through martingale-based
analysis, we show that the degree of the index graph is $O(n^{2/3+\epsilon})$,
where $\epsilon$ is an arbitrarily small constant. Furthermore, we prove that
the expected search path length during query processing is $O(\log n)$. Based
on these theoretical insights, we introduce a novel and principled method for
selecting the truncation parameter $R$ in SNG. Experimental results demonstrate
that our method achieves comparable or superior performance in terms of query
latency and Recall@10 compared to commonly used binary search heuristics, while
yielding 2x to 9x speedups in overall index construction.

</details>


### [194] [Constant time enumeration of perfect bipartite matchings](https://arxiv.org/abs/2509.16135)
*Jiří Fink*

Main category: cs.DS

TL;DR: 提出了一种高效枚举二分图完美匹配的算法，时间复杂度优于现有方法，并引入算术电路变体优化存储。


<details>
  <summary>Details</summary>
Motivation: 当前最快的算法（Uno提出）需要O(log |V|)时间枚举完美匹配，存在效率瓶颈。

Method: 通过开发一种算术电路的变体来表示访问的完美匹配，并将其存储在二叉树中。

Result: 新算法在常数分摊时间内枚举完美匹配，并展示了在某些图类中无法通过数组实现相同效率。

Conclusion: 该论文提出了一种能够在常数分摊时间内枚举二分图中所有完美匹配的算法，优于25年前Uno提出的O(log |V|)时间算法。

Abstract: We present an algorithm that enumerates all the perfect matchings in a given
bipartite graph G = (V,E). Our algorithm requires a constant amortized time to
visit one perfect matching of G, in contrast to the current fastest algorithm,
published 25 years ago by Uno, which requires O(log |V|) time.
  To facilitate the listing of all edges in a visited perfect matching, we
develop a variant of arithmetic circuits, which may have broader applications
in future enumeration algorithms. Consequently, a visited perfect matching is
represented within a binary tree. Although it is more common to provide visited
objects in an array, we present a class of graphs for which achieving constant
amortized time is not feasible in this case.

</details>


### [195] [On the Structural Parameterizations of 2-Club with Triangle Constraints](https://arxiv.org/abs/2509.16143)
*Ashwin Jacob,Diptapriyo Majumdar,Raghav Sakhuja*

Main category: cs.DS

TL;DR: 本文研究了Vertex r-Triangle s-Club问题的参数化复杂性，提供了针对不同结构参数的算法和核。


<details>
  <summary>Details</summary>
Motivation: 为了扩展对s-Club问题的理解，并研究其变体Vertex r-Triangle s-Club在参数化复杂性框架下的性质。

Method: 本文使用参数化复杂性理论，针对不同的结构参数（如树宽、h指数和反馈边数）设计了算法。

Result: 提供了针对树宽参数的FPT算法，针对h-index参数的XP算法，以及针对反馈边数参数的核。

Conclusion: 本文系统地研究了Vertex r-Triangle s-Club问题，针对不同的结构参数提供了FPT算法和XP算法，并针对反馈边数参数提供了核。

Abstract: Given an undirected graph G = (V, E) and an integer k, the s-Club asks if
Gcontains a vertex subset S of at least k vertices such that G[S] has diameter
at most s. Recently, Vertex r-Triangle s-Club, and Edge r-Triangle s-Club that
generalize the notion of s-Club have been studied by Garvardt et al.
[TOCS-2023, IWOCA-2022] from the perspective of parameterized complexity. Given
a graph G and an integer k, the Vertex r-Triangle s-Club asks if there is an
s-Club S with at least k vertices such that every vertex u \in S is part of at
least r triangles in G[S]. In this paper, we initiate a systematic study of
Vertex r-Triangle s-Club for every integer r >= 1 from the perspective of
structural parameters of the input graph. In particular, we provide FPT
algorithms for Vertex r-Triangle 2-Club when parameterized by the treewidth
(tw) of the input graph, and an XP algorithm when parameterized by the h-index
of the input graph. Additionally, when parameterized by the feedback edge
number (fes) of the input graph. We provide a kernel of O(fes) edges for Vertex
r-Triangle s-Club.

</details>


### [196] [Analyzing and improving a classical Betti number estimation algorithm](https://arxiv.org/abs/2509.16171)
*Julien Sorci*

Main category: cs.DS

TL;DR: 本文分析了经典Betti数估计算法的样本复杂度，提出改进方案，验证了其在‘简单’和‘困难’案例中的表现。


<details>
  <summary>Details</summary>
Motivation: 受量子算法启发，对具有类似蒙特卡洛结构的经典算法的样本复杂度进行更深入分析，以提升其效率。

Method: 提出了对经典算法的改进，通过分析估计器的方差及其与单纯复形组合性质的关系来优化样本复杂度。

Result: 改进后的算法在方差较小的单纯复形中显著降低了样本复杂度，但在某些情况下两者的样本复杂度仍呈指数级增长。

Conclusion: 本文通过深入分析经典算法的样本复杂度，提出了改进方案，使‘简单案例更简单’，并在Erdős-Renyi随机图模型中验证了其有效性和局限性。

Abstract: Recently, a classical algorithm for estimating the normalized Betti number of
an arbitrary simplicial complex was proposed. Motivated by a quantum algorithm
with a similar Monte Carlo structure and improved sample complexity, we give a
more in-depth analysis of the sample complexity of this classical algorithm. To
this end, we present bounds for the variance of the estimators used in the
classical algorithm and show that the variance depends on certain combinatorial
properties of the underlying simplicial complex. This new analysis leads us to
propose an improvement to the classical algorithm which makes the "easy cases
easier'', in that it reduces the sample complexity for simplicial complexes
where the variance is sufficiently small. We show the effectiveness and
limitations of these classical algorithms by considering Erd\H{o}s-Renyi random
graph models to demonstrate the existence of "easy" and "hard" cases. Namely,
we show that for certain models our improvement almost always leads to a
reduced sample complexity, and also produce separate regimes where the sample
complexity for both algorithms is exponential.

</details>


### [197] [Query-Efficient Locally Private Hypothesis Selection via the Scheffe Graph](https://arxiv.org/abs/2509.16180)
*Gautam Kamath,Alireza F. Pour,Matthew Regehr,David P. Woodruff*

Main category: cs.DS

TL;DR: 新算法在局部差分隐私下，用Õ(k³/²)次查询完成假设选择，引入Scheffé图优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有假设选择算法查询复杂度高（需Ω(k²)查询或多轮交互查询）的问题。

Method: 提出了一种满足局部差分隐私的算法，使用非自适应查询，通过Scheffé图捕捉分布间的差异结构。

Result: 算法仅需Õ(k³/²)次非自适应查询即可从集合Q中输出接近最优的分布，优于现有方法。

Conclusion: 该论文提出了一种在局部差分隐私约束下改进假设选择查询复杂度的算法，通过引入Scheffé图这一新对象，显著减少了查询次数。

Abstract: We propose an algorithm with improved query-complexity for the problem of
hypothesis selection under local differential privacy constraints. Given a set
of $k$ probability distributions $Q$, we describe an algorithm that satisfies
local differential privacy, performs $\tilde{O}(k^{3/2})$ non-adaptive queries
to individuals who each have samples from a probability distribution $p$, and
outputs a probability distribution from the set $Q$ which is nearly the closest
to $p$. Previous algorithms required either $\Omega(k^2)$ queries or many
rounds of interactive queries.
  Technically, we introduce a new object we dub the Scheff\'e graph, which
captures structure of the differences between distributions in $Q$, and may be
of more broad interest for hypothesis selection tasks.

</details>


### [198] [Clustering with Set Outliers and Applications in Relational Clustering](https://arxiv.org/abs/2509.16194)
*Vaishali Surianarayanan,Neeraj Kumar,Stavros Sintos*

Main category: cs.DS

TL;DR: 本文提出了一种支持移除集合异常值的k中心聚类模型，并提供了高效的近似算法，适用于数据库和传感器网络等实际场景。


<details>
  <summary>Details</summary>
Motivation: 传统k中心聚类仅能移除单个异常点，而实际应用中异常可能是结构化的（如数据源故障或记录损坏）。本文提出一种更通用的模型，允许移除整个集合作为异常值，以更好地适应实际需求。

Method: 通过引入三标准近似方法，使用最多2k个中心和2fz个异常集，实现了O(1)近似聚类成本。在几何设置中，利用范围和BBD树实现近线性时间算法。对于f=1的情况，通过构建小型核心集进一步优化运行时间。

Result: 在一般和几何设置下均实现了O(1)近似聚类成本，并在f=1时优化了运行时间。硬度结果表明，若不选择至少f·z个异常集，则难以获得次线性近似。

Conclusion: 本文提出了针对带有集合异常值的k中心聚类问题的近似算法，包括几何和一般设置下的解决方案，并展示了其在实际应用中的有效性。

Abstract: We introduce and study the $k$-center clustering problem with set outliers, a
natural and practical generalization of the classical $k$-center clustering
with outliers. Instead of removing individual data points, our model allows
discarding up to $z$ subsets from a given family of candidate outlier sets
$\mathcal{H}$. Given a metric space $(P,\mathsf{dist})$, where $P$ is a set of
elements and $\mathsf{dist}$ a distance metric, a family of sets
$\mathcal{H}\subseteq 2^P$, and parameters $k, z$, the goal is to compute a set
of $k$ centers $S\subseteq P$ and a family of $z$ sets $H\subseteq \mathcal{H}$
to minimize $\max_{p\in P\setminus(\bigcup_{h\in H} h)} \min_{s\in
S}\mathsf{dist}(p,s)$. This abstraction captures structured noise common in
database applications, such as faulty data sources or corrupted records in data
integration and sensor systems.
  We present the first approximation algorithms for this problem in both
general and geometric settings. Our methods provide tri-criteria
approximations: selecting up to $2k$ centers and $2f z$ outlier sets (where $f$
is the maximum number of sets that a point belongs to), while achieving
$O(1)$-approximation in clustering cost. In geometric settings, we leverage
range and BBD trees to achieve near-linear time algorithms. In many real
applications $f=1$. In this case we further improve the running time of our
algorithms by constructing small \emph{coresets}. We also provide a hardness
result for the general problem showing that it is unlikely to get any sublinear
approximation on the clustering cost selecting less than $f\cdot z$ outlier
sets.
  We demonstrate that this model naturally captures relational clustering with
outliers: outliers are input tuples whose removal affects the join output. We
provide approximation algorithms for both, establishing a tight connection
between robust clustering and relational query evaluation.

</details>
