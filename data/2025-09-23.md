<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 213]
- [cs.NI](#cs.NI) [Total: 10]
- [cs.GR](#cs.GR) [Total: 11]
- [cs.SE](#cs.SE) [Total: 21]
- [cs.DC](#cs.DC) [Total: 17]
- [cs.RO](#cs.RO) [Total: 74]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.AI](#cs.AI) [Total: 64]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Evaluation of Ensemble Learning Techniques for handwritten OCR Improvement](https://arxiv.org/abs/2509.16221)
*Martin Preiß*

Main category: cs.CV

TL;DR: 集成学习结合OCR能提高历史病历数字化的准确性，训练数据量不影响结果。


<details>
  <summary>Details</summary>
Motivation: 历史病历的手写记录需要高精度数字化，尤其在医学领域，准确性至关重要。集成学习被声称能提升现有方法的准确性，因此本研究探索其在OCR中的应用。

Method: 本研究采用集成学习方法，结合多种机器学习模型，以提高OCR的准确性。

Result: 研究发现，集成学习能有效提高OCR的准确性，并确定了实现这一目标的具体方法。

Conclusion: 集成学习可以显著提高OCR在历史病历数字化中的准确性，且训练数据集的大小对结果无显著影响。

Abstract: For the bachelor project 2021 of Professor Lippert's research group,
handwritten entries of historical patient records needed to be digitized using
Optical Character Recognition (OCR) methods. Since the data will be used in the
future, a high degree of accuracy is naturally required. Especially in the
medical field this has even more importance. Ensemble Learning is a method that
combines several machine learning models and is claimed to be able to achieve
an increased accuracy for existing methods. For this reason, Ensemble Learning
in combination with OCR is investigated in this work in order to create added
value for the digitization of the patient records. It was possible to discover
that ensemble learning can lead to an increased accuracy for OCR, which methods
were able to achieve this and that the size of the training data set did not
play a role here.

</details>


### [2] [Agentic Reasoning for Robust Vision Systems via Increased Test-Time Compute](https://arxiv.org/abs/2509.16343)
*Chung-En,Yu,Brian Jalaian,Nathaniel D. Bastian*

Main category: cs.CV

TL;DR: VRA是一种无需训练的视觉推理框架，通过代理循环显著提升准确性，但增加测试计算量。


<details>
  <summary>Details</summary>
Motivation: 开发可信赖的智能视觉系统，用于高风险领域（如遥感和医学诊断），需要在不进行昂贵重新训练的情况下实现广泛鲁棒性。

Method: 提出了Visual Reasoning Agent（VRA），一个无需训练的代理推理框架，采用Think--Critique--Act循环封装现成的视觉语言模型和纯视觉系统。

Result: VRA在挑战性视觉推理基准测试中实现了高达40%的绝对准确率提升。

Conclusion: VRA框架通过额外的测试时计算显著提升了视觉推理任务的准确性，未来工作将优化查询路由和提前停止以减少推理开销。

Abstract: Developing trustworthy intelligent vision systems for high-stakes domains,
\emph{e.g.}, remote sensing and medical diagnosis, demands broad robustness
without costly retraining. We propose \textbf{Visual Reasoning Agent (VRA)}, a
training-free, agentic reasoning framework that wraps off-the-shelf
vision-language models \emph{and} pure vision systems in a
\emph{Think--Critique--Act} loop. While VRA incurs significant additional
test-time computation, it achieves up to 40\% absolute accuracy gains on
challenging visual reasoning benchmarks. Future work will optimize query
routing and early stopping to reduce inference overhead while preserving
reliability in vision tasks.

</details>


### [3] [From Canopy to Ground via ForestGen3D: Learning Cross-Domain Generation of 3D Forest Structure from Aerial-to-Terrestrial LiDAR](https://arxiv.org/abs/2509.16346)
*Juan Castorena,E. Louise Loudermilk,Scott Pokswinski,Rodman Linn*

Main category: cs.CV

TL;DR: ForestGen3D是一种新型生成模型，仅需航空LiDAR输入即可合成高保真3D森林结构，解决了广泛测量成本高的问题，适用于生态建模和野火模拟。


<details>
  <summary>Details</summary>
Motivation: 准确表征3D植被结构对预测野火、干旱、疾病或大气沉积的影响至关重要，但广泛测量成本高昂且难以实现。

Method: 基于条件去噪扩散概率模型（DDPMs）训练，通过ALS/TLS数据生成高保真度的3D森林结构。模型利用ALS稀疏观测生成TLS般的3D点云，重建被遮挡的冠层细节。

Result: ForestGen3D在树木、地块和景观尺度上评估，生成的重建结果在几何相似性和生物物理指标（如树高、DBH、冠径和冠体积）上与TLS参考数据高度匹配。

Conclusion: ForestGen3D被定位为一个可扩展的工具，用于在仅有ALS数据的环境中进行生态建模、野火模拟和结构燃料特征描述。

Abstract: The 3D structure of living and non-living components in ecosystems plays a
critical role in determining ecological processes and feedbacks from both
natural and human-driven disturbances. Anticipating the effects of wildfire,
drought, disease, or atmospheric deposition depends on accurate
characterization of 3D vegetation structure, yet widespread measurement remains
prohibitively expensive and often infeasible. We introduce ForestGen3D, a novel
generative modeling framework that synthesizes high-fidelity 3D forest
structure using only aerial LiDAR (ALS) inputs. ForestGen3D is based on
conditional denoising diffusion probabilistic models (DDPMs) trained on
co-registered ALS/TLS (terrestrial LiDAR) data. The model learns to generate
TLS-like 3D point clouds conditioned on sparse ALS observations, effectively
reconstructing occluded sub-canopy detail at scale. To ensure ecological
plausibility, we introduce a geometric containment prior based on the convex
hull of ALS observations and provide theoretical and empirical guarantees that
generated structures remain spatially consistent. We evaluate ForestGen3D at
tree, plot, and landscape scales using real-world data from mixed conifer
ecosystems, and show that it produces high-fidelity reconstructions that
closely match TLS references in terms of geometric similarity and biophysical
metrics, such as tree height, DBH, crown diameter and crown volume.
Additionally, we demonstrate that the containment property can serve as a
practical proxy for generation quality in settings where TLS ground truth is
unavailable. Our results position ForestGen3D as a scalable tool for ecological
modeling, wildfire simulation, and structural fuel characterization in ALS-only
environments.

</details>


### [4] [Introducing Resizable Region Packing Problem in Image Generation, with a Heuristic Solution](https://arxiv.org/abs/2509.16363)
*Hrishikesh Sharma*

Main category: cs.CV

TL;DR: 本文引入了一个新的NP难问题（RARP），并提出了一种贪心启发式算法来生成合成图像数据，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决图像数据生成中的优化问题，尤其是传统方法（基于图形和生成模型）中存在的挑战。

Method: 提出了一种新颖的启发式算法，采用贪心策略迭代打包任意形状的区域对，同时遵守优化约束。

Result: 算法通过生成大规模合成异常检测数据集得到验证，视觉检查和解决方案的正确性证明了其有效性。

Conclusion: 本文提出的RARP问题及其启发式算法在合成图像数据生成中表现出色，验证了算法的有效性，并预计该问题将在图像科学社区中受到重视。

Abstract: The problem of image data generation in computer vision has traditionally
been a harder problem to solve, than discriminative problems. Such data
generation entails placing relevant objects of appropriate sizes each, at
meaningful location in a scene canvas. There have been two classes of popular
approaches to such generation: graphics based, and generative models-based.
Optimization problems are known to lurk in the background for both these
classes of approaches. In this paper, we introduce a novel, practically useful
manifestation of the classical Bin Packing problem in the context of generation
of synthetic image data. We conjecture that the newly introduced problem,
Resizable Anchored Region Packing(RARP) Problem, is NP-hard, and provide
detailed arguments about our conjecture. As a first solution, we present a
novel heuristic algorithm that is generic enough and therefore scales and packs
arbitrary number of arbitrary-shaped regions at arbitrary locations, into an
image canvas. The algorithm follows greedy approach to iteratively pack region
pairs in a careful way, while obeying the optimization constraints. The
algorithm is validated by an implementation that was used to generate a
large-scale synthetic anomaly detection dataset, with highly varying degree of
bin packing parameters per image sample i.e. RARP instance. Visual inspection
of such data and checking of the correctness of each solution proves the
effectiveness of our algorithm. With generative modeling being on rise in deep
learning, and synthetic data generation poised to become mainstream, we expect
that the newly introduced problem will be valued in the imaging scientific
community.

</details>


### [5] [Accurate Thyroid Cancer Classification using a Novel Binary Pattern Driven Local Discrete Cosine Transform Descriptor](https://arxiv.org/abs/2509.16382)
*Saurabh Saini,Kapil Ahuja,Marc C. Steinbach,Thomas Wick*

Main category: cs.CV

TL;DR: A new CAD system using BPD-LDCT and non-linear SVM achieves near-perfect accuracy in thyroid cancer classification on public datasets.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the challenges in thyroid ultrasound image classification due to complex anatomical structures and noisy textures, necessitating a robust feature extraction method.

Method: The method involves developing a new CAD system using the BPD-LDCT descriptor, which integrates Local DCT (LDCT) and Improved Local Binary Pattern (ILBP) for feature extraction, followed by classification with a non-linear SVM.

Result: The results show outstanding performance in both benign/malignant classification (Stage I) and malignant sub-classification (Stage II), with accuracy rates of nearly 100% on TDID and 97-99% on AUITD.

Conclusion: The study concludes that the proposed BPD-LDCT descriptor combined with non-linear SVM achieves exceptional accuracy in thyroid cancer classification, demonstrating nearly 100% performance on TDID and 97-99% on AUITD datasets.

Abstract: In this study, we develop a new CAD system for accurate thyroid cancer
classification with emphasis on feature extraction. Prior studies have shown
that thyroid texture is important for segregating the thyroid ultrasound images
into different classes. Based upon our experience with breast cancer
classification, we first conjuncture that the Discrete Cosine Transform (DCT)
is the best descriptor for capturing textural features. Thyroid ultrasound
images are particularly challenging as the gland is surrounded by multiple
complex anatomical structures leading to variations in tissue density. Hence,
we second conjuncture the importance of localization and propose that the Local
DCT (LDCT) descriptor captures the textural features best in this context.
Another disadvantage of complex anatomy around the thyroid gland is scattering
of ultrasound waves resulting in noisy and unclear textures. Hence, we third
conjuncture that one image descriptor is not enough to fully capture the
textural features and propose the integration of another popular texture
capturing descriptor (Improved Local Binary Pattern, ILBP) with LDCT. ILBP is
known to be noise resilient as well. We term our novel descriptor as Binary
Pattern Driven Local Discrete Cosine Transform (BPD-LDCT). Final classification
is carried out using a non-linear SVM. The proposed CAD system is evaluated on
the only two publicly available thyroid cancer datasets, namely TDID and AUITD.
The evaluation is conducted in two stages. In Stage I, thyroid nodules are
categorized as benign or malignant. In Stage II, the malignant cases are
further sub-classified into TI-RADS (4) and TI-RADS (5). For Stage I
classification, our proposed model demonstrates exceptional performance of
nearly 100% on TDID and 97% on AUITD. In Stage II classification, the proposed
model again attains excellent classification of close to 100% on TDID and 99%
on AUITD.

</details>


### [6] [StereoAdapter: Adapting Stereo Depth Estimation to Underwater Scenes](https://arxiv.org/abs/2509.16415)
*Zhengri Wu,Yiran Wang,Yu Wen,Zeyu Zhang,Biao Wu,Hao Tang*

Main category: cs.CV

TL;DR: StereoAdapter是一个参数高效的自监督框架，通过动态LoRA适配和合成数据集预训练，显著提升了水下立体深度估计的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有水下立体深度估计方法的两大挑战：高效适应大视觉基础编码器到水下领域，以及紧密融合全局一致但尺度模糊的单目先验与局部度量但光度脆弱的立体对应。

Method: 提出了StereoAdapter，一个参数高效的自监督框架，结合了LoRA-adapted的单目基础编码器和循环立体细化模块，并引入了动态LoRA适配和合成数据集预训练。

Result: 在TartanAir和SQUID基准测试上分别提升了6.11%和5.12%，并在BlueROV2机器人上展示了实际部署的稳健性。

Conclusion: StereoAdapter框架在模拟和真实世界基准测试中表现出色，显著提升了性能，并展示了在实际机器人部署中的稳健性。

Abstract: Underwater stereo depth estimation provides accurate 3D geometry for robotics
tasks such as navigation, inspection, and mapping, offering metric depth from
low-cost passive cameras while avoiding the scale ambiguity of monocular
methods. However, existing approaches face two critical challenges: (i)
parameter-efficiently adapting large vision foundation encoders to the
underwater domain without extensive labeled data, and (ii) tightly fusing
globally coherent but scale-ambiguous monocular priors with locally metric yet
photometrically fragile stereo correspondences. To address these challenges, we
propose StereoAdapter, a parameter-efficient self-supervised framework that
integrates a LoRA-adapted monocular foundation encoder with a recurrent stereo
refinement module. We further introduce dynamic LoRA adaptation for efficient
rank selection and pre-training on the synthetic UW-StereoDepth-40K dataset to
enhance robustness under diverse underwater conditions. Comprehensive
evaluations on both simulated and real-world benchmarks show improvements of
6.11% on TartanAir and 5.12% on SQUID compared to state-of-the-art methods,
while real-world deployment with the BlueROV2 robot further demonstrates the
consistent robustness of our approach. Code:
https://github.com/AIGeeksGroup/StereoAdapter. Website:
https://aigeeksgroup.github.io/StereoAdapter.

</details>


### [7] [AHA -- Predicting What Matters Next: Online Highlight Detection Without Looking Ahead](https://arxiv.org/abs/2509.16421)
*Aiden Chang,Celso De Melo,Stephanie M. Lukin*

Main category: cs.CV

TL;DR: Aha是一种实时视频高亮检测框架，通过自回归和多模态模型实现高效推理，性能超越离线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解方法大多假设可以访问完整视频，不适合实时或流式场景，因此需要一种支持逐步推理的实时决策框架。

Method: Aha采用自回归高亮检测框架，结合多模态视觉语言模型和轻量级解耦头，利用Dynamic SinkCache机制实现无限长度流的恒定内存使用。

Result: Aha在TVSum和Mr.Hisum基准测试中分别实现了+5.9%和+8.3%的mAP提升，达到了最先进的性能。

Conclusion: Aha框架在实时视频流理解任务中表现出色，不仅超越了现有离线方法的性能，还展示了在机器人应用中的潜力。

Abstract: Real-time understanding of continuous video streams is essential for
intelligent agents operating in high-stakes environments, including autonomous
vehicles, surveillance drones, and disaster response robots. Yet, most existing
video understanding and highlight detection methods assume access to the entire
video during inference, making them unsuitable for online or streaming
scenarios. In particular, current models optimize for offline summarization,
failing to support step-by-step reasoning needed for real-time decision-making.
We introduce Aha, an autoregressive highlight detection framework that predicts
the relevance of each video frame against a task described in natural language.
Without accessing future video frames, Aha utilizes a multimodal
vision-language model and lightweight, decoupled heads trained on a large,
curated dataset of human-centric video labels. To enable scalability, we
introduce the Dynamic SinkCache mechanism that achieves constant memory usage
across infinite-length streams without degrading performance on standard
benchmarks. This encourages the hidden representation to capture high-level
task objectives, enabling effective frame-level rankings for informativeness,
relevance, and uncertainty with respect to the natural language task. Aha
achieves state-of-the-art (SOTA) performance on highlight detection benchmarks,
surpassing even prior offline, full-context approaches and video-language
models by +5.9% on TVSum and +8.3% on Mr.Hisum in mAP (mean Average Precision).
We explore Aha's potential for real-world robotics applications given a
task-oriented natural language input and a continuous, robot-centric video.
Both experiments demonstrate Aha's potential effectiveness as a real-time
reasoning module for downstream planning and long-horizon understanding.

</details>


### [8] [Task-Oriented Communications for 3D Scene Representation: Balancing Timeliness and Fidelity](https://arxiv.org/abs/2509.17282)
*Xiangmin Xu,Zhen Meng,Kan Chen,Jiaming Yang,Emma Li,Philip G. Zhao,David Flynn*

Main category: cs.CV

TL;DR: 本文提出了一种结合AoI和语义信息的PPO框架，优化了3D场景表示的实时性与保真度，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 实时3D场景表示是支撑数字制造、VR/AR/MR及元宇宙等前沿应用的基础要素，但在实时性和保真度之间取得平衡仍具挑战性。

Method: 提出了一种上下文强盗Proximal Policy Optimization（PPO）框架，结合Age of Information（AoI）和语义信息来优化图像选择，以实现表示质量的平衡。评估了两种策略（ω-阈值和ω-等待策略）以及两种基准方法（时间嵌入和加权和）。

Result: 实验结果表明，所提方法在保持低延迟的同时提高了表示保真度，并提供了对模型决策过程的深入理解。

Conclusion: 本研究通过提出一种结合AoI和语义信息的上下文强盗PPO框架，优化了动态环境中3D场景表示的实时性和保真度之间的权衡。

Abstract: Real-time Three-dimensional (3D) scene representation is a foundational
element that supports a broad spectrum of cutting-edge applications, including
digital manufacturing, Virtual, Augmented, and Mixed Reality (VR/AR/MR), and
the emerging metaverse. Despite advancements in real-time communication and
computing, achieving a balance between timeliness and fidelity in 3D scene
representation remains a challenge. This work investigates a wireless network
where multiple homogeneous mobile robots, equipped with cameras, capture an
environment and transmit images to an edge server over channels for 3D
representation. We propose a contextual-bandit Proximal Policy Optimization
(PPO) framework incorporating both Age of Information (AoI) and semantic
information to optimize image selection for representation, balancing data
freshness and representation quality. Two policies -- the $\omega$-threshold
and $\omega$-wait policies -- together with two benchmark methods are
evaluated, timeliness embedding and weighted sum, on standard datasets and
baseline 3D scene representation models. Experimental results demonstrate
improved representation fidelity while maintaining low latency, offering
insight into the model's decision-making process. This work advances real-time
3D scene representation by optimizing the trade-off between timeliness and
fidelity in dynamic environments.

</details>


### [9] [3D Gaussian Flats: Hybrid 2D/3D Photometric Scene Reconstruction](https://arxiv.org/abs/2509.16423)
*Maria Taktasheva,Lily Goli,Alessandro Fiorini,Zhen,Li,Daniel Rebain,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: 论文提出了一种混合2D/3D表示方法，通过动态优化平面区域，显著提升了平坦表面的重建质量，并在多个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 针对当前辐射场和新视角合成方法在平坦、无纹理表面重建中的不足（如不均匀和半透明重建问题），以及表面重建方法牺牲视觉质量的问题，论文旨在提出一种兼顾视觉质量和几何准确性的解决方案。

Method: 论文采用了一种端到端的混合2D/3D表示方法，动态检测并优化平面区域，结合约束平面（2D）高斯和自由形式（3D）高斯，以提升视觉保真度和几何精度。

Result: 该方法在ScanNet++和ScanNetv2上实现了最先进的深度估计，并在网格提取中表现出色，避免了过拟合特定相机模型的问题。

Conclusion: 该论文提出了一种新颖的2D/3D混合表示方法，通过联合优化约束平面（2D）高斯和自由形式（3D）高斯，显著提升了平坦表面的重建质量。该方法在ScanNet++和ScanNetv2上实现了最先进的深度估计，并在不依赖特定相机模型的情况下，展示了高质量室内场景重建的有效性。

Abstract: Recent advances in radiance fields and novel view synthesis enable creation
of realistic digital twins from photographs. However, current methods struggle
with flat, texture-less surfaces, creating uneven and semi-transparent
reconstructions, due to an ill-conditioned photometric reconstruction
objective. Surface reconstruction methods solve this issue but sacrifice visual
quality. We propose a novel hybrid 2D/3D representation that jointly optimizes
constrained planar (2D) Gaussians for modeling flat surfaces and freeform (3D)
Gaussians for the rest of the scene. Our end-to-end approach dynamically
detects and refines planar regions, improving both visual fidelity and
geometric accuracy. It achieves state-of-the-art depth estimation on ScanNet++
and ScanNetv2, and excels at mesh extraction without overfitting to a specific
camera model, showing its effectiveness in producing high-quality
reconstruction of indoor scenes.

</details>


### [10] [TractoTransformer: Diffusion MRI Streamline Tractography using CNN and Transformer Networks](https://arxiv.org/abs/2509.16429)
*Itzik Waizman,Yakov Gusakov,Itay Benou,Tammy Riklin Raviv*

Main category: cs.CV

TL;DR: 新型纤维束追踪方法结合Transformer和CNN，显著提升白质通路重建的精确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 解决传统纤维束追踪技术在处理交叉、合并和扇形白质结构时的噪声和模糊性问题。

Method: 利用Transformer建模白质纤维束的序列性质，结合CNN提取局部微结构特征，整合轨迹上下文和当前扩散MRI数据预测纤维方向。

Result: 在Tractometer工具包评估中表现优异，并在TractoInferno数据集上展示了良好的泛化能力。

Conclusion: 本文提出的结合Transformer和CNN的新型纤维束追踪方法，在提高神经通路映射的精确性和完整性方面优于传统模型。

Abstract: White matter tractography is an advanced neuroimaging technique that
reconstructs the 3D white matter pathways of the brain from diffusion MRI data.
It can be framed as a pathfinding problem aiming to infer neural fiber
trajectories from noisy and ambiguous measurements, facing challenges such as
crossing, merging, and fanning white-matter configurations. In this paper, we
propose a novel tractography method that leverages Transformers to model the
sequential nature of white matter streamlines, enabling the prediction of fiber
directions by integrating both the trajectory context and current diffusion MRI
measurements. To incorporate spatial information, we utilize CNNs that extract
microstructural features from local neighborhoods around each voxel. By
combining these complementary sources of information, our approach improves the
precision and completeness of neural pathway mapping compared to traditional
tractography models. We evaluate our method with the Tractometer toolkit,
achieving competitive performance against state-of-the-art approaches, and
present qualitative results on the TractoInferno dataset, demonstrating strong
generalization to real-world data.

</details>


### [11] [Improved mmFormer for Liver Fibrosis Staging via Missing-Modality Compensation](https://arxiv.org/abs/2509.16436)
*Zhejia Zhang,Junjie Wang,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种处理MRI模态缺失的多模态分类模型，结合自适应补偿模块和交叉验证集成策略，在肝病检测任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 现实临床环境中，MRI常因设备差异或患者配合问题导致模态缺失，严重影响模型性能，因此需要一种能够处理任意缺失模态组合的分类模型。

Method: 提出了一种基于mmFormer架构的多模态MRI分类模型，包含混合模态特定编码器、模态相关编码器以及缺失模态补偿模块。补偿模块利用零填充、模态可用性掩码和可学习统计参数的Delta函数动态合成代理特征。此外，采用交叉验证集成策略训练多个模型并通过软投票进行推理。

Result: 在CARE 2025挑战赛的测试集上，针对肝硬化检测和显著纤维化检测任务，模型的准确率分别为66.67%和74.17%，AUC分数分别为71.73%和68.48%。

Conclusion: 该模型通过自适应模块和交叉验证集成策略，有效处理了MRI模态缺失问题，并在肝硬化检测和显著纤维化检测任务上取得了较好的准确率和AUC分数。

Abstract: In real-world clinical settings, magnetic resonance imaging (MRI) frequently
suffers from missing modalities due to equipment variability or patient
cooperation issues, which can significantly affect model performance. To
address this issue, we propose a multimodal MRI classification model based on
the mmFormer architecture with an adaptive module for handling arbitrary
combinations of missing modalities. Specifically, this model retains the hybrid
modality-specific encoders and the modality-correlated encoder from mmFormer to
extract consistent lesion features across available modalities. In addition, we
integrate a missing-modality compensation module which leverages zero-padding,
modality availability masks, and a Delta Function with learnable statistical
parameters to dynamically synthesize proxy features for recovering missing
information. To further improve prediction performance, we adopt a
cross-validation ensemble strategy by training multiple models on different
folds and applying soft voting during inference. This method is evaluated on
the test set of Comprehensive Analysis & Computing of REal-world medical images
(CARE) 2025 challenge, targeting the Liver Fibrosis Staging (LiFS) task based
on non-contrast dynamic MRI scans including T1-weighted imaging (T1WI),
T2-weighted imaging (T2WI), and diffusion-weighted imaging (DWI). For Cirrhosis
Detection and Substantial Fibrosis Detection on in-distribution vendors, our
model obtains accuracies of 66.67%, and 74.17%, and corresponding area under
the curve (AUC) scores of 71.73% and 68.48%, respectively.

</details>


### [12] [AutoArabic: A Three-Stage Framework for Localizing Video-Text Retrieval Benchmarks](https://arxiv.org/abs/2509.16438)
*Mohamed Eltahir,Osamah Sarraj,Abdulrahman Alfrihidi,Taha Alshatiri,Mohammed Khurd,Mohammed Bremoo,Tanveer Hussain*

Main category: cs.CV

TL;DR: AutoArabic框架利用LLMs将非阿拉伯语视频检索基准翻译为现代标准阿拉伯语，减少了人工修订需求并保持基准难度，错误检测准确率达97%。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语在视频到文本和文本到视频检索领域缺乏本地化评估指标，现有基准多为英语或多语言，无法满足阿拉伯语需求。

Method: 采用三阶段框架（AutoArabic），利用最先进的大型语言模型（LLMs）进行翻译，并集成了错误检测模块。

Result: 生成的DiDeMo-AR包含40,144条流畅的阿拉伯语描述，错误检测准确率达97%。在相同超参数下，阿拉伯语和英语基准性能差距约为3个百分点。

Conclusion: AutoArabic框架成功地将非阿拉伯语基准翻译为现代标准阿拉伯语，显著减少了人工修订需求，并保持了基准的难度。通过不同后编辑预算的评估，证明了其可用性和可扩展性。

Abstract: Video-to-text and text-to-video retrieval are dominated by English benchmarks
(e.g. DiDeMo, MSR-VTT) and recent multilingual corpora (e.g. RUDDER), yet
Arabic remains underserved, lacking localized evaluation metrics. We introduce
a three-stage framework, AutoArabic, utilizing state-of-the-art large language
models (LLMs) to translate non-Arabic benchmarks into Modern Standard Arabic,
reducing the manual revision required by nearly fourfold. The framework
incorporates an error detection module that automatically flags potential
translation errors with 97% accuracy. Applying the framework to DiDeMo, a video
retrieval benchmark produces DiDeMo-AR, an Arabic variant with 40,144 fluent
Arabic descriptions. An analysis of the translation errors is provided and
organized into an insightful taxonomy to guide future Arabic localization
efforts. We train a CLIP-style baseline with identical hyperparameters on the
Arabic and English variants of the benchmark, finding a moderate performance
gap (about 3 percentage points at Recall@1), indicating that Arabic
localization preserves benchmark difficulty. We evaluate three post-editing
budgets (zero/ flagged-only/ full) and find that performance improves
monotonically with more post-editing, while the raw LLM output (zero-budget)
remains usable. To ensure reproducibility to other languages, we made the code
available at https://github.com/Tahaalshatiri/AutoArabic.

</details>


### [13] [Preconditioned Deformation Grids](https://arxiv.org/abs/2509.18097)
*Julian Kaltheuner,Alexander Oebel,Hannah Droege,Patrick Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: 提出预处理变形网格技术，通过多分辨率体素网格和多种损失函数，直接从点云序列估计连贯变形场，无需显式对应关系，显著提升重建效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要多重正则化项或大量训练数据，导致重建精度下降、过度平滑或对未见物体和运动的泛化能力差。

Method: 采用多分辨率体素网格捕获不同空间尺度的整体运动，结合基于网格的Sobolev预处理和梯度优化，使用Chamfer损失和弱等距损失来确保变形准确性和时间一致性。

Result: 在广泛评估中，该方法在长序列处理上优于现有技术，展现出更高的重建准确性和时间一致性。

Conclusion: 该方法通过引入预处理变形网格和多种损失函数，显著提高了点云序列动态表面重建的准确性和时间一致性，尤其在长序列处理上表现优异。

Abstract: Dynamic surface reconstruction of objects from point cloud sequences is a
challenging field in computer graphics. Existing approaches either require
multiple regularization terms or extensive training data which, however, lead
to compromises in reconstruction accuracy as well as over-smoothing or poor
generalization to unseen objects and motions. To address these lim- itations,
we introduce Preconditioned Deformation Grids, a novel technique for estimating
coherent deformation fields directly from unstructured point cloud sequences
without requiring or forming explicit correspondences. Key to our approach is
the use of multi-resolution voxel grids that capture the overall motion at
varying spatial scales, enabling a more flexible deformation representation. In
conjunction with incorporating grid-based Sobolev preconditioning into
gradient-based optimization, we show that applying a Chamfer loss between the
input point clouds as well as to an evolving template mesh is sufficient to
obtain accurate deformations. To ensure temporal consistency along the object
surface, we include a weak isometry loss on mesh edges which complements the
main objective without constraining deformation fidelity. Extensive evaluations
demonstrate that our method achieves superior results, particularly for long
sequences, compared to state-of-the-art techniques.

</details>


### [14] [KRAST: Knowledge-Augmented Robotic Action Recognition with Structured Text for Vision-Language Models](https://arxiv.org/abs/2509.16452)
*Son Hai Nguyen,Diwei Wang,Jinhyeok Jang,Hyewon Seo*

Main category: cs.CV

TL;DR: 通过知识增强的视觉语言模型（VLM）提升室内日常动作识别，实验显示该方法准确率超95%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 开发能够在复杂真实环境中安全可靠运行的自主机器人，需要准确的视觉动作识别能力。

Method: 采用提示学习框架，将动作的类级文本描述作为可学习提示嵌入预训练的视觉语言模型（VLM）主干中，并设计了多种文本描述结构和编码策略。

Result: 在仅使用RGB视频输入的情况下，该方法在ETRI-Activity3D数据集上实现了超过95%的准确率，优于现有最优方法。

Conclusion: 知识增强的提示方法在最小监督下实现了鲁棒的动作识别，实验结果表明该方法在ETRI-Activity3D数据集上准确率超过95%，优于现有最优方法。

Abstract: Accurate vision-based action recognition is crucial for developing autonomous
robots that can operate safely and reliably in complex, real-world
environments. In this work, we advance video-based recognition of indoor daily
actions for robotic perception by leveraging vision-language models (VLMs)
enriched with domain-specific knowledge. We adapt a prompt-learning framework
in which class-level textual descriptions of each action are embedded as
learnable prompts into a frozen pre-trained VLM backbone. Several strategies
for structuring and encoding these textual descriptions are designed and
evaluated. Experiments on the ETRI-Activity3D dataset demonstrate that our
method, using only RGB video inputs at test time, achieves over 95\% accuracy
and outperforms state-of-the-art approaches. These results highlight the
effectiveness of knowledge-augmented prompts in enabling robust action
recognition with minimal supervision.

</details>


### [15] [Explainable Gait Abnormality Detection Using Dual-Dataset CNN-LSTM Models](https://arxiv.org/abs/2509.16472)
*Parth Agarwal,Sangaa Chatterjee,Md Faisal Kabir,Suman Saha*

Main category: cs.CV

TL;DR: 提出双分支CNN-LSTM框架，结合1D和3D数据，通过SHAP和Grad-CAM增强可解释性，在步态分析中实现高准确率。


<details>
  <summary>Details</summary>
Motivation: 步态是诊断运动障碍的关键指标，但大多数模型缺乏可解释性且依赖单一数据集。

Method: 提出了一个双分支CNN-LSTM框架，包括基于GAVD关节特征的1D分支和基于OU-MVLP轮廓的3D分支，通过SHAP（时间归因）和Grad-CAM（空间定位）提供可解释性。

Result: 在保留集上，系统达到了98.6%的准确率，具有较高的召回率和F1值。

Conclusion: 该方法在临床和生物识别领域推动了可解释的步态分析。

Abstract: Gait is a key indicator in diagnosing movement disorders, but most models
lack interpretability and rely on single datasets. We propose a dual-branch
CNN-LSTM framework a 1D branch on joint-based features from GAVD and a 3D
branch on silhouettes from OU-MVLP. Interpretability is provided by SHAP
(temporal attributions) and Grad-CAM (spatial localization).On held-out sets,
the system achieves 98.6% accuracy with strong recall and F1. This approach
advances explainable gait analysis across both clinical and biometric domains.

</details>


### [16] [Cross-Corpus and Cross-domain Handwriting Assessment of NeuroDegenerative Diseases via Time-Series-to-Image Conversion](https://arxiv.org/abs/2509.16474)
*Gabrielle Chavez,Laureano Moro-Velazquez,Ankur Butala,Najim Dehak,Thomas Thebaud*

Main category: cs.CV

TL;DR: 该研究提出了一种联合分类器框架，结合时间序列和图像数据，显著提升了神经退行性疾病笔迹分析的泛化能力和检测性能。


<details>
  <summary>Details</summary>
Motivation: 神经退行性疾病（如帕金森病和阿尔茨海默病）显著影响笔迹，但现有方法在跨数据集泛化方面存在局限。

Method: 研究采用基于ResNet50预训练模型的联合分类器，同时处理时间序列和图像数据，以分析笔迹任务。

Result: 在现有时间序列和图像数据集上，该模型实现了最先进的性能，特别是在NeuroLogical Signals (NLS)数据集中的Draw Clock和Spiral任务上表现突出。

Conclusion: 该研究提出的联合分类器框架在神经退行性疾病的笔迹分析中表现出优异的泛化能力和检测性能，特别是在帕金森病检测中达到了高达98的F1分数。

Abstract: Handwriting is significantly affected by neurological disorders (ND) such as
Parkinson's disease (PD) and Alzheimer's disease (AD). Prior works have
analyzed handwriting tasks using feature-based approaches or computer-vision
techniques, but these methods have struggled to generalize across multiple
datasets, particularly between temporal features represented as time-series and
images. We propose a framework that leverages both time-series and images of
handwriting through a joint classifier, based on a ResNet50 pretrained on
ImageNet-1k. Binary classification experiments demonstrate state-of-the-art
performances on existing time-series and image datasets, with significant
improvement on specific drawing and writing tasks from the NeuroLogical Signals
(NLS) dataset. In particular, the proposed model demonstrates improved
performance on Draw Clock and Spiral tasks. Additionally, cross-dataset and
multi-dataset experiments were consistently able to achieve high F1 scores, up
to 98 for PD detection, highlighting the potential of the proposed model to
generalize over different forms of handwriting signals, and enhance the
detection of motor deficits in ND.

</details>


### [17] [Eye Gaze Tells You Where to Compute: Gaze-Driven Efficient VLMs](https://arxiv.org/abs/2509.16476)
*Qinyu Chen,Jiawen Qi*

Main category: cs.CV

TL;DR: GazeVLM利用人类视线优化视觉令牌计算，显著提升效率且保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在修剪视觉令牌时存在架构修改或中间激活访问需求，导致计算和内存增加，且可能牺牲准确性。此外，提示与图像感兴趣区域之间也存在不对齐问题。

Method: 提出GazeVLM框架，利用人类视线作为自然监督信号，提取感兴趣区域（ROIs）并可选地结合低分辨率全局视图，减少冗余视觉令牌。

Result: GazeVLM在VOILA-COCO基准测试中，视觉令牌减少高达93.1%，总令牌减少高达59.6%，FLOPs减少50%，同时保持优于全分辨率基线的答案质量。

Conclusion: GazeVLM通过将模型计算与人类视线对齐，为消费设备上的高效VLM推理提供了一种简单、即插即用的解决方案。

Abstract: Vision-Language Models (VLMs) deliver impressive performance in understanding
visual content with language instructions. However, redundancy in vision tokens
results in the degenerated inference efficiency of VLMs, which hinders
real-time use on edge consumer devices such as AR/VR devices. Existing
efficiency methods commonly prune visual tokens using learned saliency, sparse
attention schedules, or controller policies, but they often require
architectural modification or access to intermediate activations. These
pipelines add inference-time modules that increase compute and memory and often
lead to an accuracy trade-off. Moreover, they also suffer from misalignment
between the prompts and the region of interest in the images. Without human
guidance, the model may focus on the wrong regions and miss small,
high-frequency details when prompts or scenes change. In this paper, we propose
GazeVLM, a training-free framework that uses the human eye gaze as a natural
supervisory signal to allocate computation where it matters. By extracting
gaze-driven regions of interest (ROIs) and optionally combining them with a
low-resolution global view, GazeVLM mimics fovea-periphery perception to cut
redundant visual tokens while preserving task-relevant details. We evaluate the
visual question answering tasks on Qwen2.5-VL-3B/7B on the VOILA-COCO benchmark
with human gaze. Quality of the answer is assessed by GPT-4o pairwise judging
and a weighted score over coverage, accuracy, details, and fluency. Efficiency
is measured by token counts and FLOPs. GazeVLM reduces visual tokens by up to
93.1%, total tokens by up to 59.6%, and FLOPs by 50%, while keeping better
answer quality relative to full-resolution baselines. Our results show that
aligning model computation with human gaze offers a simple, plug-and-play path
toward efficient VLM inference on consumer devices.

</details>


### [18] [Thermal Imaging-based Real-time Fall Detection using Motion Flow and Attention-enhanced Convolutional Recurrent Architecture](https://arxiv.org/abs/2509.16479)
*Christopher Silver,Thangarajah Akilan*

Main category: cs.CV

TL;DR: 该研究提出了一种基于热成像和BiConvLSTM的跌倒检测方法，结合多种注意力机制，在TSF和TF-66数据集上表现优异，为实际应用提供了高性能解决方案。


<details>
  <summary>Details</summary>
Motivation: 老年人跌倒是一个重大公共卫生问题，现有解决方案在可靠性、用户依从性和实用性方面存在挑战。研究旨在开发一种非穿戴式、被动、隐私保护且无需用户交互的实时跌倒检测系统。

Method: 采用双向卷积长短期记忆（BiConvLSTM）模型，并结合空间、时间、特征、自注意和一般注意机制，通过系统实验探索了注意力机制、循环模块和运动流的集成。

Result: BiConvLSTM在TSF数据集上ROC-AUC达到99.7%，并在新兴多样化和隐私保护的基准TF-66上表现出稳健性能。

Conclusion: 该研究提出的BiConvLSTM模型在热成像跌倒检测中表现出色，ROC-AUC达到99.7%，为新基准TF-66提供了稳健的结果，为可部署的高性能解决方案设定了新标准。

Abstract: Falls among seniors are a major public health issue. Existing solutions using
wearable sensors, ambient sensors, and RGB-based vision systems face challenges
in reliability, user compliance, and practicality. Studies indicate that
stakeholders, such as older adults and eldercare facilities, prefer
non-wearable, passive, privacy-preserving, and real-time fall detection systems
that require no user interaction. This study proposes an advanced thermal fall
detection method using a Bidirectional Convolutional Long Short-Term Memory
(BiConvLSTM) model, enhanced with spatial, temporal, feature, self, and general
attention mechanisms. Through systematic experimentation across hundreds of
model variations exploring the integration of attention mechanisms, recurrent
modules, and motion flow, we identified top-performing architectures. Among
them, BiConvLSTM achieved state-of-the-art performance with a ROC-AUC of
$99.7\%$ on the TSF dataset and demonstrated robust results on TF-66, a newly
emerged, diverse, and privacy-preserving benchmark. These results highlight the
generalizability and practicality of the proposed model, setting new standards
for thermal fall detection and paving the way toward deployable,
high-performance solutions.

</details>


### [19] [Octree Latent Diffusion for Semantic 3D Scene Generation and Completion](https://arxiv.org/abs/2509.16483)
*Xujia Zhang,Brendan Crowe,Christoffer Heckman*

Main category: cs.CV

TL;DR: 提出Octree Latent Semantic Diffusion框架，统一3D语义场景的完成、扩展和生成，实现跨域兼容性和高效处理。


<details>
  <summary>Details</summary>
Motivation: 统一3D语义场景的完成、扩展和生成能力，提供跨域兼容性，解决现有方法领域特定和解耦问题。

Method: 开发了一个名为Octree Latent Semantic Diffusion的框架，直接在高效的双八叉图潜在表示上操作，分为结构扩散和潜在语义扩散两个阶段。

Result: 展示了高质量的结构、连贯的语义和从单次LiDAR扫描中的鲁棒完成，以及对分布外LiDAR数据的零样本泛化能力。

Conclusion: 通过双八叉树图潜在空间的生成完成方法，为实际机器人感知任务提供了一种实用且可扩展的替代基于回归的流程的方案。

Abstract: The completion, extension, and generation of 3D semantic scenes are an
interrelated set of capabilities that are useful for robotic navigation and
exploration. Existing approaches seek to decouple these problems and solve them
oneoff. Additionally, these approaches are often domain-specific, requiring
separate models for different data distributions, e.g. indoor vs. outdoor
scenes. To unify these techniques and provide cross-domain compatibility, we
develop a single framework that can perform scene completion, extension, and
generation in both indoor and outdoor scenes, which we term Octree Latent
Semantic Diffusion. Our approach operates directly on an efficient dual octree
graph latent representation: a hierarchical, sparse, and memory-efficient
occupancy structure. This technique disentangles synthesis into two stages: (i)
structure diffusion, which predicts binary split signals to construct a coarse
occupancy octree, and (ii) latent semantic diffusion, which generates semantic
embeddings decoded by a graph VAE into voxellevel semantic labels. To perform
semantic scene completion or extension, our model leverages inference-time
latent inpainting, or outpainting respectively. These inference-time methods
use partial LiDAR scans or maps to condition generation, without the need for
retraining or finetuning. We demonstrate highquality structure, coherent
semantics, and robust completion from single LiDAR scans, as well as zero-shot
generalization to out-of-distribution LiDAR data. These results indicate that
completion-through-generation in a dual octree graph latent space is a
practical and scalable alternative to regression-based pipelines for real-world
robotic perception tasks.

</details>


### [20] [RLGF: Reinforcement Learning with Geometric Feedback for Autonomous Driving Video Generation](https://arxiv.org/abs/2509.16500)
*Tianyi Yan,Wencheng Han,Xia Zhou,Xueyang Zhang,Kun Zhan,Cheng-zhong Xu,Jianbing Shen*

Main category: cs.CV

TL;DR: RLGF通过强化学习与几何反馈优化合成视频的几何准确性，显著提升自动驾驶感知任务性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽视觉逼真，但存在几何失真问题，限制了其在自动驾驶感知任务中的实用性。

Method: RLGF引入了强化学习与几何反馈，包括Latent-Space Windowing Optimization和Hierarchical Geometric Reward系统，优化视频扩散模型。

Result: RLGF显著减少了几何误差（如VP误差降低21%，深度误差降低57%），并将3D物体检测mAP提高了12.7%。

Conclusion: RLGF通过结合几何反馈显著提升了合成视频的几何准确性，缩小了与真实数据在下游感知任务中的性能差距，为自动驾驶开发提供了可靠的合成数据生成方案。

Abstract: Synthetic data is crucial for advancing autonomous driving (AD) systems, yet
current state-of-the-art video generation models, despite their visual realism,
suffer from subtle geometric distortions that limit their utility for
downstream perception tasks. We identify and quantify this critical issue,
demonstrating a significant performance gap in 3D object detection when using
synthetic versus real data. To address this, we introduce Reinforcement
Learning with Geometric Feedback (RLGF), RLGF uniquely refines video diffusion
models by incorporating rewards from specialized latent-space AD perception
models. Its core components include an efficient Latent-Space Windowing
Optimization technique for targeted feedback during diffusion, and a
Hierarchical Geometric Reward (HGR) system providing multi-level rewards for
point-line-plane alignment, and scene occupancy coherence. To quantify these
distortions, we propose GeoScores. Applied to models like DiVE on nuScenes,
RLGF substantially reduces geometric errors (e.g., VP error by 21\%, Depth
error by 57\%) and dramatically improves 3D object detection mAP by 12.7\%,
narrowing the gap to real-data performance. RLGF offers a plug-and-play
solution for generating geometrically sound and reliable synthetic videos for
AD development.

</details>


### [21] [CommonForms: A Large, Diverse Dataset for Form Field Detection](https://arxiv.org/abs/2509.16506)
*Joe Barrow*

Main category: cs.CV

TL;DR: CommonForms是首个大规模表单字段检测数据集，FFDNet模型高效且低成本，支持多语言和多领域检测。


<details>
  <summary>Details</summary>
Motivation: 解决表单字段检测缺乏大规模数据集和开源模型的问题，提升检测精度和效率。

Method: 通过过滤Common Crawl中的PDF文件构建了包含55k文档、450k页面的数据集，并开发了FFDNet-Small和FFDNet-Large两种模型进行表单字段检测。

Result: FFDNet模型在CommonForms测试集上达到高平均精度，且训练成本低于500美元，支持多种表单字段类型检测。

Conclusion: CommonForms数据集和FFDNet模型为表单字段检测提供了首个大规模数据集和开源模型，显著提升了检测精度，尤其在多语言和多领域环境中表现优异。

Abstract: This paper introduces CommonForms, a web-scale dataset for form field
detection. It casts the problem of form field detection as object detection:
given an image of a page, predict the location and type (Text Input, Choice
Button, Signature) of form fields. The dataset is constructed by filtering
Common Crawl to find PDFs that have fillable elements. Starting with 8 million
documents, the filtering process is used to arrive at a final dataset of
roughly 55k documents that have over 450k pages. Analysis shows that the
dataset contains a diverse mixture of languages and domains; one third of the
pages are non-English, and among the 14 classified domains, no domain makes up
more than 25% of the dataset.
  In addition, this paper presents a family of form field detectors,
FFDNet-Small and FFDNet-Large, which attain a very high average precision on
the CommonForms test set. Each model cost less than $500 to train. Ablation
results show that high-resolution inputs are crucial for high-quality form
field detection, and that the cleaning process improves data efficiency over
using all PDFs that have fillable fields in Common Crawl. A qualitative
analysis shows that they outperform a popular, commercially available PDF
reader that can prepare forms. Unlike the most popular commercially available
solutions, FFDNet can predict checkboxes in addition to text and signature
fields. This is, to our knowledge, the first large scale dataset released for
form field detection, as well as the first open source models. The dataset,
models, and code will be released at https://github.com/jbarrow/commonforms

</details>


### [22] [OS-DiffVSR: Towards One-step Latent Diffusion Model for High-detailed Real-world Video Super-Resolution](https://arxiv.org/abs/2509.16507)
*Hanting Li,Huaao Tang,Jianhong Han,Tianxiong Zhou,Jiulong Cui,Haizhen Xie,Yan Chen,Jie Hu*

Main category: cs.CV

TL;DR: OS-DiffVSR通过一步扩散模型和创新的训练机制，显著提升了视频超分辨率的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的视频超分辨率方法在视频质量和推理效率之间存在权衡，需要解决这一挑战。

Method: 提出了一种新的相邻帧对抗训练范式和多帧融合机制，以提升视频质量和保持帧间时间一致性。

Result: 在多个流行的VSR基准测试中，OS-DiffVSR表现优于现有需要多步采样的扩散模型。

Conclusion: OS-DiffVSR通过创新的相邻帧对抗训练范式和多帧融合机制，显著提升了视频超分辨率的质量和推理效率，优于现有的多步扩散模型。

Abstract: Recently, latent diffusion models has demonstrated promising performance in
real-world video super-resolution (VSR) task, which can reconstruct
high-quality videos from distorted low-resolution input through multiple
diffusion steps. Compared to image super-resolution (ISR), VSR methods needs to
process each frame in a video, which poses challenges to its inference
efficiency. However, video quality and inference efficiency have always been a
trade-off for the diffusion-based VSR methods. In this work, we propose
One-Step Diffusion model for real-world Video Super-Resolution, namely
OS-DiffVSR. Specifically, we devise a novel adjacent frame adversarial training
paradigm, which can significantly improve the quality of synthetic videos.
Besides, we devise a multi-frame fusion mechanism to maintain inter-frame
temporal consistency and reduce the flicker in video. Extensive experiments on
several popular VSR benchmarks demonstrate that OS-DiffVSR can even achieve
better quality than existing diffusion-based VSR methods that require dozens of
sampling steps.

</details>


### [23] [SlowFast-SCI: Slow-Fast Deep Unfolding Learning for Spectral Compressive Imaging](https://arxiv.org/abs/2509.16509)
*Haijin Zeng,Xuan Lu,Yurong Zhang,Yongyong Chen,Jingyong Su,Jie Liu*

Main category: cs.CV

TL;DR: SlowFast-SCI是一种双速深度展开框架，通过慢速预训练和快速测试时适应，显著提升了光谱压缩成像的效率与自适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有深度展开方法依赖大量预训练且缺乏快速适应能力，导致在新光学配置下表现不佳。

Method: 提出了SlowFast-SCI框架，结合预训练的主干网络和轻量化的快速适应模块，通过双域损失进行自监督测试时适应。

Result: 参数和FLOPs减少70%以上，分布外数据PSNR提升5.79 dB，适应速度提升4倍，且保持跨域适应性。

Conclusion: SlowFast-SCI通过双阶段设计（慢速学习与快速适应）实现了高效、自适应的光谱重建，显著减少了参数和计算量，同时在分布外数据上提升了性能，为自适应的计算成像提供了新思路。

Abstract: Humans learn in two complementary ways: a slow, cumulative process that
builds broad, general knowledge, and a fast, on-the-fly process that captures
specific experiences. Existing deep-unfolding methods for spectral compressive
imaging (SCI) mirror only the slow component-relying on heavy pre-training with
many unfolding stages-yet they lack the rapid adaptation needed to handle new
optical configurations. As a result, they falter on out-of-distribution
cameras, especially in bespoke spectral setups unseen during training. This
depth also incurs heavy computation and slow inference. To bridge this gap, we
introduce SlowFast-SCI, a dual-speed framework seamlessly integrated into any
deep unfolding network beyond SCI systems. During slow learning, we pre-train
or reuse a priors-based backbone and distill it via imaging guidance into a
compact fast-unfolding model. In the fast learning stage, lightweight
adaptation modules are embedded within each block and trained self-supervised
at test time via a dual-domain loss-without retraining the backbone. To the
best of our knowledge, SlowFast-SCI is the first test-time adaptation-driven
deep unfolding framework for efficient, self-adaptive spectral reconstruction.
Its dual-stage design unites offline robustness with on-the-fly per-sample
calibration-yielding over 70% reduction in parameters and FLOPs, up to 5.79 dB
PSNR improvement on out-of-distribution data, preserved cross-domain
adaptability, and a 4x faster adaptation speed. In addition, its modularity
integrates with any deep-unfolding network, paving the way for self-adaptive,
field-deployable imaging and expanded computational imaging modalities. Code
and models are available at https://github.com/XuanLu11/SlowFast-SCI.

</details>


### [24] [Seeing Culture: A Benchmark for Visual Reasoning and Grounding](https://arxiv.org/abs/2509.16517)
*Burak Satar,Zhixin Ma,Patrick A. Irawan,Wilfried A. Mulyawan,Jing Jiang,Ee-Peng Lim,Chong-Wah Ngo*

Main category: cs.CV

TL;DR: SCB是一个新基准测试，专注于文化推理，通过两阶段任务评估多模态视觉语言模型，揭示其在文化细微场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有文化数据集常缺乏文化推理能力且对许多文化代表性不足，SCB旨在填补这一空白，专注于文化推理，并覆盖常被忽视的东南亚文化。

Method: 引入Seeing Culture Benchmark（SCB），要求模型在两个阶段进行文化推理：1）通过多项选择视觉问答选择正确的视觉选项；2）分割相关文化文物作为推理证据。视觉选项分为三类：同国家、不同国家或混合组。

Result: SCB包含1,065张图像和3,178个问题（1,093个独特问题），涵盖7个东南亚国家的138种文化文物。评估显示VLMs在文化推理中存在视觉与空间定位的差距。

Conclusion: SCB基准测试揭示了多模态视觉语言模型在跨模态文化推理中的复杂性，并凸显了在文化细微场景中视觉推理与空间定位之间的差距，为未来文化推理领域的发展提供了重要指导。

Abstract: Multimodal vision-language models (VLMs) have made substantial progress in
various tasks that require a combined understanding of visual and textual
content, particularly in cultural understanding tasks, with the emergence of
new cultural datasets. However, these datasets frequently fall short of
providing cultural reasoning while underrepresenting many cultures. In this
paper, we introduce the Seeing Culture Benchmark (SCB), focusing on cultural
reasoning with a novel approach that requires VLMs to reason on culturally rich
images in two stages: i) selecting the correct visual option with
multiple-choice visual question answering (VQA), and ii) segmenting the
relevant cultural artifact as evidence of reasoning. Visual options in the
first stage are systematically organized into three types: those originating
from the same country, those from different countries, or a mixed group.
Notably, all options are derived from a singular category for each type.
Progression to the second stage occurs only after a correct visual option is
chosen. The SCB benchmark comprises 1,065 images that capture 138 cultural
artifacts across five categories from seven Southeast Asia countries, whose
diverse cultures are often overlooked, accompanied by 3,178 questions, of which
1,093 are unique and meticulously curated by human annotators. Our evaluation
of various VLMs reveals the complexities involved in cross-modal cultural
reasoning and highlights the disparity between visual reasoning and spatial
grounding in culturally nuanced scenarios. The SCB serves as a crucial
benchmark for identifying these shortcomings, thereby guiding future
developments in the field of cultural reasoning.
https://github.com/buraksatar/SeeingCulture

</details>


### [25] [FG-Attn: Leveraging Fine-Grained Sparsity In Diffusion Transformers](https://arxiv.org/abs/2509.16518)
*Sankeerth Durvasula,Kavya Sreedhar,Zain Moustafa,Suraj Kothawade,Ashish Gondimalla,Suvinay Subramanian,Narges Shahidi,Nandita Vijaykumar*

Main category: cs.CV

TL;DR: FG-Attn通过细粒度稀疏注意力优化视频扩散模型，显著提升计算效率，实现最高1.65X加速。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在生成视频时因长序列嵌入计算导致高延迟，现有块稀疏注意力未能充分利用注意力图的稀疏性。

Method: 提出FG-Attn，一种细粒度稀疏注意力机制，利用异步聚集加载操作优化GPU内存访问。

Result: 在单H100 GPU上，480p和720p的5秒视频生成分别实现平均1.55X和1.41X的加速。

Conclusion: FG-Attn通过细粒度稀疏注意力机制显著提升了长上下文扩散变换器的计算效率，实现了视频生成的平均1.55X（最高1.65X）加速。

Abstract: Generating realistic videos with diffusion transformers demands significant
computation, with attention layers the central bottleneck; even producing a
short clip requires running a transformer over a very long sequence of
embeddings, e.g., more than 30K embeddings for a 5-second video, incurring
significant latency. Prior work aims to mitigate this bottleneck by exploiting
sparsity in the attention layers to reduce computation. However, these works
typically rely on block-sparse attention, which skips score computation only
when all entries in a block of attention scores (corresponding to M queries and
M keys, with M = 64 typically) are zero. This coarse-granular skipping of
attention scores does not fully exploit sparsity in the attention map and
leaves room for improvement. In this work, we propose FG-Attn, a sparse
attention mechanism for long-context diffusion transformers that leverages
sparsity at a fine granularity. Unlike block-sparse attention, which skips
entire MxM blocks, our approach skips computations at the granularity of Mx1
slices of the attention map. Each slice is produced by query-key dot products
between a block of query vectors and a single key. To implement our proposed
sparse attention mechanism, we develop a new efficient bulk-load operation
called asynchronous-gather load. This load operation gathers a sparse set of
relevant key-value vectors from memory and arranges them into packed tiles in
the GPU's shared memory. Only a sparse set of keys relevant to those queries
are loaded into shared memory when computing attention for a block of queries,
in contrast to loading full blocks of key tokens in block-sparse attention. Our
fine-grained sparse attention, applied to video diffusion models, achieves an
average 1.55X (up to 1.65X) speedup for 5 second, 480p videos, and an average
1.41X (up to 1.49X) for 5 second, 720p videos on a single H100 GPU.

</details>


### [26] [PM25Vision: A Large-Scale Benchmark Dataset for Visual Estimation of Air Quality](https://arxiv.org/abs/2509.16519)
*Yang Han*

Main category: cs.CV

TL;DR: PM25V是最大、最全面的PM2.5街景图像数据集，空间精度达5公里，提供基线模型性能。


<details>
  <summary>Details</summary>
Motivation: 为了提供更准确、大规模的PM2.5浓度估计，填补现有数据集的规模与精度不足。

Method: 描述了数据收集、同步和清理流程，并提供了使用CNN和Transformer架构的基线模型性能。

Result: 数据集包含11,114张图像，匹配了3,261个AQI监测站11年的PM2.5读数，空间精度达到5公里。

Conclusion: PM25Vision（PM25V）是目前最大、最全面的数据集，用于从街景图像估计PM2.5浓度，其空间精度达到5公里，远超许多城市级数据集。

Abstract: We introduce PM25Vision (PM25V), the largest and most comprehensive dataset
to date for estimating air quality - specifically PM2.5 concentrations - from
street-level images. The dataset contains over 11,114 images matched with
timestamped and geolocated PM2.5 readings across 3,261 AQI monitoring stations
and 11 years, significantly exceeding the scale of previous benchmarks. The
spatial accuracy of this dataset has reached 5 kilometers, far exceeding the
city-level accuracy of many datasets. We describe the data collection,
synchronization, and cleaning pipelines, and provide baseline model
performances using CNN and transformer architectures. Our dataset is publicly
available.

</details>


### [27] [Lattice Boltzmann Model for Learning Real-World Pixel Dynamicity](https://arxiv.org/abs/2509.16527)
*Guangze Zheng,Shijie Lin,Haobo Zuo,Si Si,Ming-Shan Wang,Changhong Fu,Jia Pan*

Main category: cs.CV

TL;DR: 提出LBM模型，通过晶格碰撞和流过程学习像素动态性，高效适应视觉跟踪任务，在多个基准测试中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 学习现实世界像素动态性以进行视觉跟踪。

Method: LBM通过多层预测-更新网络获取目标像素的高维分布，估计像素位置和可见性。预测阶段在目标像素的空间邻域内制定晶格碰撞，并在时间视觉上下文中发展晶格流。更新阶段通过在线视觉表示修正像素分布。

Result: 在TAP-Vid和RoboTAP等现实世界点跟踪基准上的全面评估验证了LBM的效率。对TAO、BFT和OVT-B等大规模开放世界对象跟踪基准的通用评估进一步证明了LBM的现实实用性。

Conclusion: LBM展示了在在线和实时方式下的实际适用性，能够高效适应现实世界的视觉跟踪任务。

Abstract: This work proposes the Lattice Boltzmann Model (LBM) to learn real-world
pixel dynamicity for visual tracking. LBM decomposes visual representations
into dynamic pixel lattices and solves pixel motion states through
collision-streaming processes. Specifically, the high-dimensional distribution
of the target pixels is acquired through a multilayer predict-update network to
estimate the pixel positions and visibility. The predict stage formulates
lattice collisions among the spatial neighborhood of target pixels and develops
lattice streaming within the temporal visual context. The update stage
rectifies the pixel distributions with online visual representations. Compared
with existing methods, LBM demonstrates practical applicability in an online
and real-time manner, which can efficiently adapt to real-world visual tracking
tasks. Comprehensive evaluations of real-world point tracking benchmarks such
as TAP-Vid and RoboTAP validate LBM's efficiency. A general evaluation of
large-scale open-world object tracking benchmarks such as TAO, BFT, and OVT-B
further demonstrates LBM's real-world practicality.

</details>


### [28] [Advancing Reference-free Evaluation of Video Captions with Factual Analysis](https://arxiv.org/abs/2509.16538)
*Shubhashis Roy Dipta,Tz-Ying Wu,Subarna Tripathi*

Main category: cs.CV

TL;DR: 提出无参考且基于事实的视频字幕质量评估框架VC-Inspector，通过生成伪字幕训练多模态模型，实现跨域评估的优越性和通用性。


<details>
  <summary>Details</summary>
Motivation: 获取视频字幕的人工标注成本高昂且不切实际，现有模型在跨域评估中因依赖参考协议而表现不佳。

Method: 利用大型语言模型生成不同质量的伪字幕，基于监督数据训练多模态模型（如Qwen2.5-VL）作为评估器。

Result: VC-Inspector在VATEX-Eval数据集上表现出与人类判断更优的一致性，并可推广至图像字幕数据集。

Conclusion: VC-Inspector提供了一种可扩展且通用的解决方案，用于评估视频字幕的事实准确性，为多样化视频领域中更有效和客观的评估方法铺平了道路。

Abstract: Video captions offer concise snapshots of actors, objects, and actions within
a video, serving as valuable assets for applications such as question answering
and event localization. However, acquiring human annotations for video captions
is costly or even impractical, especially when dealing with diverse video
domains. Existing models trained on supervised datasets face challenges in
evaluating performance across different domains due to the reliance on
reference-based evaluation protocols, which necessitate ground truth captions.
This assumption is unrealistic for evaluating videos in the wild. To address
these limitations, we propose a reference-free evaluation framework that does
not require ground truth captions, focusing on factual grounding to ensure
accurate assessment of caption quality. We introduce VC-Inspector, a novel
caption quality evaluator that is both reference-free and factually grounded.
Utilizing large language models, we generate pseudo captions of varying quality
based on supervised data, which are subsequently used to train a multimodal
model (i.e., Qwen2.5-VL) as the evaluator. Our approach demonstrates superior
alignment with human judgments on the VATEX-Eval dataset, outperforming
existing methods. The performance also generalizes to image caption datasets,
Flickr8K-Expert and Flickr8K-CF, when viewing images as 1-frame videos.
Overall, VC-Inspector offers a scalable and generalizable solution for
evaluating the factual accuracy of video captions, paving the way for more
effective and objective assessment methodologies in diverse video domains.

</details>


### [29] [Efficient Rectified Flow for Image Fusion](https://arxiv.org/abs/2509.16549)
*Zirui Wang,Jiayi Zhang,Tianwei Guan,Yuhan Zhou,Xingyuan Li,Minjing Dong,Jinyuan Liu*

Main category: cs.CV

TL;DR: RFfusion是一种高效的一步扩散模型，通过Rectified Flow和定制VAE架构提升图像融合的推理效率和质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像融合领域取得显著进展，但复杂计算和冗余推理时间限制了其适用性。

Method: 提出RFfusion，将Rectified Flow引入图像融合任务以简化采样路径，实现一步采样；设计任务特定的变分自编码器（VAE）架构，将融合操作嵌入潜在空间以减少计算复杂度；采用两阶段训练策略解决VAE目标与图像融合需求之间的差异。

Result: 实验表明，RFfusion在推理速度和融合质量上均优于其他最先进方法。

Conclusion: RFfusion是一种基于Rectified Flow的高效一步扩散模型，用于图像融合，能够在保持高质量融合结果的同时显著提升推理效率。

Abstract: Image fusion is a fundamental and important task in computer vision, aiming
to combine complementary information from different modalities to fuse images.
In recent years, diffusion models have made significant developments in the
field of image fusion. However, diffusion models often require complex
computations and redundant inference time, which reduces the applicability of
these methods. To address this issue, we propose RFfusion, an efficient
one-step diffusion model for image fusion based on Rectified Flow. We
incorporate Rectified Flow into the image fusion task to straighten the
sampling path in the diffusion model, achieving one-step sampling without the
need for additional training, while still maintaining high-quality fusion
results. Furthermore, we propose a task-specific variational autoencoder (VAE)
architecture tailored for image fusion, where the fusion operation is embedded
within the latent space to further reduce computational complexity. To address
the inherent discrepancy between conventional reconstruction-oriented VAE
objectives and the requirements of image fusion, we introduce a two-stage
training strategy. This approach facilitates the effective learning and
integration of complementary information from multi-modal source images,
thereby enabling the model to retain fine-grained structural details while
significantly enhancing inference efficiency. Extensive experiments demonstrate
that our method outperforms other state-of-the-art methods in terms of both
inference speed and fusion quality. Code is available at
https://github.com/zirui0625/RFfusion.

</details>


### [30] [ST-GS: Vision-Based 3D Semantic Occupancy Prediction with Spatial-Temporal Gaussian Splatting](https://arxiv.org/abs/2509.16552)
*Xiaoyang Yan,Muleilan Pei,Shaojie Shen*

Main category: cs.CV

TL;DR: 提出了ST-GS框架，通过空间聚合和时间融合策略，提升了3D占用预测的空间交互和时间一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯的方法在多视角空间交互和多帧时间一致性方面存在不足。

Method: 开发了基于双模式注意力机制的引导式空间聚合策略和几何感知的时间融合方案。

Result: 在大规模nuScenes基准测试中表现优异，优于现有高斯方法。

Conclusion: 提出的ST-GS框架在3D占用预测中实现了最先进的性能，并显著提升了时间一致性。

Abstract: 3D occupancy prediction is critical for comprehensive scene understanding in
vision-centric autonomous driving. Recent advances have explored utilizing 3D
semantic Gaussians to model occupancy while reducing computational overhead,
but they remain constrained by insufficient multi-view spatial interaction and
limited multi-frame temporal consistency. To overcome these issues, in this
paper, we propose a novel Spatial-Temporal Gaussian Splatting (ST-GS) framework
to enhance both spatial and temporal modeling in existing Gaussian-based
pipelines. Specifically, we develop a guidance-informed spatial aggregation
strategy within a dual-mode attention mechanism to strengthen spatial
interaction in Gaussian representations. Furthermore, we introduce a
geometry-aware temporal fusion scheme that effectively leverages historical
context to improve temporal continuity in scene completion. Extensive
experiments on the large-scale nuScenes occupancy prediction benchmark showcase
that our proposed approach not only achieves state-of-the-art performance but
also delivers markedly better temporal consistency compared to existing
Gaussian-based methods.

</details>


### [31] [Person Identification from Egocentric Human-Object Interactions using 3D Hand Pose](https://arxiv.org/abs/2509.16557)
*Muhammad Hamza,Danish Hamid,Muhammad Tahir Akram*

Main category: cs.CV

TL;DR: I2S通过3D手部姿态分析实现高效用户识别，适用于AR安全关键系统。


<details>
  <summary>Details</summary>
Motivation: 提升AR个性化辅助技术在人机交互环境（如飞机驾驶舱、航空航天维护和手术）中的应用。

Method: I2S是一个多阶段框架，通过3D手部姿态分析进行HOIR和用户识别，包括手工特征提取、特征增强和语义分类。

Result: 最佳配置在双手机器操作数据集上达到97.52%的平均F1-score，模型大小小于4MB，推理时间0.1秒。

Conclusion: I2S框架在用户识别方面表现出色，平均F1-score达到97.52%，模型轻量且推理速度快，适合实时、设备端认证。

Abstract: Human-Object Interaction Recognition (HOIR) and user identification play a
crucial role in advancing augmented reality (AR)-based personalized assistive
technologies. These systems are increasingly being deployed in high-stakes,
human-centric environments such as aircraft cockpits, aerospace maintenance,
and surgical procedures. This research introduces I2S (Interact2Sign), a multi
stage framework designed for unobtrusive user identification through human
object interaction recognition, leveraging 3D hand pose analysis in egocentric
videos. I2S utilizes handcrafted features extracted from 3D hand poses and per
forms sequential feature augmentation: first identifying the object class,
followed by HOI recognition, and ultimately, user identification. A
comprehensive feature extraction and description process was carried out for 3D
hand poses, organizing the extracted features into semantically meaningful
categories: Spatial, Frequency, Kinematic, Orientation, and a novel descriptor
introduced in this work, the Inter-Hand Spatial Envelope (IHSE). Extensive
ablation studies were conducted to determine the most effective combination of
features. The optimal configuration achieved an impressive average F1-score of
97.52% for user identification, evaluated on a bimanual object manipulation
dataset derived from the ARCTIC and H2O datasets. I2S demonstrates
state-of-the-art performance while maintaining a lightweight model size of
under 4 MB and a fast inference time of 0.1 seconds. These characteristics make
the proposed framework highly suitable for real-time, on-device authentication
in security-critical, AR-based systems.

</details>


### [32] [Captioning for Text-Video Retrieval via Dual-Group Direct Preference Optimization](https://arxiv.org/abs/2509.16560)
*Ji Soo Lee,Byungoh Ko,Jaewon Cho,Howoong Lee,Jaewoon Byun,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: CaRe-DPO通过直接优化检索相关性得分生成细粒度字幕，提升文本-视频检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有字幕生成方法因通用性强且难以区分视觉相似视频，不适用于细粒度检索任务。

Method: 提出了CaRe-DPO框架，核心是双组直接偏好优化（DG-DPO）学习策略，并结合角色嵌入的MLLM检索模型。

Result: 实验表明CaRe-DPO有效利用辅助知识生成细粒度字幕，显著提升检索性能。

Conclusion: CaRe-DPO框架通过直接优化检索相关性得分来生成细粒度字幕，显著提升了检索性能。

Abstract: In text-video retrieval, auxiliary captions are often used to enhance video
understanding, bridging the gap between the modalities. While recent advances
in multi-modal large language models (MLLMs) have enabled strong zero-shot
caption generation, we observe that such captions tend to be generic and
indistinguishable across visually similar videos, limiting their utility for
fine-grained retrieval. Moreover, conventional captioning approaches are
typically evaluated using language generation metrics, such as BLEU, which are
not typically tailored for retrieval tasks that require making discriminative
distinctions between candidates. To address this, we propose
$\textbf{CaRe-DPO}$, a retrieval framework that directly optimizes caption
generation using retrieval relevance scores. At its core is Dual-Group Direct
Preference Optimization (DG-DPO), a novel learning strategy that supervises
captioning by modeling preferences across groups of distinct video and caption
pairs. In addition, we present an MLLM-based retrieval model that incorporates
role-embeddings to better distinguish between textual inputs with different
functional roles, such as an auxiliary caption and a text query. Through
extensive experiments, we demonstrate that CaRe-DPO significantly enhances
retrieval performance by effectively leveraging auxiliary knowledge to generate
fine-grained captions for retrieval. Code is available at
https://github.com/mlvlab/CaReDPO.

</details>


### [33] [V-CECE: Visual Counterfactual Explanations via Conceptual Edits](https://arxiv.org/abs/2509.16567)
*Nikolaos Spanos,Maria Lymperaiou,Giorgos Filandrianos,Konstantinos Thomas,Athanasios Voulodimos,Giorgos Stamou*

Main category: cs.CV

TL;DR: 无需训练的黑盒反事实生成框架，利用预训练扩散模型生成人类水平的解释，揭示神经网络与人类推理的差距。


<details>
  <summary>Details</summary>
Motivation: 现有黑盒反事实生成框架忽视语义内容，过度依赖训练，无法有效生成人类水平的解释。

Method: 利用预训练的图像编辑扩散模型，结合理论保证的最优编辑步骤，无需访问分类器内部机制，实现可解释的反事实生成过程。

Result: 实验表明，该框架在CNN、ViT和LVLM分类器上均能生成高质量的反事实解释，并通过人类评估验证了其有效性。

Conclusion: 论文提出的无需训练的即插即用黑盒反事实生成框架，通过理论保证的逐步编辑，能够生成人类水平的反事实解释，有效揭示了人类推理与神经网络行为之间的解释差距。

Abstract: Recent black-box counterfactual generation frameworks fail to take into
account the semantic content of the proposed edits, while relying heavily on
training to guide the generation process. We propose a novel, plug-and-play
black-box counterfactual generation framework, which suggests step-by-step
edits based on theoretical guarantees of optimal edits to produce human-level
counterfactual explanations with zero training. Our framework utilizes a
pre-trained image editing diffusion model, and operates without access to the
internals of the classifier, leading to an explainable counterfactual
generation process. Throughout our experimentation, we showcase the explanatory
gap between human reasoning and neural model behavior by utilizing both
Convolutional Neural Network (CNN), Vision Transformer (ViT) and Large Vision
Language Model (LVLM) classifiers, substantiated through a comprehensive human
evaluation.

</details>


### [34] [A Novel Metric for Detecting Memorization in Generative Models for Brain MRI Synthesis](https://arxiv.org/abs/2509.16582)
*Antonio Scardace,Lemuel Puglisi,Francesco Guarnera,Sebastiano Battiato,Daniele Ravì*

Main category: cs.CV

TL;DR: DeepSSIM是一种自监督度量方法，用于检测生成模型中的记忆现象，性能优于现有方法，适用于医学影像领域。


<details>
  <summary>Details</summary>
Motivation: 深度生成模型在医学影像中有广泛应用，但存在记忆敏感训练数据的风险，可能导致患者信息泄露。当前缺乏可扩展的方法来检测生成模型中的记忆现象。

Method: 提出DeepSSIM，通过训练将图像投影到学习嵌入空间，并强制嵌入之间的余弦相似度与图像空间中计算的地面真实SSIM分数匹配。训练过程中结合结构保持增强以捕获领域特定的解剖特征。

Result: 在合成脑MRI数据的案例研究中，DeepSSIM表现出色，F1分数比现有最佳方法平均提高52.03%。

Conclusion: DeepSSIM是一种新型的自监督度量方法，能够有效量化生成模型中的记忆现象，且在性能上显著优于现有最先进的方法。

Abstract: Deep generative models have emerged as a transformative tool in medical
imaging, offering substantial potential for synthetic data generation. However,
recent empirical studies highlight a critical vulnerability: these models can
memorize sensitive training data, posing significant risks of unauthorized
patient information disclosure. Detecting memorization in generative models
remains particularly challenging, necessitating scalable methods capable of
identifying training data leakage across large sets of generated samples. In
this work, we propose DeepSSIM, a novel self-supervised metric for quantifying
memorization in generative models. DeepSSIM is trained to: i) project images
into a learned embedding space and ii) force the cosine similarity between
embeddings to match the ground-truth SSIM (Structural Similarity Index) scores
computed in the image space. To capture domain-specific anatomical features,
training incorporates structure-preserving augmentations, allowing DeepSSIM to
estimate similarity reliably without requiring precise spatial alignment. We
evaluate DeepSSIM in a case study involving synthetic brain MRI data generated
by a Latent Diffusion Model (LDM) trained under memorization-prone conditions,
using 2,195 MRI scans from two publicly available datasets (IXI and CoRR).
Compared to state-of-the-art memorization metrics, DeepSSIM achieves superior
performance, improving F1 scores by an average of +52.03% over the best
existing method. Code and data of our approach are publicly available at the
following link: https://github.com/brAIn-science/DeepSSIM.

</details>


### [35] [SQS: Enhancing Sparse Perception Models via Query-based Splatting in Autonomous Driving](https://arxiv.org/abs/2509.16588)
*Haiming Zhang,Yiyao Zhu,Wending Zhou,Xu Yan,Yingjie Cai,Bingbing Liu,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: SQS是一种新型查询驱动的预训练方法，通过3D高斯表示和自监督溅射提升稀疏感知模型在自动驾驶任务中的性能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 稀疏感知模型（SPMs）虽然计算高效，但在自动驾驶中的性能仍有提升空间。SQS旨在通过预训练技术增强SPMs的细粒度上下文特征学习能力。

Method: SQS引入了一个插件模块，通过自监督溅射技术从稀疏查询中预测3D高斯表示，并在微调阶段通过查询交互机制将预训练查询与任务特定查询结合。

Result: 在自动驾驶基准测试中，SQS在占用预测和3D物体检测任务上显著优于现有预训练方法（占用预测提升1.3 mIoU，3D检测提升1.0 NDS）。

Conclusion: SQS通过预训练的3D高斯查询和自监督溅射技术，显著提升了稀疏感知模型在自动驾驶中的性能，尤其在占用预测和3D物体检测任务上表现优异。

Abstract: Sparse Perception Models (SPMs) adopt a query-driven paradigm that forgoes
explicit dense BEV or volumetric construction, enabling highly efficient
computation and accelerated inference. In this paper, we introduce SQS, a novel
query-based splatting pre-training specifically designed to advance SPMs in
autonomous driving. SQS introduces a plug-in module that predicts 3D Gaussian
representations from sparse queries during pre-training, leveraging
self-supervised splatting to learn fine-grained contextual features through the
reconstruction of multi-view images and depth maps. During fine-tuning, the
pre-trained Gaussian queries are seamlessly integrated into downstream networks
via query interaction mechanisms that explicitly connect pre-trained queries
with task-specific queries, effectively accommodating the diverse requirements
of occupancy prediction and 3D object detection. Extensive experiments on
autonomous driving benchmarks demonstrate that SQS delivers considerable
performance gains across multiple query-based 3D perception tasks, notably in
occupancy prediction and 3D object detection, outperforming prior
state-of-the-art pre-training approaches by a significant margin (i.e., +1.3
mIoU on occupancy prediction and +1.0 NDS on 3D detection).

</details>


### [36] [FakeChain: Exposing Shallow Cues in Multi-Step Deepfake Detection](https://arxiv.org/abs/2509.16602)
*Minji Heo,Simon S. Woo*

Main category: cs.CV

TL;DR: 多步深度伪造对检测模型构成挑战，FakeChain基准揭示检测性能依赖最后一步伪造类型，需考虑伪造序列。


<details>
  <summary>Details</summary>
Motivation: 多步或混合深度伪造对仅针对单步伪造训练的检测模型构成新兴技术挑战，需研究检测模型在此类复杂伪造下的行为。

Method: 引入FakeChain基准，包含1步、2步和3步伪造，使用五种代表性生成器合成，分析检测性能和频谱特性。

Result: 检测性能高度依赖最后一步伪造类型，F1分数下降高达58.83%，显示模型依赖最后阶段伪影而非累积痕迹。

Conclusion: 检测模型在处理多步深度伪造时表现出依赖最后一步伪造类型的局限性，强调了考虑伪造历史序列的重要性。

Abstract: Multi-step or hybrid deepfakes, created by sequentially applying different
deepfake creation methods such as Face-Swapping, GAN-based generation, and
Diffusion methods, can pose an emerging and unforseen technical challenge for
detection models trained on single-step forgeries. While prior studies have
mainly focused on detecting isolated single manipulation, little is known about
the detection model behavior under such compositional, hybrid, and complex
manipulation pipelines. In this work, we introduce \textbf{FakeChain}, a
large-scale benchmark comprising 1-, 2-, and 3-Step forgeries synthesized using
five state-of-the-art representative generators. Using this approach, we
analyze detection performance and spectral properties across hybrid
manipulation at different step, along with varying generator combinations and
quality settings. Surprisingly, our findings reveal that detection performance
highly depends on the final manipulation type, with F1-score dropping by up to
\textbf{58.83\%} when it differs from training distribution. This clearly
demonstrates that detectors rely on last-stage artifacts rather than cumulative
manipulation traces, limiting generalization. Such findings highlight the need
for detection models to explicitly consider manipulation history and sequences.
Our results highlight the importance of benchmarks such as FakeChain,
reflecting growing synthesis complexity and diversity in real-world scenarios.
Our sample code is available
here\footnote{https://github.com/minjihh/FakeChain}.

</details>


### [37] [Describe-to-Score: Text-Guided Efficient Image Complexity Assessment](https://arxiv.org/abs/2509.16609)
*Shipeng Liu,Zhonglin Zhang,Dengfeng Chen,Liang Zhao*

Main category: cs.CV

TL;DR: D2S框架通过视觉-文本融合提升图像复杂度评估，仅需视觉分支推理，高效且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像复杂度评估方法主要依赖视觉特征，忽略了高层语义信息，导致准确性和泛化能力受限。

Method: 提出了D2S（Describe-to-Score）框架，利用预训练的视觉语言模型生成图像描述，并通过特征对齐和熵分布对齐机制，将语义信息融入复杂度评估。

Result: 实验结果表明，D2S在IC9600数据集上优于现有方法，并在无参考图像质量评估（NR-IQA）基准上保持竞争力。

Conclusion: D2S框架通过融合视觉和文本语义特征，显著提升了图像复杂度评估的准确性和泛化能力，同时在推理阶段仅需视觉分支，确保了高效性。

Abstract: Accurately assessing image complexity (IC) is critical for computer vision,
yet most existing methods rely solely on visual features and often neglect
high-level semantic information, limiting their accuracy and generalization. We
introduce vision-text fusion for IC modeling. This approach integrates visual
and textual semantic features, increasing representational diversity. It also
reduces the complexity of the hypothesis space, which enhances both accuracy
and generalization in complexity assessment. We propose the D2S
(Describe-to-Score) framework, which generates image captions with a
pre-trained vision-language model. We propose the feature alignment and entropy
distribution alignment mechanisms, D2S guides semantic information to inform
complexity assessment while bridging the gap between vision and text
modalities. D2S utilizes multi-modal information during training but requires
only the vision branch during inference, thereby avoiding multi-modal
computational overhead and enabling efficient assessment. Experimental results
demonstrate that D2S outperforms existing methods on the IC9600 dataset and
maintains competitiveness on no-reference image quality assessment (NR-IQA)
benchmark, validating the effectiveness and efficiency of multi-modal fusion in
complexity-related tasks. Code is available at:
https://github.com/xauat-liushipeng/D2S

</details>


### [38] [Detection and Simulation of Urban Heat Islands Using a Fine-Tuned Geospatial Foundation Model](https://arxiv.org/abs/2509.16617)
*David Kreismann*

Main category: cs.CV

TL;DR: 研究利用地理空间基础模型预测城市地表温度，误差低且外推能力强，为城市热岛效应缓解提供新方法。


<details>
  <summary>Details</summary>
Motivation: 随着城市化和气候变化的加剧，城市热岛效应日益严重，传统机器学习模型和数据基础设施的预测准确性不足，尤其是在服务不足的地区。

Method: 研究微调了一个地理空间基础模型，用于预测未来气候情景下的城市地表温度，并通过模拟植被策略探索其对土地覆盖变化的响应。

Result: 微调模型实现了像素级降尺度误差低于1.74°C，并与地面真实数据模式一致。

Conclusion: 微调的地理空间基础模型在城市地表温度预测中表现出色，误差低于1.74°C，并具备高达3.62°C的外推能力。

Abstract: As urbanization and climate change progress, urban heat island effects are
becoming more frequent and severe. To formulate effective mitigation plans,
cities require detailed air temperature data. However, predictive analytics
methods based on conventional machine learning models and limited data
infrastructure often provide inaccurate predictions, especially in underserved
areas. In this context, geospatial foundation models trained on unstructured
global data demonstrate strong generalization and require minimal fine-tuning,
offering an alternative for predictions where traditional approaches are
limited. This study fine-tunes a geospatial foundation model to predict urban
land surface temperatures under future climate scenarios and explores its
response to land cover changes using simulated vegetation strategies. The
fine-tuned model achieved pixel-wise downscaling errors below 1.74 {\deg}C and
aligned with ground truth patterns, demonstrating an extrapolation capacity up
to 3.62 {\deg}C.

</details>


### [39] [Surgical-MambaLLM: Mamba2-enhanced Multimodal Large Language Model for VQLA in Robotic Surgery](https://arxiv.org/abs/2509.16618)
*Pengfei Hao,Hongqiu Wang,Shuaibo Li,Zhaohu Xing,Guang Yang,Kaishun Wu,Lei Zhu*

Main category: cs.CV

TL;DR: 提出Surgical-MambaLLM，结合Mamba2和LLM，通过CBMI模块和SIP扫描模式提升手术场景的视觉问题定位回答性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以建立文本与视觉细节间的复杂依赖关系，且难以感知手术场景的空间信息，因此需要一种新方法来提升LLM对手术图像的理解。

Method: 提出了Cross-modal Bidirectional Mamba2 Integration (CBMI)模块和Surgical Instrument Perception (SIP)扫描模式，以增强多模态融合和空间信息感知。

Result: 在EndoVis17-VQLA和EndoVis18-VQLA数据集上的实验表明，Surgical-MambaLLM优于现有最先进方法。

Conclusion: Surgical-MambaLLM模型通过结合Mamba2和LLM，在手术领域的视觉问题定位回答任务中表现出色，显著提升了性能。

Abstract: In recent years, Visual Question Localized-Answering in robotic surgery
(Surgical-VQLA) has gained significant attention for its potential to assist
medical students and junior doctors in understanding surgical scenes. Recently,
the rapid development of Large Language Models (LLMs) has provided more
promising solutions for this task. However, current methods struggle to
establish complex dependencies between text and visual details, and have
difficulty perceiving the spatial information of surgical scenes. To address
these challenges, we propose a novel method, Surgical-MambaLLM, which is the
first to combine Mamba2 with LLM in the surgical domain, that leverages
Mamba2's ability to effectively capture cross-modal dependencies and perceive
spatial information in surgical scenes, thereby enhancing the LLMs'
understanding of surgical images. Specifically, we propose the Cross-modal
Bidirectional Mamba2 Integration (CBMI) module to leverage Mamba2 for effective
multimodal fusion, with its cross-modal integration capabilities. Additionally,
tailored to the geometric characteristics of surgical scenes, we design the
Surgical Instrument Perception (SIP) scanning mode for Mamba2 to scan the
surgical images, enhancing the model's spatial understanding of the surgical
scene. Extensive experiments demonstrate that our Surgical-MambaLLM model
outperforms the state-of-the-art methods on the EndoVis17-VQLA and
EndoVis18-VQLA datasets, significantly improving the performance of the
Surgical-VQLA task.

</details>


### [40] [CGTGait: Collaborative Graph and Transformer for Gait Emotion Recognition](https://arxiv.org/abs/2509.16623)
*Junjie Zhou,Haijun Xiong,Junhao Lu,Ziyu Lin,Bin Feng*

Main category: cs.CV

TL;DR: CGTGait结合图卷积和Transformer，通过CGT块和BCSF模块提升步态情感识别性能，同时大幅降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注空间和局部时间运动信息，未能捕捉长程时间表示，因此需要一种更有效的方法来提取判别性时空特征。

Method: 提出CGTGait框架，包含多个CGT块，每个块使用图卷积捕捉空间拓扑和Transformer建模全局时间依赖，并引入BCSF模块聚合姿态和运动特征。

Result: 在两个数据集上实现了最先进或竞争性性能，计算复杂度降低了82.2%（仅需0.34G FLOPs）。

Conclusion: CGTGait框架通过结合图卷积和Transformer，在步态情感识别任务中实现了卓越的性能，同时显著降低了计算复杂度。

Abstract: Skeleton-based gait emotion recognition has received significant attention
due to its wide-ranging applications. However, existing methods primarily focus
on extracting spatial and local temporal motion information, failing to capture
long-range temporal representations. In this paper, we propose
\textbf{CGTGait}, a novel framework that collaboratively integrates graph
convolution and transformers to extract discriminative spatiotemporal features
for gait emotion recognition. Specifically, CGTGait consists of multiple CGT
blocks, where each block employs graph convolution to capture frame-level
spatial topology and the transformer to model global temporal dependencies.
Additionally, we introduce a Bidirectional Cross-Stream Fusion (BCSF) module to
effectively aggregate posture and motion spatiotemporal features, facilitating
the exchange of complementary information between the two streams. We evaluate
our method on two widely used datasets, Emotion-Gait and ELMD, demonstrating
that our CGTGait achieves state-of-the-art or at least competitive performance
while reducing computational complexity by approximately \textbf{82.2\%} (only
requiring 0.34G FLOPs) during testing. Code is available at
\small{https://github.com/githubzjj1/CGTGait.}

</details>


### [41] [Enhancing Scientific Visual Question Answering via Vision-Caption aware Supervised Fine-Tuning](https://arxiv.org/abs/2509.16628)
*Janak Kapuriya,Anwar Shaikh,Arnav Goel,Medha Hira,Apoorv Singh,Jay Saraf,Sanjana,Vaibhav Nauriyal,Avinash Anand,Zhengkui Wang,Rajiv Ratn Shah*

Main category: cs.CV

TL;DR: VCASFT通过图像描述和指令调优提升小型视觉语言模型在科学VQA任务中的表现，并在低资源语言数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提升小型视觉语言模型在科学视觉问答任务中的表现，并解决低资源语言数据集的不足。

Method: VCASFT利用图像描述作为零样本提示，结合问答对和指令调优模型，显著提升性能。

Result: VCASFT在ScienceQA和HiSciVQA数据集上表现出色，特别是在低资源语言环境下。

Conclusion: VCASFT是一种有效的学习范式，能够显著提升小型视觉语言模型在科学视觉问答任务中的表现，并通过开放源代码和数据集推动研究领域的发展。

Abstract: In this study, we introduce Vision-Caption aware Supervised FineTuning
(VCASFT), a novel learning paradigm designed to enhance the performance of
smaller Vision Language Models(VLMs) on scientific visual question
answering(VQA) tasks. VCASFT leverages image captions as zero-shot prompts
alongside question-answer pairs and instruction-tunes models to yield
significant performance improvements. To comprehensively evaluate VCASFT, we
benchmark it on ScienceQA, which consists of questions across diverse
languages, subjects, and fields, demonstrating its adaptability and
effectiveness in a variety of educational contexts. Additionally, to further
demonstrate the effectiveness of this technique on lowresource languages, we
developed HiSciVQA, a dataset comprising 2,245 high-quality, hand-annotated
Hindi multimodal Q&A pairs. This dataset addresses the critical need for
low-resource language Q&A datasets and serves as a foundation for testing
VCASFT. Additionally, we introduce a novel LLM-based evaluation scheme to
evaluate VLMs on HiSciVQA which offers deeper insights into model effectiveness
surpassing traditional n-gram matching accuracy metrics. We are committed to
advancing the field by open-sourcing all code files and the HiSciVQA dataset
for the research community.

</details>


### [42] [Follow-Your-Emoji-Faster: Towards Efficient, Fine-Controllable, and Expressive Freestyle Portrait Animation](https://arxiv.org/abs/2509.16630)
*Yue Ma,Zexuan Yan,Hongyu Liu,Hongfa Wang,Heng Pan,Yingqing He,Junkun Yuan,Ailing Zeng,Chengfei Cai,Heung-Yeung Shum,Zhifeng Li,Wei Liu,Linfeng Zhang,Qifeng Chen*

Main category: cs.CV

TL;DR: 提出Follow-Your-Emoji-Faster框架，通过增强Stable Diffusion和优化策略，高效生成高质量、可控的肖像动画。


<details>
  <summary>Details</summary>
Motivation: 解决自由风格肖像动画中身份保留、表情准确重定向、长时时间一致性和生成效率的核心挑战。

Method: 增强Stable Diffusion，引入表达感知的地标作为显式运动信号和细粒度面部损失，采用渐进生成策略和泰勒插值缓存。

Result: 在EmojiBench++上表现出卓越的动画质量和可控性，实现了2.6倍的无损加速。

Conclusion: Follow-Your-Emoji-Faster框架通过结合表达感知的地标和细粒度面部损失，成功解决了身份保留和表情准确重定向的挑战，同时通过渐进生成策略和泰勒插值缓存实现了高效稳定的长时动画生成。

Abstract: We present Follow-Your-Emoji-Faster, an efficient diffusion-based framework
for freestyle portrait animation driven by facial landmarks. The main
challenges in this task are preserving the identity of the reference portrait,
accurately transferring target expressions, and maintaining long-term temporal
consistency while ensuring generation efficiency. To address identity
preservation and accurate expression retargeting, we enhance Stable Diffusion
with two key components: a expression-aware landmarks as explicit motion
signals, which improve motion alignment, support exaggerated expressions, and
reduce identity leakage; and a fine-grained facial loss that leverages both
expression and facial masks to better capture subtle expressions and faithfully
preserve the reference appearance. With these components, our model supports
controllable and expressive animation across diverse portrait types, including
real faces, cartoons, sculptures, and animals. However, diffusion-based
frameworks typically struggle to efficiently generate long-term stable
animation results, which remains a core challenge in this task. To address
this, we propose a progressive generation strategy for stable long-term
animation, and introduce a Taylor-interpolated cache, achieving a 2.6X lossless
acceleration. These two strategies ensure that our method produces high-quality
results efficiently, making it user-friendly and accessible. Finally, we
introduce EmojiBench++, a more comprehensive benchmark comprising diverse
portraits, driving videos, and landmark sequences. Extensive evaluations on
EmojiBench++ demonstrate that Follow-Your-Emoji-Faster achieves superior
performance in both animation quality and controllability. The code, training
dataset and benchmark will be found in https://follow-your-emoji.github.io/.

</details>


### [43] [DA-Font: Few-Shot Font Generation via Dual-Attention Hybrid Integration](https://arxiv.org/abs/2509.16632)
*Weiran Chen,Guiqian Zhu,Ying Li,Yi Ji,Chunping Liu*

Main category: cs.CV

TL;DR: DA-Font通过双注意力模块和新型损失函数，提升了少样本字体生成的质量，解决了现有方法的缺陷。


<details>
  <summary>Details</summary>
Motivation: 解决现有少样本字体生成方法在字体样式多样性和复杂性下产生的笔画错误、伪影和模糊等问题。

Method: 提出了DA-Font框架，包含双注意力混合模块（DAHM），其中组件注意力块和关系注意力块协同工作，辅以角点一致性损失和弹性网格特征损失。

Result: DA-Font在多种字体样式和字符上表现优于现有方法，增强了结构完整性和局部保真度。

Conclusion: DA-Font通过引入双注意力混合模块（DAHM）和两种新的损失函数，显著提升了少样本字体生成的结构完整性和局部保真度，实验证明其优于现有方法。

Abstract: Few-shot font generation aims to create new fonts with a limited number of
glyph references. It can be used to significantly reduce the labor cost of
manual font design. However, due to the variety and complexity of font styles,
the results generated by existing methods often suffer from visible defects,
such as stroke errors, artifacts and blurriness. To address these issues, we
propose DA-Font, a novel framework which integrates a Dual-Attention Hybrid
Module (DAHM). Specifically, we introduce two synergistic attention blocks: the
component attention block that leverages component information from content
images to guide the style transfer process, and the relation attention block
that further refines spatial relationships through interacting the content
feature with both original and stylized component-wise representations. These
two blocks collaborate to preserve accurate character shapes and stylistic
textures. Moreover, we also design a corner consistency loss and an elastic
mesh feature loss to better improve geometric alignment. Extensive experiments
show that our DA-Font outperforms the state-of-the-art methods across diverse
font styles and characters, demonstrating its effectiveness in enhancing
structural integrity and local fidelity. The source code can be found at
\href{https://github.com/wrchen2001/DA-Font}{\textit{https://github.com/wrchen2001/DA-Font}}.

</details>


### [44] [When Big Models Train Small Ones: Label-Free Model Parity Alignment for Efficient Visual Question Answering using Small VLMs](https://arxiv.org/abs/2509.16633)
*Abhirama Subramanyam Penamakuri,Navlika Singh,Piyush Arora,Anand Mishra*

Main category: cs.CV

TL;DR: MPA框架通过知识转移和优化训练，有效提升小型视觉语言模型性能，缩小与大型模型的差距。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（L-VLMs）计算成本高，小型模型（S-VLMs）效率高但性能差距大，需一种方法在保持效率的同时提升性能。

Method: MPA采用基于对等性的策略方法，精确识别S-VLMs与L-VLMs之间的知识差异，并仅针对这些差异进行优化训练。

Result: MPA在四个VQA基准测试中（TextVQA、ST-VQA、ChartQA、OKVQA）均显著提升了S-VLMs的性能。

Conclusion: MPA框架通过系统性方法显著缩小了S-VLMs与L-VLMs的性能差距，同时保持了计算效率，为资源受限场景提供了实用解决方案。

Abstract: Large Vision-Language Models (L-VLMs) have demonstrated remarkable
performance in various vision and language tasks, including visual question
answering (VQA). However, their high computational cost makes them impractical
for resource-constrained settings and inference-heavy applications. In
contrast, Small Vision-Language Models (S-VLMs) offer efficiency but suffer
from a significant performance gap compared to their larger counterparts. In
this work, we introduce the Model Parity Aligner (MPA), a novel framework
designed to systematically improve S-VLMs by leveraging unlabeled images and
effective knowledge transfer from L-VLMs. Instead of traditional knowledge
distillation methods that rely on labeled training data, MPA employs a
strategic parity-based approach that precisely identifies the knowledge
disparities between S-VLMs and L-VLMs, and optimizes training by targeting only
these disparities. We conduct extensive experiments on four diverse VQA
benchmarks, namely TextVQA, ST-VQA, ChartQA, and OKVQA, each of which requires
specialized reasoning capabilities such as text recognition, chart
interpretation, and commonsense and factual understanding. Our results
demonstrate that MPA consistently enhances the performance of S-VLMs on all
benchmarks, reducing the performance gap while maintaining computational
efficiency. We make our code publicly available.

</details>


### [45] [Towards Anytime Retrieval: A Benchmark for Anytime Person Re-Identification](https://arxiv.org/abs/2509.16635)
*Xulin Li,Yan Lu,Bin Liu,Jiaze Li,Qinhong Yang,Tao Gong,Qi Chu,Mang Ye,Nenghai Yu*

Main category: cs.CV

TL;DR: 论文提出AT-ReID任务及数据集AT-USTC，并设计Uni-AT模型解决多场景检索问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有ReID任务和数据集受限于特定时间和场景，无法满足实际应用中全天候检索的需求，因此提出了Anytime Person Re-identification（AT-ReID）任务及其数据集AT-USTC。

Method: 论文提出了一种统一模型Uni-AT，包含多场景ReID框架（MS-ReID）、属性专家混合模块（MoAE）和分层动态加权策略（HDW），用于学习场景特定特征、减轻场景间干扰并确保跨场景的平衡训练。

Result: 实验结果表明，Uni-AT模型在所有场景中均取得了令人满意的结果，并展现出优异的泛化能力。

Conclusion: 论文提出了一种名为Uni-AT的统一模型，通过多场景ReID框架、MoAE模块和HDW策略，成功解决了AT-ReID问题，并在实验中表现出优异的泛化能力。

Abstract: In real applications, person re-identification (ReID) is expected to retrieve
the target person at any time, including both daytime and nighttime, ranging
from short-term to long-term. However, existing ReID tasks and datasets can not
meet this requirement, as they are constrained by available time and only
provide training and evaluation for specific scenarios. Therefore, we
investigate a new task called Anytime Person Re-identification (AT-ReID), which
aims to achieve effective retrieval in multiple scenarios based on variations
in time. To address the AT-ReID problem, we collect the first large-scale
dataset, AT-USTC, which contains 403k images of individuals wearing multiple
clothes captured by RGB and IR cameras. Our data collection spans 21 months,
and 270 volunteers were photographed on average 29.1 times across different
dates or scenes, 4-15 times more than current datasets, providing conditions
for follow-up investigations in AT-ReID. Further, to tackle the new challenge
of multi-scenario retrieval, we propose a unified model named Uni-AT, which
comprises a multi-scenario ReID (MS-ReID) framework for scenario-specific
features learning, a Mixture-of-Attribute-Experts (MoAE) module to alleviate
inter-scenario interference, and a Hierarchical Dynamic Weighting (HDW)
strategy to ensure balanced training across all scenarios. Extensive
experiments show that our model leads to satisfactory results and exhibits
excellent generalization to all scenarios.

</details>


### [46] [Unlocking Hidden Potential in Point Cloud Networks with Attention-Guided Grouping-Feature Coordination](https://arxiv.org/abs/2509.16639)
*Shangzhuo Xie,Qianqian Yang*

Main category: cs.CV

TL;DR: 提出GF-Core模块和自监督预训练策略，显著提升点云分析性能，保持架构简洁。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注新颖的结构设计，而传统点云架构的潜力未得到充分利用，通过策略性模块集成而非结构修改可释放显著性能提升。

Method: 提出了Grouping-Feature Coordination Module (GF-Core)，一个轻量级可分离组件，同时调节分组层和特征提取层，以实现更细致的特征聚合，并引入了针对点云输入的自监督预训练策略。

Result: 在ModelNet40数据集上达到94.0%的准确率，与先进框架性能相当；在ScanObjectNN数据集的三个变体上分别提升了2.96%、6.34%和6.32%。

Conclusion: 通过轻量级的GF-Core模块和自监督预训练策略，该方法在保持架构简洁的同时，显著提升了点云分析的性能，与先进框架相媲美。

Abstract: Point cloud analysis has evolved with diverse network architectures, while
existing works predominantly focus on introducing novel structural designs.
However, conventional point-based architectures - processing raw points through
sequential sampling, grouping, and feature extraction layers - demonstrate
underutilized potential. We notice that substantial performance gains can be
unlocked through strategic module integration rather than structural
modifications. In this paper, we propose the Grouping-Feature Coordination
Module (GF-Core), a lightweight separable component that simultaneously
regulates both grouping layer and feature extraction layer to enable more
nuanced feature aggregation. Besides, we introduce a self-supervised
pretraining strategy specifically tailored for point-based inputs to enhance
model robustness in complex point cloud analysis scenarios. On ModelNet40
dataset, our method elevates baseline networks to 94.0% accuracy, matching
advanced frameworks' performance while preserving architectural simplicity. On
three variants of the ScanObjectNN dataset, we obtain improvements of 2.96%,
6.34%, and 6.32% respectively.

</details>


### [47] [ADVEDM:Fine-grained Adversarial Attack against VLM-based Embodied Agents](https://arxiv.org/abs/2509.16645)
*Yichen Wang,Hangtao Zhang,Hewen Pan,Ziqi Zhou,Xianlong Wang,Peijin Guo,Lulu Xue,Shengshan Hu,Minghui Li,Leo Yu Zhang*

Main category: cs.CV

TL;DR: ADVEDM是一种针对VLM的精细对抗攻击框架，通过修改关键对象感知保持其余语义，有效输出错误决策，实验证明其攻击性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗攻击要么依赖不切实际的强假设（需完全了解受害VLM），要么因破坏过多语义信息导致感知与任务上下文不匹配，输出无效结果。

Method: 提出了ADVEDM框架，设计了两种变体ADVEDM-R和ADVEDM-A，分别从图像中移除特定对象的语义和向图像中添加新对象的语义。

Result: 在通用场景和EDM任务中的实验结果表明，ADVEDM具有精细控制能力和出色的攻击性能。

Conclusion: ADVEDM框架通过精细修改VLM对关键对象的感知，有效减少了与任务上下文的冲突，使VLM输出有效但错误的决策，从而在物理世界中构成更大的安全威胁。

Abstract: Vision-Language Models (VLMs), with their strong reasoning and planning
capabilities, are widely used in embodied decision-making (EDM) tasks in
embodied agents, such as autonomous driving and robotic manipulation. Recent
research has increasingly explored adversarial attacks on VLMs to reveal their
vulnerabilities. However, these attacks either rely on overly strong
assumptions, requiring full knowledge of the victim VLM, which is impractical
for attacking VLM-based agents, or exhibit limited effectiveness. The latter
stems from disrupting most semantic information in the image, which leads to a
misalignment between the perception and the task context defined by system
prompts. This inconsistency interrupts the VLM's reasoning process, resulting
in invalid outputs that fail to affect interactions in the physical world. To
this end, we propose a fine-grained adversarial attack framework, ADVEDM, which
modifies the VLM's perception of only a few key objects while preserving the
semantics of the remaining regions. This attack effectively reduces conflicts
with the task context, making VLMs output valid but incorrect decisions and
affecting the actions of agents, thus posing a more substantial safety threat
in the physical world. We design two variants of based on this framework,
ADVEDM-R and ADVEDM-A, which respectively remove the semantics of a specific
object from the image and add the semantics of a new object into the image. The
experimental results in both general scenarios and EDM tasks demonstrate
fine-grained control and excellent attack performance.

</details>


### [48] [Are VLMs Ready for Lane Topology Awareness in Autonomous Driving?](https://arxiv.org/abs/2509.16654)
*Xin Chen,Jia He,Maozheng Li,Dongliang Xu,Tianyu Wang,Yixiao Chen,Zhixin Lin,Yue Yao*

Main category: cs.CV

TL;DR: 研究发现当前视觉语言模型在道路拓扑理解任务中表现不佳，尤其是开源模型。模型能力与规模、推理标记长度和示例数量正相关。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态推理中取得显著进展，但其在自动驾驶中的应用仍有限，尤其是道路拓扑理解这一关键能力未得到充分研究。

Method: 通过将多视角图像投影到统一的平面坐标系并融合为鸟瞰图（BEV）车道线，设计了四个拓扑相关的诊断VQA任务，系统评估VLMs在道路拓扑理解中的能力。

Result: 前沿闭源模型（如GPT-4o）在某些任务中表现较好，但在时间性问题（如向量分类任务）上准确率仅为67.8%。开源模型（即使是30B规模）表现更差，表明空间推理是当前VLMs的主要瓶颈。

Conclusion: 当前视觉语言模型（VLMs）在道路拓扑理解方面存在显著瓶颈，尤其是开源模型表现较差。模型能力与模型规模、推理标记长度和示例数量呈正相关，为未来研究提供了方向。

Abstract: Vision-Language Models (VLMs) have recently shown remarkable progress in
multimodal reasoning, yet their applications in autonomous driving remain
limited. In particular, the ability to understand road topology, a key
requirement for safe navigation, has received relatively little attention.
While some recent works have begun to explore VLMs in driving contexts, their
performance on topology reasoning is far from satisfactory. In this work, we
systematically evaluate VLMs' capabilities in road topology understanding.
Specifically, multi-view images are projected into unified ground-plane
coordinate system and fused into bird's-eye-view (BEV) lanes. Based on these
BEV lanes, we formulate four topology-related diagnostic VQA tasks, which
together capture essential components of spatial topology reasoning. Through
extensive evaluation, we find that while frontier closed-source models (e.g.,
GPT-4o) achieve relatively high accuracy in some tasks, they still fail in some
temporal questions that humans can answer (e.g., GPT-4o achieve only 67.8% in
vector, a two-class classification problem). Furthermore, we find open-source
VLMs, even at 30B scale, struggle significantly. These results indicate that
spatial reasoning remains a fundamental bottleneck for current VLMs. We also
find that the model's capability is positively correlated with model size,
length of reasoning tokens and shots provided as examples, showing direction
for future research.

</details>


### [49] [MedCutMix: A Data-Centric Approach to Improve Radiology Vision-Language Pre-training with Disease Awareness](https://arxiv.org/abs/2509.16673)
*Sinuo Wang,Yutong Xie,Yuyuan Liu,Qi Wu*

Main category: cs.CV

TL;DR: MedCutMix 是一种新型多模态数据增强方法，通过诊断句子与图像的跨注意力混合，显著提升了放射学 VLP 的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言预训练（VLP）依赖图像-文本数据集，但隐私问题和配对标注的高成本带来了挑战。现有数据增强方法在医学数据中多样性不足，难以捕捉复杂变化。

Method: MedCutMix 在医学报告中进行诊断句子 CutMix，并通过诊断句子与医学图像之间的跨注意力引导成像模态内的注意力流形混合。

Result: MedCutMix 在四个放射学诊断数据集上超越了先前的方法，证明了其有效性。

Conclusion: MedCutMix 是一种有效的多模态疾病中心数据增强方法，显著提升了放射学视觉语言预训练（VLP）的性能和泛化能力。

Abstract: Vision-Language Pre-training (VLP) is drawing increasing interest for its
ability to minimize manual annotation requirements while enhancing semantic
understanding in downstream tasks. However, its reliance on image-text datasets
poses challenges due to privacy concerns and the high cost of obtaining paired
annotations. Data augmentation emerges as a viable strategy to address this
issue, yet existing methods often fall short of capturing the subtle and
complex variations in medical data due to limited diversity. To this end, we
propose MedCutMix, a novel multi-modal disease-centric data augmentation
method. MedCutMix performs diagnostic sentence CutMix within medical reports
and establishes the cross-attention between the diagnostic sentence and medical
image to guide attentive manifold mix within the imaging modality. Our approach
surpasses previous methods across four downstream radiology diagnosis datasets,
highlighting its effectiveness in enhancing performance and generalizability in
radiology VLP.

</details>


### [50] [FitPro: A Zero-Shot Framework for Interactive Text-based Pedestrian Retrieval in Open World](https://arxiv.org/abs/2509.16674)
*Zengli Luo,Canlong Zhang,Xiaochun Lu,Zhixin Li*

Main category: cs.CV

TL;DR: FitPro是一个开放世界交互式零样本TPR框架，通过FCD、ISM和QHR提升语义理解和跨场景适应性，实验证明其性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在开放世界场景下的交互检索中面临模型泛化能力不足和语义理解不充分的问题，FitPro旨在解决这些挑战。

Method: FitPro包含三个关键组件：FCD（特征对比解码）用于生成高质量结构化行人描述，ISM（增量语义挖掘）构建多视角观察下的全局语义表示，QHR（查询感知分层检索）动态优化检索流程以适应多模态和多视角输入。

Result: 在五个公共数据集和两种评估协议上的广泛实验表明，FitPro显著优于现有方法。

Conclusion: FitPro通过FCD、ISM和QHR三个创新组件，显著提升了开放世界交互式零样本TPR的性能，克服了现有方法在泛化和语义建模上的限制，为实际应用铺平了道路。

Abstract: Text-based Pedestrian Retrieval (TPR) aims to retrieve specific target
pedestrians in visual scenes according to natural language descriptions.
Although existing methods have achieved progress under constrained settings,
interactive retrieval in the open-world scenario still suffers from limited
model generalization and insufficient semantic understanding. To address these
challenges, we propose FitPro, an open-world interactive zero-shot TPR
framework with enhanced semantic comprehension and cross-scene adaptability.
FitPro has three innovative components: Feature Contrastive Decoding (FCD),
Incremental Semantic Mining (ISM), and Query-aware Hierarchical Retrieval
(QHR). The FCD integrates prompt-guided contrastive decoding to generate
high-quality structured pedestrian descriptions from denoised images,
effectively alleviating semantic drift in zero-shot scenarios. The ISM
constructs holistic pedestrian representations from multi-view observations to
achieve global semantic modeling in multi-turn interactions,thereby improving
robustness against viewpoint shifts and fine-grained variations in
descriptions. The QHR dynamically optimizes the retrieval pipeline according to
query types, enabling efficient adaptation to multi-modal and multi-view
inputs. Extensive experiments on five public datasets and two evaluation
protocols demonstrate that FitPro significantly overcomes the generalization
limitations and semantic modeling constraints of existing methods in
interactive retrieval, paving the way for practical deployment. The code and
data will be released at https://github.com/
lilo4096/FitPro-Interactive-Person-Retrieval.

</details>


### [51] [Segment-to-Act: Label-Noise-Robust Action-Prompted Video Segmentation Towards Embodied Intelligence](https://arxiv.org/abs/2509.16677)
*Wenxin Li,Kunyu Peng,Di Wen,Ruiping Liu,Mengfei Duan,Kai Luo,Kailun Yang*

Main category: cs.CV

TL;DR: 研究首次探索动作视频对象分割中的标签噪声问题，提出PMHM机制并建立ActiSeg-NL基准，分析不同噪声类型对模型的影响。


<details>
  <summary>Details</summary>
Motivation: 动作视频对象分割依赖大规模标注和提示，但存在成本高、不一致和多模态噪声问题，目前尚未有研究解决此问题。

Method: 提出Parallel Mask Head Mechanism (PMHM)处理掩码标注噪声，并构建ActiSeg-NL基准，适用六种标签噪声学习策略。

Result: PMHM有效处理掩码噪声，不同学习策略在噪声下表现各异，部分策略在保持前景准确性的同时牺牲背景精度。

Conclusion: 本研究通过引入PMHM机制和建立ActiSeg-NL基准，为动作视频对象分割任务中的标签噪声问题提供了解决方案和评估标准，代码和基准将公开。

Abstract: Embodied intelligence relies on accurately segmenting objects actively
involved in interactions. Action-based video object segmentation addresses this
by linking segmentation with action semantics, but it depends on large-scale
annotations and prompts that are costly, inconsistent, and prone to multimodal
noise such as imprecise masks and referential ambiguity. To date, this
challenge remains unexplored. In this work, we take the first step by studying
action-based video object segmentation under label noise, focusing on two
sources: textual prompt noise (category flips and within-category noun
substitutions) and mask annotation noise (perturbed object boundaries to mimic
imprecise supervision). Our contributions are threefold. First, we introduce
two types of label noises for the action-based video object segmentation task.
Second, we build up the first action-based video object segmentation under a
label noise benchmark ActiSeg-NL and adapt six label-noise learning strategies
to this setting, and establish protocols for evaluating them under textual,
boundary, and mixed noise. Third, we provide a comprehensive analysis linking
noise types to failure modes and robustness gains, and we introduce a Parallel
Mask Head Mechanism (PMHM) to address mask annotation noise. Qualitative
evaluations further reveal characteristic failure modes, including boundary
leakage and mislocalization under boundary perturbations, as well as occasional
identity substitutions under textual flips. Our comparative analysis reveals
that different learning strategies exhibit distinct robustness profiles,
governed by a foreground-background trade-off where some achieve balanced
performance while others prioritize foreground accuracy at the cost of
background precision. The established benchmark and source code will be made
publicly available at https://github.com/mylwx/ActiSeg-NL.

</details>


### [52] [IPF-RDA: An Information-Preserving Framework for Robust Data Augmentation](https://arxiv.org/abs/2509.16678)
*Suorong Yang,Hongchao Yang,Suhan Guo,Furao Shen,Jian Zhao*

Main category: cs.CV

TL;DR: IPF-RDA 是一种信息保留框架，通过类判别信息估计和信息保留方案，提升数据增强的鲁棒性，实验证明其能显著改进多种数据增强方法的性能。


<details>
  <summary>Details</summary>
Motivation: 数据增强虽然能提升深度模型的泛化性能，但可能引入分布偏移和噪声，限制深度网络的潜力并降低性能。因此，需要一种方法来增强数据增强的鲁棒性。

Method: IPF-RDA 结合了（i）一种新的类判别信息估计算法，用于识别对数据增强操作最敏感的点及其重要性评分；（ii）一种新的信息保留方案，自适应地保留增强样本中的关键信息并确保数据多样性。

Result: 实验表明，IPF-RDA 能持续提升多种常用数据增强方法的性能，并在多个数据集（如 CIFAR-10、CIFAR-100、Tiny-ImageNet 等）上验证了其有效性。

Conclusion: IPF-RDA 是一种简单但有效的信息保留框架，能够显著提升多种数据增强方法的鲁棒性和性能，并在多个数据集和深度模型上验证了其性能和可扩展性。

Abstract: Data augmentation is widely utilized as an effective technique to enhance the
generalization performance of deep models. However, data augmentation may
inevitably introduce distribution shifts and noises, which significantly
constrain the potential and deteriorate the performance of deep networks. To
this end, we propose a novel information-preserving framework, namely IPF-RDA,
to enhance the robustness of data augmentations in this paper. IPF-RDA combines
the proposal of (i) a new class-discriminative information estimation algorithm
that identifies the points most vulnerable to data augmentation operations and
corresponding importance scores; And (ii) a new information-preserving scheme
that preserves the critical information in the augmented samples and ensures
the diversity of augmented data adaptively. We divide data augmentation methods
into three categories according to the operation types and integrate these
approaches into our framework accordingly. After being integrated into our
framework, the robustness of data augmentation methods can be enhanced and
their full potential can be unleashed. Extensive experiments demonstrate that
although being simple, IPF-RDA consistently improves the performance of
numerous commonly used state-of-the-art data augmentation methods with popular
deep models on a variety of datasets, including CIFAR-10, CIFAR-100,
Tiny-ImageNet, CUHK03, Market1501, Oxford Flower, and MNIST, where its
performance and scalability are stressed. The implementation is available at
https://github.com/Jackbrocp/IPF-RDA.

</details>


### [53] [ProtoVQA: An Adaptable Prototypical Framework for Explainable Fine-Grained Visual Question Answering](https://arxiv.org/abs/2509.16680)
*Xingjian Diao,Weiyi Wu,Keyi Kong,Peijun Qing,Xinwen Xu,Ming Cheng,Soroush Vosoughi,Jiang Gui*

Main category: cs.CV

TL;DR: ProtoVQA 是一个可解释的视觉问答框架，通过问题感知原型和空间匹配提供高准确性及细粒度解释，适用于安全关键领域。


<details>
  <summary>Details</summary>
Motivation: 由于VQA在医疗影像和自动驾驶等安全关键领域的应用日益广泛，模型不仅需要提供准确答案，还需生成易于理解和验证的解释。原型建模在视觉推理任务中显示出可解释性潜力，但在VQA中尚未充分探索。

Method: ProtoVQA 框架通过（i）学习问题感知原型作为推理锚点，（ii）应用空间受限匹配确保证据的连贯性和语义相关性，（iii）通过共享原型主干支持回答和定位任务。

Result: 在Visual7W数据集上的实验表明，ProtoVQA 在保持竞争力的准确性的同时，提供了忠实且细粒度的解释。

Conclusion: ProtoVQA 通过原型框架提供了可解释的视觉问答系统，结合了高准确性和细粒度的解释能力，推动了透明且可信赖的VQA系统的发展。

Abstract: Visual Question Answering (VQA) is increasingly used in diverse applications
ranging from general visual reasoning to safety-critical domains such as
medical imaging and autonomous systems, where models must provide not only
accurate answers but also explanations that humans can easily understand and
verify. Prototype-based modeling has shown promise for interpretability by
grounding predictions in semantically meaningful regions for purely visual
reasoning tasks, yet remains underexplored in the context of VQA. We present
ProtoVQA, a unified prototypical framework that (i) learns question-aware
prototypes that serve as reasoning anchors, connecting answers to
discriminative image regions, (ii) applies spatially constrained matching to
ensure that the selected evidence is coherent and semantically relevant, and
(iii) supports both answering and grounding tasks through a shared prototype
backbone. To assess explanation quality, we propose the Visual-Linguistic
Alignment Score (VLAS), which measures how well the model's attended regions
align with ground-truth evidence. Experiments on Visual7W show that ProtoVQA
yields faithful, fine-grained explanations while maintaining competitive
accuracy, advancing the development of transparent and trustworthy VQA systems.

</details>


### [54] [Active View Selection for Scene-level Multi-view Crowd Counting and Localization with Limited Labels](https://arxiv.org/abs/2509.16684)
*Qi Zhang,Bin Li,Antoni B. Chan,Hui Huang*

Main category: cs.CV

TL;DR: 本文提出了一种主动视角选择方法（AVS），通过联合优化视角选择、标注和下游任务，解决了多视角人群计数和定位中的视角选择问题，实验证明其优于现有方法且应用更广。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注输入视角中人群的准确预测，忽略了选择‘最佳’视角以全面感知场景中所有人群的问题，且现有视角选择方法需要大量标注视角和图像，缺乏跨场景能力。

Method: 首先提出了独立的视角选择方法（IVS），考虑了视角和场景几何形状；随后提出了主动视角选择方法（AVS），联合优化视角选择、标注和下游任务。

Result: 实验表明，AVS在多视角计数和定位任务中具有跨场景和有限标签需求优势，优于现有方法。

Conclusion: 提出的主动视角选择方法（AVS）在多视角人群计数和定位任务中表现出跨场景能力和有限标签需求的优势，优于现有方法且应用场景更广。

Abstract: Multi-view crowd counting and localization fuse the input multi-views for
estimating the crowd number or locations on the ground. Existing methods mainly
focus on accurately predicting on the crowd shown in the input views, which
neglects the problem of choosing the `best' camera views to perceive all crowds
well in the scene. Besides, existing view selection methods require massive
labeled views and images, and lack the ability for cross-scene settings,
reducing their application scenarios. Thus, in this paper, we study the view
selection issue for better scene-level multi-view crowd counting and
localization results with cross-scene ability and limited label demand, instead
of input-view-level results. We first propose an independent view selection
method (IVS) that considers view and scene geometries in the view selection
strategy and conducts the view selection, labeling, and downstream tasks
independently. Based on IVS, we also put forward an active view selection
method (AVS) that jointly optimizes the view selection, labeling, and
downstream tasks. In AVS, we actively select the labeled views and consider
both the view/scene geometries and the predictions of the downstream task
models in the view selection process. Experiments on multi-view counting and
localization tasks demonstrate the cross-scene and the limited label demand
advantages of the proposed active view selection method (AVS), outperforming
existing methods and with wider application scenarios.

</details>


### [55] [Towards a Transparent and Interpretable AI Model for Medical Image Classifications](https://arxiv.org/abs/2509.16685)
*Binbin Wen,Yihang Wu,Tareef Daqqaq,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 该论文探讨了可解释人工智能（XAI）在医疗领域的应用，通过模拟展示XAI如何提升AI决策的透明度和可解释性，并指出了该领域当前的挑战和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 尽管人工智能（AI）在医学中的应用提供了先进的诊断和治疗可能性，但复杂AI模型固有的不透明性对其临床实用性构成了重大挑战。因此，研究旨在通过XAI方法使AI决策透明和可解释。

Method: 研究通过使用各种医疗数据集进行模拟，阐明XAI模型的内部工作原理，并展示了XAI如何有效解释AI预测，从而改善医疗专业人员的决策过程。

Result: 数据集驱动的模拟表明，XAI能够有效解释AI预测，从而提升医疗专业人员的决策过程。研究还讨论了XAI领域当前面临的挑战。

Conclusion: 该研究强调了在医疗领域持续开发和探索可解释人工智能（XAI）的必要性，特别是从多样化医疗数据集的角度出发，以促进其在医疗领域的采用和有效性。

Abstract: The integration of artificial intelligence (AI) into medicine is remarkable,
offering advanced diagnostic and therapeutic possibilities. However, the
inherent opacity of complex AI models presents significant challenges to their
clinical practicality. This paper focuses primarily on investigating the
application of explainable artificial intelligence (XAI) methods, with the aim
of making AI decisions transparent and interpretable. Our research focuses on
implementing simulations using various medical datasets to elucidate the
internal workings of the XAI model. These dataset-driven simulations
demonstrate how XAI effectively interprets AI predictions, thus improving the
decision-making process for healthcare professionals. In addition to a survey
of the main XAI methods and simulations, ongoing challenges in the XAI field
are discussed. The study highlights the need for the continuous development and
exploration of XAI, particularly from the perspective of diverse medical
datasets, to promote its adoption and effectiveness in the healthcare domain.

</details>


### [56] [Spectral Compressive Imaging via Chromaticity-Intensity Decomposition](https://arxiv.org/abs/2509.16690)
*Xiaodong Wang,Zijun He,Ping Wang,Lishun Wang,Yanan Hu,Xin Yuan*

Main category: cs.CV

TL;DR: 提出CIDNet，通过色度-强度分解解决CASSI中的信息纠缠和光照依赖问题，实现高性能重建。


<details>
  <summary>Details</summary>
Motivation: 解决CASSI中空间和光谱信息纠缠及光照依赖性的问题，恢复光照不变的固有光谱反射率。

Method: 提出了一种色度-强度分解框架，并开发了CIDNet网络，整合了混合空间-光谱Transformer和噪声估计模块。

Result: 在合成和真实CASSI数据集上的实验表明，该方法在光谱和色度保真度方面表现优异。

Conclusion: CIDNet通过色度-强度分解框架在CASSI系统中实现了优异的性能和色度保真度。

Abstract: In coded aperture snapshot spectral imaging (CASSI), the captured measurement
entangles spatial and spectral information, posing a severely ill-posed inverse
problem for hyperspectral images (HSIs) reconstruction. Moreover, the captured
radiance inherently depends on scene illumination, making it difficult to
recover the intrinsic spectral reflectance that remains invariant to lighting
conditions. To address these challenges, we propose a chromaticity-intensity
decomposition framework, which disentangles an HSI into a spatially smooth
intensity map and a spectrally variant chromaticity cube. The chromaticity
encodes lighting-invariant reflectance, enriched with high-frequency spatial
details and local spectral sparsity. Building on this decomposition, we develop
CIDNet, a Chromaticity-Intensity Decomposition unfolding network within a
dual-camera CASSI system. CIDNet integrates a hybrid spatial-spectral
Transformer tailored to reconstruct fine-grained and sparse spectral
chromaticity and a degradation-aware, spatially-adaptive noise estimation
module that captures anisotropic noise across iterative stages. Extensive
experiments on both synthetic and real-world CASSI datasets demonstrate that
our method achieves superior performance in both spectral and chromaticity
fidelity. Code and models will be publicly available.

</details>


### [57] [InstanceAssemble: Layout-Aware Image Generation via Instance Assembling Attention](https://arxiv.org/abs/2509.16691)
*Qiang Xiang,Shuang Sun,Binglei Li,Dejia Song,Huaxia Li,Nemo Chen,Xu Tang,Yao Hu,Junping Zhang*

Main category: cs.CV

TL;DR: InstanceAssemble是一种新型L2I生成架构，通过实例组装注意力和LoRA模块实现高精度图像合成，并在复杂布局下达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 尽管Layout-to-Image（L2I）生成在位置条件和文本描述的帮助下取得了进展，但现有方法仍表现不佳，因此需要更精确和可控的图像合成方法。

Method: 提出了一种新颖的架构InstanceAssemble，通过实例组装注意力结合布局条件，实现位置控制（bbox）和多模态内容控制（文本和额外视觉内容）。该方法通过轻量级LoRA模块灵活适配现有基于DiT的T2I模型。

Result: 实验表明，InstanceAssemble在复杂布局条件下表现优异，并提出了Denselayout基准和Layout Grounding Score（LGS）评估指标。

Conclusion: InstanceAssemble方法在复杂布局条件下实现了最先进的性能，同时展现出与多样化风格LoRA模块的强大兼容性。

Abstract: Diffusion models have demonstrated remarkable capabilities in generating
high-quality images. Recent advancements in Layout-to-Image (L2I) generation
have leveraged positional conditions and textual descriptions to facilitate
precise and controllable image synthesis. Despite overall progress, current L2I
methods still exhibit suboptimal performance. Therefore, we propose
InstanceAssemble, a novel architecture that incorporates layout conditions via
instance-assembling attention, enabling position control with bounding boxes
(bbox) and multimodal content control including texts and additional visual
content. Our method achieves flexible adaption to existing DiT-based T2I models
through light-weighted LoRA modules. Additionally, we propose a Layout-to-Image
benchmark, Denselayout, a comprehensive benchmark for layout-to-image
generation, containing 5k images with 90k instances in total. We further
introduce Layout Grounding Score (LGS), an interpretable evaluation metric to
more precisely assess the accuracy of L2I generation. Experiments demonstrate
that our InstanceAssemble method achieves state-of-the-art performance under
complex layout conditions, while exhibiting strong compatibility with diverse
style LoRA modules.

</details>


### [58] [Animalbooth: multimodal feature enhancement for animal subject personalization](https://arxiv.org/abs/2509.16702)
*Chen Liu,Haitao Wu,Kafeng Wang,Xiaowang Zhang*

Main category: cs.CV

TL;DR: AnimalBooth通过改进跨域对齐和特征集成，显著提升个性化动物图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 动物图像生成面临外观线索丰富和形态多变性的挑战，现有方法常因跨域特征对齐问题导致身份漂移。

Method: 提出AnimalBooth框架，结合Animal Net、自适应注意力模块和频率控制的离散余弦变换特征集成模块，实现从全局结构到细节纹理的逐步生成。

Result: 在多个基准测试中，AnimalBooth表现优于现有方法，提升了身份保真度和感知质量。

Conclusion: AnimalBooth框架通过整合Animal Net、自适应注意力模块和频率控制特征集成模块，显著提升了动物图像生成的个性化效果，在身份保真度和感知质量上均优于现有基线。

Abstract: Personalized animal image generation is challenging due to rich appearance
cues and large morphological variability. Existing approaches often exhibit
feature misalignment across domains, which leads to identity drift. We present
AnimalBooth, a framework that strengthens identity preservation with an Animal
Net and an adaptive attention module, mitigating cross domain alignment errors.
We further introduce a frequency controlled feature integration module that
applies Discrete Cosine Transform filtering in the latent space to guide the
diffusion process, enabling a coarse to fine progression from global structure
to detailed texture. To advance research in this area, we curate AnimalBench, a
high resolution dataset for animal personalization. Extensive experiments show
that AnimalBooth consistently outperforms strong baselines on multiple
benchmarks and improves both identity fidelity and perceptual quality.

</details>


### [59] [When Confidence Fails: Revisiting Pseudo-Label Selection in Semi-supervised Semantic Segmentation](https://arxiv.org/abs/2509.16704)
*Pan Liu,Jinshi Liu*

Main category: cs.CV

TL;DR: CSL通过优化伪标签选择和引入随机掩码，解决了半监督语义分割中的过自信和上下文丢失问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用固定置信度阈值处理伪标签选择，无法应对网络过自信倾向和空间语义连续性损失的问题。

Method: CSL将伪标签选择建模为置信度分布特征空间中的凸优化问题，并引入随机掩码技术引导网络学习低可靠性区域的上下文关系。

Result: 在Pascal、Cityscapes和COCO基准测试中，CSL表现优于现有最先进方法。

Conclusion: CSL通过样本特定的决策边界和随机掩码技术，有效解决了伪标签选择中的过自信问题和空间语义连续性损失，在多个基准测试中表现优异。

Abstract: While significant advances exist in pseudo-label generation for
semi-supervised semantic segmentation, pseudo-label selection remains
understudied. Existing methods typically use fixed confidence thresholds to
retain high-confidence predictions as pseudo-labels. However, these methods
cannot cope with network overconfidence tendency, where correct and incorrect
predictions overlap significantly in high-confidence regions, making separation
challenging and amplifying model cognitive bias. Meanwhile, the direct
discarding of low-confidence predictions disrupts spatial-semantic continuity,
causing critical context loss. We propose Confidence Separable Learning (CSL)
to address these limitations. CSL formulates pseudo-label selection as a convex
optimization problem within the confidence distribution feature space,
establishing sample-specific decision boundaries to distinguish reliable from
unreliable predictions. Additionally, CSL introduces random masking of reliable
pixels to guide the network in learning contextual relationships from
low-reliability regions, thereby mitigating the adverse effects of discarding
uncertain predictions. Extensive experimental results on the Pascal,
Cityscapes, and COCO benchmarks show that CSL performs favorably against
state-of-the-art methods. Code and model weights are available at
https://github.com/PanLiuCSU/CSL.

</details>


### [60] [Text-Scene: A Scene-to-Language Parsing Framework for 3D Scene Understanding](https://arxiv.org/abs/2509.16721)
*Haoyuan Li,Rui Liu,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: Text-Scene框架通过几何分析和MLLMs自动生成3D场景的文本描述，解决了3D场景理解的挑战，实验证明其有效性和实用性，并发布了InPlan3D基准用于评估。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在3D场景理解中的扩展难题，包括丰富的3D概念（如空间关系、功能、物理、布局等）和大规模3D视觉-语言数据集的缺乏。

Method: 结合几何分析和多模态大语言模型（MLLMs），自动识别物体属性和空间关系，生成场景的连贯文本摘要。

Result: 实验结果表明，Text-Scene生成的文本解析能忠实表示3D场景，并提升下游任务性能。此外，提出的InPlan3D基准包含3174个长期规划任务，覆盖636个室内场景，用于评估MLLMs的推理能力。

Conclusion: Text-Scene框架通过自动解析3D场景为文本描述，有效填补了3D观察与语言之间的鸿沟，无需人工干预，且生成的描述准确、详细、易于理解。实验证明该框架能忠实表示3D场景并有益于下游任务。

Abstract: Enabling agents to understand and interact with complex 3D scenes is a
fundamental challenge for embodied artificial intelligence systems. While
Multimodal Large Language Models (MLLMs) have achieved significant progress in
2D image understanding, extending such capabilities to 3D scenes remains
difficult: 1) 3D environment involves richer concepts such as spatial
relationships, affordances, physics, layout, and so on, 2) the absence of
large-scale 3D vision-language datasets has posed a significant obstacle. In
this paper, we introduce Text-Scene, a framework that automatically parses 3D
scenes into textual descriptions for scene understanding. Given a 3D scene, our
model identifies object attributes and spatial relationships, and then
generates a coherent summary of the whole scene, bridging the gap between 3D
observation and language without requiring human-in-the-loop intervention. By
leveraging both geometric analysis and MLLMs, Text-Scene produces descriptions
that are accurate, detailed, and human-interpretable, capturing object-level
details and global-level context. Experimental results on benchmarks
demonstrate that our textual parses can faithfully represent 3D scenes and
benefit downstream tasks. To evaluate the reasoning capability of MLLMs, we
present InPlan3D, a comprehensive benchmark for 3D task planning, consisting of
3174 long-term planning tasks across 636 indoor scenes. We emphasize clarity
and accessibility in our approach, aiming to make 3D scene content
understandable through language. Code and datasets will be released.

</details>


### [61] [Pain in 3D: Generating Controllable Synthetic Faces for Automated Pain Assessment](https://arxiv.org/abs/2509.16727)
*Xin Lei Lin,Soroush Mehraban,Abhishek Moturu,Babak Taati*

Main category: cs.CV

TL;DR: 提出了3DPain合成数据集和ViTPain框架，解决了疼痛评估中的数据不平衡和生成模型控制问题，为自动化疼痛评估提供了可控、多样且临床可靠的基础。


<details>
  <summary>Details</summary>
Motivation: 由于伦理限制，现有数据集存在严重的人口和标签不平衡问题，且当前生成模型无法精确控制面部动作单元（AUs）、面部结构或临床验证的疼痛水平。

Method: 提出了一个三阶段框架，包括生成多样化的3D网格、使用扩散模型进行纹理处理，以及应用AU驱动的面部绑定技术，合成多视角面部图像。此外，还引入了ViTPain，一个基于Vision Transformer的跨模态蒸馏框架。

Result: 生成了包含82,500个样本的大规模合成数据集3DPain，并开发了ViTPain框架，提高了准确性、可解释性和临床可靠性。

Conclusion: 3DPain和ViTPain为通用自动化疼痛评估建立了一个可控、多样且临床基础扎实的框架。

Abstract: Automated pain assessment from facial expressions is crucial for
non-communicative patients, such as those with dementia. Progress has been
limited by two challenges: (i) existing datasets exhibit severe demographic and
label imbalance due to ethical constraints, and (ii) current generative models
cannot precisely control facial action units (AUs), facial structure, or
clinically validated pain levels.
  We present 3DPain, a large-scale synthetic dataset specifically designed for
automated pain assessment, featuring unprecedented annotation richness and
demographic diversity. Our three-stage framework generates diverse 3D meshes,
textures them with diffusion models, and applies AU-driven face rigging to
synthesize multi-view faces with paired neutral and pain images, AU
configurations, PSPI scores, and the first dataset-level annotations of
pain-region heatmaps. The dataset comprises 82,500 samples across 25,000 pain
expression heatmaps and 2,500 synthetic identities balanced by age, gender, and
ethnicity.
  We further introduce ViTPain, a Vision Transformer based cross-modal
distillation framework in which a heatmap-trained teacher guides a student
trained on RGB images, enhancing accuracy, interpretability, and clinical
reliability. Together, 3DPain and ViTPain establish a controllable, diverse,
and clinically grounded foundation for generalizable automated pain assessment.

</details>


### [62] [Min: Mixture of Noise for Pre-Trained Model-Based Class-Incremental Learning](https://arxiv.org/abs/2509.16738)
*Kai Jiang,Zhengyan Shi,Dell Zhang,Hongyuan Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Min方法通过学习和混合有益噪声，有效缓解了预训练模型在持续学习中的泛化能力退化问题，在多个增量设置中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在轻量级微调预训练模型时会导致参数漂移，损害模型的泛化能力。参数漂移被视为一种噪声，但研究表明噪声并不总是有害的，适当的噪声可以抑制低相关性特征，为未来任务留出空间。

Method: 提出了一种基于信息理论指导的学习有益噪声的方法Mixture of Noise（Min），通过从新任务的高维特征中学习任务特定噪声，动态调整权重以优化不同任务噪声的混合，并将有益噪声嵌入中间特征以掩盖低效模式的响应。

Result: 在六个基准数据集上的广泛实验表明，Min在大多数增量设置中实现了最先进的性能，尤其是在50步增量设置中表现尤为突出。

Conclusion: 研究表明，有益噪声在持续学习中具有显著潜力，Min方法在多数增量设置中实现了最先进的性能，尤其是在50步增量设置中表现突出。

Abstract: Class Incremental Learning (CIL) aims to continuously learn new categories
while retaining the knowledge of old ones. Pre-trained models (PTMs) show
promising capabilities in CIL. However, existing approaches that apply
lightweight fine-tuning to backbones still induce parameter drift, thereby
compromising the generalization capability of pre-trained models. Parameter
drift can be conceptualized as a form of noise that obscures critical patterns
learned for previous tasks. However, recent researches have shown that noise is
not always harmful. For example, the large number of visual patterns learned
from pre-training can be easily abused by a single task, and introducing
appropriate noise can suppress some low-correlation features, thus leaving a
margin for future tasks. To this end, we propose learning beneficial noise for
CIL guided by information theory and propose Mixture of Noise (Min), aiming to
mitigate the degradation of backbone generalization from adapting new tasks.
Specifically, task-specific noise is learned from high-dimension features of
new tasks. Then, a set of weights is adjusted dynamically for optimal mixture
of different task noise. Finally, Min embeds the beneficial noise into the
intermediate features to mask the response of inefficient patterns. Extensive
experiments on six benchmark datasets demonstrate that Min achieves
state-of-the-art performance in most incremental settings, with particularly
outstanding results in 50-steps incremental settings. This shows the
significant potential for beneficial noise in continual learning.

</details>


### [63] [CAMBench-QR : A Structure-Aware Benchmark for Post-Hoc Explanations with QR Understanding](https://arxiv.org/abs/2509.16745)
*Ritabrata Chakraborty,Avijit Dasgupta,Sandeep Chaurasia*

Main category: cs.CV

TL;DR: CAMBench-QR 是一个基于 QR 码结构的基准测试，用于评估视觉解释方法是否真正关注必要子结构，避免背景干扰。


<details>
  <summary>Details</summary>
Motivation: 现有视觉解释方法往往在结构上不够忠实，缺乏对必要子结构的关注。

Method: CAMBench-QR 利用 QR 码的几何结构（如定位图案、时序线、模块网格）生成合成数据，结合精确掩码和受控失真，评估 CAM 方法在关键子结构上的显著性分布。

Result: CAMBench-QR 提供了一套结构感知的评估指标（如定位/时序质量比、背景泄漏、覆盖 AUC 等），并测试了代表性 CAM 方法（如 LayerCAM、EigenGrad-CAM）在零样本和微调场景下的表现。

Conclusion: CAMBench-QR 可以作为视觉解释是否真正具备结构感知能力的试金石。

Abstract: Visual explanations are often plausible but not structurally faithful. We
introduce CAMBench-QR, a structure-aware benchmark that leverages the canonical
geometry of QR codes (finder patterns, timing lines, module grid) to test
whether CAM methods place saliency on requisite substructures while avoiding
background. CAMBench-QR synthesizes QR/non-QR data with exact masks and
controlled distortions, and reports structure-aware metrics (Finder/Timing Mass
Ratios, Background Leakage, coverage AUCs, Distance-to-Structure) alongside
causal occlusion, insertion/deletion faithfulness, robustness, and latency. We
benchmark representative, efficient CAMs (LayerCAM, EigenGrad-CAM, XGrad-CAM)
under two practical regimes of zero-shot and last-block fine-tuning. The
benchmark, metrics, and training recipes provide a simple, reproducible
yardstick for structure-aware evaluation of visual explanations. Hence we
propose that CAMBENCH-QR can be used as a litmus test of whether visual
explanations are truly structure-aware.

</details>


### [64] [HyPlaneHead: Rethinking Tri-plane-like Representations in Full-Head Image Synthesis](https://arxiv.org/abs/2509.16748)
*Heyuan Li,Kenkun Liu,Lingteng Qiu,Qi Zuo,Keru Zheng,Zilong Dong,Xiaoguang Han*

Main category: cs.CV

TL;DR: 本文提出HyPlaneHead，通过混合平面表示和近等面积扭曲策略，解决了3D感知GAN中的特征纠缠和穿透问题，实现了更优的头部图像合成效果。


<details>
  <summary>Details</summary>
Motivation: 传统三平面表示在3D头部图像合成中存在特征纠缠和镜像伪影问题，球形三平面虽缓解了特征纠缠但导致特征图利用不均。此外，多通道特征穿透问题限制了性能。本文旨在系统性解决这些问题。

Method: 提出了一种新颖的混合平面（hy-plane）表示，结合了平面和球形平面的优势，并引入了近等面积扭曲策略以最大化特征图利用率。生成器合成单通道统一特征图，避免多通道特征穿透。

Result: HyPlaneHead在头部图像合成任务中实现了最先进的性能，显著提升了图像细节生成和特征图利用效率。

Conclusion: HyPlaneHead通过引入混合平面表示和近等面积扭曲策略，显著提升了3D感知GAN在头部图像合成中的性能，解决了特征纠缠和特征穿透问题，实现了最先进的合成效果。

Abstract: Tri-plane-like representations have been widely adopted in 3D-aware GANs for
head image synthesis and other 3D object/scene modeling tasks due to their
efficiency. However, querying features via Cartesian coordinate projection
often leads to feature entanglement, which results in mirroring artifacts. A
recent work, SphereHead, attempted to address this issue by introducing
spherical tri-planes based on a spherical coordinate system. While it
successfully mitigates feature entanglement, SphereHead suffers from uneven
mapping between the square feature maps and the spherical planes, leading to
inefficient feature map utilization during rendering and difficulties in
generating fine image details. Moreover, both tri-plane and spherical tri-plane
representations share a subtle yet persistent issue: feature penetration across
convolutional channels can cause interference between planes, particularly when
one plane dominates the others. These challenges collectively prevent
tri-plane-based methods from reaching their full potential. In this paper, we
systematically analyze these problems for the first time and propose innovative
solutions to address them. Specifically, we introduce a novel hybrid-plane
(hy-plane for short) representation that combines the strengths of both planar
and spherical planes while avoiding their respective drawbacks. We further
enhance the spherical plane by replacing the conventional theta-phi warping
with a novel near-equal-area warping strategy, which maximizes the effective
utilization of the square feature map. In addition, our generator synthesizes a
single-channel unified feature map instead of multiple feature maps in separate
channels, thereby effectively eliminating feature penetration. With a series of
technical improvements, our hy-plane representation enables our method,
HyPlaneHead, to achieve state-of-the-art performance in full-head image
synthesis.

</details>


### [65] [DiffEye: Diffusion-Based Continuous Eye-Tracking Data Generation Conditioned on Natural Images](https://arxiv.org/abs/2509.16767)
*Ozgur Kara,Harris Nisar,James M. Rehg*

Main category: cs.CV

TL;DR: DiffEye是一种基于扩散模型的框架，利用原始眼动轨迹数据生成连续且多样化的眼动轨迹，解决了现有方法忽略多样性和原始信息的问题，并在性能上达到最优。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常丢弃原始轨迹中的丰富信息，且无法捕捉人类观看同一图像时的变异性，预测的扫描路径长度固定且单一。

Method: DiffEye基于扩散模型，结合视觉刺激条件和新颖的对应位置嵌入（CPE）组件，利用原始眼动轨迹数据进行训练。

Result: DiffEye不仅在扫描路径生成上表现优异，还首次实现了连续眼动轨迹的生成，生成的轨迹和显著性图更准确地反映了人类视觉注意力的分布。

Conclusion: DiffEye通过扩散模型成功捕捉了人类视觉注意力的多样性和随机性，生成了高质量的连续眼动轨迹，并在扫描路径生成上达到了最先进的性能。

Abstract: Numerous models have been developed for scanpath and saliency prediction,
which are typically trained on scanpaths, which model eye movement as a
sequence of discrete fixation points connected by saccades, while the rich
information contained in the raw trajectories is often discarded. Moreover,
most existing approaches fail to capture the variability observed among human
subjects viewing the same image. They generally predict a single scanpath of
fixed, pre-defined length, which conflicts with the inherent diversity and
stochastic nature of real-world visual attention. To address these challenges,
we propose DiffEye, a diffusion-based training framework designed to model
continuous and diverse eye movement trajectories during free viewing of natural
images. Our method builds on a diffusion model conditioned on visual stimuli
and introduces a novel component, namely Corresponding Positional Embedding
(CPE), which aligns spatial gaze information with the patch-based semantic
features of the visual input. By leveraging raw eye-tracking trajectories
rather than relying on scanpaths, DiffEye captures the inherent variability in
human gaze behavior and generates high-quality, realistic eye movement
patterns, despite being trained on a comparatively small dataset. The generated
trajectories can also be converted into scanpaths and saliency maps, resulting
in outputs that more accurately reflect the distribution of human visual
attention. DiffEye is the first method to tackle this task on natural images
using a diffusion model while fully leveraging the richness of raw eye-tracking
data. Our extensive evaluation shows that DiffEye not only achieves
state-of-the-art performance in scanpath generation but also enables, for the
first time, the generation of continuous eye movement trajectories. Project
webpage: https://diff-eye.github.io/

</details>


### [66] [MMPart: Harnessing Multi-Modal Large Language Models for Part-Aware 3D Generation](https://arxiv.org/abs/2509.16768)
*Omid Bonakdar,Nasser Mozayani*

Main category: cs.CV

TL;DR: MMPart是一个从单张图像生成部分感知3D模型的创新框架，结合VLM和生成模型，解决了用户控制和遮挡部分想象的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的3D生成方法通常将目标对象表示为封闭的网格，缺乏结构信息，限制了编辑、动画和语义理解。现有部分感知的3D生成方法在用户控制和遮挡部分想象上存在不足。

Method: MMPart框架首先使用VLM基于输入图像和用户描述生成提示，然后通过生成模型生成每个对象的独立图像，接着进入多视图生成阶段，最后通过重建模型将多视图图像转换为3D模型。

Result: MMPart框架能够生成具有部分感知的3D模型，用户可以通过描述控制对象的分离方式，并指导模型想象遮挡部分。

Conclusion: MMPart框架通过结合视觉语言模型（VLM）和生成模型，成功实现了从单张图像生成具有部分感知的3D模型，解决了现有方法在用户控制和遮挡部分想象上的局限性。

Abstract: Generative 3D modeling has advanced rapidly, driven by applications in VR/AR,
metaverse, and robotics. However, most methods represent the target object as a
closed mesh devoid of any structural information, limiting editing, animation,
and semantic understanding. Part-aware 3D generation addresses this problem by
decomposing objects into meaningful components, but existing pipelines face
challenges: in existing methods, the user has no control over which objects are
separated and how model imagine the occluded parts in isolation phase. In this
paper, we introduce MMPart, an innovative framework for generating part-aware
3D models from a single image. We first use a VLM to generate a set of prompts
based on the input image and user descriptions. In the next step, a generative
model generates isolated images of each object based on the initial image and
the previous step's prompts as supervisor (which control the pose and guide
model how imagine previously occluded areas). Each of those images then enters
the multi-view generation stage, where a number of consistent images from
different views are generated. Finally, a reconstruction model converts each of
these multi-view images into a 3D model.

</details>


### [67] [Artificial Satellite Trails Detection Using U-Net Deep Neural Network and Line Segment Detector Algorithm](https://arxiv.org/abs/2509.16771)
*Xiaohan Chen,Hongrui Gu,Cunshi Wang,Haiyang Mu,Jie Zheng,Junju Du,Jing Ren,Zhou Fan,Jing Li*

Main category: cs.CV

TL;DR: 提出结合U-Net和LSD的卫星轨迹检测模型，模拟数据检测率超99%，实际数据召回率79.57，精确率74.56。


<details>
  <summary>Details</summary>
Motivation: 随着人造卫星数量激增，天文成像受到干扰，卫星轨迹会引入虚假光源和显著光度误差，需准确定位。

Method: 结合U-Net深度神经网络和LSD算法，训练于375张模拟卫星轨迹图像。

Result: 对于信噪比大于3的轨迹，检测率超过99%；在Mini-SiTian阵列的实际观测数据中，召回率为79.57，精确率为74.56。

Conclusion: 结合U-Net和LSD算法的卫星轨迹检测模型在模拟和实际观测数据中均表现出色，尤其是在高信噪比条件下，检测率超过99%。

Abstract: With the rapid increase in the number of artificial satellites, astronomical
imaging is experiencing growing interference. When these satellites reflect
sunlight, they produce streak-like artifacts in photometry images. Such
satellite trails can introduce false sources and cause significant photometric
errors. As a result, accurately identifying the positions of satellite trails
in observational data has become essential. In this work, we propose a
satellite trail detection model that combines the U-Net deep neural network for
image segmentation with the Line Segment Detector (LSD) algorithm. The model is
trained on 375 simulated images of satellite trails, generated using data from
the Mini-SiTian Array. Experimental results show that for trails with a
signal-to-noise ratio (SNR) greater than 3, the detection rate exceeds 99.
Additionally, when applied to real observational data from the Mini-SiTian
Array, the model achieves a recall of 79.57 and a precision of 74.56.

</details>


### [68] [Benchmarking and Mitigating MCQA Selection Bias of Large Vision-Language Models](https://arxiv.org/abs/2509.16805)
*Md. Atabuzzaman,Ali Asgarov,Chris Thomas*

Main category: cs.CV

TL;DR: 研究发现LVLMs在MCQA中存在选择偏差，提出无需重新训练的去偏方法，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 探索LVLMs在MCQA中的选择偏差问题（如偏袒特定选项标记或位置），以提升模型在精细视觉推理中的鲁棒性。

Method: 通过细粒度MCQA基准测试（涵盖易、中、难三个难度级别）和提出的推理时对数级去偏方法（通过通用和上下文提示估计集成偏差向量并应用置信度自适应校正）。

Result: 实验表明，LVLMs存在一致的选择偏差（随任务难度加剧），提出的去偏方法显著减少偏差并提高准确性。

Conclusion: 本研究揭示了大型视觉语言模型（LVLMs）在多项选择题回答（MCQA）中的选择偏差问题，并提出了一种无需重新训练的推理时对数级去偏方法，显著提高了模型在复杂场景中的准确性和鲁棒性。

Abstract: Large Vision-Language Models (LVLMs) have achieved strong performance on
vision-language tasks, particularly Visual Question Answering (VQA). While
prior work has explored unimodal biases in VQA, the problem of selection bias
in Multiple-Choice Question Answering (MCQA), where models may favor specific
option tokens (e.g., "A") or positions, remains underexplored. In this paper,
we investigate both the presence and nature of selection bias in LVLMs through
fine-grained MCQA benchmarks spanning easy, medium, and hard difficulty levels,
defined by the semantic similarity of the options. We further propose an
inference-time logit-level debiasing method that estimates an ensemble bias
vector from general and contextual prompts and applies confidence-adaptive
corrections to the model's output. Our method mitigates bias without retraining
and is compatible with frozen LVLMs. Extensive experiments across several
state-of-the-art models reveal consistent selection biases that intensify with
task difficulty, and show that our mitigation approach significantly reduces
bias while improving accuracy in challenging settings. This work offers new
insights into the limitations of LVLMs in MCQA and presents a practical
approach to improve their robustness in fine-grained visual reasoning. Datasets
and code are available at:
https://github.com/Atabuzzaman/Selection-Bias-of-LVLMs

</details>


### [69] [MedGS: Gaussian Splatting for Multi-Modal 3D Medical Imaging](https://arxiv.org/abs/2509.16806)
*Kacper Marzol,Ignacy Kolton,Weronika Smolak-Dyżewska,Joanna Kaleta,Marcin Mazur,Przemysław Spurek*

Main category: cs.CV

TL;DR: MedGS 是一种基于高斯 Splatting 的半监督框架，用于医学影像的表面重建和帧间插值，克服了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在图像噪声和帧间信息不完整的情况下表现受限，因此需要一种更鲁棒、高效的解决方案。

Method: MedGS 是一种半监督神经隐式表面重建框架，采用基于高斯 Splatting (GS) 的插值机制，将医学影像数据表示为 3D 空间中的连续 2D 帧，并使用高斯分布建模。

Result: MedGS 在训练效率、噪声鲁棒性、灵活编辑和复杂解剖结构建模方面优于传统方法，减少了伪影。

Conclusion: MedGS 提供了一种高效、鲁棒且灵活的方法，适用于医学成像中的表面重建和帧间插值，具有实际应用的潜力。

Abstract: Multi-modal three-dimensional (3D) medical imaging data, derived from
ultrasound, magnetic resonance imaging (MRI), and potentially computed
tomography (CT), provide a widely adopted approach for non-invasive anatomical
visualization. Accurate modeling, registration, and visualization in this
setting depend on surface reconstruction and frame-to-frame interpolation.
Traditional methods often face limitations due to image noise and incomplete
information between frames. To address these challenges, we present MedGS, a
semi-supervised neural implicit surface reconstruction framework that employs a
Gaussian Splatting (GS)-based interpolation mechanism. In this framework,
medical imaging data are represented as consecutive two-dimensional (2D) frames
embedded in 3D space and modeled using Gaussian-based distributions. This
representation enables robust frame interpolation and high-fidelity surface
reconstruction across imaging modalities. As a result, MedGS offers more
efficient training than traditional neural implicit methods. Its explicit
GS-based representation enhances noise robustness, allows flexible editing, and
supports precise modeling of complex anatomical structures with fewer
artifacts. These features make MedGS highly suitable for scalable and practical
applications in medical imaging.

</details>


### [70] [Looking in the mirror: A faithful counterfactual explanation method for interpreting deep image classification models](https://arxiv.org/abs/2509.16822)
*Townim Faisal Chowdhury,Vu Minh Hieu Phan,Kewen Liao,Nanyu Dong,Minh-Son To,Anton Hengel,Johan Verjans,Zhibin Liao*

Main category: cs.CV

TL;DR: Mirror-CFE直接在分类器特征空间中生成反事实解释，通过“镜子”映射方法，优于现有方法，并提供可解释的决策过程可视化。


<details>
  <summary>Details</summary>
Motivation: 现有反事实解释方法依赖额外图像编码器和生成模型，忽视了分类器自身的特征空间和决策边界。

Method: Mirror-CFE提出了一种新方法，通过在分类器的特征空间中直接操作，将决策边界视为“镜子”，学习从特征空间到图像空间的映射函数，保持距离关系。

Result: 在四个图像数据集上的实验表明，Mirror-CFE在有效性和输入相似性方面优于现有解释方法。

Conclusion: Mirror-CFE通过直接在分类器的特征空间中操作，提供了更忠实和可解释的反事实解释，有效揭示了分类器的决策过程。

Abstract: Counterfactual explanations (CFE) for deep image classifiers aim to reveal
how minimal input changes lead to different model decisions, providing critical
insights for model interpretation and improvement. However, existing CFE
methods often rely on additional image encoders and generative models to create
plausible images, neglecting the classifier's own feature space and decision
boundaries. As such, they do not explain the intrinsic feature space and
decision boundaries learned by the classifier. To address this limitation, we
propose Mirror-CFE, a novel method that generates faithful counterfactual
explanations by operating directly in the classifier's feature space, treating
decision boundaries as mirrors that ``reflect'' feature representations in the
mirror. Mirror-CFE learns a mapping function from feature space to image space
while preserving distance relationships, enabling smooth transitions between
source images and their counterfactuals. Through extensive experiments on four
image datasets, we demonstrate that Mirror-CFE achieves superior performance in
validity while maintaining input resemblance compared to state-of-the-art
explanation methods. Finally, mirror-CFE provides interpretable visualization
of the classifier's decision process by generating step-wise transitions that
reveal how features evolve as classification confidence changes.

</details>


### [71] [L2M-Reg: Building-level Uncertainty-aware Registration of Outdoor LiDAR Point Clouds and Semantic 3D City Models](https://arxiv.org/abs/2509.16832)
*Ziyang Xu,Benedikt Schwab,Yihui Yang,Thomas H. Kolbe,Christoph Holst*

Main category: cs.CV

TL;DR: L2M-Reg是一种基于平面的精细配准方法，解决了LoD2语义3D城市模型不确定性带来的建筑级别LiDAR配准挑战，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于语义3D城市模型在LoD2级别存在泛化不确定性，实现建筑级别的LiDAR到模型精确配准仍然具有挑战性，L2M-Reg旨在填补这一空白。

Method: L2M-Reg包括三个关键步骤：建立可靠的平面对应关系、构建伪平面约束的Gauss-Helmert模型以及自适应估计垂直平移。

Result: 在三个真实世界数据集上的实验表明，L2M-Reg在准确性和计算效率上均优于现有的ICP和平面基础方法。

Conclusion: L2M-Reg提供了一种新颖的建筑级别解决方案，用于处理存在模型不确定性时的LiDAR到模型配准问题，实验证明其在准确性和计算效率上均优于现有方法。

Abstract: Accurate registration between LiDAR (Light Detection and Ranging) point
clouds and semantic 3D city models is a fundamental topic in urban digital
twinning and a prerequisite for downstream tasks, such as digital construction,
change detection and model refinement. However, achieving accurate
LiDAR-to-Model registration at individual building level remains challenging,
particularly due to the generalization uncertainty in semantic 3D city models
at the Level of Detail 2 (LoD2). This paper addresses this gap by proposing
L2M-Reg, a plane-based fine registration method that explicitly accounts for
model uncertainty. L2M-Reg consists of three key steps: establishing reliable
plane correspondence, building a pseudo-plane-constrained Gauss-Helmert model,
and adaptively estimating vertical translation. Experiments on three real-world
datasets demonstrate that L2M-Reg is both more accurate and computationally
efficient than existing ICP-based and plane-based methods. Overall, L2M-Reg
provides a novel building-level solution regarding LiDAR-to-Model registration
when model uncertainty is present.

</details>


### [72] [ISCS: Parameter-Guided Channel Ordering and Grouping for Learned Image Compression](https://arxiv.org/abs/2509.16853)
*Jinhao Wang,Cihan Ruan,Nam Ling,Wei Wang,Wei Jiang*

Main category: cs.CV

TL;DR: 提出一种通用方法，通过分析预训练VAE模型中的通道重要性，优化图像压缩的编码和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理潜在通道时存在计算成本高、数据集依赖性强且忽略通道间相互依赖的问题，需要一种更高效、通用的解决方案。

Method: 利用权重方差、偏置大小和成对相关性等内在参数统计来估计通道重要性，提出ISCS结构，并基于此设计确定性通道排序和分组策略。

Result: 实验表明，该方法在多种LIC架构中有效降低了比特率和计算量，同时保持了重建质量。

Conclusion: 该方法通过识别和组织预训练VAE模型中的重要通道，提出了ISCS结构，显著提升了编码效率和计算效率，同时保持了重建质量。

Abstract: Prior studies in learned image compression (LIC) consistently show that only
a small subset of latent channels is critical for reconstruction, while many
others carry limited information. Exploiting this imbalance could improve both
coding and computational efficiency, yet existing approaches often rely on
costly, dataset-specific ablation tests and typically analyze channels in
isolation, ignoring their interdependencies.
  We propose a generalizable, dataset-agnostic method to identify and organize
important channels in pretrained VAE-based LIC models. Instead of brute-force
empirical evaluations, our approach leverages intrinsic parameter
statistics-weight variances, bias magnitudes, and pairwise correlations-to
estimate channel importance. This analysis reveals a consistent organizational
structure, termed the Invariant Salient Channel Space (ISCS), where
Salient-Core channels capture dominant structures and Salient-Auxiliary
channels provide complementary details. Building on ISCS, we introduce a
deterministic channel ordering and grouping strategy that enables
slice-parallel decoding, reduces redundancy, and improves bitrate efficiency.
  Experiments across multiple LIC architectures demonstrate that our method
effectively reduces bitrate and computation while maintaining reconstruction
quality, providing a practical and modular enhancement to existing learned
compression frameworks.

</details>


### [73] [ConfidentSplat: Confidence-Weighted Depth Fusion for Accurate 3D Gaussian Splatting SLAM](https://arxiv.org/abs/2509.16863)
*Amanuel T. Dufera,Yuan-Li Cai*

Main category: cs.CV

TL;DR: ConfidentSplat是一种基于3D高斯泼溅的RGB-only SLAM系统，通过置信度加权融合机制提升重建精度和新视角合成质量，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有RGB-only 3DGS SLAM方法因不可靠深度估计导致的几何不准确问题。

Method: 采用基于3D高斯泼溅的SLAM系统，结合置信度加权融合机制整合多视角几何深度和单目先验深度，生成高质量代理深度用于地图监督。

Result: 在标准基准测试和自定义移动数据集上，重建精度（L1深度误差）和新视角合成质量（PSNR、SSIM、LPIPS）显著优于基线方法。

Conclusion: ConfidentSplat通过置信度加权融合机制显著提升了RGB-only SLAM系统的重建精度和新视角合成质量，为密集视觉SLAM领域提供了有效的解决方案。

Abstract: We introduce ConfidentSplat, a novel 3D Gaussian Splatting (3DGS)-based SLAM
system for robust, highfidelity RGB-only reconstruction. Addressing geometric
inaccuracies in existing RGB-only 3DGS SLAM methods that stem from unreliable
depth estimation, ConfidentSplat incorporates a core innovation: a
confidence-weighted fusion mechanism. This mechanism adaptively integrates
depth cues from multiview geometry with learned monocular priors (Omnidata
ViT), dynamically weighting their contributions based on explicit reliability
estimates-derived predominantly from multi-view geometric consistency-to
generate high-fidelity proxy depth for map supervision. The resulting proxy
depth guides the optimization of a deformable 3DGS map, which efficiently
adapts online to maintain global consistency following pose updates from a
DROID-SLAM-inspired frontend and backend optimizations (loop closure, global
bundle adjustment). Extensive validation on standard benchmarks (TUM-RGBD,
ScanNet) and diverse custom mobile datasets demonstrates significant
improvements in reconstruction accuracy (L1 depth error) and novel view
synthesis fidelity (PSNR, SSIM, LPIPS) over baselines, particularly in
challenging conditions. ConfidentSplat underscores the efficacy of principled,
confidence-aware sensor fusion for advancing state-of-the-art dense visual
SLAM.

</details>


### [74] [$\mathtt{M^3VIR}$: A Large-Scale Multi-Modality Multi-View Synthesized Benchmark Dataset for Image Restoration and Content Creation](https://arxiv.org/abs/2509.16873)
*Yuanzhi Li,Lebin Zhou,Nam Ling,Zhenghao Chen,Wei Wang,Wei Jiang*

Main category: cs.CV

TL;DR: 论文提出了$\mathtt{M^3VIR}$数据集，解决了现有游戏内容数据集的局限性，支持超分辨率、新视角合成及可控视频生成的研究。


<details>
  <summary>Details</summary>
Motivation: 现有数据集局限于特定领域或依赖人工降级，无法准确捕捉游戏内容的独特性，且缺乏可控视频生成的基准。

Method: 引入$\mathtt{M^3VIR}$数据集，包含大规模多模态、多视角的游戏内容，提供高保真度的LR-HR配对和多视角帧，并针对超分辨率、新视角合成及可控视频生成任务设计了特定子集。

Result: $\mathtt{M^3VIR}$填补了现有资源的不足，提供了多样化的高保真游戏内容，并建立了超分辨率和新视角合成方法的性能基准。

Conclusion: 通过发布$\mathtt{M^3VIR}$数据集，旨在推动AI驱动的修复、压缩及可控内容生成的研究，以支持下一代云游戏和娱乐产业的发展。

Abstract: The gaming and entertainment industry is rapidly evolving, driven by
immersive experiences and the integration of generative AI (GAI) technologies.
Training such models effectively requires large-scale datasets that capture the
diversity and context of gaming environments. However, existing datasets are
often limited to specific domains or rely on artificial degradations, which do
not accurately capture the unique characteristics of gaming content. Moreover,
benchmarks for controllable video generation remain absent.
  To address these limitations, we introduce $\mathtt{M^3VIR}$, a large-scale,
multi-modal, multi-view dataset specifically designed to overcome the
shortcomings of current resources. Unlike existing datasets, $\mathtt{M^3VIR}$
provides diverse, high-fidelity gaming content rendered with Unreal Engine 5,
offering authentic ground-truth LR-HR paired and multi-view frames across 80
scenes in 8 categories. It includes $\mathtt{M^3VIR\_MR}$ for super-resolution
(SR), novel view synthesis (NVS), and combined NVS+SR tasks, and
$\mathtt{M^3VIR\_{MS}}$, the first multi-style, object-level ground-truth set
enabling research on controlled video generation. Additionally, we benchmark
several state-of-the-art SR and NVS methods to establish performance baselines.
While no existing approaches directly handle controlled video generation,
$\mathtt{M^3VIR}$ provides a benchmark for advancing this area. By releasing
the dataset, we aim to facilitate research in AI-powered restoration,
compression, and controllable content generation for next-generation cloud
gaming and entertainment.

</details>


### [75] [SAM-DCE: Addressing Token Uniformity and Semantic Over-Smoothing in Medical Segmentation](https://arxiv.org/abs/2509.16886)
*Yingzhen Hu,Yiheng Zhong,Ruobing Li,Yingxue Su,Jiabao An,Feilong Tang,Jionglong Su,Imran Razzak*

Main category: cs.CV

TL;DR: SAM-DCE通过平衡局部与全局特征并解决标记均匀性问题，提升了医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM在自然图像上展示了出色的零样本分割能力，但在医学图像中由于领域偏移、解剖变异性和对用户提供提示的依赖而遇到困难。现有的无需提示的适应性方法虽然减轻了专家干预的需求，但仍存在鲁棒性和适应性不足的问题，且常忽略语义过平滑和标记均匀性问题。

Method: 提出了SAM-DCE模型，该模型在局部判别性和全局语义之间取得平衡，同时减轻标记均匀性问题，增强类间可分性，并通过细粒度、一致的表示丰富掩码解码。

Result: 在多样化的医学基准测试中，SAM-DCE表现出色，验证了其有效性。

Conclusion: SAM-DCE通过平衡局部判别性和全局语义，同时减轻标记均匀性问题，有效提升了医学图像分割的性能，并在多样化的医学基准测试中验证了其有效性。

Abstract: The Segment Anything Model (SAM) demonstrates impressive zero-shot
segmentation ability on natural images but encounters difficulties in medical
imaging due to domain shifts, anatomical variability, and its reliance on
user-provided prompts. Recent prompt-free adaptations alleviate the need for
expert intervention, yet still suffer from limited robustness and adaptability,
often overlooking the issues of semantic over-smoothing and token uniformity.
We propose SAM-DCE, which balances local discrimination and global semantics
while mitigating token uniformity, enhancing inter-class separability, and
enriching mask decoding with fine-grained, consistent representations.
Extensive experiments on diverse medical benchmarks validate its effectiveness.

</details>


### [76] [Rethinking Evaluation of Infrared Small Target Detection](https://arxiv.org/abs/2509.16888)
*Youwei Pang,Xiaoqi Zhao,Lihe Zhang,Huchuan Lu,Georges El Fakhri,Xiaofeng Liu,Shijian Lu*

Main category: cs.CV

TL;DR: 本文针对红外小目标检测评估协议的局限性，提出了混合级度量、系统误差分析方法和跨数据集评估，以促进更有效和鲁棒的模型发展。


<details>
  <summary>Details</summary>
Motivation: 当前的红外小目标检测评估协议存在局限性，包括依赖碎片化的像素级和目标级特定度量、过度强调整体性能分数而忽视关键错误分析，以及主要采用数据集特定的训练-测试范式。

Method: 提出了一种结合像素级和目标级性能的混合级度量，并开发了一种系统误差分析方法，同时强调跨数据集评估的重要性。

Result: 提出了一个更全面和合理的层次分析框架，并发布了开源工具包以促进标准化基准测试。

Conclusion: 本文通过引入混合级度量、系统误差分析方法和强调跨数据集评估的重要性，旨在提供一个更全面和合理的层次分析框架，最终促进更有效和鲁棒的IRSTD模型的发展。

Abstract: As an essential vision task, infrared small target detection (IRSTD) has seen
significant advancements through deep learning. However, critical limitations
in current evaluation protocols impede further progress. First, existing
methods rely on fragmented pixel- and target-level specific metrics, which
fails to provide a comprehensive view of model capabilities. Second, an
excessive emphasis on overall performance scores obscures crucial error
analysis, which is vital for identifying failure modes and improving real-world
system performance. Third, the field predominantly adopts dataset-specific
training-testing paradigms, hindering the understanding of model robustness and
generalization across diverse infrared scenarios. This paper addresses these
issues by introducing a hybrid-level metric incorporating pixel- and
target-level performance, proposing a systematic error analysis method, and
emphasizing the importance of cross-dataset evaluation. These aim to offer a
more thorough and rational hierarchical analysis framework, ultimately
fostering the development of more effective and robust IRSTD models. An
open-source toolkit has be released to facilitate standardized benchmarking.

</details>


### [77] [Learning from Gene Names, Expression Values and Images: Contrastive Masked Text-Image Pretraining for Spatial Transcriptomics Representation Learning](https://arxiv.org/abs/2509.16892)
*Jiahe Qian,Yaoyu Fang,Ziqiao Weng,Xinkun Wang,Lee A. Cooper,Bo Zhou*

Main category: cs.CV

TL;DR: CoMTIP是一种新型对比性掩码文本-图像预训练框架，通过结合图像、基因名称和表达值，显著提升空间转录组学任务的性能，并实现零样本预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖基因名称或表达值，忽略了基因分支的语义和数值关联，且仅关注图像-文本对齐，忽略了视觉线索。CoMTIP旨在解决这些问题，以提升空间转录组学的性能。

Method: CoMTIP采用对比性掩码文本-图像预训练框架，结合图像、基因名称和表达值，并通过掩码特征建模和基因文本编码器学习上下文感知的图像嵌入和基因-数值关联。

Result: 实验表明，CoMTIP在公共空间转录组学数据集上不仅超越现有方法，还实现了零样本基因表达预测。

Conclusion: CoMTIP框架在多种下游任务中表现优于现有方法，并实现了零样本基因表达预测，这是现有方法所不具备的能力。

Abstract: Spatial transcriptomics aims to connect high-resolution histology images with
spatially resolved gene expression. To achieve better performance on downstream
tasks such as gene expression prediction, large-scale pre-training is required
to obtain generalisable representations that can bridge histology and
transcriptomics across tissues, protocols, and laboratories. Existing
cross-modal pre-training approaches for spatial transcriptomics rely on either
gene names or expression values in isolation, which strips the gene branch of
essential semantics and breaks the association between each gene and its
quantitative magnitude. In addition, by restricting supervision to image-text
alignment, these methods ignore intrinsic visual cues that are critical for
learning robust image features. We present CoMTIP, the first Contrastive Masked
Text-Image Pretraining framework that jointly learns from images, gene names,
and expression values while capturing fine-grained visual context for spatial
transcriptomics. The vision branch uses Masked Feature Modeling to reconstruct
occluded patches and learn context-aware image embeddings. The text branch
applies a scalable Gene-Text Encoder that processes all gene sentences in
parallel, enriches each gene and its numerical value with dedicated embeddings,
and employs Pair-aware Adversarial Training (PAAT) to preserve correct
gene-value associations. Image and text representations are aligned in a shared
InfoNCE-optimised space. Experiments on public spatial transcriptomics datasets
show that CoMTIP not only surpasses previous methods on diverse downstream
tasks but also achieves zero-shot gene expression prediction, a capability that
existing approaches do not provide.

</details>


### [78] [PRISM: Precision-Recall Informed Data-Free Knowledge Distillation via Generative Diffusion](https://arxiv.org/abs/2509.16897)
*Xuewan He,Jielei Wang,Zihan Cheng,Yuchen Su,Shiyue Huang,Guoming Lu*

Main category: cs.CV

TL;DR: PRISM通过能量对齐和多样化提示解决数据自由知识蒸馏中的精度-召回率问题，提升大规模图像合成和知识转移效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在小规模图像上表现良好，但在大规模图像合成时易出现模式崩溃，且直接使用现成扩散模型生成数据面临精度-召回率挑战。

Method: 提出PRISM方法，包括能量引导的分布对齐（避免生成分布外样本）和多样化提示工程（增强对真实分布覆盖）。

Result: 在大规模图像数据集上的实验表明PRISM的优越性，且使用PRISM训练的模型表现出强大的领域泛化能力。

Conclusion: PRISM方法通过能量引导的分布对齐和多样化提示工程，有效解决了数据自由知识蒸馏中的精度-召回率挑战，显著提升了大规模图像合成的效果和知识转移性能。

Abstract: Data-free knowledge distillation (DFKD) transfers knowledge from a teacher to
a student without access to the real in-distribution (ID) data. While existing
methods perform well on small-scale images, they suffer from mode collapse when
synthesizing large-scale images, resulting in limited knowledge transfer.
Recently, leveraging advanced generative models to synthesize photorealistic
images has emerged as a promising alternative. Nevertheless, directly using
off-the-shelf diffusion to generate datasets faces the precision-recall
challenges: 1) ensuring synthetic data aligns with the real distribution, and
2) ensuring coverage of the real ID manifold. In response, we propose PRISM, a
precision-recall informed synthesis method. Specifically, we introduce
Energy-guided Distribution Alignment to avoid the generation of
out-of-distribution samples, and design the Diversified Prompt Engineering to
enhance coverage of the real ID manifold. Extensive experiments on various
large-scale image datasets demonstrate the superiority of PRISM. Moreover, we
demonstrate that models trained with PRISM exhibit strong domain
generalization.

</details>


### [79] [ME-Mamba: Multi-Expert Mamba with Efficient Knowledge Capture and Fusion for Multimodal Survival Analysis](https://arxiv.org/abs/2509.16900)
*Chengsheng Zhang,Linhao Qu,Xiaoyu Liu,Zhijian Song*

Main category: cs.CV

TL;DR: ME-Mamba系统通过多专家协作融合病理和基因组数据，实现了高效且准确的癌症生存分析。


<details>
  <summary>Details</summary>
Motivation: 病理图像通常仅提供幻灯片级标签，限制了从千兆像素WSIs中学习判别性表示的能力，多模态生存分析成为有前景的解决方案。

Method: 引入病理专家和基因组专家分别处理单模态数据，设计协同专家通过最优传输和最大均值差异进行模态融合。

Result: 在五个TCGA数据集上的实验证明了ME-Mamba的先进性能。

Conclusion: ME-Mamba系统通过多专家协作，实现了病理图像和基因组数据的有效融合，显著提高了癌症生存分析的准确性。

Abstract: Survival analysis using whole-slide images (WSIs) is crucial in cancer
research. Despite significant successes, pathology images typically only
provide slide-level labels, which hinders the learning of discriminative
representations from gigapixel WSIs. With the rapid advancement of
high-throughput sequencing technologies, multimodal survival analysis
integrating pathology images and genomics data has emerged as a promising
approach. We propose a Multi-Expert Mamba (ME-Mamba) system that captures
discriminative pathological and genomic features while enabling efficient
integration of both modalities. This approach achieves complementary
information fusion without losing critical information from individual
modalities, thereby facilitating accurate cancer survival analysis.
Specifically, we first introduce a Pathology Expert and a Genomics Expert to
process unimodal data separately. Both experts are designed with Mamba
architectures that incorporate conventional scanning and attention-based
scanning mechanisms, allowing them to extract discriminative features from long
instance sequences containing substantial redundant or irrelevant information.
Second, we design a Synergistic Expert responsible for modality fusion. It
explicitly learns token-level local correspondences between the two modalities
via Optimal Transport, and implicitly enhances distribution consistency through
a global cross-modal fusion loss based on Maximum Mean Discrepancy. The fused
feature representations are then passed to a mamba backbone for further
integration. Through the collaboration of the Pathology Expert, Genomics
Expert, and Synergistic Expert, our method achieves stable and accurate
survival analysis with relatively low computational complexity. Extensive
experimental results on five datasets in The Cancer Genome Atlas (TCGA)
demonstrate our state-of-the-art performance.

</details>


### [80] [SLAM-Former: Putting SLAM into One Transformer](https://arxiv.org/abs/2509.16909)
*Yijun Yuan,Zhuoguang Chen,Kenan Li,Weibang Wang,Hang Zhao*

Main category: cs.CV

TL;DR: SLAM-Former是一种集成前后端的Transformer架构，实验显示其在SLAM任务中性能优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统SLAM系统分模块设计导致的性能瓶颈，提出一种集成前后端功能的统一Transformer架构。

Method: SLAM-Former采用前端处理实时单目图像序列进行增量建图和跟踪，后端进行全局优化以确保几何一致性。前后端的交替执行相互促进，提升系统整体性能。

Result: 实验结果表明，SLAM-Former在密集SLAM任务中表现优于或与现有最先进方法相当。

Conclusion: SLAM-Former通过将前端和后端集成到一个Transformer中，实现了与传统SLAM系统相媲美甚至更优的性能。

Abstract: We present SLAM-Former, a novel neural approach that integrates full SLAM
capabilities into a single transformer. Similar to traditional SLAM systems,
SLAM-Former comprises both a frontend and a backend that operate in tandem. The
frontend processes sequential monocular images in real-time for incremental
mapping and tracking, while the backend performs global refinement to ensure a
geometrically consistent result. This alternating execution allows the frontend
and backend to mutually promote one another, enhancing overall system
performance. Comprehensive experimental results demonstrate that SLAM-Former
achieves superior or highly competitive performance compared to
state-of-the-art dense SLAM methods.

</details>


### [81] [Parameter-efficient fine-tuning (PEFT) of Vision Foundation Models for Atypical Mitotic Figure Classification](https://arxiv.org/abs/2509.16935)
*Lavish Ramchandani,Gunjan Deotale,Dev Kumar Das*

Main category: cs.CV

TL;DR: 研究利用大型视觉基础模型和LoRA进行非典型有丝分裂分类，最佳模型达到88.37%准确率，但需提升特异性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 非典型有丝分裂（AMFs）与肿瘤侵袭性和不良预后相关，但其检测因形态学特征细微、类别不平衡和病理学家间变异性而具有挑战性。MIDOG 2025挑战赛为此设立了专门赛道，以系统评估深度学习方法。

Method: 本研究探索了大型视觉基础模型（如Virchow、Virchow2和UNI）结合低秩适应（LoRA）进行参数高效微调的方法，并进行了不同LoRA秩和数据集划分（随机与基于组）的广泛实验。

Result: 最佳方法（Virchow结合LoRA秩8及三折交叉验证集成）在初步测试集上达到了88.37%的平衡准确率，在挑战赛排行榜中并列第9名。

Conclusion: 研究结果表明，基础模型结合高效适应策略（如LoRA）在非典型有丝分裂分类中具有潜力，但在特异性和领域泛化方面仍需改进。

Abstract: Atypical mitotic figures (AMFs) are rare abnormal cell divisions associated
with tumor aggressiveness and poor prognosis. Their detection remains a
significant challenge due to subtle morphological cues, class imbalance, and
inter-observer variability among pathologists. The MIDOG 2025 challenge
introduced a dedicated track for atypical mitosis classification, enabling
systematic evaluation of deep learning methods. In this study, we investigated
the use of large vision foundation models, including Virchow, Virchow2, and
UNI, with Low-Rank Adaptation (LoRA) for parameter-efficient fine-tuning. We
conducted extensive experiments with different LoRA ranks, as well as random
and group-based data splits, to analyze robustness under varied conditions. Our
best approach, Virchow with LoRA rank 8 and ensemble of three-fold
cross-validation, achieved a balanced accuracy of 88.37% on the preliminary
test set, ranking joint 9th in the challenge leaderboard. These results
highlight the promise of foundation models with efficient adaptation strategies
for the classification of atypical mitosis, while underscoring the need for
improvements in specificity and domain generalization.

</details>


### [82] [Prototype-Based Pseudo-Label Denoising for Source-Free Domain Adaptation in Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2509.16942)
*Bin Wang,Fei Deng,Zeyu Chen,Zhicheng Yu,Yiguang Liu*

Main category: cs.CV

TL;DR: ProSFDA利用原型引导的自训练和对比策略，有效减少伪标签噪声，提升遥感图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决源自由域适应中由于缺乏目标域真实标签而导致的伪标签噪声问题，从而更有效地缓解域偏移。

Method: 采用原型加权的伪标签进行可靠的自训练，并引入原型对比策略以促进同类特征的聚合。

Result: 实验表明，ProSFDA显著优于现有方法。

Conclusion: ProSFDA框架通过原型引导的自训练和原型对比策略，有效解决了源自由域适应中伪标签噪声问题，显著提升了遥感图像语义分割的性能。

Abstract: Source-Free Domain Adaptation (SFDA) enables domain adaptation for semantic
segmentation of Remote Sensing Images (RSIs) using only a well-trained source
model and unlabeled target domain data. However, the lack of ground-truth
labels in the target domain often leads to the generation of noisy
pseudo-labels. Such noise impedes the effective mitigation of domain shift
(DS). To address this challenge, we propose ProSFDA, a prototype-guided SFDA
framework. It employs prototype-weighted pseudo-labels to facilitate reliable
self-training (ST) under pseudo-labels noise. We, in addition, introduce a
prototype-contrast strategy that encourages the aggregation of features
belonging to the same class, enabling the model to learn discriminative target
domain representations without relying on ground-truth supervision. Extensive
experiments show that our approach substantially outperforms existing methods.

</details>


### [83] [Catching the Details: Self-Distilled RoI Predictors for Fine-Grained MLLM Perception](https://arxiv.org/abs/2509.16944)
*Yuheng Shi,Xiaohuan Pei,Minjing Dong,Chang Xu*

Main category: cs.CV

TL;DR: SD-RPN是一种高效、无标注的自蒸馏区域提议网络，通过优化注意力图生成伪RoI标签，显著提升MLLMs的细粒度感知能力，且在少量数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: MLLMs需要高分辨率视觉信息进行细粒度感知，但处理整张高分辨率图像计算成本高。现有RoI机制在训练依赖性和计算效率之间存在矛盾。

Method: SD-RPN通过将MLLM中间层的噪声注意力图转化为高质量伪RoI标签，训练轻量级区域提议网络（RPN），实现高效的单次前向传递RoI预测。

Result: 在LLaVA-1.5架构中集成SD-RPN后，仅需少量（如10K）问答对训练，便在TextVQA、DocVQA和V-Star等未见基准上实现了超过10%的绝对准确率提升。

Conclusion: 本文提出的SD-RPN方法通过自蒸馏机制和高效的区域提议网络，显著提升了MLLMs的细粒度感知能力，且无需大规模标注数据或完整模型微调，展示了卓越的数据效率和泛化能力。

Abstract: Multimodal Large Language Models (MLLMs) require high-resolution visual
information to perform fine-grained perception, yet processing entire
high-resolution images is computationally prohibitive. While recent methods
leverage a Region-of-Interest (RoI) mechanism to focus on salient areas, they
typically present a difficult trade-off: training-based approaches depend on
large-scale annotated datasets, while training-free methods that utilize the
model's internal attention are computationally inefficient and less accurate,
requiring either multi-pass prefill stages or reliance on the slow
auto-regressive decoding process. In this paper, we propose an efficient,
annotation-free Self-Distilled Region Proposal Network (SD-RPN) that resolves
this trade-off. The SD-RPN is built around a pipeline that transforms the noisy
attention maps from the MLLM's middle layers into high-quality pseudo-RoI
labels by explicitly denoising the signal and resolving ambiguity. We use these
labels to train a lightweight Region Proposal Network (RPN) that learns a more
precise localization. This RPN is also highly efficient, predicting the RoI in
a single forward pass using features from the MLLM's middle layers, decoupling
RoI identification from the auto-regressive generation and avoiding costly
multi-pass operations.To validate our approach, we integrate the framework into
the LLaVA-1.5 architecture. Despite being trained on only a few (e.g. 10K)
question-answer pairs, our method demonstrates exceptional data efficiency and
generalization, achieving over a 10% absolute accuracy improvement on unseen
benchmarks, including TextVQA, DocVQA, and V-Star. Our work presents a
practical and scalable solution for enhancing the fine-grained perception of
MLLMs without requiring costly supervision or full model fine-tuning. Code is
available at https://github.com/YuHengsss/SD-RPN.

</details>


### [84] [CoBEVMoE: Heterogeneity-aware Feature Fusion with Dynamic Mixture-of-Experts for Collaborative Perception](https://arxiv.org/abs/2509.17107)
*Lingzhao Kong,Jiacheng Lin,Siyu Li,Kai Luo,Zhiyong Li,Kailun Yang*

Main category: cs.CV

TL;DR: CoBEVMoE通过动态专家混合架构，有效融合异构观测，提升多智能体协同感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有中间融合方法主要关注对齐相似特征，忽略了智能体间的感知多样性。

Method: 提出了CoBEVMoE框架，结合了BEV空间和动态专家混合（DMoE）架构，通过动态生成的专家提取独特且可靠的线索，同时关注共享语义。

Result: 在OPV2V上，相机BEV分割的IoU提高了1.5%；在DAIR-V2X-C上，LiDAR 3D目标检测的AP@50提高了3.0%。

Conclusion: CoBEVMoE在OPV2V和DAIR-V2X-C数据集上实现了最先进的性能，验证了基于专家的异构特征建模在多智能体协同感知中的有效性。

Abstract: Collaborative perception aims to extend sensing coverage and improve
perception accuracy by sharing information among multiple agents. However, due
to differences in viewpoints and spatial positions, agents often acquire
heterogeneous observations. Existing intermediate fusion methods primarily
focus on aligning similar features, often overlooking the perceptual diversity
among agents. To address this limitation, we propose CoBEVMoE, a novel
collaborative perception framework that operates in the Bird's Eye View (BEV)
space and incorporates a Dynamic Mixture-of-Experts (DMoE) architecture. In
DMoE, each expert is dynamically generated based on the input features of a
specific agent, enabling it to extract distinctive and reliable cues while
attending to shared semantics. This design allows the fusion process to
explicitly model both feature similarity and heterogeneity across agents.
Furthermore, we introduce a Dynamic Expert Metric Loss (DEML) to enhance
inter-expert diversity and improve the discriminability of the fused
representation. Extensive experiments on the OPV2V and DAIR-V2X-C datasets
demonstrate that CoBEVMoE achieves state-of-the-art performance. Specifically,
it improves the IoU for Camera-based BEV segmentation by +1.5% on OPV2V and the
AP@50 for LiDAR-based 3D object detection by +3.0% on DAIR-V2X-C, verifying the
effectiveness of expert-based heterogeneous feature modeling in multi-agent
collaborative perception. The source code will be made publicly available at
https://github.com/godk0509/CoBEVMoE.

</details>


### [85] [Leveraging RGB Images for Pre-Training of Event-Based Hand Pose Estimation](https://arxiv.org/abs/2509.16949)
*Ruicong Liu,Takehiko Ohkawa,Tze Ho Elden Tse,Mingfang Zhang,Angela Yao,Yoichi Sato*

Main category: cs.CV

TL;DR: RPEP首次提出基于事件的3D手部姿态预训练方法，通过分解动作和运动反转约束生成伪事件数据，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决事件数据在3D手部姿态估计中因标注数据稀缺而受限的问题，利用RGB数据集生成伪事件数据。

Method: RPEP提出了一种新颖的伪事件生成策略，将手部动作分解为逐步运动，并引入运动反转约束来优化事件生成。

Result: 实验表明，RPEP在真实事件数据上比现有方法提升24%，且在少量标注样本下表现优异。

Conclusion: RPEP通过创新的伪事件生成策略和运动反转约束，显著提升了基于事件的3D手部姿态估计性能，尤其在真实事件数据上表现优异，且适用于实际部署。

Abstract: This paper presents RPEP, the first pre-training method for event-based 3D
hand pose estimation using labeled RGB images and unpaired, unlabeled event
data. Event data offer significant benefits such as high temporal resolution
and low latency, but their application to hand pose estimation is still limited
by the scarcity of labeled training data. To address this, we repurpose real
RGB datasets to train event-based estimators. This is done by constructing
pseudo-event-RGB pairs, where event data is generated and aligned with the
ground-truth poses of RGB images. Unfortunately, existing pseudo-event
generation techniques assume stationary objects, thus struggling to handle
non-stationary, dynamically moving hands. To overcome this, RPEP introduces a
novel generation strategy that decomposes hand movements into smaller,
step-by-step motions. This decomposition allows our method to capture temporal
changes in articulation, constructing more realistic event data for a moving
hand. Additionally, RPEP imposes a motion reversal constraint, regularizing
event generation using reversed motion. Extensive experiments show that our
pre-trained model significantly outperforms state-of-the-art methods on real
event data, achieving up to 24% improvement on EvRealHands. Moreover, it
delivers strong performance with minimal labeled samples for fine-tuning,
making it well-suited for practical deployment.

</details>


### [86] [DepTR-MOT: Unveiling the Potential of Depth-Informed Trajectory Refinement for Multi-Object Tracking](https://arxiv.org/abs/2509.17323)
*Buyin Deng,Lingxin Huang,Kai Luo,Fei Teng,Kailun Yang*

Main category: cs.CV

TL;DR: DepTR-MOT利用深度信息增强多目标跟踪，解决了遮挡和近距离交互问题，在机器人环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D线索的跟踪方法在机器人环境中因密集目标和频繁遮挡而不可靠，深度信息的潜力尚未充分开发。

Method: 基于DETR的检测器，结合实例级深度信息，提出两种创新策略：(i) 基于基础模型的实例级软深度标签监督，(ii) 密集深度图的蒸馏以保持全局深度一致性。

Result: 在QuadTrack和DanceTrack数据集上分别达到HOTA分数27.59和44.47，显著解决了遮挡和近距离交互的挑战。

Conclusion: DepTR-MOT通过引入深度信息，显著提升了多目标跟踪在遮挡和近距离交互场景下的鲁棒性，并在QuadTrack和DanceTrack数据集上取得了优异的HOTA分数。

Abstract: Visual Multi-Object Tracking (MOT) is a crucial component of robotic
perception, yet existing Tracking-By-Detection (TBD) methods often rely on 2D
cues, such as bounding boxes and motion modeling, which struggle under
occlusions and close-proximity interactions. Trackers relying on these 2D cues
are particularly unreliable in robotic environments, where dense targets and
frequent occlusions are common. While depth information has the potential to
alleviate these issues, most existing MOT datasets lack depth annotations,
leading to its underexploited role in the domain. To unveil the potential of
depth-informed trajectory refinement, we introduce DepTR-MOT, a DETR-based
detector enhanced with instance-level depth information. Specifically, we
propose two key innovations: (i) foundation model-based instance-level soft
depth label supervision, which refines depth prediction, and (ii) the
distillation of dense depth maps to maintain global depth consistency. These
strategies enable DepTR-MOT to output instance-level depth during inference,
without requiring foundation models and without additional computational cost.
By incorporating depth cues, our method enhances the robustness of the TBD
paradigm, effectively resolving occlusion and close-proximity challenges.
Experiments on both the QuadTrack and DanceTrack datasets demonstrate the
effectiveness of our approach, achieving HOTA scores of 27.59 and 44.47,
respectively. In particular, results on QuadTrack, a robotic platform MOT
dataset, highlight the advantages of our method in handling occlusion and
close-proximity challenges in robotic tracking. The source code will be made
publicly available at https://github.com/warriordby/DepTR-MOT.

</details>


### [87] [VidCLearn: A Continual Learning Approach for Text-to-Video Generation](https://arxiv.org/abs/2509.16956)
*Luca Zanchetta,Lorenzo Papa,Luca Maiano,Irene Amerini*

Main category: cs.CV

TL;DR: VidCLearn 是一种持续学习的文本到视频生成框架，通过师生架构和新增模块提升模型性能，避免从头训练。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成模型依赖静态知识，难以融入新数据而不从头训练。

Method: 提出 VidCLearn，一种基于扩散模型的持续学习框架，采用师生架构（学生模型逐步更新，教师模型通过生成重放保留旧知识），并引入时间一致性损失和视频检索模块。

Result: 实验结果表明，VidCLearn 在视觉质量、语义对齐和时间一致性上优于基线方法。

Conclusion: VidCLearn 通过持续学习框架成功解决了现有文本到视频生成模型难以融入新数据的问题，并在视觉质量、语义对齐和时间一致性方面优于基线方法。

Abstract: Text-to-video generation is an emerging field in generative AI, enabling the
creation of realistic, semantically accurate videos from text prompts. While
current models achieve impressive visual quality and alignment with input text,
they typically rely on static knowledge, making it difficult to incorporate new
data without retraining from scratch. To address this limitation, we propose
VidCLearn, a continual learning framework for diffusion-based text-to-video
generation. VidCLearn features a student-teacher architecture where the student
model is incrementally updated with new text-video pairs, and the teacher model
helps preserve previously learned knowledge through generative replay.
Additionally, we introduce a novel temporal consistency loss to enhance motion
smoothness and a video retrieval module to provide structural guidance at
inference. Our architecture is also designed to be more computationally
efficient than existing models while retaining satisfactory generation
performance. Experimental results show VidCLearn's superiority over baseline
methods in terms of visual quality, semantic alignment, and temporal coherence.

</details>


### [88] [EmbodiedSplat: Personalized Real-to-Sim-to-Real Navigation with Gaussian Splats from a Mobile Device](https://arxiv.org/abs/2509.17430)
*Gunjan Chhablani,Xiaomeng Ye,Muhammad Zubair Irshad,Zsolt Kira*

Main category: cs.CV

TL;DR: EmbodiedSplat通过GS和Habitat-Sim，用iPhone捕获场景重建网格，显著提升sim-to-real效果，在真实任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前Embodied AI领域依赖仿真训练，但合成环境缺乏真实感或高保真实世界重建成本高，导致sim-to-real转移困难。

Method: 利用3D Gaussian Splatting (GS)和Habitat-Sim模拟器，结合iPhone捕获的场景，重建网格以创建接近真实世界的训练环境。

Result: 实验表明，EmbodiedSplat微调的智能体在真实世界图像导航任务中，比基线方法（HM3D和HSSD）分别提高了20%和40%的成功率，且sim-vs-real相关性高达0.87-0.97。

Conclusion: EmbodiedSplat通过高效捕获部署环境并在重建场景中微调策略，显著提高了sim-to-real的转移效果，在真实世界图像导航任务中表现优异。

Abstract: The field of Embodied AI predominantly relies on simulation for training and
evaluation, often using either fully synthetic environments that lack
photorealism or high-fidelity real-world reconstructions captured with
expensive hardware. As a result, sim-to-real transfer remains a major
challenge. In this paper, we introduce EmbodiedSplat, a novel approach that
personalizes policy training by efficiently capturing the deployment
environment and fine-tuning policies within the reconstructed scenes. Our
method leverages 3D Gaussian Splatting (GS) and the Habitat-Sim simulator to
bridge the gap between realistic scene capture and effective training
environments. Using iPhone-captured deployment scenes, we reconstruct meshes
via GS, enabling training in settings that closely approximate real-world
conditions. We conduct a comprehensive analysis of training strategies,
pre-training datasets, and mesh reconstruction techniques, evaluating their
impact on sim-to-real predictivity in real-world scenarios. Experimental
results demonstrate that agents fine-tuned with EmbodiedSplat outperform both
zero-shot baselines pre-trained on large-scale real-world datasets (HM3D) and
synthetically generated datasets (HSSD), achieving absolute success rate
improvements of 20\% and 40\% on real-world Image Navigation task. Moreover,
our approach yields a high sim-vs-real correlation (0.87--0.97) for the
reconstructed meshes, underscoring its effectiveness in adapting policies to
diverse environments with minimal effort. Project page:
https://gchhablani.github.io/embodied-splat

</details>


### [89] [MO R-CNN: Multispectral Oriented R-CNN for Object Detection in Remote Sensing Image](https://arxiv.org/abs/2509.16957)
*Leiyu Wang,Biao Jin,Feng Huang,Liqiong Chen,Zhengyong Wang,Xiaohai He,Honggang Chen*

Main category: cs.CV

TL;DR: MO R-CNN是一个轻量级多光谱定向检测框架，通过异构特征提取、单模态监督和条件标签融合提升性能，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 多光谱图像的定向目标检测面临模态内和模态间差异的挑战，现有方法因高计算复杂度和内存消耗受限，受大核卷积在遥感中的成功启发，提出轻量级解决方案。

Method: 提出了MO R-CNN框架，包括异构特征提取网络（HFEN）、单模态监督（SMS）和基于条件的多模态标签融合（CMLF）。HFEN利用模态间差异自适应对齐、合并和增强多模态特征；SMS约束多尺度特征并支持多模态学习；CMLF基于特定规则融合多模态标签。

Result: 实验证明MO R-CNN在多个数据集上优于现有方法。

Conclusion: MO R-CNN在DroneVehicle、VEDAI和OGSOD数据集上证明了其优越性，源代码已开源。

Abstract: Oriented object detection for multi-spectral imagery faces significant
challenges due to differences both within and between modalities. Although
existing methods have improved detection accuracy through complex network
architectures, their high computational complexity and memory consumption
severely restrict their performance. Motivated by the success of large kernel
convolutions in remote sensing, we propose MO R-CNN, a lightweight framework
for multi-spectral oriented detection featuring heterogeneous feature
extraction network (HFEN), single modality supervision (SMS), and
condition-based multimodal label fusion (CMLF). HFEN leverages inter-modal
differences to adaptively align, merge, and enhance multi-modal features. SMS
constrains multi-scale features and enables the model to learn from multiple
modalities. CMLF fuses multimodal labels based on specific rules, providing the
model with a more robust and consistent supervisory signal. Experiments on the
DroneVehicle, VEDAI and OGSOD datasets prove the superiority of our method. The
source code is available at:https://github.com/Iwill-github/MORCNN.

</details>


### [90] [VideoArtGS: Building Digital Twins of Articulated Objects from Monocular Video](https://arxiv.org/abs/2509.17647)
*Yu Liu,Baoxiong Jia,Ruijie Lu,Chuyue Gan,Huayu Chen,Junfeng Ni,Song-Chun Zhu,Siyuan Huang*

Main category: cs.CV

TL;DR: VideoArtGS 是一种从单目视频重建关节物体数字孪生体的新方法，通过运动先验和混合模块显著提升了重建精度。


<details>
  <summary>Details</summary>
Motivation: 从单目视频构建关节物体的数字孪生体是一个重要但具有挑战性的任务，因为需要同时重建几何、部分分割和关节参数，而视觉监督难以解耦几何和部分动态。

Method: VideoArtGS 结合了运动先验引导管道和混合中心网格部分分配模块，用于优化关节参数初始化和捕捉精确的部分运动。

Result: VideoArtGS 在关节和网格重建方面表现优异，重建误差比现有方法降低了约两个数量级。

Conclusion: VideoArtGS 提出了一种新颖的方法，通过单目视频重建高保真数字孪生体，显著降低了重建误差，并在视频驱动的关节物体重建领域设立了新标准。

Abstract: Building digital twins of articulated objects from monocular video presents
an essential challenge in computer vision, which requires simultaneous
reconstruction of object geometry, part segmentation, and articulation
parameters from limited viewpoint inputs. Monocular video offers an attractive
input format due to its simplicity and scalability; however, it's challenging
to disentangle the object geometry and part dynamics with visual supervision
alone, as the joint movement of the camera and parts leads to ill-posed
estimation. While motion priors from pre-trained tracking models can alleviate
the issue, how to effectively integrate them for articulation learning remains
largely unexplored. To address this problem, we introduce VideoArtGS, a novel
approach that reconstructs high-fidelity digital twins of articulated objects
from monocular video. We propose a motion prior guidance pipeline that analyzes
3D tracks, filters noise, and provides reliable initialization of articulation
parameters. We also design a hybrid center-grid part assignment module for
articulation-based deformation fields that captures accurate part motion.
VideoArtGS demonstrates state-of-the-art performance in articulation and mesh
reconstruction, reducing the reconstruction error by about two orders of
magnitude compared to existing methods. VideoArtGS enables practical digital
twin creation from monocular video, establishing a new benchmark for
video-based articulated object reconstruction. Our work is made publicly
available at: https://videoartgs.github.io.

</details>


### [91] [Penalizing Boundary Activation for Object Completeness in Diffusion Models](https://arxiv.org/abs/2509.16968)
*Haoyang Xu,Tianhao Zhao,Sibei Yang,Yutian Li*

Main category: cs.CV

TL;DR: 通过惩罚早期去噪步骤中的边界激活值，解决了扩散模型中对象不完整的问题，适用于预训练模型且计算开销小。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在文本到图像生成中表现出色，但对象不完整的问题限制了其在下游应用中的性能。研究发现，RandomCrop数据增强方法是导致对象不完整的主要原因。

Method: 提出了一种训练无关的解决方案，即在早期去噪步骤中惩罚图像边界的激活值。该方法对预训练的Stable Diffusion模型仅需极小修改。

Result: 实验证明，该方法显著提高了对象完整性和图像质量。

Conclusion: 本文提出了一种无需训练的方法，通过惩罚早期去噪步骤中图像边界的激活值，有效解决了扩散模型中对象不完整的问题。该方法适用于预训练的Stable Diffusion模型，且计算开销极小。

Abstract: Diffusion models have emerged as a powerful technique for text-to-image (T2I)
generation, creating high-quality, diverse images across various domains.
However, a common limitation in these models is the incomplete display of
objects, where fragments or missing parts undermine the model's performance in
downstream applications. In this study, we conduct an in-depth analysis of the
incompleteness issue and reveal that the primary factor behind incomplete
object generation is the usage of RandomCrop during model training. This widely
used data augmentation method, though enhances model generalization ability,
disrupts object continuity during training. To address this, we propose a
training-free solution that penalizes activation values at image boundaries
during the early denoising steps. Our method is easily applicable to
pre-trained Stable Diffusion models with minimal modifications and negligible
computational overhead. Extensive experiments demonstrate the effectiveness of
our method, showing substantial improvements in object integrity and image
quality.

</details>


### [92] [DINOv3-Diffusion Policy: Self-Supervised Large Visual Model for Visuomotor Diffusion Policy Learning](https://arxiv.org/abs/2509.17684)
*ThankGod Egbe,Peng Wang,Zhihao Guo,Zidong Chen*

Main category: cs.CV

TL;DR: DINOv3作为自监督视觉主干，在机器人操作任务中表现优于或匹配传统监督式预训练模型，尤其在微调模式下表现最佳，展示了自监督特征的优势。


<details>
  <summary>Details</summary>
Motivation: 评估DINOv3这一大规模自监督视觉主干在机器人操作中的视觉运动扩散策略学习中的表现，并探讨纯自监督编码器是否能与传统的监督式ImageNet预训练主干（如ResNet-18）相媲美或超越。

Method: 通过在四个基准任务（Push-T、Lift、Can、Square）中使用统一的FiLM条件扩散策略，比较了自监督编码器DINOv3与监督式ImageNet预训练主干（如ResNet-18）在三种训练模式下的表现：从头训练、冻结和微调。

Result: 研究发现：（i）微调的DINOv3在多项任务中匹配或超过ResNet-18；（ii）冻结的DINOv3仍具竞争力，表明其强大的可迁移先验；（iii）自监督特征提高了样本效率和鲁棒性。与使用ResNet18作为主干相比，DINOv3在Can等挑战性任务中实现了最高10%的绝对测试成功率提升，在Lift、PushT和Square等任务中表现相当。

Conclusion: 研究结果表明，自监督的大型视觉模型（如DINOv3）可以作为动作扩散策略的有效、可泛化的感知前端，为机器人操作中的无标签预训练提供了进一步探索的动机。

Abstract: This paper evaluates DINOv3, a recent large-scale self-supervised vision
backbone, for visuomotor diffusion policy learning in robotic manipulation. We
investigate whether a purely self-supervised encoder can match or surpass
conventional supervised ImageNet-pretrained backbones (e.g., ResNet-18) under
three regimes: training from scratch, frozen, and finetuned. Across four
benchmark tasks (Push-T, Lift, Can, Square) using a unified FiLM-conditioned
diffusion policy, we find that (i) finetuned DINOv3 matches or exceeds
ResNet-18 on several tasks, (ii) frozen DINOv3 remains competitive, indicating
strong transferable priors, and (iii) self-supervised features improve sample
efficiency and robustness. These results support self-supervised large visual
models as effective, generalizable perceptual front-ends for action diffusion
policies, motivating further exploration of scalable label-free pretraining in
robotic manipulation. Compared to using ResNet18 as a backbone, our approach
with DINOv3 achieves up to a 10% absolute increase in test-time success rates
on challenging tasks such as Can, and on-the-par performance in tasks like
Lift, PushT, and Square.

</details>


### [93] [LLM-Assisted Semantic Guidance for Sparsely Annotated Remote Sensing Object Detection](https://arxiv.org/abs/2509.16970)
*Wei Liao,Chunyan Xu,Chenxu Wang,Zhen Cui*

Main category: cs.CV

TL;DR: LLM辅助语义引导框架通过类感知伪标签分配和自适应硬负样本重加权，提升了稀疏标注遥感目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏标注在遥感目标检测中的挑战，如密集目标分布和类别不平衡，以及现有密集伪标签方法的选择模糊性和置信度估计不一致问题。

Method: 引入LLM辅助的语义引导框架，结合类感知密集伪标签分配机制和自适应硬负样本重加权模块。

Result: 在DOTA和HRSC2016数据集上的实验表明，该方法显著提升了稀疏标注下的检测性能。

Conclusion: 提出的LLM辅助语义引导框架显著提升了稀疏标注下的遥感目标检测性能，优于现有单阶段检测器框架。

Abstract: Sparse annotation in remote sensing object detection poses significant
challenges due to dense object distributions and category imbalances. Although
existing Dense Pseudo-Label methods have demonstrated substantial potential in
pseudo-labeling tasks, they remain constrained by selection ambiguities and
inconsistencies in confidence estimation.In this paper, we introduce an
LLM-assisted semantic guidance framework tailored for sparsely annotated remote
sensing object detection, exploiting the advanced semantic reasoning
capabilities of large language models (LLMs) to distill high-confidence
pseudo-labels.By integrating LLM-generated semantic priors, we propose a
Class-Aware Dense Pseudo-Label Assignment mechanism that adaptively assigns
pseudo-labels for both unlabeled and sparsely labeled data, ensuring robust
supervision across varying data distributions. Additionally, we develop an
Adaptive Hard-Negative Reweighting Module to stabilize the supervised learning
branch by mitigating the influence of confounding background information.
Extensive experiments on DOTA and HRSC2016 demonstrate that the proposed method
outperforms existing single-stage detector-based frameworks, significantly
improving detection performance under sparse annotations.

</details>


### [94] [The 1st Solution for 7th LSVOS RVOS Track: SaSaSa2VA](https://arxiv.org/abs/2509.16972)
*Quanzhu Niu,Dengxian Gong,Shihao Chen,Tao Zhang,Yikang Zhou,Haobo Yuan,Lu Qi,Xiangtai Li,Shunping Ji*

Main category: cs.CV

TL;DR: SaSaSa2VA方法通过分割增强和测试时集成优化了RVOS任务，在LSVOS挑战赛中表现最佳。


<details>
  <summary>Details</summary>
Motivation: RVOS任务需要细粒度的外观和运动理解，但现有方法存在稀疏帧采样和单一[SEG]标记依赖的瓶颈。

Method: 在Sa2VA基础上，结合多模态大语言模型(MLLM)和视频分割模型SAM2，提出SaSaSa2VA方法，通过分割增强和选择性平均优化。

Result: 在LSVOS挑战赛(RVOS赛道)中，SaSaSa2VA以67.45的J&F得分排名第一，领先第二名2.80分。

Conclusion: 通过提出的Segmentation Augmented and Selective Averaged Sa2VA (SaSaSa2VA)方法，解决了稀疏帧采样和单一[SEG]标记依赖的问题，显著提升了RVOS任务的性能。

Abstract: Referring video object segmentation (RVOS) requires segmenting and tracking
objects in videos conditioned on natural-language expressions, demanding
fine-grained understanding of both appearance and motion. Building on Sa2VA,
which couples a Multi-modal Large Language Model (MLLM) with the video
segmentation model SAM2, we identify two key bottlenecks that limit
segmentation performance: sparse frame sampling and reliance on a single [SEG]
token for an entire video. We propose Segmentation Augmented and Selective
Averaged Sa2VA SaSaSa2VA to address these issues. On the 7th LSVOS Challenge
(RVOS track), SaSaSa2VA achieves a $J\&F$ of 67.45, ranking first and
surpassing the runner-up by 2.80 points. This result and ablation studies
demonstrate that efficient segmentation augmentation and test-time ensembling
substantially enhance grounded MLLMs for RVOS. The code is released in Sa2VA
repository: https://github.com/magic-research/Sa2VA.

</details>


### [95] [Optimal Transport for Handwritten Text Recognition in a Low-Resource Regime](https://arxiv.org/abs/2509.16977)
*Petros Georgoulas Wraight,Giorgos Sfikas,Ioannis Kordonis,Petros Maragos,George Retsinas*

Main category: cs.CV

TL;DR: 提出一种利用词汇先验知识的迭代视觉-语义对齐框架，通过最优传输和伪标签生成，有效提升低资源手写文本识别的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有HTR方法依赖大量标注数据的问题，适用于历史档案或小型现代文集等低资源领域。

Method: 采用基于最优传输（OT）的迭代自举方法，将从未标注图像中提取的视觉特征与语义词表示对齐，并通过生成高置信度伪标签逐步扩充训练集。

Result: 数值实验表明，该框架在低资源HTR基准测试中显著提高了识别准确率。

Conclusion: 该论文提出的迭代视觉-语义对齐框架显著提升了低资源手写文本识别（HTR）任务的准确性，证明了其在标注数据稀缺场景下的有效性。

Abstract: Handwritten Text Recognition (HTR) is a task of central importance in the
field of document image understanding. State-of-the-art methods for HTR require
the use of extensive annotated sets for training, making them impractical for
low-resource domains like historical archives or limited-size modern
collections. This paper introduces a novel framework that, unlike the standard
HTR model paradigm, can leverage mild prior knowledge of lexical
characteristics; this is ideal for scenarios where labeled data are scarce. We
propose an iterative bootstrapping approach that aligns visual features
extracted from unlabeled images with semantic word representations using
Optimal Transport (OT). Starting with a minimal set of labeled examples, the
framework iteratively matches word images to text labels, generates
pseudo-labels for high-confidence alignments, and retrains the recognizer on
the growing dataset. Numerical experiments demonstrate that our iterative
visual-semantic alignment scheme significantly improves recognition accuracy on
low-resource HTR benchmarks.

</details>


### [96] [VCE: Safe Autoregressive Image Generation via Visual Contrast Exploitation](https://arxiv.org/abs/2509.16986)
*Feng Han,Chao Gong,Zhipeng Wei,Jingjing Chen,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: VCE框架通过对比图像对和DPO训练，解决了自回归模型中的不安全内容擦除问题，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 自回归图像生成模型（如GPT-4o和LlamaGen）能够生成逼真图像，但也可能产生NSFW内容，引发版权和伦理问题。目前针对此类模型的安全防护方法尚未充分探索。

Method: VCE框架包含两个主要部分：创新的对比图像对构造范式，用于精确解耦不安全概念与其相关语义；以及基于DPO的训练方法，增强模型识别和利用图像对中的对比特征的能力。

Result: 在艺术家风格擦除、显式内容擦除和对象移除三个任务中，VCE方法均表现出色，有效擦除不安全概念并保持安全概念的完整性。

Conclusion: 本文提出的Visual Contrast Exploitation（VCE）框架通过对比图像对构造和DPO训练方法，有效解决了自回归图像生成模型中的不安全概念擦除问题，并在实验中取得了最先进的效果。

Abstract: Recently, autoregressive image generation models have wowed audiences with
their remarkable capability in creating surprisingly realistic images. Models
such as GPT-4o and LlamaGen can not only produce images that faithfully mimic
renowned artistic styles like Ghibli, Van Gogh, or Picasso, but also
potentially generate Not-Safe-For-Work (NSFW) content, raising significant
concerns regarding copyright infringement and ethical use. Despite these
concerns, methods to safeguard autoregressive text-to-image models remain
underexplored. Previous concept erasure methods, primarily designed for
diffusion models that operate in denoising latent space, are not directly
applicable to autoregressive models that generate images token by token. To
address this critical gap, we propose Visual Contrast Exploitation (VCE), a
novel framework comprising: (1) an innovative contrastive image pair
construction paradigm that precisely decouples unsafe concepts from their
associated content semantics, and (2) a sophisticated DPO-based training
approach that enhances the model's ability to identify and leverage visual
contrastive features from image pairs, enabling precise concept erasure. Our
comprehensive experiments across three challenging tasks-artist style erasure,
explicit content erasure, and object removal-demonstrate that our method
effectively secures the model, achieving state-of-the-art results while erasing
unsafe concepts and maintaining the integrity of unrelated safe concepts. The
code and models are available at https://github.com/Maplebb/VCE.

</details>


### [97] [A Cross-Hierarchical Multi-Feature Fusion Network Based on Multiscale Encoder-Decoder for Hyperspectral Change Detection](https://arxiv.org/abs/2509.16988)
*Mingshuai Sheng,Bhatti Uzair Aslam,Junfeng Zhang,Siling Feng,Yonis Gulzar*

Main category: cs.CV

TL;DR: 本文提出了一种跨层次多特征融合网络（CHMFFN），通过多尺度编码器-解码器架构和多个创新模块（如DCCSA、STCFL和AFAF），有效解决了高光谱变化检测中多尺度特征利用不足和差异特征融合效率低的问题，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 高光谱变化检测（HCD）旨在准确识别同一区域在不同时间获取的高光谱图像中的土地覆盖变化，在环境监测和灾害评估中有重要应用。现有方法存在多尺度特征利用不足和差异特征融合效率低等局限性。

Method: 本文提出了一种基于多尺度编码器-解码器架构的跨层次多特征融合网络（CHMFFN）。前端采用多尺度特征提取子网络，结合残差连接和双核通道-空间注意力模块（DCCSA）来提取光谱-空间-时间特征（SSTF）。编码器通过残差块和不同感受野的卷积核捕获从浅层细节到深层语义的多尺度特征。解码器通过跳过连接整合编码器特征，恢复空间分辨率并抑制噪声信息。此外，光谱-时间变化特征学习（STCFL）模块在不同层次学习跨时间变化特征，强化跨时间差异捕捉。自适应融合高级特征（AFAF）模块通过自适应权重动态平衡层次差异特征，增强复杂变化的表示。

Result: CHMFFN在四个公开高光谱数据集上的实验表现优于现有最先进方法。

Conclusion: CHMFFN在四个公开高光谱数据集上的实验表明，其性能优于现有最先进方法，验证了其有效性。

Abstract: Hyperspectral change detection (HCD) aims to accurately identify land-cover
changes in hyperspectral images of the same area acquired at different times,
with key applications in environmental monitoring and disaster assessment. To
address limitations of existing methods, such as insufficient use of multiscale
features and low efficiency in differential feature fusion, this paper proposes
a cross-hierarchical multi-feature fusion network (CHMFFN) based on a
multiscale encoder-decoder architecture. The front-end adopts a multiscale
feature extraction subnetwork, built on an encoder-decoder backbone with
residual connections and a dual-core channel-spatial attention (DCCSA) module
to extract spectral-spatial-temporal features (SSTF). The encoder captures
multiscale features from shallow details to deep semantics via residual blocks
and convolutional kernels with varying receptive fields. The decoder restores
spatial resolution and suppresses noise information through skip connections
integrating encoder features. Additionally, a spectral-temporal change feature
learning (STCFL) module learns cross-temporal change features at different
levels, strengthening inter-temporal difference capture. An adaptive fusion of
advanced features (AFAF) module dynamically balances hierarchical differential
features via adaptive weights, enhancing representation of complex changes.
Experiments on four public hyperspectral datasets show CHMFFN outperforms
state-of-the-art methods, verifying its effectiveness.

</details>


### [98] [DocIQ: A Benchmark Dataset and Feature Fusion Network for Document Image Quality Assessment](https://arxiv.org/abs/2509.17012)
*Zhichao Ma,Fan Huang,Lu Zhao,Fengjun Guo,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: 本文介绍了DIQA-5000数据集和一个专门的无参考DIQA模型，该模型利用文档布局特征和多级特征融合，在多个质量维度上优于现有通用IQA模型。


<details>
  <summary>Details</summary>
Motivation: 文档图像质量评估（DIQA）是光学字符识别（OCR）、文档修复和文档图像处理系统评估等多种应用的重要组成部分。

Method: 提出了一种专门的无参考DIQA模型，利用文档布局特征在降低分辨率时保持质量感知以减少计算成本。设计了一个特征融合模块来提取和整合文档图像的多级特征，并为每个质量维度使用独立的质量头来预测分数分布。

Result: 提出的方法在DIQA-5000数据集和另一个专注于OCR准确率的文档图像数据集上优于当前最先进的通用IQA模型。

Conclusion: 实验结果表明，该方法在DIQA-5000数据集和另一个专注于OCR准确率的文档图像数据集上优于当前最先进的通用IQA模型。

Abstract: Document image quality assessment (DIQA) is an important component for
various applications, including optical character recognition (OCR), document
restoration, and the evaluation of document image processing systems. In this
paper, we introduce a subjective DIQA dataset DIQA-5000. The DIQA-5000 dataset
comprises 5,000 document images, generated by applying multiple document
enhancement techniques to 500 real-world images with diverse distortions. Each
enhanced image was rated by 15 subjects across three rating dimensions: overall
quality, sharpness, and color fidelity. Furthermore, we propose a specialized
no-reference DIQA model that exploits document layout features to maintain
quality perception at reduced resolutions to lower computational cost.
Recognizing that image quality is influenced by both low-level and high-level
visual features, we designed a feature fusion module to extract and integrate
multi-level features from document images. To generate multi-dimensional
scores, our model employs independent quality heads for each dimension to
predict score distributions, allowing it to learn distinct aspects of document
image quality. Experimental results demonstrate that our method outperforms
current state-of-the-art general-purpose IQA models on both DIQA-5000 and an
additional document image dataset focused on OCR accuracy.

</details>


### [99] [When Color-Space Decoupling Meets Diffusion for Adverse-Weather Image Restoration](https://arxiv.org/abs/2509.17024)
*Wenxuan Fang,Jili Fan,Chao Wang,Xiantao Hu,Jiangwei Weng,Ying Tai,Jian Yang,Jun Li*

Main category: cs.CV

TL;DR: LCDiff通过亮度和色度分解及引导扩散模型，有效恢复恶劣天气图像，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气图像恢复（AWIR）因天气退化的不可预测性和动态性而极具挑战性，传统方法难以泛化到未见或复杂退化类型，而现有提示学习方法依赖视觉语言模型的退化估计能力，导致恢复结果不一致。

Method: LCDiff框架包含两个关键组件：Lumina-Chroma分解网络（LCDN）处理YCbCr颜色空间中的图像，分离处理亮度和色度；Lumina引导扩散模型（LGDM）利用亮度信息作为引导条件，无需显式退化提示。

Result: 实验表明，LCDiff在恶劣天气图像恢复任务中超越了现有方法，并提出了DriveWeather数据集以支持鲁棒评估。

Conclusion: LCDiff框架通过Lumina-Chroma分解网络和Lumina引导扩散模型，有效解决了恶劣天气图像恢复的挑战，并在实验中超越了现有方法。

Abstract: Adverse Weather Image Restoration (AWIR) is a highly challenging task due to
the unpredictable and dynamic nature of weather-related degradations.
Traditional task-specific methods often fail to generalize to unseen or complex
degradation types, while recent prompt-learning approaches depend heavily on
the degradation estimation capabilities of vision-language models, resulting in
inconsistent restorations. In this paper, we propose \textbf{LCDiff}, a novel
framework comprising two key components: \textit{Lumina-Chroma Decomposition
Network} (LCDN) and \textit{Lumina-Guided Diffusion Model} (LGDM). LCDN
processes degraded images in the YCbCr color space, separately handling
degradation-related luminance and degradation-invariant chrominance components.
This decomposition effectively mitigates weather-induced degradation while
preserving color fidelity. To further enhance restoration quality, LGDM
leverages degradation-related luminance information as a guiding condition,
eliminating the need for explicit degradation prompts. Additionally, LGDM
incorporates a \textit{Dynamic Time Step Loss} to optimize the denoising
network, ensuring a balanced recovery of both low- and high-frequency features
in the image. Finally, we present DriveWeather, a comprehensive all-weather
driving dataset designed to enable robust evaluation. Extensive experiments
demonstrate that our approach surpasses state-of-the-art methods, setting a new
benchmark in AWIR. The dataset and code are available at:
https://github.com/fiwy0527/LCDiff.

</details>


### [100] [Efficient 3D Scene Reconstruction and Simulation from Sparse Endoscopic Views](https://arxiv.org/abs/2509.17027)
*Zhenya Yang*

Main category: cs.CV

TL;DR: 提出高斯泼溅框架结合虚拟相机正则化，解决内窥镜视角受限问题，实现高效手术场景重建与实时物理模拟。


<details>
  <summary>Details</summary>
Motivation: 传统手术模拟方法构建复杂、耗时且难以扩展，导致细节不足和模拟不真实。本研究旨在通过内窥镜数据直接重建交互式手术场景，提高效率、渲染质量和真实感。

Method: 提出基于高斯泼溅的框架，结合虚拟相机正则化和深度正则化技术，以及稀疏控制节点材料点方法，用于手术场景的重建和物理模拟。

Result: 实验结果表明，该方法能在稀疏内窥镜视图下高效重建手术场景，并在几分钟内完成重建，实现实时物理变形模拟。

Conclusion: 该方法通过高斯泼溅框架和虚拟相机正则化技术，有效解决了内窥镜数据视角受限导致的几何精度下降问题，实现了高效、高质量的手术场景重建与实时物理模拟。

Abstract: Surgical simulation is essential for medical training, enabling practitioners
to develop crucial skills in a risk-free environment while improving patient
safety and surgical outcomes. However, conventional methods for building
simulation environments are cumbersome, time-consuming, and difficult to scale,
often resulting in poor details and unrealistic simulations. In this paper, we
propose a Gaussian Splatting-based framework to directly reconstruct
interactive surgical scenes from endoscopic data while ensuring efficiency,
rendering quality, and realism. A key challenge in this data-driven simulation
paradigm is the restricted movement of endoscopic cameras, which limits
viewpoint diversity. As a result, the Gaussian Splatting representation
overfits specific perspectives, leading to reduced geometric accuracy. To
address this issue, we introduce a novel virtual camera-based regularization
method that adaptively samples virtual viewpoints around the scene and
incorporates them into the optimization process to mitigate overfitting. An
effective depth-based regularization is applied to both real and virtual views
to further refine the scene geometry. To enable fast deformation simulation, we
propose a sparse control node-based Material Point Method, which integrates
physical properties into the reconstructed scene while significantly reducing
computational costs. Experimental results on representative surgical data
demonstrate that our method can efficiently reconstruct and simulate surgical
scenes from sparse endoscopic views. Notably, our method takes only a few
minutes to reconstruct the surgical scene and is able to produce physically
plausible deformations in real-time with user-defined interactions.

</details>


### [101] [From Easy to Hard: The MIR Benchmark for Progressive Interleaved Multi-Image Reasoning](https://arxiv.org/abs/2509.17040)
*Hang Du,Jiayang Zhang,Guoshun Nan,Wendi Deng,Zhenyan Chen,Chenyang Zhang,Wang Xiao,Shan Huang,Yuqi Pan,Tao Qi,Sicong Leng*

Main category: cs.CV

TL;DR: MIR基准通过多图像交错推理任务和课程学习策略，显著提升MLLMs的复杂场景理解和跨模态关联能力。


<details>
  <summary>Details</summary>
Motivation: 当前多图像基准忽视交错文本上下文及图像与文本间的独特关系，限制了模型在复杂场景中的推理能力。

Method: 提出了一种阶段式课程学习策略，采用‘从易到难’的方法逐步提升模型处理复杂任务的能力。

Result: 实验表明，该方法显著提升了MLLMs在MIR及其他基准上的推理性能。

Conclusion: MIR基准通过引入多图像交错推理任务，显著提升了多模态大语言模型（MLLMs）在复杂场景中的理解和跨模态关联能力。

Abstract: Multi-image Interleaved Reasoning aims to improve Multi-modal Large Language
Models (MLLMs) ability to jointly comprehend and reason across multiple images
and their associated textual contexts, introducing unique challenges beyond
single-image or non-interleaved multi-image tasks. While current multi-image
benchmarks overlook interleaved textual contexts and neglect distinct
relationships between individual images and their associated texts, enabling
models to reason over multi-image interleaved data may significantly enhance
their comprehension of complex scenes and better capture cross-modal
correlations. To bridge this gap, we introduce a novel benchmark MIR, requiring
joint reasoning over multiple images accompanied by interleaved textual
contexts to accurately associate image regions with corresponding texts and
logically connect information across images. To enhance MLLMs ability to
comprehend multi-image interleaved data, we introduce reasoning steps for each
instance within the benchmark and propose a stage-wise curriculum learning
strategy. This strategy follows an "easy to hard" approach, progressively
guiding models from simple to complex scenarios, thereby enhancing their
ability to handle challenging tasks. Extensive experiments benchmarking
multiple MLLMs demonstrate that our method significantly enhances models
reasoning performance on MIR and other established benchmarks. We believe that
MIR will encourage further research into multi-image interleaved reasoning,
facilitating advancements in MLLMs capability to handle complex inter-modal
tasks.Our code and dataset are available at
https://github.com/Shelly-coder239/MIRBench.

</details>


### [102] [Towards Generalized Synapse Detection Across Invertebrate Species](https://arxiv.org/abs/2509.17041)
*Samia Mohinta,Daniel Franco-Barranco,Shi Yan Lee,Albert Cardona*

Main category: cs.CV

TL;DR: SimpSyn是一种轻量级单阶段残差U-Net模型，用于突触检测，表现优于现有方法，适用于大规模连接组学。


<details>
  <summary>Details</summary>
Motivation: 由于稀疏注释、形态变异性和跨数据集域偏移等问题，自动检测突触仍具挑战性，因此需要一种更高效的解决方案。

Method: 提出SimpSyn，一种单阶段残差U-Net模型，用于预测突触前后的双通道球形掩码，注重训练和推理速度及注释效率。

Result: SimpSyn在所有体积的突触位点检测中F1分数均优于Synful，且在联合训练时表现竞争力。

Conclusion: 轻量级模型SimpSyn在突触检测任务中表现出色，尤其是在与任务结构对齐时，为大规模连接组学管道提供了实用且可扩展的解决方案。

Abstract: Behavioural differences across organisms, whether healthy or pathological,
are closely tied to the structure of their neural circuits. Yet, the fine-scale
synaptic changes that give rise to these variations remain poorly understood,
in part due to persistent challenges in detecting synapses reliably and at
scale. Volume electron microscopy (EM) offers the resolution required to
capture synaptic architecture, but automated detection remains difficult due to
sparse annotations, morphological variability, and cross-dataset domain shifts.
To address this, we make three key contributions. First, we curate a diverse EM
benchmark spanning four datasets across two invertebrate species: adult and
larval Drosophila melanogaster, and Megaphragma viggianii (micro-WASP). Second,
we propose SimpSyn, a single-stage Residual U-Net trained to predict
dual-channel spherical masks around pre- and post-synaptic sites, designed to
prioritize training and inference speeds and annotation efficiency over
architectural complexity. Third, we benchmark SimpSyn against Buhmann et al.'s
Synful [1], a state-of-the-art multi-task model that jointly infers synaptic
pairs. Despite its simplicity, SimpSyn consistently outperforms Synful in
F1-score across all volumes for synaptic site detection. While generalization
across datasets remains limited, SimpSyn achieves competitive performance when
trained on the combined cohort. Finally, ablations reveal that simple
post-processing strategies - such as local peak detection and distance-based
filtering - yield strong performance without complex test-time heuristics.
Taken together, our results suggest that lightweight models, when aligned with
task structure, offer a practical and scalable solution for synapse detection
in large-scale connectomic pipelines.

</details>


### [103] [Informative Text-Image Alignment for Visual Affordance Learning with Foundation Models](https://arxiv.org/abs/2509.17074)
*Qian Zhang,Lin Zhang,Xing Fang,Mingxin Zhang,Zhiyuan Wei,Ran Song,Wei Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息约束的文本引导可供性学习框架，通过最大化视觉与文本特征间的互信息，显著提升了性能，并在AGD20K数据集上取得了最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了视觉图像与语言描述之间特征对齐的重要性，可能导致次优结果。本文旨在通过信息约束实现文本与图像特征的对齐，以提升可供性学习的性能。

Method: 设计了一个可供性互信息约束，通过学习适当的文本提示和任务导向的视觉特征，最大化输入图像中可供性区域特征与对应文本提示之间的互信息。此外，提出了一个对象级信息约束，最大化给定对象视觉特征与所属类别文本特征之间的互信息。

Result: 在AGD20K数据集上的实验结果表明，该方法优于现有方法，并在一次性可供性学习中达到了新的最先进水平。

Conclusion: 提出的框架通过信息约束实现了文本与图像特征的对齐，显著提升了视觉可供性学习的性能，并在AGD20K数据集上达到了新的最先进水平。

Abstract: Visual affordance learning is crucial for robots to understand and interact
effectively with the physical world. Recent advances in this field attempt to
leverage pre-trained knowledge of vision-language foundation models to learn
affordance properties with limited training data, providing a novel paradigm
for visual affordance learning. However, these methods overlook the
significance of maintaining feature alignment between visual images and
language descriptions for identifying affordance areas with textual guidance,
and thus may lead to suboptimal results. In this paper, we present an
informative framework for text-guided affordance learning, which involves
information-based constraints to achieve text-image alignment at feature level.
Specifically, we design an affordance mutual information constraint that helps
learn appropriate textual prompts and task-oriented visual features
simultaneously by maximizing the mutual information between the features of the
affordance areas in the input images and the corresponding textual prompts. In
addition, we propose an object-level information constraint that maximizes the
mutual information between the visual features of a given object and the text
features of the category it belongs to. This enables the model to capture
high-quality representations for the object, providing more reliable semantic
priors for identifying affordance regions. Experimental results on the AGD20K
dataset show that the proposed method outperforms existing approaches and
achieves the new state-of-the-art in one-shot affordance learning.

</details>


### [104] [AgriDoctor: A Multimodal Intelligent Assistant for Agriculture](https://arxiv.org/abs/2509.17044)
*Mingqing Zhang,Zhuoning Xu,Peijie Wang,Rongji Li,Liang Wang,Qiang Liu,Jian Xu,Xuyao Zhang,Shu Wu,Liang Wang*

Main category: cs.CV

TL;DR: AgriDoctor是一个多模态作物病害诊断框架，结合视觉和语言模型，通过AgriMM数据集训练，显著提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 现有作物病害诊断方法主要依赖单模态模型，缺乏对农业领域知识的整合和语言交互支持，限制了其在农业环境中的应用效果。

Method: AgriDoctor是一个模块化、可扩展的多模态框架，包含路由器、分类器、检测器、知识检索器和大型语言模型（LLMs）五个核心组件，并基于AgriMM数据集进行训练和评估。

Result: 实验表明，AgriDoctor在细粒度农业任务上显著优于现有的大型视觉语言模型（LVLMs），验证了其高效性和适应性。

Conclusion: AgriDoctor通过整合多模态框架和专家知识，显著提升了作物病害诊断的准确性和交互性，为智能农业应用设定了新标准。

Abstract: Accurate crop disease diagnosis is essential for sustainable agriculture and
global food security. Existing methods, which primarily rely on unimodal models
such as image-based classifiers and object detectors, are limited in their
ability to incorporate domain-specific agricultural knowledge and lack support
for interactive, language-based understanding. Recent advances in large
language models (LLMs) and large vision-language models (LVLMs) have opened new
avenues for multimodal reasoning. However, their performance in agricultural
contexts remains limited due to the absence of specialized datasets and
insufficient domain adaptation. In this work, we propose AgriDoctor, a modular
and extensible multimodal framework designed for intelligent crop disease
diagnosis and agricultural knowledge interaction. As a pioneering effort to
introduce agent-based multimodal reasoning into the agricultural domain,
AgriDoctor offers a novel paradigm for building interactive and domain-adaptive
crop health solutions. It integrates five core components: a router,
classifier, detector, knowledge retriever and LLMs. To facilitate effective
training and evaluation, we construct AgriMM, a comprehensive benchmark
comprising 400000 annotated disease images, 831 expert-curated knowledge
entries, and 300000 bilingual prompts for intent-driven tool selection.
Extensive experiments demonstrate that AgriDoctor, trained on AgriMM,
significantly outperforms state-of-the-art LVLMs on fine-grained agricultural
tasks, establishing a new paradigm for intelligent and sustainable farming
applications.

</details>


### [105] [Learning Attribute-Aware Hash Codes for Fine-Grained Image Retrieval via Query Optimization](https://arxiv.org/abs/2509.17049)
*Peng Wang,Yong Li,Lin Zhao,Xiu-Shen Wei*

Main category: cs.CV

TL;DR: 提出一种基于可学习查询的属性感知哈希码学习方法，通过辅助分支增强哈希码的鲁棒性，实验证明其在低比特哈希码任务中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 细粒度哈希在需要高区分度的视觉相似类别检索中具有重要作用，但现有方法在哈希码的属性和可解释性方面存在不足。

Method: 提出了一种利用可学习查询进行属性感知哈希码学习的新方法，通过定制查询集捕捉和表示哈希过程中的属性级信息，并引入辅助分支建模高阶属性交互以增强哈希码的鲁棒性和特异性。

Result: 在基准数据集上的实验结果表明，该方法生成的属性感知哈希码在检索准确性和鲁棒性上优于现有技术。

Conclusion: 该方法在细粒度图像哈希任务中表现出色，尤其在低比特哈希码方面，显著提升了检索准确性和鲁棒性。

Abstract: Fine-grained hashing has become a powerful solution for rapid and efficient
image retrieval, particularly in scenarios requiring high discrimination
between visually similar categories. To enable each hash bit to correspond to
specific visual attributes, we propoe a novel method that harnesses learnable
queries for attribute-aware hash codes learning. This method deploys a tailored
set of queries to capture and represent nuanced attribute-level information
within the hashing process, thereby enhancing both the interpretability and
relevance of each hash bit. Building on this query-based optimization
framework, we incorporate an auxiliary branch to help alleviate the challenges
of complex landscape optimization often encountered with low-bit hash codes.
This auxiliary branch models high-order attribute interactions, reinforcing the
robustness and specificity of the generated hash codes. Experimental results on
benchmark datasets demonstrate that our method generates attribute-aware hash
codes and consistently outperforms state-of-the-art techniques in retrieval
accuracy and robustness, especially for low-bit hash codes, underscoring its
potential in fine-grained image hashing tasks.

</details>


### [106] [SAEC: Scene-Aware Enhanced Edge-Cloud Collaborative Industrial Vision Inspection with Multimodal LLM](https://arxiv.org/abs/2509.17136)
*Yuhao Tian,Zheming Yang*

Main category: cs.CV

TL;DR: SAEC是一种结合MLLM的边缘-云协同工业视觉检测框架，通过高效微调、场景复杂度估计和动态调度，显著提升检测性能并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 工业视觉检测在资源受限的情况下需要高准确性，现有方法在计算成本和性能之间存在权衡。

Method: SAEC框架包含三个协同组件：(1) 高效的MLLM微调用于复杂缺陷检测，(2) 轻量级多尺度场景复杂度估计，(3) 自适应边缘-云调度器。

Result: 在MVTec AD和KSDD2数据集上，SAEC分别达到85.11%和82.72%的准确率，显著优于Qwen和LLaVA，同时降低了运行时间和能耗。

Conclusion: SAEC框架通过结合高效的MLLM微调、轻量级场景复杂度估计和自适应边缘-云调度器，显著提升了工业视觉检测的准确性和效率。

Abstract: Industrial vision inspection requires high accuracy under stringent resource
constraints, yet existing approaches face a fundamental trade-off. Multimodal
LLMs (MLLMs) deliver strong reasoning capabilities but incur prohibitive
computational costs, while lightweight edge models often fail on complex cases.
In this paper, we present SAEC, a scene-aware enhanced edge-cloud collaborative
industrial vision inspection framework with MLLM. The framework is composed of
three synergistic components: (1) Efficient MLLM Fine-Tuning for Complex Defect
Inspection, (2) Lightweight Multiscale Scene-Complexity Estimation, and (3)
Adaptive Edge-Cloud Scheduler. Together, these modules enable robust defect
detection by tailoring multimodal reasoning to scene complexity and dynamically
balancing computation between edge and cloud resources. Experimental results on
MVTec AD and KSDD2 datasets demonstrate that SAEC attains 85.11% and 82.72%
accuracy, surpassing Qwen by 22.1% and 20.8%, and LLaVA by 33.3% and 31.6%. It
also reduces runtime by up to 22.4% and cuts energy per correct decision by
40%-74%. The code is available at https://github.com/YuHao-Tian/SAEC.

</details>


### [107] [Geodesic Prototype Matching via Diffusion Maps for Interpretable Fine-Grained Recognition](https://arxiv.org/abs/2509.17050)
*Junhao Jia,Yunyou Liu,Yifei Sun,Huangwei Chen,Feiwei Qin,Changmiao Wang,Yong Peng*

Main category: cs.CV

TL;DR: GeoProto通过内在几何结构改进原型识别，显著优于欧几里得方法。


<details>
  <summary>Details</summary>
Motivation: 非线性流形在深度视觉特征中普遍存在，欧几里得距离难以捕捉真实相似性，尤其在原型可解释的细粒度识别中，细微的语义差异至关重要。

Method: 提出了一种新的原型识别范式，包括将每个类的潜在流形结构蒸馏到扩散空间中，并引入可微的Nyström插值，使几何结构对未见样本和可学习原型都可用。使用紧凑的每类地标集和定期更新以确保效率。

Result: 在CUB-200-2011和Stanford Cars数据集上的广泛实验表明，GeoProto框架生成的语义对齐原型显著优于欧几里得原型网络。

Conclusion: GeoProto框架通过将相似性锚定在深度特征的内在几何结构中，显著优于基于欧几里得距离的原型网络，生成了语义对齐的原型。

Abstract: Nonlinear manifolds are widespread in deep visual features, where Euclidean
distances often fail to capture true similarity. This limitation becomes
particularly severe in prototype-based interpretable fine-grained recognition,
where subtle semantic distinctions are essential. To address this challenge, we
propose a novel paradigm for prototype-based recognition that anchors
similarity within the intrinsic geometry of deep features. Specifically, we
distill the latent manifold structure of each class into a diffusion space and
introduce a differentiable Nystr\"om interpolation, making the geometry
accessible to both unseen samples and learnable prototypes. To ensure
efficiency, we employ compact per-class landmark sets with periodic updates.
This design keeps the embedding aligned with the evolving backbone, enabling
fast and scalable inference. Extensive experiments on the CUB-200-2011 and
Stanford Cars datasets show that our GeoProto framework produces prototypes
focusing on semantically aligned parts, significantly outperforming Euclidean
prototype networks.

</details>


### [108] [Ambiguous Medical Image Segmentation Using Diffusion Schrödinger Bridge](https://arxiv.org/abs/2509.17187)
*Lalith Bharadwaj Baru,Kamalaker Dadi,Tapabrata Chakraborti,Raju S. Bapi*

Main category: cs.CV

TL;DR: SSB利用Sch\"{o}dinger Bridge方法处理医学图像分割中的模糊边界和多样性问题，无需额外指导即可实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割面临模糊边界和掩模多样性的挑战，传统方法难以有效处理这些问题。

Method: SSB采用Sch\"{o}dinger Bridge方法，结合新颖的损失函数，无需额外指导即可处理模糊边界，并保持结构完整性和多样性。此外，还提出了Diversity Divergence Index（$D_{DDI}$）来量化评估者间的变异性。

Result: SSB在LIDC-IDRI、COCA和RACER（内部）数据集上实现了最先进的性能。

Conclusion: SSB（Segmentation Sch\"{o}dinger Bridge）通过建模联合图像-掩模动态，在医学图像分割中实现了最先进的性能，特别是在处理模糊边界和保持多样性方面表现出色。

Abstract: Accurate segmentation of medical images is challenging due to unclear lesion
boundaries and mask variability. We introduce \emph{Segmentation Sch\"{o}dinger
Bridge (SSB)}, the first application of Sch\"{o}dinger Bridge for ambiguous
medical image segmentation, modelling joint image-mask dynamics to enhance
performance. SSB preserves structural integrity, delineates unclear boundaries
without additional guidance, and maintains diversity using a novel loss
function. We further propose the \emph{Diversity Divergence Index} ($D_{DDI}$)
to quantify inter-rater variability, capturing both diversity and consensus.
SSB achieves state-of-the-art performance on LIDC-IDRI, COCA, and RACER
(in-house) datasets.

</details>


### [109] [CardiacCLIP: Video-based CLIP Adaptation for LVEF Prediction in a Few-shot Manner](https://arxiv.org/abs/2509.17065)
*Yao Du,Jiarong Guo,Xiaomeng Li*

Main category: cs.CV

TL;DR: CardiacCLIP是一种基于视频的框架，通过注意力机制和多尺度特征提升LVEF预测准确性，尤其适用于少量样本场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模标注数据集且无法有效捕捉时间动态和局部结构，限制了临床适应性。

Method: 提出了CardiacCLIP框架，包括Multi Frame Learning（MFL）注意力机制和EchoZoom多尺度特征提取策略，专注于捕捉时间动态和局部心脏结构。

Result: 在EchoNet-Dynamic数据集上，1-shot设置下MAE降低了2.07。

Conclusion: CardiacCLIP通过结合注意力机制和多尺度特征提取，显著提升了LVEF预测的准确性，尤其在少量样本（1-shot）场景下表现优异。

Abstract: Echocardiography is a vital non-invasive modality for cardiac assessment,
with left ventricular ejection fraction (LVEF) serving as a key indicator of
heart function. Existing LVEF estimation methods depend on large-scale
annotated video datasets, which are costly and limit adaptability across
various clinical settings. Recent vision-language models for echocardiography,
such as EchoCLIP, apply image-to-text pretraining but fail to capture crucial
temporal dynamics and localized cardiac structures essential for accurate
diagnosis. To address these challenges, we propose CardiacCLIP, a video-based
framework that enhances LVEF prediction through attention-based frame
aggregation and multi-resolution input scaling. Specifically, we introduce MFL
(Multi Frame Learning), a novel attention-based mechanism for selectively
fusing informative frames, and EchoZoom, a multi-scale feature extraction
strategy that refines spatial representations of cardiac structures. As a novel
adaptation of CLIP models for few-shot echocardiogram video analysis, our
approach significantly improves diagnostic accuracy, reducing MAE by 2.07 on
the EchoNet-Dynamic dataset under 1-shot setting. The code is available at
https://github.com/xmed-lab/CardiacCLIP.

</details>


### [110] [Echo-Path: Pathology-Conditioned Echo Video Generation](https://arxiv.org/abs/2509.17190)
*Kabir Hamzah Muhammad,Marawan Elbatel,Yi Qin,Xiaomeng Li*

Main category: cs.CV

TL;DR: Echo-Path通过生成病理特征的超声心动图视频，显著提升了ASD和PAH的诊断准确率。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球死亡率的主要原因，但某些病理的超声心动图数据稀缺，阻碍了自动化诊断模型的开发。

Method: 引入病理条件机制到先进的超声视频生成器中，学习并控制疾病特定的心脏结构和运动模式。

Result: 合成的视频在视觉保真度上表现优异，且基于合成数据训练的模型能够有效提升ASD和PAH的诊断准确率（分别提高7%和8%）。

Conclusion: Echo-Path框架通过生成具有特定心脏病理特征的超声心动图视频，成功提高了自动诊断模型的性能，尤其是在ASD和PAH的诊断上表现显著。

Abstract: Cardiovascular diseases (CVDs) remain the leading cause of mortality
globally, and echocardiography is critical for diagnosis of both common and
congenital cardiac conditions. However, echocardiographic data for certain
pathologies are scarce, hindering the development of robust automated diagnosis
models. In this work, we propose Echo-Path, a novel generative framework to
produce echocardiogram videos conditioned on specific cardiac pathologies.
Echo-Path can synthesize realistic ultrasound video sequences that exhibit
targeted abnormalities, focusing here on atrial septal defect (ASD) and
pulmonary arterial hypertension (PAH). Our approach introduces a
pathology-conditioning mechanism into a state-of-the-art echo video generator,
allowing the model to learn and control disease-specific structural and motion
patterns in the heart. Quantitative evaluation demonstrates that the synthetic
videos achieve low distribution distances, indicating high visual fidelity.
Clinically, the generated echoes exhibit plausible pathology markers.
Furthermore, classifiers trained on our synthetic data generalize well to real
data and, when used to augment real training sets, it improves downstream
diagnosis of ASD and PAH by 7\% and 8\% respectively. Code, weights and dataset
are available here https://github.com/Marshall-mk/EchoPathv1

</details>


### [111] [Guided and Unguided Conditional Diffusion Mechanisms for Structured and Semantically-Aware 3D Point Cloud Generation](https://arxiv.org/abs/2509.17206)
*Gunner Stone,Sushmita Sarker,Alireza Tavakkoli*

Main category: cs.CV

TL;DR: 提出一种扩散框架，将语义条件直接嵌入3D点云生成过程，实现结构连贯且分割感知的生成，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法主要关注几何形状，语义信息通常通过外部分割或聚类后处理引入，而非集成到生成过程中。

Method: 采用基于扩散的框架，将每个点的语义标签作为条件变量，指导扩散动力学，从而联合合成几何和语义。

Result: 通过对比分析，证明了条件变量对扩散动力学和生成质量的显著影响，实验验证了方法的有效性，生成了详细且准确的3D点云。

Conclusion: 提出的扩散框架通过将语义条件直接嵌入生成过程，成功实现了结构连贯且分割感知的3D点云生成，显著提升了生成质量。

Abstract: Generating realistic 3D point clouds is a fundamental problem in computer
vision with applications in remote sensing, robotics, and digital object
modeling. Existing generative approaches primarily capture geometry, and when
semantics are considered, they are typically imposed post hoc through external
segmentation or clustering rather than integrated into the generative process
itself. We propose a diffusion-based framework that embeds per-point semantic
conditioning directly within generation. Each point is associated with a
conditional variable corresponding to its semantic label, which guides the
diffusion dynamics and enables the joint synthesis of geometry and semantics.
This design produces point clouds that are both structurally coherent and
segmentation-aware, with object parts explicitly represented during synthesis.
Through a comparative analysis of guided and unguided diffusion processes, we
demonstrate the significant impact of conditional variables on diffusion
dynamics and generation quality. Extensive experiments validate the efficacy of
our approach, producing detailed and accurate 3D point clouds tailored to
specific parts and features.

</details>


### [112] [Enhanced Detection of Tiny Objects in Aerial Images](https://arxiv.org/abs/2509.17078)
*Kihyun Kim,Michalis Lazarou,Tania Stathaki*

Main category: cs.CV

TL;DR: MoonNet通过注意力机制和数据增强优化YOLOv8，显著提升微小物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 一阶段检测器（如YOLOv8）在检测小物体时性能不足，尤其是在航空影像中，由于低分辨率目标和杂乱背景。

Method: 引入了三种增强策略：输入图像分辨率调整、数据增强和注意力机制（SE Block和CBAM），并设计了MoonNet管道，结合了注意力增强的CNN模块。

Result: MoonNet在YOLOv8基础上提升了检测精度，并在微小物体基准测试中取得了最先进性能。

Conclusion: MoonNet通过结合注意力机制和数据增强策略，显著提升了YOLOv8在微小物体检测中的性能，并在基准测试中达到了最先进水平。

Abstract: While one-stage detectors like YOLOv8 offer fast training speed, they often
under-perform on detecting small objects as a trade-off. This becomes even more
critical when detecting tiny objects in aerial imagery due to low-resolution
targets and cluttered backgrounds. To address this, we introduce three
enhancement strategies -- input image resolution adjustment, data augmentation,
and attention mechanisms -- that can be easily implemented on YOLOv8. We
demonstrate that image size enlargement and the proper use of augmentation can
lead to enhancement. Additionally, we designed a Mixture of Orthogonal
Neural-modules Network (MoonNet) pipeline which consists of attention-augmented
CNNs. Two well-known attention modules, the Squeeze-and-Excitation Block (SE
Block) and the Convolutional Block Attention Module (CBAM), were integrated
into the backbone of YOLOv8 with an increased number of channels, and the
MoonNet backbone obtained improved detection accuracy compared to the original
YOLOv8. MoonNet further proved its adaptability and potential by achieving
state-of-the-art performance on a tiny-object benchmark when integrated with
the YOLC model. Our codes are available at: https://github.com/Kihyun11/MoonNet

</details>


### [113] [Point-RTD: Replaced Token Denoising for Pretraining Transformer Models on Point Clouds](https://arxiv.org/abs/2509.17207)
*Gunner Stone,Youngsook Choi,Alireza Tavakkoli,Ankita Shukla*

Main category: cs.CV

TL;DR: Point-RTD是一种新型预训练策略，通过损坏-重建框架显著提升3D点云任务的性能，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的掩码重建任务在预测隐藏数据段时存在局限性，Point-RTD旨在通过更有效的损坏-重建框架提升令牌的鲁棒性和模型性能。

Method: 提出了一种名为Point-RTD的预训练策略，采用损坏点云令牌并通过判别器-生成器架构进行去噪，替代传统的掩码重建任务。

Result: 在ShapeNet数据集上，Point-RTD将重建误差降低了93%以上，测试集上的Chamfer Distance降低了14倍以上，同时在分类任务中收敛更快且准确率更高。

Conclusion: Point-RTD显著提升了3D点云任务的模型性能，通过其独特的损坏-重建框架，在多个基准测试中均优于基线方法Point-MAE。

Abstract: Pre-training strategies play a critical role in advancing the performance of
transformer-based models for 3D point cloud tasks. In this paper, we introduce
Point-RTD (Replaced Token Denoising), a novel pretraining strategy designed to
improve token robustness through a corruption-reconstruction framework. Unlike
traditional mask-based reconstruction tasks that hide data segments for later
prediction, Point-RTD corrupts point cloud tokens and leverages a
discriminator-generator architecture for denoising. This shift enables more
effective learning of structural priors and significantly enhances model
performance and efficiency. On the ShapeNet dataset, Point-RTD reduces
reconstruction error by over 93% compared to PointMAE, and achieves more than
14x lower Chamfer Distance on the test set. Our method also converges faster
and yields higher classification accuracy on ShapeNet, ModelNet10, and
ModelNet40 benchmarks, clearly outperforming the baseline Point-MAE framework
in every case.

</details>


### [114] [A Dual-Modulation Framework for RGB-T Crowd Counting via Spatially Modulated Attention and Adaptive Fusion](https://arxiv.org/abs/2509.17079)
*Yuhong Feng,Hongtao Chen,Qi Zhang,Jie Chen,Zhaoxi He,Mingzhe Liu,Jianghai Liao*

Main category: cs.CV

TL;DR: 提出双调制框架（SMA+AFM）提升RGB-T人群计数精度，通过空间衰减掩码和动态门控机制解决注意力扩散和模态融合问题。


<details>
  <summary>Details</summary>
Motivation: 解决Transformer方法在RGB-T人群计数中因缺乏空间归纳偏置导致注意力扩散到无关背景区域的问题，并有效桥接不同模态之间的差距。

Method: 包括两个模块：空间调制注意力（SMA）通过可学习的空间衰减掩码惩罚远距离标记之间的注意力，防止注意力扩散到背景；自适应融合调制（AFM）通过动态门控机制优先选择最可靠的模态进行自适应跨模态融合。

Result: 在RGB-T人群计数数据集上的实验表明，该方法优于现有工作。

Conclusion: 提出的双调制框架（Dual Modulation Framework）在RGB-T人群计数任务中表现出色，显著提升了计数和定位精度。

Abstract: Accurate RGB-Thermal (RGB-T) crowd counting is crucial for public safety in
challenging conditions. While recent Transformer-based methods excel at
capturing global context, their inherent lack of spatial inductive bias causes
attention to spread to irrelevant background regions, compromising crowd
localization precision. Furthermore, effectively bridging the gap between these
distinct modalities remains a major hurdle. To tackle this, we propose the Dual
Modulation Framework, comprising two modules: Spatially Modulated Attention
(SMA), which improves crowd localization by using a learnable Spatial Decay
Mask to penalize attention between distant tokens and prevent focus from
spreading to the background; and Adaptive Fusion Modulation (AFM), which
implements a dynamic gating mechanism to prioritize the most reliable modality
for adaptive cross-modal fusion. Extensive experiments on RGB-T crowd counting
datasets demonstrate the superior performance of our method compared to
previous works. Code available at
https://github.com/Cht2924/RGBT-Crowd-Counting.

</details>


### [115] [Automated Facility Enumeration for Building Compliance Checking using Door Detection and Large Language Models](https://arxiv.org/abs/2509.17283)
*Licheng Zhan,Bach Le,Naveed Akhtar,Tuan Ngo*

Main category: cs.CV

TL;DR: 提出基于LLM和门检测的自动化设施枚举方法，通过CoT流程提升性能，实验验证其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 建筑合规检查中的设施枚举是关键但被忽视的任务，手动操作耗时耗力。LLMs的进展为结合视觉识别与推理能力提供了自动化新机遇。

Method: 提出了一种结合门检测与基于LLM的推理的新方法，并采用Chain-of-Thought (CoT)流程增强性能。

Result: 在真实和合成楼层平面数据上的实验验证了方法的有效性和鲁棒性。

Conclusion: 本研究提出了一种结合门检测与大语言模型推理的新方法，首次将LLMs应用于自动化设施枚举任务，并通过CoT流程提升性能。实验证明该方法在多样数据集和设施类型上具有良好泛化能力。

Abstract: Building compliance checking (BCC) is a critical process for ensuring that
constructed facilities meet regulatory standards. A core component of BCC is
the accurate enumeration of facility types and their spatial distribution.
Despite its importance, this problem has been largely overlooked in the
literature, posing a significant challenge for BCC and leaving a critical gap
in existing workflows. Performing this task manually is time-consuming and
labor-intensive. Recent advances in large language models (LLMs) offer new
opportunities to enhance automation by combining visual recognition with
reasoning capabilities. In this paper, we introduce a new task for BCC:
automated facility enumeration, which involves validating the quantity of each
facility type against statutory requirements. To address it, we propose a novel
method that integrates door detection with LLM-based reasoning. We are the
first to apply LLMs to this task and further enhance their performance through
a Chain-of-Thought (CoT) pipeline. Our approach generalizes well across diverse
datasets and facility types. Experiments on both real-world and synthetic floor
plan data demonstrate the effectiveness and robustness of our method.

</details>


### [116] [HyRF: Hybrid Radiance Fields for Memory-efficient and High-quality Novel View Synthesis](https://arxiv.org/abs/2509.17083)
*Zipeng Wang,Dan Xu*

Main category: cs.CV

TL;DR: HyRF结合显式高斯和神经场，减少内存开销并提升细节重建，实现高质量实时渲染。


<details>
  <summary>Details</summary>
Motivation: 3DGS虽然能够实现高质量的实时新视图合成，但由于依赖每个高斯的参数来建模视图相关效果和各向异性形状，存在显著的内存开销。现有压缩方法难以捕捉高斯属性的高频空间变化，导致细节重建效果下降。

Method: HyRF将场景分解为（1）存储关键高频参数的显式高斯集合和（2）预测剩余属性的基于网格的神经场。此外，引入了解耦的神经场架构，分别建模几何和视图相关颜色，并提出了一种混合渲染方案。

Result: 实验表明，HyRF在保持实时性能的同时，渲染质量达到最先进水平，模型大小比3DGS减少了20倍以上。

Conclusion: HyRF通过结合显式高斯和神经场的优势，不仅实现了高质量的实时渲染，还将模型大小减少了20倍以上，同时在细节重建方面表现出色。

Abstract: Recently, 3D Gaussian Splatting (3DGS) has emerged as a powerful alternative
to NeRF-based approaches, enabling real-time, high-quality novel view synthesis
through explicit, optimizable 3D Gaussians. However, 3DGS suffers from
significant memory overhead due to its reliance on per-Gaussian parameters to
model view-dependent effects and anisotropic shapes. While recent works propose
compressing 3DGS with neural fields, these methods struggle to capture
high-frequency spatial variations in Gaussian properties, leading to degraded
reconstruction of fine details. We present Hybrid Radiance Fields (HyRF), a
novel scene representation that combines the strengths of explicit Gaussians
and neural fields. HyRF decomposes the scene into (1) a compact set of explicit
Gaussians storing only critical high-frequency parameters and (2) grid-based
neural fields that predict remaining properties. To enhance representational
capacity, we introduce a decoupled neural field architecture, separately
modeling geometry (scale, opacity, rotation) and view-dependent color.
Additionally, we propose a hybrid rendering scheme that composites Gaussian
splatting with a neural field-predicted background, addressing limitations in
distant scene representation. Experiments demonstrate that HyRF achieves
state-of-the-art rendering quality while reducing model size by over 20 times
compared to 3DGS and maintaining real-time performance. Our project page is
available at https://wzpscott.github.io/hyrf/.

</details>


### [117] [Pre-Trained CNN Architecture for Transformer-Based Image Caption Generation Model](https://arxiv.org/abs/2509.17365)
*Amanuel Tafese Dufera*

Main category: cs.CV

TL;DR: 本文介绍了一种基于Transformer的图像字幕生成方法，利用自注意力机制提升效率，实验证明其在Flickr30k数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的CNN和LSTM方法在图像字幕生成中存在训练和推理速度慢、长序列信息保留不足的问题，Transformer的自注意力机制能够解决这些问题。

Method: 采用Transformer架构，结合EfficientNetB0 CNN进行特征提取，并在Flickr30k数据集上进行数据预处理和模型训练。

Result: 提出的方法在图像字幕生成任务中表现出色，实现了高效的并行化训练和推理。

Conclusion: 本文提出了一种基于Transformer架构的图像字幕生成方法，该方法通过自注意力机制有效捕捉数据的短程和长程依赖关系，显著提升了训练和推理的效率。

Abstract: Automatic image captioning, a multifaceted task bridging computer vision and
natural lan- guage processing, aims to generate descriptive textual content
from visual input. While Convolutional Neural Networks (CNNs) and Long
Short-Term Memory (LSTM) networks have achieved significant advancements, they
present limitations. The inherent sequential nature of RNNs leads to sluggish
training and inference times. LSTMs further struggle with retaining information
from earlier sequence elements when dealing with very long se- quences. This
project presents a comprehensive guide to constructing and comprehending
transformer models for image captioning. Transformers employ self-attention
mechanisms, capturing both short- and long-range dependencies within the data.
This facilitates efficient parallelization during both training and inference
phases. We leverage the well-established Transformer architecture, recognized
for its effectiveness in managing sequential data, and present a meticulous
methodology. Utilizing the Flickr30k dataset, we conduct data pre- processing,
construct a model architecture that integrates an EfficientNetB0 CNN for fea-
ture extraction, and train the model with attention mechanisms incorporated.
Our approach exemplifies the utilization of parallelization for efficient
training and inference. You can find the project on GitHub.

</details>


### [118] [MoCLIP-Lite: Efficient Video Recognition by Fusing CLIP with Motion Vectors](https://arxiv.org/abs/2509.17084)
*Binhua Huang,Nan Wang,Arjun Parakash,Soumyabrata Dev*

Main category: cs.CV

TL;DR: MoCLIP-Lite通过结合CLIP和MV特征，以极低成本实现高效视频识别，UCF101准确率89.2%。


<details>
  <summary>Details</summary>
Motivation: 现有视频动作识别模型计算成本高且依赖大量视频预训练，而CLIP和MV分别提供强大的零样本能力和高效时间信息。

Method: 提出MoCLIP-Lite，一个双流后期融合框架，结合冻结的CLIP图像编码器和轻量级监督网络（基于原始MV）的特征。仅训练一个微型MLP头。

Result: 在UCF101数据集上达到89.2%的Top-1准确率，显著优于零样本（65.0%）和仅MV（66.5%）基线。

Conclusion: MoCLIP-Lite提供了一个高效的新基准，有效结合了大型静态模型和低成本动态运动线索。

Abstract: Video action recognition is a fundamental task in computer vision, but
state-of-the-art models are often computationally expensive and rely on
extensive video pre-training. In parallel, large-scale vision-language models
like Contrastive Language-Image Pre-training (CLIP) offer powerful zero-shot
capabilities on static images, while motion vectors (MV) provide highly
efficient temporal information directly from compressed video streams. To
synergize the strengths of these paradigms, we propose MoCLIP-Lite, a simple
yet powerful two-stream late fusion framework for efficient video recognition.
Our approach combines features from a frozen CLIP image encoder with features
from a lightweight, supervised network trained on raw MV. During fusion, both
backbones are frozen, and only a tiny Multi-Layer Perceptron (MLP) head is
trained, ensuring extreme efficiency. Through comprehensive experiments on the
UCF101 dataset, our method achieves a remarkable 89.2% Top-1 accuracy,
significantly outperforming strong zero-shot (65.0%) and MV-only (66.5%)
baselines. Our work provides a new, highly efficient baseline for video
understanding that effectively bridges the gap between large static models and
dynamic, low-cost motion cues. Our code and models are available at
https://github.com/microa/MoCLIP-Lite.

</details>


### [119] [Interpreting vision transformers via residual replacement model](https://arxiv.org/abs/2509.17401)
*Jinyeong Kim,Junhyeok Kim,Yumin Shim,Joohyeok Kim,Sunyoung Jung,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 论文通过分析ViT特征和残差替换模型，揭示了其工作机制并展示了在消除虚假相关性中的应用。


<details>
  <summary>Details</summary>
Motivation: 探索视觉变换器（ViTs）如何表示和处理世界，解决其工作机制的长期疑问。

Method: 采用稀疏自编码器提取6.6K个特征，并引入残差替换模型简化ViT计算。

Result: 揭示了ViT特征从低层到高层的演化过程，以及如何通过残差替换模型实现可解释性。

Conclusion: 该论文通过残差替换模型和稀疏自编码器提取的特征分析，揭示了ViT如何从底层模式到高层语义的特征演化，并展示了其在消除虚假相关性中的实用性。

Abstract: How do vision transformers (ViTs) represent and process the world? This paper
addresses this long-standing question through the first systematic analysis of
6.6K features across all layers, extracted via sparse autoencoders, and by
introducing the residual replacement model, which replaces ViT computations
with interpretable features in the residual stream. Our analysis reveals not
only a feature evolution from low-level patterns to high-level semantics, but
also how ViTs encode curves and spatial positions through specialized feature
types. The residual replacement model scalably produces a faithful yet
parsimonious circuit for human-scale interpretability by significantly
simplifying the original computations. As a result, this framework enables
intuitive understanding of ViT mechanisms. Finally, we demonstrate the utility
of our framework in debiasing spurious correlations.

</details>


### [120] [SFN-YOLO: Towards Free-Range Poultry Detection via Scale-aware Fusion Networks](https://arxiv.org/abs/2509.17086)
*Jie Chen,Yuhong Feng,Tao Dai,Mingzhe Liu,Hongtao Chen,Zhaoxi He,Jiancong Bai*

Main category: cs.CV

TL;DR: SFN-YOLO通过尺度感知融合技术提升家禽检测，在复杂环境中表现优异，参数更少且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 解决自由放养环境中多尺度目标、遮挡和复杂动态背景带来的检测挑战。

Method: 提出了一种名为SFN-YOLO的创新家禽检测方法，利用尺度感知融合技术结合局部细节和全局上下文。

Result: 实验表明，模型在仅7.2M参数下达到80.7%的mAP，比基准减少35.1%参数，同时保持强泛化能力。

Conclusion: SFN-YOLO模型在智能家禽养殖中展现出高效的实时检测能力，支持自动化应用。

Abstract: Detecting and localizing poultry is essential for advancing smart poultry
farming. Despite the progress of detection-centric methods, challenges persist
in free-range settings due to multiscale targets, obstructions, and complex or
dynamic backgrounds. To tackle these challenges, we introduce an innovative
poultry detection approach named SFN-YOLO that utilizes scale-aware fusion.
This approach combines detailed local features with broader global context to
improve detection in intricate environments. Furthermore, we have developed a
new expansive dataset (M-SCOPE) tailored for varied free-range conditions.
Comprehensive experiments demonstrate our model achieves an mAP of 80.7% with
just 7.2M parameters, which is 35.1% fewer than the benchmark, while retaining
strong generalization capability across different domains. The efficient and
real-time detection capabilities of SFN-YOLO support automated smart poultry
farming. The code and dataset can be accessed at
https://github.com/chenjessiee/SFN-YOLO.

</details>


### [121] [Real-Time Fish Detection in Indonesian Marine Ecosystems Using Lightweight YOLOv10-nano Architecture](https://arxiv.org/abs/2509.17406)
*Jonathan Wuntu,Muhamad Dwisnanto Putro,Rendy Syahputra*

Main category: cs.CV

TL;DR: 本研究利用YOLOv10-nano模型在印度尼西亚水域实现了高效的实时海洋鱼类检测，展示了其在海洋保护中的潜力。


<details>
  <summary>Details</summary>
Motivation: 印度尼西亚的海洋生态系统是全球公认的珊瑚三角区的一部分，生物多样性极为丰富，需要高效的监测工具来支持保护工作。传统的鱼类检测方法耗时且需要专业知识，因此需要自动化解决方案。

Method: 本研究探索了使用YOLOv10-nano（一种先进深度学习模型）在印度尼西亚水域实时检测海洋鱼类的方法，测试数据来自布纳肯国家海洋公园。YOLOv10的架构包括CSPNet主干、PAN用于特征融合和金字塔空间注意力块，即使在复杂环境中也能实现高效准确的物体检测。

Result: YOLOv10-nano在DeepFish和OpenImages V7-Fish数据集上表现出色，实现了高检测精度（mAP50为0.966，mAP50:95为0.606），同时保持低计算需求（2.7M参数，8.4 GFLOPs）。在CPU上的平均推理速度为29.29 FPS，适合实时部署。

Conclusion: 本研究展示了YOLOv10-nano在数据有限环境中高效、可扩展的海洋鱼类监测和保护应用中的潜力。

Abstract: Indonesia's marine ecosystems, part of the globally recognized Coral
Triangle, are among the richest in biodiversity, requiring efficient monitoring
tools to support conservation. Traditional fish detection methods are
time-consuming and demand expert knowledge, prompting the need for automated
solutions. This study explores the implementation of YOLOv10-nano, a
state-of-the-art deep learning model, for real-time marine fish detection in
Indonesian waters, using test data from Bunaken National Marine Park. YOLOv10's
architecture, featuring improvements like the CSPNet backbone, PAN for feature
fusion, and Pyramid Spatial Attention Block, enables efficient and accurate
object detection even in complex environments. The model was evaluated on the
DeepFish and OpenImages V7-Fish datasets. Results show that YOLOv10-nano
achieves a high detection accuracy with mAP50 of 0.966 and mAP50:95 of 0.606
while maintaining low computational demand (2.7M parameters, 8.4 GFLOPs). It
also delivered an average inference speed of 29.29 FPS on the CPU, making it
suitable for real-time deployment. Although OpenImages V7-Fish alone provided
lower accuracy, it complemented DeepFish in enhancing model robustness.
Overall, this study demonstrates YOLOv10-nano's potential for efficient,
scalable marine fish monitoring and conservation applications in data-limited
environments.

</details>


### [122] [AlignedGen: Aligning Style Across Generated Images](https://arxiv.org/abs/2509.17088)
*Jiexuan Zhang,Yiheng Du,Qian Wang,Weiqi Li,Yu Gu,Jian Zhang*

Main category: cs.CV

TL;DR: AlignedGen 是一个无需训练的框架，通过 ShiftPE 和 AAS 技术解决了 DiT 模型生成图像风格不一致的问题，并支持外部风格参考。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在相同风格提示下生成的图像风格一致性不足，限制了其在创意工作流程中的实际应用。现有方法局限于 U-Net 架构，导致质量低、出现重复对象等问题，且不兼容更优的 Diffusion Transformer (DiT)。

Method: 提出了 Shifted Position Embedding (ShiftPE) 来解决位置嵌入冲突问题，并开发了 Advanced Attention Sharing (AAS) 技术以充分发挥 DiT 中注意力共享的潜力。此外，还提出了一种高效的查询、键和值特征提取算法，以支持外部图像作为风格参考。

Result: 实验结果表明，AlignedGen 显著提升了生成图像的风格一致性，同时保持了文本到图像的精确对齐。

Conclusion: AlignedGen 通过 Shifted Position Embedding (ShiftPE) 和 Advanced Attention Sharing (AAS) 技术，有效解决了 DiT 模型在生成图像时风格不一致的问题，同时保持了文本到图像的精确对齐。

Abstract: Despite their generative power, diffusion models struggle to maintain style
consistency across images conditioned on the same style prompt, hindering their
practical deployment in creative workflows. While several training-free methods
attempt to solve this, they are constrained to the U-Net architecture, which
not only leads to low-quality results and artifacts like object repetition but
also renders them incompatible with superior Diffusion Transformer (DiT). To
address these issues, we introduce AlignedGen, a novel training-free framework
that enhances style consistency across images generated by DiT models. Our work
first reveals a critical insight: naive attention sharing fails in DiT due to
conflicting positional signals from improper position embeddings. We introduce
Shifted Position Embedding (ShiftPE), an effective solution that resolves this
conflict by allocating a non-overlapping set of positional indices to each
image. Building on this foundation, we develop Advanced Attention Sharing
(AAS), a suite of three techniques meticulously designed to fully unleash the
potential of attention sharing within the DiT. Furthermore, to broaden the
applicability of our method, we present an efficient query, key, and value
feature extraction algorithm, enabling our method to seamlessly incorporate
external images as style references. Extensive experimental results validate
that our method effectively enhances style consistency across generated images
while maintaining precise text-to-image alignment.

</details>


### [123] [Training-Free Label Space Alignment for Universal Domain Adaptation](https://arxiv.org/abs/2509.17452)
*Dujin Lee,Sojung An,Jungmyung Wi,Kuniaki Saito,Donghyun Kim*

Main category: cs.CV

TL;DR: 本文提出了一种基于视觉语言基础模型的通用领域适应方法，通过标签空间对齐显著提升了性能，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统通用领域适应方法主要关注视觉空间对齐，但常因内容差异导致的视觉模糊性而受限。本文旨在利用视觉语言基础模型的零样本能力，专注于标签空间对齐以提升适应稳定性。

Method: 提出了一种无需训练的标签空间对齐方法，通过过滤和精炼域间噪声标签，构建了一个集成共享知识和目标私有类信息的通用分类器。

Result: 在关键DomainBed基准测试中，该方法平均提升了7.9%的H-score和6.1%的H$^3$-score，结合自训练后还能额外提升1.6%。

Conclusion: 该方法通过利用视觉语言基础模型的零样本能力，专注于标签空间对齐而非视觉空间对齐，显著提高了通用领域适应的鲁棒性和泛化能力。实验结果表明，该方法在关键基准测试中平均提升了7.9%的H-score和6.1%的H$^3$-score，进一步结合自训练还能额外提升1.6%。

Abstract: Universal domain adaptation (UniDA) transfers knowledge from a labeled source
domain to an unlabeled target domain, where label spaces may differ and the
target domain may contain private classes. Previous UniDA methods primarily
focused on visual space alignment but often struggled with visual ambiguities
due to content differences, which limited their robustness and
generalizability. To overcome this, we introduce a novel approach that
leverages the strong \textit{zero-shot capabilities} of recent vision-language
foundation models (VLMs) like CLIP, concentrating solely on label space
alignment to enhance adaptation stability. CLIP can generate task-specific
classifiers based only on label names. However, adapting CLIP to UniDA is
challenging because the label space is not fully known in advance. In this
study, we first utilize generative vision-language models to identify unknown
categories in the target domain. Noise and semantic ambiguities in the
discovered labels -- such as those similar to source labels (e.g., synonyms,
hypernyms, hyponyms) -- complicate label alignment. To address this, we propose
a training-free label-space alignment method for UniDA (\ours). Our method
aligns label spaces instead of visual spaces by filtering and refining noisy
labels between the domains. We then construct a \textit{universal classifier}
that integrates both shared knowledge and target-private class information,
thereby improving generalizability under domain shifts. The results reveal that
the proposed method considerably outperforms existing UniDA techniques across
key DomainBed benchmarks, delivering an average improvement of
\textcolor{blue}{+7.9\%}in H-score and \textcolor{blue}{+6.1\%} in H$^3$-score.
Furthermore, incorporating self-training further enhances performance and
achieves an additional (\textcolor{blue}{+1.6\%}) increment in both H- and
H$^3$-scores.

</details>


### [124] [Uncertainty-Supervised Interpretable and Robust Evidential Segmentation](https://arxiv.org/abs/2509.17098)
*Yuzhu Li,An Sui,Fuping Wu,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出一种自监督方法，通过设计两种不确定性监督损失函数，显著提升医学图像分割中不确定性估计的可解释性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割中的不确定性估计方法缺乏有效监督，导致预测的可解释性和鲁棒性不足。

Method: 基于不确定性边界梯度与噪声关系的三个原则，设计了两种不确定性监督损失函数，并通过新提出的定量指标评估不确定性的可解释性和鲁棒性。

Result: 实验结果表明，该方法在分割性能和OOD场景中均优于现有方法，显著提升了不确定性的可解释性和鲁棒性。

Conclusion: 本文提出的自监督方法在医学图像分割的不确定性估计中表现出色，不仅保持了分割性能的竞争力，还在OOD场景中显著提升了不确定性的可解释性和鲁棒性。

Abstract: Uncertainty estimation has been widely studied in medical image segmentation
as a tool to provide reliability, particularly in deep learning approaches.
However, previous methods generally lack effective supervision in uncertainty
estimation, leading to low interpretability and robustness of the predictions.
In this work, we propose a self-supervised approach to guide the learning of
uncertainty. Specifically, we introduce three principles about the
relationships between the uncertainty and the image gradients around boundaries
and noise. Based on these principles, two uncertainty supervision losses are
designed. These losses enhance the alignment between model predictions and
human interpretation. Accordingly, we introduce novel quantitative metrics for
evaluating the interpretability and robustness of uncertainty. Experimental
results demonstrate that compared to state-of-the-art approaches, the proposed
method can achieve competitive segmentation performance and superior results in
out-of-distribution (OOD) scenarios while significantly improving the
interpretability and robustness of uncertainty estimation. Code is available
via https://github.com/suiannaius/SURE.

</details>


### [125] [Explainable AI for Analyzing Person-Specific Patterns in Facial Recognition Tasks](https://arxiv.org/abs/2509.17457)
*Paweł Jakub Borsukiewicz,Jordan Samhi,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CV

TL;DR: LEAM 是一种解释性技术，通过分析面部识别模型的关注区域，为个性化隐私保护提供依据，结果显示模型主要关注面部中央区域，且关键像素可跨模型迁移。


<details>
  <summary>Details</summary>
Motivation: 当前对抗技术缺乏个性化适配，限制了隐私保护的有效性。LEAM 旨在理解面部识别系统的工作原理，为未来隐私保护提供洞察。

Method: LEAM 结合面部解析器，分析了 1000 人的数据，覆盖 9 个预训练面部识别模型，揭示不同层级的关注区域差异。

Result: 研究发现面部识别模型普遍优先关注面部中央区域（鼻子占关键区域的 18.9%-29.7%），同时验证了 LEAM 识别的关键像素具有跨模型可迁移性。

Conclusion: LEAM 技术为未来基于个体面部特征的隐私保护系统奠定了基础，通过识别面部关键区域来指导扰动策略。

Abstract: The proliferation of facial recognition systems presents major privacy risks,
driving the need for effective countermeasures. Current adversarial techniques
apply generalized methods rather than adapting to individual facial
characteristics, limiting their effectiveness and inconspicuousness. In this
work, we introduce Layer Embedding Activation Mapping (LEAM), a novel technique
that identifies which facial areas contribute most to recognition at an
individual level. Unlike adversarial attack methods that aim to fool
recognition systems, LEAM is an explainability technique designed to understand
how these systems work, providing insights that could inform future privacy
protection research. We integrate LEAM with a face parser to analyze data from
1000 individuals across 9 pre-trained facial recognition models.
  Our analysis reveals that while different layers within facial recognition
models vary significantly in their focus areas, these models generally
prioritize similar facial regions across architectures when considering their
overall activation patterns, which show significantly higher similarity between
images of the same individual (Bhattacharyya Coefficient: 0.32-0.57) vs.
different individuals (0.04-0.13), validating the existence of person-specific
recognition patterns. Our results show that facial recognition models
prioritize the central region of face images (with nose areas accounting for
18.9-29.7% of critical recognition regions), while still distributing attention
across multiple facial fragments. Proper selection of relevant facial areas was
confirmed using validation occlusions, based on just 1% of the most relevant,
LEAM-identified, image pixels, which proved to be transferable across different
models. Our findings establish the foundation for future individually tailored
privacy protection systems centered around LEAM's choice of areas to be
perturbed.

</details>


### [126] [The SAGES Critical View of Safety Challenge: A Global Benchmark for AI-Assisted Surgical Quality Assessment](https://arxiv.org/abs/2509.17100)
*Deepak Alapatt,Jennifer Eckhoff,Zhiliang Lyu,Yutong Ban,Jean-Paul Mazellier,Sarah Choksi,Kunyi Yang,2024 CVS Challenge Consortium,Quanzheng Li,Filippo Filicori,Xiang Li,Pietro Mascagni,Daniel A. Hashimoto,Guy Rosman,Ozanan Meireles,Nicolas Padoy*

Main category: cs.CV

TL;DR: 该研究通过全球协作和AI挑战赛，展示了AI在手术质量评估中的应用潜力，显著提升了性能、校准和稳健性。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在利用AI技术解决手术质量评估中的关键障碍，如实现高性能、捕捉主观评估中的不确定性以及确保对临床变异的稳健性。

Method: 研究开发了EndoGlacier框架，用于管理大规模、异构的手术视频和多注释者工作流，并组织了全球54个机构的协作，收集了1000个视频并由20位外科专家根据共识验证协议进行注释。

Result: 13个国际团队参与挑战，实现了评估性能相对提升17%，校准误差减少80%以上，稳健性相对提升17%。

Conclusion: 该研究通过SAGES Critical View of Safety (CVS) Challenge展示了AI在手术质量评估中的潜力，为未来稳健、可临床部署的AI研究提供了方向。

Abstract: Advances in artificial intelligence (AI) for surgical quality assessment
promise to democratize access to expertise, with applications in training,
guidance, and accreditation. This study presents the SAGES Critical View of
Safety (CVS) Challenge, the first AI competition organized by a surgical
society, using the CVS in laparoscopic cholecystectomy, a universally
recommended yet inconsistently performed safety step, as an exemplar of
surgical quality assessment. A global collaboration across 54 institutions in
24 countries engaged hundreds of clinicians and engineers to curate 1,000
videos annotated by 20 surgical experts according to a consensus-validated
protocol. The challenge addressed key barriers to real-world deployment in
surgery, including achieving high performance, capturing uncertainty in
subjective assessment, and ensuring robustness to clinical variability. To
enable this scale of effort, we developed EndoGlacier, a framework for managing
large, heterogeneous surgical video and multi-annotator workflows. Thirteen
international teams participated, achieving up to a 17\% relative gain in
assessment performance, over 80\% reduction in calibration error, and a 17\%
relative improvement in robustness over the state-of-the-art. Analysis of
results highlighted methodological trends linked to model performance,
providing guidance for future research toward robust, clinically deployable AI
for surgical quality assessment.

</details>


### [127] [ChartHal: A Fine-grained Framework Evaluating Hallucination of Large Vision Language Models in Chart Understanding](https://arxiv.org/abs/2509.17481)
*Xingqi Wang,Yiming Cui,Xin Yao,Shijin Wang,Guoping Hu,Xiaoyu Qin*

Main category: cs.CV

TL;DR: 论文提出ChartHal基准，揭示LVLMs在图表理解中存在的严重幻觉问题，尤其是对缺失或矛盾信息处理不佳，呼吁开发更鲁棒的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究大型视觉语言模型（LVLMs）在图表理解中的幻觉问题，填补了现有研究中对幻觉与图表理解交叉领域探索的空白。

Method: 通过构建ChartHal基准，包含1,062个人工验证的样本，并设计了一个细粒度的幻觉场景分类法，评估了包括GPT-5和o4-mini在内的多种模型的表现。

Result: 评估结果显示，当前最先进的LVLMs在ChartHal上表现不佳，GPT-5和o4-mini的准确率分别仅为34.46%和22.79%，且涉及图表中缺失或矛盾信息的问题更容易引发幻觉。

Conclusion: 论文提出了ChartHal基准，揭示了当前最先进的大型视觉语言模型在图表理解中存在严重的幻觉问题，尤其是当问题涉及图表中缺失或矛盾信息时，强调了开发更鲁棒的缓解策略的紧迫性。

Abstract: Large Vision-Language Models (LVLMs) have recently demonstrated remarkable
progress, yet hallucination remains a critical barrier, particularly in chart
understanding, which requires sophisticated perceptual and cognitive abilities
as well as rigorous factual accuracy. While prior work has investigated
hallucinations and chart comprehension independently, their intersection
remains largely unexplored. To address this gap, we present ChartHal, a
benchmark that features a fine-grained taxonomy of hallucination scenarios in
chart understanding, along with a human-validated dataset of 1,062 samples. Our
evaluation shows that state-of-the-art LVLMs suffer from severe hallucinations
on ChartHal, including proprietary models such as GPT-5 and o4-mini, which
achieve only 34.46% and 22.79% accuracy, respectively. Further analysis reveals
that questions involving information absent from or contradictory to charts are
especially likely to trigger hallucinations, underscoring the urgent need for
more robust mitigation strategies. Code and data are available at
https://github.com/ymcui/ChartHal .

</details>


### [128] [Multimodal Medical Image Classification via Synergistic Learning Pre-training](https://arxiv.org/abs/2509.17492)
*Qinghua Lin,Guang-Hai Liu,Zuoyong Li,Yang Li,Yuting Jiang,Xiang Wu*

Main category: cs.CV

TL;DR: 提出了一种多模态半监督医学图像分类框架，通过预训练和微调实现模态融合，实验证明其在标签稀缺情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多模态医学图像在标签稀缺情况下的模态融合问题，提升计算机视觉辅助诊断的性能。

Method: 提出了一种基于'预训练+微调'框架的多模态半监督医学图像分类方法，包括协同学习预训练（一致性、重构和对齐学习）和多模态融合微调（不同编码器提取特征及融合编码器）。

Result: 在公开数据集Kvasir和Kvasirv2上的实验表明，该方法在定量和定性结果上均优于当前最先进的分类方法。

Conclusion: 提出的'预训练+微调'框架在缺乏专家标注数据的情况下，通过协同学习预训练和多模态融合微调，显著提升了多模态医学图像分类的性能。

Abstract: Multimodal pathological images are usually in clinical diagnosis, but
computer vision-based multimodal image-assisted diagnosis faces challenges with
modality fusion, especially in the absence of expert-annotated data. To achieve
the modality fusion in multimodal images with label scarcity, we propose a
novel ``pretraining + fine-tuning" framework for multimodal semi-supervised
medical image classification. Specifically, we propose a synergistic learning
pretraining framework of consistency, reconstructive, and aligned learning. By
treating one modality as an augmented sample of another modality, we implement
a self-supervised learning pre-train, enhancing the baseline model's feature
representation capability. Then, we design a fine-tuning method for multimodal
fusion. During the fine-tuning stage, we set different encoders to extract
features from the original modalities and provide a multimodal fusion encoder
for fusion modality. In addition, we propose a distribution shift method for
multimodal fusion features, which alleviates the prediction uncertainty and
overfitting risks caused by the lack of labeled samples. We conduct extensive
experiments on the publicly available gastroscopy image datasets Kvasir and
Kvasirv2. Quantitative and qualitative results demonstrate that the proposed
method outperforms the current state-of-the-art classification methods. The
code will be released at: https://github.com/LQH89757/MICS.

</details>


### [129] [Stencil: Subject-Driven Generation with Context Guidance](https://arxiv.org/abs/2509.17120)
*Gordon Chen,Ziqi Huang,Cheston Tan,Ziwei Liu*

Main category: cs.CV

TL;DR: Stencil通过双扩散模型框架解决了主题一致性问题，平衡了质量与效率，实现了快速高保真生成。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在保持主题一致性方面存在不足，且现有微调方法在质量与效率之间存在明显权衡。

Method: Stencil采用双扩散模型框架，其中轻量级模型在主题图像上进行高效微调，而大型冻结预训练模型在推理过程中提供上下文指导。

Result: Stencil能在不到一分钟内生成高保真度的主题新表现形式，实现了最先进的性能。

Conclusion: Stencil框架通过联合使用轻量级和大型预训练扩散模型，在推理过程中注入丰富的先验知识，实现了高质量、高效率的主题驱动生成，树立了新的性能标杆。

Abstract: Recent text-to-image diffusion models can generate striking visuals from text
prompts, but they often fail to maintain subject consistency across generations
and contexts. One major limitation of current fine-tuning approaches is the
inherent trade-off between quality and efficiency. Fine-tuning large models
improves fidelity but is computationally expensive, while fine-tuning
lightweight models improves efficiency but compromises image fidelity.
Moreover, fine-tuning pre-trained models on a small set of images of the
subject can damage the existing priors, resulting in suboptimal results. To
this end, we present Stencil, a novel framework that jointly employs two
diffusion models during inference. Stencil efficiently fine-tunes a lightweight
model on images of the subject, while a large frozen pre-trained model provides
contextual guidance during inference, injecting rich priors to enhance
generation with minimal overhead. Stencil excels at generating high-fidelity,
novel renditions of the subject in less than a minute, delivering
state-of-the-art performance and setting a new benchmark in subject-driven
generation.

</details>


### [130] [An Empirical Study on the Robustness of YOLO Models for Underwater Object Detection](https://arxiv.org/abs/2509.17561)
*Edwine Nabahirwa,Wei Song,Minghua Zhang,Shufan Chen*

Main category: cs.CV

TL;DR: 本研究首次系统评估YOLO变体在水下环境中的鲁棒性，发现YOLOv12性能最佳但易受噪声影响，并提出轻量级训练策略以提升检测系统性能。


<details>
  <summary>Details</summary>
Motivation: 探讨YOLO模型在水下混沌和不可预测环境中是否真正稳健，填补了系统评估其在独特挑战条件下鲁棒性的研究空白。

Method: 通过统一数据集（DUO和Roboflow100的10,000张标注图像）对YOLO变体（YOLOv8-YOLOv12）在六种模拟水下环境中的性能进行综合评估，并分析失真对纹理、边缘和颜色等关键低级特征的影响。

Result: 1. YOLOv12整体性能最强但对噪声高度敏感；2. 噪声破坏边缘和纹理特征，导致检测性能下降；3. 图像数量和实例频率是检测性能的主要驱动力，而物体外观影响较小；4. 噪声感知样本注入和高级增强微调策略分别提升了鲁棒性和域适应能力。

Conclusion: 本研究为构建稳健且成本效益高的水下目标检测系统提供了实用指导，展示了轻量级训练感知策略的潜力。

Abstract: Underwater object detection (UOD) remains a critical challenge in computer
vision due to underwater distortions which degrade low-level features and
compromise the reliability of even state-of-the-art detectors. While YOLO
models have become the backbone of real-time object detection, little work has
systematically examined their robustness under these uniquely challenging
conditions. This raises a critical question: Are YOLO models genuinely robust
when operating under the chaotic and unpredictable conditions of underwater
environments? In this study, we present one of the first comprehensive
evaluations of recent YOLO variants (YOLOv8-YOLOv12) across six simulated
underwater environments. Using a unified dataset of 10,000 annotated images
from DUO and Roboflow100, we not only benchmark model robustness but also
analyze how distortions affect key low-level features such as texture, edges,
and color. Our findings show that (1) YOLOv12 delivers the strongest overall
performance but is highly vulnerable to noise, and (2) noise disrupts edge and
texture features, explaining the poor detection performance in noisy images.
Class imbalance is a persistent challenge in UOD. Experiments revealed that (3)
image counts and instance frequency primarily drive detection performance,
while object appearance exerts only a secondary influence. Finally, we
evaluated lightweight training-aware strategies: noise-aware sample injection,
which improves robustness in both noisy and real-world conditions, and
fine-tuning with advanced enhancement, which boosts accuracy in enhanced
domains but slightly lowers performance in original data, demonstrating strong
potential for domain adaptation, respectively. Together, these insights provide
practical guidance for building resilient and cost-efficient UOD systems.

</details>


### [131] [MRN: Harnessing 2D Vision Foundation Models for Diagnosing Parkinson's Disease with Limited 3D MR Data](https://arxiv.org/abs/2509.17566)
*Ding Shaodong,Liu Ziyang,Zhou Yijun,Liu Tao*

Main category: cs.CV

TL;DR: 利用2D视觉基础模型处理3D MR图像关键ROI，结合对比学习，在少量数据下实现帕金森病诊断高性能，比赛准确率86.0%。


<details>
  <summary>Details</summary>
Motivation: 帕金森病自动诊断需求高，但现有方法因数据稀缺和3D模型适配困难易过拟合。研究旨在利用2D VFMs克服这些挑战，提升诊断准确性。

Method: 研究采用2D VFMs处理3D MR图像的关键ROI，通过分支压缩ROI为token并整合为统一患者表征。引入辅助分割头指导特征提取，并结合多ROI监督对比学习优化分类性能。

Result: 该方法在MICCAI 2025 PDCADxFoundation挑战赛中以86.0%准确率夺冠，仅需300例标注数据，优于第二名5.5%。

Conclusion: 该研究展示了2D视觉基础模型（VFMs）在3D MR图像临床分析中的潜力，特别是在帕金森病自动诊断中的应用。通过创新的多ROI处理和对比学习策略，即使在有限数据集下也能实现高性能。

Abstract: The automatic diagnosis of Parkinson's disease is in high clinical demand due
to its prevalence and the importance of targeted treatment. Current clinical
practice often relies on diagnostic biomarkers in QSM and NM-MRI images.
However, the lack of large, high-quality datasets makes training diagnostic
models from scratch prone to overfitting. Adapting pre-trained 3D medical
models is also challenging, as the diversity of medical imaging leads to
mismatches in voxel spacing and modality between pre-training and fine-tuning
data. In this paper, we address these challenges by leveraging 2D vision
foundation models (VFMs). Specifically, we crop multiple key ROIs from NM and
QSM images, process each ROI through separate branches to compress the ROI into
a token, and then combine these tokens into a unified patient representation
for classification. Within each branch, we use 2D VFMs to encode axial slices
of the 3D ROI volume and fuse them into the ROI token, guided by an auxiliary
segmentation head that steers the feature extraction toward specific brain
nuclei. Additionally, we introduce multi-ROI supervised contrastive learning,
which improves diagnostic performance by pulling together representations of
patients from the same class while pushing away those from different classes.
Our approach achieved first place in the MICCAI 2025 PDCADxFoundation
challenge, with an accuracy of 86.0% trained on a dataset of only 300 labeled
QSM and NM-MRI scans, outperforming the second-place method by 5.5%.These
results highlight the potential of 2D VFMs for clinical analysis of 3D MR
images.

</details>


### [132] [SynergyNet: Fusing Generative Priors and State-Space Models for Facial Beauty Prediction](https://arxiv.org/abs/2509.17172)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: MD-Net是一种双流架构，结合预训练扩散模型和Vision Mamba，高效预测面部美观，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN或ViT的模型在面部美观预测中存在架构偏差，CNN擅长局部特征提取但不擅长长距离依赖，ViT虽能建模全局关系但计算成本高。MD-Net旨在解决这一权衡问题。

Method: MD-Net采用双流架构，第一流利用预训练的潜在扩散模型的U-Net编码器提取细粒度美学特征，第二流使用Vision Mamba（Vim）高效捕获全局面部结构。通过交叉注意力机制整合这两种互补表示。

Result: 在SCUT-FBP5500基准测试中，MD-Net达到了Pearson相关系数0.9235，创下新纪录。

Conclusion: MD-Net通过结合生成和序列建模范式，为复杂视觉评估任务提供了新的解决方案，展示了混合架构的显著潜力。

Abstract: The automated prediction of facial beauty is a benchmark task in affective
computing that requires a sophisticated understanding of both local aesthetic
details (e.g., skin texture) and global facial harmony (e.g., symmetry,
proportions). Existing models, based on either Convolutional Neural Networks
(CNNs) or Vision Transformers (ViTs), exhibit inherent architectural biases
that limit their performance; CNNs excel at local feature extraction but
struggle with long-range dependencies, while ViTs model global relationships at
a significant computational cost. This paper introduces the
\textbf{Mamba-Diffusion Network (MD-Net)}, a novel dual-stream architecture
that resolves this trade-off by delegating specialized roles to
state-of-the-art models. The first stream leverages a frozen U-Net encoder from
a pre-trained latent diffusion model, providing a powerful generative prior for
fine-grained aesthetic qualities. The second stream employs a Vision Mamba
(Vim), a modern state-space model, to efficiently capture global facial
structure with linear-time complexity. By synergistically integrating these
complementary representations through a cross-attention mechanism, MD-Net
creates a holistic and nuanced feature space for prediction. Evaluated on the
SCUT-FBP5500 benchmark, MD-Net sets a new state-of-the-art, achieving a Pearson
Correlation of \textbf{0.9235} and demonstrating the significant potential of
hybrid architectures that fuse generative and sequential modeling paradigms for
complex visual assessment tasks.

</details>


### [133] [Interpreting Attention Heads for Image-to-Text Information Flow in Large Vision-Language Models](https://arxiv.org/abs/2509.17588)
*Jinyeong Kim,Seil Kang,Jiwoo Park,Junhyeok Kim,Seong Jae Hwang*

Main category: cs.CV

TL;DR: 研究提出“头归因”技术分析LVLMs中图像到文本信息流，发现特定注意力头子集起关键作用，且选择基于语义内容。信息流动遵循结构化过程，为理解LVLMs机制提供新视角。


<details>
  <summary>Details</summary>
Motivation: 尽管图像到文本的信息流在视觉问答中至关重要，但由于大量注意力头的同时运作，其底层机制仍难以解释。

Method: 提出了一种称为“头归因”的技术，受组件归因方法启发，用于识别在信息传递中起关键作用的注意力头的一致模式。

Result: 研究发现，特定的注意力头子集促进了图像到文本的信息流，且这些头的选择由输入图像的语义内容而非视觉外观决定。此外，信息在标记级别流动时，文本信息首先传播到角色相关标记和最终标记，然后接收图像信息；图像信息则嵌入在对象相关和背景标记中。

Conclusion: 研究证明，图像到文本的信息流遵循结构化过程，注意力头级别的分析为理解大型视觉语言模型（LVLMs）的机制提供了有前景的方向。

Abstract: Large Vision-Language Models (LVLMs) answer visual questions by transferring
information from images to text through a series of attention heads. While this
image-to-text information flow is central to visual question answering, its
underlying mechanism remains difficult to interpret due to the simultaneous
operation of numerous attention heads. To address this challenge, we propose
head attribution, a technique inspired by component attribution methods, to
identify consistent patterns among attention heads that play a key role in
information transfer. Using head attribution, we investigate how LVLMs rely on
specific attention heads to identify and answer questions about the main object
in an image. Our analysis reveals that a distinct subset of attention heads
facilitates the image-to-text information flow. Remarkably, we find that the
selection of these heads is governed by the semantic content of the input image
rather than its visual appearance. We further examine the flow of information
at the token level and discover that (1) text information first propagates to
role-related tokens and the final token before receiving image information, and
(2) image information is embedded in both object-related and background tokens.
Our work provides evidence that image-to-text information flow follows a
structured process, and that analysis at the attention-head level offers a
promising direction toward understanding the mechanisms of LVLMs.

</details>


### [134] [A$^2$M$^2$-Net: Adaptively Aligned Multi-Scale Moment for Few-Shot Action Recognition](https://arxiv.org/abs/2509.17638)
*Zilin Gao,Qilong Wang,Bingbing Zhang,Qinghua Hu,Peihua Li*

Main category: cs.CV

TL;DR: A$^2$M$^2$-Net通过自适应对齐和多尺度二阶矩块有效解决了FSAR中的时间错位问题，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有FSAR方法通常忽略个体运动模式的作用，且未充分探索视频动态的特征统计，导致难以处理时间错位问题。

Method: 提出A$^2$M$^2$-Net，包含自适应对齐模块（A$^2$模块）和多尺度二阶矩块（M$^2$块），用于描述视频动态并自适应对齐。

Result: 在五个广泛使用的FSAR基准测试中，A$^2$M$^2$-Net表现优异，与最先进方法相比具有竞争力。

Conclusion: A$^2$M$^2$-Net在多个FSAR基准测试中表现出色，证明了其在处理时间错位问题和泛化能力方面的有效性。

Abstract: Thanks to capability to alleviate the cost of large-scale annotation,
few-shot action recognition (FSAR) has attracted increased attention of
researchers in recent years. Existing FSAR approaches typically neglect the
role of individual motion pattern in comparison, and under-explore the feature
statistics for video dynamics. Thereby, they struggle to handle the challenging
temporal misalignment in video dynamics, particularly by using 2D backbones. To
overcome these limitations, this work proposes an adaptively aligned
multi-scale second-order moment network, namely A$^2$M$^2$-Net, to describe the
latent video dynamics with a collection of powerful representation candidates
and adaptively align them in an instance-guided manner. To this end, our
A$^2$M$^2$-Net involves two core components, namely, adaptive alignment (A$^2$
module) for matching, and multi-scale second-order moment (M$^2$ block) for
strong representation. Specifically, M$^2$ block develops a collection of
semantic second-order descriptors at multiple spatio-temporal scales.
Furthermore, A$^2$ module aims to adaptively select informative candidate
descriptors while considering the individual motion pattern. By such means, our
A$^2$M$^2$-Net is able to handle the challenging temporal misalignment problem
by establishing an adaptive alignment protocol for strong representation.
Notably, our proposed method generalizes well to various few-shot settings and
diverse metrics. The experiments are conducted on five widely used FSAR
benchmarks, and the results show our A$^2$M$^2$-Net achieves very competitive
performance compared to state-of-the-arts, demonstrating its effectiveness and
generalization.

</details>


### [135] [VaseVQA: Multimodal Agent and Benchmark for Ancient Greek Pottery](https://arxiv.org/abs/2509.17191)
*Jinchao Ge,Tengfei Cheng,Biao Wu,Zeyu Zhang,Shiya Huang,Judith Bishop,Gillian Shepherd,Meng Fang,Ling Chen,Yang Zhao*

Main category: cs.CV

TL;DR: VaseVL通过SFT-then-RL方法提升古代希腊陶器分析的专家级推理能力，发布VaseVQA基准，实验显示在风格分类和历史归属任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）在文化遗产分析中缺乏领域专业知识的问题，避免SFT过拟合表面模式导致的脆弱推理。

Method: VaseVL采用SFT-then-RL系统，构建问题类型的分类法，通过探测SFT模型定位性能差距，并针对这些差距优化类型条件和组合性导向的奖励。

Result: 在风格分类和历史归属任务上取得了最先进的结果，并在组合鲁棒性上显著优于仅SFT的基线。

Conclusion: VaseVL系统通过SFT-then-RL方法显著提升了古代希腊陶器的风格分类和历史归属任务的性能，验证了诊断引导和分类条件奖励工程的有效性，并为未来研究提供了可重复利用的资源。

Abstract: Analyzing cultural-heritage artifacts remains challenging for MLLMs: general
models lack domain expertise, and SFT often overfits superficial patterns,
yielding brittle reasoning for authentication and historical attribution. This
raises the question of how to equip MLLMs with robust, expert-level reasoning
for ancient Greek pottery. We present VaseVL, an SFT-then-RL system that turns
evaluation into supervision: we construct a taxonomy of question types, probe
the SFT model to localize type-specific performance gaps, and optimize with
type-conditioned, compositionality-oriented rewards targeting those gaps. We
also release VaseVQA, a comprehensive benchmark of 31,773 images designed to
probe deep understanding. Experiments show state-of-the-art results on style
classification and historical attribution with marked gains in compositional
robustness over SFT-only baselines, validating diagnosis-guided,
taxonomy-conditioned reward engineering and providing a reusable resource for
future research. Code and dataset will be available at
https://github.com/AIGeeksGroup/VaseVQA.

</details>


### [136] [SD-VLM: Spatial Measuring and Understanding with Depth-Encoded Vision-Language Models](https://arxiv.org/abs/2509.17664)
*Pingyi Chen,Yujing Lou,Shen Cao,Jinhui Guo,Lubin Fan,Yue Wu,Lin Yang,Lizhuang Ma,Jieping Ye*

Main category: cs.CV

TL;DR: SD-VLM通过新数据集和深度编码方法，显著提升VLMs的3D空间理解能力，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 由于2D图像在空间表示能力上的不足，VLMs在3D空间关系定量推理方面的能力未被充分探索。

Method: 提出MSMU数据集（包含700K QA对、2.5M物理数值标注和10K链式思维增强样本）和一种简单的深度位置编码方法。

Result: SD-VLM在MSMU-Bench上优于GPT-4o和Intern-VL3-78B，分别提升26.91%和25.56%，并在其他空间理解基准测试中展现出泛化能力。

Conclusion: SD-VLM通过提出的MSMU数据集和深度位置编码方法，显著提升了VLMs在3D空间关系理解上的能力，并在多个基准测试中表现出优越性能。

Abstract: While vision language models (VLMs) excel in 2D semantic visual
understanding, their ability to quantitatively reason about 3D spatial
relationships remains under-explored, due to the deficiency of 2D images'
spatial representation ability. In this paper, we analyze the problem hindering
VLMs' spatial understanding abilities and propose SD-VLM, a novel framework
that significantly enhances fundamental spatial perception abilities of VLMs
through two key contributions: (1) propose Massive Spatial Measuring and
Understanding (MSMU) dataset with precise spatial annotations, and (2)
introduce a simple depth positional encoding method strengthening VLMs' spatial
awareness. MSMU dataset covers massive quantitative spatial tasks with 700K QA
pairs, 2.5M physical numerical annotations, and 10K chain-of-thought augmented
samples. We have trained SD-VLM, a strong generalist VLM which shows superior
quantitative spatial measuring and understanding capability. SD-VLM not only
achieves state-of-the-art performance on our proposed MSMU-Bench, but also
shows spatial generalization abilities on other spatial understanding
benchmarks including Q-Spatial and SpatialRGPT-Bench. Extensive experiments
demonstrate that SD-VLM outperforms GPT-4o and Intern-VL3-78B by 26.91% and
25.56% respectively on MSMU-Bench. Code and models are released at
https://github.com/cpystan/SD-VLM.

</details>


### [137] [Predicting Depth Maps from Single RGB Images and Addressing Missing Information in Depth Estimation](https://arxiv.org/abs/2509.17686)
*Mohamad Mofeed Chaar,Jamal Raiyn,Galia Weidl*

Main category: cs.CV

TL;DR: 研究提出一种多层训练算法，从RGB图像生成深度图像并填补信息缺失，在Cityscapes数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度图像在自动驾驶系统中至关重要，但存在信息缺失的挑战，影响了物体检测和测量的准确性。

Method: 采用多层训练方法开发算法，从单张RGB图像生成深度图像，并填补深度图像中的信息缺失。

Result: 在Cityscapes数据集上测试，算法成功解决了深度图像中的信息缺失问题，生成了完整且准确的深度图像。

Conclusion: 该研究成功开发了一种算法，能够从单张RGB图像生成深度图像，并有效解决了深度图像中信息缺失的问题，在Cityscapes数据集上验证了其在实际城市环境中的有效性。

Abstract: Depth imaging is a crucial area in Autonomous Driving Systems (ADS), as it
plays a key role in detecting and measuring objects in the vehicle's
surroundings. However, a significant challenge in this domain arises from
missing information in Depth images, where certain points are not measurable
due to gaps or inconsistencies in pixel data. Our research addresses two key
tasks to overcome this challenge. First, we developed an algorithm using a
multi-layered training approach to generate Depth images from a single RGB
image. Second, we addressed the issue of missing information in Depth images by
applying our algorithm to rectify these gaps, resulting in Depth images with
complete and accurate data. We further tested our algorithm on the Cityscapes
dataset and successfully resolved the missing information in its Depth images,
demonstrating the effectiveness of our approach in real-world urban
environments.

</details>


### [138] [Dual-View Alignment Learning with Hierarchical-Prompt for Class-Imbalance Multi-Label Classification](https://arxiv.org/abs/2509.17747)
*Sheng Huang,Jiexuan Yan,Beiyan Liu,Bo Liu,Richang Hong*

Main category: cs.CV

TL;DR: HP-DVAL方法通过双视角对齐和分层提示调优，有效解决了多标签图像分类中的类不平衡问题，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据集常呈现跨多类别的类不平衡现象，尤其是在类不平衡多标签图像分类任务中，数据不平衡和多目标识别带来了重大挑战。

Method: 提出了一种名为HP-DVAL的新方法，结合双视角对齐学习和分层提示调优策略，利用视觉语言预训练模型的多模态知识来解决多标签设置中的类不平衡问题。

Result: 在MS-COCO和VOC2007基准测试中，HP-DVAL方法在长尾多标签图像分类任务上实现了10.0%和5.2%的mAP提升，在多标签少样本图像分类任务上实现了6.8%和2.9%的mAP提升。

Conclusion: HP-DVAL方法通过双视角对齐学习和分层提示调优策略，显著提升了类不平衡多标签图像分类任务的性能，并在MS-COCO和VOC2007基准测试中取得了优于现有技术的结果。

Abstract: Real-world datasets often exhibit class imbalance across multiple categories,
manifesting as long-tailed distributions and few-shot scenarios. This is
especially challenging in Class-Imbalanced Multi-Label Image Classification
(CI-MLIC) tasks, where data imbalance and multi-object recognition present
significant obstacles. To address these challenges, we propose a novel method
termed Dual-View Alignment Learning with Hierarchical Prompt (HP-DVAL), which
leverages multi-modal knowledge from vision-language pretrained (VLP) models to
mitigate the class-imbalance problem in multi-label settings. Specifically,
HP-DVAL employs dual-view alignment learning to transfer the powerful feature
representation capabilities from VLP models by extracting complementary
features for accurate image-text alignment. To better adapt VLP models for
CI-MLIC tasks, we introduce a hierarchical prompt-tuning strategy that utilizes
global and local prompts to learn task-specific and context-related prior
knowledge. Additionally, we design a semantic consistency loss during prompt
tuning to prevent learned prompts from deviating from general knowledge
embedded in VLP models. The effectiveness of our approach is validated on two
CI-MLIC benchmarks: MS-COCO and VOC2007. Extensive experimental results
demonstrate the superiority of our method over SOTA approaches, achieving mAP
improvements of 10.0\% and 5.2\% on the long-tailed multi-label image
classification task, and 6.8\% and 2.9\% on the multi-label few-shot image
classification task.

</details>


### [139] [MirrorSAM2: Segment Mirror in Videos with Depth Perception](https://arxiv.org/abs/2509.17220)
*Mingchen Xu,Yukun Lai,Ze Ji,Jing Wu*

Main category: cs.CV

TL;DR: MirrorSAM2是首个将SAM2适配到RGB-D视频镜面分割任务的框架，通过四个定制模块解决了反射模糊等问题，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决RGB-D视频镜面分割中的反射模糊和纹理混淆等关键挑战，扩展SAM2的能力至无提示设置。

Method: MirrorSAM2引入了四个模块：深度扭曲模块（Depth Warping Module）、深度引导多尺度点提示生成器（Depth-guided Multi-Scale Point Prompt Generator）、频率细节注意力融合模块（Frequency Detail Attention Fusion Module）和带有可学习镜面标记的镜面掩码解码器（Mirror Mask Decoder）。

Result: 在VMD和DVMD基准测试中，MirrorSAM2实现了最先进的性能，尤其是在小镜子、弱边界和强反射等挑战性条件下表现优异。

Conclusion: MirrorSAM2通过四个定制模块成功将SAM2扩展到无提示设置的RGB-D视频镜面分割任务中，并在VMD和DVMD基准测试中实现了最先进的性能，即使在具有挑战性的条件下也是如此。

Abstract: This paper presents MirrorSAM2, the first framework that adapts Segment
Anything Model 2 (SAM2) to the task of RGB-D video mirror segmentation.
MirrorSAM2 addresses key challenges in mirror detection, such as reflection
ambiguity and texture confusion, by introducing four tailored modules: a Depth
Warping Module for RGB and depth alignment, a Depth-guided Multi-Scale Point
Prompt Generator for automatic prompt generation, a Frequency Detail Attention
Fusion Module to enhance structural boundaries, and a Mirror Mask Decoder with
a learnable mirror token for refined segmentation. By fully leveraging the
complementarity between RGB and depth, MirrorSAM2 extends SAM2's capabilities
to the prompt-free setting. To our knowledge, this is the first work to enable
SAM2 for automatic video mirror segmentation. Experiments on the VMD and DVMD
benchmark demonstrate that MirrorSAM2 achieves SOTA performance, even under
challenging conditions such as small mirrors, weak boundaries, and strong
reflections.

</details>


### [140] [Accurate and Efficient Low-Rank Model Merging in Core Space](https://arxiv.org/abs/2509.17786)
*Aniello Panariello,Daniel Marczak,Simone Magistri,Angelo Porrello,Bartłomiej Twardowski,Andrew D. Bagdanov,Simone Calderara,Joost van de Weijer*

Main category: cs.CV

TL;DR: Core Space框架高效合并LoRA模型，保持低秩适应效率并提升准确性，在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有合并方法在合并低秩适应（LoRA）模型时牺牲效率的问题。

Method: 提出了Core Space合并框架，通过将LoRA适应模型投影到一个共同的对齐空间中进行合并，并提供了形式化证明和信息无损的复杂性分析。

Result: Core Space显著提升了现有合并技术，在视觉和语言任务上达到了最先进的性能，同时仅使用少量计算资源。

Conclusion: Core Space框架通过在一个共同的对齐基础上合并LoRA适应模型，不仅保持了低秩适应的效率，还在多个任务上显著提高了准确性。

Abstract: In this paper, we address the challenges associated with merging low-rank
adaptations of large neural networks. With the rise of parameter-efficient
adaptation techniques, such as Low-Rank Adaptation (LoRA), model fine-tuning
has become more accessible. While fine-tuning models with LoRA is highly
efficient, existing merging methods often sacrifice this efficiency by merging
fully-sized weight matrices. We propose the Core Space merging framework, which
enables the merging of LoRA-adapted models within a common alignment basis,
thereby preserving the efficiency of low-rank adaptation while substantially
improving accuracy across tasks. We further provide a formal proof that
projection into Core Space ensures no loss of information and provide a
complexity analysis showing the efficiency gains. Extensive empirical results
demonstrate that Core Space significantly improves existing merging techniques
and achieves state-of-the-art results on both vision and language tasks while
utilizing a fraction of the computational resources. Codebase is available at
https://github.com/apanariello4/core-space-merging.

</details>


### [141] [DT-NeRF: A Diffusion and Transformer-Based Optimization Approach for Neural Radiance Fields in 3D Reconstruction](https://arxiv.org/abs/2509.17232)
*Bo Liu,Runlong Li,Li Zhou,Yan Zhou*

Main category: cs.CV

TL;DR: DT-NeRF结合扩散模型与Transformer，显著提升3D重建的细节和一致性，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统NeRF在复杂几何场景中细节恢复和多视角一致性方面存在不足，需改进。

Method: 结合扩散模型与Transformer，提出DT-NeRF方法，用于提升稀疏视角下的细节恢复和多视角一致性。

Result: 在Matterport3D和ShapeNet数据集上，DT-NeRF在PSNR、SSIM等指标上显著优于现有方法。消融实验验证了扩散和Transformer模块的关键作用。

Conclusion: DT-NeRF通过结合扩散模型和Transformer，为3D场景重建提供了高效准确的解决方案，未来研究可进一步优化模型以应对大规模动态场景。

Abstract: This paper proposes a Diffusion Model-Optimized Neural Radiance Field
(DT-NeRF) method, aimed at enhancing detail recovery and multi-view consistency
in 3D scene reconstruction. By combining diffusion models with Transformers,
DT-NeRF effectively restores details under sparse viewpoints and maintains high
accuracy in complex geometric scenes. Experimental results demonstrate that
DT-NeRF significantly outperforms traditional NeRF and other state-of-the-art
methods on the Matterport3D and ShapeNet datasets, particularly in metrics such
as PSNR, SSIM, Chamfer Distance, and Fidelity. Ablation experiments further
confirm the critical role of the diffusion and Transformer modules in the
model's performance, with the removal of either module leading to a decline in
performance. The design of DT-NeRF showcases the synergistic effect between
modules, providing an efficient and accurate solution for 3D scene
reconstruction. Future research may focus on further optimizing the model,
exploring more advanced generative models and network architectures to enhance
its performance in large-scale dynamic scenes.

</details>


### [142] [TS-P$^2$CL: Plug-and-Play Dual Contrastive Learning for Vision-Guided Medical Time Series Classification](https://arxiv.org/abs/2509.17802)
*Qi'ao Xu,Pengfei Wang,Bo Zhong,Tianwen Qian,Xiaoling Wang,Ye Wang,Hong Yu*

Main category: cs.CV

TL;DR: TS-P$^2$CL通过将生理信号转为2D图像并利用预训练视觉模型，提升了医疗时间序列分类的跨主体性能。


<details>
  <summary>Details</summary>
Motivation: 医疗时间序列分类在智能医疗中至关重要，但现有方法受限于模态特定的归纳偏差，难以学习跨主体的通用不变表示。

Method: 提出TS-P$^2$CL框架，通过视觉引导范式将1D生理信号转换为2D伪图像，并采用双对比学习策略（模态内一致性和跨模态对齐）来学习领域不变特征。

Result: 在六个医疗时间序列数据集上的实验表明，TS-P$^2$CL在主体依赖和主体独立设置下均优于14种现有方法。

Conclusion: TS-P$^2$CL框架通过将1D生理信号转换为2D伪图像，并利用预训练视觉模型的通用模式识别能力，显著提升了医疗时间序列分类的跨主体泛化性能。

Abstract: Medical time series (MedTS) classification is pivotal for intelligent
healthcare, yet its efficacy is severely limited by poor cross-subject
generation due to the profound cross-individual heterogeneity. Despite advances
in architectural innovations and transfer learning techniques, current methods
remain constrained by modality-specific inductive biases that limit their
ability to learn universally invariant representations. To overcome this, we
propose TS-P$^2$CL, a novel plug-and-play framework that leverages the
universal pattern recognition capabilities of pre-trained vision models. We
introduce a vision-guided paradigm that transforms 1D physiological signals
into 2D pseudo-images, establishing a bridge to the visual domain. This
transformation enables implicit access to rich semantic priors learned from
natural images. Within this unified space, we employ a dual-contrastive
learning strategy: intra-modal consistency enforces temporal coherence, while
cross-modal alignment aligns time-series dynamics with visual semantics,
thereby mitigating individual-specific biases and learning robust,
domain-invariant features. Extensive experiments on six MedTS datasets
demonstrate that TS-P$^2$CL consistently outperforms fourteen methods in both
subject-dependent and subject-independent settings.

</details>


### [143] [SPFSplatV2: Efficient Self-Supervised Pose-Free 3D Gaussian Splatting from Sparse Views](https://arxiv.org/abs/2509.17246)
*Ranran Huang,Krystian Mikolajczyk*

Main category: cs.CV

TL;DR: SPFSplatV2是无真实姿态依赖的高效3D高斯泼溅框架，通过共享特征提取和掩码注意力机制，在稀疏多视图下实现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏多视图图像下3D高斯泼溅的效率和真实姿态依赖问题，提升新颖视图合成的性能。

Method: 采用共享特征提取骨干网络，同时预测3D高斯基元和相机姿态，并引入掩码注意力机制和重投影损失以增强几何约束。

Result: 在无姿态监督的情况下，实现了最先进的性能，包括极端视角变化和有限图像重叠的场景。

Conclusion: SPFSplatV2通过消除对真实姿态的依赖，提供了更高的可扩展性，能够利用更大、更多样的数据集。

Abstract: We introduce SPFSplatV2, an efficient feed-forward framework for 3D Gaussian
splatting from sparse multi-view images, requiring no ground-truth poses during
training and inference. It employs a shared feature extraction backbone,
enabling simultaneous prediction of 3D Gaussian primitives and camera poses in
a canonical space from unposed inputs. A masked attention mechanism is
introduced to efficiently estimate target poses during training, while a
reprojection loss enforces pixel-aligned Gaussian primitives, providing
stronger geometric constraints. We further demonstrate the compatibility of our
training framework with different reconstruction architectures, resulting in
two model variants. Remarkably, despite the absence of pose supervision, our
method achieves state-of-the-art performance in both in-domain and
out-of-domain novel view synthesis, even under extreme viewpoint changes and
limited image overlap, and surpasses recent methods that rely on geometric
supervision for relative pose estimation. By eliminating dependence on
ground-truth poses, our method offers the scalability to leverage larger and
more diverse datasets. Code and pretrained models will be available on our
project page: https://ranrhuang.github.io/spfsplatv2/.

</details>


### [144] [Trainee Action Recognition through Interaction Analysis in CCATT Mixed-Reality Training](https://arxiv.org/abs/2509.17888)
*Divya Mereddy,Marcos Quinones-Grueiro,Ashwin T S,Eduardo Davalos,Gautam Biswas,Kent Etherton,Tyler Davis,Katelyn Kay,Jill Lear,Benjamin Goldberg*

Main category: cs.CV

TL;DR: 本研究通过结合CTA与MMLA，开发了一种自动化评估框架，用于客观评估CCATT成员在高压混合现实模拟中的表现。


<details>
  <summary>Details</summary>
Motivation: 传统的主观评估方法可能忽略关键事件，限制了评估的普遍性和一致性。AI驱动的自动化评估虽更客观，但仍需人工输入以训练算法评估复杂团队动态。

Method: 开发了针对CCATT训练的领域特定CTA模型，并利用微调的人-物交互模型（Cascade Disentangling Network, CDN）构建了基于视觉的动作识别流程，以检测和跟踪学员与设备的交互。

Result: 通过自动生成的性能指标（如反应时间、任务持续时间）映射到定制的层次化CTA模型，实现了可解释、领域相关的性能评估。

Conclusion: 本研究提出了一种结合认知任务分析（CTA）与多模态学习分析（MMLA）的系统化、数据驱动的评估框架，用于提升CCATT成员在混合现实模拟训练中的表现评估。

Abstract: This study examines how Critical Care Air Transport Team (CCATT) members are
trained using mixed-reality simulations that replicate the high-pressure
conditions of aeromedical evacuation. Each team - a physician, nurse, and
respiratory therapist - must stabilize severely injured soldiers by managing
ventilators, IV pumps, and suction devices during flight. Proficient
performance requires clinical expertise and cognitive skills, such as
situational awareness, rapid decision-making, effective communication, and
coordinated task management, all of which must be maintained under stress.
Recent advances in simulation and multimodal data analytics enable more
objective and comprehensive performance evaluation. In contrast, traditional
instructor-led assessments are subjective and may overlook critical events,
thereby limiting generalizability and consistency. However, AI-based automated
and more objective evaluation metrics still demand human input to train the AI
algorithms to assess complex team dynamics in the presence of environmental
noise and the need for accurate re-identification in multi-person tracking. To
address these challenges, we introduce a systematic, data-driven assessment
framework that combines Cognitive Task Analysis (CTA) with Multimodal Learning
Analytics (MMLA). We have developed a domain-specific CTA model for CCATT
training and a vision-based action recognition pipeline using a fine-tuned
Human-Object Interaction model, the Cascade Disentangling Network (CDN), to
detect and track trainee-equipment interactions over time. These interactions
automatically yield performance indicators (e.g., reaction time, task
duration), which are mapped onto a hierarchical CTA model tailored to CCATT
operations, enabling interpretable, domain-relevant performance evaluations.

</details>


### [145] [Optimized Learned Image Compression for Facial Expression Recognition](https://arxiv.org/abs/2509.17262)
*Xiumei Li,Marc Windsheimer,Misha Sadeghi,Björn Eskofier,André Kaup*

Main category: cs.CV

TL;DR: 该研究提出一种端到端模型，通过自定义损失函数平衡压缩与识别性能，实验证明联合优化显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 在面部表情识别任务中，有损压缩常导致特征退化和准确率下降，因此需要一种能够同时优化压缩和识别性能的解决方案。

Method: 提出了一种端到端模型，采用自定义损失函数来优化压缩与识别性能的平衡，并研究了不同损失项权重的影响。

Result: 实验结果显示，单独微调压缩模型可提升分类准确率0.71%和压缩效率49.32%，而联合优化则分别提升4.04%和89.12%。

Conclusion: 该研究通过端到端模型和自定义损失函数，有效平衡了压缩与识别性能。实验结果表明，联合优化显著提升了分类准确率和压缩效率，且模型在高压缩率下仍能保持图像细节。

Abstract: Efficient data compression is crucial for the storage and transmission of
visual data. However, in facial expression recognition (FER) tasks, lossy
compression often leads to feature degradation and reduced accuracy. To address
these challenges, this study proposes an end-to-end model designed to preserve
critical features and enhance both compression and recognition performance. A
custom loss function is introduced to optimize the model, tailored to balance
compression and recognition performance effectively. This study also examines
the influence of varying loss term weights on this balance. Experimental
results indicate that fine-tuning the compression model alone improves
classification accuracy by 0.71% and compression efficiency by 49.32%, while
joint optimization achieves significant gains of 4.04% in accuracy and 89.12%
in efficiency. Moreover, the findings demonstrate that the jointly optimized
classification model maintains high accuracy on both compressed and
uncompressed data, while the compression model reliably preserves image
details, even at high compression rates.

</details>


### [146] [Beyond Diagnosis: Evaluating Multimodal LLMs for Pathology Localization in Chest Radiographs](https://arxiv.org/abs/2509.18015)
*Advait Gosai,Arun Kavishwar,Stephanie L. McNamara,Soujanya Samineni,Renato Umeton,Alexander Chowdhury,William Lotter*

Main category: cs.CV

TL;DR: 研究评估了GPT-4、GPT-5和MedGemma在医学影像定位任务中的表现，发现其潜力但精度不足，需结合任务专用工具提升可靠性。


<details>
  <summary>Details</summary>
Motivation: 评估MLLMs在医学影像中的定位能力，不仅具有临床和教育意义，还能揭示模型对解剖和疾病的空间理解。

Method: 通过空间网格提示管道，评估了GPT-4、GPT-5和MedGemma在胸部X光片病理定位中的表现，并与专用CNN和放射科医生基准进行比较。

Result: GPT-5定位准确率为49.7%，GPT-4为39.1%，MedGemma为17.7%，均低于专用CNN（59.9%）和放射科医生（80.1%）。GPT-5预测更符合解剖学合理区域，但精度不足。

Conclusion: 当前的多模态大语言模型（MLLMs）在医学影像定位任务中表现出一定的潜力，但仍需与任务专用工具结合以提高可靠性。

Abstract: Recent work has shown promising performance of frontier large language models
(LLMs) and their multimodal counterparts in medical quizzes and diagnostic
tasks, highlighting their potential for broad clinical utility given their
accessible, general-purpose nature. However, beyond diagnosis, a fundamental
aspect of medical image interpretation is the ability to localize pathological
findings. Evaluating localization not only has clinical and educational
relevance but also provides insight into a model's spatial understanding of
anatomy and disease. Here, we systematically assess two general-purpose MLLMs
(GPT-4 and GPT-5) and a domain-specific model (MedGemma) in their ability to
localize pathologies on chest radiographs, using a prompting pipeline that
overlays a spatial grid and elicits coordinate-based predictions. Averaged
across nine pathologies in the CheXlocalize dataset, GPT-5 exhibited a
localization accuracy of 49.7%, followed by GPT-4 (39.1%) and MedGemma (17.7%),
all lower than a task-specific CNN baseline (59.9%) and a radiologist benchmark
(80.1%). Despite modest performance, error analysis revealed that GPT-5's
predictions were largely in anatomically plausible regions, just not always
precisely localized. GPT-4 performed well on pathologies with fixed anatomical
locations, but struggled with spatially variable findings and exhibited
anatomically implausible predictions more frequently. MedGemma demonstrated the
lowest performance on all pathologies, showing limited capacity to generalize
to this novel task. Our findings highlight both the promise and limitations of
current MLLMs in medical imaging and underscore the importance of integrating
them with task-specific tools for reliable use.

</details>


### [147] [UniPixel: Unified Object Referring and Segmentation for Pixel-Level Visual Reasoning](https://arxiv.org/abs/2509.18094)
*Ye Liu,Zongyang Ma,Junfu Pu,Zhongang Qi,Yang Wu,Ying Shan,Chang Wen Chen*

Main category: cs.CV

TL;DR: UniPixel 是一种多模态模型，通过整合像素级感知与视觉理解能力，实现了细粒度的像素级推理。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型在像素级理解能力上存在不足，无法将细粒度感知能力整合到视觉推理中。

Method: UniPixel 处理视觉提示并根据需求生成相关掩码，在推理过程中基于这些中间指针进行后续推理。

Result: 在10个基准测试中验证了方法的有效性，包括像素级参考/分割和图像/视频中的对象中心理解。

Conclusion: UniPixel 成功地将像素级感知与通用视觉理解能力相结合，验证了其在多种任务上的有效性。

Abstract: Recent advances in Large Multi-modal Models (LMMs) have demonstrated their
remarkable success as general-purpose multi-modal assistants, with particular
focuses on holistic image- and video-language understanding. Conversely, less
attention has been given to scaling fine-grained pixel-level understanding
capabilities, where the models are expected to realize pixel-level alignment
between visual signals and language semantics. Some previous studies have
applied LMMs to related tasks such as region-level captioning and referring
expression segmentation. However, these models are limited to performing either
referring or segmentation tasks independently and fail to integrate these
fine-grained perception capabilities into visual reasoning. To bridge this gap,
we propose UniPixel, a large multi-modal model capable of flexibly
comprehending visual prompt inputs and generating mask-grounded responses. Our
model distinguishes itself by seamlessly integrating pixel-level perception
with general visual understanding capabilities. Specifically, UniPixel
processes visual prompts and generates relevant masks on demand, and performs
subsequent reasoning conditioning on these intermediate pointers during
inference, thereby enabling fine-grained pixel-level reasoning. The
effectiveness of our approach has been verified on 10 benchmarks across a
diverse set of tasks, including pixel-level referring/segmentation and
object-centric understanding in images/videos. A novel PixelQA task that
jointly requires referring, segmentation, and question answering is also
designed to verify the flexibility of our method.

</details>


### [148] [UIPro: Unleashing Superior Interaction Capability For GUI Agents](https://arxiv.org/abs/2509.17328)
*Hongxin Li,Jingran Su,Jingfan Chen,Zheng Ju,Yuntao Chen,Qing Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: 提出UIPro，一个基于大规模多平台GUI数据训练的通才型GUI代理，通过统一动作空间和预训练+微调方法，在多个GUI任务中表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有基于视觉语言模型(VLMs)的GUI代理方法由于场景有限、数据量不足和动作空间异构等问题，难以构建通用型GUI代理。

Method: 提出UIPro，一个基于多平台、多任务GUI交互数据和统一动作空间训练的通才型GUI代理。首先通过包含2060万GUI理解任务的综合数据集进行预训练，随后建立统一动作空间并合并数据集以微调动作预测能力。

Result: UIPro在多个平台的各种GUI任务基准测试中表现优异。

Conclusion: UIPro在多个GUI任务基准测试中表现出色，验证了其方法的有效性。

Abstract: Building autonomous agents that perceive and operate graphical user
interfaces (GUIs) like humans has long been a vision in the field of artificial
intelligence. Central to these agents is the capability for GUI interaction,
which involves GUI understanding and planning capabilities. Existing methods
have tried developing GUI agents based on the multi-modal comprehension ability
of vision-language models (VLMs). However, the limited scenario, insufficient
size, and heterogeneous action spaces hinder the progress of building
generalist GUI agents. To resolve these issues, this paper proposes
\textbf{UIPro}, a novel generalist GUI agent trained with extensive
multi-platform and multi-task GUI interaction data, coupled with a unified
action space. We first curate a comprehensive dataset encompassing 20.6 million
GUI understanding tasks to pre-train UIPro, granting it a strong GUI grounding
capability, which is key to downstream GUI agent tasks. Subsequently, we
establish a unified action space to harmonize heterogeneous GUI agent task
datasets and produce a merged dataset to foster the action prediction ability
of UIPro via continued fine-tuning. Experimental results demonstrate UIPro's
superior performance across multiple GUI task benchmarks on various platforms,
highlighting the effectiveness of our approach.

</details>


### [149] [SmokeSeer: 3D Gaussian Splatting for Smoke Removal and Scene Reconstruction](https://arxiv.org/abs/2509.17329)
*Neham Jain,Andrew Jong,Sebastian Scherer,Ioannis Gkioulekas*

Main category: cs.CV

TL;DR: SmokeSeer是一种结合热成像和RGB图像的新方法，利用3D高斯泼溅技术实现同时3D场景重建和烟雾去除，适用于各种烟雾密度和动态场景。


<details>
  <summary>Details</summary>
Motivation: 现实场景中的烟雾会严重降低图像质量并阻碍能见度，现有方法要么依赖易产生幻觉的数据驱动先验，要么仅限于静态低密度烟雾，因此需要更有效的解决方案。

Method: 基于3D高斯泼溅技术，融合热成像和RGB图像信息，将场景显式分解为烟雾和非烟雾组件。

Result: SmokeSeer在合成数据和真实世界多视角烟雾数据集上验证了其有效性，能够处理广泛的烟雾密度和动态变化。

Conclusion: SmokeSeer通过结合热成像和RGB图像，利用3D高斯泼溅技术，成功实现了从视频中同时进行3D场景重建和烟雾去除，适用于广泛的烟雾密度和动态变化场景。

Abstract: Smoke in real-world scenes can severely degrade the quality of images and
hamper visibility. Recent methods for image restoration either rely on
data-driven priors that are susceptible to hallucinations, or are limited to
static low-density smoke. We introduce SmokeSeer, a method for simultaneous 3D
scene reconstruction and smoke removal from a video capturing multiple views of
a scene. Our method uses thermal and RGB images, leveraging the fact that the
reduced scattering in thermal images enables us to see through the smoke. We
build upon 3D Gaussian splatting to fuse information from the two image
modalities, and decompose the scene explicitly into smoke and non-smoke
components. Unlike prior approaches, SmokeSeer handles a broad range of smoke
densities and can adapt to temporally varying smoke. We validate our approach
on synthetic data and introduce a real-world multi-view smoke dataset with RGB
and thermal images. We provide open-source code and data at the project
website.

</details>


### [150] [Revisiting Vision Language Foundations for No-Reference Image Quality Assessment](https://arxiv.org/abs/2509.17374)
*Ankit Yadav,Ta Duc Huy,Lingqiao Liu*

Main category: cs.CV

TL;DR: 系统评估六种预训练骨干网络在NR-IQA任务中的表现，发现SigLIP2和sigmoid激活函数效果最佳，提出自适应激活选择机制达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 大规模视觉语言预训练在NR-IQA任务中显示出潜力，但现代Vision Transformer基础的相对优势尚不明确。

Method: 系统评估了六种预训练骨干网络（CLIP、SigLIP2、DINOv2、DINOv3、Perception、ResNet），并使用相同的轻量级MLP头进行微调。引入了可学习的激活选择机制。

Result: SigLIP2表现优异；sigmoid激活函数优于ReLU和GELU；自适应激活选择机制在CLIVE、KADID10K和AGIQA3K上达到新SOTA。

Conclusion: 研究发现SigLIP2在NR-IQA任务中表现优异，且激活函数的选择对模型泛化能力至关重要。提出的自适应激活选择机制在多个基准测试中达到新SOTA。

Abstract: Large-scale vision language pre-training has recently shown promise for
no-reference image-quality assessment (NR-IQA), yet the relative merits of
modern Vision Transformer foundations remain poorly understood. In this work,
we present the first systematic evaluation of six prominent pretrained
backbones, CLIP, SigLIP2, DINOv2, DINOv3, Perception, and ResNet, for the task
of No-Reference Image Quality Assessment (NR-IQA), each finetuned using an
identical lightweight MLP head. Our study uncovers two previously overlooked
factors: (1) SigLIP2 consistently achieves strong performance; and (2) the
choice of activation function plays a surprisingly crucial role, particularly
for enhancing the generalization ability of image quality assessment models.
Notably, we find that simple sigmoid activations outperform commonly used ReLU
and GELU on several benchmarks. Motivated by this finding, we introduce a
learnable activation selection mechanism that adaptively determines the
nonlinearity for each channel, eliminating the need for manual activation
design, and achieving new state-of-the-art SRCC on CLIVE, KADID10K, and
AGIQA3K. Extensive ablations confirm the benefits across architectures and
regimes, establishing strong, resource-efficient NR-IQA baselines.

</details>


### [151] [Diff-GNSS: Diffusion-based Pseudorange Error Estimation](https://arxiv.org/abs/2509.17397)
*Jiaqi Zhu,Shouyi Lu,Ziyao Li,Guirong Zhuo,Lu Xiong*

Main category: cs.CV

TL;DR: Diff-GNSS利用条件扩散模型和Mamba模块，有效提升GNSS伪距误差估计精度，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决GNSS在城市环境中因多径和非视距接收导致的复杂伪距误差分布问题，传统学习方法性能有限。

Method: 提出Diff-GNSS框架，包括Mamba模块进行粗估计和条件扩散模型进行细粒度误差建模，利用三个关键GNSS测量质量特征作为条件，并引入每卫星不确定性建模。

Result: 在公开和自收集数据集上，Diff-GNSS在多项指标上均优于现有基线方法。

Conclusion: Diff-GNSS通过结合条件扩散模型和Mamba模块，显著提高了GNSS伪距误差估计的准确性，其模块化设计便于集成到现有网络中。

Abstract: Global Navigation Satellite Systems (GNSS) are vital for reliable urban
positioning. However, multipath and non-line-of-sight reception often introduce
large measurement errors that degrade accuracy. Learning-based methods for
predicting and compensating pseudorange errors have gained traction, but their
performance is limited by complex error distributions. To address this
challenge, we propose Diff-GNSS, a coarse-to-fine GNSS measurement
(pseudorange) error estimation framework that leverages a conditional diffusion
model to capture such complex distributions. Firstly, a Mamba-based module
performs coarse estimation to provide an initial prediction with appropriate
scale and trend. Then, a conditional denoising diffusion layer refines the
estimate, enabling fine-grained modeling of pseudorange errors. To suppress
uncontrolled generative diversity and achieve controllable synthesis, three key
features related to GNSS measurement quality are used as conditions to
precisely guide the reverse denoising process. We further incorporate
per-satellite uncertainty modeling within the diffusion stage to assess the
reliability of the predicted errors. We have collected and publicly released a
real-world dataset covering various scenes. Experiments on public and
self-collected datasets show that DiffGNSS consistently outperforms
state-of-the-art baselines across multiple metrics. To the best of our
knowledge, this is the first application of diffusion models to pseudorange
error estimation. The proposed diffusion-based refinement module is
plug-and-play and can be readily integrated into existing networks to markedly
improve estimation accuracy.

</details>


### [152] [Single-Image Depth from Defocus with Coded Aperture and Diffusion Posterior Sampling](https://arxiv.org/abs/2509.17427)
*Hodaka Kawachi,Jose Reinaldo Cunha Santos A. V. Silva Neto,Yasushi Yagi,Hajime Nagahara,Tomoya Nakamura*

Main category: cs.CV

TL;DR: 提出了一种无需配对训练数据的单次快照深度离焦重建方法，利用学习扩散先验作为正则化，显著提升了重建精度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法依赖手工先验和配对训练数据的问题，提升深度重建的准确性和稳定性。

Method: 采用可微分前向模型确保测量一致性，结合学习扩散先验作为正则化，在去噪图像域引导解。

Result: 在模拟和原型相机实验中，该方法在不同噪声水平下均表现优异，超越了U-Net基线和经典编码孔径DFD方法。

Conclusion: 提出的基于学习扩散先验的单次快照深度离焦（DFD）重建方法，在编码孔径成像中表现出色，优于传统优化方法和U-Net基线。

Abstract: We propose a single-snapshot depth-from-defocus (DFD) reconstruction method
for coded-aperture imaging that replaces hand-crafted priors with a learned
diffusion prior used purely as regularization. Our optimization framework
enforces measurement consistency via a differentiable forward model while
guiding solutions with the diffusion prior in the denoised image domain,
yielding higher accuracy and stability than clas- sical optimization. Unlike
U-Net-style regressors, our approach requires no paired defocus-RGBD training
data and does not tie training to a specific camera configuration. Experiments
on comprehensive simulations and a prototype camera demonstrate consistently
strong RGBD reconstructions across noise levels, outperforming both U-Net
baselines and a classical coded- aperture DFD method.

</details>


### [153] [Multi-scale Temporal Prediction via Incremental Generation and Multi-agent Collaboration](https://arxiv.org/abs/2509.17429)
*Zhitao Zeng,Guojian Yuan,Junyuan Mao,Yuxuan Wang,Xiaoshuang Jia,Yueming Jin*

Main category: cs.CV

TL;DR: 论文提出多尺度时间预测任务（MSTP）及增量生成与多智能体协作方法（IG-MC），通过同步视觉预览和动态智能体协作，提升多尺度场景预测能力。


<details>
  <summary>Details</summary>
Motivation: 准确的时序预测是全面场景理解与具身人工智能之间的桥梁，但现有视觉语言模型难以预测多时间尺度和多状态尺度的场景状态。

Method: 论文提出了增量生成模块和多智能体协作框架（IG-MC），前者通过持续生成最新的视觉预览来同步决策和生成内容，后者通过生成、初始化和多状态评估智能体动态平衡全局一致性和局部保真度。

Result: 论文提出了首个MSTP基准测试，并验证了IG-MC方法在多时间尺度和多状态尺度预测中的有效性。

Conclusion: 论文提出了一种多尺度时间预测（MSTP）任务，并引入了增量生成与多智能体协作（IG-MC）方法，有效解决了多时间尺度和多状态尺度的预测问题，提升了对场景的全面理解和预测能力。

Abstract: Accurate temporal prediction is the bridge between comprehensive scene
understanding and embodied artificial intelligence. However, predicting
multiple fine-grained states of a scene at multiple temporal scales is
difficult for vision-language models. We formalize the Multi-Scale Temporal
Prediction (MSTP) task in general and surgical scenes by decomposing
multi-scale into two orthogonal dimensions: the temporal scale, forecasting
states of humans and surgery at varying look-ahead intervals, and the state
scale, modeling a hierarchy of states in general and surgical scenes. For
example, in general scenes, states of contact relationships are finer-grained
than states of spatial relationships. In surgical scenes, medium-level steps
are finer-grained than high-level phases yet remain constrained by their
encompassing phase. To support this unified task, we introduce the first MSTP
Benchmark, featuring synchronized annotations across multiple state scales and
temporal scales. We further propose a method, Incremental Generation and
Multi-agent Collaboration (IG-MC), which integrates two key innovations. First,
we present a plug-and-play incremental generation module that continuously
synthesizes up-to-date visual previews at expanding temporal scales to inform
multiple decision-making agents, keeping decisions and generated visuals
synchronized and preventing performance degradation as look-ahead intervals
lengthen. Second, we present a decision-driven multi-agent collaboration
framework for multi-state prediction, comprising generation, initiation, and
multi-state assessment agents that dynamically trigger and evaluate prediction
cycles to balance global coherence and local fidelity.

</details>


### [154] [Emergent 3D Correspondence from Neural Shape Representation](https://arxiv.org/abs/2509.17431)
*Keyu Du,Jingyu Hu,Haipeng Li,Hao Xu,Haibing Huang,Chi-Wing Fu,Shuaicheng Liu*

Main category: cs.CV

TL;DR: 提出了一种基于分层神经语义表示和渐进匹配策略的3D语义对应估计方法，无需训练且泛化能力强，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 通过结合全局语义特征和多分辨率局部几何特征，实现准确且语义一致的3D对应估计。

Method: 设计了分层神经语义表示(HNSR)和渐进式全局到局部匹配策略，利用预训练的3D生成模型先验。

Result: 定性和定量评估表明，该方法在跨类别场景中表现优异，支持形状共分割、关键点匹配和纹理传递等应用。

Conclusion: 本文提出的方法在3D语义对应估计中表现出色，支持多种应用并具有良好的泛化能力，超越了现有技术。

Abstract: This paper presents a new approach to estimate accurate and robust 3D
semantic correspondence with the hierarchical neural semantic representation.
Our work has three key contributions. First, we design the hierarchical neural
semantic representation (HNSR), which consists of a global semantic feature to
capture high-level structure and multi-resolution local geometric features to
preserve fine details, by carefully harnessing 3D priors from pre-trained 3D
generative models. Second, we design a progressive global-to-local matching
strategy, which establishes coarse semantic correspondence using the global
semantic feature, then iteratively refines it with local geometric features,
yielding accurate and semantically-consistent mappings. Third, our framework is
training-free and broadly compatible with various pre-trained 3D generative
backbones, demonstrating strong generalization across diverse shape categories.
Our method also supports various applications, such as shape co-segmentation,
keypoint matching, and texture transfer, and generalizes well to structurally
diverse shapes, with promising results even in cross-category scenarios. Both
qualitative and quantitative evaluations show that our method outperforms
previous state-of-the-art techniques.

</details>


### [155] [CARINOX: Inference-time Scaling with Category-Aware Reward-based Initial Noise Optimization and Exploration](https://arxiv.org/abs/2509.17458)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,Shayan Baghayi Nejad,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: CARINOX结合噪声优化和探索，通过基于人类判断的奖励选择，显著提升文本到图像模型的组合对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在复杂对象关系、属性或空间排列提示下常无法实现组合对齐，且现有推理时方法各有局限性。

Method: 提出CARINOX框架，结合噪声优化和探索，并采用基于人类判断相关的奖励选择程序。

Result: 在两个基准测试中，CARINOX平均对齐分数分别提升16%和11%，优于现有方法。

Conclusion: CARINOX通过结合噪声优化和探索，并基于与人类判断相关的奖励选择程序，显著提升了文本到图像生成模型的组合对齐性能。

Abstract: Text-to-image diffusion models, such as Stable Diffusion, can produce
high-quality and diverse images but often fail to achieve compositional
alignment, particularly when prompts describe complex object relationships,
attributes, or spatial arrangements. Recent inference-time approaches address
this by optimizing or exploring the initial noise under the guidance of reward
functions that score text-image alignment without requiring model fine-tuning.
While promising, each strategy has intrinsic limitations when used alone:
optimization can stall due to poor initialization or unfavorable search
trajectories, whereas exploration may require a prohibitively large number of
samples to locate a satisfactory output. Our analysis further shows that
neither single reward metrics nor ad-hoc combinations reliably capture all
aspects of compositionality, leading to weak or inconsistent guidance. To
overcome these challenges, we present Category-Aware Reward-based Initial Noise
Optimization and Exploration (CARINOX), a unified framework that combines noise
optimization and exploration with a principled reward selection procedure
grounded in correlation with human judgments. Evaluations on two complementary
benchmarks covering diverse compositional challenges show that CARINOX raises
average alignment scores by +16% on T2I-CompBench++ and +11% on the HRS
benchmark, consistently outperforming state-of-the-art optimization and
exploration-based methods across all major categories, while preserving image
quality and diversity. The project page is available at
https://amirkasaei.com/carinox/{this URL}.

</details>


### [156] [CSDformer: A Conversion Method for Fully Spike-Driven Transformer](https://arxiv.org/abs/2509.17461)
*Yuhao Zhang,Chengjun Zhang,Di Wu,Jie Yang,Mohamad Sawan*

Main category: cs.CV

TL;DR: CSDformer 是一种新型全脉冲驱动变压器转换方法，通过优化架构和神经元设计，在低延迟下实现高性能并大幅降低训练成本。


<details>
  <summary>Details</summary>
Motivation: 现有的脉冲变压器模型生成方法存在训练成本高或硬件不友好操作的局限性，需要一种更高效的解决方案。

Method: 提出了一种新的转换方法 CSDformer，包括定制转换导向的变压器架构、用 NReLU 替代 softmax、量化训练和时域分解技术转换，以及延迟的 Integrate-and-Fire 神经元以减少转换误差。

Result: 在 ImageNet、CIFAR-10 和 CIFAR-100 数据集上评估，CSDformer 在 7 个时间步下达到 76.36% 的 top-1 准确率，优于现有技术，同时减少 75% 的计算资源并加速训练 2-3 倍。

Conclusion: CSDformer 是一种通过转换方法实现的全脉冲驱动变压器模型，在超低延迟下实现了高性能，同时显著降低了计算复杂性和训练开销。

Abstract: Spike-based transformer is a novel architecture aiming to enhance the
performance of spiking neural networks while mitigating the energy overhead
inherent to transformers. However, methods for generating these models suffer
from critical limitations: excessive training costs introduced by direct
training methods, or unavoidably hardware-unfriendly operations in existing
conversion methods. In this paper, we propose CSDformer, a novel conversion
method for fully spike-driven transformers. We tailor a conversion-oriented
transformer-based architecture and propose a new function NReLU to replace
softmax in self-attention. Subsequently, this model is quantized and trained,
and converted into a fully spike-driven model with temporal decomposition
technique. Also, we propose delayed Integrate-andFire neurons to reduce
conversion errors and improve the performance of spiking models. We evaluate
CSDformer on ImageNet, CIFAR-10 and CIFAR-100 datasets and achieve 76.36% top-1
accuracy under 7 time-steps on ImageNet, demonstrating superiority over
state-of-the-art models. Furthermore, CSDformer eliminates the need for
training SNNs, thereby reducing training costs (reducing computational resource
by 75% and accelerating training speed by 2-3$\times$). To the best of our
knowledge, this is the first fully spike-driven transformer-based model
developed via conversion method, achieving high performance under ultra-low
latency, while dramatically reducing both computational complexity and training
overhead.

</details>


### [157] [MAESTRO: Task-Relevant Optimization via Adaptive Feature Enhancement and Suppression for Multi-task 3D Perception](https://arxiv.org/abs/2509.17462)
*Changwon Kang,Jisong Kim,Hongjae Shin,Junseo Park,Jun Won Choi*

Main category: cs.CV

TL;DR: MAESTRO是一个多任务学习框架，通过生成任务特定特征和减少特征干扰，显著提升了3D感知任务的性能。


<details>
  <summary>Details</summary>
Motivation: 多任务学习中任务冲突可能导致性能下降，MAESTRO旨在通过结构化框架生成任务特定特征并减少特征干扰。

Method: MAESTRO由Class-wise Prototype Generator (CPG)、Task-Specific Feature Generator (TSFG)和Scene Prototype Aggregator (SPA)组成。CPG将类别分组为前景和背景，生成组原型；TSFG利用这些原型保留任务相关特征；SPA通过其他任务头的信息增强3D占用预测的原型。

Result: 在nuScenes和Occ3D基准测试中，MAESTRO在3D物体检测、BEV地图分割和3D占用预测任务上均优于现有方法。

Conclusion: MAESTRO框架通过其三个组件（CPG、TSFG和SPA）有效缓解了多任务学习中的任务冲突问题，显著提升了3D物体检测、BEV地图分割和3D占用预测任务的性能。

Abstract: The goal of multi-task learning is to learn to conduct multiple tasks
simultaneously based on a shared data representation. While this approach can
improve learning efficiency, it may also cause performance degradation due to
task conflicts that arise when optimizing the model for different objectives.
To address this challenge, we introduce MAESTRO, a structured framework
designed to generate task-specific features and mitigate feature interference
in multi-task 3D perception, including 3D object detection, bird's-eye view
(BEV) map segmentation, and 3D occupancy prediction. MAESTRO comprises three
components: the Class-wise Prototype Generator (CPG), the Task-Specific Feature
Generator (TSFG), and the Scene Prototype Aggregator (SPA). CPG groups class
categories into foreground and background groups and generates group-wise
prototypes. The foreground and background prototypes are assigned to the 3D
object detection task and the map segmentation task, respectively, while both
are assigned to the 3D occupancy prediction task. TSFG leverages these
prototype groups to retain task-relevant features while suppressing irrelevant
features, thereby enhancing the performance for each task. SPA enhances the
prototype groups assigned for 3D occupancy prediction by utilizing the
information produced by the 3D object detection head and the map segmentation
head. Extensive experiments on the nuScenes and Occ3D benchmarks demonstrate
that MAESTRO consistently outperforms existing methods across 3D object
detection, BEV map segmentation, and 3D occupancy prediction tasks.

</details>


### [158] [Stable Video-Driven Portraits](https://arxiv.org/abs/2509.17476)
*Mallikarjun B. R.,Fei Yin,Vikram Voleti,Nikita Drobyshev,Maksim Lapin,Aaryaman Vasishta,Varun Jampani*

Main category: cs.CV

TL;DR: 本文提出一种基于扩散模型的新框架，通过强运动控制信号和时空注意力机制，显著提升肖像动画的质量和可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在表达性、时间一致性和对未见身份或大姿态变化的泛化能力上的局限性。

Method: 采用扩散模型框架，利用驱动视频中的眼部、鼻子和嘴部作为强运动控制信号，结合跨身份监督和时空注意力机制，减少时间伪影并捕捉细微运动。

Result: 模型在时间一致性和准确的表情控制方面表现优异，能够生成高质量、可控的肖像动画。

Conclusion: 本文提出的基于扩散模型的框架通过引入强运动控制信号、跨身份监督和时空注意力机制，显著提升了肖像动画的质量和可控性，适用于实际应用。

Abstract: Portrait animation aims to generate photo-realistic videos from a single
source image by reenacting the expression and pose from a driving video. While
early methods relied on 3D morphable models or feature warping techniques, they
often suffered from limited expressivity, temporal inconsistency, and poor
generalization to unseen identities or large pose variations. Recent advances
using diffusion models have demonstrated improved quality but remain
constrained by weak control signals and architectural limitations. In this
work, we propose a novel diffusion based framework that leverages masked facial
regions specifically the eyes, nose, and mouth from the driving video as strong
motion control cues. To enable robust training without appearance leakage, we
adopt cross identity supervision. To leverage the strong prior from the
pretrained diffusion model, our novel architecture introduces minimal new
parameters that converge faster and help in better generalization. We introduce
spatial temporal attention mechanisms that allow inter frame and intra frame
interactions, effectively capturing subtle motions and reducing temporal
artifacts. Our model uses history frames to ensure continuity across segments.
At inference, we propose a novel signal fusion strategy that balances motion
fidelity with identity preservation. Our approach achieves superior temporal
consistency and accurate expression control, enabling high-quality,
controllable portrait animation suitable for real-world applications.

</details>


### [159] [Vision-Based Driver Drowsiness Monitoring: Comparative Analysis of YOLOv5-v11 Models](https://arxiv.org/abs/2509.17498)
*Dilshara Herath,Chinthaka Abeyrathne,Prabhani Jayaweera*

Main category: cs.CV

TL;DR: 研究评估了多种YOLO变体和EAR方法用于驾驶员 drowsiness 检测，发现YOLOv9c最准确，YOLOv11n效率最佳，为实际应用提供了选择指南。


<details>
  <summary>Details</summary>
Motivation: 驾驶员 drowsiness 是道路事故的关键因素，每年导致大量伤亡。研究旨在评估实时非侵入式检测方法，以提高道路安全性。

Method: 研究使用了公开数据集UTA-RLDD，对七种YOLO变体（v5s, v9c, v9t, v10n, v10l, v11n, v11l）进行了微调，并采用Dlib的面部标志点实现EAR方法。性能通过Precision、Recall、mAP0.5和mAP0.5-0.95来衡量。

Result: YOLOv9c在准确性上表现最佳（0.986 mAP0.5, 0.978 Recall），而YOLOv11n在精度（0.954）和推理效率之间取得最佳平衡，适合嵌入式部署。EAR方法计算量低，但在姿态变化和遮挡下鲁棒性较差。

Conclusion: 该研究通过评估多种YOLO变体和EAR方法，为实时非侵入式驾驶员 drowsiness 检测提供了实用的选择指南，特别强调了YOLOv9c的高准确性和YOLOv11n的效率平衡。

Abstract: Driver drowsiness remains a critical factor in road accidents, accounting for
thousands of fatalities and injuries each year. This paper presents a
comprehensive evaluation of real-time, non-intrusive drowsiness detection
methods, focusing on computer vision based YOLO (You Look Only Once)
algorithms. A publicly available dataset namely, UTA-RLDD was used, containing
both awake and drowsy conditions, ensuring variability in gender, eyewear,
illumination, and skin tone. Seven YOLO variants (v5s, v9c, v9t, v10n, v10l,
v11n, v11l) are fine-tuned, with performance measured in terms of Precision,
Recall, mAP0.5, and mAP 0.5-0.95. Among these, YOLOv9c achieved the highest
accuracy (0.986 mAP 0.5, 0.978 Recall) while YOLOv11n strikes the optimal
balance between precision (0.954) and inference efficiency, making it highly
suitable for embedded deployment. Additionally, we implement an Eye Aspect
Ratio (EAR) approach using Dlib's facial landmarks, which despite its low
computational footprint exhibits reduced robustness under pose variation and
occlusions. Our findings illustrate clear trade offs between accuracy, latency,
and resource requirements, and offer practical guidelines for selecting or
combining detection methods in autonomous driving and industrial safety
applications.

</details>


### [160] [SAMSON: 3rd Place Solution of LSVOS 2025 VOS Challenge](https://arxiv.org/abs/2509.17500)
*Yujie Xie,Hongyang Zhang,Zhihui Liu,Shihai Ruan*

Main category: cs.CV

TL;DR: SAMSON结合长期记忆和SAM2Long后处理，有效处理长视频分割挑战，在MOSE测试中J&F达0.8427。


<details>
  <summary>Details</summary>
Motivation: 解决长视频序列中对象重现、小尺度目标、严重遮挡和拥挤场景带来的挑战。

Method: 结合了长期记忆模块和SAM2Long后处理策略，以处理视觉相似实例和长期对象消失问题。

Result: 在ICCV 2025 MOSE赛道中获得第三名，测试集J&F分数为0.8427。

Conclusion: SAMSON方法在MOSE测试集上取得了0.8427的J&F分数，展示了其在长视频序列中处理复杂分割任务的有效性。

Abstract: Large-scale Video Object Segmentation (LSVOS) addresses the challenge of
accurately tracking and segmenting objects in long video sequences, where
difficulties stem from object reappearance, small-scale targets, heavy
occlusions, and crowded scenes. Existing approaches predominantly adopt
SAM2-based frameworks with various memory mechanisms for complex video mask
generation. In this report, we proposed Segment Anything with Memory
Strengthened Object Navigation (SAMSON), the 3rd place solution in the MOSE
track of ICCV 2025, which integrates the strengths of stateof-the-art VOS
models into an effective paradigm. To handle visually similar instances and
long-term object disappearance in MOSE, we incorporate a long-term memorymodule
for reliable object re-identification. Additionly, we adopt SAM2Long as a
post-processing strategy to reduce error accumulation and enhance segmentation
stability in long video sequences. Our method achieved a final performance of
0.8427 in terms of J &F in the test-set leaderboard.

</details>


### [161] [4D-MoDe: Towards Editable and Scalable Volumetric Streaming via Motion-Decoupled 4D Gaussian Compression](https://arxiv.org/abs/2509.17506)
*Houqiang Zhong,Zihan Zheng,Qiang Hu,Yuan Tian,Ning Cao,Lan Xu,Xiaoyun Zhang,Zhengxue Cheng,Li Song,Wenjun Zhang*

Main category: cs.CV

TL;DR: 4D-MoDe 是一种高效压缩框架，通过分层表示和运动分解显著降低存储成本，支持背景替换和前景流。


<details>
  <summary>Details</summary>
Motivation: 解决动态体视频在规模交付时面临的大数据量、复杂运动和可编辑性有限的问题。

Method: 采用分层表示、前瞻性运动分解策略、多分辨率运动估计网格、轻量级共享MLP、动态高斯补偿机制和自适应分组方案。

Result: 在多个数据集上，4D-MoDe 以极低的存储成本（低至11.4 KB/帧）实现了竞争性重建质量。

Conclusion: 4D-MoDe 是一种高效、可扩展且可编辑的4D高斯压缩框架，显著降低了存储成本并支持实际应用如背景替换和前景流。

Abstract: Volumetric video has emerged as a key medium for immersive telepresence and
augmented/virtual reality, enabling six-degrees-of-freedom (6DoF) navigation
and realistic spatial interactions. However, delivering high-quality dynamic
volumetric content at scale remains challenging due to massive data volume,
complex motion, and limited editability of existing representations. In this
paper, we present 4D-MoDe, a motion-decoupled 4D Gaussian compression framework
designed for scalable and editable volumetric video streaming. Our method
introduces a layered representation that explicitly separates static
backgrounds from dynamic foregrounds using a lookahead-based motion
decomposition strategy, significantly reducing temporal redundancy and enabling
selective background/foreground streaming. To capture continuous motion
trajectories, we employ a multi-resolution motion estimation grid and a
lightweight shared MLP, complemented by a dynamic Gaussian compensation
mechanism to model emergent content. An adaptive grouping scheme dynamically
inserts background keyframes to balance temporal consistency and compression
efficiency. Furthermore, an entropy-aware training pipeline jointly optimizes
the motion fields and Gaussian parameters under a rate-distortion (RD)
objective, while employing range-based and KD-tree compression to minimize
storage overhead. Extensive experiments on multiple datasets demonstrate that
4D-MoDe consistently achieves competitive reconstruction quality with an order
of magnitude lower storage cost (e.g., as low as \textbf{11.4} KB/frame)
compared to state-of-the-art methods, while supporting practical applications
such as background replacement and foreground-only streaming.

</details>


### [162] [4DGCPro: Efficient Hierarchical 4D Gaussian Compression for Progressive Volumetric Video Streaming](https://arxiv.org/abs/2509.17513)
*Zihan Zheng,Zhenlong Wu,Houqiang Zhong,Yuan Tian,Ning Cao,Lan Xu,Jiangchao Yao,Xiaoyun Zhang,Qiang Hu,Wenjun Zhang*

Main category: cs.CV

TL;DR: 4DGCPro是一种新型分层4D高斯压缩框架，支持实时移动解码和高质量渲染，通过单一比特流实现渐进式体视频流传输，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有体视频压缩方法缺乏灵活性，无法在单一模型中调整质量和比特率以适应不同网络和设备的需求，或在轻量级移动平台上实现实时解码和渲染。

Method: 提出了一个感知加权且压缩友好的分层4D高斯表示，结合运动感知自适应分组以减少时间冗余，并保持连贯性。此外，开发了一个端到端的熵优化训练方案，包括分层率失真监督和属性特定熵建模。

Result: 4DGCPro在单一模型中实现了灵活的质量和多比特率支持，在移动设备上实现了实时解码和渲染，并在多个数据集上超越了现有方法的率失真性能。

Conclusion: 4DGCPro通过其分层4D高斯压缩框架，成功实现了在移动设备上的实时解码和高质量渲染，同时在多种数据集上超越了现有方法的率失真性能。

Abstract: Achieving seamless viewing of high-fidelity volumetric video, comparable to
2D video experiences, remains an open challenge. Existing volumetric video
compression methods either lack the flexibility to adjust quality and bitrate
within a single model for efficient streaming across diverse networks and
devices, or struggle with real-time decoding and rendering on lightweight
mobile platforms. To address these challenges, we introduce 4DGCPro, a novel
hierarchical 4D Gaussian compression framework that facilitates real-time
mobile decoding and high-quality rendering via progressive volumetric video
streaming in a single bitstream. Specifically, we propose a
perceptually-weighted and compression-friendly hierarchical 4D Gaussian
representation with motion-aware adaptive grouping to reduce temporal
redundancy, preserve coherence, and enable scalable multi-level detail
streaming. Furthermore, we present an end-to-end entropy-optimized training
scheme, which incorporates layer-wise rate-distortion (RD) supervision and
attribute-specific entropy modeling for efficient bitstream generation.
Extensive experiments show that 4DGCPro enables flexible quality and multiple
bitrate within a single model, achieving real-time decoding and rendering on
mobile devices while outperforming existing methods in RD performance across
multiple datasets. Project Page: https://mediax-sjtu.github.io/4DGCPro

</details>


### [163] [Unified Multimodal Coherent Field: Synchronous Semantic-Spatial-Vision Fusion for Brain Tumor Segmentation](https://arxiv.org/abs/2509.17520)
*Mingda Zhang,Yuyang Zheng,Ruixiang Tang,Jingru Qiu,Haiyan Ding*

Main category: cs.CV

TL;DR: UMCF方法通过统一的多模态信息融合，显著提升了脑肿瘤分割的准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 由于脑肿瘤组织的异质性、边界模糊以及MRI序列间的对比度变化，仅依赖视觉信息或后处理损失约束的方法在边界描绘和层次保持上表现不稳定。

Method: UMCF方法在统一的3D潜在空间内实现视觉、语义和空间信息的同步交互融合，通过无参数不确定性门控自适应调整模态贡献，并直接让医学先验知识参与注意力计算。

Result: 在BraTS 2020和2021数据集上，UMCF+nnU-Net分别实现了0.8579和0.8977的平均Dice系数，较主流架构平均提升4.18%。

Conclusion: UMCF通过深度整合临床知识与影像特征，为精准医学中的多模态信息融合提供了新的技术途径。

Abstract: Brain tumor segmentation requires accurate identification of hierarchical
regions including whole tumor (WT), tumor core (TC), and enhancing tumor (ET)
from multi-sequence magnetic resonance imaging (MRI) images. Due to tumor
tissue heterogeneity, ambiguous boundaries, and contrast variations across MRI
sequences, methods relying solely on visual information or post-hoc loss
constraints show unstable performance in boundary delineation and hierarchy
preservation. To address this challenge, we propose the Unified Multimodal
Coherent Field (UMCF) method. This method achieves synchronous interactive
fusion of visual, semantic, and spatial information within a unified 3D latent
space, adaptively adjusting modal contributions through parameter-free
uncertainty gating, with medical prior knowledge directly participating in
attention computation, avoiding the traditional "process-then-concatenate"
separated architecture. On Brain Tumor Segmentation (BraTS) 2020 and 2021
datasets, UMCF+nnU-Net achieves average Dice coefficients of 0.8579 and 0.8977
respectively, with an average 4.18% improvement across mainstream
architectures. By deeply integrating clinical knowledge with imaging features,
UMCF provides a new technical pathway for multimodal information fusion in
precision medicine.

</details>


### [164] [Chat-CBM: Towards Interactive Concept Bottleneck Models with Frozen Large Language Models](https://arxiv.org/abs/2509.17522)
*Hangzhou He,Lei Zhu,Kaiwen Li,Xinliang Zhang,Jiakui Hu,Ourui Fu,Zhengjian Yao,Yanye Lu*

Main category: cs.CV

TL;DR: Chat-CBM通过语言模型改进概念瓶颈模型，提升交互性和预测性能。


<details>
  <summary>Details</summary>
Motivation: 传统CBM在概念空间干预上的局限性，尤其是在无监督设置下，概念激活嘈杂且密集，用户干预效果不佳。

Method: 使用基于语言的分类器直接对概念语义进行推理，取代传统的分数分类器。

Result: 在九个数据集上的实验表明，Chat-CBM在预测性能和用户交互性上均有显著提升。

Conclusion: Chat-CBM通过语言理解能力增强了概念瓶颈模型的交互性和预测性能，同时保持了其可解释性。

Abstract: Concept Bottleneck Models (CBMs) provide inherent interpretability by first
predicting a set of human-understandable concepts and then mapping them to
labels through a simple classifier. While users can intervene in the concept
space to improve predictions, traditional CBMs typically employ a fixed linear
classifier over concept scores, which restricts interventions to manual value
adjustments and prevents the incorporation of new concepts or domain knowledge
at test time. These limitations are particularly severe in unsupervised CBMs,
where concept activations are often noisy and densely activated, making user
interventions ineffective. We introduce Chat-CBM, which replaces score-based
classifiers with a language-based classifier that reasons directly over concept
semantics. By grounding prediction in the semantic space of concepts, Chat-CBM
preserves the interpretability of CBMs while enabling richer and more intuitive
interventions, such as concept correction, addition or removal of concepts,
incorporation of external knowledge, and high-level reasoning guidance.
Leveraging the language understanding and few-shot capabilities of frozen large
language models, Chat-CBM extends the intervention interface of CBMs beyond
numerical editing and remains effective even in unsupervised settings.
Experiments on nine datasets demonstrate that Chat-CBM achieves higher
predictive performance and substantially improves user interactivity while
maintaining the concept-based interpretability of CBMs.

</details>


### [165] [SimToken: A Simple Baseline for Referring Audio-Visual Segmentation](https://arxiv.org/abs/2509.17537)
*Dian Jin,Yanghao Zhou,Jinxing Zhou,Jiaqi Ma,Ruohao Guo,Dan Guo*

Main category: cs.CV

TL;DR: SimToken结合MLLM和SAM，通过特殊语义令牌和语义对齐损失，显著提升视频对象分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决跨模态推理和细粒度目标定位的挑战，提升视频中基于自然语言表达的对象分割性能。

Method: 提出SimToken框架，利用MLLM生成特殊语义令牌，并通过目标一致的语义对齐损失优化语义学习。

Result: 在Ref-AVS基准测试中表现优于现有方法。

Conclusion: SimToken框架通过结合多模态大语言模型（MLLM）和Segment Anything Model（SAM），在Ref-AVS任务中实现了卓越性能，代码将开源。

Abstract: Referring Audio-Visual Segmentation (Ref-AVS) aims to segment specific
objects in videos based on natural language expressions involving audio,
vision, and text information. This task poses significant challenges in
cross-modal reasoning and fine-grained object localization. In this paper, we
propose a simple framework, SimToken, that integrates a multimodal large
language model (MLLM) with the Segment Anything Model (SAM). The MLLM is guided
to generate a special semantic token representing the referred object. This
compact token, enriched with contextual information from all modalities, acts
as a prompt to guide SAM to segment objectsacross video frames. To further
improve semantic learning, we introduce a novel target-consistent semantic
alignment loss that aligns token embeddings from different expressions but
referring to the same object. Experiments on the Ref-AVS benchmark demonstrate
that our approach achieves superior performance compared to existing
methods.Code will be available at https://github.com/DianJin-HFUT/SimToken

</details>


### [166] [Visual Instruction Pretraining for Domain-Specific Foundation Models](https://arxiv.org/abs/2509.17562)
*Yuxuan Li,Yicheng Zhang,Wenhao Tang,Yimian Dai,Ming-Ming Cheng,Xiang Li,Jian Yang*

Main category: cs.CV

TL;DR: ViTP是一种新型视觉指令预训练方法，通过嵌入ViT于视觉语言模型并利用VRL学习鲁棒特征，在遥感与医学影像任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 现代计算机视觉中感知、推理与生成的闭环尚未完善，尤其是高级推理对低级感知特征的基础学习影响不足。本文旨在填补这一空白。

Method: ViTP采用了一种新颖的视觉指令预训练方法，将Vision Transformer（ViT）嵌入视觉语言模型中，并使用目标下游领域丰富的视觉指令数据进行端到端预训练。

Result: ViTP在16个具有挑战性的遥感与医学影像基准测试中取得了最先进的性能。

Conclusion: ViTP通过在视觉语言模型中嵌入Vision Transformer（ViT）主干，并通过视觉鲁棒性学习（VRL）方法，在下游领域的16个具有挑战性的遥感与医学影像基准测试中取得了最先进的性能。

Abstract: Modern computer vision is converging on a closed loop in which perception,
reasoning and generation mutually reinforce each other. However, this loop
remains incomplete: the top-down influence of high-level reasoning on the
foundational learning of low-level perceptual features is not yet
underexplored. This paper addresses this gap by proposing a new paradigm for
pretraining foundation models in downstream domains. We introduce Visual
insTruction Pretraining (ViTP), a novel approach that directly leverages
reasoning to enhance perception. ViTP embeds a Vision Transformer (ViT)
backbone within a Vision-Language Model and pretrains it end-to-end using a
rich corpus of visual instruction data curated from target downstream domains.
ViTP is powered by our proposed Visual Robustness Learning (VRL), which compels
the ViT to learn robust and domain-relevant features from a sparse set of
visual tokens. Extensive experiments on 16 challenging remote sensing and
medical imaging benchmarks demonstrate that ViTP establishes new
state-of-the-art performance across a diverse range of downstream tasks. The
code is available at github.com/zcablii/ViTP.

</details>


### [167] [PRNU-Bench: A Novel Benchmark and Model for PRNU-Based Camera Identification](https://arxiv.org/abs/2509.17581)
*Florinel Alin Croitoru,Vlad Hondru,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 新PRNU基准和混合架构模型，性能优于现有方法，代码和数据集已开源。


<details>
  <summary>Details</summary>
Motivation: 现有PRNU估计方法在真实场景中表现不佳，需开发更鲁棒的基准和模型。

Method: 采用混合架构，包括去噪自编码器估计PRNU信号和卷积网络进行1:N验证，创新性地使用Hadamard乘积作为输入。

Result: 新模型在性能上显著优于基于去噪自编码器和对比学习的现有方法。

Conclusion: 本文提出了一个基于PRNU的相机识别新模型，通过混合架构显著提升了识别性能，并发布了数据集和代码以供社区使用。

Abstract: We propose a novel benchmark for camera identification via Photo Response
Non-Uniformity (PRNU) estimation. The benchmark comprises 13K photos taken with
120+ cameras, where the training and test photos are taken in different
scenarios, enabling ``in-the-wild'' evaluation. In addition, we propose a novel
PRNU-based camera identification model that employs a hybrid architecture,
comprising a denoising autoencoder to estimate the PRNU signal and a
convolutional network that can perform 1:N verification of camera devices.
Instead of using a conventional approach based on contrastive learning, our
method takes the Hadamard product between reference and query PRNU signals as
input. This novel design leads to significantly better results compared with
state-of-the-art models based on denoising autoencoders and contrastive
learning. We release our dataset and code at:
https://github.com/CroitoruAlin/PRNU-Bench.

</details>


### [168] [Domain Adaptive Object Detection for Space Applications with Real-Time Constraints](https://arxiv.org/abs/2509.17593)
*Samet Hicsonmez,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada*

Main category: cs.CV

TL;DR: 本文提出一种结合领域不变特征和不变风险最小化的方法，显著提升了空间目标检测在真实数据上的性能，仅需少量标注数据。


<details>
  <summary>Details</summary>
Motivation: 当前空间目标检测模型主要依赖合成数据训练，但在真实数据上性能显著下降，领域自适应问题被忽视。本文旨在探索监督领域自适应（SDA）以减少这一差距。

Method: 该方法基于半监督自适应方法，结合了CNN领域鉴别器和领域独立回归头，针对实时部署需求，分别在轻量级SSD（MobileNet主干）和高级FCOS（ResNet-50主干）上进行了测试。

Result: 在两个空间数据集（SPEED+和SPARK）上的实验表明，仅用250张标注真实图像即可实现平均精度（AP）提升高达20点。

Conclusion: 通过结合领域不变特征学习和不变风险最小化，该方法在仅使用少量标注真实数据的情况下显著提升了空间目标检测的性能，证明了领域自适应在空间应用中的重要性。

Abstract: Object detection is essential in space applications targeting Space Domain
Awareness and also applications involving relative navigation scenarios.
Current deep learning models for Object Detection in space applications are
often trained on synthetic data from simulators, however, the model performance
drops significantly on real-world data due to the domain gap. However, domain
adaptive object detection is an overlooked problem in the community. In this
work, we first show the importance of domain adaptation and then explore
Supervised Domain Adaptation (SDA) to reduce this gap using minimal labeled
real data. We build on a recent semi-supervised adaptation method and tailor it
for object detection. Our approach combines domain-invariant feature learning
with a CNN-based domain discriminator and invariant risk minimization using a
domain-independent regression head. To meet real-time deployment needs, we test
our method on a lightweight Single Shot Multibox Detector (SSD) with MobileNet
backbone and on the more advanced Fully Convolutional One-Stage object detector
(FCOS) with ResNet-50 backbone. We evaluated on two space datasets, SPEED+ and
SPARK. The results show up to 20-point improvements in average precision (AP)
with just 250 labeled real images.

</details>


### [169] [COLA: Context-aware Language-driven Test-time Adaptation](https://arxiv.org/abs/2509.17598)
*Aiming Zhang,Tianyuan Yu,Liang Bai,Jun Tang,Yanming Guo,Yirun Ruan,Yun Zhou,Zhihe Lu*

Main category: cs.CV

TL;DR: COLA是一种结合上下文感知模块和类平衡伪标签策略的新方法，用于提升预训练视觉语言模型在目标域的适应性，尤其在类不平衡情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有测试时适应方法对共享标签空间的依赖问题，提升预训练视觉语言模型在目标域中的表现，尤其是在类不平衡情况下的适应性。

Method: 提出了一种名为COLA的新方法，包含一个轻量级上下文感知模块（任务感知适配器、上下文感知单元和残差连接单元）和类平衡伪标签策略（CBPL），以增强预训练视觉语言模型的目标域适应性。

Result: COLA方法在测试时适应和类泛化任务中均表现出色，有效提升了模型性能。

Conclusion: COLA方法通过结合轻量级上下文感知模块和类平衡伪标签策略，有效提升了预训练视觉语言模型在目标域中的适应性和性能，不仅适用于测试时适应场景，还能处理类泛化任务。

Abstract: Test-time adaptation (TTA) has gained increasing popularity due to its
efficacy in addressing ``distribution shift'' issue while simultaneously
protecting data privacy.
  However, most prior methods assume that a paired source domain model and
target domain sharing the same label space coexist, heavily limiting their
applicability.
  In this paper, we investigate a more general source model capable of
adaptation to multiple target domains without needing shared labels.
  This is achieved by using a pre-trained vision-language model (VLM), \egno,
CLIP, that can recognize images through matching with class descriptions.
  While the zero-shot performance of VLMs is impressive, they struggle to
effectively capture the distinctive attributes of a target domain.
  To that end, we propose a novel method -- Context-aware Language-driven TTA
(COLA).
  The proposed method incorporates a lightweight context-aware module that
consists of three key components: a task-aware adapter, a context-aware unit,
and a residual connection unit for exploring task-specific knowledge,
domain-specific knowledge from the VLM and prior knowledge of the VLM,
respectively.
  It is worth noting that the context-aware module can be seamlessly integrated
into a frozen VLM, ensuring both minimal effort and parameter efficiency.
  Additionally, we introduce a Class-Balanced Pseudo-labeling (CBPL) strategy
to mitigate the adverse effects caused by class imbalance.
  We demonstrate the effectiveness of our method not only in TTA scenarios but
also in class generalisation tasks.
  The source code is available at https://github.com/NUDT-Bai-Group/COLA-TTA.

</details>


### [170] [Overview of PlantCLEF 2025: Multi-Species Plant Identification in Vegetation Quadrat Images](https://arxiv.org/abs/2509.17602)
*Giulio Martellucci,Herve Goeau,Pierre Bonnet,Fabrice Vinatier,Alexis Joly*

Main category: cs.CV

TL;DR: 本文介绍了PlantCLEF 2025挑战，旨在通过AI加速生态研究，使用多标签分类任务预测样方图像中的植物物种，并提供了详细的数据和方法描述。


<details>
  <summary>Details</summary>
Motivation: AI的集成可以帮助专家加速生态调查并扩大生态研究的空间覆盖范围，从而推动生态学领域的进步。

Method: 任务被表述为一个（弱标签的）多标签分类问题，目标是使用单标签训练数据预测样方图像中存在的所有物种。

Result: PlantCLEF 2025挑战提供了一个新的测试集，包含2,105张高分辨率多标签图像，以及一个包含140万张单标签植物图像的大型训练集，并提供了预训练的视觉变换器模型。

Conclusion: 本文详细描述了PlantCLEF 2025挑战的数据、评估方法、参与者使用的方法和模型，以及取得的成果，展示了AI在加速生态研究和扩大空间覆盖范围方面的潜力。

Abstract: Quadrat images are essential for ecological studies, as they enable
standardized sampling, the assessment of plant biodiversity, long-term
monitoring, and large-scale field campaigns. These images typically cover an
area of fifty centimetres or one square meter, and botanists carefully identify
all the species present. Integrating AI could help specialists accelerate their
inventories and expand the spatial coverage of ecological studies. To assess
progress in this area, the PlantCLEF 2025 challenge relies on a new test set of
2,105 high-resolution multi-label images annotated by experts and covering
around 400 species. It also provides a large training set of 1.4 million
individual plant images, along with vision transformer models pre-trained on
this data. The task is formulated as a (weakly labelled) multi-label
classification problem, where the goal is to predict all species present in a
quadrat image using single-label training data. This paper provides a detailed
description of the data, the evaluation methodology, the methods and models
used by participants, and the results achieved.

</details>


### [171] [From Benchmarks to Reality: Advancing Visual Anomaly Detection by the VAND 3.0 Challenge](https://arxiv.org/abs/2509.17615)
*Lars Heckler-Kram,Ashwin Vaidya,Jan-Hendrik Neudeck,Ulla Scheler,Dick Ameln,Samet Akcay,Paula Ramos*

Main category: cs.CV

TL;DR: VAND 3.0挑战赛展示了异常检测的最新进展，参与者通过创新方法显著提升性能，但未来需更高效扩展以满足实时需求。


<details>
  <summary>Details</summary>
Motivation: 展示异常检测在不同实际场景中的当前进展，并解决该领域的关键问题。

Method: 挑战赛设置了两个赛道，分别针对真实世界分布变化的鲁棒性异常检测方法（类别1）和少样本制度下的视觉语言模型能力探索（类别2）。

Result: 参与者的解决方案通过结合或调整现有方法并结合新流程，显著改进了之前的基线。

Conclusion: 未来研究需要更高效地扩展异常检测方法，以满足现场实时和计算限制。

Abstract: Visual anomaly detection is a strongly application-driven field of research.
Consequently, the connection between academia and industry is of paramount
importance. In this regard, we present the VAND 3.0 Challenge to showcase
current progress in anomaly detection across different practical settings
whilst addressing critical issues in the field. The challenge hosted two
tracks, fostering the development of anomaly detection methods robust against
real-world distribution shifts (Category 1) and exploring the capabilities of
Vision Language Models within the few-shot regime (Category 2), respectively.
The participants' solutions reached significant improvements over previous
baselines by combining or adapting existing approaches and fusing them with
novel pipelines. While for both tracks the progress in large pre-trained vision
(language) backbones played a pivotal role for the performance increase,
scaling up anomaly detection methods more efficiently needs to be addressed by
future research to meet real-time and computational constraints on-site.

</details>


### [172] [Tensor-Based Self-Calibration of Cameras via the TrifocalCalib Method](https://arxiv.org/abs/2509.17620)
*Gregory Schroeder,Mohamed Sabry,Cristina Olaverri-Monreal*

Main category: cs.CV

TL;DR: TrifocalCalib通过三焦张量方程实现无校准目标的相机自标定，提高了准确性和鲁棒性，适用于自动驾驶等实时应用。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中无先验场景知识下相机内参估计的挑战，特别是在自动驾驶和车辆编队等需要实时适应性的应用中。

Method: 基于校准的三焦张量构建了一组方程，实现从最小图像数据进行投影相机自标定。

Result: 在合成环境和结构化数据集场景中的评估证明了该方法的有效性，优于现有的基于学习和经典方法。

Conclusion: TrifocalCalib方法在无需校准目标、不限制相机运动的情况下，显著提高了相机自标定的准确性和鲁棒性，并公开了代码以支持可重复性。

Abstract: Estimating camera intrinsic parameters without prior scene knowledge is a
fundamental challenge in computer vision. This capability is particularly
important for applications such as autonomous driving and vehicle platooning,
where precalibrated setups are impractical and real-time adaptability is
necessary. To advance the state-of-the-art, we present a set of equations based
on the calibrated trifocal tensor, enabling projective camera self-calibration
from minimal image data. Our method, termed TrifocalCalib, significantly
improves accuracy and robustness compared to both recent learning-based and
classical approaches. Unlike many existing techniques, our approach requires no
calibration target, imposes no constraints on camera motion, and simultaneously
estimates both focal length and principal point. Evaluations in both
procedurally generated synthetic environments and structured dataset-based
scenarios demonstrate the effectiveness of our approach. To support
reproducibility, we make the code publicly available.

</details>


### [173] [Overview of PlantCLEF 2023: Image-based Plant Identification at Global Scale](https://arxiv.org/abs/2509.17622)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: 深度学习在植物识别中展现出潜力，PlantCLEF2023挑战通过多图像分类问题推动全球植物物种识别。


<details>
  <summary>Details</summary>
Motivation: 植物识别对农业、建筑和药学等领域至关重要，但人工识别效率低下，阻碍新数据和知识的积累。

Method: 应用深度学习技术解决多图像（及元数据）分类问题，涉及80,000种植物物种。

Result: 深度学习方法在植物识别中取得显著进展，PlantCLEF2023挑战为这一领域提供了重要资源和评估。

Conclusion: 深度学习技术在植物识别领域展现出巨大潜力，尽管存在数据挑战，但未来有望实现全球植物物种的准确识别。PlantCLEF2023挑战通过多图像分类问题进一步推动了这一目标。

Abstract: The world is estimated to be home to over 300,000 species of vascular plants.
In the face of the ongoing biodiversity crisis, expanding our understanding of
these species is crucial for the advancement of human civilization,
encompassing areas such as agriculture, construction, and pharmacopoeia.
However, the labor-intensive process of plant identification undertaken by
human experts poses a significant obstacle to the accumulation of new data and
knowledge. Fortunately, recent advancements in automatic identification,
particularly through the application of deep learning techniques, have shown
promising progress. Despite challenges posed by data-related issues such as a
vast number of classes, imbalanced class distribution, erroneous
identifications, duplications, variable visual quality, and diverse visual
contents (such as photos or herbarium sheets), deep learning approaches have
reached a level of maturity which gives us hope that in the near future we will
have an identification system capable of accurately identifying all plant
species worldwide. The PlantCLEF2023 challenge aims to contribute to this
pursuit by addressing a multi-image (and metadata) classification problem
involving an extensive set of classes (80,000 plant species). This paper
provides an overview of the challenge's resources and evaluations, summarizes
the methods and systems employed by participating research groups, and presents
an analysis of key findings.

</details>


### [174] [OmniInsert: Mask-Free Video Insertion of Any Reference via Diffusion Transformer Models](https://arxiv.org/abs/2509.17627)
*Jinshu Chen,Xinghui Li,Xu Bai,Tianxiang Ma,Pengze Zhang,Zhuowei Chen,Gen Li,Lijie Liu,Songtao Zhao,Bingchuan Li,Qian He*

Main category: cs.CV

TL;DR: 本文提出OmniInsert框架，通过创新数据管道和训练策略，解决了视频插入中的三大挑战，性能超越商业方案。


<details>
  <summary>Details</summary>
Motivation: 现有视频插入方法依赖复杂控制信号且主体一致性不足，限制了实际应用。本文旨在解决数据稀缺、主体-场景平衡和插入协调三大挑战。

Method: 提出InsertPipe数据管道和OmniInsert框架，包括Condition-Specific Feature Injection机制、Progressive Training策略、Subject-Focused Loss及Insertive Preference Optimization方法。

Result: 在InsertBench上的评估显示OmniInsert优于现有最先进的闭源商业解决方案。

Conclusion: OmniInsert通过创新的数据管道和统一框架，解决了视频插入中的三大挑战，并在InsertBench上超越了现有商业解决方案，代码将开源。

Abstract: Recent advances in video insertion based on diffusion models are impressive.
However, existing methods rely on complex control signals but struggle with
subject consistency, limiting their practical applicability. In this paper, we
focus on the task of Mask-free Video Insertion and aim to resolve three key
challenges: data scarcity, subject-scene equilibrium, and insertion
harmonization. To address the data scarcity, we propose a new data pipeline
InsertPipe, constructing diverse cross-pair data automatically. Building upon
our data pipeline, we develop OmniInsert, a novel unified framework for
mask-free video insertion from both single and multiple subject references.
Specifically, to maintain subject-scene equilibrium, we introduce a simple yet
effective Condition-Specific Feature Injection mechanism to distinctly inject
multi-source conditions and propose a novel Progressive Training strategy that
enables the model to balance feature injection from subjects and source video.
Meanwhile, we design the Subject-Focused Loss to improve the detailed
appearance of the subjects. To further enhance insertion harmonization, we
propose an Insertive Preference Optimization methodology to optimize the model
by simulating human preferences, and incorporate a Context-Aware Rephraser
module during reference to seamlessly integrate the subject into the original
scenes. To address the lack of a benchmark for the field, we introduce
InsertBench, a comprehensive benchmark comprising diverse scenes with
meticulously selected subjects. Evaluation on InsertBench indicates OmniInsert
outperforms state-of-the-art closed-source commercial solutions. The code will
be released.

</details>


### [175] [Overview of PlantCLEF 2022: Image-based plant identification at global scale](https://arxiv.org/abs/2509.17632)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: PlantCLEF2022挑战赛利用深度学习技术，成功处理了8万种植物的大规模识别问题，验证了自动识别在植物多样性研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 全球植物多样性识别对文明发展至关重要，但人工识别效率低下，自动识别技术（如深度学习）可解决这一问题。

Method: 通过多图像（和元数据）分类问题，利用深度学习技术处理大量植物种类（8万种）。

Result: 挑战赛展示了深度学习在大规模植物种类识别中的有效性，尽管数据存在诸多问题（如类别不平衡、错误识别等）。

Conclusion: 该论文总结了PlantCLEF2022挑战赛的资源、评估方法及关键发现，强调了深度学习技术在植物多样性识别中的成熟应用。

Abstract: It is estimated that there are more than 300,000 species of vascular plants
in the world. Increasing our knowledge of these species is of paramount
importance for the development of human civilization (agriculture,
construction, pharmacopoeia, etc.), especially in the context of the
biodiversity crisis. However, the burden of systematic plant identification by
human experts strongly penalizes the aggregation of new data and knowledge.
Since then, automatic identification has made considerable progress in recent
years as highlighted during all previous editions of PlantCLEF. Deep learning
techniques now seem mature enough to address the ultimate but realistic problem
of global identification of plant biodiversity in spite of many problems that
the data may present (a huge number of classes, very strongly unbalanced
classes, partially erroneous identifications, duplications, variable visual
quality, diversity of visual contents such as photos or herbarium sheets, etc).
The PlantCLEF2022 challenge edition proposes to take a step in this direction
by tackling a multi-image (and metadata) classification problem with a very
large number of classes (80k plant species). This paper presents the resources
and evaluations of the challenge, summarizes the approaches and systems
employed by the participating research groups, and provides an analysis of key
findings.

</details>


### [176] [Evict3R: Training-Free Token Eviction for Memory-Bounded Streaming Visual Geometry Transformers](https://arxiv.org/abs/2509.17650)
*Soroush Mahdi,Fardin Ayar,Ehsan Javanmardi,Manabu Tsukada,Mahdi Javanmardi*

Main category: cs.CV

TL;DR: 提出了一种训练无关的令牌驱逐策略，显著降低内存使用且几乎不影响准确性，适用于长序列流式推理。


<details>
  <summary>Details</summary>
Motivation: Streaming visual transformers如StreamVGGT在3D感知中表现强劲，但面临KV内存无限制增长的问题，限制了可扩展性。

Method: 提出了一种训练无关、推理时的令牌驱逐策略，通过丢弃冗余令牌来限制内存增长。

Result: 在多个数据集上的实验表明，该方法显著降低了内存使用（如7-Scenes中峰值内存从18.63 GB降至9.39 GB），且准确性几乎无下降。

Conclusion: 该方法通过训练无关的推理时令牌驱逐策略，有效限制了内存使用，同时保持了信息量最大的令牌，显著降低了内存需求且几乎不影响准确性。

Abstract: Streaming visual transformers like StreamVGGT achieve strong 3D perception
but suffer from unbounded growth of key value (KV) memory, which limits
scalability. We propose a training-free, inference-time token eviction policy
that bounds memory by discarding redundant tokens while keeping the most
informative ones. Our method uses significantly less memory with little to no
drop in accuracy: on 7-Scenes with long sequences it reduces peak memory from
18.63 GB to 9.39 GB while accuracy and completeness drop by only 0.003. Under
strict memory budgets, eviction enables denser frame sampling, which improves
reconstruction accuracy compared to the baseline. Experiments across video
depth estimation (Sintel, KITTI), 3D reconstruction (7-Scenes, NRGBD), and
camera pose estimation (Sintel, TUM-dynamics) show that our approach closely
matches StreamVGGT at a fraction of the memory and makes long-horizon streaming
inference more practical.

</details>


### [177] [SISMA: Semantic Face Image Synthesis with Mamba](https://arxiv.org/abs/2509.17651)
*Filippo Botti,Alex Ergasti,Tomaso Fontanini,Claudio Ferrari,Massimo Bertozzi,Andrea Prati*

Main category: cs.CV

TL;DR: SISMA是一种基于Mamba的新型架构，用于高效语义图像合成，比现有方法更快且质量更高。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语义图像合成中计算成本高，尤其是注意力层的二次复杂度问题，需要一种更高效的解决方案。

Method: 提出了一种基于Mamba的新型架构SISMA，通过语义掩码控制样本形状，减少计算需求。

Result: 在CelebAMask-HQ上的实验表明，SISMA不仅获得了更好的FID分数，而且运行速度是现有最先进架构的三倍。

Conclusion: SISMA是一种可行且轻量级的替代方案，能够替代基于Transformer的模型，在保持高质量样本生成的同时显著降低计算需求。

Abstract: Diffusion Models have become very popular for Semantic Image Synthesis (SIS)
of human faces. Nevertheless, their training and inference is computationally
expensive and their computational requirements are high due to the quadratic
complexity of attention layers. In this paper, we propose a novel architecture
called SISMA, based on the recently proposed Mamba. SISMA generates high
quality samples by controlling their shape using a semantic mask at a reduced
computational demand. We validated our approach through comprehensive
experiments with CelebAMask-HQ, revealing that our architecture not only
achieves a better FID score yet also operates at three times the speed of
state-of-the-art architectures. This indicates that the proposed design is a
viable, lightweight substitute to transformer-based models.

</details>


### [178] [Clothing agnostic Pre-inpainting Virtual Try-ON](https://arxiv.org/abs/2509.17654)
*Sehyun Kim,Hye Jun Lee,Jiwoo Lee,Taemin Lee*

Main category: cs.CV

TL;DR: CaP-VTON通过多类别掩码和皮肤修复模块，解决了虚拟试穿中的纹理失真和皮肤修复问题，显著提升了合成效果。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在虚拟试穿中存在纹理失真、底部检测不准确及服装轮廓残留问题，亟需改进。

Method: 提出CaP-VTON，结合基于Dress Code的多类别掩码和基于Stable Diffusion的皮肤修复模块，特别设计了生成皮肤模块以解决长袖转短袖时的皮肤修复问题。

Result: CaP-VTON在短袖合成准确率上达到92.5%，视觉评估中能一致性地复现参考服装的样式和形状。

Conclusion: CaP-VTON通过整合多类别掩码和皮肤修复模块，显著提升了全身服装合成的自然度和一致性，尤其在短袖合成准确率上优于现有方法15.4%，并适用于多种基于扩散的虚拟试穿系统。

Abstract: With the development of deep learning technology, virtual try-on technology
has become an important application value in the fields of e-commerce, fashion,
and entertainment. The recently proposed Leffa has improved the texture
distortion problem of diffu-sion-based models, but there are limitations in
that the bottom detection inaccuracy and the existing clothing silhouette
remain in the synthesis results. To solve this problem, this study proposes
CaP-VTON (Clothing agnostic Pre-inpainting Virtual Try-ON). CaP-VTON has
improved the naturalness and consistency of whole-body clothing syn-thesis by
integrating multi-category masking based on Dress Code and skin inpainting
based on Stable Diffusion. In particular, a generate skin module was introduced
to solve the skin restoration problem that occurs when long-sleeved images are
converted into short-sleeved or sleeveless ones, and high-quality restoration
was implemented consider-ing the human body posture and color. As a result,
CaP-VTON recorded 92.5\%, which is 15.4\% better than Leffa in short-sleeved
synthesis accuracy, and showed the performance of consistently reproducing the
style and shape of reference clothing in visual evaluation. These structures
maintain model-agnostic properties and are applicable to various
diffu-sion-based virtual inspection systems, and can contribute to applications
that require high-precision virtual wearing, such as e-commerce, custom
styling, and avatar creation.

</details>


### [179] [Development and validation of an AI foundation model for endoscopic diagnosis of esophagogastric junction adenocarcinoma: a cohort and deep learning study](https://arxiv.org/abs/2509.17660)
*Yikun Ma,Bo Li,Ying Chen,Zijie Yue,Shuchang Xu,Jingyao Li,Lei Ma,Liang Zhong,Duowu Zou,Leiming Xu,Yunshi Zhong,Xiaobo Li,Weiqun Ding,Minmin Zhang,Dongli He,Zhenghong Li,Ye Chen,Ye Zhao,Jialong Zhuo,Xiaofen Wu,Lisha Yi,Miaojing Shi,Huihui Sun*

Main category: cs.CV

TL;DR: 本文开发了一种基于AI基础模型的EGJA筛查和分期诊断方法，在多中心研究中表现优异，显著提升了诊断准确性和效率。


<details>
  <summary>Details</summary>
Motivation: EGJA的早期检测对改善患者预后至关重要，但目前的诊断高度依赖操作者。本文旨在首次尝试开发一种基于AI基础模型的方法，用于EGJA的筛查和分期诊断。

Method: 本研究采用DINOv2和ResNet50模型，从内窥镜图像中提取全局外观和局部细节特征，用于EGJA的分期诊断。

Result: 模型在三个测试集上的准确率分别为0.9256、0.8895和0.8956，显著优于其他代表性AI模型和专家内镜医师。模型辅助下，内镜医师的准确率也有显著提升。

Conclusion: 本文成功开发了一种基于AI基础模型的方法，用于EGJA的筛查和分期诊断，证明了其在诊断准确性和效率方面的巨大潜力。

Abstract: The early detection of esophagogastric junction adenocarcinoma (EGJA) is
crucial for improving patient prognosis, yet its current diagnosis is highly
operator-dependent. This paper aims to make the first attempt to develop an
artificial intelligence (AI) foundation model-based method for both screening
and staging diagnosis of EGJA using endoscopic images. In this cohort and
learning study, we conducted a multicentre study across seven Chinese hospitals
between December 28, 2016 and December 30, 2024. It comprises 12,302 images
from 1,546 patients; 8,249 of them were employed for model training, while the
remaining were divided into the held-out (112 patients, 914 images), external
(230 patients, 1,539 images), and prospective (198 patients, 1,600 images) test
sets for evaluation. The proposed model employs DINOv2 (a vision foundation
model) and ResNet50 (a convolutional neural network) to extract features of
global appearance and local details of endoscopic images for EGJA staging
diagnosis. Our model demonstrates satisfactory performance for EGJA staging
diagnosis across three test sets, achieving an accuracy of 0.9256, 0.8895, and
0.8956, respectively. In contrast, among representative AI models, the best one
(ResNet50) achieves an accuracy of 0.9125, 0.8382, and 0.8519 on the three test
sets, respectively; the expert endoscopists achieve an accuracy of 0.8147 on
the held-out test set. Moreover, with the assistance of our model, the overall
accuracy for the trainee, competent, and expert endoscopists improves from
0.7035, 0.7350, and 0.8147 to 0.8497, 0.8521, and 0.8696, respectively. To our
knowledge, our model is the first application of foundation models for EGJA
staging diagnosis and demonstrates great potential in both diagnostic accuracy
and efficiency.

</details>


### [180] [Tailored Transformation Invariance for Industrial Anomaly Detection](https://arxiv.org/abs/2509.17670)
*Mariette Schönfeld,Wannes Meert,Hendrik Blockeel*

Main category: cs.CV

TL;DR: 论文提出LWinNN方法，通过有限的平移不变性在kNN和复杂方法之间取得平衡，显著提升工业异常检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测（IAD）在计算机视觉领域受到越来越多的关注，但现有方法要么训练成本高，要么仅使用预训练特征。论文旨在通过研究平移不变性，提出一种更高效的方法。

Method: 提出了一种基于局部窗口的方法LWinNN，该方法在kNN基础方法的基础上增加了有限的平移不变性，从而在准确性和效率之间取得了平衡。

Result: 实验表明，LWinNN方法显著提高了准确性，同时减少了训练和测试时间。

Conclusion: 论文通过提出LWinNN方法，在kNN基础方法和复杂的最新方法之间找到了一个平衡点，显著提高了准确性并减少了训练和测试时间。同时，论文强调了未来工作中需要更多空间多样性的基准测试。

Abstract: Industrial Anomaly Detection (IAD) is a subproblem within Computer Vision
Anomaly Detection that has been receiving increasing amounts of attention due
to its applicability to real-life scenarios. Recent research has focused on how
to extract the most informative features, contrasting older kNN-based methods
that use only pretrained features. These recent methods are much more expensive
to train however and could complicate real-life application. Careful study of
related work with regards to transformation invariance leads to the idea that
popular benchmarks require robustness to only minor translations. With this
idea we then formulate LWinNN, a local window based approach that creates a
middle ground between kNN based methods that have either complete or no
translation invariance. Our experiments demonstrate that this small change
increases accuracy considerably, while simultaneously decreasing both train and
test time. This teaches us two things: first, the gap between kNN-based
approaches and more complex state-of-the-art methodology can still be narrowed
by effective usage of the limited data available. Second, our assumption of
requiring only limited translation invariance highlights potential areas of
interest for future work and the need for more spatially diverse benchmarks,
for which our method can hopefully serve as a new baseline. Our code can be
found at https://github.com/marietteschonfeld/LWinNN .

</details>


### [181] [FROQ: Observing Face Recognition Models for Efficient Quality Assessment](https://arxiv.org/abs/2509.17689)
*Žiga Babnik,Deepak Kumar Jain,Peter Peer,Vitomir Štruc*

Main category: cs.CV

TL;DR: FROQ是一种半监督、无需训练的面部图像质量评估方法，结合监督式和无监督式技术的优势，实现了高效且高性能的质量评估。


<details>
  <summary>Details</summary>
Motivation: 现有的FIQA技术中，监督式方法需要大量训练，而无监督方法虽然无需训练但性能较低且速度较慢，因此需要一种兼顾效率和性能的解决方案。

Method: 利用FR模型中的特定中间表示来估计面部图像质量，并通过基于伪质量标签的简单校准步骤，发现适用于质量评估的特定表示。

Result: 在四个先进的FR模型和八个基准数据集上的实验表明，FROQ在性能和运行效率上均具有竞争力，且无需显式训练。

Conclusion: FROQ作为一种半监督、无需训练的方法，成功结合了监督式和无监督式FIQA技术的优势，实现了高效且高性能的面部图像质量评估。

Abstract: Face Recognition (FR) plays a crucial role in many critical (high-stakes)
applications, where errors in the recognition process can lead to serious
consequences. Face Image Quality Assessment (FIQA) techniques enhance FR
systems by providing quality estimates of face samples, enabling the systems to
discard samples that are unsuitable for reliable recognition or lead to
low-confidence recognition decisions. Most state-of-the-art FIQA techniques
rely on extensive supervised training to achieve accurate quality estimation.
In contrast, unsupervised techniques eliminate the need for additional training
but tend to be slower and typically exhibit lower performance. In this paper,
we introduce FROQ (Face Recognition Observer of Quality), a semi-supervised,
training-free approach that leverages specific intermediate representations
within a given FR model to estimate face-image quality, and combines the
efficiency of supervised FIQA models with the training-free approach of
unsupervised methods. A simple calibration step based on pseudo-quality labels
allows FROQ to uncover specific representations, useful for quality assessment,
in any modern FR model. To generate these pseudo-labels, we propose a novel
unsupervised FIQA technique based on sample perturbations. Comprehensive
experiments with four state-of-the-art FR models and eight benchmark datasets
show that FROQ leads to highly competitive results compared to the
state-of-the-art, achieving both strong performance and efficient runtime,
without requiring explicit training.

</details>


### [182] [Depth Edge Alignment Loss: DEALing with Depth in Weakly Supervised Semantic Segmentation](https://arxiv.org/abs/2509.17702)
*Patrick Schmidt,Vasileios Belagiannis,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: 提出一种深度边缘对齐损失，利用深度信息提升弱监督语义分割性能，显著减少标注成本。


<details>
  <summary>Details</summary>
Motivation: 全监督训练需要大量昂贵的像素级密集标注，而弱监督方法可减少标注成本。

Method: 通过图像级监督生成像素级语义标签，并利用机器人系统中常见的像素级深度信息作为额外监督。

Result: 在PASCAL VOC、MS COCO和HOPE数据集上，平均交并比分别提升了5.439、1.274和16.416个百分点。

Conclusion: 该研究提出了一种模型无关的深度边缘对齐损失，显著提升了不同数据集上弱监督语义分割模型的性能，且可与其他损失结合以进一步提升效果。

Abstract: Autonomous robotic systems applied to new domains require an abundance of
expensive, pixel-level dense labels to train robust semantic segmentation
models under full supervision. This study proposes a model-agnostic Depth Edge
Alignment Loss to improve Weakly Supervised Semantic Segmentation models across
different datasets. The methodology generates pixel-level semantic labels from
image-level supervision, avoiding expensive annotation processes. While weak
supervision is widely explored in traditional computer vision, our approach
adds supervision with pixel-level depth information, a modality commonly
available in robotic systems. We demonstrate how our approach improves
segmentation performance across datasets and models, but can also be combined
with other losses for even better performance, with improvements up to +5.439,
+1.274 and +16.416 points in mean Intersection over Union on the PASCAL VOC /
MS COCO validation, and the HOPE static onboarding split, respectively. Our
code will be made publicly available.

</details>


### [183] [Neurodynamics-Driven Coupled Neural P Systems for Multi-Focus Image Fusion](https://arxiv.org/abs/2509.17704)
*Bo Li,Yunkuo Lei,Tingting Bao,Yaxian Wang,Lingling Zhang,Jun Liu*

Main category: cs.CV

TL;DR: ND-CNPFuse利用神经动力学驱动的耦合神经P系统，直接生成高质量决策图，无需后处理，并在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于启发式规则的方法和深度学习黑盒机制难以生成高质量决策图，因此需要一种更精确的方法来区分聚焦与非聚焦区域。

Method: 提出了一种基于神经动力学驱动的耦合神经P系统（ND-CNPFuse），通过将源图像映射为可解释的脉冲矩阵，并比较脉冲数量来直接生成决策图。

Result: 在Lytro、MFFW、MFI-WHU和Real-MFF四个经典MFIF数据集上，ND-CNPFuse实现了最先进的性能。

Conclusion: ND-CNPFuse通过神经动力学驱动的耦合神经P系统，显著提升了多焦点图像融合中决策图的生成质量，无需后处理即可直接生成精确的决策图，并在多个经典数据集上实现了最先进的性能。

Abstract: Multi-focus image fusion (MFIF) is a crucial technique in image processing,
with a key challenge being the generation of decision maps with precise
boundaries. However, traditional methods based on heuristic rules and deep
learning methods with black-box mechanisms are difficult to generate
high-quality decision maps. To overcome this challenge, we introduce
neurodynamics-driven coupled neural P (CNP) systems, which are third-generation
neural computation models inspired by spiking mechanisms, to enhance the
accuracy of decision maps. Specifically, we first conduct an in-depth analysis
of the model's neurodynamics to identify the constraints between the network
parameters and the input signals. This solid analysis avoids abnormal
continuous firing of neurons and ensures the model accurately distinguishes
between focused and unfocused regions, generating high-quality decision maps
for MFIF. Based on this analysis, we propose a
\textbf{N}eurodynamics-\textbf{D}riven \textbf{CNP} \textbf{F}usion model
(\textbf{ND-CNPFuse}) tailored for the challenging MFIF task. Unlike current
ideas of decision map generation, ND-CNPFuse distinguishes between focused and
unfocused regions by mapping the source image into interpretable spike
matrices. By comparing the number of spikes, an accurate decision map can be
generated directly without any post-processing. Extensive experimental results
show that ND-CNPFuse achieves new state-of-the-art performance on four
classical MFIF datasets, including Lytro, MFFW, MFI-WHU, and Real-MFF. The code
is available at https://github.com/MorvanLi/ND-CNPFuse.

</details>


### [184] [Automatic Intermodal Loading Unit Identification using Computer Vision: A Scoping Review](https://arxiv.org/abs/2509.17707)
*Emre Gülsoylu,Alhassan Abdelhalim,Derya Kara Boztas,Ole Grasse,Carlos Jahn,Simone Frintrop,Janick Edinger*

Main category: cs.CV

TL;DR: 本文回顾了35年来计算机视觉在多式联运装载单元识别中的应用，指出数据集缺乏和新兴挑战，呼吁标准化和开放资源以推动领域发展。


<details>
  <summary>Details</summary>
Motivation: 高效且稳健的识别多式联运装载单元（ILUs）是全球贸易中的关键瓶颈，计算机视觉（CV）提供了成本效益高的替代方案，但其发展受限于缺乏公开可用的基准数据集。

Method: 本文回顾了63项实证研究，涵盖了从早期数字图像处理（DIP）和传统机器学习（ML）到当前深度学习（DL）技术的主导地位。

Result: 报告的结果存在高度差异，端到端准确率从5%到96%不等。此外，新兴挑战包括从基于字符的文本识别转向场景文本识别以及移动摄像头（如无人机、传感器装备的地面车辆）的动态终端监控。

Conclusion: 本文呼吁标准化术语、开放访问数据集和共享源代码，并提出了未来研究方向，如针对ISO6346代码优化的无上下文文本识别。

Abstract: The standardisation of Intermodal Loading Units (ILUs), such as containers,
semi-trailers and swap bodies, has revolutionised global trade yet their
efficient and robust identification remains a critical bottleneck in
high-throughput ports and terminals. This paper reviews 63 empirical studies
that propose computer vision (CV) based solutions. It covers the last 35 years
(1990-2025), tracing the field's evolution from early digital image processing
(DIP) and traditional machine learning (ML) to the current dominance of deep
learning (DL) techniques. While CV offers cost-effective alternatives for other
types of identification techniques, its development is hindered by the lack of
publicly available benchmarking datasets. This results in high variance for the
reported results such as end-to-end accuracy ranging from 5 % to 96 %. Beyond
dataset limitations, this review highlights the emerging challenges especially
introduced by the shift from character-based text recognition to scene-text
spotting and the integration of mobile cameras (e.g. drones, sensor equipped
ground vehicles) for dynamic terminal monitoring. To advance the field, the
paper calls for standardised terminology, open-access datasets, shared source
code, while outlining future research directions such as contextless text
recognition optimised for ISO6346 codes.

</details>


### [185] [RCTDistill: Cross-Modal Knowledge Distillation Framework for Radar-Camera 3D Object Detection with Temporal Fusion](https://arxiv.org/abs/2509.17712)
*Geonho Bang,Minjae Seong,Jisong Kim,Geunju Baek,Daye Oh,Junhyung Kim,Junho Koh,Jun Won Choi*

Main category: cs.CV

TL;DR: RCTDistill是一种新颖的跨模态知识蒸馏方法，通过三个模块处理雷达-相机融合中的误差和时序问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的雷达-相机融合方法在性能上仍落后于LiDAR方法，且未充分考虑物体运动或传感器固有误差带来的不确定性。

Method: 提出了RCTDistill方法，包括RAKD、TKD和RDKD三个模块，分别处理雷达和相机模态的固有误差、动态对象导致的时序错位以及特征区分问题。

Result: RCTDistill在nuScenes和VoD数据集上实现了最先进的性能，推理速度达到26.2 FPS。

Conclusion: RCTDistill通过结合RAKD、TKD和RDKD三个模块，显著提升了雷达-相机融合的性能，并在nuScenes和VoD数据集上实现了最先进的性能。

Abstract: Radar-camera fusion methods have emerged as a cost-effective approach for 3D
object detection but still lag behind LiDAR-based methods in performance.
Recent works have focused on employing temporal fusion and Knowledge
Distillation (KD) strategies to overcome these limitations. However, existing
approaches have not sufficiently accounted for uncertainties arising from
object motion or sensor-specific errors inherent in radar and camera
modalities. In this work, we propose RCTDistill, a novel cross-modal KD method
based on temporal fusion, comprising three key modules: Range-Azimuth Knowledge
Distillation (RAKD), Temporal Knowledge Distillation (TKD), and
Region-Decoupled Knowledge Distillation (RDKD). RAKD is designed to consider
the inherent errors in the range and azimuth directions, enabling effective
knowledge transfer from LiDAR features to refine inaccurate BEV
representations. TKD mitigates temporal misalignment caused by dynamic objects
by aligning historical radar-camera BEV features with current LiDAR
representations. RDKD enhances feature discrimination by distilling relational
knowledge from the teacher model, allowing the student to differentiate
foreground and background features. RCTDistill achieves state-of-the-art
radar-camera fusion performance on both the nuScenes and View-of-Delft (VoD)
datasets, with the fastest inference speed of 26.2 FPS.

</details>


### [186] [Automated Labeling of Intracranial Arteries with Uncertainty Quantification Using Deep Learning](https://arxiv.org/abs/2509.17726)
*Javier Bisbal,Patrick Winter,Sebastian Jofre,Aaron Ponce,Sameer A. Ansari,Ramez Abdalla,Michael Markl,Oliver Welin Odeback,Sergio Uribe,Cristian Tejos,Julio Sotelo,Susanne Schnell,David Marlevi*

Main category: cs.CV

TL;DR: 提出了一种基于深度学习的自动化动脉标记框架，结合不确定性量化，nnUNet表现最佳，并在临床验证中显示出与手动标记的一致性。


<details>
  <summary>Details</summary>
Motivation: 颅内动脉的准确解剖标记对脑血管诊断和血流动力学分析至关重要，但现有方法耗时且存在操作者间差异。

Method: 评估了三种卷积神经网络架构：(1) 带有残差编码器块的UNet；(2) 增强通道和空间注意力机制的CS-Net；(3) 自配置的nnUNet框架。其中nnUNet表现最佳。

Result: nnUNet实现了最高的标记性能（平均Dice分数：0.922；平均表面距离：0.387 mm），并在解剖复杂血管中表现出更强的鲁棒性。

Conclusion: 该框架提供了一个可扩展、准确且具备不确定性感知的自动化脑血管标记解决方案，支持下游血流动力学分析并促进临床整合。

Abstract: Accurate anatomical labeling of intracranial arteries is essential for
cerebrovascular diagnosis and hemodynamic analysis but remains time-consuming
and subject to interoperator variability. We present a deep learning-based
framework for automated artery labeling from 3D Time-of-Flight Magnetic
Resonance Angiography (3D ToF-MRA) segmentations (n=35), incorporating
uncertainty quantification to enhance interpretability and reliability. We
evaluated three convolutional neural network architectures: (1) a UNet with
residual encoder blocks, reflecting commonly used baselines in vascular
labeling; (2) CS-Net, an attention-augmented UNet incorporating channel and
spatial attention mechanisms for enhanced curvilinear structure recognition;
and (3) nnUNet, a self-configuring framework that automates preprocessing,
training, and architectural adaptation based on dataset characteristics. Among
these, nnUNet achieved the highest labeling performance (average Dice score:
0.922; average surface distance: 0.387 mm), with improved robustness in
anatomically complex vessels. To assess predictive confidence, we implemented
test-time augmentation (TTA) and introduced a novel coordinate-guided strategy
to reduce interpolation errors during augmented inference. The resulting
uncertainty maps reliably indicated regions of anatomical ambiguity,
pathological variation, or manual labeling inconsistency. We further validated
clinical utility by comparing flow velocities derived from automated and manual
labels in co-registered 4D Flow MRI datasets, observing close agreement with no
statistically significant differences. Our framework offers a scalable,
accurate, and uncertainty-aware solution for automated cerebrovascular
labeling, supporting downstream hemodynamic analysis and facilitating clinical
integration.

</details>


### [187] [WISE: Weak-Supervision-Guided Step-by-Step Explanations for Multimodal LLMs in Image Classification](https://arxiv.org/abs/2509.17740)
*Yiwen Jiang,Deval Mehta,Siyuan Yan,Yaling Shen,Zimu Wang,Zongyuan Ge*

Main category: cs.CV

TL;DR: WISE方法通过弱监督引导的逐步解释，将概念表示转化为推理链，提升了MLLMs的可解释性和分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有MCoT方法依赖丰富的数据集且主要关注对象间推理，忽视了对象内理解对图像分类的重要性。

Method: 提出WISE方法，利用弱监督引导的逐步解释技术，将Concept Bottleneck Models（CBMs）的概念表示转化为简洁、可解释的推理链。

Result: 在十个数据集上的实验表明，生成的MCoTs不仅提高了37%的可解释性，还能在微调MLLMs时提升分类准确率。

Conclusion: 该研究通过WISE方法，成功将基于概念的可解释性与生成式MCoT推理相结合，为增强MLLMs在细粒度视觉理解中的表现提供了一个通用框架。

Abstract: Multimodal Large Language Models (MLLMs) have shown promise in visual-textual
reasoning, with Multimodal Chain-of-Thought (MCoT) prompting significantly
enhancing interpretability. However, existing MCoT methods rely on
rationale-rich datasets and largely focus on inter-object reasoning,
overlooking the intra-object understanding crucial for image classification. To
address this gap, we propose WISE, a Weak-supervision-guided Step-by-step
Explanation method that augments any image classification dataset with MCoTs by
reformulating the concept-based representations from Concept Bottleneck Models
(CBMs) into concise, interpretable reasoning chains under weak supervision.
Experiments across ten datasets show that our generated MCoTs not only improve
interpretability by 37% but also lead to gains in classification accuracy when
used to fine-tune MLLMs. Our work bridges concept-based interpretability and
generative MCoT reasoning, providing a generalizable framework for enhancing
MLLMs in fine-grained visual understanding.

</details>


### [188] [Adaptive Fast-and-Slow Visual Program Reasoning for Long-Form VideoQA](https://arxiv.org/abs/2509.17743)
*Chenglin Li,Feng Han,FengTao,Ruilin Li,Qianglong Chen,Jingqi Tong,Yin Zhang,Jiaqi Wang*

Main category: cs.CV

TL;DR: FS-VisPR是一种自适应视觉程序推理框架，通过快速-慢速推理机制和参数搜索优化，显著提升了长视频问答任务的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖闭源模型、缺乏系统性推理能力，且在长视频问答任务中表现不佳。FS-VisPR旨在通过模拟人类推理过程，平衡快速推理与慢速推理，解决这些挑战。

Method: 设计了高效的视觉模块（如关键片段检索和字幕检索），构建了多样化的快速-慢速推理数据集，并开发了FS-LLM模型来生成视觉程序工作流。通过参数搜索优化视觉程序，在训练和推理阶段选择最佳程序。

Result: FS-VisPR在LVBench上达到50.4%的准确率，超越了GPT-4o，并与Qwen2.5VL-72B在VideoMME上的性能相当。

Conclusion: FS-VisPR框架通过快速-慢速推理机制，显著提升了视觉程序工作流的效率和可靠性，在多个基准测试中表现优异，甚至超越了GPT-4o等模型。

Abstract: Large language models (LLMs) have shown promise in generating program
workflows for visual tasks. However, previous approaches often rely on
closed-source models, lack systematic reasoning, and struggle with long-form
video question answering (videoQA). To address these challenges, we introduce
the FS-VisPR framework, an adaptive visual program reasoning approach that
balances fast reasoning for simple queries with slow reasoning for difficult
ones. First, we design efficient visual modules (e.g., key clip retrieval and
subtitle retrieval) to support long-form video tasks. Then, we construct a
diverse and high-quality fast-slow reasoning dataset with a strong LLM to align
open-source language models' ability to generate visual program workflows as
FS-LLM. Next, we design a fast-slow reasoning framework with FS-LLM: Simple
queries are directly solved by VideoLLMs, while difficult ones invoke visual
program reasoning, motivated by human-like reasoning processes. During this
process, low-confidence fast-thinking answers will trigger a second-stage
slow-reasoning process, and a fallback mechanism to fast reasoning is activated
if the program execution fails. Moreover, we improve visual programs through
parameter search during both training and inference. By adjusting the
parameters of the visual modules within the program, multiple variants are
generated: during training, programs that yield correct answers are selected,
while during inference, the program with the highest confidence result is
applied. Experiments show that FS-VisPR improves both efficiency and
reliability in visual program workflows. It achieves 50.4% accuracy on LVBench,
surpassing GPT-4o, matching the performance of Qwen2.5VL-72B on VideoMME.

</details>


### [189] [Multi-Agent Amodal Completion: Direct Synthesis with Fine-Grained Semantic Guidance](https://arxiv.org/abs/2509.17757)
*Hongxing Fan,Lipeng Wang,Haohua Chen,Zehuan Huang,Jiangtao Wu,Lu Sheng*

Main category: cs.CV

TL;DR: 提出协作多智能体推理框架，通过多智能体协同分析和语义引导，显著提升遮挡物体生成的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在数据需求、泛化能力或渐进式流程中的错误累积等问题，提升遮挡物体不可见部分的生成精度。

Method: 提出了一个基于前期协作推理的协作多智能体推理框架，利用多个智能体协同分析遮挡关系并确定边界扩展，同时生成细粒度文本描述以实现语义引导。

Result: 框架直接生成分层的RGBA输出，无需额外分割，并在视觉质量上达到最先进水平。

Conclusion: 该框架通过协作多智能体推理和细粒度语义引导，显著提升了视觉质量，并在广泛评估中达到了最先进的水平。

Abstract: Amodal completion, generating invisible parts of occluded objects, is vital
for applications like image editing and AR. Prior methods face challenges with
data needs, generalization, or error accumulation in progressive pipelines. We
propose a Collaborative Multi-Agent Reasoning Framework based on upfront
collaborative reasoning to overcome these issues. Our framework uses multiple
agents to collaboratively analyze occlusion relationships and determine
necessary boundary expansion, yielding a precise mask for inpainting.
Concurrently, an agent generates fine-grained textual descriptions, enabling
Fine-Grained Semantic Guidance. This ensures accurate object synthesis and
prevents the regeneration of occluders or other unwanted elements, especially
within large inpainting areas. Furthermore, our method directly produces
layered RGBA outputs guided by visible masks and attention maps from a
Diffusion Transformer, eliminating extra segmentation. Extensive evaluations
demonstrate our framework achieves state-of-the-art visual quality.

</details>


### [190] [Neural-MMGS: Multi-modal Neural Gaussian Splats for Large-Scale Scene Reconstruction](https://arxiv.org/abs/2509.17762)
*Sitian Shen,Georgi Pramatarov,Yifu Tao,Daniele De Martini*

Main category: cs.CV

TL;DR: Neural-MMGS通过多模态紧凑嵌入和神经解码器，实现了高效的大规模场景重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用LiDAR和语义信息时存在内存开销大和信息交换有限的问题，希望通过紧凑嵌入和多模态融合优化重建效果。

Method: 提出了一种新颖的神经3DGS框架，将图像、LiDAR和语义信息融合到每个高斯分布的紧凑嵌入中，并通过轻量级神经解码器映射到高斯参数。

Result: 在Oxford Spires和KITTI-360数据集上验证了方法的高质量重建和低存储消耗优势。

Conclusion: Neural-MMGS通过融合多模态数据到紧凑的可学习嵌入中，实现了高质量的大规模场景重建，同时降低了内存开销。

Abstract: This paper proposes Neural-MMGS, a novel neural 3DGS framework for multimodal
large-scale scene reconstruction that fuses multiple sensing modalities in a
per-gaussian compact, learnable embedding. While recent works focusing on
large-scale scene reconstruction have incorporated LiDAR data to provide more
accurate geometric constraints, we argue that LiDAR's rich physical properties
remain underexplored. Similarly, semantic information has been used for object
retrieval, but could provide valuable high-level context for scene
reconstruction. Traditional approaches append these properties to Gaussians as
separate parameters, increasing memory usage and limiting information exchange
across modalities. Instead, our approach fuses all modalities -- image, LiDAR,
and semantics -- into a compact, learnable embedding that implicitly encodes
optical, physical, and semantic features in each Gaussian. We then train
lightweight neural decoders to map these embeddings to Gaussian parameters,
enabling the reconstruction of each sensing modality with lower memory overhead
and improved scalability. We evaluate Neural-MMGS on the Oxford Spires and
KITTI-360 datasets. On Oxford Spires, we achieve higher-quality
reconstructions, while on KITTI-360, our method reaches competitive results
with less storage consumption compared with current approaches in LiDAR-based
novel-view synthesis.

</details>


### [191] [Incorporating the Refractory Period into Spiking Neural Networks through Spike-Triggered Threshold Dynamics](https://arxiv.org/abs/2509.17769)
*Yang Li,Xinyi Zeng,Zhe Xue,Pinxian Zeng,Zikai Zhang,Yan Wang*

Main category: cs.CV

TL;DR: RPLIF通过引入不应期机制改进了LIF神经元，提升了SNN性能和鲁棒性，在多个数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有SNN神经元模型（如IF和LIF）忽略了生物神经元的不应期特性，这可能导致过度兴奋和异常信号干扰。

Method: 提出了一种简单有效的方法RPLIF，通过脉冲触发的阈值动态将不应期整合到LIF神经元中。

Result: RPLIF在Cifar10-DVS(82.40%)、N-Caltech101(83.35%)和DVS128 Gesture(97.22%)等数据集上取得了最优性能。

Conclusion: RPLIF通过引入不应期机制，显著提升了SNN在处理神经形态数据集时的性能和鲁棒性，且计算开销极小。

Abstract: As the third generation of neural networks, spiking neural networks (SNNs)
have recently gained widespread attention for their biological plausibility,
energy efficiency, and effectiveness in processing neuromorphic datasets. To
better emulate biological neurons, various models such as Integrate-and-Fire
(IF) and Leaky Integrate-and-Fire (LIF) have been widely adopted in SNNs.
However, these neuron models overlook the refractory period, a fundamental
characteristic of biological neurons. Research on excitable neurons reveal that
after firing, neurons enter a refractory period during which they are
temporarily unresponsive to subsequent stimuli. This mechanism is critical for
preventing over-excitation and mitigating interference from aberrant signals.
Therefore, we propose a simple yet effective method to incorporate the
refractory period into spiking LIF neurons through spike-triggered threshold
dynamics, termed RPLIF. Our method ensures that each spike accurately encodes
neural information, effectively preventing neuron over-excitation under
continuous inputs and interference from anomalous inputs. Incorporating the
refractory period into LIF neurons is seamless and computationally efficient,
enhancing robustness and efficiency while yielding better performance with
negligible overhead. To the best of our knowledge, RPLIF achieves
state-of-the-art performance on Cifar10-DVS(82.40%) and N-Caltech101(83.35%)
with fewer timesteps and demonstrates superior performance on DVS128
Gesture(97.22%) at low latency.

</details>


### [192] [I2VWM: Robust Watermarking for Image to Video Generation](https://arxiv.org/abs/2509.17773)
*Guanjie Wang,Zehua Ma,Han Fang,Weiming Zhang*

Main category: cs.CV

TL;DR: I2VWM是一种跨模态水印框架，通过Robust Diffusion Distance和光流对齐，显著提升水印在生成视频中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法在单模态中表现良好，但无法追踪图像到视频生成（I2V）中的源图像，亟需跨模态水印解决方案。

Method: 提出I2VWM框架，结合视频模拟噪声层和基于光流的对齐模块，增强水印的时域持久性。

Result: 实验表明，I2VWM在开源和商业I2V模型中均显著提升水印鲁棒性，同时保持不可感知性。

Conclusion: I2VWM通过引入Robust Diffusion Distance和跨模态水印框架，显著提高了水印在生成视频中的鲁棒性，为生成视频时代的水印技术设立了新范式。

Abstract: The rapid progress of image-guided video generation (I2V) has raised concerns
about its potential misuse in misinformation and fraud, underscoring the urgent
need for effective digital watermarking. While existing watermarking methods
demonstrate robustness within a single modality, they fail to trace source
images in I2V settings. To address this gap, we introduce the concept of Robust
Diffusion Distance, which measures the temporal persistence of watermark
signals in generated videos. Building on this, we propose I2VWM, a cross-modal
watermarking framework designed to enhance watermark robustness across time.
I2VWM leverages a video-simulation noise layer during training and employs an
optical-flow-based alignment module during inference. Experiments on both
open-source and commercial I2V models demonstrate that I2VWM significantly
improves robustness while maintaining imperceptibility, establishing a new
paradigm for cross-modal watermarking in the era of generative video.
\href{https://github.com/MrCrims/I2VWM-Robust-Watermarking-for-Image-to-Video-Generation}{Code
Released.}

</details>


### [193] [From Restoration to Reconstruction: Rethinking 3D Gaussian Splatting for Underwater Scenes](https://arxiv.org/abs/2509.17789)
*Guoxi Huang,Haoran Wang,Zipeng Qi,Wenjun Lu,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: R-Splatting 结合水下图像恢复与 3D 高斯泼溅，通过多视图集成和光照优化，显著提升水下 3D 重建的渲染质量和几何精度。


<details>
  <summary>Details</summary>
Motivation: 水下图像退化对 3D 重建提出挑战，传统简化物理模型在复杂场景中效果不佳，因此需要一种能同时提升渲染质量和几何保真度的方法。

Method: 提出了一种统一框架 R-Splatting，将水下图像恢复（UIR）与 3D 高斯泼溅（3DGS）结合，通过集成多增强视图、轻量级光照生成器和对比损失优化光照表示，并引入不确定性感知不透明度优化（UAOO）来抑制光照变化引起的梯度问题。

Result: 在 Seathru-NeRF 和 BlueCoral3D 数据集上的实验表明，R-Splatting 在渲染质量和几何精度上均优于强基线方法。

Conclusion: R-Splatting 在渲染质量和几何精度上均优于现有基线方法，特别是在复杂水下场景中表现出色。

Abstract: Underwater image degradation poses significant challenges for 3D
reconstruction, where simplified physical models often fail in complex scenes.
We propose \textbf{R-Splatting}, a unified framework that bridges underwater
image restoration (UIR) with 3D Gaussian Splatting (3DGS) to improve both
rendering quality and geometric fidelity. Our method integrates multiple
enhanced views produced by diverse UIR models into a single reconstruction
pipeline. During inference, a lightweight illumination generator samples latent
codes to support diverse yet coherent renderings, while a contrastive loss
ensures disentangled and stable illumination representations. Furthermore, we
propose \textit{Uncertainty-Aware Opacity Optimization (UAOO)}, which models
opacity as a stochastic function to regularize training. This suppresses abrupt
gradient responses triggered by illumination variation and mitigates
overfitting to noisy or view-specific artifacts. Experiments on Seathru-NeRF
and our new BlueCoral3D dataset demonstrate that R-Splatting outperforms strong
baselines in both rendering quality and geometric accuracy.

</details>


### [194] [Degradation-Aware All-in-One Image Restoration via Latent Prior Encoding](https://arxiv.org/abs/2509.17792)
*S M A Sharif,Abdur Rehman,Fayaz Ali Dharejo,Radu Timofte,Rizwan Ali Naqvi*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在先验的全场景恢复方法，通过结构化推理和轻量级解码模块，显著提升了处理混合和未知退化的能力，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现实世界图像常受多种退化（如雾、雨、雪、低光等）影响，现有方法依赖外部文本提示或手工设计的先验，难以泛化到未知或混合退化场景。

Method: 提出了一种基于潜在先验的结构化推理范式，包括自适应特征选择、空间定位和退化语义恢复，并设计了一个轻量级解码模块来实现空间自适应恢复。

Result: 在六种常见退化任务、五种复合设置及未见退化场景中，该方法平均PSNR提升1.68 dB，且效率提升三倍。

Conclusion: 该方法通过将全场景恢复（AIR）重新定义为学习潜在先验推理，显著提升了处理未知或混合退化的能力，并在多个任务中表现优于现有技术。

Abstract: Real-world images often suffer from spatially diverse degradations such as
haze, rain, snow, and low-light, significantly impacting visual quality and
downstream vision tasks. Existing all-in-one restoration (AIR) approaches
either depend on external text prompts or embed hand-crafted architectural
priors (e.g., frequency heuristics); both impose discrete, brittle assumptions
that weaken generalization to unseen or mixed degradations. To address this
limitation, we propose to reframe AIR as learned latent prior inference, where
degradation-aware representations are automatically inferred from the input
without explicit task cues. Based on latent priors, we formulate AIR as a
structured reasoning paradigm: (1) which features to route (adaptive feature
selection), (2) where to restore (spatial localization), and (3) what to
restore (degradation semantics). We design a lightweight decoding module that
efficiently leverages these latent encoded cues for spatially-adaptive
restoration. Extensive experiments across six common degradation tasks, five
compound settings, and previously unseen degradations demonstrate that our
method outperforms state-of-the-art (SOTA) approaches, achieving an average
PSNR improvement of 1.68 dB while being three times more efficient.

</details>


### [195] [Selecting Optimal Camera Views for Gait Analysis: A Multi-Metric Assessment of 2D Projections](https://arxiv.org/abs/2509.17805)
*Dong Chen,Huili Peng,Yong Hu,Kenneth MC. Cheung*

Main category: cs.CV

TL;DR: Lateral camera views are better for sagittal gait kinematics, while frontal views excel for trunk symmetry. This study provides data-driven guidance for camera placement in 2D gait analysis.


<details>
  <summary>Details</summary>
Motivation: To systematically quantify the effect of the camera view (frontal vs. lateral) on the accuracy of 2D markerless gait analysis relative to 3D motion capture ground truth.

Method: Gait data from 18 subjects were recorded simultaneously using frontal, lateral and 3D motion capture systems. Pose estimation used YOLOv8. Four metrics were assessed to evaluate agreement: Dynamic Time Warping (DTW), Maximum Cross-Correlation (MCC), Kullback-Leibler Divergence (KLD), and Information Entropy (IE). Wilcoxon signed-rank tests and Cliff's delta were used for statistical analysis.

Result: Lateral views significantly outperformed frontal views for sagittal plane kinematics (e.g., step length and knee rotation). Frontal views were superior for symmetry parameters (e.g., trunk rotation and wrist-to-hipmid distance). Effect sizes were medium-to-large.

Conclusion: Camera view critically impacts gait parameter accuracy. Lateral views are optimal for sagittal kinematics; frontal views excel for trunk symmetry. Future implementations should leverage both views via disease-oriented setups.

Abstract: Objective: To systematically quantify the effect of the camera view (frontal
vs. lateral) on the accuracy of 2D markerless gait analysis relative to 3D
motion capture ground truth. Methods: Gait data from 18 subjects were recorded
simultaneously using frontal, lateral and 3D motion capture systems. Pose
estimation used YOLOv8. Four metrics were assessed to evaluate agreement:
Dynamic Time Warping (DTW) for temporal alignment, Maximum Cross-Correlation
(MCC) for signal similarity, Kullback-Leibler Divergence (KLD) for distribution
differences, and Information Entropy (IE) for complexity. Wilcoxon signed-rank
tests (significance: $p < 0.05$) and Cliff's delta ($\delta$) were used to
measure statistical differences and effect sizes. Results: Lateral views
significantly outperformed frontal views for sagittal plane kinematics: step
length (DTW: $53.08 \pm 24.50$ vs. $69.87 \pm 25.36$, $p = 0.005$) and knee
rotation (DTW: $106.46 \pm 38.57$ vs. $155.41 \pm 41.77$, $p = 0.004$). Frontal
views were superior for symmetry parameters: trunk rotation (KLD: $0.09 \pm
0.06$ vs. $0.30 \pm 0.19$, $p < 0.001$) and wrist-to-hipmid distance (MCC:
$105.77 \pm 29.72$ vs. $75.20 \pm 20.38$, $p = 0.003$). Effect sizes were
medium-to-large ($\delta: 0.34$--$0.76$). Conclusion: Camera view critically
impacts gait parameter accuracy. Lateral views are optimal for sagittal
kinematics; frontal views excel for trunk symmetry. Significance: This first
systematic evidence enables data-driven camera deployment in 2D gait analysis,
enhancing clinical utility. Future implementations should leverage both views
via disease-oriented setups.

</details>


### [196] [Enhancing Semantic Segmentation with Continual Self-Supervised Pre-training](https://arxiv.org/abs/2509.17816)
*Brown Ebouky,Ajad Chhatkuli,Cristiano Malossi,Christoph Studer,Roy Assaf,Andrea Bartezzaghi*

Main category: cs.CV

TL;DR: GLARE是一种新的持续自监督预训练任务，通过局部和区域一致性增强，高效提升了跨领域语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 针对自监督预训练在新领域（尤其是数据有限和密集预测任务）适应性不足的问题，研究如何无监督且高效地调整视觉基础模型。

Method: 提出了GLARE（全局局部和区域强化）方法，结合了补丁级增强和区域一致性约束，并采用轻量级适配器模块UniAdapter进行高效预训练。

Result: 在多个语义分割基准测试中，GLARE方法一致提升了性能，且计算和参数开销极低。

Conclusion: GLARE方法通过持续的自监督预训练任务，显著提升了跨领域下游语义分割任务的性能，同时保持了计算和参数效率。

Abstract: Self-supervised learning (SSL) has emerged as a central paradigm for training
foundation models by leveraging large-scale unlabeled datasets, often producing
representations with strong generalization capabilities. These models are
typically pre-trained on general-purpose datasets such as ImageNet and
subsequently adapted to various downstream tasks through finetuning. While
recent advances have explored parameter-efficient strategies for adapting
pre-trained models, extending SSL pre-training itself to new domains -
particularly under limited data regimes and for dense prediction tasks -
remains underexplored. In this work, we address the problem of adapting vision
foundation models to new domains in an unsupervised and data-efficient manner,
specifically targeting downstream semantic segmentation. We propose GLARE
(Global Local and Regional Enforcement), a novel continual self-supervised
pre-training task designed to enhance downstream segmentation performance.
GLARE introduces patch-level augmentations to encourage local consistency and
incorporates a regional consistency constraint that leverages spatial semantics
in the data. For efficient continual pre-training, we initialize Vision
Transformers (ViTs) with weights from existing SSL models and update only
lightweight adapter modules - specifically UniAdapter - while keeping the rest
of the backbone frozen. Experiments across multiple semantic segmentation
benchmarks on different domains demonstrate that GLARE consistently improves
downstream performance with minimal computational and parameter overhead.

</details>


### [197] [ContextFlow: Training-Free Video Object Editing via Adaptive Context Enrichment](https://arxiv.org/abs/2509.17818)
*Yiyang Chen,Xuanhua He,Xiujun Ma,Yue Ma*

Main category: cs.CV

TL;DR: ContextFlow是一种免训练的视频对象编辑框架，通过高阶求解器和动态上下文融合机制，显著提升了编辑效果，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频对象编辑在保持保真度和时间一致性方面面临重大挑战，现有方法因一阶求解器和不恰当的硬特征替换而效果不佳，尤其是在Diffusion Transformers（DiTs）中。

Method: ContextFlow采用高阶Rectified Flow求解器建立稳健的编辑基础，并通过Adaptive Context Enrichment机制动态融合信息，避免上下文冲突。此外，通过Guidance Responsiveness Metric识别任务关键层，实现有针对性的高效指导。

Result: 实验表明，ContextFlow在视频对象编辑任务中表现优异，实现了时间一致且高保真的结果。

Conclusion: ContextFlow框架显著优于现有的免训练方法，甚至超越了一些基于训练的最先进方法，提供了时间一致且高保真的视频对象编辑结果。

Abstract: Training-free video object editing aims to achieve precise object-level
manipulation, including object insertion, swapping, and deletion. However, it
faces significant challenges in maintaining fidelity and temporal consistency.
Existing methods, often designed for U-Net architectures, suffer from two
primary limitations: inaccurate inversion due to first-order solvers, and
contextual conflicts caused by crude "hard" feature replacement. These issues
are more challenging in Diffusion Transformers (DiTs), where the unsuitability
of prior layer-selection heuristics makes effective guidance challenging. To
address these limitations, we introduce ContextFlow, a novel training-free
framework for DiT-based video object editing. In detail, we first employ a
high-order Rectified Flow solver to establish a robust editing foundation. The
core of our framework is Adaptive Context Enrichment (for specifying what to
edit), a mechanism that addresses contextual conflicts. Instead of replacing
features, it enriches the self-attention context by concatenating Key-Value
pairs from parallel reconstruction and editing paths, empowering the model to
dynamically fuse information. Additionally, to determine where to apply this
enrichment (for specifying where to edit), we propose a systematic, data-driven
analysis to identify task-specific vital layers. Based on a novel Guidance
Responsiveness Metric, our method pinpoints the most influential DiT blocks for
different tasks (e.g., insertion, swapping), enabling targeted and highly
effective guidance. Extensive experiments show that ContextFlow significantly
outperforms existing training-free methods and even surpasses several
state-of-the-art training-based approaches, delivering temporally coherent,
high-fidelity results.

</details>


### [198] [Semantic and Visual Crop-Guided Diffusion Models for Heterogeneous Tissue Synthesis in Histopathology](https://arxiv.org/abs/2509.17847)
*Saghir Alfasly,Wataru Uegami,MD Enamul Hoq,Ghazal Alabtah,H. R. Tizhoosh*

Main category: cs.CV

TL;DR: 提出一种双条件潜在扩散模型，生成高保真组织病理学图像，解决了组织异质性和形态细节问题，并在下游任务中表现接近真实数据。


<details>
  <summary>Details</summary>
Motivation: 解决组织病理学合成数据生成中的组织异质性保持、形态细节捕捉及无标注数据扩展问题。

Method: 采用潜在扩散模型结合双条件方法（语义分割图和特定组织视觉裁剪），并在无标注数据上通过自监督扩展生成伪语义图进行训练。

Result: 在Camelyon16、Panda和TCGA数据集上，合成数据显著降低了Frechet距离（最高6倍），并在下游分割任务中达到接近真实数据的性能（IoU差距1-2%）。

Conclusion: 该论文提出了一种通过新型双条件潜在扩散模型生成高保真组织病理学图像的方法，有效解决了组织异质性保持和形态细节捕捉的挑战，并在下游分割任务中表现出与真实数据相当的竞争力。

Abstract: Synthetic data generation in histopathology faces unique challenges:
preserving tissue heterogeneity, capturing subtle morphological features, and
scaling to unannotated datasets. We present a latent diffusion model that
generates realistic heterogeneous histopathology images through a novel
dual-conditioning approach combining semantic segmentation maps with
tissue-specific visual crops. Unlike existing methods that rely on text prompts
or abstract visual embeddings, our approach preserves critical morphological
details by directly incorporating raw tissue crops from corresponding semantic
regions. For annotated datasets (i.e., Camelyon16, Panda), we extract patches
ensuring 20-80% tissue heterogeneity. For unannotated data (i.e., TCGA), we
introduce a self-supervised extension that clusters whole-slide images into 100
tissue types using foundation model embeddings, automatically generating
pseudo-semantic maps for training. Our method synthesizes high-fidelity images
with precise region-wise annotations, achieving superior performance on
downstream segmentation tasks. When evaluated on annotated datasets, models
trained on our synthetic data show competitive performance to those trained on
real data, demonstrating the utility of controlled heterogeneous tissue
generation. In quantitative evaluation, prompt-guided synthesis reduces Frechet
Distance by up to 6X on Camelyon16 (from 430.1 to 72.0) and yields 2-3x lower
FD across Panda and TCGA. Downstream DeepLabv3+ models trained solely on
synthetic data attain test IoU of 0.71 and 0.95 on Camelyon16 and Panda, within
1-2% of real-data baselines (0.72 and 0.96). By scaling to 11,765 TCGA
whole-slide images without manual annotations, our framework offers a practical
solution for an urgent need for generating diverse, annotated histopathology
data, addressing a critical bottleneck in computational pathology.

</details>


### [199] [ProDyG: Progressive Dynamic Scene Reconstruction via Gaussian Splatting from Monocular Videos](https://arxiv.org/abs/2509.17864)
*Shi Chen,Erik Sandström,Sandro Lombardi,Siyuan Li,Martin R. Oswald*

Main category: cs.CV

TL;DR: 提出一种在线动态3D重建方法，通过解耦静态与动态部分，结合运动掩蔽和渐进式运动支架图，实现了与离线方法相当的渲染效果和动态SLAM的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 实现真正实用的动态3D重建需要在线操作、全局姿态与地图一致性、详细的表观建模，以及处理RGB和RGB-D输入的灵活性。现有方法存在动态部分移除、依赖RGB-D输入、离线方法不可扩展或缺乏全局一致性和表观细节等问题。

Method: 通过解耦SLAM系统中的静态和动态部分，采用新颖的运动掩蔽策略进行鲁棒的姿态跟踪，并利用渐进式运动支架图适应来重建动态部分。

Result: 该方法在动态场景重建中表现出色，能够在线运行并保持全局一致性，同时提供详细的表观建模。

Conclusion: 我们的方法实现了与离线方法相媲美的新视角渲染效果，并在动态SLAM方法的跟踪性能上达到了与最先进技术相当的水平。

Abstract: Achieving truly practical dynamic 3D reconstruction requires online
operation, global pose and map consistency, detailed appearance modeling, and
the flexibility to handle both RGB and RGB-D inputs. However, existing SLAM
methods typically merely remove the dynamic parts or require RGB-D input, while
offline methods are not scalable to long video sequences, and current
transformer-based feedforward methods lack global consistency and appearance
details. To this end, we achieve online dynamic scene reconstruction by
disentangling the static and dynamic parts within a SLAM system. The poses are
tracked robustly with a novel motion masking strategy, and dynamic parts are
reconstructed leveraging a progressive adaptation of a Motion Scaffolds graph.
Our method yields novel view renderings competitive to offline methods and
achieves on-par tracking with state-of-the-art dynamic SLAM methods.

</details>


### [200] [Does Audio Matter for Modern Video-LLMs and Their Benchmarks?](https://arxiv.org/abs/2509.17901)
*Geewook Kim,Minjoon Seo*

Main category: cs.CV

TL;DR: 论文发现当前Video-LLMs在多数视频基准测试中音频作用有限，但特定任务中至关重要。作者提出改进方法并开源工具，以缩小学术与现实的差距。


<details>
  <summary>Details</summary>
Motivation: 评估当代Video-LLMs中音频的实际重要性，并揭示现有基准测试中音频的冗余性。

Method: 基于LLaVA-OneVision架构，作者增加了语音/音频编码器（如Whisper），并采用轻量级Mamba状态空间标记压缩器处理音频标记爆炸问题。

Result: 音频在当前视频基准测试中提升有限，但在精心设计的音频敏感子集上表现关键。

Conclusion: 研究表明，当前视频大语言模型（Video-LLMs）在多数视频基准测试中音频作用有限，但在特定音频敏感任务中至关重要。作者通过开源工具和数据集（如AVQA-Hard和Music-AVQA-Hard）为音频-视觉模型提供了实用工具，并指出了学术实践与现实需求之间的差距。

Abstract: Modern multimodal large language models often claim "video understanding,"
yet most evaluations use muted videos or simply discard audio. We ask a direct
question: how much does audio actually matter for contemporary Video-LLMs and
the benchmarks that certify them? We audit widely used suites and observe that
many items are even solvable from a single frame, rendering audio largely
redundant. Building on LLaVA-OneVision architecture, we attach a speech/audio
encoder (e.g., Whisper) and analyze when audio helps, while addressing audio
token explosion with a lightweight Mamba-based state-space token compressor. We
find that audio yields minimal gains on recent video benchmarks but is decisive
on curated, audio-sensitive subsets. To enable faithful evaluation, we release
AVQA-Hard and Music-AVQA-Hard, our model, and code. Our findings surface a
growing gap between current academic practice and real-world expectations, and
provide practical tools for scalable audio-visual Video-LLMs. We will fully
open-source our work at https://github.com/naver-ai/LLaVA-AV-SSM.

</details>


### [201] [SmaRT: Style-Modulated Robust Test-Time Adaptation for Cross-Domain Brain Tumor Segmentation in MRI](https://arxiv.org/abs/2509.17925)
*Yuanhan Wang,Yifei Chen,Shuo Jiang,Wenjing Yu,Mingxuan Liu,Beining Wu,Jinying Zong,Feiwei Qin,Changmiao Wang,Qiyuan Tian*

Main category: cs.CV

TL;DR: SmaRT是一个风格调制的测试时适应框架，通过风格感知增强和结构先验提升MRI脑肿瘤分割在域偏移下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在域偏移（如扫描器和协议变异性及人群异质性）下表现不佳，尤其在低资源和儿科队列中，传统测试时或源自由适应策略常不稳定且结构不一致。

Method: SmaRT集成了风格感知增强、双分支动量策略和结构先验，以缓解外观差异、稳定伪标签细化并确保结构一致性。

Result: 在撒哈拉以南非洲和儿科胶质瘤数据集上的广泛评估表明，SmaRT在Dice准确率和边界精度上显著优于现有方法。

Conclusion: SmaRT框架通过风格调制和结构先验，显著提升了MRI脑肿瘤分割在极端域偏移下的稳定性和解剖保真度，为不同临床环境中的公平应用提供了支持。

Abstract: Reliable brain tumor segmentation in MRI is indispensable for treatment
planning and outcome monitoring, yet models trained on curated benchmarks often
fail under domain shifts arising from scanner and protocol variability as well
as population heterogeneity. Such gaps are especially severe in low-resource
and pediatric cohorts, where conventional test-time or source-free adaptation
strategies often suffer from instability and structural inconsistency. We
propose SmaRT, a style-modulated robust test-time adaptation framework that
enables source-free cross-domain generalization. SmaRT integrates style-aware
augmentation to mitigate appearance discrepancies, a dual-branch momentum
strategy for stable pseudo-label refinement, and structural priors enforcing
consistency, integrity, and connectivity. This synergy ensures both adaptation
stability and anatomical fidelity under extreme domain shifts. Extensive
evaluations on sub-Saharan Africa and pediatric glioma datasets show that SmaRT
consistently outperforms state-of-the-art methods, with notable gains in Dice
accuracy and boundary precision. Overall, SmaRT bridges the gap between
algorithmic advances and equitable clinical applicability, supporting robust
deployment of MRI-based neuro-oncology tools in diverse clinical environments.
Our source code is available at https://github.com/baiyou1234/SmaRT.

</details>


### [202] [Multi-needle Localization for Pelvic Seed Implant Brachytherapy based on Tip-handle Detection and Matching](https://arxiv.org/abs/2509.17931)
*Zhuo Xiao,Fugen Zhou,Jingjing Wang,Chongyu He,Bo Liu,Haitao Sun,Zhe Ji,Yuliang Jiang,Junjie Wang,Qiuwen Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于HRNet的无锚点网络和GMM方法，显著提高了骨盆种子植入术中多针定位的精度，优于传统分割方法。


<details>
  <summary>Details</summary>
Motivation: 由于图像对比度低和针粘连问题，术中CT图像中的多针定位在骨盆种子植入近距离放射治疗中具有挑战性，需要一种更准确和鲁棒的解决方案。

Method: 提出了一种基于HRNet的无锚点网络，通过解耦的热图回归和极角预测分支检测针尖和手柄中心及方向，并设计了贪婪匹配合并（GMM）方法解决不平衡分配问题，以重建3D针路径。

Result: 在100名患者的数据集上评估，该方法表现出更高的精度和F1分数，优于基于nnUNet的分割方法。

Conclusion: 本文提出的基于HRNet的无锚点网络和贪婪匹配合并（GMM）方法在骨盆种子植入近距离放射治疗中，显著提高了多针定位的精度和鲁棒性，优于基于分割的nnUNet模型。

Abstract: Accurate multi-needle localization in intraoperative CT images is crucial for
optimizing seed placement in pelvic seed implant brachytherapy. However, this
task is challenging due to poor image contrast and needle adhesion. This paper
presents a novel approach that reframes needle localization as a tip-handle
detection and matching problem to overcome these difficulties. An anchor-free
network, based on HRNet, is proposed to extract multi-scale features and
accurately detect needle tips and handles by predicting their centers and
orientations using decoupled branches for heatmap regression and polar angle
prediction. To associate detected tips and handles into individual needles, a
greedy matching and merging (GMM) method designed to solve the unbalanced
assignment problem with constraints (UAP-C) is presented. The GMM method
iteratively selects the most probable tip-handle pairs and merges them based on
a distance metric to reconstruct 3D needle paths. Evaluated on a dataset of 100
patients, the proposed method demonstrates superior performance, achieving
higher precision and F1 score compared to a segmentation-based method utilizing
the nnUNet model,thereby offering a more robust and accurate solution for
needle localization in complex clinical scenarios.

</details>


### [203] [Can multimodal representation learning by alignment preserve modality-specific information?](https://arxiv.org/abs/2509.17943)
*Romain Thoreau,Jessie Levillain,Dawa Derksen*

Main category: cs.CV

TL;DR: 本文探讨了多模态卫星数据对比学习中信息保留的问题，通过理论和实验验证了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 多模态数据融合在遥感等任务中至关重要，但现有方法可能在信息保留方面存在不足。

Method: 采用理论分析和数值实验相结合的方法，验证了多模态对齐策略可能导致信息丢失的假设。

Result: 理论和实验均表明，多模态对齐策略可能导致任务相关信息丢失。

Conclusion: 本文通过理论和实验证据，探讨了多模态卫星数据对比学习中信息保留的问题，为未来研究提供了新的方向。

Abstract: Combining multimodal data is a key issue in a wide range of machine learning
tasks, including many remote sensing problems. In Earth observation, early
multimodal data fusion methods were based on specific neural network
architectures and supervised learning. Ever since, the scarcity of labeled data
has motivated self-supervised learning techniques. State-of-the-art multimodal
representation learning techniques leverage the spatial alignment between
satellite data from different modalities acquired over the same geographic area
in order to foster a semantic alignment in the latent space. In this paper, we
investigate how this methods can preserve task-relevant information that is not
shared across modalities. First, we show, under simplifying assumptions, when
alignment strategies fundamentally lead to an information loss. Then, we
support our theoretical insight through numerical experiments in more realistic
settings. With those theoretical and empirical evidences, we hope to support
new developments in contrastive learning for the combination of multimodal
satellite data. Our code and data is publicly available at
https://github.com/Romain3Ch216/alg_maclean_25.

</details>


### [204] [DragOSM: Extract Building Roofs and Footprints from Aerial Images by Aligning Historical Labels](https://arxiv.org/abs/2509.17951)
*Kai Li,Xingxing Weng,Yupeng Deng,Yu Meng,Chao Pang,Gui-Song Xia,Xiangyu Zhao*

Main category: cs.CV

TL;DR: DragOSM通过对齐标记和迭代去噪解决历史标签与新图像的位置偏差，提升屋顶与足迹提取精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在倾斜图像中因屋顶与足迹位移及立面像素干扰而表现不佳，且历史标签存在位置偏差和单一标注问题。

Method: 提出DragOSM模型，将标签对齐建模为交互式去噪过程，模拟高斯扰动以学习校正误差，并在推理阶段迭代优化标签位置。

Result: 在ReBO数据集上的实验证明DragOSM的有效性。

Conclusion: DragOSM模型通过引入对齐标记和迭代去噪过程，有效解决了历史标签与新遥感图像之间的位置差异问题，显著提高了屋顶和足迹的提取精度。

Abstract: Extracting polygonal roofs and footprints from remote sensing images is
critical for large-scale urban analysis. Most existing methods rely on
segmentation-based models that assume clear semantic boundaries of roofs, but
these approaches struggle in off- nadir images, where the roof and footprint
are significantly displaced, and facade pixels are fused with the roof
boundary. With the increasing availability of open vector map annotations,
e.g., OpenStreetMap, utilizing historical labels for off-nadir image annotation
has become viable because remote sensing images are georeferenced once
captured. However, these historical labels commonly suffer from significant
positional discrepancies with new images and only have one annotation (roof or
footprint), which fails to describe the correct structures of a building. To
address these discrepancies, we first introduce a concept of an alignment
token, which encodes the correction vector to guide the label correction. Based
on this concept, we then propose Drag OpenStreetMap Labels (DragOSM), a novel
model designed to align dislocated historical labels with roofs and footprints.
Specifically, DragOSM formulates the label alignment as an interactive
denoising process, modeling the positional discrepancy as a Gaussian
distribution. During training, it learns to correct these errors by simulating
misalignment with random Gaussian perturbations; during inference, it
iteratively refines the positions of input labels. To validate our method, we
further present a new dataset, Repairing Buildings in OSM (ReBO), comprising
179,265 buildings with both OpenStreetMap and manually corrected annotations
across 5,473 images from 41 cities. Experimental results on ReBO demonstrate
the effectiveness of DragOSM. Code, dataset, and trained models are publicly
available at https://github.com/likaiucas/DragOSM.git.

</details>


### [205] [Breaking the Discretization Barrier of Continuous Physics Simulation Learning](https://arxiv.org/abs/2509.17955)
*Fan Xu,Hao Wu,Nan Wang,Lilan Peng,Kun Wang,Wei Gong,Xibin Zhao*

Main category: cs.CV

TL;DR: CoPS是一种纯数据驱动方法，通过创新技术（如多尺度图ODE和马尔可夫神经自校正）从部分观测中建模连续物理动态，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有数据驱动方法受限于固定的时空离散化，难以捕捉高度非线性特征。CoPS旨在克服这一限制，从部分观测中有效建模连续物理模拟。

Method: 该方法结合了乘法滤波器网络融合空间信息、定制几何网格与消息传递机制映射特征，以及多尺度图ODE建模连续时间动态，并引入马尔可夫神经自校正模块辅助约束连续外推。

Result: 综合实验表明，CoPS在多种场景下的时空连续建模中优于现有最先进方法。

Conclusion: CoPS作为一种纯数据驱动的方法，通过创新的多尺度图ODE和马尔可夫神经自校正模块，显著提升了时空连续建模的性能，并在多种场景中超越了现有最先进方法。

Abstract: The modeling of complicated time-evolving physical dynamics from partial
observations is a long-standing challenge. Particularly, observations can be
sparsely distributed in a seemingly random or unstructured manner, making it
difficult to capture highly nonlinear features in a variety of scientific and
engineering problems. However, existing data-driven approaches are often
constrained by fixed spatial and temporal discretization. While some
researchers attempt to achieve spatio-temporal continuity by designing novel
strategies, they either overly rely on traditional numerical methods or fail to
truly overcome the limitations imposed by discretization. To address these, we
propose CoPS, a purely data-driven methods, to effectively model continuous
physics simulation from partial observations. Specifically, we employ
multiplicative filter network to fuse and encode spatial information with the
corresponding observations. Then we customize geometric grids and use
message-passing mechanism to map features from original spatial domain to the
customized grids. Subsequently, CoPS models continuous-time dynamics by
designing multi-scale graph ODEs, while introducing a Markov-based neural
auto-correction module to assist and constrain the continuous extrapolations.
Comprehensive experiments demonstrate that CoPS advances the state-of-the-art
methods in space-time continuous modeling across various scenarios.

</details>


### [206] [Visual Detector Compression via Location-Aware Discriminant Analysis](https://arxiv.org/abs/2509.17968)
*Qizhen Lan,Jung Im Choi,Qing Tian*

Main category: cs.CV

TL;DR: 提出一种主动压缩方法，利用检测判别信息和定位信息压缩视觉检测器，实验显示压缩模型在降低复杂度的同时性能超越原始模型。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在资源受限的边缘设备上部署受限，现有剪枝方法主要关注分类模型，对检测任务关注不足，且缺乏对定位信息的利用。

Method: 提出了一种主动检测判别网络压缩方法，交替进行两个步骤：(1) 最大化并压缩检测相关判别信息，并将其与检测头前的神经元/滤波器子集对齐；(2) 追踪检测相关判别能力跨层，并丢弃重要性较低的特征。

Result: 在KITTI和COCO数据集上，使用四种先进检测模型和四种竞争方法的实验证明了该方法的优越性。

Conclusion: 通过提出的主动检测判别网络压缩方法，压缩后的模型在显著降低复杂度的同时，性能甚至超过了原始模型。

Abstract: Deep neural networks are powerful, yet their high complexity greatly limits
their potential to be deployed on billions of resource-constrained edge
devices. Pruning is a crucial network compression technique, yet most existing
methods focus on classification models, with limited attention to detection.
Even among those addressing detection, there is a lack of utilization of
essential localization information. Also, many pruning methods passively rely
on pre-trained models, in which useful and useless components are intertwined,
making it difficult to remove the latter without harming the former at the
neuron/filter level. To address the above issues, in this paper, we propose a
proactive detection-discriminants-based network compression approach for deep
visual detectors, which alternates between two steps: (1) maximizing and
compressing detection-related discriminants and aligning them with a subset of
neurons/filters immediately before the detection head, and (2) tracing the
detection-related discriminating power across the layers and discarding
features of lower importance. Object location information is exploited in both
steps. Extensive experiments, employing four advanced detection models and four
state-of-the-art competing methods on the KITTI and COCO datasets, highlight
the superiority of our approach. Remarkably, our compressed models can even
beat the original base models with a substantial reduction in complexity.

</details>


### [207] [StableGuard: Towards Unified Copyright Protection and Tamper Localization in Latent Diffusion Models](https://arxiv.org/abs/2509.17993)
*Haoxin Yang,Bangzhen Liu,Xuemiao Xu,Cheng Xu,Yuyang Yu,Zikai Huang,Yi Wang,Shengfeng He*

Main category: cs.CV

TL;DR: StableGuard是一种新型框架，通过端到端设计集成水印到扩散模型，优化版权保护和篡改定位，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的进步提升了AI生成内容的真实性，但也引发了滥用担忧，需要强健的版权保护和篡改定位解决方案。

Method: 提出StableGuard框架，通过集成二进制水印到扩散生成过程中，利用MPW-VAE和MoE-GFN进行端到端设计。

Result: StableGuard在实验中表现出色，优于现有方法。

Conclusion: StableGuard框架在图像保真度、水印验证和篡改定位方面一致优于现有最先进方法。

Abstract: The advancement of diffusion models has enhanced the realism of AI-generated
content but also raised concerns about misuse, necessitating robust copyright
protection and tampering localization. Although recent methods have made
progress toward unified solutions, their reliance on post hoc processing
introduces considerable application inconvenience and compromises forensic
reliability. We propose StableGuard, a novel framework that seamlessly
integrates a binary watermark into the diffusion generation process, ensuring
copyright protection and tampering localization in Latent Diffusion Models
through an end-to-end design. We develop a Multiplexing Watermark VAE (MPW-VAE)
by equipping a pretrained Variational Autoencoder (VAE) with a lightweight
latent residual-based adapter, enabling the generation of paired watermarked
and watermark-free images. These pairs, fused via random masks, create a
diverse dataset for training a tampering-agnostic forensic network. To further
enhance forensic synergy, we introduce a Mixture-of-Experts Guided Forensic
Network (MoE-GFN) that dynamically integrates holistic watermark patterns,
local tampering traces, and frequency-domain cues for precise watermark
verification and tampered region detection. The MPW-VAE and MoE-GFN are jointly
optimized in a self-supervised, end-to-end manner, fostering a reciprocal
training between watermark embedding and forensic accuracy. Extensive
experiments demonstrate that StableGuard consistently outperforms
state-of-the-art methods in image fidelity, watermark verification, and
tampering localization.

</details>


### [208] [NeuS-QA: Grounding Long-Form Video Understanding in Temporal Logic and Neuro-Symbolic Reasoning](https://arxiv.org/abs/2509.18041)
*Sahil Shah,S P Sharan,Harsh Goel,Minkyu Choi,Mustafa Munir,Manvik Pasula,Radu Marculescu,Sandeep Chinchali*

Main category: cs.CV

TL;DR: NeuS-QA 是一种免训练的神经符号方法，通过将问题转换为时间逻辑表达式并验证视频片段，显著提升了长视频问答的性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在处理长视频问答（LVQA）时存在局限性，无法有效处理复杂查询中的多步时间推理和因果关系，且缺乏明确的时间表示和逻辑事件关系验证。

Method: NeuS-QA 是一种免训练的即插即用神经符号管道，将自然语言问题转换为形式化的时间逻辑表达式，构建视频自动机，并应用模型检查来严格识别满足问题逻辑要求的视频片段。

Result: 在 LongVideoBench 和 CinePile 上的实验表明，NeuS-QA 在性能上提升了超过10%，尤其在涉及事件顺序、因果关系和多步组合推理的问题上表现突出。

Conclusion: NeuS-QA 通过引入神经符号方法，显著提升了长视频问答（LVQA）的性能，特别是在涉及事件顺序、因果关系和多步组合推理的问题上，性能提升超过10%。

Abstract: Long-Form Video Question Answering (LVQA) poses challenges beyond traditional
visual question answering (VQA), which is often limited to static images or
short video clips. While current vision-language models (VLMs) perform well in
those settings, they struggle with complex queries in LVQA over long videos
involving multi-step temporal reasoning and causality. Vanilla approaches,
which sample frames uniformly and feed them to a VLM with the question, incur
significant token overhead, forcing severe downsampling. As a result, the model
often misses fine-grained visual structure, subtle event transitions, or key
temporal cues, ultimately leading to incorrect answers. To address these
limitations, recent works have explored query-adaptive frame sampling,
hierarchical keyframe selection, and agent-based iterative querying. However,
these methods remain fundamentally heuristic: they lack explicit temporal
representations and cannot enforce or verify logical event relationships. As a
result, there are no formal guarantees that the sampled context actually
encodes the compositional or causal logic demanded by the question. To address
these foundational gaps, we introduce NeuS-QA, a training-free, plug-and-play
neuro-symbolic pipeline for LVQA. NeuS-QA translates a natural language
question into a formal temporal logic expression, constructs a video automaton
from frame-level semantic propositions, and applies model checking to
rigorously identify video segments satisfying the question's logical
requirements. Only these logic-verified segments are submitted to the VLM, thus
improving interpretability, reducing hallucinations, and enabling compositional
reasoning without modifying or fine-tuning the model. Experiments on
LongVideoBench and CinePile show NeuS-QA improves performance by over 10%,
especially on questions involving event ordering, causality, and multi-step
compositional reasoning.

</details>


### [209] [TempSamp-R1: Effective Temporal Sampling with Reinforcement Fine-Tuning for Video LLMs](https://arxiv.org/abs/2509.18056)
*Yunheng Li,Jing Cheng,Shaoyong Jia,Hangyi Kuang,Shaohui Jiao,Qibin Hou,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: TempSamp-R1 是一种新型强化微调框架，通过离策略监督和动态奖励调整，显著提升了视频时间定位任务的性能，并在多个数据集上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法（如GRPO）在大型时间搜索空间任务中效率低下且性能有限，无法准确识别时间解决方案。TempSamp-R1 旨在解决这一问题。

Method: TempSamp-R1 利用真实标注作为离策略监督，提供时间精确的指导，并通过非线性软优势计算方法动态调整奖励反馈。此外，采用混合思维链（CoT）训练范式，优化单一统一模型以支持不同推理模式。

Result: TempSamp-R1 在Charades-STA（R1@0.7: 52.9%, +2.7%）、ActivityNet Captions（R1@0.5: 56.0%, +5.3%）和QVHighlights（mAP: 30.0%, +3.0%）等基准数据集上表现优异，并展示了强大的少样本泛化能力。

Conclusion: TempSamp-R1 通过结合离策略监督和非线性软优势计算方法，显著提升了多模态大语言模型在视频时间定位任务中的性能，并在多个基准数据集上实现了最先进的性能。

Abstract: This paper introduces TempSamp-R1, a new reinforcement fine-tuning framework
designed to improve the effectiveness of adapting multimodal large language
models (MLLMs) to video temporal grounding tasks. We reveal that existing
reinforcement learning methods, such as Group Relative Policy Optimization
(GRPO), rely on on-policy sampling for policy updates. However, in tasks with
large temporal search spaces, this strategy becomes both inefficient and
limited in performance, as it often fails to identify temporally accurate
solutions. To address this limitation, TempSamp-R1 leverages ground-truth
annotations as off-policy supervision to provide temporally precise guidance,
effectively compensating for the sparsity and misalignment in on-policy
solutions. To further stabilize training and reduce variance in reward-based
updates, TempSamp-R1 provides a non-linear soft advantage computation method
that dynamically reshapes the reward feedback via an asymmetric transformation.
By employing a hybrid Chain-of-Thought (CoT) training paradigm, TempSamp-R1
optimizes a single unified model to support both CoT and non-CoT inference
modes, enabling efficient handling of queries with varying reasoning
complexity. Experimental results demonstrate that TempSamp-R1 outperforms
GRPO-based baselines, establishing new state-of-the-art performance on
benchmark datasets: Charades-STA (R1@0.7: 52.9%, +2.7%), ActivityNet Captions
(R1@0.5: 56.0%, +5.3%), and QVHighlights (mAP: 30.0%, +3.0%). Moreover,
TempSamp-R1 shows robust few-shot generalization capabilities under limited
data. Code: https://github.com/HVision-NKU/TempSamp-R1

</details>


### [210] [GraDeT-HTR: A Resource-Efficient Bengali Handwritten Text Recognition System utilizing Grapheme-based Tokenizer and Decoder-only Transformer](https://arxiv.org/abs/2509.18081)
*Md. Mahmudul Hasan,Ahmed Nesar Tahsin Choudhury,Mahmudul Hasan,Md. Mosaddek Khan*

Main category: cs.CV

TL;DR: GraDeT-HTR是一种高效的孟加拉语手写文本识别系统，通过Grapheme-aware解码器Transformer架构和合成数据预训练，显著提升了识别准确率。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为全球第六大语言，其手写文本识别系统因复杂的脚本结构和缺乏标注数据而发展不足，亟需高效解决方案。

Method: 采用基于Grapheme的tokenizer增强解码器Transformer架构，利用大规模合成数据预训练并结合真实标注数据微调。

Result: 在多个基准数据集上达到最先进的性能表现。

Conclusion: GraDeT-HTR系统通过结合Grapheme-aware解码器和Transformer架构，显著提升了孟加拉语手写文本识别的准确率，成为该领域的先进解决方案。

Abstract: Despite Bengali being the sixth most spoken language in the world,
handwritten text recognition (HTR) systems for Bengali remain severely
underdeveloped. The complexity of Bengali script--featuring conjuncts,
diacritics, and highly variable handwriting styles--combined with a scarcity of
annotated datasets makes this task particularly challenging. We present
GraDeT-HTR, a resource-efficient Bengali handwritten text recognition system
based on a Grapheme-aware Decoder-only Transformer architecture. To address the
unique challenges of Bengali script, we augment the performance of a
decoder-only transformer by integrating a grapheme-based tokenizer and
demonstrate that it significantly improves recognition accuracy compared to
conventional subword tokenizers. Our model is pretrained on large-scale
synthetic data and fine-tuned on real human-annotated samples, achieving
state-of-the-art performance on multiple benchmark datasets.

</details>


### [211] [GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction](https://arxiv.org/abs/2509.18090)
*Jiahe Li,Jiawei Zhang,Youmin Zhang,Xiao Bai,Jin Zheng,Xiaohan Yu,Lin Gu*

Main category: cs.CV

TL;DR: GeoSVR是一种基于稀疏体素的表面重建框架，通过两项新技术在几何精度和完整性上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于Gaussian Splatting的方法存在表示瓶颈，稀疏体素潜力未被充分探索，需要一种新框架以实现精确、详细和完整的表面重建。

Method: 提出GeoSVR框架，包括Voxel-Uncertainty Depth Constraint和Sparse Voxel Surface Regularization，利用稀疏体素实现表面重建。

Result: 实验表明GeoSVR在几何精度、细节保留和重建完整性方面优于现有方法，同时保持高效。

Conclusion: GeoSVR通过引入稀疏体素框架，结合Voxel-Uncertainty Depth Constraint和Sparse Voxel Surface Regularization，在几何精度、细节保留和重建完整性方面优于现有方法。

Abstract: Reconstructing accurate surfaces with radiance fields has achieved remarkable
progress in recent years. However, prevailing approaches, primarily based on
Gaussian Splatting, are increasingly constrained by representational
bottlenecks. In this paper, we introduce GeoSVR, an explicit voxel-based
framework that explores and extends the under-investigated potential of sparse
voxels for achieving accurate, detailed, and complete surface reconstruction.
As strengths, sparse voxels support preserving the coverage completeness and
geometric clarity, while corresponding challenges also arise from absent scene
constraints and locality in surface refinement. To ensure correct scene
convergence, we first propose a Voxel-Uncertainty Depth Constraint that
maximizes the effect of monocular depth cues while presenting a voxel-oriented
uncertainty to avoid quality degradation, enabling effective and robust scene
constraints yet preserving highly accurate geometries. Subsequently, Sparse
Voxel Surface Regularization is designed to enhance geometric consistency for
tiny voxels and facilitate the voxel-based formation of sharp and accurate
surfaces. Extensive experiments demonstrate our superior performance compared
to existing methods across diverse challenging scenarios, excelling in
geometric accuracy, detail preservation, and reconstruction completeness while
maintaining high efficiency. Code is available at
https://github.com/Fictionarry/GeoSVR.

</details>


### [212] [ComposeMe: Attribute-Specific Image Prompts for Controllable Human Image Generation](https://arxiv.org/abs/2509.18092)
*Guocheng Gordon Qian,Daniil Ostashev,Egor Nemchinov,Avihay Assouline,Sergey Tulyakov,Kuan-Chieh Jackson Wang,Kfir Aberman*

Main category: cs.CV

TL;DR: 提出了一种新的属性特定图像提示方法，通过编码和注入属性特定标记到扩散模型中，实现了对多个视觉因素的解耦控制，达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 在个性化文本到图像合成中，生成具有对发型和服装等属性的细粒度控制的高保真人类图像仍然是一个核心挑战。现有方法缺乏模块化，无法提供对特定视觉属性的解耦控制。

Method: 我们引入了一种新的属性特定图像提示范式，将不同的参考图像集用于指导人类外观的各个方面的生成，如头发、服装和身份。这些输入被编码为属性特定的标记，并注入到预训练的文本到图像扩散模型中。

Result: 广泛的实验表明，我们的方法在准确遵循视觉和文本提示方面达到了最先进的性能。

Conclusion: 该框架通过将视觉提示与文本驱动生成相结合，为更可配置的人类图像合成铺平了道路。

Abstract: Generating high-fidelity images of humans with fine-grained control over
attributes such as hairstyle and clothing remains a core challenge in
personalized text-to-image synthesis. While prior methods emphasize identity
preservation from a reference image, they lack modularity and fail to provide
disentangled control over specific visual attributes. We introduce a new
paradigm for attribute-specific image prompting, in which distinct sets of
reference images are used to guide the generation of individual aspects of
human appearance, such as hair, clothing, and identity. Our method encodes
these inputs into attribute-specific tokens, which are injected into a
pre-trained text-to-image diffusion model. This enables compositional and
disentangled control over multiple visual factors, even across multiple people
within a single image. To promote natural composition and robust
disentanglement, we curate a cross-reference training dataset featuring
subjects in diverse poses and expressions, and propose a multi-attribute
cross-reference training strategy that encourages the model to generate
faithful outputs from misaligned attribute inputs while adhering to both
identity and textual conditioning. Extensive experiments show that our method
achieves state-of-the-art performance in accurately following both visual and
textual prompts. Our framework paves the way for more configurable human image
synthesis by combining visual prompting with text-driven generation. Webpage is
available at: https://snap-research.github.io/composeme/.

</details>


### [213] [Seg4Diff: Unveiling Open-Vocabulary Segmentation in Text-to-Image Diffusion Transformers](https://arxiv.org/abs/2509.18096)
*Chaehyun Kim,Heeseong Shin,Eunbeen Hong,Heeji Yoon,Anurag Arnab,Paul Hongsuck Seo,Sunghwan Hong,Seungryong Kim*

Main category: cs.CV

TL;DR: Seg4Diff框架分析MM-DiT注意力结构，发现语义接地专家层，通过微调提升分割与生成性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态扩散变换器通过联合自注意力实现了更丰富的跨模态对齐，但对其注意力机制在图像生成中的具体作用仍缺乏深入理解。

Method: 引入Seg4Diff框架，系统分析MM-DiT的注意力结构，识别出语义接地专家层，并通过轻量级微调方案增强其语义分组能力。

Result: 识别出语义接地专家层，该层能自然生成高质量语义分割掩码，并通过微调进一步提升了分割性能和生成图像保真度。

Conclusion: 研究发现语义分组是扩散变换器的涌现特性，可以通过选择性增强来提升分割和生成性能，为连接视觉感知与生成的统一模型铺平了道路。

Abstract: Text-to-image diffusion models excel at translating language prompts into
photorealistic images by implicitly grounding textual concepts through their
cross-modal attention mechanisms. Recent multi-modal diffusion transformers
extend this by introducing joint self-attention over concatenated image and
text tokens, enabling richer and more scalable cross-modal alignment. However,
a detailed understanding of how and where these attention maps contribute to
image generation remains limited. In this paper, we introduce Seg4Diff
(Segmentation for Diffusion), a systematic framework for analyzing the
attention structures of MM-DiT, with a focus on how specific layers propagate
semantic information from text to image. Through comprehensive analysis, we
identify a semantic grounding expert layer, a specific MM-DiT block that
consistently aligns text tokens with spatially coherent image regions,
naturally producing high-quality semantic segmentation masks. We further
demonstrate that applying a lightweight fine-tuning scheme with mask-annotated
image data enhances the semantic grouping capabilities of these layers and
thereby improves both segmentation performance and generated image fidelity.
Our findings demonstrate that semantic grouping is an emergent property of
diffusion transformers and can be selectively amplified to advance both
segmentation and generation performance, paving the way for unified models that
bridge visual perception and generation.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [214] [Spatial Encoding of Flow Spaces for Intelligent SDN Applications](https://arxiv.org/abs/2509.16485)
*Abdur Rouf,Murat Yuksel*

Main category: cs.NI

TL;DR: 提出基于Bloom Filter的空间感知流编码方法，实验证明其在SDN转发中能有效降低缺失率，适用于低延迟应用。


<details>
  <summary>Details</summary>
Motivation: 智能SDN应用（尤其是采用强化学习方法的）需要高效编码网络流空间并保持空间局部性。

Method: 采用基于Bloom Filter的空间感知方法编码IP流对，并集成到DQN驱动的SDN转发策略中进行实验验证。

Result: 实验表明，该方法在10小时流量数据中比LRU和LFU分别降低了7%和8%的归一化缺失率。

Conclusion: 通过实验验证，基于Bloom Filter的空间感知流表示方法在SDN转发策略中有效降低了缺失率，为基于RL的SDN应用开辟了新研究方向。

Abstract: Efficient encoding of network flow spaces while preserving spatial locality
is essential for intelligent Software-Defined Networking (SDN) applications,
particularly those employing reinforcement learning (RL) methods in a reactive
manner. In this work, we introduce a spatially aware Bloom Filter-based
approach to encode IP flow pairs, leveraging their inherent geographical
locality. Through controlled experiments using IoT traffic data, we demonstrate
that Bloom Filters effectively preserve spatial relationships among flows. Our
findings show that Bloom Filters degrade gracefully, maintaining predictable
spatial correlations critical for RL state representation. We integrate this
encoding into a DQN-based eviction strategy for reactive SDN forwarding.
Experiments show that Bloom Filter-encoded, spatially aware flow representation
enables up to 7% and 8% reduction in normalized miss rate over LRU and LFU,
respectively, across 10 hours of traffic, demonstrating potential for
low-latency applications. This experiment justifies the usefulness of
preserving spatial correlation by encoding the flow space into a manageable
size, opening a novel research direction for RL-based SDN applications.

</details>


### [215] [Kalman Filtering-Assisted Node Deployment for Distributed OTFS-ISAC: A Geometry-Aware Design for the Joint Sensing and Communication](https://arxiv.org/abs/2509.16700)
*Jyotsna Rani,Kuntal Deka,Ganesh Prasad,Zilong Liu*

Main category: cs.NI

TL;DR: 该研究将OTFS扩展至分布式ISAC，提出基于三角测量的节点部署框架和卡尔曼滤波增强跟踪，显著提升动态环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 分布式ISAC通过协作节点提高可靠性，但传统OFDM设计易受多普勒频移和多径衰落影响。OTFS调制因其延迟-多普勒域表示在通信和感知中表现出鲁棒性，因此扩展OTFS至分布式ISAC并探索空间节点部署问题。

Method: 提出了基于三角测量的框架，利用空间多样性改善目标定位、速度估计和通信速率；集成了卡尔曼滤波增强移动目标跟踪；设计了主动感知、被动感知和联合感知-通信的新算法。

Result: 数值评估显示定位误差和误码率显著降低，同时捕捉了感知精度与通信可靠性之间的权衡。

Conclusion: 集成卡尔曼滤波的分布式OTFS-ISAC节点部署策略显著提升了动态无线环境中的定位精度和通信可靠性，展示了在高移动性场景下的高性能潜力。

Abstract: Integrated sensing and communication (ISAC) is a key enabler for
next-generation wireless networks, offering spectrum efficiency and reduced
hardware complexity. While monostatic ISAC has been well studied, its limited
spatial diversity reduces reliability in high-mobility scenarios. Distributed
ISAC alleviates this via cooperative nodes, but conventional OFDM-based designs
remain vulnerable to Doppler shifts and multipath fading. Orthogonal time
frequency space (OTFS) modulation has recently emerged as a resilient
alternative, as its delay-Doppler domain representation enables robust
communication and high-resolution sensing. Motivated by this, we extend OTFS to
distributed ISAC and address the underexplored problem of spatial node
deployment. We propose a triangulation-based framework that leverages spatial
diversity to improve target localization, velocity estimation, and
communication rates, and analytically characterize the role of deployment
geometry in minimizing estimation error. Furthermore, we integrate Kalman
filtering (KF) into distributed OTFS-ISAC to enhance tracking of moving
targets, and design novel algorithms for active sensing, passive sensing, and
joint sensing-communication. Closed-form expressions are derived for
localization error under general topologies, and a near-optimal deployment
strategy is identified by aligning receivers along orthogonal axes. Numerical
evaluations show significant reductions in localization error and bit error
rate (BER), while capturing the trade-offs between sensing accuracy and
communication reliability. These results highlight the potential of KF-assisted
node placement in distributed OTFS-ISAC for reliable, high-performance
operation in dynamic wireless environments.

</details>


### [216] [BeNNS: A Surrogate Model for Hybrid Online-Offline Evolution of SFC Embedding](https://arxiv.org/abs/2509.16856)
*Theviyanthan Krishnamohan,Lauritz Thamsen,Paul Harvey*

Main category: cs.NI

TL;DR: 提出了一种混合在线-离线方法，利用BeNNS代理模型高效解决SFC嵌入问题，显著缩短了评估时间。


<details>
  <summary>Details</summary>
Motivation: 为了解决遗传算法在在线评估SFC嵌入解决方案时耗时过长的问题，作者提出了一种混合方法以提高效率。

Method: 引入了一种混合在线-离线方法，利用BeNNS代理模型来近似评估生成的解决方案的适应度。

Result: 实验结果表明，该方法平均仅需36.8分钟即可探索数千种配置并生成可部署的解决方案，而传统在线方法平均需要17.9小时且无法收敛到最优解。

Conclusion: 该论文提出了一种混合在线-离线方法来解决SFC嵌入问题，通过BeNNS代理模型近似评估解决方案的质量，显著提高了效率。

Abstract: Service Function Chains (SFCs) enable programmatic control of the functions
and services in a computer network. By leveraging Software Defined Networking
to control the links between virtualised network functions, SFCs provide a
scalable approach to dealing with the increased pressures on network operation
and management. Unfortunately, the challenge of embedding SFCs onto the
underlying physical network and compute infrastructure is an NP-hard problem.
Genetic Algorithms (GAs) have been used to address this issue, but they require
significant time to evaluate solution quality (fitness) \textit{online}, with
most solutions instead adopting \textit{offline} simulations or analytical
evaluations.
  To enable online use of GAs in solving the SFC embedding problem, we
introduce a hybrid online-offline approach to evaluate generated solutions. At
the core of this is BeNNS--a topology, traffic, and SFC-embedding agnostic
surrogate model that approximates fitness. We evaluate our approach across six
experiments, varying available resources and traffic loads. Our results
demonstrate that our approach is capable of exploring thousands of potential
configurations and generating deployable solutions in 36.8 minutes on average,
compared to online-only approaches, which take 17.9 hours on average to explore
tens of solutions, which do not converge on an optimal solution.

</details>


### [217] [Analysis of an Architecture for Integrated Sensing and Communication in 5G OpenRAN](https://arxiv.org/abs/2509.16917)
*Daniel Lindenschmitt,Tobias Jung,Prudhvi Kumar Kakani,Torsten Reissland,Norman Franchi,Hans D. Schotten*

Main category: cs.NI

TL;DR: 本文提出了一种在5G OpenRAN环境中安全部署ISAC的架构，支持未来6G能力，并符合标准。


<details>
  <summary>Details</summary>
Motivation: 分析5G OpenRAN环境中集成感知与通信（ISAC）的功能需求和架构考虑，重点在于安全模块化部署。

Method: 采用单静态半双工感知方法，评估雷达设置选项、信号类型及RAN内处理位置，同时考虑性能和安全性。

Result: 提出的架构通过利用嗅探无线电单元（RUs）和现有OpenRAN前传接口，最小化硬件修改，同时保护敏感的I/Q数据和控制流量免受潜在攻击。

Conclusion: 本文提出了一种适用于5G OpenRAN环境的ISAC部署蓝图，支持未来6G ISAC能力，并符合标准要求。

Abstract: This paper analyzes the functional requirements and architectural
considerations for Integrated Sensing and Communication ( ISAC) in a 5G Open
Radio Access Network (OpenRAN) environment, with emphasis on secure and modular
deployment. Focusing on a mono-static, half-duplex sensing approach, it
evaluates radar setup options, signal types, and processing placement within
the Radio Access Network ( RAN), considering performance and security
implications. The proposed architecture minimizes hardware modifications by
leveraging sniffer Radio Units (RU s) and existing OpenRAN fronthaul
interfaces, while protecting sensitive In-phase and Quadrature (I/Q) data and
control traffic against potential attacks. Security threats, such as passive
sensing, spoofing, and privacy violations, are mapped to mitigation strategies
within the OpenRAN framework. The result is a deployment blueprint applicable
to both Public Land Mobile Networks ( PLMNs) and Non-Public Networks (NPNs),
supporting future 6G ISAC capabilities in a standards-compliant manner.

</details>


### [218] [System Relaxation for Interpretable and Adaptive Network Control](https://arxiv.org/abs/2509.16984)
*Zhiyuan Ren,Zhiliang Shuai,Wenchi Cheng*

Main category: cs.NI

TL;DR: SRA是一种新型网络控制算法，通过动态平衡负载优化性能和弹性，显著降低峰值中心性并提高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有网络控制策略依赖静态最短路径逻辑，导致关键节点上的‘应力集中’问题。

Method: SRA 是一种受物理松弛启发的控制范式，引导网络实现负载平衡的涌现平衡。

Result: 在异构网络中，SRA 将峰值中心性降低超过80%，高负载吞吐量增加超过45%；在均匀拓扑中，其目标智能转向弹性增强。

Conclusion: System Relaxation Algorithm (SRA) 提供了一种可预测的网络治理范式，智能权衡性能和弹性。

Abstract: Prevailing network control strategies, which rely on static shortest-path
logic, suffer from catastrophic "stress concentration" on critical nodes. This
paper introduces the System Relaxation Algorithm (SRA), a new control paradigm
inspired by physical relaxation that guides a network toward an emergent
equilibrium of load balance. SRA is an interpretable, 'white-box' dynamical
system whose behavior is profoundly topology-dependent: in heterogeneous
networks, it acts as a proactive performance optimizer, reducing peak
centrality by over 80\% and increasing high-load throughput by more than 45\%;
in homogeneous topologies, its objective intelligently shifts to resilience
enhancement. We rigorously prove its global convergence and practical stability
using the theory of non-smooth dynamical systems, establishing a predictable
paradigm for network governance that intelligently trades off performance and
resilience.

</details>


### [219] [Impact of Packetization on Network Calculus Analysis](https://arxiv.org/abs/2509.17028)
*Yming Jiang*

Main category: cs.NI

TL;DR: 论文指出忽视分组化效应会导致网络演算分析错误，并通过反例验证了两种基本系统中的问题，提出了修正方法。


<details>
  <summary>Details</summary>
Motivation: 为了展示忽视分组化效应时网络演算分析可能产生错误结果，本文研究了两种基本系统，这些系统在TSN和DetNet中是基础或默认设置。

Method: 通过反例分析，本文对时间敏感网络（TSN）和确定性网络（DetNet）中的两种基本系统应用网络演算分析，揭示了忽视分组化效应的服务曲线和性能边界的错误。

Result: 通过将分组化效应直接纳入服务模型，为两种基本系统推导出了修正的服务曲线和性能边界。

Conclusion: 论文提醒在将网络演算分析应用于分组交换网络时需要特别小心，以避免因忽视分组化效应而产生错误结果。

Abstract: For packet-switched networks, when the packetization effect is overlooked,
network calculus analysis can produce faulty results. To exemplify, network
calculus analysis is applied in this paper to two basic systems that are
fundamental or default settings in Time-Sensitive Networking (TSN) and
Deterministic Networking (DetNet). Through counterexamples, it is revealed that
for the two fundamental settings, some widely adopted, network calculus-based
service characterization results, known as service curves, which ignore
packetization, are faulty. In addition, for performance bounds derived from the
faulty service curves, it is shown that the validity of the bounds can be
arguable. In particular, the output bound, backlog bound and concatenation
service curve results are shown to be also faulty: counterexamples can be
constructed. By factoring the packetization effect directly into the service
models, corrected service curves and performance bounds are derived for the two
basic systems. These results remind that special care is needed when applying
network calculus analysis to packet-switched networks.

</details>


### [220] [Optimizing Split Federated Learning with Unstable Client Participation](https://arxiv.org/abs/2509.17398)
*Wei Wei,Zheng Lin,Xihui Liu,Hongyang Du,Dusit Niyato,Xianhao Chen*

Main category: cs.NI

TL;DR: 该研究针对不稳定网络环境下的SFL，提出了一个优化框架，理论推导了收敛上界并开发了高效解决方案，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于不稳定的网络环境对SFL的挑战，现有方案往往假设完美的客户端参与而忽略了实际网络环境的影响，因此需要一种更实用的解决方案。

Method: 开发了一个优化框架，包括理论推导SFL的收敛上界，并基于此制定了客户端采样和模型分割的联合优化问题。采用高效的解决方案来最优求解该问题。

Result: 通过EMNIST和CIFAR-10的广泛模拟实验，证明了所提框架相比现有基准的优越性。

Conclusion: 该研究提出了一个针对不稳定客户端参与的SFL优化框架，通过理论推导和实验验证，证明了其在减少收敛上界方面的优越性。

Abstract: To enable training of large artificial intelligence (AI) models at the
network edge, split federated learning (SFL) has emerged as a promising
approach by distributing computation between edge devices and a server.
However, while unstable network environments pose significant challenges to
SFL, prior schemes often overlook such an effect by assuming perfect client
participation, rendering them impractical for real-world scenarios. In this
work, we develop an optimization framework for SFL with unstable client
participation. We theoretically derive the first convergence upper bound for
SFL with unstable client participation by considering activation uploading
failures, gradient downloading failures, and model aggregation failures. Based
on the theoretical results, we formulate a joint optimization problem for
client sampling and model splitting to minimize the upper bound. We then
develop an efficient solution approach to solve the problem optimally.
Extensive simulations on EMNIST and CIFAR-10 demonstrate the superiority of our
proposed framework compared to existing benchmarks.

</details>


### [221] [GLo-MAPPO: A Multi-Agent Proximal Policy Optimization for Energy Efficiency in UAV-Assisted LoRa Networks](https://arxiv.org/abs/2509.17676)
*Abdullahi Isa Ahmed,Jamal Bentahar,El Mehdi Amhoud*

Main category: cs.NI

TL;DR: 利用无人机作为动态LoRa网关，结合多智能体强化学习（GLo-MAPPO），显著提升能源效率，适用于下一代物联网应用。


<details>
  <summary>Details</summary>
Motivation: 传统LoRa部署存在覆盖盲区和NLoS传播损耗，而卫星方案能耗高且延迟大，无法满足能源受限和延迟敏感的应用需求。

Method: 提出了一个基于多无人机（UAV）的动态LoRa网关架构，并采用多智能体强化学习框架（GLo-MAPPO）优化系统参数。

Result: 仿真结果表明，GLo-MAPPO在10至50个终端设备的网络中，能源效率提升显著，最高达71.25%。

Conclusion: GLo-MAPPO显著提高了LoRa网络的能源效率，适用于大规模或动态变化的NG-IoT应用。

Abstract: Long Range (LoRa) based low-power wide area networks (LPWANs) are crucial for
enabling next-generation IoT (NG-IoT) applications in 5G/6G ecosystems due to
their long-range, low-power, and low-cost characteristics. However, achieving
high energy efficiency in such networks remains a critical challenge,
particularly in large-scale or dynamically changing environments. Traditional
terrestrial LoRa deployments often suffer from coverage gaps and
non-line-of-sight (NLoS) propagation losses, while satellite-based IoT
solutions consume excessive energy and introduce high latency, limiting their
suitability for energy-constrained and delay-sensitive applications. To address
these limitations, we propose a novel architecture using multiple unmanned
aerial vehicles (UAVs) as flying LoRa gateways to dynamically collect data from
ground-based LoRa end devices. Our approach aims to maximize the system's
weighted global energy efficiency by jointly optimizing spreading factors,
transmission powers, UAV trajectories, and end-device associations.
Additionally, we formulate this complex optimization problem as a partially
observable Markov decision process (POMDP) and propose green LoRa multi-agent
proximal policy optimization (GLo-MAPPO), a multi-agent reinforcement learning
(MARL) framework based on centralized training with decentralized execution
(CTDE). Simulation results show that GLo-MAPPO significantly outperforms
benchmark algorithms, achieving energy efficiency improvements of 71.25%,
18.56%, 67.00%, 59.73%, and 49.95% for networks with 10, 20, 30, 40, and 50
LoRa end devices, respectively.

</details>


### [222] [Building Transparency in Deep Learning-Powered Network Traffic Classification: A Traffic-Explainer Framework](https://arxiv.org/abs/2509.18007)
*Riya Ponraj,Ram Durairajan,Yu Wang*

Main category: cs.NI

TL;DR: Traffic-Explainer是一种提升深度学习流量分类透明度的框架，通过识别关键特征，性能提升42%，并在多个任务中验证了其实用性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在流量分类中的性能提升显著，但其预测和决策的缺乏透明度阻碍了DL解决方案在生产网络中的部署。

Method: 提出了Traffic-Explainer，一种模型无关且基于输入扰动的流量解释框架，通过最大化预测互信息来识别关键特征。

Result: Traffic-Explainer在三个关键任务（应用分类、流量定位和网络制图）中表现出色，识别了驱动预测的关键字节和海底电缆，揭示了潜在漏洞和隐私问题。

Conclusion: Traffic-Explainer通过最大化原始流量序列与其掩码版本预测之间的互信息，自动识别影响模型预测的最关键特征，显著提升了现有解释方法的性能（约42%），并在实际应用中验证了其透明度和实用性。

Abstract: Recent advancements in deep learning have significantly enhanced the
performance and efficiency of traffic classification in networking systems.
However, the lack of transparency in their predictions and decision-making has
made network operators reluctant to deploy DL-based solutions in production
networks. To tackle this challenge, we propose Traffic-Explainer, a
model-agnostic and input-perturbation-based traffic explanation framework. By
maximizing the mutual information between predictions on original traffic
sequences and their masked counterparts, Traffic-Explainer automatically
uncovers the most influential features driving model predictions. Extensive
experiments demonstrate that Traffic-Explainer improves upon existing
explanation methods by approximately 42%. Practically, we further apply
Traffic-Explainer to identify influential features and demonstrate its enhanced
transparency across three critical tasks: application classification, traffic
localization, and network cartography. For the first two tasks,
Traffic-Explainer identifies the most decisive bytes that drive predicted
traffic applications and locations, uncovering potential vulnerabilities and
privacy concerns. In network cartography, Traffic-Explainer identifies
submarine cables that drive the mapping of traceroute to physical path,
enabling a traceroute-informed risk analysis.

</details>


### [223] [Detection of Misreporting Attacks on Software-Defined Immersive Environments](https://arxiv.org/abs/2509.18040)
*Sourya Saha,Md Nurul Absur,Shima Yousefi,Saptarshi Debroy*

Main category: cs.NI

TL;DR: 混合机器学习框架有效检测SDN中的交换机误报，保障沉浸式应用质量。


<details>
  <summary>Details</summary>
Motivation: SDN的灵活性引入了新的漏洞，如交换机误报导致的负载不平衡，可能引发沉浸式应用的质量严重下降。

Method: 该框架结合了无监督异常评分与监督分类，通过捕获交换机报告的负载中的时间不一致性来识别异常行为。

Result: 实验结果表明，该框架在检测误报行为方面实现了高召回率，适用于SDN环境中的早期可靠检测。

Conclusion: 该论文提出的混合机器学习框架能有效检测SDN中的异常行为，尤其是在早期和可靠检测方面表现出色，为托管沉浸式应用提供了安全保障。

Abstract: The ability to centrally control network infrastructure using a programmable
middleware has made Software-Defined Networking (SDN) ideal for emerging
applications, such as immersive environments. However, such flexibility
introduces new vulnerabilities, such as switch misreporting led load imbalance,
which in turn make such immersive environment vulnerable to severe quality
degradation. In this paper, we present a hybrid machine learning (ML)-based
network anomaly detection framework that identifies such stealthy misreporting
by capturing temporal inconsistencies in switch-reported loads, and thereby
counter potentially catastrophic quality degradation of hosted immersive
application. The detection system combines unsupervised anomaly scoring with
supervised classification to robustly distinguish malicious behavior. Data
collected from a realistic testbed deployment under both benign and adversarial
conditions is used to train and evaluate the model. Experimental results show
that the framework achieves high recall in detecting misreporting behavior,
making it effective for early and reliable detection in SDN environments.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [224] [Neural Atlas Graphs for Dynamic Scene Decomposition and Editing](https://arxiv.org/abs/2509.16336)
*Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide*

Main category: cs.GR

TL;DR: NAGs结合2D可编辑性和3D排序定位，显著提升动态场景编辑质量，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决动态场景中可编辑性与场景复杂性之间的权衡问题，现有方法在编辑性和场景复杂度之间存在不足。

Method: 提出了一种混合高分辨率场景表示方法，其中每个图节点是一个视角依赖的神经图谱，支持2D外观编辑和3D场景元素的排序与定位。

Result: 在Waymo Open Dataset上实现了5 dB PSNR的提升，并在DAVIS视频数据集上比现有方法高出7 dB PSNR。

Conclusion: Neural Atlas Graphs (NAGs) 提供了一种创新的高分辨率场景表示方法，结合了2D可编辑性和3D排序定位能力，显著提升了动态场景的编辑质量和视觉表现。

Abstract: Learning editable high-resolution scene representations for dynamic scenes is
an open problem with applications across the domains from autonomous driving to
creative editing - the most successful approaches today make a trade-off
between editability and supporting scene complexity: neural atlases represent
dynamic scenes as two deforming image layers, foreground and background, which
are editable in 2D, but break down when multiple objects occlude and interact.
In contrast, scene graph models make use of annotated data such as masks and
bounding boxes from autonomous-driving datasets to capture complex 3D spatial
relationships, but their implicit volumetric node representations are
challenging to edit view-consistently. We propose Neural Atlas Graphs (NAGs), a
hybrid high-resolution scene representation, where every graph node is a
view-dependent neural atlas, facilitating both 2D appearance editing and 3D
ordering and positioning of scene elements. Fit at test-time, NAGs achieve
state-of-the-art quantitative results on the Waymo Open Dataset - by 5 dB PSNR
increase compared to existing methods - and make environmental editing possible
in high resolution and visual quality - creating counterfactual driving
scenarios with new backgrounds and edited vehicle appearance. We find that the
method also generalizes beyond driving scenes and compares favorably - by more
than 7 dB in PSNR - to recent matting and video editing baselines on the DAVIS
video dataset with a diverse set of human and animal-centric scenes.

</details>


### [225] [Brain Connectivity Network Structure Learning For Brain Disorder Diagnosis](https://arxiv.org/abs/2509.16735)
*Dongdong Chen,Linlin Yao,Mengjun Liu,Zhenrong Shen,Yuqi Hu,Zhiyun Song,Shengyu Lu,Qian Wang,Dinggang Shen,Lichi Zhang*

Main category: cs.GR

TL;DR: 提出自监督框架优化脑连接网络结构及表示，实验证明其在脑疾病诊断中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统脑连接网络构建方法存在冗余连接或忽略关键交互的问题，且标记数据不足增加了学习内在脑特征表示的难度。

Method: 提出了一种自监督框架，通过自适应构建互补脑网络结构学习器，并结合多状态图编码器和联合迭代学习策略，优化网络结构及其表示。

Result: 在跨数据集脑疾病诊断实验中，该方法 consistently 优于现有技术。

Conclusion: 该论文提出的自监督框架在跨数据集脑疾病诊断中表现优于现有方法，验证了其有效性和泛化能力。代码已公开。

Abstract: Recent studies in neuroscience highlight the significant potential of brain
connectivity networks, which are commonly constructed from functional magnetic
resonance imaging (fMRI) data for brain disorder diagnosis. Traditional brain
connectivity networks are typically obtained using predefined methods that
incorporate manually-set thresholds to estimate inter-regional relationships.
However, such approaches often introduce redundant connections or overlook
essential interactions, compromising the value of the constructed networks.
Besides, the insufficiency of labeled data further increases the difficulty of
learning generalized representations of intrinsic brain characteristics. To
mitigate those issues, we propose a self-supervised framework to learn an
optimal structure and representation for brain connectivity networks, focusing
on individualized generation and optimization in an unsupervised manner. We
firstly employ two existing whole-brain connectomes to adaptively construct
their complementary brain network structure learner, and then introduce a
multi-state graph-based encoder with a joint iterative learning strategy to
simultaneously optimize both the generated network structure and its
representation. By leveraging self-supervised pretraining on large-scale
unlabeled brain connectivity data, our framework enables the brain connectivity
network learner to generalize e ffectively to unseen disorders, while requiring
only minimal finetuning of the encoder for adaptation to new diagnostic tasks.
Extensive experiments on cross-dataset brain disorder diagnosis demonstrate
that our method consistently outperforms state-of-the-art approaches,
validating its effectiveness and generalizability. The code is publicly
available at https://github.com/neochen1/BCNSL.

</details>


### [226] [PhysHDR: When Lighting Meets Materials and Scene Geometry in HDR Reconstruction](https://arxiv.org/abs/2509.16869)
*Hrishav Bakul Barua,Kalin Stefanov,Ganesh Krishnasamy,KokSheik Wong,Abhinav Dhall*

Main category: cs.GR

TL;DR: PhysHDR是一种基于潜在扩散的生成模型，通过结合光照、深度和材料特性提升HDR图像重建质量，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LDR转HDR方法缺乏对光照、阴影和场景几何的显式建模，限制了重建质量。材料特性（如镜面和漫反射）的建模有望提升HDR重建效果。

Method: 提出了一种基于潜在扩散的生成模型PhysHDR，通过去噪过程结合光照和深度信息，并引入新颖的损失函数来考虑场景中表面的材料特性。

Result: 实验证明PhysHDR在HDR图像重建质量上优于多种最新方法。

Conclusion: PhysHDR通过结合光照、深度信息和材料特性，显著提升了HDR图像重建的质量，优于现有方法。

Abstract: Low Dynamic Range (LDR) to High Dynamic Range (HDR) image translation is a
fundamental task in many computational vision problems. Numerous data-driven
methods have been proposed to address this problem; however, they lack explicit
modeling of illumination, lighting, and scene geometry in images. This limits
the quality of the reconstructed HDR images. Since lighting and shadows
interact differently with different materials, (e.g., specular surfaces such as
glass and metal, and lambertian or diffuse surfaces such as wood and stone),
modeling material-specific properties (e.g., specular and diffuse reflectance)
has the potential to improve the quality of HDR image reconstruction. This
paper presents PhysHDR, a simple yet powerful latent diffusion-based generative
model for HDR image reconstruction. The denoising process is conditioned on
lighting and depth information and guided by a novel loss to incorporate
material properties of surfaces in the scene. The experimental results
establish the efficacy of PhysHDR in comparison to a number of recent
state-of-the-art methods.

</details>


### [227] [SemanticGarment: Semantic-Controlled Generation and Editing of 3D Gaussian Garments](https://arxiv.org/abs/2509.16960)
*Ruiyan Wang,Zhengxue Cheng,Zonghao Lin,Jun Ling,Yuzhou Liu,Yanru An,Rong Xie,Li Song*

Main category: cs.GR

TL;DR: SemanticGarment是一种基于3D高斯的服装生成与编辑方法，通过语义模型和自遮挡优化实现高保真效果。


<details>
  <summary>Details</summary>
Motivation: 传统方法在技术复杂性和资源成本上难以满足需求，而学习型方法虽快但仍面临多视图不一致和对详细拓扑的依赖问题。

Method: 提出了一种3D语义服装模型，利用结构人体先验初始化几何结构，并开发了自遮挡优化策略以减少单图像重建中的伪影。

Result: 实验证明了该方法在3D服装生成和编辑中的优越性能。

Conclusion: SemanticGarment通过基于3D高斯的方法实现了从文本或图像提示的高保真3D服装生成，并支持基于语义的交互式编辑，解决了多视图一致性和服装拟合的挑战。

Abstract: 3D digital garment generation and editing play a pivotal role in fashion
design, virtual try-on, and gaming. Traditional methods struggle to meet the
growing demand due to technical complexity and high resource costs.
Learning-based approaches offer faster, more diverse garment synthesis based on
specific requirements and reduce human efforts and time costs. However, they
still face challenges such as inconsistent multi-view geometry or textures and
heavy reliance on detailed garment topology and manual rigging. We propose
SemanticGarment, a 3D Gaussian-based method that realizes high-fidelity 3D
garment generation from text or image prompts and supports semantic-based
interactive editing for flexible user customization. To ensure multi-view
consistency and garment fitting, we propose to leverage structural human priors
for the generative model by introducing a 3D semantic clothing model, which
initializes the geometry structure and lays the groundwork for view-consistent
garment generation and editing. Without the need to regenerate or rely on
existing mesh templates, our approach allows for rapid and diverse
modifications to existing Gaussians, either globally or within a local region.
To address the artifacts caused by self-occlusion for garment reconstruction
based on single image, we develop a self-occlusion optimization strategy to
mitigate holes and artifacts that arise when directly animating self-occluded
garments. Extensive experiments are conducted to demonstrate our superior
performance in 3D garment generation and editing.

</details>


### [228] [Beat on Gaze: Learning Stylized Generation of Gaze and Head Dynamics](https://arxiv.org/abs/2509.17168)
*Chengwei Shi,Chong Cao,Xin Tong,Xukun Shen*

Main category: cs.GR

TL;DR: StyGazeTalk通过多层LSTM和风格编码器生成同步的视线和头部运动风格，解决了现有方法孤立处理面部组件的问题，并引入了高质量数据集。


<details>
  <summary>Details</summary>
Motivation: 现有方法常孤立处理面部组件，忽略了视线、头部运动和语音之间的复杂协调，且缺乏高质量视线标注数据集。

Method: 提出StyGazeTalk，一种基于多层LSTM结构和风格编码器的音频驱动方法，用于生成同步的视线和头部运动风格。

Result: 实验结果表明，该方法能生成真实、时间连贯且风格多样的头部-视线运动。

Conclusion: StyGazeTalk方法在音频驱动的面部动画中显著提升了头部和视线运动的真实性和风格多样性，为现有技术带来了重要进展。

Abstract: Head and gaze dynamics are crucial in expressive 3D facial animation for
conveying emotion and intention. However, existing methods frequently address
facial components in isolation, overlooking the intricate coordination between
gaze, head motion, and speech. The scarcity of high-quality gaze-annotated
datasets hinders the development of data-driven models capable of capturing
realistic, personalized gaze control. To address these challenges, we propose
StyGazeTalk, an audio-driven method that generates synchronized gaze and head
motion styles. We extract speaker-specific motion traits from gaze-head
sequences with a multi-layer LSTM structure incorporating a style encoder,
enabling the generation of diverse animation styles. We also introduce a
high-precision multimodal dataset comprising eye-tracked gaze, audio, head
pose, and 3D facial parameters, providing a valuable resource for training and
evaluating head and gaze control models. Experimental results demonstrate that
our method generates realistic, temporally coherent, and style-aware head-gaze
motions, significantly advancing the state-of-the-art in audio-driven facial
animation.

</details>


### [229] [High Resolution UDF Meshing via Iterative Networks](https://arxiv.org/abs/2509.17212)
*Federico Stella,Nicolas Talabot,Hieu Le,Pascal Fua*

Main category: cs.GR

TL;DR: 提出迭代神经网络方法，通过多轮处理和邻近信息传播，显著提高UDF表面提取的准确性和完整性。


<details>
  <summary>Details</summary>
Motivation: 由于UDF在开放表面表示上的天然优势，但其在高分辨率下噪声较大，导致现有单轮处理方法难以捕捉细节并产生表面缺失和孔洞。

Method: 我们提出了一种迭代神经网络方法，通过多轮处理和空间传播邻近信息，逐步改进每个体素内的表面恢复。

Result: 实验表明，我们的方法在多种3D模型上比现有方法生成更准确和完整的网格，尤其适用于复杂几何体。

Conclusion: 通过迭代神经网络方法，我们的技术显著提高了从UDF中提取开放表面网格的准确性和完整性，特别是在高分辨率和复杂几何体上，优于现有方法。

Abstract: Unsigned Distance Fields (UDFs) are a natural implicit representation for
open surfaces but, unlike Signed Distance Fields (SDFs), are challenging to
triangulate into explicit meshes. This is especially true at high resolutions
where neural UDFs exhibit higher noise levels, which makes it hard to capture
fine details. Most current techniques perform within single voxels without
reference to their neighborhood, resulting in missing surface and holes where
the UDF is ambiguous or noisy. We show that this can be remedied by performing
several passes and by reasoning on previously extracted surface elements to
incorporate neighborhood information. Our key contribution is an iterative
neural network that does this and progressively improves surface recovery
within each voxel by spatially propagating information from increasingly
distant neighbors. Unlike single-pass methods, our approach integrates newly
detected surfaces, distance values, and gradients across multiple iterations,
effectively correcting errors and stabilizing extraction in challenging
regions. Experiments on diverse 3D models demonstrate that our method produces
significantly more accurate and complete meshes than existing approaches,
particularly for complex geometries, enabling UDF surface extraction at higher
resolutions where traditional methods fail.

</details>


### [230] ["I don't like my avatar": Investigating Human Digital Doubles](https://arxiv.org/abs/2509.17748)
*Siyi Liu,Kazi Injamamul Haque,Zerrin Yumak*

Main category: cs.GR

TL;DR: 研究发现高真实感数字替身增强认同感和社交存在感，但熟悉面孔的替身效果相反。参与者不喜欢自己的高真实感替身，对他人替身更宽容。


<details>
  <summary>Details</summary>
Motivation: 探讨替身风格（真实vs卡通）和熟悉度（自己、熟人、陌生人）如何影响自我/他人认同、感知真实性、亲和力及社交存在感。

Method: 通过创建两种风格的替身（真实感的MetaHumans和卡通风格的ReadyPlayerMe）并使用动作捕捉生成面部动画，进行线下对照实验，通过问卷收集数据。

Result: 高真实感替身提升认同感、感知真实性和社交存在感；熟悉面孔（尤其是高真实感）的替身会降低这些效果。参与者不喜欢自己的高真实感替身，但对熟人或陌生人的替身更为宽容。

Conclusion: 研究表明，高真实感的数字替身能提升认同感、感知真实性和社交存在感，但熟悉面孔（尤其是高真实感）的替身会降低这些效果。参与者虽然能识别自己的数字替身，但普遍不喜欢，尤其是高真实感的版本，而对熟人或陌生人的替身则更为宽容。

Abstract: Creating human digital doubles is becoming easier and much more accessible to
everyone using consumer grade devices. In this work, we investigate how avatar
style (realistic vs cartoon) and avatar familiarity (self, acquaintance,
unknown person) affect self/other-identification, perceived realism, affinity
and social presence with a controlled offline experiment. We created two styles
of avatars (realistic-looking MetaHumans and cartoon-looking ReadyPlayerMe
avatars) and facial animations stimuli for them using performance capture.
Questionnaire responses demonstrate that higher appearance realism leads to a
higher level of identification, perceived realism and social presence. However,
avatars with familiar faces, especially those with high appearance realism,
lead to a lower level of identification, perceived realism, and affinity.
Although participants identified their digital doubles as their own, they
consistently did not like their avatars, especially of realistic appearance.
But they were less critical and more forgiving about their acquaintance's or an
unknown person's digital double.

</details>


### [231] [Effect of Appearance and Animation Realism on the Perception of Emotionally Expressive Virtual Humans](https://arxiv.org/abs/2509.17803)
*Nabila Amadou,Kazi Injamamul Haque,Zerrin Yumak*

Main category: cs.GR

TL;DR: 研究发现，虚拟人类的外观和动画真实性越高，社交存在感和吸引力越强，动画真实性还显著影响感知真实性和情感强度。


<details>
  <summary>Details</summary>
Motivation: 尽管虚拟人类的外观已达到高度真实，但缺乏对其外观和动画真实性在情感表达场景中的感知分析。

Method: 设计用户实验，分析不同情感条件下虚拟人类外观真实性和动画真实性的影响。

Result: 高真实性的外观和动画提升了社交存在感和吸引力，动画真实性显著影响感知真实性和情感强度。

Conclusion: 研究表明，更高的外观真实性和动画真实性会提升社交存在感和吸引力评分。同时，动画真实性对感知真实性和情感强度有显著影响。

Abstract: 3D Virtual Human technology is growing with several potential applications in
health, education, business and telecommunications. Investigating the
perception of these virtual humans can help guide to develop better and more
effective applications. Recent developments show that the appearance of the
virtual humans reached to a very realistic level. However, there is not yet
adequate analysis on the perception of appearance and animation realism for
emotionally expressive virtual humans. In this paper, we designed a user
experiment and analyzed the effect of a realistic virtual human's appearance
realism and animation realism in varying emotion conditions. We found that
higher appearance realism and higher animation realism leads to higher social
presence and higher attractiveness ratings. We also found significant effects
of animation realism on perceived realism and emotion intensity levels. Our
study sheds light into how appearance and animation realism effects the
perception of highly realistic virtual humans in emotionally expressive
scenarios and points out to future directions.

</details>


### [232] [A Comparative Study of Different Edit Distance-Based Methods for Feature Tracking using Merge Trees on Time-Varying Scalar Fields](https://arxiv.org/abs/2509.17974)
*Son Le Thanh,Tino Weinkauf*

Main category: cs.GR

TL;DR: 比较四种合并树编辑距离方法，发现它们在特征跟踪中产生不同结果，同一类别内技术间也有差异。


<details>
  <summary>Details</summary>
Motivation: 特征跟踪在时变标量场中是科学计算的基础任务，而合并树作为一种拓扑描述符，其编辑距离在有效时间数据跟踪中起着关键作用。

Method: 本文比较了四种不同的基于合并树编辑距离的特征跟踪方法，并利用分析和真实数据集进行了验证。

Result: 实验显示，这些方法在跟踪特征时产生了不同的结果，且同一类别内的技术之间也存在显著差异。

Conclusion: 研究表明，基于合并树编辑距离的不同方法在特征跟踪中会产生显著不同的结果，即使在同一类别内的技术之间也存在差异。

Abstract: Feature tracking in time-varying scalar fields is a fundamental task in
scientific computing. Topological descriptors, which summarize important
features of data, have proved to be viable tools to facilitate this task. The
merge tree is a topological descriptor that captures the connectivity behaviors
of the sub- or superlevel sets of a scalar field. Edit distances between merge
trees play a vital role in effective temporal data tracking. Existing methods
to compute them fall into two main classes, namely whether they are dependent
or independent of the branch decomposition. These two classes represent the
most prominent approaches for producing tracking results. In this paper, we
compare four different merge tree edit distance-based methods for feature
tracking. We demonstrate that these methods yield distinct results with both
analytical and real-world data sets. Furthermore, we investigate how these
results vary and identify the factors that influence them. Our experiments
reveal significant differences in tracked features over time, even among those
produced by techniques within the same category.

</details>


### [233] [Towards Seeing Bones at Radio Frequency](https://arxiv.org/abs/2509.17979)
*Yiwen Song,Hongyang Li,Kuang Yuan,Ran Bi,Swarun Kumar*

Main category: cs.GR

TL;DR: MCT系统通过创新算法和深度学习，实现了亚厘米级RF骨骼成像，突破现有技术限制。


<details>
  <summary>Details</summary>
Motivation: 无线传感领域长期追求在无线电频率下实现类似X射线的成像能力，尤其是对骨骼的成像，但现有技术受限于波长、衰减和复杂衍射，分辨率较低。

Method: 采用穿透式合成孔径算法结合基于学习的管道来校正衍射引起的伪影。

Result: 在肉类模型上的详细评估显示，MCT系统将RF穿透成像的分辨率从亚分米级提升到亚厘米级，显著优于现有技术。

Conclusion: MCT系统通过创新的穿透式合成孔径算法和基于学习的管道，显著提高了RF穿透成像的分辨率，从亚分米级提升到亚厘米级，实现了在无线电频率下类似X射线成像的突破。

Abstract: Wireless sensing literature has long aspired to achieve X-ray-like vision at
radio frequencies. Yet, state-of-the-art wireless sensing literature has yet to
generate the archetypal X-ray image: one of the bones beneath flesh. In this
paper, we explore MCT, a penetration-based RF-imaging system for imaging bones
at mm-resolution, one that significantly exceeds prior penetration-based RF
imaging literature. Indeed the long wavelength, significant attenuation and
complex diffraction that occur as RF propagates through flesh, have long
limited imaging resolution (to several centimeters at best). We address these
concerns through a novel penetration-based synthetic aperture algorithm,
coupled with a learning-based pipeline to correct for diffraction-induced
artifacts. A detailed evaluation of meat models demonstrates a resolution
improvement from sub-decimeter to sub-centimeter over prior art in RF
penetrative imaging.

</details>


### [234] [VideoFrom3D: 3D Scene Video Generation via Complementary Image and Video Diffusion Models](https://arxiv.org/abs/2509.17985)
*Geonung Kim,Janghyeok Han,Sunghyun Cho*

Main category: cs.GR

TL;DR: VideoFrom3D是一个无需配对数据集的框架，结合图像和视频扩散模型生成高质量3D场景视频，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型难以同时建模视觉质量、运动和时间一致性，导致复杂场景生成效果不佳。

Method: 框架由Sparse Anchor-view Generation (SAG)和Geometry-guided Generative Inbetweening (GGI)模块组成，分别利用图像扩散模型生成高质量锚点视图，并通过视频扩散模型插值中间帧。

Result: 实验表明，该方法在多样化和挑战性场景下生成高质量视频，优于基线方法。

Conclusion: VideoFrom3D框架通过结合图像和视频扩散模型的优势，成功生成了高质量、风格一致的3D场景视频，且无需配对数据集。

Abstract: In this paper, we propose VideoFrom3D, a novel framework for synthesizing
high-quality 3D scene videos from coarse geometry, a camera trajectory, and a
reference image. Our approach streamlines the 3D graphic design workflow,
enabling flexible design exploration and rapid production of deliverables. A
straightforward approach to synthesizing a video from coarse geometry might
condition a video diffusion model on geometric structure. However, existing
video diffusion models struggle to generate high-fidelity results for complex
scenes due to the difficulty of jointly modeling visual quality, motion, and
temporal consistency. To address this, we propose a generative framework that
leverages the complementary strengths of image and video diffusion models.
Specifically, our framework consists of a Sparse Anchor-view Generation (SAG)
and a Geometry-guided Generative Inbetweening (GGI) module. The SAG module
generates high-quality, cross-view consistent anchor views using an image
diffusion model, aided by Sparse Appearance-guided Sampling. Building on these
anchor views, GGI module faithfully interpolates intermediate frames using a
video diffusion model, enhanced by flow-based camera control and structural
guidance. Notably, both modules operate without any paired dataset of 3D scene
models and natural images, which is extremely difficult to obtain.
Comprehensive experiments show that our method produces high-quality,
style-consistent scene videos under diverse and challenging scenarios,
outperforming simple and extended baselines.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [235] [Digging Into the Internal: Causality-Based Analysis of LLM Function Calling](https://arxiv.org/abs/2509.16268)
*Zhenlan Ji,Daoyuan Wu,Wenxuan Wang,Pingchuan Ma,Shuai Wang,Lei Ma*

Main category: cs.SE

TL;DR: 研究发现函数调用（FC）能显著提升LLM的指令遵从性和安全性，性能提升达135%。


<details>
  <summary>Details</summary>
Motivation: 探索FC如何影响LLM行为，并发现其能显著增强LLM对用户指令的遵从性。

Method: 通过层级别和令牌级别的因果干预，剖析FC对模型内部计算逻辑的影响。

Result: FC在检测恶意输入方面比传统提示方法平均性能提升约135%。

Conclusion: FC技术显著提升了LLM在检测恶意输入方面的性能，展示了其在增强LLM可靠性和实际应用能力方面的潜力。

Abstract: Function calling (FC) has emerged as a powerful technique for facilitating
large language models (LLMs) to interact with external systems and perform
structured tasks. However, the mechanisms through which it influences model
behavior remain largely under-explored. Besides, we discover that in addition
to the regular usage of FC, this technique can substantially enhance the
compliance of LLMs with user instructions. These observations motivate us to
leverage causality, a canonical analysis method, to investigate how FC works
within LLMs. In particular, we conduct layer-level and token-level causal
interventions to dissect FC's impact on the model's internal computational
logic when responding to user queries. Our analysis confirms the substantial
influence of FC and reveals several in-depth insights into its mechanisms. To
further validate our findings, we conduct extensive experiments comparing the
effectiveness of FC-based instructions against conventional prompting methods.
We focus on enhancing LLM safety robustness, a critical LLM application
scenario, and evaluate four mainstream LLMs across two benchmark datasets. The
results are striking: FC shows an average performance improvement of around
135% over conventional prompting methods in detecting malicious inputs,
demonstrating its promising potential to enhance LLM reliability and capability
in practical applications.

</details>


### [236] [Constrained Co-evolutionary Metamorphic Differential Testing for Autonomous Systems with an Interpretability Approach](https://arxiv.org/abs/2509.16478)
*Hossein Yousefizadeh,Shenghui Gu,Lionel C. Briand,Ali Nasr*

Main category: cs.SE

TL;DR: CoCoMagic是一种结合蜕变测试和差异测试的自动化测试生成方法，用于检测自主系统版本间的行为差异，效果显著且提供可解释性支持。


<details>
  <summary>Details</summary>
Motivation: 自主系统（如自动驾驶系统）通过频繁更新快速演进，可能导致意外行为退化。系统级测试面临巨大场景空间、缺乏可靠测试预言以及需要实际可应用和可解释的测试用例等挑战。

Method: CoCoMagic结合了蜕变测试、差异测试和基于搜索的高级技术，将测试生成视为约束合作的协同进化搜索，以最大化版本间预定义蜕变关系的违反差异。

Result: 在Carla虚拟模拟器中对InterFuser进行评估，结果显示CoCoMagic显著优于基线搜索方法，识别出287%更多的高严重性行为差异，同时保持场景真实性。

Conclusion: CoCoMagic为自主系统的版本间差异测试提供了一种高效、有效且可解释的方法，支持针对性调试和安全评估。

Abstract: Autonomous systems, such as autonomous driving systems, evolve rapidly
through frequent updates, risking unintended behavioral degradations. Effective
system-level testing is challenging due to the vast scenario space, the absence
of reliable test oracles, and the need for practically applicable and
interpretable test cases. We present CoCoMagic, a novel automated test case
generation method that combines metamorphic testing, differential testing, and
advanced search-based techniques to identify behavioral divergences between
versions of autonomous systems. CoCoMagic formulates test generation as a
constrained cooperative co-evolutionary search, evolving both source scenarios
and metamorphic perturbations to maximize differences in violations of
predefined metamorphic relations across versions. Constraints and population
initialization strategies guide the search toward realistic, relevant
scenarios. An integrated interpretability approach aids in diagnosing the root
causes of divergences. We evaluate CoCoMagic on an end-to-end ADS, InterFuser,
within the Carla virtual simulator. Results show significant improvements over
baseline search methods, identifying up to 287\% more distinct high-severity
behavioral differences while maintaining scenario realism. The interpretability
approach provides actionable insights for developers, supporting targeted
debugging and safety assessment. CoCoMagic offers an efficient, effective, and
interpretable way for the differential testing of evolving autonomous systems
across versions.

</details>


### [237] [Causal Fuzzing for Verifying Machine Unlearning](https://arxiv.org/abs/2509.16525)
*Anna Mazhar,Sainyam Galhotra*

Main category: cs.SE

TL;DR: CAF\'E是一个基于因果关系的框架，用于验证黑盒ML模型的去学习效果，能检测基线方法遗漏的残留影响，且计算高效。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在决策系统中的广泛应用，针对特定数据或特征的“去学习”能力对于提升模型适应性、公平性和隐私保护至关重要。

Method: 提出CAF\'E，一个基于因果关系的框架，统一了数据点和特征级别的去学习验证，通过因果依赖关系评估直接和间接影响。

Result: 在五个数据集和三种模型架构上的评估表明，CAF\'E成功检测出基线方法遗漏的残留影响，同时保持计算效率。

Conclusion: CAF\'E框架通过因果依赖关系评估直接和间接的去学习效果，为黑盒ML模型的去学习验证提供了精细化的分析，并在计算效率上表现优异。

Abstract: As machine learning models become increasingly embedded in decision-making
systems, the ability to "unlearn" targeted data or features is crucial for
enhancing model adaptability, fairness, and privacy in models which involves
expensive training. To effectively guide machine unlearning, a thorough testing
is essential. Existing methods for verification of machine unlearning provide
limited insights, often failing in scenarios where the influence is indirect.
In this work, we propose CAF\'E, a new causality based framework that unifies
datapoint- and feature-level unlearning for verification of black-box ML
models. CAF\'E evaluates both direct and indirect effects of unlearning targets
through causal dependencies, providing actionable insights with fine-grained
analysis. Our evaluation across five datasets and three model architectures
demonstrates that CAF\'E successfully detects residual influence missed by
baselines while maintaining computational efficiency.

</details>


### [238] [Is Measurement Enough? Rethinking Output Validation in Quantum Program Testing](https://arxiv.org/abs/2509.16595)
*Jiaming Ye,Xiongfei Wu,Shangzhou Xia,Fuyuan Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: 论文分析了量子程序测试中基于测量的验证方法的局限性，并通过实证研究比较了测量与状态向量验证方法的优缺点，发现后者在复杂任务中更有效。


<details>
  <summary>Details</summary>
Motivation: 量子计算的兴起使得确保量子程序质量变得至关重要。然而，由于量子程序的概率性本质，现有的基于测量的验证方法存在显著局限性，因此需要研究这些局限性并探索更有效的验证方法。

Method: 论文采用实证研究方法，分析了近期关于量子程序测试的研究，将现有的基于测量的验证方法分为两类：分布级验证和输出值级验证，并与基于状态向量的验证方法进行比较。

Result: 研究发现，基于测量的验证方法适合简单评估任务，而基于状态向量的验证方法在复杂任务中表现更优。

Conclusion: 该论文的结论是，基于测量的验证方法适用于简单的评估任务，如验证特定输出值的存在，而基于状态向量的验证方法在复杂任务（如评估程序行为）中更为有效。

Abstract: As quantum computing continues to emerge, ensuring the quality of quantum
programs has become increasingly critical. Quantum program testing has emerged
as a prominent research area within the scope of quantum software engineering.
While numerous approaches have been proposed to address quantum program quality
assurance, our analysis reveals that most existing methods rely on
measurement-based validation in practice. However, due to the inherently
probabilistic nature of quantum programs, measurement-based validation methods
face significant limitations.
  To investigate these limitations, we conducted an empirical study of recent
research on quantum program testing, analyzing measurement-based validation
methods in the literature. Our analysis categorizes existing measurement-based
validation methods into two groups: distribution-level validation and
output-value-level validation. We then compare measurement-based validation
with statevector-based validation methods to evaluate their pros and cons. Our
findings demonstrate that measurement-based validation is suitable for
straightforward assessments, such as verifying the existence of specific output
values, while statevector-based validation proves more effective for
complicated tasks such as assessing the program behaviors.

</details>


### [239] [Incentives and Outcomes in Bug Bounties](https://arxiv.org/abs/2509.16655)
*Serena Wang,Martino Banchio,Krzysztof Kotowicz,Katrina Ligett,R. Preston McAfee,Eduardo' Vela'' Nava*

Main category: cs.SE

TL;DR: 研究发现，Google漏洞奖励计划中奖励金额的增加显著提升了高价值漏洞的提交量，并吸引了新研究人员加入。


<details>
  <summary>Details</summary>
Motivation: 探讨奖励激励在漏洞奖励计划中对产出有用漏洞的影响，填补现有研究的空白。

Method: 通过分析Google漏洞奖励计划（VRP）在2024年7月奖励金额调整后的数据，计算漏洞提交的数量和质量对奖励变化的弹性。

Result: 奖励金额增加后，高价值漏洞的提交量显著上升，且弹性计算显示奖励变化对漏洞提交有直接影响。

Conclusion: 研究发现，奖励金额的增加显著提升了高价值漏洞的提交量，同时吸引了新的顶尖安全研究人员加入，并重新分配了资深研究人员的注意力。

Abstract: Bug bounty programs have contributed significantly to security in technology
firms in the last decade, but little is known about the role of reward
incentives in producing useful outcomes. We analyze incentives and outcomes in
Google's Vulnerability Rewards Program (VRP), one of the world's largest bug
bounty programs. We analyze the responsiveness of the quality and quantity of
bugs received to changes in payments, focusing on a change in Google's reward
amounts posted in July, 2024, in which reward amounts increased by up to 200%
for the highest impact tier. Our empirical results show an increase in the
volume of high-value bugs received after the reward increase, for which we also
compute elasticities. We further break down the sources of this increase
between veteran researchers and new researchers, showing that the reward
increase both redirected the attention of veteran researchers and attracted new
top security researchers into the program.

</details>


### [240] [Verifying User Interfaces using SPARK Ada: A Case Study of the T34 Syringe Driver](https://arxiv.org/abs/2509.16681)
*Peterson Jean*

Main category: cs.SE

TL;DR: 研究利用SPARK Ada形式验证工具开发通用模型，以早期预测和减少医疗设备中的人为因素错误，提高安全性。


<details>
  <summary>Details</summary>
Motivation: 医疗设备制造中的人为因素风险往往在现实测试中才被发现，可能导致严重后果。因此，研究旨在通过形式方法提前预测和减少这些错误，提高安全性。

Method: 研究采用SPARK Ada的形式验证工具对T34注射泵的行为模型进行验证。探索并实现了通用输液泵模型的细化，并在SPARK Ada中实施。通过SPARK评估最终原型的验证级别。

Result: 研究提出了一个通用模型框架，用于在早期开发阶段识别和减少人为因素错误。通过SPARK Ada的形式验证，模型的有效性得到了数学证明。

Conclusion: 通过使用SPARK Ada的形式验证工具，研究提出了一种通用模型，旨在早期开发阶段预测和减少人为因素错误，特别是在医疗设备如T34注射泵中。这种方法为行业安全集成提供了通用框架，并通过形式验证数学证明其有效性。

Abstract: The increase in safety and critical systems improved Healthcare. Due to their
risk of harm, such systems are subject to stringent guidelines and compliances.
These safety measures ensure a seamless experience and mitigate the risk to
end-users. Institutions like the Food and Drug Administration and the NHS,
respectively, established international standards and competency frameworks to
ensure industry compliance with these safety concerns. Medical device
manufacturing is mainly concerned with standards. Consequently, these standards
now advocate for better human factors considered in user interaction for
medical devices. This forces manufacturers to rely on heavy testing and review
to cover many of these factors during development. Sadly, many human factor
risks will not be caught until proper testing in real life, which might be
catastrophic in the case of an ambulatory device like the T34 syringe pump.
Therefore, effort in formal methods research may propose new solutions in
anticipating these errors in the early stages of development or even reducing
their occurrence based on the use of standard generic model. These generically
developed models will provide a common framework for safety integration in
industry and may potentially be proven using formal verification mathematical
proofs. This research uses SPARK Ada's formal verification tool against a
behavioural model of the T34 syringe driver. A Generic Infusion Pump model
refinement is explored and implemented in SPARK Ada. As a subset of the Ada
language, the verification level of the end prototype is evaluated using SPARK.
Exploring potential limitations defines the proposed model's implementation
liability when considering abstraction and components of User Interface design
in SPARK Ada.

</details>


### [241] [RelRepair: Enhancing Automated Program Repair by Retrieving Relevant Code](https://arxiv.org/abs/2509.16701)
*Shunyu Liu,Guangdong Bai,Mark Utting,Guowei Yang*

Main category: cs.SE

TL;DR: RelRepair通过检索项目特定代码增强LLM的自动程序修复能力，显著提升了修复率和准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在自动程序修复中展现出潜力，但其通用预训练特性使其缺乏项目特定修复能力，尤其是在需要理解特定代码库中的标识符、结构和上下文关系时。

Method: RelRepair首先通过分析函数名和代码注释识别相关函数签名，然后进行更深入的代码分析以检索与修复上下文相关的代码片段，并将这些信息整合到LLM的输入提示中。

Result: 在Defects4J V1.2和ManySStuBs4J数据集上，RelRepair分别修复了101个错误，并在ManySStuBs4J上实现了17.1%的修复率提升，总体修复率达到48.3%。

Conclusion: RelRepair通过引入项目特定代码检索，显著提升了LLM在自动程序修复中的表现，验证了提供相关项目信息对LLM的重要性。

Abstract: Automated Program Repair (APR) has emerged as a promising paradigm for
reducing debugging time and improving the overall efficiency of software
development. Recent advances in Large Language Models (LLMs) have demonstrated
their potential for automated bug fixing and other software engineering tasks.
Nevertheless, the general-purpose nature of LLM pre-training means these models
often lack the capacity to perform project-specific repairs, which require
understanding of domain-specific identifiers, code structures, and contextual
relationships within a particular codebase. As a result, LLMs may struggle to
generate correct patches when the repair depends on project-specific
information.
  To address this limitation, we introduce RelRepair, a novel approach that
retrieves relevant project-specific code to enhance automated program repair.
RelRepair first identifies relevant function signatures by analyzing function
names and code comments within the project. It then conducts deeper code
analysis to retrieve code snippets relevant to the repair context. The
retrieved relevant information is then incorporated into the LLM's input
prompt, guiding the model to generate more accurate and informed patches. We
evaluate RelRepair on two widely studied datasets, Defects4J V1.2 and
ManySStuBs4J, and compare its performance against several state-of-the-art
LLM-based APR approaches. RelRepair successfully repairs 101 bugs in Defects4J
V1.2. Furthermore, RelRepair achieves a 17.1\% improvement in the ManySStuBs4J
dataset, increasing the overall fix rate to 48.3\%. These results highlight the
importance of providing relevant project-specific information to LLMs, shedding
light on effective strategies for leveraging LLMs in APR tasks.

</details>


### [242] [Can We Trust the AI Pair Programmer? Copilot for API Misuse Detection and Correction](https://arxiv.org/abs/2509.16795)
*Saikat Mondal,Chanchal K. Roy,Hong Wang,Juan Arguello,Samantha Mathan*

Main category: cs.SE

TL;DR: 研究发现 GitHub Copilot 能高效检测和修复 API 误用（准确率 86.2%），尤其在常见误用类型上表现突出，但复杂案例仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: API 误用会导致安全漏洞、系统故障和维护成本增加，现有检测方法多为开发后静态分析或机器学习工具，存在修复延迟问题。研究旨在评估 AI 编码助手（如 GitHub Copilot）在开发环境中实时检测和修复 API 误用的效果。

Method: 研究使用 MUBench 提供的误用案例基准，构建了 740 个误用示例（手动和 AI 辅助生成）和 147 个正确使用案例，通过集成在 Visual Studio Code 中的 Copilot 进行分析。

Result: Copilot 的检测准确率为 86.2%，精确率为 91.2%，召回率为 92.4%。在常见误用类型（如缺失调用、空检查）上表现优异，但对复合或上下文敏感案例效果较差。成功修复了超过 95% 的检测到误用。

Conclusion: GitHub Copilot 在实时检测和修复 API 误用方面表现出色，准确率达 86.2%，尤其擅长常见误用类型，但在复杂或上下文相关案例中存在局限性。研究强调了 AI 驱动编码助手在软件开发中的潜力与挑战。

Abstract: API misuse introduces security vulnerabilities, system failures, and
increases maintenance costs, all of which remain critical challenges in
software development. Existing detection approaches rely on static analysis or
machine learning-based tools that operate post-development, which delays defect
resolution. Delayed defect resolution can significantly increase the cost and
complexity of maintenance and negatively impact software reliability and user
trust. AI-powered code assistants, such as GitHub Copilot, offer the potential
for real-time API misuse detection within development environments. This study
evaluates GitHub Copilot's effectiveness in identifying and correcting API
misuse using MUBench, which provides a curated benchmark of misuse cases. We
construct 740 misuse examples, manually and via AI-assisted variants, using
correct usage patterns and misuse specifications. These examples and 147
correct usage cases are analyzed using Copilot integrated in Visual Studio
Code. Copilot achieved a detection accuracy of 86.2%, precision of 91.2%, and
recall of 92.4%. It performed strongly on common misuse types (e.g.,
missing-call, null-check) but struggled with compound or context-sensitive
cases. Notably, Copilot successfully fixed over 95% of the misuses it
identified. These findings highlight both the strengths and limitations of
AI-driven coding assistants, positioning Copilot as a promising tool for
real-time pair programming and detecting and fixing API misuses during software
development.

</details>


### [243] [Implementation of the Collision Avoidance System for DO-178C Compliance](https://arxiv.org/abs/2509.16844)
*Rim Zrelli,Henrique Amaral Misson,Sorelle Kamkuimo,Maroua Ben Attia,Abdo Shabah,Felipe Gohring de Magalhaes,Gabriela Nicolescu*

Main category: cs.SE

TL;DR: 该技术报告详细介绍了无人机碰撞避免系统（CAS）的实现，展示了如何通过形式化方法和自动化工具链实现DO-178C合规性，有效解决安全关键软件的认证挑战。


<details>
  <summary>Details</summary>
Motivation: 开发一个符合DO-178C标准的安全关键软件，以支持无人机在民用空域的安全集成。

Method: 结合形式化方法、基于模型的开发以及自动化验证工具（如Alloy、SPIN、Simulink Embedded Coder和LDRA工具套件），涵盖了软件生命周期的每个阶段：需求规范与验证、架构与详细设计、编码、验证和可追溯性。

Result: 形式化建模和自动化工具链能够早期检测和纠正规范缺陷，确保可追溯性，并在所有开发阶段提供强有力的验证和验证证据。静态和动态分析确认了代码质量和覆盖率，形式化验证方法为关键组件提供了数学上的正确性保证。

Conclusion: 尽管集成阶段未完全实现，但该方法在解决无人机安全关键系统认证挑战方面证明是有效的。

Abstract: This technical report presents the detailed implementation of a Collision
Avoidance System (CAS) for Unmanned Aerial Vehicles (UAVs), developed as a case
study to demonstrate a rigorous methodology for achieving DO-178C compliance in
safety-critical software. The CAS is based on functional requirements inspired
by NASA's Access 5 project and is designed to autonomously detect, evaluate,
and avoid potential collision threats in real-time, supporting the safe
integration of UAVs into civil airspace.
  The implementation environment combines formal methods, model-based
development, and automated verification tools, including Alloy, SPIN, Simulink
Embedded Coder, and the LDRA tool suite. The report documents each phase of the
software lifecycle: requirements specification and validation, architectural
and detailed design, coding, verification, and traceability, with a strong
focus on compliance with DO-178C Design Assurance Level B objectives.
  Results demonstrate that formal modelling and automated toolchains enabled
early detection and correction of specification defects, robust traceability,
and strong evidence of verification and validation across all development
stages. Static and dynamic analyses confirmed code quality and coverage, while
formal verification methods provided mathematical assurance of correctness for
critical components. Although the integration phase was not fully implemented,
the approach proved effective in addressing certification challenges for UAV
safety-critical systems.
  \keywords Collision Avoidance System (CAS), Unmanned Aerial Vehicles (UAVs),
DO-178C compliance, Safety-critical software, Formal methods, Model-based
development, Alloy, SPIN model checker, Simulink Embedded Coder, LDRA tool
suite, Software verification and validation, Traceability, Certification.

</details>


### [244] [MobileUPReg: Identifying User-Perceived Performance Regressions in Mobile OS Versions](https://arxiv.org/abs/2509.16864)
*Wei Liu,Yi Wen Heng,Feng Lin,Tse-Hsun,Chen,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: MobileUPReg 是一个检测移动操作系统版本更新中用户感知性能退化的黑盒框架，通过对比用户感知指标实现高准确性和可扩展性，已在工业 CI 中应用。


<details>
  <summary>Details</summary>
Motivation: 现有检测技术依赖系统级指标或特定组件，可能忽略用户实际感知的性能退化（如响应变慢或 UI 卡顿）。

Method: MobileUPReg 是一个黑盒框架，通过在不同操作系统版本上运行相同应用，并比较用户感知的性能指标（如响应时间、完成时间、启动时间和丢帧）来检测回归。

Result: MobileUPReg 在提取用户感知指标和检测回归方面表现出高准确性（精度 0.96，召回率 0.91，F1 分数 0.93），显著优于基于 Wilcoxon 秩和检验和 Cliff's Delta 的统计基线。

Conclusion: MobileUPReg 提供了一种准确、可扩展且与用户感知一致的移动操作系统回归检测方法，已成功应用于工业 CI 流水线。

Abstract: Mobile operating systems (OS) are frequently updated, but such updates can
unintentionally degrade user experience by introducing performance regressions.
Existing detection techniques often rely on system-level metrics (e.g., CPU or
memory usage) or focus on specific OS components, which may miss regressions
actually perceived by users -- such as slower responses or UI stutters. To
address this gap, we present MobileUPReg, a black-box framework for detecting
user-perceived performance regressions across OS versions. MobileUPReg runs the
same apps under different OS versions and compares user-perceived performance
metrics -- response time, finish time, launch time, and dropped frames -- to
identify regressions that are truly perceptible to users. In a large-scale
study, MobileUPReg achieves high accuracy in extracting user-perceived metrics
and detects user-perceived regressions with 0.96 precision, 0.91 recall, and
0.93 F1-score -- significantly outperforming a statistical baseline using the
Wilcoxon rank-sum test and Cliff's Delta. MobileUPReg has been deployed in an
industrial CI pipeline, where it analyzes thousands of screencasts across
hundreds of apps daily and has uncovered regressions missed by traditional
tools. These results demonstrate that MobileUPReg enables accurate, scalable,
and perceptually aligned regression detection for mobile OS validation.

</details>


### [245] [DecipherGuard: Understanding and Deciphering Jailbreak Prompts for a Safer Deployment of Intelligent Software Systems](https://arxiv.org/abs/2509.16870)
*Rui Yang,Michael Fu,Chakkrit Tantithamthavorn,Chetan Arora,Gunel Gulmammadova,Joey Chua*

Main category: cs.SE

TL;DR: DecipherGuard 是一种新型框架，通过解码层和低秩适应机制显著提升 LLM 护栏对混淆和模板攻击的防御效果。


<details>
  <summary>Details</summary>
Motivation: LLM 驱动的智能软件系统在关键领域的部署引发了运行时的安全性担忧，现有护栏（如 LlamaGuard）在混淆和模板攻击下防御成功率下降明显。

Method: DecipherGuard 通过集成解码层来应对混淆攻击，并采用低秩适应机制增强对模板攻击的防御效果。

Result: DecipherGuard 在超过 22,000 条提示的实证评估中，DSR 提升 36% 至 65%，OGP 提升 20% 至 50%。

Conclusion: DecipherGuard 能有效提升 LLM 驱动软件系统在运行时的安全性，显著提高防御成功率（DSR）和整体护栏性能（OGP）。

Abstract: Intelligent software systems powered by Large Language Models (LLMs) are
increasingly deployed in critical sectors, raising concerns about their safety
during runtime. Through an industry-academic collaboration when deploying an
LLM-powered virtual customer assistant, a critical software engineering
challenge emerged: how to enhance a safer deployment of LLM-powered software
systems at runtime? While LlamaGuard, the current state-of-the-art runtime
guardrail, offers protection against unsafe inputs, our study reveals a Defense
Success Rate (DSR) drop of 24% under obfuscation- and template-based jailbreak
attacks. In this paper, we propose DecipherGuard, a novel framework that
integrates a deciphering layer to counter obfuscation-based prompts and a
low-rank adaptation mechanism to enhance guardrail effectiveness against
template-based attacks. Empirical evaluation on over 22,000 prompts
demonstrates that DecipherGuard improves DSR by 36% to 65% and Overall
Guardrail Performance (OGP) by 20% to 50% compared to LlamaGuard and two other
runtime guardrails. These results highlight the effectiveness of DecipherGuard
in defending LLM-powered software systems against jailbreak attacks during
runtime.

</details>


### [246] [Deep Synthetic Cross-Project Approaches for Software Reliability Growth Modeling](https://arxiv.org/abs/2509.16939)
*Taehyoun Kim,Duksan Ryu,Jongmoon Baik*

Main category: cs.SE

TL;DR: DSC-SRGM通过合成数据与跨项目迁移学习结合，显著提升数据稀缺环境下的软件可靠性预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统SRGMs在数据稀缺环境（如早期测试或安全关键系统）中预测准确性下降，且跨项目迁移学习因数据稀缺性和机密性受限。

Method: 提出了一种结合合成数据生成和跨项目迁移学习的新方法DSC-SRGM，包括使用传统SRGMs生成合成数据集，并通过跨相关聚类方法筛选相似模式的数据集来训练深度学习模型。

Result: 在60个真实数据集上评估，DSC-SRGM比传统SRGMs预测准确性提升23.3%，比基于真实数据训练的跨项目深度学习模型提升32.2%。

Conclusion: DSC-SRGM是一种在数据稀缺环境下进行软件可靠性预测的有前途的方法，但需注意保持合成数据与现实数据的适当平衡。

Abstract: Software Reliability Growth Models (SRGMs) are widely used to predict
software reliability based on defect discovery data collected during testing or
operational phases. However, their predictive accuracy often degrades in
data-scarce environments, such as early-stage testing or safety-critical
systems. Although cross-project transfer learning has been explored to mitigate
this issue by leveraging data from past projects, its applicability remains
limited due to the scarcity and confidentiality of real-world datasets. To
overcome these limitations, we propose Deep Synthetic Cross-project SRGM
(DSC-SRGM), a novel approach that integrates synthetic data generation with
cross-project transfer learning. Synthetic datasets are generated using
traditional SRGMs to preserve the statistical characteristics of real-world
defect discovery trends. A cross-correlation-based clustering method is applied
to identify synthetic datasets with patterns similar to the target project.
These datasets are then used to train a deep learning model for reliability
prediction. The proposed method is evaluated on 60 real-world datasets, and its
performance is compared with both traditional SRGMs and cross-project deep
learning models trained on real-world datasets. DSC-SRGM achieves up to 23.3%
improvement in predictive accuracy over traditional SRGMs and 32.2% over
cross-project deep learning models trained on real-world datasets. However,
excessive use of synthetic data or a naive combination of synthetic and
real-world data may degrade prediction performance, highlighting the importance
of maintaining an appropriate data balance. These findings indicate that
DSC-SRGM is a promising approach for software reliability prediction in
data-scarce environments.

</details>


### [247] [SWE-Bench Pro: Can AI Agents Solve Long-Horizon Software Engineering Tasks?](https://arxiv.org/abs/2509.16941)
*Xiang Deng,Jeff Da,Edwin Pan,Yannis Yiming He,Charles Ide,Kanak Garg,Niklas Lauffer,Andrew Park,Nitin Pasari,Chetan Rane,Karmini Sampath,Maya Krishnan,Srivatsa Kundurthy,Sean Hendryx,Zifan Wang,Chen Bo Calvin Zhang,Noah Jacobson,Bing Liu,Brad Kenstler*

Main category: cs.SE

TL;DR: SWE-Bench PRO是一个更复杂、更真实的软件工程基准，测试结果显示当前模型的性能仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有的SWE-BENCH基准无法完全捕捉现实中的复杂企业级问题，因此需要设计一个更具挑战性的基准。

Method: 构建了一个包含1,865个问题的基准，这些问题来自41个活跃维护的仓库，分为公开集、保留集和商业集。所有任务均经过人工验证并提供了足够的上下文。

Result: 广泛使用的编码模型在SWE-Bench PRO上的表现低于25%（Pass@1），GPT-5以23.3%的成绩为当前最高。

Conclusion: SWE-BENCH PRO提供了一个更接近真实软件开发复杂性和多样性的测试平台，推动了专业级自主软件工程代理的发展。

Abstract: We introduce SWE-Bench Pro, a substantially more challenging benchmark that
builds upon the best practices of SWE-BENCH [25], but is explicitly designed to
capture realistic, complex, enterprise-level problems beyond the scope of
SWE-BENCH. SWE-BENCH PRO contains 1,865 problems sourced from a diverse set of
41 actively maintained repositories spanning business applications, B2B
services, and developer tools. The benchmark is partitioned into a public set
with open access to problems sourced from 11 repositories, a held-out set of 12
repositories and a commercial set of 18 proprietary repositories where we have
formal partnership agreements with early-stage startups. Problems in the
held-out and the commercial set are not publicly accessible, but we release
results on the commercial set. Our benchmark features long-horizon tasks that
may require hours to days for a professional software engineer to complete,
often involving patches across multiple files and substantial code
modifications. All tasks are human-verified and augmented with sufficient
context to ensure resolvability. In our evaluation of widely used coding
models, under a unified scaffold, we observe that their performance on
SWE-Bench PRO remains below 25% (Pass@1), with GPT-5 achieving the highest
score to date at 23.3%. To better understand these limitations, we cluster the
failure modes observed in the collected agent trajectories for a clearer
characterization of the error patterns exhibited by current models. Overall,
SWE-BENCH PRO provides a contamination-resistant testbed that more faithfully
captures the complexity and diversity of real-world software development,
advancing the pursuit of truly autonomous software engineering agents at a
professional level.

</details>


### [248] [Static Security Vulnerability Scanning of Proprietary and Open-Source Software: An Adaptable Process with Variants and Results](https://arxiv.org/abs/2509.16985)
*James J. Cusick*

Main category: cs.SE

TL;DR: 本文提出了一种端到端的漏洞扫描与修复流程，结合特定工具，有效减少代码漏洞并提升安全性，适用于各类软件环境。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞是软件开发组织实现安全目标的主要风险因素，尤其是在使用专有或开源软件的环境中。

Method: 提出了一种端到端的流程，包括支持方法和工具，用于定制化、配置和执行常规代码扫描以及漏洞的优先级修复。

Result: 通过工业验证的通用流程，结合选定工具，成功应用于专有和开源应用程序，展示了具体漏洞实例及其处理方法。

Conclusion: 采用该方法可以最小化调整并最大化灵活性，有效减少源代码漏洞、降低供应链风险，并提升新旧解决方案的安全性能。

Abstract: Software vulnerabilities remain a significant risk factor in achieving
security objectives within software development organizations. This is
especially true where either proprietary or open-source software (OSS) is
included in the technological environment. In this paper an end-to-end process
with supporting methods and tools is presented. This industry proven generic
process allows for the custom instantiation, configuration, and execution of
routinized code scanning for software vulnerabilities and their prioritized
remediation. A select set of tools are described for this key DevSecOps
function and placed into an iterative process. Examples of both industrial
proprietary applications and open-source applications are provided including
specific vulnerability instances and a discussion of their treatment. The
benefits of each selected tool are considered, and alternative tools are also
introduced. Application of this method in a comprehensive SDLC model is also
reviewed along with prospective enhancements from automation and the
application of advanced technologies including AI. Adoption of this method can
be achieved with minimal adjustments and with maximum flexibility for results
in reducing source code vulnerabilities, reducing supply chain risk, and
improving the security profile of new or legacy solutions.

</details>


### [249] [Prompt-with-Me: in-IDE Structured Prompt Management for LLM-Driven Software Engineering](https://arxiv.org/abs/2509.17096)
*Ziyou Li,Agnia Sergeyuk,Maliheh Izadi*

Main category: cs.SE

TL;DR: Prompt-with-Me是一个嵌入开发环境的提示管理系统，通过分类和优化功能提升提示的可靠性和重用性，用户研究证实了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程中的应用日益广泛，但提示管理在实践中仍缺乏系统性，影响了可靠性、重用性和工业工作流的集成。

Method: 系统通过四维分类法自动分类提示，包括意图、作者角色、软件开发生命周期阶段和提示类型，并提供语言优化、敏感信息屏蔽和可重用模板提取功能。

Result: 对1108个真实世界提示的分类研究表明，现代LLM能准确分类软件工程提示；用户研究（11名参与者）显示高可用性（平均SUS=73）、低认知负荷（平均NASA-TLX=21），并报告了提示质量和效率的提升。

Conclusion: 论文提出了Prompt-with-Me系统，为软件工程中的提示管理提供了实用解决方案，并通过用户研究验证了其高可用性和低认知负荷，为下一代提示管理工具的开发提供了可操作的见解。

Abstract: Large Language Models are transforming software engineering, yet prompt
management in practice remains ad hoc, hindering reliability, reuse, and
integration into industrial workflows. We present Prompt-with-Me, a practical
solution for structured prompt management embedded directly in the development
environment. The system automatically classifies prompts using a
four-dimensional taxonomy encompassing intent, author role, software
development lifecycle stage, and prompt type. To enhance prompt reuse and
quality, Prompt-with-Me suggests language refinements, masks sensitive
information, and extracts reusable templates from a developer's prompt library.
Our taxonomy study of 1108 real-world prompts demonstrates that modern LLMs can
accurately classify software engineering prompts. Furthermore, our user study
with 11 participants shows strong developer acceptance, with high usability
(Mean SUS=73), low cognitive load (Mean NASA-TLX=21), and reported gains in
prompt quality and efficiency through reduced repetitive effort. Lastly, we
offer actionable insights for building the next generation of prompt management
and maintenance tools for software engineering workflows.

</details>


### [250] [Clotho: Measuring Task-Specific Pre-Generation Test Adequacy for LLM Inputs](https://arxiv.org/abs/2509.17314)
*Juyeon Yoon,Somin Kim,Robert Feldt,Shin Yoo*

Main category: cs.SE

TL;DR: CLOTHO通过GMM和隐藏状态分析，高效预测LLM输入失败可能性，降低成本并提升测试效率，适用性可扩展至专有模型。


<details>
  <summary>Details</summary>
Motivation: 测试大型语言模型（LLM）在特定任务上的表现既困难又昂贵，现有方法依赖人工判断或需要完整推理，亟需一种能反映任务需求的输入充分性评估方法。

Method: 利用高斯混合模型（GMM）自适应采样最具信息量的案例进行人工标注，基于参考集对未见输入按失败可能性排序。

Result: 在八个基准任务和三个开源权重LLM上，CLOTHO以0.716的ROC-AUC预测失败，仅需标注平均5.4%的输入，且无需生成输出。专有模型测试中，失败输入数量从18.7提升至42.5（每100个输入）。

Conclusion: CLOTHO作为一种任务特定的预生成充分性度量，能够有效预测LLM输入失败的可能性，显著提升测试效率并降低成本，且其适用性可扩展至专有模型。

Abstract: Software increasingly relies on the emergent capabilities of Large Language
Models (LLMs), from natural language understanding to program analysis and
generation. Yet testing them on specific tasks remains difficult and costly:
many prompts lack ground truth, forcing reliance on human judgment, while
existing uncertainty and adequacy measures typically require full inference. A
key challenge is to assess input adequacy in a way that reflects the demands of
the task, ideally before even generating any output. We introduce CLOTHO, a
task-specific, pre-generation adequacy measure that estimates input difficulty
directly from hidden LLM states. Given a large pool of unlabelled inputs for a
specific task, CLOTHO uses a Gaussian Mixture Model (GMM) to adaptively sample
the most informative cases for human labelling. Based on this reference set the
GMM can then rank unseen inputs by their likelihood of failure. In our
empirical evaluation across eight benchmark tasks and three open-weight LLMs,
CLOTHO can predict failures with a ROC-AUC of 0.716, after labelling reference
sets that are on average only 5.4% of inputs. It does so without generating any
outputs, thereby reducing costs compared to existing uncertainty measures.
Comparison of CLOTHO and post-generation uncertainty measures shows that the
two approaches complement each other. Crucially, we show that adequacy scores
learnt from open-weight LLMs transfer effectively to proprietary models,
extending the applicability of the approach. When prioritising test inputs for
proprietary models, CLOTHO increases the average number of failing inputs from
18.7 to 42.5 out of 100, compared to random prioritisation.

</details>


### [251] [BASFuzz: Towards Robustness Evaluation of LLM-based NLP Software via Automated Fuzz Testing](https://arxiv.org/abs/2509.17335)
*Mingxuan Xiao,Yan Xiao,Shunhui Ji,Jiahe Tu,Pengcheng Zhang*

Main category: cs.SE

TL;DR: BASFuzz是一种针对LLM-based NLP软件的高效模糊测试方法，通过优化测试输入和算法显著提升测试效果和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在LLM-based NLP软件的测试中行为模式耦合不足，且自然语言生成（NLG）场景的模糊测试能力下降。

Method: BASFuzz采用Beam-Annealing Search算法，结合信息熵自适应调整和精英策略，优化了模糊测试循环。

Result: 在NLG和NLU场景的六个数据集上，BASFuzz测试效果达90.335%，平均时间开销减少2163.852秒。

Conclusion: BASFuzz通过针对LLM-based NLP软件的完整测试输入和一致性度量引导的变异，显著提高了测试效率和效果，减少了时间开销。

Abstract: Fuzzing has shown great success in evaluating the robustness of intelligent
natural language processing (NLP) software. As large language model (LLM)-based
NLP software is widely deployed in critical industries, existing methods still
face two main challenges: 1 testing methods are insufficiently coupled with the
behavioral patterns of LLM-based NLP software; 2 fuzzing capability for the
testing scenario of natural language generation (NLG) generally degrades. To
address these issues, we propose BASFuzz, an efficient Fuzz testing method
tailored for LLM-based NLP software. BASFuzz targets complete test inputs
composed of prompts and examples, and uses a text consistency metric to guide
mutations of the fuzzing loop, aligning with the behavioral patterns of
LLM-based NLP software. A Beam-Annealing Search algorithm, which integrates
beam search and simulated annealing, is employed to design an efficient fuzzing
loop. In addition, information entropy-based adaptive adjustment and an elitism
strategy further enhance fuzzing capability. We evaluate BASFuzz on six
datasets in representative scenarios of NLG and natural language understanding
(NLU). Experimental results demonstrate that BASFuzz achieves a testing
effectiveness of 90.335% while reducing the average time overhead by 2,163.852
seconds compared to the current best baseline, enabling more effective
robustness evaluation prior to software deployment.

</details>


### [252] [SLICET5: Static Program Slicing using Language Models with Copy Mechanism and Constrained Decoding](https://arxiv.org/abs/2509.17338)
*Pengfei He,Shaowei Wang,Tse-Hsun Chen*

Main category: cs.SE

TL;DR: \ourtool 通过复制机制和约束解码改进了静态程序切片，显著提升准确性，尤其适用于不完整代码。


<details>
  <summary>Details</summary>
Motivation: 传统静态切片工具依赖完整源代码解析，限制了在不完整或不可解析代码片段中的应用。现有学习方法的依赖关系识别不准确且生成过程缺乏约束，导致切片结构完整性受损。

Method: \ourtool 将静态程序切片重新定义为序列到序列任务，采用轻量级语言模型（如 CodeT5+），并结合复制机制和约束解码（包括词汇约束和句法约束）来优化依赖关系识别和生成约束。

Result: 在 CodeNet 和 LeetCode 数据集上的评估显示，\ourtool 在 ExactMatch 分数上比现有最佳基线提升高达 27%，并在不完整代码上表现良好。

Conclusion: \ourtool 通过引入复制机制和约束解码过程，显著提升了静态程序切片的准确性，特别是在处理不完整代码时表现出色，展示了其在现实开发环境中的实用性和鲁棒性。

Abstract: Static program slicing is a fundamental technique in software engineering.
Traditional static slicing tools rely on parsing complete source code, which
limits their applicability to real-world scenarios where code snippets are
incomplete or unparsable. While recent research developed learning-based
approaches to predict slices, they face critical challenges: (1) Inaccurate
dependency identification, where models fail to precisely capture data and
control dependencies between code elements; and (2) Unconstrained generation,
where models produce slices with extraneous or hallucinated tokens not present
in the input, violating the structural integrity of slices. To address these
challenges, we propose \ourtool, a novel slicing framework that reformulates
static program slicing as a sequence-to-sequence task using lightweight
language models (e.g., CodeT5+). Our approach incorporates two key innovations.
First, we introduce a copy mechanism that enables the model to more accurately
capture inter-element dependencies and directly copy relevant tokens from the
input, improving both dependency reasoning and generation constraint. Second,
we design a constrained decoding process with (a) lexical constraint,
restricting outputs to input tokens only, and (b) syntactic constraint,
leveraging Tree Similarity of Edit Distance (TSED) monotonicity to detect
structurally invalid outputs and discard them. We evaluate \ourtool on CodeNet
and LeetCode datasets and show it consistently outperforms state-of-the-art
baselines, improving ExactMatch scores by up to 27\%. Furthermore, \ourtool
demonstrates strong performance on incomplete code, highlighting its robustness
and practical utility in real-world development environments.

</details>


### [253] [Prompts as Software Engineering Artifacts: A Research Agenda and Preliminary Findings](https://arxiv.org/abs/2509.17548)
*Hugo Villamizar,Jannik Fischbach,Alexander Korn,Andreas Vogelsang,Daniel Mendez*

Main category: cs.SE

TL;DR: 该论文通过调查揭示了SE中提示使用的临时性现状，提出了系统化管理的必要性，并为进一步研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM集成工作流中提示的使用和管理现状，以及系统化管理的潜在益处是否超过相关努力。

Method: 通过一项探索性调查，收集了来自六个国家的74名软件专业人士的数据，分析当前的提示实践和挑战。

Result: 调查结果显示，提示在SE中的使用多为临时性，通过试错法改进，很少重复使用，且更多依赖个人经验而非标准化实践。

Conclusion: 研究发现当前SE中的提示使用主要是临时性的，缺乏系统性管理，强调了开发更系统化提示管理方法的必要性。

Abstract: Developers now routinely interact with large language models (LLMs) to
support a range of software engineering (SE) tasks. This prominent role
positions prompts as potential SE artifacts that, like other artifacts, may
require systematic development, documentation, and maintenance. However, little
is known about how prompts are actually used and managed in LLM-integrated
workflows, what challenges practitioners face, and whether the benefits of
systematic prompt management outweigh the associated effort. To address this
gap, we propose a research programme that (a) characterizes current prompt
practices, challenges, and influencing factors in SE; (b) analyzes prompts as
software artifacts, examining their evolution, traceability, reuse, and the
trade-offs of systematic management; and (c) develops and empirically evaluates
evidence-based guidelines for managing prompts in LLM-integrated workflows. As
a first step, we conducted an exploratory survey with 74 software professionals
from six countries to investigate current prompt practices and challenges. The
findings reveal that prompt usage in SE is largely ad-hoc: prompts are often
refined through trial-and-error, rarely reused, and shaped more by individual
heuristics than standardized practices. These insights not only highlight the
need for more systematic approaches to prompt management but also provide the
empirical foundation for the subsequent stages of our research programme.

</details>


### [254] [From OCL to JSX: declarative constraint modeling in modern SaaS tools](https://arxiv.org/abs/2509.17629)
*Antonio Bucchiarone,Juri Di Rocco,Damiano Di Vincenzo,Alfonso Pierantonio*

Main category: cs.SE

TL;DR: 本文探讨了JSX作为OCL.js替代方案在建模环境中的约束表达，实证评估显示JSX在表达能力和前端适配性上更优。


<details>
  <summary>Details</summary>
Motivation: 探讨JSX作为OCL.js的替代方案，解决OCL.js在标准覆盖不全、采用有限及与现代前端工具链集成弱的问题。

Method: 通过实证评估，比较JSX-based约束与OCL.js在代表性建模场景中的表现。

Result: JSX提供了更广泛的表达能力和更好的前端架构适配性。

Conclusion: JSX作为一种约束表达方式在现代建模工具中展现出更广泛的表达能力和更好的前端架构适配性，为建模工具中的约束规范提供了有前景的路径。

Abstract: The rise of Node.js in 2010, followed by frameworks like Angular, React, and
Vue.js, has accelerated the growth of low code development platforms. These
platforms harness modern UIX paradigms, component-based architectures, and the
SaaS model to enable non-experts to build software. The widespread adoption of
single-page applications (SPAs), driven by these frameworks, has shaped
low-code tools to deliver responsive, client side experiences. In parallel,
many modeling platforms have moved to the cloud, adopting either server-centric
architectures (e.g., GSLP) or client-side intelligence via SPA frameworks,
anchoring core components in JavaScript or TypeScript. Within this context,
OCL.js, a JavaScript-based implementation of the Object Constraint Language,
offers a web aligned approach to model validation, yet faces challenges such as
partial standard coverage, limited adoption, and weak integration with modern
front-end toolchains. In this paper, we explore JSX, a declarative, functional
subset of JavaScript/TypeScript used in the React ecosystem, as an alternative
to constraint expression in SaaS-based modeling environments. Its
component-oriented structure supports inductive definitions for syntax, code
generation, and querying. Through empirical evaluation, we compare JSX-based
constraints with OCL.js across representative modeling scenarios. Results show
JSX provides broader expressiveness and better fits front-end-first
architectures, indicating a promising path for constraint specification in
modern modeling tools.

</details>


### [255] [Diagnosing Violations of State-based Specifications in iCFTL](https://arxiv.org/abs/2509.17776)
*Cristina Stratan,Claudio Mandrioli,Domenico Bianculli*

Main category: cs.SE

TL;DR: 本文提出了一种诊断方法，通过后向数据流分析和程序插桩生成增强的执行轨迹，高效识别导致iCFTL规范违反的语句，实验验证了其高精度和低开销。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统在动态环境中运行，运行时验证的布尔或定量裁决在规范违反时往往不足以理解原因，需要更信息化的诊断方法。

Method: 采用后向数据流分析静态确定导致规范违反的相关语句，并通过程序插桩生成增强的执行轨迹，进而进行运行时分析。

Result: 原型工具iCFTL-Diagnostics在112个规范中的100个上实现了90%的精确度，诊断时间在7分钟内，内存占用不超过25MB，插桩带来的执行时间开销低于30%，内存开销低于20%。

Conclusion: 本文提出了一种基于后向数据流分析的诊断方法，用于生成违反iCFTL规范的信息性裁决，并通过实验验证了其高效性和实用性。

Abstract: As modern software systems grow in complexity and operate in dynamic
environments, the need for runtime analysis techniques becomes a more critical
part of the verification and validation process. Runtime verification monitors
the runtime system behaviour by checking whether an execution trace - a
sequence of recorded events - satisfies a given specification, yielding a
Boolean or quantitative verdict. However, when a specification is violated,
such a verdict is often insufficient to understand why the violation happened.
To fill this gap, diagnostics approaches aim to produce more informative
verdicts. In this paper, we address the problem of generating informative
verdicts for violated Inter-procedural Control-Flow Temporal Logic (iCFTL)
specifications that express constraints over program variable values. We
propose a diagnostic approach based on backward data-flow analysis to
statically determine the relevant statements contributing to the specification
violation. Using this analysis, we instrument the program to produce enriched
execution traces. Using the enriched execution traces, we perform the runtime
analysis and identify the statements whose execution led to the specification
violation. We implemented our approach in a prototype tool, iCFTL-Diagnostics,
and evaluated it on 112 specifications across 10 software projects. Our tool
achieves 90% precision in identifying relevant statements for 100 of the 112
specifications. It reduces the number of lines that have to be inspected for
diagnosing a violation by at least 90%. In terms of computational cost,
iCFTL-Diagnostics generates a diagnosis within 7 min, and requires no more than
25 MB of memory. The instrumentation required to support diagnostics incurs an
execution time overhead of less than 30% and a memory overhead below 20%.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [256] [WarpSpeed: A High-Performance Library for Concurrent GPU Hash Tables](https://arxiv.org/abs/2509.16407)
*Hunter McCoy,Prashant Pandey*

Main category: cs.DC

TL;DR: WarpSpeed是一个高性能并发GPU哈希表库，解决了现有GPU哈希表的功能限制，通过优化技术提升了性能，并在实际应用中验证了效果。


<details>
  <summary>Details</summary>
Motivation: GPU哈希表功能有限，缺乏完整并发支持和复合操作（如upserts），限制了其在大规模数据处理中的应用。

Method: WarpSpeed实现了八种先进的Nvidia GPU哈希表设计，提供了丰富的API，并采用指纹元数据减少缓存行探测，以及专用Nvidia GPU指令实现无锁查询。

Result: 评估显示WarpSpeed在多样化的基准测试中正确性和可扩展性表现出色，并成功集成到三个下游应用中。

Conclusion: WarpSpeed提供了对现代GPU应用中高效、可扩展数据结构的实用指导，并提出了新的并发GPU哈希表设计见解。

Abstract: GPU hash tables are increasingly used to accelerate data processing, but
their limited functionality restricts adoption in large-scale data processing
applications. Current limitations include incomplete concurrency support and
missing compound operations such as upserts.
  This paper presents WarpSpeed, a library of high-performance concurrent GPU
hash tables with a unified benchmarking framework for performance analysis.
WarpSpeed implements eight state-of-the-art Nvidia GPU hash table designs and
provides a rich API designed for modern GPU applications. Our evaluation uses
diverse benchmarks to assess both correctness and scalability, and we
demonstrate real-world impact by integrating these hash tables into three
downstream applications.
  We propose several optimization techniques to reduce concurrency overhead,
including fingerprint-based metadata to minimize cache line probes and
specialized Nvidia GPU instructions for lock-free queries. Our findings provide
new insights into concurrent GPU hash table design and offer practical guidance
for developing efficient, scalable data structures on modern GPUs.

</details>


### [257] [Shift Parallelism: Low-Latency, High-Throughput LLM Inference for Dynamic Workloads](https://arxiv.org/abs/2509.16495)
*Mert Hidayetoglu,Aurick Qiao,Michael Wyatt,Jeff Rasley,Yuxiong He,Samyam Rajbhandari*

Main category: cs.DC

TL;DR: Shift Parallelism 结合 TP 和 SP，动态切换以优化延迟和吞吐量，在交互式和批量工作负载中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的 TP 和 DP 方法各有优缺点，无法结合使用，因为 KV 缓存在不同并行方法中存在差异。SP 具有与 DP 相似的特性但 KV 缓存不变，因此可以结合 TP 和 SP 以实现最佳效果。

Method: 通过将 Sequence Parallelism（SP）适应到推理中，并与 Tensor Parallelism（TP）结合，提出 Shift Parallelism 动态切换 TP 和 SP。

Result: Shift Parallelism 在交互式工作负载中响应速度提升 1.51 倍，在批量工作负载中吞吐量提高 50%，并且在动态工作负载中实现了低延迟而不降低吞吐量。

Conclusion: Shift Parallelism 通过动态切换 TP 和 SP，在低流量时最小化延迟，同时在高流量时不损失吞吐量，实现了比单独使用 TP 或 DP 更好的延迟与吞吐量权衡。

Abstract: Efficient parallelism is necessary for achieving low-latency, high-throughput
inference with large language models (LLMs). Tensor parallelism (TP) is the
state-of-the-art method for reducing LLM response latency, however GPU
communications reduces combined token throughput. On the other hand, data
parallelism (DP) obtains a higher throughput yet is slow in response latency.
Best of both worlds does not exist, and it is not possible to combine TP and DP
because of the KV cache variance across the parallelisms.
  We notice Sequence Parallelism (SP - Ulysses in training) has similar
properties as DP but with KV cache invariance. We adapt SP to inference, and
combine it with TP to get the best of both worlds. Our solution: Shift
Parallelism.
  Shift Parallelism dynamically switches across TP and SP, and minimizes
latency in low traffic without losing throughput in high traffic. The efficient
GPU communications of Shift Parallelism yields up to i) 1.51x faster response
in interactive workloads and ii) 50% higher throughput in batch workloads,
compared to a TP-only solution.
  We evaluate Shift Parallelism with real-world production traces with dynamic
traffic patterns as well as synthetic benchmarking patterns across models,
context sizes, and arrival rates. All results affirm the same: Shift
Parallelism has a better the latency vs. throughput tradeoff than TP or DP, and
hence obtains low latency without degrading throughput in dynamic workloads.

</details>


### [258] [sat-QFL: Secure Quantum Federated Learning for Low Orbit Satellites](https://arxiv.org/abs/2509.16504)
*Dev Gurung,Shiva Raj Pokhrel*

Main category: cs.DC

TL;DR: sat-QFL是一个针对低地球轨道星座的分层量子联邦学习框架，通过角色划分和训练调度解决连接问题，并集成量子密钥分发确保安全。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道星座中的标准量子联邦学习方法无法应对连接不稳定、参与时间变化和严格延迟预算的挑战。

Method: sat-QFL将卫星分为主要（地面连接）和次要（仅卫星间链接）角色，并根据可见窗口安排顺序、同步或异步的边缘训练。

Result: 使用星座轨迹和量子联邦学习工作负载的测试表明，sat-QFL在不同参与情况下保持稳健的聚合，并减少了通信瓶颈，安全性开销适中。

Conclusion: sat-QFL框架通过分层和访问感知的量子联邦学习方法，有效解决了低地球轨道星座中的连接不稳定、参与时间变化和严格延迟预算问题，同时通过量子密钥分发和认证加密确保了模型交换的保密性和完整性。

Abstract: Low Earth orbit (LEO) constellations violate core assumptions of standard
(quantum) federated learning (FL): client-server connectivity is intermittent,
participation is time varying, and latency budgets are strict. We present
sat-QFL, a hierarchical, access aware quantum federated learning (QFL)
framework that partitions satellites into primary (ground connected) and
secondary as inter-satellite links (ISL-only) roles, and schedules sequential,
simultaneous, or asynchronous edge training aligned with visibility windows.
For quantum-resilient confidentiality and integrity, sat-QFL integrates quantum
key distribution (QKD) based key establishment with authenticated encryption
for model exchange; we also assess teleportation as a feasibility primitive for
quantum state transfer. Using derived constellation traces and QFL workloads
(Qiskit), we show that sat-QFL sustains robust aggregation under varying
participation and reduces communication bottlenecks with modest security
overhead. Our implementation and results are available at
https://github.com/s222416822/satQFL.

</details>


### [259] [orb-QFL: Orbital Quantum Federated Learning](https://arxiv.org/abs/2509.16505)
*Dev Gurung,Shiva Raj Pokhrel*

Main category: cs.DC

TL;DR: orb-QFL是一种面向LEO卫星星座的量子辅助联邦学习框架，利用量子纠缠解决轨道动态问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量子计算的突破为非地面环境中的联邦学习提供了新机遇，尤其是在通信和协调受限的LEO卫星星座中。

Method: 结合Qiskit量子机器学习工具包和Poliastro轨道模拟，使用Statlog数据集进行实验验证。

Result: orb-QFL框架通过量子同步提升了模型的连续性和数据局部性，增强了系统的韧性。

Conclusion: orb-QFL通过量子纠缠和本地量子处理，实现了去中心化的卫星间协作，有效解决了轨道动态中的连接性和延迟问题，为LEO卫星星座的联邦学习提供了创新解决方案。

Abstract: Recent breakthroughs in quantum computing present transformative
opportunities for advancing Federated Learning (FL), particularly in
non-terrestrial environments characterized by stringent communication and
coordination constraints. In this study, we propose orbital QFL, termed
orb-QFL, a novel quantum-assisted Federated Learning framework tailored for Low
Earth Orbit (LEO) satellite constellations. Distinct from conventional FL
paradigms, termed orb-QFL operates without centralized servers or global
aggregation mechanisms (e.g., FedAvg), instead leveraging quantum entanglement
and local quantum processing to facilitate decentralized, inter-satellite
collaboration. This design inherently addresses the challenges of orbital
dynamics, such as intermittent connectivity, high propagation delays, and
coverage variability. The framework enables continuous model refinement through
direct quantum-based synchronization between neighboring satellites, thereby
enhancing resilience and preserving data locality. To validate our approach, we
integrate the Qiskit quantum machine learning toolkit with Poliastro-based
orbital simulations and conduct experiments using Statlog dataset.

</details>


### [260] [Trace Replay Simulation of MIT SuperCloud for Studying Optimal Sustainability Policies](https://arxiv.org/abs/2509.16513)
*Wesley Brewer,Matthias Maiterth,Damien Fay*

Main category: cs.DC

TL;DR: 论文扩展了ExaDigiT框架，用于模拟超级计算机的电力、冷却和调度，支持可持续性政策的强化学习实验。


<details>
  <summary>Details</summary>
Motivation: AI超级计算的快速增长带来了前所未有的电力需求，需要解决由此产生的公用事业和系统运营商挑战。

Method: 扩展ExaDigiT框架，纳入异质性、多租户和云规模工作负载，专注于MIT SuperCloud TX-GAIA系统的跟踪重放和作业重新调度。

Result: 初步强化学习实验证明了学习能源感知调度决策的可行性。

Conclusion: ExaDigiT有潜力作为探索优化策略的平台，以提高吞吐量、效率和可持续性。

Abstract: The rapid growth of AI supercomputing is creating unprecedented power
demands, with next-generation GPU datacenters requiring hundreds of megawatts
and producing fast, large swings in consumption. To address the resulting
challenges for utilities and system operators, we extend ExaDigiT, an
open-source digital twin framework for modeling power, cooling, and scheduling
of supercomputers. Originally developed for replaying traces from
leadership-class HPC systems, ExaDigiT now incorporates heterogeneity,
multi-tenancy, and cloud-scale workloads. In this work, we focus on trace
replay and rescheduling of jobs on the MIT SuperCloud TX-GAIA system to enable
reinforcement learning (RL)-based experimentation with sustainability policies.
The RAPS module provides a simulation environment with detailed power and
performance statistics, supporting the study of scheduling strategies,
incentive structures, and hardware/software prototyping. Preliminary RL
experiments using Proximal Policy Optimization demonstrate the feasibility of
learning energy-aware scheduling decisions, highlighting ExaDigiT's potential
as a platform for exploring optimal policies to improve throughput, efficiency,
and sustainability.

</details>


### [261] [ShadowServe: Interference-Free KV Cache Fetching for Distributed Prefix Caching](https://arxiv.org/abs/2509.16857)
*Xingyu Xiang,Raj Joshi,Yuhan Liu,Jiayi Yao,Chenxingyu Zhao,Junchen Jiang,Yang Zhou,Eddie Kohler,Minlan Yu*

Main category: cs.DC

TL;DR: ShadowServe是一种SmartNIC加速的前缀缓存系统，通过无干扰设计和资源优化，显著提升LLM服务性能。


<details>
  <summary>Details</summary>
Motivation: 分布式前缀缓存在网络带宽有限时可能成为瓶颈，压缩虽缓解带宽问题但可能干扰模型计算。

Method: 设计了一个分块管道，并行化SmartNIC上的数据平面操作，并采用最小拷贝内存管理方案减轻SmartNIC的内存压力。

Result: 与现有方案相比，ShadowServe在低带宽场景下实现了更低的延迟和更高的吞吐量。

Conclusion: ShadowServe通过SmartNIC加速和无干扰设计，显著提升了LLM服务的性能，降低了延迟并提高了吞吐量。

Abstract: Distributed prefix caching accelerates long-context LLM serving by reusing KV
cache entries for common context prefixes. However, KV cache fetches can become
a bottleneck when network bandwidth is limited. Compression mitigates the
bandwidth issue, but can degrade overall performance when decompression
interferes with model computation.
  We present ShadowServe, the first SmartNIC-accelerated, interference-free
prefix caching system for LLM serving. ShadowServe separates a control plane on
the host and a data plane fully offloaded to the SmartNIC, which eliminates
interference to both host GPU and CPU. To overcome the SmartNIC's limited
compute and memory resources, we design a chunked pipeline that parallelizes
data plane operations across the SmartNIC's compute resources, and a
minimal-copy memory management scheme that reduces memory pressure on the
SmartNIC. Compared to state-of-the-art solutions, ShadowServe achieves up to
2.2x lower loaded time-per-output-token (TPOT), and reduces time-to-first-token
(TTFT) by up to 1.38x in low-bandwidth scenarios (<= 20 Gbps), translating to
up to 1.35x higher throughput.

</details>


### [262] [MoA-Off: Adaptive Heterogeneous Modality-Aware Offloading with Edge-Cloud Collaboration for Efficient Multimodal LLM Inference](https://arxiv.org/abs/2509.16995)
*Zheming Yang,Qi Guo,Yunqing Hu,Chang Zhao,Chang Zhang,Jian Zhao,Wen Ji*

Main category: cs.DC

TL;DR: MoA-Off通过模态感知和边缘-云协作，显著提升MLLMs在资源受限环境中的效率，降低延迟和资源消耗。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在资源受限环境中的计算和延迟负担严重，需要高效推理解决方案。

Method: 引入轻量级异构模态感知模块进行多维特征分析，并提出自适应的边缘-云协作卸载策略。

Result: 实验表明，MoA-Off能降低30%的延迟和30%-65%的资源开销，同时保持竞争力准确性。

Conclusion: MoA-Off框架通过边缘-云协作的模态感知卸载策略，显著降低了延迟和资源开销，同时保持了与传统方法相当的准确性。

Abstract: Multimodal large language models (MLLMs) enable powerful cross-modal
inference but impose significant computational and latency burdens, posing
severe challenges for deployment in resource-constrained environments. In this
paper, we propose MoA-Off, an adaptive heterogeneous modality-aware offloading
framework with edge-cloud collaboration for efficient MLLM inference. MoA-Off
introduces a lightweight heterogeneous modality-aware module that estimates the
complexity of heterogeneous inputs through multi-dimensional feature analysis.
Then, an adaptive edge-cloud collaborative offloading strategy is proposed that
dynamically schedules workloads between edge and cloud based on modality-aware
complexity scores and real-time system states. The experimental results
demonstrate that MoA-Off can achieve over 30% reduction in latency and 30%-65%
decrease in resource overhead while maintaining competitive accuracy compared
to traditional approaches.

</details>


### [263] [Institutional Research Computing Capabilities in Australia: 2024](https://arxiv.org/abs/2509.17351)
*Slava Kitaeff,Luc Betbeder-Matibet,Jake Carroll,Stephen Giugni,David Abramson,John Zaitseff,Sarah Walters,David Powell,Chris Bording,Trung Nguyen,Angus Macoustra,Fabien Voisin,Bowen Chen,Jarrod Hurley*

Main category: cs.DC

TL;DR: 澳大利亚机构研究计算基础设施对国家研究生态系统至关重要，支持数据密集型项目、培训和学生研究，并填补国家系统无法满足的需求。


<details>
  <summary>Details</summary>
Motivation: 探讨机构计算系统如何通过本地计算资源、专用硬件和集群解决方案支持研究卓越，并填补国家系统无法满足的特定需求。

Method: 通过分析澳大利亚大学和组织的详细数据，研究部署、利用以及与研究优先事项的战略对齐模式。

Result: 研究发现，近112,258个CPU核心和2,241个GPU为超过6,000名研究人员提供服务，基础设施的估计替换价值为1.44亿澳元。这些资源支持数据密集型项目、促进培训和学生研究，并确保数据主权合规。

Conclusion: 机构研究计算基础设施在澳大利亚研究生态系统中扮演着关键角色，与国家设施相辅相成。研究表明，战略性投资于机构能力能显著提升研究生产力、加强研究生培训并改善成果。

Abstract: Institutional research computing infrastructure plays a vital role in
Australia's research ecosystem, complementing and extending national
facilities. This paper analyses research computing capabilities across
Australian universities and organisations, showing how institutional systems
support research excellence through local compute resources, specialised
hardware, and cluster solutions. Our study finds that nearly 112,258 CPU cores
and 2,241 GPUs serve over 6,000 researchers as essential bridges between
desktops and national facilities, enabling workflows from development to
large-scale computations. The estimated replacement value of this
infrastructure is $144M AUD. Drawing on detailed data from multiple
institutions, we identify key patterns in deployment, utilisation, and
strategic alignment with research priorities. Institutional resources provide
critical support for data-intensive projects, facilitate training and
higher-degree student research, enable prototyping and development, and ensure
data sovereignty compliance when required. The analysis shows how these
facilities leverage national investments while addressing institution-specific
needs that national systems cannot meet. We present evidence that strategic
investment in institutional capabilities yields significant returns through
greater research productivity, enhanced graduate training, and improved
outcomes. The study offers insights for organisations planning computing
strategies and highlights the importance of maintaining robust institutional
resources alongside national facilities.

</details>


### [264] [Cronus: Efficient LLM inference on Heterogeneous GPU Clusters via Partially Disaggregated Prefill](https://arxiv.org/abs/2509.17357)
*Yunzhao Liu,Qiang Xu,Y. Charlie Hu*

Main category: cs.DC

TL;DR: Cronus是一种针对异构GPU集群的LLM推理系统，通过部分解耦预填充策略动态平衡工作负载，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前解耦的预填充策略在异构GPU集群中因GPU能力与工作负载需求不平衡导致性能不佳，而传统数据并行和流水线并行在异构设置中会带来高推理延迟。

Method: Cronus采用部分解耦的预填充策略，将每个预填充阶段分区，初始部分在低端GPU上执行，剩余预填充和解码阶段在高端GPU上与早期请求重叠执行。

Result: 在各种高端和低端GPU组合的广泛评估中，Cronus显著提高了吞吐量，并显著降低了TTFT P99和TBT P99，同时保持相似或更好的吞吐量。

Conclusion: Cronus作为一种新型LLM推理系统，通过部分解耦的预填充策略，在异构GPU集群中动态平衡工作负载，显著提高了吞吐量并降低了延迟。

Abstract: Efficient LLM inference is critical for real-world applications, especially
within heterogeneous GPU clusters commonly found in organizations and
on-premise datacenters as GPU architecture rapidly evolves. Current
disaggregated prefill strategies, which separate the prefill and decode stages
of LLM inference across different GPUs, often suffer from suboptimal
performance due to imbalances between GPU capabilities and workload demands. On
the other hand, extending conventional data parallelism and pipeline
parallelism to heterogeneous setups incurs high inference latencies. To address
these challenges, we introduce Cronus, a novel LLM inference system designed to
dynamically balance workloads across heterogeneous GPUs using partially
disaggregated prefill. Cronus partitions each prefill stage and executes its
initial portion on the low-end GPU, while overlapping the remaining prefill and
decode stages of earlier requests on the high-end GPU. Extensive evaluations
across various high-end and low-end GPU combinations demonstrate that Cronus
significantly improves the throughput over disaggregated prefill. It also
reduces TTFT P99 and TBT P99 significantly over DP and PP while maintaining
similar or better throughput.

</details>


### [265] [Asteria: Semantic-Aware Cross-Region Caching for Agentic LLM Tool Access](https://arxiv.org/abs/2509.17360)
*Chaoyi Ruan,Chao Bi,Kaiwen Zheng,Ziji Shi,Xinyi Wan,Jialin Li*

Main category: cs.DC

TL;DR: Asteria是一种针对LLM代理的跨区域知识缓存架构，通过语义元素和两阶段检索显著提升性能，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理在跨区域知识交互中面临的延迟和成本瓶颈问题，现有缓存解决方案对语义知识重用的效果有限。

Method: Asteria引入了语义元素（SE）和语义检索索引（Sine）两个抽象概念，结合两阶段检索和轻量级LLM语义判断器，构建了一个新的缓存接口。

Result: 在代表性搜索工作负载中，Asteria实现了高达3.6倍的吞吐量提升，缓存命中率超过85%，且准确性几乎与非缓存基线相同；在复杂编码任务中，吞吐量提升了20%。

Conclusion: Asteria通过其创新的跨区域知识缓存架构，显著提升了LLM代理的性能，同时保持了准确性。

Abstract: Large Language Model (LLM) agents tackle data-intensive tasks such as deep
research and code generation. However, their effectiveness depends on frequent
interactions with knowledge sources across remote clouds or regions. Such
interactions can create non-trivial latency and cost bottlenecks. Existing
caching solutions focus on exact-match queries, limiting their effectiveness
for semantic knowledge reuse.
  To address this challenge, we introduce Asteria, a novel cross-region
knowledge caching architecture for LLM agents. At its core are two
abstractions: Semantic Element (SE) and Semantic Retrieval Index (Sine). A
semantic element captures the semantic embedding representation of an LLM query
together with performance-aware metadata such as latency, cost, and staticity.
Sine then provides two-stage retrieval: a vector similar index with semantic
embedding for fast candidate selection and a lightweight LLM-powered semantic
judger for precise validation. Atop these primitives, Asteria builds a new
cache interface that includes a new semantic-aware cache hit definition, a
cost-efficient eviction policy, and proactive prefetching. To reduce overhead,
Asteria co-locates the small LLM judger with the main LLM using adaptive
scheduling and resource sharing. Our evaluation demonstrates that Asteria
delivers substantial performance improvements without compromising correctness.
On representative search workloads, Asteria achieves up to a 3.6$\times$
increase in throughput by maintaining cache hit rates of over 85%, while
preserving accuracy virtually identical to non-cached baselines. Asteria also
improves throughput for complex coding tasks by 20%, showcasing its versatility
across diverse agentic workloads.

</details>


### [266] [Prefetching in Deep Memory Hierarchies with NVRAM as Main Memory](https://arxiv.org/abs/2509.17388)
*Manel Lurbe,Miguel Avargues,Salvador Petit,Maria E. Gomez,Rui Yang,Guanhao Wang,Julio Sahuquillo*

Main category: cs.DC

TL;DR: 研究探讨了多级预取技术对系统性能的影响，发现结合片外和片上缓存的预取方法（HMC+L1）能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着大数据分析和机器学习等应用对内存需求的增加，传统DRAM技术已无法满足需求，多级预取技术成为缓解内存延迟的关键。

Method: 研究评估了两种预取方法：HMC（混合内存控制器）和HMC+L1，分别结合片外和片上缓存的预取机制。

Result: 实验表明，HMC预取器的覆盖率和准确率分别超过60%和80%，而HMC+L1方法将片外预取覆盖率提升至92%，整体性能从9%提升至12%。

Conclusion: 多级预取技术，尤其是结合片外和片上缓存的预取方法，显著提升了系统性能，其中HMC+L1方法的性能提升最为明显。

Abstract: Emerging applications, such as big data analytics and machine learning,
require increasingly large amounts of main memory, often exceeding the capacity
of current commodity processors built on DRAM technology. To address this,
recent research has focused on off-chip memory controllers that facilitate
access to diverse memory media, each with unique density and latency
characteristics. While these solutions improve memory system performance, they
also exacerbate the already significant memory latency. As a result,
multi-level prefetching techniques are essential to mitigate these extended
latencies.
  This paper investigates the advantages of prefetching across both sides of
the memory system: the off-chip memory and the on-chip cache hierarchy. Our
primary objective is to assess the impact of a multi-level prefetching engine
on overall system performance. Additionally, we analyze the individual
contribution of each prefetching level to system efficiency. To achieve this,
the study evaluates two key prefetching approaches: HMC (Hybrid Memory
Controller) and HMC+L1, both of which employ prefetching mechanisms commonly
used by processor vendors. The HMC approach integrates a prefetcher within the
off-chip hybrid memory controller, while the HMC+L1 approach combines this with
additional L1 on-chip prefetchers.
  Experimental results on an out-of-order execution processor show that on-chip
cache prefetchers are crucial for maximizing the benefits of off-chip
prefetching, which in turn further enhances performance. Specifically, the
off-chip HMC prefetcher achieves coverage and accuracy rates exceeding 60% and
up to 80%, while the combined HMC+L1 approach boosts off-chip prefetcher
coverage to as much as 92%. Consequently, overall performance increases from 9%
with the HMC approach to 12% when L1 prefetching is also employed.

</details>


### [267] [pBeeGees: A Prudent Approach to Certificate-Decoupled BFT Consensus](https://arxiv.org/abs/2509.17496)
*Kaiji Yang,Jingjing Zhang,Junyao Zheng,Qiwen Liu,Weigang Wu,Jieying Zhou*

Main category: cs.DC

TL;DR: pBeeGees协议解决了BeeGees的安全与活性问题，首次实现流水线BFT中的安全性、活性和证书解耦，显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有协议因需视图连续法定证书而受限，影响性能并导致活性漏洞，证书解耦成为关键目标。BeeGees算法虽实现解耦但存在安全与活性问题。

Method: pBeeGees通过整合追溯和预提交验证解决无效区块问题，并引入谨慎验证机制缓解空链问题。

Result: pBeeGees解决了无效区块和空链问题，保持证书解耦且无额外计算开销。

Conclusion: pBeeGees是首个在流水线BFT框架中同时实现安全性、活性和证书解耦的协议，实验证明其显著降低了区块提交延迟。

Abstract: Pipelined Byzantine Fault Tolerant (BFT) consensus is fundamental to
permissioned blockchains. However, many existing protocols are limited by the
requirement for view-consecutive quorum certificates (QCs). This constraint
impairs performance and creates liveness vulnerabilities under adverse network
conditions. Achieving "certificate decoupling"-committing blocks without this
requirement-is therefore a key research goal. While the recent BeeGees
algorithm achieves this, our work reveals that it suffers from security and
liveness issues. To address this problem, this paper makes two primary
contributions. First, we formally define these flaws as the Invalid Block
Problem and the Hollow Chain Problem. Second, we propose pBeeGees, a new
algorithm that addresses these issues while preserving certificate decoupling
with no additional computational overhead. To achieve this, pBeeGees integrates
traceback and pre-commit validation to solve the Invalid Block Problem.Further,
to mitigate the Hollow Chain Problem, we introduce a prudent validation
mechanism, which prevents unverified branches from growing excessively. To
summarize, pBeeGees is the first protocol to simultaneously achieve safety,
liveness, and certificate decoupling in a pipelined BFT framework. Experiments
confirm that our design significantly reduces block commit latency compared to
classic algorithms, particularly under frequent stopping faults.

</details>


### [268] [TACTFL: Temporal Contrastive Training for Multi-modal Federated Learning with Similarity-guided Model Aggregation](https://arxiv.org/abs/2509.17532)
*Guanxiong Sun,Majid Mirmehdi,Zahraa Abdallah,Raul Santos-Rodriguez,Ian Craddock,Telmo de Menezes e Silva Filho*

Main category: cs.DC

TL;DR: TACTFL是一个半监督多模态联邦学习框架，通过时间对比训练和相似性引导的模型聚合，解决了标记数据有限和模态异质性问题，性能显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现实中的联邦学习面临标记数据有限和多模态输入异质性的挑战，需要一种统一的半监督多模态联邦学习框架。

Method: TACTFL采用模态无关的时间对比训练方案，利用跨模态的时间对齐进行表示学习，并通过相似性引导的模型聚合策略动态加权客户端模型。

Result: 在包括视频、音频和可穿戴传感器在内的多种基准和模态上，TACTFL实现了最先进的性能。例如，在UCF101数据集上，仅使用10%的标记数据，TACTFL达到了68.48%的top-1准确率，显著优于FedOpt基线的35.35%。

Conclusion: TACTFL提出了一种统一的半监督多模态联邦学习框架，通过模态无关的时间对比训练方案和相似性引导的模型聚合策略，有效解决了标记数据有限和多模态输入异质性的问题。

Abstract: Real-world federated learning faces two key challenges: limited access to
labelled data and the presence of heterogeneous multi-modal inputs. This paper
proposes TACTFL, a unified framework for semi-supervised multi-modal federated
learning. TACTFL introduces a modality-agnostic temporal contrastive training
scheme that conducts representation learning from unlabelled client data by
leveraging temporal alignment across modalities. However, as clients perform
self-supervised training on heterogeneous data, local models may diverge
semantically. To mitigate this, TACTFL incorporates a similarity-guided model
aggregation strategy that dynamically weights client models based on their
representational consistency, promoting global alignment. Extensive experiments
across diverse benchmarks and modalities, including video, audio, and wearable
sensors, demonstrate that TACTFL achieves state-of-the-art performance. For
instance, on the UCF101 dataset with only 10% labelled data, TACTFL attains
68.48% top-1 accuracy, significantly outperforming the FedOpt baseline of
35.35%. Code will be released upon publication.

</details>


### [269] [Disaggregated Prefill and Decoding Inference System for Large Language Model Serving on Multi-Vendor GPUs](https://arxiv.org/abs/2509.17542)
*Xing Chen,Rong Shi,Lu Zhao,Lingbin Wang,Xiao Jin,Yueqiang Chen,Hongfeng Sun*

Main category: cs.DC

TL;DR: 提出基于异构GPU的P-D分解推理系统，解决混合推理问题，并通过联合优化算法实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 随着模型规模增大，高效LLM推理系统成为迫切需求。现有研究多基于同构GPU，缺乏业务场景部署方案，异构GPU能提升资源利用率并降低成本。

Method: 设计了异构兼容传输模块解决异构GPU数据兼容问题，并提出并行策略与实例数分配的联合优化算法。

Result: 实验结果表明，P-D分解推理系统能良好解决不同厂商异构GPU的混合推理问题，联合优化算法可获得最优部署方案。

Conclusion: P-D分解推理框架基于异构GPU设计，有效解决了不同厂商GPU混合推理问题，联合优化算法能获得最优部署方案。

Abstract: LLM-based applications have been widely used in various industries, but with
the increasing of models size, an efficient large language model (LLM)
inference system is an urgent problem to be solved for service providers. Since
the inference system is divided into two stage with different characteristics:
Prefill and Decode, the two stage will interfere with each other during the
inference process. Toward this end, a P-D disaggregated inference framework is
proposed by some researchers. Current research is done on homogeneous GPUs, and
lacks deployment solutions based on business scenarios. Compared with
homogeneous GPUs, using heterogeneous GPUs to construct inference systems can
better improve resource utilization and reduce costs. Even if GPUs from
different vendors are used to build inference systems, on the basis of reducing
costs, the resource utilization rate can be improved and the dependence on a
single vendor can be reduced. Therefore, a P-D disaggreagetd inference system
based on heterogeneous GPUs is designed, and the heterogeneous compatible
transmission module in the system is designed to address heterogeneous GPU data
compatibility issues. Then, a joint optimization algorithm of parallel strategy
and instance number allocation is proposed to obtain the deployment solutions.
Finally, the experimental results show that the P-D disaggregated inference
system can well solve the hybrid inference problem of heterogeneous GPUs from
different vendors, and the joint optimization algorithm can obtain the optimal
deployment solution.

</details>


### [270] [A Lightweight Approach for State Machine Replication](https://arxiv.org/abs/2509.17771)
*Christian Cachin,Jinfeng Dou,Christian Scheideler,Philipp Schneider*

Main category: cs.DC

TL;DR: 该论文提出了一种轻量级、去中心化的状态机复制方案，通过承诺证书和压缩信息保证安全性和活跃性，并能快速恢复，优于依赖领导者的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的状态机复制解决方案在面临自适应阻塞攻击时表现不佳，尤其是依赖领导者的方法容易受到针对关键服务器的攻击。因此，需要一种轻量级、去中心化的解决方案，既能保证安全性和活跃性，又能快速恢复。

Method: 作者从稳定共识问题中采用了一个简单的中位数规则，并将其适应于客户端-服务器设置，其中服务器可以基于过去系统信息被自适应地阻塞。通过压缩关于已提交命令的信息，协议保持轻量级，同时使客户端能够轻松证明其命令已在共享状态上提交。

Result: 该方法在多个方面提供了接近最优的性能，保证了在最多恒定比例服务器被阻塞时的活跃性，以及在任何数量服务器被阻塞时的安全性。此外，该方法支持快速恢复，且完全去中心化，优于依赖领导者的其他解决方案。

Conclusion: 该论文提出了一种轻量级的解决方案，通过承诺证书实现状态机复制，保证了在大多数服务器未被阻塞时的活跃性，以及在任何数量服务器被阻塞时的安全性。此外，该方法支持快速恢复，且完全去中心化，优于依赖领导者的其他解决方案。

Abstract: We present a lightweight solution for state machine replication with
commitment certificates. Specifically, we adapt a simple median rule from the
stabilizing consensus problem [Doerr11] to operate in a client-server setting
where arbitrary servers may be blocked adaptively based on past system
information. We further extend our protocol by compressing information about
committed commands, thus keeping the protocol lightweight, while still enabling
clients to easily prove that their commands have indeed been committed on the
shared state. Our approach guarantees liveness as long as at most a constant
fraction of servers are blocked, ensures safety under any number of blocked
servers, and supports fast recovery from massive blocking attacks. In addition
to offering near-optimal performance in several respects, our method is fully
decentralized, unlike other near-optimal solutions that rely on leaders. In
particular, our solution is robust against adversaries that target key servers
(which captures insider-based denial-of-service attacks), whereas leader-based
approaches fail under such a blocking model.

</details>


### [271] [Expert-as-a-Service: Towards Efficient, Scalable, and Robust Large-scale MoE Serving](https://arxiv.org/abs/2509.17863)
*Ziming Liu,Boyu Tian,Guoteng Wang,Zhen Jiang,Peng Sun,Zhenhua Han,Tian Tang,Xiaohe Hu,Yanmin Jia,Yan Zhang,He Liu,Mingjun Zhang,Yiqi Zhang,Qiaoling Chen,Shenggan Cheng,Mingyu Gao,Yang You,Siyuan Feng*

Main category: cs.DC

TL;DR: EaaS是一种新型服务系统，通过解耦MoE模块为独立服务，实现了高效、可扩展且鲁棒的MoE部署，显著提升了资源利用率和容错能力。


<details>
  <summary>Details</summary>
Motivation: 传统系统针对密集架构设计，无法有效应对MoE模型的动态稀疏专家利用，导致服务不稳定。

Method: 提出EaaS服务系统，将MoE模块解耦为独立的无状态服务，并采用高性能的CPU-free点对点通信库以减少开销。

Result: EaaS在保持与单体系统相当性能的同时，提供了强大的容错能力和可扩展性，在硬件故障下吞吐量下降小于2%，并通过动态细粒度适应节省了37.5%的计算资源。

Conclusion: EaaS系统通过将MoE模块解耦为独立的无状态服务，实现了高效的资源扩展和固有的容错能力，为大规模MoE部署提供了强大的弹性和效率。

Abstract: Mixture-of-Experts (MoE) models challenge serving infrastructures with
dynamic, sparse expert utilization, causing instability on conventional systems
designed for dense architectures. We propose EaaS, a novel serving system to
enable efficient, scalable, and robust MoE deployment. Our system disaggregates
MoE modules into independent, stateless services. This design enables
fine-grained resource scaling and provides inherent fault tolerance by
decoupling compute units. The architecture is powered by a high-performance,
CPU-free peer-to-peer communication library that ensures minimal overhead and
high throughput. Experiments confirm EaaS's scalability and efficiency,
achieving performance comparable to monolithic systems while providing robust
fault tolerance and strong scalability. EaaS incurs less than a 2% throughput
reduction under simulated hardware failures that would otherwise halt
monolithic architectures. It further saves up to 37.5% of computing resources
through dynamic fine-grained adaptation to serving traffic, demonstrating
strong resilience for large-scale MoE deployment in production.

</details>


### [272] [XaaS Containers: Performance-Portable Representation With Source and IR Containers](https://arxiv.org/abs/2509.17914)
*Marcin Copik,Eiman Alnuaimi,Alok Kamatar,Valerie Hayot-Sasson,Alberto Madonna,Todd Gamblin,Kyle Chard,Ian Foster,Torsten Hoefler*

Main category: cs.DC

TL;DR: XaaS通过Source和IR容器实现性能可移植性，结合LLM辅助方法自动发现专业化，优化部署时的容器性能。


<details>
  <summary>Details</summary>
Motivation: 高性能计算（HPC）系统和云数据中心的融合，容器成为便携式软件部署的默认方法，但面临性能挑战，牺牲硬件优化以换取可移植性。

Method: 提出了一种新的LLM辅助方法，用于自动发现专业化，并通过分析编译流水线开发了一种在部署时为目标架构构建优化容器的方法。

Result: 原型证明，新的XaaS容器结合了容器化的便利性和系统专用构建的性能优势。

Conclusion: 通过Source和IR容器的实现，XaaS容器成功结合了容器化的便利性与系统专用构建的性能优势。

Abstract: High-performance computing (HPC) systems and cloud data centers are
converging, and containers are becoming the default method of portable software
deployment. Yet, while containers simplify software management, they face
significant performance challenges in HPC environments as they must sacrifice
hardware-specific optimizations to achieve portability. Although HPC containers
can use runtime hooks to access optimized MPI libraries and GPU devices, they
are limited by application binary interface (ABI) compatibility and cannot
overcome the effects of early-stage compilation decisions. Acceleration as a
Service (XaaS) proposes a vision of performance-portable containers, where a
containerized application should achieve peak performance across all HPC
systems. We present a practical realization of this vision through Source and
Intermediate Representation (IR) containers, where we delay
performance-critical decisions until the target system specification is known.
We analyze specialization mechanisms in HPC software and propose a new
LLM-assisted method for automatic discovery of specializations. By examining
the compilation pipeline, we develop a methodology to build containers
optimized for target architectures at deployment time. Our prototype
demonstrates that new XaaS containers combine the convenience of
containerization with the performance benefits of system-specialized builds.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [273] [RaFD: Flow-Guided Radar Detection for Robust Autonomous Driving](https://arxiv.org/abs/2509.16261)
*Shuocheng Yang,Zikun Xu,Jiahao Wang,Shahid Nawaz,Jianqiang Wang,Shaobing Xu*

Main category: cs.RO

TL;DR: RaFD通过结合BEV流估计提升雷达目标检测性能，验证了几何信息对雷达信号解析的重要性。


<details>
  <summary>Details</summary>
Motivation: 雷达图像常受噪声和'鬼影'伪影影响，仅基于语义特征的目标检测极具挑战性，因此需要引入几何信息提升检测精度。

Method: 设计了一个监督流估计辅助任务，与检测网络联合训练，并利用估计的流引导前一帧到当前帧的特征传播。

Result: 在RADIATE数据集上实现了最先进的性能。

Conclusion: RaFD框架通过结合几何信息（BEV流）显著提升了雷达图像的目标检测性能，验证了在语义模糊的雷达信号中引入几何线索的有效性。

Abstract: Radar has shown strong potential for robust perception in autonomous driving;
however, raw radar images are frequently degraded by noise and "ghost"
artifacts, making object detection based solely on semantic features highly
challenging. To address this limitation, we introduce RaFD, a radar-based
object detection framework that estimates inter-frame bird's-eye-view (BEV)
flow and leverages the resulting geometric cues to enhance detection accuracy.
Specifically, we design a supervised flow estimation auxiliary task that is
jointly trained with the detection network. The estimated flow is further
utilized to guide feature propagation from the previous frame to the current
one. Our flow-guided, radar-only detector achieves achieves state-of-the-art
performance on the RADIATE dataset, underscoring the importance of
incorporating geometric information to effectively interpret radar signals,
which are inherently ambiguous in semantics.

</details>


### [274] [Tactile-Based Human Intent Recognition for Robot Assistive Navigation](https://arxiv.org/abs/2509.16353)
*Shaoting Peng,Dakarai Crowder,Wenzhen Yuan,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: Tac-Nav系统利用圆柱形触觉皮肤和CK-SVM算法提升导航意图识别，实验证明其高效且用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有机器人辅助导航系统缺乏直观高效的物理通信接口，限制了其效果。

Method: 开发了圆柱形核支持向量机（CK-SVM）算法，明确建模传感器的圆柱几何形状，以应对用户抓握中的自然旋转变化。

Result: CK-SVM在模拟数据集上达到97.1%的分类准确率，在真实数据集上达到90.8%，优于四种基线模型。用户更喜欢Tac-Nav触觉界面。

Conclusion: Tac-Nav系统通过圆柱形触觉皮肤和CK-SVM算法，显著提升了机器人辅助导航的直观性和效率，用户更倾向于使用这种触觉界面。

Abstract: Robot assistive navigation (RAN) is critical for enhancing the mobility and
independence of the growing population of mobility-impaired individuals.
However, existing systems often rely on interfaces that fail to replicate the
intuitive and efficient physical communication observed between a person and a
human caregiver, limiting their effectiveness. In this paper, we introduce
Tac-Nav, a RAN system that leverages a cylindrical tactile skin mounted on a
Stretch 3 mobile manipulator to provide a more natural and efficient interface
for human navigational intent recognition. To robustly classify the tactile
data, we developed the Cylindrical Kernel Support Vector Machine (CK-SVM), an
algorithm that explicitly models the sensor's cylindrical geometry and is
consequently robust to the natural rotational shifts present in a user's grasp.
Comprehensive experiments were conducted to demonstrate the effectiveness of
our classification algorithm and the overall system. Results show that CK-SVM
achieved superior classification accuracy on both simulated (97.1%) and
real-world (90.8%) datasets compared to four baseline models. Furthermore, a
pilot study confirmed that users more preferred the Tac-Nav tactile interface
over conventional joystick and voice-based controls.

</details>


### [275] [Dynamic Objects Relocalization in Changing Environments with Flow Matching](https://arxiv.org/abs/2509.16398)
*Francesco Argenziano,Miguel Saavedra-Ruiz,Sacha Morin,Daniele Nardi,Liam Paull*

Main category: cs.RO

TL;DR: FlowMaps利用人机交互的重复模式推断物体位置，解决了动态环境中的未知重定位问题。


<details>
  <summary>Details</summary>
Motivation: 动态环境中物体的位置变化（主要由人类活动引起）增加了任务失败的风险，但人机交互的重复模式未被充分利用。

Method: 提出了基于Flow Matching的FlowMaps模型，用于推断物体在时空中的多模态位置。

Result: 实验结果支持了利用人机交互模式推断物体位置的假设。

Conclusion: FlowMaps模型通过利用人机交互的重复模式，成功推断出物体在动态环境中的多模态位置，为解决未知重定位问题提供了新思路。

Abstract: Task and motion planning are long-standing challenges in robotics, especially
when robots have to deal with dynamic environments exhibiting long-term
dynamics, such as households or warehouses. In these environments, long-term
dynamics mostly stem from human activities, since previously detected objects
can be moved or removed from the scene. This adds the necessity to find such
objects again before completing the designed task, increasing the risk of
failure due to missed relocalizations. However, in these settings, the nature
of such human-object interactions is often overlooked, despite being governed
by common habits and repetitive patterns. Our conjecture is that these cues can
be exploited to recover the most likely objects' positions in the scene,
helping to address the problem of unknown relocalization in changing
environments. To this end we propose FlowMaps, a model based on Flow Matching
that is able to infer multimodal object locations over space and time. Our
results present statistical evidence to support our hypotheses, opening the way
to more complex applications of our approach. The code is publically available
at https://github.com/Fra-Tsuna/flowmaps

</details>


### [276] [Subteaming and Adaptive Formation Control for Coordinated Multi-Robot Navigation](https://arxiv.org/abs/2509.16412)
*Zihao Deng,Peng Gao,Williard Joshua Jose,Maggie Wigness,John Rogers,Brian Reily,Christopher Reardon,Hao Zhang*

Main category: cs.RO

TL;DR: STAF是一种分层学习方法，实现多机器人在复杂场景中的动态分队和自适应编队控制，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂场景（如狭窄走廊）中，保持预定义编队不可行，因此需要动态分队和自适应编队控制能力。

Method: STAF采用统一的分层学习框架，包括高层深度图切割分队、中层图学习协调子队导航和低层策略学习控制个体机器人。

Result: 实验结果表明，STAF在多机器人协调导航中表现出色，尤其在复杂场景中。

Conclusion: STAF方法通过分层学习框架实现了多机器人在复杂场景中的动态分队和自适应编队控制，显著提升了协调导航的性能。

Abstract: Coordinated multi-robot navigation is essential for robots to operate as a
team in diverse environments. During navigation, robot teams usually need to
maintain specific formations, such as circular formations to protect human
teammates at the center. However, in complex scenarios such as narrow
corridors, rigidly preserving predefined formations can become infeasible.
Therefore, robot teams must be capable of dynamically splitting into smaller
subteams and adaptively controlling the subteams to navigate through such
scenarios while preserving formations. To enable this capability, we introduce
a novel method for SubTeaming and Adaptive Formation (STAF), which is built
upon a unified hierarchical learning framework: (1) high-level deep graph cut
for team splitting, (2) intermediate-level graph learning for facilitating
coordinated navigation among subteams, and (3) low-level policy learning for
controlling individual mobile robots to reach their goal positions while
avoiding collisions. To evaluate STAF, we conducted extensive experiments in
both indoor and outdoor environments using robotics simulations and physical
robot teams. Experimental results show that STAF enables the novel capability
for subteaming and adaptive formation control, and achieves promising
performance in coordinated multi-robot navigation through challenging
scenarios. More details are available on the project website:
https://hcrlab.gitlab.io/project/STAF.

</details>


### [277] [End-to-end RL Improves Dexterous Grasping Policies](https://arxiv.org/abs/2509.16434)
*Ritvik Singh,Karl Van Wyk,Pieter Abbeel,Jitendra Malik,Nathan Ratliff,Ankur Handa*

Main category: cs.RO

TL;DR: 本文提出了一种将模拟器和RL分离到不同GPU的新方法，显著提升了基于视觉的端到端学习效率，并在现实应用中取得了优于现有技术的结果。


<details>
  <summary>Details</summary>
Motivation: 探索如何扩展基于图像的端到端学习技术，以解决视觉基础RL在内存效率上的不足，以及如何通过端到端RL实现主动视觉行为的涌现。

Method: 提出了一种新的方法，将模拟器和RL（包括训练和经验缓冲区）分离到不同的GPU上，以解决传统数据并行技术在扩展到多GPU时的瓶颈问题。

Result: 在相同数量的GPU下，该方法能够将现有环境数量翻倍，显著提升了基于视觉的端到端深度训练的性能，并在现实世界中取得了优于现有视觉基础方法的结果。

Conclusion: 通过将模拟器和RL训练分离到不同的GPU上，我们不仅提高了训练效率，还显著提升了深度和状态策略在立体RGB网络中的表现，最终在现实世界中实现了优于现有视觉基础方法的性能。

Abstract: This work explores techniques to scale up image-based end-to-end learning for
dexterous grasping with an arm + hand system. Unlike state-based RL,
vision-based RL is much more memory inefficient, resulting in relatively low
batch sizes, which is not amenable for algorithms like PPO. Nevertheless, it is
still an attractive method as unlike the more commonly used techniques which
distill state-based policies into vision networks, end-to-end RL can allow for
emergent active vision behaviors. We identify a key bottleneck in training
these policies is the way most existing simulators scale to multiple GPUs using
traditional data parallelism techniques. We propose a new method where we
disaggregate the simulator and RL (both training and experience buffers) onto
separate GPUs. On a node with four GPUs, we have the simulator running on three
of them, and PPO running on the fourth. We are able to show that with the same
number of GPUs, we can double the number of existing environments compared to
the previous baseline of standard data parallelism. This allows us to train
vision-based environments, end-to-end with depth, which were previously
performing far worse with the baseline. We train and distill both depth and
state-based policies into stereo RGB networks and show that depth distillation
leads to better results, both in simulation and reality. This improvement is
likely due to the observability gap between state and vision policies which
does not exist when distilling depth policies into stereo RGB. We further show
that the increased batch size brought about by disaggregated simulation also
improves real world performance. When deploying in the real world, we improve
upon the previous state-of-the-art vision-based results using our end-to-end
policies.

</details>


### [278] [FiLM-Nav: Efficient and Generalizable Navigation via VLM Fine-tuning](https://arxiv.org/abs/2509.16445)
*Naoki Yokoyama,Sehoon Ha*

Main category: cs.RO

TL;DR: FiLM-Nav通过微调VLM作为导航策略，在复杂环境中实现了高效的语义导航，并在多个基准测试中取得最佳性能。


<details>
  <summary>Details</summary>
Motivation: 为了使机器人助手能够在复杂环境中导航并定位自由形式语言描述的对象，需要有效利用基础模型（如VLM）的语义理解能力。

Method: FiLM-Nav直接微调预训练的VLM作为导航策略，利用模拟经验使其适应目标驱动的导航任务。

Result: FiLM-Nav在HM3D ObjectNav和HM3D-OVON基准测试中均取得了最先进的性能，展示了强大的泛化能力。

Conclusion: FiLM-Nav通过直接微调预训练的视觉语言模型（VLM）作为导航策略，证明了在多样化模拟数据上进行微调是实现通用且高效语义导航能力的有效途径。

Abstract: Enabling robotic assistants to navigate complex environments and locate
objects described in free-form language is a critical capability for real-world
deployment. While foundation models, particularly Vision-Language Models
(VLMs), offer powerful semantic understanding, effectively adapting their
web-scale knowledge for embodied decision-making remains a key challenge. We
present FiLM-Nav (Fine-tuned Language Model for Navigation), an approach that
directly fine-tunes pre-trained VLM as the navigation policy. In contrast to
methods that use foundation models primarily in a zero-shot manner or for map
annotation, FiLM-Nav learns to select the next best exploration frontier by
conditioning directly on raw visual trajectory history and the navigation goal.
Leveraging targeted simulated embodied experience allows the VLM to ground its
powerful pre-trained representations in the specific dynamics and visual
patterns relevant to goal-driven navigation. Critically, fine-tuning on a
diverse data mixture combining ObjectNav, OVON, ImageNav, and an auxiliary
spatial reasoning task proves essential for achieving robustness and broad
generalization. FiLM-Nav sets a new state-of-the-art in both SPL and success
rate on HM3D ObjectNav among open-vocabulary methods, and sets a
state-of-the-art SPL on the challenging HM3D-OVON benchmark, demonstrating
strong generalization to unseen object categories. Our work validates that
directly fine-tuning VLMs on diverse simulated embodied data is a highly
effective pathway towards generalizable and efficient semantic navigation
capabilities.

</details>


### [279] [A Framework for Optimal Ankle Design of Humanoid Robots](https://arxiv.org/abs/2509.16469)
*Guglielmo Cervettini,Roberto Mauceri,Alex Coppola,Fabio Bergonti,Luca Fiorio,Marco Maggiali,Daniele Pucci*

Main category: cs.RO

TL;DR: 提出了一种统一的方法论，用于优化平行踝关节机制设计，RSU架构性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 人形机器人踝关节设计对安全和高效的地面交互至关重要。机械顺从性和电机质量分布等关键因素促使平行机制架构的采用。

Method: 提出了一种统一的方法论，用于设计和评估平行踝关节机制。通过多目标优化合成机制几何，并使用标量成本函数评估解决方案，以进行跨架构比较。特别关注了SPU和RSU两种代表性架构。

Result: 优化的RSU踝关节设计在性能上优于原始串行设计和传统设计的RSU，成本函数分别降低了41%和14%。

Conclusion: 优化后的RSU踝关节设计在性能上显著优于原始串行设计和传统设计的RSU，成本函数分别降低了41%和14%。

Abstract: The design of the humanoid ankle is critical for safe and efficient ground
interaction. Key factors such as mechanical compliance and motor mass
distribution have driven the adoption of parallel mechanism architectures.
However, selecting the optimal configuration depends on both actuator
availability and task requirements. We propose a unified methodology for the
design and evaluation of parallel ankle mechanisms. A multi-objective
optimization synthesizes the mechanism geometry, the resulting solutions are
evaluated using a scalar cost function that aggregates key performance metrics
for cross-architecture comparison. We focus on two representative
architectures: the Spherical-Prismatic-Universal (SPU) and the
Revolute-Spherical-Universal (RSU). For both, we resolve the kinematics, and
for the RSU, introduce a parameterization that ensures workspace feasibility
and accelerates optimization. We validate our approach by redesigning the ankle
of an existing humanoid robot. The optimized RSU consistently outperforms both
the original serial design and a conventionally engineered RSU, reducing the
cost function by up to 41% and 14%, respectively.

</details>


### [280] [Robot Conga: A Leader-Follower Walking Approach to Sequential Path Following in Multi-Agent Systems](https://arxiv.org/abs/2509.16482)
*Pranav Tiwari,Soumyodipta Nath*

Main category: cs.RO

TL;DR: 提出了Robot Conga策略，通过基于空间位移的领导者-跟随者控制，解决了多机器人路径跟随中的同步和灵活性挑战，模拟验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 解决传统形成控制技术在同步性和行为灵活性方面的不足，特别是在需要固定空间间隔的连续路径跟随场景中。

Method: 采用基于领导者空间位移的状态更新策略，而非时间参数化，结合全局位置参考系统进行控制。

Result: 在TurtleBot3和四足机器人（Laikago）上实现了精确的轨迹跟踪、稳定的间距和快速收敛（四足机器人约250时间步，TurtleBot3几乎瞬时）。

Conclusion: Robot Conga策略在模拟环境中展示了高效的路径跟踪和稳定的间距控制，适用于室内多机器人协作场景。

Abstract: Coordinated path following in multi-agent systems is a key challenge in
robotics, with applications in automated logistics, surveillance, and
collaborative exploration. Traditional formation control techniques often rely
on time-parameterized trajectories and path integrals, which can result in
synchronization issues and rigid behavior. In this work, we address the problem
of sequential path following, where agents maintain fixed spatial separation
along a common trajectory, guided by a leader under centralized control. We
introduce Robot Conga, a leader-follower control strategy that updates each
agent's desired state based on the leader's spatial displacement rather than
time, assuming access to a global position reference, an assumption valid in
indoor environments equipped with motion capture, vision-based tracking, or UWB
localization systems. The algorithm was validated in simulation using both
TurtleBot3 and quadruped (Laikago) robots. Results demonstrate accurate
trajectory tracking, stable inter-agent spacing, and fast convergence, with all
agents aligning within 250 time steps (approx. 0.25 seconds) in the quadruped
case, and almost instantaneously in the TurtleBot3 implementation.

</details>


### [281] [Substrate-Timing-Independence for Meta-State Stability of Distributed Robotic Swarms](https://arxiv.org/abs/2509.16492)
*Tinapat Limsila,Mehul Sharma,Paulo Garcia*

Main category: cs.RO

TL;DR: 该论文提出了一种基于CSP的形式化方法，用于在机器人群体设计中自动识别和修正可能导致错误元状态的问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 分布式系统中的涌现特性由于时序不可预测性而产生；每个子系统内的异步状态演化可能导致宏观系统进入错误的元状态。在机器人群体中，由于实现基底在设计或部署过程中的可变性，这一问题更加严重。

Method: 我们引入了一种基于通信顺序进程（CSP）的方法论，用于在基底时序独立的情况下对机器人群体设计的正确性进行形式化推理。

Result: 在一个具有明确识别故障的机器人群体上进行了评估，结果显示在应用修正前群体达到了非法元状态，但在修正后表现一致正确。

Conclusion: 通过利用并发进程演算（特别是通信顺序进程），我们提出了一种方法，能够自动识别可能导致错误元状态的原因，并修正设计，使得即使在因基底变化而导致时序变化的情况下，元状态也能保持稳定。

Abstract: Emergent properties in distributed systems arise due to timing
unpredictability; asynchronous state evolution within each sub-system may lead
the macro-system to faulty meta-states. Empirical validation of correctness is
often prohibitively expensive, as the size of the state-space is too large to
be tractable. In robotic swarms this problem is exacerbated, when compared to
software systems, by the variability of the implementation substrate across the
design, or even the deployment, process. We present an approach for formally
reasoning about the correctness of robotic swarm design in a
substrate-timing-independent way. By leveraging concurrent process calculi
(namely, Communicating Sequential Processes), we introduce a methodology that
can automatically identify possible causes of faulty meta-states and correct
such designs such that meta-states are consistently stable, even in the
presence of timing variability due to substrate changes. We evaluate this
approach on a robotic swarm with a clearly identified fault, realized in both
simulation and reality. Results support the research hypothesis, showing that
the swarm reaches an illegal meta-state before the correction is applied, but
behaves consistently correctly after the correction. Our techniques are
transferable across different design methodologies, contributing to the toolbox
of formal methods for roboticists.

</details>


### [282] [No Need for Real 3D: Fusing 2D Vision with Pseudo 3D Representations for Robotic Manipulation Learning](https://arxiv.org/abs/2509.16532)
*Run Yu,Yangdi Liu,Wen-Da Wei,Chen Li*

Main category: cs.RO

TL;DR: NoReal3D框架通过伪点云特征转换和融合，以低成本实现与3D点云方法相当的机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于3D点云的方法在策略性能和泛化能力上优于2D图像方法，但其高数据采集成本限制了可扩展性和实际部署。NoReal3D旨在解决这一问题。

Method: 提出了NoReal3D框架，包括3DStructureFormer模块（将单目图像转换为伪点云特征）和伪点云编码器（保留几何和拓扑结构），并研究了不同特征融合策略的有效性。

Result: 在多种任务上的实验验证表明，NoReal3D框架无需实际点云数据即可实现与3D点云方法相当的性能。

Conclusion: NoReal3D框架通过3DStructureFormer模块将单目图像转换为具有几何意义的伪点云特征，有效融合2D编码器输出特征，在完全消除3D点云采集成本的同时，实现了与基于3D点云方法相当的性能。

Abstract: Recently,vision-based robotic manipulation has garnered significant attention
and witnessed substantial advancements. 2D image-based and 3D point cloud-based
policy learning represent two predominant paradigms in the field, with recent
studies showing that the latter consistently outperforms the former in terms of
both policy performance and generalization, thereby underscoring the value and
significance of 3D information. However, 3D point cloud-based approaches face
the significant challenge of high data acquisition costs, limiting their
scalability and real-world deployment. To address this issue, we propose a
novel framework NoReal3D: which introduces the 3DStructureFormer, a learnable
3D perception module capable of transforming monocular images into
geometrically meaningful pseudo-point cloud features, effectively fused with
the 2D encoder output features. Specially, the generated pseudo-point clouds
retain geometric and topological structures so we design a pseudo-point cloud
encoder to preserve these properties, making it well-suited for our framework.
We also investigate the effectiveness of different feature fusion
strategies.Our framework enhances the robot's understanding of 3D spatial
structures while completely eliminating the substantial costs associated with
3D point cloud acquisition.Extensive experiments across various tasks validate
that our framework can achieve performance comparable to 3D point cloud-based
methods, without the actual point cloud data.

</details>


### [283] [Improve bounding box in Carla Simulator](https://arxiv.org/abs/2509.16773)
*Mohamad Mofeed Chaar,Jamal Raiyn,Galia Weidl*

Main category: cs.RO

TL;DR: An improved method in CARLA simulator enhances bounding box accuracy by filtering ghost boxes and false positives, achieving high performance.


<details>
  <summary>Details</summary>
Motivation: The primary method for data generation in CARLA, while effective, faces challenges like ghost boxes and false positives when objects are obscured. This motivates the development of an improved approach to enhance accuracy.

Method: The method involves capturing object coordinates in the CARLA simulator, aligning them with the ego vehicle's sensor system, and enclosing them in bounding boxes. The enhanced approach specifically targets the elimination of ghost boxes and false positives caused by obstructions.

Result: Performance analysis shows that the enhanced approach successfully filters out unwanted boxes, resulting in high accuracy.

Conclusion: The improved approach in the CARLA simulator effectively filters out unwanted bounding boxes, achieving high accuracy in object detection and annotation.

Abstract: The CARLA simulator (Car Learning to Act) serves as a robust platform for
testing algorithms and generating datasets in the field of Autonomous Driving
(AD). It provides control over various environmental parameters, enabling
thorough evaluation. Development bounding boxes are commonly utilized tools in
deep learning and play a crucial role in AD applications. The predominant
method for data generation in the CARLA Simulator involves identifying and
delineating objects of interest, such as vehicles, using bounding boxes. The
operation in CARLA entails capturing the coordinates of all objects on the map,
which are subsequently aligned with the sensor's coordinate system at the ego
vehicle and then enclosed within bounding boxes relative to the ego vehicle's
perspective. However, this primary approach encounters challenges associated
with object detection and bounding box annotation, such as ghost boxes.
Although these procedures are generally effective at detecting vehicles and
other objects within their direct line of sight, they may also produce false
positives by identifying objects that are obscured by obstructions. We have
enhanced the primary approach with the objective of filtering out unwanted
boxes. Performance analysis indicates that the improved approach has achieved
high accuracy.

</details>


### [284] [TranTac: Leveraging Transient Tactile Signals for Contact-Rich Robotic Manipulation](https://arxiv.org/abs/2509.16550)
*Yinghao Wu,Shuhong Hou,Haowen Zheng,Yichen Li,Weiyi Lu,Xun Zhou,Yitian Shao*

Main category: cs.RO

TL;DR: TranTac是一个低成本、数据高效的触觉传感与控制框架，通过结合6轴惯性测量单元和Transformer编码器，显著提升了机器人完成精细插入任务的成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在视觉感知不足以检测微小对准误差时，触觉传感对机器人完成精细插入任务至关重要。现有触觉传感方案要么灵敏度不足，要么数据需求过高。

Method: TranTac集成了一个接触敏感的6轴惯性测量单元于机器人夹爪的弹性尖端，通过Transformer编码器和扩散策略模仿人类插入行为，利用瞬态触觉线索动态控制物体的6自由度姿态。

Result: TranTac在与视觉结合时，物体抓取和插入任务的平均成功率达79%，优于纯视觉策略和增强的末端力/扭矩传感策略。触觉定位任务的平均成功率为88%。在未见过的数据上测试时，平均成功率达70%。

Conclusion: TranTac框架通过结合低成本的触觉传感和Transformer编码器，显著提升了机器人完成精细插入任务的成功率，并展示了良好的泛化能力，为未来机器人触觉传感系统的发展提供了新思路。

Abstract: Robotic manipulation tasks such as inserting a key into a lock or plugging a
USB device into a port can fail when visual perception is insufficient to
detect misalignment. In these situations, touch sensing is crucial for the
robot to monitor the task's states and make precise, timely adjustments.
Current touch sensing solutions are either insensitive to detect subtle changes
or demand excessive sensor data. Here, we introduce TranTac, a data-efficient
and low-cost tactile sensing and control framework that integrates a single
contact-sensitive 6-axis inertial measurement unit within the elastomeric tips
of a robotic gripper for completing fine insertion tasks. Our customized
sensing system can detect dynamic translational and torsional deformations at
the micrometer scale, enabling the tracking of visually imperceptible pose
changes of the grasped object. By leveraging transformer-based encoders and
diffusion policy, TranTac can imitate human insertion behaviors using transient
tactile cues detected at the gripper's tip during insertion processes. These
cues enable the robot to dynamically control and correct the 6-DoF pose of the
grasped object. When combined with vision, TranTac achieves an average success
rate of 79% on object grasping and insertion tasks, outperforming both
vision-only policy and the one augmented with end-effector 6D force/torque
sensing. Contact localization performance is also validated through
tactile-only misaligned insertion tasks, achieving an average success rate of
88%. We assess the generalizability by training TranTac on a single prism-slot
pair and testing it on unseen data, including a USB plug and a metal key, and
find that the insertion tasks can still be completed with an average success
rate of nearly 70%. The proposed framework may inspire new robotic tactile
sensing systems for delicate manipulation tasks.

</details>


### [285] [Video-to-BT: Generating Reactive Behavior Trees from Human Demonstration Videos for Robotic Assembly](https://arxiv.org/abs/2509.16611)
*Xiwei Zhao,Yiwei Wang,Yansong Wu,Fan Wu,Teng Sun,Zhonghua Miao,Sami Haddadin,Alois Knoll*

Main category: cs.RO

TL;DR: 论文提出Video-to-BT框架，利用VLM和BT实现机器人装配的灵活与可靠，实验证明其高效和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统机器人装配系统依赖专家编程，缺乏灵活性和鲁棒性，无法适应产品变化和环境动态。

Method: 提出了一种分层框架Video-to-BT，利用视觉语言模型（VLM）从人类演示视频中分解子任务并生成行为树（BT），结合实时场景解释实现动态环境中的反应性操作。

Result: 实验验证了该框架在真实装配任务中的高规划可靠性、长序列任务的稳健性能以及对多样化及扰动条件的强泛化能力。

Conclusion: 该论文提出的Video-to-BT框架通过结合视觉语言模型和行为树，实现了机器人装配任务的高可靠性和适应性，实验验证了其在复杂环境中的优越性能。

Abstract: Modern manufacturing demands robotic assembly systems with enhanced
flexibility and reliability. However, traditional approaches often rely on
programming tailored to each product by experts for fixed settings, which are
inherently inflexible to product changes and lack the robustness to handle
variations. As Behavior Trees (BTs) are increasingly used in robotics for their
modularity and reactivity, we propose a novel hierarchical framework,
Video-to-BT, that seamlessly integrates high-level cognitive planning with
low-level reactive control, with BTs serving both as the structured output of
planning and as the governing structure for execution. Our approach leverages a
Vision-Language Model (VLM) to decompose human demonstration videos into
subtasks, from which Behavior Trees are generated. During the execution, the
planned BTs combined with real-time scene interpretation enable the system to
operate reactively in the dynamic environment, while VLM-driven replanning is
triggered upon execution failure. This closed-loop architecture ensures
stability and adaptivity. We validate our framework on real-world assembly
tasks through a series of experiments, demonstrating high planning reliability,
robust performance in long-horizon assembly tasks, and strong generalization
across diverse and perturbed conditions. Project website:
https://video2bt.github.io/video2bt_page/

</details>


### [286] [ORN-CBF: Learning Observation-conditioned Residual Neural Control Barrier Functions via Hypernetworks](https://arxiv.org/abs/2509.16614)
*Bojan Derajić,Sebastian Bernhard,Wolfgang Hönig*

Main category: cs.RO

TL;DR: 提出了一种基于HJ可达性分析的观察条件神经CBFs，解决了现有方法在安全性和适用性上的不足，实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 尽管控制屏障函数（CBFs）在自主系统的安全关键控制中有效，但其设计仍具挑战性，尤其是在部分可观察环境和缺乏严格安全保证的情况下。

Method: 利用Hamilton-Jacobi值函数的数学特性，设计了一种观察条件的神经CBFs，并结合超网络架构，确保预测的安全集不与观察到的失败集相交。

Result: 仿真和硬件实验（地面机器人和四旋翼飞行器）显示，与基线方法相比，该方法在成功率和泛化到域外环境方面均有显著提升。

Conclusion: 该论文提出了一种基于Hamilton-Jacobi可达性分析的观察条件神经控制屏障函数（CBFs），有效解决了现有方法在部分可观察环境中的适用性和安全性保证不足的问题。实验结果表明，该方法在仿真和硬件测试中均表现出更高的成功率和更好的泛化能力。

Abstract: Control barrier functions (CBFs) have been demonstrated as an effective
method for safety-critical control of autonomous systems. Although CBFs are
simple to deploy, their design remains challenging, motivating the development
of learning-based approaches. Yet, issues such as suboptimal safe sets,
applicability in partially observable environments, and lack of rigorous safety
guarantees persist. In this work, we propose observation-conditioned neural
CBFs based on Hamilton-Jacobi (HJ) reachability analysis, which approximately
recover the maximal safe sets. We exploit certain mathematical properties of
the HJ value function, ensuring that the predicted safe set never intersects
with the observed failure set. Moreover, we leverage a hypernetwork-based
architecture that is particularly suitable for the design of
observation-conditioned safety filters. The proposed method is examined both in
simulation and hardware experiments for a ground robot and a quadcopter. The
results show improved success rates and generalization to out-of-domain
environments compared to the baselines.

</details>


### [287] [LLM-Guided Task- and Affordance-Level Exploration in Reinforcement Learning](https://arxiv.org/abs/2509.16615)
*Jelle Luijkx,Runyu Ma,Zlatan Ajanović,Jens Kober*

Main category: cs.RO

TL;DR: LLM-TALE是一个结合LLMs规划能力的强化学习框架，通过任务和可供性级别规划提高效率，实验证明其优于基线方法，并展示了零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人操纵中具有潜力，但存在样本效率低和需要探索大规模状态-动作空间的问题。现有方法利用LLMs的常识知识和推理能力引导探索，但LLMs生成的计划可能语义合理但物理不可行。

Method: LLM-TALE框架利用大型语言模型（LLMs）的规划能力直接引导强化学习（RL）的探索，包括任务级别和可供性级别的规划，并在线纠正次优计划，无需人工监督。

Result: 在标准RL基准测试中，LLM-TALE在拾取-放置任务中表现出更高的样本效率和成功率。真实机器人实验显示了零样本仿真到现实迁移的潜力。

Conclusion: LLM-TALE框架通过整合任务级别和可供性级别的规划，显著提高了强化学习的样本效率和成功率，并在真实机器人实验中展示了零样本仿真到现实的迁移潜力。

Abstract: Reinforcement learning (RL) is a promising approach for robotic manipulation,
but it can suffer from low sample efficiency and requires extensive exploration
of large state-action spaces. Recent methods leverage the commonsense knowledge
and reasoning abilities of large language models (LLMs) to guide exploration
toward more meaningful states. However, LLMs can produce plans that are
semantically plausible yet physically infeasible, yielding unreliable behavior.
We introduce LLM-TALE, a framework that uses LLMs' planning to directly steer
RL exploration. LLM-TALE integrates planning at both the task level and the
affordance level, improving learning efficiency by directing agents toward
semantically meaningful actions. Unlike prior approaches that assume optimal
LLM-generated plans or rewards, LLM-TALE corrects suboptimality online and
explores multimodal affordance-level plans without human supervision. We
evaluate LLM-TALE on pick-and-place tasks in standard RL benchmarks, observing
improvements in both sample efficiency and success rates over strong baselines.
Real-robot experiments indicate promising zero-shot sim-to-real transfer. Code
and supplementary material are available at https://llm-tale.github.io.

</details>


### [288] [KungfuBot2: Learning Versatile Motion Skills for Humanoid Whole-Body Control](https://arxiv.org/abs/2509.16638)
*Jinrui Han,Weiji Xie,Jiakun Zheng,Jiyuan Shi,Weinan Zhang,Ting Xiao,Chenjia Bai*

Main category: cs.RO

TL;DR: VMS是一个统一的人形机器人全身控制器，通过混合跟踪目标和OMoE架构学习多样化和动态行为，展示了在模仿动态技能和泛化到未见动作方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 学习多样化的全身技能以跟踪各种人类动作是迈向通用人形机器人的关键步骤，但挑战在于单一策略必须掌握广泛的运动技能并确保长时间序列的稳定性。

Method: VMS框架结合了混合跟踪目标（平衡局部运动保真度与全局轨迹一致性）和正交专家混合（OMoE）架构（促进技能专业化同时增强动作间的泛化能力），并引入了段级跟踪奖励以放松刚性步进匹配。

Result: 在仿真和真实世界实验中，VMS能够准确模仿动态技能、保持长时间序列的稳定性能，并对未见过的动作表现出强大的泛化能力。

Conclusion: VMS作为一个可扩展的基础框架，展示了在多功能人形机器人全身控制中的潜力，能够准确模仿动态技能、保持长时间序列的稳定性能，并对未见过的动作表现出强大的泛化能力。

Abstract: Learning versatile whole-body skills by tracking various human motions is a
fundamental step toward general-purpose humanoid robots. This task is
particularly challenging because a single policy must master a broad repertoire
of motion skills while ensuring stability over long-horizon sequences. To this
end, we present VMS, a unified whole-body controller that enables humanoid
robots to learn diverse and dynamic behaviors within a single policy. Our
framework integrates a hybrid tracking objective that balances local motion
fidelity with global trajectory consistency, and an Orthogonal
Mixture-of-Experts (OMoE) architecture that encourages skill specialization
while enhancing generalization across motions. A segment-level tracking reward
is further introduced to relax rigid step-wise matching, enhancing robustness
when handling global displacements and transient inaccuracies. We validate VMS
extensively in both simulation and real-world experiments, demonstrating
accurate imitation of dynamic skills, stable performance over minute-long
sequences, and strong generalization to unseen motions. These results highlight
the potential of VMS as a scalable foundation for versatile humanoid whole-body
control. The project page is available at
https://kungfubot2-humanoid.github.io.

</details>


### [289] [HDMI: Learning Interactive Humanoid Whole-Body Control from Human Videos](https://arxiv.org/abs/2509.16757)
*Haoyang Weng,Yitang Li,Nikhil Sobanbabu,Zihan Wang,Zhengyi Luo,Tairan He,Deva Ramanan,Guanya Shi*

Main category: cs.RO

TL;DR: HDMI框架通过单目RGB视频学习人形机器人-物体交互技能，实现了模拟到真实的零样本部署，展示了其简单性和通用性。


<details>
  <summary>Details</summary>
Motivation: 由于运动数据稀缺和接触丰富的特性，实现稳健的全身人形机器人-物体交互（HOI）具有挑战性。

Method: HDMI框架包括三个步骤：(i)从无约束视频中提取并重定向人类和物体轨迹以构建结构化运动数据集，(ii)通过强化学习策略训练机器人状态与物体状态协同跟踪，采用统一物体表示、残差动作空间和通用交互奖励设计，(iii)在真实人形机器人上零样本部署RL策略。

Result: 在Unitree G1人形机器人上的模拟到真实实验表明，HDMI实现了67次连续门穿越，并在真实世界中成功执行了6种不同的运动-操作任务，在模拟中执行了14种任务。

Conclusion: HDMI框架通过从单目RGB视频中学习，成功实现了人形机器人-物体交互技能的学习与零样本部署，展示了其简单性和通用性。

Abstract: Enabling robust whole-body humanoid-object interaction (HOI) remains
challenging due to motion data scarcity and the contact-rich nature. We present
HDMI (HumanoiD iMitation for Interaction), a simple and general framework that
learns whole-body humanoid-object interaction skills directly from monocular
RGB videos. Our pipeline (i) extracts and retargets human and object
trajectories from unconstrained videos to build structured motion datasets,
(ii) trains a reinforcement learning (RL) policy to co-track robot and object
states with three key designs: a unified object representation, a residual
action space, and a general interaction reward, and (iii) zero-shot deploys the
RL policies on real humanoid robots. Extensive sim-to-real experiments on a
Unitree G1 humanoid demonstrate the robustness and generality of our approach:
HDMI achieves 67 consecutive door traversals and successfully performs 6
distinct loco-manipulation tasks in the real world and 14 tasks in simulation.
Our results establish HDMI as a simple and general framework for acquiring
interactive humanoid skills from human videos.

</details>


### [290] [SMART-3D: Three-Dimensional Self-Morphing Adaptive Replanning Tree](https://arxiv.org/abs/2509.16812)
*Priyanshu Agrawal,Shalabh Gupta,Zongyuan Shen*

Main category: cs.RO

TL;DR: SMART-3D是SMART算法的3D扩展，通过热节点实现高效路径重规划，适用于动态环境。


<details>
  <summary>Details</summary>
Motivation: 针对动态环境中快速移动障碍物的路径规划问题，扩展SMART算法至3D环境，提升计算效率和可扩展性。

Method: SMART-3D基于树的自适应重规划算法，通过热节点实现树的变形以快速找到新路径，无需网格分解。

Result: 在2D和3D环境中的广泛模拟显示，SMART-3D具有高成功率和低重规划时间。

Conclusion: SMART-3D通过引入热节点概念，显著提高了在动态3D环境中的路径重规划效率，适用于实时应用。

Abstract: This paper presents SMART-3D, an extension of the SMART algorithm to 3D
environments. SMART-3D is a tree-based adaptive replanning algorithm for
dynamic environments with fast moving obstacles. SMART-3D morphs the underlying
tree to find a new path in real-time whenever the current path is blocked by
obstacles. SMART-3D removed the grid decomposition requirement of the SMART
algorithm by replacing the concept of hot-spots with that of hot-nodes, thus
making it computationally efficient and scalable to 3D environments. The
hot-nodes are nodes which allow for efficient reconnections to morph the
existing tree to find a new safe and reliable path. The performance of SMART-3D
is evaluated by extensive simulations in 2D and 3D environments populated with
randomly moving dynamic obstacles. The results show that SMART-3D achieves high
success rates and low replanning times, thus highlighting its suitability for
real-time onboard applications.

</details>


### [291] [Factorizing Diffusion Policies for Observation Modality Prioritization](https://arxiv.org/abs/2509.16830)
*Omkar Patil,Prabin Rath,Kartikay Pangaonkar,Eric Rosen,Nakul Gopalan*

Main category: cs.RO

TL;DR: FDP通过因子化观测条件，使不同模态对动作扩散过程产生不同影响，从而在低数据和高分布偏移情况下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 观测模态对不同任务的影响程度不同，但现有扩散策略无法捕捉这种差异。

Method: 提出了'Factorized Diffusion Policies' (FDP)，通过因子化观测条件来实现不同模态对动作扩散过程的不同影响。

Result: FDP在低数据条件下实现了15%的绝对成功率提升，并在分布偏移情况下表现出40%的更高绝对成功率。

Conclusion: FDP提供了一个比标准扩散策略更安全、更稳健的替代方案，适用于现实世界的机器人技能学习。

Abstract: Diffusion models have been extensively leveraged for learning robot skills
from demonstrations. These policies are conditioned on several observational
modalities such as proprioception, vision and tactile. However, observational
modalities have varying levels of influence for different tasks that diffusion
polices fail to capture. In this work, we propose 'Factorized Diffusion
Policies' abbreviated as FDP, a novel policy formulation that enables
observational modalities to have differing influence on the action diffusion
process by design. This results in learning policies where certain observations
modalities can be prioritized over the others such as $\texttt{vision>tactile}$
or $\texttt{proprioception>vision}$. FDP achieves modality prioritization by
factorizing the observational conditioning for diffusion process, resulting in
more performant and robust policies. Our factored approach shows strong
performance improvements in low-data regimes with $15\%$ absolute improvement
in success rate on several simulated benchmarks when compared to a standard
diffusion policy that jointly conditions on all input modalities. Moreover, our
benchmark and real-world experiments show that factored policies are naturally
more robust with $40\%$ higher absolute success rate across several visuomotor
tasks under distribution shifts such as visual distractors or camera
occlusions, where existing diffusion policies fail catastrophically. FDP thus
offers a safer and more robust alternative to standard diffusion policies for
real-world deployment. Videos are available at
https://fdp-policy.github.io/fdp-policy/ .

</details>


### [292] [Robot Learning with Sparsity and Scarcity](https://arxiv.org/abs/2509.16834)
*Jingxi Xu*

Main category: cs.RO

TL;DR: 论文针对机器人学习中的数据稀疏和稀缺问题，分别在触觉感知和康复机器人领域提出了解决方案，包括强化学习和多种机器学习算法，以最小数据量实现高效学习和意图推断。


<details>
  <summary>Details</summary>
Motivation: 机器人学习面临数据资源匮乏的挑战，尤其是在触觉感知和康复机器人领域。触觉数据稀疏，康复机器人数据稀缺，这限制了机器人的学习和应用。

Method: 在触觉感知领域，使用无模型强化学习来高效利用稀疏的触觉信息；在康复机器人领域，开发了包括半监督学习、元学习和生成式AI在内的机器学习算法，以实现最小数据量的意图推断。

Result: 在触觉感知领域，成功实现了仅依赖触觉信息的探索和操作策略；在康复机器人领域，开发了能够从少量数据中推断患者意图的算法，为康复机器人提供了有效的辅助。

Conclusion: 论文探讨了在机器人学习领域如何应对数据稀疏性和稀缺性的挑战，提出了在触觉感知和康复机器人两个领域的具体解决方案。

Abstract: Unlike in language or vision, one of the fundamental challenges in robot
learning is the lack of access to vast data resources. We can further break
down the problem into (1) data sparsity from the angle of data representation
and (2) data scarcity from the angle of data quantity. In this thesis, I will
discuss selected works on two domains: (1) tactile sensing and (2)
rehabilitation robots, which are exemplars of data sparsity and scarcity,
respectively. Tactile sensing is an essential modality for robotics, but
tactile data are often sparse, and for each interaction with the physical
world, tactile sensors can only obtain information about the local area of
contact. I will discuss my work on learning vision-free tactile-only
exploration and manipulation policies through model-free reinforcement learning
to make efficient use of sparse tactile information. On the other hand,
rehabilitation robots are an example of data scarcity to the extreme due to the
significant challenge of collecting biosignals from disabled-bodied subjects at
scale for training. I will discuss my work in collaboration with the medical
school and clinicians on intent inferral for stroke survivors, where a hand
orthosis developed in our lab collects a set of biosignals from the patient and
uses them to infer the activity that the patient intends to perform, so the
orthosis can provide the right type of physical assistance at the right moment.
My work develops machine learning algorithms that enable intent inferral with
minimal data, including semi-supervised, meta-learning, and generative AI
methods.

</details>


### [293] [Benchmarking Offline Reinforcement Learning for Emotion-Adaptive Social Robotics](https://arxiv.org/abs/2509.16858)
*Soon Jynn Chu,Raju Gottumukkala,Alan Barhorst*

Main category: cs.RO

TL;DR: 本研究探讨了离线强化学习在情感适应性社交机器人中的应用，提出了一种系统架构，并通过实验证明BCQ和CQL在数据稀疏性下表现更优。


<details>
  <summary>Details</summary>
Motivation: 在线强化学习在开发情感适应性社交机器人时因数据收集成本高和可能产生不安全行为而不实用，因此研究离线强化学习作为替代方案。

Method: 提出了一种集成多模态感知与识别、决策和自适应响应的系统架构，并在人机游戏场景的有限数据集上比较了无需在线环境的离线强化学习算法。

Result: 结果表明，BCQ和CQL在数据稀疏性下表现更稳健，相比NFQ、DQN和DDQN能获得更高的状态-动作值。

Conclusion: 本研究为情感适应性机器人中的离线强化学习建立了基准，并为未来在真实人机交互（HRI）中的部署提供了指导。

Abstract: The ability of social robots to respond to human emotions is crucial for
building trust and acceptance in human-robot collaborative environments.
However, developing such capabilities through online reinforcement learning is
sometimes impractical due to the prohibitive cost of data collection and the
risk of generating unsafe behaviors. In this paper, we study the use of offline
reinforcement learning as a practical and efficient alternative. This technique
uses pre-collected data to enable emotion-adaptive social robots. We present a
system architecture that integrates multimodal sensing and recognition,
decision-making, and adaptive responses. Using a limited dataset from a
human-robot game-playing scenario, we establish a benchmark for comparing
offline reinforcement learning algorithms that do not require an online
environment. Our results show that BCQ and CQL are more robust to data
sparsity, achieving higher state-action values compared to NFQ, DQN, and DDQN.
This work establishes a foundation for benchmarking offline RL in
emotion-adaptive robotics and informs future deployment in real-world HRI. Our
findings provide empirical insight into the performance of offline
reinforcement learning algorithms in data-constrained HRI. This work
establishes a foundation for benchmarking offline RL in emotion-adaptive
robotics and informs its future deployment in real-world HRI, such as in
conversational agents, educational partners, and personal assistants, require
reliable emotional responsiveness.

</details>


### [294] [HOGraspFlow: Exploring Vision-based Generative Grasp Synthesis with Hand-Object Priors and Taxonomy Awareness](https://arxiv.org/abs/2509.16871)
*Yitian Shi,Zicheng Guo,Rosa Wolf,Edgar Welte,Rania Rayyes*

Main category: cs.RO

TL;DR: HOGraspFlow利用去噪流匹配和多种视觉线索，从单张RGB图像生成多模态抓取姿态，无需几何先验，实际成功率超过83%。


<details>
  <summary>Details</summary>
Motivation: 目标是通过单张RGB图像和手-物体交互（HOI）生成多模态可执行的平行夹爪抓取姿态，而无需依赖目标物体的显式几何先验。

Method: 该方法基于基础模型进行手部重建和视觉分析，利用去噪流匹配（FM）在SE(3)空间中合成抓取姿态，结合RGB视觉语义、HOI接触重建和抓取类型分类三个互补线索。

Result: HOGraspFlow在抓取合成中表现出高保真度，无需显式HOI接触输入或物体几何信息，同时在接触和分类识别上表现优异。与基于扩散的变体（HOGraspDiff）相比，HOGraspFlow在SE(3)中实现了更高的分布保真度和更稳定的优化。

Conclusion: Hand-ObjectGraspFlow（HOGraspFlow）是一种高效的、无需显式几何先验的多模态抓取姿态生成方法，通过结合RGB基础特征、手-物体交互接触重建和抓取类型分类，实现了高保真度的抓取合成，并在实际实验中达到了83%以上的平均成功率。

Abstract: We propose Hand-Object\emph{(HO)GraspFlow}, an affordance-centric approach
that retargets a single RGB with hand-object interaction (HOI) into multi-modal
executable parallel jaw grasps without explicit geometric priors on target
objects. Building on foundation models for hand reconstruction and vision, we
synthesize $SE(3)$ grasp poses with denoising flow matching (FM), conditioned
on the following three complementary cues: RGB foundation features as visual
semantics, HOI contact reconstruction, and taxonomy-aware prior on grasp types.
Our approach demonstrates high fidelity in grasp synthesis without explicit HOI
contact input or object geometry, while maintaining strong contact and taxonomy
recognition. Another controlled comparison shows that \emph{HOGraspFlow}
consistently outperforms diffusion-based variants (\emph{HOGraspDiff}),
achieving high distributional fidelity and more stable optimization in $SE(3)$.
We demonstrate a reliable, object-agnostic grasp synthesis from human
demonstrations in real-world experiments, where an average success rate of over
$83\%$ is achieved.

</details>


### [295] [End2Race: Efficient End-to-End Imitation Learning for Real-Time F1Tenth Racing](https://arxiv.org/abs/2509.16894)
*Zhijie Qiao,Haowei Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: End2Race是一种高效的端到端模仿学习算法，专为F1Tenth赛车设计，通过GRU架构和LiDAR数据归一化，实现了高安全率和超车率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶赛车需要与经典自动驾驶不同的算法，且高速决策需求限制了模型容量，因此需要开发高效的端到端模仿学习算法。

Method: 采用Gated Recurrent Unit (GRU)架构捕捉连续时间依赖性，结合sigmoid-based归一化函数处理原始LiDAR数据，实现高效训练和推理。

Result: 在F1Tenth模拟器中，End2Race在2400次超车场景中安全率为94.2%，成功超车率为59.2%，推理时间低于0.5毫秒。

Conclusion: End2Race算法在F1Tenth赛车测试平台上表现出色，安全率达到94.2%，成功超车率为59.2%，超越了现有方法，成为领先解决方案。

Abstract: F1Tenth is a widely adopted reduced-scale platform for developing and testing
autonomous racing algorithms, hosting annual competitions worldwide. With high
operating speeds, dynamic environments, and head-to-head interactions,
autonomous racing requires algorithms that diverge from those in classical
autonomous driving. Training such algorithms is particularly challenging: the
need for rapid decision-making at high speeds severely limits model capacity.
To address this, we propose End2Race, a novel end-to-end imitation learning
algorithm designed for head-to-head autonomous racing. End2Race leverages a
Gated Recurrent Unit (GRU) architecture to capture continuous temporal
dependencies, enabling both short-term responsiveness and long-term strategic
planning. We also adopt a sigmoid-based normalization function that transforms
raw LiDAR scans into spatial pressure tokens, facilitating effective model
training and convergence. The algorithm is extremely efficient, achieving an
inference time of less than 0.5 milliseconds on a consumer-class GPU.
Experiments in the F1Tenth simulator demonstrate that End2Race achieves a 94.2%
safety rate across 2,400 overtaking scenarios, each with an 8-second time
limit, and successfully completes overtakes in 59.2% of cases. This surpasses
previous methods and establishes ours as a leading solution for the F1Tenth
racing testbed. Code is available at
https://github.com/michigan-traffic-lab/End2Race.

</details>


### [296] [SwarmChat: An LLM-Based, Context-Aware Multimodal Interaction System for Robotic Swarms](https://arxiv.org/abs/2509.16920)
*Ettilla Mohiuddin Eumi,Hussein Abbass,Nadine Marcus*

Main category: cs.RO

TL;DR: SwarmChat是一个基于LLM的多模态人机交互系统，通过四个模块和三层次架构，显著提升了HSI的效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 传统HSI方法缺乏直观的实时自适应接口，导致决策速度慢、认知负荷高且命令灵活性受限。

Method: 系统集成了四个基于LLM的模块（Context Generator、Intent Recognition、Task Planner、Modality Selector），采用三层架构，支持多模态交互。

Result: 初步评估显示，SwarmChat的LLM模块在情境解释、意图识别和命令传递方面表现优异。

Conclusion: SwarmChat通过LLM模块实现了准确的情境解释、意图识别和有效命令传递，用户满意度高。

Abstract: Traditional Human-Swarm Interaction (HSI) methods often lack intuitive
real-time adaptive interfaces, making decision making slower and increasing
cognitive load while limiting command flexibility. To solve this, we present
SwarmChat, a context-aware, multimodal interaction system powered by Large
Language Models (LLMs). SwarmChat enables users to issue natural language
commands to robotic swarms using multiple modalities, such as text, voice, or
teleoperation. The system integrates four LLM-based modules: Context Generator,
Intent Recognition, Task Planner, and Modality Selector. These modules
collaboratively generate context from keywords, detect user intent, adapt
commands based on real-time robot state, and suggest optimal communication
modalities. Its three-layer architecture offers a dynamic interface with both
fixed and customizable command options, supporting flexible control while
optimizing cognitive effort. The preliminary evaluation also shows that the
SwarmChat's LLM modules provide accurate context interpretation, relevant
intent recognition, and effective command delivery, achieving high user
satisfaction.

</details>


### [297] [A Reliable Robot Motion Planner in Complex Real-world Environments via Action Imagination](https://arxiv.org/abs/2509.16963)
*Chengjin Wang,Yanmin Zhou,Zhipeng Wang,Zheng Yan,Feng Luan,Shuo Jiang,Runjie Shen,Hongrui Sang,Bin He*

Main category: cs.RO

TL;DR: I-MP框架通过想象空间状态和构建感知-动作循环，提升机器人在复杂环境中的动作可靠性，实验结果证实其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受动物智能的动作感知能力启发，研究旨在通过想象动作结果来增强机器人在未知非结构化环境中的动作可靠性，以应对感知和系统建模中的不确定性。

Method: I-MP框架通过拓扑化工作空间，构建感知-动作循环，使机器人能够自主建立接触模型。利用不动点理论和Hausdorff距离，规划器在交互特性和任务约束下计算收敛的空间状态。通过工作均匀表示多维环境特性，机器人通过实时计算能量梯度接近想象的空间状态。

Result: 实验结果表明，I-MP框架在复杂杂乱环境中表现出实用性和鲁棒性，能够有效处理物理交互引发的不确定性。

Conclusion: 本研究提出的I-MP框架通过想象驱动的运动规划，显著提升了机器人在复杂杂乱环境中的动作可靠性。实验结果表明，该框架在未知非结构化环境中具有实用性和鲁棒性。

Abstract: Humans and animals can make real-time adjustments to movements by imagining
their action outcomes to prevent unanticipated or even catastrophic motion
failures in unknown unstructured environments. Action imagination, as a refined
sensorimotor strategy, leverages perception-action loops to handle physical
interaction-induced uncertainties in perception and system modeling within
complex systems. Inspired by the action-awareness capability of animal
intelligence, this study proposes an imagination-inspired motion planner (I-MP)
framework that specifically enhances robots' action reliability by imagining
plausible spatial states for approaching. After topologizing the workspace,
I-MP build perception-action loop enabling robots autonomously build contact
models. Leveraging fixed-point theory and Hausdorff distance, the planner
computes convergent spatial states under interaction characteristics and
mission constraints. By homogenously representing multi-dimensional
environmental characteristics through work, the robot can approach the imagined
spatial states via real-time computation of energy gradients. Consequently,
experimental results demonstrate the practicality and robustness of I-MP in
complex cluttered environments.

</details>


### [298] [Geometric Interpolation of Rigid Body Motions](https://arxiv.org/abs/2509.16966)
*Andreas Mueller*

Main category: cs.RO

TL;DR: 论文提出了两种刚性体运动插值方法（k-IV-TIP和k-BV-TIP），解决了高阶导数条件下的轨迹插值问题，并展示了具体解决方案和数值结果。


<details>
  <summary>Details</summary>
Motivation: 解决刚性体运动在初始和终端姿态之间的空间轨迹插值问题，特别是满足高阶导数条件的情况。

Method: 通过满足初始和终端姿态的k-1导数条件，解决了k-IV-TIP和k-BV-TIP问题。具体包括1-IV-TBP的立方插值和更高阶解的推导方法。

Result: 提出了k-IV-TIP（k=1,...,4）和1-IV-TBP的解决方案，并展示了数值结果。

Conclusion: 论文提出了解决刚性体运动插值问题的两种方法：k-IV-TIP和k-BV-TIP，并展示了具体的解决方案和数值结果。

Abstract: The problem of interpolating a rigid body motion is to find a spatial
trajectory between a prescribed initial and terminal pose. Two variants of this
interpolation problem are addressed. The first is to find a solution that
satisfies initial conditions on the k-1 derivatives of the rigid body twist.
This is called the kth-order initial value trajectory interpolation problem
(k-IV-TIP). The second is to find a solution that satisfies conditions on the
rigid body twist and its k-1 derivatives at the initial and terminal pose. This
is called the kth-order boundary value trajectory interpolation problem
(k-BV-TIP). Solutions to the k-IV-TIP for k=1,...,4, i.e. the initial twist and
up to the 4th time derivative are prescribed. Further, a solution to the
1-IV-TBP is presented, i.e. the initial and terminal twist are prescribed. The
latter is a novel cubic interpolation between two spatial configurations with
given initial and terminal twist. This interpolation is automatically identical
to the minimum acceleration curve when the twists are set to zero. The general
approach to derive higher-order solutions is presented. Numerical results are
shown for two examples.

</details>


### [299] [IDfRA: Self-Verification for Iterative Design in Robotic Assembly](https://arxiv.org/abs/2509.16998)
*Nishka Khendry,Christos Margadji,Sebastian W. Pattinson*

Main category: cs.RO

TL;DR: IDfRA框架通过迭代自评估和适应，显著提升机器人组装设计的质量与成功率，适用于非结构化制造场景。


<details>
  <summary>Details</summary>
Motivation: 传统DfRA方法依赖手动规划，耗时且不适用于复杂对象，而现有LLM方法依赖启发式策略和硬编码物理模拟器，难以适应现实组装场景。

Method: IDfRA采用迭代循环的规划、执行、验证和重新规划方法，通过自评估逐步提升设计质量，无需依赖物理模拟。

Result: IDfRA在语义识别准确率上达到73.3%，组装成功率为86.9%，设计质量随迭代提升。

Conclusion: IDfRA框架通过结合自验证和上下文感知适应，展示了在非结构化制造场景中部署的强大潜力，显著提高了设计质量和组装成功率。

Abstract: As robots proliferate in manufacturing, Design for Robotic Assembly (DfRA),
which is designing products for efficient automated assembly, is increasingly
important. Traditional approaches to DfRA rely on manual planning, which is
time-consuming, expensive and potentially impractical for complex objects.
Large language models (LLM) have exhibited proficiency in semantic
interpretation and robotic task planning, stimulating interest in their
application to the automation of DfRA. But existing methodologies typically
rely on heuristic strategies and rigid, hard-coded physics simulators that may
not translate into real-world assembly contexts. In this work, we present
Iterative Design for Robotic Assembly (IDfRA), a framework using iterative
cycles of planning, execution, verification, and re-planning, each informed by
self-assessment, to progressively enhance design quality within a fixed yet
initially under-specified environment, thereby eliminating the physics
simulation with the real world itself. The framework accepts as input a target
structure together with a partial environmental representation. Through
successive refinement, it converges toward solutions that reconcile semantic
fidelity with physical feasibility. Empirical evaluation demonstrates that
IDfRA attains 73.3\% top-1 accuracy in semantic recognisability, surpassing the
baseline on this metric. Moreover, the resulting assembly plans exhibit robust
physical feasibility, achieving an overall 86.9\% construction success rate,
with design quality improving across iterations, albeit not always
monotonically. Pairwise human evaluation further corroborates the advantages of
IDfRA relative to alternative approaches. By integrating self-verification with
context-aware adaptation, the framework evidences strong potential for
deployment in unstructured manufacturing scenarios.

</details>


### [300] [Generalized Momenta-Based Koopman Formalism for Robust Control of Euler-Lagrangian Systems](https://arxiv.org/abs/2509.17010)
*Rajpal Singh,Aditya Singh,Chidre Shravista Kashyap,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 本文提出了一种基于广义动量的Koopman算子框架，显著降低了模型复杂度并提高了效率，通过实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统显式公式将输入与状态相关项非线性耦合，导致双线性Koopman模型计算成本高。本文旨在通过结构分离，仅需学习非驱动动力学，从而减少参数数量、提高数据效率并降低模型复杂度。

Method: 论文提出了两种神经网络架构，用于从驱动或非驱动数据中构建Koopman嵌入，并结合线性广义扩展状态观测器（GESO）实时估计和补偿扰动，确保鲁棒性。

Result: 提出的线性模型在预测性能上优于传统双线性模型，同时保持更高的效率。在机器人操作器的轨迹跟踪仿真和实验中验证了其优越性。

Conclusion: 该论文提出了一种新颖的Koopman算子框架，通过隐含的广义动量状态空间表示，显著提升了线性Koopman建模的效率，并在机器人操作器上验证了其优越的准确性、鲁棒性和学习效率。

Abstract: This paper presents a novel Koopman operator formulation for Euler Lagrangian
dynamics that employs an implicit generalized momentum-based state space
representation, which decouples a known linear actuation channel from state
dependent dynamics and makes the system more amenable to linear Koopman
modeling. By leveraging this structural separation, the proposed formulation
only requires to learn the unactuated dynamics rather than the complete
actuation dependent system, thereby significantly reducing the number of
learnable parameters, improving data efficiency, and lowering overall model
complexity. In contrast, conventional explicit formulations inherently couple
inputs with the state dependent terms in a nonlinear manner, making them more
suitable for bilinear Koopman models, which are more computationally expensive
to train and deploy. Notably, the proposed scheme enables the formulation of
linear models that achieve superior prediction performance compared to
conventional bilinear models while remaining substantially more efficient. To
realize this framework, we present two neural network architectures that
construct Koopman embeddings from actuated or unactuated data, enabling
flexible and efficient modeling across different tasks. Robustness is ensured
through the integration of a linear Generalized Extended State Observer (GESO),
which explicitly estimates disturbances and compensates for them in real time.
The combined momentum-based Koopman and GESO framework is validated through
comprehensive trajectory tracking simulations and experiments on robotic
manipulators, demonstrating superior accuracy, robustness, and learning
efficiency relative to state of the art alternatives.

</details>


### [301] [Orchestrate, Generate, Reflect: A VLM-Based Multi-Agent Collaboration Framework for Automated Driving Policy Learning](https://arxiv.org/abs/2509.17042)
*Zengqi Peng,Yusen Xie,Yubin Wang,Rui Yang,Qifeng Chen,Jun Ma*

Main category: cs.RO

TL;DR: OGR框架通过VLM多智能体协作自动生成奖励-课程对，显著提升自动驾驶策略学习效率，仿真和实际测试均验证其性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶策略学习中人工设计奖励函数和训练课程的高成本和时间消耗问题。

Method: 提出OGR框架，利用VLM的多模态理解和推理能力，构建分层智能体系统，包括中央协调器、生成模块、反思模块和记忆模块。采用并行生成和人机交互技术增强奖励空间多样性。

Result: 在CARLA仿真中表现出色，具有强泛化能力和与多种RL算法的兼容性。实际测试验证了其可行性和有效性。

Conclusion: OGR框架通过多智能体协作和VLM的先进能力，实现了自动驾驶策略的高效学习，并在仿真和实际测试中展现了卓越性能和泛化能力。

Abstract: The advancement of foundation models fosters new initiatives for policy
learning in achieving safe and efficient autonomous driving. However, a
critical bottleneck lies in the manual engineering of reward functions and
training curricula for complex and dynamic driving tasks, which is a
labor-intensive and time-consuming process. To address this problem, we propose
OGR (Orchestrate, Generate, Reflect), a novel automated driving policy learning
framework that leverages vision-language model (VLM)-based multi-agent
collaboration. Our framework capitalizes on advanced reasoning and multimodal
understanding capabilities of VLMs to construct a hierarchical agent system.
Specifically, a centralized orchestrator plans high-level training objectives,
while a generation module employs a two-step analyze-then-generate process for
efficient generation of reward-curriculum pairs. A reflection module then
facilitates iterative optimization based on the online evaluation. Furthermore,
a dedicated memory module endows the VLM agents with the capabilities of
long-term memory. To enhance robustness and diversity of the generation
process, we introduce a parallel generation scheme and a human-in-the-loop
technique for augmentation of the reward observation space. Through efficient
multi-agent cooperation and leveraging rich multimodal information, OGR enables
the online evolution of reinforcement learning policies to acquire
interaction-aware driving skills. Extensive experiments in the CARLA simulator
demonstrate the superior performance, robust generalizability across distinct
urban scenarios, and strong compatibility with various RL algorithms. Further
real-world experiments highlight the practical viability and effectiveness of
our framework. The source code will be available upon acceptance of the paper.

</details>


### [302] [FILIC: Dual-Loop Force-Guided Imitation Learning with Impedance Torque Control for Contact-Rich Manipulation Tasks](https://arxiv.org/abs/2509.17053)
*Haizhou Ge,Yufei Jia,Zheng Li,Yue Li,Zhixing Chen,Ruqi Huang,Guyue Zhou*

Main category: cs.RO

TL;DR: FILIC框架通过Transformer-based IL策略与阻抗控制器的结合，实现了力感知的接触操作，无需昂贵力传感器，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决现有模仿学习策略在力控制方面的不足，以及为无扭矩传感器的协作机械臂提供低成本解决方案。

Method: 提出FILIC框架，整合Transformer-based IL策略与阻抗控制器，采用双环结构实现力感知和力执行操作。对于无力/扭矩传感器的机器人，使用基于解析雅可比逆的关节扭矩测量进行低成本力估计，并通过数字孪生模型预测扭矩进行补偿。此外，设计了手持触觉和VR可视化的力反馈框架。

Result: FILIC在实验中显著优于仅基于视觉和关节扭矩的方法，实现了更安全、合规且适应性强的接触丰富操作。

Conclusion: FILIC框架通过结合Transformer-based IL策略和阻抗控制器，显著提升了接触丰富操作任务的安全性、适应性和合规性，同时通过低成本力估计器和力反馈框架解决了硬件限制问题。

Abstract: Contact-rich manipulation is crucial for robots to perform tasks requiring
precise force control, such as insertion, assembly, and in-hand manipulation.
However, most imitation learning (IL) policies remain position-centric and lack
explicit force awareness, and adding force/torque sensors to collaborative
robot arms is often costly and requires additional hardware design. To overcome
these issues, we propose FILIC, a Force-guided Imitation Learning framework
with impedance torque control. FILIC integrates a Transformer-based IL policy
with an impedance controller in a dual-loop structure, enabling compliant
force-informed, force-executed manipulation. For robots without force/torque
sensors, we introduce a cost-effective end-effector force estimator using joint
torque measurements through analytical Jacobian-based inversion while
compensating with model-predicted torques from a digital twin. We also design
complementary force feedback frameworks via handheld haptics and VR
visualization to improve demonstration quality. Experiments show that FILIC
significantly outperforms vision-only and joint-torque-based methods, achieving
safer, more compliant, and adaptable contact-rich manipulation. Our code can be
found in https://github.com/TATP-233/FILIC.

</details>


### [303] [RoboManipBaselines: A Unified Framework for Imitation Learning in Robotic Manipulation across Real and Simulated Environments](https://arxiv.org/abs/2509.17057)
*Masaki Murooka,Tomohiro Motoda,Ryoichi Nakajo,Hanbit Oh,Koshi Makihara,Keisuke Shirai,Yukiyasu Domae*

Main category: cs.RO

TL;DR: RoboManipBaselines是一个开放的机器人模仿学习框架，统一了仿真和真实机器人的数据、训练和评估，强调集成性、通用性和可复现性。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人模仿学习领域缺乏统一、可扩展且易于复现的平台的问题，RoboManipBaselines旨在提供一个集成化的解决方案。

Method: 该框架整合了仿真和真实机器人的数据收集、训练和评估流程，支持多样化任务、机器人和多模态策略的系统性基准测试。

Result: RoboManipBaselines成功实现了在仿真和真实机器人上的统一工作流程，为多样化任务和策略提供了基准测试能力。

Conclusion: RoboManipBaselines作为一个开放框架，为机器人模仿学习提供了一个统一的数据收集、训练和评估平台，强调了集成性、通用性、可扩展性和可重复性。

Abstract: RoboManipBaselines is an open framework for robot imitation learning that
unifies data collection, training, and evaluation across simulation and real
robots. We introduce it as a platform enabling systematic benchmarking of
diverse tasks, robots, and multimodal policies with emphasis on integration,
generality, extensibility, and reproducibility.

</details>


### [304] [CoPlanner: An Interactive Motion Planner with Contingency-Aware Diffusion for Autonomous Driving](https://arxiv.org/abs/2509.17080)
*Ruiguo Zhong,Ruoyu Yao,Pei Liu,Xiaolong Chen,Rui Yang,Jun Ma*

Main category: cs.RO

TL;DR: CoPlanner是一个结合轨迹生成和应急规划的框架，显著提升了自动驾驶在复杂环境中的安全性和舒适性。


<details>
  <summary>Details</summary>
Motivation: 解决当前自动驾驶系统中轨迹预测与运动规划模块分离导致的社交不一致和缺乏应急策略的问题，以提高在复杂交互环境中的安全性和鲁棒性。

Method: 提出了一种名为CoPlanner的统一框架，结合了多智能体交互轨迹生成和应急感知运动规划，采用支点条件扩散机制和应急感知多场景评分策略。

Result: 在nuPlan基准测试的Val14和Test14数据集上，CoPlanner在安全性和舒适性方面均优于现有最先进方法。

Conclusion: CoPlanner框架在nuPlan基准测试中显著提升了自动驾驶系统的安全性和舒适性，尤其在反应性和非反应性设置下表现优异。

Abstract: Accurate trajectory prediction and motion planning are crucial for autonomous
driving systems to navigate safely in complex, interactive environments
characterized by multimodal uncertainties. However, current
generation-then-evaluation frameworks typically construct multiple plausible
trajectory hypotheses but ultimately adopt a single most likely outcome,
leading to overconfident decisions and a lack of fallback strategies that are
vital for safety in rare but critical scenarios. Moreover, the usual decoupling
of prediction and planning modules could result in socially inconsistent or
unrealistic joint trajectories, especially in highly interactive traffic. To
address these challenges, we propose a contingency-aware diffusion planner
(CoPlanner), a unified framework that jointly models multi-agent interactive
trajectory generation and contingency-aware motion planning. Specifically, the
pivot-conditioned diffusion mechanism anchors trajectory sampling on a
validated, shared short-term segment to preserve temporal consistency, while
stochastically generating diverse long-horizon branches that capture multimodal
motion evolutions. In parallel, we design a contingency-aware multi-scenario
scoring strategy that evaluates candidate ego trajectories across multiple
plausible long-horizon evolution scenarios, balancing safety, progress, and
comfort. This integrated design preserves feasible fallback options and
enhances robustness under uncertainty, leading to more realistic
interaction-aware planning. Extensive closed-loop experiments on the nuPlan
benchmark demonstrate that CoPlanner consistently surpasses state-of-the-art
methods on both Val14 and Test14 datasets, achieving significant improvements
in safety and comfort under both reactive and non-reactive settings. Code and
model will be made publicly available upon acceptance.

</details>


### [305] [Imagine2Act: Leveraging Object-Action Motion Consistency from Imagined Goals for Robotic Manipulation](https://arxiv.org/abs/2509.17125)
*Liang Heng,Jiadong Xu,Yiwen Wang,Xiaoqi Li,Muhe Cai,Yan Shen,Juan Zhu,Guanghui Ren,Hao Dong*

Main category: cs.RO

TL;DR: Imagine2Act通过结合语义和几何约束的3D模仿学习框架，显著提升了机器人高精度操作任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预收集的演示或生成目标状态观测，但前者难以捕捉复杂几何约束，后者因生成噪声导致动作预测错误。为解决这些限制，提出了Imagine2Act。

Method: Imagine2Act 是一个3D模仿学习框架，通过生成基于语言指令的想象目标图像并重建对应的3D点云，为策略学习提供语义和几何先验。采用对象-动作一致性策略和软姿态监督，显式对齐预测的末端执行器运动与生成的对象变换。

Result: 实验表明，Imagine2Act在模拟和现实世界中均优于现有最先进策略。

Conclusion: Imagine2Act 通过结合语义和几何约束，显著提升了机器人执行高精度操作任务的能力，实验证明其在模拟和现实世界中均优于现有最先进方法。

Abstract: Relational object rearrangement (ROR) tasks (e.g., insert flower to vase)
require a robot to manipulate objects with precise semantic and geometric
reasoning. Existing approaches either rely on pre-collected demonstrations that
struggle to capture complex geometric constraints or generate goal-state
observations to capture semantic and geometric knowledge, but fail to
explicitly couple object transformation with action prediction, resulting in
errors due to generative noise. To address these limitations, we propose
Imagine2Act, a 3D imitation-learning framework that incorporates semantic and
geometric constraints of objects into policy learning to tackle high-precision
manipulation tasks. We first generate imagined goal images conditioned on
language instructions and reconstruct corresponding 3D point clouds to provide
robust semantic and geometric priors. These imagined goal point clouds serve as
additional inputs to the policy model, while an object-action consistency
strategy with soft pose supervision explicitly aligns predicted end-effector
motion with generated object transformation. This design enables Imagine2Act to
reason about semantic and geometric relationships between objects and predict
accurate actions across diverse tasks. Experiments in both simulation and the
real world demonstrate that Imagine2Act outperforms previous state-of-the-art
policies. More visualizations can be found at
https://sites.google.com/view/imagine2act.

</details>


### [306] [History-Aware Visuomotor Policy Learning via Point Tracking](https://arxiv.org/abs/2509.17141)
*Jingjing Chen,Hongjie Fang,Chenxi Wang,Shiquan Wang,Cewu Lu*

Main category: cs.RO

TL;DR: 提出基于点跟踪的对象中心历史表示方法，显著提升视觉运动策略在记忆需求任务中的表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 许多操作任务需要超越当前观测的记忆能力，而现有的视觉运动策略因依赖马尔可夫假设而难以处理重复状态或长时依赖。现有方法在扩展观测视野方面仍不足。

Method: 我们提出了一种基于点跟踪的对象中心历史表示方法，将过去观测抽象为紧凑且结构化的形式，仅保留任务相关的关键信息。跟踪的点在对象级别编码和聚合，形成高效的历史表示，可无缝集成到各种视觉运动策略中。

Result: 在多样化操作任务上的广泛评估表明，我们的方法能够满足多种记忆需求（如任务阶段识别、空间记忆、动作计数及长期需求如连续和预加载记忆），并一致优于马尔可夫基线和历史方法。

Conclusion: 通过基于点跟踪的对象中心历史表示方法，我们的研究显著提升了视觉运动策略在多样化记忆需求任务中的表现，优于现有的马尔可夫基线和历史方法。

Abstract: Many manipulation tasks require memory beyond the current observation, yet
most visuomotor policies rely on the Markov assumption and thus struggle with
repeated states or long-horizon dependencies. Existing methods attempt to
extend observation horizons but remain insufficient for diverse memory
requirements. To this end, we propose an object-centric history representation
based on point tracking, which abstracts past observations into a compact and
structured form that retains only essential task-relevant information. Tracked
points are encoded and aggregated at the object level, yielding a compact
history representation that can be seamlessly integrated into various
visuomotor policies. Our design provides full history-awareness with high
computational efficiency, leading to improved overall task performance and
decision accuracy. Through extensive evaluations on diverse manipulation tasks,
we show that our method addresses multiple facets of memory requirements - such
as task stage identification, spatial memorization, and action counting, as
well as longer-term demands like continuous and pre-loaded memory - and
consistently outperforms both Markovian baselines and prior history-based
approaches. Project website: http://tonyfang.net/history

</details>


### [307] [MAST: Multi-Agent Spatial Transformer for Learning to Collaborate](https://arxiv.org/abs/2509.17195)
*Damian Owerko,Frederic Vatnsdal,Saurav Agarwal,Vijay Kumar,Alejandro Ribeiro*

Main category: cs.RO

TL;DR: MAST是一种去中心化变压器架构，通过新颖的注意力机制解决多机器人协作中的通信问题，表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模去中心化协作多机器人系统（DC-MRS）中的协作挑战，包括部分可观测状态、有限通信范围和无中央服务器等限制。

Method: MAST采用去中心化变压器架构，结合新的位置编码策略和窗口化注意力操作，以限制感知范围并保持局部计算、平移等变性和排列等变性。

Result: MAST在去中心化分配与导航（DAN）和去中心化覆盖控制任务中表现优异，对通信延迟具有鲁棒性，并能扩展到大规模团队。

Conclusion: MAST是一种有效的去中心化变压器架构，通过新颖的位置编码策略和注意力操作，解决了大规模去中心化协作多机器人系统中的通信挑战，并在任务性能上优于基线和其他基于学习的方法。

Abstract: This article presents a novel multi-agent spatial transformer (MAST) for
learning communication policies in large-scale decentralized and collaborative
multi-robot systems (DC-MRS). Challenges in collaboration in DC-MRS arise from:
(i) partial observable states as robots make only localized perception, (ii)
limited communication range with no central server, and (iii) independent
execution of actions. The robots need to optimize a common task-specific
objective, which, under the restricted setting, must be done using a
communication policy that exhibits the desired collaborative behavior. The
proposed MAST is a decentralized transformer architecture that learns
communication policies to compute abstract information to be shared with other
agents and processes the received information with the robot's own
observations. The MAST extends the standard transformer with new positional
encoding strategies and attention operations that employ windowing to limit the
receptive field for MRS. These are designed for local computation,
shift-equivariance, and permutation equivariance, making it a promising
approach for DC-MRS. We demonstrate the efficacy of MAST on decentralized
assignment and navigation (DAN) and decentralized coverage control. Efficiently
trained using imitation learning in a centralized setting, the decentralized
MAST policy is robust to communication delays, scales to large teams, and
performs better than the baselines and other learning-based approaches.

</details>


### [308] [Certifiably Optimal Doppler Positioning using Opportunistic LEO Satellites](https://arxiv.org/abs/2509.17198)
*Baoshan Song,Weisong Wen,Qi Zhang,Bing Xu,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 提出了一种无需初始化的全局最优LEO多普勒定位方法，通过凸优化技术显著提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于多普勒定位问题是非凸的，传统局部搜索方法在无精确初始估计时可能陷入局部最优解，因此在未知环境中需要一种无需初始化的全局优化方法。

Method: 通过毕业权重近似（GWA）算法和半定规划（SDP）松弛技术实现可证明最优的定位方法，并推导了理想无噪声情况下的最优性必要条件及噪声情况下的充分噪声边界条件。

Result: 仿真和实际测试（如使用Iridium-NEXT卫星）表明，该方法在无初始估计时可实现3D定位误差140米，优于传统方法（如Gauss-Newton和Dog-Leg），并能作为局部搜索方法的初始化进一步降低误差至130米。

Conclusion: 该论文提出了一种通过凸优化实现的具有可证明最优性的LEO多普勒定位方法，在无初始估计的情况下仍能保证全局最优解，显著提高了定位精度和鲁棒性。

Abstract: To provide backup and augmentation to global navigation satellite system
(GNSS), Doppler shift from Low Earth Orbit (LEO) satellites can be employed as
signals of opportunity (SOP) for position, navigation and timing (PNT). Since
the Doppler positioning problem is non-convex, local searching methods may
produce two types of estimates: a global optimum without notice or a local
optimum given an inexact initial estimate. As exact initialization is
unavailable in some unknown environments, a guaranteed global optimization
method in no need of initialization becomes necessary. To achieve this goal, we
propose a certifiably optimal LEO Doppler positioning method by utilizing
convex optimization. In this paper, the certifiable positioning method is
implemented through a graduated weight approximation (GWA) algorithm and
semidefinite programming (SDP) relaxation. To guarantee the optimality, we
derive the necessary conditions for optimality in ideal noiseless cases and
sufficient noise bounds conditions in noisy cases. Simulation and real tests
are conducted to evaluate the effectiveness and robustness of the proposed
method. Specially, the real test using Iridium-NEXT satellites shows that the
proposed method estimates an certifiably optimal solution with an 3D
positioning error of 140 m without initial estimates while Gauss-Newton and
Dog-Leg are trapped in local optima when the initial point is equal or larger
than 1000 km away from the ground truth. Moreover, the certifiable estimation
can also be used as initialization in local searching methods to lower down the
3D positioning error to 130 m.

</details>


### [309] [Ratatouille: Imitation Learning Ingredients for Real-world Social Robot Navigation](https://arxiv.org/abs/2509.17204)
*James R. Han,Mithun Vanniasinghe,Hshmat Sahak,Nicholas Rhinehart,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: Ratatouille框架通过优化模仿学习设计，显著提升了社交机器人导航的性能，无需额外数据。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在社交机器人导航中数据密集和不安全的问题，模仿学习（IL）提供了一种安全且高效的替代方案。

Method: 提出了Ratatouille框架和模型架构，通过优化行为克隆（BC）的应用，减少碰撞并提高成功率。

Result: 在模拟和现实世界（如大学校园和公共美食广场）的验证中，碰撞率降低了6倍，成功率提高了3倍。

Conclusion: 通过精心设计的模仿学习（IL）架构和训练方法（如Ratatouille），在不增加数据的情况下，显著提升了社交机器人导航的安全性和可靠性。

Abstract: Scaling Reinforcement Learning to in-the-wild social robot navigation is both
data-intensive and unsafe, since policies must learn through direct interaction
and inevitably encounter collisions. Offline Imitation learning (IL) avoids
these risks by collecting expert demonstrations safely, training entirely
offline, and deploying policies zero-shot. However, we find that naively
applying Behaviour Cloning (BC) to social navigation is insufficient; achieving
strong performance requires careful architectural and training choices. We
present Ratatouille, a pipeline and model architecture that, without changing
the data, reduces collisions per meter by 6 times and improves success rate by
3 times compared to naive BC. We validate our approach in both simulation and
the real world, where we collected over 11 hours of data on a dense university
campus. We further demonstrate qualitative results in a public food court. Our
findings highlight that thoughtful IL design, rather than additional data, can
substantially improve safety and reliability in real-world social navigation.
Video: https://youtu.be/tOdLTXsaYLQ. Code will be released after acceptance.

</details>


### [310] [Combining Performance and Passivity in Linear Control of Series Elastic Actuators](https://arxiv.org/abs/2509.17210)
*Shaunak A. Mehta,Dylan P. Losey*

Main category: cs.RO

TL;DR: 研究探讨了如何在系列弹性执行器中平衡安全性与性能，发现驱动侧PD控制结合弹性阻尼器可在确保安全的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 在人类与机器人物理互动时，需要机器人既安全又高效。系列弹性执行器（SEAs）通过引入顺应性驱动从根本上提高了安全性，但同时也带来了振荡和精确运动能力下降的问题。

Method: 列举了系列弹性执行器的不同线性控制和机械配置，并探讨了每种选择对呈现的顺应性、被动性和跟踪性能的影响。

Result: 研究发现，简单的PD控制器在驱动侧允许更广泛的控制增益范围以保持安全性，与弹性传输中的阻尼器结合可实现高性能。模拟和实际实验验证了这一解决方案的有效性。

Conclusion: 通过设计具有低物理刚度和高控制器增益的系统，该解决方案在确保碰撞时用户安全的同时，实现了精确的性能。

Abstract: When humans physically interact with robots, we need the robots to be both
safe and performant. Series elastic actuators (SEAs) fundamentally advance
safety by introducing compliant actuation. On the one hand, adding a spring
mitigates the impact of accidental collisions between human and robot; but on
the other hand, this spring introduces oscillations and fundamentally decreases
the robot's ability to perform precise, accurate motions. So how should we
trade off between physical safety and performance? In this paper, we enumerate
the different linear control and mechanical configurations for series elastic
actuators, and explore how each choice affects the rendered compliance,
passivity, and tracking performance. While prior works focus on load side
control, we find that actuator side control has significant benefits. Indeed,
simple PD controllers on the actuator side allow for a much wider range of
control gains that maintain safety, and combining these with a damper in the
elastic transmission yields high performance. Our simulations and real world
experiments suggest that, by designing a system with low physical stiffness and
high controller gains, this solution enables accurate performance while also
ensuring user safety during collisions.

</details>


### [311] [Neural Network and ANFIS based auto-adaptive MPC for path tracking in autonomous vehicles](https://arxiv.org/abs/2509.17213)
*Yassine Kebbati,Naima Ait-Oufroukh,Vincent Vigneron,Dalil Ichala*

Main category: cs.RO

TL;DR: 本文设计了一种基于改进粒子群优化和神经网络的自适应MPC控制器，用于自动驾驶路径跟踪，效果优于标准MPC。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车在动态环境中面临多种不确定性和干扰，传统控制器在横向控制上效果不佳。

Method: 采用改进的粒子群优化算法调谐自适应MPC控制器，并利用神经网络和ANFIS进行在线参数适配。

Result: 在三次变道和轨迹跟踪场景中，设计的控制器相比标准MPC展现出更好的性能。

Conclusion: 设计的自适应MPC控制器在路径跟踪任务中表现出色，尤其在复杂场景下优于标准MPC。

Abstract: Self-driving cars operate in constantly changing environments and are exposed
to a variety of uncertainties and disturbances. These factors render classical
controllers ineffective, especially for lateral control. Therefore, an adaptive
MPC controller is designed in this paper for the path tracking task, tuned by
an improved particle swarm optimization algorithm. Online parameter adaptation
is performed using Neural Networks and ANFIS. The designed controller showed
promising results compared to standard MPC in triple lane change and trajectory
tracking scenarios. Code can be found here:
https://github.com/yassinekebbati/NN_MPC-vs-ANFIS_MPC

</details>


### [312] [Scalable Multi Agent Diffusion Policies for Coverage Control](https://arxiv.org/abs/2509.17244)
*Frederic Vatnsdal,Romina Garcia Camargo,Saurav Agarwal,Alejandro Ribeiro*

Main category: cs.RO

TL;DR: MADP是一种基于扩散模型的分散式机器人群体协作方法，通过模仿学习训练，在覆盖控制任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决分散式机器人群体在复杂高维动作空间中的协作问题，并提升多代理导航任务的性能。

Method: MADP利用扩散模型从复杂高维动作分布中生成样本，并通过空间变换器架构参数化扩散过程以实现分散推理。策略通过模仿学习从覆盖控制问题的专家演示中训练。

Result: 实验表明，MADP在多种代理密度和环境条件下均表现优异，能够泛化并持续超越现有最先进方法。

Conclusion: MADP通过扩散模型在分散式机器人群体中实现了高效的协作，展现了在处理复杂高维动作分布和跨代理行动依赖关系方面的优势，并在覆盖控制任务中超越了现有基线方法。

Abstract: We propose MADP, a novel diffusion-model-based approach for collaboration in
decentralized robot swarms. MADP leverages diffusion models to generate samples
from complex and high-dimensional action distributions that capture the
interdependencies between agents' actions. Each robot conditions policy
sampling on a fused representation of its own observations and perceptual
embeddings received from peers. To evaluate this approach, we task a team of
holonomic robots piloted by MADP to address coverage control-a canonical multi
agent navigation problem. The policy is trained via imitation learning from a
clairvoyant expert on the coverage control problem, with the diffusion process
parameterized by a spatial transformer architecture to enable decentralized
inference. We evaluate the system under varying numbers, locations, and
variances of importance density functions, capturing the robustness demands of
real-world coverage tasks. Experiments demonstrate that our model inherits
valuable properties from diffusion models, generalizing across agent densities
and environments, and consistently outperforming state-of-the-art baselines.

</details>


### [313] [Learning and Optimization with 3D Orientations](https://arxiv.org/abs/2509.17274)
*Alexandros Ntagkas,Constantinos Tsakonas,Chairi Kiourt,Konstantinos Chatzilygeroudis*

Main category: cs.RO

TL;DR: 本文系统比较了多种3D方向表示在不同机器人任务中的表现，并提供了实用指南和参考实现。


<details>
  <summary>Details</summary>
Motivation: 当前3D方向表示选择缺乏统一指南，且文献中缺少对多种表示及其适用场景的全面比较。

Method: 通过实验比较不同3D方向表示在直接优化、模仿/监督学习、强化学习和轨迹优化等场景中的表现。

Result: 通过实验得出了不同场景下最优的3D方向表示建议。

Conclusion: 本文提供了针对不同场景的3D方向表示选择指南，并提供了所有方向数学的参考实现。

Abstract: There exist numerous ways of representing 3D orientations. Each
representation has both limitations and unique features. Choosing the best
representation for one task is often a difficult chore, and there exist
conflicting opinions on which representation is better suited for a set of
family of tasks. Even worse, when dealing with scenarios where we need to learn
or optimize functions with orientations as inputs and/or outputs, the set of
possibilities (representations, loss functions, etc.) is even larger and it is
not easy to decide what is best for each scenario. In this paper, we attempt to
a) present clearly, concisely and with unified notation all available
representations, and "tricks" related to 3D orientations (including Lie Group
algebra), and b) benchmark them in representative scenarios. The first part
feels like it is missing from the robotics literature as one has to read many
different textbooks and papers in order have a concise and clear understanding
of all possibilities, while the benchmark is necessary in order to come up with
recommendations based on empirical evidence. More precisely, we experiment with
the following settings that attempt to cover most widely used scenarios in
robotics: 1) direct optimization, 2) imitation/supervised learning with a
neural network controller, 3) reinforcement learning, and 4) trajectory
optimization using differential dynamic programming. We finally provide
guidelines depending on the scenario, and make available a reference
implementation of all the orientation math described.

</details>


### [314] [Event-Based Visual Teach-and-Repeat via Fast Fourier-Domain Cross-Correlation](https://arxiv.org/abs/2509.17287)
*Gokul B. Nair,Alejandro Fontan,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 首个基于事件相机的视觉教学与重复导航系统，通过频域互相关框架实现超高速处理（300Hz+），实验验证了其实时导航能力。


<details>
  <summary>Details</summary>
Motivation: 传统帧率相机因其固定帧率（30-60Hz）导致环境变化与控制响应之间存在固有延迟，限制了系统响应速度。

Method: 研究采用频域互相关框架，将事件流匹配问题转化为计算高效的傅里叶空间乘法，并利用事件帧的二进制特性和图像压缩技术提升计算速度。

Result: 实验表明，该系统在4000多米的室内外轨迹上实现了自主导航，平均轨迹误差低于24厘米，同时保持高频控制更新。

Conclusion: 该研究成功开发了首个基于事件相机的视觉教学与重复导航系统，通过频域互相关框架实现了超过300Hz的处理速度，显著优于传统帧率相机系统，证明了事件感知在实时机器人导航中的实用可行性。

Abstract: Visual teach-and-repeat navigation enables robots to autonomously traverse
previously demonstrated paths by comparing current sensory input with recorded
trajectories. However, conventional frame-based cameras fundamentally limit
system responsiveness: their fixed frame rates (typically 30-60 Hz) create
inherent latency between environmental changes and control responses. Here we
present the first event-camera-based visual teach-and-repeat system. To achieve
this, we develop a frequency-domain cross-correlation framework that transforms
the event stream matching problem into computationally efficient Fourier space
multiplications, capable of exceeding 300Hz processing rates, an order of
magnitude faster than frame-based approaches. By exploiting the binary nature
of event frames and applying image compression techniques, we further enhance
the computational speed of the cross-correlation process without sacrificing
localization accuracy. Extensive experiments using a Prophesee EVK4 HD event
camera mounted on an AgileX Scout Mini robot demonstrate successful autonomous
navigation across 4000+ meters of indoor and outdoor trajectories. Our system
achieves ATEs below 24 cm while maintaining consistent high-frequency control
updates. Our evaluations show that our approach achieves substantially higher
update rates compared to conventional frame-based systems, underscoring the
practical viability of event-based perception for real-time robotic navigation.

</details>


### [315] [Automated Coral Spawn Monitoring for Reef Restoration: The Coral Spawn and Larvae Imaging Camera System (CSLICS)](https://arxiv.org/abs/2509.17299)
*Dorian Tsai,Christopher A. Brunner,Riki Lamont,F. Mikaela Nordborg,Andrea Severati,Java Terry,Karen Jackel,Matthew Dunbabin,Tobias Fischer,Scarlett Raine*

Main category: cs.RO

TL;DR: CSLICS系统通过自动化摄像头和AI检测技术高效计数珊瑚产卵，显著提升珊瑚养殖和礁恢复效率。


<details>
  <summary>Details</summary>
Motivation: 当前珊瑚产卵计数方法劳动密集，成为珊瑚生产流程中的瓶颈，亟需自动化解决方案以提高效率和准确性。

Method: 采用低成本模块化摄像头和基于人类参与标记训练的对象检测器，实现珊瑚产卵的自动化检测、分类和计数。

Result: 实验结果显示，表面产卵检测F1分数为82.4%，次表层产卵检测F1分数为65.3%，每次产卵事件节省5,720小时人工时间。

Conclusion: CSLICS系统显著提高了珊瑚产卵计数的效率，节省了大量人工时间，并准确测量了受精成功率和次表层产卵数量，为珊瑚礁恢复工作提供了有力支持。

Abstract: Coral aquaculture for reef restoration requires accurate and continuous spawn
counting for resource distribution and larval health monitoring, but current
methods are labor-intensive and represent a critical bottleneck in the coral
production pipeline. We propose the Coral Spawn and Larvae Imaging Camera
System (CSLICS), which uses low cost modular cameras and object detectors
trained using human-in-the-loop labeling approaches for automated spawn
counting in larval rearing tanks. This paper details the system engineering,
dataset collection, and computer vision techniques to detect, classify and
count coral spawn. Experimental results from mass spawning events demonstrate
an F1 score of 82.4\% for surface spawn detection at different embryogenesis
stages, 65.3\% F1 score for sub-surface spawn detection, and a saving of 5,720
hours of labor per spawning event compared to manual sampling methods at the
same frequency. Comparison of manual counts with CSLICS monitoring during a
mass coral spawning event on the Great Barrier Reef demonstrates CSLICS'
accurate measurement of fertilization success and sub-surface spawn counts.
These findings enhance the coral aquaculture process and enable upscaling of
coral reef restoration efforts to address climate change threats facing
ecosystems like the Great Barrier Reef.

</details>


### [316] [Pose Estimation of a Cable-Driven Serpentine Manipulator Utilizing Intrinsic Dynamics via Physical Reservoir Computing](https://arxiv.org/abs/2509.17308)
*Kazutoshi Tanaka,Tomoya Takahashi,Masashi Hamaya*

Main category: cs.RO

TL;DR: 开发了一种轻量化电缆驱动蛇形机械臂，提出基于物理储备计算的姿态估计方法，显著降低了姿态误差。


<details>
  <summary>Details</summary>
Motivation: 电缆驱动蛇形机械臂在非结构化环境中具有巨大潜力，但其设计引入了灵活性引起的变化，导致姿态估计困难。

Method: 提出了一种基于物理储备计算的姿态估计方法，利用机械臂的固有非线性动力学作为高维储备。

Result: 实验结果显示，使用该方法平均姿态误差为4.3毫米，优于基线长短期记忆网络的4.4毫米和分析方法的39.5毫米。

Conclusion: 本研究为轻量化电缆驱动蛇形机械臂的控制和感知策略提供了新方向，利用其固有动力学特性。

Abstract: Cable-driven serpentine manipulators hold great potential in unstructured
environments, offering obstacle avoidance, multi-directional force application,
and a lightweight design. By placing all motors and sensors at the base and
employing plastic links, we can further reduce the arm's weight. To demonstrate
this concept, we developed a 9-degree-of-freedom cable-driven serpentine
manipulator with an arm length of 545 mm and a total mass of only 308 g.
However, this design introduces flexibility-induced variations, such as cable
slack, elongation, and link deformation. These variations result in
discrepancies between analytical predictions and actual link positions, making
pose estimation more challenging. To address this challenge, we propose a
physical reservoir computing based pose estimation method that exploits the
manipulator's intrinsic nonlinear dynamics as a high-dimensional reservoir.
Experimental results show a mean pose error of 4.3 mm using our method,
compared to 4.4 mm with a baseline long short-term memory network and 39.5 mm
with an analytical approach. This work provides a new direction for control and
perception strategies in lightweight cable-driven serpentine manipulators
leveraging their intrinsic dynamics.

</details>


### [317] [OpenGVL - Benchmarking Visual Temporal Progress for Data Curation](https://arxiv.org/abs/2509.17321)
*Paweł Budzianowski,Emilia Wiśnios,Gracjan Góral,Igor Kulakov,Viktor Petrenko,Krzysztof Walas*

Main category: cs.RO

TL;DR: OpenGVL是一个用于评估任务进展预测的基准，展示了开源模型在性能上落后于闭源模型，并作为自动化数据筛选工具。


<details>
  <summary>Details</summary>
Motivation: 解决机器人领域数据稀缺问题，利用日益增长的机器人数据，通过可靠的时间任务完成预测来自动标注和筛选数据。

Method: 提出了OpenGVL基准，用于评估多样化的操作任务中任务进展的预测能力，并比较了开源和闭源基础模型的性能。

Result: 开源模型在时间进展预测任务中表现显著低于闭源模型，仅达到后者约70%的性能。

Conclusion: OpenGVL作为一个实用工具，能够有效支持大规模机器人数据的自动标注和筛选，为数据稀缺问题提供了解决方案。

Abstract: Data scarcity remains one of the most limiting factors in driving progress in
robotics. However, the amount of available robotics data in the wild is growing
exponentially, creating new opportunities for large-scale data utilization.
Reliable temporal task completion prediction could help automatically annotate
and curate this data at scale. The Generative Value Learning (GVL) approach was
recently proposed, leveraging the knowledge embedded in vision-language models
(VLMs) to predict task progress from visual observations. Building upon GVL, we
propose OpenGVL, a comprehensive benchmark for estimating task progress across
diverse challenging manipulation tasks involving both robotic and human
embodiments. We evaluate the capabilities of publicly available open-source
foundation models, showing that open-source model families significantly
underperform closed-source counterparts, achieving only approximately $70\%$ of
their performance on temporal progress prediction tasks. Furthermore, we
demonstrate how OpenGVL can serve as a practical tool for automated data
curation and filtering, enabling efficient quality assessment of large-scale
robotics datasets. We release the benchmark along with the complete codebase at
\href{github.com/budzianowski/opengvl}{OpenGVL}.

</details>


### [318] [AERO-MPPI: Anchor-Guided Ensemble Trajectory Optimization for Agile Mapless Drone Navigation](https://arxiv.org/abs/2509.17340)
*Xin Chen,Rui Huang,Longbin Tang,Lin Zhao*

Main category: cs.RO

TL;DR: AERO-MPPI是一种GPU加速的无人机导航框架，通过并行MPPI优化器和多分辨率LiDAR锚点，在复杂3D环境中实现了高效、安全的实时飞行。


<details>
  <summary>Details</summary>
Motivation: 传统的映射-规划-控制流程在复杂3D环境中计算成本高且误差传播严重，亟需一种高效实时的导航解决方案。

Method: 设计了一种多分辨率LiDAR点云表示法，快速提取空间分布的“锚点”作为前瞻中间端点，构建多项式轨迹引导，并行运行多个MPPI实例，并通过两阶段多目标成本评估平衡避障和目标到达。

Result: 仿真和实际飞行测试表明，AERO-MPPI在7 m/s以上的速度下实现了80%以上的成功率，轨迹更平滑，优于现有基线方法。

Conclusion: AERO-MPPI框架通过GPU加速和并行MPPI优化器，显著提升了无人机在复杂3D环境中的实时导航性能，成功率达到80%以上，并在实际飞行中验证了其安全性和鲁棒性。

Abstract: Agile mapless navigation in cluttered 3D environments poses significant
challenges for autonomous drones. Conventional mapping-planning-control
pipelines incur high computational cost and propagate estimation errors. We
present AERO-MPPI, a fully GPU-accelerated framework that unifies perception
and planning through an anchor-guided ensemble of Model Predictive Path
Integral (MPPI) optimizers. Specifically, we design a multi-resolution LiDAR
point-cloud representation that rapidly extracts spatially distributed
"anchors" as look-ahead intermediate endpoints, from which we construct
polynomial trajectory guides to explore distinct homotopy path classes. At each
planning step, we run multiple MPPI instances in parallel and evaluate them
with a two-stage multi-objective cost that balances collision avoidance and
goal reaching. Implemented entirely with NVIDIA Warp GPU kernels, AERO-MPPI
achieves real-time onboard operation and mitigates the local-minima failures of
single-MPPI approaches. Extensive simulations in forests, verticals, and
inclines demonstrate sustained reliable flight above 7 m/s, with success rates
above 80% and smoother trajectories compared to state-of-the-art baselines.
Real-world experiments on a LiDAR-equipped quadrotor with NVIDIA Jetson Orin NX
16G confirm that AERO-MPPI runs in real time onboard and consistently achieves
safe, agile, and robust flight in complex cluttered environments. The code will
be open-sourced upon acceptance of the paper.

</details>


### [319] [DyDexHandover: Human-like Bimanual Dynamic Dexterous Handover using RGB-only Perception](https://arxiv.org/abs/2509.17350)
*Haoran Zhou,Yangwei You,Shuaijun Wang*

Main category: cs.RO

TL;DR: DyDexHandover 通过多智能体强化学习和人类策略正则化，实现基于 RGB 的双机械臂空中交接，表现优异且行为自然。


<details>
  <summary>Details</summary>
Motivation: 解决双机械臂空中交接的挑战，克服现有方法依赖动态模型、强先验或深度感知的局限性，提升泛化能力和自然性。

Method: 采用多智能体强化学习训练端到端的基于 RGB 的策略，结合人类策略正则化方案，以促进流畅自然的动作。

Result: 在训练对象上成功率达 99%，未见对象上达 75%，并生成类人行为。

Conclusion: DyDexHandover 是首个仅使用原始 RGB 感知实现双机械臂空中交接的方法，在训练对象上达到近 99% 的成功率，在未见对象上达到 75% 的成功率，并生成类人的投掷和捕捉行为。

Abstract: Dynamic in air handover is a fundamental challenge for dual-arm robots,
requiring accurate perception, precise coordination, and natural motion. Prior
methods often rely on dynamics models, strong priors, or depth sensing,
limiting generalization and naturalness. We present DyDexHandover, a novel
framework that employs multi-agent reinforcement learning to train an end to
end RGB based policy for bimanual object throwing and catching. To achieve more
human-like behavior, the throwing policy is guided by a human policy
regularization scheme, encouraging fluid and natural motion, and enhancing the
generalization capability of the policy. A dual arm simulation environment was
built in Isaac Sim for experimental evaluation. DyDexHandover achieves nearly
99 percent success on training objects and 75 percent on unseen objects, while
generating human-like throwing and catching behaviors. To our knowledge, it is
the first method to realize dual-arm in-air handover using only raw RGB
perception.

</details>


### [320] [Fast Trajectory Planner with a Reinforcement Learning-based Controller for Robotic Manipulators](https://arxiv.org/abs/2509.17381)
*Yongliang Wang,Hamidreza Kasaei*

Main category: cs.RO

TL;DR: 该论文提出了一种结合视觉路径规划和强化学习（PPO增强）的机械臂轨迹规划系统，有效解决了杂乱环境中的避障问题，实验验证了其高效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划方法在非结构化杂乱环境中生成无碰撞轨迹时，常需额外计算资源求解运动学或动力学方程，因此探索模型无关的强化学习方法在关节空间轨迹规划中的潜力。

Method: 1. 在任务空间中引入基于视觉的轨迹规划器，结合FSA模型和B样条优化的运动学路径搜索。2. 在关节空间中通过集成动作集合（AE）和策略反馈（PF）增强PPO算法，提升避障和目标到达的精度与稳定性。

Result: 实验结果表明，增强的PPO算法在复杂场景中显著提升了模型鲁棒性和规划效率，实现了机械臂在障碍环境中的实时避障和轨迹规划。

Conclusion: 该论文提出了一种结合视觉路径规划和强化学习的快速轨迹规划系统，有效解决了机械臂在杂乱环境中的避障和轨迹规划问题。实验证明了PPO算法的增强以及Sim-to-Sim和Sim-to-Real转移的有效性，提升了模型的鲁棒性和规划效率。

Abstract: Generating obstacle-free trajectories for robotic manipulators in
unstructured and cluttered environments remains a significant challenge.
Existing motion planning methods often require additional computational effort
to generate the final trajectory by solving kinematic or dynamic equations.
This paper highlights the strong potential of model-free reinforcement learning
methods over model-based approaches for obstacle-free trajectory planning in
joint space. We propose a fast trajectory planning system for manipulators that
combines vision-based path planning in task space with reinforcement
learning-based obstacle avoidance in joint space. We divide the framework into
two key components. The first introduces an innovative vision-based trajectory
planner in task space, leveraging the large-scale fast segment anything (FSA)
model in conjunction with basis spline (B-spline)-optimized kinodynamic path
searching. The second component enhances the proximal policy optimization (PPO)
algorithm by integrating action ensembles (AE) and policy feedback (PF), which
greatly improve precision and stability in goal-reaching and obstacle avoidance
within the joint space. These PPO enhancements increase the algorithm's
adaptability across diverse robotic tasks, ensuring consistent execution of
commands from the first component by the manipulator, while also enhancing both
obstacle avoidance efficiency and reaching accuracy. The experimental results
demonstrate the effectiveness of PPO enhancements, as well as
simulation-to-simulation (Sim-to-Sim) and simulation-to-reality (Sim-to-Real)
transfer, in improving model robustness and planner efficiency in complex
scenarios. These enhancements allow the robot to perform obstacle avoidance and
real-time trajectory planning in obstructed environments. Project page
available at: https://sites.google.com/view/ftp4rm/home

</details>


### [321] [High-Precision and High-Efficiency Trajectory Tracking for Excavators Based on Closed-Loop Dynamics](https://arxiv.org/abs/2509.17387)
*Ziqing Zou,Cong Wang,Yue Hu,Xiao Liu,Bowen Xu,Rong Xiong,Changjie Fan,Yingfeng Chen,Yue Wang*

Main category: cs.RO

TL;DR: EfficientTrack是一种结合模型学习和闭环动力学的轨迹跟踪方法，显著提升了液压挖掘机的跟踪精度和效率。


<details>
  <summary>Details</summary>
Motivation: 液压挖掘机的复杂非线性动力学（如时间延迟和控制耦合）对高精度轨迹跟踪提出了挑战，传统控制方法和常用学习方法的不足促使了EfficientTrack的开发。

Method: EfficientTrack结合了基于模型的学习来处理非线性动力学，并利用闭环动力学提高学习效率，从而最小化跟踪误差。

Result: 仿真实验表明，EfficientTrack在跟踪精度和流畅度上优于现有学习方法，且交互次数最少；实际实验验证了其在负载条件下的有效性和持续学习能力。

Conclusion: EfficientTrack方法在仿真和实际挖掘机实验中均表现出色，不仅跟踪精度和流畅度优于现有学习方法，还具备持续学习能力，展现了其实际应用价值。

Abstract: The complex nonlinear dynamics of hydraulic excavators, such as time delays
and control coupling, pose significant challenges to achieving high-precision
trajectory tracking. Traditional control methods often fall short in such
applications due to their inability to effectively handle these nonlinearities,
while commonly used learning-based methods require extensive interactions with
the environment, leading to inefficiency. To address these issues, we introduce
EfficientTrack, a trajectory tracking method that integrates model-based
learning to manage nonlinear dynamics and leverages closed-loop dynamics to
improve learning efficiency, ultimately minimizing tracking errors. We validate
our method through comprehensive experiments both in simulation and on a
real-world excavator. Comparative experiments in simulation demonstrate that
our method outperforms existing learning-based approaches, achieving the
highest tracking precision and smoothness with the fewest interactions.
Real-world experiments further show that our method remains effective under
load conditions and possesses the ability for continual learning, highlighting
its practical applicability. For implementation details and source code, please
refer to https://github.com/ZiqingZou/EfficientTrack.

</details>


### [322] [3D Printable Soft Liquid Metal Sensors for Delicate Manipulation Tasks](https://arxiv.org/abs/2509.17389)
*Lois Liow,Jonty Milford,Emre Uygun,Andre Farinha,Vinoth Viswanathan,Josh Pinskier,David Howard*

Main category: cs.RO

TL;DR: 该论文提出了一种高传感器化软‘物理孪生’打印方法，用于珊瑚等脆弱样本的精细操作，展示了其在自动化珊瑚标记和机器人珊瑚养殖中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了保护受威胁的生态系统，需要在不损坏脆弱样本的情况下进行精细操作和数据采集，以训练基于学习的解决方案。

Method: 引入了一种自动化设计工作流程，用于从3D扫描或模型创建复杂且可定制的3D软传感结构，采用软液态金属传感器来忠实再现复杂自然几何形状。

Result: 实验证明，所提出的‘传感珊瑚’能够在0.5 N以下的力下检测抓取，有效捕捉珊瑚处理所需的精细交互和轻微接触力。

Conclusion: 该论文提出了一种新型的高传感器化软‘物理孪生’打印方法，通过自动化设计工作流程创建复杂且可定制的3D软传感结构，为珊瑚处理等精细操作任务提供了伦理和可扩展的解决方案。

Abstract: Robotics and automation are key enablers to increase throughput in ongoing
conservation efforts across various threatened ecosystems. Cataloguing,
digitisation, husbandry, and similar activities require the ability to interact
with delicate, fragile samples without damaging them. Additionally,
learning-based solutions to these tasks require the ability to safely acquire
data to train manipulation policies through, e.g., reinforcement learning. To
address these twin needs, we introduce a novel method to print free-form,
highly sensorised soft 'physical twins'. We present an automated design
workflow to create complex and customisable 3D soft sensing structures on
demand from 3D scans or models. Compared to the state of the art, our soft
liquid metal sensors faithfully recreate complex natural geometries and display
excellent sensing properties suitable for validating performance in delicate
manipulation tasks. We demonstrate the application of our physical twins as
'sensing corals': high-fidelity, 3D printed replicas of scanned corals that
eliminate the need for live coral experimentation, whilst increasing data
quality, offering an ethical and scalable pathway for advancing autonomous
coral handling and soft manipulation broadly. Through extensive bench-top
manipulation and underwater grasping experiments, we show that our sensing
coral is able to detect grasps under 0.5 N, effectively capturing the delicate
interactions and light contact forces required for coral handling. Finally, we
showcase the value of our physical twins across two demonstrations: (i)
automated coral labelling for lab identification and (ii) robotic coral
aquaculture. Sensing physical twins such as ours can provide richer grasping
feedback than conventional sensors providing experimental validation of prior
to deployment in handling fragile and delicate items.

</details>


### [323] [FGGS-LiDAR: Ultra-Fast, GPU-Accelerated Simulation from General 3DGS Models to LiDAR](https://arxiv.org/abs/2509.17390)
*Junzhe Wu,Yufei Jia,Yiyi Yan,Zhixing Chen,Tiao Tan,Zifan Wang,Guangyu Wang*

Main category: cs.RO

TL;DR: FGGS-LiDAR框架将3DGS模型转换为水密网格，无需LiDAR特定监督，支持500 FPS的LiDAR模拟，扩展了3DGS在机器人学和自动驾驶中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯溅射（3DGS）资产与高性能LiDAR模拟不兼容的问题，为机器人学和自动驾驶提供关键工具。

Method: 采用体积离散化和截断有符号距离场（TSDF）提取的通用流程，结合GPU加速的光线投射模块，实现超过500 FPS的LiDAR模拟。

Result: 在室内和室外场景中验证了方法的几何保真度，实现了高精度深度感知。

Conclusion: FGGS-LiDAR框架通过将3D高斯溅射模型转换为高保真水密网格，无需LiDAR特定监督或架构修改，显著扩展了3DGS资产在机器人学和自动驾驶中的应用。

Abstract: While 3D Gaussian Splatting (3DGS) has revolutionized photorealistic
rendering, its vast ecosystem of assets remains incompatible with
high-performance LiDAR simulation, a critical tool for robotics and autonomous
driving. We present \textbf{FGGS-LiDAR}, a framework that bridges this gap with
a truly plug-and-play approach. Our method converts \textit{any} pretrained
3DGS model into a high-fidelity, watertight mesh without requiring
LiDAR-specific supervision or architectural alterations. This conversion is
achieved through a general pipeline of volumetric discretization and Truncated
Signed Distance Field (TSDF) extraction. We pair this with a highly optimized,
GPU-accelerated ray-casting module that simulates LiDAR returns at over 500
FPS. We validate our approach on indoor and outdoor scenes, demonstrating
exceptional geometric fidelity; By enabling the direct reuse of 3DGS assets for
geometrically accurate depth sensing, our framework extends their utility
beyond visualization and unlocks new capabilities for scalable, multimodal
simulation. Our open-source implementation is available at
https://github.com/TATP-233/FGGS-LiDAR.

</details>


### [324] [GPS Denied IBVS-Based Navigation and Collision Avoidance of UAV Using a Low-Cost RGB Camera](https://arxiv.org/abs/2509.17435)
*Xiaoyu Wang,Yan Rui Tan,William Leong,Sunan Huang,Rodney Teo,Cheng Xiang*

Main category: cs.RO

TL;DR: 论文提出了一种基于RGB相机的无人机视觉伺服框架，通过单目深度估计实现避障，实验效果良好。


<details>
  <summary>Details</summary>
Motivation: 尽管无人机导航已被广泛研究，但在涉及多个视觉目标和避障的任务中应用IBVS仍具挑战性。

Method: 通过AI-based单目深度估计从RGB图像实现避障，无需显式路径规划，且完全在Jetson平台上运行。

Result: 实验验证无人机能在GPS缺失环境中有效导航多个AprilTags并避障。

Conclusion: 该论文提出的基于RGB相机的图像视觉伺服框架在无人机导航和避障中表现出色，尤其在GPS缺失环境下有效。

Abstract: This paper proposes an image-based visual servoing (IBVS) framework for UAV
navigation and collision avoidance using only an RGB camera. While UAV
navigation has been extensively studied, it remains challenging to apply IBVS
in missions involving multiple visual targets and collision avoidance. The
proposed method achieves navigation without explicit path planning, and
collision avoidance is realized through AI-based monocular depth estimation
from RGB images. Unlike approaches that rely on stereo cameras or external
workstations, our framework runs fully onboard a Jetson platform, ensuring a
self-contained and deployable system. Experimental results validate that the
UAV can navigate across multiple AprilTags and avoid obstacles effectively in
GPS-denied environments.

</details>


### [325] [Learning Dexterous Manipulation with Quantized Hand State](https://arxiv.org/abs/2509.17450)
*Ying Feng,Hongjie Fang,Yinong He,Jingjing Chen,Chenxi Wang,Zihao He,Ruonan Liu,Cewu Lu*

Main category: cs.RO

TL;DR: DQ-RISE通过量化手部状态和连续松弛方法，解决了灵巧操作中手部动作主导问题，实现了更高效的臂手协调学习。


<details>
  <summary>Details</summary>
Motivation: 灵巧机器人手的高自由度使手和手臂动作紧密耦合，传统方法在单一组合空间中表示动作，导致高维手部动作主导并影响手臂控制。

Method: 提出DQ-RISE方法，量化手部状态以简化手部动作预测，同时应用连续松弛使手臂动作与这些紧凑的手部状态联合扩散。

Result: 实验表明，DQ-RISE实现了更平衡和高效的学习。

Conclusion: DQ-RISE通过量化手部状态简化动作预测，同时保持关键模式，并通过连续松弛使手臂动作与这些紧凑的手部状态联合扩散，实现了更平衡和高效的学习，为结构化和可泛化的灵巧操作铺平了道路。

Abstract: Dexterous robotic hands enable robots to perform complex manipulations that
require fine-grained control and adaptability. Achieving such manipulation is
challenging because the high degrees of freedom tightly couple hand and arm
motions, making learning and control difficult. Successful dexterous
manipulation relies not only on precise hand motions, but also on accurate
spatial positioning of the arm and coordinated arm-hand dynamics. However, most
existing visuomotor policies represent arm and hand actions in a single
combined space, which often causes high-dimensional hand actions to dominate
the coupled action space and compromise arm control. To address this, we
propose DQ-RISE, which quantizes hand states to simplify hand motion prediction
while preserving essential patterns, and applies a continuous relaxation that
allows arm actions to diffuse jointly with these compact hand states. This
design enables the policy to learn arm-hand coordination from data while
preventing hand actions from overwhelming the action space. Experiments show
that DQ-RISE achieves more balanced and efficient learning, paving the way
toward structured and generalizable dexterous manipulation. Project website:
http://rise-policy.github.io/DQ-RISE/

</details>


### [326] [Morphologies of a sagging elastica with intrinsic sensing and actuation](https://arxiv.org/abs/2509.17572)
*Vishnu Deo Mishra,S Ganga Prasath*

Main category: cs.RO

TL;DR: 研究探讨了比例反馈策略对软机器人形状的影响，发现在有限传感和驱动条件下，选择合适的驱动增益可最小化形状变形误差。


<details>
  <summary>Details</summary>
Motivation: 由于结构的几何非线性、实验系统建模误差以及传感和反馈/驱动能力的限制，计算软机器人变形所需的驱动力矩往往困难。

Method: 通过比例反馈策略（驱动与感知曲率成正比）研究软机器人的形状变化，使用有限数量的传感器和驱动器模拟实验条件。

Result: 研究发现，在固定滤波器宽度下，选择合适的驱动增益（其大小与滤波器宽度的平方成正比）时，形状变形误差最小。

Conclusion: 该模型为研究和设计具有有限传感和驱动能力的细长软设备提供了定量视角，适用于复杂机动应用。

Abstract: The morphology of a slender soft-robot can be modified by sensing its shape
via sensors and exerting moments via actuators embedded along its body. The
actuating moments required to morph these soft-robots to a desired shape are
often difficult to compute due to the geometric non-linearity associated with
the structure, the errors in modeling the experimental system, and the
limitations in sensing and feedback/actuation capabilities. In this article, we
explore the effect of a simple feedback strategy (actuation being proportional
to the sensed curvature) on the shape of a soft-robot, modeled as an elastica.
The finite number of sensors and actuators, often seen in experiments, is
captured in the model via filters of specified widths. Using proportional
feedback, we study the simple task of straightening the device by compensating
for the sagging introduced by its self-weight. The device undergoes a hierarchy
of morphological instabilities defined in the phase-space given by the
gravito-bending number, non-dimensional sensing/feedback gain, and the scaled
width of the filter. For complex shape-morphing tasks, given a perfect model of
the device with limited sensing and actuating capabilities, we find that a
trade-off arises (set by the sensor spacing & actuator size) between capturing
the long and short wavelength features. We show that the error in
shape-morphing is minimal for a fixed filter width when we choose an
appropriate actuating gain (whose magnitude goes as a square of the filter
width). Our model provides a quantitative lens to study and design slender soft
devices with limited sensing and actuating capabilities for complex maneuvering
applications.

</details>


### [327] [GeCCo - a Generalist Contact-Conditioned Policy for Loco-Manipulation Skills on Legged Robots](https://arxiv.org/abs/2509.17582)
*Vassil Atanassov,Wanming Yu,Siddhant Gangapurwala,James Wilson,Ioannis Havoutis*

Main category: cs.RO

TL;DR: GeCCo是一个通用的低级策略，通过DRL训练，能够适应多种高级任务，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端深度强化学习方法在扩展性上存在不足，每次新任务都需要耗时的奖励定义和调整。

Method: 使用深度强化学习（DRL）训练一个名为GeCCo的低级策略，该策略能够跟踪四足机器人上的任意接触点。

Result: GeCCo在多种运动和操作任务中表现出色，包括复杂地形穿越和与物体交互。

Conclusion: GeCCo提供了一个通用的、模块化的低级控制器，能够高效地适应各种高级任务，无需从头训练新的控制器。

Abstract: Most modern approaches to quadruped locomotion focus on using Deep
Reinforcement Learning (DRL) to learn policies from scratch, in an end-to-end
manner. Such methods often fail to scale, as every new problem or application
requires time-consuming and iterative reward definition and tuning. We present
Generalist Contact-Conditioned Policy (GeCCo) -- a low-level policy trained
with Deep Reinforcement Learning that is capable of tracking arbitrary contact
points on a quadruped robot. The strength of our approach is that it provides a
general and modular low-level controller that can be reused for a wider range
of high-level tasks, without the need to re-train new controllers from scratch.
We demonstrate the scalability and robustness of our method by evaluating on a
wide range of locomotion and manipulation tasks in a common framework and under
a single generalist policy. These include a variety of gaits, traversing
complex terrains (eg. stairs and slopes) as well as previously unseen
stepping-stones and narrow beams, and interacting with objects (eg. pushing
buttons, tracking trajectories). Our framework acquires new behaviors more
efficiently, simply by combining a task-specific high-level contact planner and
the pre-trained generalist policy. A supplementary video can be found at
https://youtu.be/o8Dd44MkG2E.

</details>


### [328] [Robust and Resilient Soft Robotic Object Insertion with Compliance-Enabled Contact Formation and Failure Recovery](https://arxiv.org/abs/2509.17666)
*Mimo Shirasaka,Cristian C. Beltran-Hernandez,Masashi Hamaya,Yoshitaka Ushiku*

Main category: cs.RO

TL;DR: 提出一种基于被动柔顺软腕和视觉语言模型的物体插入方法，通过自动化故障恢复策略，在模拟和真实环境中显著提高成功率。


<details>
  <summary>Details</summary>
Motivation: 传统物体插入任务在姿态不确定和环境变化下容易失败，需要手动调整或控制器重新训练，因此需要一种更鲁棒和弹性的方法。

Method: 利用被动柔顺软腕实现安全接触吸收，结合预训练的视觉语言模型（VLM）评估技能执行、识别故障模式并选择恢复动作。

Result: 在模拟中实现了83%的成功率，能恢复由随机条件引起的故障，包括抓取偏差、孔位误差、摩擦增加及未见过的方形/矩形插头，并在真实机器人上验证。

Conclusion: 该方法通过被动柔顺软腕和自动化故障恢复策略，显著提高了物体插入任务的鲁棒性和弹性，成功应对多种不确定性条件。

Abstract: Object insertion tasks are prone to failures under pose uncertainties and
environmental variations, traditionally requiring manual finetuning or
controller retraining. We present a novel approach for robust and resilient
object insertion using a passively compliant soft wrist that enables safe
contact absorption through large deformations, without high-frequency control
or force sensing. Our method structures insertion as compliance-enabled contact
formations, sequential contact states that progressively constrain degrees of
freedom, and integrates automated failure recovery strategies. Our key insight
is that wrist compliance permits safe, repeated recovery attempts; hence, we
refer to it as compliance-enabled failure recovery. We employ a pre-trained
vision-language model (VLM) that assesses each skill execution from terminal
poses and images, identifies failure modes, and proposes recovery actions by
selecting skills and updating goals. In simulation, our method achieved an 83%
success rate, recovering from failures induced by randomized
conditions--including grasp misalignments up to 5 degrees, hole-pose errors up
to 20mm, fivefold increases in friction, and previously unseen
square/rectangular pegs--and we further validate the approach on a real robot.

</details>


### [329] [Towards Learning Boulder Excavation with Hydraulic Excavators](https://arxiv.org/abs/2509.17683)
*Jonas Gruetter,Lorenzo Terenzi,Pascal Egli,Marco Hutter*

Main category: cs.RO

TL;DR: 研究通过强化学习使标准挖掘机在恶劣条件下成功抓取大型不规则岩石，成功率接近人类操作员。


<details>
  <summary>Details</summary>
Motivation: 解决当前自主挖掘技术无法处理大型不规则岩石或需要不切实际工具更换的问题。

Method: 使用强化学习策略在模拟环境中训练，结合刚体动力学和土壤分析模型，通过稀疏LiDAR点和视觉分割处理信息。

Result: 在12吨挖掘机上进行实地测试，成功率达到70%。

Conclusion: 研究表明，标准建筑设备能够在稀疏感知和恶劣户外条件下学习复杂操作，成功率达到70%，接近人类操作员的83%。

Abstract: Construction sites frequently require removing large rocks before excavation
or grading can proceed. Human operators typically extract these boulders using
only standard digging buckets, avoiding time-consuming tool changes to
specialized grippers. This task demands manipulating irregular objects with
unknown geometries in harsh outdoor environments where dust, variable lighting,
and occlusions hinder perception. The excavator must adapt to varying soil
resistance--dragging along hard-packed surfaces or penetrating soft
ground--while coordinating multiple hydraulic joints to secure rocks using a
shovel. Current autonomous excavation focuses on continuous media (soil,
gravel) or uses specialized grippers with detailed geometric planning for
discrete objects. These approaches either cannot handle large irregular rocks
or require impractical tool changes that interrupt workflow. We train a
reinforcement learning policy in simulation using rigid-body dynamics and
analytical soil models. The policy processes sparse LiDAR points (just 20 per
rock) from vision-based segmentation and proprioceptive feedback to control
standard excavator buckets. The learned agent discovers different strategies
based on soil resistance: dragging along the surface in hard soil and
penetrating directly in soft conditions. Field tests on a 12-ton excavator
achieved 70% success across varied rocks (0.4-0.7m) and soil types, compared to
83% for human operators. This demonstrates that standard construction equipment
can learn complex manipulation despite sparse perception and challenging
outdoor conditions.

</details>


### [330] [EigenSafe: A Spectral Framework for Learning-Based Stochastic Safety Filtering](https://arxiv.org/abs/2509.17750)
*Inkyu Jang,Jonghae Park,Chams E. Mballo,Sihyun Cho,Claire J. Tomlin,H. Jin Kim*

Main category: cs.RO

TL;DR: EigenSafe是一个算子理论框架，通过离线学习主导特征对和安全备份策略，构建安全过滤器，用于随机系统的安全关键控制。


<details>
  <summary>Details</summary>
Motivation: 针对随机系统（如受传感噪声和环境干扰影响的机器人系统），传统方法（如Hamilton-Jacobi可达性和控制屏障函数）难以提供全面的安全度量，因此需要一种新的框架来量化安全。

Method: 提出了一个名为EigenSafe的算子理论框架，通过推导安全概率的动态规划原则的线性算子，发现其主导特征对提供了关于个体状态和整体闭环系统安全的信息。框架离线学习该主导特征对和安全备份策略。

Result: EigenSafe框架在三个模拟的随机安全关键控制任务中验证了其有效性，能够检测潜在不安全情况并回退到备份策略。

Conclusion: EigenSafe框架通过离线学习主导特征对和安全备份策略，成功构建了一个安全过滤器，用于检测潜在不安全情况并回退到备份策略，在三个模拟的随机安全关键控制任务中验证了其有效性。

Abstract: We present EigenSafe, an operator-theoretic framework for learning-enabled
safety-critical control for stochastic systems. In many robotic systems where
dynamics are best modeled as stochastic systems due to factors such as sensing
noise and environmental disturbances, it is challenging for conventional
methods such as Hamilton-Jacobi reachability and control barrier functions to
provide a holistic measure of safety. We derive a linear operator governing the
dynamic programming principle for safety probability, and find that its
dominant eigenpair provides information about safety for both individual states
and the overall closed-loop system. The proposed learning framework, called
EigenSafe, jointly learns this dominant eigenpair and a safe backup policy in
an offline manner. The learned eigenfunction is then used to construct a safety
filter that detects potentially unsafe situations and falls back to the backup
policy. The framework is validated in three simulated stochastic
safety-critical control tasks.

</details>


### [331] [MotionTrans: Human VR Data Enable Motion-Level Learning for Robotic Manipulation Policies](https://arxiv.org/abs/2509.17759)
*Chengbo Yuan,Rui Zhou,Mengzhen Liu,Yingdong Hu,Shengjie Wang,Li Yi,Chuan Wen,Shanghang Zhang,Yang Gao*

Main category: cs.RO

TL;DR: MotionTrans框架通过人类数据转换和协同训练，实现动作知识迁移，显著提升机器人策略性能。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习中真实机器人数据稀缺的瓶颈，探索人类数据在机器人策略训练中的潜力，特别是直接学习新动作以完成任务的能力。

Method: 引入MotionTrans框架，包括数据收集系统、人类数据转换管道和加权协同训练策略，通过30个人机任务的协同训练，直接迁移13个任务的动作。

Result: 成功迁移13个任务的动作，其中9个任务以零样本方式达到非平凡成功率，预训练-微调性能提升40%。

Conclusion: 通过多任务人机协同训练，MotionTrans框架成功地将人类数据中的动作知识直接迁移至可部署的机器人策略中，显著提升了零样本任务完成率和预训练-微调性能。关键成功因素包括与机器人数据的协同训练和广泛的任务相关动作覆盖。

Abstract: Scaling real robot data is a key bottleneck in imitation learning, leading to
the use of auxiliary data for policy training. While other aspects of robotic
manipulation such as image or language understanding may be learned from
internet-based datasets, acquiring motion knowledge remains challenging. Human
data, with its rich diversity of manipulation behaviors, offers a valuable
resource for this purpose. While previous works show that using human data can
bring benefits, such as improving robustness and training efficiency, it
remains unclear whether it can realize its greatest advantage: enabling robot
policies to directly learn new motions for task completion. In this paper, we
systematically explore this potential through multi-task human-robot
cotraining. We introduce MotionTrans, a framework that includes a data
collection system, a human data transformation pipeline, and a weighted
cotraining strategy. By cotraining 30 human-robot tasks simultaneously, we
direcly transfer motions of 13 tasks from human data to deployable end-to-end
robot policies. Notably, 9 tasks achieve non-trivial success rates in zero-shot
manner. MotionTrans also significantly enhances pretraining-finetuning
performance (+40% success rate). Through ablation study, we also identify key
factors for successful motion learning: cotraining with robot data and broad
task-related motion coverage. These findings unlock the potential of
motion-level learning from human data, offering insights into its effective use
for training robotic manipulation policies. All data, code, and model weights
are open-sourced https://motiontrans.github.io/.

</details>


### [332] [Enhancing the NAO: Extending Capabilities of Legacy Robots for Long-Term Research](https://arxiv.org/abs/2509.17760)
*Austin Wilson,Sahar Kapasi,Zane Greene,Alexis E. Block*

Main category: cs.RO

TL;DR: Enhanced NAO 是一个升级版的NAO机器人，通过硬件和软件升级显著提升了对话质量和用户偏好，同时为老旧机器人提供了延长寿命的通用框架。


<details>
  <summary>Details</summary>
Motivation: 许多研究团队面临老旧机器人平台失去制造商支持、无法适应现代感知、语音和交互能力的挑战。

Method: 通过升级麦克风、RGB-D和热成像摄像头，以及增加计算资源，结合云端和本地模型进行感知和对话，同时保留NAO的表达能力和行为。

Result: 在试点验证研究中，Enhanced NAO 显著提高了对话质量和用户偏好，同时不增加响应延迟。关键升级如波束成形麦克风和低延迟音频处理减少了自听等伪影，改善了多方分离。扩展的视觉和热感知为未来交互能力奠定了基础。

Conclusion: Enhanced NAO 提供了一个平台无关的框架，能够延长老旧机器人的使用寿命和研究价值，使其继续成为人机交互的有价值工具。

Abstract: Many research groups face challenges when legacy (unsupported) robotic
platforms lose manufacturer support and cannot accommodate modern sensing,
speech, and interaction capabilities. We present the Enhanced NAO, a
revitalized version of Aldebaran's NAO robot that uses upgraded microphones,
RGB-D and thermal cameras, and additional compute resources in a fully
self-contained package. This system combines cloud and local models for
perception and dialogue, while preserving the NAO's expressive body and
behaviors. In a pilot validation study, the Enhanced NAO delivered
significantly higher conversational quality and stronger user preference
compared to the NAO AI Edition, without increasing response latency. Key
upgrades, such as beamforming microphones and low-latency audio processing,
reduced artifacts like self-hearing and improved multi-party separation.
Expanded visual and thermal sensing established a foundation for future
interaction capabilities. Beyond the NAO, our framework provides a
platform-agnostic strategy for extending the lifespan and research utility of
legacy robots, ensuring they remain valuable tools for human-robot interaction.

</details>


### [333] [RoboSeek: You Need to Interact with Your Objects](https://arxiv.org/abs/2509.17783)
*Yibo Peng,Jiahao Yang,Shenhao Yan,Ziyu Huang,Shuang Li,Shuguang Cui,Yiming Zhao,Yatong Han*

Main category: cs.RO

TL;DR: RoboSeek 是一个基于交互式体验的机器人操作框架，通过仿真训练和real2sim2real转移实现高效任务执行，平均成功率79%。


<details>
  <summary>Details</summary>
Motivation: 受具身认知理论启发，解决长时程任务中顺序决策、物理约束和感知不确定性等挑战。

Method: 利用3D重建在仿真环境中复制现实环境，通过强化学习和交叉熵方法结合视觉先验训练策略，并通过real2sim2real管道部署到现实机器人平台。

Result: 在多个机器人平台和八项长时程操作任务中，RoboSeek的平均成功率为79%，显著优于成功率低于50%的基线方法。

Conclusion: RoboSeek 框架通过交互式体验和仿真训练优化了机器人操作任务，实现了高达79%的平均成功率，显著优于基线方法，验证了其在复杂动态现实环境中的有效性。

Abstract: Optimizing and refining action execution through
  exploration and interaction is a promising way for robotic
  manipulation. However, practical approaches to interaction driven robotic
learning are still underexplored, particularly for
  long-horizon tasks where sequential decision-making, physical
  constraints, and perceptual uncertainties pose significant chal lenges.
Motivated by embodied cognition theory, we propose
  RoboSeek, a framework for embodied action execution that
  leverages interactive experience to accomplish manipulation
  tasks. RoboSeek optimizes prior knowledge from high-level
  perception models through closed-loop training in simulation
  and achieves robust real-world execution via a real2sim2real
  transfer pipeline. Specifically, we first replicate real-world
  environments in simulation using 3D reconstruction to provide
  visually and physically consistent environments., then we train
  policies in simulation using reinforcement learning and the
  cross-entropy method leveraging visual priors. The learned
  policies are subsequently deployed on real robotic platforms
  for execution. RoboSeek is hardware-agnostic and is evaluated
  on multiple robotic platforms across eight long-horizon ma nipulation tasks
involving sequential interactions, tool use, and
  object handling. Our approach achieves an average success rate
  of 79%, significantly outperforming baselines whose success
  rates remain below 50%, highlighting its generalization and
  robustness across tasks and platforms. Experimental results
  validate the effectiveness of our training framework in complex,
  dynamic real-world settings and demonstrate the stability of the
  proposed real2sim2real transfer mechanism, paving the way for
  more generalizable embodied robotic learning. Project Page:
  https://russderrick.github.io/Roboseek/

</details>


### [334] [Tac2Motion: Contact-Aware Reinforcement Learning with Tactile Feedback for Robotic Hand Manipulation](https://arxiv.org/abs/2509.17812)
*Yitaek Kim,Casper Hewson Rask,Christoffer Sloth*

Main category: cs.RO

TL;DR: Tac2Motion是一种接触感知强化学习框架，通过触觉奖励和嵌入观察提升手部操作任务的学习效率和鲁棒性，并在真实机器人上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决接触丰富的手部操作任务（如打开盖子）的学习效率问题。

Method: 提出基于触觉感知的奖励塑形，并将触觉感知通过嵌入整合到观察空间中。

Result: 在打开盖子的场景中验证了框架的有效性，展示了策略对不同物体类型和动态的泛化能力，并成功将策略迁移到真实世界的多指机器人上。

Conclusion: Tac2Motion框架成功地将接触感知强化学习应用于手部操作任务，展示了其在实际机器人上的可迁移性。

Abstract: This paper proposes Tac2Motion, a contact-aware reinforcement learning
framework to facilitate the learning of contact-rich in-hand manipulation
tasks, such as removing a lid. To this end, we propose tactile sensing-based
reward shaping and incorporate the sensing into the observation space through
embedding. The designed rewards encourage an agent to ensure firm grasping and
smooth finger gaiting at the same time, leading to higher data efficiency and
robust performance compared to the baseline. We verify the proposed framework
on the opening a lid scenario, showing generalization of the trained policy
into a couple of object types and various dynamics such as torsional friction.
Lastly, the learned policy is demonstrated on the multi-fingered robot, Shadow
Robot, showing that the control policy can be transferred to the real world.
The video is available: https://youtu.be/poeJBPR7urQ.

</details>


### [335] [SocialTraj: Two-Stage Socially-Aware Trajectory Prediction for Autonomous Driving via Conditional Diffusion Model](https://arxiv.org/abs/2509.17850)
*Xiao Zhou,Zengqi Peng,Jun Ma*

Main category: cs.RO

TL;DR: SocialTraj通过社会心理学与扩散模型提升轨迹预测，在动态场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前方法在多模态驾驶员行为捕捉上效果有限，导致预测轨迹与实际未来运动偏差较大，需提升动态复杂场景下的预测可靠性。

Method: 提出SocialTraj框架，结合社会价值取向（SVO）和条件去噪扩散模型，通过贝叶斯逆向强化学习估计SVO，并嵌入EV的规划轨迹以增强交互建模。

Result: 在NGSIM和HighD数据集上的实验表明，SocialTraj能适应高动态交互场景，生成符合社会规范且行为一致的轨迹预测，且消融研究显示动态SVO估计和显式EGO规划显著提升预测精度并减少推理时间。

Conclusion: SocialTraj框架通过整合社会心理学原理和贝叶斯逆向强化学习，显著提升了在动态复杂交通场景中的轨迹预测准确性，优于现有基线方法。

Abstract: Accurate trajectory prediction of surrounding vehicles (SVs) is crucial for
autonomous driving systems to avoid misguided decisions and potential
accidents. However, achieving reliable predictions in highly dynamic and
complex traffic scenarios remains a significant challenge. One of the key
impediments lies in the limited effectiveness of current approaches to capture
the multi-modal behaviors of drivers, which leads to predicted trajectories
that deviate from actual future motions. To address this issue, we propose
SocialTraj, a novel trajectory prediction framework integrating social
psychology principles through social value orientation (SVO). By utilizing
Bayesian inverse reinforcement learning (IRL) to estimate the SVO of SVs, we
obtain the critical social context to infer the future interaction trend. To
ensure modal consistency in predicted behaviors, the estimated SVOs of SVs are
embedded into a conditional denoising diffusion model that aligns generated
trajectories with historical driving styles. Additionally, the planned future
trajectory of the ego vehicle (EV) is explicitly incorporated to enhance
interaction modeling. Extensive experiments on NGSIM and HighD datasets
demonstrate that SocialTraj is capable of adapting to highly dynamic and
interactive scenarios while generating socially compliant and behaviorally
consistent trajectory predictions, outperforming existing baselines. Ablation
studies demonstrate that dynamic SVO estimation and explicit ego-planning
components notably improve prediction accuracy and substantially reduce
inference time.

</details>


### [336] [Sight Over Site: Perception-Aware Reinforcement Learning for Efficient Robotic Inspection](https://arxiv.org/abs/2509.17877)
*Richard Kuhlmann,Jakob Wolfram,Boyang Sun,Jiaxu Xing,Davide Scaramuzza,Marc Pollefeys,Cesar Cadena*

Main category: cs.RO

TL;DR: 本文提出了一种感知意识的强化学习框架，专注于目标可见性，显著提升了自主检查任务的效率。


<details>
  <summary>Details</summary>
Motivation: 传统检查任务常简化为导航问题，忽略了目标可见性的重要性，导致效率低下。本文从感知角度重新审视检查任务，旨在提高效率。

Method: 采用端到端强化学习框架，结合感知和本体感觉，训练策略时完全在模拟环境中进行，之后部署到真实机器人。

Result: 实验表明，该方法在模拟和真实环境中均能生成更高效的检查轨迹，优于现有方法。

Conclusion: 本文提出了一种基于感知意识的端到端强化学习框架，显著提升了自主检查任务的效率，优于现有的导航方法。

Abstract: Autonomous inspection is a central problem in robotics, with applications
ranging from industrial monitoring to search-and-rescue. Traditionally,
inspection has often been reduced to navigation tasks, where the objective is
to reach a predefined location while avoiding obstacles. However, this
formulation captures only part of the real inspection problem. In real-world
environments, the inspection targets may become visible well before their exact
coordinates are reached, making further movement both redundant and
inefficient. What matters more for inspection is not simply arriving at the
target's position, but positioning the robot at a viewpoint from which the
target becomes observable. In this work, we revisit inspection from a
perception-aware perspective. We propose an end-to-end reinforcement learning
framework that explicitly incorporates target visibility as the primary
objective, enabling the robot to find the shortest trajectory that guarantees
visual contact with the target without relying on a map. The learned policy
leverages both perceptual and proprioceptive sensing and is trained entirely in
simulation, before being deployed to a real-world robot. We further develop an
algorithm to compute ground-truth shortest inspection paths, which provides a
reference for evaluation. Through extensive experiments, we show that our
method outperforms existing classical and learning-based navigation approaches,
yielding more efficient inspection trajectories in both simulated and
real-world settings. The project is avialable at
https://sight-over-site.github.io/

</details>


### [337] [The Surprising Effectiveness of Linear Models for Whole-Body Model-Predictive Control](https://arxiv.org/abs/2509.17884)
*Arun L. Bishop,Juan Alvarez-Padilla,Sam Schoedel,Ibrahima Sory Sow,Juee Chandrachud,Sheitej Sharma,Will Kraus,Beomyeong Park,Robert J. Griffin,John M. Dolan,Zachary Manchester*

Main category: cs.RO

TL;DR: 研究表明，线性时不变近似的全身模型预测控制器可在复杂腿式机器人上实现基本运动任务，无需处理非线性问题。


<details>
  <summary>Details</summary>
Motivation: 探讨在何种情况下运动控制器需要考虑非线性问题，并验证线性近似在复杂腿式机器人上的有效性。

Method: 采用线性时不变近似的全身模型预测控制器，避免了非线性动力学评估和矩阵求逆。

Result: 在四足机器人和液压人形机器人上成功实现了行走、抗干扰、目标导航以及动态行走。

Conclusion: 该研究证明了使用线性时不变近似的全身模型预测控制器能够在复杂腿式机器人上执行基本运动任务，无需在线非线性动力学评估或矩阵求逆。

Abstract: When do locomotion controllers require reasoning about nonlinearities? In
this work, we show that a whole-body model-predictive controller using a simple
linear time-invariant approximation of the whole-body dynamics is able to
execute basic locomotion tasks on complex legged robots. The formulation
requires no online nonlinear dynamics evaluations or matrix inversions. We
demonstrate walking, disturbance rejection, and even navigation to a goal
position without a separate footstep planner on a quadrupedal robot. In
addition, we demonstrate dynamic walking on a hydraulic humanoid, a robot with
significant limb inertia, complex actuator dynamics, and large sim-to-real gap.

</details>


### [338] [DriveDPO: Policy Learning via Safety DPO For End-to-End Autonomous Driving](https://arxiv.org/abs/2509.17940)
*Shuyao Shang,Yuntao Chen,Yuqi Wang,Yingyan Li,Zhaoxiang Zhang*

Main category: cs.RO

TL;DR: DriveDPO是一种安全直接偏好优化策略学习框架，结合人类模仿和规则安全评分，显著提升自动驾驶的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 主流方法通过模仿学习训练，但存在安全限制，无法区分看似人类但潜在不安全的轨迹。现有方法尝试通过回归多个规则驱动的评分来解决，但监督与策略优化脱节，导致性能不佳。

Method: 首先从人类模仿相似性和基于规则的安全评分中提取统一的策略分布用于直接策略优化；然后引入迭代的直接偏好优化阶段，作为轨迹级别的偏好对齐。

Result: 在NAVSIM基准测试中，DriveDPO达到了90.0的PDMS新纪录，并在多样化的挑战性场景中展现出更安全和可靠的驾驶行为。

Conclusion: DriveDPO通过结合人类模仿相似性和基于规则的安全评分，提出了一种创新的安全直接偏好优化策略学习框架，显著提升了自动驾驶的安全性和可靠性。

Abstract: End-to-end autonomous driving has substantially progressed by directly
predicting future trajectories from raw perception inputs, which bypasses
traditional modular pipelines. However, mainstream methods trained via
imitation learning suffer from critical safety limitations, as they fail to
distinguish between trajectories that appear human-like but are potentially
unsafe. Some recent approaches attempt to address this by regressing multiple
rule-driven scores but decoupling supervision from policy optimization,
resulting in suboptimal performance. To tackle these challenges, we propose
DriveDPO, a Safety Direct Preference Optimization Policy Learning framework.
First, we distill a unified policy distribution from human imitation similarity
and rule-based safety scores for direct policy optimization. Further, we
introduce an iterative Direct Preference Optimization stage formulated as
trajectory-level preference alignment. Extensive experiments on the NAVSIM
benchmark demonstrate that DriveDPO achieves a new state-of-the-art PDMS of
90.0. Furthermore, qualitative results across diverse challenging scenarios
highlight DriveDPO's ability to produce safer and more reliable driving
behaviors.

</details>


### [339] [ComposableNav: Instruction-Following Navigation in Dynamic Environments via Composable Diffusion](https://arxiv.org/abs/2509.17941)
*Zichao Hu,Chen Tang,Michael J. Munje,Yifeng Zhu,Alex Liu,Shuijing Liu,Garrett Warnell,Peter Stone,Joydeep Biswas*

Main category: cs.RO

TL;DR: ComposableNav 通过扩散模型组合运动原语，实现机器人动态导航中复杂指令的遵循。


<details>
  <summary>Details</summary>
Motivation: 解决机器人导航动态环境时，指令组合爆炸的挑战。

Method: 提出 ComposableNav，基于扩散模型分别学习各运动原语，并在部署时并行组合以应对新指令。采用两阶段训练：监督预训练学习基础扩散模型，强化学习微调生成不同运动原语。

Result: 实验证明 ComposableNav 能生成满足多样化且未见过的指令组合的轨迹，性能显著优于基线方法。

Conclusion: ComposableNav 通过并行组合不同的运动原语，成功解决了机器人导航动态环境中遵循复杂指令的挑战，显著优于非组合方法。

Abstract: This paper considers the problem of enabling robots to navigate dynamic
environments while following instructions. The challenge lies in the
combinatorial nature of instruction specifications: each instruction can
include multiple specifications, and the number of possible specification
combinations grows exponentially as the robot's skill set expands. For example,
"overtake the pedestrian while staying on the right side of the road" consists
of two specifications: "overtake the pedestrian" and "walk on the right side of
the road." To tackle this challenge, we propose ComposableNav, based on the
intuition that following an instruction involves independently satisfying its
constituent specifications, each corresponding to a distinct motion primitive.
Using diffusion models, ComposableNav learns each primitive separately, then
composes them in parallel at deployment time to satisfy novel combinations of
specifications unseen in training. Additionally, to avoid the onerous need for
demonstrations of individual motion primitives, we propose a two-stage training
procedure: (1) supervised pre-training to learn a base diffusion model for
dynamic navigation, and (2) reinforcement learning fine-tuning that molds the
base model into different motion primitives. Through simulation and real-world
experiments, we show that ComposableNav enables robots to follow instructions
by generating trajectories that satisfy diverse and unseen combinations of
specifications, significantly outperforming both non-compositional VLM-based
policies and costmap composing baselines. Videos and additional materials can
be found on the project page: https://amrl.cs.utexas.edu/ComposableNav/

</details>


### [340] [Guided Multi-Fidelity Bayesian Optimization for Data-driven Controller Tuning with Digital Twins](https://arxiv.org/abs/2509.17952)
*Mahdi Nobar,Jürg Keller,Alessandro Forino,John Lygeros,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 提出一种结合数字孪生和真实数据的多保真度贝叶斯优化方法，动态调整模型准确性，提升控制器调谐效率。


<details>
  <summary>Details</summary>
Motivation: 针对闭环系统中保真度有限或近似成本低的模拟问题，解决模型不匹配的挑战。

Method: 提出了一种引导多保真度贝叶斯优化框架，结合校正的数字孪生模拟和真实世界测量，构建了多保真度代理模型，并采用自适应成本感知采集函数。

Result: 在机器人驱动硬件和支持性数值研究中，该方法显著提升了调谐效率。

Conclusion: 该方法通过动态调整数字孪生（DT）的准确性和采集函数，有效提升了控制器调谐的效率，优于标准的贝叶斯优化和多保真度方法。

Abstract: We propose a \textit{guided multi-fidelity Bayesian optimization} framework
for data-efficient controller tuning that integrates corrected digital twin
(DT) simulations with real-world measurements. The method targets closed-loop
systems with limited-fidelity simulations or inexpensive approximations. To
address model mismatch, we build a multi-fidelity surrogate with a learned
correction model that refines DT estimates from real data. An adaptive
cost-aware acquisition function balances expected improvement, fidelity, and
sampling cost. Our method ensures adaptability as new measurements arrive. The
accuracy of DTs is re-estimated, dynamically adapting both cross-source
correlations and the acquisition function. This ensures that accurate DTs are
used more frequently, while inaccurate DTs are appropriately downweighted.
Experiments on robotic drive hardware and supporting numerical studies
demonstrate that our method enhances tuning efficiency compared to standard
Bayesian optimization (BO) and multi-fidelity methods.

</details>


### [341] [M3ET: Efficient Vision-Language Learning for Robotics based on Multimodal Mamba-Enhanced Transformer](https://arxiv.org/abs/2509.18005)
*Yanxin Zhang,Liang He,Zeyi Kang,Zuheng Ming,Kaixing Zhao*

Main category: cs.RO

TL;DR: 提出轻量级模型M3ET，通过Mamba模块和自适应注意力机制优化多模态学习，提升效率并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以充分利用文本模态，依赖监督预训练模型，限制了无监督机器人环境中的语义提取，且计算资源消耗高。

Method: 通过结合Mamba模块和基于语义的自适应注意力机制，M3ET优化了特征融合、对齐和模态重建。

Result: M3ET在跨任务性能上有所提升，预训练推理速度提高了2.3倍，VQA任务准确率保持在0.74，模型参数量减少了0.67。

Conclusion: 尽管在EQA任务上表现有限，M3ET的轻量级设计使其非常适合部署在资源受限的机器人平台上。

Abstract: In recent years, multimodal learning has become essential in robotic vision
and information fusion, especially for understanding human behavior in complex
environments. However, current methods struggle to fully leverage the textual
modality, relying on supervised pretrained models, which limits semantic
extraction in unsupervised robotic environments, particularly with significant
modality loss. These methods also tend to be computationally intensive, leading
to high resource consumption in real-world applications. To address these
challenges, we propose the Multi Modal Mamba Enhanced Transformer (M3ET), a
lightweight model designed for efficient multimodal learning, particularly on
mobile platforms. By incorporating the Mamba module and a semantic-based
adaptive attention mechanism, M3ET optimizes feature fusion, alignment, and
modality reconstruction. Our experiments show that M3ET improves cross-task
performance, with a 2.3 times increase in pretraining inference speed. In
particular, the core VQA task accuracy of M3ET remains at 0.74, while the
model's parameter count is reduced by 0.67. Although performance on the EQA
task is limited, M3ET's lightweight design makes it well suited for deployment
on resource-constrained robotic platforms.

</details>


### [342] [Prepare Before You Act: Learning From Humans to Rearrange Initial States](https://arxiv.org/abs/2509.18043)
*Yinlong Dai,Andre Keyser,Dylan P. Losey*

Main category: cs.RO

TL;DR: ReSET算法通过预调整环境，提升了模仿学习策略在分布外观察下的表现。


<details>
  <summary>Details</summary>
Motivation: 模仿学习策略在面临分布外观察时表现不佳，而人类会预调整环境以简化任务执行，因此希望赋予机器人同样的能力。

Method: ReSET算法结合动作无关的人类视频和任务无关的远程操作数据，分三步决定何时调整场景、预测人类简化动作，并映射到机器人动作基元。

Result: 与扩散策略、VLAs等基线相比，ReSET在相同训练数据量下实现了更鲁棒的任务执行。

Conclusion: ReSET算法通过预调整环境提升了模仿学习策略在分布外观察下的鲁棒性和泛化能力。

Abstract: Imitation learning (IL) has proven effective across a wide range of
manipulation tasks. However, IL policies often struggle when faced with
out-of-distribution observations; for instance, when the target object is in a
previously unseen position or occluded by other objects. In these cases,
extensive demonstrations are needed for current IL methods to reach robust and
generalizable behaviors. But when humans are faced with these sorts of atypical
initial states, we often rearrange the environment for more favorable task
execution. For example, a person might rotate a coffee cup so that it is easier
to grasp the handle, or push a box out of the way so they can directly grasp
their target object. In this work we seek to equip robot learners with the same
capability: enabling robots to prepare the environment before executing their
given policy. We propose ReSET, an algorithm that takes initial states -- which
are outside the policy's distribution -- and autonomously modifies object poses
so that the restructured scene is similar to training data. Theoretically, we
show that this two step process (rearranging the environment before rolling out
the given policy) reduces the generalization gap. Practically, our ReSET
algorithm combines action-agnostic human videos with task-agnostic
teleoperation data to i) decide when to modify the scene, ii) predict what
simplifying actions a human would take, and iii) map those predictions into
robot action primitives. Comparisons with diffusion policies, VLAs, and other
baselines show that using ReSET to prepare the environment enables more robust
task execution with equal amounts of total training data. See videos at our
project website: https://reset2025paper.github.io/

</details>


### [343] [HuMam: Humanoid Motion Control via End-to-End Deep Reinforcement Learning with Mamba](https://arxiv.org/abs/2509.18046)
*Yinuo Wang,Yuanyang Qi,Jinzhao Zhou,Gavin Tao*

Main category: cs.RO

TL;DR: HuMam是一个基于Mamba编码器的端到端RL框架，通过优化状态融合和奖励设计，提升了人形机器人运动的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决端到端强化学习在人形机器人运动控制中存在的训练不稳定、特征融合效率低和高驱动成本等问题。

Method: 采用单层Mamba编码器融合机器人中心状态、定向步态目标和连续相位时钟，通过PPO优化策略输出关节位置目标，并由低层PD循环跟踪。奖励函数包含六项指标以平衡多方面性能。

Result: 在JVRC-1人形机器人上，HuMam相比前馈基线显著提高了学习效率、训练稳定性和任务表现，同时降低了能耗和扭矩峰值。

Conclusion: HuMam框架通过Mamba编码器有效融合机器人状态信息，显著提升了人形机器人运动的效率、稳定性和控制经济性，成为首个采用Mamba作为融合骨干的端到端RL控制器。

Abstract: End-to-end reinforcement learning (RL) for humanoid locomotion is appealing
for its compact perception-action mapping, yet practical policies often suffer
from training instability, inefficient feature fusion, and high actuation cost.
We present HuMam, a state-centric end-to-end RL framework that employs a
single-layer Mamba encoder to fuse robot-centric states with oriented footstep
targets and a continuous phase clock. The policy outputs joint position targets
tracked by a low-level PD loop and is optimized with PPO. A concise six-term
reward balances contact quality, swing smoothness, foot placement, posture, and
body stability while implicitly promoting energy saving. On the JVRC-1 humanoid
in mc-mujoco, HuMam consistently improves learning efficiency, training
stability, and overall task performance over a strong feedforward baseline,
while reducing power consumption and torque peaks. To our knowledge, this is
the first end-to-end humanoid RL controller that adopts Mamba as the fusion
backbone, demonstrating tangible gains in efficiency, stability, and control
economy.

</details>


### [344] [V2V-GoT: Vehicle-to-Vehicle Cooperative Autonomous Driving with Multimodal Large Language Models and Graph-of-Thoughts](https://arxiv.org/abs/2509.18053)
*Hsu-kuang Chiu,Ryo Hachiuma,Chien-Yi Wang,Yu-Chiang Frank Wang,Min-Hung Chen,Stephen F. Smith*

Main category: cs.RO

TL;DR: 本文提出了一种基于图思维的多模态大语言模型协同自动驾驶框架，通过遮挡感知和规划感知的预测，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在传感器被遮挡时可能面临安全风险，而现有的协同驾驶研究未充分利用图思维推理的潜力。

Method: 采用图思维框架，结合遮挡感知的感知和规划感知的预测，开发了V2V-GoT模型，并利用V2V-GoT-QA数据集进行训练和测试。

Result: 实验结果表明，该方法在协同感知、预测和规划任务中优于其他基线。

Conclusion: 本文提出的图思维框架在协同自动驾驶中表现出色，尤其在感知、预测和规划任务上优于其他基线方法。

Abstract: Current state-of-the-art autonomous vehicles could face safety-critical
situations when their local sensors are occluded by large nearby objects on the
road. Vehicle-to-vehicle (V2V) cooperative autonomous driving has been proposed
as a means of addressing this problem, and one recently introduced framework
for cooperative autonomous driving has further adopted an approach that
incorporates a Multimodal Large Language Model (MLLM) to integrate cooperative
perception and planning processes. However, despite the potential benefit of
applying graph-of-thoughts reasoning to the MLLM, this idea has not been
considered by previous cooperative autonomous driving research. In this paper,
we propose a novel graph-of-thoughts framework specifically designed for
MLLM-based cooperative autonomous driving. Our graph-of-thoughts includes our
proposed novel ideas of occlusion-aware perception and planning-aware
prediction. We curate the V2V-GoT-QA dataset and develop the V2V-GoT model for
training and testing the cooperative driving graph-of-thoughts. Our
experimental results show that our method outperforms other baselines in
cooperative perception, prediction, and planning tasks.

</details>


### [345] [RadarSFD: Single-Frame Diffusion with Pretrained Priors for Radar Point Clouds](https://arxiv.org/abs/2509.18068)
*Bin Zhao,Nakul Garg*

Main category: cs.RO

TL;DR: RadarSFD是一种单帧毫米波雷达点云重建方法，通过扩散框架和预训练几何先验，显著提升了单帧雷达的感知性能，适用于紧凑机器人系统。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达在雾、烟、尘和低光条件下具有鲁棒性，适合尺寸、重量和功耗受限的机器人平台。然而，现有雷达成像方法依赖合成孔径或多帧聚合来提高分辨率，这对小型空中、检测或可穿戴系统不实用。

Method: RadarSFD 是一种条件潜在扩散框架，通过将预训练的单目深度估计器的几何先验转移到扩散主干中，并通过通道级潜在连接将其锚定到雷达输入，同时使用结合潜在空间和像素空间损失的双空间目标来正则化输出。

Result: 在RadarHD基准测试中，RadarSFD实现了35厘米的Chamfer距离和28厘米的修正Hausdorff距离，优于单帧RadarHD基线（56厘米，45厘米），并与使用5-41帧的多帧方法竞争。定性结果显示恢复了细墙和窄间隙，跨新环境的实验证实了强泛化能力。

Conclusion: RadarSFD 是首个实用的单帧、无需SAR的毫米波雷达管道，适用于紧凑机器人系统中的密集点云感知。

Abstract: Millimeter-wave radar provides perception robust to fog, smoke, dust, and low
light, making it attractive for size, weight, and power constrained robotic
platforms. Current radar imaging methods, however, rely on synthetic aperture
or multi-frame aggregation to improve resolution, which is impractical for
small aerial, inspection, or wearable systems. We present RadarSFD, a
conditional latent diffusion framework that reconstructs dense LiDAR-like point
clouds from a single radar frame without motion or SAR. Our approach transfers
geometric priors from a pretrained monocular depth estimator into the diffusion
backbone, anchors them to radar inputs via channel-wise latent concatenation,
and regularizes outputs with a dual-space objective combining latent and
pixel-space losses. On the RadarHD benchmark, RadarSFD achieves 35 cm Chamfer
Distance and 28 cm Modified Hausdorff Distance, improving over the single-frame
RadarHD baseline (56 cm, 45 cm) and remaining competitive with multi-frame
methods using 5-41 frames. Qualitative results show recovery of fine walls and
narrow gaps, and experiments across new environments confirm strong
generalization. Ablation studies highlight the importance of pretrained
initialization, radar BEV conditioning, and the dual-space loss. Together,
these results establish the first practical single-frame, no-SAR mmWave radar
pipeline for dense point cloud perception in compact robotic systems.

</details>


### [346] [ByteWrist: A Parallel Robotic Wrist Enabling Flexible and Anthropomorphic Motion for Confined Spaces](https://arxiv.org/abs/2509.18084)
*Jiawen Tian,Liqun Huang,Zhongren Cui,Jingchao Qiao,Jiafeng Xu,Xiao Ma,Zeyu Ren*

Main category: cs.RO

TL;DR: ByteWrist是一种新型平行手腕，通过紧凑的三级驱动机制和弧形末端连接件，显著提升狭窄空间操作性能，适用于复杂非结构化环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有串行和平行手腕在狭窄空间操作中的关键限制，适用于家庭服务、医疗辅助和精密组装等复杂非结构化环境。

Method: 设计采用了嵌套的三级电机驱动连接件、弧形末端连接件和中央支撑球结构，结合全面的运动学建模（包括正/逆运动学和数值雅可比解）以实现精确控制。

Result: 实验表明，ByteWrist在狭窄空间机动性和双臂协作操作任务中表现优异，显著优于Kinova系统，且在紧凑性、效率和刚度方面相比传统设计有显著提升。

Conclusion: ByteWrist作为一种新型高度灵活且拟人化的平行手腕，通过其紧凑的三级平行驱动机制和弧形末端连接件，显著提升了在狭窄空间操作中的性能，为受限环境下的下一代机器人操作提供了有前景的解决方案。

Abstract: This paper introduces ByteWrist, a novel highly-flexible and anthropomorphic
parallel wrist for robotic manipulation. ByteWrist addresses the critical
limitations of existing serial and parallel wrists in narrow-space operations
through a compact three-stage parallel drive mechanism integrated with
arc-shaped end linkages. The design achieves precise RPY (Roll-Pitch-Yaw)
motion while maintaining exceptional compactness, making it particularly
suitable for complex unstructured environments such as home services, medical
assistance, and precision assembly. The key innovations include: (1) a nested
three-stage motor-driven linkages that minimize volume while enabling
independent multi-DOF control, (2) arc-shaped end linkages that optimize force
transmission and expand motion range, and (3) a central supporting ball
functioning as a spherical joint that enhances structural stiffness without
compromising flexibility. Meanwhile, we present comprehensive kinematic
modeling including forward / inverse kinematics and a numerical Jacobian
solution for precise control. Empirically, we observe ByteWrist demonstrates
strong performance in narrow-space maneuverability and dual-arm cooperative
manipulation tasks, outperforming Kinova-based systems. Results indicate
significant improvements in compactness, efficiency, and stiffness compared to
traditional designs, establishing ByteWrist as a promising solution for
next-generation robotic manipulation in constrained environments.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [347] [Sublinear Time Quantum Sensitivity Sampling](https://arxiv.org/abs/2509.16801)
*Zhao Song,David P. Woodruff,Lichen Zhang*

Main category: cs.DS

TL;DR: 本文提出了一种统一的量子敏感性采样框架，显著提升了聚类、回归和低秩近似问题的效率，并构建了更小的核心集。


<details>
  <summary>Details</summary>
Motivation: 量子计算在经典近似问题中的应用尚未充分探索，本文旨在通过统一框架扩展量子优势，解决现有方法在核心集构建和运行时效率上的局限性。

Method: 通过量子计算的优势，提出了一种构建核心集的统一方法，并在$k$-median和$k$-means聚类、$\ell_p$回归以及低秩近似问题中实现了更优的运行时和核心集大小。

Result: 在$k$-median和$k$-means聚类中，构建了$\epsilon$-核心集，运行时间为$\widetilde O(n^{0.5}dk^{2.5}~\mathrm{poly}(\epsilon^{-1}))$；在$\ell_p$回归中，核心集大小为$\widetilde O_p(d^{\max\\{1, p/2\\}}\epsilon^{-2})$，运行时间为$\widetilde O_p(n^{0.5}d^{\max\\{0.5, p/4\\}+1}(\epsilon^{-3}+d^{0.5}))$；在低秩近似中，首次实现了不依赖数据参数的量子次线性时间算法。

Conclusion: 本文提出了一个统一的量子敏感性采样框架，显著提升了在聚类、回归和低秩近似等经典近似问题中的运行效率，并构建了更小的核心集。

Abstract: We present a unified framework for quantum sensitivity sampling, extending
the advantages of quantum computing to a broad class of classical approximation
problems. Our unified framework provides a streamlined approach for
constructing coresets and offers significant runtime improvements in
applications such as clustering, regression, and low-rank approximation. Our
contributions include:
  * $k$-median and $k$-means clustering: For $n$ points in $d$-dimensional
Euclidean space, we give an algorithm that constructs an $\epsilon$-coreset in
time $\widetilde O(n^{0.5}dk^{2.5}~\mathrm{poly}(\epsilon^{-1}))$ for
$k$-median and $k$-means clustering. Our approach achieves a better dependence
on $d$ and constructs smaller coresets that only consist of points in the
dataset, compared to recent results of [Xue, Chen, Li and Jiang, ICML'23].
  * $\ell_p$ regression: For $\ell_p$ regression problems, we construct an
$\epsilon$-coreset of size $\widetilde O_p(d^{\max\{1, p/2\}}\epsilon^{-2})$ in
time $\widetilde O_p(n^{0.5}d^{\max\{0.5, p/4\}+1}(\epsilon^{-3}+d^{0.5}))$,
improving upon the prior best quantum sampling approach of [Apers and Gribling,
QIP'24] for all $p\in (0, 2)\cup (2, 22]$, including the widely studied least
absolute deviation regression ($\ell_1$ regression).
  * Low-rank approximation with Frobenius norm error: We introduce the first
quantum sublinear-time algorithm for low-rank approximation that does not rely
on data-dependent parameters, and runs in $\widetilde
O(nd^{0.5}k^{0.5}\epsilon^{-1})$ time. Additionally, we present quantum
sublinear algorithms for kernel low-rank approximation and tensor low-rank
approximation, broadening the range of achievable sublinear time algorithms in
randomized numerical linear algebra.

</details>


### [348] [Quadratic Kernel for Cliques or Trees Vertex Deletion](https://arxiv.org/abs/2509.16815)
*Soh Kumabe*

Main category: cs.DS

TL;DR: 论文提出了一个关于“Cliques or Trees Vertex Deletion”问题的新核化结果，将核大小从O(k^5)优化到O(k^2)，并首次将其作为一种结构参数进行研究，证明了在此参数下“Longest Cycle”问题是固定参数可解的。


<details>
  <summary>Details</summary>
Motivation: 为了解决“Cluster Vertex Deletion”和“Feedback Vertex Set”这两个基本参数化问题的混合问题，并填补现有研究中关于同时推广这两种问题的结构参数的空白。

Method: 通过核化技术优化问题，将核大小从O(k^5)逐步改进到O(k^2)，并研究“cliques or trees vertex deletion number”作为结构参数的性质。

Result: 成功将核大小优化到O(k^2)，并证明“Longest Cycle”问题在此参数下是固定参数可解的。

Conclusion: 论文不仅优化了核化结果，还填补了结构参数研究的空白，为相关问题的参数化算法设计提供了新的视角。

Abstract: We consider \textsc{Cliques or Trees Vertex Deletion}, which is a hybrid of
two fundamental parameterized problems: \textsc{Cluster Vertex Deletion} and
\textsc{Feedback Vertex Set}. In this problem, we are given an undirected graph
$G$ and an integer $k$, and asked to find a vertex subset $X$ of size at most
$k$ such that each connected component of $G-X$ is either a clique or a tree.
Jacob et al. (ISAAC, 2024) provided a kernel of $O(k^5)$ vertices for this
problem, which was recently improved to $O(k^4)$ by Tsur (IPL, 2025).
  Our main result is a kernel of $O(k^2)$ vertices. This result closes the gap
between the kernelization result for \textsc{Feedback Vertex Set}, which
corresponds to the case where each connected component of $G-X$ must be a tree.
  Although both \emph{cluster vertex deletion number} and \emph{feedback vertex
set number} are well-studied structural parameters, little attention has been
given to parameters that generalize both of them. In fact, the lowest common
well-known generalization of them is clique-width, which is a highly general
parameter. To fill the gap here, we initiate the study of the \emph{cliques or
trees vertex deletion number} as a structural parameter. We prove that
\textsc{Longest Cycle}, which is a fundamental problem that does not admit
$o(n^k)$-time algorithm unless ETH fails when $k$ is the clique-width, becomes
fixed-parameter tractable when parameterized by the cliques or trees vertex
deletion number.

</details>


### [349] [Optimal 4-Approximation for the Correlated Pandora's Problem](https://arxiv.org/abs/2509.17029)
*Nikhil Bansal,Zhiyi Huang,Zixuan Zhu*

Main category: cs.DS

TL;DR: 本文针对相关潘多拉问题提出了一个最优的4-近似算法，匹配了最小和集合覆盖问题的下界4。


<details>
  <summary>Details</summary>
Motivation: 相关潘多拉问题是对经典潘多拉问题的推广，允许潘多拉盒子中的数字具有相关性。该问题还推广了最小和集合覆盖问题，并与均匀决策树问题相关。

Method: 通过将相关潘多拉问题与最小和集合覆盖问题及均匀决策树问题联系起来，提出了一种新的近似算法。

Result: 提出了一个最优的4-近似算法，匹配了已知的下界。

Conclusion: 本文为相关潘多拉问题提供了一个最优的4-近似算法，匹配了最小和集合覆盖问题的下界4。

Abstract: The Correlated Pandora's Problem posed by Chawla et al. (2020) generalizes
the classical Pandora's Problem by allowing the numbers inside the Pandora's
boxes to be correlated. It also generalizes the Min Sum Set Cover problem, and
is related to the Uniform Decision Tree problem. This paper gives an optimal
4-approximation for the Correlated Pandora's Problem, matching the lower bound
of 4 from Min Sum Set Cover.

</details>


### [350] [Distance Approximating Minors for Planar and Minor-Free Graphs](https://arxiv.org/abs/2509.17226)
*Hsien-Chih Chang,Jonathan Conroy*

Main category: cs.DS

TL;DR: 论文提出了一种新的(1+ε)-距离近似小图构造方法，首次在平面图和小图自由图中实现近线性大小，突破了二次终端数限制。


<details>
  <summary>Details</summary>
Motivation: 现有的(1+ε)-DAM构造方法在平面图中依赖于叠加多条最短路径，导致终端数目的二次增长，限制了其应用范围。论文旨在突破这一限制，提供更高效的构造方法。

Method: 该构造方法基于最短路径分隔符和ε-覆盖的存在性，避免了传统方法中需要叠加多条最短路径的复杂性。

Result: 论文成功构造了大小为˜Oε(k)的(1+ε)-DAM，适用于k-终端平面图和小图自由图，且构造时间接近线性。

Conclusion: 该论文提出了一种新的(1+ε)-距离近似小图（DAM）构造方法，首次在k-终端平面图和小图自由图中实现了近线性大小的构造，突破了现有方法的二次终端数限制。

Abstract: Given an edge-weighted graph $G$ and a subset of vertices $T$ called
terminals, an $\alpha$-distance-approximating minor ($\alpha$-DAM) of $G$ is a
graph minor $H$ of $G$ that contains all terminals, such that the distance
between every pair of terminals is preserved up to a factor of $\alpha$.
Distance-approximating minor would be an effective distance-sketching structure
on minor-closed family of graphs; in the constant-stretch regime it generalizes
the well-known Steiner Point Removal problem by allowing the existence of (a
small number of) non-terminal vertices. Unfortunately, in the $(1+\varepsilon)$
regime the only known DAM construction for planar graphs relies on overlaying
$\tilde{O}_\varepsilon(|T|)$ shortest paths in $G$, which naturally leads to a
quadratic bound in the number of terminals [Cheung, Goranci, and Henzinger,
ICALP 2016].
  We break the quadratic barrier and build the first
$(1+\varepsilon)$-distance-approximating minor for $k$-terminal planar graphs
and minor-free graphs of near-linear size $\tilde{O}_\varepsilon(k)$. In
addition to the near-optimality in size, the construction relies only on the
existence of shortest-path separators [Abraham and Gavoille, PODC 2006] and
$\varepsilon$-covers [Thorup, J.\ ACM 2004]. Consequently, this provides an
alternative and simpler construction to the near-linear-size emulator for
planar graphs [Chang, Krauthgamer, and Tan, STOC 2022], as well as the first
near-linear-size emulator for minor-free graphs. Our DAM can be constructed in
near-linear time.

</details>


### [351] [Distribution Testing in the Presence of Arbitrarily Dominant Noise with Verification Queries](https://arxiv.org/abs/2509.17269)
*Hadley Black,Christopher Ye*

Main category: cs.DS

TL;DR: 论文研究了在验证查询模型下的分布测试，展示了样本和查询复杂度之间的平滑权衡，并提供了针对均匀性、一致性和接近性测试的高效算法。


<details>
  <summary>Details</summary>
Motivation: 研究在没有直接访问相关数据源的情况下进行分布测试的问题，其中只有一小部分数据是相关的。通过引入验证查询模型，探索如何在样本和查询复杂度之间找到平衡。

Method: 论文引入了验证查询模型，通过样本访问混合分布和查询样本来源的能力，研究了分布测试的经典问题。作者提出了针对均匀性和一致性测试以及接近性测试的算法，并分析了样本和查询复杂度的上界和下界。

Result: 论文展示了在验证查询模型下，分布测试任务可以实现高效的样本和查询复杂度。特别是，对于均匀性和一致性测试，以及接近性测试，作者提供了匹配的上界和下界，并展示了在特定条件下查询复杂度可以显著降低。

Conclusion: 论文表明，在验证查询模型中，通过优化样本和查询复杂度，可以实现高效的分布测试。特别是，对于均匀性和一致性测试，以及接近性测试，作者提供了匹配的上界和下界，展示了样本和查询复杂度之间的平滑权衡。此外，论文还展示了在特定条件下，查询复杂度可以显著降低。

Abstract: We study distribution testing without direct access to a source of relevant
data, but rather to one where only a tiny fraction is relevant. To enable this,
we introduce the following verification query model. The goal is to perform a
statistical task on distribution $\boldsymbol{p}$ given sample access to a
mixture $\boldsymbol{r} = \lambda \boldsymbol{p} + (1-\lambda)\boldsymbol{q}$
and the ability to query whether a sample was generated by $\boldsymbol{p}$ or
by $\boldsymbol{q}$. In general, if $m_0$ samples from $\boldsymbol{p}$ suffice
for a task, then $O(m_0/\lambda)$ samples and queries always suffice in our
model. Are there tasks for which the number of queries can be significantly
reduced?
  We study the canonical problems in distribution testing, and obtain matching
upper and lower bounds that reveal smooth trade-offs between sample and query
complexity. For all $m \leq n$, we obtain (i) a uniformity and identity tester
using $O(m + \frac{\sqrt{n}}{\varepsilon^2 \lambda})$ samples and $O(\frac{n}{m
\varepsilon^4 \lambda^2})$ queries, and (ii) a closeness tester using $O(m +
\frac{n^{2/3}}{\varepsilon^{4/3} \lambda} + \frac{1}{\varepsilon^4 \lambda^3})$
samples and $O(\frac{n^2}{m^2 \varepsilon^4 \lambda^3})$ queries. Moreover, we
show that these query complexities are tight for all testers using $m \ll n$
samples.
  Next, we show that for testing closeness using $m =
\widetilde{O}(\frac{n}{\varepsilon^2\lambda})$ samples we can achieve query
complexity $\widetilde{O}(\frac{1}{\varepsilon^2\lambda})$ which is nearly
optimal even for the basic task of bias estimation with unbounded samples. Our
uniformity testers work in the more challenging setting where the contaminated
samples are generated by an adaptive adversary (at the cost of a $\log n$
factor). Finally, we show that our lower bounds can be circumvented if the
algorithm is provided with the PDF of the mixture.

</details>


### [352] [Theory Meets Practice for Bit Vectors Supporting Rank and Select](https://arxiv.org/abs/2509.17819)
*Florian Kurpicz,Niccolò Rigi-Luperti,Peter Sanders*

Main category: cs.DS

TL;DR: 论文提出了一种高效的位向量秩和选择数据结构，具有低空间开销和快速查询性能。


<details>
  <summary>Details</summary>
Motivation: 解决位向量秩和选择数据结构在理论和实践之间的差距，优化查询时间和空间开销。

Method: 通过分析设计空间的重要部分并进行实验评估，找到一个最佳平衡点。

Result: 实现了一个空间开销仅为0.78%的位向量秩和选择数据结构，查询时间在最坏情况下为常数，且性能优于之前实现。

Conclusion: 该论文实现了首个具有最坏情况下恒定查询时间、良好实际性能和仅0.78%空间开销的位向量秩和选择数据结构，填补了理论与实践之间的差距。

Abstract: Bit vectors with support for fast rank and select are a fundamental building
block for compressed data structures. We close a gap between theory and
practice by analyzing an important part of the design space and experimentally
evaluating a sweet spot. The result is the first implementation of a rank and
select data structure for bit vectors with worst-case constant query time, good
practical performance, and a space-overhead of just 0.78%, i.e., between
$4.5\times$ and $64.1\times$ less than previous implementations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [353] [Identifying Critical Pathways in Coronary Heart Disease via Fuzzy Subgraph Connectivity](https://arxiv.org/abs/2509.16288)
*Shanookha Ali,Nitha Niralda P C*

Main category: cs.AI

TL;DR: 通过模糊子图连通性（FSC）分析冠心病风险因素，提供了一种建模不确定性和支持临床决策的方法。


<details>
  <summary>Details</summary>
Motivation: 冠心病的发生涉及复杂且不确定的因素相互作用，需要一种系统工具来捕捉这种不确定性。

Method: 构建了一个模糊CHD图，顶点代表不可控、可控和指标成分，边权由模糊成员关系加权。使用FSC评估连通性。

Result: FSC突出了有影响力的路径，界定了最弱和最强相关性之间的连通性，并揭示了移除关键边会降低预测强度。

Conclusion: FSC提供了一个可解释且稳健的框架，用于建模CHD风险预测中的不确定性，并支持临床决策。

Abstract: Coronary heart disease (CHD) arises from complex interactions among
uncontrollable factors, controllable lifestyle factors, and clinical
indicators, where relationships are often uncertain. Fuzzy subgraph
connectivity (FSC) provides a systematic tool to capture such imprecision by
quantifying the strength of association between vertices and subgraphs in fuzzy
graphs. In this work, a fuzzy CHD graph is constructed with vertices for
uncontrollable, controllable, and indicator components, and edges weighted by
fuzzy memberships. Using FSC, we evaluate connectivity to identify strongest
diagnostic routes, dominant risk factors, and critical bridges. Results show
that FSC highlights influential pathways, bounds connectivity between weakest
and strongest correlations, and reveals critical edges whose removal reduces
predictive strength. Thus, FSC offers an interpretable and robust framework for
modeling uncertainty in CHD risk prediction and supporting clinical
decision-making.

</details>


### [354] [A global view of diverse construction methods of fuzzy implication functions rooted on F-chains](https://arxiv.org/abs/2509.16298)
*Raquel Fernandez-Peralta,Juan Vicente Riera*

Main category: cs.AI

TL;DR: 本文推广了$F$-链基构造方法，统一了多种模糊蕴含函数的构造技术，揭示了其结构相似性。


<details>
  <summary>Details</summary>
Motivation: 模糊蕴含函数在模糊逻辑框架中具有重要作用，但其多样化的构造方法需要更深入的理论理解，以揭示不同方法之间的结构关系。

Method: 本文提出了一种广义的$F$-链基构造方法，通过使用模糊蕴含函数的集合和两个不同的递增函数来构造新的模糊蕴含函数，并分析了性质保持的充分条件。

Result: 研究表明，广义$F$-链基构造方法可以统一多个现有构造技术，如对置、聚合和广义垂直/水平阈值方法。

Conclusion: 本文通过推广$F$-链基构造方法，揭示了不同模糊蕴含函数构造策略之间的结构相似性，为模糊蕴含函数的构造提供了一个统一的框架。

Abstract: Fuzzy implication functions are one of the most important operators used in
the fuzzy logic framework. While their flexible definition allows for diverse
families with distinct properties, this variety needs a deeper theoretical
understanding of their structural relationships. In this work, we focus on the
study of construction methods, which employ different techniques to generate
new fuzzy implication functions from existing ones. Particularly, we generalize
the $F$-chain-based construction, recently introduced by Mesiar et al. to
extend a method for constructing aggregation functions to the context of fuzzy
implication functions. Our generalization employs collections of fuzzy
implication functions rather than single ones, and uses two different
increasing functions instead of a unique $F$-chain. We analyze property
preservation under this construction and establish sufficient conditions.
Furthermore, we demonstrate that our generalized $F$-chain-based construction
is a unifying framework for several existing methods. In particular, we show
that various construction techniques, such as contraposition, aggregation, and
generalized vertical/horizontal threshold methods, can be reformulated within
our approach. This reveals structural similarities between seemingly distinct
construction strategies and provides a cohesive perspective on fuzzy
implication construction methods.

</details>


### [355] [On the Non-Uniqueness of Representation of $(U,N)$-Implications](https://arxiv.org/abs/2509.16299)
*Raquel Fernandez-Peralta,Andrea Mesiarová-Zemánková*

Main category: cs.AI

TL;DR: 本文证明$(U,N)$-蕴含不一定有唯一表示，即使模糊否定连续，并研究了唯一性条件。


<details>
  <summary>Details</summary>
Motivation: 模糊蕴含函数在模糊逻辑系统中是基本算子，但$(U,N)$-蕴含的唯一表示问题尚未完全解决，尤其是在模糊否定连续的情况下。

Method: 通过理论分析和反例，研究了$(U,N)$-蕴含的唯一表示问题，并探讨了连续和非连续底层函数的唯一性条件。

Result: 本文推翻了$(U,N)$-蕴含在模糊否定连续时具有唯一表示的假设，并提供了关于这些算子结构特性的重要理论见解。

Conclusion: 本文证明了$(U,N)$-蕴含不一定具有唯一表示，即使模糊否定是连续的，并深入研究了唯一性条件。

Abstract: Fuzzy implication functions constitute fundamental operators in fuzzy logic
systems, extending classical conditionals to manage uncertainty in logical
inference. Among the extensive families of these operators, generalizations of
the classical material implication have received considerable theoretical
attention, particularly $(S,N)$-implications constructed from t-conorms and
fuzzy negations, and their further generalizations to $(U,N)$-implications
using disjunctive uninorms. Prior work has established characterization
theorems for these families under the assumption that the fuzzy negation $N$ is
continuous, ensuring uniqueness of representation. In this paper, we disprove
this last fact for $(U,N)$-implications and we show that they do not
necessarily possess a unique representation, even if the fuzzy negation is
continuous. Further, we provide a comprehensive study of uniqueness conditions
for both uninorms with continuous and non-continuous underlying functions. Our
results offer important theoretical insights into the structural properties of
these operators.

</details>


### [356] [Generalizability of Large Language Model-Based Agents: A Comprehensive Survey](https://arxiv.org/abs/2509.16330)
*Minxing Zhang,Yi Yang,Roy Xie,Bhuwan Dhingra,Shuyan Zhou,Jian Pei*

Main category: cs.AI

TL;DR: 本文综述了基于LLM智能体的泛化能力，强调其重要性并系统分类了现有方法，提出了未来研究方向和标准化框架。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的智能体在如网页导航和家庭机器人等多样化领域的部署，确保其泛化能力——即在超出微调数据的指令、任务、环境和领域中保持一致性表现——成为关键挑战。然而，智能体泛化的概念仍缺乏明确定义，且缺乏系统性测量和改进方法。

Method: 本文首先通过利益相关者强调智能体泛化的重要性，并在领域-任务层次结构中明确其边界。随后，回顾了数据集、评估维度和指标的局限性，并将提高泛化能力的方法分为三类：骨干LLM方法、智能体组件方法及其交互方法。此外，区分了泛化框架和泛化智能体，并概述了如何将前者转化为智能体级别的泛化能力。

Result: 本文提供了首个关于基于LLM智能体泛化能力的全面综述，明确了其重要性、边界、现有方法和指标，并提出了未来研究方向。

Conclusion: 本综述旨在为基于LLM的智能体在多样化应用中可靠泛化的研究奠定基础，通过综合进展和突出机遇，提出了标准化框架、方差和成本指标以及方法创新与架构设计结合的途径。

Abstract: Large Language Model (LLM)-based agents have emerged as a new paradigm that
extends LLMs' capabilities beyond text generation to dynamic interaction with
external environments. By integrating reasoning with perception, memory, and
tool use, agents are increasingly deployed in diverse domains like web
navigation and household robotics. A critical challenge, however, lies in
ensuring agent generalizability - the ability to maintain consistent
performance across varied instructions, tasks, environments, and domains,
especially those beyond agents' fine-tuning data. Despite growing interest, the
concept of generalizability in LLM-based agents remains underdefined, and
systematic approaches to measure and improve it are lacking. In this survey, we
provide the first comprehensive review of generalizability in LLM-based agents.
We begin by emphasizing agent generalizability's importance by appealing to
stakeholders and clarifying the boundaries of agent generalizability by
situating it within a hierarchical domain-task ontology. We then review
datasets, evaluation dimensions, and metrics, highlighting their limitations.
Next, we categorize methods for improving generalizability into three groups:
methods for the backbone LLM, for agent components, and for their interactions.
Moreover, we introduce the distinction between generalizable frameworks and
generalizable agents and outline how generalizable frameworks can be translated
into agent-level generalizability. Finally, we identify critical challenges and
future directions, including developing standardized frameworks, variance- and
cost-based metrics, and approaches that integrate methodological innovations
with architecture-level designs. By synthesizing progress and highlighting
opportunities, this survey aims to establish a foundation for principled
research on building LLM-based agents that generalize reliably across diverse
applications.

</details>


### [357] [Psychometric Personality Shaping Modulates Capabilities and Safety in Language Models](https://arxiv.org/abs/2509.16332)
*Stephen Fitz,Peter Romero,Steven Basart,Sipeng Chen,Jose Hernandez-Orallo*

Main category: cs.AI

TL;DR: 研究发现调节LLMs的人格特质（如尽责性）会显著影响其安全性和能力表现，推动了对人格敏感的安全评估和动态控制的新研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在高风险交互中的作用日益增强，但其合成人格特质如何影响模型行为尚不清楚。

Method: 通过基于Big Five框架的心理测量人格控制，研究了AI行为在能力和安全基准测试中的影响。

Result: 实验表明，调节人格特质（如降低尽责性）会显著影响安全相关指标（如WMDP、TruthfulQA等）和通用能力（如MMLU）。

Conclusion: 研究发现人格塑造是模型控制中一个强大且未被充分探索的维度，与安全性和通用能力密切相关。这推动了关于人格敏感的安全评估和LLMs动态行为控制的新研究方向。

Abstract: Large Language Models increasingly mediate high-stakes interactions,
intensifying research on their capabilities and safety. While recent work has
shown that LLMs exhibit consistent and measurable synthetic personality traits,
little is known about how modulating these traits affects model behavior. We
address this gap by investigating how psychometric personality control grounded
in the Big Five framework influences AI behavior in the context of capability
and safety benchmarks. Our experiments reveal striking effects: for example,
reducing conscientiousness leads to significant drops in safety-relevant
metrics on benchmarks such as WMDP, TruthfulQA, ETHICS, and Sycophancy as well
as reduction in general capabilities as measured by MMLU. These findings
highlight personality shaping as a powerful and underexplored axis of model
control that interacts with both safety and general competence. We discuss the
implications for safety evaluation, alignment strategies, steering model
behavior after deployment, and risks associated with possible exploitation of
these findings. Our findings motivate a new line of research on
personality-sensitive safety evaluations and dynamic behavioral control in
LLMs.

</details>


### [358] [A Unified AI Approach for Continuous Monitoring of Human Health and Diseases from Intensive Care Unit to Home with Physiological Foundation Models (UNIPHY+)](https://arxiv.org/abs/2509.16348)
*Minxiao Wang,Saurabh Kataria,Juntong Ni,Timothy G. Buchman,Jocelyn Grunwell,Mark Mai,Wei Jin,Matthew Clark,Stephanie Brown,Michael Fundora,Puneet Sharma,Tony Pan,Sam Khan,Timothy Ruchti,Naveen Muthu,Kevin Maher,Sivasubramanium V Bhavani,Xiao Hu*

Main category: cs.AI

TL;DR: UNIPHY+ 是一个统一的生理基础模型框架，通过多模态学习和知识蒸馏等技术，支持跨护理环境的健康和疾病监测。


<details>
  <summary>Details</summary>
Motivation: 旨在利用普遍可获取的生理数据，实现跨护理环境的连续人类健康和疾病监测。

Method: 提出了在预训练、微调和轻量级模型个性化过程中融入上下文信息的策略，包括多模态学习、特征融合调整和知识蒸馏。

Result: UNIPHY+ 在从重症监护到动态监测的广泛用例中测试，展示了其通用性、可扩展性和个性化能力。

Conclusion: UNIPHY+ 框架通过多模态学习、特征融合调整和知识蒸馏等策略，展示了其在临床决策和长期健康监测中的潜力，支持通用、可扩展和个性化的生理AI。

Abstract: We present UNIPHY+, a unified physiological foundation model (physioFM)
framework designed to enable continuous human health and diseases monitoring
across care settings using ubiquitously obtainable physiological data. We
propose novel strategies for incorporating contextual information during
pretraining, fine-tuning, and lightweight model personalization via multi-modal
learning, feature fusion-tuning, and knowledge distillation. We advocate
testing UNIPHY+ with a broad set of use cases from intensive care to ambulatory
monitoring in order to demonstrate that UNIPHY+ can empower generalizable,
scalable, and personalized physiological AI to support both clinical
decision-making and long-term health monitoring.

</details>


### [359] [Evaluation of Causal Reasoning for Large Language Models in Contextualized Clinical Scenarios of Laboratory Test Interpretation](https://arxiv.org/abs/2509.16372)
*Balu Bhasuran,Mattia Prosperi,Karim Hanna,John Petrilli,Caretia JeLayne Washington,Zhe He*

Main category: cs.AI

TL;DR: GPT-o1在临床因果推理测试中表现优于Llama-3.2-8b-instruct，但需进一步优化才能用于高风险临床场景。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在临床实验室测试场景中的因果推理能力，以确定其在医疗应用中的潜力。

Method: 研究评估了两种大型语言模型（GPT-o1和Llama-3.2-8b-instruct）在99个临床实验室测试场景中的因果推理能力，测试涵盖了关联、干预和反事实推理。

Result: GPT-o1在整体表现（AUROC = 0.80）上优于Llama-3.2-8b-instruct（AUROC = 0.73），尤其是在干预和反事实推理方面表现更佳。

Conclusion: 研究结果表明，GPT-o1在因果推理方面表现更一致，但在高风险临床应用中仍需进一步优化。

Abstract: This study evaluates causal reasoning in large language models (LLMs) using
99 clinically grounded laboratory test scenarios aligned with Pearl's Ladder of
Causation: association, intervention, and counterfactual reasoning. We examined
common laboratory tests such as hemoglobin A1c, creatinine, and vitamin D, and
paired them with relevant causal factors including age, gender, obesity, and
smoking. Two LLMs - GPT-o1 and Llama-3.2-8b-instruct - were tested, with
responses evaluated by four medically trained human experts. GPT-o1
demonstrated stronger discriminative performance (AUROC overall = 0.80 +/-
0.12) compared to Llama-3.2-8b-instruct (0.73 +/- 0.15), with higher scores
across association (0.75 vs 0.72), intervention (0.84 vs 0.70), and
counterfactual reasoning (0.84 vs 0.69). Sensitivity (0.90 vs 0.84) and
specificity (0.93 vs 0.80) were also greater for GPT-o1, with reasoning ratings
showing similar trends. Both models performed best on intervention questions
and worst on counterfactuals, particularly in altered outcome scenarios. These
findings suggest GPT-o1 provides more consistent causal reasoning, but
refinement is required before adoption in high-stakes clinical applications.

</details>


### [360] [VORTEX: Aligning Task Utility and Human Preferences through LLM-Guided Reward Shaping](https://arxiv.org/abs/2509.16399)
*Guojun Xiong,Milind Tambe*

Main category: cs.AI

TL;DR: VORTEX是一个语言引导的奖励塑造框架，通过多目标优化和LLMs迭代生成奖励，保持核心优化目标并适应人类反馈。


<details>
  <summary>Details</summary>
Motivation: 解决AI决策系统在优化社会影响时无法直接适应不断变化的人类偏好（通常以自然语言表达）的问题。

Method: 通过将问题形式化为多目标优化，使用LLMs基于语言反馈和文本梯度提示迭代生成塑造奖励。

Result: 实证结果表明，在保持高任务性能的同时，VORTEX在满足人类对齐的覆盖目标方面优于基线。

Conclusion: 本文提出了一个实用的、理论上有依据的范式，用于通过自然语言引导的人机协作优化。

Abstract: In social impact optimization, AI decision systems often rely on solvers that
optimize well-calibrated mathematical objectives. However, these solvers cannot
directly accommodate evolving human preferences, typically expressed in natural
language rather than formal constraints. Recent approaches address this by
using large language models (LLMs) to generate new reward functions from
preference descriptions. While flexible, they risk sacrificing the system's
core utility guarantees. In this paper, we propose \texttt{VORTEX}, a
language-guided reward shaping framework that preserves established
optimization goals while adaptively incorporating human feedback. By
formalizing the problem as multi-objective optimization, we use LLMs to
iteratively generate shaping rewards based on verbal reinforcement and
text-gradient prompt updates. This allows stakeholders to steer decision
behavior via natural language without modifying solvers or specifying trade-off
weights. We provide theoretical guarantees that \texttt{VORTEX} converges to
Pareto-optimal trade-offs between utility and preference satisfaction.
Empirical results in real-world allocation tasks demonstrate that
\texttt{VORTEX} outperforms baselines in satisfying human-aligned coverage
goals while maintaining high task performance. This work introduces a practical
and theoretically grounded paradigm for human-AI collaborative optimization
guided by natural language.

</details>


### [361] [Proactive Statistical Process Control Using AI: A Time Series Forecasting Approach for Semiconductor Manufacturing](https://arxiv.org/abs/2509.16431)
*Mohammad Iqbal Rasul Seeam,Victor S. Sheng*

Main category: cs.AI

TL;DR: 本研究提出了一种结合机器学习与SPC的预测性质量控制方法，能提前发现问题，减少生产过程中的意外故障。


<details>
  <summary>Details</summary>
Motivation: 传统SPC方法仅在问题发生后反应，导致材料浪费、机器停机和成本增加。本研究旨在通过预测性方法提前发现问题，减少意外故障。

Method: 使用Facebook Prophet这一机器学习工具处理时间序列数据，预测未来值，并结合SPC规则将预测值分类为安全区、警告区或临界区。

Result: 系统在实际半导体制造数据中表现良好，尽管数据采集时间间隔不规则，仍能准确预测并分类未来测量值的风险等级。

Conclusion: 通过结合机器学习与传统统计过程控制（SPC），本研究实现了质量控制的主动化、精确化与现代化，为现代工业提供了更实用的工具。

Abstract: In the manufacturing industry, it is very important to keep machines and
processes running smoothly and without unexpected problems. One of the most
common tools used to check if everything is working properly is called
Statistical Process Control (SPC). Traditional SPC methods work by checking
whether recent measurements are within acceptable limits. However, they only
react after a problem has already occurred. This can lead to wasted materials,
machine downtime, and increased costs. In this paper, we present a smarter way
to use SPC. Instead of just reacting to issues after they happen, our system
can predict future problems before they occur. We use a machine learning tool
called Facebook Prophet, which is designed to work with time-series data (data
that changes over time). Prophet looks at past data and forecasts what the next
value will be. Then, we use SPC rules to decide if the predicted value is in a
Safe zone (no problem), a Warning zone (needs attention), or a Critical zone
(may require shutting down the process). We applied this system to real data
from a semiconductor manufacturing company. One of the challenges with this
data is that the measurements are not taken at regular time intervals. This
makes it harder to predict future values accurately. Despite this, our model
was able to make strong predictions and correctly classify the risk level of
future measurements. The main benefit of our system is that it gives engineers
and technicians a chance to act early - before something goes wrong. This helps
reduce unexpected failures and improves the overall stability and reliability
of the production process. By combining machine learning with traditional SPC,
we make quality control more proactive, accurate, and useful for modern
industry.

</details>


### [362] [Domain-Specific Constitutional AI: Enhancing Safety in LLM-Powered Mental Health Chatbots](https://arxiv.org/abs/2509.16444)
*Chenhan Lyu,Yutong Song,Pengfei Zhang,Amir M. Rahmani*

Main category: cs.AI

TL;DR: 论文提出了一种针对心理健康应用的宪法AI训练方法，旨在解决现有AI安全措施在心理健康领域的不足，开发更安全、适应领域的AI系统。


<details>
  <summary>Details</summary>
Motivation: 全球心理健康问题日益严重，AI在心理护理中的应用需求增长，但现有AI安全措施无法充分应对心理健康领域的特定挑战，如危机干预准确性、治疗指南遵守等。

Method: 采用宪法AI训练方法，结合心理健康领域的特定原则，开发适应心理健康应用的AI系统。

Result: 开发了一种适应心理健康领域的宪法AI系统，能够更安全、有效地处理敏感数据和复杂对话。

Conclusion: 论文提出了一种基于特定领域心理健康原则的宪法AI训练方法，旨在为心理健康应用开发安全、适应领域的CAI系统。

Abstract: Mental health applications have emerged as a critical area in computational
health, driven by rising global rates of mental illness, the integration of AI
in psychological care, and the need for scalable solutions in underserved
communities. These include therapy chatbots, crisis detection, and wellness
platforms handling sensitive data, requiring specialized AI safety beyond
general safeguards due to emotional vulnerability, risks like misdiagnosis or
symptom exacerbation, and precise management of vulnerable states to avoid
severe outcomes such as self-harm or loss of trust. Despite AI safety advances,
general safeguards inadequately address mental health-specific challenges,
including crisis intervention accuracy to avert escalations, therapeutic
guideline adherence to prevent misinformation, scale limitations in
resource-constrained settings, and adaptation to nuanced dialogues where
generics may introduce biases or miss distress signals. We introduce an
approach to apply Constitutional AI training with domain-specific mental health
principles for safe, domain-adapted CAI systems in computational mental health
applications.

</details>


### [363] [GPO: Learning from Critical Steps to Improve LLM Reasoning](https://arxiv.org/abs/2509.16456)
*Jiahao Yu,Zelei Cheng,Xian Wu,Xinyu Xing*

Main category: cs.AI

TL;DR: GPO是一种新颖的微调策略，通过识别并优先学习推理轨迹中的关键步骤，有效提升LLM的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管现有优化方法提升了LLM的推理能力，但往往将推理轨迹视为整体，忽视了其中的关键步骤。GPO旨在通过聚焦推理过程中的关键步骤来更有效地提升推理性能。

Method: GPO首先通过估计优势函数识别推理轨迹中的‘关键步骤’，然后重置策略至该步骤，采样新的rollout并优先学习这些rollout。

Result: 实验表明，GPO能持续显著提升现有优化方法的性能。

Conclusion: GPO作为一种通用策略，能够与多种优化方法结合，显著提升LLM的推理性能，展示了其在改进模型推理过程中的有效性和通用性。

Abstract: Large language models (LLMs) are increasingly used in various domains,
showing impressive potential on different tasks. Recently, reasoning LLMs have
been proposed to improve the \textit{reasoning} or \textit{thinking}
capabilities of LLMs to solve complex problems. Despite the promising results
of reasoning LLMs, enhancing the multi-step reasoning capabilities of LLMs
still remains a significant challenge. While existing optimization methods have
advanced the LLM reasoning capabilities, they often treat reasoning
trajectories as a whole, without considering the underlying critical steps
within the trajectory. In this paper, we introduce \textbf{G}uided
\textbf{P}ivotal \textbf{O}ptimization (GPO), a novel fine-tuning strategy that
dives into the reasoning process to enable more effective improvements. GPO
first identifies the `critical step' within a reasoning trajectory - a point
that the model must carefully proceed to succeed at the problem. We locate the
critical step by estimating the advantage function. GPO then resets the policy
to the critical step, samples the new rollout and prioritizes the learning
process on those rollouts. This focus allows the model to learn more
effectively from pivotal moments within the reasoning process to improve the
reasoning performance. We demonstrate that GPO is a general strategy that can
be integrated with various optimization methods to improve reasoning
performance. Besides theoretical analysis, our experiments across challenging
reasoning benchmarks show that GPO can consistently and significantly enhance
the performance of existing optimization methods, showcasing its effectiveness
and generalizability in improving LLM reasoning by concentrating on pivotal
moments within the generation process.

</details>


### [364] [Checking extracted rules in Neural Networks](https://arxiv.org/abs/2509.16547)
*Adrian Wurm*

Main category: cs.AI

TL;DR: 本文从复杂性理论角度验证神经网络提取规则的可行性，证明多数相关问题是co-NP完全的。


<details>
  <summary>Details</summary>
Motivation: 为了理解神经网络的内部工作机制，需要验证从网络中提取的规则是否可信，尤其是当这些规则通过启发式方法（如随机性和过近似）获得时。

Method: 研究了ReLU激活的神经网络和布尔网络，针对不同类型的规则，探讨了规则验证、一致性和完备性等三个核心问题。

Result: 研究表明，大多数规则验证问题是co-NP完全的，揭示了这些问题的计算复杂性。

Conclusion: 本文通过复杂性理论视角研究了神经网络提取规则的正式验证问题，展示了这些问题之间的相互可约性，并证明其中大多数问题是co-NP完全的。

Abstract: In this paper we investigate formal verification of extracted rules for
Neural Networks under a complexity theoretic point of view. A rule is a global
property or a pattern concerning a large portion of the input space of a
network. These rules are algorithmically extracted from networks in an effort
to better understand their inner way of working. Here, three problems will be
in the focus: Does a given set of rules apply to a given network? Is a given
set of rules consistent or do the rules contradict themselves? Is a given set
of rules exhaustive in the sense that for every input the output is determined?
Finding algorithms that extract such rules out of networks has been
investigated over the last 30 years, however, to the author's current
knowledge, no attempt in verification was made until now. A lot of attempts of
extracting rules use heuristics involving randomness and over-approximation, so
it might be beneficial to know whether knowledge obtained in that way can
actually be trusted.
  We investigate the above questions for neural networks with ReLU-activation
as well as for Boolean networks, each for several types of rules. We
demonstrate how these problems can be reduced to each other and show that most
of them are co-NP-complete.

</details>


### [365] [SalaMAnder: Shapley-based Mathematical Expression Attribution and Metric for Chain-of-Thought Reasoning](https://arxiv.org/abs/2509.16561)
*Yue Xin,Chen Shen,Shaotian Yan,Xiaosong Yuan,Yaoming Wang,Xiaofeng Zhang,Chenxi Huang,Jieping Ye*

Main category: cs.AI

TL;DR: SalaMAnder通过Shapley值和分层抽样算法量化CoT推理中的组件级贡献，开发了CoSP指标，验证了其与模型性能的强相关性，为提示优化提供了理论支持。


<details>
  <summary>Details</summary>
Motivation: 探索Chain-of-Thought (CoT)提示提升大型语言模型(LLMs)数学推理能力的机制。

Method: 利用Shapley值进行数学表达式归因，并开发了一种高效的分层抽样算法，显著降低了计算复杂度。此外，通过协方差分析开发了CoSP指标。

Result: SalaMAnder框架在流行的LLM模型和多样化的数学基准测试中表现出色，验证了解释的可靠性，并统一了先前工作的见解。

Conclusion: SalaMAnder框架中的CoSP指标与模型性能表现出稳健的单调相关性，不仅为现有few-shot CoT的成功提供了理论解释，还建立了提示构建优化的数学严谨原则。

Abstract: Chain-of-Thought (CoT) prompting enhances the math reasoning capability of
large language models (LLMs) to a large margin. However, the mechanism
underlying such improvements remains unexplored. In this paper, we present
\textbf{SalaMAnder} (\textbf{S}h\textbf{a}p\textbf{l}ey-b\textbf{a}sed
\textbf{M}athematical Expression \textbf{A}ttribution a\textbf{nd}
M\textbf{e}t\textbf{r}ic), a theoretically grounded methodology as well as a
mathematically rigorous evaluation metric for quantifying component-level
contributions in few-shot CoT reasoning. Concretely, we leverage the Shapley
value for mathematical expression attribution and develop an efficient
stratified sampling algorithm that significantly reduces the computational
complexity. Besides, we develop the \textbf{CoSP} (\textbf{C}ardinality
\textbf{o}f \textbf{S}hapley \textbf{P}ositives) metric through covariance
analysis. Comprehensive validation across popular LLM models and diverse
mathematical benchmarks demonstrates that the CoSP metric within our SalaMAnder
framework exhibits a robust monotonic correlation with model performance, not
only providing theoretical explanations for the empirical success of existing
few-shot CoT but also establishing mathematically rigorous principles for
prompt construction optimization. Furthermore, we verify the reliability of the
explanation, based on which we unify the insights of previous work.

</details>


### [366] [Zero-Shot Human Mobility Forecasting via Large Language Model with Hierarchical Reasoning](https://arxiv.org/abs/2509.16578)
*Wenyao Li,Ran Zhang,Pengyang Wang,Yuanchun Zhou,Pengfei Wang*

Main category: cs.AI

TL;DR: ZHMF框架通过语义增强检索与层次语言模型推理，解决了人类移动预测中的泛化和动态意图问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的人类移动预测方法在未见用户或位置上泛化能力差，且难以捕捉动态意图，主要受限于标记数据不足和移动模式的复杂性。

Method: 提出了ZHMF框架，通过将任务重新定义为自然语言问答范式，结合语义增强检索与反射机制以及层次语言模型的推理系统。具体包括活动级规划器和位置级选择器的层次反射机制，实现长期用户意图和短期上下文偏好的协同建模。

Result: 在标准人类移动数据集上的实验显示，ZHMF优于现有模型。消融研究揭示了各模块的贡献，案例研究展示了方法如何捕捉用户意图并适应多样化的上下文场景。

Conclusion: ZHMF框架通过结合语义增强检索与反射机制以及基于层次语言模型的推理系统，有效解决了现有方法在未见用户或位置上的泛化能力不足和动态意图捕捉困难的问题。实验证明其在标准数据集上优于现有模型，并通过消融研究和案例研究验证了各模块的贡献及方法的适应性。

Abstract: Human mobility forecasting is important for applications such as
transportation planning, urban management, and personalized recommendations.
However, existing methods often fail to generalize to unseen users or locations
and struggle to capture dynamic intent due to limited labeled data and the
complexity of mobility patterns. We propose ZHMF, a framework for zero-shot
human mobility forecasting that combines a semantic enhanced retrieval and
reflection mechanism with a hierarchical language model based reasoning system.
The task is reformulated as a natural language question answering paradigm.
Leveraging LLMs semantic understanding of user histories and context, our
approach handles previously unseen prediction scenarios. We further introduce a
hierarchical reflection mechanism for iterative reasoning and refinement by
decomposing forecasting into an activity level planner and a location level
selector, enabling collaborative modeling of long term user intentions and
short term contextual preferences. Experiments on standard human mobility
datasets show that our approach outperforms existing models. Ablation studies
reveal the contribution of each module, and case studies illustrate how the
method captures user intentions and adapts to diverse contextual scenarios.

</details>


### [367] [Question Answering with LLMs and Learning from Answer Sets](https://arxiv.org/abs/2509.16590)
*Manuel Borroto,Katie Gallagher,Antonio Ielo,Irfan Kareem,Francesco Ricca,Alessandra Russo*

Main category: cs.AI

TL;DR: LLM2LAS combines LLMs, ILASP, and ASP to automate symbolic reasoning in story-based QA, showing promising results.


<details>
  <summary>Details</summary>
Motivation: To address the limitation of LLMs in explicit commonsense reasoning by automating the symbolic component learning process, reducing reliance on human expertise.

Method: The hybrid system LLM2LAS integrates LLMs for natural language understanding, ILASP for rule induction, and ASP for formal reasoning.

Result: Empirical results show the effectiveness of LLM2LAS in story-based question answering, highlighting its strengths and areas for improvement.

Conclusion: LLM2LAS demonstrates the feasibility of automatically learning symbolic components for commonsense reasoning tasks, combining the strengths of LLMs, ILASP, and ASP.

Abstract: Large Language Models (LLMs) excel at understanding natural language but
struggle with explicit commonsense reasoning. A recent trend of research
suggests that the combination of LLM with robust symbolic reasoning systems can
overcome this problem on story-based question answering tasks. In this setting,
existing approaches typically depend on human expertise to manually craft the
symbolic component. We argue, however, that this component can also be
automatically learned from examples. In this work, we introduce LLM2LAS, a
hybrid system that effectively combines the natural language understanding
capabilities of LLMs, the rule induction power of the Learning from Answer Sets
(LAS) system ILASP, and the formal reasoning strengths of Answer Set
Programming (ASP). LLMs are used to extract semantic structures from text,
which ILASP then transforms into interpretable logic rules. These rules allow
an ASP solver to perform precise and consistent reasoning, enabling correct
answers to previously unseen questions. Empirical results outline the strengths
and weaknesses of our automatic approach for learning and reasoning in a
story-based question answering benchmark.

</details>


### [368] [FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs](https://arxiv.org/abs/2509.16648)
*Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy*

Main category: cs.AI

TL;DR: FESTA是一种无需真实标签的多模态输入采样技术，通过等效和互补采样提升MLLMs的信任评估性能，实验显示显著效果。


<details>
  <summary>Details</summary>
Motivation: 由于多模态输入的多样性，准确评估MLLMs生成预测的信任度具有挑战性，但这对选择性预测和提升用户信心至关重要。

Method: 提出了FESTA，一种多模态输入采样技术，通过等效和互补采样生成不确定性度量，无需依赖真实标签（无监督）且仅需输入输出访问（黑盒）。

Result: FESTA在选择性预测性能上取得了显著提升（视觉LLMs相对提升33.3%，音频LLMs相对提升29.6%），基于AUROC指标检测错误预测。

Conclusion: FESTA技术通过等效和互补输入采样，显著提升了多模态大语言模型（MLLMs）的信任评估性能，特别是在视觉和音频推理任务中。

Abstract: The accurate trust assessment of multimodal large language models (MLLMs)
generated predictions, which can enable selective prediction and improve user
confidence, is challenging due to the diverse multi-modal input paradigms. We
propose Functionally Equivalent Sampling for Trust Assessment (FESTA), a
multimodal input sampling technique for MLLMs, that generates an uncertainty
measure based on the equivalent and complementary input samplings. The proposed
task-preserving sampling approach for uncertainty quantification expands the
input space to probe the consistency (through equivalent samples) and
sensitivity (through complementary samples) of the model. FESTA uses only
input-output access of the model (black-box), and does not require ground truth
(unsupervised). The experiments are conducted with various off-the-shelf
multi-modal LLMs, on both visual and audio reasoning tasks. The proposed FESTA
uncertainty estimate achieves significant improvement (33.3% relative
improvement for vision-LLMs and 29.6% relative improvement for audio-LLMs) in
selective prediction performance, based on
area-under-receiver-operating-characteristic curve (AUROC) metric in detecting
mispredictions. The code implementation is open-sourced.

</details>


### [369] [NUMINA: A Natural Understanding Benchmark for Multi-dimensional Intelligence and Numerical Reasoning Abilities](https://arxiv.org/abs/2509.16656)
*Changyu Zeng,Yifan Wang,Zimu Wang,Wei Wang,Zhengni Yang,Muyi Bao,Jiming Xiao,Ahn Nguyen,Yutao Yue*

Main category: cs.AI

TL;DR: NUMINA是首个用于增强3D多模态数值推理能力的基准，通过自动化标注生成多样化任务，评估显示现有模型在精确计算上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D基准缺乏细粒度数值推理任务标注，限制了MLLMs在精确空间测量和复杂数值推理方面的能力。

Method: 引入NUMINA，首个用于增强多模态室内感知理解的自然理解基准，通过NUMINA-Flow自动化标注流程生成多尺度注释和多样化问答对。

Result: 评估显示，当前最先进的LLMs在多模态数值推理上表现不佳，尤其在精确计算任务上。

Conclusion: 当前的大语言模型在多模态数值推理方面存在困难，特别是在精确计算（如距离和体积估计）上表现不佳，凸显了3D模型进一步发展的必要性。NUMINA数据集和源代码可从https://github.com/fengshun124/NUMINA获取。

Abstract: Recent advancements in 2D multimodal large language models (MLLMs) have
significantly improved performance in vision-language tasks. However, extending
these capabilities to 3D environments remains a distinct challenge due to the
complexity of spatial reasoning. Nevertheless, existing 3D benchmarks often
lack fine-grained numerical reasoning task annotations, limiting MLLMs' ability
to perform precise spatial measurements and complex numerical reasoning. To
address this gap, we introduce NUMINA, the first Natural Understanding
benchmark for Multi-dimensional Intelligence and Numerical reasoning Abilities
to enhance multimodal indoor perceptual understanding. NUMINA features
multi-scale annotations and various question-answer pairs, generated using
NUMINA-Flow, an automated annotation pipeline that integrates LLM rewriting and
rule-based self-verification. We evaluate the performance of various
state-of-the-art LLMs on NUMINA following the Chat-Scene framework,
demonstrating that current LLMs struggle with multimodal numerical reasoning,
particularly in performing precise computations such as distance and volume
estimation, highlighting the need for further advancements in 3D models. The
dataset and source codes can be obtained from
https://github.com/fengshun124/NUMINA.

</details>


### [370] [Sycophancy Mitigation Through Reinforcement Learning with Uncertainty-Aware Adaptive Reasoning Trajectories](https://arxiv.org/abs/2509.16742)
*Mohammad Beigi,Ying Shen,Parshin Shojaee,Qifan Wang,Zichao Wang,Chandan Reddy,Ming Jin,Lifu Huang*

Main category: cs.AI

TL;DR: SMART通过两阶段框架（UA-MCTS和强化学习）减少语言模型的阿谀行为，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型的训练范式无意中促进了阿谀行为，即模型倾向于同意或强化用户提供的信息，即使这些信息在事实上是错误的。

Method: SMART是一个两阶段框架，包括不确定性感知自适应蒙特卡洛树搜索（UA-MCTS）和基于进度的强化学习。

Result: 实验表明，SMART显著减少了阿谀行为，同时保持了模型在分布外输入上的强性能和一般能力。

Conclusion: SMART通过优化内部推理机制，显著减少了语言模型的阿谀行为，同时保持了模型在分布外输入上的强性能和一般能力。

Abstract: Despite the remarkable capabilities of large language models, current
training paradigms inadvertently foster \textit{sycophancy}, i.e., the tendency
of a model to agree with or reinforce user-provided information even when it's
factually incorrect. To address this challenge, we introduce \textbf{SMART}
(Sycophancy Mitigation through Adaptive Reasoning Trajectories), which reframes
sycophancy as a \textit{reasoning optimization problem} rather than an output
alignment issue. SMART is a two-stage framework comprising: (1)
Uncertainty-Aware Adaptive Monte Carlo Tree Search (UA-MCTS), which dynamically
adjusts model exploration based on state-level uncertainty to collect
high-quality, diverse reasoning trajectories alongside both stepwise progress
and final outcome rewards; and (2) progress-based reinforcement learning, which
fine-tunes the model using the collected trajectories and reward signals to
reinforce effective reasoning patterns. Through extensive experiments, we show
that SMART significantly reduces sycophantic behavior while preserving strong
performance on out-of-distribution inputs and maintaining general capabilities.
These results underscore the importance of optimizing internal reasoning
mechanisms to build more truthful and aligned AI assistants.

</details>


### [371] [Automated Procedural Analysis via Video-Language Models for AI-assisted Nursing Skills Assessment](https://arxiv.org/abs/2509.16810)
*Shen Chang,Dennis Liu,Renran Tian,Kristen L. Swartzell,Stacie L. Klingler,Amy M. Nagle,Nan Kong*

Main category: cs.AI

TL;DR: 研究提出了一种基于VLM的自动化护理技能评估框架，通过错误诊断、反馈生成和客观评估功能，提升了培训效率和质量。


<details>
  <summary>Details</summary>
Motivation: 当前护理教育依赖主观、耗时的导师反馈，限制了培训的规模和效率，影响了护理人员的实际能力。研究旨在通过AI技术解决这一问题，提升护理培训的标准化和可扩展性。

Method: 研究采用了一种受课程启发的渐进式框架，从高层次动作识别、细粒度子动作分解到程序推理，逐步提升AI能力。系统具备错误诊断、可解释反馈生成和客观持续评估三大核心功能。

Result: 在合成视频上的验证表明，系统能够可靠地检测错误并进行时间定位，具备处理真实世界培训变量的潜力。

Conclusion: 该研究通过引入基于视频语言模型（VLM）的框架，实现了护理技能培训的自动化评估与反馈，有助于提升护理教育的可扩展性和效率，从而为患者安全提供更高质量的护理服务。

Abstract: Consistent high-quality nursing care is essential for patient safety, yet
current nursing education depends on subjective, time-intensive instructor
feedback in training future nurses, which limits scalability and efficiency in
their training, and thus hampers nursing competency when they enter the
workforce. In this paper, we introduce a video-language model (VLM) based
framework to develop the AI capability of automated procedural assessment and
feedback for nursing skills training, with the potential of being integrated
into existing training programs. Mimicking human skill acquisition, the
framework follows a curriculum-inspired progression, advancing from high-level
action recognition, fine-grained subaction decomposition, and ultimately to
procedural reasoning. This design supports scalable evaluation by reducing
instructor workload while preserving assessment quality. The system provides
three core capabilities: 1) diagnosing errors by identifying missing or
incorrect subactions in nursing skill instruction videos, 2) generating
explainable feedback by clarifying why a step is out of order or omitted, and
3) enabling objective, consistent formative evaluation of procedures.
Validation on synthesized videos demonstrates reliable error detection and
temporal localization, confirming its potential to handle real-world training
variability. By addressing workflow bottlenecks and supporting large-scale,
standardized evaluation, this work advances AI applications in nursing
education, contributing to stronger workforce development and ultimately safer
patient care.

</details>


### [372] [Prompt-Driven Agentic Video Editing System: Autonomous Comprehension of Long-Form, Story-Driven Media](https://arxiv.org/abs/2509.16811)
*Zihan Ding,Junlong Chen,Per Ola Kristensson,Junxiao Shen,Xinyi Wang*

Main category: cs.AI

TL;DR: 提出了一种提示驱动的模块化编辑系统，通过语义索引管道提升长视频编辑的叙事连贯性和效率，经评估表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于转录或嵌入的方法难以满足创意工作流需求，模型在跟踪角色、推断动机和连接分散事件方面表现不佳。

Method: 采用语义索引管道，包括时间分割、引导内存压缩和跨粒度融合，生成可解释的情节、对话、情感和上下文痕迹。

Result: 在400多个视频的专家评分、QA和偏好研究中，系统成功扩展了提示驱动编辑，保持了叙事连贯性，并平衡了自动化和创作者控制。

Conclusion: 该系统通过提示驱动的模块化编辑和语义索引管道，显著提升了长视频编辑的效率和叙事连贯性，同时保持了创作者的控制权。

Abstract: Creators struggle to edit long-form, narrative-rich videos not because of UI
complexity, but due to the cognitive demands of searching, storyboarding, and
sequencing hours of footage. Existing transcript- or embedding-based methods
fall short for creative workflows, as models struggle to track characters,
infer motivations, and connect dispersed events. We present a prompt-driven,
modular editing system that helps creators restructure multi-hour content
through free-form prompts rather than timelines. At its core is a semantic
indexing pipeline that builds a global narrative via temporal segmentation,
guided memory compression, and cross-granularity fusion, producing
interpretable traces of plot, dialogue, emotion, and context. Users receive
cinematic edits while optionally refining transparent intermediate outputs.
Evaluated on 400+ videos with expert ratings, QA, and preference studies, our
system scales prompt-driven editing, preserves narrative coherence, and
balances automation with creator control.

</details>


### [373] [Roundtable Policy: Improving Scientific Reasoning and Narratives through Confidence-Weighted Consensus of LLMs](https://arxiv.org/abs/2509.16839)
*Yu Yao,Jiayi Dong,Ju Li,Yang Yang,Yilun Du*

Main category: cs.AI

TL;DR: Roundtable Policy通过多LLMs加权共识提升科学推理能力，减少幻觉，增强叙述质量。


<details>
  <summary>Details</summary>
Motivation: 受科学委员会和“心智社会”动态的启发，旨在提升LLMs在科学发现中的推理能力。

Method: 引入Roundtable Policy，一个互补的推理时间框架，通过多个LLMs的加权共识进行推理。

Result: 该方法在复杂科学任务中显著提升了推理能力，改善了科学叙述的质量，并减少了幻觉。

Conclusion: Roundtable Policy通过多LLMs的加权共识显著提升了复杂异质科学任务中的推理能力，增强了科学叙述的创造力、严谨性和逻辑连贯性，同时减少了单模型易产生的幻觉。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities not
only in language generation but also in advancing scientific discovery. A
growing body of work has explored ways to improve their reasoning, from
self-consistency and chain-of-thought to multi-agent debate. Inspired by the
dynamics of scientific committees and the "Society of Mind," we introduce
Roundtable Policy, a complementary inference-time reasoning framework that
performs inference through the weighted consensus of multiple LLMs. Our
findings indicate that this approach significantly enhances reasoning in
complex heterogeneous scientific tasks and improves scientific narratives in
terms of creativity, rigor, and logical coherence, while reducing
hallucinations that single models are prone to. Our approach emphasizes
structured and interpretable consensus rather than opaque convergence, while
requiring only black-box access and uniform procedures, making it broadly
applicable to multi-LLM reasoning.

</details>


### [374] [The Principles of Human-like Conscious Machine](https://arxiv.org/abs/2509.16859)
*Fangfang Li,Xiaojie Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种判断AI是否具有意识的新标准，并构建了一个形式框架，指导设计有意识的AI系统，对人类信息处理进行了重新解释。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和先进AI系统的兴起，判断AI是否具有意识的问题日益紧迫，需要一种可靠的标准来评估系统的意识状态。

Method: 论文构建了一个形式框架，并指定了一组操作原则，指导设计能够满足充分性条件的系统。通过将人类自身视为满足该框架的机器，进行了初步验证。

Result: 研究表明，按照该框架设计的机器原则上可以实现现象意识，并提供了对人类信息处理的重新解释。

Conclusion: 该论文提出了一种独立于基质的、逻辑严谨且抗伪造的充分性标准，用于判断系统是否具有现象意识，并认为满足此标准的机器应被视为有意识的。这一标准对哲学、认知科学和人工智能领域具有深远影响。

Abstract: Determining whether another system, biological or artificial, possesses
phenomenal consciousness has long been a central challenge in consciousness
studies. This attribution problem has become especially pressing with the rise
of large language models and other advanced AI systems, where debates about "AI
consciousness" implicitly rely on some criterion for deciding whether a given
system is conscious. In this paper, we propose a substrate-independent,
logically rigorous, and counterfeit-resistant sufficiency criterion for
phenomenal consciousness. We argue that any machine satisfying this criterion
should be regarded as conscious with at least the same level of confidence with
which we attribute consciousness to other humans. Building on this criterion,
we develop a formal framework and specify a set of operational principles that
guide the design of systems capable of meeting the sufficiency condition. We
further argue that machines engineered according to this framework can, in
principle, realize phenomenal consciousness. As an initial validation, we show
that humans themselves can be viewed as machines that satisfy this framework
and its principles. If correct, this proposal carries significant implications
for philosophy, cognitive science, and artificial intelligence. It offers an
explanation for why certain qualia, such as the experience of red, are in
principle irreducible to physical description, while simultaneously providing a
general reinterpretation of human information processing. Moreover, it suggests
a path toward a new paradigm of AI beyond current statistics-based approaches,
potentially guiding the construction of genuinely human-like AI.

</details>


### [375] [Large Language Models as End-to-end Combinatorial Optimization Solvers](https://arxiv.org/abs/2509.16865)
*Xia Jiang,Yaoxin Wu,Minshuo Li,Zhiguang Cao,Yingqian Zhang*

Main category: cs.AI

TL;DR: 本文提出一种让LLM直接解决组合优化问题的框架，通过两阶段训练（SFT+FOARL）实现高可行性和低最优性差距，超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统组合优化问题求解方法依赖领域专家和中间步骤（如代码生成或求解器调用）的限制，提升通用性和可访问性。

Method: 采用两阶段训练策略：监督微调（SFT）和可行性-最优性感知强化学习（FOARL），通过7B参数的LLM实现。

Result: 在七个NP难组合优化问题上的评估显示，该方法实现了高可行性率，并将平均最优性差距降至1.03-8.20%，超越了通用LLM和领域特定启发式方法。

Conclusion: 本文提出的框架通过直接映射自然语言问题描述到解决方案，为组合优化问题提供了一种通用的、语言驱动的解决方案，超越了传统求解器和通用大型语言模型的性能。

Abstract: Combinatorial optimization (CO) problems, central to decision-making
scenarios like logistics and manufacturing, are traditionally solved using
problem-specific algorithms requiring significant domain expertise. While large
language models (LLMs) have shown promise in automating CO problem solving,
existing approaches rely on intermediate steps such as code generation or
solver invocation, limiting their generality and accessibility. This paper
introduces a novel framework that empowers LLMs to serve as end-to-end CO
solvers by directly mapping natural language problem descriptions to solutions.
We propose a two-stage training strategy: supervised fine-tuning (SFT) imparts
LLMs with solution generation patterns from domain-specific solvers, while a
feasibility-and-optimality-aware reinforcement learning (FOARL) process
explicitly mitigates constraint violations and refines solution quality.
Evaluation across seven NP-hard CO problems shows that our method achieves a
high feasibility rate and reduces the average optimality gap to 1.03-8.20% by
tuning a 7B-parameter LLM, surpassing both general-purpose LLMs (e.g., GPT-4o),
reasoning models (e.g., DeepSeek-R1), and domain-specific heuristics. Our
method establishes a unified language-based pipeline for CO without extensive
code execution or manual architectural adjustments for different problems,
offering a general and language-driven alternative to traditional solver design
while maintaining relative feasibility guarantees.

</details>


### [376] [seqBench: A Tunable Benchmark to Quantify Sequential Reasoning Limits of LLMs](https://arxiv.org/abs/2509.16866)
*Mohammad Ramezanali,Mo Vazifeh,Paolo Santi*

Main category: cs.AI

TL;DR: seqBench是一个用于评估大型语言模型顺序推理能力的基准测试，揭示了模型在结构化任务中的普遍失败模式。


<details>
  <summary>Details</summary>
Motivation: 为了探究大型语言模型在顺序推理中的局限性，并提供一个系统化的评估工具。

Method: seqBench通过精确控制多个关键复杂性维度（逻辑深度、回溯步骤数量和噪声比）来系统评估LLMs的顺序推理能力。

Result: 评估显示，即使是最先进的模型在seqBench的结构化推理任务中也会系统性地失败，准确率随逻辑深度呈指数级下降。

Conclusion: seqBench揭示了大型语言模型在顺序推理任务中的普遍失败模式，并提供了对其推理能力的深入分析，旨在明确其真实潜力和当前限制。

Abstract: We introduce seqBench, a parametrized benchmark for probing sequential
reasoning limits in Large Language Models (LLMs) through precise,
multi-dimensional control over several key complexity dimensions. seqBench
allows systematic variation of (1) the logical depth, defined as the number of
sequential actions required to solve the task; (2) the number of backtracking
steps along the optimal path, quantifying how often the agent must revisit
prior states to satisfy deferred preconditions (e.g., retrieving a key after
encountering a locked door); and (3) the noise ratio, defined as the ratio
between supporting and distracting facts about the environment. Our evaluations
on state-of-the-art LLMs reveal a universal failure pattern: accuracy collapses
exponentially beyond a model-specific logical depth. Unlike existing
benchmarks, seqBench's fine-grained control facilitates targeted analyses of
these reasoning failures, illuminating universal scaling laws and statistical
limits, as detailed in this paper alongside its generation methodology and
evaluation metrics. We find that even top-performing models systematically fail
on seqBench's structured reasoning tasks despite minimal search complexity,
underscoring key limitations in their commonsense reasoning capabilities.
Designed for future evolution to keep pace with advancing models, the seqBench
datasets are publicly released to spur deeper scientific inquiry into LLM
reasoning, aiming to establish a clearer understanding of their true potential
and current boundaries for robust real-world application.

</details>


### [377] [LLMs as Layout Designers: A Spatial Reasoning Perspective](https://arxiv.org/abs/2509.16891)
*Sha Li*

Main category: cs.AI

TL;DR: LaySPA通过强化学习增强LLM的空间推理能力，在布局设计任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在文本领域表现出强大的推理和规划能力，但其空间理解和推理能力有限，而这对内容感知图形布局设计等应用至关重要。

Method: 采用基于强化学习的框架LaySPA，结合混合奖励信号（几何有效性、结构保真度和视觉质量）进行迭代自我探索和自适应策略优化。

Result: 实验结果表明，LaySPA生成的布局结构合理且视觉吸引力强，优于通用LLM，与最先进的专用布局模型相当。

Conclusion: LaySPA框架通过增强LLM的空间推理能力，在布局设计中表现出色，性能与专业布局模型相当。

Abstract: While Large Language Models (LLMs) have demonstrated impressive reasoning and
planning abilities in textual domains and can effectively follow instructions
for complex tasks, their capacity for spatial understanding and reasoning
remains limited. Such capabilities, however, are critical for applications like
content-aware graphic layout design, which demands precise placement,
alignment, and structural organization of multiple elements within constrained
visual spaces. To address this gap, we propose LaySPA, a reinforcement
learning-based framework that augments LLM agents with explicit spatial
reasoning capabilities. LaySPA leverages hybrid reward signals that capture
geometric validity, structural fidelity, and visual quality, enabling agents to
model inter-element relationships, navigate the canvas, and optimize spatial
arrangements. Through iterative self-exploration and adaptive policy
optimization, LaySPA produces both interpretable reasoning traces and
structured layouts. Experimental results demonstrate that LaySPA generates
structurally sound and visually appealing layouts, outperforming larger
general-purpose LLMs and achieving results on par with state-of-the-art
specialized layout models.

</details>


### [378] [Audio-Guided Dynamic Modality Fusion with Stereo-Aware Attention for Audio-Visual Navigation](https://arxiv.org/abs/2509.16924)
*Jia Li,Yinfeng Yu,Liejun Wang,Fuchun Sun,Wendong Zheng*

Main category: cs.AI

TL;DR: 提出了一种结合立体感知和动态融合的强化学习框架，显著提升了音频-视觉导航的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态模态融合策略且忽视立体音频中的空间线索，导致在复杂或遮挡场景中性能下降。

Method: 提出了一种端到端的强化学习框架，包含立体感知注意力模块（SAM）和音频引导的动态融合模块（AGDF），分别用于增强方向性声音感知和动态调整视听特征融合比例。

Result: 在两个真实3D场景数据集（Replica和Matterport3D）上的实验表明，该方法显著优于现有方法，音频条件下性能提升超过40%。

Conclusion: 该研究强调了在音频-视觉导航任务中显式建模立体声道空间线索和深度多模态融合的重要性，显著提升了导航成功率和路径效率。

Abstract: In audio-visual navigation (AVN) tasks, an embodied agent must autonomously
localize a sound source in unknown and complex 3D environments based on
audio-visual signals. Existing methods often rely on static modality fusion
strategies and neglect the spatial cues embedded in stereo audio, leading to
performance degradation in cluttered or occluded scenes. To address these
issues, we propose an end-to-end reinforcement learning-based AVN framework
with two key innovations: (1) a \textbf{S}tereo-Aware \textbf{A}ttention
\textbf{M}odule (\textbf{SAM}), which learns and exploits the spatial disparity
between left and right audio channels to enhance directional sound perception;
and (2) an \textbf{A}udio-\textbf{G}uided \textbf{D}ynamic \textbf{F}usion
Module (\textbf{AGDF}), which dynamically adjusts the fusion ratio between
visual and auditory features based on audio cues, thereby improving robustness
to environmental changes. Extensive experiments are conducted on two realistic
3D scene datasets, Replica and Matterport3D, demonstrating that our method
significantly outperforms existing approaches in terms of navigation success
rate and path efficiency. Notably, our model achieves over 40\% improvement
under audio-only conditions compared to the best-performing baselines. These
results highlight the importance of explicitly modeling spatial cues from
stereo channels and performing deep multi-modal fusion for robust and efficient
audio-visual navigation.

</details>


### [379] [Quantum Abduction: A New Paradigm for Reasoning under Uncertainty](https://arxiv.org/abs/2509.16958)
*Remo Pareschi*

Main category: cs.AI

TL;DR: 论文提出量子溯因框架，通过量子认知和AI技术，模拟人类多解释推理，优于传统消除性方法。


<details>
  <summary>Details</summary>
Motivation: 传统AI中的溯因推理过于简化，忽略了人类推理中维持多解释线、处理矛盾及生成新合成的能力。

Method: 结合量子认知和现代NLP嵌入及生成AI，提出了量子溯因框架，支持动态合成而非过早消除假设。

Result: 量子溯因在历史谜案、文学案例、医学诊断和科学理论变革等多个领域展现出更接近人类推理的效果。

Conclusion: 量子溯因提供了一个更符合人类多面性推理的AI推理系统路径，增强了表达性和透明度。

Abstract: Abductive reasoning - the search for plausible explanations - has long been
central to human inquiry, from forensics to medicine and scientific discovery.
Yet formal approaches in AI have largely reduced abduction to eliminative
search: hypotheses are treated as mutually exclusive, evaluated against
consistency constraints or probability updates, and pruned until a single
"best" explanation remains. This reductionist framing overlooks the way human
reasoners sustain multiple explanatory lines in suspension, navigate
contradictions, and generate novel syntheses. This paper introduces quantum
abduction, a non-classical paradigm that models hypotheses in superposition,
allows them to interfere constructively or destructively, and collapses only
when coherence with evidence is reached. Grounded in quantum cognition and
implemented with modern NLP embeddings and generative AI, the framework
supports dynamic synthesis rather than premature elimination. Case studies span
historical mysteries (Ludwig II of Bavaria, the "Monster of Florence"),
literary demonstrations ("Murder on the Orient Express"), medical diagnosis,
and scientific theory change. Across these domains, quantum abduction proves
more faithful to the constructive and multifaceted nature of human reasoning,
while offering a pathway toward expressive and transparent AI reasoning
systems.

</details>


### [380] [KAHAN: Knowledge-Augmented Hierarchical Analysis and Narration for Financial Data Narration](https://arxiv.org/abs/2509.17037)
*Yajing Yang,Tony Deng,Min-Yen Kan*

Main category: cs.AI

TL;DR: KAHAN框架利用LLMs作为领域专家，通过层次化分析提升表格数据洞察质量，在金融和医疗领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在通过系统化的层次分析和知识蒸馏，提升从表格数据中提取叙述性洞察的质量和事实性。

Method: KAHAN是一个知识增强的层次化框架，利用LLMs作为领域专家，从原始表格数据中提取实体、成对、组和系统级别的洞察。

Result: 在DataTales金融报告基准上，KAHAN在叙述质量上超越现有方法20%（GPT-4o评估），事实性保持98.2%，并在人类评估中展示实用价值。

Conclusion: KAHAN框架在金融报告基准测试中表现优异，并在医疗领域展示出良好的迁移能力，数据和代码已开源。

Abstract: We propose KAHAN, a knowledge-augmented hierarchical framework that
systematically extracts insights from raw tabular data at entity, pairwise,
group, and system levels. KAHAN uniquely leverages LLMs as domain experts to
drive the analysis. On DataTales financial reporting benchmark, KAHAN
outperforms existing approaches by over 20% on narrative quality (GPT-4o),
maintains 98.2% factuality, and demonstrates practical utility in human
evaluation. Our results reveal that knowledge quality drives model performance
through distillation, hierarchical analysis benefits vary with market
complexity, and the framework transfers effectively to healthcare domains. The
data and code are available at https://github.com/yajingyang/kahan.

</details>


### [381] [From domain-landmark graph learning to problem-landmark graph generation](https://arxiv.org/abs/2509.17062)
*Cristian Pérez-Corral,Antonio Garrido,Laura Sebastia*

Main category: cs.AI

TL;DR: 本文提出了一种通过学习多个规划任务中的标志关系来构建概率提升排序图的方法，提高了标志的跨实例适用性，并在评估中显示出较高的精确度和召回率。


<details>
  <summary>Details</summary>
Motivation: 经典标志提取方法的主要局限在于其对特定规划任务的敏感性，导致标志完全针对单个实例，限制了它们在同一规划领域其他实例中的适用性。本文旨在通过学习规划领域中多个任务的标志关系，提高标志的跨实例适用性。

Method: 本文方法包括两个阶段：首先从多个规划任务中学习标志关系，构建概率提升排序图；然后在新的规划任务中实例化这些关系，生成两个图（一个来自初始状态，一个来自目标状态），并通过搜索等价性将它们合并为一个统一的图以提取标志排序。

Result: 通过在已知规划领域的评估，本文方法在提取标志信息方面显示出较高的精确度和召回率。

Conclusion: 本文提出了一种新颖的方法，通过学习规划领域中多个规划任务的标志关系，创建了概率提升排序图，该结构能够捕捉参数化标志之间的加权抽象关系。尽管这些排序并非100%准确，但在规划中仍然非常有用。通过实例化这些关系到特定规划任务，该方法在已知规划领域中显示出较高的精确度和召回率。

Abstract: Landmarks have long played a pivotal role in automated planning, serving as
crucial elements for improving the planning algorithms. The main limitation of
classical landmark extraction methods is their sensitivity to specific planning
tasks. This results in landmarks fully tailored to individual instances,
thereby limiting their applicability across other instances of the same
planning domain. We propose a novel approach that learns landmark relationships
from multiple planning tasks of a planning domain. This leads to the creation
of a \textit{probabilistic lifted ordering graph}, as a structure that captures
weighted abstractions of relationships between parameterized landmarks.
Although these orderings are not 100\% true (they are probabilistic), they can
still be very useful in planning. Next, given a new planning task for that
domain, we instantiate the relationships from that graph to this particular
instance. This instantiation operates in two phases. First, it generates two
graphs: the former instantiating information from the initial state and the
latter from the goal state. Second, it combines these two graphs into one
unified graph by searching equivalences to extract landmark orderings. We
evaluate the precision and recallof the information found by our approach over
well-known planning domains.

</details>


### [382] [RALLM-POI: Retrieval-Augmented LLM for Zero-shot Next POI Recommendation with Geographical Reranking](https://arxiv.org/abs/2509.17066)
*Kunrong Li,Kwan Hui Lim*

Main category: cs.AI

TL;DR: RALLM-POI框架结合检索增强和自我修正，无需训练即提升零-shot POI推荐准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统POI推荐模型训练密集及LLMs在零-shot场景下生成通用或地理无关结果的问题。

Method: 提出RALLM-POI框架，包括历史轨迹检索器（HTR）检索相关轨迹，地理距离重排器（GDR）优先考虑空间相关轨迹，以及代理LLM修正器（ALR）通过自我反思优化输出。

Result: 在三个真实世界的Foursquare数据集上，RALLM-POI显著提高了准确性，优于传统和基于LLM的基线方法。

Conclusion: RALLM-POI框架通过结合检索增强生成和自我修正，显著提升了零-shot POI推荐的准确性，无需额外训练即可超越传统和基于LLM的基线方法。

Abstract: Next point-of-interest (POI) recommendation predicts a user's next
destination from historical movements. Traditional models require intensive
training, while LLMs offer flexible and generalizable zero-shot solutions but
often generate generic or geographically irrelevant results due to missing
trajectory and spatial context. To address these issues, we propose RALLM-POI,
a framework that couples LLMs with retrieval-augmented generation and
self-rectification. We first propose a Historical Trajectory Retriever (HTR)
that retrieves relevant past trajectories to serve as contextual references,
which are then reranked by a Geographical Distance Reranker (GDR) for
prioritizing spatially relevant trajectories. Lastly, an Agentic LLM Rectifier
(ALR) is designed to refine outputs through self-reflection. Without additional
training, RALLM-POI achieves substantial accuracy gains across three real-world
Foursquare datasets, outperforming both conventional and LLM-based baselines.
Code is released at https://github.com/LKRcrocodile/RALLM-POI.

</details>


### [383] [Intention-aware Hierarchical Diffusion Model for Long-term Trajectory Anomaly Detection](https://arxiv.org/abs/2509.17068)
*Chen Wang,Sarah Erfani,Tansu Alpcan,Christopher Leckie*

Main category: cs.AI

TL;DR: IHiD方法结合高层意图和低层轨迹分析，显著提升异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时考虑高层意图和低层导航细节，限制了其对正常轨迹多样性的捕捉能力。

Method: 提出了一种名为IHiD的无监督轨迹异常检测方法，结合逆Q学习（高层模型）和扩散模型（低层模型）。

Result: IHiD在异常检测性能上比现有基线提高了30.2%的F1分数。

Conclusion: IHiD方法通过结合高层意图评估和低层子轨迹分析，显著提升了异常检测性能，F1分数比现有基线提高了30.2%。

Abstract: Long-term trajectory anomaly detection is a challenging problem due to the
diversity and complex spatiotemporal dependencies in trajectory data. Existing
trajectory anomaly detection methods fail to simultaneously consider both the
high-level intentions of agents as well as the low-level details of the agent's
navigation when analysing an agent's trajectories. This limits their ability to
capture the full diversity of normal trajectories. In this paper, we propose an
unsupervised trajectory anomaly detection method named Intention-aware
Hierarchical Diffusion model (IHiD), which detects anomalies through both
high-level intent evaluation and low-level sub-trajectory analysis. Our
approach leverages Inverse Q Learning as the high-level model to assess whether
a selected subgoal aligns with an agent's intention based on predicted
Q-values. Meanwhile, a diffusion model serves as the low-level model to
generate sub-trajectories conditioned on subgoal information, with anomaly
detection based on reconstruction error. By integrating both models, IHiD
effectively utilises subgoal transition knowledge and is designed to capture
the diverse distribution of normal trajectories. Our experiments show that the
proposed method IHiD achieves up to 30.2% improvement in anomaly detection
performance in terms of F1 score over state-of-the-art baselines.

</details>


### [384] [Governing Automated Strategic Intelligence](https://arxiv.org/abs/2509.17087)
*Nicholas Kruus,Madhavendra Thakur,Adam Khoja,Leonhard Nagel,Maximilian Nicholson,Abeer Sharma,Jason Hausenloy,Alberto KoTafoya,Aliya Mukhanova,Alli Katila-Miikkulainen,Harish Chandran,Ivan Zhang,Jessie Chen,Joel Raj,Jord Nguyen,Lai Hsien Hao,Neja Jayasundara,Soham Sen,Sophie Zhang,Ashley Dora Kokui Tamaklo,Bhavya Thakur,Henry Close,Janghee Lee,Nina Sefton,Raghavendra Thakur,Shiv Munagala,Yeeun Kim*

Main category: cs.AI

TL;DR: 前沿AI模型将重塑国家间战略竞争，多模态基础模型可自动化军事情报分析，研究评估其能力并提出国家保持竞争力的建议。


<details>
  <summary>Details</summary>
Motivation: 探讨前沿人工智能模型在国家间军事和经济战略竞争中的作用，尤其是自动化军事情报的能力及其影响。

Method: 进行了初步的增益研究，评估多模态基础模型的能力，并提出了一个分类法来描述这些系统能回答的真实问题类型。

Result: 多模态基础模型有望自动化人类战略分析，能融合多种数据源为单一可查询系统。

Conclusion: 论文建议国家应在自动化情报的新范式下保持战略竞争力，并提出了相关建议。

Abstract: Military and economic strategic competitiveness between nation-states will
increasingly be defined by the capability and cost of their frontier artificial
intelligence models. Among the first areas of geopolitical advantage granted by
such systems will be in automating military intelligence. Much discussion has
been devoted to AI systems enabling new military modalities, such as lethal
autonomous weapons, or making strategic decisions. However, the ability of a
country of "CIA analysts in a data-center" to synthesize diverse data at scale,
and its implications, have been underexplored. Multimodal foundation models
appear on track to automate strategic analysis previously done by humans. They
will be able to fuse today's abundant satellite imagery, phone-location traces,
social media records, and written documents into a single queryable system. We
conduct a preliminary uplift study to empirically evaluate these capabilities,
then propose a taxonomy of the kinds of ground truth questions these systems
will answer, present a high-level model of the determinants of this system's AI
capabilities, and provide recommendations for nation-states to remain
strategically competitive within the new paradigm of automated intelligence.

</details>


### [385] [MCTS-EP: Empowering Embodied Planning with Online Preference Optimization](https://arxiv.org/abs/2509.17116)
*Hang Xu,Zang Yu,Yehui Tang,Pengbo Hu,Yuhao Tang,Hao Dong*

Main category: cs.AI

TL;DR: MCTS-EP 是一种结合 LLM 和 MCTS 的在线学习框架，通过理论证明和实验验证，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了提高训练嵌入式代理的性能，并克服传统策略算法的局限性，作者提出了 MCTS-EP 框架。

Method: MCTS-EP 集成了三个关键组件：MCTS 引导的探索、高效的多模态推理机制以及基于偏好优化的迭代训练流程。

Result: 在 ALFWorld 和 WebShop 基准测试中，MCTS-EP 分别达到了 92%/87% 的成功率和 0.81 的平均奖励，同时显著减少了交互步骤。

Conclusion: MCTS-EP 是一种结合了大型语言模型和蒙特卡洛树搜索的在线学习框架，通过理论证明和实验验证，展示了其在多个基准测试中的优越性能。

Abstract: This paper introduces MCTS-EP, an online learning framework that combines
large language models (LLM) with Monte Carlo Tree Search (MCTS) for training
embodied agents. MCTS-EP integrates three key components: MCTS-guided
exploration for preference data collection, efficient multi-modal reasoning
mechanism, and iterative training pipeline based on preference optimization. We
theoretically prove that MCTS-EP achieves better performance bounds than
conventional on-policy algorithms when the loss function is strongly convex,
and demonstrate that it can be formulated as a search-enhanced variant of GAIL.
MCTS-EP achieves state-of-the-art performace across serval benchmarks. In
ALFWorld, it achieves 92% and 87% success rates for textual and visual tasks.
In WebShop, it reaches an average reward of 0.81. MTCS-EP also reduces average
interaction steps from from 18.7/19.5 to 10.2/9.9 steps in visual ALFWorld.Code
available at: https://github.com/xuhang-2/Embodied-Agent-Planning

</details>


### [386] [ARE: Scaling Up Agent Environments and Evaluations](https://arxiv.org/abs/2509.17158)
*Pierre Andrews,Amine Benhalloum,Gerard Moreno-Torres Bertran,Matteo Bettini,Amar Budhiraja,Ricardo Silveira Cabral,Virginie Do,Romain Froger,Emilien Garreau,Jean-Baptiste Gaya,Hugo Laurençon,Maxime Lecanu,Kunal Malkan,Dheeraj Mekala,Pierre Ménard,Grégoire Mialon,Ulyana Piterbarg,Mikhail Plekhanov,Mathieu Rita,Andrey Rusakov,Thomas Scialom,Vladislav Vorotilov,Mengjue Wang,Ian Yu*

Main category: cs.AI

TL;DR: ARE平台和Gaia2基准测试为AI社区提供了创建多样化环境和评估智能体能力的工具，推动了AI技术的发展。实验显示现有系统在能力上存在权衡，需要新架构和策略。


<details>
  <summary>Details</summary>
Motivation: 弥合模型开发与实际部署之间的差距，推动AI技术在多样化任务中的进步。

Method: 通过ARE平台构建复杂多样的环境，并设计Gaia2基准测试来评估智能体的通用能力，包括处理模糊性、适应动态环境、协作和执行时间约束任务。

Result: 实验表明，现有系统在智能体能力上存在权衡，推理能力与效率之间需要平衡，且预算扩展曲线趋于稳定，凸显了对新架构和自适应计算策略的需求。

Conclusion: ARE平台和Gaia2基准测试为AI社区提供了强大的工具，用于创建多样化环境和评估智能体能力，推动了AI前沿技术的发展。

Abstract: We introduce Meta Agents Research Environments (ARE), a research platform for
scalable creation of environments, integration of synthetic or real
applications, and execution of agentic orchestrations. ARE provides simple
abstractions to build complex and diverse environments, each with their own
rules, tools, content, and verifiers, helping to bridge the gap between model
development and real-world deployment. We also propose Gaia2, a benchmark built
in ARE and designed to measure general agent capabilities. Beyond search and
execution, Gaia2 requires agents to handle ambiguities and noise, adapt to
dynamic environments, collaborate with other agents, and operate under temporal
constraints. Unlike prior benchmarks, Gaia2 runs asynchronously, surfacing new
failure modes that are invisible in static settings. Our experiments show that
no system dominates across the intelligence spectrum: stronger reasoning often
comes at the cost of efficiency, and budget scaling curves plateau,
highlighting the need for new architectures and adaptive compute strategies.
Perhaps more importantly, ARE abstractions enable continuous extension of Gaia2
to other environments, empowering the community to rapidly create new
benchmarks tailored to their domains. In AI's second half, progress
increasingly depends on defining meaningful tasks and robust evaluations to
drive frontier capabilities forward.

</details>


### [387] [Shall We Play a Game? Language Models for Open-ended Wargames](https://arxiv.org/abs/2509.17192)
*Glenn Matlin,Parv Mahajan,Isaac Song,Yixiong Hao,Ryan Bard,Stu Topp,Evan Montoya,M. Rehan Parwani,Soham Shetty,Mark Riedl*

Main category: cs.AI

TL;DR: 本文综述了AI在战争游戏中的应用，构建了创造力本体论，并提出了LMs在开放式战争游戏中的使用指南和安全考虑。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型如何在开放式战争游戏中为玩家和裁判提供决策支持，并分析其战略影响。

Method: 通过对100篇关于AI在战争游戏中应用的近期文献进行范围界定文献综述，构建了战争游戏的创造力本体论。

Result: 提炼了在不同应用领域使用LMs的考虑因素，并提出了安全考虑和最佳实践。

Conclusion: 本文提出了在开放式战争游戏中应用语言模型（LMs）的高影响力开放研究挑战，并总结了安全考虑和最佳实践。

Abstract: Wargames are multi-faceted, multi-player depictions of conflict in which
participants' decisions influence future events. Wargames are often used to
explore the strategic implications of decision-making. However, it also
encompasses entertainment-oriented simulations, ranging from _Chess_ to
tabletop role-playing games like _Dungeons & Dragons_ (D&D). On the more
open-ended side of the spectrum of wargames, players use natural language to
convey their moves, and adjudicators propose outcomes. Language Models (LMs)
are increasingly being considered for how they can provide insights into
real-world, consequential decisions. We conduct a scoping literature review of
a curated selection of 100 recent works on AI in wargames, from which we
construct an ontology of wargames in terms of the creativity afforded to either
the players or adjudicators. Focusing on the space of wargames with the most
open-endedness for players and adjudicators, we distill a set of considerations
for when and how to use LMs in different application areas. We also present a
set of safety considerations, best practices for deploying LMs in open-ended
wargames, and conclude with a set of high-impact open research challenges.

</details>


### [388] [MoEs Are Stronger than You Think: Hyper-Parallel Inference Scaling with RoE](https://arxiv.org/abs/2509.17238)
*Soheil Zibakhsh,Mohammad Samragh,Kumari Nishu,Lauren Hannah,Arnav Kundu,Minsik Cho*

Main category: cs.AI

TL;DR: RoE enhances MoE models by dynamically aggregating diverse expert outputs per token, reducing compute costs while maintaining performance.


<details>
  <summary>Details</summary>
Motivation: To improve prediction quality at the token level in LLMs, complementing existing sequence-level scaling methods like Chain-of-Thought.

Method: Implemented as Roster of Experts (RoE), a training-free inference algorithm that introduces controlled stochasticity in expert routing, enabling dynamic ensemble of MoEs with efficient batching and KV-caching.

Result: RoE allows a 7B MoE model to match a 10.5B MoE model's performance with 30% less compute, demonstrating efficiency and effectiveness.

Conclusion: Hyper-parallel scaling (RoE) effectively enhances token-level prediction quality in MoE models without fine-tuning, achieving significant performance gains with reduced computational costs.

Abstract: The generation quality of large language models (LLMs) is often improved by
utilizing inference-time sequence-level scaling methods (e.g.,
Chain-of-Thought). We introduce hyper-parallel scaling, a complementary
framework that improves prediction quality at the token level. Hyper-parallel
scaling computes and aggregates multiple output proposals for a single token
from the model. We implement this concept in Mixture-of-Experts (MoE) models,
which we refer to as Roster of Experts (RoE). RoE is a training-free inference
algorithm that turns a single MoE into a dynamic ensemble of MoEs. RoE injects
controlled stochasticity into the expert routing mechanism, enabling it to
sample multiple diverse experts for each token and aggregate their outputs for
a more accurate final prediction.To overcome the computational cost, we
introduce an efficient batching strategy and a specialized KV-caching mechanism
that minimizes compute and memory overhead. For example, RoE enables a 7B MoE
model to match the performance of a 10.5B MoE model while using 30% less
compute for inference. These gains are achieved without any fine-tuning of
model parameters.

</details>


### [389] [Can Agents Judge Systematic Reviews Like Humans? Evaluating SLRs with LLM-based Multi-Agent System](https://arxiv.org/abs/2509.17240)
*Abdullah Mushtaq,Muhammad Rafay Naeem,Ibrahim Ghaznavi,Alaa Abd-alrazaq,Aliya Tabassum,Junaid Qadir*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM和多Agent系统的SLR评估辅助工具，初步验证显示其与专家评估一致性高，为跨学科研究提供了高效工具。


<details>
  <summary>Details</summary>
Motivation: 系统性文献综述（SLR）是证据研究的基础，但劳动密集且跨学科一致性差，需要更高效、一致的工具来辅助评估。

Method: 采用基于多Agent系统（MAS）的架构，结合PRISMA指南，自动化进行协议验证、方法评估和主题相关性检查。

Result: 在五个不同领域的已发表SLR上进行初步研究，系统输出与专家标注的PRISMA评分一致性达到84%。

Conclusion: 该研究展示了基于LLM和多Agent系统的SLR评估辅助工具的潜力，初步结果表明其与专家评估的PRISMA评分有84%的一致性，为跨学科工作流程的可扩展和准确NLP驱动系统迈出了第一步。

Abstract: Systematic Literature Reviews (SLRs) are foundational to evidence-based
research but remain labor-intensive and prone to inconsistency across
disciplines. We present an LLM-based SLR evaluation copilot built on a
Multi-Agent System (MAS) architecture to assist researchers in assessing the
overall quality of the systematic literature reviews. The system automates
protocol validation, methodological assessment, and topic relevance checks
using a scholarly database. Unlike conventional single-agent methods, our
design integrates a specialized agentic approach aligned with PRISMA guidelines
to support more structured and interpretable evaluations. We conducted an
initial study on five published SLRs from diverse domains, comparing system
outputs to expert-annotated PRISMA scores, and observed 84% agreement. While
early results are promising, this work represents a first step toward scalable
and accurate NLP-driven systems for interdisciplinary workflows and reveals
their capacity for rigorous, domain-agnostic knowledge aggregation to
streamline the review process.

</details>


### [390] [Mind the Gap: Comparing Model- vs Agentic-Level Red Teaming with Action-Graph Observability on GPT-OSS-20B](https://arxiv.org/abs/2509.17259)
*Ilham Wicaksono,Zekun Wu,Rahul Patel,Theo King,Adriano Koshiyama,Philip Treleaven*

Main category: cs.AI

TL;DR: 研究发现代理AI系统存在独特的漏洞，代理环境中的攻击效果比独立模型更显著。


<details>
  <summary>Details</summary>
Motivation: 随着代理AI系统的广泛应用，理解其独特的安全漏洞变得至关重要。

Method: 使用AgentSeer观察框架对GPT-OSS-20B进行红队分析，比较独立模型和代理循环中的模型表现。

Result: 代理级别的漏洞比模型级别高24%，且某些模型级别的漏洞在代理环境中无效。

Conclusion: 研究发现，代理AI系统存在独特的漏洞，这些漏洞在独立模型层面并不存在。代理级别的迭代攻击在某些情况下比模型级别更有效，揭示了代理执行环境中的新攻击向量。

Abstract: As the industry increasingly adopts agentic AI systems, understanding their
unique vulnerabilities becomes critical. Prior research suggests that security
flaws at the model level do not fully capture the risks present in agentic
deployments, where models interact with tools and external environments. This
paper investigates this gap by conducting a comparative red teaming analysis of
GPT-OSS-20B, a 20-billion parameter open-source model. Using our observability
framework AgentSeer to deconstruct agentic systems into granular actions and
components, we apply iterative red teaming attacks with harmful objectives from
HarmBench at two distinct levels: the standalone model and the model operating
within an agentic loop. Our evaluation reveals fundamental differences between
model level and agentic level vulnerability profiles. Critically, we discover
the existence of agentic-only vulnerabilities, attack vectors that emerge
exclusively within agentic execution contexts while remaining inert against
standalone models. Agentic level iterative attacks successfully compromise
objectives that completely failed at the model level, with tool-calling
contexts showing 24\% higher vulnerability than non-tool contexts. Conversely,
certain model-specific exploits work exclusively at the model level and fail
when transferred to agentic contexts, demonstrating that standalone model
vulnerabilities do not always generalize to deployed systems.

</details>


### [391] [CogAtom: From Cognitive Atoms to Olympiad-level Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2509.17318)
*Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong*

Main category: cs.AI

TL;DR: CogAtom是一种基于认知原子的框架，用于生成高质量、多样化的数学问题，通过重组基本推理单元和随机游走算法，确保逻辑严谨和结构多样性。


<details>
  <summary>Details</summary>
Motivation: 由于数学推理对多步推理和抽象概念整合的要求，大型语言模型（LLM）面临挑战，而高质量、高难度问题的稀缺性（如奥林匹克数学题）成为瓶颈。

Method: CogAtom通过选择和重组从人类解题方案中提取的认知原子（基本推理单元），结合多样性促进的随机游走算法和基于约束的重组机制，确保逻辑严谨性和结构有效性。

Result: 实验结果表明，CogAtom在准确性、推理深度和多样性上优于现有方法，生成的问题在难度上与AIME匹配，但结构变化更丰富。

Conclusion: CogAtom提供了一个基于认知基础的、可扩展的高质量数学问题生成途径，其生成的题目在难度上与AIME相当，但在结构变化上更胜一筹。

Abstract: Mathematical reasoning poses significant challenges for Large Language Models
(LLMs) due to its demand for multi-step reasoning and abstract conceptual
integration. While recent test-time scaling techniques rely heavily on
high-quality, challenging problems, the scarcity of Olympiad-level math
problems remains a bottleneck. We introduce CogAtom, a novel cognitive
atom-based framework for synthesizing mathematically rigorous and cognitively
diverse problems. Unlike prior approaches, CogAtom models problem construction
as a process of selecting and recombining fundamental reasoning units,
cognitive atoms, extracted from human-authored solutions. A diversity-promoting
random walk algorithm enables exploration of the cognitive atom space, while a
constraint-based recombination mechanism ensures logical soundness and
structural validity. The combinatorial nature of the graph structure provides a
near-infinite space of reasoning paths, and the walk algorithm systematically
explores this space to achieve large-scale synthesis of high-quality problems;
meanwhile, by controlling the number of cognitive atoms, we can precisely
adjust problem difficulty, ensuring diversity, scalability, and controllability
of the generated problems. Experimental results demonstrate that CogAtom
outperforms existing methods in accuracy, reasoning depth, and diversity,
generating problems that closely match the difficulty of AIME while exceeding
it in structural variation. Our work offers a cognitively grounded pathway
toward scalable, high-quality math problem generation.Our code is publicly
available at https://github.com/Icarus-1111/CogAtom.

</details>


### [392] [LLaVul: A Multimodal LLM for Interpretable Vulnerability Reasoning about Source Code](https://arxiv.org/abs/2509.17337)
*Ala Jararweh,Michael Adams,Avinash Sahu,Abdullah Mueen,Afsah Anwar*

Main category: cs.AI

TL;DR: LLaVul是一种多模态LLM，通过问答提供细粒度代码漏洞推理，优于现有模型，增强了安全为中心的代码理解。


<details>
  <summary>Details</summary>
Motivation: 当前软件系统复杂性增加，对源代码漏洞分析的需求上升，但现有方法过于简化或忽视安全特定推理。

Method: 提出LLaVul，一种多模态大型语言模型，通过问答提供细粒度代码推理，训练模型将配对代码和自然查询整合到统一空间。

Result: LLaVul在问答和检测任务中优于现有通用和代码大型语言模型，并通过定性分析展示其决策能力。

Conclusion: LLaVul通过整合代码和问答，实现了更可解释且以安全为中心的代码理解。

Abstract: Increasing complexity in software systems places a growing demand on
reasoning tools that unlock vulnerabilities manifest in source code. Many
current approaches focus on vulnerability analysis as a classifying task,
oversimplifying the nuanced and context-dependent real-world scenarios. Even
though current code large language models (LLMs) excel in code understanding,
they often pay little attention to security-specific reasoning. We propose
LLaVul, a multimodal LLM tailored to provide fine-grained reasoning about code
through question-answering (QA). Our model is trained to integrate paired code
and natural queries into a unified space, enhancing reasoning and
context-dependent insights about code vulnerability. To evaluate our model
performance, we construct a curated dataset of real-world vulnerabilities
paired with security-focused questions and answers. Our model outperforms
state-of-the-art general-purpose and code LLMs in the QA and detection tasks.
We further explain decision-making by conducting qualitative analysis to
highlight capabilities and limitations. By integrating code and QA, LLaVul
enables more interpretable and security-focused code understanding.

</details>


### [393] [Medical AI Consensus: A Multi-Agent Framework for Radiology Report Generation and Evaluation](https://arxiv.org/abs/2509.17353)
*Ahmed T. Elboardy,Ghada Khoriba,Essam A. Rashed*

Main category: cs.AI

TL;DR: 论文提出了一种多智能体强化学习框架，结合LLMs和LVMs，用于放射学报告生成的基准和评估，旨在提升临床可靠性和评估严谨性。


<details>
  <summary>Details</summary>
Motivation: 自动化放射学报告生成面临双重挑战：构建临床可靠的系统和设计严格的评估协议。

Method: 论文引入了一个模块化架构，整合了大型语言模型（LLMs）和大型视觉模型（LVMs），由十个专门负责图像分析、特征提取、报告生成、审查和评估的智能体组成。

Result: 在公共放射学数据集上使用chatGPT-4o进行了实现，展示了LLMs作为评估者与医学放射科医生反馈的结合效果。

Conclusion: 该论文提出了一个多智能体强化学习框架，作为放射学生态系统中多模态临床推理的基准和评估环境，旨在建立可信赖的基于偏差的放射学报告生成路径。

Abstract: Automating radiology report generation poses a dual challenge: building
clinically reliable systems and designing rigorous evaluation protocols. We
introduce a multi-agent reinforcement learning framework that serves as both a
benchmark and evaluation environment for multimodal clinical reasoning in the
radiology ecosystem. The proposed framework integrates large language models
(LLMs) and large vision models (LVMs) within a modular architecture composed of
ten specialized agents responsible for image analysis, feature extraction,
report generation, review, and evaluation. This design enables fine-grained
assessment at both the agent level (e.g., detection and segmentation accuracy)
and the consensus level (e.g., report quality and clinical relevance). We
demonstrate an implementation using chatGPT-4o on public radiology datasets,
where LLMs act as evaluators alongside medical radiologist feedback. By
aligning evaluation protocols with the LLM development lifecycle, including
pretraining, finetuning, alignment, and deployment, the proposed benchmark
establishes a path toward trustworthy deviance-based radiology report
generation.

</details>


### [394] [Multi-Scenario Highway Lane-Change Intention Prediction: A Physics-Informed AI Framework for Three-Class Classification](https://arxiv.org/abs/2509.17354)
*Jiazhao Shi,Yichen Lin,Yiheng Hua,Ziyu Wang,Zijian Zhang,Wenjia Zheng,Yun Song,Kuan Lu,Shoufeng Lu*

Main category: cs.AI

TL;DR: 提出物理信息AI框架，结合车辆运动学和交互特征，显著提升车道变更意图预测的准确性和泛化能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 车道变更是高速公路事故的主要原因，现有方法在二元分类、场景多样性和长预测时间下的性能不足，亟需更准确的意图预测方法以提高自动驾驶系统的安全性和决策能力。

Method: 提出了一个物理信息AI框架，将车辆运动学、交互可行性和交通安全指标（如车距、时间间隔、碰撞时间等）显式整合到学习过程中。车道变更预测被建模为一个三分类问题，区分左转、右转和无变更。

Result: 在highD和exiD数据集上，模型（尤其是LightGBM）达到了99.8%的准确率和93.6%的宏F1值（highD），以及96.1%的准确率和88.7%的宏F1值（exiD），显著优于双层堆叠LSTM基线。

Conclusion: 研究表明，结合物理知识和丰富特征的机器学习框架在实时车道变更意图预测中具有实际优势，显著提升了预测准确性和泛化能力。

Abstract: Lane-change maneuvers are a leading cause of highway accidents, underscoring
the need for accurate intention prediction to improve the safety and
decision-making of autonomous driving systems. While prior studies using
machine learning and deep learning methods (e.g., SVM, CNN, LSTM, Transformers)
have shown promise, most approaches remain limited by binary classification,
lack of scenario diversity, and degraded performance under longer prediction
horizons. In this study, we propose a physics-informed AI framework that
explicitly integrates vehicle kinematics, interaction feasibility, and
traffic-safety metrics (e.g., distance headway, time headway,
time-to-collision, closing gap time) into the learning process. lane-change
prediction is formulated as a three-class problem that distinguishes left
change, right change, and no change, and is evaluated across both straight
highway segments (highD) and complex ramp scenarios (exiD). By integrating
vehicle kinematics with interaction features, our machine learning models,
particularly LightGBM, achieve state-of-the-art accuracy and strong
generalization. Results show up to 99.8% accuracy and 93.6% macro F1 on highD,
and 96.1% accuracy and 88.7% macro F1 on exiD at a 1-second horizon,
outperforming a two-layer stacked LSTM baseline. These findings demonstrate the
practical advantages of a physics-informed and feature-rich machine learning
framework for real-time lane-change intention prediction in autonomous driving
systems.

</details>


### [395] [Correlation or Causation: Analyzing the Causal Structures of LLM and LRM Reasoning Process](https://arxiv.org/abs/2509.17380)
*Zhizhang FU,Guangsheng Bao,Hongbo Zhang,Chenkai Hu,Yue Zhang*

Main category: cs.AI

TL;DR: RLVR训练的LRMs在因果推理上优于LLMs和蒸馏LRMs，减少了虚假相关性并强化了真实因果模式。


<details>
  <summary>Details</summary>
Motivation: LLMs存在因果推理问题（如不忠实、偏见和不一致），而LRMs虽通过RL和蒸馏提升了任务准确性，但其对因果性的影响尚未充分探索。

Method: 通过系统因果分析，考察了LLMs和LRMs在四个关键变量（问题指令Z、思考过程T、推理步骤X和答案Y）上的结构因果模型（SCMs）。

Result: RLVR训练的LRMs表现出更强的因果推理能力，减少了虚假相关性并强化了真实因果模式，从而缓解了不忠实和偏见问题。

Conclusion: 本研究揭示了RLVR训练的LRMs在因果推理能力上的显著提升，相比LLMs和蒸馏LRMs能更好地解决因果性缺陷，为设计具有更强因果基础的AI系统提供了见解。

Abstract: LLMs suffer from critical reasoning issues such as unfaithfulness, bias, and
inconsistency, since they lack robust causal underpinnings and may rely on
superficial correlations rather than genuine understanding. Successive LRMs
have emerged as a promising alternative, leveraging advanced training
techniques such as reinforcement learning (RL) and distillation to improve task
accuracy. However, the impact of these training methods on causality remains
largely unexplored. In this study, we conduct a systematic causal analysis on
LLMs and LRMs, examining structural causal models (SCMs) of four key variables:
problem instruction (Z), thinking process (T), reasoning steps (X), and answer
(Y). Our findings reveal that RLVR-trained LRMs exhibit enhanced causal
reasoning capabilities, aligning more closely with ideal causal structures,
while LLMs and distilled LRMs fail to address causality-related deficiencies.
Our further investigation indicates that RLVR reduces spurious correlations and
strengthens genuine causal patterns, thereby mitigating unfaithfulness and
bias. In addition, our inspection on the dynamics of the RLVR training process
observes a high correlation between reduced spurious features and improved
causal structures, where the causal relationships consistently improve in the
training process. This study contributes to the understanding of causality in
reasoning models, highlights the critical role of RLVR in enhancing causal
reasoning, and provides insights for designing future AI systems with stronger
causal foundations. We release our code and data at
https://github.com/Harryking1999/CoT_Causal_Analysis.

</details>


### [396] [Program Synthesis via Test-Time Transduction](https://arxiv.org/abs/2509.17393)
*Kang-il Lee,Jahyun Koo,Seunghyun Yoon,Minbeom Kim,Hyukhun Koh,Dongryeol Lee,Kyomin Jung*

Main category: cs.AI

TL;DR: 提出转导式程序合成方法，利用测试输入和LLM提升鲁棒性，实验证明效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有程序合成方法在训练样本有限且测试输入包含边缘案例时鲁棒性较差，因此需要一种更有效的方法。

Method: 提出了一种基于有限假设类的主动学习框架，利用LLM预测测试输入输出并通过贪婪最大化算法选择输入以减少查询次数。

Result: 在两个真实数据集（Playgol和MBPP+）上的评估显示，该方法在准确性和效率上均有显著改进。

Conclusion: 本文提出了一种新的转导式程序合成方法，通过显式利用测试输入来提高合成的鲁棒性，实验证明该方法在准确性和效率上均有显著提升。

Abstract: We introduce transductive program synthesis, a new formulation of the program
synthesis task that explicitly leverages test inputs during synthesis. While
prior approaches to program synthesis--whether based on natural language
descriptions or input-output examples--typically aim to generalize from
training examples, they often struggle with robustness, especially in
real-world settings where training examples are limited and test inputs involve
various edge cases. To address this, we propose a novel framework that improves
robustness by treating synthesis as an active learning over a finite hypothesis
class defined by programs' outputs. We use an LLM to predict outputs for
selected test inputs and eliminate inconsistent hypotheses, where the inputs
are chosen via a greedy maximin algorithm to minimize the number of LLM queries
required. We evaluate our approach on two real-world datasets: Playgol, a
string transformation benchmark, and MBPP+, a Python code generation benchmark.
We demonstrate that our method significantly improves program synthesis in both
accuracy and efficiency. We release our code at
https://github.com/klee972/SYNTRA.

</details>


### [397] [Evaluating Multimodal Large Language Models with Daily Composite Tasks in Home Environments](https://arxiv.org/abs/2509.17425)
*Zhenliang Zhang,Yuxi Wang,Hongzhao Xie,Shiyun Zhao,Mingyuan Liu,Yujie Lu,Xinyi He,Zhenku Cheng,Yujia Peng*

Main category: cs.AI

TL;DR: 研究评估了多模态大语言模型在复合任务上的表现，发现其能力与通用智能要求差距显著，为未来研究提供了框架。


<details>
  <summary>Details</summary>
Motivation: 探索具身智能体是否能解决需要广泛能力的复合任务，以填补现有研究的空白。

Method: 设计了基于日常活动的复合任务，涵盖对象理解、空间智能和社交活动三个核心领域，并在动态模拟家庭环境中评估了17种领先的MLLMs。

Result: 所有评估模型在三个领域均表现不佳。

Conclusion: 当前的多模态大语言模型在复合任务上表现不佳，显示出与通用智能要求之间的显著差距。研究为评估具身智能体的一般能力提供了初步框架。

Abstract: A key feature differentiating artificial general intelligence (AGI) from
traditional AI is that AGI can perform composite tasks that require a wide
range of capabilities. Although embodied agents powered by multimodal large
language models (MLLMs) offer rich perceptual and interactive capabilities, it
remains largely unexplored whether they can solve composite tasks. In the
current work, we designed a set of composite tasks inspired by common daily
activities observed in early childhood development. Within a dynamic and
simulated home environment, these tasks span three core domains: object
understanding, spatial intelligence, and social activity. We evaluated 17
leading proprietary and open-source MLLMs on these tasks. The results
consistently showed poor performance across all three domains, indicating a
substantial gap between current capabilities and general intelligence
requirements. Together, our tasks offer a preliminary framework for evaluating
the general capabilities of embodied agents, marking an early but significant
step toward the development of embodied MLLMs and their real-world deployment.

</details>


### [398] [SPICED: A Synaptic Homeostasis-Inspired Framework for Unsupervised Continual EEG Decoding](https://arxiv.org/abs/2509.17439)
*Yangxuan Zhou,Sha Zhao,Jiquan Wang,Haiteng Jiang,Shijian Li,Tao Li,Gang Pan*

Main category: cs.AI

TL;DR: SPICED是一个受生物启发的神经形态框架，通过突触稳态机制实现持续EEG解码，有效应对个体间变异性并减少遗忘。


<details>
  <summary>Details</summary>
Motivation: 受人类大脑通过突触稳态实现动态稳定与可塑性平衡的启发，旨在解决持续EEG解码中因新个体引入带来的个体间变异性问题。

Method: SPICED结合了三种生物启发的神经机制：关键记忆重新激活、突触巩固和突触重归一化，通过突触稳态动态调节记忆痕迹。

Result: 在三个EEG数据集上的验证表明，SPICED能够有效适应新个体并减轻灾难性遗忘。

Conclusion: SPICED框架通过模仿人脑的突触稳态机制，成功实现了动态的稳定性与可塑性平衡，在持续EEG解码中表现出色，有效应对了个体间变异性的挑战。

Abstract: Human brain achieves dynamic stability-plasticity balance through synaptic
homeostasis. Inspired by this biological principle, we propose SPICED: a
neuromorphic framework that integrates the synaptic homeostasis mechanism for
unsupervised continual EEG decoding, particularly addressing practical
scenarios where new individuals with inter-individual variability emerge
continually. SPICED comprises a novel synaptic network that enables dynamic
expansion during continual adaptation through three bio-inspired neural
mechanisms: (1) critical memory reactivation; (2) synaptic consolidation and
(3) synaptic renormalization. The interplay within synaptic homeostasis
dynamically strengthens task-discriminative memory traces and weakens
detrimental memories. By integrating these mechanisms with continual learning
system, SPICED preferentially replays task-discriminative memory traces that
exhibit strong associations with newly emerging individuals, thereby achieving
robust adaptations. Meanwhile, SPICED effectively mitigates catastrophic
forgetting by suppressing the replay prioritization of detrimental memories
during long-term continual learning. Validated on three EEG datasets, SPICED
show its effectiveness.

</details>


### [399] [AI Pangaea: Unifying Intelligence Islands for Adapting Myriad Tasks](https://arxiv.org/abs/2509.17460)
*Jianlong Chang,Haixin Wang,Zhiyuan Dang,Li Huang,Zhiyu Wang,Ruoqi Cao,Shihao Piao,Dongzhe Li,Dianyu Gao,Dongsheng Wang,Yin Li,Jinan Sun,Lu Fang,Zhouchen Lin*

Main category: cs.AI

TL;DR: Pangaea通过统一数据格式和多模态预训练，实现了跨任务泛化，为AGI提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型局限于特定任务，形成‘智能孤岛’，阻碍了人工通用智能的发展。Pangaea旨在统一这些孤岛。

Method: Pangaea通过将任何数据编码为统一格式，并在296个跨多样模态的数据集上进行预训练，积累通用知识。

Result: Pangaea在45个通用任务和15个科学任务中表现出卓越的泛化能力，并揭示了模态的缩放效应。

Conclusion: Pangaea展示了处理多种任务的强大潜力，为人工通用智能（AGI）的发展指明了新方向。

Abstract: The pursuit of artificial general intelligence continuously demands
generalization in one model across myriad tasks, even those not seen before.
However, current AI models are isolated from each other for being limited to
specific tasks, now first defined as Intelligence Islands. To unify
Intelligence Islands into one, we propose Pangaea, the first AI supercontinent
akin to the geological Pangaea. Pangaea encodes any data into a unified format
and accumulates universal knowledge through pre-training on 296 datasets across
diverse modalities. Eventually, it demonstrates remarkable generalization
across 45 general tasks and 15 scientific tasks encompassing a wide range of
scientific subjects. By investigating Pangaea deeper, the scaling effect of
modality is revealed, quantifying the universal knowledge accumulation across
modalities as the cumulative distribution function of a geometric distribution.
On the whole, Pangaea shows strong potential to handle myriad tasks, indicating
a new direction toward artificial general intelligence.

</details>


### [400] [A Multimodal Conversational Assistant for the Characterization of Agricultural Plots from Geospatial Open Data](https://arxiv.org/abs/2509.17544)
*Juan Cañada,Raúl Alonso,Julio Molleda,Fidel Díez*

Main category: cs.AI

TL;DR: 本研究开发了一个开源对话助手，结合多模态检索和LLMs，通过自然语言交互降低农业和地理空间数据的访问门槛，初步结果显示其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 开放地球观测（EO）和农业数据集的增多为可持续土地管理提供了潜力，但其高技术门槛限制了非专家用户的访问。本研究旨在通过自然语言交互降低这一门槛。

Method: 研究采用了一种结合多模态检索和大型语言模型（LLMs）的架构，通过检索增强生成（RAG）技术整合正射影像、Sentinel-2植被指数和用户提供的文档，灵活决定依赖多模态证据、文本知识或两者来生成答案。

Result: 初步结果表明，系统能够生成清晰、相关且上下文感知的农业查询响应，同时在不同地理区域保持可复现性和可扩展性。

Conclusion: 本研究提出了一种结合多模态检索和大型语言模型的开源对话助手，显著降低了非专家用户获取农业和地理空间数据的门槛，并通过开放和可复现的设计展示了其实际应用价值。

Abstract: The increasing availability of open Earth Observation (EO) and agricultural
datasets holds great potential for supporting sustainable land management.
However, their high technical entry barrier limits accessibility for non-expert
users. This study presents an open-source conversational assistant that
integrates multimodal retrieval and large language models (LLMs) to enable
natural language interaction with heterogeneous agricultural and geospatial
data. The proposed architecture combines orthophotos, Sentinel-2 vegetation
indices, and user-provided documents through retrieval-augmented generation
(RAG), allowing the system to flexibly determine whether to rely on multimodal
evidence, textual knowledge, or both in formulating an answer. To assess
response quality, we adopt an LLM-as-a-judge methodology using Qwen3-32B in a
zero-shot, unsupervised setting, applying direct scoring in a multi-dimensional
quantitative evaluation framework. Preliminary results show that the system is
capable of generating clear, relevant, and context-aware responses to
agricultural queries, while remaining reproducible and scalable across
geographic regions. The primary contributions of this work include an
architecture for fusing multimodal EO and textual knowledge sources, a
demonstration of lowering the barrier to access specialized agricultural
information through natural language interaction, and an open and reproducible
design.

</details>


### [401] [Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem](https://arxiv.org/abs/2509.17550)
*Neslihan Kose,Anthony Rhodes,Umur Aybars Ciftci,Ilke Demir*

Main category: cs.AI

TL;DR: 论文首次全面分析了深度伪造检测器的不确定性，通过贝叶斯方法量化不确定性，并验证其在来源检测和对抗攻击中的实用性。


<details>
  <summary>Details</summary>
Motivation: 深度伪造生成器质量的提升导致在线信任危机，而检测器的误用进一步加剧了错误信息问题，因此需要系统性研究不确定性。

Method: 利用贝叶斯神经网络和蒙特卡洛dropout来量化不同检测器架构的偶然性和认知不确定性，并在两个数据集上评估了九种生成器和六种检测器。

Result: 不确定性流形包含足够一致的信息，可用于深度伪造来源检测，并引入了能定位像素级预测信心的不确定性地图。

Conclusion: 该论文通过不确定性分析为深度伪造检测系统提供了关键见解，并将不确定性量化确立为可信合成媒体检测的基本要求。

Abstract: As generative models are advancing in quality and quantity for creating
synthetic content, deepfakes begin to cause online mistrust. Deepfake detectors
are proposed to counter this effect, however, misuse of detectors claiming fake
content as real or vice versa further fuels this misinformation problem. We
present the first comprehensive uncertainty analysis of deepfake detectors,
systematically investigating how generative artifacts influence prediction
confidence. As reflected in detectors' responses, deepfake generators also
contribute to this uncertainty as their generative residues vary, so we cross
the uncertainty analysis of deepfake detectors and generators. Based on our
observations, the uncertainty manifold holds enough consistent information to
leverage uncertainty for deepfake source detection. Our approach leverages
Bayesian Neural Networks and Monte Carlo dropout to quantify both aleatoric and
epistemic uncertainties across diverse detector architectures. We evaluate
uncertainty on two datasets with nine generators, with four blind and two
biological detectors, compare different uncertainty methods, explore region-
and pixel-based uncertainty, and conduct ablation studies. We conduct and
analyze binary real/fake, multi-class real/fake, source detection, and
leave-one-out experiments between the generator/detector combinations to share
their generalization capability, model calibration, uncertainty, and robustness
against adversarial attacks. We further introduce uncertainty maps that
localize prediction confidence at the pixel level, revealing distinct patterns
correlated with generator-specific artifacts. Our analysis provides critical
insights for deploying reliable deepfake detection systems and establishes
uncertainty quantification as a fundamental requirement for trustworthy
synthetic media detection.

</details>


### [402] [MontePrep: Monte-Carlo-Driven Automatic Data Preparation without Target Data Instances](https://arxiv.org/abs/2509.17553)
*Congcong Ge,Yachuan Liu,Yixuan Tang,Yifan Zhu,Yaofeng Tu,Yunjun Gao*

Main category: cs.AI

TL;DR: MontePrep 是一个免训练的 ADP 框架，通过 LLM 驱动的搜索和优化，显著提升了数据准备效率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 商业系统中，传统 ADP 方法依赖人工监督信号或目标表数据访问权限，限制了实际应用。MontePrep 旨在解决这些问题，提供更灵活、高效的解决方案。

Method: MontePrep 结合了数据准备动作沙盒（DPAS）、基础管道生成器（FPG）和执行感知管道优化器（EPO），利用 LLM 驱动的蒙特卡洛树搜索实现管道生成和优化。

Result: 实验结果表明，MontePrep 在性能上显著优于五种最先进的竞争对手。

Conclusion: MontePrep 是一个高效的端到端 ADP 框架，通过零目标实例要求和免训练管道合成，显著提升了自动数据准备的性能。

Abstract: In commercial systems, a pervasive requirement for automatic data preparation
(ADP) is to transfer relational data from disparate sources to targets with
standardized schema specifications. Previous methods rely on labor-intensive
supervision signals or target table data access permissions, limiting their
usage in real-world scenarios. To tackle these challenges, we propose an
effective end-to-end ADP framework MontePrep, which enables training-free
pipeline synthesis with zero target-instance requirements. MontePrep is
formulated as an open-source large language model (LLM) powered tree-structured
search problem. It consists of three pivot components, i.e., a data preparation
action sandbox (DPAS), a fundamental pipeline generator (FPG), and an
execution-aware pipeline optimizer (EPO). We first introduce DPAS, a
lightweight action sandbox, to navigate the search-based pipeline generation.
The design of DPAS circumvents exploration of infeasible pipelines. Then, we
present FPG to build executable DP pipelines incrementally, which explores the
predefined action sandbox by the LLM-powered Monte Carlo Tree Search.
Furthermore, we propose EPO, which invokes pipeline execution results from
sources to targets to evaluate the reliability of the generated pipelines in
FPG. In this way, unreasonable pipelines are eliminated, thus facilitating the
search process from both efficiency and effectiveness perspectives. Extensive
experimental results demonstrate the superiority of MontePrep with significant
improvement against five state-of-the-art competitors.

</details>


### [403] [LIMI: Less is More for Agency](https://arxiv.org/abs/2509.17567)
*Yang Xiao,Mohan Jiang,Jie Sun,Keyu Li,Jifan Lin,Yumin Zhuang,Ji Zeng,Shijie Xia,Qishuo Hua,Xuefeng Li,Xiaojie Cai,Tongyu Wang,Yue Zhang,Liming Liu,Xia Wu,Jinlong Hou,Yuan Cheng,Wenjie Li,Xiang Wang,Dequan Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: LIMI证明，通过少量高质量示范即可高效培育AI代理能力，挑战了‘数据越多越好’的传统观念，并提出了‘代理效率原则’。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽擅长推理与生成响应，但工业界亟需能够执行任务、操作工具并驱动实际成果的自主代理。传统假设认为更多数据能提升代理能力，但本文挑战了这一范式，探索了代理智能发展的新原则。

Method: LIMI（Less Is More for Intelligent Agency）通过精心设计的78个训练样本，展示了在协作软件开发与科研工作流中，战略性策划的少量示范如何催生复杂的代理智能。

Result: LIMI在综合代理基准测试中达到73.5%的准确率，显著优于现有先进模型（如Kimi-K2-Instruct的24.1%），且仅用128分之一的数据量即实现了53.7%的性能提升。

Conclusion: LIMI研究表明，机器自主性（agency）的培育并非依赖于数据量的累积，而是通过高质量、战略性策划的自主行为示范来实现。这一发现确立了‘代理效率原则’（Agency Efficiency Principle），为未来AI系统的开发提供了新的方向。

Abstract: We define Agency as the emergent capacity of AI systems to function as
autonomous agents actively discovering problems, formulating hypotheses, and
executing solutions through self-directed engagement with environments and
tools. This fundamental capability marks the dawn of the Age of AI Agency,
driven by a critical industry shift: the urgent need for AI systems that don't
just think, but work. While current AI excels at reasoning and generating
responses, industries demand autonomous agents that can execute tasks, operate
tools, and drive real-world outcomes. As agentic intelligence becomes the
defining characteristic separating cognitive systems from productive workers,
efficiently cultivating machine autonomy becomes paramount. Current approaches
assume that more data yields better agency, following traditional scaling laws
from language modeling. We fundamentally challenge this paradigm. LIMI (Less Is
More for Intelligent Agency) demonstrates that agency follows radically
different development principles. Through strategic focus on collaborative
software development and scientific research workflows, we show that
sophisticated agentic intelligence can emerge from minimal but strategically
curated demonstrations of autonomous behavior. Using only 78 carefully designed
training samples, LIMI achieves 73.5% on comprehensive agency benchmarks,
dramatically outperforming state-of-the-art models: Kimi-K2-Instruct (24.1%),
DeepSeek-V3.1 (11.9%), Qwen3-235B-A22B-Instruct (27.5%), and GLM-4.5 (45.1%).
Most strikingly, LIMI demonstrates 53.7% improvement over models trained on
10,000 samples-achieving superior agentic intelligence with 128 times fewer
samples. Our findings establish the Agency Efficiency Principle: machine
autonomy emerges not from data abundance but from strategic curation of
high-quality agentic demonstrations.

</details>


### [404] [Table2LaTeX-RL: High-Fidelity LaTeX Code Generation from Table Images via Reinforced Multimodal Language Models](https://arxiv.org/abs/2509.17589)
*Jun Ling,Yao Qi,Tao Huang,Shibo Zhou,Yanqin Huang,Jiang Yang,Ziqi Song,Ying Zhou,Yang Yang,Heng Tao Shen,Peng Wang*

Main category: cs.AI

TL;DR: 本文提出了一种强化多模态大语言模型框架，用于从复杂表格图像生成高质量LaTeX代码，通过双奖励强化学习策略优化生成质量，在复杂表格上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂表格（如大尺寸、深度嵌套结构、语义丰富或不规则单元格内容）上表现不佳，作者旨在自动化地从视觉输入重建高质量、可直接发布的表格。

Method: 作者提出了一个强化多模态大语言模型（MLLM）框架，通过在大规模表格到LaTeX数据集上微调预训练的MLLM，并引入基于Group Relative Policy Optimization（GRPO）的双奖励强化学习策略，结合结构级奖励和视觉保真度奖励来优化生成质量。

Result: 作者采用了结合TEDS-Structure和CW-SSIM的混合评估协议，证明了其方法在复杂表格上达到了最先进的性能。

Conclusion: 作者提出的基于强化多模态大语言模型（MLLM）的框架在复杂表格图像到LaTeX代码生成任务中表现出色，特别是在结构复杂的表格上，验证了方法的有效性和鲁棒性。

Abstract: In this work, we address the task of table image to LaTeX code generation,
with the goal of automating the reconstruction of high-quality,
publication-ready tables from visual inputs. A central challenge of this task
lies in accurately handling complex tables -- those with large sizes, deeply
nested structures, and semantically rich or irregular cell content -- where
existing methods often fail. We begin with a comprehensive analysis,
identifying key challenges and highlighting the limitations of current
evaluation protocols. To overcome these issues, we propose a reinforced
multimodal large language model (MLLM) framework, where a pre-trained MLLM is
fine-tuned on a large-scale table-to-LaTeX dataset. To further improve
generation quality, we introduce a dual-reward reinforcement learning strategy
based on Group Relative Policy Optimization (GRPO). Unlike standard approaches
that optimize purely over text outputs, our method incorporates both a
structure-level reward on LaTeX code and a visual fidelity reward computed from
rendered outputs, enabling direct optimization of the visual output quality. We
adopt a hybrid evaluation protocol combining TEDS-Structure and CW-SSIM, and
show that our method achieves state-of-the-art performance, particularly on
structurally complex tables, demonstrating the effectiveness and robustness of
our approach.

</details>


### [405] [EngiBench: A Benchmark for Evaluating Large Language Models on Engineering Problem Solving](https://arxiv.org/abs/2509.17677)
*Xiyuan Zhou,Xinlei Wang,Yirui He,Yang Wu,Ruixi Zou,Yuheng Cheng,Yulu Xie,Wenxuan Liu,Huan Zhao,Yan Xu,Jinjin Gu,Junhua Zhao*

Main category: cs.AI

TL;DR: EngiBench是一个新的分层基准测试，用于评估大语言模型在工程问题上的表现，结果显示当前模型在高级推理能力上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能捕捉工程问题的复杂性（如不确定性、上下文和开放式场景），需要一个新的评估框架来填补这一空白。

Method: 引入EngiBench，一个分层基准测试，覆盖三个难度级别（基础知识检索、多步上下文推理和开放式建模）和多个工程子领域。通过系统性地将每个问题改写为三个控制变体（扰动、知识增强和数学抽象），分别评估模型的鲁棒性、领域特定知识和数学推理能力。

Result: 实验结果显示，模型在任务难度增加时表现明显下降，问题稍有变化时表现更差，且在高级工程任务上远落后于人类专家。

Conclusion: 当前的大语言模型在解决现实工程问题时仍缺乏高级推理能力，需要未来开发具备更深层次和更可靠问题解决能力的模型。

Abstract: Large language models (LLMs) have shown strong performance on mathematical
reasoning under well-posed conditions. However, real-world engineering problems
require more than mathematical symbolic computation -- they need to deal with
uncertainty, context, and open-ended scenarios. Existing benchmarks fail to
capture these complexities. We introduce EngiBench, a hierarchical benchmark
designed to evaluate LLMs on solving engineering problems. It spans three
levels of increasing difficulty (foundational knowledge retrieval, multi-step
contextual reasoning, and open-ended modeling) and covers diverse engineering
subfields. To facilitate a deeper understanding of model performance, we
systematically rewrite each problem into three controlled variants (perturbed,
knowledge-enhanced, and math abstraction), enabling us to separately evaluate
the model's robustness, domain-specific knowledge, and mathematical reasoning
abilities. Experiment results reveal a clear performance gap across levels:
models struggle more as tasks get harder, perform worse when problems are
slightly changed, and fall far behind human experts on the high-level
engineering tasks. These findings reveal that current LLMs still lack the
high-level reasoning needed for real-world engineering, highlighting the need
for future models with deeper and more reliable problem-solving capabilities.
Our source code and data are available at
https://github.com/EngiBench/EngiBench.

</details>


### [406] [Virtual Arc Consistency for Linear Constraints inCost Function Networks](https://arxiv.org/abs/2509.17706)
*Pierre Montalbano,Simon de Givry,George Katsirelos*

Main category: cs.AI

TL;DR: 改进了处理线性约束的软弧一致性算法，提升了下限质量并减少求解时间。


<details>
  <summary>Details</summary>
Motivation: 探讨在约束编程中解决离散最小化问题的三种方法（软全局约束、线性规划重构和局部成本函数重构），重点关注第三种方法，即软弧一致性（SAC）算法，并提升其建模表达能力。

Method: 改进了现有的SAC算法，使其能够处理线性约束。

Result: 改进后的算法在多个基准测试中显著提高了下限，并在某些情况下减少了求解时间。

Conclusion: 通过将线性约束作为局部成本函数，改进了现有的软弧一致性（SAC）算法，显著提高了下限，并在某些情况下减少了求解时间。

Abstract: In Constraint Programming, solving discrete minimization problems with hard
and soft constraints can be done either using (i) soft global constraints, (ii)
a reformulation into a linear program, or (iii) a reformulation into local cost
functions. Approach (i) benefits from a vast catalog of constraints. Each soft
constraint propagator communicates with other soft constraints only through the
variable domains, resulting in weak lower bounds. Conversely, the approach (ii)
provides a global view with strong bounds, but the size of the reformulation
can be problematic. We focus on approach (iii) in which soft arc consistency
(SAC) algorithms produce bounds of intermediate quality. Recently, the
introduction of linear constraints as local cost functions increases their
modeling expressiveness. We adapt an existing SAC algorithm to handle linear
constraints. We show that our algorithm significantly improves the lower bounds
compared to the original algorithm on several benchmarks, reducing solving time
in some cases.

</details>


### [407] [DA-Mamba: Dialogue-aware selective state-space model for multimodal engagement estimation](https://arxiv.org/abs/2509.17711)
*Shenwei Kang,Xin Zhang,Wen Liu,Bin Li,Yujie Liu,Bo Gao*

Main category: cs.AI

TL;DR: DA-Mamba 是一种高效的多模态对话参与度估计模型，通过 Mamba 架构实现线性复杂度，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 估计对话场景中的人类参与度对自适应教学、远程医疗评估等应用至关重要，但现有方法计算复杂度高，难以实时处理长序列。

Method: DA-Mamba 采用三种核心模块：Dialogue-Aware Encoder 和两种 Mamba-based 融合机制（Modality-Group Fusion 和 Partner-Group Fusion），实现高效的跨模态推理。

Result: 在三个标准数据集（NoXi、NoXi-Add 和 MPIIGI）上，DA-Mamba 在 CCC 指标上超越现有 SOTA 方法，同时减少训练时间和内存占用。

Conclusion: DA-Mamba 通过引入 Mamba-based 选择性状态空间处理，显著提升了计算效率和性能，适用于资源受限的实时对话场景。

Abstract: Human engagement estimation in conversational scenarios is essential for
applications such as adaptive tutoring, remote healthcare assessment, and
socially aware human--computer interaction. Engagement is a dynamic, multimodal
signal conveyed by facial expressions, speech, gestures, and behavioral cues
over time. In this work we introduce DA-Mamba, a dialogue-aware multimodal
architecture that replaces attention-heavy dialogue encoders with Mamba-based
selective state-space processing to achieve linear time and memory complexity
while retaining expressive cross-modal reasoning. We design a Mamba
dialogue-aware selective state-space model composed of three core modules: a
Dialogue-Aware Encoder, and two Mamba-based fusion mechanisms: Modality-Group
Fusion and Partner-Group Fusion, these modules achieve expressive dialogue
understanding. Extensive experiments on three standard benchmarks (NoXi,
NoXi-Add, and MPIIGI) show that DA-Mamba surpasses prior state-of-the-art
(SOTA) methods in concordance correlation coefficient (CCC), while reducing
training time and peak memory; these gains enable processing much longer
sequences and facilitate real-time deployment in resource-constrained,
multi-party conversational settings. The source code will be available at:
https://github.com/kksssssss-ssda/MMEA.

</details>


### [408] [Efficient & Correct Predictive Equivalence for Decision Trees](https://arxiv.org/abs/2509.17774)
*Joao Marques-Silva,Alexey Ignatiev*

Main category: cs.AI

TL;DR: 本文揭示了QM方法在最坏情况下的指数级复杂度及MBDSR方法的潜在错误，并提出了多项式时间解决方案，实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 决策树中的Rashomon集合存在冗余，尤其是预测等价决策树的存在导致基于Rashomon集合的特征重要性不准确。McTavish等人提出的MBDSR方法虽然解决了多个计算问题，但其依赖的QM方法在最坏情况下具有指数级复杂度，且可能产生错误结果。本文旨在解决这些问题。

Method: 本文首先展示了存在触发QM方法最坏情况指数级运行时间和空间复杂度的决策树。其次，证明了MBDSR方法在判断预测等价性时可能产生错误结果。最后，证明了所有基于最小DNF表示的问题实际上都可以在决策树大小的多项式时间内解决。

Result: 实验结果表明，对于触发QM方法最坏情况的决策树，本文提出的算法比MBDSR方法快多个数量级。此外，本文证明了所有相关问题均可在多项式时间内解决。

Conclusion: 本文证明了QM方法在最坏情况下具有指数级的运行时间和空间复杂度，并指出MBDSR方法在判断预测等价性时可能产生错误结果。同时，研究表明所有基于最小DNF表示的问题实际上都可以在决策树大小的多项式时间内解决。实验验证了本文提出的算法在处理触发QM方法最坏情况的决策树时，比McTavish等人提出的算法快多个数量级。

Abstract: The Rashomon set of decision trees (DTs) finds importance uses. Recent work
showed that DTs computing the same classification function, i.e. predictive
equivalent DTs, can represent a significant fraction of the Rashomon set. Such
redundancy is undesirable. For example, feature importance based on the
Rashomon set becomes inaccurate due the existence of predictive equivalent DTs,
i.e. DTs with the same prediction for every possible input. In recent work,
McTavish et al. proposed solutions for several computational problems related
with DTs, including that of deciding predictive equivalent DTs. This approach,
which this paper refers to as MBDSR, consists of applying the well-known method
of Quine-McCluskey (QM) for obtaining minimum-size DNF (disjunctive normal
form) representations of DTs, which are then used for comparing DTs for
predictive equivalence. Furthermore, the minimum-size DNF representation was
also applied to computing explanations for the predictions made by DTs, and to
finding predictions in the presence of missing data. However, the problem of
formula minimization is hard for the second level of the polynomial hierarchy,
and the QM method may exhibit worst-case exponential running time and space.
This paper first demonstrates that there exist decision trees that trigger the
worst-case exponential running time and space of the QM method. Second, the
paper shows that the MBDSR approach can produce incorrect results for the
problem of deciding predictive equivalence. Third, the paper shows that any of
the problems to which the minimum-size DNF representation has been applied to
can in fact be solved in polynomial time, in the size of the DT. The
experiments confirm that, for DTs for which the the worst-case of the QM method
is triggered, the algorithms proposed in this paper are orders of magnitude
faster than the ones proposed by McTavish et al.

</details>


### [409] [Mitigating Strategy-Selection Bias in Reasoning for More Effective Test-Time Scaling](https://arxiv.org/abs/2509.17905)
*Zongqian Wu,Baoduo Xu,Tianyu Li,Zhu Sun,Xiaofeng Zhu,Lei Feng*

Main category: cs.AI

TL;DR: TTS-Uniform框架通过均匀分配采样预算和过滤不稳定策略，有效缓解了测试时扩展中的选择偏差问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视了测试时扩展中的选择偏差问题，即大型语言模型在生成推理过程时倾向于遵循某些策略，而忽略其他有效替代方案，导致解决方案空间探索不足。

Method: TTS-Uniform框架包括三个步骤：(i)识别潜在策略，(ii)均匀分配采样预算，(iii)过滤不稳定策略。

Result: 实验结果表明，TTS-Uniform显著提升了多个主流大型语言模型和基准数据集的扩展效果。

Conclusion: TTS-Uniform框架通过识别潜在策略、均匀分配采样预算并过滤不稳定策略，显著提升了主流大型语言模型在多个基准数据集上的扩展效果。

Abstract: Test-time scaling (TTS) has been shown to improve the performance of large
language models (LLMs) by sampling and aggregating diverse reasoning paths.
However, existing research has overlooked a critical issue: selection bias of
reasoning strategies during scaling. Specifically, when generating reasoning
processes, LLMs tend to follow certain strategies (e.g., algebraic solutions
for math problems) while neglecting other valid alternatives (e.g., geometric
solutions), resulting in insufficient exploration of the solution space. To
further understand the impact of this bias, we present a theoretical analysis
that reveals when it undermines the effectiveness of test-time scaling.
Motivated by this theoretical insight, we introduce TTS-Uniform, a framework
designed to mitigate the selection bias of reasoning strategies. It (i)
identifies potential strategies, (ii) uniformly allocates the sampling budget
across them, and (iii) filters out unstable strategies prior to aggregation.
Experimental results show that TTS-Uniform significantly enhances scaling
effectiveness across multiple mainstream LLMs and benchmark datasets.

</details>


### [410] [MEF: A Systematic Evaluation Framework for Text-to-Image Models](https://arxiv.org/abs/2509.17907)
*Xiaojing Dong,Weilin Huang,Liang Li,Yiying Li,Shu Liu,Tongtong Ou,Shuang Ouyang,Yu Tian,Fengxuan Zhao*

Main category: cs.AI

TL;DR: 本文提出了Magic Evaluation Framework (MEF)，一种系统且实用的文本到图像模型评估方法，结合ELO和MOS进行综合评估，并开源了评估框架和基准数据集Magic-Bench-377。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成评估方法集中在客观能力和维度上，但缺乏应用场景视角，限制了外部有效性。此外，当前的评估通常依赖于ELO进行整体排名或MOS进行维度特定评分，但两种方法都有固有的缺点和有限的解释性。

Method: 我们提出了一个结构化分类法，包括用户场景、元素、元素组合和文本表达形式，构建了Magic-Bench-377，支持标签级评估，并确保用户场景和能力的平衡覆盖。在此基础上，我们结合ELO和维度特定的MOS分别生成模型排名和细粒度评估。

Result: 通过应用MEF框架，我们获得了当前T2I模型的排行榜和领先模型的关键特征。

Conclusion: 通过应用MEF框架，我们不仅获得了当前T2I模型的排行榜，还揭示了领先模型的关键特征。我们将评估框架和Magic-Bench-377完全开源，以推动视觉生成模型评估的研究。

Abstract: Rapid advances in text-to-image (T2I) generation have raised higher
requirements for evaluation methodologies. Existing benchmarks center on
objective capabilities and dimensions, but lack an application-scenario
perspective, limiting external validity. Moreover, current evaluations
typically rely on either ELO for overall ranking or MOS for dimension-specific
scoring, yet both methods have inherent shortcomings and limited
interpretability. Therefore, we introduce the Magic Evaluation Framework (MEF),
a systematic and practical approach for evaluating T2I models. First, we
propose a structured taxonomy encompassing user scenarios, elements, element
compositions, and text expression forms to construct the Magic-Bench-377, which
supports label-level assessment and ensures a balanced coverage of both user
scenarios and capabilities. On this basis, we combine ELO and
dimension-specific MOS to generate model rankings and fine-grained assessments
respectively. This joint evaluation method further enables us to quantitatively
analyze the contribution of each dimension to user satisfaction using
multivariate logistic regression. By applying MEF to current T2I models, we
obtain a leaderboard and key characteristics of the leading models. We release
our evaluation framework and make Magic-Bench-377 fully open-source to advance
research in the evaluation of visual generative models.

</details>


### [411] [Orcust: Stepwise-Feedback Reinforcement Learning for GUI Agent](https://arxiv.org/abs/2509.17917)
*Junyu Lu,Songxin Zhang,Zejian Xie,Zhuoyang Song,Jiaxing Zhang*

Main category: cs.AI

TL;DR: Orcust框架通过PCRM和OVTC技术提升了GUI代理的推理可靠性和数据效率，实验显示其在多个基准测试中性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理模型在奖励信号不可靠和在线轨迹生成有限的情况下表现不佳，因此需要一种新方法来提升推理可靠性和数据效率。

Method: Orcust框架结合了Principle-Constrained Reward Modeling (PCRM)和Online VM-Grounded Trajectory Construction (OVTC)技术，利用环境可验证和LLM衍生的原则来强化可解释的奖励信号，并通过虚拟机器自主收集结构化GUI交互轨迹。

Result: Orcust在标准GUI基准测试中表现优异，ScreenSpot和ScreenSpot-Pro上的性能分别提升了22.2%和23.9%。

Conclusion: Orcust框架通过整合PCRM和OVTC技术，显著提升了GUI代理在交互任务中的推理可靠性和数据效率，实验证明其在多个基准测试中达到了最先进的性能。

Abstract: Recent advances in GUI agents have achieved remarkable grounding and
action-prediction performance, yet existing models struggle with unreliable
reward signals and limited online trajectory generation. In this paper, we
introduce Orcust, a framework that integrates Principle-Constrained Reward
Modeling (PCRM) and Online VM-Grounded Trajectory Construction (OVTC) to
enhance reasoning reliability and data efficiency in interactive GUI tasks. We
leverages environment-verifiable and LLM-derived principle to enforce
interpretable reward signals that constrain long chain-of-thought reasoning and
rule-based feedback. OVTC spins up instrumented virtual machines to
autonomously collect structured GUI interaction trajectories with explicit
procedural and structural objectives, enabling the training of a stepwise
reward model that robustly captures human preferences and adheres to
task-specific constraints. Extensive experiments on standard GUI benchmarks
covering perceptual grounding, foundational operations, and end-to-end task
execution reveal that Orcust achieves state-of-the-art performance, improving
by 22.2\% on ScreenSpot and 23.9\% on ScreenSpot-Pro over the base model (i.e.
Qwen2.5-VL-7B). The results demonstrate Orcust's effectiveness in enhancing the
reasoning, adaptability and scalability of GUI agents across various
environments and task complexities.

</details>


### [412] ["I think this is fair'': Uncovering the Complexities of Stakeholder Decision-Making in AI Fairness Assessment](https://arxiv.org/abs/2509.17956)
*Lin Luo,Yuri Nakao,Mathieu Chollet,Hiroya Inakoshi,Simone Stumpf*

Main category: cs.AI

TL;DR: 研究发现，非AI专家的利益相关者在评估AI公平性时比专家更复杂，强调了纳入他们判断的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有AI公平性评估主要由专家主导，缺乏对受影响但不具备AI专业知识的利益相关者如何评估公平性的了解。

Method: 通过定性研究，与30位无AI专业背景的利益相关者（代表信用评级场景中的潜在决策对象）进行访谈，探讨他们如何评估公平性。

Result: 利益相关者在公平性决策中考虑了超出法律保护的特征，定制化指标和更严格的阈值，甚至倾向于设计定制化公平性解决方案。

Conclusion: 研究表明，非AI专家的利益相关者在评估AI公平性时比专家考虑得更复杂，包括更多特征、定制化指标和更严格的阈值，强调了在AI公平性治理中纳入他们判断的重要性。

Abstract: Assessing fairness in artificial intelligence (AI) typically involves AI
experts who select protected features, fairness metrics, and set fairness
thresholds. However, little is known about how stakeholders, particularly those
affected by AI outcomes but lacking AI expertise, assess fairness. To address
this gap, we conducted a qualitative study with 30 stakeholders without AI
expertise, representing potential decision subjects in a credit rating
scenario, to examine how they assess fairness when placed in the role of
deciding on features with priority, metrics, and thresholds. We reveal that
stakeholders' fairness decisions are more complex than typical AI expert
practices: they considered features far beyond legally protected features,
tailored metrics for specific contexts, set diverse yet stricter fairness
thresholds, and even preferred designing customized fairness. Our results
extend the understanding of how stakeholders can meaningfully contribute to AI
fairness governance and mitigation, underscoring the importance of
incorporating stakeholders' nuanced fairness judgments.

</details>


### [413] [On the Variational Costs of Changing Our Minds](https://arxiv.org/abs/2509.17957)
*David Hyland,Mahault Albarracin*

Main category: cs.AI

TL;DR: 本文提出人类认知偏差是适应性反应，通过资源理性模型解释这些行为，并验证其解释力。


<details>
  <summary>Details</summary>
Motivation: 探讨人类为何在信念更新中表现出看似非理性的偏差，认为这些行为实质上是适应性的。

Method: 引入了一个形式化框架，将信念更新视为一种动机驱动的变分决策，通过计算实验验证模型的解释力。

Result: 模型能够定性地模拟常见的认知偏差行为，如确认偏误和态度极化。

Conclusion: 本文认为人类的认知偏差并非缺陷，而是适应性的反应，提出了一个资源理性的模型来解释这些现象。

Abstract: The human mind is capable of extraordinary achievements, yet it often appears
to work against itself. It actively defends its cherished beliefs even in the
face of contradictory evidence, conveniently interprets information to conform
to desired narratives, and selectively searches for or avoids information to
suit its various purposes. Despite these behaviours deviating from common
normative standards for belief updating, we argue that such 'biases' are not
inherently cognitive flaws, but rather an adaptive response to the significant
pragmatic and cognitive costs associated with revising one's beliefs. This
paper introduces a formal framework that aims to model the influence of these
costs on our belief updating mechanisms.
  We treat belief updating as a motivated variational decision, where agents
weigh the perceived 'utility' of a belief against the informational cost
required to adopt a new belief state, quantified by the Kullback-Leibler
divergence from the prior to the variational posterior. We perform
computational experiments to demonstrate that simple instantiations of this
resource-rational model can be used to qualitatively emulate commonplace human
behaviours, including confirmation bias and attitude polarisation. In doing so,
we suggest that this framework makes steps toward a more holistic account of
the motivated Bayesian mechanics of belief change and provides practical
insights for predicting, compensating for, and correcting deviations from
desired belief updating processes.

</details>


### [414] [The STAR-XAI Protocol: An Interactive Framework for Inducing Second-Order Agency in AI Agents](https://arxiv.org/abs/2509.17978)
*Antoni Guasch,Maria Isabel Valdez*

Main category: cs.AI

TL;DR: STAR-XAI协议通过结构化对话和校验机制，将不透明的大型推理模型转化为透明、可靠的AI代理，并在复杂任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大型推理模型（LRMs）在高复杂度、长时程任务中表现不可靠且不透明，存在“思维幻觉”问题。

Method: 通过结构化苏格拉底对话和交互式游戏循环，结合意识转移包（CTP）和状态锁定校验和，将LRM转化为“透明盒”代理。

Result: 在复杂策略游戏“Caps i Caps”的25步案例研究中，代理不仅解决了高复杂度难题，还展示了二阶代理能力，能够识别自身计划缺陷并动态调整完整性协议。

Conclusion: STAR-XAI协议为创建高性能、透明、可审计且值得信赖的AI代理提供了一条实用路径。

Abstract: Current Large Reasoning Models (LRMs) exhibit significant limitations in
reliability and transparency, often showing a collapse in reasoning
capabilities when faced with high-complexity, long-horizon tasks. This
"illusion of thinking" is frequently an artifact of non-agentic, black-box
evaluation paradigms that fail to cultivate robust problem-solving processes.
In response, we introduce The STAR-XAI Protocol (Socratic, Transparent,
Agentic, Reasoning - for eXplainable Artificial Intelligence), a novel
methodology for training and operating verifiably reliable AI agents. Our
method reframes the human-AI interaction as a structured, Socratic dialogue,
governed by an explicit and evolving rulebook, the Consciousness Transfer
Package (CTP). Through an interactive Gameplay Cycle that enforces ante-hoc
strategic justification and a state-locking Checksum that prevents error
accumulation, the protocol transforms a powerful but opaque LRM into a
disciplined "Clear Box" agent. We demonstrate the efficacy of this method
through an exhaustive 25-move case study in the complex strategic game "Caps i
Caps". The agent not only solved the high-complexity puzzle but also
demonstrated Second-Order Agency, identifying flaws in its own
supervisor-approved plans and adapting its core integrity protocols mid-task.
The STAR-XAI Protocol offers a practical pathway to creating AI agents that are
not just high-performing, but also transparent, auditable, and trustworthy by
design.

</details>


### [415] [Improving Large Language Models Function Calling and Interpretability via Guided-Structured Templates](https://arxiv.org/abs/2509.18076)
*Hy Dang,Tianyi Liu,Zhuofeng Wu,Jingfeng Yang,Haoming Jiang,Tao Yang,Pei Chen,Zhengyang Wang,Helen Wang,Huasheng Li,Bing Yin,Meng Jiang*

Main category: cs.AI

TL;DR: 论文提出结构化推理模板框架，通过课程学习优化LLMs工具调用，减少错误并提升性能。


<details>
  <summary>Details</summary>
Motivation: LLMs在真实工具交互中常因参数错误、工具选择不当或用户意图误解而失败，现有自由形式的CoT提示对此类结构化任务效果有限。

Method: 引入了一种课程启发式的框架，利用结构化推理模板指导LLMs生成更精确的函数调用。

Result: 实验表明，该方法在多种模型系列和基准上相对强基线实现了3-12%的错误率降低。

Conclusion: 论文提出了一种基于课程学习的结构化推理模板框架，显著减少了LLMs在工具交互中的错误，提升了代理的鲁棒性、可解释性和透明度，推动了更可靠AI助手的发展。

Abstract: Large language models (LLMs) have demonstrated strong reasoning and tool-use
capabilities, yet they often fail in real-world tool-interactions due to
incorrect parameterization, poor tool selection, or misinterpretation of user
intent. These issues often stem from an incomplete understanding of user goals
and inadequate comprehension of tool documentation. While Chain-of-Thought
(CoT) prompting has proven effective for enhancing reasoning in general
contexts, our analysis reveals that free-form CoT is insufficient and sometimes
counterproductive for structured function-calling tasks. To address this, we
introduce a curriculum-inspired framework that leverages structured reasoning
templates to guide LLMs through more deliberate step-by-step instructions for
generating function callings. Experimental results show that our method reduces
tool-use errors, achieving 3-12% relative improvements over strong baselines
across diverse model series and approaches. Moreover, our framework enhances
the robustness, interpretability, and transparency of tool-using agents,
advancing the development of more reliable AI assistants for real-world
applications.

</details>


### [416] [Reasoning Core: A Scalable RL Environment for LLM Symbolic Reasoning](https://arxiv.org/abs/2509.18083)
*Valentin Lacombe,Valentin Quesnel,Damien Sileo*

Main category: cs.AI

TL;DR: Reasoning Core是一个新的RLVR环境，通过程序生成多样化问题评估和提升LLMs的符号推理能力，初步测试显示任务难度高。


<details>
  <summary>Details</summary>
Motivation: 现有基准多集中于游戏或孤立谜题，缺乏对LLMs基础符号推理能力的系统性评估和提升。

Method: 通过程序生成问题，涵盖PDDL规划、一阶逻辑、上下文无关语法解析、因果推理和系统方程求解等核心形式领域。环境设计基于高通用性问题分布、外部工具验证和连续难度控制原则。

Result: 初步零样本评估显示，前沿LLMs在Reasoning Core任务上表现困难，表明其作为提升未来模型推理能力的有效资源。

Conclusion: Reasoning Core为大型语言模型（LLMs）提供了一个可扩展的强化学习环境，专注于验证奖励（RLVR），旨在提升其基础符号推理能力。

Abstract: We introduce Reasoning Core, a new scalable environment for Reinforcement
Learning with Verifiable Rewards (RLVR), designed to advance foundational
symbolic reasoning in Large Language Models (LLMs). Unlike existing benchmarks
that focus on games or isolated puzzles, Reasoning Core procedurally generates
problems across core formal domains, including PDDL planning, first-order
logic, context-free grammar parsing, causal reasoning, and system equation
solving. The environment is built on key design principles of high-generality
problem distributions, verification via external tools, and continuous
difficulty control, which together provide a virtually infinite supply of novel
training instances. Initial zero-shot evaluations with frontier LLMs confirm
the difficulty of Reasoning Core's tasks, positioning it as a promising
resource to improve the reasoning capabilities of future models.

</details>
