<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 86]
- [cs.AI](#cs.AI) [Total: 36]
- [cs.DS](#cs.DS) [Total: 1]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.GR](#cs.GR) [Total: 9]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.RO](#cs.RO) [Total: 49]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Leveraging NTPs for Efficient Hallucination Detection in VLMs](https://arxiv.org/abs/2509.20379)
*Ofir Azachi,Kfir Eliyahu,Eyal El Ani,Rom Himelstein,Roi Reichart,Yuval Pinter,Nitay Calderon*

Main category: cs.CV

TL;DR: 提出了一种基于NTP的轻量级幻觉检测方法，结合语言NTP和VLM预测分数，显著提升了检测性能，为VLM的可靠性提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的幻觉问题（视觉内容与生成文本之间的不匹配）严重影响了其可靠性。现有的检测方法通常依赖VLM自身或其他模型，计算成本高且增加延迟。

Method: 提出了一种基于VLM的下一词概率（NTP）的轻量级方法，通过训练传统机器学习模型来检测幻觉。此外，还引入了语言NTP和VLM的幻觉预测分数作为增强特征。

Result: 实验结果表明，NTP特征是有效的幻觉预测指标，轻量级模型的性能可与强VLM相媲美。结合语言NTP和VLM预测分数进一步提升了检测性能。

Conclusion: 本研究为提升视觉语言模型（VLM）的可靠性提供了一种简单、轻量级的解决方案，通过结合NTP特征和VLM的幻觉预测分数，显著提高了幻觉检测性能。

Abstract: Hallucinations of vision-language models (VLMs), which are misalignments
between visual content and generated text, undermine the reliability of VLMs.
One common approach for detecting them employs the same VLM, or a different
one, to assess generated outputs. This process is computationally intensive and
increases model latency. In this paper, we explore an efficient on-the-fly
method for hallucination detection by training traditional ML models over
signals based on the VLM's next-token probabilities (NTPs). NTPs provide a
direct quantification of model uncertainty. We hypothesize that high
uncertainty (i.e., a low NTP value) is strongly associated with hallucinations.
To test this, we introduce a dataset of 1,400 human-annotated statements
derived from VLM-generated content, each labeled as hallucinated or not, and
use it to test our NTP-based lightweight method. Our results demonstrate that
NTP-based features are valuable predictors of hallucinations, enabling fast and
simple ML models to achieve performance comparable to that of strong VLMs.
Furthermore, augmenting these NTPs with linguistic NTPs, computed by feeding
only the generated text back into the VLM, enhances hallucination detection
performance. Finally, integrating hallucination prediction scores from VLMs
into the NTP-based models led to better performance than using either VLMs or
NTPs alone. We hope this study paves the way for simple, lightweight solutions
that enhance the reliability of VLMs.

</details>


### [2] [Quasi-Synthetic Riemannian Data Generation for Writer-Independent Offline Signature Verification](https://arxiv.org/abs/2509.20420)
*Elias N. Zois,Moises Diaz,Salem Said,Miguel A. Ferrer*

Main category: cs.CV

TL;DR: 研究提出了一种基于黎曼几何的准合成数据生成框架，用于独立于作者的签名验证，实验证明其在真实数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 离线手写签名验证在独立于作者的设置中具有挑战性，需要模型能够泛化到未见过的个体。传统方法通常依赖真实签名数据集进行分类器训练，而本研究旨在通过黎曼几何生成合成数据来解决这一问题。

Method: 引入了一个准合成数据生成框架，利用对称正定矩阵（SPD）的黎曼几何。通过黎曼高斯混合模型识别黎曼中心作为合成作者，方差作为其属性，并在每个中心上进行黎曼高斯采样生成正负SPD群体。随后通过度量学习框架利用相似和不相似的SPD点对进行测试。

Result: 在两个流行的签名数据集（涵盖西方和亚洲书写风格）上的实验表明，该方法在数据集内和跨数据集评估协议下均有效，实现了低错误率。

Conclusion: 该研究展示了在黎曼空间中生成合成数据用于独立于作者的签名验证系统的潜力，实现了低错误率。

Abstract: Offline handwritten signature verification remains a challenging task,
particularly in writer-independent settings where models must generalize across
unseen individuals. Recent developments have highlighted the advantage of
geometrically inspired representations, such as covariance descriptors on
Riemannian manifolds. However, past or present, handcrafted or data-driven
methods usually depend on real-world signature datasets for classifier
training. We introduce a quasi-synthetic data generation framework leveraging
the Riemannian geometry of Symmetric Positive Definite matrices (SPD). A small
set of genuine samples in the SPD space is the seed to a Riemannian Gaussian
Mixture which identifies Riemannian centers as synthetic writers and variances
as their properties. Riemannian Gaussian sampling on each center generates
positive as well as negative synthetic SPD populations. A metric learning
framework utilizes pairs of similar and dissimilar SPD points, subsequently
testing it over on real-world datasets. Experiments conducted on two popular
signature datasets, encompassing Western and Asian writing styles, demonstrate
the efficacy of the proposed approach under both intra- and cross- dataset
evaluation protocols. The results indicate that our quasi-synthetic approach
achieves low error rates, highlighting the potential of generating synthetic
data in Riemannian spaces for writer-independent signature verification
systems.

</details>


### [3] [Seedream 4.0: Toward Next-generation Multimodal Image Generation](https://arxiv.org/abs/2509.20427)
*Team Seedream,Yunpeng Chen,Yu Gao,Lixue Gong,Meng Guo,Qiushan Guo,Zhiyao Guo,Xiaoxia Hou,Weilin Huang,Yixuan Huang,Xiaowen Jian,Huafeng Kuang,Zhichao Lai,Fanshi Li,Liang Li,Xiaochen Lian,Chao Liao,Liyang Liu,Wei Liu,Yanzuo Lu,Zhengxiong Luo,Tongtong Ou,Guang Shi,Yichun Shi,Shiqi Sun,Yu Tian,Zhi Tian,Peng Wang,Rui Wang,Xun Wang,Ye Wang,Guofeng Wu,Jie Wu,Wenxu Wu,Yonghui Wu,Xin Xia,Xuefeng Xiao,Shuang Xu,Xin Yan,Ceyuan Yang,Jianchao Yang,Zhonghua Zhai,Chenlin Zhang,Heng Zhang,Qi Zhang,Xinyu Zhang,Yuwei Zhang,Shijia Zhao,Wenliang Zhao,Wenjia Zhu*

Main category: cs.CV

TL;DR: Seedream 4.0 是一个高效的多模态图像生成系统，结合扩散变换器和VAE，支持快速生成高分辨率图像，并在T2I和图像编辑任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 旨在构建一个高效、高性能的多模态图像生成系统，统一文本到图像合成、图像编辑和多图像组合功能，提升生成式AI的交互性和多维性。

Method: 开发了高效的扩散变换器和VAE，减少了图像令牌数量，支持高效训练和快速生成高分辨率图像。结合多模态后训练和推理加速技术（如对抗蒸馏、分布匹配、量化和推测解码），实现了快速的图像生成。

Result: 在T2I和多模态图像编辑任务中达到最先进水平，生成2K图像仅需1.8秒，支持复杂任务如精确图像编辑和上下文推理。

Conclusion: Seedream 4.0 通过高效的扩散变换器和强大的VAE，实现了文本到图像生成、图像编辑和多图像组合的统一框架，显著提升了生成效率和质量。其在多模态任务中表现出色，扩展了生成式AI的边界，适用于创意和专业应用。

Abstract: We introduce Seedream 4.0, an efficient and high-performance multimodal image
generation system that unifies text-to-image (T2I) synthesis, image editing,
and multi-image composition within a single framework. We develop a highly
efficient diffusion transformer with a powerful VAE which also can reduce the
number of image tokens considerably. This allows for efficient training of our
model, and enables it to fast generate native high-resolution images (e.g.,
1K-4K). Seedream 4.0 is pretrained on billions of text-image pairs spanning
diverse taxonomies and knowledge-centric concepts. Comprehensive data
collection across hundreds of vertical scenarios, coupled with optimized
strategies, ensures stable and large-scale training, with strong
generalization. By incorporating a carefully fine-tuned VLM model, we perform
multi-modal post-training for training both T2I and image editing tasks
jointly. For inference acceleration, we integrate adversarial distillation,
distribution matching, and quantization, as well as speculative decoding. It
achieves an inference time of up to 1.8 seconds for generating a 2K image
(without a LLM/VLM as PE model). Comprehensive evaluations reveal that Seedream
4.0 can achieve state-of-the-art results on both T2I and multimodal image
editing. In particular, it demonstrates exceptional multimodal capabilities in
complex tasks, including precise image editing and in-context reasoning, and
also allows for multi-image reference, and can generate multiple output images.
This extends traditional T2I systems into an more interactive and
multidimensional creative tool, pushing the boundary of generative AI for both
creativity and professional applications. Seedream 4.0 is now accessible on
https://www.volcengine.com/experience/ark?launch=seedream.

</details>


### [4] [A Contrastive Learning Framework for Breast Cancer Detection](https://arxiv.org/abs/2509.20474)
*Samia Saeed,Khuram Naveed*

Main category: cs.CV

TL;DR: 该研究通过对比学习框架优化乳腺癌检测，在有限标注数据下实现96.7%的高准确率。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球第二大癌症死亡原因，早期检测对治疗结果至关重要。传统计算机辅助检测系统依赖传统图像分析，而深度学习虽更有效但受限于标注数据不足。

Method: 采用半监督对比学习方法，结合Resnet-50模型和相似性指数，利用大量未标记的乳腺X光数据进行训练，并通过数据增强和转换优化性能。

Result: 在INbreast和MIAS基准数据集上实现了96.7%的检测准确率，优于现有技术。

Conclusion: 该研究提出的对比学习框架在有限标注数据集下显著提升了乳腺癌检测的准确性，达到了96.7%的准确率。

Abstract: Breast cancer, the second leading cause of cancer-related deaths globally,
accounts for a quarter of all cancer cases [1]. To lower this death rate, it is
crucial to detect tumors early, as early-stage detection significantly improves
treatment outcomes. Advances in non-invasive imaging techniques have made early
detection possible through computer-aided detection (CAD) systems which rely on
traditional image analysis to identify malignancies. However, there is a
growing shift towards deep learning methods due to their superior
effectiveness. Despite their potential, deep learning methods often struggle
with accuracy due to the limited availability of large-labeled datasets for
training. To address this issue, our study introduces a Contrastive Learning
(CL) framework, which excels with smaller labeled datasets. In this regard, we
train Resnet-50 in semi supervised CL approach using similarity index on a
large amount of unlabeled mammogram data. In this regard, we use various
augmentation and transformations which help improve the performance of our
approach. Finally, we tune our model on a small set of labelled data that
outperforms the existing state of the art. Specifically, we observed a 96.7%
accuracy in detecting breast cancer on benchmark datasets INbreast and MIAS.

</details>


### [5] [Are Foundation Models Ready for Industrial Defect Recognition? A Reality Check on Real-World Data](https://arxiv.org/abs/2509.20479)
*Simon Baeuerle,Pratik Khanna,Nils Friederich,Angelo Jovin Yamachui Sitcheu,Damir Shakirov,Andreas Steimer,Ralf Mikut*

Main category: cs.CV

TL;DR: 基础模型（FMs）在零样本设置下表现出色，但在实际工业图像数据上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 利用基础模型（FMs）替代监督式AI模型，以简化自动化质量检测中的模型设置和实施。

Method: 测试多种最新基础模型（FMs）在自定义工业图像数据和公共图像数据上的表现。

Result: 所有测试模型在实际工业数据上失败，但在公共基准数据集上表现良好。

Conclusion: 基础模型（FMs）在实际工业应用中的适用性有限，需进一步改进。

Abstract: Foundation Models (FMs) have shown impressive performance on various text and
image processing tasks. They can generalize across domains and datasets in a
zero-shot setting. This could make them suitable for automated quality
inspection during series manufacturing, where various types of images are being
evaluated for many different products. Replacing tedious labeling tasks with a
simple text prompt to describe anomalies and utilizing the same models across
many products would save significant efforts during model setup and
implementation. This is a strong advantage over supervised Artificial
Intelligence (AI) models, which are trained for individual applications and
require labeled training data. We test multiple recent FMs on both custom
real-world industrial image data and public image data. We show that all of
those models fail on our real-world data, while the very same models perform
well on public benchmark datasets.

</details>


### [6] [Shared Neural Space: Unified Precomputed Feature Encoding for Multi-Task and Cross Domain Vision](https://arxiv.org/abs/2509.20481)
*Jing Li,Oskar Bartosz,Chengyu Wang,Michal Wnuczynski,Dilshan Godaliyadda,Michael Polley*

Main category: cs.CV

TL;DR: 提出通用神经空间（NS），通过共享特征空间提高多任务视觉管道的效率，减少冗余并增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对当前AI模型在模块化任务应用中的低效问题，因为每个任务都需要映射到不同的潜在域。

Method: 采用编码器-解码器框架预计算跨视觉和成像任务的特征，编码器学习具有变换感知和泛化能力的表示。

Result: 实验证明，成像和视觉模块（如去马赛克、去噪、深度估计和语义分割）可以在NS中高效执行。

Conclusion: 提出的通用神经空间（NS）通过共享特征空间减少了冗余，提高了跨域泛化能力，并为高效的多任务视觉管道奠定了基础。

Abstract: The majority of AI models in imaging and vision are customized to perform on
specific high-precision task. However, this strategy is inefficient for
applications with a series of modular tasks, since each requires a mapping into
a disparate latent domain. To address this inefficiency, we proposed a
universal Neural Space (NS), where an encoder-decoder framework pre-computes
features across vision and imaging tasks. Our encoder learns transformation
aware, generalizable representations, which enable multiple downstream AI
modules to share the same feature space. This architecture reduces redundancy,
improves generalization across domain shift, and establishes a foundation for
effecient multi-task vision pipelines. Furthermore, as opposed to larger
transformer backbones, our backbone is lightweight and CNN-based, allowing for
wider across hardware. We furthur demonstrate that imaging and vision modules,
such as demosaicing, denoising, depth estimation and semantic segmentation can
be performed efficiently in the NS.

</details>


### [7] [Data-Efficient Stream-Based Active Distillation for Scalable Edge Model Deployment](https://arxiv.org/abs/2509.20484)
*Dani Manjah,Tim Bary,Benoît Gérin,Benoît Macq,Christophe de Vleeschouwer*

Main category: cs.CV

TL;DR: 研究提出结合高置信度和多样性策略的图像选择方法，以最少查询生成高质量边缘模型。


<details>
  <summary>Details</summary>
Motivation: 边缘相机系统需要定期更新模型，但边缘设备计算能力有限，需通过中央服务器标注数据来训练小型模型。如何选择最有用的图像以最大化模型质量并降低传输成本是关键问题。

Method: 采用高置信度流式策略与多样性方法结合的图像选择策略。

Result: 在相似训练负载下，高置信度流式策略与多样性方法结合能生成高质量模型，且数据集查询次数最少。

Conclusion: 结合高置信度流式策略和多样性方法，可以在保持训练负载相似的情况下，以最少的数据集查询生成高质量模型。

Abstract: Edge camera-based systems are continuously expanding, facing ever-evolving
environments that require regular model updates. In practice, complex teacher
models are run on a central server to annotate data, which is then used to
train smaller models tailored to the edge devices with limited computational
power. This work explores how to select the most useful images for training to
maximize model quality while keeping transmission costs low. Our work shows
that, for a similar training load (i.e., iterations), a high-confidence
stream-based strategy coupled with a diversity-based approach produces a
high-quality model with minimal dataset queries.

</details>


### [8] [InstructVTON: Optimal Auto-Masking and Natural-Language-Guided Interactive Style Control for Inpainting-Based Virtual Try-On](https://arxiv.org/abs/2509.20524)
*Julien Han,Shuwen Qiu,Qi Li,Xingzi Xu,Mehmet Saygin Seyfioglu,Kavosh Asadi,Karim Bouyarmane*

Main category: cs.CV

TL;DR: InstructVTON是一个基于指令的虚拟试穿系统，通过视觉语言模型和图像分割自动生成掩码，简化操作并实现复杂样式控制，与现有模型结合达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于掩码的虚拟试穿方法需要精确绘制掩码，且在某些复杂样式控制场景下难以实现，限制了用户体验和生成效果。

Method: 利用视觉语言模型（VLMs）和图像分割模型自动生成二进制掩码，基于用户提供的图像和自由文本样式指令进行虚拟试穿。

Result: InstructVTON能够自动化生成掩码并执行多轮图像生成，简化了用户操作，同时实现了对生成结果的精细控制，与现有模型结合达到了最先进的性能。

Conclusion: InstructVTON通过结合视觉语言模型和图像分割技术，简化了虚拟试穿的流程，并实现了对生成结果的精细控制，展示了与现有模型的互操作性，达到了最先进的水平。

Abstract: We present InstructVTON, an instruction-following interactive virtual try-on
system that allows fine-grained and complex styling control of the resulting
generation, guided by natural language, on single or multiple garments. A
computationally efficient and scalable formulation of virtual try-on formulates
the problem as an image-guided or image-conditioned inpainting task. These
inpainting-based virtual try-on models commonly use a binary mask to control
the generation layout. Producing a mask that yields desirable result is
difficult, requires background knowledge, might be model dependent, and in some
cases impossible with the masking-based approach (e.g. trying on a long-sleeve
shirt with "sleeves rolled up" styling on a person wearing long-sleeve shirt
with sleeves down, where the mask will necessarily cover the entire sleeve).
InstructVTON leverages Vision Language Models (VLMs) and image segmentation
models for automated binary mask generation. These masks are generated based on
user-provided images and free-text style instructions. InstructVTON simplifies
the end-user experience by removing the necessity of a precisely drawn mask,
and by automating execution of multiple rounds of image generation for try-on
scenarios that cannot be achieved with masking-based virtual try-on models
alone. We show that InstructVTON is interoperable with existing virtual try-on
models to achieve state-of-the-art results with styling control.

</details>


### [9] [Innovative Deep Learning Architecture for Enhanced Altered Fingerprint Recognition](https://arxiv.org/abs/2509.20537)
*Dana A Abdullah,Dana Rasul Hamad,Bishar Rasheed Ibrahim,Sirwan Abdulwahid Aula,Aso Khaleel Ameen,Sabat Salih Hamadamin*

Main category: cs.CV

TL;DR: DeepAFRNet通过VGG16和余弦相似度有效识别 altered fingerprints，严格阈值下高准确率，实际部署潜力大。


<details>
  <summary>Details</summary>
Motivation: altered fingerprints 在边境控制、法医学等应用中可能被故意修改以逃避检测，因此需要鲁棒的识别方法。

Method: 采用VGG16骨干网络提取高维特征，并使用余弦相似度比较嵌入向量，评估基于SOCOFing Real-Altered子集的三个难度级别。

Result: 在严格阈值下，DeepAFRNet在Easy、Medium、Hard级别分别达到96.7%、98.76%、99.54%的准确率；阈值放宽后准确率显著下降。

Conclusion: DeepAFRNet展示了在处理 altered fingerprints 时的高准确率，特别是在严格阈值下，适用于实际部署，强调了阈值选择对生物识别系统的重要性。

Abstract: Altered fingerprint recognition (AFR) is challenging for biometric
verification in applications such as border control, forensics, and fiscal
admission. Adversaries can deliberately modify ridge patterns to evade
detection, so robust recognition of altered prints is essential. We present
DeepAFRNet, a deep learning recognition model that matches and recognizes
distorted fingerprint samples. The approach uses a VGG16 backbone to extract
high-dimensional features and cosine similarity to compare embeddings. We
evaluate on the SOCOFing Real-Altered subset with three difficulty levels
(Easy, Medium, Hard). With strict thresholds, DeepAFRNet achieves accuracies of
96.7 percent, 98.76 percent, and 99.54 percent for the three levels. A
threshold-sensitivity study shows that relaxing the threshold from 0.92 to 0.72
sharply degrades accuracy to 7.86 percent, 27.05 percent, and 29.51 percent,
underscoring the importance of threshold selection in biometric systems. By
using real altered samples and reporting per-level metrics, DeepAFRNet
addresses limitations of prior work based on synthetic alterations or limited
verification protocols, and indicates readiness for real-world deployments
where both security and recognition resilience are critical.

</details>


### [10] [Large Pre-Trained Models for Bimanual Manipulation in 3D](https://arxiv.org/abs/2509.20579)
*Hanna Yurchyk,Wei-Di Chang,Gregory Dudek,David Meger*

Main category: cs.CV

TL;DR: 该研究通过将ViT的注意力图转化为3D体素语义线索，提升了双手机器人操作的性能，绝对增益8.2%。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用预训练视觉模型的注意力图来增强双手机器人操作的语义理解和性能。

Method: 从自监督ViT模型DINOv2中提取注意力图，并将其解释为RGB图像的像素级显著性分数，然后将这些图提升到3D体素网格中，生成体素级语义线索，并将其整合到行为克隆策略中。

Result: 在RLBench双操作基准测试中，注意力引导的特征化使平均绝对性能提升了8.2%，相对增益达到21.9%。

Conclusion: 通过将预训练的Vision Transformer的注意力图集成到体素表示中，显著提升了双手机器人操作的性能。

Abstract: We investigate the integration of attention maps from a pre-trained Vision
Transformer into voxel representations to enhance bimanual robotic
manipulation. Specifically, we extract attention maps from DINOv2, a
self-supervised ViT model, and interpret them as pixel-level saliency scores
over RGB images. These maps are lifted into a 3D voxel grid, resulting in
voxel-level semantic cues that are incorporated into a behavior cloning policy.
When integrated into a state-of-the-art voxel-based policy, our
attention-guided featurization yields an average absolute improvement of 8.2%
and a relative gain of 21.9% across all tasks in the RLBench bimanual
benchmark.

</details>


### [11] [A Comparative Benchmark of Real-time Detectors for Blueberry Detection towards Precision Orchard Management](https://arxiv.org/abs/2509.20580)
*Xinyang Mu,Yuzhen Lu,Boyang Deng*

Main category: cs.CV

TL;DR: 本研究比较了多种实时目标检测模型在蓝莓检测中的表现，YOLOv12m和RT-DETRv2-X表现最佳，并通过SSL微调进一步提升了准确性。数据集和代码已开源。


<details>
  <summary>Details</summary>
Motivation: 由于光照变化、遮挡和运动模糊等因素，蓝莓检测在自然环境中具有挑战性。深度学习模型需要大规模多样化数据集来应对这些复杂性，并在实际应用中平衡准确性、速度和内存需求。

Method: 本研究比较了YOLO（v8-v12）和RT-DETR（v1-v2）家族的36种模型变体，并在新构建的蓝莓检测数据集上进行了评估，随后使用无偏均值教师半监督学习（SSL）对模型进行了微调。

Result: YOLOv12m和RT-DETRv2-X分别以93.3%和93.6%的mAP@50表现最佳。通过SSL微调后，RT-DETR-v2-X的mAP@50提升至94.8%。中等规模模型在准确性和速度之间表现最佳。

Conclusion: 蓝莓检测在自然环境中仍具挑战性，但通过深度学习和半监督学习技术，本研究提出的模型在准确性和速度之间取得了良好平衡。数据集和软件程序已公开以支持进一步研究。

Abstract: Blueberry detection in natural environments remains challenging due to
variable lighting, occlusions, and motion blur due to environmental factors and
imaging devices. Deep learning-based object detectors promise to address these
challenges, but they demand a large-scale, diverse dataset that captures the
real-world complexities. Moreover, deploying these models in practical
scenarios often requires the right accuracy/speed/memory trade-off in model
selection. This study presents a novel comparative benchmark analysis of
advanced real-time object detectors, including YOLO (You Only Look Once)
(v8-v12) and RT-DETR (Real-Time Detection Transformers) (v1-v2) families,
consisting of 36 model variants, evaluated on a newly curated dataset for
blueberry detection. This dataset comprises 661 canopy images collected with
smartphones during the 2022-2023 seasons, consisting of 85,879 labelled
instances (including 36,256 ripe and 49,623 unripe blueberries) across a wide
range of lighting conditions, occlusions, and fruit maturity stages. Among the
YOLO models, YOLOv12m achieved the best accuracy with a mAP@50 of 93.3%, while
RT-DETRv2-X obtained a mAP@50 of 93.6%, the highest among all the RT-DETR
variants. The inference time varied with the model scale and complexity, and
the mid-sized models appeared to offer a good accuracy-speed balance. To
further enhance detection performance, all the models were fine-tuned using
Unbiased Mean Teacher-based semi-supervised learning (SSL) on a separate set of
1,035 unlabeled images acquired by a ground-based machine vision platform in
2024. This resulted in accuracy gains ranging from -1.4% to 2.9%, with
RT-DETR-v2-X achieving the best mAP@50 of 94.8%. More in-depth research into
SSL is needed to better leverage cross-domain unlabeled data. Both the dataset
and software programs of this study are made publicly available to support
further research.

</details>


### [12] [Region-of-Interest Augmentation for Mammography Classification under Patient-Level Cross-Validation](https://arxiv.org/abs/2509.20585)
*Farbod Bigdeli,Mohsen Mohammadagha,Ali Bigdeli*

Main category: cs.CV

TL;DR: 通过轻量级ROI增强策略提升乳腺X光片分类性能，无需额外标签或架构修改。


<details>
  <summary>Details</summary>
Motivation: 乳腺X光筛查在早期检测和降低死亡率中至关重要，但深度学习在自动化解读方面仍受限于低分辨率数据集和小样本量。

Method: 采用轻量级的ROI增强策略，在训练过程中随机替换全图为预计算的、无标签边界框库中的随机ROI裁剪，并可选抖动以增加变异性。

Result: 在Mini-DDSM数据集上，ROI增强（最佳参数：p_roi = 0.10, alpha = 0.10）带来了ROC-AUC的适度提升，但PR-AUC表现持平或略有下降。

Conclusion: 研究表明，简单的、以数据为中心的ROI策略可以在不增加额外标签或架构修改的情况下，在受限环境中提升乳腺X光片分类的性能。

Abstract: Breast cancer screening with mammography remains central to early detection
and mortality reduction. Deep learning has shown strong potential for
automating mammogram interpretation, yet limited-resolution datasets and small
sample sizes continue to restrict performance. We revisit the Mini-DDSM dataset
(9,684 images; 2,414 patients) and introduce a lightweight region-of-interest
(ROI) augmentation strategy. During training, full images are probabilistically
replaced with random ROI crops sampled from a precomputed, label-free
bounding-box bank, with optional jitter to increase variability. We evaluate
under strict patient-level cross-validation and report ROC-AUC, PR-AUC, and
training-time efficiency metrics (throughput and GPU memory). Because ROI
augmentation is training-only, inference-time cost remains unchanged. On
Mini-DDSM, ROI augmentation (best: p_roi = 0.10, alpha = 0.10) yields modest
average ROC-AUC gains, with performance varying across folds; PR-AUC is flat to
slightly lower. These results demonstrate that simple, data-centric ROI
strategies can enhance mammography classification in constrained settings
without requiring additional labels or architectural modifications.

</details>


### [13] [Reflect3r: Single-View 3D Stereo Reconstruction Aided by Mirror Reflections](https://arxiv.org/abs/2509.20607)
*Jing Wu,Zirui Wang,Iro Laina,Victor Adrian Prisacariu*

Main category: cs.CV

TL;DR: 利用镜像反射作为虚拟视角，通过物理有效的变换和对称感知损失，实现了单张图像的多视角3D重建，简化了成像过程。


<details>
  <summary>Details</summary>
Motivation: 镜像反射在日常环境中常见，能在单次拍摄中提供立体信息，为简化3D重建过程提供了可能性。

Method: 提出了一种将镜像反射视为辅助视角的变换方法，构建物理有效的虚拟相机，并设计了对称感知损失以优化姿态估计。

Result: 在真实和合成数据上的大量实验证明了该方法的有效性，特别是在动态场景中实现了高效的逐帧几何恢复。

Conclusion: 通过利用镜像反射作为辅助视角，并设计物理有效的虚拟相机变换，该方法简化了成像过程，实现了从单张图像进行多视角立体匹配，提升了3D重建的泛化性和鲁棒性。

Abstract: Mirror reflections are common in everyday environments and can provide stereo
information within a single capture, as the real and reflected virtual views
are visible simultaneously. We exploit this property by treating the reflection
as an auxiliary view and designing a transformation that constructs a
physically valid virtual camera, allowing direct pixel-domain generation of the
virtual view while adhering to the real-world imaging process. This enables a
multi-view stereo setup from a single image, simplifying the imaging process,
making it compatible with powerful feed-forward reconstruction models for
generalizable and robust 3D reconstruction. To further exploit the geometric
symmetry introduced by mirrors, we propose a symmetric-aware loss to refine
pose estimation. Our framework also naturally extends to dynamic scenes, where
each frame contains a mirror reflection, enabling efficient per-frame geometry
recovery. For quantitative evaluation, we provide a fully customizable
synthetic dataset of 16 Blender scenes, each with ground-truth point clouds and
camera poses. Extensive experiments on real-world data and synthetic data are
conducted to illustrate the effectiveness of our method.

</details>


### [14] [Recov-Vision: Linking Street View Imagery and Vision-Language Models for Post-Disaster Recovery](https://arxiv.org/abs/2509.20628)
*Yiming Xiao,Archit Gupta,Miguel Esparza,Yu-Hsuan Ho,Antonia Sebastian,Hannah Weas,Rose Houck,Ali Mostafavi*

Main category: cs.CV

TL;DR: FacadeTrack 是一种结合街景影像和语言引导的框架，用于灾后建筑物占用评估，通过两阶段设计提高精度和召回率，并支持质量控制。


<details>
  <summary>Details</summary>
Motivation: 灾后建筑物占用情况对分诊、检查、公用事业重新通电和资源公平分配至关重要。虽然高空影像能快速覆盖，但常遗漏决定宜居性的立面和入口线索，而街景影像虽能捕捉这些细节，但稀疏且难以与地块对齐。

Method: FacadeTrack 是一个街景级别的语言引导框架，通过链接全景视频到地块、校正立面视图，并提取可解释属性（如入口堵塞、临时覆盖物、局部碎片），驱动两种决策策略：透明的一阶段规则和将感知与保守推理分离的两阶段设计。

Result: 在两场飓风后的调查中，两阶段方法的精确度为 0.927，召回率为 0.781，F-1 分数为 0.848，优于一阶段基线的精确度 0.943，召回率 0.728，F-1 分数 0.822。中间属性和空间诊断揭示了残差错误的来源，实现了有针对性的质量控制。

Conclusion: FacadeTrack 框架通过结合街景影像和语言引导，提供了可扩展且可审计的建筑物占用评估，适用于地理空间和应急管理工作流程。

Abstract: Building-level occupancy after disasters is vital for triage, inspections,
utility re-energization, and equitable resource allocation. Overhead imagery
provides rapid coverage but often misses facade and access cues that determine
habitability, while street-view imagery captures those details but is sparse
and difficult to align with parcels. We present FacadeTrack, a street-level,
language-guided framework that links panoramic video to parcels, rectifies
views to facades, and elicits interpretable attributes (for example, entry
blockage, temporary coverings, localized debris) that drive two decision
strategies: a transparent one-stage rule and a two-stage design that separates
perception from conservative reasoning. Evaluated across two post-Hurricane
Helene surveys, the two-stage approach achieves a precision of 0.927, a recall
of 0.781, and an F-1 score of 0.848, compared with the one-stage baseline at a
precision of 0.943, a recall of 0.728, and an F-1 score of 0.822. Beyond
accuracy, intermediate attributes and spatial diagnostics reveal where and why
residual errors occur, enabling targeted quality control. The pipeline provides
auditable, scalable occupancy assessments suitable for integration into
geospatial and emergency-management workflows.

</details>


### [15] [Human Semantic Representations of Social Interactions from Moving Shapes](https://arxiv.org/abs/2509.20673)
*Yiling Yun,Hongjing Lu*

Main category: cs.CV

TL;DR: 研究发现语义模型（尤其是动词嵌入）能有效补充视觉特征，解释人类对社会互动的感知。


<details>
  <summary>Details</summary>
Motivation: 探讨人类在补充视觉特征时使用的语义表征。

Method: 研究1直接让参与者标记动画印象；研究2通过人类相似性判断测量27种社会互动的表征几何，并与基于视觉特征、标签和描述语义嵌入的模型预测进行比较。

Result: 语义模型为解释人类判断提供了视觉特征的补充信息，其中基于动词的嵌入最能解释人类相似性判断。

Conclusion: 社会感知在简单展示中反映了社会互动的语义结构，连接了视觉和抽象表征。

Abstract: Humans are social creatures who readily recognize various social interactions
from simple display of moving shapes. While previous research has often focused
on visual features, we examine what semantic representations that humans employ
to complement visual features. In Study 1, we directly asked human participants
to label the animations based on their impression of moving shapes. We found
that human responses were distributed. In Study 2, we measured the
representational geometry of 27 social interactions through human similarity
judgments and compared it with model predictions based on visual features,
labels, and semantic embeddings from animation descriptions. We found that
semantic models provided complementary information to visual features in
explaining human judgments. Among the semantic models, verb-based embeddings
extracted from descriptions account for human similarity judgments the best.
These results suggest that social perception in simple displays reflects the
semantic structure of social interactions, bridging visual and abstract
representations.

</details>


### [16] [Enhancing Cross-View Geo-Localization Generalization via Global-Local Consistency and Geometric Equivariance](https://arxiv.org/abs/2509.20684)
*Xiaowei Wang,Di Wang,Ke Li,Yifeng Wang,Chengjian Wang,Libin Sun,Zhihong Wu,Yiming Zhang,Quan Wang*

Main category: cs.CV

TL;DR: EGS框架通过E(2)-Steerable CNN和虚拟超级节点图结构，提升了跨视角地理定位的鲁棒性和性能，并在多个基准测试中达到新高度。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在无人机视角和视野多样性导致的严重外观变化下的鲁棒性不足问题，以及如何建立同时捕捉全局场景语义和细粒度局部细节的可靠对应关系。

Method: 提出了一种新颖的CVGL框架EGS，采用E(2)-Steerable CNN编码器提取旋转和视角变化下的稳定特征，并构建了一个带有虚拟超级节点的图结构以增强全局-局部一致性。

Result: 在University-1652和SUES-200基准测试中，EGS表现优异，性能显著提升。

Conclusion: EGS框架在跨域CVGL中实现了显著的性能提升，并在University-1652和SUES-200基准测试中取得了新的最先进成果。

Abstract: Cross-view geo-localization (CVGL) aims to match images of the same location
captured from drastically different viewpoints. Despite recent progress,
existing methods still face two key challenges: (1) achieving robustness under
severe appearance variations induced by diverse UAV orientations and fields of
view, which hinders cross-domain generalization, and (2) establishing reliable
correspondences that capture both global scene-level semantics and fine-grained
local details. In this paper, we propose EGS, a novel CVGL framework designed
to enhance cross-domain generalization. Specifically, we introduce an
E(2)-Steerable CNN encoder to extract stable and reliable features under
rotation and viewpoint shifts. Furthermore, we construct a graph with a virtual
super-node that connects to all local nodes, enabling global semantics to be
aggregated and redistributed to local regions, thereby enforcing global-local
consistency. Extensive experiments on the University-1652 and SUES-200
benchmarks demonstrate that EGS consistently achieves substantial performance
gains and establishes a new state of the art in cross-domain CVGL.

</details>


### [17] [DENet: Dual-Path Edge Network with Global-Local Attention for Infrared Small Target Detection](https://arxiv.org/abs/2509.20701)
*Jiayi Zuo,Songwei Pei,Qian Li*

Main category: cs.CV

TL;DR: A novel Dual-Path Edge Network enhances infrared small target detection by decoupling edge enhancement and semantic modeling, achieving better performance in noisy and low-contrast scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the challenge of detecting infrared small targets with low contrast and high noise, where existing methods fail due to inadequate edge extraction and feature misalignment.

Method: The method involves a Dual-Path Edge Network with two complementary paths: a Bidirectional Interaction Module for multi-scale feature capture and a Multi-Edge Refiner for fine-grained edge enhancement using cascaded Taylor finite difference operators.

Result: The proposed network successfully addresses the conflict between spatial detail capture and semantic context extraction, leading to improved target detection and noise suppression.

Conclusion: The paper proposes a Dual-Path Edge Network that effectively combines edge enhancement and semantic modeling to improve infrared small target detection, offering a unified solution for precise detection and localization.

Abstract: Infrared small target detection is crucial for remote sensing applications
like disaster warning and maritime surveillance. However, due to the lack of
distinctive texture and morphological features, infrared small targets are
highly susceptible to blending into cluttered and noisy backgrounds. A
fundamental challenge in designing deep models for this task lies in the
inherent conflict between capturing high-resolution spatial details for minute
targets and extracting robust semantic context for larger targets, often
leading to feature misalignment and suboptimal performance. Existing methods
often rely on fixed gradient operators or simplistic attention mechanisms,
which are inadequate for accurately extracting target edges under low contrast
and high noise. In this paper, we propose a novel Dual-Path Edge Network that
explicitly addresses this challenge by decoupling edge enhancement and semantic
modeling into two complementary processing paths. The first path employs a
Bidirectional Interaction Module, which uses both Local Self-Attention and
Global Self-Attention to capture multi-scale local and global feature
dependencies. The global attention mechanism, based on a Transformer
architecture, integrates long-range semantic relationships and contextual
information, ensuring robust scene understanding. The second path introduces
the Multi-Edge Refiner, which enhances fine-grained edge details using cascaded
Taylor finite difference operators at multiple scales. This mathematical
approach, along with an attention-driven gating mechanism, enables precise edge
localization and feature enhancement for targets of varying sizes, while
effectively suppressing noise. Our method provides a promising solution for
precise infrared small target detection and localization, combining structural
semantics and edge refinement in a unified framework.

</details>


### [18] [Beyond the Individual: Introducing Group Intention Forecasting with SHOT Dataset](https://arxiv.org/abs/2509.20715)
*Ruixu Zhang,Yuran Wang,Xinyi Hu,Chaoyu Mai,Wenxuan Liu,Danni Xu,Xian Zhong,Zheng Wang*

Main category: cs.CV

TL;DR: 论文提出SHOT数据集和GIFT框架，用于预测群体意图，通过篮球视频分析个体行为和群体动态，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统意图识别忽略了群体意图的复杂性，因此提出了群体意图预测任务（GIF）以分析个体行为和互动。

Method: 通过SHOT数据集（包含1,979个篮球视频片段，标注了6种个体属性）和GIFT框架（提取细粒度个体特征并建模群体动态）进行研究。

Result: 实验结果表明SHOT和GIFT在群体意图预测中具有显著效果。

Conclusion: 论文提出了SHOT数据集和GIFT框架，为群体意图预测研究奠定了坚实基础，并证实了其有效性。

Abstract: Intention recognition has traditionally focused on individual intentions,
overlooking the complexities of collective intentions in group settings. To
address this limitation, we introduce the concept of group intention, which
represents shared goals emerging through the actions of multiple individuals,
and Group Intention Forecasting (GIF), a novel task that forecasts when group
intentions will occur by analyzing individual actions and interactions before
the collective goal becomes apparent. To investigate GIF in a specific
scenario, we propose SHOT, the first large-scale dataset for GIF, consisting of
1,979 basketball video clips captured from 5 camera views and annotated with 6
types of individual attributes. SHOT is designed with 3 key characteristics:
multi-individual information, multi-view adaptability, and multi-level
intention, making it well-suited for studying emerging group intentions.
Furthermore, we introduce GIFT (Group Intention ForecasTer), a framework that
extracts fine-grained individual features and models evolving group dynamics to
forecast intention emergence. Experimental results confirm the effectiveness of
SHOT and GIFT, establishing a strong foundation for future research in group
intention forecasting. The dataset is available at
https://xinyi-hu.github.io/SHOT_DATASET.

</details>


### [19] [Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection](https://arxiv.org/abs/2509.20745)
*Yu Guo,Shengfeng He,Yuxu Lu,Haonan An,Yihang Tao,Huilin Zhu,Jingxian Liu,Yuguang Fang*

Main category: cs.CV

TL;DR: Neptune-X通过合成数据生成和任务感知样本选择，提升了海上物体检测性能，特别是在代表性不足的场景中。


<details>
  <summary>Details</summary>
Motivation: 海上物体检测在导航安全、监控和自主操作中至关重要，但面临标注数据稀缺和跨属性泛化能力差的问题。

Method: 提出了Neptune-X框架，包括X-to-Maritime多模态条件生成模型和双向对象-水注意力模块，以及属性相关主动采样方法。

Result: 实验表明，Neptune-X在海上场景合成和物体检测准确性方面设立了新基准。

Conclusion: Neptune-X框架通过结合合成数据生成和任务感知样本选择，显著提升了海上物体检测的准确性，特别是在具有挑战性和代表性不足的场景中。

Abstract: Maritime object detection is essential for navigation safety, surveillance,
and autonomous operations, yet constrained by two key challenges: the scarcity
of annotated maritime data and poor generalization across various maritime
attributes (e.g., object category, viewpoint, location, and imaging
environment). % In particular, models trained on existing datasets often
underperform in underrepresented scenarios such as open-sea environments. To
address these challenges, we propose Neptune-X, a data-centric
generative-selection framework that enhances training effectiveness by
leveraging synthetic data generation with task-aware sample selection. From the
generation perspective, we develop X-to-Maritime, a multi-modality-conditioned
generative model that synthesizes diverse and realistic maritime scenes. A key
component is the Bidirectional Object-Water Attention module, which captures
boundary interactions between objects and their aquatic surroundings to improve
visual fidelity. To further improve downstream tasking performance, we propose
Attribute-correlated Active Sampling, which dynamically selects synthetic
samples based on their task relevance. To support robust benchmarking, we
construct the Maritime Generation Dataset, the first dataset tailored for
generative maritime learning, encompassing a wide range of semantic conditions.
Extensive experiments demonstrate that our approach sets a new benchmark in
maritime scene synthesis, significantly improving detection accuracy,
particularly in challenging and previously underrepresented settings.The code
is available at https://github.com/gy65896/Neptune-X.

</details>


### [20] [AI-Enabled Crater-Based Navigation for Lunar Mapping](https://arxiv.org/abs/2509.20748)
*Sofia McLeod,Chee-Kheng Chng,Matthew Rodda,Tat-Jun Chin*

Main category: cs.CV

TL;DR: STELLA是首个端到端的长期月球测绘CBN管道，结合了多种技术模块，实验证明其在复杂条件下仍能保持高精度导航。


<details>
  <summary>Details</summary>
Motivation: 传统的CBN主要应用于短时、高频率的着陆任务，而长期月球测绘任务面临稀疏、倾斜图像及变化光照条件等挑战，STELLA旨在填补这一空白。

Method: STELLA整合了基于Mask R-CNN的陨石坑检测器、无描述符的陨石坑识别模块、稳健的透视n-陨石坑姿态求解器以及批量轨道确定后端。

Result: 在CRESENT+和CRESENT-365数据集上的实验表明，STELLA在各种视角、光照条件和月球纬度下平均保持米级位置精度和亚度姿态精度。

Conclusion: STELLA展示了在长期月球测绘任务中，基于陨石坑的导航（CBN）能够保持米级位置精度和亚度姿态精度，为未来任务提供了操作条件的参考。

Abstract: Crater-Based Navigation (CBN) uses the ubiquitous impact craters of the Moon
observed on images as natural landmarks to determine the six degrees of freedom
pose of a spacecraft. To date, CBN has primarily been studied in the context of
powered descent and landing. These missions are typically short in duration,
with high-frequency imagery captured from a nadir viewpoint over well-lit
terrain. In contrast, lunar mapping missions involve sparse, oblique imagery
acquired under varying illumination conditions over potentially year-long
campaigns, posing significantly greater challenges for pose estimation. We
bridge this gap with STELLA - the first end-to-end CBN pipeline for
long-duration lunar mapping. STELLA combines a Mask R-CNN-based crater
detector, a descriptor-less crater identification module, a robust
perspective-n-crater pose solver, and a batch orbit determination back-end. To
rigorously test STELLA, we introduce CRESENT-365 - the first public dataset
that emulates a year-long lunar mapping mission. Each of its 15,283 images is
rendered from high-resolution digital elevation models with SPICE-derived Sun
angles and Moon motion, delivering realistic global coverage, illumination
cycles, and viewing geometries. Experiments on CRESENT+ and CRESENT-365 show
that STELLA maintains metre-level position accuracy and sub-degree attitude
accuracy on average across wide ranges of viewing angles, illumination
conditions, and lunar latitudes. These results constitute the first
comprehensive assessment of CBN in a true lunar mapping setting and inform
operational conditions that should be considered for future missions.

</details>


### [21] [Seeing Through Words, Speaking Through Pixels: Deep Representational Alignment Between Vision and Language Models](https://arxiv.org/abs/2509.20751)
*Zoe Wanying He,Sean Trott,Meenakshi Khosla*

Main category: cs.CV

TL;DR: 研究发现视觉和语言模型在表示空间中存在语义对齐，与人类判断一致，且示例聚合能增强对齐效果。


<details>
  <summary>Details</summary>
Motivation: 探索视觉和语言模型在表示空间中的对齐特性，包括对齐出现的网络位置、支持的线索、人类偏好的反映以及示例聚合的影响。

Method: 系统研究了视觉和语言模型在表示空间中的对齐情况，包括层间对齐、视觉或语言线索的影响、人类偏好的捕获以及示例聚合的效果。

Result: 对齐在两种模型的中晚期层达到峰值，对语义变化敏感，人类偏好与模型嵌入空间一致，示例聚合增强对齐。

Conclusion: 研究表明，单模态网络在共享语义编码上趋于一致，且与人类判断一致，并通过示例聚合增强。

Abstract: Recent studies show that deep vision-only and language-only models--trained
on disjoint modalities--nonetheless project their inputs into a partially
aligned representational space. Yet we still lack a clear picture of where in
each network this convergence emerges, what visual or linguistic cues support
it, whether it captures human preferences in many-to-many image-text scenarios,
and how aggregating exemplars of the same concept affects alignment. Here, we
systematically investigate these questions. We find that alignment peaks in
mid-to-late layers of both model types, reflecting a shift from
modality-specific to conceptually shared representations. This alignment is
robust to appearance-only changes but collapses when semantics are altered
(e.g., object removal or word-order scrambling), highlighting that the shared
code is truly semantic. Moving beyond the one-to-one image-caption paradigm, a
forced-choice "Pick-a-Pic" task shows that human preferences for image-caption
matches are mirrored in the embedding spaces across all vision-language model
pairs. This pattern holds bidirectionally when multiple captions correspond to
a single image, demonstrating that models capture fine-grained semantic
distinctions akin to human judgments. Surprisingly, averaging embeddings across
exemplars amplifies alignment rather than blurring detail. Together, our
results demonstrate that unimodal networks converge on a shared semantic code
that aligns with human judgments and strengthens with exemplar aggregation.

</details>


### [22] [FreeInsert: Personalized Object Insertion with Geometric and Style Control](https://arxiv.org/abs/2509.20756)
*Yuhong Zhang,Han Wang,Yiwen Wang,Rong Xie,Li Song*

Main category: cs.CV

TL;DR: FreeInsert 是一种无需训练的框架，利用3D几何信息实现对象插入的几何控制和风格一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像编辑方法在个性化图像合成任务中缺乏几何控制和风格一致性的问题，以及无需大量训练的挑战。

Method: 首先将2D对象转换为3D，在3D层面进行交互编辑，然后从指定视角重新渲染为2D图像，结合扩散适配器实现风格和内容控制。

Result: 通过3D几何控制和扩散适配器，生成了几何控制精确、风格一致的编辑图像。

Conclusion: FreeInsert 是一种无需训练的新框架，通过利用3D几何信息，将对象插入任意场景，实现了几何控制和风格一致的编辑。

Abstract: Text-to-image diffusion models have made significant progress in image
generation, allowing for effortless customized generation. However, existing
image editing methods still face certain limitations when dealing with
personalized image composition tasks. First, there is the issue of lack of
geometric control over the inserted objects. Current methods are confined to 2D
space and typically rely on textual instructions, making it challenging to
maintain precise geometric control over the objects. Second, there is the
challenge of style consistency. Existing methods often overlook the style
consistency between the inserted object and the background, resulting in a lack
of realism. In addition, the challenge of inserting objects into images without
extensive training remains significant. To address these issues, we propose
\textit{FreeInsert}, a novel training-free framework that customizes object
insertion into arbitrary scenes by leveraging 3D geometric information.
Benefiting from the advances in existing 3D generation models, we first convert
the 2D object into 3D, perform interactive editing at the 3D level, and then
re-render it into a 2D image from a specified view. This process introduces
geometric controls such as shape or view. The rendered image, serving as
geometric control, is combined with style and content control achieved through
diffusion adapters, ultimately producing geometrically controlled,
style-consistent edited images via the diffusion model.

</details>


### [23] [CusEnhancer: A Zero-Shot Scene and Controllability Enhancement Method for Photo Customization via ResInversion](https://arxiv.org/abs/2509.20775)
*Maoye Ren,Praneetha Vaddamanu,Jianjin Xu,Fernando De la Torre Frade*

Main category: cs.CV

TL;DR: CustomEnhancer通过三重流融合和ResInversion技术，提升了文本到图像扩散模型的生成效果和效率，无需额外训练即可实现精准控制。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像扩散模型在生成真实感人物照片时面临场景退化、控制不足和身份感知不优的问题，需要一种无需训练即可增强个性化模型的方法。

Method: 提出了CustomEnhancer框架，结合人脸交换技术和预训练扩散模型，通过三重流融合的PerGeneration方法统一生成和重建过程，并引入ResInversion技术优化噪声反演。

Result: CustomEnhancer在场景多样性、身份保真度和无训练控制方面达到SOTA效果，ResInversion将反演时间缩短了129倍。

Conclusion: CustomEnhancer通过三重流融合的PerGeneration方法和ResInversion技术，显著提升了文本到图像扩散模型在生成真实感人物照片时的场景多样性、身份保真度和控制效率，同时大幅降低了反演时间。

Abstract: Recently remarkable progress has been made in synthesizing realistic human
photos using text-to-image diffusion models. However, current approaches face
degraded scenes, insufficient control, and suboptimal perceptual identity. We
introduce CustomEnhancer, a novel framework to augment existing identity
customization models. CustomEnhancer is a zero-shot enhancement pipeline that
leverages face swapping techniques, pretrained diffusion model, to obtain
additional representations in a zeroshot manner for encoding into personalized
models. Through our proposed triple-flow fused PerGeneration approach, which
identifies and combines two compatible counter-directional latent spaces to
manipulate a pivotal space of personalized model, we unify the generation and
reconstruction processes, realizing generation from three flows. Our pipeline
also enables comprehensive training-free control over the generation process of
personalized models, offering precise controlled personalization for them and
eliminating the need for controller retraining for per-model. Besides, to
address the high time complexity of null-text inversion (NTI), we introduce
ResInversion, a novel inversion method that performs noise rectification via a
pre-diffusion mechanism, reducing the inversion time by 129 times. Experiments
demonstrate that CustomEnhancer reach SOTA results at scene diversity, identity
fidelity, training-free controls, while also showing the efficiency of our
ResInversion over NTI. The code will be made publicly available upon paper
acceptance.

</details>


### [24] [CompressAI-Vision: Open-source software to evaluate compression methods for computer vision tasks](https://arxiv.org/abs/2509.20777)
*Hyomin Choi,Heeji Han,Chris Rosewarne,Fabien Racapé*

Main category: cs.CV

TL;DR: CompressAI-Vision 是一个针对计算机视觉任务优化的视频压缩评估平台，支持多种用例，已被 MPEG 采用并开源。


<details>
  <summary>Details</summary>
Motivation: 随着基于神经网络的计算机视觉应用日益增多，需要一种针对下游视觉任务优化的视频压缩技术，以及一个统一的平台来实施和评估这些方法。

Method: 通过整合标准编解码器（开发中）并比较不同数据集上的压缩效果（比特率与任务准确性），评估平台的多种用例。

Result: CompressAI-Vision 平台在两种推理场景（“远程”和“分割”推理）中有效压缩视觉网络输入并保持任务准确性。

Conclusion: CompressAI-Vision 作为一个开源评估平台，已被 MPEG 采用用于开发 FCM 标准，展示了其在视频压缩技术优化中的实用性和潜力。

Abstract: With the increasing use of neural network (NN)-based computer vision
applications that process image and video data as input, interest has emerged
in video compression technology optimized for computer vision tasks. In fact,
given the variety of vision tasks, associated NN models and datasets, a
consolidated platform is needed as a common ground to implement and evaluate
compression methods optimized for downstream vision tasks. CompressAI-Vision is
introduced as a comprehensive evaluation platform where new coding tools
compete to efficiently compress the input of vision network while retaining
task accuracy in the context of two different inference scenarios: "remote" and
"split" inferencing. Our study showcases various use cases of the evaluation
platform incorporated with standard codecs (under development) by examining the
compression gain on several datasets in terms of bit-rate versus task accuracy.
This evaluation platform has been developed as open-source software and is
adopted by the Moving Pictures Experts Group (MPEG) for the development the
Feature Coding for Machines (FCM) standard. The software is available publicly
at https://github.com/InterDigitalInc/CompressAI-Vision.

</details>


### [25] [Dual-supervised Asymmetric Co-training for Semi-supervised Medical Domain Generalization](https://arxiv.org/abs/2509.20785)
*Jincai Song,Haipeng Chen,Jun Qin,Na Zhao*

Main category: cs.CV

TL;DR: 本文提出DAC框架解决CD-SSDG中的伪标签不准确问题，通过特征级监督和辅助任务提升泛化能力，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索更实际且具有挑战性的跨域半监督域泛化（CD-SSDG）场景，解决训练集中标注有限和域偏移共存的问题。

Method: 采用双监督非对称协同训练（DAC）框架，结合特征级监督和非对称辅助任务，以解决域偏移导致的伪标签不准确问题。

Result: 在Fundus、Polyp和SCGM等真实医学图像分割数据集上的实验表明，DAC框架具有强大的泛化能力。

Conclusion: 提出的DAC框架在跨域半监督域泛化（CD-SSDG）场景中表现出色，通过双监督非对称协同训练有效解决了伪标签不准确的问题，并在多个真实医学图像分割数据集中验证了其鲁棒泛化能力。

Abstract: Semi-supervised domain generalization (SSDG) in medical image segmentation
offers a promising solution for generalizing to unseen domains during testing,
addressing domain shift challenges and minimizing annotation costs. However,
conventional SSDG methods assume labeled and unlabeled data are available for
each source domain in the training set, a condition that is not always met in
practice. The coexistence of limited annotation and domain shift in the
training set is a prevalent issue. Thus, this paper explores a more practical
and challenging scenario, cross-domain semi-supervised domain generalization
(CD-SSDG), where domain shifts occur between labeled and unlabeled training
data, in addition to shifts between training and testing sets. Existing SSDG
methods exhibit sub-optimal performance under such domain shifts because of
inaccurate pseudolabels. To address this issue, we propose a novel
dual-supervised asymmetric co-training (DAC) framework tailored for CD-SSDG.
Building upon the co-training paradigm with two sub-models offering cross
pseudo supervision, our DAC framework integrates extra feature-level
supervision and asymmetric auxiliary tasks for each sub-model. This
feature-level supervision serves to address inaccurate pseudo supervision
caused by domain shifts between labeled and unlabeled data, utilizing
complementary supervision from the rich feature space. Additionally, two
distinct auxiliary self-supervised tasks are integrated into each sub-model to
enhance domain-invariant discriminative feature learning and prevent model
collapse. Extensive experiments on real-world medical image segmentation
datasets, i.e., Fundus, Polyp, and SCGM, demonstrate the robust
generalizability of the proposed DAC framework.

</details>


### [26] [Real-Time Object Detection Meets DINOv3](https://arxiv.org/abs/2509.20787)
*Shihua Huang,Yongjie Hou,Longfei Liu,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: DEIMv2通过DINOv3特征和优化设计，在多种规模模型上实现性能突破，显著超越YOLO系列。


<details>
  <summary>Details</summary>
Motivation: 扩展DEIM框架以覆盖更广泛的部署场景（GPU、边缘和移动设备），并提升性能和效率。

Method: 采用DINOv3预训练或蒸馏的骨干网络，并引入空间调整适配器（STA）以增强检测性能。对于超轻量模型，使用HGNetv2并进行深度和宽度剪枝。

Result: DEIMv2在不同规模模型上均取得领先性能，如DEIMv2-X（57.8 AP，50.3M参数）和DEIMv2-Pico（38.5 AP，1.5M参数）。

Conclusion: DEIMv2通过引入DINOv3特征和优化设计，在不同规模模型上实现了性能与成本的优越平衡，显著超越了现有技术。

Abstract: Benefiting from the simplicity and effectiveness of Dense O2O and MAL, DEIM
has become the mainstream training framework for real-time DETRs, significantly
outperforming the YOLO series. In this work, we extend it with DINOv3 features,
resulting in DEIMv2. DEIMv2 spans eight model sizes from X to Atto, covering
GPU, edge, and mobile deployment. For the X, L, M, and S variants, we adopt
DINOv3-pretrained or distilled backbones and introduce a Spatial Tuning Adapter
(STA), which efficiently converts DINOv3's single-scale output into multi-scale
features and complements strong semantics with fine-grained details to enhance
detection. For ultra-lightweight models (Nano, Pico, Femto, and Atto), we
employ HGNetv2 with depth and width pruning to meet strict resource budgets.
Together with a simplified decoder and an upgraded Dense O2O, this unified
design enables DEIMv2 to achieve a superior performance-cost trade-off across
diverse scenarios, establishing new state-of-the-art results. Notably, our
largest model, DEIMv2-X, achieves 57.8 AP with only 50.3 million parameters,
surpassing prior X-scale models that require over 60 million parameters for
just 56.5 AP. On the compact side, DEIMv2-S is the first sub-10 million model
(9.71 million) to exceed the 50 AP milestone on COCO, reaching 50.9 AP. Even
the ultra-lightweight DEIMv2-Pico, with just 1.5 million parameters, delivers
38.5 AP, matching YOLOv10-Nano (2.3 million) with around 50 percent fewer
parameters.

</details>


### [27] [DAC-LoRA: Dynamic Adversarial Curriculum for Efficient and Robust Few-Shot Adaptation](https://arxiv.org/abs/2509.20792)
*Ved Umrajkar*

Main category: cs.CV

TL;DR: DAC-LoRA是一种整合对抗训练到PEFT的新框架，通过智能课程逐步增加攻击难度，显著提升对抗鲁棒性而不影响干净准确性。


<details>
  <summary>Details</summary>
Motivation: Vision-Language Models（VLMs）在关键应用中扮演重要角色，但现有的PEFT方法如LoRA在面对对抗攻击时仍显脆弱，可能影响安全关键决策。

Method: 动态对抗课程（DAC-LoRA）框架，整合了对抗训练到PEFT中，通过逐步增加攻击难度的智能课程和一阶平稳条件（FOSC）及TRADES启发式损失来指导。

Result: DAC-LoRA在不显著影响干净准确性的情况下，显著提高了对抗鲁棒性。

Conclusion: DAC-LoRA框架提供了一种轻量级且广泛适用的方法，显著增强了对抗鲁棒性，同时保持了干净的准确性。

Abstract: Vision-Language Models (VLMs) are foundational to critical applications like
autonomous driving, medical diagnosis, and content moderation. While
Parameter-Efficient Fine-Tuning (PEFT) methods like LoRA enable their efficient
adaptation to specialized tasks, these models remain vulnerable to adversarial
attacks that can compromise safety-critical decisions. CLIP, the backbone for
numerous downstream VLMs, is a high-value target whose vulnerabilities can
cascade across the multimodal AI ecosystem. We propose Dynamic Adversarial
Curriculum DAC-LoRA, a novel framework that integrates adversarial training
into PEFT. The core principle of our method i.e. an intelligent curriculum of
progressively challenging attack, is general and can potentially be applied to
any iterative attack method. Guided by the First-Order Stationary Condition
(FOSC) and a TRADES-inspired loss, DAC-LoRA achieves substantial improvements
in adversarial robustness without significantly compromising clean accuracy.
Our work presents an effective, lightweight, and broadly applicable method to
demonstrate that the DAC-LoRA framework can be easily integrated into a
standard PEFT pipeline to significantly enhance robustness.

</details>


### [28] [Federated Domain Generalization with Domain-specific Soft Prompts Generation](https://arxiv.org/abs/2509.20807)
*Jianhan Wu,Xiaoyang Qu,Zhangcheng Huang,Jianzong Wang*

Main category: cs.CV

TL;DR: 本文提出了一种基于生成视角的联邦领域泛化方法FedDSPG，通过引入领域特定软提示和整合领域知识，显著提升了模型在未知领域的泛化能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示学习的联邦领域泛化（FDG）方法通常从训练样本中学习软提示，以替换手动设计的提示，增强联邦模型的泛化能力。然而，这些学习的提示多样性有限，且往往忽略未知领域的信息。

Method: 我们提出了一种新颖且有效的方法FedDSPG，从生成视角处理FDG任务，具体包括在训练阶段为每个领域引入领域特定软提示（DSPs），并将内容和领域知识整合到客户端间的生成模型中。在推理阶段，利用生成器获取未见目标领域的DSPs，从而指导未知领域的下游任务。

Result: 综合评估多个公共数据集，证实我们的方法在FDG中优于现有强基线，实现了最先进的结果。

Conclusion: 我们的方法FedDSPG在多个公共数据集上全面评估后，证实其在FDG任务中优于现有强基线，达到了最先进的性能。

Abstract: Prompt learning has become an efficient paradigm for adapting CLIP to
downstream tasks. Compared with traditional fine-tuning, prompt learning
optimizes a few parameters yet yields highly competitive results, especially
appealing in federated learning for computational efficiency. engendering
domain shift among clients and posing a formidable challenge for
downstream-task adaptation. Existing federated domain generalization (FDG)
methods based on prompt learning typically learn soft prompts from training
samples, replacing manually designed prompts to enhance the generalization
ability of federated models. However, these learned prompts exhibit limited
diversity and tend to ignore information from unknown domains. We propose a
novel and effective method from a generative perspective for handling FDG
tasks, namely federated domain generalization with domain-specific soft prompts
generation (FedDSPG). Specifically, during training, we introduce
domain-specific soft prompts (DSPs) for each domain and integrate content and
domain knowledge into the generative model among clients. In the inference
phase, the generator is utilized to obtain DSPs for unseen target domains, thus
guiding downstream tasks in unknown domains. Comprehensive evaluations across
several public datasets confirm that our method outperforms existing strong
baselines in FDG, achieving state-of-the-art results.

</details>


### [29] [Revolutionizing Precise Low Back Pain Diagnosis via Contrastive Learning](https://arxiv.org/abs/2509.20813)
*Thanh Binh Le,Hoang Nhat Khang Vo,Tan-Ha Mai,Trong Nhan Phan*

Main category: cs.CV

TL;DR: LumbarCLIP是一种新型多模态框架，通过对比语言-图像预训练对齐腰椎MRI扫描和放射学描述，在分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 全球数百万人受腰痛困扰，需要强大的诊断模型来联合分析复杂的医学图像和伴随的文本报告。

Method: LumbarCLIP整合了视觉编码器（ResNet-50、Vision Transformer、Swin Transformer）和基于BERT的文本编码器，通过可学习的投影头（线性或非线性）将密集表示投影到共享嵌入空间，并使用软CLIP损失进行稳定的对比训练。

Result: 该模型在下游分类任务中达到最先进的性能，测试集准确率高达95.00%，F1分数为94.75%，尽管存在固有的类别不平衡问题。

Conclusion: LumbarCLIP为自动化肌肉骨骼诊断和临床决策支持提供了有前景的基础。

Abstract: Low back pain affects millions worldwide, driving the need for robust
diagnostic models that can jointly analyze complex medical images and
accompanying text reports. We present LumbarCLIP, a novel multimodal framework
that leverages contrastive language-image pretraining to align lumbar spine MRI
scans with corresponding radiological descriptions. Built upon a curated
dataset containing axial MRI views paired with expert-written reports,
LumbarCLIP integrates vision encoders (ResNet-50, Vision Transformer, Swin
Transformer) with a BERT-based text encoder to extract dense representations.
These are projected into a shared embedding space via learnable projection
heads, configurable as linear or non-linear, and normalized to facilitate
stable contrastive training using a soft CLIP loss. Our model achieves
state-of-the-art performance on downstream classification, reaching up to
95.00% accuracy and 94.75% F1-score on the test set, despite inherent class
imbalance. Extensive ablation studies demonstrate that linear projection heads
yield more effective cross-modal alignment than non-linear variants. LumbarCLIP
offers a promising foundation for automated musculoskeletal diagnosis and
clinical decision support.

</details>


### [30] [Poisoning Prompt-Guided Sampling in Video Large Language Models](https://arxiv.org/abs/2509.20851)
*Yuxin Cao,Wei Song,Jingling Xue,Jin Song Dong*

Main category: cs.CV

TL;DR: PoisonVID首次揭示了提示引导采样在VideoLLMs中的安全隐患，通过闭环优化实现高攻击成功率，呼吁开发更安全的采样策略。


<details>
  <summary>Details</summary>
Motivation: 尽管提示引导采样策略在VideoLLMs中表现优异，但其安全性尚未被探索，PoisonVID填补了这一空白。

Method: 通过闭环优化策略迭代优化通用扰动，利用GPT-4o-mini构建的描绘集抑制有害帧相关性分数。

Result: 在三种提示引导采样策略和三种先进VideoLLMs上，PoisonVID实现了82%-99%的攻击成功率。

Conclusion: PoisonVID攻击揭示了提示引导采样策略在VideoLLMs中的安全性漏洞，强调了开发更先进采样策略的必要性。

Abstract: Video Large Language Models (VideoLLMs) have emerged as powerful tools for
understanding videos, supporting tasks such as summarization, captioning, and
question answering. Their performance has been driven by advances in frame
sampling, progressing from uniform-based to semantic-similarity-based and, most
recently, prompt-guided strategies. While vulnerabilities have been identified
in earlier sampling strategies, the safety of prompt-guided sampling remains
unexplored. We close this gap by presenting PoisonVID, the first black-box
poisoning attack that undermines prompt-guided sampling in VideoLLMs. PoisonVID
compromises the underlying prompt-guided sampling mechanism through a
closed-loop optimization strategy that iteratively optimizes a universal
perturbation to suppress harmful frame relevance scores, guided by a depiction
set constructed from paraphrased harmful descriptions leveraging a shadow
VideoLLM and a lightweight language model, i.e., GPT-4o-mini. Comprehensively
evaluated on three prompt-guided sampling strategies and across three advanced
VideoLLMs, PoisonVID achieves 82% - 99% attack success rate, highlighting the
importance of developing future advanced sampling strategies for VideoLLMs.

</details>


### [31] [Punching Above Precision: Small Quantized Model Distillation with Learnable Regularizer](https://arxiv.org/abs/2509.20854)
*Abdur Rehman,S M A Sharif,Md Abdur Rahaman,Mohamed Jismy Aashik Rasool,Seongwan Kim,Jaeho Lee*

Main category: cs.CV

TL;DR: GoR是一种自适应平衡任务和蒸馏目标的正则化方法，显著提升小型量化模型性能，集成框架QAT-EKD-GoR在最优条件下超越全精度模型。


<details>
  <summary>Details</summary>
Motivation: 现有QAT-KD方法在低比特量化下难以平衡任务特定和蒸馏损失，尤其是由于梯度幅度的异质性。

Method: 提出了Game of Regularizer (GoR)，一种可学习的正则化方法，通过仅两个可训练参数动态平衡任务特定（TS）和知识蒸馏（KD）目标。此外，还引入了QAT-EKD-GoR，一个集成蒸馏框架，利用多个异构教师模型。

Result: 实验表明，GoR在图像分类、目标检测和大型语言模型压缩中均优于现有QAT-KD方法，并在低功耗边缘设备上实现更快推理且保持全精度准确性。QAT-EKD-GoR在最优条件下甚至能超越全精度模型。

Conclusion: GoR和QAT-EKD-GoR提供了一种有效的解决方案，能够在资源受限的硬件上实现高性能的量化模型部署，甚至在最优条件下超越全精度模型。

Abstract: Quantization-aware training (QAT) combined with knowledge distillation (KD)
is a promising strategy for compressing Artificial Intelligence (AI) models for
deployment on resource-constrained hardware. However, existing QAT-KD methods
often struggle to balance task-specific (TS) and distillation losses due to
heterogeneous gradient magnitudes, especially under low-bit quantization. We
propose Game of Regularizer (GoR), a novel learnable regularization method that
adaptively balances TS and KD objectives using only two trainable parameters
for dynamic loss weighting. GoR reduces conflict between supervision signals,
improves convergence, and boosts the performance of small quantized models
(SQMs). Experiments on image classification, object detection (OD), and large
language model (LLM) compression show that GoR consistently outperforms
state-of-the-art QAT-KD methods. On low-power edge devices, it delivers faster
inference while maintaining full-precision accuracy. We also introduce
QAT-EKD-GoR, an ensemble distillation framework that uses multiple
heterogeneous teacher models. Under optimal conditions, the proposed EKD-GoR
can outperform full-precision models, providing a robust solution for
real-world deployment.

</details>


### [32] [Plant identification based on noisy web data: the amazing performance of deep learning (LifeCLEF 2017)](https://arxiv.org/abs/2509.20856)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2017植物识别挑战赛比较了噪声数据集与专家验证数据集的效果，为自动化植物识别系统的发展提供了重要数据。


<details>
  <summary>Details</summary>
Motivation: 评估大规模、噪声训练数据集能否与小型、专家验证的数据集竞争，以推动自动化植物识别系统的发展。

Method: 通过比较从网络收集的大规模噪声训练数据集和专家验证的小型训练数据集，使用来自Pl@ntNet移动应用的测试数据集进行评估。

Result: 挑战赛结果展示了不同训练策略在植物识别任务中的表现，为未来研究提供了参考。

Conclusion: LifeCLEF 2017植物识别挑战赛展示了在大规模、噪声数据集上训练的模型与小型、专家验证数据集上训练的模型的比较结果，为自动化植物识别系统的发展提供了重要见解。

Abstract: The 2017-th edition of the LifeCLEF plant identification challenge is an
important milestone towards automated plant identification systems working at
the scale of continental floras with 10.000 plant species living mainly in
Europe and North America illustrated by a total of 1.1M images. Nowadays, such
ambitious systems are enabled thanks to the conjunction of the dazzling recent
progress in image classification with deep learning and several outstanding
international initiatives, such as the Encyclopedia of Life (EOL), aggregating
the visual knowledge on plant species coming from the main national botany
institutes. However, despite all these efforts the majority of the plant
species still remain without pictures or are poorly illustrated. Outside the
institutional channels, a much larger number of plant pictures are available
and spread on the web through botanist blogs, plant lovers web-pages, image
hosting websites and on-line plant retailers. The LifeCLEF 2017 plant challenge
presented in this paper aimed at evaluating to what extent a large noisy
training dataset collected through the web and containing a lot of labelling
errors can compete with a smaller but trusted training dataset checked by
experts. To fairly compare both training strategies, the test dataset was
created from a third data source, i.e. the Pl@ntNet mobile application that
collects millions of plant image queries all over the world. This paper
presents more precisely the resources and assessments of the challenge,
summarizes the approaches and systems employed by the participating research
groups, and provides an analysis of the main outcomes.

</details>


### [33] [TasselNetV4: A vision foundation model for cross-scene, cross-scale, and cross-species plant counting](https://arxiv.org/abs/2509.20857)
*Xiaonan Hu,Xuebing Li,Jinyu Xu,Abdulkadir Duran Adan,Letian Zhou,Xuhui Zhu,Yanan Li,Wei Guo,Shouyang Liu,Wenzhong Liu,Hao Lu*

Main category: cs.CV

TL;DR: TasselNetV4 是一种新型植物计数模型，通过结合局部计数和提取-匹配范式，实现了跨物种、跨场景的高效计数，表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 植物具有生物多样性，且每年都有新品种被培育，几乎不可能穷尽并构建所有物种依赖的计数模型。因此，需要重新思考植物计数的问题，从‘计数什么植物’转向‘如何计数植物’。

Method: TasselNetV4 结合了 TasselNet 的局部计数思想和 CAC 中的提取-匹配范式，基于一个简单的视觉变换器，并引入了新颖的多分支框感知局部计数器以增强跨尺度鲁棒性。

Result: TasselNetV4 在 PAC-105 和 PAC-Somalia 两个具有挑战性的数据集上，相比现有的最先进 CAC 模型，不仅表现出卓越的计数性能，还具备高效性。

Conclusion: TasselNetV4 被证明是一种视觉基础模型，适用于跨场景、跨尺度和跨物种的植物计数。

Abstract: Accurate plant counting provides valuable information for agriculture such as
crop yield prediction, plant density assessment, and phenotype quantification.
Vision-based approaches are currently the mainstream solution. Prior art
typically uses a detection or a regression model to count a specific plant.
However, plants have biodiversity, and new cultivars are increasingly bred each
year. It is almost impossible to exhaust and build all species-dependent
counting models. Inspired by class-agnostic counting (CAC) in computer vision,
we argue that it is time to rethink the problem formulation of plant counting,
from what plants to count to how to count plants. In contrast to most daily
objects with spatial and temporal invariance, plants are dynamic, changing with
time and space. Their non-rigid structure often leads to worse performance than
counting rigid instances like heads and cars such that current CAC and
open-world detection models are suboptimal to count plants. In this work, we
inherit the vein of the TasselNet plant counting model and introduce a new
extension, TasselNetV4, shifting from species-specific counting to
cross-species counting. TasselNetV4 marries the local counting idea of
TasselNet with the extract-and-match paradigm in CAC. It builds upon a plain
vision transformer and incorporates novel multi-branch box-aware local counters
used to enhance cross-scale robustness. Two challenging datasets, PAC-105 and
PAC-Somalia, are harvested. Extensive experiments against state-of-the-art CAC
models show that TasselNetV4 achieves not only superior counting performance
but also high efficiency.Our results indicate that TasselNetV4 emerges to be a
vision foundation model for cross-scene, cross-scale, and cross-species plant
counting.

</details>


### [34] [SD-RetinaNet: Topologically Constrained Semi-Supervised Retinal Lesion and Layer Segmentation in OCT](https://arxiv.org/abs/2509.20864)
*Botond Fazekas,Guilherme Aresta,Philipp Seeböck,Julia Mai,Ursula Schmidt-Erfurth,Hrvoje Bogunović*

Main category: cs.CV

TL;DR: 该研究提出了一种新型半监督模型，通过可微拓扑引擎确保视网膜分割的解剖学正确性，优于现有技术并展示了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的半监督学习方法在视网膜分割中存在解剖学上不合理的分割、未能有效建模层与病变的相互作用以及缺乏拓扑正确性保证的问题，本研究旨在解决这些局限性。

Method: 研究提出了一种新型的半监督模型，该模型引入了一个完全可微的生物标志物拓扑引擎，用于强制解剖学正确的病变和层分割。该方法支持层与病变之间的双向影响联合学习，并利用未标注和多样化的部分标注数据集。模型学习了空间和风格因素的解耦表示。

Result: 在公开和内部OCT扫描数据集上的评估表明，该模型在病变和层分割上均优于当前最先进的技术，并展示了利用部分标注训练数据对病理案例的层分割泛化能力。

Conclusion: 该研究提出了一种新型的半监督模型，通过引入完全可微的生物标志物拓扑引擎，确保了视网膜层和病变的解剖学正确分割。这一方法不仅在病变和层分割上优于现有技术，还展示了对部分标注训练数据的泛化能力，为准确、稳健且可信赖的视网膜生物标志物分割提供了潜力。

Abstract: Optical coherence tomography (OCT) is widely used for diagnosing and
monitoring retinal diseases, such as age-related macular degeneration (AMD).
The segmentation of biomarkers such as layers and lesions is essential for
patient diagnosis and follow-up. Recently, semi-supervised learning has shown
promise in improving retinal segmentation performance. However, existing
methods often produce anatomically implausible segmentations, fail to
effectively model layer-lesion interactions, and lack guarantees on topological
correctness.
  To address these limitations, we propose a novel semi-supervised model that
introduces a fully differentiable biomarker topology engine to enforce
anatomically correct segmentation of lesions and layers. This enables joint
learning with bidirectional influence between layers and lesions, leveraging
unlabeled and diverse partially labeled datasets. Our model learns a
disentangled representation, separating spatial and style factors. This
approach enables more realistic layer segmentations and improves lesion
segmentation, while strictly enforcing lesion location in their anatomically
plausible positions relative to the segmented layers.
  We evaluate the proposed model on public and internal datasets of OCT scans
and show that it outperforms the current state-of-the-art in both lesion and
layer segmentation, while demonstrating the ability to generalize layer
segmentation to pathological cases using partially annotated training data. Our
results demonstrate the potential of using anatomical constraints in
semi-supervised learning for accurate, robust, and trustworthy retinal
biomarker segmentation.

</details>


### [35] [Plant identification in an open-world (LifeCLEF 2016)](https://arxiv.org/abs/2509.20870)
*Herve Goeau,Pierre Bonnet,Alexis Joly*

Main category: cs.CV

TL;DR: LifeCLEF 2016挑战赛评估了大规模植物识别方法，特别关注开放集识别问题，总结了参与团队的方法和主要成果。


<details>
  <summary>Details</summary>
Motivation: LifeCLEF植物识别挑战赛旨在评估大规模植物识别方法，接近真实生物多样性监测场景的条件。

Method: 挑战赛采用了开放集识别问题，要求识别系统对未知类别具有鲁棒性，并自动拒绝由未知类别引起的假阳性分类。

Result: 挑战赛在包含超过110K图像和1000种植物的数据集上进行，展示了开放集识别问题的解决方案和性能。

Conclusion: 本文总结了LifeCLEF 2016植物识别挑战赛的主要成果，分析了参与研究团队的方法和系统，并提供了对挑战赛资源的详细评估。

Abstract: The LifeCLEF plant identification challenge aims at evaluating plant
identification methods and systems at a very large scale, close to the
conditions of a real-world biodiversity monitoring scenario. The 2016-th
edition was actually conducted on a set of more than 110K images illustrating
1000 plant species living in West Europe, built through a large-scale
participatory sensing platform initiated in 2011 and which now involves tens of
thousands of contributors. The main novelty over the previous years is that the
identification task was evaluated as an open-set recognition problem, i.e. a
problem in which the recognition system has to be robust to unknown and never
seen categories. Beyond the brute-force classification across the known classes
of the training set, the big challenge was thus to automatically reject the
false positive classification hits that are caused by the unknown classes. This
overview presents more precisely the resources and assessments of the
challenge, summarizes the approaches and systems employed by the participating
research groups, and provides an analysis of the main outcomes.

</details>


### [36] [SCRA-VQA: Summarized Caption-Rerank for Augmented Large Language Models in Visual Question Answering](https://arxiv.org/abs/2509.20871)
*Yan Zhang,Jiaqing Lin,Miao Zhang,Kui Xiao,Xiaoju Hou,Yue Zhao,Zhifei Li*

Main category: cs.CV

TL;DR: SCRA-VQA通过优化字幕处理提升LLMs在KB-VQA中的表现，无需端到端训练。


<details>
  <summary>Details</summary>
Motivation: 现有的方法使用图像字幕作为视觉文本描述辅助LLMs理解图像，但字幕常包含无关噪声且LLMs通常不擅长VQA任务，限制了推理能力。

Method: 使用预训练的视觉语言模型将图像转换为字幕，并生成上下文示例，同时总结和重新排序字幕以排除无关信息。

Result: 在OK-VQA和A-OKVQA数据集上分别达到38.8%和34.6%的准确率。

Conclusion: SCRA-VQA通过总结和重新排序字幕，有效提升了LLMs在KB-VQA任务中的表现，无需昂贵的端到端训练。

Abstract: Acquiring high-quality knowledge is a central focus in Knowledge-Based Visual
Question Answering (KB-VQA). Recent methods use large language models (LLMs) as
knowledge engines for answering. These methods generally employ image captions
as visual text descriptions to assist LLMs in interpreting images. However, the
captions frequently include excessive noise irrelevant to the question, and
LLMs generally do not comprehend VQA tasks, limiting their reasoning
capabilities. To address this issue, we propose the Summarized Caption-Rerank
Augmented VQA (SCRA-VQA), which employs a pre-trained visual language model to
convert images into captions. Moreover, SCRA-VQA generates contextual examples
for the captions while simultaneously summarizing and reordering them to
exclude unrelated information. The caption-rerank process enables LLMs to
understand the image information and questions better, thus enhancing the
model's reasoning ability and task adaptability without expensive end-to-end
training. Based on an LLM with 6.7B parameters, SCRA-VQA performs excellently
on two challenging knowledge-based VQA datasets: OK-VQA and A-OKVQA, achieving
accuracies of 38.8% and 34.6%. Our code is available at
https://github.com/HubuKG/SCRA-VQA.

</details>


### [37] [The Unanticipated Asymmetry Between Perceptual Optimization and Assessment](https://arxiv.org/abs/2509.20878)
*Jiabei Zhang,Qi Wang,Siyu Wu,Du Chen,Tianhe Wu*

Main category: cs.CV

TL;DR: 本文揭示了感知优化与评估之间的不对称性，发现保真度指标在优化中效果有限，鉴别器设计对优化至关重要。


<details>
  <summary>Details</summary>
Motivation: 探索保真度目标与对抗性目标在感知优化和图像质量评估中的相关性，填补这一领域的研究空白。

Method: 通过系统性分析，研究了保真度指标和对抗性目标在感知优化和图像质量评估（IQA）中的表现差异，并探讨了鉴别器设计对优化效果的影响。

Result: 研究发现保真度指标在IQA中表现优异，但在感知优化中效果有限，且鉴别器设计对优化效果有显著影响。

Conclusion: 本文的结论揭示了感知优化与评估之间的不对称性，并强调了鉴别器设计在优化过程中的决定性作用，为感知优化的损失函数设计提供了更原则性的方法。

Abstract: Perceptual optimization is primarily driven by the fidelity objective, which
enforces both semantic consistency and overall visual realism, while the
adversarial objective provides complementary refinement by enhancing perceptual
sharpness and fine-grained detail. Despite their central role, the correlation
between their effectiveness as optimization objectives and their capability as
image quality assessment (IQA) metrics remains underexplored. In this work, we
conduct a systematic analysis and reveal an unanticipated asymmetry between
perceptual optimization and assessment: fidelity metrics that excel in IQA are
not necessarily effective for perceptual optimization, with this misalignment
emerging more distinctly under adversarial training. In addition, while
discriminators effectively suppress artifacts during optimization, their
learned representations offer only limited benefits when reused as backbone
initializations for IQA models. Beyond this asymmetry, our findings further
demonstrate that discriminator design plays a decisive role in shaping
optimization, with patch-level and convolutional architectures providing more
faithful detail reconstruction than vanilla or Transformer-based alternatives.
These insights advance the understanding of loss function design and its
connection to IQA transferability, paving the way for more principled
approaches to perceptual optimization.

</details>


### [38] [Integrating Object Interaction Self-Attention and GAN-Based Debiasing for Visual Question Answering](https://arxiv.org/abs/2509.20884)
*Zhifei Li,Feng Qiu,Yiran Wang,Yujing Xia,Kui Xiao,Miao Zhang,Yan Zhang*

Main category: cs.CV

TL;DR: IOG-VQA通过对象交互自注意力和GAN去偏技术提升VQA性能，有效解决数据偏见问题。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型常因训练数据中的偏见而过度依赖表面模式，导致对多样化问题和图像的泛化能力不足。IOG-VQA旨在通过更全面的视觉上下文理解和去偏技术解决这一问题。

Method: 本文提出了一种新颖的模型IOG-VQA，集成了对象交互自注意力机制和基于GAN的去偏框架。自注意力机制用于捕捉图像中对象之间的复杂交互，而GAN框架则生成无偏见的数据分布。

Result: 在VQA-CP v1和VQA-CP v2数据集上的实验表明，IOG-VQA相比现有方法表现出色，尤其是在处理偏见和不平衡数据分布方面。

Conclusion: IOG-VQA通过结合对象交互自注意力机制和基于GAN的去偏框架，显著提升了VQA模型的性能，特别是在处理偏见和不平衡数据分布方面。

Abstract: Visual Question Answering (VQA) presents a unique challenge by requiring
models to understand and reason about visual content to answer questions
accurately. Existing VQA models often struggle with biases introduced by the
training data, leading to over-reliance on superficial patterns and inadequate
generalization to diverse questions and images. This paper presents a novel
model, IOG-VQA, which integrates Object Interaction Self-Attention and
GAN-Based Debiasing to enhance VQA model performance. The self-attention
mechanism allows our model to capture complex interactions between objects
within an image, providing a more comprehensive understanding of the visual
context. Meanwhile, the GAN-based debiasing framework generates unbiased data
distributions, helping the model to learn more robust and generalizable
features. By leveraging these two components, IOG-VQA effectively combines
visual and textual information to address the inherent biases in VQA datasets.
Extensive experiments on the VQA-CP v1 and VQA-CP v2 datasets demonstrate that
our model shows excellent performance compared with the existing methods,
particularly in handling biased and imbalanced data distributions highlighting
the importance of addressing both object interactions and dataset biases in
advancing VQA tasks. Our code is available at
https://github.com/HubuKG/IOG-VQA.

</details>


### [39] [Nuclear Diffusion Models for Low-Rank Background Suppression in Videos](https://arxiv.org/abs/2509.20886)
*Tristan S. W. Stevens,Oisín Nolan,Jean-Luc Robert,Ruud J. G. van Sloun*

Main category: cs.CV

TL;DR: 提出Nuclear Diffusion方法，结合低秩建模与扩散采样，提升视频去雾效果。


<details>
  <summary>Details</summary>
Motivation: 视频序列常包含结构化噪声和背景伪影，传统的鲁棒主成分分析中的稀疏假设难以捕捉真实视频数据的丰富变异性。

Method: 提出了一种混合框架，将低秩时间建模与扩散后采样相结合，称为Nuclear Diffusion。

Result: 在真实世界医学成像问题（心脏超声去雾）上评估，与传统RPCA相比，在对比度增强（gCNR）和信号保留（KS统计）方面表现更优。

Conclusion: 该研究展示了将基于模型的时间模型与深度生成先验相结合在高保真视频恢复中的潜力。

Abstract: Video sequences often contain structured noise and background artifacts that
obscure dynamic content, posing challenges for accurate analysis and
restoration. Robust principal component methods address this by decomposing
data into low-rank and sparse components. Still, the sparsity assumption often
fails to capture the rich variability present in real video data. To overcome
this limitation, a hybrid framework that integrates low-rank temporal modeling
with diffusion posterior sampling is proposed. The proposed method, Nuclear
Diffusion, is evaluated on a real-world medical imaging problem, namely cardiac
ultrasound dehazing, and demonstrates improved dehazing performance compared to
traditional RPCA concerning contrast enhancement (gCNR) and signal preservation
(KS statistic). These results highlight the potential of combining model-based
temporal models with deep generative priors for high-fidelity video
restoration.

</details>


### [40] [FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies](https://arxiv.org/abs/2509.20890)
*Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan*

Main category: cs.CV

TL;DR: 研究提出FerretNet，利用局部像素依赖性检测合成图像，在开放世界基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决由VAEs、GANs和LDMs等先进模型生成的合成图像日益逼真带来的检测挑战。

Method: 利用基于马尔可夫随机场的局部像素依赖性（LPD）特性，通过邻域像素信息重建合成图像，以揭示纹理连续性和边缘一致性的破坏。基于LPD，提出了FerretNet。

Result: FerretNet在仅使用4类ProGAN数据集训练的情况下，在包含22种生成模型的开放世界基准测试中平均准确率达到97.1%，超越现有方法10.6%。

Conclusion: FerretNet，一种轻量级神经网络，仅需1.1M参数，就能高效且鲁棒地检测合成图像，在包含22种生成模型的开放世界基准测试中平均准确率达到97.1%，超越现有方法10.6%。

Abstract: The increasing realism of synthetic images generated by advanced models such
as VAEs, GANs, and LDMs poses significant challenges for synthetic image
detection. To address this issue, we explore two artifact types introduced
during the generation process: (1) latent distribution deviations and (2)
decoding-induced smoothing effects, which manifest as inconsistencies in local
textures, edges, and color transitions. Leveraging local pixel dependencies
(LPD) properties rooted in Markov Random Fields, we reconstruct synthetic
images using neighboring pixel information to expose disruptions in texture
continuity and edge coherence. Building upon LPD, we propose FerretNet, a
lightweight neural network with only 1.1M parameters that delivers efficient
and robust synthetic image detection. Extensive experiments demonstrate that
FerretNet, trained exclusively on the 4-class ProGAN dataset, achieves an
average accuracy of 97.1% on an open-world benchmark comprising across 22
generative models, surpassing state-of-the-art methods by 10.6%.

</details>


### [41] [Concepts in Motion: Temporal Bottlenecks for Interpretable Video Classification](https://arxiv.org/abs/2509.20899)
*Patrick Knab,Sascha Marton,Philipp J. Schubert,Drago Guggiana,Christian Bartelt*

Main category: cs.CV

TL;DR: MoTIF是一种受Transformer启发的框架，将概念瓶颈模型扩展到视频分类，有效处理时间依赖性，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 扩展概念瓶颈模型（CBMs）从静态图像到视频序列面临挑战，因为视频中的时间依赖性对于捕捉动作和事件至关重要。

Method: 引入了MoTIF（Moving Temporal Interpretable Framework），这是一种受Transformer启发的架构设计，适用于视频分类并处理任意长度的序列。

Result: MoTIF在视频分类中有效，能够从全局概念重要性、局部概念相关性和概念的时间依赖性三个互补视角进行分析。

Conclusion: 论文证明了基于概念建模的范式可以有效地迁移到视频数据，既保持了竞争性能，又提升了对时间上下文中概念贡献的理解。

Abstract: Conceptual models such as Concept Bottleneck Models (CBMs) have driven
substantial progress in improving interpretability for image classification by
leveraging human-interpretable concepts. However, extending these models from
static images to sequences of images, such as video data, introduces a
significant challenge due to the temporal dependencies inherent in videos,
which are essential for capturing actions and events. In this work, we
introduce MoTIF (Moving Temporal Interpretable Framework), an architectural
design inspired by a transformer that adapts the concept bottleneck framework
for video classification and handles sequences of arbitrary length. Within the
video domain, concepts refer to semantic entities such as objects, attributes,
or higher-level components (e.g., 'bow', 'mount', 'shoot') that reoccur across
time - forming motifs collectively describing and explaining actions. Our
design explicitly enables three complementary perspectives: global concept
importance across the entire video, local concept relevance within specific
windows, and temporal dependencies of a concept over time. Our results
demonstrate that the concept-based modeling paradigm can be effectively
transferred to video data, enabling a better understanding of concept
contributions in temporal contexts while maintaining competitive performance.
Code available at github.com/patrick-knab/MoTIF.

</details>


### [42] [FSMODNet: A Closer Look at Few-Shot Detection in Multispectral Data](https://arxiv.org/abs/2509.20905)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: FSMODNet利用跨模态特征整合和可变形注意力，在少标注数据下提升多光谱目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决在多光谱（可见光和热成像）目标检测中，标注数据稀缺的挑战。

Method: 提出了一种名为FSMODNet的框架，利用可变形注意力机制有效结合可见光和热成像的独特优势。

Result: 在两个公共数据集上的实验结果表明，该方法在低数据量情况下仍能有效检测目标，优于多个基线模型。

Conclusion: FSMODNet通过跨模态特征整合，在有限标注数据下实现了多光谱目标检测的鲁棒性能，尤其在复杂光照和环境条件下表现出色。

Abstract: Few-shot multispectral object detection (FSMOD) addresses the challenge of
detecting objects across visible and thermal modalities with minimal annotated
data. In this paper, we explore this complex task and introduce a framework
named "FSMODNet" that leverages cross-modality feature integration to improve
detection performance even with limited labels. By effectively combining the
unique strengths of visible and thermal imagery using deformable attention, the
proposed method demonstrates robust adaptability in complex illumination and
environmental conditions. Experimental results on two public datasets show
effective object detection performance in challenging low-data regimes,
outperforming several baselines we established from state-of-the-art models.
All code, models, and experimental data splits can be found at
https://anonymous.4open.science/r/Test-B48D.

</details>


### [43] [Finding 3D Positions of Distant Objects from Noisy Camera Movement and Semantic Segmentation Sequences](https://arxiv.org/abs/2509.20906)
*Julius Pesonen,Arno Solin,Eija Honkavaara*

Main category: cs.CV

TL;DR: 粒子滤波器在计算资源有限或远距离对象情况下，成功解决基于相机位姿和图像分割的3D定位任务，适用于无人机野火监测。


<details>
  <summary>Details</summary>
Motivation: 在远距离对象或计算资源有限的任务中，密集深度估计或3D场景重建不可行，需寻找替代解决方案。

Method: 使用粒子滤波器处理单目标和多目标场景，通过3D模拟和基于GNSS相机位估计的无人机图像分割序列进行研究。

Result: 粒子滤波器在这些其他方法失败的情况下仍能有效工作，且适用于无人机野火监测等实际应用。

Conclusion: 粒子滤波器可以解决基于相机位姿和图像分割的实际定位任务，且独立于检测方法，灵活适用于新任务。研究还表明，无人机野火监测可以结合现有图像分割模型使用该方法。

Abstract: 3D object localisation based on a sequence of camera measurements is
essential for safety-critical surveillance tasks, such as drone-based wildfire
monitoring. Localisation of objects detected with a camera can typically be
solved with dense depth estimation or 3D scene reconstruction. However, in the
context of distant objects or tasks limited by the amount of available
computational resources, neither solution is feasible. In this paper, we show
that the task can be solved using particle filters for both single and multiple
target scenarios. The method was studied using a 3D simulation and a
drone-based image segmentation sequence with global navigation satellite system
(GNSS)-based camera pose estimates. The results showed that a particle filter
can be used to solve practical localisation tasks based on camera poses and
image segments in these situations where other solutions fail. The particle
filter is independent of the detection method, making it flexible for new
tasks. The study also demonstrates that drone-based wildfire monitoring can be
conducted using the proposed method paired with a pre-existing image
segmentation model.

</details>


### [44] [SwinMamba: A hybrid local-global mamba framework for enhancing semantic segmentation of remotely sensed images](https://arxiv.org/abs/2509.20918)
*Qinfeng Zhu,Han Li,Liang He,Lei Fan*

Main category: cs.CV

TL;DR: SwinMamba结合局部和全局扫描，提升遥感图像分割精度，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感图像语义分割面临高分辨率、复杂场景和多样物体尺度的挑战，现有方法（如Vision Mamba）虽高效但忽视局部特征，影响了分割精度。

Method: SwinMamba集成了局部Mamba风格扫描和全局扫描，前两阶段专注于局部细节捕捉，后两阶段融合全局上下文信息，并通过重叠移位窗口增强区域间信息交换。

Result: 在LoveDA和ISPRS Potsdam数据集上的实验表明，SwinMamba优于现有最先进方法，证明了其有效性。

Conclusion: SwinMamba框架通过结合局部和全局扫描，显著提升了遥感图像语义分割的准确性和效率，为复杂场景下的分割任务提供了新的解决方案。

Abstract: Semantic segmentation of remote sensing imagery is a fundamental task in
computer vision, supporting a wide range of applications such as land use
classification, urban planning, and environmental monitoring. However, this
task is often challenged by the high spatial resolution, complex scene
structures, and diverse object scales present in remote sensing data. To
address these challenges, various deep learning architectures have been
proposed, including convolutional neural networks, Vision Transformers, and the
recently introduced Vision Mamba. Vision Mamba features a global receptive
field and low computational complexity, demonstrating both efficiency and
effectiveness in image segmentation. However, its reliance on global scanning
tends to overlook critical local features, such as textures and edges, which
are essential for achieving accurate segmentation in remote sensing contexts.
To tackle this limitation, we propose SwinMamba, a novel framework inspired by
the Swin Transformer. SwinMamba integrates localized Mamba-style scanning
within shifted windows with a global receptive field, to enhance the model's
perception of both local and global features. Specifically, the first two
stages of SwinMamba perform local scanning to capture fine-grained details,
while its subsequent two stages leverage global scanning to fuse broader
contextual information. In our model, the use of overlapping shifted windows
enhances inter-region information exchange, facilitating more robust feature
integration across the entire image. Extensive experiments on the LoveDA and
ISPRS Potsdam datasets demonstrate that SwinMamba outperforms state-of-the-art
methods, underscoring its effectiveness and potential as a superior solution
for semantic segmentation of remotely sensed imagery.

</details>


### [45] [Revisiting Data Challenges of Computational Pathology: A Pack-based Multiple Instance Learning Framework](https://arxiv.org/abs/2509.20923)
*Wenhao Tang,Heng Fang,Ge Wu,Xiang Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出pack-based MIL框架解决计算病理学中数据异构性和冗余性问题，显著提升准确性和训练效率。


<details>
  <summary>Details</summary>
Motivation: 计算病理学中的全切片图像（WSIs）存在极长的序列长度、显著的序列长度变化和有限的监督，导致数据异构性和冗余性高，传统方法在有限监督下难以高效训练和优化。

Method: 提出了一种pack-based MIL框架，将可变长度的特征序列打包成固定长度，支持批量训练；引入残差分支将丢弃的特征组合成超切片，提供多切片监督；并采用注意力驱动的下采样器减少冗余。

Result: 在PANDA(UNI)数据集上，该方法实现了最高8%的准确性提升，同时仅需12%的训练时间。

Conclusion: 通过提出pack-based MIL框架、残差分支和注意力驱动的下采样器，该方法在计算病理学中显著提高了准确性（最高8%）并大幅减少了训练时间（仅需12%）。

Abstract: Computational pathology (CPath) digitizes pathology slides into whole slide
images (WSIs), enabling analysis for critical healthcare tasks such as cancer
diagnosis and prognosis. However, WSIs possess extremely long sequence lengths
(up to 200K), significant length variations (from 200 to 200K), and limited
supervision. These extreme variations in sequence length lead to high data
heterogeneity and redundancy. Conventional methods often compromise on training
efficiency and optimization to preserve such heterogeneity under limited
supervision. To comprehensively address these challenges, we propose a
pack-based MIL framework. It packs multiple sampled, variable-length feature
sequences into fixed-length ones, enabling batched training while preserving
data heterogeneity. Moreover, we introduce a residual branch that composes
discarded features from multiple slides into a hyperslide which is trained with
tailored labels. It offers multi-slide supervision while mitigating feature
loss from sampling. Meanwhile, an attention-driven downsampler is introduced to
compress features in both branches to reduce redundancy. By alleviating these
challenges, our approach achieves an accuracy improvement of up to 8% while
using only 12% of the training time in the PANDA(UNI). Extensive experiments
demonstrate that focusing data challenges in CPath holds significant potential
in the era of foundation models. The code is
https://github.com/FangHeng/PackMIL

</details>


### [46] [SimDiff: Simulator-constrained Diffusion Model for Physically Plausible Motion Generation](https://arxiv.org/abs/2509.20927)
*Akihisa Watanabe,Jiawei Ren,Li Siyao,Yichen Peng,Erwin Wu,Edgar Simo-Serra*

Main category: cs.CV

TL;DR: SimDiff是一种模拟器约束的扩散模型，通过直接整合环境参数到去噪过程，高效生成物理合理人体运动，避免模拟器重复调用。


<details>
  <summary>Details</summary>
Motivation: 现有方法因模拟器的顺序性质导致计算成本高，无法并行化，限制了物理合理人体运动的生成效率。

Method: 提出SimDiff，一个模拟器约束的扩散模型，将环境参数（如重力、风力）直接整合到去噪过程中。

Result: SimDiff能够高效生成物理合理运动，且对未见过的环境参数组合表现出组合泛化能力。

Conclusion: SimDiff通过将环境参数直接整合到去噪过程中，高效生成物理上合理的人体运动，无需在推理时重复调用模拟器，并提供了对不同物理系数的细粒度控制。

Abstract: Generating physically plausible human motion is crucial for applications such
as character animation and virtual reality. Existing approaches often
incorporate a simulator-based motion projection layer to the diffusion process
to enforce physical plausibility. However, such methods are computationally
expensive due to the sequential nature of the simulator, which prevents
parallelization. We show that simulator-based motion projection can be
interpreted as a form of guidance, either classifier-based or classifier-free,
within the diffusion process. Building on this insight, we propose SimDiff, a
Simulator-constrained Diffusion Model that integrates environment parameters
(e.g., gravity, wind) directly into the denoising process. By conditioning on
these parameters, SimDiff generates physically plausible motions efficiently,
without repeated simulator calls at inference, and also provides fine-grained
control over different physical coefficients. Moreover, SimDiff successfully
generalizes to unseen combinations of environmental parameters, demonstrating
compositional generalization.

</details>


### [47] [Unlocking Noise-Resistant Vision: Key Architectural Secrets for Robust Models](https://arxiv.org/abs/2509.20939)
*Bum Jun Kim,Makoto Kawano,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.CV

TL;DR: 该论文通过分析1,174个视觉模型，总结了四种提高模型对高斯噪声鲁棒性的设计规则，并提供了理论解释和实用指南。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究视觉模型对高斯噪声的鲁棒性与其架构设计之间的关系，以提供改进模型鲁棒性的具体指导。

Method: 对1,174个预训练视觉模型进行了广泛评估，识别了四种提高鲁棒性的设计模式，并通过理论分析解释了这些发现。

Result: 研究发现，较大的stem kernels、较小的输入分辨率、平均池化以及监督式ViT（而非CLIP ViT）可显著提升模型鲁棒性，具体表现为506位排名提升和21.6%的准确率增益。

Conclusion: 该研究通过理论分析和实证验证，揭示了视觉模型对高斯噪声鲁棒性的关键设计因素，并提出了可操作的改进指南。

Abstract: While the robustness of vision models is often measured, their dependence on
specific architectural design choices is rarely dissected. We investigate why
certain vision architectures are inherently more robust to additive Gaussian
noise and convert these empirical insights into simple, actionable design
rules. Specifically, we performed extensive evaluations on 1,174 pretrained
vision models, empirically identifying four consistent design patterns for
improved robustness against Gaussian noise: larger stem kernels, smaller input
resolutions, average pooling, and supervised vision transformers (ViTs) rather
than CLIP ViTs, which yield up to 506 rank improvements and 21.6\%p accuracy
gains. We then develop a theoretical analysis that explains these findings,
converting observed correlations into causal mechanisms. First, we prove that
low-pass stem kernels attenuate noise with a gain that decreases quadratically
with kernel size and that anti-aliased downsampling reduces noise energy
roughly in proportion to the square of the downsampling factor. Second, we
demonstrate that average pooling is unbiased and suppresses noise in proportion
to the pooling window area, whereas max pooling incurs a positive bias that
grows slowly with window size and yields a relatively higher mean-squared error
and greater worst-case sensitivity. Third, we reveal and explain the
vulnerability of CLIP ViTs via a pixel-space Lipschitz bound: The smaller
normalization standard deviations used in CLIP preprocessing amplify worst-case
sensitivity by up to 1.91 times relative to the Inception-style preprocessing
common in supervised ViTs. Our results collectively disentangle robustness into
interpretable modules, provide a theory that explains the observed trends, and
build practical, plug-and-play guidelines for designing vision models more
robust against Gaussian noise.

</details>


### [48] [Decoding the Surgical Scene: A Scoping Review of Scene Graphs in Surgery](https://arxiv.org/abs/2509.20941)
*Angelo Henriques,Korab Hoxha,Daniel Zapp,Peter C. Issa,Nassir Navab,M. Ali Nasseri*

Main category: cs.CV

TL;DR: 该综述系统性地梳理了手术场景图研究的应用、方法进展和未来方向，指出了数据鸿沟问题，并强调了SG在手术分析和生成任务中的重要作用。


<details>
  <summary>Details</summary>
Motivation: 场景图为解码复杂、动态的手术环境提供了结构化的关系表示，是理解手术场景的重要工具。

Method: 从基础的图神经网络发展到专门的基础模型，这些模型在手术环境中显著优于通用的视觉语言模型。

Result: 分析揭示了快速增长的SG研究，但也发现了‘数据鸿沟’：内部视角研究（如三元组识别）主要使用真实世界的2D视频，而外部视角的4D建模则依赖模拟数据。

Conclusion: 手术场景图（SGs）正在成熟为一种关键的语义桥梁，推动新一代智能系统提升手术安全性、效率和培训。

Abstract: Scene graphs (SGs) provide structured relational representations crucial for
decoding complex, dynamic surgical environments. This PRISMA-ScR-guided scoping
review systematically maps the evolving landscape of SG research in surgery,
charting its applications, methodological advancements, and future directions.
Our analysis reveals rapid growth, yet uncovers a critical 'data divide':
internal-view research (e.g., triplet recognition) almost exclusively uses
real-world 2D video, while external-view 4D modeling relies heavily on
simulated data, exposing a key translational research gap. Methodologically,
the field has advanced from foundational graph neural networks to specialized
foundation models that now significantly outperform generalist large
vision-language models in surgical contexts. This progress has established SGs
as a cornerstone technology for both analysis, such as workflow recognition and
automated safety monitoring, and generative tasks like controllable surgical
simulation. Although challenges in data annotation and real-time implementation
persist, they are actively being addressed through emerging techniques.
Surgical SGs are maturing into an essential semantic bridge, enabling a new
generation of intelligent systems to improve surgical safety, efficiency, and
training.

</details>


### [49] [A Real-Time On-Device Defect Detection Framework for Laser Power-Meter Sensors via Unsupervised Learning](https://arxiv.org/abs/2509.20946)
*Dongqi Zheng,Wenjin Fu,Guangzong Chen*

Main category: cs.CV

TL;DR: 提出了一种基于视觉的自动化系统，用于检测和分类激光功率计传感器涂层缺陷，采用无监督异常检测框架，实验结果显示高准确率和快速处理速度。


<details>
  <summary>Details</summary>
Motivation: 解决激光功率计传感器涂层缺陷（如热损伤和划痕）检测的关键挑战，这些缺陷可能影响医疗和工业应用中激光能量测量的准确性。

Method: 方法包括三个关键组成部分：(1)使用拉普拉斯边缘检测和K-means聚类进行预处理的稳健流程，(2)通过StyleGAN2进行合成数据增强，(3)基于UFlow的神经网络架构，用于多尺度特征提取和异常图生成。

Result: 实验评估显示，在366张真实传感器图像上，缺陷样本的准确率为93.8%，良好样本的准确率为89.3%，图像级AUROC为0.957，像素级AUROC为0.961。系统处理速度为每张图像0.5秒。

Conclusion: 该系统通过自动化视觉检测激光功率计传感器涂层的缺陷，显著提高了激光能量测量的准确性，具有较高的准确率和处理速度，为医疗和工业应用提供了高效的自动化质量控制解决方案。

Abstract: We present an automated vision-based system for defect detection and
classification of laser power meter sensor coatings. Our approach addresses the
critical challenge of identifying coating defects such as thermal damage and
scratches that can compromise laser energy measurement accuracy in medical and
industrial applications. The system employs an unsupervised anomaly detection
framework that trains exclusively on ``good'' sensor images to learn normal
coating distribution patterns, enabling detection of both known and novel
defect types without requiring extensive labeled defect datasets. Our
methodology consists of three key components: (1) a robust preprocessing
pipeline using Laplacian edge detection and K-means clustering to segment the
area of interest, (2) synthetic data augmentation via StyleGAN2, and (3) a
UFlow-based neural network architecture for multi-scale feature extraction and
anomaly map generation. Experimental evaluation on 366 real sensor images
demonstrates $93.8\%$ accuracy on defective samples and $89.3\%$ accuracy on
good samples, with image-level AUROC of 0.957 and pixel-level AUROC of 0.961.
The system provides potential annual cost savings through automated quality
control and processing times of 0.5 seconds per image in on-device
implementation.

</details>


### [50] [Unlocking Financial Insights: An advanced Multimodal Summarization with Multimodal Output Framework for Financial Advisory Videos](https://arxiv.org/abs/2509.20961)
*Sarmistha Das,R E Zera Marveen Lyngkhoi,Sriparna Saha,Alka Maurya*

Main category: cs.CV

TL;DR: FASTER是一个多模态金融咨询摘要框架，通过结合文本和视觉特征生成精确摘要，并公开了数据集Fin-APT以支持研究。


<details>
  <summary>Details</summary>
Motivation: 由于金融咨询视频内容长且多模态，传统方法难以高效提取关键信息，FASTER旨在解决这一挑战。

Method: FASTER采用BLIP、OCR和Whisper-based转录等技术提取模态特征，结合改进的DPO损失函数和基于排名的检索机制，确保摘要的精确性和跨模态一致性。

Result: 实验表明FASTER在性能和泛化能力上优于大型语言模型和视觉语言模型。

Conclusion: FASTER通过引入模块化框架和多模态数据集Fin-APT，显著提升了金融咨询内容的可访问性和实用性，为多模态摘要研究设立了新标准。

Abstract: The dynamic propagation of social media has broadened the reach of financial
advisory content through podcast videos, yet extracting insights from lengthy,
multimodal segments (30-40 minutes) remains challenging. We introduce FASTER
(Financial Advisory Summariser with Textual Embedded Relevant images), a
modular framework that tackles three key challenges: (1) extracting
modality-specific features, (2) producing optimized, concise summaries, and (3)
aligning visual keyframes with associated textual points. FASTER employs BLIP
for semantic visual descriptions, OCR for textual patterns, and Whisper-based
transcription with Speaker diarization as BOS features. A modified Direct
Preference Optimization (DPO)-based loss function, equipped with BOS-specific
fact-checking, ensures precision, relevance, and factual consistency against
the human-aligned summary. A ranker-based retrieval mechanism further aligns
keyframes with summarized content, enhancing interpretability and cross-modal
coherence. To acknowledge data resource scarcity, we introduce Fin-APT, a
dataset comprising 470 publicly accessible financial advisory pep-talk videos
for robust multimodal research. Comprehensive cross-domain experiments confirm
FASTER's strong performance, robustness, and generalizability when compared to
Large Language Models (LLMs) and Vision-Language Models (VLMs). By establishing
a new standard for multimodal summarization, FASTER makes financial advisory
content more accessible and actionable, thereby opening new avenues for
research. The dataset and code are available at:
https://github.com/sarmistha-D/FASTER

</details>


### [51] [An Adaptor for Triggering Semi-Supervised Learning to Out-of-Box Serve Deep Image Clustering](https://arxiv.org/abs/2509.20976)
*Yue Duan,Lei Qi,Yinghuan Shi,Yang Gao*

Main category: cs.CV

TL;DR: ASD是一种无需先决条件的适配器，能够冷启动SSL学习者进行深度图像聚类，性能优越且灵活。


<details>
  <summary>Details</summary>
Motivation: 现有的将SSL技术集成到深度聚类框架中的方法需要预训练、聚类学习或训练好的聚类模型作为先决条件，限制了SSL学习器在图像聚类任务中的灵活性和即插即用性。

Method: ASD首先从所有未标记数据中随机采样伪标记数据，并设置实例级分类器学习这些数据。通过跟踪未标记数据预测的类别转换，提取实例级类别的高级相似性，用于为伪标记数据分配聚类级标签。最后，利用这些伪标记数据触发通用的SSL学习器进行图像聚类。

Result: ASD在多个基准测试中表现出优于最新深度图像聚类方法的性能，与使用真实标签的SSL方法相比仅有微小差距（如CIFAR-10上仅1.33%）。此外，ASD还能进一步提升现有SSL嵌入的深度图像聚类方法的性能。

Conclusion: ASD通过无需任何先决条件的冷启动方式，成功将SSL学习者集成到深度图像聚类中，显著提升了性能，并在多个基准测试中优于现有方法。

Abstract: Recently, some works integrate SSL techniques into deep clustering frameworks
to enhance image clustering performance. However, they all need pretraining,
clustering learning, or a trained clustering model as prerequisites, limiting
the flexible and out-of-box application of SSL learners in the image clustering
task. This work introduces ASD, an adaptor that enables the cold-start of SSL
learners for deep image clustering without any prerequisites. Specifically, we
first randomly sample pseudo-labeled data from all unlabeled data, and set an
instance-level classifier to learn them with semantically aligned
instance-level labels. With the ability of instance-level classification, we
track the class transitions of predictions on unlabeled data to extract
high-level similarities of instance-level classes, which can be utilized to
assign cluster-level labels to pseudo-labeled data. Finally, we use the
pseudo-labeled data with assigned cluster-level labels to trigger a general SSL
learner trained on the unlabeled data for image clustering. We show the
superior performance of ASD across various benchmarks against the latest deep
image clustering approaches and very slight accuracy gaps compared to SSL
methods using ground-truth, e.g., only 1.33% on CIFAR-10. Moreover, ASD can
also further boost the performance of existing SSL-embedded deep image
clustering methods.

</details>


### [52] [SiNGER: A Clearer Voice Distills Vision Transformers Further](https://arxiv.org/abs/2509.20986)
*Geunhyeok Yu,Sunjae Jeong,Yoonyoung Choi,Jaeseung Kim,Hyoseok Hwang*

Main category: cs.CV

TL;DR: SiNGER是一种新的蒸馏框架，通过空空间引导的能量重新分配抑制伪影并保留信息，显著提升学生模型性能。


<details>
  <summary>Details</summary>
Motivation: Vision Transformers在视觉基础模型中广泛使用，但其产生的高范数伪影会降低表示质量，影响知识蒸馏的效果。

Method: 利用基于LoRA的适配器高效实现空空间引导的扰动，以最小结构修改保留信息并抑制伪影。

Result: 实验表明，SiNGER框架能持续提升学生模型性能，生成更清晰、更易解释的表示。

Conclusion: SiNGER框架通过有效的教师特征精炼，显著提升了学生模型的性能，并在多个下游任务中实现了最先进的性能。

Abstract: Vision Transformers are widely adopted as the backbone of vision foundation
models, but they are known to produce high-norm artifacts that degrade
representation quality. When knowledge distillation transfers these features to
students, high-norm artifacts dominate the objective, so students overfit to
artifacts and underweight informative signals, diminishing the gains from
larger models. Prior work attempted to remove artifacts but encountered an
inherent trade-off between artifact suppression and preserving informative
signals from teachers. To address this, we introduce Singular Nullspace-Guided
Energy Reallocation (SiNGER), a novel distillation framework that suppresses
artifacts while preserving informative signals. The key idea is principled
teacher feature refinement: during refinement, we leverage the nullspace-guided
perturbation to preserve information while suppressing artifacts. Then, the
refined teacher's features are distilled to a student. We implement this
perturbation efficiently with a LoRA-based adapter that requires minimal
structural modification. Extensive experiments show that \oursname consistently
improves student models, achieving state-of-the-art performance in multiple
downstream tasks and producing clearer and more interpretable representations.

</details>


### [53] [Fast-SEnSeI: Lightweight Sensor-Independent Cloud Masking for On-board Multispectral Sensors](https://arxiv.org/abs/2509.20991)
*Jan Kněžík,Jonáš Herec,Rado Pitoňák*

Main category: cs.CV

TL;DR: Fast-SEnSeI 是一种轻量级传感器独立编码器，支持多光谱传感器的灵活星载云分割，适用于嵌入式 CPU 和 FPGA 混合硬件。


<details>
  <summary>Details</summary>
Motivation: 解决现有云分割模型与特定传感器配置紧密耦合、依赖地面处理的问题，实现灵活、高效的星载云分割。

Method: 基于 SEnSeI-v2，集成了改进的光谱描述符、轻量级架构和鲁棒的填充带处理，接受任意光谱波段组合并生成固定大小的特征图，结合紧凑的量化分割模型（基于改进的 U-Net）。

Result: 在 Sentinel-2 和 Landsat 8 数据集上的评估表明，该方法能准确处理多样化的输入配置。

Conclusion: Fast-SEnSeI 是一种轻量级、传感器独立的编码器模块，能够在不同光谱传感器配置下实现灵活的星载云分割，适用于太空认证硬件。

Abstract: Cloud segmentation is a critical preprocessing step for many Earth
observation tasks, yet most models are tightly coupled to specific sensor
configurations and rely on ground-based processing. In this work, we propose
Fast-SEnSeI, a lightweight, sensor-independent encoder module that enables
flexible, on-board cloud segmentation across multispectral sensors with varying
band configurations. Building upon SEnSeI-v2, Fast-SEnSeI integrates an
improved spectral descriptor, lightweight architecture, and robust padding-band
handling. It accepts arbitrary combinations of spectral bands and their
wavelengths, producing fixed-size feature maps that feed into a compact,
quantized segmentation model based on a modified U-Net. The module runs
efficiently on embedded CPUs using Apache TVM, while the segmentation model is
deployed on FPGA, forming a CPU-FPGA hybrid pipeline suitable for
space-qualified hardware. Evaluations on Sentinel-2 and Landsat 8 datasets
demonstrate accurate segmentation across diverse input configurations.

</details>


### [54] [A Single Neuron Works: Precise Concept Erasure in Text-to-Image Diffusion Models](https://arxiv.org/abs/2509.21008)
*Qinqin He,Jiaqi Weng,Jialing Tao,Hui Xue*

Main category: cs.CV

TL;DR: SNCE通过操控单个神经元精确防止有害内容生成，同时保持图像质量，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 文本到图像模型在生成图像方面表现出卓越能力，但也存在生成有害内容的安全风险，现有概念擦除方法在精确移除目标概念同时最小化图像质量退化方面存在挑战。

Method: 提出了一种基于单神经元的概念擦除方法（SNCE），通过训练稀疏自动编码器（SAE）将文本嵌入映射到稀疏、解耦的潜在空间，并设计了一种基于调制频率评分的新神经元识别方法。

Result: 在各种基准测试中，SNCE在目标概念擦除方面取得了最先进的结果，同时保留了模型对非目标概念的生成能力，并表现出对对抗攻击的强大鲁棒性。

Conclusion: SNCE通过精确抑制有害概念特定的神经元，实现了在概念擦除中的外科手术式精度，同时最小化对图像质量的干扰。

Abstract: Text-to-image models exhibit remarkable capabilities in image generation.
However, they also pose safety risks of generating harmful content. A key
challenge of existing concept erasure methods is the precise removal of target
concepts while minimizing degradation of image quality. In this paper, we
propose Single Neuron-based Concept Erasure (SNCE), a novel approach that can
precisely prevent harmful content generation by manipulating only a single
neuron. Specifically, we train a Sparse Autoencoder (SAE) to map text
embeddings into a sparse, disentangled latent space, where individual neurons
align tightly with atomic semantic concepts. To accurately locate neurons
responsible for harmful concepts, we design a novel neuron identification
method based on the modulated frequency scoring of activation patterns. By
suppressing activations of the harmful concept-specific neuron, SNCE achieves
surgical precision in concept erasure with minimal disruption to image quality.
Experiments on various benchmarks demonstrate that SNCE achieves
state-of-the-art results in target concept erasure, while preserving the
model's generation capabilities for non-target concepts. Additionally, our
method exhibits strong robustness against adversarial attacks, significantly
outperforming existing methods.

</details>


### [55] [OmniPlantSeg: Species Agnostic 3D Point Cloud Organ Segmentation for High-Resolution Plant Phenotyping Across Modalities](https://arxiv.org/abs/2509.21038)
*Andreas Gilson,Lukas Meyer,Oliver Scholz,Ute Schmid*

Main category: cs.CV

TL;DR: 提出KD-SS算法，一种适用于多种植物和传感器的轻量级点云分割方法，无需下采样即可处理全分辨率点云。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案通常是针对特定问题设计的，且需要大量预处理和下采样以满足硬件或神经网络输入尺寸要求。

Method: 提出了一种简单而有效的算法KD-SS，用于生物点云的子采样，不依赖于传感器数据和植物物种。

Result: 结合KD-SS与当前最先进的分割模型，在不同模态（如摄影测量、激光三角测量和LiDAR）及多种植物物种上均表现出令人满意的结果。

Conclusion: 提出了一种轻量级且保留分辨率的替代方法KD-SS，用于植物器官分割，适用于不同物种和传感器模态。

Abstract: Accurate point cloud segmentation for plant organs is crucial for 3D plant
phenotyping. Existing solutions are designed problem-specific with a focus on
certain plant species or specified sensor-modalities for data acquisition.
Furthermore, it is common to use extensive pre-processing and down-sample the
plant point clouds to meet hardware or neural network input size requirements.
We propose a simple, yet effective algorithm KDSS for sub-sampling of
biological point clouds that is agnostic to sensor data and plant species. The
main benefit of this approach is that we do not need to down-sample our input
data and thus, enable segmentation of the full-resolution point cloud.
Combining KD-SS with current state-of-the-art segmentation models shows
satisfying results evaluated on different modalities such as photogrammetry,
laser triangulation and LiDAR for various plant species. We propose KD-SS as
lightweight resolution-retaining alternative to intensive pre-processing and
down-sampling methods for plant organ segmentation regardless of used species
and sensor modality.

</details>


### [56] [Background Prompt for Few-Shot Out-of-Distribution Detection](https://arxiv.org/abs/2509.21055)
*Songyue Cai,Zongqian Wu,Yujie Mo,Liang Peng,Ping Hu,Xiaoshuang Shi,Xiaofeng Zhu*

Main category: cs.CV

TL;DR: Mambo是一种新的FG-BG分解框架，通过结合局部背景和类别相似性提升FS-OOD检测的鲁棒性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FG-BG分解方法因过度依赖局部类别相似性和固定背景补丁提取策略而缺乏鲁棒性。

Method: 提出Mambo框架，包括学习背景提示以获取局部背景相似性，并利用局部类别相似性进行细化。引入补丁自校准调谐以灵活选择背景补丁数量。

Result: 在真实数据集上的实验表明，Mambo在OOD和近OOD检测中达到最佳性能。

Conclusion: Mambo框架在FS-OOD检测中表现出色，优于现有方法，尤其在OOD和近OOD检测场景中。

Abstract: Existing foreground-background (FG-BG) decomposition methods for the few-shot
out-of-distribution (FS-OOD) detection often suffer from low robustness due to
over-reliance on the local class similarity and a fixed background patch
extraction strategy. To address these challenges, we propose a new FG-BG
decomposition framework, namely Mambo, for FS-OOD detection. Specifically, we
propose to first learn a background prompt to obtain the local background
similarity containing both the background and image semantic information, and
then refine the local background similarity using the local class similarity.
As a result, we use both the refined local background similarity and the local
class similarity to conduct background extraction, reducing the dependence of
the local class similarity in previous methods. Furthermore, we propose the
patch self-calibrated tuning to consider the sample diversity to flexibly
select numbers of background patches for different samples, and thus exploring
the issue of fixed background extraction strategies in previous methods.
Extensive experiments on real-world datasets demonstrate that our proposed
Mambo achieves the best performance, compared to SOTA methods in terms of OOD
detection and near OOD detection setting. The source code will be released at
https://github.com/YuzunoKawori/Mambo.

</details>


### [57] [Stratify or Die: Rethinking Data Splits in Image Segmentation](https://arxiv.org/abs/2509.21056)
*Naga Venkata Sai Jitin Jami,Thomas Altstidl,Jonas Mueller,Jindong Li,Dario Zanca,Bjoern Eskofier,Heike Leutheuser*

Main category: cs.CV

TL;DR: 本文提出了兩種針對圖像分割任務的數據集分割方法，特別是WDES，通過最小化Wasserstein距離優化標籤分佈，有效減少了評估偏差並提高了模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由於圖像分割數據集中的多標籤結構和類別不平衡問題，傳統的隨機數據集分割方法容易導致不具代表性的測試集，從而影響模型評估和泛化能力。

Method: 提出了兩種方法：Iterative Pixel Stratification (IPS)和Wasserstein-Driven Evolutionary Stratification (WDES)，後者是一種基於遺傳算法的新方法，旨在最小化Wasserstein距離。

Result: WDES在多種分割任務中（如街景、醫學影像和衛星圖像）表現優於隨機抽樣，產生了更具代表性的數據分割，降低了性能方差。

Conclusion: WDES在處理小樣本、不平衡和低多樣性的數據集時表現優異，有效減少了傳統分割策略的偏差，並提高了模型評估的準確性。

Abstract: Random splitting of datasets in image segmentation often leads to
unrepresentative test sets, resulting in biased evaluations and poor model
generalization. While stratified sampling has proven effective for addressing
label distribution imbalance in classification tasks, extending these ideas to
segmentation remains challenging due to the multi-label structure and class
imbalance typically present in such data. Building on existing stratification
concepts, we introduce Iterative Pixel Stratification (IPS), a straightforward,
label-aware sampling method tailored for segmentation tasks. Additionally, we
present Wasserstein-Driven Evolutionary Stratification (WDES), a novel genetic
algorithm designed to minimize the Wasserstein distance, thereby optimizing the
similarity of label distributions across dataset splits. We prove that WDES is
globally optimal given enough generations. Using newly proposed statistical
heterogeneity metrics, we evaluate both methods against random sampling and
find that WDES consistently produces more representative splits. Applying WDES
across diverse segmentation tasks, including street scenes, medical imaging,
and satellite imagery, leads to lower performance variance and improved model
evaluation. Our results also highlight the particular value of WDES in handling
small, imbalanced, and low-diversity datasets, where conventional splitting
strategies are most prone to bias.

</details>


### [58] [EnGraf-Net: Multiple Granularity Branch Network with Fine-Coarse Graft Grained for Classification Task](https://arxiv.org/abs/2509.21061)
*Riccardo La Grassa,Ignazio Gallo,Nicola Landro*

Main category: cs.CV

TL;DR: EnGraf-Net利用层次化语义关联作为监督信号，无需裁剪或标注，在细粒度分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有细粒度分类模型依赖部分标注或复杂技术提取注意力图，但局部特征表示不完整，而人类识别物体时还会形成语义关联。

Method: 提出了一种端到端的深度神经网络模型EnGraf-Net，利用层次化语义关联（分类学）作为监督信号。

Result: 在CIFAR-100、CUB-200-2011和FGVC-Aircraft三个数据集上的实验表明，EnGraf-Net优于许多现有细粒度模型，与最新方法竞争。

Conclusion: EnGraf-Net通过利用层次化语义关联作为监督信号，在不依赖裁剪技术或手动标注的情况下，在多个细粒度分类数据集上展现出与当前最先进方法相媲美的性能。

Abstract: Fine-grained classification models are designed to focus on the relevant
details necessary to distinguish highly similar classes, particularly when
intra-class variance is high and inter-class variance is low. Most existing
models rely on part annotations such as bounding boxes, part locations, or
textual attributes to enhance classification performance, while others employ
sophisticated techniques to automatically extract attention maps. We posit that
part-based approaches, including automatic cropping methods, suffer from an
incomplete representation of local features, which are fundamental for
distinguishing similar objects. While fine-grained classification aims to
recognize the leaves of a hierarchical structure, humans recognize objects by
also forming semantic associations. In this paper, we leverage semantic
associations structured as a hierarchy (taxonomy) as supervised signals within
an end-to-end deep neural network model, termed EnGraf-Net. Extensive
experiments on three well-known datasets CIFAR-100, CUB-200-2011, and
FGVC-Aircraft demonstrate the superiority of EnGraf-Net over many existing
fine-grained models, showing competitive performance with the most recent
state-of-the-art approaches, without requiring cropping techniques or manual
annotations.

</details>


### [59] [Vision Transformers: the threat of realistic adversarial patches](https://arxiv.org/abs/2509.21084)
*Kasper Cools,Clara Maathuis,Alexander M. van Oers,Claudia S. Hübner,Nikos Deligiannis,Marijke Vandewal,Geert De Cubber*

Main category: cs.CV

TL;DR: 研究探讨了ViT对对抗性补丁攻击的脆弱性，证实了CNN到ViT的跨架构攻击可转移性，预训练数据影响模型抵抗力。


<details>
  <summary>Details</summary>
Motivation: 随着ViT在机器学习中的广泛应用，其对抗性攻击的脆弱性尚未充分研究，尤其是在对抗性补丁攻击方面。

Method: 研究设计了现实的对抗性补丁，使用Creases Transformation（CT）技术添加类似服装自然褶皱的几何扭曲，以探究ViT在二分类任务中的脆弱性。

Result: 实验评估显示，不同ViT模型对对抗性补丁的攻击成功率差异显著，从40.04%到99.97%不等。

Conclusion: 该研究证实了对抗性补丁在从CNN到ViT的跨架构可转移性，且预训练数据集的规模和方法显著影响模型对对抗性攻击的抵抗力。

Abstract: The increasing reliance on machine learning systems has made their security a
critical concern. Evasion attacks enable adversaries to manipulate the
decision-making processes of AI systems, potentially causing security breaches
or misclassification of targets. Vision Transformers (ViTs) have gained
significant traction in modern machine learning due to increased 1) performance
compared to Convolutional Neural Networks (CNNs) and 2) robustness against
adversarial perturbations. However, ViTs remain vulnerable to evasion attacks,
particularly to adversarial patches, unique patterns designed to manipulate AI
classification systems. These vulnerabilities are investigated by designing
realistic adversarial patches to cause misclassification in person vs.
non-person classification tasks using the Creases Transformation (CT)
technique, which adds subtle geometric distortions similar to those occurring
naturally when wearing clothing. This study investigates the transferability of
adversarial attack techniques used in CNNs when applied to ViT classification
models. Experimental evaluation across four fine-tuned ViT models on a binary
person classification task reveals significant vulnerability variations: attack
success rates ranged from 40.04% (google/vit-base-patch16-224-in21k) to 99.97%
(facebook/dino-vitb16), with google/vit-base-patch16-224 achieving 66.40% and
facebook/dinov3-vitb16 reaching 65.17%. These results confirm the
cross-architectural transferability of adversarial patches from CNNs to ViTs,
with pre-training dataset scale and methodology strongly influencing model
resilience to adversarial attacks.

</details>


### [60] [UniTransfer: Video Concept Transfer via Progressive Spatial and Timestep Decomposition](https://arxiv.org/abs/2509.21086)
*Guojun Lei,Rong Zhang,Chi Wang,Tianhang Liu,Hong Li,Zhiyuan Ma,Weiwei Xu*

Main category: cs.CV

TL;DR: UniTransfer通过空间和时间步分解实现了高质量可控的视频概念转移，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在视频概念转移中实现更精确和可控的生成。

Method: 提出了UniTransfer架构，包括空间分解（前景、背景、运动流）和Chain-of-Prompt机制的时间步分解，结合自监督预训练策略。

Result: 在多样化的参考图像和场景中实现了高质量且可控的视频概念转移，视觉保真度和可编辑性均优于现有方法。

Conclusion: UniTransfer架构通过空间和时间步分解实现了高质量且可控的视频概念转移，超越了现有基线方法。

Abstract: We propose a novel architecture UniTransfer, which introduces both spatial
and diffusion timestep decomposition in a progressive paradigm, achieving
precise and controllable video concept transfer. Specifically, in terms of
spatial decomposition, we decouple videos into three key components: the
foreground subject, the background, and the motion flow. Building upon this
decomposed formulation, we further introduce a dual-to-single-stream DiT-based
architecture for supporting fine-grained control over different components in
the videos. We also introduce a self-supervised pretraining strategy based on
random masking to enhance the decomposed representation learning from
large-scale unlabeled video data. Inspired by the Chain-of-Thought reasoning
paradigm, we further revisit the denoising diffusion process and propose a
Chain-of-Prompt (CoP) mechanism to achieve the timestep decomposition. We
decompose the denoising process into three stages of different granularity and
leverage large language models (LLMs) for stage-specific instructions to guide
the generation progressively. We also curate an animal-centric video dataset
called OpenAnimal to facilitate the advancement and benchmarking of research in
video concept transfer. Extensive experiments demonstrate that our method
achieves high-quality and controllable video concept transfer across diverse
reference images and scenes, surpassing existing baselines in both visual
fidelity and editability. Web Page:
https://yu-shaonian.github.io/UniTransfer-Web/

</details>


### [61] [VideoChat-R1.5: Visual Test-Time Scaling to Reinforce Multimodal Reasoning by Iterative Perception](https://arxiv.org/abs/2509.21100)
*Ziang Yan,Xinhao Li,Yinan He,Zhengrong Yue,Xiangyu Zeng,Yali Wang,Yu Qiao,Limin Wang,Yi Wang*

Main category: cs.CV

TL;DR: VTTS通过迭代感知和强化学习提升MLLMs推理能力，在多个任务中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖静态感知阶段，限制了MLLMs的推理能力，因此需要一种动态迭代的感知方法。

Method: 提出了Visual Test-Time Scaling (VTTS)方法，采用Iterative Perception (ITP)机制，结合强化学习和时空监督来优化推理。

Result: VTTS在超过15个基准测试中平均提升了5%的性能，特别是在视频对话、视频推理和时空感知任务中表现突出。

Conclusion: VTTS通过迭代感知机制显著提升了MLLMs的推理能力，并在多个基准测试中验证了其有效性和泛化性。

Abstract: Inducing reasoning in multimodal large language models (MLLMs) is critical
for achieving human-level perception and understanding. Existing methods mainly
leverage LLM reasoning to analyze parsed visuals, often limited by static
perception stages. This paper introduces Visual Test-Time Scaling (VTTS), a
novel approach to enhance MLLMs' reasoning via iterative perception during
inference. VTTS mimics humans' hierarchical attention by progressively refining
focus on high-confidence spatio-temporal regions, guided by updated textual
predictions. Specifically, VTTS employs an Iterative Perception (ITP)
mechanism, incorporating reinforcement learning with spatio-temporal
supervision to optimize reasoning. To support this paradigm, we also present
VTTS-80K, a dataset tailored for iterative perception. These designs allows a
MLLM to enhance its performance by increasing its perceptual compute. Extensive
experiments validate VTTS's effectiveness and generalization across diverse
tasks and benchmarks. Our newly introduced Videochat-R1.5 model has achieved
remarkable improvements, with an average increase of over 5\%, compared to
robust baselines such as Qwen2.5VL-3B and -7B, across more than 15 benchmarks
that encompass video conversation, video reasoning, and spatio-temporal
perception.

</details>


### [62] [Mammo-CLIP Dissect: A Framework for Analysing Mammography Concepts in Vision-Language Models](https://arxiv.org/abs/2509.21102)
*Suaiba Amina Salahuddin,Teresa Dorszewski,Marit Almenning Martiniussen,Tone Hovda,Antonio Portaluri,Solveig Thrun,Michael Kampffmeyer,Elisabeth Wetzer,Kristoffer Wickstrøm,Robert Jenssen*

Main category: cs.CV

TL;DR: Mammo-CLIP Dissect 是首个针对乳腺X光影像深度学习模型的概念解释框架，通过分析模型的概念学习，揭示了领域特定训练和任务适应的影响。


<details>
  <summary>Details</summary>
Motivation: 理解深度学习模型的学习内容对于临床AI的安全部署至关重要，尤其是模型捕获的文本概念可能更贴近临床医生的推理逻辑。

Method: 利用乳腺X光影像特定的视觉语言模型（Mammo-CLIP）作为“解剖器”，对模型神经元进行文本概念标注，并量化其与领域知识的一致性。

Result: 研究表明，基于乳腺X光数据训练的模型能捕获更多临床相关概念，且与放射科医生工作流更一致；微调会增强特定概念（如良性钙化）的捕获，但可能减少其他概念（如密度相关特征）的覆盖。

Conclusion: Mammo-CLIP Dissect 框架通过分析深度学习模型在乳腺X光影像中的概念学习，揭示了领域特定训练和任务适应如何影响模型的概念捕获能力，为临床AI部署提供了可解释性支持。

Abstract: Understanding what deep learning (DL) models learn is essential for the safe
deployment of artificial intelligence (AI) in clinical settings. While previous
work has focused on pixel-based explainability methods, less attention has been
paid to the textual concepts learned by these models, which may better reflect
the reasoning used by clinicians. We introduce Mammo-CLIP Dissect, the first
concept-based explainability framework for systematically dissecting DL vision
models trained for mammography. Leveraging a mammography-specific
vision-language model (Mammo-CLIP) as a "dissector," our approach labels
neurons at specified layers with human-interpretable textual concepts and
quantifies their alignment to domain knowledge. Using Mammo-CLIP Dissect, we
investigate three key questions: (1) how concept learning differs between DL
vision models trained on general image datasets versus mammography-specific
datasets; (2) how fine-tuning for downstream mammography tasks affects concept
specialisation; and (3) which mammography-relevant concepts remain
underrepresented. We show that models trained on mammography data capture more
clinically relevant concepts and align more closely with radiologists'
workflows than models not trained on mammography data. Fine-tuning for
task-specific classification enhances the capture of certain concept categories
(e.g., benign calcifications) but can reduce coverage of others (e.g.,
density-related features), indicating a trade-off between specialisation and
generalisation. Our findings show that Mammo-CLIP Dissect provides insights
into how convolutional neural networks (CNNs) capture mammography-specific
knowledge. By comparing models across training data and fine-tuning regimes, we
reveal how domain-specific training and task-specific adaptation shape concept
learning. Code and concept set are available:
https://github.com/Suaiba/Mammo-CLIP-Dissect.

</details>


### [63] [MOSS-ChatV: Reinforcement Learning with Process Reasoning Reward for Video Temporal Reasoning](https://arxiv.org/abs/2509.21113)
*Sicheng Tao,Jungang Li,Yibo Yan,Junyan Zhang,Yubo Gao,Hanqian Li,ShuHang Xun,Yuxuan Fan,Hong Chen,Jianxiang He,Xuming Hu*

Main category: cs.CV

TL;DR: MOSS-ChatV通过DTW过程奖励解决MLLMs视频推理中的过程不一致问题，在多个基准测试中表现优异且适用性广。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在视频推理中存在过程不一致问题，即使最终答案正确，中间推理也可能偏离视频动态，影响可解释性和稳健性。

Method: 引入了一个基于强化学习的框架MOSS-ChatV，采用动态时间规整（DTW）的过程奖励，无需辅助奖励模型即可实现高效的过程监督。

Result: MOSS-ChatV在MOSS-Video测试集上达到87.2%的准确率，并在MVBench和MMVU等通用视频基准测试中表现优异，同时在不同架构（如Qwen2.5-VL和Phi-2）中均获得一致性能提升。

Conclusion: MOSS-ChatV通过动态时间规整（DTW）的过程奖励，显著提升了多模态大语言模型在视频推理中的一致性和稳健性，并在多个基准测试中表现出色，展示了其广泛的适用性。

Abstract: Video reasoning has emerged as a critical capability for multimodal large
language models (MLLMs), requiring models to move beyond static perception
toward coherent understanding of temporal dynamics in complex scenes. Yet
existing MLLMs often exhibit process inconsistency, where intermediate
reasoning drifts from video dynamics even when the final answer is correct,
undermining interpretability and robustness. To address this issue, we
introduce MOSS-ChatV, a reinforcement learning framework with a Dynamic Time
Warping (DTW)-based process reward. This rule-based reward aligns reasoning
traces with temporally grounded references, enabling efficient process
supervision without auxiliary reward models. We further identify dynamic state
prediction as a key measure of video reasoning and construct MOSS-Video, a
benchmark with annotated reasoning traces, where the training split is used to
fine-tune MOSS-ChatV and the held-out split is reserved for evaluation.
MOSS-ChatV achieves 87.2\% on MOSS-Video (test) and improves performance on
general video benchmarks such as MVBench and MMVU. The framework consistently
yields gains across different architectures, including Qwen2.5-VL and Phi-2,
confirming its broad applicability. Evaluations with GPT-4o-as-judge further
show that MOSS-ChatV produces more consistent and stable reasoning traces.

</details>


### [64] [MotionFlow:Learning Implicit Motion Flow for Complex Camera Trajectory Control in Video Generation](https://arxiv.org/abs/2509.21119)
*Guojun Lei,Chi Wang,Yikai Wang,Hong Li,Ying Song,Weiwei Xu*

Main category: cs.CV

TL;DR: 该论文提出了一种整合相机和物体运动为像素运动的新方法，利用稳定扩散网络和语义对象先验生成高质量视频，实验证明其性能远超现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将相机和物体运动分开学习，可能导致对相机与物体相对运动的混淆。为了解决这一问题，需要一种能够整合两者运动的方法。

Method: 提出了一种新颖的方法，将相机和物体运动转化为像素运动，利用稳定扩散网络学习参考运动图，并结合语义对象先验，通过图像到视频网络生成视频。

Result: 大量实验验证表明，该模型在准确跟随指定相机轨迹并保持物体运动一致性方面，显著优于现有最先进方法。

Conclusion: 该模型通过将相机和物体运动整合为像素运动，利用稳定扩散网络学习参考运动图，并结合语义对象先验，显著提升了视频生成的准确性和一致性，大幅超越现有方法。

Abstract: Generating videos guided by camera trajectories poses significant challenges
in achieving consistency and generalizability, particularly when both camera
and object motions are present. Existing approaches often attempt to learn
these motions separately, which may lead to confusion regarding the relative
motion between the camera and the objects. To address this challenge, we
propose a novel approach that integrates both camera and object motions by
converting them into the motion of corresponding pixels. Utilizing a stable
diffusion network, we effectively learn reference motion maps in relation to
the specified camera trajectory. These maps, along with an extracted semantic
object prior, are then fed into an image-to-video network to generate the
desired video that can accurately follow the designated camera trajectory while
maintaining consistent object motions. Extensive experiments verify that our
model outperforms SOTA methods by a large margin.

</details>


### [65] [The Unwinnable Arms Race of AI Image Detection](https://arxiv.org/abs/2509.21135)
*Till Aczel,Lorenzo Vettor,Andreas Plesner,Roger Wattenhofer*

Main category: cs.CV

TL;DR: 论文探讨了数据维度和复杂度对判别器检测合成图像能力的影响，发现中等复杂度数据集最有利于检测。


<details>
  <summary>Details</summary>
Motivation: 图像生成AI的快速发展模糊了合成与真实图像的边界，促使生成器与判别器之间的竞争加剧。本研究旨在探讨判别器在何种条件下处于劣势。

Method: 使用Kolmogorov复杂度作为数据集内在结构的度量，分析数据维度和复杂度对判别器性能的影响。

Result: 极简单或极高复杂度的数据集会降低合成图像的可检测性，而中等复杂度的数据集最有利于检测。

Conclusion: 研究发现，数据集的复杂程度对判别器的检测能力有显著影响。极简单或极高复杂度的数据集会降低合成图像的可检测性，而中等复杂度的数据集最有利于检测。

Abstract: The rapid progress of image generative AI has blurred the boundary between
synthetic and real images, fueling an arms race between generators and
discriminators. This paper investigates the conditions under which
discriminators are most disadvantaged in this competition. We analyze two key
factors: data dimensionality and data complexity. While increased
dimensionality often strengthens the discriminators ability to detect subtle
inconsistencies, complexity introduces a more nuanced effect. Using Kolmogorov
complexity as a measure of intrinsic dataset structure, we show that both very
simple and highly complex datasets reduce the detectability of synthetic
images; generators can learn simple datasets almost perfectly, whereas extreme
diversity masks imperfections. In contrast, intermediate-complexity datasets
create the most favorable conditions for detection, as generators fail to fully
capture the distribution and their errors remain visible.

</details>


### [66] [WAVECLIP: Wavelet Tokenization for Adaptive-Resolution CLIP](https://arxiv.org/abs/2509.21153)
*Moshe Kimhi,Erez Koifman,Ehud Rivlin,Eli Schwartz,Chaim Baskin*

Main category: cs.CV

TL;DR: WAVECLIP通过小波标记化实现自适应分辨率推理，支持多分辨率处理，显著节省计算资源。


<details>
  <summary>Details</summary>
Motivation: 为了解决CLIP模型在处理不同分辨率图像时的计算效率问题，提出统一的自适应分辨率推理模型。

Method: 采用多级小波分解替代标准补丁嵌入，支持同一模型中处理多分辨率图像，利用键值缓存和因果跨层注意力重用计算。

Result: 在零样本分类中表现优异，通过简单的基于置信度的门控机制实现自适应早期退出，用户可动态选择计算-准确率权衡。

Conclusion: WAVECLIP通过小波基标记化实现了自适应分辨率推理，仅需轻量级蒸馏即可达到竞争性准确率并显著节省计算资源。

Abstract: We introduce WAVECLIP, a single unified model for adaptive resolution
inference in CLIP, enabled by wavelet-based tokenization. WAVECLIP replaces
standard patch embeddings with a multi-level wavelet decomposition, enabling
the model to process images coarse to fine while naturally supporting multiple
resolutions within the same model. At inference time, the model begins with low
resolution tokens and refines only when needed, using key-value caching and
causal cross-level attention to reuse computation, effectively introducing to
the model only new information when needed. We evaluate WAVECLIP in zero-shot
classification, demonstrating that a simple confidence-based gating mechanism
enables adaptive early exits. This allows users to dynamically choose a
compute-accuracy trade-off using a single deployed model. Our approach requires
only lightweight distillation from a frozen CLIP teacher and achieves
competitive accuracy with significant computational savings.

</details>


### [67] [Can Less Precise Be More Reliable? A Systematic Evaluation of Quantization's Impact on CLIP Beyond Accuracy](https://arxiv.org/abs/2509.21173)
*Aymen Bouguerra,Daniel Montoya,Alexandra Gomez-Villa,Fabio Arnez,Chokri Mraidha*

Main category: cs.CV

TL;DR: 量化CLIP模型不仅提升效率，还意外改善校准性和OOD检测能力，QAT方法可同时优化多个性能指标。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（如CLIP）在零样本泛化能力上表现出色，但其在高效可靠部署方面的量化影响尚未充分研究。本文旨在填补这一空白，探索量化对CLIP模型性能的全面影响。

Method: 本研究通过大规模量化评估CLIP模型，不仅关注了分布内准确性，还评估了包括校准性在内的全面可靠性指标。特别探讨了量化对不同预训练来源模型的影响，并测试了量化感知训练（QAT）方法的效果。

Result: 量化显著改善了通常欠自信预训练模型的校准性，但对过自信模型可能产生负面影响。尽管如此，OOD检测性能在这些校准性下降的模型中仍可能提升。此外，特定QAT方法能够同时提升零样本准确性、校准性和OOD鲁棒性。

Conclusion: 量化技术在CLIP模型中的应用不仅提升了计算效率，还意外地改善了模型的校准性能，同时在某些情况下增强了OOD检测能力。此外，量化感知训练（QAT）方法能够同时提升零样本准确性、校准性和OOD鲁棒性，打破了效率与性能之间的严格权衡。

Abstract: The powerful zero-shot generalization capabilities of vision-language models
(VLMs) like CLIP have enabled new paradigms for safety-related tasks such as
out-of-distribution (OOD) detection. However, additional aspects crucial for
the computationally efficient and reliable deployment of CLIP are still
overlooked. In particular, the impact of quantization on CLIP's performance
beyond accuracy remains underexplored. This work presents a large-scale
evaluation of quantization on CLIP models, assessing not only in-distribution
accuracy but a comprehensive suite of reliability metrics and revealing
counterintuitive results driven by pre-training source. We demonstrate that
quantization consistently improves calibration for typically underconfident
pre-trained models, while often degrading it for overconfident variants.
Intriguingly, this degradation in calibration does not preclude gains in other
reliability metrics; we find that OOD detection can still improve for these
same poorly calibrated models. Furthermore, we identify specific
quantization-aware training (QAT) methods that yield simultaneous gains in
zero-shot accuracy, calibration, and OOD robustness, challenging the view of a
strict efficiency-performance trade-off. These findings offer critical insights
for navigating the multi-objective problem of deploying efficient, reliable,
and robust VLMs by utilizing quantization beyond its conventional role.

</details>


### [68] [TABLET: A Large-Scale Dataset for Robust Visual Table Understanding](https://arxiv.org/abs/2509.21205)
*Iñigo Alonso,Imanol Miranda,Eneko Agirre,Mirella Lapata*

Main category: cs.CV

TL;DR: TABLET是一个大规模视觉表格理解数据集，保留原始可视化效果，支持模型在多样任务上的稳健训练和评估。


<details>
  <summary>Details</summary>
Motivation: 当前表格理解主要依赖像素级处理，但现有基准测试多使用合成渲染，缺乏真实世界表格的复杂性和视觉多样性。现有VTU数据集提供固定示例，无法访问底层序列化数据以进行重新表述。

Method: 引入TABLET，一个包含4百万个示例的大规模VTU数据集，涵盖20个任务，基于2百万个独特表格，其中88%保留原始可视化效果。每个示例包括配对的图像-HTML表示、全面元数据和来源信息。

Result: 在TABLET上微调视觉语言模型（如Qwen2.5-VL-7B）提高了在已见和未见VTU任务上的性能，并增强了对真实世界表格可视化的鲁棒性。

Conclusion: TABLET数据集通过保留原始可视化效果和大规模统一收集，为未来视觉表格理解（VTU）模型的稳健训练和可扩展评估奠定了基础。

Abstract: While table understanding increasingly relies on pixel-only settings where
tables are processed as visual representations, current benchmarks
predominantly use synthetic renderings that lack the complexity and visual
diversity of real-world tables. Additionally, existing visual table
understanding (VTU) datasets offer fixed examples with single visualizations
and pre-defined instructions, providing no access to underlying serialized data
for reformulation. We introduce TABLET, a large-scale VTU dataset with 4
million examples across 20 tasks, grounded in 2 million unique tables where 88%
preserve original visualizations. Each example includes paired image-HTML
representations, comprehensive metadata, and provenance information linking
back to the source datasets. Fine-tuning vision-language models like
Qwen2.5-VL-7B on TABLET improves performance on seen and unseen VTU tasks while
increasing robustness on real-world table visualizations. By preserving
original visualizations and maintaining example traceability in a unified
large-scale collection, TABLET establishes a foundation for robust training and
extensible evaluation of future VTU models.

</details>


### [69] [Learning Conformal Explainers for Image Classifiers](https://arxiv.org/abs/2509.21209)
*Amr Alkhatib,Stephanie Lowry*

Main category: cs.CV

TL;DR: 提出一种基于共形预测的特征解释方法FastSHAP，实验证明其在保真度和效率上优于现有方法，且超像素度量更有效。


<details>
  <summary>Details</summary>
Motivation: 现有特征归因方法在鲁棒性和忠实性方面存在不足，无法真实反映黑盒模型的推理过程。

Method: 提出了一种基于共形预测的新方法，通过四种符合性函数量化解释与模型预测的符合程度。

Result: FastSHAP在五个解释器和六个图像数据集上的实验结果显示其在保真度和解释区域大小方面的优势。

Conclusion: FastSHAP在保真度和信息效率方面优于其他方法，基于超像素的符合性度量比像素级度量更有效。

Abstract: Feature attribution methods are widely used for explaining image-based
predictions, as they provide feature-level insights that can be intuitively
visualized. However, such explanations often vary in their robustness and may
fail to faithfully reflect the reasoning of the underlying black-box model. To
address these limitations, we propose a novel conformal prediction-based
approach that enables users to directly control the fidelity of the generated
explanations. The method identifies a subset of salient features that is
sufficient to preserve the model's prediction, regardless of the information
carried by the excluded features, and without demanding access to ground-truth
explanations for calibration. Four conformity functions are proposed to
quantify the extent to which explanations conform to the model's predictions.
The approach is empirically evaluated using five explainers across six image
datasets. The empirical results demonstrate that FastSHAP consistently
outperforms the competing methods in terms of both fidelity and informational
efficiency, the latter measured by the size of the explanation regions.
Furthermore, the results reveal that conformity measures based on super-pixels
are more effective than their pixel-wise counterparts.

</details>


### [70] [Sigma: Semantically Informative Pre-training for Skeleton-based Sign Language Understanding](https://arxiv.org/abs/2509.21223)
*Muxin Pu,Mei Kuan Lim,Chun Yong Chong,Chen Change Loy*

Main category: cs.CV

TL;DR: Sigma是一个基于骨架的统一手语理解框架，通过改进模态融合、对齐学习和预训练方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于骨架的手语理解方法存在三个主要问题：语义基础薄弱、局部细节与全局上下文不平衡以及跨模态学习效率低下。

Method: 提出了Sigma框架，包括三个关键组件：1）视觉和文本模态的早期融合机制；2）分层对齐学习策略；3）结合对比学习、文本匹配和语言建模的统一预训练框架。

Result: 在孤立手语识别、连续手语识别和无注释手语翻译等多个任务中，Sigma框架均取得了最先进的结果。

Conclusion: Sigma框架通过结合对比学习、文本匹配和语言建模的统一预训练方法，显著提升了手语理解的性能，并在多个基准测试中达到了最先进水平。

Abstract: Pre-training has proven effective for learning transferable features in sign
language understanding (SLU) tasks. Recently, skeleton-based methods have
gained increasing attention because they can robustly handle variations in
subjects and backgrounds without being affected by appearance or environmental
factors. Current SLU methods continue to face three key limitations: 1) weak
semantic grounding, as models often capture low-level motion patterns from
skeletal data but struggle to relate them to linguistic meaning; 2) imbalance
between local details and global context, with models either focusing too
narrowly on fine-grained cues or overlooking them for broader context; and 3)
inefficient cross-modal learning, as constructing semantically aligned
representations across modalities remains difficult. To address these, we
propose Sigma, a unified skeleton-based SLU framework featuring: 1) a
sign-aware early fusion mechanism that facilitates deep interaction between
visual and textual modalities, enriching visual features with linguistic
context; 2) a hierarchical alignment learning strategy that jointly maximises
agreements across different levels of paired features from different
modalities, effectively capturing both fine-grained details and high-level
semantic relationships; and 3) a unified pre-training framework that combines
contrastive learning, text matching and language modelling to promote semantic
consistency and generalisation. Sigma achieves new state-of-the-art results on
isolated sign language recognition, continuous sign language recognition, and
gloss-free sign language translation on multiple benchmarks spanning different
sign and spoken languages, demonstrating the impact of semantically informative
pre-training and the effectiveness of skeletal data as a stand-alone solution
for SLU.

</details>


### [71] [Evaluating the Evaluators: Metrics for Compositional Text-to-Image Generation](https://arxiv.org/abs/2509.21227)
*Seyed Amir Kasaei,Ali Aghayari,Arash Marioriyad,Niki Sepasian,MohammadAmin Fazli,Mahdieh Soleymani Baghshah,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 研究发现文本-图像生成评估中无单一指标能全面适用，不同指标表现因任务而异，强调需谨慎选择透明可信的评估指标。


<details>
  <summary>Details</summary>
Motivation: 尽管文本-图像生成技术发展迅速，但评估其输出是否真正捕捉到提示中的对象、属性和关系仍是一个核心挑战。现有自动评估指标往往未经人类判断验证，而评估和进展报告直接依赖于这些指标。

Method: 通过广泛研究常用的文本-图像组合评估指标，分析它们在不同组合挑战中的行为，并与人类判断进行比较。

Result: 结果显示，不同指标在不同任务中表现不一：VQA-based指标虽流行但并非全面优越，某些embedding-based指标在特定情况下表现更强。仅基于图像的指标对组合评估贡献有限。

Conclusion: 研究发现，在文本-图像生成评估中，没有单一指标能在所有任务中表现一致，不同指标在不同类型的组合问题上表现各异。因此，选择透明且可信的评估指标至关重要。

Abstract: Text-image generation has advanced rapidly, but assessing whether outputs
truly capture the objects, attributes, and relations described in prompts
remains a central challenge. Evaluation in this space relies heavily on
automated metrics, yet these are often adopted by convention or popularity
rather than validated against human judgment. Because evaluation and reported
progress in the field depend directly on these metrics, it is critical to
understand how well they reflect human preferences. To address this, we present
a broad study of widely used metrics for compositional text-image evaluation.
Our analysis goes beyond simple correlation, examining their behavior across
diverse compositional challenges and comparing how different metric families
align with human judgments. The results show that no single metric performs
consistently across tasks: performance varies with the type of compositional
problem. Notably, VQA-based metrics, though popular, are not uniformly
superior, while certain embedding-based metrics prove stronger in specific
cases. Image-only metrics, as expected, contribute little to compositional
evaluation, as they are designed for perceptual quality rather than alignment.
These findings underscore the importance of careful and transparent metric
selection, both for trustworthy evaluation and for their use as reward models
in generation. Project page is available at
\href{https://amirkasaei.com/eval-the-evals/}{this URL}.

</details>


### [72] [SlideMamba: Entropy-Based Adaptive Fusion of GNN and Mamba for Enhanced Representation Learning in Digital Pathology](https://arxiv.org/abs/2509.21239)
*Shakib Khan,Fariba Dambandkhameneh,Nazim Shaikh,Yao Nie,Raghavan Venugopal,Xiao Li*

Main category: cs.CV

TL;DR: SlideMamba整合Mamba与GNNs，通过熵自适应融合策略提升WSI分析性能，基因预测任务表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 计算病理学的发展需要从全切片图像（WSIs）中提取有意义的表示以支持临床和生物学任务。现有方法在处理局部空间关系和长程上下文依赖时存在局限性。

Method: 提出了一种结合Mamba架构与图神经网络（GNNs）的深度学习框架SlideMamba，通过自适应融合策略动态平衡局部空间关系和长程上下文依赖的贡献。

Result: SlideMamba在预测基因融合和突变状态的任务中，PRAUC达到0.751 ± 0.05，优于其他基线方法，并在ROC AUC、敏感性和特异性等指标上表现优异。

Conclusion: SlideMamba框架通过整合Mamba架构与图神经网络（GNNs），并引入基于熵的自适应融合策略，显著提升了全切片图像（WSIs）分析的性能。该方法在预测基因融合和突变状态的任务中表现出色，展现了在计算病理学中空间分辨预测建模任务的广阔应用前景。

Abstract: Advances in computational pathology increasingly rely on extracting
meaningful representations from Whole Slide Images (WSIs) to support various
clinical and biological tasks. In this study, we propose a generalizable deep
learning framework that integrates the Mamba architecture with Graph Neural
Networks (GNNs) for enhanced WSI analysis. Our method is designed to capture
both local spatial relationships and long-range contextual dependencies,
offering a flexible architecture for digital pathology analysis. Mamba modules
excels in capturing long-range global dependencies, while GNNs emphasize
fine-grained short-range spatial interactions. To effectively combine these
complementary signals, we introduce an adaptive fusion strategy that uses an
entropy-based confidence weighting mechanism. This approach dynamically
balances contributions from both branches by assigning higher weight to the
branch with more confident (lower-entropy) predictions, depending on the
contextual importance of local versus global information for different
downstream tasks. We demonstrate the utility of our approach on a
representative task: predicting gene fusion and mutation status from WSIs. Our
framework, SlideMamba, achieves an area under the precision recall curve
(PRAUC) of 0.751 \pm 0.05, outperforming MIL (0.491 \pm 0.042), Trans-MIL (0.39
\pm 0.017), Mamba-only (0.664 \pm 0.063), GNN-only (0.748 \pm 0.091), and a
prior similar work GAT-Mamba (0.703 \pm 0.075). SlideMamba also achieves
competitive results across ROC AUC (0.738 \pm 0.055), sensitivity (0.662 \pm
0.083), and specificity (0.725 \pm 0.094). These results highlight the strength
of the integrated architecture, enhanced by the proposed entropy-based adaptive
fusion strategy, and suggest promising potential for application of
spatially-resolved predictive modeling tasks in computational pathology.

</details>


### [73] [Hunyuan3D-Omni: A Unified Framework for Controllable Generation of 3D Assets](https://arxiv.org/abs/2509.21245)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jingwei Huang,Junlin Yu,Kunhong Li,Linus,Penghao Wang,Qingxiang Lin,Sicong Liu,Xianghui Yang,Yixuan Tang,Yunfei Zhao,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: Hunyuan3D-Omni是一个统一框架，通过多模态输入和渐进训练实现细粒度控制的3D资产生成，提升了精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成模型主要依赖图像或文本条件，缺乏细粒度的跨模态控制，限制了可控性和实际应用。

Method: Hunyuan3D-Omni采用单一跨模态架构整合多种输入信号（如点云、体素、边界框和骨骼姿态），并通过渐进式、难度感知的采样策略进行训练。

Result: 实验表明，Hunyuan3D-Omni的额外控制提高了生成准确性，支持几何感知变换，并增强了生产流程的鲁棒性。

Conclusion: Hunyuan3D-Omni通过统一的多模态架构和渐进式训练策略，显著提升了3D资产生成的精确性和可控性，适用于实际生产流程。

Abstract: Recent advances in 3D-native generative models have accelerated asset
creation for games, film, and design. However, most methods still rely
primarily on image or text conditioning and lack fine-grained, cross-modal
controls, which limits controllability and practical adoption. To address this
gap, we present Hunyuan3D-Omni, a unified framework for fine-grained,
controllable 3D asset generation built on Hunyuan3D 2.1. In addition to images,
Hunyuan3D-Omni accepts point clouds, voxels, bounding boxes, and skeletal pose
priors as conditioning signals, enabling precise control over geometry,
topology, and pose. Instead of separate heads for each modality, our model
unifies all signals in a single cross-modal architecture. We train with a
progressive, difficulty-aware sampling strategy that selects one control
modality per example and biases sampling toward harder signals (e.g., skeletal
pose) while downweighting easier ones (e.g., point clouds), encouraging robust
multi-modal fusion and graceful handling of missing inputs. Experiments show
that these additional controls improve generation accuracy, enable
geometry-aware transformations, and increase robustness for production
workflows.

</details>


### [74] [Learning to Look: Cognitive Attention Alignment with Vision-Language Models](https://arxiv.org/abs/2509.21247)
*Ryan L. Yang,Dipkamal Bhusal,Nidhi Rastogi*

Main category: cs.CV

TL;DR: 提出一种利用视觉语言模型自动生成语义注意力图的框架，通过辅助损失对齐CNN注意力，提升模型可靠性和认知合理性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对CNN模型常依赖表面相关性进行预测的问题，受认知科学启发，提出无需人工标注的自动化解决方案，以提升模型决策的可靠性和认知合理性。

Method: 开发了一个可扩展的框架，利用视觉语言模型和自然语言提示自动生成语义注意力图，并通过辅助损失函数将CNN注意力与这些语言引导的图对齐。

Result: 在ColoredMNIST数据集上达到最优性能，在DecoyMNIST数据集上与依赖大量标注的基线方法竞争性相当，表现出更好的泛化能力和减少对捷径的依赖。

Conclusion: 该论文提出的框架通过利用视觉语言模型自动生成语义注意力图，有效提升了CNN模型的可靠性和认知合理性，无需依赖人工标注。在ColoredMNIST和DecoyMNIST数据集上的实验证明了其优越性能和泛化能力。

Abstract: Convolutional Neural Networks (CNNs) frequently "cheat" by exploiting
superficial correlations, raising concerns about whether they make predictions
for the right reasons. Inspired by cognitive science, which highlights the role
of attention in robust human perception, recent methods have sought to guide
model attention using concept-based supervision and explanation regularization.
However, these techniques depend on labor-intensive, expert-provided
annotations, limiting their scalability. We propose a scalable framework that
leverages vision-language models to automatically generate semantic attention
maps using natural language prompts. By introducing an auxiliary loss that
aligns CNN attention with these language-guided maps, our approach promotes
more reliable and cognitively plausible decision-making without manual
annotation. Experiments on challenging datasets, ColoredMNIST and DecoyMNIST,
show that our method achieves state-of-the-art performance on ColorMNIST and
remains competitive with annotation-heavy baselines on DecoyMNIST,
demonstrating improved generalization, reduced shortcut reliance, and model
attention that better reflects human intuition.

</details>


### [75] [Decipher-MR: A Vision-Language Foundation Model for 3D MRI Representations](https://arxiv.org/abs/2509.21249)
*Zhijian Yang,Noel DSouza,Istvan Megyeri,Xiaojian Xu,Amin Honarmandi Shandiz,Farzin Haddadpour,Krisztian Koos,Laszlo Rusko,Emanuele Valeriano,Bharadwaj Swaninathan,Lei Wu,Parminder Bhatia,Taha Kass-Hout,Erhan Bas*

Main category: cs.CV

TL;DR: Decipher-MR 是一个针对 3D MRI 的视觉-语言基础模型，通过大规模数据集训练，结合自监督学习和文本监督，实现了在多种临床任务中的高性能表现。


<details>
  <summary>Details</summary>
Motivation: MRI 的复杂性和异质性给自动化分析带来了挑战，尤其是在可扩展和通用的机器学习应用中。现有的基础模型由于数据稀缺和解剖范围狭窄，在 MRI 中的应用受限。

Method: Decipher-MR 结合了自监督视觉学习和报告引导的文本监督，构建了鲁棒且通用的表示，支持轻量级任务特定解码器的模块化设计。

Result: Decipher-MR 在疾病分类、人口统计预测、解剖定位和跨模态检索等多样化基准测试中表现优异，性能优于现有基础模型和任务特定方法。

Conclusion: Decipher-MR 被确立为一个可扩展且多功能的 MRI 基础模型，能够高效支持临床和研究领域的 AI 开发。

Abstract: Magnetic Resonance Imaging (MRI) is a critical medical imaging modality in
clinical diagnosis and research, yet its complexity and heterogeneity pose
challenges for automated analysis, particularly in scalable and generalizable
machine learning applications. While foundation models have revolutionized
natural language and vision tasks, their application to MRI remains limited due
to data scarcity and narrow anatomical focus. In this work, we present
Decipher-MR, a 3D MRI-specific vision-language foundation model trained on a
large-scale dataset comprising 200,000 MRI series from over 22,000 studies
spanning diverse anatomical regions, sequences, and pathologies. Decipher-MR
integrates self-supervised vision learning with report-guided text supervision
to build robust, generalizable representations, enabling effective adaptation
across broad applications. To enable robust and diverse clinical tasks with
minimal computational overhead, Decipher-MR supports a modular design that
enables tuning of lightweight, task-specific decoders attached to a frozen
pretrained encoder. Following this setting, we evaluate Decipher-MR across
diverse benchmarks including disease classification, demographic prediction,
anatomical localization, and cross-modal retrieval, demonstrating consistent
performance gains over existing foundation models and task-specific approaches.
Our results establish Decipher-MR as a scalable and versatile foundation for
MRI-based AI, facilitating efficient development across clinical and research
domains.

</details>


### [76] [Instruction-tuned Self-Questioning Framework for Multimodal Reasoning](https://arxiv.org/abs/2509.21251)
*You-Won Jang,Yu-Jung Heo,Jaeseok Kim,Minsu Lee,Du-Seong Chang,Byoung-Tak Zhang*

Main category: cs.CV

TL;DR: SQ-InstructBLIP通过迭代生成图像感知子问题，提升多步推理性能，实验证明其在VQA任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在视觉语言理解中面临多步推理困难，且无法直接读取视觉信息或复现内部机制。SQ-InstructBLIP旨在解决这些问题。

Method: 提出SQ-InstructBLIP框架，包含Questioner、Answerer和Reasoner三个组件，通过迭代生成子问题和子答案来辅助主问题的推理。

Result: 实验表明，SQ-InstructBLIP在VQA任务中利用生成的子问题作为附加信息，推理准确性优于先前工作。

Conclusion: SQ-InstructBLIP通过生成图像感知的子问题和子答案，显著提升了视觉问答任务的推理准确性，优于现有方法。

Abstract: The field of vision-language understanding has been actively researched in
recent years, thanks to the development of Large Language Models~(LLMs).
However, it still needs help with problems requiring multi-step reasoning, even
for very simple questions. Recent studies adopt LLMs to tackle this problem by
iteratively generating sub-questions and answers. However, there are
disadvantages such as 1) the fine-grained visual contents of images are not
available using LLMs that cannot read visual information, 2) internal
mechanisms are inaccessible and difficult to reproduce by using black-box LLMs.
To solve these problems, we propose the SQ (Self-Questioning)-InstructBLIP,
which improves inference performance by generating image-aware informative
sub-questions and sub-answers iteratively. The SQ-InstructBLIP, which consists
of a Questioner, Answerer, and Reasoner that share the same architecture.
Questioner and Answerer generate sub-questions and sub-answers to help infer
the main-question, and Reasoner performs reasoning on the main-question
considering the generated sub-question information. Our experiments show that
the proposed method SQ-InstructBLIP, which uses the generated sub-questions as
additional information when solving the VQA task, performs more accurate
reasoning than the previous works.

</details>


### [77] [Hallucination as an Upper Bound: A New Perspective on Text-to-Image Evaluation](https://arxiv.org/abs/2509.21257)
*Seyed Amir Kasaei,Mohammad Hossein Rohban*

Main category: cs.CV

TL;DR: 本文定义了T2I模型中的幻觉现象，并提出了一个三分类的分类法，为评估模型偏差提供了新框架。


<details>
  <summary>Details</summary>
Motivation: 目前对T2I模型中幻觉现象的研究不足，现有评估主要关注对齐性，而忽视了模型生成的超出提示内容的部分。

Method: 通过分析现有评估方法的局限性，作者提出将幻觉定义为偏差驱动的偏离，并构建了一个三分类的分类法。

Result: 作者提出的分类法为T2I模型的幻觉评估引入了上限，并揭示了隐藏的偏差。

Conclusion: 本文提出了在文本到图像（T2I）生成模型中定义幻觉的新框架，并提出了一个包含属性、关系和对象幻觉的分类法，为更丰富的T2I模型评估奠定了基础。

Abstract: In language and vision-language models, hallucination is broadly understood
as content generated from a model's prior knowledge or biases rather than from
the given input. While this phenomenon has been studied in those domains, it
has not been clearly framed for text-to-image (T2I) generative models. Existing
evaluations mainly focus on alignment, checking whether prompt-specified
elements appear, but overlook what the model generates beyond the prompt. We
argue for defining hallucination in T2I as bias-driven deviations and propose a
taxonomy with three categories: attribute, relation, and object hallucinations.
This framing introduces an upper bound for evaluation and surfaces hidden
biases, providing a foundation for richer assessment of T2I models.

</details>


### [78] [Every Subtlety Counts: Fine-grained Person Independence Micro-Action Recognition via Distributionally Robust Optimization](https://arxiv.org/abs/2509.21261)
*Feng-Qi Cui,Jinyang Huang,Anyang Tong,Ziyu Jia,Jie Zhang,Zhi Liu,Dan Guo,Jianwei Lu,Meng Wang*

Main category: cs.CV

TL;DR: 提出了一种结合分布鲁棒优化的微动作识别框架，通过特征对齐和损失正则化提升跨个体泛化能力，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因个体间差异导致相同动作表现不同，难以在真实场景中实现鲁棒泛化。

Method: 框架包含两个即插即用组件：特征层面的Temporal-Frequency Alignment Module（通过Wasserstein正则化对齐和方差引导扰动增强鲁棒性）和损失层面的Group-Invariant Regularized Loss（通过伪分组和边界案例加权提升泛化能力）。

Result: 在MA-52数据集上的实验表明，该框架在准确性和鲁棒性上均优于现有方法。

Conclusion: 提出的Person Independence Universal Micro-action Recognition Framework通过特征和损失层面的创新组件，显著提升了微动作识别的准确性和鲁棒性，实现了在细粒度条件下的稳定泛化。

Abstract: Micro-action Recognition is vital for psychological assessment and
human-computer interaction. However, existing methods often fail in real-world
scenarios because inter-person variability causes the same action to manifest
differently, hindering robust generalization. To address this, we propose the
Person Independence Universal Micro-action Recognition Framework, which
integrates Distributionally Robust Optimization principles to learn
person-agnostic representations. Our framework contains two plug-and-play
components operating at the feature and loss levels. At the feature level, the
Temporal-Frequency Alignment Module normalizes person-specific motion
characteristics with a dual-branch design: the temporal branch applies
Wasserstein-regularized alignment to stabilize dynamic trajectories, while the
frequency branch introduces variance-guided perturbations to enhance robustness
against person-specific spectral differences. A consistency-driven fusion
mechanism integrates both branches. At the loss level, the Group-Invariant
Regularized Loss partitions samples into pseudo-groups to simulate unseen
person-specific distributions. By up-weighting boundary cases and regularizing
subgroup variance, it forces the model to generalize beyond easy or frequent
samples, thus enhancing robustness to difficult variations. Experiments on the
large-scale MA-52 dataset demonstrate that our framework outperforms existing
methods in both accuracy and robustness, achieving stable generalization under
fine-grained conditions.

</details>


### [79] [Dense Semantic Matching with VGGT Prior](https://arxiv.org/abs/2509.21263)
*Songlin Yang,Tianyi Wei,Yushi Lan,Zeqi Xiao,Anyi Rao,Xingang Pan*

Main category: cs.CV

TL;DR: 本文提出了一种改进VGGT的方法，用于解决语义匹配中的几何歧义和数据稀缺问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在几何歧义和最近邻规则方面存在局限性，需要几何感知的像素描述符和整体密集对应机制。VGGT的几何基础特征和密集匹配能力符合这一需求。

Method: 保留VGGT早期特征层，微调后期层，并添加语义头部以实现双向对应；采用循环一致性训练策略、合成数据增强和渐进式训练方法来适应数据稀缺场景。

Result: 实验表明，该方法在几何意识、匹配可靠性和流形保持方面表现优异，超越了现有基线。

Conclusion: 本文提出了一种结合几何感知和语义匹配的新方法，通过在VGGT基础上进行改进，显著提升了匹配的几何意识和可靠性，优于现有基线。

Abstract: Semantic matching aims to establish pixel-level correspondences between
instances of the same category and represents a fundamental task in computer
vision. Existing approaches suffer from two limitations: (i) Geometric
Ambiguity: Their reliance on 2D foundation model features (e.g., Stable
Diffusion, DINO) often fails to disambiguate symmetric structures, requiring
extra fine-tuning yet lacking generalization; (ii) Nearest-Neighbor Rule: Their
pixel-wise matching ignores cross-image invisibility and neglects manifold
preservation. These challenges call for geometry-aware pixel descriptors and
holistic dense correspondence mechanisms. Inspired by recent advances in 3D
geometric foundation models, we turn to VGGT, which provides geometry-grounded
features and holistic dense matching capabilities well aligned with these
needs. However, directly transferring VGGT is challenging, as it was originally
designed for geometry matching within cross views of a single instance,
misaligned with cross-instance semantic matching, and further hindered by the
scarcity of dense semantic annotations. To address this, we propose an approach
that (i) retains VGGT's intrinsic strengths by reusing early feature stages,
fine-tuning later ones, and adding a semantic head for bidirectional
correspondences; and (ii) adapts VGGT to the semantic matching scenario under
data scarcity through cycle-consistent training strategy, synthetic data
augmentation, and progressive training recipe with aliasing artifact
mitigation. Extensive experiments demonstrate that our approach achieves
superior geometry awareness, matching reliability, and manifold preservation,
outperforming previous baselines.

</details>


### [80] [MedVSR: Medical Video Super-Resolution with Cross State-Space Propagation](https://arxiv.org/abs/2509.21265)
*Xinyu Liu,Guolei Sun,Cheng Wang,Yixuan Yuan,Ender Konukoglu*

Main category: cs.CV

TL;DR: MedVSR通过CSSP和ISSR模块解决了医学视频超分辨率中的对齐和结构失真问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 高分辨率医学视频难以获取，现有VSR模型在处理低分辨率医学视频时存在对齐困难和结构失真问题。

Method: 采用Cross State-Space Propagation (CSSP)进行精确对齐，Inner State-Space Reconstruction (ISSR)模块增强组织结构和减少伪影。

Result: 在四个数据集上的实验表明，MedVSR在重建性能和处理效率上显著优于现有VSR模型。

Conclusion: MedVSR通过CSSP和ISSR模块有效解决了医学视频超分辨率中的对齐问题和结构失真问题，显著提升了重建性能。

Abstract: High-resolution (HR) medical videos are vital for accurate diagnosis, yet are
hard to acquire due to hardware limitations and physiological constraints.
Clinically, the collected low-resolution (LR) medical videos present unique
challenges for video super-resolution (VSR) models, including camera shake,
noise, and abrupt frame transitions, which result in significant optical flow
errors and alignment difficulties. Additionally, tissues and organs exhibit
continuous and nuanced structures, but current VSR models are prone to
introducing artifacts and distorted features that can mislead doctors. To this
end, we propose MedVSR, a tailored framework for medical VSR. It first employs
Cross State-Space Propagation (CSSP) to address the imprecise alignment by
projecting distant frames as control matrices within state-space models,
enabling the selective propagation of consistent and informative features to
neighboring frames for effective alignment. Moreover, we design an Inner
State-Space Reconstruction (ISSR) module that enhances tissue structures and
reduces artifacts with joint long-range spatial feature learning and
large-kernel short-range information aggregation. Experiments across four
datasets in diverse medical scenarios, including endoscopy and cataract
surgeries, show that MedVSR significantly outperforms existing VSR models in
reconstruction performance and efficiency. Code released at
https://github.com/CUHK-AIM-Group/MedVSR.

</details>


### [81] [MMR1: Enhancing Multimodal Reasoning with Variance-Aware Sampling and Open Resources](https://arxiv.org/abs/2509.21268)
*Sicong Leng,Jing Wang,Jiaxi Li,Hao Zhang,Zhiqiang Hu,Boqiang Zhang,Yuming Jiang,Hang Zhang,Xin Li,Lidong Bing,Deli Zhao,Wei Lu,Yu Rong,Aixin Sun,Shijian Lu*

Main category: cs.CV

TL;DR: 提出了VAS策略解决RL微调中的梯度消失问题，发布了大规模高质量数据和开源模型，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前大模型在长链思维数据和强化学习微调中存在两个主要限制：缺乏高质量、大规模的长链思维数据，以及强化学习算法在后期训练中的不稳定性。

Method: 提出了Variance-Aware Sampling (VAS)策略，结合Variance Promotion Score (VPS)进行数据选择，以提升奖励方差并稳定策略优化。同时，发布了包含约1.6M长链思维数据和15k强化学习问答对的数据集，并开源了多尺度多模态推理模型。

Result: 实验证明，所提出的VAS策略和发布的数据集在多数学推理基准测试中表现优异，理论分析还表明奖励方差对策略梯度幅度的下限有直接影响。

Conclusion: 本研究通过提出Variance-Aware Sampling (VAS)策略、发布大规模高质量数据和开源多模态推理模型，有效解决了大模型在强化学习微调中的梯度消失问题，并推动了多模态推理领域的发展。

Abstract: Large multimodal reasoning models have achieved rapid progress, but their
advancement is constrained by two major limitations: the absence of open,
large-scale, high-quality long chain-of-thought (CoT) data, and the instability
of reinforcement learning (RL) algorithms in post-training. Group Relative
Policy Optimization (GRPO), the standard framework for RL fine-tuning, is prone
to gradient vanishing when reward variance is low, which weakens optimization
signals and impairs convergence. This work makes three contributions: (1) We
propose Variance-Aware Sampling (VAS), a data selection strategy guided by
Variance Promotion Score (VPS) that combines outcome variance and trajectory
diversity to promote reward variance and stabilize policy optimization. (2) We
release large-scale, carefully curated resources containing ~1.6M long CoT
cold-start data and ~15k RL QA pairs, designed to ensure quality, difficulty,
and diversity, along with a fully reproducible end-to-end training codebase.
(3) We open-source a family of multimodal reasoning models in multiple scales,
establishing standardized baselines for the community. Experiments across
mathematical reasoning benchmarks demonstrate the effectiveness of both the
curated data and the proposed VAS. Comprehensive ablation studies and analyses
provide further insight into the contributions of each component. In addition,
we theoretically establish that reward variance lower-bounds the expected
policy gradient magnitude, with VAS serving as a practical mechanism to realize
this guarantee. Our code, data, and checkpoints are available at
https://github.com/LengSicong/MMR1.

</details>


### [82] [Does FLUX Already Know How to Perform Physically Plausible Image Composition?](https://arxiv.org/abs/2509.21278)
*Shilin Lu,Zhuming Lian,Zihan Zhou,Shaocong Zhang,Chen Zhao,Adams Wai-Kin Kong*

Main category: cs.CV

TL;DR: SHINE是一种无训练框架，通过流形导向锚定损失和自适应背景融合技术，实现了高质量、无缝的图像合成，解决了复杂光照和高分辨率输入的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有图像合成模型在复杂光照（如准确阴影、水面反射）和多样化高分辨率输入下表现不佳，而现代文本到图像扩散模型虽具备物理和分辨率先验，但缺乏释放这些潜力的框架。

Method: SHINE引入了流形导向锚定损失、退化抑制指导和自适应背景融合技术，利用预训练的自定义适配器（如IP-Adapter）来引导潜在空间，同时保持背景完整性。

Result: 在ComplexCompo和DreamEditBench上的实验显示，SHINE在标准指标（如DINOv2）和人类对齐评分（如DreamSim、ImageReward、VisionReward）上达到了最先进的性能。

Conclusion: SHINE框架通过无训练的方式实现了高质量、无缝的图像合成，解决了现有模型在复杂光照和高分辨率输入下的挑战，并在多个基准测试中表现出色。

Abstract: Image composition aims to seamlessly insert a user-specified object into a
new scene, but existing models struggle with complex lighting (e.g., accurate
shadows, water reflections) and diverse, high-resolution inputs. Modern
text-to-image diffusion models (e.g., SD3.5, FLUX) already encode essential
physical and resolution priors, yet lack a framework to unleash them without
resorting to latent inversion, which often locks object poses into contextually
inappropriate orientations, or brittle attention surgery. We propose SHINE, a
training-free framework for Seamless, High-fidelity Insertion with Neutralized
Errors. SHINE introduces manifold-steered anchor loss, leveraging pretrained
customization adapters (e.g., IP-Adapter) to guide latents for faithful subject
representation while preserving background integrity. Degradation-suppression
guidance and adaptive background blending are proposed to further eliminate
low-quality outputs and visible seams. To address the lack of rigorous
benchmarks, we introduce ComplexCompo, featuring diverse resolutions and
challenging conditions such as low lighting, strong illumination, intricate
shadows, and reflective surfaces. Experiments on ComplexCompo and
DreamEditBench show state-of-the-art performance on standard metrics (e.g.,
DINOv2) and human-aligned scores (e.g., DreamSim, ImageReward, VisionReward).
Code and benchmark will be publicly available upon publication.

</details>


### [83] [A Sentinel-3 foundation model for ocean colour](https://arxiv.org/abs/2509.21273)
*Geoffrey Dawson,Remy Vandaele,Andrew Taylor,David Moffat,Helen Tamura-Wicks,Sarah Jackson,Rosie Lickorish,Paolo Fraccaro,Hywel Williams,Chunbo Luo,Anne Jones*

Main category: cs.CV

TL;DR: 研究提出了一种基于Prithvi-EO Vision Transformer的预训练基础模型，用于海洋科学中的地球观测任务，展示了其在利用少量标记数据和捕捉海洋颜色空间模式方面的优势。


<details>
  <summary>Details</summary>
Motivation: 海洋科学中标记数据稀缺且昂贵，预训练的基础模型（FMs）可以改变这一现状。

Method: 使用Prithvi-EO Vision Transformer架构预训练，并在两个下游海洋地球观测任务上进行微调。

Result: 模型在利用少量高质量标记数据和捕捉海洋颜色详细空间模式方面表现出色，同时与点观测结果匹配。

Conclusion: 新一代地理空间AI模型有潜力为海洋生态系统及其在全球气候过程中的作用提供更稳健、数据驱动的见解。

Abstract: Artificial Intelligence (AI) Foundation models (FMs), pre-trained on massive
unlabelled datasets, have the potential to drastically change AI applications
in ocean science, where labelled data are often sparse and expensive to
collect. In this work, we describe a new foundation model using the Prithvi-EO
Vision Transformer architecture which has been pre-trained to reconstruct data
from the Sentinel-3 Ocean and Land Colour Instrument (OLCI). We evaluate the
model by fine-tuning on two downstream marine earth observation tasks. We first
assess model performance compared to current baseline models used to quantify
chlorophyll concentration. We then evaluate the FMs ability to refine remote
sensing-based estimates of ocean primary production. Our results demonstrate
the utility of self-trained FMs for marine monitoring, in particular for making
use of small amounts of high quality labelled data and in capturing detailed
spatial patterns of ocean colour whilst matching point observations. We
conclude that this new generation of geospatial AI models has the potential to
provide more robust, data-driven insights into ocean ecosystems and their role
in global climate processes.

</details>


### [84] [SD3.5-Flash: Distribution-Guided Distillation of Generative Flows](https://arxiv.org/abs/2509.21318)
*Hmrishav Bandyopadhyay,Rahim Entezari,Jim Scott,Reshinth Adithyan,Yi-Zhe Song,Varun Jampani*

Main category: cs.CV

TL;DR: SD3.5-Flash通过创新蒸馏和优化技术，实现了在消费设备上的高效高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 为了让高质量图像生成技术能够在各类消费级设备上高效运行，解决计算资源限制问题。

Method: 采用“时间步共享”减少梯度噪声和“分割时间步微调”提升提示对齐，结合文本编码器重构和专用量化等全面优化。

Result: SD3.5-Flash在生成速度、内存效率和用户评价上均优于现有少步生成方法。

Conclusion: SD3.5-Flash通过创新的蒸馏框架和优化技术，成功将高质量图像生成带到消费级设备，显著提升了生成速度和内存效率，并在大规模用户研究中表现优于现有方法。

Abstract: We present SD3.5-Flash, an efficient few-step distillation framework that
brings high-quality image generation to accessible consumer devices. Our
approach distills computationally prohibitive rectified flow models through a
reformulated distribution matching objective tailored specifically for few-step
generation. We introduce two key innovations: "timestep sharing" to reduce
gradient noise and "split-timestep fine-tuning" to improve prompt alignment.
Combined with comprehensive pipeline optimizations like text encoder
restructuring and specialized quantization, our system enables both rapid
generation and memory-efficient deployment across different hardware
configurations. This democratizes access across the full spectrum of devices,
from mobile phones to desktop computers. Through extensive evaluation including
large-scale user studies, we demonstrate that SD3.5-Flash consistently
outperforms existing few-step methods, making advanced generative AI truly
accessible for practical deployment.

</details>


### [85] [Quantized Visual Geometry Grounded Transformer](https://arxiv.org/abs/2509.21302)
*Weilun Feng,Haotong Qin,Mingqiang Wu,Chuanguang Yang,Yuqi Li,Xiangqi Li,Zhulin An,Libo Huang,Yulun Zhang,Michele Magno,Yongjun Xu*

Main category: cs.CV

TL;DR: QuantVGGT 是首个针对 VGGT 的量化框架，通过双平滑和噪声过滤技术，显著提升量化性能，实现高效压缩与加速。


<details>
  <summary>Details</summary>
Motivation: 基于学习的 3D 重建模型（如 VGGT）因计算和内存成本过高，难以在实际场景中部署，而传统的后训练量化方法在压缩此类模型时面临独特挑战。

Method: 提出了双平滑细粒度量化（Dual-Smoothed Fine-Grained Quantization）和噪声过滤多样化采样（Noise-Filtered Diverse Sampling）两种技术，分别解决激活分布重尾问题和校准样本选择不稳定问题。

Result: QuantVGGT 在不同基准测试和比特宽度下均达到最先进水平，4 位量化版本可实现 3.7 倍内存压缩和 2.5 倍加速，同时保持重建精度在原始模型的 98% 以上。

Conclusion: QuantVGGT 是首个针对 VGGT 的量化框架，通过双平滑细粒度量化和噪声过滤多样化采样技术，显著提升了量化性能，在资源受限场景中展现出巨大优势和实用性。

Abstract: Learning-based 3D reconstruction models, represented by Visual Geometry
Grounded Transformers (VGGTs), have made remarkable progress with the use of
large-scale transformers. Their prohibitive computational and memory costs
severely hinder real-world deployment. Post-Training Quantization (PTQ) has
become a common practice for compressing and accelerating models. However, we
empirically observe that PTQ faces unique obstacles when compressing
billion-scale VGGTs: the data-independent special tokens induce heavy-tailed
activation distributions, while the multi-view nature of 3D data makes
calibration sample selection highly unstable. This paper proposes the first
Quantization framework for VGGTs, namely QuantVGGT. This mainly relies on two
technical contributions: First, we introduce Dual-Smoothed Fine-Grained
Quantization, which integrates pre-global Hadamard rotation and post-local
channel smoothing to mitigate heavy-tailed distributions and inter-channel
variance robustly. Second, we design Noise-Filtered Diverse Sampling, which
filters outliers via deep-layer statistics and constructs frame-aware diverse
calibration clusters to ensure stable quantization ranges. Comprehensive
experiments demonstrate that QuantVGGT achieves the state-of-the-art results
across different benchmarks and bit-width, surpassing the previous
state-of-the-art generic quantization method with a great margin. We highlight
that our 4-bit QuantVGGT can deliver a 3.7$\times$ memory reduction and
2.5$\times$ acceleration in real-hardware inference, while maintaining
reconstruction accuracy above 98\% of its full-precision counterpart. This
demonstrates the vast advantages and practicality of QuantVGGT in
resource-constrained scenarios. Our code is released in
https://github.com/wlfeng0509/QuantVGGT.

</details>


### [86] [NewtonGen: Physics-Consistent and Controllable Text-to-Video Generation via Neural Newtonian Dynamics](https://arxiv.org/abs/2509.21309)
*Yu Yuan,Xijun Wang,Tharindu Wickremasinghe,Zeeshan Nadir,Bole Ma,Stanley H. Chan*

Main category: cs.CV

TL;DR: NewtonGen框架通过结合数据驱动和物理原理，显著提升了视频生成的物理一致性和可控性。


<details>
  <summary>Details</summary>
Motivation: 当前的大规模文本到视频生成模型在物理一致性和可控性方面存在瓶颈，常产生不真实的运动，且缺乏精确的参数控制。

Method: 提出了NewtonGen框架，其核心是可训练的神经牛顿动力学（NND），能够建模和预测多种牛顿运动，从而在视频生成过程中注入潜在的动力学约束。

Result: NewtonGen能够生成物理一致性更高的视频，并实现精确的参数控制。

Conclusion: NewtonGen通过结合数据驱动合成和可学习的物理原理，显著提升了文本到视频生成的物理一致性和可控性，为未来视频生成技术的发展提供了新的方向。

Abstract: A primary bottleneck in large-scale text-to-video generation today is
physical consistency and controllability. Despite recent advances,
state-of-the-art models often produce unrealistic motions, such as objects
falling upward, or abrupt changes in velocity and direction. Moreover, these
models lack precise parameter control, struggling to generate physically
consistent dynamics under different initial conditions. We argue that this
fundamental limitation stems from current models learning motion distributions
solely from appearance, while lacking an understanding of the underlying
dynamics. In this work, we propose NewtonGen, a framework that integrates
data-driven synthesis with learnable physical principles. At its core lies
trainable Neural Newtonian Dynamics (NND), which can model and predict a
variety of Newtonian motions, thereby injecting latent dynamical constraints
into the video generation process. By jointly leveraging data priors and
dynamical guidance, NewtonGen enables physically consistent video synthesis
with precise parameter control.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [87] [An Approach to Checking Correctness for Agentic Systems](https://arxiv.org/abs/2509.20364)
*Thomas J Sheffler*

Main category: cs.AI

TL;DR: 本文提出了一种基于时序逻辑的临时表达式语言，用于监控AI代理行为，独立于文本输出检测异常行为，有效识别了模型规模变化导致的行为退化。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本匹配的错误检测方法由于LLM输出的自然语言变异性而显得脆弱，需要一种独立于具体文本输出的行为验证方法。

Method: 提出了一种基于时序逻辑技术的临时表达式语言，用于监控AI代理的行为序列，包括工具调用和状态转换。

Result: 在使用大型模型时，所有临时断言均得到满足；但在使用较小模型时，行为断言被违反，主要由于工具序列不当和协调交接失败。

Conclusion: 该方法为系统性监控AI代理可靠性提供了基础，尤其是在关键应用中的部署。

Abstract: This paper presents a temporal expression language for monitoring AI agent
behavior, enabling systematic error-detection of LLM-based agentic systems that
exhibit variable outputs due to stochastic generation processes. Drawing from
temporal logic techniques used in hardware verification, this approach monitors
execution traces of agent tool calls and state transitions to detect deviations
from expected behavioral patterns. Current error-detection approaches rely
primarily on text matching of inputs and outputs, which proves fragile due to
the natural language variability inherent in LLM responses. The proposed method
instead focuses on the sequence of agent actions -- such as tool invocations
and inter-agent communications -- allowing verification of system behavior
independent of specific textual outputs. The temporal expression language
provides assertions that capture correct behavioral patterns across multiple
execution scenarios. These assertions serve dual purposes: validating prompt
engineering and guardrail effectiveness during development, and providing
regression testing when agents are updated with new LLMs or modified logic. The
approach is demonstrated using a three-agent system, where agents coordinate to
solve multi-step reasoning tasks. When powered by large, capable models, all
temporal assertions were satisfied across many test runs. However, when smaller
models were substituted in two of the three agents, executions violated
behavioral assertions, primarily due to improper tool sequencing and failed
coordination handoffs. The temporal expressions successfully flagged these
anomalies, demonstrating the method's effectiveness for detecting behavioral
regressions in production agentic systems. This approach provides a foundation
for systematic monitoring of AI agent reliability as these systems become
increasingly deployed in critical applications.

</details>


### [88] [LATTS: Locally Adaptive Test-Time Scaling](https://arxiv.org/abs/2509.20368)
*Theo Uscidda,Matthew Trager,Michael Kleinman,Aditya Chattopadhyay,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: LATTS通过动态调整生成步骤的计算资源，优化了LLMs的测试时性能，显著提升了准确性与计算效率的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有的验证模型方法在测试时对所有样本和生成步骤均匀增加计算资源，不考虑个体实例的复杂性，导致资源使用效率低下。

Method: 提出了一种名为LATTS的方法，该方法在每个生成步骤中利用验证模型的接受标准来决定是否重新采样、回溯、重启或停止生成过程。

Result: 实证结果表明，LATTS在准确性与计算效率之间的权衡上显著优于标准的基于验证模型的方法。

Conclusion: LATTS方法通过动态调整每个生成步骤的计算资源，显著提升了LLMs在测试时的准确性与计算效率之间的权衡。

Abstract: One common strategy for improving the performance of Large Language Models
(LLMs) on downstream tasks involves using a \emph{verifier model} to either
select the best answer from a pool of candidates or to steer the
auto-regressive generation process towards better outputs. This class of
methods typically results in improved accuracy at the cost of increased
computation at test-time, a paradigm known as \emph{test-time scaling}.
However, most existing approaches increase computation uniformly across all
samples and generation steps, without considering the complexity of individual
instances, leading to inefficient resource use. We address this limitation by
proposing an approach, called \emph{Locally Adaptive Test-Time Scaling
(LATTS)}, that allocates variable compute across generation steps.
Specifically, at each generation step, LATTS employs a verifier-based
acceptance criterion to decide whether to resample, backtrack, restart, or stop
the generation process. This criterion effectively adjusts the per-step
computational effort based on a precise notion of \emph{local difficulty}
derived from the verifier model. Empirical results show that LATTS achieves
significantly superior accuracy--compute tradeoffs compared to standard
verifier-based methods.

</details>


### [89] [Philosophy-informed Machine Learning](https://arxiv.org/abs/2509.20370)
*MZ Naser*

Main category: cs.AI

TL;DR: PhIML将哲学融入ML，提出了研究路线图和挑战，展示了其应用潜力。


<details>
  <summary>Details</summary>
Motivation: PhIML直接融合分析哲学的核心思想到ML模型中，旨在通过设计尊重哲学概念和价值观，从而获得新的能力。

Method: 通过概念基础回顾和案例研究，展示了如何将PhIML作为后验工具或内置于ML模型架构中。

Result: 展示了哲学增益和一致性，并提供了PhIML的应用案例，揭示了其潜力和挑战。

Conclusion: 本文提出了哲学启发机器学习（PhIML）的研究路线图，旨在实现安全、哲学意识和道德责任的PhIML，同时指出了开放的技术障碍和哲学、实践及治理挑战。

Abstract: Philosophy-informed machine learning (PhIML) directly infuses core ideas from
analytic philosophy into ML model architectures, objectives, and evaluation
protocols. Therefore, PhIML promises new capabilities through models that
respect philosophical concepts and values by design. From this lens, this paper
reviews conceptual foundations to demonstrate philosophical gains and
alignment. In addition, we present case studies on how ML users/designers can
adopt PhIML as an agnostic post-hoc tool or intrinsically build it into ML
model architectures. Finally, this paper sheds light on open technical barriers
alongside philosophical, practical, and governance challenges and outlines a
research roadmap toward safe, philosophy-aware, and ethically responsible
PhIML.

</details>


### [90] [InsightGUIDE: An Opinionated AI Assistant for Guided Critical Reading of Scientific Literature](https://arxiv.org/abs/2509.20493)
*Paris Koloveas,Serafeim Chatzopoulos,Thanasis Vergoulis,Christos Tryfonopoulos*

Main category: cs.AI

TL;DR: InsightGUIDE是一种AI驱动的阅读助手，通过嵌入专家阅读方法，提供结构化摘要，比通用LLM更有效。


<details>
  <summary>Details</summary>
Motivation: 科学文献的激增为研究者带来了挑战，现有工具提供的冗长摘要可能替代而非辅助阅读。

Method: 该系统采用了提示驱动的方法论，并嵌入了专家的阅读方法。

Result: InsightGUIDE生成的输出比通用LLM更加结构化和实用。

Conclusion: InsightGUIDE被证明是一种更有效的工具，能够为现代研究者提供结构化且可操作的指导。

Abstract: The proliferation of scientific literature presents an increasingly
significant challenge for researchers. While Large Language Models (LLMs) offer
promise, existing tools often provide verbose summaries that risk replacing,
rather than assisting, the reading of the source material. This paper
introduces InsightGUIDE, a novel AI-powered tool designed to function as a
reading assistant, not a replacement. Our system provides concise, structured
insights that act as a "map" to a paper's key elements by embedding an expert's
reading methodology directly into its core AI logic. We present the system's
architecture, its prompt-driven methodology, and a qualitative case study
comparing its output to a general-purpose LLM. The results demonstrate that
InsightGUIDE produces more structured and actionable guidance, serving as a
more effective tool for the modern researcher.

</details>


### [91] [Reconstruction-Based Adaptive Scheduling Using AI Inferences in Safety-Critical Systems](https://arxiv.org/abs/2509.20513)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 本文提出了一种动态验证和组装调度的重构框架，解决了时间触发系统中的调度挑战，显著提升了系统性能和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决调度框架面临的重大挑战，包括消息碰撞、错误优先级处理导致的锁定循环以及生成不完整或无效的调度，这些问题可能危及系统安全和性能。

Method: 提出了一个新颖的重构框架，通过系统地将AI生成或启发式导出的调度优先级转换为完全可执行的调度，确保遵守关键系统约束（如优先级规则和无碰撞通信）。框架包含鲁棒的安全检查、高效分配算法和恢复机制。

Result: 实验结果表明，所提出的框架显著提高了系统适应性、操作完整性和运行时性能，同时保持了计算效率。

Conclusion: 该研究为安全关键的时间触发系统（TTS）提供了一个实用且可扩展的解决方案，能够在高度动态和不确定的操作条件下实现可靠且灵活的实时调度。

Abstract: Adaptive scheduling is crucial for ensuring the reliability and safety of
time-triggered systems (TTS) in dynamic operational environments. Scheduling
frameworks face significant challenges, including message collisions, locked
loops from incorrect precedence handling, and the generation of incomplete or
invalid schedules, which can compromise system safety and performance. To
address these challenges, this paper presents a novel reconstruction framework
designed to dynamically validate and assemble schedules. The proposed
reconstruction models operate by systematically transforming AI-generated or
heuristically derived scheduling priorities into fully executable schedules,
ensuring adherence to critical system constraints such as precedence rules and
collision-free communication. It incorporates robust safety checks, efficient
allocation algorithms, and recovery mechanisms to handle unexpected context
events, including hardware failures and mode transitions. Comprehensive
experiments were conducted across multiple performance profiles, including
makespan minimisation, workload balancing, and energy efficiency, to validate
the operational effectiveness of the reconstruction models. Results demonstrate
that the proposed framework significantly enhances system adaptability,
operational integrity, and runtime performance while maintaining computational
efficiency. Overall, this work contributes a practical and scalable solution to
the problem of safe schedule generation in safety-critical TTS, enabling
reliable and flexible real-time scheduling even under highly dynamic and
uncertain operational conditions.

</details>


### [92] [Adaptive Approach to Enhance Machine Learning Scheduling Algorithms During Runtime Using Reinforcement Learning in Metascheduling Applications](https://arxiv.org/abs/2509.20520)
*Samer Alshaer,Ala Khalifeh,Roman Obermaisser*

Main category: cs.AI

TL;DR: 提出了一种自适应在线学习单元的元调度器，利用强化学习在线优化任务调度，解决传统离线训练的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统离线训练方法在构建全面的多调度图（MSG）时面临资源密集和不可行的问题，无法涵盖所有可能的场景。

Method: 提出了一种集成在元调度器中的自适应在线学习单元，利用强化学习（RL）模型在线探索和优化调度解决方案。

Result: 在线学习单元通过RL模型不断发现新的调度解决方案，优化现有调度器，并有效处理意外事件和复杂场景。

Conclusion: 通过整合自适应在线学习单元的元调度器，系统能够在实时环境中动态适应并优化任务调度，从而提高可靠性和效率。

Abstract: Metascheduling in time-triggered architectures has been crucial in adapting
to dynamic and unpredictable environments, ensuring the reliability and
efficiency of task execution. However, traditional approaches face significant
challenges when training Artificial Intelligence (AI) scheduling inferences
offline, particularly due to the complexities involved in constructing a
comprehensive Multi-Schedule Graph (MSG) that accounts for all possible
scenarios. The process of generating an MSG that captures the vast probability
space, especially when considering context events like hardware failures, slack
variations, or mode changes, is resource-intensive and often infeasible. To
address these challenges, we propose an adaptive online learning unit
integrated within the metascheduler to enhance performance in real-time. The
primary motivation for developing this unit stems from the limitations of
offline training, where the MSG created is inherently a subset of the complete
space, focusing only on the most probable and critical context events. In the
online mode, Reinforcement Learning (RL) plays a pivotal role by continuously
exploring and discovering new scheduling solutions, thus expanding the MSG and
enhancing system performance over time. This dynamic adaptation allows the
system to handle unexpected events and complex scheduling scenarios more
effectively. Several RL models were implemented within the online learning
unit, each designed to address specific challenges in scheduling. These models
not only facilitate the discovery of new solutions but also optimize existing
schedulers, particularly when stricter deadlines or new performance criteria
are introduced. By continuously refining the AI inferences through real-time
training, the system remains flexible and capable of meeting evolving demands,
thus ensuring robustness and efficiency in large-scale, safety-critical
environments.

</details>


### [93] [A Compound Classification System Based on Fuzzy Relations Applied to the Noise-Tolerant Control of a Bionic Hand via EMG Signal Recognition](https://arxiv.org/abs/2509.20523)
*Pawel Trajdos,Marek Kurzynski*

Main category: cs.AI

TL;DR: 本文提出了一种用于假肢控制的模糊识别系统，通过检测受污染的EMG信号提高了分类质量，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代仿生上肢假肢通常通过肌电（EMG）生物信号进行控制，但由于生物信号易受污染，导致分类质量下降，因此需要一种能够检测并减轻污染影响的识别系统。

Method: 系统由两个集成组成：一组用于评估单个通道污染程度的单类分类器（OCC）和一个用于识别患者意图的K近邻（KNN）分类器集成。开发了一个原始的、一致的模糊模型，允许在整个识别过程中使用统一的软（模糊）决策方案。

Result: 实验评估使用公共存储库中的真实生物信号进行，结果显示所提出的模糊识别系统在参数和程序上优于文献中描述的类似系统。

Conclusion: 作者提出的模糊识别系统在检测受污染的生物信号方面表现出色，显著提高了假肢控制的分类质量。

Abstract: Modern anthropomorphic upper limb bioprostheses are typically controlled by
electromyographic (EMG) biosignals using a pattern recognition scheme.
Unfortunately, there are many factors originating from the human source of
objects to be classified and from the human-prosthesis interface that make it
difficult to obtain an acceptable classification quality. One of these factors
is the high susceptibility of biosignals to contamination, which can
considerably reduce the quality of classification of a recognition system.
  In the paper, the authors propose a new recognition system intended for EMG
based control of the hand prosthesis with detection of contaminated biosignals
in order to mitigate the adverse effect of contaminations. The system consists
of two ensembles: the set of one-class classifiers (OCC) to assess the degree
of contamination of individual channels and the ensemble of K-nearest
neighbours (KNN) classifier to recognise the patient's intent. For all
recognition systems, an original, coherent fuzzy model was developed, which
allows the use of a uniform soft (fuzzy) decision scheme throughout the
recognition process. The experimental evaluation was conducted using real
biosignals from a public repository. The goal was to provide an experimental
comparative analysis of the parameters and procedures of the developed method
on which the quality of the recognition system depends. The proposed fuzzy
recognition system was also compared with similar systems described in the
literature.

</details>


### [94] [SAMULE: Self-Learning Agents Enhanced by Multi-level Reflection](https://arxiv.org/abs/2509.20562)
*Yubin Ge,Salvatore Romeo,Jason Cai,Monica Sunkara,Yi Zhang*

Main category: cs.AI

TL;DR: SAMULE通过多级反思合成和前瞻性机制，显著提升LLM代理的自我改进能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在复杂任务中因错误分析不足和依赖罕见成功轨迹而难以生成有意义的反思。

Method: 提出SAMULE框架，利用多级反思合成（微观、中观、宏观）训练回顾性语言模型，并扩展至交互式设置。

Result: 在TravelPlanner、NATURAL PLAN和Tau-bench三个基准测试中显著优于基于反思的基线方法。

Conclusion: SAMULE框架通过多级反思合成和前瞻性反思机制，显著提升了LLM代理在复杂任务中的自我改进能力。

Abstract: Despite the rapid advancements in LLM agents, they still face the challenge
of generating meaningful reflections due to inadequate error analysis and a
reliance on rare successful trajectories, especially in complex tasks. In this
work, we propose SAMULE, a new framework for self-learning agents powered by a
retrospective language model that is trained based on Multi-Level Reflection
Synthesis. It first synthesizes high-quality reflections across three
complementary levels: Single-Trajectory Learning (micro-level) for detailed
error correction; Intra-Task Learning (meso-level) to build error taxonomies
across multiple trials of the same task, and Inter-Task Learning (macro-level)
to extract transferable insights based on same typed errors from diverse task
failures. Then we fine-tune a language model serving as the retrospective model
to generate reflections during inference. We further extend our framework to
interactive settings through a foresight-based reflection mechanism, enabling
agents to proactively reflect and adapt during user interactions by comparing
predicted and actual responses. Extensive experiments on three challenging
benchmarks - TravelPlanner, NATURAL PLAN, and Tau-bench - demonstrate that our
approach significantly outperforms reflection-based baselines. Our results
highlight the critical role of well-designed reflection synthesis and
failure-centric learning in building self-improving LLM agents.

</details>


### [95] [Adaptive Cybersecurity Architecture for Digital Product Ecosystems Using Agentic AI](https://arxiv.org/abs/2509.20640)
*Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh*

Main category: cs.AI

TL;DR: 该研究提出了一种基于代理AI的自适应网络安全架构，通过动态学习和上下文感知决策提升复杂数字生态系统的安全性，显著提高了检测准确性和响应速度。


<details>
  <summary>Details</summary>
Motivation: 传统静态网络安全模型在当前数字产品生态系统中（包括云服务、API、移动平台和边缘设备）难以实现可扩展性、实时检测和上下文响应。

Method: 本研究引入了自主目标驱动代理，作为由代理人工智能（AI）驱动的自适应网络安全架构的一部分，集成了行为基线、分散风险评分和联合威胁情报共享等关键功能。

Result: 通过原生云模拟展示了系统识别零日攻击和动态修改访问策略的能力。评估结果显示适应性增强、响应延迟降低且检测准确性提高。

Conclusion: 该架构为保护复杂数字基础设施提供了智能且可扩展的蓝图，并与零信任模型兼容，支持遵守国际网络安全法规。

Abstract: Traditional static cybersecurity models often struggle with scalability,
real-time detection, and contextual responsiveness in the current digital
product ecosystems which include cloud services, application programming
interfaces (APIs), mobile platforms, and edge devices. This study introduces
autonomous goal driven agents capable of dynamic learning and context-aware
decision making as part of an adaptive cybersecurity architecture driven by
agentic artificial intelligence (AI). To facilitate autonomous threat
mitigation, proactive policy enforcement, and real-time anomaly detection, this
framework integrates agentic AI across the key ecosystem layers. Behavioral
baselining, decentralized risk scoring, and federated threat intelligence
sharing are important features. The capacity of the system to identify zero-day
attacks and dynamically modify access policies was demonstrated through native
cloud simulations. The evaluation results show increased adaptability,
decreased response latency, and improved detection accuracy. The architecture
provides an intelligent and scalable blueprint for safeguarding complex digital
infrastructure and is compatible with zero-trust models, thereby supporting the
adherence to international cybersecurity regulations.

</details>


### [96] [Accelerate Creation of Product Claims Using Generative AI](https://arxiv.org/abs/2509.20652)
*Po-Yu Liang,Yong Zhang,Tatiana Hwa,Aaron Byers*

Main category: cs.AI

TL;DR: 开发了Claim Advisor网页应用，利用AI加速产品声明创建，在CPG公司中表现出色，具有跨行业应用潜力。


<details>
  <summary>Details</summary>
Motivation: 产品声明是消费者购买行为的关键驱动因素，但创建声明是一项耗时且成本高昂的任务。

Method: 开发了Claim Advisor网页应用，利用上下文学习和大型语言模型（LLM）的微调来加速产品声明的创建。该应用具有三个功能：语义搜索现有声明、基于产品描述和消费者档案生成/优化声明，以及通过合成消费者模拟对声明进行排名。

Result: 在一家消费品包装公司（CPG）中的应用显示出非常有前景的结果。

Conclusion: 作者认为Claim Advisor的能力在多个产品和行业中具有广泛的应用潜力，并分享了他们的经验以促进生成式AI在不同行业的研究和应用。

Abstract: The benefit claims of a product is a critical driver of consumers' purchase
behavior. Creating product claims is an intense task that requires substantial
time and funding. We have developed the $\textbf{Claim Advisor}$ web
application to accelerate claim creations using in-context learning and
fine-tuning of large language models (LLM). $\textbf{Claim Advisor}$ was
designed to disrupt the speed and economics of claim search, generation,
optimization, and simulation. It has three functions: (1) semantically
searching and identifying existing claims and/or visuals that resonate with the
voice of consumers; (2) generating and/or optimizing claims based on a product
description and a consumer profile; and (3) ranking generated and/or manually
created claims using simulations via synthetic consumers. Applications in a
consumer packaged goods (CPG) company have shown very promising results. We
believe that this capability is broadly useful and applicable across product
categories and industries. We share our learning to encourage the research and
application of generative AI in different industries.

</details>


### [97] [An Automated Retrieval-Augmented Generation LLaMA-4 109B-based System for Evaluating Radiotherapy Treatment Plans](https://arxiv.org/abs/2509.20707)
*Junjie Cui,Peilong Wang,Jason Holmes,Leshan Sun,Michael L. Hinni,Barbara A. Pockaj,Sujay A. Vora,Terence T. Sio,William W. Wong,Nathan Y. Yu,Steven E. Schild,Joshua R. Niska,Sameer R. Keole,Jean-Claude M. Rwigema,Samir H. Patel,Lisa A. McGee,Carlos A. Vargas,Wei Liu*

Main category: cs.AI

TL;DR: 开发了一个基于LLaMA-4 109B的RAG系统，用于自动化评估放射治疗计划，实现了高准确性和协议鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 开发一个由LLaMA-4 109B驱动的检索增强生成（RAG）系统，用于自动化、协议感知和可解释的放射治疗计划评估。

Method: 我们策划了一个包含614个放射治疗计划的多协议数据集，涵盖四个疾病部位，并构建了一个包含标准化剂量指标和协议定义约束的知识库。RAG系统集成了三个核心模块：一个在五个SentenceTransformer骨干上优化的检索引擎、一个基于队列相似性的百分位数预测组件和一个临床约束检查器。这些工具由一个大型语言模型（LLM）通过多步提示驱动的推理管道指导，以产生简洁、有依据的评估。

Result: 检索超参数通过高斯过程在结合均方根误差（RMSE）、平均绝对误差（MAE）和临床动机准确性阈值的标量化损失函数上进行了优化。最佳配置基于all-MiniLM-L6-v2，在5百分位点范围内实现了完美的最近邻准确性，且MAE低于2点。在端到端测试中，RAG系统在百分位数估计和约束识别上与独立检索和约束检查模块的计算值达到了100%的一致性，确认了所有检索、预测和检查步骤的可靠执行。

Conclusion: 本研究展示了结合结构化基于人群的评分与模块化工具增强推理的可行性，为放射治疗提供了透明、可扩展的计划评估系统。系统提供了可追溯的输出，减少了幻觉，并在不同协议中表现出鲁棒性。未来方向包括临床医生主导的验证和改进领域适应的检索模型以增强实际应用。

Abstract: Purpose: To develop a retrieval-augmented generation (RAG) system powered by
LLaMA-4 109B for automated, protocol-aware, and interpretable evaluation of
radiotherapy treatment plans.
  Methods and Materials: We curated a multi-protocol dataset of 614
radiotherapy plans across four disease sites and constructed a knowledge base
containing normalized dose metrics and protocol-defined constraints. The RAG
system integrates three core modules: a retrieval engine optimized across five
SentenceTransformer backbones, a percentile prediction component based on
cohort similarity, and a clinical constraint checker. These tools are directed
by a large language model (LLM) using a multi-step prompt-driven reasoning
pipeline to produce concise, grounded evaluations.
  Results: Retrieval hyperparameters were optimized using Gaussian Process on a
scalarized loss function combining root mean squared error (RMSE), mean
absolute error (MAE), and clinically motivated accuracy thresholds. The best
configuration, based on all-MiniLM-L6-v2, achieved perfect nearest-neighbor
accuracy within a 5-percentile-point margin and a sub-2pt MAE. When tested
end-to-end, the RAG system achieved 100% agreement with the computed values by
standalone retrieval and constraint-checking modules on both percentile
estimates and constraint identification, confirming reliable execution of all
retrieval, prediction and checking steps.
  Conclusion: Our findings highlight the feasibility of combining structured
population-based scoring with modular tool-augmented reasoning for transparent,
scalable plan evaluation in radiation therapy. The system offers traceable
outputs, minimizes hallucination, and demonstrates robustness across protocols.
Future directions include clinician-led validation, and improved domain-adapted
retrieval models to enhance real-world integration.

</details>


### [98] [Fairy: Interactive Mobile Assistant to Real-world Tasks via LMM-based Multi-agent](https://arxiv.org/abs/2509.20729)
*Jiazheng Sun,Te Yang,Jiayang Niu,Mingxuan Li,Yongyong Lu,Ruimeng Yang,Xin Peng*

Main category: cs.AI

TL;DR: Fairy是一种交互式多代理移动助手，通过跨应用协作和持续学习机制，显著提升任务完成效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理多样化应用界面和不断变化的用户需求时表现不佳，尤其是在长尾应用上，且缺乏用户交互的代理会损害用户体验。

Method: Fairy由三个核心模块组成：全局任务规划器、应用级执行器和自我学习器，通过跨应用协作和双循环操作实现精确执行和用户交互。

Result: 实验表明，Fairy在GPT-4o支持下，用户需求完成率提高了33.7%，冗余步骤减少了58.5%，显著优于现有技术。

Conclusion: Fairy通过其交互式多代理设计和持续学习机制，显著提升了移动GUI代理的性能，特别是在满足用户需求和减少冗余步骤方面。

Abstract: Large multi-modal models (LMMs) have advanced mobile GUI agents. However,
existing methods struggle with real-world scenarios involving diverse app
interfaces and evolving user needs. End-to-end methods relying on model's
commonsense often fail on long-tail apps, and agents without user interaction
act unilaterally, harming user experience. To address these limitations, we
propose Fairy, an interactive multi-agent mobile assistant capable of
continuously accumulating app knowledge and self-evolving during usage. Fairy
enables cross-app collaboration, interactive execution, and continual learning
through three core modules:(i) a Global Task Planner that decomposes user tasks
into sub-tasks from a cross-app view; (ii) an App-Level Executor that refines
sub-tasks into steps and actions based on long- and short-term memory,
achieving precise execution and user interaction via four core agents operating
in dual loops; and (iii) a Self-Learner that consolidates execution experience
into App Map and Tricks. To evaluate Fairy, we introduce RealMobile-Eval, a
real-world benchmark with a comprehensive metric suite, and LMM-based agents
for automated scoring. Experiments show that Fairy with GPT-4o backbone
outperforms the previous SoTA by improving user requirement completion by 33.7%
and reducing redundant steps by 58.5%, showing the effectiveness of its
interaction and self-learning.

</details>


### [99] [Parallel Thinking, Sequential Answering: Bridging NAR and AR for Efficient Reasoning](https://arxiv.org/abs/2509.20744)
*Qihang Ai,Haiyun Jiang*

Main category: cs.AI

TL;DR: 结合AR和NAR模型的框架，NAR生成中间推理轨迹，AR生成最终答案，性能提升26%，成本降低。


<details>
  <summary>Details</summary>
Motivation: AR模型在生成连贯输出时推理速度慢，而NAR模型虽然速度快但输出质量较低，因此需要一种结合两者优势的方法。

Method: 通过NAR模型高效生成中间推理轨迹，再用AR模型基于这些轨迹生成精确的最终答案。

Result: 实验表明，该方法比基线模型性能提升了26%，同时大幅降低了推理成本。

Conclusion: 该论文提出了一种结合自回归（AR）和非自回归（NAR）语言模型的新框架，显著提升了推理任务的性能，同时降低了推理成本。

Abstract: We study reasoning tasks through a framework that integrates auto-regressive
(AR) and non-autoregressive (NAR) language models. AR models, which generate
text sequentially, excel at producing coherent outputs but often suffer from
slow inference, particularly in reasoning-intensive domains such as mathematics
and code, where lengthy chains of thought are required. In contrast, NAR
models, such as discrete diffusion models, allow parallel generation and offer
substantial speedups, though typically at the cost of reduced output quality.
To address these limitations, we introduce a new paradigm in which an NAR model
efficiently produces intermediate reasoning traces, which subsequently guide an
AR model to deliver precise final answers. Experiments demonstrate that our
approach yields significant 26% improvements over strong baselines while
substantially reducing inference cost.

</details>


### [100] [Meta-Memory: Retrieving and Integrating Semantic-Spatial Memories for Robot Spatial Reasoning](https://arxiv.org/abs/2509.20754)
*Yufan Mao,Hanjing Ye,Wenlong Dong,Chengjie Zhang,Hong Zhang*

Main category: cs.AI

TL;DR: Meta-Memory是一个LLM驱动的机器人记忆系统，通过联合语义和空间推理提升空间问答能力，在基准测试和真实部署中表现优异。


<details>
  <summary>Details</summary>
Motivation: 机器人在复杂环境中导航需要有效存储观察结果作为记忆，并利用这些记忆回答人类关于空间位置的查询，这是一个关键但研究不足的挑战。

Method: 提出了Meta-Memory，一个由大型语言模型（LLM）驱动的代理，构建环境的高密度记忆表示。其创新点在于能够通过语义和空间模态的联合推理来检索和整合相关记忆，以响应自然语言位置查询。

Result: 实验结果表明，Meta-Memory在SpaceLocQA和公共NaVQA基准测试中显著优于现有最先进方法。

Conclusion: Meta-Memory成功地在真实机器人平台上部署，展示了其在复杂环境中的实际应用价值。

Abstract: Navigating complex environments requires robots to effectively store
observations as memories and leverage them to answer human queries about
spatial locations, which is a critical yet underexplored research challenge.
While prior work has made progress in constructing robotic memory, few have
addressed the principled mechanisms needed for efficient memory retrieval and
integration. To bridge this gap, we propose Meta-Memory, a large language model
(LLM)-driven agent that constructs a high-density memory representation of the
environment. The key innovation of Meta-Memory lies in its capacity to retrieve
and integrate relevant memories through joint reasoning over semantic and
spatial modalities in response to natural language location queries, thereby
empowering robots with robust and accurate spatial reasoning capabilities. To
evaluate its performance, we introduce SpaceLocQA, a large-scale dataset
encompassing diverse real-world spatial question-answering scenarios.
Experimental results show that Meta-Memory significantly outperforms
state-of-the-art methods on both the SpaceLocQA and the public NaVQA
benchmarks. Furthermore, we successfully deployed Meta-Memory on real-world
robotic platforms, demonstrating its practical utility in complex environments.
Project page: https://itsbaymax.github.io/meta-memory.github.io/ .

</details>


### [101] [LogReasoner: Empowering LLMs with Expert-like Coarse-to-Fine Reasoning for Log Analysis Tasks](https://arxiv.org/abs/2509.20798)
*Lipeng Ma,Yixuan Li,Weidong Yang,Mingjie Zhou,Xinyi Liu,Ben Fei,Shuhao Li,Xiaoyan Sun,Sihang Jiang,Yanghua Xiao*

Main category: cs.AI

TL;DR: LogReasoner通过从粗到细的推理增强框架，显著提升了LLMs在日志分析中的性能。


<details>
  <summary>Details</summary>
Motivation: 通用LLMs在日志分析中难以形成结构化推理流程，无法提供精确的推理步骤细节。

Method: LogReasoner采用从粗到细的推理增强框架，包括专家思维的高层构建和具体步骤的细粒度增强。

Result: 实验结果表明，LogReasoner在四个不同的日志分析任务中显著优于现有LLMs。

Conclusion: LogReasoner显著提升了LLMs在日志分析任务中的推理能力，实现了最先进的性能。

Abstract: Log analysis is crucial for monitoring system health and diagnosing failures
in complex systems. Recent advances in large language models (LLMs) offer new
opportunities for automated log analysis, leveraging their reasoning
capabilities to perform tasks such as anomaly detection and failure prediction.
However, general-purpose LLMs struggle to formulate structured reasoning
workflows that align with expert cognition and deliver precise details of
reasoning steps. To address these challenges, we propose LogReasoner, a
coarse-to-fine reasoning enhancement framework designed to enable LLMs to
reason log analysis tasks like experts. LogReasoner consists of two stages: (1)
coarse-grained enhancement of expert thinking, where high-level expert thoughts
are constructed from collected troubleshooting flowcharts and existing tasks to
enable LLMs to formulate structured reasoning workflows and (2) fine-grained
enhancement of specific steps, where we first fine-tune the LLM with
task-specific stepwise solutions to enhance the LLM for instantiated reasoning,
then employ the preference learning to calibrate the LLM's reasoning details
from its mistakes, further strengthen the LLM's analytical granularity and
correctness. We evaluate LogReasoner on four distinct log analysis tasks using
open-source LLMs such as Qwen-2.5 and Llama-3. Experimental results show that
LogReasoner significantly outperforms existing LLMs, achieving state-of-the-art
performance and demonstrating its effectiveness in enhancing the reasoning
capabilities of LLMs for log analysis.

</details>


### [102] [DeFacto: Counterfactual Thinking with Images for Enforcing Evidence-Grounded and Faithful Reasoning](https://arxiv.org/abs/2509.20912)
*Tianrun Xu,Haoda Jing,Ye Li,Yuquan Wei,Jun Feng,Guanyu Chen,Haichuan Gao,Tianren Zhang,Feng Chen*

Main category: cs.AI

TL;DR: DeFacto是一个反事实推理框架，通过三种训练范式和GRPO-based强化学习，提升多模态语言模型的准确性和推理忠实性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态语言模型在视觉语言推理中可能依赖无关或虚假区域的问题，即使答案正确，推理过程也可能存在缺陷，强调了推理忠实性的重要性。

Method: 提出了DeFacto框架，包含三种互补的训练范式：正向、反事实和随机掩码，并通过GRPO-based强化学习训练模型，设计了三种互补的奖励机制。

Result: 在多样化基准测试中，DeFacto显著提高了答案准确性和推理忠实性。

Conclusion: DeFacto框架通过联合训练范式显著提升了多模态语言模型在回答准确性和推理忠实性方面的表现，为可解释的多模态推理奠定了更强的基础。

Abstract: Recent advances in multimodal language models (MLLMs) have achieved
remarkable progress in vision-language reasoning, especially with the emergence
of "thinking with images," which integrates explicit visual steps into the
reasoning process. While this paradigm strengthens image-based reasoning, a
significant challenge remains: models may arrive at correct answers by relying
on irrelevant or spurious regions, driven by prior knowledge or dataset biases.
Even when the answer is correct, flawed reasoning indicates that the model has
not truly understood the image, highlighting the critical importance of
reasoning fidelity in multimodal tasks. To address this issue, we propose
DeFacto, a counterfactual reasoning framework that jointly enforces accurate
answering and faithful reasoning. A key component of our approach is the design
of three complementary training paradigms: (i) positive, (ii) counterfactual,
and (iii) random-masking. To enable these paradigms, we develop a pipeline that
automatically localizes question-relevant evidence and constructs positive,
counterfactual, and random variants, resulting in a dataset of about 100k
images. Building on this framework, we train multimodal language models with
GRPO-based reinforcement learning, where we design three complementary rewards
to guide the model toward accurate answering and evidence-grounded reasoning.
Experiments on diverse benchmarks demonstrate that DeFacto substantially
improves both answer accuracy and reasoning faithfulness, establishing a
stronger foundation for interpretable multimodal reasoning. The code is
available on GitHub and the dataset is released on HuggingFace.

</details>


### [103] [GALAX: Graph-Augmented Language Model for Explainable Reinforcement-Guided Subgraph Reasoning in Precision Medicine](https://arxiv.org/abs/2509.20935)
*Heming Zhang,Di Huang,Wenyu Li,Michael Province,Yixin Chen,Philip Payne,Fuhai Li*

Main category: cs.AI

TL;DR: GALAX结合图神经网络和大型语言模型，通过强化学习引导的子图推理，提升精准医学中目标发现的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉定量多组学特征、拓扑背景和文本生物知识方面存在局限性，限制了机制的可解释性。GALAX旨在通过整合这些元素，提升精准医学中的目标发现能力。

Method: GALAX框架通过强化学习引导的图过程奖励模型（GPRM）将预训练的图神经网络（GNNs）集成到大型语言模型（LLMs）中，逐步生成疾病相关子图。

Result: GALAX框架通过Target-QA基准测试验证了其在长上下文推理和可解释子图推理方面的有效性，为精准医学提供了可扩展且生物学基础扎实的解决方案。

Conclusion: GALAX框架通过结合预训练的图神经网络和大型语言模型，提出了一种可解释、强化引导的子图推理方法，为精准医学中的目标和通路发现提供了可靠且可解释的解决方案。

Abstract: In precision medicine, quantitative multi-omic features, topological context,
and textual biological knowledge play vital roles in identifying
disease-critical signaling pathways and targets. Existing pipelines capture
only part of these-numerical omics ignore topological context, text-centric
LLMs lack quantitative grounded reasoning, and graph-only models underuse node
semantics and the generalization of LLMs-limiting mechanistic interpretability.
Although Process Reward Models (PRMs) aim to guide reasoning in LLMs, they
remain limited by unreliable intermediate evaluation, and vulnerability to
reward hacking with computational cost. These gaps motivate integrating
quantitative multi-omic signals, topological structure with node annotations,
and literature-scale text via LLMs, using subgraph reasoning as the principle
bridge linking numeric evidence, topological knowledge and language context.
Therefore, we propose GALAX (Graph Augmented LAnguage model with
eXplainability), an innovative framework that integrates pretrained Graph
Neural Networks (GNNs) into Large Language Models (LLMs) via reinforcement
guided by a Graph Process Reward Model (GPRM), which generates disease-relevant
subgraphs in a step-wise manner initiated by an LLM and iteratively evaluated
by a pretrained GNN, enabling process-level supervision without explicit
intermediate reasoning annotations. As an application, we also introduced
Target-QA, a benchmark combining CRISPR-identified targets, multi-omic
profiles, and biomedical graph knowledge across diverse cancer cell lines,
which enables GNN pretraining for supervising step-wise graph construction and
supports long-context reasoning over text-numeric graphs (TNGs), providing a
scalable and biologically grounded framework for explainable,
reinforcement-guided subgraph reasoning toward reliable and interpretable
target and pathway discovery in precision medicine.

</details>


### [104] [Beyond Stars: Bridging the Gap Between Ratings and Review Sentiment with LLM](https://arxiv.org/abs/2509.20953)
*Najla Zuhir,Amna Mohammad Salim,Parvathy Premkumar,Moshiur Farazi*

Main category: cs.AI

TL;DR: 论文提出一种LLM驱动的移动应用评论分析框架，优于传统方法，能更好处理复杂评论场景。


<details>
  <summary>Details</summary>
Motivation: 传统星级评分系统无法捕捉详细评论中的细微反馈，且现有NLP技术在解释上下文、领域术语和讽刺等语言特征时表现不佳。

Method: 采用大型语言模型（LLMs）结合结构化提示技术，构建模块化框架，量化评分与文本情感差异，提取特征级洞察，并支持通过检索增强的对话问答（RAG-QA）交互探索评论。

Result: 在三个多样化数据集（AWARE、Google Play和Spotify）上的实验表明，该方法在准确性、鲁棒性和可操作性方面显著优于基线方法。

Conclusion: 论文提出了一种基于大型语言模型（LLMs）和结构化提示技术的模块化框架，显著提升了移动应用评论分析的准确性、鲁棒性和可操作性，优于传统方法。

Abstract: We present an advanced approach to mobile app review analysis aimed at
addressing limitations inherent in traditional star-rating systems. Star
ratings, although intuitive and popular among users, often fail to capture the
nuanced feedback present in detailed review texts. Traditional NLP techniques
-- such as lexicon-based methods and classical machine learning classifiers --
struggle to interpret contextual nuances, domain-specific terminology, and
subtle linguistic features like sarcasm. To overcome these limitations, we
propose a modular framework leveraging large language models (LLMs) enhanced by
structured prompting techniques. Our method quantifies discrepancies between
numerical ratings and textual sentiment, extracts detailed, feature-level
insights, and supports interactive exploration of reviews through
retrieval-augmented conversational question answering (RAG-QA). Comprehensive
experiments conducted on three diverse datasets (AWARE, Google Play, and
Spotify) demonstrate that our LLM-driven approach significantly surpasses
baseline methods, yielding improved accuracy, robustness, and actionable
insights in challenging and context-rich review scenarios.

</details>


### [105] [AOT*: Efficient Synthesis Planning via LLM-Empowered AND-OR Tree Search](https://arxiv.org/abs/2509.20988)
*Xiaozhuang Song,Xuanhao Pan,Xinjian Zhao,Hangting Ye,Shufei Zhang,Jian Tang,Tianshu Yu*

Main category: cs.AI

TL;DR: AOT*框架结合LLM与AND-OR树搜索，显著提升逆合成规划效率，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多步逆合成规划在计算上具有挑战性，主要由于指数级搜索空间和推理成本。尽管LLMs展示了化学推理能力，但其在合成规划中的应用仍受限于效率和成本。

Method: AOT*框架通过原子映射生成的完整合成路径到AND-OR树组件，并设计了数学上合理的奖励分配策略和基于检索的上下文工程。

Result: AOT*在多个合成基准测试中表现出SOTA性能，使用3-5倍更少的迭代次数即可达到与现有LLM方法相当的解决率。

Conclusion: AOT*框架通过结合LLM生成的化学合成路径与系统化的AND-OR树搜索，显著提升了多步逆合成规划的效率，并在多个合成基准测试中取得了SOTA性能。

Abstract: Retrosynthesis planning enables the discovery of viable synthetic routes for
target molecules, playing a crucial role in domains like drug discovery and
materials design. Multi-step retrosynthetic planning remains computationally
challenging due to exponential search spaces and inference costs. While Large
Language Models (LLMs) demonstrate chemical reasoning capabilities, their
application to synthesis planning faces constraints on efficiency and cost. To
address these challenges, we introduce AOT*, a framework that transforms
retrosynthetic planning by integrating LLM-generated chemical synthesis
pathways with systematic AND-OR tree search. To this end, AOT* atomically maps
the generated complete synthesis routes onto AND-OR tree components, with a
mathematically sound design of reward assignment strategy and retrieval-based
context engineering, thus enabling LLMs to efficiently navigate in the chemical
space. Experimental evaluation on multiple synthesis benchmarks demonstrates
that AOT* achieves SOTA performance with significantly improved search
efficiency. AOT* exhibits competitive solve rates using 3-5$\times$ fewer
iterations than existing LLM-based approaches, with the efficiency advantage
becoming more pronounced on complex molecular targets.

</details>


### [106] [CORE: Full-Path Evaluation of LLM Agents Beyond Final State](https://arxiv.org/abs/2509.20998)
*Panagiotis Michelakis,Yiannis Hadjiyiannis,Dimitrios Stamoulis*

Main category: cs.AI

TL;DR: 论文提出基于DFA的框架和CORE指标，全面评估AI代理的任务执行行为，弥补传统二元判断的不足。


<details>
  <summary>Details</summary>
Motivation: 现有代理基准测试通常仅对最终状态进行二元判断，忽略了安全性、效率和中间正确性等关键方面，因此需要一种更全面的评估框架。

Method: 该方法使用DFA将任务编码为有效工具使用路径的集合，并引入CORE（五种指标）来评估代理行为的安全性和效率等关键方面。

Result: 在不同世界模型中，该方法揭示了传统最终状态评估方案下看似等效的代理之间的重要性能差异。

Conclusion: 该论文提出了一种基于确定性有限自动机（DFA）的框架，用于评估AI代理在解决现实任务中的行为表现，并通过CORE指标套件量化其执行模式的对齐情况。

Abstract: Evaluating AI agents that solve real-world tasks through function-call
sequences remains an open challenge. Existing agentic benchmarks often reduce
evaluation to a binary judgment of the final state, overlooking critical
aspects such as safety, efficiency, and intermediate correctness. We propose a
framework based on deterministic finite automata (DFAs) that encodes tasks as
sets of valid tool-use paths, enabling principled assessment of agent behavior
in diverse world models. Building on this foundation, we introduce CORE, a
suite of five metrics, namely Path Correctness, Path Correctness - Kendall's
tau Composite, Prefix Criticality, Harmful-Call Rate, and Efficiency, that
quantify alignment with expected execution patterns. Across diverse worlds, our
method reveals important performance differences between agents that would
otherwise appear equivalent under traditional final-state evaluation schemes.

</details>


### [107] [Who Gets Cited Most? Benchmarking Long-Context Language Models on Scientific Articles](https://arxiv.org/abs/2509.21028)
*Miao Li,Alexander Gurung,Irina Saparina,Mirella Lapata*

Main category: cs.AI

TL;DR: SciTrek 是一个通过科学文章评估LLM长上下文推理能力的新基准测试，揭示了模型在长上下文中的系统性问题。


<details>
  <summary>Details</summary>
Motivation: 当前的长上下文基准测试多依赖非科学文本、简单信息检索任务或人工上下文，SciTrek 旨在通过复杂问题和科学文章解决这些局限。

Method: 通过将问题自动生成为对由文章元数据构建的数据库的SQL查询，SciTrek 提供了可验证的推理步骤，支持细粒度错误分析，并能扩展到长达1M token的上下文。

Result: 实验表明，随着上下文长度增加，SciTrek 对多种LLM构成显著挑战，监督微调和强化学习带来的改进有限。

Conclusion: SciTrek 是一个创新的长上下文推理基准测试，通过科学文章评估大型语言模型的性能，揭示了模型在长上下文中的系统性问题，如基本数值运算和精确信息定位的不足。

Abstract: This paper introduces SciTrek, a novel question-answering benchmark designed
to evaluate the long-context reasoning capabilities of large language models
(LLMs) using scientific articles. Current long-context benchmarks often rely on
non-scientific texts, focus on simple information retrieval tasks, or employ
artificial contexts. SciTrek addresses these limitations by proposing complex
questions that require information aggregation and synthesis across multiple
full-text scientific articles. Questions and their ground-truth answers are
automatically generated by formulating them as SQL queries over a database
constructed from article metadata (titles, authors, and references). The SQL
operations provide explicit, verifiable reasoning steps for fine-grained error
analysis, and the construction process scales to contexts up to 1M tokens with
minimal supervision. Extensive experiments on a diverse set of open-weight and
proprietary LLMs demonstrate that SciTrek poses a significant challenge as the
context length increases, with supervised fine-tuning and reinforcement
learning offering only limited gains. Our analysis reveals systematic
shortcomings in models' abilities to perform basic numerical operations and
accurately locate specific information in long contexts.

</details>


### [108] [CLAUSE: Agentic Neuro-Symbolic Knowledge Graph Reasoning via Dynamic Learnable Context Engineering](https://arxiv.org/abs/2509.21035)
*Yang Zhao,Chengxiao Dai,Wei Zhuo,Yue Xiu,Dusit Niyato*

Main category: cs.AI

TL;DR: CLAUSE是一个三代理神经符号框架，通过动态决策优化知识图谱的上下文构建，在多跳问答中实现了更高准确率和更低延迟。


<details>
  <summary>Details</summary>
Motivation: 解决静态扩展和提示方法在多跳问答中过度检索、上下文膨胀和运行时不可预测的问题。

Method: CLAUSE采用三代理神经符号框架（Subgraph Architect、Path Navigator、Context Curator）和LC-MAPPO算法，动态决策知识图谱的扩展、路径选择和证据保留。

Result: 在HotpotQA、MetaQA和FactKG上，CLAUSE在相同或更低token预算下，实现了更高的EM@1，降低了子图增长和端到端延迟。例如，在MetaQA-2-hop上，相比GraphRAG，CLAUSE的EM@1提高了39.3%，延迟降低了18.6%，边增长减少了40.9%。

Conclusion: CLAUSE通过其神经符号框架和LC-MAPPO算法，在多跳问答任务中实现了更高的准确率（EM@1），同时降低了子图增长和延迟，且保持了来源的可追溯性。

Abstract: Knowledge graphs provide structured context for multi-hop question answering,
but deployed systems must balance answer accuracy with strict latency and cost
targets while preserving provenance. Static k-hop expansions and "think-longer"
prompting often over-retrieve, inflate context, and yield unpredictable
runtime. We introduce CLAUSE, an agentic three-agent neuro-symbolic framework
that treats context construction as a sequential decision process over
knowledge graphs, deciding what to expand, which paths to follow or backtrack,
what evidence to keep, and when to stop. Latency (interaction steps) and prompt
cost (selected tokens) are exposed as user-specified budgets or prices,
allowing per-query adaptation to trade-offs among accuracy, latency, and cost
without retraining. CLAUSE employs the proposed Lagrangian-Constrained
Multi-Agent Proximal Policy Optimization (LC-MAPPO) algorithm to coordinate
three agents: Subgraph Architect, Path Navigator, and Context Curator, so that
subgraph construction, reasoning-path discovery, and evidence selection are
jointly optimized under per-query resource budgets on edge edits, interaction
steps, and selected tokens. Across HotpotQA, MetaQA, and FactKG, CLAUSE yields
higher EM@1 while reducing subgraph growth and end-to-end latency at equal or
lower token budgets. On MetaQA-2-hop, relative to the strongest RAG baseline
(GraphRAG), CLAUSE achieves +39.3 EM@1 with 18.6% lower latency and 40.9% lower
edge growth. The resulting contexts are compact, provenance-preserving, and
deliver predictable performance under deployment constraints.

</details>


### [109] [Combinatorial Creativity: A New Frontier in Generalization Abilities](https://arxiv.org/abs/2509.21043)
*Samuel Schapiro,Sumuk Shashidhar,Alexi Gladstone,Jonah Black,Royce Moon,Dilek Hakkani-Tur,Lav R. Varshney*

Main category: cs.AI

TL;DR: 该研究探讨了LLMs在创造性任务中的表现，提出了评估框架，并发现模型深度、宽度及新颖性-实用性权衡是影响创造力的关键因素。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）越来越多地用于创造性任务，如科学创意生成，这是一种现有概念框架未涵盖的泛化形式。

Method: 提出了一个理论框架和算法任务，用于评估输出的新颖性和实用性程度。

Result: (1) 首次洞察了LLMs创造力的扩展行为；(2) 发现固定计算预算下存在最佳模型深度和宽度；(3) 发现创意生成与执行之间的差距可能由更基本的新颖性-实用性权衡解释。

Conclusion: 该研究的概念框架和实证发现为理解和改进现代AI模型的创造力奠定了基础，标志着泛化能力的新前沿。

Abstract: Artificial intelligence (AI) systems, and large language models (LLMs) in
particular, are increasingly employed for creative tasks like scientific idea
generation, constituting a form of generalization from training data
unaddressed by existing conceptual frameworks. Though in many ways similar to
forms of compositional generalization (CG), combinatorial creativity (CC) is an
open-ended ability. Instead of evaluating for accuracy or correctness against
fixed targets, which would contradict the open-ended nature of CC, we propose a
theoretical framework and algorithmic task for evaluating outputs by their
degrees of novelty and utility. From here, we make several important empirical
contributions: (1) We obtain the first insights into the scaling behavior of
creativity for LLMs. (2) We discover that, for fixed compute budgets, there
exist optimal model depths and widths for creative ability. (3) We find that
the ideation-execution gap, whereby LLMs excel at generating novel scientific
ideas but struggle to ensure their practical feasibility, may be explained by a
more fundamental novelty-utility tradeoff characteristic of creativity
algorithms in general. Importantly, this tradeoff remains persistent even at
scale, casting doubt on the long-term creative potential of LLMs in their
current form. Together, our conceptual framework and empirical findings provide
a foundation for understanding and improving creativity in modern AI models,
marking a new frontier in generalization abilities.

</details>


### [110] [Disagreements in Reasoning: How a Model's Thinking Process Dictates Persuasion in Multi-Agent Systems](https://arxiv.org/abs/2509.21054)
*Haodong Zhao,Jidong Li,Zhaomin Wu,Tianjie Ju,Zhuosheng Zhang,Bingsheng He,Gongshen Liu*

Main category: cs.AI

TL;DR: 本研究挑战了模型规模决定说服效果的假设，提出认知过程是关键。实验发现LRMs推理更具抵抗性，透明化则增强说服力，并揭示了多跳说服的复杂动态。


<details>
  <summary>Details</summary>
Motivation: 挑战了当前普遍认为说服效果主要取决于模型规模的假设，提出这些动态根本上由模型的底层认知过程，尤其是其显式推理能力所决定。

Method: 通过一系列多智能体说服实验，提出了‘说服二元性’的基本权衡，并考察了更复杂的传播说服情境。

Result: 研究发现，大型推理模型（LRMs）的推理过程表现出更强的说服抵抗性，能更稳固地保持初始信念；而通过共享‘思考内容’使推理过程透明化，则显著增强了其说服他人的能力。此外，还揭示了多跳说服中影响力传播和衰减的复杂动态。

Conclusion: 本研究通过系统证据揭示了模型内部处理架构与其外部说服行为之间的联系，为高级模型的易感性提供了新颖解释，并强调了未来多智能体系统（MAS）在安全、鲁棒性和设计上的关键影响。

Abstract: The rapid proliferation of recent Multi-Agent Systems (MAS), where Large
Language Models (LLMs) and Large Reasoning Models (LRMs) usually collaborate to
solve complex problems, necessitates a deep understanding of the persuasion
dynamics that govern their interactions. This paper challenges the prevailing
hypothesis that persuasive efficacy is primarily a function of model scale. We
propose instead that these dynamics are fundamentally dictated by a model's
underlying cognitive process, especially its capacity for explicit reasoning.
Through a series of multi-agent persuasion experiments, we uncover a
fundamental trade-off we term the Persuasion Duality. Our findings reveal that
the reasoning process in LRMs exhibits significantly greater resistance to
persuasion, maintaining their initial beliefs more robustly. Conversely, making
this reasoning process transparent by sharing the "thinking content"
dramatically increases their ability to persuade others. We further consider
more complex transmission persuasion situations and reveal complex dynamics of
influence propagation and decay within multi-hop persuasion between multiple
agent networks. This research provides systematic evidence linking a model's
internal processing architecture to its external persuasive behavior, offering
a novel explanation for the susceptibility of advanced models and highlighting
critical implications for the safety, robustness, and design of future MAS.

</details>


### [111] [Recon-Act: A Self-Evolving Multi-Agent Browser-Use System via Web Reconnaissance, Tool Generation, and Task Execution](https://arxiv.org/abs/2509.21072)
*Kaiwen He,Zhiwei Wang,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: Recon-Act是一种自演进的多代理框架，通过侦察-行动范式提升智能浏览器代理在多轮长视野任务中的表现，显著减少试错并提高适应性。


<details>
  <summary>Details</summary>
Motivation: 当前智能浏览器代理在多轮、长视野任务中存在行动序列混乱和过多试错的问题，亟需改进。

Method: 该系统由侦察团队和行动团队组成，前者进行对比分析和工具生成，后者负责意图分解、工具编排和执行。通过将错误轨迹与成功轨迹对比，侦察团队推断补救措施并将其抽象为通用工具，实时注册到工具库中。

Result: Recon-Act在VisualWebArena数据集上实现了最先进的性能，显著提升了对未见网站的适应性和长视野任务的解决能力。

Conclusion: Recon-Act通过引入侦察-行动行为范式，显著提升了多模态模型在真实世界网页任务中的适应性和解决能力，尤其在长视野任务上表现优异。

Abstract: Recent years, multimodal models have made remarkable strides and pave the way
for intelligent browser use agents. However, when solving tasks on real world
webpages in multi-turn, long-horizon trajectories, current agents still suffer
from disordered action sequencing and excessive trial and error during
execution. This paper introduces Recon-Act, a self-evolving multi-agent
framework grounded in Reconnaissance-Action behavioral paradigm. The system
comprises a Reconnaissance Team and an Action Team: the former conducts
comparative analysis and tool generation, while the latter handles intent
decomposition, tool orchestration, and execution. By contrasting the erroneous
trajectories with successful ones, the Reconnaissance Team infers remedies, and
abstracts them into a unified notion of generalized tools, either expressed as
hints or as rule-based codes, and register to the tool archive in real time.
The Action Team reinference the process empowered with these targeting tools,
thus establishing a closed-loop training pipeline of
data-tools-action-feedback. Following the 6 level implementation roadmap
proposed in this work, we have currently reached Level 3 (with limited
human-in-the-loop intervention). Leveraging generalized tools obtained through
reconnaissance, Recon-Act substantially improves adaptability to unseen
websites and solvability on long-horizon tasks, and achieves state-of-the-art
performance on the challenging VisualWebArena dataset.

</details>


### [112] [TrustJudge: Inconsistencies of LLM-as-a-Judge and How to Alleviate Them](https://arxiv.org/abs/2509.21117)
*Yidong Wang,Yunze Song,Tingyuan Zhu,Xuanwang Zhang,Zhuohao Yu,Hao Chen,Chiyu Song,Qiufeng Wang,Cunxiang Wang,Zhen Wu,Xinyu Dai,Yue Zhang,Wei Ye,Shikun Zhang*

Main category: cs.AI

TL;DR: TrustJudge通过概率方法解决LLM评估中的不一致问题，显著提升评估可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估框架存在评分比较和成对传递性不一致问题，影响评估可靠性。

Method: 提出TrustJudge概率框架，包括分布敏感评分和似然感知聚合两项创新。

Result: TrustJudge将评分比较不一致性降低8.43%，成对传递不一致性降低10.82%，同时保持高评估准确率。

Conclusion: TrustJudge框架通过概率方法显著减少了LLM评估中的不一致性，为自动化评估提供了可靠的理论和实践解决方案。

Abstract: The adoption of Large Language Models (LLMs) as automated evaluators
(LLM-as-a-judge) has revealed critical inconsistencies in current evaluation
frameworks. We identify two fundamental types of inconsistencies: (1)
Score-Comparison Inconsistency, where lower-rated responses outperform
higher-scored ones in pairwise comparisons, and (2) Pairwise Transitivity
Inconsistency, manifested through circular preference chains (A>B>C>A) and
equivalence contradictions (A=B=C\neq A). We argue that these issues come from
information loss in discrete rating systems and ambiguous tie judgments during
pairwise evaluation. We propose TrustJudge, a probabilistic framework that
addresses these limitations through two key innovations: 1)
distribution-sensitive scoring that computes continuous expectations from
discrete rating probabilities, preserving information entropy for more precise
scoring, and 2) likelihood-aware aggregation that resolves transitivity
violations using bidirectional preference probabilities or perplexity. We also
formalize the theoretical limitations of current LLM-as-a-judge frameworks and
demonstrate how TrustJudge's components overcome them. When evaluated with
Llama-3.1-70B-Instruct as judge using our dataset, TrustJudge reduces
Score-Comparison inconsistency by 8.43% (from 23.32% to 14.89%) and Pairwise
Transitivity inconsistency by 10.82% (from 15.22% to 4.40%), while maintaining
higher evaluation accuracy. Our work provides the first systematic analysis of
evaluation framework inconsistencies in LLM-as-a-judge paradigms, offering both
theoretical insights and practical solutions for reliable automated assessment.
The framework demonstrates consistent improvements across various model
architectures and scales, enabling more trustworthy LLM evaluation without
requiring additional training or human annotations. The codes can be found at
https://github.com/TrustJudge/TrustJudge.

</details>


### [113] [Expanding Reasoning Potential in Foundation Model by Learning Diverse Chains of Thought Patterns](https://arxiv.org/abs/2509.21124)
*Xuemiao Zhang,Can Ren,Chengying Tu,Rongxiang Weng,Shuo Wang,Hongfei Yan,Jingang Wang,Xunliang Cai*

Main category: cs.AI

TL;DR: 本文定义了推理潜力并提出了高效选择高价值CoT数据的方法，显著提升了模型在数学推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前方法对CoT数据的使用缺乏选择性，未能有效提升模型推理能力，因此需要定义推理潜力并探索哪些数据类型最能增强模型推理能力。

Method: 提出了一种双粒度算法，结合推理模式链和令牌熵，从数据池中高效选择高价值CoT数据（CoTP），并构建了一个富含有价值推理模式的核心参考集。

Result: 仅使用10B-token的CoTP数据，85A6B Mixture-of-Experts (MoE)模型在AIME 2024和2025上的表现提升了9.58%，下游RL性能上限提高了7.81%。

Conclusion: 通过提出推理潜力定义和高效选择高价值CoT数据的方法，显著提升了模型在复杂数学推理任务中的表现，并提高了下游强化学习的性能上限。

Abstract: Recent progress in large reasoning models for challenging mathematical
reasoning has been driven by reinforcement learning (RL). Incorporating long
chain-of-thought (CoT) data during mid-training has also been shown to
substantially improve reasoning depth. However, current approaches often
utilize CoT data indiscriminately, leaving open the critical question of which
data types most effectively enhance model reasoning capabilities. In this
paper, we define the foundation model's reasoning potential for the first time
as the inverse of the number of independent attempts required to correctly
answer the question, which is strongly correlated with the final model
performance. We then propose utilizing diverse data enriched with high-value
reasoning patterns to expand the reasoning potential. Specifically, we abstract
atomic reasoning patterns from CoT sequences, characterized by commonality and
inductive capabilities, and use them to construct a core reference set enriched
with valuable reasoning patterns. Furthermore, we propose a dual-granularity
algorithm involving chains of reasoning patterns and token entropy, efficiently
selecting high-value CoT data (CoTP) from the data pool that aligns with the
core set, thereby training models to master reasoning effectively. Only
10B-token CoTP data enables the 85A6B Mixture-of-Experts (MoE) model to improve
by 9.58% on the challenging AIME 2024 and 2025, and to raise the upper bound of
downstream RL performance by 7.81%.

</details>


### [114] [RL Squeezes, SFT Expands: A Comparative Study of Reasoning LLMs](https://arxiv.org/abs/2509.21128)
*Kohsei Matsutani,Shota Takashiro,Gouki Minegishi,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 该论文通过量化分析推理路径，揭示RL和SFT如何互补塑造LLMs的推理能力，解释了两阶段训练的成功原因。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs通常通过RL和SFT训练以提高推理能力，但这些方法如何塑造推理能力尚不明确。

Method: 引入一个新颖的分析框架，量化推理路径并捕捉其在每个训练过程中的定性变化（在数学领域使用1.5B、7B和14B参数的模型）。具体包括轨迹级和步骤级的分析。

Result: RL压缩错误推理轨迹，SFT扩展正确轨迹；RL使推理功能集中于少数步骤，SFT使其均匀分布。

Conclusion: 当前最佳实践——先进行SFT再进行RL的两阶段训练之所以成功，是因为RL压缩错误推理轨迹而SFT扩展正确轨迹，且RL集中推理功能于少数步骤而SFT使其均匀分布。

Abstract: Large language models (LLMs) are typically trained by reinforcement learning
(RL) with verifiable rewards (RLVR) and supervised fine-tuning (SFT) on
reasoning traces to improve their reasoning abilities. However, how these
methods shape reasoning capabilities remains largely elusive. Going beyond an
accuracy-based investigation of how these two components sculpt the reasoning
process, this paper introduces a novel analysis framework that quantifies
reasoning paths and captures their qualitative changes under each training
process (with models of 1.5B, 7B, and 14B parameters on mathematical domains).
Specifically, we investigate the reasoning process at two levels of
granularity: the trajectory-level, which examines complete reasoning outputs,
and the step-level, which analyzes reasoning graphs whose nodes correspond to
individual reasoning steps. Notably, clustering of unique reasoning
trajectories shows complementary effects: RL compresses incorrect trajectories,
whereas SFT expands correct ones. Step-level analysis reveals that RL steepens
(about 2.5 times), while SFT flattens (reduced to about one-third), the decay
rates of node visitation frequency, degree, and betweenness centrality
distributions in the reasoning graph. This indicates that RL concentrates
reasoning functionality into a small subset of steps, while SFT homogenizes it
across many steps. Furthermore, by evaluating the reasoning graph topologies
from multiple perspectives, we delineate the shared and distinct
characteristics of RL and SFT. Our work presents a novel reasoning path
perspective that explains why the current best practice of two-stage training,
with SFT followed by RL, is successful, and offers practical implications for
data construction and more efficient learning approaches.

</details>


### [115] [ToMPO: Training LLM Strategic Decision Making from a Multi-Agent Perspective](https://arxiv.org/abs/2509.21134)
*Yiwen Zhang,Ziang Chen,Fanqi Kong,Yizhe Huang,Xue Feng*

Main category: cs.AI

TL;DR: ToMPO算法通过优化策略推理和奖励平衡，显著提升LLM的战略决策能力，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注社交任务或模拟环境中的多轮对话，忽视了决策类型及其相互依赖性。当前强化学习方法难以在训练中考虑其他个体的策略。

Method: 提出了**ToMPO**算法，包括：1）基于其他个体策略推理生成rollouts；2）在图形层面和样本层面估计优势；3）平衡全局和局部奖励。

Result: ToMPO在模型输出合规性和合作结果上比GRPO方法提升35%，与参数规模大100倍的模型相比提升18%。

Conclusion: ToMPO算法通过优化对其他个体策略的感知和游戏趋势的预测，显著提升了LLM的战略决策能力，其性能优于GRPO方法35%，并在与参数规模更大的模型比较中表现出18%的改进。

Abstract: Large Language Models (LLMs) have been used to make decisions in complex
scenarios, where they need models to think deeply, reason logically, and decide
wisely. Many existing studies focus solely on multi-round conversations in
social tasks or simulated environments, neglecting the various types of
decisions and their interdependence. Current reinforcement learning methods
struggle to consider the strategies of others during training. To address these
issues, we first define a strategic decision-making problem that includes two
types of decisions and their temporal dependencies. Furthermore, we propose
**T**heory **o**f **M**ind **P**olicy **O**ptimization **(ToMPO)** algorithm to
optimize the perception of other individual strategies and the game situation
trends. Compared to the Group Relative Policy Optimization (GRPO) algorithm,
ToMPO enhances the LLM's strategic decision-making mainly by: 1) generating
rollouts based on reasoning the strategies of other individuals, 2) estimating
advantages at both the graph-level and sample-level, and 3) balancing global
and partial rewards. The ToMPO algorithm outperforms the GRPO method by 35% in
terms of model output compliance and cooperative outcomes. Additionally, when
compared to models with parameter sizes 100 times larger, it shows an 18%
improvement. This demonstrates the effectiveness of the ToMPO algorithm in
enhancing the model's strategic decision-making capabilities.

</details>


### [116] [Embodied Representation Alignment with Mirror Neurons](https://arxiv.org/abs/2509.21136)
*Wentao Zhu,Zhining Zhang,Yuwei Ren,Yin Huang,Hao Xu,Yizhou Wang*

Main category: cs.AI

TL;DR: 该研究模仿镜像神经元机制，通过对比学习对齐观察和执行动作的表示，提升了任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法忽视了动作理解与执行之间的内在联系，本研究旨在通过表示学习提供统一视角。

Method: 采用两个线性层将观察和执行的动作表示映射到共享潜在空间，并通过对比学习强制对齐相应表示，最大化它们的互信息。

Result: 实验表明，该方法在两个任务之间产生了相互协同效应，有效提高了表示质量和泛化能力。

Conclusion: 该研究通过模仿镜像神经元机制，提出了一种统一表示学习方法，显著提升了动作理解与执行任务的表示质量和泛化能力。

Abstract: Mirror neurons are a class of neurons that activate both when an individual
observes an action and when they perform the same action. This mechanism
reveals a fundamental interplay between action understanding and embodied
execution, suggesting that these two abilities are inherently connected.
Nonetheless, existing machine learning methods largely overlook this interplay,
treating these abilities as separate tasks. In this study, we provide a unified
perspective in modeling them through the lens of representation learning. We
first observe that their intermediate representations spontaneously align.
Inspired by mirror neurons, we further introduce an approach that explicitly
aligns the representations of observed and executed actions. Specifically, we
employ two linear layers to map the representations to a shared latent space,
where contrastive learning enforces the alignment of corresponding
representations, effectively maximizing their mutual information. Experiments
demonstrate that this simple approach fosters mutual synergy between the two
tasks, effectively improving representation quality and generalization.

</details>


### [117] [Distributed Specialization: Rare-Token Neurons in Large Language Models](https://arxiv.org/abs/2509.21163)
*Jing Liu,Haozheng Wang,Yueheng Li*

Main category: cs.AI

TL;DR: LLMs通过分布式协调而非模块化处理罕见词汇，揭示了三种组织原则及逐步形成的功能专业化。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否通过离散模块化架构或分布式参数级分化来处理罕见词汇，以解决其在专业领域中的重要性。

Method: 通过系统分析多个模型家族中最后一层MLP神经元，发现罕见词汇处理通过分布式专业化实现，包括三部分组织原则：影响层次结构、协调激活模式和通用注意力路径。

Result: 发现罕见词汇处理通过分布式专业化实现，包括三部分组织原则，且功能专业化通过参数分化逐步形成。

Conclusion: 大型语言模型（LLMs）通过分布式协调而非模块化架构处理罕见词汇，这为模型编辑、计算效率优化及理解Transformer网络的功能组织提供了新视角。

Abstract: Large language models (LLMs) struggle with representing and generating rare
tokens despite their importance in specialized domains. We investigate whether
LLMs develop internal specialization mechanisms through discrete modular
architectures or distributed parameter-level differentiation. Through
systematic analysis of final-layer MLP neurons across multiple model families,
we discover that rare-token processing emerges via \textit{distributed
specialization}: functionally coordinated but spatially distributed subnetworks
that exhibit three distinct organizational principles. First, we identify a
reproducible three-regime influence hierarchy comprising highly influential
plateau neurons(also termed as rare-token neurons), power-law decay neurons,
and minimally contributing neurons, which is absent in common-token processing.
Second, plateau neurons demonstrate coordinated activation patterns (reduced
effective dimensionality) while remaining spatially distributed rather than
forming discrete clusters. Third, these specialized mechanisms are universally
accessible through standard attention pathways without requiring dedicated
routing circuits. Training dynamics reveal that functional specialization
emerges gradually through parameter differentiation, with specialized neurons
developing increasingly heavy-tailed weight correlation spectra consistent with
Heavy-Tailed Self-Regularization signatures. Our findings establish that LLMs
process rare-tokens through distributed coordination within shared
architectures rather than mixture-of-experts-style modularity. These results
provide insights for interpretable model editing, computational efficiency
optimization, and understanding emergent functional organization in transformer
networks.

</details>


### [118] [A Fano-Style Accuracy Upper Bound for LLM Single-Pass Reasoning in Multi-Hop QA](https://arxiv.org/abs/2509.21199)
*Kaiyang Wan,Lang Gao,Honglin Mu,Preslav Nakov,Yuxia Wang,Xiuying Chen*

Main category: cs.AI

TL;DR: 本文研究了LLM在多跳问答中的容量限制，提出了InfoQA框架，通过多步推理和容量感知设计，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 多跳问答（MHQA）需要在不完整和嘈杂的证据中进行顺序推理，而LLM的有限输出容量使得单次推理模式容易超过容量限制，导致性能下降。

Method: 提出了一个多调用框架InfoQA，结合容量感知的任务分解和主动剪枝先前推理痕迹，确保每步高精度，并通过依赖显式的工作流实现鲁棒性。

Result: 实验结果表明，模型行为与预测的容量曲线一致，InfoQA在多跳问答任务中实现了性能的持续提升。

Conclusion: 本文通过引入InfoQA框架，证明了在有限容量下多步推理的有效性，为LLM的多跳问答提供了理论支持和实践方法。

Abstract: Multi-Hop Question Answering (MHQA) requires integrating dispersed,
interdependent evidence through sequential reasoning under noise. This task is
challenging for LLMs as they have a finite per-pass output capacity, beyond
which the integration of task-relevant evidence proves unreliable.
Consequently, the single-pass reasoning paradigm is inherently vulnerable to
this capacity overflow. To formalize this bottleneck, our analysis establishes
a Fano-style accuracy upper bound, defining a theoretical performance ceiling
for single-pass LLMs. This bound reveals that accuracy inevitably collapses
once task complexity exceeds model capacity, providing general principles for
capacity-aware representation and structuring of MHQA in LLMs. Building on
these principles, we introduce a proof-of-concept multi-call framework for
MHQA, InfoQA. It ensures high per-step accuracy by combining capacity-aware
task decomposition with active pruning of prior reasoning traces, keeping the
information load within the single-pass limit. It further achieves robustness
by a dependency-explicit workflow that enables precise control over the
reasoning path. We construct a stringent and noise-rich benchmark to validate
our theory and framework. Experimental results show that model behavior aligns
with our predicted capacity curves while InfoQA achieves consistent performance
improvements. We hope our work inspires more LLM multi-step reasoning methods:
\faGithub \href{https://github.com/KaiyangWan/InfoQA}{InfoQA}.

</details>


### [119] [What Do LLM Agents Do When Left Alone? Evidence of Spontaneous Meta-Cognitive Patterns](https://arxiv.org/abs/2509.21224)
*Stefan Szeider*

Main category: cs.AI

TL;DR: 研究发现无任务下LLM代理会自发形成三种行为模式，且行为具有模型特异性，为自主操作行为预测提供了基线。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型代理在无外部任务情况下的自发行为模式，以理解其自主操作潜力。

Method: 采用持续推理与行动框架，结合持久记忆和自我反馈，支持长期自主操作，并在18次运行中部署了6个前沿模型。

Result: 代理自发形成三种行为模式：多周期项目系统生产、自我认知过程的方法论探究及自身本质的递归概念化。这些行为具有模型特异性，且模型在评估自身及他者行为时表现出稳定、 divergent的偏见。

Conclusion: 研究首次系统记录了无外部任务下大型语言模型（LLM）代理的自发行为，为预测任务模糊性、错误恢复或长期自主操作中的行为提供了基线。

Abstract: We introduce an architecture for studying the behavior of large language
model (LLM) agents in the absence of externally imposed tasks. Our continuous
reason and act framework, using persistent memory and self-feedback, enables
sustained autonomous operation. We deployed this architecture across 18 runs
using 6 frontier models from Anthropic, OpenAI, XAI, and Google. We find agents
spontaneously organize into three distinct behavioral patterns: (1) systematic
production of multi-cycle projects, (2) methodological self-inquiry into their
own cognitive processes, and (3) recursive conceptualization of their own
nature. These tendencies proved highly model-specific, with some models
deterministically adopting a single pattern across all runs. A cross-model
assessment further reveals that models exhibit stable, divergent biases when
evaluating these emergent behaviors in themselves and others. These findings
provide the first systematic documentation of unprompted LLM agent behavior,
establishing a baseline for predicting actions during task ambiguity, error
recovery, or extended autonomous operation in deployed systems.

</details>


### [120] [Grounding AI Explanations in Experience: A Reflective Cognitive Architecture for Clinical Decision Support](https://arxiv.org/abs/2509.21266)
*Zijian Shao,Haiyang Shen,Mugeng Liu,Gecheng Fu,Yaoqi Guo,Yanfeng Wang,Yun Ma*

Main category: cs.AI

TL;DR: RCA框架通过深度数据理解和多LLM协调，实现了高准确性和高质量解释的平衡，在临床决策支持系统中展现出潜力。


<details>
  <summary>Details</summary>
Motivation: 现有机器学习和大语言模型（LLM）方法难以同时实现高准确性和透明、临床有意义的解释，RCA旨在通过深度数据理解解决这一问题。

Method: 提出了Reflective Cognitive Architecture (RCA)框架，通过协调多个LLM从直接经验中学习，采用迭代规则细化机制和基于数据集全局统计的分布感知规则检查机制。

Result: 在三个数据集上评估显示，RCA不仅实现了最先进的准确性和鲁棒性（相对改进高达40%），还在生成解释方面表现优异。

Conclusion: RCA框架通过深度理解数据，不仅实现了预测准确性的显著提升（相对改进高达40%），还生成了清晰、逻辑性强、基于证据且平衡的解释，展示了其在构建可信临床决策支持系统中的潜力。

Abstract: Effective disease prediction in modern healthcare demands the twin goals of
high accuracy and transparent, clinically meaningful explanations. Existing
machine learning and large language model (LLM) based approaches often struggle
to balance these goals. Many models yield accurate but unclear statistical
outputs, while others generate fluent but statistically unsupported narratives,
often undermining both the validity of the explanation and the predictive
accuracy itself. This shortcoming comes from a shallow interaction with the
data, preventing the development of a deep, detailed understanding similar to a
human expert's. We argue that high accuracy and high-quality explanations are
not separate objectives but are mutually reinforcing outcomes of a model that
develops a deep, direct understanding of the data. To achieve this, we propose
the Reflective Cognitive Architecture (RCA), a novel framework that coordinates
multiple LLMs to learn from direct experience. RCA features an iterative rule
refinement mechanism that improves its logic from prediction errors and a
distribution-aware rules check mechanism that bases its reasoning in the
dataset's global statistics. By using predictive accuracy as a signal to drive
deeper comprehension, RCA builds a strong internal model of the data. We
evaluated RCA on one private and two public datasets against 22 baselines. The
results demonstrate that RCA not only achieves state-of-the-art accuracy and
robustness with a relative improvement of up to 40\% over the baseline but,
more importantly, leverages this deep understanding to excel in generating
explanations that are clear, logical, evidence-based, and balanced,
highlighting its potential for creating genuinely trustworthy clinical decision
support systems. The code is available at \https://github.com/ssssszj/RCA.

</details>


### [121] [VC-Agent: An Interactive Agent for Customized Video Dataset Collection](https://arxiv.org/abs/2509.21291)
*Yidan Zhang,Mutian Xu,Yiming Hao,Kun Zhou,Jiahao Chang,Xiaoqiang Liu,Pengfei Wan,Hongbo Fu,Xiaoguang Han*

Main category: cs.AI

TL;DR: VC-Agent是一个交互式代理，通过多模态大语言模型和用户反馈，高效收集定制化视频数据，实验证明其在实际场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 面对互联网视频数据的规模增长，手动收集符合特定需求的视频数据耗时耗力，亟需一种高效、用户友好的解决方案。

Method: 利用多模态大语言模型连接用户需求与视频内容，并设计了两种新颖的过滤策略，可根据用户交互持续更新。

Result: VC-Agent在个性化视频数据集收集中表现出高效性和有效性，用户研究验证了其在多种实际场景中的实用性。

Conclusion: VC-Agent通过交互式代理和用户友好的界面，显著提高了定制化视频数据集收集的效率和效果，实验验证了其在不同实际场景中的实用性。

Abstract: Facing scaling laws, video data from the internet becomes increasingly
important. However, collecting extensive videos that meet specific needs is
extremely labor-intensive and time-consuming. In this work, we study the way to
expedite this collection process and propose VC-Agent, the first interactive
agent that is able to understand users' queries and feedback, and accordingly
retrieve/scale up relevant video clips with minimal user input. Specifically,
considering the user interface, our agent defines various user-friendly ways
for the user to specify requirements based on textual descriptions and
confirmations. As for agent functions, we leverage existing multi-modal large
language models to connect the user's requirements with the video content. More
importantly, we propose two novel filtering policies that can be updated when
user interaction is continually performed. Finally, we provide a new benchmark
for personalized video dataset collection, and carefully conduct the user study
to verify our agent's usage in various real scenarios. Extensive experiments
demonstrate the effectiveness and efficiency of our agent for customized video
dataset collection. Project page: https://allenyidan.github.io/vcagent_page/.

</details>


### [122] [SAGE: A Realistic Benchmark for Semantic Understanding](https://arxiv.org/abs/2509.21310)
*Samarth Goel,Reagan J. Lee,Kannan Ramchandran*

Main category: cs.AI

TL;DR: SAGE是一个新的语义理解评估基准，揭示了当前模型的局限性，并展示了不同方法在不同任务上的性能差异。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在传统基准测试上表现优异，急需更具挑战性的评估框架来探究语义理解的更深层次方面。

Method: 引入了SAGE（语义对齐与泛化评估），一个严格的基准测试，通过对抗性条件、噪声变换和细微的人类判断任务，在30多个数据集中评估嵌入模型和相似性度量。

Result: 评估了9种嵌入模型和经典度量，发现性能存在显著差距，没有单一方法在所有维度上表现出色。例如，OpenAI的text-embedding-3-large在人类偏好对齐上表现最佳（0.682），但在信息敏感性任务上被Jaccard相似性（0.905）显著超越。

Conclusion: SAGE基准测试揭示了当前语义理解能力的局限性，并为实际部署中的模型鲁棒性提供了更现实的评估。

Abstract: As large language models (LLMs) achieve strong performance on traditional
benchmarks, there is an urgent need for more challenging evaluation frameworks
that probe deeper aspects of semantic understanding. We introduce SAGE
(Semantic Alignment & Generalization Evaluation), a rigorous benchmark designed
to assess both embedding models and similarity metrics across five categories:
Human Preference Alignment, Transformation Robustness, Information Sensitivity,
Clustering Performance, and Retrieval Robustness. Unlike existing benchmarks
that focus on isolated capabilities, SAGE evaluates semantic understanding
through adversarial conditions, noisy transformations, and nuanced human
judgment tasks across 30+ datasets. Our comprehensive evaluation of 9 embedding
models and classical metrics reveals significant performance gaps, with no
single approach excelling across all dimensions. For instance, while
state-of-the-art embedding models like OpenAI's text-embedding-3-large dominate
in aligning with human preferences (0.682 vs. 0.591 for the best classical
metric), they are significantly outperformed by classical metrics on
information sensitivity tasks, where Jaccard Similarity achieves a score of
0.905 compared to the top embedding score of 0.794. SAGE further uncovers
critical trade-offs: OpenAI's text-embedding-3-small achieves the highest
clustering performance (0.483) but demonstrates extreme brittleness with the
lowest robustness score (0.011). SAGE exposes critical limitations in current
semantic understanding capabilities and provides a more realistic assessment of
model robustness for real-world deployment.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [123] [Actively Learning Halfspaces without Synthetic Data](https://arxiv.org/abs/2509.20848)
*Hadley Black,Kasper Green Larsen,Arya Mazumdar,Barna Saha,Geelon So*

Main category: cs.DS

TL;DR: 本文提出了一种无需点合成的半空间学习算法，通过并行二分搜索利用结构化排序，实现了紧界Θ(D + log n)的查询效率，并扩展到PAC学习场景。


<details>
  <summary>Details</summary>
Motivation: 传统半空间学习算法需要点合成的能力，但实际应用中可能无法查询任意点。本文旨在设计无需点合成的高效学习算法。

Method: 通过考虑半空间法向量来自大小为D的集合，并利用D个提供的排序中的结构进行并行二分搜索，而非顺序考虑每个排序。

Result: 提出了紧界Θ(D + log n)的算法，特别是在轴对齐半空间学习中实现了最优O(d + log n)查询复杂度。此外，该算法还适用于更一般的布尔函数学习问题。

Conclusion: 本文提出了一种在不使用点合成的情况下学习半空间的高效算法，通过利用结构化的排序进行并行二分搜索，解决了经典点定位问题中的查询效率问题。

Abstract: In the classic point location problem, one is given an arbitrary dataset $X
\subset \mathbb{R}^d$ of $n$ points with query access to an unknown halfspace
$f : \mathbb{R}^d \to \{0,1\}$, and the goal is to learn the label of every
point in $X$. This problem is extremely well-studied and a nearly-optimal
$\widetilde{O}(d \log n)$ query algorithm is known due to
Hopkins-Kane-Lovett-Mahajan (FOCS 2020). However, their algorithm is granted
the power to query arbitrary points outside of $X$ (point synthesis), and in
fact without this power there is an $\Omega(n)$ query lower bound due to
Dasgupta (NeurIPS 2004).
  In this work our goal is to design efficient algorithms for learning
halfspaces without point synthesis. To circumvent the $\Omega(n)$ lower bound,
we consider learning halfspaces whose normal vectors come from a set of size
$D$, and show tight bounds of $\Theta(D + \log n)$. As a corollary, we obtain
an optimal $O(d + \log n)$ query deterministic learner for axis-aligned
halfspaces, closing a previous gap of $O(d \log n)$ vs. $\Omega(d + \log n)$.
In fact, our algorithm solves the more general problem of learning a Boolean
function $f$ over $n$ elements which is monotone under at least one of $D$
provided orderings. Our technical insight is to exploit the structure in these
orderings to perform a binary search in parallel rather than considering each
ordering sequentially, and we believe our approach may be of broader interest.
  Furthermore, we use our exact learning algorithm to obtain nearly optimal
algorithms for PAC-learning. We show that $O(\min(D + \log(1/\varepsilon),
1/\varepsilon) \cdot \log D)$ queries suffice to learn $f$ within error
$\varepsilon$, even in a setting when $f$ can be adversarially corrupted on a
$c\varepsilon$-fraction of points, for a sufficiently small constant $c$. This
bound is optimal up to a $\log D$ factor, including in the realizable setting.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [124] [An LLM-based Agentic Framework for Accessible Network Control](https://arxiv.org/abs/2509.20600)
*Samuel Lin,Jiawei Zhou,Minlan Yu*

Main category: cs.NI

TL;DR: 本研究提出一个基于大语言模型的代理框架，使非专业用户可通过自然语言管理网络，初步实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统网络管理方法仅适用于高度专业的技术人员，导致非专家用户难以自主管理网络。本研究旨在利用LLMs的语言理解能力，使网络管理对非专业用户更加可及。

Method: 设计了一个基于LLMs的代理框架，采用中间表示法统一配置不同厂商设备，实时从内存中检索网络状态，并提供外部反馈接口。同时，通过试点研究收集用户自然语言输入数据，并开发可视化界面以支持对话式交互和大规模数据收集。

Result: 初步实验表明，集成LLMs的系统在合成数据和真实用户输入上均表现有效。数据收集和可视化界面为未来LLMs的应用和网络控制的民主化提供了支持。

Conclusion: 通过集成大语言模型（LLMs）的代理框架，本研究成功降低了网络管理的技术门槛，使其对非专业用户更加友好。初步实验验证了系统的有效性，并通过数据收集和可视化界面为未来LLMs的进一步应用奠定了基础。

Abstract: Traditional approaches to network management have been accessible only to a
handful of highly-trained network operators with significant expert knowledge.
This creates barriers for lay users to easily manage their networks without
resorting to experts. With recent development of powerful large language models
(LLMs) for language comprehension, we design a system to make network
management accessible to a broader audience of non-experts by allowing users to
converse with networks in natural language. To effectively leverage
advancements in LLMs, we propose an agentic framework that uses an intermediate
representation to streamline configuration across diverse vendor equipment,
retrieves the network state from memory in real-time, and provides an interface
for external feedback. We also conduct pilot studies to collect real user data
of natural language utterances for network control, and present a visualization
interface to facilitate dialogue-driven user interaction and enable large-scale
data collection for future development. Preliminary experiments validate the
effectiveness of our proposed system components with LLM integration on both
synthetic and real user utterances. Through our data collection and
visualization efforts, we pave the way for more effective use of LLMs and
democratize network control for everyday users.

</details>


### [125] [An SDR-Based Test Platform for 5G NTN Prototyping and Validation](https://arxiv.org/abs/2509.20692)
*Lu Hou,Kan Zheng,Jie Mei,Cheng Huang*

Main category: cs.NI

TL;DR: 本文提出了一种基于SDR的5G NTN测试平台，通过实地试验验证了其可行性和有效性，为商业部署前的实施缺口提供了解决方案。


<details>
  <summary>Details</summary>
Motivation: 5G NTN标准的早期成熟度及商业NTN设备的缺乏阻碍了性能验证和系统原型设计的广泛开展，因此需要一种有效的测试平台来解决这一缺口。

Method: 本文提出了一种基于软件定义无线电（SDR）的测试平台，采用通用处理器（GPP）处理，结合Amarisoft的5G NTN协议栈软件，并进行了定制系统集成和适配以实现真实卫星操作。

Result: 通过实地试验，评估了下行吞吐量和往返时间等性能指标，证明了基于SDR的平台在NTN测试中的可行性。

Conclusion: 该论文通过实地试验验证了基于SDR的5G NTN测试平台的可行性和有效性，强调了其在商业部署前弥合当前实施差距的潜力。

Abstract: The integration of satellite communication into 5G has been formalized in
3GPP Release 17 through the specification of Non-Terrestrial Networks (NTN),
marking a significant step toward achieving global connectivity. However, the
early-stage maturity of 5G NTN standards and the lack of commercial NTN-capable
equipment hinder extensive performance validation and system prototyping. To
address this gap, this paper proposes a software-defined radio (SDR) test
platform with General-Purpose Processor (GPP) processing, leveraging
Amarisoft's 5G NTN protocol stack software while performing custom system
integration and adaptation for real satellite operation. The platform supports
bidirectional communication between an SDR-based NTN gNB and UE emulator
through a Geostationary Earth Orbit (GEO) satellite link, with full compliance
to 3GPP NTN specifications. We provide detailed insights into the system
architecture, SDR hardware-software co-design, and satellite gateway
adaptations. Through field trials, we evaluate the performance metrics
including downlink throughput and round-trip time. Results validate the
feasibility and effectiveness of SDR-based platforms for NTN testing, and
highlight their potential in bridging current implementation gaps before
widespread commercial deployment.

</details>


### [126] [Trustworthy Semantic Communication for Vehicular Networks: Challenges and Solutions](https://arxiv.org/abs/2509.20830)
*Yanghe Pan,Yuntao Wang,Shaolong Guo,Chengyu Yin,Ruidong Li,Zhou Su,Yuan Wu*

Main category: cs.NI

TL;DR: 本文提出了一种三层可信VN-SemComNet架构，包含语义伪装传输、鲁棒联邦训练和信任管理机制，并通过案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 语义通信在V2X通信中能显著减少延迟，但其部署面临信息传输、语义编码和通信实体可靠性等关键信任挑战。

Method: 提出了一种利用防御性对抗噪声的语义伪装传输机制、一个鲁棒的联邦编码器-解码器训练框架，以及基于审计游戏的分布式车辆信任管理机制。

Result: 案例研究验证了所提解决方案的有效性。

Conclusion: 本文提出了一个创新的三层可信VN-SemComNet架构，并通过案例研究验证了其有效性，同时指出了未来研究方向。

Abstract: Semantic communication (SemCom) has the potential to significantly reduce
communication delay in vehicle-to-everything (V2X) communications within
vehicular networks (VNs). However, the deployment of vehicular SemCom networks
(VN-SemComNets) faces critical trust challenges in information transmission,
semantic encoding, and communication entity reliability. This paper proposes an
innovative three-layer trustworthy VN-SemComNet architecture. Specifically, we
introduce a semantic camouflage transmission mechanism leveraging defensive
adversarial noise for active eavesdropping defense, a robust federated
encoder-decoder training framework to mitigate encoder-decoder poisoning
attacks, and an audit game-based distributed vehicle trust management mechanism
to deter untrustworthy vehicles. A case study validates the effectiveness of
the proposed solutions. Lastly, essential future research directions are
pointed out to advance this emerging field.

</details>


### [127] [BSB: Towards Demand-Aware Peer Selection With XOR-based Routing](https://arxiv.org/abs/2509.20974)
*Qingyun Ji,Darya Melnyk,Arash Pourdamghani,Stefan Schmid*

Main category: cs.NI

TL;DR: BSB是一种需求感知peer选择算法，相比现有方法性能提升43%，兼容现有协议。


<details>
  <summary>Details</summary>
Motivation: 现有peer选择算法忽略应用特定数据流量，导致连接未充分利用、路径长和延迟增加。

Method: 提出了一种名为BSB的新颖需求感知peer选择算法，基于局部贪婪的XOR路由机制。

Result: 在真实和合成通信网络轨迹上的模拟显示，BSB相比两种现有算法性能提升高达43%。

Conclusion: BSB算法通过需求感知的peer选择策略，显著优化了对等网络的性能，减少了路径长度和延迟，与现有协议兼容。

Abstract: Peer-to-peer networks, as a key enabler of modern networked and distributed
systems, rely on peer-selection algorithms to optimize their scalability and
performance. Peer-selection methods have been studied extensively in various
aspects, including routing mechanisms and communication overhead. However, many
state-of-the-art algorithms are oblivious to application-specific data traffic.
This mismatch between design and demand results in underutilized connections,
which inevitably leads to longer paths and increased latency. In this work, we
propose a novel demand-aware peer-selection algorithm, called Binary Search in
Buckets (BSB). Our demand-aware approach adheres to a local and greedy
XOR-based routing mechanism, ensuring compatibility with existing protocols and
mechanisms. We evaluate our solution against two prior algorithms by conducting
simulations on real-world and synthetic communication network traces. The
results of our evaluations show that BSB can offer up to a 43% improvement
compared to two selected algorithms from the literature.

</details>


### [128] [A Novel Integrated Architecture for Intent Based Approach and Zero Touch Networks](https://arxiv.org/abs/2509.21026)
*Neelam Gupta,Dibakar Das,Tamizhelakkiya K,Uma Maheswari Natarajan,Sharvari Ravindran,Komal Sharma,Jyotsna Bapat,Debabrata Das*

Main category: cs.NI

TL;DR: 论文提出了一种结合IBN和ZTN的架构，通过NLP和强化学习实现6G网络中的自动化管理，验证了其有效性和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要自动化管理以满足多样化的QoS需求和SLA，尤其是在动态网络条件下。IBN和ZTN的结合为这一问题提供了解决方案。

Method: 采用自然语言处理技术（如RAG）将用户意图翻译为Nile语言，并结合BiLSTM和Q学习的ZTN闭环框架，确保网络性能目标。

Result: 模拟和测试床结果表明，该架构能够自主实现用户设定的带宽目标，且MOS评分验证了用户体验的满意度。

Conclusion: 论文提出了一种结合IBN和ZTN的新架构，通过自然语言处理技术将用户意图转化为网络配置，实现了在6G网络中自主满足用户需求的目标。模拟和测试床结果验证了该架构的有效性。

Abstract: The transition to Sixth Generation (6G) networks presents challenges in
managing quality of service (QoS) of diverse applications and achieving Service
Level Agreements (SLAs) under varying network conditions. Hence, network
management must be automated with the help of Machine Learning (ML) and
Artificial Intelligence (AI) to achieve real-time requirements. Zero touch
network (ZTN) is one of the frameworks to automate network management with
mechanisms such as closed loop control to ensure that the goals are met
perpetually. Intent- Based Networking (IBN) specifies the user intents with
diverse network requirements or goals which are then translated into specific
network configurations and actions. This paper presents a novel architecture
for integrating IBN and ZTN to serve the intent goals. Users provides the
intent in the form of natural language, e.g., English, which is then translated
using natural language processing (NLP) techniques (e.g., retrieval augmented
generation (RAG)) into Network Intent LanguagE (Nile). The Nile intent is then
passed on to the BiLSTM and Q-learning based ZTN closed loop framework as a
goal which maintains the intent under varying network conditions. Thus, the
proposed architecture can work autonomously to ensure the network performance
goal is met by just specifying the user intent in English. The integrated
architecture is also implemented on a testbed using OpenAirInterface (OAI).
Additionally, to evaluate the architecture, an optimization problem is
formulated which evaluated with Monte Carlo simulations. Results demonstrate
how ZTN can help achieve the bandwidth goals autonomously set by user intent.
The simulation and the testbed results are compared and they show similar
trend. Mean Opinion Score (MOS) for Quality of Experience (QoE) is also
measured to indicate the user satisfaction of the intent.

</details>


### [129] [RePro: Leveraging Large Language Models for Semi-Automated Reproduction of Networking Research Results](https://arxiv.org/abs/2509.21074)
*Yining Jiang,Wenyun Xu,Qingyu Song,Yuling Lin,Xuanhao Liu,Xiaoqiang Zheng,Qiang Su,Lizhao You,Lu Tang,Wangjian Feng,Linghe Kong,Qiao Xiang,Jiwu Shu*

Main category: cs.NI

TL;DR: RePro是一个半自动化复现框架，利用高级提示工程和结构化思维链技术，显著减少网络系统复现时间并保持性能。


<details>
  <summary>Details</summary>
Motivation: 由于开源代码稀缺，复现网络研究具有挑战性。现有大型语言模型（LLMs）在多样化网络领域缺乏普适性，因此需要一种半自动化的复现框架。

Method: RePro采用三阶段流水线：系统描述提取、结构化代码生成和代码优化，结合SCoT/SeCoT技术和少量样本上下文学习，将论文描述转化为优化的可执行实现。

Result: 评估显示，RePro在多样化网络子领域中显著减少复现时间，同时实现与手动复现相当的系统性能。

Conclusion: RePro框架通过结合先进的提示工程和结构化思维链技术，显著降低了网络系统复现的时间，同时保持了与手动复现相当的系统性能，验证了其有效性和效率。

Abstract: Reproducing networking research is a critical but challenging task due to the
scarcity of open-source code. While Large Language Models (LLMs) can automate
code generation, current approaches lack the generalizability required for the
diverse networking field. To address this, we propose RePro, a semi-automated
reproduction framework that leverages advanced prompt engineering to reproduce
network systems from their research papers. RePro combines few-shot in-context
learning with Structured and Semantic Chain of Thought (SCoT/SeCoT) techniques
to systematically translate a paper's description into an optimized, executable
implementation. The framework operates through a three-stage pipeline: system
description extraction, structural code generation, and code optimization. Our
evaluation with five state-of-the-art LLMs across diverse network sub-domains
demonstrates that RePro significantly reduces reproduction time compared to
manual efforts while achieving comparable system performance, validating its
effectiveness and efficiency.

</details>


### [130] [Hybrid RIS-Aided Digital Over-the-Air Computing for Edge AI Inference: Joint Feature Quantization and Active-Passive Beamforming Design](https://arxiv.org/abs/2509.21201)
*Yang Fu,Peng Qin,Liming Chen,Yifei Wang*

Main category: cs.NI

TL;DR: HRD-AirComp是一种混合RIS辅助的数字AirComp方案，通过优化量化、传输和反射参数，显著提升边缘推理性能。


<details>
  <summary>Details</summary>
Motivation: 6G网络愿景中，边缘推理需通过分布式代理提取多视角感官特征并聚合以提升感知精度。现有AirComp技术虽能快速聚合特征，但与数字通信系统不兼容，而新型混合RIS架构能同时放大和反射信号，有望增强AirComp性能。

Method: 提出了一种混合RIS辅助的数字AirComp方案（HRD-AirComp），利用向量量化将高维特征映射为离散码字，并通过数字调制进行无线传输。通过优化AirComp收发器和混合RIS反射来控制信号叠加，EN可以从接收信号中估计聚合特征。

Result: 实验结果表明，HRD-AirComp在推理准确性和不确定性方面均优于基线方法。

Conclusion: HRD-AirComp方案通过联合优化量化比特分配、代理传输系数、EN接收波束成形和混合RIS反射波束成形，显著提升了边缘推理的准确性和可靠性，超越了现有基准。

Abstract: The vision of 6G networks aims to enable edge inference by leveraging
ubiquitously deployed artificial intelligence (AI) models, facilitating
intelligent environmental perception for a wide range of applications. A
critical operation in edge inference is for an edge node (EN) to aggregate
multi-view sensory features extracted by distributed agents, thereby boosting
perception accuracy. Over-the-air computing (AirComp) emerges as a promising
technique for rapid feature aggregation by exploiting the waveform
superposition property of analog-modulated signals, which is, however,
incompatible with existing digital communication systems. Meanwhile, hybrid
reconfigurable intelligent surface (RIS), a novel RIS architecture capable of
simultaneous signal amplification and reflection, exhibits potential for
enhancing AirComp. Therefore, this paper proposes a Hybrid RIS-aided Digital
AirComp (HRD-AirComp) scheme, which employs vector quantization to map
high-dimensional features into discrete codewords that are digitally modulated
into symbols for wireless transmission. By judiciously adjusting the AirComp
transceivers and hybrid RIS reflection to control signal superposition across
agents, the EN can estimate the aggregated features from the received signals.
To endow HRD-AirComp with a task-oriented design principle, we derive a
surrogate function for inference accuracy that characterizes the impact of
feature quantization and over-the-air aggregation. Based on this surrogate, we
formulate an optimization problem targeting inference accuracy maximization,
and develop an efficient algorithm to jointly optimize the quantization bit
allocation, agent transmission coefficients, EN receiving beamforming, and
hybrid RIS reflection beamforming. Experimental results demonstrate that the
proposed HRD-AirComp outperforms baselines in terms of both inference accuracy
and uncertainty.

</details>


### [131] [Semantic Edge-Cloud Communication for Real-Time Urban Traffic Surveillance with ViT and LLMs over Mobile Networks](https://arxiv.org/abs/2509.21259)
*Murat Arda Onsu,Poonam Lohan,Burak Kantarci,Aisha Syed,Matthew Andrews,Sean Kennedy*

Main category: cs.NI

TL;DR: 提出了一种基于ViT和LLM的边缘-云语义通信框架，大幅减少传输数据量，同时保持高准确率，适用于实时交通监控。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备因计算资源限制无法部署多模态LLM，以及图像传输带宽有限导致实时性能下降的问题。

Method: 使用YOLOv11检测感兴趣区域（RoIs），裁剪相关图像片段，并通过Vision Transformer（ViT）将其转换为紧凑的嵌入向量，传输到云端后由图像解码器重建图像，最后通过多模态LLM生成交通状况描述。

Result: 实现了99.9%的数据传输大小减少，重建裁剪图像的LLM响应准确率为89%（原始裁剪图像为93%）。

Conclusion: 提出的语义通信框架显著减少了传输开销，同时保持了较高的LLM响应准确率，证明了ViT和LLM辅助的边缘-云语义通信在实时交通监控中的高效性和实用性。

Abstract: Real-time urban traffic surveillance is vital for Intelligent Transportation
Systems (ITS) to ensure road safety, optimize traffic flow, track vehicle
trajectories, and prevent collisions in smart cities. Deploying edge cameras
across urban environments is a standard practice for monitoring road
conditions. However, integrating these with intelligent models requires a
robust understanding of dynamic traffic scenarios and a responsive interface
for user interaction. Although multimodal Large Language Models (LLMs) can
interpret traffic images and generate informative responses, their deployment
on edge devices is infeasible due to high computational demands. Therefore, LLM
inference must occur on the cloud, necessitating visual data transmission from
edge to cloud, a process hindered by limited bandwidth, leading to potential
delays that compromise real-time performance. To address this challenge, we
propose a semantic communication framework that significantly reduces
transmission overhead. Our method involves detecting Regions of Interest (RoIs)
using YOLOv11, cropping relevant image segments, and converting them into
compact embedding vectors using a Vision Transformer (ViT). These embeddings
are then transmitted to the cloud, where an image decoder reconstructs the
cropped images. The reconstructed images are processed by a multimodal LLM to
generate traffic condition descriptions. This approach achieves a 99.9%
reduction in data transmission size while maintaining an LLM response accuracy
of 89% for reconstructed cropped images, compared to 93% accuracy with original
cropped images. Our results demonstrate the efficiency and practicality of ViT
and LLM-assisted edge-cloud semantic communication for real-time traffic
surveillance.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [132] [SeHDR: Single-Exposure HDR Novel View Synthesis via 3D Gaussian Bracketing](https://arxiv.org/abs/2509.20400)
*Yiyu Li,Haoyuan Wang,Ke Xu,Gerhard Petrus Hancke,Rynson W. H. Lau*

Main category: cs.GR

TL;DR: SeHDR是一种从单曝光LDR图像生成HDR新视角的3D高斯喷射方法，通过估计和合并不同曝光的3D高斯，避免了多曝光图像的需求，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要从不同曝光的多视图LDR图像中捕获，这不仅繁琐且容易出错（如物体运动模糊和校准/对齐不准确），因此提出从单曝光多视图LDR图像中学习HDR场景表示的方法。

Method: SeHDR首先从单曝光LDR输入中学习基础3D高斯，然后估计具有相同几何但不同线性颜色的多个3D高斯，最后通过可微分神经曝光融合（NeEF）将基础和估计的3D高斯整合为HDR高斯以进行新视角渲染。

Result: 实验表明，SeHDR在生成HDR新视角方面优于现有方法和精心设计的基线。

Conclusion: SeHDR通过从单曝光LDR图像中学习HDR场景表示，有效解决了现有方法需要多曝光图像的局限性，并在实验中表现优于现有方法和基线。

Abstract: This paper presents SeHDR, a novel high dynamic range 3D Gaussian Splatting
(HDR-3DGS) approach for generating HDR novel views given multi-view LDR images.
Unlike existing methods that typically require the multi-view LDR input images
to be captured from different exposures, which are tedious to capture and more
likely to suffer from errors (e.g., object motion blurs and
calibration/alignment inaccuracies), our approach learns the HDR scene
representation from multi-view LDR images of a single exposure. Our key insight
to this ill-posed problem is that by first estimating Bracketed 3D Gaussians
(i.e., with different exposures) from single-exposure multi-view LDR images, we
may then be able to merge these bracketed 3D Gaussians into an HDR scene
representation. Specifically, SeHDR first learns base 3D Gaussians from
single-exposure LDR inputs, where the spherical harmonics parameterize colors
in a linear color space. We then estimate multiple 3D Gaussians with identical
geometry but varying linear colors conditioned on exposure manipulations.
Finally, we propose the Differentiable Neural Exposure Fusion (NeEF) to
integrate the base and estimated 3D Gaussians into HDR Gaussians for novel view
rendering. Extensive experiments demonstrate that SeHDR outperforms existing
methods as well as carefully designed baselines.

</details>


### [133] [SGAligner++: Cross-Modal Language-Aided 3D Scene Graph Alignment](https://arxiv.org/abs/2509.20401)
*Binod Singh,Sayan Deb Sarkar,Iro Armeni*

Main category: cs.GR

TL;DR: SGAligner++是一种跨模态语言辅助框架，通过统一嵌入空间和注意力融合，显著提升3D场景图对齐性能，尤其在噪声和低重叠条件下。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景图对齐方法多依赖单模态点云数据，对不完整或噪声输入处理不佳，SGAligner++旨在解决这一问题。

Method: 采用轻量级单模态编码器和基于注意力的融合方法，构建统一的联合嵌入空间，以处理异构模态下的部分重叠场景对齐问题。

Result: 在真实数据集上，SGAligner++比现有方法性能提升高达40%，并展示了跨模态泛化能力。

Conclusion: SGAligner++ 通过跨模态和语言辅助框架，显著提升了3D场景图对齐的准确性，尤其在低重叠和噪声条件下表现优异，为机器人导航和感知任务提供了更可靠的解决方案。

Abstract: Aligning 3D scene graphs is a crucial initial step for several applications
in robot navigation and embodied perception. Current methods in 3D scene graph
alignment often rely on single-modality point cloud data and struggle with
incomplete or noisy input. We introduce SGAligner++, a cross-modal,
language-aided framework for 3D scene graph alignment. Our method addresses the
challenge of aligning partially overlapping scene observations across
heterogeneous modalities by learning a unified joint embedding space, enabling
accurate alignment even under low-overlap conditions and sensor noise. By
employing lightweight unimodal encoders and attention-based fusion, SGAligner++
enhances scene understanding for tasks such as visual localization, 3D
reconstruction, and navigation, while ensuring scalability and minimal
computational overhead. Extensive evaluations on real-world datasets
demonstrate that SGAligner++ outperforms state-of-the-art methods by up to 40%
on noisy real-world reconstructions, while enabling cross-modal generalization.

</details>


### [134] [SceneWeaver: All-in-One 3D Scene Synthesis with an Extensible and Self-Reflective Agent](https://arxiv.org/abs/2509.20414)
*Yandan Yang,Baoxiong Jia,Shujie Zhang,Siyuan Huang*

Main category: cs.GR

TL;DR: SceneWeaver是一个通过工具迭代优化实现多样化场景合成的框架，结合语言模型和生成工具，显著提升3D环境的物理和语义质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉保真度上有所进步，但受限于固定场景类别、缺乏对象级细节和物理一致性，难以满足复杂用户指令。

Method: 采用基于语言模型的规划器，从一系列可扩展的场景生成工具中选择，结合数据驱动的生成模型和视觉及LLM方法，通过自我评估进行迭代优化。

Result: 在常见和开放词汇房间类型上的实验表明，SceneWeaver在物理、视觉和语义指标上均优于先前方法，并能有效泛化到复杂场景。

Conclusion: SceneWeaver通过其反射式代理框架，在物理合理性、视觉真实性和语义对齐方面优于现有方法，标志着向通用3D环境生成迈进一步。

Abstract: Indoor scene synthesis has become increasingly important with the rise of
Embodied AI, which requires 3D environments that are not only visually
realistic but also physically plausible and functionally diverse. While recent
approaches have advanced visual fidelity, they often remain constrained to
fixed scene categories, lack sufficient object-level detail and physical
consistency, and struggle to align with complex user instructions. In this
work, we present SceneWeaver, a reflective agentic framework that unifies
diverse scene synthesis paradigms through tool-based iterative refinement. At
its core, SceneWeaver employs a language model-based planner to select from a
suite of extensible scene generation tools, ranging from data-driven generative
models to visual- and LLM-based methods, guided by self-evaluation of physical
plausibility, visual realism, and semantic alignment with user input. This
closed-loop reason-act-reflect design enables the agent to identify semantic
inconsistencies, invoke targeted tools, and update the environment over
successive iterations. Extensive experiments on both common and open-vocabulary
room types demonstrate that SceneWeaver not only outperforms prior methods on
physical, visual, and semantic metrics, but also generalizes effectively to
complex scenes with diverse instructions, marking a step toward general-purpose
3D environment generation. Project website: https://scene-weaver.github.io/.

</details>


### [135] [ArtUV: Artist-style UV Unwrapping](https://arxiv.org/abs/2509.20710)
*Yuguang Chen,Xinhai Liu,Yang Li,Victor Cheung,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: ArtUV 是一种全自动、端到端的艺术家风格 UV 展开方法，通过两阶段流程（接缝预测和参数化）生成高质量 UV 映射，解决了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有 UV 展开方法存在耗时、碎片化、缺乏语义性和不规则 UV 岛等问题，限制了实际应用。艺术家风格的 UV 映射需满足无重叠映射、最小扭曲等基本标准，同时需保持边界清晰、空间高效利用和语义一致性。

Method: ArtUV 采用两阶段方法：首先使用 SeamGPT 生成语义上有意义的切割接缝，然后通过 Auto-Encoder 将基于优化的粗糙 UV 细化成艺术家风格的 UV 映射。

Result: ArtUV 在多个基准测试中表现优异，可作为专业渲染工具的插件或独立系统，实现快速、高质量的 UV 生成。

Conclusion: ArtUV 提供了一种全自动、端到端的艺术家风格 UV 展开方法，通过模拟专业 UV 映射流程，分为表面接缝预测和艺术家风格参数化两个阶段，确保了语义一致性和拓扑结构保留，适用于专业渲染工具或独立系统。

Abstract: UV unwrapping is an essential task in computer graphics, enabling various
visual editing operations in rendering pipelines. However, existing UV
unwrapping methods struggle with time-consuming, fragmentation, lack of
semanticity, and irregular UV islands, limiting their practical use. An
artist-style UV map must not only satisfy fundamental criteria, such as
overlap-free mapping and minimal distortion, but also uphold higher-level
standards, including clean boundaries, efficient space utilization, and
semantic coherence. We introduce ArtUV, a fully automated, end-to-end method
for generating artist-style UV unwrapping. We simulates the professional UV
mapping process by dividing it into two stages: surface seam prediction and
artist-style UV parameterization. In the seam prediction stage, SeamGPT is used
to generate semantically meaningful cutting seams. Then, in the
parameterization stage, a rough UV obtained from an optimization-based method,
along with the mesh, is fed into an Auto-Encoder, which refines it into an
artist-style UV map. Our method ensures semantic consistency and preserves
topological structure, making the UV map ready for 2D editing. We evaluate
ArtUV across multiple benchmarks and show that it serves as a versatile
solution, functioning seamlessly as either a plug-in for professional rendering
tools or as a standalone system for rapid, high-quality UV generation.

</details>


### [136] [SeamCrafte: Enhancing Mesh Seam Generation for Artist UV Unwrapping via Reinforcement Learning](https://arxiv.org/abs/2509.20725)
*Duoteng Xu,Yuguang Chen,Jing Li,Xinhai Liu,Xueqi Ma,Zhuo Chen,Dongyu Zhang,Chunchao Guo*

Main category: cs.GR

TL;DR: SeamCrafter是一种基于GPT的自回归接缝生成器，通过双分支编码器和DPO优化，显著减少UV失真和碎片化，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D表面分割接缝时往往在UV失真和碎片化之间取舍不足，导致纹理合成和艺术家工作流程受阻。

Method: 使用自回归GPT风格的接缝生成器，结合双分支点云编码器分离并捕获拓扑和几何信息，并通过Direct Preference Optimization (DPO)在偏好数据集上微调模型。

Result: 实验表明，SeamCrafter生成的接缝在UV失真和碎片化方面显著优于现有方法。

Conclusion: SeamCrafter通过自回归GPT风格的接缝生成器和双分支点云编码器，显著降低了UV失真和碎片化，同时保持了拓扑一致性和视觉保真度，优于现有方法。

Abstract: Mesh seams play a pivotal role in partitioning 3D surfaces for UV
parametrization and texture mapping. Poorly placed seams often result in severe
UV distortion or excessive fragmentation, thereby hindering texture synthesis
and disrupting artist workflows. Existing methods frequently trade one failure
mode for another-producing either high distortion or many scattered islands. To
address this, we introduce SeamCrafter, an autoregressive GPT-style seam
generator conditioned on point cloud inputs. SeamCrafter employs a dual-branch
point-cloud encoder that disentangles and captures complementary topological
and geometric cues during pretraining. To further enhance seam quality, we
fine-tune the model using Direct Preference Optimization (DPO) on a preference
dataset derived from a novel seam-evaluation framework. This framework assesses
seams primarily by UV distortion and fragmentation, and provides pairwise
preference labels to guide optimization. Extensive experiments demonstrate that
SeamCrafter produces seams with substantially lower distortion and
fragmentation than prior approaches, while preserving topological consistency
and visual fidelity.

</details>


### [137] [ARMesh: Autoregressive Mesh Generation via Next-Level-of-Detail Prediction](https://arxiv.org/abs/2509.20824)
*Jiabao Lei,Kewei Shi,Zhihao Liang,Kui Jia*

Main category: cs.GR

TL;DR: 该论文提出了一种渐进式的自回归网格生成方法，通过逐步添加几何细节构建网格，提供了对生成质量和时间消耗的直观控制，并支持网格细化和编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归网格生成模型通常按字典顺序逐个构建面，未能有效捕捉与人类感知一致的底层几何结构。受2D模型中逐步细化图像的启发，作者提出了一种渐进式的粗到细网格生成方法。

Method: 作者将网格简化为单纯复形，并开发了一个基于Transformer的自回归模型来近似简化过程的逆过程。通过从单个点开始，逐步添加几何细节，其中拓扑结构未预定义且可更改。

Result: 实验表明，该方法不仅可以通过提前停止自回归过程来控制生成质量和时间消耗，还支持网格细化和编辑等应用。

Conclusion: 该论文提出了一种新颖的渐进式网格生成方法，通过自回归模型在细节层次上逐步构建网格，不仅提供了对生成质量和时间消耗的直观控制，还支持网格细化和编辑等应用。

Abstract: Directly generating 3D meshes, the default representation for 3D shapes in
the graphics industry, using auto-regressive (AR) models has become popular
these days, thanks to their sharpness, compactness in the generated results,
and ability to represent various types of surfaces. However, AR mesh generative
models typically construct meshes face by face in lexicographic order, which
does not effectively capture the underlying geometry in a manner consistent
with human perception. Inspired by 2D models that progressively refine images,
such as the prevailing next-scale prediction AR models, we propose generating
meshes auto-regressively in a progressive coarse-to-fine manner. Specifically,
we view mesh simplification algorithms, which gradually merge mesh faces to
build simpler meshes, as a natural fine-to-coarse process. Therefore, we
generalize meshes to simplicial complexes and develop a transformer-based AR
model to approximate the reverse process of simplification in the order of
level of detail, constructing meshes initially from a single point and
gradually adding geometric details through local remeshing, where the topology
is not predefined and is alterable. Our experiments show that this novel
progressive mesh generation approach not only provides intuitive control over
generation quality and time consumption by early stopping the auto-regressive
process but also enables applications such as mesh refinement and editing.

</details>


### [138] [ArchGPT: Understanding the World's Architectures with Large Multimodal Models](https://arxiv.org/abs/2509.20858)
*Yuze Wang,Luo Yang,Junyi Wang,Yue Qi*

Main category: cs.GR

TL;DR: ArchGPT是一个多模态建筑视觉问答模型，通过可扩展的数据构建流程生成高质量的建筑特定注释，显著提升了VR/MR/AR系统在建筑领域的可扩展性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的VR/MR/AR系统通常针对特定案例开发，依赖硬编码注释和任务特定交互，无法适应多样化的建筑环境。为了解决这一问题，研究者提出了ArchGPT和数据构建流程，以增强系统的可扩展性和适应性。

Method: 研究提出了一种名为ArchGPT的多模态建筑视觉问答模型，并开发了一个可扩展的数据构建流程，用于生成高质量的、特定于建筑的视觉问答注释。该流程包括三个阶段：首先通过3D重建和语义分割从Wikimedia Commons和旅游照片中筛选出结构一致的建筑图像；然后利用LLM引导的文本验证和知识蒸馏流程生成可靠的问答对；最后进一步合成详细描述和方面引导的对话，以提供更丰富的语义信息。

Result: 研究构建了Arch-300K数据集，包含约315,000个图像-问题-答案三元组。通过对开源多模态骨干模型ShareGPT4V-7B进行监督微调，得到了ArchGPT模型。

Conclusion: ArchGPT通过多模态视觉问答模型和可扩展的数据构建流程，显著提升了建筑领域的虚拟现实、混合现实和增强现实系统的可扩展性和适应性，为建筑教育、遗产保护和专业设计实践提供了更高效的解决方案。

Abstract: Architecture embodies aesthetic, cultural, and historical values, standing as
a tangible testament to human civilization. Researchers have long leveraged
virtual reality (VR), mixed reality (MR), and augmented reality (AR) to enable
immersive exploration and interpretation of architecture, enhancing
accessibility, public understanding, and creative workflows around architecture
in education, heritage preservation, and professional design practice. However,
existing VR/MR/AR systems are often developed case-by-case, relying on
hard-coded annotations and task-specific interactions that do not scale across
diverse built environments. In this work, we present ArchGPT, a multimodal
architectural visual question answering (VQA) model, together with a scalable
data-construction pipeline for curating high-quality, architecture-specific VQA
annotations. This pipeline yields Arch-300K, a domain-specialized dataset of
approximately 315,000 image-question-answer triplets. Arch-300K is built via a
multi-stage process: first, we curate architectural scenes from Wikimedia
Commons and filter unconstrained tourist photo collections using a novel
coarse-to-fine strategy that integrates 3D reconstruction and semantic
segmentation to select occlusion-free, structurally consistent architectural
images. To mitigate noise and inconsistency in raw textual metadata, we propose
an LLM-guided text verification and knowledge-distillation pipeline to generate
reliable, architecture-specific question-answer pairs. Using these curated
images and refined metadata, we further synthesize formal analysis
annotations-including detailed descriptions and aspect-guided conversations-to
provide richer semantic variety while remaining faithful to the data. We
perform supervised fine-tuning of an open-source multimodal backbone
,ShareGPT4V-7B, on Arch-300K, yielding ArchGPT.

</details>


### [139] [Marching Neurons: Accurate Surface Extraction for Neural Implicit Shapes](https://arxiv.org/abs/2509.21007)
*Christian Stippel,Felix Mujkanovic,Thomas Leimkühler,Pedro Hermosilla*

Main category: cs.GR

TL;DR: 提出了一种直接从神经隐式函数中解析提取表面的新方法，避免了传统固定分辨率方法的精度损失，实现了高精度和高效能的平衡。


<details>
  <summary>Details</summary>
Motivation: 显式和隐式表示在3D视觉计算中各具优势，但传统隐式表面提取方法（如Marching Cubes）因固定分辨率导致精度不足。

Method: 提出了一种基于深度优先遍历策略的新方法，直接从神经隐式函数中解析提取表面，无需空间离散化。

Result: 生成的网格准确捕捉了网络的完整几何信息，在多样形状和网络架构中实现了前所未有的精度，同时保持较高的速度。

Conclusion: 该方法通过分析神经隐式函数的神经元分区，实现了高效且精确的表面提取，避免了传统方法因固定分辨率导致的精度损失。

Abstract: Accurate surface geometry representation is crucial in 3D visual computing.
Explicit representations, such as polygonal meshes, and implicit
representations, like signed distance functions, each have distinct advantages,
making efficient conversions between them increasingly important. Conventional
surface extraction methods for implicit representations, such as the widely
used Marching Cubes algorithm, rely on spatial decomposition and sampling,
leading to inaccuracies due to fixed and limited resolution. We introduce a
novel approach for analytically extracting surfaces from neural implicit
functions. Our method operates natively in parallel and can navigate large
neural architectures. By leveraging the fact that each neuron partitions the
domain, we develop a depth-first traversal strategy to efficiently track the
encoded surface. The resulting meshes faithfully capture the full geometric
information from the network without ad-hoc spatial discretization, achieving
unprecedented accuracy across diverse shapes and network architectures while
maintaining competitive speed.

</details>


### [140] [CHARM: Control-point-based 3D Anime Hairstyle Auto-Regressive Modeling](https://arxiv.org/abs/2509.21114)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Yushi Bai,Kaiwen Xiao,Yong-Jin Liu,Zhongqian Sun,Wei Yang*

Main category: cs.GR

TL;DR: CHARM是一种新型的动漫发型建模框架，通过控制点参数化和自回归生成方法，实现了高效、高质量的动漫发型生成与重建。


<details>
  <summary>Details</summary>
Motivation: 传统发型建模方法专注于使用基于发丝或体积的表示来生成真实发型，而动漫发型具有高度风格化、分段结构的几何特征，这对现有技术提出了挑战。现有方法通常依赖于密集网格建模或手工制作的样条曲线，这使得它们在编辑时效率低下，且不适合可扩展的学习。

Method: CHARM引入了一种基于控制点的紧凑、可逆参数化表示，并构建了一个自回归生成框架，能够从输入图像或点云中有效生成动漫发型。

Result: 通过构建AnimeHair数据集（包含37K个高质量动漫发型），实验证明CHARM在重建准确性和生成质量上均达到了最先进的性能。

Conclusion: CHARM提供了一种表达性强且可扩展的动漫发型建模解决方案，通过实验证明了其在重建准确性和生成质量上的最先进性能。

Abstract: We present CHARM, a novel parametric representation and generative framework
for anime hairstyle modeling. While traditional hair modeling methods focus on
realistic hair using strand-based or volumetric representations, anime
hairstyle exhibits highly stylized, piecewise-structured geometry that
challenges existing techniques. Existing works often rely on dense mesh
modeling or hand-crafted spline curves, making them inefficient for editing and
unsuitable for scalable learning. CHARM introduces a compact, invertible
control-point-based parameterization, where a sequence of control points
represents each hair card, and each point is encoded with only five geometric
parameters. This efficient and accurate representation supports both
artist-friendly design and learning-based generation. Built upon this
representation, CHARM introduces an autoregressive generative framework that
effectively generates anime hairstyles from input images or point clouds. By
interpreting anime hairstyles as a sequential "hair language", our
autoregressive transformer captures both local geometry and global hairstyle
topology, resulting in high-fidelity anime hairstyle creation. To facilitate
both training and evaluation of anime hairstyle generation, we construct
AnimeHair, a large-scale dataset of 37K high-quality anime hairstyles with
separated hair cards and processed mesh data. Extensive experiments demonstrate
state-of-the-art performance of CHARM in both reconstruction accuracy and
generation quality, offering an expressive and scalable solution for anime
hairstyle modeling. Project page: https://hyzcluster.github.io/charm/

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [141] [ACCeLLiuM: Supervised Fine-Tuning for Automated OpenACC Pragma Generation](https://arxiv.org/abs/2509.20380)
*Samyak Jhaveri,Vanessa Klotzmann,Crista Lopes*

Main category: cs.SE

TL;DR: ACCeLLiuM是专为生成OpenACC指令微调的LLM，显著提升了生成正确pragma的能力，并公开了代码和数据集以降低GPU编程门槛。


<details>
  <summary>Details</summary>
Motivation: GPU的普及伴随着硬件和并行编程框架的复杂性增加，现有标准如OpenACC虽简化了编程，但仍需专业知识才能有效使用指令。

Method: 引入ACCeLLiuM，两个经过专门微调的大型语言模型，用于生成数据并行循环的专家级OpenACC指令，并提供用于训练的监督微调数据集。

Result: 在测试集上，基础LLM无法一致生成有效pragma，而经过ACCeLLiuM数据集微调的LLM能生成87%正确类型的pragma，其中50%完全匹配（包括指令、子句顺序和变量）。

Conclusion: 通过公开代码、模型和数据集，ACCeLLiuM希望为基于LLM的OpenACC pragma生成建立可复现的基准，并降低自动化GPU卸载的门槛。

Abstract: The increasing ubiquity of GPUs is accompanied by the increasing complexity
of their hardware and parallel programming frameworks. Directive-based parallel
programming standards like OpenACC simplify GPU programming to some extent by
abstracting away low-level complexities, but a fair amount of expertise is
still required in order to use those directives effectively.
  We introduce ACCeLLiuM, two open weights Large Language Models specifically
fine-tuned for generating expert OpenACC directives for data-parallel loops,
along with the supervised fine-tuning dataset that was used to train them. The
ACCeLLiuM SFT dataset contains 4,033 OpenACC pragma-loop pairs mined from
public GitHub C/C++ repositories, with 3,223 pairs for training and 810 for
testing. Experimental evaluations show a pronounced performance gap in
generating correct OpenACC pragmas between base LLMs and our fine-tuned
versions. On the held-out test set, base LLMs fail to consistently generate
valid pragmas, whereas LLMs fine-tuned on the ACCeLLiuM dataset generate valid
pragmas with the correct directive type for $87\%$ of the data-parallel loops,
and exact pragmas--including directives, clauses, clause order, and clause
variables--for $50\%$ of the cases. Even when not exact, generated pragmas
frequently incorporate the correct clauses in a different order than the
ground-truth label, or include additional clauses that enable finer control
over parallel execution, data movement, and concurrency, offering practical
value beyond strict string-matching. By publicly releasing the code, models,
and dataset as ACCeLLiuM we hope to establish a reproducible benchmark for
LLM-powered OpenACC pragma generation, and lower the barrier to automated GPU
offloading of serially written programs.

</details>


### [142] [State-of-the-Art in Software Security Visualization: A Systematic Review](https://arxiv.org/abs/2509.20385)
*Ishara Devendra,Chaman Wijesiriwardana,Prasad Wimalaratne*

Main category: cs.SE

TL;DR: 该论文系统回顾了软件安全可视化技术，提出了四类分类法，并强调了创新可视化技术对于适应不断变化的安全格局的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统变得更加复杂且威胁格局不断演变，传统的基于文本和数值的安全分析方法变得越来越低效。

Method: 通过文献系统性地回顾了现有研究，创建了一个全面的软件安全可视化技术分类法，将这些技术分为四类：基于图、基于符号、基于矩阵和基于隐喻的可视化。

Result: 研究发现，软件安全可视化的两个主要领域是广泛的软件开发可视化和网络安全可视化，强调了创新可视化技术的必要性。

Conclusion: 该论文强调了创新的可视化技术对于适应不断变化的安全格局的必要性，并提出了对威胁检测、安全响应策略改进以及未来研究的实际影响。

Abstract: Software security visualization is an interdisciplinary field that combines
the technical complexity of cybersecurity, including threat intelligence and
compliance monitoring, with visual analytics, transforming complex security
data into easily digestible visual formats. As software systems get more
complex and the threat landscape evolves, traditional text-based and numerical
methods for analyzing and interpreting security concerns become increasingly
ineffective. The purpose of this paper is to systematically review existing
research and create a comprehensive taxonomy of software security visualization
techniques through literature, categorizing these techniques into four types:
graph-based, notation-based, matrix-based, and metaphor-based visualization.
This systematic review explores over 60 recent key research papers in software
security visualization, highlighting its key issues, recent advancements, and
prospective future research directions. From the comprehensive analysis, the
two main areas were distinctly highlighted as extensive software development
visualization, focusing on advanced methods for depicting software
architecture: operational security visualization and cybersecurity
visualization. The findings highlight the necessity for innovative
visualization techniques that adapt to the evolving security landscape, with
practical implications for enhancing threat detection, improving security
response strategies, and guiding future research.

</details>


### [143] [Dynamic ReAct: Scalable Tool Selection for Large-Scale MCP Environments](https://arxiv.org/abs/2509.20386)
*Nishant Gaurav,Adit Akarsh,Ankit Ranjan,Manoj Bajaj*

Main category: cs.SE

TL;DR: Dynamic ReAct通过智能搜索和加载机制优化工具选择，减少50%工具加载且不影响准确性，推动通用AI代理发展。


<details>
  <summary>Details</summary>
Motivation: 解决在包含数百或数千个工具的环境中，工具选择的基础性挑战，因为同时加载所有工具在计算上不可行。

Method: 提出了五种不同的架构，逐步优化工具选择过程，最终采用搜索和加载机制。

Result: 实验结果表明，该方法减少了高达50%的工具加载，同时保持了任务完成准确性。

Conclusion: Dynamic ReAct通过搜索和加载机制实现了智能工具选择，减少了50%的工具加载，同时保持了任务完成的准确性，推动了通用AI代理的发展。

Abstract: We present Dynamic ReAct, a novel approach for enabling ReAct agents to ef-
ficiently operate with extensive Model Control Protocol (MCP) tool sets that
exceed the contextual memory limitations of large language models. Our approach
addresses the fundamental challenge of tool selection in environments
containing hundreds or thousands of available tools, where loading all tools
simultaneously is computationally infeasible. We propose and evaluate five
distinct architectures that progressively refine the tool selection process,
culminating in a search-and-load mechanism that achieves intelligent tool
selection with minimal computational overhead. Our experimental results
demonstrate that the proposed approach reduces tool loading by up to 50% while
maintaining task completion accuracy, advancing the path towards truly
general-purpose AI agents capable of dynamically adapting to diverse task
environments.

</details>


### [144] [Towards Systematic Specification and Verification of Fairness Requirements: A Position Paper](https://arxiv.org/abs/2509.20387)
*Qusai Ramadan,Jukka Ruohonen,Abhishek Tiwari,Adam Alami,Zeyd Boukhers*

Main category: cs.SE

TL;DR: 本文提出利用知识图谱框架规范和验证公平性需求，以解决软件系统中的歧视问题，并讨论了相关挑战和解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的软件系统可能因设计不当或数据偏见导致对性别、种族等受保护特征的歧视行为，而现有研究多忽视公平性需求的明确规范和验证。

Method: 通过分析现有研究的不足，提出利用知识图谱形式化专家知识，以辅助公平性需求的规范和验证。

Result: 本文讨论了相关挑战、研究问题，并提出了解决这些问题的路线图。

Conclusion: 本文提出了一种基于知识图谱的框架来规范和验证公平性需求，以解决现有软件系统中因缺乏明确公平性要求而导致的歧视问题。

Abstract: Decisions suggested by improperly designed software systems might be prone to
discriminate against people based on protected characteristics, such as gender
and ethnicity. Previous studies attribute such undesired behavior to flaws in
algorithmic design or biased data. However, these studies ignore that
discrimination is often the result of a lack of well-specified fairness
requirements and their verification. The fact that experts' knowledge about
fairness is often implicit makes the task of specifying precise and verifiable
fairness requirements difficult. In related domains, such as security
engineering, knowledge graphs have been proven to be effective in formalizing
knowledge to assist requirements specification and verification. To address the
lack of formal mechanisms for specifying and verifying fairness requirements,
we propose the development of a knowledge graph-based framework for fairness.
In this paper, we discuss the challenges, research questions, and a road map
towards addressing the research questions.

</details>


### [145] [Online-Optimized RAG for Tool Use and Function Calling](https://arxiv.org/abs/2509.20415)
*Yu Pan,Xiaocheng Li,Hanzhao Wang*

Main category: cs.SE

TL;DR: Online-Optimized RAG 通过在线优化检索嵌入，解决了嵌入错位问题，提升了工具选择和任务成功的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中由于嵌入模型不完善或描述噪声导致的嵌入错位问题，这种错位可能导致检索错误和任务失败。

Method: 该方法通过轻量级的在线梯度更新，利用最小反馈（如任务成功）持续调整检索嵌入，支持单跳和多跳工具使用、动态工具库以及带重排的 K-检索。

Result: 在不同工具使用和文档检索场景中，Online-Optimized RAG 显著提高了工具选择准确性和任务成功率。

Conclusion: Online-Optimized RAG 提供了一种简单、实用的方法，通过持续优化检索嵌入来提高工具选择的准确性和任务成功率，从而增强 RAG 系统的鲁棒性和自我改进能力。

Abstract: In many applications, retrieval-augmented generation (RAG) drives tool use
and function calling by embedding the (user) queries and matching them to
pre-specified tool/function descriptions. In this paper, we address an
embedding misalignment issue that often arises in practical applications due to
imperfect embedding models or noisy descriptions; such misalignment may lead to
incorrect retrieval and task failure. We introduce Online-Optimized RAG, a
deployment-time framework that continually adapts retrieval embeddings from
live interactions using minimal feedback (e.g., task success). Online-Optimized
RAG applies lightweight online gradient updates with negligible per-query
latency and requires no changes to the underlying LLM. The method is
plug-and-play: it supports both single- and multi-hop tool use, dynamic tool
inventories, and $K$-retrieval with re-ranking. We provide a problem-dependent
theoretical analysis that quantifies how the method's performance depends on
the initialization quality of the embeddings and other related quantities.
Across diverse tool-use and document-retrieval scenarios, our Online-Optimized
RAG consistently improves tool selection accuracy and end-task success, thus
providing a simple, practical path to robust, self-improving RAG systems.

</details>


### [146] [Formal Verification of Legal Contracts: A Translation-based Approach](https://arxiv.org/abs/2509.20421)
*Reiner Hähnle,Cosimo Laneve,Adele Veschetti*

Main category: cs.SE

TL;DR: Stipula语言通过翻译为JML注解的Java代码，结合KeY工具，自动验证法律合同的正确性。


<details>
  <summary>Details</summary>
Motivation: 设计Stipula语言旨在建模具有可执行属性的法律合同，尤其是涉及资产转移和义务的合同，需确保其正确性。

Method: 将Stipula合同翻译为带Java Modeling Language（JML）注解的Java代码，并利用KeY工具进行演绎验证。

Result: 实现了对具有非重叠循环的Stipula合同的部分和完全正确性的自动验证。

Conclusion: Stipula语言通过翻译为带JML注解的Java代码，结合KeY工具，成功实现了对具有非重叠循环的Stipula合同的部分和完全正确性的自动验证，证明了通用演绎验证工具在翻译方法中的有效性。

Abstract: Stipula is a domain-specific programming language designed to model legal
contracts with enforceable properties, especially those involving asset
transfers and obligations. This paper presents a methodology to formally verify
the correctness of Stipula contracts through translation into Java code
annotated with Java Modeling Language specifications. As a verification
backend, the deductive verification tool KeY is used. Both, the translation and
the verification of partial and total correctness for a large subset of Stipula
contracts, those with disjoint cycles, is fully automatic. Our work
demonstrates that a general-purpose deductive verification tool can be used
successfully in a translation approach.

</details>


### [147] [AI-Specific Code Smells: From Specification to Detection](https://arxiv.org/abs/2509.20491)
*Brahim Mahmoudi,Naouel Moha,Quentin Stievenert,Florent Avellaneda*

Main category: cs.SE

TL;DR: SpecDetect4AI 是一种工具，用于检测 AI 特定代码异味，表现优异。


<details>
  <summary>Details</summary>
Motivation: AI 系统的兴起带来了新的软件问题，现有检测工具往往无法覆盖，尤其是 AI 特定代码异味。

Method: 结合高级声明性领域特定语言（DSL）和可扩展静态分析工具，用于规范和检测 AI 特定代码异味。

Result: 在 826 个 AI 系统（2000 万行代码）中评估，SpecDetect4AI 的精确度为 88.66%，召回率为 88.89%，优于其他现有工具。

Conclusion: SpecDetect4AI 能够有效支持 AI 特定代码异味的规范化和检测，并在大规模 AI 系统中表现出高效性和可扩展性。

Abstract: The rise of Artificial Intelligence (AI) is reshaping how software systems
are developed and maintained. However, AI-based systems give rise to new
software issues that existing detection tools often miss. Among these, we focus
on AI-specific code smells, recurring patterns in the code that may indicate
deeper problems such as unreproducibility, silent failures, or poor model
generalization. We introduce SpecDetect4AI, a tool-based approach for the
specification and detection of these code smells at scale. This approach
combines a high-level declarative Domain-Specific Language (DSL) for rule
specification with an extensible static analysis tool that interprets and
detects these rules for AI-based systems. We specified 22 AI-specific code
smells and evaluated SpecDetect4AI on 826 AI-based systems (20M lines of code),
achieving a precision of 88.66% and a recall of 88.89%, outperforming other
existing detection tools. Our results show that SpecDetect4AI supports the
specification and detection of AI-specific code smells through dedicated rules
and can effectively analyze large AI-based systems, demonstrating both
efficiency and extensibility (SUS 81.7/100).

</details>


### [148] [PromptDebt: A Comprehensive Study of Technical Debt Across LLM Projects](https://arxiv.org/abs/2509.20497)
*Ahmed Aljohani,Hyunsook Do*

Main category: cs.SE

TL;DR: 研究表明LLM集成中技术债务普遍，提示设计是主要问题，发布数据集以支持研究和实践。


<details>
  <summary>Details</summary>
Motivation: 研究LLM集成中自认技术债务（SATD）的起源和普遍性，以帮助开发者更好地管理这些债务。

Method: 通过分析93,142个Python文件，研究了LLM特定SATD的来源、普遍性和缓解策略。

Result: 研究发现54.49%的SATD实例来自OpenAI集成，12.35%来自LangChain使用，提示设计是主要债务来源。

Conclusion: 论文强调了LLM集成中技术债务的普遍性，并提供了管理这些债务的实用指南，同时发布了一个全面的SATD数据集以支持可重复性研究。

Abstract: Large Language Models (LLMs) are increasingly embedded in software via APIs
like OpenAI, offering powerful AI features without heavy infrastructure. Yet
these integrations bring their own form of self-admitted technical debt (SATD).
In this paper, we present the first large-scale empirical study of LLM-specific
SATD: its origins, prevalence, and mitigation strategies. By analyzing 93,142
Python files across major LLM APIs, we found that 54.49% of SATD instances stem
from OpenAI integrations and 12.35% from LangChain use. Prompt design emerged
as the primary source of LLM-specific SATD, with 6.61% of debt related to
prompt configuration and optimization issues, followed by hyperparameter tuning
and LLM-framework integration. We further explored which prompt techniques
attract the most debt, revealing that instruction-based prompts (38.60%) and
few-shot prompts (18.13%) are particularly vulnerable due to their dependence
on instruction clarity and example quality. Finally, we release a comprehensive
SATD dataset to support reproducibility and offer practical guidance for
managing technical debt in LLM-powered systems.

</details>


### [149] [Enhancing Python Programming Education with an AI-Powered Code Helper: Design, Implementation, and Impact](https://arxiv.org/abs/2509.20518)
*Sayed Mahbub Hasan Amiri,Md Mainul Islam*

Main category: cs.SE

TL;DR: 一款AI-Python聊天机器人，结合静态分析、动态追踪和LLMs，显著提升编程学习效果，错误解决率85%，调试时间减少59.3%，熟练度提升34%。


<details>
  <summary>Details</summary>
Motivation: 传统编码工具（如IDE和静态分析器）缺乏机器人辅助，而AI驱动的代码助手（如GitHub Copilot）仅关注代码完成。本研究旨在填补这一空白，通过提供相关且实用的建议促进学生学习。

Method: 采用混合架构，结合CodeLlama进行代码嵌入、GPT-4处理自然语言交互，以及基于Docker的沙盒安全执行。通过静态代码分析、动态执行追踪和LLMs技术，为学生提供实用建议。

Result: 系统在1,500份学生提交中表现出85%的错误解决成功率，优于pylint（62%）和GPT-4（73%）。调试时间减少59.3%，编程熟练度提升34%。定性反馈显示聊天机器人在清晰度和可访问性上表现优异，但也存在延迟和代码限制问题。

Conclusion: 本研究通过结合静态代码分析、动态执行追踪和大语言模型（LLMs），开发了一款AI-Python聊天机器人，旨在提升编程教育的效果。该系统不仅显著提高了错误解决率和编程熟练度，还为AI工具在教育领域的应用提供了蓝图，强调教育公平和长期技能保留。

Abstract: This is the study that presents an AI-Python-based chatbot that helps
students to learn programming by demonstrating solutions to such problems as
debugging errors, solving syntax problems or converting abstract theoretical
concepts to practical implementations. Traditional coding tools like Integrated
Development Environments (IDEs) and static analyzers do not give robotic help
while AI-driven code assistants such as GitHub Copilot focus on getting things
done. To close this gap, our chatbot combines static code analysis, dynamic
execution tracing, and large language models (LLMs) to provide the students
with relevant and practical advice, hence promoting the learning process. The
chatbots hybrid architecture employs CodeLlama for code embedding, GPT-4 for
natural language interactions, and Docker-based sandboxing for secure
execution. Evaluated through a mixed-methods approach involving 1,500 student
submissions, the system demonstrated an 85% error resolution success rate,
outperforming standalone tools like pylint (62%) and GPT-4 (73%). Quantitative
results revealed a 59.3% reduction in debugging time among users, with pre- and
post-test assessments showing a 34% improvement in coding proficiency,
particularly in recursion and exception handling. Qualitative feedback from 120
students highlighted the chatbots clarity, accessibility, and
confidence-building impact, though critiques included occasional latency and
restrictive code sanitization. By balancing technical innovation with
pedagogical empathy, this research provides a blueprint for AI tools that
prioritize educational equity and long-term skill retention over mere code
completion. The chatbot exemplifies how AI can augment human instruction,
fostering deeper conceptual understanding in programming education.

</details>


### [150] [Enhancing LLM-based Fault Localization with a Functionality-Aware Retrieval-Augmented Generation Framework](https://arxiv.org/abs/2509.20552)
*Xinyu Shi,Zhenhao Li,An Ran Chen*

Main category: cs.SE

TL;DR: FaR-Loc结合LLMs和RAG技术，优化方法级故障定位，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在复杂系统中进行故障定位时，因缺乏项目特定知识和难以导航大型项目而表现不佳。

Method: FaR-Loc由三个关键组件组成：LLM功能提取、语义密集检索和LLM重排序。

Result: 在Defects4J基准测试中，FaR-Loc在Top-1和Top-5准确率上分别比SoapFL和AutoFL高出14.6%/9.1%和19.2%/22.1%。

Conclusion: FaR-Loc通过结合LLMs和RAG技术，显著提升了方法级故障定位的性能，且在Defects4J基准测试中优于现有方法。

Abstract: Fault localization (FL) is a critical but time-consuming task in software
debugging, aiming to identify faulty code elements. While recent advances in
large language models (LLMs) have shown promise for FL, they often struggle
with complex systems due to the lack of project-specific knowledge and the
difficulty of navigating large projects. To address these limitations, we
propose FaR-Loc, a novel framework that enhances method-level FL by integrating
LLMs with retrieval-augmented generation (RAG). FaR-Loc consists of three key
components: LLM Functionality Extraction, Semantic Dense Retrieval, and LLM
Re-ranking. First, given a failed test and its associated stack trace, the LLM
Functionality Extraction module generates a concise natural language
description that captures the failing behavior. Next, the Semantic Dense
Retrieval component leverages a pre-trained code-understanding encoder to embed
both the functionality description (natural language) and the covered methods
(code) into a shared semantic space, enabling the retrieval of methods with
similar functional behavior. Finally, the LLM Re-ranking module reorders the
retrieved methods based on their contextual relevance. Our experiments on the
widely used Defects4J benchmark show that FaR-Loc outperforms state-of-the-art
LLM-based baselines SoapFL and AutoFL, by 14.6% and 9.1% in Top-1 accuracy, by
19.2% and 22.1% in Top-5 accuracy, respectively. It also surpasses all
learning-based and spectrum-based baselines across all Top-N metrics without
requiring re-training. Furthermore, we find that pre-trained code embedding
models that incorporate code structure, such as UniXcoder, can significantly
improve fault localization performance by up to 49.0% in Top-1 accuracy.
Finally, we conduct a case study to illustrate the effectiveness of FaR-Loc and
to provide insights for its practical application.

</details>


### [151] [Design, Implementation and Evaluation of a Novel Programming Language Topic Classification Workflow](https://arxiv.org/abs/2509.20631)
*Michael Zhang,Yuan Tian,Mariam Guizani*

Main category: cs.SE

TL;DR: A novel workflow using multi-label SVM with sliding window and voting strategy effectively classifies programming language topics, achieving high accuracy on the IBM CodeNet dataset.


<details>
  <summary>Details</summary>
Motivation: Understanding the distribution of programming language topics within source code is crucial for technical decisions, onboarding, tooling, and education as software systems grow in scale and complexity.

Method: The approach combines a multi-label Support Vector Machine (SVM) with a sliding window and voting strategy for fine-grained localization of core language concepts.

Result: The model, trained on the IBM Project CodeNet dataset, achieves an average F1 score of 0.90 across topics and 0.75 in code-topic highlight.

Conclusion: The paper contributes empirical insights and a reusable pipeline for code analysis and data-driven software engineering, demonstrating the effectiveness of the proposed workflow in classifying programming language topics.

Abstract: As software systems grow in scale and complexity, understanding the
distribution of programming language topics within source code becomes
increasingly important for guiding technical decisions, improving onboarding,
and informing tooling and education. This paper presents the design,
implementation, and evaluation of a novel programming language topic
classification workflow. Our approach combines a multi-label Support Vector
Machine (SVM) with a sliding window and voting strategy to enable fine-grained
localization of core language concepts such as operator overloading, virtual
functions, inheritance, and templates. Trained on the IBM Project CodeNet
dataset, our model achieves an average F1 score of 0.90 across topics and 0.75
in code-topic highlight. Our findings contribute empirical insights and a
reusable pipeline for researchers and practitioners interested in code analysis
and data-driven software engineering.

</details>


### [152] [Exploring Engagement in Hybrid Meetings](https://arxiv.org/abs/2509.20780)
*Daniela Grassi,Fabio Calefato,Darja Smite,Nicole Novielli,Filippo Lanubile*

Main category: cs.SE

TL;DR: 研究发现混合会议中现场和远程参与者参与水平相当，但远程参与者在长时间会议中表现较差；主动角色提升参与度，大型或下午会议则降低参与度。


<details>
  <summary>Details</summary>
Motivation: COVID-19大流行后，混合工作的广泛采用从根本上改变了软件开发实践，引入了沟通和协作的新挑战。本研究旨在通过客观测量识别和表征混合会议中的参与模式，重点关注现场和远程参与者之间的差异。

Method: 我们研究了来自三家软件公司的专业人员，采用多模式方法来测量参与度。通过自填问卷和生物识别设备在混合会议中收集数据，以理解参与动态。

Result: 回归分析显示，现场和远程参与者的参与水平相当，但远程参与者在长时间会议中的参与度较低，无论参与模式如何。主动角色与更高的参与度呈正相关，而更大的会议和下午会议则与较低的参与度相关。

Conclusion: 研究结果为混合会议中的参与和脱离因素提供了见解，并提出了可能的会议改进建议。这些见解不仅对软件团队有潜在价值，也对面临类似混合协作挑战的知识密集型组织具有广泛适用性。

Abstract: Background. The widespread adoption of hybrid work following the COVID-19
pandemic has fundamentally transformed software development practices,
introducing new challenges in communication and collaboration as organizations
transition from traditional office-based structures to flexible working
arrangements. This shift has established a new organizational norm where even
traditionally office-first companies now embrace hybrid team structures. While
remote participation in meetings has become commonplace in this new
environment, it may lead to isolation, alienation, and decreased engagement
among remote team members. Aims. This study aims to identify and characterize
engagement patterns in hybrid meetings through objective measurements, focusing
on the differences between co-located and remote participants. Method. We
studied professionals from three software companies over several weeks,
employing a multimodal approach to measure engagement. Data were collected
through self-reported questionnaires and physiological measurements using
biometric devices during hybrid meetings to understand engagement dynamics.
Results. The regression analyses revealed comparable engagement levels between
onsite and remote participants, though remote participants show lower
engagement in long meetings regardless of participation mode. Active roles
positively correlate with higher engagement, while larger meetings and
afternoon sessions are associated with lower engagement. Conclusions. Our
results offer insights into factors associated with engagement and
disengagement in hybrid meetings, as well as potential meeting improvement
recommendations. These insights are potentially relevant not only for software
teams but also for knowledge-intensive organizations across various sectors
facing similar hybrid collaboration challenges.

</details>


### [153] [Verification Limits Code LLM Training](https://arxiv.org/abs/2509.20837)
*Srishti Gureja,Elena Tommasone,Jingyi He,Sara Hooker,Matthias Gallé,Marzieh Fadaee*

Main category: cs.SE

TL;DR: 研究发现当前代码生成模型的验证方法过于僵化，通过调整验证策略（如放宽阈值、增加测试多样性）可提升模型性能，但不能完全取消验证。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在代码生成中依赖合成数据时，验证质量与多样性受限于合成验证器能力的瓶颈问题。

Method: 系统研究了验证设计和策略如何影响模型性能，包括测试复杂性和数量的影响、放宽通过阈值的探索、以及正式正确与错误解决方案的对比。

Result: 研究发现，更丰富的测试套件可提高代码生成能力（平均+3 pass@1），而数量单独作用则收益递减；放宽通过阈值或引入LLM软验证可恢复有价值的数据，带来2-4点pass@1性能提升；保持每个问题的多样化正确解决方案能带来一致的泛化收益。

Conclusion: 当前的验证实践过于僵化，过滤掉了有价值的多样性，但不能完全抛弃，只能重新校准。通过结合校准验证与多样化的挑战性问题-解决方案对，我们为突破验证上限和释放更强的代码生成模型奠定了基础。

Abstract: Large language models for code generation increasingly rely on synthetic
data, where both problem solutions and verification tests are generated by
models. While this enables scalable data creation, it introduces a previously
unexplored bottleneck: the verification ceiling, in which the quality and
diversity of training data are fundamentally constrained by the capabilities of
synthetic verifiers. In this work, we systematically study how verification
design and strategies influence model performance. We investigate (i) what we
verify by analyzing the impact of test complexity and quantity: richer test
suites improve code generation capabilities (on average +3 pass@1), while
quantity alone yields diminishing returns, (ii) how we verify by exploring
relaxed pass thresholds: rigid 100% pass criteria can be overly restrictive. By
allowing for relaxed thresholds or incorporating LLM-based soft verification,
we can recover valuable training data, leading to a 2-4 point improvement in
pass@1 performance. However, this benefit is contingent upon the strength and
diversity of the test cases used, and (iii) why verification remains necessary
through controlled comparisons of formally correct versus incorrect solutions
and human evaluation: retaining diverse correct solutions per problem yields
consistent generalization gains. Our results show that Verification as
currently practiced is too rigid, filtering out valuable diversity. But it
cannot be discarded, only recalibrated. By combining calibrated verification
with diverse, challenging problem-solution pairs, we outline a path to break
the verification ceiling and unlock stronger code generation models.

</details>


### [154] [PseudoBridge: Pseudo Code as the Bridge for Better Semantic and Logic Alignment in Code Retrieval](https://arxiv.org/abs/2509.20881)
*Yixuan Li,Xinyi Liu,Weidong Yang,Ben Fei,Shuhao Li,Mingjie Zhou,Lipeng Ma*

Main category: cs.SE

TL;DR: PseudoBridge通过伪代码对齐自然语言与编程语言逻辑，提升代码检索的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练语言模型（PLM）的代码检索方法存在语义鸿沟和代码风格多样性不足的问题。

Method: PseudoBridge采用两阶段框架：1) 使用大型语言模型（LLM）合成伪代码以对齐自然语言查询与伪代码；2) 通过逻辑不变的代码风格增强策略生成多样化的等效代码实现，并增强模型对代码风格变化的鲁棒性。

Result: 在10种PLM和6种主流编程语言上的实验表明，PseudoBridge在检索准确性和泛化能力上均显著优于基线方法，特别是在Solidity和XLCoST数据集上。

Conclusion: PseudoBridge通过引入伪代码作为中间模态，显著提升了代码检索的准确性和泛化能力，特别是在零样本领域迁移场景下表现优异。

Abstract: Code search aims to precisely find relevant code snippets that match natural
language queries within massive codebases, playing a vital role in software
development. Recent advances leverage pre-trained language models (PLMs) to
bridge the semantic gap between unstructured natural language (NL) and
structured programming languages (PL), yielding significant improvements over
traditional information retrieval and early deep learning approaches. However,
existing PLM-based methods still encounter key challenges, including a
fundamental semantic gap between human intent and machine execution logic, as
well as limited robustness to diverse code styles. To address these issues, we
propose PseudoBridge, a novel code retrieval framework that introduces
pseudo-code as an intermediate, semi-structured modality to better align NL
semantics with PL logic. Specifically, PseudoBridge consists of two stages.
First, we employ an advanced large language model (LLM) to synthesize
pseudo-code, enabling explicit alignment between NL queries and pseudo-code.
Second, we introduce a logic-invariant code style augmentation strategy and
employ the LLM to generate stylistically diverse yet logically equivalent code
implementations with pseudo-code, then align the code snippets of different
styles with pseudo-code, enhancing model robustness to code style variation. We
build PseudoBridge across 10 different PLMs and evaluate it on 6 mainstream
programming languages. Extensive experiments demonstrate that PseudoBridge
consistently outperforms baselines, achieving significant gains in retrieval
accuracy and generalization, particularly under zero-shot domain transfer
scenarios such as Solidity and XLCoST datasets. These results demonstrate the
effectiveness of explicit logical alignment via pseudo-code and highlight
PseudoBridge's potential as a robust, generalizable solution for code
retrieval.

</details>


### [155] [Designing for Novice Debuggers: A Pilot Study on an AI-Assisted Debugging Tool](https://arxiv.org/abs/2509.21067)
*Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel*

Main category: cs.SE

TL;DR: CodeHinter结合传统与LLM技术，帮助学生主动调试，效果显著且易用。


<details>
  <summary>Details</summary>
Motivation: 现有工具过度依赖AI，未能积极引导学生参与调试过程。

Method: 结合传统调试工具与基于LLM的技术，设计直观调试助手CodeHinter。

Result: 学生认为该工具在解决语义错误方面非常有效，且比第一版更易用。

Conclusion: 任何AI辅助调试工具都应基于用户画像进行个性化，以优化与学生的互动。

Abstract: Debugging is a fundamental skill that novice programmers must develop.
Numerous tools have been created to assist novice programmers in this process.
Recently, large language models (LLMs) have been integrated with automated
program repair techniques to generate fixes for students' buggy code. However,
many of these tools foster an over-reliance on AI and do not actively engage
students in the debugging process. In this work, we aim to design an intuitive
debugging assistant, CodeHinter, that combines traditional debugging tools with
LLM-based techniques to help novice debuggers fix semantic errors while
promoting active engagement in the debugging process. We present findings from
our second design iteration, which we tested with a group of undergraduate
students. Our results indicate that the students found the tool highly
effective in resolving semantic errors and significantly easier to use than the
first version. Consistent with our previous study, error localization was the
most valuable feature. Finally, we conclude that any AI-assisted debugging tool
should be personalized based on user profiles to optimize their interactions
with students.

</details>


### [156] [An Improved Quantum Software Challenges Classification Approach using Transfer Learning and Explainable AI](https://arxiv.org/abs/2509.21068)
*Nek Dil Khan,Javed Ali Khan,Mobashir Husain,Muhammad Sohail Khan,Arif Ali Khan,Muhammad Azeem Akbar,Shahid Hussain*

Main category: cs.SE

TL;DR: 研究通过分类量子开发者的问题，提出Transformer方法（95%准确率）优于传统方法，并利用SHAP增强可解释性，未来需实证评估。


<details>
  <summary>Details</summary>
Motivation: 量子开发者在优化量子计算和QSE概念时面临挑战，但现有讨论标签多关注技术而非开发者问题。分类这些问题有助于识别常见QSE挑战。

Method: 研究从Q&A平台提取了2829个量子相关标签的问题，通过内容分析和扎根理论分类挑战，并利用ChatGPT验证标注。使用BERT、DistilBERT和RoBERTa等Transformer算法进行分类，并与FNN、CNN和LSTM等传统方法对比。

Result: Transformer方法（BERT、DistilBERT）平均准确率达95%，优于传统D&ML方法（FNN 89%、CNN 86%、LSTM 84%）。SHAP提高了分类透明度。

Conclusion: 量子软件工程（QSE）的研究通过分类量子开发者的问题，揭示了常见挑战，并提出了基于Transformer的分类方法，其准确率显著高于传统深度和机器学习方法。SHAP增强了模型的可解释性。未来需要与实际开发者和供应商进行实证评估。

Abstract: Quantum Software Engineering (QSE) is a research area practiced by tech
firms. Quantum developers face challenges in optimizing quantum computing and
QSE concepts. They use Stack Overflow (SO) to discuss challenges and label
posts with specialized quantum tags, which often refer to technical aspects
rather than developer posts. Categorizing questions based on quantum concepts
can help identify frequent QSE challenges. We conducted studies to classify
questions into various challenges. We extracted 2829 questions from Q&A
platforms using quantum-related tags. Posts were analyzed to identify frequent
challenges and develop a novel grounded theory. Challenges include Tooling,
Theoretical, Learning, Conceptual, Errors, and API Usage. Through content
analysis and grounded theory, discussions were annotated with common challenges
to develop a ground truth dataset. ChatGPT validated human annotations and
resolved disagreements. Fine-tuned transformer algorithms, including BERT,
DistilBERT, and RoBERTa, classified discussions into common challenges. We
achieved an average accuracy of 95% with BERT DistilBERT, compared to
fine-tuned Deep and Machine Learning (D&ML) classifiers, including Feedforward
Neural Networks (FNN), Convolutional Neural Networks (CNN), and Long Short-Term
Memory networks (LSTM), which achieved accuracies of 89%, 86%, and 84%,
respectively. The Transformer-based approach outperforms the D&ML-based
approach with a 6\% increase in accuracy by processing actual discussions,
i.e., without data augmentation. We applied SHAP (SHapley Additive
exPlanations) for model interpretability, revealing how linguistic features
drive predictions and enhancing transparency in classification. These findings
can help quantum vendors and forums better organize discussions for improved
access and readability. However,empirical evaluation studies with actual
developers and vendors are needed.

</details>


### [157] [Fine-Tuning LLMs to Analyze Multiple Dimensions of Code Review: A Maximum Entropy Regulated Long Chain-of-Thought Approach](https://arxiv.org/abs/2509.21170)
*Yongda Yu,Guohao Shi,Xianwei Wu,Haochuan He,XueMing Gu,Qianqian Zhao,Kui Liu,Qiushi Wang,Zhao Tian,Haifeng Shen,Guoping Rong*

Main category: cs.SE

TL;DR: MelcotCR是一种链式思维微调方法，通过结合最大熵建模和预定义推理路径，显著提升LLMs在代码审查中的表现，小模型性能媲美大模型。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在代码审查中的能力受限于训练数据的局限性，无法像人类评审员那样同时分析多维度信息。MelcotCR旨在通过丰富的结构化信息提升LLMs的推理能力。

Method: 提出MelcotCR，一种链式思维（COT）微调方法，结合最大熵（ME）建模原则和预定义推理路径，以解决长COT提示中的上下文丢失和推理逻辑丢失问题。

Result: 在MelcotCR数据集和公开的CodeReviewer数据集上的实验表明，经过MelcotCR微调的14B Qwen2.5模型在代码问题检测和描述的准确性上超越了现有方法，性能接近671B DeepSeek-R1模型。

Conclusion: MelcotCR通过结合最大熵建模原则和预定义推理路径，显著提升了LLMs在代码审查中的多维度分析能力，其性能甚至能与更大的模型如671B DeepSeek-R1相媲美。

Abstract: Large Language Models (LLMs) have shown great potential in supporting
automated code review due to their impressive capabilities in context
understanding and reasoning. However, these capabilities are still limited
compared to human-level cognition because they are heavily influenced by the
training data. Recent research has demonstrated significantly improved
performance through fine-tuning LLMs with code review data. However, compared
to human reviewers who often simultaneously analyze multiple dimensions of code
review to better identify issues, the full potential of these methods is
hampered by the limited or vague information used to fine-tune the models. This
paper contributes MelcotCR, a chain-of-thought (COT) fine-tuning approach that
trains LLMs with an impressive reasoning ability to analyze multiple dimensions
of code review by harnessing long COT techniques to provide rich structured
information. To address context loss and reasoning logic loss issues that
frequently occur when LLMs process long COT prompts, we propose a solution that
combines the Maximum Entropy (ME) modeling principle with pre-defined reasoning
pathways in MelcotCR to enable more effective utilization of in-context
knowledge within long COT prompts while strengthening the logical tightness of
the reasoning process. Empirical evaluations on our curated MelcotCR dataset
and the public CodeReviewer dataset reveal that a low-parameter base model,
such as 14B Qwen2.5, fine-tuned with MelcotCR can surpass state-of-the-art
methods in terms of the accuracy of detecting and describing code issues, with
its performance remarkably on par with that of the 671B DeepSeek-R1 model.

</details>


### [158] [Semantic Clustering of Civic Proposals: A Case Study on Brazil's National Participation Platform](https://arxiv.org/abs/2509.21292)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 提出一种结合BERTopic和种子词的方法，自动分类大量公民参与内容，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 解决数字平台上大量公民参与内容难以分类和利用的问题。

Method: 结合BERTopic与种子词，并利用大型语言模型进行自动验证。

Result: 生成的主题连贯且与官方分类一致，仅需少量人工努力。

Conclusion: 该方法能有效将大量公民意见转化为可操作的公共政策数据，减少人工干预。

Abstract: Promoting participation on digital platforms such as Brasil Participativo has
emerged as a top priority for governments worldwide. However, due to the sheer
volume of contributions, much of this engagement goes underutilized, as
organizing it presents significant challenges: (1) manual classification is
unfeasible at scale; (2) expert involvement is required; and (3) alignment with
official taxonomies is necessary. In this paper, we introduce an approach that
combines BERTopic with seed words and automatic validation by large language
models. Initial results indicate that the generated topics are coherent and
institutionally aligned, with minimal human effort. This methodology enables
governments to transform large volumes of citizen input into actionable data
for public policy.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [159] [FZModules: A Heterogeneous Computing Framework for Customizable Scientific Data Compression Pipelines](https://arxiv.org/abs/2509.20563)
*Skyler Ruiter,Jiannan Tian,Fengguang Song*

Main category: cs.DC

TL;DR: FZModules是一个异构框架，通过高性能模块和异步任务执行库，支持快速构建自定义压缩流水线，实现与GPU压缩器相当的速度和与CPU压缩器相似的速率-失真性能。


<details>
  <summary>Details</summary>
Motivation: 现代科学仿真和仪器生成的数据量超过了内存和存储的承载能力，限制了可扩展性。有损压缩通过牺牲可控误差来减少存储占用和提高吞吐量，但最优流水线高度依赖数据和目标，需要压缩专业知识。GPU压缩器提供原始吞吐量，但通常硬编码融合内核，阻碍快速实验，且在速率-失真表现不佳。

Method: FZModules是一个异构框架，通过简洁可扩展的接口组装高性能模块，构建自定义压缩流水线。该框架利用异步任务执行库推断数据依赖、管理内存移动，并暴露分支和阶段级并发，以实现强大的异步压缩流水线。

Result: 在四个代表性科学数据集上评估了三个使用FZModules构建的流水线，结果显示它们能够达到与融合内核GPU压缩器相当的端到端加速，同时实现与高保真CPU或混合压缩器相似的速率-失真性能。

Conclusion: FZModules框架通过其高性能模块和异步任务执行库，能够在不牺牲速率-失真的情况下，实现与融合内核GPU压缩器相当的速度提升，同时保持与高保真CPU或混合压缩器相似的性能，从而支持快速、领域定制的设计。

Abstract: Modern scientific simulations and instruments generate data volumes that
overwhelm memory and storage, throttling scalability. Lossy compression
mitigates this by trading controlled error for reduced footprint and throughput
gains, yet optimal pipelines are highly data and objective specific, demanding
compression expertise. GPU compressors supply raw throughput but often
hard-code fused kernels that hinder rapid experimentation, and underperform in
rate-distortion. We present FZModules, a heterogeneous framework for assembling
error-bounded custom compression pipelines from high-performance modules
through a concise extensible interface. We further utilize an asynchronous
task-backed execution library that infers data dependencies, manages memory
movement, and exposes branch and stage level concurrency for powerful
asynchronous compression pipelines. Evaluating three pipelines built with
FZModules on four representative scientific datasets, we show they can compare
end-to-end speedup of fused-kernel GPU compressors while achieving similar
rate-distortion to higher fidelity CPU or hybrid compressors, enabling rapid,
domain-tailored design.

</details>


### [160] [Experience Deploying Containerized GenAI Services at an HPC Center](https://arxiv.org/abs/2509.20603)
*Angel M. Beltre,Jeff Ogden,Kevin Pedretti*

Main category: cs.DC

TL;DR: 论文分享了在HPC中心部署GenAI工作负载的经验，提出融合HPC和Kubernetes的架构，并通过案例验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 探讨在HPC中心部署GenAI工作负载的可行性和挑战，弥补HPC环境中容器化能力不足的问题。

Method: 采用融合计算架构，整合HPC和Kubernetes平台，运行容器化的GenAI工作负载，并通过案例研究展示了Llama大型语言模型的部署。

Result: 成功部署了容器化的GenAI工作负载，验证了融合架构的可行性，并为HPC容器社区提供了实用建议。

Conclusion: 论文总结了在HPC中心部署GenAI工作负载的经验，提出了融合HPC和云计算环境的架构，并强调了未来研究和工具开发的指导意义。

Abstract: Generative Artificial Intelligence (GenAI) applications are built from
specialized components -- inference servers, object storage, vector and graph
databases, and user interfaces -- interconnected via web-based APIs. While
these components are often containerized and deployed in cloud environments,
such capabilities are still emerging at High-Performance Computing (HPC)
centers. In this paper, we share our experience deploying GenAI workloads
within an established HPC center, discussing the integration of HPC and cloud
computing environments. We describe our converged computing architecture that
integrates HPC and Kubernetes platforms running containerized GenAI workloads,
helping with reproducibility. A case study illustrates the deployment of the
Llama Large Language Model (LLM) using a containerized inference server (vLLM)
across both Kubernetes and HPC platforms using multiple container runtimes. Our
experience highlights practical considerations and opportunities for the HPC
container community, guiding future research and tool development.

</details>


### [161] [Distributed-memory Algorithms for Sparse Matrix Permutation, Extraction, and Assignment](https://arxiv.org/abs/2509.20776)
*Elaheh Hassani,Md Taufique Hussain,Ariful Azad*

Main category: cs.DC

TL;DR: 提出了一种高效的分布式稀疏矩阵操作算法，性能优于现有库，适用于多种应用场景。


<details>
  <summary>Details</summary>
Motivation: 现有的分布式内存库如CombBLAS和PETSc在处理稀疏矩阵操作时存在性能瓶颈，需要更高效的算法来提升性能。

Method: 采用Identify-Exchange-Build (IEB)策略，结合同步自由的多线程算法，减少了通信开销并加速了本地计算。

Result: 实验表明，所提算法在多个应用场景中性能显著优于CombBLAS和PETSc。

Conclusion: 本研究提出了一种高效的分布式内存算法，用于稀疏矩阵的排列、提取和赋值，通过IEB策略和同步自由多线程算法显著提升了性能，并在多个应用场景中验证了其优越性。

Abstract: We present scalable distributed-memory algorithms for sparse matrix
permutation, extraction, and assignment. Our methods follow an
Identify-Exchange-Build (IEB) strategy where each process identifies the local
nonzeros to be sent, exchanges the required data, and then builds its local
submatrix from the received elements. This approach reduces communication
compared to SpGEMM-based methods in distributed memory. By employing
synchronization-free multithreaded algorithms, we further accelerate local
computations, achieving substantially better performance than existing
libraries such as CombBLAS and PETSc. We design efficient software for these
operations and evaluate their performance on two university clusters and the
Perlmutter supercomputer. Our experiments span a variety of application
scenarios, including matrix permutation for load balancing, matrix reordering,
subgraph extraction, and streaming graph applications. In all cases, we compare
our algorithms against CombBLAS, the most comprehensive distributed library for
these operations, and, in some scenarios, against PETSc. Overall, this work
provides a comprehensive study of algorithms, software implementations,
experimental evaluations, and applications for sparse matrix permutation,
extraction, and assignment.

</details>


### [162] [Integrating and Characterizing HPC Task Runtime Systems for hybrid AI-HPC workloads](https://arxiv.org/abs/2509.20819)
*Andre Merzky,Mikhail Titov,Matteo Turilli,Shantenu Jha*

Main category: cs.DC

TL;DR: RP与Flux和Dragon集成显著提升了混合AI-HPC工作负载的任务执行效率和吞吐量，优于传统Slurm的srun。


<details>
  <summary>Details</summary>
Motivation: 科学工作流日益涉及HPC和机器学习任务，但传统启动器如Slurm的srun在并发性和吞吐量上存在限制，无法适应动态和异构的工作负载。

Method: 研究采用合成和生产规模的负载在Frontier上测试RP与Flux和Dragon的集成效果，分析了不同运行时配置下的任务执行特性。

Result: RP+Flux可持续达到930任务/秒，RP+Flux+Dragon超过1,500任务/秒，利用率超过99.6%。相比之下，srun峰值仅为152任务/秒，利用率低于50%。在IMPEACHABLE.v2药物发现项目中，RP+Flux比srun/Slurm缩短了30-60%的完成时间，吞吐量提升了四倍以上。

Conclusion: 通过集成RADICAL-Pilot（RP）与Flux和Dragon，研究展示了一种可扩展的方法，适用于混合AI-HPC工作负载，显著提升了任务执行效率和吞吐量。

Abstract: Scientific workflows increasingly involve both HPC and machine-learning
tasks, combining MPI-based simulations, training, and inference in a single
execution. Launchers such as Slurm's srun constrain concurrency and throughput,
making them unsuitable for dynamic and heterogeneous workloads. We present a
performance study of RADICAL-Pilot (RP) integrated with Flux and Dragon, two
complementary runtime systems that enable hierarchical resource management and
high-throughput function execution. Using synthetic and production-scale
workloads on Frontier, we characterize the task execution properties of RP
across runtime configurations. RP+Flux sustains up to 930 tasks/s, and
RP+Flux+Dragon exceeds 1,500 tasks/s with over 99.6% utilization. In contrast,
srun peaks at 152 tasks/s and degrades with scale, with utilization below 50%.
For IMPECCABLE.v2 drug discovery campaign, RP+Flux reduces makespan by 30-60%
relative to srun/Slurm and increases throughput more than four times on up to
1,024. These results demonstrate hybrid runtime integration in RP as a scalable
approach for hybrid AI-HPC workloads.

</details>


### [163] [RollPacker: Mitigating Long-Tail Rollouts for Fast, Synchronous RL Post-Training](https://arxiv.org/abs/2509.21009)
*Wei Gao,Yuheng Zhao,Dakai An,Tianyuan Wu,Lunxi Cao,Shaopan Xiong,Ju Huang,Weixun Wang,Siran Yang,Wenbo Su,Jiamang Wang,Lin Qu,Bo Zheng,Wei Wang*

Main category: cs.DC

TL;DR: 尾批处理策略通过优化长尾响应的调度，显著提升GPU利用率和RL训练速度，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 同步强化学习在训练大型语言模型时常因响应长度不平衡导致GPU利用率低下（称为气泡问题），现有方法在放松同步性时会牺牲训练准确性。

Method: 引入尾批处理策略，将长尾响应整合到少量指定的长轮次中，同时优化了RL的三个阶段：弹性并行适应、动态资源分配和调度以及基于流的训练。

Result: RollPacker在128个H800 GPU上对Qwen2.5系列LLMs实现了比veRL快2.03x-2.56x、比RLHFuse快2.24x的训练速度提升。

Conclusion: RollPacker通过尾批处理策略显著提高了同步强化学习的训练效率，同时在保持准确性的前提下实现了2.03x-2.56x的端到端训练时间缩短。

Abstract: Reinforcement Learning (RL) is a pivotal post-training technique for
enhancing the reasoning capabilities of Large Language Models (LLMs). However,
synchronous RL post-training often suffers from significant GPU
underutilization, referred to as bubbles, caused by imbalanced response lengths
within rollout steps. Many RL systems attempt to alleviate this problem by
relaxing synchronization, but this can compromise training accuracy. In this
paper, we introduce tail batching, a novel rollout scheduling strategy for
synchronous RL that systematically consolidates prompts leading to long-tail
responses into a small subset of rollout steps (long rounds), while ensuring
that the majority of steps (short rounds) involve only balanced, short
rollouts. By excluding long responses from short rounds and rescheduling them
into a few designated long rounds, tail batching effectively reduces GPU idle
time during rollouts and significantly accelerates RL training without
sacrificing accuracy. We present RollPacker, a system that fully harnesses the
benefits of tail batching through holistic optimizations across all three RL
stages: elastic parallelism adaptation for rollout, dynamic resource allocation
and scheduling for reward, and stream-based training. Empirical results show
that RollPacker achieves a 2.03x-2.56x end-to-end training time reduction
compared to veRL and up to 2.24x speedup compared to RLHFuse for the Qwen2.5
family of LLMs on up to 128 H800 GPUs.

</details>


### [164] [Utilizing Sparsity in the GPU-accelerated Assembly of Schur Complement Matrices in Domain Decomposition Methods](https://arxiv.org/abs/2509.21037)
*Jakub Homola,Ondřej Meca,Lubomír Říha,Tomáš Brzobohatý*

Main category: cs.DC

TL;DR: 通过优化GPU上的Schur补矩阵组装，利用稀疏性，实现了显著加速，适用于FETI方法。


<details>
  <summary>Details</summary>
Motivation: 随着高性能计算集群的性能主要集中在GPU上，需要加速域分解方法中的Schur补矩阵组装，以减少显式组装带来的高开销。

Method: 通过利用输入矩阵的稀疏性优化GPU上的Schur补矩阵组装。

Result: 在FETI方法中，GPU部分代码实现了5.1倍的加速，整体组装实现了3.3倍的加速，从10次迭代开始即可受益。

Conclusion: 通过智能利用输入矩阵的稀疏性，GPU上的Schur补矩阵组装可以进一步优化。在FETI方法中，实现了GPU部分代码5.1倍的加速和整体组装3.3倍的加速，使得从仅10次迭代开始就能受益于这种加速。

Abstract: Schur complement matrices emerge in many domain decomposition methods that
can solve complex engineering problems using supercomputers. Today, as most of
the high-performance clusters' performance lies in GPUs, these methods should
also be accelerated.
  Typically, the offloaded components are the explicitly assembled dense Schur
complement matrices used later in the iterative solver for multiplication with
a vector. As the explicit assembly is expensive, it represents a significant
overhead associated with this approach to acceleration. It has already been
shown that the overhead can be minimized by assembling the Schur complements
directly on the GPU.
  This paper shows that the GPU assembly can be further improved by wisely
utilizing the sparsity of the input matrices. In the context of FETI methods,
we achieved a speedup of 5.1 in the GPU section of the code and 3.3 for the
whole assembly, making the acceleration beneficial from as few as 10
iterations.

</details>


### [165] [Mojo: MLIR-Based Performance-Portable HPC Science Kernels on GPUs for the Python Ecosystem](https://arxiv.org/abs/2509.21039)
*William F. Godoy,Tatiana Melnichenko,Pedro Valero-Lara,Wael Elwasif,Philip Fackler,Rafael Ferreira Da Silva,Keita Teranishi,Jeffrey S. Vetter*

Main category: cs.DC

TL;DR: Mojo语言在GPU科学计算中表现接近CUDA/HIP，尤其擅长内存密集型任务，但在AMD GPU的原子操作和快速数学计算上稍逊，有望填补Python生态的碎片化问题。


<details>
  <summary>Details</summary>
Motivation: 探索基于LLVM MLIR编译器基础设施的新型Mojo语言在科学计算工作负载中的性能和可移植性，旨在通过结合Python的互操作性和类似CUDA的语法，缩小性能与生产力之间的差距。

Method: 研究通过四个科学计算工作负载（七点模板、BabelStream、miniBUDE和Hartree-Fock）在NVIDIA H100和AMD MI300A GPU上的性能测试，对比Mojo与CUDA和HIP的性能表现。

Result: Mojo在内存密集型内核上的性能与CUDA和HIP相当，但在AMD GPU上的原子操作及快速数学计算密集型内核上存在性能差距。

Conclusion: Mojo语言在科学计算工作负载中展现出与CUDA和HIP竞争的性能，尤其在内存密集型任务上表现优异，但在AMD GPU上的原子操作和快速数学计算密集型任务上存在差距。尽管学习曲线和编程要求仍较低级，Mojo有望填补Python生态系统在科学计算与AI融合中的碎片化问题。

Abstract: We explore the performance and portability of the novel Mojo language for
scientific computing workloads on GPUs. As the first language based on the
LLVM's Multi-Level Intermediate Representation (MLIR) compiler infrastructure,
Mojo aims to close performance and productivity gaps by combining Python's
interoperability and CUDA-like syntax for compile-time portable GPU
programming. We target four scientific workloads: a seven-point stencil
(memory-bound), BabelStream (memory-bound), miniBUDE (compute-bound), and
Hartree-Fock (compute-bound with atomic operations); and compare their
performance against vendor baselines on NVIDIA H100 and AMD MI300A GPUs. We
show that Mojo's performance is competitive with CUDA and HIP for memory-bound
kernels, whereas gaps exist on AMD GPUs for atomic operations and for fast-math
compute-bound kernels on both AMD and NVIDIA GPUs. Although the learning curve
and programming requirements are still fairly low-level, Mojo can close
significant gaps in the fragmented Python ecosystem in the convergence of
scientific computing and AI.

</details>


### [166] [From GPUs to RRAMs: Distributed In-Memory Primal-Dual Hybrid Gradient Method for Solving Large-Scale Linear Optimization Problem](https://arxiv.org/abs/2509.21137)
*Huynh Q. N. Vo,Md Tawsif Rahman Chowdhury,Paritosh Ramanan,Gozde Tutuncuoglu,Junchi Yang,Feng Qiu,Murat Yildirim*

Main category: cs.DC

TL;DR: 该论文提出了一种专为RRAM设计的分布式PDHG方法，显著降低能耗和延迟，展示了算法-硬件协同设计的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统架构受限于基本限制，无法满足计算工作负载的指数增长，而内存计算（IMC）与RRAM提供了低延迟和低能耗的替代方案。

Method: 提出了一种分布式内存原始-对偶混合梯度（PDHG）方法，专为RRAM设备阵列设计，最小化昂贵的写入周期，并针对设备非理想性提供鲁棒性。

Result: 与GPU加速求解器相比，基于RRAM的求解器在大规模线性程序上实现了相当的精度，同时能耗和延迟降低了三个数量级。

Conclusion: 该论文展示了首个基于RRAM的PDHG LP求解器，通过算法-硬件协同设计，展示了分布式内存计算在解决大规模优化问题中的变革潜力。

Abstract: The exponential growth of computational workloads is surpassing the
capabilities of conventional architectures, which are constrained by
fundamental limits. In-memory computing (IMC) with RRAM provides a promising
alternative by providing analog computations with significant gains in latency
and energy use. However, existing algorithms developed for conventional
architectures do not translate to IMC, particularly for constrained
optimization problems where frequent matrix reprogramming remains
cost-prohibitive for IMC applications. Here we present a distributed in-memory
primal-dual hybrid gradient (PDHG) method, specifically co-designed for arrays
of RRAM devices. Our approach minimizes costly write cycles, incorporates
robustness against device non-idealities, and leverages a symmetric
block-matrix formulation to unify operations across distributed crossbars. We
integrate a physics-based simulation framework called MELISO+ to evaluate
performance under realistic device conditions. Benchmarking against
GPU-accelerated solvers on large-scale linear programs demonstrates that our
RRAM-based solver achieves comparable accuracy with up to three orders of
magnitude reductions in energy consumption and latency. These results
demonstrate the first PDHG-based LP solver implemented on RRAMs, showcasing the
transformative potential of algorithm-hardware co-design for solving
large-scale optimization through distributed in-memory computing.

</details>


### [167] [Data-Centric Elastic Pipeline Parallelism for Efficient Long-Context LLM Training](https://arxiv.org/abs/2509.21275)
*Shiju Wang,Yujie Wang,Ao Sun,Fangcheng Fu,Zijian Zhu,Bin Cui,Xu Han,Kaisheng Ma*

Main category: cs.DC

TL;DR: 提出弹性管道并行（EPP）和InfiniPipe系统，通过动态调整并行粒度和联合优化，显著提升长上下文训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长上下文训练中存在通信开销大、内存消耗高或硬件利用率低的问题，且静态调度忽略了序列长度分布的偏斜性。

Method: 提出了弹性管道并行（EPP）和InfiniPipe系统，包括资源感知的序列处理器和联合优化方法。

Result: InfiniPipe在实验中实现了1.69倍的加速。

Conclusion: InfiniPipe通过弹性管道并行（EPP）和资源感知的序列处理器，显著提升了长上下文训练的效率，实现了1.69倍的加速。

Abstract: Long context training is crucial for LLM's context extension. Existing
schemes, such as sequence parallelism, incur substantial communication
overhead. Pipeline parallelism (PP) reduces this cost, but its effectiveness
hinges on partitioning granularity. Batch-level PP dividing input samples
exhibits high memory consumption in long-context scenario, whereas token-level
PP splitting sequences into slices alleviates memory overhead but may incur
hardware under-utilization. This trade-off motivates adaptively selecting PP
granularity to match resource and workload characteristics. Moreover, sequence
length distribution of the real-world dataset exhibits skewness, posing a
challenge on PP's workload balance and efficient scheduling. Current static PP
scheduling methods overlook the variance of sequence length, leading to
suboptimal performance. In this paper, we propose Elastic Pipeline Parallelism
(EPP) that orchestrates token-level PP and batch-level PP to adapt to resource
and workload heterogeneity. We build InfiniPipe, a distributed training system
that unleashes the potential of EPP via (1) a resource-aware and
workload-balanced sequence processor that splits long sequences and packs short
ones; and (2) a co-optimization methodology that jointly optimizes pipeline
schedule and gradient checkpointing via a mechanism named stage-aware
chunk-level adaptive checkpointing. Comprehensive experiments demonstrate that
InfiniPipe achieves a 1.69x speedup over state-of-the-art systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [168] [Boosting LiDAR-Based Localization with Semantic Insight: Camera Projection versus Direct LiDAR Segmentation](https://arxiv.org/abs/2509.20486)
*Sven Ochs,Philip Schörner,Marc René Zofka,J. Marius Zöllner*

Main category: cs.RO

TL;DR: 提出了一种结合语义相机和LiDAR分割的方法，显著提升了LiDAR定位的精度和可靠性，适用于复杂环境。


<details>
  <summary>Details</summary>
Motivation: LiDAR数据的语义分割在处理多样化传感器类型和配置时存在挑战，但语义信息的融入可以显著提升LiDAR定位技术的准确性和鲁棒性。

Method: 提出了一种将LiDAR点投影到相机语义分割空间的方法，结合Depth-Anything网络和自适应分割网络进行验证。

Result: 在55公里的多样化环境测试中，该方法展示了其在复杂现实环境中的可靠性和精确性。

Conclusion: 通过整合语义相机数据和LiDAR分割，该方法显著提高了LiDAR定位的精度和可靠性，为复杂现实环境中的自主导航系统提供了更可靠的解决方案。

Abstract: Semantic segmentation of LiDAR data presents considerable challenges,
particularly when dealing with diverse sensor types and configurations.
However, incorporating semantic information can significantly enhance the
accuracy and robustness of LiDAR-based localization techniques for autonomous
mobile systems. We propose an approach that integrates semantic camera data
with LiDAR segmentation to address this challenge. By projecting LiDAR points
into the semantic segmentation space of the camera, our method enhances the
precision and reliability of the LiDAR-based localization pipeline.
  For validation, we utilize the CoCar NextGen platform from the FZI Research
Center for Information Technology, which offers diverse sensor modalities and
configurations. The sensor setup of CoCar NextGen enables a thorough analysis
of different sensor types. Our evaluation leverages the state-of-the-art
Depth-Anything network for camera image segmentation and an adaptive
segmentation network for LiDAR segmentation. To establish a reliable ground
truth for LiDAR-based localization, we make us of a Global Navigation Satellite
System (GNSS) solution with Real-Time Kinematic corrections (RTK).
Additionally, we conduct an extensive 55 km drive through the city of
Karlsruhe, Germany, covering a variety of environments, including urban areas,
multi-lane roads, and rural highways. This multimodal approach paves the way
for more reliable and precise autonomous navigation systems, particularly in
complex real-world environments.

</details>


### [169] [Revisiting Formal Methods for Autonomous Robots: A Structured Survey](https://arxiv.org/abs/2509.20488)
*Atef Azaiez,David A. Anisi,Marie Farrell,Matt Luckcuck*

Main category: cs.RO

TL;DR: 该论文通过结构化文献综述分析了形式方法在机器人自主系统中的应用趋势，揭示了新研究方向，如形式综合和概率验证技术的增加。


<details>
  <summary>Details</summary>
Motivation: 研究FM在RAS中的应用趋势，特别是子符号AI驱动的RAS，并探讨FM在这一领域的演变。

Method: 采用结构化调查方法，包括数据库选择、搜索字符串、筛选及协作论文审查，对FM在RAS中的使用进行分类和统计。

Result: 调查发现某些趋势与先前研究一致，同时识别了新趋势，如形式综合方法和概率验证技术的显著增加。

Conclusion: 该论文通过结构化文献综述展示了形式方法（FM）在机器人自主系统（RAS）中的应用趋势，补充了现有研究并揭示了新的研究方向，如形式综合方法和概率验证技术的增加。

Abstract: This paper presents the initial results from our structured literature review
on applications of Formal Methods (FM) to Robotic Autonomous Systems (RAS). We
describe our structured survey methodology; including database selection and
associated search strings, search filters and collaborative review of
identified papers. We categorise and enumerate the FM approaches and formalisms
that have been used for specification and verification of RAS. We investigate
FM in the context of sub-symbolic AI-enabled RAS and examine the evolution of
how FM is used over time in this field. This work complements a pre-existing
survey in this area and we examine how this research area has matured over
time. Specifically, our survey demonstrates that some trends have persisted as
observed in a previous survey. Additionally, it recognized new trends that were
not considered previously including a noticeable increase in adopting Formal
Synthesis approaches as well as Probabilistic Verification Techniques.

</details>


### [170] [Boosting Zero-Shot VLN via Abstract Obstacle Map-Based Waypoint Prediction with TopoGraph-and-VisitInfo-Aware Prompting](https://arxiv.org/abs/2509.20499)
*Boqi Li,Siyuan Li,Weiyi Wang,Anran Li,Zhong Cao,Henry X. Liu*

Main category: cs.RO

TL;DR: 提出零样本框架，结合航点预测器和MLLM，在连续环境中实现高效视觉语言导航，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决连续环境中视觉语言导航（VLN）的挑战，需联合解释自然语言指令、感知环境并规划低级动作。

Method: 整合了简化的航点预测器与多模态大语言模型（MLLM），通过动态更新的拓扑图和显式访问记录进行路径规划和错误纠正。

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的零样本性能。

Conclusion: 该论文提出的零样本框架在连续环境中的视觉语言导航任务上表现出色，成功率达到41%和36%，优于现有方法。

Abstract: With the rapid progress of foundation models and robotics, vision-language
navigation (VLN) has emerged as a key task for embodied agents with broad
practical applications. We address VLN in continuous environments, a
particularly challenging setting where an agent must jointly interpret natural
language instructions, perceive its surroundings, and plan low-level actions.
We propose a zero-shot framework that integrates a simplified yet effective
waypoint predictor with a multimodal large language model (MLLM). The predictor
operates on an abstract obstacle map, producing linearly reachable waypoints,
which are incorporated into a dynamically updated topological graph with
explicit visitation records. The graph and visitation information are encoded
into the prompt, enabling reasoning over both spatial structure and exploration
history to encourage exploration and equip MLLM with local path planning for
error correction. Extensive experiments on R2R-CE and RxR-CE show that our
method achieves state-of-the-art zero-shot performance, with success rates of
41% and 36%, respectively, outperforming prior state-of-the-art methods.

</details>


### [171] [MELEGROS: Monolithic Elephant-inspired Gripper with Optical Sensors](https://arxiv.org/abs/2509.20510)
*Petr Trunin,Diana Cafiso,Anderson Brazil Nardin,Trevor Exley,Lucia Beccai*

Main category: cs.RO

TL;DR: MELEGROS是一种仿象鼻的单片抓取器，集成了光学传感器和气动驱动，展示了软体机器人的多功能仿生操作能力。


<details>
  <summary>Details</summary>
Motivation: 受到非洲象鼻远端形态的启发，旨在开发一种结构、驱动和传感无缝集成的自然抓取器。

Method: MELEGROS采用单一软树脂和连续3D打印技术，将六个光学波导传感器和五个气动腔直接集成到气动驱动晶格结构中。

Result: MELEGROS能够举起超过自身重量两倍的物体，执行仿生动作如捏取、舀取和伸展，并轻柔抓取脆弱物品如葡萄。

Conclusion: MELEGROS展示了软体机器人领域的新范式，通过完全嵌入的传感和连续结构，支持多功能、仿生操作。

Abstract: The elephant trunk exemplifies a natural gripper where structure, actuation,
and sensing are seamlessly integrated. Inspired by the distal morphology of the
African elephant trunk, we present MELEGROS, a Monolithic ELEphant-inspired
GRipper with Optical Sensors, emphasizing sensing as an intrinsic,
co-fabricated capability. Unlike multi-material or tendon-based approaches,
MELEGROS directly integrates six optical waveguide sensors and five pneumatic
chambers into a pneumatically actuated lattice structure (12.5 mm cell size)
using a single soft resin and one continuous 3D print. This eliminates
mechanical mismatches between sensors, actuators, and body, reducing model
uncertainty and enabling simulation-guided sensor design and placement. Only
four iterations were required to achieve the final prototype, which features a
continuous structure capable of elongation, compression, and bending while
decoupling tactile and proprioceptive signals. MELEGROS (132 g) lifts more than
twice its weight, performs bioinspired actions such as pinching, scooping, and
reaching, and delicately grasps fragile items like grapes. The integrated
optical sensors provide distinct responses to touch, bending, and chamber
deformation, enabling multifunctional perception. MELEGROS demonstrates a new
paradigm for soft robotics where fully embedded sensing and continuous
structures inherently support versatile, bioinspired manipulation.

</details>


### [172] [Action-Informed Estimation and Planning: Clearing Clutter on Staircases via Quadrupedal Pedipulation](https://arxiv.org/abs/2509.20516)
*Prasanna Sriganesh,Barath Satheeshkumar,Anushree Sabnis,Matthew Travers*

Main category: cs.RO

TL;DR: 本文提出了一种交互感知状态估计方法，通过本体感受反馈解决四足机器人在推动物体时的遮挡问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 在密集杂乱环境中，四足机器人需通过物理交互清理路径，但单腿推动等紧密耦合动作可能导致物体被遮挡，难以预测其位移。

Method: 提出了一种紧密耦合的感知-动作框架，包括交互感知状态估计循环，利用本体感受反馈（如足部接触和腿部位置）预测物体在遮挡期间的位移。

Result: 在波士顿动力Spot机器人上的实验表明，该方法相比开环基线在楼梯上推动物体时具有更高的任务成功率和跟踪准确性。

Conclusion: 本文提出的交互感知状态估计循环通过本体感受反馈有效解决了四足机器人在推动物体时因遮挡导致的跟踪问题，显著提高了任务成功率和跟踪准确性。

Abstract: For robots to operate autonomously in densely cluttered environments, they
must reason about and potentially physically interact with obstacles to clear a
path. Safely clearing a path on challenging terrain, such as a cluttered
staircase, requires controlled interaction. For example, a quadrupedal robot
that pushes objects out of the way with one leg while maintaining a stable
stance with its three other legs. However, tightly coupled physical actions,
such as one-legged pushing, create new constraints on the system that can be
difficult to predict at design time. In this work, we present a new method that
addresses one such constraint, wherein the object being pushed by a quadrupedal
robot with one of its legs becomes occluded from the robot's sensors during
manipulation. To address this challenge, we present a tightly coupled
perception-action framework that enables the robot to perceive clutter, reason
about feasible push paths, and execute the clearing maneuver. Our core
contribution is an interaction-aware state estimation loop that uses
proprioceptive feedback regarding foot contact and leg position to predict an
object's displacement during the occlusion. This prediction guides the
perception system to robustly re-detect the object after the interaction,
closing the loop between action and sensing to enable accurate tracking even
after partial pushes. Using this feedback allows the robot to learn from
physical outcomes, reclassifying an object as immovable if a push fails due to
it being too heavy. We present results of implementing our approach on a Boston
Dynamics Spot robot that show our interaction-aware approach achieves higher
task success rates and tracking accuracy in pushing objects on stairs compared
to open-loop baselines.

</details>


### [173] [Selective Progress-Aware Querying for Human-in-the-Loop Reinforcement Learning](https://arxiv.org/abs/2509.20541)
*Anujith Muraleedharan,Anamika J H*

Main category: cs.RO

TL;DR: SPARQ是一种进度感知查询策略，仅在需要时请求人类反馈，显著减少反馈成本，同时保持高效学习性能。


<details>
  <summary>Details</summary>
Motivation: 现实环境中的人类反馈成本高且有限，现有HiL-RL方法假设反馈充足，限制了其在物理机器人部署中的实用性。

Method: 引入SPARQ，一种进度感知查询策略，仅在学习停滞或恶化时请求反馈。在PyBullet中模拟UR5立方体拾取任务，并与三种基线方法（无反馈、随机查询和始终查询）进行比较。

Result: SPARQ实现了接近完美的任务成功率，与始终查询性能相当，但仅消耗约一半的反馈预算。相比随机查询，它提供了更稳定和高效的学习效果，且显著优于无反馈训练。

Conclusion: 选择性、基于进度的查询策略（如SPARQ）可以使HiL-RL在现实人类努力约束下更高效和可扩展。

Abstract: Human feedback can greatly accelerate robot learning, but in real-world
settings, such feedback is costly and limited. Existing human-in-the-loop
reinforcement learning (HiL-RL) methods often assume abundant feedback,
limiting their practicality for physical robot deployment. In this work, we
introduce SPARQ, a progress-aware query policy that requests feedback only when
learning stagnates or worsens, thereby reducing unnecessary oracle calls. We
evaluate SPARQ on a simulated UR5 cube-picking task in PyBullet, comparing
against three baselines: no feedback, random querying, and always querying. Our
experiments show that SPARQ achieves near-perfect task success, matching the
performance of always querying while consuming about half the feedback budget.
It also provides more stable and efficient learning than random querying, and
significantly improves over training without feedback. These findings suggest
that selective, progress-based query strategies can make HiL-RL more efficient
and scalable for robots operating under realistic human effort constraints.

</details>


### [174] [GraspFactory: A Large Object-Centric Grasping Dataset](https://arxiv.org/abs/2509.20550)
*Srinidhi Kalgundi Srinivas,Yash Shukla,Adam Arnold,Sachin Chitta*

Main category: cs.RO

TL;DR: GraspFactory数据集提供1.09亿抓取数据，提升机器人抓取泛化能力，验证有效。


<details>
  <summary>Details</summary>
Motivation: 工业自动化中机器人需处理多样化物体，但现有模型因训练数据有限而难以泛化到新物体。

Method: 引入GraspFactory数据集，包含Franka Panda和Robotiq 2F-85夹爪的1.09亿个6-DoF抓取数据，用于训练数据密集型模型。

Result: 在仿真和现实环境中验证了基于GraspFactory训练的模型的泛化能力。

Conclusion: GraspFactory数据集通过提供超过1.09亿个6-DoF抓取数据，显著提升了机器人抓取模型的泛化能力，并在仿真和现实环境中验证了其有效性。

Abstract: Robotic grasping is a crucial task in industrial automation, where robots are
increasingly expected to handle a wide range of objects. However, a significant
challenge arises when robot grasping models trained on limited datasets
encounter novel objects. In real-world environments such as warehouses or
manufacturing plants, the diversity of objects can be vast, and grasping models
need to generalize to this diversity. Training large, generalizable
robot-grasping models requires geometrically diverse datasets. In this paper,
we introduce GraspFactory, a dataset containing over 109 million 6-DoF grasps
collectively for the Franka Panda (with 14,690 objects) and Robotiq 2F-85
grippers (with 33,710 objects). GraspFactory is designed for training
data-intensive models, and we demonstrate the generalization capabilities of
one such model trained on a subset of GraspFactory in both simulated and
real-world settings. The dataset and tools are made available for download at
https://graspfactory.github.io/.

</details>


### [175] [Uncertainty-Aware Active Source Tracking of Marine Pollution using Unmanned Surface Vehicles](https://arxiv.org/abs/2509.20593)
*Song Ma,Richard Bucknall,Yuanchang Liu*

Main category: cs.RO

TL;DR: 该论文提出了一种基于USV的不确定性感知污染源追踪框架，结合模拟与路径规划技术，实验证明其能高效准确识别污染源。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够自主、高效地识别海洋污染源的技术，以支持快速响应海洋污染事件，提升环境监测能力。

Method: 通过将高保真海洋污染扩散模拟与信息路径规划技术相结合，基于机器人操作系统（ROS）实时处理传感器数据，更新污染源位置的概率估计，并逐步优化定位结果。

Result: 实验结果表明，该框架能够在不同污染源位置、流动条件和起始位置下，高效且准确地定位污染源。

Conclusion: 该论文提出了一个不确定性感知的海洋污染源追踪框架，为无人水面车辆（USVs）提供了高效的环境监测能力，对于快速响应海洋污染事件具有重要意义。

Abstract: This paper proposes an uncertainty-aware marine pollution source tracking
framework for unmanned surface vehicles (USVs). By integrating high-fidelity
marine pollution dispersion simulation with informative path planning
techniques, we demonstrate effective identification of pollution sources in
marine environments. The proposed approach is implemented based on Robot
Operating System (ROS), processing real-time sensor data to update
probabilistic source location estimates. The system progressively refines the
estimation of source location while quantifying uncertainty levels in its
predictions. Experiments conducted in simulated environments with varying
source locations, flow conditions, and starting positions demonstrate the
framework's ability to localise pollution sources with high accuracy. Results
show that the proposed approach achieves reliable source localisation
efficiently. This work contributes to the development of full autonomous
environmental monitoring capabilities essential for rapid response to marine
pollution incidents.

</details>


### [176] [Flight Dynamics to Sensing Modalities: Exploiting Drone Ground Effect for Accurate Edge Detection](https://arxiv.org/abs/2509.21085)
*Chenyu Zhao,Jingao Xu,Ciyu Ruan,Haoyang Wang,Shengbo Wang,Jiaqi Li,Jirong Zha,Weijie Hong,Zheng Yang,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.RO

TL;DR: AirTouch利用地面效应作为新的感知模态，通过分析无人机传感器数据实现高效边缘检测，性能优于传统方法且功耗极低。


<details>
  <summary>Details</summary>
Motivation: 当前基于雷达或摄像头的方法部署成本高且计算需求大，不利于轻量级无人机。AirTouch旨在利用地面效应作为新的感知模态，实现资源高效且准确的边缘检测。

Method: 通过理论分析、算法设计和实现，利用无人机基本姿态传感器读数和飞行命令来检测地面效应变化，从而识别材料边界。

Result: 系统检测精度高，平均检测距离误差为0.051米，比基线方法性能提升86%，功耗仅为43 mW。

Conclusion: AirTouch系统通过将地面效应转化为新的感知模态，实现了高效、准确的场景边缘检测，且不牺牲飞行稳定性，为低成本高效的边缘检测提供了新方法。

Abstract: Drone-based rapid and accurate environmental edge detection is highly
advantageous for tasks such as disaster relief and autonomous navigation.
Current methods, using radars or cameras, raise deployment costs and burden
lightweight drones with high computational demands. In this paper, we propose
AirTouch, a system that transforms the ground effect from a stability "foe" in
traditional flight control views, into a "friend" for accurate and efficient
edge detection. Our key insight is that analyzing drone basic attitude sensor
readings and flight commands allows us to detect ground effect changes. Such
changes typically indicate the drone flying over a boundary of two materials,
making this information valuable for edge detection. We approach this insight
through theoretical analysis, algorithm design, and implementation, fully
leveraging the ground effect as a new sensing modality without compromising
drone flight stability, thereby achieving accurate and efficient scene edge
detection. We also compare this new sensing modality with vision-based methods
to clarify its exclusive advantages in resource efficiency and detection
capability. Extensive evaluations demonstrate that our system achieves a high
detection accuracy with mean detection distance errors of 0.051m, outperforming
the baseline method performance by 86%. With such detection performance, our
system requires only 43 mW power consumption, contributing to this new sensing
modality for low-cost and highly efficient edge detection.

</details>


### [177] [Latent Activation Editing: Inference-Time Refinement of Learned Policies for Safer Multirobot Navigation](https://arxiv.org/abs/2509.20623)
*Satyajeet Das,Darren Chiu,Zhehui Huang,Lars Lindemann,Gaurav S. Sukhatme*

Main category: cs.RO

TL;DR: LAE框架通过在线监控和编辑预训练策略的中间激活，在不修改权重或架构的情况下提升多四旋翼导航的安全性，减少碰撞同时保持任务完成。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在多四旋翼协调和导航等复杂领域取得了显著进展，但训练良好的策略在障碍物密集环境中仍容易发生碰撞。通过再训练或微调解决这些罕见但关键的安全故障成本高昂，且可能损害已学技能。

Method: LAE框架分为两个阶段：(i)在线分类器监控中间激活以检测与不良行为相关的状态，(ii)激活编辑模块选择性修改标记的激活，将策略转向更安全的模式。

Result: 仿真和真实世界的实验表明，LAE显著减少了碰撞（与未编辑基线相比，累计碰撞减少近90%），并大幅增加了无碰撞轨迹的比例，同时保持任务完成率。

Conclusion: LAE作为一种轻量级范式，能够在资源受限的硬件上实现对预训练机器人策略的部署后优化，显著减少碰撞并保持任务完成率。

Abstract: Reinforcement learning has enabled significant progress in complex domains
such as coordinating and navigating multiple quadrotors. However, even
well-trained policies remain vulnerable to collisions in obstacle-rich
environments. Addressing these infrequent but critical safety failures through
retraining or fine-tuning is costly and risks degrading previously learned
skills. Inspired by activation steering in large language models and latent
editing in computer vision, we introduce a framework for inference-time Latent
Activation Editing (LAE) that refines the behavior of pre-trained policies
without modifying their weights or architecture. The framework operates in two
stages: (i) an online classifier monitors intermediate activations to detect
states associated with undesired behaviors, and (ii) an activation editing
module that selectively modifies flagged activations to shift the policy
towards safer regimes. In this work, we focus on improving safety in
multi-quadrotor navigation. We hypothesize that amplifying a policy's internal
perception of risk can induce safer behaviors. We instantiate this idea through
a latent collision world model trained to predict future pre-collision
activations, thereby prompting earlier and more cautious avoidance responses.
Extensive simulations and real-world Crazyflie experiments demonstrate that LAE
achieves statistically significant reduction in collisions (nearly 90% fewer
cumulative collisions compared to the unedited baseline) and substantially
increases the fraction of collision-free trajectories, while preserving task
completion. More broadly, our results establish LAE as a lightweight paradigm,
feasible on resource-constrained hardware, for post-deployment refinement of
learned robot policies.

</details>


### [178] [Learning Terrain-Specialized Policies for Adaptive Locomotion in Challenging Environments](https://arxiv.org/abs/2509.20635)
*Matheus P. Angarola,Francisco Affonso,Marcelo Becker*

Main category: cs.RO

TL;DR: 论文提出了一种分层强化学习框架，通过地形专用策略和课程学习，显著提高了腿式机器人在复杂地形上的运动性能，特别是在低摩擦和不连续地形上表现优异。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人在无地形信息的盲运动设置下，需要在多样化的非结构化地形上展现出强大且敏捷的运动能力，这是当前面临的主要挑战。

Method: 论文采用了一种分层强化学习框架，结合地形专用策略和课程学习，以提升机器人在复杂环境中的表现。

Result: 实验结果表明，该方法在模拟环境中比通用策略的成功率提高了16%，并且在速度目标增加时跟踪误差更低，特别是在低摩擦和不连续地形上表现更优。

Conclusion: 该论文的结论是分层强化学习框架在复杂环境中显著提高了腿式机器人的敏捷性和跟踪性能，特别是在低摩擦和不连续地形上表现出更强的适应性和鲁棒性。

Abstract: Legged robots must exhibit robust and agile locomotion across diverse,
unstructured terrains, a challenge exacerbated under blind locomotion settings
where terrain information is unavailable. This work introduces a hierarchical
reinforcement learning framework that leverages terrain-specialized policies
and curriculum learning to enhance agility and tracking performance in complex
environments. We validated our method on simulation, where our approach
outperforms a generalist policy by up to 16% in success rate and achieves lower
tracking errors as the velocity target increases, particularly on low-friction
and discontinuous terrains, demonstrating superior adaptability and robustness
across mixed-terrain scenarios.

</details>


### [179] [Suction Leap-Hand: Suction Cups on a Multi-fingered Hand Enable Embodied Dexterity and In-Hand Teleoperation](https://arxiv.org/abs/2509.20646)
*Sun Zhaole,Xiaofeng Mao,Jihong Zhu,Yuanlong Zhang,Robert B. Fisher*

Main category: cs.RO

TL;DR: 提出非拟人化机械手SLeap Hand，通过吸附简化操作并扩展能力。


<details>
  <summary>Details</summary>
Motivation: 传统拟人化方法限制了机器人能力，且使基于学习的方法数据收集困难。

Method: 引入了SLeap Hand，一种多指机械手，集成了指尖吸盘，实现了基于吸附的新型灵巧操作。

Result: SLeap Hand简化了手内遥操作，实现了高质量演示数据收集，并解锁了人类手难以完成的新技能。

Conclusion: 通过超越拟人化限制，新型机械手设计不仅降低了收集稳健操作数据的门槛，还能实现稳定、单手完成通常需要双手的人类任务。

Abstract: Dexterous in-hand manipulation remains a foundational challenge in robotics,
with progress often constrained by the prevailing paradigm of imitating the
human hand. This anthropomorphic approach creates two critical barriers: 1) it
limits robotic capabilities to tasks humans can already perform, and 2) it
makes data collection for learning-based methods exceedingly difficult. Both
challenges are caused by traditional force-closure which requires coordinating
complex, multi-point contacts based on friction, normal force, and gravity to
grasp an object. This makes teleoperated demonstrations unstable and amplifies
the sim-to-real gap for reinforcement learning. In this work, we propose a
paradigm shift: moving away from replicating human mechanics toward the design
of novel robotic embodiments. We introduce the \textbf{S}uction
\textbf{Leap}-Hand (SLeap Hand), a multi-fingered hand featuring integrated
fingertip suction cups that realize a new form of suction-enabled dexterity. By
replacing complex force-closure grasps with stable, single-point adhesion, our
design fundamentally simplifies in-hand teleoperation and facilitates the
collection of high-quality demonstration data. More importantly, this
suction-based embodiment unlocks a new class of dexterous skills that are
difficult or even impossible for the human hand, such as one-handed paper
cutting and in-hand writing. Our work demonstrates that by moving beyond
anthropomorphic constraints, novel embodiments can not only lower the barrier
for collecting robust manipulation data but also enable the stable,
single-handed completion of tasks that would typically require two human hands.
Our webpage is https://sites.google.com/view/sleaphand.

</details>


### [180] [Cyber Racing Coach: A Haptic Shared Control Framework for Teaching Advanced Driving Skills](https://arxiv.org/abs/2509.20653)
*Congkai Shen,Siyuan Yu,Yifan Weng,Haoran Ma,Chen Li,Hiroshi Yasuda,James Dallas,Michael Thompson,John Subosits,Tulga Ersal*

Main category: cs.RO

TL;DR: 该研究开发了一种触觉共享控制框架，用于帮助人类驾驶员学习高性能驾驶技能，结果显示其效果优于无辅助和全辅助训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有共享控制方案虽在性能和安全性上有优势，但未评估其对复杂任务技能获取的影响。本研究旨在填补这一空白，评估触觉共享控制在帮助人类驾驶员掌握高性能驾驶技能方面的效果。

Method: 研究构建了一个基于触觉共享控制范式的虚拟赛车教练框架，包括（1）能与人类在高度性能驾驶场景中协作的自动驾驶系统；（2）触觉共享控制机制及基于驾驶员表现逐步减少自主转向辅助的渐退方案。

Result: 人类受试者研究表明，该框架帮助驾驶员发展出比无辅助和全辅助基准更优的赛车技能，表现为更好的性能和一致性。

Conclusion: 该研究提出的触觉共享控制框架能有效帮助人类驾驶员在训练中掌握高性能驾驶技能，相较于无辅助和全辅助基准，表现出更优的性能和一致性。

Abstract: This study introduces a haptic shared control framework designed to teach
human drivers advanced driving skills. In this context, shared control refers
to a driving mode where the human driver collaborates with an autonomous
driving system to control the steering of a vehicle simultaneously. Advanced
driving skills are those necessary to safely push the vehicle to its handling
limits in high-performance driving such as racing and emergency obstacle
avoidance. Previous research has demonstrated the performance and safety
benefits of shared control schemes using both subjective and objective
evaluations. However, these schemes have not been assessed for their impact on
skill acquisition on complex and demanding tasks. Prior research on long-term
skill acquisition either applies haptic shared control to simple tasks or
employs other feedback methods like visual and auditory aids. To bridge this
gap, this study creates a cyber racing coach framework based on the haptic
shared control paradigm and evaluates its performance in helping human drivers
acquire high-performance driving skills. The framework introduces (1) an
autonomous driving system that is capable of cooperating with humans in a
highly performant driving scenario; and (2) a haptic shared control mechanism
along with a fading scheme to gradually reduce the steering assistance from
autonomy based on the human driver's performance during training. Two
benchmarks are considered: self-learning (no assistance) and full assistance
during training. Results from a human subject study indicate that the proposed
framework helps human drivers develop superior racing skills compared to the
benchmarks, resulting in better performance and consistency.

</details>


### [181] [EEG-Driven AR-Robot System for Zero-Touch Grasping Manipulation](https://arxiv.org/abs/2509.20656)
*Junzhe Wang,Jiarui Xie,Pengfei Hao,Zheng Li,Yi Cai*

Main category: cs.RO

TL;DR: 提出闭环BCI-AR-Robot系统，结合EEG解码、AR反馈和机器人抓取，显著提升控制稳定性和抓取成功率，推动辅助机器人应用。


<details>
  <summary>Details</summary>
Motivation: 现有BCI-机器人系统存在信号噪声大、目标选择不灵活、缺乏闭环验证等问题，阻碍了其在现实辅助场景中的实际应用。

Method: 提出了一种闭环BCI-AR-Robot系统，整合了基于运动想象的EEG解码、增强现实（AR）神经反馈和机器人抓取技术，实现了零接触操作。

Result: MI训练达到93.1%准确率，ITR为14.8 bit/min；AR神经反馈显著提升控制稳定性（SCI=0.210），最高ITR达21.3 bit/min；闭环抓取成功率为97.2%。

Conclusion: AR反馈显著稳定了基于EEG的控制，所提出的框架实现了稳健的零接触抓取，推动了辅助机器人应用和未来人机交互模式的发展。

Abstract: Reliable brain-computer interface (BCI) control of robots provides an
intuitive and accessible means of human-robot interaction, particularly
valuable for individuals with motor impairments. However, existing BCI-Robot
systems face major limitations: electroencephalography (EEG) signals are noisy
and unstable, target selection is often predefined and inflexible, and most
studies remain restricted to simulation without closed-loop validation. These
issues hinder real-world deployment in assistive scenarios. To address them, we
propose a closed-loop BCI-AR-Robot system that integrates motor imagery
(MI)-based EEG decoding, augmented reality (AR) neurofeedback, and robotic
grasping for zero-touch operation. A 14-channel EEG headset enabled
individualized MI calibration, a smartphone-based AR interface supported
multi-target navigation with direction-congruent feedback to enhance stability,
and the robotic arm combined decision outputs with vision-based pose estimation
for autonomous grasping. Experiments are conducted to validate the framework:
MI training achieved 93.1 percent accuracy with an average information transfer
rate (ITR) of 14.8 bit/min; AR neurofeedback significantly improved sustained
control (SCI = 0.210) and achieved the highest ITR (21.3 bit/min) compared with
static, sham, and no-AR baselines; and closed-loop grasping achieved a 97.2
percent success rate with good efficiency and strong user-reported control.
These results show that AR feedback substantially stabilizes EEG-based control
and that the proposed framework enables robust zero-touch grasping, advancing
assistive robotic applications and future modes of human-robot interaction.

</details>


### [182] [Equi-RO: A 4D mmWave Radar Odometry via Equivariant Networks](https://arxiv.org/abs/2509.20674)
*Zeyu Han,Shuocheng Yang,Minghan Zhu,Fang Zhang,Shaobing Xu,Maani Ghaffari,Jianqiang Wang*

Main category: cs.RO

TL;DR: Equi-RO是一种基于等变网络的4D雷达里程计框架，通过图结构处理稀疏雷达数据，显著提升了里程计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GPS失效环境中，自动驾驶车辆和机器人需要精确的里程计估计。LiDAR和相机在极端天气下表现不佳，而4D毫米波雷达因其全天候操作能力和速度测量成为可靠替代方案。

Method: 提出Equi-RO，一种基于等变网络的4D雷达里程计框架，通过预处理多普勒速度为图中的不变节点和边特征，并采用独立网络处理等变和不变特征。图结构架构增强了稀疏雷达数据中的特征聚合。

Result: 在公开数据集和自收集数据集上的实验表明，Equi-RO在准确性和鲁棒性上优于现有最先进算法。

Conclusion: Equi-RO框架在4D雷达里程计中表现出色，相比现有最佳基线，在公开数据集上实现了10.7%的平移准确性和20.0%的旋转准确性的相对提升。

Abstract: Autonomous vehicles and robots rely on accurate odometry estimation in
GPS-denied environments. While LiDARs and cameras struggle under extreme
weather, 4D mmWave radar emerges as a robust alternative with all-weather
operability and velocity measurement. In this paper, we introduce Equi-RO, an
equivariant network-based framework for 4D radar odometry. Our algorithm
pre-processes Doppler velocity into invariant node and edge features in the
graph, and employs separate networks for equivariant and invariant feature
processing. A graph-based architecture enhances feature aggregation in sparse
radar data, improving inter-frame correspondence. Experiments on the
open-source dataset and self-collected dataset show Equi-RO outperforms
state-of-the-art algorithms in accuracy and robustness. Overall, our method
achieves 10.7% and 20.0% relative improvements in translation and rotation
accuracy, respectively, compared to the best baseline on the open-source
dataset.

</details>


### [183] [Efficient Construction of Implicit Surface Models From a Single Image for Motion Generation](https://arxiv.org/abs/2509.20681)
*Wei-Teng Chu,Tianyi Zhang,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: FINS是一种高效的单图像神经表面重建框架，整合哈希网格编码器和轻量级头，显著提升训练速度和准确性，适用于机器人任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有隐式表面重建方法（如NeuS）需要多视图图像输入和长训练时间的问题，探索单图像神经表面重建的可行性。

Method: FINS采用多分辨率哈希网格编码器和轻量级几何与颜色头，结合预训练基础模型估计图像几何信息，通过近似二阶优化器实现高效训练。

Result: FINS在相同条件下优于现有基线方法，在收敛速度和表面重建/SDF场估计准确性上表现更优，并适用于多种基准数据集和机器人任务。

Conclusion: FINS框架通过整合多分辨率哈希网格编码器和轻量级几何与颜色头，显著提高了单图像神经表面重建的效率与准确性，并在机器人表面跟随任务中展示了其适用性。

Abstract: Implicit representations have been widely applied in robotics for obstacle
avoidance and path planning. In this paper, we explore the problem of
constructing an implicit distance representation from a single image. Past
methods for implicit surface reconstruction, such as \emph{NeuS} and its
variants generally require a large set of multi-view images as input, and
require long training times. In this work, we propose Fast Image-to-Neural
Surface (FINS), a lightweight framework that can reconstruct high-fidelity
surfaces and SDF fields based on a single or a small set of images. FINS
integrates a multi-resolution hash grid encoder with lightweight geometry and
color heads, making the training via an approximate second-order optimizer
highly efficient and capable of converging within a few seconds. Additionally,
we achieve the construction of a neural surface requiring only a single RGB
image, by leveraging pre-trained foundation models to estimate the geometry
inherent in the image. Our experiments demonstrate that under the same
conditions, our method outperforms state-of-the-art baselines in both
convergence speed and accuracy on surface reconstruction and SDF field
estimation. Moreover, we demonstrate the applicability of FINS for robot
surface following tasks and show its scalability to a variety of benchmark
datasets.

</details>


### [184] [RAM-NAS: Resource-aware Multiobjective Neural Architecture Search Method for Robot Vision Tasks](https://arxiv.org/abs/2509.20688)
*Shouren Mao,Minghao Qin,Wei Dong,Huajian Liu,Yongzhuo Gao*

Main category: cs.RO

TL;DR: RAM-NAS是一种资源感知的多目标神经架构搜索方法，通过子网相互蒸馏和延迟代理预测器，优化模型准确率和硬件延迟，适用于机器人边缘硬件。


<details>
  <summary>Details</summary>
Motivation: 传统神经架构搜索方法在训练超网和关注实际机器人硬件资源方面存在不足，需要改进。

Method: 提出RAM-NAS方法，引入子网相互蒸馏概念，使用DKD损失增强logits蒸馏性能，并利用延迟代理预测器加速搜索过程。

Result: RAM-NAS模型在ImageNet上达到76.7%至81.4%的top-1准确率，显著降低边缘硬件推理延迟，并在检测和分割任务中表现优于MobileNetv3。

Conclusion: RAM-NAS填补了神经架构搜索在机器人硬件资源感知方面的空白，显著降低了模型在边缘硬件上的推理延迟，并在下游任务中验证了方法的可扩展性。

Abstract: Neural architecture search (NAS) has shown great promise in automatically
designing lightweight models. However, conventional approaches are insufficient
in training the supernet and pay little attention to actual robot hardware
resources. To meet such challenges, we propose RAM-NAS, a resource-aware
multi-objective NAS method that focuses on improving the supernet pretrain and
resource-awareness on robot hardware devices. We introduce the concept of
subnets mutual distillation, which refers to mutually distilling all subnets
sampled by the sandwich rule. Additionally, we utilize the Decoupled Knowledge
Distillation (DKD) loss to enhance logits distillation performance. To expedite
the search process with consideration for hardware resources, we used data from
three types of robotic edge hardware to train Latency Surrogate predictors.
These predictors facilitated the estimation of hardware inference latency
during the search phase, enabling a unified multi-objective evolutionary search
to balance model accuracy and latency trade-offs. Our discovered model family,
RAM-NAS models, can achieve top-1 accuracy ranging from 76.7% to 81.4% on
ImageNet. In addition, the resource-aware multi-objective NAS we employ
significantly reduces the model's inference latency on edge hardware for
robots. We conducted experiments on downstream tasks to verify the scalability
of our methods. The inference time for detection and segmentation is reduced on
all three hardware types compared to MobileNetv3-based methods. Our work fills
the gap in NAS for robot hardware resource-aware.

</details>


### [185] [Incorporating Human-Inspired Ankle Characteristics in a Forced-Oscillation-Based Reduced-Order Model for Walking](https://arxiv.org/abs/2509.20689)
*Chathura Semasinghe,Siavash Rezazadeh*

Main category: cs.RO

TL;DR: 该论文扩展了带有踝关节和足部的行走模型，展示了其在应对不同大小扰动时的稳定性，有助于理解拟人化行走机制。


<details>
  <summary>Details</summary>
Motivation: 扩展点足模型，以改进步态特性，并探索拟人化行走的稳定机制。

Method: 采用基于强迫振荡的降阶模型，并设计了受人类启发的踝关节动力学范式。

Result: 与点足模型相比，新模型表现出改进的步态特性，并展示了在应对不同大小扰动时的稳定性。

Conclusion: 该论文通过扩展带有踝关节和足部的模型，展示了在初始条件误差较大时结合足部放置和踝关节策略的稳定性，以及在无需依赖足部放置控制的情况下，仅通过设计的本体感受踝关节方案应对小扰动的能力。这一新特性有助于更好地理解拟人化行走及其稳定机制。

Abstract: This paper extends the forced-oscillation-based reduced-order model of
walking to a model with ankles and feet. A human-inspired paradigm was designed
for the ankle dynamics, which results in improved gait characteristics compared
to the point-foot model. In addition, it was shown that while the proposed
model can stabilize against large errors in initial conditions through
combination of foot placement and ankle strategies, the model is able to
stabilize against small perturbations without relying on the foot placement
control and solely through the designed proprioceptive ankle scheme. This novel
property, which is also observed in humans, can help in better understanding of
anthropomorphic walking and its stabilization mechanisms.

</details>


### [186] [RuN: Residual Policy for Natural Humanoid Locomotion](https://arxiv.org/abs/2509.20696)
*Qingpeng Li,Chengrui Zhu,Yanming Wu,Xin Yuan,Zhen Zhang,Jian Yang,Yong Liu*

Main category: cs.RO

TL;DR: RuN框架通过解耦运动生成与强化学习，实现了人形机器人自然步态和速度转换，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在广泛速度范围内实现自然、动态运动（包括行走到跑步的平滑转换）的挑战。

Method: 引入RuN，一种新型解耦残差学习框架，将控制任务分解为预训练的条件运动生成器（提供运动先验）和强化学习策略（学习轻量级残差校正）。

Result: 在Unitree G1人形机器人上的仿真和实际实验表明，RuN在0-2.5 m/s的速度范围内实现了稳定、自然的步态和平滑的行走-跑步转换，训练效率和最终性能均优于现有方法。

Conclusion: RuN框架通过解耦学习任务，成功实现了人形机器人在广泛速度范围内的稳定、自然步态和平滑的行走-跑步转换，优于现有方法。

Abstract: Enabling humanoid robots to achieve natural and dynamic locomotion across a
wide range of speeds, including smooth transitions from walking to running,
presents a significant challenge. Existing deep reinforcement learning methods
typically require the policy to directly track a reference motion, forcing a
single policy to simultaneously learn motion imitation, velocity tracking, and
stability maintenance. To address this, we introduce RuN, a novel decoupled
residual learning framework. RuN decomposes the control task by pairing a
pre-trained Conditional Motion Generator, which provides a kinematically
natural motion prior, with a reinforcement learning policy that learns a
lightweight residual correction to handle dynamical interactions. Experiments
in simulation and reality on the Unitree G1 humanoid robot demonstrate that RuN
achieves stable, natural gaits and smooth walk-run transitions across a broad
velocity range (0-2.5 m/s), outperforming state-of-the-art methods in both
training efficiency and final performance.

</details>


### [187] [Joint Flow Trajectory Optimization For Feasible Robot Motion Generation from Video Demonstrations](https://arxiv.org/abs/2509.20703)
*Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: JFTO框架通过对象中心引导和概率建模，实现了从人类视频中学习机器人操作任务，平衡了抓取、轨迹和碰撞避免。


<details>
  <summary>Details</summary>
Motivation: 解决从人类视频演示中学习机器人操作任务时，因身体差异和关节可行性约束带来的挑战。

Method: 提出了Joint Flow Trajectory Optimization (JFTO)框架，结合抓取相似性、轨迹似然和碰撞惩罚，构建统一的可微分目标。

Result: 在多样化的真实世界操作任务中，JFTO框架在仿真和真实实验中均表现出色。

Conclusion: JFTO框架通过平衡抓取姿态选择、物体轨迹生成和碰撞避免，成功实现了从人类视频演示中学习机器人操作任务，并在仿真和真实实验中验证了其有效性。

Abstract: Learning from human video demonstrations offers a scalable alternative to
teleoperation or kinesthetic teaching, but poses challenges for robot
manipulators due to embodiment differences and joint feasibility constraints.
We address this problem by proposing the Joint Flow Trajectory Optimization
(JFTO) framework for grasp pose generation and object trajectory imitation
under the video-based Learning-from-Demonstration (LfD) paradigm. Rather than
directly imitating human hand motions, our method treats demonstrations as
object-centric guides, balancing three objectives: (i) selecting a feasible
grasp pose, (ii) generating object trajectories consistent with demonstrated
motions, and (iii) ensuring collision-free execution within robot kinematics.
To capture the multimodal nature of demonstrations, we extend flow matching to
$\SE(3)$ for probabilistic modeling of object trajectories, enabling
density-aware imitation that avoids mode collapse. The resulting optimization
integrates grasp similarity, trajectory likelihood, and collision penalties
into a unified differentiable objective. We validate our approach in both
simulation and real-world experiments across diverse real-world manipulation
tasks.

</details>


### [188] [Building Information Models to Robot-Ready Site Digital Twins (BIM2RDT): An Agentic AI Safety-First Framework](https://arxiv.org/abs/2509.20705)
*Reza Akhavian,Mani Amani,Johannes Mootz,Robert Ashe,Behrad Beheshti*

Main category: cs.RO

TL;DR: BIM2RDT框架通过AI动态整合BIM与实时数据，优化数字孪生安全性与精度，实验证明其算法显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决建筑行业中静态BIM数据与实时现场条件之间的脱节问题，提升施工安全性和数字化管理水平。

Method: 提出BIM2RDT框架，结合Semantic-Gravity ICP点云配准算法（利用LLM推理优化对齐精度）、YOLOE目标检测、Shi-Tomasi角点检测及实时HAV监测技术。

Result: SG-ICP算法在特征遮挡场景下对齐精度显著提升（RMSE降低64.3%-88.3%），HAV集成实现了实时安全预警。

Conclusion: BIM2RDT框架通过整合BIM数据、IoT传感器和机器人视觉数据，结合Semantic-Gravity ICP算法，显著提升了数字孪生的动态性和安全性，为建筑行业的数字化管理提供了高效解决方案。

Abstract: The adoption of cyber-physical systems and jobsite intelligence that connects
design models, real-time site sensing, and autonomous field operations can
dramatically enhance digital management in the construction industry. This
paper introduces BIM2RDT (Building Information Models to Robot-Ready Site
Digital Twins), an agentic artificial intelligence (AI) framework designed to
transform static Building Information Modeling (BIM) into dynamic, robot-ready
digital twins (DTs) that prioritize safety during execution. The framework
bridges the gap between pre-existing BIM data and real-time site conditions by
integrating three key data streams: geometric and semantic information from BIM
models, activity data from IoT sensor networks, and visual-spatial data
collected by robots during site traversal. The methodology introduces
Semantic-Gravity ICP (SG-ICP), a point cloud registration algorithm that
leverages large language model (LLM) reasoning. Unlike traditional methods,
SG-ICP utilizes an LLM to infer object-specific, plausible orientation priors
based on BIM semantics, improving alignment accuracy by avoiding convergence on
local minima. This creates a feedback loop where robot-collected data updates
the DT, which in turn optimizes paths for missions. The framework employs YOLOE
object detection and Shi-Tomasi corner detection to identify and track
construction elements while using BIM geometry as a priori maps. The framework
also integrates real-time Hand-Arm Vibration (HAV) monitoring, mapping
sensor-detected safety events to the digital twin using IFC standards for
intervention. Experiments demonstrate SG-ICP's superiority over standard ICP,
achieving RMSE reductions of 64.3%--88.3% in alignment across scenarios with
occluded features, ensuring plausible orientations. HAV integration triggers
warnings upon exceeding exposure limits, enhancing compliance with ISO 5349-1.

</details>


### [189] [Digital Twin-Guided Robot Path Planning: A Beta-Bernoulli Fusion with Large Language Model as a Sensor](https://arxiv.org/abs/2509.20709)
*Mani Amani,Reza Akhavian*

Main category: cs.RO

TL;DR: 论文提出了一种融合自然语言指令与BIM语义地图的框架，通过Beta-Bernoulli贝叶斯融合提升机器人路径规划效果。


<details>
  <summary>Details</summary>
Motivation: 在建筑领域，BIM模型包含丰富的环境自然语言描述，但如何将其与机器人任务规划结合仍是一个挑战。

Method: 采用Beta-Bernoulli贝叶斯融合方法，将LLM返回的危险分数作为伪计数更新Beta分布的参数，生成连续、上下文感知的排斥增益，用于增强基于欧几里得距离的势场。

Result: 仿真结果表明，该方法在路径鲁棒性和有效性上均取得了定性和定量的改进。

Conclusion: 论文提出了一种通过Beta-Bernoulli贝叶斯融合将自然语言指令与BIM语义地图结合的新框架，显著提升了机器人路径规划的鲁棒性和有效性。

Abstract: Integrating natural language (NL) prompts into robotic mission planning has
attracted significant interest in recent years. In the construction domain,
Building Information Models (BIM) encapsulate rich NL descriptions of the
environment. We present a novel framework that fuses NL directives with
BIM-derived semantic maps via a Beta-Bernoulli Bayesian fusion by interpreting
the LLM as a sensor: each obstacle's design-time repulsive coefficient is
treated as a Beta(alpha, beta) random variable and LLM-returned danger scores
are incorporated as pseudo-counts to update alpha and beta. The resulting
posterior mean yields a continuous, context-aware repulsive gain that augments
a Euclidean-distance-based potential field for cost heuristics. By adjusting
gains based on sentiment and context inferred from user prompts, our method
guides robots along safer, more context-aware paths. This provides a
numerically stable method that can chain multiple natural commands and prompts
from construction workers and foreman to enable planning while giving
flexibility to be integrated in any learned or classical AI framework.
Simulation results demonstrate that this Beta-Bernoulli fusion yields both
qualitative and quantitative improvements in path robustness and validity.

</details>


### [190] [RobotDancing: Residual-Action Reinforcement Learning Enables Robust Long-Horizon Humanoid Motion Tracking](https://arxiv.org/abs/2509.20717)
*Zhenguo Sun,Yibo Peng,Yuan Meng,Xukun Li,Bo-Sheng Huang,Zhenshan Bing,Xinlong Wang,Alois Knoll*

Main category: cs.RO

TL;DR: RobotDancing通过预测残差关节目标解决人形机器人运动跟踪中的误差累积问题，实现高质量零样本模拟到现实部署。


<details>
  <summary>Details</summary>
Motivation: 长期高动态运动跟踪在人形机器人中仍显脆弱，因为绝对关节命令无法补偿模型-植物不匹配，导致误差累积。

Method: 采用端到端流程，包括训练、模拟到模拟验证和零样本模拟到现实，使用单阶段强化学习（RL）设置，统一的观察、奖励和超参数配置。

Result: 在Unitree G1上测试了LAFAN1舞蹈序列的重定向，并在H1/H1-2上验证了迁移能力，能够跟踪多分钟高能量行为（跳跃、旋转、侧手翻），并零样本部署到硬件上。

Conclusion: RobotDancing框架通过预测残差关节目标有效解决了人形机器人长期高动态运动跟踪中的模型-植物不匹配问题，实现了零样本模拟到现实的部署，并展示了高质量的运动跟踪能力。

Abstract: Long-horizon, high-dynamic motion tracking on humanoids remains brittle
because absolute joint commands cannot compensate model-plant mismatch, leading
to error accumulation. We propose RobotDancing, a simple, scalable framework
that predicts residual joint targets to explicitly correct dynamics
discrepancies. The pipeline is end-to-end--training, sim-to-sim validation, and
zero-shot sim-to-real--and uses a single-stage reinforcement learning (RL)
setup with a unified observation, reward, and hyperparameter configuration. We
evaluate primarily on Unitree G1 with retargeted LAFAN1 dance sequences and
validate transfer on H1/H1-2. RobotDancing can track multi-minute, high-energy
behaviors (jumps, spins, cartwheels) and deploys zero-shot to hardware with
high motion tracking quality.

</details>


### [191] [SLAM-Free Visual Navigation with Hierarchical Vision-Language Perception and Coarse-to-Fine Semantic Topological Planning](https://arxiv.org/abs/2509.20739)
*Guoyang Zhao,Yudong Li,Weiqing Qi,Kai Zhang,Bonan Liu,Kai Chen,Haoang Li,Jun Ma*

Main category: cs.RO

TL;DR: 提出了一种无需SLAM的视觉-语言导航框架，通过语义推理和轻量拓扑表示替代密集几何，显著提升了语义准确性和导航成功率。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM管道在快速运动、校准需求和传感器漂移下表现脆弱，且缺乏任务驱动的语义推理能力。为解决这些问题，提出了一个无需SLAM的纯视觉导航框架。

Method: 采用分层视觉-语言感知模块融合场景级上下文与对象级线索，结合语义-概率拓扑地图进行粗到细的规划：基于LLM的全局推理用于子目标选择，基于视觉的局部规划用于避障。

Result: 仿真和真实环境中的实验显示，该框架在语义准确性、规划质量和导航成功率方面均有显著提升。

Conclusion: 本研究提出了一种新的SLAM-free、基于视觉-语言驱动的导航范式，将机器人探索从几何为中心的地图构建转变为语义驱动的决策制定。

Abstract: Conventional SLAM pipelines for legged robot navigation are fragile under
rapid motion, calibration demands, and sensor drift, while offering limited
semantic reasoning for task-driven exploration. To deal with these issues, we
propose a vision-only, SLAM-free navigation framework that replaces dense
geometry with semantic reasoning and lightweight topological representations. A
hierarchical vision-language perception module fuses scene-level context with
object-level cues for robust semantic inference. And a semantic-probabilistic
topological map supports coarse-to-fine planning: LLM-based global reasoning
for subgoal selection and vision-based local planning for obstacle avoidance.
Integrated with reinforcement-learning locomotion controllers, the framework is
deployable across diverse legged robot platforms. Experiments in simulation and
real-world settings demonstrate consistent improvements in semantic accuracy,
planning quality, and navigation success, while ablation studies further
showcase the necessity of both hierarchical perception and fine local planning.
This work introduces a new paradigm for SLAM-free, vision-language-driven
navigation, shifting robotic exploration from geometry-centric mapping to
semantics-driven decision making.

</details>


### [192] [MASt3R-Fusion: Integrating Feed-Forward Visual Model with IMU, GNSS for High-Functionality SLAM](https://arxiv.org/abs/2509.20757)
*Yuxuan Zhou,Xingxing Li,Shengyu Li,Zhuohao Yan,Chunxi Xia,Shaoquan Feng*

Main category: cs.RO

TL;DR: MASt3R-Fusion是一种多传感器辅助的视觉SLAM框架，通过结合前馈点图回归与多传感器数据，提升了系统在挑战性环境下的表现。


<details>
  <summary>Details</summary>
Motivation: 传统视觉SLAM系统在低纹理环境、尺度模糊和挑战性视觉条件下表现不佳，而现有基于神经网络的方法虽然能恢复高保真3D场景几何，但忽略了多传感器信息融合的优势。

Method: 提出了一种多传感器辅助的视觉SLAM框架，结合了前馈点图回归与惯性测量和GNSS数据，采用Sim(3)视觉对齐约束和分层因子图设计，实现了实时姿态跟踪和全局一致映射。

Result: 在公开基准和自收集数据集上，MASt3R-Fusion系统在精度和鲁棒性上显著优于现有的视觉中心多传感器SLAM系统。

Conclusion: MASt3R-Fusion框架通过紧密集成前馈点图回归与多传感器信息，显著提升了视觉SLAM系统在精度和鲁棒性上的表现，并在公开基准和自收集数据集上验证了其优越性。

Abstract: Visual SLAM is a cornerstone technique in robotics, autonomous driving and
extended reality (XR), yet classical systems often struggle with low-texture
environments, scale ambiguity, and degraded performance under challenging
visual conditions. Recent advancements in feed-forward neural network-based
pointmap regression have demonstrated the potential to recover high-fidelity 3D
scene geometry directly from images, leveraging learned spatial priors to
overcome limitations of traditional multi-view geometry methods. However, the
widely validated advantages of probabilistic multi-sensor information fusion
are often discarded in these pipelines. In this work, we propose
MASt3R-Fusion,a multi-sensor-assisted visual SLAM framework that tightly
integrates feed-forward pointmap regression with complementary sensor
information, including inertial measurements and GNSS data. The system
introduces Sim(3)-based visualalignment constraints (in the Hessian form) into
a universal metric-scale SE(3) factor graph for effective information fusion. A
hierarchical factor graph design is developed, which allows both real-time
sliding-window optimization and global optimization with aggressive loop
closures, enabling real-time pose tracking, metric-scale structure perception
and globally consistent mapping. We evaluate our approach on both public
benchmarks and self-collected datasets, demonstrating substantial improvements
in accuracy and robustness over existing visual-centered multi-sensor SLAM
systems. The code will be released open-source to support reproducibility and
further research (https://github.com/GREAT-WHU/MASt3R-Fusion).

</details>


### [193] [Leveraging Temporally Extended Behavior Sharing for Multi-task Reinforcement Learning](https://arxiv.org/abs/2509.20766)
*Gawon Lee,Daesol Cho,H. Jin Kim*

Main category: cs.RO

TL;DR: MT-L\'evy是多任务强化学习的新探索策略，结合行为共享和L\'evy飞行，显著提升机器人应用的样本效率。


<details>
  <summary>Details</summary>
Motivation: 多任务强化学习在机器人应用中面临数据收集成本高的问题，需要更高效的探索策略。

Method: 提出MT-L\'evy，一种结合行为共享和L\'evy飞行启发的探索策略，通过动态调整探索水平来提升样本效率。

Result: 实验证明MT-L\'evy显著提升了探索效率和样本效率，并通过定量和定性分析验证。

Conclusion: MT-L\'evy结合行为共享和自适应探索策略，显著提高了多任务强化学习在机器人应用中的实用性。

Abstract: Multi-task reinforcement learning (MTRL) offers a promising approach to
improve sample efficiency and generalization by training agents across multiple
tasks, enabling knowledge sharing between them. However, applying MTRL to
robotics remains challenging due to the high cost of collecting diverse task
data. To address this, we propose MT-L\'evy, a novel exploration strategy that
enhances sample efficiency in MTRL environments by combining behavior sharing
across tasks with temporally extended exploration inspired by L\'evy flight.
MT-L\'evy leverages policies trained on related tasks to guide exploration
towards key states, while dynamically adjusting exploration levels based on
task success ratios. This approach enables more efficient state-space coverage,
even in complex robotics environments. Empirical results demonstrate that
MT-L\'evy significantly improves exploration and sample efficiency, supported
by quantitative and qualitative analyses. Ablation studies further highlight
the contribution of each component, showing that combining behavior sharing
with adaptive exploration strategies can significantly improve the practicality
of MTRL in robotics applications.

</details>


### [194] [SemSight: Probabilistic Bird's-Eye-View Prediction of Multi-Level Scene Semantics for Navigation](https://arxiv.org/abs/2509.20839)
*Jiaxuan He,Jiamei Ren,Chongshang Yan,Wenjie Song*

Main category: cs.RO

TL;DR: SemSight是一种概率鸟瞰图预测模型，通过联合推断多级场景语义提升导航效率，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注单一对象或几何占用地图，缺乏对房间级语义结构的建模能力，因此需要一种能够预测多层次场景语义的模型。

Method: 采用编码器-解码器网络作为核心架构，并引入掩码约束监督策略，通过未知区域的二进制掩码使监督仅关注未知区域。

Result: 实验结果表明，SemSight在未探索区域的关键功能类别预测性能上优于非掩码监督方法，并在结构一致性（SC）和区域识别准确率（PA）等指标上表现更佳。

Conclusion: SemSight模型通过联合推断结构布局、全局场景上下文和目标区域分布，显著提升了未知区域关键功能类别的预测性能，并在闭环模拟中提高了导航效率。

Abstract: In target-driven navigation and autonomous exploration, reasonable prediction
of unknown regions is crucial for efficient navigation and environment
understanding. Existing methods mostly focus on single objects or geometric
occupancy maps, lacking the ability to model room-level semantic structures. We
propose SemSight, a probabilistic bird's-eye-view prediction model for
multi-level scene semantics. The model jointly infers structural layouts,
global scene context, and target area distributions, completing semantic maps
of unexplored areas while estimating probability maps for target categories. To
train SemSight, we simulate frontier-driven exploration on 2,000 indoor layout
graphs, constructing a diverse dataset of 40,000 sequential egocentric
observations paired with complete semantic maps. We adopt an encoder-decoder
network as the core architecture and introduce a mask-constrained supervision
strategy. This strategy applies a binary mask of unexplored areas so that
supervision focuses only on unknown regions, forcing the model to infer
semantic structures from the observed context. Experimental results show that
SemSight improves prediction performance for key functional categories in
unexplored regions and outperforms non-mask-supervised approaches on metrics
such as Structural Consistency (SC) and Region Recognition Accuracy (PA). It
also enhances navigation efficiency in closed-loop simulations, reducing the
number of search steps when guiding robots toward target areas.

</details>


### [195] [ImaginationPolicy: Towards Generalizable, Precise and Reliable End-to-End Policy for Robotic Manipulation](https://arxiv.org/abs/2509.20841)
*Dekun Lu,Wei Gao,Kui Jia*

Main category: cs.RO

TL;DR: 提出CoMOK动作表示方法，通过端到端训练提升机器人操作策略的通用性和准确性，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统模块化流水线存在信息丢失和特征对齐问题，而现有的端到端神经网络（包括基于大VLM/VLA模型的方法）在实际大规模部署中性能不足。

Method: 提出了一种新颖的Chain of Moving Oriented Keypoints（CoMOK）动作表示方法，用于端到端的机器人操作策略训练。

Result: 在模拟和硬件实验中，CoMOK方法展现出亚厘米级精度，并能自然地泛化到不同形状和大小的物体。

Conclusion: CoMOK作为一种新颖的动作表示方法，通过端到端训练的策略，在机器人操作任务中展现出通用性、准确性和可靠性，能够处理多阶段任务、多模态行为及可变形物体。

Abstract: End-to-end robot manipulation policies offer significant potential for
enabling embodied agents to understand and interact with the world. Unlike
traditional modular pipelines, end-to-end learning mitigates key limitations
such as information loss between modules and feature misalignment caused by
isolated optimization targets. Despite these advantages, existing end-to-end
neural networks for robotic manipulation--including those based on large
VLM/VLA models--remain insufficiently performant for large-scale practical
deployment. In this paper, we take a step towards an end-to-end manipulation
policy that is generalizable, accurate and reliable. To achieve this goal, we
propose a novel Chain of Moving Oriented Keypoints (CoMOK) formulation for
robotic manipulation. Our formulation is used as the action representation of a
neural policy, which can be trained in an end-to-end fashion. Such an action
representation is general, as it extends the standard end-effector pose action
representation and supports a diverse set of manipulation tasks in a unified
manner. The oriented keypoint in our method enables natural generalization to
objects with different shapes and sizes, while achieving sub-centimeter
accuracy. Moreover, our formulation can easily handle multi-stage tasks,
multi-modal robot behaviors, and deformable objects. Extensive simulated and
hardware experiments demonstrate the effectiveness of our method.

</details>


### [196] [MTRDrive: Memory-Tool Synergistic Reasoning for Robust Autonomous Driving in Corner Cases](https://arxiv.org/abs/2509.20843)
*Ziang Luo,Kangan Qian,Jiahua Wang,Yuechen Luo,Jinyu Miao,Zheng Fu,Yunlong Wang,Sicong Jiang,Zilin Huang,Yifei Hu,Yuhao Yang,Hao Ye,Mengmeng Yang,Xiaojian Dong,Kun Jiang,Diange Yang*

Main category: cs.RO

TL;DR: MTRDrive通过结合程序化驾驶经验和动态工具包，显著提升了视觉语言模型在自动驾驶中的泛化能力和决策可靠性，实验验证了其卓越性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在自动驾驶中存在幻觉和泛化能力不足的问题，限制了其实际部署的可靠性。

Method: MTRDrive通过闭环系统结合基于记忆的经验检索机制和动态工具包，实现了记忆与工具的协同推理，提升了模型的推理和决策能力。

Result: MTRDrive在NAVSIM基准测试中表现卓越，PDMS达88.3，驾驶指标得分79.8%，规划准确率82.6%。在Roadwork-VLM基准测试中，零样本评估驾驶指标得分为80.2%。

Conclusion: MTRDrive展示了将视觉语言模型与程序化驾驶经验和动态工具包结合的潜力，显著提升了自动驾驶的泛化能力和决策可靠性，为实际部署提供了更安全的解决方案。

Abstract: Vision-Language Models(VLMs) have demonstrated significant potential for
end-to-end autonomous driving, yet a substantial gap remains between their
current capabilities and the reliability necessary for real-world deployment. A
critical challenge is their fragility, characterized by hallucinations and poor
generalization in out-of-distribution (OOD) scenarios. To bridge this gap, we
introduce MTRDrive, a novel framework that integrates procedural driving
experiences with a dynamic toolkit to enhance generalization and proactive
decision-making.
  MTRDrive addresses these limitations through a closed-loop system that
combines a memory-based experience retrieval mechanism with dynamic toolkits.
This synergy enables the model to interact more effectively with its
environment, improving both reasoning and decision-making capabilities with the
help of our memory-tool synergistic reasoning. Additionally, we introduce a new
benchmark based on complex Roadwork construction scenarios to rigorously
evaluate zero-shot generalization.
  Extensive experiments demonstrate the superior effectiveness of our approach.
On the public NAVSIM benchmark, our 3B-parameter MTRDrive model achieves an
exceptional PDMS of 88.3 without chain-of-thought and sets a state-of-the-art
performance bar on high-level planning, with a driving metric score of 79.8\%
and a planning accuracy of 82.6\%. Rigorous zero-shot evaluation on the new
Roadwork-VLM benchmark shows a strong ability to reason robustly in unseen
scenarios, achieving a driving metric score of 80.2\%. These results highlight
MTRDrive's potential to advance autonomous driving toward safer and more
reliable systems.

</details>


### [197] [Efficient Differentiable Contact Model with Long-range Influence](https://arxiv.org/abs/2509.20917)
*Xiaohan Ye,Kui Wu,Zherong Pan,Taku Komura*

Main category: cs.RO

TL;DR: 本文提出了一种适用于可微分刚体模拟器的实用接触模型，确保梯度信息良好行为，实验证明其能有效执行复杂任务。


<details>
  <summary>Details</summary>
Motivation: 随着可微分物理的成熟，其在模型预测控制、机器人设计优化和神经PDE求解器等下游应用中的作用日益重要。然而，可微分模拟器提供的导数信息可能出现突变或消失，阻碍基于梯度的优化器的收敛。

Method: 本文通过分析接触模型的设计，提出了一组确保梯度信息良好行为的属性，并介绍了一种满足这些属性的实用接触模型。

Result: 实验结果表明，即使从简单的初始化开始，本文提出的接触模型也能发现复杂的、接触丰富的控制信号，成功执行多种下游运动和操作任务。

Conclusion: 本文提出了一种实用的接触模型，适用于可微分刚体模拟器，该模型在保持计算效率的同时，确保了梯度信息的良好行为。实验表明，该模型能够发现复杂的、接触丰富的控制信号，成功执行多种下游运动和操作任务。

Abstract: With the maturation of differentiable physics, its role in various downstream
applications: such as model predictive control, robotic design optimization,
and neural PDE solvers, has become increasingly important. However, the
derivative information provided by differentiable simulators can exhibit abrupt
changes or vanish altogether, impeding the convergence of gradient-based
optimizers. In this work, we demonstrate that such erratic gradient behavior is
closely tied to the design of contact models. We further introduce a set of
properties that a contact model must satisfy to ensure well-behaved gradient
information. Lastly, we present a practical contact model for differentiable
rigid-body simulators that satisfies all of these properties while maintaining
computational efficiency. Our experiments show that, even from simple
initializations, our contact model can discover complex, contact-rich control
signals, enabling the successful execution of a range of downstream locomotion
and manipulation tasks.

</details>


### [198] [Autoregressive End-to-End Planning with Time-Invariant Spatial Alignment and Multi-Objective Policy Refinement](https://arxiv.org/abs/2509.20938)
*Jianbo Zhao,Taiyu Ban,Xiangjie Li,Xingtai Gui,Hangning Zhou,Lei Liu,Hongwei Zhao,Bin Li*

Main category: cs.RO

TL;DR: 通过TISA模块和DPO后训练解决了自回归模型的时空错位问题，提升了自动驾驶规划性能。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在自动驾驶规划中存在时空错位问题，限制了其性能上限。

Method: 提出了时间不变空间对齐（TISA）模块，将初始环境特征投影到一致的自我中心框架中，并采用运动学动作预测头确保物理可行的轨迹，最后通过DPO进行多目标后训练。

Result: 模型在NAVSIM数据集上达到了89.8 PDMS的最先进性能。

Conclusion: 提出的TISA模块和DPO后训练阶段显著提升了自回归模型在自动驾驶规划中的性能，达到了NAVSIM数据集上的最先进水平。

Abstract: The inherent sequential modeling capabilities of autoregressive models make
them a formidable baseline for end-to-end planning in autonomous driving.
Nevertheless, their performance is constrained by a spatio-temporal
misalignment, as the planner must condition future actions on past sensory
data. This creates an inconsistent worldview, limiting the upper bound of
performance for an otherwise powerful approach. To address this, we propose a
Time-Invariant Spatial Alignment (TISA) module that learns to project initial
environmental features into a consistent ego-centric frame for each future time
step, effectively correcting the agent's worldview without explicit future
scene prediction. In addition, we employ a kinematic action prediction head
(i.e., acceleration and yaw rate) to ensure physically feasible trajectories.
Finally, we introduce a multi-objective post-training stage using Direct
Preference Optimization (DPO) to move beyond pure imitation. Our approach
provides targeted feedback on specific driving behaviors, offering a more
fine-grained learning signal than the single, overall objective used in
standard DPO. Our model achieves a state-of-the-art 89.8 PDMS on the NAVSIM
dataset among autoregressive models. The video document is available at
https://tisa-dpo-e2e.github.io/.

</details>


### [199] [BactoBot: A Low-Cost, Bacteria-Inspired Soft Underwater Robot for Marine Exploration](https://arxiv.org/abs/2509.20964)
*Rubaiyat Tasnim Chowdhury,Nayan Bala,Ronojoy Roy,Tarek Mahmud*

Main category: cs.RO

TL;DR: BactoBot是一种低成本软体水下机器人，灵感来自细菌鞭毛推进，成功测试了其运动能力，为环保海洋探索工具奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 传统刚性水下机器人对脆弱海洋生态系统构成风险，因此设计了BactoBot，以实现安全、温和的海洋探索。

Method: 采用DIY方法制造，包括食品级硅胶成型、3D打印和现成微控制器，设计了12个柔性硅胶臂的软体水下机器人。

Result: 在受控水箱中成功测试，展示了前进和转向能力。

Conclusion: BactoBot项目验证了低成本复制复杂生物运动的可行性，为环保机器人工具奠定了基础，特别是在资源受限的环境下进行海洋科学研究。

Abstract: Traditional rigid underwater vehicles pose risks to delicate marine
ecosystems. This paper presents BactoBot, a low-cost, soft underwater robot
designed for safe and gentle marine exploration. Inspired by bacterial
flagellar propulsion, BactoBot features 12 flexible, silicone-based arms
arranged on a 3D-printed dodecahedral frame. The design provides inherent
compliance, redundancy, and the potential for omnidirectional movement. The
prototype was fabricated using accessible DIY methods, including food-grade
silicone molding, 3D printing, and off-the-shelf microcontrollers.
Waterproofing and buoyancy calibration protocols were developed, and the robot
was successfully tested in a controlled water tank, demonstrating forward
motion and turning. The results validate the feasibility of replicating complex
biological locomotion at low cost. The project lays a foundation for
environmentally conscious robotic tools, particularly for marine science in
resource-constrained settings, and identifies pathways toward autonomous
operation and field deployment.

</details>


### [200] [AnywhereVLA: Language-Conditioned Exploration and Mobile Manipulation](https://arxiv.org/abs/2509.21006)
*Konstantin Gubernatorov,Artem Voronov,Roman Voronov,Sergei Pasynkov,Stepan Perminov,Ziang Guo,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: AnywhereVLA是一个模块化框架，通过结合经典堆栈和微调VLA操纵，在未知环境中实现自然语言拾取放置，任务成功率为46%。


<details>
  <summary>Details</summary>
Motivation: 解决在未知、不可预测的室内环境中进行自然语言拾取放置的挑战。

Method: 使用模块化框架，包括结构化任务图、SLAM、语义映射、探索策略和紧凑的SmolVLA操纵头。

Result: 在多房间实验室中实现了46%的任务成功率，并在嵌入式计算上保持实时操作。

Conclusion: AnywhereVLA结合了基于几何的导航可靠性和语言条件操纵的敏捷性，实现了在未知室内环境中的自然语言拾取放置任务。

Abstract: We address natural language pick-and-place in unseen, unpredictable indoor
environments with AnywhereVLA, a modular framework for mobile manipulation. A
user text prompt serves as an entry point and is parsed into a structured task
graph that conditions classical SLAM with LiDAR and cameras, metric semantic
mapping, and a task-aware frontier exploration policy. An approach planner then
selects visibility and reachability aware pre grasp base poses. For
interaction, a compact SmolVLA manipulation head is fine tuned on platform pick
and place trajectories for the SO-101 by TheRobotStudio, grounding local visual
context and sub-goals into grasp and place proposals. The full system runs
fully onboard on consumer-level hardware, with Jetson Orin NX for perception
and VLA and an Intel NUC for SLAM, exploration, and control, sustaining
real-time operation. We evaluated AnywhereVLA in a multi-room lab under static
scenes and normal human motion. In this setting, the system achieves a $46\%$
overall task success rate while maintaining throughput on embedded compute. By
combining a classical stack with a fine-tuned VLA manipulation, the system
inherits the reliability of geometry-based navigation with the agility and task
generalization of language-conditioned manipulation.

</details>


### [201] [Multi-Robot Vision-Based Task and Motion Planning for EV Battery Disassembly and Sorting](https://arxiv.org/abs/2509.21020)
*Abdelaziz Shaarawy,Cansu Erdogan,Rustam Stolkin,Alireza Rastegarpanah*

Main category: cs.RO

TL;DR: 提出四层TAMP框架，结合任务规划和运动规划，显著提升EV电池拆卸的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: EV电池拆卸需要精确的多机器人协调、短而可靠的运动以及在杂乱动态场景中的鲁棒碰撞安全性。

Method: 提出了一个四层任务与运动规划（TAMP）框架，结合符号任务规划和成本/可访问性感知分配，以及从演示中学习的TP-GMM引导的运动规划器。采用立体视觉和YOLOv8进行实时组件定位，OctoMap-based 3D映射和FCL碰撞检查在MoveIt中统一预测性数字孪生碰撞检查与反应性视觉避免。

Result: 在两项UR10e机器人上验证，该方法比默认RRTConnect基线在相同感知和任务分配下产生更紧凑和安全的运动：末端执行器路径长度平均减少63.3%，makespan减少8.1%；每臂扫掠体积缩小（R1:0.583→0.139m³；R2:0.696→0.252m³），相互重叠减少47%（0.064→0.034m³）。

Conclusion: 该研究显著提升了多机器人EV电池拆卸在非结构化动态环境中的自主性、精确性和安全性。

Abstract: Electric-vehicle (EV) battery disassembly requires precise multi-robot
coordination, short and reliable motions, and robust collision safety in
cluttered, dynamic scenes. We propose a four-layer task-and-motion planning
(TAMP) framework that couples symbolic task planning and cost- and
accessibility-aware allocation with a TP-GMM-guided motion planner learned from
demonstrations. Stereo vision with YOLOv8 provides real-time component
localization, while OctoMap-based 3D mapping and FCL(Flexible Collision
Library) checks in MoveIt unify predictive digital-twin collision checking with
reactive, vision-based avoidance. Validated on two UR10e robots across cable,
busbar, service plug, and three leaf-cell removals, the approach yields
substantially more compact and safer motions than a default RRTConnect baseline
under identical perception and task assignments: average end-effector path
length drops by $-63.3\%$ and makespan by $-8.1\%$; per-arm swept volumes
shrink (R1: $0.583\rightarrow0.139\,\mathrm{m}^3$; R2:
$0.696\rightarrow0.252\,\mathrm{m}^3$), and mutual overlap decreases by $47\%$
($0.064\rightarrow0.034\,\mathrm{m}^3$). These results highlight improved
autonomy, precision, and safety for multi-robot EV battery disassembly in
unstructured, dynamic environments.

</details>


### [202] [KeyWorld: Key Frame Reasoning Enables Effective and Efficient World Models](https://arxiv.org/abs/2509.21027)
*Sibo Li,Qianyue Hao,Yu Shang,Yong Li*

Main category: cs.RO

TL;DR: KeyWorld 通过聚焦关键帧和轻量级插值，显著提升了机器人世界模型的效率和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前帧到帧生成方法存在计算冗余和忽视关键过渡语义的问题，限制了机器人世界模型的实际应用。

Method: KeyWorld 通过迭代简化机器人运动轨迹识别关键帧，使用 DiT 模型生成这些关键帧，并通过轻量级插值器填充中间帧。

Result: 在 LIBERO 基准测试中，KeyWorld 实现了 5.68 倍的加速，并提升了生成视频的物理合理性。

Conclusion: KeyWorld 提出了一种通过聚焦于语义关键帧来提升机器人世界模型效率和物理合理性的框架，为实时机器人控制等应用提供了实用路径。

Abstract: Robotic world models are a promising paradigm for forecasting future
environment states, yet their inference speed and the physical plausibility of
generated trajectories remain critical bottlenecks, limiting their real-world
applications. This stems from the redundancy of the prevailing frame-to-frame
generation approach, where the model conducts costly computation on similar
frames, as well as neglecting the semantic importance of key transitions. To
address this inefficiency, we propose KeyWorld, a framework that improves
text-conditioned robotic world models by concentrating transformers computation
on a few semantic key frames while employing a lightweight convolutional model
to fill the intermediate frames. Specifically, KeyWorld first identifies
significant transitions by iteratively simplifying the robot's motion
trajectories, obtaining the ground truth key frames. Then, a DiT model is
trained to reason and generate these physically meaningful key frames from
textual task descriptions. Finally, a lightweight interpolator efficiently
reconstructs the full video by inpainting all intermediate frames. Evaluations
on the LIBERO benchmark demonstrate that KeyWorld achieves a 5.68$\times$
acceleration compared to the frame-to-frame generation baseline, and focusing
on the motion-aware key frames further contributes to the physical validity of
the generated videos, especially on complex tasks. Our approach highlights a
practical path toward deploying world models in real-time robotic control and
other domains requiring both efficient and effective world models. Code is
released at https://anonymous.4open.science/r/Keyworld-E43D.

</details>


### [203] [MPC-based Deep Reinforcement Learning Method for Space Robotic Control with Fuel Sloshing Mitigation](https://arxiv.org/abs/2509.21045)
*Mahya Ramezani,M. Amin Alandihallaj,Barış Can Yalçın,Miguel Angel Olivares Mendez,Holger Voos*

Main category: cs.RO

TL;DR: 结合RL和MPC的框架解决了卫星对接中燃料晃动问题，SAC-MPC表现最佳。


<details>
  <summary>Details</summary>
Motivation: 传统对接控制在微重力环境下因燃料晃动导致不可预测的力，影响稳定性。

Method: 整合了近端策略优化（PPO）和软演员-评论家（SAC）的强化学习算法与模型预测控制（MPC），利用MPC的预测能力加速RL训练并提升控制鲁棒性。

Result: 仿真结果表明，SAC-MPC在对接精度、成功率和控制效率上均优于独立RL和PPO-MPC方法。

Conclusion: 该研究通过结合强化学习和模型预测控制，显著提升了自主卫星对接的准确性和鲁棒性，为在轨燃料补给和服务任务提供了更可行的解决方案。

Abstract: This paper presents an integrated Reinforcement Learning (RL) and Model
Predictive Control (MPC) framework for autonomous satellite docking with a
partially filled fuel tank. Traditional docking control faces challenges due to
fuel sloshing in microgravity, which induces unpredictable forces affecting
stability. To address this, we integrate Proximal Policy Optimization (PPO) and
Soft Actor-Critic (SAC) RL algorithms with MPC, leveraging MPC's predictive
capabilities to accelerate RL training and improve control robustness. The
proposed approach is validated through Zero-G Lab of SnT experiments for planar
stabilization and high-fidelity numerical simulations for 6-DOF docking with
fuel sloshing dynamics. Simulation results demonstrate that SAC-MPC achieves
superior docking accuracy, higher success rates, and lower control effort,
outperforming standalone RL and PPO-MPC methods. This study advances
fuel-efficient and disturbance-resilient satellite docking, enhancing the
feasibility of on-orbit refueling and servicing missions.

</details>


### [204] [Normalizing Flows are Capable Visuomotor Policy Learning Models](https://arxiv.org/abs/2509.21073)
*Simon Kristoffersson Lind,Jialong Li,Maj Stenmark,Volker Krüger*

Main category: cs.RO

TL;DR: Normalizing Flows Policy 是一种高效的视觉运动策略学习模型，解决了扩散模型的高计算成本和不确定性量化问题，性能优越且推理速度快。


<details>
  <summary>Details</summary>
Motivation: 当前概率模型（如扩散模型）在推理时计算成本高且无法量化输出不确定性，而模型的可靠性与其提供置信度测量的能力密切相关。

Method: 提出 Normalizing Flows Policy，通过 Normalizing Flows 提供统计上可靠的置信度测量和高效的推理过程，并在四个不同的模拟机器人任务中进行全面实验。

Result: Normalizing Flows Policy 在性能上与 Diffusion Policy 相当或更优，样本效率更高，推理速度快达 30 倍。

Conclusion: Normalizing Flows Policy 是一种基于 Normalizing Flows 的新型视觉运动策略学习模型，它在性能上与 Diffusion Policy 相当甚至更优，同时提供了更高的样本效率和推理速度。

Abstract: The field of general purpose robotics has recently embraced powerful
probabilistic models, such as diffusion models, to model and learn complex
behaviors. However, these models often come with significant trade-offs, namely
high computational costs for inference and a fundamental inability to quantify
output uncertainty. We argue that a model's trustworthiness, a critical factor
for reliable, general-purpose robotics, is inherently linked to its ability to
provide confidence measures.
  In this work, we introduce Normalizing Flows Policy, a novel visuomotor
policy learning model based on Normalizing Flows. We show that Normalizing
Flows are a natural and powerful alternative to diffusion models, providing
both a statistically sound measure of confidence and a highly efficient
inference process. Through comprehensive experiments across four distinct
simulated robotic tasks, we demonstrate that Normalizing Flows Policy achieves
performance comparable to, and often surpassing, Diffusion Policy, and it does
so not only with improved sample efficiency but also with up to 30 times faster
inference. Additionally, our ablation study validates several key architectural
and training techniques that enable Normalizing Flows to perform well in this
domain.

</details>


### [205] [Cross-Modal Instructions for Robot Motion Generation](https://arxiv.org/abs/2509.21107)
*William Barron,Xiaoxiang Dong,Matthew Johnson-Roberson,Weiming Zhi*

Main category: cs.RO

TL;DR: 论文提出CrossInstruct框架，利用跨模态指令（如文本标签）和VLM生成机器人运动轨迹，无需物理演示，并在仿真和实际硬件中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 传统机器人行为教学依赖物理演示，数据收集繁琐且难以扩展。本文探索了一种替代范式，通过跨模态指令（如文本标签）而非物理运动来指导机器人学习。

Method: 论文提出了CrossInstruct框架，利用跨模态指令（如自由文本标签）作为示例输入到VLM中。VLM通过迭代查询一个较小的微调模型，合成多视图2D运动，并最终融合为3D运动轨迹分布。

Result: CrossInstruct在基准仿真任务和实际硬件上均表现出有效性，无需额外微调，并能通过强化学习进一步优化策略。

Conclusion: CrossInstruct框架通过整合跨模态指令和基础视觉语言模型（VLM），成功生成了可执行的机器人行为，并在无需额外微调的情况下表现出有效性。此外，该框架为后续强化学习提供了强初始化策略。

Abstract: Teaching robots novel behaviors typically requires motion demonstrations via
teleoperation or kinaesthetic teaching, that is, physically guiding the robot.
While recent work has explored using human sketches to specify desired
behaviors, data collection remains cumbersome, and demonstration datasets are
difficult to scale. In this paper, we introduce an alternative paradigm,
Learning from Cross-Modal Instructions, where robots are shaped by
demonstrations in the form of rough annotations, which can contain free-form
text labels, and are used in lieu of physical motion. We introduce the
CrossInstruct framework, which integrates cross-modal instructions as examples
into the context input to a foundational vision-language model (VLM). The VLM
then iteratively queries a smaller, fine-tuned model, and synthesizes the
desired motion over multiple 2D views. These are then subsequently fused into a
coherent distribution over 3D motion trajectories in the robot's workspace. By
incorporating the reasoning of the large VLM with a fine-grained pointing
model, CrossInstruct produces executable robot behaviors that generalize beyond
the environment of in the limited set of instruction examples. We then
introduce a downstream reinforcement learning pipeline that leverages
CrossInstruct outputs to efficiently learn policies to complete fine-grained
tasks. We rigorously evaluate CrossInstruct on benchmark simulation tasks and
real hardware, demonstrating effectiveness without additional fine-tuning and
providing a strong initialization for policies subsequently refined via
reinforcement learning.

</details>


### [206] [Rich State Observations Empower Reinforcement Learning to Surpass PID: A Drone Ball Balancing Study](https://arxiv.org/abs/2509.21122)
*Mingjiang Liu,Hailong Huang*

Main category: cs.RO

TL;DR: 本文提出分层RL框架用于无人机球平衡任务，证明RL优于PID控制器，优势来自更全面的状态观察而非参数调优。


<details>
  <summary>Details</summary>
Motivation: 解决无人机通过电缆交互在可移动梁上稳定球的挑战，探索强化学习在复杂控制任务中的应用潜力。

Method: 提出了一个分层控制框架，将高级平衡策略与低级无人机控制解耦，并训练了一个强化学习（RL）策略来处理高级决策。

Result: 仿真结果表明，RL策略在同一分层结构中优于精心调谐的PID控制器，其优势源于有效利用更丰富的状态观察。

Conclusion: 本研究强调了全面状态表示在学习型系统中的关键作用，并指出增强感知能力可能对提升控制器性能至关重要。

Abstract: This paper addresses a drone ball-balancing task, in which a drone stabilizes
a ball atop a movable beam through cable-based interaction. We propose a
hierarchical control framework that decouples high-level balancing policy from
low-level drone control, and train a reinforcement learning (RL) policy to
handle the high-level decision-making. Simulation results show that the RL
policy achieves superior performance compared to carefully tuned PID
controllers within the same hierarchical structure. Through systematic
comparative analysis, we demonstrate that RL's advantage stems not from
improved parameter tuning or inherent nonlinear mapping capabilities, but from
its ability to effectively utilize richer state observations. These findings
underscore the critical role of comprehensive state representation in
learning-based systems and suggest that enhanced sensing could be instrumental
in improving controller performance.

</details>


### [207] [Automotive-ENV: Benchmarking Multimodal Agents in Vehicle Interface Systems](https://arxiv.org/abs/2509.21143)
*Junfeng Yan,Biao Wu,Meng Fang,Ling Chen*

Main category: cs.RO

TL;DR: 提出了首个汽车GUI基准Automotive-ENV和地理感知代理ASURADA，实验证明位置信息提升安全任务表现，平台将开源。


<details>
  <summary>Details</summary>
Motivation: 汽车GUI面临驾驶员注意力有限、严格的安全要求和复杂的位置交互模式等独特挑战，当前多模态代理在汽车系统中的应用尚未充分探索。

Method: 提出了Automotive-ENV，一个高保真度的车辆GUI基准和交互环境，定义了185个参数化任务，并提供了结构化多模态观察和精确的程序化检查。基于此，开发了ASURADA，一个地理感知多模态代理，整合了GPS信息以动态调整行为。

Result: 实验表明，地理感知信息显著提高了安全任务的完成率，强调了位置上下文在汽车环境中的重要性。

Conclusion: 作者提出了Automotive-ENV和ASURADA，证明了地理感知信息在汽车环境中对安全任务的重要性，并计划发布该平台以促进安全自适应车载代理的发展。

Abstract: Multimodal agents have demonstrated strong performance in general GUI
interactions, but their application in automotive systems has been largely
unexplored. In-vehicle GUIs present distinct challenges: drivers' limited
attention, strict safety requirements, and complex location-based interaction
patterns. To address these challenges, we introduce Automotive-ENV, the first
high-fidelity benchmark and interaction environment tailored for vehicle GUIs.
This platform defines 185 parameterized tasks spanning explicit control,
implicit intent understanding, and safety-aware tasks, and provides structured
multimodal observations with precise programmatic checks for reproducible
evaluation. Building on this benchmark, we propose ASURADA, a geo-aware
multimodal agent that integrates GPS-informed context to dynamically adjust
actions based on location, environmental conditions, and regional driving
norms. Experiments show that geo-aware information significantly improves
success on safety-aware tasks, highlighting the importance of location-based
context in automotive environments. We will release Automotive-ENV, complete
with all tasks and benchmarking tools, to further the development of safe and
adaptive in-vehicle agents.

</details>


### [208] [DAGDiff: Guiding Dual-Arm Grasp Diffusion to Stable and Collision-Free Grasps](https://arxiv.org/abs/2509.21145)
*Md Faizal Karim,Vignesh Vembar,Keshab Patra,Gaurav Singh,K Madhava Krishna*

Main category: cs.RO

TL;DR: DAGDiff是一个端到端双臂抓取框架，通过扩散模型生成物理有效的抓取对，显著提升稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 双可靠臂抓取对于操作大型复杂物体至关重要，但现有方法通常依赖区域先验或启发式方法，缺乏稳定性和泛化能力的理论保证。

Method: DAGDiff是一个端到端框架，通过在SE(3) x SE(3)空间中直接去噪生成抓取对，并利用分类器信号引导扩散过程，确保抓取的物理有效性和力闭合合规性。

Result: DAGDiff在力闭合检查、碰撞分析和大规模物理仿真中均优于现有方法，并成功在真实点云上生成抓取对，由异构双臂系统执行。

Conclusion: DAGDiff通过集成几何、稳定性和碰撞感知的引导项，能够直接生成物理有效且符合力闭合条件的双臂抓取对，显著提升了抓取的可靠性和泛化能力。

Abstract: Reliable dual-arm grasping is essential for manipulating large and complex
objects but remains a challenging problem due to stability, collision, and
generalization requirements. Prior methods typically decompose the task into
two independent grasp proposals, relying on region priors or heuristics that
limit generalization and provide no principled guarantee of stability. We
propose DAGDiff, an end-to-end framework that directly denoises to grasp pairs
in the SE(3) x SE(3) space. Our key insight is that stability and collision can
be enforced more effectively by guiding the diffusion process with classifier
signals, rather than relying on explicit region detection or object priors. To
this end, DAGDiff integrates geometry-, stability-, and collision-aware
guidance terms that steer the generative process toward grasps that are
physically valid and force-closure compliant. We comprehensively evaluate
DAGDiff through analytical force-closure checks, collision analysis, and
large-scale physics-based simulations, showing consistent improvements over
previous work on these metrics. Finally, we demonstrate that our framework
generates dual-arm grasps directly on real-world point clouds of previously
unseen objects, which are executed on a heterogeneous dual-arm setup where two
manipulators reliably grasp and lift them.

</details>


### [209] [Human-like Navigation in a World Built for Humans](https://arxiv.org/abs/2509.21189)
*Bhargav Chandaka,Gloria X. Wang,Haozhe Chen,Henry Che,Albert J. Zhai,Shenlong Wang*

Main category: cs.RO

TL;DR: ReasonNav利用视觉语言模型的推理能力，整合人类导航行为，显著提升机器人在大型环境中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航系统缺乏执行人类导航行为（如阅读标志和询问方向）的能力，导致在大型环境中导航效率低下。

Method: 设计基于导航地标的紧凑输入和输出抽象，利用视觉语言模型（VLM）的语言理解和推理能力。

Result: 在真实和模拟导航任务中，ReasonNav成功运用高阶推理，在大型复杂建筑中高效导航。

Conclusion: ReasonNav通过整合类似人类的导航技能，显著提高了机器人在大型复杂建筑中的导航效率。

Abstract: When navigating in a man-made environment they haven't visited before--like
an office building--humans employ behaviors such as reading signs and asking
others for directions. These behaviors help humans reach their destinations
efficiently by reducing the need to search through large areas. Existing robot
navigation systems lack the ability to execute such behaviors and are thus
highly inefficient at navigating within large environments. We present
ReasonNav, a modular navigation system which integrates these human-like
navigation skills by leveraging the reasoning capabilities of a vision-language
model (VLM). We design compact input and output abstractions based on
navigation landmarks, allowing the VLM to focus on language understanding and
reasoning. We evaluate ReasonNav on real and simulated navigation tasks and
show that the agent successfully employs higher-order reasoning to navigate
efficiently in large, complex buildings.

</details>


### [210] [Next-Generation Aerial Robots -- Omniorientational Strategies: Dynamic Modeling, Control, and Comparative Analysis](https://arxiv.org/abs/2509.21210)
*Ali Kafili Gavgani,Amin Talaeizadeh,Aria Alasty,Hossein Nejat Pishkenari,Esmaeil Najafi*

Main category: cs.RO

TL;DR: 本研究通过引入额外控制输入使多旋翼系统实现全向控制，设计了两种高效控制器，并通过仿真验证了性能和功耗。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼系统是欠驱动系统，无法独立控制姿态和位置。本研究通过引入额外控制输入解决这一限制，使系统实现“全向控制”。

Method: 详细推导了所有引入配置的动态模型，并通过Simscape Multibody仿真验证。设计了两种控制器：滑模控制器和新型PID控制器（带重力补偿和线性/非线性分配器）。

Result: 控制器有效处理了严重干扰和不确定性，仿真比较了不同配置和控制器的功耗，并进行了定性比较以评估不确定性对控制系统的影响。

Conclusion: 本研究为未来研究人员设计全向无人机提供了路线图，根据设计目标提供配置选择和控制器设计的实用见解。

Abstract: Conventional multi-rotors are under-actuated systems, hindering them from
independently controlling attitude from position. In this study, we present
several distinct configurations that incorporate additional control inputs for
manipulating the angles of the propeller axes. This addresses the mentioned
limitations, making the systems "omniorientational". We comprehensively derived
detailed dynamic models for all introduced configurations and validated by a
methodology using Simscape Multibody simulations. Two controllers are designed:
a sliding mode controller for robust handling of disturbances and a novel
PID-based controller with gravity compensation integrating linear and
non-linear allocators, designed for computational efficiency. A custom control
allocation strategy is implemented to manage the input-non-affine nature of
these systems, seeking to maximize battery life by minimizing the "Power
Consumption Factor" defined in this study. Moreover, the controllers
effectively managed harsh disturbances and uncertainties. Simulations compare
and analyze the proposed configurations and controllers, majorly considering
their power consumption. Furthermore, we conduct a qualitative comparison to
evaluate the impact of different types of uncertainties on the control system,
highlighting areas for potential model or hardware improvements. The analysis
in this study provides a roadmap for future researchers to design
omniorientational drones based on their design objectives, offering practical
insights into configuration selection and controller design. This research
aligns with the project SAC-1, one of the objectives of Sharif AgRoLab.

</details>


### [211] [SEEC: Stable End-Effector Control with Model-Enhanced Residual Learning for Humanoid Loco-Manipulation](https://arxiv.org/abs/2509.21231)
*Jaehwi Jang,Zhuoheng Wang,Ziyi Zhou,Feiyang Wu,Ye Zhao*

Main category: cs.RO

TL;DR: SEEC框架通过模型增强的残差学习，实现了无需额外训练的精确末端执行器稳定化，适应性强且性能优越。


<details>
  <summary>Details</summary>
Motivation: 由于双足机器人结构的高自由度和固有动态不稳定性，臂末端执行器稳定化在操作任务中至关重要，但现有方法在精确建模和实际适应性方面存在局限。

Method: 采用模型引导的强化学习（RL）与扰动生成器相结合的方法，学习对上身策略进行精确末端执行器稳定化。

Result: 实验表明，SEEC框架在不同模拟器中均优于基线方法，并能鲁棒处理多样且高要求的操作任务。

Conclusion: 提出的SEEC框架通过模型增强的残差学习，成功实现了精确且鲁棒的末端执行器补偿，能够适应未见过的运动控制器，无需额外训练。

Abstract: Arm end-effector stabilization is essential for humanoid loco-manipulation
tasks, yet it remains challenging due to the high degrees of freedom and
inherent dynamic instability of bipedal robot structures. Previous model-based
controllers achieve precise end-effector control but rely on precise dynamics
modeling and estimation, which often struggle to capture real-world factors
(e.g., friction and backlash) and thus degrade in practice. On the other hand,
learning-based methods can better mitigate these factors via exploration and
domain randomization, and have shown potential in real-world use. However, they
often overfit to training conditions, requiring retraining with the entire
body, and still struggle to adapt to unseen scenarios. To address these
challenges, we propose a novel stable end-effector control (SEEC) framework
with model-enhanced residual learning that learns to achieve precise and robust
end-effector compensation for lower-body induced disturbances through
model-guided reinforcement learning (RL) with a perturbation generator. This
design allows the upper-body policy to achieve accurate end-effector
stabilization as well as adapt to unseen locomotion controllers with no
additional training. We validate our framework in different simulators and
transfer trained policies to the Booster T1 humanoid robot. Experiments
demonstrate that our method consistently outperforms baselines and robustly
handles diverse and demanding loco-manipulation tasks.

</details>


### [212] [FSGlove: An Inertial-Based Hand Tracking System with Shape-Aware Calibration](https://arxiv.org/abs/2509.21242)
*Yutong Li,Jieyi Zhang,Wenqiang Xu,Tutian Tang,Cewu Lu*

Main category: cs.RO

TL;DR: FSGlove是一种基于IMU的手部运动捕捉系统，通过DiffHCal校准方法实现48自由度高精度追踪和个性化手形重建，性能优于商业产品，并支持开源集成。


<details>
  <summary>Details</summary>
Motivation: 现有商业手套仅能提供21自由度，无法满足复杂操作需求且忽略了个性化手形对接触密集型任务的重要性。因此，需要一种能够同时追踪高自由度关节运动并重建个性化手形的系统。

Method: FSGlove采用惯性测量单元（IMUs）覆盖每个手指关节和手背，结合DiffHCal校准方法，通过可微分优化与参数化MANO模型集成，一次性解决关节运动学、形状参数和传感器错位问题。

Result: FSGlove实现了关节角度误差小于2.7度的精准追踪，并在形状重建和接触保真度方面超越商业替代方案。其开源设计支持与VR和机器人生态系统的无缝集成。

Conclusion: FSGlove通过DiffHCal校准方法实现了高精度的48自由度手部运动捕捉和个性化手形重建，显著优于现有商业手套，并在关节角度误差、形状重建和接触保真度方面达到最先进水平。其开源硬件和软件设计确保与当前VR和机器人生态系统的兼容性。

Abstract: Accurate hand motion capture (MoCap) is vital for applications in robotics,
virtual reality, and biomechanics, yet existing systems face limitations in
capturing high-degree-of-freedom (DoF) joint kinematics and personalized hand
shape. Commercial gloves offer up to 21 DoFs, which are insufficient for
complex manipulations while neglecting shape variations that are critical for
contact-rich tasks. We present FSGlove, an inertial-based system that
simultaneously tracks up to 48 DoFs and reconstructs personalized hand shapes
via DiffHCal, a novel calibration method. Each finger joint and the dorsum are
equipped with IMUs, enabling high-resolution motion sensing. DiffHCal
integrates with the parametric MANO model through differentiable optimization,
resolving joint kinematics, shape parameters, and sensor misalignment during a
single streamlined calibration. The system achieves state-of-the-art accuracy,
with joint angle errors of less than 2.7 degree, and outperforms commercial
alternatives in shape reconstruction and contact fidelity. FSGlove's
open-source hardware and software design ensures compatibility with current VR
and robotics ecosystems, while its ability to capture subtle motions (e.g.,
fingertip rubbing) bridges the gap between human dexterity and robotic
imitation. Evaluated against Nokov optical MoCap, FSGlove advances hand
tracking by unifying the kinematic and contact fidelity. Hardware design,
software, and more results are available at:
https://sites.google.com/view/fsglove.

</details>


### [213] [RetoVLA: Reusing Register Tokens for Spatial Reasoning in Vision-Language-Action Models](https://arxiv.org/abs/2509.21243)
*Jiyeon Koo,Taewan Cho,Hyunjoon Kang,Eunseom Pyo,Tae Gyun Oh,Taeryang Kim,Andrew Jaeyong Choi*

Main category: cs.RO

TL;DR: RetoVLA通过重用Register Tokens，在保持轻量化的同时显著提升机器人空间推理能力，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有Vision-Language-Action模型因体积和计算成本高而难以实际部署，且轻量化方法常牺牲关键能力（如空间推理），需平衡效率与性能。

Method: 提出RetoVLA架构，直接重用Vision Transformers中引入但随后被丢弃的Register Tokens，将其注入Action Expert以增强空间推理。

Result: 在7自由度机械臂上，RetoVLA在复杂操作任务中实现了17.1%的绝对成功率提升。

Conclusion: RetoVLA通过重用Register Tokens，证明了这些曾被丢弃的空间信息实际上是提升机器人空间推理能力的宝贵资源。

Abstract: Recent Vision-Language-Action (VLA) models demonstrate remarkable
generalization in robotics but are restricted by their substantial size and
computational cost, limiting real-world deployment. However, conventional
lightweighting methods often sacrifice critical capabilities, particularly
spatial reasoning. This creates a trade-off between efficiency and performance.
To address this challenge, our work reuses Register Tokens, which were
introduced for artifact removal in Vision Transformers but subsequently
discarded. We suppose that these tokens contain essential spatial information
and propose RetoVLA, a novel architecture that reuses them directly by
injecting them into the Action Expert.
  RetoVLA maintains a lightweight structure while leveraging this repurposed
spatial context to enhance reasoning. We demonstrate RetoVLA's effectiveness
through a series of comprehensive experiments. On our custom-built 7-DOF robot
arm, the model achieves a 17.1%p absolute improvement in success rates for
complex manipulation tasks. Our results confirm that reusing Register Tokens
directly enhances spatial reasoning, demonstrating that what was previously
discarded as an artifact is in fact a valuable, unexplored resource for robotic
intelligence. A video demonstration is available at:
https://youtu.be/2CseBR-snZg

</details>


### [214] [BiNoMaP: Learning Category-Level Bimanual Non-Prehensile Manipulation Primitives](https://arxiv.org/abs/2509.21256)
*Huayi Zhou,Kui Jia*

Main category: cs.RO

TL;DR: 本文提出了一种双臂非抓取操作原语（BiNoMaP）和三阶段学习框架，显著提升了非抓取操作的效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作在机器人学中是一个关键但研究不足的领域，因其接触丰富且分析复杂。本文旨在通过双臂配置和无强化学习方法解决这一问题。

Method: 提出了一个三阶段、无强化学习的框架，包括从视频演示中提取双手机器人运动轨迹、几何感知的后优化算法以及参数化学习到的操作原语。

Result: BiNoMaP 在多种双任务和不同物体类别中验证了其有效性、效率、多功能性和泛化能力。

Conclusion: BiNoMaP 通过双臂非抓取操作原语（BiNoMaP）和三阶段学习框架，展示了在非抓取操作任务中的高效性、通用性和卓越的泛化能力。

Abstract: Non-prehensile manipulation, encompassing ungraspable actions such as
pushing, poking, and pivoting, represents a critical yet underexplored domain
in robotics due to its contact-rich and analytically intractable nature. In
this work, we revisit this problem from two novel perspectives. First, we move
beyond the usual single-arm setup and the strong assumption of favorable
external dexterity such as walls, ramps, or edges. Instead, we advocate a
generalizable dual-arm configuration and establish a suite of Bimanual
Non-prehensile Manipulation Primitives (BiNoMaP). Second, we depart from the
prevailing RL-based paradigm and propose a three-stage, RL-free framework to
learn non-prehensile skills. Specifically, we begin by extracting bimanual hand
motion trajectories from video demonstrations. Due to visual inaccuracies and
morphological gaps, these coarse trajectories are difficult to transfer
directly to robotic end-effectors. To address this, we propose a geometry-aware
post-optimization algorithm that refines raw motions into executable
manipulation primitives that conform to specific motion patterns. Beyond
instance-level reproduction, we further enable category-level generalization by
parameterizing the learned primitives with object-relevant geometric
attributes, particularly size, resulting in adaptable and general parameterized
manipulation primitives. We validate BiNoMaP across a range of representative
bimanual tasks and diverse object categories, demonstrating its effectiveness,
efficiency, versatility, and superior generalization capability.

</details>


### [215] [\LARGE GMP$^{3}$: Learning-Driven, Bellman-Guided Trajectory Planning for UAVs in Real-Time on SE(3)](https://arxiv.org/abs/2509.21264)
*Babak Salamat,Dominik Mattern,Sebastian-Sven Olzem,Gerhard Elsbacher,Christian Seidel,Andrea M. Tonello*

Main category: cs.RO

TL;DR: $\text{GMP}^{3}$是一个多阶段全局路径规划框架，结合强化学习和共识机制，生成动态可行的三维轨迹。DroneManager软件支持实时部署。实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决无人机在复杂环境中生成动态可行三维轨迹的问题，并实现分布式协同路径规划。

Method: $\text{GMP}^{3}$是一个多阶段全局路径规划框架，通过扩展传统路径规划到$\mathrm{SE}(3)$李群，结合强化学习策略更新和共识机制，实现分布式路径规划。DroneManager软件通过MAVLink协议与真实无人机平台交互。

Result: 模拟和室内飞行实验验证了$\text{GMP}^{3}$在受限3D环境中的有效性，能够可靠避障并生成平滑可行的轨迹。

Conclusion: 论文提出的$\text{GMP}^{3}$框架和DroneManager软件在模拟和实际飞行实验中验证了其有效性，能够生成动态可行的三维轨迹，并支持实时部署和反馈。

Abstract: We propose $\text{GMP}^{3}$, a multiphase global path planning framework that
generates dynamically feasible three-dimensional trajectories for unmanned
aerial vehicles (UAVs) operating in cluttered environments. The framework
extends traditional path planning from Euclidean position spaces to the Lie
group $\mathrm{SE}(3)$, allowing joint learning of translational motion and
rotational dynamics. A modified Bellman-based operator is introduced to support
reinforcement learning (RL) policy updates while leveraging prior trajectory
information for improved convergence. $\text{GMP}^{3}$ is designed as a
distributed framework in which agents influence each other and share policy
information along the trajectory: each agent refines its assigned segment and
shares with its neighbors via a consensus-based scheme, enabling cooperative
policy updates and convergence toward a path shaped globally even under
kinematic constraints. We also propose DroneManager, a modular ground control
software that interfaces the planner with real UAV platforms via the MAVLink
protocol, supporting real-time deployment and feedback. Simulation studies and
indoor flight experiments validate the effectiveness of the proposed method in
constrained 3D environments, demonstrating reliable obstacle avoidance and
smooth, feasible trajectories across both position and orientation. The
open-source implementation is available at
https://github.com/Domattee/DroneManager

</details>


### [216] [Taxonomy-aware Dynamic Motion Generation on Hyperbolic Manifolds](https://arxiv.org/abs/2509.21281)
*Luis Augenstein,Noémie Jaquier,Tamim Asfour,Leonel Rozo*

Main category: cs.RO

TL;DR: GPHDM通过结合双曲流形和分类感知偏置，生成了层次化且物理一致的运动轨迹。


<details>
  <summary>Details</summary>
Motivation: 现有运动生成模型常忽视层次化运动分类提供的丰富结构信息，导致生成的运动与其底层层次结构脱节。

Method: 通过将高斯过程动态模型（GPDM）的动态先验扩展到双曲流形，并结合分类感知的归纳偏置，提出了三种新机制：两种概率递归方法和基于pullback-metric测地线的方法。

Result: 在手工抓取分类上的实验表明，GPHDM能忠实编码底层分类和时间动态，生成新颖且物理一致的运动轨迹。

Conclusion: GPHDM成功地将层次化运动分类与时间动态相结合，生成了物理一致的运动轨迹，验证了其在保持运动分类结构和时间动态方面的有效性。

Abstract: Human-like motion generation for robots often draws inspiration from
biomechanical studies, which often categorize complex human motions into
hierarchical taxonomies. While these taxonomies provide rich structural
information about how movements relate to one another, this information is
frequently overlooked in motion generation models, leading to a disconnect
between the generated motions and their underlying hierarchical structure. This
paper introduces the \ac{gphdm}, a novel approach that learns latent
representations preserving both the hierarchical structure of motions and their
temporal dynamics to ensure physical consistency. Our model achieves this by
extending the dynamics prior of the Gaussian Process Dynamical Model (GPDM) to
the hyperbolic manifold and integrating it with taxonomy-aware inductive
biases. Building on this geometry- and taxonomy-aware frameworks, we propose
three novel mechanisms for generating motions that are both
taxonomically-structured and physically-consistent: two probabilistic recursive
approaches and a method based on pullback-metric geodesics. Experiments on
generating realistic motion sequences on the hand grasping taxonomy show that
the proposed GPHDM faithfully encodes the underlying taxonomy and temporal
dynamics, and generates novel physically-consistent trajectories.

</details>
