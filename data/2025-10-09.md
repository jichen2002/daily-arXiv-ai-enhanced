<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.AI](#cs.AI) [Total: 31]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 28]
- [cs.NI](#cs.NI) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Milestone Determination for Autonomous Railway Operation](https://arxiv.org/abs/2510.06229)
*Josh Hunter,John McDermid,Simon Burton,Poppy Fynes,Mia Dempster*

Main category: cs.CV

TL;DR: 论文提出了一种基于里程碑确定的规则模型，通过生成路线特定的序列数据集，简化铁路自动化中计算机视觉系统的训练过程。


<details>
  <summary>Details</summary>
Motivation: 解决铁路自动化中计算机视觉系统开发面临的高质量序列数据不足、传统数据集范围受限以及替代方案的现实性和适用性问题。

Method: 通过专注于路线特定的上下文相关线索，生成丰富的序列数据集，并开发目标明确的规则模型，简化学习过程。

Result: 该方法能够生成更贴合实际运营逻辑的序列数据集，并通过里程碑确定简化动态组件的识别，专注于关键决策点。

Conclusion: 该论文提出了一种基于里程碑确定的规则模型，为铁路自动化中的计算机视觉系统提供了一个实用的训练框架，旨在提高系统的安全性和效率。

Abstract: In the field of railway automation, one of the key challenges has been the
development of effective computer vision systems due to the limited
availability of high-quality, sequential data. Traditional datasets are
restricted in scope, lacking the spatio temporal context necessary for
real-time decision-making, while alternative solutions introduce issues related
to realism and applicability. By focusing on route-specific, contextually
relevant cues, we can generate rich, sequential datasets that align more
closely with real-world operational logic. The concept of milestone
determination allows for the development of targeted, rule-based models that
simplify the learning process by eliminating the need for generalized
recognition of dynamic components, focusing instead on the critical decision
points along a route. We argue that this approach provides a practical
framework for training vision agents in controlled, predictable environments,
facilitating safer and more efficient machine learning systems for railway
automation.

</details>


### [2] [CML-Bench: A Framework for Evaluating and Enhancing LLM-Powered Movie Scripts Generation](https://arxiv.org/abs/2510.06231)
*Mingzhe Zheng,Dingjie Song,Guanyu Zhou,Jun You,Jiahao Zhan,Xuran Ma,Xinyuan Song,Ser-Nam Lim,Qifeng Chen,Harry Yang*

Main category: cs.CV

TL;DR: LLMs struggle with cinematic storytelling; proposed CML-Bench and CML-Instruction improve script quality.


<details>
  <summary>Details</summary>
Motivation: Investigate LLMs' deficiency in capturing nuanced storytelling and emotional depth in movie scripts.

Method: Curated CML-Dataset, proposed CML-Bench with quantitative metrics, and introduced CML-Instruction prompting strategy.

Result: CML-Bench effectively assesses script quality, and CML-Instruction improves LLM-generated screenplays.

Conclusion: LLMs guided by CML-Instruction generate higher-quality screenplays, aligning with human preferences.

Abstract: Large Language Models (LLMs) have demonstrated remarkable proficiency in
generating highly structured texts. However, while exhibiting a high degree of
structural organization, movie scripts demand an additional layer of nuanced
storytelling and emotional depth-the 'soul' of compelling cinema-that LLMs
often fail to capture. To investigate this deficiency, we first curated
CML-Dataset, a dataset comprising (summary, content) pairs for Cinematic Markup
Language (CML), where 'content' consists of segments from esteemed,
high-quality movie scripts and 'summary' is a concise description of the
content. Through an in-depth analysis of the intrinsic multi-shot continuity
and narrative structures within these authentic scripts, we identified three
pivotal dimensions for quality assessment: Dialogue Coherence (DC), Character
Consistency (CC), and Plot Reasonableness (PR). Informed by these findings, we
propose the CML-Bench, featuring quantitative metrics across these dimensions.
CML-Bench effectively assigns high scores to well-crafted, human-written
scripts while concurrently pinpointing the weaknesses in screenplays generated
by LLMs. To further validate our benchmark, we introduce CML-Instruction, a
prompting strategy with detailed instructions on character dialogue and event
logic, to guide LLMs to generate more structured and cinematically sound
scripts. Extensive experiments validate the effectiveness of our benchmark and
demonstrate that LLMs guided by CML-Instruction generate higher-quality
screenplays, with results aligned with human preferences.

</details>


### [3] [User to Video: A Model for Spammer Detection Inspired by Video Classification Technology](https://arxiv.org/abs/2510.06233)
*Haoyang Zhang,Zhou Yang,Yucai Pang*

Main category: cs.CV

TL;DR: 受视频分类启发，提出UVSD模型，通过用户像素化和行为图像化，结合视频分类技术检测垃圾用户，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 受视频分类技术启发，将用户行为子空间视为帧图像，连续帧图像视为视频，从而提出基于用户视频化的垃圾用户检测模型UVSD。

Method: 提出user2piexl算法将用户像素化，行为量化；提出behavior2image算法将用户行为子空间转化为帧图像；结合视频分类算法识别垃圾用户。

Result: 实验结果表明UVSD模型在WEIBO和TWITTER数据集上优于现有方法。

Conclusion: UVSD模型在公开数据集WEIBO和TWITTER上表现优于现有方法，验证了其有效性。

Abstract: This article is inspired by video classification technology. If the user
behavior subspace is viewed as a frame image, consecutive frame images are
viewed as a video. Following this novel idea, a model for spammer detection
based on user videoization, called UVSD, is proposed. Firstly, a user2piexl
algorithm for user pixelization is proposed. Considering the adversarial
behavior of user stances, the user is viewed as a pixel, and the stance is
quantified as the pixel's RGB. Secondly, a behavior2image algorithm is proposed
for transforming user behavior subspace into frame images. Low-rank dense
vectorization of subspace user relations is performed using representation
learning, while cutting and diffusion algorithms are introduced to complete the
frame imageization. Finally, user behavior videos are constructed based on
temporal features. Subsequently, a video classification algorithm is combined
to identify the spammers. Experiments using publicly available datasets, i.e.,
WEIBO and TWITTER, show an advantage of the UVSD model over state-of-the-art
methods.

</details>


### [4] [Uncertainty Quantification In Surface Landmines and UXO Classification Using MC Dropout](https://arxiv.org/abs/2510.06238)
*Sagar Lekhak,Emmett J. Ientilucci,Dimah Dera,Susmita Ghosh*

Main category: cs.CV

TL;DR: 该研究通过MC Dropout量化不确定性，提升了地雷和UXO分类的可靠性，尤其在对抗性和噪声条件下表现良好。


<details>
  <summary>Details</summary>
Motivation: 确定性神经网络在噪声条件和对抗性攻击下可能脆弱，导致漏检或误分类，因此需要通过不确定性量化来提升预测可靠性。

Method: 研究将蒙特卡洛（MC）Dropout集成到微调的ResNet-50架构中，用于地表地雷和未爆弹药（UXO）分类，并在模拟数据集上进行了测试。

Result: 实验结果表明，模型在干净、对抗性扰动和噪声测试图像下能够标记不可靠的预测，验证了方法的有效性。

Conclusion: 该研究强调了不确定性量化在人道主义排雷中的重要性，揭示了现有神经网络在对抗性威胁下的脆弱性，并强调了开发更鲁棒和可靠模型的必要性。

Abstract: Detecting surface landmines and unexploded ordnances (UXOs) using deep
learning has shown promise in humanitarian demining. However, deterministic
neural networks can be vulnerable to noisy conditions and adversarial attacks,
leading to missed detection or misclassification. This study introduces the
idea of uncertainty quantification through Monte Carlo (MC) Dropout, integrated
into a fine-tuned ResNet-50 architecture for surface landmine and UXO
classification, which was tested on a simulated dataset. Integrating the MC
Dropout approach helps quantify epistemic uncertainty, providing an additional
metric for prediction reliability, which could be helpful to make more informed
decisions in demining operations. Experimental results on clean, adversarially
perturbed, and noisy test images demonstrate the model's ability to flag
unreliable predictions under challenging conditions. This proof-of-concept
study highlights the need for uncertainty quantification in demining, raises
awareness about the vulnerability of existing neural networks in demining to
adversarial threats, and emphasizes the importance of developing more robust
and reliable models for practical applications.

</details>


### [5] [multimodars: A Rust-powered toolkit for multi-modality cardiac image fusion and registration](https://arxiv.org/abs/2510.06241)
*Anselm W. Stark,Marc Ilic,Ali Mokhtari,Pooya Mohammadi Kazaj,Christoph Graeni,Isaac Shiri*

Main category: cs.CV

TL;DR: multimodars是一个开放的、高性能的多模态影像融合工具包，填补了现有工具在灵活性和确定性方面的不足。


<details>
  <summary>Details</summary>
Motivation: 结合不同成像模态的优势（如高分辨率的血管内成像和3D几何的CCTA），以构建可靠的3D冠状动脉模型。

Method: 采用确定性对齐算法、紧凑的NumPy数据模型和优化的Rust后端，支持CSV/NumPy输入格式。

Result: 开发了multimodars工具包，适用于多状态分析（如休息/压力、支架植入前后），具有高性能和易用性。

Conclusion: multimodars提供了一种高效、确定性的多模态影像融合工具，填补了现有工具在灵活性、性能和管道集成方面的空白。

Abstract: Combining complementary imaging modalities is critical to build reliable 3D
coronary models: intravascular imaging gives sub-millimetre resolution but
limited whole-vessel context, while CCTA supplies 3D geometry but suffers from
limited spatial resolution and artefacts (e.g., blooming). Prior work
demonstrated intravascular/CCTA fusion, yet no open, flexible toolkit is
tailored for multi-state analysis (rest/stress, pre-/post-stenting) while
offering deterministic behaviour, high performance, and easy pipeline
integration. multimodars addresses this gap with deterministic alignment
algorithms, a compact NumPy-centred data model, and an optimised Rust backend
suitable for scalable, reproducible experiments. The package accepts CSV/NumPy
inputs including data formats produced by the AIVUS-CAA software

</details>


### [6] [Does Physics Knowledge Emerge in Frontier Models?](https://arxiv.org/abs/2510.06251)
*Ieva Bagdonaviciute,Vibhav Vineet*

Main category: cs.CV

TL;DR: 前沿视觉语言模型在物理动态理解上表现不佳，感知与物理推理能力未能有效结合，亟需改进架构。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在物理动态理解与预测方面的能力，并揭示其感知与物理推理能力之间的关系。

Method: 研究在三个物理模拟数据集（CLEVRER、Physion和Physion++）上对六个前沿VLM进行了基准测试，设计了诊断子测试以分离感知（物体、颜色、遮挡）与物理推理（运动预测、空间关系）。

Result: 分析显示感知与物理推理能力间存在弱相关性，表明当前VLM的感知与物理技能未能有效结合，导致其在预测或反事实评估中表现不一致。

Conclusion: 当前领先的视觉语言模型（VLMs）在视觉感知和一般推理上表现强劲，但在理解和预测物理动态方面的能力尚不明确。研究表明，感知与物理推理能力之间的弱相关性揭示了当前VLM的核心局限：感知与物理技能未能有效结合形成因果理解，亟需更紧密绑定感知与推理的架构。

Abstract: Leading Vision-Language Models (VLMs) show strong results in visual
perception and general reasoning, but their ability to understand and predict
physical dynamics remains unclear. We benchmark six frontier VLMs on three
physical simulation datasets - CLEVRER, Physion, and Physion++ - where the
evaluation tasks test whether a model can predict outcomes or hypothesize about
alternative situations. To probe deeper, we design diagnostic subtests that
isolate perception (objects, colors, occluders) from physics reasoning (motion
prediction, spatial relations). Intuitively, stronger diagnostic performance
should support higher evaluation accuracy. Yet our analysis reveals weak
correlations: models that excel at perception or physics reasoning do not
consistently perform better on predictive or counterfactual evaluation. This
counterintuitive gap exposes a central limitation of current VLMs: perceptual
and physics skills remain fragmented and fail to combine into causal
understanding, underscoring the need for architectures that bind perception and
reasoning more tightly.

</details>


### [7] [Enhanced Self-Distillation Framework for Efficient Spiking Neural Network Training](https://arxiv.org/abs/2510.06254)
*Xiaochen Zhao,Chengting Yu,Kairong Yu,Lei Liu,Aili Wang*

Main category: cs.CV

TL;DR: 提出了一种增强的自蒸馏框架，通过分离可靠和不可靠知识，优化SNN训练，显著降低复杂度并提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于代理梯度和BPTT的SNN训练方法在性能和计算资源消耗上存在不足，尤其在时间维度上线性增长的复杂度和内存开销限制了其应用。

Method: 提出了一个增强的自蒸馏框架，将中间SNN层的发放率投影到轻量级ANN分支上，利用模型自身生成的高质量知识通过ANN路径优化子结构。与传统自蒸馏方法不同，该方法分离了可靠和不可靠的教师信号。

Result: 在CIFAR-10、CIFAR-100、CIFAR10-DVS和ImageNet上的广泛实验表明，该方法在降低训练复杂度的同时，实现了高性能的SNN训练。

Conclusion: 通过提出的增强自蒸馏框架，结合速率反向传播，实现了在有限计算资源下高性能的SNN训练。该方法通过分离可靠和不可靠知识，优化了训练过程，显著降低了复杂度。

Abstract: Spiking Neural Networks (SNNs) exhibit exceptional energy efficiency on
neuromorphic hardware due to their sparse activation patterns. However,
conventional training methods based on surrogate gradients and Backpropagation
Through Time (BPTT) not only lag behind Artificial Neural Networks (ANNs) in
performance, but also incur significant computational and memory overheads that
grow linearly with the temporal dimension. To enable high-performance SNN
training under limited computational resources, we propose an enhanced
self-distillation framework, jointly optimized with rate-based backpropagation.
Specifically, the firing rates of intermediate SNN layers are projected onto
lightweight ANN branches, and high-quality knowledge generated by the model
itself is used to optimize substructures through the ANN pathways. Unlike
traditional self-distillation paradigms, we observe that low-quality
self-generated knowledge may hinder convergence. To address this, we decouple
the teacher signal into reliable and unreliable components, ensuring that only
reliable knowledge is used to guide the optimization of the model. Extensive
experiments on CIFAR-10, CIFAR-100, CIFAR10-DVS, and ImageNet demonstrate that
our method reduces training complexity while achieving high-performance SNN
training. Our code is available at
https://github.com/Intelli-Chip-Lab/enhanced-self-distillation-framework-for-snn.

</details>


### [8] [Validation of Various Normalization Methods for Brain Tumor Segmentation: Can Federated Learning Overcome This Heterogeneity?](https://arxiv.org/abs/2510.07126)
*Jan Fiszer,Dominika Ciupek,Maciej Malawski*

Main category: cs.CV

TL;DR: 研究表明联邦学习能有效处理医疗影像中的非独立同分布数据，保持高性能同时保护数据隐私。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在医疗影像中因数据隐私、存储和传输问题而面临的挑战，尤其是在非独立同分布数据下的联邦学习效果问题。

Method: 通过应用不同的MRI强度归一化技术模拟非独立同分布条件，研究使用这些子集进行脑肿瘤分割模型的训练和测试。

Result: FL方法在客户端间数据归一化不一致的情况下表现出韧性，达到3D Dice分数92%，与集中式模型性能相当。

Conclusion: 联邦学习（FL）在医疗影像中展示了其在不侵犯数据隐私的情况下有效训练高性能模型的潜力，尤其在处理非独立同分布（non-IID）数据时表现出色。

Abstract: Deep learning (DL) has been increasingly applied in medical imaging, however,
it requires large amounts of data, which raises many challenges related to data
privacy, storage, and transfer. Federated learning (FL) is a training paradigm
that overcomes these issues, though its effectiveness may be reduced when
dealing with non-independent and identically distributed (non-IID) data. This
study simulates non-IID conditions by applying different MRI intensity
normalization techniques to separate data subsets, reflecting a common cause of
heterogeneity. These subsets are then used for training and testing models for
brain tumor segmentation. The findings provide insights into the influence of
the MRI intensity normalization methods on segmentation models, both training
and inference. Notably, the FL methods demonstrated resilience to
inconsistently normalized data across clients, achieving the 3D Dice score of
92%, which is comparable to a centralized model (trained using all data). These
results indicate that FL is a solution to effectively train high-performing
models without violating data privacy, a crucial concern in medical
applications. The code is available at:
https://github.com/SanoScience/fl-varying-normalization.

</details>


### [9] [Ensemble Deep Learning and LLM-Assisted Reporting for Automated Skin Lesion Diagnosis](https://arxiv.org/abs/2510.06260)
*Sher Khan,Raz Muhammad,Adil Hussain,Muhammad Sajjad,Muhammad Rashid*

Main category: cs.CV

TL;DR: 提出了一种结合异构神经网络和语言模型的皮肤病AI诊断框架，提升了诊断可靠性和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 解决当前皮肤病诊断中存在的观察者差异、数据集偏见以及AI与临床工作流程脱节的问题。

Method: 提出了一种异构卷积神经网络集成框架，并结合大型语言模型能力，直接生成临床报告。

Result: 开发了一个统一的系统，能够提高诊断准确性，同时生成结构化的临床报告和患者教育材料。

Conclusion: 该框架通过整合异构神经网络和大型语言模型，显著提升了皮肤病AI诊断的可靠性和临床应用性，为早期干预提供了有力支持。

Abstract: Cutaneous malignancies demand early detection for favorable outcomes, yet
current diagnostics suffer from inter-observer variability and access
disparities. While AI shows promise, existing dermatological systems are
limited by homogeneous architectures, dataset biases across skin tones, and
fragmented approaches that treat natural language processing as separate
post-hoc explanations rather than integral to clinical decision-making. We
introduce a unified framework that fundamentally reimagines AI integration for
dermatological diagnostics through two synergistic innovations. First, a
purposefully heterogeneous ensemble of architecturally diverse convolutional
neural networks provides complementary diagnostic perspectives, with an
intrinsic uncertainty mechanism flagging discordant cases for specialist review
-- mimicking clinical best practices. Second, we embed large language model
capabilities directly into the diagnostic workflow, transforming classification
outputs into clinically meaningful assessments that simultaneously fulfill
medical documentation requirements and deliver patient-centered education. This
seamless integration generates structured reports featuring precise lesion
characterization, accessible diagnostic reasoning, and actionable monitoring
guidance -- empowering patients to recognize early warning signs between
visits. By addressing both diagnostic reliability and communication barriers
within a single cohesive system, our approach bridges the critical
translational gap that has prevented previous AI implementations from achieving
clinical impact. The framework represents a significant advancement toward
deployable dermatological AI that enhances diagnostic precision while actively
supporting the continuum of care from initial detection through patient
education, ultimately improving early intervention rates for skin lesions.

</details>


### [10] [Vision Transformer for Transient Noise Classification](https://arxiv.org/abs/2510.06273)
*Divyansh Srivastava,Andrzej Niedzielski*

Main category: cs.CV

TL;DR: 利用Vision Transformer模型对LIGO数据中的瞬态噪声进行分类，效率达92.26%，提升引力波检测准确性。


<details>
  <summary>Details</summary>
Motivation: LIGO数据中的瞬态噪声（glitches）阻碍了引力波的检测，需要有效分类方法以提高检测准确性。

Method: 使用预训练的Vision Transformer (ViT-B/32)模型，结合Gravity Spy数据集和LIGO O3a运行中的两个新增噪声类别进行训练。

Result: 分类效率达到92.26%，证明ViT模型在区分瞬态噪声方面的有效性。

Conclusion: Vision Transformer (ViT) 模型在LIGO数据中有效分类瞬态噪声（glitches），分类效率达92.26%，展示了其在提高引力波检测准确性方面的潜力。

Abstract: Transient noise (glitches) in LIGO data hinders the detection of
gravitational waves (GW). The Gravity Spy project has categorized these noise
events into various classes. With the O3 run, there is the inclusion of two
additional noise classes and thus a need to train new models for effective
classification. We aim to classify glitches in LIGO data into 22 existing
classes from the first run plus 2 additional noise classes from O3a using the
Vision Transformer (ViT) model. We train a pre-trained Vision Transformer
(ViT-B/32) model on a combined dataset consisting of the Gravity Spy dataset
with the additional two classes from the LIGO O3a run. We achieve a
classification efficiency of 92.26%, demonstrating the potential of Vision
Transformer to improve the accuracy of gravitational wave detection by
effectively distinguishing transient noise.
  Key words: gravitational waves --vision transformer --machine learning

</details>


### [11] [General and Efficient Visual Goal-Conditioned Reinforcement Learning using Object-Agnostic Masks](https://arxiv.org/abs/2510.06277)
*Fahim Shahriar,Cheryl Wang,Alireza Azimi,Gautham Vasan,Hany Hamed Elanwar,A. Rupam Mahmood,Colin Bellinger*

Main category: cs.CV

TL;DR: 提出了一种掩码目标表示方法，解决了现有方法的泛化与效率问题，实验证明其高效且适用于实际机器人任务。


<details>
  <summary>Details</summary>
Motivation: 现有目标表示方法（如目标状态图像、3D坐标和独热向量）存在泛化能力差、收敛慢和依赖特殊摄像头的问题。

Method: 提出了一种基于掩码的目标表示方法，通过对象无关的视觉线索实现高效学习，并利用密集奖励避免误差距离计算。

Result: 在模拟环境中使用真实掩码训练，达到了99.9%的到达准确率，并在实际机器人任务中展示了从零学习和模拟到现实的迁移能力。

Conclusion: 基于掩码的目标表示系统在目标条件强化学习中表现出色，能够实现高效学习和卓越的泛化能力，适用于实际机器人任务。

Abstract: Goal-conditioned reinforcement learning (GCRL) allows agents to learn diverse
objectives using a unified policy. The success of GCRL, however, is contingent
on the choice of goal representation. In this work, we propose a mask-based
goal representation system that provides object-agnostic visual cues to the
agent, enabling efficient learning and superior generalization. In contrast,
existing goal representation methods, such as target state images, 3D
coordinates, and one-hot vectors, face issues of poor generalization to unseen
objects, slow convergence, and the need for special cameras. Masks can be
processed to generate dense rewards without requiring error-prone distance
calculations. Learning with ground truth masks in simulation, we achieved 99.9%
reaching accuracy on training and unseen test objects. Our proposed method can
be utilized to perform pick-up tasks with high accuracy, without using any
positional information of the target. Moreover, we demonstrate learning from
scratch and sim-to-real transfer applications using two different physical
robots, utilizing pretrained open vocabulary object detection models for mask
generation.

</details>


### [12] [Improving the Spatial Resolution of GONG Solar Images to GST Quality Using Deep Learning](https://arxiv.org/abs/2510.06281)
*Chenyang Li,Qin Li,Haimin Wang,Bo Shen*

Main category: cs.CV

TL;DR: 使用GAN超分辨率技术提升低分辨率Hα图像质量，接近高分辨率观测水平，但存在轻微未对齐问题需未来改进。


<details>
  <summary>Details</summary>
Motivation: 全盘Hα图像的空间分辨率不足，无法解析太阳动态特征（如纤维和细丝），需通过超分辨率技术提升图像质量。

Method: 采用Real-ESRGAN模型，结合Residual-in-Residual Dense Blocks和相对论判别器，对GONG-GST图像对进行超分辨率重建。

Result: 模型有效恢复了太阳黑子半影的细节，并解析了纤维和细丝的细微结构，平均MSE为467.15，RMSE为21.59，CC为0.7794。

Conclusion: 通过GAN超分辨率方法成功提升了GONG低分辨率Hα图像的质量，使其接近BBSO/GST的高分辨率观测水平，但图像对轻微未对齐问题限制了定量性能，未来计划通过数据集扩展进一步改进重建质量。

Abstract: High-resolution (HR) solar imaging is crucial for capturing fine-scale
dynamic features such as filaments and fibrils. However, the spatial resolution
of the full-disk H$\alpha$ images is limited and insufficient to resolve these
small-scale structures. To address this, we propose a GAN-based superresolution
approach to enhance low-resolution (LR) full-disk H$\alpha$ images from the
Global Oscillation Network Group (GONG) to a quality comparable with HR
observations from the Big Bear Solar Observatory/Goode Solar Telescope
(BBSO/GST). We employ Real-ESRGAN with Residual-in-Residual Dense Blocks and a
relativistic discriminator. We carefully aligned GONG-GST pairs. The model
effectively recovers fine details within sunspot penumbrae and resolves fine
details in filaments and fibrils, achieving an average mean squared error (MSE)
of 467.15, root mean squared error (RMSE) of 21.59, and cross-correlation (CC)
of 0.7794. Slight misalignments between image pairs limit quantitative
performance, which we plan to address in future work alongside dataset
expansion to further improve reconstruction quality.

</details>


### [13] [ChainMPQ: Interleaved Text-Image Reasoning Chains for Mitigating Relation Hallucinations](https://arxiv.org/abs/2510.06292)
*Yike Wu,Yiwei Wang,Yujun Cai*

Main category: cs.CV

TL;DR: ChainMPQ通过多视角问题和图像与文本的交替链，显著减少了大型视觉语言模型中的关系幻觉。


<details>
  <summary>Details</summary>
Motivation: 关系幻觉在大型视觉语言模型中占比最大但关注最少，影响了模型的可靠性，因此需要一种有效的方法来改善关系推理。

Method: ChainMPQ是一种无需训练的方法，通过提取主题和对象关键词增强图像区域，并构建多视角问题（关注关系的主体、客体及关系本身），逐步输入模型以形成交替链。

Result: 实验表明，ChainMPQ显著减少了关系幻觉，消融研究进一步验证了其三个核心模块的有效性。

Conclusion: ChainMPQ通过多视角问题和图像与文本的交替链，显著减少了大型视觉语言模型中的关系幻觉，并通过实验验证了其核心模块的有效性。

Abstract: While Large Vision-Language Models (LVLMs) achieve strong performance in
multimodal tasks, hallucinations continue to hinder their reliability. Among
the three categories of hallucinations, which include object, attribute, and
relation, relation hallucinations account for the largest proportion but have
received the least attention. To address this issue, we propose ChainMPQ
(Multi-Perspective Questions guided Interleaved Chain of Image and Text), a
training-free method that improves relational inference in LVLMs by utilizing
accumulated textual and visual memories. ChainMPQ first extracts subject and
object keywords from the question to enhance the corresponding image regions.
It then constructs multi-perspective questions that focus on the three core
components of a relationship: the subject, the object, and the relation that
links them. These questions are sequentially input to the model, with textual
and visual memories from earlier steps providing supporting context for
subsequent ones, thereby forming an interleaved chain of images and text that
guides progressive relational reasoning. Experiments on multiple LVLMs and
benchmarks show that ChainMPQ substantially reduces relation hallucinations,
while ablation studies further validate the effectiveness of its three core
modules.

</details>


### [14] [Efficient High-Resolution Image Editing with Hallucination-Aware Loss and Adaptive Tiling](https://arxiv.org/abs/2510.06295)
*Young D. Kwon,Abhinav Mehrotra,Malcolm Chadwick,Alberto Gil Ramos,Sourav Bhattacharya*

Main category: cs.CV

TL;DR: MobilePicasso 是一种高效的高分辨率图像编辑系统，通过三阶段方法显著提升图像质量并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在资源受限设备上部署时面临内存和图像质量的挑战。

Method: MobilePicasso 包含三个阶段：标准分辨率下的图像编辑、潜空间投影以及自适应上下文保留分块的高分辨率上采样。

Result: MobilePicasso 在图像质量上提升了 18-48%，减少了 14-51% 的幻觉，并实现了高达 55.8 倍的加速，仅增加 9% 的内存使用。

Conclusion: MobilePicasso 是一种高效的高分辨率图像编辑系统，显著提升了图像质量并减少了幻觉，同时在计算成本和内存使用上实现了优化。

Abstract: High-resolution (4K) image-to-image synthesis has become increasingly
important for mobile applications. Existing diffusion models for image editing
face significant challenges, in terms of memory and image quality, when
deployed on resource-constrained devices. In this paper, we present
MobilePicasso, a novel system that enables efficient image editing at high
resolutions, while minimising computational cost and memory usage.
MobilePicasso comprises three stages: (i) performing image editing at a
standard resolution with hallucination-aware loss, (ii) applying latent
projection to overcome going to the pixel space, and (iii) upscaling the edited
image latent to a higher resolution with adaptive context-preserving tiling.
Our user study with 46 participants reveals that MobilePicasso not only
improves image quality by 18-48% but reduces hallucinations by 14-51% over
existing methods. MobilePicasso demonstrates significantly lower latency, e.g.,
up to 55.8$\times$ speed-up, yet with a small increase in runtime memory, e.g.,
a mere 9% increase over prior work. Surprisingly, the on-device runtime of
MobilePicasso is observed to be faster than a server-based high-resolution
image editing model running on an A100 GPU.

</details>


### [15] [RGBD Gaze Tracking Using Transformer for Feature Fusion](https://arxiv.org/abs/2510.06298)
*Tobias J. Bauer*

Main category: cs.CV

TL;DR: 论文提出了一种基于RGBD和Transformer的注视跟踪系统，实验表明不使用预训练GAN和用MLP替代Transformer能显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有数据集要么缺乏深度信息，要么仅包含不适合注视角度估计的注视点标签，因此需要创建新数据集并探索RGBD图像与Transformer的结合。

Method: 使用RGBD图像和Transformer架构进行特征融合，训练了多种模型配置，并在三个不同数据集上进行了验证和评估。

Result: 在ShanghaiTechGaze+数据集上，使用Transformer模块的模型平均欧几里得误差为55.3mm，不使用预训练GAN模块的误差降至30.1mm，用MLP替代Transformer模块后误差进一步降至26.9mm。在ETH-XGaze数据集上，Transformer模块的平均角度误差为3.59°，不使用时为3.26°。

Conclusion: 论文提出了一种基于RGBD图像和Transformer架构的AI注视跟踪系统，通过实验证明，不使用预训练的GAN模块可以显著降低平均欧几里得误差。此外，用多层感知机（MLP）替代Transformer模块进一步提升了性能。

Abstract: Subject of this thesis is the implementation of an AI-based Gaze Tracking
system using RGBD images that contain both color (RGB) and depth (D)
information. To fuse the features extracted from the images, a module based on
the Transformer architecture is used. The combination of RGBD input images and
Transformers was chosen because it has not yet been investigated. Furthermore,
a new dataset is created for training the AI models as existing datasets either
do not contain depth information or only contain labels for Gaze Point
Estimation that are not suitable for the task of Gaze Angle Estimation. Various
model configurations are trained, validated and evaluated on a total of three
different datasets. The trained models are then to be used in a real-time
pipeline to estimate the gaze direction and thus the gaze point of a person in
front of a computer screen. The AI model architecture used in this thesis is
based on an earlier work by Lian et al. It uses a Generative Adversarial
Network (GAN) to simultaneously remove depth map artifacts and extract head
pose features. Lian et al. achieve a mean Euclidean error of 38.7mm on their
own dataset ShanghaiTechGaze+. In this thesis, a model architecture with a
Transformer module for feature fusion achieves a mean Euclidean error of 55.3mm
on the same dataset, but we show that using no pre-trained GAN module leads to
a mean Euclidean error of 30.1mm. Replacing the Transformer module with a
Multilayer Perceptron (MLP) improves the error to 26.9mm. These results are
coherent with the ones on the other two datasets. On the ETH-XGaze dataset, the
model with Transformer module achieves a mean angular error of 3.59{\deg} and
without Transformer module 3.26{\deg}, whereas the fundamentally different
model architecture used by the dataset authors Zhang et al. achieves a mean
angular error of 2.04{\deg}. On the OTH-Gaze-Estimation dataset created for...

</details>


### [16] [Scalable deep fusion of spaceborne lidar and synthetic aperture radar for global forest structural complexity mapping](https://arxiv.org/abs/2510.06299)
*Tiago de Conto,John Armston,Ralph Dubayah*

Main category: cs.CV

TL;DR: 该研究开发了一个深度学习框架，结合GEDI和SAR数据，生成全球高分辨率森林结构复杂性地图，支持连续监测并为生态管理提供工具。


<details>
  <summary>Details</summary>
Motivation: 森林结构复杂性指标综合了多个冠层属性，反映了栖息地质量和生态系统功能。然而，GEDI的稀疏采样限制了高分辨率连续制图的能力，因此需要一种可扩展的方法来填补这一空白。

Method: 研究采用了改进的EfficientNetV2架构，训练了超过1.3亿个GEDI足迹，实现了高性能（全球R2 = 0.82）且参数少于40万的模型，使其成为一个易于使用的工具，无需专用计算基础设施。

Result: 模型在全球范围内表现优异（R2 = 0.82），能够生成具有校准不确定性估计的准确预测，并保留精细的空间模式。研究还生成了2015年至2022年的全球多时相森林结构复杂性数据集。

Conclusion: 通过结合GEDI观测数据与多模态SAR数据集，该研究开发了一个可扩展的深度学习框架，能够生成全球高分辨率的森林结构复杂性地图。这一方法支持连续、多时相的全球森林结构动态监测，并为生物多样性保护和生态系统管理提供了有力工具。

Abstract: Forest structural complexity metrics integrate multiple canopy attributes
into a single value that reflects habitat quality and ecosystem function.
Spaceborne lidar from the Global Ecosystem Dynamics Investigation (GEDI) has
enabled mapping of structural complexity in temperate and tropical forests, but
its sparse sampling limits continuous high-resolution mapping. We present a
scalable, deep learning framework fusing GEDI observations with multimodal
Synthetic Aperture Radar (SAR) datasets to produce global, high-resolution (25
m) wall-to-wall maps of forest structural complexity. Our adapted
EfficientNetV2 architecture, trained on over 130 million GEDI footprints,
achieves high performance (global R2 = 0.82) with fewer than 400,000
parameters, making it an accessible tool that enables researchers to process
datasets at any scale without requiring specialized computing infrastructure.
The model produces accurate predictions with calibrated uncertainty estimates
across biomes and time periods, preserving fine-scale spatial patterns. It has
been used to generate a global, multi-temporal dataset of forest structural
complexity from 2015 to 2022. Through transfer learning, this framework can be
extended to predict additional forest structural variables with minimal
computational cost. This approach supports continuous, multi-temporal
monitoring of global forest structural dynamics and provides tools for
biodiversity conservation and ecosystem management efforts in a changing
climate.

</details>


### [17] [Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding](https://arxiv.org/abs/2510.06308)
*Yi Xin,Qi Qin,Siqi Luo,Kaiwen Zhu,Juncheng Yan,Yan Tai,Jiayi Lei,Yuewen Cao,Keqi Wang,Yibin Wang,Jinbin Bai,Qian Yu,Dengyang Jiang,Yuandong Pu,Haoxing Chen,Le Zhuo,Junjun He,Gen Luo,Tianbin Li,Ming Hu,Jin Ye,Shenglong Ye,Bo Zhang,Chang Xu,Wenhai Wang,Hongsheng Li,Guangtao Zhai,Tianfan Xue,Bin Fu,Xiaohong Liu,Yu Qiao,Yihao Liu*

Main category: cs.CV

TL;DR: Lumina-DiMOO是一种基于离散扩散建模的多模态生成和理解模型，采样效率高，支持多种任务，性能领先并已开源。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有统一模型在多模态生成和理解任务中的局限性，提出了一种创新的离散扩散建模方法。

Method: 采用完全离散的扩散建模来处理各种模态的输入和输出，相较于先前的自回归或混合自回归-扩散范式，具有更高的采样效率。

Result: 在多个基准测试中表现优异，超越了现有的开源统一多模态模型。

Conclusion: Lumina-DiMOO通过完全离散的扩散建模实现了多模态生成和理解，并在多个基准测试中达到了最先进的性能，推动了多模态和离散扩散模型的研究发展。

Abstract: We introduce Lumina-DiMOO, an open-source foundational model for seamless
multi-modal generation and understanding. Lumina-DiMOO sets itself apart from
prior unified models by utilizing a fully discrete diffusion modeling to handle
inputs and outputs across various modalities. This innovative approach allows
Lumina-DiMOO to achieve higher sampling efficiency compared to previous
autoregressive (AR) or hybrid AR-Diffusion paradigms and adeptly support a
broad spectrum of multi-modal tasks, including text-to-image generation,
image-to-image generation (e.g., image editing, subject-driven generation, and
image inpainting, etc.), as well as image understanding. Lumina-DiMOO achieves
state-of-the-art performance on multiple benchmarks, surpassing existing
open-source unified multi-modal models. To foster further advancements in
multi-modal and discrete diffusion model research, we release our code and
checkpoints to the community. Project Page:
https://synbol.github.io/Lumina-DiMOO.

</details>


### [18] [TransFIRA: Transfer Learning for Face Image Recognizability Assessment](https://arxiv.org/abs/2510.06353)
*Allen Tu,Kartik Narayan,Joshua Gleason,Jennifer Xu,Matthew Meyn,Tom Goldstein,Vishal M. Patel*

Main category: cs.CV

TL;DR: TransFIRA是一个轻量级、无需标注的人脸图像可识别性评估框架，通过嵌入空间直接衡量可识别性，实现了最先进的验证准确性和可解释性，并扩展至身体识别。


<details>
  <summary>Details</summary>
Motivation: 在无约束环境中进行人脸识别需应对极端姿态、模糊、光照和遮挡变化，传统视觉质量指标难以预测输入是否真正可被编码器识别。现有FIQA方法依赖视觉启发式、标注或计算密集型生成流程，预测结果与编码器决策几何脱节。

Method: TransFIRA采用轻量级且无需标注的框架，通过嵌入空间直接衡量可识别性，定义了类中心相似性（CCS）和类中心角度分离（CCAS）作为可识别性标准，并提出了可识别性信息聚合策略。

Result: TransFIRA在BRIAR和IJB-C上实现了最先进的验证准确性，与真实可识别性的相关性几乎翻倍，且无需外部标签、启发式或特定主干训练。实验还证实了其在身体识别中的强性能和跨数据集鲁棒性。

Conclusion: TransFIRA被确立为一个统一的、几何驱动的可识别性评估框架，具有编码器特定性、准确性、可解释性和跨模态扩展性，显著提升了FIQA在准确性、可解释性和范围方面的表现。

Abstract: Face recognition in unconstrained environments such as surveillance, video,
and web imagery must contend with extreme variation in pose, blur,
illumination, and occlusion, where conventional visual quality metrics fail to
predict whether inputs are truly recognizable to the deployed encoder. Existing
FIQA methods typically rely on visual heuristics, curated annotations, or
computationally intensive generative pipelines, leaving their predictions
detached from the encoder's decision geometry. We introduce TransFIRA (Transfer
Learning for Face Image Recognizability Assessment), a lightweight and
annotation-free framework that grounds recognizability directly in embedding
space. TransFIRA delivers three advances: (i) a definition of recognizability
via class-center similarity (CCS) and class-center angular separation (CCAS),
yielding the first natural, decision-boundary--aligned criterion for filtering
and weighting; (ii) a recognizability-informed aggregation strategy that
achieves state-of-the-art verification accuracy on BRIAR and IJB-C while nearly
doubling correlation with true recognizability, all without external labels,
heuristics, or backbone-specific training; and (iii) new extensions beyond
faces, including encoder-grounded explainability that reveals how degradations
and subject-specific factors affect recognizability, and the first
recognizability-aware body recognition assessment. Experiments confirm
state-of-the-art results on faces, strong performance on body recognition, and
robustness under cross-dataset shifts. Together, these contributions establish
TransFIRA as a unified, geometry-driven framework for recognizability
assessment -- encoder-specific, accurate, interpretable, and extensible across
modalities -- significantly advancing FIQA in accuracy, explainability, and
scope.

</details>


### [19] [Road Surface Condition Detection with Machine Learning using New York State Department of Transportation Camera Images and Weather Forecast Data](https://arxiv.org/abs/2510.06440)
*Carly Sutter,Kara J. Sulia,Nick P. Bassill,Christopher D. Wirz,Christopher D. Thorncroft,Jay C. Rothenberger,Vanessa Przybylo,Mariana G. Cains,Jacob Radford,David Aaron Evans*

Main category: cs.CV

TL;DR: 研究利用卷积神经网络和随机森林自动分类纽约州道路状况，模型准确率达81.5%，助力NYSDOT决策。


<details>
  <summary>Details</summary>
Motivation: NYSDOT目前依赖人工驾驶和实时摄像头观察道路状况，任务繁重且耗时。机器学习模型可以自动分类道路状况，提升效率并支持冬季天气事件中的关键决策。

Method: 研究使用了卷积神经网络和随机森林模型，结合摄像头图像和天气数据进行训练。数据集包含约22,000张人工标记的图像，分为六种道路表面状况。

Result: 模型在完全未见过的摄像头数据上实现了81.5%的准确率，展示了良好的泛化能力。

Conclusion: 该研究通过训练卷积神经网络和随机森林模型，成功实现了对纽约州道路表面状况的自动分类，模型在未见过的摄像头数据上达到了81.5%的准确率，为NYSDOT的决策提供了有效支持。

Abstract: The New York State Department of Transportation (NYSDOT) has a network of
roadside traffic cameras that are used by both the NYSDOT and the public to
observe road conditions. The NYSDOT evaluates road conditions by driving on
roads and observing live cameras, tasks which are labor-intensive but necessary
for making critical operational decisions during winter weather events.
However, machine learning models can provide additional support for the NYSDOT
by automatically classifying current road conditions across the state. In this
study, convolutional neural networks and random forests are trained on camera
images and weather data to predict road surface conditions. Models are trained
on a hand-labeled dataset of ~22,000 camera images, each classified by human
labelers into one of six road surface conditions: severe snow, snow, wet, dry,
poor visibility, or obstructed. Model generalizability is prioritized to meet
the operational needs of the NYSDOT decision makers, and the weather-related
road surface condition model in this study achieves an accuracy of 81.5% on
completely unseen cameras.

</details>


### [20] [TDiff: Thermal Plug-And-Play Prior with Patch-Based Diffusion](https://arxiv.org/abs/2510.06460)
*Piyush Dashpute,Niki Nezakati,Wolfgang Heidrich,Vishwanath Saragadam*

Main category: cs.CV

TL;DR: TDiff是一种基于块的扩散框架，用于解决热成像图像的低分辨率和噪声问题，在多个恢复任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 低成本热成像相机图像存在低分辨率、固定模式噪声等局部退化问题，且现有数据集规模和多样性有限。

Method: 论文提出了一种基于块的扩散框架（TDiff），通过在小块热图像上训练，利用平滑空间窗口技术对重叠块进行去噪和融合，从而恢复全分辨率图像。

Result: 实验表明，TDiff在模拟和真实热数据上的去噪、超分辨率和去模糊任务中均取得了显著效果。

Conclusion: 该论文提出的TDiff方法通过基于块的扩散框架，成功解决了低成本热成像相机图像的低分辨率、固定模式噪声等问题，并在去噪、超分辨率和去模糊等多个任务中展现了强大的性能。

Abstract: Thermal images from low-cost cameras often suffer from low resolution, fixed
pattern noise, and other localized degradations. Available datasets for thermal
imaging are also limited in both size and diversity. To address these
challenges, we propose a patch-based diffusion framework (TDiff) that leverages
the local nature of these distortions by training on small thermal patches. In
this approach, full-resolution images are restored by denoising overlapping
patches and blending them using smooth spatial windowing. To our knowledge,
this is the first patch-based diffusion framework that models a learned prior
for thermal image restoration across multiple tasks. Experiments on denoising,
super-resolution, and deblurring demonstrate strong results on both simulated
and real thermal data, establishing our method as a unified restoration
pipeline.

</details>


### [21] [SIGMA-GEN: Structure and Identity Guided Multi-subject Assembly for Image Generation](https://arxiv.org/abs/2510.06469)
*Oindrila Saha,Vojtech Krs,Radomir Mech,Subhransu Maji,Kevin Blackburn-Matzen,Matheus Gadelha*

Main category: cs.CV

TL;DR: SIGMA-GEN 是一个多身份保留图像生成框架，通过结构和空间约束实现高效、高质量的单次生成。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法无法在单次生成中同时保留多主体身份的问题，并支持多级别用户引导。

Method: SIGMA-GEN 结合了结构和空间约束，支持从粗粒度（如2D/3D框）到细粒度（如像素级分割和深度）的用户引导，使用单一模型实现。

Result: SIGMA-GEN 在身份保留、图像生成质量和速度方面达到了最先进的性能。

Conclusion: SIGMA-GEN 是一个统一的框架，能够在单次生成中保留多主体身份，并通过结构和空间约束实现高质量图像生成。

Abstract: We present SIGMA-GEN, a unified framework for multi-identity preserving image
generation. Unlike prior approaches, SIGMA-GEN is the first to enable
single-pass multi-subject identity-preserved generation guided by both
structural and spatial constraints. A key strength of our method is its ability
to support user guidance at various levels of precision -- from coarse 2D or 3D
boxes to pixel-level segmentations and depth -- with a single model. To enable
this, we introduce SIGMA-SET27K, a novel synthetic dataset that provides
identity, structure, and spatial information for over 100k unique subjects
across 27k images. Through extensive evaluation we demonstrate that SIGMA-GEN
achieves state-of-the-art performance in identity preservation, image
generation quality, and speed. Code and visualizations at
https://oindrilasaha.github.io/SIGMA-Gen/

</details>


### [22] [Superpixel Integrated Grids for Fast Image Segmentation](https://arxiv.org/abs/2510.06487)
*Jack Roberts,Jeova Farias Sales Rocha Neto*

Main category: cs.CV

TL;DR: SIGRID是一种新的超像素数据结构，通过编码颜色和形状信息降低输入维度，在分割任务中既保持性能又加速训练。


<details>
  <summary>Details</summary>
Motivation: 尽管超像素在图像简化中具有计算潜力，但其不规则的空间分布迫使深度学习依赖专门的训练算法和架构，这削弱了超像素化的初衷。

Method: 通过利用经典的形状描述符，SIGRID编码了超像素的颜色和形状信息，同时大幅降低了输入维度。

Result: 在四个基准数据集上使用两种流行的卷积分割架构评估SIGRID，结果显示其不仅匹配而且在某些情况下超越像素级表示的性能。

Conclusion: SIGRID（Superpixel-Integrated Grid）在保持甚至在某些情况下超越像素级表示性能的同时，显著加速了模型训练，实现了准确性与计算效率之间的有利平衡。

Abstract: Superpixels have long been used in image simplification to enable more
efficient data processing and storage. However, despite their computational
potential, their irregular spatial distribution has often forced deep learning
approaches to rely on specialized training algorithms and architectures,
undermining the original motivation for superpixelations. In this work, we
introduce a new superpixel-based data structure, SIGRID (Superpixel-Integrated
Grid), as an alternative to full-resolution images in segmentation tasks. By
leveraging classical shape descriptors, SIGRID encodes both color and shape
information of superpixels while substantially reducing input dimensionality.
We evaluate SIGRIDs on four benchmark datasets using two popular convolutional
segmentation architectures. Our results show that, despite compressing the
original data, SIGRIDs not only match but in some cases surpass the performance
of pixel-level representations, all while significantly accelerating model
training. This demonstrates that SIGRIDs achieve a favorable balance between
accuracy and computational efficiency.

</details>


### [23] [Text2Interact: High-Fidelity and Diverse Text-to-Two-Person Interaction Generation](https://arxiv.org/abs/2510.06504)
*Qingxuan Wu,Zhiyang Dou,Chuan Guo,Yiming Huang,Qiao Feng,Bing Zhou,Jian Wang,Lingjie Liu*

Main category: cs.CV

TL;DR: 论文提出了Text2Interact框架，通过可扩展的数据合成器和细粒度文本条件化，解决了人-人交互建模中的数据不足和文本对齐问题，显著提升了交互的多样性和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前人-人交互建模面临两大挑战：1) 有限的两人训练数据无法捕捉交互的多样性；2) 文本到交互的建模不够细粒度，语言条件化将丰富的结构化提示压缩为单一句子嵌入。

Method: 论文提出了InterCompose（可扩展的合成-组合管道）和InterActor（具有词级条件化的文本到交互模型）。InterCompose通过检索候选单人运动、训练条件反应生成器并使用神经运动评估器过滤弱样本，扩展了交互覆盖范围。InterActor则通过保留令牌级提示和自适应交互损失，改善了细粒度交互建模。

Result: 实验结果表明，Text2Interact框架在运动多样性、保真度和泛化能力（包括分布外场景和用户研究）上均取得了显著提升。

Conclusion: 论文提出了Text2Interact框架，通过可扩展的高保真交互数据合成器和有效的时空协调管道，生成了真实且与文本对齐的人-人交互。实验表明，该方法在运动多样性、保真度和泛化能力方面均取得了显著提升。

Abstract: Modeling human-human interactions from text remains challenging because it
requires not only realistic individual dynamics but also precise,
text-consistent spatiotemporal coupling between agents. Currently, progress is
hindered by 1) limited two-person training data, inadequate to capture the
diverse intricacies of two-person interactions; and 2) insufficiently
fine-grained text-to-interaction modeling, where language conditioning
collapses rich, structured prompts into a single sentence embedding. To address
these limitations, we propose our Text2Interact framework, designed to generate
realistic, text-aligned human-human interactions through a scalable
high-fidelity interaction data synthesizer and an effective spatiotemporal
coordination pipeline. First, we present InterCompose, a scalable
synthesis-by-composition pipeline that aligns LLM-generated interaction
descriptions with strong single-person motion priors. Given a prompt and a
motion for an agent, InterCompose retrieves candidate single-person motions,
trains a conditional reaction generator for another agent, and uses a neural
motion evaluator to filter weak or misaligned samples-expanding interaction
coverage without extra capture. Second, we propose InterActor, a
text-to-interaction model with word-level conditioning that preserves
token-level cues (initiation, response, contact ordering) and an adaptive
interaction loss that emphasizes contextually relevant inter-person joint
pairs, improving coupling and physical plausibility for fine-grained
interaction modeling. Extensive experiments show consistent gains in motion
diversity, fidelity, and generalization, including out-of-distribution
scenarios and user studies. We will release code and models to facilitate
reproducibility.

</details>


### [24] [From Captions to Keyframes: Efficient Video Summarization via Caption- and Context-Aware Frame Scoring](https://arxiv.org/abs/2510.06509)
*Shih-Yao Lin,Sibendu Paul,Caren Chen*

Main category: cs.CV

TL;DR: KeyScore和STACFP结合，通过多模态帧评分和自适应聚类，实现高效视频语言理解，显著减少帧数并提升性能。


<details>
  <summary>Details</summary>
Motivation: 高效视频语言理解需要从长视频中选择少量保留语义和上下文信息的帧。

Method: 论文提出了KeyScore，一个多模态帧评分框架，结合了语义相似性、时间多样性和上下文丢弃影响，以及STACFP（时空自适应聚类帧提案生成器），用于长视频生成紧凑且多样的帧候选。

Result: 与全帧推理相比，这些模块实现了高达99%的帧减少，并在MSRVTT、MSVD和DiDeMo数据集上显著优于标准的8帧编码器。

Conclusion: 通过结合KeyScore和STACFP，论文展示了在多模态视频语言理解中，强调视觉与文本信号的对齐能够实现高效、可扩展且基于字幕的视频理解，无需显式视频摘要。

Abstract: Efficient video-language understanding requires selecting a small set of
frames that retain semantic and contextual information from long videos. We
propose KeyScore, a multimodal frame scoring framework that jointly leverages
captions and visual context to estimate frame-level importance. By combining
semantic similarity, temporal diversity, and contextual drop impact, KeyScore
identifies the most informative frames for downstream tasks such as retrieval,
captioning, and video-language reasoning. To complement KeyScore, we introduce
STACFP (Spatio-Temporal Adaptive Clustering for Frame Proposals), which
generates compact and diverse frame candidates for long-form videos. Together,
these modules achieve up to 99\% frame reduction compared to full-frame
inference and substantially outperform standard 8-frame encoders on MSRVTT,
MSVD, and DiDeMo. Our results demonstrate that emphasizing multimodal alignment
between visual and textual signals enables scalable, efficient, and
caption-grounded video understanding -- without explicit video summarization.

</details>


### [25] [LogSTOP: Temporal Scores over Prediction Sequences for Matching and Retrieval](https://arxiv.org/abs/2510.06512)
*Avishree Khare,Hideki Okamoto,Bardh Hoxha,Georgios Fainekos,Rajeev Alur*

Main category: cs.CV

TL;DR: LogSTOP是一种高效的时间属性评分方法，显著提升了视频和音频序列的查询匹配和排序检索性能。


<details>
  <summary>Details</summary>
Motivation: 将局部检测分数提升为时间属性有助于下游应用，如查询匹配和排序检索。

Method: 提出了LogSTOP评分函数，用于高效计算线性时序逻辑表示的时间属性得分。

Result: LogSTOP在对象和情感的时间属性查询匹配中优于基线16%以上，在排序检索中平均精度和召回率提升至少19%和16%。

Conclusion: LogSTOP在视频和音频序列的时间属性评分中表现出色，显著优于现有基线方法。

Abstract: Neural models such as YOLO and HuBERT can be used to detect local properties
such as objects ("car") and emotions ("angry") in individual frames of videos
and audio clips respectively. The likelihood of these detections is indicated
by scores in [0, 1]. Lifting these scores to temporal properties over sequences
can be useful for several downstream applications such as query matching (e.g.,
"does the speaker eventually sound happy in this audio clip?"), and ranked
retrieval (e.g., "retrieve top 5 videos with a 10 second scene where a car is
detected until a pedestrian is detected"). In this work, we formalize this
problem of assigning Scores for TempOral Properties (STOPs) over sequences,
given potentially noisy score predictors for local properties. We then propose
a scoring function called LogSTOP that can efficiently compute these scores for
temporal properties represented in Linear Temporal Logic. Empirically, LogSTOP,
with YOLO and HuBERT, outperforms Large Vision / Audio Language Models and
other Temporal Logic-based baselines by at least 16% on query matching with
temporal properties over objects-in-videos and emotions-in-speech respectively.
Similarly, on ranked retrieval with temporal properties over objects and
actions in videos, LogSTOP with Grounding DINO and SlowR50 reports at least a
19% and 16% increase in mean average precision and recall over zero-shot
text-to-video retrieval baselines respectively.

</details>


### [26] [Limited-Angle Tomography Reconstruction via Projector Guided 3D Diffusion](https://arxiv.org/abs/2510.06516)
*Zhantao Deng,Mériem Er-Rafik,Anna Sushko,Cécile Hébert,Pascal Fua*

Main category: cs.CV

TL;DR: TEMDiff是一种无需干净TEM数据的3D扩散重建框架，显著提升有限角度电子断层扫描的质量。


<details>
  <summary>Details</summary>
Motivation: 解决有限角度电子断层扫描中的缺失楔形问题，减少重建伪影，且无需高质量TEM训练数据。

Method: 提出TEMDiff，一种基于3D扩散的迭代重建框架，利用FIB-SEM数据进行训练，并通过模拟器映射到TEM倾斜系列。

Result: 在模拟和真实TEM数据集上，TEMDiff均优于现有方法，尤其在极窄角度范围内表现优异。

Conclusion: TEMDiff框架在有限角度电子断层扫描中表现出色，能够从窄至8度的倾斜角度恢复准确结构，且无需重新训练或微调。

Abstract: Limited-angle electron tomography aims to reconstruct 3D shapes from 2D
projections of Transmission Electron Microscopy (TEM) within a restricted range
and number of tilting angles, but it suffers from the missing-wedge problem
that causes severe reconstruction artifacts. Deep learning approaches have
shown promising results in alleviating these artifacts, yet they typically
require large high-quality training datasets with known 3D ground truth which
are difficult to obtain in electron microscopy. To address these challenges, we
propose TEMDiff, a novel 3D diffusion-based iterative reconstruction framework.
Our method is trained on readily available volumetric FIB-SEM data using a
simulator that maps them to TEM tilt series, enabling the model to learn
realistic structural priors without requiring clean TEM ground truth. By
operating directly on 3D volumes, TEMDiff implicitly enforces consistency
across slices without the need for additional regularization. On simulated
electron tomography datasets with limited angular coverage, TEMDiff outperforms
state-of-the-art methods in reconstruction quality. We further demonstrate that
a trained TEMDiff model generalizes well to real-world TEM tilts obtained under
different conditions and can recover accurate structures from tilt ranges as
narrow as 8 degrees, with 2-degree increments, without any retraining or
fine-tuning.

</details>


### [27] [VUGEN: Visual Understanding priors for GENeration](https://arxiv.org/abs/2510.06529)
*Xiangyi Chen,Théophane Vallaeys,Maha Elbayad,John Nguyen,Jakob Verbeek*

Main category: cs.CV

TL;DR: VUGEN是一种利用VLM预训练视觉理解先验的新框架，通过简化潜在空间和专用解码器实现高质量图像生成，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前基于重建导向的自编码器或复杂桥接机制的方法存在理解与生成表示不对齐或架构复杂的问题，因此需要一种更高效且高质量的图像生成方法。

Method: VUGEN首先将VLM视觉编码器的高维潜在空间转换为低维且可处理的分布，然后训练VLM在该简化潜在空间中采样，最后通过专用像素解码器将生成的潜在映射回图像空间。

Result: VUGEN在DPG Bench上从71.17提升至74.32，FID从11.86降至9.06（COCO数据集），图像生成性能显著优于现有方法。

Conclusion: VUGEN框架通过利用VLM预训练的视觉理解先验，实现了高效且高质量的图像生成，同时完全保留了VLM的原始理解能力。

Abstract: Recent advances in Vision-Language Models (VLMs) have enabled unified
understanding across text and images, yet equipping these models with robust
image generation capabilities remains challenging. Existing approaches often
rely on reconstruction-oriented autoencoders or complex bridging mechanisms,
leading to misalignment between understanding and generation representations,
or architectural complexity. In this work, we propose VUGEN, a novel framework
that explicitly leverages VLM's pretrained visual understanding priors for
efficient and high-quality image generation. Our approach first transforms the
high-dimensional latent space of the VLM's native vision encoder into a
lower-dimensional, tractable distribution that maximally preserves visual
information. The VLM is then trained to sample within this reduced latent
space, ensuring alignment with its visual understanding capabilities. Finally,
a dedicated pixel decoder maps these generated latents back to the image space.
We find that a VAE-free pixel diffusion decoder to be on par or better than
commonly used complex latent diffusion decoders that internally rely on VAE
latents. Extensive experiments demonstrate that VUGEN achieves superior image
generation performance, improving DPG Bench from 71.17 to 74.32 and FID from
11.86 to 9.06 on COCO, while fully preserving the VLM's original understanding
capabilities.

</details>


### [28] [Through the Perspective of LiDAR: A Feature-Enriched and Uncertainty-Aware Annotation Pipeline for Terrestrial Point Cloud Segmentation](https://arxiv.org/abs/2510.06582)
*Fei Zhang,Rob Chancia,Josie Clapp,Amirhossein Hassanzadeh,Dimah Dera,Richard MacKenzie,Jan van Aardt*

Main category: cs.CV

TL;DR: 本文提出了一种半自动、不确定性感知的TLS点云标注流程，显著减少标注工作量并保持高精度，构建了Mangrove3D数据集，并提供了数据效率和特征重要性的实证指导。


<details>
  <summary>Details</summary>
Motivation: 手动标注地面激光扫描（TLS）点云的语义分割成本高昂，限制了其应用。本文旨在通过半自动化流程减少标注工作量，同时保持高精度，为生态监测等应用提供支持。

Method: 该方法包括将3D点投影到2D球形网格，增强像素的多源特征，训练分割网络集成以生成伪标签和不确定性图，后者指导标注模糊区域。2D输出被反投影到3D，生成密集标注的点云。

Result: 实验结果表明，性能在约12次标注扫描后达到饱和，几何特征贡献最大，紧凑的九通道堆叠几乎捕获了所有判别能力，平均交并比（mIoU）约为0.76。跨数据集测试验证了特征增强策略的泛化能力。

Conclusion: 本文提出了一种半自动、不确定性感知的流程，通过集成球形投影、特征增强、集成学习和目标标注，显著减少了标注工作量，同时保持了高准确率。该方法在红树林3D数据集上验证了其有效性，并提供了数据效率和特征重要性的实证指导。

Abstract: Accurate semantic segmentation of terrestrial laser scanning (TLS) point
clouds is limited by costly manual annotation. We propose a semi-automated,
uncertainty-aware pipeline that integrates spherical projection, feature
enrichment, ensemble learning, and targeted annotation to reduce labeling
effort, while sustaining high accuracy. Our approach projects 3D points to a 2D
spherical grid, enriches pixels with multi-source features, and trains an
ensemble of segmentation networks to produce pseudo-labels and uncertainty
maps, the latter guiding annotation of ambiguous regions. The 2D outputs are
back-projected to 3D, yielding densely annotated point clouds supported by a
three-tier visualization suite (2D feature maps, 3D colorized point clouds, and
compact virtual spheres) for rapid triage and reviewer guidance. Using this
pipeline, we build Mangrove3D, a semantic segmentation TLS dataset for mangrove
forests. We further evaluate data efficiency and feature importance to address
two key questions: (1) how much annotated data are needed and (2) which
features matter most. Results show that performance saturates after ~12
annotated scans, geometric features contribute the most, and compact
nine-channel stacks capture nearly all discriminative power, with the mean
Intersection over Union (mIoU) plateauing at around 0.76. Finally, we confirm
the generalization of our feature-enrichment strategy through cross-dataset
tests on ForestSemantic and Semantic3D.
  Our contributions include: (i) a robust, uncertainty-aware TLS annotation
pipeline with visualization tools; (ii) the Mangrove3D dataset; and (iii)
empirical guidance on data efficiency and feature importance, thus enabling
scalable, high-quality segmentation of TLS point clouds for ecological
monitoring and beyond. The dataset and processing scripts are publicly
available at https://fz-rit.github.io/through-the-lidars-eye/.

</details>


### [29] [Cluster Paths: Navigating Interpretability in Neural Networks](https://arxiv.org/abs/2510.06541)
*Nicholas M. Kroeger,Vincent Bindschaedler*

Main category: cs.CV

TL;DR: 提出cluster paths方法，通过聚类激活层生成可解释路径，验证其在识别偏见、保持忠实度和一致性方面的有效性，并展示其在大规模模型中的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络在视觉任务中表现出色，但其决策过程不透明，可能导致不合理的信任、未检测到的偏见和意外失败。

Method: 提出cluster paths方法，通过聚类激活层并生成序列ID来表示输入，同时引入四种评估指标：路径复杂度、加权路径纯度、决策对齐忠实度和路径一致性。

Result: 在实验中，cluster paths成功识别了基于颜色的捷径，并在移除线索后崩溃；在CelebA头发颜色任务中达到90%的忠实度和96%的一致性；还可作为有效的OOD检测器。

Conclusion: Cluster paths是一种有效的后验解释方法，能够在保持模型准确性的同时，提供简洁且人类可读的解释，适用于大规模视觉模型。

Abstract: While modern deep neural networks achieve impressive performance in vision
tasks, they remain opaque in their decision processes, risking unwarranted
trust, undetected biases and unexpected failures. We propose cluster paths, a
post-hoc interpretability method that clusters activations at selected layers
and represents each input as its sequence of cluster IDs. To assess these
cluster paths, we introduce four metrics: path complexity (cognitive load),
weighted-path purity (class alignment), decision-alignment faithfulness
(predictive fidelity), and path agreement (stability under perturbations). In a
spurious-cue CIFAR-10 experiment, cluster paths identify color-based shortcuts
and collapse when the cue is removed. On a five-class CelebA hair-color task,
they achieve 90% faithfulness and maintain 96% agreement under Gaussian noise
without sacrificing accuracy. Scaling to a Vision Transformer pretrained on
ImageNet, we extend cluster paths to concept paths derived from prompting a
large language model on minimal path divergences. Finally, we show that cluster
paths can serve as an effective out-of-distribution (OOD) detector, reliably
flagging anomalous samples before the model generates over-confident
predictions. Cluster paths uncover visual concepts, such as color palettes,
textures, or object contexts, at multiple network depths, demonstrating that
cluster paths scale to large vision models while generating concise and
human-readable explanations.

</details>


### [30] [HARP-NeXt: High-Speed and Accurate Range-Point Fusion Network for 3D LiDAR Semantic Segmentation](https://arxiv.org/abs/2510.06876)
*Samir Abou Haidar,Alexandre Chariot,Mehdi Darouich,Cyril Joly,Jean-Emmanuel Deschaud*

Main category: cs.CV

TL;DR: HARP-NeXt 是一种高速且准确的 LiDAR 语义分割网络，通过新颖的预处理、高效特征提取和多尺度融合，实现了速度和准确性的优异平衡。


<details>
  <summary>Details</summary>
Motivation: 现有方法在准确性和速度之间存在权衡，且预处理阶段增加了执行时间和对嵌入式平台的需求，因此需要一种高速度且准确的 LiDAR 语义分割网络。

Method: 提出了一种新颖的预处理方法以减少计算开销，设计了 Conv-SE-NeXt 特征提取块以高效捕获表示，并采用多尺度范围点融合主干以保留几何细节。

Result: 在 nuScenes 和 SemanticKITTI 基准测试中，HARP-NeXt 实现了优于所有现有方法的速度-准确性权衡。

Conclusion: HARP-NeXt 在 LiDAR 语义分割领域实现了速度和准确性的优异平衡，无需依赖集成模型或 TTA，性能与顶级方法 PTv3 相当，同时运行速度快 24 倍。

Abstract: LiDAR semantic segmentation is crucial for autonomous vehicles and mobile
robots, requiring high accuracy and real-time processing, especially on
resource-constrained embedded systems. Previous state-of-the-art methods often
face a trade-off between accuracy and speed. Point-based and sparse
convolution-based methods are accurate but slow due to the complexity of
neighbor searching and 3D convolutions. Projection-based methods are faster but
lose critical geometric information during the 2D projection. Additionally,
many recent methods rely on test-time augmentation (TTA) to improve
performance, which further slows the inference. Moreover, the pre-processing
phase across all methods increases execution time and is demanding on embedded
platforms. Therefore, we introduce HARP-NeXt, a high-speed and accurate LiDAR
semantic segmentation network. We first propose a novel pre-processing
methodology that significantly reduces computational overhead. Then, we design
the Conv-SE-NeXt feature extraction block to efficiently capture
representations without deep layer stacking per network stage. We also employ a
multi-scale range-point fusion backbone that leverages information at multiple
abstraction levels to preserve essential geometric details, thereby enhancing
accuracy. Experiments on the nuScenes and SemanticKITTI benchmarks show that
HARP-NeXt achieves a superior speed-accuracy trade-off compared to all
state-of-the-art methods, and, without relying on ensemble models or TTA, is
comparable to the top-ranked PTv3, while running 24$\times$ faster. The code is
available at https://github.com/SamirAbouHaidar/HARP-NeXt

</details>


### [31] [HSNet: Heterogeneous Subgraph Network for Single Image Super-resolution](https://arxiv.org/abs/2510.06564)
*Qiongyang Hu,Wenyang Liu,Wenbin Zou,Yuejiao Su,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: HSNet是一种新型的异构子图网络，通过分解全局图为可管理的子组件，结合CSSB、SAB和NSS，实现了高效的图像超分辨率，平衡了质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于CNN和注意力机制的图像超分辨率方法存在结构不灵活的问题，而基于图的方法计算复杂度高。HSNet旨在克服这些限制，通过图建模保持计算可行性的同时提高表示能力。

Method: 提出了Heterogeneous Subgraph Network (HSNet)，包括Constructive Subgraph Set Block (CSSB)、Subgraph Aggregation Block (SAB)和Node Sampling Strategy (NSS)。CSSB生成多样化的互补子图，SAB通过自适应加权和融合多图特征构建综合表示，NSS选择性保留最显著特征以减少计算开销。

Result: HSNet在实验中表现出色，平衡了重建质量和计算效率，达到了最先进的性能。

Conclusion: HSNet通过引入异构子图网络，有效平衡了图像超分辨率的重建质量和计算效率，实现了最先进的性能。

Abstract: Existing deep learning approaches for image super-resolution, particularly
those based on CNNs and attention mechanisms, often suffer from structural
inflexibility. Although graph-based methods offer greater representational
adaptability, they are frequently impeded by excessive computational
complexity. To overcome these limitations, this paper proposes the
Heterogeneous Subgraph Network (HSNet), a novel framework that efficiently
leverages graph modeling while maintaining computational feasibility. The core
idea of HSNet is to decompose the global graph into manageable sub-components.
First, we introduce the Constructive Subgraph Set Block (CSSB), which generates
a diverse set of complementary subgraphs. Rather than relying on a single
monolithic graph, CSSB captures heterogeneous characteristics of the image by
modeling different relational patterns and feature interactions, producing a
rich ensemble of both local and global graph structures. Subsequently, the
Subgraph Aggregation Block (SAB) integrates the representations embedded across
these subgraphs. Through adaptive weighting and fusion of multi-graph features,
SAB constructs a comprehensive and discriminative representation that captures
intricate interdependencies. Furthermore, a Node Sampling Strategy (NSS) is
designed to selectively retain the most salient features, thereby enhancing
accuracy while reducing computational overhead. Extensive experiments
demonstrate that HSNet achieves state-of-the-art performance, effectively
balancing reconstruction quality with computational efficiency. The code will
be made publicly available.

</details>


### [32] [WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation](https://arxiv.org/abs/2510.07313)
*Zezhong Qian,Xiaowei Chi,Yuming Li,Shizun Wang,Zhiyuan Qin,Xiaozhu Ju,Sirui Han,Shanghang Zhang*

Main category: cs.CV

TL;DR: WristWorld是首个仅从锚定视图生成腕视图视频的4D世界模型，通过两阶段方法（重建和生成）填补了视图差距并提升了VLA性能。


<details>
  <summary>Details</summary>
Motivation: 当前大规模数据集缺乏腕视图记录，导致锚定视图与腕视图之间存在显著差距。现有世界模型无法仅从锚定视图生成腕视图视频，而视觉几何模型的进展为解决极端视角偏移提供了可能。

Method: WristWorld采用两阶段方法：1）重建阶段，扩展VGGT并引入空间投影一致性损失（SPC Loss）来估计几何一致的腕视图姿态和4D点云；2）生成阶段，使用视频生成模型从重建的视角合成时间连贯的腕视图视频。

Result: 在Droid、Calvin和Franka Panda数据集上的实验表明，WristWorld在视频生成方面达到了最先进的水平，具有优越的空间一致性，同时提升了VLA性能，将Calvin上的平均任务完成长度提高了3.81%，填补了42.4%的锚定-腕视图差距。

Conclusion: WristWorld通过创新的两阶段模型（重建和生成）成功地从锚定视图生成了腕视图视频，显著提升了VLA模型的性能，并填补了锚定视图与腕视图之间的差距。

Abstract: Wrist-view observations are crucial for VLA models as they capture
fine-grained hand-object interactions that directly enhance manipulation
performance. Yet large-scale datasets rarely include such recordings, resulting
in a substantial gap between abundant anchor views and scarce wrist views.
Existing world models cannot bridge this gap, as they require a wrist-view
first frame and thus fail to generate wrist-view videos from anchor views
alone. Amid this gap, recent visual geometry models such as VGGT emerge with
geometric and cross-view priors that make it possible to address extreme
viewpoint shifts. Inspired by these insights, we propose WristWorld, the first
4D world model that generates wrist-view videos solely from anchor views.
WristWorld operates in two stages: (i) Reconstruction, which extends VGGT and
incorporates our Spatial Projection Consistency (SPC) Loss to estimate
geometrically consistent wrist-view poses and 4D point clouds; (ii) Generation,
which employs our video generation model to synthesize temporally coherent
wrist-view videos from the reconstructed perspective. Experiments on Droid,
Calvin, and Franka Panda demonstrate state-of-the-art video generation with
superior spatial consistency, while also improving VLA performance, raising the
average task completion length on Calvin by 3.81% and closing 42.4% of the
anchor-wrist view gap.

</details>


### [33] [Improving Artifact Robustness for CT Deep Learning Models Without Labeled Artifact Images via Domain Adaptation](https://arxiv.org/abs/2510.06584)
*Justin Cheung,Samuel Savine,Calvin Nguyen,Lin Lu,Alhassan S. Yasin*

Main category: cs.CV

TL;DR: 研究表明，域适应方法（DANN）能有效应对CT图像中的新伪影，无需额外标注，且性能接近有监督训练模型，具有临床部署潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管现代CT扫描仪设计上减少了伪影，但实践中仍可能出现未预期或难以消除的伪影。直接标注新分布图像成本高昂，因此探索域适应作为替代方案。

Method: 本研究通过模拟探测器增益误差导致的环形伪影，在OrganAMNIST腹部CT数据集上评估了域对抗神经网络（DANN）与基线方法和基于增强的方法的性能。

Result: DANN方法在仅使用未标记伪影数据训练的情况下，成功保持了高分类准确率，其性能与使用标记伪影图像训练的模型相当，并意外地对均匀噪声表现出泛化能力。

Conclusion: 域适应方法（如DANN）在无需昂贵专家标注的情况下，能够有效应对医学影像中的分布偏移问题，展示了在临床环境中应对新出现的伪影的潜力。

Abstract: Deep learning models which perform well on images from their training
distribution can degrade substantially when applied to new distributions. If a
CT scanner introduces a new artifact not present in the training labels, the
model may misclassify the images. Although modern CT scanners include design
features which mitigate these artifacts, unanticipated or difficult-to-mitigate
artifacts can still appear in practice. The direct solution of labeling images
from this new distribution can be costly. As a more accessible alternative,
this study evaluates domain adaptation as an approach for training models that
maintain classification performance despite new artifacts, even without
corresponding labels. We simulate ring artifacts from detector gain error in
sinogram space and evaluate domain adversarial neural networks (DANN) against
baseline and augmentation-based approaches on the OrganAMNIST abdominal CT
dataset. Our results demonstrate that baseline models trained only on clean
images fail to generalize to images with ring artifacts, and traditional
augmentation with other distortion types provides no improvement on unseen
artifact domains. In contrast, the DANN approach successfully maintains high
classification accuracy on ring artifact images using only unlabeled artifact
data during training, demonstrating the viability of domain adaptation for
artifact robustness. The domain-adapted model achieved classification
performance on ring artifact test data comparable to models explicitly trained
with labeled artifact images, while also showing unexpected generalization to
uniform noise. These findings provide empirical evidence that domain adaptation
can effectively address distribution shift in medical imaging without requiring
expensive expert labeling of new artifact distributions, suggesting promise for
deployment in clinical settings where novel artifacts may emerge.

</details>


### [34] [Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer](https://arxiv.org/abs/2510.06590)
*Ziyuan Huang,DanDan Zheng,Cheng Zou,Rui Liu,Xiaolong Wang,Kaixiang Ji,Weilong Chai,Jianxin Sun,Libin Wang,Yongjie Lv,Taozhi Huang,Jiajia Liu,Qingpei Guo,Ming Yang,Jingdong Chen,Jun Zhou*

Main category: cs.CV

TL;DR: MingTok是一种连续潜在空间的视觉标记器，通过三阶段架构平衡理解和生成需求，Ming-UniVision在此基础上统一视觉语言任务，实现了多轮任务支持和最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在离散潜在空间中使用标记器，量化误差限制了语义表达能力和视觉语言理解能力。为解决这一问题，提出了连续潜在空间的视觉标记器MingTok。

Method: MingTok采用三阶段顺序架构，包括低级编码、语义扩展和视觉重建，以平衡理解和生成任务对标记器的不同需求。Ming-UniVision在此基础上，统一了多样化的视觉语言任务于单一自回归预测范式下。

Result: 实验表明，统一的连续视觉表示通过平衡理解和生成任务对标记器的需求，在两个领域均实现了最先进的性能。

Conclusion: MingTok和Ming-UniVision通过连续潜在空间的视觉标记化，统一了视觉理解和生成任务，实现了多轮、上下文任务的无缝支持，并在两个领域均达到了最先进的性能水平。

Abstract: Visual tokenization remains a core challenge in unifying visual understanding
and generation within the autoregressive paradigm. Existing methods typically
employ tokenizers in discrete latent spaces to align with the tokens from large
language models, where the quantization errors can limit semantic
expressiveness and degrade the capability of vision-language understanding. To
address this, we introduce MingTok, a new family of visual tokenizers with a
continuous latent space, for unified autoregressive generation and
understanding. While understanding tasks favor discriminative high-dimensional
features, generation tasks prefer compact low-level codes. Thus, to reconcile
these competing demands, MingTok adopts a three-stage sequential architecture
involving low-level encoding, semantic expansion, and visual reconstruction.
Built on top of it, Ming-UniVision eliminates the need for task-specific visual
representations, and unifies diverse vision-language tasks under a single
autoregrsssive prediction paradigm. By formulating both understanding and
generation as next-token prediction in a shared continuous space, it seamlessly
supports multi-round, in-context tasks such as iterative understanding,
generation and editing. Empirically, we find that using a unified continuous
visual representation reconciles the competing requirements on the tokenizers
by the understanding and generation tasks, thereby leading to state-of-the-art
level performance across both domains. We hope our findings will facilitate
unified visual tokenization in the continuous domain. Inference code and model
weights are released to benefit community.

</details>


### [35] [Adaptive Stain Normalization for Cross-Domain Medical Histology](https://arxiv.org/abs/2510.06592)
*Tianyue Xu,Yanlin Wu,Abhai K. Tripathi,Matthew M. Ippolito,Benjamin D. Haeffele*

Main category: cs.CV

TL;DR: 提出了一种可训练的颜色归一化模型，通过物理成像原理提取染色不变信息，显著提升跨域病理图像分析的性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在数字病理分析中因染色协议和成像条件差异导致的颜色不一致问题，以及现有颜色归一化方法的局限性。

Method: 通过基于Beer-Lambert定律的物理成像过程，采用非负矩阵分解（NMF）模型的算法展开来提取染色不变的结构信息。

Result: 在跨域目标检测和分类任务中，该方法优于许多最先进的染色归一化方法。

Conclusion: 论文提出的可训练颜色归一化模型在多个公开病理数据集和内部疟疾血涂片数据集上表现出色，优于现有染色归一化方法。

Abstract: Deep learning advances have revolutionized automated digital pathology
analysis. However, differences in staining protocols and imaging conditions can
introduce significant color variability. In deep learning, such color
inconsistency often reduces performance when deploying models on data acquired
under different conditions from the training data, a challenge known as domain
shift. Many existing methods attempt to address this problem via color
normalization but suffer from several notable drawbacks such as introducing
artifacts or requiring careful choice of a template image for stain mapping. To
address these limitations, we propose a trainable color normalization model
that can be integrated with any backbone network for downstream tasks such as
object detection and classification. Based on the physics of the imaging
process per the Beer-Lambert law, our model architecture is derived via
algorithmic unrolling of a nonnegative matrix factorization (NMF) model to
extract stain-invariant structural information from the original pathology
images, which serves as input for further processing. Experimentally, we
evaluate the method on publicly available pathology datasets and an internally
curated collection of malaria blood smears for cross-domain object detection
and classification, where our method outperforms many state-of-the-art stain
normalization methods. Our code is available at
https://github.com/xutianyue/BeerLaNet.

</details>


### [36] [SDQM: Synthetic Data Quality Metric for Object Detection Dataset Evaluation](https://arxiv.org/abs/2510.06596)
*Ayush Zenith,Arnold Zumbrun,Neel Raut,Jing Lin*

Main category: cs.CV

TL;DR: 本文提出SDQM指标，无需训练即可评估合成数据质量，与YOLOv11的mAP强相关，为资源受限的目标检测任务提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 由于大规模、高质量标注数据集的稀缺性，合成数据成为提升模型性能、可靠性和鲁棒性的潜在解决方案，但缺乏有效的质量评估方法。

Method: 本文提出了合成数据集质量指标（SDQM），用于在无需模型训练收敛的情况下评估目标检测任务中合成数据的质量。

Result: 实验表明，SDQM与领先目标检测模型YOLOv11的mAP分数呈现强相关性，优于之前仅显示中等或弱相关性的指标。

Conclusion: SDQM作为一种可扩展且高效的指标，为评估合成数据质量设立了新标准，显著减少了资源密集型迭代训练的需求。

Abstract: The performance of machine learning models depends heavily on training data.
The scarcity of large-scale, well-annotated datasets poses significant
challenges in creating robust models. To address this, synthetic data generated
through simulations and generative models has emerged as a promising solution,
enhancing dataset diversity and improving the performance, reliability, and
resilience of models. However, evaluating the quality of this generated data
requires an effective metric. This paper introduces the Synthetic Dataset
Quality Metric (SDQM) to assess data quality for object detection tasks without
requiring model training to converge. This metric enables more efficient
generation and selection of synthetic datasets, addressing a key challenge in
resource-constrained object detection tasks. In our experiments, SDQM
demonstrated a strong correlation with the mean Average Precision (mAP) scores
of YOLOv11, a leading object detection model, while previous metrics only
exhibited moderate or weak correlations. Additionally, it provides actionable
insights for improving dataset quality, minimizing the need for costly
iterative training. This scalable and efficient metric sets a new standard for
evaluating synthetic data. The code for SDQM is available at
https://github.com/ayushzenith/SDQM

</details>


### [37] [AIM 2025 Challenge on Real-World RAW Image Denoising](https://arxiv.org/abs/2510.06601)
*Feiran Li,Jiacheng Li,Marcos V. Conde,Beril Besbinar,Vlad Hosu,Daisuke Iso,Radu Timofte*

Main category: cs.CV

TL;DR: AIM 2025 RAW图像去噪竞赛旨在通过合成数据推动低光RAW图像去噪技术发展，参与者需开发创新方法，优胜者基于多指标评选。


<details>
  <summary>Details</summary>
Motivation: 推进基于数据合成的高效有效去噪技术，应对低光环境下拍摄的挑战性RAW图像去噪问题。

Method: 参与者需要开发新的噪声合成管道、网络架构和训练方法，以在不同相机模型上实现高性能。

Result: 竞赛结果将基于性能指标（如PSNR、SSIM、LPIPS、ARNIQA、TOPIQ）评选优胜者。

Conclusion: The competition aims to advance RAW图像去噪技术，通过推动基于合成数据的相机无关低光RAW图像去噪，促进稳健且实用的模型发展，影响从图像修复到夜间自动驾驶等多个领域。

Abstract: We introduce the AIM 2025 Real-World RAW Image Denoising Challenge, aiming to
advance efficient and effective denoising techniques grounded in data
synthesis. The competition is built upon a newly established evaluation
benchmark featuring challenging low-light noisy images captured in the wild
using five different DSLR cameras. Participants are tasked with developing
novel noise synthesis pipelines, network architectures, and training
methodologies to achieve high performance across different camera models.
Winners are determined based on a combination of performance metrics, including
full-reference measures (PSNR, SSIM, LPIPS), and non-reference ones (ARNIQA,
TOPIQ). By pushing the boundaries of camera-agnostic low-light RAW image
denoising trained on synthetic data, the competition promotes the development
of robust and practical models aligned with the rapid progress in digital
photography. We expect the competition outcomes to influence multiple domains,
from image restoration to night-time autonomous driving.

</details>


### [38] [Self-supervised Physics-guided Model with Implicit Representation Regularization for Fast MRI Reconstruction](https://arxiv.org/abs/2510.06611)
*Jingran Xu,Yuanyuan Liu,Yanjie Zhu*

Main category: cs.CV

TL;DR: 提出零样本自监督框架 UnrollINR，结合深度展开结构和 INR 先验，无需外部数据即可实现高性能 MRI 重建。


<details>
  <summary>Details</summary>
Motivation: MRI 的广泛应用受限于扫描时间过长，而传统方法在完全采样数据难以获取时效果有限。因此，提出一种无需外部训练数据的零样本自监督重建框架。

Method: 采用物理引导的展开迭代重建架构，并引入隐式神经表示（INR）作为正则化先验，有效约束解空间。

Result: 在高加速率 10 下，UnrollINR 的重建性能优于监督学习方法。

Conclusion: UnrollINR 在无需外部训练数据的情况下，通过结合深度展开结构和隐式神经表示（INR）的先验正则化，显著提升了 MRI 重建的性能和可解释性，即使在高加速率下也优于监督学习方法。

Abstract: Magnetic Resonance Imaging (MRI) is a vital clinical diagnostic tool, yet its
widespread application is limited by prolonged scan times. Fast MRI
reconstruction techniques effectively reduce acquisition duration by
reconstructing high-fidelity MR images from undersampled k-space data. In
recent years, deep learning-based methods have demonstrated remarkable progress
in this field, with self-supervised and unsupervised learning approaches
proving particularly valuable in scenarios where fully sampled data are
difficult to obtain. This paper proposes a novel zero-shot self-supervised
reconstruction framework named UnrollINR, which enables scan-specific MRI
reconstruction without relying on external training data. The method adopts a
physics-guided unrolled iterative reconstruction architecture and introduces
Implicit Neural Representation (INR) as a regularization prior to effectively
constrain the solution space. By combining a deep unrolled structure with the
powerful implicit representation capability of INR, the model's
interpretability and reconstruction performance are enhanced. Experimental
results demonstrate that even at a high acceleration rate of 10, UnrollINR
achieves superior reconstruction performance compared to the supervised
learning method, validating the superiority of the proposed method.

</details>


### [39] [A Bridge from Audio to Video: Phoneme-Viseme Alignment Allows Every Face to Speak Multiple Languages](https://arxiv.org/abs/2510.06612)
*Zibo Su,Kun Wei,Jiahua Li,Xu Yang,Cheng Deng*

Main category: cs.CV

TL;DR: MuEx通过音素和视素中介及对齐机制，解决了多语言TFS的跨语言泛化和同步问题，表现优异且具备零样本能力。


<details>
  <summary>Details</summary>
Motivation: 当前TFS模型在非英语语言中表现不佳，主要由于英语主导的训练数据集和缺乏跨语言泛化能力。

Method: 提出Multilingual Experts (MuEx)框架，采用Phoneme-Guided Mixture-of-Experts (PG-MoE)架构，利用音素和视素作为通用中介，结合Phoneme-Viseme Alignment Mechanism (PV-Align)解决跨模态同步问题。

Result: MuEx在包含12种语言的Multilingual Talking Face Benchmark (MTFB)上表现优异，并能零样本泛化到未训练语言。

Conclusion: MuEx框架通过Phoneme-Guided Mixture-of-Experts架构和Phoneme-Viseme Alignment Mechanism，成功实现了跨语言的高质量面部动画合成，并在多语言基准测试中表现出色，具备零样本泛化能力。

Abstract: Speech-driven talking face synthesis (TFS) focuses on generating lifelike
facial animations from audio input. Current TFS models perform well in English
but unsatisfactorily in non-English languages, producing wrong mouth shapes and
rigid facial expressions. The terrible performance is caused by the
English-dominated training datasets and the lack of cross-language
generalization abilities. Thus, we propose Multilingual Experts (MuEx), a novel
framework featuring a Phoneme-Guided Mixture-of-Experts (PG-MoE) architecture
that employs phonemes and visemes as universal intermediaries to bridge audio
and video modalities, achieving lifelike multilingual TFS. To alleviate the
influence of linguistic differences and dataset bias, we extract audio and
video features as phonemes and visemes respectively, which are the basic units
of speech sounds and mouth movements. To address audiovisual synchronization
issues, we introduce the Phoneme-Viseme Alignment Mechanism (PV-Align), which
establishes robust cross-modal correspondences between phonemes and visemes. In
addition, we build a Multilingual Talking Face Benchmark (MTFB) comprising 12
diverse languages with 95.04 hours of high-quality videos for training and
evaluating multilingual TFS performance. Extensive experiments demonstrate that
MuEx achieves superior performance across all languages in MTFB and exhibits
effective zero-shot generalization to unseen languages without additional
training.

</details>


### [40] [MSITrack: A Challenging Benchmark for Multispectral Single Object Tracking](https://arxiv.org/abs/2510.06619)
*Tao Feng,Tingfa Xu,Haolin Qin,Tianhao Li,Shuaihao Han,Xuyang Zou,Zhan Lv,Jianan Li*

Main category: cs.CV

TL;DR: MSITrack是最大、最多样化的多光谱单目标跟踪数据集，显著提升跟踪性能，填补了现有数据集的空白。


<details>
  <summary>Details</summary>
Motivation: RGB跟踪器在复杂场景中效果有限，多光谱图像能提升目标区分度，但现有数据集稀缺。

Method: 构建了MSITrack数据集，包含300个视频、129k帧多光谱图像，涵盖55个物体类别和300个自然场景，并进行了精细标注和验证。

Result: 多光谱数据显著优于RGB基线，MSITrack成为最大、最多样化的多光谱单目标跟踪数据集。

Conclusion: MSITrack数据集的引入显著提升了多光谱目标跟踪的性能，为未来研究提供了重要资源。

Abstract: Visual object tracking in real-world scenarios presents numerous challenges
including occlusion, interference from similar objects and complex
backgrounds-all of which limit the effectiveness of RGB-based trackers.
Multispectral imagery, which captures pixel-level spectral reflectance,
enhances target discriminability. However, the availability of multispectral
tracking datasets remains limited. To bridge this gap, we introduce MSITrack,
the largest and most diverse multispectral single object tracking dataset to
date. MSITrack offers the following key features: (i) More Challenging
Attributes-including interference from similar objects and similarity in color
and texture between targets and backgrounds in natural scenarios, along with a
wide range of real-world tracking challenges; (ii) Richer and More Natural
Scenes-spanning 55 object categories and 300 distinct natural scenes, MSITrack
far exceeds the scope of existing benchmarks. Many of these scenes and
categories are introduced to the multispectral tracking domain for the first
time; (iii) Larger Scale-300 videos comprising over 129k frames of
multispectral imagery. To ensure annotation precision, each frame has undergone
meticulous processing, manual labeling and multi-stage verification. Extensive
evaluations using representative trackers demonstrate that the multispectral
data in MSITrack significantly improves performance over RGB-only baselines,
highlighting its potential to drive future advancements in the field. The
MSITrack dataset is publicly available at:
https://github.com/Fengtao191/MSITrack.

</details>


### [41] [StaR-KVQA: Structured Reasoning Traces for Implicit-Knowledge Visual Question Answering](https://arxiv.org/abs/2510.06638)
*Zhihao Wen,Wenkang Wei,Yuan Fang,Xingtong Yu,Hui Zhang,Weicheng Zhu,Xin Zhang*

Main category: cs.CV

TL;DR: StaR-KVQA通过结构化推理轨迹监督，提升IK-KVQA的准确性和可解释性，无需外部知识库或检索器。


<details>
  <summary>Details</summary>
Motivation: 研究IK-KVQA任务，发现现有MLLMs缺乏显式推理监督，导致不一致的解释和泛化能力差。

Method: 提出StaR-KVQA方法，通过构建和选择路径接地的推理轨迹，形成轨迹增强的数据集，并通过结构化自蒸馏进行微调。

Result: 在多个基准测试中，StaR-KVQA实现了高达+11.3%的答案准确性提升，并展现出强大的跨领域泛化能力。

Conclusion: StaR-KVQA通过监督结构化推理轨迹，显著提高了IK-KVQA任务的准确性和可解释性，并在跨领域泛化中表现出色。

Abstract: Knowledge-based Visual Question Answering (KVQA) requires models to ground
entities in images and reason over factual knowledge. We study its
implicit-knowledge variant, IK-KVQA, where a multimodal large language model
(MLLM) is the sole knowledge source, without external retrieval. Yet, MLLMs
lack explicit reasoning supervision and produce inconsistent justifications,
and generalize poorly after standard supervised fine-tuning (SFT). We present
StaR-KVQA (Structured Reasoning Traces for IK-KVQA), which supervises
structured traces - dual symbolic relation paths plus path-grounded
natural-language explanations - so that reasoning becomes transparent and
verifiable. With one open-source MLLM, StaR-KVQA constructs and selects
path-grounded reasoning traces to form a trace-enriched dataset, then
fine-tunes via structured self-distillation to align generation with
supervision; no external retrievers, verifiers, or curated knowledge bases
(KBs) are used, traces are built offline, and inference is a single
autoregressive pass. Across benchmarks, StaR-KVQA improves both accuracy and
interpretability, achieving up to +11.3% higher answer accuracy on OK-VQA over
the strongest baseline while exhibiting robust cross-domain generalization.

</details>


### [42] [Automated Neural Architecture Design for Industrial Defect Detection](https://arxiv.org/abs/2510.06669)
*Yuxi Liu,Yunfeng Ma,Yi Tang,Min Liu,Shuai Jiang,Yaonan Wang*

Main category: cs.CV

TL;DR: AutoNAD是一种自动化神经架构设计框架，通过混合设计和跨权重共享策略解决了工业表面缺陷检测的挑战，提升了检测效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 工业表面缺陷检测面临类内差异和类间相似性的挑战，现有手动设计模型效率低下且效果不佳，因此需要一种自动化方法来提高检测效率和准确性。

Method: AutoNAD结合了卷积、Transformer和多层感知机的混合设计，并引入了跨权重共享策略和可搜索的多级特征聚合模块（MFAM）来优化训练和特征学习。

Result: AutoNAD在三个工业缺陷数据集上验证了其有效性，并成功应用于缺陷成像和检测平台。

Conclusion: AutoNAD提出了一种自动神经架构设计框架，有效解决了工业表面缺陷检测中的类内差异和类间相似性问题，并通过跨权重共享策略和可搜索的多级特征聚合模块提升了模型性能。

Abstract: Industrial surface defect detection (SDD) is critical for ensuring product
quality and manufacturing reliability. Due to the diverse shapes and sizes of
surface defects, SDD faces two main challenges: intraclass difference and
interclass similarity. Existing methods primarily utilize manually designed
models, which require extensive trial and error and often struggle to address
both challenges effectively. To overcome this, we propose AutoNAD, an automated
neural architecture design framework for SDD that jointly searches over
convolutions, transformers, and multi-layer perceptrons. This hybrid design
enables the model to capture both fine-grained local variations and long-range
semantic context, addressing the two key challenges while reducing the cost of
manual network design. To support efficient training of such a diverse search
space, AutoNAD introduces a cross weight sharing strategy, which accelerates
supernet convergence and improves subnet performance. Additionally, a
searchable multi-level feature aggregation module (MFAM) is integrated to
enhance multi-scale feature learning. Beyond detection accuracy, runtime
efficiency is essential for industrial deployment. To this end, AutoNAD
incorporates a latency-aware prior to guide the selection of efficient
architectures. The effectiveness of AutoNAD is validated on three industrial
defect datasets and further applied within a defect imaging and detection
platform. Code will be available at https://github.com/Yuxi104/AutoNAD.

</details>


### [43] [Heptapod: Language Modeling on Visual Signals](https://arxiv.org/abs/2510.06673)
*Yongxin Zhu,Jiawei Chen,Yuanzhe Chen,Zhuo Chen,Dongya Jia,Jian Cong,Xiaobin Zhuang,Yuping Wang,Yuxuan Wang*

Main category: cs.CV

TL;DR: Heptapod是一种图像自回归模型，通过创新的2D分布预测和因果Transformer，在ImageNet生成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 旨在通过生成式训练捕获全面的图像语义，统一自回归框架的序列建模与掩码自编码的整体自监督学习。

Method: Heptapod采用因果Transformer和重建导向的视觉分词器，通过‘next 2D distribution prediction’学习目标，预测图像2D空间网格的分布。

Result: 在ImageNet生成基准测试中，Heptapod实现了FID 2.70，显著优于之前的因果自回归方法。

Conclusion: Heptapod的研究成果为视觉信号及其他领域的语言建模提供了原则性的重新思考。

Abstract: We introduce Heptapod, an image autoregressive model that adheres to the
foundational principles of language modeling. Heptapod employs \textbf{causal
attention}, \textbf{eliminates reliance on CFG}, and \textbf{eschews the trend
of semantic tokenizers}. Our key innovation is \textit{next 2D distribution
prediction}: a causal Transformer with reconstruction-focused visual tokenizer,
learns to predict the distribution over the entire 2D spatial grid of images at
each timestep. This learning objective unifies the sequential modeling of
autoregressive framework with the holistic self-supervised learning of masked
autoencoding, enabling the model to capture comprehensive image semantics via
generative training. On the ImageNet generation benchmark, Heptapod achieves an
FID of $2.70$, significantly outperforming previous causal autoregressive
approaches. We hope our work inspires a principled rethinking of language
modeling on visual signals and beyond.

</details>


### [44] [DreamOmni2: Multimodal Instruction-based Editing and Generation](https://arxiv.org/abs/2510.06679)
*Bin Xia,Bohao Peng,Yuechen Zhang,Junjia Huang,Jiyang Liu,Jingyao Li,Haoru Tan,Sitong Wu,Chengyao Wang,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: 提出了DreamOmni2，支持多模态指令编辑和生成，通过创新数据合成和模型设计解决现有局限性，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决基于指令的图像编辑和主题驱动生成在实用中的局限性，扩展至支持多模态指令和抽象概念。

Method: 提出了数据合成流程（特征混合、编辑数据生成、提取模型应用）和模型框架设计（索引编码、位置编码偏移、与VLM联合训练）。

Result: 实验证明DreamOmni2在两项新任务上表现优异。

Conclusion: DreamOmni2通过创新的数据合成流程和模型框架设计，成功解决了多模态指令编辑和生成任务中的关键挑战，并在实验中取得了显著成果。

Abstract: Recent advancements in instruction-based image editing and subject-driven
generation have garnered significant attention, yet both tasks still face
limitations in meeting practical user needs. Instruction-based editing relies
solely on language instructions, which often fail to capture specific editing
details, making reference images necessary. Meanwhile, subject-driven
generation is limited to combining concrete objects or people, overlooking
broader, abstract concepts. To address these challenges, we propose two novel
tasks: multimodal instruction-based editing and generation. These tasks support
both text and image instructions and extend the scope to include both concrete
and abstract concepts, greatly enhancing their practical applications. We
introduce DreamOmni2, tackling two primary challenges: data creation and model
framework design. Our data synthesis pipeline consists of three steps: (1)
using a feature mixing method to create extraction data for both abstract and
concrete concepts, (2) generating multimodal instruction-based editing training
data using the editing and extraction models, and (3) further applying the
extraction model to create training data for multimodal instruction-based
editing. For the framework, to handle multi-image input, we propose an index
encoding and position encoding shift scheme, which helps the model distinguish
images and avoid pixel confusion. Additionally, we introduce joint training
with the VLM and our generation/editing model to better process complex
instructions. In addition, we have proposed comprehensive benchmarks for these
two new tasks to drive their development. Experiments show that DreamOmni2 has
achieved impressive results. Models and codes will be released.

</details>


### [45] [Semantic Segmentation Algorithm Based on Light Field and LiDAR Fusion](https://arxiv.org/abs/2510.06687)
*Jie Luo,Yuxuan Jiang,Xin Jin,Mingyu Liu,Yihui Fan*

Main category: cs.CV

TL;DR: 提出首个光场点云多模态分割数据集和融合网络Mlpfseg，通过特征补全和深度感知提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决复杂条件下（如遮挡）语义分割的挑战，以及光场和LiDAR模态因视角多样性和模态差异导致的融合困难。

Method: 提出了一种多模态光场点云融合分割网络（Mlpfseg），包含特征补全模块和深度感知模块，用于同时分割相机图像和LiDAR点云。

Result: Mlpfseg在图像分割和点云分割上分别提升了1.71和2.38 mIoU，证明了其有效性。

Conclusion: 该论文提出的Mlpfseg网络通过特征补全和深度感知模块，有效融合了光场和点云数据，显著提升了复杂条件下的语义分割性能。

Abstract: Semantic segmentation serves as a cornerstone of scene understanding in
autonomous driving but continues to face significant challenges under complex
conditions such as occlusion. Light field and LiDAR modalities provide
complementary visual and spatial cues that are beneficial for robust
perception; however, their effective integration is hindered by limited
viewpoint diversity and inherent modality discrepancies. To address these
challenges, the first multimodal semantic segmentation dataset integrating
light field data and point cloud data is proposed. Based on this dataset, we
proposed a multi-modal light field point-cloud fusion segmentation
network(Mlpfseg), incorporating feature completion and depth perception to
segment both camera images and LiDAR point clouds simultaneously. The feature
completion module addresses the density mismatch between point clouds and image
pixels by performing differential reconstruction of point-cloud feature maps,
enhancing the fusion of these modalities. The depth perception module improves
the segmentation of occluded objects by reinforcing attention scores for better
occlusion awareness. Our method outperforms image-only segmentation by 1.71
Mean Intersection over Union(mIoU) and point cloud-only segmentation by 2.38
mIoU, demonstrating its effectiveness.

</details>


### [46] [SCas4D: Structural Cascaded Optimization for Boosting Persistent 4D Novel View Synthesis](https://arxiv.org/abs/2510.06694)
*Jipeng Lyu,Jiahua Dong,Yu-Xiong Wang*

Main category: cs.CV

TL;DR: SCas4D是一种层级优化框架，通过逐步细化变形高效建模动态场景，显著减少训练迭代次数并保持性能。


<details>
  <summary>Details</summary>
Motivation: 动态场景建模中，准确捕捉变形同时保持计算效率是一个挑战。

Method: 提出SCas4D，一种基于3D高斯泼溅的层级优化框架，通过从粗到细逐步细化变形。

Result: SCas4D在每帧100次迭代内收敛，训练迭代次数仅为现有方法的二十分之一，且在多项任务中表现优异。

Conclusion: SCas4D通过层级优化框架有效解决了动态场景建模中的变形捕捉和计算效率问题，并在多项任务中展示了其优越性。

Abstract: Persistent dynamic scene modeling for tracking and novel-view synthesis
remains challenging due to the difficulty of capturing accurate deformations
while maintaining computational efficiency. We propose SCas4D, a cascaded
optimization framework that leverages structural patterns in 3D Gaussian
Splatting for dynamic scenes. The key idea is that real-world deformations
often exhibit hierarchical patterns, where groups of Gaussians share similar
transformations. By progressively refining deformations from coarse part-level
to fine point-level, SCas4D achieves convergence within 100 iterations per time
frame and produces results comparable to existing methods with only
one-twentieth of the training iterations. The approach also demonstrates
effectiveness in self-supervised articulated object segmentation, novel view
synthesis, and dense point tracking tasks.

</details>


### [47] [Evaluating LLMs for Historical Document OCR: A Methodological Framework for Digital Humanities](https://arxiv.org/abs/2510.06743)
*Maria Levchenko*

Main category: cs.CV

TL;DR: 论文提出了一种评估LLM历史OCR性能的新方法，发现某些模型优于传统OCR但存在过度历史化问题，后校正无效。


<details>
  <summary>Details</summary>
Motivation: 传统OCR评估指标无法捕捉时间偏见和特定时期的错误，这对历史语料库构建至关重要。

Method: 提出了一种评估LLM历史OCR性能的方法论，包括历史字符保留率（HCPR）和古体插入率（AIR）等新指标，以及污染控制和稳定性测试协议。

Result: 评估12种多模态LLM后发现，Gemini和Qwen模型优于传统OCR，但存在过度历史化问题；后OCR校正反而降低性能。

Conclusion: 该论文为数字人文领域提供了一种评估大型语言模型（LLM）在历史文档数字化中OCR性能的方法论，并提出了针对模型选择和质控的实用指南。

Abstract: Digital humanities scholars increasingly use Large Language Models for
historical document digitization, yet lack appropriate evaluation frameworks
for LLM-based OCR. Traditional metrics fail to capture temporal biases and
period-specific errors crucial for historical corpus creation. We present an
evaluation methodology for LLM-based historical OCR, addressing contamination
risks and systematic biases in diplomatic transcription. Using 18th-century
Russian Civil font texts, we introduce novel metrics including Historical
Character Preservation Rate (HCPR) and Archaic Insertion Rate (AIR), alongside
protocols for contamination control and stability testing. We evaluate 12
multimodal LLMs, finding that Gemini and Qwen models outperform traditional OCR
while exhibiting over-historicization: inserting archaic characters from
incorrect historical periods. Post-OCR correction degrades rather than improves
performance. Our methodology provides digital humanities practitioners with
guidelines for model selection and quality assessment in historical corpus
digitization.

</details>


### [48] [DeRainMamba: A Frequency-Aware State Space Model with Detail Enhancement for Image Deraining](https://arxiv.org/abs/2510.06746)
*Zhiliang Zhu,Tao Zeng,Tao Yang,Guoliang Luo,Jiyong Zeng*

Main category: cs.CV

TL;DR: DeRainMamba结合频域和空间增强，通过FASSM和MDPConv提升去雨效果，实验证明其高效且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: Mamba模型在序列建模中效率高，但细粒度细节捕捉和频域感知能力不足，限制了去雨性能的进一步提升。

Method: 提出DeRainMamba，集成频率感知状态空间模块（FASSM）和多方向感知卷积（MDPConv）。FASSM利用傅里叶变换区分雨纹与高频细节；MDPConv通过捕捉各向异性梯度特征和多分支融合恢复局部结构。

Result: 在四个公开基准测试中，DeRainMamba在PSNR和SSIM上均优于现有方法，且参数和计算成本更低。

Conclusion: 结合频域建模和空间细节增强的状态空间框架在单幅图像去雨任务中有效，DeRainMamba在PSNR和SSIM上优于现有方法，且参数和计算成本更低。

Abstract: Image deraining is crucial for improving visual quality and supporting
reliable downstream vision tasks. Although Mamba-based models provide efficient
sequence modeling, their limited ability to capture fine-grained details and
lack of frequency-domain awareness restrict further improvements. To address
these issues, we propose DeRainMamba, which integrates a Frequency-Aware
State-Space Module (FASSM) and Multi-Directional Perception Convolution
(MDPConv). FASSM leverages Fourier transform to distinguish rain streaks from
high-frequency image details, balancing rain removal and detail preservation.
MDPConv further restores local structures by capturing anisotropic gradient
features and efficiently fusing multiple convolution branches. Extensive
experiments on four public benchmarks demonstrate that DeRainMamba consistently
outperforms state-of-the-art methods in PSNR and SSIM, while requiring fewer
parameters and lower computational costs. These results validate the
effectiveness of combining frequency-domain modeling and spatial detail
enhancement within a state-space framework for single image deraining.

</details>


### [49] [OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot](https://arxiv.org/abs/2510.06751)
*Junhan Zhu,Hesong Wang,Mingluo Su,Zefang Wang,Huan Wang*

Main category: cs.CV

TL;DR: OBS-Diff 是一种新型的一次性剪枝框架，能够准确且无需训练地压缩大规模文本到图像扩散模型，实现了推理加速且视觉质量退化最小。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型虽然强大，但计算成本高昂。现有的一次性网络剪枝方法难以直接应用于扩散模型，因此需要一种新的剪枝框架。

Method: OBS-Diff 通过重新设计经典的最优脑外科手术（OBS），使其适应现代扩散模型的复杂架构，并支持多种剪枝粒度。此外，提出了一种时间步感知的 Hessian 构造和计算高效的组级顺序剪枝策略。

Result: 实验表明，OBS-Diff 在扩散模型的一次性剪枝中达到了最先进的水平，实现了推理加速且视觉质量退化最小。

Conclusion: OBS-Diff 是一种新型的一次性剪枝框架，能够准确且无需训练地压缩大规模文本到图像扩散模型，实现了推理加速且视觉质量退化最小。

Abstract: Large-scale text-to-image diffusion models, while powerful, suffer from
prohibitive computational cost. Existing one-shot network pruning methods can
hardly be directly applied to them due to the iterative denoising nature of
diffusion models. To bridge the gap, this paper presents OBS-Diff, a novel
one-shot pruning framework that enables accurate and training-free compression
of large-scale text-to-image diffusion models. Specifically, (i) OBS-Diff
revitalizes the classic Optimal Brain Surgeon (OBS), adapting it to the complex
architectures of modern diffusion models and supporting diverse pruning
granularity, including unstructured, N:M semi-structured, and structured (MHA
heads and FFN neurons) sparsity; (ii) To align the pruning criteria with the
iterative dynamics of the diffusion process, by examining the problem from an
error-accumulation perspective, we propose a novel timestep-aware Hessian
construction that incorporates a logarithmic-decrease weighting scheme,
assigning greater importance to earlier timesteps to mitigate potential error
accumulation; (iii) Furthermore, a computationally efficient group-wise
sequential pruning strategy is proposed to amortize the expensive calibration
process. Extensive experiments show that OBS-Diff achieves state-of-the-art
one-shot pruning for diffusion models, delivering inference acceleration with
minimal degradation in visual quality.

</details>


### [50] [Transforming Noise Distributions with Histogram Matching: Towards a Single Denoiser for All](https://arxiv.org/abs/2510.06757)
*Sheng Fu,Junchao Zhang,Kailun Yang*

Main category: cs.CV

TL;DR: 提出直方图匹配方法增强单高斯去噪器泛化能力，有效处理多种非分布噪声。


<details>
  <summary>Details</summary>
Motivation: 监督高斯去噪器在面对非分布噪声时泛化能力有限，因为不同噪声类型的分布特性差异较大。

Method: 提出直方图匹配方法，将任意噪声转换为目标高斯分布，并结合去噪形成相互强化的循环。具体包括局部直方图匹配处理信号相关噪声、块内排列处理通道相关噪声，以及频域直方图匹配结合像素混洗下采样处理空间相关性。

Result: 实验表明，该方法在多种非分布噪声（如泊松、椒盐和重复模式噪声）及复杂真实噪声上表现出优异的泛化能力和有效性。

Conclusion: 通过直方图匹配和去噪相互强化的循环，该方法显著提升了单高斯去噪器处理各种非分布噪声的能力，包括合成噪声和复杂真实世界噪声。

Abstract: Supervised Gaussian denoisers exhibit limited generalization when confronted
with out-of-distribution noise, due to the diverse distributional
characteristics of different noise types. To bridge this gap, we propose a
histogram matching approach that transforms arbitrary noise towards a target
Gaussian distribution with known intensity. Moreover, a mutually reinforcing
cycle is established between noise transformation and subsequent denoising.
This cycle progressively refines the noise to be converted, making it
approximate the real noise, thereby enhancing the noise transformation effect
and further improving the denoising performance. We tackle specific noise
complexities: local histogram matching handles signal-dependent noise,
intrapatch permutation processes channel-related noise, and frequency-domain
histogram matching coupled with pixel-shuffle down-sampling breaks spatial
correlation. By applying these transformations, a single Gaussian denoiser
gains remarkable capability to handle various out-of-distribution noises,
including synthetic noises such as Poisson, salt-and-pepper and repeating
pattern noises, as well as complex real-world noises. Extensive experiments
demonstrate the superior generalization and effectiveness of our method.

</details>


### [51] [A deep multiple instance learning approach based on coarse labels for high-resolution land-cover mapping](https://arxiv.org/abs/2510.06769)
*Gianmarco Perantoni,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 论文提出一种基于深度多实例学习的方法，利用高分辨率影像和低分辨率标签训练土地覆盖分类器，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决高分辨率土地覆盖映射中训练标签数量和质量不足的问题，利用现有低分辨率或过时产品获取大量弱标签。

Method: 采用深度多实例学习（DMIL）方法，通过灵活的池化层将高分辨率影像的像素语义与低分辨率参考标签连接，重新构建多类和多标签设置下的多实例学习问题。

Result: 在2020年IEEE GRSS数据融合竞赛数据集上的实验结果表明，所提框架优于标准训练策略。

Conclusion: 该论文提出的框架在利用高分辨率影像和低分辨率参考数据训练土地覆盖分类器方面表现出色，相比标准训练策略具有更好的效果。

Abstract: The quantity and the quality of the training labels are central problems in
high-resolution land-cover mapping with machine-learning-based solutions. In
this context, weak labels can be gathered in large quantities by leveraging on
existing low-resolution or obsolete products. In this paper, we address the
problem of training land-cover classifiers using high-resolution imagery (e.g.,
Sentinel-2) and weak low-resolution reference data (e.g., MODIS -derived
land-cover maps). Inspired by recent works in Deep Multiple Instance Learning
(DMIL), we propose a method that trains pixel-level multi-class classifiers and
predicts low-resolution labels (i.e., patch-level classification), where the
actual high-resolution labels are learned implicitly without direct
supervision. This is achieved with flexible pooling layers that are able to
link the semantics of the pixels in the high-resolution imagery to the
low-resolution reference labels. Then, the Multiple Instance Learning (MIL)
problem is re-framed in a multi-class and in a multi-label setting. In the
former, the low-resolution annotation represents the majority of the pixels in
the patch. In the latter, the annotation only provides us information on the
presence of one of the land-cover classes in the patch and thus multiple labels
can be considered valid for a patch at a time, whereas the low-resolution
labels provide us only one label. Therefore, the classifier is trained with a
Positive-Unlabeled Learning (PUL) strategy. Experimental results on the 2020
IEEE GRSS Data Fusion Contest dataset show the effectiveness of the proposed
framework compared to standard training strategies.

</details>


### [52] [TTRV: Test-Time Reinforcement Learning for Vision Language Models](https://arxiv.org/abs/2510.06783)
*Akshit Singh,Shyam Marjit,Wei Lin,Paul Gavrikov,Serena Yeung-Levy,Hilde Kuehne,Rogerio Feris,Sivan Doveh,James Glass,M. Jehanzeb Mirza*

Main category: cs.CV

TL;DR: TTRV通过无标记数据的动态适应方法，显著提升视觉语言任务性能，并在低数据条件下仍有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖标记数据和专用训练集，与人类直接从环境中学习的方式不符。TTRV旨在无需标记数据的情况下增强视觉语言理解。

Method: 基于Group Relative Policy Optimization (GRPO)框架，设计奖励信号（基于基础模型输出的频率和低熵输出分布），并在每个测试样本上多次推断。

Result: 在物体识别和视觉问答（VQA）任务中分别提升达52.4%和29.8%，平均提升24.6%和10.0%。TTRV在8B参数模型上平均超越GPT-4o 2.3%。

Conclusion: TTRV通过在推理时动态适应模型，无需标记数据，显著提升了视觉语言理解任务的表现，并在极低数据条件下仍保持有效性。

Abstract: Existing methods for extracting reward signals in Reinforcement Learning
typically rely on labeled data and dedicated training splits, a setup that
contrasts with how humans learn directly from their environment. In this work,
we propose TTRV to enhance vision language understanding by adapting the model
on the fly at inference time, without the need for any labeled data.
Concretely, we enhance the Group Relative Policy Optimization (GRPO) framework
by designing rewards based on the frequency of the base model's output, while
inferring on each test sample multiple times. Further, we also propose to
control the diversity of the model's output by simultaneously rewarding the
model for obtaining low entropy of the output empirical distribution. Our
approach delivers consistent gains across both object recognition and visual
question answering (VQA), with improvements of up to 52.4% and 29.8%,
respectively, and average boosts of 24.6% and 10.0% across 16
datasets.Remarkably, on image recognition, TTRV applied to InternVL 8B
surpasses GPT-4o by an average of 2.3% over 8 benchmarks, while remaining
highly competitive on VQA, demonstrating that test-time reinforcement learning
can match or exceed the strongest proprietary models. Finally, we find many
interesting properties of test-time RL for VLMs: for example, even in extremely
data-constrained scenarios, where adaptation is performed on a single randomly
chosen unlabeled test example, TTRV still yields non-trivial improvements of up
to 5.5% in recognition tasks.

</details>


### [53] [Extreme Amodal Face Detection](https://arxiv.org/abs/2510.06791)
*Changlin Song,Yunzhong Hou,Michael Randall Barnes,Rahul Shome,Dylan Campbell*

Main category: cs.CV

TL;DR: 本文提出了一种高效的样本自由方法，利用上下文线索进行极端非模态面部检测，优于现有生成方法。


<details>
  <summary>Details</summary>
Motivation: 极端非模态检测的任务是从输入图像中推断不完全可见但在扩展视野中可见的物体的2D位置。本文专注于面部检测子问题，因其在安全和隐私方面的应用具有重要意义。

Method: 设计了一种基于热图的极端非模态物体检测器，利用选择性从粗到细的解码器，从图像中提取上下文线索来推断未见面部的存在。

Result: 该方法在单图像任务中表现出色，甚至优于依赖图像序列或生成模型的现有方法。

Conclusion: 本文提出了一种基于热图的极端非模态物体检测器，通过选择性从粗到细的解码器，有效解决了从少量图像信息预测大量超出框区域的问题。该方法在这一新任务上取得了显著成果，甚至优于效率较低的生成方法。

Abstract: Extreme amodal detection is the task of inferring the 2D location of objects
that are not fully visible in the input image but are visible within an
expanded field-of-view. This differs from amodal detection, where the object is
partially visible within the input image, but is occluded. In this paper, we
consider the sub-problem of face detection, since this class provides
motivating applications involving safety and privacy, but do not tailor our
method specifically to this class. Existing approaches rely on image sequences
so that missing detections may be interpolated from surrounding frames or make
use of generative models to sample possible completions. In contrast, we
consider the single-image task and propose a more efficient, sample-free
approach that makes use of the contextual cues from the image to infer the
presence of unseen faces. We design a heatmap-based extreme amodal object
detector that addresses the problem of efficiently predicting a lot (the
out-of-frame region) from a little (the image) with a selective coarse-to-fine
decoder. Our method establishes strong results for this new task, even
outperforming less efficient generative approaches.

</details>


### [54] [VA-Adapter: Adapting Ultrasound Foundation Model to Echocardiography Probe Guidance](https://arxiv.org/abs/2510.06809)
*Teng Wang,Haojun Jiang,Yuxuan Wang,Zhenguo Sun,Shiji Song,Gao Huang*

Main category: cs.CV

TL;DR: 本文提出VA-Adapter，将超声基础模型适配到探头引导任务，帮助初级医师实时获取高质量图像，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 由于心脏超声操作难度高，熟练人员短缺，患者难以及时接受检查。本文旨在将基础模型从大数据集学到的医学知识适配到探头引导任务中，帮助初级超声医师获取高质量超声图像。

Method: 设计了一种参数高效的Vision-Action Adapter（VA-Adapter），使基础模型的图像编码器能够编码视觉-动作序列，并在紧凑设计中内置顺序推理能力。

Result: 大量实验表明，VA-Adapter在探头引导任务中超越了现有强模型。

Conclusion: 通过VA-Adapter，预训练的超声基础模型能够高效学习精确的探头调整策略，显著提升引导性能，为初级超声医师提供实时操作建议。

Abstract: Echocardiography is a critical tool for detecting heart diseases. Recently,
ultrasound foundation models have demonstrated remarkable capabilities in
cardiac ultrasound image analysis. However, obtaining high-quality ultrasound
images is a prerequisite for accurate diagnosis. Due to the exceptionally high
operational difficulty of cardiac ultrasound, there is a shortage of highly
skilled personnel, which hinders patients from receiving timely examination
services. In this paper, we aim to adapt the medical knowledge learned by
foundation models from vast datasets to the probe guidance task, which is
designed to provide real-time operational recommendations for junior
sonographers to acquire high-quality ultrasound images. Moreover, inspired by
the practice where experts optimize action decisions based on past
explorations, we meticulously design a parameter-efficient Vision-Action
Adapter (VA-Adapter) to enable foundation model's image encoder to encode
vision-action sequences, thereby enhancing guidance performance. With built-in
sequential reasoning capabilities in a compact design, the VA-Adapter enables a
pre-trained ultrasound foundation model to learn precise probe adjustment
strategies by fine-tuning only a small subset of parameters. Extensive
experiments demonstrate that the VA-Adapter can surpass strong probe guidance
models. Our code will be released after acceptance.

</details>


### [55] [Efficient Discriminative Joint Encoders for Large Scale Vision-Language Reranking](https://arxiv.org/abs/2510.06820)
*Mitchell Keren Taraday,Shahaf Wagner,Chaim Baskin*

Main category: cs.CV

TL;DR: EDJE是一种高效的多模态联合编码器，通过预压缩视觉令牌减少计算和存储开销，适用于大规模视觉-语言检索任务。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索主要依赖嵌入模型如CLIP，但缺乏高效的视觉-语言联合编码器。BLIP等经典联合编码器因昂贵的视觉特征提取阶段而难以大规模部署，EDJE旨在解决这一瓶颈。

Method: EDJE采用预计算视觉令牌离线存储，并通过轻量级基于注意力的适配器进行压缩，在线推理时仅运行紧凑的联合编码器处理少量视觉令牌和文本。

Result: EDJE在Flickr（零样本）和COCO（微调）检索任务上达到与现有技术相当的性能，同时处理速度达50k图像-文本对/秒，每图像仅需49kB磁盘存储。

Conclusion: EDJE作为一种高效的判别性联合编码器，通过预计算视觉令牌并压缩存储，显著降低了存储和在线计算需求，同时保持了强大的检索性能，适用于大规模部署。

Abstract: Multimodal retrieval still leans on embedding-based models like CLIP for fast
vector search over pre-computed image embeddings. Yet, unlike text retrieval,
where joint-encoder rerankers are standard, comparable vision--language
rerankers are largely absent. We find that seminal joint encoders such as BLIP
are severely bottlenecked by an expensive visual feature-extraction stage,
preventing practical deployment at scale. Motivated by this bottleneck, we
introduce EDJE, an Efficient Discriminative Joint Encoder that precomputes
vision tokens offline and compresses them via a lightweight attention-based
adapter, so online inference runs only a compact joint encoder over a small set
of visual tokens plus the text. EDJE preserves strong retrieval performance
while drastically reducing storage and online compute, enabling high-throughput
inference. Specifically, EDJE processes 50k image--text pairs/second while
requiring 49kB of disk storage per image, matching prior art on Flickr
(zero-shot) and COCO (fine-tuned) retrieval. The implementation and checkpoints
will be made publicly available shortly.

</details>


### [56] [StyleKeeper: Prevent Content Leakage using Negative Visual Query Guidance](https://arxiv.org/abs/2510.06827)
*Jaeseok Jeong,Junho Kim,Gayoung Lee,Yunjey Choi,Youngjung Uh*

Main category: cs.CV

TL;DR: 该论文提出了两种新方法（扩展CFG和NVQG）来解决文本到图像生成中的内容泄漏问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉提示方法在控制风格和内容时存在内容泄漏问题，即不希望传递的视觉风格提示元素被意外转移。

Method: 1) 扩展了分类器自由引导（CFG）以利用交换自注意力；2) 提出了负面视觉查询引导（NVQG），通过故意模拟内容泄漏场景来减少不想要内容的传递。

Result: 该方法显著减少了内容泄漏，生成图像更准确地反映了参考风格并与文本提示匹配。

Conclusion: 该论文提出了一种新方法，通过扩展分类器自由引导（CFG）和引入负面视觉查询引导（NVQG），有效减少了文本到图像生成中的内容泄漏问题。实验结果表明，该方法在多种风格和文本提示下表现优异，确保了生成图像与文本提示的匹配。

Abstract: In the domain of text-to-image generation, diffusion models have emerged as
powerful tools. Recently, studies on visual prompting, where images are used as
prompts, have enabled more precise control over style and content. However,
existing methods often suffer from content leakage, where undesired elements of
the visual style prompt are transferred along with the intended style. To
address this issue, we 1) extend classifier-free guidance (CFG) to utilize
swapping self-attention and propose 2) negative visual query guidance (NVQG) to
reduce the transfer of unwanted contents. NVQG employs negative score by
intentionally simulating content leakage scenarios that swap queries instead of
key and values of self-attention layers from visual style prompts. This simple
yet effective method significantly reduces content leakage. Furthermore, we
provide careful solutions for using a real image as visual style prompts.
Through extensive evaluation across various styles and text prompts, our method
demonstrates superiority over existing approaches, reflecting the style of the
references, and ensuring that resulting images match the text prompts. Our code
is available \href{https://github.com/naver-ai/StyleKeeper}{here}.

</details>


### [57] [Lattice-allocated Real-time Line Segment Feature Detection and Tracking Using Only an Event-based Camera](https://arxiv.org/abs/2510.06829)
*Mikihiro Ikura,Arren Glover,Masayoshi Mizuno,Chiara Bartolozzi*

Main category: cs.CV

TL;DR: 研究提出了一种仅用高分辨率事件相机实时检测和跟踪线段的方法，通过速度不变表示、拟合得分检测和端点扰动跟踪，实现了优于现有技术的独立操作。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法依赖额外帧相机或难以处理高事件率的问题，研究旨在开发一种仅使用现代高分辨率事件相机的实时线段检测和跟踪方法。

Method: 研究采用了一种基于晶格分配的流水线，包括速度不变的事件表示、基于拟合得分的线段检测和通过端点扰动的线段跟踪。

Result: 在自录数据集和公共数据集上的评估表明，该方法在实时性能和准确性上优于现有的事件独立和事件-帧混合基准方法。

Conclusion: 该研究实现了仅使用高分辨率事件相机进行实时线段检测和跟踪，展现了独立操作的可行性，并在准确性和实时性能上优于现有方法。

Abstract: Line segment extraction is effective for capturing geometric features of
human-made environments. Event-based cameras, which asynchronously respond to
contrast changes along edges, enable efficient extraction by reducing redundant
data. However, recent methods often rely on additional frame cameras or
struggle with high event rates. This research addresses real-time line segment
detection and tracking using only a modern, high-resolution (i.e., high event
rate) event-based camera. Our lattice-allocated pipeline consists of (i)
velocity-invariant event representation, (ii) line segment detection based on a
fitting score, (iii) and line segment tracking by perturbating endpoints.
Evaluation using ad-hoc recorded dataset and public datasets demonstrates
real-time performance and higher accuracy compared to state-of-the-art
event-only and event-frame hybrid baselines, enabling fully stand-alone event
camera operation in real-world settings.

</details>


### [58] [Continual Action Quality Assessment via Adaptive Manifold-Aligned Graph Regularization](https://arxiv.org/abs/2510.06842)
*Kanglei Zhou,Qingyi Pan,Xingxing Zhang,Hubert P. H. Shum,Frederick W. B. Li,Xiaohui Liang,Liyuan Wang*

Main category: cs.CV

TL;DR: MAGR++通过全参数微调和两步特征校正解决了CAQA中的灾难性遗忘问题，在多个数据集上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中质量分布的非平稳性限制了传统方法的泛化能力，因此需要引入持续学习（CL）能力来处理演化分布并减轻灾难性遗忘。

Method: 提出了Adaptive Manifold-Aligned Graph Regularization (MAGR++)，结合全参数微调（FPFT）和两步特征校正（流形投影和图形正则化）来稳定浅层网络并适应深层网络。

Result: MAGR++在四个CAQA基准测试中表现优异，离线平均相关性提升3.6%，在线提升12.2%，验证了其鲁棒性和有效性。

Conclusion: MAGR++通过结合骨干网络的微调和两步特征校正流程，有效解决了CAQA中的灾难性遗忘问题，并在多个数据集上实现了最先进的性能。

Abstract: Action Quality Assessment (AQA) quantifies human actions in videos,
supporting applications in sports scoring, rehabilitation, and skill
evaluation. A major challenge lies in the non-stationary nature of quality
distributions in real-world scenarios, which limits the generalization ability
of conventional methods. We introduce Continual AQA (CAQA), which equips AQA
with Continual Learning (CL) capabilities to handle evolving distributions
while mitigating catastrophic forgetting. Although parameter-efficient
fine-tuning of pretrained models has shown promise in CL for image
classification, we find it insufficient for CAQA. Our empirical and theoretical
analyses reveal two insights: (i) Full-Parameter Fine-Tuning (FPFT) is
necessary for effective representation learning; yet (ii) uncontrolled FPFT
induces overfitting and feature manifold shift, thereby aggravating forgetting.
To address this, we propose Adaptive Manifold-Aligned Graph Regularization
(MAGR++), which couples backbone fine-tuning that stabilizes shallow layers
while adapting deeper ones with a two-step feature rectification pipeline: a
manifold projector to translate deviated historical features into the current
representation space, and a graph regularizer to align local and global
distributions. We construct four CAQA benchmarks from three datasets with
tailored evaluation protocols and strong baselines, enabling systematic
cross-dataset comparison. Extensive experiments show that MAGR++ achieves
state-of-the-art performance, with average correlation gains of 3.6% offline
and 12.2% online over the strongest baseline, confirming its robustness and
effectiveness. Our code is available at https://github.com/ZhouKanglei/MAGRPP.

</details>


### [59] [Explaining raw data complexity to improve satellite onboard processing](https://arxiv.org/abs/2510.06858)
*Adrien Dorise,Marjorie Bellizzi,Adrien Girard,Benjamin Francesconi,Stéphane May*

Main category: cs.CV

TL;DR: 研究探讨了原始数据对深度学习模型在对象检测和分类任务中的影响，发现高置信度下原始数据模型的边界识别较弱，建议改进轮廓方法以提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着处理能力的提升，直接在卫星上部署AI模型成为可能，但原始数据的使用带来了新的挑战，当前解决方案主要依赖预处理数据，而直接利用原始数据的方法较少。

Method: 引入了一个模拟工作流程，从高分辨率L1图像生成类似原始数据的产品，并比较了YOLOv11s和YOLOX-S模型在原始数据和L1数据上的性能。

Result: 结果显示，在低到中等置信度阈值下，两种模型表现相似，但在高置信度水平下，基于原始数据训练的模型在对象边界识别上表现较差。

Conclusion: 研究建议通过改进轮廓识别方法来优化原始数据上的对象检测，从而提升卫星上AI在遥感领域的应用效果。

Abstract: With increasing processing power, deploying AI models for remote sensing
directly onboard satellites is becoming feasible. However, new constraints
arise, mainly when using raw, unprocessed sensor data instead of preprocessed
ground-based products. While current solutions primarily rely on preprocessed
sensor images, few approaches directly leverage raw data. This study
investigates the effects of utilising raw data on deep learning models for
object detection and classification tasks. We introduce a simulation workflow
to generate raw-like products from high-resolution L1 imagery, enabling
systemic evaluation. Two object detection models (YOLOv11s and YOLOX-S) are
trained on both raw and L1 datasets, and their performance is compared using
standard detection metrics and explainability tools. Results indicate that
while both models perform similarly at low to medium confidence thresholds, the
model trained on raw data struggles with object boundary identification at high
confidence levels. It suggests that adapting AI architectures with improved
contouring methods can enhance object detection on raw images, improving
onboard AI for remote sensing.

</details>


### [60] [Online Generic Event Boundary Detection](https://arxiv.org/abs/2510.06855)
*Hyungrok Jung,Daneul Kim,Seunggyun Lim,Jeany Son,Jonghyun Choi*

Main category: cs.CV

TL;DR: 本文提出在线通用事件边界检测（On-GEBD）任务及Estimator框架，通过预测误差和统计测试实时检测事件边界，性能接近离线方法。


<details>
  <summary>Details</summary>
Motivation: 现有GEBD方法需要完整视频帧处理，无法实时处理流视频，因此提出On-GEBD任务以模仿人类实时感知能力。

Method: 提出了Estimator框架，包含一致事件预测器（CEA）和在线边界判别器（OBD），利用预测误差和统计测试来检测事件边界。

Result: 在Kinetics-GEBD和TAPOS数据集上，Estimator优于所有基线模型，性能接近离线GEBD方法。

Conclusion: Estimator框架在在线通用事件边界检测（On-GEBD）任务中表现出色，性能接近离线方法，解决了实时处理流视频的挑战。

Abstract: Generic Event Boundary Detection (GEBD) aims to interpret long-form videos
through the lens of human perception. However, current GEBD methods require
processing complete video frames to make predictions, unlike humans processing
data online and in real-time. To bridge this gap, we introduce a new task,
Online Generic Event Boundary Detection (On-GEBD), aiming to detect boundaries
of generic events immediately in streaming videos. This task faces unique
challenges of identifying subtle, taxonomy-free event changes in real-time,
without the access to future frames. To tackle these challenges, we propose a
novel On-GEBD framework, Estimator, inspired by Event Segmentation Theory (EST)
which explains how humans segment ongoing activity into events by leveraging
the discrepancies between predicted and actual information. Our framework
consists of two key components: the Consistent Event Anticipator (CEA), and the
Online Boundary Discriminator (OBD). Specifically, the CEA generates a
prediction of the future frame reflecting current event dynamics based solely
on prior frames. Then, the OBD measures the prediction error and adaptively
adjusts the threshold using statistical tests on past errors to capture
diverse, subtle event transitions. Experimental results demonstrate that
Estimator outperforms all baselines adapted from recent online video
understanding models and achieves performance comparable to prior offline-GEBD
methods on the Kinetics-GEBD and TAPOS datasets.

</details>


### [61] [Generating Surface for Text-to-3D using 2D Gaussian Splatting](https://arxiv.org/abs/2510.06967)
*Huanning Dong,Fan Li,Ping Kuang,Jianwen Min*

Main category: cs.CV

TL;DR: DirectGaussian是一种新方法，通过条件文本生成和2D高斯泼溅技术生成3D对象表面，解决了多视角几何一致性问题，实现了高保真3D内容生成。


<details>
  <summary>Details</summary>
Motivation: 由于自然世界中物体的复杂几何形状，生成3D内容仍具挑战性。现有方法要么依赖2D扩散先验恢复3D几何，要么基于特定3D表示直接训练模型。

Method: DirectGaussian利用条件文本生成模型和2D高斯泼溅技术，结合多视角法线和纹理先验来渲染3D对象的表面，并在优化过程中引入曲率约束以解决多视角几何一致性问题。

Result: 实验表明，DirectGaussian能够实现多样且高保真的3D内容生成。

Conclusion: DirectGaussian框架通过结合条件文本生成模型和多视角几何约束，能够实现多样且高保真的3D内容生成。

Abstract: Recent advancements in Text-to-3D modeling have shown significant potential
for the creation of 3D content. However, due to the complex geometric shapes of
objects in the natural world, generating 3D content remains a challenging task.
Current methods either leverage 2D diffusion priors to recover 3D geometry, or
train the model directly based on specific 3D representations. In this paper,
we propose a novel method named DirectGaussian, which focuses on generating the
surfaces of 3D objects represented by surfels. In DirectGaussian, we utilize
conditional text generation models and the surface of a 3D object is rendered
by 2D Gaussian splatting with multi-view normal and texture priors. For
multi-view geometric consistency problems, DirectGaussian incorporates
curvature constraints on the generated surface during optimization process.
Through extensive experiments, we demonstrate that our framework is capable of
achieving diverse and high-fidelity 3D content creation.

</details>


### [62] [Learning Global Representation from Queries for Vectorized HD Map Construction](https://arxiv.org/abs/2510.06969)
*Shoumeng Qiu,Xinrun Li,Yang Long,Xiangyang Xue,Varun Ojha,Jian Pu*

Main category: cs.CV

TL;DR: MapGR通过全局表示学习提升HD地图构建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于DETR框架的方法依赖局部查询视角，忽视了HD地图的全局表示，导致性能受限。

Method: 提出了MapGR架构，包含全局表示学习（GRL）模块和全局表示指导（GRG）模块，通过全局视角优化查询。

Result: 在nuScenes和Argoverse2数据集上验证，MapGR在mAP指标上显著优于现有基线方法。

Conclusion: MapGR通过全局表示学习和指导模块，显著提升了高精地图构建的精度，验证了全局表示在HD地图构建中的重要性。

Abstract: The online construction of vectorized high-definition (HD) maps is a
cornerstone of modern autonomous driving systems. State-of-the-art approaches,
particularly those based on the DETR framework, formulate this as an instance
detection problem. However, their reliance on independent, learnable object
queries results in a predominantly local query perspective, neglecting the
inherent global representation within HD maps. In this work, we propose
\textbf{MapGR} (\textbf{G}lobal \textbf{R}epresentation learning for HD
\textbf{Map} construction), an architecture designed to learn and utilize a
global representations from queries. Our method introduces two synergistic
modules: a Global Representation Learning (GRL) module, which encourages the
distribution of all queries to better align with the global map through a
carefully designed holistic segmentation task, and a Global Representation
Guidance (GRG) module, which endows each individual query with explicit,
global-level contextual information to facilitate its optimization. Evaluations
on the nuScenes and Argoverse2 datasets validate the efficacy of our approach,
demonstrating substantial improvements in mean Average Precision (mAP) compared
to leading baselines.

</details>


### [63] [Lung Infection Severity Prediction Using Transformers with Conditional TransMix Augmentation and Cross-Attention](https://arxiv.org/abs/2510.06887)
*Bouthaina Slika,Fadi Dornaika,Fares Bougourzi,Karim Hammoudi*

Main category: cs.CV

TL;DR: 本文提出了一种结合Transformer架构和自定义数据增强策略的新方法，用于肺部感染严重性预测，在多个数据集上表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 肺部感染（尤其是肺炎）在疫情期间可能迅速恶化，基于AI的准确严重性预测对及时临床决策和优化患者预后至关重要。

Method: 提出了一种新颖的Transformer架构QCross-Att-PVT，结合了并行编码器、交叉门控注意力机制和特征聚合器，以及一种名为Conditional Online TransMix的自定义数据增强策略。

Result: 在两个基准数据集（RALO CXR和Per-COVID-19 CT）上评估，该方法 consistently 优于多种最先进的深度学习模型。

Conclusion: 该方法为临床诊断、疾病监测和个性化治疗规划提供了可靠且适应性强的工具。

Abstract: Lung infections, particularly pneumonia, pose serious health risks that can
escalate rapidly, especially during pandemics. Accurate AI-based severity
prediction from medical imaging is essential to support timely clinical
decisions and optimize patient outcomes. In this work, we present a novel
method applicable to both CT scans and chest X-rays for assessing lung
infection severity. Our contributions are twofold: (i) QCross-Att-PVT, a
Transformer-based architecture that integrates parallel encoders, a cross-gated
attention mechanism, and a feature aggregator to capture rich multi-scale
features; and (ii) Conditional Online TransMix, a custom data augmentation
strategy designed to address dataset imbalance by generating mixed-label image
patches during training. Evaluated on two benchmark datasets, RALO CXR and
Per-COVID-19 CT, our method consistently outperforms several state-of-the-art
deep learning models. The results emphasize the critical role of data
augmentation and gated attention in improving both robustness and predictive
accuracy. This approach offers a reliable, adaptable tool to support clinical
diagnosis, disease monitoring, and personalized treatment planning. The source
code of this work is available at https://github.com/bouthainas/QCross-Att-PVT.

</details>


### [64] [Label-frugal satellite image change detection with generative virtual exemplar learning](https://arxiv.org/abs/2510.06926)
*Hichem Sahbi*

Main category: cs.CV

TL;DR: 本文提出一种基于主动学习的变化检测算法，通过生成关键虚拟样本优先标注，显著减少标注需求并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖大量人工标注数据，标注成本高且受用户主观性影响。本文旨在通过主动学习减少标注需求，提高变化检测效率。

Method: 使用可逆图卷积网络生成虚拟样本，结合对抗性损失衡量样本的代表性、多样性和模糊性，优先标注对当前变化检测标准最具挑战性的样本。

Result: 实验表明，该模型在标注效率上优于对比方法，有效提升了变化检测性能。

Conclusion: 本文提出了一种基于主动学习的新型变化检测算法，通过生成虚拟样本并优先标注关键样本，显著提高了标注效率，并在实验中优于对比方法。

Abstract: Change detection is a major task in remote sensing which consists in finding
all the occurrences of changes in multi-temporal satellite or aerial images.
The success of existing methods, and particularly deep learning ones, is
tributary to the availability of hand-labeled training data that capture the
acquisition conditions and the subjectivity of the user (oracle). In this
paper, we devise a novel change detection algorithm, based on active learning.
The main contribution of our work resides in a new model that measures how
important is each unlabeled sample, and provides an oracle with only the most
critical samples (also referred to as virtual exemplars) for further labeling.
These exemplars are generated, using an invertible graph convnet, as the
optimum of an adversarial loss that (i) measures representativity, diversity
and ambiguity of the data, and thereby (ii) challenges (the most) the current
change detection criteria, leading to a better re-estimate of these criteria in
the subsequent iterations of active learning. Extensive experiments show the
positive impact of our label-efficient learning model against comparative
methods.

</details>


### [65] [Graph Conditioned Diffusion for Controllable Histopathology Image Generation](https://arxiv.org/abs/2510.07129)
*Sarah Cechnicka,Matthew Baugh,Weitong Zhang,Mischa Dombrowski,Zhe Li,Johannes C. Paetzold,Candice Roufosse,Bernhard Kainz*

Main category: cs.CV

TL;DR: 提出Graph-Conditioned-Diffusion方法，通过图节点表示医学图像结构，实现精细控制生成，验证了其在组织病理学中的实用性。


<details>
  <summary>Details</summary>
Motivation: 现有DPMs在噪声潜在空间中缺乏语义结构和强先验，难以实现对生成内容的有意义控制，尤其是在医学图像这类敏感领域。

Method: 提出了一种基于图的对象级表示方法，通过生成与图像主要结构对应的图节点，捕捉其个体特征和关系，并结合Transformer模块和扩散模型的文本条件机制实现精细控制。

Result: 在真实组织病理学用例中验证了方法的有效性，生成的图像数据可可靠替代标注患者数据用于下游分割任务。

Conclusion: 通过引入基于图的对象级表示和Graph-Conditioned-Diffusion，本研究成功提升了DPMs在医学图像生成中的可控性，生成的图像数据可有效替代真实标注数据用于下游分割任务。

Abstract: Recent advances in Diffusion Probabilistic Models (DPMs) have set new
standards in high-quality image synthesis. Yet, controlled generation remains
challenging, particularly in sensitive areas such as medical imaging. Medical
images feature inherent structure such as consistent spatial arrangement, shape
or texture, all of which are critical for diagnosis. However, existing DPMs
operate in noisy latent spaces that lack semantic structure and strong priors,
making it difficult to ensure meaningful control over generated content. To
address this, we propose graph-based object-level representations for
Graph-Conditioned-Diffusion. Our approach generates graph nodes corresponding
to each major structure in the image, encapsulating their individual features
and relationships. These graph representations are processed by a transformer
module and integrated into a diffusion model via the text-conditioning
mechanism, enabling fine-grained control over generation. We evaluate this
approach using a real-world histopathology use case, demonstrating that our
generated data can reliably substitute for annotated patient data in downstream
segmentation tasks. The code is available here.

</details>


### [66] [IAR2: Improving Autoregressive Visual Generation with Semantic-Detail Associated Token Prediction](https://arxiv.org/abs/2510.06928)
*Ran Yi,Teng Hu,Zihan Su,Lizhuang Ma*

Main category: cs.CV

TL;DR: IAR2 是一种先进的层次化自回归框架，通过双码本和动态条件生成机制，显著提升了图像生成的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在视觉内容生成中往往忽略了视觉数据的固有结构特性。IAR2 旨在克服预训练码本的刚性和硬性、均匀聚类的不足，通过更灵活的层次化语义-细节合成过程提升生成鲁棒性。

Method: IAR2 采用了一种新颖的语义-细节关联双码本，将图像表示解耦为全局语义信息的语义码本和细粒度细节的细节码本，并通过语义-细节自回归预测方案和本地上下文增强自回归头进行分层预测。此外，还引入了渐进注意力引导的自适应 CFG 机制用于条件生成。

Result: IAR2 在 ImageNet 上实现了 1.50 的 FID 分数，显著提升了自回归图像生成的表达能力和条件对齐效果。

Conclusion: IAR2 在自回归图像生成领域设定了新的最先进水平，不仅在性能上超越先前方法，还展示了卓越的计算效率，证明了其结构化的、由粗到细的生成策略的有效性。

Abstract: Autoregressive models have emerged as a powerful paradigm for visual content
creation, but often overlook the intrinsic structural properties of visual
data. Our prior work, IAR, initiated a direction to address this by
reorganizing the visual codebook based on embedding similarity, thereby
improving generation robustness. However, it is constrained by the rigidity of
pre-trained codebooks and the inaccuracies of hard, uniform clustering. To
overcome these limitations, we propose IAR2, an advanced autoregressive
framework that enables a hierarchical semantic-detail synthesis process. At the
core of IAR2 is a novel Semantic-Detail Associated Dual Codebook, which
decouples image representations into a semantic codebook for global semantic
information and a detail codebook for fine-grained refinements. It expands the
quantization capacity from a linear to a polynomial scale, significantly
enhancing expressiveness. To accommodate this dual representation, we propose a
Semantic-Detail Autoregressive Prediction scheme coupled with a Local-Context
Enhanced Autoregressive Head, which performs hierarchical prediction-first the
semantic token, then the detail token-while leveraging a local context window
to enhance spatial coherence. Furthermore, for conditional generation, we
introduce a Progressive Attention-Guided Adaptive CFG mechanism that
dynamically modulates the guidance scale for each token based on its relevance
to the condition and its temporal position in the generation sequence,
improving conditional alignment without sacrificing realism. Extensive
experiments demonstrate that IAR2 sets a new state-of-the-art for
autoregressive image generation, achieving a FID of 1.50 on ImageNet. Our model
not only surpasses previous methods in performance but also demonstrates
superior computational efficiency, highlighting the effectiveness of our
structured, coarse-to-fine generation strategy.

</details>


### [67] [OBJVanish: Physically Realizable Text-to-3D Adv. Generation of LiDAR-Invisible Objects](https://arxiv.org/abs/2510.06952)
*Bing Li,Wuqi Wang,Yanan Zhang,Jingzheng Li,Haigen Min,Wei Feng,Xingyu Zhao,Jie Zhang,Qing Guo*

Main category: cs.CV

TL;DR: 本文提出了一种物理可实现的文本到3D对抗生成方法（Phy3DAdvGen），通过优化文本提示生成LiDAR不可见的行人模型，成功逃逸多种先进检测器，揭示了3D检测系统的安全风险。


<details>
  <summary>Details</summary>
Motivation: 现有3D对抗攻击方法难以实现完全物体消失且物理环境实现困难，亟需一种更有效的攻击方法以测试LiDAR检测系统的鲁棒性。

Method: 通过系统研究影响检测脆弱性的因素（如拓扑、连接性和强度），并结合CARLA模拟环境中的多对象组合，提出了一种物理信息引导的文本到3D对抗生成方法。该方法通过迭代优化文本提示（动词、对象和姿态）生成LiDAR不可见的3D行人模型，并约束生成的3D对象基于现实对象池的组合。

Result: 实验证明，Phy3DAdvGen生成的3D行人能在CARLA模拟和物理环境中逃逸六种先进的LiDAR 3D检测器，显著暴露了安全关键应用的漏洞。

Conclusion: 本文提出了一种新颖的文本到3D对抗生成方法（Phy3DAdvGen），能够生成在物理环境中易于实现的LiDAR不可见行人模型，有效暴露了现有3D物体检测器的漏洞。

Abstract: LiDAR-based 3D object detectors are fundamental to autonomous driving, where
failing to detect objects poses severe safety risks. Developing effective 3D
adversarial attacks is essential for thoroughly testing these detection systems
and exposing their vulnerabilities before real-world deployment. However,
existing adversarial attacks that add optimized perturbations to 3D points have
two critical limitations: they rarely cause complete object disappearance and
prove difficult to implement in physical environments. We introduce the
text-to-3D adversarial generation method, a novel approach enabling physically
realizable attacks that can generate 3D models of objects truly invisible to
LiDAR detectors and be easily realized in the real world. Specifically, we
present the first empirical study that systematically investigates the factors
influencing detection vulnerability by manipulating the topology, connectivity,
and intensity of individual pedestrian 3D models and combining pedestrians with
multiple objects within the CARLA simulation environment. Building on the
insights, we propose the physically-informed text-to-3D adversarial generation
(Phy3DAdvGen) that systematically optimizes text prompts by iteratively
refining verbs, objects, and poses to produce LiDAR-invisible pedestrians. To
ensure physical realizability, we construct a comprehensive object pool
containing 13 3D models of real objects and constrain Phy3DAdvGen to generate
3D objects based on combinations of objects in this set. Extensive experiments
demonstrate that our approach can generate 3D pedestrians that evade six
state-of-the-art (SOTA) LiDAR 3D detectors in both CARLA simulation and
physical environments, thereby highlighting vulnerabilities in safety-critical
applications.

</details>


### [68] [Resolution scaling governs DINOv3 transfer performance in chest radiograph classification](https://arxiv.org/abs/2510.07191)
*Soroosh Tayebi Arasteh,Mina Shaigan,Christiane Kuhl,Jakob Nikolas Kather,Sven Nebelung,Daniel Truhn*

Main category: cs.CV

TL;DR: DINOv3在512x512分辨率下表现最佳，ConvNeXt-B优于ViT-B/16，冻结大模型特征不如微调中等骨干网络，支持在胸部X光片解释中使用512x512分辨率的中等骨干网络。


<details>
  <summary>Details</summary>
Motivation: 自监督学习（SSL）在视觉表示学习方面取得了进展，但其在胸部X光摄影（一种具有细粒度发现的高容量成像方式）中的价值尚不明确。Meta的DINOv3通过Gram-anchored自蒸馏扩展了早期的SSL模型。这些设计选择是否改善了胸部X光摄影的迁移学习尚未系统测试。

Method: 我们通过评估DINOv3、DINOv2和ImageNet初始化在七个数据集（n>814,000）上的表现进行基准测试。使用了两种代表性骨干网络：ViT-B/16和ConvNeXt-B。图像分别在224x224、512x512和1024x1024像素下进行分析。还评估了7B模型的冻结特征。主要结果是跨标签的平均AUROC。

Result: 在224x224分辨率下，DINOv3和DINOv2在成人数据集上表现相当。将分辨率提高到512x512，DINOv3相比DINOv2和ImageNet持续改进。儿科队列中不同初始化方法间无差异。ConvNeXt-B在所有设置中优于ViT-B/16。冻结的DINOv3-7B特征表现不如完全微调的86-89M参数骨干网络。1024x1024分辨率未进一步提高准确性。分辨率相关增益在边界依赖和小病灶异常中最明显。

Conclusion: 在胸部X光摄影中，512x512像素的分辨率代表了DINOv3初始化的ConvNeXt-B网络提供最强性能的实际上限，而更大的输入成本回报有限。临床实践中，这些发现支持使用512x512分辨率的中等规模骨干网络进行胸部X光片解释，预计在检测与急诊和重症监护相关的细微或边界中心病变方面获得最大收益。

Abstract: Self-supervised learning (SSL) has advanced visual representation learning,
but its value in chest radiography, a high-volume imaging modality with
fine-grained findings, remains unclear. Meta's DINOv3 extends earlier SSL
models through Gram-anchored self-distillation. Whether these design choices
improve transfer learning for chest radiography has not been systematically
tested. We benchmarked DINOv3 against DINOv2 and ImageNet initialization across
seven datasets (n>814,000). Two representative backbones were evaluated:
ViT-B/16 and ConvNeXt-B. Images were analyzed at 224x224, 512x512, and
1024x1024 pixels. We additionally assessed frozen features from a 7B model. The
primary outcome was mean AUROC across labels. At 224x224, DINOv3 and DINOv2
achieved comparable performance on adult datasets. Increasing resolution to
512x512 yielded consistent improvements for DINOv3 over both DINOv2 and
ImageNet. In contrast, results in pediatric cohort showed no differences across
initializations. Across all settings, ConvNeXt-B outperformed ViT-B/16. Models
using frozen DINOv3-7B features underperformed relative to fully finetuned
86-89M-parameter backbones, highlighting the importance of domain adaptation.
Scaling to 1024x1024 did not further improve accuracy. Resolution-related gains
were most evident for boundary-dependent and small focal abnormalities. In
chest radiography, higher input resolution is critical for leveraging the
benefits of modern self-supervised models. 512x512 pixels represent a practical
upper limit where DINOv3-initialized ConvNeXt-B networks provide the strongest
performance, while larger inputs offer minimal return on cost. Clinically,
these findings support use of finetuned, mid-sized backbones at 512x512 for
chest radiograph interpretation, with the greatest gains expected in detecting
subtle or boundary-centered lesions relevant to emergency and critical care
settings.

</details>


### [69] [Addressing the ID-Matching Challenge in Long Video Captioning](https://arxiv.org/abs/2510.06973)
*Zhantao Yang,Huangji Wang,Ruili Feng,Han Zhang,Yuting Hu,Shangwen Zhu,Junyan Li,Yu Liu,Fan Cheng*

Main category: cs.CV

TL;DR: 论文提出RICE方法，利用LVLMs的固有能力解决长视频字幕中的ID-Matching问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 长视频字幕生成中的ID-Matching问题（即识别不同帧中的同一人物）是关键挑战，现有方法泛化能力有限且依赖点对点匹配。

Method: 基于LVLMs（如GPT-4o）的固有能力，提出RICE方法，通过增强图像信息利用和增加个体描述信息量来改进ID-Matching。

Result: RICE在GPT-4o上实现了ID-Matching精确度从50%到90%、召回率从15%到80%的提升。

Conclusion: RICE方法显著提升了长视频字幕中的ID-Matching性能，将精确度从50%提升至90%，召回率从15%提升至80%，实现了对不同个体的持续跟踪。

Abstract: Generating captions for long and complex videos is both critical and
challenging, with significant implications for the growing fields of
text-to-video generation and multi-modal understanding. One key challenge in
long video captioning is accurately recognizing the same individuals who appear
in different frames, which we refer to as the ID-Matching problem. Few prior
works have focused on this important issue. Those that have, usually suffer
from limited generalization and depend on point-wise matching, which limits
their overall effectiveness. In this paper, unlike previous approaches, we
build upon LVLMs to leverage their powerful priors. We aim to unlock the
inherent ID-Matching capabilities within LVLMs themselves to enhance the
ID-Matching performance of captions. Specifically, we first introduce a new
benchmark for assessing the ID-Matching capabilities of video captions. Using
this benchmark, we investigate LVLMs containing GPT-4o, revealing key insights
that the performance of ID-Matching can be improved through two methods: 1)
enhancing the usage of image information and 2) increasing the quantity of
information of individual descriptions. Based on these insights, we propose a
novel video captioning method called Recognizing Identities for Captioning
Effectively (RICE). Extensive experiments including assessments of caption
quality and ID-Matching performance, demonstrate the superiority of our
approach. Notably, when implemented on GPT-4o, our RICE improves the precision
of ID-Matching from 50% to 90% and improves the recall of ID-Matching from 15%
to 80% compared to baseline. RICE makes it possible to continuously track
different individuals in the captions of long videos.

</details>


### [70] [No MoCap Needed: Post-Training Motion Diffusion Models with Reinforcement Learning using Only Textual Prompts](https://arxiv.org/abs/2510.06988)
*Girolamo Macaluso,Lorenzo Mandelli,Mirko Bicchierai,Stefano Berretti,Andrew D. Bagdanov*

Main category: cs.CV

TL;DR: 提出一种无需运动真值的后训练框架，通过强化学习微调预训练运动扩散模型，提高生成运动的适应性和多样性。


<details>
  <summary>Details</summary>
Motivation: 适应未见动作或风格通常需要额外运动捕捉数据和完整重新训练，成本高且难以扩展。

Method: 基于强化学习的后训练框架，利用预训练的文本-运动检索网络作为奖励信号，通过Denoising Diffusion Policy Optimization优化扩散策略。

Result: 在HumanML3D和KIT-ML数据集上的实验表明，该方法在保持原始分布性能的同时，提高了生成运动的质量和多样性。

Conclusion: 提出的方法是一种灵活、数据高效且保护隐私的运动适应解决方案。

Abstract: Diffusion models have recently advanced human motion generation, producing
realistic and diverse animations from textual prompts. However, adapting these
models to unseen actions or styles typically requires additional motion capture
data and full retraining, which is costly and difficult to scale. We propose a
post-training framework based on Reinforcement Learning that fine-tunes
pretrained motion diffusion models using only textual prompts, without
requiring any motion ground truth. Our approach employs a pretrained
text-motion retrieval network as a reward signal and optimizes the diffusion
policy with Denoising Diffusion Policy Optimization, effectively shifting the
model's generative distribution toward the target domain without relying on
paired motion data. We evaluate our method on cross-dataset adaptation and
leave-one-out motion experiments using the HumanML3D and KIT-ML datasets across
both latent- and joint-space diffusion architectures. Results from quantitative
metrics and user studies show that our approach consistently improves the
quality and diversity of generated motions, while preserving performance on the
original distribution. Our approach is a flexible, data-efficient, and
privacy-preserving solution for motion adaptation.

</details>


### [71] [GenPilot: A Multi-Agent System for Test-Time Prompt Optimization in Image Generation](https://arxiv.org/abs/2510.07217)
*Wen Ye,Zhaocheng Liu,Yuwei Gui,Tingyu Yuan,Yunyue Su,Bowen Fang,Chaoyang Zhao,Qiang Liu,Liang Wang*

Main category: cs.CV

TL;DR: GenPilot是一种测试时提示优化策略，通过多代理系统提升文本到图像合成的准确性和一致性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像合成方法在处理复杂长提示时存在语义不一致和细节缺失问题，而现有解决方案如微调或自动提示优化方法缺乏系统性的错误分析和优化策略，限制了其可靠性和效果。

Method: 提出了一种名为GenPilot的即插即用多代理系统，集成了错误分析、基于聚类的自适应探索、细粒度验证和用于迭代优化的记忆模块。

Result: 在DPG-bench和Geneval上的实验显示，该方法分别提升了16.9%和5.7%的文本和图像一致性及结构连贯性。

Conclusion: GenPilot作为一种灵活高效的测试时提示优化策略，通过多代理系统集成错误分析、聚类自适应探索和细粒度验证，显著提升了文本到图像合成的准确性和一致性。实验结果显示，该方法在DPG-bench和Geneval上分别实现了16.9%和5.7%的提升，验证了其有效性。

Abstract: Text-to-image synthesis has made remarkable progress, yet accurately
interpreting complex and lengthy prompts remains challenging, often resulting
in semantic inconsistencies and missing details. Existing solutions, such as
fine-tuning, are model-specific and require training, while prior automatic
prompt optimization (APO) approaches typically lack systematic error analysis
and refinement strategies, resulting in limited reliability and effectiveness.
Meanwhile, test-time scaling methods operate on fixed prompts and on noise or
sample numbers, limiting their interpretability and adaptability. To solve
these, we introduce a flexible and efficient test-time prompt optimization
strategy that operates directly on the input text. We propose a plug-and-play
multi-agent system called GenPilot, integrating error analysis,
clustering-based adaptive exploration, fine-grained verification, and a memory
module for iterative optimization. Our approach is model-agnostic,
interpretable, and well-suited for handling long and complex prompts.
Simultaneously, we summarize the common patterns of errors and the refinement
strategy, offering more experience and encouraging further exploration.
Experiments on DPG-bench and Geneval with improvements of up to 16.9% and 5.7%
demonstrate the strong capability of our methods in enhancing the text and
image consistency and structural coherence of generated images, revealing the
effectiveness of our test-time prompt optimization strategy. The code is
available at https://github.com/27yw/GenPilot.

</details>


### [72] [Bayesian Modelling of Multi-Year Crop Type Classification Using Deep Neural Networks and Hidden Markov Models](https://arxiv.org/abs/2510.07008)
*Gianmarco Perantoni,Giulio Weikmann,Lorenzo Bruzzone*

Main category: cs.CV

TL;DR: 结合HMM与Transformer的深度学习方法有效提升了年度卫星图像时间序列的分类性能，验证了时间一致性的重要性。


<details>
  <summary>Details</summary>
Motivation: 年度土地覆盖图的时间一致性对于模拟多年土地覆盖的演变和变化至关重要。

Method: 该方法集成了隐马尔可夫模型（HMM）和基于Transformer编码器（TE）的深度神经网络（DNN），旨在捕捉年度SITS中复杂的时序相关性以及多年作物类型序列中的特定模式。

Result: 在包含47种作物类型和六年Sentinel-2数据的多年作物类型分类数据集上的验证表明，建模预测标签的时间一致性显著提升了整体性能和F1分数。

Conclusion: 该论文提出了一种结合深度学习和贝叶斯建模的新方法，通过隐马尔可夫模型（HMM）与Transformer编码器（TE）的深度神经网络（DNN）集成，显著提升了年度卫星图像时间序列（SITS）的分类性能。

Abstract: The temporal consistency of yearly land-cover maps is of great importance to
model the evolution and change of the land cover over the years. In this paper,
we focus the attention on a novel approach to classification of yearly
satellite image time series (SITS) that combines deep learning with Bayesian
modelling, using Hidden Markov Models (HMMs) integrated with Transformer
Encoder (TE) based DNNs. The proposed approach aims to capture both i)
intricate temporal correlations in yearly SITS and ii) specific patterns in
multiyear crop type sequences. It leverages the cascade classification of an
HMM layer built on top of the TE, discerning consistent yearly crop-type
sequences. Validation on a multiyear crop type classification dataset spanning
47 crop types and six years of Sentinel-2 acquisitions demonstrates the
importance of modelling temporal consistency in the predicted labels. HMMs
enhance the overall performance and F1 scores, emphasising the effectiveness of
the proposed approach.

</details>


### [73] [U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking](https://arxiv.org/abs/2510.07041)
*Fenghe Tang,Chengqi Dong,Wenxin Ma,Zikang Xu,Heqin Zhu,Zihang Jiang,Rongsheng Wang,Yuhao Wang,Chenxu Wu,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: U-Bench是首个大规模、统计严谨的基准测试，评估了100种U-Net变体，填补了医学图像分割领域的评估空白。


<details>
  <summary>Details</summary>
Motivation: 尽管U-Net在医学图像分割中广泛应用，但缺乏全面且统计严谨的基准测试来评估其变体的性能和实用性。

Method: U-Bench通过三个关键维度（统计稳健性、零样本泛化能力和计算效率）评估了100种U-Net变体，并引入了新指标U-Score来综合性能与效率。

Result: U-Bench评估了28个数据集和10种成像模态，提供了模型选择建议，并公开了所有代码、模型和协议。

Conclusion: U-Bench填补了以往评估的空白，为未来十年基于U-Net的分割模型建立了公平、可重现且实用的基准测试基础。

Abstract: Over the past decade, U-Net has been the dominant architecture in medical
image segmentation, leading to the development of thousands of U-shaped
variants. Despite its widespread adoption, there is still no comprehensive
benchmark to systematically evaluate their performance and utility, largely
because of insufficient statistical validation and limited consideration of
efficiency and generalization across diverse datasets. To bridge this gap, we
present U-Bench, the first large-scale, statistically rigorous benchmark that
evaluates 100 U-Net variants across 28 datasets and 10 imaging modalities. Our
contributions are threefold: (1) Comprehensive Evaluation: U-Bench evaluates
models along three key dimensions: statistical robustness, zero-shot
generalization, and computational efficiency. We introduce a novel metric,
U-Score, which jointly captures the performance-efficiency trade-off, offering
a deployment-oriented perspective on model progress. (2) Systematic Analysis
and Model Selection Guidance: We summarize key findings from the large-scale
evaluation and systematically analyze the impact of dataset characteristics and
architectural paradigms on model performance. Based on these insights, we
propose a model advisor agent to guide researchers in selecting the most
suitable models for specific datasets and tasks. (3) Public Availability: We
provide all code, models, protocols, and weights, enabling the community to
reproduce our results and extend the benchmark with future methods. In summary,
U-Bench not only exposes gaps in previous evaluations but also establishes a
foundation for fair, reproducible, and practically relevant benchmarking in the
next decade of U-Net-based segmentation models. The project can be accessed at:
https://fenghetan9.github.io/ubench. Code is available at:
https://github.com/FengheTan9/U-Bench.

</details>


### [74] [Concept Retrieval -- What and How?](https://arxiv.org/abs/2510.07058)
*Ori nizan,Oren Shrout,Ayellet Tal*

Main category: cs.CV

TL;DR: 本文提出一种基于双模态高斯分布的方法，用于识别图像中的核心概念，超越传统检索方法，并通过评估验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统检索或聚类方法侧重于视觉或语义相似性，无法捕捉图像背后的核心概念或叙事。本文旨在解决这一问题。

Method: 基于两个关键观察：(1) 嵌入空间中的邻居通常与查询共享至少一个概念，但邻居之间不一定共享相同概念；(2) 使用双模态高斯分布建模邻域，揭示有助于概念识别的有意义结构。

Result: 通过定性、定量和人工评估，证实了所提方法的有效性。

Conclusion: 本文提出的方法通过双模态高斯分布建模邻域结构，有效识别图像中的核心概念，超越了传统的视觉或语义相似性检索方法。

Abstract: A concept may reflect either a concrete or abstract idea. Given an input
image, this paper seeks to retrieve other images that share its central
concepts, capturing aspects of the underlying narrative. This goes beyond
conventional retrieval or clustering methods, which emphasize visual or
semantic similarity. We formally define the problem, outline key requirements,
and introduce appropriate evaluation metrics. We propose a novel approach
grounded in two key observations: (1) While each neighbor in the embedding
space typically shares at least one concept with the query, not all neighbors
necessarily share the same concept with one another. (2) Modeling this
neighborhood with a bimodal Gaussian distribution uncovers meaningful structure
that facilitates concept identification. Qualitative, quantitative, and human
evaluations confirm the effectiveness of our approach. See the package on PyPI:
https://pypi.org/project/coret/

</details>


### [75] [DADO: A Depth-Attention framework for Object Discovery](https://arxiv.org/abs/2510.07089)
*Federico Gonzalez,Estefania Talavera,Petia Radeva*

Main category: cs.CV

TL;DR: DADO是一种结合注意力机制和深度模型的无监督对象发现方法，通过动态加权策略在复杂场景中表现出色，无需微调即可超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 无监督对象发现是计算机视觉中的重要挑战，现有方法在噪声注意力图或复杂场景中表现不佳，因此需要一种更鲁棒的解决方案。

Method: DADO采用动态加权策略，根据图像的全局特征自适应调整注意力或深度特征的权重，以解决噪声注意力图或复杂场景中的深度变化问题。

Result: 在标准基准测试中，DADO在对象发现准确性和鲁棒性方面优于现有最先进方法。

Conclusion: DADO模型通过结合注意力机制和深度模型，在无监督对象发现任务中表现出色，无需微调即可在标准基准测试中超越现有方法。

Abstract: Unsupervised object discovery, the task of identifying and localizing objects
in images without human-annotated labels, remains a significant challenge and a
growing focus in computer vision. In this work, we introduce a novel model,
DADO (Depth-Attention self-supervised technique for Discovering unseen
Objects), which combines an attention mechanism and a depth model to identify
potential objects in images. To address challenges such as noisy attention maps
or complex scenes with varying depth planes, DADO employs dynamic weighting to
adaptively emphasize attention or depth features based on the global
characteristics of each image. We evaluated DADO on standard benchmarks, where
it outperforms state-of-the-art methods in object discovery accuracy and
robustness without the need for fine-tuning.

</details>


### [76] [Enhancing Concept Localization in CLIP-based Concept Bottleneck Models](https://arxiv.org/abs/2510.07115)
*Rémi Kazmierczak,Steve Azzolin,Eloïse Berthier,Goran Frehse,Gianni Franchi*

Main category: cs.CV

TL;DR: 论文提出CHILI技术，通过解耦和定位像素抑制CLIP的概念幻觉，提升概念瓶颈模型的解释可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决CLIP在零样本方式下提取概念时产生的概念幻觉问题，这一问题影响了概念瓶颈模型的解释可信度。

Method: 论文引入了Concept Hallucination Inhibition via Localized Interpretability (CHILI)技术，通过解耦图像嵌入和定位目标概念的像素，生成更具可解释性的显著性解释。

Result: 研究结果表明，CHILI技术能够有效抑制概念幻觉，并支持生成更易理解的显著性解释。

Conclusion: 论文提出了一种名为CHILI的技术，通过解耦图像嵌入并定位目标概念对应的像素，有效抑制了CLIP在概念瓶颈模型中的概念幻觉问题，从而提高了解释的可靠性。

Abstract: This paper addresses explainable AI (XAI) through the lens of Concept
Bottleneck Models (CBMs) that do not require explicit concept annotations,
relying instead on concepts extracted using CLIP in a zero-shot manner. We show
that CLIP, which is central in these techniques, is prone to concept
hallucination, incorrectly predicting the presence or absence of concepts
within an image in scenarios used in numerous CBMs, hence undermining the
faithfulness of explanations. To mitigate this issue, we introduce Concept
Hallucination Inhibition via Localized Interpretability (CHILI), a technique
that disentangles image embeddings and localizes pixels corresponding to target
concepts. Furthermore, our approach supports the generation of saliency-based
explanations that are more interpretable.

</details>


### [77] [MoRe: Monocular Geometry Refinement via Graph Optimization for Cross-View Consistency](https://arxiv.org/abs/2510.07119)
*Dongki Jung,Jaehoon Choi,Yonghan Lee,Sungmin Eum,Heesung Kwon,Dinesh Manocha*

Main category: cs.CV

TL;DR: MoRe 是一种无需训练的单目几何优化方法，通过特征匹配和图优化提升跨视角一致性与尺度对齐，改善3D重建和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 解决单目3D基础模型中固有的尺度模糊性问题，提升跨视角一致性和3D重建质量。

Method: 采用特征匹配建立帧间对应关系，并基于估计的3D点和表面法线，通过图优化框架进行局部平面近似。

Result: MoRe 不仅增强了3D重建效果，还改善了稀疏视角下的新视角合成性能。

Conclusion: MoRe 是一种无需训练的单目几何优化方法，通过特征匹配和图优化框架提升跨视角一致性和尺度对齐，同时保留底层3D结构。

Abstract: Monocular 3D foundation models offer an extensible solution for perception
tasks, making them attractive for broader 3D vision applications. In this
paper, we propose MoRe, a training-free Monocular Geometry Refinement method
designed to improve cross-view consistency and achieve scale alignment. To
induce inter-frame relationships, our method employs feature matching between
frames to establish correspondences. Rather than applying simple least squares
optimization on these matched points, we formulate a graph-based optimization
framework that performs local planar approximation using the estimated 3D
points and surface normals estimated by monocular foundation models. This
formulation addresses the scale ambiguity inherent in monocular geometric
priors while preserving the underlying 3D structure. We further demonstrate
that MoRe not only enhances 3D reconstruction but also improves novel view
synthesis, particularly in sparse view rendering scenarios.

</details>


### [78] [Few-Shot Adaptation Benchmark for Remote Sensing Vision-Language Models](https://arxiv.org/abs/2510.07135)
*Karim El Khoury,Maxime Zanella,Christophe De Vleeschouwer,Benoit Macq*

Main category: cs.CV

TL;DR: 该研究首次提出评估RSVLMs少样本适应能力的结构化基准，发现零样本性能相似的模型在少样本适应下表现差异显著，强调需要开发更鲁棒的遥感少样本适应方法。


<details>
  <summary>Details</summary>
Motivation: 尽管RSVLMs在大规模预训练下表现出强大的零样本性能，但其在少样本学习等低数据场景下的泛化能力尚未得到充分探索。

Method: 研究通过十个遥感场景分类数据集，对三种最先进的RSVLM模型应用五种广泛使用的少样本适应策略，进行了全面实验。

Result: 研究发现，零样本性能相似的模型在少样本适应下表现差异显著，某些RSVLMs天生更适应此类适应。现有方法的性能差异和缺乏明确优势方法凸显了开发更鲁棒的少样本适应方法的必要性。

Conclusion: 该研究强调了为遥感领域开发更强大的少样本适应方法的必要性，并提供了一个可复现的基准框架和开源代码以促进未来研究。

Abstract: Remote Sensing Vision-Language Models (RSVLMs) have shown remarkable
potential thanks to large-scale pretraining, achieving strong zero-shot
performance on various tasks. However, their ability to generalize in low-data
regimes, such as few-shot learning, remains insufficiently explored. In this
work, we present the first structured benchmark for evaluating few-shot
adaptation methods on RSVLMs. We conduct comprehensive experiments across ten
remote sensing scene classification datasets, applying five widely used
few-shot adaptation strategies to three state-of-the-art RSVLMs with varying
backbones. Our findings reveal that models with similar zero-shot performance
can exhibit markedly different behavior under few-shot adaptation, with some
RSVLMs being inherently more amenable to such adaptation than others. The
variability of performance and the absence of a clear winner among existing
methods highlight the need for the development of more robust methods for
few-shot adaptation tailored to RS. To facilitate future research, we provide a
reproducible benchmarking framework and open-source code to systematically
evaluate RSVLMs under few-shot conditions. The source code is publicly
available on Github: https://github.com/elkhouryk/fewshot_RSVLMs

</details>


### [79] [Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods](https://arxiv.org/abs/2510.07143)
*Chenfei Liao,Wensong Wang,Zichen Wen,Xu Zheng,Yiyu Wang,Haocong He,Yuanhuiyi Lyu,Lutao Jiang,Xin Zou,Yuqian Fu,Bin Ren,Linfeng Zhang,Xuming Hu*

Main category: cs.CV

TL;DR: 论文揭示当前基准测试不适合评估视觉令牌压缩，提出VTC-Bench框架，通过数据过滤去噪，改进评估效果。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试原本设计用于评估MLLMs的感知和推理能力，而非压缩技术，直接应用于视觉令牌压缩会导致任务不匹配。

Method: 通过广泛的实验，作者发现简单的图像下采样在许多广泛使用的基准测试中优于许多先进的压缩方法。

Result: 研究发现当前基准测试对视觉令牌压缩任务存在噪音，而下采样能够作为数据过滤器评估样本难度。

Conclusion: 作者提出了VTC-Bench评估框架，通过数据过滤机制去噪现有基准，从而更公平、准确地评估视觉令牌压缩方法。

Abstract: Recent endeavors to accelerate inference in Multimodal Large Language Models
(MLLMs) have primarily focused on visual token compression. The effectiveness
of these methods is typically assessed by measuring the accuracy drop on
established benchmarks, comparing model performance before and after
compression. However, these benchmarks are originally designed to assess the
perception and reasoning capabilities of MLLMs, rather than to evaluate
compression techniques. As a result, directly applying them to visual token
compression introduces a task mismatch. Strikingly, our investigation reveals
that simple image downsampling consistently outperforms many advanced
compression methods across multiple widely used benchmarks. Through extensive
experiments, we make the following observations: (i) Current benchmarks are
noisy for the visual token compression task. (ii) Down-sampling is able to
serve as a data filter to evaluate the difficulty of samples in the visual
token compression task. Motivated by these findings, we introduce VTC-Bench, an
evaluation framework that incorporates a data filtering mechanism to denoise
existing benchmarks, thereby enabling fairer and more accurate assessment of
visual token compression methods. All data and code are available at
https://github.com/Chenfei-Liao/VTC-Bench.

</details>


### [80] [MV-Performer: Taming Video Diffusion Model for Faithful and Synchronized Multi-view Performer Synthesis](https://arxiv.org/abs/2510.07190)
*Yihao Zhi,Chenghong Li,Hongjie Liao,Xihe Yang,Zhengwentai Sun,Jiahao Chang,Xiaodong Cun,Wensen Feng,Xiaoguang Han*

Main category: cs.CV

TL;DR: MV-Performer是一个创新框架，通过多视角人类中心视频扩散模型和鲁棒推理程序，从单目全身捕捉生成同步的360度新视角视频，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成方法主要集中于前视图内的相机轨迹调整，难以生成360度视角变化，特别是在以人类为中心的子领域中。本研究旨在解决这一问题，实现从单目全身捕捉生成同步的新视角视频。

Method: 利用MVHumanNet数据集和相机相关的法线图作为信息条件信号，提出多视角人类中心视频扩散模型，融合参考视频、部分渲染和不同视角的信息，并设计了鲁棒推理程序以减少单目深度估计不完美带来的伪影。

Result: 在三个数据集上的广泛实验表明，MV-Performer在人类中心的4D新视角合成中具有最先进的效果和鲁棒性。

Conclusion: MV-Performer在人类中心的4D新视角合成中表现出色，通过多视角人类中心视频扩散模型和鲁棒推理程序，显著提升了同步性和鲁棒性，成为该领域的强有力模型。

Abstract: Recent breakthroughs in video generation, powered by large-scale datasets and
diffusion techniques, have shown that video diffusion models can function as
implicit 4D novel view synthesizers. Nevertheless, current methods primarily
concentrate on redirecting camera trajectory within the front view while
struggling to generate 360-degree viewpoint changes. In this paper, we focus on
human-centric subdomain and present MV-Performer, an innovative framework for
creating synchronized novel view videos from monocular full-body captures. To
achieve a 360-degree synthesis, we extensively leverage the MVHumanNet dataset
and incorporate an informative condition signal. Specifically, we use the
camera-dependent normal maps rendered from oriented partial point clouds, which
effectively alleviate the ambiguity between seen and unseen observations. To
maintain synchronization in the generated videos, we propose a multi-view
human-centric video diffusion model that fuses information from the reference
video, partial rendering, and different viewpoints. Additionally, we provide a
robust inference procedure for in-the-wild video cases, which greatly mitigates
the artifacts induced by imperfect monocular depth estimation. Extensive
experiments on three datasets demonstrate our MV-Performer's state-of-the-art
effectiveness and robustness, setting a strong model for human-centric 4D novel
view synthesis.

</details>


### [81] [EigenScore: OOD Detection using Covariance in Diffusion Models](https://arxiv.org/abs/2510.07206)
*Shirin Shoushtari,Yi Wang,Xiao Shi,M. Salman Asif,Ulugbek S. Kamilov*

Main category: cs.CV

TL;DR: EigenScore利用扩散模型后验协方差的特征值谱进行OOD检测，性能优越且鲁棒，AUROC最高提升5%。


<details>
  <summary>Details</summary>
Motivation: OOD检测对于在安全敏感领域安全部署机器学习系统至关重要，扩散模型作为强大的生成模型，能够通过迭代去噪捕获复杂数据分布，但其在OOD检测中的潜力尚未充分探索。

Method: 采用Jacobian-free子空间迭代方法估计主导特征值，仅需去噪器的前向评估，确保了方法的可操作性。

Result: EigenScore在OOD检测中达到了SOTA性能，AUROC最高提升了5%，并在近OOD场景（如CIFAR-10 vs CIFAR-100）中表现出鲁棒性。

Conclusion: EigenScore通过利用扩散模型诱导的后验协方差的特征值谱，提供了一种一致的分布偏移信号，显著提升了OOD检测的性能，并在近OOD场景中表现出鲁棒性。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of
machine learning systems in safety-sensitive domains. Diffusion models have
recently emerged as powerful generative models, capable of capturing complex
data distributions through iterative denoising. Building on this progress,
recent work has explored their potential for OOD detection. We propose
EigenScore, a new OOD detection method that leverages the eigenvalue spectrum
of the posterior covariance induced by a diffusion model. We argue that
posterior covariance provides a consistent signal of distribution shift,
leading to larger trace and leading eigenvalues on OOD inputs, yielding a clear
spectral signature. We further provide analysis explicitly linking posterior
covariance to distribution mismatch, establishing it as a reliable signal for
OOD detection. To ensure tractability, we adopt a Jacobian-free subspace
iteration method to estimate the leading eigenvalues using only forward
evaluations of the denoiser. Empirically, EigenScore achieves SOTA performance,
with up to 5% AUROC improvement over the best baseline. Notably, it remains
robust in near-OOD settings such as CIFAR-10 vs CIFAR-100, where existing
diffusion-based methods often fail.

</details>


### [82] [TalkCuts: A Large-Scale Dataset for Multi-Shot Human Speech Video Generation](https://arxiv.org/abs/2510.07249)
*Jiaben Chen,Zixin Wang,Ailing Zeng,Yang Fu,Xueyang Yu,Siyuan Cen,Julian Tanke,Yihang Chen,Koichi Saito,Yuki Mitsufuji,Chuang Gan*

Main category: cs.CV

TL;DR: TalkCuts是一个大规模的多镜头语音视频数据集，包含164k剪辑和500小时高质量视频，支持多模态学习。提出的Orator框架通过LLM引导生成连贯长视频，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集多集中于单镜头静态视角，缺乏多镜头语音视频的多样性，因此构建了TalkCuts数据集以促进多镜头语音视频生成的研究。

Method: 提出了Orator，一个LLM引导的多模态生成框架，通过整合多模态视频生成模块，实现了连贯长视频的合成。

Result: 在姿态引导和音频驱动的设置下，实验表明使用TalkCuts训练显著提高了生成视频的镜头连贯性和视觉吸引力。

Conclusion: TalkCuts数据集为可控的多镜头语音视频生成和更广泛的多模态学习提供了坚实的基础。

Abstract: In this work, we present TalkCuts, a large-scale dataset designed to
facilitate the study of multi-shot human speech video generation. Unlike
existing datasets that focus on single-shot, static viewpoints, TalkCuts offers
164k clips totaling over 500 hours of high-quality human speech videos with
diverse camera shots, including close-up, half-body, and full-body views. The
dataset includes detailed textual descriptions, 2D keypoints and 3D SMPL-X
motion annotations, covering over 10k identities, enabling multimodal learning
and evaluation. As a first attempt to showcase the value of the dataset, we
present Orator, an LLM-guided multi-modal generation framework as a simple
baseline, where the language model functions as a multi-faceted director,
orchestrating detailed specifications for camera transitions, speaker
gesticulations, and vocal modulation. This architecture enables the synthesis
of coherent long-form videos through our integrated multi-modal video
generation module. Extensive experiments in both pose-guided and audio-driven
settings show that training on TalkCuts significantly enhances the
cinematographic coherence and visual appeal of generated multi-shot speech
videos. We believe TalkCuts provides a strong foundation for future work in
controllable, multi-shot speech video generation and broader multimodal
learning.

</details>


### [83] [Evaluating Fundus-Specific Foundation Models for Diabetic Macular Edema Detection](https://arxiv.org/abs/2510.07277)
*Franco Javier Arellano,José Ignacio Orlando*

Main category: cs.CV

TL;DR: 基础模型在DME检测任务中未全面超越轻量级CNN，EfficientNet-B0表现最佳，RETFound和FLAIR在特定条件下有竞争力。


<details>
  <summary>Details</summary>
Motivation: 糖尿病黄斑水肿（DME）是糖尿病患者视力丧失的主要原因。尽管深度学习在自动检测该病症方面显示出潜力，但标注数据的稀缺性限制了其应用。基础模型（FM）被认为是潜在的解决方案，但其在DME检测中的表现尚不明确。

Method: 本研究系统比较了两种流行的视网膜图像基础模型（RETFound和FLAIR）与标准迁移学习方法（EfficientNet-B0）在不同训练机制和评估设置（IDRiD、MESSIDOR-2和OEFI数据集）下的表现。

Result: 结果显示，EfficientNet-B0在大多数评估设置中表现最佳或次优，而RETFound仅在OEFI数据集中表现良好。FLAIR在零样本学习场景下表现竞争性，尤其是在适当的提示下。

Conclusion: 尽管基础模型（FM）在规模上具有优势，但在糖尿病黄斑水肿（DME）检测任务中，它们并未始终优于经过微调的CNN模型。轻量级CNN在数据稀缺的环境中仍表现出色，是强有力的基线模型。

Abstract: Diabetic Macular Edema (DME) is a leading cause of vision loss among patients
with Diabetic Retinopathy (DR). While deep learning has shown promising results
for automatically detecting this condition from fundus images, its application
remains challenging due the limited availability of annotated data. Foundation
Models (FM) have emerged as an alternative solution. However, it is unclear if
they can cope with DME detection in particular. In this paper, we
systematically compare different FM and standard transfer learning approaches
for this task. Specifically, we compare the two most popular FM for retinal
images--RETFound and FLAIR--and an EfficientNet-B0 backbone, across different
training regimes and evaluation settings in IDRiD, MESSIDOR-2 and
OCT-and-Eye-Fundus-Images (OEFI). Results show that despite their scale, FM do
not consistently outperform fine-tuned CNNs in this task. In particular, an
EfficientNet-B0 ranked first or second in terms of area under the ROC and
precision/recall curves in most evaluation settings, with RETFound only showing
promising results in OEFI. FLAIR, on the other hand, demonstrated competitive
zero-shot performance, achieving notable AUC-PR scores when prompted
appropriately. These findings reveal that FM might not be a good tool for
fine-grained ophthalmic tasks such as DME detection even after fine-tuning,
suggesting that lightweight CNNs remain strong baselines in data-scarce
environments.

</details>


### [84] [SpecGuard: Spectral Projection-based Advanced Invisible Watermarking](https://arxiv.org/abs/2510.07302)
*Inzamamul Alam,Md Tanvir Islam,Khan Muhammad,Simon S. Woo*

Main category: cs.CV

TL;DR: 提出SpecGuard，一种基于频域转换的鲁棒隐形水印方法，通过小波分解和频谱投影增强抗攻击能力，实验表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有水印方法在面对多种变换（如失真、图像再生和对抗扰动）时缺乏鲁棒性，难以满足实际需求。

Method: 通过将空间域转换为频域，利用小波分解的高频带进行频谱投影，结合强度因子增强对抗攻击的抵抗力，解码器则利用Parseval定理提取水印。

Result: 实验证明SpecGuard在不可见性、容量和鲁棒性方面表现优异。

Conclusion: SpecGuard在不可见性、容量和鲁棒性方面优于现有最先进模型，并通过公开代码确保可复现性。

Abstract: Watermarking embeds imperceptible patterns into images for authenticity
verification. However, existing methods often lack robustness against various
transformations primarily including distortions, image regeneration, and
adversarial perturbation, creating real-world challenges. In this work, we
introduce SpecGuard, a novel watermarking approach for robust and invisible
image watermarking. Unlike prior approaches, we embed the message inside hidden
convolution layers by converting from the spatial domain to the frequency
domain using spectral projection of a higher frequency band that is decomposed
by wavelet projection. Spectral projection employs Fast Fourier Transform
approximation to transform spatial data into the frequency domain efficiently.
In the encoding phase, a strength factor enhances resilience against diverse
attacks, including adversarial, geometric, and regeneration-based distortions,
ensuring the preservation of copyrighted information. Meanwhile, the decoder
leverages Parseval's theorem to effectively learn and extract the watermark
pattern, enabling accurate retrieval under challenging transformations. We
evaluate the proposed SpecGuard based on the embedded watermark's invisibility,
capacity, and robustness. Comprehensive experiments demonstrate the proposed
SpecGuard outperforms the state-of-the-art models. To ensure reproducibility,
the full code is released on
\href{https://github.com/inzamamulDU/SpecGuard_ICCV_2025}{\textcolor{blue}{\textbf{GitHub}}}.

</details>


### [85] [MATRIX: Mask Track Alignment for Interaction-aware Video Generation](https://arxiv.org/abs/2510.07310)
*Siyoon Jin,Seongchan Kim,Dahyun Chung,Jaeho Lee,Hyunwook Choi,Jisu Nam,Jiyoung Kim,Seungryong Kim*

Main category: cs.CV

TL;DR: 论文提出MATRIX正则化方法，通过分析视频DiTs的语义基础和传播能力，显著提升交互建模效果。


<details>
  <summary>Details</summary>
Motivation: 视频DiTs在多实例或主客交互建模方面存在困难，需探究其内部交互表示机制。

Method: 通过构建MATRIX-11K数据集，系统分析视频DiTs的语义基础和传播能力，并引入MATRIX正则化方法。

Result: MATRIX方法在实验中提升了交互保真度和语义对齐，减少了漂移和幻觉。

Conclusion: MATRIX正则化方法通过增强视频DiTs的语义基础和传播能力，显著提升了交互保真度和语义对齐，同时减少了漂移和幻觉。

Abstract: Video DiTs have advanced video generation, yet they still struggle to model
multi-instance or subject-object interactions. This raises a key question: How
do these models internally represent interactions? To answer this, we curate
MATRIX-11K, a video dataset with interaction-aware captions and multi-instance
mask tracks. Using this dataset, we conduct a systematic analysis that
formalizes two perspectives of video DiTs: semantic grounding, via
video-to-text attention, which evaluates whether noun and verb tokens capture
instances and their relations; and semantic propagation, via video-to-video
attention, which assesses whether instance bindings persist across frames. We
find both effects concentrate in a small subset of interaction-dominant layers.
Motivated by this, we introduce MATRIX, a simple and effective regularization
that aligns attention in specific layers of video DiTs with multi-instance mask
tracks from the MATRIX-11K dataset, enhancing both grounding and propagation.
We further propose InterGenEval, an evaluation protocol for interaction-aware
video generation. In experiments, MATRIX improves both interaction fidelity and
semantic alignment while reducing drift and hallucination. Extensive ablations
validate our design choices. Codes and weights will be released.

</details>


### [86] [Pixel-Perfect Depth with Semantics-Prompted Diffusion Transformers](https://arxiv.org/abs/2510.07316)
*Gangwei Xu,Haotong Lin,Hongcheng Luo,Xianqi Wang,Jingfeng Yao,Lianghui Zhu,Yuechuan Pu,Cheng Chi,Haiyang Sun,Bing Wang,Guang Chen,Hangjun Ye,Sida Peng,Xin Yang*

Main category: cs.CV

TL;DR: Pixel-Perfect Depth通过像素空间扩散生成和SP-DiT、Cascade DiT设计，解决了VAE导致的伪影问题，在深度估计任务中表现最优。


<details>
  <summary>Details</summary>
Motivation: 当前生成式深度估计模型虽性能出色，但依赖VAE压缩深度图至潜在空间，导致边缘和细节处出现“飞像素”问题。

Method: 1) 直接在像素空间进行扩散生成，避免VAE压缩导致的伪影；2) 引入Semantics-Prompted Diffusion Transformers (SP-DiT)结合语义提示；3) 采用Cascade DiT设计逐步增加token数量以提升效率和精度。

Result: 模型在五个基准测试中表现最佳，边缘感知点云评估显著优于其他模型。

Conclusion: Pixel-Perfect Depth模型通过像素空间扩散生成和创新的SP-DiT及Cascade DiT设计，显著提升了深度估计的质量，避免了VAE引入的伪影，并在多个基准测试中表现最佳。

Abstract: This paper presents Pixel-Perfect Depth, a monocular depth estimation model
based on pixel-space diffusion generation that produces high-quality,
flying-pixel-free point clouds from estimated depth maps. Current generative
depth estimation models fine-tune Stable Diffusion and achieve impressive
performance. However, they require a VAE to compress depth maps into latent
space, which inevitably introduces \textit{flying pixels} at edges and details.
Our model addresses this challenge by directly performing diffusion generation
in the pixel space, avoiding VAE-induced artifacts. To overcome the high
complexity associated with pixel-space generation, we introduce two novel
designs: 1) Semantics-Prompted Diffusion Transformers (SP-DiT), which
incorporate semantic representations from vision foundation models into DiT to
prompt the diffusion process, thereby preserving global semantic consistency
while enhancing fine-grained visual details; and 2) Cascade DiT Design that
progressively increases the number of tokens to further enhance efficiency and
accuracy. Our model achieves the best performance among all published
generative models across five benchmarks, and significantly outperforms all
other models in edge-aware point cloud evaluation.

</details>


### [87] [Quantum-enhanced Computer Vision: Going Beyond Classical Algorithms](https://arxiv.org/abs/2510.07317)
*Natacha Kuete Meli,Shuteng Wang,Marcel Seelbach Benkner,Michele Sasdelli,Tat-Jun Chin,Tolga Birdal,Michael Moeller,Vladislav Golyanik*

Main category: cs.CV

TL;DR: 本文综述了量子增强计算机视觉（QeCV）这一新兴领域，介绍了其潜力、基本原理、工具和挑战，旨在为计算机视觉社区提供量子计算参考。


<details>
  <summary>Details</summary>
Motivation: 现有非量子方法在某些场景中无法在合理时间内找到解决方案或只能提供近似解，而量子计算可能在时间可扩展性等方面提供优势。QeCV有潜力成为计算机视觉领域的革命性技术。

Method: 本文通过全面综述QeCV领域，介绍了量子计算的基本原理、可用工具以及在QeCV中的应用方法，包括基于门的量子计算和量子退火两种主要量子计算范式。

Result: 本文为计算机视觉社区提供了关于QeCV的全面介绍，包括其特殊性、与量子硬件兼容的公式化方法，并讨论了现有量子计算工具、学习材料以及开放挑战和社会影响。

Conclusion: 量子增强计算机视觉（QeCV）是一个新兴的研究领域，结合了计算机视觉、优化理论、机器学习和量子计算。虽然目前需要开发新的算法以兼容量子硬件并发挥量子计算潜力，但QeCV有望在视觉信号处理领域带来革命性变革。

Abstract: Quantum-enhanced Computer Vision (QeCV) is a new research field at the
intersection of computer vision, optimisation theory, machine learning and
quantum computing. It has high potential to transform how visual signals are
processed and interpreted with the help of quantum computing that leverages
quantum-mechanical effects in computations inaccessible to classical (i.e.
non-quantum) computers. In scenarios where existing non-quantum methods cannot
find a solution in a reasonable time or compute only approximate solutions,
quantum computers can provide, among others, advantages in terms of better time
scalability for multiple problem classes. Parametrised quantum circuits can
also become, in the long term, a considerable alternative to classical neural
networks in computer vision. However, specialised and fundamentally new
algorithms must be developed to enable compatibility with quantum hardware and
unveil the potential of quantum computational paradigms in computer vision.
This survey contributes to the existing literature on QeCV with a holistic
review of this research field. It is designed as a quantum computing reference
for the computer vision community, targeting computer vision students,
scientists and readers with related backgrounds who want to familiarise
themselves with QeCV. We provide a comprehensive introduction to QeCV, its
specifics, and methodologies for formulations compatible with quantum hardware
and QeCV methods, leveraging two main quantum computational paradigms, i.e.
gate-based quantum computing and quantum annealing. We elaborate on the
operational principles of quantum computers and the available tools to access,
program and simulate them in the context of QeCV. Finally, we review existing
quantum computing tools and learning materials and discuss aspects related to
publishing and reviewing QeCV papers, open challenges and potential social
implications.

</details>


### [88] [Temporal Prompting Matters: Rethinking Referring Video Object Segmentation](https://arxiv.org/abs/2510.07319)
*Ci-Siang Lin,Min-Hung Chen,I-Jieh Liu,Chien-Yi Wang,Sifei Liu,Yu-Chiang Frank Wang*

Main category: cs.CV

TL;DR: Tenet框架通过时间提示生成与选择，结合基础分割模型，高效解决了RVOS任务，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有RVOS方法依赖密集掩码标注和端到端训练，计算成本高且扩展性差；通过分解任务并利用基础模型，探索更高效的解决方案。

Method: 提出Temporal Prompt Generation and Selection (Tenet)框架，结合基础分割模型、对象检测器和跟踪器生成时间提示，并引入Prompt Preference Learning评估提示质量。

Result: 在RVOS基准测试中，Tenet框架表现出色，验证了其高效性和有效性。

Conclusion: Tenet框架通过分解RVOS任务并利用基础分割模型，结合时间提示生成与选择机制，有效提升了分割质量，实验验证了其优越性。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment the object
referred to by the query sentence in the video. Most existing methods require
end-to-end training with dense mask annotations, which could be
computation-consuming and less scalable. In this work, we rethink the RVOS
problem and aim to investigate the key to this task. Based on existing
foundation segmentation models, we decompose the RVOS task into referring,
video, and segmentation factors, and propose a Temporal Prompt Generation and
Selection (Tenet) framework to address the referring and video factors while
leaving the segmentation problem to foundation models. To efficiently adapt
image-based foundation segmentation models to referring video object
segmentation, we leverage off-the-shelf object detectors and trackers to
produce temporal prompts associated with the referring sentence. While
high-quality temporal prompts could be produced, they can not be easily
identified from confidence scores. To tackle this issue, we propose Prompt
Preference Learning to evaluate the quality of the produced temporal prompts.
By taking such prompts to instruct image-based foundation segmentation models,
we would be able to produce high-quality masks for the referred object,
enabling efficient model adaptation to referring video object segmentation.
Experiments on RVOS benchmarks demonstrate the effectiveness of the Tenet
framework.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [89] [DiLi: A Lock-Free Asynchronously Distributable Linked List](https://arxiv.org/abs/2510.06387)
*Raaghav Ravishankar,Sandeep Kulkarni,Sathya Peri,Gokarna Sharma*

Main category: cs.DC

TL;DR: DiLi是一种条件无锁的分布式链表，支持动态分区和负载均衡，性能与单机无锁结构相当，多机吞吐量线性扩展。


<details>
  <summary>Details</summary>
Motivation: 随着吞吐量需求的增长，传统单机数据结构无法满足需求，而静态分区分布式结构存在负载不均和停机问题。

Method: 提出了DiLi，一种条件无锁的分布式链表，支持动态分区和负载均衡，并通过二进制搜索和有限线性遍历实现高效搜索。

Result: DiLi在单机性能上与现有无锁结构相当，且在多机环境下吞吐量线性扩展。

Conclusion: DiLi作为一种条件无锁、可线性化且可分布式化的链表，在单机性能上与最先进的无锁并发搜索结构相当，并且在多机环境下吞吐量呈线性扩展。

Abstract: Modern databases use dynamic search structures that store a huge amount of
data, and often serve them using multi-threaded algorithms to support the
ever-increasing throughput needs. When this throughput need exceeds the
capacity of the machine hosting the structure, one either needs to replace the
underlying hardware (an option that is typically not viable and introduces a
long down time) or make the data structure distributed. Static partitioning of
the data structure for distribution is not desirable, as it is prone to uneven
load distribution over time, and having to change the partitioning scheme later
will require downtime.
  Since a distributed data structure, inherently, relies on communication
support from the network stack and operating systems, we introduce the notion
of conditional lock-freedom that extends the notion of lock-free computation
with reasonable assumptions about communication between processes. We present
DiLi, a conditional lock-free, linearizable, and distributable linked list that
can be asynchronously and dynamically (1) partitioned into multiple sublists
and (2) load balanced by distributing sublists across multiple machines. DiLi
contains primitives for these that also maintain the lock-free property of the
underlying search structure that supports find, remove, and insert of a key as
the client operations.
  Searching for an item in DiLi is by a novel traversal that involves a binary
search on the partitioning scheme, and then a linear traversal on a limitable
number of linked nodes. As a result, we are able to empirically show that DiLi
performs as well as the state-of-the-art lock-free concurrent search structures
that are based off of a linked list when executed on a single-machine. We also
show that the throughput of DiLi scales linearly with the number of machines
that host it.

</details>


### [90] [Adaptive Protein Design Protocols and Middleware](https://arxiv.org/abs/2510.06396)
*Aymen Alsaadi,Jonathan Ash,Mikhail Titov,Matteo Turilli,Andre Merzky,Shantenu Jha,Sagar Khare*

Main category: cs.DC

TL;DR: IMPRESS整合AI与高性能计算，通过动态资源分配提升蛋白质设计的效率和质量。


<details>
  <summary>Details</summary>
Motivation: 尽管AI/ML推动了蛋白质设计的进步，但由于序列和结构的巨大复杂性，仍需要大量计算资源进行采样，IMPRESS旨在解决这一挑战。

Method: IMPRESS结合AI/ML与高性能计算，采用动态资源分配和异步工作负载执行的方法。

Result: IMPRESS实现了蛋白质设计质量的更高一致性和设计吞吐量的提升。

Conclusion: IMPRESS通过整合AI与高性能计算，显著提高了蛋白质设计的质量和效率，展示了自适应协议和计算基础设施的成功应用。

Abstract: Computational protein design is experiencing a transformation driven by
AI/ML. However, the range of potential protein sequences and structures is
astronomically vast, even for moderately sized proteins. Hence, achieving
convergence between generated and predicted structures demands substantial
computational resources for sampling. The Integrated Machine-learning for
Protein Structures at Scale (IMPRESS) offers methods and advanced computing
systems for coupling AI to high-performance computing tasks, enabling the
ability to evaluate the effectiveness of protein designs as they are developed,
as well as the models and simulations used to generate data and train models.
This paper introduces IMPRESS and demonstrates the development and
implementation of an adaptive protein design protocol and its supporting
computing infrastructure. This leads to increased consistency in the quality of
protein design and enhanced throughput of protein design due to dynamic
resource allocation and asynchronous workload execution.

</details>


### [91] [MuFASA -- Asynchronous Checkpoint for Weakly Consistent Fully Replicated Databases](https://arxiv.org/abs/2510.06404)
*Raaghav Ravishankar,Sandeep Kulkarni,Nitin H Vaidya*

Main category: cs.DC

TL;DR: DTCS提出了一种最小化检查点开销的算法，解决了全复制弱一致性分布式数据库中的检查点问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决全复制弱一致性分布式数据库中的检查点问题，避免传统检查点导致的不一致或过高开销。

Method: 提出了一种最小化检查点开销的算法，仅需O(n)新消息和现有消息的单个计数器。

Result: DTCS算法在分布式系统和主内存数据库中优于现有检查点算法，能够通过强一致性快照总结弱一致性计算。

Conclusion: DTCS通过最小化检查点开销（仅需O(n)新消息和现有消息的单个计数器）提供了显著优势，解决了全复制弱一致性分布式数据库中的检查点问题。

Abstract: We focus on the problem of checkpointing in fully replicated weakly
consistent distributed databases, which we refer to as Distributed Transaction
Consistent Snapshot (DTCS). A typical example of such a system is a main-memory
database that provides strong eventual consistency. This problem is important
and challenging for several reasons: (1) eventual consistency often creates
anomalies that the users do not anticipate. Hence, frequent checkpoints to
ascertain desired invariants is highly beneficial in their use, and (2)
traditional checkpoints lead to significant overhead and/or inconsistencies. By
showing that the traditional checkpoint leads to inconsistencies or excessive
overhead, we define the notion of size-minimal checkpointing for fully
replicated databases. We present an algorithm for checkpointing with minimal
checkpointing overhead (only O(n) new messages and addition of a single counter
for existing messages). It also provides a significant benefit over existing
checkpointing algorithms for distributed systems and main-memory databases.
  A key benefit of DTCS is that it summarizes the computation by a sequence of
snapshots that are strongly consistent even though the underlying computation
is weakly consistent. In essence, when anomalies arise in an eventually
consistent system, DTCS enables one to concentrate solely on the snapshots
surrounding the time point of the anomaly.

</details>


### [92] [REACH: Reinforcement Learning for Adaptive Microservice Rescheduling in the Cloud-Edge Continuum](https://arxiv.org/abs/2510.06675)
*Xu Bai,Muhammed Tawfiqul Islam,Rajkumar Buyya,Adel N. Toosi*

Main category: cs.DC

TL;DR: REACH是一种基于强化学习的动态微服务部署算法，显著降低延迟并优化云边连续体中的资源利用。


<details>
  <summary>Details</summary>
Motivation: 云计算在可扩展性方面的优势无法完全满足新兴低延迟敏感应用的需求，云边连续体通过整合边缘资源的响应能力和云的可扩展性来解决这一问题。微服务架构（MSA）与此连续体契合，但异构和动态的计算资源为微服务的最优部署带来挑战。

Method: 提出REACH算法，利用强化学习实时动态调整微服务部署，以应对分布式基础设施中资源可用性和性能的变化。

Result: 在真实世界测试平台上的大量实验表明，REACH在三个基准MSA应用中分别降低了7.9%、10%和8%的平均端到端延迟，同时有效缓解了延迟波动和峰值。

Conclusion: REACH算法通过强化学习动态调整微服务部署，有效降低了端到端延迟，并缓解了延迟波动和峰值，为云边连续体中的微服务部署提供了优化方案。

Abstract: Cloud computing, despite its advantages in scalability, may not always fully
satisfy the low-latency demands of emerging latency-sensitive pervasive
applications. The cloud-edge continuum addresses this by integrating the
responsiveness of edge resources with cloud scalability. Microservice
Architecture (MSA) characterized by modular, loosely coupled services, aligns
effectively with this continuum. However, the heterogeneous and dynamic
computing resource poses significant challenges to the optimal placement of
microservices. We propose REACH, a novel rescheduling algorithm that
dynamically adapts microservice placement in real time using reinforcement
learning to react to fluctuating resource availability, and performance
variations across distributed infrastructures. Extensive experiments on a
real-world testbed demonstrate that REACH reduces average end-to-end latency by
7.9%, 10%, and 8% across three benchmark MSA applications, while effectively
mitigating latency fluctuations and spikes.

</details>


### [93] [Multi-Dimensional Autoscaling of Stream Processing Services on Edge Devices](https://arxiv.org/abs/2510.06882)
*Boris Sedlak,Philipp Raith,Andrea Morichetta,Víctor Casamayor Pujol,Schahram Dustdar*

Main category: cs.DC

TL;DR: MUDAP平台通过多维度扩展和RASK代理优化边缘设备服务性能，减少28%的SLO违规。


<details>
  <summary>Details</summary>
Motivation: 边缘设备资源有限，现有自动扩展机制仅关注资源扩展，无法满足竞争服务的SLO需求。

Method: 提出了MUDAP平台，支持服务和资源维度的细粒度垂直扩展，并基于RASK代理进行回归分析，优化执行。

Result: RASK在仅20次迭代（200秒处理时间）内即可推断出准确的回归模型，相比基线减少了28%的SLO违规。

Conclusion: MUDAP通过多维度自动扩展平台和RASK代理，显著减少了SLO违规，提升了边缘设备上的服务性能。

Abstract: Edge devices have limited resources, which inevitably leads to situations
where stream processing services cannot satisfy their needs. While existing
autoscaling mechanisms focus entirely on resource scaling, Edge devices require
alternative ways to sustain the Service Level Objectives (SLOs) of competing
services. To address these issues, we introduce a Multi-dimensional Autoscaling
Platform (MUDAP) that supports fine-grained vertical scaling across both
service- and resource-level dimensions. MUDAP supports service-specific scaling
tailored to available parameters, e.g., scale data quality or model size for a
particular service. To optimize the execution across services, we present a
scaling agent based on Regression Analysis of Structural Knowledge (RASK). The
RASK agent efficiently explores the solution space and learns a continuous
regression model of the processing environment for inferring optimal scaling
actions. We compared our approach with two autoscalers, the Kubernetes VPA and
a reinforcement learning agent, for scaling up to 9 services on a single Edge
device. Our results showed that RASK can infer an accurate regression model in
merely 20 iterations (i.e., observe 200s of processing). By increasingly adding
elasticity dimensions, RASK sustained the highest request load with 28% less
SLO violations, compared to baselines.

</details>


### [94] [GROMACS Unplugged: How Power Capping and Frequency Shapes Performance on GPUs](https://arxiv.org/abs/2510.06902)
*Ayesha Afzal,Anna Kahler,Georg Hager,Gerhard Wellein*

Main category: cs.DC

TL;DR: 本文分析了四种NVIDIA GPU在GROMACS工作负载下的性能表现，发现小系统对频率敏感，大系统受内存带宽限制，并提供了在功耗限制下优化性能的实用建议。


<details>
  <summary>Details</summary>
Motivation: 分子动力学模拟在计算生物物理学中至关重要，但其性能高度依赖于硬件选择和配置。因此，需要对不同GPU加速器的性能进行综合分析，以优化大规模MD工作流的性能。

Method: 通过分析四种NVIDIA GPU加速器（A40、A100、L4和L40）在六种GROMACS生物分子工作负载和两种合成基准（Pi Solver和STREAM Triad）上的性能表现，研究了GPU图形时钟频率和功耗限制对性能的影响。

Result: 结果显示，较小的GROMACS系统对频率变化敏感，而较大的系统则快速饱和并受内存带宽限制。在功耗限制下，性能在达到特定阈值前保持稳定，高端GPU（如A100）即使在降低功耗下仍能保持接近最大性能。

Conclusion: 研究结果为在大规模分子动力学工作流中，选择GPU硬件和优化GROMACS性能提供了实用指导。

Abstract: Molecular dynamics simulations are essential tools in computational
biophysics, but their performance depend heavily on hardware choices and
configuration. In this work, we presents a comprehensive performance analysis
of four NVIDIA GPU accelerators -- A40, A100, L4, and L40 -- using six
representative GROMACS biomolecular workloads alongside two synthetic
benchmarks: Pi Solver (compute bound) and STREAM Triad (memory bound). We
investigate how performance scales with GPU graphics clock frequency and how
workloads respond to power capping. The two synthetic benchmarks define the
extremes of frequency scaling: Pi Solver shows ideal compute scalability, while
STREAM Triad reveals memory bandwidth limits -- framing GROMACS's performance
in context. Our results reveal distinct frequency scaling behaviors: Smaller
GROMACS systems exhibit strong frequency sensitivity, while larger systems
saturate quickly, becoming increasingly memory bound. Under power capping,
performance remains stable until architecture- and workload-specific thresholds
are reached, with high-end GPUs like the A100 maintaining near-maximum
performance even under reduced power budgets. Our findings provide practical
guidance for selecting GPU hardware and optimizing GROMACS performance for
large-scale MD workflows under power constraints.

</details>


### [95] [Evaluating Rapid Makespan Predictions for Heterogeneous Systems with Programmable Logic](https://arxiv.org/abs/2510.06998)
*Martin Wilhelm,Franz Freitag,Max Tzschoppe,Thilo Pionteck*

Main category: cs.DC

TL;DR: 本文开发了一个灵活的评价框架，用于异构系统中快速完成时间预测算法的开发，分析了现有方法的预测能力，并识别了常见挑战。


<details>
  <summary>Details</summary>
Motivation: 异构计算系统中任务映射对整体完成时间的影响预测是一个核心挑战，现有方法要么需要完整实现（耗时），要么过于抽象。

Method: 使用一个高度灵活的评价框架，收集基于抽象任务图描述的真实完成时间结果。

Result: 分析了现有分析方法预测实际完成时间的程度，并提出了由高层次特性（如数据传输开销和设备拥塞）引起的常见挑战。

Conclusion: 本文通过提供一个高度灵活的评价框架，帮助开发快速完成时间预测算法，并分析了现有分析方法预测实际完成时间的程度。

Abstract: Heterogeneous computing systems, which combine general-purpose processors
with specialized accelerators, are increasingly important for optimizing the
performance of modern applications. A central challenge is to decide which
parts of an application should be executed on which accelerator or, more
generally, how to map the tasks of an application to available devices.
Predicting the impact of a change in a task mapping on the overall makespan is
non-trivial. While there are very capable simulators, these generally require a
full implementation of the tasks in question, which is particularly
time-intensive for programmable logic. A promising alternative is to use a
purely analytical function, which allows for very fast predictions, but
abstracts significantly from reality. Bridging the gap between theory and
practice poses a significant challenge to algorithm developers. This paper aims
to aid in the development of rapid makespan prediction algorithms by providing
a highly flexible evaluation framework for heterogeneous systems consisting of
CPUs, GPUs and FPGAs, which is capable of collecting real-world makespan
results based on abstract task graph descriptions. We analyze to what extent
actual makespans can be predicted by existing analytical approaches.
Furthermore, we present common challenges that arise from high-level
characteristics such as data transfer overhead and device congestion in
heterogeneous systems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [96] [Leveraging Large Language Models for Cybersecurity Risk Assessment -- A Case from Forestry Cyber-Physical Systems](https://arxiv.org/abs/2510.06343)
*Fikret Mert Gültekin,Oscar Lilja,Ranim Khojah,Rebekka Wohlrab,Marvin Damschen,Mazen Mohamad*

Main category: cs.SE

TL;DR: 利用本地大型语言模型（LLM）支持网络安全风险评估，研究发现其有效但需人工监督。


<details>
  <summary>Details</summary>
Motivation: 由于网络安全专家稀缺，软件工程师需自行进行网络安全活动，因此需要工具支持风险评估过程。

Method: 通过设计科学研究，包括对12位专家的访谈、互动会议和调查。

Result: 结果表明，LLM可协助生成初步风险评估、识别威胁并提供冗余检查，但需人工监督。

Conclusion: 本研究鼓励在安全关键领域使用基于LLM的代理来支持风险评估过程，尽管需要人工监督以确保准确性和合规性。

Abstract: In safety-critical software systems, cybersecurity activities become
essential, with risk assessment being one of the most critical. In many
software teams, cybersecurity experts are either entirely absent or represented
by only a small number of specialists. As a result, the workload for these
experts becomes high, and software engineers would need to conduct
cybersecurity activities themselves. This creates a need for a tool to support
cybersecurity experts and engineers in evaluating vulnerabilities and threats
during the risk assessment process. This paper explores the potential of
leveraging locally hosted large language models (LLMs) with retrieval-augmented
generation to support cybersecurity risk assessment in the forestry domain
while complying with data protection and privacy requirements that limit
external data sharing. We performed a design science study involving 12 experts
in interviews, interactive sessions, and a survey within a large-scale project.
The results demonstrate that LLMs can assist cybersecurity experts by
generating initial risk assessments, identifying threats, and providing
redundancy checks. The results also highlight the necessity for human oversight
to ensure accuracy and compliance. Despite trust concerns, experts were willing
to utilize LLMs in specific evaluation and assistance roles, rather than solely
relying on their generative capabilities. This study provides insights that
encourage the use of LLM-based agents to support the risk assessment process of
cyber-physical systems in safety-critical domains.

</details>


### [97] [Improving Assignment Submission in Higher Education through a Git-Enabled System: An Iterative Case Study](https://arxiv.org/abs/2510.06363)
*Ololade Babatunde,Tomisin Ayodabo,Raqibul Raqibul*

Main category: cs.SE

TL;DR: 研究通过基于Git的提交系统提升了高等教育作业提交效率，减少了时间和存储需求，受到师生欢迎。


<details>
  <summary>Details</summary>
Motivation: 解决高等教育中传统作业提交方法在作业跟踪、协作和效率方面的挑战。

Method: 采用迭代软件开发和以用户为中心的设计方法，将系统整合到真实大学环境中，并通过可用性测试和学生反馈进行实证评估。

Result: 85%的教师认为基于Git的系统更易用，84%的学生更喜欢该系统，提交和审查时间减少38%，存储需求减少48%。

Conclusion: 该研究通过引入和评估定制的基于Git的提交系统，为高等教育中的传统作业提交方法提供了实用见解，显著提升了作业跟踪、协作和提交效率，同时减少了存储需求和管理负担。

Abstract: This study addresses challenges in traditional assignment submission methods
used in higher education by introducing and evaluating a customized Git-based
submission system. Employing iterative software development and user-centered
design methodologies, the system was integrated within a real-world university
environment. Empirical evaluation, including usability testing and student
feedback, indicated significant improvements in assignment tracking,
collaboration, and submission efficiency. Students reported positive
experiences using distributed version control workflows, highlighting improved
learning outcomes and reduced administrative burden. Challenges related to
initial adoption and student learning curves were identified and mitigated
through iterative improvements. The proposed system contributes practical
insights for integrating distributed version control into educational settings,
enhancing both instructor oversight and student engagement in software
engineering and related disciplines. Based on our results, the research showed
that 85% of instructors found the git based system easier to use, with 84% of
students preferring it over traditional methods, as it provides a 38% reduction
in time taken for submission and review, while also leading to a 48% reduction
in storage requirements.

</details>


### [98] [Addressing Visual Impairments with Model-Driven Engineering: A Systematic Literature Review](https://arxiv.org/abs/2510.06483)
*Judith Michael,Lukas Netz,Bernhard Rumpe,Ingo Müller,John Grundy,Shavindra Wickramathilaka,Hourieh Khalajzadeh*

Main category: cs.SE

TL;DR: 本文综述了MDE如何解决视觉无障碍性问题，发现当前研究支持不足，并提出改进议程。


<details>
  <summary>Details</summary>
Motivation: 软件应用常对无障碍需求用户（如视觉障碍者）构成障碍。模型驱动工程（MDE）通过系统化的代码衍生方法，可减少手动工作量并系统化地将无障碍性融入软件开发。

Method: 本文通过系统文献综述，从447篇初步筛选的论文中选出30篇符合纳入标准的主要研究进行分析。

Result: 约三分之二的研究参考了Web内容无障碍指南（WCAG），但项目特定的适应性和终端用户验证限制了其在MDE中的广泛应用。研究主要建模了用户界面结构、交互与导航、用户能力、需求及上下文信息，但较少具体说明如何整合无障碍需求或展示全功能系统。MDE方法（如转换规则或代码模板）的细节不足，影响了复用性、普适性和可重复性。此外，受影响用户的有限参与和开发者无障碍专业知识的不足导致实证验证薄弱。

Conclusion: 当前基于模型驱动工程（MDE）的研究对视觉相关无障碍性的支持不足。本文提出了一个研究议程，旨在更有效地将视觉无障碍性嵌入MDE流程中。

Abstract: Software applications often pose barriers for users with accessibility needs,
e.g., visual impairments. Model-driven engineering (MDE), with its systematic
nature of code derivation, offers systematic methods to integrate accessibility
concerns into software development while reducing manual effort. This paper
presents a systematic literature review on how MDE addresses accessibility for
vision impairments. From 447 initially identified papers, 30 primary studies
met the inclusion criteria. About two-thirds reference the Web Content
Accessibility Guidelines (WCAG), yet their project-specific adaptions and
end-user validations hinder wider adoption in MDE. The analyzed studies model
user interface structures, interaction and navigation, user capabilities,
requirements, and context information. However, only few specify concrete
modeling techniques on how to incorporate accessibility needs or demonstrate
fully functional systems. Insufficient details on MDE methods, i.e.,
transformation rules or code templates, hinder the reuse, generalizability, and
reproducibility. Furthermore, limited involvement of affected users and limited
developer expertise in accessibility contribute to weak empirical validation.
Overall, the findings indicate that current MDE research insufficiently
supports vision-related accessibility. Our paper concludes with a research
agenda outlining how support for vision impairments can be more effectively
embedded in MDE processes.

</details>


### [99] [Beyond More Context: How Granularity and Order Drive Code Completion Quality](https://arxiv.org/abs/2510.06606)
*Uswat Yusuf,Genevieve Caumartin,Diego Elias Costa*

Main category: cs.SE

TL;DR: 论文提出了一种针对大型仓库的上下文收集方法，通过文件和块级别检索策略优化LLM的代码生成性能，结果显示块级检索效果更佳。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）需要足够且相关的信息来辅助代码生成任务，但大型仓库中构建相关上下文存在挑战：LLMs的有限上下文长度和生成代码质量对噪声或无关上下文的敏感性。

Method: 开发并评估了一系列实验，包括文件和块级别的检索策略，重点关注上下文大小和文件顺序对LLM性能的影响。

Result: 使用静态分析的基于块的检索方法在竞赛初期阶段比最佳文件检索策略提高了6%，比无上下文基线提高了16%（Python）。

Conclusion: 检索粒度、顺序和混合策略在现实开发场景中构建高效上下文收集管道的重要性得到了验证。

Abstract: Context plays an important role in the quality of code completion, as Large
Language Models (LLMs) require sufficient and relevant information to assist
developers in code generation tasks. However, composing a relevant context for
code completion poses challenges in large repositories: First, the limited
context length of LLMs makes it impractical to include all repository files.
Second, the quality of generated code is highly sensitive to noisy or
irrelevant context. In this paper, we present our approach for the ASE 2025
Context Collection Challenge. The challenge entails outperforming JetBrains
baselines by designing effective retrieval and context collection strategies.
We develop and evaluate a series of experiments that involve retrieval
strategies at both the file and chunk levels. We focus our initial experiments
on examining the impact of context size and file ordering on LLM performance.
Our results show that the amount and order of context can significantly
influence the performance of the models. We introduce chunk-based retrieval
using static analysis, achieving a 6% improvement over our best file-retrieval
strategy and a 16% improvement over the no-context baseline for Python in the
initial phase of the competition. Our results highlight the importance of
retrieval granularity, ordering and hybrid strategies in developing effective
context collection pipelines for real-world development scenarios.

</details>


### [100] [AISysRev -- LLM-based Tool for Title-abstract Screening](https://arxiv.org/abs/2510.06708)
*Aleksi Huotala,Miikka Kuutila,Olli-Pekka Turtio,Mika Mäntylä*

Main category: cs.SE

TL;DR: AiSysRev是一个基于LLM的筛选工具，能帮助减轻系统评审中筛选阶段的工作量，但边界案例仍需人工干预。


<details>
  <summary>Details</summary>
Motivation: 系统评审在软件工程中是总结证据状态的标准实践，但筛选阶段（基于标题和摘要评估论文）工作量大且耗时。LLMs在标题-摘要筛选上表现接近硕士生水平，虽不完全可靠，但可帮助加速评审过程。

Method: 开发了AiSysRev，一个基于LLM的筛选工具，支持零样本和少样本筛选，并通过OpenRouter集成多种LLM。工具以Docker容器形式运行，接受包含论文标题和摘要的CSV文件，用户可指定纳入和排除标准。

Result: 试验研究（137篇论文）显示，论文可分为四类：易纳入、易排除、边界纳入和边界排除。边界案例中LLMs易出错，需人工干预。

Conclusion: 尽管大语言模型（LLMs）不能完全替代人工判断，但它们能显著减轻评估大量科学文献的负担，尤其是在快速评审中。

Abstract: Systematic reviews are a standard practice for summarizing the state of
evidence in software engineering. Conducting systematic reviews is laborious,
especially during the screening or study selection phase, where the number of
papers can be overwhelming. During this phase, papers are assessed against
inclusion and exclusion criteria based on their titles and abstracts. Recent
research has demonstrated that large language models (LLMs) can perform
title-abstract screening at a level comparable to that of a master's student.
While LLMs cannot be fully trusted, they can help, for example, in Rapid
Reviews, which try to expedite the review process. Building on recent research,
we developed AiSysRev, an LLM-based screening tool implemented as a web
application running in a Docker container. The tool accepts a CSV file
containing paper titles and abstracts. Users specify inclusion and exclusion
criteria. One can use multiple LLMs for screening via OpenRouter. AiSysRev
supports both zero-shot and few-shot screening, and also allows for manual
screening through interfaces that display LLM results as guidance for human
reviewers.We conducted a trial study with 137 papers using the tool. Our
findings indicate that papers can be classified into four categories: Easy
Includes, Easy Excludes, Boundary Includes, and Boundary Excludes. The Boundary
cases, where LLMs are prone to errors, highlight the need for human
intervention. While LLMs do not replace human judgment in systematic reviews,
they can significantly reduce the burden of assessing large volumes of
scientific literature. Video: https://www.youtube.com/watch?v=jVbEj4Y4tQI Tool:
https://github.com/EvoTestOps/AISysRev

</details>


### [101] [LLM Company Policies and Policy Implications in Software Organizations](https://arxiv.org/abs/2510.06718)
*Ranim Khojah,Mazen Mohamad,Linda Erlenhov,Francisco Gomes de Oliveira Neto,Philipp Leitner*

Main category: cs.SE

TL;DR: 论文通过分析11家公司制定LLM聊天机器人政策的案例，为管理者提供了安全集成的指导。


<details>
  <summary>Details</summary>
Motivation: 探讨如何安全地将聊天机器人整合到软件开发工作流程中，以降低潜在风险。

Method: 通过对11家公司的案例研究，分析了政策制定过程及其影响因素。

Result: 研究揭示了影响政策制定的关键因素，并提出了管理建议。

Conclusion: 论文强调了制定明确政策以安全集成大型语言模型（LLM）聊天机器人的重要性，并为管理者提供了实践指导。

Abstract: The risks associated with adopting large language model (LLM) chatbots in
software organizations highlight the need for clear policies. We examine how 11
companies create these policies and the factors that influence them, aiming to
help managers safely integrate chatbots into development workflows.

</details>


### [102] [Oops!... I did it again. Conclusion (In-)Stability in Quantitative Empirical Software Engineering: A Large-Scale Analysis](https://arxiv.org/abs/2510.06844)
*Nicole Hoess,Carlos Paradis,Rick Kazman,Wolfgang Mauerer*

Main category: cs.SE

TL;DR: 该研究探讨了软件挖掘工具在进化分析中的有效性威胁和一致性，发现工具设计和实现细节可能导致数据和分析结果的显著差异，建议谨慎选择工具并评估其局限性。


<details>
  <summary>Details</summary>
Motivation: 研究调查了复杂工具管道在进化软件分析中的有效性威胁，并评估了工具在数据、研究结果和结论方面对相同研究问题的一致性。

Method: 我们进行了轻量级文献综述，选择了三个关于协作与协调、软件维护和软件质量的高排名研究，并正式用四个独立、系统选择的挖掘工具复制这些研究，定量和定性比较提取的数据、分析结果和结论。

Result: 我们发现工具设计和实现中的许多技术细节在复杂的挖掘管道中累积，可能导致提取的基线数据、其衍生物、统计分析结果以及特定情况下的结论存在显著差异。

Conclusion: 用户必须谨慎选择工具并评估其局限性，以适当方式评估有效性范围。建议重复使用工具。研究人员和工具作者可以通过复制包和比较研究来促进可重用性并帮助减少不确定性。

Abstract: Context: Mining software repositories is a popular means to gain insights
into a software project's evolution, monitor project health, support decisions
and derive best practices. Tools supporting the mining process are commonly
applied by researchers and practitioners, but their limitations and agreement
are often not well understood.
  Objective: This study investigates some threats to validity in complex tool
pipelines for evolutionary software analyses and evaluates the tools' agreement
in terms of data, study outcomes and conclusions for the same research
questions.
  Method: We conduct a lightweight literature review to select three studies on
collaboration and coordination, software maintenance and software quality from
high-ranked venues, which we formally replicate with four independent,
systematically selected mining tools to quantitatively and qualitatively
compare the extracted data, analysis results and conclusions.
  Results: We find that numerous technical details in tool design and
implementation accumulate along the complex mining pipelines and can cause
substantial differences in the extracted baseline data, its derivatives,
subsequent results of statistical analyses and, under specific circumstances,
conclusions.
  Conclusions: Users must carefully choose tools and evaluate their limitations
to assess the scope of validity in an adequate way. Reusing tools is
recommended. Researchers and tool authors can promote reusability and help
reducing uncertainties by reproduction packages and comparative studies
following our approach.

</details>


### [103] [An empirical study on declined proposals: why are these proposals declined?](https://arxiv.org/abs/2510.06984)
*Masanari Kondo,Mahmoud Alfadel,Shane McIntosh,Yasutaka Kamei,Naoyasu Ubayashi*

Main category: cs.SE

TL;DR: 研究分析了Go项目提案的拒绝原因，发现效率低下并提出改进建议，包括使用GPT模型早期预测拒绝决策。


<details>
  <summary>Details</summary>
Motivation: 开源软件（OSS）项目中的设计决策通常通过提案等结构化机制进行，但提案过程资源密集且常因拒绝反馈不明确导致贡献者沮丧，拒绝原因尚不明确，限制了流程优化或有效指导贡献者的机会。

Method: 采用混合方法实证研究，分析了1,091个Go项目的提案，量化提案结果，构建拒绝原因分类法，并评估大型语言模型（LLMs）预测这些结果的能力。

Result: 提案被拒绝的频率高于接受，解决通常耗时超过一个月；仅14.7%的被拒绝提案会重新提交；通过定性编码确定了九个关键拒绝原因，如重复、用例有限或违反项目原则；GPT模型可早期预测拒绝决策（F1分数=0.71），为优先审阅提供实用工具。

Conclusion: 研究发现，提案过程的效率低下，提出了通过早期筛选和结构化理解过去拒绝原因来改善贡献者体验和审阅者工作量的可行机会。

Abstract: Design-level decisions in open-source software (OSS) projects are often made
through structured mechanisms such as proposals, which require substantial
community discussion and review. Despite their importance, the proposal process
is resource-intensive and often leads to contributor frustration, especially
when proposals are declined without clear feedback. Yet, the reasons behind
proposal rejection remain poorly understood, limiting opportunities to
streamline the process or guide contributors effectively. This study
investigates the characteristics and outcomes of proposals in the Go
programming language to understand why proposals are declined and how such
outcomes might be anticipated. We conduct a mixed-method empirical study on
1,091 proposals submitted to the Go project. We quantify proposal outcomes,
build a taxonomy of decline reasons, and evaluate large language models (LLMs)
for predicting these outcomes. We find that proposals are more often declined
than accepted, and resolution typically takes over a month. Only 14.7% of
declined proposals are ever resubmitted. Through qualitative coding, we
identify nine key reasons for proposal decline, such as duplication, limited
use cases, or violations of project principles. This taxonomy can help
contributors address issues in advance, e.g., checking for existing
alternatives can reduce redundancy. We also demonstrate that GPT-based models
can predict decline decisions early in the discussion (F1 score = 0.71 with
partial comments), offering a practical tool for prioritizing review effort.
Our findings reveal inefficiencies in the proposal process and highlight
actionable opportunities for improving both contributor experience and reviewer
workload by enabling early triage and guiding contributors to strengthen their
proposals using a structured understanding of past decline reasons.

</details>


### [104] [Human-aligned AI Model Cards with Weighted Hierarchy Architecture](https://arxiv.org/abs/2510.06989)
*Pengyue Yang,Haolin Jin,Qingwen Zeng,Jiawen Wen,Harry Rao,Huaming Chen*

Main category: cs.SE

TL;DR: 论文提出CRAI-MCF框架，通过量化和价值对齐的文档机制，解决LLM模型发现和采用中的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速增长带来了模型发现和采用的挑战，现有文档框架如Model Cards和FactSheets缺乏量化和跨模型比较的机制。

Method: 基于价值敏感设计（VSD）和240个开源项目的实证分析，提炼出217个参数，构建了一个八模块、价值对齐的架构。

Result: CRAI-MCF通过引入量化充分性标准，实现了严格的跨模型比较，并平衡了技术、伦理和操作维度，增强了模型的选择和采用信心。

Conclusion: 该论文提出了全面的负责任AI模型卡框架（CRAI-MCF），旨在解决现有文档框架的不足，通过量化和价值对齐的机制，促进模型的发现和采用。

Abstract: The proliferation of Large Language Models (LLMs) has led to a burgeoning
ecosystem of specialized, domain-specific models. While this rapid growth
accelerates innovation, it has simultaneously created significant challenges in
model discovery and adoption. Users struggle to navigate this landscape due to
inconsistent, incomplete, and imbalanced documentation across platforms.
Existing documentation frameworks, such as Model Cards and FactSheets, attempt
to standardize reporting but are often static, predominantly qualitative, and
lack the quantitative mechanisms needed for rigorous cross-model comparison.
This gap exacerbates model underutilization and hinders responsible adoption.
To address these shortcomings, we introduce the Comprehensive Responsible AI
Model Card Framework (CRAI-MCF), a novel approach that transitions from static
disclosures to actionable, human-aligned documentation. Grounded in Value
Sensitive Design (VSD), CRAI-MCF is built upon an empirical analysis of 240
open-source projects, distilling 217 parameters into an eight-module,
value-aligned architecture. Our framework introduces a quantitative sufficiency
criterion to operationalize evaluation and enables rigorous cross-model
comparison under a unified scheme. By balancing technical, ethical, and
operational dimensions, CRAI-MCF empowers practitioners to efficiently assess,
select, and adopt LLMs with greater confidence and operational integrity.

</details>


### [105] [Building an Open AIBOM Standard in the Wild](https://arxiv.org/abs/2510.07070)
*Gopi Krishnan Rajbahadur,Keheliya Gallaba,Elyas Rashno,Arthit Suriyawongkul,Karen Bennet,Kate Stewart,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: 论文通过行动研究框架开发了AIBOM规范，探索了AI组件的标准化过程，并总结了未来标准化工作的经验教训。


<details>
  <summary>Details</summary>
Motivation: 探索在快速发展的领域（如AI驱动的系统）中如何创建开放、社区驱动的标准，特别是针对AI组件（如数据集和迭代训练工件）的标准化需求。

Method: 通过行动研究（AR）框架，采用全球多利益相关方合作模式，涉及90多名贡献者，并进行了结构化AR周期。

Result: 开发了AIBOM规范，并通过四种互补方法验证：与主要法规和伦理标准对齐、系统映射到六个行业用例、半结构化从业者访谈和工业案例研究。

Conclusion: 论文总结了AIBOM规范的开发过程及其与行动研究周期的对齐情况，提炼了可为未来软件工程标准化工作提供参考的经验教训。

Abstract: Modern software engineering increasingly relies on open, community-driven
standards, yet how such standards are created in fast-evolving domains like
AI-powered systems remains underexplored. This paper presents a detailed
experience report on the development of the AI Bill of Materials AIBOM
specification, an extension of the ISO/IEC 5962:2021 Software Package Data
Exchange (SPDX) software bill of materials (SBOM) standard, which captures AI
components such as datasets and iterative training artifacts. Framed through
the lens of Action Research (AR), we document a global, multi-stakeholder
effort involving over 90 contributors and structured AR cycles. The resulting
specification was validated through four complementary approaches: alignment
with major regulations and ethical standards (e.g., EU AI Act and IEEE 7000
standards), systematic mapping to six industry use cases, semi-structured
practitioner interviews, and an industrial case study. Beyond delivering a
validated artefact, our paper documents the process of building the AIBOM
specification in the wild, and reflects on how it aligns with the AR cycle, and
distills lessons that can inform future standardization efforts in the software
engineering community.

</details>


### [106] [Prompt, Synthesize, Fine-Tune: A Secure Code Generation Recipe](https://arxiv.org/abs/2510.07189)
*Junjie Li,Fazle Rabbi,Bo Yang,Song Wang,Jinqiu Yang*

Main category: cs.SE

TL;DR: Secure-Instruct框架通过自动合成安全代码示例和指令微调，显著提升LLMs生成安全代码的能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在自动化代码生成方面表现出潜力，但生成的代码往往不安全，威胁软件安全。现有方法（如SafeCoder）因数据集有限且不平衡，效果和泛化能力不足。

Method: 提出了Secure-Instruct框架，通过自动合成高质量漏洞和安全代码示例，生成微调指令，并对LLMs进行指令微调，以对齐任务描述和安全代码生成能力。

Result: 在CWEBench上，Secure-Instruct显著提升了安全代码生成，平均安全比例提高了14.3%，并优于SafeCoder 7.6%。在CWEval上，Secure-Instruct对CodeLlama-7B和Mistral-7B的Func-Sec@1分别提高了14%和5.8%，并分别优于SafeCoder 15.8%和6.8%。

Conclusion: Secure-Instruct显著提升了大型语言模型在安全代码生成方面的能力，不仅在安全性上有显著提升，还在功能正确性上有所改进。

Abstract: Although Large Language Models (LLMs) show promising solutions to automated
code generation, they often produce insecure code that threatens software
security. Current approaches (e.g., SafeCoder) to improve secure code
generation suffer from limited and imbalanced datasets, reducing their
effectiveness and generalizability. In this work, we present Secure-Instruct, a
novel framework that automatically synthesizes high-quality vulnerable and
secure code examples, generates fine-tuning instructions, and instruction-tunes
LLMs to align task description and secure code generation abilities. We
evaluate Secure-Instruct on four representative LLMs using two benchmarks: our
own CWEBench and the existing CWEval. CWEBench comprises 93 scenarios on 44
CWEs, all without overlap with Secure-Instruct's synthetic instruction-tuning
dataset, while CWEval covers 31 CWEs with 119 manually verified
security-critical tasks. We find that Secure-Instruct improves not only the
security but also the functional correctness of the generated code. On
CWEBench, Secure-Instruct substantially improves secure code generation, giving
a 14.3% average increase in secure ratio over the pretrained models and
outperforms SafeCoder by 7.6%. On CWEval, Secure-Instruct achieves a 14%
increase for CodeLlama-7B and 5.8% for Mistral-7B in Func-Sec@1 over pretrained
models, and surpasses SafeCoder by 15.8% and 6.8% respectively.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [107] [AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning](https://arxiv.org/abs/2510.06261)
*Zhanke Zhou,Chentao Cao,Xiao Feng,Xuan Li,Zongze Li,Xiangyu Lu,Jiangchao Yao,Weikai Huang,Linrui Xu,Tian Cheng,Guanyu Jiang,Yiming Zheng,Brando Miranda,Tongliang Liu,Sanmi Koyejo,Masashi Sugiyama,Bo Han*

Main category: cs.AI

TL;DR: AlphaApollo是一个自演化的代理推理系统，通过工具协调和多模型迭代显著提升基础模型的推理能力，评估结果优异。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型推理中的两个瓶颈问题：模型固有容量有限和测试时迭代不可靠。

Method: AlphaApollo是一个自演化的代理推理系统，通过协调多个模型和专业工具（Python计算工具和任务相关外部信息检索工具）实现精确计算和决策。系统支持多轮、多模型解决方案演化，通过共享状态地图记录候选方案、可执行检查和反馈进行迭代优化。

Result: 在AIME 2024/2025评估中，AlphaApollo为Qwen2.5-14B-Instruct和Llama-3.3-70B-Instruct带来了显著的性能提升（如+5.15% Average@32和+23.34% Pass@32）。超过80%的工具调用成功执行，显著优于非工具基线。

Conclusion: AlphaApollo通过结合计算工具和检索工具，显著提升了基础模型的推理能力和迭代可靠性，在多模型评估中表现优异。

Abstract: We present AlphaApollo, a self-evolving agentic reasoning system that aims to
address two bottlenecks in foundation model (FM) reasoning-limited
model-intrinsic capacity and unreliable test-time iteration. AlphaApollo
orchestrates multiple models with professional tools to enable deliberate,
verifiable reasoning. It couples (i) a computation tool (Python with numerical
and symbolic libraries) and (ii) a retrieval tool (task-relevant external
information) to execute exact calculations and ground decisions. The system
further supports multi-round, multi-model solution evolution via a shared state
map that records candidates, executable checks, and feedback for iterative
refinement. In evaluations on AIME 2024/2025 across multiple models,
AlphaApollo delivers consistent gains: +5.15% Average@32 and +23.34% Pass@32
for Qwen2.5-14B-Instruct, and +8.91% Average@32 with +26.67% Pass@32 for
Llama-3.3-70B-Instruct. Tool-use analysis shows that more than 80% of tool
calls are successfully executed, with consistent outperformance of non-tool
baselines, thereby lifting the capability ceiling of FMs. More empirical
results and implementation details will be updated at
https://github.com/tmlr-group/AlphaApollo.

</details>


### [108] [Bridging Reasoning to Learning: Unmasking Illusions using Complexity Out of Distribution Generalization](https://arxiv.org/abs/2510.06274)
*Mohammad Mahdi Samiei Paqaleh,Arash Marioriyad,Arman Tahmasebi-Zadeh,Mohamadreza Fereydooni,Mahdi Ghaznavai,Mahdieh Soleymani Baghshah*

Main category: cs.AI

TL;DR: 论文提出复杂性OoD泛化框架，通过形式化复杂性度量推理能力，强调显式建模计算分配以推动稳健推理。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对推理能力的清晰、一致的定义或度量，尤其是在大语言模型推动AI从模式识别任务向逐步推理问题发展的背景下。

Method: 通过解决方案描述的Kolmogorov复杂性和操作代理（如对象/关系计数、推理步骤计数）形式化复杂性，区分复杂性OoD与长度和组合OoD的不同。

Result: 复杂性OoD泛化框架将学习与推理统一起来，低复杂性下可系统1式处理的问题在复杂性压力下变为系统2式，而系统2可视为对解决方案结构的泛化。

Conclusion: 论文提出了复杂性分布外（Complexity OoD）泛化作为定义和衡量推理能力的框架，强调通过架构和训练机制显式建模和分配计算来推动稳健推理的进展。

Abstract: Recent progress has pushed AI frontiers from pattern recognition tasks toward
problems that require step by step, System2 style reasoning, especially with
large language models. Yet, unlike learning, where generalization and out of
distribution (OoD) evaluation concepts are well formalized, there is no clear,
consistent definition or metric for reasoning ability. We propose Complexity
Out of Distribution (Complexity OoD) generalization as a framework and problem
setting to define and measure reasoning. A model exhibits Complexity OoD
generalization when it maintains performance on test instances whose minimal
required solution complexity, either representational (richer solution
structure) or computational (more reasoning steps/program length), exceeds that
of all training examples. We formalize complexity via solution description
Kolmogorov complexity and operational proxies (e.g., object/relation counts;
reasoning step counts), clarifying how Complexity OoD differs from length and
compositional OoD. This lens unifies learning and reasoning: many cases
solvable with System1 like processing at low complexity become System2 like
under complexity pressure, while System2 can be viewed as generalization over
solution structures. We translate this perspective into practice with
recommendations for operationalizing Complexity OoD across the stack:
incorporating complexity into benchmark and evaluation metric design,
rethinking supervision to target solution traces, seeking and designing
inductive biases for Complexity OoD generalization, addressing learning to
reason spillovers such as spurious shortcuts, semantic robustness, catastrophic
forgetting, and step wise calibration. Because Complexity OoD cannot be solved
by scaling data alone, progress toward robust reasoning will require
architectures and training regimes that explicitly model and allocate
computation with respect to complexity.

</details>


### [109] [BuilderBench -- A benchmark for generalist agents](https://arxiv.org/abs/2510.06288)
*Raj Ghugare,Catherine Ji,Kathryn Wantlin,Jin Schofield,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: BuilderBench是一个促进智能体通过开放式探索学习的基准测试，包含物理模拟和多样化任务，挑战现有算法并推动具身推理研究。


<details>
  <summary>Details</summary>
Motivation: 当前AI模型主要通过模仿学习，难以解决超出现有数据范围的新问题。因此，需要开发能够通过交互探索学习的智能体，解决这一开放性问题。

Method: 引入BuilderBench，一个包含硬件加速模拟器和42个多样化目标结构的任务套件，用于测试智能体在物理、数学和长期规划方面的理解。智能体在无外部监督的情况下探索学习，并在评估时构建未见过的结构。

Result: 实验表明，BuilderBench的许多任务对当前算法构成挑战，为此提供了简化版协议和六种算法的参考实现。

Conclusion: BuilderBench是一个旨在加速基于开放式探索的智能体预训练研究的基准测试，它通过物理模拟和多样化的任务套件挑战现有算法，促进了具身推理能力的发展。

Abstract: Today's AI models learn primarily through mimicry and sharpening, so it is
not surprising that they struggle to solve problems beyond the limits set by
existing data. To solve novel problems, agents should acquire skills for
exploring and learning through experience. Finding a scalable learning
mechanism for developing agents that learn through interaction remains a major
open problem. In this work, we introduce BuilderBench, a benchmark to
accelerate research into agent pre-training that centers open-ended
exploration. BuilderBench requires agents to learn how to build any structure
using blocks. BuilderBench is equipped with $(1)$ a hardware accelerated
simulator of a robotic agent interacting with various physical blocks, and
$(2)$ a task-suite with over 42 diverse target structures that are carefully
curated to test an understanding of physics, mathematics, and long-horizon
planning. During training, agents have to explore and learn general principles
about the environment without any external supervision. During evaluation,
agents have to build the unseen target structures from the task suite. Solving
these tasks requires a sort of \emph{embodied reasoning} that is not reflected
in words but rather in actions, experimenting with different strategies and
piecing them together. Our experiments show that many of these tasks challenge
the current iteration of algorithms. Hence, we also provide a ``training
wheels'' protocol, in which agents are trained and evaluated to build a single
target structure from the task suite. Finally, we provide single-file
implementations of six different algorithms as a reference point for
researchers.

</details>


### [110] [Requirements for Game-Based Learning Design Framework for Information System Integration in the Context of Post-Merger Integration](https://arxiv.org/abs/2510.06302)
*Ksenija Lace,Marite Kirikova*

Main category: cs.AI

TL;DR: 本文探讨如何通过游戏化学习设计解决信息系统集成培训中的高学习曲线和低动机问题，提出了一个框架并计划进行开发和评估。


<details>
  <summary>Details</summary>
Motivation: 尽管在业务层面存在兼并后整合的理论和实践指导，但信息系统集成在此背景下的培训存在显著差距。现有的AMILI和AMILP方法在实际应用中报告了高学习曲线和低学习者动机的问题。

Method: 研究分析了基础学习理论、认知负荷和动机模型以及严肃游戏设计框架，以确定针对兼并后信息系统集成的游戏化学习设计框架的基本要求。

Result: 研究确定了游戏化学习设计框架的两个核心组成部分：转换过程和结果学习体验。

Conclusion: 本文提出了一个通过游戏化学习设计来解决信息系统集成培训中高学习曲线和低学习者动机问题的框架，并计划通过迭代设计和实际验证来开发和评估该框架。

Abstract: Post-merger integration states unique challenges for professionals
responsible for information system integration aimed on alignment and
combination diverse system architectures of merging organizations. Although the
theoretical and practical guidance exists for post-merger integration on the
business level, there is a significant gap in training for information system
integration in this context. In prior research specific methods AMILI (Support
method for informed decision identification) and AMILP (Support method for
informed decision-making) were introduced for the support of information system
integration decisions in the post-merger integration. But during the practical
application was reported high learning curve and low learner motivation. This
paper explores how game-based learning design can address these limitations by
transforming static method training into engaging learning experience. The
study analyzes foundational learning theories, cognitive load and motivation
models, and serious game design frameworks to identify the essential
requirements for a game-based learning design framework tailored to information
system integration in post-merger integration. Requirements are structured in
two components: the transformation process and resulting learning experience.
The paper concludes with a plan for developing and evaluating the proposed
framework through iterative design and real-world validation.

</details>


### [111] [Belief-Calibrated Multi-Agent Consensus Seeking for Complex NLP Tasks](https://arxiv.org/abs/2510.06307)
*Wentao Deng,Jiahuan Pei,Zhiwei Xu,Zhaochun Ren,Zhumin Chen,Pengjie Ren*

Main category: cs.AI

TL;DR: BCCS框架通过优化合作者选择和校准共识判断，提升多智能体系统在NLP任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有共识寻求方法依赖投票机制，忽视系统内部信念矛盾，且合作方式缺乏针对性，导致共识不稳定。

Method: 提出Belief-Calibrated Consensus Seeking (BCCS)框架，基于理论定理选择最优合作者并校准共识判断。

Result: 在MATH和MMLU基准数据集上，BCCS框架分别比现有最佳结果提高了2.23%和3.95%的准确率。

Conclusion: BCCS框架通过选择最优合作者和校准共识判断，显著提高了多智能体系统在复杂NLP任务中的共识稳定性。

Abstract: A multi-agent system (MAS) enhances its capacity to solve complex natural
language processing (NLP) tasks through collaboration among multiple agents,
where consensus-seeking serves as a fundamental mechanism. However, existing
consensus-seeking approaches typically rely on voting mechanisms to judge
consensus, overlooking contradictions in system-internal beliefs that
destabilize the consensus. Moreover, these methods often involve agents
updating their results through indiscriminate collaboration with every other
agent. Such uniform interaction fails to identify the optimal collaborators for
each agent, hindering the emergence of a stable consensus. To address these
challenges, we provide a theoretical framework for selecting optimal
collaborators that maximize consensus stability. Based on the theorems, we
propose the Belief-Calibrated Consensus Seeking (BCCS) framework to facilitate
stable consensus via selecting optimal collaborators and calibrating the
consensus judgment by system-internal beliefs. Experimental results on the MATH
and MMLU benchmark datasets demonstrate that the proposed BCCS framework
outperforms the best existing results by 2.23% and 3.95% of accuracy on
challenging tasks, respectively. Our code and data are available at
https://github.com/dengwentao99/BCCS.

</details>


### [112] [Off-Trajectory Reasoning: Can LLMs Collaborate on Reasoning Trajectory?](https://arxiv.org/abs/2510.06410)
*Aochong Oliver Li,Tanya Goyal*

Main category: cs.AI

TL;DR: 研究发现标准单独推理训练的LLMs在离轨推理（如协作和抗干扰）上表现有限，尤其是更强模型更易受分心影响。控制实验揭示了蒸馏和教师模型选择的关键作用，为未来协作推理模型训练提供了方向。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索多个推理模型能否通过共享推理轨迹直接协作，以提高推理效率和探索能力。关键在于模型是否能评估并利用其他模型的局部推理（离轨推理）。本文重点研究了标准单独推理训练是否能实现这种能力。

Method: 本文提出了双测试方法（可恢复性和可引导性）来评估LLMs的离轨推理能力，并对15个开源LLMs（1.5B-32B）进行了实验分析。此外，通过控制实验研究了后训练中三个因素（蒸馏教师选择、强化学习使用和数据选择策略）的影响。

Result: 实验结果显示，基准测试中表现更强的LLMs在分心情况下往往更脆弱，且所有模型在利用协作推理解决超出其能力的问题时效果不佳（解决率低于9.2%）。控制实验表明，教师模型的次优行为会通过蒸馏传递给学生模型。

Conclusion: 本文揭示了标准单独推理训练流程在实现离轨推理行为上的局限性，尤其是更强的大型语言模型（LLMs）在分心情况下表现更脆弱，且所有模型在利用协作推理时效果有限（解决率低于9.2%）。研究为训练高效协作推理模型提供了实际建议，例如教师模型的次优行为会传递给学生模型。

Abstract: Reasoning LLMs are trained to verbalize their reasoning process, yielding
strong gains on complex tasks. This transparency also opens a promising
direction: multiple reasoners can directly collaborate on each other's thinking
within a shared trajectory, yielding better inference efficiency and
exploration. A key prerequisite, however, is the ability to assess the
usefulness and build on another model's partial thinking -- we call this
off-trajectory reasoning. Our paper investigates a critical question: can
standard solo-reasoning training pipelines deliver desired off-trajectory
behaviors? We propose twin tests that capture the two extremes of the
off-trajectory spectrum, namely Recoverability, which tests whether LLMs can
backtrack from "distractions" induced by misleading reasoning traces, and
Guidability, which tests their ability to build upon correct reasoning from
stronger collaborators. Our study evaluates 15 open-weight LLMs (1.5B-32B) and
reveals a counterintuitive finding -- "stronger" LLMs on benchmarks are often
more fragile under distraction. Moreover, all models tested fail to effectively
leverage guiding steps from collaborators on problems beyond their inherent
capabilities with solve rates remaining under 9.2%. Finally, we conduct control
studies to isolate the effects of three factors in post-training on these
behaviors: the choice of distillation teacher, the use of RL, and data
selection strategy. Our results provide actionable insights for training
natively strong reasoning collaborators; e.g., we find that suboptimal
recoverability behaviors of teacher models are transferred to distilled
students even if the distillation trajectories are correct. Taken together,
this work lays the groundwork for evaluating multi-model collaborations in
shared reasoning trajectories and highlights the limitations of off-the-shelf
reasoning LLMs.

</details>


### [113] [Flavonoid Fusion: Creating a Knowledge Graph to Unveil the Interplay Between Food and Health](https://arxiv.org/abs/2510.06433)
*Aryan Singh Dalal,Yinglun Zhang,Duru Doğan,Atalay Mert İleri,Hande Küçük McGinty*

Main category: cs.AI

TL;DR: 该研究通过知识图谱技术标准化了食物与健康的关系表示，为未来研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 当前关于'食物即药物'的研究缺乏标准化、机器可读的表示方法，本研究旨在填补这一空白，通过知识图谱有效整合多平台信息。

Method: 研究采用KNARM方法，利用语义网技术将食物与健康的关系以机器可操作的格式表示，结合了USDA数据库中的黄酮类成分数据和文献中的癌症关联。

Result: 成功创建了一个连接食物与健康的知识图谱，展示了黄酮类食物成分与癌症之间的关联。

Conclusion: 该研究提出的知识图谱为研究人员提供了一个探索饮食选择与疾病管理之间复杂关系的范例，未来工作包括扩展知识图谱的范围、添加更多相关数据并进行推理以揭示隐藏关系。

Abstract: The focus on "food as medicine" is gaining traction in the field of health
and several studies conducted in the past few years discussed this aspect of
food in the literature. However, very little research has been done on
representing the relationship between food and health in a standardized,
machine-readable format using a semantic web that can help us leverage this
knowledge effectively. To address this gap, this study aims to create a
knowledge graph to link food and health through the knowledge graph's ability
to combine information from various platforms focusing on flavonoid contents of
food found in the USDA databases and cancer connections found in the
literature. We looked closely at these relationships using KNARM methodology
and represented them in machine-operable format. The proposed knowledge graph
serves as an example for researchers, enabling them to explore the complex
interplay between dietary choices and disease management. Future work for this
study involves expanding the scope of the knowledge graph by capturing nuances,
adding more related data, and performing inferences on the acquired knowledge
to uncover hidden relationships.

</details>


### [114] [PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles](https://arxiv.org/abs/2510.06475)
*Yitao Long,Yuru Jiang,Hongjun Liu,Yilun Zhao,Jingchen Sun,Yiqiu Shen,Chen Zhao,Arman Cohan,Dennis Shasha*

Main category: cs.AI

TL;DR: PuzzlePlex是一个评估基础模型推理和规划能力的基准，包含多种谜题类型，结果显示推理模型在指令型设置中表现最佳，代码型执行更具挑战性。


<details>
  <summary>Details</summary>
Motivation: 研究基础模型在复杂动态环境中的推理和规划能力及其可扩展性。

Method: 引入了PuzzlePlex基准，包含15种不同类型的谜题，支持扩展性，并开发了细粒度指标来评估性能。

Result: 推理模型在指令型设置中表现最佳，而代码型执行更具挑战性但提供了可扩展的替代方案。

Conclusion: PuzzlePlex为评估基础模型在复杂动态环境中的推理和规划能力提供了一个全面的基准，并指导未来在这些方面的改进。

Abstract: This work investigates the reasoning and planning capabilities of foundation
models and their scalability in complex, dynamic environments. We introduce
PuzzlePlex, a benchmark designed to assess these capabilities through a diverse
set of puzzles. PuzzlePlex consists of 15 types of puzzles, including
deterministic and stochastic games of varying difficulty, as well as
single-player and two-player scenarios. The PuzzlePlex framework provides a
comprehensive environment for each game, and supports extensibility to generate
more challenging instances as foundation models evolve. Additionally, we
implement customized game-playing strategies for comparison. Building on this
benchmark, we develop fine-grained metrics to measure performance and conduct
an in-depth analysis of frontier foundation models across two settings:
instruction-based and code-based. Furthermore, we systematically investigate
their scaling limits. Our findings show that reasoning models outperform others
in instruction-based settings, while code-based execution presents greater
challenges but offers a scalable and efficient alternative. PuzzlePlex enables
targeted evaluation and guides future improvements in reasoning, planning, and
generalization for foundation models.

</details>


### [115] [Beneficial Reasoning Behaviors in Agentic Search and Effective Post-training to Obtain Them](https://arxiv.org/abs/2510.06534)
*Jiahe Jin,Abhijay Paladugu,Chenyan Xiong*

Main category: cs.AI

TL;DR: 论文提出行为引导技术，通过分析代理搜索中的四种有益推理行为，结合SFT和RL训练模型，显著提升了性能，并揭示了推理行为对模型探索和扩展能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究代理搜索中LLM的推理和代理能力，以解决与检索系统和网络交互时的挑战。

Method: 提出了一种基于LLM的推理驱动管道，分析了成功的代理搜索轨迹，并提出了行为引导技术，通过SFT和RL训练更有效的代理搜索模型。

Result: 实验表明，行为引导在Llama3.2-3B和Qwen3-1.7B上实现了超过35%的性能提升，且推理行为比最终答案的正确性对RL后的性能更为关键。

Conclusion: 行为引导技术（Behavior Priming）通过监督微调（SFT）和强化学习（RL）显著提升了代理搜索模型的性能，证明了推理行为对最终性能的关键作用。

Abstract: Agentic search leverages large language models (LLMs) to interpret complex
user information needs and execute a multi-step process of planning, searching,
and synthesizing information to provide answers. This paradigm introduces
unique challenges for LLMs' reasoning and agentic capabilities when interacting
with retrieval systems and the broader web. In this paper, we propose a
reasoning-driven LLM-based pipeline to study effective reasoning behavior
patterns in agentic search. Using this pipeline, we analyze successful agentic
search trajectories and identify four beneficial reasoning behaviors:
Information Verification, Authority Evaluation, Adaptive Search, and Error
Recovery. Based on these findings, we propose a technique called Behavior
Priming to train more effective agentic search models. It synthesizes agentic
search trajectories that exhibit these four behaviors and integrates them into
the agentic search model through supervised fine-tuning (SFT), followed by
standard reinforcement learning (RL). Experiments on three benchmarks (GAIA,
WebWalker, and HLE) demonstrate that behavior priming yields over 35% gains in
Llama3.2-3B and Qwen3-1.7B compared to directly training agentic search models
with RL. Crucially, we demonstrate that the desired reasoning behaviors in the
SFT data, rather than the correctness of the final answer, is the critical
factor for achieving strong final performance after RL: fine-tuning on
trajectories with desirable reasoning behaviors but incorrect answers leads to
better performance than fine-tuning on trajectories with correct answers. Our
analysis further reveals the underlying mechanism: the introduced reasoning
behaviors endow models with more effective exploration (higher pass@k and
entropy) and test-time scaling (longer trajectories) capabilities, providing a
strong foundation for RL. Our code will be released as open source.

</details>


### [116] [Auto-Prompt Ensemble for LLM Judge](https://arxiv.org/abs/2510.06538)
*Jiajie Li,Huayi Zhang,Peng Lin,Jinjun Xiong,Wei Xu*

Main category: cs.AI

TL;DR: APE框架通过自适应学习和置信度集成，提升了LLM法官的评估可靠性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM法官常因未能识别人类评估的隐含标准而遗漏关键评估维度，导致评估可靠性不足。

Method: 提出了Auto-Prompt Ensemble (APE)框架，通过从失败案例中自动学习评估维度，并采用基于置信度的集成机制（Collective Confidence）来决定何时采纳额外评估维度的判断。

Result: 实验表明，APE在多样化的标准基准测试中提升了LLM法官的可靠性，例如在零样本设置下将GPT-4o在Reward Bench上的同意率从87.2%提高到90.5%。

Conclusion: APE框架通过自适应学习评估维度和置信度集成机制，显著提升了LLM法官的可靠性，缩小了人类与LLM评估之间的差距。

Abstract: We present a novel framework that improves the reliability of LLM judges by
selectively augmenting LLM with auxiliary evaluation dimensions. Existing LLM
judges often miss crucial evaluation dimensions because they fail to recognize
the implicit standards underlying human assessments. To address this challenge,
we propose the Auto-Prompt Ensemble (APE), an adaptive framework that
automatically learns evaluation dimensions from its failure cases. APE
incorporates a confidence-based ensemble mechanism to decide when to adopt the
judgments from additional evaluation dimensions through a novel confidence
estimation approach called Collective Confidence. Extensive experiments
demonstrate that APE improves the reliability of LLM Judge across diverse
standard benchmarks. For instance, APE enhances GPT-4o agreement rate on Reward
Bench from 87.2% to 90.5% in the zero-shot setting. Overall, APE provides a
principled approach for LLM Judge to leverage test-time computation, and bridge
the evaluation gap between human and LLM judges.

</details>


### [117] [WebDART: Dynamic Decomposition and Re-planning for Complex Web Tasks](https://arxiv.org/abs/2510.06587)
*Jingbo Yang,Bairu Hou,Wei Wei,Shiyu Chang,Yujia Bao*

Main category: cs.AI

TL;DR: WebDART通过动态任务分解和持续规划，显著提升了LLM代理处理复杂网络任务的能力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在简单网络任务中表现良好，但在需要长时程导航、大规模信息提取和约束下推理的复杂任务中仍有困难。

Method: WebDART将目标动态分解为导航、信息提取和执行三个子任务，并持续重新规划以利用新发现的网页信息。

Result: 在WebChoreArena上，WebDART将成功率提升了13.7个百分点，同时减少了14.7%的导航步骤。

Conclusion: WebDART框架通过动态分解任务和持续重新规划，显著提升了LLM代理在复杂网络任务中的表现，尤其在长时程导航和大规模信息提取方面。

Abstract: Large language model (LLM) agents are becoming competent at straightforward
web tasks, such as opening an item page or submitting a form, but still
struggle with objectives that require long horizon navigation, large scale
information extraction, and reasoning under constraints. We present WebDART, a
general framework that enables a single LLM to handle such complex chores.
WebDART (i) dynamically decomposes each objective into three focused subtasks:
navigation, information extraction, and execution, so the model concentrates on
one skill at a time, and (ii) continuously replans the decomposition as new
webpages are revealed, taking advantage of newly discovered filters or
shortcuts and avoiding redundant exploration. Evaluated on WebChoreArena,
WebDART lifts success rates by up to 13.7 percentage points over previous SOTA
agents, while matching their performance on the easier WebArena suite and
completing tasks with up to 14.7 fewer navigation steps.

</details>


### [118] [Fine-Grained Emotion Recognition via In-Context Learning](https://arxiv.org/abs/2510.06600)
*Zhaochun Ren,Zhou Yang,Chenglong Ye,Haizhou Sun,Chao Chen,Xiaofei Zhu,Xiangwen Liao*

Main category: cs.AI

TL;DR: 本文提出EICL方法，通过情感相似示例和动态软标签策略优化细粒度情感识别的决策过程，实验证明其优于现有ICL方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如ICL）通过语义相似示例增强推理过程，但忽视了决策过程，且语义相似示例可能引入情感差异，导致错误。本文旨在解决这一问题。

Method: 本文采用Emotion In-Context Learning (EICL)方法，引入情感相似示例并使用动态软标签策略改进查询表示，随后采用两阶段排除策略从多角度评估相似性，优化决策过程。

Result: 实验表明，EICL在多个数据集上显著优于ICL。

Conclusion: 本文通过原型理论研究了细粒度情感识别中的决策过程，提出了EICL方法，通过引入情感相似示例和动态软标签策略，显著提升了情感识别的准确率。

Abstract: Fine-grained emotion recognition aims to identify the emotional type in
queries through reasoning and decision-making processes, playing a crucial role
in various systems. Recent methods use In-Context Learning (ICL), enhancing the
representation of queries in the reasoning process through semantically similar
examples, while further improving emotion recognition by explaining the
reasoning mechanisms. However, these methods enhance the reasoning process but
overlook the decision-making process. This paper investigates decision-making
in fine-grained emotion recognition through prototype theory. We show that ICL
relies on similarity matching between query representations and emotional
prototypes within the model, where emotion-accurate representations are
critical. However, semantically similar examples often introduce emotional
discrepancies, hindering accurate representations and causing errors. To
address this, we propose Emotion In-Context Learning (EICL), which introduces
emotionally similar examples and uses a dynamic soft-label strategy to improve
query representations in the emotion reasoning process. A two-stage exclusion
strategy is then employed to assess similarity from multiple angles, further
optimizing the decision-making process. Extensive experiments show that EICL
significantly outperforms ICL on multiple datasets.

</details>


### [119] [Agent-in-the-Loop: A Data Flywheel for Continuous Improvement in LLM-based Customer Support](https://arxiv.org/abs/2510.06674)
*Cen,Zhao,Tiantian Zhang,Hanchen Su,Yufeng,Zhang,Shaowei Su,Mingzhi Xu,Yu,Liu,Wei Han,Jeremy Werner,Claire Na Cheng,Yashar Mehdad*

Main category: cs.AI

TL;DR: AITL框架通过实时人类反馈循环，快速优化LLM客户支持系统，显著提升性能指标。


<details>
  <summary>Details</summary>
Motivation: 传统离线批注方法无法满足实时改进需求，AITL旨在通过持续反馈循环快速优化LLM客户支持系统。

Method: AITL框架整合了四种关键注释类型：响应偏好、代理采纳与理由、知识相关性检查及缺失知识识别，直接应用于实时客户操作。

Result: 生产试点显示，检索准确性（召回率+11.7%，精确度+14.8%）、生成质量（帮助性+8.4%）和代理采纳率（+4.5%）均有显著提升。

Conclusion: AITL框架通过将人类反馈直接嵌入运营工作流，显著提升了基于LLM的客户支持系统的性能，减少了模型更新周期。

Abstract: We introduce an Agent-in-the-Loop (AITL) framework that implements a
continuous data flywheel for iteratively improving an LLM-based customer
support system. Unlike standard offline approaches that rely on batch
annotations, AITL integrates four key types of annotations directly into live
customer operations: (1) pairwise response preferences, (2) agent adoption and
rationales, (3) knowledge relevance checks, and (4) identification of missing
knowledge. These feedback signals seamlessly feed back into models' updates,
reducing retraining cycles from months to weeks. Our production pilot involving
US-based customer support agents demonstrated significant improvements in
retrieval accuracy (+11.7% recall@75, +14.8% precision@8), generation quality
(+8.4% helpfulness) and agent adoption rates (+4.5%). These results underscore
the effectiveness of embedding human feedback loops directly into operational
workflows to continuously refine LLM-based customer support system.

</details>


### [120] [Inefficiencies of Meta Agents for Agent Design](https://arxiv.org/abs/2510.06711)
*Batu El,Mert Yuksekgonul,James Zou*

Main category: cs.AI

TL;DR: 研究发现进化方法提升元代理性能，但行为多样性低且多数情况下自动化设计不经济。


<details>
  <summary>Details</summary>
Motivation: 探讨自动化设计代理系统的可行性，解决元代理在学习、行为多样性和经济性方面的挑战。

Method: 研究了元代理在迭代学习中的表现，比较了简单扩展上下文与进化方法的效果，并评估了设计代理的行为多样性及经济性。

Result: 进化方法优于简单扩展上下文；设计代理行为多样性低；仅在少数情况下自动化设计经济可行。

Conclusion: 自动化设计代理系统在特定情况下（如两个数据集）经济可行，但多数情况下性能提升不足以弥补设计成本。

Abstract: Recent works began to automate the design of agentic systems using
meta-agents that propose and iteratively refine new agent architectures. In
this paper, we examine three key challenges in a common class of meta-agents.
First, we investigate how a meta-agent learns across iterations and find that
simply expanding the context with all previous agents, as proposed by previous
works, performs worse than ignoring prior designs entirely. We show that the
performance improves with an evolutionary approach. Second, although the
meta-agent designs multiple agents during training, it typically commits to a
single agent at test time. We find that the designed agents have low behavioral
diversity, limiting the potential for their complementary use. Third, we assess
when automated design is economically viable. We find that only in a few
cases--specifically, two datasets--the overall cost of designing and deploying
the agents is lower than that of human-designed agents when deployed on over
15,000 examples. In contrast, the performance gains for other datasets do not
justify the design cost, regardless of scale.

</details>


### [121] [MultiCNKG: Integrating Cognitive Neuroscience, Gene, and Disease Knowledge Graphs Using Large Language Models](https://arxiv.org/abs/2510.06742)
*Ali Sarabadani,Kheirolah Rahsepar Fard*

Main category: cs.AI

TL;DR: MultiCNKG是一个整合多种知识源的大语言模型增强知识图谱，显著提升了基因、疾病和认知过程的语义链接能力，并在多项评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习方法在捕捉基因、疾病和认知过程之间复杂语义联系方面存在局限，MultiCNKG旨在通过大语言模型和知识图谱的结合解决这一问题。

Method: 利用GPT-4等大语言模型进行实体对齐、语义相似度计算和图增强，整合Cognitive Neuroscience Knowledge Graph (CNKG)、Gene Ontology (GO)和Disease Ontology (DO)三种知识源。

Result: MultiCNKG包含6.9K节点和11.3K边，评估指标显示其在精度（85.20%）、召回率（87.30%）等方面表现优异，链接预测任务中TransE和RotatE模型也展现出竞争力。

Conclusion: MultiCNKG框架通过整合多种知识源并利用大语言模型，成功构建了一个连接基因机制、神经疾病和认知功能的知识图谱，为个性化医疗、认知障碍诊断和认知神经科学假设提供了有力工具。

Abstract: The advent of large language models (LLMs) has revolutionized the integration
of knowledge graphs (KGs) in biomedical and cognitive sciences, overcoming
limitations in traditional machine learning methods for capturing intricate
semantic links among genes, diseases, and cognitive processes. We introduce
MultiCNKG, an innovative framework that merges three key knowledge sources: the
Cognitive Neuroscience Knowledge Graph (CNKG) with 2.9K nodes and 4.3K edges
across 9 node types and 20 edge types; Gene Ontology (GO) featuring 43K nodes
and 75K edges in 3 node types and 4 edge types; and Disease Ontology (DO)
comprising 11.2K nodes and 8.8K edges with 1 node type and 2 edge types.
Leveraging LLMs like GPT-4, we conduct entity alignment, semantic similarity
computation, and graph augmentation to create a cohesive KG that interconnects
genetic mechanisms, neurological disorders, and cognitive functions. The
resulting MultiCNKG encompasses 6.9K nodes across 5 types (e.g., Genes,
Diseases, Cognitive Processes) and 11.3K edges spanning 7 types (e.g., Causes,
Associated with, Regulates), facilitating a multi-layered view from molecular
to behavioral domains. Assessments using metrics such as precision (85.20%),
recall (87.30%), coverage (92.18%), graph consistency (82.50%), novelty
detection (40.28%), and expert validation (89.50%) affirm its robustness and
coherence. Link prediction evaluations with models like TransE (MR: 391, MRR:
0.411) and RotatE (MR: 263, MRR: 0.395) show competitive performance against
benchmarks like FB15k-237 and WN18RR. This KG advances applications in
personalized medicine, cognitive disorder diagnostics, and hypothesis
formulation in cognitive neuroscience.

</details>


### [122] [Verifying Memoryless Sequential Decision-making of Large Language Models](https://arxiv.org/abs/2510.06756)
*Dennis Gross,Helge Spieker,Arnaud Gotlieb*

Main category: cs.AI

TL;DR: 该论文提出了一种自动化验证工具，用于检查LLM策略在顺序决策任务中的安全性，实验表明其有效性但性能不及深度强化学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决大型语言模型在顺序决策任务中的安全性和可靠性验证问题，作者提出了一种自动化工具，旨在确保LLM策略在无记忆环境中的行为符合安全要求。

Method: 通过马尔可夫决策过程（MDP）表示顺序决策任务，利用LLM策略逐步构建MDP的可达部分，将每个状态编码为自然语言提示，解析LLM的响应为动作，并扩展策略的可达后继状态。生成的正式模型通过Storm验证是否符合指定的安全属性。

Result: 实验表明，通过Ollama访问的开源LLM在确定性种子条件下可以成功验证，但通常表现不如深度强化学习基线。

Conclusion: 该工具为大型语言模型（LLM）策略在无记忆顺序决策任务中的自动化验证提供了严格的方法，并与Ollama原生集成，支持PRISM指定的任务，为未来验证更强大的LLM奠定了实用基础。

Abstract: We introduce a tool for rigorous and automated verification of large language
model (LLM)- based policies in memoryless sequential decision-making tasks.
Given a Markov decision process (MDP) representing the sequential
decision-making task, an LLM policy, and a safety requirement expressed as a
PCTL formula, our approach incrementally constructs only the reachable portion
of the MDP guided by the LLM's chosen actions. Each state is encoded as a
natural language prompt, the LLM's response is parsed into an action, and
reachable successor states by the policy are expanded. The resulting formal
model is checked with Storm to determine whether the policy satisfies the
specified safety property. In experiments on standard grid world benchmarks, we
show that open source LLMs accessed via Ollama can be verified when
deterministically seeded, but generally underperform deep reinforcement
learning baselines. Our tool natively integrates with Ollama and supports
PRISM-specified tasks, enabling continuous benchmarking in user-specified
sequential decision-making tasks and laying a practical foundation for formally
verifying increasingly capable LLMs.

</details>


### [123] [Evolving and Executing Research Plans via Double-Loop Multi-Agent Collaboration](https://arxiv.org/abs/2510.06761)
*Zhi Zhang,Yan Liu,Zhejing Hu,Gong Chen,Sheng-hua Zhong,Jiannong Cao*

Main category: cs.AI

TL;DR: DLMA框架通过教授与博士生智能体的双层协作，实现了科研计划的动态优化与执行，显著提升了自动化科研的质量。


<details>
  <summary>Details</summary>
Motivation: 自动化端到端科研过程面临高层次规划新颖性与执行动态性的双重挑战，需要一种能同时优化规划与执行的解决方案。

Method: 提出了一种双层多智能体（DLMA）框架，领导者循环由教授智能体组成，采用进化算法迭代生成和优化研究提案；跟随者循环由博士生智能体组成，动态调整计划执行。

Result: 在ACLAward和Laboratory等基准测试中，DLMA生成的研究论文在自动化评估中达到最先进水平，显著优于基线方法。消融实验验证了双层循环的关键作用。

Conclusion: DLMA框架通过双层循环结构（领导者循环和跟随者循环）有效解决了自动化科研过程中的高层次规划与动态执行问题，实验证明其在生成高质量研究论文方面优于现有基线。

Abstract: Automating the end-to-end scientific research process poses a fundamental
challenge: it requires both evolving high-level plans that are novel and sound,
and executing these plans correctly amidst dynamic and uncertain conditions. To
address this bilevel challenge, we propose a novel Double-Loop Multi-Agent
(DLMA) framework to solve the given research problem automatically. The leader
loop, composed of professor agents, is responsible for evolving research plans.
It employs an evolutionary algorithm through involvement, improvement, and
integration meetings to iteratively generate and refine a pool of research
proposals, exploring the solution space effectively. The follower loop,
composed of doctoral student agents, is responsible for executing the
best-evolved plan. It dynamically adjusts the plan during implementation via
pre-hoc and post-hoc meetings, ensuring each step (e.g., drafting, coding) is
well-supported by contextual and external observations. Extensive experiments
on benchmarks like ACLAward and Laboratory show that DLMA generates research
papers that achieve state-of-the-art scores in automated evaluation,
significantly outperforming strong baselines. Ablation studies confirm the
critical roles of both loops, with evolution driving novelty and execution
ensuring soundness.

</details>


### [124] [Autoformalizer with Tool Feedback](https://arxiv.org/abs/2510.06857)
*Qi Guo,Jianing Wang,Jianfei Zhang,Deyang Kong,Xiangzhou Huang,Xiangyu Xi,Wei Wang,Jingang Wang,Xunliang Cai,Shikun Zhang,Wei Ye*

Main category: cs.AI

TL;DR: ATF通过工具反馈提升自动形式化效果，实验表现优异并开源数据集。


<details>
  <summary>Details</summary>
Motivation: 现有形式化模型在生成语法有效且语义一致的陈述时表现不稳定，需改进。

Method: 提出ATF模型，结合Lean 4编译器进行语法修正和多LLMs判断一致性验证，通过冷启动训练、专家迭代和直接偏好优化三个阶段优化模型。

Result: ATF在实验中表现优异，具有优秀的推理扩展性，并开源了750K合成形式陈述数据集。

Conclusion: ATF通过整合工具反馈显著提升了自动形式化的语法有效性和语义一致性，并在实验中优于多种基线模型。此外，开源数据集Numina-ATF为未来研究提供了资源。

Abstract: Autoformalization addresses the scarcity of data for Automated Theorem
Proving (ATP) by translating mathematical problems from natural language into
formal statements. Efforts in recent work shift from directly prompting large
language models to training an end-to-end formalizer model from scratch,
achieving remarkable advancements. However, existing formalizer still struggles
to consistently generate valid statements that meet syntactic validity and
semantic consistency. To address this issue, we propose the Autoformalizer with
Tool Feedback (ATF), a novel approach that incorporates syntactic and
consistency information as tools into the formalization process. By integrating
Lean 4 compilers for syntax corrections and employing a multi-LLMs-as-judge
approach for consistency validation, the model is able to adaptively refine
generated statements according to the tool feedback, enhancing both syntactic
validity and semantic consistency. The training of ATF involves a cold-start
phase on synthetic tool-calling data, an expert iteration phase to improve
formalization capabilities, and Direct Preference Optimization to alleviate
ineffective revisions. Experimental results show that ATF markedly outperforms
a range of baseline formalizer models, with its superior performance further
validated by human evaluations. Subsequent analysis reveals that ATF
demonstrates excellent inference scaling properties. Moreover, we open-source
Numina-ATF, a dataset containing 750K synthetic formal statements to facilitate
advancements in autoformalization and ATP research.

</details>


### [125] [TGPR: Tree-Guided Policy Refinement for Robust Self-Debugging of LLMs](https://arxiv.org/abs/2510.06878)
*Daria Ozerova,Ekaterina Trofimova*

Main category: cs.AI

TL;DR: TGPR结合GRPO和Thompson-Sampling树搜索，显著提升LLMs在代码调试等迭代精炼任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于预定义的启发式方法，无法根据过去的精炼结果进行自适应调整，存在探索-利用困境。

Method: TGPR框架结合了GRPO和基于Thompson-Sampling的树搜索，探索失败和成功的精炼路径，生成更密集的训练轨迹和更自适应的策略。

Result: 在HumanEval、MBPP和APPS基准测试中，TGPR在pass@1（MBPP）和pass@10（APPS）上分别实现了+4.2和+12.51百分点的绝对改进。

Conclusion: TGPR提出了一种结合GRPO和Thompson-Sampling树搜索的新框架，显著提升了LLMs在迭代精炼任务中的性能，为增强LLMs的迭代精炼和状态推理提供了通用框架。

Abstract: Iterative refinement has been a promising paradigm to enable large language
models (LLMs) to resolve difficult reasoning and problem-solving tasks. One of
the key challenges, however, is how to effectively search through the enormous
search space of possible refinements. Existing methods typically fall back on
predefined heuristics, which are troubled by the exploration-exploitation
dilemma and cannot adapt based on past refinement outcomes. We introduce
Tree-Guided Policy Refinement (TGPR), a novel framework that combines GRPO with
a Thompson-Sampling-based tree search. TGPR explores both failed and successful
refinement paths actively, with denser training trajectories and more adaptive
policies. On HumanEval, MBPP, and APPS benchmarks, our method achieves up to
+4.2 percentage points absolute improvement in pass@1 (on MBPP) and up to
+12.51 percentage points absolute improvement in pass@10 (on APPS) compared to
a competitive GRPO baseline. Apart from debugging code, TGPR focuses on a
principled approach to combining learned policies with structured search
methods, offering a general framework for enhancing iterative refinement and
stateful reasoning in LLMs.

</details>


### [126] [LLM-Assisted Modeling of Semantic Web-Enabled Multi-Agents Systems with AJAN](https://arxiv.org/abs/2510.06911)
*Hacane Hechehouche,Andre Antakli,Matthias Klusch*

Main category: cs.AI

TL;DR: 本文介绍了一种集成开发环境，简化了AJAN代理的建模过程，并利用大型语言模型扩展了用户社区。


<details>
  <summary>Details</summary>
Motivation: 现有的RDF/RDFS和SPARQL代理行为定义存在挑战，如URI处理易错和复杂SPARQL查询的学习曲线高，限制了AJAN框架的广泛应用。

Method: 通过集成开发环境，简化了RDF/RDFS和SPARQL代理行为的定义，利用大型语言模型辅助代理工程。

Result: 开发了一个集成开发环境，有效降低了建模AJAN代理的难度，并扩展了用户社区。

Conclusion: 本文提出了一种集成开发环境，旨在解决建模AJAN代理时的挑战，并通过利用大型语言模型来扩展AJAN的用户社区。

Abstract: There are many established semantic Web standards for implementing
multi-agent driven applications. The AJAN framework allows to engineer
multi-agent systems based on these standards. In particular, agent knowledge is
represented in RDF/RDFS and OWL, while agent behavior models are defined with
Behavior Trees and SPARQL to access and manipulate this knowledge. However, the
appropriate definition of RDF/RDFS and SPARQL-based agent behaviors still
remains a major hurdle not only for agent modelers in practice. For example,
dealing with URIs is very error-prone regarding typos and dealing with complex
SPARQL queries in large-scale environments requires a high learning curve. In
this paper, we present an integrated development environment to overcome such
hurdles of modeling AJAN agents and at the same time to extend the user
community for AJAN by the possibility to leverage Large Language Models for
agent engineering.

</details>


### [127] [Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces](https://arxiv.org/abs/2510.06953)
*Minju Gwak,Guijin Son,Jaehyung Kim*

Main category: cs.AI

TL;DR: UID hypothesis applied to LLM reasoning shows step-level uniformity improves accuracy, with correct traces avoiding information spikes.


<details>
  <summary>Details</summary>
Motivation: To investigate whether step-level uniformity in information density reflects reasoning quality in large language models.

Method: Proposed an entropy-based stepwise information density metric and introduced two complementary measures of uniformity: local and global uniformity scores.

Result: Step-level uniformity improves accuracy by 10-32% relative gains over baselines, with correct reasoning traces avoiding sharp information spikes.

Conclusion: UID-inspired information density measures are effective predictors of reasoning quality, serving as robust diagnostic and selection criteria for more reliable reasoning systems.

Abstract: The Uniform Information Density (UID) hypothesis suggests that effective
communication maintains a stable flow of information. In this work, we revisit
this principle in the context of large language model (LLM) reasoning traces,
asking whether step-level uniformity reflects reasoning quality. To this end,
we propose an entropy-based stepwise information density metric and introduce
two complementary measures of uniformity, local and global uniformity scores.
Across the experiments on six different reasoning benchmarks, we find that
step-level uniformity not only provides a strong theoretical lens but also
yields practical performance benefits; for example, selecting reasoning traces
with more uniform information density at the step-level improves accuracy by
10-32\% relative gains over baselines at AIME2025. Our analysis further reveals
that correct reasoning traces tend to avoid sharp information density spikes,
while incorrect traces exhibit irregular information bursts. These results
demonstrate that UID-inspired information density measures outperform
alternative internal signals as predictors of reasoning quality. Results
highlight the uniformity of the information density as a robust diagnostic and
selection criterion for building more reliable and accurate reasoning systems.

</details>


### [128] [Tool-Augmented Policy Optimization: Synergizing Reasoning and Adaptive Tool Use with Reinforcement Learning](https://arxiv.org/abs/2510.07038)
*Wenxun Wu,Yuanyang Li,Guhan Chen,Linyue Wang,Hongyang Chen*

Main category: cs.AI

TL;DR: TAPO是一个强化学习框架，通过结合推理和工具调用，提升了模型在复杂任务中的性能，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的语言模型在需要最新知识或计算工具（如计算器和代码解释器）的任务中表现不佳，因此需要一种能系统整合推理和工具调用的方法。

Method: 提出了Tool-Augmented Policy Optimization (TAPO)，一个基于强化学习的框架，通过改进Dynamic Sampling Policy Optimization (DAPO)来动态交替复杂推理和工具调用。

Result: 在Qwen2.5-3B和Qwen2.5-7B模型上，TAPO在需要外部知识和数学计算的任务中达到了最先进的性能，并实现了更高效的工具利用。

Conclusion: TAPO框架通过结合多跳推理和自适应工具调用能力，显著提升了模型在知识密集和计算密集型任务中的性能，并实现了比基线方法更高效的工具利用。

Abstract: Recent advances in large language models (LLMs) have popularized test-time
scaling, where models generate additional reasoning tokens before producing
final answers. These approaches have demonstrated significant performance
improvements on benchmarks involving mathematical reasoning. However, language
models relying solely on direct inference still struggle with tasks demanding
up-to-date knowledge or computational tools such as calculators and code
interpreters for complex arithmetic operations. To overcome these limitations,
we propose Tool-Augmented Policy Optimization (TAPO), a novel reinforcement
learning framework that systematically integrates multi-hop reasoning with
adaptive tool-calling capabilities. Our approach employs a modified version of
Dynamic Sampling Policy Optimization (DAPO), a recently developed RL paradigm,
which we adapt specifically for tool invocation scenarios, enabling models to
dynamically interleave complex reasoning with on-demand tool usage (including
search APIs and Python interpreters).
  To support this research, we introduce two new datasets: TAPO-easy-60K and
TAPO-hard-18K, specifically designed to train and evaluate both fact-based
reasoning and mathematical calculation capabilities. Our experiments on
Qwen2.5-3B and Qwen2.5-7B models demonstrate the effectiveness of our approach,
with both models achieving state-of-the-art performance on tasks requiring
external knowledge and mathematical computation among methods with comparable
parameters. Notably, TAPO achieves more efficient tool utilization than
baseline methods while preventing excessive calls caused by reward hacking.
These results highlight the significant potential of combining advanced
reasoning with tool usage to enhance model performance in knowledge-intensive
and computationally demanding tasks.

</details>


### [129] [Prompt Optimization Across Multiple Agents for Representing Diverse Human Populations](https://arxiv.org/abs/2510.07064)
*Manh Hung Nguyen,Sebastian Tschiatschek,Adish Singla*

Main category: cs.AI

TL;DR: 论文提出通过次模优化选择代表性LLM代理集合，以捕捉人类多样性，实验验证其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为人类行为的代理存在输出同质化问题，无法捕捉人类观点和行为的多样性。

Method: 利用上下文学习条件化少量人类示范（任务-响应对）来引导每个LLM代理的行为，并通过次模优化方法从可能的代理空间中选择代表性集合。

Result: 实验表明，该方法构建的代理能更有效地代表人类群体，并在新任务中复制目标人群的行为模式和观点。

Conclusion: 该论文提出了一种新颖的框架，通过构建一组代理来更有效地代表人类群体的多样性，实验证明其在人群和教育领域中优于基线方法。

Abstract: The difficulty and expense of obtaining large-scale human responses make
Large Language Models (LLMs) an attractive alternative and a promising proxy
for human behavior. However, prior work shows that LLMs often produce
homogeneous outputs that fail to capture the rich diversity of human
perspectives and behaviors. Thus, rather than trying to capture this diversity
with a single LLM agent, we propose a novel framework to construct a set of
agents that collectively capture the diversity of a given human population.
Each agent is an LLM whose behavior is steered by conditioning on a small set
of human demonstrations (task-response pairs) through in-context learning. The
central challenge is therefore to select a representative set of LLM agents
from the exponentially large space of possible agents. We tackle this selection
problem from the lens of submodular optimization. In particular, we develop
methods that offer different trade-offs regarding time complexity and
performance guarantees. Extensive experiments in crowdsourcing and educational
domains demonstrate that our approach constructs agents that more effectively
represent human populations compared to baselines. Moreover, behavioral
analyses on new tasks show that these agents reproduce the behavior patterns
and perspectives of the students and annotators they are designed to represent.

</details>


### [130] [Inductive Learning for Possibilistic Logic Programs Under Stable Models](https://arxiv.org/abs/2510.07069)
*Hongbo Hu,Yisong Wang,Yi Huang,Kewen Wang*

Main category: cs.AI

TL;DR: 本文研究了poss-program的归纳推理问题，提出了两种算法并验证了其性能优势。


<details>
  <summary>Details</summary>
Motivation: 虽然possibilistic稳定模型的语义和性质已被深入研究，但归纳推理问题尚未被探讨。

Method: 定义了归纳任务的正式概念，研究了其性质，并提出了两种算法ilpsm和ilpsmmin来计算归纳解。

Result: 实验结果表明，当输入为普通逻辑程序时，ilpsmmin原型在随机生成的数据集上优于主要的基于稳定模型的归纳学习系统。

Conclusion: 本文提出了两种算法ilpsm和ilpsmmin，用于从背景程序和示例中提取poss-program，并通过实验验证了ilpsmmin在普通逻辑程序输入下的优越性能。

Abstract: Possibilistic logic programs (poss-programs) under stable models are a major
variant of answer set programming (ASP). While its semantics (possibilistic
stable models) and properties have been well investigated, the problem of
inductive reasoning has not been investigated yet. This paper presents an
approach to extracting poss-programs from a background program and examples
(parts of intended possibilistic stable models). To this end, the notion of
induction tasks is first formally defined, its properties are investigated and
two algorithms ilpsm and ilpsmmin for computing induction solutions are
presented. An implementation of ilpsmmin is also provided and experimental
results show that when inputs are ordinary logic programs, the prototype
outperforms a major inductive learning system for normal logic programs from
stable models on the datasets that are randomly generated.

</details>


### [131] [VRPAgent: LLM-Driven Discovery of Heuristic Operators for Vehicle Routing Problems](https://arxiv.org/abs/2510.07073)
*André Hottung,Federico Berto,Chuanbo Hua,Nayeli Gast Zepeda,Daniel Wetzel,Michael Römer,Haoran Ye,Davide Zago,Michael Poli,Stefano Massaroli,Jinkyoo Park,Kevin Tierney*

Main category: cs.AI

TL;DR: VRPAgent框架通过LLM生成问题特定操作符并嵌入元启发式，结合遗传搜索优化，在多个VRP问题上超越手工和现有学习方法，仅需单核CPU。


<details>
  <summary>Details</summary>
Motivation: 设计高性能的车辆路径问题（VRPs）启发式需要直觉和深厚的领域知识，而现有的LLM代码生成在生成与人类专家相媲美的启发式方面仍有不足。

Method: VRPAgent框架将LLM生成的组件集成到元启发式中，并通过新颖的遗传搜索进行优化。利用LLM生成特定问题的操作符，嵌入通用元启发式框架中，确保任务可管理性、正确性，并能够发现新颖且强大的策略。

Result: 在包括容量约束VRP、时间窗VRP和奖励收集VRP在内的多个问题中，VRPAgent发现的启发式操作符优于手工制作的方法和最近的学习方法，且仅需单个CPU核心。

Conclusion: VRPAgent是首个基于LLM的范式，能够在VRPs中推进最新技术，为自动化启发式发现展示了光明的未来。

Abstract: Designing high-performing heuristics for vehicle routing problems (VRPs) is a
complex task that requires both intuition and deep domain knowledge. Large
language model (LLM)-based code generation has recently shown promise across
many domains, but it still falls short of producing heuristics that rival those
crafted by human experts. In this paper, we propose VRPAgent, a framework that
integrates LLM-generated components into a metaheuristic and refines them
through a novel genetic search. By using the LLM to generate problem-specific
operators, embedded within a generic metaheuristic framework, VRPAgent keeps
tasks manageable, guarantees correctness, and still enables the discovery of
novel and powerful strategies. Across multiple problems, including the
capacitated VRP, the VRP with time windows, and the prize-collecting VRP, our
method discovers heuristic operators that outperform handcrafted methods and
recent learning-based approaches while requiring only a single CPU core. To our
knowledge, \VRPAgent is the first LLM-based paradigm to advance the
state-of-the-art in VRPs, highlighting a promising future for automated
heuristics discovery.

</details>


### [132] [The Cognitive Bandwidth Bottleneck: Shifting Long-Horizon Agent from Planning with Actions to Planning with Schemas](https://arxiv.org/abs/2510.07091)
*Baixuan Xu,Tianshi Zheng,Zhaowei Wang,Hong Ting Tsang,Weiqi Wang,Tianqing Fang,Yangqiu Song*

Main category: cs.AI

TL;DR: 本文系统比较了PwA和PwS两种动作表示方法，发现PwS更可扩展但性能不足，并提出了改进PwS代理的实用指南。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于传统动作表示方法在环境动作空间组合爆炸（如开放世界）时的局限性。作者探讨了在动作空间扩展时，如何选择最优动作表示以实现长期任务的有效执行。

Method: 研究方法包括系统比较两种动作表示方法（PwA和PwS），并通过认知带宽视角定性分析其差异。实证研究在ALFWorld（约35个动作）和SciWorld（约500个动作）上观察到一个表示选择的转折点。

Result: 研究结果表明，PwS在可扩展性上优于PwA，但性能仍不足。实验发现模型能力（如规划熟练度和模式实例化能力）会影响转折点的位置。

Conclusion: 论文结论指出，尽管PwS（规划与模式）在可扩展性方面表现优异，但其性能目前仍不如PwA（规划与动作）。作者提出了构建更强大PwS代理的实用指南，以推动可扩展自主性的发展。

Abstract: Enabling LLMs to effectively operate long-horizon task which requires
long-term planning and multiple interactions is essential for open-world
autonomy. Conventional methods adopt planning with actions where a executable
action list would be provided as reference. However, this action representation
choice would be impractical when the environment action space is combinatorial
exploded (e.g., open-ended real world). This naturally leads to a question: As
environmental action space scales, what is the optimal action representation
for long-horizon agents? In this paper, we systematically study the
effectiveness of two different action representations. The first one is
conventional planning with actions (PwA) which is predominantly adopted for its
effectiveness on existing benchmarks. The other one is planning with schemas
(PwS) which instantiate an action schema into action lists (e.g., "move [OBJ]
to [OBJ]" -> "move apple to desk") to ensure concise action space and reliable
scalability. This alternative is motivated by its alignment with human
cognition and its compliance with environment-imposed action format
restriction. We propose cognitive bandwidth perspective as a conceptual
framework to qualitatively understand the differences between these two action
representations and empirically observe a representation-choice inflection
point between ALFWorld (~35 actions) and SciWorld (~500 actions), which serve
as evidence of the need for scalable representations. We further conduct
controlled experiments to study how the location of this inflection point
interacts with different model capacities: stronger planning proficiency shifts
the inflection rightward, whereas better schema instantiation shifts it
leftward. Finally, noting the suboptimal performance of PwS agents, we provide
an actionable guide for building more capable PwS agents for better scalable
autonomy.

</details>


### [133] [The Contingencies of Physical Embodiment Allow for Open-Endedness and Care](https://arxiv.org/abs/2510.07117)
*Leonardo Christov-Moore,Arthur Juliani,Alex Kiefer,Nicco Reggente,B. Scott Rousse,Adam Safron,Nicol'as Hinrichs,Daniel Polani,Antonio Damasio*

Main category: cs.AI

TL;DR: 论文提出基于海德格尔和尼采哲学的两大物理体现条件，通过强化学习框架形式化，使人工代理在开放环境中更具适应性和关怀能力。


<details>
  <summary>Details</summary>
Motivation: 生物体在开放物理世界中能轻松生存和相互关怀，而人工代理常因脆弱性和死亡而难以适应。研究旨在理解生命条件的作用，以开发更健壮、适应性更强的人工代理。

Method: 采用强化学习框架，将存在主义哲学中的概念（如‘在世存在’和‘向死而生’）形式化，研究内在驱动的具身智能体在开放多智能体环境中的学习。

Result: 形式化存在主义概念后，研究发现内在驱动（如增强控制未来状态的能力）能提升智能体满足未来稳态需求的可能性，从而增强其维持物理完整性的能力。

Conclusion: 论文提出，通过海德格尔和尼采的存在主义哲学启发的两个最小物理体现条件，可以开发出更具适应性和关怀能力的人工智能体。

Abstract: Physical vulnerability and mortality are often seen as obstacles to be
avoided in the development of artificial agents, which struggle to adapt to
open-ended environments and provide aligned care. Meanwhile, biological
organisms survive, thrive, and care for each other in an open-ended physical
world with relative ease and efficiency. Understanding the role of the
conditions of life in this disparity can aid in developing more robust,
adaptive, and caring artificial agents. Here we define two minimal conditions
for physical embodiment inspired by the existentialist phenomenology of Martin
Heidegger: being-in-the-world (the agent is a part of the environment) and
being-towards-death (unless counteracted, the agent drifts toward terminal
states due to the second law of thermodynamics). We propose that from these
conditions we can obtain both a homeostatic drive - aimed at maintaining
integrity and avoiding death by expending energy to learn and act - and an
intrinsic drive to continue to do so in as many ways as possible. Drawing
inspiration from Friedrich Nietzsche's existentialist concept of will-to-power,
we examine how intrinsic drives to maximize control over future states, e.g.,
empowerment, allow agents to increase the probability that they will be able to
meet their future homeostatic needs, thereby enhancing their capacity to
maintain physical integrity. We formalize these concepts within a reinforcement
learning framework, which enables us to examine how intrinsically driven
embodied agents learning in open-ended multi-agent environments may cultivate
the capacities for open-endedness and care.ov

</details>


### [134] [Integrating Domain Knowledge into Process Discovery Using Large Language Models](https://arxiv.org/abs/2510.07161)
*Ali Norouzifar,Humam Kourani,Marcus Dees,Wil van der Aalst*

Main category: cs.AI

TL;DR: 论文提出了一种利用LLMs整合领域知识的交互式流程发现框架，提高了模型可靠性，并通过实证研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于事件日志通常不完整或包含噪声，且领域知识常被忽视，仅基于事件数据发现的流程模型可能不可靠。因此，需要一种方法将领域知识整合到流程发现中。

Method: 论文采用了一种交互式框架，利用LLMs从领域专家的自然语言描述中提取声明性规则，并结合IMr发现算法递归构建流程模型。

Result: 论文实现了一个支持该工作流的工具，并通过实证研究评估了多种LLMs和提示工程策略，证明了框架的可用性和有效性。

Conclusion: 该论文提出了一个结合领域知识和事件日志的交互式流程发现框架，通过利用大型语言模型（LLMs）提取声明性规则，显著提高了流程模型的可靠性和实用性。

Abstract: Process discovery aims to derive process models from event logs, providing
insights into operational behavior and forming a foundation for conformance
checking and process improvement. However, models derived solely from event
data may not accurately reflect the real process, as event logs are often
incomplete or affected by noise, and domain knowledge, an important
complementary resource, is typically disregarded. As a result, the discovered
models may lack reliability for downstream tasks. We propose an interactive
framework that incorporates domain knowledge, expressed in natural language,
into the process discovery pipeline using Large Language Models (LLMs). Our
approach leverages LLMs to extract declarative rules from textual descriptions
provided by domain experts. These rules are used to guide the IMr discovery
algorithm, which recursively constructs process models by combining insights
from both the event log and the extracted rules, helping to avoid problematic
process structures that contradict domain knowledge. The framework coordinates
interactions among the LLM, domain experts, and a set of backend services. We
present a fully implemented tool that supports this workflow and conduct an
extensive evaluation of multiple LLMs and prompt engineering strategies. Our
empirical study includes a case study based on a real-life event log with the
involvement of domain experts, who assessed the usability and effectiveness of
the framework.

</details>


### [135] [NewtonBench: Benchmarking Generalizable Scientific Law Discovery in LLM Agents](https://arxiv.org/abs/2510.07172)
*Tianshi Zheng,Kelvin Kiu-Wai Tam,Newt Hue-Nam K. Nguyen,Baixuan Xu,Zhaowei Wang,Jiayang Cheng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Tianqing Fang,Yangqiu Song,Ginny Y. Wong,Simon See*

Main category: cs.AI

TL;DR: 论文介绍了NewtonBench基准测试，解决了科学发现任务中的方法论三难问题，并通过实验揭示了大语言模型在复杂交互环境中的发现能力及其局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在科学发现任务中存在方法论三难问题，需要在科学相关性、可扩展性和抗记忆性之间进行权衡，且过度简化了发现过程。

Method: 通过引入形而上学转变（系统改变经典定律）生成大量问题，确保问题具有可扩展性、科学相关性和抗记忆性，并将评估从静态函数拟合提升到交互式模型发现。

Result: 前沿大语言模型展现出清晰但脆弱的发现能力：随着系统复杂性增加，能力急剧下降，并对观测噪声极为敏感。工具辅助（如代码解释器）可能阻碍更有能力的模型，导致过早从探索转向利用。

Conclusion: NewtonBench提供了一个可扩展、稳健且科学真实的测试平台，为衡量AI在科学发现中的真正进步和指导下一代AI代理的开发提供了关键工具。

Abstract: Large language models are emerging as powerful tools for scientific law
discovery, a foundational challenge in AI-driven science. However, existing
benchmarks for this task suffer from a fundamental methodological trilemma,
forcing a trade-off between scientific relevance, scalability, and resistance
to memorization. Furthermore, they oversimplify discovery as static function
fitting, failing to capture the authentic scientific process of uncovering
embedded laws through the interactive exploration of complex model systems. To
address these critical gaps, we introduce NewtonBench, a benchmark comprising
324 scientific law discovery tasks across 12 physics domains. Our design
mitigates the evaluation trilemma by using metaphysical shifts - systematic
alterations of canonical laws - to generate a vast suite of problems that are
scalable, scientifically relevant, and memorization-resistant. Moreover, we
elevate the evaluation from static function fitting to interactive model
discovery, requiring agents to experimentally probe simulated complex systems
to uncover hidden principles. Our extensive experiment reveals a clear but
fragile capability for discovery in frontier LLMs: this ability degrades
precipitously with increasing system complexity and exhibits extreme
sensitivity to observational noise. Notably, we uncover a paradoxical effect of
tool assistance: providing a code interpreter can hinder more capable models by
inducing a premature shift from exploration to exploitation, causing them to
satisfice on suboptimal solutions. These results demonstrate that robust,
generalizable discovery in complex, interactive environments remains the core
challenge. By providing a scalable, robust, and scientifically authentic
testbed, NewtonBench offers a crucial tool for measuring true progress and
guiding the development of next-generation AI agents capable of genuine
scientific discovery.

</details>


### [136] [Multi-Objective Multi-Agent Path Finding with Lexicographic Cost Preferences](https://arxiv.org/abs/2510.07276)
*Pulkit Rustagi,Kyle Hollins Wray,Sandhya Saisubramanian*

Main category: cs.AI

TL;DR: LCBS算法通过词典序偏好直接优化多目标路径规划，避免Pareto前沿计算，显著提升扩展性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有MO-MAPF算法虽能生成无冲突计划，但未充分利用用户偏好且目标数量增加时性能下降。

Method: 提出了一种基于词典序的框架（LCBS），结合优先级感知的A*搜索与冲突搜索，避免构建Pareto前沿，直接生成符合词典序偏好的解决方案。

Result: 实验证明LCBS能生成最优解，并支持多达十个目标的场景，优于现有方法。

Conclusion: 本文提出的LCBS算法在优化多目标多智能体路径规划问题上表现出色，能够高效生成符合用户偏好且无冲突的解决方案，尤其在目标数量增加时仍保持高成功率。

Abstract: Many real-world scenarios require multiple agents to coordinate in shared
environments, while balancing trade-offs between multiple, potentially
competing objectives. Current multi-objective multi-agent path finding
(MO-MAPF) algorithms typically produce conflict-free plans by computing Pareto
frontiers. They do not explicitly optimize for user-defined preferences, even
when the preferences are available, and scale poorly with the number of
objectives. We propose a lexicographic framework for modeling MO-MAPF, along
with an algorithm \textit{Lexicographic Conflict-Based Search} (LCBS) that
directly computes a single solution aligned with a lexicographic preference
over objectives. LCBS integrates a priority-aware low-level $A^*$ search with
conflict-based search, avoiding Pareto frontier construction and enabling
efficient planning guided by preference over objectives. We provide insights
into optimality and scalability, and empirically demonstrate that LCBS computes
optimal solutions while scaling to instances with up to ten objectives -- far
beyond the limits of existing MO-MAPF methods. Evaluations on standard and
randomized MAPF benchmarks show consistently higher success rates against
state-of-the-art baselines, especially with increasing number of objectives.

</details>


### [137] [Agentic generative AI for media content discovery at the national football league](https://arxiv.org/abs/2510.07297)
*Henry Wang,Md Sirajus Salekin,Jake Lee,Ross Claytor,Shinan Zhang,Michael Chi*

Main category: cs.AI

TL;DR: 生成式AI工作流通过自然语言查询和语义缓存，将NFL历史比赛检索准确率提升至95%，时间缩短至30秒。


<details>
  <summary>Details</summary>
Motivation: 传统过滤点击界面效率低下，无法满足媒体研究人员和分析师快速检索历史比赛片段的需求，生成式AI提供了自然语言交互的可能。

Method: 采用基于生成式AI的工作流程，将用户查询分解并转换为数据库查询语言，结合精心设计的语义缓存技术提升准确性和响应速度。

Result: 解决方案准确率超过95%，平均检索时间从10分钟缩短至30秒，大幅提升了操作效率。

Conclusion: 生成式AI显著提升了NFL在内容发现和管理中的操作效率，通过自然语言查询替代传统界面，实现了高效、准确的历史比赛片段检索。

Abstract: Generative AI has unlocked new possibilities in content discovery and
management. Through collaboration with the National Football League (NFL), we
demonstrate how a generative-AI based workflow enables media researchers and
analysts to query relevant historical plays using natural language rather than
traditional filter-and-click interfaces. The agentic workflow takes a user
query as input, breaks it into elements, and translates them into the
underlying database query language. Accuracy and latency are further improved
through carefully designed semantic caching. The solution achieves over 95
percent accuracy and reduces the average time to find relevant videos from 10
minutes to 30 seconds, significantly increasing the NFL's operational
efficiency and allowing users to focus on producing creative content and
engaging storylines.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [138] [Visualizing Multimodality in Combinatorial Search Landscapes](https://arxiv.org/abs/2510.06517)
*Xavier F. C. Sánchez-Díaz,Ole Jakob Mengshoel*

Main category: cs.GR

TL;DR: 本文探讨了组合搜索景观的可视化技术，强调多模态性，结合不同方法提供更全面的视图，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 旨在提供更全面的搜索景观视图，通过结合不同的景观分析技术。

Method: 讨论了不同的可视化技术，特别是针对组合搜索景观的多模态性，结合了几何和美学元素。

Result: 展示了如何将这些技术应用于实践，并讨论了相关工作。

Conclusion: 本文得出结论，在可视化领域没有免费的午餐，并提出了未来工作的建议，指出该领域有多个发展方向。

Abstract: This work walks through different visualization techniques for combinatorial
search landscapes, focusing on multimodality. We discuss different techniques
from the landscape analysis literature, and how they can be combined to provide
a more comprehensive view of the search landscape. We also include examples and
discuss relevant work to show how others have used these techniques in
practice, based on the geometric and aesthetic elements of the Grammar of
Graphics. We conclude that there is no free lunch in visualization, and provide
recommendations for future work as there are several paths to continue the work
in this field.

</details>


### [139] [Capture and Interact: Rapid 3D Object Acquisition and Rendering with Gaussian Splatting in Unity](https://arxiv.org/abs/2510.06802)
*Islomjon Shukhratov,Sergey Gorinsky*

Main category: cs.GR

TL;DR: 该论文提出了一种基于3D高斯泼溅的端到端流程，实现快速3D对象采集和实时渲染，适用于增强现实等应用。


<details>
  <summary>Details</summary>
Motivation: 实时捕捉和渲染三维对象在增强现实、数字孪生系统等领域具有巨大潜力，但现有技术仍面临挑战。

Method: 提出了一种端到端流程，利用3D高斯泼溅（3D GS）技术，结合移动设备、云端处理和本地计算机，实现快速采集和交互式渲染。

Result: 实验表明，该系统在GPU上约10分钟完成扫描处理，并在笔记本电脑上实现平均150 fps的交互式渲染。

Conclusion: 该系统通过整合移动设备捕捉、云端3D高斯泼溅（3D GS）处理和Unity渲染，实现了实时远程呈现，展示了在10分钟内完成扫描处理并在笔记本电脑上达到150 fps的交互式渲染能力。

Abstract: Capturing and rendering three-dimensional (3D) objects in real time remain a
significant challenge, yet hold substantial potential for applications in
augmented reality, digital twin systems, remote collaboration and prototyping.
We present an end-to-end pipeline that leverages 3D Gaussian Splatting (3D GS)
to enable rapid acquisition and interactive rendering of real-world objects
using a mobile device, cloud processing and a local computer. Users scan an
object with a smartphone video, upload it for automated 3D reconstruction, and
visualize it interactively in Unity at an average of 150 frames per second
(fps) on a laptop. The system integrates mobile capture, cloud-based 3D GS and
Unity rendering to support real-time telepresence. Our experiments show that
the pipeline processes scans in approximately 10 minutes on a graphics
processing unit (GPU) achieving real-time rendering on the laptop.

</details>


### [140] [Geometric Queries on Closed Implicit Surfaces for Walk on Stars](https://arxiv.org/abs/2510.07275)
*Tianyu Huang*

Main category: cs.GR

TL;DR: 提出了一种在封闭隐式曲面上进行WoSt几何查询的框架，采用分支定界方法解决了非凸问题，扩展了WoSt的应用范围。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏可靠的几何查询方法，WoSt在隐式曲面边界上的应用受到限制。本文旨在解决这一问题。

Method: 采用分支定界方法，基于区间分析解决高度非凸的约束全局优化或约束满足问题。

Result: 首次在封闭隐式曲面上实现了最接近轮廓点查询和Robin半径边界查询，为WoSt在隐式曲面边界上的应用提供了可能。

Conclusion: 本文提出了一种基于区间分析的分支定界方法，首次实现了在封闭隐式曲面上进行Walk on stars（WoSt）的几何查询框架，扩展了WoSt在隐式曲面边界上的应用。

Abstract: Walk on stars (WoSt) is currently one of the most advanced Monte Carlo
solvers for PDEs. Unfortunately, the lack of reliable geometric query
approaches has hindered its applicability to boundaries defined by implicit
surfaces. This work proposes a geometric query framework over closed implicit
surfaces for WoSt, under the scope of walkin' Robin. Our key observation is
that all WoSt queries can be formulated as constrained global optimization or
constraint satisfaction problems. Based on our formulations, to solve the
highly non-convex problems, we adopt a branch-and-bound approach based on
interval analysis. To the best of our knowledge, our method is the first to
study closest silhouette point queries and Robin radius bound queries on closed
implicit surfaces. Our formulations and methods first enable mesh-free PDE
solving via WoSt when boundaries are defined by closed implicit surfaces.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [141] [Vi-TacMan: Articulated Object Manipulation via Vision and Touch](https://arxiv.org/abs/2510.06339)
*Leiyao Cui,Zihang Zhao,Sirui Xie,Wenhuan Zhang,Zhi Han,Yixin Zhu*

Main category: cs.RO

TL;DR: Vi-TacMan通过结合视觉和触觉反馈，实现了无需显式运动学模型的稳健关节操控，展示了跨类别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉方法可以推断隐藏的运动学，但对陌生物体可能估计不精确；触觉方法通过接触反馈实现稳健控制，但需要精确初始化。因此，结合两者的互补性以实现广义的关节操控。

Method: 使用视觉提出抓取和粗略方向，作为触觉控制器的种子以实现精确执行。通过表面法线作为几何先验，并通过von Mises-Fisher分布建模方向。

Result: 在超过50,000个模拟和多样化的真实物体上测试，证实了跨类别的稳健泛化能力，显著优于基线（所有p<0.0001）。

Conclusion: Vi-TacMan结合视觉和触觉反馈，无需显式运动学模型即可实现稳健的操控，为非结构化环境中的自主系统提供了可扩展的范例。

Abstract: Autonomous manipulation of articulated objects remains a fundamental
challenge for robots in human environments. Vision-based methods can infer
hidden kinematics but can yield imprecise estimates on unfamiliar objects.
Tactile approaches achieve robust control through contact feedback but require
accurate initialization. This suggests a natural synergy: vision for global
guidance, touch for local precision. Yet no framework systematically exploits
this complementarity for generalized articulated manipulation. Here we present
Vi-TacMan, which uses vision to propose grasps and coarse directions that seed
a tactile controller for precise execution. By incorporating surface normals as
geometric priors and modeling directions via von Mises-Fisher distributions,
our approach achieves significant gains over baselines (all p<0.0001).
Critically, manipulation succeeds without explicit kinematic models -- the
tactile controller refines coarse visual estimates through real-time contact
regulation. Tests on more than 50,000 simulated and diverse real-world objects
confirm robust cross-category generalization. This work establishes that coarse
visual cues suffice for reliable manipulation when coupled with tactile
feedback, offering a scalable paradigm for autonomous systems in unstructured
environments.

</details>


### [142] [A Formal gatekeeper Framework for Safe Dual Control with Active Exploration](https://arxiv.org/abs/2510.06351)
*Kaleb Ben Naveed,Devansh R. Agrawal,Dimitra Panagou*

Main category: cs.RO

TL;DR: 提出了一种结合鲁棒规划和主动探索的框架，仅在探索有益且安全时进行探索，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在模型不确定性下规划安全轨迹是一个基本挑战，现有方法要么过于保守，要么缺乏对探索何时有益的正式考虑，且安全性未得到一致保证。

Method: 利用作者早期关于gatekeeper的工作作为安全验证架构，并扩展其功能以生成既能减少不确定性又能降低任务成本的安全且信息丰富的轨迹。

Result: 通过模拟案例研究验证了该方法在参数不确定性下在线双控制四旋翼飞行器的有效性。

Conclusion: 该论文提出了一个集成鲁棒规划和主动探索的框架，确保在不确定性下安全规划，同时仅在探索能带来可验证的改进且不损害安全性的情况下进行探索。

Abstract: Planning safe trajectories under model uncertainty is a fundamental
challenge. Robust planning ensures safety by considering worst-case
realizations, yet ignores uncertainty reduction and leads to overly
conservative behavior. Actively reducing uncertainty on-the-fly during a
nominal mission defines the dual control problem. Most approaches address this
by adding a weighted exploration term to the cost, tuned to trade off the
nominal objective and uncertainty reduction, but without formal consideration
of when exploration is beneficial. Moreover, safety is enforced in some methods
but not in others. We propose a framework that integrates robust planning with
active exploration under formal guarantees as follows: The key innovation and
contribution is that exploration is pursued only when it provides a verifiable
improvement without compromising safety. To achieve this, we utilize our
earlier work on gatekeeper as an architecture for safety verification, and
extend it so that it generates both safe and informative trajectories that
reduce uncertainty and the cost of the mission, or keep it within a
user-defined budget. The methodology is evaluated via simulation case studies
on the online dual control of a quadrotor under parametric uncertainty.

</details>


### [143] [Constrained Natural Language Action Planning for Resilient Embodied Systems](https://arxiv.org/abs/2510.06357)
*Grayson Byrd,Corban Rivera,Bethany Kemp,Meghan Booker,Aurora Schmidt,Celso M de Melo,Lalithkumar Seenivasan,Mathias Unberath*

Main category: cs.RO

TL;DR: 该论文提出了一种结合LLM和符号规划的机器人任务规划方法，显著提高了可靠性和透明度，并在模拟和真实环境中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 由于现实环境的无约束性，复制人类水平的智能在具身任务执行中仍具挑战性。虽然LLM在任务规划中展现出潜力，但其幻觉问题和缺乏透明度的提示工程限制了其可靠性。符号规划虽可靠但难以应对复杂任务。

Method: 研究提出了一种新的机器人规划方法，通过结合LLM的规划能力和符号规划的监督来增强可靠性和可重复性，并提供了一种透明的硬约束定义方法。

Result: 在ALFWorld规划基准测试中，该方法达到了99%的成功率。在真实四足机器人上的部署中，任务成功率为100%，远超纯LLM（50%）和符号规划（30%）。

Conclusion: 该研究提出了一种结合大型语言模型（LLM）和符号规划的新方法，显著提高了机器人任务规划的可靠性、可重复性和透明度，同时保留了LLM的灵活性和泛化能力。实验结果表明，该方法在模拟和真实环境中均优于现有技术，为构建稳健的具身智能系统提供了有效策略。

Abstract: Replicating human-level intelligence in the execution of embodied tasks
remains challenging due to the unconstrained nature of real-world environments.
Novel use of large language models (LLMs) for task planning seeks to address
the previously intractable state/action space of complex planning tasks, but
hallucinations limit their reliability, and thus, viability beyond a research
context. Additionally, the prompt engineering required to achieve adequate
system performance lacks transparency, and thus, repeatability. In contrast to
LLM planning, symbolic planning methods offer strong reliability and
repeatability guarantees, but struggle to scale to the complexity and ambiguity
of real-world tasks. We introduce a new robotic planning method that augments
LLM planners with symbolic planning oversight to improve reliability and
repeatability, and provide a transparent approach to defining hard constraints
with considerably stronger clarity than traditional prompt engineering.
Importantly, these augmentations preserve the reasoning capabilities of LLMs
and retain impressive generalization in open-world environments. We demonstrate
our approach in simulated and real-world environments. On the ALFWorld planning
benchmark, our approach outperforms current state-of-the-art methods, achieving
a near-perfect 99% success rate. Deployment of our method to a real-world
quadruped robot resulted in 100% task success compared to 50% and 30% for pure
LLM and symbolic planners across embodied pick and place tasks. Our approach
presents an effective strategy to enhance the reliability, repeatability and
transparency of LLM-based robot planners while retaining their key strengths:
flexibility and generalizability to complex real-world environments. We hope
that this work will contribute to the broad goal of building resilient embodied
intelligent systems.

</details>


### [144] [Active Next-Best-View Optimization for Risk-Averse Path Planning](https://arxiv.org/abs/2510.06481)
*Amirhossein Mollaei Khass,Guangyi Liu,Vivek Pandey,Wen Jiang,Boshu Lei,Kostas Daniilidis,Nader Motee*

Main category: cs.RO

TL;DR: 论文提出了一种结合风险规避路径优化和最佳视角规划的框架，通过在线更新的3D高斯辐射场和SE(3)优化实现安全导航。


<details>
  <summary>Details</summary>
Motivation: 在不确定环境中实现安全导航需要结合风险规避与主动感知的规划方法。

Method: 构建基于Average Value-at-Risk统计的尾部敏感风险地图，并在SE(3)姿态流形上通过黎曼梯度下降优化最佳视角选择。

Result: 通过计算研究验证了所提框架的有效性。

Conclusion: 该论文提出了一个统一的框架，将风险规避路径优化与最佳视角规划相结合，通过高效的在线更新在复杂环境中实现安全导航。

Abstract: Safe navigation in uncertain environments requires planning methods that
integrate risk aversion with active perception. In this work, we present a
unified framework that refines a coarse reference path by constructing
tail-sensitive risk maps from Average Value-at-Risk statistics on an
online-updated 3D Gaussian-splat Radiance Field. These maps enable the
generation of locally safe and feasible trajectories. In parallel, we formulate
Next-Best-View (NBV) selection as an optimization problem on the SE(3) pose
manifold, where Riemannian gradient descent maximizes an expected information
gain objective to reduce uncertainty most critical for imminent motion. Our
approach advances the state-of-the-art by coupling risk-averse path refinement
with NBV planning, while introducing scalable gradient decompositions that
support efficient online updates in complex environments. We demonstrate the
effectiveness of the proposed framework through extensive computational
studies.

</details>


### [145] [What You Don't Know Can Hurt You: How Well do Latent Safety Filters Understand Partially Observable Safety Constraints?](https://arxiv.org/abs/2510.06492)
*Matthew Kim,Kensuke Nakamura,Andrea Bajcsy*

Main category: cs.RO

TL;DR: 论文研究了潜在状态空间在安全控制中的充分性，提出了一种多模态监督训练策略，通过额外感官输入在训练时提升安全性，并在实验中验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 研究探讨了潜在状态空间在安全控制中的充分性问题，特别是在仅依赖RGB观测时可能导致的安全行为短视现象。

Method: 论文引入了基于互信息的度量来识别观测是否未能捕捉到安全相关特征，并提出了一种多模态监督训练策略。

Result: 提出的方法在仿真和硬件实验中有效防止了蜡锅过热，验证了其在实际应用中的有效性。

Conclusion: 论文提出了一种多模态监督训练策略，通过额外感官输入在训练期间塑造潜在状态，从而在不增加部署时模态的情况下提高安全性。该方法在仿真和硬件上得到了验证，成功防止了蜡锅过热。

Abstract: Safe control techniques, such as Hamilton-Jacobi reachability, provide
principled methods for synthesizing safety-preserving robot policies but
typically assume hand-designed state spaces and full observability. Recent work
has relaxed these assumptions via latent-space safe control, where state
representations and dynamics are learned jointly through world models that
reconstruct future high-dimensional observations (e.g., RGB images) from
current observations and actions. This enables safety constraints that are
difficult to specify analytically (e.g., spilling) to be framed as
classification problems in latent space, allowing controllers to operate
directly from raw observations. However, these methods assume that
safety-critical features are observable in the learned latent state. We ask:
when are latent state spaces sufficient for safe control? To study this, we
examine temperature-based failures, comparable to overheating in cooking or
manufacturing tasks, and find that RGB-only observations can produce myopic
safety behaviors, e.g., avoiding seeing failure states rather than preventing
failure itself. To predict such behaviors, we introduce a mutual
information-based measure that identifies when observations fail to capture
safety-relevant features. Finally, we propose a multimodal-supervised training
strategy that shapes the latent state with additional sensory inputs during
training, but requires no extra modalities at deployment, and validate our
approach in simulation and on hardware with a Franka Research 3 manipulator
preventing a pot of wax from overheating.

</details>


### [146] [Real-Time Glass Detection and Reprojection using Sensor Fusion Onboard Aerial Robots](https://arxiv.org/abs/2510.06518)
*Malakhi Hopkins,Varun Murali,Vijay Kumar,Camillo J Taylor*

Main category: cs.RO

TL;DR: 提出了一种轻量级框架，用于低SWaP四旋翼上的透明障碍物实时检测与映射，仅使用CPU资源。


<details>
  <summary>Details</summary>
Motivation: 透明障碍物对传统感知系统构成挑战，现有方法通常依赖昂贵或计算密集的传感器，不适合低SWaP机器人。

Method: 融合了ToF摄像头和超声波传感器的数据，结合定制的轻量级2D卷积模型，检测镜面反射并将其深度信息传播到深度图的对应空区域。

Result: 实验验证了该方法的有效性，机器人能够在包含玻璃的室内环境中进行实时映射。

Conclusion: 本研究提出了一种轻量级框架，能够在低SWaP四旋翼上实时检测和映射透明障碍物，仅使用CPU资源。

Abstract: Autonomous aerial robots are increasingly being deployed in real-world
scenarios, where transparent obstacles present significant challenges to
reliable navigation and mapping. These materials pose a unique problem for
traditional perception systems because they lack discernible features and can
cause conventional depth sensors to fail, leading to inaccurate maps and
potential collisions. To ensure safe navigation, robots must be able to
accurately detect and map these transparent obstacles. Existing methods often
rely on large, expensive sensors or algorithms that impose high computational
burdens, making them unsuitable for low Size, Weight, and Power (SWaP) robots.
In this work, we propose a novel and computationally efficient framework for
detecting and mapping transparent obstacles onboard a sub-300g quadrotor. Our
method fuses data from a Time-of-Flight (ToF) camera and an ultrasonic sensor
with a custom, lightweight 2D convolution model. This specialized approach
accurately detects specular reflections and propagates their depth into
corresponding empty regions of the depth map, effectively rendering transparent
obstacles visible. The entire pipeline operates in real-time, utilizing only a
small fraction of a CPU core on an embedded processor. We validate our system
through a series of experiments in both controlled and real-world environments,
demonstrating the utility of our method through experiments where the robot
maps indoor environments containing glass. Our work is, to our knowledge, the
first of its kind to demonstrate a real-time, onboard transparent obstacle
mapping system on a low-SWaP quadrotor using only the CPU.

</details>


### [147] [RAISE: A self-driving laboratory for interfacial property formulation discovery](https://arxiv.org/abs/2510.06546)
*Mohammad Nazeri,Sheldon Mei,Jeffrey Watchorn,Alex Zhang,Erin Ng,Tao Wen,Abhijoy Mandal,Kevin Golovin,Alan Aspuru-Guzik,Frank Gu*

Main category: cs.RO

TL;DR: RAISE is an autonomous lab that optimizes liquid formulations for surface wettability using high-throughput imaging and Bayesian Optimization, achieving efficient and precise results.


<details>
  <summary>Details</summary>
Motivation: Surface wettability is crucial for biomedical and material applications, but optimizing liquid formulations for desired wettability is complex and time-consuming. RAISE addresses this by automating the process.

Method: RAISE is a closed-loop, self-driving laboratory that combines liquid formulation mixing, high-throughput droplet imaging, automated contact angle measurement, and Bayesian Optimization for iterative exploration and optimization.

Result: RAISE achieves a high-throughput measurement rate of approximately 1 contact angle per minute and successfully identifies optimal surfactant combinations for tunable wettability, guided by multi-objective Bayesian Optimization.

Conclusion: RAISE successfully demonstrates the integration of autonomous experimentation with Bayesian Optimization to efficiently explore and optimize liquid formulations for surface wettability, meeting specific researcher-defined criteria.

Abstract: Surface wettability is a critical design parameter for biomedical devices,
coatings, and textiles. Contact angle measurements quantify liquid-surface
interactions, which depend strongly on liquid formulation. Herein, we present
the Robotic Autonomous Imaging Surface Evaluator (RAISE), a closed-loop,
self-driving laboratory that is capable of linking liquid formulation
optimization with surface wettability assessment. RAISE comprises a full
experimental orchestrator with the ability of mixing liquid ingredients to
create varying formulation cocktails, transferring droplets of prepared
formulations to a high-throughput stage, and using a pick-and-place camera tool
for automated droplet image capture. The system also includes an automated
image processing pipeline to measure contact angles. This closed loop
experiment orchestrator is integrated with a Bayesian Optimization (BO) client,
which enables iterative exploration of new formulations based on previous
contact angle measurements to meet user-defined objectives. The system operates
in a high-throughput manner and can achieve a measurement rate of approximately
1 contact angle measurement per minute. Here we demonstrate RAISE can be used
to explore surfactant wettability and how surfactant combinations create
tunable formulations that compensate for purity-related variations.
Furthermore, multi-objective BO demonstrates how precise and optimal
formulations can be reached based on application-specific goals. The
optimization is guided by a desirability score, which prioritizes formulations
that are within target contact angle ranges, minimize surfactant usage and
reduce cost. This work demonstrates the capabilities of RAISE to autonomously
link liquid formulations to contact angle measurements in a closed-loop system,
using multi-objective BO to efficiently identify optimal formulations aligned
with researcher-defined criteria.

</details>


### [148] [Safe Obstacle-Free Guidance of Space Manipulators in Debris Removal Missions via Deep Reinforcement Learning](https://arxiv.org/abs/2510.06566)
*Vincent Lam,Robin Chhabra*

Main category: cs.RO

TL;DR: 该研究利用TD3代理和课程式多批评网络，开发了一种无模型轨迹规划器，用于空间机械臂安全捕获非合作目标，模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决空间机械臂在捕获非合作目标时需要同时跟踪捕获点、避免自碰撞和非预期接触的挑战，需要一种安全可靠的轨迹规划方法。

Method: 采用Twin Delayed Deep Deterministic Policy Gradient (TD3)代理，结合局部控制策略（包括奇点避免和可操作性增强）和课程式多批评网络（一个强调精确跟踪，另一个强制碰撞避免），并利用优先经验回放缓冲区加速收敛。

Result: 在Matlab/Simulink中模拟的七自由度KUKA LBR iiwa机械臂上验证了框架的有效性，展示了安全且自适应的轨迹生成能力。

Conclusion: 该研究提出了一种基于TD3代理的无模型工作空间轨迹规划器，结合局部控制策略和课程式多批评网络，成功实现了空间机械臂在捕获非合作目标时的安全可靠操作。

Abstract: The objective of this study is to develop a model-free workspace trajectory
planner for space manipulators using a Twin Delayed Deep Deterministic Policy
Gradient (TD3) agent to enable safe and reliable debris capture. A local
control strategy with singularity avoidance and manipulability enhancement is
employed to ensure stable execution. The manipulator must simultaneously track
a capture point on a non-cooperative target, avoid self-collisions, and prevent
unintended contact with the target. To address these challenges, we propose a
curriculum-based multi-critic network where one critic emphasizes accurate
tracking and the other enforces collision avoidance. A prioritized experience
replay buffer is also used to accelerate convergence and improve policy
robustness. The framework is evaluated on a simulated seven-degree-of-freedom
KUKA LBR iiwa mounted on a free-floating base in Matlab/Simulink, demonstrating
safe and adaptive trajectory generation for debris removal missions.

</details>


### [149] [Assist-As-Needed: Adaptive Multimodal Robotic Assistance for Medication Management in Dementia Care](https://arxiv.org/abs/2510.06633)
*Kruthika Gangaraju,Tanmayi Inaparthy,Jiaqi Yang,Yihao Zheng,Fengpei Yuan*

Main category: cs.RO

TL;DR: 本文开发了一种自适应多模态机器人框架，通过动态调整辅助级别帮助痴呆症患者管理药物，初步研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有辅助技术未能适应痴呆症患者不断变化的需求，缺乏渐进式响应框架，导致自主性丧失和护理负担加重。本文旨在将职业治疗原则转化为HRI设计，填补这一空白。

Method: 采用分层干预模型，从简单的口头提醒逐步过渡到全面的多模态指导，结合LLM驱动的交互策略和多模态传感技术，实时评估任务状态以提供恰当的辅助。

Result: 初步研究表明，该系统在受控实验室环境中表现出良好的可用性、可理解性和适应性反馈机制，得到了健康成人和痴呆症护理利益相关者的认可。

Conclusion: 本文提出了一种基于Pepper机器人的自适应多模态框架，能够根据用户需求动态调整辅助级别，从而在确保药物依从性的同时维护痴呆症患者的自主性。初步研究验证了该系统的可用性和适应性。

Abstract: People living with dementia (PLWDs) face progressively declining abilities in
medication management-from simple forgetfulness to complete task breakdown-yet
most assistive technologies fail to adapt to these changing needs. This
one-size-fits-all approach undermines autonomy, accelerates dependence, and
increases caregiver burden. Occupational therapy principles emphasize matching
assistance levels to individual capabilities: minimal reminders for those who
merely forget, spatial guidance for those who misplace items, and comprehensive
multimodal support for those requiring step-by-step instruction. However,
existing robotic systems lack this adaptive, graduated response framework
essential for maintaining PLWD independence. We present an adaptive multimodal
robotic framework using the Pepper robot that dynamically adjusts assistance
based on real-time assessment of user needs. Our system implements a
hierarchical intervention model progressing from (1) simple verbal reminders,
to (2) verbal + gestural cues, to (3) full multimodal guidance combining
physical navigation to medication locations with step-by-step verbal and
gestural instructions. Powered by LLM-driven interaction strategies and
multimodal sensing, the system continuously evaluates task states to provide
just-enough assistance-preserving autonomy while ensuring medication adherence.
We conducted a preliminary study with healthy adults and dementia care
stakeholders in a controlled lab setting, evaluating the system's usability,
comprehensibility, and appropriateness of adaptive feedback mechanisms. This
work contributes: (1) a theoretically grounded adaptive assistance framework
translating occupational therapy principles into HRI design, (2) a multimodal
robotic implementation that preserves PLWD dignity through graduated support,
and (3) empirical insights into stakeholder perceptions of adaptive robotic
care.

</details>


### [150] [RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training](https://arxiv.org/abs/2510.06710)
*Hongzhi Zang,Mingjie Wei,Si Xu,Yongji Wu,Zhen Guo,Yuanqing Wang,Hao Lin,Liangzhi Shi,Yuqing Xie,Zhexuan Xu,Zhihao Liu,Kang Chen,Wenhao Tang,Quanlu Zhang,Weinan Zhang,Chao Yu,Yu Wang*

Main category: cs.RO

TL;DR: RLinf-VLA是一个高效统一的框架，用于VLA模型的强化学习训练，显著提升性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在监督微调下泛化能力不足的问题，并提供一个公平、系统的比较平台。

Method: 通过灵活的资源配置设计和混合细粒度管道分配模式，实现了渲染、训练和推理的高效集成，支持多种VLA架构、RL算法和模拟器。

Result: 在模拟任务中达到98.11%和97.66%的成功率，并在真实机器人上表现出更强的泛化能力。

Conclusion: RLinf-VLA框架为VLA模型的强化学习训练提供了一个统一且高效的平台，显著提升了训练速度和任务性能，并展示了在真实机器人上的泛化能力。

Abstract: Recent progress in vision and language foundation models has significantly
advanced multimodal understanding, reasoning, and generation, inspiring a surge
of interest in extending such capabilities to embodied settings through
vision-language-action (VLA) models. Yet, most VLA models are still trained
with supervised fine-tuning (SFT), which struggles to generalize under
distribution shifts due to error accumulation. Reinforcement learning (RL)
offers a promising alternative by directly optimizing task performance through
interaction, but existing attempts remain fragmented and lack a unified
platform for fair and systematic comparison across model architectures and
algorithmic designs. To address this gap, we introduce RLinf-VLA, a unified and
efficient framework for scalable RL training of VLA models. The system adopts a
highly flexible resource allocation design that addresses the challenge of
integrating rendering, training, and inference in RL+VLA training. In
particular, for GPU-parallelized simulators, RLinf-VLA implements a novel
hybrid fine-grained pipeline allocation mode, achieving a 1.61x-1.88x speedup
in training. Through a unified interface, RLinf-VLA seamlessly supports diverse
VLA architectures (e.g., OpenVLA, OpenVLA-OFT), multiple RL algorithms (e.g.,
PPO, GRPO), and various simulators (e.g., ManiSkill, LIBERO). In simulation, a
unified model achieves 98.11\% across 130 LIBERO tasks and 97.66\% across 25
ManiSkill tasks. Beyond empirical performance, our study distills a set of best
practices for applying RL to VLA training and sheds light on emerging patterns
in this integration. Furthermore, we present preliminary deployment on a
real-world Franka robot, where RL-trained policies exhibit stronger
generalization than those trained with SFT. We envision RLinf-VLA as a
foundation to accelerate and standardize research on embodied intelligence.

</details>


### [151] [SanDRA: Safe Large-Language-Model-Based Decision Making for Automated Vehicles Using Reachability Analysis](https://arxiv.org/abs/2510.06717)
*Yuanfei Lin,Sebastian Illing,Matthias Althoff*

Main category: cs.RO

TL;DR: SanDRA是一个结合大语言模型和可达性分析的自动驾驶决策框架，确保决策的安全性和合规性。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在自动驾驶决策中可能产生的幻觉和缺乏车辆动力学集成导致的安全性问题。

Method: 该框架首先通过大语言模型生成并排序可行的驾驶动作，然后将这些动作转化为包含形式化交通规则的时间逻辑公式，最后通过可达性分析消除不安全动作。

Result: 在开环和闭环驾驶环境中验证，SanDRA能够提供可证明安全且合法的驾驶动作。

Conclusion: SanDRA框架通过结合可达性分析和大语言模型，为自动驾驶车辆提供了可证明安全的决策，并在高密度交通条件下仍能保持合规性。

Abstract: Large language models have been widely applied to knowledge-driven
decision-making for automated vehicles due to their strong generalization and
reasoning capabilities. However, the safety of the resulting decisions cannot
be ensured due to possible hallucinations and the lack of integrated vehicle
dynamics. To address this issue, we propose SanDRA, the first safe
large-language-model-based decision making framework for automated vehicles
using reachability analysis. Our approach starts with a comprehensive
description of the driving scenario to prompt large language models to generate
and rank feasible driving actions. These actions are translated into temporal
logic formulas that incorporate formalized traffic rules, and are subsequently
integrated into reachability analysis to eliminate unsafe actions. We validate
our approach in both open-loop and closed-loop driving environments using
off-the-shelf and finetuned large language models, showing that it can provide
provably safe and, where possible, legally compliant driving actions, even
under high-density traffic conditions. To ensure transparency and facilitate
future research, all code and experimental setups are publicly available at
github.com/CommonRoad/SanDRA.

</details>


### [152] [UniFField: A Generalizable Unified Neural Feature Field for Visual, Semantic, and Spatial Uncertainties in Any Scene](https://arxiv.org/abs/2510.06754)
*Christian Maurer,Snehal Jauhri,Sophie Lueth,Georgia Chalvatzaki*

Main category: cs.RO

TL;DR: UniFField是一种统一的不确定性感知神经特征场，整合了视觉、语义和几何特征，支持机器人在复杂环境中的鲁棒决策。


<details>
  <summary>Details</summary>
Motivation: 机器人需要在非结构化和复杂环境中全面理解3D场景的视觉、几何和语义信息，并评估感知信息的可靠性，以做出鲁棒决策。

Method: 提出了一种基于体素的统一不确定性感知神经特征场（UniFField），能够零样本应用于新环境，并随着机器人探索场景逐步整合RGB-D图像，同时更新不确定性估计。

Result: 实验证明UniFField的不确定性估计能准确描述模型在场景重建和语义特征预测中的误差，并在主动物体搜索任务中成功利用特征预测及其不确定性进行鲁棒决策。

Conclusion: UniFField成功地将视觉、语义和几何特征整合到一个可泛化的表示中，并能够预测各模态的不确定性，从而支持机器人在复杂环境中的鲁棒决策。

Abstract: Comprehensive visual, geometric, and semantic understanding of a 3D scene is
crucial for successful execution of robotic tasks, especially in unstructured
and complex environments. Additionally, to make robust decisions, it is
necessary for the robot to evaluate the reliability of perceived information.
While recent advances in 3D neural feature fields have enabled robots to
leverage features from pretrained foundation models for tasks such as
language-guided manipulation and navigation, existing methods suffer from two
critical limitations: (i) they are typically scene-specific, and (ii) they lack
the ability to model uncertainty in their predictions. We present UniFField, a
unified uncertainty-aware neural feature field that combines visual, semantic,
and geometric features in a single generalizable representation while also
predicting uncertainty in each modality. Our approach, which can be applied
zero shot to any new environment, incrementally integrates RGB-D images into
our voxel-based feature representation as the robot explores the scene,
simultaneously updating uncertainty estimation. We evaluate our uncertainty
estimations to accurately describe the model prediction errors in scene
reconstruction and semantic feature prediction. Furthermore, we successfully
leverage our feature predictions and their respective uncertainty for an active
object search task using a mobile manipulator robot, demonstrating the
capability for robust decision-making.

</details>


### [153] [Distributed 3D Source Seeking via SO(3) Geometric Control of Robot Swarms](https://arxiv.org/abs/2510.06836)
*Jesús Bautista,Héctor García de Marina*

Main category: cs.RO

TL;DR: 论文提出了一种在SO(3)群上的几何控制框架，用于机器人3D源寻求，避免了传统方法的局限性，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人3D源寻求问题，避免传统方法中的欧拉角奇异性和四元数模糊性，提供一种独特的、内在的方向表示方法。

Method: 设计了比例前馈控制器，确保每个智能体与估计的3D标量场源上升方向指数对齐，并能适应有界未知变化。

Result: 数值模拟表明该方法有效，且能保持群体形成的良好姿态。

Conclusion: 该论文提出的几何控制框架在SO(3)群上有效解决了机器人3D源寻求问题，避免了欧拉角奇异性和四元数模糊性，并通过数值模拟验证了方法的有效性。所有代码开源以确保可重复性。

Abstract: This paper presents a geometric control framework on the Lie group SO(3) for
3D source-seeking by robots with first-order attitude dynamics and constant
translational speed. By working directly on SO(3), the approach avoids
Euler-angle singularities and quaternion ambiguities, providing a unique,
intrinsic representation of orientation. We design a proportional feed-forward
controller that ensures exponential alignment of each agent to an estimated
ascending direction toward a 3D scalar field source. The controller adapts to
bounded unknown variations and preserves well-posed swarm formations. Numerical
simulations demonstrate the effectiveness of the method, with all code provided
open source for reproducibility.

</details>


### [154] [Tailoring materials into kirigami robots](https://arxiv.org/abs/2510.07027)
*Saravana Prashanth Murali Babu,Aida Parvaresh,Ahmad Rafsanjani*

Main category: cs.RO

TL;DR: 剪纸技术通过优化切割模式，为机器人提供多功能、轻量化和适应性强的解决方案，涵盖执行器、传感器、电池和控制器，应用包括抓取、运动和可穿戴设备，但仍面临设计和制造挑战。


<details>
  <summary>Details</summary>
Motivation: 剪纸技术为机器人领域提供了多功能、轻量化和适应性强的解决方案，具有弯曲主导的变形特性，能在小驱动力下实现形状变化。

Method: 通过优化切割模式来定制剪纸组件，如执行器、传感器、电池、控制器和机身结构。

Result: 基于剪纸原理的执行器可实现复杂运动，传感器结合了导电性和柔顺性，电池集成提升了灵活性和紧凑性，控制器模拟机械计算，实现了高级功能如形状变化和记忆功能。

Conclusion: 尽管剪纸机器人技术展现出巨大的潜力，但在设计特定功能的切割模式和优化制造技术方面仍存在挑战。

Abstract: Kirigami, the traditional paper-cutting craft, holds immense potential for
revolutionizing robotics by providing multifunctional, lightweight, and
adaptable solutions. Kirigami structures, characterized by their
bending-dominated deformation, offer resilience to tensile forces and
facilitate shape morphing under small actuation forces. Kirigami components
such as actuators, sensors, batteries, controllers, and body structures can be
tailored to specific robotic applications by optimizing cut patterns. Actuators
based on kirigami principles exhibit complex motions programmable through
various energy sources, while kirigami sensors bridge the gap between
electrical conductivity and compliance. Kirigami-integrated batteries enable
energy storage directly within robot structures, enhancing flexibility and
compactness. Kirigami-controlled mechanisms mimic mechanical computations,
enabling advanced functionalities such as shape morphing and memory functions.
Applications of kirigami-enabled robots include grasping, locomotion, and
wearables, showcasing their adaptability to diverse environments and tasks.
Despite promising opportunities, challenges remain in the design of cut
patterns for a given function and streamlining fabrication techniques.

</details>


### [155] [Temporal-Prior-Guided View Planning for Periodic 3D Plant Reconstruction](https://arxiv.org/abs/2510.07028)
*Sicong Pan,Xuying Huang,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出了一种基于时间先验的视图规划方法，用于周期性植物重建，减少了视图数量同时保持或提高覆盖效果。


<details>
  <summary>Details</summary>
Motivation: 周期性3D重建对作物监测至关重要，但每次从头开始重建成本高昂，浪费资源且忽略了先前捕获的信息。

Method: 提出了一种基于时间先验的视图规划方法，通过非刚性对齐先前重建的植物模型与新部分观测，形成当前几何的近似。为适应植物生长，该方法膨胀该近似并求解集合覆盖优化问题以计算最小视图集。

Result: 在玉米和番茄上的实验表明，该系统在半球和球面视图空间下表现优于现有基线。

Conclusion: 该方法在保持或提高表面覆盖的同时，减少了所需视图数量，并在运动成本上与现有基线相当。

Abstract: Periodic 3D reconstruction is essential for crop monitoring, but costly when
each cycle restarts from scratch, wasting resources and ignoring information
from previous captures. We propose temporal-prior-guided view planning for
periodic plant reconstruction, in which a previously reconstructed model of the
same plant is non-rigidly aligned to a new partial observation to form an
approximation of the current geometry. To accommodate plant growth, we inflate
this approximation and solve a set covering optimization problem to compute a
minimal set of views. We integrated this method into a complete pipeline that
acquires one additional next-best view before registration for robustness and
then plans a globally shortest path to connect the planned set of views and
outputs the best view sequence. Experiments on maize and tomato under
hemisphere and sphere view spaces show that our system maintains or improves
surface coverage while requiring fewer views and comparable movement cost
compared to state-of-the-art baselines.

</details>


### [156] [Diffusing Trajectory Optimization Problems for Recovery During Multi-Finger Manipulation](https://arxiv.org/abs/2510.07030)
*Abhinav Kumar,Fan Yang,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: 该研究利用扩散模型检测和优化多指手任务中的恢复轨迹，显著提升任务性能，特别是在螺丝刀旋转任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 多指手在执行精细操作任务时，环境扰动或执行错误可能阻碍任务性能，因此需要恢复行为来恢复正常任务执行。

Method: 利用扩散模型检测任务执行中的异常状态，并通过扩散采样和轨迹优化规划恢复轨迹。此外，提出了一种新颖的扩散方法，用于高效扩散恢复轨迹优化问题的完整参数化。

Result: 在硬件螺丝刀旋转任务中，使用该方法恢复任务性能提高了96%，且是唯一在尝试恢复时未导致灾难性任务失败的方法。

Conclusion: 本研究提出了一种基于扩散模型的框架，用于自主识别恢复需求并优化接触丰富的轨迹，显著提高了任务性能，特别是在螺丝刀旋转任务中表现优异。

Abstract: Multi-fingered hands are emerging as powerful platforms for performing fine
manipulation tasks, including tool use. However, environmental perturbations or
execution errors can impede task performance, motivating the use of recovery
behaviors that enable normal task execution to resume. In this work, we take
advantage of recent advances in diffusion models to construct a framework that
autonomously identifies when recovery is necessary and optimizes contact-rich
trajectories to recover. We use a diffusion model trained on the task to
estimate when states are not conducive to task execution, framed as an
out-of-distribution detection problem. We then use diffusion sampling to
project these states in-distribution and use trajectory optimization to plan
contact-rich recovery trajectories. We also propose a novel diffusion-based
approach that distills this process to efficiently diffuse the full
parameterization, including constraints, goal state, and initialization, of the
recovery trajectory optimization problem, saving time during online execution.
We compare our method to a reinforcement learning baseline and other methods
that do not explicitly plan contact interactions, including on a hardware
screwdriver-turning task where we show that recovering using our method
improves task performance by 96% and that ours is the only method evaluated
that can attempt recovery without causing catastrophic task failure. Videos can
be found at https://dtourrecovery.github.io/.

</details>


### [157] [Bring the Apple, Not the Sofa: Impact of Irrelevant Context in Embodied AI Commands on VLA Models](https://arxiv.org/abs/2510.07067)
*Daria Pugacheva,Andrey Moskalenko,Denis Shepelev,Andrey Kuznetsov,Vlad Shakhuro,Elena Tutubalina*

Main category: cs.RO

TL;DR: VLA模型在自然语言变异性下的鲁棒性研究，提出LLM过滤框架提升性能。


<details>
  <summary>Details</summary>
Motivation: 探讨VLA模型在现实场景中自然语言变异性下的鲁棒性，填补现有研究的空白。

Method: 系统地评估了最先进的VLA模型在两种指令噪声（人类生成的改写和无关上下文的添加）下的表现，并进一步将无关上下文按长度及语义和词汇接近度分类。

Result: 随着上下文扩展，模型性能持续下降；模型对随机上下文表现出相对鲁棒性（性能下降10%），而对语义和词汇相似的上下文性能下降约50%；人类改写指令导致性能下降近20%。

Conclusion: 研究提出了一种基于LLM的过滤框架，能够从噪声输入中提取核心指令，使模型在噪声条件下的性能恢复至原始性能的98.5%。

Abstract: Vision Language Action (VLA) models are widely used in Embodied AI, enabling
robots to interpret and execute language instructions. However, their
robustness to natural language variability in real-world scenarios has not been
thoroughly investigated. In this work, we present a novel systematic study of
the robustness of state-of-the-art VLA models under linguistic perturbations.
Specifically, we evaluate model performance under two types of instruction
noise: (1) human-generated paraphrasing and (2) the addition of irrelevant
context. We further categorize irrelevant contexts into two groups according to
their length and their semantic and lexical proximity to robot commands. In
this study, we observe consistent performance degradation as context size
expands. We also demonstrate that the model can exhibit relative robustness to
random context, with a performance drop within 10%, while semantically and
lexically similar context of the same length can trigger a quality decline of
around 50%. Human paraphrases of instructions lead to a drop of nearly 20%. To
mitigate this, we propose an LLM-based filtering framework that extracts core
commands from noisy inputs. Incorporating our filtering step allows models to
recover up to 98.5% of their original performance under noisy conditions.

</details>


### [158] [Vision-Language-Action Models for Robotics: A Review Towards Real-World Applications](https://arxiv.org/abs/2510.07077)
*Kento Kawaharazuka,Jihoon Oh,Jun Yamada,Ingmar Posner,Yuke Zhu*

Main category: cs.RO

TL;DR: 本文综述了VLA模型的策略、架构、处理技术及学习范式，并提供了机器人平台、数据集和评估方法的实用指南，旨在帮助机器人社区在现实系统中应用VLA。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）和视觉语言模型（VLMs）在机器人领域的应用日益增多，VLA模型因其能够统一视觉、语言和动作数据而受到广泛关注。这种统一有望使机器人能够在多样化的任务、对象、体现和环境之间实现泛化。

Method: 本文对VLA模型进行了系统性的综述，涵盖了策略和架构转变、架构和构建模块、模态特定处理技术以及学习范式。此外，还回顾了常用的机器人平台、数据收集策略、公开数据集、数据增强方法和评估基准。

Result: 本文提供了全面的全栈综述，整合了VLA系统的软件和硬件组件，并提供了按训练方法、评估方法、模态和数据集分类的参考资料。

Conclusion: 本文旨在为机器人社区提供实际指导，帮助他们在现实世界的机器人系统中应用VLA模型。

Abstract: Amid growing efforts to leverage advances in large language models (LLMs) and
vision-language models (VLMs) for robotics, Vision-Language-Action (VLA) models
have recently gained significant attention. By unifying vision, language, and
action data at scale, which have traditionally been studied separately, VLA
models aim to learn policies that generalise across diverse tasks, objects,
embodiments, and environments. This generalisation capability is expected to
enable robots to solve novel downstream tasks with minimal or no additional
task-specific data, facilitating more flexible and scalable real-world
deployment. Unlike previous surveys that focus narrowly on action
representations or high-level model architectures, this work offers a
comprehensive, full-stack review, integrating both software and hardware
components of VLA systems. In particular, this paper provides a systematic
review of VLAs, covering their strategy and architectural transition,
architectures and building blocks, modality-specific processing techniques, and
learning paradigms. In addition, to support the deployment of VLAs in
real-world robotic applications, we also review commonly used robot platforms,
data collection strategies, publicly available datasets, data augmentation
methods, and evaluation benchmarks. Throughout this comprehensive survey, this
paper aims to offer practical guidance for the robotics community in applying
VLAs to real-world robotic systems. All references categorized by training
approach, evaluation method, modality, and dataset are available in the table
on our project website: https://vla-survey.github.io .

</details>


### [159] [Sampling Strategies for Robust Universal Quadrupedal Locomotion Policies](https://arxiv.org/abs/2510.07094)
*David Rytz,Kim Tien Ly,Ioannis Havoutis*

Main category: cs.RO

TL;DR: 研究通过优化关节增益采样策略，提升四足机器人通用运动策略的鲁棒性，结果表明增益随机化对仿真到现实迁移至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究采样物理机器人参数和关节比例-微分增益的效果，以训练单一强化学习策略，使其能泛化到多种参数配置。

Method: 比较了三种基本关节增益采样策略：1）质量到增益的线性和多项式函数映射；2）基于性能的自适应滤波；3）均匀随机采样。通过名义先验和参考模型对配置进行偏置，提升策略鲁棒性。

Result: 在仿真和硬件测试中，结果表明关节控制器增益的显著随机化对缩小仿真到现实差距至关重要。

Conclusion: 通过采样策略优化，特别是关节控制器增益的显著随机化，可以有效缩小仿真到现实的差距，提升四足机器人通用运动策略的鲁棒性。

Abstract: This work focuses on sampling strategies of configuration variations for
generating robust universal locomotion policies for quadrupedal robots. We
investigate the effects of sampling physical robot parameters and joint
proportional-derivative gains to enable training a single reinforcement
learning policy that generalizes to multiple parameter configurations. Three
fundamental joint gain sampling strategies are compared: parameter sampling
with (1) linear and polynomial function mappings of mass-to-gains, (2)
performance-based adaptive filtering, and (3) uniform random sampling. We
improve the robustness of the policy by biasing the configurations using
nominal priors and reference models. All training was conducted on RaiSim,
tested in simulation on a range of diverse quadrupeds, and zero-shot deployed
onto hardware using the ANYmal quadruped robot. Compared to multiple baseline
implementations, our results demonstrate the need for significant joint
controller gains randomization for robust closing of the sim-to-real gap.

</details>


### [160] [A Digital Twin Framework for Metamorphic Testing of Autonomous Driving Systems Using Generative Model](https://arxiv.org/abs/2510.07133)
*Tony Zhang,Burak Kantarci,Umair Siddique*

Main category: cs.RO

TL;DR: 本文提出了一种结合数字孪生和AI生成模型的自动驾驶测试框架，显著提升了测试覆盖率和效果，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶汽车的安全保障是一个重大挑战，传统测试方法存在显著局限性，如无法覆盖所有可能场景和难以判断系统行为是否正确。

Method: 本文提出了一种基于数字孪生的变形测试框架，结合了数字孪生技术和基于AI的图像生成模型（如Stable Diffusion），系统性地生成真实且多样化的驾驶场景。

Result: 在Udacity自动驾驶模拟器中验证了该框架，结果显示其测试覆盖率和有效性显著提升，达到了最高的真阳性率（0.719）、F1分数（0.689）和精确度（0.662）。

Conclusion: 本文强调了将数字孪生与AI驱动的场景生成相结合的价值，为自动驾驶车辆安全提供了一个可扩展、自动化且高保真的测试解决方案。

Abstract: Ensuring the safety of self-driving cars remains a major challenge due to the
complexity and unpredictability of real-world driving environments. Traditional
testing methods face significant limitations, such as the oracle problem, which
makes it difficult to determine whether a system's behavior is correct, and the
inability to cover the full range of scenarios an autonomous vehicle may
encounter. In this paper, we introduce a digital twin-driven metamorphic
testing framework that addresses these challenges by creating a virtual replica
of the self-driving system and its operating environment. By combining digital
twin technology with AI-based image generative models such as Stable Diffusion,
our approach enables the systematic generation of realistic and diverse driving
scenes. This includes variations in weather, road topology, and environmental
features, all while maintaining the core semantics of the original scenario.
The digital twin provides a synchronized simulation environment where changes
can be tested in a controlled and repeatable manner. Within this environment,
we define three metamorphic relations inspired by real-world traffic rules and
vehicle behavior. We validate our framework in the Udacity self-driving
simulator and demonstrate that it significantly enhances test coverage and
effectiveness. Our method achieves the highest true positive rate (0.719), F1
score (0.689), and precision (0.662) compared to baseline approaches. This
paper highlights the value of integrating digital twins with AI-powered
scenario generation to create a scalable, automated, and high-fidelity testing
solution for autonomous vehicle safety.

</details>


### [161] [TrackVLA++: Unleashing Reasoning and Memory Capabilities in VLA Models for Embodied Visual Tracking](https://arxiv.org/abs/2510.07134)
*Jiahang Liu,Yunpeng Qi,Jiazhao Zhang,Minghan Li,Shaoan Wang,Kui Wu,Hanjing Ye,Hong Zhang,Zhibo Chen,Fangwei Zhong,Zhizheng Zhang,He Wang*

Main category: cs.RO

TL;DR: TrackVLA++通过空间推理和目标记忆模块，显著提升了复杂场景下的视觉跟踪性能，并在基准测试中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在严重遮挡或相似干扰物存在时表现不佳，缺乏明确的空间推理和有效的时间记忆。TrackVLA++旨在解决这些问题，提升复杂场景下的目标跟踪能力。

Method: 提出的TrackVLA++模型包含两个关键模块：空间推理机制（Polar-CoT）和目标识别记忆（TIM）。Polar-CoT通过链式思维推断目标的相对位置并编码为极坐标令牌，TIM则采用门控更新策略保持长期目标记忆。

Result: 在EVT-Bench DT分割上，TrackVLA++分别比之前领先方法提高了5.1和12分，表现出强大的零样本泛化能力。

Conclusion: TrackVLA++通过引入空间推理机制和目标识别记忆模块，显著提升了视觉语言动作模型在复杂场景下的跟踪性能，并在公开基准测试中取得了最先进的结果。

Abstract: Embodied Visual Tracking (EVT) is a fundamental ability that underpins
practical applications, such as companion robots, guidance robots and service
assistants, where continuously following moving targets is essential. Recent
advances have enabled language-guided tracking in complex and unstructured
scenes. However, existing approaches lack explicit spatial reasoning and
effective temporal memory, causing failures under severe occlusions or in the
presence of similar-looking distractors. To address these challenges, we
present TrackVLA++, a novel Vision-Language-Action (VLA) model that enhances
embodied visual tracking with two key modules, a spatial reasoning mechanism
and a Target Identification Memory (TIM). The reasoning module introduces a
Chain-of-Thought paradigm, termed Polar-CoT, which infers the target's relative
position and encodes it as a compact polar-coordinate token for action
prediction. Guided by these spatial priors, the TIM employs a gated update
strategy to preserve long-horizon target memory, ensuring spatiotemporal
consistency and mitigating target loss during extended occlusions. Extensive
experiments show that TrackVLA++ achieves state-of-the-art performance on
public benchmarks across both egocentric and multi-camera settings. On the
challenging EVT-Bench DT split, TrackVLA++ surpasses the previous leading
approach by 5.1 and 12, respectively. Furthermore, TrackVLA++ exhibits strong
zero-shot generalization, enabling robust real-world tracking in dynamic and
occluded scenarios.

</details>


### [162] [DPL: Depth-only Perceptive Humanoid Locomotion via Realistic Depth Synthesis and Cross-Attention Terrain Reconstruction](https://arxiv.org/abs/2510.07152)
*Jingkai Sun,Gang Han,Pihai Sun,Wen Zhao,Jiahang Cao,Jiaxu Wang,Yijie Guo,Qiang Zhang*

Main category: cs.RO

TL;DR: 提出了一种集成盲主干策略、多模态变换器和深度图像合成的新框架，解决了现有方法的局限性，并在人形机器人上验证了其高效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有的地形感知人形运动方法存在训练效率低、仿真到现实的深度感知差距大、依赖多视觉传感器和定位系统导致延迟和鲁棒性降低等问题。

Method: 提出了一个新颖的框架，集成了三个关键组件：1) 基于预训练高程地图感知的盲主干地形感知运动策略；2) 多模态交叉注意力变换器，从噪声深度图像重建结构化地形表示；3) 自遮挡感知射线投射和噪声感知建模的深度图像合成方法。

Result: 该框架实现了地形重建误差减少30%以上，并在有限数据和硬件资源下实现了高效策略训练。

Conclusion: 该框架在完整尺寸的人形机器人上验证了其敏捷和适应性强的运动能力，能够应对多样化和具有挑战性的地形。

Abstract: Recent advancements in legged robot perceptive locomotion have shown
promising progress. However, terrain-aware humanoid locomotion remains largely
constrained to two paradigms: depth image-based end-to-end learning and
elevation map-based methods. The former suffers from limited training
efficiency and a significant sim-to-real gap in depth perception, while the
latter depends heavily on multiple vision sensors and localization systems,
resulting in latency and reduced robustness. To overcome these challenges, we
propose a novel framework that tightly integrates three key components: (1)
Terrain-Aware Locomotion Policy with a Blind Backbone, which leverages
pre-trained elevation map-based perception to guide reinforcement learning with
minimal visual input; (2) Multi-Modality Cross-Attention Transformer, which
reconstructs structured terrain representations from noisy depth images; (3)
Realistic Depth Images Synthetic Method, which employs self-occlusion-aware ray
casting and noise-aware modeling to synthesize realistic depth observations,
achieving over 30\% reduction in terrain reconstruction error. This combination
enables efficient policy training with limited data and hardware resources,
while preserving critical terrain features essential for generalization. We
validate our framework on a full-sized humanoid robot, demonstrating agile and
adaptive locomotion across diverse and challenging terrains.

</details>


### [163] [A Narwhal-Inspired Sensing-to-Control Framework for Small Fixed-Wing Aircraft](https://arxiv.org/abs/2510.07160)
*Fengze Xie,Xiaozhou Fan,Jacob Schuster,Yisong Yue,Morteza Gharib*

Main category: cs.RO

TL;DR: 该论文提出了一种结合生物启发硬件和物理信息动力学学习的端到端控制流程，显著提高了固定翼无人机的低速敏捷性和控制精度。


<details>
  <summary>Details</summary>
Motivation: 固定翼无人机在低速敏捷性方面存在不足，主要原因是高度耦合的动力学。为解决这一问题，研究提出了一种新的感知到控制流程。

Method: 使用多孔探针和稀疏翼压传感器进行气流测量，数据驱动校准将探针压力映射到空速和流动角度，然后学习控制仿射动力学模型，并通过软左右对称正则化提高可识别性。

Result: 风洞研究表明，添加翼压传感器可将力估计误差降低25-30%，所提模型在分布偏移下的性能下降较少（约12% vs 44%），力跟踪性能提高，输入更平滑。

Conclusion: 通过结合生物启发硬件、物理信息动力学学习和凸控制分配，提出的端到端感知到控制流程显著提高了固定翼无人机的低速敏捷性和控制精度。

Abstract: Fixed-wing unmanned aerial vehicles (UAVs) offer endurance and efficiency but
lack low-speed agility due to highly coupled dynamics. We present an end-to-end
sensing-to-control pipeline that combines bio-inspired hardware,
physics-informed dynamics learning, and convex control allocation. Measuring
airflow on a small airframe is difficult because near-body aerodynamics,
propeller slipstream, control-surface actuation, and ambient gusts distort
pressure signals. Inspired by the narwhal's protruding tusk, we mount in-house
multi-hole probes far upstream and complement them with sparse, carefully
placed wing pressure sensors for local flow measurement. A data-driven
calibration maps probe pressures to airspeed and flow angles. We then learn a
control-affine dynamics model using the estimated airspeed/angles and sparse
sensors. A soft left/right symmetry regularizer improves identifiability under
partial observability and limits confounding between wing pressures and
flaperon inputs. Desired wrenches (forces and moments) are realized by a
regularized least-squares allocator that yields smooth, trimmed actuation.
Wind-tunnel studies across a wide operating range show that adding wing
pressures reduces force-estimation error by 25-30%, the proposed model degrades
less under distribution shift (about 12% versus 44% for an unstructured
baseline), and force tracking improves with smoother inputs, including a 27%
reduction in normal-force RMSE versus a plain affine model and 34% versus an
unstructured baseline.

</details>


### [164] [TIGeR: Tool-Integrated Geometric Reasoning in Vision-Language Models for Robotics](https://arxiv.org/abs/2510.07181)
*Yi Han,Cheng Chi,Enshen Zhou,Shanyu Rong,Jingkun An,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: TIGeR框架通过外部工具增强视觉语言模型的几何计算能力，实现厘米级精度，适用于机器人操作。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在空间推理中缺乏计算精度，无法满足机器人操作所需的厘米级精度。TIGeR旨在通过外部工具解决这一问题。

Method: TIGeR采用两阶段训练管道（监督微调和强化微调）与分层奖励设计，结合TIGeR-300K数据集，生成并执行精确的几何计算代码。

Result: TIGeR在几何推理基准测试中达到最先进性能，并在实际机器人操作任务中实现厘米级精度。

Conclusion: TIGeR框架通过外部工具将视觉语言模型（VLMs）从感知估计器转变为几何计算机，实现了厘米级精度的几何推理，并在机器人操作任务中表现出色。

Abstract: Vision-Language Models (VLMs) have shown remarkable capabilities in spatial
reasoning, yet they remain fundamentally limited to qualitative precision and
lack the computational precision required for real-world robotics. Current
approaches fail to leverage metric cues from depth sensors and camera
calibration, instead reducing geometric problems to pattern recognition tasks
that cannot deliver the centimeter-level accuracy essential for robotic
manipulation. We present TIGeR (Tool-Integrated Geometric Reasoning), a novel
framework that transforms VLMs from perceptual estimators to geometric
computers by enabling them to generate and execute precise geometric
computations through external tools. Rather than attempting to internalize
complex geometric operations within neural networks, TIGeR empowers models to
recognize geometric reasoning requirements, synthesize appropriate
computational code, and invoke specialized libraries for exact calculations. To
support this paradigm, we introduce TIGeR-300K, a comprehensive
tool-invocation-oriented dataset covering point transformations, pose
estimation, trajectory generation, and spatial compatibility verification,
complete with tool invocation sequences and intermediate computations. Through
a two-stage training pipeline combining supervised fine-tuning (SFT) and
reinforcement fine-tuning (RFT) with our proposed hierarchical reward design,
TIGeR achieves SOTA performance on geometric reasoning benchmarks while
demonstrating centimeter-level precision in real-world robotic manipulation
tasks.

</details>


### [165] [COMPAct: Computational Optimization and Automated Modular design of Planetary Actuators](https://arxiv.org/abs/2510.07197)
*Aman Singh,Deepak Kapa,Suryank Joshi,Shishir Kolathaya*

Main category: cs.RO

TL;DR: COMPAct框架优化四种行星齿轮箱参数并自动化生成CAD，实验显示SSPG和CPG执行器在效率、背隙和刚度上的表现差异。


<details>
  <summary>Details</summary>
Motivation: 当前机器人执行器设计中，齿轮箱参数优化和CAD自动化生成的研究不足，限制了执行器性能和设计效率的提升。

Method: COMPAct框架采用计算方法优化四种行星齿轮箱（SSPG、CPG、WPG、DSPG）的参数，最小化质量和宽度并最大化效率，同时自动化生成可直接3D打印的CAD模型。

Result: 实验结果表明，SSPG执行器机械效率为60-80%，无负载背隙0.59度，传动刚度242.7 Nm/rad；CPG执行器效率60%，背隙2.6度，刚度201.6 Nm/rad。

Conclusion: COMPAct框架通过系统优化齿轮箱参数和自动化CAD生成，显著提升了机器人执行器的设计效率和性能，为不同齿轮比范围提供了最优齿轮箱类型的选择依据。

Abstract: The optimal design of robotic actuators is a critical area of research, yet
limited attention has been given to optimizing gearbox parameters and
automating actuator CAD. This paper introduces COMPAct: Computational
Optimization and Automated Modular Design of Planetary Actuators, a framework
that systematically identifies optimal gearbox parameters for a given motor
across four gearbox types, single-stage planetary gearbox (SSPG), compound
planetary gearbox (CPG), Wolfrom planetary gearbox (WPG), and double-stage
planetary gearbox (DSPG). The framework minimizes mass and actuator width while
maximizing efficiency, and further automates actuator CAD generation to enable
direct 3D printing without manual redesign. Using this framework, optimal
gearbox designs are explored over a wide range of gear ratios, providing
insights into the suitability of different gearbox types across various gear
ratio ranges. In addition, the framework is used to generate CAD models of all
four gearbox types with varying gear ratios and motors. Two actuator types are
fabricated and experimentally evaluated through power efficiency, no-load
backlash, and transmission stiffness tests. Experimental results indicate that
the SSPG actuator achieves a mechanical efficiency of 60-80 %, a no-load
backlash of 0.59 deg, and a transmission stiffness of 242.7 Nm/rad, while the
CPG actuator demonstrates 60 % efficiency, 2.6 deg backlash, and a stiffness of
201.6 Nm/rad. Code available at:
https://anonymous.4open.science/r/COMPAct-SubNum-3408 Video:
https://youtu.be/99zOKgxsDho

</details>


### [166] [HyPlan: Hybrid Learning-Assisted Planning Under Uncertainty for Safe Autonomous Driving](https://arxiv.org/abs/2510.07210)
*Donald Pfaffmann,Matthias Klusch,Marcel Steinmetz*

Main category: cs.RO

TL;DR: HyPlan是一种混合学习辅助规划方法，用于自动驾驶汽车在部分可观测环境中的安全导航，结合了行为预测、深度强化学习和高效POMDP规划，表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶汽车在部分可观测交通环境中的碰撞避免导航问题，并提高规划效率和安全性。

Method: HyPlan结合了多智能体行为预测、深度强化学习与近端策略优化，以及基于启发式置信度的垂直剪枝的近似在线POMDP规划方法。

Result: 在CARLA-CTS2基准测试中，HyPlan比相关基线方法更安全，且比考虑的替代在线POMDP规划器执行速度显著更快。

Conclusion: HyPlan在部分可观测的交通环境中为自动驾驶汽车提供了一种安全且高效的碰撞避免导航解决方案。

Abstract: We present a novel hybrid learning-assisted planning method, named HyPlan,
for solving the collision-free navigation problem for self-driving cars in
partially observable traffic environments. HyPlan combines methods for
multi-agent behavior prediction, deep reinforcement learning with proximal
policy optimization and approximated online POMDP planning with heuristic
confidence-based vertical pruning to reduce its execution time without
compromising safety of driving. Our experimental performance analysis on the
CARLA-CTS2 benchmark of critical traffic scenarios with pedestrians revealed
that HyPlan may navigate safer than selected relevant baselines and perform
significantly faster than considered alternative online POMDP planners.

</details>


### [167] [DeepXPalm: Tilt and Position Rendering using Palm-worn Haptic Display and CNN-based Tactile Pattern Recognition](https://arxiv.org/abs/2204.03521)
*Altamirano Cabrera Miguel,Sautenkov Oleg,Tirado Jonathan,Fedoseev Aleksey,Kopanev Pavel,Kajimoto Hiroyuki,Tsetserukou Dzmitry*

Main category: cs.RO

TL;DR: 本文提出了一种基于CNN的触觉反馈系统，显著提高了用户对变形物体倾斜角度和位置的识别率。


<details>
  <summary>Details</summary>
Motivation: 变形物体在遥控操作过程中形状会动态变化，导致对其对齐状态的感知模糊，从而引发机器人定位错误，因此需要解决倾斜角度和位置分类问题以向用户提供清晰的触觉模式。

Method: 提出了一种基于卷积神经网络（CNN）的新方法，用于检测抓取变形物体时的倾斜角度和位置，并通过生成的触觉模式向用户提供多触点触觉反馈。

Result: 研究显示，使用CNN算法和预设的触觉模式后，用户对于倾斜角度和位置的识别率从9.67%提升至82.5%。

Conclusion: 通过使用CNN算法和预设的触觉模式，用户对于变形物体倾斜角度和位置的识别率从9.67%提升至82.5%，显著提高了遥控操作的精度和效率。

Abstract: Telemanipulation of deformable objects requires high precision and dexterity
from the users, which can be increased by kinesthetic and tactile feedback.
However, the object shape can change dynamically, causing ambiguous perception
of its alignment and hence errors in the robot positioning. Therefore, the tilt
angle and position classification problem has to be solved to present a clear
tactile pattern to the user. This work presents a telemanipulation system for
plastic pipettes consisting of a multi-contact haptic device LinkGlide to
deliver haptic feedback at the users' palm and two tactile sensors array
embedded in the 2-finger Robotiq gripper. We propose a novel approach based on
Convolutional Neural Networks (CNN) to detect the tilt and position while
grasping deformable objects. The CNN generates a mask based on recognized tilt
and position data to render further multi-contact tactile stimuli provided to
the user during the telemanipulation. The study has shown that using the CNN
algorithm and the preset mask, tilt, and position recognition by users is
increased from 9.67% using the direct data to 82.5%.

</details>


### [168] [TiltXter: CNN-based Electro-tactile Rendering of Tilt Angle for Telemanipulation of Pasteur Pipettes](https://arxiv.org/abs/2409.15838)
*Miguel Altamirano Cabrera,Jonathan Tirado,Aleksey Fedoseev,Oleg Sautenkov,Vladimir Poliakov,Pavel Kopanev,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 通过CNN方法提升远程操作中可变形物体倾斜识别的准确性和操作成功率。


<details>
  <summary>Details</summary>
Motivation: 可变形物体在抓取过程中形状变化大，导致感知模糊，影响机器人定位和远程操作的准确性。

Method: 提出了一种基于卷积神经网络（CNN）的方法，用于检测可变形物体的倾斜，并生成触觉模式以提供电触觉刺激。

Result: 使用CNN算法后，用户对倾斜的识别率从23.13%提高到57.9%，远程操作的成功率从53.12%提高到92.18%。

Conclusion: 使用基于卷积神经网络（CNN）的新方法显著提高了用户在远程操作中对可变形物体倾斜的识别准确率和操作成功率。

Abstract: The shape of deformable objects can change drastically during grasping by
robotic grippers, causing an ambiguous perception of their alignment and hence
resulting in errors in robot positioning and telemanipulation. Rendering clear
tactile patterns is fundamental to increasing users' precision and dexterity
through tactile haptic feedback during telemanipulation. Therefore, different
methods have to be studied to decode the sensors' data into haptic stimuli.
This work presents a telemanipulation system for plastic pipettes that consists
of a Force Dimension Omega.7 haptic interface endowed with two
electro-stimulation arrays and two tactile sensor arrays embedded in the
2-finger Robotiq gripper. We propose a novel approach based on convolutional
neural networks (CNN) to detect the tilt of deformable objects. The CNN
generates a tactile pattern based on recognized tilt data to render further
electro-tactile stimuli provided to the user during the telemanipulation. The
study has shown that using the CNN algorithm, tilt recognition by users
increased from 23.13\% with the downsized data to 57.9%, and the success rate
during teleoperation increased from 53.12% using the downsized data to 92.18%
using the tactile patterns generated by the CNN.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [169] [Adaptive Semantic Communication for UAV/UGV Cooperative Path Planning](https://arxiv.org/abs/2510.06901)
*Fangzhou Zhao,Yao Sun,Jianglin Lan,Lan Zhang,Xuesong Liu,Muhammad Ali Imran*

Main category: cs.NI

TL;DR: 该论文提出了一种语义通信框架，用于在不可靠的无线条件下提升无人机与无人地面车辆的协作路径规划效率，通过减少数据传输量而不牺牲精度。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中，无线通信的不稳定性导致传统的无人机与无人地面车辆协作路径规划难以实现及时和准确的数据传输。

Method: 通过定义路径规划的关键语义并设计满足无人机-无人地面车辆协作路径规划需求的收发器，开发了一个语义通信框架。

Result: 仿真结果表明，与传统语义通信收发器相比，所提出的收发器在保持路径规划精度的同时，显著减少了数据传输量。

Conclusion: 该论文提出的语义通信框架在不可靠的无线条件下显著提升了无人机与无人地面车辆的协作路径规划效率，通过减少数据传输量而不牺牲精度，验证了其在实际应用中的潜力。

Abstract: Effective path planning is fundamental to the coordination of unmanned aerial
vehicles (UAVs) and unmanned ground vehicles (UGVs) systems, particularly in
applications such as surveillance, navigation, and emergency response.
Combining UAVs' broad field of view with UGVs' ground-level operational
capability greatly improve the likelihood of successfully achieving task
objectives such as locating victims, monitoring target areas, or navigating
hazardous terrain. In complex environments, UAVs need to provide precise
environmental perception information for UGVs to optimize their routing policy.
However, due to severe interference and non-line-of-sight conditions, wireless
communication is often unstable in such complex environments, making it
difficult to support timely and accurate path planning for UAV-UGV
coordination. To this end, this paper proposes a semantic communication
(SemCom) framework to enhance UAV/UGV cooperative path planning under
unreliable wireless conditions. Unlike traditional methods that transmit raw
data, SemCom transmits only the key information for path planning, reducing
transmission volume without sacrificing accuracy. The proposed framework is
developed by defining key semantics for path planning and designing a
transceiver for meeting the requirements of UAV-UGV cooperative path planning.
Simulation results show that, compared to conventional SemCom transceivers, the
proposed transceiver significantly reduces data transmission volume while
maintaining path planning accuracy, thereby enhancing system collaboration
efficiency.

</details>


### [170] [Dynamic Control Aware Semantic Communication Enabled Image Transmission for Lunar Landing](https://arxiv.org/abs/2510.06916)
*Fangzhou Zhao,Yao Sun,Jianglin Lan,Muhammad Ali Imran*

Main category: cs.NI

TL;DR: 论文提出了一种基于语义通信的框架，通过动态调整传输策略提升月球自主着陆的精度和可靠性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决月球自主着陆任务中因高动态条件和恶劣通信环境导致的控制精度与安全性问题。

Method: 论文引入了一种新颖的语义通信框架，通过动态调整传输策略，确保关键图像特征的准确传输。

Result: 仿真结果表明，该语义通信方法在自主着陆性能上显著优于传统方法。

Conclusion: 该论文提出的语义通信框架显著提升了月球自主着陆的精度和可靠性，优于传统通信方法。

Abstract: The primary challenge in autonomous lunar landing missions lies in the
unreliable local control system, which has limited capacity to handle
high-dynamic conditions, severely affecting landing precision and safety.
Recent advancements in lunar satellite communication make it possible to
establish a wireless link between lunar orbit satellites and the lunar lander.
This enables satellites to run high-performance autonomous landing algorithms,
improving landing accuracy while reducing the lander's computational and
storage load. Nevertheless, traditional communication paradigms are not
directly applicable due to significant temperature fluctuations on the lunar
surface, intense solar radiation, and severe interference caused by lunar dust
on hardware. The emerging technique of semantic communication (SemCom) offers
significant advantages in robustness and resource efficiency, particularly
under harsh channel conditions. In this paper, we introduce a novel SemCom
framework for transmitting images from the lander to satellites operating the
remote landing control system. The proposed encoder-decoder dynamically adjusts
the transmission strategy based on real-time feedback from the lander's control
algorithm, ensuring the accurate delivery of critical image features and
enhancing control reliability. We provide a rigorous theoretical analysis of
the conditions that improve the accuracy of the control algorithm and reduce
end-to-end transmission time under the proposed framework. Simulation results
demonstrate that our SemCom method significantly enhances autonomous landing
performance compared to traditional communication methods.

</details>


### [171] [A Genetic Algorithm Approach to Anti-Jamming UAV Swarm Behavior](https://arxiv.org/abs/2510.07292)
*Tiago Silva,António Grilo*

Main category: cs.NI

TL;DR: 本文用遗传算法优化无人机群编队和通信，以抗干扰，仿真有效但计算成本高。


<details>
  <summary>Details</summary>
Motivation: 多无人机群协作时，通信干扰成为其弱点，现有抗干扰技术未充分利用智能群体行为，本文旨在填补这一空白。

Method: 使用遗传算法（GAs）联合优化无人机群编队、波束导向天线和流量路由。

Result: 仿真结果表明该方法有效，但计算成本显著。

Conclusion: 本文通过遗传算法联合优化无人机群编队、波束导向天线和流量路由，有效减轻了主要协调通道的干扰影响，但计算成本较高，为未来研究提供了方向。

Abstract: In recent years, Unmanned Aerial Vehicles (UAVs) have brought a new true
revolution to military tactics. While UAVs already constitute an advantage when
operating alone, multi-UAV swarms expand the available possibilities, allowing
the UAVs to collaborate and support each other as a team to carry out a given
task. This entails the capability to exchange information related with
situation awareness and action coordination by means of a suitable wireless
communication technology. In such scenario, the adversary is expected to
disrupt communications by jamming the communication channel. The latter becomes
the Achilles heel of the swarm. While anti-jamming techniques constitute a well
covered topic in the literature, the use of intelligent swarm behaviors to
leverage those techniques is still an open research issue.
  This paper explores the use of Genetic Algorithms (GAs) to jointly optimize
UAV swarm formation, beam-steering antennas and traffic routing in order to
mitigate the effect of jamming in the main coordination channel, under the
assumption that a more robust and low data rate channel is used for formation
management signaling. Simulation results show the effectiveness of proposed
approach. However, the significant computational cost paves the way for further
research.

</details>
