<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 99]
- [cs.SE](#cs.SE) [Total: 13]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.DC](#cs.DC) [Total: 8]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.RO](#cs.RO) [Total: 30]
- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [SimULi: Real-Time LiDAR and Camera Simulation with Unscented Transforms](https://arxiv.org/abs/2510.12901)
*Haithem Turki,Qi Wu,Xin Kang,Janick Martinez Esturo,Shengyu Huang,Ruilong Li,Zan Gojcic,Riccardo de Lutio*

Main category: cs.CV

TL;DR: SimULi 是一种实时渲染任意相机模型和LiDAR数据的新方法，通过改进的3D高斯表示和锚定策略，显著提升了渲染速度和跨传感器一致性，适用于自动驾驶测试。


<details>
  <summary>Details</summary>
Motivation: 现有神经渲染方法在渲染速度或支持多传感器（如高畸变镜头和LiDAR）方面存在不足，限制了其在自动驾驶等领域的应用。

Method: SimULi 扩展了3DGUT，支持复杂相机模型，并通过自动分块策略和基于光线的剔除方法添加LiDAR支持。采用因子化的3D高斯表示和锚定策略减少跨传感器不一致性。

Result: SimULi 的渲染速度比光线追踪方法快10-20倍，比现有基于光栅化的方法快1.5-10倍，且在多个相机和LiDAR指标上达到或超过现有最先进方法的保真度。

Conclusion: SimULi 提出了一种能够实时渲染任意相机模型和LiDAR数据的方法，通过改进的3D高斯表示和锚定策略，显著减少了跨传感器不一致性，并在渲染速度和保真度上优于现有方法。

Abstract: Rigorous testing of autonomous robots, such as self-driving vehicles, is
essential to ensure their safety in real-world deployments. This requires
building high-fidelity simulators to test scenarios beyond those that can be
safely or exhaustively collected in the real-world. Existing neural rendering
methods based on NeRF and 3DGS hold promise but suffer from low rendering
speeds or can only render pinhole camera models, hindering their suitability to
applications that commonly require high-distortion lenses and LiDAR data.
Multi-sensor simulation poses additional challenges as existing methods handle
cross-sensor inconsistencies by favoring the quality of one modality at the
expense of others. To overcome these limitations, we propose SimULi, the first
method capable of rendering arbitrary camera models and LiDAR data in
real-time. Our method extends 3DGUT, which natively supports complex camera
models, with LiDAR support, via an automated tiling strategy for arbitrary
spinning LiDAR models and ray-based culling. To address cross-sensor
inconsistencies, we design a factorized 3D Gaussian representation and
anchoring strategy that reduces mean camera and depth error by up to 40%
compared to existing methods. SimULi renders 10-20x faster than ray tracing
approaches and 1.5-10x faster than prior rasterization-based work (and handles
a wider range of camera models). When evaluated on two widely benchmarked
autonomous driving datasets, SimULi matches or exceeds the fidelity of existing
state-of-the-art methods across numerous camera and LiDAR metrics.

</details>


### [2] [State-Change Learning for Prediction of Future Events in Endoscopic Videos](https://arxiv.org/abs/2510.12904)
*Saurav Sharma,Chinedu Innocent Nwoye,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: SurgFUTR通过状态变化学习框架，统一了手术未来预测的短期和长期任务，显著提升了预测准确性和跨流程适应性。


<details>
  <summary>Details</summary>
Motivation: 当前手术AI研究集中于理解正在发生的事件，缺乏对未来事件的预测能力，且现有方法局限于特定任务，缺乏统一框架。

Method: 采用教师-学生架构，结合Sinkhorn-Knopp聚类压缩视频片段为状态表示，并通过Action Dynamics模块引导学生网络预测未来状态。

Result: 在四个数据集和三种手术流程上的实验显示，SurgFUTR在短期和长期预测任务上均取得一致改进，跨流程迁移验证了其泛化性。

Conclusion: SurgFUTR通过状态变化学习框架，显著提升了手术未来预测的准确性和泛化能力，尤其在跨手术流程的适应性上表现突出。

Abstract: Surgical future prediction, driven by real-time AI analysis of surgical
video, is critical for operating room safety and efficiency. It provides
actionable insights into upcoming events, their timing, and risks-enabling
better resource allocation, timely instrument readiness, and early warnings for
complications (e.g., bleeding, bile duct injury). Despite this need, current
surgical AI research focuses on understanding what is happening rather than
predicting future events. Existing methods target specific tasks in isolation,
lacking unified approaches that span both short-term (action triplets, events)
and long-term horizons (remaining surgery duration, phase transitions). These
methods rely on coarse-grained supervision while fine-grained surgical action
triplets and steps remain underexplored. Furthermore, methods based only on
future feature prediction struggle to generalize across different surgical
contexts and procedures. We address these limits by reframing surgical future
prediction as state-change learning. Rather than forecasting raw observations,
our approach classifies state transitions between current and future timesteps.
We introduce SurgFUTR, implementing this through a teacher-student
architecture. Video clips are compressed into state representations via
Sinkhorn-Knopp clustering; the teacher network learns from both current and
future clips, while the student network predicts future states from current
videos alone, guided by our Action Dynamics (ActDyn) module. We establish
SFPBench with five prediction tasks spanning short-term (triplets, events) and
long-term (remaining surgery duration, phase and step transitions) horizons.
Experiments across four datasets and three procedures show consistent
improvements. Cross-procedure transfer validates generalizability.

</details>


### [3] [Foveation Improves Payload Capacity in Steganography](https://arxiv.org/abs/2510.13151)
*Lifeng Qiu Lin,Henry Kam,Qi Sun,Kaan Akşit*

Main category: cs.CV

TL;DR: 该研究通过新型感知设计提升了隐写术的容量和准确性，达到更高的视觉质量。


<details>
  <summary>Details</summary>
Motivation: 隐写在视觉媒体中的应用需要更高的容量和准确性，现有技术存在限制。

Method: 利用高效的潜在表示和注视点渲染技术训练模型。

Result: 容量从100比特提升至500比特，准确性达到2000比特中仅1比特失败，视觉质量达到31.47 dB PSNR和0.13 LPIPS。

Conclusion: 论文展示了新型感知设计在隐写术中创建多模态潜在表示的有效性，显著提升了容量限制和准确性。

Abstract: Steganography finds its use in visual medium such as providing metadata and
watermarking. With support of efficient latent representations and foveated
rendering, we trained models that improve existing capacity limits from 100 to
500 bits, while achieving better accuracy of up to 1 failure bit out of 2000,
at 200K test bits. Finally, we achieve a comparable visual quality of 31.47 dB
PSNR and 0.13 LPIPS, showing the effectiveness of novel perceptual design in
creating multi-modal latent representations in steganography.

</details>


### [4] [Robust Plant Disease Diagnosis with Few Target-Domain Samples](https://arxiv.org/abs/2510.12909)
*Takafumi Nogami,Satoshi Kagiwada,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: TMPS 是一种适应性强的方法，通过少量目标域样本提升植物病害诊断的鲁棒性，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在植物病害诊断中表现良好，但在训练环境外的条件下性能下降，主要原因是训练数据多样性与任务复杂性不匹配。

Method: 提出了 Target-Aware Metric Learning with Prioritized Sampling (TMPS) 框架，基于度量学习，利用少量目标域样本进行训练。

Result: TMPS 在包含 223,073 张叶片图像的数据集上测试，仅使用每病害 10 个目标域样本即可显著提升性能，平均宏 F1 分数分别提高 7.3 和 3.6 分。

Conclusion: TMPS 框架通过结合目标域样本的度量学习，显著提高了植物病害诊断模型在不同条件下的鲁棒性，优于现有方法。

Abstract: Various deep learning-based systems have been proposed for accurate and
convenient plant disease diagnosis, achieving impressive performance. However,
recent studies show that these systems often fail to maintain diagnostic
accuracy on images captured under different conditions from the training
environment -- an essential criterion for model robustness. Many deep learning
methods have shown high accuracy in plant disease diagnosis. However, they
often struggle to generalize to images taken in conditions that differ from the
training setting. This drop in performance stems from the subtle variability of
disease symptoms and domain gaps -- differences in image context and
environment. The root cause is the limited diversity of training data relative
to task complexity, making even advanced models vulnerable in unseen domains.
To tackle this challenge, we propose a simple yet highly adaptable learning
framework called Target-Aware Metric Learning with Prioritized Sampling (TMPS),
grounded in metric learning. TMPS operates under the assumption of access to a
limited number of labeled samples from the target (deployment) domain and
leverages these samples effectively to improve diagnostic robustness. We assess
TMPS on a large-scale automated plant disease diagnostic task using a dataset
comprising 223,073 leaf images sourced from 23 agricultural fields, spanning 21
diseases and healthy instances across three crop species. By incorporating just
10 target domain samples per disease into training, TMPS surpasses models
trained using the same combined source and target samples, and those fine-tuned
with these target samples after pre-training on source data. It achieves
average macro F1 score improvements of 7.3 and 3.6 points, respectively, and a
remarkable 18.7 and 17.1 point improvement over the baseline and conventional
metric learning.

</details>


### [5] [Automated document processing system for government agencies using DBNET++ and BART models](https://arxiv.org/abs/2510.13303)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 提出一种自动文档分类系统，结合DBNet++和BART，有效应对多种实际挑战，在复杂场景下实现高准确率分类。


<details>
  <summary>Details</summary>
Motivation: 解决实际应用中因光照变化、任意方向、弯曲或部分遮挡文本、低分辨率及远距离文本等挑战带来的文档分类难题。

Method: 系统包括四个阶段：图像捕获与预处理、使用DBNet++进行文本检测、使用BART分类器进行文本分类，以及通过PyQt5实现的用户界面。

Result: 在Total-Text数据集上，文本检测准确率达到约92.88%，表明系统在复杂场景下具有良好表现。

Conclusion: 该系统在无约束成像场景中有效实现了混合来源文档的自动分类。

Abstract: An automatic document classification system is presented that detects textual
content in images and classifies documents into four predefined categories
(Invoice, Report, Letter, and Form). The system supports both offline images
(e.g., files on flash drives, HDDs, microSD) and real-time capture via
connected cameras, and is designed to mitigate practical challenges such as
variable illumination, arbitrary orientation, curved or partially occluded
text, low resolution, and distant text. The pipeline comprises four stages:
image capture and preprocessing, text detection [1] using a DBNet++
(Differentiable Binarization Network Plus) detector, and text classification
[2] using a BART (Bidirectional and Auto-Regressive Transformers) classifier,
all integrated within a user interface implemented in Python with PyQt5. The
achieved results by the system for text detection in images were good at about
92.88% through 10 hours on Total-Text dataset that involve high resolution
images simulate a various and very difficult challenges. The results indicate
the proposed approach is effective for practical, mixed-source document
categorization in unconstrained imaging scenarios.

</details>


### [6] [Unifying Vision-Language Latents for Zero-label Image Caption Enhancement](https://arxiv.org/abs/2510.12931)
*Sanghyun Byun,Jung Ick Guack,Mohanad Odema,Baisub Lee,Jacob Song,Woo Seong Chung*

Main category: cs.CV

TL;DR: ViZer是一种无需标签的视觉语言对齐框架，通过改进现有VLMs的图像描述能力，展示了在零标签学习中的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型（VLMs）依赖标注图像数据集的问题，利用大量未标注图像数据提升模型性能。

Method: 提出Unified Vision-Language Alignment for Zero-Label Enhancement (ViZer)框架，通过主动对齐视觉和语言表示特征，无需文本标签或完整重新训练即可改进现有VLM的生成能力。

Result: 在SmolVLM-Base和Qwen2-VL上应用ViZer后，生成的描述更接地气和详细，定性评估显示优于基线。

Conclusion: ViZer框架通过无标签学习在图像描述任务中实现了性能提升，为视觉语言任务的零标签适应提供了实用起点。

Abstract: Vision-language models (VLMs) achieve remarkable performance through
large-scale image-text pretraining. However, their reliance on labeled image
datasets limits scalability and leaves vast amounts of unlabeled image data
underutilized. To address this, we propose Unified Vision-Language Alignment
for Zero-Label Enhancement (ViZer), an enhancement training framework that
enables zero-label learning in image captioning, providing a practical starting
point for broader zero-label adaptation in vision-language tasks. Unlike prior
approaches that rely on human or synthetically annotated datasets, ViZer
actively aligns vision and language representation features during training,
enabling existing VLMs to generate improved captions without requiring text
labels or full retraining. We demonstrate ViZer's advantage in qualitative
evaluation, as automated caption metrics such as CIDEr and BERTScore often
penalize details that are absent in reference captions. Applying ViZer on
SmolVLM-Base and Qwen2-VL, we observe consistent qualitative improvements,
producing captions that are more grounded and descriptive than their baseline.

</details>


### [7] [Leveraging 2D Priors and SDF Guidance for Dynamic Urban Scene Rendering](https://arxiv.org/abs/2510.13381)
*Siddharth Tourani,Jayaram Reddy,Akash Kumbar,Satyajit Tourani,Nishant Goyal,Madhava Krishna,N. Dinesh Reddy,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 提出SDF与3DGS结合的新方法，提升动态场景渲染与重建精度，减少对LiDAR和运动数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS方法在动态城市场景建模中需要相机、LiDAR数据、真实3D分割和运动数据，限制了其应用范围。本文旨在探索如何通过2D先验和SDF表示减少这些依赖。

Method: 通过结合2D对象无关先验（深度和点跟踪）与SDF表示，提出了一种统一优化框架，增强了3D高斯泼溅的几何精度并改进了SDF中的变形建模。

Result: 实验表明，该方法无需LiDAR数据即可在渲染指标上达到先进水平，结合LiDAR后进一步提升了重建和生成新视图的能力，且支持多种场景编辑任务。

Conclusion: 本文提出了一种将SDF与3DGS结合的新方法，显著提升了动态场景渲染与重建的精度和适应性，无需依赖LiDAR数据即可达到先进水平。

Abstract: Dynamic scene rendering and reconstruction play a crucial role in computer
vision and augmented reality. Recent methods based on 3D Gaussian Splatting
(3DGS), have enabled accurate modeling of dynamic urban scenes, but for urban
scenes they require both camera and LiDAR data, ground-truth 3D segmentations
and motion data in the form of tracklets or pre-defined object templates such
as SMPL. In this work, we explore whether a combination of 2D object agnostic
priors in the form of depth and point tracking coupled with a signed distance
function (SDF) representation for dynamic objects can be used to relax some of
these requirements. We present a novel approach that integrates Signed Distance
Functions (SDFs) with 3D Gaussian Splatting (3DGS) to create a more robust
object representation by harnessing the strengths of both methods. Our unified
optimization framework enhances the geometric accuracy of 3D Gaussian splatting
and improves deformation modeling within the SDF, resulting in a more adaptable
and precise representation. We demonstrate that our method achieves
state-of-the-art performance in rendering metrics even without LiDAR data on
urban scenes. When incorporating LiDAR, our approach improved further in
reconstructing and generating novel views across diverse object categories,
without ground-truth 3D motion annotation. Additionally, our method enables
various scene editing tasks, including scene decomposition, and scene
composition.

</details>


### [8] [Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation](https://arxiv.org/abs/2510.12953)
*Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du*

Main category: cs.CV

TL;DR: FetalMind 是一个针对胎儿超声的医疗AI系统，通过SED方法和FetalSigma-1M数据集，显著提升了报告生成和诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型在胎儿超声领域表现不佳，主要由于多视图推理、疾病多样性和图像异质性等挑战。

Method: 提出了 Salient Epistemic Disentanglement (SED) 方法，通过专家构建的双分图解耦视图与疾病的关联，并通过强化学习引导模型沿临床步骤进行推理。

Result: FetalMind 在所有孕期的任务中平均提升了14%，并在关键条件下实现了61.2%的准确率提升。

Conclusion: FetalMind 在胎儿超声报告生成和诊断任务中表现出色，显著优于现有开源和闭源基线模型，尤其在关键条件下的准确率提高了61.2%。

Abstract: Recent medical vision-language models have shown promise on tasks such as
VQA, report generation, and anomaly detection. However, most are adapted to
structured adult imaging and underperform in fetal ultrasound, which poses
challenges of multi-view image reasoning, numerous diseases, and image
diversity. To bridge this gap, we introduce FetalMind, a medical AI system
tailored to fetal ultrasound for both report generation and diagnosis. Guided
by clinical workflow, we propose Salient Epistemic Disentanglement (SED), which
injects an expert-curated bipartite graph into the model to decouple
view-disease associations and to steer preference selection along clinically
faithful steps via reinforcement learning. This design mitigates variability
across diseases and heterogeneity across views, reducing learning bottlenecks
while aligning the model's inference with obstetric practice. To train
FetalMind at scale, we curate FetalSigma-1M dataset, the first large-scale
fetal ultrasound report corpus, comprising 20K reports from twelve medical
centers, addressing the scarcity of domain data. Extensive experiments show
that FetalMind outperforms open- and closed-source baselines across all
gestational stages, achieving +14% average gains and +61.2% higher accuracy on
critical conditions while remaining efficient, stable, and scalable. Project
Page: https://hexiao0275.github.io/FetalMind.

</details>


### [9] [CADE 2.5 - ZeResFDG: Frequency-Decoupled, Rescaled and Zero-Projected Guidance for SD/SDXL Latent Diffusion Models](https://arxiv.org/abs/2510.12954)
*Denis Rychkovskiy,GPT-5*

Main category: cs.CV

TL;DR: CADE 2.5通过创新技术提升了扩散模型的采样质量，无需重新训练，适用于SD/SDXL模型。


<details>
  <summary>Details</summary>
Motivation: 旨在提升潜在扩散模型在采样阶段的细节增强、稳定性和高频微纹理生成能力，同时保持高效性。

Method: 论文提出了ZeResFDG模块，结合频率解耦引导、能量重新缩放和零投影技术，以及轻量级频谱EMA切换策略。此外，还引入了QSilk Micrograin Stabilizer进行推理时稳定化处理。

Result: 实验表明，ZeResFDG在多种SD/SDXL采样器中均能有效提升图像质量，特别是在中等引导尺度下。QSilk进一步增强了高频细节的鲁棒性。

Conclusion: CADE 2.5通过ZeResFDG和QSilk Micrograin Stabilizer技术，显著提升了SD/SDXL潜在扩散模型在采样阶段的清晰度、提示遵循和伪影控制能力，且无需重新训练。

Abstract: We introduce CADE 2.5 (Comfy Adaptive Detail Enhancer), a sampler-level
guidance stack for SD/SDXL latent diffusion models. The central module,
ZeResFDG, unifies (i) frequency-decoupled guidance that reweights low- and
high-frequency components of the guidance signal, (ii) energy rescaling that
matches the per-sample magnitude of the guided prediction to the positive
branch, and (iii) zero-projection that removes the component parallel to the
unconditional direction. A lightweight spectral EMA with hysteresis switches
between a conservative and a detail-seeking mode as structure crystallizes
during sampling. Across SD/SDXL samplers, ZeResFDG improves sharpness, prompt
adherence, and artifact control at moderate guidance scales without any
retraining. In addition, we employ a training-free inference-time stabilizer,
QSilk Micrograin Stabilizer (quantile clamp + depth/edge-gated micro-detail
injection), which improves robustness and yields natural high-frequency
micro-texture at high resolutions with negligible overhead. For completeness we
note that the same rule is compatible with alternative parameterizations (e.g.,
velocity), which we briefly discuss in the Appendix; however, this paper
focuses on SD/SDXL latent diffusion models.

</details>


### [10] [Scope: Selective Cross-modal Orchestration of Visual Perception Experts](https://arxiv.org/abs/2510.12974)
*Tianyu Zhang,Suyuchen Wang,Chao Wang,Juan Rodriguez,Ahmed Masry,Xiangru Jian,Yoshua Bengio,Perouz Taslakian*

Main category: cs.CV

TL;DR: SCOPE框架通过动态选择编码器，显著提升性能并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 多视觉编码器在视觉语言模型中虽有益，但简单堆叠会导致性能提升有限且计算成本倍增。

Method: 提出了SCOPE框架，采用混合编码器（MoEnc）方法，通过轻量级路由器动态选择每个图像-文本对的最佳编码器。路由器使用文本提示与共享视觉特征之间的交叉注意力进行选择，并通过双熵正则化和辅助损失进行训练。

Result: SCOPE仅使用一个共享编码器和一个路由编码器，性能优于同时使用四个额外编码器的模型，同时计算成本降低24-49%。

Conclusion: SCOPE的智能编码器选择方法优于传统的多编码器暴力聚合方法，不仅提高了性能，还显著降低了计算成本。

Abstract: Vision-language models (VLMs) benefit from multiple vision encoders, but
naively stacking them yields diminishing returns while multiplying inference
costs. We propose SCOPE, a Mixture-of-Encoders (MoEnc) framework that
dynamically selects one specialized encoder per image-text pair via
instance-level routing, unlike token-level routing in traditional MoE. SCOPE
maintains a shared encoder and a pool of routed encoders. A lightweight router
uses cross-attention between text prompts and shared visual features to select
the optimal encoder from the routed encoders. To train this router, we
introduce dual entropy regularization with auxiliary losses to balance
dataset-level load distribution with instance-level routing confidence.
Remarkably, SCOPE with one shared plus one routed encoder outperforms models
using all four extra encoders simultaneously, while reducing compute by
24-49\%. This demonstrates that intelligent encoder selection beats brute-force
aggregation, challenging the prevailing paradigm in multi-encoder VLMs.

</details>


### [11] [SVAG-Bench: A Large-Scale Benchmark for Multi-Instance Spatio-temporal Video Action Grounding](https://arxiv.org/abs/2510.13016)
*Tanveer Hannan,Shuaicong Wu,Mark Weber,Suprosanna Shit,Jindong Gu,Rajat Koner,Aljoša Ošep,Laura Leal-Taixé,Thomas Seidl*

Main category: cs.CV

TL;DR: 提出了SVAG任务和SVAG-Bench基准数据集，开发了SVAGFormer框架和SVAGEval工具，发现现有模型在复杂场景中表现不足，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解方法主要集中在粗粒度动作识别或通用对象跟踪，忽略了联合检测和跟踪多个对象并根据其动作进行时间定位的挑战。

Method: 提出了SVAGFormer框架，该框架基于最先进的视觉语言模型，用于联合空间和时间定位，并引入了SVAGEval评估工具包。

Result: 构建了SVAG-Bench基准数据集，包含688个视频、19,590个标注记录和903个独特动词，覆盖了多样化的对象、动作和真实场景。现有模型在SVAG任务上表现不佳，尤其是在密集或复杂场景中。

Conclusion: SVAGFormer框架和SVAGEval评估工具为视频动作时空定位任务提供了新的基准和解决方案，但现有模型在复杂场景中的表现不佳，突显了进一步研究的必要性。

Abstract: Understanding fine-grained actions and accurately localizing their
corresponding actors in space and time are fundamental capabilities for
advancing next-generation AI systems, including embodied agents, autonomous
platforms, and human-AI interaction frameworks. Despite recent progress in
video understanding, existing methods predominantly address either
coarse-grained action recognition or generic object tracking, thereby
overlooking the challenge of jointly detecting and tracking multiple objects
according to their actions while grounding them temporally. To address this
gap, we introduce Spatio-temporal Video Action Grounding (SVAG), a novel task
that requires models to simultaneously detect, track, and temporally localize
all referent objects in videos based on natural language descriptions of their
actions. To support this task, we construct SVAG-Bench, a large-scale benchmark
comprising 688 videos, 19,590 annotated records, and 903 unique verbs, covering
a diverse range of objects, actions, and real-world scenes. We further propose
SVAGFormer, a baseline framework that adapts state of the art vision language
models for joint spatial and temporal grounding, and introduce SVAGEval, a
standardized evaluation toolkit for fair and reproducible benchmarking.
Empirical results show that existing models perform poorly on SVAG,
particularly in dense or complex scenes, underscoring the need for more
advanced reasoning over fine-grained object-action interactions in long videos.

</details>


### [12] [SeqBench: Benchmarking Sequential Narrative Generation in Text-to-Video Models](https://arxiv.org/abs/2510.13042)
*Zhengxu Tang,Zizheng Wang,Luning Wang,Zitao Shuai,Chenhao Zhang,Siyu Qian,Yirui Wu,Bohao Wang,Haosong Rao,Zhenyu Yang,Chenwei Wu*

Main category: cs.CV

TL;DR: SeqBench是一个新的基准，用于评估T2V生成中的叙事连贯性，包含320个提示的数据集和基于DTG的自动评估指标，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的T2V基准主要关注视觉质量指标，但未能评估长序列中的叙事连贯性，因此需要一个新的基准来填补这一空白。

Method: 设计了基于动态时间图（DTG）的自动评估指标，能够高效捕捉长距离依赖和时间顺序，同时保持计算效率。

Result: 通过SeqBench的系统评估，揭示了当前T2V模型在多动作序列中保持对象状态一致性的失败、多对象场景中物理上不合理的结果以及在保持序列动作之间现实时间顺序关系上的困难。

Conclusion: SeqBench提供了一个系统化的框架来评估T2V生成中的叙事连贯性，并为未来模型的序列推理能力改进提供了具体见解。

Abstract: Text-to-video (T2V) generation models have made significant progress in
creating visually appealing videos. However, they struggle with generating
coherent sequential narratives that require logical progression through
multiple events. Existing T2V benchmarks primarily focus on visual quality
metrics but fail to evaluate narrative coherence over extended sequences. To
bridge this gap, we present SeqBench, a comprehensive benchmark for evaluating
sequential narrative coherence in T2V generation. SeqBench includes a carefully
designed dataset of 320 prompts spanning various narrative complexities, with
2,560 human-annotated videos generated from 8 state-of-the-art T2V models.
Additionally, we design a Dynamic Temporal Graphs (DTG)-based automatic
evaluation metric, which can efficiently capture long-range dependencies and
temporal ordering while maintaining computational efficiency. Our DTG-based
metric demonstrates a strong correlation with human annotations. Through
systematic evaluation using SeqBench, we reveal critical limitations in current
T2V models: failure to maintain consistent object states across multi-action
sequences, physically implausible results in multi-object scenarios, and
difficulties in preserving realistic timing and ordering relationships between
sequential actions. SeqBench provides the first systematic framework for
evaluating narrative coherence in T2V generation and offers concrete insights
for improving sequential reasoning capabilities in future models. Please refer
to https://videobench.github.io/SeqBench.github.io/ for more details.

</details>


### [13] [SceneAdapt: Scene-aware Adaptation of Human Motion Diffusion](https://arxiv.org/abs/2510.13044)
*Jungbin Cho,Minsu Kim,Jisoo Kim,Ce Zheng,Laszlo A. Jeni,Ming-Hsuan Yang,Youngjae Yu,Seonjoo Kim*

Main category: cs.CV

TL;DR: SceneAdapt通过两阶段适应框架，将场景感知注入文本到动作模型，解决了现有方法缺乏同时处理语义和场景的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有动作生成方法仅单独处理动作语义或场景感知，缺乏同时覆盖两者的数据集，因此需要一种新的框架来融合这两者。

Method: 通过两个适应阶段（中间帧生成和场景感知中间帧生成），利用不重叠的场景-动作和文本-动作数据集，引入关键帧层和场景条件层来调制动作潜在空间。

Result: 实验结果表明，SceneAdapt能有效注入场景感知，并分析了其机制。

Conclusion: SceneAdapt成功将场景感知注入到文本到动作的模型中，并通过实验验证了其有效性。

Abstract: Human motion is inherently diverse and semantically rich, while also shaped
by the surrounding scene. However, existing motion generation approaches
address either motion semantics or scene-awareness in isolation, since
constructing large-scale datasets with both rich text--motion coverage and
precise scene interactions is extremely challenging. In this work, we introduce
SceneAdapt, a framework that injects scene awareness into text-conditioned
motion models by leveraging disjoint scene--motion and text--motion datasets
through two adaptation stages: inbetweening and scene-aware inbetweening. The
key idea is to use motion inbetweening, learnable without text, as a proxy task
to bridge two distinct datasets and thereby inject scene-awareness to
text-to-motion models. In the first stage, we introduce keyframing layers that
modulate motion latents for inbetweening while preserving the latent manifold.
In the second stage, we add a scene-conditioning layer that injects scene
geometry by adaptively querying local context through cross-attention.
Experimental results show that SceneAdapt effectively injects scene awareness
into text-to-motion models, and we further analyze the mechanisms through which
this awareness emerges. Code and models will be released.

</details>


### [14] [One Dimensional CNN ECG Mamba for Multilabel Abnormality Classification in 12 Lead ECG](https://arxiv.org/abs/2510.13046)
*Huawei Jiang,Husna Mutahira,Gan Huang,Mannan Saeed Muhammad*

Main category: cs.CV

TL;DR: 提出了一种结合卷积特征提取和Mamba模型的混合框架，用于心电图异常检测，实验结果显示其在性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在处理长序列信号时性能有限，而状态空间模型作为高效替代方案被引入。本研究旨在结合卷积特征提取和Mamba模型，以提高心电图异常检测的准确性。

Method: 提出了一种名为一维卷积神经网络心电图Mamba的混合框架，结合了卷积特征提取和选择性状态空间模型Mamba，用于有效序列建模。该模型基于Vision Mamba，通过双向变体增强了心电图数据中时间依赖性的表示。

Result: 在PhysioNet Computing in Cardiology Challenges 2020和2021上进行的全面实验表明，该模型在十二导联心电图上的AUPRC和AUROC得分显著高于之前发表的最佳算法。

Conclusion: 基于Mamba的架构在提高可靠的心电图分类方面具有潜力，支持早期诊断和个性化治疗，同时提高了远程医疗和资源受限医疗系统的可及性。

Abstract: Accurate detection of cardiac abnormalities from electrocardiogram recordings
is regarded as essential for clinical diagnostics and decision support.
Traditional deep learning models such as residual networks and transformer
architectures have been applied successfully to this task, but their
performance has been limited when long sequential signals are processed.
Recently, state space models have been introduced as an efficient alternative.
In this study, a hybrid framework named One Dimensional Convolutional Neural
Network Electrocardiogram Mamba is introduced, in which convolutional feature
extraction is combined with Mamba, a selective state space model designed for
effective sequence modeling. The model is built upon Vision Mamba, a
bidirectional variant through which the representation of temporal dependencies
in electrocardiogram data is enhanced. Comprehensive experiments on the
PhysioNet Computing in Cardiology Challenges of 2020 and 2021 were conducted,
and superior performance compared with existing methods was achieved.
Specifically, the proposed model achieved substantially higher AUPRC and AUROC
scores than those reported by the best previously published algorithms on
twelve lead electrocardiograms. These results demonstrate the potential of
Mamba-based architectures to advance reliable ECG classification. This
capability supports early diagnosis and personalized treatment, while enhancing
accessibility in telemedicine and resource-constrained healthcare systems.

</details>


### [15] [True Self-Supervised Novel View Synthesis is Transferable](https://arxiv.org/abs/2510.13063)
*Thomas W. Mitchel,Hyunwoo Ryu,Vincent Sitzmann*

Main category: cs.CV

TL;DR: XFactor是首个无需3D先验的自我监督模型，通过成对姿态估计和输入输出增强实现了真正的新视角合成，其潜在姿态与实际世界姿态高度相关。


<details>
  <summary>Details</summary>
Motivation: 确定模型是否真正具备新视角合成能力的关键标准是可转移性：从一个视频序列中提取的姿态表示能否用于重新渲染另一个视频中的相同相机轨迹。

Method: XFactor结合了成对姿态估计与输入输出的简单增强方案，共同实现了相机姿态与场景内容的解耦，并促进了几何推理。

Result: XFactor在量化可转移性的新指标上显著优于先前的无姿态NVS变换器，且潜在姿态与实际世界姿态高度相关。

Conclusion: XFactor是第一个无需几何先验的自我监督模型，能够实现真正的新视角合成（NVS），其潜在姿态变量与实际世界姿态高度相关。

Abstract: In this paper, we identify that the key criterion for determining whether a
model is truly capable of novel view synthesis (NVS) is transferability:
Whether any pose representation extracted from one video sequence can be used
to re-render the same camera trajectory in another. We analyze prior work on
self-supervised NVS and find that their predicted poses do not transfer: The
same set of poses lead to different camera trajectories in different 3D scenes.
Here, we present XFactor, the first geometry-free self-supervised model capable
of true NVS. XFactor combines pair-wise pose estimation with a simple
augmentation scheme of the inputs and outputs that jointly enables
disentangling camera pose from scene content and facilitates geometric
reasoning. Remarkably, we show that XFactor achieves transferability with
unconstrained latent pose variables, without any 3D inductive biases or
concepts from multi-view geometry -- such as an explicit parameterization of
poses as elements of SE(3). We introduce a new metric to quantify
transferability, and through large-scale experiments, we demonstrate that
XFactor significantly outperforms prior pose-free NVS transformers, and show
that latent poses are highly correlated with real-world poses through probing
experiments.

</details>


### [16] [Direction-aware multi-scale gradient loss for infrared and visible image fusion](https://arxiv.org/abs/2510.13067)
*Kaixuan Yang,Wei Xiang,Zhenshuai Chen,Tong Jin,Yunpeng Liu*

Main category: cs.CV

TL;DR: 提出方向感知多尺度梯度损失，改进红外与可见光图像融合的边缘和纹理质量。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在梯度处理中忽略了方向信息，导致监督模糊和边缘保真度不佳。

Method: 引入了一种方向感知、多尺度梯度损失，分别监督水平和垂直分量，并在不同尺度上保留其符号。

Result: 实验证明，该方法在不改变模型架构或训练协议的情况下，显著提升了边缘对齐和纹理保留效果。

Conclusion: 该论文提出的方向感知、多尺度梯度损失方法有效提升了红外与可见光图像融合的质量，尤其是在边缘清晰度和纹理保留方面。

Abstract: Infrared and visible image fusion aims to integrate complementary information
from co-registered source images to produce a single, informative result. Most
learning-based approaches train with a combination of structural similarity
loss, intensity reconstruction loss, and a gradient-magnitude term. However,
collapsing gradients to their magnitude removes directional information,
yielding ambiguous supervision and suboptimal edge fidelity. We introduce a
direction-aware, multi-scale gradient loss that supervises horizontal and
vertical components separately and preserves their sign across scales. This
axis-wise, sign-preserving objective provides clear directional guidance at
both fine and coarse resolutions, promoting sharper, better-aligned edges and
richer texture preservation without changing model architectures or training
protocols. Experiments on open-source model and multiple public benchmarks
demonstrate effectiveness of our approach.

</details>


### [17] [Unsupervised Domain Adaptation via Content Alignment for Hippocampus Segmentation](https://arxiv.org/abs/2510.13075)
*Hoda Kalabizadeh,Ludovica Griffanti,Pak-Hei Yeung,Ana I. L. Namburete,Nicola K. Dinsdale,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 该论文提出了一种针对海马体MRI分割的无监督领域自适应框架，通过风格协调和双向DIR有效应对领域偏移，显著提升跨数据集分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割模型在不同数据集上因领域偏移（风格和内容变化）导致的性能下降问题，特别是在海马体分割中。

Method: 结合了高效的z归一化风格协调和双向可变形图像配准（DIR）策略，DIR网络与分割和判别器网络联合训练，以生成解剖学上合理的变换。

Result: 在合成数据集和三个MRI海马体数据集上的全面评估中，该方法均优于现有基线，尤其在内容变化显著的情况下表现最佳。

Conclusion: 该论文提出的无监督领域自适应框架在跨领域海马体分割中表现出色，特别是在内容变化显著的情况下，相对于标准增强方法实现了高达15%的相对Dice分数提升。

Abstract: Deep learning models for medical image segmentation often struggle when
deployed across different datasets due to domain shifts - variations in both
image appearance, known as style, and population-dependent anatomical
characteristics, referred to as content. This paper presents a novel
unsupervised domain adaptation framework that directly addresses domain shifts
encountered in cross-domain hippocampus segmentation from MRI, with specific
emphasis on content variations. Our approach combines efficient style
harmonisation through z-normalisation with a bidirectional deformable image
registration (DIR) strategy. The DIR network is jointly trained with
segmentation and discriminator networks to guide the registration with respect
to a region of interest and generate anatomically plausible transformations
that align source images to the target domain. We validate our approach through
comprehensive evaluations on both a synthetic dataset using Morpho-MNIST (for
controlled validation of core principles) and three MRI hippocampus datasets
representing populations with varying degrees of atrophy. Across all
experiments, our method outperforms existing baselines. For hippocampus
segmentation, when transferring from young, healthy populations to clinical
dementia patients, our framework achieves up to 15% relative improvement in
Dice score compared to standard augmentation methods, with the largest gains
observed in scenarios with substantial content shift. These results highlight
the efficacy of our approach for accurate hippocampus segmentation across
diverse populations.

</details>


### [18] [Counting Hallucinations in Diffusion Models](https://arxiv.org/abs/2510.13080)
*Shuai Fu,Jian Zhou,Qi Chen,Huang Jing,Huy Anh Nguyen,Xiaohan Liu,Zhixiong Zeng,Lin Ma,Quanshi Zhang,Qi Wu*

Main category: cs.CV

TL;DR: 该研究系统性量化了扩散模型中的计数幻觉问题，构建了CountHalluSet数据集和评估协议，发现FID等指标无法有效捕捉此类幻觉，为未来生成模型设计提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型在生成任务中表现卓越，但仍常产生与真实世界知识冲突的幻觉样本（如生成不合理的重复物体）。缺乏系统性量化方法阻碍了解决这一挑战的进展，也模糊了在事实约束下设计下一代生成模型的潜在路径。

Method: 研究构建了包含ToyShape、SimObject和RealHand的CountHalluSet数据集，定义了明确的计数标准，并开发了标准化评估协议。通过分析不同采样条件（如求解器类型、ODE求解器阶数、采样步骤和初始噪声）对计数幻觉水平的影响，以及与FID等常见评估指标的相关性。

Result: 研究发现FID等广泛使用的图像质量指标无法一致捕捉计数幻觉，同时不同采样条件对计数幻觉水平有显著影响。

Conclusion: 本研究通过构建CountHalluSet数据集和标准化评估协议，首次系统性地量化了扩散概率模型中的计数幻觉问题，揭示了常见评估指标如FID在捕捉此类幻觉上的不足，为下一代生成模型的设计提供了新视角。

Abstract: Diffusion probabilistic models (DPMs) have demonstrated remarkable progress
in generative tasks, such as image and video synthesis. However, they still
often produce hallucinated samples (hallucinations) that conflict with
real-world knowledge, such as generating an implausible duplicate cup floating
beside another cup. Despite their prevalence, the lack of feasible
methodologies for systematically quantifying such hallucinations hinders
progress in addressing this challenge and obscures potential pathways for
designing next-generation generative models under factual constraints. In this
work, we bridge this gap by focusing on a specific form of hallucination, which
we term counting hallucination, referring to the generation of an incorrect
number of instances or structured objects, such as a hand image with six
fingers, despite such patterns being absent from the training data. To this
end, we construct a dataset suite CountHalluSet, with well-defined counting
criteria, comprising ToyShape, SimObject, and RealHand. Using these datasets,
we develop a standardized evaluation protocol for quantifying counting
hallucinations, and systematically examine how different sampling conditions in
DPMs, including solver type, ODE solver order, sampling steps, and initial
noise, affect counting hallucination levels. Furthermore, we analyze their
correlation with common evaluation metrics such as FID, revealing that this
widely used image quality metric fails to capture counting hallucinations
consistently. This work aims to take the first step toward systematically
quantifying hallucinations in diffusion models and offer new insights into the
investigation of hallucination phenomena in image generation.

</details>


### [19] [Edit-Your-Interest: Efficient Video Editing via Feature Most-Similar Propagation](https://arxiv.org/abs/2510.13084)
*Yi Zuo,Zitao Wang,Lingling Li,Xu Liu,Fang Liu,Licheng Jiao*

Main category: cs.CV

TL;DR: Edit-Your-Interest是一种轻量级、零样本的视频编辑方法，通过SFM和FMP技术显著提高了编辑效率和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法存在高计算开销、内存消耗大以及视觉保真度低等问题，导致时间不一致性和视觉伪影。

Method: 该方法引入了时空特征记忆库（SFM）和特征最相似传播（FMP）方法，结合交叉注意力图自动提取目标对象掩码，实现了高效且精细的视频编辑。

Result: 实验结果表明，Edit-Your-Interest在效率和视觉保真度上均优于现有方法。

Conclusion: Edit-Your-Interest方法在视频编辑效率和视觉保真度方面均优于当前最先进的方法，验证了其卓越的有效性和实用性。

Abstract: Text-to-image (T2I) diffusion models have recently demonstrated significant
progress in video editing.
  However, existing video editing methods are severely limited by their high
computational overhead and memory consumption.
  Furthermore, these approaches often sacrifice visual fidelity, leading to
undesirable temporal inconsistencies and artifacts such as blurring and
pronounced mosaic-like patterns.
  We propose Edit-Your-Interest, a lightweight, text-driven, zero-shot video
editing method.
  Edit-Your-Interest introduces a spatio-temporal feature memory to cache
features from previous frames, significantly reducing computational overhead
compared to full-sequence spatio-temporal modeling approaches.
  Specifically, we first introduce a Spatio-Temporal Feature Memory bank (SFM),
which is designed to efficiently cache and retain the crucial image tokens
processed by spatial attention.
  Second, we propose the Feature Most-Similar Propagation (FMP) method. FMP
propagates the most relevant tokens from previous frames to subsequent ones,
preserving temporal consistency.
  Finally, we introduce an SFM update algorithm that continuously refreshes the
cached features, ensuring their long-term relevance and effectiveness
throughout the video sequence.
  Furthermore, we leverage cross-attention maps to automatically extract masks
for the instances of interest.
  These masks are seamlessly integrated into the diffusion denoising process,
enabling fine-grained control over target objects and allowing
Edit-Your-Interest to perform highly accurate edits while robustly preserving
the background integrity.
  Extensive experiments decisively demonstrate that the proposed
Edit-Your-Interest outperforms state-of-the-art methods in both efficiency and
visual fidelity, validating its superior effectiveness and practicality.

</details>


### [20] [EgoSocial: Benchmarking Proactive Intervention Ability of Omnimodal LLMs via Egocentric Social Interaction Perception](https://arxiv.org/abs/2510.13105)
*Xijun Wang,Tanay Sharma,Achin Kulshrestha,Abhimitra Meka,Aveek Purohit,Dinesh Manocha*

Main category: cs.CV

TL;DR: EgoSoD通过整合多模态线索动态建模社交互动，显著提升了AI在干预时机和社交互动上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs缺乏社交意识，导致在作为AI助手时可能干扰自然对话和用户专注。需要从自我中心视角理解人类社交动态的AI。

Method: 提出了EgoSoD（EgoSocial Detection）方法，整合多模态上下文线索（如音频和视觉线索）到社交思维图中，动态建模参与者和互动。

Result: EgoSoD在干预时机性能上提升Phi-4 45.6%、Gemini 2.5 Pro 9.9%，在整体社交互动性能上提升Phi-4 20.4%、Gemini 2.5 Pro 6.9%。

Conclusion: EgoSoD方法在干预时机和社交互动性能上显著提升了现有模型的表现，未来将发布数据集和代码。

Abstract: As AR/VR technologies become integral to daily life, there's a growing need
for AI that understands human social dynamics from an egocentric perspective.
However, current LLMs often lack the social awareness to discern when to
intervene as AI assistant. This leads to constant, socially unaware responses
that may disrupt natural conversation and negatively impact user focus. To
address these limitations, we introduce EgoSocial, a large-scale egocentric
dataset with 13,500 social video-question pairs, specifically designed to
benchmark intervention in social interaction perception. We also present an
in-depth analysis of current omnimodal LLMs (OLLMs) to assess their
effectiveness in detecting diverse social contextual cues. Experiments show
that OLLMs still struggle to detect the intervention timing (14.4% for Gemini
2.5 Pro). We also propose EgoSoD (EgoSocial Detection), an end-to-end method
for robustly discerning social dynamics. Informed by our OLLM analysis, EgoSoD
integrates multimodal contextual cues (e.g., audio and visual cues) into a
social thinking graph, dynamically modeling participants and interactions. Our
method proactively detects intervention timing and social interactions,
precisely determining when to intervene. Our EgoSoD improves Phi-4 by 45.6% and
Gemini 2.5 Pro by 9.9% on Intervention Timing performance, and improves Phi-4
by 20.4% and Gemini 2.5 Pro by 6.9% on overall Social Interaction performance.
We will release the dataset and code soon.

</details>


### [21] [DriveCritic: Towards Context-Aware, Human-Aligned Evaluation for Autonomous Driving with Vision-Language Models](https://arxiv.org/abs/2510.13108)
*Jingyu Song,Zhenxin Li,Shiyi Lan,Xinglong Sun,Nadine Chang,Maying Shen,Joshua Chen,Katherine A. Skinner,Jose M. Alvarez*

Main category: cs.CV

TL;DR: DriveCritic是一个新框架，通过上下文感知的VLM评估器和数据集，显著提升自动驾驶系统评估的可靠性和人类对齐性。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的指标（如EPDMS）在复杂场景中缺乏上下文感知能力，因此需要一种更符合人类判断的评估方法。

Method: DriveCritic框架包括DriveCritic数据集和基于视觉语言模型（VLM）的评估器，采用两阶段监督和强化学习管道进行微调。

Result: 实验表明DriveCritic在匹配人类偏好和上下文感知方面显著优于现有指标和基线。

Conclusion: DriveCritic提供了一个更可靠、与人类判断一致的自动驾驶系统评估基础。

Abstract: Benchmarking autonomous driving planners to align with human judgment remains
a critical challenge, as state-of-the-art metrics like the Extended Predictive
Driver Model Score (EPDMS) lack context awareness in nuanced scenarios. To
address this, we introduce DriveCritic, a novel framework featuring two key
contributions: the DriveCritic dataset, a curated collection of challenging
scenarios where context is critical for correct judgment and annotated with
pairwise human preferences, and the DriveCritic model, a Vision-Language Model
(VLM) based evaluator. Fine-tuned using a two-stage supervised and
reinforcement learning pipeline, the DriveCritic model learns to adjudicate
between trajectory pairs by integrating visual and symbolic context.
Experiments show DriveCritic significantly outperforms existing metrics and
baselines in matching human preferences and demonstrates strong context
awareness. Overall, our work provides a more reliable, human-aligned foundation
to evaluating autonomous driving systems.

</details>


### [22] [VPREG: An Optimal Control Formulation for Diffeomorphic Image Registration Based on the Variational Principle Grid Generation Method](https://arxiv.org/abs/2510.13109)
*Zicong Zhou,Baihan Zhao,Andreas Mang,Guojun Liao*

Main category: cs.CV

TL;DR: VPreg是一种新型微分同胚图像配准方法，通过变分原理生成网格，确保变换质量，并在脑部扫描配准中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 改进现有网格生成和微分同胚图像配准方法，确保变换的正雅可比行列式及逆映射的准确性，以满足神经影像工作流的需求。

Method: VPreg采用变分原理（VP）生成网格，确保空间变换的微分同胚性，并提供精确的逆变换近似。

Result: 在OASIS-1数据集上的150次脑部扫描配准中，VPreg在35个兴趣区域的Dice分数、变换规律性及逆映射准确性上均优于现有方法。

Conclusion: VPreg在脑部扫描图像配准中表现出色，优于现有方法如ANTs-SyN、Freesurfer-Easyreg和FSL-Fnirt，特别是在Dice分数、变换规律性及逆映射准确性方面。

Abstract: This paper introduces VPreg, a novel diffeomorphic image registration method.
This work provides several improvements to our past work on mesh generation and
diffeomorphic image registration. VPreg aims to achieve excellent registration
accuracy while controlling the quality of the registration transformations. It
ensures a positive Jacobian determinant of the spatial transformation and
provides an accurate approximation of the inverse of the registration, a
crucial property for many neuroimaging workflows. Unlike conventional methods,
VPreg generates this inverse transformation within the group of diffeomorphisms
rather than operating on the image space. The core of VPreg is a grid
generation approach, referred to as \emph{Variational Principle} (VP), which
constructs non-folding grids with prescribed Jacobian determinant and curl.
These VP-generated grids guarantee diffeomorphic spatial transformations
essential for computational anatomy and morphometry, and provide a more
accurate inverse than existing methods. To assess the potential of the proposed
approach, we conduct a performance analysis for 150 registrations of brain
scans from the OASIS-1 dataset. Performance evaluation based on Dice scores for
35 regions of interest, along with an empirical analysis of the properties of
the computed spatial transformations, demonstrates that VPreg outperforms
state-of-the-art methods in terms of Dice scores, regularity properties of the
computed transformation, and accuracy and consistency of the provided inverse
map. We compare our results to ANTs-SyN, Freesurfer-Easyreg, and FSL-Fnirt.

</details>


### [23] [OS-HGAdapter: Open Semantic Hypergraph Adapter for Large Language Models Assisted Entropy-Enhanced Image-Text Alignment](https://arxiv.org/abs/2510.13131)
*Rongjun Chen,Chengsi Yao,Jinchang Ren,Xianxian Zeng,Peixian Wang,Jun Yuan,Jiawen Li,Huimin Zhao,Xu Lu*

Main category: cs.CV

TL;DR: 利用LLM增强文本多义性描述，通过超图适配器优化跨模态对齐，显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决文本和图像模态之间信息熵差异导致的跨模态检索不平衡问题，利用LLM的开放语义知识填补熵差，模拟人类在这些任务中的对齐能力。

Method: 提出了一种不依赖任务领域显式知识的新提示模板，利用LLM增强文本模态的多义性描述；使用超图适配器构建文本和图像模态之间的多边连接，以纠正同义词义的正负匹配错误，并通过将降维映射回原始维度来减少开放语义熵引起的噪声。

Result: 在Flickr30K和MS-COCO基准测试中，OS-HGAdapter在文本到图像和图像到文本的跨模态检索任务中分别实现了16.8%和40.1%的性能提升，并达到了语义对齐任务的最先进水平。

Conclusion: OS-HGAdapter通过在Flickr30K和MS-COCO基准测试上的全面评估，验证了其在跨模态检索任务中的优越性，相较于现有方法，文本到图像和图像到文本的检索性能分别提升了16.8%和40.1%，并在语义对齐任务中建立了新的最先进性能。

Abstract: Text-image alignment constitutes a foundational challenge in multimedia
content understanding, where effective modeling of cross-modal semantic
correspondences critically enhances retrieval system performance through joint
embedding space optimization. Given the inherent difference in information
entropy between texts and images, conventional approaches often show an
imbalance in the mutual retrieval of these two modalities. To address this
particular challenge, we propose to use the open semantic knowledge of Large
Language Model (LLM) to fill for the entropy gap and reproduce the alignment
ability of humans in these tasks. Our entropy-enhancing alignment is achieved
through a two-step process: 1) a new prompt template that does not rely on
explicit knowledge in the task domain is designed to use LLM to enhance the
polysemy description of the text modality. By analogy, the information entropy
of the text modality relative to the visual modality is increased; 2) A
hypergraph adapter is used to construct multilateral connections between the
text and image modalities, which can correct the positive and negative matching
errors for synonymous semantics in the same fixed embedding space, whilst
reducing the noise caused by open semantic entropy by mapping the reduced
dimensions back to the original dimensions. Comprehensive evaluations on the
Flickr30K and MS-COCO benchmarks validate the superiority of our Open Semantic
Hypergraph Adapter (OS-HGAdapter), showcasing 16.8\% (text-to-image) and 40.1\%
(image-to-text) cross-modal retrieval gains over existing methods while
establishing new state-of-the-art performance in semantic alignment tasks.

</details>


### [24] [Real-Time Sign Language to text Translation using Deep Learning: A Comparative study of LSTM and 3D CNN](https://arxiv.org/abs/2510.13137)
*Madhumati Pol,Anvay Anturkar,Anushka Khot,Ayush Andure,Aniruddha Ghosh,Anvit Magadum,Anvay Bahadur*

Main category: cs.CV

TL;DR: 研究比较了3D CNNs和LSTMs在实时ASL识别中的性能，发现3D CNNs准确率更高但计算成本更高，LSTMs资源消耗更低，混合模型表现良好，为实际应用提供了权衡参考。


<details>
  <summary>Details</summary>
Motivation: 研究3D CNNs和LSTMs在实时ASL识别中的性能，以探索哪种架构更适合实际应用。

Method: 评估了3D卷积神经网络（3D CNNs）和长短期记忆网络（LSTMs）在实时美国手语（ASL）识别中的性能，比较了它们在准确性、计算效率和延迟方面的表现。

Result: 实验结果表明，3D CNNs达到92.4%的识别准确率，但每帧处理时间比LSTMs多3.2%；LSTMs保持86.7%的准确率且资源消耗显著更低。混合3D CNN-LSTM模型表现良好，表明上下文相关的架构选择对实际应用至关重要。

Conclusion: 本研究为开发辅助技术提供了专业基准，强调了在边缘计算环境中识别精度与实时操作需求之间的权衡。

Abstract: This study investigates the performance of 3D Convolutional Neural Networks
(3D CNNs) and Long Short-Term Memory (LSTM) networks for real-time American
Sign Language (ASL) recognition. Though 3D CNNs are good at spatiotemporal
feature extraction from video sequences, LSTMs are optimized for modeling
temporal dependencies in sequential data. We evaluate both architectures on a
dataset containing 1,200 ASL signs across 50 classes, comparing their accuracy,
computational efficiency, and latency under similar training conditions.
Experimental results demonstrate that 3D CNNs achieve 92.4% recognition
accuracy but require 3.2% more processing time per frame compared to LSTMs,
which maintain 86.7% accuracy with significantly lower resource consumption.
The hybrid 3D CNNLSTM model shows decent performance, which suggests that
context-dependent architecture selection is crucial for practical
implementation.This project provides professional benchmarks for developing
assistive technologies, highlighting trade-offs between recognition precision
and real-time operational requirements in edge computing environments.

</details>


### [25] [DP-TTA: Test-time Adaptation for Transient Electromagnetic Signal Denoising via Dictionary-driven Prior Regularization](https://arxiv.org/abs/2510.13160)
*Meng Yang,Kecheng Chen,Wei Luo,Xianjie Chen,Yong Jia,Mingyue Wang,Fanqiang Lin*

Main category: cs.CV

TL;DR: DP-TTA利用TEM信号的物理特性作为先验知识，通过字典学习和自监督损失动态适应新环境，显著提升去噪性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在跨地域应用时因噪声特性差异导致性能下降，需利用TEM信号的固有物理特性（如指数衰减和平滑性）作为先验知识提升适应性。

Method: 提出了Dictionary-driven Prior Regularization Test-time Adaptation (DP-TTA)方法，结合字典学习和自监督损失，动态调整预训练模型参数以适应新环境。

Result: 实验结果表明，DP-TTA方法在多种场景下均优于现有TEM去噪方法和TTA方法。

Conclusion: DP-TTA方法通过利用TEM信号的固有物理特性作为先验知识，显著提高了在新环境中的去噪性能，优于现有的TEM去噪方法和TTA方法。

Abstract: Transient Electromagnetic (TEM) method is widely used in various geophysical
applications, providing valuable insights into subsurface properties. However,
time-domain TEM signals are often submerged in various types of noise. While
recent deep learning-based denoising models have shown strong performance,
these models are mostly trained on simulated or single real-world scenario
data, overlooking the significant differences in noise characteristics from
different geographical regions. Intuitively, models trained in one environment
often struggle to perform well in new settings due to differences in geological
conditions, equipment, and external interference, leading to reduced denoising
performance. To this end, we propose the Dictionary-driven Prior Regularization
Test-time Adaptation (DP-TTA). Our key insight is that TEM signals possess
intrinsic physical characteristics, such as exponential decay and smoothness,
which remain consistent across different regions regardless of external
conditions. These intrinsic characteristics serve as ideal prior knowledge for
guiding the TTA strategy, which helps the pre-trained model dynamically adjust
parameters by utilizing self-supervised losses, improving denoising performance
in new scenarios. To implement this, we customized a network, named DTEMDNet.
Specifically, we first use dictionary learning to encode these intrinsic
characteristics as a dictionary-driven prior, which is integrated into the
model during training. At the testing stage, this prior guides the model to
adapt dynamically to new environments by minimizing self-supervised losses
derived from the dictionary-driven consistency and the signal one-order
variation. Extensive experimental results demonstrate that the proposed method
achieves much better performance than existing TEM denoising methods and TTA
methods.

</details>


### [26] [STT-GS: Sample-Then-Transmit Edge Gaussian Splatting with Joint Client Selection and Power Control](https://arxiv.org/abs/2510.13186)
*Zhen Li,Xibin Jin,Guoliang Li,Shuai Wang,Miaowen Wen,Huseyin Arslan,Derrick Wing Kwan Ng,Chengzhong Xu*

Main category: cs.CV

TL;DR: 本文提出了一种针对边缘高斯泼溅（EGS）的样本后传输策略（STT-GS），通过特征域聚类和试点传输优化，联合客户端选择和功率控制框架，显著提升了场景重建质量并降低了通信成本。


<details>
  <summary>Details</summary>
Motivation: 边缘高斯泼溅（EGS）是一种新兴的场景重建范式，但传统边缘资源管理方法无法直接适用于EGS，因为它们侧重于通信吞吐量或通用学习性能。本文旨在最大化GS质量，解决现有方法不适用的问题。

Method: 本文提出了一种基于样本后传输的EGS策略（STT-GS），包括特征域聚类（FDC）方案和试点传输时间最小化（PTTM），以减少试点开销。随后，开发了一个联合客户端选择和功率控制（JCSPC）框架，并基于惩罚交替主优化最小化（PAMM）算法提出了一种低复杂度高效解决方案。

Result: 提出的STT-GS策略通过两阶段评估优先分配通信资源给更有价值的客户端，实验证明该方法显著优于现有基准方法，并实现了低采样比例下的准确预测和优秀权衡。

Conclusion: 实验结果表明，所提出的方案在真实数据集上显著优于现有基准方法，且能够在低采样比例（如10%）下准确预测GS导向目标，实现了视角贡献与通信成本的优秀权衡。

Abstract: Edge Gaussian splatting (EGS), which aggregates data from distributed clients
and trains a global GS model at the edge server, is an emerging paradigm for
scene reconstruction. Unlike traditional edge resource management methods that
emphasize communication throughput or general-purpose learning performance, EGS
explicitly aims to maximize the GS qualities, rendering existing approaches
inapplicable. To address this problem, this paper formulates a novel
GS-oriented objective function that distinguishes the heterogeneous view
contributions of different clients. However, evaluating this function in turn
requires clients' images, leading to a causality dilemma. To this end, this
paper further proposes a sample-then-transmit EGS (or STT-GS for short)
strategy, which first samples a subset of images as pilot data from each client
for loss prediction. Based on the first-stage evaluation, communication
resources are then prioritized towards more valuable clients. To achieve
efficient sampling, a feature-domain clustering (FDC) scheme is proposed to
select the most representative data and pilot transmission time minimization
(PTTM) is adopted to reduce the pilot overhead.Subsequently, we develop a joint
client selection and power control (JCSPC) framework to maximize the
GS-oriented function under communication resource constraints. Despite the
nonconvexity of the problem, we propose a low-complexity efficient solution
based on the penalty alternating majorization minimization (PAMM) algorithm.
Experiments unveil that the proposed scheme significantly outperforms existing
benchmarks on real-world datasets. It is found that the GS-oriented objective
can be accurately predicted with low sampling ratios (e.g.,10%), and our method
achieves an excellent tradeoff between view contributions and communication
costs.

</details>


### [27] [Complementary Information Guided Occupancy Prediction via Multi-Level Representation Fusion](https://arxiv.org/abs/2510.13198)
*Rongtao Xu,Jinzhou Lin,Jialei Zhou,Jiahua Dong,Changwei Wang,Ruisheng Wang,Li Guo,Shibiao Xu,Xiaodan Liang*

Main category: cs.CV

TL;DR: CIGOcc是一个两阶段占用预测框架，通过多级特征融合和知识蒸馏技术，显著提升了相机占用预测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过结构改进（如轻量级骨干网络和复杂级联框架）来提升性能，但性能提升有限。很少有研究从表示融合的角度探索，导致2D图像中丰富的特征多样性未被充分利用。

Method: CIGOcc是一个基于多级表示融合的两阶段占用预测框架，从输入图像中提取分割、图形和深度特征，并引入可变形多级融合机制来融合这三种多级特征。此外，CIGOcc还结合了从SAM中蒸馏的知识以进一步提高预测准确性。

Result: CIGOcc在SemanticKITTI基准测试中实现了最先进的性能。

Conclusion: CIGOcc通过多级特征融合和知识蒸馏技术，在不增加训练成本的情况下，在SemanticKITTI基准测试中实现了最先进的性能。

Abstract: Camera-based occupancy prediction is a mainstream approach for 3D perception
in autonomous driving, aiming to infer complete 3D scene geometry and semantics
from 2D images. Almost existing methods focus on improving performance through
structural modifications, such as lightweight backbones and complex cascaded
frameworks, with good yet limited performance. Few studies explore from the
perspective of representation fusion, leaving the rich diversity of features in
2D images underutilized. Motivated by this, we propose \textbf{CIGOcc, a
two-stage occupancy prediction framework based on multi-level representation
fusion. \textbf{CIGOcc extracts segmentation, graphics, and depth features from
an input image and introduces a deformable multi-level fusion mechanism to fuse
these three multi-level features. Additionally, CIGOcc incorporates knowledge
distilled from SAM to further enhance prediction accuracy. Without increasing
training costs, CIGOcc achieves state-of-the-art performance on the
SemanticKITTI benchmark. The code is provided in the supplementary material and
will be released https://github.com/VitaLemonTea1/CIGOcc

</details>


### [28] [Paper Copilot: Tracking the Evolution of Peer Review in AI Conferences](https://arxiv.org/abs/2510.13201)
*Jing Yang,Qiyao Wei,Jiaxin Pei*

Main category: cs.CV

TL;DR: Paper Copilot 是一个系统，通过创建同行评审的数字存档和开放数据集，支持对评审系统的透明化和改进研究。


<details>
  <summary>Details</summary>
Motivation: AI 会议的快速增长导致同行评审系统压力剧增，出现评审质量下降、标准不一等问题，亟需透明化和改进。

Method: 开发了 Paper Copilot 系统，创建了计算机科学领域多个会议的同行评审数字存档，并进行了 ICLR 多年评审的大规模实证分析。

Result: 发布了 Paper Copilot 的基础设施和数据集，支持对同行评审演化的可重复研究。

Conclusion: Paper Copilot 通过提供持久的数字存档和开放数据集，支持对同行评审系统的可重复研究，旨在促进更稳健、透明和可靠的评审系统。

Abstract: The rapid growth of AI conferences is straining an already fragile
peer-review system, leading to heavy reviewer workloads, expertise mismatches,
inconsistent evaluation standards, superficial or templated reviews, and
limited accountability under compressed timelines. In response, conference
organizers have introduced new policies and interventions to preserve review
standards. Yet these ad-hoc changes often create further concerns and confusion
about the review process, leaving how papers are ultimately accepted - and how
practices evolve across years - largely opaque. We present Paper Copilot, a
system that creates durable digital archives of peer reviews across a wide
range of computer-science venues, an open dataset that enables researchers to
study peer review at scale, and a large-scale empirical analysis of ICLR
reviews spanning multiple years. By releasing both the infrastructure and the
dataset, Paper Copilot supports reproducible research on the evolution of peer
review. We hope these resources help the community track changes, diagnose
failure modes, and inform evidence-based improvements toward a more robust,
transparent, and reliable peer-review system.

</details>


### [29] [MimicParts: Part-aware Style Injection for Speech-Driven 3D Motion Generation](https://arxiv.org/abs/2510.13208)
*Lianlian Liu,YongKang He,Zhaojie Chu,Xiaofen Xing,Xiangmin Xu*

Main category: cs.CV

TL;DR: MimicParts通过区域感知风格注入和注意力机制，生成更自然和表现力强的3D人体运动，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在风格编码上过于简化或忽略区域差异，且未能动态适应语音节奏和情感变化，限制了运动生成的真实感。

Method: 提出MimicParts框架，包括区域感知风格编码和区域感知注意力块，以捕捉局部运动风格差异并动态适应语音节奏和情感变化。

Result: 实验结果表明，MimicParts在自然性和表现力上优于现有方法。

Conclusion: MimicParts框架通过区域感知风格注入和去噪网络，显著提升了基于语音的3D人体运动生成的自然性和表现力。

Abstract: Generating stylized 3D human motion from speech signals presents substantial
challenges, primarily due to the intricate and fine-grained relationships among
speech signals, individual styles, and the corresponding body movements.
Current style encoding approaches either oversimplify stylistic diversity or
ignore regional motion style differences (e.g., upper vs. lower body), limiting
motion realism. Additionally, motion style should dynamically adapt to changes
in speech rhythm and emotion, but existing methods often overlook this. To
address these issues, we propose MimicParts, a novel framework designed to
enhance stylized motion generation based on part-aware style injection and
part-aware denoising network. It divides the body into different regions to
encode localized motion styles, enabling the model to capture fine-grained
regional differences. Furthermore, our part-aware attention block allows rhythm
and emotion cues to guide each body region precisely, ensuring that the
generated motion aligns with variations in speech rhythm and emotional state.
Experimental results show that our method outperforming existing methods
showcasing naturalness and expressive 3D human motion sequences.

</details>


### [30] [Prompt-based Adaptation in Large-scale Vision Models: A Survey](https://arxiv.org/abs/2510.13219)
*Xi Xiao,Yunbei Zhang,Lin Zhao,Yiyang Liu,Xiaoying Liao,Zheda Mai,Xingjian Li,Xiao Wang,Hao Xu,Jihun Hamm,Xue Lin,Min Xu,Qifan Wang,Tianyang Wang,Cheng Han*

Main category: cs.CV

TL;DR: 该综述首次系统梳理了视觉提示适应的核心方法及其应用，提出了统一框架PA，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 由于当前研究中VP和VPT的界限模糊，缺乏系统区分，因此需要澄清这些技术及其应用。

Method: 通过从第一原理重新审视视觉提示（VP）和视觉提示调优（VPT）的设计，提出了一个统一框架——基于提示的适应（PA），并提供了分类法来组织现有方法。

Result: 提出了PA框架，总结了现有方法，并探讨了其在多个领域的应用及挑战。

Conclusion: 该综述首次全面梳理了提示适应的核心方法及其应用，为研究人员提供了清晰的路线图，并指出了未来研究的关键方向。

Abstract: In computer vision, Visual Prompting (VP) and Visual Prompt Tuning (VPT) have
recently emerged as lightweight and effective alternatives to full fine-tuning
for adapting large-scale vision models within the ``pretrain-then-finetune''
paradigm. However, despite rapid progress, their conceptual boundaries remain
blurred, as VP and VPT are frequently used interchangeably in current research,
reflecting a lack of systematic distinction between these techniques and their
respective applications. In this survey, we revisit the designs of VP and VPT
from first principles, and conceptualize them within a unified framework termed
Prompt-based Adaptation (PA). We provide a taxonomy that categorizes existing
methods into learnable, generative, and non-learnable prompts, and further
organizes them by injection granularity -- pixel-level and token-level. Beyond
the core methodologies, we examine PA's integrations across diverse domains,
including medical imaging, 3D point clouds, and vision-language tasks, as well
as its role in test-time adaptation and trustworthy AI. We also summarize
current benchmarks and identify key challenges and future directions. To the
best of our knowledge, we are the first comprehensive survey dedicated to PA's
methodologies and applications in light of their distinct characteristics. Our
survey aims to provide a clear roadmap for researchers and practitioners in all
area to understand and explore the evolving landscape of PA-related research.

</details>


### [31] [Sample-Centric Multi-Task Learning for Detection and Segmentation of Industrial Surface Defects](https://arxiv.org/abs/2510.13226)
*Hang-Cheng Dong,Yibo Jiao,Fupeng Wei,Guodong Liu,Dong Ye,Bingguo Liu*

Main category: cs.CV

TL;DR: 提出样本中心多任务学习框架，通过联合学习样本级分类和像素级定位，解决工业缺陷检测中的样本级稳定性问题，提升决策可靠性。


<details>
  <summary>Details</summary>
Motivation: 工业表面缺陷检测中的极端前景-背景不平衡、缺陷稀疏性及低对比度问题导致现有模型在样本级别稳定性不足，尤其是对稀疏或细长缺陷。优化目标与QC决策粒度不匹配是根本原因。

Method: 基于共享编码器架构，该方法联合学习样本级缺陷分类和像素级掩模定位。样本级监督调制特征分布，并在梯度层面持续提升对小缺陷和低对比度缺陷的召回率，而分割分支保留边界和形状细节以增强每个样本的决策稳定性并减少遗漏。

Result: 在两个基准数据集上的实验表明，该方法显著提升了样本级决策的可靠性和缺陷定位的完整性。

Conclusion: 提出的样本中心多任务学习框架和评估套件显著提高了样本级决策的可靠性和缺陷定位的完整性。

Abstract: Industrial surface defect inspection for sample-wise quality control (QC)
must simultaneously decide whether a given sample contains defects and localize
those defects spatially. In real production lines, extreme
foreground-background imbalance, defect sparsity with a long-tailed scale
distribution, and low contrast are common. As a result, pixel-centric training
and evaluation are easily dominated by large homogeneous regions, making it
difficult to drive models to attend to small or low-contrast defects-one of the
main bottlenecks for deployment. Empirically, existing models achieve strong
pixel-overlap metrics (e.g., mIoU) but exhibit insufficient stability at the
sample level, especially for sparse or slender defects. The root cause is a
mismatch between the optimization objective and the granularity of QC
decisions. To address this, we propose a sample-centric multi-task learning
framework and evaluation suite. Built on a shared-encoder architecture, the
method jointly learns sample-level defect classification and pixel-level mask
localization. Sample-level supervision modulates the feature distribution and,
at the gradient level, continually boosts recall for small and low-contrast
defects, while the segmentation branch preserves boundary and shape details to
enhance per-sample decision stability and reduce misses. For evaluation, we
propose decision-linked metrics, Seg_mIoU and Seg_Recall, which remove the bias
of classical mIoU caused by empty or true-negative samples and tightly couple
localization quality with sample-level decisions. Experiments on two benchmark
datasets demonstrate that our approach substantially improves the reliability
of sample-level decisions and the completeness of defect localization.

</details>


### [32] [What "Not" to Detect: Negation-Aware VLMs via Structured Reasoning and Token Merging](https://arxiv.org/abs/2510.13232)
*Inha Kang,Youngsun Lim,Seonho Lee,Jiho Choi,Junsuk Choe,Hyunjung Shim*

Main category: cs.CV

TL;DR: 论文提出CoVAND数据集和NegToMe模块，有效解决视觉语言模型的否定理解问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在否定理解上存在严重缺陷（肯定性偏见），尤其在描述性目标检测任务中表现明显。论文旨在解决这一局限性。

Method: 论文提出两个主要贡献：(1) CoVAND数据集，通过系统化的思维链和VQA流程生成高质量的实例接地否定数据；(2) NegToMe模块，通过合并否定词与属性为连贯语义短语，解决否定线索在分词中的结构性丢失问题。

Result: NegToMe模块显著提升了模型在否定基准测试上的性能，降低了假阳性率，在OVDEval上NMS-AP提升了10.8分，并展示了在SoTA VLMs上的泛化能力。

Conclusion: 该论文通过提出CoVAND数据集和NegToMe模块，显著提升了视觉语言模型在否定理解上的性能，为实际检测应用中的否定理解问题提供了关键解决方案。

Abstract: State-of-the-art vision-language models (VLMs) suffer from a critical failure
in understanding negation, often referred to as affirmative bias. This
limitation is particularly severe in described object detection (DOD) tasks. To
address this, we propose two primary contributions: (1) a new dataset pipeline
and (2) a novel, lightweight adaptation recipe. First, we introduce CoVAND, a
dataset constructed with a systematic chain-of-thought (CoT) and VQA-based
pipeline to generate high-quality, instance-grounded negation data. Second, we
propose NegToMe, a novel text token merging module that directly tackles the
architectural cause of affirmative bias. NegToMe fundamentally addresses the
structural loss of negation cues in tokenization, grouping them with attributes
into coherent semantic phrases. It maintains correct polarity at the input
level, enabling robust negation understanding even with limited data. For
instance, to prevent a model from treating the fragmented tokens "not" and
"girl" as simply "girl", NegToMe binds them into a single token whose meaning
is correctly distinguished from that of "girl" alone. This module is integrated
with a parameter-efficient and strategic LoRA fine-tuning approach. Our method
significantly improves performance on challenging negation benchmarks with a
lowered false positive rate, boosting NMS-AP by up to +10.8 points on OVDEval
and demonstrating generalization to SoTA VLMs. This work marks a crucial step
forward in addressing negation understanding for real-world detection
applications.

</details>


### [33] [UniVector: Unified Vector Extraction via Instance-Geometry Interaction](https://arxiv.org/abs/2510.13234)
*Yinglong Yan,Jun Yue,Shaobo Xia,Hanmeng Sun,Tianxu Ying,Chengcheng Wu,Sifan Lan,Min He,Pedram Ghamisi,Leyuan Fang*

Main category: cs.CV

TL;DR: UniVector是一个统一矢量提取框架，通过实例-几何交互提取多种矢量类型，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常针对单一矢量类型，无法捕捉复杂结构。受人类大脑语义和空间交互的启发，提出统一框架以解决这一问题。

Method: UniVector利用实例-几何交互，通过结构化查询编码矢量信息，并通过交互模块迭代更新。动态形状约束进一步优化全局结构和关键点。

Result: 实验表明UniVector在单结构和多结构任务中均达到最先进水平。

Conclusion: UniVector通过统一的框架成功提取多种矢量类型，并在单结构和多结构任务中均达到最先进水平。

Abstract: Vector extraction retrieves structured vector geometry from raster images,
offering high-fidelity representation and broad applicability. Existing
methods, however, are usually tailored to a single vector type (e.g., polygons,
polylines, line segments), requiring separate models for different structures.
This stems from treating instance attributes (category, structure) and
geometric attributes (point coordinates, connections) independently, limiting
the ability to capture complex structures. Inspired by the human brain's
simultaneous use of semantic and spatial interactions in visual perception, we
propose UniVector, a unified VE framework that leverages instance-geometry
interaction to extract multiple vector types within a single model. UniVector
encodes vectors as structured queries containing both instance- and
geometry-level information, and iteratively updates them through an interaction
module for cross-level context exchange. A dynamic shape constraint further
refines global structures and key points. To benchmark multi-structure
scenarios, we introduce the Multi-Vector dataset with diverse polygons,
polylines, and line segments. Experiments show UniVector sets a new state of
the art on both single- and multi-structure VE tasks. Code and dataset will be
released at https://github.com/yyyyll0ss/UniVector.

</details>


### [34] [EPIPTrack: Rethinking Prompt Modeling with Explicit and Implicit Prompts for Multi-Object Tracking](https://arxiv.org/abs/2510.13235)
*Yukuan Zhang,Jiarui Zhao,Shangqing Nie,Jin Kuang,Shengsheng Wang*

Main category: cs.CV

TL;DR: EPIPTrack是一个多模态视觉-语言跟踪框架，通过动态调整的显式和隐式提示提升目标跟踪性能，实验证明其在多种场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大型语言模型的静态文本描述，缺乏对实时目标状态变化的适应性且容易产生幻觉。为了解决这些问题，提出了EPIPTrack框架。

Method: 提出了一个统一的多模态视觉-语言跟踪框架EPIPTrack，利用显式和隐式提示进行动态目标建模和语义对齐。显式提示将空间运动信息转化为自然语言描述，隐式提示结合伪词和可学习描述符构建个体化知识表示。通过CLIP文本编码器动态调整提示，并设计了鉴别性特征增强器来增强视觉和跨模态表示。

Result: 在MOT17、MOT20和DanceTrack上的大量实验表明，EPIPTrack在多样场景中优于现有跟踪器。

Conclusion: EPIPTrack通过结合显式和隐式提示，实现了动态目标建模和语义对齐，展现出强大的适应性和卓越的性能。

Abstract: Multimodal semantic cues, such as textual descriptions, have shown strong
potential in enhancing target perception for tracking. However, existing
methods rely on static textual descriptions from large language models, which
lack adaptability to real-time target state changes and prone to
hallucinations. To address these challenges, we propose a unified multimodal
vision-language tracking framework, named EPIPTrack, which leverages explicit
and implicit prompts for dynamic target modeling and semantic alignment.
Specifically, explicit prompts transform spatial motion information into
natural language descriptions to provide spatiotemporal guidance. Implicit
prompts combine pseudo-words with learnable descriptors to construct
individualized knowledge representations capturing appearance attributes. Both
prompts undergo dynamic adjustment via the CLIP text encoder to respond to
changes in target state. Furthermore, we design a Discriminative Feature
Augmentor to enhance visual and cross-modal representations. Extensive
experiments on MOT17, MOT20, and DanceTrack demonstrate that EPIPTrack
outperforms existing trackers in diverse scenarios, exhibiting robust
adaptability and superior performance.

</details>


### [35] [Through the Lens of Doubt: Robust and Efficient Uncertainty Estimation for Visual Place Recognition](https://arxiv.org/abs/2510.13464)
*Emily Miller,Michael Milford,Muhammad Burhan Hafez,SD Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 本文提出三种无需训练的不确定性度量方法，显著提升VPR匹配的鲁棒性和实时性。


<details>
  <summary>Details</summary>
Motivation: VPR系统在视觉环境、光照条件和季节变化等不同场景下表现不稳定，尤其是在SLAM等关键应用中需要更鲁棒的匹配不确定性估计。

Method: 提出了三种无需训练的不确定性度量方法：相似性分布（SD）、比例扩展（RS）和统计不确定性（SU），通过分析VPR方法中的相似性分数来估计预测置信度。

Result: 在九种先进的VPR方法和六个基准数据集上的实验表明，这三种度量方法能有效区分正确和错误的匹配，且计算开销极低，适用于实时应用。

Conclusion: 本文提出的三种无需训练的VPR不确定性度量方法（SD、RS、SU）在多个VPR方法和数据集上表现出色，显著提升了匹配精度和召回率，适用于实时机器人应用。

Abstract: Visual Place Recognition (VPR) enables robots and autonomous vehicles to
identify previously visited locations by matching current observations against
a database of known places. However, VPR systems face significant challenges
when deployed across varying visual environments, lighting conditions, seasonal
changes, and viewpoints changes. Failure-critical VPR applications, such as
loop closure detection in simultaneous localization and mapping (SLAM)
pipelines, require robust estimation of place matching uncertainty. We propose
three training-free uncertainty metrics that estimate prediction confidence by
analyzing inherent statistical patterns in similarity scores from any existing
VPR method. Similarity Distribution (SD) quantifies match distinctiveness by
measuring score separation between candidates; Ratio Spread (RS) evaluates
competitive ambiguity among top-scoring locations; and Statistical Uncertainty
(SU) is a combination of SD and RS that provides a unified metric that
generalizes across datasets and VPR methods without requiring validation data
to select the optimal metric. All three metrics operate without additional
model training, architectural modifications, or computationally expensive
geometric verification. Comprehensive evaluation across nine state-of-the-art
VPR methods and six benchmark datasets confirms that our metrics excel at
discriminating between correct and incorrect VPR matches, and consistently
outperform existing approaches while maintaining negligible computational
overhead, making it deployable for real-time robotic applications across varied
environmental conditions with improved precision-recall performance.

</details>


### [36] [Model-agnostic Adversarial Attack and Defense for Vision-Language-Action Models](https://arxiv.org/abs/2510.13237)
*Haochuan Xu,Yun Sing Koh,Shuhuai Huang,Zirun Zhou,Di Wang,Jun Sakuma,Jingfeng Zhang*

Main category: cs.CV

TL;DR: 研究提出针对VLA模型的对抗补丁攻击EDPA及防御策略，通过破坏视觉-文本对齐及潜在表示差异生成补丁，防御方法通过对抗微调视觉编码器缓解攻击效果。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在机器人学习中取得了革命性进展，但其对抗鲁棒性尚未得到充分探索。

Method: 提出Embedding Disruption Patch Attack（EDPA），通过破坏视觉与文本潜在表示的语义对齐及最大化对抗性与干净视觉输入潜在表示的差异来生成对抗补丁；同时提出针对视觉编码器的对抗微调方案。

Result: 在LIBERO机器人仿真基准测试中，EDPA显著增加了尖端VLA模型的任务失败率，而防御方法有效缓解了性能下降。

Conclusion: 本研究提出了针对VLA模型的对抗性补丁攻击（EDPA）及相应的防御策略，通过广泛评估证明了EDPA能显著增加VLA模型的任务失败率，而提出的防御方法有效缓解了这种性能下降。

Abstract: Vision-Language-Action (VLA) models have achieved revolutionary progress in
robot learning, enabling robots to execute complex physical robot tasks from
natural language instructions. Despite this progress, their adversarial
robustness remains underexplored. In this work, we propose both adversarial
patch attack and corresponding defense strategies for VLA models. We first
introduce the Embedding Disruption Patch Attack (EDPA), a model-agnostic
adversarial attack that generates patches directly placeable within the
camera's view. In comparison to prior methods, EDPA can be readily applied to
different VLA models without requiring prior knowledge of the model
architecture, or the controlled robotic manipulator. EDPA constructs these
patches by (i) disrupting the semantic alignment between visual and textual
latent representations, and (ii) maximizing the discrepancy of latent
representations between adversarial and corresponding clean visual inputs.
Through the optimization of these objectives, EDPA distorts the VLA's
interpretation of visual information, causing the model to repeatedly generate
incorrect actions and ultimately result in failure to complete the given
robotic task. To counter this, we propose an adversarial fine-tuning scheme for
the visual encoder, in which the encoder is optimized to produce similar latent
representations for both clean and adversarially perturbed visual inputs.
Extensive evaluations on the widely recognized LIBERO robotic simulation
benchmark demonstrate that EDPA substantially increases the task failure rate
of cutting-edge VLA models, while our proposed defense effectively mitigates
this degradation. The codebase is accessible via the homepage at
https://edpa-attack.github.io/.

</details>


### [37] [Accelerated Feature Detectors for Visual SLAM: A Comparative Study of FPGA vs GPU](https://arxiv.org/abs/2510.13546)
*Ruiqi Ye,Mikel Luján*

Main category: cs.CV

TL;DR: 比较GPU和FPGA加速特征检测在V-SLAM中的表现：GPU适合非学习型检测器，FPGA在SuperPoint中更优，但GPU总体更准确。


<details>
  <summary>Details</summary>
Motivation: 研究硬件加速（GPU和FPGA）对V-SLAM中特征检测模块的性能和能效影响，以应对功耗受限平台（如无人机）的需求。

Method: 比较GPU和FPGA加速的FAST、Harris和SuperPoint检测器在现代SoC（Nvidia Jetson Orin和AMD Versal）上的性能。

Result: GPU在非学习型检测器中表现更优，而FPGA在SuperPoint中性能提升3.1倍、能效提升1.4倍。FPGA加速的V-SLAM在部分数据集上帧率更高，但GPU总体更准确。

Conclusion: 硬件加速的特征检测在V-SLAM中表现优异，尤其是FPGA在基于学习的检测器（如SuperPoint）中表现优于GPU，但在非学习型检测器（如FAST和Harris）中GPU更具优势。

Abstract: Feature detection is a common yet time-consuming module in Simultaneous
Localization and Mapping (SLAM) implementations, which are increasingly
deployed on power-constrained platforms, such as drones. Graphics Processing
Units (GPUs) have been a popular accelerator for computer vision in general,
and feature detection and SLAM in particular.
  On the other hand, System-on-Chips (SoCs) with integrated Field Programmable
Gate Array (FPGA) are also widely available. This paper presents the first
study of hardware-accelerated feature detectors considering a Visual SLAM
(V-SLAM) pipeline. We offer new insights by comparing the best GPU-accelerated
FAST, Harris, and SuperPoint implementations against the FPGA-accelerated
counterparts on modern SoCs (Nvidia Jetson Orin and AMD Versal).
  The evaluation shows that when using a non-learning-based feature detector
such as FAST and Harris, their GPU implementations, and the GPU-accelerated
V-SLAM can achieve better run-time performance and energy efficiency than the
FAST and Harris FPGA implementations as well as the FPGA-accelerated V-SLAM.
However, when considering a learning-based detector such as SuperPoint, its
FPGA implementation can achieve better run-time performance and energy
efficiency (up to 3.1$\times$ and 1.4$\times$ improvements, respectively) than
the GPU implementation. The FPGA-accelerated V-SLAM can also achieve comparable
run-time performance compared to the GPU-accelerated V-SLAM, with better FPS in
2 out of 5 dataset sequences. When considering the accuracy, the results show
that the GPU-accelerated V-SLAM is more accurate than the FPGA-accelerated
V-SLAM in general. Last but not least, the use of hardware acceleration for
feature detection could further improve the performance of the V-SLAM pipeline
by having the global bundle adjustment module invoked less frequently without
sacrificing accuracy.

</details>


### [38] [FlyAwareV2: A Multimodal Cross-Domain UAV Dataset for Urban Scene Understanding](https://arxiv.org/abs/2510.13243)
*Francesco Barbato,Matteo Caligiuri,Pietro Zanuttigh*

Main category: cs.CV

TL;DR: FlyAwareV2是一个多模态无人机数据集，旨在解决真实数据收集和标注的挑战，支持城市场景理解研究。


<details>
  <summary>Details</summary>
Motivation: 由于收集和标注真实无人机数据成本高昂且困难，需要一种替代方案来支持计算机视觉算法的开发。

Method: 提出了FlyAwareV2数据集，包含真实和合成的无人机图像，涵盖RGB、深度和语义标签等多模态数据，并在不同环境条件下进行了测试。

Result: FlyAwareV2数据集引入了多模态数据、深度图、语义分割基准以及合成到真实域适应的研究，为研究提供了全面的资源。

Conclusion: FlyAwareV2数据集为无人机在城市环境中的3D场景理解研究提供了宝贵的资源，通过丰富的注释和环境多样性，支持了算法的开发与评估。

Abstract: The development of computer vision algorithms for Unmanned Aerial Vehicle
(UAV) applications in urban environments heavily relies on the availability of
large-scale datasets with accurate annotations. However, collecting and
annotating real-world UAV data is extremely challenging and costly. To address
this limitation, we present FlyAwareV2, a novel multimodal dataset encompassing
both real and synthetic UAV imagery tailored for urban scene understanding
tasks. Building upon the recently introduced SynDrone and FlyAware datasets,
FlyAwareV2 introduces several new key contributions: 1) Multimodal data (RGB,
depth, semantic labels) across diverse environmental conditions including
varying weather and daytime; 2) Depth maps for real samples computed via
state-of-the-art monocular depth estimation; 3) Benchmarks for RGB and
multimodal semantic segmentation on standard architectures; 4) Studies on
synthetic-to-real domain adaptation to assess the generalization capabilities
of models trained on the synthetic data. With its rich set of annotations and
environmental diversity, FlyAwareV2 provides a valuable resource for research
on UAV-based 3D urban scene understanding.

</details>


### [39] [CymbaDiff: Structured Spatial Diffusion for Sketch-based 3D Semantic Urban Scene Generation](https://arxiv.org/abs/2510.13245)
*Li Liang,Bo Miao,Xinyu Wang,Naveed Akhtar,Jordan Vice,Ajmal Mian*

Main category: cs.CV

TL;DR: 介绍了SketchSem3D数据集和CymbaDiff方法，显著提升了室外3D语义场景生成的质量。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏公开且标注良好的数据集限制了室外3D语义场景生成的发展，因此引入了SketchSem3D这一大规模基准数据集。

Method: 提出了Cylinder Mamba Diffusion (CymbaDiff)，通过结构化空间排序、显式捕捉圆柱连续性和垂直层次，以及保持物理邻域关系和全局上下文，显著增强了室外3D场景生成的空间连贯性。

Result: 在SketchSem3D上的大量实验表明，CymbaDiff在语义一致性、空间真实性和跨数据集泛化方面表现优异。

Conclusion: CymbaDiff在SketchSem3D数据集上表现出色，显著提升了室外3D场景生成的语义一致性和空间真实性，并展示了跨数据集的泛化能力。

Abstract: Outdoor 3D semantic scene generation produces realistic and semantically rich
environments for applications such as urban simulation and autonomous driving.
However, advances in this direction are constrained by the absence of publicly
available, well-annotated datasets. We introduce SketchSem3D, the first
large-scale benchmark for generating 3D outdoor semantic scenes from abstract
freehand sketches and pseudo-labeled annotations of satellite images.
SketchSem3D includes two subsets, Sketch-based SemanticKITTI and Sketch-based
KITTI-360 (containing LiDAR voxels along with their corresponding sketches and
annotated satellite images), to enable standardized, rigorous, and diverse
evaluations. We also propose Cylinder Mamba Diffusion (CymbaDiff) that
significantly enhances spatial coherence in outdoor 3D scene generation.
CymbaDiff imposes structured spatial ordering, explicitly captures cylindrical
continuity and vertical hierarchy, and preserves both physical neighborhood
relationships and global context within the generated scenes. Extensive
experiments on SketchSem3D demonstrate that CymbaDiff achieves superior
semantic consistency, spatial realism, and cross-dataset generalization. The
code and dataset will be available at
https://github.com/Lillian-research-hub/CymbaDiff

</details>


### [40] [Real-Time Crowd Counting for Embedded Systems with Lightweight Architecture](https://arxiv.org/abs/2510.13250)
*Zhiyuan Zhao,Yubin Wen,Siyu Yang,Lichen Ning,Yuandong Liu,Junyu Gao*

Main category: cs.CV

TL;DR: 提出了一种超实时人群计数模型，结合大卷积核和轻量级设计，在嵌入式系统上实现最快推理速度，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的人群计数方法在嵌入式系统上存在模型参数过多、计算复杂等问题，无法满足实时性需求。

Method: 设计了一个具有stem-encoder-decoder结构的超实时模型，采用大卷积核扩大感受野，结合条件通道加权和多分支局部融合块以低计算成本合并多尺度特征，并添加特征金字塔网络以缓解不完全融合问题。

Result: 在三个基准测试中，该网络在NVIDIA GTX 1080Ti上达到381.7 FPS，在NVIDIA Jetson TX1上达到71.9 FPS，推理速度最快。

Conclusion: 该论文提出的模型在嵌入式系统上实现了超实时的人群计数，同时保持了竞争力的准确性，推理速度是最快的。

Abstract: Crowd counting is a task of estimating the number of the crowd through
images, which is extremely valuable in the fields of intelligent security,
urban planning, public safety management, and so on. However, the existing
counting methods have some problems in practical application on embedded
systems for these fields, such as excessive model parameters, abundant complex
calculations, etc. The practical application of embedded systems requires the
model to be real-time, which means that the model is fast enough. Considering
the aforementioned problems, we design a super real-time model with a
stem-encoder-decoder structure for crowd counting tasks, which achieves the
fastest inference compared with state-of-the-arts. Firstly, large convolution
kernels in the stem network are used to enlarge the receptive field, which
effectively extracts detailed head information. Then, in the encoder part, we
use conditional channel weighting and multi-branch local fusion block to merge
multi-scale features with low computational consumption. This part is crucial
to the super real-time performance of the model. Finally, the feature pyramid
networks are added to the top of the encoder to alleviate its incomplete fusion
problems. Experiments on three benchmarks show that our network is suitable for
super real-time crowd counting on embedded systems, ensuring competitive
accuracy. At the same time, the proposed network reasoning speed is the
fastest. Specifically, the proposed network achieves 381.7 FPS on NVIDIA GTX
1080Ti and 71.9 FPS on NVIDIA Jetson TX1.

</details>


### [41] [Self-Augmented Visual Contrastive Decoding](https://arxiv.org/abs/2510.13315)
*Eun Woo Im,Muhammad Kashif Ali,Vivek Gupta*

Main category: cs.CV

TL;DR: 研究提出了一种无训练解码策略，通过自增强提示和自适应阈值算法，显著提升大型视觉-语言模型的事实一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉对比解码方法因通用视觉增强而忽视文本查询特定上下文的问题，以提升大型视觉-语言模型的事实一致性。

Method: 提出了一种自增强提示策略和自适应阈值算法，动态对齐查询与视觉增强的语义，并基于输出稀疏性调整下一个令牌候选大小。

Result: 在四个大型视觉-语言模型和七个基准测试上的广泛实验表明，所提出的解码方法在事实一致性上显著优于现有最先进方法。

Conclusion: 本研究通过引入一种新颖的无训练解码策略，显著提升了大型视觉-语言模型的事实一致性，强调了查询依赖增强和熵感知解码在提升模型生成效果中的重要性。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable multimodal
capabilities, but they inherit the tendency to hallucinate from their
underlying language models. While visual contrastive decoding has been proposed
to mitigate this issue, existing methods often apply generic visual
augmentations that disregard the specific context provided by the text query,
limiting their effectiveness. This study introduces a novel training-free
decoding strategy that addresses these limitations, featuring two key
contributions. First, a self-augmentation prompting strategy that leverages the
intrinsic knowledge of the model to dynamically align semantics between the
query and the visual augmentation. Second, an adaptive thresholding algorithm
that adaptively adjusts next token candidate size based on the output sparsity,
utilizing full information from the logit distribution. Extensive experiments
across four LVLMs and seven benchmarks demonstrate that the proposed decoding
significantly enhances factual consistency compared to state-of-the-art
decoding methods. This work highlights the importance of integrating
query-dependent augmentation and entropy-aware decoding for improving effective
generation of LVLMs.

</details>


### [42] [Map the Flow: Revealing Hidden Pathways of Information in VideoLLMs](https://arxiv.org/abs/2510.13251)
*Minji Kim,Taekyung Kim,Bohyung Han*

Main category: cs.CV

TL;DR: 研究发现VideoLLMs在时间推理中通过特定层的信息流动模式实现高效问答，选择性信息路径可保持性能。


<details>
  <summary>Details</summary>
Motivation: 探索VideoLLMs在视频问答任务中如何提取和传播时空信息，以增强模型的可解释性和下游泛化能力。

Method: 使用机制解释性技术分析VideoLLMs的内部信息流动，揭示了跨帧交互和视频-语言整合的特定层模式。

Result: 揭示了VideoLLMs在早期至中层进行跨帧交互、中层进行视频-语言整合的模式，并证明通过选择有效信息路径可保持性能。

Conclusion: 研究发现VideoLLMs在时间推理中展现出特定的信息流动模式，通过选择性保留有效信息路径可以在保持性能的同时提高模型效率。

Abstract: Video Large Language Models (VideoLLMs) extend the capabilities of
vision-language models to spatiotemporal inputs, enabling tasks such as video
question answering (VideoQA). Despite recent advances in VideoLLMs, their
internal mechanisms on where and how they extract and propagate video and
textual information remain less explored. In this study, we investigate the
internal information flow of VideoLLMs using mechanistic interpretability
techniques. Our analysis reveals consistent patterns across diverse VideoQA
tasks: (1) temporal reasoning in VideoLLMs initiates with active cross-frame
interactions in early-to-middle layers, (2) followed by progressive
video-language integration in middle layers. This is facilitated by alignment
between video representations and linguistic embeddings containing temporal
concepts. (3) Upon completion of this integration, the model is ready to
generate correct answers in middle-to-late layers. (4) Based on our analysis,
we show that VideoLLMs can retain their VideoQA performance by selecting these
effective information pathways while suppressing a substantial amount of
attention edges, e.g., 58% in LLaVA-NeXT-7B-Video-FT. These findings provide a
blueprint on how VideoLLMs perform temporal reasoning and offer practical
insights for improving model interpretability and downstream generalization.
Our project page with the source code is available at
https://map-the-flow.github.io

</details>


### [43] [End-to-End Multi-Modal Diffusion Mamba](https://arxiv.org/abs/2510.13253)
*Chunhao Lu,Qiang Lu,Meichen Dong,Jake Luo*

Main category: cs.CV

TL;DR: MDM通过统一的变分自编码器和Mamba扩散模型统一多模态处理，在高维数据处理中表现卓越，优于现有端到端模型。


<details>
  <summary>Details</summary>
Motivation: 当前端到端多模态模型使用不同的编码器和解码器处理输入和输出信息，这种分离阻碍了多模态的联合表示学习。

Method: MDM采用基于Mamba的多步选择扩散模型，通过统一的变分自编码器逐步生成和细化模态特定信息。

Result: MDM在高分辨率图像生成和长文本序列生成等任务中表现优异，显著超越现有端到端模型，并与SOTA模型（如GPT-4V、Gemini Pro、Mistral）竞争。

Conclusion: MDM（多模态扩散Mamba）通过统一的变分自编码器实现了多模态处理的统一，并在保持计算效率的同时显著优于现有端到端模型，为多模态架构开辟了新方向。

Abstract: Current end-to-end multi-modal models utilize different encoders and decoders
to process input and output information. This separation hinders the joint
representation learning of various modalities. To unify multi-modal processing,
we propose a novel architecture called MDM (Multi-modal Diffusion Mamba). MDM
utilizes a Mamba-based multi-step selection diffusion model to progressively
generate and refine modality-specific information through a unified variational
autoencoder for both encoding and decoding. This innovative approach allows MDM
to achieve superior performance when processing high-dimensional data,
particularly in generating high-resolution images and extended text sequences
simultaneously. Our evaluations in areas such as image generation, image
captioning, visual question answering, text comprehension, and reasoning tasks
demonstrate that MDM significantly outperforms existing end-to-end models
(MonoFormer, LlamaGen, and Chameleon etc.) and competes effectively with SOTA
models like GPT-4V, Gemini Pro, and Mistral. Our results validate MDM's
effectiveness in unifying multi-modal processes while maintaining computational
efficiency, establishing a new direction for end-to-end multi-modal
architectures.

</details>


### [44] [Language as a Label: Zero-Shot Multimodal Classification of Everyday Postures under Data Scarcity](https://arxiv.org/abs/2510.13364)
*MingZe Tang,Jubal Chandy Jacob*

Main category: cs.CV

TL;DR: 研究发现，高性能视觉语言模型在零样本分类中，简单提示词设计效果最佳，增加细节反而降低性能（“提示过拟合”），而低性能模型在描述性提示下表现更好。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在零样本分类中表现出色，但提示词设计对识别视觉相似类别（如人体姿势）的影响尚未得到充分理解。本研究旨在探讨提示词特异性如何影响零样本分类性能。

Method: 研究使用了一套现代视觉语言模型（包括OpenCLIP、MetaCLIP 2和SigLip），在一个包含285张图像的COCO衍生数据集上，通过三级提示词设计系统地增加语言细节，评估了提示词特异性对零样本分类的影响。

Result: 对于高性能模型（MetaCLIP 2和OpenCLIP），最简单的提示词设计表现最佳（如MetaCLIP 2的多类准确率从68.8%降至55.1%）。而SigLip模型在提供更多描述性提示时，对模糊类别的分类效果有所提升。

Conclusion: 研究发现，对于性能最高的模型（如MetaCLIP 2和OpenCLIP），最简单、最基础的提示词设计反而能取得最佳效果，而增加描述性细节会显著降低性能，这种现象被称为“提示过拟合”。相反，性能较低的SigLip模型在提供更多基于身体线索的描述性提示时，对模糊类别的分类效果有所提升。

Abstract: Recent Vision-Language Models (VLMs) enable zero-shot classification by
aligning images and text in a shared space, a promising approach for
data-scarce conditions. However, the influence of prompt design on recognizing
visually similar categories, such as human postures, is not well understood.
This study investigates how prompt specificity affects the zero-shot
classification of sitting, standing, and walking/running on a small, 285-image
COCO-derived dataset. A suite of modern VLMs, including OpenCLIP, MetaCLIP 2,
and SigLip, were evaluated using a three-tiered prompt design that
systematically increases linguistic detail. Our findings reveal a compelling,
counter-intuitive trend: for the highest-performing models (MetaCLIP 2 and
OpenCLIP), the simplest, most basic prompts consistently achieve the best
results. Adding descriptive detail significantly degrades performance for
instance, MetaCLIP 2's multi-class accuracy drops from 68.8\% to 55.1\% a
phenomenon we term "prompt overfitting". Conversely, the lower-performing
SigLip model shows improved classification on ambiguous classes when given more
descriptive, body-cue-based prompts.

</details>


### [45] [MMLongCite: A Benchmark for Evaluating Fidelity of Long-Context Vision-Language Models](https://arxiv.org/abs/2510.13276)
*Keyan Zhou,Zecheng Tang,Lingfeng Ming,Guanghao Zhou,Qiguang Chen,Dan Qiao,Zheming Yang,Libo Qin,Minghui Qiu,Juntao Li,Min Zhang*

Main category: cs.CV

TL;DR: 论文介绍了MMLongCite，一个评估大型视觉语言模型在长上下文场景中忠实性的综合基准，发现现有模型在长多模态上下文处理上存在局限性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型的上下文窗口扩展迅速，但长上下文的有效利用仍是一个挑战，现有评估主要局限于文本领域或短上下文多模态场景。

Method: 提出MMLongCite基准，包含8个任务，覆盖6个上下文长度区间，整合文本、图像和视频等多种模态。

Result: 评估显示当前最先进的大型视觉语言模型在长多模态上下文处理上忠实性有限，并分析了上下文长度和关键内容位置对模型忠实性的影响。

Conclusion: MMLongCite填补了多模态长上下文评估的空白，揭示了现有模型的局限性，为未来研究提供了重要参考。

Abstract: The rapid advancement of large vision language models (LVLMs) has led to a
significant expansion of their context windows. However, an extended context
window does not guarantee the effective utilization of the context, posing a
critical challenge for real-world applications. Current evaluations of such
long-context faithfulness are predominantly focused on the text-only domain,
while multimodal assessments remain limited to short contexts. To bridge this
gap, we introduce MMLongCite, a comprehensive benchmark designed to evaluate
the fidelity of LVLMs in long-context scenarios. MMLongCite comprises 8
distinct tasks spanning 6 context length intervals and incorporates diverse
modalities, including text, images, and videos. Our evaluation of
state-of-the-art LVLMs reveals their limited faithfulness in handling long
multimodal contexts. Furthermore, we provide an in-depth analysis of how
context length and the position of crucial content affect the faithfulness of
these models.

</details>


### [46] [UniME-V2: MLLM-as-a-Judge for Universal Multimodal Embedding Learning](https://arxiv.org/abs/2510.13515)
*Tiancheng Gu,Kaicheng Yang,Kaichen Zhang,Xiang An,Ziyong Feng,Yueyi Zhang,Weidong Cai,Jiankang Deng,Lidong Bing*

Main category: cs.CV

TL;DR: UniME-V2模型通过MLLM-as-a-Judge机制和全局检索提升多模态嵌入的判别能力，实验显示其在多个任务上表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在捕捉候选样本间细微语义差异和负样本多样性方面表现不足，且嵌入模型的判别能力有限。

Method: 模型首先通过全局检索构建潜在硬负样本集，然后利用MLLM-as-a-Judge机制评估查询-候选对的语义对齐并生成软语义匹配分数，用于硬负样本挖掘和相似度矩阵对齐。

Result: 在MMEB基准测试和多个检索任务上的实验表明，UniME-V2模型在所有任务上平均达到了最先进的性能。

Conclusion: 本文提出的UniME-V2模型通过结合MLLM-as-a-Judge机制和全局检索，显著提升了多模态嵌入模型的判别能力，并在多个任务上实现了最先进的性能。

Abstract: Universal multimodal embedding models are foundational to various tasks.
Existing approaches typically employ in-batch negative mining by measuring the
similarity of query-candidate pairs. However, these methods often struggle to
capture subtle semantic differences among candidates and lack diversity in
negative samples. Moreover, the embeddings exhibit limited discriminative
ability in distinguishing false and hard negatives. In this paper, we leverage
the advanced understanding capabilities of MLLMs to enhance representation
learning and present a novel Universal Multimodal Embedding (UniME-V2) model.
Our approach first constructs a potential hard negative set through global
retrieval. We then introduce the MLLM-as-a-Judge mechanism, which utilizes
MLLMs to assess the semantic alignment of query-candidate pairs and generate
soft semantic matching scores. These scores serve as a foundation for hard
negative mining, mitigating the impact of false negatives and enabling the
identification of diverse, high-quality hard negatives. Furthermore, the
semantic matching scores are used as soft labels to mitigate the rigid
one-to-one mapping constraint. By aligning the similarity matrix with the soft
semantic matching score matrix, the model learns semantic distinctions among
candidates, significantly enhancing its discriminative capacity. To further
improve performance, we propose UniME-V2-Reranker, a reranking model trained on
our mined hard negatives through a joint pairwise and listwise optimization
approach. We conduct comprehensive experiments on the MMEB benchmark and
multiple retrieval tasks, demonstrating that our method achieves
state-of-the-art performance on average across all tasks.

</details>


### [47] [Universal Image Restoration Pre-training via Masked Degradation Classification](https://arxiv.org/abs/2510.13282)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yinghao Chen,Yanye Lu*

Main category: cs.CV

TL;DR: MaskDCPT是一种新型预训练方法，通过结合退化类型分类和图像重建，显著提升图像恢复任务的性能，并展示了强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统预训练方法在图像恢复任务中表现不足，因此提出MaskDCPT，利用极弱的退化类型监督和图像重建来提升性能和鲁棒性。

Method: MaskDCPT包括一个编码器和两个解码器：编码器从掩码的低质量输入图像中提取特征，分类解码器识别退化类型，重建解码器则重建高质量图像。该方法结合了掩码图像建模和对比学习。

Result: MaskDCPT在5D全能恢复任务中PSNR最低提升3.77 dB，在真实世界退化场景中PIQE降低34.8%，并在未见过的退化类型和级别上表现出强泛化能力。

Conclusion: MaskDCPT方法通过结合掩码图像建模和对比学习，为图像恢复任务提供了通用且强大的预训练表示，显著提升了CNN和Transformer的性能，并在未见过的退化类型和级别上表现出强泛化能力。

Abstract: This study introduces a Masked Degradation Classification Pre-Training method
(MaskDCPT), designed to facilitate the classification of degradation types in
input images, leading to comprehensive image restoration pre-training. Unlike
conventional pre-training methods, MaskDCPT uses the degradation type of the
image as an extremely weak supervision, while simultaneously leveraging the
image reconstruction to enhance performance and robustness. MaskDCPT includes
an encoder and two decoders: the encoder extracts features from the masked
low-quality input image. The classification decoder uses these features to
identify the degradation type, whereas the reconstruction decoder aims to
reconstruct a corresponding high-quality image. This design allows the
pre-training to benefit from both masked image modeling and contrastive
learning, resulting in a generalized representation suited for restoration
tasks. Benefit from the straightforward yet potent MaskDCPT, the pre-trained
encoder can be used to address universal image restoration and achieve
outstanding performance. Implementing MaskDCPT significantly improves
performance for both convolution neural networks (CNNs) and Transformers, with
a minimum increase in PSNR of 3.77 dB in the 5D all-in-one restoration task and
a 34.8% reduction in PIQE compared to baseline in real-world degradation
scenarios. It also emergences strong generalization to previously unseen
degradation types and levels. In addition, we curate and release the UIR-2.5M
dataset, which includes 2.5 million paired restoration samples across 19
degradation types and over 200 degradation levels, incorporating both synthetic
and real-world data. The dataset, source code, and models are available at
https://github.com/MILab-PKU/MaskDCPT.

</details>


### [48] [Modeling Cultural Bias in Facial Expression Recognition with Adaptive Agents](https://arxiv.org/abs/2510.13557)
*David Freire-Obregón,José Salas-Cáceres,Javier Lorenzo-Navarro,Oliverio J. Santana,Daniel Hernández-Sosa,Modesto Castrillón-Santana*

Main category: cs.CV

TL;DR: 本文提出一种基于代理的流式基准测试，研究文化组成和渐进模糊对FER鲁棒性的影响，发现亚洲和西方群体在模糊条件下表现不同，混合群体则呈现中间模式。


<details>
  <summary>Details</summary>
Motivation: 现有FER评估通常假设数据同质且图像质量高，而实际应用中需要面对文化差异和视觉条件退化。本文旨在揭示跨文化组成和渐进模糊如何共同影响FER的鲁棒性。

Method: 采用基于代理的流式基准测试，代理在冻结的CLIP特征空间中运行，配备轻量级残差适配器（在线训练，测试时固定）。代理在5x5网格上移动和互动，环境提供按sigma调度的Gaussian模糊输入。

Result: 结果显示文化群体间存在不对称的退化曲线：JAFFE（亚洲）群体在低模糊下性能更高，但在中等模糊阶段下降更陡；KDEF（西方）群体退化更均匀。混合群体表现出中间模式，平衡混合缓解早期退化，但不平衡设置在高模糊下放大多数群体弱点。

Conclusion: 研究发现，文化组成和互动结构显著影响面部表情识别（FER）在感知条件恶化时的鲁棒性。混合文化群体表现出中间模式，平衡的混合可以缓解早期退化，但不平衡的设置在高模糊下会放大多数群体的弱点。

Abstract: Facial expression recognition (FER) must remain robust under both cultural
variation and perceptually degraded visual conditions, yet most existing
evaluations assume homogeneous data and high-quality imagery. We introduce an
agent-based, streaming benchmark that reveals how cross-cultural composition
and progressive blurring interact to shape face recognition robustness. Each
agent operates in a frozen CLIP feature space with a lightweight residual
adapter trained online at sigma=0 and fixed during testing. Agents move and
interact on a 5x5 lattice, while the environment provides inputs with
sigma-scheduled Gaussian blur. We examine monocultural populations
(Western-only, Asian-only) and mixed environments with balanced (5/5) and
imbalanced (8/2, 2/8) compositions, as well as different spatial contact
structures. Results show clear asymmetric degradation curves between cultural
groups: JAFFE (Asian) populations maintain higher performance at low blur but
exhibit sharper drops at intermediate stages, whereas KDEF (Western)
populations degrade more uniformly. Mixed populations exhibit intermediate
patterns, with balanced mixtures mitigating early degradation, but imbalanced
settings amplify majority-group weaknesses under high blur. These findings
quantify how cultural composition and interaction structure influence the
robustness of FER as perceptual conditions deteriorate.

</details>


### [49] [Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning](https://arxiv.org/abs/2510.13307)
*Yang Li,Aming Wu,Zihao Zhang,Yahong Han*

Main category: cs.CV

TL;DR: 论文提出了一种基于SCM的联合学习因果表示和推理的方法，有效解决了3D点云分割中的新类发现问题。


<details>
  <summary>Details</summary>
Motivation: 研究3D点云分割中的新类发现（3D-NCD），旨在利用已标记基类的监督信息分割未标记新类，关键在于建立点表示与基类标签之间的精确关联。

Method: 使用结构因果模型（SCM）重新形式化3D-NCD问题，设计了因果表示原型以消除混杂因素，并通过图结构建模基类与新类之间的因果关系。

Result: 在3D和2D NCD语义分割任务中，通过大量实验和可视化结果验证了方法的优越性。

Conclusion: 论文提出了一种基于结构因果模型（SCM）的新方法，通过联合学习因果表示和推理，成功解决了3D-NCD问题，并在实验和可视化结果中展示了其优越性。

Abstract: In this paper, we focus on Novel Class Discovery for Point Cloud Segmentation
(3D-NCD), aiming to learn a model that can segment unlabeled (novel) 3D classes
using only the supervision from labeled (base) 3D classes. The key to this task
is to setup the exact correlations between the point representations and their
base class labels, as well as the representation correlations between the
points from base and novel classes. A coarse or statistical correlation
learning may lead to the confusion in novel class inference. lf we impose a
causal relationship as a strong correlated constraint upon the learning
process, the essential point cloud representations that accurately correspond
to the classes should be uncovered. To this end, we introduce a structural
causal model (SCM) to re-formalize the 3D-NCD problem and propose a new method,
i.e., Joint Learning of Causal Representation and Reasoning. Specifically, we
first analyze hidden confounders in the base class representations and the
causal relationships between the base and novel classes through SCM. We devise
a causal representation prototype that eliminates confounders to capture the
causal representations of base classes. A graph structure is then used to model
the causal relationships between the base classes' causal representation
prototypes and the novel class prototypes, enabling causal reasoning from base
to novel classes. Extensive experiments and visualization results on 3D and 2D
NCD semantic segmentation demonstrate the superiorities of our method.

</details>


### [50] [CanvasMAR: Improving Masked Autoregressive Video Generation With Canvas](https://arxiv.org/abs/2510.13669)
*Zian Li,Muhan Zhang*

Main category: cs.CV

TL;DR: CanvasMAR通过画布机制和组合式无分类器引导，解决了视频MAR模型的启动慢和误差积累问题，提升了生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频MAR模型存在的启动慢问题和自回归过程中空间和时间维度的误差积累问题。

Method: 提出了CanvasMAR模型，通过画布机制（模糊的全局预测）作为起点，结合组合式无分类器引导和基于噪声的画布增强技术，优化了视频生成过程。

Result: 在BAIR和Kinetics-600基准测试中，CanvasMAR以更少的自回归步骤生成了高质量视频，性能显著优于其他自回归模型，并与扩散方法相当。

Conclusion: CanvasMAR通过引入画布机制和组合式无分类器引导，显著提升了视频生成的质量和效率，在Kinetics-600数据集上表现出色，甚至可与基于扩散的方法媲美。

Abstract: Masked autoregressive models (MAR) have recently emerged as a powerful
paradigm for image and video generation, combining the flexibility of masked
modeling with the potential of continuous tokenizer. However, video MAR models
suffer from two major limitations: the slow-start problem, caused by the lack
of a structured global prior at early sampling stages, and error accumulation
across the autoregression in both spatial and temporal dimensions. In this
work, we propose CanvasMAR, a novel video MAR model that mitigates these issues
by introducing a canvas mechanism--a blurred, global prediction of the next
frame, used as the starting point for masked generation. The canvas provides
global structure early in sampling, enabling faster and more coherent frame
synthesis. Furthermore, we introduce compositional classifier-free guidance
that jointly enlarges spatial (canvas) and temporal conditioning, and employ
noise-based canvas augmentation to enhance robustness. Experiments on the BAIR
and Kinetics-600 benchmarks demonstrate that CanvasMAR produces high-quality
videos with fewer autoregressive steps. Our approach achieves remarkable
performance among autoregressive models on Kinetics-600 dataset and rivals
diffusion-based methods.

</details>


### [51] [InstantSfM: Fully Sparse and Parallel Structure-from-Motion](https://arxiv.org/abs/2510.13310)
*Jiankun Zhong,Zitong Zhan,Quankai Gao,Ziyu Chen,Haozhe Lou,Jiageng Mao,Ulrich Neumann,Yue Wang*

Main category: cs.CV

TL;DR: 本文提出了一种利用GPU并行计算优化SfM流程的方法，显著提升了处理速度并保持或提高了重建精度，特别是在大规模场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统SfM方法（如COLMAP和GLOMAP）在处理大规模场景时存在计算效率低和灵活性不足的问题，而基于深度学习的SfM方法（如VGGSfM和VGGT）则受限于GPU内存消耗。本文旨在通过GPU并行计算解决这些局限性。

Method: 基于稀疏感知的束调整优化技术，将GPU并行计算应用于标准SfM流程中的每个关键阶段，包括束调整（BA）和全局定位（GP）。

Result: 在包含5000张图像的数据集上，本文方法比COLMAP快约40倍，同时保持或提高了重建精度。

Conclusion: 通过利用GPU并行计算优化SfM流程中的关键步骤，本文提出的方法在保持或提高重建精度的同时，显著提升了处理速度，特别是在大规模场景下表现优异。

Abstract: Structure-from-Motion (SfM), a method that recovers camera poses and scene
geometry from uncalibrated images, is a central component in robotic
reconstruction and simulation. Despite the state-of-the-art performance of
traditional SfM methods such as COLMAP and its follow-up work, GLOMAP, naive
CPU-specialized implementations of bundle adjustment (BA) or global positioning
(GP) introduce significant computational overhead when handling large-scale
scenarios, leading to a trade-off between accuracy and speed in SfM. Moreover,
the blessing of efficient C++-based implementations in COLMAP and GLOMAP comes
with the curse of limited flexibility, as they lack support for various
external optimization options. On the other hand, while deep learning based SfM
pipelines like VGGSfM and VGGT enable feed-forward 3D reconstruction, they are
unable to scale to thousands of input views at once as GPU memory consumption
increases sharply as the number of input views grows. In this paper, we unleash
the full potential of GPU parallel computation to accelerate each critical
stage of the standard SfM pipeline. Building upon recent advances in
sparse-aware bundle adjustment optimization, our design extends these
techniques to accelerate both BA and GP within a unified global SfM framework.
Through extensive experiments on datasets of varying scales (e.g. 5000 images
where VGGSfM and VGGT run out of memory), our method demonstrates up to about
40 times speedup over COLMAP while achieving consistently comparable or even
improved reconstruction accuracy. Our project page can be found at
https://cre185.github.io/InstantSfM/.

</details>


### [52] [MVCustom: Multi-View Customized Diffusion via Geometric Latent Rendering and Completion](https://arxiv.org/abs/2510.13702)
*Minjung Shin,Hyunin Cho,Sooyeon Go,Jin-Hwa Kim,Youngjung Uh*

Main category: cs.CV

TL;DR: MVCustom 是一个扩散框架，通过特征场表示和时空注意力实现多视角一致性和定制保真度，解决了现有模型在几何一致性和视角控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有多视角生成模型缺乏几何一致性的定制支持，而定制模型又缺乏明确的视角控制。MVCustom 旨在统一这两者，解决训练数据稀缺和多样化提示泛化问题。

Method: MVCustom 采用基于扩散的框架，结合特征场表示和密集时空注意力的文本到视频扩散主干，学习主题的身份和几何信息。推理阶段引入深度感知特征渲染和一致性感知潜在补全技术。

Result: 实验表明，MVCustom 是唯一能同时实现忠实多视角生成和定制的框架。

Conclusion: MVCustom 是首个同时实现忠实多视角生成和定制的框架，通过深度感知特征渲染和一致性感知潜在补全技术，确保了定制主题与周围背景的几何一致性。

Abstract: Multi-view generation with camera pose control and prompt-based customization
are both essential elements for achieving controllable generative models.
However, existing multi-view generation models do not support customization
with geometric consistency, whereas customization models lack explicit
viewpoint control, making them challenging to unify. Motivated by these gaps,
we introduce a novel task, multi-view customization, which aims to jointly
achieve multi-view camera pose control and customization. Due to the scarcity
of training data in customization, existing multi-view generation models, which
inherently rely on large-scale datasets, struggle to generalize to diverse
prompts. To address this, we propose MVCustom, a novel diffusion-based
framework explicitly designed to achieve both multi-view consistency and
customization fidelity. In the training stage, MVCustom learns the subject's
identity and geometry using a feature-field representation, incorporating the
text-to-video diffusion backbone enhanced with dense spatio-temporal attention,
which leverages temporal coherence for multi-view consistency. In the inference
stage, we introduce two novel techniques: depth-aware feature rendering
explicitly enforces geometric consistency, and consistent-aware latent
completion ensures accurate perspective alignment of the customized subject and
surrounding backgrounds. Extensive experiments demonstrate that MVCustom is the
only framework that simultaneously achieves faithful multi-view generation and
customization.

</details>


### [53] [Visual Interestingness Decoded: How GPT-4o Mirrors Human Interests](https://arxiv.org/abs/2510.13316)
*Fitim Abdullahu,Helmut Grabner*

Main category: cs.CV

TL;DR: 论文研究了GPT-4o在视觉趣味性评估上与人类的一致性，发现其优于现有方法，可用于训练排序模型，为理解人类兴趣提供新途径。


<details>
  <summary>Details</summary>
Motivation: 探索大型多模态模型（LMMs）对视觉趣味性概念的理解程度，以及其与人类评估的一致性。

Method: 通过比较分析，研究人类评估与GPT-4o预测的一致性，并利用其标注的图像对训练学习排序模型。

Result: 研究发现GPT-4o在视觉趣味性评估上与人类部分一致，且优于现有方法，可用于有效标注图像对并训练排序模型。

Conclusion: 论文揭示了GPT-4o在视觉趣味性评估上与人类的部分一致性，并展示了其在图像标注和训练学习排序模型中的潜力，为深入理解人类兴趣提供了新视角。

Abstract: Our daily life is highly influenced by what we consume and see. Attracting
and holding one's attention -- the definition of (visual) interestingness -- is
essential. The rise of Large Multimodal Models (LMMs) trained on large-scale
visual and textual data has demonstrated impressive capabilities. We explore
these models' potential to understand to what extent the concepts of visual
interestingness are captured and examine the alignment between human
assessments and GPT-4o's, a leading LMM, predictions through comparative
analysis. Our studies reveal partial alignment between humans and GPT-4o. It
already captures the concept as best compared to state-of-the-art methods.
Hence, this allows for the effective labeling of image pairs according to their
(commonly) interestingness, which are used as training data to distill the
knowledge into a learning-to-rank model. The insights pave the way for a deeper
understanding of human interest.

</details>


### [54] [Multi-Scale High-Resolution Logarithmic Grapher Module for Efficient Vision GNNs](https://arxiv.org/abs/2510.13740)
*Mustafa Munir,Alex Zhang,Radu Marculescu*

Main category: cs.CV

TL;DR: LogViG通过LSGC方法优化图构建，结合高分辨率分支，在图像任务中超越现有ViG、CNN和ViT架构。


<details>
  <summary>Details</summary>
Motivation: 现有的图构建方法（如KNN）在大型图像上计算成本高，而SVGA的固定步长尺度可能导致信息损失。

Method: 提出了一种新的图构建方法LSGC，并开发了混合CNN-GNN模型LogViG，结合高分辨率和多尺度架构。

Result: LogViG在准确率、GMACs和参数量上均优于现有架构，最小的Ti-LogViG在ImageNet-1K上达到79.9%的平均top-1准确率。

Conclusion: LogViG通过提出的LSGC方法在图像分类和语义分割任务中超越了现有的ViG、CNN和ViT架构，展示了在ViG中利用长距离链接的潜力。

Abstract: Vision graph neural networks (ViG) have demonstrated promise in vision tasks
as a competitive alternative to conventional convolutional neural nets (CNN)
and transformers (ViTs); however, common graph construction methods, such as
k-nearest neighbor (KNN), can be expensive on larger images. While methods such
as Sparse Vision Graph Attention (SVGA) have shown promise, SVGA's fixed step
scale can lead to over-squashing and missing multiple connections to gain the
same information that could be gained from a long-range link. Through this
observation, we propose a new graph construction method, Logarithmic Scalable
Graph Construction (LSGC) to enhance performance by limiting the number of
long-range links. To this end, we propose LogViG, a novel hybrid CNN-GNN model
that utilizes LSGC. Furthermore, inspired by the successes of multi-scale and
high-resolution architectures, we introduce and apply a high-resolution branch
and fuse features between our high-resolution and low-resolution branches for a
multi-scale high-resolution Vision GNN network. Extensive experiments show that
LogViG beats existing ViG, CNN, and ViT architectures in terms of accuracy,
GMACs, and parameters on image classification and semantic segmentation tasks.
Our smallest model, Ti-LogViG, achieves an average top-1 accuracy on
ImageNet-1K of 79.9% with a standard deviation of 0.2%, 1.7% higher average
accuracy than Vision GNN with a 24.3% reduction in parameters and 35.3%
reduction in GMACs. Our work shows that leveraging long-range links in graph
construction for ViGs through our proposed LSGC can exceed the performance of
current state-of-the-art ViGs. Code is available at
https://github.com/mmunir127/LogViG-Official.

</details>


### [55] [Removing Cost Volumes from Optical Flow Estimators](https://arxiv.org/abs/2510.13317)
*Simon Kiefhaber,Stefan Roth,Simone Schaub-Meyer*

Main category: cs.CV

TL;DR: 提出一种训练策略，通过移除成本体积显著提升光流估计器的速度和内存效率，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 观察到成本体积在训练后期失去重要性，限制了处理速度和输入帧分辨率。

Method: 提出一种训练策略，允许在训练过程中移除成本体积。

Result: 创建了三个不同计算预算的模型，最准确的模型在保持最先进准确性的同时，速度提高了1.2倍，内存占用减少了6倍；最快的模型能够在仅使用500MB GPU内存的情况下以20FPS处理全高清帧。

Conclusion: 通过引入一种新的训练策略，可以在不影响准确性的情况下显著提高光流估计器的推理速度和内存效率。

Abstract: Cost volumes are used in every modern optical flow estimator, but due to
their computational and space complexity, they are often a limiting factor
regarding both processing speed and the resolution of input frames. Motivated
by our empirical observation that cost volumes lose their importance once all
other network parts of, e.g., a RAFT-based pipeline have been sufficiently
trained, we introduce a training strategy that allows removing the cost volume
from optical flow estimators throughout training. This leads to significantly
improved inference speed and reduced memory requirements. Using our training
strategy, we create three different models covering different compute budgets.
Our most accurate model reaches state-of-the-art accuracy while being
$1.2\times$ faster and having a $6\times$ lower memory footprint than
comparable models; our fastest model is capable of processing Full HD frames at
$20\,\mathrm{FPS}$ using only $500\,\mathrm{MB}$ of GPU memory.

</details>


### [56] [RECODE: Reasoning Through Code Generation for Visual Question Answering](https://arxiv.org/abs/2510.13756)
*Junhong Shen,Mu Cai,Bo Hu,Ameet Talwalkar,David A Ross,Cordelia Schmid,Alireza Fathi*

Main category: cs.CV

TL;DR: RECODE通过代码逆向视觉为可执行程序，提升多模态推理的准确性和可验证性，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在结构化视觉（如图表和图表）精确推理中的不足，像素级感知缺乏验证机制。

Method: 提出RECODE代理框架，生成多个候选程序来复现输入图像，并通过批评者选择最忠实重建，迭代优化代码。

Result: 在CharXiv、ChartQA和Geometry3K等视觉推理基准上，RECODE显著优于不利用代码或仅将代码用于辅助绘图或裁剪的方法。

Conclusion: RECODE框架通过将视觉感知与可执行代码结合，为多模态推理提供了更准确和可验证的新路径。

Abstract: Multimodal Large Language Models (MLLMs) struggle with precise reasoning for
structured visuals like charts and diagrams, as pixel-based perception lacks a
mechanism for verification. To address this, we propose to leverage derendering
-- the process of reverse-engineering visuals into executable code -- as a new
modality for verifiable visual reasoning. Specifically, we propose RECODE, an
agentic framework that first generates multiple candidate programs to reproduce
the input image. It then uses a critic to select the most faithful
reconstruction and iteratively refines the code. This process not only
transforms an ambiguous perceptual task into a verifiable, symbolic problem,
but also enables precise calculations and logical inferences later on. On
various visual reasoning benchmarks such as CharXiv, ChartQA, and Geometry3K,
RECODE significantly outperforms methods that do not leverage code or only use
code for drawing auxiliary lines or cropping. Our work demonstrates that
grounding visual perception in executable code provides a new path toward more
accurate and verifiable multimodal reasoning.

</details>


### [57] [DEF-YOLO: Leveraging YOLO for Concealed Weapon Detection in Thermal Imagin](https://arxiv.org/abs/2510.13326)
*Divya Bhardwaj,Arnav Ramamoorthy,Poonam Goyal*

Main category: cs.CV

TL;DR: 本文提出了一种改进的YOLOv8架构DEF-YOLO和首个大规模热成像隐蔽武器数据集TICW，解决了现有成像模态的局限性，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有成像模态（如毫米波、微波等）在隐蔽武器检测中存在分辨率低或隐私问题等局限性，因此选择热成像作为低成本、隐私保护的解决方案。

Method: 采用了改进的YOLOv8架构，包括在SPPF层引入可变形卷积以利用多尺度特征，以及通过骨干和颈部层提取低、中、高级特征。此外，还引入了焦点损失来解决类别不平衡问题。

Result: 提出的DEF-YOLO架构在热成像中实现了高效的对象定位，并通过新的大规模数据集TICW验证了其性能。

Conclusion: 本文提出了一种基于YOLO的新型架构DEF-YOLO，用于热成像中的隐蔽武器检测，并通过实验验证了其有效性。

Abstract: Concealed weapon detection aims at detecting weapons hidden beneath a
person's clothing or luggage. Various imaging modalities like Millimeter Wave,
Microwave, Terahertz, Infrared, etc., are exploited for the concealed weapon
detection task. These imaging modalities have their own limitations, such as
poor resolution in microwave imaging, privacy concerns in millimeter wave
imaging, etc. To provide a real-time, 24 x 7 surveillance, low-cost, and
privacy-preserved solution, we opted for thermal imaging in spite of the lack
of availability of a benchmark dataset. We propose a novel approach and a
dataset for concealed weapon detection in thermal imagery. Our YOLO-based
architecture, DEF-YOLO, is built with key enhancements in YOLOv8 tailored to
the unique challenges of concealed weapon detection in thermal vision. We adopt
deformable convolutions at the SPPF layer to exploit multi-scale features;
backbone and neck layers to extract low, mid, and high-level features, enabling
DEF-YOLO to adaptively focus on localization around the objects in thermal
homogeneous regions, without sacrificing much of the speed and throughput. In
addition to these simple yet effective key architectural changes, we introduce
a new, large-scale Thermal Imaging Concealed Weapon dataset, TICW, featuring a
diverse set of concealed weapons and capturing a wide range of scenarios. To
the best of our knowledge, this is the first large-scale contributed dataset
for this task. We also incorporate focal loss to address the significant class
imbalance inherent in the concealed weapon detection task. The efficacy of the
proposed work establishes a new benchmark through extensive experimentation for
concealed weapon detection in thermal imagery.

</details>


### [58] [Scaling Vision Transformers for Functional MRI with Flat Maps](https://arxiv.org/abs/2510.13768)
*Connor Lane,Daniel Z. Kaplan,Tanishq Mathew Abraham,Paul S. Scotti*

Main category: cs.CV

TL;DR: 研究将fMRI数据转换为视频，使用MAE框架训练Vision Transformers，性能随数据量提升，支持跨被试和解码任务。


<details>
  <summary>Details</summary>
Motivation: 解决现代深度学习架构适应fMRI数据时如何表示数据输入的关键问题，弥合fMRI与自然图像之间的模态差距。

Method: 通过将4D体积fMRI数据转换为2D fMRI活动平面图的视频，并使用时空掩码自编码器（MAE）框架在Human Connectome Project的2.3K小时fMRI数据上训练Vision Transformers。

Result: 掩码fMRI建模性能随数据集大小按严格幂律缩放提升。下游分类基准表明模型学习到了丰富的表示，支持跨被试的细粒度状态解码和跨脑状态变化的被试特异性特征解码。

Conclusion: 该研究是构建fMRI数据基础模型的开放科学项目的一部分，代码和数据集已开源。

Abstract: A key question for adapting modern deep learning architectures to functional
MRI (fMRI) is how to represent the data for model input. To bridge the modality
gap between fMRI and natural images, we transform the 4D volumetric fMRI data
into videos of 2D fMRI activity flat maps. We train Vision Transformers on 2.3K
hours of fMRI flat map videos from the Human Connectome Project using the
spatiotemporal masked autoencoder (MAE) framework. We observe that masked fMRI
modeling performance improves with dataset size according to a strict power
scaling law. Downstream classification benchmarks show that our model learns
rich representations supporting both fine-grained state decoding across
subjects, as well as subject-specific trait decoding across changes in brain
state. This work is part of an ongoing open science project to build foundation
models for fMRI data. Our code and datasets are available at
https://github.com/MedARC-AI/fmri-fm.

</details>


### [59] [Group-Wise Optimization for Self-Extensible Codebooks in Vector Quantized Models](https://arxiv.org/abs/2510.13331)
*Hong-Kai Zheng,Piji Li*

Main category: cs.CV

TL;DR: Group-VQ通过分组优化和训练后重采样，解决了VQ-VAE代码本崩溃问题，提升了重建性能和灵活性。


<details>
  <summary>Details</summary>
Motivation: VQ-VAE存在代码本崩溃问题，现有方法因静态代码本或全局优化限制了学习能力，导致重建质量下降。

Method: 提出Group-VQ方法，对代码本进行分组优化，每组独立优化并在组内联合优化。同时引入无需训练的代码本重采样方法，支持训练后调整代码本大小。

Result: Group-VQ在多种设置下的图像重建实验中表现优异，重建指标提升，且训练后代码本采样方法实现了灵活的代码本大小调整。

Conclusion: Group-VQ通过分组优化和训练后重采样方法，有效提升了代码本利用率和重建性能，并在图像重建实验中表现出优越性能。

Abstract: Vector Quantized Variational Autoencoders (VQ-VAEs) leverage self-supervised
learning through reconstruction tasks to represent continuous vectors using the
closest vectors in a codebook. However, issues such as codebook collapse
persist in the VQ model. To address these issues, existing approaches employ
implicit static codebooks or jointly optimize the entire codebook, but these
methods constrain the codebook's learning capability, leading to reduced
reconstruction quality. In this paper, we propose Group-VQ, which performs
group-wise optimization on the codebook. Each group is optimized independently,
with joint optimization performed within groups. This approach improves the
trade-off between codebook utilization and reconstruction performance.
Additionally, we introduce a training-free codebook resampling method, allowing
post-training adjustment of the codebook size. In image reconstruction
experiments under various settings, Group-VQ demonstrates improved performance
on reconstruction metrics. And the post-training codebook sampling method
achieves the desired flexibility in adjusting the codebook size.

</details>


### [60] [No-Reference Rendered Video Quality Assessment: Dataset and Metrics](https://arxiv.org/abs/2510.13349)
*Sipeng Yang,Jiayu Ji,Qingchuan Zhu,Zhiyao Yang,Xiaogang Jin*

Main category: cs.CV

TL;DR: 论文针对渲染视频提出了一种新的无参考质量评估方法，通过构建专用数据集和设计新指标，显著提升了评估准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的无参考视频质量评估方法和数据集主要针对摄像机拍摄的视频，直接应用于渲染视频会导致预测偏差，因为渲染视频更容易出现时间伪影。

Method: 研究团队构建了一个大型的渲染视频数据集，并设计了一个专门针对渲染视频的无参考质量评估指标，该指标综合考虑了图像质量和时间稳定性。

Result: 提出的NR-VQA指标在渲染视频上表现出优于现有方法的性能，并能用于超采样方法和实时渲染中帧生成策略的基准测试。

Conclusion: 论文提出了一种针对渲染视频的无参考质量评估方法，并通过实验验证了其在渲染视频上的优越性能。

Abstract: Quality assessment of videos is crucial for many computer graphics
applications, including video games, virtual reality, and augmented reality,
where visual performance has a significant impact on user experience. When test
videos cannot be perfectly aligned with references or when references are
unavailable, the significance of no-reference video quality assessment (NR-VQA)
methods is undeniable. However, existing NR-VQA datasets and metrics are
primarily focused on camera-captured videos; applying them directly to rendered
videos would result in biased predictions, as rendered videos are more prone to
temporal artifacts. To address this, we present a large rendering-oriented
video dataset with subjective quality annotations, as well as a designed NR-VQA
metric specific to rendered videos. The proposed dataset includes a wide range
of 3D scenes and rendering settings, with quality scores annotated for various
display types to better reflect real-world application scenarios. Building on
this dataset, we calibrate our NR-VQA metric to assess rendered video quality
by looking at both image quality and temporal stability. We compare our metric
to existing NR-VQA metrics, demonstrating its superior performance on rendered
videos. Finally, we demonstrate that our metric can be used to benchmark
supersampling methods and assess frame generation strategies in real-time
rendering.

</details>


### [61] [Bee: A High-Quality Corpus and Full-Stack Suite to Unlock Advanced Fully Open MLLMs](https://arxiv.org/abs/2510.13795)
*Yi Zhang,Bolin Ni,Xin-Sheng Chen,Heng-Rui Zhang,Yongming Rao,Houwen Peng,Qinglin Lu,Han Hu,Meng-Hao Guo,Shi-Min Hu*

Main category: cs.CV

TL;DR: 本研究通过高质量数据集和工具链，训练出完全开放的MLLM模型Bee-8B，性能媲美半开放模型，强调数据质量是关键。


<details>
  <summary>Details</summary>
Motivation: 完全开放的多模态大语言模型（MLLMs）目前落后于专有模型，主要原因是监督微调（SFT）数据质量的差距。现有开源数据集普遍存在噪声且缺乏复杂推理数据（如Chain-of-Thought）。

Method: 引入Honey-Data-15M数据集（约1500万QA对），采用多重清理技术和双级（短和长）CoT增强策略；开发HoneyPipe数据清理管道及其框架DataStudio；训练8B参数的Bee-8B模型。

Result: Bee-8B在完全开放的MLLMs中达到了新的SOTA性能，与部分半开放模型（如InternVL3.5-8B）竞争甚至超越。

Conclusion: 本研究通过高质量数据集Honey-Data-15M、数据清理工具HoneyPipe及其框架DataStudio，以及训练出的Bee-8B模型，证明了数据质量是开发完全开放的多模态大语言模型（MLLMs）并使其与半开放模型竞争的关键。

Abstract: Fully open multimodal large language models (MLLMs) currently lag behind
proprietary counterparts, primarily due to a significant gap in data quality
for supervised fine-tuning (SFT). Existing open-source datasets are often
plagued by widespread noise and a critical deficit in complex reasoning data,
such as Chain-of-Thought (CoT), which hinders the development of advanced model
capabilities. Addressing these challenges, our work makes three primary
contributions. First, we introduce Honey-Data-15M, a new SFT dataset comprising
approximately 15 million QA pairs, processed through multiple cleaning
techniques and enhanced with a novel dual-level (short and long) CoT enrichment
strategy. Second, we introduce HoneyPipe, the data curation pipeline, and its
underlying framework DataStudio, providing the community with a transparent and
adaptable methodology for data curation that moves beyond static dataset
releases. Finally, to validate our dataset and pipeline, we train Bee-8B, an 8B
model on Honey-Data-15M. Experiments show that Bee-8B establishes a new
state-of-the-art (SOTA) for fully open MLLMs, achieving performance that is
competitive with, and in some cases surpasses, recent semi-open models such as
InternVL3.5-8B. Our work delivers to the community a suite of foundational
resources, including: the Honey-Data-15M corpus; the full-stack suite
comprising HoneyPipe and DataStudio; training recipes; an evaluation harness;
and the model weights. This effort demonstrates that a principled focus on data
quality is a key pathway to developing fully open MLLMs that are highly
competitive with their semi-open counterparts.

</details>


### [62] [Generative Universal Verifier as Multimodal Meta-Reasoner](https://arxiv.org/abs/2510.13804)
*Xinchen Zhang,Xiaoying Zhang,Youbin Wu,Yanbin Cao,Renrui Zhang,Ruihang Chu,Ling Yang,Yujiu Yang*

Main category: cs.CV

TL;DR: 论文提出了Generative Universal Verifier概念，通过构建ViVerBench基准、训练OmniVerifier-7B和提出OmniVerifier-TTS，显著提升了多模态推理中的视觉验证能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型在多模态推理中的视觉结果验证能力不足，与人类水平的可靠视觉验证存在显著差距。

Method: 设计了两种自动化管道来构建大规模视觉验证数据，并训练了OmniVerifier-7B，这是首个为通用视觉验证训练的生成验证器。同时提出了OmniVerifier-TTS，一种顺序测试时扩展范式。

Result: OmniVerifier-7B在ViVerBench上取得了显著提升（+8.3），OmniVerifier-TTS在T2I-ReasonBench（+3.7）和GenEval++（+4.3）上优于现有方法。

Conclusion: OmniVerifier通过为多模态推理提供可靠的视觉验证，推动了生成过程中的可靠反思和可扩展的测试时优化，标志着朝着更可信和可控的下一代推理系统迈出了一步。

Abstract: We introduce Generative Universal Verifier, a novel concept and plugin
designed for next-generation multimodal reasoning in vision-language models and
unified multimodal models, providing the fundamental capability of reflection
and refinement on visual outcomes during the reasoning and generation process.
This work makes three main contributions: (1) We build ViVerBench, a
comprehensive benchmark spanning 16 categories of critical tasks for evaluating
visual outcomes in multimodal reasoning. Results show that existing VLMs
consistently underperform across these tasks, underscoring a substantial gap
from human-level capability in reliable visual verification. (2) We design two
automated pipelines to construct large-scale visual verification data and train
OmniVerifier-7B, the first omni-capable generative verifier trained for
universal visual verification and achieves notable gains on ViVerBench(+8.3).
Through training, we identify three atomic capabilities in visual verification
and demonstrate how they generalize and interact synergistically. (3) We
propose OmniVerifier-TTS, a sequential test-time scaling paradigm that
leverages the universal verifier to bridge image generation and editing within
unified models, enhancing the upper bound of generative ability through
iterative fine-grained optimization. Beyond generation, we extend universal
verifier to broader world-modeling interleaved reasoning scenarios.
Empirically, OmniVerifier-TTS achieves improvements on T2I-ReasonBench(+3.7),
and GenEval++(+4.3), outperforming existing parallel test-time scaling methods,
such as Best-of-N. By endowing multimodal reasoning with reliable visual
verification, OmniVerifier advances both reliable reflection during generation
and scalable test-time refinement, marking a step toward more trustworthy and
controllable next-generation reasoning systems.

</details>


### [63] [DepthVLA: Enhancing Vision-Language-Action Models with Depth-Aware Spatial Reasoning](https://arxiv.org/abs/2510.13375)
*Tianyuan Yuan,Yicheng Liu,Chenhao Lu,Zhuoguang Chen,Tao Jiang,Hang Zhao*

Main category: cs.CV

TL;DR: DepthVLA通过引入深度预测模块提升VLA模型的空间推理能力，在多项任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因继承自VLM的有限空间推理能力，在需要精确空间推理的任务中表现不佳。

Method: 采用混合Transformer设计，统一了VLM、深度Transformer和动作专家，通过全共享注意力形成端到端模型。

Result: DepthVLA在真实世界任务中达到78.5%（vs. 65.0%），在LIBERO模拟器中达到94.9%（vs. 93.6%），在Simpler模拟器中达到74.8%（vs. 58.8%）。

Conclusion: DepthVLA通过引入预训练的深度预测模块，显著提升了VLA模型的空间推理能力，在真实世界和模拟环境中均优于现有方法。

Abstract: Vision-Language-Action (VLA) models have recently shown impressive
generalization and language-guided manipulation capabilities. However, their
performance degrades on tasks requiring precise spatial reasoning due to
limited spatial reasoning inherited from Vision-Language Models (VLMs).
Existing VLAs rely on extensive action-data pretraining to ground VLMs in 3D
space, which reduces training efficiency and is still insufficient for accurate
spatial understanding. In this work, we present DepthVLA, a simple yet
effective VLA architecture that explicitly incorporates spatial awareness
through a pretrained depth prediction module. DepthVLA adopts a
mixture-of-transformers design that unifies a VLM, a depth transformer, and an
action expert with fully shared attentions, forming an end-to-end model with
enhanced spatial reasoning. Extensive evaluations in both real-world and
simulated environments show that DepthVLA outperforms state-of-the-art
approaches, achieving 78.5% vs. 65.0% progress in real-world tasks, 94.9% vs.
93.6% in the LIBERO simulator, and 74.8% vs. 58.8% in the Simpler simulator.
Our code will be made publicly available.

</details>


### [64] [Generalizing WiFi Gesture Recognition via Large-Model-Aware Semantic Distillation and Alignment](https://arxiv.org/abs/2510.13390)
*Feng-Qi Cui,Yu-Tong Guo,Tianyue Zheng,Jinyang Huang*

Main category: cs.CV

TL;DR: GLSDA框架利用大型基础模型的语义先验提升WiFi手势识别性能，通过双路径编码、多尺度语义学习和双蒸馏策略，在泛化能力和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi手势识别方法因CSI的域敏感性和缺乏高级手势抽象而泛化能力和语义表达能力有限。

Method: 提出了一种名为GLSDA的新颖泛化框架，通过预训练大型基础模型的语义先验增强手势表示学习。包括双路径CSI编码管道、多尺度语义编码器、语义感知软监督方案和鲁棒双蒸馏策略。

Result: 在Widar3.0基准测试中，GLSDA在域内和跨域手势识别任务中均优于现有方法，同时显著减少模型大小和推理延迟。

Conclusion: GLSDA框架在WiFi手势识别任务中表现出色，不仅在域内和跨域场景下超越现有方法，还显著降低了模型大小和推理延迟，为现实AIoT应用提供了可扩展和可部署的解决方案。

Abstract: WiFi-based gesture recognition has emerged as a promising RF sensing paradigm
for enabling non-contact and privacy-preserving human-computer interaction in
AIoT environments. However, existing methods often suffer from limited
generalization and semantic expressiveness due to the domain-sensitive nature
of Channel State Information and the lack of high-level gesture abstraction. To
address these challenges, we propose a novel generalization framework, termed
Large-Model-Aware Semantic Distillation and Alignment (GLSDA), which leverages
the semantic prior of pre-trained large foundation models to enhance gesture
representation learning in both in-domain and cross-domain scenarios.
Specifically, we first design a dual-path CSI encoding pipeline that captures
geometric and dynamic gesture patterns via CSI-Ratio phase sequences and
Doppler spectrograms. These representations are then fed into a Multiscale
Semantic Encoder, which learns robust temporal embeddings and aligns them with
gesture semantics through cross-modal attention mechanisms. To further enhance
category discrimination, we introduce a Semantic-Aware Soft Supervision scheme
that encodes inter-class correlations and reduces label ambiguity, especially
for semantically similar gestures. Finally, we develop a Robust
Dual-Distillation strategy to compress the aligned model into a lightweight
student network, jointly distilling intermediate features and semantic-informed
soft labels from the teacher model. Extensive experiments on the Widar3.0
benchmark show that GLSDA consistently outperforms state-of-the-art methods in
both in-domain and cross-domain gesture recognition tasks, while significantly
reducing model size and inference latency. Our method offers a scalable and
deployable solution for generalized RF-based gesture interfaces in real-world
AIoT applications.

</details>


### [65] [Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2510.13394)
*Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang*

Main category: cs.CV

TL;DR: Spatial-DISE 是一个评估 VLMs 空间推理能力的新基准，揭示了当前模型的不足，并提供了数据集和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法充分评估 VLMs 的空间推理能力，尤其是内在动态空间推理这一人类空间认知的核心方面。

Method: 提出了一种基于认知分类的统一基准 Spatial-DISE，并开发了一个自动化流水线生成多样化的空间推理问题。

Result: 评估了 28 种先进 VLMs，发现其在多步多视角空间推理上与人类能力存在显著差距。

Conclusion: Spatial-DISE 提供了一个强大的评估框架和数据集，揭示了当前 VLMs 在空间推理能力上的不足，并为未来研究指明了方向。

Abstract: Spatial reasoning ability is crucial for Vision Language Models (VLMs) to
support real-world applications in diverse domains including robotics,
augmented reality, and autonomous navigation. Unfortunately, existing
benchmarks are inadequate in assessing spatial reasoning ability, especially
the \emph{intrinsic-dynamic} spatial reasoning which is a fundamental aspect of
human spatial cognition. In this paper, we propose a unified benchmark,
\textbf{Spatial-DISE}, based on a cognitively grounded taxonomy that
categorizes tasks into four fundamental quadrants:
\textbf{I}ntrinsic-\textbf{S}tatic, Intrinsic-\textbf{D}ynamic,
\textbf{E}xtrinsic-Static, and Extrinsic-Dynamic spatial reasoning. Moreover,
to address the issue of data scarcity, we develop a scalable and automated
pipeline to generate diverse and verifiable spatial reasoning questions,
resulting in a new \textbf{Spatial-DISE} dataset that includes Spatial-DISE
Bench (559 evaluation VQA pairs) and Spatial-DISE-12K (12K+ training VQA
pairs). Our comprehensive evaluation across 28 state-of-the-art VLMs reveals
that, current VLMs have a large and consistent gap to human competence,
especially on multi-step multi-view spatial reasoning. Spatial-DISE offers a
robust framework, valuable dataset, and clear direction for future research
toward human-like spatial intelligence. Benchmark, dataset, and code will be
publicly released.

</details>


### [66] [Reinforcement Learning Meets Masked Generative Models: Mask-GRPO for Text-to-Image Generation](https://arxiv.org/abs/2510.13418)
*Yifu Luo,Xinhao Hu,Keyu Fan,Haoyuan Sun,Zeyu Chen,Bo Xia,Tiantian Zhang,Yongzhe Chang,Xueqian Wang*

Main category: cs.CV

TL;DR: Mask-GRPO首次将GRPO强化学习应用于掩码生成模型，通过多步决策和优化策略，显著提升文本到图像生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法主要针对扩散模型或自回归模型，忽略了掩码生成模型这一重要范式。

Method: 提出Mask-GRPO，将基于GRPO的强化学习融入掩码生成模型，重新定义转移概率，并将解掩过程建模为多步决策问题。采用去除KL约束、应用缩减策略和过滤低质量样本等策略。

Result: 在标准T2I基准测试和偏好对齐上显著提升基础模型Show-o的性能，超越现有最先进方法。

Conclusion: Mask-GRPO通过重新定义转移概率并采用多步决策方法，显著提升了文本到图像生成的性能，超越了现有最先进方法。

Abstract: Reinforcement learning (RL) has garnered increasing attention in
text-to-image (T2I) generation. However, most existing RL approaches are
tailored to either diffusion models or autoregressive models, overlooking an
important alternative: masked generative models. In this work, we propose
Mask-GRPO, the first method to incorporate Group Relative Policy Optimization
(GRPO)-based RL into this overlooked paradigm. Our core insight is to redefine
the transition probability, which is different from current approaches, and
formulate the unmasking process as a multi-step decision-making problem. To
further enhance our method, we explore several useful strategies, including
removing the KL constraint, applying the reduction strategy, and filtering out
low-quality samples. Using Mask-GRPO, we improve a base model, Show-o, with
substantial improvements on standard T2I benchmarks and preference alignment,
outperforming existing state-of-the-art approaches. The code is available on
https://github.com/xingzhejun/Mask-GRPO

</details>


### [67] [Ultra High-Resolution Image Inpainting with Patch-Based Content Consistency Adapter](https://arxiv.org/abs/2510.13419)
*Jianhui Zhang,Sheng Cheng,Qirui Sun,Jia Liu,Wang Luyang,Chaoyu Feng,Chen Fang,Lei Lei,Jue Wang,Shuaicheng Liu*

Main category: cs.CV

TL;DR: Patch-Adapter是一个双阶段适配器框架，通过全局结构一致性和局部细节保真实现4K+分辨率的文本引导图像修复，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在高分辨率和复杂纹理下难以保持内容一致性和提示对齐，Patch-Adapter旨在填补高分辨率修复的可扩展性差距。

Method: Patch-Adapter采用双阶段适配器架构：(1) Dual Context Adapter在降低的分辨率下学习掩码与非掩码区域的连贯性以建立全局结构一致性；(2) Reference Patch Adapter通过补丁级注意力机制实现全分辨率修复，通过自适应特征融合保留局部细节保真度。

Result: 实验表明，Patch-Adapter不仅解决了大规模修复中常见的伪影问题，还在OpenImages和Photo-Concept-Bucket数据集上实现了最先进的性能，在感知质量和文本提示对齐方面优于现有方法。

Conclusion: Patch-Adapter通过双阶段适配器架构有效解决了高分辨率图像修复中的全局语义一致性和局部细节保真问题，实现了4K+分辨率的文本引导图像修复，并在OpenImages和Photo-Concept-Bucket数据集上取得了最先进的性能。

Abstract: In this work, we present Patch-Adapter, an effective framework for
high-resolution text-guided image inpainting. Unlike existing methods limited
to lower resolutions, our approach achieves 4K+ resolution while maintaining
precise content consistency and prompt alignment, two critical challenges in
image inpainting that intensify with increasing resolution and texture
complexity. Patch-Adapter leverages a two-stage adapter architecture to scale
the diffusion model's resolution from 1K to 4K+ without requiring structural
overhauls: (1) Dual Context Adapter learns coherence between masked and
unmasked regions at reduced resolutions to establish global structural
consistency; and (2) Reference Patch Adapter implements a patch-level attention
mechanism for full-resolution inpainting, preserving local detail fidelity
through adaptive feature fusion. This dual-stage architecture uniquely
addresses the scalability gap in high-resolution inpainting by decoupling
global semantics from localized refinement. Experiments demonstrate that
Patch-Adapter not only resolves artifacts common in large-scale inpainting but
also achieves state-of-the-art performance on the OpenImages and
Photo-Concept-Bucket datasets, outperforming existing methods in both
perceptual quality and text-prompt adherence.

</details>


### [68] [CoDS: Enhancing Collaborative Perception in Heterogeneous Scenarios via Domain Separation](https://arxiv.org/abs/2510.13432)
*Yushan Han,Hui Zhang,Honglei Zhang,Chuntao Ding,Yuanzhouhan Cao,Yidong Li*

Main category: cs.CV

TL;DR: CoDS通过轻量级特征对齐和域分离模块，解决了异构协作感知中的特征差异问题，提升了模型效率。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法通常假设所有代理使用相同编码器，而实际异构场景中存在特征差异和噪声问题，导致模型效率低下。

Method: CoDS采用轻量级空间通道调整器（LSCR）和域分离模块（DADS）进行特征对齐，并使用域对齐互信息（DAMI）损失优化训练过程。

Result: 实验表明，CoDS能有效缓解异构场景中的特征差异，并在检测精度与推理效率之间取得平衡。

Conclusion: CoDS提出了一种在异构场景中有效解决特征差异的协作感知方法，通过轻量级空间通道调整器和域分离模块，实现了检测精度与推理效率的平衡。

Abstract: Collaborative perception has been proven to improve individual perception in
autonomous driving through multi-agent interaction. Nevertheless, most methods
often assume identical encoders for all agents, which does not hold true when
these models are deployed in real-world applications. To realize collaborative
perception in actual heterogeneous scenarios, existing methods usually align
neighbor features to those of the ego vehicle, which is vulnerable to noise
from domain gaps and thus fails to address feature discrepancies effectively.
Moreover, they adopt transformer-based modules for domain adaptation, which
causes the model inference inefficiency on mobile devices. To tackle these
issues, we propose CoDS, a Collaborative perception method that leverages
Domain Separation to address feature discrepancies in heterogeneous scenarios.
The CoDS employs two feature alignment modules, i.e., Lightweight
Spatial-Channel Resizer (LSCR) and Distribution Alignment via Domain Separation
(DADS). Besides, it utilizes the Domain Alignment Mutual Information (DAMI)
loss to ensure effective feature alignment. Specifically, the LSCR aligns the
neighbor feature across spatial and channel dimensions using a lightweight
convolutional layer. Subsequently, the DADS mitigates feature distribution
discrepancy with encoder-specific and encoder-agnostic domain separation
modules. The former removes domain-dependent information and the latter
captures task-related information. During training, the DAMI loss maximizes the
mutual information between aligned heterogeneous features to enhance the domain
separation process. The CoDS employs a fully convolutional architecture, which
ensures high inference efficiency. Extensive experiments demonstrate that the
CoDS effectively mitigates feature discrepancies in heterogeneous scenarios and
achieves a trade-off between detection accuracy and inference efficiency.

</details>


### [69] [Beyond Pixels: A Differentiable Pipeline for Probing Neuronal Selectivity in 3D](https://arxiv.org/abs/2510.13433)
*Pavithra Elumalai,Mohammad Bashiri,Goirik Chakrabarty,Suhas Shrinivasan,Fabian H. Sinz*

Main category: cs.CV

TL;DR: 该论文提出了一种可微分渲染方法，用于在3D中直接优化变形网格以探索神经元对物理场景属性的选择性，为神经科学研究提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要在2D像素上操作，难以分离对物理场景属性的选择性，因此需要开发一种直接在3D中操作的方法。

Method: 引入可微分渲染管道，优化变形网格以直接在3D中获取MEIs，参数化网格变形使用径向基函数，学习偏移和缩放以最大化神经元响应并保持几何规律性。

Result: 应用于猴子V4区模型，该方法能够探测神经元对可解释3D因素（如姿态和光照）的选择性。

Conclusion: 该方法通过可微分渲染和3D变形网格，成功探索了神经元对可解释3D场景属性的选择性，为系统神经科学和逆向图形学的结合提供了新途径。

Abstract: Visual perception relies on inference of 3D scene properties such as shape,
pose, and lighting. To understand how visual sensory neurons enable robust
perception, it is crucial to characterize their selectivity to such physically
interpretable factors. However, current approaches mainly operate on 2D pixels,
making it difficult to isolate selectivity for physical scene properties. To
address this limitation, we introduce a differentiable rendering pipeline that
optimizes deformable meshes to obtain MEIs directly in 3D. The method
parameterizes mesh deformations with radial basis functions and learns offsets
and scales that maximize neuronal responses while enforcing geometric
regularity. Applied to models of monkey area V4, our approach enables probing
neuronal selectivity to interpretable 3D factors such as pose and lighting.
This approach bridges inverse graphics with systems neuroscience, offering a
way to probe neural selectivity with physically grounded, 3D stimuli beyond
conventional pixel-based methods.

</details>


### [70] [Near-Infrared Hyperspectral Imaging Applications in Food Analysis -- Improving Algorithms and Methodologies](https://arxiv.org/abs/2510.13452)
*Ole-Christian Galbo Engstrøm*

Main category: cs.CV

TL;DR: NIR-HSI结合CNNs和PLS在食品质量分析中表现优异，2D CNN结合光谱卷积层效果最佳，同时开发了两个开源工具。


<details>
  <summary>Details</summary>
Motivation: 探索近红外高光谱成像在食品质量分析中的应用，解决化学参数空间分布建模的局限性，并开发高效的分析工具。

Method: 通过四项研究，比较了基于CNNs和PLS的模型，特别关注了联合空间-光谱分析的性能。使用了2D CNN结合光谱卷积层的方法，并与传统PLS方法进行了对比。

Result: 联合空间-光谱分析的CNNs模型在化学和物理视觉信息相关的参数建模中表现最佳。2D CNN结合光谱卷积层显著提升了预测性能，而PLS在分析化学参数均值时仍具竞争力。

Conclusion: 近红外高光谱成像（NIR-HSI）在食品质量分析中具有潜力，尤其是结合卷积神经网络（CNNs）和偏最小二乘法（PLS）的联合分析。对于化学参数的建模，2D CNN结合光谱卷积层表现更优，而PLS在分析样本化学参数均值时同样有效。此外，研究开发了两个开源Python包，分别用于快速PLS建模和高效的交叉验证。

Abstract: This thesis investigates the application of near-infrared hyperspectral
imaging (NIR-HSI) for food quality analysis. The investigation is conducted
through four studies operating with five research hypotheses. For several
analyses, the studies compare models based on convolutional neural networks
(CNNs) and partial least squares (PLS). Generally, joint spatio-spectral
analysis with CNNs outperforms spatial analysis with CNNs and spectral analysis
with PLS when modeling parameters where chemical and physical visual
information are relevant. When modeling chemical parameters with a
2-dimensional (2D) CNN, augmenting the CNN with an initial layer dedicated to
performing spectral convolution enhances its predictive performance by learning
a spectral preprocessing similar to that applied by domain experts. Still,
PLS-based spectral modeling performs equally well for analysis of the mean
content of chemical parameters in samples and is the recommended approach.
Modeling the spatial distribution of chemical parameters with NIR-HSI is
limited by the ability to obtain spatially resolved reference values.
Therefore, a study used bulk mean references for chemical map generation of fat
content in pork bellies. A PLS-based approach gave non-smooth chemical maps and
pixel-wise predictions outside the range of 0-100\%. Conversely, a 2D CNN
augmented with a spectral convolution layer mitigated all issues arising with
PLS. The final study attempted to model barley's germinative capacity by
analyzing NIR spectra, RGB images, and NIR-HSI images. However, the results
were inconclusive due to the dataset's low degree of germination. Additionally,
this thesis has led to the development of two open-sourced Python packages. The
first facilitates fast PLS-based modeling, while the second facilitates very
fast cross-validation of PLS and other classical machine learning models with a
new algorithm.

</details>


### [71] [VIST3A: Text-to-3D by Stitching a Multi-view Reconstruction Network to a Video Generator](https://arxiv.org/abs/2510.13454)
*Hyojun Go,Dominik Narnhofer,Goutam Bhat,Prune Truong,Federico Tombari,Konrad Schindler*

Main category: cs.CV

TL;DR: VIST3A框架通过缝合文本到视频生成器和3D解码器，提升了文本到3D生成质量，并支持点云生成。


<details>
  <summary>Details</summary>
Motivation: 结合现代潜在文本到视频模型和3D重建系统的优势，以提升文本到3D生成的效果。

Method: 通过模型缝合技术将文本到视频生成器与3D重建解码器结合，并使用直接奖励微调进行对齐。

Result: 所有测试组合均显著优于之前的文本到3D模型，且支持高质量的文本到点云生成。

Conclusion: VIST3A框架通过结合文本到视频生成器和3D重建解码器，显著提升了文本到3D生成的质量，并支持高质量的文本到点云生成。

Abstract: The rapid progress of large, pretrained models for both visual content
generation and 3D reconstruction opens up new possibilities for text-to-3D
generation. Intuitively, one could obtain a formidable 3D scene generator if
one were able to combine the power of a modern latent text-to-video model as
"generator" with the geometric abilities of a recent (feedforward) 3D
reconstruction system as "decoder". We introduce VIST3A, a general framework
that does just that, addressing two main challenges. First, the two components
must be joined in a way that preserves the rich knowledge encoded in their
weights. We revisit model stitching, i.e., we identify the layer in the 3D
decoder that best matches the latent representation produced by the
text-to-video generator and stitch the two parts together. That operation
requires only a small dataset and no labels. Second, the text-to-video
generator must be aligned with the stitched 3D decoder, to ensure that the
generated latents are decodable into consistent, perceptually convincing 3D
scene geometry. To that end, we adapt direct reward finetuning, a popular
technique for human preference alignment. We evaluate the proposed VIST3A
approach with different video generators and 3D reconstruction models. All
tested pairings markedly improve over prior text-to-3D models that output
Gaussian splats. Moreover, by choosing a suitable 3D base model, VIST3A also
enables high-quality text-to-pointmap generation.

</details>


### [72] [ExpressNet-MoE: A Hybrid Deep Neural Network for Emotion Recognition](https://arxiv.org/abs/2510.13493)
*Deeptimaan Banerjee,Prateek Gothwal,Ashis Kumer Biswas*

Main category: cs.CV

TL;DR: 提出ExpressNet-MoE模型，结合CNN和MoE框架，显著提高情感识别准确率，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的面部情感识别（FER）因头部位置变化、遮挡、光照变化和人口多样性等因素而具有挑战性，现有模型在参与度检测等应用中表现有限。

Method: 提出了一种混合深度学习模型ExpressNet-MoE，结合了CNN和多专家混合框架（MoE），通过动态选择最相关的专家网络和多尺度特征提取来提升性能。

Result: 在多个数据集上评估，模型在AffectNet (v7)上达到74.77%的准确率，AffectNet (v8)上72.55%，RAF-DB上84.29%，FER-2013上64.66%。

Conclusion: ExpressNet-MoE模型通过结合CNN和MoE框架，显著提高了情感识别的准确率，并展示了在多种数据集上的适应性，为实际应用中的端到端情感识别系统提供了可能。

Abstract: In many domains, including online education, healthcare, security, and
human-computer interaction, facial emotion recognition (FER) is essential.
Real-world FER is still difficult despite its significance because of some
factors such as variable head positions, occlusions, illumination shifts, and
demographic diversity. Engagement detection, which is essential for
applications like virtual learning and customer services, is frequently
challenging due to FER limitations by many current models. In this article, we
propose ExpressNet-MoE, a novel hybrid deep learning model that blends both
Convolution Neural Networks (CNNs) and Mixture of Experts (MoE) framework, to
overcome the difficulties. Our model dynamically chooses the most pertinent
expert networks, thus it aids in the generalization and providing flexibility
to model across a wide variety of datasets. Our model improves on the accuracy
of emotion recognition by utilizing multi-scale feature extraction to collect
both global and local facial features. ExpressNet-MoE includes numerous
CNN-based feature extractors, a MoE module for adaptive feature selection, and
finally a residual network backbone for deep feature learning. To demonstrate
efficacy of our proposed model we evaluated on several datasets, and compared
with current state-of-the-art methods. Our model achieves accuracies of 74.77%
on AffectNet (v7), 72.55% on AffectNet (v8), 84.29% on RAF-DB, and 64.66% on
FER-2013. The results show how adaptive our model is and how it may be used to
develop end-to-end emotion recognition systems in practical settings.
Reproducible codes and results are made publicly accessible at
https://github.com/DeeptimaanB/ExpressNet-MoE.

</details>


### [73] [High Semantic Features for the Continual Learning of Complex Emotions: a Lightweight Solution](https://arxiv.org/abs/2510.13534)
*Thibault Geoffroy,gauthier Gerspacher,Lionel Prevost*

Main category: cs.CV

TL;DR: 通过动作单元解决增量学习中的遗忘问题，在复杂情感识别任务中表现优异，准确率0.75，模型轻量。


<details>
  <summary>Details</summary>
Motivation: 增量学习过程中，旧任务的灾难性遗忘问题主要由任务间不适用的瞬态特征引起，特别是在复杂情感识别任务中。

Method: 利用描述面部肌肉运动的动作单元作为非瞬态、高语义特征，替代传统的浅层和深层卷积神经网络特征。

Result: 在CFEE数据集上，该方法在增量学习复杂情感时达到了0.75的准确率，且模型轻量、内存占用小。

Conclusion: 该论文提出了一种基于动作单元（Action Units）的增量学习方法，有效解决了复杂情感识别中的灾难性遗忘问题，并在CFEE数据集上取得了0.75的准确率，同时实现了轻量级模型。

Abstract: Incremental learning is a complex process due to potential catastrophic
forgetting of old tasks when learning new ones. This is mainly due to transient
features that do not fit from task to task. In this paper, we focus on complex
emotion recognition. First, we learn basic emotions and then, incrementally,
like humans, complex emotions. We show that Action Units, describing facial
muscle movements, are non-transient, highly semantical features that outperform
those extracted by both shallow and deep convolutional neural networks. Thanks
to this ability, our approach achieves interesting results when learning
incrementally complex, compound emotions with an accuracy of 0.75 on the CFEE
dataset and can be favorably compared to state-of-the-art results. Moreover, it
results in a lightweight model with a small memory footprint.

</details>


### [74] [Learning Neural Parametric 3D Breast Shape Models for Metrical Surface Reconstruction From Monocular RGB Videos](https://arxiv.org/abs/2510.13540)
*Maximilian Weiherer,Antonia von Riedheim,Vanessa Brébant,Bernhard Egger,Christoph Palm*

Main category: cs.CV

TL;DR: 低成本单目RGB视频3D乳房重建方法，结合局部隐式模型，提升精度与细节。


<details>
  <summary>Details</summary>
Motivation: 解决现有商业3D乳房扫描方案成本高昂及低成本替代方案依赖专有硬件或软件的问题。

Method: 采用基于解剖标志位置的局部神经符号距离函数（SDF）分解隐式乳房域，结合现成的运动结构（SfM）管道进行重建。

Result: liRBSM模型在重建质量上显著优于全局隐式模型（iRBSM），能恢复细节更丰富的表面几何，误差小于2毫米。

Conclusion: 该研究提出了一种低成本、可访问的3D乳房表面重建管道，结合局部隐式乳房形状模型（liRBSM），显著提升了重建质量和细节表现，误差控制在2毫米以内。

Abstract: We present a neural parametric 3D breast shape model and, based on this
model, introduce a low-cost and accessible 3D surface reconstruction pipeline
capable of recovering accurate breast geometry from a monocular RGB video. In
contrast to widely used, commercially available yet prohibitively expensive 3D
breast scanning solutions and existing low-cost alternatives, our method
requires neither specialized hardware nor proprietary software and can be used
with any device that is able to record RGB videos. The key building blocks of
our pipeline are a state-of-the-art, off-the-shelf Structure-from-motion
pipeline, paired with a parametric breast model for robust and metrically
correct surface reconstruction. Our model, similarly to the recently proposed
implicit Regensburg Breast Shape Model (iRBSM), leverages implicit neural
representations to model breast shapes. However, unlike the iRBSM, which
employs a single global neural signed distance function (SDF), our approach --
inspired by recent state-of-the-art face models -- decomposes the implicit
breast domain into multiple smaller regions, each represented by a local neural
SDF anchored at anatomical landmark positions. When incorporated into our
surface reconstruction pipeline, the proposed model, dubbed liRBSM (short for
localized iRBSM), significantly outperforms the iRBSM in terms of
reconstruction quality, yielding more detailed surface reconstruction than its
global counterpart. Overall, we find that the introduced pipeline is able to
recover high-quality 3D breast geometry within an error margin of less than 2
mm. Our method is fast (requires less than six minutes), fully transparent and
open-source, and -- together with the model -- publicly available at
https://rbsm.re-mic.de/local-implicit.

</details>


### [75] [XD-RCDepth: Lightweight Radar-Camera Depth Estimation with Explainability-Aligned and Distribution-Aware Distillation](https://arxiv.org/abs/2510.13565)
*Huawei Sun,Zixu Wang,Xiangyuan Peng,Julius Ott,Georg Stettinger,Lorenzo Servadei,Robert Wille*

Main category: cs.CV

TL;DR: XD-RCDepth是一种轻量化深度估计架构，通过两种知识蒸馏策略在参数减少29.7%的情况下保持精度，MAE降低7.97%，适用于自动驾驶。


<details>
  <summary>Details</summary>
Motivation: 深度估计对自动驾驶至关重要，雷达-相机融合在恶劣条件下提供互补的几何线索以增强鲁棒性。

Method: 提出了XD-RCDepth轻量化架构，引入了两种知识蒸馏策略：可解释性对齐蒸馏和深度分布蒸馏。

Result: XD-RCDepth参数减少了29.7%，MAE相比直接训练降低了7.97%，在nuScenes和ZJU-4DRadarCam数据集上实现了竞争性精度和实时效率。

Conclusion: XD-RCDepth通过两种知识蒸馏策略（可解释性对齐蒸馏和深度分布蒸馏）在保持轻量化的同时，实现了与最先进轻量化基线相当的精度，并在nuScenes和ZJU-4DRadarCam数据集上展示了实时效率。

Abstract: Depth estimation remains central to autonomous driving, and radar-camera
fusion offers robustness in adverse conditions by providing complementary
geometric cues. In this paper, we present XD-RCDepth, a lightweight
architecture that reduces the parameters by 29.7% relative to the
state-of-the-art lightweight baseline while maintaining comparable accuracy. To
preserve performance under compression and enhance interpretability, we
introduce two knowledge-distillation strategies: an explainability-aligned
distillation that transfers the teacher's saliency structure to the student,
and a depth-distribution distillation that recasts depth regression as soft
classification over discretized bins. Together, these components reduce the MAE
compared with direct training with 7.97% and deliver competitive accuracy with
real-time efficiency on nuScenes and ZJU-4DRadarCam datasets.

</details>


### [76] [Fusion Meets Diverse Conditions: A High-diversity Benchmark and Baseline for UAV-based Multimodal Object Detection with Condition Cues](https://arxiv.org/abs/2510.13620)
*Chen Chen,Kangcheng Bin,Ting Hu,Jiahao Qi,Xingyue Liu,Tianpeng Liu,Zhen Liu,Yongxiang Liu,Ping Zhong*

Main category: cs.CV

TL;DR: 论文介绍了高多样性数据集ATR-UMOD和PCDF方法，用于无人机在多样化条件下的物体检测，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集难以完全捕捉真实世界的复杂性，特别是在有限的成像条件下。为了应对这一挑战，引入了高多样性的数据集ATR-UMOD，并提出了PCDF方法。

Method: 提出了一种新颖的提示引导的条件感知动态融合（PCDF）方法，通过编码成像条件作为文本提示，利用任务特定的软门变换建模条件与多模态贡献之间的关系。

Result: 在ATR-UMOD数据集上的实验验证了PCDF的有效性。

Conclusion: PCDF方法通过利用标注的条件线索，自适应地重新分配多模态贡献，有效解决了无人机在多样化条件下物体检测的挑战。

Abstract: Unmanned aerial vehicles (UAV)-based object detection with visible (RGB) and
infrared (IR) images facilitates robust around-the-clock detection, driven by
advancements in deep learning techniques and the availability of high-quality
dataset. However, the existing dataset struggles to fully capture real-world
complexity for limited imaging conditions. To this end, we introduce a
high-diversity dataset ATR-UMOD covering varying scenarios, spanning altitudes
from 80m to 300m, angles from 0{\deg} to 75{\deg}, and all-day, all-year time
variations in rich weather and illumination conditions. Moreover, each RGB-IR
image pair is annotated with 6 condition attributes, offering valuable
high-level contextual information. To meet the challenge raised by such diverse
conditions, we propose a novel prompt-guided condition-aware dynamic fusion
(PCDF) to adaptively reassign multimodal contributions by leveraging annotated
condition cues. By encoding imaging conditions as text prompts, PCDF
effectively models the relationship between conditions and multimodal
contributions through a task-specific soft-gating transformation. A
prompt-guided condition-decoupling module further ensures the availability in
practice without condition annotations. Experiments on ATR-UMOD dataset reveal
the effectiveness of PCDF.

</details>


### [77] [AVAR-Net: A Lightweight Audio-Visual Anomaly Recognition Framework with a Benchmark Dataset](https://arxiv.org/abs/2510.13630)
*Amjid Ali,Zulfiqar Ahmad Khan,Altaf Hussain,Muhammad Munsif,Adnan Hussain,Sung Wook Baik*

Main category: cs.CV

TL;DR: AVAR-Net是一个轻量级音频-视觉异常识别框架，通过Wav2Vec2和MobileViT提取特征，结合早期融合和MTCN模型，在VAAR和XD-Violence数据集上表现优异，并提出VAAR数据集作为新基准。


<details>
  <summary>Details</summary>
Motivation: 现有异常识别方法主要依赖视觉数据，在遮挡、低光照等复杂条件下不可靠，且缺乏大规模同步音频-视觉数据集，阻碍了多模态异常识别的发展。

Method: AVAR-Net由音频特征提取器、视频特征提取器、融合策略和序列模式学习网络组成，采用Wav2Vec2和MobileViT分别提取音频和视频特征，通过早期融合机制和MTCN模型学习跨模态关系。

Result: AVAR-Net在VAAR数据集上达到89.29%的准确率，在XD-Violence数据集上平均精度提升2.8%，优于现有最先进方法。

Conclusion: AVAR-Net框架在VAAR和XD-Violence数据集上分别达到了89.29%的准确率和88.56%的平均精度，展示了其高效性、泛化能力，并验证了VAAR数据集作为多模态异常识别研究的价值。

Abstract: Anomaly recognition plays a vital role in surveillance, transportation,
healthcare, and public safety. However, most existing approaches rely solely on
visual data, making them unreliable under challenging conditions such as
occlusion, low illumination, and adverse weather. Moreover, the absence of
large-scale synchronized audio-visual datasets has hindered progress in
multimodal anomaly recognition. To address these limitations, this study
presents AVAR-Net, a lightweight and efficient audio-visual anomaly recognition
framework designed for real-world environments. AVAR-Net consists of four main
modules: an audio feature extractor, a video feature extractor, fusion
strategy, and a sequential pattern learning network that models cross-modal
relationships for anomaly recognition. Specifically, the Wav2Vec2 model
extracts robust temporal features from raw audio, while MobileViT captures both
local and global visual representations from video frames. An early fusion
mechanism combines these modalities, and a Multi-Stage Temporal Convolutional
Network (MTCN) model that learns long-range temporal dependencies within the
fused representation, enabling robust spatiotemporal reasoning. A novel
Visual-Audio Anomaly Recognition (VAAR) dataset, is also introduced, serving as
a medium-scale benchmark containing 3,000 real-world videos with synchronized
audio across ten diverse anomaly classes. Experimental evaluations demonstrate
that AVAR-Net achieves 89.29% accuracy on VAAR and 88.56% Average Precision on
the XD-Violence dataset, improving Average Precision by 2.8% over existing
state-of-the-art methods. These results highlight the effectiveness,
efficiency, and generalization capability of the proposed framework, as well as
the utility of VAAR as a benchmark for advancing multimodal anomaly recognition
research.

</details>


### [78] [Challenges, Advances, and Evaluation Metrics in Medical Image Enhancement: A Systematic Literature Review](https://arxiv.org/abs/2510.13638)
*Chun Wai Chin,Haniza Yazid,Hoi Leong Lee*

Main category: cs.CV

TL;DR: 本文综述了医学图像增强的研究进展，指出MRI和多模态成像最受关注，深度学习技术逐渐重要，但专业模态研究不足。评估方法多样，非参考指标为主。


<details>
  <summary>Details</summary>
Motivation: 医学图像增强对于提高诊断图像的质量和可解释性至关重要，有助于早期检测、准确诊断和有效治疗规划。尽管成像技术有所进步，但医学图像仍常面临噪声、伪影和低对比度等挑战。

Method: 本系统综述遵循PRISMA方法，分析了39篇同行评审的研究，探讨了不同成像模态下各种增强方法的有效性及评估指标的重要性。

Result: 研究发现，MRI和多模态成像得到最多关注，而组织病理学、内窥镜和骨闪烁等专业模态研究较少。39项研究中，29项采用传统数学方法，9项专注于深度学习技术，1项探索混合方法。在图像质量评估方面，18项研究同时使用基于参考和非参考的指标，9项仅依赖基于参考的指标，12项仅使用非参考指标，共引入65种IQA指标，主要为非参考型。

Conclusion: 本文综述了医学图像增强领域的关键挑战、最新进展和评估方法，指出了当前研究的局限性、研究空白以及未来潜在的发展方向。

Abstract: Medical image enhancement is crucial for improving the quality and
interpretability of diagnostic images, ultimately supporting early detection,
accurate diagnosis, and effective treatment planning. Despite advancements in
imaging technologies such as X-ray, CT, MRI, and ultrasound, medical images
often suffer from challenges like noise, artifacts, and low contrast, which
limit their diagnostic potential. Addressing these challenges requires robust
preprocessing, denoising algorithms, and advanced enhancement methods, with
deep learning techniques playing an increasingly significant role. This
systematic literature review, following the PRISMA approach, investigates the
key challenges, recent advancements, and evaluation metrics in medical image
enhancement. By analyzing findings from 39 peer-reviewed studies, this review
provides insights into the effectiveness of various enhancement methods across
different imaging modalities and the importance of evaluation metrics in
assessing their impact. Key issues like low contrast and noise are identified
as the most frequent, with MRI and multi-modal imaging receiving the most
attention, while specialized modalities such as histopathology, endoscopy, and
bone scintigraphy remain underexplored. Out of the 39 studies, 29 utilize
conventional mathematical methods, 9 focus on deep learning techniques, and 1
explores a hybrid approach. In terms of image quality assessment, 18 studies
employ both reference-based and non-reference-based metrics, 9 rely solely on
reference-based metrics, and 12 use only non-reference-based metrics, with a
total of 65 IQA metrics introduced, predominantly non-reference-based. This
review highlights current limitations, research gaps, and potential future
directions for advancing medical image enhancement.

</details>


### [79] [Towards Adversarial Robustness and Uncertainty Quantification in DINOv2-based Few-Shot Anomaly Detection](https://arxiv.org/abs/2510.13643)
*Akib Mohammed Khan,Bartosz Krawczyk*

Main category: cs.CV

TL;DR: 该研究系统评估了DINOv2在少样本异常检测中的对抗鲁棒性和不确定性校准问题，提出了一种基于Platt缩放的校准方法，显著提升了对抗性攻击检测能力并降低了校准误差。


<details>
  <summary>Details</summary>
Motivation: 探讨基础模型（如DINOv2）在少样本异常检测中的对抗性扰动敏感性和异常分数的不确定性校准问题，以提升异常检测系统的可信度和实际部署能力。

Method: 研究在AnomalyDINO的基础上，通过附加一个轻量级线性头到冻结的DINOv2特征上，进行白盒梯度攻击，同时评估了FGSM攻击对性能的影响，并应用事后Platt缩放对异常分数进行校准。

Result: 研究发现微小的扰动可以翻转特征空间中的最近邻关系，导致错误分类，且原始异常分数校准较差。通过Platt缩放校准的后验概率在对抗性扰动输入上表现出更高的预测熵，同时降低了校准误差（ECE）。

Conclusion: 该研究揭示了基于DINOv2的小样本异常检测器在对抗性扰动和不确定性校准方面的具体漏洞，提出了一个评估协议和基线方法，强调了对抗鲁棒性和不确定性量化在异常检测系统中的必要性。

Abstract: Foundation models such as DINOv2 have shown strong performance in few-shot
anomaly detection, yet two key questions remain unexamined: (i) how susceptible
are these detectors to adversarial perturbations; and (ii) how well do their
anomaly scores reflect calibrated uncertainty? Building on AnomalyDINO, a
training-free deep nearest-neighbor detector over DINOv2 features, we present
one of the first systematic studies of adversarial attacks and uncertainty
estimation in this setting. To enable white-box gradient attacks while
preserving test-time behavior, we attach a lightweight linear head to frozen
DINOv2 features only for crafting perturbations. Using this heuristic, we
evaluate the impact of FGSM across the MVTec-AD and VisA datasets and observe
consistent drops in F1, AUROC, AP, and G-mean, indicating that imperceptible
perturbations can flip nearest-neighbor relations in feature space to induce
confident misclassification. Complementing robustness, we probe reliability and
find that raw anomaly scores are poorly calibrated, revealing a gap between
confidence and correctness that limits safety-critical use. As a simple, strong
baseline toward trustworthiness, we apply post-hoc Platt scaling to the anomaly
scores for uncertainty estimation. The resulting calibrated posteriors yield
significantly higher predictive entropy on adversarially perturbed inputs than
on clean ones, enabling a practical flagging mechanism for attack detection
while reducing calibration error (ECE). Our findings surface concrete
vulnerabilities in DINOv2-based few-shot anomaly detectors and establish an
evaluation protocol and baseline for robust, uncertainty-aware anomaly
detection. We argue that adversarial robustness and principled uncertainty
quantification are not optional add-ons but essential capabilities if anomaly
detection systems are to be trustworthy and ready for real-world deployment.

</details>


### [80] [Local-Global Context-Aware and Structure-Preserving Image Super-Resolution](https://arxiv.org/abs/2510.13649)
*Sanchar Palit,Subhasis Chaudhuri,Biplab Banerjee*

Main category: cs.CV

TL;DR: 本文提出了一种结合局部-全局上下文感知注意力和分布-感知对齐条件机制的图像超分辨率框架，有效解决了现有方法在处理退化图像时的不足，生成了高质量且结构一致的结果。


<details>
  <summary>Details</summary>
Motivation: 尽管现有方法利用预训练文本到图像模型（如Stable Diffusion）在超分辨率任务中取得先进成果，但在处理多样化和高度退化图像时仍存在噪声放大或错误内容生成的问题。

Method: 采用局部-全局上下文感知注意力（Local-Global Context-Aware Attention）和分布-感知对齐条件机制，以保持局部和全局像素关系，并增强感知保真度。

Result: 实验表明，该方法能生成结构一致的高质量图像，减少伪影并确保真实的细节恢复。

Conclusion: 本文提出的上下文精确图像超分辨率框架通过局部-全局上下文感知注意力和分布-感知对齐条件机制，有效生成了高质量图像，并在多个超分辨率基准测试中验证了其有效性。

Abstract: Diffusion models have recently achieved significant success in various image
manipulation tasks, including image super-resolution and perceptual quality
enhancement. Pretrained text-to-image models, such as Stable Diffusion, have
exhibited strong capabilities in synthesizing realistic image content, which
makes them particularly attractive for addressing super-resolution tasks. While
some existing approaches leverage these models to achieve state-of-the-art
results, they often struggle when applied to diverse and highly degraded
images, leading to noise amplification or incorrect content generation. To
address these limitations, we propose a contextually precise image
super-resolution framework that effectively maintains both local and global
pixel relationships through Local-Global Context-Aware Attention, enabling the
generation of high-quality images. Furthermore, we propose a distribution- and
perceptual-aligned conditioning mechanism in the pixel space to enhance
perceptual fidelity. This mechanism captures fine-grained pixel-level
representations while progressively preserving and refining structural
information, transitioning from local content details to the global structural
composition. During inference, our method generates high-quality images that
are structurally consistent with the original content, mitigating artifacts and
ensuring realistic detail restoration. Extensive experiments on multiple
super-resolution benchmarks demonstrate the effectiveness of our approach in
producing high-fidelity, perceptually accurate reconstructions.

</details>


### [81] [EditCast3D: Single-Frame-Guided 3D Editing with Video Propagation and View Selection](https://arxiv.org/abs/2510.13652)
*Huaizhi Qu,Ruichen Zhang,Shuqing Luo,Luchao Qi,Zhihao Zhang,Xiaoming Liu,Roni Sengupta,Tianlong Chen*

Main category: cs.CV

TL;DR: EditCast3D通过视频生成模型和视图选择策略，提供了一种高效且一致的3D编辑方法，减少了计算成本并提升了编辑质量。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在图像编辑中取得了显著进展，但其在3D编辑中的应用仍未被充分探索，且现有方法在计算成本和API限制上面临挑战。

Method: EditCast3D采用视频生成基础模型，通过首帧编辑传播到整个数据集，并引入视图选择策略以确保多视图对齐。

Result: EditCast3D在常用3D编辑数据集上表现出优于现有方法的编辑质量和效率。

Conclusion: EditCast3D被证明是一种可扩展且通用的范式，能够高效地将基础模型集成到3D编辑流程中。

Abstract: Recent advances in foundation models have driven remarkable progress in image
editing, yet their extension to 3D editing remains underexplored. A natural
approach is to replace the image editing modules in existing workflows with
foundation models. However, their heavy computational demands and the
restrictions and costs of closed-source APIs make plugging these models into
existing iterative editing strategies impractical. To address this limitation,
we propose EditCast3D, a pipeline that employs video generation foundation
models to propagate edits from a single first frame across the entire dataset
prior to reconstruction. While editing propagation enables dataset-level
editing via video models, its consistency remains suboptimal for 3D
reconstruction, where multi-view alignment is essential. To overcome this,
EditCast3D introduces a view selection strategy that explicitly identifies
consistent and reconstruction-friendly views and adopts feedforward
reconstruction without requiring costly refinement. In combination, the
pipeline both minimizes reliance on expensive image editing and mitigates
prompt ambiguities that arise when applying foundation models independently
across images. We evaluate EditCast3D on commonly used 3D editing datasets and
compare it against state-of-the-art 3D editing baselines, demonstrating
superior editing quality and high efficiency. These results establish
EditCast3D as a scalable and general paradigm for integrating foundation models
into 3D editing pipelines. The code is available at
https://github.com/UNITES-Lab/EditCast3D

</details>


### [82] [OmniGaze: Reward-inspired Generalizable Gaze Estimation In The Wild](https://arxiv.org/abs/2510.13660)
*Hongyu Qu,Jianan Wei,Xiangbo Shu,Yazhou Yao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: OmniGaze通过半监督学习和奖励模型，利用多样化未标记数据提升3D视线估计的跨域性能，达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有3D视线估计方法因标注数据稀缺和多样性不足，难以跨域泛化。OmniGaze旨在利用多样化的未标记数据解决这一问题。

Method: OmniGaze采用伪标签策略和奖励模型，结合视觉嵌入和多模态大语言模型的语义线索，筛选高质量伪标签并加权计算损失。

Result: OmniGaze在五个数据集上（域内和跨域）表现最佳，并在四个未见数据集上展示零样本泛化能力。

Conclusion: OmniGaze通过半监督框架和奖励模型，有效利用大规模未标记数据，提升了3D视线估计的跨域泛化能力，并在多个数据集上达到最先进性能。

Abstract: Current 3D gaze estimation methods struggle to generalize across diverse data
domains, primarily due to i) the scarcity of annotated datasets, and ii) the
insufficient diversity of labeled data. In this work, we present OmniGaze, a
semi-supervised framework for 3D gaze estimation, which utilizes large-scale
unlabeled data collected from diverse and unconstrained real-world environments
to mitigate domain bias and generalize gaze estimation in the wild. First, we
build a diverse collection of unlabeled facial images, varying in facial
appearances, background environments, illumination conditions, head poses, and
eye occlusions. In order to leverage unlabeled data spanning a broader
distribution, OmniGaze adopts a standard pseudo-labeling strategy and devises a
reward model to assess the reliability of pseudo labels. Beyond pseudo labels
as 3D direction vectors, the reward model also incorporates visual embeddings
extracted by an off-the-shelf visual encoder and semantic cues from gaze
perspective generated by prompting a Multimodal Large Language Model to compute
confidence scores. Then, these scores are utilized to select high-quality
pseudo labels and weight them for loss computation. Extensive experiments
demonstrate that OmniGaze achieves state-of-the-art performance on five
datasets under both in-domain and cross-domain settings. Furthermore, we also
evaluate the efficacy of OmniGaze as a scalable data engine for gaze
estimation, which exhibits robust zero-shot generalization on four unseen
datasets.

</details>


### [83] [NTIRE 2025 Challenge on Low Light Image Enhancement: Methods and Results](https://arxiv.org/abs/2510.13670)
*Xiaoning Liu,Zongwei Wu,Florin-Alexandru Vasluianu,Hailong Yan,Bin Ren,Yulun Zhang,Shuhang Gu,Le Zhang,Ce Zhu,Radu Timofte,Kangbiao Shi,Yixu Feng,Tao Hu,Yu Cao,Peng Wu,Yijin Liang,Yanning Zhang,Qingsen Yan,Han Zhou,Wei Dong,Yan Min,Mohab Kishawy,Jun Chen,Pengpeng Yu,Anjin Park,Seung-Soo Lee,Young-Joon Park,Zixiao Hu,Junyv Liu,Huilin Zhang,Jun Zhang,Fei Wan,Bingxin Xu,Hongzhe Liu,Cheng Xu,Weiguo Pan,Songyin Dai,Xunpeng Yi,Qinglong Yan,Yibing Zhang,Jiayi Ma,Changhui Hu,Kerui Hu,Donghang Jing,Tiesheng Chen,Zhi Jin,Hongjun Wu,Biao Huang,Haitao Ling,Jiahao Wu,Dandan Zhan,G Gyaneshwar Rao,Vijayalaxmi Ashok Aralikatti,Nikhil Akalwadi,Ramesh Ashok Tabib,Uma Mudenagudi,Ruirui Lin,Guoxi Huang,Nantheera Anantrasirichai,Qirui Yang,Alexandru Brateanu,Ciprian Orhei,Cosmin Ancuti,Daniel Feijoo,Juan C. Benito,Álvaro García,Marcos V. Conde,Yang Qin,Raul Balmez,Anas M. Ali,Bilel Benjdira,Wadii Boulila,Tianyi Mao,Huan Zheng,Yanyan Wei,Shengeng Tang,Dan Guo,Zhao Zhang,Sabari Nathan,K Uma,A Sasithradevi,B Sathya Bama,S. Mohamed Mansoor Roomi,Ao Li,Xiangtao Zhang,Zhe Liu,Yijie Tang,Jialong Tang,Zhicheng Fu,Gong Chen,Joe Nasti,John Nicholson,Zeyu Xiao,Zhuoyuan Li,Ashutosh Kulkarni,Prashant W. Patil,Santosh Kumar Vipparthi,Subrahmanyam Murala,Duan Liu,Weile Li,Hangyuan Lu,Rixian Liu,Tengfeng Wang,Jinxing Liang,Chenxin Yu*

Main category: cs.CV

TL;DR: 论文总结了NTIRE 2025低光图像增强挑战赛的成果，展示了该领域的最新技术和未来潜力。


<details>
  <summary>Details</summary>
Motivation: 低光环境下图像质量提升是计算机视觉中的重要挑战，该挑战赛旨在推动技术进步并寻找最有效的解决方案。

Method: 论文通过评估762名参赛者中28支团队的提交方案，对比分析了各种网络在低光图像增强中的表现。

Result: 挑战赛结果显示，部分网络能够显著提升低光图像的亮度和清晰度，展现了该领域的显著进展。

Conclusion: 该论文全面回顾了NTIRE 2025低光图像增强挑战赛，展示了该领域的最新进展和未来方向。

Abstract: This paper presents a comprehensive review of the NTIRE 2025 Low-Light Image
Enhancement (LLIE) Challenge, highlighting the proposed solutions and final
outcomes. The objective of the challenge is to identify effective networks
capable of producing brighter, clearer, and visually compelling images under
diverse and challenging conditions. A remarkable total of 762 participants
registered for the competition, with 28 teams ultimately submitting valid
entries. This paper thoroughly evaluates the state-of-the-art advancements in
LLIE, showcasing the significant progress.

</details>


### [84] [Seeing and Knowing in the Wild: Open-domain Visual Entity Recognition with Large-scale Knowledge Graphs via Contrastive Learning](https://arxiv.org/abs/2510.13675)
*Hongkuan Zhou,Lavdim Halilaj,Sebastian Monka,Stefan Schmid,Yuqicheng Zhu,Jingcheng Wu,Nadeem Nazer,Steffen Staab*

Main category: cs.CV

TL;DR: KnowCoL框架通过结合视觉、文本和结构化知识，显著提升了开放域视觉实体识别的性能，尤其在罕见和未见实体上表现优异。


<details>
  <summary>Details</summary>
Motivation: 开放域视觉实体识别任务在开放集条件下运行，目标实体大多在训练中未见且呈现长尾分布，存在监督有限、视觉模糊度高和语义歧义等挑战。

Method: 提出了一种知识引导的对比学习（KnowCoL）框架，将图像和文本描述结合到由Wikidata结构化信息支持的共享语义空间中。

Result: 在OVEN基准测试中，最小的模型在未见实体上的准确率比现有技术提高了10.5%，尽管模型规模小了35倍。

Conclusion: 结合视觉、文本和结构化知识的KnowCoL框架显著提高了开放域视觉实体识别的准确性，特别是在罕见和未见实体上。

Abstract: Open-domain visual entity recognition aims to identify and link entities
depicted in images to a vast and evolving set of real-world concepts, such as
those found in Wikidata. Unlike conventional classification tasks with fixed
label sets, it operates under open-set conditions, where most target entities
are unseen during training and exhibit long-tail distributions. This makes the
task inherently challenging due to limited supervision, high visual ambiguity,
and the need for semantic disambiguation. In this work, we propose a
Knowledge-guided Contrastive Learning (KnowCoL) framework that combines both
images and text descriptions into a shared semantic space grounded by
structured information from Wikidata. By abstracting visual and textual inputs
to a conceptual level, the model leverages entity descriptions, type
hierarchies, and relational context to support zero-shot entity recognition. We
evaluate our approach on the OVEN benchmark, a large-scale open-domain visual
recognition dataset with Wikidata IDs as the label space. Our experiments show
that using visual, textual, and structured knowledge greatly improves accuracy,
especially for rare and unseen entities. Our smallest model improves the
accuracy on unseen entities by 10.5% compared to the state-of-the-art, despite
being 35 times smaller.

</details>


### [85] [FlashWorld: High-quality 3D Scene Generation within Seconds](https://arxiv.org/abs/2510.13678)
*Xinyang Li,Tengfei Wang,Zixiao Gu,Shengchuan Zhang,Chunchao Guo,Liujuan Cao*

Main category: cs.CV

TL;DR: FlashWorld是一种生成模型，通过双模式训练和蒸馏技术，实现从单图或文本提示快速生成高质量3D场景，速度提升10~100倍。


<details>
  <summary>Details</summary>
Motivation: 传统MV导向方法生成多视图图像后需3D重建，速度慢且质量受限；3D导向方法直接生成3D高斯表示但视觉质量差。FlashWorld旨在结合两者优势，实现快速且高质量的3D生成。

Method: 采用双模式预训练（支持MV导向和3D导向生成）和跨模式后训练蒸馏，通过视频扩散模型的先验知识提升3D一致性生成质量。

Result: 实验证明FlashWorld生成速度比先前工作快10~100倍，渲染质量更优，且能泛化至分布外输入。

Conclusion: FlashWorld通过双模式预训练和跨模式后训练蒸馏，成功整合了MV导向和3D导向方法的优势，实现了快速且高质量的3D场景生成。

Abstract: We propose FlashWorld, a generative model that produces 3D scenes from a
single image or text prompt in seconds, 10~100$\times$ faster than previous
works while possessing superior rendering quality. Our approach shifts from the
conventional multi-view-oriented (MV-oriented) paradigm, which generates
multi-view images for subsequent 3D reconstruction, to a 3D-oriented approach
where the model directly produces 3D Gaussian representations during multi-view
generation. While ensuring 3D consistency, 3D-oriented method typically suffers
poor visual quality. FlashWorld includes a dual-mode pre-training phase
followed by a cross-mode post-training phase, effectively integrating the
strengths of both paradigms. Specifically, leveraging the prior from a video
diffusion model, we first pre-train a dual-mode multi-view diffusion model,
which jointly supports MV-oriented and 3D-oriented generation modes. To bridge
the quality gap in 3D-oriented generation, we further propose a cross-mode
post-training distillation by matching distribution from consistent 3D-oriented
mode to high-quality MV-oriented mode. This not only enhances visual quality
while maintaining 3D consistency, but also reduces the required denoising steps
for inference. Also, we propose a strategy to leverage massive single-view
images and text prompts during this process to enhance the model's
generalization to out-of-distribution inputs. Extensive experiments demonstrate
the superiority and efficiency of our method.

</details>


### [86] [Generating healthy counterfactuals with denoising diffusion bridge models](https://arxiv.org/abs/2510.13684)
*Ana Lawry Aguila,Peirong Liu,Marina Crespo Aguirre,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: DDBM通过结合健康与病理图像信息，生成更准确的健康反事实图像，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中生成健康反事实图像具有重要应用价值，但现有方法在平衡去除异常与保留个体特征方面存在挑战。

Method: 提出了一种新颖的去噪扩散桥模型（DDBMs）应用，该模型不仅基于初始点（健康图像）还基于终点（合成生成的病理图像）来调节扩散过程。

Result: 实验结果表明，DDBM在分割和异常检测任务中优于先前提出的扩散模型和全监督方法。

Conclusion: 使用去噪扩散桥模型（DDBMs）生成健康反事实图像在医学影像中表现出显著优势，尤其在保留个体解剖特征的同时选择性去除病理区域方面优于现有方法。

Abstract: Generating healthy counterfactuals from pathological images holds significant
promise in medical imaging, e.g., in anomaly detection or for application of
analysis tools that are designed for healthy scans. These counterfactuals
should represent what a patient's scan would plausibly look like in the absence
of pathology, preserving individual anatomical characteristics while modifying
only the pathological regions. Denoising diffusion probabilistic models (DDPMs)
have become popular methods for generating healthy counterfactuals of pathology
data. Typically, this involves training on solely healthy data with the
assumption that a partial denoising process will be unable to model disease
regions and will instead reconstruct a closely matched healthy counterpart.
More recent methods have incorporated synthetic pathological images to better
guide the diffusion process. However, it remains challenging to guide the
generative process in a way that effectively balances the removal of anomalies
with the retention of subject-specific features. To solve this problem, we
propose a novel application of denoising diffusion bridge models (DDBMs) -
which, unlike DDPMs, condition the diffusion process not only on the initial
point (i.e., the healthy image), but also on the final point (i.e., a
corresponding synthetically generated pathological image). Treating the
pathological image as a structurally informative prior enables us to generate
counterfactuals that closely match the patient's anatomy while selectively
removing pathology. The results show that our DDBM outperforms previously
proposed diffusion models and fully supervised approaches at segmentation and
anomaly detection tasks.

</details>


### [87] [Risk-adaptive Activation Steering for Safe Multimodal Large Language Models](https://arxiv.org/abs/2510.13698)
*Jonghyun Park,Minhyuk Seo,Jonghyun Choi*

Main category: cs.CV

TL;DR: RAS通过强化跨模态注意力，有效提升多模态AI模型的安全性，同时保持性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现代AI模型在处理多模态查询时，常因图像中嵌入的有害意图而脆弱。传统的安全对齐方法成本高昂，而推理时对齐则存在过度拒绝和速度慢的问题。

Method: 提出风险自适应激活导向（RAS），通过重新制定查询以强化对安全关键图像区域的跨模态注意力，实现查询级别的准确风险评估。

Result: RAS在多个基准测试中显著降低了攻击成功率，保持了任务性能，并提高了推理速度。

Conclusion: RAS（风险自适应激活导向）通过强化跨模态注意力，显著降低了攻击成功率，保持了通用任务性能，并提高了推理速度。

Abstract: One of the key challenges of modern AI models is ensuring that they provide
helpful responses to benign queries while refusing malicious ones. But often,
the models are vulnerable to multimodal queries with harmful intent embedded in
images. One approach for safety alignment is training with extensive safety
datasets at the significant costs in both dataset curation and training.
Inference-time alignment mitigates these costs, but introduces two drawbacks:
excessive refusals from misclassified benign queries and slower inference speed
due to iterative output adjustments. To overcome these limitations, we propose
to reformulate queries to strengthen cross-modal attention to safety-critical
image regions, enabling accurate risk assessment at the query level. Using the
assessed risk, it adaptively steers activations to generate responses that are
safe and helpful without overhead from iterative output adjustments. We call
this Risk-adaptive Activation Steering (RAS). Extensive experiments across
multiple benchmarks on multimodal safety and utility demonstrate that the RAS
significantly reduces attack success rates, preserves general task performance,
and improves inference speed over prior inference-time defenses.

</details>


### [88] [Circle of Willis Centerline Graphs: A Dataset and Baseline Algorithm](https://arxiv.org/abs/2510.13720)
*Fabio Musio,Norman Juchler,Kaiyuan Yang,Suprosanna Shit,Chinmay Prabhakar,Bjoern Menze,Sven Hirsch*

Main category: cs.CV

TL;DR: 该论文提出了一种基于学习的骨架化与图连接相结合的基线算法，用于从TopCoW数据集中提取解剖学上合理的中心线，展示了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于CoW的复杂几何形状，传统骨架化技术难以提取可靠的中心线，且公开可用的中心线数据集稀缺。

Method: 使用基于细化的骨架化算法从TopCoW数据集中提取和整理中心线图和形态特征，结合U-Net骨架化和A*图连接开发基线算法。

Result: 基线算法以高精度（F1 = 1）重建图拓扑结构，参考图和预测图之间的平均欧几里得节点距离低于一个体素。特征如段半径、长度和分叉比率显示出强鲁棒性，中值相对误差低于5%，Pearson相关系数高于0.95。

Conclusion: 该研究强调了基于学习的骨架化与图连接相结合在提取解剖学上合理的中心线方面的实用性，并强调通过评估解剖学准确性和特征鲁棒性超越简单的基于体素的测量的重要性。数据集和基线算法已发布以支持进一步的方法开发和临床研究。

Abstract: The Circle of Willis (CoW) is a critical network of arteries in the brain,
often implicated in cerebrovascular pathologies. Voxel-level segmentation is an
important first step toward an automated CoW assessment, but a full
quantitative analysis requires centerline representations. However,
conventional skeletonization techniques often struggle to extract reliable
centerlines due to the CoW's complex geometry, and publicly available
centerline datasets remain scarce. To address these challenges, we used a
thinning-based skeletonization algorithm to extract and curate centerline
graphs and morphometric features from the TopCoW dataset, which includes 200
stroke patients, each imaged with MRA and CTA. The curated graphs were used to
develop a baseline algorithm for centerline and feature extraction, combining
U-Net-based skeletonization with A* graph connection. Performance was evaluated
on a held-out test set, focusing on anatomical accuracy and feature robustness.
Further, we used the extracted features to predict the frequency of fetal PCA
variants, confirm theoretical bifurcation optimality relations, and detect
subtle modality differences. The baseline algorithm consistently reconstructed
graph topology with high accuracy (F1 = 1), and the average Euclidean node
distance between reference and predicted graphs was below one voxel. Features
such as segment radius, length, and bifurcation ratios showed strong
robustness, with median relative errors below 5% and Pearson correlations above
0.95. Our results demonstrate the utility of learning-based skeletonization
combined with graph connection for anatomically plausible centerline
extraction. We emphasize the importance of going beyond simple voxel-based
measures by evaluating anatomical accuracy and feature robustness. The dataset
and baseline algorithm have been released to support further method development
and clinical research.

</details>


### [89] [LiFMCR: Dataset and Benchmark for Light Field Multi-Camera Registration](https://arxiv.org/abs/2510.13729)
*Aymeric Fleith,Julian Zirbel,Daniel Cremers,Niclas Zeller*

Main category: cs.CV

TL;DR: LiFMCR是一个新型多光场相机配准数据集，提供同步图像序列和高精度姿态数据，支持两种配准方法验证。


<details>
  <summary>Details</summary>
Motivation: 现有光场数据集多为单相机设置且缺乏外部基准，LiFMCR旨在填补这一空白，支持多相机光场配准的严格评估。

Method: 论文提出了两种配准方法：基于RANSAC的3D变换估计和光场PnP算法，均结合了光场相机模型。

Result: 实验结果显示两种配准方法与高精度地面真实数据对齐良好。

Conclusion: LiFMCR数据集为多微透镜阵列光场相机的配准提供了可靠的外部基准，并通过两种互补的配准方法验证了其有效性。

Abstract: We present LiFMCR, a novel dataset for the registration of multiple micro
lens array (MLA)-based light field cameras. While existing light field datasets
are limited to single-camera setups and typically lack external ground truth,
LiFMCR provides synchronized image sequences from two high-resolution Raytrix
R32 plenoptic cameras, together with high-precision 6-degrees of freedom (DoF)
poses recorded by a Vicon motion capture system. This unique combination
enables rigorous evaluation of multi-camera light field registration methods.
  As a baseline, we provide two complementary registration approaches: a robust
3D transformation estimation via a RANSAC-based method using cross-view point
clouds, and a plenoptic PnP algorithm estimating extrinsic 6-DoF poses from
single light field images. Both explicitly integrate the plenoptic camera
model, enabling accurate and scalable multi-camera registration. Experiments
show strong alignment with the ground truth, supporting reliable multi-view
light field processing.
  Project page: https://lifmcr.github.io/

</details>


### [90] [Cyclic Self-Supervised Diffusion for Ultra Low-field to High-field MRI Synthesis](https://arxiv.org/abs/2510.13735)
*Zhenxuan Zhang,Peiyuan Jing,Zi Wang,Ula Briski,Coraline Beitone,Yue Yang,Yinzhe Wu,Fanwen Wang,Liutao Yang,Jiahao Huang,Zhifan Gao,Zhaolin Chen,Kh Tohidul Islam,Guang Yang,Peter J. Lally*

Main category: cs.CV

TL;DR: 论文提出了一种循环自监督扩散框架（CSS-Diff），用于从低场 MRI 合成高场 MRI 图像，解决了临床保真度差距问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 低场 MRI 虽然更便宜、更安全，但分辨率低且信噪比差。合成高场 MRI 图像可以减少对昂贵采集的依赖并扩展数据可用性，但现有方法存在临床保真度差距。

Method: 提出了一个循环自监督扩散（CSS-Diff）框架，通过循环一致性约束和两个新过程（切片间差距感知网络和局部结构校正网络）来增强生成过程。

Result: 在跨场合成任务中，CSS-Diff 实现了最先进的性能（如 PSNR 31.80 ± 2.70 dB，SSIM 0.943 ± 0.102，LPIPS 0.0864 ± 0.0689），并显著保留了细粒度解剖结构。

Conclusion: CSS-Diff 框架能够合成既在定量上可靠又在解剖学上一致的图像，解决了临床保真度差距的问题。

Abstract: Synthesizing high-quality images from low-field MRI holds significant
potential. Low-field MRI is cheaper, more accessible, and safer, but suffers
from low resolution and poor signal-to-noise ratio. This synthesis process can
reduce reliance on costly acquisitions and expand data availability. However,
synthesizing high-field MRI still suffers from a clinical fidelity gap. There
is a need to preserve anatomical fidelity, enhance fine-grained structural
details, and bridge domain gaps in image contrast. To address these issues, we
propose a \emph{cyclic self-supervised diffusion (CSS-Diff)} framework for
high-field MRI synthesis from real low-field MRI data. Our core idea is to
reformulate diffusion-based synthesis under a cycle-consistent constraint. It
enforces anatomical preservation throughout the generative process rather than
just relying on paired pixel-level supervision. The CSS-Diff framework further
incorporates two novel processes. The slice-wise gap perception network aligns
inter-slice inconsistencies via contrastive learning. The local structure
correction network enhances local feature restoration through
self-reconstruction of masked and perturbed patches. Extensive experiments on
cross-field synthesis tasks demonstrate the effectiveness of our method,
achieving state-of-the-art performance (e.g., 31.80 $\pm$ 2.70 dB in PSNR,
0.943 $\pm$ 0.102 in SSIM, and 0.0864 $\pm$ 0.0689 in LPIPS). Beyond pixel-wise
fidelity, our method also preserves fine-grained anatomical structures compared
with the original low-field MRI (e.g., left cerebral white matter error drops
from 12.1$\%$ to 2.1$\%$, cortex from 4.2$\%$ to 3.7$\%$). To conclude, our
CSS-Diff can synthesize images that are both quantitatively reliable and
anatomically consistent.

</details>


### [91] [UniCalli: A Unified Diffusion Framework for Column-Level Generation and Recognition of Chinese Calligraphy](https://arxiv.org/abs/2510.13745)
*Tianshuo Xu,Kai Wang,Zhifei Chen,Leyi Wu,Tianshui Wen,Fei Chao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: UniCalli是一个统一的扩散框架，通过联合训练识别和生成任务，解决了中文书法计算复制中页面级美学与书法正确性的平衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的中文书法计算复制方法在页面级美学（如连笔和间距）和书法正确性之间存在权衡，难以兼顾。

Method: UniCalli采用非对称噪声和栅格化框图提供空间先验，结合合成、标记和未标记数据进行训练。

Result: UniCalli在生成质量和识别能力上均达到最先进水平，尤其在连笔连续性和布局保真度方面表现突出。

Conclusion: UniCalli框架成功扩展到其他古代文字，如甲骨文和埃及象形文字，展示了其通用性和适应性。

Abstract: Computational replication of Chinese calligraphy remains challenging.
Existing methods falter, either creating high-quality isolated characters while
ignoring page-level aesthetics like ligatures and spacing, or attempting page
synthesis at the expense of calligraphic correctness. We introduce
\textbf{UniCalli}, a unified diffusion framework for column-level recognition
and generation. Training both tasks jointly is deliberate: recognition
constrains the generator to preserve character structure, while generation
provides style and layout priors. This synergy fosters concept-level
abstractions that improve both tasks, especially in limited-data regimes. We
curated a dataset of over 8,000 digitized pieces, with ~4,000 densely
annotated. UniCalli employs asymmetric noising and a rasterized box map for
spatial priors, trained on a mix of synthetic, labeled, and unlabeled data. The
model achieves state-of-the-art generative quality with superior ligature
continuity and layout fidelity, alongside stronger recognition. The framework
successfully extends to other ancient scripts, including Oracle bone
inscriptions and Egyptian hieroglyphs. Code and data can be viewed in
\href{https://github.com/EnVision-Research/UniCalli}{this URL}.

</details>


### [92] [InteractiveOmni: A Unified Omni-modal Model for Audio-Visual Multi-turn Dialogue](https://arxiv.org/abs/2510.13747)
*Wenwen Tong,Hewei Guo,Dongchuan Ran,Jiangnan Chen,Jiefan Lu,Kaibin Wang,Keqiang Li,Xiaoxu Zhu,Jiakui Li,Kehan Li,Xueheng Li,Lumin Li,Chenxu Guo,Jiasheng Zhou,Jiandong Chen,Xianye Wu,Jiahao Wang,Silei Wu,Lei Chen,Hanming Deng,Yuxuan Song,Dinghao Zhou,Guiping Zhong,Ken Zheng,Shiyin Kang,Lewei Lu*

Main category: cs.CV

TL;DR: InteractiveOmni 是一个 4B 到 8B 参数的开源多模态大语言模型，整合了视觉、音频、语言和语音模块，通过多阶段训练和精心设计的数据集，实现了领先的多模态理解和语音生成能力，尤其在长期记忆和多轮交互中表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一且开源的多模态大语言模型，以提供全面的多模态理解和语音生成能力，并在轻量级模型中领先。

Method: 通过整合视觉编码器、音频编码器、大语言模型和语音解码器，设计多阶段训练策略（包括预训练和后训练），并精心策划多轮训练数据集以增强模型处理复杂多轮交互的能力。

Result: 实验表明，InteractiveOmni 显著优于领先的开源模型，尤其在长期记忆能力方面表现突出，其 4B 版本在通用基准测试中可与更大的模型（如 Qwen2.5-Omni-7B）相媲美，且仅使用 50% 的模型大小即可保留 97% 的 8B 版本性能。

Conclusion: InteractiveOmni 作为一个开源的轻量级多模态大语言模型，在图像、音频、视频理解和语音生成任务中实现了与同类模型相比的最先进性能，为下一代智能交互系统提供了可访问的开源基础。

Abstract: We introduce InteractiveOmni, a unified and open-source omni-modal large
language model for audio-visual multi-turn interaction, ranging from 4B to 8B
parameters, designed to lead the field of lightweight models by offering
comprehensive omni-modal understanding and speech generation capabilities. To
achieve this, we integrate the vision encoder, audio encoder, large language
model, and speech decoder into a unified model for understanding and generation
tasks. We design a multi-stage training strategy to ensure robust cross-modal
capabilities, including pre-training for omni-modal understanding, followed by
post-training with speech conversation and audio-visual interaction. To enable
human-like long-term conversational ability, we meticulously curate a
multi-turn training dataset that enhances the model's ability to handle complex
and multi-turn interactions. To effectively evaluate the multi-turn memory and
speech interaction capabilities, we construct the multi-modal multi-turn memory
benchmark and the multi-turn speech interaction benchmark. Experiments
demonstrate that InteractiveOmni significantly outperforms leading open-source
models and provides a more intelligent multi-turn audio-visual experience,
particularly in its long-term memory capabilities. Notably, InteractiveOmni-4B
is comparable to the much larger model like Qwen2.5-Omni-7B on general
benchmarks, and it can retain 97% of the performance of the InteractiveOmni-8B
while utilizing only 50% of the model size. Achieving state-of-the-art results
against similarly sized models across image, audio, video understanding, and
speech generation tasks, InteractiveOmni is an accessible, open-source
foundation for next-generation intelligent interactive systems.

</details>


### [93] [Uni-MMMU: A Massive Multi-discipline Multimodal Unified Benchmark](https://arxiv.org/abs/2510.13759)
*Kai Zou,Ziqi Huang,Yuhao Dong,Shulin Tian,Dian Zheng,Hongbo Liu,Jingwen He,Bin Liu,Yu Qiao,Ziwei Liu*

Main category: cs.CV

TL;DR: Uni-MMMU 是一个综合性基准测试，旨在评估多模态模型中视觉理解和生成的双向协同作用，揭示了性能差异和跨模态依赖关系。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试很少真正检验视觉理解和生成的集成，现有评估要么孤立处理这两种能力，要么忽视了其内在耦合的任务。

Method: 通过 Uni-MMMU 基准测试，系统地评估了八种推理中心领域的双向协同作用，结合可验证的中间推理步骤、独特真实值和可重复的评分协议。

Result: 评估揭示了最先进的统一、仅生成和仅理解模型之间的显著性能差异和跨模态依赖关系。

Conclusion: Uni-MMMU 基准测试揭示了统一多模态模型中视觉理解和生成能力之间的显著性能差异和跨模态依赖关系，为推进统一模型提供了可靠基础。

Abstract: Unified multimodal models aim to jointly enable visual understanding and
generation, yet current benchmarks rarely examine their true integration.
Existing evaluations either treat the two abilities in isolation or overlook
tasks that inherently couple them. To address this gap, we present Uni-MMMU, a
comprehensive and discipline-aware benchmark that systematically unfolds the
bidirectional synergy between generation and understanding across eight
reasoning-centric domains, including science, coding, mathematics, and puzzles.
Each task is bidirectionally coupled, demanding models to (i) leverage
conceptual understanding to guide precise visual synthesis, or (ii) utilize
generation as a cognitive scaffold for analytical reasoning. Uni-MMMU
incorporates verifiable intermediate reasoning steps, unique ground truths, and
a reproducible scoring protocol for both textual and visual outputs. Through
extensive evaluation of state-of-the-art unified, generation-only, and
understanding-only models, we reveal substantial performance disparities and
cross-modal dependencies, offering new insights into when and how these
abilities reinforce one another, and establishing a reliable foundation for
advancing unified models.

</details>


### [94] [Adaptive Visual Conditioning for Semantic Consistency in Diffusion-Based Story Continuation](https://arxiv.org/abs/2510.13787)
*Seyed Mohammad Mousavi,Morteza Analoui*

Main category: cs.CV

TL;DR: AVC是一个基于扩散的故事延续框架，通过自适应视觉调节和CLIP模型，有效利用视觉上下文并避免误导信息，在连贯性和视觉质量上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 故事延续任务的关键挑战在于如何有效利用先前的视觉上下文，同时确保与当前文本输入的语义对齐。为了解决这一问题，作者提出了AVC框架。

Method: AVC采用CLIP模型检索先前帧中最语义对齐的图像，并在没有足够相关图像时，自适应地限制先前视觉对扩散过程的影响。此外，通过使用大型语言模型重新标注噪声数据集，提升了数据质量和文本监督的强度。

Result: 定量结果和人工评估表明，AVC在连贯性、语义一致性和视觉保真度上优于现有基线方法，尤其在先前视觉与当前输入冲突的挑战性案例中表现突出。

Conclusion: AVC框架在故事延续任务中表现出色，能够有效利用先前的视觉上下文，同时避免误导信息的注入，从而在连贯性、语义一致性和视觉保真度上优于现有基线方法。

Abstract: Story continuation focuses on generating the next image in a narrative
sequence so that it remains coherent with both the ongoing text description and
the previously observed images. A central challenge in this setting lies in
utilizing prior visual context effectively, while ensuring semantic alignment
with the current textual input. In this work, we introduce AVC (Adaptive Visual
Conditioning), a framework for diffusion-based story continuation. AVC employs
the CLIP model to retrieve the most semantically aligned image from previous
frames. Crucially, when no sufficiently relevant image is found, AVC adaptively
restricts the influence of prior visuals to only the early stages of the
diffusion process. This enables the model to exploit visual context when
beneficial, while avoiding the injection of misleading or irrelevant
information. Furthermore, we improve data quality by re-captioning a noisy
dataset using large language models, thereby strengthening textual supervision
and semantic alignment. Quantitative results and human evaluations demonstrate
that AVC achieves superior coherence, semantic consistency, and visual fidelity
compared to strong baselines, particularly in challenging cases where prior
visuals conflict with the current input.

</details>


### [95] [NoisePrints: Distortion-Free Watermarks for Authorship in Private Diffusion Models](https://arxiv.org/abs/2510.13793)
*Nir Goren,Oren Katzir,Abhinav Nakarmi,Eyal Ronen,Mahmood Sharif,Or Patashnik*

Main category: cs.CV

TL;DR: NoisePrints是一种轻量级水印方案，利用扩散过程的随机种子作为版权证明，无需模型权重，验证高效且隐私保护强。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型在视觉内容生成中的广泛应用，保护版权和证明作者身份变得尤为重要，尤其是在模型所有者保持模型私有且不愿处理版权问题时。

Method: 提出了一种利用扩散过程初始种子的水印方案，通过哈希函数确保种子与生成内容的关联性，并采用零知识证明保护种子隐私。

Result: 实验验证了NoisePrints在多种先进扩散模型上的有效性，展示了仅需种子和输出即可高效验证的可行性。

Conclusion: NoisePrints提供了一种轻量级的水印方案，通过利用扩散过程的随机种子作为作者证明，无需修改生成过程或访问模型权重，有效解决了版权保护问题。

Abstract: With the rapid adoption of diffusion models for visual content generation,
proving authorship and protecting copyright have become critical. This
challenge is particularly important when model owners keep their models private
and may be unwilling or unable to handle authorship issues, making third-party
verification essential. A natural solution is to embed watermarks for later
verification. However, existing methods require access to model weights and
rely on computationally heavy procedures, rendering them impractical and
non-scalable. To address these challenges, we propose , a lightweight
watermarking scheme that utilizes the random seed used to initialize the
diffusion process as a proof of authorship without modifying the generation
process. Our key observation is that the initial noise derived from a seed is
highly correlated with the generated visual content. By incorporating a hash
function into the noise sampling process, we further ensure that recovering a
valid seed from the content is infeasible. We also show that sampling an
alternative seed that passes verification is infeasible, and demonstrate the
robustness of our method under various manipulations. Finally, we show how to
use cryptographic zero-knowledge proofs to prove ownership without revealing
the seed. By keeping the seed secret, we increase the difficulty of watermark
removal. In our experiments, we validate NoisePrints on multiple
state-of-the-art diffusion models for images and videos, demonstrating
efficient verification using only the seed and output, without requiring access
to model weights.

</details>


### [96] [Reasoning in Space via Grounding in the World](https://arxiv.org/abs/2510.13800)
*Yiming Chen,Zekun Qi,Wenyao Zhang,Xin Jin,Li Zhang,Peidong Liu*

Main category: cs.CV

TL;DR: GS-Reasoner通过双路径池化机制和统一3D表示，实现了无需外部模块的自回归定位，显著提升空间推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D LLMs缺乏统一的3D表示，导致定位性能差或过度依赖外部模块，阻碍了定位与空间推理的无缝集成。

Method: 提出了一种简单而有效的双路径池化机制，紧密对齐几何特征与语义和位置线索，构建了一个统一的基于图像块的3D表示。

Result: GS-Reasoner在3D视觉定位任务中表现出色，并显著提升了空间推理能力。

Conclusion: GS-Reasoner通过统一的三维表示和自回归定位，显著提升了空间推理能力，并在3D视觉定位任务中取得了最先进的性能。

Abstract: In this paper, we claim that 3D visual grounding is the cornerstone of
spatial reasoning and introduce the Grounded-Spatial Reasoner (GS-Reasoner) to
explore the effective spatial representations that bridge the gap between them.
Existing 3D LLMs suffer from the absence of a unified 3D representation capable
of jointly capturing semantic and geometric information. This deficiency is
manifested either in poor performance on grounding or in an excessive reliance
on external modules, ultimately hindering the seamless integration of grounding
and spatial reasoning. To address this, we propose a simple yet effective
dual-path pooling mechanism that tightly aligns geometric features with both
semantic and positional cues, constructing a unified image patch-based 3D
representation that encapsulates all essential information without increasing
the number of input tokens. Leveraging this holistic representation,
GS-Reasoner is the first 3D LLM that achieves autoregressive grounding entirely
without external modules while delivering performance comparable to
state-of-the-art models, establishing a unified and self-contained framework
for 3D spatial reasoning. To further bridge grounding and spatial reasoning, we
introduce the Grounded Chain-of-Thought (GCoT) dataset. This dataset is
meticulously curated to include both 3D bounding box annotations for objects
referenced in reasoning questions and step-by-step reasoning paths that
integrate grounding as a core component of the problem-solving process.
Extensive experiments demonstrate that GS-Reasoner achieves impressive results
on 3D visual grounding, which in turn significantly enhances its spatial
reasoning capabilities, leading to state-of-the-art performance.

</details>


### [97] [Trace Anything: Representing Any Video in 4D via Trajectory Fields](https://arxiv.org/abs/2510.13802)
*Xinhang Liu,Yuxi Xiao,Donny Y. Chen,Jiashi Feng,Yu-Wing Tai,Chi-Keung Tang,Bingyi Kang*

Main category: cs.CV

TL;DR: 论文提出用Trajectory Field表示视频中的像素轨迹，开发了Trace Anything模型，通过单次前向传递预测轨迹场，在性能和效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 视频中的像素随时间形成连续的3D轨迹，这是动态的基本元素，因此需要有效的时空表示来建模和理解视频动态。

Method: 提出Trajectory Field表示方法，使用B样条参数化轨迹，并通过神经网络预测控制点。

Result: Trace Anything在新基准测试中达到最先进性能，并在效率和新能力方面表现出色。

Conclusion: Trace Anything通过单次前向传递预测整个轨迹场，在轨迹场估计和点跟踪基准上表现出色，同时提供了显著的效率提升和新兴能力。

Abstract: Effective spatio-temporal representation is fundamental to modeling,
understanding, and predicting dynamics in videos. The atomic unit of a video,
the pixel, traces a continuous 3D trajectory over time, serving as the
primitive element of dynamics. Based on this principle, we propose representing
any video as a Trajectory Field: a dense mapping that assigns a continuous 3D
trajectory function of time to each pixel in every frame. With this
representation, we introduce Trace Anything, a neural network that predicts the
entire trajectory field in a single feed-forward pass. Specifically, for each
pixel in each frame, our model predicts a set of control points that
parameterizes a trajectory (i.e., a B-spline), yielding its 3D position at
arbitrary query time instants. We trained the Trace Anything model on
large-scale 4D data, including data from our new platform, and our experiments
demonstrate that: (i) Trace Anything achieves state-of-the-art performance on
our new benchmark for trajectory field estimation and performs competitively on
established point-tracking benchmarks; (ii) it offers significant efficiency
gains thanks to its one-pass paradigm, without requiring iterative optimization
or auxiliary estimators; and (iii) it exhibits emergent abilities, including
goal-conditioned manipulation, motion forecasting, and spatio-temporal fusion.
Project page: https://trace-anything.github.io/.

</details>


### [98] [VisCoP: Visual Probing for Video Domain Adaptation of Vision Language Models](https://arxiv.org/abs/2510.13808)
*Dominick Reilly,Manish Kumar Govind,Le Xue,Srijan Das*

Main category: cs.CV

TL;DR: VisCoP通过可学习视觉探针增强VLM，实现了高效领域适应，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）在新领域中出现性能急剧下降的问题，现有领域适应方法往往导致有限的领域特定特征学习或灾难性遗忘。

Method: 提出了Vision Contextualized Probing (VisCoP)，通过在视觉编码器中添加一组紧凑的可学习视觉探针，实现高效的领域特定适应。

Result: VisCoP在三种具有挑战性的领域适应设置（跨视角、跨模态、跨任务）中均优于现有适应策略。

Conclusion: VisCoP通过引入可学习的视觉探针，实现了在目标领域的卓越性能，同时有效保留了源领域的知识。

Abstract: Large Vision-Language Models (VLMs) excel at general visual reasoning tasks
but exhibit sharp performance degradation when applied to novel domains with
substantial distribution shifts from pretraining data. Existing domain
adaptation approaches finetune different VLM components, but this often results
in limited domain-specific feature learning or catastrophic forgetting of prior
capabilities. To address these issues, we introduce Vision Contextualized
Probing (VisCoP), which augments the VLM's vision encoder with a compact set of
learnable visual probes. These probes enable efficient domain-specific
adaptation with minimal modification to pretrained parameters. We evaluate
VisCoP across three challenging domain adaptation settings-cross-view
(exocentric to egocentric), cross-modal (RGB to depth), and cross-task (human
understanding to robot control). Experiments show that VisCoP consistently
outperforms existing adaptation strategies, achieving superior performance on
target domains while effectively retaining source-domain knowledge.

</details>


### [99] [PhysMaster: Mastering Physical Representation for Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.13809)
*Sihui Ji,Xi Chen,Xin Tao,Pengfei Wan,Hengshuang Zhao*

Main category: cs.CV

TL;DR: PhysMaster通过物理表示学习增强视频生成模型的物理意识，结合强化学习和人类反馈优化物理表示，证明其在多种物理场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型虽能生成视觉效果逼真的视频，但往往不符合物理规律，限制了其生成物理合理视频的能力。

Method: 基于图像到视频任务，设计了PhysEncoder来从输入图像中编码物理信息，并采用强化学习结合人类反馈优化物理表示。

Result: PhysMaster在提高视频生成模型的物理意识方面提供了可行方案，并在简单代理任务和广泛物理场景中展示了其通用性。

Conclusion: PhysMaster提出了一种通过物理表示学习增强视频生成模型物理意识的方法，并在简单代理任务和广泛物理场景中证明了其有效性。

Abstract: Video generation models nowadays are capable of generating visually realistic
videos, but often fail to adhere to physical laws, limiting their ability to
generate physically plausible videos and serve as ''world models''. To address
this issue, we propose PhysMaster, which captures physical knowledge as a
representation for guiding video generation models to enhance their
physics-awareness. Specifically, PhysMaster is based on the image-to-video task
where the model is expected to predict physically plausible dynamics from the
input image. Since the input image provides physical priors like relative
positions and potential interactions of objects in the scenario, we devise
PhysEncoder to encode physical information from it as an extra condition to
inject physical knowledge into the video generation process. The lack of proper
supervision on the model's physical performance beyond mere appearance
motivates PhysEncoder to apply reinforcement learning with human feedback to
physical representation learning, which leverages feedback from generation
models to optimize physical representations with Direct Preference Optimization
(DPO) in an end-to-end manner. PhysMaster provides a feasible solution for
improving physics-awareness of PhysEncoder and thus of video generation,
proving its ability on a simple proxy task and generalizability to wide-ranging
physical scenarios. This implies that our PhysMaster, which unifies solutions
for various physical processes via representation learning in the reinforcement
learning paradigm, can act as a generic and plug-in solution for physics-aware
video generation and broader applications.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [100] [AutoCode: LLMs as Problem Setters for Competitive Programming](https://arxiv.org/abs/2510.12803)
*Shang Zhou,Zihan Zheng,Kaiyuan Liu,Zeyu Shen,Zerui Cheng,Zexing Chen,Hansen He,Jianzhu Yao,Huanzhi Mao,Qiuyang Mang,Tianfu Fu,Beichen Li,Dongruixuan Li,Wenhao Chai,Zhuang Liu,Aleksandra Korolova,Peter Henderson,Natasha Jaques,Pramod Viswanath,Saining Xie,Jingbo Shang*

Main category: cs.SE

TL;DR: AutoCode是一个通过多轮验证生成竞赛级编程题目和测试用例的系统，其测试套件与官方评判的一致性接近99%，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 编写高质量的竞赛编程题目具有挑战性，需要设定约束、输入分布和边缘案例，这成为测试大型语言模型能力的理想场景。

Method: AutoCode采用多轮验证机制生成题目和测试用例，并通过交叉验证生成参考和暴力解决方案来过滤不良问题。

Result: AutoCode生成的题目被顶级竞赛程序员评为竞赛质量，测试套件一致性达99%，优于现有方法的81%。

Conclusion: AutoCode能可靠生成高质量的竞赛编程题目，验证了其在自动化题目生成中的有效性。

Abstract: Writing competitive programming problems is exacting. Authors must: set
constraints, input distributions, and edge cases that rule out shortcuts;
target specific algorithms (e.g., max-flow, dynamic programming, data
structures); and calibrate complexity beyond the reach of most competitors. We
argue that this makes for an ideal test of general large language model
capabilities and study whether they can do this reliably. We introduce
AutoCode, which uses multiple rounds of validation to yield competition-grade
problem statements and test cases. On held-out problems, AutoCode test suites
approach 99% consistency with official judgments, a significant improvement
over current state-of-the-art methods like HardTests, which achieve less than
81%. Furthermore, starting with a random seed problem, AutoCode can create
novel variants with reference and brute-force solutions. By cross-verifying
these generated solutions against test cases, we can further filter out
malformed problems. Our system ensures high correctness, as verified by human
experts. AutoCode successfully produces novel problems judged by
Grandmaster-level (top 0.3%) competitive programmers to be of contest quality.

</details>


### [101] [SpareCodeSearch: Searching for Code Context When You Have No Spare GPU](https://arxiv.org/abs/2510.12948)
*Minh Nguyen*

Main category: cs.SE

TL;DR: 论文提出使用关键词搜索而非语义搜索来增强代码语言模型，减少计算资源需求，并在轻量级应用中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有检索增强生成框架依赖语义搜索，计算资源需求高，难以集成到轻量级应用（如IDE中的AI代码补全）。

Method: 采用关键词搜索替代语义搜索，从大型代码库中检索相关代码上下文。

Result: 在Code Context Competition基准测试中，Kotlin和Python轨道的chRF分数分别达到0.748和0.725。

Conclusion: 关键词搜索足以检索有用代码上下文，无需昂贵GPU资源，适合轻量级应用。

Abstract: Retrieval-Augmented Generation (RAG) frameworks aim to enhance Code Language
Models (CLMs) by including another module for retrieving relevant context to
construct the input prompt. However, these retrieval modules commonly use
semantic search, requiring substantial computational resources for training and
hosting these embedded models, making them infeasible to integrate into
lightweight applications such as in-IDE AI-based code completion. In this
solution paper, we prove that using keyword-search is sufficient to retrieve
relevant and useful code context inside large codebases, without the need for
extensive GPU resources. The usefulness of code contexts found by our solution
is demonstrated through their completion results on the Code Context
Competition's benchmark, reaching 0.748 and 0.725 chRF scores on Kotlin and
Python tracks, respectively.

</details>


### [102] [ADPerf: Investigating and Testing Performance in Autonomous Driving Systems](https://arxiv.org/abs/2510.13078)
*Tri Minh-Triet Pham,Diego Elias Costa,Weiyi Shang,Jinqiu Yang*

Main category: cs.SE

TL;DR: 该论文提出了ADPerf工具，用于测试自动驾驶系统中障碍物检测模块的延迟及其对其他模块的影响。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统的障碍物检测模块延迟及其对系统性能的影响尚未完全理解。

Method: 通过ADPerf工具生成真实的点云数据测试案例，测量和建模Apollo和Autoware系统中障碍物检测模块的性能。

Result: 评估表明，3D障碍物检测模块可能成为系统延迟的主要瓶颈，并会影响其他模块的可靠性。

Conclusion: 强调了性能测试的重要性，尤其是3D障碍物检测模块，以提高自动驾驶系统的整体可靠性。

Abstract: Obstacle detection is crucial to the operation of autonomous driving systems,
which rely on multiple sensors, such as cameras and LiDARs, combined with code
logic and deep learning models to detect obstacles for time-sensitive
decisions. Consequently, obstacle detection latency is critical to the safety
and effectiveness of autonomous driving systems. However, the latency of the
obstacle detection module and its resilience to various changes in the LiDAR
point cloud data are not yet fully understood. In this work, we present the
first comprehensive investigation on measuring and modeling the performance of
the obstacle detection modules in two industry-grade autonomous driving
systems, i.e., Apollo and Autoware. Learning from this investigation, we
introduce ADPerf, a tool that aims to generate realistic point cloud data test
cases that can expose increased detection latency. Increasing latency decreases
the availability of the detected obstacles and stresses the capabilities of
subsequent modules in autonomous driving systems, i.e., the modules may be
negatively impacted by the increased latency in obstacle detection.
  We applied ADPerf to stress-test the performance of widely used 3D obstacle
detection modules in autonomous driving systems, as well as the propagation of
such tests on trajectory prediction modules. Our evaluation highlights the need
to conduct performance testing of obstacle detection components, especially 3D
obstacle detection, as they can be a major bottleneck to increased latency of
the autonomous driving system. Such an adverse outcome will also further
propagate to other modules, reducing the overall reliability of autonomous
driving systems.

</details>


### [103] [TRUSTVIS: A Multi-Dimensional Trustworthiness Evaluation Framework for Large Language Models](https://arxiv.org/abs/2510.13106)
*Ruoyu Sun,Da Song,Jiayang Song,Yuheng Huang,Lei Ma*

Main category: cs.SE

TL;DR: TRUSTVIS是一个自动化评估LLM信任度的框架，通过直观的可视化界面和多种评估方法，帮助识别模型漏洞并支持改进。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在NLP应用中的广泛使用，其安全性和鲁棒性方面的信任问题日益凸显，亟需一种全面的评估框架。

Method: 采用AutoDAN等已知扰动方法，并结合多数投票机制，TRUSTVIS框架实现了对LLM信任度的自动化评估。

Result: 在Vicuna-7b、Llama2-7b和GPT-3.5等模型上的初步案例研究表明，TRUSTVIS能有效识别安全性和鲁棒性漏洞。

Conclusion: TRUSTVIS框架通过集成多种评估方法和直观的可视化界面，有效识别LLM的安全性和鲁棒性漏洞，为针对性模型改进提供了有力工具。

Abstract: As Large Language Models (LLMs) continue to revolutionize Natural Language
Processing (NLP) applications, critical concerns about their trustworthiness
persist, particularly in safety and robustness. To address these challenges, we
introduce TRUSTVIS, an automated evaluation framework that provides a
comprehensive assessment of LLM trustworthiness. A key feature of our framework
is its interactive user interface, designed to offer intuitive visualizations
of trustworthiness metrics. By integrating well-known perturbation methods like
AutoDAN and employing majority voting across various evaluation methods,
TRUSTVIS not only provides reliable results but also makes complex evaluation
processes accessible to users. Preliminary case studies on models like
Vicuna-7b, Llama2-7b, and GPT-3.5 demonstrate the effectiveness of our
framework in identifying safety and robustness vulnerabilities, while the
interactive interface allows users to explore results in detail, empowering
targeted model improvements. Video Link: https://youtu.be/k1TrBqNVg8g

</details>


### [104] [Isolating Compiler Bugs through Compilation Steps Analysis](https://arxiv.org/abs/2510.13128)
*Yujie Liu,Mingxuan Zhu,Shengyu Cheng,Dan Hao*

Main category: cs.SE

TL;DR: CompSCAN 通过分析编译步骤序列，显著提升了编译器错误隔离的准确性和效率，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 编译器错误会传播到依赖软件中，但现有技术缺乏对内部步骤的因果分析，限制了其有效性。

Method: CompSCAN 采用三阶段过程：(1) 提取导致原始失败的编译步骤序列，(2) 识别错误步骤并收集相关编译器代码元素，(3) 计算每个代码元素的可疑分数并输出可疑排名列表。

Result: 在 185 个真实世界的 LLVM 和 GCC 错误上，CompSCAN 在 Top-1/3/5/10 排名中分别成功隔离了 50、85、100 和 123 个错误，优于 ETEM 和 ODFL，且运行速度更快。

Conclusion: CompSCAN 是一种高效的编译器错误隔离技术，通过分析编译步骤序列，显著提升了错误定位的准确性和效率，优于现有技术。

Abstract: Compilers are essential to software systems, and their bugs can propagate to
dependent software. Ensuring compiler correctness is critical. However,
isolating compiler bugs remains challenging due to the internal complexity of
compiler execution. Existing techniques primarily mutate compilation inputs to
generate passing and failing tests, but often lack causal analysis of internal
steps, limiting their effectiveness.
  To address this limitation, we propose CompSCAN, a novel compiler bug
isolation technique that applies analysis over the sequence of compilation
steps. CompSCAN follows a three-stage process: (1) extracting the array of
compilation steps that leads to the original failure, (2) identifying
bug-causing steps and collecting corresponding compiler code elements, and (3)
calculating suspicious scores for each code element and outputting a suspicious
ranking list as the bug isolation result.
  We evaluate CompSCAN on 185 real-world LLVM and GCC bugs. Results show that
CompSCAN outperforms state-of-the-art techniques in both effectiveness and
efficiency. CompSCAN successfully isolates 50, 85, 100, and 123 bugs within the
Top-1/3/5/10 ranks, respectively. Compared with ETEM and ODFL, two
state-of-the-art compiler bug isolation techniques, CompSCAN achieves relative
improvements of 44.51% / 50.18% / 36.24% / 24.49% over ETEM, and 31.58% /
49.12% / 44.93% / 21.78% over ODFL on those metrics. Moreover, CompSCAN runs
faster on average per bug than both baselines.

</details>


### [105] [GRACE: Globally-Seeded Representation-Aware Cluster-Specific Evolution for Compiler Auto-Tuning](https://arxiv.org/abs/2510.13176)
*Haolin Pan,Chao Zha,Jinyuan Dong,Mingjie Xing,Yanjun Wu*

Main category: cs.SE

TL;DR: GRACE是一种高效的编译器自动调优框架，通过对比学习和进化搜索优化LLVM IR指令数，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 标准编译器启发式方法通用但效果不佳，迭代编译搜索成本高，机器学习方法泛化能力不足，因此需要一种高效且泛化能力强的编译器自动调优框架。

Method: GRACE利用pass协同效应和加权评分方法缩小搜索空间，采用对比学习和数据增强生成程序嵌入，再通过进化搜索得到核心集。

Result: GRACE在七个数据集上平均减少LLVM IR指令数10.09%（LLVM 10.0.0）和10.19%（LLVM 18.1.6），调优时间低于1秒/程序。

Conclusion: GRACE框架通过结合对比学习和进化搜索，显著提升了编译器自动调优的性能和效率，适用于不同版本的LLVM，展现了其先进性和实用性。

Abstract: Compiler pass selection and phase ordering present a significant challenge in
achieving optimal program performance, particularly for objectives like code
size reduction. Standard compiler heuristics offer general applicability but
often yield suboptimal, program-specific results due to their one-size-fits-all
nature. While iterative compilation can find tailored solutions, its
prohibitive search cost limits practical use. Machine learning approaches
promise faster inference but frequently struggle with generalization to unseen
programs. This paper introduces GRACE, a novel framework for compiler
auto-tuning, demonstrated for LLVM IR instruction count optimization. GRACE
effectively curtails the search space by leveraging pass synergies and a
weighted scoring method to generate initial high-quality candidate sequences
and a pass pool. It then employs contrastive learning, using pass
sequence-based data augmentation, to create program embeddings that facilitate
similarity-aware clustering. Evolutionary search within these clusters yields a
coreset of $k$ specialized pass sequences designed for robust generalization to
unseen programs. At test time, GRACE efficiently selects the best coreset
sequence and refines it using lightweight techniques. Experimental results on
seven diverse datasets show that GRACE reduces LLVM IR instruction count by an
average of 10.09% on LLVM 10.0.0 and 10.19% on LLVM 18.1.6 compared to opt -Oz,
while incurring an average tuning time of less than 1s per program,
demonstrating its state-of-the-art performance and practical effectiveness.

</details>


### [106] [Synergy-Guided Compiler Auto-Tuning of Nested LLVM Pass Pipelines](https://arxiv.org/abs/2510.13184)
*Haolin Pan,Jinyuan Dong,Mingjie Xing,Yanjun Wu*

Main category: cs.SE

TL;DR: 提出专为LLVM新Pass Manager设计的自动调优框架，通过形式化语法和结构感知遗传算法，生成有效且高性能的优化流水线。


<details>
  <summary>Details</summary>
Motivation: 传统编译器自动调优方法假设线性序列，与LLVM新Pass Manager的层次设计不兼容，无法保证生成语法有效的优化流水线。

Method: 引入形式化语法定义有效嵌套流水线空间，并开发基于森林的数据结构表示；采用结构感知的遗传算法直接操作这些森林，确保候选解的有效性。

Result: 在LLVM 18.1.6上评估，发现的新流水线平均比标准opt -Oz优化级别多减少13.62%的指令计数。

Conclusion: 该论文提出的新型自动调优框架能够有效导航复杂且受限的搜索空间，生成有效且高性能的编译器优化流水线。

Abstract: Compiler optimization relies on sequences of passes to improve program
performance. Selecting and ordering these passes automatically, known as
compiler auto-tuning, is challenging due to the large and complex search space.
Existing approaches generally assume a linear sequence of passes, a model
compatible with legacy compilers but fundamentally misaligned with the
hierarchical design of the LLVM New Pass Manager. This misalignment prevents
them from guaranteeing the generation of syntactically valid optimization
pipelines. In this work, we present a new auto-tuning framework built from the
ground up for the New Pass Manager. We introduce a formal grammar to define the
space of valid nested pipelines and a forest-based data structure for their
native representation. Upon this foundation, we develop a structure-aware
Genetic Algorithm whose operators manipulate these forests directly, ensuring
that all candidate solutions are valid by construction. The framework first
mines synergistic pass relationships to guide the search. An optional
refinement stage further explores subtle performance variations arising from
different valid structural arrangements.
  We evaluate our approach on seven benchmark datasets using LLVM 18.1.6. The
discovered pipelines achieve an average of 13.62% additional instruction count
reduction compared to the standard opt -Oz optimization level, showing that our
framework is capable of navigating this complex, constrained search space to
identify valid and effective pass pipelines.

</details>


### [107] [Towards Richer Challenge Problems for Scientific Computing Correctness](https://arxiv.org/abs/2510.13423)
*Matthew Sottile,Mohit Tekriwal,John Sarracino*

Main category: cs.SE

TL;DR: 本文旨在通过提出科学计算中的专门挑战问题和正确性维度，促进形式方法和编程语言验证技术的发展，以解决科学计算中的正确性问题。


<details>
  <summary>Details</summary>
Motivation: 科学计算中的正确性问题日益受到关注，但现有验证技术难以应对其复杂性，且科学计算与形式方法/编程语言社区之间缺乏共同理解。

Method: 提出了科学计算中相关正确性的多个维度，并讨论了设计挑战问题的准则和标准。

Result: 提出了一系列科学计算中正确性的相关维度和设计挑战问题的指南，以填补现有验证技术的不足。

Conclusion: 本文呼吁为科学计算中的正确性设计专门的挑战问题，以促进形式方法和编程语言验证技术的发展，并满足科学计算应用的需求。

Abstract: Correctness in scientific computing (SC) is gaining increasing attention in
the formal methods (FM) and programming languages (PL) community. Existing
PL/FM verification techniques struggle with the complexities of realistic SC
applications. Part of the problem is a lack of a common understanding between
the SC and PL/FM communities of machine-verifiable correctness challenges and
dimensions of correctness in SC applications.
  To address this gap, we call for specialized challenge problems to inform the
development and evaluation of FM/PL verification techniques for correctness in
SC. These specialized challenges are intended to augment existing problems
studied by FM/PL researchers for general programs to ensure the needs of SC
applications can be met. We propose several dimensions of correctness relevant
to scientific computing, and discuss some guidelines and criteria for designing
challenge problems to evaluate correctness in scientific computing.

</details>


### [108] [Verifying a Sparse Matrix Algorithm Using Symbolic Execution](https://arxiv.org/abs/2510.13424)
*Alexander C. Wilton*

Main category: cs.SE

TL;DR: 符号执行增强科学软件测试，应用于稀疏矩阵算法。


<details>
  <summary>Details</summary>
Motivation: 科学软件因其数学性和高度优化而复杂，传统测试难以检测细微错误。

Method: 提出使用符号执行技术编写测试，类似于传统单元测试但更强大。

Result: 成功将符号执行应用于稀疏矩阵算法测试。

Conclusion: 符号执行方法为科学软件测试提供了更强的验证保证，适用于复杂算法如稀疏矩阵。

Abstract: Scientific software is, by its very nature, complex. It is mathematical and
highly optimized which makes it prone to subtle bugs not as easily detected by
traditional testing. We outline how symbolic execution can be used to write
tests similar to traditional unit tests while providing stronger verification
guarantees and apply this methodology to a sparse matrix algorithm.

</details>


### [109] [OpenDerisk: An Industrial Framework for AI-Driven SRE, with Design, Implementation, and Case Studies](https://arxiv.org/abs/2510.13561)
*Peng Di,Faqiang Chen,Xiao Bai,Hongjun Yang,Qingfeng Li,Ganglin Wei,Jian Mou,Feng Shi,Keting Chen,Peng Tang,Zhitao Shen,Zheng Li,Wenhui Shi,Junwei Guo,Hang Yu*

Main category: cs.SE

TL;DR: OpenDerisk是一个专为SRE设计的开源多智能体框架，通过集成多种技术组件，显著提升了复杂问题的解决能力，并在实际应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代软件的复杂性不断增加，给SRE团队带来了不可持续的运营负担，需要能够模拟专家诊断推理的AI驱动自动化解决方案。现有解决方案要么缺乏深度因果推理，要么不适合SRE的专用调查工作流。

Method: OpenDerisk框架集成了诊断原生协作模型、可插拔推理引擎、知识引擎和标准化协议（MCP），使专家智能体能够共同解决复杂问题。

Result: OpenDerisk在准确性和效率上显著优于现有最先进基线，并在Ant Group的大规模生产部署中验证了其工业级可扩展性和实际影响。

Conclusion: OpenDerisk是一个专为SRE设计的开源多智能体框架，通过集成诊断原生协作模型、可插拔推理引擎、知识引擎和标准化协议（MCP），显著提升了复杂多领域问题的解决准确性和效率。

Abstract: The escalating complexity of modern software imposes an unsustainable
operational burden on Site Reliability Engineering (SRE) teams, demanding
AI-driven automation that can emulate expert diagnostic reasoning. Existing
solutions, from traditional AI methods to general-purpose multi-agent systems,
fall short: they either lack deep causal reasoning or are not tailored for the
specialized, investigative workflows unique to SRE. To address this gap, we
present OpenDerisk, a specialized, open-source multi-agent framework
architected for SRE. OpenDerisk integrates a diagnostic-native collaboration
model, a pluggable reasoning engine, a knowledge engine, and a standardized
protocol (MCP) to enable specialist agents to collectively solve complex,
multi-domain problems. Our comprehensive evaluation demonstrates that
OpenDerisk significantly outperforms state-of-the-art baselines in both
accuracy and efficiency. This effectiveness is validated by its large-scale
production deployment at Ant Group, where it serves over 3,000 daily users
across diverse scenarios, confirming its industrial-grade scalability and
practical impact. OpenDerisk is open source and available at
https://github.com/derisk-ai/OpenDerisk/

</details>


### [110] [Auto-repair without test cases: How LLMs fix compilation errors in large industrial embedded code](https://arxiv.org/abs/2510.13575)
*Han Fu,Sigrid Eldh,Kristian Wiklund,Andreas Ermedahl,Philipp Haller,Cyrille Artho*

Main category: cs.SE

TL;DR: LLM驱动的自动化修复方法有效解决工业CI中的编译错误，63%的错误被修复，83%修复合理，调试时间缩短至8分钟。


<details>
  <summary>Details</summary>
Motivation: 工业嵌入式系统中硬件和软件的协同开发常导致持续集成（CI）中的编译错误，现有修复技术依赖于测试用例，但非可编译代码缺乏测试用例。

Method: 研究采用了基于大型语言模型（LLM）的自动化修复方法，收集了超过40000个产品源代码提交，并评估了四种最先进的LLM在工业CI系统中的性能。

Result: LLM增强的CI系统能够修复基线数据集中63%的编译错误，其中83%的修复被认为是合理的，且调试时间大幅缩短至8分钟内。

Conclusion: 使用大型语言模型（LLM）增强的持续集成系统能够有效解决编译错误，其中63%的错误被成功修复，且83%的修复被认为是合理的。此外，LLM显著减少了调试时间，多数成功案例在8分钟内完成，而手动调试通常需要数小时。

Abstract: The co-development of hardware and software in industrial embedded systems
frequently leads to compilation errors during continuous integration (CI).
Automated repair of such failures is promising, but existing techniques rely on
test cases, which are not available for non-compilable code.
  We employ an automated repair approach for compilation errors driven by large
language models (LLMs). Our study encompasses the collection of more than 40000
commits from the product's source code. We assess the performance of an
industrial CI system enhanced by four state-of-the-art LLMs, comparing their
outcomes with manual corrections provided by human programmers. LLM-equipped CI
systems can resolve up to 63 % of the compilation errors in our baseline
dataset. Among the fixes associated with successful CI builds, 83 % are deemed
reasonable. Moreover, LLMs significantly reduce debugging time, with the
majority of successful cases completed within 8 minutes, compared to hours
typically required for manual debugging.

</details>


### [111] [Property Testing for Ocean Models. Can We Specify It? (Invited Talk)](https://arxiv.org/abs/2510.13692)
*Deepak A. Cherian*

Main category: cs.SE

TL;DR: 论文探讨了将GFD理论作为属性测试用于海洋模型验证的潜力，展示了物理学如何自然适合指定测试，但具体应用仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 解决海洋模型验证中的“预言问题”，即如何测试模型的正确性。

Method: 研究从属性测试文献中汲取灵感，特别是John Hughes教授的工作，探讨如何将这些思想应用于海洋的数值模型。提出了将简单的理想化GFD问题框架化为属性测试的方法。

Result: 研究表明，物理学自然适合指定属性测试，并通过示例展示了这一点。

Conclusion: 论文探讨了将地球物理流体动力学（GFD）理论作为属性测试应用于海洋模型验证的潜力，但具体哪些测试最可行和有用仍需进一步研究。

Abstract: I take inspiration from the property-testing literature, particularly the
work of Prof. John Hughes, and explore how such ideas might be applied to
numerical models of the ocean. Specifically, I ask whether geophysical fluid
dynamics (GFD) theory, expressed as property tests, might be used to address
the oracle problem of testing the correctness of ocean models. I propose that a
number of simple idealized GFD problems can be framed as property tests. These
examples clearly illustrate how physics naturally lends itself to specifying
property tests. Which of these proposed tests might be most feasible and
useful, remains to be seen.

</details>


### [112] [On Pretraining for Project-Level Code Completion](https://arxiv.org/abs/2510.13697)
*Maksim Sapronov,Evgeniy Glukhov*

Main category: cs.SE

TL;DR: 研究发现，仓库处理策略对OpenCoder模型的上下文学习影响有限，主要性能提升来自RoPE参数调整，且文件级训练在资源受限时仍高效。


<details>
  <summary>Details</summary>
Motivation: 探索仓库级预训练如何通过利用代码库范围内的上下文，提升大型语言模型生成准确且上下文感知的代码补全的能力。

Method: 通过扩展上下文窗口（从4,096到16,384 tokens）并训练额外的1B tokens的仓库级数据，研究不同仓库处理策略对OpenCoder模型（1.5B参数）的影响。

Result: 尽管数据集规模较小，模型在Long Code Arena基准测试中表现与竞争模型相当。不同仓库处理技术效果相似，主要提升来自适应新的RoPE缩放参数。

Conclusion: 研究表明，采用更简单的文件级训练方法在原始序列长度下仍非常有效，为资源受限的环境下开展仓库级代码补全研究提供了可能。

Abstract: Repository-level pretraining is commonly used to enable large language models
for code to leverage codebase-wide context. This enhances their ability to
generate accurate and context-aware code completions. In this work, we
investigate how different repository-processing strategies affect in-context
learning in OpenCoder, a 1.5B-parameter model. We extend its context window
from 4,096 to 16,384 tokens by training on additional 1B tokens of curated
repository-level data. Despite relying on a smaller dataset than competing
models (which often use hundreds of billions of tokens), our model achieves
comparable performance on the Long Code Arena benchmark. We find that various
repository-processing techniques yield similarly strong results, with the
primary gain coming from adapting to a new rotary positional embedding (RoPE)
scaling parameter. Finally, we show that a simpler file-level training approach
at the original sequence length remains highly effective, opening up
repository-level code completion research to settings with more constrained
data and compute resources.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [113] [Toward Hyper-Dimensional Connectivity in Beyond 6G: A Conceptual Framework](https://arxiv.org/abs/2510.12896)
*Ekram Hossain,Angelo Vera-Rivera*

Main category: cs.NI

TL;DR: 本文提出了一个B6G系统的愿景框架，整合了通信、认知、计算和网络物理能力，为未来移动宽带技术的研究和创新提供了方向。


<details>
  <summary>Details</summary>
Motivation: 随着5G的部署和6G的研究，需要为B6G系统制定愿景，以推动未来移动宽带技术的发展。

Method: 通过整合通信、认知、计算和网络物理能力作为核心连接维度，提出了B6G蜂窝系统的概念框架，并定义了潜在用例和系统级要求。

Result: 文章提出了B6G系统的概念框架、技术定义、潜在技术推动者以及前瞻性研究议程。

Conclusion: 本文提出了一个超越6G（B6G）系统的愿景框架，旨在实现超沉浸式互联网技术的无线接入，为未来移动宽带技术的研究和创新提供了方向。

Abstract: Cellular wireless networks enable mobile broadband connectivity for
Internet-based applications through their radio access and core network
infrastructure. While Fifth-Generation (5G) cellular systems are currently
being deployed, ongoing research on cellular technologies primarily focuses on
Sixth-Generation (6G) networks to set the stage for developing standards for
these systems. Therefore, the time has come to articulate the visions for
beyond 6G (B6G) systems. In this article, we present a visionary framework
toward hyper-dimensional connectivity in B6G that enables wireless access to
hyper-immersive Internet technologies. Our contributions include a conceptual
framework for B6G cellular systems with jointly integrated communication,
cognition, computing, and cyber-physical capabilities as core connectivity
dimensions, a set of technical definitions outlining potential use cases and
system-level requirements, a mapping of prospective technology enablers, and a
forward-looking research agenda for B6G systems. The conceptual discussions in
this article would be helpful for identifying innovation drivers, shaping
long-term technical goals, and defining research agendas for the future of
mobile broadband technologies.

</details>


### [114] [Towards xApp Conflict Evaluation with Explainable Machine Learning and Causal Inference in O-RAN](https://arxiv.org/abs/2510.13031)
*Pragya Sharma,Shihua Sun,Shachi Deshpande,Angelos Stavrou,Haining Wang*

Main category: cs.NI

TL;DR: 该论文提出了一种结合可解释机器学习和因果推理的框架，用于管理O-RAN中xApp的冲突，帮助运营商识别和量化冲突影响。


<details>
  <summary>Details</summary>
Motivation: O-RAN架构中多个xApp的并发操作可能导致冲突的控制行为，从而引发网络性能下降，因此需要一种方法来管理和解决这些冲突。

Method: 使用SHAP等模型可解释性工具识别共同影响同一KPI的RCP，并将这些交互表示为因果有向无环图（DAG），然后通过ATE和CATE等指标估计每个RCP对相关KPI的因果影响。

Result: 该框架能够为网络运营商提供识别冲突和量化其影响的指导性见解，从而实现更明智和有效的冲突解决策略。

Conclusion: 该论文提出了一个结合可解释机器学习和因果推理的框架，用于管理O-RAN架构中xApp的冲突，帮助网络运营商更有效地识别和解决冲突。

Abstract: The Open Radio Access Network (O-RAN) architecture enables a flexible,
vendor-neutral deployment of 5G networks by disaggregating base station
components and supporting third-party xApps for near real-time RAN control.
However, the concurrent operation of multiple xApps can lead to conflicting
control actions, which may cause network performance degradation. In this work,
we propose a framework for xApp conflict management that combines explainable
machine learning and causal inference to evaluate the causal relationships
between RAN Control Parameters (RCPs) and Key Performance Indicators (KPIs). We
use model explainability tools such as SHAP to identify RCPs that jointly
affect the same KPI, signaling potential conflicts, and represent these
interactions as a causal Directed Acyclic Graph (DAG). We then estimate the
causal impact of each of these RCPs on their associated KPIs using metrics such
as Average Treatment Effect (ATE) and Conditional Average Treatment Effect
(CATE). This approach offers network operators guided insights into identifying
conflicts and quantifying their impacts, enabling more informed and effective
conflict resolution strategies across diverse xApp deployments.

</details>


### [115] [Automated Network Protocol Testing with LLM Agents](https://arxiv.org/abs/2510.13248)
*Yunze Wei,Kaiwen Wei,Shibo Du,Jianyu Wang,Zhangzhong Liu,Yawen Wang,Zhanyou Li,Congcong Miao,Xiaohui Xie,Yong Cui*

Main category: cs.NI

TL;DR: NeTestLLM 是一个基于LLM的自动化网络协议测试系统，显著提高了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统网络协议测试方法劳动密集且易出错，现有模型方法仍需大量人工建模和专家干预，成本高且适应性有限。

Method: NeTestLLM 利用多代理大型语言模型（LLMs），采用分层协议理解、迭代测试用例生成、特定任务工作流和运行时反馈分析。

Result: NeTestLLM 生成了4,632个测试用例，覆盖了41个历史FRRouting bug，测试效率比手动方法提高了8.65倍。

Conclusion: NeTestLLM 提供了首个实用的基于LLM的自动化端到端测试解决方案，显著提高了网络协议测试的效率和覆盖率。

Abstract: Network protocol testing is fundamental for modern network infrastructure.
However, traditional network protocol testing methods are labor-intensive and
error-prone, requiring manual interpretation of specifications, test case
design, and translation into executable artifacts, typically demanding one
person-day of effort per test case. Existing model-based approaches provide
partial automation but still involve substantial manual modeling and expert
intervention, leading to high costs and limited adaptability to diverse and
evolving protocols. In this paper, we propose a first-of-its-kind system called
NeTestLLM that takes advantage of multi-agent Large Language Models (LLMs) for
end-to-end automated network protocol testing. NeTestLLM employs hierarchical
protocol understanding to capture complex specifications, iterative test case
generation to improve coverage, a task-specific workflow for executable
artifact generation, and runtime feedback analysis for debugging and
refinement. NeTestLLM has been deployed in a production environment for several
months, receiving positive feedback from domain experts. In experiments,
NeTestLLM generated 4,632 test cases for OSPF, RIP, and BGP, covering 41
historical FRRouting bugs compared to 11 by current national standards. The
process of generating executable artifacts also improves testing efficiency by
a factor of 8.65x compared to manual methods. NeTestLLM provides the first
practical LLM-powered solution for automated end-to-end testing of
heterogeneous network protocols.

</details>


### [116] [NetMCP: Network-Aware Model Context Protocol Platform for LLM Capability Extension](https://arxiv.org/abs/2510.13467)
*Enhan Li,Hongyang Du,Kaibin Huang*

Main category: cs.NI

TL;DR: NetMCP平台和SONAR算法通过结合语义和网络状态优化，显著提升了LLM系统的稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决当前MCP实现仅依赖语义匹配的脆弱性，特别是在延迟波动或服务器故障情况下的表现不佳。

Method: 构建了NetMCP平台，提供五种代表性网络状态，并提出了SONAR算法，联合优化语义相似性和网络QoS指标。

Result: SONAR在任务成功率、完成时间和失败次数上均优于仅依赖语义或基于LLM的基线方法。

Conclusion: SONAR算法通过结合语义相似性和网络QoS指标，显著提高了任务成功率并减少了完成时间和失败次数，证明了网络感知设计在生产规模LLM系统中的价值。

Abstract: Large Language Models (LLMs) remain static in functionality after training,
and extending their capabilities requires integration with external data,
computation, and services. The Model Context Protocol (MCP) has emerged as a
standard interface for such extensions, but current implementations rely solely
on semantic matching between users' requests and server function descriptions,
which makes current deployments and simulation testbeds fragile under latency
fluctuations or server failures. We address this gap by enhancing MCP tool
routing algorithms with real-time awareness of network and server status. To
provide a controlled test environment for development and evaluation, we
construct a heterogeneous experimental platform, namely Network-aware MCP
(NetMCP), which offers five representative network states and build a benchmark
for latency sequence generation and MCP server datasets. On top of NetMCP
platform, we analyze latency sequences and propose a Semantic-Oriented and
Network-Aware Routing (SONAR) algorithm, which jointly optimizes semantic
similarity and network Quality of Service (QoS) metrics for adaptive tool
routing. Results show that SONAR consistently improves task success rate and
reduces completion time and failure number compared with semantic-only,
LLM-based baselines, demonstrating the value of network-aware design for
production-scale LLM systems. The code for NetMCP is available at
https://github.com/NICE-HKU/NetMCP.

</details>


### [117] [Fair Ordering](https://arxiv.org/abs/2510.13664)
*Muhammad Haseeb,Jinkun Geng,Radhika Mittal,Aurojit Panda,Srinivas Narayana,Anirudh Sivaraman*

Main category: cs.NI

TL;DR: Tommy系统通过概率模型处理时间戳噪声，提出‘likely-happened-before’关系，解决公平排序问题，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 解决由于时钟同步限制导致的公平排序问题，提出了一种接受时钟变化而非消除误差的方法。

Method: 利用统计模型学习每个时钟的偏移分布，比较两个噪声时间戳的概率，计算一个事件在挂钟时间上先于另一个事件的概率。

Result: 提出了‘likely-happened-before’关系（$\xrightarrow{p}$），为并发事件的排序提供了新的基础。

Conclusion: Tommy系统通过概率模型处理时间戳的噪声，提出了一种新的‘likely-happened-before’关系，为公平排序提供了理论基础，并指出了未来研究方向。

Abstract: A growing class of applications demands \emph{fair ordering/sequencing} of
events which ensures that events generated earlier by one client are processed
before later events from other clients. However, achieving such sequencing is
fundamentally challenging due to the inherent limitations of clock
synchronization. We advocate for an approach that embraces, rather than
eliminates, clock variability. Instead of attempting to remove error from a
timestamp, Tommy, our proposed system, leverages a statistical model to compare
two noisy timestamps probabilistically by learning per-clock offset
distributions. Our preliminary statistical model computes the probability that
one event precedes another w.r.t. the wall-clock time without access to the
wall-clock. This serves as a foundation for a new relation:
\emph{likely-happened-before} denoted by $\xrightarrow{p}$ where $p$ represents
the probability of an event to have happened before another. The
$\xrightarrow{p}$ relation provides a basis for ordering multiple events which
are otherwise considered \emph{concurrent} by the typical
\emph{happened-before} ($\rightarrow$) relation. We highlight various related
challenges including intransitivity of $\xrightarrow{p}$ relation as opposed to
the transitive $\rightarrow$ relation. We also outline several research
directions: online fair sequencing, stochastically fair total ordering,
host-level support for fairness and more.

</details>


### [118] [Optimize Replica Server Placement in a Satellite Network](https://arxiv.org/abs/2510.13689)
*Zhiyuan He,Yi Xu,Cheng Luo,Lili Qiu,Yuqing Yang*

Main category: cs.NI

TL;DR: 该论文提出了一种优化卫星网络中内容副本放置的方法，以降低传输成本并提升性能，适用于多种卫星网络类型。


<details>
  <summary>Details</summary>
Motivation: 卫星通信为偏远地区提供互联网连接，但传输成本高昂。通过优化内容副本放置，可以降低这一成本并提升性能。

Method: 通过在卫星网络中放置内容副本服务器，并优化副本放置策略，考虑卫星移动轨迹，以优化客户端性能和内容传输成本。

Result: 通过模拟流量轨迹和原型系统的验证，证明了该方法的有效性。

Conclusion: 该论文提出的方法通过优化卫星网络中的内容副本放置策略，有效降低了传输成本并提升了性能，适用于多种卫星网络类型。

Abstract: Satellite communication offers Internet connectivity to remote locations,
such as villages, deserts, mountains, and at sea. However, transmitting content
over satellite networks is significantly more expensive than traditional
Internet. To address this issue, we propose placing content replica servers
within satellite networks and optimizing replica placement for important
performance metrics, such as latency, transmission, and storage cost. Our
approach can support different types of satellite networks, including Low Earth
Orbit (LEO), Medium Earth Orbit (MEO), Geostationary Orbit (GEO), and their
combinations. An important challenge for supporting content replicas in such
networks is that LEO and MEO satellites are constantly moving. We address this
challenge by explicitly considering their moving trajectories and strategically
optimizing not only client performance, but also the cost of transferring
content from one satellite to another as needed. We demonstrate the
effectiveness of our approach using both simulated traffic traces and a
prototype system.

</details>


### [119] [Investigating Web Content Delivery Performance over Starlink](https://arxiv.org/abs/2510.13710)
*Rohan Bose,Jinwei Zhao,Tanya Shreedhar,Jianping Pan,Nitinder Mohan*

Main category: cs.NI

TL;DR: 该研究通过大规模测量揭示了Starlink卫星网络在不同基础设施密度下的内容交付性能差异，并指出基础设施接近程度是关键因素，而非卫星覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解LEO卫星ISP（如Starlink）与内容交付的交互，尤其是其性能表现。

Method: 通过结合225K Cloudflare AIM测试、M-Lab数据以及从99个RIPE Atlas和受控Starlink探针的主动探测，收集了6.1M条追踪路径和10.8M条DNS查询，量化了卫星架构如何干扰地面CDN假设。

Result: 研究发现，基础设施密度决定了三种不同的性能模式：本地内容丰富的PoP区域实现接近地面的延迟；基础设施稀疏的区域因远程PoP导致CDN定位错误，延迟超过200毫秒；基础设施密集区域对PoP变化不敏感。此外，2025年Starlink基础设施扩展实验显示，将PoP靠近用户位置可将页面获取时间中位数减少60%。

Conclusion: 该论文的结论是，基础设施的接近程度而非卫星覆盖范围影响网络性能，需要对卫星ISP的CDN映射和DNS解析进行根本性改变。

Abstract: Low Earth Orbit (LEO) satellite ISPs promise universal Internet connectivity,
yet their interaction with content delivery remains poorly understood. We
present the first comprehensive measurement study decomposing Starlink's web
content delivery performance decomposed across Point of Presence (PoP), DNS,
and CDN layers. Through two years of measurements combining 225K Cloudflare AIM
tests, M-Lab data, and active probing from 99 RIPE Atlas and controlled
Starlink probes, we collect 6.1M traceroutes and 10.8M DNS queries to quantify
how satellite architecture disrupts terrestrial CDN assumptions. We identify
three distinct performance regimes based on infrastructure density. Regions
with local content-rich PoPs achieve near-terrestrial latencies with the
satellite segment dominating 80-90% of RTT. Infrastructure-sparse regions
suffer cascading penalties: remote PoPs force distant resolver selection, which
triggers CDN mis-localization, pushing latencies beyond 200 ms.
Dense-infrastructure regions show minimal sensitivity to PoP changes.
Leveraging Starlink's infrastructure expansion in early 2025 as a natural
experiment, we demonstrate that relocating PoPs closer to user location reduces
median page-fetch times by 60%. Our findings reveal that infrastructure
proximity, not satellite coverage, influences web performance, requiring
fundamental changes to CDN mapping and DNS resolution for satellite ISPs.

</details>


### [120] [Scalable Pilot Assignment for Distributed Massive MIMO using Channel Estimation Error](https://arxiv.org/abs/2510.13732)
*Mohd Saif Ali Khan,Karthik RM,Samar Agnihotri*

Main category: cs.NI

TL;DR: 论文提出了两种动态导频分配策略（集中式和分布式），有效减少导频污染并提升网络吞吐量。


<details>
  <summary>Details</summary>
Motivation: 导频污染是分布式大规模MIMO系统实现其潜力的主要瓶颈，需要动态且可扩展的导频分配策略来提升系统性能。

Method: 提出了一种低复杂度的集中式算法和一种完全分布式的优先级导频选择算法。集中式算法按顺序分配导频以最小化全局信道估计误差；分布式算法则基于本地信息和AP优先级进行导频选择。

Result: 数值模拟表明，所提出的方案在网络吞吐量方面优于其他最先进的基准方案。

Conclusion: 论文提出的两种动态可扩展的导频分配策略在分布式大规模MIMO系统中有效减少了导频污染，提升了网络吞吐量。

Abstract: Pilot contamination remains a major bottleneck in realizing the full
potential of distributed massive MIMO systems. We propose two dynamic and
scalable pilot assignment strategies designed for practical deployment in such
networks. First, we present a low complexity centralized algorithm that
sequentially assigns pilots to user equipments (UEs) to minimize the global
channel estimation errors across serving access points (APs). This improves the
channel estimation quality and reduces interference among UEs, enhancing the
spectral efficiency. Second, we develop a fully distributed algorithm that uses
a priority-based pilot selection approach. In this algorithm, each selected AP
minimizes estimation error using only local information and offers candidate
pilots to the UEs. Every UE then selects a suitable pilot based on AP priority.
This approach ensures consistency and minimizes interference while
significantly reducing pilot contamination. The method requires no global
coordination, maintains low signaling overhead, and adapts dynamically to the
UE deployment. Numerical simulations demonstrate the superiority of our
proposed schemes in terms of network throughput when compared to other
state-of-the-art benchmark schemes.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [121] [Dodoor: Efficient Randomized Decentralized Scheduling with Load Caching for Heterogeneous Tasks and Clusters](https://arxiv.org/abs/2510.12889)
*Wei Da,Evangelia Kalyvianaki*

Main category: cs.DC

TL;DR: Dodoor是一种高效的去中心化任务调度器，通过批处理更新和新型负载评分，显著降低通信开销并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心的分布式任务调度需要高效且低通信开销的解决方案，传统调度器依赖实时探测，通信成本高。

Method: Dodoor采用基于缓存服务器信息的批处理更新机制，并引入新型负载评分来动态调度多维资源需求的任务。

Result: 在101节点异构集群上，Dodoor减少了55-66%的调度消息，吞吐量提升最高33.2%，平均完成时间减少12.1%，尾部延迟改善21.9%。

Conclusion: Dodoor通过减少通信开销和优化负载评分，显著提高了任务调度的效率和性能，适用于现代数据中心。

Abstract: This paper introduces Dodoor, an efficient randomized decentralized scheduler
designed for task scheduling in modern data centers. Dodoor leverages advanced
research on the weighted balls-into-bins model with b-batched setting. Unlike
other decentralized schedulers that rely on real-time probing of remote
servers, Dodoor makes scheduling decisions based on cached server information,
which is updated in batches, to reduce communication overheads. To schedule
tasks with dynamic, multidimensional resource requirements in heterogeneous
cluster, Dodoor uses a novel load score to measure servers' loads for each
scheduled task. This score captures the anti-affinity between servers and tasks
in contrast to the commonly used heuristic of counting pending tasks to balance
load. On a 101-node heterogeneous cluster, Dodoor is evaluated using two
workloads: (i) simulated Azure virtual machines placements and (ii) real
serverless Python functions executions in Docker. The evaluation shows that
Dodoor reduces scheduling messages by 55--66% on both workloads. Dodoor can
also increase throughput by up to 33.2% and 21.5%, reduce mean makespan latency
by 12.1% and 7.2%, and improve tail latency by 21.9% and 24.6% across the two
workloads.

</details>


### [122] [Scrutiny new framework in integrated distributed reliable systems](https://arxiv.org/abs/2510.13203)
*Mehdi Zekriyapanah Gashti*

Main category: cs.DC

TL;DR: 提出FDIRS新框架，通过异构分布式数据库技术提升集成系统性能，仿真结果显示其优于现有框架。


<details>
  <summary>Details</summary>
Motivation: 提出新框架以提高集成系统的满意度和性能。

Method: 分析了集成系统及其演进过程，简要介绍了ERPSD和ERPDRT框架，随后详细解释了新的FDIRS框架，并通过仿真与现有框架进行结果比较。

Result: FDIRS框架采用异构分布式数据库技术，显著提升了响应速度和性能。

Conclusion: 通过使用FDIRS框架，成功提高了集成系统的效率、性能和可靠性，并解决了先前框架的一些问题。

Abstract: In this paper we represent a new framework for integrated distributed
systems. In the proposed framework we have used three parts to increase
Satisfaction and Performance of this framework. At first we analyse integrated
systems and their evolution process and also ERPSD and ERPDRT framework briefly
then we explain the new FDIRS framework. Finally we compare the results of
simulation of the new framework with presented frameworks. Result showed In
FIDRS framework, the technique of heterogeneous distributed data base is used
to improve Performance and speed in responding to users. Finally by using FDIRS
framework we succeeded to increase Efficiency, Performance and reliability of
integrated systems and remove some of previous frameworks problems.

</details>


### [123] [BanaServe: Unified KV Cache and Dynamic Module Migration for Balancing Disaggregated LLM Serving in AI Infrastructure](https://arxiv.org/abs/2510.13223)
*Yiyuan He,Minxian Xu,Jingfeng Wu,Jianmin Hu,Chong Ma,Min Shen,Le Chen,Chengzhong Xu,Lin Qu,Kejiang Ye*

Main category: cs.DC

TL;DR: BanaServe是一个动态调度框架，通过资源迁移和缓存共享解决LLM服务中的负载不均衡问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前解耦式LLM服务系统存在静态资源分配不足、负载不均衡和缓存感知路由导致的效率低下问题。

Method: BanaServe引入了层级权重迁移、注意力级KV缓存迁移以及全局KV缓存共享机制，支持粗粒度和细粒度的负载重新分配。

Result: 与vLLM和DistServe相比，BanaServe实现了1.2x-3.9x的吞吐量提升和3.9%-78.4%的处理时间降低。

Conclusion: BanaServe通过动态资源重新分配和负载均衡机制，显著提升了LLM服务系统的吞吐量和效率，同时降低了处理时间和延迟。

Abstract: Large language models (LLMs) are increasingly deployed in AI infrastructure,
driving the need for high throughput, resource efficient serving systems.
Disaggregated LLM serving, which separates prompt prefill from auto-regressive
decode, has emerged as a promising architecture by isolating their
heterogeneous compute and memory demands. However, current disaggregated
systems face three key limitations: (i) static resource allocation cannot adapt
to highly dynamic workloads, causing over-provisioning that wastes resources or
under-provisioning that violates service level objectives (SLOs); (ii) inherent
load imbalance between prefill and decode stages, where prefill is
compute-bound and decode is memory-bound, causes under-utilization in one tier
while the other becomes a bottleneck; and (iii) prefix cache aware routing
skews load distribution, as high cache hit rate prefill nodes attract
disproportionately more requests, further degrading balance and efficiency. To
address these issues, we present BanaServe, a dynamic orchestration framework
that continuously rebalances computational and memory resources across prefill
and decode instances while eliminating hotspots induced by cache. BanaServe
introduces layer level weight migration, attention level Key Value Cache (KV
Cache) migration, and Global KV Cache Store sharing with layer wise overlapped
transmission, enabling both coarse grained (layer level) and fine grained
(attention level) load redistribution with minimal latency overhead. These
mechanisms allow routers to perform purely load aware scheduling, unconstrained
by cache placement. Compared to vLLM, BanaServe achieves 1.2x-3.9x higher
throughput with 3.9%-78.4% lower total processing time, and outperforms
DistServe by 1.1x-2.8x in throughput with 1.4%-70.1% latency reduction.

</details>


### [124] [Distributed Reductions for the Maximum Weight Independent Set Problem](https://arxiv.org/abs/2510.13306)
*Jannick Borowitz,Ernestine Großmann,Mattthias Schimek*

Main category: cs.DC

TL;DR: 首个分布式内存并行缩减算法用于最大权重独立集问题，在1024个处理器上展示良好扩展性，异步reduce-and-peel实现33倍加速，reduce-and-greedy实现50倍加速但解质量较低。


<details>
  <summary>Details</summary>
Motivation: 最大权重独立集问题是一个重要的NP难优化问题，现有的顺序算法难以处理超大规模图，因此需要分布式并行方法。

Method: 提出了分布式内存并行缩减算法，包括reduce-and-greedy和reduce-and-peel启发式算法，用于处理超大规模图。

Result: 在1024个处理器上进行的实验表明，分布式缩减算法具有良好的扩展性和缩减效果。异步reduce-and-peel方法实现了平均33倍的加速，而reduce-and-greedy方法实现了最高50倍的加速，但解质量较低。

Conclusion: 本文提出了首个分布式内存并行缩减算法，用于解决最大权重独立集问题，并在实践中展示了良好的扩展性和缩减效果。异步的reduce-and-peel方法在36个真实世界图上实现了平均33倍的加速，同时保持接近顺序算法的解质量。

Abstract: Finding maximum-weight independent sets in graphs is an important NP-hard
optimization problem. Given a vertex-weighted graph $G$, the task is to find a
subset of pairwise non-adjacent vertices of $G$ with maximum weight. Most
recently published practical exact algorithms and heuristics for this problem
use a variety of data-reduction rules to compute (near-)optimal solutions.
Applying these rules results in an equivalent instance of reduced size. An
optimal solution to the reduced instance can be easily used to construct an
optimal solution for the original input.
  In this work, we present the first distributed-memory parallel reduction
algorithms for this problem, targeting graphs beyond the scale of previous
sequential approaches. Furthermore, we propose the first distributed
reduce-and-greedy and reduce-and-peel algorithms for finding a maximum weight
independent set heuristically.
  In our practical evaluation, our experiments on up to $1024$ processors
demonstrate good scalability of our distributed reduce algorithms while
maintaining good reduction impact. Our asynchronous reduce-and-peel approach
achieves an average speedup of $33\times$ over a sequential state-of-the-art
reduce-and-peel approach on 36 real-world graphs with a solution quality close
to the sequential algorithm. Our reduce-and-greedy algorithms even achieve
average speedups of up to $50\times$ at the cost of a lower solution quality.
Moreover, our distributed approach allows us to consider graphs with more than
one billion vertices and 17 billion edges.

</details>


### [125] [Service-Level Energy Modeling and Experimentation for Cloud-Native Microservices](https://arxiv.org/abs/2510.13447)
*Julian Legler,Sebastian Werner,Maria C. Borges,Stefan Tai*

Main category: cs.DC

TL;DR: 提出了一种服务级别的能源模型，考虑了网络和存储的能耗，实验表明忽略这些组件会导致辅助服务能源使用低估高达63%。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在容器级别的CPU和内存细粒度能源使用测量或系统范围评估，往往忽略了跨容器服务交互（尤其是涉及网络和存储的辅助服务）的能源影响。

Method: 引入了一个服务级别的能源模型，该模型能够捕捉微服务在容器间执行的分布式特性，并得到了一个实验工具的支持，该工具不仅考虑了CPU和内存的能耗，还包括了网络和存储组件的能耗。

Result: 通过对流行的开源云原生微服务应用的多样化实验配置进行广泛实验验证，结果表明忽略网络和存储会导致辅助服务能源使用低估高达63%。

Conclusion: 研究表明，忽略网络和存储组件的能耗会导致对辅助服务能源使用的低估高达63%，强调了在能源高效微服务架构设计中需要进行更全面的能源评估。

Abstract: Microservice architectures have become the dominant paradigm for cloud-native
systems, offering flexibility and scalability. However, this shift has also led
to increased demand for cloud resources, contributing to higher energy
consumption and carbon emissions. While existing research has focused on
measuring fine-grained energy usage of CPU and memory at the container level,
or on system-wide assessments, these approaches often overlook the energy
impact of cross-container service interactions, especially those involving
network and storage for auxiliary services such as observability and system
monitoring. To address this gap, we introduce a service-level energy model that
captures the distributed nature of microservice execution across containers.
Our model is supported by an experimentation tool that accounts for energy
consumption not just in CPU and memory, but also in network and storage
components. We validate our approach through extensive experimentation with
diverse experiment configurations of auxiliary services for a popular
open-source cloud-native microservice application. Results show that omitting
network and storage can lead to an underestimation of auxiliary service energy
use by up to 63%, highlighting the need for more comprehensive energy
assessments in the design of energy-efficient microservice architectures.

</details>


### [126] [Adaptive Rescheduling in Prefill-Decode Disaggregated LLM Inference](https://arxiv.org/abs/2510.13668)
*Zhibin Wang,Zetao Hong,Xue Li,Zibo Wang,Shipeng Li,Qingkai Meng,Qing Wang,Chengying Huan,Rong Gu,Sheng Zhong,Chen Tian*

Main category: cs.DC

TL;DR: ARES通过长度预测和动态负载平衡，优化LLM推理效率，减少错误并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现实场景中，输出长度变化导致解码阶段工作负载严重不平衡，现有静态调度系统无法适应动态解码工作负载，导致SLO违规和OOM故障。

Method: 提出了一种轻量级且连续的LLM原生预测方法，利用LLM隐藏状态建模剩余生成长度；设计了动态平衡机制，整合当前和预测的工作负载。

Result: 减少MAE 49.42%，削减预测器参数93.28%；降低P99 TPOT 74.77%，提升吞吐量最高2.24倍。

Conclusion: ARES通过长度预测和动态负载平衡机制，显著提升了LLM推理的效率，减少了SLO违规和OOM故障，实现了更高的吞吐量。

Abstract: Large Language Model (LLM) inference has emerged as a fundamental paradigm.
In real-world scenarios, variations in output length cause severe workload
imbalance in the decode phase, particularly for long-output reasoning tasks.
Existing systems, such as PD disaggregation architectures, rely on static
prefill-to-decode scheduling, which often results in SLO violations and OOM
failures under evolving decode workloads.
  In this paper, we propose ARES, an adaptive decoding rescheduling system
powered by length prediction to anticipate future workloads. Our core
contributions include: (1) A lightweight and continuous LLM-native prediction
method that leverages LLM hidden state to model remaining generation length
with high precision (reducing MAE by 49.42%) and low overhead (cutting
predictor parameters by 93.28%); (2) A rescheduling solution in decode phase
with : A dynamic balancing mechanism that integrates current and predicted
workloads, reducing P99 TPOT by 74.77% and achieving up to 2.24 times higher
goodput.

</details>


### [127] [FIRST: Federated Inference Resource Scheduling Toolkit for Scientific AI Model Access](https://arxiv.org/abs/2510.13724)
*Aditya Tanikanti,Benoit Côté,Yanfei Guo,Le Chen,Nickolaus Saint,Ryan Chard,Ken Raffenetti,Rajeev Thakur,Thomas Uram,Ian Foster,Michael E. Papka,Venkatram Vishwanath*

Main category: cs.DC

TL;DR: FIRST是一个分布式HPC集群上的AI推理框架，提供私有、安全且可扩展的推理服务，支持多种模型和高效资源管理。


<details>
  <summary>Details</summary>
Motivation: 解决科学工作流中对私有、安全且可扩展AI推理的日益增长需求，避免依赖商业云基础设施。

Method: FIRST利用Globus Auth和Globus Compute，通过OpenAI兼容的API在分布式HPC集群上运行并行推理任务，支持多种推理后端（如vLLM）和自动资源扩展。

Result: FIRST支持在私有、安全的环境中高效运行大规模AI模型，实现每日数十亿token的生成，并提供高吞吐量和低延迟的推理服务。

Conclusion: FIRST框架为科学工作流提供了私有、安全且可扩展的AI推理解决方案，使研究人员能够在本地基础设施上高效运行大规模AI模型，摆脱对商业云服务的依赖。

Abstract: We present the Federated Inference Resource Scheduling Toolkit (FIRST), a
framework enabling Inference-as-a-Service across distributed High-Performance
Computing (HPC) clusters. FIRST provides cloud-like access to diverse AI
models, like Large Language Models (LLMs), on existing HPC infrastructure.
Leveraging Globus Auth and Globus Compute, the system allows researchers to run
parallel inference workloads via an OpenAI-compliant API on private, secure
environments. This cluster-agnostic API allows requests to be distributed
across federated clusters, targeting numerous hosted models. FIRST supports
multiple inference backends (e.g., vLLM), auto-scales resources, maintains
"hot" nodes for low-latency execution, and offers both high-throughput batch
and interactive modes. The framework addresses the growing demand for private,
secure, and scalable AI inference in scientific workflows, allowing researchers
to generate billions of tokens daily on-premises without relying on commercial
cloud infrastructure.

</details>


### [128] [Tight Conditions for Binary-Output Tasks under Crashes](https://arxiv.org/abs/2510.13755)
*Timothé Albouy,Antonio Fernández Anta,Chryssis Georgiou,Nicolas Nicolaou,Junlang Wang*

Main category: cs.DC

TL;DR: 本文研究了分布式系统中解决二进制输出任务的必要和充分条件，统一了多个问题，并提供了适用于不同系统的紧条件。


<details>
  <summary>Details</summary>
Motivation: 探索分布式系统中解决二进制输出任务的必要条件，以统一和扩展现有分布式计算问题的理解。

Method: 通过关注任务的可能输出集（忽略有效性和值多重性），并考虑部分进程可能无输出的情况，对n和t的紧条件进行了完整表征。

Result: 得出在n个进程中最多t个可能崩溃的情况下，解决所有二进制输出任务类的紧条件，适用于同步和异步系统。

Conclusion: 本文提供了在同步和异步分布式系统中，解决具有二进制输出任务的充分和必要条件，统一了多个分布式计算问题，如二进制共识和对称性破坏。

Abstract: This paper explores necessary and sufficient system conditions to solve
distributed tasks with binary outputs (\textit{i.e.}, tasks with output values
in $\{0,1\}$). We focus on the distinct output sets of values a task can
produce (intentionally disregarding validity and value multiplicity),
considering that some processes may output no value. In a distributed system
with $n$ processes, of which up to $t \leq n$ can crash, we provide a complete
characterization of the tight conditions on $n$ and $t$ under which every class
of tasks with binary outputs is solvable, for both synchronous and asynchronous
systems. This output-set approach yields highly general results: it unifies
multiple distributed computing problems, such as binary consensus and symmetry
breaking, and it produces impossibility proofs that hold for stronger task
formulations, including those that consider validity, account for value
multiplicity, or move beyond binary outputs.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [129] [A faster algorithm for efficient longest common substring calculation for non-parametric entropy estimation in sequential data](https://arxiv.org/abs/2510.13330)
*Bridget Smart,Max Ward,Matthew Roughan*

Main category: cs.DS

TL;DR: LCSFinder是一种新算法，将LCS计算的最坏时间复杂度从三次方降至对数线性，大幅提升了熵估计的效率。


<details>
  <summary>Details</summary>
Motivation: 非参数熵估计在序列数据中是信号处理的基础工具，但现有基于最长公共子串的方法效率低下，限制了其在实际数据中的应用。

Method: LCSFinder基于标准算法构建（如排序后缀数组和持久化二叉搜索树），通过精心设计的细节实现动态增长序列的匹配需求。

Result: LCSFinder在真实和模拟数据上实现了显著的加速，远超现有实现。

Conclusion: LCSFinder算法显著提升了最长公共子串（LCS）计算的效率，将最坏情况下的时间复杂度从三次方降低到对数线性时间，使得在实际信号处理中进行大规模熵估计成为可能。

Abstract: Non-parametric entropy estimation on sequential data is a fundamental tool in
signal processing, capturing information flow within or between processes to
measure predictability, redundancy, or similarity. Methods based on longest
common substrings (LCS) provide a non-parametric estimate of typical set size
but are often inefficient, limiting use on real-world data. We introduce
LCSFinder, a new algorithm that improves the worst-case performance of LCS
calculations from cubic to log-linear time. Although built on standard
algorithmic constructs - including sorted suffix arrays and persistent binary
search trees - the details require care to provide the matches required for
entropy estimation on dynamically growing sequences. We demonstrate that
LCSFinder achieves dramatic speedups over existing implementations on real and
simulated data, enabling entropy estimation at scales previously infeasible in
practical signal processing.

</details>


### [130] [Tight Parameterized (In)tractability of Layered Crossing Minimization: Subexponential Algorithms and Kernelization](https://arxiv.org/abs/2510.13335)
*Fedor V. Fomin,Petr A. Golovach,Tanmay Inamdar,Saket Saurabh,Meirav Zehavi*

Main category: cs.DS

TL;DR: 论文解决了2层交叉最小化问题的子指数参数化复杂性，并扩展到多层情况，提出了针对3层的子指数算法和多项式核，排除了h≥4层的多项式核可能性。


<details>
  <summary>Details</summary>
Motivation: 研究的起点是关于2层交叉最小化问题的子指数参数化复杂性的十年未解之谜。作者希望进一步探讨多层情况下的子指数现象，并研究多项式核化的可能性。

Method: 论文采用了子指数固定参数算法，针对2层和3层交叉最小化问题设计了新的算法，并进行了理论分析。

Result: 论文首次为2层交叉最小化问题提供了子指数固定参数算法，运行时间为2^O(√k log k) + n·k^O(1)。对于3层情况，提出了运行时间为2^O(k^{2/3} log k) + n·k^O(1)的子指数FPT算法。同时，证明了对于h≥5层，除非指数时间假设失败，否则不存在运行时间为2^{o(k/log k)}·n^{O(1)}的算法。此外，为h=3层设计了一个新的多项式核，并排除了h≥4层存在多项式核的可能性。

Conclusion: 该论文解决了关于2层交叉最小化问题的十年未解之谜，并进一步探讨了多层情况下的子指数参数化复杂性。研究还涉及多项式核化的问题，为h=3层设计了一个新的多项式核，并排除了h≥4层存在多项式核的可能性。

Abstract: The starting point of our work is a decade-old open question concerning the
subexponential parameterized complexity of \textsc{2-Layer Crossing
Minimization}. In this problem, the input is an $n$-vertex graph $G$ whose
vertices are partitioned into two independent sets $V_1$ and $V_2$, and a
non-negative integer $k$. The question is whether $G$ admits a 2-layered
drawing with at most $k$ crossings, where each $V_i$ lies on a distinct line
parallel to the $x$-axis, and all edges are straight lines. We resolve this
open question by giving the first subexponential fixed-parameter algorithm for
this problem, running in time $2^{O(\sqrt{k}\log k)} + n \cdot k^{O(1)}$.
  We then ask whether the subexponential phenomenon extends beyond two layers.
In the general $h$-Layer Crossing Minimization problem, the vertex set is
partitioned into $h$ independent sets $V_1, \ldots, V_h$, and the goal is to
decide whether an $h$-layered drawing with at most $k$ crossings exists. We
present a subexponential FPT algorithm for three layers with running time
$2^{O(k^{2/3}\log k)} + n \cdot k^{O(1)}$ for $h = 3$ layers. In contrast, we
show that for all $h \ge 5$, no algorithm with running time $2^{o(k/\log k)}
\cdot n^{O(1)}$ exists unless the Exponential-Time Hypothesis fails.
  Finally, we address polynomial kernelization. While a polynomial kernel was
already known for $h=2$, we design a new polynomial kernel for $h=3$. These
kernels are essential ingredients in our subexponential algorithms. Finally, we
rule out polynomial kernels for all $h \ge 4$ unless the polynomial hierarchy
collapses.

</details>


### [131] [Chromatic correlation clustering via cluster LP](https://arxiv.org/abs/2510.13446)
*Fateme Abbasi,Hyung-Chan An,Jarosław Byrka,Changyeol Lee,Yongho Shin*

Main category: cs.DS

TL;DR: 本文通过色聚类LP，为色相关性聚类开发了一个$(2+\varepsilon)$-近似算法，证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 鉴于聚类LP在相关性聚类中的成功应用，研究者探索了其在色相关性聚类中的潜在用途。

Method: 研究采用了色聚类LP作为核心工具，开发了一种新的近似算法。

Result: 提出了一个$(2+\varepsilon)$-近似算法，验证了色聚类LP在色相关性聚类中的适用性。

Conclusion: 本文通过使用色聚类LP，为色相关性聚类提供了一个$(2+\varepsilon)$-近似算法，证明了色聚类LP在这一问题中的有效性。

Abstract: Correlation Clustering is a fundamental clustering problem, and there has
been a line of work on improving the approximation ratio for this problem in
recent years. A key algorithmic component in these works is the cluster LP.
Chromatic Correlation Clustering is an interesting generalization that has also
been intensively studied. In light of success of the cluster LP in Correlation
Clustering, it would be an interesting question whether the cluster LP can be
used in Chromatic Correlation Clustering. We answer this question with
affirmatives by presenting a $(2+\varepsilon)$-approximation algorithm for
Chromatic Correlation Clustering using a chromatic cluster LP.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [132] [MiGumi: Making Tightly Coupled Integral Joints Millable](https://arxiv.org/abs/2510.13168)
*Aditya Ganeshan,Kurt Fleischer,Wenzel Jakob,Ariel Shamir,Daniel Ritchie,Takeo Igarashi,Maria Larsson*

Main category: cs.GR

TL;DR: 研究提出了一种名为MXG的语言和优化方法，使传统木工接头能够通过CNC铣削高效生产，解决了几何偏差问题，确保了接头的紧密配合和功能性。


<details>
  <summary>Details</summary>
Motivation: 传统木工接头虽然强度高、耐用且优雅，但由于手工制作的成本高和难度大，在现代工作流程中很少使用。CNC铣削提供了可扩展的替代方案，但直接铣削传统接头往往因几何偏差而无法产生功能性结果。

Method: 提出了Millable Extrusion Geometry（MXG）语言，用于表示通过平端钻头进行的铣削操作生成的几何形状，并开发了两种可微分的损失函数来优化接头几何形状。

Result: 在30种传统接头设计上评估了该方法，证明其能够生产出与原始几何形状近似且紧密配合的CNC兼容接头。

Conclusion: 通过重新设计传统木工接头以适应CNC工作流程，研究不仅延续了这一传统工艺的演变，还确保了其在未来制造实践中的相关性。

Abstract: Traditional integral wood joints, despite their strength, durability, and
elegance, remain rare in modern workflows due to the cost and difficulty of
manual fabrication. CNC milling offers a scalable alternative, but directly
milling traditional joints often fails to produce functional results because
milling induces geometric deviations, such as rounded inner corners, that alter
the target geometries of the parts. Since joints rely on tightly fitting
surfaces, such deviations introduce gaps or overlaps that undermine fit or
block assembly. We propose to overcome this problem by (1) designing a language
that represent millable geometry, and (2) co-optimizing part geometries to
restore coupling. We introduce Millable Extrusion Geometry (MXG), a language
for representing geometry as the outcome of milling operations performed with
flat-end drill bits. MXG represents each operation as a subtractive extrusion
volume defined by a tool direction and drill radius. This parameterization
enables the modeling of artifact-free geometry under an idealized zero-radius
drill bit, matching traditional joint designs. Increasing the radius then
reveals milling-induced deviations, which compromise the integrity of the
joint. To restore coupling, we formalize tight coupling in terms of both
surface proximity and proximity constraints on the mill-bit paths associated
with mating surfaces. We then derive two tractable, differentiable losses that
enable efficient optimization of joint geometry. We evaluate our method on 30
traditional joint designs, demonstrating that it produces CNC-compatible,
tightly fitting joints that approximates the original geometry. By
reinterpreting traditional joints for CNC workflows, we continue the evolution
of this heritage craft and help ensure its relevance in future making
practices.

</details>


### [133] [HRM^2Avatar: High-Fidelity Real-Time Mobile Avatars from Monocular Phone Scans](https://arxiv.org/abs/2510.13587)
*Chao Shi,Shenghao Jia,Jinhui Liu,Yong Zhang,Liangchao Zhu,Zhonglei Yang,Jinze Ma,Chaoyue Niu,Chengfei Lv*

Main category: cs.GR

TL;DR: HRM$^2$Avatar通过智能手机单目扫描创建高保真虚拟化身，支持实时渲染，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为普通用户提供低成本、高保真的虚拟化身创建方案，替代昂贵的工作室级多相机设备。

Method: 利用智能手机捕获的静态姿势序列和动态运动序列，结合轻量级表达表示，提取服装网格并附着光照感知高斯模型，实现高效渲染。

Result: 在移动设备上实现120 FPS、VR设备上90 FPS的2K分辨率渲染，速度比基线快2.7倍。

Conclusion: HRM$^2$Avatar框架在移动设备上实现了高保真虚拟化身的实时渲染和动画，视觉真实性和交互性均优于现有单目方法。

Abstract: We present HRM$^2$Avatar, a framework for creating high-fidelity avatars from
monocular phone scans, which can be rendered and animated in real time on
mobile devices. Monocular capture with smartphones provides a low-cost
alternative to studio-grade multi-camera rigs, making avatar digitization
accessible to non-expert users. Reconstructing high-fidelity avatars from
single-view video sequences poses challenges due to limited visual and
geometric data. To address these limitations, at the data level, our method
leverages two types of data captured with smartphones: static pose sequences
for texture reconstruction and dynamic motion sequences for learning
pose-dependent deformations and lighting changes. At the representation level,
we employ a lightweight yet expressive representation to reconstruct
high-fidelity digital humans from sparse monocular data. We extract garment
meshes from monocular data to model clothing deformations effectively, and
attach illumination-aware Gaussians to the mesh surface, enabling high-fidelity
rendering and capturing pose-dependent lighting. This representation
efficiently learns high-resolution and dynamic information from monocular data,
enabling the creation of detailed avatars. At the rendering level, real-time
performance is critical for animating high-fidelity avatars in AR/VR, social
gaming, and on-device creation. Our GPU-driven rendering pipeline delivers 120
FPS on mobile devices and 90 FPS on standalone VR devices at 2K resolution,
over $2.7\times$ faster than representative mobile-engine baselines.
Experiments show that HRM$^2$Avatar delivers superior visual realism and
real-time interactivity, outperforming state-of-the-art monocular methods.

</details>


### [134] [MimicKit: A Reinforcement Learning Framework for Motion Imitation and Control](https://arxiv.org/abs/2510.13794)
*Xue Bin Peng*

Main category: cs.GR

TL;DR: MimicKit是一个开源框架，结合运动模仿和强化学习训练运动控制器，支持计算机图形学和机器人研究，提供模块化和可配置的设计。


<details>
  <summary>Details</summary>
Motivation: 旨在为计算机图形学和机器人领域的研究与应用提供一个统一的训练框架，包括标准化的环境、代理和数据结构。

Method: 该框架提供了常用的运动模仿技术和强化学习算法的实现，采用模块化和可配置的设计，便于修改和扩展到新角色和任务。

Result: 开发了一个模块化且易于配置的开源代码库，支持新角色和任务的快速扩展。

Conclusion: MimicKit是一个开源框架，旨在通过运动模仿和强化学习训练运动控制器，支持计算机图形学和机器人领域的研究与应用。

Abstract: MimicKit is an open-source framework for training motion controllers using
motion imitation and reinforcement learning. The codebase provides
implementations of commonly-used motion-imitation techniques and RL algorithms.
This framework is intended to support research and applications in computer
graphics and robotics by providing a unified training framework, along with
standardized environment, agent, and data structures. The codebase is designed
to be modular and easily configurable, enabling convenient modification and
extension to new characters and tasks. The open-source codebase is available
at: https://github.com/xbpeng/MimicKit.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [135] [Learning to Grasp Anything by Playing with Random Toys](https://arxiv.org/abs/2510.12866)
*Dantong Niu,Yuvan Sharma,Baifeng Shi,Rachel Ding,Matteo Gioia,Haoru Xue,Henry Tsai,Konstantinos Kallidromitis,Anirudh Pai,Shankar Shastry,Trevor Darrell,Jitendra Malik,Roei Herzig*

Main category: cs.RO

TL;DR: 受儿童学习启发，研究通过四种基本形状训练机器人，实现了对新物体的零样本抓取，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 受儿童通过简单玩具发展出通用操作技能的启发，研究探索机器人是否也能通过类似方式实现对新物体的通用抓取能力。

Method: 研究提出了一种物体中心视觉表示方法，通过检测池化机制实现，并在模拟和物理机器人上进行了评估。

Result: 在YCB数据集上，模型实现了67%的真实世界抓取成功率，优于依赖更多领域内数据的最先进方法。

Conclusion: 该研究展示了通过使用由四种基本形状组成的随机组装物体进行训练，机器人能够实现对新物体的零样本抓取，且性能优于现有方法。

Abstract: Robotic manipulation policies often struggle to generalize to novel objects,
limiting their real-world utility. In contrast, cognitive science suggests that
children develop generalizable dexterous manipulation skills by mastering a
small set of simple toys and then applying that knowledge to more complex
items. Inspired by this, we study if similar generalization capabilities can
also be achieved by robots. Our results indicate robots can learn generalizable
grasping using randomly assembled objects that are composed from just four
shape primitives: spheres, cuboids, cylinders, and rings. We show that training
on these "toys" enables robust generalization to real-world objects, yielding
strong zero-shot performance. Crucially, we find the key to this generalization
is an object-centric visual representation induced by our proposed detection
pooling mechanism. Evaluated in both simulation and on physical robots, our
model achieves a 67% real-world grasping success rate on the YCB dataset,
outperforming state-of-the-art approaches that rely on substantially more
in-domain data. We further study how zero-shot generalization performance
scales by varying the number and diversity of training toys and the
demonstrations per toy. We believe this work offers a promising path to
scalable and generalizable learning in robotic manipulation. Demonstration
videos, code, checkpoints and our dataset are available on our project page:
https://lego-grasp.github.io/ .

</details>


### [136] [Kinematic Kitbashing for Modeling Functional Articulated Objects](https://arxiv.org/abs/2510.13048)
*Minghao Guo,Victor Zordan,Sheldon Andrews,Wojciech Matusik,Maneesh Agrawala,Hsueh-Ti Derek Liu*

Main category: cs.RO

TL;DR: Kinematic Kitbashing是一种自动框架，通过重用部件合成功能感知的关节化对象，结合优化和几何匹配，实现快速创建互动资产。


<details>
  <summary>Details</summary>
Motivation: 旨在通过重用现有模型中的部件，自动合成功能感知的关节化对象，满足用户指定的功能目标。

Method: 框架采用运动学感知的附着能量，结合退火Riemannian Langevin动力学采样器，解决非可微功能目标和约束问题。

Result: 生成的关节化形状多样，在几何、运动学和功能指标上显著优于现有基线。

Conclusion: Kinematic Kitbashing通过紧密结合基于部分的形状建模和功能驱动的优化，实现了互动式关节化资产的快速创建。

Abstract: We introduce Kinematic Kitbashing, an automatic framework that synthesizes
functionality-aware articulated objects by reusing parts from existing models.
Given a kinematic graph with a small collection of articulated parts, our
optimizer jointly solves for the spatial placement of every part so that (i)
attachments remain geometrically sound over the entire range of motion and (ii)
the assembled object satisfies user-specified functional goals such as
collision-free actuation, reachability, or trajectory following. At its core is
a kinematics-aware attachment energy that aligns vector distance function
features sampled across multiple articulation snapshots. We embed this
attachment term within an annealed Riemannian Langevin dynamics sampler that
treats functionality objectives as additional energies, enabling robust global
exploration while accommodating non-differentiable functionality objectives and
constraints. Our framework produces a wide spectrum of assembled articulated
shapes, from trash-can wheels grafted onto car bodies to multi-segment lamps,
gear-driven paddlers, and reconfigurable furniture, and delivers strong
quantitative improvements over state-of-the-art baselines across geometric,
kinematic, and functional metrics. By tightly coupling articulation-aware
geometry matching with functionality-driven optimization, Kinematic Kitbashing
bridges part-based shape modeling and functional assembly design, empowering
rapid creation of interactive articulated assets.

</details>


### [137] [Gaussian Process Implicit Surfaces as Control Barrier Functions for Safe Robot Navigation](https://arxiv.org/abs/2510.12919)
*Mouhyemen Khan,Tatsuya Ibuki,Abhijit Chatterjee*

Main category: cs.RO

TL;DR: 论文提出将隐式表面作为控制屏障函数（CBF），利用高斯过程隐式表面（GPIS）表示安全边界，并通过稀疏化解决计算复杂度问题。实验验证了该方法在避免碰撞任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 受水平集方法和控制屏障函数（CBFs）的启发，作者希望将隐式表面本身作为CBF，以统一这两种范式，并利用GPIS的优越性（如不确定性估计和解析可操作性）来增强安全性。

Method: 论文利用高斯过程隐式表面（GPIS）表示安全边界，并通过安全样本（来自传感器测量）来调节GP。GP后验均值定义了隐式安全表面（安全信念），后验方差提供了鲁棒的安全裕度。此外，开发了稀疏解决方案（稀疏高斯CBF）以缓解GP计算复杂度高的问题。

Result: 在模拟的7自由度机械臂和四旋翼飞行器的实验中，高斯CBF（带和不带稀疏性）均实现了安全交互和无碰撞执行，避免了原本会与物体相交的轨迹。

Conclusion: 该论文提出了一个统一的框架，将隐式表面作为控制屏障函数（CBF），并通过高斯过程隐式表面（GPIS）表示安全边界。稀疏高斯CBF的开发解决了GP计算复杂度高的问题，实验验证了该方法在避免碰撞任务中的有效性。

Abstract: Level set methods underpin modern safety techniques such as control barrier
functions (CBFs), while also serving as implicit surface representations for
geometric shapes via distance fields. Inspired by these two paradigms, we
propose a unified framework where the implicit surface itself acts as a CBF. We
leverage Gaussian process (GP) implicit surface (GPIS) to represent the safety
boundaries, using safety samples which are derived from sensor measurements to
condition the GP. The GP posterior mean defines the implicit safety surface
(safety belief), while the posterior variance provides a robust safety margin.
Although GPs have favorable properties such as uncertainty estimation and
analytical tractability, they scale cubically with data. To alleviate this
issue, we develop a sparse solution called sparse Gaussian CBFs. To the best of
our knowledge, GPIS have not been explicitly used to synthesize CBFs. We
validate the approach on collision avoidance tasks in two settings: a simulated
7-DOF manipulator operating around the Stanford bunny, and a quadrotor
navigating in 3D around a physical chair. In both cases, Gaussian CBFs (with
and without sparsity) enable safe interaction and collision-free execution of
trajectories that would otherwise intersect the objects.

</details>


### [138] [Geometric Model Predictive Path Integral for Agile UAV Control with Online Collision Avoidance](https://arxiv.org/abs/2510.12924)
*Pavel Pochobradský,Ondřej Procházka,Robert Pěnička,Vojtěch Vonásek,Martin Saska*

Main category: cs.RO

TL;DR: GMPPI是一种采样控制器，结合几何SE(3)控制和动态参数优化，显著提升无人机在复杂环境中的敏捷轨迹跟踪和避障能力。


<details>
  <summary>Details</summary>
Motivation: 现有Model Predictive Path Integral (MPPI)实现无法兼顾敏捷飞行和复杂环境避障，需提升跟踪性能和避障能力。

Method: 提出Geometric Model Predictive Path Integral (GMPPI)控制器，结合几何SE(3)控制生成部分轨迹，采用变化的仿真时间步长和动态成本/噪声参数，并集成立体深度相机实现在线避障。

Result: GMPPI在模拟环境中能以13m/s速度避开障碍物，跟踪误差与几何SE(3)控制器相当；真实实验中速度达10m/s。

Conclusion: GMPPI控制器在模拟和真实世界实验中均能有效跟踪敏捷轨迹并避开障碍物，速度高达10m/s，性能优于现有先进避障规划器。

Abstract: In this letter, we introduce Geometric Model Predictive Path Integral
(GMPPI), a sampling-based controller capable of tracking agile trajectories
while avoiding obstacles. In each iteration, GMPPI generates a large number of
candidate rollout trajectories and then averages them to create a nominal
control to be followed by the Unmanned Aerial Vehicle (UAV). We propose using
geometric SE(3) control to generate part of the rollout trajectories,
significantly increasing precision in agile flight. Furthermore, we introduce
varying rollout simulation time step length and dynamic cost and noise
parameters, vastly improving tracking performance of smooth and low-speed
trajectories over an existing Model Predictive Path Integral (MPPI)
implementation. Finally, we propose an integration of GMPPI with a stereo depth
camera, enabling online obstacle avoidance at high speeds, a crucial step
towards autonomous UAV flights in complex environments. The proposed controller
can track simulated agile reference trajectories with position error similar to
the geometric SE(3) controller. However, the same configuration of the proposed
controller can avoid obstacles in a simulated forest environment at speeds of
up to 13m/s, surpassing the performance of a state-of-the-art obstacle-aware
planner. In real-world experiments, GMPPI retains the capability to track agile
trajectories and avoids obstacles at speeds of up to 10m/s.

</details>


### [139] [Enhancing Sampling-based Planning with a Library of Paths](https://arxiv.org/abs/2510.12962)
*Michal Minařík,Vojtěch Vonásek,Robert Pěnička*

Main category: cs.RO

TL;DR: 该论文提出一种重用历史路径的规划方法，显著提升狭窄通道中的规划效率，速度提升高达85%。


<details>
  <summary>Details</summary>
Motivation: 传统的采样规划器在狭窄通道中效率低下，且每次规划都从零开始，无法利用历史信息。

Method: 通过存储一组物体的路径库，在新物体规划时找到最相似的物体并利用其路径作为近似解，随后在配置空间沿近似路径进行采样。

Result: 在多种狭窄通道场景中测试，与OMPL库中的先进方法相比，该方法速度提升高达85%，且在传统规划器失败的情况下仍能找到解。

Conclusion: 该论文提出了一种基于历史解决方案库的路径规划方法，显著提高了在狭窄通道场景中的规划效率，并开源了其实现。

Abstract: Path planning for 3D solid objects is a challenging problem, requiring a
search in a six-dimensional configuration space, which is, nevertheless,
essential in many robotic applications such as bin-picking and assembly. The
commonly used sampling-based planners, such as Rapidly-exploring Random Trees,
struggle with narrow passages where the sampling probability is low, increasing
the time needed to find a solution. In scenarios like robotic bin-picking,
various objects must be transported through the same environment. However,
traditional planners start from scratch each time, losing valuable information
gained during the planning process. We address this by using a library of past
solutions, allowing the reuse of previous experiences even when planning for a
new, previously unseen object. Paths for a set of objects are stored, and when
planning for a new object, we find the most similar one in the library and use
its paths as approximate solutions, adjusting for possible mutual
transformations. The configuration space is then sampled along the approximate
paths. Our method is tested in various narrow passage scenarios and compared
with state-of-the-art methods from the OMPL library. Results show significant
speed improvements (up to 85% decrease in the required time) of our method,
often finding a solution in cases where the other planners fail. Our
implementation of the proposed method is released as an open-source package.

</details>


### [140] [The Omega Turn: A General Turning Template for Elongate Robots](https://arxiv.org/abs/2510.12970)
*Baxi Chong,Tianyu Wang,Kelimar Diaz,Christopher J. Pierce,Eva Erickson,Julian Whitman,Yuelin Deng,Esteban Flores,Ruijie Fu,Juntao He,Jianfeng Lin,Hang Lu,Guillaume Sartoretti,Howie Choset,Daniel I. Goldman*

Main category: cs.RO

TL;DR: 通过模仿线虫的欧米茄转弯，设计了一个基于行波叠加的控制器，实现了细长机器人在复杂环境中的有效转弯。


<details>
  <summary>Details</summary>
Motivation: 细长无肢机器人在紧密空间中的运动能力对于搜救和工业检查等应用至关重要，但目前关于此类系统转弯策略的研究有限。

Method: 使用理论和生物学比较的方法，将欧米茄转弯描述为两个行波的叠加，并基于此设计了一个控制器。

Result: 设计的控制器在实验室和杂乱环境中实现了稳健有效的转弯行为，并能推广到多足机器人。

Conclusion: 通过理论和生物学比较的方法，我们提出了一种将欧米茄转弯描述为两个行波叠加的控制器设计，该设计不仅在实验室和杂乱环境中实现了稳健有效的转弯行为，还能推广到多足机器人，展示了无肢体和有肢体细长机器人的另一种有效身体驱动转弯策略。

Abstract: Elongate limbless robots have the potential to locomote through tightly
packed spaces for applications such as search-and-rescue and industrial
inspections. The capability to effectively and robustly maneuver elongate
limbless robots is crucial to realize such potential. However, there has been
limited research on turning strategies for such systems. To achieve effective
and robust turning performance in cluttered spaces, we take inspiration from a
microscopic nematode, C. elegans, which exhibits remarkable maneuverability in
rheologically complex environments partially because of its ability to perform
omega turns. Despite recent efforts to analyze omega turn kinematics, it
remains unknown if there exists a wave equation sufficient to prescribe an
omega turn, let alone its reconstruction on robot platforms. Here, using a
comparative theory-biology approach, we prescribe the omega turn as a
superposition of two traveling waves. With wave equations as a guideline, we
design a controller for limbless robots enabling robust and effective turning
behaviors in lab and cluttered field environments. Finally, we show that such
omega turn controllers can also generalize to elongate multi-legged robots,
demonstrating an alternative effective body-driven turning strategy for
elongate robots, with and without limbs.

</details>


### [141] [Actron3D: Learning Actionable Neural Functions from Videos for Transferable Robotic Manipulation](https://arxiv.org/abs/2510.12971)
*Anran Zhang,Hanzhi Chen,Yannick Burkhardt,Yao Zhong,Johannes Betz,Helen Oleynikova,Stefan Leutenegger*

Main category: cs.RO

TL;DR: Actron3D通过Neural Affordance Function从少量RGB视频学习6-DoF操作技能，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人从少量未校准RGB视频中学习可转移6-DoF操作技能的挑战。

Method: 采用Neural Affordance Function作为核心表示，通过粗到细的优化管道检索和转移操作策略。

Result: 在13项任务中平均成功率提升14.9个百分点，每任务仅需2-3个演示视频。

Conclusion: Actron3D框架通过Neural Affordance Function从少量单目RGB人类视频中提取可转移的6-DoF操作技能，显著提升了任务成功率。

Abstract: We present Actron3D, a framework that enables robots to acquire transferable
6-DoF manipulation skills from just a few monocular, uncalibrated, RGB-only
human videos. At its core lies the Neural Affordance Function, a compact
object-centric representation that distills actionable cues from diverse
uncalibrated videos-geometry, visual appearance, and affordance-into a
lightweight neural network, forming a memory bank of manipulation skills.
During deployment, we adopt a pipeline that retrieves relevant affordance
functions and transfers precise 6-DoF manipulation policies via coarse-to-fine
optimization, enabled by continuous queries to the multimodal features encoded
in the neural functions. Experiments in both simulation and the real world
demonstrate that Actron3D significantly outperforms prior methods, achieving a
14.9 percentage point improvement in average success rate across 13 tasks while
requiring only 2-3 demonstration videos per task.

</details>


### [142] [UNCAP: Uncertainty-Guided Planning Using Natural Language Communication for Cooperative Autonomous Vehicles](https://arxiv.org/abs/2510.12992)
*Neel P. Bhatt,Po-han Li,Kushagra Gupta,Rohan Siva,Daniel Milan,Alexander T. Hogue,Sandeep P. Chinchali,David Fridovich-Keil,Zhangyang Wang,Ufuk Topcu*

Main category: cs.RO

TL;DR: UNCAP是一种基于视觉-语言模型的CAV协同规划方法，通过轻量级自然语言消息和两阶段通信协议，显著提升通信效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中因传输高带宽原始传感器数据或忽略共享数据中的感知和规划不确定性而导致的系统不可扩展和不安全的问题。

Method: UNCAP采用基于视觉-语言模型的规划方法，通过轻量级自然语言消息进行通信，并明确考虑感知不确定性。其两阶段协议包括：1)识别最相关的车辆子集；2)发送定量表达感知不确定性的消息。

Result: 实验显示，UNCAP在多种驾驶场景下实现了通信带宽减少63%，驾驶安全评分提高31%，决策不确定性降低61%，并在近距离事件中碰撞距离裕量增加了四倍。

Conclusion: UNCAP通过两阶段通信协议，显著提高了多CAV协同规划的通信效率和安全性，同时减少了决策不确定性。

Abstract: Safe large-scale coordination of multiple cooperative connected autonomous
vehicles (CAVs) hinges on communication that is both efficient and
interpretable. Existing approaches either rely on transmitting high-bandwidth
raw sensor data streams or neglect perception and planning uncertainties
inherent in shared data, resulting in systems that are neither scalable nor
safe. To address these limitations, we propose Uncertainty-Guided Natural
Language Cooperative Autonomous Planning (UNCAP), a vision-language model-based
planning approach that enables CAVs to communicate via lightweight natural
language messages while explicitly accounting for perception uncertainty in
decision-making. UNCAP features a two-stage communication protocol: (i) an ego
CAV first identifies the subset of vehicles most relevant for information
exchange, and (ii) the selected CAVs then transmit messages that quantitatively
express their perception uncertainty. By selectively fusing messages that
maximize mutual information, this strategy allows the ego vehicle to integrate
only the most relevant signals into its decision-making, improving both the
scalability and reliability of cooperative planning. Experiments across diverse
driving scenarios show a 63% reduction in communication bandwidth with a 31%
increase in driving safety score, a 61% reduction in decision uncertainty, and
a four-fold increase in collision distance margin during near-miss events.
Project website: https://uncap-project.github.io/

</details>


### [143] [Development of a Linear Guide-Rail Testbed for Physically Emulating ISAM Operations](https://arxiv.org/abs/2510.13005)
*Robert Muldrow,Channing Ludden,Christopher Petersen*

Main category: cs.RO

TL;DR: 本文设计了一个6-DOF机械臂和1-DOF导轨系统组成的实验平台，用于模拟和验证ISAM操作中的动力学模型。


<details>
  <summary>Details</summary>
Motivation: 在自由飞行的卫星上，机械臂运动产生的复杂扰动力和运动是一个复杂的控制问题，需要进一步研究，而现有的动力学模型在太空环境中的实验验证存在挑战。

Method: 通过将6-DOF UR3e机械臂安装在卫星总线上，并将卫星总线安装在1-DOF导轨系统上，设计了一个实验性ISAM模拟系统。

Result: 该实验系统将用于探索和验证空间运动、串联机器人操作和接触力学模型。

Conclusion: 本文提出了一种新的硬件在环（HIL）实验测试平台，用于模拟在轨服务、组装和制造（ISAM）操作，解决了在太空环境中验证动力学模型的挑战。

Abstract: In-Space Servicing, Assembly, and Manufacturing (ISAM) is a set of emerging
operations that provides several benefits to improve the longevity, capacity,
mo- bility, and expandability of existing and future space assets. Serial
robotic ma- nipulators are particularly vital in accomplishing ISAM operations,
however, the complex perturbation forces and motions associated with movement
of a robotic arm on a free-flying satellite presents a complex controls problem
requiring addi- tional study. While many dynamical models are developed,
experimentally test- ing and validating these models is challenging given that
the models operate in space, where satellites have six-degrees-of-freedom
(6-DOF). This paper attempts to resolve those challenges by presenting the
design and development of a new hardware-in-the-loop (HIL) experimental testbed
utilized to emulate ISAM. This emulation will be accomplished by means of a
6-DOF UR3e robotic arm attached to a satellite bus. This satellite bus is
mounted to a 1-DOF guide-rail system, en- abling the satellite bus and robotic
arm to move freely in one linear direction. This experimental ISAM emulation
system will explore and validate models for space motion, serial robot
manipulation, and contact mechanics.

</details>


### [144] [VLA-0: Building State-of-the-Art VLAs with Zero Modification](https://arxiv.org/abs/2510.13054)
*Ankit Goyal,Hugo Hadfield,Xuning Yang,Valts Blukis,Fabio Ramos*

Main category: cs.RO

TL;DR: VLA-0是一种简单但高效的视觉-语言-动作模型设计，通过直接使用文本表示动作，在性能上超越了更复杂的模型。


<details>
  <summary>Details</summary>
Motivation: 当前构建视觉-语言-动作模型（VLA）的方法通常过于复杂，而直接使用文本表示动作的简单策略尚未被充分探索。

Method: 通过直接使用文本来表示动作，避免了复杂的修改或特殊动作头的引入。

Result: VLA-0在LIBERO基准测试中超越了所有现有方法，包括那些需要大规模机器人数据训练的方法，并在实际应用中表现优异。

Conclusion: VLA-0，一种将动作直接表示为文本的简单方法，不仅有效，而且表现出色，超越了更复杂的模型设计。

Abstract: Vision-Language-Action models (VLAs) hold immense promise for enabling
generalist robot manipulation. However, the best way to build them remains an
open question. Current approaches often add complexity, such as modifying the
existing vocabulary of a Vision-Language Model (VLM) with action tokens or
introducing special action heads. Curiously, the simplest strategy of
representing actions directly as text has remained largely unexplored. This
work introduces VLA-0 to investigate this idea. We find that VLA-0 is not only
effective; it is surprisingly powerful. With the right design, VLA-0
outperforms more involved models. On LIBERO, a popular benchmark for evaluating
VLAs, VLA-0 outperforms all existing methods trained on the same robotic data,
including $\pi_0.5$-KI, OpenVLA-OFT and SmolVLA. Furthermore, without
large-scale robotics-specific training, it outperforms methods trained on
large-scale robotic data, like $\pi_0.5$-KI, $\pi_0$, GR00T-N1 and MolmoAct.
These findings also translate to the real world, where VLA-0 outperforms
SmolVLA, a VLA model pre-trained on large-scale real data. This paper
summarizes our unexpected findings and spells out the specific techniques
required to unlock the high performance of this simple yet potent VLA design.
Visual results, code, and trained models are provided here:
https://vla0.github.io/.

</details>


### [145] [RoboHiMan: A Hierarchical Evaluation Paradigm for Compositional Generalization in Long-Horizon Manipulation](https://arxiv.org/abs/2510.13149)
*Yangtao Chen,Zixuan Chen,Nga Teng Chan,Junting Chen,Junhui Yin,Jieqi Shi,Yang Gao,Yong-Lu Li,Jing Huo*

Main category: cs.RO

TL;DR: RoboHiMan 是一个层次化评估范式，用于系统研究长时程操作中的组合泛化和鲁棒性，揭示了当前模型的局限性并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 解决机器人灵活调度和组合学习技能以应对复杂扰动的挑战，并填补现有基准在组合泛化、鲁棒性和规划-执行交互方面的不足。

Method: 提出了 RoboHiMan，包括 HiMan-Bench 基准测试、多级训练数据集和三种评估范式（vanilla、decoupled、coupled）。

Result: 实验表明，当前模型在组合泛化和鲁棒性方面存在明显能力差距。

Conclusion: RoboHiMan 作为一个层次化评估范式，揭示了当前模型在长时程操作任务中的能力差距，并指出了改进方向。

Abstract: Enabling robots to flexibly schedule and compose learned skills for novel
long-horizon manipulation under diverse perturbations remains a core challenge.
Early explorations with end-to-end VLA models show limited success, as these
models struggle to generalize beyond the training distribution. Hierarchical
approaches, where high-level planners generate subgoals for low-level policies,
bring certain improvements but still suffer under complex perturbations,
revealing limited capability in skill composition. However, existing benchmarks
primarily emphasize task completion in long-horizon settings, offering little
insight into compositional generalization, robustness, and the interplay
between planning and execution. To systematically investigate these gaps, we
propose RoboHiMan, a hierarchical evaluation paradigm for compositional
generalization in long-horizon manipulation. RoboHiMan introduces HiMan-Bench,
a benchmark of atomic and compositional tasks under diverse perturbations,
supported by a multi-level training dataset for analyzing progressive data
scaling, and proposes three evaluation paradigms (vanilla, decoupled, coupled)
that probe the necessity of skill composition and reveal bottlenecks in
hierarchical architectures. Experiments highlight clear capability gaps across
representative models and architectures, pointing to directions for advancing
models better suited to real-world long-horizon manipulation tasks. Videos and
open-source code can be found on our project website:
https://chenyt31.github.io/robo-himan.github.io/.

</details>


### [146] [ALOHA2 Robot Kitchen Application Scenario Reproduction Report](https://arxiv.org/abs/2510.13284)
*Haoyang Wu,Siheng Wu,William X. Liu,Fangui Zeng*

Main category: cs.RO

TL;DR: ALOHA2是ALOHA的升级版，性能更强、更耐用，且更符合人体工学，适合远程操作。


<details>
  <summary>Details</summary>
Motivation: 提升ALOHA的性能和鲁棒性，同时优化人体工程学设计。

Method: ALOHA2由两个夹持器、两个ViperX 6-DoF手臂和两个较小的WidowX手臂组成，用户通过后驱操作控制机械臂。设备配备多视角摄像头，用于RGB数据收集。

Result: ALOHA2实现了更高性能和鲁棒性，并改善了用户体验。

Conclusion: ALOHA2是ALOHA的增强版，具有更高性能和鲁棒性，同时更符合人体工程学。

Abstract: ALOHA2 is an enhanced version of the dual-arm teleoperated robot ALOHA,
featuring higher performance and robustness compared to the original design,
while also being more ergonomic. Like ALOHA, ALOHA2 consists of two grippers
and two ViperX 6-DoF arms, as well as two smaller WidowX arms. Users control
the follower mechanical arms by operating the leader mechanical arms through
back-driving. The device also includes cameras that generate images from
multiple viewpoints, allowing for RGB data collection during teleoperation. The
robot is mounted on a 48-inch x 30-inch table, equipped with an aluminum frame
that provides additional mounting points for cameras and gravity compensation
systems.

</details>


### [147] [DAMM-LOAM: Degeneracy Aware Multi-Metric LiDAR Odometry and Mapping](https://arxiv.org/abs/2510.13287)
*Nishant Chandna,Akshat Kaushal*

Main category: cs.RO

TL;DR: DAMM-LOAM通过点云分类和退化感知ICP算法，提升了LiDAR SLAM在稀疏和重复结构环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 当前点对平面ICP算法在特征稀疏、重复几何结构和高频运动场景中表现不佳，导致6自由度姿态估计退化。为了解决这一问题，提出了DAMM-LOAM模块。

Method: 提出了一种基于表面法线和邻域分析的点云分类方法，将点分为地面、墙壁、屋顶、边缘和非平面点，并应用退化感知的加权最小二乘ICP算法进行里程计估计。后端采用Scan Context实现鲁棒的回环检测。

Result: DAMM-LOAM在室内环境（如长走廊）中显著提高了里程计精度。

Conclusion: DAMM-LOAM模块通过点云分类和退化感知的加权最小二乘ICP算法，显著提高了SLAM系统在稀疏特征和重复几何结构环境中的定位和建图精度。

Abstract: LiDAR Simultaneous Localization and Mapping (SLAM) systems are essential for
enabling precise navigation and environmental reconstruction across various
applications. Although current point-to-plane ICP algorithms perform effec-
tively in structured, feature-rich environments, they struggle in scenarios
with sparse features, repetitive geometric structures, and high-frequency
motion. This leads to degeneracy in 6- DOF pose estimation. Most
state-of-the-art algorithms address these challenges by incorporating
additional sensing modalities, but LiDAR-only solutions continue to face
limitations under such conditions. To address these issues, we propose a novel
Degeneracy-Aware Multi-Metric LiDAR Odometry and Map- ping (DAMM-LOAM) module.
Our system improves mapping accuracy through point cloud classification based
on surface normals and neighborhood analysis. Points are classified into
ground, walls, roof, edges, and non-planar points, enabling accurate
correspondences. A Degeneracy-based weighted least squares-based ICP algorithm
is then applied for accurate odom- etry estimation. Additionally, a Scan
Context based back-end is implemented to support robust loop closures.
DAMM-LOAM demonstrates significant improvements in odometry accuracy,
especially in indoor environments such as long corridors

</details>


### [148] [Tactile-Conditioned Diffusion Policy for Force-Aware Robotic Manipulation](https://arxiv.org/abs/2510.13324)
*Erik Helmut,Niklas Funk,Tim Schneider,Cristiana de Farias,Jan Peters*

Main category: cs.RO

TL;DR: FARM是一个模仿学习框架，通过整合高维触觉数据推断触觉条件化的力信号，定义基于力的动作空间，在多种力需求任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 接触丰富的操作任务需要在整个操作过程中施加正确的抓取力，尤其是处理易碎或可变形物体时。现有模仿学习方法通常仅将视觉触觉反馈作为额外观察，未控制施加的力。

Method: 提出了Force-Aware Robotic Manipulation (FARM)模仿学习框架，整合高维触觉数据推断触觉条件化的力信号，并定义基于力的动作空间。使用改进的UMI夹持器和GelSight Mini视觉触觉传感器收集人类演示数据。

Result: FARM在三个具有不同力需求的任务（高力、低力和动态力适应）中表现优于多个基线方法。

Conclusion: FARM框架通过整合高维触觉数据成功推断触觉条件化的力信号，并定义了基于力的动作空间，在具有不同力需求的任务中表现优于多个基线方法。

Abstract: Contact-rich manipulation depends on applying the correct grasp forces
throughout the manipulation task, especially when handling fragile or
deformable objects. Most existing imitation learning approaches often treat
visuotactile feedback only as an additional observation, leaving applied forces
as an uncontrolled consequence of gripper commands. In this work, we present
Force-Aware Robotic Manipulation (FARM), an imitation learning framework that
integrates high-dimensional tactile data to infer tactile-conditioned force
signals, which in turn define a matching force-based action space. We collect
human demonstrations using a modified version of the handheld Universal
Manipulation Interface (UMI) gripper that integrates a GelSight Mini visual
tactile sensor. For deploying the learned policies, we developed an actuated
variant of the UMI gripper with geometry matching our handheld version. During
policy rollouts, the proposed FARM diffusion policy jointly predicts robot
pose, grip width, and grip force. FARM outperforms several baselines across
three tasks with distinct force requirements -- high-force, low-force, and
dynamic force adaptation -- demonstrating the advantages of its two key
components: leveraging force-grounded, high-dimensional tactile observations
and a force-based control space. The codebase and design files are open-sourced
and available at https://tactile-farm.github.io .

</details>


### [149] [MODUR: A Modular Dual-reconfigurable Robot](https://arxiv.org/abs/2510.13356)
*Jie Gu,Tin Lun Lam,Chunxu Tian,Zhihao Xia,Yongheng Xing,Dan Zhang*

Main category: cs.RO

TL;DR: MODUR是一种新型模块化自重构机器人，具备双级重构能力，设计紧凑，实验验证了其运动性能。


<details>
  <summary>Details</summary>
Motivation: 提升模块化自重构机器人系统的适应性和鲁棒性，通过双级重构能力整合可重构机制。

Method: MODUR采用紧凑连接器和剪刀连杆组设计，形成平行机构，实现连接器运动解耦和相邻位置迁移能力。

Result: MODUR成功实现了模块间高级自重构和模块内部形状变化，其工作空间分析为基本运动设计提供了理论基础。

Conclusion: MODUR的模块化自重构机器人系统通过实验验证了其运动能力，展示了双级重构设计的有效性。

Abstract: Modular Self-Reconfigurable Robot (MSRR) systems are a class of robots
capable of forming higher-level robotic systems by altering the topological
relationships between modules, offering enhanced adaptability and robustness in
various environments. This paper presents a novel MSRR called MODUR, featuring
dual-level reconfiguration capabilities designed to integrate reconfigurable
mechanisms into MSRR. Specifically, MODUR can perform high-level
self-reconfiguration among modules to create different configurations, while
each module is also able to change its shape to execute basic motions. The
design of MODUR primarily includes a compact connector and scissor linkage
groups that provide actuation, forming a parallel mechanism capable of
achieving both connector motion decoupling and adjacent position migration
capabilities. Furthermore, the workspace, considering the interdependent
connectors, is comprehensively analyzed, laying a theoretical foundation for
the design of the module's basic motion. Finally, the motion of MODUR is
validated through a series of experiments.

</details>


### [150] [Adversarial Fine-tuning in Offline-to-Online Reinforcement Learning for Robust Robot Control](https://arxiv.org/abs/2510.13358)
*Shingo Ayabe,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.RO

TL;DR: 该研究提出了一种离线到在线框架，通过对抗性微调提升策略鲁棒性，实验证明其在连续控制任务中优于纯离线基线，且收敛更快。


<details>
  <summary>Details</summary>
Motivation: 离线强化学习虽能高效获取策略，但在静态数据集上训练的策略对动作空间扰动（如执行器故障）仍显脆弱。本研究旨在通过对抗性微调提升策略的鲁棒性。

Method: 研究提出了一种离线到在线的框架，首先在清洁数据上训练策略，然后进行对抗性微调，通过注入扰动到执行动作中诱导补偿行为。此外，采用性能感知课程进一步调整训练中的扰动概率，通过指数移动平均信号平衡鲁棒性和稳定性。

Result: 在连续控制运动任务上的实验表明，该方法比纯离线基线更鲁棒，比从头训练收敛更快。匹配微调与评估条件可获得最强的鲁棒性，而自适应课程策略减轻了线性课程策略中观察到的名义性能下降。

Conclusion: 对抗性微调框架通过结合离线数据的高效利用和在线微调的适应性，成功提升了策略在不确定环境下的鲁棒性，填补了离线效率与在线适应性之间的鸿沟。

Abstract: Offline reinforcement learning enables sample-efficient policy acquisition
without risky online interaction, yet policies trained on static datasets
remain brittle under action-space perturbations such as actuator faults. This
study introduces an offline-to-online framework that trains policies on clean
data and then performs adversarial fine-tuning, where perturbations are
injected into executed actions to induce compensatory behavior and improve
resilience. A performance-aware curriculum further adjusts the perturbation
probability during training via an exponential-moving-average signal, balancing
robustness and stability throughout the learning process. Experiments on
continuous-control locomotion tasks demonstrate that the proposed method
consistently improves robustness over offline-only baselines and converges
faster than training from scratch. Matching the fine-tuning and evaluation
conditions yields the strongest robustness to action-space perturbations, while
the adaptive curriculum strategy mitigates the degradation of nominal
performance observed with the linear curriculum strategy. Overall, the results
show that adversarial fine-tuning enables adaptive and robust control under
uncertain environments, bridging the gap between offline efficiency and online
adaptability.

</details>


### [151] [Real-Time Knee Angle Prediction Using EMG and Kinematic Data with an Attention-Based CNN-LSTM Network and Transfer Learning Across Multiple Datasets](https://arxiv.org/abs/2510.13443)
*Mojtaba Mollahossein,Gholamreza Vossoughi,Mohammad Hossein Rohban*

Main category: cs.RO

TL;DR: A transfer-learning framework using a lightweight CNN-LSTM model improves knee joint angle prediction from EMG signals, achieving low error rates across diverse datasets and conditions.


<details>
  <summary>Details</summary>
Motivation: Existing EMG-based ML and DL methods face challenges like limited real-time applicability, non-representative test conditions, and the need for large datasets. This paper aims to address these issues with a transfer-learning approach.

Method: A lightweight attention-based CNN-LSTM model was developed and pre-trained on the Georgia Tech dataset, then transferred to the UCI and SMLE datasets. The framework requires only a few gait cycles from new subjects.

Result: The model achieved NMAE of 6.8% and 13.7% for one-step and 50-step predictions on abnormal subjects using EMG alone. Incorporating historical knee angles reduced NMAE further, and adaptation to SMLE exoskeleton with additional inputs achieved even lower errors (1.09% and 3.1%).

Conclusion: The proposed transfer-learning framework demonstrates robust performance and strong generalization for both short- and long-term rehabilitation scenarios, achieving low Normalized Mean Absolute Errors (NMAE) across different datasets and conditions.

Abstract: Electromyography (EMG) signals are widely used for predicting body joint
angles through machine learning (ML) and deep learning (DL) methods. However,
these approaches often face challenges such as limited real-time applicability,
non-representative test conditions, and the need for large datasets to achieve
optimal performance. This paper presents a transfer-learning framework for knee
joint angle prediction that requires only a few gait cycles from new subjects.
Three datasets - Georgia Tech, the University of California Irvine (UCI), and
the Sharif Mechatronic Lab Exoskeleton (SMLE) - containing four EMG channels
relevant to knee motion were utilized. A lightweight attention-based CNN-LSTM
model was developed and pre-trained on the Georgia Tech dataset, then
transferred to the UCI and SMLE datasets. The proposed model achieved
Normalized Mean Absolute Errors (NMAE) of 6.8 percent and 13.7 percent for
one-step and 50-step predictions on abnormal subjects using EMG inputs alone.
Incorporating historical knee angles reduced the NMAE to 3.1 percent and 3.5
percent for normal subjects, and to 2.8 percent and 7.5 percent for abnormal
subjects. When further adapted to the SMLE exoskeleton with EMG, kinematic, and
interaction force inputs, the model achieved 1.09 percent and 3.1 percent NMAE
for one- and 50-step predictions, respectively. These results demonstrate
robust performance and strong generalization for both short- and long-term
rehabilitation scenarios.

</details>


### [152] [Bridge the Gap: Enhancing Quadruped Locomotion with Vertical Ground Perturbations](https://arxiv.org/abs/2510.13488)
*Maximilian Stasica,Arne Bick,Nico Bohlinger,Omid Mohseni,Max Johannes Alois Fritzsche,Clemens Hübler,Jan Peters,André Seyfarth*

Main category: cs.RO

TL;DR: 通过强化学习在振荡桥梁上训练四足机器人，显著提升了其在动态地面扰动下的稳定性和适应性，展示了模拟训练在机器人运动优化中的潜力。


<details>
  <summary>Details</summary>
Motivation: 四足机器人（尤其是四足机器人）在崎岖地形上表现出色，但在垂直地面扰动（如振荡表面）下的性能尚未得到充分探索。本研究旨在通过训练Unitree Go2机器人在振荡桥梁上增强其运动稳健性。

Method: 使用MuJoCo模拟中的近端策略优化（PPO）算法进行强化学习（RL），训练了15种不同的运动策略，结合五种步态（小跑、踱步、跳跃、自由和默认）和三种训练条件（刚性桥梁和两种振荡桥梁设置，具有不同的高度调节策略）。通过领域随机化实现了零样本迁移到现实世界的桥梁。

Result: 在振荡桥梁上训练的策略表现出比在刚性表面上训练的策略更高的稳定性和适应性。框架实现了稳健的步态模式，即使机器人未预先接触桥梁。

Conclusion: 研究结果表明，在振荡桥梁上训练的策略比在刚性表面上训练的策略表现出更高的稳定性和适应性。该框架即使在未预先接触桥梁的情况下也能实现稳健的步态模式。这些发现凸显了基于模拟的强化学习在改善四足机器人动态地面扰动下的运动能力方面的潜力，为设计能够穿越振动环境的机器人提供了见解。

Abstract: Legged robots, particularly quadrupeds, excel at navigating rough terrains,
yet their performance under vertical ground perturbations, such as those from
oscillating surfaces, remains underexplored. This study introduces a novel
approach to enhance quadruped locomotion robustness by training the Unitree Go2
robot on an oscillating bridge - a 13.24-meter steel-and-concrete structure
with a 2.0 Hz eigenfrequency designed to perturb locomotion. Using
Reinforcement Learning (RL) with the Proximal Policy Optimization (PPO)
algorithm in a MuJoCo simulation, we trained 15 distinct locomotion policies,
combining five gaits (trot, pace, bound, free, default) with three training
conditions: rigid bridge and two oscillating bridge setups with differing
height regulation strategies (relative to bridge surface or ground). Domain
randomization ensured zero-shot transfer to the real-world bridge. Our results
demonstrate that policies trained on the oscillating bridge exhibit superior
stability and adaptability compared to those trained on rigid surfaces. Our
framework enables robust gait patterns even without prior bridge exposure.
These findings highlight the potential of simulation-based RL to improve
quadruped locomotion during dynamic ground perturbations, offering insights for
designing robots capable of traversing vibrating environments.

</details>


### [153] [A Novel Robot Hand with Hoeckens Linkages and Soft Phalanges for Scooping and Self-Adaptive Grasping in Environmental Constraints](https://arxiv.org/abs/2510.13535)
*Wentao Guo,Yizhou Wang,Wenzeng Zhang*

Main category: cs.RO

TL;DR: Hockens-A Hand是一种新型欠驱动自适应机器人手，通过集成Hoeckens机构、双平行四边形连杆和专用四连杆机构，实现了三种自适应抓取模式。实验验证了其设计的有效性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种新型欠驱动自适应机器人手，能够在非结构化环境中实现适应性抓取。

Method: 研究采用了详细的运动学分析来优化推角和设计连杆长度，并通过仿真验证了指尖运动和抓取模式之间的平滑过渡。此外，使用功率方程分析了抓取力以增强对系统性能的理解。

Result: 实验验证表明，Hockens-A Hand能够在各种场景下实现平行捏取、非对称舀取和包裹抓取三种模式，表现出良好的抓取稳定性和适用性。

Conclusion: 该研究通过实验验证了Hockens-A Hand的三种抓取模式在各种环境约束下的稳定性和广泛适用性，证明了其设计的有效性。

Abstract: This paper presents a novel underactuated adaptive robotic hand, Hockens-A
Hand, which integrates the Hoeckens mechanism, a double-parallelogram linkage,
and a specialized four-bar linkage to achieve three adaptive grasping modes:
parallel pinching, asymmetric scooping, and enveloping grasping. Hockens-A Hand
requires only a single linear actuator, leveraging passive mechanical
intelligence to ensure adaptability and compliance in unstructured
environments. Specifically, the vertical motion of the Hoeckens mechanism
introduces compliance, the double-parallelogram linkage ensures line contact at
the fingertip, and the four-bar amplification system enables natural
transitions between different grasping modes. Additionally, the inclusion of a
mesh-textured silicone phalanx further enhances the ability to envelop objects
of various shapes and sizes. This study employs detailed kinematic analysis to
optimize the push angle and design the linkage lengths for optimal performance.
Simulations validated the design by analyzing the fingertip motion and ensuring
smooth transitions between grasping modes. Furthermore, the grasping force was
analyzed using power equations to enhance the understanding of the system's
performance.Experimental validation using a 3D-printed prototype demonstrates
the three grasping modes of the hand in various scenarios under environmental
constraints, verifying its grasping stability and broad applicability.

</details>


### [154] [Hoecken-D Hand: A Novel Robotic Hand for Linear Parallel Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.13553)
*Wentao Guo,Wenzeng Zhang*

Main category: cs.RO

TL;DR: Hoecken-D Hand是一种新型机械抓手，结合改进的Hoecken连杆和差动弹簧机制，实现线性夹持和自适应包裹，适用于非结构化环境。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够在非结构化环境中可靠抓取不规则或薄物体的机械抓手，同时减少执行器数量和复杂性。

Method: 通过改进Hoecken连杆和引入差动弹簧机制，实现了线性平行夹持和自适应包裹的过渡。采用双平行四边形保持指尖平行，差动机制允许手指在遇到障碍时向内包裹。

Result: 原型通过PLA 3D打印制造，线性夹持范围约200毫米，初步测试显示在各种物体几何形状下都能可靠抓取。

Conclusion: Hoecken-D Hand是一种紧凑、适应性强且成本效益高的机械抓手，适用于非结构化环境中的操作。

Abstract: This paper presents the Hoecken-D Hand, an underactuated robotic gripper that
combines a modified Hoecken linkage with a differential spring mechanism to
achieve both linear parallel pinching and a mid-stroke transition to adaptive
envelope. The original Hoecken linkage is reconfigured by replacing one member
with differential links, preserving straight-line guidance while enabling
contact-triggered reconfiguration without additional actuators. A
double-parallelogram arrangement maintains fingertip parallelism during
conventional pinching, whereas the differential mechanism allows one finger to
wrap inward upon encountering an obstacle, improving stability on irregular or
thin objects. The mechanism can be driven by a single linear actuator,
minimizing complexity and cost; in our prototype, each finger is driven by its
own linear actuator for simplicity. We perform kinematic modeling and force
analysis to characterize grasp performance, including simulated grasping forces
and spring-opening behavior under varying geometric parameters. The design was
prototyped using PLA-based 3D printing, achieving a linear pinching span of
approximately 200 mm. Preliminary tests demonstrate reliable grasping in both
modes across a wide range of object geometries, highlighting the Hoecken-D Hand
as a compact, adaptable, and cost-effective solution for manipulation in
unstructured environments.

</details>


### [155] [Development of an Intuitive GUI for Non-Expert Teleoperation of Humanoid Robots](https://arxiv.org/abs/2510.13594)
*Austin Barret,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 研究开发了一个为非专家设计的直观GUI，用于控制人形机器人通过障碍课程，结合了UI和HRI的最佳实践。


<details>
  <summary>Details</summary>
Motivation: 当前许多人形机器人系统缺乏为非专家操作者设计的图形用户界面（GUI），这限制了其实际应用。

Method: 结合用户界面开发（UI）的常见实践以及人机交互（HRI）等相关概念，开发了一个新的界面。

Result: 开发了一个简单直观的GUI，使非专家操作者能够有效控制机器人。

Conclusion: 该研究成功开发了一个针对非专家操作者的可扩展且直观的GUI，用于控制人形机器人通过FIRA规定的障碍课程。

Abstract: The operation of humanoid robotics is an essential field of research with
many practical and competitive applications. Many of these systems, however, do
not invest heavily in developing a non-expert-centered graphical user interface
(GUI) for operation. The focus of this research is to develop a scalable GUI
that is tailored to be simple and intuitive so non-expert operators can control
the robot through a FIRA-regulated obstacle course. Using common practices from
user interface development (UI) and understanding concepts described in
human-robot interaction (HRI) and other related concepts, we will develop a new
interface with the goal of a non-expert teleoperation system.

</details>


### [156] [Active Tactile Exploration for Rigid Body Pose and Shape Estimation](https://arxiv.org/abs/2510.13595)
*Ethan K. Gordon,Bruke Baraki,Hien Bui,Michael Posa*

Main category: cs.RO

TL;DR: 提出了一种仅使用触觉数据的学习和探索框架，通过优化物理约束违反的损失函数，快速学习刚性物体的形状和位置，显著提升模拟和真实机器人实验中的学习效率。


<details>
  <summary>Details</summary>
Motivation: 通用机器人操作需要处理先前未见过的物体。在测试时学习物理精确模型可以在数据效率、可预测性和任务间重用方面提供显著优势。触觉感知可以补充视觉，因其对遮挡具有鲁棒性，但其时间稀疏性需要仔细的在线探索以保持数据效率。直接接触还可能导致不受约束的物体移动，需要同时进行形状和位置估计。

Method: 基于接触丰富的系统识别的最新进展，构建了一个损失函数，该函数在不引入刚体接触固有数值刚度的情况下惩罚物理约束违反。优化此损失函数，可以在首次接触后使用少于10秒的随机收集数据学习立方体和凸多面体几何形状。探索方案旨在最大化预期信息增益。

Result: 该方法能够在模拟和真实机器人实验中显著加快学习速度，尤其是在使用少于10秒的随机收集数据后，能够学习立方体和凸多面体几何形状。

Conclusion: 本研究提出了一种仅使用触觉数据的学习和探索框架，能够以最少的机器人运动同时确定刚性物体的形状和位置。该方法在模拟和真实机器人实验中均显示出显著的学习速度提升。

Abstract: General robot manipulation requires the handling of previously unseen
objects. Learning a physically accurate model at test time can provide
significant benefits in data efficiency, predictability, and reuse between
tasks. Tactile sensing can compliment vision with its robustness to occlusion,
but its temporal sparsity necessitates careful online exploration to maintain
data efficiency. Direct contact can also cause an unrestrained object to move,
requiring both shape and location estimation. In this work, we propose a
learning and exploration framework that uses only tactile data to
simultaneously determine the shape and location of rigid objects with minimal
robot motion. We build on recent advances in contact-rich system identification
to formulate a loss function that penalizes physical constraint violation
without introducing the numerical stiffness inherent in rigid-body contact.
Optimizing this loss, we can learn cuboid and convex polyhedral geometries with
less than 10s of randomly collected data after first contact. Our exploration
scheme seeks to maximize Expected Information Gain and results in significantly
faster learning in both simulated and real-robot experiments. More information
can be found at https://dairlab.github.io/activetactile

</details>


### [157] [PlanarMesh: Building Compact 3D Meshes from LiDAR using Incremental Adaptive Resolution Reconstruction](https://arxiv.org/abs/2510.13599)
*Jiahao Wang,Nived Chebrolu,Yifu Tao,Lintong Zhang,Ayoung Kim,Maurice Fallon*

Main category: cs.RO

TL;DR: PlanarMesh 是一种实时LiDAR重建系统，通过自适应网格分辨率实现高效详细重建，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 在线3D LiDAR映射系统需要在保持计算效率的同时实现详细的表面重建，这是一项具有挑战性的任务。

Method: PlanarMesh 结合了平面建模和网格化技术，采用多线程架构和BVH数据结构，支持实时增量更新。

Result: 实验结果表明，PlanarMesh 在重建精度上达到或超过了现有技术，同时输出文件大小显著减小（比原始输入小10倍，比基于网格的方法小5倍以上），并保持实时性能（约2 Hz）。

Conclusion: PlanarMesh 是一种高效、实时的LiDAR重建系统，通过自适应调整网格分辨率，实现了紧凑且详细的表面重建，其性能优于现有技术。

Abstract: Building an online 3D LiDAR mapping system that produces a detailed surface
reconstruction while remaining computationally efficient is a challenging task.
In this paper, we present PlanarMesh, a novel incremental, mesh-based LiDAR
reconstruction system that adaptively adjusts mesh resolution to achieve
compact, detailed reconstructions in real-time. It introduces a new
representation, planar-mesh, which combines plane modeling and meshing to
capture both large surfaces and detailed geometry. The planar-mesh can be
incrementally updated considering both local surface curvature and free-space
information from sensor measurements. We employ a multi-threaded architecture
with a Bounding Volume Hierarchy (BVH) for efficient data storage and fast
search operations, enabling real-time performance. Experimental results show
that our method achieves reconstruction accuracy on par with, or exceeding,
state-of-the-art techniques-including truncated signed distance functions,
occupancy mapping, and voxel-based meshing-while producing smaller output file
sizes (10 times smaller than raw input and more than 5 times smaller than
mesh-based methods) and maintaining real-time performance (around 2 Hz for a
64-beam sensor).

</details>


### [158] [Efficient Force and Stiffness Prediction in Robotic Produce Handling with a Piezoresistive Pressure Sensor](https://arxiv.org/abs/2510.13616)
*Preston Fairchild,Claudia Chen,Xiaobo Tan*

Main category: cs.RO

TL;DR: 研究开发了一种低成本柔性压力传感器，集成到机器人夹持器中，实现了对农产品的精准抓取和成熟度估计，为农业自动化提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 自动化在农业收获和加工中的未来角色需要机器人能够精准抓取易损农产品，而合适的抓取力度不仅确保抓取稳定性，还能避免产品损伤。

Method: 研究将柔性压力传感器集成到刚性机器人夹持器和气动软指中，并提出了一种基于瞬态响应数据的算法，用于加速估计传感器输出的稳态值，以实现实时应用。

Result: 传感器成功实现了对未知大小和硬度物体的精准抓取，并能估计成熟度和损伤情况，同时为可变硬度物体提供力反馈。

Conclusion: 该研究成功开发了一种低成本、易制造的柔性压力传感器，并将其集成到机器人夹持器中，有效实现了对不同形状、大小和硬度的农产品的精准抓取。传感器不仅能提供实时反馈，还能估计农产品的成熟度和损伤情况，为未来的质量控制和选择性分配提供了可能。

Abstract: Properly handling delicate produce with robotic manipulators is a major part
of the future role of automation in agricultural harvesting and processing.
Grasping with the correct amount of force is crucial in not only ensuring
proper grip on the object, but also to avoid damaging or bruising the product.
In this work, a flexible pressure sensor that is both low cost and easy to
fabricate is integrated with robotic grippers for working with produce of
varying shapes, sizes, and stiffnesses. The sensor is successfully integrated
with both a rigid robotic gripper, as well as a pneumatically actuated soft
finger. Furthermore, an algorithm is proposed for accelerated estimation of the
steady-state value of the sensor output based on the transient response data,
to enable real-time applications. The sensor is shown to be effective in
incorporating feedback to correctly grasp objects of unknown sizes and
stiffnesses. At the same time, the sensor provides estimates for these values
which can be utilized for identification of qualities such as ripeness levels
and bruising. It is also shown to be able to provide force feedback for objects
of variable stiffnesses. This enables future use not only for produce
identification, but also for tasks such as quality control and selective
distribution based on ripeness levels.

</details>


### [159] [Characterizing Lidar Point-Cloud Adversities Using a Vector Field Visualization](https://arxiv.org/abs/2510.13619)
*Daniel Choate,Jason Rife*

Main category: cs.RO

TL;DR: 提出了一种离线可视化方法，通过向量场图帮助分析师识别和消除激光雷达扫描匹配中的逆境模式，并在仿真和实验中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助分析师更直观地识别和理解激光雷达扫描匹配中的逆境模式，这些模式在原始点云数据中难以直接提取。

Method: 提出了一种离线分析的可视化方法，通过生成向量场图来表征已配准点云对之间的局部差异。

Result: 在两个概念验证案例（仿真研究和现场实验）中，分析师能够推理并逐步消除逆境机制，从而聚焦于更小的差异。

Conclusion: 该方法通过可视化手段有效帮助分析师识别并逐步消除影响激光雷达扫描匹配的逆境模式，提升了数据分析的效率和准确性。

Abstract: In this paper we introduce a visualization methodology to aid a human analyst
in classifying adversity modes that impact lidar scan matching. Our methodology
is intended for offline rather than real-time analysis. The method generates a
vector-field plot that characterizes local discrepancies between a pair of
registered point clouds. The vector field plot reveals patterns that would be
difficult for the analyst to extract from raw point-cloud data. After
introducing our methodology, we apply the process to two proof-of-concept
examples: one a simulation study and the other a field experiment. For both
data sets, a human analyst was able to reason about a series of adversity
mechanisms and iteratively remove those mechanisms from the raw data, to help
focus attention on progressively smaller discrepancies.

</details>


### [160] [A Modular Object Detection System for Humanoid Robots Using YOLO](https://arxiv.org/abs/2510.13625)
*Nicolas Pottier,Meng Cheng Lau*

Main category: cs.RO

TL;DR: 研究提出基于YOLOv9的通用视觉模块，在机器人环境中实现高效视觉系统，性能与几何模型相当但计算成本更高，鲁棒性更强。


<details>
  <summary>Details</summary>
Motivation: 机器人领域中的计算机视觉仍然是进展的重要障碍，许多任务因低效的视觉系统而受阻。

Method: 研究提出了一个基于YOLOv9的通用视觉模块，并在ROS1中使用虚拟环境实现YOLO兼容性。模型在FIRA机器人Hurocup定制数据集上训练，并通过FPS和mAP等指标评估性能。

Result: YOLO模型在静态和动态环境中与现有几何框架相比，实现了相当的精度，但计算成本更高，同时提供了更好的鲁棒性。

Conclusion: YOLOv9模型在计算成本较高的情况下实现了与几何模型相当的精度，同时提供了更强的鲁棒性。

Abstract: Within the field of robotics, computer vision remains a significant barrier
to progress, with many tasks hindered by inefficient vision systems. This
research proposes a generalized vision module leveraging YOLOv9, a
state-of-the-art framework optimized for computationally constrained
environments like robots. The model is trained on a dataset tailored to the
FIRA robotics Hurocup. A new vision module is implemented in ROS1 using a
virtual environment to enable YOLO compatibility. Performance is evaluated
using metrics such as frames per second (FPS) and Mean Average Precision (mAP).
Performance is then compared to the existing geometric framework in static and
dynamic contexts. The YOLO model achieved comparable precision at a higher
computational cost then the geometric model, while providing improved
robustness.

</details>


### [161] [LIBERO-Plus: In-depth Robustness Analysis of Vision-Language-Action Models](https://arxiv.org/abs/2510.13626)
*Senyu Fei,Siyin Wang,Junhao Shi,Zihao Dai,Jikun Cai,Pengfang Qian,Li Ji,Xinzhe He,Shiduo Zhang,Zhaoye Fei,Jinlan Fu,Jingjing Gong,Xipeng Qiu*

Main category: cs.RO

TL;DR: VLA模型在基准测试中表现优异，但实际对多种扰动极度敏感，性能显著下降，尤其是对相机视角和初始状态。模型甚至忽略语言指令，高分不代表真正能力。


<details>
  <summary>Details</summary>
Motivation: 揭示VLA模型在基准测试高分背后的实际脆弱性，挑战高分等同于真正能力的假设。

Method: 通过引入七种维度的受控扰动（如物体布局、相机视角、机器人初始状态等），对多个最先进的VLA模型进行了全面分析。

Result: 模型对相机视角和机器人初始状态等扰动极度敏感，性能从95%降至30%以下；但对语言指令变化不敏感，甚至完全忽略。

Conclusion: 视觉-语言-动作（VLA）模型在基准测试中表现优异，但实际存在严重的鲁棒性问题。通过系统性脆弱性分析，发现模型对多种扰动因素极度敏感，性能显著下降。

Abstract: Visual-Language-Action (VLA) models report impressive success rates on
robotic manipulation benchmarks, yet these results may mask fundamental
weaknesses in robustness. We perform a systematic vulnerability analysis by
introducing controlled perturbations across seven dimensions: objects layout,
camera viewpoints, robot initial states, language instructions, light
conditions, background textures and sensor noise. We comprehensively analyzed
multiple state-of-the-art models and revealed consistent brittleness beneath
apparent competence. Our analysis exposes critical weaknesses: models exhibit
extreme sensitivity to perturbation factors, including camera viewpoints and
robot initial states, with performance dropping from 95% to below 30% under
modest perturbations. Surprisingly, models are largely insensitive to language
variations, with further experiments revealing that models tend to ignore
language instructions completely. Our findings challenge the assumption that
high benchmark scores equate to true competency and highlight the need for
evaluation practices that assess reliability under realistic variation.

</details>


### [162] [On Your Own: Pro-level Autonomous Drone Racing in Uninstrumented Arenas](https://arxiv.org/abs/2510.13644)
*Michael Bosello,Flavio Pinzarrone,Sara Kiade,Davide Aguiari,Yvo Keuter,Aaesha AlShehhi,Gyordan Caminati,Kei Long Wong,Ka Seng Chou,Junaid Halepota,Fares Alneyadi,Jacopo Panerati,Giovanni Pau*

Main category: cs.RO

TL;DR: 无人机自主系统在受控和非受控环境中均能匹配人类飞行员性能，为解决商业应用限制提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 当前无人机自主系统多在高度受控环境中训练和评估，限制了其在商业和实地操作中的直接适用性。

Method: 在受控环境中使用外部跟踪进行真实数据对比，并在非受控环境中验证系统性能。

Result: 系统在受控和非受控环境中均表现出与专业人类飞行员相当的性能。

Conclusion: 研究表明，该方法在受控和非受控环境中均能匹配专业人类飞行员的性能，为无人机自主技术在商业和实地操作中的应用提供了潜在解决方案。

Abstract: Drone technology is proliferating in many industries, including agriculture,
logistics, defense, infrastructure, and environmental monitoring. Vision-based
autonomy is one of its key enablers, particularly for real-world applications.
This is essential for operating in novel, unstructured environments where
traditional navigation methods may be unavailable. Autonomous drone racing has
become the de facto benchmark for such systems. State-of-the-art research has
shown that autonomous systems can surpass human-level performance in racing
arenas. However, direct applicability to commercial and field operations is
still limited as current systems are often trained and evaluated in highly
controlled environments. In our contribution, the system's capabilities are
analyzed within a controlled environment -- where external tracking is
available for ground-truth comparison -- but also demonstrated in a
challenging, uninstrumented environment -- where ground-truth measurements were
never available. We show that our approach can match the performance of
professional human pilots in both scenarios. We also publicly release the data
from the flights carried out by our approach and a world-class human pilot.

</details>


### [163] [Hierarchical Discrete Lattice Assembly: An Approach for the Digital Fabrication of Scalable Macroscale Structures](https://arxiv.org/abs/2510.13686)
*Miana Smith,Paul Arthur Richard,Alexander Htet Kyaw,Neil Gershenfeld*

Main category: cs.RO

TL;DR: 本研究提出了一种使用简单机器人和互锁格子构建块制造可扩展宏观结构的方法，通过实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 尽管桌面规模的数字制造工艺已经成熟且广泛应用，但针对更大规模结构的系统通常复杂、昂贵且不可靠。本研究旨在解决这一问题。

Method: 首先将目标结构体素化，随后将其分组为更大的互连块，使用标准数字制造工艺生产这些块。然后由移动相对机器人将这些块组装成米级结构。引入了一个实时数字孪生模拟工具来控制协调组装机器人，并设计了一种新型模块化组装机器人以提高装配吞吐量。

Result: 通过演示一组米级物体的体素化、分层阻塞、路径规划和机器人制造，验证了该系统的有效性。

Conclusion: 本研究提出了一种利用简单机器人和互锁格子构建块来制造可扩展宏观结构的方法，并通过实验验证了其有效性。

Abstract: Although digital fabrication processes at the desktop scale have become
proficient and prolific, systems aimed at producing larger-scale structures are
still typically complex, expensive, and unreliable. In this work, we present an
approach for the fabrication of scalable macroscale structures using simple
robots and interlocking lattice building blocks. A target structure is first
voxelized so that it can be populated with an architected lattice. These voxels
are then grouped into larger interconnected blocks, which are produced using
standard digital fabrication processes, leveraging their capability to produce
highly complex geometries at a small scale. These blocks, on the size scale of
tens of centimeters, are then fed to mobile relative robots that are able to
traverse over the structure and place new blocks to form structures on the
meter scale. To facilitate the assembly of large structures, we introduce a
live digital twin simulation tool for controlling and coordinating assembly
robots that enables both global planning for a target structure and live user
design, interaction, or intervention. To improve assembly throughput, we
introduce a new modular assembly robot, designed for hierarchical voxel
handling. We validate this system by demonstrating the voxelization,
hierarchical blocking, path planning, and robotic fabrication of a set of
meter-scale objects.

</details>


### [164] [InternVLA-M1: A Spatially Guided Vision-Language-Action Framework for Generalist Robot Policy](https://arxiv.org/abs/2510.13778)
*Xinyi Chen,Yilun Chen,Yanwei Fu,Ning Gao,Jiaya Jia,Weiyang Jin,Hao Li,Yao Mu,Jiangmiao Pang,Yu Qiao,Yang Tian,Bin Wang,Bolun Wang,Fangjing Wang,Hanqing Wang,Tai Wang,Ziqin Wang,Xueyuan Wei,Chao Wu,Shuai Yang,Jinhui Ye,Junqiu Yu,Jia Zeng,Jingjing Zhang,Jinyu Zhang,Shi Zhang,Feng Zheng,Bowen Zhou,Yangkun Zhu*

Main category: cs.RO

TL;DR: InternVLA-M1通过空间引导的视觉-语言-动作训练，显著提升了机器人的指令跟随能力和空间推理性能，证明了其在通用机器人领域的潜力。


<details>
  <summary>Details</summary>
Motivation: 推动指令跟随机器人向可扩展、通用智能方向发展，空间基础作为指令与机器人行动之间的关键桥梁。

Method: 采用两阶段流水线：（i）在超过230万空间推理数据上进行空间基础预训练，以确定“在哪里行动”；（ii）通过即插即用的空间提示进行空间引导的动作后训练，以决定“如何行动”。

Result: 在多个测试平台上表现优于无空间引导的变体，如SimperEnv Google Robot（+14.6%）、WidowX（+17%）和LIBERO Franka（+4.3%），并在真实世界和模拟环境中展示了显著的性能提升。

Conclusion: InternVLA-M1通过空间引导的训练方法，显著提升了指令跟随机器人的性能和泛化能力，证明了空间引导训练作为通用机器人可扩展和弹性统一原则的有效性。

Abstract: We introduce InternVLA-M1, a unified framework for spatial grounding and
robot control that advances instruction-following robots toward scalable,
general-purpose intelligence. Its core idea is spatially guided
vision-language-action training, where spatial grounding serves as the critical
link between instructions and robot actions. InternVLA-M1 employs a two-stage
pipeline: (i) spatial grounding pre-training on over 2.3M spatial reasoning
data to determine ``where to act'' by aligning instructions with visual,
embodiment-agnostic positions, and (ii) spatially guided action post-training
to decide ``how to act'' by generating embodiment-aware actions through
plug-and-play spatial prompting. This spatially guided training recipe yields
consistent gains: InternVLA-M1 outperforms its variant without spatial guidance
by +14.6% on SimplerEnv Google Robot, +17% on WidowX, and +4.3% on LIBERO
Franka, while demonstrating stronger spatial reasoning capability in box,
point, and trace prediction. To further scale instruction following, we built a
simulation engine to collect 244K generalizable pick-and-place episodes,
enabling a 6.2% average improvement across 200 tasks and 3K+ objects. In
real-world clustered pick-and-place, InternVLA-M1 improved by 7.3%, and with
synthetic co-training, achieved +20.6% on unseen objects and novel
configurations. Moreover, in long-horizon reasoning-intensive scenarios, it
surpassed existing works by over 10%. These results highlight spatially guided
training as a unifying principle for scalable and resilient generalist robots.
Code and models are available at
https://github.com/InternRobotics/InternVLA-M1.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [165] [From Literal to Liberal: A Meta-Prompting Framework for Eliciting Human-Aligned Exception Handling in Large Language Models](https://arxiv.org/abs/2510.12864)
*Imran Khan*

Main category: cs.AI

TL;DR: RID Framework improves LLMs' human alignment via zero-shot meta-prompting, achieving 95% HAS.


<details>
  <summary>Details</summary>
Motivation: Address the 'rule-rigidity' flaw in LLMs, which causes misalignment with human common sense, by providing a low-compute alternative to supervised fine-tuning.

Method: The RID Framework, a meta-prompting technique, structures tasks into rules and intents, enabling zero-shot exception handling.

Result: RID achieved a 95% Human Alignment Score, outperforming baseline (80%) and CoT prompting (75%), with higher-quality reasoning.

Conclusion: The RID framework presents a practical and effective method for improving LLMs' alignment with human intent, offering a low-compute solution for more reliable AI agents.

Abstract: Large Language Models (LLMs) are increasingly being deployed as the reasoning
engines for agentic AI systems, yet they exhibit a critical flaw: a rigid
adherence to explicit rules that leads to decisions misaligned with human
common sense and intent. This "rule-rigidity" is a significant barrier to
building trustworthy autonomous agents. While prior work has shown that
supervised fine-tuning (SFT) with human explanations can mitigate this issue,
SFT is computationally expensive and inaccessible to many practitioners. To
address this gap, we introduce the Rule-Intent Distinction (RID) Framework, a
novel, low-compute meta-prompting technique designed to elicit human-aligned
exception handling in LLMs in a zero-shot manner. The RID framework provides
the model with a structured cognitive schema for deconstructing tasks,
classifying rules, weighing conflicting outcomes, and justifying its final
decision. We evaluated the RID framework against baseline and Chain-of-Thought
(CoT) prompting on a custom benchmark of 20 scenarios requiring nuanced
judgment across diverse domains. Our human-verified results demonstrate that
the RID framework significantly improves performance, achieving a 95% Human
Alignment Score (HAS), compared to 80% for the baseline and 75% for CoT.
Furthermore, it consistently produces higher-quality, intent-driven reasoning.
This work presents a practical, accessible, and effective method for steering
LLMs from literal instruction-following to liberal, goal-oriented reasoning,
paving the way for more reliable and pragmatic AI agents.

</details>


### [166] [DeepPlanner: Scaling Planning Capability for Deep Research Agents via Advantage Shaping](https://arxiv.org/abs/2510.12979)
*Wei Fan,Wenlin Yao,Zheng Li,Feng Yao,Xin Liu,Liang Qiu,Qingyu Yin,Yangqiu Song,Bing Yin*

Main category: cs.AI

TL;DR: DeepPlanner通过优化规划令牌的熵和选择性加权样本优势，显著提升LLMs的规划能力，并在低预算下实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在规划阶段缺乏系统性优化，导致规划令牌的熵显著高于其他动作令牌，显示出未优化的决策点。

Method: 提出了DeepPlanner，一个端到端的强化学习框架，通过熵基项塑造令牌级优势，并为规划密集型rollouts选择性加权样本级优势。

Result: 在七个深度研究基准测试中，DeepPlanner提升了规划质量，并在较低训练预算下取得了最先进的成果。

Conclusion: DeepPlanner通过端到端强化学习框架显著提升了深度研究代理的规划能力，并在较低训练预算下实现了最先进的性能。

Abstract: Large language models (LLMs) augmented with multi-step reasoning and action
generation abilities have shown promise in leveraging external tools to tackle
complex tasks that require long-horizon planning. However, existing approaches
either rely on implicit planning in the reasoning stage or introduce explicit
planners without systematically addressing how to optimize the planning stage.
As evidence, we observe that under vanilla reinforcement learning (RL),
planning tokens exhibit significantly higher entropy than other action tokens,
revealing uncertain decision points that remain under-optimized. To address
this, we propose DeepPlanner, an end-to-end RL framework that effectively
enhances the planning capabilities of deep research agents. Our approach shapes
token-level advantage with an entropy-based term to allocate larger updates to
high entropy tokens, and selectively upweights sample-level advantages for
planning-intensive rollouts. Extensive experiments across seven deep research
benchmarks demonstrate that DeepPlanner improves planning quality and achieves
state-of-the-art results under a substantially lower training budget.

</details>


### [167] [SENTINEL: A Multi-Level Formal Framework for Safety Evaluation of LLM-based Embodied Agents](https://arxiv.org/abs/2510.12985)
*Simon Sinong Zhan,Yao Liu,Philip Wang,Zinan Wang,Qineng Wang,Zhian Ruan,Xiangyu Shi,Xinyu Cao,Frank Yang,Kangrui Wang,Huajie Shao,Manling Li,Qi Zhu*

Main category: cs.AI

TL;DR: Sentinel是首个用于形式化评估基于LLM的具身代理在语义、计划和轨迹层面物理安全性的框架，通过时序逻辑和多级验证提供更精确的安全评估。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于启发式规则或主观的LLM判断，无法精确指定状态不变性、时间依赖性和时间约束。Sentinel旨在通过形式化时序逻辑（TL）语义来满足实际安全需求，从而提供更精确和系统的安全评估。

Method: Sentinel采用多级验证管道：（i）在语义层面，将直观的自然语言安全要求形式化为TL公式，并探测LLM代理对这些要求的理解是否与TL公式对齐；（ii）在计划层面，验证LLM代理生成的高级行动计划和子目标是否符合TL公式，以在执行前检测不安全计划；（iii）在轨迹层面，将多个执行轨迹合并为计算树，并针对物理详细的TL规范进行高效验证，以进行最终安全检查。

Result: 在VirtualHome和ALFRED中应用Sentinel，并对多个基于LLM的具身代理进行形式化评估，实验表明Sentinel能够系统地评估代理的安全性，并暴露先前方法忽视的安全违规行为。

Conclusion: Sentinel通过将物理安全基础建立在时序逻辑上，并应用多级验证方法，为系统评估基于LLM的具身代理在物理环境中的安全性提供了严格基础，揭示了先前方法忽视的安全违规行为，并提供了对其失败模式的洞察。

Abstract: We present Sentinel, the first framework for formally evaluating the physical
safety of Large Language Model(LLM-based) embodied agents across the semantic,
plan, and trajectory levels. Unlike prior methods that rely on heuristic rules
or subjective LLM judgments, Sentinel grounds practical safety requirements in
formal temporal logic (TL) semantics that can precisely specify state
invariants, temporal dependencies, and timing constraints. It then employs a
multi-level verification pipeline where (i) at the semantic level, intuitive
natural language safety requirements are formalized into TL formulas and the
LLM agent's understanding of these requirements is probed for alignment with
the TL formulas; (ii) at the plan level, high-level action plans and subgoals
generated by the LLM agent are verified against the TL formulas to detect
unsafe plans before execution; and (iii) at the trajectory level, multiple
execution trajectories are merged into a computation tree and efficiently
verified against physically-detailed TL specifications for a final safety
check. We apply Sentinel in VirtualHome and ALFRED, and formally evaluate
multiple LLM-based embodied agents against diverse safety requirements. Our
experiments show that by grounding physical safety in temporal logic and
applying verification methods across multiple levels, Sentinel provides a
rigorous foundation for systematically evaluating LLM-based embodied agents in
physical environments, exposing safety violations overlooked by previous
methods and offering insights into their failure modes.

</details>


### [168] [From Narratives to Probabilistic Reasoning: Predicting and Interpreting Drivers' Hazardous Actions in Crashes Using Large Language Model](https://arxiv.org/abs/2510.13002)
*Boyou Chen,Gerui Xu,Zifei Wang,Huizhong Guo,Ananna Ahmed,Zhaonan Sun,Zhen Hu,Kaihan Zhang,Shan Bao*

Main category: cs.AI

TL;DR: 研究提出了一种基于微调大型语言模型的框架，用于自动从文本碰撞叙述中推断DHA，提高了分类的有效性和可解释性，性能优于传统机器学习方法。


<details>
  <summary>Details</summary>
Motivation: 车辆碰撞中驾驶员危险行为（DHA）的识别对理解碰撞原因至关重要，但大规模数据库中DHA数据的可靠性受限于不一致且劳动密集型的手动编码实践。

Method: 研究通过微调Llama 3.2 1B模型，利用详细的碰撞叙述数据进行训练，并与传统机器学习分类器（如随机森林、XGBoost、CatBoost和神经网络）进行性能对比。

Result: 微调后的LLM总体准确率达到80%，超越了所有基线模型，并在数据不平衡场景中表现出显著改进。通过概率推理方法，分析模型输出在原始测试集和三种针对性反事实场景中的变化，揭示了不同因素对DHA分类的影响。

Conclusion: 该框架和分析方法为大规模自动化DHA检测提供了稳健且可解释的解决方案，为交通安全分析和干预提供了新机遇。

Abstract: Vehicle crashes involve complex interactions between road users, split-second
decisions, and challenging environmental conditions. Among these, two-vehicle
crashes are the most prevalent, accounting for approximately 70% of roadway
crashes and posing a significant challenge to traffic safety. Identifying
Driver Hazardous Action (DHA) is essential for understanding crash causation,
yet the reliability of DHA data in large-scale databases is limited by
inconsistent and labor-intensive manual coding practices. Here, we present an
innovative framework that leverages a fine-tuned large language model to
automatically infer DHAs from textual crash narratives, thereby improving the
validity and interpretability of DHA classifications. Using five years of
two-vehicle crash data from MTCF, we fine-tuned the Llama 3.2 1B model on
detailed crash narratives and benchmarked its performance against conventional
machine learning classifiers, including Random Forest, XGBoost, CatBoost, and a
neural network. The fine-tuned LLM achieved an overall accuracy of 80%,
surpassing all baseline models and demonstrating pronounced improvements in
scenarios with imbalanced data. To increase interpretability, we developed a
probabilistic reasoning approach, analyzing model output shifts across original
test sets and three targeted counterfactual scenarios: variations in driver
distraction and age. Our analysis revealed that introducing distraction for one
driver substantially increased the likelihood of "General Unsafe Driving";
distraction for both drivers maximized the probability of "Both Drivers Took
Hazardous Actions"; and assigning a teen driver markedly elevated the
probability of "Speed and Stopping Violations." Our framework and analytical
methods provide a robust and interpretable solution for large-scale automated
DHA detection, offering new opportunities for traffic safety analysis and
intervention.

</details>


### [169] [Toward Reasoning-Centric Time-Series Analysis](https://arxiv.org/abs/2510.13029)
*Xinlei Wang,Mingtian Tan,Jing Qiu,Junhua Zhao,Jinjin Gu*

Main category: cs.AI

TL;DR: 本文提出利用LLMs的推理能力重新定义时间序列分析，强调因果结构和可解释性，以应对复杂现实环境中的动态变化。


<details>
  <summary>Details</summary>
Motivation: 传统时间序列分析依赖静态基准，难以应对现实世界中的动态变化。LLMs的兴起为整合多模态输入提供了新机会，但现有方法多忽视其深层推理潜力。

Method: 通过重新思考时间序列分析，将其视为优先考虑因果结构和可解释性的推理任务，利用LLMs的多模态输入能力。

Result: 通过将时间序列分析重新定义为推理任务，利用LLMs的因果推理能力，实现了更贴近人类理解的透明和上下文感知分析。

Conclusion: 本文提出将时间序列分析与LLMs结合作为一种推理任务，强调因果结构和可解释性，从而在复杂现实环境中实现透明且上下文感知的洞察。

Abstract: Traditional time series analysis has long relied on pattern recognition,
trained on static and well-established benchmarks. However, in real-world
settings -- where policies shift, human behavior adapts, and unexpected events
unfold -- effective analysis must go beyond surface-level trends to uncover the
actual forces driving them. The recent rise of Large Language Models (LLMs)
presents new opportunities for rethinking time series analysis by integrating
multimodal inputs. However, as the use of LLMs becomes popular, we must remain
cautious, asking why we use LLMs and how to exploit them effectively. Most
existing LLM-based methods still employ their numerical regression ability and
ignore their deeper reasoning potential. This paper argues for rethinking time
series with LLMs as a reasoning task that prioritizes causal structure and
explainability. This shift brings time series analysis closer to human-aligned
understanding, enabling transparent and context-aware insights in complex
real-world environments.

</details>


### [170] [Repairing Reward Functions with Human Feedback to Mitigate Reward Hacking](https://arxiv.org/abs/2510.13036)
*Stephane Hatgis-Kessell,Logan Mondal Bhamidipaty,Emma Brunskill*

Main category: cs.AI

TL;DR: PBRR通过迭代修正代理奖励函数，减少偏好数据需求，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决人类设计的奖励函数与真实目标不一致导致的奖励黑客问题，同时减少从零开始学习奖励函数的高成本。

Method: 提出Preference-Based Reward Repair (PBRR)框架，通过迭代学习一个与状态转移相关的加性修正项来修复代理奖励函数。

Result: PBRR在表格域中具有与现有偏好RL方法相当的累积遗憾，并在奖励黑客基准测试中表现优于基线方法。

Conclusion: PBRR框架通过从人类偏好中学习修正项，显著减少了所需偏好数据量，并在多个基准测试中优于现有方法。

Abstract: Human-designed reward functions for reinforcement learning (RL) agents are
frequently misaligned with the humans' true, unobservable objectives, and thus
act only as proxies. Optimizing for a misspecified proxy reward function often
induces reward hacking, resulting in a policy misaligned with the human's true
objectives. An alternative is to perform RL from human feedback, which involves
learning a reward function from scratch by collecting human preferences over
pairs of trajectories. However, building such datasets is costly. To address
the limitations of both approaches, we propose Preference-Based Reward Repair
(PBRR): an automated iterative framework that repairs a human-specified proxy
reward function by learning an additive, transition-dependent correction term
from preferences. A manually specified reward function can yield policies that
are highly suboptimal under the ground-truth objective, yet corrections on only
a few transitions may suffice to recover optimal performance. To identify and
correct for those transitions, PBRR uses a targeted exploration strategy and a
new preference-learning objective. We prove in tabular domains PBRR has a
cumulative regret that matches, up to constants, that of prior preference-based
RL methods. In addition, on a suite of reward-hacking benchmarks, PBRR
consistently outperforms baselines that learn a reward function from scratch
from preferences or modify the proxy reward function using other approaches,
requiring substantially fewer preferences to learn high performing policies.

</details>


### [171] [Emotional Cognitive Modeling Framework with Desire-Driven Objective Optimization for LLM-empowered Agent in Social Simulation](https://arxiv.org/abs/2510.13195)
*Qun Ma,Xiao Xue,Xuwen Zhang,Zihan Zhao,Yuwei Guo,Ming Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种情感认知框架，通过模拟完整决策过程，显著提升了LLM代理在情感模拟和决策行为上的表现，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在情感认知方面存在局限，无法模拟有限理性，缺乏将情感嵌入代理决策架构的实证验证机制。

Method: 构建了一个包含欲望生成和目标管理的情感认知框架，模拟LLM代理的完整决策过程，包括状态演化、欲望生成、目标优化、决策生成和行动执行。

Result: 实验结果表明，采用该框架的代理不仅行为与情感状态一致，且在生态效度和决策结果近似人类行为模式方面显著优于其他代理类型。

Conclusion: 提出的情感认知框架显著提升了LLM代理在模拟人类情感和决策行为方面的能力，验证了其在生态效度和行为模式近似人类方面的优越性。

Abstract: The advent of large language models (LLMs) has enabled agents to represent
virtual humans in societal simulations, facilitating diverse interactions
within complex social systems. However, existing LLM-based agents exhibit
severe limitations in affective cognition: They fail to simulate the bounded
rationality essential for bridging virtual and real-world services; They lack
empirically validated integration mechanisms embedding emotions within agent
decision architectures. This paper constructs an emotional cognition framework
incorporating desire generation and objective management, designed to achieve
emotion alignment between LLM-based agents and humans, modeling the complete
decision-making process of LLM-based agents, encompassing state evolution,
desire generation, objective optimization, decision generation, and action
execution. This study implements the proposed framework within our proprietary
multi-agent interaction environment. Experimental results demonstrate that
agents governed by our framework not only exhibit behaviors congruent with
their emotional states but also, in comparative assessments against other agent
types, demonstrate superior ecological validity and generate decision outcomes
that significantly more closely approximate human behavioral patterns.

</details>


### [172] [Adaptive Reasoning Executor: A Collaborative Agent System for Efficient Reasoning](https://arxiv.org/abs/2510.13214)
*Zehui Ling,Deshu Chen,Yichi Zhang,Yuchen Liu,Xigui Li,Xin Guo,Yuan Cheng*

Main category: cs.AI

TL;DR: 结合小型和大型LLM的互补代理系统，显著降低计算成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度推理在复杂任务中有显著效果，但全面应用计算成本过高，因此需要一种更高效的方法。

Method: 通过小型LLM生成初始答案，再由大型LLM验证其正确性。若正确则直接采用，否则大型LLM进行深度推理。

Result: 实验结果显示，对于简单问题，该方法将大型LLM的计算成本降低了50%以上，且准确率损失可忽略，同时在复杂任务中保持稳健性能。

Conclusion: 该论文提出了一种结合小型和大型LLM的互补代理系统，有效降低了复杂任务中的计算成本，同时保持了高性能。

Abstract: Recent advances in Large Language Models (LLMs) demonstrate that
chain-of-thought prompting and deep reasoning substantially enhance performance
on complex tasks, and multi-agent systems can further improve accuracy by
enabling model debates. However, applying deep reasoning to all problems is
computationally expensive. To mitigate these costs, we propose a complementary
agent system integrating small and large LLMs. The small LLM first generates an
initial answer, which is then verified by the large LLM. If correct, the answer
is adopted directly; otherwise, the large LLM performs in-depth reasoning.
Experimental results show that, for simple problems, our approach reduces the
computational cost of the large LLM by more than 50% with negligible accuracy
loss, while consistently maintaining robust performance on complex tasks.

</details>


### [173] [Mobile Coverage Analysis using Crowdsourced Data](https://arxiv.org/abs/2510.13459)
*Timothy Wong,Tom Freeman,Joseph Feehily*

Main category: cs.AI

TL;DR: 提出基于OC-SVM的众包数据框架，精准分析移动网络覆盖及薄弱点，提升城市环境QoE。


<details>
  <summary>Details</summary>
Motivation: 移动网络运营商需精准评估覆盖范围和识别服务薄弱点以提升用户QoE。

Method: 利用众包QoE数据，在单个蜂窝级别进行覆盖分析并聚合到站点级别，应用OC-SVM算法建模决策超平面作为有效覆盖轮廓。

Result: 框架成功实现了移动网络覆盖的准确映射，并突出显示了信号缺陷的细粒度区域。

Conclusion: 本研究提出的框架通过OC-SVM算法有效识别移动网络覆盖薄弱区域，尤其在复杂城市环境中表现突出，为运营商提升QoE提供了精确工具。

Abstract: Effective assessment of mobile network coverage and the precise
identification of service weak spots are paramount for network operators
striving to enhance user Quality of Experience (QoE). This paper presents a
novel framework for mobile coverage and weak spot analysis utilising
crowdsourced QoE data. The core of our methodology involves coverage analysis
at the individual cell (antenna) level, subsequently aggregated to the site
level, using empirical geolocation data. A key contribution of this research is
the application of One-Class Support Vector Machine (OC-SVM) algorithm for
calculating mobile network coverage. This approach models the decision
hyperplane as the effective coverage contour, facilitating robust calculation
of coverage areas for individual cells and entire sites. The same methodology
is extended to analyse crowdsourced service loss reports, thereby identifying
and quantifying geographically localised weak spots. Our findings demonstrate
the efficacy of this novel framework in accurately mapping mobile coverage and,
crucially, in highlighting granular areas of signal deficiency, particularly
within complex urban environments.

</details>


### [174] [Personalized Learning Path Planning with Goal-Driven Learner State Modeling](https://arxiv.org/abs/2510.13215)
*Joy Jia Yin Lim,Ye He,Jifan Yu,Xin Cong,Daniel Zhang-Li,Zhiyuan Liu,Huiqin Liu,Lei Hou,Juanzi Li,Bin Xu*

Main category: cs.AI

TL;DR: Pxplore是一个结合强化学习和LLM的新型框架，用于生成个性化学习路径，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏目标对齐规划机制，Pxplore旨在解决这一问题，利用LLM潜力实现个性化学习路径规划。

Method: 设计了结构化的学习者状态模型和自动奖励函数，结合监督微调（SFT）和组相对策略优化（GRPO）训练策略，并在实际学习平台中部署。

Result: 大量实验验证了Pxplore在生成连贯、个性化且目标驱动的学习路径方面的有效性。

Conclusion: Pxplore框架通过结合强化学习和LLM驱动的教育架构，有效生成了连贯、个性化且目标驱动的学习路径，为未来研究提供了代码和数据集。

Abstract: Personalized Learning Path Planning (PLPP) aims to design adaptive learning
paths that align with individual goals. While large language models (LLMs) show
potential in personalizing learning experiences, existing approaches often lack
mechanisms for goal-aligned planning. We introduce Pxplore, a novel framework
for PLPP that integrates a reinforcement-based training paradigm and an
LLM-driven educational architecture. We design a structured learner state model
and an automated reward function that transforms abstract objectives into
computable signals. We train the policy combining supervised fine-tuning (SFT)
and Group Relative Policy Optimization (GRPO), and deploy it within a
real-world learning platform. Extensive experiments validate Pxplore's
effectiveness in producing coherent, personalized, and goal-driven learning
paths. We release our code and dataset to facilitate future research.

</details>


### [175] [EvoTest: Evolutionary Test-Time Learning for Self-Improving Agentic Systems](https://arxiv.org/abs/2510.13220)
*Yufei He,Juncheng Liu,Yue Liu,Yibo Li,Tri Cao,Zhiyuan Hu,Xinxing Xu,Bryan Hooi*

Main category: cs.AI

TL;DR: EvoTest通过进化式测试时学习框架显著提升AI智能体在动态环境中的表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前AI智能体在测试时无法动态学习复杂技能，限制了其实际应用。为了解决这一问题，作者引入了J-TTL基准测试，并开发了EvoTest框架。

Method: 提出了EvoTest框架，包含执行游戏的Actor Agent和分析游戏记录以提出改进配置的Evolver Agent。该方法通过改写提示、更新记忆、调整超参数和学习工具使用例程来优化智能体。

Result: EvoTest在J-TTL基准测试中表现优于现有方法，是唯一能在两个游戏中获胜的方法，而其他基线方法均未能获胜。

Conclusion: EvoTest是一种进化式测试时学习框架，通过在每轮游戏后进化整个智能体系统，显著提升了智能体在J-TTL基准测试中的表现，尤其是在复杂任务中展现出独特优势。

Abstract: A fundamental limitation of current AI agents is their inability to learn
complex skills on the fly at test time, often behaving like "clever but
clueless interns" in novel environments. This severely limits their practical
utility. To systematically measure and drive progress on this challenge, we
first introduce the Jericho Test-Time Learning (J-TTL) benchmark. J-TTL is a
new evaluation setup where an agent must play the same game for several
consecutive episodes, attempting to improve its performance from one episode to
the next. On J-TTL, we find that existing adaptation methods like reflection,
memory, or reinforcement learning struggle. To address the challenges posed by
our benchmark, we present EvoTest, an evolutionary test-time learning framework
that improves an agent without any fine-tuning or gradients-by evolving the
entire agentic system after every episode. EvoTest has two roles: the Actor
Agent, which plays the game, and the Evolver Agent, which analyzes the episode
transcript to propose a revised configuration for the next run. This
configuration rewrites the prompt, updates memory by logging effective
state-action choices, tunes hyperparameters, and learns the tool-use routines.
On our J-TTL benchmark, EvoTest consistently increases performance,
outperforming not only reflection and memory-only baselines but also more
complex online fine-tuning methods. Notably, our method is the only one capable
of winning two games (Detective and Library), while all baselines fail to win
any.

</details>


### [176] [An Analytical Framework to Enhance Autonomous Vehicle Perception for Smart Cities](https://arxiv.org/abs/2510.13230)
*Jalal Khan,Manzoor Khan,Sherzod Turaev,Sumbal Malik,Hesham El-Sayed,Farman Ullah*

Main category: cs.AI

TL;DR: A utility-based model using YOLOv8s for AV perception outperforms others, with AdamW-based model excelling in class-level accuracy.


<details>
  <summary>Details</summary>
Motivation: To enhance autonomous vehicles by accurately perceiving multiple objects on the road and predicting driver perception for smart mobility.

Method: The article proposes a utility-based analytical model with modules for dataset acquisition, a DL-based model (YOLOv8s) for object detection, and a module to measure perception service utility.

Result: Three best-performing YOLOv8s instances were identified: SGD-based (mAP@0.5: 0.832), Adam-based (0.810), and AdamW-based (0.822). The AdamW-based model showed superior class-level performance.

Conclusion: The proposed perception model effectively evaluates the utility of learning models and determines the appropriate perception for AVs, validated by superior class-level performance of the AdamW-based model.

Abstract: The driving environment perception has a vital role for autonomous driving
and nowadays has been actively explored for its realization. The research
community and relevant stakeholders necessitate the development of Deep
Learning (DL) models and AI-enabled solutions to enhance autonomous vehicles
(AVs) for smart mobility. There is a need to develop a model that accurately
perceives multiple objects on the road and predicts the driver's perception to
control the car's movements. This article proposes a novel utility-based
analytical model that enables perception systems of AVs to understand the
driving environment. The article consists of modules: acquiring a custom
dataset having distinctive objects, i.e., motorcyclists, rickshaws, etc; a
DL-based model (YOLOv8s) for object detection; and a module to measure the
utility of perception service from the performance values of trained model
instances. The perception model is validated based on the object detection
task, and its process is benchmarked by state-of-the-art deep learning models'
performance metrics from the nuScense dataset. The experimental results show
three best-performing YOLOv8s instances based on mAP@0.5 values, i.e.,
SGD-based (0.832), Adam-based (0.810), and AdamW-based (0.822). However, the
AdamW-based model (i.e., car: 0.921, motorcyclist: 0.899, truck: 0.793, etc.)
still outperforms the SGD-based model (i.e., car: 0.915, motorcyclist: 0.892,
truck: 0.781, etc.) because it has better class-level performance values,
confirmed by the proposed perception model. We validate that the proposed
function is capable of finding the right perception for AVs. The results above
encourage using the proposed perception model to evaluate the utility of
learning models and determine the appropriate perception for AVs.

</details>


### [177] [SAJA: A State-Action Joint Attack Framework on Multi-Agent Deep Reinforcement Learning](https://arxiv.org/abs/2510.13262)
*Weiqi Guo,Guanjun Liu,Ziyuan Zhou*

Main category: cs.AI

TL;DR: 本文提出了一种名为SAJA的状态-动作联合攻击框架，通过协同利用状态和动作扰动，显著提升了攻击效果，并验证了其优于单一攻击方式及现有防御方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的多智能体深度强化学习（MADRL）模型易受状态或动作的对抗性扰动影响，但现有研究仅关注单一攻击方式，未充分利用状态与动作的协同效应。

Method: 提出SAJA框架，分两阶段攻击：状态攻击阶段通过多步梯度上升法生成对抗性状态；动作攻击阶段基于扰动状态进一步生成对抗性动作，并引入启发式正则器优化效果。

Result: 在MPE环境中验证，SAJA攻击效果优于单一攻击方式，且现有防御方法无法有效抵御。

Conclusion: SAJA框架通过协同攻击状态与动作，显著提升了攻击的隐蔽性和有效性，揭示了现有防御的局限性。

Abstract: Multi-Agent Deep Reinforcement Learning (MADRL) has shown potential for
cooperative and competitive tasks such as autonomous driving and strategic
gaming. However, models trained by MADRL are vulnerable to adversarial
perturbations on states and actions. Therefore, it is essential to investigate
the robustness of MADRL models from an attack perspective. Existing studies
focus on either state-only attacks or action-only attacks, but do not consider
how to effectively joint them. Simply combining state and action perturbations
such as randomly perturbing states and actions does not exploit their potential
synergistic effects. In this paper, we propose the State-Action Joint Attack
(SAJA) framework that has a good synergistic effects. SAJA consists of two
important phases: (1) In the state attack phase, a multi-step gradient ascent
method utilizes both the actor network and the critic network to compute an
adversarial state, and (2) in the action attack phase, based on the perturbed
state, a second gradient ascent uses the critic network to craft the final
adversarial action. Additionally, a heuristic regularizer measuring the
distance between the perturbed actions and the original clean ones is added
into the loss function to enhance the effectiveness of the critic's guidance.
We evaluate SAJA in the Multi-Agent Particle Environment (MPE), demonstrating
that (1) it outperforms and is more stealthy than state-only or action-only
attacks, and (2) existing state or action defense methods cannot defend its
attacks.

</details>


### [178] [Learnable Game-theoretic Policy Optimization for Data-centric Self-explanation Rationalization](https://arxiv.org/abs/2510.13393)
*Yunxiao Zhao,Zhiqiang Wang,Xingtong Yu,Xiaoli Li,Jiye Liang,Ru Li*

Main category: cs.AI

TL;DR: 本文提出PORAT方法，通过游戏理论解决合理化中的模式崩溃问题，实验显示性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统合理化方法存在模式崩溃问题，即生成器倾向于输出固定模式的解释，缺乏统一考虑。本文从游戏理论视角系统分析了这一问题的根本原因。

Method: 提出了一种基于游戏理论的策略优化方法（PORAT），通过逐步引入策略干预来优化合作游戏过程，从而引导模型达到更优的解状态。

Result: 在九个真实数据集和两个合成设置上验证了PORAT的有效性，性能提升最高达8.1%。

Conclusion: 本文提出了一种名为PORAT的新方法，通过游戏理论视角解决传统合理化方法中的模式崩溃问题，并在多个数据集上验证了其有效性，性能提升高达8.1%。

Abstract: Rationalization, a data-centric framework, aims to build self-explanatory
models to explain the prediction outcome by generating a subset of
human-intelligible pieces of the input data. It involves a cooperative game
model where a generator generates the most human-intelligible parts of the
input (i.e., rationales), followed by a predictor that makes predictions based
on these generated rationales. Conventional rationalization methods typically
impose constraints via regularization terms to calibrate or penalize undesired
generation. However, these methods are suffering from a problem called mode
collapse, in which the predictor produces correct predictions yet the generator
consistently outputs rationales with collapsed patterns. Moreover, existing
studies are typically designed separately for specific collapsed patterns,
lacking a unified consideration. In this paper, we systematically revisit
cooperative rationalization from a novel game-theoretic perspective and
identify the fundamental cause of this problem: the generator no longer tends
to explore new strategies to uncover informative rationales, ultimately leading
the system to converge to a suboptimal game equilibrium (correct predictions
v.s collapsed rationales). To solve this problem, we then propose a novel
approach, Game-theoretic Policy Optimization oriented RATionalization (PORAT),
which progressively introduces policy interventions to address the game
equilibrium in the cooperative game process, thereby guiding the model toward a
more optimal solution state. We theoretically analyse the cause of such a
suboptimal equilibrium and prove the feasibility of the proposed method.
Furthermore, we validate our method on nine widely used real-world datasets and
two synthetic settings, where PORAT achieves up to 8.1% performance
improvements over existing state-of-the-art methods.

</details>


### [179] [Assessing LLM Reasoning Through Implicit Causal Chain Discovery in Climate Discourse](https://arxiv.org/abs/2510.13417)
*Liesbeth Allein,Nataly Pineda-Castañeda,Andrea Rocci,Marie-Francine Moens*

Main category: cs.AI

TL;DR: 研究评估了LLMs在隐性因果链发现中的表现，发现其因果推理主要依赖关联模式匹配，但生成链逻辑连贯。为未来因果推理研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 探究大语言模型（LLMs）在机制性因果推理方面的能力，特别是如何解释因果之间的中间步骤。

Method: 在一个诊断评估框架中，指导九个LLMs生成给定因果对之间的所有可能中间因果步骤，这些因果对来自气候变化辩论的最新资源。

Result: LLMs生成的因果步骤的数量和粒度各不相同，尽管它们对中间因果连接表现出自信和一致性，但其判断主要基于关联模式匹配。人类评估确认了生成链的逻辑连贯性。

Conclusion: 大语言模型（LLMs）在隐性因果链发现任务中表现出一定的能力，但其因果推理主要基于关联模式匹配而非真正的因果推理。尽管如此，人类评估确认了生成链的逻辑连贯性和完整性。研究为未来在论证环境中推进隐性、机制性因果推理提供了基础。

Abstract: How does a cause lead to an effect, and which intermediate causal steps
explain their connection? This work scrutinizes the mechanistic causal
reasoning capabilities of large language models (LLMs) to answer these
questions through the task of implicit causal chain discovery. In a diagnostic
evaluation framework, we instruct nine LLMs to generate all possible
intermediate causal steps linking given cause-effect pairs in causal chain
structures. These pairs are drawn from recent resources in argumentation
studies featuring polarized discussion on climate change. Our analysis reveals
that LLMs vary in the number and granularity of causal steps they produce.
Although they are generally self-consistent and confident about the
intermediate causal connections in the generated chains, their judgments are
mainly driven by associative pattern matching rather than genuine causal
reasoning. Nonetheless, human evaluations confirmed the logical coherence and
integrity of the generated chains. Our baseline causal chain discovery
approach, insights from our diagnostic evaluation, and benchmark dataset with
causal chains lay a solid foundation for advancing future work in implicit,
mechanistic causal reasoning in argumentation settings.

</details>


### [180] [Confidence as a Reward: Transforming LLMs into Reward Models](https://arxiv.org/abs/2510.13501)
*He Du,Bowen Li,Chengxing Xie,Chang Gao,Kai Chen,Dacheng Tao*

Main category: cs.AI

TL;DR: CRew是一种无训练方法，利用模型置信度作为奖励代理，在数学推理任务中表现优异，并进一步提出了CRew-DPO训练策略以提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的奖励模型通常需要大量精心策划的数据和昂贵的训练，而CRew作为一种无训练方法，旨在解决这些挑战。

Method: 本文系统地研究了Confidence-as-a-Reward（CRew），这是一种简单但强大的无训练方法，利用模型对最终答案的token级置信度作为奖励代理。

Result: 实验表明，CRew在数学推理任务上优于现有的无训练奖励方法，甚至超过了大多数经过训练的奖励模型。

Conclusion: CRew-DPO作为一种基于置信度的训练策略，能够有效提升模型的判断能力，并优于现有的自训练方法。

Abstract: Reward models can significantly enhance the reasoning capabilities of large
language models (LLMs), but they typically require extensive curated data and
costly training. To mitigate these challenges, training-free approaches such as
LLM-as-a-Judge leverage the intrinsic reasoning abilities of LLMs to evaluate
responses, achieving promising results. Recent works have also indicated that
model confidence can serve effectively as a reward metric, distinguishing
between chain-of-thought (CoT) and non-CoT paths. However, the concept of using
confidence as a reward has not been comprehensively studied. In this work, we
systematically investigate Confidence-as-a-Reward (CRew), a simple yet powerful
training-free method that utilizes token-level confidence in the model's final
answers as a proxy for reward, especially suitable for close-ended tasks.
Through extensive experiments on mathematical reasoning tasks, we demonstrate
that CRew outperforms existing training-free reward approaches on the MATH500
and RewardMATH benchmarks, and even surpasses most trained reward models. We
further identify a strong correlation between CRew scores and the actual
reasoning performance of the model. Additionally, we find that CRew can
effectively filter high-quality training data. Building upon these insights, we
propose CRew-DPO, a training strategy that constructs preference data from
confidence scores combined with correctness signals. Finetuning with CRew-DPO
further enhances the model's judging capabilities and consistently outperforms
existing self-training methods.

</details>


### [181] [A Methodology for Assessing the Risk of Metric Failure in LLMs Within the Financial Domain](https://arxiv.org/abs/2510.13524)
*William Flanagan,Mukunda Das,Rajitha Ramanyake,Swaunja Maslekar,Meghana Manipuri,Joong Ho Choi,Shruti Nair,Shambhavi Bhusan,Sanjana Dulam,Mouni Pendharkar,Nidhi Singh,Vashisth Doshi,Sachi Shah Paresh*

Main category: cs.AI

TL;DR: 本文探讨了生成式AI在金融服务业中模型性能测量的挑战，并提出一个结合领域专家和机器学习指标的风险评估框架。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能在金融服务业的广泛应用面临模型性能测量的挑战，现有指标和评估方法难以适应其独特需求。

Method: 通过分析现有机器学习指标的局限性以及领域专家评估的不足，本文设计了一个风险评估框架。

Result: 提出的风险评估框架能够更有效地结合领域专家和机器学习指标，提升模型性能测量的准确性和适用性。

Conclusion: 本文提出了一个风险评估框架，以更好地结合领域专家评估和机器学习指标，解决生成式人工智能在金融服务业中模型性能测量的挑战。

Abstract: As Generative Artificial Intelligence is adopted across the financial
services industry, a significant barrier to adoption and usage is measuring
model performance. Historical machine learning metrics can oftentimes fail to
generalize to GenAI workloads and are often supplemented using Subject Matter
Expert (SME) Evaluation. Even in this combination, many projects fail to
account for various unique risks present in choosing specific metrics.
Additionally, many widespread benchmarks created by foundational research labs
and educational institutions fail to generalize to industrial use. This paper
explains these challenges and provides a Risk Assessment Framework to allow for
better application of SME and machine learning Metrics

</details>


### [182] [Tandem Training for Language Models](https://arxiv.org/abs/2510.13551)
*Robert West,Ashton Anderson,Ece Kamar,Eric Horvitz*

Main category: cs.AI

TL;DR: 论文提出串联训练方法，通过强化学习使强模型的解决方案对弱模型保持可理解性，实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着语言模型的快速进步，其行为和推理可能超出弱模型或人类的理解范围，影响可解释性和监督。论文旨在探索方法，使模型生成的解决方案对弱合作者保持可理解性。

Method: 采用强化学习（RL）范式，在训练过程中随机从冻结的弱模型中采样令牌，而非强模型本身。

Result: 在GSM8K数学推理任务中，串联训练成功让模型放弃专业术语并适应弱伙伴的语言风格，同时保持高任务准确性。

Conclusion: 论文提出了一种通过串联训练（tandem training）来提升语言模型可解释性的方法，确保强模型的行为和推理过程能够被弱模型理解，从而保持任务准确性。

Abstract: As language models continue to rapidly improve, we can expect their actions
and reasoning to become difficult or impossible for weaker agents and humans to
follow, undermining interpretability and oversight. With an eye on long-term
futures, we pursue methods that encourage models to produce solutions that
remain intelligible to weaker collaborators. We formalize intelligibility as
handoff robustness: a strong model's solution is intelligible to a weaker model
if randomly handing off control to the weaker model along the solution path
does not cause failure. Building on this criterion, we introduce tandem
training for language models, a reinforcement learning (RL) paradigm in which
rollout tokens are intermittently and randomly sampled from a frozen weak model
rather than the strong model being trained. Because rollouts succeed only when
the strong model's actions and reasoning process can be continued by the weak
model -- when the two can co-construct a successful solution -- optimizing
standard RL objectives with tandem training implicitly incentivizes both
correctness and intelligibility. In the GSM8K math reasoning task, tandem
training reliably teaches models to abandon jargon and adapt their language to
weaker partners while keeping task accuracy high. Our results demonstrate a
promising route to building AI systems that remain auditable by weaker agents,
with implications for human--AI collaboration and multi-agent communication.

</details>


### [183] [A Modal Logic for Temporal and Jurisdictional Classifier Models](https://arxiv.org/abs/2510.13691)
*Cecilia Di Florio,Huimin Dong,Antonino Rotolo*

Main category: cs.AI

TL;DR: 论文提出一种模态逻辑框架，用于法律案例推理的冲突解决，结合时间维度和法院层级。


<details>
  <summary>Details</summary>
Motivation: 旨在为法律领域的机器学习分类器提供形式化验证工具，以支持案例推理（CBR）的冲突解决。

Method: 研究设计了一种模态逻辑，结合时间维度和法院层级，以构建机器学习分类器的验证工具。

Result: 成功开发了一种模态逻辑，能够捕捉法律CBR并解决判例冲突。

Conclusion: 该论文提出了一种模态逻辑框架，用于形式化法律案例推理（CBR），并通过引入时间维度和法院层级来解决判例冲突。

Abstract: Logic-based models can be used to build verification tools for machine
learning classifiers employed in the legal field. ML classifiers predict the
outcomes of new cases based on previous ones, thereby performing a form of
case-based reasoning (CBR). In this paper, we introduce a modal logic of
classifiers designed to formally capture legal CBR. We incorporate principles
for resolving conflicts between precedents, by introducing into the logic the
temporal dimension of cases and the hierarchy of courts within the legal
system.

</details>


### [184] [Training LLM Agents to Empower Humans](https://arxiv.org/abs/2510.13709)
*Evan Ellis,Vivek Myers,Jens Tuyls,Sergey Levine,Anca Dragan,Benjamin Eysenbach*

Main category: cs.AI

TL;DR: Empower是一种自监督方法，通过最大化人类赋权微调语言模型，显著提升辅助效果且无需额外反馈。


<details>
  <summary>Details</summary>
Motivation: 当前构建辅助代理的方法（如模仿专家或基于推断奖励的RL微调）往往鼓励代理独立完成任务，而非真正协助人类实现目标，且需要昂贵的人类显式反馈。

Method: 提出了一种基于最大化人类赋权（empowerment）的新方法Empower，仅需离线文本数据进行语言模型的微调。

Result: 用户研究表明，Empower辅助代理的偏好率为78%（p=0.015），接受率提高31%，建议数减少38%；在模拟编程环境中，Empower代理使模拟人类程序员的成功率平均提升192%。

Conclusion: 通过Empower方法，我们提出了一种仅需离线文本数据的自监督微调框架，显著提升了语言模型在协助人类方面的表现，且无需额外的人类反馈或可验证奖励。

Abstract: Assistive agents should not only take actions on behalf of a human, but also
step out of the way and cede control when there are important decisions to be
made. However, current methods for building assistive agents, whether via
mimicking expert humans or via RL finetuning on an inferred reward, often
encourage agents to complete tasks on their own rather than truly assisting the
human attain their objectives. Additionally, these methods often require costly
explicit human feedback to provide a training signal. We propose a new approach
to tuning assistive language models based on maximizing the human's
empowerment, their ability to effect desired changes in the environment. Our
empowerment-maximizing method, Empower, only requires offline text data,
providing a self-supervised method for fine-tuning language models to better
assist humans. To study the efficacy of our approach, we conducted an 18-person
user study comparing our empowerment assistant with a strong baseline.
Participants preferred our assistant 78% of the time (p=0.015), with a 31%
higher acceptance rate and 38% fewer suggestions. Additionally, we introduce a
new environment for evaluating multi-turn code assistance using simulated
humans. Using this environment, we show that agents trained with Empower
increase the success rate of a simulated human programmer on challenging coding
questions by an average of 192% over an SFT baseline. With this empowerment
objective, we provide a framework for useful aligned AI agents at scale using
only offline data without the need for any additional human feedback or
verifiable rewards.

</details>


### [185] [From Refusal to Recovery: A Control-Theoretic Approach to Generative AI Guardrails](https://arxiv.org/abs/2510.13727)
*Ravi Pandya,Madison Bland,Duy P. Nguyen,Changliu Liu,Jaime Fernández Fisac,Andrea Bajcsy*

Main category: cs.AI

TL;DR: 本文提出了一种基于控制理论的动态AI安全护栏，能够实时监控并主动纠正风险输出，避免灾难性后果，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI系统在现实场景中的应用增加，传统的基于输出分类的安全措施显得脆弱且无法应对新的危险情况，需要一种更动态的安全方法。

Method: 通过安全关键控制理论的视角，在AI模型的世界潜在表示中构建预测性护栏，包括实时监控和主动纠正风险输出。

Result: 在模拟驾驶和电子商务环境中的实验表明，控制理论护栏能有效避免碰撞和破产等灾难性后果，同时保持任务性能。

Conclusion: 控制理论护栏提供了一种动态、原则性的替代方案，能够可靠地引导LLM代理避免灾难性后果，同时保持任务性能。

Abstract: Generative AI systems are increasingly assisting and acting on behalf of end
users in practical settings, from digital shopping assistants to
next-generation autonomous cars. In this context, safety is no longer about
blocking harmful content, but about preempting downstream hazards like
financial or physical harm. Yet, most AI guardrails continue to rely on output
classification based on labeled datasets and human-specified criteria,making
them brittle to new hazardous situations. Even when unsafe conditions are
flagged, this detection offers no path to recovery: typically, the AI system
simply refuses to act--which is not always a safe choice. In this work, we
argue that agentic AI safety is fundamentally a sequential decision problem:
harmful outcomes arise from the AI system's continually evolving interactions
and their downstream consequences on the world. We formalize this through the
lens of safety-critical control theory, but within the AI model's latent
representation of the world. This enables us to build predictive guardrails
that (i) monitor an AI system's outputs (actions) in real time and (ii)
proactively correct risky outputs to safe ones, all in a model-agnostic manner
so the same guardrail can be wrapped around any AI model. We also offer a
practical training recipe for computing such guardrails at scale via
safety-critical reinforcement learning. Our experiments in simulated driving
and e-commerce settings demonstrate that control-theoretic guardrails can
reliably steer LLM agents clear of catastrophic outcomes (from collisions to
bankruptcy) while preserving task performance, offering a principled dynamic
alternative to today's flag-and-block guardrails.

</details>


### [186] [Hard2Verify: A Step-Level Verification Benchmark for Open-Ended Frontier Math](https://arxiv.org/abs/2510.13744)
*Shrey Pandit,Austin Xu,Xuan-Phi Nguyen,Yifei Ming,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: Hard2Verify是一个人工标注的步骤级验证基准，用于评估前沿验证器在开放数学问题中的表现，结果显示开源验证器普遍落后于闭源模型。


<details>
  <summary>Details</summary>
Motivation: 在开放数学问题中，强验证器是训练LLM推理系统的关键前提，需能捕捉步骤级错误。

Method: 引入Hard2Verify基准，评估29种生成式批评家和过程奖励模型，分析性能驱动因素和计算扩展影响。

Result: 开源验证器整体表现落后于闭源模型，但少数例外。

Conclusion: 当前开源验证器在步骤级验证任务上表现不佳，但通过计算资源扩展和深入研究验证-生成动态，可以提升性能。

Abstract: Large language model (LLM)-based reasoning systems have recently achieved
gold medal-level performance in the IMO 2025 competition, writing mathematical
proofs where, to receive full credit, each step must be not only correct but
also sufficiently supported. To train LLM-based reasoners in such challenging,
open-ended settings, strong verifiers capable of catching step-level mistakes
are necessary prerequisites. We introduce Hard2Verify, a human-annotated,
step-level verification benchmark produced with over 500 hours of human labor.
Hard2Verify is designed to rigorously assess step-level verifiers at the
frontier: Verifiers must provide step-level annotations or identify the first
error in responses generated by frontier LLMs for very recent, challenging, and
open-ended math questions. We evaluate 29 generative critics and process reward
models, demonstrating that, beyond a few standouts, open-source verifiers lag
closed source models. We subsequently analyze what drives poor performance in
step-level verification, the impacts of scaling verifier compute, as well as
fundamental questions such as self-verification and verification-generation
dynamics.

</details>
