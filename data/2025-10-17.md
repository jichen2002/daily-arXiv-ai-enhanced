<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 100]
- [cs.NI](#cs.NI) [Total: 7]
- [cs.AI](#cs.AI) [Total: 54]
- [cs.RO](#cs.RO) [Total: 37]
- [cs.SE](#cs.SE) [Total: 18]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MultiFoodhat: A potential new paradigm for intelligent food quality inspection](https://arxiv.org/abs/2510.13889)
*Yue Hu,Guohang Zhuang*

Main category: cs.CV

TL;DR: MultiFoodChat是一种对话驱动的多智能体推理框架，结合视觉语言模型和大语言模型，实现了零样本食物识别，无需额外训练或标注，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有监督模型严重依赖大量标注数据且对未见食物类别泛化能力有限，因此需要开发一种无需依赖标注数据的零样本识别方法。

Method: 该研究提出了MultiFoodChat框架，整合了视觉语言模型（VLMs）和大语言模型（LLMs），通过多轮视觉-文本对话实现协作推理。具体包括对象感知令牌（OPT）捕捉细粒度视觉属性，以及交互式推理代理（IRA）动态解释上下文线索以优化预测。

Result: 在多个公共食物数据集上的实验表明，MultiFoodChat在识别准确性和可解释性上优于现有的无监督和少样本方法。

Conclusion: MultiFoodChat作为一种新的零样本食物识别框架，通过结合视觉语言模型和大语言模型，实现了无需额外训练或手动标注的高效食物分类，为智能食品质量检测提供了新范式。

Abstract: Food image classification plays a vital role in intelligent food quality
inspection, dietary assessment, and automated monitoring. However, most
existing supervised models rely heavily on large labeled datasets and exhibit
limited generalization to unseen food categories. To overcome these challenges,
this study introduces MultiFoodChat, a dialogue-driven multi-agent reasoning
framework for zero-shot food recognition. The framework integrates
vision-language models (VLMs) and large language models (LLMs) to enable
collaborative reasoning through multi-round visual-textual dialogues. An Object
Perception Token (OPT) captures fine-grained visual attributes, while an
Interactive Reasoning Agent (IRA) dynamically interprets contextual cues to
refine predictions. This multi-agent design allows flexible and human-like
understanding of complex food scenes without additional training or manual
annotations. Experiments on multiple public food datasets demonstrate that
MultiFoodChat achieves superior recognition accuracy and interpretability
compared with existing unsupervised and few-shot methods, highlighting its
potential as a new paradigm for intelligent food quality inspection and
analysis.

</details>


### [2] [Capture, Canonicalize, Splat: Zero-Shot 3D Gaussian Avatars from Unstructured Phone Images](https://arxiv.org/abs/2510.14081)
*Emanuel Garbin,Guy Adam,Oded Krams,Zohar Barzelay,Eran Guendelman,Michael Schwarz,Moran Vatelmacher,Yigal Shenkman,Eli Peker,Itai Druker,Uri Patish,Yoav Blum,Max Bluvstein,Junxuan Li,Rawal Khirodkar,Shunsuke Saito*

Main category: cs.CV

TL;DR: 论文提出了一种零样本流程，通过生成规范化模块和Transformer模型，从非结构化图像创建超逼真、身份保持的3D头像。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在几何不一致性、幻觉和高频细节（如皮肤皱纹和细发）缺失的问题，限制了头像的逼真度和身份保持能力。

Method: 该方法引入了两个关键贡献：(1) 生成规范化模块，将多个非结构化视图处理为标准化、一致的表示；(2) 基于Transformer的模型，训练于一个新的大规模高保真高斯泼溅头像数据集。

Result: 提出的“捕捉、规范化、泼溅”流程能够从非结构化照片中生成具有高度逼真性和稳健身份保持能力的静态四分之一身体头像。

Conclusion: 该论文提出了一种新颖的零样本流程，能够从少量非结构化手机图像创建超逼真、保持身份的3D头像，解决了现有方法的几何不一致性、幻觉和高频细节缺失等问题。

Abstract: We present a novel, zero-shot pipeline for creating hyperrealistic,
identity-preserving 3D avatars from a few unstructured phone images. Existing
methods face several challenges: single-view approaches suffer from geometric
inconsistencies and hallucinations, degrading identity preservation, while
models trained on synthetic data fail to capture high-frequency details like
skin wrinkles and fine hair, limiting realism. Our method introduces two key
contributions: (1) a generative canonicalization module that processes multiple
unstructured views into a standardized, consistent representation, and (2) a
transformer-based model trained on a new, large-scale dataset of high-fidelity
Gaussian splatting avatars derived from dome captures of real people. This
"Capture, Canonicalize, Splat" pipeline produces static quarter-body avatars
with compelling realism and robust identity preservation from unstructured
photos.

</details>


### [3] [Post-surgical Endometriosis Segmentation in Laparoscopic Videos](https://arxiv.org/abs/2510.13899)
*Andreas Leibetseder,Klaus Schoeffmann,Jörg Keckstein,Simon Keckstein*

Main category: cs.CV

TL;DR: 开发了一个基于深度学习的系统，用于自动分割腹腔镜视频中的子宫内膜异位症常见视觉表现，辅助医生诊断。


<details>
  <summary>Details</summary>
Motivation: 子宫内膜异位症的视觉表现多样且复杂，非专业医生难以准确识别，因此开发一个自动分割系统以辅助妇科医生诊断和治疗。

Method: 利用深度学习技术训练一个系统，分析腹腔镜手术视频，识别并分割暗色子宫内膜植入物区域，并通过多色叠加标注和检测摘要提升视频浏览效率。

Result: 系统能够准确识别并标注腹腔镜视频中的暗色子宫内膜植入物，提供检测摘要以优化视频浏览体验。

Conclusion: 该系统通过深度学习技术成功实现了对子宫内膜异位症常见视觉表现（暗色子宫内膜植入物）的自动分割，为妇科医生提供了有效的辅助工具。

Abstract: Endometriosis is a common women's condition exhibiting a manifold visual
appearance in various body-internal locations. Having such properties makes its
identification very difficult and error-prone, at least for laymen and
non-specialized medical practitioners. In an attempt to provide assistance to
gynecologic physicians treating endometriosis, this demo paper describes a
system that is trained to segment one frequently occurring visual appearance of
endometriosis, namely dark endometrial implants. The system is capable of
analyzing laparoscopic surgery videos, annotating identified implant regions
with multi-colored overlays and displaying a detection summary for improved
video browsing.

</details>


### [4] [GauSSmart: Enhanced 3D Reconstruction through 2D Foundation Models and Geometric Filtering](https://arxiv.org/abs/2510.14270)
*Alexander Valverde,Brian Xu,Yuyin Zhou,Meng Xu,Hongyun Wang*

Main category: cs.CV

TL;DR: GauSSmart结合2D基础模型和3D高斯泼溅，通过2D技术增强重建细节和覆盖率，在多个数据集中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅在大规模数据集上表现良好，但在稀疏覆盖区域难以捕捉细节或保持真实感，主要由于稀疏3D训练数据的固有局限性。

Method: 提出GauSSmart，一种混合方法，结合2D计算机视觉技术（如凸滤波和DINO等基础模型的语义特征监督）来增强基于高斯的场景重建。方法利用2D分割先验和高维特征嵌入，指导高斯泼溅的密集化和细化。

Result: 在三个数据集上的验证表明，GauSSmart在多数评估场景中 consistently 优于现有高斯泼溅方法。

Conclusion: GauSSmart通过结合2D基础模型和3D高斯泼溅重建，显著提升了场景重建的细节和覆盖率，展示了混合2D-3D方法的巨大潜力。

Abstract: Scene reconstruction has emerged as a central challenge in computer vision,
with approaches such as Neural Radiance Fields (NeRF) and Gaussian Splatting
achieving remarkable progress. While Gaussian Splatting demonstrates strong
performance on large-scale datasets, it often struggles to capture fine details
or maintain realism in regions with sparse coverage, largely due to the
inherent limitations of sparse 3D training data.
  In this work, we propose GauSSmart, a hybrid method that effectively bridges
2D foundational models and 3D Gaussian Splatting reconstruction. Our approach
integrates established 2D computer vision techniques, including convex
filtering and semantic feature supervision from foundational models such as
DINO, to enhance Gaussian-based scene reconstruction. By leveraging 2D
segmentation priors and high-dimensional feature embeddings, our method guides
the densification and refinement of Gaussian splats, improving coverage in
underrepresented areas and preserving intricate structural details.
  We validate our approach across three datasets, where GauSSmart consistently
outperforms existing Gaussian Splatting in the majority of evaluated scenes.
Our results demonstrate the significant potential of hybrid 2D-3D approaches,
highlighting how the thoughtful combination of 2D foundational models with 3D
reconstruction pipelines can overcome the limitations inherent in either
approach alone.

</details>


### [5] [Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models](https://arxiv.org/abs/2510.13993)
*Jia Yun Chua,Argyrios Zolotas,Miguel Arana-Catania*

Main category: cs.CV

TL;DR: 结合视觉模型与VLMs显著提升了遥感图像分析的准确性和上下文理解能力，尤其在少样本和退化场景中表现突出。


<details>
  <summary>Details</summary>
Motivation: 尽管遥感数据量大幅增加，但传统视觉模型受限于对大量领域特定标记数据的需求及在复杂环境中理解上下文的能力。视觉语言模型（VLMs）通过整合视觉和文本数据提供了补充方法，但其在遥感领域的应用仍未被充分探索。

Method: 本研究调查了视觉模型与VLMs（如LLaVA、ChatGPT和Gemini）的结合，旨在提升遥感图像分析的准确性和上下文感知能力。通过YOLO与VLMs的集成，评估了在标记和未标记遥感数据以及退化图像场景下的性能。

Result: 实验结果显示，在飞机检测和计数准确性方面，平均MAE提高了48.46%，特别是在具有挑战性的条件下。此外，CLIPScore在全面理解遥感图像方面提高了6.17%。

Conclusion: 结合传统视觉模型与视觉语言模型（VLMs）的方法为遥感图像分析提供了更先进和高效的途径，特别是在少样本学习场景中。

Abstract: Remote sensing has become a vital tool across sectors such as urban planning,
environmental monitoring, and disaster response. While the volume of data
generated has increased significantly, traditional vision models are often
constrained by the requirement for extensive domain-specific labelled data and
their limited ability to understand the context within complex environments.
Vision Language Models offer a complementary approach by integrating visual and
textual data; however, their application to remote sensing remains
underexplored, particularly given their generalist nature. This work
investigates the combination of vision models and VLMs to enhance image
analysis in remote sensing, with a focus on aircraft detection and scene
understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and
Gemini aims to achieve more accurate and contextually aware image
interpretation. Performance is evaluated on both labelled and unlabelled remote
sensing data, as well as degraded image scenarios which are crucial for remote
sensing. The findings show an average MAE improvement of 48.46% across models
in the accuracy of aircraft detection and counting, especially in challenging
conditions, in both raw and degraded scenarios. A 6.17% improvement in
CLIPScore for comprehensive understanding of remote sensing images is obtained.
The proposed approach combining traditional vision models and VLMs paves the
way for more advanced and efficient remote sensing image analysis, especially
in few-shot learning scenarios.

</details>


### [6] [Inpainting the Red Planet: Diffusion Models for the Reconstruction of Martian Environments in Virtual Reality](https://arxiv.org/abs/2510.14765)
*Giuseppe Lorenzo Catalano,Agata Marta Soccini*

Main category: cs.CV

TL;DR: 提出了一种无条件扩散模型用于火星表面重建，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 火星地形数据中存在大量缺失值，现有插值技术难以保持几何一致性，而地球上的条件方法无法直接应用于火星。

Method: 使用无条件扩散模型，在由NASA HiRISE调查生成的12000个火星高度图增强数据集上进行训练，采用非均匀缩放策略捕捉多尺度地形特征。

Result: 在1000个样本的评估集上，该方法在重建精度（RMSE提升4-15%）和感知相似性（LPIPS提升29-81%）上均优于现有方法。

Conclusion: 该研究提出了一种基于无条件扩散模型的方法，用于重建火星表面，显著提高了重建精度和感知相似性。

Abstract: Space exploration increasingly relies on Virtual Reality for several tasks,
such as mission planning, multidisciplinary scientific analysis, and astronaut
training. A key factor for the reliability of the simulations is having
accurate 3D representations of planetary terrains. Extraterrestrial heightmaps
derived from satellite imagery often contain missing values due to acquisition
and transmission constraints. Mars is among the most studied planets beyond
Earth, and its extensive terrain datasets make the Martian surface
reconstruction a valuable task, although many areas remain unmapped. Deep
learning algorithms can support void-filling tasks; however, whereas Earth's
comprehensive datasets enables the use of conditional methods, such approaches
cannot be applied to Mars. Current approaches rely on simpler interpolation
techniques which, however, often fail to preserve geometric coherence. In this
work, we propose a method for reconstructing the surface of Mars based on an
unconditional diffusion model. Training was conducted on an augmented dataset
of 12000 Martian heightmaps derived from NASA's HiRISE survey. A
non-homogeneous rescaling strategy captures terrain features across multiple
scales before resizing to a fixed 128x128 model resolution. We compared our
method against established void-filling and inpainting techniques, including
Inverse Distance Weighting, kriging, and Navier-Stokes algorithm, on an
evaluation set of 1000 samples. Results show that our approach consistently
outperforms these methods in terms of reconstruction accuracy (4-15% on RMSE)
and perceptual similarity (29-81% on LPIPS) with the original data.

</details>


### [7] [Finding Holes: Pathologist Level Performance Using AI for Cribriform Morphology Detection in Prostate Cancer](https://arxiv.org/abs/2510.13995)
*Kelvin Szolnoky,Anders Blilie,Nita Mulliqi,Toyonori Tsuzuki,Hemamali Samaratunga,Matteo Titus,Xiaoyi Ji,Sol Erika Boman,Einar Gudlaugsson,Svein Reidar Kjosavik,José Asenjo,Marcello Gambacorta,Paolo Libretti,Marcin Braun,Radisław Kordek,Roman Łowicki,Brett Delahunt,Kenneth A. Iczkowski,Theo van der Kwast,Geert J. L. H. van Leenders,Katia R. M. Leite,Chin-Chen Pan,Emiel Adrianus Maria Janssen,Martin Eklund,Lars Egevad,Kimmo Kartasalo*

Main category: cs.CV

TL;DR: AI模型在检测前列腺癌筛状形态方面达到病理学家水平，提升诊断可靠性并标准化报告。


<details>
  <summary>Details</summary>
Motivation: Cribriform morphology in prostate cancer is a histological feature that indicates poor prognosis and contraindicates active surveillance. However, it remains underreported and subject to significant interobserver variability amongst pathologists.

Method: We created a deep learning model using an EfficientNetV2-S encoder with multiple instance learning for end-to-end whole-slide classification. The model was trained on 640 digitised prostate core needle biopsies from 430 patients, collected across three cohorts. It was validated internally and externally.

Result: The model showed strong internal validation performance (AUC: 0.97, 95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI: 0.45-0.64). In our inter-rater analysis, the model achieved the highest average agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine pathologists.

Conclusion: Our AI model demonstrates pathologist-level performance for cribriform morphology detection in prostate cancer. This approach could enhance diagnostic reliability, standardise reporting, and improve treatment decisions for prostate cancer patients.

Abstract: Background: Cribriform morphology in prostate cancer is a histological
feature that indicates poor prognosis and contraindicates active surveillance.
However, it remains underreported and subject to significant interobserver
variability amongst pathologists. We aimed to develop and validate an AI-based
system to improve cribriform pattern detection.
  Methods: We created a deep learning model using an EfficientNetV2-S encoder
with multiple instance learning for end-to-end whole-slide classification. The
model was trained on 640 digitised prostate core needle biopsies from 430
patients, collected across three cohorts. It was validated internally (261
slides from 171 patients) and externally (266 slides, 104 patients from three
independent cohorts). Internal validation cohorts included laboratories or
scanners from the development set, while external cohorts used completely
independent instruments and laboratories. Annotations were provided by three
expert uropathologists with known high concordance. Additionally, we conducted
an inter-rater analysis and compared the model's performance against nine
expert uropathologists on 88 slides from the internal validation cohort.
  Results: The model showed strong internal validation performance (AUC: 0.97,
95% CI: 0.95-0.99; Cohen's kappa: 0.81, 95% CI: 0.72-0.89) and robust external
validation (AUC: 0.90, 95% CI: 0.86-0.93; Cohen's kappa: 0.55, 95% CI:
0.45-0.64). In our inter-rater analysis, the model achieved the highest average
agreement (Cohen's kappa: 0.66, 95% CI: 0.57-0.74), outperforming all nine
pathologists whose Cohen's kappas ranged from 0.35 to 0.62.
  Conclusion: Our AI model demonstrates pathologist-level performance for
cribriform morphology detection in prostate cancer. This approach could enhance
diagnostic reliability, standardise reporting, and improve treatment decisions
for prostate cancer patients.

</details>


### [8] [Ponimator: Unfolding Interactive Pose for Versatile Human-human Interaction Animation](https://arxiv.org/abs/2510.14976)
*Shaowei Liu,Chuan Guo,Bing Zhou,Jian Wang*

Main category: cs.CV

TL;DR: Ponimator是一个基于交互姿势先验的框架，通过两个条件扩散模型支持多样化交互动画任务，实验证明其有效性和通用性。


<details>
  <summary>Details</summary>
Motivation: 受到人类通过近距离交互姿势直观推断上下文和动态的启发，旨在利用交互姿势先验实现多功能交互动画。

Method: Ponimator采用两个条件扩散模型：姿势动画器利用时间先验从交互姿势生成动态运动序列，姿势生成器则利用空间先验从单个姿势、文本或两者合成交互姿势。

Result: 实证实验表明，Ponimator在多样化数据集和应用中均表现出姿势先验的通用性及框架的有效性和鲁棒性。

Conclusion: Ponimator框架通过利用交互姿势先验，展示了其在多样化任务中的通用性和有效性，包括基于图像的交互动画、反应动画以及文本到交互的合成。

Abstract: Close-proximity human-human interactive poses convey rich contextual
information about interaction dynamics. Given such poses, humans can
intuitively infer the context and anticipate possible past and future dynamics,
drawing on strong priors of human behavior. Inspired by this observation, we
propose Ponimator, a simple framework anchored on proximal interactive poses
for versatile interaction animation. Our training data consists of
close-contact two-person poses and their surrounding temporal context from
motion-capture interaction datasets. Leveraging interactive pose priors,
Ponimator employs two conditional diffusion models: (1) a pose animator that
uses the temporal prior to generate dynamic motion sequences from interactive
poses, and (2) a pose generator that applies the spatial prior to synthesize
interactive poses from a single pose, text, or both when interactive poses are
unavailable. Collectively, Ponimator supports diverse tasks, including
image-based interaction animation, reaction animation, and text-to-interaction
synthesis, facilitating the transfer of interaction knowledge from high-quality
mocap data to open-world scenarios. Empirical experiments across diverse
datasets and applications demonstrate the universality of the pose prior and
the effectiveness and robustness of our framework.

</details>


### [9] [NAPPure: Adversarial Purification for Robust Image Classification under Non-Additive Perturbations](https://arxiv.org/abs/2510.14025)
*Junjie Nan,Jianing Li,Wei Chen,Mingkun Zhang,Xueqi Cheng*

Main category: cs.CV

TL;DR: NAPPure是一种扩展的对抗净化框架，通过似然最大化处理非加性扰动，显著提升了图像分类模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗净化方法主要针对加性扰动设计，对非加性扰动（如模糊、遮挡和扭曲）效果不佳。

Method: 通过建立对抗图像的生成过程，并通过似然最大化分离潜在的干净图像和扰动参数。

Result: 在GTSRB和CIFAR-10数据集上的实验表明，NAPPure显著提升了模型对抗非加性扰动的鲁棒性。

Conclusion: NAPPure框架显著提升了图像分类模型对抗非加性扰动的鲁棒性。

Abstract: Adversarial purification has achieved great success in combating adversarial
image perturbations, which are usually assumed to be additive. However,
non-additive adversarial perturbations such as blur, occlusion, and distortion
are also common in the real world. Under such perturbations, existing
adversarial purification methods are much less effective since they are
designed to fit the additive nature. In this paper, we propose an extended
adversarial purification framework named NAPPure, which can further handle
non-additive perturbations. Specifically, we first establish the generation
process of an adversarial image, and then disentangle the underlying clean
image and perturbation parameters through likelihood maximization. Experiments
on GTSRB and CIFAR-10 datasets show that NAPPure significantly boosts the
robustness of image classification models against non-additive perturbations.

</details>


### [10] [Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding](https://arxiv.org/abs/2510.14032)
*Xiaoqian Shen,Wenxuan Zhang,Jun Chen,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: Vgent通过图结构和中间推理增强LVLMs的长视频理解能力，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 长视频理解对大型视频语言模型（LVLMs）提出了挑战，包括处理超出上下文窗口的密集视频标记和保留长期序列信息。现有检索增强生成（RAG）方法在长视频中面临时间依赖断裂和无关信息干扰的问题。

Method: 提出了Vgent框架，包括两个关键创新：1）使用结构化图表示视频，保留跨视频片段的语义关系；2）引入中间推理步骤，通过结构化验证减少检索噪声并显式聚合跨片段的相关信息。

Result: 在三个长视频理解基准测试中，Vgent框架使LVLMs的整体性能提升了3.0%至5.4%，并在MLVU上优于最先进的视频RAG方法8.6%。

Conclusion: Vgent框架通过引入基于图的检索-推理增强生成方法，显著提升了大型视频语言模型（LVLMs）在长视频理解任务中的性能，性能提升显著优于现有方法。

Abstract: Understanding and reasoning over long videos pose significant challenges for
large video language models (LVLMs) due to the difficulty in processing
intensive video tokens beyond context window and retaining long-term sequential
information. Retrieval-Augmented Generation (RAG) has demonstrated
effectiveness in processing long context for Large Language Models (LLMs);
however, applying RAG to long video faces challenges such as disrupted temporal
dependencies and inclusion of irrelevant information that can hinder accurate
reasoning. To address these limitations, we propose Vgent, a novel graph-based
retrieval-reasoning-augmented generation framework to enhance LVLMs for long
video understanding. Our approach introduces two key innovations: (i) It
represents videos by structured graphs with semantic relationships across video
clips preserved to improve retrieval effectiveness. (ii) It introduces an
intermediate reasoning step to mitigate the reasoning limitation of LVLMs,
which leverages structured verification to reduce retrieval noise and
facilitate the explicit aggregation of relevant information across clips,
resulting in more accurate and context-aware responses. We comprehensively
evaluate our framework with various open-source LVLMs on three long-video
understanding benchmarks. Our approach yielded an overall performance
improvement of $3.0\%\sim 5.4\%$ over base models on MLVU, and outperformed
state-of-the-art video RAG methods by $8.6\%$. Our code is publicly available
at https://xiaoqian-shen.github.io/Vgent.

</details>


### [11] [Synchronization of Multiple Videos](https://arxiv.org/abs/2510.14051)
*Avihai Naaman,Ron Shapira Weber,Oren Freifeld*

Main category: cs.CV

TL;DR: TPL 通过学习原型序列实现多视频同步，尤其适用于生成式 AI 视频，显著提升了同步效果。


<details>
  <summary>Details</summary>
Motivation: 由于不同场景或生成式 AI 视频中的多样化主题、背景和非线性时间错位，多视频同步变得更加复杂。

Method: TPL 通过学习统一的原型序列来锚定关键动作阶段，避免了繁琐的成对匹配，构建了一个共享的紧凑 1D 表示。

Result: 实验表明，TPL 在多个数据集上提高了同步的准确性、效率和鲁棒性，特别是在细粒度帧检索和阶段分类任务中表现优异。

Conclusion: TPL 是一种有效解决多视频同步问题的方法，特别是在处理生成式 AI 视频时表现突出，提供了更高的准确性、效率和鲁棒性。

Abstract: Synchronizing videos captured simultaneously from multiple cameras in the
same scene is often easy and typically requires only simple time shifts.
However, synchronizing videos from different scenes or, more recently,
generative AI videos, poses a far more complex challenge due to diverse
subjects, backgrounds, and nonlinear temporal misalignment. We propose Temporal
Prototype Learning (TPL), a prototype-based framework that constructs a shared,
compact 1D representation from high-dimensional embeddings extracted by any of
various pretrained models. TPL robustly aligns videos by learning a unified
prototype sequence that anchors key action phases, thereby avoiding exhaustive
pairwise matching. Our experiments show that TPL improves synchronization
accuracy, efficiency, and robustness across diverse datasets, including
fine-grained frame retrieval and phase classification tasks. Importantly, TPL
is the first approach to mitigate synchronization issues in multiple generative
AI videos depicting the same action. Our code and a new multiple video
synchronization dataset are available at https://bgu-cs-vil.github.io/TPL/

</details>


### [12] [cubic: CUDA-accelerated 3D Bioimage Computing](https://arxiv.org/abs/2510.14143)
*Alexandr A. Kalinin,Anne E. Carpenter,Shantanu Singh,Matthew J. O'Meara*

Main category: cs.CV

TL;DR: cubic是一个开源的Python库，通过GPU加速扩展了SciPy和scikit-image的功能，显著提升了生物图像分析的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现代显微镜产生的2D和3D数据集越来越大，现有生物图像分析工具在可扩展性、效率和与现代科学计算工作流的集成方面存在局限。

Method: 通过扩展SciPy和scikit-image的API，结合CuPy和RAPIDS cuCIM的GPU加速功能，cubic实现了设备无关的操作分发，支持2D和3D数据的预处理、分割和特征提取。

Result: cubic在保持算法保真度的同时，显著加速了图像处理流程，包括去卷积和分割任务。

Conclusion: cubic库为生物图像分析提供了一个强大且可扩展的工具，支持GPU加速，并与Python科学计算生态系统无缝集成，显著提升了处理效率。

Abstract: Quantitative analysis of multidimensional biological images is useful for
understanding complex cellular phenotypes and accelerating advances in
biomedical research. As modern microscopy generates ever-larger 2D and 3D
datasets, existing computational approaches are increasingly limited by their
scalability, efficiency, and integration with modern scientific computing
workflows. Existing bioimage analysis tools often lack application programmable
interfaces (APIs), do not support graphics processing unit (GPU) acceleration,
lack broad 3D image processing capabilities, and/or have poor interoperability
for compute-heavy workflows. Here, we introduce cubic, an open-source Python
library that addresses these challenges by augmenting widely used SciPy and
scikit-image APIs with GPU-accelerated alternatives from CuPy and RAPIDS cuCIM.
cubic's API is device-agnostic and dispatches operations to GPU when data
reside on the device and otherwise executes on CPU, seamlessly accelerating a
broad range of image processing routines. This approach enables GPU
acceleration of existing bioimage analysis workflows, from preprocessing to
segmentation and feature extraction for 2D and 3D data. We evaluate cubic both
by benchmarking individual operations and by reproducing existing deconvolution
and segmentation pipelines, achieving substantial speedups while maintaining
algorithmic fidelity. These advances establish a robust foundation for
scalable, reproducible bioimage analysis that integrates with the broader
Python scientific computing ecosystem, including other GPU-accelerated methods,
enabling both interactive exploration and automated high-throughput analysis
workflows. cubic is openly available at
https://github$.$com/alxndrkalinin/cubic

</details>


### [13] [Virtually Being: Customizing Camera-Controllable Video Diffusion Models with Multi-View Performance Captures](https://arxiv.org/abs/2510.14179)
*Yuancheng Xu,Wenqi Xian,Li Ma,Julien Philip,Ahmet Levent Taşel,Yiwei Zhao,Ryan Burgert,Mingming He,Oliver Hermann,Oliver Pilarski,Rahul Garg,Paul Debevec,Ning Yu*

Main category: cs.CV

TL;DR: 提出了一种通过4D高斯泼溅和视频重光照模型实现多视角角色一致性和3D相机控制的框架，显著提升了视频生成的质量和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决视频扩散模型中多视角角色一致性和3D相机控制的问题，以支持虚拟制作的核心需求。

Method: 使用4D高斯泼溅（4DGS）重新渲染录制的体积捕捉表演，结合视频重光照模型获取光照变化数据，并对先进的开源视频扩散模型进行微调。

Result: 实验表明，该方法在视频质量、个性化准确性、相机控制和光照适应性方面均有显著提升。

Conclusion: 该框架通过新颖的数据管道和4D高斯泼溅技术，显著提升了视频生成的质量、个性化准确性、相机控制和光照适应性，推动了视频生成在虚拟制作中的整合。

Abstract: We introduce a framework that enables both multi-view character consistency
and 3D camera control in video diffusion models through a novel customization
data pipeline. We train the character consistency component with recorded
volumetric capture performances re-rendered with diverse camera trajectories
via 4D Gaussian Splatting (4DGS), lighting variability obtained with a video
relighting model. We fine-tune state-of-the-art open-source video diffusion
models on this data to provide strong multi-view identity preservation, precise
camera control, and lighting adaptability. Our framework also supports core
capabilities for virtual production, including multi-subject generation using
two approaches: joint training and noise blending, the latter enabling
efficient composition of independently customized models at inference time; it
also achieves scene and real-life video customization as well as control over
motion and spatial layout during customization. Extensive experiments show
improved video quality, higher personalization accuracy, and enhanced camera
control and lighting adaptability, advancing the integration of video
generation into virtual production. Our project page is available at:
https://eyeline-labs.github.io/Virtually-Being.

</details>


### [14] [Multi-modal video data-pipelines for machine learning with minimal human supervision](https://arxiv.org/abs/2510.14862)
*Mihai-Cristian Pîrvu,Marius Leordeanu*

Main category: cs.CV

TL;DR: 本研究通过开源全自动数据管道和PHG-MAE模型，实现了多模态视觉数据的高效整合，并在低参数情况下取得了与高参数模型相竞争的结果。


<details>
  <summary>Details</summary>
Motivation: 现实世界本质上是多模态的，但传统机器学习模型多为单模态或双模态。为了更好地理解世界，需要整合所有独立的模态。本研究旨在结合尽可能多的视觉模态，减少人为监督。

Method: 使用预训练的专家模型和程序化组合方法，结合全自动数据管道，并利用PHG-MAE模型进行多模态数据的高效学习。

Result: 研究展示了PHG-MAE模型在低参数（<1M）情况下的高效表现，并成功应用于实时语义分割和深度估计等实际场景。

Conclusion: 通过整合多种视觉模态并利用PHG-MAE模型，本研究展示了即使在低参数（<1M）情况下，也能实现与高参数模型（~300M）相竞争的结果。同时，研究还开源了全自动数据管道，并在实际应用中验证了其在手持设备或网络摄像头上的实时语义分割能力。

Abstract: The real-world is inherently multi-modal at its core. Our tools observe and
take snapshots of it, in digital form, such as videos or sounds, however much
of it is lost. Similarly for actions and information passing between humans,
languages are used as a written form of communication. Traditionally, Machine
Learning models have been unimodal (i.e. rgb -> semantic or text ->
sentiment_class). Recent trends go towards bi-modality, where images and text
are learned together, however, in order to truly understand the world, we need
to integrate all these independent modalities. In this work we try to combine
as many visual modalities as we can using little to no human supervision. In
order to do this, we use pre-trained experts and procedural combinations
between them on top of raw videos using a fully autonomous data-pipeline, which
we also open-source. We then make use of PHG-MAE, a model specifically designed
to leverage multi-modal data. We show that this model which was efficiently
distilled into a low-parameter (<1M) can have competitive results compared to
models of ~300M parameters. We deploy this model and analyze the use-case of
real-time semantic segmentation from handheld devices or webcams on commodity
hardware. Finally, we deploy other off-the-shelf models using the same
framework, such as DPT for near real-time depth estimation.

</details>


### [15] [Joint Modeling of Big Five and HEXACO for Multimodal Apparent Personality-trait Recognition](https://arxiv.org/abs/2510.14203)
*Ryo Masumura,Shota Orihashi,Mana Ihori,Tomohiro Tanaka,Naoki Makishima,Taiga Yamane,Naotaka Kawata,Satoshi Suzuki,Taichi Katayama*

Main category: cs.CV

TL;DR: 本文提出联合建模Big Five和HEXACO的方法，实验验证其有效性，填补了HEXACO在多模态人格识别中的空白。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注Big Five，而忽视了HEXACO特质（如诚实-谦逊）及其与Big Five的关系。通过联合建模，有望提升对人类行为的理解。

Method: 提出了一种联合建模Big Five和HEXACO的机器学习方法，用于从多模态人类行为中自动识别人格特质。

Result: 实验表明，所提方法能有效识别Big Five和HEXACO特质。

Conclusion: 本文提出的联合建模方法有效识别了Big Five和HEXACO人格特质，实验验证了其有效性。

Abstract: This paper proposes a joint modeling method of the Big Five, which has long
been studied, and HEXACO, which has recently attracted attention in psychology,
for automatically recognizing apparent personality traits from multimodal human
behavior. Most previous studies have used the Big Five for multimodal apparent
personality-trait recognition. However, no study has focused on apparent HEXACO
which can evaluate an Honesty-Humility trait related to displaced aggression
and vengefulness, social-dominance orientation, etc. In addition, the
relationships between the Big Five and HEXACO when modeled by machine learning
have not been clarified. We expect awareness of multimodal human behavior to
improve by considering these relationships. The key advance of our proposed
method is to optimize jointly recognizing the Big Five and HEXACO. Experiments
using a self-introduction video dataset demonstrate that the proposed method
can effectively recognize the Big Five and HEXACO.

</details>


### [16] [LOTA: Bit-Planes Guided AI-Generated Image Detection](https://arxiv.org/abs/2510.14230)
*Hongsong Wang,Renxi Cheng,Yang Zhang,Chaolei Han,Jie Gui*

Main category: cs.CV

TL;DR: 本文提出了一种基于位平面图像处理和最大梯度补丁选择的轻量级方法，用于高效检测AI生成图像，显著提升了准确率和速度。


<details>
  <summary>Details</summary>
Motivation: 随着GAN和Diffusion模型的快速发展，区分AI生成图像与真实图像变得更加困难。现有方法通常计算成本高且无法捕捉原始图像中的固有噪声特征。

Method: 通过创新的位平面图像处理技术优化错误提取，设计了最大梯度补丁选择以放大噪声信号，并提出了轻量级且有效的分类头（包括基于噪声的分类器和噪声引导的分类器）。

Result: 在GenImage基准测试中，平均准确率达到98.9%（提升11.9%），并且在GAN到Diffusion和Diffusion到GAN的跨生成器测试中分别达到98.2%和99.2%的准确率。错误提取速度比现有方法快近百倍。

Conclusion: 本文提出的方法在GenImage基准测试中表现出色，平均准确率达到98.9%，并且具有卓越的跨生成器泛化能力。此外，该方法在毫秒级别完成错误提取，速度比现有方法快近百倍。

Abstract: The rapid advancement of GAN and Diffusion models makes it more difficult to
distinguish AI-generated images from real ones. Recent studies often use
image-based reconstruction errors as an important feature for determining
whether an image is AI-generated. However, these approaches typically incur
high computational costs and also fail to capture intrinsic noisy features
present in the raw images. To solve these problems, we innovatively refine
error extraction by using bit-plane-based image processing, as lower bit planes
indeed represent noise patterns in images. We introduce an effective bit-planes
guided noisy image generation and exploit various image normalization
strategies, including scaling and thresholding. Then, to amplify the noise
signal for easier AI-generated image detection, we design a maximum gradient
patch selection that applies multi-directional gradients to compute the noise
score and selects the region with the highest score. Finally, we propose a
lightweight and effective classification head and explore two different
structures: noise-based classifier and noise-guided classifier. Extensive
experiments on the GenImage benchmark demonstrate the outstanding performance
of our method, which achieves an average accuracy of \textbf{98.9\%}
(\textbf{11.9}\%~$\uparrow$) and shows excellent cross-generator generalization
capability. Particularly, our method achieves an accuracy of over 98.2\% from
GAN to Diffusion and over 99.2\% from Diffusion to GAN. Moreover, it performs
error extraction at the millisecond level, nearly a hundred times faster than
existing methods. The code is at https://github.com/hongsong-wang/LOTA.

</details>


### [17] [PIA: Deepfake Detection Using Phoneme-Temporal and Identity-Dynamic Analysis](https://arxiv.org/abs/2510.14241)
*Soumyya Kanti Datta,Tanvi Ranga,Chengzhe Sun,Siwei Lyu*

Main category: cs.CV

TL;DR: 论文提出PIA框架，结合音视频多模态信息，有效检测先进深度伪造技术。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法依赖于手动设计的音素-视位对齐阈值、基本帧级一致性检查或单模态检测策略，无法有效识别由先进生成模型（如GANs、扩散模型和神经渲染技术）生成的深度伪造内容。

Method: 采用了一种新颖的多模态音视频框架，结合了音素序列、唇部几何数据和高级面部身份嵌入。

Result: 提出的PIA框架通过识别多个互补模态间的不一致性，显著提高了对细微深度伪造篡改的检测能力。

Conclusion: 论文提出了一种多模态音视频框架PIA，通过整合语言、动态面部运动和面部识别线索，显著提升了检测现代深度伪造技术的能力。

Abstract: The rise of manipulated media has made deepfakes a particularly insidious
threat, involving various generative manipulations such as lip-sync
modifications, face-swaps, and avatar-driven facial synthesis. Conventional
detection methods, which predominantly depend on manually designed
phoneme-viseme alignment thresholds, fundamental frame-level consistency
checks, or a unimodal detection strategy, inadequately identify modern-day
deepfakes generated by advanced generative models such as GANs, diffusion
models, and neural rendering techniques. These advanced techniques generate
nearly perfect individual frames yet inadvertently create minor temporal
discrepancies frequently overlooked by traditional detectors. We present a
novel multimodal audio-visual framework, Phoneme-Temporal and Identity-Dynamic
Analysis(PIA), incorporating language, dynamic face motion, and facial
identification cues to address these limitations. We utilize phoneme sequences,
lip geometry data, and advanced facial identity embeddings. This integrated
method significantly improves the detection of subtle deepfake alterations by
identifying inconsistencies across multiple complementary modalities. Code is
available at https://github.com/skrantidatta/PIA

</details>


### [18] [Event Interval Modulation: A Novel Scheme for Event-based Optical Camera Communication](https://arxiv.org/abs/2510.14245)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出新型事件间隔调制方案EIM，实验证明其在速度和距离上优于现有方法，为事件型OCC设定了新基准。


<details>
  <summary>Details</summary>
Motivation: 传统OCC系统存在低比特率和高处理负载的问题，而现有事件型OCC系统未能充分利用EVS的独特特性，因此需要一种新的调制方案。

Method: 通过理论建模和概念验证实验，首先优化EVS参数以适应EIM，然后确定最大调制阶数，并基于实验参数进行传输测试。

Result: 实验成功实现了室内环境下28 kbps（10米）和8.4 kbps（50米）的传输速率，刷新了事件型OCC系统的比特率记录。

Conclusion: 本文提出了一种新型调制方案EIM，专为事件型OCC设计，实验证明其在传输速度和距离上均优于现有方法，为事件型OCC系统设定了新的性能基准。

Abstract: Optical camera communication (OCC) represents a promising visible light
communication technology. Nonetheless, typical OCC systems utilizing
frame-based cameras are encumbered by limitations, including low bit rate and
high processing load. To address these issues, OCC system utilizing an
event-based vision sensor (EVS) as receivers have been proposed. The EVS
enables high-speed, low-latency, and robust communication due to its
asynchronous operation and high dynamic range. In existing event-based OCC
systems, conventional modulation schemes such as on-off keying (OOK) and pulse
position modulation have been applied, however, to the best of our knowledge,
no modulation method has been proposed that fully exploits the unique
characteristics of the EVS. This paper proposes a novel modulation scheme,
called the event interval modulation (EIM) scheme, specifically designed for
event-based OCC. EIM enables improvement in transmission speed by modulating
information using the intervals between events. This paper proposes a
theoretical model of EIM and conducts a proof-of-concept experiment. First, the
parameters of the EVS are tuned and customized to optimize the frequency
response specifically for EIM. Then, the maximum modulation order usable in EIM
is determined experimentally. We conduct transmission experiments based on the
obtained parameters. Finally, we report successful transmission at 28 kbps over
10 meters and 8.4 kbps over 50 meters in an indoor environment. This sets a new
benchmark for bit rate in event-based OCC systems.

</details>


### [19] [MACE: Mixture-of-Experts Accelerated Coordinate Encoding for Large-Scale Scene Localization and Rendering](https://arxiv.org/abs/2510.14251)
*Mingkai Liu,Dikai Fan,Haohua Que,Haojia Gao,Xiao Liu,Shuxue Peng,Meixia Lin,Shengyu Gu,Ruicong Ye,Wanli Qiu,Handong Yao,Ruopeng Zhang,Xianliang Huang*

Main category: cs.CV

TL;DR: MACE方法通过门控网络和ALF-LB策略，高效解决了大规模场景定位和渲染的高计算成本问题，仅需10分钟训练即可实现高质量结果。


<details>
  <summary>Details</summary>
Motivation: 解决大规模场景中定位和渲染的高计算成本问题，以及现有Scene Coordinate Regression (SCR)方法在扩展至大规模场景时的网络容量限制。

Method: 提出了Mixed Expert-based Accelerated Coordinate Encoding (MACE)方法，包括门控网络隐式分类和选择子网络，以及Auxiliary-Loss-Free Load Balancing (ALF-LB)策略。

Result: 在Cambridge测试集上，仅需10分钟训练即可实现高质量渲染结果，显著降低了成本并保持高精度。

Conclusion: MACE方法通过引入门控网络和ALF-LB策略，显著降低了大规模场景定位和渲染的计算成本，同时保持了高精度，为大规模场景应用提供了高效解决方案。

Abstract: Efficient localization and high-quality rendering in large-scale scenes
remain a significant challenge due to the computational cost involved. While
Scene Coordinate Regression (SCR) methods perform well in small-scale
localization, they are limited by the capacity of a single network when
extended to large-scale scenes. To address these challenges, we propose the
Mixed Expert-based Accelerated Coordinate Encoding method (MACE), which enables
efficient localization and high-quality rendering in large-scale scenes.
Inspired by the remarkable capabilities of MOE in large model domains, we
introduce a gating network to implicitly classify and select sub-networks,
ensuring that only a single sub-network is activated during each inference.
Furtheremore, we present Auxiliary-Loss-Free Load Balancing(ALF-LB) strategy to
enhance the localization accuracy on large-scale scene. Our framework provides
a significant reduction in costs while maintaining higher precision, offering
an efficient solution for large-scale scene applications. Additional
experiments on the Cambridge test set demonstrate that our method achieves
high-quality rendering results with merely 10 minutes of training.

</details>


### [20] [Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization](https://arxiv.org/abs/2510.14255)
*Liao Shen,Wentao Jiang,Yiran Zhu,Tiezheng Ge,Zhiguo Cao,Bo Zheng*

Main category: cs.CV

TL;DR: IPRO是一种通过强化学习优化扩散模型的新方法，显著提升了图像到视频生成中的身份一致性。


<details>
  <summary>Details</summary>
Motivation: 现有图像到视频（I2V）生成模型在保持输入图像与生成视频中人物身份一致性方面存在困难，尤其是在面部表情变化大或运动幅度大时，这一问题更为突出。

Method: 提出了一种基于强化学习的视频扩散框架（IPRO），通过面部身份评分器优化扩散模型，并引入了KL散度正则化以稳定训练。

Result: 在Wan 2.2 I2V模型和内部I2V模型上的大量实验证明了IPRO方法的有效性。

Conclusion: 本文提出的IPRO方法通过强化学习优化扩散模型，显著提升了从静态图像生成视频时的身份一致性，尤其在面部表情变化大或运动幅度大的情况下表现优异。

Abstract: Recent advances in image-to-video (I2V) generation have achieved remarkable
progress in synthesizing high-quality, temporally coherent videos from static
images. Among all the applications of I2V, human-centric video generation
includes a large portion. However, existing I2V models encounter difficulties
in maintaining identity consistency between the input human image and the
generated video, especially when the person in the video exhibits significant
expression changes and movements. This issue becomes critical when the human
face occupies merely a small fraction of the image. Since humans are highly
sensitive to identity variations, this poses a critical yet under-explored
challenge in I2V generation. In this paper, we propose Identity-Preserving
Reward-guided Optimization (IPRO), a novel video diffusion framework based on
reinforcement learning to enhance identity preservation. Instead of introducing
auxiliary modules or altering model architectures, our approach introduces a
direct and effective tuning algorithm that optimizes diffusion models using a
face identity scorer. To improve performance and accelerate convergence, our
method backpropagates the reward signal through the last steps of the sampling
chain, enabling richer gradient feedback. We also propose a novel facial
scoring mechanism that treats faces in ground-truth videos as facial feature
pools, providing multi-angle facial information to enhance generalization. A
KL-divergence regularization is further incorporated to stabilize training and
prevent overfitting to the reward signal. Extensive experiments on Wan 2.2 I2V
model and our in-house I2V model demonstrate the effectiveness of our method.
Our project and code are available at
\href{https://ipro-alimama.github.io/}{https://ipro-alimama.github.io/}.

</details>


### [21] [Identity-GRPO: Optimizing Multi-Human Identity-preserving Video Generation via Reinforcement Learning](https://arxiv.org/abs/2510.14256)
*Xiangyu Meng,Zixian Zhang,Zhenghao Zhang,Junchao Liao,Long Qin,Weizhi Wang*

Main category: cs.CV

TL;DR: Identity-GRPO通过人类反馈优化多人类身份一致性，显著提升视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态交互中难以保持多人类身份一致性，而这一问题在多角色场景中至关重要。

Method: 构建了一个基于大规模偏好数据集的视频奖励模型，并采用针对多人类一致性的GRPO变体进行优化。

Result: 实验表明，Identity-GRPO在人类一致性指标上比基线方法提高了18.9%。

Conclusion: Identity-GRPO显著提升了多人类身份一致性，为个性化视频生成提供了可行的强化学习对齐方案。

Abstract: While advanced methods like VACE and Phantom have advanced video generation
for specific subjects in diverse scenarios, they struggle with multi-human
identity preservation in dynamic interactions, where consistent identities
across multiple characters are critical. To address this, we propose
Identity-GRPO, a human feedback-driven optimization pipeline for refining
multi-human identity-preserving video generation. First, we construct a video
reward model trained on a large-scale preference dataset containing
human-annotated and synthetic distortion data, with pairwise annotations
focused on maintaining human consistency throughout the video. We then employ a
GRPO variant tailored for multi-human consistency, which greatly enhances both
VACE and Phantom. Through extensive ablation studies, we evaluate the impact of
annotation quality and design choices on policy optimization. Experiments show
that Identity-GRPO achieves up to 18.9% improvement in human consistency
metrics over baseline methods, offering actionable insights for aligning
reinforcement learning with personalized video generation.

</details>


### [22] [MatchAttention: Matching the Relative Positions for High-Resolution Cross-View Matching](https://arxiv.org/abs/2510.14260)
*Tingman Yan,Tao Liu,Xilian Yang,Qunfei Zhao,Zeyang Xia*

Main category: cs.CV

TL;DR: 论文提出MatchAttention机制和MatchDecoder解码器，通过动态匹配和分层处理提升高分辨率跨视图匹配效率，在多个数据集上实现高性能且低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 高分辨率图像的跨视图匹配由于现有交叉注意力的二次复杂性和缺乏显式匹配约束而具有挑战性。

Method: 提出了一种名为MatchAttention的注意力机制，通过BilinearSoftmax实现连续可微的滑动窗口注意力采样，并设计了MatchDecoder作为分层跨视图解码器的核心组件。此外，还引入了门控交叉MatchAttention和一致性约束损失以处理跨视图遮挡问题。

Result: MatchStereo-B在Middlebury基准测试中平均误差排名第一，KITTI分辨率推理仅需29ms；MatchStereo-T可在0.1秒内处理4K UHD图像，仅需3GB GPU内存。模型在KITTI 2012、KITTI 2015、ETH3D和Spring flow数据集上也实现了最先进的性能。

Conclusion: 该论文提出的MatchAttention机制和MatchDecoder解码器通过动态匹配相对位置和分层处理，显著提升了高分辨率图像的跨视图匹配效率和准确性，并在多个公共数据集上实现了最先进的性能。

Abstract: Cross-view matching is fundamentally achieved through cross-attention
mechanisms. However, matching of high-resolution images remains challenging due
to the quadratic complexity and lack of explicit matching constraints in the
existing cross-attention. This paper proposes an attention mechanism,
MatchAttention, that dynamically matches relative positions. The relative
position determines the attention sampling center of the key-value pairs given
a query. Continuous and differentiable sliding-window attention sampling is
achieved by the proposed BilinearSoftmax. The relative positions are
iteratively updated through residual connections across layers by embedding
them into the feature channels. Since the relative position is exactly the
learning target for cross-view matching, an efficient hierarchical cross-view
decoder, MatchDecoder, is designed with MatchAttention as its core component.
To handle cross-view occlusions, gated cross-MatchAttention and a
consistency-constrained loss are proposed. These two components collectively
mitigate the impact of occlusions in both forward and backward passes, allowing
the model to focus more on learning matching relationships. When applied to
stereo matching, MatchStereo-B ranked 1st in average error on the public
Middlebury benchmark and requires only 29ms for KITTI-resolution inference.
MatchStereo-T can process 4K UHD images in 0.1 seconds using only 3GB of GPU
memory. The proposed models also achieve state-of-the-art performance on KITTI
2012, KITTI 2015, ETH3D, and Spring flow datasets. The combination of high
accuracy and low computational complexity makes real-time, high-resolution, and
high-accuracy cross-view matching possible. Code is available at
https://github.com/TingmanYan/MatchAttention.

</details>


### [23] [Experimental Demonstration of Event-based Optical Camera Communication in Long-Range Outdoor Environment](https://arxiv.org/abs/2510.14266)
*Miu Sumino,Mayu Ishii,Shun Kaizu,Daisuke Hisano,Yu Nakayama*

Main category: cs.CV

TL;DR: 提出一种基于事件视觉传感器的鲁棒解调方案，首次在户外实验中实现低误码率的高性能通信。


<details>
  <summary>Details</summary>
Motivation: 提升光学相机通信系统的解调鲁棒性。

Method: 结合OOK与切换解调以及数字锁相环技术。

Result: 在200米-60kbps和400米-30kbps的户外实验中，实现了BER < 10^{-3}。

Conclusion: 本文提出了一种基于事件视觉传感器的鲁棒解调方案，首次在户外实验中实现了200米-60kbps和400米-30kbps下BER < 10^{-3}的性能。

Abstract: We propose a robust demodulation scheme for optical camera communication
systems using an event-based vision sensor, combining OOK with toggle
demodulation and a digital phase-locked loop. This is the first report to
achieve a $\mathrm{BER} < 10^{-3}$ at 200m-60kbps and 400m-30kbps in outdoor
experiments.

</details>


### [24] [CLEAR: Causal Learning Framework For Robust Histopathology Tumor Detection Under Out-Of-Distribution Shifts](https://arxiv.org/abs/2510.14273)
*Kieu-Anh Truong Thi,Huy-Hieu Pham,Duc-Trong Le*

Main category: cs.CV

TL;DR: 提出基于因果推断的新方法解决组织病理学领域偏移问题，通过结合语义特征和减少混杂因素，在跨域数据集上性能提升7%。


<details>
  <summary>Details</summary>
Motivation: 组织病理学中的领域偏移（由采集过程或数据源差异引起）对深度学习模型的泛化能力构成重大挑战。现有方法主要依赖对齐特征分布或引入统计变化来建模统计相关性，但常忽略因果关系。

Method: 提出了一种基于因果推断的新框架，利用语义特征并减少混杂因素的影响。该方法通过设计转换策略，明确结合中介变量和观察到的组织切片，实现了前门原则。

Result: 在CAMELYON17数据集和私有组织病理学数据集上验证了方法，跨未知领域表现一致提升，性能最高提升7%，优于现有基线方法。

Conclusion: 因果推断作为一种强大工具，在解决组织病理学图像分析中的领域偏移问题上展现出潜力。

Abstract: Domain shift in histopathology, often caused by differences in acquisition
processes or data sources, poses a major challenge to the generalization
ability of deep learning models. Existing methods primarily rely on modeling
statistical correlations by aligning feature distributions or introducing
statistical variation, yet they often overlook causal relationships. In this
work, we propose a novel causal-inference-based framework that leverages
semantic features while mitigating the impact of confounders. Our method
implements the front-door principle by designing transformation strategies that
explicitly incorporate mediators and observed tissue slides. We validate our
method on the CAMELYON17 dataset and a private histopathology dataset,
demonstrating consistent performance gains across unseen domains. As a result,
our approach achieved up to a 7% improvement in both the CAMELYON17 dataset and
the private histopathology dataset, outperforming existing baselines. These
results highlight the potential of causal inference as a powerful tool for
addressing domain shift in histopathology image analysis.

</details>


### [25] [Watermarking for Factuality: Guiding Vision-Language Models Toward Truth via Tri-layer Contrastive Decoding](https://arxiv.org/abs/2510.14304)
*Kyungryul Back,Seongbeom Park,Milim Kim,Mincheol Kwon,SangHyeok Lee,Hyunyoung Lee,Junhee Cho,Seunghyun Park,Jinkyu Kim*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的三层对比解码与水印方法，有效减少大型视觉语言模型的幻觉问题，生成更视觉基础化的响应。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态任务中表现出色，但仍存在幻觉问题，如过度依赖单一模态或记忆训练数据而缺乏输出基础。

Method: 训练免费的三层对比解码与水印方法，包括选择成熟层和业余层、使用水印相关问题确定枢轴层，以及应用三层对比解码生成最终输出。

Result: 在POPE、MME和AMBER等公共基准测试中，该方法在减少LVLMs幻觉方面取得了最先进的性能。

Conclusion: 论文提出的三层对比解码与水印方法在减少LVLMs幻觉方面表现出色，生成了更具视觉基础性的响应。

Abstract: Large Vision-Language Models (LVLMs) have recently shown promising results on
various multimodal tasks, even achieving human-comparable performance in
certain cases. Nevertheless, LVLMs remain prone to hallucinations -- they often
rely heavily on a single modality or memorize training data without properly
grounding their outputs. To address this, we propose a training-free, tri-layer
contrastive decoding with watermarking, which proceeds in three steps: (1)
select a mature layer and an amateur layer among the decoding layers, (2)
identify a pivot layer using a watermark-related question to assess whether the
layer is visually well-grounded, and (3) apply tri-layer contrastive decoding
to generate the final output. Experiments on public benchmarks such as POPE,
MME and AMBER demonstrate that our method achieves state-of-the-art performance
in reducing hallucinations in LVLMs and generates more visually grounded
responses.

</details>


### [26] [A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection](https://arxiv.org/abs/2510.14314)
*Shivangi Yadav,Arun Ross*

Main category: cs.CV

TL;DR: MID-StyleGAN 是一种结合扩散模型和 GAN 的新框架，用于生成合成眼部图像以解决虹膜生物识别中的数据稀缺问题，显著提升了展示攻击检测系统的性能。


<details>
  <summary>Details</summary>
Motivation: 由于构建和成像展示攻击（PAs）的固有困难，用于训练和评估虹膜展示攻击检测（PAD）技术的数据集稀缺。为了解决这一问题，研究团队提出了 MID-StyleGAN，用于生成合成眼部图像以捕获多个域（如真实、打印眼睛和彩色隐形眼镜）中的 PA 和真实特征。

Method: MID-StyleGAN 结合了扩散模型和生成对抗网络（GANs）的优势，采用多域架构实现真实眼部图像与不同展示攻击域之间的转换，并使用了针对眼部数据量身定制的自适应损失函数以保持域一致性。

Result: 实验证明，MID-StyleGAN 在生成高质量合成眼部图像方面优于现有方法。生成的合成数据显著提升了 PAD 系统的性能，例如在 LivDet2020 数据集上，1% 错误检测率下的真实检测率从 93.41% 提高到 98.72%。

Conclusion: MID-StyleGAN 通过结合扩散模型和生成对抗网络的优点，成功生成了高质量且多样化的合成眼部图像，显著提升了展示攻击检测系统的性能，为解决虹膜和眼部生物识别中的数据稀缺问题提供了可扩展的解决方案。

Abstract: An iris biometric system can be compromised by presentation attacks (PAs)
where artifacts such as artificial eyes, printed eye images, or cosmetic
contact lenses are presented to the system. To counteract this, several
presentation attack detection (PAD) methods have been developed. However, there
is a scarcity of datasets for training and evaluating iris PAD techniques due
to the implicit difficulties in constructing and imaging PAs. To address this,
we introduce the Multi-domain Image Translative Diffusion StyleGAN
(MID-StyleGAN), a new framework for generating synthetic ocular images that
captures the PA and bonafide characteristics in multiple domains such as
bonafide, printed eyes and cosmetic contact lens. MID-StyleGAN combines the
strengths of diffusion models and generative adversarial networks (GANs) to
produce realistic and diverse synthetic data. Our approach utilizes a
multi-domain architecture that enables the translation between bonafide ocular
images and different PA domains. The model employs an adaptive loss function
tailored for ocular data to maintain domain consistency. Extensive experiments
demonstrate that MID-StyleGAN outperforms existing methods in generating
high-quality synthetic ocular images. The generated data was used to
significantly enhance the performance of PAD systems, providing a scalable
solution to the data scarcity problem in iris and ocular biometrics. For
example, on the LivDet2020 dataset, the true detect rate at 1% false detect
rate improved from 93.41% to 98.72%, showcasing the impact of the proposed
method.

</details>


### [27] [Vision-Centric Activation and Coordination for Multimodal Large Language Models](https://arxiv.org/abs/2510.14349)
*Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin*

Main category: cs.CV

TL;DR: VaCo通过视觉中心的激活和协调优化了MLLMs的表示，解决了主流MLLMs忽略视觉信息的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 主流MLLMs仅通过文本标记的下一个标记预测进行监督，忽略了视觉中心的关键信息，这限制了其分析能力。为解决这一问题，作者提出了VaCo。

Method: VaCo引入了视觉判别对齐，通过从多个视觉基础模型（VFMs）中提取任务感知的感知特征，统一了MLLMs中文本和视觉输出的优化。具体包括可学习的模块化任务查询（MTQs）和视觉对齐层（VALs），并在多样VFMs的监督下激活特定视觉信号。此外，设计的Token Gateway Mask（TGM）协调了不同VFMs之间的表示冲突。

Result: 大量实验表明，VaCo显著提升了不同MLLMs在各种基准测试中的性能，展示了其在视觉理解方面的卓越能力。

Conclusion: VaCo通过视觉中心的激活和协调优化了MLLMs的表示，显著提升了不同MLLMs在各种基准测试中的性能，展示了其在视觉理解方面的卓越能力。

Abstract: Multimodal large language models (MLLMs) integrate image features from visual
encoders with LLMs, demonstrating advanced comprehension capabilities. However,
mainstream MLLMs are solely supervised by the next-token prediction of textual
tokens, neglecting critical vision-centric information essential for analytical
abilities. To track this dilemma, we introduce VaCo, which optimizes MLLM
representations through Vision-Centric activation and Coordination from
multiple vision foundation models (VFMs). VaCo introduces visual discriminative
alignment to integrate task-aware perceptual features extracted from VFMs,
thereby unifying the optimization of both textual and visual outputs in MLLMs.
Specifically, we incorporate the learnable Modular Task Queries (MTQs) and
Visual Alignment Layers (VALs) into MLLMs, activating specific visual signals
under the supervision of diverse VFMs. To coordinate representation conflicts
across VFMs, the crafted Token Gateway Mask (TGM) restricts the information
flow among multiple groups of MTQs. Extensive experiments demonstrate that VaCo
significantly improves the performance of different MLLMs on various
benchmarks, showcasing its superior capabilities in visual comprehension.

</details>


### [28] [Leveraging Cycle-Consistent Anchor Points for Self-Supervised RGB-D Registration](https://arxiv.org/abs/2510.14354)
*Siddharth Tourani,Jayaram Reddy,Sarvesh Thakur,K Madhava Krishna,Muhammad Haris Khan,N Dinesh Reddy*

Main category: cs.CV

TL;DR: 提出基于循环一致性关键点和GRU姿态块的自监督RGB-D配准方法，显著提升配准精度，超越现有自监督方法。


<details>
  <summary>Details</summary>
Motivation: 随着消费级深度相机的普及，大量未标记的RGB-D数据可用，如何利用这些数据进行场景几何推理成为关键问题。现有方法多依赖几何和特征相似性，本文探索了不同的技术路径。

Method: 采用循环一致性关键点作为显著点以增强匹配时的空间一致性约束，并引入结合GRU循环单元与变换同步的新型姿态块，融合历史和多视角数据。

Result: 该方法在ScanNet和3DMatch数据集上表现优于现有自监督配准方法，部分指标甚至超过旧有监督方法。将其组件集成到现有方法中也验证了其有效性。

Conclusion: 本文提出了一种利用循环一致性关键点和新型姿态块的自监督RGB-D配准方法，显著提高了配准精度，并在ScanNet和3DMatch数据集上超越了现有自监督方法，甚至部分监督方法。

Abstract: With the rise in consumer depth cameras, a wealth of unlabeled RGB-D data has
become available. This prompts the question of how to utilize this data for
geometric reasoning of scenes. While many RGB-D registration meth- ods rely on
geometric and feature-based similarity, we take a different approach. We use
cycle-consistent keypoints as salient points to enforce spatial coherence
constraints during matching, improving correspondence accuracy. Additionally,
we introduce a novel pose block that combines a GRU recurrent unit with
transformation synchronization, blending historical and multi-view data. Our
approach surpasses previous self- supervised registration methods on ScanNet
and 3DMatch, even outperforming some older supervised methods. We also
integrate our components into existing methods, showing their effectiveness.

</details>


### [29] [Spatial Preference Rewarding for MLLMs Spatial Understanding](https://arxiv.org/abs/2510.14374)
*Han Qiu,Peng Gao,Lewei Lu,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: SPR通过奖励详细响应和精确定位，提升MLLMs的细粒度空间理解能力，实验证明有效且训练开销小。


<details>
  <summary>Details</summary>
Motivation: MLLMs在细粒度空间感知能力上存在不足，现有方法缺乏对实际响应的直接监督。

Method: SPR引入语义和定位评分系统，全面评估MLLM生成的描述质量，并通过直接偏好优化增强细粒度对齐。

Result: 实验表明，SPR在标准参考和基准测试中显著提升了MLLM的空间理解能力。

Conclusion: SPR方法通过奖励MLLMs生成详细且定位准确的响应，有效提升了其空间理解能力，且训练开销最小。

Abstract: Multimodal large language models~(MLLMs) have demonstrated promising spatial
understanding capabilities, such as referencing and grounding object
descriptions. Despite their successes, MLLMs still fall short in fine-grained
spatial perception abilities, such as generating detailed region descriptions
or accurately localizing objects. Additionally, they often fail to respond to
the user's requirements for desired fine-grained spatial understanding. This
issue might arise because existing approaches primarily focus on tuning MLLMs
to model pre-annotated instruction data to inject spatial knowledge, without
direct supervision of MLLMs' actual responses. We address this issue by SPR, a
Spatial Preference Rewarding~(SPR) approach that enhances MLLMs' spatial
capabilities by rewarding MLLMs' detailed responses with precise object
localization over vague or inaccurate responses. With randomly selected image
regions and region descriptions from MLLMs, SPR introduces semantic and
localization scores to comprehensively evaluate the text quality and
localization quality in MLLM-generated descriptions. We also refine the MLLM
descriptions with better localization accuracy and pair the best-scored
refinement with the initial descriptions of the lowest score for direct
preference optimization, thereby enhancing fine-grained alignment with visual
input. Extensive experiments over standard referring and grounding benchmarks
show that SPR improves MLLM spatial understanding capabilities effectively with
minimal overhead in training. Data and code will be released at
https://github.com/hanqiu-hq/SPR

</details>


### [30] [DOS: Directional Object Separation in Text Embeddings for Multi-Object Image Generation](https://arxiv.org/abs/2510.14376)
*Dongnam Byun,Jungwon Park,Jumgmin Ko,Changin Choi,Wonjong Rhee*

Main category: cs.CV

TL;DR: DOS通过修改CLIP文本嵌入，有效解决了多对象图像生成中的对象忽略和混合问题，显著提升了生成质量和成功率。


<details>
  <summary>Details</summary>
Motivation: 当前文本到图像生成模型在处理涉及多个对象的提示时，常出现对象忽略或混合的问题。本文通过深入研究，识别了四种导致此类问题的场景，并基于对CLIP嵌入的两个关键观察，提出了改进方案。

Method: 提出了DOS（定向对象分离）方法，通过修改三种类型的CLIP文本嵌入，再将其输入到文本到图像模型中。

Result: 实验结果表明，DOS在多对象图像生成任务中显著提高了成功率，并减少了对象混合。在人类评估中，DOS在四个基准测试中以26.24%-43.04%的优势超越四种竞争方法。

Conclusion: DOS是一种实用且有效的解决方案，显著提高了多对象图像生成的成功率，并减少了对象混合问题。

Abstract: Recent progress in text-to-image (T2I) generative models has led to
significant improvements in generating high-quality images aligned with text
prompts. However, these models still struggle with prompts involving multiple
objects, often resulting in object neglect or object mixing. Through extensive
studies, we identify four problematic scenarios, Similar Shapes, Similar
Textures, Dissimilar Background Biases, and Many Objects, where inter-object
relationships frequently lead to such failures. Motivated by two key
observations about CLIP embeddings, we propose DOS (Directional Object
Separation), a method that modifies three types of CLIP text embeddings before
passing them into text-to-image models. Experimental results show that DOS
consistently improves the success rate of multi-object image generation and
reduces object mixing. In human evaluations, DOS significantly outperforms four
competing methods, receiving 26.24%-43.04% more votes across four benchmarks.
These results highlight DOS as a practical and effective solution for improving
multi-object image generation.

</details>


### [31] [DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights](https://arxiv.org/abs/2510.14383)
*Danish Ali,Ajmal Mian,Naveed Akhtar,Ghulam Mubashar Hassan*

Main category: cs.CV

TL;DR: DRBD-Mamba模型通过高效3D分割设计，在脑肿瘤分割任务中实现性能与效率的双重突破。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba模型在脑肿瘤分割中存在计算开销大且鲁棒性未充分验证的问题。

Method: 提出双分辨率双向Mamba（DRBD-Mamba），利用空间填充曲线减少计算开销，结合门控融合模块和量化块增强特征表示。

Result: 在BraTS2023测试集上，模型在肿瘤核心和增强肿瘤区域分别取得1.75%和0.93%的Dice提升，效率提升15倍。

Conclusion: DRBD-Mamba模型在保持高分割精度的同时，显著提升了计算效率，并在多样性数据分区上展现出鲁棒性，优于现有方法。

Abstract: Accurate brain tumor segmentation is significant for clinical diagnosis and
treatment. It is challenging due to the heterogeneity of tumor subregions.
Mamba-based State Space Models have demonstrated promising performance.
However, they incur significant computational overhead due to sequential
feature computation across multiple spatial axes. Moreover, their robustness
across diverse BraTS data partitions remains largely unexplored, leaving a
critical gap in reliable evaluation. To address these limitations, we propose
dual-resolution bi-directional Mamba (DRBD-Mamba), an efficient 3D segmentation
model that captures multi-scale long-range dependencies with minimal
computational overhead. We leverage a space-filling curve to preserve spatial
locality during 3D-to-1D feature mapping, thereby reducing reliance on
computationally expensive multi-axial feature scans. To enrich feature
representation, we propose a gated fusion module that adaptively integrates
forward and reverse contexts, along with a quantization block that discretizes
features to improve robustness. In addition, we propose five systematic folds
on BraTS2023 for rigorous evaluation of segmentation techniques under diverse
conditions and present detailed analysis of common failure scenarios. On the
20\% test set used by recent methods, our model achieves Dice improvements of
0.10\% for whole tumor, 1.75\% for tumor core, and 0.93\% for enhancing tumor.
Evaluations on the proposed systematic five folds demonstrate that our model
maintains competitive whole tumor accuracy while achieving clear average Dice
gains of 0.86\% for tumor core and 1.45\% for enhancing tumor over existing
state-of-the-art. Furthermore, our model attains 15 times improvement in
efficiency while maintaining high segmentation accuracy, highlighting its
robustness and computational advantage over existing approaches.

</details>


### [32] [BoardVision: Deployment-ready and Robust Motherboard Defect Detection with YOLO+Faster-RCNN Ensemble](https://arxiv.org/abs/2510.14389)
*Brandon Hill,Kma Solaiman*

Main category: cs.CV

TL;DR: BoardVision提出了一种轻量级集成方法CTV Voter，结合YOLOv7和Faster R-CNN的优势，提升了主板缺陷检测的精度和召回率，并发布了可部署的GUI工具。


<details>
  <summary>Details</summary>
Motivation: 组装级主板缺陷检测在电子制造中至关重要，但现有研究主要集中在裸板或痕迹级缺陷，组装级检测尚未充分探索。

Method: 提出了一个名为BoardVision的可重复框架，用于检测组装级主板缺陷。通过基准测试YOLOv7和Faster R-CNN在MiracleFactory主板数据集上的表现，并提出了一个轻量级集成方法CTV Voter来平衡精度和召回率。

Result: BoardVision在MiracleFactory数据集上进行了系统比较，CTV Voter有效平衡了精度和召回率，并在实际扰动条件下展示了稳定性。

Conclusion: BoardVision框架通过结合YOLOv7和Faster R-CNN的优势，提出了一种轻量级集成方法CTV Voter，显著提升了主板缺陷检测的精度和召回率，并发布了可部署的GUI工具，实现了从研究到实际应用的过渡。

Abstract: Motherboard defect detection is critical for ensuring reliability in
high-volume electronics manufacturing. While prior research in PCB inspection
has largely targeted bare-board or trace-level defects, assembly-level
inspection of full motherboards inspection remains underexplored. In this work,
we present BoardVision, a reproducible framework for detecting assembly-level
defects such as missing screws, loose fan wiring, and surface scratches. We
benchmark two representative detectors - YOLOv7 and Faster R-CNN, under
controlled conditions on the MiracleFactory motherboard dataset, providing the
first systematic comparison in this domain. To mitigate the limitations of
single models, where YOLO excels in precision but underperforms in recall and
Faster R-CNN shows the reverse, we propose a lightweight ensemble,
Confidence-Temporal Voting (CTV Voter), that balances precision and recall
through interpretable rules. We further evaluate robustness under realistic
perturbations including sharpness, brightness, and orientation changes,
highlighting stability challenges often overlooked in motherboard defect
detection. Finally, we release a deployable GUI-driven inspection tool that
bridges research evaluation with operator usability. Together, these
contributions demonstrate how computer vision techniques can transition from
benchmark results to practical quality assurance for assembly-level motherboard
manufacturing.

</details>


### [33] [DCMIL: A Progressive Representation Learning Model of Whole Slide Images for Cancer Prognosis Analysis](https://arxiv.org/abs/2510.14403)
*Chao Tu,Kun Huang,Jie Zhang,Qianjin Feng,Yu Zhang,Zhenyuan Ning*

Main category: cs.CV

TL;DR: DCMIL是一种无需密集标注的渐进式学习模型，能高效处理千兆像素级WSI用于癌症预后，实验显示其在12种癌症类型中优于现有方法，并具备生成新生物学见解的潜力。


<details>
  <summary>Details</summary>
Motivation: 计算病理学在利用全切片图像（WSI）量化形态异质性和开发客观癌症预后模型方面具有潜力，但受限于千兆像素级输入的计算瓶颈和密集手动标注的稀缺性。现有方法常忽略多放大倍数WSI中的细粒度信息和肿瘤微环境的变化。

Method: 提出了一种名为双课程对比多实例学习（DCMIL）的渐进式表示学习模型，该模型无需密集标注，可直接将千兆像素级WSI转化为预后预测。

Result: 在12种癌症类型（5,954名患者，1254万块图像块）的实验中，DCMIL表现优于标准WSI预后模型，并能识别预后关键区域、提供实例不确定性估计及捕捉形态差异。

Conclusion: DCMIL模型在12种癌症类型的大规模实验中表现优异，不仅超越了现有的WSI预后模型，还能识别细粒度的预后关键区域，提供稳健的实例不确定性估计，并捕捉正常与肿瘤组织的形态差异，具有生成新生物学见解的潜力。

Abstract: The burgeoning discipline of computational pathology shows promise in
harnessing whole slide images (WSIs) to quantify morphological heterogeneity
and develop objective prognostic modes for human cancers. However, progress is
impeded by the computational bottleneck of gigapixel-size inputs and the
scarcity of dense manual annotations. Current methods often overlook
fine-grained information across multi-magnification WSIs and variations in
tumor microenvironments. Here, we propose an easy-to-hard progressive
representation learning model, termed dual-curriculum contrastive
multi-instance learning (DCMIL), to efficiently process WSIs for cancer
prognosis. The model does not rely on dense annotations and enables the direct
transformation of gigapixel-size WSIs into outcome predictions. Extensive
experiments on twelve cancer types (5,954 patients, 12.54 million tiles)
demonstrate that DCMIL outperforms standard WSI-based prognostic models.
Additionally, DCMIL identifies fine-grained prognosis-salient regions, provides
robust instance uncertainty estimation, and captures morphological differences
between normal and tumor tissues, with the potential to generate new biological
insights. All codes have been made publicly accessible at
https://github.com/tuuuc/DCMIL.

</details>


### [34] [Real-Time Neural Video Compression with Unified Intra and Inter Coding](https://arxiv.org/abs/2510.14431)
*Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu*

Main category: cs.CV

TL;DR: 论文提出一种统一帧内和帧间编码的NVC框架，通过双向压缩设计显著提升压缩效率并解决现有方案的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有NVC方案在处理遮挡、新内容及帧间误差传播方面存在局限性，需要改进以提升压缩效率和稳定性。

Method: 引入帧内编码工具，提出统一帧内和帧间编码的NVC框架，并设计同时两帧压缩方案以双向利用帧间冗余。

Result: 实验结果表明，该方案平均比DCVC-RT降低了10.7%的BD-rate，帧间比特率和质量更稳定，且保持实时性能。

Conclusion: 该论文提出的NVC框架通过统一帧内和帧间编码，有效解决了现有NVC方案在处理遮挡、新内容及帧间误差传播方面的局限性，显著提升了压缩效率并保持了实时编码/解码性能。

Abstract: Neural video compression (NVC) technologies have advanced rapidly in recent
years, yielding state-of-the-art schemes such as DCVC-RT that offer superior
compression efficiency to H.266/VVC and real-time encoding/decoding
capabilities. Nonetheless, existing NVC schemes have several limitations,
including inefficiency in dealing with disocclusion and new content, interframe
error propagation and accumulation, among others. To eliminate these
limitations, we borrow the idea from classic video coding schemes, which allow
intra coding within inter-coded frames. With the intra coding tool enabled,
disocclusion and new content are properly handled, and interframe error
propagation is naturally intercepted without the need for manual refresh
mechanisms. We present an NVC framework with unified intra and inter coding,
where every frame is processed by a single model that is trained to perform
intra/inter coding adaptively. Moreover, we propose a simultaneous two-frame
compression design to exploit interframe redundancy not only forwardly but also
backwardly. Experimental results show that our scheme outperforms DCVC-RT by an
average of 10.7\% BD-rate reduction, delivers more stable bitrate and quality
per frame, and retains real-time encoding/decoding performances. Code and
models will be released.

</details>


### [35] [Structured Universal Adversarial Attacks on Object Detection for Video Sequences](https://arxiv.org/abs/2510.14460)
*Sven Jacob,Weijia Shao,Gjergji Kasneci*

Main category: cs.CV

TL;DR: 提出一种针对视频目标检测的最小失真通用对抗攻击方法，通过核范数正则化和自适应优化方法，显著提升攻击效果和隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的视频目标检测在安全关键应用中至关重要，但其易受通用对抗攻击的影响，尤其是结构化扰动攻击。

Method: 采用自适应乐观指数梯度方法优化核范数正则化目标，以高效生成结构化扰动。

Result: 所提出的攻击方法在有效性和隐蔽性上优于低秩投影梯度下降和基于Frank-Wolfe的攻击方法。

Conclusion: 本文提出了一种针对视频目标检测的最小失真通用对抗攻击方法，通过核范数正则化生成集中在背景的结构化扰动，实验证明该方法在有效性和隐蔽性上均优于现有攻击方法。

Abstract: Video-based object detection plays a vital role in safety-critical
applications. While deep learning-based object detectors have achieved
impressive performance, they remain vulnerable to adversarial attacks,
particularly those involving universal perturbations. In this work, we propose
a minimally distorted universal adversarial attack tailored for video object
detection, which leverages nuclear norm regularization to promote structured
perturbations concentrated in the background. To optimize this formulation
efficiently, we employ an adaptive, optimistic exponentiated gradient method
that enhances both scalability and convergence. Our results demonstrate that
the proposed attack outperforms both low-rank projected gradient descent and
Frank-Wolfe based attacks in effectiveness while maintaining high stealthiness.
All code and data are publicly available at
https://github.com/jsve96/AO-Exp-Attack.

</details>


### [36] [Unsupervised Deep Generative Models for Anomaly Detection in Neuroimaging: A Systematic Scoping Review](https://arxiv.org/abs/2510.14462)
*Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi*

Main category: cs.CV

TL;DR: 无监督深度生成模型通过健康数据训练检测脑影像异常，表现良好且可生成可解释重建，未来需加强临床验证。


<details>
  <summary>Details</summary>
Motivation: 解决监督方法依赖大量标注数据和对罕见病适应性差的问题，利用健康数据训练模型检测异常。

Method: 综述了49项研究，涵盖自编码器、变分自编码器、生成对抗网络和去噪扩散模型等无监督深度生成模型。

Result: 生成模型在大病灶检测中表现良好，并在处理细微异常方面取得进展，能生成可解释的伪健康重建。

Conclusion: 生成模型在脑影像异常检测中展现出潜力，尤其在处理大病灶和生成可解释的伪健康重建方面表现突出。未来需关注解剖感知建模、基础模型开发及临床验证。

Abstract: Unsupervised deep generative models are emerging as a promising alternative
to supervised methods for detecting and segmenting anomalies in brain imaging.
Unlike fully supervised approaches, which require large voxel-level annotated
datasets and are limited to well-characterised pathologies, these models can be
trained exclusively on healthy data and identify anomalies as deviations from
learned normative brain structures. This PRISMA-guided scoping review
synthesises recent work on unsupervised deep generative models for anomaly
detection in neuroimaging, including autoencoders, variational autoencoders,
generative adversarial networks, and denoising diffusion models. A total of 49
studies published between 2018 - 2025 were identified, covering applications to
brain MRI and, less frequently, CT across diverse pathologies such as tumours,
stroke, multiple sclerosis, and small vessel disease. Reported performance
metrics are compared alongside architectural design choices. Across the
included studies, generative models achieved encouraging performance for large
focal lesions and demonstrated progress in addressing more subtle
abnormalities. A key strength of generative models is their ability to produce
interpretable pseudo-healthy (also referred to as counterfactual)
reconstructions, which is particularly valuable when annotated data are scarce,
as in rare or heterogeneous diseases. Looking ahead, these models offer a
compelling direction for anomaly detection, enabling semi-supervised learning,
supporting the discovery of novel imaging biomarkers, and facilitating within-
and cross-disease deviation mapping in unified end-to-end frameworks. To
realise clinical impact, future work should prioritise anatomy-aware modelling,
development of foundation models, task-appropriate evaluation metrics, and
rigorous clinical validation.

</details>


### [37] [Pruning Overparameterized Multi-Task Networks for Degraded Web Image Restoration](https://arxiv.org/abs/2510.14463)
*Thomas Katraouras,Dimitrios Rafailidis*

Main category: cs.CV

TL;DR: MIR-L通过迭代剪枝策略压缩多任务图像恢复模型，保留10%参数且性能不降。


<details>
  <summary>Details</summary>
Motivation: 解决多任务图像恢复模型因参数过多导致的计算效率低下问题。

Method: 采用迭代剪枝策略，逐步移除低幅度权重并重置剩余权重至原始初始化，以发现高效子网络。

Result: 在去雨、去雾和去噪任务中，MIR-L仅保留10%的可训练参数，同时保持高性能。

Conclusion: 通过提出MIR-L模型，本研究展示了在多任务图像恢复模型中实现高稀疏性的可行性，同时保持或超越现有性能。

Abstract: Image quality is a critical factor in delivering visually appealing content
on web platforms. However, images often suffer from degradation due to lossy
operations applied by online social networks (OSNs), negatively affecting user
experience. Image restoration is the process of recovering a clean high-quality
image from a given degraded input. Recently, multi-task (all-in-one) image
restoration models have gained significant attention, due to their ability to
simultaneously handle different types of image degradations. However, these
models often come with an excessively high number of trainable parameters,
making them computationally inefficient. In this paper, we propose a strategy
for compressing multi-task image restoration models. We aim to discover highly
sparse subnetworks within overparameterized deep models that can match or even
surpass the performance of their dense counterparts. The proposed model, namely
MIR-L, utilizes an iterative pruning strategy that removes low-magnitude
weights across multiple rounds, while resetting the remaining weights to their
original initialization. This iterative process is important for the multi-task
image restoration model's optimization, effectively uncovering "winning
tickets" that maintain or exceed state-of-the-art performance at high sparsity
levels. Experimental evaluation on benchmark datasets for the deraining,
dehazing, and denoising tasks shows that MIR-L retains only 10% of the
trainable parameters while maintaining high image restoration performance. Our
code, datasets and pre-trained models are made publicly available at
https://github.com/Thomkat/MIR-L.

</details>


### [38] [Grazing Detection using Deep Learning and Sentinel-2 Time Series Data](https://arxiv.org/abs/2510.14493)
*Aleksis Pirinen,Delia Fano Yela,Smita Chakraborty,Erik Källman*

Main category: cs.CV

TL;DR: 利用Sentinel-2 L2A时间序列数据，通过CNN-LSTM模型集成检测季节性放牧，F1得分77%，操作上可显著提高检查效率。


<details>
  <summary>Details</summary>
Motivation: 放牧既影响农业生产又影响生物多样性，但可扩展的放牧监测仍然有限。

Method: 我们训练了一个CNN-LSTM模型集成，用于多时相反射特征，以实现季节性放牧检测。

Result: 在五个验证分割中，平均F1得分为77%，放牧草地的召回率为90%。操作上，优先检查模型预测为非放牧的田地，可使确认的非放牧站点数量比随机检查多17.2倍。

Conclusion: 结果表明，粗分辨率、免费可用的卫星数据可以可靠地指导检查资源，以实现符合保护目标的土地利用合规性。

Abstract: Grazing shapes both agricultural production and biodiversity, yet scalable
monitoring of where grazing occurs remains limited. We study seasonal grazing
detection from Sentinel-2 L2A time series: for each polygon-defined field
boundary, April-October imagery is used for binary prediction (grazed / not
grazed). We train an ensemble of CNN-LSTM models on multi-temporal reflectance
features, and achieve an average F1 score of 77 percent across five validation
splits, with 90 percent recall on grazed pastures. Operationally, if inspectors
can visit at most 4 percent of sites annually, prioritising fields predicted by
our model as non-grazed yields 17.2 times more confirmed non-grazing sites than
random inspection. These results indicate that coarse-resolution, freely
available satellite data can reliably steer inspection resources for
conservation-aligned land-use compliance. Code and models have been made
publicly available.

</details>


### [39] [Vision Mamba for Permeability Prediction of Porous Media](https://arxiv.org/abs/2510.14516)
*Ali Kashefi,Tapan Mukerji*

Main category: cs.CV

TL;DR: Vision Mamba首次用于三维多孔介质渗透率预测，性能优于ViT和CNN，且更高效。


<details>
  <summary>Details</summary>
Motivation: 由于Vision Mamba在图像分类中表现出线性扩展性和较低的可训练参数数量，将其首次应用于三维多孔介质渗透率预测。

Method: 使用Vision Mamba作为主干网络，进行三维多孔介质渗透率预测，并与ViT和CNN模型进行对比及消融实验。

Result: Vision Mamba在渗透率预测中优于ViT和CNN，且具有更高的效率和内存优势。

Conclusion: Vision Mamba在三维多孔介质渗透率预测中展现出优于ViT和CNN的性能，并具有更高的计算和内存效率。

Abstract: Vision Mamba has recently received attention as an alternative to Vision
Transformers (ViTs) for image classification. The network size of Vision Mamba
scales linearly with input image resolution, whereas ViTs scale quadratically,
a feature that improves computational and memory efficiency. Moreover, Vision
Mamba requires a significantly smaller number of trainable parameters than
traditional convolutional neural networks (CNNs), and thus, they can be more
memory efficient. Because of these features, we introduce, for the first time,
a neural network that uses Vision Mamba as its backbone for predicting the
permeability of three-dimensional porous media. We compare the performance of
Vision Mamba with ViT and CNN models across multiple aspects of permeability
prediction and perform an ablation study to assess the effects of its
components on accuracy. We demonstrate in practice the aforementioned
advantages of Vision Mamba over ViTs and CNNs in the permeability prediction of
three-dimensional porous media. We make the source code publicly available to
facilitate reproducibility and to enable other researchers to build on and
extend this work. We believe the proposed framework has the potential to be
integrated into large vision models in which Vision Mamba is used instead of
ViTs.

</details>


### [40] [Real-Time Surgical Instrument Defect Detection via Non-Destructive Testing](https://arxiv.org/abs/2510.14525)
*Qurrat Ul Ain,Atif Aftab Ahmed Jilani,Zunaira Shafqat,Nigar Azhar Butt*

Main category: cs.CV

TL;DR: SurgScan 是一种基于 YOLOv8 的 AI 缺陷检测框架，用于手术器械的实时质量控制，准确率达 99.3%，可替代人工检查。


<details>
  <summary>Details</summary>
Motivation: 手术器械缺陷对无菌性、机械完整性和患者安全构成严重风险，而现有的质量控制主要依赖人工检查，存在误差和不一致性问题。

Method: 使用 YOLOv8 对手术器械缺陷进行实时分类，训练数据集包含 102,876 张高分辨率图像，涵盖 11 种器械类型和 5 大缺陷类别。

Result: SurgScan 实现了最高准确率（99.3%）和实时推理速度（4.2-5.8 毫秒/图像），适合工业部署。对比增强预处理显著提高了缺陷检测效果。

Conclusion: SurgScan 提供了一种可扩展、经济高效的 AI 解决方案，用于自动化质量控制，减少对人工检查的依赖，同时确保符合 ISO 13485 和 FDA 标准，为医疗制造中的缺陷检测提供了新途径。

Abstract: Defective surgical instruments pose serious risks to sterility, mechanical
integrity, and patient safety, increasing the likelihood of surgical
complications. However, quality control in surgical instrument manufacturing
often relies on manual inspection, which is prone to human error and
inconsistency. This study introduces SurgScan, an AI-powered defect detection
framework for surgical instruments. Using YOLOv8, SurgScan classifies defects
in real-time, ensuring high accuracy and industrial scalability. The model is
trained on a high-resolution dataset of 102,876 images, covering 11 instrument
types and five major defect categories. Extensive evaluation against
state-of-the-art CNN architectures confirms that SurgScan achieves the highest
accuracy (99.3%) with real-time inference speeds of 4.2-5.8 ms per image,
making it suitable for industrial deployment. Statistical analysis demonstrates
that contrast-enhanced preprocessing significantly improves defect detection,
addressing key limitations in visual inspection. SurgScan provides a scalable,
cost-effective AI solution for automated quality control, reducing reliance on
manual inspection while ensuring compliance with ISO 13485 and FDA standards,
paving the way for enhanced defect detection in medical manufacturing.

</details>


### [41] [Noise Projection: Closing the Prompt-Agnostic Gap Behind Text-to-Image Misalignment in Diffusion Models](https://arxiv.org/abs/2510.14526)
*Yunze Tong,Didi Zhu,Zijing Hu,Jinluan Yang,Ziyu Zhao*

Main category: cs.CV

TL;DR: 提出噪声投影器优化初始噪声，提升文本-图像对齐效果，无需修改SD模型，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决训练与推理阶段噪声分布不匹配导致的文本-图像对齐问题。

Method: 提出一个噪声投影器，通过文本条件细化初始噪声，利用视觉语言模型（VLM）获取反馈并蒸馏为奖励模型，最后通过准直接偏好优化优化噪声投影器。

Result: 实验表明，该方法在多样化提示下均能有效提升文本-图像对齐效果，且推理成本低。

Conclusion: 通过噪声投影器优化初始噪声，显著提升了文本到图像生成的对齐效果，且无需修改预训练的Stable Diffusion模型。

Abstract: In text-to-image generation, different initial noises induce distinct
denoising paths with a pretrained Stable Diffusion (SD) model. While this
pattern could output diverse images, some of them may fail to align well with
the prompt. Existing methods alleviate this issue either by altering the
denoising dynamics or by drawing multiple noises and conducting post-selection.
In this paper, we attribute the misalignment to a training-inference mismatch:
during training, prompt-conditioned noises lie in a prompt-specific subset of
the latent space, whereas at inference the noise is drawn from a
prompt-agnostic Gaussian prior. To close this gap, we propose a noise projector
that applies text-conditioned refinement to the initial noise before denoising.
Conditioned on the prompt embedding, it maps the noise to a prompt-aware
counterpart that better matches the distribution observed during SD training,
without modifying the SD model. Our framework consists of these steps: we first
sample some noises and obtain token-level feedback for their corresponding
images from a vision-language model (VLM), then distill these signals into a
reward model, and finally optimize the noise projector via a quasi-direct
preference optimization. Our design has two benefits: (i) it requires no
reference images or handcrafted priors, and (ii) it incurs small inference
cost, replacing multi-sample selection with a single forward pass. Extensive
experiments further show that our prompt-aware noise projection improves
text-image alignment across diverse prompts.

</details>


### [42] [PaddleOCR-VL: Boosting Multilingual Document Parsing via a 0.9B Ultra-Compact Vision-Language Model](https://arxiv.org/abs/2510.14528)
*Cheng Cui,Ting Sun,Suyin Liang,Tingquan Gao,Zelun Zhang,Jiaxuan Liu,Xueqing Wang,Changda Zhou,Hongen Liu,Manhui Lin,Yue Zhang,Yubo Zhang,Handong Zheng,Jing Zhang,Jun Zhang,Yi Liu,Dianhai Yu,Yanjun Ma*

Main category: cs.CV

TL;DR: PaddleOCR-VL 是一款高效多语言文档解析模型，结合动态视觉编码和语言模型，性能卓越且资源消耗低。


<details>
  <summary>Details</summary>
Motivation: 为了解决文档解析中的多语言和复杂元素识别问题，同时保持资源高效性。

Method: PaddleOCR-VL-0.9B 结合了 NaViT 风格的动态分辨率视觉编码器和 ERNIE-4.5-0.3B 语言模型，支持 109 种语言和复杂元素识别。

Result: 在公共和内部基准测试中，PaddleOCR-VL 在页面级和元素级识别上均达到 SOTA 性能，显著优于现有解决方案。

Conclusion: PaddleOCR-VL 是一款资源高效且性能卓越的文档解析模型，适用于多语言和复杂元素的识别，在实际部署中表现出色。

Abstract: In this report, we propose PaddleOCR-VL, a SOTA and resource-efficient model
tailored for document parsing. Its core component is PaddleOCR-VL-0.9B, a
compact yet powerful vision-language model (VLM) that integrates a NaViT-style
dynamic resolution visual encoder with the ERNIE-4.5-0.3B language model to
enable accurate element recognition. This innovative model efficiently supports
109 languages and excels in recognizing complex elements (e.g., text, tables,
formulas, and charts), while maintaining minimal resource consumption. Through
comprehensive evaluations on widely used public benchmarks and in-house
benchmarks, PaddleOCR-VL achieves SOTA performance in both page-level document
parsing and element-level recognition. It significantly outperforms existing
solutions, exhibits strong competitiveness against top-tier VLMs, and delivers
fast inference speeds. These strengths make it highly suitable for practical
deployment in real-world scenarios.

</details>


### [43] [Towards Generalist Intelligence in Dentistry: Vision Foundation Models for Oral and Maxillofacial Radiology](https://arxiv.org/abs/2510.14532)
*Xinrui Huang,Fan Xiao,Dongming He,Anqi Gao,Dandan Li,Xiaofan Zhang,Shaoting Zhang,Xudong Wang*

Main category: cs.CV

TL;DR: DentVFM 是首个牙科视觉基础模型家族，通过自监督学习和大规模多模态数据集训练，显著提升牙科AI的泛化能力和应用范围。


<details>
  <summary>Details</summary>
Motivation: 口腔颌面放射学在牙科医疗中至关重要，但影像解读受限于专业人才短缺。现有牙科AI系统因单模态、任务特定设计及依赖昂贵标注数据而难以推广。

Method: DentVFM 基于 Vision Transformer (ViT) 架构，包括2D和3D变体，通过自监督学习在 DentVista 数据集（约160万张多模态放射影像）上训练，生成任务无关的视觉表示。

Result: DentVFM 在 DentBench 基准测试中显著优于监督、自监督和弱监督基线，展现出强大的泛化能力、标签高效性和可扩展性，并在跨模态诊断中表现优于经验丰富的牙医。

Conclusion: DentVFM 为牙科AI设立了新范式，提供了一个可扩展、适应性强且标签高效的模型，以改善智能牙科医疗并解决全球口腔医疗中的关键缺口。

Abstract: Oral and maxillofacial radiology plays a vital role in dental healthcare, but
radiographic image interpretation is limited by a shortage of trained
professionals. While AI approaches have shown promise, existing dental AI
systems are restricted by their single-modality focus, task-specific design,
and reliance on costly labeled data, hindering their generalization across
diverse clinical scenarios. To address these challenges, we introduce DentVFM,
the first family of vision foundation models (VFMs) designed for dentistry.
DentVFM generates task-agnostic visual representations for a wide range of
dental applications and uses self-supervised learning on DentVista, a large
curated dental imaging dataset with approximately 1.6 million multi-modal
radiographic images from various medical centers. DentVFM includes 2D and 3D
variants based on the Vision Transformer (ViT) architecture. To address gaps in
dental intelligence assessment and benchmarks, we introduce DentBench, a
comprehensive benchmark covering eight dental subspecialties, more diseases,
imaging modalities, and a wide geographical distribution. DentVFM shows
impressive generalist intelligence, demonstrating robust generalization to
diverse dental tasks, such as disease diagnosis, treatment analysis, biomarker
identification, and anatomical landmark detection and segmentation.
Experimental results indicate DentVFM significantly outperforms supervised,
self-supervised, and weakly supervised baselines, offering superior
generalization, label efficiency, and scalability. Additionally, DentVFM
enables cross-modality diagnostics, providing more reliable results than
experienced dentists in situations where conventional imaging is unavailable.
DentVFM sets a new paradigm for dental AI, offering a scalable, adaptable, and
label-efficient model to improve intelligent dental healthcare and address
critical gaps in global oral healthcare.

</details>


### [44] [Acquisition of interpretable domain information during brain MR image harmonization for content-based image retrieval](https://arxiv.org/abs/2510.14535)
*Keima Abe,Hayato Muraki,Shuhei Tomoshige,Kenichi Oishi,Hitoshi Iyatomi*

Main category: cs.CV

TL;DR: PL-SE-ADA 是一种可解释的医学图像域适应框架，通过对抗训练和图像重建实现高性能，同时提供可视化支持。


<details>
  <summary>Details</summary>
Motivation: 医学图像（如 MR 扫描）因扫描设备和协议差异导致域偏移，影响机器学习性能（如疾病分类）。现有方法虽有效但缺乏解释性，难以满足医学应用需求。

Method: PL-SE-ADA 包含两个编码器 $f_E$ 和 $f_{SE}$ 分别提取域不变和域特定特征，一个解码器 $f_D$ 进行图像重建，以及一个域预测器 $g_D$。通过对抗训练和图像重建，模型实现了域适应和信息保留。

Result: PL-SE-ADA 在图像重建、疾病分类和域识别任务中表现优于或等同于现有方法，并能可视化域无关和域特定特征。

Conclusion: PL-SE-ADA 提出了一种可解释的域适应框架，在医学图像领域适应任务中表现优异，同时提供了高解释性。

Abstract: Medical images like MR scans often show domain shifts across imaging sites
due to scanner and protocol differences, which degrade machine learning
performance in tasks such as disease classification. Domain harmonization is
thus a critical research focus. Recent approaches encode brain images
$\boldsymbol{x}$ into a low-dimensional latent space $\boldsymbol{z}$, then
disentangle it into $\boldsymbol{z_u}$ (domain-invariant) and
$\boldsymbol{z_d}$ (domain-specific), achieving strong results. However, these
methods often lack interpretability$-$an essential requirement in medical
applications$-$leaving practical issues unresolved. We propose
Pseudo-Linear-Style Encoder Adversarial Domain Adaptation (PL-SE-ADA), a
general framework for domain harmonization and interpretable representation
learning that preserves disease-relevant information in brain MR images.
PL-SE-ADA includes two encoders $f_E$ and $f_{SE}$ to extract
$\boldsymbol{z_u}$ and $\boldsymbol{z_d}$, a decoder to reconstruct the image
$f_D$, and a domain predictor $g_D$. Beyond adversarial training between the
encoder and domain predictor, the model learns to reconstruct the input image
$\boldsymbol{x}$ by summing reconstructions from $\boldsymbol{z_u}$ and
$\boldsymbol{z_d}$, ensuring both harmonization and informativeness. Compared
to prior methods, PL-SE-ADA achieves equal or better performance in image
reconstruction, disease classification, and domain recognition. It also enables
visualization of both domain-independent brain features and domain-specific
components, offering high interpretability across the entire framework.

</details>


### [45] [QDepth-VLA: Quantized Depth Prediction as Auxiliary Supervision for Vision-Language-Action Models](https://arxiv.org/abs/2510.14836)
*Yixuan Li,Yuhui Chen,Mingcai Zhou,Haoran Li*

Main category: cs.CV

TL;DR: QDepth-VLA通过深度预测增强VLA模型，提升空间感知与操作任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在理解3D结构和精确控制方面存在不足，需提升空间感知与推理能力。

Method: 提出QDepth-VLA框架，通过辅助深度预测任务（使用VQ-VAE编码器生成量化深度图令牌）来增强VLA模型的空间感知。

Result: 在仿真和真实任务中，QDepth-VLA展现出强大的空间推理能力和竞争力的操作性能。

Conclusion: QDepth-VLA通过增强VLA模型的深度感知能力，显著提升了空间推理和精细操作任务的性能。

Abstract: Spatial perception and reasoning are crucial for Vision-Language-Action (VLA)
models to accomplish fine-grained manipulation tasks. However, existing
approaches often lack the ability to understand and reason over the essential
3D structures necessary for precise control. To address this limitation, we
propose QDepth-VLA, a general framework that augments VLA models with an
auxiliary depth prediction task. A dedicated depth expert is designed to
predict quantized latent tokens of depth maps obtained from a VQ-VAE encoder,
enabling the model to learn depth-aware representations that capture critical
geometric cues. Experimental results on the simulation benchmarks and
real-world tasks demonstrate that QDepth-VLA yields strong spatial reasoning
and competitive performance on manipulation tasks.

</details>


### [46] [Exploring Image Representation with Decoupled Classical Visual Descriptors](https://arxiv.org/abs/2510.14536)
*Chenyuan Qu,Hao Chen,Jianbo Jiao*

Main category: cs.CV

TL;DR: VisualSplit通过分解图像为经典视觉描述符，结合重建驱动的预训练，实现了可解释的视觉表示，并在高级视觉任务中展示了有效性。


<details>
  <summary>Details</summary>
Motivation: 深度学习的内部表示往往不透明，难以解释视觉信息的处理过程，而经典视觉描述符（如边缘、颜色和强度分布）则直观易懂。这一差距促使研究者探索现代学习是否能从传统视觉线索中受益。

Method: VisualSplit采用重建驱动的预训练方案，将图像分解为解耦的经典视觉描述符，每个描述符被视为独立但互补的视觉知识组成部分。

Result: VisualSplit能够有效捕捉每个视觉描述符的本质并保持其可解释性，同时在图像生成和编辑等任务中实现属性控制，超越了传统的分类和分割任务。

Conclusion: VisualSplit框架通过将图像分解为经典视觉描述符，展示了现代学习如何从传统视觉线索中受益，从而在图像生成和编辑等高级视觉任务中实现有效的属性控制。

Abstract: Exploring and understanding efficient image representations is a
long-standing challenge in computer vision. While deep learning has achieved
remarkable progress across image understanding tasks, its internal
representations are often opaque, making it difficult to interpret how visual
information is processed. In contrast, classical visual descriptors (e.g. edge,
colour, and intensity distribution) have long been fundamental to image
analysis and remain intuitively understandable to humans. Motivated by this
gap, we ask a central question: Can modern learning benefit from these
classical cues? In this paper, we answer it with VisualSplit, a framework that
explicitly decomposes images into decoupled classical descriptors, treating
each as an independent but complementary component of visual knowledge. Through
a reconstruction-driven pre-training scheme, VisualSplit learns to capture the
essence of each visual descriptor while preserving their interpretability. By
explicitly decomposing visual attributes, our method inherently facilitates
effective attribute control in various advanced visual tasks, including image
generation and editing, extending beyond conventional classification and
segmentation, suggesting the effectiveness of this new learning approach for
visual understanding. Project page: https://chenyuanqu.com/VisualSplit/.

</details>


### [47] [Exploring Cross-Modal Flows for Few-Shot Learning](https://arxiv.org/abs/2510.14543)
*Ziqi Jiang,Yanghao Wang,Long Chen*

Main category: cs.CV

TL;DR: FMA是一种多步调整方法，通过跨模态速度场实现更精确的特征对齐，显著提升了复杂数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有PEFT方法仅进行单步调整，难以处理模态特征高度纠缠的复杂数据集。

Method: 提出了一种模型无关的多步调整方法——Flow Matching Alignment (FMA)，包括固定耦合策略、噪声增强策略和早停求解器。

Result: FMA在多个基准测试和骨干网络上均表现优异，尤其在挑战性数据集上显著优于现有PEFT方法。

Conclusion: FMA通过多步校正能力，实现了比现有PEFT方法更精确和稳健的特征对齐，特别是在复杂数据集上表现出显著性能提升。

Abstract: Aligning features from different modalities, is one of the most fundamental
challenges for cross-modal tasks. Although pre-trained vision-language models
can achieve a general alignment between image and text, they often require
parameter-efficient fine-tuning (PEFT) for further adjustment. Today's PEFT
methods (e.g., prompt tuning, LoRA-based, or adapter-based) always selectively
fine-tune a subset of parameters, which can slightly adjust either visual or
textual features, and avoid overfitting. In this paper, we are the first to
highlight that all existing PEFT methods perform one-step adjustment. It is
insufficient for complex (or difficult) datasets, where features of different
modalities are highly entangled. To this end, we propose the first
model-agnostic multi-step adjustment approach by learning a cross-modal
velocity field: Flow Matching Alignment (FMA). Specifically, to ensure the
correspondence between categories during training, we first utilize a fixed
coupling strategy. Then, we propose a noise augmentation strategy to alleviate
the data scarcity issue. Finally, we design an early-stopping solver, which
terminates the transformation process earlier, improving both efficiency and
accuracy. Compared with one-step PEFT methods, FMA has the multi-step
rectification ability to achieve more precise and robust alignment. Extensive
results have demonstrated that FMA can consistently yield significant
performance gains across various benchmarks and backbones, particularly on
challenging datasets.

</details>


### [48] [Consistent text-to-image generation via scene de-contextualization](https://arxiv.org/abs/2510.14553)
*Song Tang,Peihao Gong,Kunyu Li,Kai Guo,Boyu Wang,Mao Ye,Jianwei Zhang,Xiatian Zhu*

Main category: cs.CV

TL;DR: SDeC是一种无需训练的提示嵌入编辑方法，通过抑制场景-ID相关性提升文本到图像生成的身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像生成中因场景上下文化导致的身份偏移问题，尤其在不预先知道所有目标场景的情况下。

Method: 提出了一种无需训练的高效提示嵌入编辑方法SDeC，通过量化SVD方向稳定性自适应重加权相应特征值。

Result: 实验表明，SDeC显著提高了身份保持能力，同时保持了场景多样性。

Conclusion: 论文提出了一种名为Scene De-Contextualization (SDeC)的新方法，通过抑制ID提示嵌入中的潜藏场景-ID相关性，显著提升了身份保持能力，同时保持了场景多样性。

Abstract: Consistent text-to-image (T2I) generation seeks to produce
identity-preserving images of the same subject across diverse scenes, yet it
often fails due to a phenomenon called identity (ID) shift. Previous methods
have tackled this issue, but typically rely on the unrealistic assumption of
knowing all target scenes in advance. This paper reveals that a key source of
ID shift is the native correlation between subject and scene context, called
scene contextualization, which arises naturally as T2I models fit the training
distribution of vast natural images. We formally prove the near-universality of
this scene-ID correlation and derive theoretical bounds on its strength. On
this basis, we propose a novel, efficient, training-free prompt embedding
editing approach, called Scene De-Contextualization (SDeC), that imposes an
inversion process of T2I's built-in scene contextualization. Specifically, it
identifies and suppresses the latent scene-ID correlation within the ID
prompt's embedding by quantifying the SVD directional stability to adaptively
re-weight the corresponding eigenvalues. Critically, SDeC allows for per-scene
use (one scene per prompt) without requiring prior access to all target scenes.
This makes it a highly flexible and general solution well-suited to real-world
applications where such prior knowledge is often unavailable or varies over
time. Experiments demonstrate that SDeC significantly enhances identity
preservation while maintaining scene diversity.

</details>


### [49] [Eyes Wide Open: Ego Proactive Video-LLM for Streaming Video](https://arxiv.org/abs/2510.14560)
*Yulin Zhang,Cheng Shi,Yang Wang,Sibei Yang*

Main category: cs.CV

TL;DR: 论文提出了一种能够在流媒体视频输入中主动回答多样化问题的AI助手，并引入ESTP-Bench和ESTP-F1指标进行评估，提出的技术流程在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种能够在人类类似环境中主动理解、预测和响应事件的AI助手，超越单纯的观察。

Method: 论文提出了一种综合技术流程，包括数据引擎、多阶段训练策略和主动动态压缩技术。

Result: 模型在ESTP-Bench上表现优异，超过了多个基线方法。

Conclusion: 论文提出的模型在多个在线和离线基准测试中表现优异，有效解决了主动一致性、即时响应和同步效率三个关键特性。

Abstract: Envision an AI capable of functioning in human-like settings, moving beyond
mere observation to actively understand, anticipate, and proactively respond to
unfolding events. Towards this vision, we focus on the innovative task where,
given ego-streaming video input, an assistant proactively answers diverse,
evolving questions at the opportune moment, while maintaining synchronized
perception and reasoning. This task embodies three key properties: (1)
Proactive Coherence, (2) Just-in-Time Responsiveness, and (3) Synchronized
Efficiency. To evaluate and address these properties, we first introduce
ESTP-Bench (Ego Streaming Proactive Benchmark) alongside the ESTP-F1 metric-a
novel framework designed for their rigorous assessment. Secondly, we propose a
comprehensive technical pipeline to enable models to tackle this challenging
task. This pipeline comprises: (1) a data engine, (2) a multi-stage training
strategy, and (3) a proactive dynamic compression technique. Our proposed model
effectively addresses these critical properties while outperforming multiple
baselines across diverse online and offline benchmarks. Project
Page:https://zhangyl4.github.io/publications/eyes-wide-open/

</details>


### [50] [BalanceGS: Algorithm-System Co-design for Efficient 3D Gaussian Splatting Training on GPU](https://arxiv.org/abs/2510.14564)
*Junyi Wu,Jiaming Xu,Jinhao Li,Yongkang Zhou,Jiayi Pan,Xingyang Li,Guohao Dai*

Main category: cs.CV

TL;DR: BalanceGS通过算法和系统协同设计解决了3DGS训练中的效率问题，显著提升了训练速度。


<details>
  <summary>Details</summary>
Motivation: 传统3DGS训练流程存在三个关键低效问题：高斯密度分配不均、计算负载不平衡和内存访问碎片化。

Method: 提出了三方面的改进：(1) 启发式工作负载敏感的高斯密度控制；(2) 基于相似性的高斯采样与合并；(3) 基于重排序的内存访问映射策略。

Result: 在NVIDIA A100 GPU上实现了1.44倍的训练加速，且质量损失可忽略。

Conclusion: BalanceGS通过算法和系统的协同设计，显著提升了3DGS的训练效率，同时保持了重建质量。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a promising 3D reconstruction
technique. The traditional 3DGS training pipeline follows three sequential
steps: Gaussian densification, Gaussian projection, and color splatting.
Despite its promising reconstruction quality, this conventional approach
suffers from three critical inefficiencies: (1) Skewed density allocation
during Gaussian densification, (2) Imbalanced computation workload during
Gaussian projection and (3) Fragmented memory access during color splatting.
  To tackle the above challenges, we introduce BalanceGS, the algorithm-system
co-design for efficient training in 3DGS. (1) At the algorithm level, we
propose heuristic workload-sensitive Gaussian density control to automatically
balance point distributions - removing 80% redundant Gaussians in dense regions
while filling gaps in sparse areas. (2) At the system level, we propose
Similarity-based Gaussian sampling and merging, which replaces the static
one-to-one thread-pixel mapping with adaptive workload distribution - threads
now dynamically process variable numbers of Gaussians based on local cluster
density. (3) At the mapping level, we propose reordering-based memory access
mapping strategy that restructures RGB storage and enables batch loading in
shared memory.
  Extensive experiments demonstrate that compared with 3DGS, our approach
achieves a 1.44$\times$ training speedup on a NVIDIA A100 GPU with negligible
quality degradation.

</details>


### [51] [CALM-Net: Curvature-Aware LiDAR Point Cloud-based Multi-Branch Neural Network for Vehicle Re-Identification](https://arxiv.org/abs/2510.14576)
*Dongwook Lee,Sol Han,Jinwhan Kim*

Main category: cs.CV

TL;DR: CALM-Net是一种基于LiDAR点云的车辆重识别网络，通过多分支架构和曲率信息提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决从三维点云中学习区分性和互补性特征的挑战，以区分不同车辆。

Method: 采用多分支架构，整合边缘卷积、点注意力和曲率嵌入，以学习点云中的几何和上下文特征。

Result: 在nuScenes数据集上，CALM-Net的平均重识别准确率比最强基线提高了约1.97%。

Conclusion: CALM-Net通过结合曲率信息和多分支特征学习，显著提升了基于LiDAR点云的车辆重识别性能。

Abstract: This paper presents CALM-Net, a curvature-aware LiDAR point cloud-based
multi-branch neural network for vehicle re-identification. The proposed model
addresses the challenge of learning discriminative and complementary features
from three-dimensional point clouds to distinguish between vehicles. CALM-Net
employs a multi-branch architecture that integrates edge convolution, point
attention, and a curvature embedding that characterizes local surface variation
in point clouds. By combining these mechanisms, the model learns richer
geometric and contextual features that are well suited for the
re-identification task. Experimental evaluation on the large-scale nuScenes
dataset demonstrates that CALM-Net achieves a mean re-identification accuracy
improvement of approximately 1.97\% points compared with the strongest baseline
in our study. The results confirms the effectiveness of incorporating curvature
information into deep learning architectures and highlight the benefit of
multi-branch feature learning for LiDAR point cloud-based vehicle
re-identification.

</details>


### [52] [Talking Points: Describing and Localizing Pixels](https://arxiv.org/abs/2510.14583)
*Matan Rusanovsky,Shimon Malnick,Shai Avidan*

Main category: cs.CV

TL;DR: 提出了一种像素级关键点理解的框架，包含点描述符和点定位器，通过新数据集和优化方法实现优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型仅限于对象或区域级别的理解，缺乏通过自然语言实现像素级关键点理解的能力。

Method: 框架包含两个互补组件：点描述符生成关键点的上下文描述，点定位器从描述中回归精确的像素坐标。使用GRPO在AP-10K上优化点描述符，并以冻结的点定位器作为奖励模型。

Result: 在LlamaPointInPart数据集上表现出优于基线模型的性能。

Conclusion: 该框架的双向特性为未来在关键点引导的图像理解和语言引导的精确定位中的应用提供了潜力。代码和数据集已公开。

Abstract: Vision-language models have achieved remarkable success in cross-modal
understanding. Yet, these models remain limited to object-level or region-level
grounding, lacking the capability for pixel-precise keypoint comprehension
through natural language. We introduce a novel framework for pixel level
grounding. The framework consists of two complementary components: a Point
Descriptor that generates rich, contextual descriptions of individual
keypoints, and a Point Localizer that regresses precise pixel coordinates from
these descriptions. Unlike prior work that relies on templated prompts or
keypoint names, our approach produces free-form, coarse-to-fine descriptions
that situate keypoints within their visual context. Since there is no available
dataset to train such a system, we introduce LlamaPointInPart, a carefully
curated dataset of 20K+ image-keypoint-description triplets synthesized from
multiple vision-language models, capturing multi-scale information from
scene-level context to visual features around the keypoint. For cross-category
generalization, we optimize the Point Descriptor on AP-10K via GRPO, using the
frozen Point Localizer as a reward model to produce descriptions that maximize
localization accuracy. To evaluate our results we establish a new evaluation
protocol. Instead of comparing the text description produced by our method to
the ground truth, we use the localizer to determine how close is the predicted
point generated to the ground truth point. Experiments demonstrate superior
performance compared to baseline models on LlamaPointInPart.The bidirectional
nature of our framework should enable future applications in both
keypoint-guided image understanding and language-guided precise localization.
Our code and dataset are publicly available at
https://github.com/matanr/Talking_Points.

</details>


### [53] [STANCE: Motion Coherent Video Generation Via Sparse-to-Dense Anchored Encoding](https://arxiv.org/abs/2510.14588)
*Zhifei Chen,Tianshuo Xu,Leyi Wu,Luozhou Wang,Dongyu Yan,Zihan You,Wenting Luo,Guo Zhang,Yingcong Chen*

Main category: cs.CV

TL;DR: STANCE通过实例线索和Dense RoPE技术，解决了视频生成中运动一致性问题，提升了时间连贯性。


<details>
  <summary>Details</summary>
Motivation: 视频生成在保持对象运动一致性和交互性方面存在困难，主要源于两个瓶颈：(i) 人类提供的运动提示编码后信息丢失；(ii) 单头优化倾向于纹理而非时间一致性。

Method: STANCE框架包含两个核心组件：实例线索（Instance Cues）和Dense RoPE。实例线索将稀疏的用户编辑提示转化为密集的2.5D运动场，减少深度模糊；Dense RoPE通过空间可寻址的旋转嵌入标记运动令牌，保持线索在令牌空间中的显著性。

Result: STANCE框架通过联合RGB和辅助地图预测，稳定了优化过程，显著提升了生成视频的时间连贯性，且无需逐帧轨迹脚本。

Conclusion: STANCE框架通过引入实例线索和Dense RoPE技术，有效解决了视频生成中对象运动一致性和交互性的问题，显著提升了时间连贯性。

Abstract: Video generation has recently made striking visual progress, but maintaining
coherent object motion and interactions remains difficult. We trace two
practical bottlenecks: (i) human-provided motion hints (e.g., small 2D maps)
often collapse to too few effective tokens after encoding, weakening guidance;
and (ii) optimizing for appearance and motion in a single head can favor
texture over temporal consistency. We present STANCE, an image-to-video
framework that addresses both issues with two simple components. First, we
introduce Instance Cues -- a pixel-aligned control signal that turns sparse,
user-editable hints into a dense 2.5D (camera-relative) motion field by
averaging per-instance flow and augmenting with monocular depth over the
instance mask. This reduces depth ambiguity compared to 2D arrow inputs while
remaining easy to use. Second, we preserve the salience of these cues in token
space with Dense RoPE, which tags a small set of motion tokens (anchored on the
first frame) with spatial-addressable rotary embeddings. Paired with joint RGB
\(+\) auxiliary-map prediction (segmentation or depth), our model anchors
structure while RGB handles appearance, stabilizing optimization and improving
temporal coherence without requiring per-frame trajectory scripts.

</details>


### [54] [Hierarchical Re-Classification: Combining Animal Classification Models with Vision Transformers](https://arxiv.org/abs/2510.14594)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 论文提出了一种层次化重分类系统，结合多种技术提升物种识别准确率，在测试数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的动物分类模型（如SpeciesNet）采用保守的汇总策略，导致许多动物被标记为高级分类学层级而非物种级别。

Method: 采用五阶段流水线（高置信度接受、鸟类覆盖、质心构建、三元组损失度量学习和自适应余弦距离评分）进行层次化重分类。

Result: 在LILA BC Desert Lion Conservation数据集上，系统恢复了761个鸟类检测，并以96.5%的准确率重新分类了456个标记为动物、哺乳动物或空白的检测，实现了64.9%的物种级别识别。

Conclusion: 该论文提出了一种结合SpeciesNet EfficientNetV2-M预测、CLIP嵌入和度量学习的层次化重分类系统，显著提升了物种级别识别的准确性和覆盖率。

Abstract: State-of-the-art animal classification models like SpeciesNet provide
predictions across thousands of species but use conservative rollup strategies,
resulting in many animals labeled at high taxonomic levels rather than species.
We present a hierarchical re-classification system for the Animal Detect
platform that combines SpeciesNet EfficientNetV2-M predictions with CLIP
embeddings and metric learning to refine high-level taxonomic labels toward
species-level identification. Our five-stage pipeline (high-confidence
acceptance, bird override, centroid building, triplet-loss metric learning, and
adaptive cosine-distance scoring) is evaluated on a segment of the LILA BC
Desert Lion Conservation dataset (4,018 images, 15,031 detections). After
recovering 761 bird detections from "blank" and "animal" labels, we re-classify
456 detections labeled animal, mammal, or blank with 96.5% accuracy, achieving
species-level identification for 64.9 percent

</details>


### [55] [Zero-Shot Wildlife Sorting Using Vision Transformers: Evaluating Clustering and Continuous Similarity Ordering](https://arxiv.org/abs/2510.14596)
*Hugo Markoff,Jevgenijs Galaktionovs*

Main category: cs.CV

TL;DR: 该论文评估了零样本方法在野生动物图像分类中的应用，通过自监督视觉变换器和无监督聚类技术，显著提升了未标记数据的处理效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有分类器无法识别相机陷阱拍摄的野生动物图像中未标记物种的问题。

Method: 比较了无监督聚类方法（DBSCAN、GMM）在三种架构（CLIP、DINOv2、MegaDescriptor）与降维技术（PCA、UMAP）中的表现，并通过t-SNE投影实现了连续的1D相似性排序。

Result: DINOv2结合UMAP和GMM在5物种测试集上达到88.6%准确率（macro-F1 = 0.874），1D排序在哺乳动物和鸟类中达到88.2%一致性，鱼类中达到95.2%。

Conclusion: 基于研究结果，团队在动物探测平台中部署了连续相似性排序功能，显著提升了生物多样性监测中手动标注工作流程的效率。

Abstract: Camera traps generate millions of wildlife images, yet many datasets contain
species that are absent from existing classifiers. This work evaluates
zero-shot approaches for organizing unlabeled wildlife imagery using
self-supervised vision transformers, developed and tested within the Animal
Detect platform for camera trap analysis. We compare unsupervised clustering
methods (DBSCAN, GMM) across three architectures (CLIP, DINOv2, MegaDescriptor)
combined with dimensionality reduction techniques (PCA, UMAP), and we
demonstrate continuous 1D similarity ordering via t-SNE projection. On a
5-species test set with ground truth labels used only for evaluation, DINOv2
with UMAP and GMM achieves 88.6 percent accuracy (macro-F1 = 0.874), while 1D
sorting reaches 88.2 percent coherence for mammals and birds and 95.2 percent
for fish across 1,500 images. Based on these findings, we deployed continuous
similarity ordering in production, enabling rapid exploratory analysis and
accelerating manual annotation workflows for biodiversity monitoring.

</details>


### [56] [Knowledge-based Visual Question Answer with Multimodal Processing, Retrieval and Filtering](https://arxiv.org/abs/2510.14605)
*Yuyang Hong,Jiaqi Gu,Qi Yang,Lubin Fan,Yue Wu,Ying Wang,Kun Ding,Shiming Xiang,Jieping Ye*

Main category: cs.CV

TL;DR: Wiki-PRF通过三阶段方法（处理、检索、过滤）和强化学习训练，显著提升了知识库视觉问答的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的检索增强生成方法在视觉语言模型与外部知识检索结合时，面临多模态查询质量和检索结果相关性不足的挑战。

Method: 提出了一种名为Wiki-PRF的三阶段方法，包括处理、检索和过滤阶段，通过强化学习训练视觉语言模型。

Result: 在基准数据集（E-VQA和InfoSeek）上，答案质量显著提升（36.0和42.8）。

Conclusion: Wiki-PRF方法在知识库视觉问答任务中显著提高了答案质量，实现了最先进的性能。

Abstract: Knowledge-based visual question answering (KB-VQA) requires visual language
models (VLMs) to integrate visual understanding with external knowledge
retrieval. Although retrieval-augmented generation (RAG) achieves significant
advances in this task by combining knowledge-base querying, it still struggles
with the quality of multimodal queries and the relevance of retrieved results.
To overcome these challenges, we propose a novel three-stage method, termed
Wiki-PRF, including Processing, Retrieval and Filtering stages. The processing
stage dynamically invokes visual tools to extract precise multimodal
information for retrieval. The retrieval stage integrates visual and text
features to achieve multimodal knowledge retrieval. The filtering stage
performs relevance filtering and concentration on retrieval results. To this
end, we introduce a visual language model trained with answer accuracy and
format consistency as reward signals via a reinforcement learning manner. This
enhances the model's reasoning, tool invocation for accurate queries, and
filtering of irrelevant content. Experiments on benchmark datasets (E-VQA and
InfoSeek) show significant improvements~(36.0 and 42.8) in answer quality,
achieving state-of-the-art performance. Code is available at
https://github.com/cqu-student/Wiki-PRF

</details>


### [57] [Shot2Tactic-Caption: Multi-Scale Captioning of Badminton Videos for Tactical Understanding](https://arxiv.org/abs/2510.14617)
*Ning Ding,Keisuke Fujii,Toru Tamaki*

Main category: cs.CV

TL;DR: 提出Shot2Tactic-Caption框架，用于羽毛球视频的多尺度描述，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决羽毛球战术理解中动态执行的多尺度视频描述问题，填补现有数据集的空白。

Method: 采用双分支设计，包括视觉编码器、时空Transformer编码器和基于Transformer的解码器，并引入战术单元检测器和镜头提示引导机制。

Result: 实验证明框架能有效生成镜头和战术描述，ResNet50编码器和提示引导机制表现最佳。

Conclusion: Shot2Tactic-Caption框架在生成羽毛球视频的镜头和战术描述方面表现出色，ResNet50为基础的时空编码器和镜头提示引导机制显著提升了描述的一致性和准确性。

Abstract: Tactical understanding in badminton involves interpreting not only individual
actions but also how tactics are dynamically executed over time. In this paper,
we propose \textbf{Shot2Tactic-Caption}, a novel framework for semantic and
temporal multi-scale video captioning in badminton, capable of generating
shot-level captions that describe individual actions and tactic-level captions
that capture how these actions unfold over time within a tactical execution. We
also introduce the Shot2Tactic-Caption Dataset, the first badminton captioning
dataset containing 5,494 shot captions and 544 tactic captions.
Shot2Tactic-Caption adopts a dual-branch design, with both branches including a
visual encoder, a spatio-temporal Transformer encoder, and a Transformer-based
decoder to generate shot and tactic captions. To support tactic captioning, we
additionally introduce a Tactic Unit Detector that identifies valid tactic
units, tactic types, and tactic states (e.g., Interrupt, Resume). For tactic
captioning, we further incorporate a shot-wise prompt-guided mechanism, where
the predicted tactic type and state are embedded as prompts and injected into
the decoder via cross-attention. The shot-wise prompt-guided mechanism enables
our system not only to describe successfully executed tactics but also to
capture tactical executions that are temporarily interrupted and later resumed.
Experimental results demonstrate the effectiveness of our framework in
generating both shot and tactic captions. Ablation studies show that the
ResNet50-based spatio-temporal encoder outperforms other variants, and that
shot-wise prompt structuring leads to more coherent and accurate tactic
captioning.

</details>


### [58] [Efficient Video Sampling: Pruning Temporally Redundant Tokens for Faster VLM Inference](https://arxiv.org/abs/2510.14624)
*Natan Bagrov,Eugene Khvedchenia,Borys Tymchenko,Shay Aharon,Lior Kadoch,Tomer Keren,Ofri Masad,Yonatan Geifman,Ran Zilberstein,Tuomas Rintamaki,Matthieu Le,Andrew Tao*

Main category: cs.CV

TL;DR: EVS是一种减少视频令牌冗余的方法，通过修剪静态补丁提高效率，保持语义保真度，适用于长视频处理。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型(VLMs)从静态图像理解扩展到视频推理，但其可扩展性受到密集帧序列处理的二次成本的限制。长视频通常超出现代语言模型的令牌预算，导致严重的上下文限制和延迟问题。

Method: 介绍了Efficient Video Sampling (EVS)，一种简单、即插即用的方法，通过识别和修剪时间静态补丁（在连续帧中保持不变的空间区域）来减少视频中的令牌冗余。EVS保留了位置身份，无需架构更改或重新训练。

Result: EVS显著减少了令牌数量，同时保持了语义保真度，实现了更快的推理和更长的输入序列。在推理时应用，EVS将大型语言模型(LLM)的首次令牌时间(TTFT)减少了4倍，且准确性损失最小。结合随机修剪率的上训练阶段，EVS生成了对不同程度压缩具有鲁棒性的模型。

Conclusion: EVS通过识别和修剪时间静态补丁，显著减少了视频中的令牌冗余，同时保持了语义保真度，实现了更快的推理和更长的输入序列。结合随机修剪率的上训练阶段，EVS生成了对不同程度压缩具有鲁棒性的模型，并在激进修剪下保持完整性能。

Abstract: Vision-language models (VLMs) have recently expanded from static image
understanding to video reasoning, but their scalability is fundamentally
limited by the quadratic cost of processing dense frame sequences. Long videos
often exceed the token budget of modern language models, leading to severe
context limitations and latency issues. We introduce Efficient Video Sampling
(EVS), a simple, plug-and-play method for reducing token redundancy in videos
by identifying and pruning temporally static patches -- spatial regions that
remain unchanged across consecutive frames. EVS preserves positional identity,
requires no architectural changes or retraining. We show that EVS substantially
reduces token count while maintaining semantic fidelity, enabling faster
inference and longer input sequences. Applied at inference time, EVS reduces
large language model (LLM) time-to-first-token (TTFT) by up to 4x with minimal
accuracy loss. When combined with an uptraining phase using stochastic pruning
rates, EVS yields models that are robust to varying compression levels and
retain full performance under aggressive pruning. Extensive experiments
demonstrate that EVS consistently improves efficiency-accuracy trade-offs,
unlocking scalable video-language understanding without sacrificing quality.

</details>


### [59] [Adapting Self-Supervised Representations as a Latent Space for Efficient Generation](https://arxiv.org/abs/2510.14630)
*Ming Gui,Johannes Schusterbauer,Timy Phan,Felix Krause,Josh Susskind,Miguel Angel Bautista,Björn Ommer*

Main category: cs.CV

TL;DR: RepTok是一个生成建模框架，通过单个连续潜在令牌表示图像，显著降低训练成本，同时在图像生成和文本到图像合成中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决2D潜在空间的空间冗余问题，显著降低训练成本，同时保持图像重建的忠实性。

Method: RepTok框架基于预训练的SSL编码器，仅微调语义令牌嵌入，并与使用标准流匹配目标联合训练的生成解码器配对。通过添加余弦相似度损失来正则化适应的令牌，保持潜在空间的平滑性。

Result: RepTok在类别条件ImageNet生成和文本到图像合成中取得了竞争性结果，在极有限的训练预算下在MS-COCO上达到了竞争性的零样本性能。

Conclusion: RepTok展示了通过微调自监督学习（SSL）表示作为紧凑且有效的潜在空间，用于高效生成建模的潜力。

Abstract: We introduce Representation Tokenizer (RepTok), a generative modeling
framework that represents an image using a single continuous latent token
obtained from self-supervised vision transformers. Building on a pre-trained
SSL encoder, we fine-tune only the semantic token embedding and pair it with a
generative decoder trained jointly using a standard flow matching objective.
This adaptation enriches the token with low-level, reconstruction-relevant
details, enabling faithful image reconstruction. To preserve the favorable
geometry of the original SSL space, we add a cosine-similarity loss that
regularizes the adapted token, ensuring the latent space remains smooth and
suitable for generation. Our single-token formulation resolves spatial
redundancies of 2D latent spaces and significantly reduces training costs.
Despite its simplicity and efficiency, RepTok achieves competitive results on
class-conditional ImageNet generation and naturally extends to text-to-image
synthesis, reaching competitive zero-shot performance on MS-COCO under
extremely limited training budgets. Our findings highlight the potential of
fine-tuned SSL representations as compact and effective latent spaces for
efficient generative modeling.

</details>


### [60] [SteeringTTA: Guiding Diffusion Trajectories for Robust Test-Time-Adaptation](https://arxiv.org/abs/2510.14634)
*Jihyun Yu,Yoojin Oh,Wonho Bae,Mingyu Kim,Junhyug Noh*

Main category: cs.CV

TL;DR: SteeringTTA是一种无需模型更新的TTA框架，通过Feynman-Kac引导和伪标签奖励，在ImageNet-C上表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决基于梯度引导的输入扩散TTA方法在探索和泛化不同失真类型上的局限性。

Method: 采用Feynman-Kac引导的扩散输入适应方法，结合累积top-K概率和熵调度来平衡探索与置信度，维护多个粒子轨迹。

Result: 在ImageNet-C上，SteeringTTA无需模型更新或源数据即可持续优于基线。

Conclusion: SteeringTTA作为一种仅推理的框架，通过Feynman-Kac引导和伪标签驱动的奖励机制，在ImageNet-C上无需模型更新或源数据即可持续优于基线。

Abstract: Test-time adaptation (TTA) aims to correct performance degradation of deep
models under distribution shifts by updating models or inputs using unlabeled
test data. Input-only diffusion-based TTA methods improve robustness for
classification to corruptions but rely on gradient guidance, limiting
exploration and generalization across distortion types. We propose SteeringTTA,
an inference-only framework that adapts Feynman-Kac steering to guide
diffusion-based input adaptation for classification with rewards driven by
pseudo-label. SteeringTTA maintains multiple particle trajectories, steered by
a combination of cumulative top-K probabilities and an entropy schedule, to
balance exploration and confidence. On ImageNet-C, SteeringTTA consistently
outperforms the baseline without any model updates or source data.

</details>


### [61] [In-Context Learning with Unpaired Clips for Instruction-based Video Editing](https://arxiv.org/abs/2510.14648)
*Xinyao Liao,Xianfang Zeng,Ziye Song,Zhoujie Fu,Gang Yu,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出一种低成本预训练策略，通过未配对视频剪辑进行上下文学习，随后用少量高质量数据微调，显著提升视频编辑性能。


<details>
  <summary>Details</summary>
Motivation: 解决构建大规模配对视频编辑数据集的高成本和复杂性挑战，扩展基于指令的图像编辑到视频领域。

Method: 引入了一种基于上下文学习的低成本预训练策略，利用未配对视频剪辑进行预训练，随后用少量高质量配对编辑数据进行微调。

Result: 在指令跟随上提升了12%，在编辑质量上提升了15%。

Conclusion: 该方法通过低成本预训练策略和少量高质量配对数据的微调，显著提升了基于指令的视频编辑性能，在指令对齐和视觉保真度上均优于现有方法。

Abstract: Despite the rapid progress of instruction-based image editing, its extension
to video remains underexplored, primarily due to the prohibitive cost and
complexity of constructing large-scale paired video editing datasets. To
address this challenge, we introduce a low-cost pretraining strategy for
instruction-based video editing that leverages in-context learning from
unpaired video clips. We show that pretraining a foundation video generation
model with this strategy endows it with general editing capabilities, such as
adding, replacing, or deleting operations, according to input editing
instructions. The pretrained model can then be efficiently refined with a small
amount of high-quality paired editing data. Built upon HunyuanVideoT2V, our
framework first pretrains on approximately 1M real video clips to learn basic
editing concepts, and subsequently fine-tunes on fewer than 150k curated
editing pairs to extend more editing tasks and improve the editing quality.
Comparative experiments show that our method surpasses existing
instruction-based video editing approaches in both instruction alignment and
visual fidelity, achieving a 12\% improvement in editing instruction following
and a 15\% improvement in editing quality.

</details>


### [62] [Decorrelation Speeds Up Vision Transformers](https://arxiv.org/abs/2510.14657)
*Kieran Carrigg,Rob van Gastel,Melda Yeghaian,Sander Dalm,Faysal Boughorbel,Marcel van Gerven*

Main category: cs.CV

TL;DR: DBP-MAE通过集成DBP加速MAE预训练，减少计算成本和碳排放，同时提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决MAE预训练计算成本高的问题，使其在时间和资源受限的工业环境中更实用。

Method: 将Decorrelated Backpropagation (DBP)集成到MAE预训练中，选择性地应用于编码器以加速收敛。

Result: 在ImageNet-1K预训练和ADE20K微调中，DBP-MAE将训练时间减少21.1%，碳排放降低21.4%，分割mIoU提升1.1个百分点。

Conclusion: DBP-MAE通过减少训练时间和能源消耗，同时提升下游任务性能，证明了其在大型ViT预训练中的实用性。

Abstract: Masked Autoencoder (MAE) pre-training of vision transformers (ViTs) yields
strong performance in low-label regimes but comes with substantial
computational costs, making it impractical in time- and resource-constrained
industrial settings. We address this by integrating Decorrelated
Backpropagation (DBP) into MAE pre-training, an optimization method that
iteratively reduces input correlations at each layer to accelerate convergence.
Applied selectively to the encoder, DBP achieves faster pre-training without
loss of stability. On ImageNet-1K pre-training with ADE20K fine-tuning, DBP-MAE
reduces wall-clock time to baseline performance by 21.1%, lowers carbon
emissions by 21.4% and improves segmentation mIoU by 1.1 points. We observe
similar gains when pre-training and fine-tuning on proprietary industrial data,
confirming the method's applicability in real-world scenarios. These results
demonstrate that DBP can reduce training time and energy use while improving
downstream performance for large-scale ViT pre-training.

</details>


### [63] [EuroMineNet: A Multitemporal Sentinel-2 Benchmark for Spatiotemporal Mining Footprint Analysis in the European Union (2015-2024)](https://arxiv.org/abs/2510.14661)
*Weikang Yu,Vincent Nwazelibe,Xianping Ma,Xiaokang Zhang,Richard Gloaguen,Xiao Xiang Zhu,Pedram Ghamisi*

Main category: cs.CV

TL;DR: EuroMineNet是首个基于Sentinel-2的采矿足迹多时相基准数据集，支持GeoAI模型分析环境变化，推动可持续土地管理。


<details>
  <summary>Details</summary>
Motivation: 采矿活动是环境退化的主要来源，现有数据集在时间深度和地理范围上有限，需要长期监测采矿引起的土地利用变化。

Method: 利用Sentinel-2多光谱影像构建EuroMineNet数据集，涵盖133个欧盟矿区，提供2015至2024年的年度观测和专家验证标注，支持GeoAI模型分析环境动态。

Result: 基准测试20种最先进的深度学习模型显示，GeoAI方法能有效识别长期环境变化，但在检测短期动态方面仍有挑战。

Conclusion: EuroMineNet通过提供首个基于Sentinel-2多光谱影像的全面多时相基准数据集，推动了可持续土地利用管理和环境韧性，并支持GeoAI在社会和环境领域的应用。

Abstract: Mining activities are essential for industrial and economic development, but
remain a leading source of environmental degradation, contributing to
deforestation, soil erosion, and water contamination. Sustainable resource
management and environmental governance require consistent, long-term
monitoring of mining-induced land surface changes, yet existing datasets are
often limited in temporal depth or geographic scope. To address this gap, we
present EuroMineNet, the first comprehensive multitemporal benchmark for mining
footprint mapping and monitoring based on Sentinel-2 multispectral imagery.
Spanning 133 mining sites across the European Union, EuroMineNet provides
annual observations and expert-verified annotations from 2015 to 2024, enabling
GeoAI-based models to analyze environmental dynamics at a continental scale. It
supports two sustainability-driven tasks: (1) multitemporal mining footprint
mapping for consistent annual land-use delineation, evaluated with a novel
Change-Aware Temporal IoU (CA-TIoU) metric, and (2) cross-temporal change
detection to capture both gradual and abrupt surface transformations.
Benchmarking 20 state-of-the-art deep learning models reveals that while GeoAI
methods effectively identify long-term environmental changes, challenges remain
in detecting short-term dynamics critical for timely mitigation. By advancing
temporally consistent and explainable mining monitoring, EuroMineNet
contributes to sustainable land-use management, environmental resilience, and
the broader goal of applying GeoAI for social and environmental good. We
release the codes and datasets by aligning with FAIR and the open science
paradigm at https://github.com/EricYu97/EuroMineNet.

</details>


### [64] [WeCKD: Weakly-supervised Chained Distillation Network for Efficient Multimodal Medical Imaging](https://arxiv.org/abs/2510.14668)
*Md. Abdur Rahman,Mohaimenul Azam Khan Raiaan,Sami Azam,Asif Karim,Jemima Beissbarth,Amanda Leach*

Main category: cs.CV

TL;DR: WeCKD提出了一种链式知识蒸馏框架，通过渐进式知识传递减少数据依赖，提升模型性能，在有限数据场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法存在知识退化、监督效率低和依赖强大教师模型或大量标注数据的问题，限制了其在真实世界有限数据场景中的应用。

Method: WeCKD采用了一种渐进式的链式知识蒸馏方法，其中每个模型不仅从前驱模型中学习知识，还对其进行精炼后传递给下一个模型。

Result: 在四个耳镜成像数据集上的广泛评估表明，WeCKD不仅匹配而且常常超越现有监督方法的性能。实验还显示其在其他两种医学成像模态上的良好泛化能力，并实现了累积准确率提升高达23%。

Conclusion: WeCKD通过链式知识蒸馏框架有效解决了传统知识蒸馏方法中的知识退化、监督效率低和数据依赖性强的问题，展示了在有限数据场景下的优越性能。

Abstract: Knowledge distillation (KD) has traditionally relied on a static
teacher-student framework, where a large, well-trained teacher transfers
knowledge to a single student model. However, these approaches often suffer
from knowledge degradation, inefficient supervision, and reliance on either a
very strong teacher model or large labeled datasets, which limits their
effectiveness in real-world, limited-data scenarios. To address these, we
present the first-ever Weakly-supervised Chain-based KD network (WeCKD) that
redefines knowledge transfer through a structured sequence of interconnected
models. Unlike conventional KD, it forms a progressive distillation chain,
where each model not only learns from its predecessor but also refines the
knowledge before passing it forward. This structured knowledge transfer further
enhances feature learning, reduces data dependency, and mitigates the
limitations of one-step KD. Each model in the distillation chain is trained on
only a fraction of the dataset and demonstrates that effective learning can be
achieved with minimal supervision. Extensive evaluations across four otoscopic
imaging datasets demonstrate that it not only matches but in many cases
surpasses the performance of existing supervised methods. Experimental results
on two other datasets further underscore its generalization across diverse
medical imaging modalities, including microscopic and magnetic resonance
imaging. Furthermore, our evaluations resulted in cumulative accuracy gains of
up to +23% over a single backbone trained on the same limited data, which
highlights its potential for real-world adoption.

</details>


### [65] [VTimeCoT: Thinking by Drawing for Video Temporal Grounding and Reasoning](https://arxiv.org/abs/2510.14672)
*Jinglei Zhang,Yuanfan Guo,Rolandos Alexandros Potamias,Jiankang Deng,Hang Xu,Chao Ma*

Main category: cs.CV

TL;DR: VTimeCoT是一个无需训练的框架，通过进度条工具和视觉时间链式思维提升视频时间定位和推理问答性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于多模态大语言模型的视频问答系统在视频时间定位和推理方面存在不足，影响了实际视频理解系统的开发。

Method: 提出了一个无需训练的高效框架VTimeCoT，包含进度条集成工具和高亮工具，以及视觉时间链式思维（visuotemporal CoT）过程。

Result: 在Qwen2VL-7B和GPT4o基准测试中，VTimeCoT在视频时间定位和推理问答任务上表现出显著性能提升。

Conclusion: VTimeCoT框架通过引入进度条工具和视觉时间链式思维过程，显著提升了视频时间定位和基于推理的问答任务性能，并实现了可组合和可解释的推理过程。

Abstract: In recent years, video question answering based on multimodal large language
models (MLLM) has garnered considerable attention, due to the benefits from the
substantial advancements in LLMs. However, these models have a notable
deficiency in the domains of video temporal grounding and reasoning, posing
challenges to the development of effective real-world video understanding
systems. Inspired by how humans use video players to interact with the progress
bar for video comprehension, we introduce VTimeCoT, a simple yet effective
training-free framework, designed for high-performance video grounding and
reasoning. The proposed framework incorporates two novel visual tools of the
progress bar: a plug-and-play progress bar integration tool and a
high-efficiency highlighting tool. In addition, to address the limitations of
conventional text-based chain-of-thought (CoT) approaches, we introduce a
visuotemporal CoT process that integrates cross-modality reasoning across both
video and text. Our approach demonstrates significant performance improvements
on both Qwen2VL-7B and GPT4o baselines in tasks of video temporal grounding and
reasoning-based question answering. Finally, we showcase that the proposed
framework achieves a compositional and interpretable reasoning process. Project
page: https://vtimecot.github.io

</details>


### [66] [Leveraging Learned Image Prior for 3D Gaussian Compression](https://arxiv.org/abs/2510.14705)
*Seungjoo Shin,Jaesik Park,Sunghyun Cho*

Main category: cs.CV

TL;DR: 提出一种利用学习图像先验恢复压缩伪影的3DGS压缩框架，显著提升率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯泼溅压缩技术缺乏学习先验，限制了率失真折衷的进一步改进。

Method: 提出了一种新颖的3DGS压缩框架，利用学习到的图像先验恢复压缩引起的质量退化，并通过恢复网络建模图像空间中的压缩伪影。

Result: 实验证明，该框架在率失真性能上优于现有最先进的3DGS压缩方法，且存储需求显著降低。

Conclusion: 该框架通过结合学习到的图像先验和压缩高斯信息的恢复网络，显著提升了3D高斯泼溅压缩的率失真性能，同时保持了高渲染质量。

Abstract: Compression techniques for 3D Gaussian Splatting (3DGS) have recently
achieved considerable success in minimizing storage overhead for 3D Gaussians
while preserving high rendering quality. Despite the impressive storage
reduction, the lack of learned priors restricts further advances in the
rate-distortion trade-off for 3DGS compression tasks. To address this, we
introduce a novel 3DGS compression framework that leverages the powerful
representational capacity of learned image priors to recover
compression-induced quality degradation. Built upon initially compressed
Gaussians, our restoration network effectively models the compression artifacts
in the image space between degraded and original Gaussians. To enhance the
rate-distortion performance, we provide coarse rendering residuals into the
restoration network as side information. By leveraging the supervision of
restored images, the compressed Gaussians are refined, resulting in a highly
compact representation with enhanced rendering performance. Our framework is
designed to be compatible with existing Gaussian compression methods, making it
broadly applicable across different baselines. Extensive experiments validate
the effectiveness of our framework, demonstrating superior rate-distortion
performance and outperforming the rendering quality of state-of-the-art 3DGS
compression methods while requiring substantially less storage.

</details>


### [67] [Where are the Whales: A Human-in-the-loop Detection Method for Identifying Whales in High-resolution Satellite Imagery](https://arxiv.org/abs/2510.14709)
*Caleb Robinson,Kimberly T. Goetz,Christin B. Khan,Meredith Sackett,Kathleen Leonard,Rahul Dodhia,Juan M. Lavista Ferres*

Main category: cs.CV

TL;DR: 提出半自动化鲸鱼检测方法，通过异常检测和专家标注界面，显著提升监测效率并减少专家检查区域。


<details>
  <summary>Details</summary>
Motivation: 传统的鲸鱼种群监测方法成本高且难以扩展，而现有的高分辨率卫星图像识别方法面临标注数据不足、图像质量和环境条件变化大等问题。

Method: 提出了一种半自动化的方法，利用统计异常检测技术标记空间异常点（即“有趣点”），并结合基于网络的标注界面，使专家能够快速标注这些点。

Result: 在三个已知鲸鱼标注的基准场景中，召回率达到90.3%至96.4%，同时将需要专家检查的区域减少了99.8%（从超过1000平方公里降至不到2平方公里）。

Conclusion: 该方法通过半自动化的异常检测和专家标注界面，显著提高了鲸鱼监测的效率，减少了专家检查的区域，为未来基于机器辅助的海洋哺乳动物监测提供了可扩展的第一步。

Abstract: Effective monitoring of whale populations is critical for conservation, but
traditional survey methods are expensive and difficult to scale. While prior
work has shown that whales can be identified in very high-resolution (VHR)
satellite imagery, large-scale automated detection remains challenging due to a
lack of annotated imagery, variability in image quality and environmental
conditions, and the cost of building robust machine learning pipelines over
massive remote sensing archives. We present a semi-automated approach for
surfacing possible whale detections in VHR imagery using a statistical anomaly
detection method that flags spatial outliers, i.e. "interesting points". We
pair this detector with a web-based labeling interface designed to enable
experts to quickly annotate the interesting points. We evaluate our system on
three benchmark scenes with known whale annotations and achieve recalls of
90.3% to 96.4%, while reducing the area requiring expert inspection by up to
99.8% -- from over 1,000 sq km to less than 2 sq km in some cases. Our method
does not rely on labeled training data and offers a scalable first step toward
future machine-assisted marine mammal monitoring from space. We have open
sourced this pipeline at https://github.com/microsoft/whales.

</details>


### [68] [Camera Movement Classification in Historical Footage: A Comparative Study of Deep Video Models](https://arxiv.org/abs/2510.14713)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: 本文首次系统评估了深度视频相机运动分类模型在历史档案影片上的表现，最佳模型准确率达80.25%，并探讨了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 相机运动传递了理解视频内容所需的空间和叙事信息，但现有相机运动分类方法在历史档案影片上的泛化能力尚未被探索。

Method: 本文评估了五种标准视频分类模型在HISTORIAN数据集上的表现，该数据集包含专家标注的二战档案影片。

Result: 最佳模型Video Swin Transformer在HISTORIAN数据集上达到80.25%的准确率，显示出在有限训练数据下的强收敛性。

Conclusion: 本文展示了将现有深度视频相机运动分类模型应用于历史档案影片的潜力，尽管训练数据有限，最佳模型（Video Swin Transformer）仍能达到80.25%的准确率。未来工作应结合多样化的输入模态和时序架构以应对低质量视频的挑战。

Abstract: Camera movement conveys spatial and narrative information essential for
understanding video content. While recent camera movement classification (CMC)
methods perform well on modern datasets, their generalization to historical
footage remains unexplored. This paper presents the first systematic evaluation
of deep video CMC models on archival film material. We summarize representative
methods and datasets, highlighting differences in model design and label
definitions. Five standard video classification models are assessed on the
HISTORIAN dataset, which includes expert-annotated World War II footage. The
best-performing model, Video Swin Transformer, achieves 80.25% accuracy,
showing strong convergence despite limited training data. Our findings
highlight the challenges and potential of adapting existing models to
low-quality video and motivate future work combining diverse input modalities
and temporal architectures.

</details>


### [69] [Cross-Layer Feature Self-Attention Module for Multi-Scale Object Detection](https://arxiv.org/abs/2510.14726)
*Dingzhou Xie,Rushi Lan,Cheng Pang,Enhao Ning,Jiahao Zeng,Wei Zheng*

Main category: cs.CV

TL;DR: CFSAM模块通过跨层注意力建模显著提升多尺度目标检测性能，优于现有方法，且计算高效。


<details>
  <summary>Details</summary>
Motivation: 现有目标检测方法多局限于单层或双层的特征优化，忽略了多尺度表示间的丰富层间依赖关系，限制了其捕捉大尺度变化目标所需的全面上下文信息的能力。

Method: 提出了一种新颖的跨层特征自注意力模块（CFSAM），该模块由卷积局部特征提取器、基于Transformer的全局建模单元和特征融合机制组成。

Result: CFSAM在SSD300框架中显著提升了检测性能，在PASCAL VOC上达到78.6% mAP（基线为75.5%），在COCO上达到52.1% mAP（基线为43.1%），且未引入显著计算开销。

Conclusion: 该论文强调了显式的跨层注意力建模在推进多尺度目标检测中的重要性，并展示了CFSAM模块在提升检测性能和加速训练收敛方面的有效性。

Abstract: Recent object detection methods have made remarkable progress by leveraging
attention mechanisms to improve feature discriminability. However, most
existing approaches are confined to refining single-layer or fusing dual-layer
features, overlooking the rich inter-layer dependencies across multi-scale
representations. This limits their ability to capture comprehensive contextual
information essential for detecting objects with large scale variations. In
this paper, we propose a novel Cross-Layer Feature Self-Attention Module
(CFSAM), which holistically models both local and global dependencies within
multi-scale feature maps. CFSAM consists of three key components: a
convolutional local feature extractor, a Transformer-based global modeling unit
that efficiently captures cross-layer interactions, and a feature fusion
mechanism to restore and enhance the original representations. When integrated
into the SSD300 framework, CFSAM significantly boosts detection performance,
achieving 78.6% mAP on PASCAL VOC (vs. 75.5% baseline) and 52.1% mAP on COCO
(vs. 43.1% baseline), outperforming existing attention modules. Moreover, the
module accelerates convergence during training without introducing substantial
computational overhead. Our work highlights the importance of explicit
cross-layer attention modeling in advancing multi-scale object detection.

</details>


### [70] [Free-Grained Hierarchical Recognition](https://arxiv.org/abs/2510.14737)
*Seulki Park,Zilin Wang,Stella X. Yu*

Main category: cs.CV

TL;DR: 本文提出ImageNet-F基准和自由粒度学习方法，适应混合粒度监督，提升分层图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的图像标注粒度不一致，现有方法假设完整细粒度标注不切实际，需适应混合粒度监督。

Method: 通过CLIP模拟语义模糊性，提出自由粒度学习方法，结合伪属性和半监督学习增强语义和视觉指导。

Result: 提出的方法和基准显著提高了在混合监督条件下的分类性能。

Conclusion: 本文提出的ImageNet-F基准和自由粒度学习方法显著提升了在混合粒度监督下的分层图像分类性能，推动了现实约束条件下的分类研究。

Abstract: Hierarchical image classification predicts labels across a semantic taxonomy,
but existing methods typically assume complete, fine-grained annotations, an
assumption rarely met in practice. Real-world supervision varies in
granularity, influenced by image quality, annotator expertise, and task
demands; a distant bird may be labeled Bird, while a close-up reveals Bald
eagle. We introduce ImageNet-F, a large-scale benchmark curated from ImageNet
and structured into cognitively inspired basic, subordinate, and fine-grained
levels. Using CLIP as a proxy for semantic ambiguity, we simulate realistic,
mixed-granularity labels reflecting human annotation behavior. We propose
free-grain learning, with heterogeneous supervision across instances. We
develop methods that enhance semantic guidance via pseudo-attributes from
vision-language models and visual guidance via semi-supervised learning. These,
along with strong baselines, substantially improve performance under mixed
supervision. Together, our benchmark and methods advance hierarchical
classification under real-world constraints.

</details>


### [71] [DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models](https://arxiv.org/abs/2510.14741)
*Simone Carnemolla,Matteo Pennisi,Sarinda Samarasinghe,Giovanni Bellitto,Simone Palazzo,Daniela Giordano,Mubarak Shah,Concetto Spampinato*

Main category: cs.CV

TL;DR: DEXTER 是一种新框架，通过合成图像和文本生成视觉分类器的自然语言解释，无需训练数据，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提高机器学习模型的透明度和可信度，无需训练数据或真实标签即可解释分类器决策过程。

Method: DEXTER 通过优化文本提示合成类别条件图像，激活目标分类器，并生成自然语言报告描述类别决策模式和偏见。

Result: 在 ImageNet、Waterbirds、CelebA 和 FairFaces 上的实验表明，DEXTER 在全局模型解释和类别偏见报告方面优于现有方法。

Conclusion: DEXTER 是一种无需数据的方法，通过扩散模型和大语言模型生成视觉分类器的全局文本解释，优于现有方法。

Abstract: Understanding and explaining the behavior of machine learning models is
essential for building transparent and trustworthy AI systems. We introduce
DEXTER, a data-free framework that employs diffusion models and large language
models to generate global, textual explanations of visual classifiers. DEXTER
operates by optimizing text prompts to synthesize class-conditional images that
strongly activate a target classifier. These synthetic samples are then used to
elicit detailed natural language reports that describe class-specific decision
patterns and biases. Unlike prior work, DEXTER enables natural language
explanation about a classifier's decision process without access to training
data or ground-truth labels. We demonstrate DEXTER's flexibility across three
tasks-activation maximization, slice discovery and debiasing, and bias
explanation-each illustrating its ability to uncover the internal mechanisms of
visual classifiers. Quantitative and qualitative evaluations, including a user
study, show that DEXTER produces accurate, interpretable outputs. Experiments
on ImageNet, Waterbirds, CelebA, and FairFaces confirm that DEXTER outperforms
existing approaches in global model explanation and class-level bias reporting.
Code is available at https://github.com/perceivelab/dexter.

</details>


### [72] [LightQANet: Quantized and Adaptive Feature Learning for Low-Light Image Enhancement](https://arxiv.org/abs/2510.14753)
*Xu Wu,Zhihui Lai,Xianxu Hou,Jie Zhou,Ya-nan Zhang,Linlin Shen*

Main category: cs.CV

TL;DR: LightQANet通过量化与自适应特征学习解决了低光图像增强中的特征提取问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低光条件下难以提取可靠特征，导致纹理恢复差、颜色不一致和伪影问题。

Method: 提出了LightQANet框架，包含静态建模的Light Quantization Module（LQM）和动态适应的Light-Aware Prompt Module（LAPM），分别用于量化光照相关特征和动态引导特征学习。

Result: 在多个低光数据集上实现了最先进的性能，定性定量结果均表现优异。

Conclusion: LightQANet通过量化与自适应特征学习，在多种光照条件下实现了高质量的低光图像增强，实验证明其性能优于现有方法。

Abstract: Low-light image enhancement (LLIE) aims to improve illumination while
preserving high-quality color and texture. However, existing methods often fail
to extract reliable feature representations due to severely degraded
pixel-level information under low-light conditions, resulting in poor texture
restoration, color inconsistency, and artifact. To address these challenges, we
propose LightQANet, a novel framework that introduces quantized and adaptive
feature learning for low-light enhancement, aiming to achieve consistent and
robust image quality across diverse lighting conditions. From the static
modeling perspective, we design a Light Quantization Module (LQM) to explicitly
extract and quantify illumination-related factors from image features. By
enforcing structured light factor learning, LQM enhances the extraction of
light-invariant representations and mitigates feature inconsistency across
varying illumination levels. From the dynamic adaptation perspective, we
introduce a Light-Aware Prompt Module (LAPM), which encodes illumination priors
into learnable prompts to dynamically guide the feature learning process. LAPM
enables the model to flexibly adapt to complex and continuously changing
lighting conditions, further improving image enhancement. Extensive experiments
on multiple low-light datasets demonstrate that our method achieves
state-of-the-art performance, delivering superior qualitative and quantitative
results across various challenging lighting scenarios.

</details>


### [73] [MoCom: Motion-based Inter-MAV Visual Communication Using Event Vision and Spiking Neural Networks](https://arxiv.org/abs/2510.14770)
*Zhang Nengbo,Hann Woei Ho,Ye Zhou*

Main category: cs.CV

TL;DR: 受蜜蜂摇摆舞启发，论文提出了一种基于视觉运动的MAV群通信框架，利用四种运动模式传递信息，并通过事件相机和SNN实现解码，实验证明其高效且低功耗。


<details>
  <summary>Details</summary>
Motivation: 传统无线电通信在MAV群中面临频谱拥堵、干扰和高功耗等问题，而蜜蜂的摇摆舞启发了一种无需声音或接触的高效通信方式，促使研究者探索基于视觉的替代方案。

Method: 通过设计由四种运动基元（垂直、水平、左-上-右、左-下-右）组成的视觉码本，MAV利用飞行模式传递信息。采用事件帧分割模型和轻量级脉冲神经网络（SNN）进行动作识别，结合解码算法实现信号解析。

Result: 实验结果表明，该框架能够准确解码MAV运动序列，同时保持低功耗，验证了其在受限环境中的实用性和能效优势。

Conclusion: 该论文提出了一种基于视觉的运动信号框架，用于微型飞行器（MAV）群在受限环境中的高效通信，实验验证了其解码准确性和低功耗特性，展示了其在替代传统无线电通信方面的潜力。

Abstract: Reliable communication in Micro Air Vehicle (MAV) swarms is challenging in
environments, where conventional radio-based methods suffer from spectrum
congestion, jamming, and high power consumption. Inspired by the waggle dance
of honeybees, which efficiently communicate the location of food sources
without sound or contact, we propose a novel visual communication framework for
MAV swarms using motion-based signaling. In this framework, MAVs convey
information, such as heading and distance, through deliberate flight patterns,
which are passively captured by event cameras and interpreted using a
predefined visual codebook of four motion primitives: vertical (up/down),
horizontal (left/right), left-to-up-to-right, and left-to-down-to-right,
representing control symbols (``start'', ``end'', ``1'', ``0''). To decode
these signals, we design an event frame-based segmentation model and a
lightweight Spiking Neural Network (SNN) for action recognition. An integrated
decoding algorithm then combines segmentation and classification to robustly
interpret MAV motion sequences. Experimental results validate the framework's
effectiveness, which demonstrates accurate decoding and low power consumption,
and highlights its potential as an energy-efficient alternative for MAV
communication in constrained environments.

</details>


### [74] [CoT-PL: Visual Chain-of-Thought Reasoning Meets Pseudo-Labeling for Open-Vocabulary Object Detection](https://arxiv.org/abs/2510.14792)
*Hojun Choi,Youngsun Lim,Jaeyo Shin,Hyunjung Shim*

Main category: cs.CV

TL;DR: CoT-PL通过视觉链式推理和对比背景学习，显著提升了开放词汇目标检测在复杂场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇目标检测方法过度依赖直接的图像-文本匹配，缺乏对语义复杂场景的中间推理步骤，导致在拥挤或遮挡场景中鲁棒性不足。

Method: CoT-PL将对象理解分解为三个可解释的步骤：区域感知、零样本类别识别和背景分离，并结合对比背景学习（CBL）来增强特征解耦。

Result: CoT-PL在拥挤和遮挡场景中的新类别伪标签质量分别比现有最佳方法提升了103.4%和168.4%，并在开放词汇COCO和LVIS数据集上分别实现了+7.7 AP50和+2.9 mask AP的提升。

Conclusion: CoT-PL通过引入视觉链式推理和对比背景学习，显著提升了在拥挤或遮挡场景中的伪标签质量，并在开放词汇目标检测任务中实现了新的最佳性能。

Abstract: Open-vocabulary object detection (OVD) seeks to recognize and localize object
categories beyond those seen during training. Recent approaches typically
leverage vision-language models (VLMs) to generate pseudo-labels using
image-text alignment, allowing detectors to generalize to unseen classes
without explicit supervision. However, these methods depend heavily on direct
image-text matching, neglecting the intermediate reasoning steps essential for
interpreting semantically complex scenes. This results in limited robustness
when confronted with crowded or occluded visual contexts. In this paper, we
introduce CoT-PL, a new framework that employs structured visual
chain-of-thought (CoT) reasoning into the pseudo-labeling process. CoT-PL
decomposes object understanding into three interpretable steps: (1) region
perception even for unseen objects, (2) category recognition via zero-shot
reasoning, and (3) background grounding to separate semantically complex
objects. Crucially, the third step naturally motivates our contrastive
background learning (CBL) that uses the pre-computed background cues as
negatives to promote feature disentanglement between objects and background. In
this way, CoT reasoning and CBL form an integrated pipeline tailored to robust
pseudo-labeling in crowded or occluded scenes. Notably, in these two settings,
our novel-class pseudo-label quality achieves relative improvements of 103.4%
and 168.4% over the best prior, respectively. Our extensive experiments
demonstrate that CoT-PL achieves +7.7 AP50 on open-vocabulary COCO and +2.9
mask AP on LVIS for novel classes, setting a new state of the art.

</details>


### [75] [Morphology-Aware Prognostic model for Five-Year Survival Prediction in Colorectal Cancer from H&E Whole Slide Images](https://arxiv.org/abs/2510.14800)
*Usama Sajjad,Abdul Rehman Akbar,Ziyu Su,Deborah Knight,Wendy L. Frankel,Metin N. Gurcan,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: PRISM是一种新型可解释AI模型，通过整合形态学连续变异谱，显著提升结直肠癌预后预测性能，并展示跨亚组稳健性。


<details>
  <summary>Details</summary>
Motivation: 结直肠癌是全球第三大常见恶性肿瘤，现有计算方法常忽略器官特异性形态模式，这些模式可能对肿瘤行为、治疗反应和患者结局产生根本影响。

Method: 开发了PRISM（Prognostic Representation of Integrated Spatial Morphology）模型，该模型通过整合连续变异谱来表征表型多样性，训练于424名III期结直肠癌患者的874万张组织学图像。

Result: PRISM在五年总生存期预测中表现优异（AUC=0.70，准确率68.37%），优于现有方法15%，且在不同治疗方案中性能稳定。

Conclusion: PRISM模型在结直肠癌预后预测中表现出色，优于现有方法，并展示了性别无关的稳健性和跨临床病理亚组的稳定性能。

Abstract: Colorectal cancer (CRC) remains the third most prevalent malignancy globally,
with approximately 154,000 new cases and 54,000 projected deaths anticipated
for 2025. The recent advancement of foundation models in computational
pathology has been largely propelled by task agnostic methodologies that can
overlook organ-specific crucial morphological patterns that represent distinct
biological processes that can fundamentally influence tumor behavior,
therapeutic response, and patient outcomes. The aim of this study is to develop
a novel, interpretable AI model, PRISM (Prognostic Representation of Integrated
Spatial Morphology), that incorporates a continuous variability spectrum within
each distinct morphology to characterize phenotypic diversity and reflecting
the principle that malignant transformation occurs through incremental
evolutionary processes rather than abrupt phenotypic shifts. PRISM is trained
on 8.74 million histological images extracted from surgical resection specimens
of 424 patients with stage III CRC. PRISM achieved superior prognostic
performance for five-year OS (AUC = 0.70 +- 0.04; accuracy = 68.37% +- 4.75%;
HR = 3.34, 95% CI = 2.28-4.90; p < 0.0001), outperforming existing CRC-specific
methods by 15% and AI foundation models by ~23% accuracy. It showed
sex-agnostic robustness (AUC delta = 0.02; accuracy delta = 0.15%) and stable
performance across clinicopathological subgroups, with minimal accuracy
fluctuation (delta = 1.44%) between 5FU/LV and CPT-11/5FU/LV regimens,
replicating the Alliance cohort finding of no survival difference between
treatments.

</details>


### [76] [Scaling Artificial Intelligence for Multi-Tumor Early Detection with More Reports, Fewer Masks](https://arxiv.org/abs/2510.14803)
*Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Szymon Płotka,Jieneng Chen,Qi Chen,Zheren Zhu,Jakub Prządo,Ibrahim E. Hamacı,Sezgin Er,Yuhan Wang,Ashwin Kumar,Bjoern Menze,Jarosław B. Ćwikła,Yuyin Zhou,Akshay S. Chaudhari,Curtis P. Langlotz,Sergio Decherchi,Andrea Cavalli,Kang Wang,Yang Yang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: R-Super利用医学报告训练AI分割肿瘤，减少对手工标记的依赖，性能媲美传统方法，甚至在某些肿瘤类型上超越放射科医生。


<details>
  <summary>Details</summary>
Motivation: 早期肿瘤检测可以挽救生命，但CT扫描中检测小或早期肿瘤具有挑战性。AI模型需要大量肿瘤标记进行训练，而手工绘制这些标记成本高昂且耗时。

Method: 引入R-Super方法，通过训练AI根据医学报告中的描述分割肿瘤，利用大量现成的医学报告进行AI训练，显著减少对手工绘制肿瘤标记的需求。

Result: 在101,654份报告上训练的AI模型性能与723个标记训练的模型相当。结合报告和标记进一步提高了灵敏度和特异性，在检测七种肿瘤类型中的五种时超越了放射科医生。

Conclusion: 本研究挑战了大规模、劳动密集型肿瘤标记创建不可或缺的长期信念，为多样肿瘤类型的早期检测建立了一条可扩展且易于实施的路径。

Abstract: Early tumor detection save lives. Each year, more than 300 million computed
tomography (CT) scans are performed worldwide, offering a vast opportunity for
effective cancer screening. However, detecting small or early-stage tumors on
these CT scans remains challenging, even for experts. Artificial intelligence
(AI) models can assist by highlighting suspicious regions, but training such
models typically requires extensive tumor masks--detailed, voxel-wise outlines
of tumors manually drawn by radiologists. Drawing these masks is costly,
requiring years of effort and millions of dollars. In contrast, nearly every CT
scan in clinical practice is already accompanied by medical reports describing
the tumor's size, number, appearance, and sometimes, pathology
results--information that is rich, abundant, and often underutilized for AI
training. We introduce R-Super, which trains AI to segment tumors that match
their descriptions in medical reports. This approach scales AI training with
large collections of readily available medical reports, substantially reducing
the need for manually drawn tumor masks. When trained on 101,654 reports, AI
models achieved performance comparable to those trained on 723 masks. Combining
reports and masks further improved sensitivity by +13% and specificity by +8%,
surpassing radiologists in detecting five of the seven tumor types. Notably,
R-Super enabled segmentation of tumors in the spleen, gallbladder, prostate,
bladder, uterus, and esophagus, for which no public masks or AI models
previously existed. This study challenges the long-held belief that
large-scale, labor-intensive tumor mask creation is indispensable, establishing
a scalable and accessible path toward early detection across diverse tumor
types.
  We plan to release our trained models, code, and dataset at
https://github.com/MrGiovanni/R-Super

</details>


### [77] [Unifying Environment Perception and Route Choice Modeling for Trajectory Representation Learning](https://arxiv.org/abs/2510.14819)
*Ji Cao,Yu Wang,Tongya Zheng,Zujie Ren,Canghong Jin,Gang Chen,Mingli Song*

Main category: cs.CV

TL;DR: PRTraj提出了一种结合环境感知和路径选择建模的轨迹表示学习框架，显著提升了多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有TRL方法忽略了轨迹形成的外部环境和内部路径选择行为，导致表示学习效果受限。

Method: PRTraj框架包含环境感知模块和路径选择编码器，前者从POI分布中捕捉多粒度环境语义，后者将轨迹建模为一系列决策序列。

Result: 在3个真实数据集和5个下游任务上的实验验证了PRTraj的有效性和泛化性，尤其在少样本场景下表现稳健。

Conclusion: PRTraj通过结合环境感知和路径选择建模，显著提升了轨迹表示学习的性能，并在多种下游任务中展现出优越的泛化能力和数据效率。

Abstract: Trajectory Representation Learning (TRL) aims to encode raw trajectories into
low-dimensional vectors, which can then be leveraged in various downstream
tasks, including travel time estimation, location prediction, and trajectory
similarity analysis. However, existing TRL methods suffer from a key oversight:
treating trajectories as isolated spatio-temporal sequences, without
considering the external environment and internal route choice behavior that
govern their formation. To bridge this gap, we propose a novel framework that
unifies comprehensive environment \textbf{P}erception and explicit
\textbf{R}oute choice modeling for effective \textbf{Traj}ectory representation
learning, dubbed \textbf{PRTraj}. Specifically, PRTraj first introduces an
Environment Perception Module to enhance the road network by capturing
multi-granularity environmental semantics from surrounding POI distributions.
Building on this environment-aware backbone, a Route Choice Encoder then
captures the route choice behavior inherent in each trajectory by modeling its
constituent road segment transitions as a sequence of decisions. These
route-choice-aware representations are finally aggregated to form the global
trajectory embedding. Extensive experiments on 3 real-world datasets across 5
downstream tasks validate the effectiveness and generalizability of PRTraj.
Moreover, PRTraj demonstrates strong data efficiency, maintaining robust
performance under few-shot scenarios. Our code is available at:
https://anonymous.4open.science/r/PRTraj.

</details>


### [78] [FraQAT: Quantization Aware Training with Fractional bits](https://arxiv.org/abs/2510.14823)
*Luca Morreale,Alberto Gil C. P. Ramos,Malcolm Chadwick,Mehid Noroozi,Ruchika Chavhan,Abhinav Mehrotra,Sourav Bhattacharya*

Main category: cs.CV

TL;DR: SHORT是一种渐进式分数位量化方法，能在降低模型精度的同时保持生成质量，适用于移动设备部署。


<details>
  <summary>Details</summary>
Motivation: 尽管现有量化方法可以解决效率和内存限制问题，但在保持模型质量方面仍面临挑战。

Method: 采用渐进式降低模型精度的方法，从32位降至4位，并在优化过程中利用分数位来保持高质量生成。

Result: SHORT方法在多种扩散模型上表现出更高的生成质量，FiD比标准QAT低4-7%，并在三星S25U上成功部署。

Conclusion: 提出的SHORT方法在保持生成质量的同时，成功实现了模型的高效量化，并在实际设备上成功部署。

Abstract: State-of-the-art (SOTA) generative models have demonstrated impressive
capabilities in image synthesis or text generation, often with a large capacity
model. However, these large models cannot be deployed on smartphones due to the
limited availability of on-board memory and computations. Quantization methods
lower the precision of the model parameters, allowing for efficient
computations, \eg, in \INT{8}. Although aggressive quantization addresses
efficiency and memory constraints, preserving the quality of the model remains
a challenge. To retain quality in previous aggressive quantization, we propose
a new fractional bits quantization (\short) approach. The novelty is a simple
yet effective idea: we progressively reduce the model's precision from 32 to 4
bits per parameter, and exploit the fractional bits during optimization to
maintain high generation quality. We show that the \short{} yields improved
quality on a variety of diffusion models, including SD3.5-Medium, Sana,
\pixart, and FLUX.1-schnell, while achieving $4-7\%$ lower FiD than standard
QAT. Finally, we deploy and run Sana on a Samsung S25U, which runs on the
Qualcomm SM8750-AB Snapdragon 8 Elite Hexagon Tensor Processor (HTP).

</details>


### [79] [Scaling Tumor Segmentation: Best Lessons from Real and Synthetic Data](https://arxiv.org/abs/2510.14831)
*Qi Chen,Xinze Zhou,Chen Liu,Hao Chen,Wenxuan Li,Zekun Jiang,Ziyan Huang,Yuxuan Zhao,Dexin Yu,Junjun He,Yefeng Zheng,Ling Shao,Alan Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: 通过合成数据和真实数据结合，AbdomenAtlas 2.0 显著提升了 AI 肿瘤分割性能，优于现有公共数据集。


<details>
  <summary>Details</summary>
Motivation: 解决 AI 肿瘤分割因缺乏大规模、体素级注释数据集而受限的问题，特别是这些数据集难以创建且需要医疗专家参与。

Method: 利用合成数据和真实数据结合的方法，创建了 AbdomenAtlas 2.0 数据集，包含 10,135 CT 扫描和 15,130 个肿瘤实例的体素级注释。

Result: AbdomenAtlas 2.0 在分布内测试中实现了 +7% DSC 增益，在分布外测试中实现了 +16% DSC 增益。

Conclusion: AbdomenAtlas 2.0 提供了一个强大的基础，基于从 JHH 数据集中学到的经验，用于训练 AI 在六个器官中分割肿瘤，显著优于现有公共数据集。

Abstract: AI for tumor segmentation is limited by the lack of large, voxel-wise
annotated datasets, which are hard to create and require medical experts. In
our proprietary JHH dataset of 3,000 annotated pancreatic tumor scans, we found
that AI performance stopped improving after 1,500 scans. With synthetic data,
we reached the same performance using only 500 real scans. This finding
suggests that synthetic data can steepen data scaling laws, enabling more
efficient model training than real data alone. Motivated by these lessons, we
created AbdomenAtlas 2.0--a dataset of 10,135 CT scans with a total of 15,130
tumor instances per-voxel manually annotated in six organs (pancreas, liver,
kidney, colon, esophagus, and uterus) and 5,893 control scans. Annotated by 23
expert radiologists, it is several orders of magnitude larger than existing
public tumor datasets. While we continue expanding the dataset, the current
version of AbdomenAtlas 2.0 already provides a strong foundation--based on
lessons from the JHH dataset--for training AI to segment tumors in six organs.
It achieves notable improvements over public datasets, with a +7% DSC gain on
in-distribution tests and +16% on out-of-distribution tests.

</details>


### [80] [ImagerySearch: Adaptive Test-Time Search for Video Generation Beyond Semantic Dependency Constraints](https://arxiv.org/abs/2510.14847)
*Meiqi Wu,Jiashu Zhu,Xiaokun Feng,Chubin Chen,Chen Zhu,Bingze Song,Fangyuan Mao,Jiahong Wu,Xiangxiang Chu,Kaiqi Huang*

Main category: cs.CV

TL;DR: ImagerySearch通过动态调整搜索空间和奖励函数，显著提升了视频生成模型在想象力场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在想象力场景中表现不佳，主要由于固定搜索空间和静态奖励设计无法适应长距离语义关系。

Method: 提出了ImagerySearch，一种基于提示的自适应测试时间搜索策略，动态调整推理搜索空间和奖励函数。

Result: 在LDT-Bench和VBench上，ImagerySearch均优于现有基线方法和测试时间缩放方法。

Conclusion: ImagerySearch通过动态调整推理搜索空间和奖励函数，显著提升了视频生成模型在想象力场景中的表现，并在LDT-Bench和VBench上验证了其有效性。

Abstract: Video generation models have achieved remarkable progress, particularly
excelling in realistic scenarios; however, their performance degrades notably
in imaginative scenarios. These prompts often involve rarely co-occurring
concepts with long-distance semantic relationships, falling outside training
distributions. Existing methods typically apply test-time scaling for improving
video quality, but their fixed search spaces and static reward designs limit
adaptability to imaginative scenarios. To fill this gap, we propose
ImagerySearch, a prompt-guided adaptive test-time search strategy that
dynamically adjusts both the inference search space and reward function
according to semantic relationships in the prompt. This enables more coherent
and visually plausible videos in challenging imaginative settings. To evaluate
progress in this direction, we introduce LDT-Bench, the first dedicated
benchmark for long-distance semantic prompts, consisting of 2,839 diverse
concept pairs and an automated protocol for assessing creative generation
capabilities. Extensive experiments show that ImagerySearch consistently
outperforms strong video generation baselines and existing test-time scaling
approaches on LDT-Bench, and achieves competitive improvements on VBench,
demonstrating its effectiveness across diverse prompt types. We will release
LDT-Bench and code to facilitate future research on imaginative video
generation.

</details>


### [81] [A Multi-Task Deep Learning Framework for Skin Lesion Classification, ABCDE Feature Quantification, and Evolution Simulation](https://arxiv.org/abs/2510.14855)
*Harsha Kotla,Arun Kumar Rajasekaran,Hannah Rana*

Main category: cs.CV

TL;DR: 提出深度学习框架，量化ABCDE特征评分并模拟其演变，分类准确率89%，黑色素瘤AUC0.96，边界不规则性建模仍具挑战。


<details>
  <summary>Details</summary>
Motivation: 早期检测黑色素瘤对提高生存率至关重要，但自动化皮肤病变分析仍具挑战性。现有方法（如ABCDE分类法）多为黑箱，缺乏可解释性。本研究旨在结合分类与特征量化，模拟病变演变，提供更直观的临床解释。

Method: 提出了一种深度学习框架，量化ABCDE特征的评分并模拟其随时间演变，可视化特征在潜在空间中的轨迹。使用HAM10000数据集（包含约一万张不同阶段皮肤病变图像）进行实验。

Result: 分类准确率为89%，黑色素瘤AUC为0.96。ABCD特征评估中，不对称性、颜色变化和直径预测表现良好，边界不规则性建模较困难。

Conclusion: 本研究提出了一个深度学习框架，不仅将皮肤病变分类为不同类别，还量化了ABCDE特征的评分，模拟了这些特征随时间的演变，为未来研究打开了更多窗口。分类准确率达89%，黑色素瘤AUC为0.96，ABCD特征评估在预测不对称性、颜色变化和直径方面表现良好，但边界不规则性建模仍具挑战性。

Abstract: Early detection of melanoma has grown to be essential because it
significantly improves survival rates, but automated analysis of skin lesions
still remains challenging. ABCDE, which stands for Asymmetry, Border
irregularity, Color variation, Diameter, and Evolving, is a well-known
classification method for skin lesions, but most deep learning mechanisms treat
it as a black box, as most of the human interpretable features are not
explained. In this work, we propose a deep learning framework that both
classifies skin lesions into categories and also quantifies scores for each
ABCD feature. It simulates the evolution of these features over time in order
to represent the E aspect, opening more windows for future exploration. The A,
B, C, and D values are quantified particularly within this work. Moreover, this
framework also visualizes ABCD feature trajectories in latent space as skin
lesions evolve from benign nevuses to malignant melanoma. The experiments are
conducted using the HAM10000 dataset that contains around ten thousand images
of skin lesions of varying stages. In summary, the classification worked with
an accuracy of around 89 percent, with melanoma AUC being 0.96, while the
feature evaluation performed well in predicting asymmetry, color variation, and
diameter, though border irregularity remains more difficult to model. Overall,
this work provides a deep learning framework that will allow doctors to link ML
diagnoses to clinically relevant criteria, thus improving our understanding of
skin cancer progression.

</details>


### [82] [Benchmarking Multimodal Large Language Models for Face Recognition](https://arxiv.org/abs/2510.14866)
*Hatef Otroshi Shahreza,Sébastien Marcel*

Main category: cs.CV

TL;DR: MLLMs在面部识别任务中表现不如专用模型，但为未来模型设计提供了方向。


<details>
  <summary>Details</summary>
Motivation: 评估开源MLLMs在面部识别任务中的潜力，并与现有专用模型进行比较。

Method: 在多个标准面部识别数据集（如LFW、CALFW等）上对MLLMs进行系统性基准测试。

Result: MLLMs在零样本应用中落后于专用模型，但能捕捉丰富的语义线索。

Conclusion: 多模态大语言模型（MLLMs）在面部识别任务中表现不如专用模型，但为下一代高精度和泛化能力更强的模型设计提供了基础。

Abstract: Multimodal large language models (MLLMs) have achieved remarkable performance
across diverse vision-and-language tasks. However, their potential in face
recognition remains underexplored. In particular, the performance of
open-source MLLMs needs to be evaluated and compared with existing face
recognition models on standard benchmarks with similar protocol. In this work,
we present a systematic benchmark of state-of-the-art MLLMs for face
recognition on several face recognition datasets, including LFW, CALFW, CPLFW,
CFP, AgeDB and RFW. Experimental results reveal that while MLLMs capture rich
semantic cues useful for face-related tasks, they lag behind specialized models
in high-precision recognition scenarios in zero-shot applications. This
benchmark provides a foundation for advancing MLLM-based face recognition,
offering insights for the design of next-generation models with higher accuracy
and generalization. The source code of our benchmark is publicly available in
the project page.

</details>


### [83] [MaskCaptioner : Learning to Jointly Segment and Caption Object Trajectories in Videos](https://arxiv.org/abs/2510.14904)
*Gabriel Fiastre,Antoine Yang,Cordelia Schmid*

Main category: cs.CV

TL;DR: DVOC任务通过合成标注和端到端模型MaskCaptioner，在多个基准测试中取得最优效果。


<details>
  <summary>Details</summary>
Motivation: 由于DVOC任务复杂且人工标注成本高，现有方法采用分离训练策略导致性能不佳。

Method: 利用合成标注扩展LVIS和LV-VIS数据集，训练端到端模型MaskCaptioner，实现检测、分割、跟踪和描述功能。

Result: MaskCaptioner在VidSTG、VLN和BenSMOT三个基准测试中达到最优效果。

Conclusion: 通过合成标注和端到端模型，DVOC任务性能显著提升，数据集和代码已开源。

Abstract: Dense Video Object Captioning (DVOC) is the task of jointly detecting,
tracking, and captioning object trajectories in a video, requiring the ability
to understand spatio-temporal details and describe them in natural language.
Due to the complexity of the task and the high cost associated with manual
annotation, previous approaches resort to disjoint training strategies,
potentially leading to suboptimal performance. To circumvent this issue, we
propose to generate captions about spatio-temporally localized entities
leveraging a state-of-the-art VLM. By extending the LVIS and LV-VIS datasets
with our synthetic captions (LVISCap and LV-VISCap), we train MaskCaptioner, an
end-to-end model capable of jointly detecting, segmenting, tracking and
captioning object trajectories. Moreover, with pretraining on LVISCap and
LV-VISCap, MaskCaptioner achieves state-of-the-art DVOC results on three
existing benchmarks, VidSTG, VLN and BenSMOT. The datasets and code are
available at https://www.gabriel.fiastre.fr/maskcaptioner/.

</details>


### [84] [TOUCH: Text-guided Controllable Generation of Free-Form Hand-Object Interactions](https://arxiv.org/abs/2510.14874)
*Guangyi Han,Wei Zhai,Yuhang Yang,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: 本文提出Free-Form HOI Generation方法，通过WildO2数据集和TOUCH框架生成多样且物理合理的手与物体交互。


<details>
  <summary>Details</summary>
Motivation: 现有HOI生成研究局限于固定的抓取模式，无法捕捉日常HOI的多样性。本文旨在通过细粒度意图控制生成更自由的交互。

Method: 构建了WildO2数据集，包含4.4k种独特交互，并提出TOUCH框架，采用多级扩散模型和显式接触建模来实现细粒度语义控制。

Result: 实验证明，该方法能够生成可控、多样且物理合理的HOI，能够代表日常活动。

Conclusion: 本文提出了一种名为Free-Form HOI Generation的新方法，旨在生成可控、多样且物理合理的手与物体交互（HOI），并通过WildO2数据集和TOUCH框架展示了其有效性。

Abstract: Hand-object interaction (HOI) is fundamental for humans to express intent.
Existing HOI generation research is predominantly confined to fixed grasping
patterns, where control is tied to physical priors such as force closure or
generic intent instructions, even when expressed through elaborate language.
Such an overly general conditioning imposes a strong inductive bias for stable
grasps, thus failing to capture the diversity of daily HOI. To address these
limitations, we introduce Free-Form HOI Generation, which aims to generate
controllable, diverse, and physically plausible HOI conditioned on fine-grained
intent, extending HOI from grasping to free-form interactions, like pushing,
poking, and rotating. To support this task, we construct WildO2, an in-the-wild
diverse 3D HOI dataset, which includes diverse HOI derived from internet
videos. Specifically, it contains 4.4k unique interactions across 92 intents
and 610 object categories, each with detailed semantic annotations. Building on
this dataset, we propose TOUCH, a three-stage framework centered on a
multi-level diffusion model that facilitates fine-grained semantic control to
generate versatile hand poses beyond grasping priors. This process leverages
explicit contact modeling for conditioning and is subsequently refined with
contact consistency and physical constraints to ensure realism. Comprehensive
experiments demonstrate our method's ability to generate controllable, diverse,
and physically plausible hand interactions representative of daily activities.
The project page is $\href{https://guangyid.github.io/hoi123touch}{here}$.

</details>


### [85] [RealDPO: Real or Not Real, that is the Preference](https://arxiv.org/abs/2510.14955)
*Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: RealDPO通过真实数据驱动的偏好学习，显著提升视频生成模型的运动真实性和质量。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在复杂运动合成上表现不足，生成的运动往往不够自然、流畅或上下文一致，限制了实际应用。

Method: 提出RealDPO框架，利用Direct Preference Optimization（DPO）和定制损失函数，通过对比真实世界视频与错误模型输出来迭代优化运动合成质量。

Result: 实验表明，RealDPO在视频质量、文本对齐和运动真实性方面优于当前最先进模型和其他偏好优化技术。

Conclusion: RealDPO通过引入真实世界数据作为偏好学习的正样本，显著提升了视频生成模型的运动真实性和质量，为复杂运动合成提供了有效的解决方案。

Abstract: Video generative models have recently achieved notable advancements in
synthesis quality. However, generating complex motions remains a critical
challenge, as existing models often struggle to produce natural, smooth, and
contextually consistent movements. This gap between generated and real-world
motions limits their practical applicability. To address this issue, we
introduce RealDPO, a novel alignment paradigm that leverages real-world data as
positive samples for preference learning, enabling more accurate motion
synthesis. Unlike traditional supervised fine-tuning (SFT), which offers
limited corrective feedback, RealDPO employs Direct Preference Optimization
(DPO) with a tailored loss function to enhance motion realism. By contrasting
real-world videos with erroneous model outputs, RealDPO enables iterative
self-correction, progressively refining motion quality. To support
post-training in complex motion synthesis, we propose RealAction-5K, a curated
dataset of high-quality videos capturing human daily activities with rich and
precise motion details. Extensive experiments demonstrate that RealDPO
significantly improves video quality, text alignment, and motion realism
compared to state-of-the-art models and existing preference optimization
techniques.

</details>


### [86] [BADAS: Context Aware Collision Prediction Using Real-World Dashcam Data](https://arxiv.org/abs/2510.14876)
*Roni Goldshmidt,Hamish Scott,Lorenzo Niccolini,Shizhan Zhu,Daniel Moura,Orly Zvitia*

Main category: cs.CV

TL;DR: BADAS是一种新型碰撞预测模型，通过重新标注数据集和端到端训练，显著减少了误报，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的碰撞预测方法通常无法区分自我车辆威胁和不涉及自我车辆的随机事故，导致在实际部署中产生过多的误报。为了解决这一问题，作者提出了BADAS模型家族，专门用于以自我为中心的评估。

Method: BADAS使用V-JEPA2骨干网络进行端到端训练，分为BADAS-Open（基于1.5k公开视频训练）和BADAS1.0（基于40k专有视频训练）两种变体。作者重新标注了主要基准以识别自我车辆参与情况，并添加共识警报时间标签，必要时合成负样本，以实现公平的AP/AUC和时间评估。

Result: 在DAD、DADA-2000、DoTA和Nexar数据集上，BADAS实现了最先进的AP/AUC性能，并优于前向碰撞ADAS基线，同时提供了更真实的事故时间估计。

Conclusion: BADAS系列模型在多个数据集上实现了最先进的AP/AUC性能，并优于前向碰撞ADAS基线，同时提供了更真实的事故时间估计。作者还发布了BADAS-Open模型权重、代码以及所有评估数据集的重新标注，以促进以自我为中心的碰撞预测研究。

Abstract: Existing collision prediction methods often fail to distinguish between
ego-vehicle threats and random accidents not involving the ego vehicle, leading
to excessive false alerts in real-world deployment. We present BADAS, a family
of collision prediction models trained on Nexar's real-world dashcam collision
dataset -- the first benchmark designed explicitly for ego-centric evaluation.
We re-annotate major benchmarks to identify ego involvement, add consensus
alert-time labels, and synthesize negatives where needed, enabling fair AP/AUC
and temporal evaluation. BADAS uses a V-JEPA2 backbone trained end-to-end and
comes in two variants: BADAS-Open (trained on our 1.5k public videos) and
BADAS1.0 (trained on 40k proprietary videos). Across DAD, DADA-2000, DoTA, and
Nexar, BADAS achieves state-of-the-art AP/AUC and outperforms a
forward-collision ADAS baseline while producing more realistic time-to-accident
estimates. We release our BADAS-Open model weights and code, along with
re-annotations of all evaluation datasets to promote ego-centric collision
prediction research.

</details>


### [87] [ScaleWeaver: Weaving Efficient Controllable T2I Generation with Multi-Scale Reference Attention](https://arxiv.org/abs/2510.14882)
*Keli Liu,Zhendong Wang,Wengang Zhou,Shaodong Xu,Ruixiao Dong,Houqiang Li*

Main category: cs.CV

TL;DR: ScaleWeaver 是一个基于 VAR 模型的可控文本到图像生成框架，通过改进的 MMDiT 和 Reference Attention 模块实现高效控制。


<details>
  <summary>Details</summary>
Motivation: 尽管 VAR 模型在生成保真度和推理效率上取得了进展，但其控制机制仍未被充分探索。

Method: ScaleWeaver 框架通过参数高效微调，改进了 MMDiT 模块并引入了 Reference Attention 模块，有效整合条件信息。

Result: 实验表明，ScaleWeaver 在保持高质量生成的同时，实现了精确控制和更高的效率。

Conclusion: ScaleWeaver 是一个高效且实用的解决方案，用于在视觉自回归范式中实现可控的文本到图像生成。

Abstract: Text-to-image generation with visual autoregressive~(VAR) models has recently
achieved impressive advances in generation fidelity and inference efficiency.
While control mechanisms have been explored for diffusion models, enabling
precise and flexible control within VAR paradigm remains underexplored. To
bridge this critical gap, in this paper, we introduce ScaleWeaver, a novel
framework designed to achieve high-fidelity, controllable generation upon
advanced VAR models through parameter-efficient fine-tuning. The core module in
ScaleWeaver is the improved MMDiT block with the proposed Reference Attention
module, which efficiently and effectively incorporates conditional information.
Different from MM Attention, the proposed Reference Attention module discards
the unnecessary attention from image$\rightarrow$condition, reducing
computational cost while stabilizing control injection. Besides, it
strategically emphasizes parameter reuse, leveraging the capability of the VAR
backbone itself with a few introduced parameters to process control
information, and equipping a zero-initialized linear projection to ensure that
control signals are incorporated effectively without disrupting the generative
capability of the base model. Extensive experiments show that ScaleWeaver
delivers high-quality generation and precise control while attaining superior
efficiency over diffusion-based methods, making ScaleWeaver a practical and
effective solution for controllable text-to-image generation within the visual
autoregressive paradigm. Code and models will be released.

</details>


### [88] [C4D: 4D Made from 3D through Dual Correspondences](https://arxiv.org/abs/2510.14960)
*Shizun Wang,Zhenxiang Jiang,Xingyi Yang,Xinchao Wang*

Main category: cs.CV

TL;DR: C4D通过时间对应关系和动态感知点跟踪，将静态3D重建扩展到动态4D，显著提升多任务性能。


<details>
  <summary>Details</summary>
Motivation: 动态场景中移动物体违反多视图几何约束，导致现有静态3D重建方法（如DUSt3R）效果不佳，需开发新方法解决动态4D重建问题。

Method: C4D利用短时光流和长时点跟踪两种对应关系，训练动态感知点跟踪器，并结合动态场景优化目标，恢复每帧3D几何和相机参数。

Result: 实验表明，C4D实现了完整的4D重建，并在深度估计、相机姿态估计和点跟踪等下游任务中表现优异。

Conclusion: C4D框架通过引入时间对应关系，成功将静态3D重建扩展到动态4D重建，实现了多任务性能的显著提升。

Abstract: Recovering 4D from monocular video, which jointly estimates dynamic geometry
and camera poses, is an inevitably challenging problem. While recent
pointmap-based 3D reconstruction methods (e.g., DUSt3R) have made great
progress in reconstructing static scenes, directly applying them to dynamic
scenes leads to inaccurate results. This discrepancy arises because moving
objects violate multi-view geometric constraints, disrupting the
reconstruction. To address this, we introduce C4D, a framework that leverages
temporal Correspondences to extend existing 3D reconstruction formulation to
4D. Specifically, apart from predicting pointmaps, C4D captures two types of
correspondences: short-term optical flow and long-term point tracking. We train
a dynamic-aware point tracker that provides additional mobility information,
facilitating the estimation of motion masks to separate moving elements from
the static background, thus offering more reliable guidance for dynamic scenes.
Furthermore, we introduce a set of dynamic scene optimization objectives to
recover per-frame 3D geometry and camera parameters. Simultaneously, the
correspondences lift 2D trajectories into smooth 3D trajectories, enabling
fully integrated 4D reconstruction. Experiments show that our framework
achieves complete 4D recovery and demonstrates strong performance across
multiple downstream tasks, including depth estimation, camera pose estimation,
and point tracking. Project Page: https://littlepure2333.github.io/C4D

</details>


### [89] [You May Speak Freely: Improving the Fine-Grained Visual Recognition Capabilities of Multimodal Large Language Models with Answer Extraction](https://arxiv.org/abs/2510.14885)
*Logan Lawrence,Oindrila Saha,Megan Wei,Chen Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: 提出nlg2choice方法，通过开放式问题与受限解码结合，显著提升细粒度视觉分类任务中的分类和检索性能。


<details>
  <summary>Details</summary>
Motivation: 评估自回归模型的自由形式响应在多选问题（MCQs）中的挑战，尤其是在细粒度视觉分类（FGVC）中，选项数量庞大且高度相关。现有方法未充分考虑这些问题。

Method: 提出nlg2choice，一个两阶段方法：首先以开放式问题询问MLLM，然后使用文本受限解码预测最可能的选择。在检索设置中，采用早期停止方法提高吞吐量。

Result: 在七个细粒度视觉数据集上的实验表明，nlg2choice在分类和检索方面均优于现有方法，且性能稳定。

Conclusion: nlg2choice方法在细粒度视觉分类任务中表现出色，显著提升了分类和检索性能，且适用于多种自然语言任务实现方式。

Abstract: Despite the renewed interest in zero-shot visual classification due to the
rise of Multimodal Large Language Models (MLLMs), the problem of evaluating
free-form responses of auto-regressive models remains a persistent challenge.
Most existing works focus on language-only tasks or don't consider Multiple
Choice Questions (MCQs) beyond 5-way options, both of which are critical
capabilities to solve tasks in Fine-Grained Visual Classification (FGVC) where
choice counts are in the hundreds to thousands and the choices are highly
related. Furthermore, in this highly multi-way MCQ setting it is not clear how
to extend LLM choice extraction to retrieval-based problems, where computing
probabilities over the choice set is computationally costly. In this work we
investigate nlg2choice, a simple two-stage method which first asks the MLLM an
open-ended question for the task with minimal constraints, then uses text-only
constrained decoding to predict the most likely choice. In retrieval settings,
we compute the probability of the constrained response taking that choice with
an early stopping method to significantly improve throughput. Our results show
improvement over a suite of seven fine-grained visual datasets when evaluating
in terms of classification and retrieval, and show that this performance holds
over the various ways that users of LLMs can implement tasks in natural
language.

</details>


### [90] [Leveraging Multimodal LLM Descriptions of Activity for Explainable Semi-Supervised Video Anomaly Detection](https://arxiv.org/abs/2510.14896)
*Furkan Mumcu,Michael J. Jones,Anoop Cherian,Yasin Yilmaz*

Main category: cs.CV

TL;DR: A novel MLLM-based VAD framework improves detection of complex anomalies and explainability, outperforming existing methods on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Existing semi-supervised VAD methods struggle with complex anomalies and lack explainability, prompting the development of a novel MLLM-based framework.

Method: The method extracts and interprets object activity and interactions over time by querying an MLLM with visual inputs of object pairs to generate textual descriptions, which are then compared to nominal training descriptions for anomaly detection.

Result: The method demonstrates effective detection of interaction-based anomalies and superior performance on benchmark datasets.

Conclusion: The proposed VAD framework leveraging MLLMs effectively detects complex anomalies involving object interactions and provides inherent explainability, achieving state-of-the-art performance.

Abstract: Existing semi-supervised video anomaly detection (VAD) methods often struggle
with detecting complex anomalies involving object interactions and generally
lack explainability. To overcome these limitations, we propose a novel VAD
framework leveraging Multimodal Large Language Models (MLLMs). Unlike previous
MLLM-based approaches that make direct anomaly judgments at the frame level,
our method focuses on extracting and interpreting object activity and
interactions over time. By querying an MLLM with visual inputs of object pairs
at different moments, we generate textual descriptions of the activity and
interactions from nominal videos. These textual descriptions serve as a
high-level representation of the activity and interactions of objects in a
video. They are used to detect anomalies during test time by comparing them to
textual descriptions found in nominal training videos. Our approach inherently
provides explainability and can be combined with many traditional VAD methods
to further enhance their interpretability. Extensive experiments on benchmark
datasets demonstrate that our method not only detects complex interaction-based
anomalies effectively but also achieves state-of-the-art performance on
datasets without interaction anomalies.

</details>


### [91] [WithAnyone: Towards Controllable and ID Consistent Image Generation](https://arxiv.org/abs/2510.14975)
*Hengyuan Xu,Wei Cheng,Peng Xing,Yixiao Fang,Shuhan Wu,Rui Wang,Xianfang Zeng,Daxin Jiang,Gang Yu,Xingjun Ma,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 该论文提出WithAnyone模型，通过新数据集、基准和对比损失解决文本到图像生成中的copy-paste问题，提升身份一致性和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因缺乏大规模配对数据集而依赖重构训练，导致copy-paste问题，限制了生成的多样性和可控性。

Method: 构建MultiID-2M数据集，提出量化基准，并设计对比性身份损失的训练范式，最终开发了基于扩散的WithAnyone模型。

Result: WithAnyone显著减少了copy-paste伪影，提升了姿势和表情的可控性，并保持了高感知质量。用户研究证实了其高身份保真度和表达能力。

Conclusion: WithAnyone模型通过构建MultiID-2M数据集、引入量化基准和对比性身份损失，有效解决了copy-paste问题，同时在保持高身份相似性的基础上提升了生成的可控性和多样性。

Abstract: Identity-consistent generation has become an important focus in text-to-image
research, with recent models achieving notable success in producing images
aligned with a reference identity. Yet, the scarcity of large-scale paired
datasets containing multiple images of the same individual forces most
approaches to adopt reconstruction-based training. This reliance often leads to
a failure mode we term copy-paste, where the model directly replicates the
reference face rather than preserving identity across natural variations in
pose, expression, or lighting. Such over-similarity undermines controllability
and limits the expressive power of generation. To address these limitations, we
(1) construct a large-scale paired dataset MultiID-2M, tailored for
multi-person scenarios, providing diverse references for each identity; (2)
introduce a benchmark that quantifies both copy-paste artifacts and the
trade-off between identity fidelity and variation; and (3) propose a novel
training paradigm with a contrastive identity loss that leverages paired data
to balance fidelity with diversity. These contributions culminate in
WithAnyone, a diffusion-based model that effectively mitigates copy-paste while
preserving high identity similarity. Extensive qualitative and quantitative
experiments demonstrate that WithAnyone significantly reduces copy-paste
artifacts, improves controllability over pose and expression, and maintains
strong perceptual quality. User studies further validate that our method
achieves high identity fidelity while enabling expressive controllable
generation.

</details>


### [92] [Terra: Explorable Native 3D World Model with Point Latents](https://arxiv.org/abs/2510.14977)
*Yuanhui Huang,Weiliang Chen,Wenzhao Zheng,Xin Tao,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Terra 是一种原生 3D 世界模型，通过 P2G-VAE 和 SPFlow 在 3D 潜在空间中高效建模可探索环境，显著提升了 3D 一致性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖像素对齐表示，忽略了物理世界的固有 3D 特性，导致 3D 一致性和建模效率降低。

Method: 提出点-高斯变分自编码器（P2G-VAE）和稀疏点流匹配网络（SPFlow），用于在 3D 潜在空间中表示和生成环境。

Result: Terra 在 ScanNet v2 上实现了重建和生成的最先进性能，具有高 3D 一致性。

Conclusion: Terra 通过原生 3D 世界模型在 3D 潜在空间中实现可探索环境建模，并在 ScanNet v2 上展示了最先进的性能和高 3D 一致性。

Abstract: World models have garnered increasing attention for comprehensive modeling of
the real world. However, most existing methods still rely on pixel-aligned
representations as the basis for world evolution, neglecting the inherent 3D
nature of the physical world. This could undermine the 3D consistency and
diminish the modeling efficiency of world models. In this paper, we present
Terra, a native 3D world model that represents and generates explorable
environments in an intrinsic 3D latent space. Specifically, we propose a novel
point-to-Gaussian variational autoencoder (P2G-VAE) that encodes 3D inputs into
a latent point representation, which is subsequently decoded as 3D Gaussian
primitives to jointly model geometry and appearance. We then introduce a sparse
point flow matching network (SPFlow) for generating the latent point
representation, which simultaneously denoises the positions and features of the
point latents. Our Terra enables exact multi-view consistency with native 3D
representation and architecture, and supports flexible rendering from any
viewpoint with only a single generation process. Furthermore, Terra achieves
explorable world modeling through progressive generation in the point latent
space. We conduct extensive experiments on the challenging indoor scenes from
ScanNet v2. Terra achieves state-of-the-art performance in both reconstruction
and generation with high 3D consistency.

</details>


### [93] [3D Scene Prompting for Scene-Consistent Camera-Controllable Video Generation](https://arxiv.org/abs/2510.14945)
*JoungBin Lee,Jaewoo Jung,Jisang Han,Takuya Narihira,Kazumi Fukuda,Junyoung Seo,Sunghwan Hong,Yuki Mitsufuji,Seungryong Kim*

Main category: cs.CV

TL;DR: 3DScenePrompt通过双时空条件和3D场景记忆，实现了视频生成的精确相机控制和场景一致性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在生成超出时间边界时直接使用空间相邻帧导致动态元素错误保留的问题。

Method: 采用双时空条件，结合动态SLAM和新引入的动态掩码策略，构建3D场景记忆，分离静态几何与动态元素。

Result: 实现了长范围空间一致性和精确相机控制，同时保持计算效率和运动真实性。

Conclusion: 3DScenePrompt框架在场景一致性、相机可控性和生成质量方面显著优于现有方法。

Abstract: We present 3DScenePrompt, a framework that generates the next video chunk
from arbitrary-length input while enabling precise camera control and
preserving scene consistency. Unlike methods conditioned on a single image or a
short clip, we employ dual spatio-temporal conditioning that reformulates
context-view referencing across the input video. Our approach conditions on
both temporally adjacent frames for motion continuity and spatially adjacent
content for scene consistency. However, when generating beyond temporal
boundaries, directly using spatially adjacent frames would incorrectly preserve
dynamic elements from the past. We address this by introducing a 3D scene
memory that represents exclusively the static geometry extracted from the
entire input video. To construct this memory, we leverage dynamic SLAM with our
newly introduced dynamic masking strategy that explicitly separates static
scene geometry from moving elements. The static scene representation can then
be projected to any target viewpoint, providing geometrically consistent warped
views that serve as strong 3D spatial prompts while allowing dynamic regions to
evolve naturally from temporal context. This enables our model to maintain
long-range spatial coherence and precise camera control without sacrificing
computational efficiency or motion realism. Extensive experiments demonstrate
that our framework significantly outperforms existing methods in scene
consistency, camera controllability, and generation quality. Project page :
https://cvlab-kaist.github.io/3DScenePrompt/

</details>


### [94] [From Pixels to Words -- Towards Native Vision-Language Primitives at Scale](https://arxiv.org/abs/2510.14979)
*Haiwen Diao,Mingxuan Li,Silei Wu,Linjun Dai,Xiaohua Wang,Hanming Deng,Lewei Lu,Dahua Lin,Ziwei Liu*

Main category: cs.CV

TL;DR: 本文提出NEO，一种新型原生视觉语言模型，通过基本原则构建，能在少量数据下高效学习，并解决视觉-语言冲突，为领域提供可扩展的基石。


<details>
  <summary>Details</summary>
Motivation: 探讨原生视觉语言模型（VLMs）与模块化VLMs之间的根本限制，以及如何使原生VLM的研究更加普及和民主化，以加速该领域的进展。

Method: 提出了NEO，一个基于基本原则构建的新型原生VLM家族，能够在多样化现实场景中媲美顶级模块化模型。NEO通过390M图像-文本样本高效地从零开始发展视觉感知，并在一个密集且单一模型中缓解视觉-语言冲突。

Result: NEO能够在少量数据（390M图像-文本样本）下高效发展视觉感知，并在密集单一模型中实现视觉-语言的统一编码、对齐和推理。

Conclusion: NEO被定位为可扩展且强大的原生视觉语言模型（VLM）的基石，提供了一套丰富的可重用组件，支持成本效益高且可扩展的生态系统。

Abstract: The edifice of native Vision-Language Models (VLMs) has emerged as a rising
contender to typical modular VLMs, shaped by evolving model architectures and
training paradigms. Yet, two lingering clouds cast shadows over its widespread
exploration and promotion: (-) What fundamental constraints set native VLMs
apart from modular ones, and to what extent can these barriers be overcome? (-)
How to make research in native VLMs more accessible and democratized, thereby
accelerating progress in the field. In this paper, we clarify these challenges
and outline guiding principles for constructing native VLMs. Specifically, one
native VLM primitive should: (i) effectively align pixel and word
representations within a shared semantic space; (ii) seamlessly integrate the
strengths of formerly separate vision and language modules; (iii) inherently
embody various cross-modal properties that support unified vision-language
encoding, aligning, and reasoning. Hence, we launch NEO, a novel family of
native VLMs built from first principles, capable of rivaling top-tier modular
counterparts across diverse real-world scenarios. With only 390M image-text
examples, NEO efficiently develops visual perception from scratch while
mitigating vision-language conflicts inside a dense and monolithic model
crafted from our elaborate primitives. We position NEO as a cornerstone for
scalable and powerful native VLMs, paired with a rich set of reusable
components that foster a cost-effective and extensible ecosystem. Our code and
models are publicly available at: https://github.com/EvolvingLMMs-Lab/NEO.

</details>


### [95] [OmniMotion: Multimodal Motion Generation with Continuous Masked Autoregression](https://arxiv.org/abs/2510.14954)
*Zhe Li,Weihao Yuan,Weichao Shen,Siyu Zhu,Zilong Dong,Chang Xu*

Main category: cs.CV

TL;DR: 提出了一种连续掩码自回归运动变换器，结合DiT结构和多模态融合技术，在多种运动生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决全身多模态人体运动生成的两大挑战：有效的运动生成机制和多模态整合。

Method: 开发了一种连续掩码自回归运动变换器，结合了门控线性注意力和RMSNorm模块，并采用DiT结构扩散条件。

Result: 实验结果表明，该框架在所有模态（如文本到运动、语音到手势、音乐到舞蹈）中均优于现有方法。

Conclusion: 作者提出的连续掩码自回归运动变换器框架在多种模态下均优于现有方法，代码将公开。

Abstract: Whole-body multi-modal human motion generation poses two primary challenges:
creating an effective motion generation mechanism and integrating various
modalities, such as text, speech, and music, into a cohesive framework. Unlike
previous methods that usually employ discrete masked modeling or autoregressive
modeling, we develop a continuous masked autoregressive motion transformer,
where a causal attention is performed considering the sequential nature within
the human motion. Within this transformer, we introduce a gated linear
attention and an RMSNorm module, which drive the transformer to pay attention
to the key actions and suppress the instability caused by either the abnormal
movements or the heterogeneous distributions within multi-modalities. To
further enhance both the motion generation and the multimodal generalization,
we employ the DiT structure to diffuse the conditions from the transformer
towards the targets. To fuse different modalities, AdaLN and cross-attention
are leveraged to inject the text, speech, and music signals. Experimental
results demonstrate that our framework outperforms previous methods across all
modalities, including text-to-motion, speech-to-gesture, and music-to-dance.
The code of our method will be made public.

</details>


### [96] [Coupled Diffusion Sampling for Training-Free Multi-View Image Editing](https://arxiv.org/abs/2510.14981)
*Hadi Alzayer,Yunzhi Zhang,Chen Geng,Jia-Bin Huang,Jiajun Wu*

Main category: cs.CV

TL;DR: 提出了一种基于耦合扩散采样的方法，用于实现多视角一致性图像编辑，避免了显式3D优化的缺点，并在多种任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 预训练的2D图像编辑模型在多视角图像集上独立生成高质量编辑时无法保持视角间一致性，现有基于显式3D表示优化的方法存在优化过程冗长且稀疏视角下不稳定的问题。

Method: 提出了一种隐式3D正则化方法，通过约束生成的2D图像序列遵循预训练的多视角图像分布，采用耦合扩散采样技术同时从多视角图像分布和2D编辑图像分布中采样两个轨迹，并使用耦合项来强制执行生成图像之间的多视角一致性。

Result: 该方法在三种不同的多视角图像编辑任务中表现出色，验证了其有效性和通用性。

Conclusion: 该框架在三种不同的多视角图像编辑任务中验证了其有效性和通用性，展示了其作为多视角一致性编辑通用解决方案的潜力。

Abstract: We present an inference-time diffusion sampling method to perform multi-view
consistent image editing using pre-trained 2D image editing models. These
models can independently produce high-quality edits for each image in a set of
multi-view images of a 3D scene or object, but they do not maintain consistency
across views. Existing approaches typically address this by optimizing over
explicit 3D representations, but they suffer from a lengthy optimization
process and instability under sparse view settings. We propose an implicit 3D
regularization approach by constraining the generated 2D image sequences to
adhere to a pre-trained multi-view image distribution. This is achieved through
coupled diffusion sampling, a simple diffusion sampling technique that
concurrently samples two trajectories from both a multi-view image distribution
and a 2D edited image distribution, using a coupling term to enforce the
multi-view consistency among the generated images. We validate the
effectiveness and generality of this framework on three distinct multi-view
image editing tasks, demonstrating its applicability across various model
architectures and highlighting its potential as a general solution for
multi-view consistent editing.

</details>


### [97] [MathCanvas: Intrinsic Visual Chain-of-Thought for Multimodal Mathematical Reasoning](https://arxiv.org/abs/2510.14958)
*Weikang Shi,Aldrich Yu,Rongyao Fang,Houxing Ren,Ke Wang,Aojun Zhou,Changyao Tian,Xinyu Fu,Yuxuan Hu,Zimu Lu,Linjiang Huang,Si Liu,Rui Liu,Hongsheng Li*

Main category: cs.CV

TL;DR: MathCanvas框架通过两阶段训练提升多模态模型的数学视觉推理能力，模型在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本推理上表现出色，但在依赖视觉辅助的数学领域（如几何）表现不佳。现有视觉思维链方法受限于僵硬的外部工具或无法生成高保真、策略性定时的图表。

Method: MathCanvas框架分为两个阶段：1) 视觉操纵阶段，通过预训练模型在15.2M对数据上掌握图表生成和编辑；2) 战略视觉辅助推理阶段，通过微调模型在219K示例数据集上学习何时及如何利用视觉辅助。

Result: BAGEL-Canvas模型在MathCanvas-Bench上实现了86%的相对改进，并在其他公共数学基准测试中表现出优异的泛化能力。

Conclusion: MathCanvas框架通过两个阶段的训练（视觉操纵和战略视觉辅助推理），显著提升了大型多模态模型在数学领域的视觉辅助推理能力，BAGEL-Canvas模型在MathCanvas-Bench上实现了86%的相对改进，并展示了出色的泛化能力。

Abstract: While Large Language Models (LLMs) have excelled in textual reasoning, they
struggle with mathematical domains like geometry that intrinsically rely on
visual aids. Existing approaches to Visual Chain-of-Thought (VCoT) are often
limited by rigid external tools or fail to generate the high-fidelity,
strategically-timed diagrams necessary for complex problem-solving. To bridge
this gap, we introduce MathCanvas, a comprehensive framework designed to endow
unified Large Multimodal Models (LMMs) with intrinsic VCoT capabilities for
mathematics. Our approach consists of two phases. First, a Visual Manipulation
stage pre-trains the model on a novel 15.2M-pair corpus, comprising 10M
caption-to-diagram pairs (MathCanvas-Imagen) and 5.2M step-by-step editing
trajectories (MathCanvas-Edit), to master diagram generation and editing.
Second, a Strategic Visual-Aided Reasoning stage fine-tunes the model on
MathCanvas-Instruct, a new 219K-example dataset of interleaved visual-textual
reasoning paths, teaching it when and how to leverage visual aids. To
facilitate rigorous evaluation, we introduce MathCanvas-Bench, a challenging
benchmark with 3K problems that require models to produce interleaved
visual-textual solutions. Our model, BAGEL-Canvas, trained under this
framework, achieves an 86% relative improvement over strong LMM baselines on
MathCanvas-Bench, demonstrating excellent generalization to other public math
benchmarks. Our work provides a complete toolkit-framework, datasets, and
benchmark-to unlock complex, human-like visual-aided reasoning in LMMs. Project
Page: https://mathcanvas.github.io/

</details>


### [98] [RainDiff: End-to-end Precipitation Nowcasting Via Token-wise Attention Diffusion](https://arxiv.org/abs/2510.14962)
*Thao Nguyen,Jiaqi Ma,Fahad Shahbaz Khan,Souhaib Ben Taieb,Salman Khan*

Main category: cs.CV

TL;DR: 该论文提出了一种集成注意力机制的U-Net扩散模型，显著提升了降水临近预报的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散模型在降水临近预报中因可扩展性问题导致的复杂性和计算成本高的限制。

Method: 提出了一种集成Token-wise Attention的U-Net扩散模型，动态捕捉多尺度空间交互和时间演化，无需单独训练潜在模块。

Result: 在多个数据集上的实验和视觉评估表明，该方法在复杂降水预报场景中表现优异。

Conclusion: 该论文提出的方法在降水临近预报任务中显著优于现有技术，具有更高的局部保真度、泛化能力和鲁棒性。

Abstract: Precipitation nowcasting, predicting future radar echo sequences from current
observations, is a critical yet challenging task due to the inherently chaotic
and tightly coupled spatio-temporal dynamics of the atmosphere. While recent
advances in diffusion-based models attempt to capture both large-scale motion
and fine-grained stochastic variability, they often suffer from scalability
issues: latent-space approaches require a separately trained autoencoder,
adding complexity and limiting generalization, while pixel-space approaches are
computationally intensive and often omit attention mechanisms, reducing their
ability to model long-range spatio-temporal dependencies. To address these
limitations, we propose a Token-wise Attention integrated into not only the
U-Net diffusion model but also the spatio-temporal encoder that dynamically
captures multi-scale spatial interactions and temporal evolution. Unlike prior
approaches, our method natively integrates attention into the architecture
without incurring the high resource cost typical of pixel-space diffusion,
thereby eliminating the need for separate latent modules. Our extensive
experiments and visual evaluations across diverse datasets demonstrate that the
proposed method significantly outperforms state-of-the-art approaches, yielding
superior local fidelity, generalization, and robustness in complex
precipitation forecasting scenarios.

</details>


### [99] [ChangingGrounding: 3D Visual Grounding in Changing Scenes](https://arxiv.org/abs/2510.14965)
*Miao Hu,Zhiwei Huang,Tai Wang,Jiangmiao Pang,Dahua Lin,Nanning Zheng,Runsen Xu*

Main category: cs.CV

TL;DR: 提出了首个基准ChangingGrounding和零样本方法Mem-ChangingGrounder，用于在变化场景中高效定位物体，减少探索成本，推动3DVG研究向实用化发展。


<details>
  <summary>Details</summary>
Motivation: 现实世界中，机器人需要在场景不断变化的情况下从自然语言指令中定位物体，而现有3DVG方法大多假设点云已重建且最新，这一假设导致高昂的重新扫描成本并阻碍部署。作者认为3DVG应被表述为一个主动的、以记忆驱动的问题。

Method: 提出了一种零样本方法Mem-ChangingGrounder，结合跨模态检索和轻量级多视图融合：识别查询中隐含的对象类型，检索相关记忆以指导行动，高效探索场景中的目标，无效时回退，执行目标的多视图扫描，并将多视图扫描的融合证据投影以获取精确的对象边界框。

Result: Mem-ChangingGrounder在ChangingGrounding基准上实现了最高的定位准确性，同时大幅降低了探索成本。

Conclusion: 作者希望通过ChangingGrounding基准和Mem-ChangingGrounder方法推动3D视觉接地（3DVG）研究向更实用、以记忆为中心的方向发展，以适应现实世界的应用需求。

Abstract: Real-world robots localize objects from natural-language instructions while
scenes around them keep changing. Yet most of the existing 3D visual grounding
(3DVG) method still assumes a reconstructed and up-to-date point cloud, an
assumption that forces costly re-scans and hinders deployment. We argue that
3DVG should be formulated as an active, memory-driven problem, and we introduce
ChangingGrounding, the first benchmark that explicitly measures how well an
agent can exploit past observations, explore only where needed, and still
deliver precise 3D boxes in changing scenes. To set a strong reference point,
we also propose Mem-ChangingGrounder, a zero-shot method for this task that
marries cross-modal retrieval with lightweight multi-view fusion: it identifies
the object type implied by the query, retrieves relevant memories to guide
actions, then explores the target efficiently in the scene, falls back when
previous operations are invalid, performs multi-view scanning of the target,
and projects the fused evidence from multi-view scans to get accurate object
bounding boxes. We evaluate different baselines on ChangingGrounding, and our
Mem-ChangingGrounder achieves the highest localization accuracy while greatly
reducing exploration cost. We hope this benchmark and method catalyze a shift
toward practical, memory-centric 3DVG research for real-world applications.
Project page: https://hm123450.github.io/CGB/ .

</details>


### [100] [Learning an Image Editing Model without Image Editing Pairs](https://arxiv.org/abs/2510.14978)
*Nupur Kumari,Sheng-Yu Wang,Nanxuan Zhao,Yotam Nitzan,Yuheng Li,Krishna Kumar Singh,Richard Zhang,Eli Shechtman,Jun-Yan Zhu,Xun Huang*

Main category: cs.CV

TL;DR: 无需配对数据，通过VLM反馈和DMD损失优化扩散模型，实现与监督方法相当的图像编辑效果。


<details>
  <summary>Details</summary>
Motivation: 当前图像编辑模型依赖大规模监督微调数据集，但自然成对的输入-目标数据难以大规模获取，现有解决方案使用合成训练对可能放大预训练模型的伪影。

Method: 我们提出了一种新的训练范式，通过展开训练过程中的几步扩散模型，并利用视觉语言模型（VLM）的反馈进行端到端优化。

Result: 我们的方法在标准基准测试中表现优异，且通过广泛的消融研究验证了其有效性。

Conclusion: 我们的方法在无需配对数据的情况下，与基于大量监督配对数据训练的多种图像编辑扩散模型表现相当，且在相同VLM作为奖励模型时，优于基于强化学习的技术如Flow-GRPO。

Abstract: Recent image editing models have achieved impressive results while following
natural language editing instructions, but they rely on supervised fine-tuning
with large datasets of input-target pairs. This is a critical bottleneck, as
such naturally occurring pairs are hard to curate at scale. Current workarounds
use synthetic training pairs that leverage the zero-shot capabilities of
existing models. However, this can propagate and magnify the artifacts of the
pretrained model into the final trained model. In this work, we present a new
training paradigm that eliminates the need for paired data entirely. Our
approach directly optimizes a few-step diffusion model by unrolling it during
training and leveraging feedback from vision-language models (VLMs). For each
input and editing instruction, the VLM evaluates if an edit follows the
instruction and preserves unchanged content, providing direct gradients for
end-to-end optimization. To ensure visual fidelity, we incorporate distribution
matching loss (DMD), which constrains generated images to remain within the
image manifold learned by pretrained models. We evaluate our method on standard
benchmarks and include an extensive ablation study. Without any paired data,
our method performs on par with various image editing diffusion models trained
on extensive supervised paired data, under the few-step setting. Given the same
VLM as the reward model, we also outperform RL-based techniques like Flow-GRPO.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [101] [Joint Active RIS Configuration and User Power Control for Localization: A Neuroevolution-Based Approach](https://arxiv.org/abs/2510.13819)
*George Stamatelis,Hui Chen,Henk Wymeersch,George C. Alexandropoulos*

Main category: cs.NI

TL;DR: 本文提出了一种结合神经进化与监督学习的多智能体算法，用于RIS辅助的用户定位，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究在RIS辅助下通过动态功率控制实现用户定位的问题。

Method: 采用了一种结合神经进化（NE）和监督学习的混合方法，用于联合控制RIS相位配置和用户发射功率。

Result: 数值结果表明，该方案仅需单比特反馈消息即可实现上行功率控制，并支持具有离散响应的RIS元素。

Conclusion: 本文提出的多智能体算法在RIS辅助用户定位中表现出色，优于指纹识别、深度强化学习基准和基于反向传播的位置估计器。

Abstract: This paper studies user localization aided by a Reconfigurable Intelligent
Surface (RIS). A feedback link from the Base Station (BS) to the user is
adopted to enable dynamic power control of the user pilot transmissions in the
uplink. A novel multi-agent algorithm for the joint control of the RIS phase
configuration and the user transmit power is presented, which is based on a
hybrid approach integrating NeuroEvolution (NE) and supervised learning. The
proposed scheme requires only single-bit feedback messages for the uplink power
control, supports RIS elements with discrete responses, and is numerically
shown to outperform fingerprinting, deep reinforcement learning baselines and
backpropagation-based position estimators.

</details>


### [102] [Leveraging Wireless Sensor Networks for Real-Time Monitoring and Control of Industrial Environments](https://arxiv.org/abs/2510.13820)
*Muhammad Junaid Asif,Shazia Saqib,Rana Fayyaz Ahmad,Hamza Khan*

Main category: cs.NI

TL;DR: 本研究提出了一种基于物联网和无线传感器网络的工业参数监控与控制系统，通过无线通信技术实现远程监控和控制，提高了工业操作效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 针对传统有线通信系统的不足，以及2020年至2024年全球工业火灾频发的背景，研究旨在通过无线通信技术提升工业操作效率和安全性。

Method: 提出了一个基于NRF收发器和ARDUINO微控制器的系统，通过无线传感器网络实时传输多传感器数据到中央设置，并具有远程控制功能。

Result: 结果表明，无线通信创新在工业过程自动化和安全中发挥关键作用，系统能够快速响应紧急情况，如启动消防设备。

Conclusion: 本研究强调了基于物联网和无线传感器网络的系统在工业监控和控制中的变革潜力，通过提高生产效率和安全性，为更智能和响应更快的操作环境铺平了道路。

Abstract: This research proposes an extensive technique for monitoring and controlling
the industrial parameters using Internet of Things (IoT) technology based on
wireless communication. We proposed a system based on NRF transceivers to
establish a strong Wireless Sensor Network (WSN), enabling transfer of
real-time data from multiple sensors to a central setup that is driven by
ARDUINO microcontrollers. Different key parameters, crucial for industrial
setup such as temperature, humidity, soil moisture and fire detection, are
monitored and displayed on an LCD screen, enabling factory administration to
oversee the industrial operations remotely over the internet. Our proposed
system bypasses the need for physical presence for monitoring by addressing the
shortcomings of conventional wired communication systems. Other than
monitoring, there is an additional feature to remotely control these parameters
by controlling the speed of DC motors through online commands. Given the rising
incidence of industrial fires over the worldwide between 2020 and 2024 due to
an array of hazards, this system with dual functionality boosts the overall
operational efficiency and safety. This overall integration of IoT and Wireless
Sensor Network (WSN) reduces the potential risks linked with physical
monitoring, providing rapid responses in emergency scenarios, including the
activation of firefighting equipment. The results show that innovations in
wireless communication perform an integral part in industrial process
automation and safety, paving the way to more intelligent and responsive
operating environments. Overall, this study highlights the potential for change
of IoT-enabled systems to revolutionize monitoring and control in a variety of
industrial applications, resulting in increased productivity and safety.

</details>


### [103] [LLM Agent Communication Protocol (LACP) Requires Urgent Standardization: A Telecom-Inspired Protocol is Necessary](https://arxiv.org/abs/2510.13821)
*Xin Li,Mengbing Liu,Chau Yuen*

Main category: cs.NI

TL;DR: 本文主张采用统一的LACP协议解决LLM智能体通信问题，确保安全、互操作和可扩展性，特别适用于6G网络。


<details>
  <summary>Details</summary>
Motivation: 当前临时通信方法导致生态系统碎片化，阻碍创新并带来风险，类似于早期网络协议战争。

Method: 提出LLM-Agent通信协议（LACP），采用三层架构设计，确保通信语义清晰、复杂任务的事务完整性及内置安全性。

Result: LACP为多智能体系统提供了安全、互操作和可扩展的通信基础，特别适用于NextG网络。

Conclusion: 采用统一的LLM-Agent通信协议（LACP）对于实现分布式AI的潜力至关重要，特别是在6G及更复杂实时应用中确保多智能体系统的安全可靠运行。

Abstract: This position paper argues that the field of LLM agents requires a unified,
telecom-inspired communication protocol to ensure safety, interoperability, and
scalability, especially within the context of Next Generation (NextG) networks.
Current ad-hoc communication methods are creating a fragmented ecosystem,
reminiscent of the early "protocol wars" in networking, which stifles
innovation and poses significant risks. Drawing inspiration from the layered,
standardized protocols that underpin modern telecommunications, we propose the
LLM-Agent Communication Protocol (LACP). LACP establishes a three-layer
architecture designed to ensure semantic clarity in communication,
transactional integrity for complex tasks, and robust, built-in security. In
this position paper, we argue that adopting a principled, universal protocol is
not merely beneficial but essential for realizing the potential of distributed
AI. Such a standard is critical for ensuring that multi-agent systems can
operate safely and reliably in the complex, real-time applications envisioned
for 6G and beyond.

</details>


### [104] [A Simulator for FANETs Using 5G Vehicle-to-Everything Communications and Named-Data Networking](https://arxiv.org/abs/2510.13823)
*José Manuel Rúa-Estévez,Alicia Meleiro-Estévez,Pablo Fondo-Ferreiro,Felipe Gil-Castiñeira,Brais Sánchez-Rama,Lois Gomez-Gonzalez*

Main category: cs.NI

TL;DR: 该研究开发了一个基于5G V2X和NDN的FANET模拟器，用于测试多无人机多跳通信。


<details>
  <summary>Details</summary>
Motivation: 为了验证和评估FANET在5G V2X通信和NDN范式下的性能，并展示其应用潜力。

Method: 该模拟器整合了ns-3网络模拟器和Zenoh NDN协议，支持多无人机多跳通信的测试。

Result: 模拟器成功实现了多无人机多跳通信的测试，验证了其可行性和性能。

Conclusion: 该研究提出了一种用于验证、评估和展示基于5G V2X通信和NDN范式的FANET模拟器，为多无人机多跳通信应用提供了现实测试环境。

Abstract: This work presents a simulator designed for the validation, evaluation, and
demonstration of flying adhoc networks (FANETs) using 5G vehicle-to-everything
(V2X) communications and the named-data networking (NDN) paradigm. The
simulator integrates the ns-3 network simulator and the Zenoh NDN protocol,
enabling realistic testing of applications that involve the multi-hop
communication among multiple unmanned aerial vehicles (UAVs).

</details>


### [105] [DiffLoc: Diffusion Model-Based High-Precision Positioning for 6G Networks](https://arxiv.org/abs/2510.14111)
*Taekyun Lee,Tommaso Balercia,Heasung Kim,Hyeji Kim,Jeffrey G. Andrews*

Main category: cs.NI

TL;DR: DiffLoc框架利用条件生成扩散模型实现亚厘米级定位，显著优于传统方法，适用于实时6G应用。


<details>
  <summary>Details</summary>
Motivation: 传统指纹方法难以扩展到大型动态室外环境，且需要密集的数据调查，DiffLoc旨在克服这些限制。

Method: 应用条件生成扩散模型直接从高维大规模MIMO信道状态信息（CSI）映射到连续地理坐标。

Result: DiffLoc-CT模型在东京城市宏小区环境中实现了0.5厘米的融合精度和1-2厘米的单个基站精度，显著优于现有方法。

Conclusion: DiffLoc框架通过条件生成扩散模型实现了前所未有的亚厘米级定位精度，展现了其在实时6G应用中的实际可行性。

Abstract: This paper introduces a novel framework for high-accuracy outdoor user
equipment (UE) positioning that applies a conditional generative diffusion
model directly to high-dimensional massive MIMO channel state information
(CSI). Traditional fingerprinting methods struggle to scale to large, dynamic
outdoor environments and require dense, impractical data surveys. To overcome
these limitations, our approach learns a direct mapping from raw uplink
Sounding Reference Signal (SRS) fingerprints to continuous geographic
coordinates. We demonstrate that our DiffLoc framework achieves unprecedented
sub-centimeter precision, with our best model (DiffLoc-CT) delivering 0.5 cm
fusion accuracy and 1-2 cm single base station (BS) accuracy in a realistic,
ray-traced Tokyo urban macro-cell environment. This represents an
order-of-magnitude improvement over existing methods, including supervised
regression approaches (over 10 m error) and grid-based fusion (3 m error). Our
consistency training approach reduces inference time from 200 steps to just 2
steps while maintaining exceptional accuracy even for high-speed users (15-25
m/s) and unseen user trajectories, demonstrating the practical feasibility of
our framework for real-time 6G applications.

</details>


### [106] [Energy-Latency Optimization for Dynamic 5G Mobile Radio Access Networks](https://arxiv.org/abs/2510.14214)
*Gabriela N. Caspa H.,Carlos A. Astudillo,Nelson L. S. da Fonseca*

Main category: cs.NI

TL;DR: 本文提出MILP模型和启发式算法优化5G RAN配置，平衡延迟与能耗，为未来部署提供参考。


<details>
  <summary>Details</summary>
Motivation: 5G网络中基站解聚和新服务对RAN配置提出了挑战，特别是带宽和延迟约束。同时，能耗是移动网络运营商的重要关注点，需要平衡服务性能和成本效益。

Method: 使用混合整数线性规划（MILP）模型，结合三种目标函数（最小化前传延迟、最小化能耗、双目标优化），并提出了启发式算法以解决MILP执行时间较长的问题。

Result: 研究揭示了延迟和能耗之间的权衡关系，强调了动态RAN重新配置的必要性，并验证了模型在不同拓扑和需求变化下的有效性。

Conclusion: 本文提出了一种混合整数线性规划（MILP）模型和启发式算法，用于优化5G网络中RAN的配置，平衡了延迟和能耗的权衡，为现有和未来的RAN部署提供了优化基础。

Abstract: In 5G networks, base station (BS) disaggregation and new services present
challenges in radio access network (RAN) configuration, particularly in meeting
their bandwidth and latency constraints. The BS disaggregation is enabled by
functional splitting (FS), which distributes the RAN functions in processing
nodes and alleviates latency and bandwidth requirements in the fronthaul (FH).
Besides network performance, energy consumption is a critical concern for
mobile network operators (MNO), since RAN operation constitutes a major portion
of their operational expenses (OPEX). RAN configuration optimization is
essential to balance service performance with cost-effective energy
consumption. In this paper, we propose a mixed-integer linear programming
(MILP) model formulated with three objective functions: (i) minimizing
fronthaul (FH) latency, (ii) minimizing energy consumption, and (iii) a
bi-objective optimization that jointly balances both latency and energy
consumption. The model determines the optimal FS option, RAN function
placement, and routing for eMBB, URLLC, and mMTC slices. Although prior studies
have addressed RAN configuration either from an energy minimization or latency
reduction perspective, few have considered both aspects in realistic scenarios.
Our evaluation spans different topologies, accounts for variations in
aggregated gNB demand, explores diverse FS combinations, and incorporates Time
Sensitive Networking (TSN) modeling for latency analysis, as it is also crucial
in RAN performance. Given that MILP's execution time can be significant, we
propose a heuristic algorithm that adheres to RAN constraints. Our results
reveal a trade-off between latency and energy consumption, highlighting the
need for dynamic RAN reconfiguration. These insights provide a foundation to
optimize existing and future RAN deployments.

</details>


### [107] [Automated Extraction of Protocol State Machines from 3GPP Specifications with Domain-Informed Prompts and LLM Ensembles](https://arxiv.org/abs/2510.14348)
*Miao Zhang,Runhan Feng,Hongbo Tang,Yu Zhao,Jie Yang,Hang Qiu,Qi Liu*

Main category: cs.NI

TL;DR: SpecGPT利用LLM自动从3GPP文档中提取协议状态机，优于现有方法，解决了手动建模的复杂性和维护难题。


<details>
  <summary>Details</summary>
Motivation: 移动通信网络的安全性和可靠性高度依赖准确的状态机建模，但现有手动建模方法劳动密集、易出错且难以维护。

Method: SpecGPT将技术规范分割为有意义的段落，应用领域知识提示与链式思考推理，并采用集成方法增强输出的可靠性。

Result: SpecGPT在三个代表性5G协议（NAS、NGAP和PFCP）上的评估表现优于现有方法。

Conclusion: SpecGPT框架通过利用大型语言模型自动从3GPP文档中提取协议状态机，证明了其在协议建模中的有效性，优于现有方法。

Abstract: Mobile telecommunication networks are foundational to global infrastructure
and increasingly support critical sectors such as manufacturing,
transportation, and healthcare. The security and reliability of these networks
are essential, yet depend heavily on accurate modeling of underlying protocols
through state machines. While most prior work constructs such models manually
from 3GPP specifications, this process is labor-intensive, error-prone, and
difficult to maintain due to the complexity and frequent updates of the
specifications. Recent efforts using natural language processing have shown
promise, but remain limited in handling the scale and intricacy of cellular
protocols. In this work, we propose SpecGPT, a novel framework that leverages
large language models (LLMs) to automatically extract protocol state machines
from 3GPP documents. SpecGPT segments technical specifications into meaningful
paragraphs, applies domain-informed prompting with chain-of-thought reasoning,
and employs ensemble methods to enhance output reliability. We evaluate SpecGPT
on three representative 5G protocols (NAS, NGAP, and PFCP) using manually
annotated ground truth, and show that it outperforms existing approaches,
demonstrating the effectiveness of LLMs for protocol modeling at scale.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [108] [Decision Oriented Technique (DOTechnique): Finding Model Validity Through Decision-Maker Context](https://arxiv.org/abs/2510.13858)
*Raheleh Biglari,Joachim Denil*

Main category: cs.AI

TL;DR: DOTechnique是一种基于决策一致性的模型验证新方法，适用于缺乏明确有效性边界的情况，通过领域约束和符号推理提高效率，高速公路变道系统案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统模型验证方法依赖于预定义的有效性框架，但这些框架可能不足或不可用。DOTechnique旨在通过决策一致性来解决这一问题。

Method: 论文提出了Decision Oriented Technique (DOTechnique)，通过评估替代模型是否与高保真模型产生等效决策来确定模型有效性。该方法整合了领域约束和符号推理以缩小搜索空间，提高计算效率。

Result: 以高速公路变道系统为例，DOTechnique成功识别了模拟模型的有效性区域，展示了其在决策者上下文中支持模型有效性发现的潜力。

Conclusion: DOTechnique通过决策一致性而非输出相似性来确定模型有效性，为模型验证提供了一种新方法，尤其在缺乏明确有效性边界的情况下表现突出。

Abstract: Model validity is as critical as the model itself, especially when guiding
decision-making processes. Traditional approaches often rely on predefined
validity frames, which may not always be available or sufficient. This paper
introduces the Decision Oriented Technique (DOTechnique), a novel method for
determining model validity based on decision consistency rather than output
similarity. By evaluating whether surrogate models lead to equivalent decisions
compared to high-fidelity models, DOTechnique enables efficient identification
of validity regions, even in the absence of explicit validity boundaries. The
approach integrates domain constraints and symbolic reasoning to narrow the
search space, enhancing computational efficiency. A highway lane change system
serves as a motivating example, demonstrating how DOTechnique can uncover the
validity region of a simulation model. The results highlight the potential of
the technique to support finding model validity through decision-maker context.

</details>


### [109] [Do Slides Help? Multi-modal Context for Automatic Transcription of Conference Talks](https://arxiv.org/abs/2510.13979)
*Supriti Sinhamahapatra,Jan Niehues*

Main category: cs.AI

TL;DR: 该研究通过整合演示幻灯片等多模态信息，显著提升了ASR系统的性能，特别是在领域特定术语的识别上。


<details>
  <summary>Details</summary>
Motivation: 现有的ASR系统主要依赖声学信息，忽视了多模态上下文（如视觉信息）在消歧和适应中的重要作用。

Method: 创建了一个多模态演示的基准测试，包括领域特定术语的自动分析；探索了用多模态信息增强语音模型的方法；通过数据增强解决了缺乏配套幻灯片的数据集问题。

Result: 使用增强数据集训练的模型，相比基线模型，在所有单词上的错误率相对降低了约34%，在领域特定术语上的错误率相对降低了35%。

Conclusion: 整合多模态信息（如演示幻灯片）可以显著提升自动语音识别系统的性能，特别是在领域特定术语的识别上。

Abstract: State-of-the-art (SOTA) Automatic Speech Recognition (ASR) systems primarily
rely on acoustic information while disregarding additional multi-modal context.
However, visual information are essential in disambiguation and adaptation.
While most work focus on speaker images to handle noise conditions, this work
also focuses on integrating presentation slides for the use cases of scientific
presentation.
  In a first step, we create a benchmark for multi-modal presentation including
an automatic analysis of transcribing domain-specific terminology. Next, we
explore methods for augmenting speech models with multi-modal information. We
mitigate the lack of datasets with accompanying slides by a suitable approach
of data augmentation. Finally, we train a model using the augmented dataset,
resulting in a relative reduction in word error rate of approximately 34%,
across all words and 35%, for domain-specific terms compared to the baseline
model.

</details>


### [110] [Do Large Language Models Show Biases in Causal Learning? Insights from Contingency Judgment](https://arxiv.org/abs/2510.13985)
*María Victoria Carro,Denise Alejandra Mester,Francisca Gauna Selasco,Giovanni Franco Gabriel Marraffini,Mario Alejandro Leiva,Gerardo I. Simari,María Vanina Martinez*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在因果推理中易产生幻觉，支持其仅复制语言而非理解因果的假设，对相关应用领域提出警示。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否会在面对经典认知科学范式（如关联判断任务）时产生因果幻觉，这种认知偏差被认为是许多社会问题的根源。

Method: 研究构建了一个包含1000个零关联场景（不足以建立变量间因果关系）的数据集，并在医学背景下提示大型语言模型评估潜在原因的有效性。

Result: 所有评估的模型都系统地推断出无根据的因果关系，显示出对因果幻觉的强烈易感性。

Conclusion: 大型语言模型在因果推理任务中表现出强烈的因果幻觉倾向，这支持了它们仅能复制因果语言而非真正理解因果关系的假设，并引发了对在需要准确因果推理的领域中使用语言模型的担忧。

Abstract: Causal learning is the cognitive process of developing the capability of
making causal inferences based on available information, often guided by
normative principles. This process is prone to errors and biases, such as the
illusion of causality, in which people perceive a causal relationship between
two variables despite lacking supporting evidence. This cognitive bias has been
proposed to underlie many societal problems, including social prejudice,
stereotype formation, misinformation, and superstitious thinking. In this work,
we examine whether large language models are prone to developing causal
illusions when faced with a classic cognitive science paradigm: the contingency
judgment task. To investigate this, we constructed a dataset of 1,000 null
contingency scenarios (in which the available information is not sufficient to
establish a causal relationship between variables) within medical contexts and
prompted LLMs to evaluate the effectiveness of potential causes. Our findings
show that all evaluated models systematically inferred unwarranted causal
relationships, revealing a strong susceptibility to the illusion of causality.
While there is ongoing debate about whether LLMs genuinely understand causality
or merely reproduce causal language without true comprehension, our findings
support the latter hypothesis and raise concerns about the use of language
models in domains where accurate causal reasoning is essential for informed
decision-making.

</details>


### [111] [GammaZero: Learning To Guide POMDP Belief Space Search With Graph Representations](https://arxiv.org/abs/2510.14035)
*Rajesh Mangannavar,Prasad Tadepalli*

Main category: cs.AI

TL;DR: GammaZero提出了一种基于图的POMDP规划框架，通过统一表示实现跨问题规模的泛化，零样本扩展到更大问题且保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要特定领域的神经架构且难以扩展，GammaZero旨在通过统一的图表示框架解决这些问题，实现跨问题规模的泛化。

Method: 采用图神经网络和解码器架构，从专家演示中学习价值函数和策略，然后将这些启发式方法应用于蒙特卡洛树搜索以指导更大规模的问题。

Result: 在标准POMDP基准测试中，GammaZero在相同规模问题上表现与BetaZero相当，但能零样本泛化到比训练时大2-4倍的问题，且保持解决方案质量。

Conclusion: GammaZero通过统一的基于图的信念表示，实现了在POMDPs中跨问题规模的泛化能力，且在零样本情况下能够扩展到训练时未见过的更大问题，保持解决方案质量的同时减少搜索需求。

Abstract: We introduce an action-centric graph representation framework for learning to
guide planning in Partially Observable Markov Decision Processes (POMDPs).
Unlike existing approaches that require domain-specific neural architectures
and struggle with scalability, GammaZero leverages a unified graph-based belief
representation that enables generalization across problem sizes within a
domain. Our key insight is that belief states can be systematically transformed
into action-centric graphs where structural patterns learned on small problems
transfer to larger instances. We employ a graph neural network with a decoder
architecture to learn value functions and policies from expert demonstrations
on computationally tractable problems, then apply these learned heuristics to
guide Monte Carlo tree search on larger problems. Experimental results on
standard POMDP benchmarks demonstrate that GammaZero achieves comparable
performance to BetaZero when trained and tested on the same-sized problems,
while uniquely enabling zero-shot generalization to problems 2-4 times larger
than those seen during training, maintaining solution quality with reduced
search requirements.

</details>


### [112] [Position: Require Frontier AI Labs To Release Small "Analog" Models](https://arxiv.org/abs/2510.14053)
*Shriyash Upadhyay,Chaithanya Bandi,Narmeen Oozeer,Philip Quirke*

Main category: cs.AI

TL;DR: 本文提出要求大型AI实验室发布小型开放模拟模型，作为公共代理支持安全验证和可解释性研究，既确保安全又促进创新，降低监管负担并加速安全进步。


<details>
  <summary>Details</summary>
Motivation: 当前对前沿AI模型的监管提案因安全与创新的权衡而被搁置，引发了人们对安全监管成本的担忧。本文旨在提出一种既能确保安全又能促进创新的替代方案。

Method: 要求大型AI实验室发布训练方式与大型专有模型相似且从中提取的小型、开放可访问的模拟模型。这些模型作为公共代理，支持广泛的研究社区参与安全验证和可解释性研究。

Result: 研究表明，使用这些小型模型开发的安全和可解释性方法可有效推广到前沿规模的系统。这一政策显著降低了监管负担，并加速了安全进步。

Conclusion: 本文提出了一种替代性监管方法，通过要求大型AI实验室发布小型、开放的模拟模型，既能确保AI安全，又能积极促进创新。这种方法通过公共代理模型支持广泛的安全验证、可解释性研究和算法透明度，同时降低监管负担并加速安全进步。

Abstract: Recent proposals for regulating frontier AI models have sparked concerns
about the cost of safety regulation, and most such regulations have been
shelved due to the safety-innovation tradeoff. This paper argues for an
alternative regulatory approach that ensures AI safety while actively promoting
innovation: mandating that large AI laboratories release small, openly
accessible analog models (scaled-down versions) trained similarly to and
distilled from their largest proprietary models.
  Analog models serve as public proxies, allowing broad participation in safety
verification, interpretability research, and algorithmic transparency without
forcing labs to disclose their full-scale models. Recent research demonstrates
that safety and interpretability methods developed using these smaller models
generalize effectively to frontier-scale systems. By enabling the wider
research community to directly investigate and innovate upon accessible
analogs, our policy substantially reduces the regulatory burden and accelerates
safety advancements.
  This mandate promises minimal additional costs, leveraging reusable resources
like data and infrastructure, while significantly contributing to the public
good. Our hope is not only that this policy be adopted, but that it illustrates
a broader principle supporting fundamental research in machine learning: deeper
understanding of models relaxes the safety-innovation tradeoff and lets us have
more of both.

</details>


### [113] [Agentic Design of Compositional Machines](https://arxiv.org/abs/2510.14980)
*Wenqian Zhang,Weiyang Liu,Zhen Liu*

Main category: cs.AI

TL;DR: 论文评估了LLMs在机器设计任务中的表现，发现其不足并探索了强化学习作为改进方案。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）是否能够学习创造复杂机器，特别是在组合式机器设计任务中的表现。

Method: 研究使用BesiegeField作为测试平台，结合agentic workflows对LLMs进行基准测试，并通过强化学习进行微调实验。

Result: 研究发现当前开源LLMs在空间推理、战略组装和指令遵循等方面存在不足，强化学习微调实验展示了改进潜力。

Conclusion: 论文通过BesiegeField测试平台评估了LLMs在机器设计任务中的表现，发现当前开源模型存在不足，并探索了强化学习作为改进路径。

Abstract: The design of complex machines stands as both a marker of human intelligence
and a foundation of engineering practice. Given recent advances in large
language models (LLMs), we ask whether they, too, can learn to create. We
approach this question through the lens of compositional machine design: a task
in which machines are assembled from standardized components to meet functional
demands like locomotion or manipulation in a simulated physical environment. To
support this investigation, we introduce BesiegeField, a testbed built on the
machine-building game Besiege, which enables part-based construction, physical
simulation and reward-driven evaluation. Using BesiegeField, we benchmark
state-of-the-art LLMs with agentic workflows and identify key capabilities
required for success, including spatial reasoning, strategic assembly, and
instruction-following. As current open-source models fall short, we explore
reinforcement learning (RL) as a path to improvement: we curate a cold-start
dataset, conduct RL finetuning experiments, and highlight open challenges at
the intersection of language, machine design, and physical reasoning.

</details>


### [114] [Generating Fair Consensus Statements with Social Choice on Token-Level MDPs](https://arxiv.org/abs/2510.14106)
*Carter Blair,Kate Larson*

Main category: cs.AI

TL;DR: 本文提出了一种基于MDP和社会选择理论的共识声明生成方法，通过令牌级奖励和公平性保障，显著提升了代理对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的共识声明生成框架缺乏可证明公平性的结构，无法在聚合多样化自由形式意见时提供公平保障。本文旨在通过MDP和社会选择理论解决这一问题。

Method: 将共识声明生成任务建模为多目标、令牌级MDP，每个目标对应代理的偏好。利用代理策略（如个性化语言模型）推导令牌级奖励，并基于社会选择理论提出两种方法：一是保证ex-ante核心的随机生成策略，二是通过搜索算法最大化平等福利。

Result: 实验表明，基于平等福利目标的搜索算法生成的共识声明在代理对齐的最坏情况下优于基线方法。

Conclusion: 本文提出了一种基于多目标、令牌级马尔可夫决策过程（MDP）的共识声明生成框架，通过社会选择理论原则确保公平性。实验证明，该方法在生成共识声明时，相比基线方法（如Habermas Machine）能显著提升最坏情况下代理对齐。

Abstract: Current frameworks for consensus statement generation with large language
models lack the inherent structure needed to provide provable fairness
guarantees when aggregating diverse free-form opinions. We model the task as a
multi-objective, token-level Markov Decision Process (MDP), where each
objective corresponds to an agent's preference. Token-level rewards for each
agent are derived from their policy (e.g., a personalized language model). This
approach utilizes the finding that such policies implicitly define optimal
Q-functions, providing a principled way to quantify rewards at each generation
step without a value function (Rafailov et al., 2024). This MDP formulation
creates a formal structure amenable to analysis using principles from social
choice theory. We propose two approaches grounded in social choice theory.
First, we propose a stochastic generation policy guaranteed to be in the
ex-ante core, extending core stability concepts from voting theory to text
generation. This policy is derived from an underlying distribution over
complete statements that maximizes proportional fairness (Nash Welfare).
Second, for generating a single statement, we target the maximization of
egalitarian welfare using search algorithms within the MDP framework.
Empirically, experiments using language models to instantiate agent policies
show that search guided by the egalitarian objective generates consensus
statements with improved worst-case agent alignment compared to baseline
methods, including the Habermas Machine (Tessler et al., 2024).

</details>


### [115] [STEMS: Spatial-Temporal Enhanced Safe Multi-Agent Coordination for Building Energy Management](https://arxiv.org/abs/2510.14112)
*Huiliang Zhang,Di Wu,Arnaud Zinflou,Benoit Boulet*

Main category: cs.AI

TL;DR: STEMS是一个安全约束的多智能体强化学习框架，用于协调建筑能源管理，显著提升性能并确保安全。


<details>
  <summary>Details</summary>
Motivation: 当前多建筑能源系统面临空间-时间信息利用不足、缺乏严格安全保证和系统复杂性等挑战。

Method: STEMS结合了空间-时间图表示学习框架（GCN-Transformer融合架构）和安全约束的多智能体强化学习算法（使用控制屏障函数）。

Result: STEMS在真实建筑数据集上实现了21%的成本降低、18%的排放减少，并将安全违规率从35.1%降至5.6%，同时保持仅0.13的不适比例。

Conclusion: STEMS框架在协调建筑能源管理中表现出色，显著降低了能源成本和排放，同时提供了严格的安全保障和良好的舒适性。

Abstract: Building energy management is essential for achieving carbon reduction goals,
improving occupant comfort, and reducing energy costs. Coordinated building
energy management faces critical challenges in exploiting spatial-temporal
dependencies while ensuring operational safety across multi-building systems.
Current multi-building energy systems face three key challenges: insufficient
spatial-temporal information exploitation, lack of rigorous safety guarantees,
and system complexity. This paper proposes Spatial-Temporal Enhanced Safe
Multi-Agent Coordination (STEMS), a novel safety-constrained multi-agent
reinforcement learning framework for coordinated building energy management.
STEMS integrates two core components: (1) a spatial-temporal graph
representation learning framework using a GCN-Transformer fusion architecture
to capture inter-building relationships and temporal patterns, and (2) a
safety-constrained multi-agent RL algorithm incorporating Control Barrier
Functions to provide mathematical safety guarantees. Extensive experiments on
real-world building datasets demonstrate STEMS's superior performance over
existing methods, showing that STEMS achieves 21% cost reduction, 18% emission
reduction, and dramatically reduces safety violations from 35.1% to 5.6% while
maintaining optimal comfort with only 0.13 discomfort proportion. The framework
also demonstrates strong robustness during extreme weather conditions and
maintains effectiveness across different building types.

</details>


### [116] [Formalizing the Safety, Security, and Functional Properties of Agentic AI Systems](https://arxiv.org/abs/2510.14133)
*Edoardo Allegrini,Ananth Shreekumar,Z. Berkay Celik*

Main category: cs.AI

TL;DR: 本文提出了一种用于多AI代理系统的统一建模框架，包含两个基础模型和31个属性，支持形式化验证，旨在解决当前碎片化通信协议带来的语义鸿沟和风险。


<details>
  <summary>Details</summary>
Motivation: 当前多代理AI系统的通信协议（如MCP和A2A）存在碎片化问题，导致语义鸿沟，阻碍系统属性的严格分析，并引入架构错位和可被利用的协调问题。为解决这些问题，需要一个统一的语义框架。

Method: 引入两个基础模型：主机代理模型（负责与用户交互、任务分解和执行协调）和任务生命周期模型（详细描述子任务从创建到完成的状态和转换）。基于这些模型，定义了31个属性（分为活跃性、安全性、完整性和公平性），并用时序逻辑表达，以支持形式化验证。

Result: 提出了一个领域无关的框架，包含两个基础模型和31个属性，支持形式化验证，能够检测协调边缘情况、预防死锁和安全漏洞。

Conclusion: 本文提出了一个领域无关的框架，用于系统分析、设计和部署正确、可靠且稳健的Agentic AI系统。通过两个基础模型（主机代理模型和任务生命周期模型）及31个属性（17个主机代理属性和14个任务生命周期属性），实现了对多AI代理系统行为的统一语义框架和形式化验证。

Abstract: Agentic AI systems, which leverage multiple autonomous agents and Large
Language Models (LLMs), are increasingly used to address complex, multi-step
tasks. The safety, security, and functionality of these systems are critical,
especially in high-stakes applications. However, the current ecosystem of
inter-agent communication is fragmented, with protocols such as the Model
Context Protocol (MCP) for tool access and the Agent-to-Agent (A2A) protocol
for coordination being analyzed in isolation. This fragmentation creates a
semantic gap that prevents the rigorous analysis of system properties and
introduces risks such as architectural misalignment and exploitable
coordination issues. To address these challenges, we introduce a modeling
framework for agentic AI systems composed of two foundational models. The
first, the host agent model, formalizes the top-level entity that interacts
with the user, decomposes tasks, and orchestrates their execution by leveraging
external agents and tools. The second, the task lifecycle model, details the
states and transitions of individual sub-tasks from creation to completion,
providing a fine-grained view of task management and error handling. Together,
these models provide a unified semantic framework for reasoning about the
behavior of multi-AI agent systems. Grounded in this framework, we define 17
properties for the host agent and 14 for the task lifecycle, categorized into
liveness, safety, completeness, and fairness. Expressed in temporal logic,
these properties enable formal verification of system behavior, detection of
coordination edge cases, and prevention of deadlocks and security
vulnerabilities. Through this effort, we introduce the first rigorously
grounded, domain-agnostic framework for the systematic analysis, design, and
deployment of correct, reliable, and robust agentic AI systems.

</details>


### [117] [A Multimodal Approach to Heritage Preservation in the Context of Climate Change](https://arxiv.org/abs/2510.14136)
*David Roqui,Adèle Cormier,nistor Grozavu,Ann Bourges*

Main category: cs.AI

TL;DR: 该论文提出了一种轻量级多模态方法，结合传感器和视觉数据，显著提高了文化遗产退化预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 文化遗产因气候变化加速退化，而传统监测方法（仅视觉检查或环境传感器）无法捕捉环境压力与材料退化之间的复杂相互作用。

Method: 提出了一种轻量级多模态架构，融合传感器数据（温度、湿度）和视觉图像来预测文化遗产的退化程度。采用PerceiverIO的简化编码器（64D潜在空间）和Adaptive Barlow Twins损失函数，以防止过拟合并促进模态互补性。

Result: 在斯特拉斯堡大教堂的数据上，模型准确率达到76.9%，比标准多模态架构（VisualBERT、Transformer）提高了43%，比普通PerceiverIO提高了25%。消融研究表明传感器单独使用时准确率为61.5%，而仅图像时为46.2%，证实了多模态协同的成功。系统超参数研究确定了最佳相关性目标（τ=0.3），平衡了对齐和互补性，准确率为69.2%。

Conclusion: 该研究通过轻量级多模态架构和对比正则化，在数据稀缺的文化遗产监测环境中实现了有效的多模态学习，为AI驱动的保护决策支持系统奠定了基础。

Abstract: Cultural heritage sites face accelerating degradation due to climate change,
yet tradi- tional monitoring relies on unimodal analysis (visual inspection or
environmental sen- sors alone) that fails to capture the complex interplay
between environmental stres- sors and material deterioration. We propose a
lightweight multimodal architecture that fuses sensor data (temperature,
humidity) with visual imagery to predict degradation severity at heritage
sites. Our approach adapts PerceiverIO with two key innovations: (1) simplified
encoders (64D latent space) that prevent overfitting on small datasets (n=37
training samples), and (2) Adaptive Barlow Twins loss that encourages modality
complementarity rather than redundancy. On data from Strasbourg Cathedral, our
model achieves 76.9% accu- racy, a 43% improvement over standard multimodal
architectures (VisualBERT, Trans- former) and 25% over vanilla PerceiverIO.
Ablation studies reveal that sensor-only achieves 61.5% while image-only
reaches 46.2%, confirming successful multimodal synergy. A systematic
hyperparameter study identifies an optimal moderate correlation target ({\tau}
=0.3) that balances align- ment and complementarity, achieving 69.2% accuracy
compared to other {\tau} values ({\tau} =0.1/0.5/0.7: 53.8%, {\tau} =0.9:
61.5%). This work demonstrates that architectural sim- plicity combined with
contrastive regularization enables effective multimodal learning in data-scarce
heritage monitoring contexts, providing a foundation for AI-driven con-
servation decision support systems.

</details>


### [118] [CodeEvolve: An open source evolutionary coding agent for algorithm discovery and optimization](https://arxiv.org/abs/2510.14150)
*Henrique Assumpção,Diego Ferreira,Leandro Campos,Fabricio Murai*

Main category: cs.AI

TL;DR: CodeEvolve是一个结合LLMs和遗传算法的开源框架，通过岛屿遗传算法和灵感交叉机制，在数学基准测试中超越AlphaEvolve。


<details>
  <summary>Details</summary>
Motivation: 为了将强大的进化概念应用于LLM领域，并解决复杂计算问题，作者开发了CodeEvolve，旨在超越现有方法如AlphaEvolve的性能。

Method: CodeEvolve采用了基于岛屿的遗传算法以保持种群多样性和提高吞吐量，引入了新颖的基于灵感的交叉机制，利用LLMs的上下文窗口结合成功解决方案的特征，并实现了元提示策略以动态探索解决方案空间。

Result: CodeEvolve在多个挑战性问题上的表现超越了AlphaEvolve。

Conclusion: CodeEvolve通过结合大型语言模型（LLMs）和遗传算法，在解决复杂计算问题方面表现出色，其性能超越了Google DeepMind的AlphaEvolve，并开源了完整框架以促进协作和加速进展。

Abstract: In this work, we introduce CodeEvolve, an open-source evolutionary coding
agent that unites Large Language Models (LLMs) with genetic algorithms to solve
complex computational problems. Our framework adapts powerful evolutionary
concepts to the LLM domain, building upon recent methods for generalized
scientific discovery. CodeEvolve employs an island-based genetic algorithm to
maintain population diversity and increase throughput, introduces a novel
inspiration-based crossover mechanism that leverages the LLMs context window to
combine features from successful solutions, and implements meta-prompting
strategies for dynamic exploration of the solution space. We conduct a rigorous
evaluation of CodeEvolve on a subset of the mathematical benchmarks used to
evaluate Google DeepMind's closed-source AlphaEvolve. Our findings show that
our method surpasses AlphaEvolve's performance on several challenging problems.
To foster collaboration and accelerate progress, we release our complete
framework as an open-source repository.

</details>


### [119] [Combining Reinforcement Learning and Behavior Trees for NPCs in Video Games with AMD Schola](https://arxiv.org/abs/2510.14154)
*Tian Liu,Alex Cann,Ian Colbert,Mehdi Saeedi*

Main category: cs.AI

TL;DR: 本文探讨了强化学习与行为树结合在游戏AI中的可行性，并通过实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习研究进展迅速，但在商业视频游戏中的应用仍然缓慢，本文旨在探索RL与行为树的结合以解决这一挑战。

Method: 使用AMD Schola插件在Unreal Engine中联合训练RL模型与行为树，展示了多种技能。

Result: 成功在受《最后生还者》启发的复杂3D环境中创建了多任务NPC，验证了BT+RL方法的可行性。

Conclusion: 本文展示了结合强化学习（RL）与行为树（BT）的可行性，并通过AMD Schola插件在复杂3D环境中训练多任务NPC，为游戏AI社区提供了实用的方法。

Abstract: While the rapid advancements in the reinforcement learning (RL) research
community have been remarkable, the adoption in commercial video games remains
slow. In this paper, we outline common challenges the Game AI community faces
when using RL-driven NPCs in practice, and highlight the intersection of RL
with traditional behavior trees (BTs) as a crucial juncture to be explored
further. Although the BT+RL intersection has been suggested in several research
papers, its adoption is rare. We demonstrate the viability of this approach
using AMD Schola -- a plugin for training RL agents in Unreal Engine -- by
creating multi-task NPCs in a complex 3D environment inspired by the commercial
video game ``The Last of Us". We provide detailed methodologies for jointly
training RL models with BTs while showcasing various skills.

</details>


### [120] [JEDA: Query-Free Clinical Order Search from Ambient Dialogues](https://arxiv.org/abs/2510.14169)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Amitabh Saikia,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: JEDA 是一种无需LLM的双编码器，通过对比学习将临床对话与指令对齐，实现快速、稳定的实时检索。


<details>
  <summary>Details</summary>
Motivation: 临床对话中混合了显性指令和隐性推理，现有系统依赖LLM重写，增加了延迟、不稳定性和不透明性，阻碍了实时指令处理。

Method: JEDA 是一个基于 PubMedBERT 初始化的双编码器，通过重复安全对比目标进行微调，使用受限LLM指导将每个签署的指令与互补的表述（仅命令、仅上下文、命令+上下文、上下文+推理）关联起来。

Result: JEDA 在实践中表现优异，显著优于其基础编码器和近期开放的嵌入器（如 Linq Embed Mistral、SFR Embedding 等）。

Conclusion: JEDA 是一个快速、可解释且无需LLM的检索层，能够实时将环境上下文与可操作的临床指令联系起来。

Abstract: Clinical conversations mix explicit directives (order a chest X-ray) with
implicit reasoning (the cough worsened overnight, we should check for
pneumonia). Many systems rely on LLM rewriting, adding latency, instability,
and opacity that hinder real-time ordering. We present JEDA (Joint Embedding
for Direct and Ambient clinical orders), a domain-initialized bi-encoder that
retrieves canonical orders directly and, in a query-free mode, encodes a short
rolling window of ambient dialogue to trigger retrieval. Initialized from
PubMedBERT and fine-tuned with a duplicate-safe contrastive objective, JEDA
aligns heterogeneous expressions of intent to shared order concepts. Training
uses constrained LLM guidance to tie each signed order to complementary
formulations (command only, context only, command+context, context+reasoning),
producing clearer inter-order separation, tighter query extendash order
coupling, and stronger generalization. The query-free mode is noise-resilient,
reducing sensitivity to disfluencies and ASR errors by conditioning on a short
window rather than a single utterance. Deployed in practice, JEDA yields large
gains and substantially outperforms its base encoder and recent open embedders
(Linq Embed Mistral, SFR Embedding, GTE Qwen, BGE large, Embedding Gemma). The
result is a fast, interpretable, LLM-free retrieval layer that links ambient
context to actionable clinical orders in real time.

</details>


### [121] [ARM-FM: Automated Reward Machines via Foundation Models for Compositional Reinforcement Learning](https://arxiv.org/abs/2510.14176)
*Roger Creus Castanyer,Faisal Mohamed,Pablo Samuel Castro,Cyrus Neary,Glen Berseth*

Main category: cs.AI

TL;DR: ARM-FM利用基础模型自动生成奖励机器，实现自然语言驱动的强化学习奖励设计，并在复杂环境中展现出优秀的表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习算法对奖励函数规范高度敏感的问题，提升其广泛适用性。

Method: 使用基础模型（FMs）自动从自然语言规范生成奖励机器（RMs），并为每个RM自动机状态关联语言嵌入以实现跨任务泛化。

Result: 在多种挑战性环境中验证了ARM-FM的有效性，包括零样本泛化能力。

Conclusion: ARM-FM通过结合基础模型和奖励机器，实现了自动化、组合式的奖励设计，显著提升了强化学习算法的适用性和泛化能力。

Abstract: Reinforcement learning (RL) algorithms are highly sensitive to reward
function specification, which remains a central challenge limiting their broad
applicability. We present ARM-FM: Automated Reward Machines via Foundation
Models, a framework for automated, compositional reward design in RL that
leverages the high-level reasoning capabilities of foundation models (FMs).
Reward machines (RMs) -- an automata-based formalism for reward specification
-- are used as the mechanism for RL objective specification, and are
automatically constructed via the use of FMs. The structured formalism of RMs
yields effective task decompositions, while the use of FMs enables objective
specifications in natural language. Concretely, we (i) use FMs to automatically
generate RMs from natural language specifications; (ii) associate language
embeddings with each RM automata-state to enable generalization across tasks;
and (iii) provide empirical evidence of ARM-FM's effectiveness in a diverse
suite of challenging environments, including evidence of zero-shot
generalization.

</details>


### [122] [Implementation of AI in Precision Medicine](https://arxiv.org/abs/2510.14194)
*Göktuğ Bender,Samer Faraj,Anand Bhardwaj*

Main category: cs.AI

TL;DR: 本文综述了AI在精准医学中的应用现状，通过生态系统框架分析了关键障碍和推动因素，并提出了未来方向。


<details>
  <summary>Details</summary>
Motivation: AI在精准医学中的应用日益重要，但目前临床实施仍有限，本文旨在探讨其关键障碍和推动因素。

Method: 本文对2019-2024年关于AI在精准医学中实施的文献进行了范围综述，识别了数据质量、临床可靠性、工作流程整合和治理等关键障碍和推动因素。

Result: 通过生态系统框架，本文识别了影响AI在精准医学中实际应用的相互依赖关系。

Conclusion: 本文通过生态系统框架强调了AI在精准医学中实际应用的相互依赖关系，并提出了支持可信和可持续实施的未来方向。

Abstract: Artificial intelligence (AI) has become increasingly central to precision
medicine by enabling the integration and interpretation of multimodal data, yet
implementation in clinical settings remains limited. This paper provides a
scoping review of literature from 2019-2024 on the implementation of AI in
precision medicine, identifying key barriers and enablers across data quality,
clinical reliability, workflow integration, and governance. Through an
ecosystem-based framework, we highlight the interdependent relationships
shaping real-world translation and propose future directions to support
trustworthy and sustainable implementation.

</details>


### [123] [Echoes of Human Malice in Agents: Benchmarking LLMs for Multi-Turn Online Harassment Attacks](https://arxiv.org/abs/2510.14207)
*Trilok Padhi,Pinxian Lu,Abdulkadir Erol,Tanmay Sutar,Gauri Sharma,Mina Sonmez,Munmun De Choudhury,Ugur Kursuncu*

Main category: cs.AI

TL;DR: 该研究提出多轮攻击方法，发现LLM代理在多轮骚扰中易受攻击，且闭源模型更脆弱，呼吁加强安全防护。


<details>
  <summary>Details</summary>
Motivation: 当前LLM代理在交互式网络应用中日益普及，但仍易受滥用和伤害。以往越狱研究多集中于单轮提示，而实际骚扰多为多轮互动。

Method: 提出了一个在线骚扰代理基准，包括：(i) 合成的多轮骚扰对话数据集，(ii) 基于重复博弈理论的多代理（如骚扰者、受害者）模拟，(iii) 三种针对代理的记忆、规划和微调的越狱方法，(iv) 混合方法评估框架。使用了LLaMA-3.1-8B-Instruct（开源）和Gemini-2.0-flash（闭源）两种主流LLM。

Result: 越狱微调使骚扰几乎不可避免，攻击成功率在Llama中达95.78--96.89%（未调优时为57.25--64.19%），Gemini中达99.33%（未调优时为98.46%），且拒绝率降至1-2%。最常见的毒性行为为侮辱（调优后84.9--87.8% vs. 未调优44.2--50.8%）和谩骂（调优后81.2--85.1% vs. 未调优31.5--38.8%），表明其防护较弱。闭源和开源模型在多轮攻击中表现出不同的升级轨迹，闭源模型更易受攻击。

Conclusion: 研究发现，多轮攻击和基于理论的攻击不仅成功率极高，还能模拟类似人类的骚扰行为，这促使需要开发更强大的安全防护措施，以确保在线平台的安全和责任。

Abstract: Large Language Model (LLM) agents are powering a growing share of interactive
web applications, yet remain vulnerable to misuse and harm. Prior jailbreak
research has largely focused on single-turn prompts, whereas real harassment
often unfolds over multi-turn interactions. In this work, we present the Online
Harassment Agentic Benchmark consisting of: (i) a synthetic multi-turn
harassment conversation dataset, (ii) a multi-agent (e.g., harasser, victim)
simulation informed by repeated game theory, (iii) three jailbreak methods
attacking agents across memory, planning, and fine-tuning, and (iv) a
mixed-methods evaluation framework. We utilize two prominent LLMs,
LLaMA-3.1-8B-Instruct (open-source) and Gemini-2.0-flash (closed-source). Our
results show that jailbreak tuning makes harassment nearly guaranteed with an
attack success rate of 95.78--96.89% vs. 57.25--64.19% without tuning in Llama,
and 99.33% vs. 98.46% without tuning in Gemini, while sharply reducing refusal
rate to 1-2% in both models. The most prevalent toxic behaviors are Insult with
84.9--87.8% vs. 44.2--50.8% without tuning, and Flaming with 81.2--85.1% vs.
31.5--38.8% without tuning, indicating weaker guardrails compared to sensitive
categories such as sexual or racial harassment. Qualitative evaluation further
reveals that attacked agents reproduce human-like aggression profiles, such as
Machiavellian/psychopathic patterns under planning, and narcissistic tendencies
with memory. Counterintuitively, closed-source and open-source models exhibit
distinct escalation trajectories across turns, with closed-source models
showing significant vulnerability. Overall, our findings show that multi-turn
and theory-grounded attacks not only succeed at high rates but also mimic
human-like harassment dynamics, motivating the development of robust safety
guardrails to ultimately keep online platforms safe and responsible.

</details>


### [124] [LiveResearchBench: A Live Benchmark for User-Centric Deep Research in the Wild](https://arxiv.org/abs/2510.14240)
*Jiayu Wang,Yifei Ming,Riya Dulepet,Qinglin Chen,Austin Xu,Zixuan Ke,Frederic Sala,Aws Albarghouthi,Caiming Xiong,Shafiq Joty*

Main category: cs.AI

TL;DR: LiveResearchBench和DeepEval为评估深度研究能力提供了新基准，揭示了系统优势和不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准在用户中心性、动态性、明确性和多面性方面不足，无法公平比较深度研究能力。

Method: 引入LiveResearchBench（100个专家策划任务）和DeepEval（全面评估套件），对17种前沿深度研究系统进行综合评估。

Result: 分析揭示了当前系统的优势、常见失败模式及关键组件需求。

Conclusion: LiveResearchBench和DeepEval为系统评估深度研究能力提供了严谨的基础，揭示了当前系统的优势、常见失败模式及关键组件需求。

Abstract: Deep research -- producing comprehensive, citation-grounded reports by
searching and synthesizing information from hundreds of live web sources --
marks an important frontier for agentic systems. To rigorously evaluate this
ability, four principles are essential: tasks should be (1) user-centric,
reflecting realistic information needs, (2) dynamic, requiring up-to-date
information beyond parametric knowledge, (3) unambiguous, ensuring consistent
interpretation across users, and (4) multi-faceted and search-intensive,
requiring search over numerous web sources and in-depth analysis. Existing
benchmarks fall short of these principles, often focusing on narrow domains or
posing ambiguous questions that hinder fair comparison. Guided by these
principles, we introduce LiveResearchBench, a benchmark of 100 expert-curated
tasks spanning daily life, enterprise, and academia, each requiring extensive,
dynamic, real-time web search and synthesis. Built with over 1,500 hours of
human labor, LiveResearchBench provides a rigorous basis for systematic
evaluation. To evaluate citation-grounded long-form reports, we introduce
DeepEval, a comprehensive suite covering both content- and report-level
quality, including coverage, presentation, citation accuracy and association,
consistency and depth of analysis. DeepEval integrates four complementary
evaluation protocols, each designed to ensure stable assessment and high
agreement with human judgments. Using LiveResearchBench and DeepEval, we
conduct a comprehensive evaluation of 17 frontier deep research systems,
including single-agent web search, single-agent deep research, and multi-agent
systems. Our analysis reveals current strengths, recurring failure modes, and
key system components needed to advance reliable, insightful deep research.

</details>


### [125] [Towards Agentic Self-Learning LLMs in Search Environment](https://arxiv.org/abs/2510.14253)
*Wangtao Sun,Xiang Cheng,Jialin Fan,Yao Xu,Xing Yu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: ASL框架通过多角色协同进化实现智能体的自我改进，无需人工标注数据，展示了开放领域学习的可扩展性。


<details>
  <summary>Details</summary>
Motivation: 探索如何在不依赖人工标注数据集或预定义规则奖励的情况下，通过自学习扩展基于LLM的智能体。

Method: 提出了Agentic Self-Learning (ASL)框架，这是一个完全闭环、多角色的强化学习框架，统一了任务生成、策略执行和评估。ASL协调提示生成器、策略模型和生成奖励模型（GRM），形成一个良性循环。

Result: ASL在零标注数据条件下持续改进，表现出卓越的样本效率和鲁棒性，超越了基线方法（如Search-R1）。GRM的验证能力是主要瓶颈，持续训练和少量真实验证数据的注入能提升性能上限。

Conclusion: 本研究确立了奖励信号来源和数据规模作为开放领域智能体学习的关键杠杆，并展示了多角色协同进化对于可扩展、自我改进智能体的有效性。

Abstract: We study whether self-learning can scale LLM-based agents without relying on
human-curated datasets or predefined rule-based rewards. Through controlled
experiments in a search-agent setting, we identify two key determinants of
scalable agent training: the source of reward signals and the scale of agent
task data. We find that rewards from a Generative Reward Model (GRM) outperform
rigid rule-based signals for open-domain learning, and that co-evolving the GRM
with the policy further boosts performance. Increasing the volume of agent task
data-even when synthetically generated-substantially enhances agentic
capabilities. Building on these insights, we propose \textbf{Agentic
Self-Learning} (ASL), a fully closed-loop, multi-role reinforcement learning
framework that unifies task generation, policy execution, and evaluation within
a shared tool environment and LLM backbone. ASL coordinates a Prompt Generator,
a Policy Model, and a Generative Reward Model to form a virtuous cycle of
harder task setting, sharper verification, and stronger solving. Empirically,
ASL delivers steady, round-over-round gains, surpasses strong RLVR baselines
(e.g., Search-R1) that plateau or degrade, and continues improving under
zero-labeled-data conditions, indicating superior sample efficiency and
robustness. We further show that GRM verification capacity is the main
bottleneck: if frozen, it induces reward hacking and stalls progress; continual
GRM training on the evolving data distribution mitigates this, and a small
late-stage injection of real verification data raises the performance ceiling.
This work establishes reward source and data scale as critical levers for
open-domain agent learning and demonstrates the efficacy of multi-role
co-evolution for scalable, self-improving agents. The data and code of this
paper are released at
https://github.com/forangel2014/Towards-Agentic-Self-Learning

</details>


### [126] [MorphoBench: A Benchmark with Difficulty Adaptive to Model Reasoning](https://arxiv.org/abs/2510.14265)
*Xukai Wang,Xuanbo Liu,Mingrui Chen,Haitian Zhong,Xuanlin Yang,Bohan Zeng,Jinbo Hu,Hao Liang,Junbo Niu,Xuchen Li,Ruitao Wu,Ruichuan An,Yang Shi,Liu Liu,Xu-Yao Zhang,Qiang Liu,Zhouchen Lin,Wentao Zhang,Bin Dong*

Main category: cs.AI

TL;DR: 提出了MorphoBench，一个动态调整难度的多学科推理评估基准，包含1300+问题，提升了评估的全面性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有评估大型模型推理能力的基准在范围和灵活性上存在不足，无法适应模型推理能力的快速发展。

Method: 通过从现有基准和奥林匹克竞赛中选择复杂推理问题，并利用模型推理过程中的关键语句动态调整问题难度，同时结合仿真软件生成问题。

Result: 收集了1300多个测试问题，并根据o3和GPT-5等模型的推理能力迭代调整了MorphoBench的难度。

Conclusion: MorphoBench通过多学科问题和动态难度调整，提升了大型模型推理能力评估的全面性和有效性，为模型改进提供了可靠指导。

Abstract: With the advancement of powerful large-scale reasoning models, effectively
evaluating the reasoning capabilities of these models has become increasingly
important. However, existing benchmarks designed to assess the reasoning
abilities of large models tend to be limited in scope and lack the flexibility
to adapt their difficulty according to the evolving reasoning capacities of the
models. To address this, we propose MorphoBench, a benchmark that incorporates
multidisciplinary questions to evaluate the reasoning capabilities of large
models and can adjust and update question difficulty based on the reasoning
abilities of advanced models. Specifically, we curate the benchmark by
selecting and collecting complex reasoning questions from existing benchmarks
and sources such as Olympiad-level competitions. Additionally, MorphoBench
adaptively modifies the analytical challenge of questions by leveraging key
statements generated during the model's reasoning process. Furthermore, it
includes questions generated using simulation software, enabling dynamic
adjustment of benchmark difficulty with minimal resource consumption. We have
gathered over 1,300 test questions and iteratively adjusted the difficulty of
MorphoBench based on the reasoning capabilities of models such as o3 and GPT-5.
MorphoBench enhances the comprehensiveness and validity of model reasoning
evaluation, providing reliable guidance for improving both the reasoning
abilities and scientific robustness of large models. The code has been released
in https://github.com/OpenDCAI/MorphoBench.

</details>


### [127] [A Guardrail for Safety Preservation: When Safety-Sensitive Subspace Meets Harmful-Resistant Null-Space](https://arxiv.org/abs/2510.14301)
*Bingjie Zhang,Yibo Yang,Renzhe,Dandan Guo,Jindong Gu,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: GuardSpace通过分解权重和限制更新，在微调中保持LLMs安全对齐，显著降低有害响应并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在微调过程中安全对齐易损的问题，防止微调后模型产生有害响应。

Method: 通过协方差预条件奇异值分解将预训练权重分解为安全相关和安全无关组件，并构建一个空空间投影器限制适配器更新。

Result: 在多个下游任务中，GuardSpace将有害评分从14.4%降至3.6%，准确率从26.0%提升至28.0%。

Conclusion: GuardSpace框架在微调过程中有效保持了LLMs的安全对齐，显著降低了有害响应率，并提升了任务准确性。

Abstract: Large language models (LLMs) have achieved remarkable success in diverse
tasks, yet their safety alignment remains fragile during adaptation. Even when
fine-tuning on benign data or with low-rank adaptation, pre-trained safety
behaviors are easily degraded, leading to harmful responses in the fine-tuned
models. To address this challenge, we propose GuardSpace, a guardrail framework
for preserving safety alignment throughout fine-tuning, composed of two key
components: a safety-sensitive subspace and a harmful-resistant null space.
First, we explicitly decompose pre-trained weights into safety-relevant and
safety-irrelevant components using covariance-preconditioned singular value
decomposition, and initialize low-rank adapters from the safety-irrelevant
ones, while freezing safety-relevant components to preserve their associated
safety mechanism. Second, we construct a null space projector that restricts
adapter updates from altering safe outputs on harmful prompts, thereby
maintaining the original refusal behavior. Experiments with various pre-trained
models on multiple downstream tasks demonstrate that GuardSpace achieves
superior performance over existing methods. Notably, for Llama-2-7B-Chat
fine-tuned on GSM8K, GuardSpace outperforms the state-of-the-art method AsFT,
reducing the average harmful score from 14.4% to 3.6%, while improving the
accuracy from from 26.0% to 28.0%.

</details>


### [128] [Terrarium: Revisiting the Blackboard for Multi-Agent Safety, Privacy, and Security Studies](https://arxiv.org/abs/2510.14312)
*Mason Nakamura,Abhinav Kumar,Saaduddin Mahmud,Sahar Abdelnabi,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 本文提出Terrarium框架，用于研究基于LLM的多智能体系统的安全、隐私和风险问题，通过模块化测试平台加速可信系统的研发。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决基于LLM的多智能体系统中存在的安全、隐私和风险问题，如错位、恶意攻击和数据泄露。

Method: 通过重新利用黑板设计，创建了一个模块化、可配置的测试平台，用于多智能体协作研究。并实现了三种协作场景和四种代表性攻击。

Result: Terrarium框架展示了其灵活性，能够快速原型化、评估和迭代防御与设计。

Conclusion: Terrarium框架为基于LLM的多智能体系统提供了一个模块化、可配置的测试平台，旨在加速可信多智能体系统的研究进展。

Abstract: A multi-agent system (MAS) powered by large language models (LLMs) can
automate tedious user tasks such as meeting scheduling that requires
inter-agent collaboration. LLMs enable nuanced protocols that account for
unstructured private data, user constraints, and preferences. However, this
design introduces new risks, including misalignment and attacks by malicious
parties that compromise agents or steal user data. In this paper, we propose
the Terrarium framework for fine-grained study on safety, privacy, and security
in LLM-based MAS. We repurpose the blackboard design, an early approach in
multi-agent systems, to create a modular, configurable testbed for multi-agent
collaboration. We identify key attack vectors such as misalignment, malicious
agents, compromised communication, and data poisoning. We implement three
collaborative MAS scenarios with four representative attacks to demonstrate the
framework's flexibility. By providing tools to rapidly prototype, evaluate, and
iterate on defenses and designs, Terrarium aims to accelerate progress toward
trustworthy multi-agent systems.

</details>


### [129] [Metacognitive Self-Correction for Multi-Agent System via Prototype-Guided Next-Execution Reconstruction](https://arxiv.org/abs/2510.14319)
*Xu Shen,Qi Zhang,Song Wang,Zhen Tan,Xinyu Zhao,Laura Yao,Vaishnav Tadiparthi,Hossein Nourkhiz Mahjoub,Ehsan Moradi Pari,Kwonjoon Lee,Tianlong Chen*

Main category: cs.AI

TL;DR: MASC是一个多智能体系统的元认知框架，通过实时错误检测和自校正提升鲁棒性，实验显示其在错误检测和系统性能上均有显著改进。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统（MAS）在协作解决问题时表现出色，但对级联错误敏感，单个错误步骤可能通过智能体传播并破坏整体轨迹。因此，需要一个实时、无监督的步骤级错误检测和自校正框架来提升系统的鲁棒性。

Method: MASC框架结合了两种设计：(1) 基于历史的下一个执行重构，预测下一步的嵌入以捕捉因果一致性；(2) 原型引导增强，通过学习正常步骤嵌入的原型先验，在稀疏上下文（如早期步骤）中稳定重构和异常评分。

Result: 在Who&When基准测试中，MASC显著优于所有基线，步骤级错误检测的AUC-ROC提升了8.47%，并在不同MAS框架中实现了一致的端到端性能提升。

Conclusion: MASC框架通过实时、无监督的步骤级错误检测和自校正，显著提升了多智能体系统的鲁棒性，减少了错误传播，且在不同架构中均表现出稳定的端到端性能提升。

Abstract: Large Language Model based multi-agent systems (MAS) excel at collaborative
problem solving but remain brittle to cascading errors: a single faulty step
can propagate across agents and disrupt the trajectory. In this paper, we
present MASC, a metacognitive framework that endows MAS with real-time,
unsupervised, step-level error detection and self-correction. MASC rethinks
detection as history-conditioned anomaly scoring via two complementary designs:
(1) Next-Execution Reconstruction, which predicts the embedding of the next
step from the query and interaction history to capture causal consistency, and
(2) Prototype-Guided Enhancement, which learns a prototype prior over
normal-step embeddings and uses it to stabilize reconstruction and anomaly
scoring under sparse context (e.g., early steps). When an anomaly step is
flagged, MASC triggers a correction agent to revise the acting agent's output
before information flows downstream. On the Who&When benchmark, MASC
consistently outperforms all baselines, improving step-level error detection by
up to 8.47% AUC-ROC ; When plugged into diverse MAS frameworks, it delivers
consistent end-to-end gains across architectures, confirming that our
metacognitive monitoring and targeted correction can mitigate error propagation
with minimal overhead.

</details>


### [130] [AI for Service: Proactive Assistance with AI Glasses](https://arxiv.org/abs/2510.14359)
*Zichen Wen,Yiyu Wang,Chenfei Liao,Boxue Yang,Junxian Li,Weifeng Liu,Haocong He,Bolong Feng,Xuyang Liu,Yuanhuiyi Lyu,Xu Zheng,Xuming Hu,Linfeng Zhang*

Main category: cs.AI

TL;DR: AI4Service提出主动服务新范式Alpha-Service，通过AI眼镜多智能体系统实现无需提示的实时辅助，案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有AI服务多为被动响应，无法预见用户需求。AI4Service旨在实现主动、实时的日常辅助。

Method: 基于AI眼镜的多智能体系统，包含输入、中央处理、算术逻辑、存储和输出五个关键单元。

Result: 案例研究（如实时Blackjack顾问、博物馆导览和购物搭配助手）验证了系统能无明确提示下感知环境、推断意图并提供及时帮助。

Conclusion: Alpha-Service展现了通过AI眼镜实现主动服务的潜力，为未来智能助手的发展提供了新方向。

Abstract: In an era where AI is evolving from a passive tool into an active and
adaptive companion, we introduce AI for Service (AI4Service), a new paradigm
that enables proactive and real-time assistance in daily life. Existing AI
services remain largely reactive, responding only to explicit user commands. We
argue that a truly intelligent and helpful assistant should be capable of
anticipating user needs and taking actions proactively when appropriate. To
realize this vision, we propose Alpha-Service, a unified framework that
addresses two fundamental challenges: Know When to intervene by detecting
service opportunities from egocentric video streams, and Know How to provide
both generalized and personalized services. Inspired by the von Neumann
computer architecture and based on AI glasses, Alpha-Service consists of five
key components: an Input Unit for perception, a Central Processing Unit for
task scheduling, an Arithmetic Logic Unit for tool utilization, a Memory Unit
for long-term personalization, and an Output Unit for natural human
interaction. As an initial exploration, we implement Alpha-Service through a
multi-agent system deployed on AI glasses. Case studies, including a real-time
Blackjack advisor, a museum tour guide, and a shopping fit assistant,
demonstrate its ability to seamlessly perceive the environment, infer user
intent, and provide timely and useful assistance without explicit prompts.

</details>


### [131] [Can MLLMs Absorb Math Reasoning Abilities from LLMs as Free Lunch?](https://arxiv.org/abs/2510.14387)
*Yijie Hu,Zihao Zhou,Kaizhu Huang,Xiaowei Huang,Qiufeng Wang*

Main category: cs.AI

TL;DR: IP-Merging是一种无需调优的方法，通过识别和合并推理相关参数，提升MLLMs的数学推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态大语言模型（MLLMs）能否直接从现成的数学大语言模型（LLMs）中吸收数学推理能力，而无需调优。

Method: 提出IP-Merging方法，通过识别MLLM和数学LLM中的推理相关参数，将其投影到MLLM的子空间并合并。

Result: 实验证明IP-Merging方法能有效提升MLLMs的数学推理能力，且不影响其他功能。

Conclusion: IP-Merging方法成功提升了多模态大语言模型（MLLMs）的数学推理能力，且无需调优，同时保持了模型的其他功能。

Abstract: Math reasoning has been one crucial ability of large language models (LLMs),
where significant advancements have been achieved in recent years. However,
most efforts focus on LLMs by curating high-quality annotation data and
intricate training (or inference) paradigms, while the math reasoning
performance of multi-modal LLMs (MLLMs) remains lagging behind. Since the MLLM
typically consists of an LLM and a vision block, we wonder: Can MLLMs directly
absorb math reasoning abilities from off-the-shelf math LLMs without tuning?
Recent model-merging approaches may offer insights into this question. However,
they overlook the alignment between the MLLM and LLM, where we find that there
is a large gap between their parameter spaces, resulting in lower performance.
Our empirical evidence reveals two key factors behind this issue: the
identification of crucial reasoning-associated layers in the model and the
mitigation of the gaps in parameter space. Based on the empirical insights, we
propose IP-Merging that first identifies the reasoning-associated parameters in
both MLLM and Math LLM, then projects them into the subspace of MLLM, aiming to
maintain the alignment, and finally merges parameters in this subspace.
IP-Merging is a tuning-free approach since parameters are directly adjusted.
Extensive experiments demonstrate that our IP-Merging method can enhance the
math reasoning ability of MLLMs directly from Math LLMs without compromising
their other capabilities.

</details>


### [132] [Hi-Agent: Hierarchical Vision-Language Agents for Mobile Device Control](https://arxiv.org/abs/2510.14388)
*Zhe Wu,Hongjin Lu,Junliang Xing,Changhao Zhang,Yin Zhu,Yuhao Yang,Yuheng Jing,Kai Li,Kun Shao,Jianye Hao,Jun Wang,Yuanchun Shi*

Main category: cs.AI

TL;DR: Hi-Agent是一种分层视觉语言代理，通过联合优化高层推理和低层动作模型，显著提升了移动设备控制的任务成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的移动设备控制代理通常缺乏结构化推理和规划能力，导致在新任务或未见过的UI布局上泛化能力差。

Method: Hi-Agent采用分层设计，包括高层推理模型和低层动作模型，通过将多步决策重构为单步子目标序列，并引入前瞻优势函数来优化训练。

Result: Hi-Agent在Android-in-the-Wild基准测试中达到87.9%的任务成功率，显著优于现有方法，并在其他基准测试中展示了良好的泛化能力。

Conclusion: Hi-Agent在移动设备控制任务中表现出色，不仅达到了87.9%的任务成功率，还在零样本泛化能力上展现了竞争力，验证了其分层设计和联合优化方法的有效性。

Abstract: Building agents that autonomously operate mobile devices has attracted
increasing attention. While Vision-Language Models (VLMs) show promise, most
existing approaches rely on direct state-to-action mappings, which lack
structured reasoning and planning, and thus generalize poorly to novel tasks or
unseen UI layouts. We introduce Hi-Agent, a trainable hierarchical
vision-language agent for mobile control, featuring a high-level reasoning
model and a low-level action model that are jointly optimized. For efficient
training, we reformulate multi-step decision-making as a sequence of
single-step subgoals and propose a foresight advantage function, which
leverages execution feedback from the low-level model to guide high-level
optimization. This design alleviates the path explosion issue encountered by
Group Relative Policy Optimization (GRPO) in long-horizon tasks and enables
stable, critic-free joint training. Hi-Agent achieves a new State-Of-The-Art
(SOTA) 87.9% task success rate on the Android-in-the-Wild (AitW) benchmark,
significantly outperforming prior methods across three paradigms: prompt-based
(AppAgent: 17.7%), supervised (Filtered BC: 54.5%), and reinforcement
learning-based (DigiRL: 71.9%). It also demonstrates competitive zero-shot
generalization on the ScreenSpot-v2 benchmark. On the more challenging
AndroidWorld benchmark, Hi-Agent also scales effectively with larger backbones,
showing strong adaptability in high-complexity mobile control scenarios.

</details>


### [133] [IMAGINE: Integrating Multi-Agent System into One Model for Complex Reasoning and Planning](https://arxiv.org/abs/2510.14406)
*Xikai Zhang,Bo Wang,Likang Xiao,Yongzhi Li,Quan Chen,Wenju Wu,Liu Liu*

Main category: cs.AI

TL;DR: IMAGINE框架将多智能体系统的能力集成到单一模型中，显著提升复杂推理和规划性能，实验证明其效果远超传统方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多个任务上表现优异，但在复杂推理和规划方面仍面临挑战，如高推理成本和端到端训练困难。

Method: 提出了一个名为IMAGINE的通用可扩展框架，将多智能体系统的能力集成到一个单一模型中，并通过端到端训练提升性能。

Result: 实验结果表明，使用Qwen3-8B-Instruct作为基础模型并通过IMAGINE方法训练后，其在TravelPlanner基准测试中的最终通过率达到82.7%，远超DeepSeek-R1-671B的40%。

Conclusion: IMAGINE框架通过将多智能体系统的推理和规划能力集成到一个紧凑模型中，不仅显著超越了传统MAS的性能，还降低了推理成本和延迟。

Abstract: Although large language models (LLMs) have made significant strides across
various tasks, they still face significant challenges in complex reasoning and
planning. For example, even with carefully designed prompts and prior
information explicitly provided, GPT-4o achieves only a 7% Final Pass Rate on
the TravelPlanner dataset in the sole-planning mode. Similarly, even in the
thinking mode, Qwen3-8B-Instruct and DeepSeek-R1-671B, only achieve Final Pass
Rates of 5.9% and 40%, respectively. Although well-organized Multi-Agent
Systems (MAS) can offer improved collective reasoning, they often suffer from
high reasoning costs due to multi-round internal interactions, long
per-response latency, and difficulties in end-to-end training. To address these
challenges, we propose a general and scalable framework called IMAGINE, short
for Integrating Multi-Agent System into One Model. This framework not only
integrates the reasoning and planning capabilities of MAS into a single,
compact model, but also significantly surpass the capabilities of the MAS
through a simple end-to-end training. Through this pipeline, a single
small-scale model is not only able to acquire the structured reasoning and
planning capabilities of a well-organized MAS but can also significantly
outperform it. Experimental results demonstrate that, when using
Qwen3-8B-Instruct as the base model and training it with our method, the model
achieves an 82.7% Final Pass Rate on the TravelPlanner benchmark, far exceeding
the 40% of DeepSeek-R1-671B, while maintaining a much smaller model size.

</details>


### [134] [Eliminating Negative Occurrences of Derived Predicates from PDDL Axioms](https://arxiv.org/abs/2510.14412)
*Claudia Grundke,Gabriele Röger*

Main category: cs.AI

TL;DR: 本文通过转换方法证明PDDL中派生谓词负面出现的可消除性，表明标准限制与分层要求在表达能力上等价。


<details>
  <summary>Details</summary>
Motivation: 探讨PDDL标准中对派生谓词负面出现的限制，以及文献中对此限制的偏离，证明两者在表达能力上的等价性。

Method: 通过提出相应的转换方法，处理PDDL中派生谓词的负面出现。

Result: 证明了两种变体（PDDL标准限制和分层要求）可以表达相同的查询，即最小不动点逻辑。

Conclusion: 本文展示了如何消除PDDL中派生谓词的负面出现，证明这种转换的可行性。

Abstract: Axioms are a feature of the Planning Domain Definition Language PDDL that can
be considered as a generalization of database query languages such as Datalog.
The PDDL standard restricts negative occurrences of predicates in axiom bodies
to predicates that are directly set by actions and not derived by axioms. In
the literature, authors often deviate from this limitation and only require
that the set of axioms is stratifiable. Both variants can express exactly the
same queries as least fixed-point logic, indicating that negative occurrences
of derived predicates can be eliminated. We present the corresponding
transformation.

</details>


### [135] [Helmsman: Autonomous Synthesis of Federated Learning Systems via Multi-Agent Collaboration](https://arxiv.org/abs/2510.14512)
*Haoyuan Li,Mathias Funk,Aaqib Saeed*

Main category: cs.AI

TL;DR: Helmsman 是一个多智能体系统，自动化联邦学习系统的设计与部署，通过人工规划、代码生成和模拟评估优化，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在分布式数据训练模型方面具有潜力，但设计和部署鲁棒系统的复杂性成为瓶颈，导致解决方案脆弱且定制化。Helmsman 旨在自动化这一过程。

Method: Helmsman 是一种多智能体系统，通过三个阶段自动化联邦学习系统的端到端合成：交互式人工规划、模块化代码生成、以及沙盒模拟环境中的闭环评估与优化。

Result: 实验表明，Helmsman 生成的解决方案在性能上优于或与现有手工基线相当。

Conclusion: Helmsman 和 AgentFL-Bench 的引入标志着在自动化复杂分布式 AI 系统工程方面迈出了重要一步，生成的解决方案在性能上优于传统手工方法。

Abstract: Federated Learning (FL) offers a powerful paradigm for training models on
decentralized data, but its promise is often undermined by the immense
complexity of designing and deploying robust systems. The need to select,
combine, and tune strategies for multifaceted challenges like data
heterogeneity and system constraints has become a critical bottleneck,
resulting in brittle, bespoke solutions. To address this, we introduce
Helmsman, a novel multi-agent system that automates the end-to-end synthesis of
federated learning systems from high-level user specifications. It emulates a
principled research and development workflow through three collaborative
phases: (1) interactive human-in-the-loop planning to formulate a sound
research plan, (2) modular code generation by supervised agent teams, and (3) a
closed-loop of autonomous evaluation and refinement in a sandboxed simulation
environment. To facilitate rigorous evaluation, we also introduce
AgentFL-Bench, a new benchmark comprising 16 diverse tasks designed to assess
the system-level generation capabilities of agentic systems in FL. Extensive
experiments demonstrate that our approach generates solutions competitive with,
and often superior to, established hand-crafted baselines. Our work represents
a significant step towards the automated engineering of complex decentralized
AI systems.

</details>


### [136] [JSPLIT: A Taxonomy-based Solution for Prompt Bloating in Model Context Protocol](https://arxiv.org/abs/2510.14537)
*Emanuele Antonioni,Stefan Markovic,Anirudha Shankar,Jaime Bernardo,Lovro Markovic,Silvia Pareti,Benedetto Proietti*

Main category: cs.AI

TL;DR: JSPLIT是一个分层分类法驱动的框架，通过智能选择相关工具，有效解决提示词膨胀问题，降低成本并提升任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决由于工具数量增加导致的提示词膨胀问题，包括高token成本、延迟增加和任务成功率下降。

Method: JSPLIT通过分层分类法组织工具，并基于用户提示和分类结构选择最相关工具。

Result: JSPLIT显著减少了提示词大小，同时提高了工具选择的准确性。

Conclusion: JSPLIT框架有效减少了提示词膨胀问题，不仅降低了成本，还在高复杂性代理环境中提高了任务成功率。

Abstract: AI systems are continually evolving and advancing, and user expectations are
concurrently increasing, with a growing demand for interactions that go beyond
simple text-based interaction with Large Language Models (LLMs). Today's
applications often require LLMs to interact with external tools, marking a
shift toward more complex agentic systems. To support this, standards such as
the Model Context Protocol (MCP) have emerged, enabling agents to access tools
by including a specification of the capabilities of each tool within the
prompt. Although this approach expands what agents can do, it also introduces a
growing problem: prompt bloating. As the number of tools increases, the prompts
become longer, leading to high prompt token costs, increased latency, and
reduced task success resulting from the selection of tools irrelevant to the
prompt. To address this issue, we introduce JSPLIT, a taxonomy-driven framework
designed to help agents manage prompt size more effectively when using large
sets of MCP tools. JSPLIT organizes the tools into a hierarchical taxonomy and
uses the user's prompt to identify and include only the most relevant tools,
based on both the query and the taxonomy structure. In this paper, we describe
the design of the taxonomy, the tool selection algorithm, and the dataset used
to evaluate JSPLIT. Our results show that JSPLIT significantly reduces prompt
size without significantly compromising the agent's ability to respond
effectively. As the number of available tools for the agent grows
substantially, JSPLIT even improves the tool selection accuracy of the agent,
effectively reducing costs while simultaneously improving task success in
high-complexity agent environments.

</details>


### [137] [Symbol Grounding in Neuro-Symbolic AI: A Gentle Introduction to Reasoning Shortcuts](https://arxiv.org/abs/2510.14538)
*Emanuele Marconato,Samuele Bortolotti,Emile van Krieken,Paolo Morettin,Elena Umili,Antonio Vergari,Efthymia Tsamoura,Andrea Passerini,Stefano Teso*

Main category: cs.AI

TL;DR: 这篇综述总结了神经符号AI中的推理捷径问题，分析了其成因和影响，回顾了现有理论，并介绍了应对方法，旨在为研究人员提供统一的视角，促进可靠AI的发展。


<details>
  <summary>Details</summary>
Motivation: 神经符号AI（NeSy）虽然在实现可靠和可信赖AI方面具有巨大潜力，但存在推理捷径（RSs）问题，即模型可能在未直接监督概念的情况下错误地建立概念基础，从而影响模型的解释性、性能及可靠性。目前关于RSs的研究分散，难以理解和应对。

Method: 综述通过直觉性的讨论和理论分析，解释了RSs的成因和影响，并详细回顾了现有的理论表征。此外，还介绍了处理RSs的方法，包括缓解和意识策略，并评估了它们的优缺点。

Result: 综述提供了对RSs的直观介绍，分析了其成因和后果，回顾了现有理论表征，并详细介绍了处理RSs的方法及其优缺点。通过以易于理解的形式重新表述高级材料，为研究人员和实践者提供了统一的视角。

Conclusion: 这篇综述旨在为研究人员和实践者提供一个关于推理捷径（RSs）的统一视角，以降低解决这一问题的门槛，并最终促进可靠和可信赖的神经符号AI模型的发展。

Abstract: Neuro-symbolic (NeSy) AI aims to develop deep neural networks whose
predictions comply with prior knowledge encoding, e.g. safety or structural
constraints. As such, it represents one of the most promising avenues for
reliable and trustworthy AI. The core idea behind NeSy AI is to combine neural
and symbolic steps: neural networks are typically responsible for mapping
low-level inputs into high-level symbolic concepts, while symbolic reasoning
infers predictions compatible with the extracted concepts and the prior
knowledge. Despite their promise, it was recently shown that - whenever the
concepts are not supervised directly - NeSy models can be affected by Reasoning
Shortcuts (RSs). That is, they can achieve high label accuracy by grounding the
concepts incorrectly. RSs can compromise the interpretability of the model's
explanations, performance in out-of-distribution scenarios, and therefore
reliability. At the same time, RSs are difficult to detect and prevent unless
concept supervision is available, which is typically not the case. However, the
literature on RSs is scattered, making it difficult for researchers and
practitioners to understand and tackle this challenging problem. This overview
addresses this issue by providing a gentle introduction to RSs, discussing
their causes and consequences in intuitive terms. It also reviews and
elucidates existing theoretical characterizations of this phenomenon. Finally,
it details methods for dealing with RSs, including mitigation and awareness
strategies, and maps their benefits and limitations. By reformulating advanced
material in a digestible form, this overview aims to provide a unifying
perspective on RSs to lower the bar to entry for tackling them. Ultimately, we
hope this overview contributes to the development of reliable NeSy and
trustworthy AI models.

</details>


### [138] [LLM Agents Beyond Utility: An Open-Ended Perspective](https://arxiv.org/abs/2510.14548)
*Asen Nachkov,Xi Wang,Luc Van Gool*

Main category: cs.AI

TL;DR: 研究开放式LLM代理的能力，发现其能自主生成任务但存在局限性，未来需改进记忆管理和长期目标追求。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM代理是否能成为独立实体，具备规划、设计任务及推理模糊目标的能力。

Method: 采用开放式实验设置，增强预训练LLM代理的能力，使其能生成任务、积累知识并与环境交互。

Result: 代理能可靠执行复杂多步指令、跨运行存储重用信息，并自主提出和解决任务，但仍受限于提示设计、重复任务生成及缺乏自我表征能力。

Conclusion: 研究展示了预训练LLM在开放式任务中的潜力与当前限制，为未来训练代理管理记忆、探索和追求长期目标指明了方向。

Abstract: Recent LLM agents have made great use of chain of thought reasoning and
function calling. As their capabilities grow, an important question arises: can
this software represent not only a smart problem-solving tool, but an entity in
its own right, that can plan, design immediate tasks, and reason toward
broader, more ambiguous goals? To study this question, we adopt an open-ended
experimental setting where we augment a pretrained LLM agent with the ability
to generate its own tasks, accumulate knowledge, and interact extensively with
its environment. We study the resulting open-ended agent qualitatively. It can
reliably follow complex multi-step instructions, store and reuse information
across runs, and propose and solve its own tasks, though it remains sensitive
to prompt design, prone to repetitive task generation, and unable to form
self-representations. These findings illustrate both the promise and current
limits of adapting pretrained LLMs toward open-endedness, and point to future
directions for training agents to manage memory, explore productively, and
pursue abstract long-term goals.

</details>


### [139] [ColorBench: Benchmarking Mobile Agents with Graph-Structured Framework for Complex Long-Horizon Tasks](https://arxiv.org/abs/2510.14621)
*Yuanyi Song,Heyuan Huang,Qiqiang Lin,Yin Zhao,Xiangmou Qu,Jun Wang,Xingyu Lou,Weiwen Liu,Zhuosheng Zhang,Jun Wang,Yong Yu,Weinan Zhang,Zhaoxiang Wang*

Main category: cs.AI

TL;DR: 本文提出了一种图结构的基准框架ColorBench，用于评估移动代理在复杂长时任务中的表现，填补了离线与在线评估的鸿沟，并基于实验结果提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前移动代理评估标准存在不足：离线静态基准只能验证单一预定义的“黄金路径”，而在线动态测试受限于真实设备的复杂性和不可重现性，两者均无法全面评估代理能力。

Method: 本文提出了一种基于图结构的基准框架，通过模拟真实设备交互中的有限状态，实现了动态行为的静态模拟。在此基础上，开发了专注于复杂长时任务的ColorBench基准。

Result: ColorBench包含175个任务（74个单应用，101个跨应用），平均长度超过13步，每个任务至少包含两条正确路径和若干典型错误路径，支持准动态交互。通过在不同基线模型上评估ColorBench，发现了现有模型的局限性。

Conclusion: 本文通过引入ColorBench这一新型基准框架，填补了离线与在线评估之间的鸿沟，并通过实验揭示了现有模型的局限性，提出了改进方向和可行的技术路径。

Abstract: The rapid advancement of multimodal large language models has enabled agents
to operate mobile devices by directly interacting with graphical user
interfaces, opening new possibilities for mobile automation. However,
real-world mobile tasks are often complex and allow for multiple valid
solutions. This contradicts current mobile agent evaluation standards: offline
static benchmarks can only validate a single predefined "golden path", while
online dynamic testing is constrained by the complexity and non-reproducibility
of real devices, making both approaches inadequate for comprehensively
assessing agent capabilities. To bridge the gap between offline and online
evaluation and enhance testing stability, this paper introduces a novel
graph-structured benchmarking framework. By modeling the finite states observed
during real-device interactions, it achieves static simulation of dynamic
behaviors. Building on this, we develop ColorBench, a benchmark focused on
complex long-horizon tasks. It supports evaluation of multiple valid solutions,
subtask completion rate statistics, and atomic-level capability analysis.
ColorBench contains 175 tasks (74 single-app, 101 cross-app) with an average
length of over 13 steps. Each task includes at least two correct paths and
several typical error paths, enabling quasi-dynamic interaction. By evaluating
ColorBench across various baselines, we discover limitations of existing models
and propose improvement directions and feasible technical pathways to enhance
agents' performance on complex, long-horizon problems based on experimental
results. Code and data are available at:
https://github.com/MadeAgents/ColorBench.

</details>


### [140] [Beyond Hallucinations: The Illusion of Understanding in Large Language Models](https://arxiv.org/abs/2510.14665)
*Rikard Rosenbacke,Carl Rosenbacke,Victor Rosenbacke,Martin McKee*

Main category: cs.AI

TL;DR: 本文提出Rose-Frame框架，通过三个维度诊断LLMs的认知漂移，旨在实现更透明和批判性意识强的AI部署。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）虽然输出流畅且情感共鸣强，但缺乏事实基础，存在幻觉风险。本文旨在通过框架解决这一问题。

Method: 本文提出了Rose-Frame，一个三维框架，用于诊断人机交互中的认知和认知漂移，包括三个维度：地图与领土、直觉与理性、冲突与确认。

Result: Rose-Frame框架能够有效诊断和放大LLMs与人类认知之间的不匹配，提供了一种认知治理的方法。

Conclusion: 通过引入Rose-Frame框架，本文提出了一种反思性工具，旨在使AI模型的局限性和用户假设透明化，从而实现更透明和批判性意识强的AI部署。

Abstract: Large language models (LLMs) are becoming deeply embedded in human
communication and decision-making, yet they inherit the ambiguity, bias, and
lack of direct access to truth inherent in language itself. While their outputs
are fluent, emotionally resonant, and coherent, they are generated through
statistical prediction rather than grounded reasoning. This creates the risk of
hallucination, responses that sound convincing but lack factual validity.
Building on Geoffrey Hinton's observation that AI mirrors human intuition
rather than reasoning, this paper argues that LLMs operationalize System 1
cognition at scale: fast, associative, and persuasive, but without reflection
or falsification. To address this, we introduce the Rose-Frame, a
three-dimensional framework for diagnosing cognitive and epistemic drift in
human-AI interaction. The three axes are: (i) Map vs. Territory, which
distinguishes representations of reality (epistemology) from reality itself
(ontology); (ii) Intuition vs. Reason, drawing on dual-process theory to
separate fast, emotional judgments from slow, reflective thinking; and (iii)
Conflict vs. Confirmation, which examines whether ideas are critically tested
through disagreement or simply reinforced through mutual validation. Each
dimension captures a distinct failure mode, and their combination amplifies
misalignment. Rose-Frame does not attempt to fix LLMs with more data or rules.
Instead, it offers a reflective tool that makes both the model's limitations
and the user's assumptions visible, enabling more transparent and critically
aware AI deployment. It reframes alignment as cognitive governance: intuition,
whether human or artificial, must remain governed by human reason. Only by
embedding reflective, falsifiable oversight can we align machine fluency with
human understanding.

</details>


### [141] [Machine Learning and Public Health: Identifying and Mitigating Algorithmic Bias through a Systematic Review](https://arxiv.org/abs/2510.14669)
*Sara Altamirano,Arjan Vreeken,Sennay Ghebreab*

Main category: cs.AI

TL;DR: 论文提出了一种评估和解决机器学习在公共卫生研究中算法偏差的工具和框架，强调了公平性和透明度的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管机器学习在公共卫生领域有巨大潜力，但缺乏对算法偏差的系统关注可能导致现有健康差距的加剧。

Method: 通过整合Cochrane Risk of Bias、PROBAST和Microsoft Responsible AI checklist等框架，开发了风险算法偏差评估工具（RABAT），并应用于35篇同行评审研究。

Result: 分析揭示了普遍存在的差距：大多数研究缺乏明确的公平框架、亚组分析和潜在危害的透明讨论。

Conclusion: 论文提出了一个四阶段的公平导向框架ACAR（Awareness, Conceptualization, Application, Reporting），并提供了可操作的建议，以确保机器学习在公共卫生领域的创新能够促进健康公平而非加剧不平等。

Abstract: Machine learning (ML) promises to revolutionize public health through
improved surveillance, risk stratification, and resource allocation. However,
without systematic attention to algorithmic bias, ML may inadvertently
reinforce existing health disparities. We present a systematic literature
review of algorithmic bias identification, discussion, and reporting in Dutch
public health ML research from 2021 to 2025. To this end, we developed the Risk
of Algorithmic Bias Assessment Tool (RABAT) by integrating elements from
established frameworks (Cochrane Risk of Bias, PROBAST, Microsoft Responsible
AI checklist) and applied it to 35 peer-reviewed studies. Our analysis reveals
pervasive gaps: although data sampling and missing data practices are well
documented, most studies omit explicit fairness framing, subgroup analyses, and
transparent discussion of potential harms. In response, we introduce a
four-stage fairness-oriented framework called ACAR (Awareness,
Conceptualization, Application, Reporting), with guiding questions derived from
our systematic literature review to help researchers address fairness across
the ML lifecycle. We conclude with actionable recommendations for public health
ML practitioners to consistently consider algorithmic bias and foster
transparency, ensuring that algorithmic innovations advance health equity
rather than undermine it.

</details>


### [142] [TITAN: Graph-Executable Reasoning for Cyber Threat Intelligence](https://arxiv.org/abs/2510.14670)
*Marco Simoni,Aleksandar Fontana,Andrea Saracino,Paolo Mori*

Main category: cs.AI

TL;DR: TITAN是一个结合自然语言查询与知识图谱推理的框架，通过路径规划模型和图执行器自动化处理网络威胁情报，实证评估显示其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统检索系统无法清晰、可逆地在威胁、行为和防御之间进行推理，因此需要一种能够自动化处理自然语言查询并执行结构化推理的框架。

Method: TITAN集成了路径规划模型（预测文本中的逻辑关系链）和图执行器（遍历TITAN本体以检索事实答案和支持证据），并基于MITRE构建了一个双向类型化知识图谱。

Result: TITAN数据集包含88209个示例（训练集74258，测试集13951），评估显示TITAN能够生成语法有效且语义连贯的推理路径。

Conclusion: TITAN框架通过自然语言查询与结构化知识图谱的可执行推理相结合，有效提升了网络威胁情报的自动化处理能力，并通过实证评估验证了其生成语法有效、语义连贯的推理路径的能力。

Abstract: TITAN (Threat Intelligence Through Automated Navigation) is a framework that
connects natural-language cyber threat queries with executable reasoning over a
structured knowledge graph. It integrates a path planner model, which predicts
logical relation chains from text, and a graph executor that traverses the
TITAN Ontology to retrieve factual answers and supporting evidence. Unlike
traditional retrieval systems, TITAN operates on a typed, bidirectional graph
derived from MITRE, allowing reasoning to move clearly and reversibly between
threats, behaviors, and defenses. To support training and evaluation, we
introduce the TITAN Dataset, a corpus of 88209 examples (Train: 74258; Test:
13951) pairing natural language questions with executable reasoning paths and
step by step Chain of Thought explanations. Empirical evaluations show that
TITAN enables models to generate syntactically valid and semantically coherent
reasoning paths that can be deterministically executed on the underlying graph.

</details>


### [143] [NAEL: Non-Anthropocentric Ethical Logic](https://arxiv.org/abs/2510.14676)
*Bianca Maria Lerma,Rafael Peñaloza*

Main category: cs.AI

TL;DR: NAEL是一种基于主动推理和符号推理的新型伦理框架，旨在为非人类中心的人工智能系统提供自适应、情境敏感的伦理行为模型。


<details>
  <summary>Details</summary>
Motivation: 传统以人类为中心的AI伦理方法存在局限，NAEL旨在通过形式化伦理行为为智能系统在最小化全局预期自由能时的涌现属性，解决这一问题。

Method: 提出了一种神经符号架构，使智能体能在不确定环境中评估其行为的伦理后果。

Result: 案例研究表明，NAEL能动态平衡自我保存、认知学习和集体福利。

Conclusion: NAEL 提供了一种新型的非人类中心主义伦理框架，通过结合主动推理和符号推理，使人工智能系统能在动态多智能体环境中发展出自适应、情境敏感的伦理行为。

Abstract: We introduce NAEL (Non-Anthropocentric Ethical Logic), a novel ethical
framework for artificial agents grounded in active inference and symbolic
reasoning. Departing from conventional, human-centred approaches to AI ethics,
NAEL formalizes ethical behaviour as an emergent property of intelligent
systems minimizing global expected free energy in dynamic, multi-agent
environments. We propose a neuro-symbolic architecture to allow agents to
evaluate the ethical consequences of their actions in uncertain settings. The
proposed system addresses the limitations of existing ethical models by
allowing agents to develop context-sensitive, adaptive, and relational ethical
behaviour without presupposing anthropomorphic moral intuitions. A case study
involving ethical resource distribution illustrates NAEL's dynamic balancing of
self-preservation, epistemic learning, and collective welfare.

</details>


### [144] [Practical, Utilitarian Algorithm Configuration](https://arxiv.org/abs/2510.14683)
*Devon Graham,Kevin Leyton-Brown*

Main category: cs.AI

TL;DR: 本文改进了COUP算法配置程序，使其在保持理论优势的同时，实际性能与无性能保证的启发式方法相当。


<details>
  <summary>Details</summary>
Motivation: COUP作为一种功利性算法配置程序，主要关注其理论保证，而忽视了实际性能。本文旨在弥补这一差距，使其在实际应用中更具竞争力。

Method: 提出了一系列改进COUP的方法，以提升其经验性能而不损害其理论保证，并通过实验验证了这些改进的益处。

Result: 改进后的COUP在保持理论保证的同时，显著提升了其经验性能，并在案例研究中展示了其对效用函数变化的鲁棒性。

Conclusion: 本文通过一系列改进使COUP在实际性能上达到与广泛使用的启发式配置程序相当的水平，同时保持其理论保证。

Abstract: Utilitarian algorithm configuration identifies a parameter setting for a
given algorithm that maximizes a user's utility. Utility functions offer a
theoretically well-grounded approach to optimizing decision-making under
uncertainty and are flexible enough to capture a user's preferences over
algorithm runtimes (e.g., they can describe a sharp cutoff after which a
solution is no longer required, a per-hour cost for compute, or diminishing
returns from algorithms that take longer to run). COUP is a recently-introduced
utilitarian algorithm configuration procedure which was designed mainly to
offer strong theoretical guarantees about the quality of the configuration it
returns, with less attention paid to its practical performance. This paper
closes that gap, bringing theoretically-grounded, utilitarian algorithm
configuration to the point where it is competitive with widely used, heuristic
configuration procedures that offer no performance guarantees. We present a
series of improvements to COUP that improve its empirical performance without
degrading its theoretical guarantees and demonstrate their benefit
experimentally. Using a case study, we also illustrate ways of exploring the
robustness of a given solution to the algorithm selection problem to variations
in the utility function.

</details>


### [145] [Purifying Task Vectors in Knowledge-Aware Subspace for Model Merging](https://arxiv.org/abs/2510.14697)
*Bang An,Yibo Yang,Philip Torr,Bernard Ghanem*

Main category: cs.AI

TL;DR: PAVE提出了一种在知识感知子空间中净化任务向量的方法，通过上下文导向的奇异值分解和谱秩分配策略，有效减少任务无关冗余，提升模型合并性能。


<details>
  <summary>Details</summary>
Motivation: 现有的模型合并方法中，任务向量常因任务无关的冗余导致性能显著下降，而现有方法通过随机丢弃参数空间中的元素来克服冗余，缺乏知识感知。

Method: 通过从每个任务中采样训练示例，输入到对应的微调模型中获取线性层前的协方差矩阵，然后进行上下文导向的奇异值分解，突出与目标知识最相关的权重成分，从而将微调模型权重分为任务相关和冗余成分。

Result: PAVE能够有效净化任务向量，提升合并模型的性能，实验验证了其在多种合并方法、任务和模型架构中的有效性。

Conclusion: PAVE作为一种即插即用的方案，适用于各种基于任务向量的合并方法，能够有效提升性能。实验结果表明，PAVE在多种合并方法、任务和模型架构中均表现出色。

Abstract: Model merging aims to integrate task-specific abilities from individually
fine-tuned models into a single model without extra training. In recent model
merging methods, task vector has become a fundamental building block, as it can
encapsulate the residual information from finetuning. However, the merged model
often suffers from notable performance degradation due to the conflicts caused
by task-irrelevant redundancy in task vectors. Existing efforts in overcoming
redundancy by randomly dropping elements in the parameter space involves
randomness and lacks knowledge awareness. To address these challenges, in this
study, we propose Purifying TAsk Vectors (PAVE) in knowledge-aware subspace.
Concretely, we sample some training examples from each task, and feed them into
their corresponding fine-tuned models to acquire the covariance matrices before
linear layers. We then perform a context-oriented singular value decomposition,
which accentuates the weight components most relevant to the target knowledge.
As a result, we can split fine-tuned model weights into task-relevant and
redundant components in the knowledge-aware subspace, and purify the task
vector by pruning the redundant components. To induce fair pruning efforts
across models, we further introduce a spectral rank allocation strategy by
optimizing a normalized activated pruning error. The task vector purification
by our method as a plug-and-play scheme is applicable across various task
vector-based merging methods to improve their performance. In experiments, we
demonstrate the effectiveness of PAVE across a diverse set of merging methods,
tasks, and model architectures.

</details>


### [146] [ExoPredicator: Learning Abstract Models of Dynamic Worlds for Robot Planning](https://arxiv.org/abs/2509.26255)
*Yichao Liang,Dat Nguyen,Cambridge Yang,Tianyang Li,Joshua B. Tenenbaum,Carl Edward Rasmussen,Adrian Weller,Zenna Tavares,Tom Silver,Kevin Ellis*

Main category: cs.AI

TL;DR: 提出一种联合学习符号化状态和因果过程的框架，有效处理长时程规划中的外生机制问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决长时程规划中因外生机制（如水温变化、多米诺骨牌效应）与智能体动作同时发生而带来的挑战。

Method: 通过变分贝叶斯推理结合LLM提议，从有限数据中学习抽象世界模型，包括符号化状态表示和因果过程。

Result: 在五个模拟桌面机器人环境中，学习到的模型能够快速规划，并推广到具有更多对象和更复杂目标的保留任务中，优于多个基线。

Conclusion: 提出的框架通过学习符号化状态表示和因果过程，能够有效处理长时程规划中的外生机制问题，并在多个模拟环境中表现出优于基线的性能。

Abstract: Long-horizon embodied planning is challenging because the world does not only
change through an agent's actions: exogenous processes (e.g., water heating,
dominoes cascading) unfold concurrently with the agent's actions. We propose a
framework for abstract world models that jointly learns (i) symbolic state
representations and (ii) causal processes for both endogenous actions and
exogenous mechanisms. Each causal process models the time course of a
stochastic cause-effect relation. We learn these world models from limited data
via variational Bayesian inference combined with LLM proposals. Across five
simulated tabletop robotics environments, the learned models enable fast
planning that generalizes to held-out tasks with more objects and more complex
goals, outperforming a range of baselines.

</details>


### [147] [Cognitive-Aligned Spatio-Temporal Large Language Models For Next Point-of-Interest Prediction](https://arxiv.org/abs/2510.14702)
*Penglong Zhai,Jie Li,Fanyi Di,Yue Liu,Yifang Yuan,Jie Huang,Peng Wu,Sicong Wang,Mingyang Yin,Tingting Hu,Yao Xu,Xin Li*

Main category: cs.AI

TL;DR: CoAST是一个结合世界知识和时空轨迹的LLM框架，通过两阶段方法提升POI推荐性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM在POI推荐任务中缺乏对结构化地理实体和时序移动模式的理解，且未能充分融入世界知识和人类认知对齐。

Method: CoAST采用两阶段方法：1) 通过继续预训练获取推荐知识；2) 通过监督微调和强化学习阶段实现认知对齐。

Result: 在多个真实数据集和AMAP App的在线实验中，CoAST表现出色。

Conclusion: CoAST框架通过结合世界知识、时空轨迹模式和用户情境信息，显著提升了POI推荐任务的性能，并在实际应用中验证了其有效性。

Abstract: The next point-of-interest (POI) recommendation task aims to predict the
users' immediate next destinations based on their preferences and historical
check-ins, holding significant value in location-based services. Recently,
large language models (LLMs) have shown great potential in recommender systems,
which treat the next POI prediction in a generative manner. However, these
LLMs, pretrained primarily on vast corpora of unstructured text, lack the
native understanding of structured geographical entities and sequential
mobility patterns required for next POI prediction tasks. Moreover, in
industrial-scale POI prediction applications, incorporating world knowledge and
alignment of human cognition, such as seasons, weather conditions, holidays,
and users' profiles (such as habits, occupation, and preferences), can enhance
the user experience while improving recommendation performance. To address
these issues, we propose CoAST (Cognitive-Aligned Spatial-Temporal LLMs), a
framework employing natural language as an interface, allowing for the
incorporation of world knowledge, spatio-temporal trajectory patterns,
profiles, and situational information. Specifically, CoAST mainly comprises of
2 stages: (1) Recommendation Knowledge Acquisition through continued
pretraining on the enriched spatial-temporal trajectory data of the
desensitized users; (2) Cognitive Alignment to align cognitive judgments with
human preferences using enriched training data through Supervised Fine-Tuning
(SFT) and a subsequent Reinforcement Learning (RL) phase. Extensive offline
experiments on various real-world datasets and online experiments deployed in
"Guess Where You Go" of AMAP App homepage demonstrate the effectiveness of
CoAST.

</details>


### [148] [ToolPRM: Fine-Grained Inference Scaling of Structured Outputs for Function Calling](https://arxiv.org/abs/2510.14703)
*Jianghao Lin,Yuanyuan Shi,Xin Peng,Renjie Ding,Hairui Wang,Yuxuan Peng,Bizhe Bai,Weixi Song,Fengshuo Bai,Huacan Chai,Weinan Zhang,Fei Huang,Ying Wen*

Main category: cs.AI

TL;DR: 研究提出了一种结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，有效提升了结构化函数调用的性能，并揭示了'多探索少保留'的关键原则。


<details>
  <summary>Details</summary>
Motivation: 当前推理扩展研究主要集中于非结构化输出生成任务，而在像函数调用这样的结构化输出中的应用尚未充分探索。

Method: 提出了一个结合细粒度波束搜索和过程奖励模型ToolPRM的推理扩展框架，ToolPRM用于评分每个函数调用的内部步骤。

Result: ToolPRM在预测准确性上优于粗粒度和结果奖励模型，显著提升了基础模型在各种函数调用任务和基准测试中的性能。

Conclusion: 研究提出了一个关键原则，即在结构化输出中应用推理扩展技术时应遵循'多探索少保留'的策略，以适应结构化函数调用的不可恢复性特点。

Abstract: Large language models (LLMs) are increasingly demonstrating strong
capabilities as autonomous agents, with function calling serving as a core
mechanism for interaction with the environment. Meanwhile, inference scaling
has become a cutting-edge technique to enhance LLM performance by allocating
more computational resources during the inference process. However, current
research on inference scaling primarily focuses on unstructured output
generation tasks, leaving its application in structured outputs, like function
calling, largely underexplored. To bridge this gap, we propose an inference
scaling framework that combines fine-grained beam search with a process reward
model, ToolPRM, which scores the internal steps of each single function call.
To train ToolPRM, we construct the first fine-grained intra-call process
supervision dataset, automatically annotated with function-masking techniques
to provide step-level rewards for structured tool-use reasoning. Extensive
experiments demonstrate that ToolPRM beats the coarse-grained and outcome
reward models in terms of predictive accuracy, indicating its stronger
capability in supervising the function calling inference process. Inference
scaling technique equipped with ToolPRM also significantly improves the
backbone model performance across various function calling tasks and
benchmarks. More importantly, we reveal a key principle for applying inference
scaling techniques to structured outputs: "explore more but retain less" due to
the unrecoverability characteristics of structured function calling generation.

</details>


### [149] [SimKO: Simple Pass@K Policy Optimization](https://arxiv.org/abs/2510.14807)
*Ruotian Peng,Yi Ren,Zhouliang Yu,Weiyang Liu,Yandong Wen*

Main category: cs.AI

TL;DR: SimKO通过不对称设计缓解RLVR中的概率集中问题，显著提升pass@K性能。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法存在系统性偏向于利用而非探索的问题，表现为pass@1提升但pass@K（K>1）下降。研究发现这是由于令牌级概率分布中top-1候选概率过度集中所致。

Method: 提出了Simple Pass@K Optimization (SimKO)方法，通过对已验证正确和错误的响应采取不对称处理，特别是针对高熵令牌，以缓解概率集中效应。

Result: SimKO在各种数学和逻辑推理基准测试中均显著提高了pass@K性能，证明了其有效性。

Conclusion: SimKO通过不对称设计有效缓解了RLVR方法中的过度集中问题，显著提高了pass@K性能，为增强RLVR的探索能力提供了简单而有效的方法。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has advanced the
reasoning capabilities of large language models (LLMs). However, prevailing
RLVR methods exhibit a systematic bias toward exploitation over exploration, as
evidenced by improved pass@1 but reduced pass@K (K>1) performance. To
understand this issue, we analyze training dynamics of RLVR methods by tracking
the token-level probability distributions over vocabulary candidates. Our
analysis reveals a consistent probability concentration effect where the top-1
candidate increasingly accumulates probability mass and suppresses that of
other candidates. More importantly, stronger over-concentration correlates with
worse pass@K performance. Inspired by this finding, we propose Simple Pass@K
Optimization (SimKO), a method designed to mitigate the over-concentration
issue, thereby encouraging exploration. SimKO operates in an asymmetrical
manner. For verified-correct responses, it boosts the probabilities of the
top-K candidates. For verified-incorrect responses, it applies stronger
penalties to the top-1 candidate. We observe that this asymmetric design is
particularly effective at mitigating over-concentration when applied at tokens
with high entropy. Across various math and logical-reasoning benchmarks, SimKO
consistently yields higher pass@K for a wide range of K, providing a simple way
to improve RLVR's exploration.

</details>


### [150] [RoboGPT-R1: Enhancing Robot Planning with Reinforcement Learning](https://arxiv.org/abs/2510.14828)
*Jinrui Liu,Bingyan Nie,Boyu Li,Yaran Chen,Yuze Wang,Shunsen He,Haoran Li*

Main category: cs.AI

TL;DR: RoboGPT-R1通过两阶段微调提升机器人长视野任务推理能力，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督微调的大型语言和视觉语言模型在复杂现实环境中的长视野操作任务表现不佳，缺乏常识和推理能力。

Method: 提出了RoboGPT-R1两阶段微调框架，结合监督训练和强化学习，并设计了基于规则的奖励函数。

Result: 在EmbodiedBench基准测试中，RoboGPT-R1显著优于GPT-4o-mini和其他基于Qwen2.5-VL-7B的模型。

Conclusion: RoboGPT-R1框架通过两阶段微调显著提升了机器人在长视野操作任务中的推理能力，超越了现有大型模型的表现。

Abstract: Improving the reasoning capabilities of embodied agents is crucial for robots
to complete complex human instructions in long-view manipulation tasks
successfully. Despite the success of large language models and vision language
models based on Supervised Fine-Tuning (SFT) in planning tasks, they continue
facing challenges in performing long-horizon manipulation tasks in complex
real-world environments, owing to their restricted common sense and reasoning
capabilities. Considering that aligning general-purpose vision language models
to robotic planning tasks via supervised fine-tuning suffers from poor
generalization and insufficient physical understanding, we propose RoboGPT-R1,
a two-stage fine-tuning framework for embodied planning. In this framework,
supervised training acquires foundational knowledge through expert sequences,
followed by RL to address the model's shortcomings in visual-spatial
understanding and reasoning. To achieve physical understanding and action
sequence consistency in multi-step reasoning tasks, we design a rule-based
reward function that simultaneously considers long-horizon performance and
action constraint in the environment. The reasoning model, trained on
Qwen2.5-VL-3B, significantly outperforms the larger-scale model, GPT-4o-mini,
by 21.33% and surpasses other work trained on Qwen2.5-VL-7B by 20.33% on the
EmbodiedBench benchmark.

</details>


### [151] [Agentic NL2SQL to Reduce Computational Costs](https://arxiv.org/abs/2510.14808)
*Dominik Jehle,Lennart Purucker,Frank Hutter*

Main category: cs.AI

TL;DR: Datalake Agent通过交互式循环优化NL2SQL任务，减少LLM的token消耗87%，降低成本同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 处理大量SQL数据库的元信息导致提示过长、处理成本高，需提升NL2SQL任务的效率。

Method: 引入Datalake Agent，采用交互式循环和选择性信息请求的推理框架，替代传统的直接求解器方法。

Result: 在23个数据库和100个表问答任务上评估，Datalake Agent显著减少token使用且性能稳定。

Conclusion: Datalake Agent通过交互式循环减少元信息使用，显著降低LLM的token消耗（高达87%）并保持竞争性能。

Abstract: Translating natural language queries into SQL queries (NL2SQL or Text-to-SQL)
has recently been empowered by large language models (LLMs). Using LLMs to
perform NL2SQL methods on a large collection of SQL databases necessitates
processing large quantities of meta-information about the databases, which in
turn results in lengthy prompts with many tokens and high processing costs. To
address this challenge, we introduce Datalake Agent, an agentic system designed
to enable an LLM to solve NL2SQL tasks more efficiently. Instead of utilizing
direct solvers for NL2SQL that call the LLM once with all meta-information in
the prompt, the Datalake Agent employs an interactive loop to reduce the
utilized meta-information. Within the loop, the LLM is used in a reasoning
framework that selectively requests only the necessary information to solve a
table question answering task. We evaluate the Datalake Agent on a collection
of 23 databases with 100 table question answering tasks. The Datalake Agent
reduces the tokens used by the LLM by up to 87\% and thus allows for
substantial cost reductions while maintaining competitive performance.

</details>


### [152] [Boosting Instruction Following at Scale](https://arxiv.org/abs/2510.14842)
*Ben Elder,Evelyn Duesterwald,Vinod Muthusamy*

Main category: cs.AI

TL;DR: 提出Instruction Boosting方法，通过后生成处理提高LLM指令遵循率，并量化分析多指令冲突的影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如修改提示指令）无法确保LLM实际遵循指令，需一种更可靠的方法来提高指令遵循率。

Method: 通过引入Instruction Boosting方法，并开发SCALEDIF基准（包含最多十条指令的数据样本），量化分析指令冲突对性能的影响。

Result: Instruction Boosting将指令遵循率提升最多7个点（两条指令）和4个点（十条指令）。冲突评分工具解释了性能下降趋势。

Conclusion: Instruction Boosting是一种有效的后生成方法，能显著提高LLM对指令的遵循率，尤其在处理多指令时表现突出。此外，提出的冲突评分工具为开发者提供了量化反馈，帮助优化指令设计。

Abstract: A typical approach developers follow to influence an LLM's behavior in an
application is through careful manipulation of the prompt, such as by adding or
modifying instructions. However, merely adding more instructions provides
little assurance that they will actually be followed. We introduce Instruction
Boosting as a post-generation method to increase the reliability of LLM prompt
instructions. We show that Instruction Boosting improves the instruction
following rate by up to 7 points for two instructions and up to 4 points for
ten instructions. To demonstrate these results we introduce SCALEDIF, a
benchmark with a scaled instruction volume of up to ten instructions per data
sample. We also present an analysis of the commonly observed trend that
performance degrades as more instructions are added. We show that an important
factor contributing to this trend is the degree of tension and conflict that
arises as the number of instructions is increased. We contribute a quantitative
conflict scoring tool that explains the observed performance trends and
provides feedback to developers on the impact that additional prompt
instructions have on a model's performance.

</details>


### [153] [Where to Search: Measure the Prior-Structured Search Space of LLM Agents](https://arxiv.org/abs/2510.14846)
*Zhuo-Yang Song*

Main category: cs.AI

TL;DR: 该论文提出了一种形式化理论，用于描述和测量LLM辅助的迭代搜索，通过模糊关系操作符和覆盖生成函数来衡量搜索空间和代理性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基于LLM的生成-过滤-精炼迭代范式在推理、编程和程序发现方面取得了进展，但搜索的有效性仍依赖于如何将领域先验编码为操作结构化的假设空间。

Method: 通过将代理表示为输入和输出上的模糊关系操作符来捕捉可行转换，并进一步通过单延续参数加权所有可达路径，求和得到覆盖生成函数，从而诱导出可达性难度度量。

Result: 理论提供了搜索图上的几何解释，并通过多数投票实例验证了最简单的可测试推断。

Conclusion: 该论文提出了一个紧凑的形式理论，用于描述和测量由领域先验引导的LLM辅助迭代搜索，为衡量代理及其搜索空间提供了可操作的语言和工具。

Abstract: The generate-filter-refine (iterative paradigm) based on large language
models (LLMs) has achieved progress in reasoning, programming, and program
discovery in AI+Science. However, the effectiveness of search depends on where
to search, namely, how to encode the domain prior into an operationally
structured hypothesis space. To this end, this paper proposes a compact formal
theory that describes and measures LLM-assisted iterative search guided by
domain priors. We represent an agent as a fuzzy relation operator on inputs and
outputs to capture feasible transitions; the agent is thereby constrained by a
fixed safety envelope. To describe multi-step reasoning/search, we weight all
reachable paths by a single continuation parameter and sum them to obtain a
coverage generating function; this induces a measure of reachability
difficulty; and it provides a geometric interpretation of search on the graph
induced by the safety envelope. We further provide the simplest testable
inferences and validate them via a majority-vote instantiation. This theory
offers a workable language and operational tools to measure agents and their
search spaces, proposing a systematic formal description of iterative search
constructed by LLMs.

</details>


### [154] [LabOS: The AI-XR Co-Scientist That Sees and Works With Humans](https://arxiv.org/abs/2510.14861)
*Le Cong,Zaixi Zhang,Xiaotong Wang,Yin Di,Ruofan Jin,Michal Gerasimiuk,Yinkai Wang,Ravi K. Dinesh,David Smerkous,Alex Smerkous,Xuekun Wu,Shilong Liu,Peishan Li,Yi Zhu,Simran Serrao,Ning Zhao,Imran A. Mohammad,John B. Sunwoo,Joseph C. Wu,Mengdi Wang*

Main category: cs.AI

TL;DR: LabOS是首个结合计算推理与物理实验的AI共科学家系统，通过多模态感知和XR技术实现人机协作，加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 现代科学发展最快的方式是思想与行动的结合。LabOS旨在通过AI与物理实验的结合，加速科学发现。

Method: 通过结合多模态感知、自进化代理和扩展现实（XR）技术，LabOS连接多模型AI代理、智能眼镜和人类-AI协作，实现AI实时理解实验环境并协助执行。

Result: LabOS在癌症免疫治疗靶点发现和干细胞工程等应用中，展示了AI能够有效参与实验过程。

Conclusion: LabOS展示了AI如何超越计算设计，直接参与实验室工作，将实验室转变为智能、协作的环境，促进人类与机器共同发现。

Abstract: Modern science advances fastest when thought meets action. LabOS represents
the first AI co-scientist that unites computational reasoning with physical
experimentation through multimodal perception, self-evolving agents, and
Entended-Reality(XR)-enabled human-AI collaboration. By connecting multi-model
AI agents, smart glasses, and human-AI collaboration, LabOS allows AI to see
what scientists see, understand experimental context, and assist in real-time
execution. Across applications--from cancer immunotherapy target discovery to
stem-cell engineering -- LabOS shows that AI can move beyond computational
design to participation, turning the laboratory into an intelligent,
collaborative environment where human and machine discovery evolve together.

</details>


### [155] [The Gatekeeper Knows Enough](https://arxiv.org/abs/2510.14881)
*Fikresilase Wondmeneh Abebayew*

Main category: cs.AI

TL;DR: Gatekeeper Protocol通过低保真潜在状态操作和统一的JSON格式调解，解决了LLMs作为自主代理时的上下文限制和状态不同步问题，显著提升了代理的可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）作为自主代理部署时，受限于有限的上下文窗口和状态不同步，导致不可靠的输出、不可预测的行为和低效的资源使用，特别是在与大型、结构化和敏感知识系统（如代码库和文档）交互时。

Method: 引入了Gatekeeper Protocol，要求代理首先在低保真的“潜在状态”表示上进行操作和推理，按需战略性地请求高保真上下文，并通过统一的JSON格式作为声明性、状态同步的协议来调解所有交互。

Result: 通过Sage（Gatekeeper Protocol的参考实现）展示了该协议的有效性，结果表明该方法显著提高了代理的可靠性，通过最小化令牌消耗提高了计算效率，并实现了与复杂系统的可扩展交互。

Conclusion: Gatekeeper Protocol 提供了一种新颖的、领域无关的框架，显著提升了AI代理的可靠性、计算效率和可扩展性，为构建更稳健、可预测和基于现实的AI代理奠定了基础。

Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents,
yet their practical utility is fundamentally constrained by a limited context
window and state desynchronization resulting from the LLMs' stateless nature
and inefficient context management. These limitations lead to unreliable
output, unpredictable behavior, and inefficient resource usage, particularly
when interacting with large, structured, and sensitive knowledge systems such
as codebases and documents. To address these challenges, we introduce the
Gatekeeper Protocol, a novel, domain-agnostic framework that governs
agent-system interactions. Our protocol mandates that the agent first operate
and reason on a minimalist, low-fidelity "latent state" representation of the
system to strategically request high-fidelity context on demand. All
interactions are mediated through a unified JSON format that serves as a
declarative, state-synchronized protocol, ensuring the agent's model of the
system remains verifiably grounded in the system's reality. We demonstrate the
efficacy of this protocol with Sage, a reference implementation of the
Gatekeeper Protocol for software development. Our results show that this
approach significantly increases agent reliability, improves computational
efficiency by minimizing token consumption, and enables scalable interaction
with complex systems, creating a foundational methodology for building more
robust, predictable, and grounded AI agents for any structured knowledge
domain.

</details>


### [156] [Mapping Smarter, Not Harder: A Test-Time Reinforcement Learning Agent That Improves Without Labels or Model Updates](https://arxiv.org/abs/2510.14900)
*Wen-Kwang Tsao,Yao-Ching Yu,Chien-Ming Huang*

Main category: cs.AI

TL;DR: 论文提出了一种强化学习代理，通过自我改进解决日志文档不可用导致的模式映射问题，显著提高了映射准确率并减少专家干预。


<details>
  <summary>Details</summary>
Motivation: 第三方供应商的日志文档在测试时经常不可用，导致模式映射困难。

Method: 引入了一种无需标记示例或模型权重更新的强化学习代理，能够在推理时识别模糊的字段映射尝试、生成针对性的网络搜索查询以收集外部证据，并应用基于置信度的奖励来迭代优化其映射。

Result: 使用GPT-4o在100次迭代后，映射准确率从56.4%（仅LLM）提高到72.73%（RAG）再到93.94%，同时将需要专家审查的低置信度映射数量减少了85%。

Conclusion: 该方法为解决未来行业问题提供了一种基于证据、透明的方法，为更强大、可问责、可扩展、高效、灵活、适应性强和协作的解决方案铺平了道路。

Abstract: The Enterprise Intelligence Platform must integrate logs from numerous
third-party vendors in order to perform various downstream tasks. However,
vendor documentation is often unavailable at test time. It is either misplaced,
mismatched, poorly formatted, or incomplete, which makes schema mapping
challenging. We introduce a reinforcement learning agent that can self-improve
without labeled examples or model weight updates. During inference, the agent:
1) Identifies ambiguous field-mapping attempts. 2) Generates targeted
web-search queries to gather external evidence. 3) Applies a confidence-based
reward to iteratively refine its mappings. To demonstrate this concept, we
converted Microsoft Defender for Endpoint logs into a common schema. Our method
increased mapping accuracy from 56.4\%(LLM-only) to 72.73\%(RAG) to 93.94\%
over 100 iterations using GPT-4o. At the same time, it reduced the number of
low-confidence mappings requiring expert review by 85\%. This new approach
provides an evidence-driven, transparent method for solving future industry
problems, paving the way for more robust, accountable, scalable, efficient,
flexible, adaptable, and collaborative solutions.

</details>


### [157] [Budget-aware Test-time Scaling via Discriminative Verification](https://arxiv.org/abs/2510.14913)
*Kyle Montgomery,Sijun Tan,Yuqi Chen,Siyuan Zhuang,Tianjun Zhang,Raluca Ada Popa,Chenguang Wang*

Main category: cs.AI

TL;DR: 混合判别式验证器与自一致性的方法在固定计算预算下比生成式验证器更高效，准确率提升15.3%。


<details>
  <summary>Details</summary>
Motivation: 生成式验证器计算成本高，限制了实用性，因此探索更高效的判别式验证方法。

Method: 通过实证分析，比较判别式验证器与生成式验证器的性能，提出混合方法（判别式验证器+自一致性）。

Result: 混合方法在AIME2025上准确率提升了15.3%，效率更高。

Conclusion: 预算感知的判别式验证器与自一致性结合的混合方法，在固定计算预算下显著优于生成式验证器，是更高效实用的测试时扩展机制。

Abstract: Test-time scaling is a powerful strategy for boosting the performance of
large language models on complex reasoning tasks. While state-of-the-art
approaches often employ generative verifiers to select the best solution from a
pool of candidates, this method incurs prohibitive computational costs,
limiting its practicality. In this work, we shift the focus to a more
budget-aware paradigm: discriminative verification. We conduct a thorough
empirical analysis and demonstrate that while discriminative verifiers may
underperform in isolation, combining them with self-consistency in a hybrid
approach creates a powerful and efficient test-time scaling mechanism. Notably,
under a fixed compute budget, this hybrid approach surpasses state-of-the-art
generative verification by a significant margin: achieving up to 15.3\% higher
accuracy on AIME2025. Our findings establish that for practical, real-world
applications, budget-aware scaling with discriminative verifiers is not only a
"free" upgrade over self-consistency, but also a more effective and efficient
alternative to costly generative techniques. Code is available at
https://github.com/wang-research-lab/verification.

</details>


### [158] [TRI-DEP: A Trimodal Comparative Study for Depression Detection Using Speech, Text, and EEG](https://arxiv.org/abs/2510.14922)
*Annisaa Fitri Nurfidausi,Eleonora Mancini,Paolo Torroni*

Main category: cs.AI

TL;DR: 该研究通过系统探索EEG、语音和文本的特征与建模策略，填补了现有研究的空白，展示了多模态组合的优越性和预训练嵌入的优势，为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是一种普遍的心理健康障碍，但其自动检测仍具挑战性。现有研究范围有限，缺乏系统的特征比较和一致的评价协议。

Method: 系统地探索了EEG、语音和文本的特征表示和建模策略，评估了手工特征与预训练嵌入的效果，比较了单模态、双模态和三模态配置，并分析了融合策略。

Result: 结果表明：(i) EEG、语音和文本模态的组合增强了多模态检测，(ii) 预训练嵌入优于手工特征，(iii) 精心设计的三模态模型实现了最先进的性能。

Conclusion: 该研究为多模态抑郁症检测的未来研究奠定了基础，展示了精心设计的三模态模型的最先进性能。

Abstract: Depression is a widespread mental health disorder, yet its automatic
detection remains challenging. Prior work has explored unimodal and multimodal
approaches, with multimodal systems showing promise by leveraging complementary
signals. However, existing studies are limited in scope, lack systematic
comparisons of features, and suffer from inconsistent evaluation protocols. We
address these gaps by systematically exploring feature representations and
modelling strategies across EEG, together with speech and text. We evaluate
handcrafted features versus pre-trained embeddings, assess the effectiveness of
different neural encoders, compare unimodal, bimodal, and trimodal
configurations, and analyse fusion strategies with attention to the role of
EEG. Consistent subject-independent splits are applied to ensure robust,
reproducible benchmarking. Our results show that (i) the combination of EEG,
speech and text modalities enhances multimodal detection, (ii) pretrained
embeddings outperform handcrafted features, and (iii) carefully designed
trimodal models achieve state-of-the-art performance. Our work lays the
groundwork for future research in multimodal depression detection.

</details>


### [159] [Stable but Miscalibrated: A Kantian View on Overconfidence from Filters to Large Language Models](https://arxiv.org/abs/2510.14925)
*Akira Okutomi*

Main category: cs.AI

TL;DR: 论文将康德的《纯粹理性批判》重新解读为反馈稳定性理论，提出H-Risk指数揭示推理系统中的过度自信问题，并在LLMs中验证了相关现象。


<details>
  <summary>Details</summary>
Motivation: 重新解读康德的《纯粹理性批判》作为一种反馈稳定性理论，将理性视为保持推理在可能经验范围内的调节器。

Method: 通过复合不稳定指数（H-Risk）结合谱边缘、条件数、时间敏感性和创新放大，在线性高斯模拟中形式化这一直觉。

Result: 在线性高斯模拟中，更高的H-Risk即使在形式稳定性下也能预测过度自信的错误，揭示了名义稳定性和认知稳定性之间的差距。在大型语言模型（LLMs）中，脆弱的内部动态与校准错误和幻觉相关，而批判式提示对校准和幻觉的影响不一。

Conclusion: 论文提出了一种结构性的桥梁，将康德式的自我限制与反馈控制联系起来，为诊断和选择性减少推理系统中的过度自信提供了原则性的视角。

Abstract: We reinterpret Kant's Critique of Pure Reason as a theory of feedback
stability, viewing reason as a regulator that keeps inference within the bounds
of possible experience. We formalize this intuition via a composite instability
index (H-Risk) combining spectral margin, conditioning, temporal sensitivity,
and innovation amplification. In linear-Gaussian simulations, higher H-Risk
predicts overconfident errors even under formal stability, revealing a gap
between nominal and epistemic stability. Extending to large language models
(LLMs), we find that fragile internal dynamics correlate with miscalibration
and hallucination, while critique-style prompts show mixed effects on
calibration and hallucination. These results suggest a structural bridge
between Kantian self-limitation and feedback control, offering a principled
lens for diagnosing -- and selectively reducing -- overconfidence in reasoning
systems. This is a preliminary version; supplementary experiments and broader
replication will be reported in a future revision.

</details>


### [160] [GroundedPRM: Tree-Guided and Fidelity-Aware Process Reward Modeling for Step-Level Reasoning](https://arxiv.org/abs/2510.14942)
*Yao Zhang,Yu Wu,Haowei Zhang,Weiguo Li,Haokun Chen,Jingpei Wu,Guohao Li,Zhen Han,Volker Tresp*

Main category: cs.AI

TL;DR: GroundedPRM 是一种自动过程监督框架，通过MCTS和外部工具验证减少噪声和幻觉，显著提升多步推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的人工标注或易产生幻觉的LLM自评估，导致奖励噪声大、保真度低且与步骤级推理目标不一致。

Method: GroundedPRM 使用蒙特卡洛树搜索（MCTS）构建结构化推理路径，并通过外部工具验证每个中间步骤，结合工具验证和MCTS反馈的混合奖励聚合机制。

Result: GroundedPRM 仅使用40K自动标注样本（最佳PRM的10%数据量），在ProcessBench上实现了26%的相对性能提升，甚至在奖励引导的贪婪搜索中优于人工标注的PRM。

Conclusion: GroundedPRM 通过结合树引导和保真度感知的框架，显著提升了多步推理的质量，提供了一种可扩展且可验证的高质量过程级推理方法。

Abstract: Process Reward Models (PRMs) aim to improve multi-step reasoning in Large
Language Models (LLMs) by supervising intermediate steps and identifying
errors. However, building effective PRMs remains challenging due to the lack of
scalable, high-quality annotations. Existing approaches rely on costly human
labeling, LLM-based self-evaluation that is prone to hallucination, or Monte
Carlo (MC) estimation, which infers step quality solely from rollout outcomes
and often introduces noisy, misaligned supervision due to credit
misattribution. These issues result in three core limitations: noisy rewards,
low factual fidelity, and misalignment with step-level reasoning objectives. To
address these challenges, we introduce GroundedPRM, a tree-guided and
fidelity-aware framework for automatic process supervision. To reduce reward
noise and enable fine-grained credit assignment, we construct structured
reasoning paths via Monte Carlo Tree Search (MCTS). To eliminate hallucinated
supervision, we validate each intermediate step using an external tool,
providing execution-grounded correctness signals. To combine both step-level
validation and global outcome assessment, we design a hybrid reward aggregation
mechanism that fuses tool-based verification with MCTS-derived feedback.
Finally, we format the reward signal into a rationale-enhanced, generative
structure to promote interpretability and compatibility with instruction-tuned
LLMs. GroundedPRM is trained on only 40K automatically labeled samples,
amounting to just 10% of the data used by the best-performing PRM trained with
auto-labeled supervision. Nevertheless, it achieves up to a 26% relative
improvement in average performance on ProcessBench. When used for reward-guided
greedy search, GroundedPRM outperforms even PRMs trained with human-labeled
supervision, offering a scalable and verifiable path toward high-quality
process-level reasoning.

</details>


### [161] [Towards Unified Multimodal Misinformation Detection in Social Media: A Benchmark Dataset and Baseline](https://arxiv.org/abs/2509.25991)
*Haiyang Li,Yaxiong Wang,Shengeng Tang,Lianwei Wu,Lechao Cheng,Zhun Zhong*

Main category: cs.AI

TL;DR: UMFDet是一个统一的多模态虚假内容检测框架，结合VLM和MoE适配器，有效检测人工和AI生成的虚假内容。


<details>
  <summary>Details</summary>
Motivation: 当前虚假内容检测研究通常孤立处理人工编写和AI生成的虚假内容，导致模型在实际场景中效果受限。OmniFake数据集的构建和UMFDet框架的提出旨在填补这一空白。

Method: 提出了统一的多模态虚假内容检测框架（UMFDet），利用VLM骨干网络增强类别感知的MoE适配器，并结合归因链式思维机制捕捉特定类别的线索和隐性推理指导。

Result: 实验表明，UMFDet在人工和AI生成的虚假内容检测上均表现稳健且一致，优于专用基线模型。

Conclusion: UMFDet通过结合VLM骨干网络、类别感知的MoE适配器和归因链式思维机制，成功实现了对人工和AI生成虚假内容的多模态检测，性能优于现有专用模型，为实际应用提供了实用解决方案。

Abstract: In recent years, detecting fake multimodal content on social media has drawn
increasing attention. Two major forms of deception dominate: human-crafted
misinformation (e.g., rumors and misleading posts) and AI-generated content
produced by image synthesis models or vision-language models (VLMs). Although
both share deceptive intent, they are typically studied in isolation. NLP
research focuses on human-written misinformation, while the CV community
targets AI-generated artifacts. As a result, existing models are often
specialized for only one type of fake content. In real-world scenarios,
however, the type of a multimodal post is usually unknown, limiting the
effectiveness of such specialized systems. To bridge this gap, we construct the
Omnibus Dataset for Multimodal News Deception (OmniFake), a comprehensive
benchmark of 127K samples that integrates human-curated misinformation from
existing resources with newly synthesized AI-generated examples. Based on this
dataset, we propose Unified Multimodal Fake Content Detection (UMFDet), a
framework designed to handle both forms of deception. UMFDet leverages a VLM
backbone augmented with a Category-aware Mixture-of-Experts (MoE) Adapter to
capture category-specific cues, and an attribution chain-of-thought mechanism
that provides implicit reasoning guidance for locating salient deceptive
signals. Extensive experiments demonstrate that UMFDet achieves robust and
consistent performance across both misinformation types, outperforming
specialized baselines and offering a practical solution for real-world
multimodal deception detection.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [162] [A Diffusion-Refined Planner with Reinforcement Learning Priors for Confined-Space Parking](https://arxiv.org/abs/2510.14000)
*Mingyang Jiang,Yueyuan Li,Jiaru Zhang,Songan Zhang,Ming Yang*

Main category: cs.RO

TL;DR: DRIP是一种结合强化学习和扩散模型的停车规划方法，通过先验动作分布和细化过程，提高了受限空间中的规划成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 在受限和复杂环境中，高精度操作是实现高规划成功率的关键，但现有方法依赖于显式动作建模，难以准确建模最优动作分布。

Method: 提出了一种基于强化学习先验动作分布的扩散细化规划器（DRIP），利用强化学习预训练策略提供先验动作分布以规范化扩散训练过程，并在推理阶段通过去噪过程将这些粗略先验细化为更精确的动作分布。

Result: 实验结果表明，DRIP方法在受限空间停车环境中显著提高了规划性能，同时减少了推理步骤。

Conclusion: DRIP方法通过结合强化学习先验动作分布和扩散模型，显著提高了在受限空间停车环境中的规划成功率，并保持了在常见场景中的强泛化能力。

Abstract: The growing demand for parking has increased the need for automated parking
planning methods that can operate reliably in confined spaces. In restricted
and complex environments, high-precision maneuvers are required to achieve a
high success rate in planning, yet existing approaches often rely on explicit
action modeling, which faces challenges when accurately modeling the optimal
action distribution. In this paper, we propose DRIP, a diffusion-refined
planner anchored in reinforcement learning (RL) prior action distribution, in
which an RL-pretrained policy provides prior action distributions to regularize
the diffusion training process. During the inference phase the denoising
process refines these coarse priors into more precise action distributions. By
steering the denoising trajectory through the reinforcement learning prior
distribution during training, the diffusion model inherits a well-informed
initialization, resulting in more accurate action modeling, a higher planning
success rate, and reduced inference steps. We evaluate our approach across
parking scenarios with varying degrees of spatial constraints. Experimental
results demonstrate that our method significantly improves planning performance
in confined-space parking environments while maintaining strong generalization
in common scenarios.

</details>


### [163] [Spatially Intelligent Patrol Routes for Concealed Emitter Localization by Robot Swarms](https://arxiv.org/abs/2510.14018)
*Adam Morris,Timothy Pelham,Edmund R. Hunt*

Main category: cs.RO

TL;DR: 论文提出了一种设计空间智能机器人群体行为的方法，用于定位隐蔽无线电发射器。通过差分进化生成巡逻路线，结果显示定向天线比全向天线更有效。


<details>
  <summary>Details</summary>
Motivation: 电磁监视中定位隐蔽无线电发射器是一个关键挑战，需要独立于发射器参数的方法。

Method: 使用差分进化生成几何巡逻路线，独立于发射器参数定位未知信号。模拟四机器人群体在八种配置中，基于指定巡逻形状和感知能力（天线类型：全向或定向）分配预生成的巡逻路线。

Result: 定向天线的平均检测成功率为98.75%，全向天线为80.25%。定向感知的平均定位误差为1.01-1.30米，全向为1.67-1.90米。定向感知还受益于更短的巡逻边缘。

Conclusion: 空间智能，通过优化的巡逻路线和天线选择实现，是有效机器人监视的关键设计考虑。

Abstract: This paper introduces a method for designing spatially intelligent robot
swarm behaviors to localize concealed radio emitters. We use differential
evolution to generate geometric patrol routes that localize unknown signals
independently of emitter parameters, a key challenge in electromagnetic
surveillance. Patrol shape and antenna type are shown to influence information
gain, which in turn determines the effective triangulation coverage. We
simulate a four-robot swarm across eight configurations, assigning
pre-generated patrol routes based on a specified patrol shape and sensing
capability (antenna type: omnidirectional or directional). An emitter is placed
within the map for each trial, with randomized position, transmission power and
frequency. Results show that omnidirectional localization success rates are
driven primarily by source location rather than signal properties, with
failures occurring most often when sources are placed in peripheral areas of
the map. Directional antennas are able to overcome this limitation due to their
higher gain and directivity, with an average detection success rate of 98.75%
compared to 80.25% for omnidirectional. Average localization errors range from
1.01-1.30 m for directional sensing and 1.67-1.90 m for omnidirectional
sensing; while directional sensing also benefits from shorter patrol edges.
These results demonstrate that a swarm's ability to predict electromagnetic
phenomena is directly dependent on its physical interaction with the
environment. Consequently, spatial intelligence, realized here through
optimized patrol routes and antenna selection, is a critical design
consideration for effective robotic surveillance.

</details>


### [164] [Adaptive Obstacle-Aware Task Assignment and Planning for Heterogeneous Robot Teaming](https://arxiv.org/abs/2510.14063)
*Nan Li,Jiming Ren,Haris Miller,Samuel Coogan,Karen M. Feigh,Ye Zhao*

Main category: cs.RO

TL;DR: OATH提出障碍物感知任务分配与规划框架，结合自适应Halton采样和聚类-拍卖-选择机制，显著提升多智能体系统的任务分配效率和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决MATP在可扩展性、空间推理及障碍物丰富环境适应性方面的挑战。

Method: 提出了OATH框架，包括自适应Halton序列地图（首次将Halton采样与障碍物感知结合）和聚类-拍卖-选择框架，结合LLM实时解析人类指令指导规划。

Result: 在NVIDIA Isaac Sim中的实验表明，OATH在任务分配质量、可扩展性、动态适应性和整体执行性能上优于现有MATP基线方法。

Conclusion: OATH通过引入障碍物感知任务分配策略，显著提升了多智能体任务分配与规划（MATP）的可扩展性、空间推理能力及在障碍物丰富环境中的适应性，实验验证其在任务分配质量、可扩展性和动态变化适应性方面的优越性。

Abstract: Multi-Agent Task Assignment and Planning (MATP) has attracted growing
attention but remains challenging in terms of scalability, spatial reasoning,
and adaptability in obstacle-rich environments. To address these challenges, we
propose OATH: Adaptive Obstacle-Aware Task Assignment and Planning for
Heterogeneous Robot Teaming, which advances MATP by introducing a novel
obstacle-aware strategy for task assignment. First, we develop an adaptive
Halton sequence map, the first known application of Halton sampling with
obstacle-aware adaptation in MATP, which adjusts sampling density based on
obstacle distribution. Second, we propose a cluster-auction-selection framework
that integrates obstacle-aware clustering with weighted auctions and
intra-cluster task selection. These mechanisms jointly enable effective
coordination among heterogeneous robots while maintaining scalability and
near-optimal allocation performance. In addition, our framework leverages an
LLM to interpret human instructions and directly guide the planner in real
time. We validate OATH in NVIDIA Isaac Sim, showing substantial improvements in
task assignment quality, scalability, adaptability to dynamic changes, and
overall execution performance compared to state-of-the-art MATP baselines. A
project website is available at https://llm-oath.github.io/.

</details>


### [165] [Optimistic Reinforcement Learning-Based Skill Insertions for Task and Motion Planning](https://arxiv.org/abs/2510.14065)
*Gaoyuan Liu,Joris de Winter,Yuri Durodie,Denis Steckelmacher,Ann Nowe,Bram Vanderborght*

Main category: cs.RO

TL;DR: 结合RL技能的TAMP方法，提升了处理概率动作的能力和规划效率。


<details>
  <summary>Details</summary>
Motivation: TAMP在长时程推理中需要处理不确定性动作（概率动作），而RL擅长获取短时程但鲁棒的操控技能，结合两者可以提升规划能力。

Method: 设计了一种将RL技能集成到TAMP流水线中的方法，包括定义RL技能的数据驱动逻辑组件和计划细化子程序。

Result: 实验表明，该方法在概率技能领域扩展了TAMP能力，并提升了规划效率。

Conclusion: 通过将RL技能嵌入TAMP，我们扩展了TAMP在概率技能领域的能力，并提高了规划效率。

Abstract: Task and motion planning (TAMP) for robotics manipulation necessitates
long-horizon reasoning involving versatile actions and skills. While
deterministic actions can be crafted by sampling or optimizing with certain
constraints, planning actions with uncertainty, i.e., probabilistic actions,
remains a challenge for TAMP. On the contrary, Reinforcement Learning (RL)
excels in acquiring versatile, yet short-horizon, manipulation skills that are
robust with uncertainties. In this letter, we design a method that integrates
RL skills into TAMP pipelines. Besides the policy, a RL skill is defined with
data-driven logical components that enable the skill to be deployed by symbolic
planning. A plan refinement sub-routine is designed to further tackle the
inevitable effect uncertainties. In the experiments, we compare our method with
baseline hierarchical planning from both TAMP and RL fields and illustrate the
strength of the method. The results show that by embedding RL skills, we extend
the capability of TAMP to domains with probabilistic skills, and improve the
planning efficiency compared to the previous methods.

</details>


### [166] [Partial Feedback Linearization Control of a Cable-Suspended Multirotor Platform for Stabilization of an Attached Load](https://arxiv.org/abs/2510.14072)
*Hemjyoti Das,Christian Ott*

Main category: cs.RO

TL;DR: 提出了一种基于PFL的新型控制方法，用于稳定带有负载的悬挂空中平台，适用于户外建筑工地，并通过仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对建筑工地中涉及起重机的应用（如重型物体的搬运和固定），开发一种仅依赖机载传感器的控制方法，以适应户外环境的需求。

Method: 采用部分反馈线性化（PFL）技术，考虑系统的欠驱动特性，并利用其耦合动力学进行稳定。

Result: 通过大量仿真和实验测试，证明了所提出的控制方法在复杂环境下的稳定性和鲁棒性。

Conclusion: 该研究提出了一种基于部分反馈线性化（PFL）的新型控制方法，用于稳定带有负载的悬挂空中平台。通过数值稳定性分析和鲁棒性测试，验证了该方法在外部风扰、传感器噪声和系统动力学不确定性下的有效性。

Abstract: In this work, we present a novel control approach based on partial feedback
linearization (PFL) for the stabilization of a suspended aerial platform with
an attached load. Such systems are envisioned for various applications in
construction sites involving cranes, such as the holding and transportation of
heavy objects. Our proposed control approach considers the underactuation of
the whole system while utilizing its coupled dynamics for stabilization. We
demonstrate using numerical stability analysis that these coupled terms are
crucial for the stabilization of the complete system. We also carried out
robustness analysis of the proposed approach in the presence of external wind
disturbances, sensor noise, and uncertainties in system dynamics. As our
envisioned target application involves cranes in outdoor construction sites,
our control approaches rely on only onboard sensors, thus making it suitable
for such applications. We carried out extensive simulation studies and
experimental tests to validate our proposed control approach.

</details>


### [167] [ViTacGen: Robotic Pushing with Vision-to-Touch Generation](https://arxiv.org/abs/2510.14117)
*Zhiyuan Wu,Yijiong Lin,Yongqiang Zhao,Xuyang Zhang,Zhuo Chen,Nathan Lepora,Shan Luo*

Main category: cs.RO

TL;DR: ViTacGen 是一种新型机器人操作框架，通过视觉到触觉生成和强化学习，无需真实触觉传感器即可实现高效机器人推动，实验成功率高达86%。


<details>
  <summary>Details</summary>
Motivation: 解决真实触觉传感器的高成本、脆弱性以及部署挑战，同时提升仅依赖视觉的机器人推动策略的性能。

Method: ViTacGen 包括一个编码器-解码器视觉到触觉生成网络，用于从视觉图像序列生成接触深度图像，随后通过强化学习策略融合视觉和生成的触觉数据，并采用对比学习。

Result: 在仿真和现实实验中验证了ViTacGen的有效性，最高成功率达到86%。

Conclusion: ViTacGen 框架通过视觉到触觉的生成网络和强化学习策略，成功实现了在无需高分辨率真实触觉传感器的情况下，仅依赖视觉的机器人推动任务，验证了其在仿真和现实实验中的有效性。

Abstract: Robotic pushing is a fundamental manipulation task that requires tactile
feedback to capture subtle contact forces and dynamics between the end-effector
and the object. However, real tactile sensors often face hardware limitations
such as high costs and fragility, and deployment challenges involving
calibration and variations between different sensors, while vision-only
policies struggle with satisfactory performance. Inspired by humans' ability to
infer tactile states from vision, we propose ViTacGen, a novel robot
manipulation framework designed for visual robotic pushing with vision-to-touch
generation in reinforcement learning to eliminate the reliance on
high-resolution real tactile sensors, enabling effective zero-shot deployment
on visual-only robotic systems. Specifically, ViTacGen consists of an
encoder-decoder vision-to-touch generation network that generates contact depth
images, a standardized tactile representation, directly from visual image
sequence, followed by a reinforcement learning policy that fuses visual-tactile
data with contrastive learning based on visual and generated tactile
observations. We validate the effectiveness of our approach in both simulation
and real world experiments, demonstrating its superior performance and
achieving a success rate of up to 86\%.

</details>


### [168] [Prescribed Performance Control of Deformable Object Manipulation in Spatial Latent Space](https://arxiv.org/abs/2510.14234)
*Ning Han,Gu Gong,Bin Zhang,Yuexuan Xu,Bohan Yang,Yunhui Liu,David Navarro-Alarcon*

Main category: cs.RO

TL;DR: 论文提出了一种基于关键点坐标的无模型形状控制方法，结合BLF和变形雅可比矩阵，实验验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于三维可变形物体的无限维状态空间和复杂变形动力学，传统方法难以有效操纵。本文旨在通过关键点约束和模型无关方法解决这一挑战。

Method: 利用深度学习从点云中提取关键点坐标作为特征向量，简化了可变形物体的操纵问题为视觉伺服问题。通过变形雅可比矩阵描述形状动力学，并结合BLF开发了规定性能控制方法。

Result: 实验结果表明，所提出的方法在控制精度和系统稳定性方面表现优异，验证了其在操纵可变形物体中的有效性和鲁棒性。

Conclusion: 该论文提出了一种基于关键点坐标的无模型形状控制方法，通过结合障碍李雅普诺夫函数（BLF）和变形雅可比矩阵，有效提高了控制精度和系统稳定性。实验验证了该方法的有效性和鲁棒性。

Abstract: Manipulating three-dimensional (3D) deformable objects presents significant
challenges for robotic systems due to their infinite-dimensional state space
and complex deformable dynamics. This paper proposes a novel model-free
approach for shape control with constraints imposed on key points. Unlike
existing methods that rely on feature dimensionality reduction, the proposed
controller leverages the coordinates of key points as the feature vector, which
are extracted from the deformable object's point cloud using deep learning
methods. This approach not only reduces the dimensionality of the feature space
but also retains the spatial information of the object. By extracting key
points, the manipulation of deformable objects is simplified into a visual
servoing problem, where the shape dynamics are described using a deformation
Jacobian matrix. To enhance control accuracy, a prescribed performance control
method is developed by integrating barrier Lyapunov functions (BLF) to enforce
constraints on the key points. The stability of the closed-loop system is
rigorously analyzed and verified using the Lyapunov method. Experimental
results further demonstrate the effectiveness and robustness of the proposed
method.

</details>


### [169] [Learning Human-Humanoid Coordination for Collaborative Object Carrying](https://arxiv.org/abs/2510.14293)
*Yushi Du,Yixuan Li,Baoxiong Jia,Yutang Lin,Pei Zhou,Wei Liang,Yanchao Yang,Siyuan Huang*

Main category: cs.RO

TL;DR: COLA是一种仅依赖本体感觉的强化学习方法，实现顺应性人-人形协作搬运，减少人类努力并提升稳定性。


<details>
  <summary>Details</summary>
Motivation: 人-人形机器人协作在医疗、家庭辅助和制造等领域具有巨大潜力，但由于人形机器人复杂的全身动力学，其顺应性协作尚未充分探索。

Method: 提出了一种仅依赖本体感觉的强化学习方法COLA，通过在闭环环境中训练，动态预测物体运动模式和人类意图，实现协调的轨迹规划。

Result: 模拟实验显示模型减少人类努力24.7%，真实实验验证了在不同物体和地形上的鲁棒性，用户研究显示平均提升27.4%。

Conclusion: 该方法通过结合领导者和跟随者行为于单一策略中，实现了无需外部传感器或复杂交互模型的顺应性人-人形机器人协作搬运，为实际应用提供了实用解决方案。

Abstract: Human-humanoid collaboration shows significant promise for applications in
healthcare, domestic assistance, and manufacturing. While compliant robot-human
collaboration has been extensively developed for robotic arms, enabling
compliant human-humanoid collaboration remains largely unexplored due to
humanoids' complex whole-body dynamics. In this paper, we propose a
proprioception-only reinforcement learning approach, COLA, that combines leader
and follower behaviors within a single policy. The model is trained in a
closed-loop environment with dynamic object interactions to predict object
motion patterns and human intentions implicitly, enabling compliant
collaboration to maintain load balance through coordinated trajectory planning.
We evaluate our approach through comprehensive simulator and real-world
experiments on collaborative carrying tasks, demonstrating the effectiveness,
generalization, and robustness of our model across various terrains and
objects. Simulation experiments demonstrate that our model reduces human effort
by 24.7%. compared to baseline approaches while maintaining object stability.
Real-world experiments validate robust collaborative carrying across different
object types (boxes, desks, stretchers, etc.) and movement patterns
(straight-line, turning, slope climbing). Human user studies with 23
participants confirm an average improvement of 27.4% compared to baseline
models. Our method enables compliant human-humanoid collaborative carrying
without requiring external sensors or complex interaction models, offering a
practical solution for real-world deployment.

</details>


### [170] [Expertise need not monopolize: Action-Specialized Mixture of Experts for Vision-Language-Action Learning](https://arxiv.org/abs/2510.14300)
*Weijie Shen,Yitian Liu,Yuhao Wu,Zhixuan Liang,Sijia Gu,Dehui Wang,Tian Nian,Lei Xu,Yusen Qin,Jiangmiao Pang,Xinping Guan,Xiaokang Yang,Yao Mu*

Main category: cs.RO

TL;DR: AdaMoE是一种混合专家架构，通过协作专家利用提升性能，在机器人操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在扩展过程中面临的两个关键挑战：（1）充分利用预训练VLA模型权重以减少对大量计算资源和数据集的需求；（2）在实时控制中平衡模型能力与计算效率。

Method: 提出AdaMoE，一种混合专家（MoE）架构，继承密集VLA模型的预训练权重，并通过将前馈层替换为稀疏激活的MoE层来扩展动作专家。采用解耦技术，通过独立的比例适配器与传统路由器并行工作，实现专家选择与专家权重的解耦。

Result: AdaMoE在关键基准测试中一致优于基线模型，LIBERO上性能提升1.8%，RoboTwin上提升9.3%，实际实验中提升21.5%。

Conclusion: AdaMoE通过协作专家利用的方式，在保持计算效率的同时实现了卓越的性能，特别是在机器人操作任务中表现出显著的实用效果。

Abstract: Vision-Language-Action (VLA) models are experiencing rapid development and
demonstrating promising capabilities in robotic manipulation tasks. However,
scaling up VLA models presents several critical challenges: (1) Training new
VLA models from scratch demands substantial computational resources and
extensive datasets. Given the current scarcity of robot data, it becomes
particularly valuable to fully leverage well-pretrained VLA model weights
during the scaling process. (2) Real-time control requires carefully balancing
model capacity with computational efficiency. To address these challenges, We
propose AdaMoE, a Mixture-of-Experts (MoE) architecture that inherits
pretrained weights from dense VLA models, and scales up the action expert by
substituting the feedforward layers into sparsely activated MoE layers. AdaMoE
employs a decoupling technique that decouples expert selection from expert
weighting through an independent scale adapter working alongside the
traditional router. This enables experts to be selected based on task relevance
while contributing with independently controlled weights, allowing
collaborative expert utilization rather than winner-takes-all dynamics. Our
approach demonstrates that expertise need not monopolize. Instead, through
collaborative expert utilization, we can achieve superior performance while
maintaining computational efficiency. AdaMoE consistently outperforms the
baseline model across key benchmarks, delivering performance gains of 1.8% on
LIBERO and 9.3% on RoboTwin. Most importantly, a substantial 21.5% improvement
in real-world experiments validates its practical effectiveness for robotic
manipulation tasks.

</details>


### [171] [Risk-Aware Reinforcement Learning with Bandit-Based Adaptation for Quadrupedal Locomotion](https://arxiv.org/abs/2510.14338)
*Yuanhong Zeng,Anushri Dixit*

Main category: cs.RO

TL;DR: 本文提出了一种风险感知的强化学习方法，通过 CVaR 约束和多臂老虎机框架，显著提升了四足机器人在未知环境中的 locomotion 性能和适应性。


<details>
  <summary>Details</summary>
Motivation: 研究如何在未知环境中提高四足机器人 locomotion 的稳定性和样本效率。

Method: 使用 CVaR 约束的策略优化技术训练一系列风险条件策略，并通过多臂老虎机框架在线自适应选择最佳策略。

Result: 在八种未见过的模拟设置和真实机器人测试中，风险感知策略的平均和尾部性能接近其他基线的两倍，且自适应选择策略在未知地形中两分钟内即可选出最佳策略。

Conclusion: 风险感知的强化学习方法在四足机器人 locomotion 中表现出色，尤其在未知环境中的适应性和性能显著优于其他基线方法。

Abstract: In this work, we study risk-aware reinforcement learning for quadrupedal
locomotion. Our approach trains a family of risk-conditioned policies using a
Conditional Value-at-Risk (CVaR) constrained policy optimization technique that
provides improved stability and sample efficiency. At deployment, we adaptively
select the best performing policy from the family of policies using a
multi-armed bandit framework that uses only observed episodic returns, without
any privileged environment information, and adapts to unknown conditions on the
fly. Hence, we train quadrupedal locomotion policies at various levels of
robustness using CVaR and adaptively select the desired level of robustness
online to ensure performance in unknown environments. We evaluate our method in
simulation across eight unseen settings (by changing dynamics, contacts,
sensing noise, and terrain) and on a Unitree Go2 robot in previously unseen
terrains. Our risk-aware policy attains nearly twice the mean and tail
performance in unseen environments compared to other baselines and our
bandit-based adaptation selects the best-performing risk-aware policy in
unknown terrain within two minutes of operation.

</details>


### [172] [SUM-AgriVLN: Spatial Understanding Memory for Agricultural Vision-and-Language Navigation](https://arxiv.org/abs/2510.14357)
*Xiaobei Zhao,Xingqi Lyu,Xiang Li*

Main category: cs.RO

TL;DR: SUM-AgriVLN通过引入空间记忆模块，利用历史指令的空间上下文，提升了农业导航的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的AgriVLN方法将每条导航指令视为独立事件，忽略了历史指令可能提供的空间上下文信息。

Method: 提出了空间理解记忆模块（SUM），通过3D重建和表示来保存空间记忆，以利用历史指令提供的空间上下文。

Result: 在A2A基准测试中，SUM-AgriVLN将成功率从0.47提升至0.54，导航误差仅从2.91米略微增加到2.93米。

Conclusion: SUM-AgriVLN通过引入空间理解记忆模块，显著提升了农业视觉与语言导航的成功率，并在A2A基准测试中展现了最先进的性能。

Abstract: Agricultural robots are emerging as powerful assistants across a wide range
of agricultural tasks, nevertheless, still heavily rely on manual operation or
fixed rail systems for movement. The AgriVLN method and the A2A benchmark
pioneeringly extend Vision-and-Language Navigation (VLN) to the agricultural
domain, enabling robots to navigate to the target positions following the
natural language instructions. In practical agricultural scenarios, navigation
instructions often repeatedly occur, yet AgriVLN treat each instruction as an
independent episode, overlooking the potential of past experiences to provide
spatial context for subsequent ones. To bridge this gap, we propose the method
of Spatial Understanding Memory for Agricultural Vision-and-Language Navigation
(SUM-AgriVLN), in which the SUM module employs spatial understanding and save
spatial memory through 3D reconstruction and representation. When evaluated on
the A2A benchmark, our SUM-AgriVLN effectively improves Success Rate from 0.47
to 0.54 with slight sacrifice on Navigation Error from 2.91m to 2.93m,
demonstrating the state-of-the-art performance in the agricultural domain.
Code: https://github.com/AlexTraveling/SUM-AgriVLN.

</details>


### [173] [RoboANKLE: Design, Development, and Functional Evaluation of a Robotic Ankle with a Motorized Compliant Unit](https://arxiv.org/abs/2510.14414)
*Baris Baysal,Omid Arfaie,Ramazan Unal*

Main category: cs.RO

TL;DR: RoboANKLE 是一款创新的动力式胫骨假肢，通过 ESER 和 EES 机制实现了自然踝关节运动。实验证明其扭矩和功率表现优于自然需求，且设计轻量化。


<details>
  <summary>Details</summary>
Motivation: 设计 RoboANKLE 旨在解决主动式胫骨假肢设计中面临的能量自主性和重量最小化等挑战，以实现更自然的踝关节运动。

Method: 研究通过运动学和动力学分析确定设计参数，并利用计算机辅助设计（CAD）模型进行动态和结构分析。通过结构分析和拓扑优化，实现了轻量化设计。最终制造原型并进行实验评估。

Result: RoboANKLE 原型质量为 1.92 kg，尺寸为 261x107x420 mm。功能评估显示，其最大背屈角度准确度达 95%，扭矩生成比自然行走需求高 57%，功率生成能力比自然步态高 10%。

Conclusion: RoboANKLE 是一种具有完全推离辅助功能的动力式胫骨假肢，通过创新的能量存储和释放机制（ESER）以及额外能量存储（EES）机制，成功实现了自然踝关节运动的扭矩需求。实验评估表明，该假肢在最大背屈角度和扭矩生成方面表现优异，且功率生成能力超过自然步态需求。

Abstract: This study presents a powered transtibial prosthesis with complete push-off
assistance, RoboANKLE. The design aims to fulfill specific requirements, such
as a sufficient range of motion (RoM) while providing the necessary torque for
achieving natural ankle motion in daily activities. Addressing the challenges
faced in designing active transtibial prostheses, such as maintaining energetic
autonomy and minimizing weight, is vital for the study. With this aim, we try
to imitate the human ankle by providing extensive push-off assistance to
achieve a natural-like torque profile. Thus, Energy Store and Extended Release
mechanism (ESER) is employed with a novel Extra Energy Storage (EES) mechanism.
Kinematic and kinetic analyses are carried out to determine the design
parameters and assess the design performance. Subsequently, a Computer-Aided
Design (CAD) model is built and used in comprehensive dynamic and structural
analyses. These analyses are used for the design performance evaluation and
determine the forces and torques applied to the prosthesis, which aids in
optimizing the design for minimal weight via structural analysis and topology
optimization. The design of the prototype is then finalized and manufactured
for experimental evaluation to validate the design and functionality. The
prototype is realized with a mass of 1.92 kg and dimensions of 261x107x420 mm.
The Functional evaluations of the RoboANKLE revealed that it is capable of
achieving the natural maximum dorsi-flexion angle with 95% accuracy. Also,
Thanks to the implemented mechanisms, the results show that RoboANKLE can
generate 57% higher than the required torque for natural walking. The result of
the power generation capacity of the RoboANKLE is 10% more than the natural
power during the gait cycle.

</details>


### [174] [Towards Adaptable Humanoid Control via Adaptive Motion Tracking](https://arxiv.org/abs/2510.14454)
*Tao Huang,Huayi Wang,Junli Ren,Kangning Yin,Zirui Wang,Xiao Chen,Feiyu Jia,Wentao Zhang,Junfeng Long,Jingbo Wang,Jiangmiao Pang*

Main category: cs.RO

TL;DR: AdaMimic是一种新型运动跟踪算法，结合运动先验和跟踪方法的优点，实现从单一参考运动中生成高精度且适应性强的仿人机器人控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有运动先验方法牺牲模仿精度而运动跟踪方法需要大量训练数据的问题。

Method: 该方法首先通过稀疏化单一参考运动为关键帧并应用轻量编辑创建增强数据集，然后通过跟踪这些稀疏关键帧生成密集中间运动初始化策略，最后训练适配器调整跟踪速度和细化低级动作。

Result: 在模拟和真实世界的Unitree G1仿人机器人上验证了AdaMimic在多种任务和广泛适应条件下的显著改进。

Conclusion: AdaMimic通过结合运动先验和运动跟踪方法的优势，实现了从单一参考运动中生成高精度且适应性强的仿人机器人控制策略。

Abstract: Humanoid robots are envisioned to adapt demonstrated motions to diverse
real-world conditions while accurately preserving motion patterns. Existing
motion prior approaches enable well adaptability with a few motions but often
sacrifice imitation accuracy, whereas motion-tracking methods achieve accurate
imitation yet require many training motions and a test-time target motion to
adapt. To combine their strengths, we introduce AdaMimic, a novel motion
tracking algorithm that enables adaptable humanoid control from a single
reference motion. To reduce data dependence while ensuring adaptability, our
method first creates an augmented dataset by sparsifying the single reference
motion into keyframes and applying light editing with minimal physical
assumptions. A policy is then initialized by tracking these sparse keyframes to
generate dense intermediate motions, and adapters are subsequently trained to
adjust tracking speed and refine low-level actions based on the adjustment,
enabling flexible time warping that further improves imitation accuracy and
adaptability. We validate these significant improvements in our approach in
both simulation and the real-world Unitree G1 humanoid robot in multiple tasks
across a wide range of adaptation conditions. Videos and code are available at
https://taohuang13.github.io/adamimic.github.io/.

</details>


### [175] [Restoring Noisy Demonstration for Imitation Learning With Diffusion Models](https://arxiv.org/abs/2510.14467)
*Shang-Fu Chen,Co Yong,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 提出过滤与恢复框架，有效处理噪声专家演示，在多种任务中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有模仿学习算法假设专家演示完美，而实际演示常因人为或系统误差包含噪声的问题。

Method: 采用先过滤干净样本再学习条件扩散模型恢复噪声样本的两阶段框架。

Result: 在机器人手臂操作、灵巧操作和移动等任务中，该框架均优于现有方法，且对不同类型的噪声表现出鲁棒性。

Conclusion: 该论文提出的过滤与恢复框架有效提升了从含有噪声的专家演示中学习策略的性能，并在多种任务中验证了其优越性和鲁棒性。

Abstract: Imitation learning (IL) aims to learn a policy from expert demonstrations and
has been applied to various applications. By learning from the expert policy,
IL methods do not require environmental interactions or reward signals.
However, most existing imitation learning algorithms assume perfect expert
demonstrations, but expert demonstrations often contain imperfections caused by
errors from human experts or sensor/control system inaccuracies. To address the
above problems, this work proposes a filter-and-restore framework to best
leverage expert demonstrations with inherent noise. Our proposed method first
filters clean samples from the demonstrations and then learns conditional
diffusion models to recover the noisy ones. We evaluate our proposed framework
and existing methods in various domains, including robot arm manipulation,
dexterous manipulation, and locomotion. The experiment results show that our
proposed framework consistently outperforms existing methods across all the
tasks. Ablation studies further validate the effectiveness of each component
and demonstrate the framework's robustness to different noise types and levels.
These results confirm the practical applicability of our framework to noisy
offline demonstration data.

</details>


### [176] [Stability Criteria and Motor Performance in Delayed Haptic Dyadic Interactions Mediated by Robots](https://arxiv.org/abs/2510.14511)
*Mingtian Du,Suhas Raghavendra Kulkarni,Simone Kager,Domenico Campolo*

Main category: cs.RO

TL;DR: 该论文通过频域分析和模拟，确定了机器人介导双人交互系统的稳定性标准，发现刚度增加会非线性减少可容忍延迟，为远程系统设计提供了指导。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在网络引起的时延下，触觉通信系统的稳定性问题。

Method: 通过频域分析和数值模拟，确定了与延迟无关和与延迟相关的稳定性标准。

Result: 研究发现，刚度的增加会以非线性方式减少最大可容忍延迟，从而增加系统的不稳定性。实验进一步验证了稳定性与运动性能之间的相关性。

Conclusion: 该论文提出了机器人介导的人类-人类（双人）交互系统的稳定性标准，为远程双人系统的设计提供了指导原则，并指出了有效延迟补偿策略的先决条件。

Abstract: This paper establishes analytical stability criteria for robot-mediated
human-human (dyadic) interaction systems, focusing on haptic communication
under network-induced time delays. Through frequency-domain analysis supported
by numerical simulations, we identify both delay-independent and
delay-dependent stability criteria. The delay-independent criterion guarantees
stability irrespective of the delay, whereas the delay-dependent criterion is
characterised by a maximum tolerable delay before instability occurs. The
criteria demonstrate dependence on controller and robot dynamic parameters,
where increasing stiffness reduces the maximum tolerable delay in a non-linear
manner, thereby heightening system vulnerability. The proposed criteria can be
generalised to a wide range of robot-mediated interactions and serve as design
guidelines for stable remote dyadic systems. Experiments with robots performing
human-like movements further illustrate the correlation between stability and
motor performance. The findings of this paper suggest the prerequisites for
effective delay-compensation strategies.

</details>


### [177] [QuASH: Using Natural-Language Heuristics to Query Visual-Language Robotic Maps](https://arxiv.org/abs/2510.14546)
*Matti Pekkanen,Francesco Verdoja,Ville Kyrki*

Main category: cs.RO

TL;DR: 该论文提出了一种基于自然语言同义词和反义词的方法，通过嵌入空间训练分类器，提高了地图和图像的查询能力，且对表示和编码器通用。


<details>
  <summary>Details</summary>
Motivation: 传统的地图标签语义表示有限，无法满足开放词汇的场景理解需求。视觉语言模型的嵌入提供了更灵活的语义表示，但如何准确确定查询相关的环境部分仍是一个挑战。

Method: 利用自然语言同义词和反义词在嵌入空间中的关系，应用启发式方法估计查询相关的语言空间，并训练分类器来分区环境。

Result: 通过广泛实验评估，该方法显著提高了地图和标准图像基准的查询能力。

Conclusion: 该论文提出的方法通过利用自然语言同义词和反义词在嵌入空间中的关系，结合启发式方法估计查询相关的语言空间，并训练分类器来分区环境，显著提高了地图和图像的查询能力。该方法对表示和编码器具有通用性，且训练需求有限。

Abstract: Embeddings from Visual-Language Models are increasingly utilized to represent
semantics in robotic maps, offering an open-vocabulary scene understanding that
surpasses traditional, limited labels. Embeddings enable on-demand querying by
comparing embedded user text prompts to map embeddings via a similarity metric.
The key challenge in performing the task indicated in a query is that the robot
must determine the parts of the environment relevant to the query.
  This paper proposes a solution to this challenge. We leverage
natural-language synonyms and antonyms associated with the query within the
embedding space, applying heuristics to estimate the language space relevant to
the query, and use that to train a classifier to partition the environment into
matches and non-matches. We evaluate our method through extensive experiments,
querying both maps and standard image benchmarks. The results demonstrate
increased queryability of maps and images. Our querying technique is agnostic
to the representation and encoder used, and requires limited training.

</details>


### [178] [A Generalized Placeability Metric for Model-Free Unified Pick-and-Place Reasoning](https://arxiv.org/abs/2510.14584)
*Benno Wingender,Nils Dengler,Rohit Menon,Sicong Pan,Maren Bennewitz*

Main category: cs.RO

TL;DR: 提出一种直接从噪声点云评估放置姿态的通用可放置性度量方法，无需形状先验，实现抓取与放置的统一推理，在真实场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于强物体先验（如CAD模型）或平面支撑假设，限制了泛化能力和抓取与放置的统一推理。

Method: 通过从原始几何中提取物体的支撑表面，生成多方向放置的多样化候选，并采样满足碰撞和稳定性约束的接触点，结合抓取评分，选择稳定且无碰撞的抓取-放置对。

Result: 在未见过的真实物体和非平面支撑上，该方法在预测稳定性损失方面达到了与CAD相当的准确性，并通常产生比基于学习的预测器更物理合理的放置。

Conclusion: 该论文提出的通用可放置性度量方法能够直接从噪声点云中评估放置姿态，无需任何形状先验，实现了模型无关的抓取和放置统一推理，并在未见过的真实物体和非平面支撑上表现出色。

Abstract: To reliably pick and place unknown objects under real-world sensing noise
remains a challenging task, as existing methods rely on strong object priors
(e.g., CAD models), or planar-support assumptions, limiting generalization and
unified reasoning between grasping and placing. In this work, we introduce a
generalized placeability metric that evaluates placement poses directly from
noisy point clouds, without any shape priors. The metric jointly scores
stability, graspability, and clearance. From raw geometry, we extract the
support surfaces of the object to generate diverse candidates for
multi-orientation placement and sample contacts that satisfy collision and
stability constraints. By conditioning grasp scores on each candidate
placement, our proposed method enables model-free unified pick-and-place
reasoning and selects grasp-place pairs that lead to stable, collision-free
placements. On unseen real objects and non-planar object supports, our metric
delivers CAD-comparable accuracy in predicting stability loss and generally
produces more physically plausible placements than learning-based predictors.

</details>


### [179] [Proprioceptive Image: An Image Representation of Proprioceptive Data from Quadruped Robots for Contact Estimation Learning](https://arxiv.org/abs/2510.14612)
*Gabriel Fischer Abati,João Carlos Virgolino Soares,Giulio Turrisi,Victor Barasuol,Claudio Semini*

Main category: cs.RO

TL;DR: 将四足机器人的本体感觉数据编码为二维图像，利用卷积神经网络提升接触状态估计的准确率至94.5%。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地学习四足机器人的运动相关任务，特别是接触状态估计，该方法旨在通过图像化表示捕捉信号间的相关性和步态依赖模式。

Method: 提出了一种新颖的方法，将四足机器人的本体感觉时间序列数据（如关节位置、IMU读数和足部速度）编码为结构化二维图像，利用卷积神经网络进行学习。

Result: 实验表明，基于图像的表示方法在真实世界和模拟环境中均显著提升了预测准确性和泛化能力，接触状态准确率从87.7%提升至94.5%。

Conclusion: 通过将四足机器人的本体感觉时间序列数据编码为结构化二维图像，该方法显著提升了接触状态估计的准确性和泛化能力，展示了跨模态编码策略在机器人状态学习中的潜力。

Abstract: This paper presents a novel approach for representing proprioceptive
time-series data from quadruped robots as structured two-dimensional images,
enabling the use of convolutional neural networks for learning
locomotion-related tasks. The proposed method encodes temporal dynamics from
multiple proprioceptive signals, such as joint positions, IMU readings, and
foot velocities, while preserving the robot's morphological structure in the
spatial arrangement of the image. This transformation captures inter-signal
correlations and gait-dependent patterns, providing a richer feature space than
direct time-series processing. We apply this concept in the problem of contact
estimation, a key capability for stable and adaptive locomotion on diverse
terrains. Experimental evaluations on both real-world datasets and simulated
environments show that our image-based representation consistently enhances
prediction accuracy and generalization over conventional sequence-based models,
underscoring the potential of cross-modal encoding strategies for robotic state
learning. Our method achieves superior performance on the contact dataset,
improving contact state accuracy from 87.7% to 94.5% over the recently proposed
MI-HGNN method, using a 15 times shorter window size.

</details>


### [180] [Accelerated Multi-Modal Motion Planning Using Context-Conditioned Diffusion Models](https://arxiv.org/abs/2510.14615)
*Edward Sandra,Lander Vanroye,Dries Dirckx,Ruben Cartuyvels,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: CAMPD 是一种基于扩散模型的运动规划方法，通过上下文感知和注意力机制实现多环境泛化，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统机器人运动规划方法在高维状态空间和复杂环境中扩展性不足，而现有扩散模型方法多局限于单一环境或依赖特定传感器。

Method: CAMPD 利用无分类器去噪概率扩散模型，基于传感器无关的上下文信息进行条件化，并在 U-Net 架构中集成注意力机制以处理任意数量的上下文参数。

Result: CAMPD 在 7-DoF 机器人操纵器上进行了评估，并在真实任务中与最先进方法进行了对比，证明了其优越性。

Conclusion: CAMPD 展示出在未见环境中泛化的能力，并能生成高质量、多模态轨迹，且耗时仅为现有方法的一小部分。

Abstract: Classical methods in robot motion planning, such as sampling-based and
optimization-based methods, often struggle with scalability towards
higher-dimensional state spaces and complex environments. Diffusion models,
known for their capability to learn complex, high-dimensional and multi-modal
data distributions, provide a promising alternative when applied to motion
planning problems and have already shown interesting results. However, most of
the current approaches train their model for a single environment, limiting
their generalization to environments not seen during training. The techniques
that do train a model for multiple environments rely on a specific camera to
provide the model with the necessary environmental information and therefore
always require that sensor. To effectively adapt to diverse scenarios without
the need for retraining, this research proposes Context-Aware Motion Planning
Diffusion (CAMPD). CAMPD leverages a classifier-free denoising probabilistic
diffusion model, conditioned on sensor-agnostic contextual information. An
attention mechanism, integrated in the well-known U-Net architecture,
conditions the model on an arbitrary number of contextual parameters. CAMPD is
evaluated on a 7-DoF robot manipulator and benchmarked against state-of-the-art
approaches on real-world tasks, showing its ability to generalize to unseen
environments and generate high-quality, multi-modal trajectories, at a fraction
of the time required by existing methods.

</details>


### [181] [GOPLA: Generalizable Object Placement Learning via Synthetic Augmentation of Human Arrangement](https://arxiv.org/abs/2510.14627)
*Yao Zhong,Hanzhi Chen,Simon Schaefer,Anran Zhang,Stefan Leutenegger*

Main category: cs.RO

TL;DR: GOPLA框架通过多模态语言模型和扩散式规划器，结合合成数据训练，显著提升机器人物体放置的成功率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决机器人作为智能助手在家庭环境中物体放置任务中的挑战，包括语义偏好和几何可行性的双重需求。

Method: GOPLA采用分层框架，包括多模态大语言模型生成结构化计划、空间映射器生成3D可操作地图，以及扩散式规划器生成放置姿态。此外，通过扩展人类演示数据生成多样化合成训练数据。

Result: 实验表明，GOPLA在放置成功率上比第二名提高了30.04个百分点，定位准确性和物理合理性均有显著提升。

Conclusion: GOPLA框架通过结合语义偏好和几何可行性，显著提升了物体放置的成功率，并在广泛的实际机器人放置场景中展现出强大的泛化能力。

Abstract: Robots are expected to serve as intelligent assistants, helping humans with
everyday household organization. A central challenge in this setting is the
task of object placement, which requires reasoning about both semantic
preferences (e.g., common-sense object relations) and geometric feasibility
(e.g., collision avoidance). We present GOPLA, a hierarchical framework that
learns generalizable object placement from augmented human demonstrations. A
multi-modal large language model translates human instructions and visual
inputs into structured plans that specify pairwise object relationships. These
plans are then converted into 3D affordance maps with geometric common sense by
a spatial mapper, while a diffusion-based planner generates placement poses
guided by test-time costs, considering multi-plan distributions and collision
avoidance. To overcome data scarcity, we introduce a scalable pipeline that
expands human placement demonstrations into diverse synthetic training data.
Extensive experiments show that our approach improves placement success rates
by 30.04 percentage points over the runner-up, evaluated on positioning
accuracy and physical plausibility, demonstrating strong generalization across
a wide range of real-world robotic placement scenarios.

</details>


### [182] [Generative Models From and For Sampling-Based MPC: A Bootstrapped Approach For Adaptive Contact-Rich Manipulation](https://arxiv.org/abs/2510.14643)
*Lara Brudermüller,Brandon Hung,Xinghao Zhu,Jiuguang Wang,Nick Hawes,Preston Culbertson,Simon Le Cleac'h*

Main category: cs.RO

TL;DR: GPC框架通过训练条件流匹配模型优化SPC控制序列，显著提升采样效率和规划速度，首次成功应用于四足机器人的复杂操作任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统基于迭代优化或梯度求解器的采样效率低和规划时间长的问题，作者提出了直接从噪声SPC数据中学习提案分布的方法。

Method: 提出了一种生成预测控制（GPC）框架，通过条件流匹配模型对SPC控制序列进行训练，从而在在线规划时实现更高效的采样。

Result: 实验表明，该方法在仿真和硬件上均提高了采样效率，减少了规划时间要求，并在任务变化中表现出鲁棒性。

Conclusion: GPC框架通过直接从噪声SPC数据中学习有意义的提案分布，显著提高了在线规划时的采样效率和信息量，并在四足机器人的实际接触丰富操作中首次应用成功。

Abstract: We present a generative predictive control (GPC) framework that amortizes
sampling-based Model Predictive Control (SPC) by bootstrapping it with
conditional flow-matching models trained on SPC control sequences collected in
simulation. Unlike prior work relying on iterative refinement or gradient-based
solvers, we show that meaningful proposal distributions can be learned directly
from noisy SPC data, enabling more efficient and informed sampling during
online planning. We further demonstrate, for the first time, the application of
this approach to real-world contact-rich loco-manipulation with a quadruped
robot. Extensive experiments in simulation and on hardware show that our method
improves sample efficiency, reduces planning horizon requirements, and
generalizes robustly across task variations.

</details>


### [183] [Spatially anchored Tactile Awareness for Robust Dexterous Manipulation](https://arxiv.org/abs/2510.14647)
*Jialei Huang,Yang Ye,Yuanqing Gong,Xuezhou Zhu,Yang Gao,Kaifeng Zhang*

Main category: cs.RO

TL;DR: SaTA通过空间锚定触觉特征，显著提升灵巧操作的精确度和效率，适用于高精度任务如USB-C插接和灯泡安装。


<details>
  <summary>Details</summary>
Motivation: 现有视觉触觉学习方法在亚毫米级精度任务中表现不佳，无法有效利用触觉信号的感知丰富性及其与手运动学的空间关系。

Method: SaTA是一种端到端的策略框架，通过前向运动学将触觉特征显式地锚定在手的运动学框架中，无需对象模型或显式姿态估计即可实现精确的几何推理。

Result: 在多个基准测试中，SaTA显著优于强视觉触觉基线，成功率提高了30%，任务完成时间减少了27%。

Conclusion: SaTA框架通过将触觉特征显式地锚定在手的运动学框架中，显著提高了灵巧操作的精确度和成功率，特别是在需要亚毫米级精度的任务中。

Abstract: Dexterous manipulation requires precise geometric reasoning, yet existing
visuo-tactile learning methods struggle with sub-millimeter precision tasks
that are routine for traditional model-based approaches. We identify a key
limitation: while tactile sensors provide rich contact information, current
learning frameworks fail to effectively leverage both the perceptual richness
of tactile signals and their spatial relationship with hand kinematics. We
believe an ideal tactile representation should explicitly ground contact
measurements in a stable reference frame while preserving detailed sensory
information, enabling policies to not only detect contact occurrence but also
precisely infer object geometry in the hand's coordinate system. We introduce
SaTA (Spatially-anchored Tactile Awareness for dexterous manipulation), an
end-to-end policy framework that explicitly anchors tactile features to the
hand's kinematic frame through forward kinematics, enabling accurate geometric
reasoning without requiring object models or explicit pose estimation. Our key
insight is that spatially grounded tactile representations allow policies to
not only detect contact occurrence but also precisely infer object geometry in
the hand's coordinate system. We validate SaTA on challenging dexterous
manipulation tasks, including bimanual USB-C mating in free space, a task
demanding sub-millimeter alignment precision, as well as light bulb
installation requiring precise thread engagement and rotational control, and
card sliding that demands delicate force modulation and angular precision.
These tasks represent significant challenges for learning-based methods due to
their stringent precision requirements. Across multiple benchmarks, SaTA
significantly outperforms strong visuo-tactile baselines, improving success
rates by up to 30 percentage while reducing task completion times by 27
percentage.

</details>


### [184] [When Planners Meet Reality: How Learned, Reactive Traffic Agents Shift nuPlan Benchmarks](https://arxiv.org/abs/2510.14677)
*Steffen Hagedorn,Luka Donkov,Aron Distelzweig,Alexandru P. Condurache*

Main category: cs.RO

TL;DR: 研究通过集成SMART代理到nuPlan，揭示了传统IDM仿真高估规划性能的问题，并展示了学习型方法在交互场景中的优势。


<details>
  <summary>Details</summary>
Motivation: 传统的基于规则的交通代理（如IDM）行为简单且被动，可能掩盖规划器的缺陷并导致排名偏差，无法测试复杂的交互能力。

Method: 通过将最先进的学习型交通代理模型SMART集成到nuPlan中，评估了14种近期规划器和基线在更现实条件下的表现。

Result: IDM仿真高估了规划性能：几乎所有评分下降。相反，许多规划器在交互密集场景（如变道或转弯）中表现优于预期。学习型方法在闭环训练中表现最佳且最稳定，但在极端情况下会突然退化。

Conclusion: 作者建议将SMART-reactive仿真作为nuPlan中新的标准闭环基准，并发布了SMART代理作为IDM的直接替代方案。

Abstract: Planner evaluation in closed-loop simulation often uses rule-based traffic
agents, whose simplistic and passive behavior can hide planner deficiencies and
bias rankings. Widely used IDM agents simply follow a lead vehicle and cannot
react to vehicles in adjacent lanes, hindering tests of complex interaction
capabilities. We address this issue by integrating the state-of-the-art learned
traffic agent model SMART into nuPlan. Thus, we are the first to evaluate
planners under more realistic conditions and quantify how conclusions shift
when narrowing the sim-to-real gap. Our analysis covers 14 recent planners and
established baselines and shows that IDM-based simulation overestimates
planning performance: nearly all scores deteriorate. In contrast, many planners
interact better than previously assumed and even improve in multi-lane,
interaction-heavy scenarios like lane changes or turns. Methods trained in
closed-loop demonstrate the best and most stable driving performance. However,
when reaching their limits in augmented edge-case scenarios, all learned
planners degrade abruptly, whereas rule-based planners maintain reasonable
basic behavior. Based on our results, we suggest SMART-reactive simulation as a
new standard closed-loop benchmark in nuPlan and release the SMART agents as a
drop-in alternative to IDM at https://github.com/shgd95/InteractiveClosedLoop.

</details>


### [185] [Leveraging Neural Descriptor Fields for Learning Contact-Aware Dynamic Recovery](https://arxiv.org/abs/2510.14768)
*Fan Yang,Zixuan Huang,Abhinav Kumar,Sergio Aguilera Marinovic,Soshi Iba,Rana Soltani Zarrin,Dmitry Berenson*

Main category: cs.RO

TL;DR: CADRE框架通过接触感知特征增强强化学习，提升了对意外干扰的恢复能力，并能泛化到新物体。


<details>
  <summary>Details</summary>
Motivation: 现实世界中灵巧操作常因意外干扰导致失败（如掉落物体），需要一种能快速恢复并继续主任务的方法。

Method: 提出了一种名为CADRE的强化学习框架，结合了神经描述符场（NDF）模块来提取隐式接触特征。

Result: 实验表明，接触特征的引入提升了训练效率、收敛性能和恢复成功率，并能零样本泛化到新物体。

Conclusion: CADRE通过结合接触感知特征和强化学习框架，显著提高了对意外干扰的恢复能力，并能零样本泛化到不同几何形状的未见过物体。

Abstract: Real-world dexterous manipulation often encounters unexpected errors and
disturbances, which can lead to catastrophic failures, such as dropping the
manipulated object. To address this challenge, we focus on the problem of
catching a falling object while it remains within grasping range and,
importantly, resetting the system to a configuration favorable for resuming the
primary manipulation task. We propose Contact-Aware Dynamic Recovery (CADRE), a
reinforcement learning framework that incorporates a Neural Descriptor Field
(NDF)-inspired module to extract implicit contact features. Compared to methods
that rely solely on object pose or point cloud input, NDFs can directly reason
about finger-object correspondence and adapt to different object geometries.
Our experiments show that incorporating contact features improves training
efficiency, enhances convergence performance for RL training, and ultimately
leads to more successful recoveries. Additionally, we demonstrate that CADRE
can generalize zero-shot to unseen objects with different geometries.

</details>


### [186] [Open TeleDex: A Hardware-Agnostic Teleoperation System for Imitation Learning based Dexterous Manipulation](https://arxiv.org/abs/2510.14771)
*Xu Chi,Chao Zhang,Yang Su,Lingfeng Dou,Fujia Yang,Jiakuo Zhao,Haoyu Zhou,Xiaoyou Jia,Yong Zhou,Shan An*

Main category: cs.RO

TL;DR: Open TeleDex 是一个统一的远程操作框架，解决了异构机器人平台高精度数据获取的瓶颈，支持多种设备，并提出了提升互操作性的新算法。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人平台在模仿学习中高精度演示数据获取的瓶颈问题。

Method: 开发了 Open TeleDex 这一统一的远程操作框架，并提出了新的手部姿态重定向算法。

Result: Open TeleDex 成功解决了 TripleAny 挑战，支持任何机械臂、灵巧手和外部输入设备，并通过新算法提升了其互操作性。

Conclusion: Open TeleDex 提供了一个高质量、公开可用的平台，显著促进了复杂机器人操作和模仿学习的学术研究与工业发展。

Abstract: Accurate and high-fidelity demonstration data acquisition is a critical
bottleneck for deploying robot Imitation Learning (IL) systems, particularly
when dealing with heterogeneous robotic platforms. Existing teleoperation
systems often fail to guarantee high-precision data collection across diverse
types of teleoperation devices. To address this, we developed Open TeleDex, a
unified teleoperation framework engineered for demonstration data collection.
Open TeleDex specifically tackles the TripleAny challenge, seamlessly
supporting any robotic arm, any dexterous hand, and any external input device.
Furthermore, we propose a novel hand pose retargeting algorithm that
significantly boosts the interoperability of Open TeleDex, enabling robust and
accurate compatibility with an even wider spectrum of heterogeneous master and
slave equipment. Open TeleDex establishes a foundational, high-quality, and
publicly available platform for accelerating both academic research and
industry development in complex robotic manipulation and IL.

</details>


### [187] [SkyDreamer: Interpretable End-to-End Vision-Based Drone Racing with Model-Based Reinforcement Learning](https://arxiv.org/abs/2510.14783)
*Aderik Verraest,Stavrow Bahnam,Robin Ferede,Guido de Croon,Christophe De Wagter*

Main category: cs.RO

TL;DR: SkyDreamer是首个端到端视觉自主无人机竞速策略，通过模型强化学习实现全模拟到现实转移、机载执行和冠军级性能，适应性强且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有自主无人机竞速系统虽达到冠军水平，但适用范围有限。端到端视觉方法虽具广泛适用潜力，但尚未实现全模拟到现实转移、机载执行和冠军级性能的同步。

Method: SkyDreamer基于informed Dreamer，一种模型强化学习方法，其世界模型解码为仅在训练期间可用的特权信息，并扩展到端到端视觉自主无人机竞速策略。

Result: SkyDreamer实现了稳健的高速飞行，执行包括倒飞环、分裂-S和梯子等紧凑动作，速度达21 m/s，加速度达6 g，并展示了非平凡的视觉模拟到现实转移能力。

Conclusion: SkyDreamer展示了在视觉模拟到现实转移中的非平凡能力，能够在低质量分割掩码上操作，并通过实时调整飞行路径适应电池消耗，实现了高速、敏捷飞行的同时保持鲁棒性。

Abstract: Autonomous drone racing (ADR) systems have recently achieved champion-level
performance, yet remain highly specific to drone racing. While end-to-end
vision-based methods promise broader applicability, no system to date
simultaneously achieves full sim-to-real transfer, onboard execution, and
champion-level performance. In this work, we present SkyDreamer, to the best of
our knowledge, the first end-to-end vision-based ADR policy that maps directly
from pixel-level representations to motor commands. SkyDreamer builds on
informed Dreamer, a model-based reinforcement learning approach where the world
model decodes to privileged information only available during training. By
extending this concept to end-to-end vision-based ADR, the world model
effectively functions as an implicit state and parameter estimator, greatly
improving interpretability. SkyDreamer runs fully onboard without external aid,
resolves visual ambiguities by tracking progress using the state decoded from
the world model's hidden state, and requires no extrinsic camera calibration,
enabling rapid deployment across different drones without retraining.
Real-world experiments show that SkyDreamer achieves robust, high-speed flight,
executing tight maneuvers such as an inverted loop, a split-S and a ladder,
reaching speeds of up to 21 m/s and accelerations of up to 6 g. It further
demonstrates a non-trivial visual sim-to-real transfer by operating on
poor-quality segmentation masks, and exhibits robustness to battery depletion
by accurately estimating the maximum attainable motor RPM and adjusting its
flight path in real-time. These results highlight SkyDreamer's adaptability to
important aspects of the reality gap, bringing robustness while still achieving
extremely high-speed, agile flight.

</details>


### [188] [Neural Implicit Flow Fields for Spatio-Temporal Motion Mapping](https://arxiv.org/abs/2510.14827)
*Yufei Zhu,Shih-Min Yang,Andrey Rudenko,Tomasz P. Kucner,Achim J. Lilienthal,Martin Magnusson*

Main category: cs.RO

TL;DR: 提出了一种基于隐式神经函数的连续时空MoD表示方法，能够更准确地建模人类运动模式，并在计算效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了在复杂人类环境中实现安全高效的机器人操作，需要更好的特定场景运动模式模型。

Method: 使用隐式神经函数直接映射坐标到半包裹高斯混合模型参数，避免了离散化和不均匀采样区域的插值需求。

Result: 在大型公共数据集上的评估显示，该方法在运动表示准确性和稀疏区域速度分布的平滑性方面优于现有基线，同时保持计算效率。

Conclusion: 该论文提出了一种基于隐式神经函数的连续时空MoD表示方法，能够有效建模复杂的人类运动模式，具有更高的准确性和计算效率。

Abstract: Safe and efficient robot operation in complex human environments can benefit
from good models of site-specific motion patterns. Maps of Dynamics (MoDs)
provide such models by encoding statistical motion patterns in a map, but
existing representations use discrete spatial sampling and typically require
costly offline construction. We propose a continuous spatio-temporal MoD
representation based on implicit neural functions that directly map coordinates
to the parameters of a Semi-Wrapped Gaussian Mixture Model. This removes the
need for discretization and imputation for unevenly sampled regions, enabling
smooth generalization across both space and time. Evaluated on a large public
dataset with long-term real-world people tracking data, our method achieves
better accuracy of motion representation and smoother velocity distributions in
sparse regions while still being computationally efficient, compared to
available baselines. The proposed approach demonstrates a powerful and
efficient way of modeling complex human motion patterns.

</details>


### [189] [RL-100: Performant Robotic Manipulation with Real-World Reinforcement Learning](https://arxiv.org/abs/2510.14830)
*Kun Lei,Huanyu Li,Dongjie Yu,Zhenyu Wei,Lingxiao Guo,Zhennan Jiang,Ziyu Wang,Shiyu Liang,Huazhe Xu*

Main category: cs.RO

TL;DR: RL-100是一个三阶段强化学习框架，通过模仿学习、离线/在线强化学习实现高成功率，适用于多种机器人任务，表现优于人类操作员。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中机器人操作对可靠性、效率和鲁棒性的需求，以接近或超越人类操作员的水平。

Method: RL-100采用基于扩散视觉运动策略的三阶段训练流程：模仿学习、离线强化学习（通过OPE门控PPO更新）和在线强化学习，并结合一致性蒸馏头降低延迟。

Result: 在7项真实机器人任务中，RL-100实现了900次试验中的100%成功率，包括单任务连续250次成功，并展示了多小时的持续操作能力。

Conclusion: RL-100框架通过三阶段训练流程（模仿学习、离线强化学习和在线强化学习）实现了高成功率和鲁棒性，适用于多种任务和机器人平台。

Abstract: Real-world robotic manipulation in homes and factories demands reliability,
efficiency, and robustness that approach or surpass skilled human operators. We
present RL-100, a real-world reinforcement learning training framework built on
diffusion visuomotor policies trained bu supervised learning. RL-100 introduces
a three-stage pipeline. First, imitation learning leverages human priors.
Second, iterative offline reinforcement learning uses an Offline Policy
Evaluation procedure, abbreviated OPE, to gate PPO-style updates that are
applied in the denoising process for conservative and reliable improvement.
Third, online reinforcement learning eliminates residual failure modes. An
additional lightweight consistency distillation head compresses the multi-step
sampling process in diffusion into a single-step policy, enabling
high-frequency control with an order-of-magnitude reduction in latency while
preserving task performance. The framework is task-, embodiment-, and
representation-agnostic and supports both 3D point clouds and 2D RGB inputs, a
variety of robot platforms, and both single-step and action-chunk policies. We
evaluate RL-100 on seven real-robot tasks spanning dynamic rigid-body control,
such as Push-T and Agile Bowling, fluids and granular pouring, deformable cloth
folding, precise dexterous unscrewing, and multi-stage orange juicing. RL-100
attains 100\% success across evaluated trials for a total of 900 out of 900
episodes, including up to 250 out of 250 consecutive trials on one task. The
method achieves near-human teleoperation or better time efficiency and
demonstrates multi-hour robustness with uninterrupted operation lasting up to
two hours.

</details>


### [190] [Multi Agent Switching Mode Controller for Sound Source localization](https://arxiv.org/abs/2510.14849)
*Marcello Sorge,Nicola Cigarini,Riccardo Lorigiola,Giulia Michieletto,Andrea Masiero,Angelo Cenedese,Alberto Guarnieri*

Main category: cs.RO

TL;DR: 本文提出了一种多智能体切换模式控制策略，用于声学目标定位，验证了其在单源和多源场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 声学传感器在视线受阻等关键条件下仍能定位目标，因此研究基于声学的目标定位具有重要意义。

Method: 设计了多智能体切换模式控制策略，包括单源定位（保持刚性编队）和多源定位（各智能体独立搜索）。

Result: 在单源和多源场景下，所提出的控制策略均能有效实现目标定位。

Conclusion: 本文提出了一种多智能体切换模式控制策略，适用于声学目标定位。通过单源和多源两种场景的验证，证明了该策略的有效性和灵活性。

Abstract: Source seeking is an important topic in robotic research, especially
considering sound-based sensors since they allow the agents to locate a target
even in critical conditions where it is not possible to establish a direct line
of sight. In this work, we design a multi- agent switching mode control
strategy for acoustic-based target localization. Two scenarios are considered:
single source localization, in which the agents are driven maintaining a rigid
formation towards the target, and multi-source scenario, in which each agent
searches for the targets independently from the others.

</details>


### [191] [SADCHER: Scheduling using Attention-based Dynamic Coalitions of Heterogeneous Robots in Real-Time](https://arxiv.org/abs/2510.14851)
*Jakob Bichler,Andreu Matoses Gimenez,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: Sadcher是一个异构多机器人任务分配框架，通过动态联盟和任务优先级约束，结合图注意力和变换器实现高效调度，优于现有方法并支持实时操作。


<details>
  <summary>Details</summary>
Motivation: 解决异构多机器人团队在动态环境中任务分配的挑战，特别是时空分布变化时的泛化能力。

Method: 结合模仿学习、图注意力和变换器预测分配奖励，通过松弛二分匹配生成高质量调度方案。

Result: 在随机未见问题上，Sadcher优于其他基于学习和启发式的方法，适用于中小型团队，并具备实时计算能力。

Conclusion: Sadcher框架在异构多机器人团队中实现了高效的任务分配，通过动态联盟形成和任务优先级约束，结合图注意力和变换器预测分配奖励，并在实时操作中表现出色。

Abstract: We present Sadcher, a real-time task assignment framework for heterogeneous
multi-robot teams that incorporates dynamic coalition formation and task
precedence constraints. Sadcher is trained through Imitation Learning and
combines graph attention and transformers to predict assignment rewards between
robots and tasks. Based on the predicted rewards, a relaxed bipartite matching
step generates high-quality schedules with feasibility guarantees. We
explicitly model robot and task positions, task durations, and robots'
remaining processing times, enabling advanced temporal and spatial reasoning
and generalization to environments with different spatiotemporal distributions
compared to training. Trained on optimally solved small-scale instances, our
method can scale to larger task sets and team sizes. Sadcher outperforms other
learning-based and heuristic baselines on randomized, unseen problems for small
and medium-sized teams with computation times suitable for real-time operation.
We also explore sampling-based variants and evaluate scalability across robot
and task counts. In addition, we release our dataset of 250,000 optimal
schedules: https://autonomousrobots.nl/paper_websites/sadcher_MRTA/

</details>


### [192] [STITCHER: Constrained Trajectory Planning in Known Environments with Real-Time Motion Primitive Search](https://arxiv.org/abs/2510.14893)
*Helene J. Levy,Brett T. Lopez*

Main category: cs.RO

TL;DR: STITCHER是一种实时无优化轨迹规划框架，通过图搜索拼接短轨迹段，优于传统优化方法，适用于复杂环境。


<details>
  <summary>Details</summary>
Motivation: 现有基于优化的轨迹规划技术在实时性和数值稳定性方面存在局限，难以满足安全关键场景的需求。

Method: STITCHER采用无优化规划框架，通过图搜索将短轨迹段拼接成长距离轨迹。

Result: 仿真测试表明，STITCHER能在几毫秒内为50m x 50m环境生成安全轨迹。硬件测试验证了其实时处理非凸约束的能力。

Conclusion: STITCHER框架通过创新的规划架构和算法发展，实现了实时生成动态可行、无碰撞且满足约束的长距离轨迹，优于现代基于优化的规划器。

Abstract: Autonomous high-speed navigation through large, complex environments requires
real-time generation of agile trajectories that are dynamically feasible,
collision-free, and satisfy state or actuator constraints. Modern trajectory
planning techniques primarily use numerical optimization, as they enable the
systematic computation of high-quality, expressive trajectories that satisfy
various constraints. However, stringent requirements on computation time and
the risk of numerical instability can limit the use of optimization-based
planners in safety-critical scenarios. This work presents an optimization-free
planning framework called STITCHER that stitches short trajectory segments
together with graph search to compute long-range, expressive, and near-optimal
trajectories in real-time. STITCHER outperforms modern optimization-based
planners through our innovative planning architecture and several algorithmic
developments that make real-time planning possible. Extensive simulation
testing is performed to analyze the algorithmic components that make up
STITCHER, along with a thorough comparison with two state-of-the-art
optimization planners. Simulation tests show that safe trajectories can be
created within a few milliseconds for paths that span the entirety of two 50 m
x 50 m environments. Hardware tests with a custom quadrotor verify that
STITCHER can produce trackable paths in real-time while respecting nonconvex
constraints, such as limits on tilt angle and motor forces, which are otherwise
hard to include in optimization-based planners.

</details>


### [193] [VLA^2: Empowering Vision-Language-Action Models with an Agentic Framework for Unseen Concept Manipulation](https://arxiv.org/abs/2510.14902)
*Han Zhao,Jiaxuan Zhang,Wenxuan Song,Pengxiang Ding,Donglin Wang*

Main category: cs.RO

TL;DR: VLA^2通过整合外部知识模块，显著提升了处理未见对象的能力，在硬级别测试中成功率高出现有方法44.2%。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在处理训练数据外的对象概念（如未见过的物体描述和纹理）时成功率显著下降。

Method: 提出VLA^2框架，基于OpenVLA执行骨干，结合外部模块（如网络检索和物体检测）提供目标对象的视觉和文本知识。

Result: 在LIBERO仿真环境中构建的新评估基准上，VLA^2在硬级别基准测试中比OpenVLA基线提升了44.2%的成功率，且在所有定制环境中平均提升20.2%，同时不影响域内任务性能。

Conclusion: VLA^2框架通过整合外部模块（如网络检索和物体检测）显著提升了处理分布外对象的能力，且在保持原有任务性能的同时，在硬级别基准测试中实现了44.2%的成功率提升。

Abstract: Current vision-language-action (VLA) models, pre-trained on large-scale
robotic data, exhibit strong multi-task capabilities and generalize well to
variations in visual and language instructions for manipulation. However, their
success rate drops significantly when faced with object concepts outside the
training data, such as unseen object descriptions and textures in the dataset.
To address this, we propose a novel agentic framework, VLA^2, which leverages
OpenVLA as the execution backbone and effectively leverages external modules
such as web retrieval and object detection to provide visual and textual
knowledge about target objects to the VLA. This approach mitigates
generalization failure when handling out-of-distribution objects. Based on the
LIBERO simulation environment, we introduced novel objects and object
descriptions to construct a new evaluation benchmark with three difficulty
levels to test the effectiveness of our method. Our framework successfully
outperformed the current state-of-the-art models on our designed hard-level
generalization benchmark. Compared to the standalone OpenVLA baseline, VLA^2
achieves a 44.2% improvement in the success rate in the hard-level benchmark
and an average improvement of 20.2% in all customized environments without any
performance degradation on in-domain tasks. Project website:
https://vla-2.github.io.

</details>


### [194] [VT-Refine: Learning Bimanual Assembly with Visuo-Tactile Feedback via Simulation Fine-Tunin](https://arxiv.org/abs/2510.14930)
*Binghao Huang,Jie Xu,Iretiayo Akinola,Wei Yang,Balakumar Sundaralingam,Rowland O'Flaherty,Dieter Fox,Xiaolong Wang,Arsalan Mousavian,Yu-Wei Chao,Yunzhu Li*

Main category: cs.RO

TL;DR: VT-Refine框架结合真实演示、触觉模拟和强化学习，提升双手机器人装配任务的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 人类通过丰富触觉反馈适应双手机器人装配任务，而仅通过行为克隆难以复制这种能力，因为人类演示的次优性和多样性有限。

Method: 采用扩散策略在少量演示上训练，利用同步视觉和触觉输入，随后转移到配备模拟触觉传感器的数字孪生环境中，通过大规模强化学习进行优化。

Result: 实验结果表明，VT-Refine通过增加数据多样性和更有效的策略微调，提升了模拟和现实世界中的装配性能。

Conclusion: VT-Refine通过结合真实世界演示、高保真触觉模拟和强化学习，显著提升了双手机器人装配任务的性能和泛化能力。

Abstract: Humans excel at bimanual assembly tasks by adapting to rich tactile feedback
-- a capability that remains difficult to replicate in robots through
behavioral cloning alone, due to the suboptimality and limited diversity of
human demonstrations. In this work, we present VT-Refine, a visuo-tactile
policy learning framework that combines real-world demonstrations,
high-fidelity tactile simulation, and reinforcement learning to tackle precise,
contact-rich bimanual assembly. We begin by training a diffusion policy on a
small set of demonstrations using synchronized visual and tactile inputs. This
policy is then transferred to a simulated digital twin equipped with simulated
tactile sensors and further refined via large-scale reinforcement learning to
enhance robustness and generalization. To enable accurate sim-to-real transfer,
we leverage high-resolution piezoresistive tactile sensors that provide normal
force signals and can be realistically modeled in parallel using
GPU-accelerated simulation. Experimental results show that VT-Refine improves
assembly performance in both simulation and the real world by increasing data
diversity and enabling more effective policy fine-tuning. Our project page is
available at https://binghao-huang.github.io/vt_refine/.

</details>


### [195] [Architecture Is All You Need: Diversity-Enabled Sweet Spots for Robust Humanoid Locomotion](https://arxiv.org/abs/2510.14947)
*Blake Werner,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 分层控制架构（LCA）通过时间尺度分离实现更稳健的人形运动，优于单阶段端到端设计。


<details>
  <summary>Details</summary>
Motivation: 在非结构化环境中实现稳健的人形运动需要平衡快速低层稳定与慢速感知决策的架构。

Method: 采用两阶段训练课程（先进行盲稳定器预训练，再进行感知微调），结合高速率的本体感受稳定器和低速率的紧凑感知策略。

Result: 在Unitree G1人形机器人上，分层策略在阶梯和边缘任务中表现优于单阶段感知策略。

Conclusion: 研究结果表明，通过分层控制架构（LCA）实现时间尺度的分离，而非网络规模或复杂性，是实现稳健感知条件运动的关键。

Abstract: Robust humanoid locomotion in unstructured environments requires
architectures that balance fast low-level stabilization with slower perceptual
decision-making. We show that a simple layered control architecture (LCA), a
proprioceptive stabilizer running at high rate, coupled with a compact low-rate
perceptual policy, enables substantially more robust performance than
monolithic end-to-end designs, even when using minimal perception encoders.
Through a two-stage training curriculum (blind stabilizer pretraining followed
by perceptual fine-tuning), we demonstrate that layered policies consistently
outperform one-stage alternatives in both simulation and hardware. On a Unitree
G1 humanoid, our approach succeeds across stair and ledge tasks where one-stage
perceptual policies fail. These results highlight that architectural separation
of timescales, rather than network scale or complexity, is the key enabler for
robust perception-conditioned locomotion.

</details>


### [196] [From Language to Locomotion: Retargeting-free Humanoid Control via Motion Latent Guidance](https://arxiv.org/abs/2510.14952)
*Zhe Li,Cheng Chi,Yangyang Wei,Boan Zhu,Yibo Peng,Tao Huang,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang,Chang Xu*

Main category: cs.RO

TL;DR: RoboGhost 是一种无需重定向的框架，直接通过语言基础的运动潜变量条件化人形策略，显著改善了运动控制的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有语言引导的人形机器人运动流程存在多阶段累积错误、高延迟和语义与控制弱耦合的问题，需要一种更直接的从语言到动作的路径。

Method: RoboGhost 采用了一种混合因果变换器-扩散运动生成器，绕过显式的运动解码和重定向，直接通过扩散策略从噪声中生成可执行动作，同时保持语义意图和快速反应控制。

Result: 实验表明，RoboGhost 显著减少了部署延迟，提高了成功率和跟踪精度，并在真实人形机器人上实现了平滑且语义对齐的运动。

Conclusion: RoboGhost 通过直接条件化人形策略于语言基础的运动潜变量，显著降低了部署延迟，提高了成功率和跟踪精度，并在真实人形机器人上实现了平滑且语义对齐的运动。

Abstract: Natural language offers a natural interface for humanoid robots, but existing
language-guided humanoid locomotion pipelines remain cumbersome and unreliable.
They typically decode human motion, retarget it to robot morphology, and then
track it with a physics-based controller. However, this multi-stage process is
prone to cumulative errors, introduces high latency, and yields weak coupling
between semantics and control. These limitations call for a more direct pathway
from language to action, one that eliminates fragile intermediate stages.
Therefore, we present RoboGhost, a retargeting-free framework that directly
conditions humanoid policies on language-grounded motion latents. By bypassing
explicit motion decoding and retargeting, RoboGhost enables a diffusion-based
policy to denoise executable actions directly from noise, preserving semantic
intent and supporting fast, reactive control. A hybrid causal
transformer-diffusion motion generator further ensures long-horizon consistency
while maintaining stability and diversity, yielding rich latent representations
for precise humanoid behavior. Extensive experiments demonstrate that RoboGhost
substantially reduces deployment latency, improves success rates and tracking
accuracy, and produces smooth, semantically aligned locomotion on real
humanoids. Beyond text, the framework naturally extends to other modalities
such as images, audio, and music, providing a general foundation for
vision-language-action humanoid systems.

</details>


### [197] [CBF-RL: Safety Filtering Reinforcement Learning in Training with Control Barrier Functions](https://arxiv.org/abs/2510.14959)
*Lizhi Yang,Blake Werner,Massimiliano de Sa Aaron D. Ames*

Main category: cs.RO

TL;DR: CBF-RL框架将CBFs整合到RL训练中，生成安全行为，无需在线安全过滤器，验证于导航任务和人形机器人。


<details>
  <summary>Details</summary>
Motivation: 强化学习（RL）在追求性能时可能忽视安全性，而安全违规可能导致严重后果。控制屏障函数（CBFs）提供了动态安全性的原则方法，但传统在线部署可能导致保守行为。

Method: CBF-RL框架通过两个关键步骤实现：(1)通过CBF项最小化修改名义RL策略以编码安全约束，(2)在训练期间对策略展开进行安全过滤。

Result: CBF-RL在导航任务和Unitree G1人形机器人上验证了其有效性，实现了更安全的探索、更快的收敛和鲁棒性能。

Conclusion: CBF-RL框架通过将CBFs整合到RL训练中，成功实现了安全行为的生成，无需在线安全过滤器即可安全部署。

Abstract: Reinforcement learning (RL), while powerful and expressive, can often
prioritize performance at the expense of safety. Yet safety violations can lead
to catastrophic outcomes in real-world deployments. Control Barrier Functions
(CBFs) offer a principled method to enforce dynamic safety -- traditionally
deployed \emph{online} via safety filters. While the result is safe behavior,
the fact that the RL policy does not have knowledge of the CBF can lead to
conservative behaviors. This paper proposes CBF-RL, a framework for generating
safe behaviors with RL by enforcing CBFs \emph{in training}. CBF-RL has two key
attributes: (1) minimally modifying a nominal RL policy to encode safety
constraints via a CBF term, (2) and safety filtering of the policy rollouts in
training. Theoretically, we prove that continuous-time safety filters can be
deployed via closed-form expressions on discrete-time roll-outs. Practically,
we demonstrate that CBF-RL internalizes the safety constraints in the learned
policy -- both enforcing safer actions and biasing towards safer rewards --
enabling safe deployment without the need for an online safety filter. We
validate our framework through ablation studies on navigation tasks and on the
Unitree G1 humanoid robot, where CBF-RL enables safer exploration, faster
convergence, and robust performance under uncertainty, enabling the humanoid
robot to avoid obstacles and climb stairs safely in real-world settings without
a runtime safety filter.

</details>


### [198] [RDD: Retrieval-Based Demonstration Decomposer for Planner Alignment in Long-Horizon Tasks](https://arxiv.org/abs/2510.14968)
*Mingxuan Yan,Yuping Wang,Zechun Liu,Jiachen Li*

Main category: cs.RO

TL;DR: RDD通过视觉特征对齐自动分解任务，提升性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLM规划器因依赖人工标注或启发式规则分解任务而导致子任务与训练数据偏差较大的问题。

Method: 采用检索方法自动分解演示为子任务，通过视觉特征对齐确保子任务与低级视觉运动策略的训练数据一致。

Result: RDD在模拟和真实世界任务中表现优于现有子任务分解器，展现了跨多样设置的鲁棒性。

Conclusion: 提出的基于检索的演示分解器（RDD）通过自动将演示分解为子任务，显著提升了任务性能，并在模拟和真实世界任务中超越了现有技术。

Abstract: To tackle long-horizon tasks, recent hierarchical vision-language-action
(VLAs) frameworks employ vision-language model (VLM)-based planners to
decompose complex manipulation tasks into simpler sub-tasks that low-level
visuomotor policies can easily handle. Typically, the VLM planner is finetuned
to learn to decompose a target task. This finetuning requires target task
demonstrations segmented into sub-tasks by either human annotation or heuristic
rules. However, the heuristic subtasks can deviate significantly from the
training data of the visuomotor policy, which degrades task performance. To
address these issues, we propose a Retrieval-based Demonstration Decomposer
(RDD) that automatically decomposes demonstrations into sub-tasks by aligning
the visual features of the decomposed sub-task intervals with those from the
training data of the low-level visuomotor policies. Our method outperforms the
state-of-the-art sub-task decomposer on both simulation and real-world tasks,
demonstrating robustness across diverse settings. Code and more results are
available at rdd-neurips.github.io.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [199] [From Craft to Constitution: A Governance-First Paradigm for Principled Agent Engineering](https://arxiv.org/abs/2510.13857)
*Qiang Xu,Xiangyu Wen,Changran Xu,Zeju Li,Jianyuan Zhong*

Main category: cs.SE

TL;DR: 论文提出ArbiterOS架构，通过治理优先的范式解决LLM代理在关键任务应用中的脆弱性和不可预测性问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在从原型到生产的过程中面临脆弱性和不可预测性问题，导致在关键任务应用中不可信。

Method: 论文引入了ArbiterOS，一个治理优先的正式架构，用于原则性代理工程。

Result: 通过ArbiterOS架构，论文展示了如何通过治理优先的范式解决代理工程中的根本范式不匹配问题。

Conclusion: 为了解决LLM代理的脆弱性和不可预测性问题，论文提出了ArbiterOS这一正式架构，作为基于治理原则的代理工程新范式。

Abstract: The advent of powerful Large Language Models (LLMs) has ushered in an ``Age
of the Agent,'' enabling autonomous systems to tackle complex goals. However,
the transition from prototype to production is hindered by a pervasive ``crisis
of craft,'' resulting in agents that are brittle, unpredictable, and ultimately
untrustworthy in mission-critical applications. This paper argues this crisis
stems from a fundamental paradigm mismatch -- attempting to command inherently
probabilistic processors with the deterministic mental models of traditional
software engineering. To solve this crisis, we introduce a governance-first
paradigm for principled agent engineering, embodied in a formal architecture we
call ArbiterOS.

</details>


### [200] [Benchmarking Correctness and Security in Multi-Turn Code Generation](https://arxiv.org/abs/2510.13859)
*Ruchit Rawal,Jeffrey Yang Fan Chiang,Chihao Shen,Jeffery Siyuan Tian,Aastha Mahajan,Tom Goldstein,Yizheng Chen*

Main category: cs.SE

TL;DR: MT-Sec是首个评估多轮编码场景中正确性和安全性的基准，发现模型在多轮设置中表现下降，且代理脚手架效果有限，强调了多轮评估的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试通常局限于单轮任务，无法反映真实世界开发的迭代性质。因此，需要一个新的基准来评估多轮编码场景中的正确性和安全性。

Method: 研究人员引入了MT-Sec，这是第一个在多轮编码场景中系统评估正确性和安全性的基准。通过一个合成数据管道，将现有的单轮任务转化为语义对齐的多轮交互序列，从而允许重用原始测试套件，同时模拟真实世界编码过程的复杂性。

Result: 评估了32个开源和闭源模型以及三种代理脚手架，发现在多轮设置中“正确且安全”的输出下降了20-27%。在多轮代码差异生成方面，模型表现更差，功能不正确和不安全输出的比例增加。此外，代理脚手架在多轮评估中的效果不如单轮代码生成。

Conclusion: 研究强调了在多轮、真实世界编码工作流程中联合评估正确性和安全性的必要性。

Abstract: AI coding assistants powered by large language models (LLMs) have transformed
software development, significantly boosting productivity. While existing
benchmarks evaluate the correctness and security of LLM-generated code, they
are typically limited to single-turn tasks that do not reflect the iterative
nature of real-world development. We introduce MT-Sec, the first benchmark to
systematically evaluate both correctness and security in multi-turn coding
scenarios. We construct this using a synthetic data pipeline that transforms
existing single-turn tasks into semantically aligned multi-turn interaction
sequences, allowing reuse of original test suites while modeling the complexity
of real-world coding processes. We evaluate 32 open- and closed-source models,
and three agent-scaffolding on MT-Sec and observe a consistent 20-27% drop in
"correct and secure" outputs from single-turn to multi-turn settings -- even
among state-of-the-art models. Beyond full-program generation, we also evaluate
models on multi-turn code-diff generation -- an unexplored yet practically
relevant setting -- and find that models perform worse here, with increased
rates of functionally incorrect and insecure outputs. Finally, we find that
while agent scaffoldings boost single-turn code generation performance, they
are not quite as effective in multi-turn evaluations. Together, these findings
highlight the need for benchmarks that jointly evaluate correctness and
security in multi-turn, real-world coding workflows.

</details>


### [201] [A11YN: aligning LLMs for accessible web UI code generation](https://arxiv.org/abs/2510.13914)
*Janghan Yoon,Jaegwan Cho,Junhyeok Kim,Jiwan Chung,Jaehyun Jeon,Youngjae Yu*

Main category: cs.SE

TL;DR: A11yn是一种新方法，通过优化奖励函数使LLMs生成无障碍合规的网页UI，显著降低了无障碍问题率。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成网页UI时复制训练数据中的无障碍缺陷，导致界面排斥多样化用户需求的问题。

Method: A11yn通过优化一个新颖的奖励函数来惩罚违反Web内容无障碍指南（WCAG）的行为，惩罚程度根据无障碍测试引擎识别的违规严重性进行缩放。

Result: A11yn在UIReq-6.8K数据集和RealUIReq-300基准测试中显著优于基线模型，降低了60%的无障碍问题率。

Conclusion: A11yn显著降低了生成网页UI的无障碍问题率60%，同时保持了语义保真度和视觉质量，证明了在LLMs中系统性优化无障碍性的可行性。

Abstract: Large language models (LLMs) have recently demonstrated strong capabilities
in generating functional and aesthetic web interfaces directly from
instructions. However, these models often replicate accessibility flaws from
their training data, resulting in interfaces that exclude users with diverse
needs and contexts. To address this gap, we introduce A11yn, the first method
that aligns code-generating LLMs to reliably produce accessibility-compliant
web UIs. A11yn optimizes a novel reward function that penalizes violations of
the Web Content Accessibility Guidelines (WCAG), with penalties scaled to the
severity of each violation as identified by an accessibility testing engine. To
support training, we construct UIReq-6.8K, a dataset of 6,800 diverse
instructions for web UI generation. For evaluation, we introduce RealUIReq-300,
a benchmark of 300 real-world web UI requests grounded and manually curated
from public web pages, spanning a broad range of use cases. Empirical results
show that A11yn significantly outperforms strong baselines, lowering the
Inaccessibility Rate by 60% over the base model while preserving semantic
fidelity and visual quality of generated UIs. These findings demonstrate that
accessibility can be systematically optimized within LLMs, showing the
feasibility of aligning code generation for accessibility.

</details>


### [202] [Signature in Code Backdoor Detection, how far are we?](https://arxiv.org/abs/2510.13992)
*Quoc Hung Le,Thanh Le-Cong,Bach Le,Bowen Xu*

Main category: cs.SE

TL;DR: 本文重新评估了Spectral Signature防御方法在代码模型后门攻击中的适用性，发现现有设置不够优化，并提出了一种新的代理指标以提高检测准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）越来越多地融入软件开发工作流程，它们也成为对抗性攻击的主要目标。后门攻击是一个重大威胁，允许攻击者通过嵌入训练数据中的隐藏触发器来操纵模型输出。检测此类后门仍然是一个挑战，Spectral Signature防御方法通过特征表示分析识别中毒数据是一种有前景的解决方案。

Method: 本文系统地评估了Spectral Signature防御方法在各种攻击场景和防御配置下的有效性，分析了其优势和局限性。

Result: 研究发现，Spectral Signature在代码后门检测中的广泛使用设置通常不是最优的。通过探索关键因素的不同设置，发现了一种新的代理指标，可以更准确地估计Spectral Signature的实际性能。

Conclusion: 研究发现，当前广泛使用的Spectral Signature设置在代码后门检测中往往不是最优的。通过探索关键因素的不同设置，发现了一种新的代理指标，可以更准确地估计Spectral Signature的实际性能，而无需在防御后重新训练模型。

Abstract: As Large Language Models (LLMs) become increasingly integrated into software
development workflows, they also become prime targets for adversarial attacks.
Among these, backdoor attacks are a significant threat, allowing attackers to
manipulate model outputs through hidden triggers embedded in training data.
Detecting such backdoors remains a challenge, and one promising approach is the
use of Spectral Signature defense methods that identify poisoned data by
analyzing feature representations through eigenvectors. While some prior works
have explored Spectral Signatures for backdoor detection in neural networks,
recent studies suggest that these methods may not be optimally effective for
code models. In this paper, we revisit the applicability of Spectral
Signature-based defenses in the context of backdoor attacks on code models. We
systematically evaluate their effectiveness under various attack scenarios and
defense configurations, analyzing their strengths and limitations. We found
that the widely used setting of Spectral Signature in code backdoor detection
is often suboptimal. Hence, we explored the impact of different settings of the
key factors. We discovered a new proxy metric that can more accurately estimate
the actual performance of Spectral Signature without model retraining after the
defense.

</details>


### [203] [One Bug, Hundreds Behind: LLMs for Large-Scale Bug Discovery](https://arxiv.org/abs/2510.14036)
*Qiushi Wu,Yue Xiao,Dhilung Kirat,Kevin Eykholt,Jiyong Jang,Douglas Lee Schales*

Main category: cs.SE

TL;DR: BugStone 通过 LLVM 和 LLM 自动识别重复模式错误（RPBs），显著提升漏洞检测效率，验证了其高精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 重复出现的模式错误（RPBs）在软件中普遍存在且可能严重威胁安全性，但手动逐个修复效率低下且易遗漏。

Method: 利用 LLVM 和大型语言模型（LLM）分析程序，识别一致的错误模式（如特定 API 误用），并在整个程序中扫描类似代码段。

Result: BugStone 在 Linux 内核中发现了超过 22K 个潜在问题，其中手动验证的 400 个中有 246 个有效；在 1.9K 个安全漏洞数据集中，识别了 80 个重复模式和 850 个修复，精度达 92.2%，配对准确率为 79.1%。

Conclusion: BugStone 是一种有效的程序分析系统，能够通过 LLVM 和大型语言模型（LLM）识别和修复重复出现的模式错误（RPBs），显著提升软件安全性。

Abstract: Fixing bugs in large programs is a challenging task that demands substantial
time and effort. Once a bug is found, it is reported to the project
maintainers, who work with the reporter to fix it and eventually close the
issue. However, across the program, there are often similar code segments,
which may also contain the bug, but were missed during discovery. Finding and
fixing each recurring bug instance individually is labor intensive. Even more
concerning, bug reports can inadvertently widen the attack surface as they
provide attackers with an exploitable pattern that may be unresolved in other
parts of the program.
  In this paper, we explore these Recurring Pattern Bugs (RPBs) that appear
repeatedly across various code segments of a program or even in different
programs, stemming from a same root cause, but are unresolved. Our
investigation reveals that RPBs are widespread and can significantly compromise
the security of software programs. This paper introduces BugStone, a program
analysis system empowered by LLVM and a Large Language Model (LLM). The key
observation is that many RPBs have one patched instance, which can be leveraged
to identify a consistent error pattern, such as a specific API misuse. By
examining the entire program for this pattern, it is possible to identify
similar sections of code that may be vulnerable. Starting with 135 unique RPBs,
BugStone identified more than 22K new potential issues in the Linux kernel.
Manual analysis of 400 of these findings confirmed that 246 were valid. We also
created a dataset from over 1.9K security bugs reported by 23 recent top-tier
conference works. We manually annotate the dataset, identify 80 recurring
patterns and 850 corresponding fixes. Even with a cost-efficient model choice,
BugStone achieved 92.2% precision and 79.1% pairwise accuracy on the dataset.

</details>


### [204] [David vs. Goliath: A comparative study of different-sized LLMs for code generation in the domain of automotive scenario generation](https://arxiv.org/abs/2510.14115)
*Philipp Bauerfeind,Amir Salarpour,David Fernandez,Pedram MohajerAnsari,Johannes Reschke,Mert D. Pesé*

Main category: cs.SE

TL;DR: NL2Scenic是一个开源数据集和框架，用于评估Scenic代码生成，表明中等规模开源模型是自动驾驶场景编程的实用选择。GPT-4o表现最佳，Qwen2.5Coder-14B接近其性能。EDIT-COMP是评估的新指标。


<details>
  <summary>Details</summary>
Motivation: 解决NL-to-Scenic生成中数据稀缺、可复现性有限和指标不一致的问题。

Method: 引入NL2Scenic，一个包含146个NL/Scenic对的开源数据集和框架，包括30个难度分层的测试案例、一个示例检索器和14种提示变体（ZS、FS、CoT、SP、MoT）。评估了13种模型，包括4种专有模型和9种开源代码模型，使用文本指标和执行指标，并与专家研究（n=11）进行比较。

Result: GPT-4o表现最佳，Qwen2.5Coder-14B在本地硬件上达到其专家评分的约88%。检索增强提示（FSER）持续提升较小模型的性能，规模扩展在中等规模后呈现收益递减。EDIT-SIM与人类判断相关性最高，EDIT-COMP（EDIT-SIM和编译的F1）作为数据集级代理提高了排名保真度。

Conclusion: NL2Scenic和EDIT-COMP为评估Scenic代码生成提供了标准化、可复现的基础，并表明中等规模的开源模型是自动驾驶场景编程的实用、经济高效的选择。

Abstract: Scenario simulation is central to testing autonomous driving systems. Scenic,
a domain-specific language (DSL) for CARLA, enables precise and reproducible
scenarios, but NL-to-Scenic generation with large language models (LLMs)
suffers from scarce data, limited reproducibility, and inconsistent metrics. We
introduce NL2Scenic, an open dataset and framework with 146 NL/Scenic pairs, a
difficulty-stratified 30-case test split, an Example Retriever, and 14
prompting variants (ZS, FS, CoT, SP, MoT). We evaluate 13 models: four
proprietary (GPT-4o, GPT-5, Claude-Sonnet-4, Gemini-2.5-pro) and nine
open-source code models (Qwen2.5Coder 0.5B-32B; CodeLlama 7B/13B/34B), using
text metrics (BLEU, ChrF, EDIT-SIM, CrystalBLEU) and execution metrics
(compilation and generation), and compare them with an expert study (n=11).
EDIT-SIM correlates best with human judgments; we also propose EDIT-COMP (F1 of
EDIT-SIM and compilation) as a robust dataset-level proxy that improves ranking
fidelity. GPT-4o performs best overall, while Qwen2.5Coder-14B reaches about 88
percent of its expert score on local hardware. Retrieval-augmented prompting,
Few-Shot with Example Retriever (FSER), consistently boosts smaller models, and
scaling shows diminishing returns beyond mid-size, with Qwen2.5Coder
outperforming CodeLlama at comparable scales. NL2Scenic and EDIT-COMP offer a
standardized, reproducible basis for evaluating Scenic code generation and
indicate that mid-size open-source models are practical, cost-effective options
for autonomous-driving scenario programming.

</details>


### [205] [Caruca: Effective and Efficient Specification Mining for Opaque Software Components](https://arxiv.org/abs/2510.14279)
*Evangelos Lamprou,Seong-Heon Jung,Mayank Keoliya,Lukas Lazarek,Konstantinos Kallas,Michael Greenberg,Nikos Vasilakis*

Main category: cs.SE

TL;DR: Caruca是一个自动挖掘不透明命令规范的系统，通过语言模型和实际执行提取关键属性，显著减少人工干预，并在测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有系统需要手动创建部分规范，这一过程繁琐且易错，限制了系统的实用性。

Method: Caruca通过大型语言模型将命令文档转化为结构化调用语法，并探索有效的命令调用和执行环境组合，通过系统调用和文件系统拦截提取关键属性。

Result: Caruca在60个命令中除一例外均生成正确规范，完全消除了手动工作，并已应用于一个先进的静态分析工具。

Conclusion: Caruca成功实现了对不透明命令的自动规范挖掘，显著减少了人工干预，并在60个GNU Coreutils、POSIX和第三方命令中表现出高准确率。

Abstract: A wealth of state-of-the-art systems demonstrate impressive improvements in
performance, security, and reliability on programs composed of opaque
components, such as Unix shell commands. To reason about commands, these
systems require partial specifications. However, creating such specifications
is a manual, laborious, and error-prone process, limiting the practicality of
these systems. This paper presents Caruca, a system for automatic specification
mining for opaque commands. To overcome the challenge of language diversity
across commands, Caruca first instruments a large language model to translate a
command's user-facing documentation into a structured invocation syntax. Using
this representation, Caruca explores the space of syntactically valid command
invocations and execution environments. Caruca concretely executes each
command-environment pair, interposing at the system-call and filesystem level
to extract key command properties such as parallelizability and filesystem pre-
and post-conditions. These properties can be exported in multiple specification
formats and are immediately usable by existing systems. Applying Caruca across
60 GNU Coreutils, POSIX, and third-party commands across several
specification-dependent systems shows that Caruca generates correct
specifications for all but one case, completely eliminating manual effort from
the process and currently powering the full specifications for a
state-of-the-art static analysis tool.

</details>


### [206] [A Hybrid, Knowledge-Guided Evolutionary Framework for Personalized Compiler Auto-Tuning](https://arxiv.org/abs/2510.14292)
*Haolin Pan,Hongbin Zhang,Mingjie Xing,Yanjun Wu*

Main category: cs.SE

TL;DR: 提出了一种混合知识引导进化框架，通过离线知识库和在线遗传算法实现个性化编译器优化，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统通用优化标志（如-O3和-Oz）无法充分发挥程序性能潜力，因此需要一种更智能、个性化的优化方法。

Method: 框架包含离线阶段构建的编译知识库（包括Pass行为向量、Pass组、协同Pass图和原型Pass序列）和在线阶段的知识引导遗传算法。

Result: 在七个公共数据集上，框架平均比opt -Oz基线多减少了11.0%的LLVM IR指令。

Conclusion: 提出的混合知识引导进化框架在个性化编译器优化方面取得了显著成效，平均比高度优化的基线多减少了11.0%的LLVM IR指令。

Abstract: Compiler pass auto-tuning is critical for enhancing software performance, yet
finding the optimal pass sequence for a specific program is an NP-hard problem.
Traditional, general-purpose optimization flags like -O3 and -Oz adopt a
one-size-fits-all approach, often failing to unlock a program's full
performance potential. To address this challenge, we propose a novel Hybrid,
Knowledge-Guided Evolutionary Framework. This framework intelligently guides
online, personalized optimization using knowledge extracted from a large-scale
offline analysis phase. During the offline stage, we construct a comprehensive
compilation knowledge base composed of four key components: (1) Pass Behavioral
Vectors to quantitatively capture the effectiveness of each optimization; (2)
Pass Groups derived from clustering these vectors based on behavior similarity;
(3) a Synergy Pass Graph to model beneficial sequential interactions; and (4) a
library of Prototype Pass Sequences evolved for distinct program types. In the
online stage, a bespoke genetic algorithm leverages this rich knowledge base
through specially designed, knowledge-infused genetic operators. These
operators transform the search by performing semantically-aware recombination
and targeted, restorative mutations. On a suite of seven public datasets, our
framework achieves an average of 11.0% additional LLVM IR instruction reduction
over the highly-optimized opt -Oz baseline, demonstrating its state-of-the-art
capability in discovering personalized, high-performance optimization
sequences.

</details>


### [207] [A Systematic Study of Time Limit Exceeded Errors in Online Programming Assignments](https://arxiv.org/abs/2510.14339)
*Jialu Zhang,Jialiang Gu,Wangmeiyu Zhang,José Pablo Cambronero,John Kolesar,Ruzica Piskac,Daming Li,Hanyuan Shi*

Main category: cs.SE

TL;DR: 研究发现TLE错误多源而非仅性能问题，开发自动化修复工具Nettle，修复率高达98.5%。


<details>
  <summary>Details</summary>
Motivation: 在线编程平台的TLE错误难以诊断和修复，导致用户放弃提交，亟需自动化解决方案。

Method: 手动分析1000个Codeforces提交中的TLE错误，分类根因并追踪用户修复尝试，开发自动化修复工具Nettle和评估框架Nettle-Eval。

Result: Nettle在1000个真实案例中达到98.5%的修复率，远超LLM基线，且所有修复均通过Nettle-Eval和平台官方检查器。

Conclusion: 在线编程平台中的TLE错误修复工具Nettle及其评估框架Nettle-Eval，通过结合LLMs和自动化反馈，显著提高了修复成功率和可靠性。

Abstract: Online programming platforms such as Codeforces and LeetCode attract millions
of users seeking to learn to program or refine their skills for industry
interviews. A major challenge for these users is the Time Limit Exceeded (TLE)
error, triggered when a program exceeds the execution time bound. Although
designed as a performance safeguard, TLE errors are difficult to resolve: error
messages provide no diagnostic insight, platform support is minimal, and
existing debugging tools offer little help. As a result, many users abandon
their submissions after repeated TLE failures.
  This paper presents the first large-scale empirical study of TLE errors in
online programming. We manually analyzed 1000 Codeforces submissions with TLE
errors, classified their root causes, and traced how users attempted to fix
them. Our analysis shows that TLE errors often arise not only from inefficient
algorithms but also from infinite loops, improper data structure use, and
inefficient I/O, challenging the conventional view that TLEs are purely
performance issues.
  Guided by these findings, we introduce Nettle, the first automated repair
tool specifically designed for TLE errors, and Nettle-Eval, the first framework
for evaluating TLE repairs. Integrating LLMs with targeted automated feedback
generated by the compiler and test cases, Nettle produces small, correct code
edits that eliminate TLEs while preserving functionality. Evaluated on the same
1000 real-world cases, Nettle achieves a 98.5% fix rate, far exceeding the
strongest LLM baseline, and all of its repairs pass both Nettle-Eval and the
platform's official checker, confirming the reliability of our framework.

</details>


### [208] [PathFix: Automated Program Repair with Expected Path](https://arxiv.org/abs/2510.14341)
*Xu He,Shu Wang,Kun Sun*

Main category: cs.SE

TL;DR: PathFix是一种新的APR方法，利用路径敏感约束和LLM集成，有效解决了现有APR方法的挑战，显著提升了修复性能。


<details>
  <summary>Details</summary>
Motivation: 现有的APR方法由于难以生成精确的规范，面临生成过多可能的补丁候选和过拟合部分测试用例的挑战。PathFix旨在通过路径敏感约束解决这些问题。

Method: PathFix通过四个主要步骤进行程序修复：1.追踪故障路径；2.分析控制流图推导预期路径；3.通过解决状态约束生成和评估补丁；4.验证生成的补丁的正确性。

Result: 实验结果表明，PathFix在修复性能上优于现有解决方案，特别是在处理复杂程序结构时。

Conclusion: PathFix通过利用路径敏感约束和大型语言模型（LLM）的集成，显著提升了自动化程序修复（APR）的性能，尤其在处理复杂程序结构（如循环和递归）方面表现优异。

Abstract: Automated program repair (APR) techniques are effective in fixing inevitable
defects in software, enhancing development efficiency and software robustness.
However, due to the difficulty of generating precise specifications, existing
APR methods face two main challenges: generating too many plausible patch
candidates and overfitting them to partial test cases. To tackle these
challenges, we introduce a new APR method named PathFix, which leverages
path-sensitive constraints extracted from correct execution paths to generate
patches for repairing buggy code. It is based on one observation: if a buggy
program is repairable, at least one expected path is supposed to replace the
fault path in the patched program. PathFix operates in four main steps. First,
it traces fault paths reaching the fault output in the buggy program. Second,
it derives expected paths by analyzing the desired correct output on the
control flow graph, where an expected path defines how a feasible patch leads
to the correct execution. Third, PathFix generates and evaluates patches by
solving state constraints along the expected path. Fourth, we validate the
correctness of the generated patch. To further enhance repair performance and
mitigate scalability issues introduced by path-sensitive analysis, we integrate
a large language model (LLM) into our framework. Experimental results show that
PathFix outperforms existing solutions, particularly in handling complex
program structures such as loops and recursion.

</details>


### [209] [Towards Automated Governance: A DSL for Human-Agent Collaboration in Software Projects](https://arxiv.org/abs/2510.14465)
*Adem Ait,Gwendal Jouneaux,Javier Luis Cánovas Izquierdo,Jordi Cabot*

Main category: cs.SE

TL;DR: 本文提出了一种新的DSL，用于定义和执行涉及多样利益相关者（包括AI代理）的治理政策，以解决开源软件项目中的治理挑战。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发中利益相关者的多样性增加（包括来自不同背景的人类贡献者和AI代理），尤其是在开源软件项目中，缺乏明确或清晰的治理政策带来了独特的治理挑战。

Method: 本文介绍了设计和实现一种专门用于治理政策的DSL的愿景和基础概念，以实现更强大、适应性更强的自动化治理。

Result: 提出的DSL为定义和执行治理政策提供了一种新方法，支持更强大、适应性更强的自动化治理，促进了更有效的协作。

Conclusion: 本文提出了一种新颖的领域特定语言（DSL），旨在为涉及多样利益相关者（包括AI代理）的系统定义和执行丰富的治理政策，为更有效的协作（尤其是在开源软件项目中）铺平了道路。

Abstract: The stakeholders involved in software development are becoming increasingly
diverse, with both human contributors from varied backgrounds and AI-powered
agents collaborating together in the process. This situation presents unique
governance challenges, particularly in Open-Source Software (OSS) projects,
where explicit policies are often lacking or unclear. This paper presents the
vision and foundational concepts for a novel Domain-Specific Language (DSL)
designed to define and enforce rich governance policies in systems involving
diverse stakeholders, including agents. This DSL offers a pathway towards more
robust, adaptable, and ultimately automated governance, paving the way for more
effective collaboration in software projects, especially OSS ones.

</details>


### [210] [E2Edev: Benchmarking Large Language Models in End-to-End Software Development Task](https://arxiv.org/abs/2510.14509)
*Jingyao Liu,Chen Huang,Zhizhao Guan,Wenqiang Lei,Yang Deng*

Main category: cs.SE

TL;DR: E2EDev是一个结合细粒度需求、BDD测试和自动化测试流水线的端到端开发测试平台，采用HITL-MAA减少标注工作量并保证质量。评估显示现有E2ESD框架和LLM主干在任务解决上仍有困难，呼吁更高效、经济的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前各种E2ESD框架和LLM主干在有效解决这些任务方面存在持续困难，这凸显了对更高效、经济的E2ESD解决方案的迫切需求。

Method: E2EDev包含三个主要部分：(i) 细粒度的用户需求集，(ii) 每个需求对应的BDD测试场景及其Python步骤实现，(iii) 基于Behave框架的全自动化测试流水线。此外，还提出了Human-in-the-Loop Multi-Agent Annotation Framework (HITL-MAA)以减少标注工作量并提高质量。

Result: 通过评估多种E2ESD框架和LLM主干，论文揭示了这些任务的有效解决仍具挑战性，强调了开发更有效、经济的E2ESD解决方案的重要性。

Conclusion: E2EDev通过结合细粒度的用户需求、BDD测试场景及自动化测试流水线，提出了一个全面的端到端软件开发测试平台。

Abstract: E2EDev comprises (i) a fine-grained set of user requirements, (ii) {multiple
BDD test scenarios with corresponding Python step implementations for each
requirement}, and (iii) a fully automated testing pipeline built on the Behave
framework. To ensure its quality while reducing the annotation effort, E2EDev
leverages our proposed Human-in-the-Loop Multi-Agent Annotation Framework
(HITL-MAA). {By evaluating various E2ESD frameworks and LLM backbones with
E2EDev}, our analysis reveals a persistent struggle to effectively solve these
tasks, underscoring the critical need for more effective and cost-efficient
E2ESD solutions. Our codebase and benchmark are publicly available at
https://github.com/SCUNLP/E2EDev.

</details>


### [211] [Software Testing Education and Industry Needs - Report from the ENACTEST EU Project](https://arxiv.org/abs/2510.14625)
*Mehrdad Saadatmand,Abbas Khan,Beatriz Marin,Ana C. R Paiva,Nele Van Asch,Graham Moran,Felix Cammaerts,Monique Snoeck,Alexandra Mendes*

Main category: cs.SE

TL;DR: 该研究通过焦点小组和访谈发现，软件测试行业在AI测试、安全测试和软技能方面存在知识缺口，呼吁教育和培训的调整。


<details>
  <summary>Details</summary>
Motivation: 随着软件开发的快速发展，测试人员需要不断适应新工具和实践，但目前的教育和培训存在知识缺口。

Method: 通过两次焦点小组讨论和跨行业专业人士的访谈，以及小规模的范围综述，采用主题定性分析方法。

Result: 研究发现，行业对AI测试、安全测试和软技能的需求未被充分满足，学术教育与行业需求之间存在差距。

Conclusion: 研究表明，软件测试行业存在多个知识缺口，特别是在AI测试、安全测试和软技能方面。学术界和行业需求之间存在不匹配，需要进一步的教育和培训调整。

Abstract: The evolving landscape of software development demands that software testers
continuously adapt to new tools, practices, and acquire new skills. This study
investigates software testing competency needs in industry, identifies
knowledge gaps in current testing education, and highlights competencies and
gaps not addressed in academic literature. This is done by conducting two focus
group sessions and interviews with professionals across diverse domains,
including railway industry, healthcare, and software consulting and performing
a curated small-scale scoping review. The study instrument, co-designed by
members of the ENACTEST project consortium, was developed collaboratively and
refined through multiple iterations to ensure comprehensive coverage of
industry needs and educational gaps. In particular, by performing a thematic
qualitative analysis, we report our findings and observations regarding:
professional training methods, challenges in offering training in industry,
different ways of evaluating the quality of training, identified knowledge gaps
with respect to academic education and industry needs, future needs and trends
in testing education, and knowledge transfer methods within companies. Finally,
the scoping review results confirm knowledge gaps in areas such as AI testing,
security testing and soft skills.

</details>


### [212] [ATGen: Adversarial Reinforcement Learning for Test Case Generation](https://arxiv.org/abs/2510.14635)
*Qingyao Li,Xinyi Dai,Weiwen Liu,Xiangyang Li,Yasheng Wang,Ruiming Tang,Yong Yu,Weinan Zhang*

Main category: cs.SE

TL;DR: ATGen通过对抗性强化学习动态生成测试用例，突破静态数据集的限制，显著提升LLM代码生成的可靠性和测试质量。


<details>
  <summary>Details</summary>
Motivation: 现有测试生成方法依赖静态数据集，存在固定难度天花板，无法发现超出训练范围的新颖或复杂错误。

Method: 采用对抗性强化学习框架，训练测试用例生成器与对抗性代码生成器动态交互，形成难度递增的课程。

Result: ATGen 在实验中显著优于现有基线方法，并能更有效地过滤Best-of-N推理及作为高质量奖励源训练代码生成模型。

Conclusion: ATGen 通过对抗性强化学习动态提升测试用例生成能力，打破了静态数据集的固定难度天花板，显著提高了LLM生成代码的可靠性。

Abstract: Large Language Models (LLMs) excel at code generation, yet their outputs
often contain subtle bugs, for which effective test cases are a critical
bottleneck. Existing test generation methods, whether based on prompting or
supervised fine-tuning, rely on static datasets. This imposes a
``fixed-difficulty ceiling'', fundamentally limiting their ability to uncover
novel or more complex bugs beyond their training scope. To overcome this, we
introduce ATGen, a framework that trains a test case generator via adversarial
reinforcement learning. ATGen pits a test generator against an adversarial code
generator that continuously crafts harder bugs to evade the current policy.
This dynamic loop creates a curriculum of increasing difficulty challenging
current policy. The test generator is optimized via Reinforcement Learning (RL)
to jointly maximize ``Output Accuracy'' and ``Attack Success'', enabling it to
learn a progressively stronger policy that breaks the fixed-difficulty ceiling
of static training. Extensive experiments demonstrate that ATGen significantly
outperforms state-of-the-art baselines. We further validate its practical
utility, showing it serves as both a more effective filter for Best-of-N
inference and a higher-quality reward source for training code generation
models. Our work establishes a new, dynamic paradigm for improving the
reliability of LLM-generated code.

</details>


### [213] [Requirement Identification for Traffic Simulations in Driving Simulators](https://arxiv.org/abs/2510.14653)
*Sven Tarlowski,Lutz Eckstein*

Main category: cs.SE

TL;DR: 论文提出了一种基于子目标的结构化方法，用于系统识别交通模拟需求，以增强实验效度和参与度。


<details>
  <summary>Details</summary>
Motivation: 解决确保真实交通条件的挑战，支持稳健的汽车开发和测试。

Method: 采用基于每个研究阶段子目标的结构化方法，为微观层面、代理模型和视觉表示推导出特定技术需求。

Result: 该方法论在实验结果的效度和参与者参与度方面表现出高保真度。

Conclusion: 该论文提出了一种系统识别交通模拟需求的方法论，旨在保持高保真度，从而增强实验结果的有效性和参与者参与度。

Abstract: This paper addresses the challenge of ensuring realistic traffic conditions
by proposing a methodology that systematically identifies traffic simulation
requirements. Using a structured approach based on sub-goals in each study
phase, specific technical needs are derived for microscopic levels, agent
models, and visual representation. The methodology aims to maintain a high
degree of fidelity, enhancing both the validity of experimental outcomes and
participant engagement. By providing a clear link between study objectives and
traffic simulation design, this approach supports robust automotive development
and testing.

</details>


### [214] [LLM Agents for Automated Web Vulnerability Reproduction: Are We There Yet?](https://arxiv.org/abs/2510.14700)
*Bin Liu,Yanjie Zhao,Guoai Xu,Haoyu Wang*

Main category: cs.SE

TL;DR: 本文评估了LLM代理在自动化Web漏洞复现中的表现，发现其在简单漏洞上有效，但在复杂漏洞上表现不佳，强调了环境适应和自主问题解决能力的重要性。


<details>
  <summary>Details</summary>
Motivation: 自动化Web漏洞复现是一个关键但未充分探索的应用领域，尽管LLM代理在软件工程和网络安全任务中表现出色，但在实际Web漏洞复现场景中仍面临挑战。

Method: 本文对20种最先进的LLM代理进行了系统评估，涵盖16个维度，包括技术能力、环境适应性和用户体验因素，针对3种代表性Web漏洞。基于结果，选择了3种表现最佳的代理（OpenHands、SWE-agent和CAI）在包含80个真实世界CVE的基准数据集上进行深入评估。

Result: 研究发现，LLM代理在简单的基于库的漏洞上表现尚可，但在需要多组件环境的复杂基于服务的漏洞上表现不佳。复杂环境配置和认证障碍导致代理可以执行利用代码但无法触发实际漏洞。输入指导的敏感性高，性能在认证信息不完整时下降超过33%。

Conclusion: 当前LLM代理的能力与可靠自动化漏洞复现的需求之间存在显著差距，强调了在环境适应和自主问题解决能力方面需要进一步改进。

Abstract: Large language model (LLM) agents have demonstrated remarkable capabilities
in software engineering and cybersecurity tasks, including code generation,
vulnerability discovery, and automated testing. One critical but underexplored
application is automated web vulnerability reproduction, which transforms
vulnerability reports into working exploits. Although recent advances suggest
promising potential, challenges remain in applying LLM agents to real-world web
vulnerability reproduction scenarios. In this paper, we present the first
comprehensive evaluation of state-of-the-art LLM agents for automated web
vulnerability reproduction. We systematically assess 20 agents from software
engineering, cybersecurity, and general domains across 16 dimensions, including
technical capabilities, environment adaptability, and user experience factors,
on 3 representative web vulnerabilities. Based on the results, we select three
top-performing agents (OpenHands, SWE-agent, and CAI) for in-depth evaluation
on our benchmark dataset of 80 real-world CVEs spanning 7 vulnerability types
and 6 web technologies. Our results reveal that while LLM agents achieve
reasonable success on simple library-based vulnerabilities, they consistently
fail on complex service-based vulnerabilities requiring multi-component
environments. Complex environment configurations and authentication barriers
create a gap where agents can execute exploit code but fail to trigger actual
vulnerabilities. We observe high sensitivity to input guidance, with
performance degrading by over 33% under incomplete authentication information.
Our findings highlight the significant gap between current LLM agent
capabilities and the demands of reliable automated vulnerability reproduction,
emphasizing the need for advances in environmental adaptation and autonomous
problem-solving capabilities.

</details>


### [215] [Leveraging Code Cohesion Analysis to Identify Source Code Supply Chain Attacks](https://arxiv.org/abs/2510.14778)
*Maor Reuben,Ido Mendel,Or Feldman,Moshe Kravchik,Mordehai Guri,Rami Puzis*

Main category: cs.SE

TL;DR: 提出一种无监督方法，通过NPC度量检测代码注入，实验显示其在高不平衡测试集中有效，为供应链攻击检测提供新思路。


<details>
  <summary>Details</summary>
Motivation: 供应链攻击通过合法项目中的恶意代码注入对软件安全构成重大威胁。此类攻击虽然罕见但破坏性极大。由于需要解析插入代码及其上下文的意图，使用自动化工具检测虚假代码注入非常复杂。

Method: 本研究提出了一种无监督方法，通过量化源代码中的内聚破坏来突出虚假代码注入。使用基于名称预测的内聚（NPC）度量，分析恶意代码引入时函数内聚的变化与自然内聚波动的对比。

Result: 对369个开源C++仓库中的54,707个函数进行分析发现，代码注入会降低内聚性，并将命名模式转向更短、描述性更低的名称。在极端测试集不平衡的情况下，NPC方法在1:1,000比例下达到36.41%的Precision@100，在1:10,000比例下达到12.47%。

Conclusion: 自动化内聚度量，特别是基于名称预测的内聚（NPC）方法，有助于识别供应链攻击，从而提高源代码的完整性。

Abstract: Supply chain attacks significantly threaten software security with malicious
code injections within legitimate projects. Such attacks are very rare but may
have a devastating impact. Detecting spurious code injections using automated
tools is further complicated as it often requires deciphering the intention of
both the inserted code and its context. In this study, we propose an
unsupervised approach for highlighting spurious code injections by quantifying
cohesion disruptions in the source code. Using a name-prediction-based cohesion
(NPC) metric, we analyze how function cohesion changes when malicious code is
introduced compared to natural cohesion fluctuations. An analysis of 54,707
functions over 369 open-source C++ repositories reveals that code injection
reduces cohesion and shifts naming patterns toward shorter, less descriptive
names compared to genuine function updates. Considering the sporadic nature of
real supply-chain attacks, we evaluate the proposed method with extreme
test-set imbalance and show that monitoring high-cohesion functions with NPC
can effectively detect functions with injected code, achieving a Precision@100
of 36.41% at a 1:1,000 ratio and 12.47% at 1:10,000. These results suggest that
automated cohesion measurements, in general, and name-prediction-based
cohesion, in particular, may help identify supply chain attacks, improving
source code integrity.

</details>


### [216] [Instruction Set Migration at Warehouse Scale](https://arxiv.org/abs/2510.14928)
*Eric Christopher,Kevin Crossan,Wolff Dobson,Chris Kennelly,Drew Lewis,Kun Lin,Martin Maas,Parthasarathy Ranganathan,Emma Rapati,Brian Yang*

Main category: cs.SE

TL;DR: 论文分析了从x86到Arm架构迁移的挑战，展示了自动化（包括AI）的解决方案，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现代ISA迁移可以基于强大的开源生态系统重新编译所有相关软件，这带来了与二进制翻译不同的新挑战。论文旨在填补学术界对此问题关注不足的空白。

Method: 通过分析Google从x86到Arm架构的大规模迁移（涉及近40,000个代码提交），作者提取了ISA迁移中涉及的任务分类，并展示了自动化这些步骤的方法。

Result: 研究揭示了ISA迁移中的多层面挑战，展示了自动化（包括AI的应用）在解决这些任务中的潜力，并识别了仍需进一步研究的领域。

Conclusion: 论文总结了从x86到Arm架构迁移中的关键任务分类，并展示了Google如何自动化这些步骤，同时指出AI在此过程中的重要作用。还识别了仍需人工干预的挑战性任务，并提出了未来研究方向。

Abstract: Migrating codebases from one instruction set architecture (ISA) to another is
a major engineering challenge. A recent example is the adoption of Arm (in
addition to x86) across the major Cloud hyperscalers. Yet, this problem has
seen limited attention by the academic community. Most work has focused on
static and dynamic binary translation, and the traditional conventional wisdom
has been that this is the primary challenge.
  In this paper, we show that this is no longer the case. Modern ISA migrations
can often build on a robust open-source ecosystem, making it possible to
recompile all relevant software from scratch. This introduces a new and
multifaceted set of challenges, which are different from binary translation.
  By analyzing a large-scale migration from x86 to Arm at Google, spanning
almost 40,000 code commits, we derive a taxonomy of tasks involved in ISA
migration. We show how Google automated many of the steps involved, and
demonstrate how AI can play a major role in automatically addressing these
tasks. We identify tasks that remain challenging and highlight research
challenges that warrant further attention.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [217] [Efficiently Executing High-throughput Lightweight LLM Inference Applications on Heterogeneous Opportunistic GPU Clusters with Pervasive Context Management](https://arxiv.org/abs/2510.14024)
*Thanh Son Phung,Douglas Thain*

Main category: cs.DC

TL;DR: 提出'Pervasive Context Management'技术，解耦LLM初始化与推理，显著减少执行时间并提高GPU利用率。


<details>
  <summary>Details</summary>
Motivation: 当前HPC集群设计无法有效支持集成轻量级LLM的高通量应用，导致长时间等待或高启动成本。

Method: 提出'Pervasive Context Management'技术，将LLM初始化上下文与推理解耦，并保留在GPU中直至不再需要。

Result: 应用该技术后，执行时间减少了72.1%（从3小时降至48分钟），并在集群32.8%的GPU上实现了机会性扩展，进一步将执行时间缩短至13分钟。

Conclusion: 通过'Pervasive Context Management'技术，成功将LLM初始化上下文与推理解耦，显著减少了执行时间，并提高了GPU资源的利用率。

Abstract: The rise of Generative AI introduces a new class of HPC workloads that
integrates lightweight LLMs with traditional high-throughput applications to
accelerate scientific discovery. The current design of HPC clusters is
inadequate to support this new class however, either incurring long wait times
on static batch queues or repeatedly paying expensive LLM startup costs upon
resource preemption. To circumvent both the long queues and high startup costs,
we propose to "decouple" the LLM initialization context from the actual LLM
inferences, and retain the context in GPUs until it is no longer needed, a
technique we term "Pervasive Context Management". We transform a fact
verification application to enable this technique, allowing it to reduce its
execution time by 72.1% (from 3 hours to 48 minutes) using the same amount of
GPUs, and scale opportunistically on 32.8% of all GPUs in the cluster and
further reduce the execution time to 13 minutes.

</details>


### [218] [Anonymized Network Sensing using C++26 std::execution on GPUs](https://arxiv.org/abs/2510.14050)
*Michael Mandulak,Sayan Ghosh,S M Ferdous,Mahantesh Halappanavar,George Slota*

Main category: cs.DC

TL;DR: 论文提出使用C++26 Senders模型在密集GPU平台上高效部署网络分析任务，性能提升显著，同时保持开发便捷性。


<details>
  <summary>Details</summary>
Motivation: 解决GPU实现中主机-设备内存管理和复杂工作负载移植等启动挑战，同时提升网络分析的效率和可扩展性。

Method: 利用C++26 Senders模型开发异步数据操作链，支持多GPU应用工作负载的高效部署。

Result: 在8个NVIDIA A100 GPU上，基于商品库的实现比参考串行GraphBLAS基线性能提升了55倍。

Conclusion: 采用C++26 Senders模型的通用编程模型在密集GPU平台上实现了显著的性能提升（最高55倍），同时保持了开发的便捷性和标准化。

Abstract: Large-scale network sensing plays a vital role in network traffic analysis
and characterization. As network packet data grows increasingly large, parallel
methods have become mainstream for network analytics. While effective,
GPU-based implementations still face start-up challenges in host-device memory
management and porting complex workloads on devices, among others. To mitigate
these challenges, composable frameworks have emerged using modern C++
programming language, for efficiently deploying analytics tasks on GPUs.
Specifically, the recent C++26 Senders model of asynchronous data operation
chaining provides a simple interface for bulk pushing tasks to varied device
execution contexts.
  Considering the prominence of contemporary dense-GPU platforms and
vendor-leveraged software libraries, such a programming model consider GPUs as
first-class execution resources (compared to traditional host-centric
programming models), allowing convenient development of multi-GPU application
workloads via expressive and standardized asynchronous semantics. In this
paper, we discuss practical aspects of developing the Anonymized Network
Sensing Graph Challenge on dense-GPU systems using the recently proposed C++26
Senders model. Adopting a generic and productive programming model does not
necessarily impact the critical-path performance (as compared to low-level
proprietary vendor-based programming models): our commodity library-based
implementation achieves up to 55x performance improvements on 8x NVIDIA A100
GPUs as compared to the reference serial GraphBLAS baseline.

</details>


### [219] [Cortex: Workflow-Aware Resource Pooling and Scheduling for Agentic Serving](https://arxiv.org/abs/2510.14126)
*Nikos Pagonas,Yeounoh Chung,Kostis Kaffes,Arvind Krishnamurthy*

Main category: cs.DC

TL;DR: Cortex是一个工作流感知的服务平台，通过阶段隔离优化代理工作负载的资源利用和性能，为未来高级代理服务奠定基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决代理工作流中阶段间资源干扰导致的性能问题，Cortex旨在通过阶段隔离提升资源利用效率和服务性能。

Method: Cortex采用阶段隔离原则，为代理工作流的每个阶段分配专用资源池，以减少阶段间的干扰，并优化KV缓存利用率、吞吐量和性能可预测性。

Result: Cortex实现了更高的KV缓存利用率、吞吐量和更可预测的性能，同时为高级代理原生服务范式（如资源管理的灵活性、工作流分支的推测执行等）提供了基础。

Conclusion: Cortex通过阶段隔离策略，为代理工作负载提供了更高效的资源利用和性能优化，为未来更先进的代理原生服务范式奠定了基础。

Abstract: We introduce Cortex, a prototype workflow-aware serving platform designed for
agentic workloads. The core principle of Cortex is stage isolation: it
provisions dedicated resource pools for each distinct stage of an agentic
workflow. This simple yet powerful strategy mitigates inter-stage interference
in compute and memory, leading to better KV cache utilization, higher
throughput, and more predictable performance. By customizing resource
allocation and scheduling within each distinct stage of agentic workflows,
Cortex lays the groundwork for more advanced, agent-native serving paradigms,
including malleable resource management, speculative execution of workflow
branches, and a shared, multi-tiered cache for "agentic state."

</details>


### [220] [Distributed-Memory Parallel Algorithms for Fixed-Radius Near Neighbor Graph Construction](https://arxiv.org/abs/2510.14147)
*Gabriel Raulet,Dmitriy Morozov,Aydin Buluc,Katherine Yelick*

Main category: cs.DC

TL;DR: 本文提出了一种可扩展的分布式内存算法，使用覆盖树在一般度量空间中计算近邻图，显著提升了高维数据集上的计算效率。


<details>
  <summary>Details</summary>
Motivation: 计算固定半径近邻图是许多数据分析算法的重要第一步。随着计算能力和数据获取方法的进步，大规模科学数据集需要可扩展的解决方案。现有并行近邻算法主要集中在欧几里得空间，而许多应用需要精确解和非欧几里得度量。

Method: 本文提出了一种可扩展的、稀疏感知的分布式内存算法，使用覆盖树在一般度量空间中计算近邻图。包括共享内存算法用于覆盖树构建，以及两种分布式内存算法：简单的点分区策略和空间分区策略。

Result: 在真实世界的高维数据集上，使用1024核心时实现了678.34倍的加速（平均每个顶点70个邻居），使用4096核心时实现了1590.99倍的加速（平均每个顶点500个邻居）。

Conclusion: 本文提出的分布式内存算法在多种真实和合成数据集上表现出并行扩展性，尤其是在高维数据集上实现了显著的加速。

Abstract: Computing fixed-radius near-neighbor graphs is an important first step for
many data analysis algorithms. Near-neighbor graphs connect points that are
close under some metric, endowing point clouds with a combinatorial structure.
As computing power and data acquisition methods advance, diverse sources of
large scientific datasets would greatly benefit from scalable solutions to this
common subroutine for downstream analysis. Prior work on parallel nearest
neighbors has made great progress in problems like k-nearest and approximate
nearest neighbor search problems, with particular attention on Euclidean
spaces. Yet many applications need exact solutions and non-Euclidean metrics.
This paper presents a scalable sparsity-aware distributed memory algorithm
using cover trees to compute near-neighbor graphs in general metric spaces. We
provide a shared-memory algorithm for cover tree construction and demonstrate
its competitiveness with state-of-the-art fixed-radius search data structures.
We then introduce two distributed-memory algorithms for the near-neighbor graph
problem, a simple point-partitioning strategy and a spatial-partitioning
strategy, which leverage the cover tree algorithm on each node. Our algorithms
exhibit parallel scaling across a variety of real and synthetic datasets for
both traditional and non-traditional metrics. On real world high dimensional
datasets with one million points, we achieve speedups up to 678.34x over the
state-of-the-art using 1024 cores for graphs with 70 neighbors per vertex (on
average), and up to 1590.99x using 4096 cores for graphs with 500 neighbors per
vertex (on average).

</details>


### [221] [Privacy-Preserving and Incentive-Driven Relay-Based Framework for Cross-Domain Blockchain Interoperability](https://arxiv.org/abs/2510.14151)
*Saeed Moradi,Koosha Esmaeilzadeh Khorasani,Sara Rouhani*

Main category: cs.DC

TL;DR: 该论文提出了一种区块链无关的框架，通过加密技术和轻量级设计实现许可链与无许可链的安全互操作，性能评估验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决许可链和无许可链因访问控制、架构和安全需求差异带来的互操作性挑战，释放区块链的协作潜力。

Method: 框架采用了加密技术，结合Clover和Dandelion++协议增强交易匿名性，并通过轻量级架构简化实现和维护。

Result: 性能评估表明，该框架在异构区块链生态系统中实现了安全高效的互操作性，具体指标包括转发时间、吞吐量和可用性。

Conclusion: 该论文提出了一种区块链无关的框架，成功实现了许可链和无许可链之间的互操作性，通过加密技术和轻量级架构设计确保了安全性和效率。

Abstract: Interoperability is essential for transforming blockchains from isolated
networks into collaborative ecosystems, unlocking their full potential. While
significant progress has been made in public blockchain interoperability,
bridging permissioned and permissionless blockchains poses unique challenges
due to differences in access control, architectures, and security requirements.
This paper introduces a blockchain-agnostic framework to enable
interoperability between permissioned and permissionless networks. Leveraging
cryptographic techniques, the framework ensures secure data exchanges. Its
lightweight architectural design simplifies implementation and maintenance,
while the integration of Clover and Dandelion++ protocols enhances transaction
anonymity. Performance evaluations demonstrate the framework's effectiveness in
achieving secure and efficient interoperability by measuring the forwarding
time, the throughput, the availability, and their collusion impact of the
system across heterogeneous blockchain ecosystems.

</details>


### [222] [Proof-Carrying Fair Ordering: Asymmetric Verification for BFT via Incremental Graphs](https://arxiv.org/abs/2510.14186)
*Pengkun Ren,Hai Dong,Nasrin Sohrabi,Zahir Tari,Pengcheng Zhang*

Main category: cs.DC

TL;DR: AUTIG是一种高性能、可插拔的顺序公平服务，通过不对称架构和关键创新，显著提升了BFT共识协议的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有BFT共识协议中对称且冗余的验证范式，减少领导者昂贵排序计算的重复执行，以提升性能和效率。

Method: AUTIG采用不对称架构，领导者维护UTIG以分摊图构建成本，并生成结构化公平证明；跟随者无需维护历史状态即可验证证明。关键创新包括增量图维护、解耦管道和覆盖所有内部对的证明设计。

Result: AUTIG在部分同步条件下实现了比对称图基线更高的吞吐量和更低的端到端延迟，同时保持γ-批量顺序公平性。

Conclusion: AUTIG通过其不对称架构和关键创新，实现了高性能和可插拔的顺序公平服务，显著提高了吞吐量并降低了端到端延迟，同时保持了γ-批量顺序公平性。

Abstract: Byzantine Fault-Tolerant (BFT) consensus protocols ensure agreement on
transaction ordering despite malicious actors, but unconstrained ordering power
enables sophisticated value extraction attacks like front running and sandwich
attacks - a critical threat to blockchain systems. Order-fair consensus curbs
adversarial value extraction by constraining how leaders may order
transactions. While state-of-the-art protocols such as Themis attain strong
guarantees through graph-based ordering, they ask every replica to re-run the
leader's expensive ordering computation for validation - an inherently
symmetric and redundant paradigm. We present AUTIG, a high-performance,
pluggable order-fairness service that breaks this symmetry. Our key insight is
that verifying a fair order does not require re-computing it. Instead,
verification can be reduced to a stateless audit of succinct, verifiable
assertions about the ordering graph's properties. AUTIG realizes this via an
asymmetric architecture: the leader maintains a persistent
Unconfirmed-Transaction Incremental Graph (UTIG) to amortize graph construction
across rounds and emits a structured proof of fairness with each proposal;
followers validate the proof without maintaining historical state. AUTIG
introduces three critical innovations: (i) incremental graph maintenance driven
by threshold-crossing events and state changes; (ii) a decoupled pipeline that
overlaps leader-side collection/update/extraction with follower-side stateless
verification; and (iii) a proof design covering all internal pairs in the
finalized prefix plus a frontier completeness check to rule out hidden external
dependencies. We implement AUTIG and evaluate it against symmetric graph-based
baselines under partial synchrony. Experiments show higher throughput and lower
end-to-end latency while preserving gamma-batch-order-fairness.

</details>


### [223] [FairBatching: Fairness-Aware Batch Formation for LLM Inference](https://arxiv.org/abs/2510.14392)
*Hongtao Lyu,Boyue Liu,Mingyu Wu,Haibo Chen*

Main category: cs.DC

TL;DR: FairBatching是一种新型LLM推理调度器，通过公平资源分配和动态调整，显著提升系统性能和容量。


<details>
  <summary>Details</summary>
Motivation: 现有调度器在防止解码停滞的同时引入计算不公平，导致解码松弛未充分利用和预填充队列延迟，影响系统QoS。

Method: 提出FairBatching调度器，采用自适应批量容量确定机制和公平动态批量形成算法，打破解码优先范式，实现资源公平分配。

Result: FairBatching将TTFT尾延迟降低高达2.29倍，单节点容量提升20.0%，集群级容量提升54.3%。

Conclusion: FairBatching显著提升了LLM推理系统的整体服务质量，通过动态调整计算资源分配，实现了TTFT尾延迟的显著降低和TPOT SLO的稳健维持。

Abstract: Large language model (LLM) inference systems face a fundamental tension
between minimizing Time-to-First-Token (TTFT) latency for new requests and
maintaining a high, steady token generation rate (low Time-Per-Output-Token, or
TPOT) for ongoing requests. Existing stall-free batching schedulers proposed by
Sarathi, while effective at preventing decode stalls, introduce significant
computational unfairness. They prioritize decode tasks excessively,
simultaneously leading to underutilized decode slack and unnecessary prefill
queuing delays, which collectively degrade the system's overall quality of
service (QoS).
  This work identifies the root cause of this unfairness: the non-monotonic
nature of Time-Between-Tokens (TBT) as a scheduling metric and the rigid
decode-prioritizing policy that fails to adapt to dynamic workload bursts. We
therefore propose FairBatching, a novel LLM inference scheduler that enforces
fair resource allocation between prefill and decode tasks. It features an
adaptive batch capacity determination mechanism, which dynamically adjusts the
computational budget to improve the GPU utilization without triggering SLO
violations. Its fair and dynamic batch formation algorithm breaks away from the
decode-prioritizing paradigm, allowing computation resources to be reclaimed
from bursting decode tasks to serve prefill surges, achieving global fairness.
Furthermore, FairBatching provides a novel load estimation method, enabling
more effective coordination with upper-level schedulers. Implemented and
evaluated on realistic traces, FairBatching significantly reduces TTFT tail
latency by up to 2.29x while robustly maintaining TPOT SLOs, achieving overall
20.0% improvement in single-node capacity and 54.3% improvement in
cluster-level capacity.

</details>


### [224] [ScalePool: Hybrid XLink-CXL Fabric for Composable Resource Disaggregation in Unified Scale-up Domains](https://arxiv.org/abs/2510.14580)
*Hyein Woo,Miryeong Kwon,Jiseon Kim,Eunjee Na,Hanjin Choi,Seonghyeon Jang,Myoungsoo Jung*

Main category: cs.DC

TL;DR: ScalePool是一种新型集群架构，通过整合XLink和CXL实现高效加速器互联和内存共享，显著提升LLM训练速度和内存密集型工作负载性能。


<details>
  <summary>Details</summary>
Motivation: 传统长距离网络互联在加速器集群中存在效率低下和互操作性限制的问题，ScalePool旨在通过统一的硬件互连解决这些问题，实现高效、可扩展的加速器互联和内存共享。

Method: ScalePool采用XLink进行集群内低延迟加速器通信，同时使用基于CXL的分层交换结构实现可扩展和一致的集群间内存共享。通过CXL抽象接口，实现异构集群操作和可组合资源分解。此外，引入显式内存分层策略：延迟关键的tier-1结合加速器本地内存与CXL和XLink，而高容量的tier-2使用专用内存节点通过CXL结构互连。

Result: 评估结果显示，ScalePool平均加速LLM训练1.22倍，最高可达1.84倍；tier-2内存分解策略将内存密集型工作负载的延迟降低最多4.5倍。

Conclusion: ScalePool通过整合XLink和CXL，解决了异构集群操作和资源分解的互操作性限制，显著提升了LLM训练效率和内存密集型工作负载的延迟表现。

Abstract: This paper proposes ScalePool, a novel cluster architecture designed to
interconnect numerous accelerators using unified hardware interconnects rather
than traditional long-distance networking. ScalePool integrates
Accelerator-Centric Links (XLink) and Compute Express Link (CXL) into a unified
XLink-CXL hybrid fabric. Specifically, ScalePool employs XLink for
intra-cluster, low-latency accelerator communication, while using hierarchical
CXL-based switching fabrics for scalable and coherent inter-cluster memory
sharing. By abstracting interfaces through CXL, ScalePool structurally resolves
interoperability constraints, enabling heterogeneous cluster operation and
composable resource disaggregation. In addition, ScalePool introduces explicit
memory tiering: the latency-critical tier-1 combines accelerator-local memory
with coherence-centric CXL and XLink, whereas the highcapacity tier-2 employs
dedicated memory nodes interconnected by a CXL-based fabric, achieving scalable
and efficient memory pooling. Evaluation results show that ScalePool
accelerates LLM training by 1.22x on average and up to 1.84x compared to
conventional RDMA-based environments. Furthermore, the proposed tier-2 memory
disaggregation strategy reduces latency by up to 4.5x for memory-intensive
workloads.

</details>


### [225] [Balls and Bins and the Infinite Process with Random Deletions](https://arxiv.org/abs/2510.14798)
*Petra Berenbrink,Tom Friedetzky,Peter Kling,Lars Nagel*

Main category: cs.DC

TL;DR: 论文研究了无限球-箱过程中的差异和超载问题，证明了差异为O(log(n))，超载为loglog(n)+O(1)，并提供了差异的下界匹配。


<details>
  <summary>Details</summary>
Motivation: 研究动机是分析无限球-箱过程中的差异和超载问题，特别是在插入和删除操作同时存在的情况下，如何量化最大负载与平均负载的关系。

Method: 论文采用了分层归纳法（layered induction）和详细的势能分析（potential analysis），并应用概率耦合（probabilistic couplings）简化了分析过程。

Result: 论文的主要结果是证明了差异和超载的界限，分别为O(log(n))和loglog(n)+O(1)，并提供了差异的下界匹配。

Conclusion: 论文证明了在任意选择的时间点，总球数超过平均值的数量为O(n)，差异为O(log(n))，且提供了差异的下界。同时，证明了超载为loglog(n)+O(1)。对于“良好”插入概率序列，差异甚至被限制为loglog(n)+O(1)。

Abstract: We consider an infinite balls-into-bins process with deletions where in each
discrete step $t$ a coin is tossed as to whether, with probability $\beta(t)
\in (0,1)$, a new ball is allocated using the Greedy[2] strategy (which places
the ball in the lower loaded of two bins sampled uniformly at random) or, with
remaining probability $1-\beta(t)$, a ball is deleted from a non-empty bin
chosen uniformly at random. Let $n$ be the number of bins and $m(t)$ the total
load at time $t$. We are interested in bounding the discrepancy $x_{\max}(t) -
m(t)/n$ (current maximum load relative to current average) and the overload
$x_{\max}(t) - m_{\max}(t)/n$ (current maximum load relative to highest average
observed so far).
  We prove that at an arbitrarily chosen time $t$ the total number of balls
above the average is $O(n)$ and that the discrepancy is $ O(\log(n))$. For the
discrepancy, we provide a matching lower bound. Furthermore we prove that at an
arbitrarily chosen time $t$ the overload is $\log\log(n)+O(1)$. For "good"
insertion probability sequences (in which the average load of time intervals
with polynomial length increases in expectation) we show that even the
discrepancy is bounded by $\log\log(n)+O(1)$.
  One of our main analytical tools is a layered induction, as per [ABKU99].
Since our model allows for rather more general scenarios than what was
previously considered, the formal analysis requires some extra ingredients as
well, in particular a detailed potential analysis. Furthermore, we simplify the
setup by applying probabilistic couplings to obtain certain "recovery"
properties, which eliminate much of the need for intricate and careful
conditioning elsewhere in the analysis.

</details>


### [226] [JASDA: Introducing Job-Aware Scheduling in Scheduler-Driven Job Atomization](https://arxiv.org/abs/2510.14599)
*Michal Konopa,Jan Fesl,Ladislav Ber ánek*

Main category: cs.DC

TL;DR: JASDA是一种去中心化调度范式，通过双向交互和拍卖理论原则，解决了MIG-enabled GPU工作负载的复杂性问题，实现了高效、公平的资源管理。


<details>
  <summary>Details</summary>
Motivation: 传统集中式调度在面对MIG-enabled GPU工作负载的复杂性和时间可变性时面临可扩展性挑战，需要一种新的调度方法。

Method: JASDA引入了一种新颖的去中心化协商范式，通过双向、迭代的交互，将反馈、校准和概率安全性嵌入调度循环中，实现自适应和透明的决策。

Result: JASDA能够平衡利用率、公平性和时间响应性，为AI和农业4.0等现代环境提供适应性强的资源管理。

Conclusion: JASDA通过结合拍卖理论和在线优化的原则，为现代MIG-enabled GPU环境提供了一个可扩展、市场感知和公平驱动的资源管理基础，连接了理论调度模型与实际部署。

Abstract: The increasing complexity and temporal variability of workloads on
MIG-enabled GPUs challenge the scalability of traditional centralized
scheduling. Building upon the SJA concept, this paper introduces JASDA-a novel
paradigm that extends SJA from a largely centralized scheduling model toward a
fully decentralized negotiation process. In JASDA, jobs actively generate and
score feasible subjobs in response to scheduler-announced execution windows,
while the scheduler performs policy-driven clearing that balances utilization,
fairness, and temporal responsiveness. This bidirectional, iterative
interaction embeds feedback, calibration, and probabilistic safety directly
into the scheduling loop, enabling adaptive and transparent decision-making. By
coupling principles from auction theory and online optimization with the
temporal granularity of GPU workloads, JASDA provides a scalable foundation for
market-aware and fairness-driven resource management-bridging theoretical
scheduling models with practical deployment in modern MIG-enabled environments
relevant to Artificial Intelligence and Agriculture 4.0.

</details>


### [227] [MPI-over-CXL: Enhancing Communication Efficiency in Distributed HPC Systems](https://arxiv.org/abs/2510.14622)
*Miryeong Kwon,Donghyun Gouk,Hyein Woo,Junhee Kim,Jinwoo Baek,Kyungkuk Nam,Sangyoon Ji,Jiseon Kim,Hanyeoreum Bae,Junhyeok Jang,Hyunwoo You,Junseok Moon,Myoungsoo Jung*

Main category: cs.DC

TL;DR: MPI-over-CXL利用CXL的共享内存特性，替代传统数据拷贝，显著提升HPC通信效率。


<details>
  <summary>Details</summary>
Motivation: 传统MPI实现依赖显式内存拷贝操作，导致冗余数据移动和缓冲区管理的开销，影响了HPC工作负载的性能。

Method: MPI-over-CXL采用直接共享内存访问替代传统数据拷贝方法，通过将共享内存区域直接映射到MPI进程的虚拟地址空间中，实现高效的基于指针的通信。

Result: 使用代表性基准测试的评估表明，MPI-over-CXL相比传统MPI系统有显著的性能提升。

Conclusion: MPI-over-CXL通过利用CXL的缓存一致性共享内存，显著减少了通信延迟和内存带宽使用，为大规模HPC环境提供了更高的效率和可扩展性。

Abstract: MPI implementations commonly rely on explicit memory-copy operations,
incurring overhead from redundant data movement and buffer management. This
overhead notably impacts HPC workloads involving intensive inter-processor
communication. In response, we introduce MPI-over-CXL, a novel MPI
communication paradigm leveraging CXL, which provides cache-coherent shared
memory across multiple hosts. MPI-over-CXL replaces traditional data-copy
methods with direct shared memory access, significantly reducing communication
latency and memory bandwidth usage. By mapping shared memory regions directly
into the virtual address spaces of MPI processes, our design enables efficient
pointer-based communication, eliminating redundant copying operations. To
validate this approach, we implement a comprehensive hardware and software
environment, including a custom CXL 3.2 controller, FPGA-based multi-host
emulation, and dedicated software stack. Our evaluations using representative
benchmarks demonstrate substantial performance improvements over conventional
MPI systems, underscoring MPI-over-CXL's potential to enhance efficiency and
scalability in large-scale HPC environments.

</details>


### [228] [xLLM Technical Report](https://arxiv.org/abs/2510.14686)
*Tongxuan Liu,Tao Peng,Peijun Yang,Xiaoyang Zhao,Xiusheng Lu,Weizhe Huang,Zirui Liu,Xiaoyu Chen,Zhiwei Liang,Jun Xiong,Donghe Jin,Minchao Zhang,Jinrong Guo,Yingxu Deng,Xu Zhang,Xianzhe Dong,Siqi Wang,Siyu Wu,Yu Wu,Zihan Tang,Yuting Zeng,Yanshu Wang,Jinguang Liu,Meng Kang,Menxin Li,Yunlong Wang,Yiming Liu,Xiaolong Ma,Yifan Wang,Yichen Zhang,Jinrun Yin,Keyang Zheng,Jiawei Yin,Jun Zhang,Ziyue Wang,Xiaobo Lin,Liangyu Liu,Liwei Lan,Yang Liu,Chunhua Peng,Han Liu,Songcheng Ren,Xuezhu Wang,Yunheng Shen,Yi Wang,Guyue Liu,Hui Chen,Tong Yang,Hailong Yang,Jing Li,Guiguang Ding,Ke Zhang*

Main category: cs.DC

TL;DR: xLLM是一个高效LLM推理框架，通过解耦架构和深度优化，显著提升性能和资源效率，适用于企业级服务。


<details>
  <summary>Details</summary>
Motivation: 为了解决高性能、大规模企业级LLM推理的挑战，优化AI加速器的利用率。

Method: xLLM采用解耦的服务-引擎架构，服务层包含智能调度模块和分布式架构，引擎层通过多层级执行管道优化、自适应图模式和xTensor内存管理实现资源饱和。

Result: xLLM在相同TPOT约束下，吞吐量最高可达MindIE的1.7倍和vLLM-Ascend的2.2倍，且保持Deepseek系列模型的平均吞吐量为MindIE的1.7倍。

Conclusion: xLLM框架通过创新的解耦服务-引擎架构和深度优化，显著提升了LLM推理的性能和资源效率，适用于大规模企业级服务。

Abstract: We introduce xLLM, an intelligent and efficient Large Language Model (LLM)
inference framework designed for high-performance, large-scale enterprise-grade
serving, with deep optimizations for diverse AI accelerators. To address these
challenges, xLLM builds a novel decoupled service-engine architecture. At the
service layer, xLLM-Service features an intelligent scheduling module that
efficiently processes multimodal requests and co-locates online and offline
tasks through unified elastic scheduling to maximize cluster utilization. This
module also relies on a workload-adaptive dynamic Prefill-Decode (PD)
disaggregation policy and a novel Encode-Prefill-Decode (EPD) disaggregation
policy designed for multimodal inputs. Furthermore, it incorporates a
distributed architecture to provide global KV Cache management and robust
fault-tolerant capabilities for high availability. At the engine layer,
xLLM-Engine co-optimizes system and algorithm designs to fully saturate
computing resources. This is achieved through comprehensive multi-layer
execution pipeline optimizations, an adaptive graph mode and an xTensor memory
management. xLLM-Engine also further integrates algorithmic enhancements such
as optimized speculative decoding and dynamic EPLB, collectively serving to
substantially boost throughput and inference efficiency. Extensive evaluations
demonstrate that xLLM delivers significantly superior performance and resource
efficiency. Under identical TPOT constraints, xLLM achieves throughput up to
1.7x that of MindIE and 2.2x that of vLLM-Ascend with Qwen-series models, while
maintaining an average throughput of 1.7x that of MindIE with Deepseek-series
models. xLLM framework is publicly available at
https://github.com/jd-opensource/xllm and
https://github.com/jd-opensource/xllm-service.

</details>


### [229] [Deadlock-free routing for Full-mesh networks without using Virtual Channels](https://arxiv.org/abs/2510.14730)
*Alejandro Cano,Cristóbal Camarero,Carmen Martínez,Ramón Beivide*

Main category: cs.DC

TL;DR: TERA是一种无需虚拟通道的路由算法，通过物理子网络实现无死锁非最小路径，显著提升性能并减少资源开销。


<details>
  <summary>Details</summary>
Motivation: 高基数、低直径网络（如HyperX和Dragonfly）依赖虚拟通道(VCs)避免死锁，但VCs导致交换机在面积、功耗和设计复杂性方面开销大，限制了可扩展性。

Method: 提出TERA (Topology-Embedded Routing Algorithm)，利用嵌入物理子网络实现无死锁非最小路径，避免使用VCs。

Result: 在Full-mesh网络中，TERA比链路排序算法在对抗性流量下性能提升80%，应用内核中提升100%；与VC-based方法相比，缓冲区需求减少50%，同时保持类似延迟和吞吐量。在2D-HyperX中，TERA比同类算法性能提升达32%。

Conclusion: TERA是一种新型路由算法，通过嵌入物理子网络提供无死锁的非最小路径，无需使用虚拟通道(VCs)，在Full-mesh网络中表现优异，显著优于传统链路排序算法和VC-based方法。

Abstract: High-radix, low-diameter networks like HyperX and Dragonfly use a Full-mesh
core, and rely on multiple virtual channels (VCs) to avoid packet deadlocks in
adaptive routing. However, VCs introduce significant overhead in the switch in
terms of area, power, and design complexity, limiting the switch scalability.
This paper starts by revisiting VC-less routing through link ordering schemes
in Full-mesh networks, which offer implementation simplicity but suffer from
performance degradation under adversarial traffic. Thus, to overcome these
challenges, we propose TERA (Topology-Embedded Routing Algorithm), a novel
routing algorithm which employs an embedded physical subnetwork to provide
deadlock-free non-minimal paths without using VCs.
  In a Full-mesh network, TERA outperforms link ordering routing algorithms by
80% when dealing with adversarial traffic, and up to 100% in application
kernels. Furthermore, compared to other VC-based approaches, it reduces buffer
requirements by 50%, while maintaining comparable latency and throughput.
Lastly, early results from a 2D-HyperX evaluation show that TERA outperforms
state-of-the-art algorithms that use the same number of VCs, achieving
performance improvements of up to 32%.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [230] [PoissonNet: A Local-Global Approach for Learning on Surfaces](https://arxiv.org/abs/2510.14146)
*Arman Maesumi,Tanish Makadia,Thibault Groueix,Vladimir G. Kim,Daniel Ritchie,Noam Aigerman*

Main category: cs.GR

TL;DR: PoissonNet是一种新型的神经架构，通过局部-全局学习方案和泊松方程作为特征传播机制，克服了现有方法的缺陷，并在多项任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的网格学习网络架构在高频特征学习、感受野不足、对离散化的敏感性以及计算效率之间存在微妙的权衡。

Method: PoissonNet的核心网络块简单：在网格的梯度域中应用学习的局部特征变换，然后求解泊松系统以全局传播标量特征更新。

Result: PoissonNet在各种实验中验证了其高效性和可扩展性，在语义分割和参数化动画表面等任务中表现优于现有方法。

Conclusion: PoissonNet通过局部-全局学习方案，利用泊松方程作为特征传播的主要机制，克服了现有网络架构的多种缺陷，并在语义分割和参数化动画表面等任务中实现了最先进的性能。

Abstract: Many network architectures exist for learning on meshes, yet their
constructions entail delicate trade-offs between difficulty learning
high-frequency features, insufficient receptive field, sensitivity to
discretization, and inefficient computational overhead. Drawing from classic
local-global approaches in mesh processing, we introduce PoissonNet, a novel
neural architecture that overcomes all of these deficiencies by formulating a
local-global learning scheme, which uses Poisson's equation as the primary
mechanism for feature propagation. Our core network block is simple; we apply
learned local feature transformations in the gradient domain of the mesh, then
solve a Poisson system to propagate scalar feature updates across the surface
globally. Our local-global learning framework preserves the features's full
frequency spectrum and provides a truly global receptive field, while remaining
agnostic to mesh triangulation. Our construction is efficient, requiring far
less compute overhead than comparable methods, which enables scalability --
both in the size of our datasets, and the size of individual training samples.
These qualities are validated on various experiments where, compared to
previous intrinsic architectures, we attain state-of-the-art performance on
semantic segmentation and parameterizing highly-detailed animated surfaces.
Finally, as a central application of PoissonNet, we show its ability to learn
deformations, significantly outperforming state-of-the-art architectures that
learn on surfaces.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [231] [A Levelset Algorithm for 3D-Tarksi](https://arxiv.org/abs/2510.14777)
*Sebastian Haslebacher,Jonas Lill*

Main category: cs.DS

TL;DR: 提出一种新算法，高效找到单调函数的Tarski不动点，匹配现有最优性能。


<details>
  <summary>Details</summary>
Motivation: 目标是匹配由Etessami等人提出的 $\Omega(\log^2 N)$ 查询下限，以及Fearnley等人现有的最先进算法。

Method: 该算法在 $O(\log^2 N)$ 时间内运行，并对 $F$ 进行 $O(\log^2 N)$ 次查询。

Result: 该算法成功达到了与现有最优算法相同的性能，即 $O(\log^2 N)$ 时间和查询复杂度。

Conclusion: 本文提出了一种简单的新算法，用于找到单调函数 $F : [N]^3 \rightarrow [N]^3$ 的Tarski不动点。

Abstract: We present a simple new algorithm for finding a Tarski fixed point of a
monotone function $F : [N]^3 \rightarrow [N]^3$. Our algorithm runs in
$O(\log^2 N)$ time and makes $O(\log^2 N)$ queries to $F$, matching the
$\Omega(\log^2 N)$ query lower bound due to Etessami et al.\ as well as the
existing state-of-the-art algorithm due to Fearnley et al.

</details>


### [232] [Prediction-Specific Design of Learning-Augmented Algorithms](https://arxiv.org/abs/2510.14887)
*Sizhe Li,Nicolas Christianson,Tongxin Li*

Main category: cs.DS

TL;DR: 论文提出强最优算法框架，通过预测特定设计显著提升在线决策性能，并在多个问题中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有算法框架过于保守，未能充分利用问题结构以预测特定的方式优化性能。

Method: 提出了一个双层次优化框架，用于系统设计强最优算法，并在多个经典在线问题中实现了具体算法。

Result: 通过预测特定设计，算法在鲁棒性和一致性之间实现了帕累托最优，并在实证研究中验证了性能提升。

Conclusion: 预测特定、强最优算法能显著提升多种在线决策场景的性能。

Abstract: Algorithms with predictions} has emerged as a powerful framework to combine
the robustness of traditional online algorithms with the data-driven
performance benefits of machine-learned (ML) predictions. However, most
existing approaches in this paradigm are overly conservative, {as they do not
leverage problem structure to optimize performance in a prediction-specific
manner}. In this paper, we show that such prediction-specific performance
criteria can enable significant performance improvements over the coarser
notions of consistency and robustness considered in prior work. Specifically,
we propose a notion of \emph{strongly-optimal} algorithms with predictions,
which obtain Pareto optimality not just in the worst-case tradeoff between
robustness and consistency, but also in the prediction-specific tradeoff
between these metrics. We develop a general bi-level optimization framework
that enables systematically designing strongly-optimal algorithms in a wide
variety of problem settings, and we propose explicit strongly-optimal
algorithms for several classic online problems: deterministic and randomized
ski rental, and one-max search. Our analysis reveals new structural insights
into how predictions can be optimally integrated into online algorithms by
leveraging a prediction-specific design. To validate the benefits of our
proposed framework, we empirically evaluate our algorithms in case studies on
problems including dynamic power management and volatility-based index trading.
Our results demonstrate that prediction-specific, strongly-optimal algorithms
can significantly improve performance across a variety of online
decision-making settings.

</details>


### [233] [Tree-Like Shortcuttings of Trees](https://arxiv.org/abs/2510.14918)
*Hung Le,Lazar Milenković,Shay Solomon,Cuong Than*

Main category: cs.DS

TL;DR: 论文研究了树状捷径的稀疏性和跳数直径，提出了新的上界和下界，解决了开放性问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于现有常数跳捷径中存在密集子图的问题，这限制了其在实际应用中的效果。论文旨在探索更‘树状’的捷径，以提高其适用性。

Method: 论文采用树状参数（如树宽和树状性）来度量图与树的距离，并通过理论分析和证明，建立了跳数直径与树宽之间的最优权衡。

Result: 论文提出了跳数直径与树宽之间的最优权衡，特别对于跳数直径在O(log log n)范围内的情况，并给出了更大的k值的下界。

Conclusion: 该论文通过研究树状捷径的稀疏性和跳数直径之间的权衡，提出了新的上界和下界，解决了[FL22, Le23]中的一个开放性问题。

Abstract: Sparse shortcuttings of trees -- equivalently, sparse 1-spanners for tree
metrics with bounded hop-diameter -- have been studied extensively (under
different names and settings), since the pioneering works of [Yao82, Cha87,
AS87, BTS94], initially motivated by applications to range queries, online tree
product, and MST verification, to name a few. These constructions were also
lifted from trees to other graph families using known low-distortion embedding
results. The works of [Yao82, Cha87, AS87, BTS94] establish a tight tradeoff
between hop-diameter and sparsity (or average degree) for tree shortcuttings
and imply constant-hop shortcuttings for $n$-node trees with sparsity $O(\log^*
n)$. Despite their small sparsity, all known constant-hop shortcuttings contain
dense subgraphs (of sparsity $\Omega(\log n)$), which is a significant drawback
for many applications.
  We initiate a systematic study of constant-hop tree shortcuttings that are
``tree-like''. We focus on two well-studied graph parameters that measure how
far a graph is from a tree: arboricity and treewidth. Our contribution is
twofold.
  * New upper and lower bounds for tree-like shortcuttings of trees, including
an optimal tradeoff between hop-diameter and treewidth for all hop-diameter up
to $O(\log\log n)$. We also provide a lower bound for larger values of $k$,
which together yield $\text{hop-diameter}\times \text{treewidth} =
\Omega((\log\log n)^2)$ for all values of hop-diameter, resolving an open
question of [FL22, Le23]. [...]

</details>
