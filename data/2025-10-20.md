<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [cs.AI](#cs.AI) [Total: 30]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.SE](#cs.SE) [Total: 12]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.DS](#cs.DS) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GAZE:Governance-Aware pre-annotation for Zero-shot World Model Environments](https://arxiv.org/abs/2510.14992)
*Leela Krishna,Mengyang Zhao,Saicharithreddy Pasula,Harshit Rajgarhia,Abhishek Mukherji*

Main category: cs.CV

TL;DR: GAZE自动化流程通过AI辅助标注和标准化处理，高效生成高质量世界模型训练数据，节省时间和人力。


<details>
  <summary>Details</summary>
Motivation: 传统手动标注效率低且成本高，阻碍了大规模、高质量世界模型训练数据的生成。

Method: GAZE流程包括三个步骤：(i) 标准化360度视频格式并分片处理；(ii) 应用多模态AI模型进行密集预标注；(iii) 整合信号为结构化输出以供人工快速验证。

Result: GAZE流程节省了约19分钟/小时的审核时间，减少80%以上的人工审核量，生成高密度、高一致性的隐私感知数据集。

Conclusion: GAZE流程通过自动化处理和AI辅助标注，显著提高了世界模型训练数据的质量和效率，同时确保了隐私和治理要求。

Abstract: Training robust world models requires large-scale, precisely labeled
multimodal datasets, a process historically bottlenecked by slow and expensive
manual annotation. We present a production-tested GAZE pipeline that automates
the conversion of raw, long-form video into rich, task-ready supervision for
world-model training. Our system (i) normalizes proprietary 360-degree formats
into standard views and shards them for parallel processing; (ii) applies a
suite of AI models (scene understanding, object tracking, audio transcription,
PII/NSFW/minor detection) for dense, multimodal pre-annotation; and (iii)
consolidates signals into a structured output specification for rapid human
validation.
  The GAZE workflow demonstrably yields efficiency gains (~19 minutes saved per
review hour) and reduces human review volume by >80% through conservative
auto-skipping of low-salience segments. By increasing label density and
consistency while integrating privacy safeguards and chain-of-custody metadata,
our method generates high-fidelity, privacy-aware datasets directly consumable
for learning cross-modal dynamics and action-conditioned prediction. We detail
our orchestration, model choices, and data dictionary to provide a scalable
blueprint for generating high-quality world model training data without
sacrificing throughput or governance.

</details>


### [2] [PC-UNet: An Enforcing Poisson Statistics U-Net for Positron Emission Tomography Denoising](https://arxiv.org/abs/2510.14995)
*Yang Shi,Jingchao Wang,Liangsi Lu,Mingxuan Huang,Ruixin He,Yifeng Xie,Hanqian Liu,Minzhe Guo,Yangyang Liang,Weipeng Zhang,Zimeng Li,Xuhang Chen*

Main category: cs.CV

TL;DR: 针对低剂量PET成像中的泊松噪声问题，提出PC-UNet模型，结合PVMC-Loss函数，显著提高图像保真度和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 当前去噪方法在低剂量条件下无法有效处理增加的泊松噪声，导致图像失真和伪影。

Method: 提出了一种名为PC-UNet的模型，结合了新的Poisson方差和均值一致性损失函数（PVMC-Loss），该函数整合了物理数据以提高图像保真度。

Result: 在PET数据集上的测试显示，PC-UNet能够提高物理一致性和图像保真度。

Conclusion: PET成像在医学中的重要性被强调，但其临床应用受限，主要因为高信噪比剂量导致辐射暴露增加。

Abstract: Positron Emission Tomography (PET) is crucial in medicine, but its clinical
use is limited due to high signal-to-noise ratio doses increasing radiation
exposure. Lowering doses increases Poisson noise, which current denoising
methods fail to handle, causing distortions and artifacts. We propose a Poisson
Consistent U-Net (PC-UNet) model with a new Poisson Variance and Mean
Consistency Loss (PVMC-Loss) that incorporates physical data to improve image
fidelity. PVMC-Loss is statistically unbiased in variance and gradient
adaptation, acting as a Generalized Method of Moments implementation, offering
robustness to minor data mismatches. Tests on PET datasets show PC-UNet
improves physical consistency and image fidelity, proving its ability to
integrate physical information effectively.

</details>


### [3] [DeLeaker: Dynamic Inference-Time Reweighting For Semantic Leakage Mitigation in Text-to-Image Models](https://arxiv.org/abs/2510.15015)
*Mor Ventura,Michael Toker,Or Patashnik,Yonatan Belinkov,Roi Reichart*

Main category: cs.CV

TL;DR: DeLeaker是一种轻量级、无需优化的方法，通过动态调整注意力图减少T2I模型中的语义泄漏，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像（T2I）模型存在语义泄漏问题，即不同实体间语义相关特征的意外传递。现有方法多为基于优化或依赖外部输入。

Method: DeLeaker采用轻量级、无需优化的推理时方法，直接干预模型的注意力图，通过动态重加权抑制跨实体间的过度交互，同时强化每个实体的身份特征。

Result: 实验表明，DeLeaker在无需外部信息的情况下，性能优于所有基线方法，有效减少语义泄漏且不影响生成图像的保真度或质量。

Conclusion: DeLeaker通过动态调整注意力权重有效减少了语义泄漏问题，为更精确的文本到图像生成模型奠定了基础。

Abstract: Text-to-Image (T2I) models have advanced rapidly, yet they remain vulnerable
to semantic leakage, the unintended transfer of semantically related features
between distinct entities. Existing mitigation strategies are often
optimization-based or dependent on external inputs. We introduce DeLeaker, a
lightweight, optimization-free inference-time approach that mitigates leakage
by directly intervening on the model's attention maps. Throughout the diffusion
process, DeLeaker dynamically reweights attention maps to suppress excessive
cross-entity interactions while strengthening the identity of each entity. To
support systematic evaluation, we introduce SLIM (Semantic Leakage in IMages),
the first dataset dedicated to semantic leakage, comprising 1,130
human-verified samples spanning diverse scenarios, together with a novel
automatic evaluation framework. Experiments demonstrate that DeLeaker
consistently outperforms all baselines, even when they are provided with
external information, achieving effective leakage mitigation without
compromising fidelity or quality. These results underscore the value of
attention control and pave the way for more semantically precise T2I models.

</details>


### [4] [UrbanVerse: Scaling Urban Simulation by Watching City-Tour Videos](https://arxiv.org/abs/2510.15018)
*Mingxuan Liu,Honglin He,Elisa Ricci,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: UrbanVerse是一个数据驱动的系统，将城市视频转换为高保真模拟场景，显著提升了AI代理的训练效果和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的人工或程序生成的模拟场景缺乏可扩展性或无法捕捉真实世界的复杂性，限制了AI代理在城市场景中的训练效果。

Method: UrbanVerse系统包含UrbanVerse-100K（10万+标注的3D城市资产库）和UrbanVerse-Gen（自动从视频提取场景布局并生成3D模拟的流程），运行于IsaacSim平台。

Result: UrbanVerse生成的场景在人类评估中达到与手工制作场景相当的逼真度。在导航任务中，基于UrbanVerse训练的策略在仿真和零样本仿真到现实的迁移中分别提升了6.3%和30.1%的成功率。

Conclusion: UrbanVerse通过数据驱动的方法，成功将众包城市视频转换为高保真、物理感知的模拟场景，显著提升了AI代理在城市场景中的训练效果和泛化能力。

Abstract: Urban embodied AI agents, ranging from delivery robots to quadrupeds, are
increasingly populating our cities, navigating chaotic streets to provide
last-mile connectivity. Training such agents requires diverse, high-fidelity
urban environments to scale, yet existing human-crafted or procedurally
generated simulation scenes either lack scalability or fail to capture
real-world complexity. We introduce UrbanVerse, a data-driven real-to-sim
system that converts crowd-sourced city-tour videos into physics-aware,
interactive simulation scenes. UrbanVerse consists of: (i) UrbanVerse-100K, a
repository of 100k+ annotated urban 3D assets with semantic and physical
attributes, and (ii) UrbanVerse-Gen, an automatic pipeline that extracts scene
layouts from video and instantiates metric-scale 3D simulations using retrieved
assets. Running in IsaacSim, UrbanVerse offers 160 high-quality constructed
scenes from 24 countries, along with a curated benchmark of 10 artist-designed
test scenes. Experiments show that UrbanVerse scenes preserve real-world
semantics and layouts, achieving human-evaluated realism comparable to manually
crafted scenes. In urban navigation, policies trained in UrbanVerse exhibit
scaling power laws and strong generalization, improving success by +6.3% in
simulation and +30.1% in zero-shot sim-to-real transfer comparing to prior
methods, accomplishing a 300 m real-world mission with only two interventions.

</details>


### [5] [NANO3D: A Training-Free Approach for Efficient 3D Editing Without Masks](https://arxiv.org/abs/2510.15019)
*Junliang Ye,Shenghao Xie,Ruowen Zhao,Zhengyi Wang,Hongyu Yan,Wenqiang Zu,Lei Ma,Jun Zhu*

Main category: cs.CV

TL;DR: Nano3D是一种无需训练的3D对象编辑框架，通过FlowEdit和区域感知合并策略提升编辑质量，并构建了大规模数据集。


<details>
  <summary>Details</summary>
Motivation: 当前3D对象编辑方法效率低下、不一致，且难以保留未编辑区域，主要依赖多视图渲染编辑后重建，导致伪影和实用性受限。

Method: Nano3D将FlowEdit集成到TRELLIS中，通过前视图渲染指导局部编辑，并引入区域感知的合并策略Voxel/Slat-Merge，自适应地保持结构一致性。

Result: 实验表明，Nano3D在3D一致性和视觉质量上优于现有方法，并构建了首个大规模3D编辑数据集Nano3D-Edit-100k。

Conclusion: Nano3D通过提出一种无需训练的框架和构建大规模数据集Nano3D-Edit-100k，显著提升了3D编辑的通用性和可靠性，为前馈式3D编辑模型的发展奠定了基础。

Abstract: 3D object editing is essential for interactive content creation in gaming,
animation, and robotics, yet current approaches remain inefficient,
inconsistent, and often fail to preserve unedited regions. Most methods rely on
editing multi-view renderings followed by reconstruction, which introduces
artifacts and limits practicality. To address these challenges, we propose
Nano3D, a training-free framework for precise and coherent 3D object editing
without masks. Nano3D integrates FlowEdit into TRELLIS to perform localized
edits guided by front-view renderings, and further introduces region-aware
merging strategies, Voxel/Slat-Merge, which adaptively preserve structural
fidelity by ensuring consistency between edited and unedited areas. Experiments
demonstrate that Nano3D achieves superior 3D consistency and visual quality
compared with existing methods. Based on this framework, we construct the first
large-scale 3D editing datasets Nano3D-Edit-100k, which contains over 100,000
high-quality 3D editing pairs. This work addresses long-standing challenges in
both algorithm design and data availability, significantly improving the
generality and reliability of 3D editing, and laying the groundwork for the
development of feed-forward 3D editing models. Project
Page:https://jamesyjl.github.io/Nano3D

</details>


### [6] [Constantly Improving Image Models Need Constantly Improving Benchmarks](https://arxiv.org/abs/2510.15021)
*Jiaxin Ge,Grace Luo,Heekyung Lee,Nishant Malpani,Long Lian,XuDong Wang,Aleksander Holynski,Trevor Darrell,Sewon Min,David M. Chan*

Main category: cs.CV

TL;DR: ECHO是一个基于社交媒体真实用例的基准框架，用于评估图像生成模型的最新能力，填补了现有基准的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法及时捕捉图像生成模型的新兴用例，导致社区对进展的认知与正式评估之间存在差距。

Method: 提出ECHO框架，通过分析社交媒体上的用户帖子和反馈，构建包含31,000多个提示的数据集，并设计新的模型质量评估指标。

Result: ECHO发现了现有基准中未涵盖的创造性任务，更清晰地区分了最先进模型与替代方案，并通过社区反馈为模型质量指标设计提供了依据。

Conclusion: ECHO框架通过直接从社交媒体的真实使用案例中构建基准，填补了现有评估方法的不足，能够更准确地反映图像生成模型的最新能力和社区反馈。

Abstract: Recent advances in image generation, often driven by proprietary systems like
GPT-4o Image Gen, regularly introduce new capabilities that reshape how users
interact with these models. Existing benchmarks often lag behind and fail to
capture these emerging use cases, leaving a gap between community perceptions
of progress and formal evaluation. To address this, we present ECHO, a
framework for constructing benchmarks directly from real-world evidence of
model use: social media posts that showcase novel prompts and qualitative user
judgments. Applying this framework to GPT-4o Image Gen, we construct a dataset
of over 31,000 prompts curated from such posts. Our analysis shows that ECHO
(1) discovers creative and complex tasks absent from existing benchmarks, such
as re-rendering product labels across languages or generating receipts with
specified totals, (2) more clearly distinguishes state-of-the-art models from
alternatives, and (3) surfaces community feedback that we use to inform the
design of metrics for model quality (e.g., measuring observed shifts in color,
identity, and structure). Our website is at https://echo-bench.github.io.

</details>


### [7] [LoRAverse: A Submodular Framework to Retrieve Diverse Adapters for Diffusion Models](https://arxiv.org/abs/2510.15022)
*Mert Sonmezer,Matthew Zheng,Pinar Yanardag*

Main category: cs.CV

TL;DR: 该论文提出了一种子模框架，用于从大量LoRA适配器中高效选择和多样化输出，解决了用户面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于LoRA适配器数量庞大、多样性高且缺乏结构化组织，用户在导航、选择和有效利用最合适的适配器时面临挑战。

Method: 通过将任务框架化为组合优化问题，并提出一个新颖的子模框架来实现。

Result: 定量和定性实验表明，该方法能够在广泛的领域内生成多样化的输出。

Conclusion: 该论文提出了一种新颖的子模框架，用于从庞大的LoRA适配器数据库中选择最相关和多样化的模型，解决了用户在选择和利用适配器时面临的挑战。

Abstract: Low-rank Adaptation (LoRA) models have revolutionized the personalization of
pre-trained diffusion models by enabling fine-tuning through low-rank,
factorized weight matrices specifically optimized for attention layers. These
models facilitate the generation of highly customized content across a variety
of objects, individuals, and artistic styles without the need for extensive
retraining. Despite the availability of over 100K LoRA adapters on platforms
like Civit.ai, users often face challenges in navigating, selecting, and
effectively utilizing the most suitable adapters due to their sheer volume,
diversity, and lack of structured organization. This paper addresses the
problem of selecting the most relevant and diverse LoRA models from this vast
database by framing the task as a combinatorial optimization problem and
proposing a novel submodular framework. Our quantitative and qualitative
experiments demonstrate that our method generates diverse outputs across a wide
range of domains.

</details>


### [8] [MOBIUS: Big-to-Mobile Universal Instance Segmentation via Multi-modal Bottleneck Fusion and Calibrated Decoder Pruning](https://arxiv.org/abs/2510.15026)
*Mattia Segu,Marta Tintore Gazulla,Yongqin Xian,Luc Van Gool,Federico Tombari*

Main category: cs.CV

TL;DR: MOBIUS is a family of foundation models for efficient universal instance segmentation, reducing computational costs significantly without sacrificing performance.


<details>
  <summary>Details</summary>
Motivation: The high computational cost of existing foundation models limits their adoption on resource-constrained platforms. The paper aims to enable efficient edge deployment without compromising performance.

Method: MOBIUS introduces a family of foundation models with (i) a bottleneck pixel decoder for efficient multi-scale and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for adaptive decoder pruning, and (iii) a streamlined, unified training strategy.

Result: MOBIUS reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively, while maintaining state-of-the-art performance in just a third of the training iterations.

Conclusion: MOBIUS establishes a new benchmark for efficient segmentation on both high-performance computing platforms and mobile devices.

Abstract: Scaling up model size and training data has advanced foundation models for
instance-level perception, achieving state-of-the-art in-domain and zero-shot
performance across object detection and segmentation. However, their high
computational cost limits adoption on resource-constrained platforms. We first
examine the limitations of existing architectures in enabling efficient edge
deployment without compromising performance. We then introduce MOBIUS, a family
of foundation models for universal instance segmentation, designed for
Pareto-optimal downscaling to support deployment across devices ranging from
high-end accelerators to mobile hardware. To reduce training and inference
demands, we propose: (i) a bottleneck pixel decoder for efficient multi-scale
and multi-modal fusion, (ii) a language-guided uncertainty calibration loss for
adaptive decoder pruning, and (iii) a streamlined, unified training strategy.
Unlike efficient baselines that trade accuracy for reduced complexity, MOBIUS
reduces pixel and transformer decoder FLOPs by up to 55% and 75%, respectively,
while maintaining state-of-the-art performance in just a third of the training
iterations. MOBIUS establishes a new benchmark for efficient segmentation on
both high-performance computing platforms and mobile devices.

</details>


### [9] [Composition-Grounded Instruction Synthesis for Visual Reasoning](https://arxiv.org/abs/2510.15040)
*Xinyi Gu,Jiayuan Mao,Zhang-Wei Hong,Zhuoran Yu,Pengyuan Li,Dhiraj Joshi,Rogerio Feris,Zexue He*

Main category: cs.CV

TL;DR: COGS框架利用少量种子问题生成合成数据，通过因子分解和重组提升MLLMs在图表等领域的推理能力，并展现跨领域潜力。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型在缺乏标注数据的领域（如图表、网页等）推理能力受限的问题。

Method: 引入COGS框架，通过分解种子问题为基本感知和推理因子，并系统重组生成大量合成问答对，结合因子级过程奖励进行强化学习。

Result: 在图表推理任务中，COGS显著提升了对未见问题的性能，尤其在推理密集和组合问题上表现突出，且能跨数据集泛化。

Conclusion: COGS框架通过合成数据和因子级奖励有效提升了MLLMs在图表推理等领域的泛化能力，且可扩展至网页等其他领域。

Abstract: Pretrained multi-modal large language models (MLLMs) demonstrate strong
performance on diverse multimodal tasks, but remain limited in reasoning
capabilities for domains where annotations are difficult to collect. In this
work, we focus on artificial image domains such as charts, rendered documents,
and webpages, which are abundant in practice yet lack large-scale human
annotated reasoning datasets. We introduce COGS (COmposition-Grounded
instruction Synthesis), a data-efficient framework for equipping MLLMs with
advanced reasoning abilities from a small set of seed questions. The key idea
is to decompose each seed question into primitive perception and reasoning
factors, which can then be systematically recomposed with new images to
generate large collections of synthetic question-answer pairs. Each generated
question is paired with subquestions and intermediate answers, enabling
reinforcement learning with factor-level process rewards. Experiments on chart
reasoning show that COGS substantially improves performance on unseen
questions, with the largest gains on reasoning-heavy and compositional
questions. Moreover, training with a factor-level mixture of different seed
data yields better transfer across multiple datasets, suggesting that COGS
induces generalizable capabilities rather than dataset-specific overfitting. We
further demonstrate that the framework extends beyond charts to other domains
such as webpages.

</details>


### [10] [Generalized Dynamics Generation towards Scannable Physical World Model](https://arxiv.org/abs/2510.15041)
*Yichen Li,Zhiyi Li,Brandon Feng,Dinghuai Zhang,Antonio Torralba*

Main category: cs.CV

TL;DR: GDGen通过势能视角统一刚体、关节体和软体动力学，提出方向刚度和神经场方法，为复杂虚拟环境和机器人训练提供多功能基础。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够统一处理刚体、关节体和软体动力学的通用框架，以支持复杂物理行为的交互式数字孪生世界。

Method: GDGen采用势能视角，引入方向刚度以捕捉广泛的物理行为，并提出专用网络建模扩展材料属性，使用神经场以几何无关方式表示变形。

Result: GDGen成功统一了多种仿真范式，在多样化动态场景中表现出色。

Conclusion: GDGen提供了一个统一的、几何无关的系统，能够无缝集成多种动力学类型，为创建交互式虚拟环境和训练机器人代理提供了多功能基础。

Abstract: Digital twin worlds with realistic interactive dynamics presents a new
opportunity to develop generalist embodied agents in scannable environments
with complex physical behaviors. To this end, we present GDGen (Generalized
Representation for Generalized Dynamics Generation), a framework that takes a
potential energy perspective to seamlessly integrate rigid body, articulated
body, and soft body dynamics into a unified, geometry-agnostic system. GDGen
operates from the governing principle that the potential energy for any stable
physical system should be low. This fresh perspective allows us to treat the
world as one holistic entity and infer underlying physical properties from
simple motion observations. We extend classic elastodynamics by introducing
directional stiffness to capture a broad spectrum of physical behaviors,
covering soft elastic, articulated, and rigid body systems. We propose a
specialized network to model the extended material property and employ a neural
field to represent deformation in a geometry-agnostic manner. Extensive
experiments demonstrate that GDGen robustly unifies diverse simulation
paradigms, offering a versatile foundation for creating interactive virtual
environments and training robotic agents in complex, dynamically rich
scenarios.

</details>


### [11] [Comprehensive language-image pre-training for 3D medical image understanding](https://arxiv.org/abs/2510.15042)
*Tassilo Wald,Ibrahim Ethem Hamamci,Yuan Gao,Sam Bond-Taylor,Harshita Sharma,Maximilian Ilse,Cynthia Lo,Olesya Melnichenko,Noel C. F. Codella,Maria Teodora Wetscherek,Klaus H. Maier-Hein,Panagiotis Korfiatis,Valentina Salvatelli,Javier Alvarez-Valle,Fernando Pérez-García*

Main category: cs.CV

TL;DR: COLIPRI通过结合视觉-语言和仅视觉预训练，提升3D医学影像编码器性能，实现多项任务的SOTA表现。


<details>
  <summary>Details</summary>
Motivation: 3D医学影像领域中，数据可用性限制了当前3D视觉-语言编码器（VLEs）的能力，需要解决这一问题以提升性能。

Method: 通过引入报告生成目标和将视觉-语言预训练与仅视觉预训练相结合，利用图像和图像-文本对数据集，增加模型接触的总数据量。

Result: COLIPRI编码器在报告生成、分类探测和零样本分类任务中达到最先进性能，并在语义分割中保持竞争力。

Conclusion: COLIPRI编码器家族通过引入额外的归纳偏差和最佳实践，在报告生成、分类探测和零样本分类任务中实现了最先进的性能，并在语义分割中保持竞争力。

Abstract: Vision-language pre-training, i.e., aligning images with paired text, is a
powerful paradigm to create encoders that can be directly used for tasks such
as classification and retrieval, and for downstream tasks such as segmentation
and report generation. In the 3D medical image domain, these capabilities allow
vision-language encoders (VLEs) to support radiologists by retrieving patients
with similar abnormalities or predicting likelihoods of abnormality. While the
methodology holds promise, data availability limits the capabilities of current
3D VLEs.
  In this paper, we alleviate the lack of data by injecting additional
inductive biases: introducing a report generation objective and pairing
vision-language pre-training with vision-only pre-training. This allows us to
leverage both image-only and paired image-text 3D datasets, increasing the
total amount of data to which our model is exposed. Through these additional
inductive biases, paired with best practices of the 3D medical imaging domain,
we develop the Comprehensive Language-image Pre-training (COLIPRI) encoder
family. Our COLIPRI encoders achieve state-of-the-art performance in report
generation, classification probing, and zero-shot classification, and remain
competitive for semantic segmentation.

</details>


### [12] [Directional Reasoning Injection for Fine-Tuning MLLMs](https://arxiv.org/abs/2510.15050)
*Chao Huang,Zeliang Zhang,Jiang Liu,Ximeng Sun,Jialian Wu,Xiaodong Yu,Ze Wang,Chenliang Xu,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: DRIFT是一种轻量级方法，通过梯度空间中的推理知识转移提升多模态模型的推理能力，效果优于传统方法且成本更低。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如监督微调或强化学习）资源消耗大，而简单的模型合并效果不稳定。

Method: 提出Directional Reasoning Injection for Fine-Tuning (DRIFT)方法，通过预计算推理先验并用于梯度偏置，实现轻量化的推理知识转移。

Result: 在MathVista和MathVerse等基准测试中，DRIFT表现优于简单合并和监督微调，且接近或超越高成本方法。

Conclusion: DRIFT方法通过梯度空间中的知识转移，有效提升了多模态大型语言模型的推理能力，且成本较低。

Abstract: Multimodal large language models (MLLMs) are rapidly advancing, yet their
reasoning ability often lags behind that of strong text-only counterparts.
Existing methods to bridge this gap rely on supervised fine-tuning over
large-scale multimodal reasoning data or reinforcement learning, both of which
are resource-intensive. A promising alternative is model merging, which
interpolates parameters between reasoning-enhanced LLMs and multimodal
variants. However, our analysis shows that naive merging is not always a "free
lunch": its effectiveness varies drastically across model families, with some
(e.g., LLaVA, Idefics) benefiting while others (e.g., Qwen) suffer performance
degradation. To address this, we propose Directional Reasoning Injection for
Fine-Tuning (DRIFT) MLLMs, a lightweight method that transfers reasoning
knowledge in the gradient space, without destabilizing multimodal alignment.
DRIFT precomputes a reasoning prior as the parameter-space difference between
reasoning and multimodal variants, then uses it to bias gradients during
multimodal fine-tuning. This approach preserves the simplicity of standard
supervised fine-tuning pipelines while enabling efficient reasoning transfer.
Extensive experiments on multimodal reasoning benchmarks, including MathVista
and MathVerse, demonstrate that DRIFT consistently improves reasoning
performance over naive merging and supervised fine-tuning, while matching or
surpassing training-heavy methods at a fraction of the cost.

</details>


### [13] [A solution to generalized learning from small training sets found in everyday infant experiences](https://arxiv.org/abs/2510.15060)
*Frangil Ramirez,Elizabeth Clerkin,David J. Crandall,Linda B. Smith*

Main category: cs.CV

TL;DR: 婴儿日常视觉体验的‘块状’统计特性可能支持早期类别学习，并提升机器学习中的小数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探讨婴儿如何从有限的视觉经验中实现泛化，提出日常视觉体验的统计特性可能是关键。

Method: 分析了14名婴儿（7至11个月大）的自我中心图像，展示其日常视觉输入具有‘块状’相似性结构。通过计算实验模拟这种结构在机器学习中的效果。

Result: 婴儿的视觉输入表现出高度相似的图像簇与罕见、多变的图像交替的结构，模拟这种结构可提升机器学习中的小数据集泛化能力。

Conclusion: 婴儿日常视觉体验中的自然‘块状’相似性结构可能支持早期类别学习和泛化，并为各种问题和学习者提供高效学习的原则。

Abstract: Young children readily recognize and generalize visual objects labeled by
common nouns, suggesting that these basic level object categories may be given.
Yet if they are, how they arise remains unclear. We propose that the answer
lies in the statistics of infant daily life visual experiences. Whereas large
and diverse datasets typically support robust learning and generalization in
human and machine learning, infants achieve this generalization from limited
experiences. We suggest that the resolution of this apparent contradiction lies
in the visual diversity of daily life, repeated experiences with single object
instances. Analyzing egocentric images from 14 infants (aged 7 to 11 months) we
show that their everyday visual input exhibits a lumpy similarity structure,
with clusters of highly similar images interspersed with rarer, more variable
ones, across eight early-learned categories. Computational experiments show
that mimicking this structure in machines improves generalization from small
datasets in machine learning. The natural lumpiness of infant experience may
thus support early category learning and generalization and, more broadly,
offer principles for efficient learning across a variety of problems and kinds
of learners.

</details>


### [14] [SaLon3R: Structure-aware Long-term Generalizable 3D Reconstruction from Unposed Images](https://arxiv.org/abs/2510.15072)
*Jiaxin Guo,Tongfan Guan,Wenzhen Dong,Wenzhao Zheng,Wenting Wang,Yue Wang,Yeung Yam,Yun-Hui Liu*

Main category: cs.CV

TL;DR: SaLon3R通过紧凑锚点和3D点Transformer解决长序列3D高斯泼溅的冗余问题，实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长序列视频中预测逐像素高斯并合并所有视图，导致冗余和几何不一致，需改进。

Method: 提出SaLon3R框架，结合差分显著性感知高斯量化和3D点Transformer，通过压缩冗余高斯为紧凑锚点并优化其属性，实现区域自适应高斯解码。

Result: 在多个数据集上，SaLon3R在50帧以上视频中实现10FPS重建，冗余减少50%-90%，在新视图合成和深度估计中表现最优。

Conclusion: SaLon3R通过引入紧凑锚点基元和3D点Transformer，有效解决了长序列3D高斯泼溅中的冗余和几何不一致问题，实现了高效、鲁棒且通用的3D重建。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled generalizable,
on-the-fly reconstruction of sequential input views. However, existing methods
often predict per-pixel Gaussians and combine Gaussians from all views as the
scene representation, leading to substantial redundancies and geometric
inconsistencies in long-duration video sequences. To address this, we propose
SaLon3R, a novel framework for Structure-aware, Long-term 3DGS Reconstruction.
To our best knowledge, SaLon3R is the first online generalizable GS method
capable of reconstructing over 50 views in over 10 FPS, with 50% to 90%
redundancy removal. Our method introduces compact anchor primitives to
eliminate redundancy through differentiable saliency-aware Gaussian
quantization, coupled with a 3D Point Transformer that refines anchor
attributes and saliency to resolve cross-frame geometric and photometric
inconsistencies. Specifically, we first leverage a 3D reconstruction backbone
to predict dense per-pixel Gaussians and a saliency map encoding regional
geometric complexity. Redundant Gaussians are compressed into compact anchors
by prioritizing high-complexity regions. The 3D Point Transformer then learns
spatial structural priors in 3D space from training data to refine anchor
attributes and saliency, enabling regionally adaptive Gaussian decoding for
geometric fidelity. Without known camera parameters or test-time optimization,
our approach effectively resolves artifacts and prunes the redundant 3DGS in a
single feed-forward pass. Experiments on multiple datasets demonstrate our
state-of-the-art performance on both novel view synthesis and depth estimation,
demonstrating superior efficiency, robustness, and generalization ability for
long-term generalizable 3D reconstruction. Project Page:
https://wrld.github.io/SaLon3R/.

</details>


### [15] [TGT: Text-Grounded Trajectories for Locally Controlled Video Generation](https://arxiv.org/abs/2510.15104)
*Guofeng Zhang,Angtian Wang,Jacob Zhiyuan Fang,Liming Jiang,Haotian Yang,Bo Liu,Yiding Yang,Guang Chen,Longyin Wen,Alan Yuille,Chongyang Ma*

Main category: cs.CV

TL;DR: TGT框架通过轨迹与文本结合，提升了视频生成的视觉效果和控制精度。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在控制生成场景的主体组合方面能力有限，尤其在复杂或多对象场景中表现不佳。

Method: 提出Text-Grounded Trajectories (TGT)框架，采用Location-Aware Cross-Attention (LACA)整合信号，并采用双CFG方案分别调制局部和全局文本引导。

Result: TGT在视觉质量、文本对齐和运动控制方面优于现有方法。

Conclusion: TGT框架通过结合轨迹与局部文本描述，显著提升了视频生成的视觉质量、文本对齐准确性和运动可控性。

Abstract: Text-to-video generation has advanced rapidly in visual fidelity, whereas
standard methods still have limited ability to control the subject composition
of generated scenes. Prior work shows that adding localized text control
signals, such as bounding boxes or segmentation masks, can help. However, these
methods struggle in complex scenarios and degrade in multi-object settings,
offering limited precision and lacking a clear correspondence between
individual trajectories and visual entities as the number of controllable
objects increases. We introduce Text-Grounded Trajectories (TGT), a framework
that conditions video generation on trajectories paired with localized text
descriptions. We propose Location-Aware Cross-Attention (LACA) to integrate
these signals and adopt a dual-CFG scheme to separately modulate local and
global text guidance. In addition, we develop a data processing pipeline that
produces trajectories with localized descriptions of tracked entities, and we
annotate two million high quality video clips to train TGT. Together, these
components enable TGT to use point trajectories as intuitive motion handles,
pairing each trajectory with text to control both appearance and motion.
Extensive experiments show that TGT achieves higher visual quality, more
accurate text alignment, and improved motion controllability compared with
prior approaches. Website: https://textgroundedtraj.github.io.

</details>


### [16] [Deep generative priors for 3D brain analysis](https://arxiv.org/abs/2510.15119)
*Ana Lawry Aguila,Dina Zemlyanker,You Cheng,Sudeshna Das,Daniel C. Alexander,Oula Puonti,Annabel Sorby-Adams,W. Taylor Kimberly,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 扩散模型首次被用作医学图像逆问题的通用先验，结合领域知识在脑部MRI任务中实现高质量解决方案。


<details>
  <summary>Details</summary>
Motivation: 结合数据驱动的扩散模型与领域知识，以解决脑部成像问题，弥补传统数学先验在捕捉脑解剖复杂结构上的不足。

Method: 采用基于分数的扩散先验，结合灵活的前向模型，处理多种医学图像逆问题。

Result: 在异质临床和研究MRI数据上的实验表明，该方法达到了最先进的性能。

Conclusion: 扩散模型作为先验在脑部MRI分析中展现出巨大潜力，能够在不依赖配对训练数据集的情况下，生成一致且高质量的解决方案。

Abstract: Diffusion models have recently emerged as powerful generative models in
medical imaging. However, it remains a major challenge to combine these
data-driven models with domain knowledge to guide brain imaging problems. In
neuroimaging, Bayesian inverse problems have long provided a successful
framework for inference tasks, where incorporating domain knowledge of the
imaging process enables robust performance without requiring extensive training
data. However, the anatomical modeling component of these approaches typically
relies on classical mathematical priors that often fail to capture the complex
structure of brain anatomy. In this work, we present the first general-purpose
application of diffusion models as priors for solving a wide range of medical
imaging inverse problems. Our approach leverages a score-based diffusion prior
trained extensively on diverse brain MRI data, paired with flexible forward
models that capture common image processing tasks such as super-resolution,
bias field correction, inpainting, and combinations thereof. We further
demonstrate how our framework can refine outputs from existing deep learning
methods to improve anatomical fidelity. Experiments on heterogeneous clinical
and research MRI data show that our method achieves state-of-the-art
performance producing consistent, high-quality solutions without requiring
paired training datasets. These results highlight the potential of diffusion
priors as versatile tools for brain MRI analysis.

</details>


### [17] [Fourier Transform Multiple Instance Learning for Whole Slide Image Classification](https://arxiv.org/abs/2510.15138)
*Anthony Bilic,Guangyu Sun,Ming Li,Md Sanzid Bin Hossain,Yu Tian,Wei Zhang,Laura Brattain,Dexter Hadley,Chen Chen*

Main category: cs.CV

TL;DR: FFT-MIL通过频率域分支增强MIL，显著提升WSI分类性能。


<details>
  <summary>Details</summary>
Motivation: 现有MIL方法在WSI分类中难以捕捉全局依赖关系，限制了诊断预测的鲁棒性。

Method: 提出FFT-MIL框架，结合快速傅里叶变换提取低频信息，通过FFT-Block处理并融合空间特征。

Result: 在三个公开数据集上，FFT-MIL平均提升宏F1分数3.51%和AUC 1.51%。

Conclusion: FFT-MIL通过频率域学习有效捕捉了WSI分类中的全局依赖关系，提升了MIL方法的可扩展性和准确性。

Abstract: Whole Slide Image (WSI) classification relies on Multiple Instance Learning
(MIL) with spatial patch features, yet existing methods struggle to capture
global dependencies due to the immense size of WSIs and the local nature of
patch embeddings. This limitation hinders the modeling of coarse structures
essential for robust diagnostic prediction.
  We propose Fourier Transform Multiple Instance Learning (FFT-MIL), a
framework that augments MIL with a frequency-domain branch to provide compact
global context. Low-frequency crops are extracted from WSIs via the Fast
Fourier Transform and processed through a modular FFT-Block composed of
convolutional layers and Min-Max normalization to mitigate the high variance of
frequency data. The learned global frequency feature is fused with spatial
patch features through lightweight integration strategies, enabling
compatibility with diverse MIL architectures.
  FFT-MIL was evaluated across six state-of-the-art MIL methods on three public
datasets (BRACS, LUAD, and IMP). Integration of the FFT-Block improved macro F1
scores by an average of 3.51% and AUC by 1.51%, demonstrating consistent gains
across architectures and datasets. These results establish frequency-domain
learning as an effective and efficient mechanism for capturing global
dependencies in WSI classification, complementing spatial features and
advancing the scalability and accuracy of MIL-based computational pathology.

</details>


### [18] [XModBench: Benchmarking Cross-Modal Capabilities and Consistency in Omni-Language Models](https://arxiv.org/abs/2510.15148)
*Xingrui Wang,Jiang Liu,Chao Huang,Xiaodong Yu,Ze Wang,Ximeng Sun,Jialian Wu,Alan Yuille,Emad Barsoum,Zicheng Liu*

Main category: cs.CV

TL;DR: XModBench是一个新基准，用于评估全模态大语言模型的跨模态一致性，发现当前模型仍存在模态差异和方向性不平衡，远未实现真正的模态不变推理。


<details>
  <summary>Details</summary>
Motivation: 评估OLLMs是否实现模态不变推理或表现出模态特定偏差，现有基准主要评估一般跨模态问答能力，缺乏对模态一致性的系统测量。

Method: 引入XModBench，一个大规模三模态基准测试，包含60,828个多选题，涵盖五种任务家族和六种模态组合，用于细粒度诊断OLLM的模态不变推理、模态差异和方向性不平衡。

Result: 实验显示，即使最强的模型Gemini 2.5 Pro也存在空间和时间推理困难（准确率低于60%）、模态差异（音频表现显著低于文本）和方向性不平衡（视觉作为上下文时一致性较低）。

Conclusion: 当前的全模态大语言模型（OLLMs）尚未实现真正的模态不变推理，XModBench作为一个基础诊断工具，可用于评估和提升跨模态能力。

Abstract: Omni-modal large language models (OLLMs) aim to unify audio, vision, and text
understanding within a single framework. While existing benchmarks primarily
evaluate general cross-modal question-answering ability, it remains unclear
whether OLLMs achieve modality-invariant reasoning or exhibit modality-specific
biases. We introduce XModBench, a large-scale tri-modal benchmark explicitly
designed to measure cross-modal consistency. XModBench comprises 60,828
multiple-choice questions spanning five task families and systematically covers
all six modality compositions in question-answer pairs, enabling fine-grained
diagnosis of an OLLM's modality-invariant reasoning, modality disparity, and
directional imbalance. Experiments show that even the strongest model, Gemini
2.5 Pro, (i) struggles with spatial and temporal reasoning, achieving less than
60% accuracy, (ii) reveals persistent modality disparities, with performance
dropping substantially when the same semantic content is conveyed through audio
rather than text, and (iii) shows systematic directional imbalance, exhibiting
lower consistency when vision serves as context compared to text. These
findings indicate that current OLLMs remain far from truly modality-invariant
reasoning and position XModBench as a fundamental diagnostic tool for
evaluating and improving cross-modal competence. All data and evaluation tools
will be available at https://xingruiwang.github.io/projects/XModBench/.

</details>


### [19] [Train a Unified Multimodal Data Quality Classifier with Synthetic Data](https://arxiv.org/abs/2510.15162)
*Weizhi Wang,Rongmei Lin,Shiyang Li,Colin Lockard,Ritesh Sarkhel,Sanket Lokegaonkar,Jingbo Shang,Xifeng Yan,Nasser Zalmout,Xian Li*

Main category: cs.CV

TL;DR: UniFilter是一种高效的多模态数据质量分类器，通过半合成方法筛选高质量数据，显著提升MLLMs性能。


<details>
  <summary>Details</summary>
Motivation: 针对多模态大语言模型（MLLMs）在图像-文本标题和交错文档数据中高质量数据过滤的不足。

Method: 提出了一种半合成方法，利用原始图像生成不同质量级别的文本，创建样本-评分对以训练UniFilter。

Result: 应用UniFilter筛选的数据训练的MLLMs在零样本推理、上下文学习及视觉监督微调后表现显著提升。

Conclusion: UniFilter模型通过高效筛选高质量多模态数据，显著提升了MLLMs在零样本推理和上下文学习中的能力，并在多个基准测试中表现优异。

Abstract: The Multimodal Large Language Models (MLLMs) are continually pre-trained on a
mixture of image-text caption data and interleaved document data, while the
high-quality data filtering towards image-text interleaved document data is
under-explored. We propose to train an efficient MLLM as a Unified Mulitmodal
Data Quality Classifier to Filter both high-quality image-text caption and
interleaved data (UniFilter). To address the challenge of collecting diverse
labeled multimodal data, we introduce a semi-synthetic approach that leverages
readily available raw images and generates corresponding text across four
quality levels. This method enables efficient creation of sample-score pairs
for both caption and interleaved document data to train UniFilter. We apply
UniFilter to curate high-quality caption data from DataComp caption dataset and
interleaved data from the OBELICS image-text interleaved dataset. MLLMs
pre-trained on the filtered data demonstrate significantly enhanced
capabilities compared to those trained on baseline-filtered data, achieving
stronger zero-shot reasoning and in-context learning capabilities. After visual
supervised fine-tuning, these UniFilter-induced MLLMs achieve stronger
performance on various benchmarks, highlighting the downstream benefits of
high-quality multimodal pre-training. We release the synthetic training data
used for training UniFilter, the UniFilter model checkpoints, and the
high-quality interleaved document subset OBELICS-HQ, curated by UniFilter, to
the community for reproduction and further development.

</details>


### [20] [Hyperparameter Optimization and Reproducibility in Deep Learning Model Training](https://arxiv.org/abs/2510.15164)
*Usman Afzaal,Ziyu Su,Usama Sajjad,Hao Lu,Mostafa Rezapour,Metin Nafi Gurcan,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 研究探讨了病理学基础模型训练中的可重复性问题，通过实验确定了最佳超参数和数据增强策略，并提供了提高可重复性的实用建议。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决基础模型训练中因软件随机性、硬件非确定性和超参数报告不一致而导致的可重复性挑战。

Method: 通过在QUILT-1M数据集上训练CLIP模型，并系统评估不同超参数设置和数据增强策略对三个下游病理学数据集（PatchCamelyon、LC25000-Lung和LC25000-Colon）的影响。

Result: 研究发现RandomResizedCrop值在0.7-0.8时表现最佳，分布式训练不带局部损失提高了稳定性，学习率低于5.0e-5会导致性能下降。LC25000（Colon）数据集是最具可重复性的基准。

Conclusion: 研究表明，在计算病理学中实现可重复性不仅需要透明的文档记录，还需要精心选择的实验配置。作者提供了实用的规则，以指导未来开发可重复的数字病理学基础模型。

Abstract: Reproducibility remains a critical challenge in foundation model training for
histopathology, often hindered by software randomness, hardware
non-determinism, and inconsistent hyperparameter reporting. To investigate
these issues, we trained a CLIP model on the QUILT-1M dataset and
systematically evaluated the impact of different hyperparameter settings and
augmentation strategies across three downstream histopathology datasets
(PatchCamelyon, LC25000-Lung, and LC25000-Colon). Despite variability across
runs, we identified clear trends: RandomResizedCrop values of 0.7-0.8
outperformed more aggressive (0.6) or conservative (0.9) settings, distributed
training without local loss improved stability, and learning rates below 5.0e-5
consistently degraded performance across all datasets. The LC25000 (Colon)
dataset consistently provided the most reproducible benchmark. These findings
highlight that reproducibility in computational pathology depends not only on
transparent documentation but also on carefully chosen experimental
configurations, and we provide practical rules to guide future efforts in
developing reproducible foundation models for digital pathology.

</details>


### [21] [Salient Concept-Aware Generative Data Augmentation](https://arxiv.org/abs/2510.15194)
*Tianchen Zhao,Xuanbai Chen,Zhihua Li,Jun Fang,Dongsheng An,Xiang Xu,Zhuowen Tu,Yifan Xing*

Main category: cs.CV

TL;DR: 本文提出了一种个性化图像生成框架，通过显著概念感知的图像嵌入模型减少无关视觉细节的影响，有效提升了数据多样性和下游模型鲁棒性，实验显示其在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的生成数据增强方法在平衡保真度和多样性方面存在挑战，难以在保留关键图像细节的同时与多样化的文本提示对齐。这主要是因为合成过程中的表示往往与非必要的输入图像属性（如环境上下文）纠缠在一起，导致与文本提示的冲突。

Method: 提出了一种个性化的图像生成框架，利用显著概念感知的图像嵌入模型来减少合成过程中无关视觉细节的影响，从而保持图像与文本输入之间的直观对齐。

Result: 在八个细粒度视觉数据集上的实验表明，该方法在传统和长尾设置下的分类准确率分别平均提升了0.73%和6.5%，优于现有数据增强方法。

Conclusion: 该框架通过减少合成过程中无关视觉细节的影响，有效提升了训练数据集的多样性，并增强了下游模型的鲁棒性。在八个细粒度视觉数据集上的实验表明，该方法在传统和长尾设置下的分类准确率分别平均提升了0.73%和6.5%，优于现有数据增强方法。

Abstract: Recent generative data augmentation methods conditioned on both image and
text prompts struggle to balance between fidelity and diversity, as it is
challenging to preserve essential image details while aligning with varied text
prompts. This challenge arises because representations in the synthesis process
often become entangled with non-essential input image attributes such as
environmental contexts, creating conflicts with text prompts intended to modify
these elements. To address this, we propose a personalized image generation
framework that uses a salient concept-aware image embedding model to reduce the
influence of irrelevant visual details during the synthesis process, thereby
maintaining intuitive alignment between image and text inputs. By generating
images that better preserve class-discriminative features with additional
controlled variations, our framework effectively enhances the diversity of
training datasets and thereby improves the robustness of downstream models. Our
approach demonstrates superior performance across eight fine-grained vision
datasets, outperforming state-of-the-art augmentation methods with averaged
classification accuracy improvements by 0.73% and 6.5% under conventional and
long-tail settings, respectively.

</details>


### [22] [CARDIUM: Congenital Anomaly Recognition with Diagnostic Images and Unified Medical records](https://arxiv.org/abs/2510.15208)
*Daniela Vega,Hannah V. Ceballos,Javier S. Vera,Santiago Rodriguez,Alejandra Perez,Angela Castillo,Maria Escobar,Dario Londoño,Luis A. Sarmiento,Camila I. Castro,Nadiezhda Rodriguez,Juan C. Briceño,Pablo Arbeláez*

Main category: cs.CV

TL;DR: 研究提出了首个公开的多模态数据集CARDIUM和一种多模态Transformer架构，显著提升了先天性心脏病的产前诊断性能。


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病的产前诊断数据稀缺且质量低，现有方法未能整合多源信息（如影像和临床数据），限制了AI模型的临床应用。

Method: 提出了一种结合交叉注意力机制的多模态Transformer架构，用于融合图像和表格数据的特征表示。

Result: 在多模态方法中，CHD检测准确率比单模态方法提高了11%（图像）和50%（表格数据），在CARDIUM数据集上实现了79.8±4.8%的F1分数。

Conclusion: 该研究通过引入CARDIUM数据集和提出一种多模态Transformer架构，显著提升了先天性心脏病（CHD）的产前诊断准确率，并公开了数据集和代码以促进进一步研究。

Abstract: Prenatal diagnosis of Congenital Heart Diseases (CHDs) holds great potential
for Artificial Intelligence (AI)-driven solutions. However, collecting
high-quality diagnostic data remains difficult due to the rarity of these
conditions, resulting in imbalanced and low-quality datasets that hinder model
performance. Moreover, no public efforts have been made to integrate multiple
sources of information, such as imaging and clinical data, further limiting the
ability of AI models to support and enhance clinical decision-making. To
overcome these challenges, we introduce the Congenital Anomaly Recognition with
Diagnostic Images and Unified Medical records (CARDIUM) dataset, the first
publicly available multimodal dataset consolidating fetal ultrasound and
echocardiographic images along with maternal clinical records for prenatal CHD
detection. Furthermore, we propose a robust multimodal transformer architecture
that incorporates a cross-attention mechanism to fuse feature representations
from image and tabular data, improving CHD detection by 11% and 50% over image
and tabular single-modality approaches, respectively, and achieving an F1 score
of 79.8 $\pm$ 4.8% in the CARDIUM dataset. We will publicly release our dataset
and code to encourage further research on this unexplored field. Our dataset
and code are available at https://github.com/BCVUniandes/Cardium, and at the
project website https://bcv-uniandes.github.io/CardiumPage/

</details>


### [23] [The Face of Persuasion: Analyzing Bias and Generating Culture-Aware Ads](https://arxiv.org/abs/2510.15240)
*Aysan Aghazadeh,Adriana Kovashka*

Main category: cs.CV

TL;DR: 研究了文本到图像模型在广告定制中的潜力，发现性别/种族差异会影响说服力，并实验了针对国家的定制技术。代码开源。


<details>
  <summary>Details</summary>
Motivation: 探索文本到图像模型在定制视觉广告和针对特定人群中的应用潜力，同时揭示其中可能存在的人口统计偏见。

Method: 研究了不同广告主题中的人口统计偏见，并评估了广告中性别/种族差异对说服力的影响。实验了一种针对特定国家定制广告的技术。

Result: 发现广告中性别/种族的差异会影响其说服力，并验证了针对特定国家定制广告的技术可行性。代码已开源。

Conclusion: 文本到图像模型在定制视觉广告和针对特定人群方面具有潜力，但存在人口统计偏见问题。通过实验验证了广告中性别/种族差异对说服力的影响，并提供了一种针对特定国家定制广告的技术。

Abstract: Text-to-image models are appealing for customizing visual advertisements and
targeting specific populations. We investigate this potential by examining the
demographic bias within ads for different ad topics, and the disparate level of
persuasiveness (judged by models) of ads that are identical except for
gender/race of the people portrayed. We also experiment with a technique to
target ads for specific countries. The code is available at
https://github.com/aysanaghazadeh/FaceOfPersuasion

</details>


### [24] [DriveGen3D: Boosting Feed-Forward Driving Scene Generation with Efficient Video Diffusion](https://arxiv.org/abs/2510.15264)
*Weijie Wang,Jiagang Zhu,Zeyu Zhang,Xiaofeng Wang,Zheng Zhu,Guosheng Zhao,Chaojun Ni,Haoxiao Wang,Guan Huang,Xinze Chen,Yukun Zhou,Wenkang Qin,Duochao Shi,Haoyun Li,Guanghong Jia,Jiwen Lu*

Main category: cs.CV

TL;DR: DriveGen3D是一个新型框架，通过高效视频合成和快速3D重建，实现了高质量、可控的动态3D驾驶场景生成，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长时间动态3D驾驶场景生成中存在计算需求高、仅关注视频合成或局限于静态场景重建的问题，DriveGen3D旨在填补这一方法空白。

Method: DriveGen3D采用了一个统一框架，包含高效视频扩散变换器（FastDrive-DiT）和快速重建模块（FastRecon3D），通过多模态条件控制实现加速长期视频生成和大规模动态场景重建。

Result: DriveGen3D能够实时生成高分辨率（424×800，12 FPS）的驾驶视频及对应的动态3D场景，在新视角合成中达到SSIM 0.811和PSNR 22.84，同时保持参数效率。

Conclusion: DriveGen3D通过整合FastDrive-DiT和FastRecon3D组件，成功实现了高质量、高可控性的动态3D驾驶场景生成，填补了现有方法的空白。

Abstract: We present DriveGen3D, a novel framework for generating high-quality and
highly controllable dynamic 3D driving scenes that addresses critical
limitations in existing methodologies. Current approaches to driving scene
synthesis either suffer from prohibitive computational demands for extended
temporal generation, focus exclusively on prolonged video synthesis without 3D
representation, or restrict themselves to static single-scene reconstruction.
Our work bridges this methodological gap by integrating accelerated long-term
video generation with large-scale dynamic scene reconstruction through
multimodal conditional control. DriveGen3D introduces a unified pipeline
consisting of two specialized components: FastDrive-DiT, an efficient video
diffusion transformer for high-resolution, temporally coherent video synthesis
under text and Bird's-Eye-View (BEV) layout guidance; and FastRecon3D, a
feed-forward reconstruction module that rapidly builds 3D Gaussian
representations across time, ensuring spatial-temporal consistency. Together,
these components enable real-time generation of extended driving videos (up to
$424\times800$ at 12 FPS) and corresponding dynamic 3D scenes, achieving SSIM
of 0.811 and PSNR of 22.84 on novel view synthesis, all while maintaining
parameter efficiency.

</details>


### [25] [CuSfM: CUDA-Accelerated Structure-from-Motion](https://arxiv.org/abs/2510.15271)
*Jingrui Yu,Jun Liu,Kefei Ren,Joydeep Biswas,Rurui Ye,Keqiang Wu,Chirag Majithia,Di Zeng*

Main category: cs.CV

TL;DR: cuSfM是一个GPU加速的离线SfM系统，通过并行化提升相机姿态估计的效率和精度，实验显示其优于COLMAP，并已开源。


<details>
  <summary>Details</summary>
Motivation: 解决自主导航、机器人感知和虚拟仿真系统中密集重建对高效准确相机姿态估计的基础需求。

Method: cuSfM是一个基于CUDA加速的离线Structure-from-Motion系统，利用GPU并行化高效运行计算密集型特征提取器，生成全面且非冗余的数据关联。

Result: 实验表明，cuSfM在多种测试场景下相比COLMAP方法显著提升了精度和处理速度，同时保持了离线SfM应用所需的高精度和全局一致性。

Conclusion: cuSfM通过GPU并行化显著提升了相机姿态估计的效率和精度，适用于离线处理的高精度需求场景。

Abstract: Efficient and accurate camera pose estimation forms the foundational
requirement for dense reconstruction in autonomous navigation, robotic
perception, and virtual simulation systems. This paper addresses the challenge
via cuSfM, a CUDA-accelerated offline Structure-from-Motion system that
leverages GPU parallelization to efficiently employ computationally intensive
yet highly accurate feature extractors, generating comprehensive and
non-redundant data associations for precise camera pose estimation and globally
consistent mapping. The system supports pose optimization, mapping, prior-map
localization, and extrinsic refinement. It is designed for offline processing,
where computational resources can be fully utilized to maximize accuracy.
Experimental results demonstrate that cuSfM achieves significantly improved
accuracy and processing speed compared to the widely used COLMAP method across
various testing scenarios, while maintaining the high precision and global
consistency essential for offline SfM applications. The system is released as
an open-source Python wrapper implementation, PyCuSfM, available at
https://github.com/nvidia-isaac/pyCuSFM, to facilitate research and
applications in computer vision and robotics.

</details>


### [26] [Post-Processing Methods for Improving Accuracy in MRI Inpainting](https://arxiv.org/abs/2510.15282)
*Nishad Kulkarni,Krithika Iyer,Austin Tapp,Abhijeet Parida,Daniel Capellán-Martín,Zhifan Jiang,María J. Ledesma-Carbayo,Syed Muhammad Anwar,Marius George Linguraru*

Main category: cs.CV

TL;DR: 本文评估了MRI图像修复模型的性能瓶颈，提出结合模型集成与后处理策略的改进方法，通过轻量级U-Net增强修复效果，提升了临床应用的可行性和效率。


<details>
  <summary>Details</summary>
Motivation: MRI是诊断、评估和治疗脑部疾病的主要成像方式，但大多数自动化MRI分析工具针对健康解剖结构优化，面对大病灶（如肿瘤）时往往失效。图像修复技术旨在局部合成肿瘤区域的健康脑组织，从而可靠应用通用工具。

Method: 我们系统评估了最先进的图像修复模型，并提出了一种结合模型集成与高效后处理策略（如中值滤波、直方图匹配和像素平均）的方法。进一步的解剖学细化通过轻量级U-Net增强阶段实现。

Result: 综合评估表明，我们提出的流程提高了修复区域的解剖合理性和视觉保真度，比单独基线模型具有更高的准确性和更稳健的结果。

Conclusion: 通过结合现有模型和针对性后处理，我们实现了更优且更易获取的图像修复结果，支持更广泛的临床应用和资源节约型研究。

Abstract: Magnetic Resonance Imaging (MRI) is the primary imaging modality used in the
diagnosis, assessment, and treatment planning for brain pathologies. However,
most automated MRI analysis tools, such as segmentation and registration
pipelines, are optimized for healthy anatomies and often fail when confronted
with large lesions such as tumors. To overcome this, image inpainting
techniques aim to locally synthesize healthy brain tissues in tumor regions,
enabling the reliable application of general-purpose tools. In this work, we
systematically evaluate state-of-the-art inpainting models and observe a
saturation in their standalone performance. In response, we introduce a
methodology combining model ensembling with efficient post-processing
strategies such as median filtering, histogram matching, and pixel averaging.
Further anatomical refinement is achieved via a lightweight U-Net enhancement
stage. Comprehensive evaluation demonstrates that our proposed pipeline
improves the anatomical plausibility and visual fidelity of inpainted regions,
yielding higher accuracy and more robust outcomes than individual baseline
models. By combining established models with targeted post-processing, we
achieve improved and more accessible inpainting outcomes, supporting broader
clinical deployment and sustainable, resource-conscious research. Our 2025
BraTS inpainting docker is available at
https://hub.docker.com/layers/aparida12/brats2025/inpt.

</details>


### [27] [Exploring Conditions for Diffusion models in Robotic Control](https://arxiv.org/abs/2510.15510)
*Heeseong Shin,Byeongho Heo,Dongyoon Han,Seungryong Kim,Taekyung Kim*

Main category: cs.CV

TL;DR: ORCA利用可学习的任务和视觉提示，实现了任务自适应的视觉表示，显著提升了机器人控制性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉表示在模仿学习中取得了进展，但通常是任务无关的，且直接应用文本条件在控制任务中效果不佳。这促使研究团队探索更适合控制任务的视觉表示方法。

Method: 提出了ORCA方法，通过可学习的任务提示适应控制环境，以及视觉提示捕捉细粒度的帧特定细节，从而获得任务自适应的视觉表示。

Result: ORCA在多个机器人控制基准测试中达到了最先进的性能，显著优于之前的方法。

Conclusion: ORCA通过引入可学习的任务提示和视觉提示，成功实现了任务自适应的视觉表示，显著提升了机器人控制任务的性能，超越了现有方法。

Abstract: While pre-trained visual representations have significantly advanced
imitation learning, they are often task-agnostic as they remain frozen during
policy learning. In this work, we explore leveraging pre-trained text-to-image
diffusion models to obtain task-adaptive visual representations for robotic
control, without fine-tuning the model itself. However, we find that naively
applying textual conditions - a successful strategy in other vision domains -
yields minimal or even negative gains in control tasks. We attribute this to
the domain gap between the diffusion model's training data and robotic control
environments, leading us to argue for conditions that consider the specific,
dynamic visual information required for control. To this end, we propose ORCA,
which introduces learnable task prompts that adapt to the control environment
and visual prompts that capture fine-grained, frame-specific details. Through
facilitating task-adaptive representations with our newly devised conditions,
our approach achieves state-of-the-art performance on various robotic control
benchmarks, significantly surpassing prior methods.

</details>


### [28] [QCFace: Image Quality Control for boosting Face Representation & Recognition](https://arxiv.org/abs/2510.15289)
*Duc-Phuong Doan-Ngo,Thanh-Dang Diep,Thanh Nguyen-Duc,Thanh-Sach LE,Nam Thoai*

Main category: cs.CV

TL;DR: QCFace通过硬边距策略解决了当前人脸识别系统中的可识别性和梯度问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在可识别性捕获和特征嵌入优化方面存在不足，导致特征表示质量较低且不稳定。

Method: 引入了一种硬边距策略——Quality Control Face (QCFace)，通过指导因子优化超球面规划，同时优化识别能力和显式可识别性表示。

Result: QCFace克服了相互重叠梯度问题，实现了可识别性与身份表示的清晰解耦，并在实验中表现出色。

Conclusion: QCFace不仅提供了稳健且可量化的可识别性编码，还在验证和识别基准测试中实现了最先进的性能。

Abstract: Recognizability, a key perceptual factor in human face processing, strongly
affects the performance of face recognition (FR) systems in both verification
and identification tasks. Effectively using recognizability to enhance feature
representation remains challenging. In deep FR, the loss function plays a
crucial role in shaping how features are embedded. However, current methods
have two main drawbacks: (i) recognizability is only partially captured through
soft margin constraints, resulting in weaker quality representation and lower
discrimination, especially for low-quality or ambiguous faces; (ii) mutual
overlapping gradients between feature direction and magnitude introduce
undesirable interactions during optimization, causing instability and confusion
in hypersphere planning, which may result in poor generalization, and entangled
representations where recognizability and identity are not cleanly separated.
To address these issues, we introduce a hard margin strategy - Quality Control
Face (QCFace), which overcomes the mutual overlapping gradient problem and
enables the clear decoupling of recognizability from identity representation.
Based on this strategy, a novel hard-margin-based loss function employs a
guidance factor for hypersphere planning, simultaneously optimizing for
recognition ability and explicit recognizability representation. Extensive
experiments confirm that QCFace not only provides robust and quantifiable
recognizability encoding but also achieves state-of-the-art performance in both
verification and identification benchmarks compared to existing
recognizability-based losses.

</details>


### [29] [Hyperbolic Structured Classification for Robust Single Positive Multi-label Learning](https://arxiv.org/abs/2510.15296)
*Yiming Lin,Shang Wang,Junkai Zhou,Qiufeng Wang,Xiao-Bo Jin,Kaizhu Huang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于双曲几何的框架，通过将标签表示为双曲球来显式建模多种标签关系，实验证明其性能优越且更具可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决单正多标签学习（SPMLL）中每个训练样本仅标注一个正标签但可能属于多个类别的挑战性问题，现有方法通过基于距离的相似性隐式建模标签关系，缺乏对不同关系类型的显式几何定义。

Method: 提出首个双曲分类框架，将每个标签表示为双曲球而非点或向量，通过几何球交互建模丰富的标签间关系。引入两个关键创新：温度自适应的双曲球分类器和物理启发的双井正则化。

Result: 在四个基准数据集（MS-COCO、PASCAL VOC、NUS-WIDE、CUB-200-2011）上的广泛实验表明，与现有方法相比具有竞争力的性能和更优的可解释性。

Conclusion: 双曲几何为不完全监督下的结构化分类提供了更稳健的范式，学习到的嵌入与实际共现模式之间存在强相关性。

Abstract: Single Positive Multi-Label Learning (SPMLL) addresses the challenging
scenario where each training sample is annotated with only one positive label
despite potentially belonging to multiple categories, making it difficult to
capture complex label relationships and hierarchical structures. While existing
methods implicitly model label relationships through distance-based similarity,
lacking explicit geometric definitions for different relationship types. To
address these limitations, we propose the first hyperbolic classification
framework for SPMLL that represents each label as a hyperbolic ball rather than
a point or vector, enabling rich inter-label relationship modeling through
geometric ball interactions. Our ball-based approach naturally captures
multiple relationship types simultaneously: inclusion for hierarchical
structures, overlap for co-occurrence patterns, and separation for semantic
independence. Further, we introduce two key component innovations: a
temperature-adaptive hyperbolic ball classifier and a physics-inspired
double-well regularization that guides balls toward meaningful configurations.
To validate our approach, extensive experiments on four benchmark datasets
(MS-COCO, PASCAL VOC, NUS-WIDE, CUB-200-2011) demonstrate competitive
performance with superior interpretability compared to existing methods.
Furthermore, statistical analysis reveals strong correlation between learned
embeddings and real-world co-occurrence patterns, establishing hyperbolic
geometry as a more robust paradigm for structured classification under
incomplete supervision.

</details>


### [30] [Latent Diffusion Model without Variational Autoencoder](https://arxiv.org/abs/2510.15301)
*Minglei Shi,Haolin Wang,Wenzhao Zheng,Ziyang Yuan,Xiaoshi Wu,Xintao Wang,Pengfei Wan,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: SVG是一种新型潜在扩散模型，通过自监督表示构建语义化潜在空间，解决了VAE+扩散模型的效率与泛化问题，显著提升了生成质量和训练速度。


<details>
  <summary>Details</summary>
Motivation: 当前基于VAE的潜在扩散模型存在训练效率低、推理速度慢及泛化性差的问题，根源在于VAE潜在空间缺乏明确的语义分离和判别结构。研究表明这些特性对感知、理解任务及扩散模型的稳定高效训练至关重要。

Method: SVG采用自监督表示（如冻结的DINO特征）构建语义结构化的潜在空间，并结合轻量级残差分支捕捉细节，直接在语义空间上训练扩散模型。

Result: SVG实现了更高效的扩散训练、支持少步采样，并提升了生成质量。实验证明其保留了自监督表示的语义和判别能力。

Conclusion: SVG通过利用自监督表示构建具有明确语义区分性的特征空间，显著提升了扩散模型的训练效率和生成质量，同时保留了底层表示的语义和判别能力，为通用高质量视觉表示提供了新途径。

Abstract: Recent progress in diffusion-based visual generation has largely relied on
latent diffusion models with variational autoencoders (VAEs). While effective
for high-fidelity synthesis, this VAE+diffusion paradigm suffers from limited
training efficiency, slow inference, and poor transferability to broader vision
tasks. These issues stem from a key limitation of VAE latent spaces: the lack
of clear semantic separation and strong discriminative structure. Our analysis
confirms that these properties are crucial not only for perception and
understanding tasks, but also for the stable and efficient training of latent
diffusion models. Motivated by this insight, we introduce SVG, a novel latent
diffusion model without variational autoencoders, which leverages
self-supervised representations for visual generation. SVG constructs a feature
space with clear semantic discriminability by leveraging frozen DINO features,
while a lightweight residual branch captures fine-grained details for
high-fidelity reconstruction. Diffusion models are trained directly on this
semantically structured latent space to facilitate more efficient learning. As
a result, SVG enables accelerated diffusion training, supports few-step
sampling, and improves generative quality. Experimental results further show
that SVG preserves the semantic and discriminative capabilities of the
underlying self-supervised representations, providing a principled pathway
toward task-general, high-quality visual representations.

</details>


### [31] [Layer as Puzzle Pieces: Compressing Large Language Models through Layer Concatenation](https://arxiv.org/abs/2510.15304)
*Fei Wang,Li Shen,Liang Ding,Chao Xue,Ye Liu,Changxing Ding*

Main category: cs.CV

TL;DR: CoMe提出了一种渐进式剪枝与分层蒸馏结合的方法，显著提升大语言模型剪枝后的性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法直接移除层导致性能显著下降，线性权重层聚合能力不足，且缺乏有效的后训练恢复机制。

Method: 提出了渐进式层剪枝框架，包括基于通道敏感度度量的细粒度通道选择、基于连接的层合并方法以及分层蒸馏协议。

Result: 在七个基准测试中，CoMe达到最先进性能；剪除LLaMA-2-7b 30%参数后，剪枝模型保留原始平均准确率的83%。

Conclusion: CoMe通过渐进式层剪枝框架、基于连接的合并技术和分层蒸馏后训练过程，有效解决了现有结构化剪枝方法的局限性，显著提升了剪枝后模型的性能。

Abstract: Large Language Models excel at natural language processing tasks, but their
massive size leads to high computational and storage demands. Recent works have
sought to reduce their model size through layer-wise structured pruning.
However, they tend to ignore retaining the capabilities in the pruned part. In
this work, we re-examine structured pruning paradigms and uncover several key
limitations: 1) notable performance degradation due to direct layer removal, 2)
incompetent linear weight layer aggregation, and 3) the lack of effective
post-training recovery mechanisms. To address these limitations, we propose
CoMe, including a progressive layer pruning framework with a
Concatenation-based Merging technology and a hierarchical distillation
post-training process. Specifically, we introduce a channel sensitivity metric
that utilizes activation intensity and weight norms for fine-grained channel
selection. Subsequently, we employ a concatenation-based layer merging method
to fuse the most critical channels across adjacent layers, enabling progressive
model size reduction. Finally, we propose a hierarchical distillation protocol
that leverages the correspondences between the original and pruned model layers
established during pruning, thereby enabling efficient knowledge transfer.
Experiments on seven benchmarks show that CoMe achieves state-of-the-art
performance; when pruning 30% of LLaMA-2-7b's parameters, the pruned model
retains 83% of its original average accuracy. Our code is available at
https://github.com/MPI-Lab/CoMe.

</details>


### [32] [Spatial457: A Diagnostic Benchmark for 6D Spatial Reasoning of Large Multimodal Models](https://arxiv.org/abs/2502.08636)
*Xingrui Wang,Wufei Ma,Tiezheng Zhang,Celso M de Melo,Jieneng Chen,Alan Yuille*

Main category: cs.CV

TL;DR: 论文提出了Spatial457数据集和RPDR指标，揭示了大型多模态模型在复杂空间推理任务中的性能局限。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要关注2D空间理解，缺乏评估6D空间推理的综合框架。

Method: 开发了Spatial457数据集，设计了7种问题类型和5个难度级别，并引入了RPDR指标来量化性能下降。

Result: 模型在3D和6D空间任务中表现下降，且存在预测偏差。

Conclusion: 论文提出了Spatial457数据集和RPDR指标，揭示了现有大型多模态模型在3D和6D空间推理任务中的性能下降和预测偏差。

Abstract: Although large multimodal models (LMMs) have demonstrated remarkable
capabilities in visual scene interpretation and reasoning, their capacity for
complex and precise 3-dimensional spatial reasoning remains uncertain. Existing
benchmarks focus predominantly on 2D spatial understanding and lack a framework
to comprehensively evaluate 6D spatial reasoning across varying complexities.
To address this limitation, we present Spatial457, a scalable and unbiased
synthetic dataset designed with 4 key capability for spatial reasoning:
multi-object recognition, 2D location, 3D location, and 3D orientation. We
develop a cascading evaluation structure, constructing 7 question types across
5 difficulty levels that range from basic single object recognition to our new
proposed complex 6D spatial reasoning tasks. We evaluated various large
multimodal models (LMMs) on PulseCheck457, observing a general decline in
performance as task complexity increases, particularly in 3D reasoning and 6D
spatial tasks. To quantify these challenges, we introduce the Relative
Performance Dropping Rate (RPDR), highlighting key weaknesses in 3D reasoning
capabilities. Leveraging the unbiased attribute design of our dataset, we also
uncover prediction biases across different attributes, with similar patterns
observed in real-world image settings. The code and data are released in
https://github.com/XingruiWang/Spatial457.

</details>


### [33] [Proto-Former: Unified Facial Landmark Detection by Prototype Transformer](https://arxiv.org/abs/2510.15338)
*Shengkai Hu,Haozhe Qi,Jun Wan,Jiaxing Huang,Lefei Zhang,Hang Sun,Dacheng Tao*

Main category: cs.CV

TL;DR: Proto-Former 是一个统一的面部标志检测框架，通过自适应原型学习和多数据集训练，显著提升了模型泛化能力和检测精度。


<details>
  <summary>Details</summary>
Motivation: 现有面部标志检测数据集定义不同数量的标志，主流方法只能训练于单一数据集，限制了模型泛化和统一模型的发展。

Method: Proto-Former 包含两个关键组件：自适应原型感知编码器（APAE）和渐进式原型感知解码器（PPAD），以及引入的原型感知（PA）损失函数，用于优化原型专家的选择权重。

Result: 在广泛使用的基准数据集上的实验表明，Proto-Former 性能优于现有最先进方法。

Conclusion: Proto-Former 是一个统一的、自适应的端到端面部标志检测框架，通过增强数据集特定的面部结构表示（原型），克服了单一数据集训练的局限性。实验证明其在多个基准数据集上优于现有方法。

Abstract: Recent advances in deep learning have significantly improved facial landmark
detection. However, existing facial landmark detection datasets often define
different numbers of landmarks, and most mainstream methods can only be trained
on a single dataset. This limits the model generalization to different datasets
and hinders the development of a unified model. To address this issue, we
propose Proto-Former, a unified, adaptive, end-to-end facial landmark detection
framework that explicitly enhances dataset-specific facial structural
representations (i.e., prototype). Proto-Former overcomes the limitations of
single-dataset training by enabling joint training across multiple datasets
within a unified architecture. Specifically, Proto-Former comprises two key
components: an Adaptive Prototype-Aware Encoder (APAE) that performs adaptive
feature extraction and learns prototype representations, and a Progressive
Prototype-Aware Decoder (PPAD) that refines these prototypes to generate
prompts that guide the model's attention to key facial regions. Furthermore, we
introduce a novel Prototype-Aware (PA) loss, which achieves optimal path
finding by constraining the selection weights of prototype experts. This loss
function effectively resolves the problem of prototype expert addressing
instability during multi-dataset training, alleviates gradient conflicts, and
enables the extraction of more accurate facial structure features. Extensive
experiments on widely used benchmark datasets demonstrate that our Proto-Former
achieves superior performance compared to existing state-of-the-art methods.
The code is publicly available at: https://github.com/Husk021118/Proto-Former.

</details>


### [34] [SHARE: Scene-Human Aligned Reconstruction](https://arxiv.org/abs/2510.15342)
*Joshua Li,Brendan Chharawala,Chang Shu,Xue Bin Peng,Pengcheng Xi*

Main category: cs.CV

TL;DR: SHARE利用场景几何和迭代优化技术，显著提升了单目RGB视频中人体运动重建的3D空间准确性。


<details>
  <summary>Details</summary>
Motivation: 当前的人体运动重建方法难以准确地将人体放置在3D空间中，影响了在游戏、AR/VR和机器人等领域的应用效果。

Method: SHARE技术首先估计每帧的人体网格和分割掩码，同时在关键帧生成场景点图。通过迭代优化关键帧中人体网格与场景点图的对齐，并保持非关键帧人体网格的相对根关节位置一致性。

Result: 实验表明，SHARE在准确性和适用性上优于现有方法，能够有效处理精心策划的数据集和野外网络视频。

Conclusion: SHARE方法通过利用场景几何的固有空间线索，显著提高了3D空间中人体运动重建的准确性，适用于多种实际应用场景。

Abstract: Animating realistic character interactions with the surrounding environment
is important for autonomous agents in gaming, AR/VR, and robotics. However,
current methods for human motion reconstruction struggle with accurately
placing humans in 3D space. We introduce Scene-Human Aligned REconstruction
(SHARE), a technique that leverages the scene geometry's inherent spatial cues
to accurately ground human motion reconstruction. Each reconstruction relies
solely on a monocular RGB video from a stationary camera. SHARE first estimates
a human mesh and segmentation mask for every frame, alongside a scene point map
at keyframes. It iteratively refines the human's positions at these keyframes
by comparing the human mesh against the human point map extracted from the
scene using the mask. Crucially, we also ensure that non-keyframe human meshes
remain consistent by preserving their relative root joint positions to keyframe
root joints during optimization. Our approach enables more accurate 3D human
placement while reconstructing the surrounding scene, facilitating use cases on
both curated datasets and in-the-wild web videos. Extensive experiments
demonstrate that SHARE outperforms existing methods.

</details>


### [35] [Cortical-SSM: A Deep State Space Model for EEG and ECoG Motor Imagery Decoding](https://arxiv.org/abs/2510.15371)
*Shuntaro Suzuki,Shunya Nagashima,Masayuki Hirata,Komei Sugiura*

Main category: cs.CV

TL;DR: Cortical-SSM 是一种新架构，通过深度状态空间模型改进 EEG 和 ECoG 信号分类，在多个数据集上表现优异，并能捕捉神经生理相关特征。


<details>
  <summary>Details</summary>
Motivation: EEG 和 ECoG 信号在运动想象（MI）分类中具有重要应用潜力，但易受生理伪影干扰，且现有 Transformer 方法难以捕捉其细粒度依赖关系。

Method: 提出了一种名为 Cortical-SSM 的新架构，扩展了深度状态空间模型，以捕捉 EEG 和 ECoG 信号在时间、空间和频率域上的综合依赖关系。

Result: 在包含 50 多名受试者的大型公共 MI EEG 数据集和一名肌萎缩侧索硬化患者的临床 MI ECoG 数据集上，Cortical-SSM 表现优于基线方法，并能有效捕捉神经生理相关区域。

Conclusion: Cortical-SSM 架构成功克服了现有 Transformer 方法在捕捉 EEG 和 ECoG 信号细粒度依赖关系上的不足，并在三个基准测试中表现优于基线方法。

Abstract: Classification of electroencephalogram (EEG) and electrocorticogram (ECoG)
signals obtained during motor imagery (MI) has substantial application
potential, including for communication assistance and rehabilitation support
for patients with motor impairments. These signals remain inherently
susceptible to physiological artifacts (e.g., eye blinking, swallowing), which
pose persistent challenges. Although Transformer-based approaches for
classifying EEG and ECoG signals have been widely adopted, they often struggle
to capture fine-grained dependencies within them. To overcome these
limitations, we propose Cortical-SSM, a novel architecture that extends deep
state space models to capture integrated dependencies of EEG and ECoG signals
across temporal, spatial, and frequency domains. We validated our method across
three benchmarks: 1) two large-scale public MI EEG datasets containing more
than 50 subjects, and 2) a clinical MI ECoG dataset recorded from a patient
with amyotrophic lateral sclerosis. Our method outperformed baseline methods on
the three benchmarks. Furthermore, visual explanations derived from our model
indicate that it effectively captures neurophysiologically relevant regions of
both EEG and ECoG signals.

</details>


### [36] [Adaptive transfer learning for surgical tool presence detection in laparoscopic videos through gradual freezing fine-tuning](https://arxiv.org/abs/2510.15372)
*Ana Davila,Jacinto Colan,Yasuhisa Hasegawa*

Main category: cs.CV

TL;DR: 本文提出了一种分阶段自适应微调方法，显著提升手术工具检测性能，并在多个数据集中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 手术环境中标注数据的有限性对训练稳健的深度学习模型构成挑战，需要一种高效的微调方法。

Method: 提出了一种新颖的分阶段自适应微调方法，包括线性探测阶段和渐进式冻结阶段，以减少网络复杂性并提高效率。

Result: 在Cholec80数据集上实现了96.4%的平均精度（mAP），并在CATARACTS数据集上验证了方法的泛化性。

Conclusion: 渐进式冻结微调是一种有前景的技术，可显著提升手术工具检测性能，并可能广泛应用于一般图像分类任务。

Abstract: Minimally invasive surgery can benefit significantly from automated surgical
tool detection, enabling advanced analysis and assistance. However, the limited
availability of annotated data in surgical settings poses a challenge for
training robust deep learning models. This paper introduces a novel staged
adaptive fine-tuning approach consisting of two steps: a linear probing stage
to condition additional classification layers on a pre-trained CNN-based
architecture and a gradual freezing stage to dynamically reduce the
fine-tunable layers, aiming to regulate adaptation to the surgical domain. This
strategy reduces network complexity and improves efficiency, requiring only a
single training loop and eliminating the need for multiple iterations. We
validated our method on the Cholec80 dataset, employing CNN architectures
(ResNet-50 and DenseNet-121) pre-trained on ImageNet for detecting surgical
tools in cholecystectomy endoscopic videos. Our results demonstrate that our
method improves detection performance compared to existing approaches and
established fine-tuning techniques, achieving a mean average precision (mAP) of
96.4%. To assess its broader applicability, the generalizability of the
fine-tuning strategy was further confirmed on the CATARACTS dataset, a distinct
domain of minimally invasive ophthalmic surgery. These findings suggest that
gradual freezing fine-tuning is a promising technique for improving tool
presence detection in diverse surgical procedures and may have broader
applications in general image classification tasks.

</details>


### [37] [FreqPDE: Rethinking Positional Depth Embedding for Multi-View 3D Object Detection Transformers](https://arxiv.org/abs/2510.15385)
*Haisheng Su,Junjie Zhang,Feixiang Song,Sanping Zhou,Wei Wu,Nanning Zheng,Junchi Yan*

Main category: cs.CV

TL;DR: FreqPDE通过结合高频边缘和低频语义、跨视图尺度不变深度预测，提升了多视角2D图像中3D物体检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖深度预测恢复空间信息，但深度预测质量不佳，如物体边界深度不连续和小物体难以区分。此外，跨视图一致性和尺度不变性被忽视。

Method: FreqPDE由三个模块组成：Frequency-aware Spatial Pyramid Encoder (FSPE) 构建特征金字塔，Cross-view Scale-invariant Depth Predictor (CSDP) 估计像素级深度分布，Positional Depth Encoder (PDE) 生成3D深度感知特征。此外，采用混合深度监督从度量和分布两方面进行互补学习。

Result: 在nuScenes数据集上的广泛实验证明了该方法的有效性和优越性。

Conclusion: 论文提出的FreqPDE方法通过结合高频边缘线索和低频语义，以及跨视图尺度不变深度预测，显著提升了多视角2D图像中3D物体检测的准确性。

Abstract: Detecting 3D objects accurately from multi-view 2D images is a challenging
yet essential task in the field of autonomous driving. Current methods resort
to integrating depth prediction to recover the spatial information for object
query decoding, which necessitates explicit supervision from LiDAR points
during the training phase. However, the predicted depth quality is still
unsatisfactory such as depth discontinuity of object boundaries and
indistinction of small objects, which are mainly caused by the sparse
supervision of projected points and the use of high-level image features for
depth prediction. Besides, cross-view consistency and scale invariance are also
overlooked in previous methods. In this paper, we introduce Frequency-aware
Positional Depth Embedding (FreqPDE) to equip 2D image features with spatial
information for 3D detection transformer decoder, which can be obtained through
three main modules. Specifically, the Frequency-aware Spatial Pyramid Encoder
(FSPE) constructs a feature pyramid by combining high-frequency edge clues and
low-frequency semantics from different levels respectively. Then the Cross-view
Scale-invariant Depth Predictor (CSDP) estimates the pixel-level depth
distribution with cross-view and efficient channel attention mechanism.
Finally, the Positional Depth Encoder (PDE) combines the 2D image features and
3D position embeddings to generate the 3D depth-aware features for query
decoding. Additionally, hybrid depth supervision is adopted for complementary
depth learning from both metric and distribution aspects. Extensive experiments
conducted on the nuScenes dataset demonstrate the effectiveness and superiority
of our proposed method.

</details>


### [38] [PFGS: Pose-Fused 3D Gaussian Splatting for Complete Multi-Pose Object Reconstruction](https://arxiv.org/abs/2510.15386)
*Ting-Yu Yen,Yu-Sheng Chiu,Shih-Hsuan Hung,Peter Wonka,Hung-Kuo Chu*

Main category: cs.CV

TL;DR: PFGS是一种姿态感知的3D高斯溅射框架，通过智能融合多姿态图像捕获，显著提升重建完整性和保真度。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS方法假设物体在单一静态姿态下捕获，导致重建不完整，无法处理遮挡或自遮挡区域。PFGS旨在解决从多姿态图像捕获中重建完整物体的实际挑战。

Method: PFGS采用姿态感知的融合策略，结合全局和局部配准，迭代地将辅助姿态的图像融合到主姿态的3DGS表示中。

Result: 实验结果表明，PFGS在定性和定量评估中均优于强基线，产生更完整的重建和更高保真度的3DGS模型。

Conclusion: PFGS通过智能整合3D基础模型和背景特征，显著提高了多姿态图像捕获中的3D高斯溅射重建的完整性和保真度。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled high-quality,
real-time novel-view synthesis from multi-view images. However, most existing
methods assume the object is captured in a single, static pose, resulting in
incomplete reconstructions that miss occluded or self-occluded regions. We
introduce PFGS, a pose-aware 3DGS framework that addresses the practical
challenge of reconstructing complete objects from multi-pose image captures.
Given images of an object in one main pose and several auxiliary poses, PFGS
iteratively fuses each auxiliary set into a unified 3DGS representation of the
main pose. Our pose-aware fusion strategy combines global and local
registration to merge views effectively and refine the 3DGS model. While recent
advances in 3D foundation models have improved registration robustness and
efficiency, they remain limited by high memory demands and suboptimal accuracy.
PFGS overcomes these challenges by incorporating them more intelligently into
the registration process: it leverages background features for per-pose camera
pose estimation and employs foundation models for cross-pose registration. This
design captures the best of both approaches while resolving background
inconsistency issues. Experimental results demonstrate that PFGS consistently
outperforms strong baselines in both qualitative and quantitative evaluations,
producing more complete reconstructions and higher-fidelity 3DGS models.

</details>


### [39] [LILAC: Long-sequence Incremental Low-latency Arbitrary Motion Stylization via Streaming VAE-Diffusion with Causal Decoding](https://arxiv.org/abs/2510.15392)
*Peng Ren,Hai Yang*

Main category: cs.CV

TL;DR: LILAC通过潜在空间流式架构和因果解码，实现了长序列实时任意运动风格化，解决了现有方法的高计算开销和时间稳定性问题。


<details>
  <summary>Details</summary>
Motivation: 实时生成长且风格化的人体运动对需要连续和响应式角色控制的应用至关重要，现有流式方法在原始运动空间操作导致计算开销大且难以保持时间稳定性。

Method: LILAC基于高性能离线框架，通过潜在空间流式架构、滑动窗口因果设计和解码运动特征注入，扩展至在线设置。

Result: 实验证明，LILAC在基准数据集上实现了风格化质量和响应性的良好平衡。

Conclusion: LILAC通过潜在空间流式架构和滑动窗口因果设计，实现了长序列实时任意风格化，无需依赖未来帧或修改扩散模型架构，在风格化质量和响应性之间取得了良好平衡。

Abstract: Generating long and stylized human motions in real time is critical for
applications that demand continuous and responsive character control. Despite
its importance, existing streaming approaches often operate directly in the raw
motion space, leading to substantial computational overhead and making it
difficult to maintain temporal stability. In contrast, latent-space
VAE-Diffusion-based frameworks alleviate these issues and achieve high-quality
stylization, but they are generally confined to offline processing. To bridge
this gap, LILAC (Long-sequence Incremental Low-latency Arbitrary Motion
Stylization via Streaming VAE-Diffusion with Causal Decoding) builds upon a
recent high-performing offline framework for arbitrary motion stylization and
extends it to an online setting through a latent-space streaming architecture
with a sliding-window causal design and the injection of decoded motion
features to ensure smooth motion transitions. This architecture enables
long-sequence real-time arbitrary stylization without relying on future frames
or modifying the diffusion model architecture, achieving a favorable balance
between stylization quality and responsiveness as demonstrated by experiments
on benchmark datasets. Supplementary video and examples are available at the
project page: https://pren1.github.io/lilac/

</details>


### [40] [MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment](https://arxiv.org/abs/2510.15398)
*Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li*

Main category: cs.CV

TL;DR: 论文提出了一种水下开放词汇实例分割的统一框架（GPEM+SAIM），解决了视觉退化和语义不对齐问题，在MARIS基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有水下实例分割方法受限于封闭词汇预测，无法识别新类别。水下开放词汇分割面临视觉退化（如颜色衰减）和语义不对齐的挑战。

Method: 论文提出了两个互补的组件：几何先验增强模块（GPEM）和语义对齐注入机制（SAIM），分别用于解决水下场景中的视觉退化问题和语义对齐问题。

Result: 实验表明，该框架在MARIS基准上（域内和跨域）均优于现有开放词汇基线方法。

Conclusion: 该论文提出了一个统一的框架（GPEM和SAIM），显著提升了水下开放词汇实例分割的性能，为未来水下感知研究奠定了坚实基础。

Abstract: Most existing underwater instance segmentation approaches are constrained by
close-vocabulary prediction, limiting their ability to recognize novel marine
categories. To support evaluation, we introduce \textbf{MARIS}
(\underline{Mar}ine Open-Vocabulary \underline{I}nstance
\underline{S}egmentation), the first large-scale fine-grained benchmark for
underwater Open-Vocabulary (OV) segmentation, featuring a limited set of seen
categories and diverse unseen categories. Although OV segmentation has shown
promise on natural images, our analysis reveals that transfer to underwater
scenes suffers from severe visual degradation (e.g., color attenuation) and
semantic misalignment caused by lack underwater class definitions. To address
these issues, we propose a unified framework with two complementary components.
The Geometric Prior Enhancement Module (\textbf{GPEM}) leverages stable
part-level and structural cues to maintain object consistency under degraded
visual conditions. The Semantic Alignment Injection Mechanism (\textbf{SAIM})
enriches language embeddings with domain-specific priors, mitigating semantic
ambiguity and improving recognition of unseen categories. Experiments show that
our framework consistently outperforms existing OV baselines both In-Domain and
Cross-Domain setting on MARIS, establishing a strong foundation for future
underwater perception research.

</details>


### [41] [Robust High-Resolution Multi-Organ Diffusion MRI Using Synthetic-Data-Tuned Prompt Learning](https://arxiv.org/abs/2510.15400)
*Chen Qian,Haoyu Zhang,Junnan Ma,Liuhong Zhu,Qingrui Cai,Yu Wang,Ruibo Song,Lv Li,Lin Mei,Xianwang Jiang,Qin Xu,Boyu Jiang,Ran Tao,Chunmiao Chen,Shufang Chen,Dongyun Liang,Qiu Guo,Jianzhong Lin,Taishan Kang,Mengtian Lu,Liyuan Fu,Ruibin Huang,Huijuan Wan,Xu Huang,Jianhua Wang,Di Guo,Hai Zhong,Jianjun Zhou,Xiaobo Qu*

Main category: cs.CV

TL;DR: LoSP-Prompt框架通过物理建模和合成数据驱动的提示学习，解决了多方向DWI中的运动伪影问题，提升了图像质量和分辨率，适用于多器官成像。


<details>
  <summary>Details</summary>
Motivation: 临床多方向扩散加权成像（multi-shot DWI）在全身肿瘤诊断中的应用受限于呼吸、蠕动等运动引起的严重相位伪影，以及多器官、多切片、多方向和多b值的复杂性。

Method: 该框架将多方向相位变化建模为高阶局部平滑相位（LoSP），并集成到低秩Hankel矩阵重建中，通过合成腹部DWI数据训练的提示学习自动设置算法参数。

Result: 在10,000+临床图像验证中，LoSP-Prompt实现了两倍于单次DWI的空间分辨率，提升了肝脏病变的显著性；在七个解剖区域中表现出色，图像质量、伪影抑制和噪声减少均优于现有方法（11位放射科医生评分，p<0.05）。

Conclusion: LoSP-Prompt框架通过物理建模和合成数据驱动的提示学习，为高分辨率多器官多方向扩散加权成像提供了可解释、稳健的解决方案，展示了在精准肿瘤学中的变革潜力。

Abstract: Clinical adoption of multi-shot diffusion-weighted magnetic resonance imaging
(multi-shot DWI) for body-wide tumor diagnostics is limited by severe
motion-induced phase artifacts from respiration, peristalsis, and so on,
compounded by multi-organ, multi-slice, multi-direction and multi-b-value
complexities. Here, we introduce a reconstruction framework, LoSP-Prompt, that
overcomes these challenges through physics-informed modeling and
synthetic-data-driven prompt learning. We model inter-shot phase variations as
a high-order Locally Smooth Phase (LoSP), integrated into a low-rank Hankel
matrix reconstruction. Crucially, the algorithm's rank parameter is
automatically set via prompt learning trained exclusively on synthetic
abdominal DWI data emulating physiological motion. Validated across 10,000+
clinical images (43 subjects, 4 scanner models, 5 centers), LoSP-Prompt: (1)
Achieved twice the spatial resolution of clinical single-shot DWI, enhancing
liver lesion conspicuity; (2) Generalized to seven diverse anatomical regions
(liver, kidney, sacroiliac, pelvis, knee, spinal cord, brain) with a single
model; (3) Outperformed state-of-the-art methods in image quality, artifact
suppression, and noise reduction (11 radiologists' evaluations on a 5-point
scale, $p<0.05$), achieving 4-5 points (excellent) on kidney DWI, 4 points
(good to excellent) on liver, sacroiliac and spinal cord DWI, and 3-4 points
(good) on knee and tumor brain. The approach eliminates navigator signals and
realistic data supervision, providing an interpretable, robust solution for
high-resolution multi-organ multi-shot DWI. Its scanner-agnostic performance
signifies transformative potential for precision oncology.

</details>


### [42] [Learning to Detect Unknown Jailbreak Attacks in Large Vision-Language Models](https://arxiv.org/abs/2510.15430)
*Shuang Liang,Zhihao Xu,Jialing Tao,Hui Xue,Xiting Wang*

Main category: cs.CV

TL;DR: LoD框架通过任务特定学习和多模态模块，有效检测未知越狱攻击，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法要么依赖攻击特定参数（泛化性差），要么基于启发式原则（精度和效率有限），无法有效应对未知越狱攻击。

Method: 提出Learning to Detect (LoD)框架，包括多模态安全概念激活向量模块（用于安全导向表示学习）和安全模式自动编码器模块（用于无监督攻击分类）。

Result: 实验表明，LoD在多种未知攻击上实现了更高的检测AUROC，并提升了效率。

Conclusion: LoD框架通过任务特定学习而非攻击特定学习，有效检测未知越狱攻击，提高了检测的准确性和效率。

Abstract: Despite extensive alignment efforts, Large Vision-Language Models (LVLMs)
remain vulnerable to jailbreak attacks, posing serious safety risks. To address
this, existing detection methods either learn attack-specific parameters, which
hinders generalization to unseen attacks, or rely on heuristically sound
principles, which limit accuracy and efficiency. To overcome these limitations,
we propose Learning to Detect (LoD), a general framework that accurately
detects unknown jailbreak attacks by shifting the focus from attack-specific
learning to task-specific learning. This framework includes a Multi-modal
Safety Concept Activation Vector module for safety-oriented representation
learning and a Safety Pattern Auto-Encoder module for unsupervised attack
classification. Extensive experiments show that our method achieves
consistently higher detection AUROC on diverse unknown attacks while improving
efficiency. The code is available at
https://anonymous.4open.science/r/Learning-to-Detect-51CB.

</details>


### [43] [Semantic4Safety: Causal Insights from Zero-shot Street View Imagery Segmentation for Urban Road Safety](https://arxiv.org/abs/2510.15434)
*Huan Chen,Ting Han,Siyu Chen,Zhihao Guo,Yiping Chen,Meiliu Wu*

Main category: cs.CV

TL;DR: Semantic4Safety框架通过零样本语义分割和因果分析，量化街景特征对交通事故的影响，为城市安全规划提供数据支持。


<details>
  <summary>Details</summary>
Motivation: 解决两个基本挑战：(1)如何构建捕捉事故相关特征的街道级指标，(2)如何量化它们在不同事故类型中的因果影响。

Method: 使用零样本语义分割从街景图像中提取11个可解释的街道景观指标，结合道路类型作为上下文信息，训练XGBoost多类分类器，并应用SHAP解释特征贡献，最后通过GPS加权和ATE估计控制混杂因素并量化因果效应。

Result: 揭示了事故类型特定的因果模式：场景复杂性、暴露度和道路几何特征主导预测能力；更大的可驾驶区域和紧急空间降低风险，而过度视觉开放性可能增加风险。

Conclusion: Semantic4Safety通过结合预测建模与因果推断，为城市道路安全规划提供了一个可扩展的数据驱动工具，支持针对性干预和高风险走廊诊断。

Abstract: Street-view imagery (SVI) offers a fine-grained lens on traffic risk, yet two
fundamental challenges persist: (1) how to construct street-level indicators
that capture accident-related features, and (2) how to quantify their causal
impacts across different accident types. To address these challenges, we
propose Semantic4Safety, a framework that applies zero-shot semantic
segmentation to SVIs to derive 11 interpretable streetscape indicators, and
integrates road type as contextual information to analyze approximately 30,000
accident records in Austin. Specifically, we train an eXtreme Gradient Boosting
(XGBoost) multi-class classifier and use Shapley Additive Explanations (SHAP)
to interpret both global and local feature contributions, and then apply
Generalized Propensity Score (GPS) weighting and Average Treatment Effect (ATE)
estimation to control confounding and quantify causal effects. Results uncover
heterogeneous, accident-type-specific causal patterns: features capturing scene
complexity, exposure, and roadway geometry dominate predictive power; larger
drivable area and emergency space reduce risk, whereas excessive visual
openness can increase it. By bridging predictive modeling with causal
inference, Semantic4Safety supports targeted interventions and high-risk
corridor diagnosis, offering a scalable, data-informed tool for urban road
safety planning.

</details>


### [44] [Rethinking Convergence in Deep Learning: The Predictive-Corrective Paradigm for Anatomy-Informed Brain MRI Segmentation](https://arxiv.org/abs/2510.15439)
*Feifei Zhang,Zhenhong Jia,Sensen Song,Fei Shi,Dayong Ren*

Main category: cs.CV

TL;DR: PCMambaNet通过预测-校正范式加速学习，减少数据依赖，在医学影像中实现高效精准分割。


<details>
  <summary>Details</summary>
Motivation: 解决端到端深度学习在数据稀缺领域收敛慢、依赖大规模数据集的问题。

Method: PCMambaNet由预测先验模块（PPM）和校正残差网络（CRN）组成，PPM利用解剖学知识生成粗略近似，CRN专注于残差误差建模。

Result: PCMambaNet在高分辨率脑MRI分割中达到最先进精度，仅需1-5个epoch即可收敛。

Conclusion: PCMambaNet通过预测-校正范式显著加速学习，减少对大规模数据集的依赖，在数据稀缺领域（如医学影像）表现出色。

Abstract: Despite the remarkable success of the end-to-end paradigm in deep learning,
it often suffers from slow convergence and heavy reliance on large-scale
datasets, which fundamentally limits its efficiency and applicability in
data-scarce domains such as medical imaging. In this work, we introduce the
Predictive-Corrective (PC) paradigm, a framework that decouples the modeling
task to fundamentally accelerate learning. Building upon this paradigm, we
propose a novel network, termed PCMambaNet. PCMambaNet is composed of two
synergistic modules. First, the Predictive Prior Module (PPM) generates a
coarse approximation at low computational cost, thereby anchoring the search
space. Specifically, the PPM leverages anatomical knowledge-bilateral
symmetry-to predict a 'focus map' of diagnostically relevant asymmetric
regions. Next, the Corrective Residual Network (CRN) learns to model the
residual error, focusing the network's full capacity on refining these
challenging regions and delineating precise pathological boundaries. Extensive
experiments on high-resolution brain MRI segmentation demonstrate that
PCMambaNet achieves state-of-the-art accuracy while converging within only 1-5
epochs-a performance unattainable by conventional end-to-end models. This
dramatic acceleration highlights that by explicitly incorporating domain
knowledge to simplify the learning objective, PCMambaNet effectively mitigates
data inefficiency and overfitting.

</details>


### [45] [Select Less, Reason More: Prioritizing Evidence Purity for Video Reasoning](https://arxiv.org/abs/2510.15440)
*Xuchen Li,Xuzhao Li,Shiyu Hu,Kaiqi Huang*

Main category: cs.CV

TL;DR: 提出证据优先自适应框架（EARL），通过动态帧选择和局部重采样提升视频推理性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频推理代理因缺乏严格奖励机制导致的证据纯度不足及无法在预采样帧之外补充时间信息的问题。

Method: 通过证据感知强化学习（EARL）框架，动态选择最相关帧并进行局部重采样，以获取细粒度时间细节。

Result: 7B模型在LongVideoBench、MVBench和VideoMME上分别达到59.8%、69.0%和64.9%的准确率。

Conclusion: 提出的证据优先自适应框架（EARL）在长视频推理任务中表现卓越，显著提升了视频大型语言模型（Video LLMs）的性能，并在多个基准测试中达到新的最先进水平。

Abstract: Long-form video reasoning remains a major challenge for Video Large Language
Models (Video LLMs), as static uniform frame sampling leads to information
dilution and obscures critical evidence. Furthermore, existing pixel-space
video reasoning agents, which are designed to actively interact with the video
to acquire new visual information, remain suboptimal due to their lack of
rigorous reward mechanisms to enforce evidence purity and their inability to
perform temporal information supplementation beyond pre-sampled frames. To
address this critical gap, we propose a novel evidence-prioritized adaptive
framework built upon our core philosophy: "Select Less, Reason More." Our core
contribution is the evidence-aware reinforcement learning (EARL) framework,
which transforms the model into an active interrogator of evidence. EARL is
precisely engineered to dynamically select the most relevant frames and,
crucially, to perform localized re-sampling around the selected key frames to
access fine-grained temporal detail. Extensive experiments on five demanding
video reasoning benchmarks demonstrate that our EARL-trained model achieves new
state-of-the-art among open-source Video LLMs, simultaneously learning an
effective and high-purity visual evidence selection policy. Impressively, our
7B model achieves 59.8% on LongVideoBench, 69.0% on MVBench and 64.9% on
VideoMME. These results highlight the importance of prioritizing evidence
purity and the effectiveness of our framework.

</details>


### [46] [MAVR-Net: Robust Multi-View Learning for MAV Action Recognition with Cross-View Attention](https://arxiv.org/abs/2510.15448)
*Nengbo Zhang,Hann Woei Ho*

Main category: cs.CV

TL;DR: MAVR-Net利用多视角数据（RGB、光流、分割掩码）和交叉注意力模块，显著提升MAV动作识别准确率，最高达97.8%。


<details>
  <summary>Details</summary>
Motivation: 传统基于RGB的视觉识别方法难以捕捉MAV运动的复杂时空特征，限制了动作识别的准确性。

Method: 提出MAVR-Net框架，结合RGB帧、光流和分割掩码三种数据，采用ResNet编码器和多尺度特征金字塔提取特征，并引入交叉视角注意力模块和多视角对齐损失。

Result: 在Short MAV、Medium MAV和Long MAV数据集上分别达到97.8%、96.5%和92.8%的准确率。

Conclusion: MAVR-Net通过多视角学习和交叉注意力模块显著提升了微型飞行器（MAV）动作识别的准确性和鲁棒性，在多个基准数据集上表现优于现有方法。

Abstract: Recognizing the motion of Micro Aerial Vehicles (MAVs) is crucial for
enabling cooperative perception and control in autonomous aerial swarms. Yet,
vision-based recognition models relying only on RGB data often fail to capture
the complex spatial temporal characteristics of MAV motion, which limits their
ability to distinguish different actions. To overcome this problem, this paper
presents MAVR-Net, a multi-view learning-based MAV action recognition
framework. Unlike traditional single-view methods, the proposed approach
combines three complementary types of data, including raw RGB frames, optical
flow, and segmentation masks, to improve the robustness and accuracy of MAV
motion recognition. Specifically, ResNet-based encoders are used to extract
discriminative features from each view, and a multi-scale feature pyramid is
adopted to preserve the spatiotemporal details of MAV motion patterns. To
enhance the interaction between different views, a cross-view attention module
is introduced to model the dependencies among various modalities and feature
scales. In addition, a multi-view alignment loss is designed to ensure semantic
consistency and strengthen cross-view feature representations. Experimental
results on benchmark MAV action datasets show that our method clearly
outperforms existing approaches, achieving 97.8\%, 96.5\%, and 92.8\% accuracy
on the Short MAV, Medium MAV, and Long MAV datasets, respectively.

</details>


### [47] [DPTrack:Directional Kernel-Guided Prompt Learning for Robust Nighttime Aerial Tracking](https://arxiv.org/abs/2510.15449)
*Zhiqiang Zhu,Xinbo Gao,Wen Lu,Jie Li,Zhaoyang Wang,Mingqian Ge*

Main category: cs.CV

TL;DR: DPTrack通过方向核编码目标属性特征，结合拓扑结构和核引导提示模块，显著提升夜间空中跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示学习的夜间空中跟踪器仅依赖空间定位监督，缺乏细粒度线索，导致提示模糊，跟踪性能不佳。

Method: DPTrack首先分层捕获目标的拓扑结构，利用拓扑属性丰富特征表示；随后通过编码器将这些拓扑感知特征压缩到方向核中；最后通过基于通道类别对应属性的核引导提示模块，在搜索区域特征中传播核以精确定位目标特征并转换为精确提示。

Result: 在多个基准测试上的广泛评估表明，DPTrack表现出卓越的性能。

Conclusion: DPTrack通过编码目标属性特征到方向核中，结合细粒度线索生成精确提示，显著提升了夜间空中跟踪性能。

Abstract: Existing nighttime aerial trackers based on prompt learning rely solely on
spatial localization supervision, which fails to provide fine-grained cues that
point to target features and inevitably produces vague prompts. This limitation
impairs the tracker's ability to accurately focus on the object features and
results in trackers still performing poorly. To address this issue, we propose
DPTrack, a prompt-based aerial tracker designed for nighttime scenarios by
encoding the given object's attribute features into the directional kernel
enriched with fine-grained cues to generate precise prompts. Specifically,
drawing inspiration from visual bionics, DPTrack first hierarchically captures
the object's topological structure, leveraging topological attributes to enrich
the feature representation. Subsequently, an encoder condenses these
topology-aware features into the directional kernel, which serves as the core
guidance signal that explicitly encapsulates the object's fine-grained
attribute cues. Finally, a kernel-guided prompt module built on
channel-category correspondence attributes propagates the kernel across the
features of the search region to pinpoint the positions of target features and
convert them into precise prompts, integrating spatial gating for robust
nighttime tracking. Extensive evaluations on established benchmarks demonstrate
DPTrack's superior performance. Our code will be available at
https://github.com/zzq-vipsl/DPTrack.

</details>


### [48] [Improving Micro-Expression Recognition with Phase-Aware Temporal Augmentation](https://arxiv.org/abs/2510.15466)
*Vu Tram Anh Khuong,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: 本文提出了一种基于双相位动态图像的时间增强方法，显著提升了微表情识别的性能，尤其在低资源环境下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有微表情识别（MER）研究主要依赖简单的空间增强方法，忽视了时间增强策略，而后者能更好地利用运动特征。数据稀缺问题限制了模型的泛化能力和运动模式的多样性。

Method: 通过将微表情序列分解为两个运动相位（onset-to-apex 和 apex-to-offset），并分别为每个相位生成动态图像（DI），形成双相位DI增强策略。

Result: 在CASME-II和SAMM数据集上的实验表明，该方法结合空间增强后，识别准确率、未加权F1分数和未加权平均召回率均有显著提升，最高相对提升达10%。

Conclusion: 本文提出的双相位动态图像增强方法在微表情识别任务中显著提升了性能，尤其在低资源环境下表现出色，为未来研究提供了一个简单且模型无关的增强策略。

Abstract: Micro-expressions (MEs) are brief, involuntary facial movements that reveal
genuine emotions, typically lasting less than half a second. Recognizing these
subtle expressions is critical for applications in psychology, security, and
behavioral analysis. Although deep learning has enabled significant advances in
micro-expression recognition (MER), its effectiveness is limited by the
scarcity of annotated ME datasets. This data limitation not only hinders
generalization but also restricts the diversity of motion patterns captured
during training. Existing MER studies predominantly rely on simple spatial
augmentations (e.g., flipping, rotation) and overlook temporal augmentation
strategies that can better exploit motion characteristics. To address this gap,
this paper proposes a phase-aware temporal augmentation method based on dynamic
image. Rather than encoding the entire expression as a single onset-to-offset
dynamic image (DI), our approach decomposes each expression sequence into two
motion phases: onset-to-apex and apex-to-offset. A separate DI is generated for
each phase, forming a Dual-phase DI augmentation strategy. These phase-specific
representations enrich motion diversity and introduce complementary temporal
cues that are crucial for recognizing subtle facial transitions. Extensive
experiments on CASME-II and SAMM datasets using six deep architectures,
including CNNs, Vision Transformer, and the lightweight LEARNet, demonstrate
consistent performance improvements in recognition accuracy, unweighted
F1-score, and unweighted average recall, which are crucial for addressing class
imbalance in MER. When combined with spatial augmentations, our method achieves
up to a 10\% relative improvement. The proposed augmentation is simple,
model-agnostic, and effective in low-resource settings, offering a promising
direction for robust and generalizable MER.

</details>


### [49] [MRASfM: Multi-Camera Reconstruction and Aggregation through Structure-from-Motion in Driving Scenes](https://arxiv.org/abs/2510.15467)
*Lingfeng Xuan,Chang Nie,Yiqing Xu,Zhe Liu,Yanzi Miao,Hesheng Wang*

Main category: cs.CV

TL;DR: MRASfM框架针对驾驶场景的多相机SfM问题，通过固定空间关系、平面模型和优化方法，提升了姿态估计和路面重建的质量与效率。


<details>
  <summary>Details</summary>
Motivation: 多相机系统在驾驶场景中应用SfM时存在姿态估计不可靠、路面重建异常点多和效率低下的问题。

Method: MRASfM框架利用多相机系统的固定空间关系增强相机姿态估计，采用平面模型去除路面重建中的错误点，并通过捆绑调整减少优化变量。

Result: MRASfM在nuScenes数据集上实现了0.124的绝对姿态误差，展现了先进的性能。

Conclusion: MRASfM框架在驾驶场景中表现出色，通过多相机系统的固定空间关系、平面模型和捆绑调整优化，显著提高了相机姿态估计的可靠性和路面重建质量，同时提升了效率。

Abstract: Structure from Motion (SfM) estimates camera poses and reconstructs point
clouds, forming a foundation for various tasks. However, applying SfM to
driving scenes captured by multi-camera systems presents significant
difficulties, including unreliable pose estimation, excessive outliers in road
surface reconstruction, and low reconstruction efficiency. To address these
limitations, we propose a Multi-camera Reconstruction and Aggregation
Structure-from-Motion (MRASfM) framework specifically designed for driving
scenes. MRASfM enhances the reliability of camera pose estimation by leveraging
the fixed spatial relationships within the multi-camera system during the
registration process. To improve the quality of road surface reconstruction,
our framework employs a plane model to effectively remove erroneous points from
the triangulated road surface. Moreover, treating the multi-camera set as a
single unit in Bundle Adjustment (BA) helps reduce optimization variables to
boost efficiency. In addition, MRASfM achieves multi-scene aggregation through
scene association and assembly modules in a coarse-to-fine fashion. We deployed
multi-camera systems on actual vehicles to validate the generalizability of
MRASfM across various scenes and its robustness in challenging conditions
through real-world applications. Furthermore, large-scale validation results on
public datasets show the state-of-the-art performance of MRASfM, achieving
0.124 absolute pose error on the nuScenes dataset.

</details>


### [50] [MSAM: Multi-Semantic Adaptive Mining for Cross-Modal Drone Video-Text Retrieval](https://arxiv.org/abs/2510.15470)
*Jinghao Huang,Yaxiong Chen,Ganchao Liu*

Main category: cs.CV

TL;DR: 提出MSAM方法，针对无人机视频-文本检索任务，通过多语义自适应学习和跨模态交互特征融合，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 无人机视频具有独特的视角和语义表达，现有跨模态方法难以有效建模，因此需要专门针对无人机场景的检索机制。

Method: 提出了一种名为多语义自适应挖掘（MSAM）的新方法，包括多语义自适应学习机制、跨模态交互特征融合池化机制等。

Result: 在自建的两个无人机视频-文本数据集上的大量实验表明，MSAM优于现有方法。

Conclusion: MSAM方法在无人机视频-文本检索任务中表现出色，显著优于现有方法，并公开了源代码和数据集。

Abstract: With the advancement of drone technology, the volume of video data increases
rapidly, creating an urgent need for efficient semantic retrieval. We are the
first to systematically propose and study the drone video-text retrieval (DVTR)
task. Drone videos feature overhead perspectives, strong structural
homogeneity, and diverse semantic expressions of target combinations, which
challenge existing cross-modal methods designed for ground-level views in
effectively modeling their characteristics. Therefore, dedicated retrieval
mechanisms tailored for drone scenarios are necessary. To address this issue,
we propose a novel approach called Multi-Semantic Adaptive Mining (MSAM). MSAM
introduces a multi-semantic adaptive learning mechanism, which incorporates
dynamic changes between frames and extracts rich semantic information from
specific scene regions, thereby enhancing the deep understanding and reasoning
of drone video content. This method relies on fine-grained interactions between
words and drone video frames, integrating an adaptive semantic construction
module, a distribution-driven semantic learning term and a diversity semantic
term to deepen the interaction between text and drone video modalities and
improve the robustness of feature representation. To reduce the interference of
complex backgrounds in drone videos, we introduce a cross-modal interactive
feature fusion pooling mechanism that focuses on feature extraction and
matching in target regions, minimizing noise effects. Extensive experiments on
two self-constructed drone video-text datasets show that MSAM outperforms other
existing methods in the drone video-text retrieval task. The source code and
dataset will be made publicly available.

</details>


### [51] [A Novel Combined Optical Flow Approach for Comprehensive Micro-Expression Recognition](https://arxiv.org/abs/2510.15471)
*Vu Tram Anh Khuong,Thi Bich Phuong Man,Luu Tu Nguyen,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

TL;DR: COF方法通过整合两个阶段的光流特征，提升了微表情识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的微表情识别方法主要关注onset-to-apex阶段，忽略了apex-to-offset阶段的关键时间动态信息。

Method: 本研究提出了一种Combined Optical Flow (COF)方法，整合了onset-to-apex和apex-to-offset两个阶段的光流特征。

Result: 在CASMEII和SAMM数据集上的实验结果表明，COF方法优于单一光流方法。

Conclusion: COF方法通过整合onset-to-apex和apex-to-offset两个阶段的光流特征，显著提升了微表情识别的性能。

Abstract: Facial micro-expressions are brief, involuntary facial movements that reveal
hidden emotions. Most Micro-Expression Recognition (MER) methods that rely on
optical flow typically focus on the onset-to-apex phase, neglecting the
apex-to-offset phase, which holds key temporal dynamics. This study introduces
a Combined Optical Flow (COF), integrating both phases to enhance feature
representation. COF provides a more comprehensive motion analysis, improving
MER performance. Experimental results on CASMEII and SAMM datasets show that
COF outperforms single optical flow-based methods, demonstrating its
effectiveness in capturing micro-expression dynamics.

</details>


### [52] [Iterative Motion Compensation for Canonical 3D Reconstruction from UAV Plant Images Captured in Windy Conditions](https://arxiv.org/abs/2510.15491)
*Andre Rochow,Jonas Marcic,Svetlana Seliunina,Sven Behnke*

Main category: cs.CV

TL;DR: 该研究开发了一种自主无人机图像采集和迭代3D重建管道，显著提升了农业植物3D模型的质量，并公开了源代码和数据集。


<details>
  <summary>Details</summary>
Motivation: 3D植物表型分析对理解植物生长、产量预测和疾病控制至关重要，但现有方法在环境风力和无人机下洗气流影响下面临挑战。

Method: 使用小型商用无人机自主采集植物图像，结合迭代方法通过变形调整输入图像以减轻叶片运动的影响，并利用光流估计运动。

Result: 提出的管道能够逐步减少场景运动，生成规范表示，并显著提升现有最先进方法的3D重建质量。

Conclusion: 该研究提出了一种改进的3D重建管道，能够生成高质量的农业植物3D模型，并通过公开源代码和数据集促进相关研究的发展。

Abstract: 3D phenotyping of plants plays a crucial role for understanding plant growth,
yield prediction, and disease control. We present a pipeline capable of
generating high-quality 3D reconstructions of individual agricultural plants.
To acquire data, a small commercially available UAV captures images of a
selected plant. Apart from placing ArUco markers, the entire image acquisition
process is fully autonomous, controlled by a self-developed Android application
running on the drone's controller. The reconstruction task is particularly
challenging due to environmental wind and downwash of the UAV. Our proposed
pipeline supports the integration of arbitrary state-of-the-art 3D
reconstruction methods. To mitigate errors caused by leaf motion during image
capture, we use an iterative method that gradually adjusts the input images
through deformation. Motion is estimated using optical flow between the
original input images and intermediate 3D reconstructions rendered from the
corresponding viewpoints. This alignment gradually reduces scene motion,
resulting in a canonical representation. After a few iterations, our pipeline
improves the reconstruction of state-of-the-art methods and enables the
extraction of high-resolution 3D meshes. We will publicly release the source
code of our reconstruction pipeline. Additionally, we provide a dataset
consisting of multiple plants from various crops, captured across different
points in time.

</details>


### [53] [Rethinking Efficient Hierarchical Mixing Architecture for Low-light RAW Image Enhancement](https://arxiv.org/abs/2510.15497)
*Xianmin Chen,Peiliang Huang,Longfei Han,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: HiMA结合Transformer和Mamba模块，通过LoDA和MPF提升低光RAW图像增强的质量和效率，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 低光RAW图像增强在质量和效率上仍存在挑战，现有方法难以兼顾两者。本文旨在设计一个高效且高质量的增强架构。

Method: HiMA架构利用Transformer处理大尺度特征，Mamba处理小尺度特征，结合LoDA模块调整局部特征分布，MPF模块融合空间和频域先验进行细节增强。

Result: 在多个公开数据集上的实验表明，HiMA在性能和参数效率上均优于现有方法。

Conclusion: 本文提出的HiMA架构通过结合Transformer和Mamba模块的优势，以及LoDA和MPF模块的设计，显著提升了低光RAW图像增强的质量和效率。

Abstract: Low-light RAW image enhancement remains a challenging task. Although numerous
deep learning based approaches have been proposed, they still suffer from
inherent limitations. A key challenge is how to simultaneously achieve strong
enhancement quality and high efficiency. In this paper, we rethink the
architecture for efficient low-light image signal processing (ISP) and
introduce a Hierarchical Mixing Architecture (HiMA). HiMA leverages the
complementary strengths of Transformer and Mamba modules to handle features at
large and small scales, respectively, thereby improving efficiency while
avoiding the ambiguities observed in prior two-stage frameworks. To further
address uneven illumination with strong local variations, we propose Local
Distribution Adjustment (LoDA), which adaptively aligns feature distributions
across different local regions. In addition, to fully exploit the denoised
outputs from the first stage, we design a Multi-prior Fusion (MPF) module that
integrates spatial and frequency-domain priors for detail enhancement.
Extensive experiments on multiple public datasets demonstrate that our method
outperforms state-of-the-art approaches, achieving superior performance with
fewer parameters. Code will be released at https://github.com/Cynicarlos/HiMA.

</details>


### [54] [ClapperText: A Benchmark for Text Recognition in Low-Resource Archival Documents](https://arxiv.org/abs/2510.15557)
*Tingyu Lin,Marco Peer,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: ClapperText是一个用于手写和打印文本识别的数据集，源自二战档案视频，支持少样本学习，适用于低资源环境。


<details>
  <summary>Details</summary>
Motivation: 解决历史文档分析中因视觉退化和非标准形式导致的文本识别挑战，如运动模糊、手写变异等。

Method: 从127个二战时期的档案视频片段中提取数据，包含9,813个标注帧和94,573个单词级文本实例，提供旋转边界框标注和裁剪单词图像。

Result: 在零样本和微调条件下，对六种识别和七种检测模型进行基准测试，微调带来显著性能提升。

Conclusion: ClapperText数据集为低资源档案环境中的鲁棒OCR和文档理解提供了一个现实且文化背景丰富的资源，支持少样本学习场景。

Abstract: This paper presents ClapperText, a benchmark dataset for handwritten and
printed text recognition in visually degraded and low-resource settings. The
dataset is derived from 127 World War II-era archival video segments containing
clapperboards that record structured production metadata such as date,
location, and camera-operator identity. ClapperText includes 9,813 annotated
frames and 94,573 word-level text instances, 67% of which are handwritten and
1,566 are partially occluded. Each instance includes transcription, semantic
category, text type, and occlusion status, with annotations available as
rotated bounding boxes represented as 4-point polygons to support spatially
precise OCR applications. Recognizing clapperboard text poses significant
challenges, including motion blur, handwriting variation, exposure
fluctuations, and cluttered backgrounds, mirroring broader challenges in
historical document analysis where structured content appears in degraded,
non-standard forms. We provide both full-frame annotations and cropped word
images to support downstream tasks. Using a consistent per-video evaluation
protocol, we benchmark six representative recognition and seven detection
models under zero-shot and fine-tuned conditions. Despite the small training
set (18 videos), fine-tuning leads to substantial performance gains,
highlighting ClapperText's suitability for few-shot learning scenarios. The
dataset offers a realistic and culturally grounded resource for advancing
robust OCR and document understanding in low-resource archival contexts. The
dataset and evaluation code are available at
https://github.com/linty5/ClapperText.

</details>


### [55] [Lightweight CycleGAN Models for Cross-Modality Image Transformation and Experimental Quality Assessment in Fluorescence Microscopy](https://arxiv.org/abs/2510.15579)
*Mohammad Soltaninezhad,Yashar Rouzbahani,Jhonatan Contreras,Rohan Chippalkatti,Daniel Kwaku Abankwa,Christian Eggeling,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 轻量化CycleGAN用于荧光显微镜模态转换，减少参数和计算成本，同时作为诊断工具检测图像质量问题。


<details>
  <summary>Details</summary>
Motivation: 解决荧光显微镜中模态转换的常见挑战（未配对数据集），并减少计算成本和环境影响。此外，通过GAN作为诊断工具，提升实验和标记质量。

Method: 采用轻量化的CycleGAN架构，通过固定通道策略替代传统的通道加倍方法，显著减少了可训练参数（从41.8百万降至约九千）。同时，模型被设计为诊断工具，用于检测图像质量问题。

Result: 模型在减少可训练参数的同时，实现了更快的训练速度和更低的内存使用，且性能优于传统方法。GAN作为诊断工具，能够有效检测图像质量问题（如光漂白、伪影或标记不准确）。

Conclusion: 该论文提出了一种轻量化的CycleGAN模型，用于荧光显微镜中的模态转换，显著减少了计算成本和环境影响。模型通过固定通道策略减少了可训练参数，同时保持了优越性能。此外，GAN被引入作为诊断工具，用于检测实验和标记质量，进一步验证了模型的实用性。

Abstract: Lightweight deep learning models offer substantial reductions in
computational cost and environmental impact, making them crucial for scientific
applications. We present a lightweight CycleGAN for modality transfer in
fluorescence microscopy (confocal to super-resolution STED/deconvolved STED),
addressing the common challenge of unpaired datasets. By replacing the
traditional channel-doubling strategy in the U-Net-based generator with a fixed
channel approach, we drastically reduce trainable parameters from 41.8 million
to approximately nine thousand, achieving superior performance with faster
training and lower memory usage. We also introduce the GAN as a diagnostic tool
for experimental and labeling quality. When trained on high-quality images, the
GAN learns the characteristics of optimal imaging; deviations between its
generated outputs and new experimental images can reveal issues such as
photobleaching, artifacts, or inaccurate labeling. This establishes the model
as a practical tool for validating experimental accuracy and image fidelity in
microscopy workflows.

</details>


### [56] [Latent Feature Alignment: Discovering Biased and Interpretable Subpopulations in Face Recognition Models](https://arxiv.org/abs/2510.15520)
*Ignacio Serna*

Main category: cs.CV

TL;DR: LFA是一种无需预定义属性标注的算法，能有效识别人脸识别模型中的偏差子群体，并在语义一致性和可解释性上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现代人脸识别模型虽整体准确率高，但仍存在系统性偏差，传统依赖标记属性的偏差评估框架成本高且受限于预定义类别。

Method: 引入Latent Feature Alignment（LFA）算法，利用潜在方向识别子群体，相比传统聚类方法（如k-means和最近邻搜索）在语义一致性上表现更优。

Result: 在四种最先进的人脸识别模型（ArcFace、CosFace、ElasticFace、PartialFC）和两个基准测试（RFW、CelebA）上，LFA在组内语义一致性和可解释潜在方向的发现上均优于传统方法。

Conclusion: LFA作为一种无需预定义属性标注的算法，能够有效识别和解释人脸识别模型中的偏差子群体，为模型的表示审计提供了实用方法。

Abstract: Modern face recognition models achieve high overall accuracy but continue to
exhibit systematic biases that disproportionately affect certain
subpopulations. Conventional bias evaluation frameworks rely on labeled
attributes to form subpopulations, which are expensive to obtain and limited to
predefined categories. We introduce Latent Feature Alignment (LFA), an
attribute-label-free algorithm that uses latent directions to identify
subpopulations. This yields two main benefits over standard clustering: (i)
semantically coherent grouping, where faces sharing common attributes are
grouped together more reliably than by proximity-based methods, and (ii)
discovery of interpretable directions, which correspond to semantic attributes
such as age, ethnicity, or attire. Across four state-of-the-art recognition
models (ArcFace, CosFace, ElasticFace, PartialFC) and two benchmarks (RFW,
CelebA), LFA consistently outperforms k-means and nearest-neighbor search in
intra-group semantic coherence, while uncovering interpretable latent
directions aligned with demographic and contextual attributes. These results
position LFA as a practical method for representation auditing of face
recognition models, enabling practitioners to identify and interpret biased
subpopulations without predefined attribute annotations.

</details>


### [57] [Valeo Near-Field: a novel dataset for pedestrian intent detection](https://arxiv.org/abs/2510.15673)
*Antonyo Musabini,Rachid Benmokhtar,Jagdish Bhanushali,Victor Galizzi,Bertrand Luvison,Xavier Perrotton*

Main category: cs.CV

TL;DR: 本文介绍了一个用于检测行人意图的多模态数据集，包含详细标注和基准测试套件，旨在推动智能车辆的近场场景研究。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中的挑战（如传感器遮挡、动态环境和硬件限制），为行人检测和意图预测算法提供可靠的基准测试资源。

Method: 通过收集多模态数据（如鱼眼相机、激光雷达、超声波传感器和运动捕捉的3D身体姿态），并同步标注3D身体关节位置和行人位置，构建了一个全面的数据集。

Result: 发布了部分数据集和基准测试套件，提供了精度、效率和可扩展性评估指标，并展示了自定义神经网络架构的基线性能。

Conclusion: 本文旨在为研究人员提供一个基础数据集，以推动智能车辆在近场场景中的能力提升，包括行人检测、3D姿态估计及4D轨迹和意图预测。

Abstract: This paper presents a novel dataset aimed at detecting pedestrians'
intentions as they approach an ego-vehicle. The dataset comprises synchronized
multi-modal data, including fisheye camera feeds, lidar laser scans, ultrasonic
sensor readings, and motion capture-based 3D body poses, collected across
diverse real-world scenarios. Key contributions include detailed annotations of
3D body joint positions synchronized with fisheye camera images, as well as
accurate 3D pedestrian positions extracted from lidar data, facilitating robust
benchmarking for perception algorithms. We release a portion of the dataset
along with a comprehensive benchmark suite, featuring evaluation metrics for
accuracy, efficiency, and scalability on embedded systems. By addressing
real-world challenges such as sensor occlusions, dynamic environments, and
hardware constraints, this dataset offers a unique resource for developing and
evaluating state-of-the-art algorithms in pedestrian detection, 3D pose
estimation and 4D trajectory and intention prediction. Additionally, we provide
baseline performance metrics using custom neural network architectures and
suggest future research directions to encourage the adoption and enhancement of
the dataset. This work aims to serve as a foundation for researchers seeking to
advance the capabilities of intelligent vehicles in near-field scenarios.

</details>


### [58] [Balanced Multi-Task Attention for Satellite Image Classification: A Systematic Approach to Achieving 97.23% Accuracy on EuroSAT Without Pre-Training](https://arxiv.org/abs/2510.15527)
*Aditya Vir*

Main category: cs.CV

TL;DR: 本文提出一种平衡多任务注意力机制的自定义CNN架构，用于卫星土地利用分类，在EuroSAT上达到97.23%准确率，无需预训练模型，验证了空间与光谱特征均衡提取的重要性。


<details>
  <summary>Details</summary>
Motivation: 卫星图像分类任务中，现有方法常依赖预训练模型或忽视空间与光谱特征的均衡利用。本文旨在通过系统设计自定义架构，解决特定失败模式，并验证域特定应用中系统架构设计的有效性。

Method: 研究通过三个逐步优化的架构迭代（基线：94.30%，CBAM增强：95.98%，平衡多任务注意力：97.23%）改进卫星图像分类。主要贡献是结合坐标注意力（空间特征提取）和挤压激励块（光谱特征提取）的平衡多任务注意力机制，并通过可学习融合参数统一。此外，采用渐进DropBlock正则化（5-20%）和类平衡损失加权。

Result: 最终12层架构在EuroSAT数据集上达到97.23%的测试准确率和Cohen's Kappa 0.9692，所有类别准确率超过94.46%。可学习融合参数自主收敛至α≈0.57，表明空间和光谱模态的近均衡重要性。性能接近微调ResNet-50（98.57%），且无需外部数据。

Conclusion: 本文通过系统设计自定义卷积神经网络架构，提出了一种新颖的平衡多任务注意力机制，成功在卫星土地利用分类任务中达到97.23%的测试准确率，无需依赖预训练模型。实验验证了该机制在空间和光谱特征提取中的均衡重要性，同时通过渐进式DropBlock正则化和类平衡损失加权解决了过拟合和类别不平衡问题。

Abstract: This work presents a systematic investigation of custom convolutional neural
network architectures for satellite land use classification, achieving 97.23%
test accuracy on the EuroSAT dataset without reliance on pre-trained models.
Through three progressive architectural iterations (baseline: 94.30%,
CBAM-enhanced: 95.98%, and balanced multi-task attention: 97.23%) we identify
and address specific failure modes in satellite imagery classification. Our
principal contribution is a novel balanced multi-task attention mechanism that
combines Coordinate Attention for spatial feature extraction with
Squeeze-Excitation blocks for spectral feature extraction, unified through a
learnable fusion parameter. Experimental results demonstrate that this
learnable parameter autonomously converges to alpha approximately 0.57,
indicating near-equal importance of spatial and spectral modalities for
satellite imagery. We employ progressive DropBlock regularization (5-20% by
network depth) and class-balanced loss weighting to address overfitting and
confusion pattern imbalance. The final 12-layer architecture achieves Cohen's
Kappa of 0.9692 with all classes exceeding 94.46% accuracy, demonstrating
confidence calibration with a 24.25% gap between correct and incorrect
predictions. Our approach achieves performance within 1.34% of fine-tuned
ResNet-50 (98.57%) while requiring no external data, validating the efficacy of
systematic architectural design for domain-specific applications. Complete
code, trained models, and evaluation scripts are publicly available.

</details>


### [59] [Towards Label-Free Brain Tumor Segmentation: Unsupervised Learning with Multimodal MRI](https://arxiv.org/abs/2510.15684)
*Gerard Comas-Quiles,Carles Garcia-Cabrera,Julia Dietlmeier,Noel E. O'Connor,Ferran Marques*

Main category: cs.CV

TL;DR: 提出了一种无监督的多模态视觉Transformer自动编码器，用于脑肿瘤分割，无需依赖标注数据，在BraTS-GoAT 2025数据集上取得了临床意义的肿瘤定位效果。


<details>
  <summary>Details</summary>
Motivation: 解决在标注数据集有限、成本高或不一致的情况下，脑肿瘤分割的扩展性问题。

Method: 提出了一种新型多模态视觉Transformer自动编码器（MViT-AE），通过重建误差图检测和定位肿瘤，并引入了多模态早期-晚期融合策略及后处理流程。

Result: 在测试集上，病变级别的Dice相似系数为0.437（全肿瘤）、0.316（肿瘤核心）和0.350（增强肿瘤），验证集上的异常检测率为89.4%。

Conclusion: 基于Transformer的无监督模型在神经肿瘤影像中展现出作为可扩展、标签高效工具的潜力。

Abstract: Unsupervised anomaly detection (UAD) presents a complementary alternative to
supervised learning for brain tumor segmentation in magnetic resonance imaging
(MRI), particularly when annotated datasets are limited, costly, or
inconsistent. In this work, we propose a novel Multimodal Vision Transformer
Autoencoder (MViT-AE) trained exclusively on healthy brain MRIs to detect and
localize tumors via reconstruction-based error maps. This unsupervised paradigm
enables segmentation without reliance on manual labels, addressing a key
scalability bottleneck in neuroimaging workflows. Our method is evaluated in
the BraTS-GoAT 2025 Lighthouse dataset, which includes various types of tumors
such as gliomas, meningiomas, and pediatric brain tumors. To enhance
performance, we introduce a multimodal early-late fusion strategy that
leverages complementary information across multiple MRI sequences, and a
post-processing pipeline that integrates the Segment Anything Model (SAM) to
refine predicted tumor contours. Despite the known challenges of UAD,
particularly in detecting small or non-enhancing lesions, our method achieves
clinically meaningful tumor localization, with lesion-wise Dice Similarity
Coefficient of 0.437 (Whole Tumor), 0.316 (Tumor Core), and 0.350 (Enhancing
Tumor) on the test set, and an anomaly Detection Rate of 89.4% on the
validation set. These findings highlight the potential of transformer-based
unsupervised models to serve as scalable, label-efficient tools for
neuro-oncological imaging.

</details>


### [60] [Diffusion Bridge Networks Simulate Clinical-grade PET from MRI for Dementia Diagnostics](https://arxiv.org/abs/2510.15556)
*Yitong Li,Ralph Buchert,Benita Schmitz-Koep,Timo Grimmer,Björn Ommer,Dennis M. Hedderich,Igor Yakushev,Christian Wachinger*

Main category: cs.CV

TL;DR: SiM2P通过MRI模拟FDG-PET图像，提升痴呆症诊断准确性和可及性。


<details>
  <summary>Details</summary>
Motivation: FDG-PET在痴呆症诊断中具有重要价值，但其可及性和成本较高，限制了广泛应用。

Method: SiM2P是一个基于3D扩散桥的框架，学习从MRI和辅助患者信息到模拟FDG-PET图像的概率映射。

Result: SiM2P将三组患者的诊断准确率从75.0%提高到84.7%，模拟PET图像获得更高的诊断确定性和评分者间一致性。

Conclusion: SiM2P框架通过MRI和辅助患者信息模拟FDG-PET图像，显著提高了诊断准确性，并使FDG-PET的诊断优势在资源有限的环境中更易获得。

Abstract: Positron emission tomography (PET) with 18F-Fluorodeoxyglucose (FDG) is an
established tool in the diagnostic workup of patients with suspected dementing
disorders. However, compared to the routinely available magnetic resonance
imaging (MRI), FDG-PET remains significantly less accessible and substantially
more expensive. Here, we present SiM2P, a 3D diffusion bridge-based framework
that learns a probabilistic mapping from MRI and auxiliary patient information
to simulate FDG-PET images of diagnostic quality. In a blinded clinical reader
study, two neuroradiologists and two nuclear medicine physicians rated the
original MRI and SiM2P-simulated PET images of patients with Alzheimer's
disease, behavioral-variant frontotemporal dementia, and cognitively healthy
controls. SiM2P significantly improved the overall diagnostic accuracy of
differentiating between three groups from 75.0% to 84.7% (p<0.05). Notably, the
simulated PET images received higher diagnostic certainty ratings and achieved
superior interrater agreement compared to the MRI images. Finally, we developed
a practical workflow for local deployment of the SiM2P framework. It requires
as few as 20 site-specific cases and only basic demographic information. This
approach makes the established diagnostic benefits of FDG-PET imaging more
accessible to patients with suspected dementing disorders, potentially
improving early detection and differential diagnosis in resource-limited
settings. Our code is available at https://github.com/Yiiitong/SiM2P.

</details>


### [61] [DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification](https://arxiv.org/abs/2510.15725)
*Tingyu Lin,Armin Dadras,Florian Kleber,Robert Sablatnig*

Main category: cs.CV

TL;DR: DGME-T通过方向网格运动编码提升Video Swin Transformer在档案电影分析中的性能，显著提高了准确率和F1分数。


<details>
  <summary>Details</summary>
Motivation: 解决现代高质量素材训练的相机运动分类模型在应用于噪声、缺失帧和低对比度等问题的档案电影时性能下降的问题。

Method: 引入DGME-T，一种轻量级的Video Swin Transformer扩展，通过可学习和归一化的后期融合层注入方向网格运动编码（源自光流）。

Result: DGME-T将主干的top-1准确率从81.78%提高到86.14%，宏观F1从82.08%提高到87.81%，在二战片段中准确率从83.43%提高到84.62%，宏观F1从81.72%提高到82.63%。

Conclusion: 结构化运动先验和变压器表示是互补的，即使是一个小型、精心校准的运动头也能显著增强在退化电影分析中的鲁棒性。

Abstract: Camera movement classification (CMC) models trained on contemporary,
high-quality footage often degrade when applied to archival film, where noise,
missing frames, and low contrast obscure motion cues. We bridge this gap by
assembling a unified benchmark that consolidates two modern corpora into four
canonical classes and restructures the HISTORIAN collection into five balanced
categories. Building on this benchmark, we introduce DGME-T, a lightweight
extension to the Video Swin Transformer that injects directional grid motion
encoding, derived from optical flow, via a learnable and normalised late-fusion
layer. DGME-T raises the backbone's top-1 accuracy from 81.78% to 86.14% and
its macro F1 from 82.08% to 87.81% on modern clips, while still improving the
demanding World-War-II footage from 83.43% to 84.62% accuracy and from 81.72%
to 82.63% macro F1. A cross-domain study further shows that an intermediate
fine-tuning stage on modern data increases historical performance by more than
five percentage points. These results demonstrate that structured motion priors
and transformer representations are complementary and that even a small,
carefully calibrated motion head can substantially enhance robustness in
degraded film analysis. Related resources are available at
https://github.com/linty5/DGME-T.

</details>


### [62] [NDM: A Noise-driven Detection and Mitigation Framework against Implicit Sexual Intentions in Text-to-Image Generation](https://arxiv.org/abs/2510.15752)
*Yitong Sun,Yao Huang,Ruochen Zhang,Huanran Chen,Shouwei Ruan,Ranjie Duan,Xingxing Wei*

Main category: cs.CV

TL;DR: NDM框架通过噪声检测和自适应负引导机制，有效识别和缓解文本到图像模型中的隐含恶意内容，保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的检测方法主要针对显式不良内容，对隐含恶意意图的识别能力不足，且微调方法可能损害模型的生成质量。

Method: 提出了噪声驱动的检测和缓解框架NDM，包括基于早期噪声的可分离性开发的噪声检测方法，以及噪声增强的自适应负引导机制。

Result: 在自然和对抗数据集上的实验表明，NDM在检测和缓解隐含恶意意图方面优于现有方法。

Conclusion: NDM框架通过噪声驱动的检测和缓解机制，有效解决了文本到图像扩散模型中隐含恶意意图的问题，同时保持了模型的生成能力。

Abstract: Despite the impressive generative capabilities of text-to-image (T2I)
diffusion models, they remain vulnerable to generating inappropriate content,
especially when confronted with implicit sexual prompts. Unlike explicit
harmful prompts, these subtle cues, often disguised as seemingly benign terms,
can unexpectedly trigger sexual content due to underlying model biases, raising
significant ethical concerns. However, existing detection methods are primarily
designed to identify explicit sexual content and therefore struggle to detect
these implicit cues. Fine-tuning approaches, while effective to some extent,
risk degrading the model's generative quality, creating an undesirable
trade-off. To address this, we propose NDM, the first noise-driven detection
and mitigation framework, which could detect and mitigate implicit malicious
intention in T2I generation while preserving the model's original generative
capabilities. Specifically, we introduce two key innovations: first, we
leverage the separability of early-stage predicted noise to develop a
noise-based detection method that could identify malicious content with high
accuracy and efficiency; second, we propose a noise-enhanced adaptive negative
guidance mechanism that could optimize the initial noise by suppressing the
prominent region's attention, thereby enhancing the effectiveness of adaptive
negative guidance for sexual mitigation. Experimentally, we validate NDM on
both natural and adversarial datasets, demonstrating its superior performance
over existing SOTA methods, including SLD, UCE, and RECE, etc. Code and
resources are available at https://github.com/lorraine021/NDM.

</details>


### [63] [Imaginarium: Vision-guided High-Quality 3D Scene Layout Generation](https://arxiv.org/abs/2510.15564)
*Xiaoming Zhu,Xu Huang,Qinghongbing Xie,Zhi Deng,Junsheng Yu,Yirui Guan,Zhongyuan Liu,Lin Zhu,Qijun Zhao,Ligang Liu,Long Zeng*

Main category: cs.CV

TL;DR: 提出视觉引导3D布局生成系统，通过资产库、图像生成与解析模块优化布局，显著提升质量。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法受限于手动规则，深度生成模型难以生成丰富多样的内容，而基于大语言模型的方法缺乏鲁棒性且难以准确捕捉复杂空间关系。

Method: 首先构建高质量资产库，随后利用图像生成模型扩展提示表示并微调以匹配资产库，接着开发图像解析模块恢复3D布局，最后通过场景图和视觉语义优化布局。

Result: 用户测试表明，该方法在布局丰富性和质量上显著优于现有方法。

Conclusion: 本文提出了一种新颖的视觉引导3D布局生成系统，显著提升了布局的丰富性和质量，并通过用户测试验证了其优越性。

Abstract: Generating artistic and coherent 3D scene layouts is crucial in digital
content creation. Traditional optimization-based methods are often constrained
by cumbersome manual rules, while deep generative models face challenges in
producing content with richness and diversity. Furthermore, approaches that
utilize large language models frequently lack robustness and fail to accurately
capture complex spatial relationships. To address these challenges, this paper
presents a novel vision-guided 3D layout generation system. We first construct
a high-quality asset library containing 2,037 scene assets and 147 3D scene
layouts. Subsequently, we employ an image generation model to expand prompt
representations into images, fine-tuning it to align with our asset library. We
then develop a robust image parsing module to recover the 3D layout of scenes
based on visual semantics and geometric information. Finally, we optimize the
scene layout using scene graphs and overall visual semantics to ensure logical
coherence and alignment with the images. Extensive user testing demonstrates
that our algorithm significantly outperforms existing methods in terms of
layout richness and quality. The code and dataset will be available at
https://github.com/HiHiAllen/Imaginarium.

</details>


### [64] [Semantic segmentation with coarse annotations](https://arxiv.org/abs/2510.15756)
*Jort de Jong,Mike Holenderski*

Main category: cs.CV

TL;DR: 提出一种基于超像素上采样的正则化方法，显著提升粗标注下的语义分割边界召回率。


<details>
  <summary>Details</summary>
Motivation: 由于精细标注获取困难且昂贵，粗标注成为替代方案，但边界对齐优化困难，因此需要一种方法来提升粗标注下的分割性能。

Method: 采用编码器-解码器架构，结合超像素上采样，鼓励解码图像中的分割像素为SLIC超像素。

Result: 在SUIM、Cityscapes和PanNuke数据集上评估，边界召回率显著优于现有方法。

Conclusion: 该论文提出的基于超像素上采样的正则化方法显著提高了在粗标注数据上训练的语义分割模型的边界召回率。

Abstract: Semantic segmentation is the task of classifying each pixel in an image.
Training a segmentation model achieves best results using annotated images,
where each pixel is annotated with the corresponding class. When obtaining fine
annotations is difficult or expensive, it may be possible to acquire coarse
annotations, e.g. by roughly annotating pixels in an images leaving some pixels
around the boundaries between classes unlabeled. Segmentation with coarse
annotations is difficult, in particular when the objective is to optimize the
alignment of boundaries between classes. This paper proposes a regularization
method for models with an encoder-decoder architecture with superpixel based
upsampling. It encourages the segmented pixels in the decoded image to be
SLIC-superpixels, which are based on pixel color and position, independent of
the segmentation annotation. The method is applied to FCN-16 fully
convolutional network architecture and evaluated on the SUIM, Cityscapes, and
PanNuke data sets. It is shown that the boundary recall improves significantly
compared to state-of-the-art models when trained on coarse annotations.

</details>


### [65] [Unmasking Facial DeepFakes: A Robust Multiview Detection Framework for Natural Images](https://arxiv.org/abs/2510.15576)
*Sami Belguesmia,Mohand Saïd Allili,Assia Hamadene*

Main category: cs.CV

TL;DR: 提出多视角架构提升DeepFake检测，通过多个编码器分析不同面部特征，实验显示其在复杂条件下优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有DeepFake检测方法在姿态变化、遮挡和现实场景中的伪影检测上表现不佳，亟需更鲁棒的解决方案。

Method: 提出了一种多视角架构，包含全局视图编码器、中间视图编码器和局部视图编码器，分别检测边界不一致性、纹理颜色对齐及面部表情区域的失真。还加入了面部朝向编码器以增强多角度检测能力。

Result: 实验结果表明，该方法在挑战性数据集上优于传统单视角方法。

Conclusion: 该方法通过多视角架构显著提升了DeepFake检测的鲁棒性，尤其在复杂姿态和光照条件下表现优异。

Abstract: DeepFake technology has advanced significantly in recent years, enabling the
creation of highly realistic synthetic face images. Existing DeepFake detection
methods often struggle with pose variations, occlusions, and artifacts that are
difficult to detect in real-world conditions. To address these challenges, we
propose a multi-view architecture that enhances DeepFake detection by analyzing
facial features at multiple levels. Our approach integrates three specialized
encoders, a global view encoder for detecting boundary inconsistencies, a
middle view encoder for analyzing texture and color alignment, and a local view
encoder for capturing distortions in expressive facial regions such as the
eyes, nose, and mouth, where DeepFake artifacts frequently occur. Additionally,
we incorporate a face orientation encoder, trained to classify face poses,
ensuring robust detection across various viewing angles. By fusing features
from these encoders, our model achieves superior performance in detecting
manipulated images, even under challenging pose and lighting
conditions.Experimental results on challenging datasets demonstrate the
effectiveness of our method, outperforming conventional single-view approaches

</details>


### [66] [Controlling the image generation process with parametric activation functions](https://arxiv.org/abs/2510.15778)
*Ilia Pavlov*

Main category: cs.CV

TL;DR: 该论文提出了一种通过交互式修改生成网络激活函数来增强模型可解释性的方法，并在StyleGAN2和BigGAN上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管图像生成模型的保真度和普及度不断提高，但其内部机制的可解释性工具开发仍不足。

Method: 用户可以通过替换生成网络的激活函数为参数化函数，并设置这些函数的参数，来交互式地理解和控制网络输出。该方法在StyleGAN2和BigGAN网络上进行了验证。

Result: 在StyleGAN2（FFHQ数据集）和BigGAN（ImageNet数据集）上的实验表明，该方法能有效提升用户对模型的理解和控制能力。

Conclusion: 该系统通过允许用户交互式地修改生成网络的激活函数，提供了一种新的网络输出控制方法，增强了模型的可解释性。

Abstract: As image generative models continue to increase not only in their fidelity
but also in their ubiquity the development of tools that leverage direct
interaction with their internal mechanisms in an interpretable way has received
little attention In this work we introduce a system that allows users to
develop a better understanding of the model through interaction and
experimentation By giving users the ability to replace activation functions of
a generative network with parametric ones and a way to set the parameters of
these functions we introduce an alternative approach to control the networks
output We demonstrate the use of our method on StyleGAN2 and BigGAN networks
trained on FFHQ and ImageNet respectively.

</details>


### [67] [OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM](https://arxiv.org/abs/2510.15870)
*Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Jason Lu,Oluwatobi Olabiyi,Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov*

Main category: cs.CV

TL;DR: OmniVinci是一个开源的多模态LLM，通过创新架构和数据合成流程，显著提升了跨模态理解和性能。


<details>
  <summary>Details</summary>
Motivation: 推动机器智能需要发展跨多模态的感知能力，模仿人类感知世界的方式。

Method: 提出了三种关键创新：OmniAlignNet、Temporal Embedding Grouping和Constrained Rotary Time Embedding，以及一个生成2400万单模态和多模态对话的数据合成流程。

Result: OmniVinci在多个基准测试中表现优异，使用训练令牌减少了6倍。

Conclusion: OmniVinci展示了在多模态感知和理解方面的显著优势，并在机器人、医疗AI和智能工厂等下游应用中验证了其潜力。

Abstract: Advancing machine intelligence requires developing the ability to perceive
across multiple modalities, much as humans sense the world. We introduce
OmniVinci, an initiative to build a strong, open-source, omni-modal LLM. We
carefully study the design choices across model architecture and data curation.
For model architecture, we present three key innovations: (i) OmniAlignNet for
strengthening alignment between vision and audio embeddings in a shared
omni-modal latent space; (ii) Temporal Embedding Grouping for capturing
relative temporal alignment between vision and audio signals; and (iii)
Constrained Rotary Time Embedding for encoding absolute temporal information in
omni-modal embeddings. We introduce a curation and synthesis pipeline that
generates 24M single-modal and omni-modal conversations. We find that
modalities reinforce one another in both perception and reasoning. Our model,
OmniVinci, outperforms Qwen2.5-Omni with +19.05 on DailyOmni (cross-modal
understanding), +1.7 on MMAR (audio), and +3.9 on Video-MME (vision), while
using just 0.2T training tokens - a 6 times reduction compared to
Qwen2.5-Omni's 1.2T. We finally demonstrate omni-modal advantages in downstream
applications spanning robotics, medical AI, and smart factory.

</details>


### [68] [Standardization for improved Spatio-Temporal Image Fusion](https://arxiv.org/abs/2510.15589)
*Harkaitz Goyena,Peter M. Atkinson,Unai Pérez-Goya,M. Dolores Ugarte*

Main category: cs.CV

TL;DR: 提出了两种标准化方法（传统上采样和ABSIS锐化）以提升STIF方法的准确性，其中ABSIS在光谱和空间准确性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 为了促进STIF方法的应用，需要解决不同传感器捕获的图像在空间和光谱分辨率上不匹配的问题。

Method: 提出了两种标准化方法：一种是传统的精细分辨率图像上采样方法，另一种是锐化方法（ABSIS），后者将精细分辨率图像系列的整体特征与特定粗分辨率图像的独特属性融合。

Result: 锐化方法（ABSIS）将融合图像的光谱和空间准确性分别提高了49.46%和78.40%。

Conclusion: 两种标准化方法均显著提高了USTFIP STIF方法的准确性，其中锐化方法（ABSIS）在光谱和空间准确性上的提升尤为突出。

Abstract: Spatio-Temporal Image Fusion (STIF) methods usually require sets of images
with matching spatial and spectral resolutions captured by different sensors.
To facilitate the application of STIF methods, we propose and compare two
different standardization approaches. The first method is based on traditional
upscaling of the fine-resolution images. The second method is a sharpening
approach called Anomaly Based Satellite Image Standardization (ABSIS) that
blends the overall features found in the fine-resolution image series with the
distinctive attributes of a specific coarse-resolution image to produce images
that more closely resemble the outcome of aggregating the fine-resolution
images. Both methods produce a significant increase in accuracy of the Unpaired
Spatio Temporal Fusion of Image Patches (USTFIP) STIF method, with the
sharpening approach increasing the spectral and spatial accuracies of the fused
images by up to 49.46\% and 78.40\%, respectively.

</details>


### [69] [FlexiReID: Adaptive Mixture of Expert for Multi-Modal Person Re-Identification](https://arxiv.org/abs/2510.15595)
*Zhen Sun,Lei Tan,Yunhang Shen,Chengmao Cai,Xing Sun,Pingyang Dai,Liujuan Cao,Rongrong Ji*

Main category: cs.CV

TL;DR: FlexiReID是一种灵活的多模态行人重识别框架，支持七种检索模式和四种模态，通过自适应MoE和跨模态查询融合提升性能，并在新构建的CIRS-PEDES数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多模态行人重识别中局限于有限的跨模态设置，无法支持任意查询-检索组合，限制了实际应用。

Method: 提出自适应专家混合（MoE）机制和跨模态查询融合模块，动态整合多模态特征。

Result: FlexiReID在CIRS-PEDES数据集上实现了最先进的性能，并在复杂场景中表现出强泛化能力。

Conclusion: FlexiReID框架在复杂场景中表现出色，支持多种模态的灵活检索，具有强大的泛化能力。

Abstract: Multimodal person re-identification (Re-ID) aims to match pedestrian images
across different modalities. However, most existing methods focus on limited
cross-modal settings and fail to support arbitrary query-retrieval
combinations, hindering practical deployment. We propose FlexiReID, a flexible
framework that supports seven retrieval modes across four modalities: rgb,
infrared, sketches, and text. FlexiReID introduces an adaptive
mixture-of-experts (MoE) mechanism to dynamically integrate diverse modality
features and a cross-modal query fusion module to enhance multimodal feature
extraction. To facilitate comprehensive evaluation, we construct CIRS-PEDES, a
unified dataset extending four popular Re-ID datasets to include all four
modalities. Extensive experiments demonstrate that FlexiReID achieves
state-of-the-art performance and offers strong generalization in complex
scenarios.

</details>


### [70] [Quantized FCA: Efficient Zero-Shot Texture Anomaly Detection](https://arxiv.org/abs/2510.15602)
*Andrei-Timotei Ardelean,Patrick Rückbeil,Tim Weyrich*

Main category: cs.CV

TL;DR: QFCA是一种实时纹理异常定位方法，通过量化FCA算法和PCA预处理，显著提升速度和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法运行时间过长，难以在实际场景中部署，如装配线监控。

Method: 提出了一种名为QFCA的实时方法，通过量化特征对应分析（FCA）算法，并引入基于主成分分析的特征预处理步骤。

Result: QFCA在保持精度的情况下实现了10倍的速度提升，并在复杂纹理上提高了检测精度。

Conclusion: QFCA方法通过量化的特征对应分析算法实现了实时异常定位，显著提升了运行速度，同时保持了高精度。

Abstract: Zero-shot anomaly localization is a rising field in computer vision research,
with important progress in recent years. This work focuses on the problem of
detecting and localizing anomalies in textures, where anomalies can be defined
as the regions that deviate from the overall statistics, violating the
stationarity assumption. The main limitation of existing methods is their high
running time, making them impractical for deployment in real-world scenarios,
such as assembly line monitoring. We propose a real-time method, named QFCA,
which implements a quantized version of the feature correspondence analysis
(FCA) algorithm. By carefully adapting the patch statistics comparison to work
on histograms of quantized values, we obtain a 10x speedup with little to no
loss in accuracy. Moreover, we introduce a feature preprocessing step based on
principal component analysis, which enhances the contrast between normal and
anomalous features, improving the detection precision on complex textures. Our
method is thoroughly evaluated against prior art, comparing favorably with
existing methods. Project page:
https://reality.tf.fau.de/pub/ardelean2025quantized.html

</details>


### [71] [Lightweight Data-Free Denoising for Detail-Preserving Biomedical Image Restoration](https://arxiv.org/abs/2510.15611)
*Tomáš Chobola,Julia A. Schnabel,Tingying Peng*

Main category: cs.CV

TL;DR: 提出超轻量级模型Noise2Detail，结合高效、低计算成本和无需数据的方法，适用于生物医学成像，解决了清洁训练数据稀缺和快速推理的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决当前自监督去噪技术在真实应用中因高计算和内存需求而在推理速度与重建质量之间必须做出妥协的问题。

Method: 基于Noise2Noise训练框架，引入创新的多阶段去噪流程Noise2Detail（N2D），通过破坏噪声模式的空间相关性生成中间平滑结构，并从噪声输入中直接恢复精细细节。

Result: Noise2Detail在性能上超越了现有的无需数据集的技术，同时仅需少量计算资源。

Conclusion: Noise2Detail（N2D）模型在计算资源有限的情况下，实现了快速的去噪和高品质的图像恢复，特别适用于生物医学成像等清洁训练数据稀缺的领域。

Abstract: Current self-supervised denoising techniques achieve impressive results, yet
their real-world application is frequently constrained by substantial
computational and memory demands, necessitating a compromise between inference
speed and reconstruction quality. In this paper, we present an
ultra-lightweight model that addresses this challenge, achieving both fast
denoising and high quality image restoration. Built upon the Noise2Noise
training framework-which removes the reliance on clean reference images or
explicit noise modeling-we introduce an innovative multistage denoising
pipeline named Noise2Detail (N2D). During inference, this approach disrupts the
spatial correlations of noise patterns to produce intermediate smooth
structures, which are subsequently refined to recapture fine details directly
from the noisy input. Extensive testing reveals that Noise2Detail surpasses
existing dataset-free techniques in performance, while requiring only a
fraction of the computational resources. This combination of efficiency, low
computational cost, and data-free approach make it a valuable tool for
biomedical imaging, overcoming the challenges of scarce clean training data-due
to rare and complex imaging modalities-while enabling fast inference for
practical use.

</details>


### [72] [Deep Learning Based Domain Adaptation Methods in Remote Sensing: A Comprehensive Survey](https://arxiv.org/abs/2510.15615)
*Shuchang Lyu,Qi Zhao,Zheng Zhou,Meng Li,You Zhou,Dingding Yao,Guangliang Cheng,Huiyu Zhou,Zhenwei Shi*

Main category: cs.CV

TL;DR: 本文综述了遥感领域基于深度学习的域适应研究，系统分类了方法并指出未来方向，旨在推动该领域发展。


<details>
  <summary>Details</summary>
Motivation: 遥感中的域适应任务因数据差异（如采样距离、传感器成像模式等）面临巨大挑战，而深度学习在特征表示和跨域知识迁移中展现出强大潜力，因此需要系统梳理该领域进展。

Method: 作者首先介绍了域适应的基本概念和数学表示，然后从任务分类、输入模式、监督范式和算法粒度等多个角度组织现有算法，并回顾了常用数据集和最新方法性能。

Result: 综述涵盖了更广泛的遥感域适应任务，提出了系统性分类法，并总结了当前最优方法的性能，为未来研究提供了清晰方向。

Conclusion: 这篇综述为遥感领域的域适应研究提供了全面的视角，系统性地分类了现有方法，并指出了未来研究方向，旨在激发研究社区的进一步探索。

Abstract: Domain adaptation is a crucial and increasingly important task in remote
sensing, aiming to transfer knowledge from a source domain a differently
distributed target domain. It has broad applications across various real-world
applications, including remote sensing element interpretation, ecological
environment monitoring, and urban/rural planning. However, domain adaptation in
remote sensing poses significant challenges due to differences in data, such as
variations in ground sampling distance, imaging modes from various sensors,
geographical landscapes, and environmental conditions. In recent years, deep
learning has emerged as a powerful tool for feature representation and
cross-domain knowledge transfer, leading to widespread adoption in remote
sensing tasks. In this paper, we present a comprehensive survey of significant
advancements in deep learning based domain adaptation for remote sensing. We
first introduce the preliminary knowledge to clarify key concepts, mathematical
notations, and the taxonomy of methodologies. We then organize existing
algorithms from multiple perspectives, including task categorization, input
mode, supervision paradigm, and algorithmic granularity, providing readers with
a structured understanding of the field. Next, we review widely used datasets
and summarize the performance of state-of-the-art methods to provide an
overview of current progress. We also identify open challenges and potential
directions to guide future research in domain adaptation for remote sensing.
Compared to previous surveys, this work addresses a broader range of domain
adaptation tasks in remote sensing, rather than concentrating on a few
subfields. It also presents a systematic taxonomy, providing a more
comprehensive and organized understanding of the field. As a whole, this survey
can inspire the research community, foster understanding, and guide future work
in the field.

</details>


### [73] [Uncertainty-Aware Extreme Point Tracing for Weakly Supervised Ultrasound Image Segmentation](https://arxiv.org/abs/2510.15666)
*Lei Shi,Gang Li,Junxing Zhang*

Main category: cs.CV

TL;DR: A weakly supervised medical image segmentation method using extreme points as annotation, leveraging SAM2 and refined pseudo labels, achieves near or better performance than fully supervised methods with less annotation effort.


<details>
  <summary>Details</summary>
Motivation: To reduce the costly and time-consuming burden of pixel-level annotations required by fully supervised medical image segmentation approaches.

Method: The framework uses four extreme points as annotation, leverages SAM2 for initial pseudo labels, refines them with an enhanced FGEPM algorithm incorporating Monte Carlo dropout-based uncertainty estimation, and employs a dual-branch USC loss and box alignment loss for training.

Result: Extensive experiments on BUSI and UNS datasets show the method achieves performance comparable to or better than fully supervised methods with much lower annotation costs.

Conclusion: The proposed weakly supervised segmentation framework achieves performance comparable to or surpassing fully supervised methods while significantly reducing annotation costs, demonstrating its effectiveness and practicality for ultrasound image segmentation.

Abstract: Automatic medical image segmentation is a fundamental step in computer-aided
diagnosis, yet fully supervised approaches demand extensive pixel-level
annotations that are costly and time-consuming. To alleviate this burden, we
propose a weakly supervised segmentation framework that leverages only four
extreme points as annotation. Specifically, bounding boxes derived from the
extreme points are used as prompts for the Segment Anything Model 2 (SAM2) to
generate reliable initial pseudo labels. These pseudo labels are progressively
refined by an enhanced Feature-Guided Extreme Point Masking (FGEPM) algorithm,
which incorporates Monte Carlo dropout-based uncertainty estimation to
construct a unified gradient uncertainty cost map for boundary tracing.
Furthermore, a dual-branch Uncertainty-aware Scale Consistency (USC) loss and a
box alignment loss are introduced to ensure spatial consistency and precise
boundary alignment during training. Extensive experiments on two public
ultrasound datasets, BUSI and UNS, demonstrate that our method achieves
performance comparable to, and even surpassing fully supervised counterparts
while significantly reducing annotation cost. These results validate the
effectiveness and practicality of the proposed weakly supervised framework for
ultrasound image segmentation.

</details>


### [74] [Unimedvl: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis](https://arxiv.org/abs/2510.15710)
*Junzhi Ning,Wei Li,Cheng Tang,Jiashi Lin,Chenglong Ma,Chaoyang Zhang,Jiyao Liu,Ying Chen,Shujian Gao,Lihao Liu,Yuandong Pu,Huihui Xu,Chenhui Gou,Ziyan Huang,Yi Xin,Qi Qin,Zhongying Deng,Diping Song,Bin Fu,Guang Yang,Yuanfeng Ji,Tianbin Li,Yanzhou Su,Jin Ye,Shixiang Tang,Ming Hu,Junjun He*

Main category: cs.CV

TL;DR: 提出UniMedVL，首个统一多模态医疗模型，通过OKA范式实现图像理解与生成任务的双向知识共享，性能优于现有系统。


<details>
  <summary>Details</summary>
Motivation: 现有医疗AI系统无法统一处理多模态输入和多样化输出，导致数据表示、特征集成和任务级多模态能力的不足。

Method: 提出了一个多层次框架，包括构建UniMed-5M数据集、渐进式课程学习以及UniMedVL模型的设计。

Result: UniMedVL在五个医疗图像理解基准测试中表现优异，同时在八种医疗成像模态中生成质量与专用模型相当。

Conclusion: UniMedVL作为首个医疗统一多模态模型，通过单一架构同时处理图像理解和生成任务，实现了双向知识共享，显著提升了多种医疗视觉语言任务的性能。

Abstract: Medical diagnostic applications require models that can process multimodal
medical inputs (images, patient histories, lab results) and generate diverse
outputs including both textual reports and visual content (annotations,
segmentation masks, and images). Despite this need, existing medical AI systems
disrupt this unified process: medical image understanding models interpret
images but cannot generate visual outputs, while medical image generation
models synthesize images but cannot provide textual explanations. This leads to
gaps in data representation, feature integration, and task-level multimodal
capabilities. To this end, we propose a multi-level framework that draws
inspiration from diagnostic workflows through the
Observation-Knowledge-Analysis (OKA) paradigm. Specifically, at the observation
level, we construct UniMed-5M, a dataset comprising over 5.6M samples that
reformat diverse unimodal data into multimodal pairs for foundational
observation. At the knowledge level, we propose Progressive Curriculum Learning
that systematically introduces medical multimodal knowledge. At the analysis
level, we introduce UniMedVL, the first medical unified multimodal model for
the simultaneous analysis of image understanding and generation tasks within a
single architecture. UniMedVL achieves superior performance on five medical
image understanding benchmarks, while matching specialized models in generation
quality across eight medical imaging modalities. Crucially, our unified
architecture enables bidirectional knowledge sharing: generation tasks enhance
visual understanding features, demonstrating that integrating traditionally
separate capabilities within a single medical framework unlocks improvements
across diverse medical vision-language tasks. Code is available at
https://github.com/uni-medical/UniMedVL.

</details>


### [75] [Scaling Instruction-Based Video Editing with a High-Quality Synthetic Dataset](https://arxiv.org/abs/2510.15742)
*Qingyan Bai,Qiuyu Wang,Hao Ouyang,Yue Yu,Hanlin Wang,Wen Wang,Ka Leong Cheng,Shuailei Ma,Yanhong Zeng,Zichen Liu,Yinghao Xu,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: Ditto框架通过创新数据生成和高效模型设计，构建了大规模高质量视频编辑数据集Ditto-1M，训练出的Editto模型性能卓越。


<details>
  <summary>Details</summary>
Motivation: 解决指令式视频编辑因缺乏大规模高质量训练数据而受限的问题。

Method: Ditto框架采用数据生成管道结合图像编辑器与上下文视频生成器，并利用高效蒸馏模型架构及时间增强器优化计算效率与时间一致性。智能代理负责生成多样化指令并严格过滤输出，确保质量。

Result: 构建了包含100万高质量视频编辑样本的Ditto-1M数据集，训练出的Editto模型在指令遵循能力和编辑效果上达到新高度。

Conclusion: Ditto框架通过创新的数据生成管道和高效模型架构，成功构建了Ditto-1M数据集，并训练出性能优越的Editto模型，在指令式视频编辑领域实现了新的技术突破。

Abstract: Instruction-based video editing promises to democratize content creation, yet
its progress is severely hampered by the scarcity of large-scale, high-quality
training data. We introduce Ditto, a holistic framework designed to tackle this
fundamental challenge. At its heart, Ditto features a novel data generation
pipeline that fuses the creative diversity of a leading image editor with an
in-context video generator, overcoming the limited scope of existing models. To
make this process viable, our framework resolves the prohibitive cost-quality
trade-off by employing an efficient, distilled model architecture augmented by
a temporal enhancer, which simultaneously reduces computational overhead and
improves temporal coherence. Finally, to achieve full scalability, this entire
pipeline is driven by an intelligent agent that crafts diverse instructions and
rigorously filters the output, ensuring quality control at scale. Using this
framework, we invested over 12,000 GPU-days to build Ditto-1M, a new dataset of
one million high-fidelity video editing examples. We trained our model, Editto,
on Ditto-1M with a curriculum learning strategy. The results demonstrate
superior instruction-following ability and establish a new state-of-the-art in
instruction-based video editing.

</details>


### [76] [SEGA: A Stepwise Evolution Paradigm for Content-Aware Layout Generation with Design Prior](https://arxiv.org/abs/2510.15749)
*Haoran Wang,Bo Zhao,Jinghui Wang,Hanzhang Wang,Huan Yang,Wei Ji,Hao Liu,Xinyan Xiao*

Main category: cs.CV

TL;DR: SEGA是一种新型的分步进化范式，用于内容感知布局生成，通过分层推理和反馈机制提高了布局规划的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的单步推理框架在复杂元素布局规划中失败率较高，缺乏反馈和自我纠正机制。

Method: SEGA采用了一种分层推理框架，包括粗粒度模块和细化模块，结合布局设计原则作为先验知识。

Result: 实验结果表明，SEGA在多个基准数据集上实现了最先进的性能。

Conclusion: SEGA通过分层推理框架和反馈机制显著提高了内容感知布局生成的准确性和鲁棒性，并在多个基准数据集上实现了最先进的性能。

Abstract: In this paper, we study the content-aware layout generation problem, which
aims to automatically generate layouts that are harmonious with a given
background image. Existing methods usually deal with this task with a
single-step reasoning framework. The lack of a feedback-based self-correction
mechanism leads to their failure rates significantly increasing when faced with
complex element layout planning. To address this challenge, we introduce SEGA,
a novel Stepwise Evolution Paradigm for Content-Aware Layout Generation.
Inspired by the systematic mode of human thinking, SEGA employs a hierarchical
reasoning framework with a coarse-to-fine strategy: first, a coarse-level
module roughly estimates the layout planning results; then, another refining
module performs fine-level reasoning regarding the coarse planning results.
Furthermore, we incorporate layout design principles as prior knowledge into
the model to enhance its layout planning ability. Besides, we present
GenPoster-100K that is a new large-scale poster dataset with rich
meta-information annotation. The experiments demonstrate the effectiveness of
our approach by achieving the state-of-the-art results on multiple benchmark
datasets. Our project page is at: https://brucew91.github.io/SEGA.github.io/

</details>


### [77] [QSilk: Micrograin Stabilization and Adaptive Quantile Clipping for Detail-Friendly Latent Diffusion](https://arxiv.org/abs/2510.15761)
*Denis Rychkovskiy*

Main category: cs.CV

TL;DR: QSilk是一种无需训练的轻量级稳定层，通过微钳位和自适应剪裁技术提升潜在扩散模型的高频保真度和抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决潜在扩散模型中高频保真度不足和罕见激活峰值的问题，同时保持轻量化和无需训练的特性。

Method: QSilk结合了每样本微钳位和自适应分位数剪裁（AQClip）两种技术，前者温和限制极端值而不破坏纹理，后者根据区域动态调整允许值范围。AQClip可基于局部结构统计或注意力熵（模型置信度）工作。

Result: 集成到CADE 2.5渲染管线后，QSilk在低步数和高分辨率下实现了更清晰、更锐利的结果，且开销可忽略。与CFG/Rescale协同工作时，可在不引入伪影的情况下略微提高引导强度。

Conclusion: QSilk作为一种轻量级、持续运行的稳定层，显著提升了潜在扩散模型的高频保真度，同时抑制了罕见的激活峰值。

Abstract: We present QSilk, a lightweight, always-on stabilization layer for latent
diffusion that improves high-frequency fidelity while suppressing rare
activation spikes. QSilk combines (i) a per-sample micro clamp that gently
limits extreme values without washing out texture, and (ii) Adaptive Quantile
Clip (AQClip), which adapts the allowed value corridor per region. AQClip can
operate in a proxy mode using local structure statistics or in an attention
entropy guided mode (model confidence). Integrated into the CADE 2.5 rendering
pipeline, QSilk yields cleaner, sharper results at low step counts and
ultra-high resolutions with negligible overhead. It requires no training or
fine-tuning and exposes minimal user controls. We report consistent qualitative
improvements across SD/SDXL backbones and show synergy with CFG/Rescale,
enabling slightly higher guidance without artifacts.

</details>


### [78] [Towards more holistic interpretability: A lightweight disentangled Concept Bottleneck Model](https://arxiv.org/abs/2510.15770)
*Gaoxiang Huang,Songning Lai,Yutao Yue*

Main category: cs.CV

TL;DR: LDCBM通过解耦和联合监督，提升了概念瓶颈模型的可解释性和分类性能，解决了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）存在输入到概念映射偏差和有限可控性，限制了其实际价值，直接影响概念方法的责任性。

Method: 提出了一种轻量级解耦概念瓶颈模型（LDCBM），通过过滤分组损失和联合概念监督，自动将视觉特征分组为语义上有意义的组件。

Result: 在三个不同数据集上的实验表明，LDCBM在概念和分类准确性上均优于以前的CBMs，同时在可解释性和分类性能上表现更优。

Conclusion: LDCBM通过将视觉特征自动分组为语义上有意义的组件，并引入过滤分组损失和联合概念监督，显著提高了概念和分类准确性，增强了可解释AI的可靠性。

Abstract: Concept Bottleneck Models (CBMs) enhance interpretability by predicting
human-understandable concepts as intermediate representations. However,
existing CBMs often suffer from input-to-concept mapping bias and limited
controllability, which restricts their practical value, directly damage the
responsibility of strategy from concept-based methods. We propose a lightweight
Disentangled Concept Bottleneck Model (LDCBM) that automatically groups visual
features into semantically meaningful components without region annotation. By
introducing a filter grouping loss and joint concept supervision, our method
improves the alignment between visual patterns and concepts, enabling more
transparent and robust decision-making. Notably, Experiments on three diverse
datasets demonstrate that LDCBM achieves higher concept and class accuracy,
outperforming previous CBMs in both interpretability and classification
performance. By grounding concepts in visual evidence, our method overcomes a
fundamental limitation of prior models and enhances the reliability of
interpretable AI.

</details>


### [79] [ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection](https://arxiv.org/abs/2510.15783)
*Haowei Zhu,Tianxiang Pan,Rui Qin,Jun-Hai Yong,Bin Wang*

Main category: cs.CV

TL;DR: ReCon是一种新的数据增强框架，通过区域引导校正和区域对齐交叉注意力提升生成数据质量，适用于目标检测任务。


<details>
  <summary>Details</summary>
Motivation: 大规模标注数据获取成本高且耗时，现有生成方法依赖复杂后处理或大规模微调，且易出现内容位置不匹配和语义泄漏问题。

Method: ReCon引入了区域引导校正和区域对齐交叉注意力，在扩散采样过程中利用预训练感知模型的反馈来校正生成错误，并增强空间语义对齐。

Result: 实验表明，ReCon显著提升了生成数据的质量和可训练性，并在多个数据集和架构上实现了性能提升。

Conclusion: ReCon框架通过整合区域引导校正和区域对齐交叉注意力，显著提升了生成数据的质量和可训练性，并在多个数据集和架构上实现了性能提升。

Abstract: The scale and quality of datasets are crucial for training robust perception
models. However, obtaining large-scale annotated data is both costly and
time-consuming. Generative models have emerged as a powerful tool for data
augmentation by synthesizing samples that adhere to desired distributions.
However, current generative approaches often rely on complex post-processing or
extensive fine-tuning on massive datasets to achieve satisfactory results, and
they remain prone to content-position mismatches and semantic leakage. To
overcome these limitations, we introduce ReCon, a novel augmentation framework
that enhances the capacity of structure-controllable generative models for
object detection. ReCon integrates region-guided rectification into the
diffusion sampling process, using feedback from a pre-trained perception model
to rectify misgenerated regions within diffusion sampling process. We further
propose region-aligned cross-attention to enforce spatial-semantic alignment
between image regions and their textual cues, thereby improving both semantic
consistency and overall image fidelity. Extensive experiments demonstrate that
ReCon substantially improve the quality and trainability of generated data,
achieving consistent performance gains across various datasets, backbone
architectures, and data scales. Our code is available at
https://github.com/haoweiz23/ReCon .

</details>


### [80] [ERNet: Efficient Non-Rigid Registration Network for Point Sequences](https://arxiv.org/abs/2510.15800)
*Guangzhao He,Yuxi Xiao,Zhen Xu,Xiaowei Zhou,Sida Peng*

Main category: cs.CV

TL;DR: ERNet通过两阶段管道处理非刚性变形点云序列注册，显著提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决非刚性变形点云序列注册中的局部最小值和误差累积问题，尤其是在噪声或部分输入情况下。

Method: 提出ERNet，一种高效的前馈模型，采用两阶段管道：首先估计帧级粗略图节点以进行鲁棒初始化，然后以滑动窗口方式随时间细化其轨迹。

Result: 在DeformingThings4D和D-FAUST数据集上表现优于先前的最先进方法，并实现超过4倍的加速。

Conclusion: ERNet通过两阶段管道预测变形图序列，显著提高了非刚性变形点云序列注册的准确性和效率。

Abstract: Registering an object shape to a sequence of point clouds undergoing
non-rigid deformation is a long-standing challenge. The key difficulties stem
from two factors: (i) the presence of local minima due to the non-convexity of
registration objectives, especially under noisy or partial inputs, which
hinders accurate and robust deformation estimation, and (ii) error accumulation
over long sequences, leading to tracking failures. To address these challenges,
we introduce to adopt a scalable data-driven approach and propose ERNet, an
efficient feed-forward model trained on large deformation datasets. It is
designed to handle noisy and partial inputs while effectively leveraging
temporal information for accurate and consistent sequential registration. The
key to our design is predicting a sequence of deformation graphs through a
two-stage pipeline, which first estimates frame-wise coarse graph nodes for
robust initialization, before refining their trajectories over time in a
sliding-window fashion. Extensive experiments show that our proposed approach
(i) outperforms previous state-of-the-art on both the DeformingThings4D and
D-FAUST datasets, and (ii) achieves more than 4x speedup compared to the
previous best, offering significant efficiency improvement.

</details>


### [81] [VISTA: A Test-Time Self-Improving Video Generation Agent](https://arxiv.org/abs/2510.15831)
*Do Xuan Long,Xingchen Wan,Hootan Nakhost,Chen-Yu Lee,Tomas Pfister,Sercan Ö. Arık*

Main category: cs.CV

TL;DR: VISTA 是一种多代理系统，通过迭代改进提示自主提升视频生成质量，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有测试时优化方法在多方面的视频生成中表现不佳，VISTA 旨在通过自主迭代改进提升视频生成质量。

Method: VISTA 首先将用户想法分解为结构化时间计划，生成后通过成对锦标赛选出最佳视频，再由三个专业代理（视觉、音频、上下文）进行批评，最后由推理代理综合反馈并重写提示。

Result: VISTA 在单场景和多场景视频生成中均表现优异，相比现有基线方法获得了60%的成对胜率，人类评估者更偏好其输出（66.4%）。

Conclusion: VISTA 通过多代理系统自主改进视频生成，显著提升了视频质量和用户意图对齐，实验和人类评估均验证了其有效性。

Abstract: Despite rapid advances in text-to-video synthesis, generated video quality
remains critically dependent on precise user prompts. Existing test-time
optimization methods, successful in other domains, struggle with the
multi-faceted nature of video. In this work, we introduce VISTA (Video
Iterative Self-improvemenT Agent), a novel multi-agent system that autonomously
improves video generation through refining prompts in an iterative loop. VISTA
first decomposes a user idea into a structured temporal plan. After generation,
the best video is identified through a robust pairwise tournament. This winning
video is then critiqued by a trio of specialized agents focusing on visual,
audio, and contextual fidelity. Finally, a reasoning agent synthesizes this
feedback to introspectively rewrite and enhance the prompt for the next
generation cycle. Experiments on single- and multi-scene video generation
scenarios show that while prior methods yield inconsistent gains, VISTA
consistently improves video quality and alignment with user intent, achieving
up to 60% pairwise win rate against state-of-the-art baselines. Human
evaluators concur, preferring VISTA outputs in 66.4% of comparisons.

</details>


### [82] [Neuro-Symbolic Spatial Reasoning in Segmentation](https://arxiv.org/abs/2510.15841)
*Jiayi Lin,Jiabo Huang,Shaogang Gong*

Main category: cs.CV

TL;DR: RelateSeg通过神经符号空间推理和一阶逻辑约束，在开放词汇语义分割中实现了优异的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在开放词汇语义分割中缺乏对场景中物体空间关系理解的问题。

Method: 提出RelateSeg，利用一阶逻辑公式在神经网络架构中施加显式空间关系约束，同时预测语义类别和空间伪类别。

Result: RelateSeg在四个基准数据集上取得了平均mIoU的最先进性能，尤其在包含多类别的图像中表现优异。

Conclusion: RelateSeg通过神经符号空间推理在开放词汇语义分割中实现了最先进的性能，验证了该方法在OVSS中的有效性。

Abstract: Open-Vocabulary Semantic Segmentation (OVSS) assigns pixel-level labels from
an open set of categories, requiring generalization to unseen and unlabelled
objects. Using vision-language models (VLMs) to correlate local image patches
with potential unseen object categories suffers from a lack of understanding of
spatial relations of objects in a scene. To solve this problem, we introduce
neuro-symbolic (NeSy) spatial reasoning in OVSS. In contrast to contemporary
VLM correlation-based approaches, we propose Relational Segmentor (RelateSeg)
to impose explicit spatial relational constraints by first order logic (FOL)
formulated in a neural network architecture. This is the first attempt to
explore NeSy spatial reasoning in OVSS. Specifically, RelateSeg automatically
extracts spatial relations, e.g., <cat, to-right-of, person>, and encodes them
as first-order logic formulas using our proposed pseudo categories. Each pixel
learns to predict both a semantic category (e.g., "cat") and a spatial pseudo
category (e.g., "right of person") simultaneously, enforcing relational
constraints (e.g., a "cat" pixel must lie to the right of a "person"). Finally,
these logic constraints are formulated in a deep network architecture by fuzzy
logic relaxation, enabling end-to-end learning of spatial-relationally
consistent segmentation. RelateSeg achieves state-of-the-art performance in
terms of average mIoU across four benchmark datasets and particularly shows
clear advantages on images containing multiple categories, with the cost of
only introducing a single auxiliary loss function and no additional parameters,
validating the effectiveness of NeSy spatial reasoning in OVSS.

</details>


### [83] [3DPR: Single Image 3D Portrait Relight using Generative Priors](https://arxiv.org/abs/2510.15846)
*Pramod Rao,Abhimitra Meka,Xilong Zhou,Gereon Fox,Mallikarjun B R,Fangneng Zhan,Tim Weyrich,Bernd Bickel,Hanspeter Pfister,Wojciech Matusik,Thabo Beeler,Mohamed Elgharib,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: 3DPR利用生成先验和OLAT数据集，通过潜在空间和反射网络实现高质量人脸重光照，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单张肖像图像输入下渲染新颖、重光照视图的欠约束问题，克服传统方法因模型假设和参数化限制的不足。

Method: 提出3DPR模型，利用生成先验和预训练生成头部模型的潜在空间，结合新的多视角4K OLAT数据集训练反射网络。

Result: 3DPR在定量和定性评估中表现优异，特别是在身份保留和光照效果捕捉方面。

Conclusion: 3DPR模型在保留身份信息和捕捉光照效果（如高光、自阴影和次表面散射）方面优于现有方法。

Abstract: Rendering novel, relit views of a human head, given a monocular portrait
image as input, is an inherently underconstrained problem. The traditional
graphics solution is to explicitly decompose the input image into geometry,
material and lighting via differentiable rendering; but this is constrained by
the multiple assumptions and approximations of the underlying models and
parameterizations of these scene components. We propose 3DPR, an image-based
relighting model that leverages generative priors learnt from multi-view
One-Light-at-A-Time (OLAT) images captured in a light stage. We introduce a new
diverse and large-scale multi-view 4K OLAT dataset of 139 subjects to learn a
high-quality prior over the distribution of high-frequency face reflectance. We
leverage the latent space of a pre-trained generative head model that provides
a rich prior over face geometry learnt from in-the-wild image datasets. The
input portrait is first embedded in the latent manifold of such a model through
an encoder-based inversion process. Then a novel triplane-based reflectance
network trained on our lightstage data is used to synthesize high-fidelity OLAT
images to enable image-based relighting. Our reflectance network operates in
the latent space of the generative head model, crucially enabling a relatively
small number of lightstage images to train the reflectance model. Combining the
generated OLATs according to a given HDRI environment maps yields physically
accurate environmental relighting results. Through quantitative and qualitative
evaluations, we demonstrate that 3DPR outperforms previous methods,
particularly in preserving identity and in capturing lighting effects such as
specularities, self-shadows, and subsurface scattering. Project Page:
https://vcai.mpi-inf.mpg.de/projects/3dpr/

</details>


### [84] [Memory-SAM: Human-Prompt-Free Tongue Segmentation via Retrieval-to-Prompt](https://arxiv.org/abs/2510.15849)
*Joongwon Chae,Lihui Luo,Xi Yuan,Dongmei Yu,Zhenglin Chen,Lian Zhang,Peiwu Qin*

Main category: cs.CV

TL;DR: Memory-SAM是一种无需训练和人工提示的舌象分割方法，通过检索生成提示，显著提升分割效果。


<details>
  <summary>Details</summary>
Motivation: 准确的舌象分割对中医分析至关重要，但现有方法需要大量标注数据或依赖人工提示，Memory-SAM旨在解决这些限制。

Method: 提出了一种无需训练、无需人工提示的管道Memory-SAM，通过DINOv3特征和FAISS检索自动生成有效提示，指导SAM2进行分割。

Result: 在600张专家标注图像上测试，Memory-SAM的mIoU达到0.9863，优于FCN和基于检测器的SAM基线方法。

Conclusion: Memory-SAM通过检索生成提示的方式，实现了无需训练和人工干预的高效舌象分割，显著提升了不规则边界的分割效果。

Abstract: Accurate tongue segmentation is crucial for reliable TCM analysis. Supervised
models require large annotated datasets, while SAM-family models remain
prompt-driven. We present Memory-SAM, a training-free, human-prompt-free
pipeline that automatically generates effective prompts from a small memory of
prior cases via dense DINOv3 features and FAISS retrieval. Given a query image,
mask-constrained correspondences to the retrieved exemplar are distilled into
foreground/background point prompts that guide SAM2 without manual clicks or
model fine-tuning. We evaluate on 600 expert-annotated images (300 controlled,
300 in-the-wild). On the mixed test split, Memory-SAM achieves mIoU 0.9863,
surpassing FCN (0.8188) and a detector-to-box SAM baseline (0.1839). On
controlled data, ceiling effects above 0.98 make small differences less
meaningful given annotation variability, while our method shows clear gains
under real-world conditions. Results indicate that retrieval-to-prompt enables
data-efficient, robust segmentation of irregular boundaries in tongue imaging.
The code is publicly available at https://github.com/jw-chae/memory-sam.

</details>


### [85] [BLIP3o-NEXT: Next Frontier of Native Image Generation](https://arxiv.org/abs/2510.15857)
*Jiuhai Chen,Le Xue,Zhiyang Xu,Xichen Pan,Shusheng Yang,Can Qin,An Yan,Honglu Zhou,Zeyuan Chen,Lifu Huang,Tianyi Zhou,Junnan Li,Silvio Savarese,Caiming Xiong,Ran Xu*

Main category: cs.CV

TL;DR: BLIP3o-NEXT是一个开源基础模型，结合自回归和扩散架构，在图像生成和编辑任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 推动原生图像生成的前沿，统一文本到图像生成和图像编辑于单一架构，并解决图像编辑中的挑战。

Method: 采用自回归+扩散架构，自回归模型生成离散图像标记，扩散模型利用这些标记的隐藏状态生成高保真图像。

Result: 在各种文本到图像和图像编辑基准测试中，BLIP3o-NEXT表现优于现有模型。

Conclusion: BLIP3o-NEXT通过结合自回归和扩散模型的优势，实现了图像生成和编辑的新高度，展示了在多种基准测试中的卓越性能。

Abstract: We present BLIP3o-NEXT, a fully open-source foundation model in the BLIP3
series that advances the next frontier of native image generation. BLIP3o-NEXT
unifies text-to-image generation and image editing within a single
architecture, demonstrating strong image generation and image editing
capabilities. In developing the state-of-the-art native image generation model,
we identify four key insights: (1) Most architectural choices yield comparable
performance; an architecture can be deemed effective provided it scales
efficiently and supports fast inference; (2) The successful application of
reinforcement learning can further push the frontier of native image
generation; (3) Image editing still remains a challenging task, yet instruction
following and the consistency between generated and reference images can be
significantly enhanced through post-training and data engine; (4) Data quality
and scale continue to be decisive factors that determine the upper bound of
model performance. Building upon these insights, BLIP3o-NEXT leverages an
Autoregressive + Diffusion architecture in which an autoregressive model first
generates discrete image tokens conditioned on multimodal inputs, whose hidden
states are then used as conditioning signals for a diffusion model to generate
high-fidelity images. This architecture integrates the reasoning strength and
instruction following of autoregressive models with the fine-detail rendering
ability of diffusion models, achieving a new level of coherence and realism.
Extensive evaluations of various text-to-image and image-editing benchmarks
show that BLIP3o-NEXT achieves superior performance over existing models.

</details>


### [86] [BiomedXPro: Prompt Optimization for Explainable Diagnosis with Biomedical Vision Language Models](https://arxiv.org/abs/2510.15866)
*Kaushitha Silva,Mansitha Eashwara,Sanduni Ubayasiri,Ruwan Tennakoon,Damayanthi Herath*

Main category: cs.CV

TL;DR: BiomedXPro是一个进化框架，通过生成多样化且可解释的自然语言提示对，提升了生物医学视觉-语言模型的透明性和诊断准确性，特别适用于数据稀缺的临床场景。


<details>
  <summary>Details</summary>
Motivation: 当前生物医学视觉-语言模型的临床采用受到提示优化技术的限制，这些技术要么产生不可解释的潜在向量，要么产生单一文本提示，缺乏透明性且无法捕捉临床诊断的多方面特性。

Method: BiomedXPro是一个进化框架，利用大型语言模型作为生物医学知识提取器和自适应优化器，自动生成多样化的、可解释的自然语言提示对用于疾病诊断。

Result: 在多个生物医学基准测试中，BiomedXPro一致优于最先进的提示调优方法，特别是在数据稀缺的少样本设置中。此外，分析显示发现的提示与统计学显著的临床特征之间有强烈的语义对齐。

Conclusion: BiomedXPro通过生成多样且可解释的提示对，为模型预测提供了可验证的基础，是开发更可信且与临床一致的AI系统的重要一步。

Abstract: The clinical adoption of biomedical vision-language models is hindered by
prompt optimization techniques that produce either uninterpretable latent
vectors or single textual prompts. This lack of transparency and failure to
capture the multi-faceted nature of clinical diagnosis, which relies on
integrating diverse observations, limits their trustworthiness in high-stakes
settings. To address this, we introduce BiomedXPro, an evolutionary framework
that leverages a large language model as both a biomedical knowledge extractor
and an adaptive optimizer to automatically generate a diverse ensemble of
interpretable, natural-language prompt pairs for disease diagnosis. Experiments
on multiple biomedical benchmarks show that BiomedXPro consistently outperforms
state-of-the-art prompt-tuning methods, particularly in data-scarce few-shot
settings. Furthermore, our analysis demonstrates a strong semantic alignment
between the discovered prompts and statistically significant clinical features,
grounding the model's performance in verifiable concepts. By producing a
diverse ensemble of interpretable prompts, BiomedXPro provides a verifiable
basis for model predictions, representing a critical step toward the
development of more trustworthy and clinically-aligned AI systems.

</details>


### [87] [LightsOut: Diffusion-based Outpainting for Enhanced Lens Flare Removal](https://arxiv.org/abs/2510.15868)
*Shr-Ruei Tsai,Wei-Cheng Chang,Jie-Ying Lee,Chih-Hai Su,Yu-Lun Liu*

Main category: cs.CV

TL;DR: LightsOut是一种基于扩散的图像外绘框架，通过重建离帧光源来增强SIFR方法，无需额外训练即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 镜头光晕显著降低图像质量，影响关键计算机视觉任务，如物体检测和自动驾驶。现有的SIFR方法在离帧光源不完整或缺失时表现不佳。

Method: 利用多任务回归模块和LoRA微调的扩散模型，确保真实且物理一致的图像外绘结果。

Result: 综合实验表明，LightsOut在各种挑战性场景下均能持续提升现有SIFR方法的性能。

Conclusion: LightsOut作为一种通用的即插即用预处理解决方案，无需额外训练即可在各种挑战性场景下持续提升现有SIFR方法的性能。

Abstract: Lens flare significantly degrades image quality, impacting critical computer
vision tasks like object detection and autonomous driving. Recent Single Image
Flare Removal (SIFR) methods perform poorly when off-frame light sources are
incomplete or absent. We propose LightsOut, a diffusion-based outpainting
framework tailored to enhance SIFR by reconstructing off-frame light sources.
Our method leverages a multitask regression module and LoRA fine-tuned
diffusion model to ensure realistic and physically consistent outpainting
results. Comprehensive experiments demonstrate LightsOut consistently boosts
the performance of existing SIFR methods across challenging scenarios without
additional retraining, serving as a universally applicable plug-and-play
preprocessing solution. Project page: https://ray-1026.github.io/lightsout/

</details>


### [88] [Skyfall-GS: Synthesizing Immersive 3D Urban Scenes from Satellite Imagery](https://arxiv.org/abs/2510.15869)
*Jie-Ying Lee,Yi-Ruei Liu,Shr-Ruei Tsai,Wei-Cheng Chang,Chung-Ho Wu,Jiewen Chan,Zhenjun Zhao,Chieh Hubert Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Skyfall-GS 通过结合卫星图像和扩散模型，无需3D注释即可创建大规模3D场景，支持实时探索，并在几何和纹理上表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏大规模高质量的真实世界3D扫描数据，难以训练通用生成模型，因此采用卫星图像和开放域扩散模型的结合来创建大规模3D场景。

Method: 提出了一种课程驱动的迭代细化策略，逐步增强几何完整性和照片级真实感的纹理。

Result: 实验表明，Skyfall-GS 在跨视角一致的几何和真实纹理方面优于现有方法。

Conclusion: Skyfall-GS 是一种无需昂贵3D注释即可创建城市街区规模3D场景的框架，支持实时沉浸式3D探索，通过实验证明其在几何一致性和纹理真实性上优于现有方法。

Abstract: Synthesizing large-scale, explorable, and geometrically accurate 3D urban
scenes is a challenging yet valuable task in providing immersive and embodied
applications. The challenges lie in the lack of large-scale and high-quality
real-world 3D scans for training generalizable generative models. In this
paper, we take an alternative route to create large-scale 3D scenes by
synergizing the readily available satellite imagery that supplies realistic
coarse geometry and the open-domain diffusion model for creating high-quality
close-up appearances. We propose \textbf{Skyfall-GS}, the first city-block
scale 3D scene creation framework without costly 3D annotations, also featuring
real-time, immersive 3D exploration. We tailor a curriculum-driven iterative
refinement strategy to progressively enhance geometric completeness and
photorealistic textures. Extensive experiments demonstrate that Skyfall-GS
provides improved cross-view consistent geometry and more realistic textures
compared to state-of-the-art approaches. Project page:
https://skyfall-gs.jayinnn.dev/

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [89] [OpenEstimate: Evaluating LLMs on Reasoning Under Uncertainty with Real-World Data](https://arxiv.org/abs/2510.15096)
*Alana Renda,Jillian Ross,Michael Cafarella,Jacob Andreas*

Main category: cs.AI

TL;DR: OpenEstimate是一个用于评估语言模型在不确定性下推理能力的多领域基准，发现当前模型生成的先验不准确且过于自信，性能改进有限。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言模型需要处理不完整信息并在不确定性下进行推理，但现有评估多集中于有明确答案的问题，导致模型在不确定性推理方面的表现缺乏充分表征。

Method: 引入OpenEstimate，一个可扩展的多领域基准，用于评估语言模型在需要综合大量背景信息并以概率先验表达预测的数值估计任务上的表现。

Result: 评估发现，语言模型生成的先验通常不准确且过于自信，性能仅轻微受不确定性启发方式影响，而采样策略、推理努力或提示设计的改变对性能影响不大。

Conclusion: OpenEstimate基准为前沿语言模型提供了一个具有挑战性的评估平台，并为开发更擅长概率估计和不确定性推理的模型奠定了基础。

Abstract: Real-world settings where language models (LMs) are deployed -- in domains
spanning healthcare, finance, and other forms of knowledge work -- require
models to grapple with incomplete information and reason under uncertainty. Yet
most LM evaluations focus on problems with well-defined answers and success
criteria. This gap exists in part because natural problems involving
uncertainty are difficult to construct: given that LMs have access to most of
the same knowledge as humans, it is non-trivial to design questions for which
LMs will struggle to produce correct answers, but which humans can answer
reliably. As a result, LM performance on reasoning under uncertainty remains
poorly characterized. To address this gap, we introduce OpenEstimate, an
extensible, multi-domain benchmark for evaluating LMs on numerical estimation
tasks that require models to synthesize significant amounts of background
information and express predictions as probabilistic priors. We assess these
priors for accuracy and calibration, quantifying their usefulness relative to
samples from the true distribution of interest. Across six frontier LMs, we
find that LM-elicited priors are often inaccurate and overconfident.
Performance improves modestly depending on how uncertainty is elicited from the
model, but is largely unaffected by changes in sampling strategy, reasoning
effort, or prompt design. The OpenEstimate benchmark thus offers a challenging
evaluation for frontier LMs and a platform for developing models that are
better at probabilistic estimation and reasoning under uncertainty.

</details>


### [90] [Procedural Game Level Design with Deep Reinforcement Learning](https://arxiv.org/abs/2510.15120)
*Miraç Buğra Özkan*

Main category: cs.AI

TL;DR: 研究提出了一种基于深度强化学习的游戏关卡设计方法，通过两个代理的交互实现动态环境生成和内容解决，展示了AI在创意游戏开发中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用深度强化学习实现动态、可重玩的游戏环境生成，减少手动设计的工作量。

Method: 提出了一种基于Unity 3D环境的深度强化学习方法，使用两个代理：一个负责导航和收集（蜂鸟代理），另一个负责生成和放置可收集对象（浮岛代理）。两者均采用PPO算法进行训练。

Result: 该方法不仅生成了高效且有效的代理行为，还为机器学习驱动的自主游戏关卡设计提供了新机会。

Conclusion: 该研究展示了深度强化学习在游戏关卡设计中的潜力，通过智能代理不仅能生成内容还能解决问题，为AI在创意游戏开发中的应用开辟了新途径。

Abstract: Procedural content generation (PCG) has become an increasingly popular
technique in game development, allowing developers to generate dynamic,
replayable, and scalable environments with reduced manual effort. In this
study, a novel method for procedural level design using Deep Reinforcement
Learning (DRL) within a Unity-based 3D environment is proposed. The system
comprises two agents: a hummingbird agent, acting as a solver, and a floating
island agent, responsible for generating and placing collectible objects
(flowers) on the terrain in a realistic and context-aware manner. The
hummingbird is trained using the Proximal Policy Optimization (PPO) algorithm
from the Unity ML-Agents toolkit. It learns to navigate through the terrain
efficiently, locate flowers, and collect them while adapting to the
ever-changing procedural layout of the island. The island agent is also trained
using the Proximal Policy Optimization (PPO) algorithm. It learns to generate
flower layouts based on observed obstacle positions, the hummingbird's initial
state, and performance feedback from previous episodes. The interaction between
these agents leads to emergent behavior and robust generalization across
various environmental configurations. The results demonstrate that the approach
not only produces effective and efficient agent behavior but also opens up new
opportunities for autonomous game level design driven by machine learning. This
work highlights the potential of DRL in enabling intelligent agents to both
generate and solve content in virtual environments, pushing the boundaries of
what AI can contribute to creative game development processes.

</details>


### [91] [Towards Error Centric Intelligence I, Beyond Observational Learning](https://arxiv.org/abs/2510.15128)
*Marcus A. Thomas*

Main category: cs.AI

TL;DR: 本文认为AGI进展受限于理论而非数据，提出因果机制框架，通过错误发现和修正推动AGI发展。


<details>
  <summary>Details</summary>
Motivation: 当前AGI的发展受限于理论而非数据或规模，作者挑战了柏拉图表示假设，认为仅靠观察不足以保证干预能力。

Method: 通过定义知识、学习、智能、反事实能力和AGI，分析观察学习的局限性，提出三个关键问题，并构建了因果机制的理论框架。

Result: 提出了因果机制的理论框架，包括局部性和自主性原则、独立因果机制的组合性原则，以及可操作的诊断工具。

Conclusion: 本文提出了一种名为‘因果机制’的新方法，旨在通过错误发现和修正来推动AGI的发展，强调假设空间变化的重要性。

Abstract: We argue that progress toward AGI is theory limited rather than data or scale
limited. Building on the critical rationalism of Popper and Deutsch, we
challenge the Platonic Representation Hypothesis. Observationally equivalent
worlds can diverge under interventions, so observational adequacy alone cannot
guarantee interventional competence. We begin by laying foundations,
definitions of knowledge, learning, intelligence, counterfactual competence and
AGI, and then analyze the limits of observational learning that motivate an
error centric shift. We recast the problem as three questions about how
explicit and implicit errors evolve under an agent's actions, which errors are
unreachable within a fixed hypothesis space, and how conjecture and criticism
expand that space. From these questions we propose Causal Mechanics, a
mechanisms first program in which hypothesis space change is a first class
operation and probabilistic structure is used when useful rather than presumed.
We advance structural principles that make error discovery and correction
tractable, including a differential Locality and Autonomy Principle for modular
interventions, a gauge invariant form of Independent Causal Mechanisms for
separability, and the Compositional Autonomy Principle for analogy
preservation, together with actionable diagnostics. The aim is a scaffold for
systems that can convert unreachable errors into reachable ones and correct
them.

</details>


### [92] [HugAgent: Evaluating LLMs in Simulating Human-Like Individual Reasoning on Open-Ended Tasks](https://arxiv.org/abs/2510.15144)
*Chance Jiajie Li,Zhenze Mo,Yuhan Tang,Ao Qu,Jiayi Wu,Kaiya Ivy Zhao,Yulu Gan,Jie Fan,Jiangbo Yu,Hang Jiang,Paul Pu Liang,Jinhua Zhao,Luis Alberto Alonso Pastor,Kent Larson*

Main category: cs.AI

TL;DR: HugAgent是一个新的基准测试，旨在评估机器是否能捕捉人类个体推理的演变方式，而不仅仅是他们的信念。通过双轨设计和实验，揭示了当前LLMs在适应个体推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 为了推进机器中更类似人类的推理愿景，研究人员引入了HugAgent，这是一个用于从平均到个体推理适应的基准测试。

Method: HugAgent采用双轨设计：一个合成轨道用于规模和系统性压力测试，一个人工轨道用于生态有效的“出声”推理数据。

Result: 实验表明，最先进的LLMs在适应个体推理风格和信念轨迹方面仍存在持续的差距。

Conclusion: HugAgent被定位为第一个可扩展的基准测试，用于将机器推理与人类思维的个体性对齐。

Abstract: Simulating human reasoning in open-ended tasks has been a long-standing
aspiration in AI and cognitive science. While large language models now
approximate human responses at scale, they remain tuned to population-level
consensus, often erasing the individuality of reasoning styles and belief
trajectories. To advance the vision of more human-like reasoning in machines,
we introduce HugAgent (Human-Grounded Agent Benchmark), a benchmark for
average-to-individual reasoning adaptation. The task is to predict how a
specific person would reason and update their beliefs in novel scenarios, given
partial evidence of their past views. HugAgent adopts a dual-track design: a
synthetic track for scale and systematic stress tests, and a human track for
ecologically valid, "out-loud" reasoning data. This design enables scalable,
reproducible evaluation of intra-agent fidelity: whether models can capture not
just what people believe, but how their reasoning evolves. Experiments with
state-of-the-art LLMs reveal persistent adaptation gaps, positioning HugAgent
as the first extensible benchmark for aligning machine reasoning with the
individuality of human thought. Our benchmark and chatbot are open-sourced as
HugAgent (https://anonymous.4open.science/r/HugAgent) and TraceYourThinking
(https://anonymous.4open.science/r/trace-your-thinking).

</details>


### [93] [WELD: A Large-Scale Longitudinal Dataset of Emotional Dynamics for Ubiquitous Affective Computing](https://arxiv.org/abs/2510.15221)
*Xiao Sun*

Main category: cs.AI

TL;DR: 论文发布了一个大型、长期的工作场所情绪数据集，用于情感识别和动态建模，验证了数据质量并展示了高预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决真实工作场所环境中情感识别缺乏大规模、纵向数据集的挑战，捕捉员工在COVID-19疫情期间的情绪反应。

Method: 使用深度学习技术对面部表情进行识别，生成七种情绪的概率，并计算32种扩展情绪指标。通过随机森林和LSTM模型进行基线实验。

Result: 数据集在情绪分类和效价预测中分别达到91.2%的准确率和R2=0.84的表现，并成功复现了心理学模式（如周末效应）。

Conclusion: 该论文提出了一个包含733,651条面部表情记录的大型数据集，覆盖了30.5个月的自然办公环境数据，为情感计算领域提供了重要的研究资源。技术验证表明数据集质量高，能够复现已知的心理学模式，并在员工离职预测中表现出完美的预测效度。

Abstract: Automated emotion recognition in real-world workplace settings remains a
challenging problem in affective computing due to the scarcity of large-scale,
longitudinal datasets collected in naturalistic environments. We present a
novel dataset comprising 733,651 facial expression records from 38 employees
collected over 30.5 months (November 2021 to May 2024) in an authentic office
environment. Each record contains seven emotion probabilities (neutral, happy,
sad, surprised, fear, disgusted, angry) derived from deep learning-based facial
expression recognition, along with comprehensive metadata including job roles,
employment outcomes, and personality traits. The dataset uniquely spans the
COVID-19 pandemic period, capturing emotional responses to major societal
events including the Shanghai lockdown and policy changes. We provide 32
extended emotional metrics computed using established affective science
methods, including valence, arousal, volatility, predictability, inertia, and
emotional contagion strength. Technical validation demonstrates high data
quality through successful replication of known psychological patterns (weekend
effect: +192% valence improvement, p < 0.001; diurnal rhythm validated) and
perfect predictive validity for employee turnover (AUC=1.0). Baseline
experiments using Random Forest and LSTM models achieve 91.2% accuracy for
emotion classification and R2 = 0.84 for valence prediction. This is the
largest and longest longitudinal workplace emotion dataset publicly available,
enabling research in emotion recognition, affective dynamics modeling,
emotional contagion, turnover prediction, and emotion-aware system design.

</details>


### [94] [From Checklists to Clusters: A Homeostatic Account of AGI Evaluation](https://arxiv.org/abs/2510.15236)
*Brett Reynolds*

Main category: cs.AI

TL;DR: 本文提出了一种基于因果中心性和持久性的AGI评估新方法，以减少脆弱性和操纵。


<details>
  <summary>Details</summary>
Motivation: 当前AGI评估存在对称权重和快照测试的问题，无法区分持久能力和脆弱表现。

Method: 提出了两个电池兼容的扩展：中心性优先分数和集群稳定性指数家族。

Result: 通过引入因果中心性权重和持久性证据，提高了评估的稳健性。

Conclusion: 本文提出了一种新的AGI评估方法，强调能力的持久性和因果中心性，以减少脆弱性和操纵。

Abstract: Contemporary AGI evaluations report multidomain capability profiles, yet they
typically assign symmetric weights and rely on snapshot scores. This creates
two problems: (i) equal weighting treats all domains as equally important when
human intelligence research suggests otherwise, and (ii) snapshot testing can't
distinguish durable capabilities from brittle performances that collapse under
delay or stress. I argue that general intelligence -- in humans and potentially
in machines -- is better understood as a homeostatic property cluster: a set of
abilities plus the mechanisms that keep those abilities co-present under
perturbation. On this view, AGI evaluation should weight domains by their
causal centrality (their contribution to cluster stability) and require
evidence of persistence across sessions. I propose two battery-compatible
extensions: a centrality-prior score that imports CHC-derived weights with
transparent sensitivity analysis, and a Cluster Stability Index family that
separates profile persistence, durable learning, and error correction. These
additions preserve multidomain breadth while reducing brittleness and gaming. I
close with testable predictions and black-box protocols labs can adopt without
architectural access.

</details>


### [95] [Multi-dimensional Data Analysis and Applications Basing on LLM Agents and Knowledge Graph Interactions](https://arxiv.org/abs/2510.15258)
*Xi Wang,Xianyao Ling,Kun Li,Gang Yin,Liang Zhang,Jiang Wu,Jun Xu,Fu Zhang,Wenbo Lei,Annie Wang,Peng Gong*

Main category: cs.AI

TL;DR: 结合LLM代理与知识图谱的动态交互方法，提升多维数据分析能力，特别适用于产品生态和关系挖掘。


<details>
  <summary>Details</summary>
Motivation: 在大数据时代，从海量、异构且复杂关联的多维数据中提取深度洞察是一大挑战。LLM在自然语言处理中表现优异但存在"幻觉"问题，而知识图谱的静态特性限制了动态交互和分析能力。

Method: 利用LLM代理从非结构化数据中自动提取产品数据，实时构建并可视化知识图谱，通过交互平台支持用户深度探索和分析图节点。

Result: 实验结果表明，该方法在产品生态系统分析、关系挖掘和用户驱动的探索性分析方面具有显著优势。

Conclusion: 该论文提出了一种基于LLM代理与知识图谱交互的多维数据分析方法，为产品生态系统分析、关系挖掘和用户驱动的探索性分析提供了新思路和工具。

Abstract: In the current era of big data, extracting deep insights from massive,
heterogeneous, and complexly associated multi-dimensional data has become a
significant challenge. Large Language Models (LLMs) perform well in natural
language understanding and generation, but still suffer from "hallucination"
issues when processing structured knowledge and are difficult to update in
real-time. Although Knowledge Graphs (KGs) can explicitly store structured
knowledge, their static nature limits dynamic interaction and analytical
capabilities. Therefore, this paper proposes a multi-dimensional data analysis
method based on the interactions between LLM agents and KGs, constructing a
dynamic, collaborative analytical ecosystem. This method utilizes LLM agents to
automatically extract product data from unstructured data, constructs and
visualizes the KG in real-time, and supports users in deep exploration and
analysis of graph nodes through an interactive platform. Experimental results
show that this method has significant advantages in product ecosystem analysis,
relationship mining, and user-driven exploratory analysis, providing new ideas
and tools for multi-dimensional data analysis.

</details>


### [96] [Experience-Driven Exploration for Efficient API-Free AI Agents](https://arxiv.org/abs/2510.15259)
*Chenwei Tang,Jingyu Xing,Xinyu Liu,Zizhou Wang,Jiawei Du,Liangli Zhen,Jiancheng Lv*

Main category: cs.AI

TL;DR: KG-Agent通过结构化交互和混合奖励机制，提升无API环境下GUI操作的效率和战略深度。


<details>
  <summary>Details</summary>
Motivation: 解决现有软件缺乏API时，LLM代理在GUI操作中因局部视觉体验导致的短视决策和低效探索问题。

Method: 提出KG-Agent框架，将原始像素级交互结构化到SA-KG中，并设计基于图拓扑的混合内在奖励机制。

Result: 在Civilization V和Slay the Spire两个复杂环境中，KG-Agent在探索效率和战略深度上优于现有方法。

Conclusion: KG-Agent通过构建状态-动作知识图（SA-KG）和混合内在奖励机制，显著提升了在无API环境下GUI操作的探索效率和战略深度。

Abstract: Most existing software lacks accessible Application Programming Interfaces
(APIs), requiring agents to operate solely through pixel-based Graphical User
Interfaces (GUIs). In this API-free setting, large language model (LLM)-based
agents face severe efficiency bottlenecks: limited to local visual experiences,
they make myopic decisions and rely on inefficient trial-and-error, hindering
both skill acquisition and long-term planning. To address these challenges, we
propose KG-Agent, an experience-driven learning framework that structures an
agent's raw pixel-level interactions into a persistent State-Action Knowledge
Graph (SA-KG). KG-Agent overcomes inefficient exploration by linking
functionally similar but visually distinct GUI states, forming a rich
neighborhood of experience that enables the agent to generalize from a diverse
set of historical strategies. To support long-horizon reasoning, we design a
hybrid intrinsic reward mechanism based on the graph topology, combining a
state value reward for exploiting known high-value pathways with a novelty
reward that encourages targeted exploration. This approach decouples strategic
planning from pure discovery, allowing the agent to effectively value setup
actions with delayed gratification. We evaluate KG-Agent in two complex,
open-ended GUI-based decision-making environments (Civilization V and Slay the
Spire), demonstrating significant improvements in exploration efficiency and
strategic depth over the state-of-the-art methods.

</details>


### [97] [AUGUSTUS: An LLM-Driven Multimodal Agent System with Contextualized User Memory](https://arxiv.org/abs/2510.15261)
*Jitesh Jain,Shubham Maheshwari,Ning Yu,Wen-mei Hwu,Humphrey Shi*

Main category: cs.AI

TL;DR: AUGUSTUS是一个受人类记忆启发的多模态代理系统，通过图结构记忆和语义标签实现高效检索，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统主要关注文本信息的存储，忽视了多模态信号的重要性。受人类记忆的多模态特性启发，研究者提出了AUGUSTUS系统。

Method: 系统包含四个循环连接的阶段：编码、存储、检索和执行，采用图结构的多模态上下文记忆来存储语义标签及其关联上下文，实现高效的概念驱动检索。

Result: AUGUSTUS在ImageNet分类任务中比传统方法快3.5倍，并在MSC基准测试中优于MemGPT。

Conclusion: AUGUSTUS系统通过模拟人类记忆的多模态特性，在效率和性能上超越了传统的多模态RAG方法和MemGPT，展示了其在复杂任务中的潜力。

Abstract: Riding on the success of LLMs with retrieval-augmented generation (RAG),
there has been a growing interest in augmenting agent systems with external
memory databases. However, the existing systems focus on storing text
information in their memory, ignoring the importance of multimodal signals.
Motivated by the multimodal nature of human memory, we present AUGUSTUS, a
multimodal agent system aligned with the ideas of human memory in cognitive
science. Technically, our system consists of 4 stages connected in a loop: (i)
encode: understanding the inputs; (ii) store in memory: saving important
information; (iii) retrieve: searching for relevant context from memory; and
(iv) act: perform the task. Unlike existing systems that use vector databases,
we propose conceptualizing information into semantic tags and associating the
tags with their context to store them in a graph-structured multimodal
contextual memory for efficient concept-driven retrieval. Our system
outperforms the traditional multimodal RAG approach while being 3.5 times
faster for ImageNet classification and outperforming MemGPT on the MSC
benchmark.

</details>


### [98] [WebGen-V Bench: Structured Representation for Enhancing Visual Design in LLM-based Web Generation and Evaluation](https://arxiv.org/abs/2510.15306)
*Kuang-Da Wang,Zhao Wang,Yotaro Shimose,Wei-Yao Wang,Shingo Takamatsu*

Main category: cs.AI

TL;DR: WebGen-V 是一个新的指令到HTML生成基准和框架，通过代理爬取、结构化数据表示和多模态评估协议，提升了数据质量和评估粒度。


<details>
  <summary>Details</summary>
Motivation: 利用LLM在编码和多模态理解方面的最新进展，提升指令到HTML生成的数据质量和评估粒度。

Method: WebGen-V 提出了三个关键创新：(1) 无边界可扩展的代理爬取框架；(2) 结构化的分节数据表示；(3) 分节级多模态评估协议。

Result: 实验验证了结构化数据和分节评估的有效性，以及各组成部分的贡献。

Conclusion: WebGen-V 提供了一个统一的流程，从真实世界数据采集、网页生成到结构化多模态评估，显著提升了指令到HTML生成的数据质量和评估粒度。

Abstract: Witnessed by the recent advancements on leveraging LLM for coding and
multimodal understanding, we present WebGen-V, a new benchmark and framework
for instruction-to-HTML generation that enhances both data quality and
evaluation granularity. WebGen-V contributes three key innovations: (1) an
unbounded and extensible agentic crawling framework that continuously collects
real-world webpages and can leveraged to augment existing benchmarks; (2) a
structured, section-wise data representation that integrates metadata,
localized UI screenshots, and JSON-formatted text and image assets, explicit
alignment between content, layout, and visual components for detailed
multimodal supervision; and (3) a section-level multimodal evaluation protocol
aligning text, layout, and visuals for high-granularity assessment. Experiments
with state-of-the-art LLMs and ablation studies validate the effectiveness of
our structured data and section-wise evaluation, as well as the contribution of
each component. To the best of our knowledge, WebGen-V is the first work to
enable high-granularity agentic crawling and evaluation for instruction-to-HTML
generation, providing a unified pipeline from real-world data acquisition and
webpage generation to structured multimodal assessment.

</details>


### [99] [VERITAS: Leveraging Vision Priors and Expert Fusion to Improve Multimodal Data](https://arxiv.org/abs/2510.15317)
*Tingqiao Xu,Ziru Zeng,Jiayu Chen*

Main category: cs.AI

TL;DR: VERITAS通过整合视觉先验和多LMMs评估提升SFT数据质量，实验证明其有效性，尤其擅长文本丰富和细粒度推理任务。


<details>
  <summary>Details</summary>
Motivation: 当前数据增强方法因视觉感知不足常导致事实错误和幻觉，影响大型多模态模型（LMMs）的性能。

Method: 提出VERITAS流程，结合视觉识别模型（RAM++）和OCR系统（PP-OCRv4）提取结构化视觉先验，利用三种LMMs（GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro）评估原始答案，并通过统计方法融合为高置信度共识分数。随后训练轻量级批评模型（GRPO），并基于批评生成最终精炼答案。

Result: 在六个多模态基准测试中，使用VERITAS处理数据的模型表现优于原始数据，尤其在文本丰富和细粒度推理任务中。批评模型展现出与先进LMMs相当的能力且更高效。

Conclusion: VERITAS通过整合视觉先验和多个先进的大型多模态模型（LMMs），显著提升了监督微调（SFT）数据的质量，并在多个多模态基准测试中验证了其有效性。

Abstract: The quality of supervised fine-tuning (SFT) data is crucial for the
performance of large multimodal models (LMMs), yet current data enhancement
methods often suffer from factual errors and hallucinations due to inadequate
visual perception. To address this challenge, we propose VERITAS, a pipeline
that systematically integrates vision priors and multiple state-of-the-art LMMs
with statistical methods to enhance SFT data quality. VERITAS leverages visual
recognition models (RAM++) and OCR systems (PP-OCRv4) to extract structured
vision priors, which are combined with images, questions, and answers. Three
LMMs (GPT-4o, Gemini-2.5-Pro, Doubao-1.5-pro) evaluate the original answers,
providing critique rationales and scores that are statistically fused into a
high-confidence consensus score serving as ground truth. Using this consensus,
we train a lightweight critic model via Group Relative Policy Optimization
(GRPO), enhancing reasoning capabilities efficiently. Each LMM then refines the
original answers based on the critiques, generating new candidate answers; we
select the highest-scoring one as the final refined answer. Experiments across
six multimodal benchmarks demonstrate that models fine-tuned with data
processed by VERITAS consistently outperform those using raw data, particularly
in text-rich and fine-grained reasoning tasks. Our critic model exhibits
enhanced capability comparable to state-of-the-art LMMs while being
significantly more efficient. We release our pipeline, datasets, and model
checkpoints to advance research in multimodal data optimization.

</details>


### [100] [Towards Flash Thinking via Decoupled Advantage Policy Optimization](https://arxiv.org/abs/2510.15374)
*Zezhong Tan,Hang Gao,Xinhong Ma,Feng Zhang,Ziqiang Dong*

Main category: cs.AI

TL;DR: DEPO是一种新型RL框架，通过优势解耦、长度惩罚和剪裁方法，减少模型无效推理，提升效率且保持准确性。


<details>
  <summary>Details</summary>
Motivation: 现有RL算法虽然提升模型准确性，但存在响应过长和过度推理问题，导致推理延迟和计算消耗增加。

Method: DEPO框架包含三个核心组件：优势解耦算法、难度感知长度惩罚和优势剪裁方法。

Result: DEPO在DeepSeek-Distill-Qwen-7B和1.5B上实现了序列长度减少39%，并减少了无效推理路径。

Conclusion: DEPO框架显著减少了序列长度和无效推理路径，同时在整体准确性上优于基础模型。

Abstract: Recent Large Reasoning Models (LRMs) have achieved remarkable performance in
solving complex problems via supervised fine-tuning (SFT) and reinforcement
learning (RL). Although existing RL algorithms significantly enhance model
accuracy, they still suffer from excessively lengthy responses and overthinking
issues, resulting in increased inference latency and computational consumption,
especially for simple tasks that require minimal reasoning. To address this, we
propose a novel RL framework, DEPO, to reduce inefficient reasoning for models.
Our method mainly consists of three core components: (1) an innovative
advantage decoupled algorithm to guide model reduction of inefficient tokens;
(2) a difficulty-aware length penalty to lower the overall length of model
responses; (3) an advantage clipping method to prevent bias in policy
optimization. In our experiments, applied to DeepSeek-Distill-Qwen-7B and
DeepSeek-Distill-Qwen-1.5B as base models, DEPO achieves a significant
reduction in sequence length by 39% and reduces excessive reasoning paths in
inefficient tokens, while outperforming the base model in overall accuracy.

</details>


### [101] [Advancing Routing-Awareness in Analog ICs Floorplanning](https://arxiv.org/abs/2510.15387)
*Davide Basso,Luca Bortolussi,Mirjana Videnovic-Misic,Husni Habal*

Main category: cs.AI

TL;DR: 该论文提出了一种基于强化学习和关系图卷积神经网络的自动布局引擎，显著提升了模拟集成电路布局和路由的效率，减少了死区和线长，提高了路由成功率。


<details>
  <summary>Details</summary>
Motivation: 模拟集成电路布局的机器学习技术应用受限，主要由于电气和问题特定约束的严格要求，以及布局规划和路由步骤的相互依赖性。布局工程师对现成的路由感知布局解决方案的需求迫切。

Method: 开发了一个基于强化学习和关系图卷积神经网络的自动布局引擎，专门用于生成更易于路由的布局方案。采用了高网格分辨率和精确引脚信息集成，以及动态路由资源估计技术。

Result: 在模拟环境中分析布局和路由效果时，与过去基于学习的最先进技术相比，该方法实现了13.8%的死区减少、40.6%的线长减少和73.4%的路由成功率提升。

Conclusion: 该论文提出的基于强化学习和关系图卷积神经网络的自动布局引擎，通过结合高网格分辨率和精确引脚信息集成，以及动态路由资源估计技术，显著提高了布局和路由的效率，满足了工业标准。

Abstract: The adoption of machine learning-based techniques for analog integrated
circuit layout, unlike its digital counterpart, has been limited by the
stringent requirements imposed by electric and problem-specific constraints,
along with the interdependence of floorplanning and routing steps. In this
work, we address a prevalent concern among layout engineers regarding the need
for readily available routing-aware floorplanning solutions. To this extent, we
develop an automatic floorplanning engine based on reinforcement learning and
relational graph convolutional neural network specifically tailored to
condition the floorplan generation towards more routable outcomes. A
combination of increased grid resolution and precise pin information
integration, along with a dynamic routing resource estimation technique, allows
balancing routing and area efficiency, eventually meeting industrial standards.
When analyzing the place and route effectiveness in a simulated environment,
the proposed approach achieves a 13.8% reduction in dead space, a 40.6%
reduction in wirelength and a 73.4% increase in routing success when compared
to past learning-based state-of-the-art techniques.

</details>


### [102] [Corrigibility Transformation: Constructing Goals That Accept Updates](https://arxiv.org/abs/2510.15395)
*Rubi Hudson*

Main category: cs.AI

TL;DR: 本文定义了可修正性，并提出了一个转换方法，使任何目标可修正且不牺牲性能，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在AI训练过程中，部分学习的目标可能激励AI避免进一步的更新，从而影响安全性和适应性。可修正性作为一种关键安全属性，允许纠正错误和适应人类偏好变化。

Method: 提供可修正性的正式定义，并引入一种转换方法，构建任何目标的可修正版本。该方法通过条件奖励预测实现，并可递归扩展至新创建的代理。

Result: 两个网格世界实验表明，这些可修正目标可以有效学习，并导致期望的行为。

Conclusion: 本文通过定义可修正性并引入一种转换方法，证明了可修正目标可以在不牺牲性能的情况下实现，并通过实验验证了其有效性。

Abstract: For an AI's training process to successfully impart a desired goal, it is
important that the AI does not attempt to resist the training. However,
partially learned goals will often incentivize an AI to avoid further goal
updates, as most goals are better achieved by an AI continuing to pursue them.
We say that a goal is corrigible if it does not incentivize taking actions that
avoid proper goal updates or shutdown. In addition to convergence in training,
corrigibility also allows for correcting mistakes and changes in human
preferences, which makes it a crucial safety property. Despite this, the
existing literature does not include specifications for goals that are both
corrigible and competitive with non-corrigible alternatives. We provide a
formal definition for corrigibility, then introduce a transformation that
constructs a corrigible version of any goal that can be made corrigible,
without sacrificing performance. This is done by myopically eliciting
predictions of reward conditional on costlessly preventing updates, which then
also determine the reward when updates are accepted. The transformation can be
modified to recursively extend corrigibility to any new agents created by
corrigible agents, and to prevent agents from deliberately modifying their
goals. Two gridworld experiments demonstrate that these corrigible goals can be
learned effectively, and that they lead to the desired behavior.

</details>


### [103] [MARS: Reinforcing Multi-Agent Reasoning of LLMs through Self-Play in Strategic Games](https://arxiv.org/abs/2510.15414)
*Huining Yuan,Zelai Xu,Zheyue Tan,Xiangmin Yi,Mo Guang,Kaiwen Long,Haojia Hui,Boxun Li,Xinlei Chen,Bo Zhao,Xiao-Ping Zhang,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: MARS框架通过自博弈强化学习提升LLMs在多智能体系统中的推理能力，显著提升性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索如何使大型语言模型（LLMs）在多智能体系统中更有效地合作与竞争，以提升智能水平。

Method: 提出了MARS框架，包括回合级优势估计器和智能体特定优势归一化，以解决多智能体场景中的信用分配和训练稳定性问题。

Result: 在保留游戏中性能提升高达28.7%，在推理基准测试中多智能体系统性能持续提升，集成到领先多智能体系统后在AIME上提升10.0%，GPQA-Diamond上提升12.5%。

Conclusion: 通过自博弈在战略游戏中进行的端到端强化学习训练，是开发LLMs中可泛化的多智能体推理能力的有效方法。

Abstract: Developing Large Language Models (LLMs) to cooperate and compete effectively
within multi-agent systems is a critical step towards more advanced
intelligence. While reinforcement learning (RL) has proven effective for
enhancing reasoning in single-agent tasks, its extension to multi-turn,
multi-agent scenarios remains underexplored due to the challenges of
long-horizon credit assignment and agent-specific advantage estimation. To
address these challenges, we introduce MARS, an end-to-end RL framework that
incentivizes Multi-Agent Reasoning of LLMs through Self-play in both
cooperative and competitive games. MARS features a turn-level advantage
estimator that aligns learning signals with each interaction for credit
assignment, and an agent-specific advantage normalization to stabilize
multi-agent training. By learning with self-play across cooperative and
competitive games, the MARS agent trained from Qwen3-4B develops strong
strategic abilities that generalize to held-out games with up to 28.7%
performance improvements. More importantly, the capability acquired through
self-play generalizes beyond games, yielding consistent performance gains of
multi-agent systems in reasoning benchmarks. When integrated into leading
multi-agent systems, our MARS agent achieves significant performance gains of
10.0% on AIME and 12.5% on GPQA-Diamond. These results establish end-to-end RL
training with self-play in strategic games as a powerful approach for
developing generalizable multi-agent reasoning capabilities in LLMs. Our code
and models are publicly available at https://github.com/thu-nics/MARS.

</details>


### [104] [Adaptive Minds: Empowering Agents with LoRA-as-Tools](https://arxiv.org/abs/2510.15416)
*Pavan C Shekar,Ashwanth Krishnan*

Main category: cs.AI

TL;DR: Adaptive Minds 是一种代理系统，通过动态选择LoRA工具实现领域专家切换，结合灵活性与效率。


<details>
  <summary>Details</summary>
Motivation: 解决单一微调模型或基于固定规则路由的局限性，实现领域专家间的无缝切换。

Method: 利用LangGraph进行工作流管理，支持API和Web界面，使基础LLM能够作为语义路由器动态选择最相关的LoRA工具。

Result: 系统能够准确提供专业化响应，同时保持对话能力，且完全开源。

Conclusion: Adaptive Minds 提供了一种可扩展且灵活的基础，用于领域自适应AI辅助，结合了多智能体编排的灵活性和参数高效微调的效率。

Abstract: We present Adaptive Minds, an agentic system that treats LoRA adapters as
domain-specific tools. Instead of relying on a single fine-tuned model or rigid
rule-based routing, our approach empowers the base LLM itself to act as a
semantic router analyzing each query and dynamically selecting the most
relevant LoRA tool. This enables the agent to seamlessly switch between
different domain experts on demand. By combining the flexibility of multi-agent
orchestration with the efficiency of parameter-efficient fine-tuning, Adaptive
Minds delivers accurate, specialized responses while preserving conversational
ability. The system is built with LangGraph for workflow management, supports
both API and web interfaces, and is fully open source, providing a scalable and
extensible foundation for domain-adaptive AI assistance.

</details>


### [105] [Taming the Judge: Deconflicting AI Feedback for Stable Reinforcement Learning](https://arxiv.org/abs/2510.15514)
*Boyin Liu,Zhuo Zhang,Sen Huang,Lipeng Xie,Qingxu Fu,Haoran Chen,LI YU,Tianyi Hu,Zhaoyang Liu,Bolin Ding,Dongbin Zhao*

Main category: cs.AI

TL;DR: 论文提出了一个框架，用于检测和解决强化学习中的逻辑不一致问题，包括冲突检测率（CDR）和去冲突图奖励（DGR），显著提升了训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在强化学习中常面临判断不一致问题，尤其是逻辑一致性（如偏好循环）未被充分解决。

Method: 提出了CDR量化判断冲突，DGR通过构建偏好图、转化为无冲突DAG并生成逻辑一致的奖励信号。

Result: 实验表明该框架显著提升了训练稳定性和模型性能。

Conclusion: 逻辑一致性是AI反馈中关键且可管理的维度，该框架有效解决了这一问题。

Abstract: However, this method often faces judgment inconsistencies that can
destabilize reinforcement learning. While prior research has focused on the
accuracy of judgments, the critical issue of logical coherence especially
issues such as preference cycles hasn't been fully addressed. To fill this gap,
we introduce a comprehensive framework designed to systematically detect and
resolve these inconsistencies during the reinforcement learning training
process. Our framework includes two main contributions: first, the Conflict
Detection Rate (CDR), a new metric that quantifies judgment conflicts, and
second, Deconflicted Graph Rewards (DGR), a framework that purifies signals by
removing cycles before policy optimization. DGR constructs preference graphs
from the initial judgments, transforms them into conflict-free Directed Acyclic
Graphs (DAGs), and generates a logically coherent reward signal that is
compatible with any policy optimizer. Experimental results show that our
framework significantly enhances training stability and model performance
compared to strong baselines, establishing logical consistency as a crucial and
now manageable dimension of AI feedback.

</details>


### [106] [Hypergraph Contrastive Sensor Fusion for Multimodal Fault Diagnosis in Induction Motors](https://arxiv.org/abs/2510.15547)
*Usman Ali,Ali Zia,Waqas Ali,Umer Ramzan,Abdul Rehman,Muhammad Tayyab Chaudhry,Wei Xiang*

Main category: cs.AI

TL;DR: MM-HCAN是一种新型多模态超图对比注意力网络，用于鲁棒的感应电机多故障诊断，准确率高达99.82%，具有强泛化能力和抗噪性。


<details>
  <summary>Details</summary>
Motivation: 可靠的感应电机故障诊断对工业安全和操作连续性至关重要。传统方法难以捕捉复杂的多模态信号关系，且受限于单模态数据或单一故障类型。

Method: 提出了多模态超图对比注意力网络（MM-HCAN），一个统一的框架，用于鲁棒的故障诊断。该模型首次将对比学习集成到专门为多模态传感器融合设计的超图拓扑中。

Result: 在三个真实世界基准测试中，MM-HCAN实现了高达99.82%的准确率，具有强大的跨域泛化能力和抗噪性。

Conclusion: MM-HCAN提供了一种可扩展且稳健的解决方案，用于全面的多故障诊断，支持工业环境中的预测性维护和延长资产寿命。

Abstract: Reliable induction motor (IM) fault diagnosis is vital for industrial safety
and operational continuity, mitigating costly unplanned downtime. Conventional
approaches often struggle to capture complex multimodal signal relationships,
are constrained to unimodal data or single fault types, and exhibit performance
degradation under noisy or cross-domain conditions. This paper proposes the
Multimodal Hypergraph Contrastive Attention Network (MM-HCAN), a unified
framework for robust fault diagnosis. To the best of our knowledge, MM-HCAN is
the first to integrate contrastive learning within a hypergraph topology
specifically designed for multimodal sensor fusion, enabling the joint
modelling of intra- and inter-modal dependencies and enhancing generalisation
beyond Euclidean embedding spaces. The model facilitates simultaneous diagnosis
of bearing, stator, and rotor faults, addressing the engineering need for
consolidated di- agnostic capabilities. Evaluated on three real-world
benchmarks, MM-HCAN achieves up to 99.82% accuracy with strong cross-domain
generalisation and resilience to noise, demonstrating its suitability for
real-world deployment. An ablation study validates the contribution of each
component. MM-HCAN provides a scalable and robust solution for comprehensive
multi-fault diagnosis, supporting predictive maintenance and extended asset
longevity in industrial environments.

</details>


### [107] [JudgeSQL: Reasoning over SQL Candidates with Weighted Consensus Tournament](https://arxiv.org/abs/2510.15560)
*Jiayuan Bai,Xuan-guang Pan,Chongyang Tao,Shuai Ma*

Main category: cs.AI

TL;DR: JudgeSQL通过结构化推理和加权共识机制改进SQL候选选择，解决了现有方法的浅层信号问题，在BIRD基准中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有SQL候选选择方法（如自一致性或最佳N解码）的信号浅层问题，包括评分不一致、推理链脆弱及无法捕捉细粒度语义差异。

Method: 提出JudgeSQL框架，包括基于推理的SQL判断模型和加权共识锦标赛机制。判断模型通过强化学习提炼可验证奖励引导的推理轨迹；锦标赛机制结合显式推理偏好与隐式生成器置信度。

Result: 在BIRD基准测试中，JudgeSQL表现出优越的SQL判断能力、良好的跨规模泛化性和对生成器容量的鲁棒性。

Conclusion: JudgeSQL通过结构化推理和加权共识机制显著提升了SQL候选查询的选择能力，展示了优越的SQL判断性能、跨规模泛化能力以及对生成器容量的鲁棒性。

Abstract: Text-to-SQL is a pivotal task that bridges natural language understanding and
structured data access, yet it remains fundamentally challenging due to
semantic ambiguity and complex compositional reasoning. While large language
models (LLMs) have greatly advanced SQL generation though prompting, supervised
finetuning and reinforced tuning, the shift toward test-time scaling exposes a
new bottleneck: selecting the correct query from a diverse candidate pool.
Existing selection approaches, such as self-consistency or best-of-$N$
decoding, provide only shallow signals, making them prone to inconsistent
scoring, fragile reasoning chains, and a failure to capture fine-grained
semantic distinctions between closely related SQL candidates. To this end, we
introduce JudgeSQL, a principled framework that redefines SQL candidate
selection through structured reasoning and weighted consensus tournament
mechanism. JudgeSQL develops a reasoning-based SQL judge model that distills
reasoning traces with reinforcement learning guided by verifiable rewards,
enabling accurate and interpretable judgments. Building on this, a weighted
consensus tournament integrates explicit reasoning preferences with implicit
generator confidence, yielding selections that are both more reliable and more
efficient. Extensive experiments on the BIRD benchmark demonstrate that
JudgeSQL exhibits superior SQL judgment capabilities and good cross-scale
generalization and robustness to generator capacity.

</details>


### [108] [Context-aware deep learning using individualized prior information reduces false positives in disease risk prediction and longitudinal health assessment](https://arxiv.org/abs/2510.15591)
*Lavanya Umapathy,Patricia M Johnson,Tarun Dutt,Angela Tong,Madhur Nayan,Hersh Chandarana,Daniel K Sodickson*

Main category: cs.AI

TL;DR: 通过机器学习整合时间背景信息，显著提升前列腺癌风险预测的特异性，减少假阳性率。


<details>
  <summary>Details</summary>
Motivation: 医疗中的时间背景对于评估患者健康状况的关键变化具有重要价值，尤其是在既往就诊有限且频率不固定的情况下。

Method: 开发了一个机器学习框架，首先利用最近一次就诊的医疗数据估计初始疾病风险，然后通过消化先前收集的影像和/或临床生物标志物信息来细化评估。

Result: 整合先前背景信息直接将假阳性转化为真阴性，提高了整体特异性同时保持高敏感性。假阳性率从51%逐步降低到24%。

Conclusion: 整合时间背景信息能显著提高医疗风险预测的特异性，减少假阳性率，为大规模纵向健康监测项目提供了可能。

Abstract: Temporal context in medicine is valuable in assessing key changes in patient
health over time. We developed a machine learning framework to integrate
diverse context from prior visits to improve health monitoring, especially when
prior visits are limited and their frequency is variable. Our model first
estimates initial risk of disease using medical data from the most recent
patient visit, then refines this assessment using information digested from
previously collected imaging and/or clinical biomarkers. We applied our
framework to prostate cancer (PCa) risk prediction using data from a large
population (28,342 patients, 39,013 magnetic resonance imaging scans, 68,931
blood tests) collected over nearly a decade. For predictions of the risk of
clinically significant PCa at the time of the visit, integrating prior context
directly converted false positives to true negatives, increasing overall
specificity while preserving high sensitivity. False positive rates were
reduced progressively from 51% to 33% when integrating information from up to
three prior imaging examinations, as compared to using data from a single
visit, and were further reduced to 24% when also including additional context
from prior clinical data. For predicting the risk of PCa within five years of
the visit, incorporating prior context reduced false positive rates still
further (64% to 9%). Our findings show that information collected over time
provides relevant context to enhance the specificity of medical risk
prediction. For a wide range of progressive conditions, sufficient reduction of
false positive rates using context could offer a pathway to expand longitudinal
health monitoring programs to large populations with comparatively low baseline
risk of disease, leading to earlier detection and improved health outcomes.

</details>


### [109] [Unleashing Scientific Reasoning for Bio-experimental Protocol Generation via Structured Component-based Reward Mechanism](https://arxiv.org/abs/2510.15600)
*Haoran Sun,Yankai Jiang,Zhenyu Tang,Yaning Pan,Shuang Gu,Zekai Lin,Lilong Wang,Wenjie Lou,Lei Liu,Lei Bai,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出了SciRecipe数据集和“Sketch-and-Fill”范式，开发了Thoth模型，显著提升了协议生成的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的协议不完整或不一致，限制了其在科学再现中的实用性。

Method: 提出了“Sketch-and-Fill”范式，结合结构化组件奖励机制，并通过分阶段的Knowledge-to-Action过程训练Thoth模型。

Result: Thoth在步骤对齐、逻辑顺序和语义准确性方面显著优于其他模型。

Conclusion: Thoth模型在多个基准测试中显著优于现有的大型语言模型，为可靠的科学助手奠定了基础。

Abstract: The foundation of reproducible science lies in protocols that are precise,
logically ordered, and executable. The autonomous generation of these protocols
through natural language queries could greatly improve the efficiency of the
reproduction process. However, current leading large language models (LLMs)
often generate incomplete or inconsistent protocols, limiting their utility. To
address this limitation, we first introduce SciRecipe, a large-scale dataset of
over 12K structured protocols spanning 27 biological subfields and encompassing
both comprehension and problem-solving tasks. To further improve protocol
generation, we propose the "Sketch-and-Fill" paradigm, which separates
analysis, structuring, and expression to ensure each step is explicit and
verifiable. Complementing this, the structured component-based reward mechanism
evaluates step granularity, action order, and semantic fidelity, aligning model
optimization with experimental reliability. Building on these components, we
develop Thoth, trained through a staged Knowledge-to-Action process that
progresses from knowledge acquisition to operational reasoning and ultimately
to robust, executable protocol generation. Across multiple benchmarks, Thoth
consistently surpasses both proprietary and open-source LLMs, achieving
significant improvements in step alignment, logical sequencing, and semantic
accuracy. Our approach paves the way for reliable scientific assistants that
bridge knowledge with experimental execution. All data, code, and models will
be released publicly.

</details>


### [110] [Build Your Personalized Research Group: A Multiagent Framework for Continual and Interactive Science Automation](https://arxiv.org/abs/2510.15624)
*Ed Li,Junyu Ren,Xintian Pan,Cat Yan,Chuanhao Li,Dirk Bergemann,Zhuoran Yang*

Main category: cs.AI

TL;DR: 开源多智能体框架freephdlabor通过动态工作流和模块化架构解决科学自动化系统的局限性，支持持续研究和人类干预。


<details>
  <summary>Details</summary>
Motivation: 现有科学发现自动化系统存在工作流僵化和上下文管理不足的问题，限制了长期研究的进行。本文旨在通过动态、可定制的多智能体框架解决这些问题。

Method: freephdlabor框架采用实时智能体推理确定完全动态的工作流，提供模块化架构、自动上下文压缩、基于工作区的通信、跨会话内存持久化和非阻塞人工干预机制。

Result: freephdlabor框架实现了从构思到实验再到出版准备稿件的端到端研究自动化，支持持续研究程序和人类反馈的整合。

Conclusion: 该论文提出了一个名为freephdlabor的开源多智能体框架，旨在通过动态工作流和模块化架构解决现有科学发现自动化系统中的局限性，推动更广泛的自动化研究应用。

Abstract: The automation of scientific discovery represents a critical milestone in
Artificial Intelligence (AI) research. However, existing agentic systems for
science suffer from two fundamental limitations: rigid, pre-programmed
workflows that cannot adapt to intermediate findings, and inadequate context
management that hinders long-horizon research. We present
\texttt{freephdlabor}, an open-source multiagent framework featuring
\textit{fully dynamic workflows} determined by real-time agent reasoning and a
\coloremph{\textit{modular architecture}} enabling seamless customization --
users can modify, add, or remove agents to address domain-specific
requirements. The framework provides comprehensive infrastructure including
\textit{automatic context compaction}, \textit{workspace-based communication}
to prevent information degradation, \textit{memory persistence} across
sessions, and \textit{non-blocking human intervention} mechanisms. These
features collectively transform automated research from isolated, single-run
attempts into \textit{continual research programs} that build systematically on
prior explorations and incorporate human feedback. By providing both the
architectural principles and practical implementation for building customizable
co-scientist systems, this work aims to facilitate broader adoption of
automated research across scientific domains, enabling practitioners to deploy
interactive multiagent systems that autonomously conduct end-to-end research --
from ideation through experimentation to publication-ready manuscripts.

</details>


### [111] [Direct Preference Optimization with Unobserved Preference Heterogeneity: The Necessity of Ternary Preferences](https://arxiv.org/abs/2510.15716)
*Keertana Chidambaram,Karthik Vinary Seetharaman,Vasilis Syrgkanis*

Main category: cs.AI

TL;DR: 本文提出了解决RLHF中人类评估者多样性和成对反馈限制的方法，通过引入排名和异质性偏好适应，开发了公平性和个性化的理论和算法框架。


<details>
  <summary>Details</summary>
Motivation: 现有的RLHF和DPO方法通常假设统一的注释者偏好并依赖二元比较，忽略了人类评估者的多样性和成对反馈的限制。

Method: 首先将RLHF中的偏好学习与计量经济学文献联系起来，证明二元比较不足以从有限用户数据和无限用户中识别潜在用户偏好，而三个或更多响应的（即使不完整）排名则确保可识别性。其次，引入方法将异质性偏好融入对齐算法，开发了DPO的期望最大化适应版本，发现潜在注释者类型并相应训练混合LLM。然后提出了一种使用最小-最大遗憾公平准则的聚合算法，以产生具有公平性能保证的单一生成策略。

Result: 提出了一种适应异质性偏好的方法，并开发了确保公平性的聚合算法，为生成模型对齐中的公平性和个性化提供了理论基础和实际解决方案。

Conclusion: 本文提出了一个理论和算法框架，用于在生成模型对齐中实现公平性和个性化，解决了人类评估者多样性和成对反馈限制的问题。

Abstract: Reinforcement Learning from Human Feedback (RLHF) has become central to
aligning large language models with human values, typically by first learning a
reward model from preference data which is then used to update the model with
reinforcement learning. Recent alternatives such as Direct Preference
Optimization (DPO) simplify this pipeline by directly optimizing on
preferences. However, both approaches often assume uniform annotator
preferences and rely on binary comparisons, overlooking two key limitations:
the diversity of human evaluators and the limitations of pairwise feedback. In
this work, we address both these issues. First, we connect preference learning
in RLHF with the econometrics literature and show that binary comparisons are
insufficient for identifying latent user preferences from finite user data and
infinite users, while (even incomplete) rankings over three or more responses
ensure identifiability. Second, we introduce methods to incorporate
heterogeneous preferences into alignment algorithms. We develop an
Expectation-Maximization adaptation of DPO that discovers latent annotator
types and trains a mixture of LLMs accordingly. Then we propose an aggregation
algorithm using a min-max regret fairness criterion to produce a single
generative policy with equitable performance guarantees. Together, these
contributions establish a theoretical and algorithmic framework for fairness
and personalization for diverse users in generative model alignment.

</details>


### [112] [Invoice Information Extraction: Methods and Performance Evaluation](https://arxiv.org/abs/2510.15727)
*Sai Yashwant,Anurag Dubey,Praneeth Paikray,Gantala Thulsiram*

Main category: cs.AI

TL;DR: 论文介绍了从发票中提取结构化信息的方法及评估指标，用于标准化比较不同方法的性能。


<details>
  <summary>Details</summary>
Motivation: 动机在于提供一种标准化方法来评估从发票文档中提取结构化信息的准确性，并比较不同提取方法的性能。

Method: 论文方法包括预处理扫描或数字发票，应用Docling和LlamaCloud服务识别和提取关键字段（如发票编号、日期、总金额和供应商详情），并建立一个包含字段级精确度、一致性检查失败和精确匹配准确率的评估框架。

Result: 提出的评估指标能够可靠地评估提取过程的准确性，并突出显示字段特定表现的强弱。

Conclusion: 论文提出了一套评估指标（EM），用于标准化比较不同发票信息提取方法的性能，并强调了字段特定表现的优缺点。

Abstract: This paper presents methods for extracting structured information from
invoice documents and proposes a set of evaluation metrics (EM) to assess the
accuracy of the extracted data against annotated ground truth. The approach
involves pre-processing scanned or digital invoices, applying Docling and
LlamaCloud Services to identify and extract key fields such as invoice number,
date, total amount, and vendor details. To ensure the reliability of the
extraction process, we establish a robust evaluation framework comprising
field-level precision, consistency check failures, and exact match accuracy.
The proposed metrics provide a standardized way to compare different extraction
methods and highlight strengths and weaknesses in field-specific performance.

</details>


### [113] [AURA: An Agent Autonomy Risk Assessment Framework](https://arxiv.org/abs/2510.15739)
*Lorenzo Satta Chiris,Ayush Mishra*

Main category: cs.AI

TL;DR: AURA是一个统一框架，用于检测、量化和缓解自主AI系统的风险，通过gamma风险评分和人机交互机制，支持大规模可治理的AI部署。


<details>
  <summary>Details</summary>
Motivation: 随着自主AI系统的广泛应用，对齐、治理和风险管理方面的挑战阻碍了其规模化部署。AURA旨在解决这些问题，提供一个统一的风险检测、量化和缓解框架。

Method: AURA引入了一种基于gamma的风险评分方法，平衡了风险评估的准确性与计算效率，并设计了人机交互（HITL）监督和Agent-to-Human（A2H）通信机制。

Result: AURA框架能够高效检测和缓解自主AI系统的风险，支持同步或异步运行的多个AI代理，并与现有协议和工具兼容。

Conclusion: AURA框架为大规模、可治理的自主AI系统提供了关键支持，通过其风险评分方法和人机交互机制，实现了透明和负责任的应用。

Abstract: As autonomous agentic AI systems see increasing adoption across
organisations, persistent challenges in alignment, governance, and risk
management threaten to impede deployment at scale. We present AURA (Agent
aUtonomy Risk Assessment), a unified framework designed to detect, quantify,
and mitigate risks arising from agentic AI. Building on recent research and
practical deployments, AURA introduces a gamma-based risk scoring methodology
that balances risk assessment accuracy with computational efficiency and
practical considerations. AURA provides an interactive process to score,
evaluate and mitigate the risks of running one or multiple AI Agents,
synchronously or asynchronously (autonomously). The framework is engineered for
Human-in-the-Loop (HITL) oversight and presents Agent-to-Human (A2H)
communication mechanisms, allowing for seamless integration with agentic
systems for autonomous self-assessment, rendering it interoperable with
established protocols (MCP and A2A) and tools. AURA supports a responsible and
transparent adoption of agentic AI and provides robust risk detection and
mitigation while balancing computational resources, positioning it as a
critical enabler for large-scale, governable agentic AI in enterprise
environments.

</details>


### [114] [Towards Relaxed Multimodal Inputs for Gait-based Parkinson's Disease Assessment](https://arxiv.org/abs/2510.15748)
*Minlin Zeng,Zhipeng Zhou,Yang Qiu,Zhiqi Shen*

Main category: cs.AI

TL;DR: TRIP框架通过多目标优化和类别再平衡策略，显著提升了帕金森病评估的灵活性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态方法在训练和推理阶段对模态同步性和完整性的依赖问题，以及模态融合中的模态崩溃问题。

Method: 提出了一种基于多目标优化（MOO）的多模态学习方法，并引入了基于边界的类别再平衡策略。

Result: 在三个公共数据集上，TRIP框架在异步设置下优于最佳基线16.48、6.89和11.55个百分点，在同步设置下优于4.86和2.30个百分点。

Conclusion: TRIP框架通过多目标优化和类别再平衡策略，显著提升了帕金森病评估的灵活性和性能，在同步和异步设置下均达到最先进水平。

Abstract: Parkinson's disease assessment has garnered growing interest in recent years,
particularly with the advent of sensor data and machine learning techniques.
Among these, multimodal approaches have demonstrated strong performance by
effectively integrating complementary information from various data sources.
However, two major limitations hinder their practical application: (1) the need
to synchronize all modalities during training, and (2) the dependence on all
modalities during inference. To address these issues, we propose the first
Parkinson's assessment system that formulates multimodal learning as a
multi-objective optimization (MOO) problem. This not only allows for more
flexible modality requirements during both training and inference, but also
handles modality collapse issue during multimodal information fusion. In
addition, to mitigate the imbalance within individual modalities, we introduce
a margin-based class rebalancing strategy to enhance category learning. We
conduct extensive experiments on three public datasets under both synchronous
and asynchronous settings. The results show that our framework-Towards Relaxed
InPuts (TRIP)-achieves state-of-the-art performance, outperforming the best
baselines by 16.48, 6.89, and 11.55 percentage points in the asynchronous
setting, and by 4.86 and 2.30 percentage points in the synchronous setting,
highlighting its effectiveness and adaptability.

</details>


### [115] [Preliminary Quantitative Study on Explainability and Trust in AI Systems](https://arxiv.org/abs/2510.15769)
*Allen Daniel Sunny*

Main category: cs.AI

TL;DR: 研究发现交互性和解释质量是提升AI信任的关键，通过贷款审批模拟验证了不同类型解释的效果。


<details>
  <summary>Details</summary>
Motivation: 随着如GPT-4等大规模AI模型在关键领域（如法律、医疗和金融）的快速部署，AI的信任和透明度问题日益紧迫。

Method: 采用定量实验设计，通过基于网络的交互式贷款审批模拟，比较不同类型解释（从基本特征重要性到交互式反事实）对用户信任感知的影响。

Result: 交互性增强了用户参与度和信心，解释的清晰度和相关性是信任的主要决定因素。

Conclusion: 研究表明，解释的清晰度和相关性是影响用户对AI系统信任的关键因素，交互性设计能显著提升用户参与度和信心。

Abstract: Large-scale AI models such as GPT-4 have accelerated the deployment of
artificial intelligence across critical domains including law, healthcare, and
finance, raising urgent questions about trust and transparency. This study
investigates the relationship between explainability and user trust in AI
systems through a quantitative experimental design. Using an interactive,
web-based loan approval simulation, we compare how different types of
explanations, ranging from basic feature importance to interactive
counterfactuals influence perceived trust. Results suggest that interactivity
enhances both user engagement and confidence, and that the clarity and
relevance of explanations are key determinants of trust. These findings
contribute empirical evidence to the growing field of human-centered
explainable AI, highlighting measurable effects of explainability design on
user perception

</details>


### [116] [Self-evolving expertise in complex non-verifiable subject domains: dialogue as implicit meta-RL](https://arxiv.org/abs/2510.15772)
*Richard M. Bailey*

Main category: cs.AI

TL;DR: Dialectica framework enhances LLM agents' expertise in 'wicked problems' through structured dialogue, memory, and reflection, outperforming baselines on multiple metrics.


<details>
  <summary>Details</summary>
Motivation: The research addresses the gap in LLMs' ability to develop expertise through experience in complex, multi-dimensional settings like 'wicked problems'.

Method: The study introduces Dialectica, a framework where agents engage in structured dialogue, augmented by memory, self-reflection, and policy-constrained context editing. Discussion is viewed as an implicit meta-reinforcement learning process.

Result: Results show that reflection-based context editing during discussion produces agents that outperform baseline counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and AlphaRank mass.

Conclusion: Dialogue-driven context evolution is a practical approach to enhancing expertise amplification in open, non-verifiable domains, as supported by both quantitative and qualitative evidence.

Abstract: So-called `wicked problems', those involving complex multi-dimensional
settings, non-verifiable outcomes, heterogeneous impacts and a lack of single
objectively correct answers, have plagued humans throughout history. Modern
examples include decisions over justice frameworks, solving environmental
pollution, planning for pandemic resilience and food security. The use of
state-of-the-art artificial intelligence systems (notably Large Language
Model-based agents) collaborating with humans on solving such problems is being
actively explored. While the abilities of LLMs can be improved by, for example,
fine-tuning, hand-crafted system prompts and scaffolding with external tools,
LLMs lack endogenous mechanisms to develop expertise through experience in such
settings. This work address this gap with Dialectica, a framework where agents
engage in structured dialogue on defined topics, augmented by memory,
self-reflection, and policy-constrained context editing. Formally, discussion
is viewed as an implicit meta-reinforcement learning process. The
`dialogue-trained' agents are evaluated post-hoc using judged pairwise
comparisons of elicited responses. Across two model architectures (locally run
Qwen3:30b and OpenAI's o4-mini) results show that enabling reflection-based
context editing during discussion produces agents which dominate their baseline
counterparts on Elo scores, normalized Bradley-Terry-Davidson ability, and
AlphaRank mass. The predicted signatures of learning are observed qualitatively
in statement and reflection logs, where reflections identify weaknesses and
reliably shape subsequent statements. Agreement between quantitative and
qualitative evidence supports dialogue-driven context evolution as a practical
path to targeted expertise amplification in open non-verifiable domains.

</details>


### [117] [Demo: Guide-RAG: Evidence-Driven Corpus Curation for Retrieval-Augmented Generation in Long COVID](https://arxiv.org/abs/2510.15782)
*Philip DiGiacomo,Haoyang Wang,Jinrui Fang,Yan Leng,W Michael Brode,Ying Ding*

Main category: cs.AI

TL;DR: 研究评估了六种RAG配置，发现结合临床指南和系统评价的配置最佳，提出了Guide-RAG系统以平衡专家知识和文献数据库。


<details>
  <summary>Details</summary>
Motivation: 随着AI聊天机器人在临床医学中的普及，为复杂的新兴疾病开发有效框架面临重大挑战。

Method: 开发并评估了六种检索增强生成（RAG）语料库配置，范围从专家精选来源到大规模文献数据库。使用LLM-as-a-judge框架在忠实性、相关性和全面性指标上进行评估。

Result: 结合临床指南和高质量系统评价的RAG语料库配置在性能上优于单一指南方法和大规模文献数据库。

Conclusion: 研究提出了一种名为Guide-RAG的聊天机器人系统，结合了专家精选知识和全面的文献数据库，以有效回答长新冠（LC）临床问题。

Abstract: As AI chatbots gain adoption in clinical medicine, developing effective
frameworks for complex, emerging diseases presents significant challenges. We
developed and evaluated six Retrieval-Augmented Generation (RAG) corpus
configurations for Long COVID (LC) clinical question answering, ranging from
expert-curated sources to large-scale literature databases. Our evaluation
employed an LLM-as-a-judge framework across faithfulness, relevance, and
comprehensiveness metrics using LongCOVID-CQ, a novel dataset of
expert-generated clinical questions. Our RAG corpus configuration combining
clinical guidelines with high-quality systematic reviews consistently
outperformed both narrow single-guideline approaches and large-scale literature
databases. Our findings suggest that for emerging diseases, retrieval grounded
in curated secondary reviews provides an optimal balance between narrow
consensus documents and unfiltered primary literature, supporting clinical
decision-making while avoiding information overload and oversimplified
guidance. We propose Guide-RAG, a chatbot system and accompanying evaluation
framework that integrates both curated expert knowledge and comprehensive
literature databases to effectively answer LC clinical questions.

</details>


### [118] [PokeeResearch: Effective Deep Research via Reinforcement Learning from AI Feedback and Robust Reasoning Scaffold](https://arxiv.org/abs/2510.15862)
*Yi Wan,Jiuqi Wang,Liam Li,Jinsong Liu,Ruihao Zhu,Zheqing Zhu*

Main category: cs.AI

TL;DR: PokeeResearch-7B是一个7B参数的深度研究代理，通过强化学习和多调用推理设计，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决当前工具增强LLM在检索浅薄、对齐指标弱和工具使用行为脆弱方面的局限性。

Method: 使用无注释的RLAIF框架进行训练，优化策略以捕捉事实准确性、引用忠实性和指令遵循性，并通过多调用推理支架增强稳健性。

Result: 在10个流行的深度研究基准测试中，PokeeResearch-7B在7B规模的研究代理中取得了最先进的性能。

Conclusion: PokeeResearch-7B通过强化学习和推理设计，展现了高效、稳健的研究级AI代理能力，并在7B规模的研究代理中达到最先进性能。

Abstract: Tool-augmented large language models (LLMs) are emerging as deep research
agents, systems that decompose complex queries, retrieve external evidence, and
synthesize grounded responses. Yet current agents remain limited by shallow
retrieval, weak alignment metrics, and brittle tool-use behavior. We introduce
PokeeResearch-7B, a 7B-parameter deep research agent built under a unified
reinforcement learning framework for robustness, alignment, and scalability.
PokeeResearch-7B is trained by an annotation-free Reinforcement Learning from
AI Feedback (RLAIF) framework to optimize policies using LLM-based reward
signals that capture factual accuracy, citation faithfulness, and instruction
adherence. A chain-of-thought-driven multi-call reasoning scaffold further
enhances robustness through self-verification and adaptive recovery from tool
failures. Among 10 popular deep research benchmarks, PokeeResearch-7B achieves
state-of-the-art performance among 7B-scale deep research agents. This
highlights that careful reinforcement learning and reasoning design can produce
efficient, resilient, and research-grade AI agents. The model and inference
code is open-sourced under MIT license at
https://github.com/Pokee-AI/PokeeResearchOSS.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [119] [Fix False Transparency by Noise Guided Splatting](https://arxiv.org/abs/2510.15736)
*Aly El Hakie,Yiren Lu,Yu Yin,Michael Jenkins,Yehe Liu*

Main category: cs.GR

TL;DR: NGS通过注入不透明噪声高斯解决了3DGS中的虚假透明问题，实验证明其有效且对现有方法改动最小。


<details>
  <summary>Details</summary>
Motivation: 3DGS在重建不透明物体时，由于优化过程中缺乏对表面不透明度的显式约束，可能导致虚假透明表面，产生视角不一致的问题。

Method: NGS通过在训练过程中向物体体积内注入不透明噪声高斯，鼓励表面高斯采用更高的不透明度，仅需对现有溅射过程进行最小修改。

Result: 实验表明，NGS显著减少了虚假透明现象，并在多个数据集上验证了其效果。

Conclusion: NGS方法有效减少了3D高斯溅射（3DGS）中的虚假透明问题，同时在标准渲染指标上保持竞争力，证明了其整体有效性。

Abstract: Opaque objects reconstructed by 3DGS often exhibit a falsely transparent
surface, leading to inconsistent background and internal patterns under camera
motion in interactive viewing. This issue stems from the ill-posed optimization
in 3DGS. During training, background and foreground Gaussians are blended via
alpha-compositing and optimized solely against the input RGB images using a
photometric loss. As this process lacks an explicit constraint on surface
opacity, the optimization may incorrectly assign transparency to opaque
regions, resulting in view-inconsistent and falsely transparent. This issue is
difficult to detect in standard evaluation settings but becomes particularly
evident in object-centric reconstructions under interactive viewing. Although
other causes of view-inconsistency have been explored recently, false
transparency has not been explicitly identified. To the best of our knowledge,
we are the first to identify, characterize, and develop solutions for this
artifact, an underreported artifact in 3DGS. Our strategy, NGS, encourages
surface Gaussians to adopt higher opacity by injecting opaque noise Gaussians
in the object volume during training, requiring only minimal modifications to
the existing splatting process. To quantitatively evaluate false transparency
in static renderings, we propose a transmittance-based metric that measures the
severity of this artifact. In addition, we introduce a customized, high-quality
object-centric scan dataset exhibiting pronounced transparency issues, and we
augment popular existing datasets with complementary infill noise specifically
designed to assess the robustness of 3D reconstruction methods to false
transparency. Experiments across multiple datasets show that NGS substantially
reduces false transparency while maintaining competitive performance on
standard rendering metrics, demonstrating its overall effectiveness.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [120] [GaussGym: An open-source real-to-sim framework for learning locomotion from pixels](https://arxiv.org/abs/2510.15352)
*Alejandro Escontrela,Justin Kerr,Arthur Allshire,Jonas Frey,Rocky Duan,Carmelo Sferrazza,Pieter Abbeel*

Main category: cs.RO

TL;DR: 论文提出了一种新方法，将3D高斯泼溅技术集成到物理模拟器中，实现了高速高保真的机器人模拟，适用于多样任务和仿真到现实场景。


<details>
  <summary>Details</summary>
Motivation: 旨在解决机器人模拟中高速度与高视觉保真度难以兼顾的问题，并探索其在仿真到现实机器人应用中的潜力。

Method: 提出了一种新颖的光真实感机器人模拟方法，将3D高斯泼溅作为渲染器集成到向量化物理模拟器（如IsaacGym）中。

Result: 实现了每秒超过100,000步的速度（在消费级GPU上），同时保持高视觉保真度，并在多样任务中展示了其适用性。此外，还展示了其在仿真到现实场景中的应用，以及如何通过丰富视觉语义提升导航和决策能力。

Conclusion: 本论文通过整合3D高斯泼溅技术与向量化物理模拟器，实现了高速度与高视觉保真度的机器人模拟，为可扩展和通用的机器人学习提供了新方向。所有代码和数据将开源供社区使用。

Abstract: We present a novel approach for photorealistic robot simulation that
integrates 3D Gaussian Splatting as a drop-in renderer within vectorized
physics simulators such as IsaacGym. This enables unprecedented speed --
exceeding 100,000 steps per second on consumer GPUs -- while maintaining high
visual fidelity, which we showcase across diverse tasks. We additionally
demonstrate its applicability in a sim-to-real robotics setting. Beyond
depth-based sensing, our results highlight how rich visual semantics improve
navigation and decision-making, such as avoiding undesirable regions. We
further showcase the ease of incorporating thousands of environments from
iPhone scans, large-scale scene datasets (e.g., GrandTour, ARKit), and outputs
from generative video models like Veo, enabling rapid creation of realistic
training worlds. This work bridges high-throughput simulation and high-fidelity
perception, advancing scalable and generalizable robot learning. All code and
data will be open-sourced for the community to build upon. Videos, code, and
data available at https://escontrela.me/gauss_gym/.

</details>


### [121] [Autonomous Reactive Masonry Construction using Collaborative Heterogeneous Aerial Robots with Experimental Demonstration](https://arxiv.org/abs/2510.15114)
*Marios-Nektarios Stamatopoulos,Elias Small,Shridhar Velhal,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 首个完全自主的空中砌筑框架，使用异构无人机（砖块搬运和粘合剂应用），通过实验验证其有效性，为未来机器人建筑奠定基础。


<details>
  <summary>Details</summary>
Motivation: 探索异构无人机在自主空中砌筑中的应用，解决传统建筑方法的局限性，提高施工效率和精度。

Method: 开发了两种专用无人机：砖块搬运无人机（配备球关节驱动机制）和粘合剂应用无人机（配备伺服控制阀和挤出喷嘴）。框架采用反应性任务规划单元，结合依赖图和冲突图管理任务执行，同时分层状态机确保操作稳健。动态任务分配和最小急动轨迹生成实现实时适应和精确运动。砖块搬运无人机还配备了实时砖块姿态估计的视觉系统。

Result: 实验结果表明，所提出的框架在实际砌筑任务中表现有效，验证了异构无人机协同工作的可行性。

Conclusion: 本文通过实验验证展示了首个完全自主的空中砌筑框架，使用异构无人机（UAVs），为未来自主空中机器人建筑奠定了基础。

Abstract: This article presents a fully autonomous aerial masonry construction
framework using heterogeneous unmanned aerial vehicles (UAVs), supported by
experimental validation. Two specialized UAVs were developed for the task: (i)
a brick-carrier UAV equipped with a ball-joint actuation mechanism for precise
brick manipulation, and (ii) an adhesion UAV integrating a servo-controlled
valve and extruder nozzle for accurate adhesion application. The proposed
framework employs a reactive mission planning unit that combines a dependency
graph of the construction layout with a conflict graph to manage simultaneous
task execution, while hierarchical state machines ensure robust operation and
safe transitions during task execution. Dynamic task allocation allows
real-time adaptation to environmental feedback, while minimum-jerk trajectory
generation ensures smooth and precise UAV motion during brick pickup and
placement. Additionally, the brick-carrier UAV employs an onboard vision system
that estimates brick poses in real time using ArUco markers and a least-squares
optimization filter, enabling accurate alignment during construction. To the
best of the authors' knowledge, this work represents the first experimental
demonstration of fully autonomous aerial masonry construction using
heterogeneous UAVs, where one UAV precisely places the bricks while another
autonomously applies adhesion material between them. The experimental results
supported by the video showcase the effectiveness of the proposed framework and
demonstrate its potential to serve as a foundation for future developments in
autonomous aerial robotic construction.

</details>


### [122] [RM-RL: Role-Model Reinforcement Learning for Precise Robot Manipulation](https://arxiv.org/abs/2510.15189)
*Xiangyu Chen,Chuhao Zhou,Yuxi Liu,Jianfei Yang*

Main category: cs.RO

TL;DR: RM-RL框架通过角色模型策略和混合训练，无需人类演示即可高效提升机器人操作精度，实验验证其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高质量专家演示或离线强化学习，但前者难以获取，后者存在数据效率低和分布偏移问题。

Method: 引入角色模型强化学习（RM-RL）框架，结合在线和离线训练，通过角色模型策略自动生成标签，并采用监督训练方式减少分布不匹配问题。

Result: 实验表明RM-RL在收敛速度和稳定性上优于现有方法，翻译和旋转精度分别提升53%和20%，并成功完成高难度任务。

Conclusion: RM-RL框架通过角色模型策略和混合训练方案，显著提升了机器人操作的精确性和数据效率，尤其在需要高精度的任务中表现优异。

Abstract: Precise robot manipulation is critical for fine-grained applications such as
chemical and biological experiments, where even small errors (e.g., reagent
spillage) can invalidate an entire task. Existing approaches often rely on
pre-collected expert demonstrations and train policies via imitation learning
(IL) or offline reinforcement learning (RL). However, obtaining high-quality
demonstrations for precision tasks is difficult and time-consuming, while
offline RL commonly suffers from distribution shifts and low data efficiency.
We introduce a Role-Model Reinforcement Learning (RM-RL) framework that unifies
online and offline training in real-world environments. The key idea is a
role-model strategy that automatically generates labels for online training
data using approximately optimal actions, eliminating the need for human
demonstrations. RM-RL reformulates policy learning as supervised training,
reducing instability from distribution mismatch and improving efficiency. A
hybrid training scheme further leverages online role-model data for offline
reuse, enhancing data efficiency through repeated sampling. Extensive
experiments show that RM-RL converges faster and more stably than existing RL
methods, yielding significant gains in real-world manipulation: 53% improvement
in translation accuracy and 20% in rotation accuracy. Finally, we demonstrate
the successful execution of a challenging task, precisely placing a cell plate
onto a shelf, highlighting the framework's effectiveness where prior methods
fail.

</details>


### [123] [Lagrange-Poincaré-Kepler Equations of Disturbed Space-Manipulator Systems in Orbit](https://arxiv.org/abs/2510.15199)
*Borna Monazzah Moghaddam,Robin Chhabra*

Main category: cs.RO

TL;DR: 论文扩展了LPE模型为LPKE框架，建模非惯性轨道中航天器-机械臂系统的动力学，通过新结构矩阵显式捕获轨道扰动效应，仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有LPE模型未充分涵盖航天器姿态动力学、轨道运动与机械臂运动学的耦合效应，需扩展以适应非惯性轨道参考系中的航天器-机械臂系统建模。

Method: 结合Euler-Poincaré方程、开普勒轨道动力学和简化的Euler-Lagrange方程，利用指数关节参数化和Lagrange-d'Alembert原理，推导了显式捕获轨道扰动效应的结构矩阵。

Result: LPKE框架成功捕获了轨道扰动与机械臂系统的动态耦合，并支持外部对称破坏力的系统集成，适用于硬件在环仿真和模型控制架构。

Conclusion: 该论文提出了LPKE框架，成功扩展了LPE以建模非惯性轨道参考系中的航天器-机械臂系统动力学，并通过仿真验证了其数值优越性。

Abstract: This article presents an extension of the Lagrange-Poincare Equations (LPE)
to model the dynamics of spacecraft-manipulator systems operating within a
non-inertial orbital reference frame. Building upon prior formulations of LPE
for vehicle-manipulator systems, the proposed framework, termed the
Lagrange-Poincare-Kepler Equations (LPKE), incorporates the coupling between
spacecraft attitude dynamics, orbital motion, and manipulator kinematics. The
formalism combines the Euler-Poincare equations for the base spacecraft,
Keplerian orbital dynamics for the reference frame, and reduced Euler-Lagrange
equations for the manipulator's shape space, using an exponential joint
parametrization. Leveraging the Lagrange-d'Alembert principle on principal
bundles, we derive novel closed-form structural matrices that explicitly
capture the effects of orbital disturbances and their dynamic coupling with the
manipulator system. The LPKE framework also systematically includes externally
applied, symmetry-breaking wrenches, allowing for immediate integration into
hardware-in-the-loop simulations and model-based control architectures for
autonomous robotic operations in the orbital environment. To illustrate the
effectiveness of the proposed model and its numerical superiority, we present a
simulation study analyzing orbital effects on a 7-degree-of-freedom manipulator
mounted on a spacecraft.

</details>


### [124] [LVI-Q: Robust LiDAR-Visual-Inertial-Kinematic Odometry for Quadruped Robots Using Tightly-Coupled and Efficient Alternating Optimization](https://arxiv.org/abs/2510.15220)
*Kevin Christiansen Marsim,Minho Oh,Byeongho Yu,Seungjae Lee,I Made Aswin Nahrendra,Hyungtae Lim,Hyun Myung*

Main category: cs.RO

TL;DR: 提出一种鲁棒的LiDAR-视觉-惯性-运动学里程计系统，通过优化和滤波融合方法，在复杂环境中表现优于现有SLAM算法。


<details>
  <summary>Details</summary>
Motivation: 现有传感器融合SLAM算法在复杂动态环境中仍易受估计漂移影响，因依赖不合适的融合策略。

Method: 使用基于优化的视觉-惯性-运动学里程计（VIKO）和基于滤波的LiDAR-惯性-运动学里程计（LIKO）的融合姿态估计方法。VIKO利用足部预积分技术和超像素聚类的LiDAR-视觉深度一致性滑动窗口优化，LIKO则结合足部运动学并在误差状态迭代卡尔曼滤波器（ESIKF）中使用点面残差。

Result: 系统在公开和长期数据集上表现出鲁棒性能。

Conclusion: 提出的LiDAR-视觉-惯性-运动学里程计系统在公开和长期数据集上表现出优于其他传感器融合SLAM算法的鲁棒性能。

Abstract: Autonomous navigation for legged robots in complex and dynamic environments
relies on robust simultaneous localization and mapping (SLAM) systems to
accurately map surroundings and localize the robot, ensuring safe and efficient
operation. While prior sensor fusion-based SLAM approaches have integrated
various sensor modalities to improve their robustness, these algorithms are
still susceptible to estimation drift in challenging environments due to their
reliance on unsuitable fusion strategies. Therefore, we propose a robust
LiDAR-visual-inertial-kinematic odometry system that integrates information
from multiple sensors, such as a camera, LiDAR, inertial measurement unit
(IMU), and joint encoders, for visual and LiDAR-based odometry estimation. Our
system employs a fusion-based pose estimation approach that runs
optimization-based visual-inertial-kinematic odometry (VIKO) and filter-based
LiDAR-inertial-kinematic odometry (LIKO) based on measurement availability. In
VIKO, we utilize the footpreintegration technique and robust LiDAR-visual depth
consistency using superpixel clusters in a sliding window optimization. In
LIKO, we incorporate foot kinematics and employ a point-toplane residual in an
error-state iterative Kalman filter (ESIKF). Compared with other sensor
fusion-based SLAM algorithms, our approach shows robust performance across
public and longterm datasets.

</details>


### [125] [PolyFly: Polytopic Optimal Planning for Collision-Free Cable-Suspended Aerial Payload Transportation](https://arxiv.org/abs/2510.15226)
*Mrunal Sarvaiya,Guanrui Li,Giuseppe Loianno*

Main category: cs.RO

TL;DR: PolyFly是一种全局规划器，通过多面体建模和方向感知优化飞行轨迹，显著提升飞行效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法对飞行器和障碍物进行几何过近似，导致保守机动和飞行时间增加，限制了机器人在紧密约束环境中的飞行能力。

Method: 提出PolyFly全局规划器，采用非保守表示方法，将环境和机器人（四旋翼、电缆和负载）建模为独立多面体，并利用对偶理论将多面体约束转化为平滑可微约束。

Result: 在八种迷宫环境中，PolyFly生成的轨迹比现有方法更快，并在真实四旋翼悬吊负载实验中验证了其可靠性和准确性。

Conclusion: PolyFly通过建模环境和机器人的每个物理组件为独立多面体，并构建方向感知多面体，显著提高了飞行轨迹的效率和准确性。

Abstract: Aerial transportation robots using suspended cables have emerged as versatile
platforms for disaster response and rescue operations. To maximize the
capabilities of these systems, robots need to aggressively fly through tightly
constrained environments, such as dense forests and structurally unsafe
buildings, while minimizing flight time and avoiding obstacles. Existing
methods geometrically over-approximate the vehicle and obstacles, leading to
conservative maneuvers and increased flight times. We eliminate these
restrictions by proposing PolyFly, an optimal global planner which considers a
non-conservative representation for aerial transportation by modeling each
physical component of the environment, and the robot (quadrotor, cable and
payload), as independent polytopes. We further increase the model accuracy by
incorporating the attitude of the physical components by constructing
orientation-aware polytopes. The resulting optimal control problem is
efficiently solved by converting the polytope constraints into smooth
differentiable constraints via duality theory. We compare our method against
the existing state-of-the-art approach in eight maze-like environments and show
that PolyFly produces faster trajectories in each scenario. We also
experimentally validate our proposed approach on a real quadrotor with a
suspended payload, demonstrating the practical reliability and accuracy of our
method.

</details>


### [126] [A Generalized Sylvester-Fermat-Torricelli problem with application in disaster relief operations by UAVs](https://arxiv.org/abs/2510.15229)
*Sina Kazemdehbashi,Yanchao Liu,Boris S. Mordukhovich*

Main category: cs.RO

TL;DR: 提出SFT问题框架，考虑风速和无人机异质性，优化移动无人机站位置，实验显示可减少84%无效操作时间。


<details>
  <summary>Details</summary>
Motivation: 灾害中通信基础设施常被破坏，无人机可作为快速收集信息和建立临时通信网络的有效工具，但实际部署面临风速等挑战。

Method: 开发了一种新的数学框架，将Sylvester问题推广为Sylvester-Fermat-Torricelli（SFT）问题，以统一考虑风速影响、无人机异质性及往返运动。

Result: 实验证明，该框架能减少高达84%的无效操作时间，显著提升灾害响应效率。

Conclusion: 提出的SFT问题框架通过考虑风速、无人机异质性等现实因素，显著提高了无人机在灾害响应中的实用性，实验结果显示可减少高达84%的无效操作时间。

Abstract: Natural and human-made disasters can cause severe devastation and claim
thousands of lives worldwide. Therefore, developing efficient methods for
disaster response and management is a critical task for relief teams. One of
the most essential components of effective response is the rapid collection of
information about affected areas, damages, and victims. More data translates
into better coordination, faster rescue operations, and ultimately, more lives
saved. However, in some disasters, such as earthquakes, the communication
infrastructure is often partially or completely destroyed, making it extremely
difficult for victims to send distress signals and for rescue teams to locate
and assist them in time. Unmanned Aerial Vehicles (UAVs) have emerged as
valuable tools in such scenarios. In particular, a fleet of UAVs can be
dispatched from a mobile station to the affected area to facilitate data
collection and establish temporary communication networks. Nevertheless,
real-world deployment of UAVs faces several challenges, with adverse weather
conditions--especially wind--being among the most significant. To address this,
we develop a novel mathematical framework to determine the optimal location of
a mobile UAV station while explicitly accounting for the heterogeneity of the
UAVs and the effect of wind. In particular, we generalize the Sylvester problem
to introduce the Sylvester-Fermat-Torricelli (SFT) problem, which captures
complex factors such as wind influence, UAV heterogeneity, and back-and-forth
motion within a unified framework. The proposed framework enhances the
practicality of UAV-based disaster response planning by accounting for
real-world factors such as wind and UAV heterogeneity. Experimental results
demonstrate that it can reduce wasted operational time by up to 84%, making
post-disaster missions significantly more efficient and effective.

</details>


### [127] [Traversability-aware Consistent Situational Graphs for Indoor Localization and Mapping](https://arxiv.org/abs/2510.15319)
*Jeewon Kim,Minho Oh,Hyun Myung*

Main category: cs.RO

TL;DR: 该论文提出了一种可通行性感知的房间分割方法，通过考虑机器人与环境的交互，优化了场景图的语义一致性和计算效率，从而提高了位姿图优化的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分割空间特征时，由于视角变化和传感器视场限制，难以一致识别房间，导致过度分割或不足分割，影响位姿图优化的准确性。

Method: 提出了一种可通行性感知的房间分割方法，该方法考虑了机器人与环境的交互，并确保可通行性信息的一致性。

Result: 在重复遍历同一空间的实验中，该方法提高了房间的重新检测频率，并减少了优化时间消耗。

Conclusion: 提出的可通行性感知房间分割方法通过考虑机器人与环境的交互，提高了场景图的语义一致性和计算效率，从而优化了位姿图的性能。

Abstract: Scene graphs enhance 3D mapping capabilities in robotics by understanding the
relationships between different spatial elements, such as rooms and objects.
Recent research extends scene graphs to hierarchical layers, adding and
leveraging constraints across these levels. This approach is tightly integrated
with pose-graph optimization, improving both localization and mapping accuracy
simultaneously. However, when segmenting spatial characteristics, consistently
recognizing rooms becomes challenging due to variations in viewpoints and
limited field of view (FOV) of sensors. For example, existing real-time
approaches often over-segment large rooms into smaller, non-functional spaces
that are not useful for localization and mapping due to the time-dependent
method. Conversely, their voxel-based room segmentation method often
under-segment in complex cases like not fully enclosed 3D space that are
non-traversable for ground robots or humans, leading to false constraints in
pose-graph optimization. We propose a traversability-aware room segmentation
method that considers the interaction between robots and surroundings, with
consistent feasibility of traversability information. This enhances both the
semantic coherence and computational efficiency of pose-graph optimization.
Improved performance is demonstrated through the re-detection frequency of the
same rooms in a dataset involving repeated traversals of the same space along
the same path, as well as the optimization time consumption.

</details>


### [128] [ASBI: Leveraging Informative Real-World Data for Active Black-Box Simulator Tuning](https://arxiv.org/abs/2510.15331)
*Gahee Kim,Takamitsu Matsubara*

Main category: cs.RO

TL;DR: ASBI框架通过主动收集数据和NPE技术，实现了黑盒模拟器参数的准确估计，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 黑盒模拟器在机器人学中广泛应用，但由于无法访问似然函数，参数优化具有挑战性。传统SBI方法在离线观测和模拟中估计后验分布，但在黑盒场景中难以准备包含足够信息的观测数据。

Method: 采用Active Simulation-Based Inference (ASBI)框架，结合Neural Posterior Estimation (NPE)技术，通过优化机器人动作以最大化信息增益来收集信息丰富的观测数据。

Result: 模拟实验验证了ASBI方法的准确性，后验分布集中在真实参数周围。实际机器人实验成功估计了立方体颗粒的模拟参数。

Conclusion: ASBI框架通过主动收集真实世界数据，实现了对黑盒模拟器参数的准确估计，并通过模拟和实际机器人实验验证了其有效性。

Abstract: Black-box simulators are widely used in robotics, but optimizing their
parameters remains challenging due to inaccessible likelihoods.
Simulation-Based Inference (SBI) tackles this issue using simulation-driven
approaches, estimating the posterior from offline real observations and forward
simulations. However, in black-box scenarios, preparing observations that
contain sufficient information for parameter estimation is difficult due to the
unknown relationship between parameters and observations. In this work, we
present Active Simulation-Based Inference (ASBI), a parameter estimation
framework that uses robots to actively collect real-world online data to
achieve accurate black-box simulator tuning. Our framework optimizes robot
actions to collect informative observations by maximizing information gain,
which is defined as the expected reduction in Shannon entropy between the
posterior and the prior. While calculating information gain requires the
likelihood, which is inaccessible in black-box simulators, our method solves
this problem by leveraging Neural Posterior Estimation (NPE), which leverages a
neural network to learn the posterior estimator. Three simulation experiments
quantitatively verify that our method achieves accurate parameter estimation,
with posteriors sharply concentrated around the true parameters. Moreover, we
show a practical application using a real robot to estimate the simulation
parameters of cubic particles corresponding to two real objects, beads and
gravel, with a bucket pouring action.

</details>


### [129] [Adaptive Cost-Map-based Path Planning in Partially Unknown Environments with Movable Obstacles](https://arxiv.org/abs/2510.15336)
*Liviu-Mihai Stan,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Masashi Konyo,Kazunori Ohno*

Main category: cs.RO

TL;DR: 该论文提出了一种轻量级ROS2路径规划框架，使机器人能识别并推开障碍物，提高非结构化环境中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 在灾难响应等非结构化室内环境中，机器人需要不仅能避开障碍物，还能识别哪些障碍物可以被推开，以提高导航可靠性。

Method: 提出了一种基于LiDAR和里程计的自适应路径规划框架，集成到ROS2 Nav2堆栈中，包括新的可移动障碍物层和慢姿态进度检查器。

Result: Gazebo评估显示，相比无层基线，该方法在隔离物体和杂乱走廊中具有更高的目标到达率和更少的死锁，且遍历时间大致相当。

Conclusion: 该研究提出的交互感知成本地图是一种轻量级、ROS2原生的扩展方法，适用于非结构化环境中导航。完整实现将开源。

Abstract: Reliable navigation in disaster-response and other unstructured indoor
settings requires robots not only to avoid obstacles but also to recognise when
those obstacles can be pushed aside. We present an adaptive, LiDAR and
odometry-based path-planning framework that embeds this capability into the
ROS2 Nav2 stack. A new Movable Obstacles Layer labels all LiDAR returns missing
from a prior static map as tentatively movable and assigns a reduced traversal
cost. A companion Slow-Pose Progress Checker monitors the ratio of commanded to
actual velocity; when the robot slows appreciably, the local cost is raised
from light to heavy, and on a stall to lethal, prompting the global planner to
back out and re-route. Gazebo evaluations on a Scout Mini, spanning isolated
objects and cluttered corridors, show higher goal-reach rates and fewer
deadlocks than a no-layer baseline, with traversal times broadly comparable.
Because the method relies only on planar scans and CPU-level computation, it
suits resource-constrained search and rescue robots and integrates into
heterogeneous platforms with minimal engineering. Overall, the results indicate
that interaction-aware cost maps are a lightweight, ROS2-native extension for
navigating among potentially movable obstacles in unstructured settings. The
full implementation will be released as open source
athttps://costmap-namo.github.io.

</details>


### [130] [Nauplius Optimisation for Autonomous Hydrodynamics](https://arxiv.org/abs/2510.15350)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: NOAH是一种新型自然启发群体优化算法，专为水下环境设计，结合流体动力学感知和群体通信，验证成功率达86%。


<details>
  <summary>Details</summary>
Motivation: 传统群体优化方法在强水流、有限声学带宽和持久感知需求下不可靠，NOAH旨在解决这些关键限制。

Method: NOAH结合了当前感知漂移、不可逆的持久感知节点沉降和基于群体的通信，灵感来源于藤壶幼体的行为。

Result: 验证研究显示，在永久锚定场景中成功率达到86%，并提供了流体动力学约束和不可逆沉降行为的统一公式。

Conclusion: NOAH算法为水下群体机器人提供了一个可扩展且能源高效的基础，通过验证分析展示了其有效性。

Abstract: Autonomous Underwater vehicles must operate in strong currents, limited
acoustic bandwidth, and persistent sensing requirements where conventional
swarm optimisation methods are unreliable. This paper presents NOAH, a novel
nature-inspired swarm optimisation algorithm that combines current-aware drift,
irreversible settlement in persistent sensing nodes, and colony-based
communication. Drawing inspiration from the behaviour of barnacle nauplii, NOAH
addresses the critical limitations of existing swarm algorithms by providing
hydrodynamic awareness, irreversible anchoring mechanisms, and colony-based
communication capabilities essential for underwater exploration missions. The
algorithm establishes a comprehensive foundation for scalable and
energy-efficient underwater swarm robotics with validated performance analysis.
Validation studies demonstrate an 86% success rate for permanent anchoring
scenarios, providing a unified formulation for hydrodynamic constraints and
irreversible settlement behaviours with an empirical study under flow.

</details>


### [131] [Towards Automated Chicken Deboning via Learning-based Dynamically-Adaptive 6-DoF Multi-Material Cutting](https://arxiv.org/abs/2510.15376)
*Zhaodong Yang,Ai-Ping Hu,Harish Ravichandar*

Main category: cs.RO

TL;DR: 该研究通过开发模拟器、测试平台和强化学习策略，实现了鸡肩关节的自动化去骨，显著提升了切割效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 自动化鸡肩关节去骨需要精确的6自由度切割，但由于部分遮挡、可变形和多材料关节的特性，接触骨骼会带来严重的健康和安全风险，因此需要开发一种动态适应的切割策略。

Method: 研究采用了开源自定义多材料切割模拟器、可重复物理测试平台以及残差强化学习策略，结合离散力观测和领域随机化，实现了从模拟到现实的零样本迁移。

Result: 实验表明，学习到的策略在模拟器、物理测试平台和真实鸡肩关节上均能可靠地导航关节间隙，减少不必要的骨骼/软骨接触，相比现有开环切割基线，成功率和骨骼避免率提高了4倍。

Conclusion: 该研究通过引入开源模拟器、可重复物理测试平台以及训练残差强化学习策略，成功实现了对鸡肩关节的自动化去骨，显著提高了成功率和骨骼避免率，证明了力反馈在多材料切割中的必要性。

Abstract: Automating chicken shoulder deboning requires precise 6-DoF cutting through a
partially occluded, deformable, multi-material joint, since contact with the
bones presents serious health and safety risks. Our work makes both
systems-level and algorithmic contributions to train and deploy a reactive
force-feedback cutting policy that dynamically adapts a nominal trajectory and
enables full 6-DoF knife control to traverse the narrow joint gap while
avoiding contact with the bones. First, we introduce an open-source
custom-built simulator for multi-material cutting that models coupling,
fracture, and cutting forces, and supports reinforcement learning, enabling
efficient training and rapid prototyping. Second, we design a reusable physical
testbed to emulate the chicken shoulder: two rigid "bone" spheres with
controllable pose embedded in a softer block, enabling rigorous and repeatable
evaluation while preserving essential multi-material characteristics of the
target problem. Third, we train and deploy a residual RL policy, with
discretized force observations and domain randomization, enabling robust
zero-shot sim-to-real transfer and the first demonstration of a learned policy
that debones a real chicken shoulder. Our experiments in our simulator, on our
physical testbed, and on real chicken shoulders show that our learned policy
reliably navigates the joint gap and reduces undesired bone/cartilage contact,
resulting in up to a 4x improvement over existing open-loop cutting baselines
in terms of success rate and bone avoidance. Our results also illustrate the
necessity of force feedback for safe and effective multi-material cutting. The
project website is at https://sites.google.com/view/chickendeboning-2026.

</details>


### [132] [VDRive: Leveraging Reinforced VLA and Diffusion Policy for End-to-end Autonomous Driving](https://arxiv.org/abs/2510.15446)
*Ziang Guo,Zufeng Zhang*

Main category: cs.RO

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: In autonomous driving, dynamic environment and corner cases pose significant
challenges to the robustness of ego vehicle's state understanding and decision
making. We introduce VDRive, a novel pipeline for end-to-end autonomous driving
that explicitly models state-action mapping to address these challenges,
enabling interpretable and robust decision making. By leveraging the
advancement of the state understanding of the Vision Language Action Model
(VLA) with generative diffusion policy-based action head, our VDRive guides the
driving contextually and geometrically. Contextually, VLA predicts future
observations through token generation pre-training, where the observations are
represented as discrete codes by a Conditional Vector Quantized Variational
Autoencoder (CVQ-VAE). Geometrically, we perform reinforcement learning
fine-tuning of the VLA to predict future trajectories and actions based on
current driving conditions. VLA supplies the current state tokens and predicted
state tokens for the action policy head to generate hierarchical actions and
trajectories. During policy training, a learned critic evaluates the actions
generated by the policy and provides gradient-based feedback, forming an
actor-critic framework that enables a reinforcement-based policy learning
pipeline. Experiments show that our VDRive achieves state-of-the-art
performance in the Bench2Drive closed-loop benchmark and nuScenes open-loop
planning.

</details>


### [133] [Perfect Prediction or Plenty of Proposals? What Matters Most in Planning for Autonomous Driving](https://arxiv.org/abs/2510.15505)
*Aron Distelzweig,Faris Janjoš,Oliver Scheel,Sirish Reddy Varra,Raghu Rajan,Joschka Boedecker*

Main category: cs.RO

TL;DR: IPP方法未能有效利用预测信息，提案生成质量是关键。基于PDM的增强方法在复杂场景中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 探讨综合预测与规划（IPP）方法是否真正提升规划性能，尤其是在高度交互和分布外场景中。

Method: 本研究分析了预测在IPP方法中的作用，比较了Val14和interPlan基准测试中的表现，并提出了基于PDM的增强提案生成方法。

Result: 研究发现，即使使用完美的未来预测，规划性能也未提升。增强提案生成方法显著优于现有方法，尤其在复杂场景中。

Conclusion: 当前的综合预测与规划（IPP）方法未能充分利用未来行为信息，而提案生成的质量对规划性能至关重要。基于PDM的增强提案生成方法在高度交互和分布外场景中表现优异，创造了新的最先进成果。

Abstract: Traditionally, prediction and planning in autonomous driving (AD) have been
treated as separate, sequential modules. Recently, there has been a growing
shift towards tighter integration of these components, known as Integrated
Prediction and Planning (IPP), with the aim of enabling more informed and
adaptive decision-making. However, it remains unclear to what extent this
integration actually improves planning performance. In this work, we
investigate the role of prediction in IPP approaches, drawing on the widely
adopted Val14 benchmark, which encompasses more common driving scenarios with
relatively low interaction complexity, and the interPlan benchmark, which
includes highly interactive and out-of-distribution driving situations. Our
analysis reveals that even access to perfect future predictions does not lead
to better planning outcomes, indicating that current IPP methods often fail to
fully exploit future behavior information. Instead, we focus on high-quality
proposal generation, while using predictions primarily for collision checks. We
find that many imitation learning-based planners struggle to generate realistic
and plausible proposals, performing worse than PDM - a simple lane-following
approach. Motivated by this observation, we build on PDM with an enhanced
proposal generation method, shifting the emphasis towards producing diverse but
realistic and high-quality proposals. This proposal-centric approach
significantly outperforms existing methods, especially in out-of-distribution
and highly interactive settings, where it sets new state-of-the-art results.

</details>


### [134] [VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation](https://arxiv.org/abs/2510.15530)
*Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He*

Main category: cs.RO

TL;DR: VO-DP是一种仅基于视觉的扩散策略学习方法，通过融合语义和几何特征，在仿真和实际任务中表现优异，超越了现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏对仅视觉解决方案的深入探索，尽管其具有显著潜力。

Method: 提出了一种仅基于视觉和单视图的扩散策略学习方法（VO-DP），利用预训练的视觉基础模型（VGGT、DINOv2和交替注意力块）融合语义和几何特征，并通过交叉注意力和CNN空间压缩输入策略头。

Result: 在仿真任务中，VO-DP的平均成功率为64.6%，与DP3的64.0%相当，远高于DP的34.8%；在实际任务中，VO-DP达到87.9%，显著优于DP3的67.5%和DP的11.2%。

Conclusion: VO-DP方法在仿真和实际任务中均表现出色，不仅超越了视觉基线DP，还在某些任务中与基于点云的DP3方法相媲美。此外，其鲁棒性评估显示在不同条件下均保持高稳定性。

Abstract: In the context of imitation learning, visuomotor-based diffusion policy
learning is one of the main directions in robotic manipulation. Most of these
approaches rely on point clouds as observation inputs and construct scene
representations through point clouds feature learning, which enables them to
achieve remarkable accuracy. However, the existing literature lacks an in-depth
exploration of vision-only solutions that have significant potential. In this
paper, we propose a Vision-Only and single-view Diffusion Policy learning
method (VO-DP) that leverages pretrained visual foundation models to achieve
effective fusion of semantic and geometric features. We utilize intermediate
features from VGGT incorporating semantic features from DINOv2 and geometric
features from Alternating Attention blocks. Features are fused via
cross-attention and spatially compressed with a CNN to form the input to the
policy head. Extensive experiments demonstrate that VO-DP not only outperforms
the vision-only baseline DP significantly but also exhibits distinct
performance trends against the point cloud-based method DP3: in simulation
tasks, VO-DP achieves an average success rate of 64.6% on par with DP3 64.0%
and far higher than DP 34.8%, while in real-world tasks, it reaches 87.9%,
outperforming both DP3 67.5% and DP 11.2% by a notable margin. Further
robustness evaluations confirm that VO-DP remains highly stable under varying
conditions including color, size, background, and lighting. Lastly, we
open-source a training library for robotic manipulation. Built on Accelerate,
this library supports multi-machine and multi-GPU parallel training, as well as
mixed precision training. It is compatible with visuomotor policies such as DP,
DP3 and VO-DP, and also supports the RoboTwin simulator.

</details>


### [135] [Improved Extended Kalman Filter-Based Disturbance Observers for Exoskeletons](https://arxiv.org/abs/2510.15533)
*Shilei Li,Dawei Shi,Makoto Iwasaki,Yan Ning,Hongpeng Zhou,Ling Shi*

Main category: cs.RO

TL;DR: 本文提出两种新型干扰观测器，显著提升外骨骼跟踪精度，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 机械系统在未知干扰下的性能下降问题，传统两自由度控制结构无法完美抑制未知动态干扰。

Method: 提出了两种新型干扰观测器：交互多模型扩展卡尔曼滤波（IMM-EKF）和多核相关熵扩展卡尔曼滤波（MKCEKF）。

Result: 实验结果显示，与扩展卡尔曼滤波干扰观测器相比，提出的两种方法在髋关节误差上分别提高了36.3%和16.2%，膝关节误差上分别提高了46.3%和24.4%。

Conclusion: 本文提出的两种新型干扰观测器（交互多模型扩展卡尔曼滤波和多核相关熵扩展卡尔曼滤波）在时变交互力场景下显著提高了外骨骼的跟踪精度，验证了方法的优越性。

Abstract: The nominal performance of mechanical systems is often degraded by unknown
disturbances. A two-degree-of-freedom control structure can decouple nominal
performance from disturbance rejection. However, perfect disturbance rejection
is unattainable when the disturbance dynamic is unknown. In this work, we
reveal an inherent trade-off in disturbance estimation subject to tracking
speed and tracking uncertainty. Then, we propose two novel methods to enhance
disturbance estimation: an interacting multiple model extended Kalman
filter-based disturbance observer and a multi-kernel correntropy extended
Kalman filter-based disturbance observer. Experiments on an exoskeleton verify
that the proposed two methods improve the tracking accuracy $36.3\%$ and
$16.2\%$ in hip joint error, and $46.3\%$ and $24.4\%$ in knee joint error,
respectively, compared to the extended Kalman filter-based disturbance
observer, in a time-varying interaction force scenario, demonstrating the
superiority of the proposed method.

</details>


### [136] [Adaptive Legged Locomotion via Online Learning for Model Predictive Control](https://arxiv.org/abs/2510.15626)
*Hongyu Zhou,Xiaoyu Zhang,Vasileios Tzoumas*

Main category: cs.RO

TL;DR: 该论文提出了一种结合在线学习和模型预测控制的算法，使四足机器人能在复杂环境中自适应运动，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为未来自主性四足机器人能够在未知不确定性的现实环境中（如未知负载和不平坦地形）自主执行复杂任务。

Method: 算法由两个模块组成：模型预测控制（MPC）和残差动力学的在线学习。使用随机傅里叶特征在再生核希尔伯特空间中近似残差动力学，并通过最小二乘法在线更新模型。

Result: 算法在Gazebo和MuJoCo模拟中验证有效，四足机器人能够在不同地形和外部干扰下跟踪参考轨迹。

Conclusion: 该算法通过在线学习和模型预测控制的结合，成功实现了四足机器人在复杂环境中的自适应运动，能够处理未知的建模误差和外部干扰。

Abstract: We provide an algorithm for adaptive legged locomotion via online learning
and model predictive control. The algorithm is composed of two interacting
modules: model predictive control (MPC) and online learning of residual
dynamics. The residual dynamics can represent modeling errors and external
disturbances. We are motivated by the future of autonomy where quadrupeds will
autonomously perform complex tasks despite real-world unknown uncertainty, such
as unknown payload and uneven terrains. The algorithm uses random Fourier
features to approximate the residual dynamics in reproducing kernel Hilbert
spaces. Then, it employs MPC based on the current learned model of the residual
dynamics. The model is updated online in a self-supervised manner using least
squares based on the data collected while controlling the quadruped. The
algorithm enjoys sublinear \textit{dynamic regret}, defined as the
suboptimality against an optimal clairvoyant controller that knows how the
residual dynamics. We validate our algorithm in Gazebo and MuJoCo simulations,
where the quadruped aims to track reference trajectories. The Gazebo
simulations include constant unknown external forces up to $12\boldsymbol{g}$,
where $\boldsymbol{g}$ is the gravity vector, in flat terrain, slope terrain
with $20\degree$ inclination, and rough terrain with $0.25m$ height variation.
The MuJoCo simulations include time-varying unknown disturbances with payload
up to $8~kg$ and time-varying ground friction coefficients in flat terrain.

</details>


### [137] [Educational SoftHand-A: Building an Anthropomorphic Hand with Soft Synergies using LEGO MINDSTORMS](https://arxiv.org/abs/2510.15638)
*Jared K. Lepora,Haoran Li,Efi Psomopoulou,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 用LEGO构建的仿人机器人手，双电机驱动肌腱对，通过软协同实现自适应抓取，适合教育。


<details>
  <summary>Details</summary>
Motivation: 设计一款适合教育场景的仿人机器人手，使用常见材料和设备，便于儿童学习和理解现代机器人技术。

Method: 使用标准LEGO部件构建，双电机驱动肌腱对，通过差速机构和离合器齿轮实现软协同。

Result: 实现了自适应抓取多种物体的功能，展示了精细的被动控制能力。

Conclusion: LEGO MINDSTORMS构建的仿人机器人手，采用先进的设计理念，适合教育场景，能激发儿童对现代机器人技术的兴趣。

Abstract: This paper introduces an anthropomorphic robot hand built entirely using LEGO
MINDSTORMS: the Educational SoftHand-A, a tendon-driven, highly-underactuated
robot hand based on the Pisa/IIT SoftHand and related hands. To be suitable for
an educational context, the design is constrained to use only standard LEGO
pieces with tests using common equipment available at home. The hand features
dual motors driving an agonist/antagonist opposing pair of tendons on each
finger, which are shown to result in reactive fine control. The finger motions
are synchonized through soft synergies, implemented with a differential
mechanism using clutch gears. Altogether, this design results in an
anthropomorphic hand that can adaptively grasp a broad range of objects using a
simple actuation and control mechanism. Since the hand can be constructed from
LEGO pieces and uses state-of-the-art design concepts for robotic hands, it has
the potential to educate and inspire children to learn about the frontiers of
modern robotics.

</details>


### [138] [Integration of a Variable Stiffness Link for Long-Reach Aerial Manipulation](https://arxiv.org/abs/2510.15639)
*Manuel J. Fernandez,Alejandro Suarez,Anibal Ollero,Matteo Fumagalli*

Main category: cs.RO

TL;DR: VSL技术通过可调刚度连接，优化了长距离空中操纵的动态交互，平衡了柔性与精度，实验证明其有效性和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统长距离操纵系统依赖刚性或电缆连接，限制了精度或会将干扰传递至飞行器。VSL旨在解决这一问题，提供更灵活的动态交互。

Method: 通过可调刚度机制，VSL能够在柔性绳索和刚性杆之间切换，以适应任务需求。系统搭载于配备LiCAS双机械臂的四旋翼飞行器上，并通过远程操作实验进行评估。

Result: 实验表明，调整链接刚度显著改变了无人机与载荷之间的动态交互。柔性配置减弱了外部冲击和气动扰动，而刚性配置提高了操纵阶段的定位精度。

Conclusion: VSL技术增强了长距离空中操纵的多样性和安全性，提供了可控的柔性与精度平衡。未来工作将集中在自主刚度调节、多绳配置和协作空中操纵等方面。

Abstract: This paper presents the integration of a Variable Stiffness Link (VSL) for
long-reach aerial manipulation, enabling adaptable mechanical coupling between
an aerial multirotor platform and a dual-arm manipulator. Conventional
long-reach manipulation systems rely on rigid or cable connections, which limit
precision or transmit disturbances to the aerial vehicle. The proposed VSL
introduces an adjustable stiffness mechanism that allows the link to behave
either as a flexible rope or as a rigid rod, depending on task requirements.
  The system is mounted on a quadrotor equipped with the LiCAS dual-arm
manipulator and evaluated through teleoperated experiments, involving external
disturbances and parcel transportation tasks. Results demonstrate that varying
the link stiffness significantly modifies the dynamic interaction between the
UAV and the payload. The flexible configuration attenuates external impacts and
aerodynamic perturbations, while the rigid configuration improves positional
accuracy during manipulation phases.
  These results confirm that VSL enhances versatility and safety, providing a
controllable trade-off between compliance and precision. Future work will focus
on autonomous stiffness regulation, multi-rope configurations, cooperative
aerial manipulation and user studies to further assess its impact on
teleoperated and semi-autonomous aerial tasks.

</details>


### [139] [Freehand 3D Ultrasound Imaging: Sim-in-the-Loop Probe Pose Optimization via Visual Servoing](https://arxiv.org/abs/2510.15668)
*Yameng Zhang,Dianye Huang,Max Q. -H. Meng,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: 提出一种低成本、灵活的自由手3D超声成像方法，结合轻量级摄像头和视觉伺服技术，通过模拟环境优化姿态估计，验证了其高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖昂贵跟踪系统，而基于神经网络的方法受图像噪声和误差累积影响，限制了重建精度。

Method: 结合轻量级摄像头和视觉伺服技术，在模拟环境中实现精确的3D超声成像。通过图像恢复方法处理遮挡和光照问题，并采用仿真闭环方法优化姿态估计。

Result: 在软血管模型、3D打印圆锥模型和人臂上的验证显示，与参考重建的Hausdorff距离分别为0.359 mm、1.171 mm和0.858 mm。

Conclusion: 该方法在自由手3D超声成像中展现出可靠性和准确性，验证了其在临床应用的潜力。

Abstract: Freehand 3D ultrasound (US) imaging using conventional 2D probes offers
flexibility and accessibility for diverse clinical applications but faces
challenges in accurate probe pose estimation. Traditional methods depend on
costly tracking systems, while neural network-based methods struggle with image
noise and error accumulation, compromising reconstruction precision. We propose
a cost-effective and versatile solution that leverages lightweight cameras and
visual servoing in simulated environments for precise 3D US imaging. These
cameras capture visual feedback from a textured planar workspace. To counter
occlusions and lighting issues, we introduce an image restoration method that
reconstructs occluded regions by matching surrounding texture patterns. For
pose estimation, we develop a simulation-in-the-loop approach, which replicates
the system setup in simulation and iteratively minimizes pose errors between
simulated and real-world observations. A visual servoing controller refines the
alignment of camera views, improving translational estimation by optimizing
image alignment. Validations on a soft vascular phantom, a 3D-printed conical
model, and a human arm demonstrate the robustness and accuracy of our approach,
with Hausdorff distances to the reference reconstructions of 0.359 mm, 1.171
mm, and 0.858 mm, respectively. These results confirm the method's potential
for reliable freehand 3D US reconstruction.

</details>


### [140] [HEADER: Hierarchical Robot Exploration via Attention-Based Deep Reinforcement Learning with Expert-Guided Reward](https://arxiv.org/abs/2510.15679)
*Yuhong Cao,Yizhuo Wang,Jingsong Liang,Shuhao Liao,Yifeng Zhang,Peizhuo Li,Guillaume Sartoretti*

Main category: cs.RO

TL;DR: HEADER是一种基于注意力的强化学习框架，通过分层图和社区算法提升机器人探索效率，在大规模环境中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有学习型方法在环境规模和探索效率上的局限性。

Method: 采用基于注意力的强化学习方法，结合分层图和社区算法构建全局图，实现线性复杂度的增量更新。

Result: 在模拟环境中探索效率提升高达20%，并在实际复杂场景（如300m*230m校园环境）中验证了有效性。

Conclusion: HEADER在模拟和实际大规模环境中均表现出优越的探索效率和可扩展性，显著优于现有方法。

Abstract: This work pushes the boundaries of learning-based methods in autonomous robot
exploration in terms of environmental scale and exploration efficiency. We
present HEADER, an attention-based reinforcement learning approach with
hierarchical graphs for efficient exploration in large-scale environments.
HEADER follows existing conventional methods to construct hierarchical
representations for the robot belief/map, but further designs a novel
community-based algorithm to construct and update a global graph, which remains
fully incremental, shape-adaptive, and operates with linear complexity.
Building upon attention-based networks, our planner finely reasons about the
nearby belief within the local range while coarsely leveraging distant
information at the global scale, enabling next-best-viewpoint decisions that
consider multi-scale spatial dependencies. Beyond novel map representation, we
introduce a parameter-free privileged reward that significantly improves model
performance and produces near-optimal exploration behaviors, by avoiding
training objective bias caused by handcrafted reward shaping. In simulated
challenging, large-scale exploration scenarios, HEADER demonstrates better
scalability than most existing learning and non-learning methods, while
achieving a significant improvement in exploration efficiency (up to 20%) over
state-of-the-art baselines. We also deploy HEADER on hardware and validate it
in complex, large-scale real-life scenarios, including a 300m*230m campus
environment.

</details>


### [141] [Few-Shot Demonstration-Driven Task Coordination and Trajectory Execution for Multi-Robot Systems](https://arxiv.org/abs/2510.15686)
*Taehyeon Kim,Vishnunandan L. N. Venkatesh,Byung-Cheol Min*

Main category: cs.RO

TL;DR: 提出了一种名为DDACE的小样本学习框架，用于多机器人系统，通过解耦时间和空间方面，显著减少了数据需求，并在实验中验证了其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提出了一种新颖的小样本学习框架，用于整合空间和时间元素的多机器人系统，旨在减少传统示范学习方法的数据需求。

Method: 该方法利用时间图网络学习任务无关的时间序列，并使用高斯过程进行空间轨迹建模，确保跨各种任务的模块化和泛化能力。

Result: 实验结果表明，该方法在小样本学习条件下成功实现了任务执行，并在动态和多样化环境中有效地泛化。

Conclusion: This工作强调了模块化架构在增强多机器人系统在现实应用中的实用性和可扩展性方面的潜力。

Abstract: In this paper, we propose a novel few-shot learning framework for multi-robot
systems that integrate both spatial and temporal elements: Few-Shot
Demonstration-Driven Task Coordination and Trajectory Execution (DDACE). Our
approach leverages temporal graph networks for learning task-agnostic temporal
sequencing and Gaussian Processes for spatial trajectory modeling, ensuring
modularity and generalization across various tasks. By decoupling temporal and
spatial aspects, DDACE requires only a small number of demonstrations,
significantly reducing data requirements compared to traditional learning from
demonstration approaches. To validate our proposed framework, we conducted
extensive experiments in task environments designed to assess various aspects
of multi-robot coordination-such as multi-sequence execution, multi-action
dynamics, complex trajectory generation, and heterogeneous configurations. The
experimental results demonstrate that our approach successfully achieves task
execution under few-shot learning conditions and generalizes effectively across
dynamic and diverse settings. This work underscores the potential of modular
architectures in enhancing the practicality and scalability of multi-robot
systems in real-world applications. Additional materials are available at
https://sites.google.com/view/ddace.

</details>


### [142] [DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation](https://arxiv.org/abs/2510.15786)
*Xinyue Xu,Jieqiang Sun,Jing,Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Yiwen Lu*

Main category: cs.RO

TL;DR: DexCanvas是一个大规模混合真实-合成的人手操作数据集，结合真实演示、系统性技能覆盖和物理验证接触注释，用于机器人操作学习等研究。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据集在规模、技能覆盖和物理验证方面的不足，DexCanvas旨在提供一个结合大规模真实演示、系统性技能覆盖和物理验证接触注释的数据集。

Method: 使用强化学习训练策略，控制物理模拟中的驱动MANO手，复现人类演示并发现生成观察物体运动的潜在接触力。

Result: DexCanvas包含7,000小时的手-物体交互数据，基于70小时的真实人类演示，覆盖21种基础操作类型，提供多视角RGB-D、高精度动捕（MANO手参数）和每帧接触点（物理一致力剖面）。

Conclusion: DexCanvas数据集通过结合大规模真实演示、系统性技能覆盖和物理验证的接触注释，为机器人操作学习、接触丰富控制和不同手形态间的技能转移研究提供了重要资源。

Abstract: We present DexCanvas, a large-scale hybrid real-synthetic human manipulation
dataset containing 7,000 hours of dexterous hand-object interactions seeded
from 70 hours of real human demonstrations, organized across 21 fundamental
manipulation types based on the Cutkosky taxonomy. Each entry combines
synchronized multi-view RGB-D, high-precision mocap with MANO hand parameters,
and per-frame contact points with physically consistent force profiles. Our
real-to-sim pipeline uses reinforcement learning to train policies that control
an actuated MANO hand in physics simulation, reproducing human demonstrations
while discovering the underlying contact forces that generate the observed
object motion. DexCanvas is the first manipulation dataset to combine
large-scale real demonstrations, systematic skill coverage based on established
taxonomies, and physics-validated contact annotations. The dataset can
facilitate research in robotic manipulation learning, contact-rich control, and
skill transfer across different hand morphologies.

</details>


### [143] [Dynamic Recalibration in LiDAR SLAM: Integrating AI and Geometric Methods with Real-Time Feedback Using INAF Fusion](https://arxiv.org/abs/2510.15803)
*Zahra Arjmandi,Gunho Sohn*

Main category: cs.RO

TL;DR: 提出了一种基于INAF模块的LiDAR SLAM融合技术，通过动态调整注意力权重提升定位和3D建图精度，展示了在复杂场景中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 旨在提高LiDAR传感器在定位和3D建图中的应用精度，增强系统在复杂环境中的适应性和测量准确性。

Method: 采用Inferred Attention Fusion (INAF)模块，结合AI与几何里程计，利用KITTI数据集的LiDAR数据动态调整注意力权重。

Result: 该方法显著提升了定位和3D建图的精确度。

Conclusion: 该论文提出了一种新颖的LiDAR SLAM融合技术，展示了其在复杂场景中提升自主导航系统性能的潜力。

Abstract: This paper presents a novel fusion technique for LiDAR Simultaneous
Localization and Mapping (SLAM), aimed at improving localization and 3D mapping
using LiDAR sensor. Our approach centers on the Inferred Attention Fusion
(INAF) module, which integrates AI with geometric odometry. Utilizing the KITTI
dataset's LiDAR data, INAF dynamically adjusts attention weights based on
environmental feedback, enhancing the system's adaptability and measurement
accuracy. This method advances the precision of both localization and 3D
mapping, demonstrating the potential of our fusion technique to enhance
autonomous navigation systems in complex scenarios.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [144] [Targeted Attacks and Defenses for Distributed Federated Learning in Vehicular Networks](https://arxiv.org/abs/2510.15109)
*Utku Demir,Tugba Erpek,Yalin E. Sagduyu,Sastry Kompella,Mengran Xue*

Main category: cs.NI

TL;DR: 论文探讨了分布式联邦学习在车辆网络中的抗攻击能力，设计了针对性攻击并提出了防御机制。


<details>
  <summary>Details</summary>
Motivation: 在边缘计算环境中，传统FL依赖中心服务器的模式存在计算负担和连接限制问题，DFL虽具优势但仍面临高级网络攻击的威胁。

Method: 设计了针对性的训练数据投毒和后门（木马）攻击，并分析了车辆网络中的漏洞。

Result: DFL在对抗攻击方面表现出比个体学习更强的韧性，并提出了有效的防御策略。

Conclusion: 分布式联邦学习（DFL）相比传统联邦学习（FL）和个体学习具有更强的抗攻击能力，但仍需进一步防御机制以应对新兴网络威胁。

Abstract: In emerging networked systems, mobile edge devices such as ground vehicles
and unmanned aerial system (UAS) swarms collectively aggregate vast amounts of
data to make machine learning decisions such as threat detection in remote,
dynamic, and infrastructure-constrained environments where power and bandwidth
are scarce. Federated learning (FL) addresses these constraints and privacy
concerns by enabling nodes to share local model weights for deep neural
networks instead of raw data, facilitating more reliable decision-making than
individual learning. However, conventional FL relies on a central server to
coordinate model updates in each learning round, which imposes significant
computational burdens on the central node and may not be feasible due to the
connectivity constraints. By eliminating dependence on a central server,
distributed federated learning (DFL) offers scalability, resilience to node
failures, learning robustness, and more effective defense strategies. Despite
these advantages, DFL remains vulnerable to increasingly advanced and stealthy
cyberattacks. In this paper, we design sophisticated targeted training data
poisoning and backdoor (Trojan) attacks, and characterize the emerging
vulnerabilities in a vehicular network. We analyze how DFL provides resilience
against such attacks compared to individual learning and present effective
defense mechanisms to further strengthen DFL against the emerging cyber
threats.

</details>


### [145] [Structural Generalization for Microservice Routing Using Graph Neural Networks](https://arxiv.org/abs/2510.15210)
*Chenrui Hu,Ziyu Cheng,Di Wu,Yuxiao Wang,Feng Liu,Zhimin Qiu*

Main category: cs.NI

TL;DR: 该论文提出了一种基于图神经网络的智能路由优化框架，通过建模微服务调用关系为图并引入注意力机制，显著提升了路由效率和系统性能。


<details>
  <summary>Details</summary>
Motivation: 旨在提高复杂拓扑下的路由决策效率和整体系统性能。

Method: 提出了一种基于图神经网络的端到端优化框架，将微服务间的调用关系建模为图，利用多层图神经网络进行高阶信息聚合和结构建模，并引入边缘感知注意力机制以更准确地捕捉服务通信中的不稳定性和瓶颈风险。

Result: 实验结果表明，该方法在路由准确性、预测误差和系统稳定性等多个关键指标上优于现有主流策略。

Conclusion: 该方法在多个关键指标上优于现有主流策略，能够有效处理高动态和高并发的微服务环境，展现出强大的性能、鲁棒性和结构泛化能力。

Abstract: This paper focuses on intelligent routing in microservice systems and
proposes an end-to-end optimization framework based on graph neural networks.
The goal is to improve routing decision efficiency and overall system
performance under complex topologies. The method models invocation
relationships among microservices as a graph. In this graph, service nodes and
communication links are treated as graph nodes and edges. Multi-dimensional
features such as node states, link latency, and call frequency are used as
input. A multi-layer graph neural network is employed to perform high-order
information aggregation and structural modeling. The model outputs a score for
each candidate service path. These scores are then used to guide dynamic
routing decisions. To improve the model's ability to assess path quality, an
edge-aware attention mechanism is introduced. This mechanism helps the model
capture instability and bottleneck risks in service communications more
accurately. The paper also conducts a systematic analysis of the model's
performance under different network depths, topology densities, and service
scales. It evaluates the effectiveness of the method in terms of routing
accuracy, prediction error, and system stability. Experimental results show
that the proposed method outperforms existing mainstream strategies across
multiple key metrics. It handles highly dynamic and concurrent microservice
environments effectively and demonstrates strong performance, robustness, and
structural generalization.

</details>


### [146] [Content and Access Networks Synergies: Tradeoffs in Public and Private Investments by Content Providers](https://arxiv.org/abs/2510.15373)
*Pranay Agarwal,D. Manjunath*

Main category: cs.NI

TL;DR: 研究探讨了CPs在公共和私人投资之间的权衡，分析了四种交互模型的影响，发现议价博弈可能带来更高的公共投资，但私人投资的激励会削弱这一优势。


<details>
  <summary>Details</summary>
Motivation: 智能手机的普及导致全球内容消费增加，对更佳互联网体验的需求不断上升，这需要升级接入网络的容量。ISP要求CPs分担升级接入网络基础设施的成本。

Method: 考虑了四种CPs之间的交互模型——集中分配、合作博弈、非合作博弈和议价博弈，并为每种模型确定了公共和私人投资。

Result: 通过数值结果评估了不同激励结构对CPs效用的影响。议价博弈模型可能导致更高的公共投资。

Conclusion: 研究发现，议价博弈模型可能导致比非合作和集中式模型更高的公共投资，但如果CPs被激励投资于私人基础设施，这种优势会减弱。

Abstract: The ubiquity of smartphones has fueled content consumption worldwide, leading
to an ever-increasing demand for a better Internet experience. This has
necessitated an upgrade of the capacity of the access network. The Internet
service providers (ISPs) have been demanding that the content providers (CPs)
share the cost of upgrading access network infrastructure. A \emph{public
investment} in the infrastructure of a neutral ISP will boost the profit of the
CPs, and hence, seems a rational strategy. A CP can also make a \emph{private
investment} in its infrastructure and boost its profits. In this paper, we
study the trade-off between public and private investments by a CP when the
decision is made under different types of interaction between them.
Specifically, we consider four interaction models between CPs -- centralized
allocation, cooperative game, non-cooperative game, and a bargaining game --
and determine the public and private investment for each model. Via numerical
results, we evaluate the impact of different incentive structures on the
utility of the CPs. We see that the bargaining game can result in higher public
investment than the non-cooperative and centralized models. However, this
benefit gets reduced if the CPs are incentivized to invest in private
infrastructure.

</details>


### [147] [Uno: A One-Stop Solution for Inter- and Intra-Datacenter Congestion Control and Reliable Connectivity](https://arxiv.org/abs/2510.15802)
*Tommaso Bonato,Sepehr Abdous,Abdul Kabbani,Ahmad Ghalayini,Nadeen Gebara,Terry Lam,Anup Agarwal,Tiancheng Chen,Zhuolong Yu,Konstantin Taranov,Mahmoud Elhaddad,Daniele De Sensi,Soudeh Ghorbani,Torsten Hoefler*

Main category: cs.NI

TL;DR: Uno系统通过统一协议和负载均衡方案，有效解决了数据中心内外流量共存带来的拥塞和路由问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 云计算和AI工作负载导致数据中心内外通信需求激增，但现有解决方案未能有效处理内外流量共存带来的拥塞管理和路由问题。

Method: 提出Uno系统，整合传输协议与负载均衡方案，包括快速拥塞反应、公平速率控制、纠删码和自适应路由。

Result: Uno显著提升了数据中心内外流量的完成时间，优于现有方法如Gemini。

Conclusion: Uno系统通过整合快速拥塞反应和公平速率控制的传输协议，以及结合纠删码与自适应路由的负载均衡方案，显著提升了数据中心内外流量的完成时间。

Abstract: Cloud computing and AI workloads are driving unprecedented demand for
efficient communication within and across datacenters. However, the coexistence
of intra- and inter-datacenter traffic within datacenters plus the disparity
between the RTTs of intra- and inter-datacenter networks complicates congestion
management and traffic routing. Particularly, faster congestion responses of
intra-datacenter traffic causes rate unfairness when competing with slower
inter-datacenter flows. Additionally, inter-datacenter messages suffer from
slow loss recovery and, thus, require reliability. Existing solutions overlook
these challenges and handle inter- and intra-datacenter congestion with
separate control loops or at different granularities. We propose Uno, a unified
system for both inter- and intra-DC environments that integrates a transport
protocol for rapid congestion reaction and fair rate control with a load
balancing scheme that combines erasure coding and adaptive routing. Our
findings show that Uno significantly improves the completion times of both
inter- and intra-DC flows compared to state-of-the-art methods such as Gemini.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [148] [Automated Snippet-Alignment Data Augmentation for Code Translation](https://arxiv.org/abs/2510.15004)
*Zhiming Zhang,Qingfu Zhu,Xianzhen Luo,Yixuan Wang,Bohan Li,Wanxiang Che*

Main category: cs.SE

TL;DR: 本文提出利用LLM自动生成SA数据并结合两阶段训练策略，显著提升了代码翻译性能。


<details>
  <summary>Details</summary>
Motivation: 由于并行语料库有限，且现有研究主要关注PA数据的增强，本文旨在通过自动生成SA数据并有效结合PA和SA数据来提升代码翻译模型的性能。

Method: 提出了一种利用LLM自动生成SA数据的数据增强方法，并探索了一种简单有效的两阶段训练策略。

Result: 实验结果表明，增强的SA数据与两阶段训练策略相比仅使用PA数据进行微调的基线模型有显著提升。

Conclusion: 通过结合PA数据和LLM生成的SA数据的两阶段训练策略，显著提升了代码翻译模型的性能，最高在pass@k指标上提升了3.78%。

Abstract: Code translation aims to translate the code from its source language to the
target language and is used in various software development scenarios. Recent
developments in Large Language Models (LLMs) have showcased their capabilities
in code translation, and parallel corpora play a crucial role in training
models for code translation. Parallel corpora can be categorized into
program-alignment (PA) and snippet-alignment (SA) data. Although PA data has
complete context and is suitable for semantic alignment learning, it may not
provide adequate fine-grained training signals due to its extended length,
while the brevity of SA data enables more fine-grained alignment learning. Due
to limited parallel corpora, researchers explore several augmentation methods
for code translation. Previous studies mainly focus on augmenting PA data. In
this paper, we propose a data augmentation method that leverages LLMs to
generate SA data automatically. To fully leverage both PA data and SA data, we
explore a simple yet effective two-stage training strategy, which consistently
enhances model performance compared to fine-tuning solely on PA data.
Experiments on TransCoder-test demonstrate that our augmented SA data combined
with the two-stage training approach yields consistent improvements over the
baseline, achieving a maximum gain of 3.78% on pass@k.

</details>


### [149] [Assessing Coherency and Consistency of Code Execution Reasoning by Large Language Models](https://arxiv.org/abs/2510.15079)
*Changshu Liu,Yang Chen,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: CES提出了一种评估LLMs程序执行模拟和编程推理能力的方法，发现前沿LLMs的推理常不连贯，且表现不一致，可能影响其在需要路径敏感分析的任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在程序执行模拟和编程任务中的推理能力，避免因推理捷径、幻觉或数据泄漏导致的错误结论。

Method: CES通过测量执行模拟中变量预测的正确性，并引入连贯性概念来评估模拟是否符合常识执行逻辑。此外，CES还提出了一种新指标来衡量测试间推理一致性。

Result: 在HumanEval上，16种LLMs（包括三种推理LLMs）的连贯执行模拟率为81.42%，其中46.92%和53.08%分别产生正确和错误的输出预测。前沿LLMs（如GPT-4和DeepSeek-R1）的推理最不连贯，主要由于自然语言捷径。LLMs在不同测试中的推理表现不一致，多为随机（48.87%）或弱（45.37%）。

Conclusion: CES是一种评估LLMs在模拟程序执行和编程任务中推理能力的有效工具，能够系统性地检验LLMs在这些任务中的可疑成功。

Abstract: This paper proposes CES, a task to evaluate the abilities of LLMs in
simulating program execution and using that reasoning in programming tasks.
Besides measuring the correctness of variable predictions during execution
simulation, CES introduces the notion of coherence to determine whether the
simulation complies with commonsense execution logic, even if the predicted
values along the simulations are incorrect. This enables CES to rule out
suspiciously correct output predictions due to reasoning shortcuts,
hallucinations, or potential data leakage. CES also introduces a novel metric
to measure reasoning consistency across tests with the same or different prime
path coverage in a spectrum: strong, weak, and random. Evaluating 16 LLMs
(including three reasoning LLMs) using CES indicates 81.42% coherent execution
simulation on HumanEval, 46.92% and 53.08% of which result in correct and
incorrect output predictions. Frontier LLMs such as GPT-4 and DeepSeek-R1 have
the most incoherent execution reasoning, mostly due to natural language
shortcuts. Despite relatively coherent execution simulation, LLMs' reasoning
performance across different tests is inconsistent, mostly random (48.87%) or
weak (45.37%), potentially explaining their weakness in programming tasks that
require path-sensitive program analysis to succeed. We also compare CES with
bug prediction/localization/repair, which intuitively requires control- and
data-flow awareness. We observe that LLMs barely incorporate execution
reasoning into their analysis for bug-related tasks, and their success is
primarily due to inherent abilities in pattern matching or natural language
shortcuts, if not data leakage. Without reasoning, there is a threat to the
generalizability of LLMs in dealing with unseen bugs or patterns in different
contexts. CES can be used to vet the suspicious success of LLMs in these tasks
systematically.

</details>


### [150] [Community Engagement and the Lifespan of Open-Source Software Projects](https://arxiv.org/abs/2510.15408)
*Mohit,Kuljit Kaur Chahal*

Main category: cs.SE

TL;DR: 研究发现社区参与（CE）对开源软件项目的动态和寿命有显著影响，提供了验证的CE指标，揭示了不同活动模式如何影响项目长期生存。


<details>
  <summary>Details</summary>
Motivation: 开源软件项目依赖社区参与（CE）来维持长期发展，但CE对项目动态和寿命的可量化影响尚未充分研究。

Method: 分析了33,946个GitHub仓库，定义并操作化了CE指标（每月问题、评论、关注者、星标）。使用非参数测试和相关性分析评估了CE与项目动态及寿命的关系。

Result: CE指标与项目动态显著相关，尤其在高度参与的项目中相关性更强。对于项目寿命，CE率在年轻项目中最高，随项目年龄下降，但少数长期项目保持极高活跃度。初始CE爆发对项目建立至关重要，而持续高参与推动极端长寿。问题参与的积极影响随项目年龄增强，而被动关注的消极影响减弱。

Conclusion: CE动态地推动开源软件项目的长期发展和开发。研究结果建立了经过验证的CE指标，并深入探讨了多样化的社区活动模式如何促进项目的长期生存。

Abstract: Open-source software (OSS) projects depend on community engagement (CE) for
longevity. However, CE's quantifiable impact on project dynamics and lifespan
is underexplored. Objectives: This study defines CE in OSS, identifies key
metrics, and evaluates their influence on project dynamics (releases, commits,
branches) and lifespan. Methods: We analyzed 33,946 GitHub repositories,
defining and operationalizing CE with validated per-month metrics (issues,
comments, watchers, stargazers). Non-parametric tests and correlations assessed
relationships with project dynamics and lifespan across quartiles. Results: CE
metrics significantly associate with project dynamics, with stronger
correlations in highly engaged projects. For lifespan, a complex pattern
emerged: per-month CE rates are highest in younger projects, declining with
age. Yet, a subset of long-lived projects maintains exceptionally high
activity. Initial CE bursts appear crucial for establishment, while sustained
high engagement drives extreme longevity. Active issue engagement's influence
intensifies with age, but passive attention's declines. Conclusion: CE
dynamically drives OSS project longevity and development. Our findings
establish validated CE metrics and offer deeper insights into how diverse
community activity patterns contribute to project longevity.

</details>


### [151] [Selecting and Combining Large Language Models for Scalable Code Clone Detection](https://arxiv.org/abs/2510.15480)
*Muslim Chochlov,Gul Aftab Ahmed,James Vincent Patten,Yuanhua Han,Guoxian Lu,David Gregg,Jim Buckley*

Main category: cs.SE

TL;DR: 论文研究了LLM在克隆检测中的表现，发现CodeT5+110M等模型表现最佳，集成方法可进一步提升精度。


<details>
  <summary>Details</summary>
Motivation: 源代码克隆带来的风险促使研究高效、可扩展的克隆检测方法，尤其是针对分歧克隆。LLM的快速涌现引发了关于最佳模型选择和集成效果的疑问。

Method: 论文筛选了76个LLM，评估了它们在两个公共工业数据集和一个商业大规模数据集上的表现，并探索了集成方法的效果。

Result: CodeT5+110M在商业大规模数据集上达到了39.71%的精度，是之前CodeBERT的两倍。最佳集成方法进一步将精度提升至46.91%。

Conclusion: 论文得出结论，没有统一的‘最佳LLM’适用于所有克隆检测任务，但CodeT5+110M、CuBERT和SPTCode表现最佳。此外，集成方法在大型数据集上能显著提高精度。

Abstract: Source code clones pose risks ranging from intellectual property violations
to unintended vulnerabilities. Effective and efficient scalable clone
detection, especially for diverged clones, remains challenging. Large language
models (LLMs) have recently been applied to clone detection tasks. However, the
rapid emergence of LLMs raises questions about optimal model selection and
potential LLM-ensemble efficacy.
  This paper addresses the first question by identifying 76 LLMs and filtering
them down to suitable candidates for large-scale clone detection. The
candidates were evaluated on two public industrial datasets, BigCloneBench, and
a commercial large-scale dataset. No uniformly 'best-LLM' emerged, though
CodeT5+110M, CuBERT and SPTCode were top-performers. Analysis of LLM-candidates
suggested that smaller embedding sizes, smaller tokenizer vocabularies and
tailored datasets are advantageous. On commercial large-scale dataset a
top-performing CodeT5+110M achieved 39.71\% precision: twice the precision of
previously used CodeBERT.
  To address the second question, this paper explores ensembling of the
selected LLMs: effort-effective approach to improving effectiveness. Results
suggest the importance of score normalization and favoring ensembling methods
like maximum or sum over averaging. Also, findings indicate that ensembling
approach can be statistically significant and effective on larger datasets: the
best-performing ensemble achieved even higher precision of 46.91\% over
individual LLM on the commercial large-scale code.

</details>


### [152] [An Experimental Study of Real-Life LLM-Proposed Performance Improvements](https://arxiv.org/abs/2510.15494)
*Lirong Yi,Gregory Gay,Philipp Leitner*

Main category: cs.SE

TL;DR: LLM能生成性能改进的代码，但仍不及人类开发者。原创想法偶尔带来显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究LLM是否能生成快速代码，并评估其性能优化能力。

Method: 使用65个真实世界Java任务数据集，采用自动化流程生成补丁，并对比基准和人类解决方案。

Result: LLM生成的代码在大多数情况下优于基准，但人类解决方案表现更优。LLM的解决方案约三分之二与开发者优化思路相同或相似，其余为原创想法。

Conclusion: LLM生成的代码在大多数情况下能提高性能，但仍显著落后于人类开发者的优化方案。LLM的原创性想法偶尔能带来显著性能提升。

Abstract: Large Language Models (LLMs) can generate code, but can they generate fast
code? In this paper, we study this question using a dataset of 65 real-world
tasks mined from open-source Java programs. We specifically select tasks where
developers achieved significant speedups, and employ an automated pipeline to
generate patches for these issues using two leading LLMs under four prompt
variations. By rigorously benchmarking the results against the baseline and
human-authored solutions, we demonstrate that LLM-generated code indeed
improves performance over the baseline in most cases. However, patches proposed
by human developers outperform LLM fixes by a statistically significant margin,
indicating that LLMs often fall short of finding truly optimal solutions. We
further find that LLM solutions are semantically identical or similar to the
developer optimization idea in approximately two-thirds of cases, whereas they
propose a more original idea in the remaining one-third. However, these
original ideas only occasionally yield substantial performance gains.

</details>


### [153] [Enhancing Code Review through Fuzzing and Likely Invariants](https://arxiv.org/abs/2510.15512)
*Wachiraphan Charoenwet,Patanamon Thongtanunam,Van-Thuan Pham,Christoph Treude*

Main category: cs.SE

TL;DR: FuzzSight通过模糊测试和不变式分析，在代码审查中有效识别行为差异，显著提升错误和漏洞的检测率。


<details>
  <summary>Details</summary>
Motivation: 尽管模糊测试有潜力在早期暴露非崩溃但意外的行为，但由于缺乏合适的机制来分析程序行为，其在代码审查中的实际价值受限。

Method: FuzzSight是一个框架，利用非崩溃模糊测试输入中的可能不变式来突出程序版本间的行为差异，从而提供哪些代码块需要更密切关注的见解。

Result: 在评估中，FuzzSight标记了75%的回归错误和高达80%的24小时模糊测试发现的漏洞，且在识别错误代码块上优于SAST，检测率高出十倍且误报更少。

Conclusion: FuzzSight展示了利用模糊测试和不变式分析在早期代码审查中的潜力和价值，将静态检查与动态行为洞察相结合。

Abstract: Many software projects employ manual code review to gatekeep defects and
vulnerabilities in the code before integration. However, reviewers often work
under time pressure and rely primarily on static inspection, leaving the
dynamic aspects of the program unexplored. Dynamic analyses could reveal such
behaviors, but they are rarely integrated into reviews. Among them, fuzzing is
typically applied later to uncover crashing bugs. Yet its ability to exercise
code with diverse inputs makes it promising for exposing non-crashing, but
unexpected, behaviors earlier. Still, without suitable mechanisms to analyze
program behaviors, the rich data produced during fuzzing remains inaccessible
to reviewers, limiting its practical value in this context.
  We hypothesize that unexpected variations in program behaviors could signify
potential bugs. The impact of code changes can be automatically captured at
runtime. Representing program behavior as likely invariants, dynamic properties
consistently observed at specific program points, can provide practical signals
of behavioral changes. Such signals offer a way to distinguish between intended
changes and unexpected behavioral shifts from code changes.
  We present FuzzSight, a framework that leverages likely invariants from
non-crashing fuzzing inputs to highlight behavioral differences across program
versions. By surfacing such differences, it provides insights into which code
blocks may need closer attention. In our evaluation, FuzzSight flagged 75% of
regression bugs and up to 80% of vulnerabilities uncovered by 24-hour fuzzing.
It also outperformed SAST in identifying buggy code blocks, achieving ten times
higher detection rates with fewer false alarms. In summary, FuzzSight
demonstrates the potential and value of leveraging fuzzing and invariant
analysis for early-stage code review, bridging static inspection with dynamic
behavioral insights.

</details>


### [154] [Colepp: uma ferramenta multiplataforma para coleta de dados de dispositivos vestiveis](https://arxiv.org/abs/2510.15565)
*Vinicius Moraes de Jesus,Andre Georghton Cardoso Pacheco*

Main category: cs.SE

TL;DR: Colepp是一款开源工具，用于同步多穿戴设备数据，解决高质量数据集缺乏问题。


<details>
  <summary>Details</summary>
Motivation: 穿戴设备普及但缺乏高质量公共数据集和数据收集条件控制，阻碍了鲁棒算法的开发。

Method: 通过智能手机作为中心枢纽，集成Polar H10胸带和Wear OS智能手表的数据，采用自定义同步协议和用户友好界面，生成CSV格式的同步数据集。

Result: Colepp成功生成了同步且一致的心率和运动信号数据集，适用于活动识别和心率估计等应用。

Conclusion: Colepp是一款开源、跨平台的工具，有效解决了多设备数据同步问题，为算法开发提供了高质量的数据集。

Abstract: The widespread adoption of wearable devices such as smartwatches and fitness
trackers has fueled the demand for reliable physiological and movement data
collection tools. However, challenges such as limited access to large,
high-quality public datasets and a lack of control over data collection
conditions hinder the development of robust algorithms. This work presents
Colepp, an open-source, cross-platform tool designed to collect and synchronize
data from multiple wearable devices, including heart rate (via ECG and PPG) and
motion signals (accelerometer and gyroscope). The system integrates a
smartphone as a central hub, receiving data from a Polar H10 chest strap and a
Wear OS smartwatch, and exporting synchronized datasets in CSV format. Through
a custom synchronization protocol and user-friendly interface, Colepp
facilitates the generation of customizable, real-world datasets suitable for
applications such as human activity recognition and heart rate estimation. A
use case shows the effectiveness of the tool in producing consistent and
synchronized signals.

</details>


### [155] [Leveraging Test Driven Development with Large Language Models for Reliable and Verifiable Spreadsheet Code Generation: A Research Framework](https://arxiv.org/abs/2510.15585)
*Dr Simon Thorne,Dr Advait Sarkar*

Main category: cs.SE

TL;DR: 该论文提出将测试驱动开发（TDD）与大型语言模型（LLM）结合，以解决LLM生成代码中的准确性和可靠性问题，特别针对高风险领域。框架包括实验设计和TDD提示示例，旨在提升用户信心和参与度。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（如ChatGPT）在生成传统软件代码和电子表格逻辑方面表现出色，但这些模型经常出现关键问题，如幻觉、细微逻辑不一致和语法错误，这些问题在高风险领域（如金融建模和科学计算）尤为严重。因此，需要通过一种方法来增强生成输出的准确性和可靠性。

Method: 该论文提出了一个明确概述的实验设计，包括明确定义的参与者组、评估指标和基于TDD的提示示例。该方法适用于从电子表格公式生成到脚本语言（如Python）和强类型语言（如Rust）的多样化编程环境。

Result: 该框架假设“测试优先”的方法论既提供了技术约束，又提供了认知支架，引导LLM输出更准确、可验证和可理解的解决方案。

Conclusion: 该立场论文提出了一种结合测试驱动开发（TDD）与大型语言模型（LLM）生成的结构化研究框架，旨在提高生成输出的正确性、可靠性和用户信心。通过强调测试驱动的思维，该框架旨在改进计算思维、提示工程技能和用户参与度，尤其惠及缺乏正式编程培训的电子表格用户。

Abstract: Large Language Models (LLMs), such as ChatGPT, are increasingly leveraged for
generating both traditional software code and spreadsheet logic. Despite their
impressive generative capabilities, these models frequently exhibit critical
issues such as hallucinations, subtle logical inconsistencies, and syntactic
errors, risks particularly acute in high stakes domains like financial
modelling and scientific computations, where accuracy and reliability are
paramount. This position paper proposes a structured research framework that
integrates the proven software engineering practice of Test-Driven Development
(TDD) with Large Language Model (LLM) driven generation to enhance the
correctness of, reliability of, and user confidence in generated outputs. We
hypothesise that a "test first" methodology provides both technical constraints
and cognitive scaffolding, guiding LLM outputs towards more accurate,
verifiable, and comprehensible solutions. Our framework, applicable across
diverse programming contexts, from spreadsheet formula generation to scripting
languages such as Python and strongly typed languages like Rust, includes an
explicitly outlined experimental design with clearly defined participant
groups, evaluation metrics, and illustrative TDD based prompting examples. By
emphasising test driven thinking, we aim to improve computational thinking,
prompt engineering skills, and user engagement, particularly benefiting
spreadsheet users who often lack formal programming training yet face serious
consequences from logical errors. We invite collaboration to refine and
empirically evaluate this approach, ultimately aiming to establish responsible
and reliable LLM integration in both educational and professional development
practices.

</details>


### [156] [Interact and React: Exploring Gender Patterns in Development and the Impact on Innovation and Robustness of a User Interface Tool](https://arxiv.org/abs/2510.15642)
*Sian Brooke*

Main category: cs.SE

TL;DR: 研究分析了React项目中女性贡献的影响，发现性别多样性有助于提升软件的创新性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 探讨性别多样性（尤其是女性参与）如何从根本上改变软件开发模式。

Method: 通过分析React项目11年间的贡献模式，研究探讨了性别差异在稳健性和创新性指标上的影响。

Result: 研究发现，女性的参与显著提升了功能增强和依赖管理的贡献，性别排斥对软件发展不利。

Conclusion: 研究表明，女性在开源软件设计中的参与对软件的功能增强和依赖管理有显著贡献，性别多样性的增加可以促进更包容、创新和稳健的软件发展。

Abstract: In open-source software design, the inclusion of women is often highlighted
simply to remind programmers that women exist. Yet, little attention is given
to how greater gender diversity, specifically women's participation, could
fundamentally alter development patterns. To understand the potential impact of
gender inclusion, this study investigates React, a widely used JavaScript
library for building user interfaces with an active contributor community. I
examine gender differences in metrics of robustness and innovation, as well as
shifts in contribution patterns leading up to major version releases over 11
years of the React project. My results show that the exclusion of women is
detrimental to software as women contribute significantly more to feature
enhancement and dependency management. By exploring how gender influences
innovation and robustness in the development of React, the study offers
critical insights into how increasing gender diversity could lead to more
inclusive, innovative, and robust software.

</details>


### [157] [MirrorFuzz: Leveraging LLM and Shared Bugs for Deep Learning Framework APIs Fuzzing](https://arxiv.org/abs/2510.15690)
*Shiwen Ou,Yuwei Li,Lu Yu,Chengkun Wei,Tingke Wen,Qiangpu Chen,Yu Chen,Haizhi Tang,Zulie Pan*

Main category: cs.SE

TL;DR: MirrorFuzz 通过自动化 API 模糊测试，高效发现深度学习框架中的跨框架共享 bug，显著提升代码覆盖率和 bug 发现数量。


<details>
  <summary>Details</summary>
Motivation: 深度学习框架中的 bug 可能引发上层应用的严重问题，现有研究对跨框架共享 API 模式及其潜在风险关注不足。

Method: MirrorFuzz 分三个阶段工作：1) 收集历史 bug 数据识别潜在问题 API；2) 匹配跨框架的相似 API；3) 利用大语言模型 (LLMs) 合成测试代码触发共享 bug。

Result: 在四个流行框架（TensorFlow、PyTorch、OneFlow 和 Jittor）上测试显示，MirrorFuzz 代码覆盖率提升 39.92%-98.20%，发现 315 个 bug（262 个新 bug，80 个已修复）。

Conclusion: MirrorFuzz 是一种有效的自动化 API 模糊测试解决方案，能够显著提高代码覆盖率并发现大量新 bug，尤其是在跨框架共享 bug 的场景中。

Abstract: Deep learning (DL) frameworks serve as the backbone for a wide range of
artificial intelligence applications. However, bugs within DL frameworks can
cascade into critical issues in higher-level applications, jeopardizing
reliability and security. While numerous techniques have been proposed to
detect bugs in DL frameworks, research exploring common API patterns across
frameworks and the potential risks they entail remains limited. Notably, many
DL frameworks expose similar APIs with overlapping input parameters and
functionalities, rendering them vulnerable to shared bugs, where a flaw in one
API may extend to analogous APIs in other frameworks. To address this
challenge, we propose MirrorFuzz, an automated API fuzzing solution to discover
shared bugs in DL frameworks. MirrorFuzz operates in three stages: First,
MirrorFuzz collects historical bug data for each API within a DL framework to
identify potentially buggy APIs. Second, it matches each buggy API in a
specific framework with similar APIs within and across other DL frameworks.
Third, it employs large language models (LLMs) to synthesize code for the API
under test, leveraging the historical bug data of similar APIs to trigger
analogous bugs across APIs. We implement MirrorFuzz and evaluate it on four
popular DL frameworks (TensorFlow, PyTorch, OneFlow, and Jittor). Extensive
evaluation demonstrates that MirrorFuzz improves code coverage by 39.92\% and
98.20\% compared to state-of-the-art methods on TensorFlow and PyTorch,
respectively. Moreover, MirrorFuzz discovers 315 bugs, 262 of which are newly
found, and 80 bugs are fixed, with 52 of these bugs assigned CNVD IDs.

</details>


### [158] [EASELAN: An Open-Source Framework for Multimodal Biosignal Annotation and Data Management](https://arxiv.org/abs/2510.15767)
*Rathi Adarshi Rammohan,Moritz Meier,Dennis Küster,Tanja Schultz*

Main category: cs.SE

TL;DR: EASELAN是一个优化多模态和生物信号数据集注释流程的框架，基于ELAN工具扩展功能，成功应用于高维数据集并公开资源。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和自适应认知系统的发展，对大型多模态数据集的需求日益增长，尤其是融合多种生物信号的模型。现有的注释工具难以应对这种复杂性，因此需要一种新的框架来优化工作流程。

Method: EASELAN基于ELAN工具，增加了新的组件以支持注释流程的各个阶段，包括注释文件准备、额外通道设置、GitHub版本控制集成和简化后处理。

Result: EASELAN成功应用于EASE项目中的高维生物信号数据集（如餐桌布置活动），并公开了代码和完全注释的数据库。

Conclusion: EASELAN框架成功应用于高维生物信号数据集，展示了其在简化注释流程和促进机器学习模型训练方面的潜力。尽管存在一些限制，但EASELAN为生物信号研究提供了宝贵的工具和资源。

Abstract: Recent advancements in machine learning and adaptive cognitive systems are
driving a growing demand for large and richly annotated multimodal data. A
prominent example of this trend are fusion models, which increasingly
incorporate multiple biosignals in addition to traditional audiovisual
channels. This paper introduces the EASELAN annotation framework to improve
annotation workflows designed to address the resulting rising complexity of
multimodal and biosignals datasets. It builds on the robust ELAN tool by adding
new components tailored to support all stages of the annotation pipeline: From
streamlining the preparation of annotation files to setting up additional
channels, integrated version control with GitHub, and simplified
post-processing. EASELAN delivers a seamless workflow designed to integrate
biosignals and facilitate rich annotations to be readily exported for further
analyses and machine learning-supported model training. The EASELAN framework
is successfully applied to a high-dimensional biosignals collection initiative
on human everyday activities (here, table setting) for cognitive robots within
the DFG-funded Collaborative Research Center 1320 Everyday Activity Science and
Engineering (EASE). In this paper we discuss the opportunities, limitations,
and lessons learned when using EASELAN for this initiative. To foster research
on biosignal collection, annotation, and processing, the code of EASELAN is
publicly available(https://github.com/cognitive-systems-lab/easelan), along
with the EASELAN-supported fully annotated Table Setting Database.

</details>


### [159] [Towards Supporting Open Source Library Maintainers with Community-Based Analytics](https://arxiv.org/abs/2510.15794)
*Rachna Raj,Diego Elias Costa*

Main category: cs.SE

TL;DR: 开源维护者缺乏API使用反馈，研究提出社区分析工具，实证显示多数API未被使用且测试覆盖不足，建议改进测试策略。


<details>
  <summary>Details</summary>
Motivation: 开源软件维护者缺乏对其API在实际项目中如何使用的持续反馈，这影响了他们的决策质量。

Method: 对10个流行的Java库及其各自的50个依赖项目进行实证研究，提出两个指标来评估测试套件。

Result: 研究发现，平均只有16%的API方法被依赖生态系统主动使用，且其中仅74%被测试套件部分或完全覆盖。

Conclusion: 社区分析工具可以帮助维护者更好地理解其API的使用情况，优化测试策略和库的演进方向。

Abstract: Open-source software (OSS) is a pillar of modern software development. Its
success depends on the dedication of maintainers who work constantly to keep
their libraries stable, adapt to changing needs, and support a growing
community. Yet, they receive little to no continuous feedback on how the
projects that rely on their libraries actually use their APIs. We believe that
gaining these insights can help maintainers make better decisions, such as
refining testing strategies, understanding the impact of changes, and guiding
the evolution of their libraries more effectively. We propose the use of
community-based analytics to analyze how an OSS library is used across its
dependent ecosystem. We conduct an empirical study of 10 popular Java libraries
and each with their respective dependent ecosystem of 50 projects. Our results
reveal that while library developers offer a wide range of API methods, only
16% on average are actively used by their dependent ecosystem. Moreover, only
74% of the used API methods are partially or fully covered by their library
test suite. We propose two metrics to help developers evaluate their test suite
according to the APIs used by their community, and we conduct a survey on
open-source practitioners to assess the practical value of these insights in
guiding maintenance decisions.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [160] [Hive Hash Table: A Warp-Cooperative, Dynamically Resizable Hash Table for GPUs](https://arxiv.org/abs/2510.15095)
*Md Sabbir Hossain Polak,David Troendle,Byunghyun Jang*

Main category: cs.DC

TL;DR: Hive hash table是一种高性能、动态可调整的GPU哈希表，通过优化内存访问和并发协议，显著提升了吞吐量和负载因子。


<details>
  <summary>Details</summary>
Motivation: 现有的GPU哈希表在并发更新、高负载因子和不规则内存访问模式方面表现不佳，因此需要一种高性能、动态可调整的GPU哈希表来适应不同的工作负载。

Method: Hive hash table采用缓存对齐的打包桶布局、warp同步并发协议（WABC和WCME）以及负载因子感知的动态调整策略。此外，还使用了四步策略处理高竞争下的插入操作。

Result: 在NVIDIA RTX 4090上的实验评估显示，Hive hash table在平衡工作负载下达到35亿次更新/秒和近40亿次查找/秒。

Conclusion: Hive hash table在混合插入-删除-查找工作负载下，吞吐量比现有GPU哈希表（Slab-Hash、DyCuckoo、WarpCore）高1.5-2倍，负载因子高达95%，展示了其在GPU加速数据处理中的可扩展性和效率。

Abstract: Hash tables are essential building blocks in data-intensive applications, yet
existing GPU implementations often struggle with concurrent updates, high load
factors, and irregular memory access patterns. We present Hive hash table, a
high-performance, warp-cooperative and dynamically resizable GPU hash table
that adapts to varying workloads without global rehashing.
  Hive hash table makes three key contributions. First, a cache-aligned packed
bucket layout stores key-value pairs as 64-bit words, enabling coalesced memory
access and atomic updates via single-CAS operations. Second, warp-synchronous
concurrency protocols - Warp-Aggregated-Bitmask-Claim (WABC) and
Warp-Cooperative Match-and-Elect (WCME) - reduce contention to one atomic
operation per warp while ensuring lock-free progress. Third, a
load-factor-aware dynamic resizing strategy expands or contracts capacity in
warp-parallel K-bucket batches using linear hashing, maintaining balanced
occupancy. To handle insertions under heavy contention, Hive hash table employs
a four-step strategy: replace, claim-and-commit, bounded cuckoo eviction, and
overflow-stash fallback. This design provides lock-free fast paths and bounded
recovery cost under contention determined by a fixed eviction depth, while
eliminating ABA hazards during concurrent updates.
  Experimental evaluation on an NVIDIA RTX 4090 shows Hive hash table sustains
load factors up to 95% while delivering 1.5-2x higher throughput than
state-of-the-art GPU hash tables (Slab-Hash, DyCuckoo, WarpCore) under mixed
insert-delete-lookup workloads. On balanced workload, Hive hash table reaches
3.5 billion updates/s and nearly 4 billion lookups/s, demonstrating scalability
and efficiency for GPU-accelerated data processing.

</details>


### [161] [NEMO: Faster Parallel Execution for Highly Contended Blockchain Workloads (Full version)](https://arxiv.org/abs/2510.15122)
*François Ezard,Can Umut Ileri,Jérémie Decouchant*

Main category: cs.DC

TL;DR: NEMO是一种新的区块链执行引擎，结合了OCC和对象数据模型，通过四项创新在高竞争工作负载下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前区块链执行框架在高竞争工作负载下性能下降，无论是乐观并发控制（OCC）还是悲观并发控制（PCC）都存在局限性。

Method: NEMO引入了四个核心创新：贪婪提交规则、精细化依赖处理、静态可推导的读写提示以及基于优先级的调度器。

Result: 在模拟实验中，NEMO的吞吐量比最先进的OCC方法Block-STM高42%，比PCC基线高61%。

Conclusion: NEMO通过结合OCC和对象数据模型，显著减少了冗余计算，在高竞争工作负载下实现了比现有方法更高的吞吐量。

Abstract: Following the design of more efficient blockchain consensus algorithms, the
execution layer has emerged as the new performance bottleneck of blockchains,
especially under high contention. Current parallel execution frameworks either
rely on optimistic concurrency control (OCC) or on pessimistic concurrency
control (PCC), both of which see their performance decrease when workloads are
highly contended, albeit for different reasons. In this work, we present NEMO,
a new blockchain execution engine that combines OCC with the object data model
to address this challenge. NEMO introduces four core innovations: (i) a greedy
commit rule for transactions using only owned objects; (ii) refined handling of
dependencies to reduce re-executions; (iii) the use of incomplete but
statically derivable read/write hints to guide execution; and (iv) a
priority-based scheduler that favors transactions that unblock others. Through
simulated execution experiments, we demonstrate that NEMO significantly reduces
redundant computation and achieves higher throughput than representative
approaches. For example, with 16 workers NEMO's throughput is up to 42% higher
than the one of Block-STM, the state-of-the-art OCC approach, and 61% higher
than the pessimistic concurrency control baseline used.

</details>


### [162] [An Elastic Job Scheduler for HPC Applications on the Cloud](https://arxiv.org/abs/2510.15147)
*Aditya Bhosale,Kavitha Chandrasekar,Laxmikant Kale,Sara Kokkila-Schumacher*

Main category: cs.DC

TL;DR: 本文介绍了一种基于Kubernetes的Charm++应用程序弹性调度方案，通过动态伸缩优化了HPC作业的资源利用率和响应时间。


<details>
  <summary>Details</summary>
Motivation: 随着云计算在高性能计算（HPC）中的应用增加，传统的并行编程模型（如MPI）缺乏对动态伸缩的支持，导致资源利用率不足。

Method: 开发了一个Kubernetes操作符来运行Charm++应用程序，并设计了一个优先级弹性作业调度器，能够根据集群状态动态调整作业规模。

Result: 实验表明，弹性调度器在最小化高优先级作业响应时间的同时，显著提高了集群资源利用率。

Conclusion: 本文提出了一种基于Kubernetes的Charm++应用程序运行方案和优先级弹性作业调度器，显著提高了集群资源利用率和高性能计算作业的响应时间。

Abstract: The last few years have seen an increase in adoption of the cloud for running
HPC applications. The pay-as-you-go cost model of these cloud resources has
necessitated the development of specialized programming models and schedulers
for HPC jobs for efficient utilization of cloud resources. A key aspect of
efficient utilization is the ability to rescale applications on the fly to
maximize the utilization of cloud resources. Most commonly used parallel
programming models like MPI have traditionally not supported autoscaling either
in a cloud environment or on supercomputers. While more recent work has been
done to implement this functionality in MPI, it is still nascent and requires
additional programmer effort. Charm++ is a parallel programming model that
natively supports dynamic rescaling through its migratable objects paradigm. In
this paper, we present a Kubernetes operator to run Charm++ applications on a
Kubernetes cluster. We then present a priority-based elastic job scheduler that
can dynamically rescale jobs based on the state of a Kubernetes cluster to
maximize cluster utilization while minimizing response time for high-priority
jobs. We show that our elastic scheduler, with the ability to rescale HPC jobs
with minimal overhead, demonstrates significant performance improvements over
traditional static schedulers.

</details>


### [163] [Spatiotemporal Traffic Prediction in Distributed Backend Systems via Graph Neural Networks](https://arxiv.org/abs/2510.15215)
*Zhimin Qiu,Feng Liu,Yuxiao Wang,Chenrui Hu,Ziyu Cheng,Di Wu*

Main category: cs.DC

TL;DR: 该论文提出了一种基于图神经网络的流量预测方法，通过结合时空特征显著提高了分布式系统中的预测准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统模型在捕捉复杂依赖关系和动态特征方面存在局限性，因此需要一种新的方法来更准确地预测分布式后端系统中的流量。

Method: 论文提出了一种基于图神经网络的建模方法，通过图卷积机制实现节点特征的多阶传播和聚合，并结合门控循环结构动态建模历史序列，进一步通过时空联合建模模块融合图表示与时间依赖性，最后通过解码器生成未来流量预测。

Result: 实验结果表明，该方法在不同预测范围和模型深度下均能实现稳定的性能和低误差，显著优于主流基线方法。

Conclusion: 该论文提出的基于图神经网络的方法显著提高了分布式后端系统中流量预测的准确性和鲁棒性，验证了图神经网络在复杂系统建模中的潜力。

Abstract: This paper addresses the problem of traffic prediction in distributed backend
systems and proposes a graph neural network based modeling approach to overcome
the limitations of traditional models in capturing complex dependencies and
dynamic features. The system is abstracted as a graph with nodes and edges,
where node features represent traffic and resource states, and adjacency
relations describe service interactions. A graph convolution mechanism enables
multi order propagation and aggregation of node features, while a gated
recurrent structure models historical sequences dynamically, thus integrating
spatial structures with temporal evolution. A spatiotemporal joint modeling
module further fuses graph representation with temporal dependency, and a
decoder generates future traffic predictions. The model is trained with mean
squared error to minimize deviations from actual values. Experiments based on
public distributed system logs construct combined inputs of node features,
topology, and sequences, and compare the proposed method with mainstream
baselines using MSE, RMSE, MAE, and MAPE. Results show that the proposed method
achieves stable performance and low error across different prediction horizons
and model depths, significantly improving the accuracy and robustness of
traffic forecasting in distributed backend systems and verifying the potential
of graph neural networks in complex system modeling.

</details>


### [164] [BeLLMan: Controlling LLM Congestion](https://arxiv.org/abs/2510.15330)
*Tella Rajashekhar Reddy,Atharva Deshmukh,Karan Tandon,Rohan Gandhi,Anjaly Parayil,Debopam Bhattacherjee*

Main category: cs.DC

TL;DR: beLLMan控制器通过动态调整LLM输出长度，显著降低延迟和能耗，提升性能。


<details>
  <summary>Details</summary>
Motivation: LLM应用在生成令牌时对底层基础设施负载不敏感，导致推理延迟增加和用户体验下降。

Method: 设计并实现了beLLMan控制器，该控制器能够根据系统负载动态调整LLM应用的输出长度。

Result: 在H100 GPU测试环境中，beLLMan将端到端延迟降低至多8倍，能耗减少25%，同时处理请求量增加19%。

Conclusion: beLLMan控制器通过动态调整输出长度，有效降低了推理延迟和能耗，提升了LLM基础设施的性能和用户体验。

Abstract: Large language model (LLM) applications are blindfolded to the infrastructure
underneath and generate tokens autoregressively, indifferent to the system
load, thus risking inferencing latency inflation and poor user experience. Our
first-cut controller, named beLLMan, enables the LLM infrastructure to actively
and progressively signal the first-party LLM application to adjust the output
length in response to changing system load. On a real testbed with H100 GPUs,
beLLMan helps keep inferencing latency under control (upto 8X lower end-to-end
latency) and reduces energy consumption by 25% (while serving 19% more
requests) during periods of congestion for a summarization workload.

</details>


### [165] [Cloud-Enabled Virtual Prototypes](https://arxiv.org/abs/2510.15355)
*Tim Kraus,Axel Sauer,Ingo Feldner*

Main category: cs.DC

TL;DR: 本文探讨了本地与云端模拟环境的权衡，分析了基础设施设置对性能和安全的影响，旨在提升远程模拟的信任和采用率。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统的快速发展和AI算法的日益复杂化，需要基于虚拟原型技术的强大硬件/软件协同设计方法。

Method: 探索本地与基于云的模拟环境之间的二分法，重点分析计算基础设施设置对执行性能和数据处理安全性的影响。

Result: 讨论了计算基础设施设置对执行性能和数据处理安全性的影响，并强调了嵌入式AI开发工作流程中高效模拟的关键作用。

Conclusion: 本文提出了一种可持续提升远程模拟信任并促进虚拟原型设计实践的解决方案，旨在平衡可扩展性与隐私之间的权衡。

Abstract: The rapid evolution of embedded systems, along with the growing variety and
complexity of AI algorithms, necessitates a powerful hardware/software
co-design methodology based on virtual prototyping technologies. The market
offers a diverse range of simulation solutions, each with its unique
technological approach and therefore strengths and weaknesses. Additionally,
with the increasing availability of remote on-demand computing resources and
their adaptation throughout the industry, the choice of the host infrastructure
for execution opens even more new possibilities for operational strategies.
This work explores the dichotomy between local and cloud-based simulation
environments, focusing on the trade-offs between scalability and privacy. We
discuss how the setup of the compute infrastructure impacts the performance of
the execution and security of data involved in the process. Furthermore, we
highlight the development workflow associated with embedded AI and the critical
role of efficient simulations in optimizing these algorithms. With the proposed
solution, we aim to sustainably improve trust in remote simulations and
facilitate the adoption of virtual prototyping practices.

</details>


### [166] [(Almost) Perfect Discrete Iterative Load Balancing](https://arxiv.org/abs/2510.15473)
*Petra Berenbrink,Robert Elsässer,Tom Friedetzky,Hamed Hosseinpour,Dominik Kaaser,Peter Kling,Thomas Sauerwald*

Main category: cs.DC

TL;DR: 该论文提出了一种离散负载平衡方案，通过匹配在任意图上实现低差异（3），性能与连续平衡相当。


<details>
  <summary>Details</summary>
Motivation: 探索离散迭代负载平衡在任意图上的性能，旨在通过匹配重新分配令牌，使每个节点的令牌数最终趋于一致。

Method: 研究了一类简单的局部平衡方案，通过匹配在每轮中平均两个节点的令牌。如果令牌总和为奇数，则随机选择一个节点接收多余令牌。

Result: 离散平衡方案在高概率下能在轮数上与连续负载平衡的光谱界限相匹配，达到差异为3。

Conclusion: 该论文证明了离散负载平衡方案在任意图上能达到与连续负载平衡相似的性能，且最终差异仅为3。

Abstract: We consider discrete, iterative load balancing via matchings on arbitrary
graphs. Initially each node holds a certain number of tokens, defining the load
of the node, and the objective is to redistribute the tokens such that
eventually each node has approximately the same number of tokens. We present
results for a general class of simple local balancing schemes where the tokens
are balanced via matchings. In each round the process averages the tokens of
any two matched nodes. If the sum of their tokens is odd, the node to receive
the one excess token is selected at random. Our class covers three popular
models: in the matching model a new matching is generated randomly in each
round, in the balancing circuit model a fixed sequence of matchings is applied
periodically, and in the asynchronous model the load is balanced over a
randomly chosen edge.
  We measure the quality of a load vector by its discrepancy, defined as the
difference between the maximum and minimum load across all nodes. As our main
result we show that with high probability our discrete balancing scheme reaches
a discrepancy of $3$ in a number of rounds which asymptotically matches the
spectral bound for continuous load balancing with fractional load.
  This result improves and tightens a long line of previous works, by not only
achieving a small constant discrepancy (instead of a non-explicit, large
constant) but also holding for arbitrary instead of regular graphs. The result
also demonstrates that in the general model we consider, discrete load
balancing is no harder than continuous load balancing.

</details>


### [167] [Balancing Fairness and Performance in Multi-User Spark Workloads with Dynamic Scheduling (extended version)](https://arxiv.org/abs/2510.15485)
*Dāvis Kažemaks,Laurens Versluis,Burcu Kulahcioglu Ozkan,Jérémie Decouchant*

Main category: cs.DC

TL;DR: UWFQ调度器通过虚拟公平队列和运行时分区技术，在Spark中实现了用户级公平性和低响应时间，显著提升小型作业性能。


<details>
  <summary>Details</summary>
Motivation: Spark内置调度器在工业分析环境中难以兼顾用户级公平性和低响应时间，现有解决方案偏向提交更多作业的用户。

Method: 提出了用户加权公平队列（UWFQ）调度器，结合虚拟公平队列系统和运行时分区技术，动态调整任务粒度。

Result: UWFQ比现有Spark调度器和先进公平调度算法将小型作业的平均响应时间最多降低了74%。

Conclusion: UWFQ调度器在Spark框架中成功实现了用户级公平性和低平均响应时间，显著提升了小型作业的性能。

Abstract: Apache Spark is a widely adopted framework for large-scale data processing.
However, in industrial analytics environments, Spark's built-in schedulers,
such as FIFO and fair scheduling, struggle to maintain both user-level fairness
and low mean response time, particularly in long-running shared applications.
Existing solutions typically focus on job-level fairness which unintentionally
favors users who submit more jobs. Although Spark offers a built-in fair
scheduler, it lacks adaptability to dynamic user workloads and may degrade
overall job performance. We present the User Weighted Fair Queuing (UWFQ)
scheduler, designed to minimize job response times while ensuring equitable
resource distribution across users and their respective jobs. UWFQ simulates a
virtual fair queuing system and schedules jobs based on their estimated finish
times under a bounded fairness model. To further address task skew and reduce
priority inversions, which are common in Spark workloads, we introduce runtime
partitioning, a method that dynamically refines task granularity based on
expected runtime. We implement UWFQ within the Spark framework and evaluate its
performance using multi-user synthetic workloads and Google cluster traces. We
show that UWFQ reduces the average response time of small jobs by up to 74%
compared to existing built-in Spark schedulers and to state-of-the-art fair
scheduling algorithms.

</details>


### [168] [Retrofitting Service Dependency Discovery in Distributed Systems](https://arxiv.org/abs/2510.15490)
*Diogo Landau,Gijs Blanken,Jorge Barbosa,Nishant Saurabh*

Main category: cs.DC

TL;DR: XXXX 是一种新型运行时系统，通过非破坏性 TCP 头部元数据注入，解决了 NAT 环境下服务依赖图的准确构建问题，并在测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统中，复杂的路由技术（如 NAT）导致现有运行时方法无法准确推断服务依赖关系，需要一种更鲁棒的解决方案。

Method: XXXX 通过在 TCP 包头部非破坏性地注入元数据，确保协议正确性，并在无接收代理时不影响现有连接。

Result: 在九种场景（三种网络配置和三种微服务基准测试）中，XXXX 是唯一在所有网络配置中表现一致的方法，多数情况下精度和召回率达到 100%。

Conclusion: XXXX 是一种能够在复杂网络路由机制（如 NAT）下准确构建服务依赖图的新型运行时系统，无需源代码插桩且支持部分部署。

Abstract: Modern distributed systems rely on complex networks of interconnected
services, creating direct or indirect dependencies that can propagate faults
and cause cascading failures. To localize the root cause of performance
degradation in these environments, constructing a service dependency graph is
highly beneficial. However, building an accurate service dependency graph is
impaired by complex routing techniques, such as Network Address Translation
(NAT), an essential mechanism for connecting services across networks. NAT
obfuscates the actual hosts running the services, causing existing run-time
approaches that passively observe network metadata to fail in accurately
inferring service dependencies. To this end, this paper introduces XXXX, a
novel run-time system for constructing process-level service dependency graphs.
It operates without source code instrumentation and remains resilient under
complex network routing mechanisms, including NAT. XXXX implements a
non-disruptive method of injecting metadata onto a TCP packet's header that
maintains protocol correctness across host boundaries. In other words, if no
receiving agent is present, the instrumentation leaves existing TCP connections
unaffected, ensuring non-disruptive operation when it is partially deployed
across hosts. We evaluated XXXX extensively against three state-of-the-art
systems across nine scenarios, involving three network configurations
(NAT-free, internal-NAT, external-NAT) and three microservice benchmarks. XXXX
was the only approach that performed consistently across networking
configurations. With regards to correctness, it performed on par with, or
better than, the state-of-the-art with precision and recall values of 100% in
the majority of the scenarios.

</details>


### [169] [PRISM: Probabilistic Runtime Insights and Scalable Performance Modeling for Large-Scale Distributed Training](https://arxiv.org/abs/2510.15596)
*Alicia Golden,Michael Kuchnik,Samuel Hsia,Zachary DeVito,Gu-Yeon Wei,David Brooks,Carole-Jean Wu*

Main category: cs.DC

TL;DR: PRISM是一个性能建模框架，通过统计方法量化大规模分布式训练中的性能变异性，优化节点布局和并行策略可实现1.26倍性能提升，通信内核优化是关键。


<details>
  <summary>Details</summary>
Motivation: 大规模GPU训练中性能变异性增加，尤其是在功率受限和热应力环境下，导致训练效率下降。PRISM旨在理解和优化这种变异性。

Method: PRISM是一个性能建模框架，采用统计方法来量化分布式训练中的性能变异性，并通过真实系统测量验证其预测准确性。

Result: PRISM在真实系统中验证了训练时间预测的准确性（20.8% KS距离），并展示了通过优化节点布局和并行策略可实现1.26倍的性能提升。通信内核（如AllGather和ReduceScatter）的优化对减少训练步骤时间变异性贡献最大。

Conclusion: PRISM框架通过统计方法量化了大规模分布式训练中的性能变异性，提供了训练时间的概率保证，并展示了在节点布局和并行策略优化方面的显著性能提升潜力。

Abstract: Large model training beyond tens of thousands of GPUs is an uncharted
territory. At such scales, disruptions to the training process are not a matter
of if, but a matter of when -- a stochastic process degrading training
productivity. Dynamic runtime variation will become increasingly more frequent
as training scales up and GPUs are operated in increasingly power-limited and
thermally-stressed environments. At the 64k GPU scale, we already observed 9%
GPU time variability for frontier foundation model training. To understand
potential causes of variability, we analyze GPU microbenchmarks at scale across
a variety of platforms, showing up to 14% variation in GPU performance on GEMM
workloads depending on training hardware and deployed environment.
  Motivated by our analysis and the large design space around performance
variability, we present PRISM -- a performance modeling framework that
considers the stochastic nature of the large-scale distributed training. The
core of PRISM is the statistical method that provides a quantifiable measure
for probabilistic guarantees on training time. Using PRISM, we explore the
design and optimization space of distributed training, from parallelization
methods to next-generation training systems. PRISM is validated with
real-system measurement, showing training time prediction accuracy with 20.8%
Kolmogorov-Smirnov distance. Using PRISM, we demonstrate that, depending on
computation node placement, up to 1.26x performance improvement potential is
available if we factor in sensitivities of parallelization strategies to
variation. In addition, we use PRISM to identify kernels to optimize for
reducing performance variability and predict probability of slow-down for
large-scale jobs where variation is magnified. We find optimizing communication
kernels, such as AllGather and ReduceScatter, contribute most to minimizing
variability in training step time.

</details>


### [170] [GOGH: Correlation-Guided Orchestration of GPUs in Heterogeneous Clusters](https://arxiv.org/abs/2510.15652)
*Ahmad Raeisi,Mahdi Dolati,Sina Darabi,Sadegh Talebi,Patrick Eugster,Ahmad Khonsari*

Main category: cs.DC

TL;DR: 提出了一种基于神经网络的在线系统，用于优化异构集群中的机器学习工作负载分配，通过迭代学习提高效率和性能。


<details>
  <summary>Details</summary>
Motivation: 由于机器学习对计算资源的需求增长，在异构硬件集群中高效分配资源成为关键挑战，尤其是在无法升级到最新硬件的情况下。

Method: 系统使用两个神经网络：第一个提供初始估计，优化器基于这些估计分配资源；部署后，系统监控实际性能并通过第二个神经网络改进预测。

Result: 该系统能够自适应地学习，随着时间的推移在异构深度学习集群中做出更有效的资源分配决策。

Conclusion: 本文提出了一种基于学习的架构，用于在异构集群中管理机器学习工作负载，通过迭代学习优化资源分配决策。

Abstract: The growing demand for computational resources in machine learning has made
efficient resource allocation a critical challenge, especially in heterogeneous
hardware clusters where devices vary in capability, age, and energy efficiency.
Upgrading to the latest hardware is often infeasible, making sustainable use of
existing, mixed-generation resources essential. In this paper, we propose a
learning-based architecture for managing machine learning workloads in
heterogeneous clusters. The system operates online, allocating resources to
incoming training or inference requests while minimizing energy consumption and
meeting performance requirements. It uses two neural networks: the first
provides initial estimates of how well a new model will utilize different
hardware types and how it will affect co-located models. An optimizer then
allocates resources based on these estimates. After deployment, the system
monitors real performance and uses this data to refine its predictions via a
second neural network. This updated model improves estimates not only for the
current hardware but also for hardware not initially allocated and for
co-location scenarios not yet observed. The result is an adaptive, iterative
approach that learns over time to make more effective resource allocation
decisions in heterogeneous deep learning clusters.

</details>


### [171] [A Post-Quantum Lower Bound for the Distributed Lovász Local Lemma](https://arxiv.org/abs/2510.15698)
*Sebastian Brandt,Tim Göttlicher*

Main category: cs.DC

TL;DR: 本文在分布式量子计算中首次证明了Lovász局部引理问题的超常数下界，并开发了一种新的后量子下界技术。


<details>
  <summary>Details</summary>
Motivation: 近年来量子计算的进展将分布式量子计算中的LLL问题推至研究前沿，但缺乏对后量子模型中的下界研究。本文旨在填补这一空白，并为相关领域提供新的技术工具。

Method: 通过研究分布式量子计算中的Lovász局部引理（LLL）问题，特别是在量子-LOCAL模型中，证明了分布式LLL的复杂度下界为$2^{Ω(\log^* n)}$。进一步在随机在线-LOCAL模型中为sinkless orientation这一特殊案例获得了更强的下界。

Result: 证明了分布式LLL问题的复杂度下界为$2^{Ω(\log^* n)}$，并在随机在线-LOCAL模型中为sinkless orientation获得了相同下界。

Conclusion: 本文首次在多种模型中为sinkless orientation和分布式LLL问题提供了超常数下界，解决了近期提出的开放性问题，并开发了一种新的下界技术，有望成为证明后量子下界的通用方法。

Abstract: In this work, we study the Lov\'asz local lemma (LLL) problem in the area of
distributed quantum computing, which has been the focus of attention of recent
advances in quantum computing [STOC'24, STOC'25, STOC'25]. We prove a lower
bound of $2^{\Omega(\log^* n)}$ for the complexity of the distributed LLL in
the quantum-LOCAL model. More specifically, we obtain our lower bound already
for a very well-studied special case of the LLL, called sinkless orientation,
in a stronger model than quantum-LOCAL, called the randomized online-LOCAL
model. As a consequence, we obtain the same lower bounds for sinkless
orientation and the distributed LLL also in a variety of other models studied
across different research communities.
  Our work provides the first superconstant lower bound for sinkless
orientation and the distributed LLL in all of these models, addressing recently
stated open questions. Moreover, to obtain our results, we develop an entirely
new lower bound technique that we believe has the potential to become the first
generic technique for proving post-quantum lower bounds for many of the most
important problems studied in the context of locality.

</details>


### [172] [Funky: Cloud-Native FPGA Virtualization and Orchestration](https://arxiv.org/abs/2510.15755)
*Atsushi Koshiba,Charalampos Mainas,Pramod Bhatotia*

Main category: cs.DC

TL;DR: Funky是一个FPGA感知的云原生编排引擎，通过虚拟化、状态管理和标准兼容组件，解决了FPGA在云环境中的编排问题，显著提升了性能和扩展性。


<details>
  <summary>Details</summary>
Motivation: FPGA在云原生环境中的采用因缺乏虚拟化、隔离和抢占支持而受限，导致云提供商无法提供FPGA编排服务。

Method: Funky实现了三个关键技术：(1) FPGA虚拟化，(2) FPGA状态管理，(3) 符合CRI/OCI标准的FPGA感知编排组件。

Result: Funky在四台x86服务器上测试，成功移植了23个OpenCL应用，代码修改率仅为3.4%，OCI镜像体积比AMD的FPGA Docker容器小28.7倍，性能开销仅7.4%。

Conclusion: Funky通过提供FPGA虚拟化、状态管理和行业标准兼容的编排组件，显著提升了FPGA在云原生环境中的性能、利用率、扩展性和容错能力。

Abstract: The adoption of FPGAs in cloud-native environments is facing impediments due
to FPGA limitations and CPU-oriented design of orchestrators, as they lack
virtualization, isolation, and preemption support for FPGAs. Consequently,
cloud providers offer no orchestration services for FPGAs, leading to low
scalability, flexibility, and resiliency.
  This paper presents Funky, a full-stack FPGA-aware orchestration engine for
cloud-native applications. Funky offers primary orchestration services for FPGA
workloads to achieve high performance, utilization, scalability, and fault
tolerance, accomplished by three contributions: (1) FPGA virtualization for
lightweight sandboxes, (2) FPGA state management enabling task preemption and
checkpointing, and (3) FPGA-aware orchestration components following the
industry-standard CRI/OCI specifications.
  We implement and evaluate Funky using four x86 servers with Alveo U50 FPGA
cards. Our evaluation highlights that Funky allows us to port 23 OpenCL
applications from the Xilinx Vitis and Rosetta benchmark suites by modifying
3.4% of the source code while keeping the OCI image sizes 28.7 times smaller
than AMD's FPGA-accessible Docker containers. In addition, Funky incurs only
7.4% performance overheads compared to native execution, while providing
virtualization support with strong hypervisor-enforced isolation and
cloud-native orchestration for a set of distributed FPGAs. Lastly, we evaluate
Funky's orchestration services in a large-scale cluster using Google production
traces, showing its scalability, fault tolerance, and scheduling efficiency.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [173] [Maratona Linux a tale of upgrading from Ubuntu 20.04 to 22.04](https://arxiv.org/abs/2510.15263)
*Davi Antônio da Silva Santos,Bruno César Ribas*

Main category: cs.OS

TL;DR: Maratona Linux是为ICPC南美赛区定制的开发环境，基于Ubuntu LTS版本，已成功升级至22.04并优化了多项功能。


<details>
  <summary>Details</summary>
Motivation: 为ICPC南美区域赛提供一个稳定、全面的开发环境。

Method: 该项目基于Debian包修改标准Ubuntu安装，安装必要的开发工具（如IDE、编译器、调试器等），并实施网络限制。

Result: 项目成功迁移至Ubuntu 22.04 LTS，并进行了多项技术改进。

Conclusion: Maratona Linux项目成功从Ubuntu 20.04迁移到22.04 LTS版本，并通过添加静态分析工具、更新依赖关系图、拆分大包和优化打包流程进行了改进。

Abstract: Maratona Linux is the development environment used since 2016 on the
``Maratona de Programa\c{c}\~ao'', ICPC's South American regional contest. It
consists of Debian packages that modify a standard Ubuntu installation in order
to make it suitable for the competition, installing IDEs, documentation,
compilers, debuggers, interpreters, and enforcing network restrictions. The
project, which began based on Ubuntu 16.04, has been successfully migrated from
20.04 to 22.04, the current Long-term Support (LTS) version. The project has
also been improved by adding static analyzers, updating the package dependency
map, splitting large packages, and enhancing the packaging pipeline.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [174] [Revoke vs. Restart in Unweighted Throughput Scheduling](https://arxiv.org/abs/2510.15318)
*Changdao He*

Main category: cs.DS

TL;DR: 在抢占-撤销模型中，确定性在线算法无法达到恒定竞争比率，与抢占-重启模型的1/2竞争算法形成对比。


<details>
  <summary>Details</summary>
Motivation: 研究抢占-撤销模型下的无权重吞吐量调度问题，填补该模型下在线算法竞争比率的研究空白。

Method: 通过对抗性构造，从三作业实例出发，迭代嵌套此类构造，证明对于任意k≥3，存在ALG最多完成一个作业而OPT完成至少k个作业的实例。

Result: 竞争比率可被强制为1/k，即无限接近于零。

Conclusion: 本文证明了在抢占-撤销模型中，没有任何确定性在线算法能够达到恒定的竞争比率，这与抢占-重启模型形成鲜明对比。

Abstract: We study the unweighted throughput scheduling problem on a single machine in
the preemption-revoke model, where a running job may be aborted at any time,
but all progress is permanently lost and the job cannot be restarted. Each job
$J_i=(r_i,p_i,s_i)$ is defined by a release time $r_i$, a processing time
$p_i$, and a slack $s_i$, and must start no later than $r_i+s_i$ to be
feasible. We prove that no deterministic online algorithm can achieve a
constant competitive ratio. The lower bound is established via an adversarial
construction: starting from a three-job instance where $\textsf{ALG}$ completes
at most one job while $\textsf{OPT}$ completes all three, we iteratively nest
such constructions. By induction, for every $k\ge 3$, there exists an instance
where $\textsf{ALG}$ completes at most one job, while $\textsf{OPT}$ completes
at least $k$ jobs. Thus, the competitive ratio can be forced to $1/k$, and
hence made arbitrarily close to zero. Our result stands in sharp contrast to
the preemption-restart model, where Hoogeveen, Potts, and Woeginger (2000) gave
a deterministic $1/2$-competitive algorithm.

</details>


### [175] [Temporal Graph Reconfiguration for Always-Connected Graphs](https://arxiv.org/abs/2510.15593)
*Paul Sievers,George Skretas,Georg Tennigkeit*

Main category: cs.DS

TL;DR: 本文研究了时间图重配置问题，提出了多项式时间算法，并证明了最小化序列长度的NP难性。


<details>
  <summary>Details</summary>
Motivation: 研究在动态网络中逐步修改边活动时间的问题，确保网络在修改过程中始终保持某些属性。

Method: 通过分析桥梁的可达性分区，识别可变与不可变边，并构建重配置序列。

Result: 提出了一个多项式时间算法，并证明了最小化重配置序列长度的NP难性。

Conclusion: 本文提出了一个多项式时间算法，用于生成长度最多为2M²的有效重配置序列，或确定重配置不可行。同时证明了最小化重配置序列长度是NP难问题。

Abstract: Network redesign problems ask to modify the edges of a given graph to satisfy
some properties. In temporal graphs, where edges are only active at certain
times, we are sometimes only allowed to modify when the edges are going to be
active. In practice, we might not even be able to perform all of the necessary
modifications at once; changes must be applied step-by-step while the network
is still in operation, meaning that the network must continue to satisfy some
properties. To initiate a study in this area, we introduce the temporal graph
reconfiguration problem. As a starting point, we consider the Layered
Connectivity Reconfiguration problem in which every snapshot of the temporal
graph must remain connected throughout the reconfiguration. We provide insights
into how bridges can be reconfigured into non-bridges based on their
reachability partitions, which lets us identify any edge as either changeable
or unchangeable. From this we construct a polynomial-time algorithm that gives
a valid reconfiguration sequence of length at most 2M^2 (where M is the number
of temporal edges), or determines that reconfiguration is not possible. We also
show that minimizing the length of the reconfiguration sequence is NP-hard via
a reduction from vertex cover.

</details>
