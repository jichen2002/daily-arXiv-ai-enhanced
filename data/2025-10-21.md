<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 181]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.AI](#cs.AI) [Total: 70]
- [cs.GR](#cs.GR) [Total: 10]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.DS](#cs.DS) [Total: 19]
- [cs.DC](#cs.DC) [Total: 11]
- [cs.RO](#cs.RO) [Total: 48]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [ESCA: Contextualizing Embodied Agents via Scene-Graph Generation](https://arxiv.org/abs/2510.15963)
*Jiani Huang,Amish Sethi,Matthew Kuo,Mayank Keoliya,Neelay Velingker,JungHo Jung,Ser-Nam Lim,Ziyang Li,Mayur Naik*

Main category: cs.CV

TL;DR: ESCA框架通过SGClip模型提升多模态大语言模型的性能，无需人工标注，在场景图生成和动作定位中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的训练管道缺乏像素级视觉内容与文本语义的细粒度对齐，限制了其作为通用具身代理的能力。

Method: 提出了ESCA框架，其核心是SGClip模型，通过神经符号学习管道在87K+开放域视频上训练，结合模型驱动的自监督和结构化推理。

Result: SGClip在场景图生成和动作定位基准测试中表现优异，ESCA框架在两个具身环境中实现了最先进的性能。

Conclusion: ESCA框架通过SGClip模型显著提升了多模态大语言模型在具身环境中的性能，减少了感知错误，并使开源模型超越专有基线。

Abstract: Multi-modal large language models (MLLMs) are making rapid progress toward
general-purpose embodied agents. However, current training pipelines primarily
rely on high-level vision-sound-text pairs and lack fine-grained, structured
alignment between pixel-level visual content and textual semantics. To overcome
this challenge, we propose ESCA, a new framework for contextualizing embodied
agents through structured spatial-temporal understanding. At its core is
SGClip, a novel CLIP-based, open-domain, and promptable model for generating
scene graphs. SGClip is trained on 87K+ open-domain videos via a neurosymbolic
learning pipeline, which harnesses model-driven self-supervision from
video-caption pairs and structured reasoning, thereby eliminating the need for
human-labeled scene graph annotations. We demonstrate that SGClip supports both
prompt-based inference and task-specific fine-tuning, excelling in scene graph
generation and action localization benchmarks. ESCA with SGClip consistently
improves both open-source and commercial MLLMs, achieving state-of-the-art
performance across two embodied environments. Notably, it significantly reduces
agent perception errors and enables open-source models to surpass proprietary
baselines.

</details>


### [2] [CrossRay3D: Geometry and Distribution Guidance for Efficient Multimodal 3D Detection](https://arxiv.org/abs/2510.15991)
*Huiming Yang*

Main category: cs.CV

TL;DR: CrossRay3D是一种稀疏多模态检测器，通过改进token表示质量，在nuScenes基准测试中取得最优性能，且运行更快、鲁棒性更强。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏检测器忽视了token表示的质量，导致前景质量次优和性能受限。本文发现几何结构保留和类别分布是提升稀疏检测器性能的关键。

Method: 提出了Sparse Selector (SS)，其核心模块是Ray-Aware Supervision (RAS)和Class-Balanced Supervision，以及Ray Positional Encoding (Ray PE)，并将其集成到端到端的稀疏多模态检测器CrossRay3D中。

Result: 在nuScenes基准测试中，CrossRay3D达到72.4 mAP和74.7 NDS，运行速度快1.84倍，且在数据缺失场景下表现鲁棒。

Conclusion: CrossRay3D在nuScenes基准测试中取得了72.4 mAP和74.7 NDS的最先进性能，运行速度比其他领先方法快1.84倍，且在LiDAR或相机数据部分或完全缺失的场景下表现出强鲁棒性。

Abstract: The sparse cross-modality detector offers more advantages than its
counterpart, the Bird's-Eye-View (BEV) detector, particularly in terms of
adaptability for downstream tasks and computational cost savings. However,
existing sparse detectors overlook the quality of token representation, leaving
it with a sub-optimal foreground quality and limited performance. In this
paper, we identify that the geometric structure preserved and the class
distribution are the key to improving the performance of the sparse detector,
and propose a Sparse Selector (SS). The core module of SS is Ray-Aware
Supervision (RAS), which preserves rich geometric information during the
training stage, and Class-Balanced Supervision, which adaptively reweights the
salience of class semantics, ensuring that tokens associated with small objects
are retained during token sampling. Thereby, outperforming other sparse
multi-modal detectors in the representation of tokens. Additionally, we design
Ray Positional Encoding (Ray PE) to address the distribution differences
between the LiDAR modality and the image. Finally, we integrate the
aforementioned module into an end-to-end sparse multi-modality detector, dubbed
CrossRay3D. Experiments show that, on the challenging nuScenes benchmark,
CrossRay3D achieves state-of-the-art performance with 72.4 mAP and 74.7 NDS,
while running 1.84 faster than other leading methods. Moreover, CrossRay3D
demonstrates strong robustness even in scenarios where LiDAR or camera data are
partially or entirely missing.

</details>


### [3] [InfraGPT Smart Infrastructure: An End-to-End VLM-Based Framework for Detecting and Managing Urban Defects](https://arxiv.org/abs/2510.16017)
*Ibrahim Sheikh Mohamed,Abdullah Yahya Abdullah Omaisan*

Main category: cs.CV

TL;DR: 本文提出了一种利用CCTV和视觉语言模型自动检测和总结城市基础设施缺陷的系统，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 智能城市基础设施中的手动检查成本高且危险，现有自动系统通常只能处理单一缺陷类型或提供非结构化输出。

Method: 提出了一个综合管道，利用街道CCTV流进行多缺陷检测和分割，使用YOLO系列目标检测器，并将检测结果传递给视觉语言模型（VLM）进行场景感知总结。

Result: 在公共数据集和捕获的CCTV片段上的实验评估表明，系统能准确识别多种缺陷并生成连贯的总结。

Conclusion: 本文讨论了将系统扩展到城市范围部署的挑战和方向。

Abstract: Infrastructure in smart cities is increasingly monitored by networks of
closed circuit television (CCTV) cameras. Roads, bridges and tunnels develop
cracks, potholes, and fluid leaks that threaten public safety and require
timely repair. Manual inspection is costly and hazardous, and existing
automatic systems typically address individual defect types or provide
unstructured outputs that cannot directly guide maintenance crews. This paper
proposes a comprehensive pipeline that leverages street CCTV streams for multi
defect detection and segmentation using the YOLO family of object detectors and
passes the detections to a vision language model (VLM) for scene aware
summarization. The VLM generates a structured action plan in JSON format that
includes incident descriptions, recommended tools, dimensions, repair plans,
and urgent alerts. We review literature on pothole, crack and leak detection,
highlight recent advances in large vision language models such as QwenVL and
LLaVA, and describe the design of our early prototype. Experimental evaluation
on public datasets and captured CCTV clips demonstrates that the system
accurately identifies diverse defects and produces coherent summaries. We
conclude by discussing challenges and directions for scaling the system to city
wide deployments.

</details>


### [4] [IAD-GPT: Advancing Visual Knowledge in Multimodal Large Language Model for Industrial Anomaly Detection](https://arxiv.org/abs/2510.16036)
*Zewen Li,Zitong Yu,Qilang Ye,Weicheng Xie,Wei Zhuo,Linlin Shen*

Main category: cs.CV

TL;DR: IAD-GPT 是一种基于多模态大语言模型的新范式，通过结合文本语义和图像信息，显著提升了工业异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法缺乏多轮人机对话和详细描述能力，而基于大预训练模型的方法尚未充分激发大模型在异常检测任务中的潜力。

Method: 结合丰富的文本语义与图像级和像素级信息，采用异常提示生成器（APG）生成详细异常提示，并通过文本引导增强器和多掩码融合模块增强视觉基础能力。

Result: 在 MVTec-AD 和 VisA 数据集上实现了最先进的性能。

Conclusion: IAD-GPT 在自监督和少样本异常检测与分割任务中表现出色，证明了其在工业异常检测中的先进性能。

Abstract: The robust causal capability of Multimodal Large Language Models (MLLMs) hold
the potential of detecting defective objects in Industrial Anomaly Detection
(IAD). However, most traditional IAD methods lack the ability to provide
multi-turn human-machine dialogues and detailed descriptions, such as the color
of objects, the shape of an anomaly, or specific types of anomalies. At the
same time, methods based on large pre-trained models have not fully stimulated
the ability of large models in anomaly detection tasks. In this paper, we
explore the combination of rich text semantics with both image-level and
pixel-level information from images and propose IAD-GPT, a novel paradigm based
on MLLMs for IAD. We employ Abnormal Prompt Generator (APG) to generate
detailed anomaly prompts for specific objects. These specific prompts from the
large language model (LLM) are used to activate the detection and segmentation
functions of the pre-trained visual-language model (i.e., CLIP). To enhance the
visual grounding ability of MLLMs, we propose Text-Guided Enhancer, wherein
image features interact with normal and abnormal text prompts to dynamically
select enhancement pathways, which enables language models to focus on specific
aspects of visual data, enhancing their ability to accurately interpret and
respond to anomalies within images. Moreover, we design a Multi-Mask Fusion
module to incorporate mask as expert knowledge, which enhances the LLM's
perception of pixel-level anomalies. Extensive experiments on MVTec-AD and VisA
datasets demonstrate our state-of-the-art performance on self-supervised and
few-shot anomaly detection and segmentation tasks, such as MVTec-AD and VisA
datasets. The codes are available at
\href{https://github.com/LiZeWen1225/IAD-GPT}{https://github.com/LiZeWen1225/IAD-GPT}.

</details>


### [5] [Effect of Reporting Mode and Clinical Experience on Radiologists' Gaze and Image Analysis Behavior in Chest Radiography](https://arxiv.org/abs/2510.16070)
*Mahta Khoobi,Marc Sebastian von der Stueck,Felix Barajas Ordonez,Anca-Maria Iancu,Eric Corban,Julia Nowak,Aleksandar Kargaliev,Valeria Perelygina,Anna-Sophie Schott,Daniel Pinto dos Santos,Christiane Kuhl,Daniel Truhn,Sven Nebelung,Robert Siepmann*

Main category: cs.CV

TL;DR: 结构化报告（SR）和AI辅助SR（AI-SR）显著提升放射科诊断效率和准确性，AI-SR效果最佳且最受用户青睐。


<details>
  <summary>Details</summary>
Motivation: 探索结构化报告（SR）和人工智能（AI）如何改变放射科医生与影像研究的互动方式，评估其对诊断准确性、效率和用户体验的影响。

Method: 本研究为前瞻性研究（2024年7月至12月），评估了三种报告模式（自由文本FT、结构化报告SR、AI辅助结构化报告AI-SR）对图像分析行为、诊断准确性、效率和用户体验的影响。参与者包括四位新手和四位非新手读者（放射科医生和医学生），每人使用定制化查看器和眼动追踪系统分析35张床旁胸片。结果指标包括诊断准确性（与专家共识比较，使用Cohen's κ）、每张胸片报告时间、眼动追踪指标和问卷调查的用户体验。统计分析采用广义线性混合模型和Bonferroni事后检验，显著性水平为P ≤ 0.01。

Result: 诊断准确性在FT（κ = 0.58）和SR（κ = 0.60）中相似，但在AI-SR中更高（κ = 0.71, P < 0.001）。报告时间从FT的88 ± 38秒减少到SR的37 ± 18秒和AI-SR的25 ± 9秒（P < 0.001）。SR和AI-SR降低了放射图区域的扫视次数和报告区域的总注视时间（P < 0.001）。新手读者在SR中视线转向放射图，而非新手读者保持对放射图的关注。AI-SR是最受欢迎的模式。

Conclusion: 结构化报告（SR）通过引导视觉注意力朝向图像提高效率，而AI预填充的SR（AI-SR）进一步提升了诊断准确性和用户满意度。

Abstract: Structured reporting (SR) and artificial intelligence (AI) may transform how
radiologists interact with imaging studies. This prospective study (July to
December 2024) evaluated the impact of three reporting modes: free-text (FT),
structured reporting (SR), and AI-assisted structured reporting (AI-SR), on
image analysis behavior, diagnostic accuracy, efficiency, and user experience.
Four novice and four non-novice readers (radiologists and medical students)
each analyzed 35 bedside chest radiographs per session using a customized
viewer and an eye-tracking system. Outcomes included diagnostic accuracy
(compared with expert consensus using Cohen's $\kappa$), reporting time per
radiograph, eye-tracking metrics, and questionnaire-based user experience.
Statistical analysis used generalized linear mixed models with Bonferroni
post-hoc tests with a significance level of ($P \le .01$). Diagnostic accuracy
was similar in FT ($\kappa = 0.58$) and SR ($\kappa = 0.60$) but higher in
AI-SR ($\kappa = 0.71$, $P < .001$). Reporting times decreased from $88 \pm 38$
s (FT) to $37 \pm 18$ s (SR) and $25 \pm 9$ s (AI-SR) ($P < .001$). Saccade
counts for the radiograph field ($205 \pm 135$ (FT), $123 \pm 88$ (SR), $97 \pm
58$ (AI-SR)) and total fixation duration for the report field ($11 \pm 5$ s
(FT), $5 \pm 3$ s (SR), $4 \pm 1$ s (AI-SR)) were lower with SR and AI-SR ($P <
.001$ each). Novice readers shifted gaze towards the radiograph in SR, while
non-novice readers maintained their focus on the radiograph. AI-SR was the
preferred mode. In conclusion, SR improves efficiency by guiding visual
attention toward the image, and AI-prefilled SR further enhances diagnostic
accuracy and user satisfaction.

</details>


### [6] [Data-Driven Analysis of Intersectional Bias in Image Classification: A Framework with Bias-Weighted Augmentation](https://arxiv.org/abs/2510.16072)
*Farjana Yesmin*

Main category: cs.CV

TL;DR: 本文提出IFEF和BWA框架，有效减少图像分类中的交叉偏见，实验证明其显著提升公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决机器学习模型在训练数据不平衡时出现的交叉偏见问题。

Method: 引入了交叉公平评估框架（IFEF）和偏见加权增强（BWA）策略，结合定量公平指标和可解释性工具。

Result: 在Open Images V7数据集上，BWA将代表性不足的类别-环境交叉的准确率提高了24个百分点，公平性指标差异减少了35%。

Conclusion: 本文提出了一种可重复的方法来分析和解决图像分类系统中的交叉偏见，通过实验验证了其有效性。

Abstract: Machine learning models trained on imbalanced datasets often exhibit
intersectional biases-systematic errors arising from the interaction of
multiple attributes such as object class and environmental conditions. This
paper presents a data-driven framework for analyzing and mitigating such biases
in image classification. We introduce the Intersectional Fairness Evaluation
Framework (IFEF), which combines quantitative fairness metrics with
interpretability tools to systematically identify bias patterns in model
predictions. Building on this analysis, we propose Bias-Weighted Augmentation
(BWA), a novel data augmentation strategy that adapts transformation
intensities based on subgroup distribution statistics. Experiments on the Open
Images V7 dataset with five object classes demonstrate that BWA improves
accuracy for underrepresented class-environment intersections by up to 24
percentage points while reducing fairness metric disparities by 35%.
Statistical analysis across multiple independent runs confirms the significance
of improvements (p < 0.05). Our methodology provides a replicable approach for
analyzing and addressing intersectional biases in image classification systems.

</details>


### [7] [Differentiable, Bit-shifting, and Scalable Quantization without training neural network from scratch](https://arxiv.org/abs/2510.16088)
*Zia Badar*

Main category: cs.CV

TL;DR: 该论文提出了一种可微分的量化方法，支持多比特量化，显著降低了计算和内存需求，在ImageNet上接近全精度模型的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决以往量化方法中非可微分性和激活量化与权重量化难以兼顾的问题，提高量化模型的准确性和训练效率。

Method: 采用可微分的量化方法，支持多比特量化，并提供了收敛性证明。

Result: 在ImageNet数据集上，仅对权重进行量化时，准确率损失小于1%；同时对权重和激活进行量化时，性能与SOTA方法相当，训练仅需15个epoch。

Conclusion: 该论文提出的可微分量化方法在图像分类任务中表现优异，接近全精度模型的准确率，同时显著降低了计算和内存需求。

Abstract: Quantization of neural networks provides benefits of inference in less
compute and memory requirements. Previous work in quantization lack two
important aspects which this work provides. First almost all previous work in
quantization used a non-differentiable approach and for learning; the
derivative is usually set manually in backpropogation which make the learning
ability of algorithm questionable, our approach is not just differentiable, we
also provide proof of convergence of our approach to the optimal neural
network. Second previous work in shift/logrithmic quantization either have
avoided activation quantization along with weight quantization or achieved less
accuracy. Learning logrithmic quantize values of form $2^n$ requires the
quantization function can scale to more than 1 bit quantization which is
another benifit of our quantization that it provides $n$ bits quantization as
well. Our approach when tested with image classification task using imagenet
dataset, resnet18 and weight quantization only achieves less than 1 percent
accuracy compared to full precision accuracy while taking only 15 epochs to
train using shift bit quantization and achieves comparable to SOTA approaches
accuracy in both weight and activation quantization using shift bit
quantization in 15 training epochs with slightly higher(only higher cpu
instructions) inference cost compared to 1 bit quantization(without logrithmic
quantization) and not requiring any higher precision multiplication.

</details>


### [8] [StripRFNet: A Strip Receptive Field and Shape-Aware Network for Road Damage Detection](https://arxiv.org/abs/2510.16115)
*Jianhan Lin,Yuchu Qin,Shuai Gao,Yikang Rui,Jie Liu,Yanjie Lv*

Main category: cs.CV

TL;DR: StripRFNet是一种新型深度神经网络，通过三个模块解决了道路损伤检测中的挑战，在RDD2022基准测试中表现优异，实现了高准确性和实时效率。


<details>
  <summary>Details</summary>
Motivation: 道路表面损伤威胁交通安全并阻碍可持续城市发展，但准确检测仍面临挑战，如损伤形状多样、细长裂缝难以捕捉和小规模损伤识别错误率高。

Method: StripRFNet由三个模块组成：形状感知模块（SPM）通过多尺度特征聚合增强形状区分；条状感受野模块（SRFM）捕获细长裂缝特征；小规模增强模块（SSEM）提高小物体检测能力。

Result: 在RDD2022基准测试中，StripRFNet优于现有方法，在中国子集上F1分数、mAP50和mAP50:95分别提高了4.4、2.9和3.4个百分点，在全数据集上F1分数达到80.33%。

Conclusion: StripRFNet在道路表面损伤检测中实现了最先进的准确性和实时效率，为智能道路维护和可持续基础设施管理提供了有前景的工具。

Abstract: Well-maintained road networks are crucial for achieving Sustainable
Development Goal (SDG) 11. Road surface damage not only threatens traffic
safety but also hinders sustainable urban development. Accurate detection,
however, remains challenging due to the diverse shapes of damages, the
difficulty of capturing slender cracks with high aspect ratios, and the high
error rates in small-scale damage recognition. To address these issues, we
propose StripRFNet, a novel deep neural network comprising three modules: (1) a
Shape Perception Module (SPM) that enhances shape discrimination via large
separable kernel attention (LSKA) in multi-scale feature aggregation; (2) a
Strip Receptive Field Module (SRFM) that employs large strip convolutions and
pooling to capture features of slender cracks; and (3) a Small-Scale
Enhancement Module (SSEM) that leverages a high-resolution P2 feature map, a
dedicated detection head, and dynamic upsampling to improve small-object
detection. Experiments on the RDD2022 benchmark show that StripRFNet surpasses
existing methods. On the Chinese subset, it improves F1-score, mAP50, and
mAP50:95 by 4.4, 2.9, and 3.4 percentage points over the baseline,
respectively. On the full dataset, it achieves the highest F1-score of 80.33%
compared with CRDDC'2022 participants and ORDDC'2024 Phase 2 results, while
maintaining competitive inference speed. These results demonstrate that
StripRFNet achieves state-of-the-art accuracy and real-time efficiency,
offering a promising tool for intelligent road maintenance and sustainable
infrastructure management.

</details>


### [9] [ObjectTransforms for Uncertainty Quantification and Reduction in Vision-Based Perception for Autonomous Vehicles](https://arxiv.org/abs/2510.16118)
*Nishad Sahu,Shounak Sural,Aditya Satish Patil,Ragunathan,Rajkumar*

Main category: cs.CV

TL;DR: ObjectTransforms通过对象特定变换在训练和推理阶段量化并减少视觉目标检测中的不确定性，提升检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶中基于视觉的目标检测神经网络易受数据偏差和分布偏移等不确定性影响，影响安全决策的可靠性。

Method: 在训练时，ObjectTransforms通过对单个对象进行色彩空间扰动，增强对光照和颜色变化的鲁棒性；同时利用扩散模型生成多样化的行人实例。在推理时，对检测到的对象应用扰动，并通过检测分数的方差实时量化预测不确定性。

Result: 在NuImages 10K数据集上使用YOLOv8的实验表明，该方法在所有目标类别上均显著提高了准确性并减少了不确定性，同时在推理阶段对假阳性预测了更高的不确定性值。

Conclusion: ObjectTransforms作为一种轻量级但有效的机制，在训练和推理阶段分别减少和量化视觉感知中的不确定性，展现出显著潜力。

Abstract: Reliable perception is fundamental for safety critical decision making in
autonomous driving. Yet, vision based object detector neural networks remain
vulnerable to uncertainty arising from issues such as data bias and
distributional shifts. In this paper, we introduce ObjectTransforms, a
technique for quantifying and reducing uncertainty in vision based object
detection through object specific transformations at both training and
inference times. At training time, ObjectTransforms perform color space
perturbations on individual objects, improving robustness to lighting and color
variations. ObjectTransforms also uses diffusion models to generate realistic,
diverse pedestrian instances. At inference time, object perturbations are
applied to detected objects and the variance of detection scores are used to
quantify predictive uncertainty in real time. This uncertainty signal is then
used to filter out false positives and also recover false negatives, improving
the overall precision recall curve. Experiments with YOLOv8 on the NuImages 10K
dataset demonstrate that our method yields notable accuracy improvements and
uncertainty reduction across all object classes during training, while
predicting desirably higher uncertainty values for false positives as compared
to true positives during inference. Our results highlight the potential of
ObjectTransforms as a lightweight yet effective mechanism for reducing and
quantifying uncertainty in vision-based perception during training and
inference respectively.

</details>


### [10] [Aria Gen 2 Pilot Dataset](https://arxiv.org/abs/2510.16134)
*Chen Kong,James Fort,Aria Kang,Jonathan Wittmer,Simon Green,Tianwei Shen,Yipu Zhao,Cheng Peng,Gustavo Solaira,Andrew Berkovich,Nikhil Raina,Vijay Baiyya,Evgeniy Oleinik,Eric Huang,Fan Zhang,Julian Straub,Mark Schwesinger,Luis Pesqueira,Xiaqing Pan,Jakob Julian Engel,Carl Ren,Mingfei Yan,Richard Newcombe*

Main category: cs.CV

TL;DR: A2PD是一个通过Aria Gen 2眼镜捕捉的多模态数据集，涵盖五种日常活动场景，公开提供数据及工具，支持多模态感知研究。


<details>
  <summary>Details</summary>
Motivation: 为了促进多模态感知研究，提供及时的数据访问，并展示设备在不同用户和条件下的稳健性能。

Method: 使用Aria Gen 2眼镜捕捉多模态数据，涵盖五种主要场景（清洁、烹饪、进食、玩耍和户外步行），并提供原始传感器数据及机器感知算法输出数据。

Result: A2PD数据集已公开发布，包含丰富的场景数据和机器感知算法输出，展示了设备在感知佩戴者、环境和交互方面的能力。

Conclusion: A2PD作为一个公开的多模态数据集，通过Aria Gen 2眼镜捕捉了丰富的日常活动场景数据，并提供了开源工具和示例，支持研究者和开发者使用。

Abstract: The Aria Gen 2 Pilot Dataset (A2PD) is an egocentric multimodal open dataset
captured using the state-of-the-art Aria Gen 2 glasses. To facilitate timely
access, A2PD is released incrementally with ongoing dataset enhancements. The
initial release features Dia'ane, our primary subject, who records her daily
activities alongside friends, each equipped with Aria Gen 2 glasses. It
encompasses five primary scenarios: cleaning, cooking, eating, playing, and
outdoor walking. In each of the scenarios, we provide comprehensive raw sensor
data and output data from various machine perception algorithms. These data
illustrate the device's ability to perceive the wearer, the surrounding
environment, and interactions between the wearer and the environment, while
maintaining robust performance across diverse users and conditions. The A2PD is
publicly available at projectaria.com, with open-source tools and usage
examples provided in Project Aria Tools.

</details>


### [11] [GuideFlow3D: Optimization-Guided Rectified Flow For Appearance Transfer](https://arxiv.org/abs/2510.16136)
*Sayan Deb Sarkar,Sinisa Stekovic,Vincent Lepetit,Iro Armeni*

Main category: cs.CV

TL;DR: 本文提出一种无训练方法，通过通用引导成功将外观细节转移到3D资产，优于基线方法，并使用GPT系统进行客观评估。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的方法在输入与外观对象的几何形状差异较大时仍存在失败。直接应用3D生成模型无法产生吸引人的结果，因此需要一种更有效的方法。

Method: 提出了一种基于预训练校正流模型的无训练方法，通过周期性添加引导来与采样过程交互。引导可建模为可微分损失函数，实验使用了两种引导类型：外观的部分感知损失和自相似性。

Result: 实验表明，该方法成功将纹理和几何细节转移到输入3D资产上，且在定性和定量上均优于基线方法。传统评估指标不适用于此任务，因此采用基于GPT的客观排名系统进行评估。

Conclusion: 本文提出了一种基于通用引导原则的无训练方法，成功将外观细节转移到3D资产上，并在质量和数量上优于基线方法。该方法具有通用性，可扩展到不同类型的扩散模型和引导函数。

Abstract: Transferring appearance to 3D assets using different representations of the
appearance object - such as images or text - has garnered interest due to its
wide range of applications in industries like gaming, augmented reality, and
digital content creation. However, state-of-the-art methods still fail when the
geometry between the input and appearance objects is significantly different. A
straightforward approach is to directly apply a 3D generative model, but we
show that this ultimately fails to produce appealing results. Instead, we
propose a principled approach inspired by universal guidance. Given a
pretrained rectified flow model conditioned on image or text, our training-free
method interacts with the sampling process by periodically adding guidance.
This guidance can be modeled as a differentiable loss function, and we
experiment with two different types of guidance including part-aware losses for
appearance and self-similarity. Our experiments show that our approach
successfully transfers texture and geometric details to the input 3D asset,
outperforming baselines both qualitatively and quantitatively. We also show
that traditional metrics are not suitable for evaluating the task due to their
inability of focusing on local details and comparing dissimilar inputs, in
absence of ground truth data. We thus evaluate appearance transfer quality with
a GPT-based system objectively ranking outputs, ensuring robust and human-like
assessment, as further confirmed by our user study. Beyond showcased scenarios,
our method is general and could be extended to different types of diffusion
models and guidance functions.

</details>


### [12] [From Mannequin to Human: A Pose-Aware and Identity-Preserving Video Generation Framework for Lifelike Clothing Display](https://arxiv.org/abs/2510.16833)
*Xiangyu Mu,Dongliang Zhou,Jie Hou,Haijun Zhang,Weili Guan*

Main category: cs.CV

TL;DR: M2HVideo是一种从人体模型生成真实人类视频的新框架，通过动态头部编码和镜像损失等技术，解决了运动不对齐和身份漂移问题，实验证明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决基于人体模型的服装展示缺乏真实感和表达细节的问题，提出了从人体模型到真实人类视频生成的新任务。

Method: 提出了M2HVideo框架，结合动态姿态感知头部编码器、基于DDIM的一步去噪镜像损失和分布感知适配器，以解决身份漂移和运动不对齐问题。

Result: 在UBC时尚数据集、自建的ASOS数据集和现场采集的MannequinVideos数据集上的实验表明，M2HVideo在服装一致性、身份保持和视频保真度方面表现优异。

Conclusion: M2HVideo框架在服装一致性、身份保持和视频保真度方面优于现有方法，通过动态姿态感知头部编码器和镜像损失等创新设计，成功解决了头部与身体运动不对齐及身份漂移问题。

Abstract: Mannequin-based clothing displays offer a cost-effective alternative to
real-model showcases for online fashion presentation, but lack realism and
expressive detail. To overcome this limitation, we introduce a new task called
mannequin-to-human (M2H) video generation, which aims to synthesize
identity-controllable, photorealistic human videos from footage of mannequins.
We propose M2HVideo, a pose-aware and identity-preserving video generation
framework that addresses two key challenges: the misalignment between head and
body motion, and identity drift caused by temporal modeling. In particular,
M2HVideo incorporates a dynamic pose-aware head encoder that fuses facial
semantics with body pose to produce consistent identity embeddings across
frames. To address the loss of fine facial details due to latent space
compression, we introduce a mirror loss applied in pixel space through a
denoising diffusion implicit model (DDIM)-based one-step denoising.
Additionally, we design a distribution-aware adapter that aligns statistical
distributions of identity and clothing features to enhance temporal coherence.
Extensive experiments on the UBC fashion dataset, our self-constructed ASOS
dataset, and the newly collected MannequinVideos dataset captured on-site
demonstrate that M2HVideo achieves superior performance in terms of clothing
consistency, identity preservation, and video fidelity in comparison to
state-of-the-art methods.

</details>


### [13] [C-arm Guidance: A Self-supervised Approach To Automated Positioning During Stroke Thrombectomy](https://arxiv.org/abs/2510.16145)
*Ahmad Arrabi,Jay hwasung Jung,J Le,A Nguyen,J Reed,E Stahl,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 本文提出自监督学习框架，通过回归任务分类骨骼标志点，提升血栓切除术效率，未来目标为实现自主C臂控制。


<details>
  <summary>Details</summary>
Motivation: 血栓切除术是治疗缺血性中风的有效方法，但资源密集且依赖专业人员。通过深度学习自动化关键步骤可提高效率和安全性。

Method: 采用自监督学习框架，利用回归任务作为前置任务来分类骨骼标志点。

Result: 模型在回归和分类任务中表现优于现有方法，位置前置任务显著提升下游分类性能。

Conclusion: 本文提出了一种自监督框架，通过基于回归的前置任务分类骨骼标志点，实验证明该模型在回归和分类任务中均优于现有方法。未来工作将扩展此框架以实现完全自主的C臂控制，优化中风血栓切除术中的轨迹。

Abstract: Thrombectomy is one of the most effective treatments for ischemic stroke, but
it is resource and personnel-intensive. We propose employing deep learning to
automate critical aspects of thrombectomy, thereby enhancing efficiency and
safety. In this work, we introduce a self-supervised framework that classifies
various skeletal landmarks using a regression-based pretext task. Our
experiments demonstrate that our model outperforms existing methods in both
regression and classification tasks. Notably, our results indicate that the
positional pretext task significantly enhances downstream classification
performance. Future work will focus on extending this framework toward fully
autonomous C-arm control, aiming to optimize trajectories from the pelvis to
the head during stroke thrombectomy procedures. All code used is available at
https://github.com/AhmadArrabi/C_arm_guidance

</details>


### [14] [DuetMatch: Harmonizing Semi-Supervised Brain MRI Segmentation via Decoupled Branch Optimization](https://arxiv.org/abs/2510.16146)
*Thanh-Huy Nguyen,Hoang-Thien Nguyen,Vi Vu,Ba-Thinh Lam,Phat Huynh,Tianyang Wang,Xingjian Li,Ulas Bagci,Min Xu*

Main category: cs.CV

TL;DR: DuetMatch是一种新型双分支半监督框架，通过异步优化和多种正则化技术，显著提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像标注数据有限的问题，并提升教师-学生框架在联合优化时的收敛性和稳定性。

Method: 提出DuetMatch，一种具有异步优化的双分支半监督框架，采用解耦丢弃扰动、成对CutMix交叉引导和一致性匹配来提升模型性能。

Result: 在ISLES2022和BraTS等脑MRI分割基准数据集上，DuetMatch持续优于现有最先进方法。

Conclusion: DuetMatch在医学图像分割的多种半监督场景中表现出色，证明了其有效性和鲁棒性。

Abstract: The limited availability of annotated data in medical imaging makes
semi-supervised learning increasingly appealing for its ability to learn from
imperfect supervision. Recently, teacher-student frameworks have gained
popularity for their training benefits and robust performance. However, jointly
optimizing the entire network can hinder convergence and stability, especially
in challenging scenarios. To address this for medical image segmentation, we
propose DuetMatch, a novel dual-branch semi-supervised framework with
asynchronous optimization, where each branch optimizes either the encoder or
decoder while keeping the other frozen. To improve consistency under noisy
conditions, we introduce Decoupled Dropout Perturbation, enforcing
regularization across branches. We also design Pair-wise CutMix Cross-Guidance
to enhance model diversity by exchanging pseudo-labels through augmented input
pairs. To mitigate confirmation bias from noisy pseudo-labels, we propose
Consistency Matching, refining labels using stable predictions from frozen
teacher models. Extensive experiments on benchmark brain MRI segmentation
datasets, including ISLES2022 and BraTS, show that DuetMatch consistently
outperforms state-of-the-art methods, demonstrating its effectiveness and
robustness across diverse semi-supervised segmentation scenarios.

</details>


### [15] [Automated C-Arm Positioning via Conformal Landmark Localization](https://arxiv.org/abs/2510.16160)
*Ahmad Arrabi,Jay Hwasung Jung,Jax Luo,Nathan Franssen,Scott Raymond,Safwan Wshah*

Main category: cs.CV

TL;DR: 该论文提出了一种自主导航C臂到解剖标志的流程，结合预测不确定性和校准方法，验证了其在安全和可靠自主系统中的潜力。


<details>
  <summary>Details</summary>
Motivation: 临床工作流程依赖手动对齐C臂，增加了辐射暴露和手术延迟，需要一种自主导航方法以提高效率和安全性。

Method: 提出了一种结合概率损失和骨骼姿态正则化的训练框架，利用X射线图像预测3D位移向量，并采用保形预测校准不确定性。

Result: 在合成X射线数据集上的验证表明，该方法不仅定位准确，而且预测边界校准良好。

Conclusion: 该论文展示了一种自主导航C臂到预定义解剖标志的流程，结合了预测不确定性和校准方法，展示了其在安全和可靠自主C臂系统中的潜力。

Abstract: Accurate and reliable C-arm positioning is essential for fluoroscopy-guided
interventions. However, clinical workflows rely on manual alignment that
increases radiation exposure and procedural delays. In this work, we present a
pipeline that autonomously navigates the C-arm to predefined anatomical
landmarks utilizing X-ray images. Given an input X-ray image from an arbitrary
starting location on the operating table, the model predicts a 3D displacement
vector toward each target landmark along the body. To ensure reliable
deployment, we capture both aleatoric and epistemic uncertainties in the
model's predictions and further calibrate them using conformal prediction. The
derived prediction regions are interpreted as 3D confidence regions around the
predicted landmark locations. The training framework combines a probabilistic
loss with skeletal pose regularization to encourage anatomically plausible
outputs. We validate our approach on a synthetic X-ray dataset generated from
DeepDRR. Results show not only strong localization accuracy across multiple
architectures but also well-calibrated prediction bounds. These findings
highlight the pipeline's potential as a component in safe and reliable
autonomous C-arm systems. Code is available at
https://github.com/AhmadArrabi/C_arm_guidance_APAH

</details>


### [16] [Cost Savings from Automatic Quality Assessment of Generated Images](https://arxiv.org/abs/2510.16179)
*Xavier Giro-i-Nieto,Nefeli Andreou,Anqi Liang,Manel Baradad,Francesc Moreno-Noguer,Aleix Martinez*

Main category: cs.CV

TL;DR: 本文提出了一种自动预过滤方法，通过公式估计成本节约，并在背景修复用例中验证了其有效性，实现了51.61%的成本节约。


<details>
  <summary>Details</summary>
Motivation: 当前深度生成模型生成的图像质量尚未达到传统摄影方法的标准，手动图像质量评估（IQA）过程成本高且效率低。

Method: 提出了一种公式，用于估计通用IQA引擎的精度和通过率对成本节约的影响，并在背景修复的用例中应用该公式。

Result: 在背景修复的用例中，通过自动预过滤阶段实现了51.61%的成本节约。

Conclusion: 本文提出了一种自动预过滤阶段的方法，显著降低了高质量图像获取的平均成本，通过简单的AutoML解决方案实现了51.61%的成本节约。

Abstract: Deep generative models have shown impressive progress in recent years, making
it possible to produce high quality images with a simple text prompt or a
reference image. However, state of the art technology does not yet meet the
quality standards offered by traditional photographic methods. For this reason,
production pipelines that use generated images often include a manual stage of
image quality assessment (IQA). This process is slow and expensive, especially
because of the low yield of automatically generated images that pass the
quality bar. The IQA workload can be reduced by introducing an automatic
pre-filtering stage, that will increase the overall quality of the images sent
to review and, therefore, reduce the average cost required to obtain a high
quality image. We present a formula that estimates the cost savings depending
on the precision and pass yield of a generic IQA engine. This formula is
applied in a use case of background inpainting, showcasing a significant cost
saving of 51.61% obtained with a simple AutoML solution.

</details>


### [17] [Seeing Through the Brain: New Insights from Decoding Visual Stimuli with fMRI](https://arxiv.org/abs/2510.16196)
*Zheng Huang,Enpei Zhang,Yinghao Cai,Weikang Qiu,Carl Yang,Elynn Chen,Xiang Zhang,Rex Ying,Dawei Zhou,Yujun Yan*

Main category: cs.CV

TL;DR: PRISM模型通过将fMRI信号投射到结构化文本空间并结合对象组合和属性关系优化，显著提升了图像重建质量，验证了文本空间作为中间表示的有效性。


<details>
  <summary>Details</summary>
Motivation: 理解大脑如何编码视觉信息是神经科学和机器学习中的核心挑战。从fMRI信号重建视觉刺激（图像）是一个有前景的方法，但哪种潜在空间最适合这种转换及其组织方式尚不明确。

Method: PRISM模型包括两个关键模块：1) 对象中心扩散模块，通过组合单个对象生成图像以减少对象检测错误；2) 属性关系搜索模块，自动识别与神经活动最匹配的关键属性和关系。

Result: 实验表明，PRISM框架在真实数据集上优于现有方法，实现了高达8%的感知损失减少。fMRI信号与语言模型的文本空间相似度高于视觉或文本图像联合空间。

Conclusion: 使用结构化文本作为中间空间来连接fMRI信号和图像重建的重要性得到了验证。PRISM模型通过将fMRI信号投射到结构化文本空间，并结合对象中心扩散模块和属性关系搜索模块，显著提升了重建质量。

Abstract: Understanding how the brain encodes visual information is a central challenge
in neuroscience and machine learning. A promising approach is to reconstruct
visual stimuli, essentially images, from functional Magnetic Resonance Imaging
(fMRI) signals. This involves two stages: transforming fMRI signals into a
latent space and then using a pretrained generative model to reconstruct
images. The reconstruction quality depends on how similar the latent space is
to the structure of neural activity and how well the generative model produces
images from that space. Yet, it remains unclear which type of latent space best
supports this transformation and how it should be organized to represent visual
stimuli effectively. We present two key findings. First, fMRI signals are more
similar to the text space of a language model than to either a vision based
space or a joint text image space. Second, text representations and the
generative model should be adapted to capture the compositional nature of
visual stimuli, including objects, their detailed attributes, and
relationships. Building on these insights, we propose PRISM, a model that
Projects fMRI sIgnals into a Structured text space as an interMediate
representation for visual stimuli reconstruction. It includes an object centric
diffusion module that generates images by composing individual objects to
reduce object detection errors, and an attribute relationship search module
that automatically identifies key attributes and relationships that best align
with the neural activity. Extensive experiments on real world datasets
demonstrate that our framework outperforms existing methods, achieving up to an
8% reduction in perceptual loss. These results highlight the importance of
using structured text as the intermediate space to bridge fMRI signals and
image reconstruction.

</details>


### [18] [Data-Centric AI for Tropical Agricultural Mapping: Challenges, Strategies and Scalable Solutions](https://arxiv.org/abs/2510.16207)
*Mateus Pinto da Silva,Sabrina P. L. P. Correa,Hugo N. Oliveira,Ian M. Nunes,Jefersson A. dos Santos*

Main category: cs.CV

TL;DR: 本文提出数据中心AI方法解决热带农业遥感制图挑战，推荐9种实用技术。


<details>
  <summary>Details</summary>
Motivation: 热带农业遥感制图面临高质量标注数据缺乏、标注成本高、数据变异性和区域泛化性等挑战，传统模型中心方法受限。

Method: 采用数据中心的AI视角和流程，重点包括数据质量和整理，评估了如置信学习、核心集选择、数据增强和主动学习等技术。

Result: 确定了25种策略在大规模农业制图流程中的适用性，并推荐了其中9种最成熟的方法。

Conclusion: 本文提出了一种数据中心的AI方法，特别适用于热带农业遥感制图，推荐了9种成熟且简单的方法，适用于大规模项目。

Abstract: Mapping agriculture in tropical areas through remote sensing presents unique
challenges, including the lack of high-quality annotated data, the elevated
costs of labeling, data variability, and regional generalisation. This paper
advocates a Data-Centric Artificial Intelligence (DCAI) perspective and
pipeline, emphasizing data quality and curation as key drivers for model
robustness and scalability. It reviews and prioritizes techniques such as
confident learning, core-set selection, data augmentation, and active learning.
The paper highlights the readiness and suitability of 25 distinct strategies in
large-scale agricultural mapping pipelines. The tropical context is of high
interest, since high cloudiness, diverse crop calendars, and limited datasets
limit traditional model-centric approaches. This tutorial outlines practical
solutions as a data-centric approach for curating and training AI models better
suited to the dynamic realities of tropical agriculture. Finally, we propose a
practical pipeline using the 9 most mature and straightforward methods that can
be applied to a large-scale tropical agricultural mapping project.

</details>


### [19] [StretchySnake: Flexible SSM Training Unlocks Action Recognition Across Spatio-Temporal Scales](https://arxiv.org/abs/2510.16209)
*Nyle Siddiqui,Rohit Gupta,Sirnam Swetha,Mubarak Shah*

Main category: cs.CV

TL;DR: 提出StretchySnake，一种灵活训练SSMs的方法，通过动态调整时空分辨率，显著提升视频理解性能，尤其适用于长视频和短视频。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解任务的训练方法主要针对Transformer设计，未能充分利用SSMs的线性复杂度和隐藏状态递归特性，导致模型在未见过的时空分辨率下性能下降。

Method: 提出了一种灵活的训练方法，通过采样不同时空分辨率的视频并动态插值模型权重，使SSMs适应各种时空尺度。

Result: 在短动作（UCF-101, HMDB-51）和长动作（COIN, Breakfast）基准测试中，StretchySnake比Transformer和SSM基线模型性能提升高达28%，且对细粒度动作（SSV2, Diving-48）有强适应性。

Conclusion: 本文提出了一种灵活的SSMs训练方法StretchySnake，通过动态调整时空分辨率，显著提升了视频理解任务的性能，尤其在长视频和短视频上均表现出色。

Abstract: State space models (SSMs) have emerged as a competitive alternative to
transformers in various tasks. Their linear complexity and hidden-state
recurrence make them particularly attractive for modeling long sequences,
whereas attention becomes quadratically expensive. However, current training
methods for video understanding are tailored towards transformers and fail to
fully leverage the unique attributes of SSMs. For example, video models are
often trained at a fixed resolution and video length to balance the quadratic
scaling of attention cost against performance. Consequently, these models
suffer from degraded performance when evaluated on videos with spatial and
temporal resolutions unseen during training; a property we call spatio-temporal
inflexibility. In the context of action recognition, this severely limits a
model's ability to retain performance across both short- and long-form videos.
Therefore, we propose a flexible training method that leverages and improves
the inherent adaptability of SSMs. Our method samples videos at varying
temporal and spatial resolutions during training and dynamically interpolates
model weights to accommodate any spatio-temporal scale. This instills our SSM,
which we call StretchySnake, with spatio-temporal flexibility and enables it to
seamlessly handle videos ranging from short, fine-grained clips to long,
complex activities. We introduce and compare five different variants of
flexible training, and identify the most effective strategy for video SSMs. On
short-action (UCF-101, HMDB-51) and long-action (COIN, Breakfast) benchmarks,
StretchySnake outperforms transformer and SSM baselines alike by up to 28%,
with strong adaptability to fine-grained actions (SSV2, Diving-48). Therefore,
our method provides a simple drop-in training recipe that makes video SSMs more
robust, resolution-agnostic, and efficient across diverse action recognition
scenarios.

</details>


### [20] [VM-BeautyNet: A Synergistic Ensemble of Vision Transformer and Mamba for Facial Beauty Prediction](https://arxiv.org/abs/2510.16220)
*Djamel Eddine Boukhari*

Main category: cs.CV

TL;DR: VM-BeautyNet结合ViT和Mamba模型的优势，在面部美预测任务中实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法（如CNN）难以捕捉人类审美判断中关键的全局、整体面部特征，而Vision Transformers虽能有效建模长距离空间关系，但其二次复杂度成为瓶颈。

Method: 提出了一种新颖的异构集成架构VM-BeautyNet，融合了Vision Transformer和Mamba-based Vision模型的优势，前者擅长捕捉全局面部结构，后者高效建模长距离依赖关系。

Result: 在SCUT-FBP5500数据集上，VM-BeautyNet取得了Pearson Correlation (PC)为0.9212、Mean Absolute Error (MAE)为0.2085、Root Mean Square Error (RMSE)为0.2698的优异表现。

Conclusion: VM-BeautyNet通过结合Vision Transformer和Mamba-based Vision模型的互补优势，在SCUT-FBP5500数据集上实现了最先进的性能，为计算美学提供了强大的新架构范式。

Abstract: Facial Beauty Prediction (FBP) is a complex and challenging computer vision
task, aiming to model the subjective and intricate nature of human aesthetic
perception. While deep learning models, particularly Convolutional Neural
Networks (CNNs), have made significant strides, they often struggle to capture
the global, holistic facial features that are critical to human judgment.
Vision Transformers (ViT) address this by effectively modeling long-range
spatial relationships, but their quadratic complexity can be a bottleneck. This
paper introduces a novel, heterogeneous ensemble architecture,
\textbf{VM-BeautyNet}, that synergistically fuses the complementary strengths
of a Vision Transformer and a Mamba-based Vision model, a recent advancement in
State-Space Models (SSMs). The ViT backbone excels at capturing global facial
structure and symmetry, while the Mamba backbone efficiently models long-range
dependencies with linear complexity, focusing on sequential features and
textures. We evaluate our approach on the benchmark SCUT-FBP5500 dataset. Our
proposed VM-BeautyNet achieves state-of-the-art performance, with a
\textbf{Pearson Correlation (PC) of 0.9212}, a \textbf{Mean Absolute Error
(MAE) of 0.2085}, and a \textbf{Root Mean Square Error (RMSE) of 0.2698}.
Furthermore, through Grad-CAM visualizations, we provide interpretability
analysis that confirms the complementary feature extraction of the two
backbones, offering new insights into the model's decision-making process and
presenting a powerful new architectural paradigm for computational aesthetics.

</details>


### [21] [Designing a Convolutional Neural Network for High-Accuracy Oral Cavity Squamous Cell Carcinoma (OCSCC) Detection](https://arxiv.org/abs/2510.16235)
*Vishal Manikanden,Aniketh Bandlamudi,Daniel Haehn*

Main category: cs.CV

TL;DR: 研究通过CNN和图像硬件系统提升口腔鳞状细胞癌的早期检测效率，发现更高分辨率图像能提高准确率但边际效益递减。


<details>
  <summary>Details</summary>
Motivation: 口腔鳞状细胞癌（OCSCC）是头颈部最常见的癌症，早期症状不明显且生长缓慢，常被忽视而导致可预防的死亡。通过训练CNN结合图像采集和处理硬件，可以提高OCSCC的早期检测效率。

Method: 研究团队训练了一个卷积神经网络（CNN），使用4293张包含良性和恶性肿瘤以及阴性样本的训练图像。测试数据集包括随机选择的癌症、非癌症和阴性图像，每张图像被调整为5种常见分辨率。CNN对这些图像进行了全面分析，并根据准确性评分。此外，设计了图像增强硬件以捕获详细图像，并评估其效果。

Result: CNN在测试数据集上表现出色，图像分辨率的增加以对数比例提高了预测准确率，但高像素的边际效益递减。开发的硬件系统和应用程序显著提升了检测效率和可访问性。

Conclusion: 研究表明，图像分辨率的提高可以显著提升CNN对口腔鳞状细胞癌（OCSCC）的检测准确率，但高像素带来的边际效益递减。开发的硬件系统和应用程序为OCSCC的早期检测提供了开放且高效的工具。

Abstract: Oral Cavity Squamous Cell Carcinoma (OCSCC) is the most common type of head
and neck cancer. Due to the subtle nature of its early stages, deep and hidden
areas of development, and slow growth, OCSCC often goes undetected, leading to
preventable deaths. However, properly trained Convolutional Neural Networks
(CNNs), with their precise image segmentation techniques and ability to apply
kernel matrices to modify the RGB values of images for accurate image pattern
recognition, would be an effective means for early detection of OCSCC. Pairing
this neural network with image capturing and processing hardware would allow
increased efficacy in OCSCC detection. The aim of our project is to develop a
Convolutional Neural Network trained to recognize OCSCC, as well as to design a
physical hardware system to capture and process detailed images, in order to
determine the image quality required for accurate predictions. A CNN was
trained on 4293 training images consisting of benign and malignant tumors, as
well as negative samples, and was evaluated for its precision, recall, and Mean
Average Precision (mAP) in its predictions of OCSCC. A testing dataset of
randomly assorted images of cancerous, non-cancerous, and negative images was
chosen, and each image was altered to represent 5 common resolutions. This test
data set was thoroughly analyzed by the CNN and predictions were scored on the
basis of accuracy. The designed enhancement hardware was used to capture
detailed images, and its impact was scored. An application was developed to
facilitate the testing process and bring open access to the CNN. Images of
increasing resolution resulted in higher-accuracy predictions on a logarithmic
scale, demonstrating the diminishing returns of higher pixel counts.

</details>


### [22] [Embody 3D: A Large-scale Multimodal Motion and Behavior Dataset](https://arxiv.org/abs/2510.16258)
*Claire McLean,Makenzie Meendering,Tristan Swartz,Orri Gabbay,Alexandra Olsen,Rachel Jacobs,Nicholas Rosen,Philippe de Bree,Tony Garcia,Gadsden Merrill,Jake Sandakly,Julia Buffalini,Neham Jain,Steven Krenn,Moneish Kumar,Dejan Markovic,Evonne Ng,Fabian Prada,Andrew Saba,Siwei Zhang,Vasu Agrawal,Tim Godisart,Alexander Richard,Michael Zollhoefer*

Main category: cs.CV

TL;DR: Meta的Codec Avatars Lab发布Embody 3D数据集，包含500小时439人的3D运动数据，涵盖手势、情感对话及协作活动。


<details>
  <summary>Details</summary>
Motivation: 为研究3D人体运动、手势识别、情感对话及多人协作行为提供高质量、多样化的数据集。

Method: 通过多摄像头采集439名参与者的500小时3D运动数据，包括单人动作、手势、多人对话及协作活动。

Result: 收集了超过5400万帧的3D运动数据，包括手部追踪、身体形状、文本注释及独立音频轨道。

Conclusion: Embody 3D数据集为研究3D运动、手势、情感状态下的对话及协作活动提供了丰富的多模态数据支持。

Abstract: The Codec Avatars Lab at Meta introduces Embody 3D, a multimodal dataset of
500 individual hours of 3D motion data from 439 participants collected in a
multi-camera collection stage, amounting to over 54 million frames of tracked
3D motion. The dataset features a wide range of single-person motion data,
including prompted motions, hand gestures, and locomotion; as well as
multi-person behavioral and conversational data like discussions, conversations
in different emotional states, collaborative activities, and co-living
scenarios in an apartment-like space. We provide tracked human motion including
hand tracking and body shape, text annotations, and a separate audio track for
each participant.

</details>


### [23] [Proactive Scene Decomposition and Reconstruction](https://arxiv.org/abs/2510.16272)
*Baicheng Li,Zike Yan,Dong Wu,Hongbin Zha*

Main category: cs.CV

TL;DR: 该论文提出了一种基于人机交互的动态场景分解与重建系统，通过高斯溅射技术实现高效渲染，验证了其在实际应用中的优势。


<details>
  <summary>Details</summary>
Motivation: 传统静态物体级重建方法存在固有模糊性，而人类行为是场景动态的主要驱动力，蕴含丰富动态线索。

Method: 利用人机交互线索，结合高斯溅射技术，实现动态场景的在线分解与重建，同时整合相机和物体姿态估计、实例分解及在线地图更新等多任务。

Result: 在多种真实场景中验证了方法的有效性，展示了其在动态环境中的灵活性和渐进式优势。

Conclusion: 该论文提出了一种基于人机交互的动态场景分解与重建方法，通过高斯溅射技术实现了高效且逼真的渲染，验证了其在多种真实场景中的有效性。

Abstract: Human behaviors are the major causes of scene dynamics and inherently contain
rich cues regarding the dynamics. This paper formalizes a new task of proactive
scene decomposition and reconstruction, an online approach that leverages
human-object interactions to iteratively disassemble and reconstruct the
environment. By observing these intentional interactions, we can dynamically
refine the decomposition and reconstruction process, addressing inherent
ambiguities in static object-level reconstruction. The proposed system
effectively integrates multiple tasks in dynamic environments such as accurate
camera and object pose estimation, instance decomposition, and online map
updating, capitalizing on cues from human-object interactions in egocentric
live streams for a flexible, progressive alternative to conventional
object-level reconstruction methods. Aided by the Gaussian splatting technique,
accurate and consistent dynamic scene modeling is achieved with photorealistic
and efficient rendering. The efficacy is validated in multiple real-world
scenarios with promising advantages.

</details>


### [24] [Cerberus: Real-Time Video Anomaly Detection via Cascaded Vision-Language Models](https://arxiv.org/abs/2510.16290)
*Yue Zheng,Xiufang Shi,Jiming Chen,Yuanchao Shu*

Main category: cs.CV

TL;DR: Cerberus通过两阶段设计和运动掩码提示、规则偏差检测等创新，实现了高效且准确的实时视频异常检测，速度提升151.79倍，精度达97.2%。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言模型（VLM）在零样本检测方面表现优异，但其高计算成本和不稳定的视觉定位性能限制了实时部署。Cerberus旨在克服这些挑战。

Method: Cerberus采用两阶段级联系统，离线学习正常行为规则，在线推理时结合轻量级过滤和细粒度VLM推理。关键创新包括运动掩码提示和基于规则的偏差检测。

Result: 在四个数据集上的评估显示，Cerberus平均达到57.68 fps（151.79倍加速），97.2%的准确率，与最先进的VLM-based VAD方法相当。

Conclusion: Cerberus提出了一种高效且准确的实时视频异常检测系统，通过两阶段级联设计和关键创新（运动掩码提示和基于规则的偏差检测），在保持高精度的同时显著提升了处理速度。

Abstract: Video anomaly detection (VAD) has rapidly advanced by recent development of
Vision-Language Models (VLMs). While these models offer superior zero-shot
detection capabilities, their immense computational cost and unstable visual
grounding performance hinder real-time deployment. To overcome these
challenges, we introduce Cerberus, a two-stage cascaded system designed for
efficient yet accurate real-time VAD. Cerberus learns normal behavioral rules
offline, and combines lightweight filtering with fine-grained VLM reasoning
during online inference. The performance gains of Cerberus come from two key
innovations: motion mask prompting and rule-based deviation detection. The
former directs the VLM's attention to regions relevant to motion, while the
latter identifies anomalies as deviations from learned norms rather than
enumerating possible anomalies. Extensive evaluations on four datasets show
that Cerberus on average achieves 57.68 fps on an NVIDIA L40S GPU, a
151.79$\times$ speedup, and 97.2\% accuracy comparable to the state-of-the-art
VLM-based VAD methods, establishing it as a practical solution for real-time
video analytics.

</details>


### [25] [OpenLVLM-MIA: A Controlled Benchmark Revealing the Limits of Membership Inference Attacks on Large Vision-Language Models](https://arxiv.org/abs/2510.16295)
*Ryoto Miyamoto,Xin Fan,Fuyuko Kido,Tsuneo Matsumoto,Hayato Yamana*

Main category: cs.CV

TL;DR: OpenLVLM-MIA是一个新的基准，通过平衡成员和非成员样本分布，揭示了当前成员推理攻击方法在无偏条件下的局限性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究报告了高攻击成功率，但这些结果往往源于检测数据集构建过程中引入的分布偏差，而非真实的成员状态识别。

Method: 引入了一个包含6,000张图像的受控基准，其中成员和非成员样本的分布经过精心平衡，并在三个不同的训练阶段提供了真实成员标签。

Result: 实验表明，在最先进的成员推理攻击方法在无偏条件下，其性能收敛于随机猜测水平。

Conclusion: OpenLVLM-MIA作为一个透明且无偏的基准，揭示了当前针对大型视觉语言模型的成员推理攻击研究的局限性，并为开发更强的隐私保护技术奠定了基础。

Abstract: OpenLVLM-MIA is a new benchmark that highlights fundamental challenges in
evaluating membership inference attacks (MIA) against large vision-language
models (LVLMs). While prior work has reported high attack success rates, our
analysis suggests that these results often arise from detecting distributional
bias introduced during dataset construction rather than from identifying true
membership status. To address this issue, we introduce a controlled benchmark
of 6{,}000 images where the distributions of member and non-member samples are
carefully balanced, and ground-truth membership labels are provided across
three distinct training stages. Experiments using OpenLVLM-MIA demonstrated
that the performance of state-of-the-art MIA methods converged to random chance
under unbiased conditions. By offering a transparent and unbiased benchmark,
OpenLVLM-MIA clarifies the current limitations of MIA research on LVLMs and
provides a solid foundation for developing stronger privacy-preserving
techniques.

</details>


### [26] [Stroke2Sketch: Harnessing Stroke Attributes for Training-Free Sketch Generation](https://arxiv.org/abs/2510.16319)
*Rui Yang,Huining Li,Yiyi Long,Xiaojun Wu,Shengfeng He*

Main category: cs.CV

TL;DR: Stroke2Sketch是一种无需训练的框架，通过跨图像笔画注意机制实现风格化草图生成，保持语义结构并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成参考风格引导的草图需要精确传递笔画属性（如线条粗细、变形和纹理稀疏性），同时保持语义结构和内容保真度。

Method: 提出Stroke2Sketch框架，引入跨图像笔画注意机制，嵌入自注意力层以实现细粒度语义对应和笔画属性传递；开发自适应对比增强和语义聚焦注意以增强内容保留和前景强调。

Result: Stroke2Sketch能够合成风格忠实且接近手工绘制结果的草图，在表达性笔画控制和语义一致性方面表现优异。

Conclusion: Stroke2Sketch是一种无需训练的新框架，通过跨图像笔画注意机制，能够准确传递笔画属性并保持语义结构完整性，在表达性笔画控制和语义一致性方面优于现有方法。

Abstract: Generating sketches guided by reference styles requires precise transfer of
stroke attributes, such as line thickness, deformation, and texture sparsity,
while preserving semantic structure and content fidelity. To this end, we
propose Stroke2Sketch, a novel training-free framework that introduces
cross-image stroke attention, a mechanism embedded within self-attention layers
to establish fine-grained semantic correspondences and enable accurate stroke
attribute transfer. This allows our method to adaptively integrate reference
stroke characteristics into content images while maintaining structural
integrity. Additionally, we develop adaptive contrast enhancement and
semantic-focused attention to reinforce content preservation and foreground
emphasis. Stroke2Sketch effectively synthesizes stylistically faithful sketches
that closely resemble handcrafted results, outperforming existing methods in
expressive stroke control and semantic coherence. Codes are available at
https://github.com/rane7/Stroke2Sketch.

</details>


### [27] [Scaling Laws for Deepfake Detection](https://arxiv.org/abs/2510.16320)
*Wenhao Wang,Longqi Cai,Taihong Xiao,Yuxiao Wang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 本文构建了最大深度伪造检测数据集ScaleDF，发现检测误差随数据规模增加呈幂律衰减，为预测性能提升和数据对策提供了依据。


<details>
  <summary>Details</summary>
Motivation: 由于现有数据集规模不足，无法满足深度伪造检测任务的研究需求，因此构建了大规模数据集ScaleDF，并研究其缩放规律。

Method: 通过构建ScaleDF数据集（包含580万真实图像和880万伪造图像），系统分析了模型性能与真实图像域数量、深度伪造生成方法及训练图像数量的关系。

Result: 观察到类似于大型语言模型的幂律缩放规律，即平均检测误差随真实域或深度伪造方法数量的增加而呈幂律衰减。

Conclusion: 研究发现，随着真实图像域或深度伪造方法数量的增加，平均检测误差遵循可预测的幂律衰减。这一关键观察不仅有助于预测达到目标性能所需的额外资源，还启发了以数据为中心的对策来应对不断演变的深度伪造技术。

Abstract: This paper presents a systematic study of scaling laws for the deepfake
detection task. Specifically, we analyze the model performance against the
number of real image domains, deepfake generation methods, and training images.
Since no existing dataset meets the scale requirements for this research, we
construct ScaleDF, the largest dataset to date in this field, which contains
over 5.8 million real images from 51 different datasets (domains) and more than
8.8 million fake images generated by 102 deepfake methods. Using ScaleDF, we
observe power-law scaling similar to that shown in large language models
(LLMs). Specifically, the average detection error follows a predictable
power-law decay as either the number of real domains or the number of deepfake
methods increases. This key observation not only allows us to forecast the
number of additional real domains or deepfake methods required to reach a
target performance, but also inspires us to counter the evolving deepfake
technology in a data-centric manner. Beyond this, we examine the role of
pre-training and data augmentations in deepfake detection under scaling, as
well as the limitations of scaling itself.

</details>


### [28] [Scale-DiT: Ultra-High-Resolution Image Generation with Hierarchical Local Attention](https://arxiv.org/abs/2510.16325)
*Yuyao Zhang,Yu-Wing Tai*

Main category: cs.CV

TL;DR: Scale-DiT是一种新型扩散框架，通过分层局部注意力和全局引导实现高效、可扩展的超高分辨率图像生成，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决当前扩散模型在超高分辨率（如4K）图像生成中因注意力机制复杂度高和训练数据稀缺而受限的问题。

Method: 提出Scale-DiT框架，采用分层局部注意力机制和低分辨率潜在空间全局引导，结合LoRA适配和Hilbert曲线排序优化，实现高效的超高清图像生成。

Result: Scale-DiT在4K分辨率下实现了2倍以上的推理速度提升和更低的内存占用，同时在定量和定性评估中均优于现有方法。

Conclusion: Scale-DiT通过引入分层局部注意力和低分辨率全局引导，实现了高效、可扩展且语义连贯的超高分辨率图像生成，无需额外的高分辨率训练数据，且在性能和效率上优于现有方法。

Abstract: Ultra-high-resolution text-to-image generation demands both fine-grained
texture synthesis and globally coherent structure, yet current diffusion models
remain constrained to sub-$1K \times 1K$ resolutions due to the prohibitive
quadratic complexity of attention and the scarcity of native $4K$ training
data. We present \textbf{Scale-DiT}, a new diffusion framework that introduces
hierarchical local attention with low-resolution global guidance, enabling
efficient, scalable, and semantically coherent image synthesis at ultra-high
resolutions. Specifically, high-resolution latents are divided into fixed-size
local windows to reduce attention complexity from quadratic to near-linear,
while a low-resolution latent equipped with scaled positional anchors injects
global semantics. A lightweight LoRA adaptation bridges global and local
pathways during denoising, ensuring consistency across structure and detail. To
maximize inference efficiency, we repermute token sequence in Hilbert curve
order and implement a fused-kernel for skipping masked operations, resulting in
a GPU-friendly design. Extensive experiments demonstrate that Scale-DiT
achieves more than $2\times$ faster inference and lower memory usage compared
to dense attention baselines, while reliably scaling to $4K \times 4K$
resolution without requiring additional high-resolution training data. On both
quantitative benchmarks (FID, IS, CLIP Score) and qualitative comparisons,
Scale-DiT delivers superior global coherence and sharper local detail, matching
or outperforming state-of-the-art methods that rely on native 4K training.
Taken together, these results highlight hierarchical local attention with
guided low-resolution anchors as a promising and effective approach for
advancing ultra-high-resolution image generation.

</details>


### [29] [DiffusionX: Efficient Edge-Cloud Collaborative Image Generation with Multi-Round Prompt Evolution](https://arxiv.org/abs/2510.16326)
*Yi Wei,Shunpu Tang,Liang Zhao,Qiangian Yang*

Main category: cs.CV

TL;DR: DiffusionX通过云边协同和动态负载平衡，显著降低扩散模型生成延迟，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型生成过程计算密集、用户需多次迭代优化提示导致延迟高和云资源负担重的问题。

Method: 提出了DiffusionX框架，结合轻量级设备端扩散模型和高容量云端模型，并引入噪声水平预测器动态平衡计算负载。

Result: 实验表明，DiffusionX比Stable Diffusion v1.5平均生成时间减少15.8%，图像质量相近；比Tiny-SD仅慢0.9%但图像质量显著提升。

Conclusion: DiffusionX通过云边协同框架有效降低了生成延迟和云资源负担，同时在保证图像质量的前提下显著提升了效率。

Abstract: Recent advances in diffusion models have driven remarkable progress in image
generation. However, the generation process remains computationally intensive,
and users often need to iteratively refine prompts to achieve the desired
results, further increasing latency and placing a heavy burden on cloud
resources. To address this challenge, we propose DiffusionX, a cloud-edge
collaborative framework for efficient multi-round, prompt-based generation. In
this system, a lightweight on-device diffusion model interacts with users by
rapidly producing preview images, while a high-capacity cloud model performs
final refinements after the prompt is finalized. We further introduce a noise
level predictor that dynamically balances the computation load, optimizing the
trade-off between latency and cloud workload. Experiments show that DiffusionX
reduces average generation time by 15.8% compared with Stable Diffusion v1.5,
while maintaining comparable image quality. Moreover, it is only 0.9% slower
than Tiny-SD with significantly improved image quality, thereby demonstrating
efficiency and scalability with minimal overhead.

</details>


### [30] [TokenAR: Multiple Subject Generation via Autoregressive Token-level enhancement](https://arxiv.org/abs/2510.16332)
*Haiyue Sun,Qingdong He,Jinlong Peng,Peng Tang,Jiangning Zhang,Junwei Zhu,Xiaobin Hu,Shuicheng Yan*

Main category: cs.CV

TL;DR: TokenAR通过令牌级增强机制解决了多参考图像生成中的身份混淆问题，显著提升了性能，并引入了InstructAR数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归模型在多参考图像生成中存在参考身份混淆问题，需要一种简单但有效的机制来解耦不同参考身份。

Method: TokenAR框架包含三个部分：令牌索引嵌入（Token Index Embedding）、指令令牌注入（Instruct Token Injection）和身份令牌解耦策略（ITD）。此外，还引入了InstructAR数据集，包含28K训练对，用于多参考图像生成的训练和评估。

Result: 综合实验表明，TokenAR在多参考图像生成任务中超越了当前最先进的模型。

Conclusion: TokenAR框架通过简单的令牌级增强机制有效解决了参考身份混淆问题，显著提升了现有自回归模型在多参考图像生成中的性能。

Abstract: Autoregressive Model (AR) has shown remarkable success in conditional image
generation. However, these approaches for multiple reference generation
struggle with decoupling different reference identities. In this work, we
propose the TokenAR framework, specifically focused on a simple but effective
token-level enhancement mechanism to address reference identity confusion
problem. Such token-level enhancement consists of three parts, 1). Token Index
Embedding clusters the tokens index for better representing the same reference
images; 2). Instruct Token Injection plays as a role of extra visual feature
container to inject detailed and complementary priors for reference tokens; 3).
The identity-token disentanglement strategy (ITD) explicitly guides the token
representations toward independently representing the features of each
identity.This token-enhancement framework significantly augments the
capabilities of existing AR based methods in conditional image generation,
enabling good identity consistency while preserving high quality background
reconstruction. Driven by the goal of high-quality and high-diversity in
multi-subject generation, we introduce the InstructAR Dataset, the first
open-source, large-scale, multi-reference input, open domain image generation
dataset that includes 28K training pairs, each example has two reference
subjects, a relative prompt and a background with mask annotation, curated for
multiple reference image generation training and evaluating. Comprehensive
experiments validate that our approach surpasses current state-of-the-art
models in multiple reference image generation task. The implementation code and
datasets will be made publicly. Codes are available, see
https://github.com/lyrig/TokenAR

</details>


### [31] [RL makes MLLMs see better than SFT](https://arxiv.org/abs/2510.16333)
*Junha Song,Sangdoo Yun,Dongyoon Han,Jaegul Choo,Byeongho Heo*

Main category: cs.CV

TL;DR: 研究发现RL训练优于SFT，能提升视觉编码器的能力；提出的PIVOT方法高效且性能卓越。


<details>
  <summary>Details</summary>
Motivation: 当前MLLM研究忽视了视觉编码器的作用，尤其是从SFT转向RL训练范式时，缺乏对其如何重塑视觉编码器及MLLM的分析。

Method: 通过多样化的实验（如ImageNet分类、分割和梯度可视化）分析MLLM的视觉编码器，比较不同训练策略（SFT和RL）对视觉表示的影响。

Result: RL训练策略在强视觉相关的VQA基准测试中优于SFT，且能产生更精确的视觉表示。PIVOT方法在计算成本极低的情况下表现优异。

Conclusion: 通过研究发现，强化学习（RL）相较于监督微调（SFT）能产生更强且定位更精确的视觉表示，提升视觉编码器的能力。提出的PIVOT方法在计算成本极低的情况下，表现优于更大规模训练的视觉编码器，为MLLM的视觉主干提供了高效推进路径。

Abstract: A dominant assumption in Multimodal Language Model (MLLM) research is that
its performance is largely inherited from the LLM backbone, given its immense
parameter scale and remarkable capabilities. This has created a void in the
understanding of the vision encoder, which determines how MLLMs perceive
images. The recent shift in MLLM training paradigms, from Supervised Finetuning
(SFT) to Reinforcement Learning (RL), magnifies this oversight-namely, the
significant lack of analysis on how such training reshapes the vision encoder
as well as the MLLM. To address this, we first investigate the impact of
training strategies on MLLMs, where RL shows a clear advantage over SFT in
strongly vision-related VQA benchmarks. Motivated by this, we conduct a
critical yet under-explored analysis of the vision encoder of MLLMs through
diverse and in-depth experiments, ranging from ImageNet classification and
segmentation to gradient visualization. Our results demonstrate that MLLM's
post-training strategy (i.e., SFT or RL) not only leads to distinct outcomes on
MLLM downstream tasks, but also fundamentally reshapes MLLM's underlying visual
representations. Specifically, the key finding of our study is that RL produces
stronger and precisely localized visual representations compared to SFT,
boosting the ability of the vision encoder for MLLM. We then reframe our
findings into a simple recipe for building strong vision encoders for MLLMs,
Preference-Instructed Vision OpTimization (PIVOT). When integrated into MLLMs,
a PIVOT-trained vision encoder outperforms even larger and more heavily-trained
counterparts, despite requiring less than 1% of the computational cost of
standard vision pretraining. This result opens an effective and efficient path
for advancing the vision backbones of MLLMs. Project page available at
https://june-page.github.io/pivot/

</details>


### [32] [On the Provable Importance of Gradients for Language-Assisted Image Clustering](https://arxiv.org/abs/2510.16335)
*Bo Peng,Jie Lu,Guangquan Zhang,Zhen Fang*

Main category: cs.CV

TL;DR: 本文提出 GradNorm，一种基于梯度的框架，用于语言辅助图像聚类中的正名词过滤，理论上有保证且实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决 Language-assisted Image Clustering (LaIC) 中正名词过滤的挑战，现有方法缺乏理论基础。

Method: 提出了一种基于梯度的框架 GradNorm，通过反向传播交叉熵损失的梯度大小来衡量名词的积极性。

Result: GradNorm 在理论上有严格的误差界限，并在多个基准测试中表现出色。

Conclusion: GradNorm 提供了一个理论上有保证的框架，能够有效过滤正名词，显著提升图像聚类性能，并在多个基准测试中达到最先进水平。

Abstract: This paper investigates the recently emerged problem of Language-assisted
Image Clustering (LaIC), where textual semantics are leveraged to improve the
discriminability of visual representations to facilitate image clustering. Due
to the unavailability of true class names, one of core challenges of LaIC lies
in how to filter positive nouns, i.e., those semantically close to the images
of interest, from unlabeled wild corpus data. Existing filtering strategies are
predominantly based on the off-the-shelf feature space learned by CLIP;
however, despite being intuitive, these strategies lack a rigorous theoretical
foundation. To fill this gap, we propose a novel gradient-based framework,
termed as GradNorm, which is theoretically guaranteed and shows strong
empirical performance. In particular, we measure the positiveness of each noun
based on the magnitude of gradients back-propagated from the cross-entropy
between the predicted target distribution and the softmax output.
Theoretically, we provide a rigorous error bound to quantify the separability
of positive nouns by GradNorm and prove that GradNorm naturally subsumes
existing filtering strategies as extremely special cases of itself.
Empirically, extensive experiments show that GradNorm achieves the
state-of-the-art clustering performance on various benchmarks.

</details>


### [33] [MIRAD - A comprehensive real-world robust anomaly detection dataset for Mass Individualization](https://arxiv.org/abs/2510.16370)
*Pulin Li,Guocheng Wu,Li Yin,Yuxin Zheng,Wei Zhang,Yanjie Zhou*

Main category: cs.CV

TL;DR: MIRAD是首个针对社会制造中异常检测的基准数据集，覆盖了个体化产品的多样性、地理分散的制造节点和成像异质性。评估显示现有模型性能显著下降，为工业5.0的质量控制提供了现实基础。


<details>
  <summary>Details</summary>
Motivation: 社会制造模式下的质量控制在缺陷检测方面面临三大挑战：高度定制化的产品配置、小批量碎片化订单以及分布式站点间成像环境的显著差异。

Method: 引入了Mass Individualization Robust Anomaly Detection (MIRAD)数据集，并在该数据集上对最先进的异常检测方法进行了广泛评估，涵盖单类、多类和零样本方法。

Result: 所有模型在MIRAD上的性能均显著下降，凸显了现实世界个体化生产中缺陷检测的未解决复杂性。

Conclusion: MIRAD数据集为工业5.0时代提供了开发鲁棒质量控制解决方案的现实基础，填补了工业需求与学术研究之间的鸿沟。

Abstract: Social manufacturing leverages community collaboration and scattered
resources to realize mass individualization in modern industry. However, this
paradigm shift also introduces substantial challenges in quality control,
particularly in defect detection. The main difficulties stem from three
aspects. First, products often have highly customized configurations. Second,
production typically involves fragmented, small-batch orders. Third, imaging
environments vary considerably across distributed sites. To overcome the
scarcity of real-world datasets and tailored algorithms, we introduce the Mass
Individualization Robust Anomaly Detection (MIRAD) dataset. As the first
benchmark explicitly designed for anomaly detection in social manufacturing,
MIRAD captures three critical dimensions of this domain: (1) diverse
individualized products with large intra-class variation, (2) data collected
from six geographically dispersed manufacturing nodes, and (3) substantial
imaging heterogeneity, including variations in lighting, background, and motion
conditions. We then conduct extensive evaluations of state-of-the-art (SOTA)
anomaly detection methods on MIRAD, covering one-class, multi-class, and
zero-shot approaches. Results show a significant performance drop across all
models compared with conventional benchmarks, highlighting the unresolved
complexities of defect detection in real-world individualized production. By
bridging industrial requirements and academic research, MIRAD provides a
realistic foundation for developing robust quality control solutions essential
for Industry 5.0. The dataset is publicly available at
https://github.com/wu33learn/MIRAD.

</details>


### [34] [Cataract-LMM: Large-Scale, Multi-Source, Multi-Task Benchmark for Deep Learning in Surgical Video Analysis](https://arxiv.org/abs/2510.16371)
*Mohammad Javad Ahmadi,Iman Gandomi,Parisa Abdi,Seyed-Farzad Mohammadi,Amirhossein Taslimi,Mehdi Khodaparast,Hassan Hashemi,Mahdi Tavakoli,Hamid D. Taghirad*

Main category: cs.CV

TL;DR: 本文提出了一个包含3,000个白内障手术视频的数据集，具有多层注释，并通过基准测试验证了其对手术AI任务的价值。


<details>
  <summary>Details</summary>
Motivation: 现有白内障手术数据集缺乏多样性和注释深度，限制了深度学习模型的泛化能力。

Method: 收集了来自两个手术中心的3,000个超声乳化白内障手术视频，并添加了四种注释层：手术阶段、工具和结构的实例分割、工具-组织交互跟踪以及基于ICO-OSCAR的技能评分。

Result: 数据集支持关键手术AI任务的基准测试，包括工作流识别、场景分割和自动技能评估，并建立了阶段识别任务的领域适应基线。

Conclusion: 该数据集为白内障手术AI任务提供了多样化的注释资源，并通过基准测试验证了其技术质量，为未来计算机辅助手术系统的开发奠定了基础。

Abstract: The development of computer-assisted surgery systems depends on large-scale,
annotated datasets. Current resources for cataract surgery often lack the
diversity and annotation depth needed to train generalizable deep-learning
models. To address this gap, we present a dataset of 3,000 phacoemulsification
cataract surgery videos from two surgical centers, performed by surgeons with a
range of experience levels. This resource is enriched with four annotation
layers: temporal surgical phases, instance segmentation of instruments and
anatomical structures, instrument-tissue interaction tracking, and quantitative
skill scores based on the established competency rubrics like the ICO-OSCAR.
The technical quality of the dataset is supported by a series of benchmarking
experiments for key surgical AI tasks, including workflow recognition, scene
segmentation, and automated skill assessment. Furthermore, we establish a
domain adaptation baseline for the phase recognition task by training a model
on a subset of surgical centers and evaluating its performance on a held-out
center. The dataset and annotations are available in Google Form
(https://docs.google.com/forms/d/e/1FAIpQLSfmyMAPSTGrIy2sTnz0-TMw08ZagTimRulbAQcWdaPwDy187A/viewform?usp=dialog).

</details>


### [35] [iWatchRoadv2: Pothole Detection, Geospatial Mapping, and Intelligent Road Governance](https://arxiv.org/abs/2510.16375)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

TL;DR: iWatchRoadv2是一个自动化平台，用于实时检测道路坑洞、地理标记和道路健康可视化，支持智能治理和数据驱动的道路维护。


<details>
  <summary>Details</summary>
Motivation: 印度多样化且维护不足的道路网络中，道路坑洞带来了显著的安全隐患和维护挑战，亟需自动化解决方案。

Method: 该研究利用自标注的7,000多帧印度道路多样化条件的仪表盘摄像头数据集，微调Ultralytics YOLO模型进行坑洞检测，并结合OCR提取的视频时间戳与外部GPS日志同步，实现精确的地理定位。系统还包括优化的后端数据库管理道路段属性和承包商信息，以及智能治理功能。

Result: iWatchRoadv2平台实现了实时坑洞检测、GPS地理标记和动态道路健康可视化，支持自动化问责和保修执行，并通过直观的Web界面为利益相关者和公众提供可操作的 analytics。

Conclusion: iWatchRoadv2通过自动化整个坑洞监测生命周期，实现了数据驱动的智慧城市管理、透明治理和道路基础设施维护的可持续改进。

Abstract: Road potholes pose significant safety hazards and maintenance challenges,
particularly on India's diverse and under-maintained road networks. This paper
presents iWatchRoadv2, a fully automated end-to-end platform for real-time
pothole detection, GPS-based geotagging, and dynamic road health visualization
using OpenStreetMap (OSM). We curated a self-annotated dataset of over 7,000
dashcam frames capturing diverse Indian road conditions, weather patterns, and
lighting scenarios, which we used to fine-tune the Ultralytics YOLO model for
accurate pothole detection. The system synchronizes OCR-extracted video
timestamps with external GPS logs to precisely geolocate each detected pothole,
enriching detections with comprehensive metadata, including road segment
attribution and contractor information managed through an optimized backend
database. iWatchRoadv2 introduces intelligent governance features that enable
authorities to link road segments with contract metadata through a secure login
interface. The system automatically sends alerts to contractors and officials
when road health deteriorates, supporting automated accountability and warranty
enforcement. The intuitive web interface delivers actionable analytics to
stakeholders and the public, facilitating evidence-driven repair planning,
budget allocation, and quality assessment. Our cost-effective and scalable
solution streamlines frame processing and storage while supporting seamless
public engagement for urban and rural deployments. By automating the complete
pothole monitoring lifecycle, from detection to repair verification,
iWatchRoadv2 enables data-driven smart city management, transparent governance,
and sustainable improvements in road infrastructure maintenance. The platform
and live demonstration are accessible at
https://smlab.niser.ac.in/project/iwatchroad.

</details>


### [36] [Demeter: A Parametric Model of Crop Plant Morphology from the Real World](https://arxiv.org/abs/2510.16377)
*Tianhang Cheng,Albert J. Zhai,Evan Z. Chen,Rui Zhou,Yawen Deng,Zitong Li,Kejie Zhao,Janice Shiu,Qianyu Zhao,Yide Xu,Xinlei Wang,Yuan Shen,Sheng Wang,Lisa Ainsworth,Kaiyu Guan,Shenlong Wang*

Main category: cs.CV

TL;DR: Demeter是一种数据驱动的植物形态参数模型，能处理多种形状变化，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 虽然人类和动物的3D参数形状模型已经非常强大，但植物建模方面缺乏同样表达力的方法。本研究旨在填补这一空白。

Method: Demeter通过编码植物的拓扑、形状、关节和变形等关键因素到一个紧凑的学习表示中，处理不同物种的形状拓扑变化，并建模三种形状变化源：关节、子组件形状变化和非刚性变形。

Result: 实验表明，Demeter在形状合成、结构重建和生物物理过程模拟方面表现优异。

Conclusion: Demeter提供了一个强大的数据驱动参数模型，能够有效合成植物形态、重建结构并模拟生物物理过程。

Abstract: Learning 3D parametric shape models of objects has gained popularity in
vision and graphics and has showed broad utility in 3D reconstruction,
generation, understanding, and simulation. While powerful models exist for
humans and animals, equally expressive approaches for modeling plants are
lacking. In this work, we present Demeter, a data-driven parametric model that
encodes key factors of a plant morphology, including topology, shape,
articulation, and deformation into a compact learned representation. Unlike
previous parametric models, Demeter handles varying shape topology across
various species and models three sources of shape variation: articulation,
subcomponent shape variation, and non-rigid deformation. To advance crop plant
modeling, we collected a large-scale, ground-truthed dataset from a soybean
farm as a testbed. Experiments show that Demeter effectively synthesizes
shapes, reconstructs structures, and simulates biophysical processes. Code and
data is available at https://tianhang-cheng.github.io/Demeter/.

</details>


### [37] [SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation](https://arxiv.org/abs/2510.16396)
*Yeh Keng Hao,Hsu Tzu Wei,Sun Min*

Main category: cs.CV

TL;DR: 提出轻量级框架，通过稀疏卷积和SPLite解码器提升AR/VR边缘设备的效率，速度提升2.98倍，精度不变。


<details>
  <summary>Details</summary>
Motivation: 随着AR/VR设备的普及，边缘设备需要实时推理、低功耗和低延迟，但现有框架难以平衡效率与性能。

Method: 采用编码器-解码器架构，结合稀疏卷积和SPLite解码器，并应用量化感知训练。

Result: 在Raspberry Pi 5上实现端到端效率提升42%，解码帧率提升3.1倍，整体速度提升2.98倍，精度与先进方法相当。

Conclusion: 本文提出的轻量级框架在保持精度的同时显著提升了计算效率，适用于AR/VR边缘设备的实时推理。

Abstract: With the increasing ubiquity of AR/VR devices, the deployment of deep
learning models on edge devices has become a critical challenge. These devices
require real-time inference, low power consumption, and minimal latency. Many
framework designers face the conundrum of balancing efficiency and performance.
We design a light framework that adopts an encoder-decoder architecture and
introduces several key contributions aimed at improving both efficiency and
accuracy. We apply sparse convolution on a ResNet-18 backbone to exploit the
inherent sparsity in hand pose images, achieving a 42% end-to-end efficiency
improvement. Moreover, we propose our SPLite decoder. This new architecture
significantly boosts the decoding process's frame rate by 3.1x on the Raspberry
Pi 5, while maintaining accuracy on par. To further optimize performance, we
apply quantization-aware training, reducing memory usage while preserving
accuracy (PA-MPJPE increases only marginally from 9.0 mm to 9.1 mm on
FreiHAND). Overall, our system achieves a 2.98x speed-up on a Raspberry Pi 5
CPU (BCM2712 quad-core Arm A76 processor). Our method is also evaluated on
compound benchmark datasets, demonstrating comparable accuracy to
state-of-the-art approaches while significantly enhancing computational
efficiency.

</details>


### [38] [REALM: An MLLM-Agent Framework for Open World 3D Reasoning Segmentation and Editing on Gaussian Splatting](https://arxiv.org/abs/2510.16410)
*Changyue Shi,Minghao Chen,Yiping Mao,Chuxiao Yang,Xinyuan Hu,Jiajun Ding,Zhou Yu*

Main category: cs.CV

TL;DR: REALM是一种创新的MLLM框架，通过全局到局部策略实现3D对象的高精度分割，支持复杂指令和多种交互任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D分割方法难以处理模糊、基于推理的指令，以及2D视觉语言模型缺乏3D空间理解的局限性。

Method: REALM采用基于3D高斯泼溅表示的全局到局部空间定位策略，通过多视图并行处理实现粗粒度定位，再通过合成特写视图进行细粒度分割。

Result: 在LERF、3D-OVS和REALM3D基准测试中表现优异，支持对象移除、替换和风格转换等多种任务。

Conclusion: REALM框架在理解和执行复杂的人类指令方面表现出色，支持多种3D交互任务，展示了其实际应用价值和多功能性。

Abstract: Bridging the gap between complex human instructions and precise 3D object
grounding remains a significant challenge in vision and robotics. Existing 3D
segmentation methods often struggle to interpret ambiguous, reasoning-based
instructions, while 2D vision-language models that excel at such reasoning lack
intrinsic 3D spatial understanding. In this paper, we introduce REALM, an
innovative MLLM-agent framework that enables open-world reasoning-based
segmentation without requiring extensive 3D-specific post-training. We perform
segmentation directly on 3D Gaussian Splatting representations, capitalizing on
their ability to render photorealistic novel views that are highly suitable for
MLLM comprehension. As directly feeding one or more rendered views to the MLLM
can lead to high sensitivity to viewpoint selection, we propose a novel
Global-to-Local Spatial Grounding strategy. Specifically, multiple global views
are first fed into the MLLM agent in parallel for coarse-level localization,
aggregating responses to robustly identify the target object. Then, several
close-up novel views of the object are synthesized to perform fine-grained
local segmentation, yielding accurate and consistent 3D masks. Extensive
experiments show that REALM achieves remarkable performance in interpreting
both explicit and implicit instructions across LERF, 3D-OVS, and our newly
introduced REALM3D benchmarks. Furthermore, our agent framework seamlessly
supports a range of 3D interaction tasks, including object removal,
replacement, and style transfer, demonstrating its practical utility and
versatility. Project page: https://ChangyueShi.github.io/REALM.

</details>


### [39] [SSL4RL: Revisiting Self-supervised Learning as Intrinsic Reward for Visual-Language Reasoning](https://arxiv.org/abs/2510.16416)
*Xiaojun Guo,Runyu Zhou,Yifei Wang,Qi Zhang,Chenheng Zhang,Stefanie Jegelka,Xiaohan Wang,Jiajun Chai,Guojun Yin,Wei Lin,Yisen Wang*

Main category: cs.CV

TL;DR: SSL4RL 是一种新框架，利用自监督学习任务作为强化学习的可验证奖励，显著提升了视觉语言模型的性能，并展示了其通用性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在视觉中心任务中过度依赖语言先验或在推理中使用文本捷径，缺乏可扩展且可靠的奖励机制来应用强化学习。

Method: 提出 SSL4RL 框架，将自监督学习（SSL）任务（如图像旋转预测或掩码补丁重建）转化为密集的自动奖励信号，用于强化学习（RL）微调。

Result: 实验表明，SSL4RL 在视觉中心和视觉语言推理基准测试中显著提升了性能，并在图学习中也取得了显著效果。

Conclusion: SSL4RL 提出了一种通用且有效的范式，通过可验证的自监督目标来对齐多模态模型，为未来工作提供了新的设计原则。

Abstract: Vision-language models (VLMs) have shown remarkable abilities by integrating
large language models with visual inputs. However, they often fail to utilize
visual evidence adequately, either depending on linguistic priors in
vision-centric tasks or resorting to textual shortcuts during reasoning.
Although reinforcement learning (RL) can align models with desired behaviors,
its application to VLMs has been hindered by the lack of scalable and reliable
reward mechanisms. To overcome this challenge, we propose SSL4RL, a novel
framework that leverages self-supervised learning (SSL) tasks as a source of
verifiable rewards for RL-based fine-tuning. Our approach reformulates SSL
objectives-such as predicting image rotation or reconstructing masked
patches-into dense, automatic reward signals, eliminating the need for human
preference data or unreliable AI evaluators. Experiments show that SSL4RL
substantially improves performance on both vision-centric and vision-language
reasoning benchmarks. Furthermore, through systematic ablations, we identify
key factors-such as task difficulty, model scale, and semantic alignment with
the target domain-that influence the effectiveness of SSL4RL tasks, offering
new design principles for future work. We also demonstrate the framework's
generality by applying it to graph learning, where it yields significant gains.
SSL4RL establishes a versatile and effective paradigm for aligning multimodal
models using verifiable, self-supervised objectives.

</details>


### [40] [LightGlueStick: a Fast and Robust Glue for Joint Point-Line Matching](https://arxiv.org/abs/2510.16438)
*Aidyn Ubingazhibov,Rémi Pautrat,Iago Suárez,Shaohui Liu,Marc Pollefeys,Viktor Larsson*

Main category: cs.CV

TL;DR: LightGlueStick是一种轻量级点线匹配器，通过ALMP提升效率，成为新的SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 传统点线匹配独立处理且计算复杂，GlueStick虽联合匹配但架构笨重，无法实时或边缘部署。

Method: 提出了轻量级匹配器LightGlueStick，核心是注意力线消息传递（ALMP）组件，显式暴露线条连接性。

Result: LightGlueStick在不同基准测试中达到新的最先进水平。

Conclusion: LightGlueStick通过ALMP组件显著提升了点线匹配的效率，成为新的最先进方法，代码已开源。

Abstract: Lines and points are complementary local features, whose combination has
proven effective for applications such as SLAM and Structure-from-Motion. The
backbone of these pipelines are the local feature matchers, establishing
correspondences across images. Traditionally, point and line matching have been
treated as independent tasks. Recently, GlueStick proposed a GNN-based network
that simultaneously operates on points and lines to establish matches. While
running a single joint matching reduced the overall computational complexity,
the heavy architecture prevented real-time applications or deployment to edge
devices.
  Inspired by recent progress in point matching, we propose LightGlueStick, a
lightweight matcher for points and line segments. The key novel component in
our architecture is the Attentional Line Message Passing (ALMP), which
explicitly exposes the connectivity of the lines to the network, allowing for
efficient communication between nodes. In thorough experiments we show that
LightGlueStick establishes a new state-of-the-art across different benchmarks.
The code is available at https://github.com/aubingazhib/LightGlueStick.

</details>


### [41] [EDVD-LLaMA: Explainable Deepfake Video Detection via Multimodal Large Language Model Reasoning](https://arxiv.org/abs/2510.16442)
*Haoran Sun,Chen Cai,Huiping Zhuang,Kong Aik Lee,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 本文提出可解释深伪造视频检测任务 EDVD，设计多模态大语言模型框架 EDVD-LLaMA，通过 ST-SIT 和 Fg-MCoT 机制实现高精度检测与可追溯推理，并在实验中验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统深伪造视频检测方法缺乏透明性和泛化能力，亟需能够识别伪造内容并提供可验证解释的检测器。

Method: 采用 Spatio-Temporal Subtle Information Tokenization (ST-SIT) 提取和融合全局与局部的跨帧深伪造特征，并构建 Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) 机制，引入面部特征数据作为硬约束以实现像素级时空视频定位。

Result: EDVD-LLaMA 在检测准确性、可解释性及跨伪造方法和跨数据集场景下的鲁棒性方面表现优异。

Conclusion: EDVD-LLaMA 提供了一种更可解释且性能优越的解决方案，能够准确检测并解释深伪造视频内容，其源代码和数据集将公开。

Abstract: The rapid development of deepfake video technology has not only facilitated
artistic creation but also made it easier to spread misinformation. Traditional
deepfake video detection (DVD) methods face issues such as a lack of
transparency in their principles and insufficient generalization capabilities
to cope with evolving forgery techniques. This highlights an urgent need for
detectors that can identify forged content and provide verifiable reasoning
explanations. This paper proposes the explainable deepfake video detection
(EDVD) task and designs the EDVD-LLaMA multimodal, a large language model
(MLLM) reasoning framework, which provides traceable reasoning processes
alongside accurate detection results and trustworthy explanations. Our approach
first incorporates a Spatio-Temporal Subtle Information Tokenization (ST-SIT)
to extract and fuse global and local cross-frame deepfake features, providing
rich spatio-temporal semantic information input for MLLM reasoning. Second, we
construct a Fine-grained Multimodal Chain-of-Thought (Fg-MCoT) mechanism, which
introduces facial feature data as hard constraints during the reasoning process
to achieve pixel-level spatio-temporal video localization, suppress
hallucinated outputs, and enhance the reliability of the chain of thought. In
addition, we build an Explainable Reasoning FF++ benchmark dataset
(ER-FF++set), leveraging structured data to annotate videos and ensure quality
control, thereby supporting dual supervision for reasoning and detection.
Extensive experiments demonstrate that EDVD-LLaMA achieves outstanding
performance and robustness in terms of detection accuracy, explainability, and
its ability to handle cross-forgery methods and cross-dataset scenarios.
Compared to previous DVD methods, it provides a more explainable and superior
solution. The source code and dataset will be publicly available.

</details>


### [42] [RefAtomNet++: Advancing Referring Atomic Video Action Recognition using Semantic Retrieval based Multi-Trajectory Mamba](https://arxiv.org/abs/2510.16444)
*Kunyu Peng,Di Wen,Jia Fu,Jiamin Wu,Kailun Yang,Junwei Zheng,Ruiping Liu,Yufan Chen,Yuqian Fu,Danda Pani Paudel,Luc Van Gool,Rainer Stiefelhagen*

Main category: cs.CV

TL;DR: RAVAR任务通过RefAtomNet++框架提升细粒度动作识别，RefAVA++数据集扩展至290万帧，新方法显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在跨模态信息对齐和目标人物定位上的不足，提升细粒度动作识别的性能。

Method: 提出RefAtomNet++框架，结合多层级语义对齐的跨注意力机制和多轨迹Mamba建模，动态选择视觉空间token进行跨模态信息对齐。

Result: RefAtomNet++在RefAVA++数据集上实现了最先进的性能。

Conclusion: RefAtomNet++通过多层级语义对齐的跨模态注意力机制和多轨迹Mamba建模，显著提升了在RefAVA++数据集上的性能，成为新的最先进方法。

Abstract: Referring Atomic Video Action Recognition (RAVAR) aims to recognize
fine-grained, atomic-level actions of a specific person of interest conditioned
on natural language descriptions. Distinct from conventional action recognition
and detection tasks, RAVAR emphasizes precise language-guided action
understanding, which is particularly critical for interactive human action
analysis in complex multi-person scenarios. In this work, we extend our
previously introduced RefAVA dataset to RefAVA++, which comprises >2.9 million
frames and >75.1k annotated persons in total. We benchmark this dataset using
baselines from multiple related domains, including atomic action localization,
video question answering, and text-video retrieval, as well as our earlier
model, RefAtomNet. Although RefAtomNet surpasses other baselines by
incorporating agent attention to highlight salient features, its ability to
align and retrieve cross-modal information remains limited, leading to
suboptimal performance in localizing the target person and predicting
fine-grained actions. To overcome the aforementioned limitations, we introduce
RefAtomNet++, a novel framework that advances cross-modal token aggregation
through a multi-hierarchical semantic-aligned cross-attention mechanism
combined with multi-trajectory Mamba modeling at the partial-keyword,
scene-attribute, and holistic-sentence levels. In particular, scanning
trajectories are constructed by dynamically selecting the nearest visual
spatial tokens at each timestep for both partial-keyword and scene-attribute
levels. Moreover, we design a multi-hierarchical semantic-aligned
cross-attention strategy, enabling more effective aggregation of spatial and
temporal tokens across different semantic hierarchies. Experiments show that
RefAtomNet++ establishes new state-of-the-art results. The dataset and code are
released at https://github.com/KPeng9510/refAVA2.

</details>


### [43] [Enhancing Rotated Object Detection via Anisotropic Gaussian Bounding Box and Bhattacharyya Distance](https://arxiv.org/abs/2510.16445)
*Chien Thai,Mai Xuan Trang,Huong Ninh,Hoang Hiep Ly,Anh Son Le*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的损失函数，通过高斯表示和Bhattacharyya距离提升旋转物体检测性能，实验显示显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统物体检测框架在旋转物体场景中表现不佳，因为难以捕捉方向变化。

Method: 论文引入了一种改进的损失函数，利用高斯边界框表示和Bhattacharyya距离，并结合各向异性高斯表示来解决方形物体各向同性方差的问题。

Result: 实验表明，该方法在平均精度指标上显著优于现有方法。

Conclusion: 该论文提出的改进损失函数通过高斯边界框表示和Bhattacharyya距离，显著提升了旋转物体检测的准确性和鲁棒性，为需要精确物体定位的应用提供了新的基准。

Abstract: Detecting rotated objects accurately and efficiently is a significant
challenge in computer vision, particularly in applications such as aerial
imagery, remote sensing, and autonomous driving. Although traditional object
detection frameworks are effective for axis-aligned objects, they often
underperform in scenarios involving rotated objects due to their limitations in
capturing orientation variations. This paper introduces an improved loss
function aimed at enhancing detection accuracy and robustness by leveraging the
Gaussian bounding box representation and Bhattacharyya distance. In addition,
we advocate for the use of an anisotropic Gaussian representation to address
the issues associated with isotropic variance in square-like objects. Our
proposed method addresses these challenges by incorporating a
rotation-invariant loss function that effectively captures the geometric
properties of rotated objects. We integrate this proposed loss function into
state-of-the-art deep learning-based rotated object detection detectors, and
extensive experiments demonstrated significant improvements in mean Average
Precision metrics compared to existing methods. The results highlight the
potential of our approach to establish new benchmark in rotated object
detection, with implications for a wide range of applications requiring precise
and reliable object localization irrespective of orientation.

</details>


### [44] [VIPAMIN: Visual Prompt Initialization via Embedding Selection and Subspace Expansion](https://arxiv.org/abs/2510.16446)
*Jaekyun Park,Hye Won Chung*

Main category: cs.CV

TL;DR: VIPAMIN是一种高效的视觉提示初始化策略，通过语义对齐和表示扩展，显著提升自监督模型的适应性，尤其在资源有限场景下表现卓越。


<details>
  <summary>Details</summary>
Motivation: 在大规模基础模型时代，完全微调预训练网络对每个下游任务来说资源消耗巨大。现有的视觉提示调优方法在自监督骨干网络上往往无法有效专业化提示或丰富表示空间，尤其是在挑战性任务和数据稀缺场景中。

Method: VIPAMIN是一种视觉提示初始化策略，通过（1）将提示与嵌入空间中的语义信息区域对齐，（2）在预训练子空间之外注入新的表示方向，来增强自监督模型的适应性。

Result: VIPAMIN在多样化的任务和数据集规模上均能一致提升性能，成为视觉提示调优领域的新标杆。

Conclusion: VIPAMIN通过简单的单次前向传播和轻量级操作，显著提升了视觉提示调优的性能，在各种任务和数据集规模上均表现优异，成为新的最先进方法。

Abstract: In the era of large-scale foundation models, fully fine-tuning pretrained
networks for each downstream task is often prohibitively resource-intensive.
Prompt tuning offers a lightweight alternative by introducing tunable prompts
while keeping the backbone frozen. However, existing visual prompt tuning
methods often fail to specialize the prompts or enrich the representation
space--especially when applied to self-supervised backbones. We show that these
limitations become especially pronounced in challenging tasks and data-scarce
settings, where effective adaptation is most critical. In this work, we
introduce VIPAMIN, a visual prompt initialization strategy that enhances
adaptation of self-supervised models by (1) aligning prompts with semantically
informative regions in the embedding space, and (2) injecting novel
representational directions beyond the pretrained subspace. Despite its
simplicity--requiring only a single forward pass and lightweight
operations--VIPAMIN consistently improves performance across diverse tasks and
dataset sizes, setting a new state of the art in visual prompt tuning. Our code
is available at https://github.com/iamjaekyun/vipamin.

</details>


### [45] [Instance-Aware Pseudo-Labeling and Class-Focused Contrastive Learning for Weakly Supervised Domain Adaptive Segmentation of Electron Microscopy](https://arxiv.org/abs/2510.16450)
*Shan Xiong,Jiabao Chen,Ye Wang,Jialin Peng*

Main category: cs.CV

TL;DR: 提出了一种结合多任务学习和实例感知伪标签选择策略的弱监督域适应方法，显著提升了线粒体分割的性能，缩小了与监督上限的差距。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜（EM）图像中大量线粒体实例的标注成本高，无监督域适应（UDA）方法在实际应用中性能较低。因此，研究弱监督域适应（WDA）以利用目标域上的稀疏点标注，减少标注成本和专家知识需求。

Method: 引入了一个多任务学习框架，结合分割和中心检测任务，采用交叉教学机制和类聚焦跨域对比学习。此外，还提出了实例感知伪标签（IPL）选择策略的自训练分割方法。

Result: 在多个挑战性数据集上的验证和比较表明，该方法优于现有的UDA和WDA方法，显著缩小了与监督上限的性能差距。在UDA设置下，也大幅优于其他UDA技术。

Conclusion: 该方法在弱监督域适应（WDA）和无监督域适应（UDA）设置下均表现出色，显著缩小了与监督上限的性能差距。

Abstract: Annotation-efficient segmentation of the numerous mitochondria instances from
various electron microscopy (EM) images is highly valuable for biological and
neuroscience research. Although unsupervised domain adaptation (UDA) methods
can help mitigate domain shifts and reduce the high costs of annotating each
domain, they typically have relatively low performance in practical
applications. Thus, we investigate weakly supervised domain adaptation (WDA)
that utilizes additional sparse point labels on the target domain, which
require minimal annotation effort and minimal expert knowledge. To take full
use of the incomplete and imprecise point annotations, we introduce a multitask
learning framework that jointly conducts segmentation and center detection with
a novel cross-teaching mechanism and class-focused cross-domain contrastive
learning. While leveraging unlabeled image regions is essential, we introduce
segmentation self-training with a novel instance-aware pseudo-label (IPL)
selection strategy. Unlike existing methods that typically rely on pixel-wise
pseudo-label filtering, the IPL semantically selects reliable and diverse
pseudo-labels with the help of the detection task. Comprehensive validations
and comparisons on challenging datasets demonstrate that our method outperforms
existing UDA and WDA methods, significantly narrowing the performance gap with
the supervised upper bound. Furthermore, under the UDA setting, our method also
achieves substantial improvements over other UDA techniques.

</details>


### [46] [NavQ: Learning a Q-Model for Foresighted Vision-and-Language Navigation](https://arxiv.org/abs/2510.16457)
*Peiran Xu,Xicheng Gong,Yadong MU*

Main category: cs.CV

TL;DR: 本文提出一种基于Q学习和跨模态未来编码器的前瞻性VLN方法，通过结合未来信息提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常基于历史信息做出决策，忽略了动作的未来影响和长期结果。本文旨在开发一个具有前瞻性的智能体。

Method: 利用Q学习训练一个Q模型，通过大规模无标签轨迹数据学习室内场景布局和物体关系的通用知识。该模型生成类似传统Q网络中Q值的Q特征，描述采取特定动作后可能观察到的潜在未来信息。随后，跨模态未来编码器将这些任务无关的Q特征与导航指令结合，生成反映未来前景的动作分数。

Result: 实验结果表明，结合Q特征和导航指令的A*搜索策略能有效探索更可能导向目的地的区域。

Conclusion: 所提出的方法在广泛使用的目标导向VLN数据集上验证了其有效性，表明结合未来信息的A*搜索策略能有效提升导航性能。

Abstract: In this work we concentrate on the task of goal-oriented Vision-and-Language
Navigation (VLN). Existing methods often make decisions based on historical
information, overlooking the future implications and long-term outcomes of the
actions. In contrast, we aim to develop a foresighted agent. Specifically, we
draw upon Q-learning to train a Q-model using large-scale unlabeled trajectory
data, in order to learn the general knowledge regarding the layout and object
relations within indoor scenes. This model can generate a Q-feature, analogous
to the Q-value in traditional Q-network, for each candidate action, which
describes the potential future information that may be observed after taking
the specific action. Subsequently, a cross-modal future encoder integrates the
task-agnostic Q-feature with navigation instructions to produce a set of action
scores reflecting future prospects. These scores, when combined with the
original scores based on history, facilitate an A*-style searching strategy to
effectively explore the regions that are more likely to lead to the
destination. Extensive experiments conducted on widely used goal-oriented VLN
datasets validate the effectiveness of the proposed method.

</details>


### [47] [HGC-Avatar: Hierarchical Gaussian Compression for Streamable Dynamic 3D Avatars](https://arxiv.org/abs/2510.16463)
*Haocheng Tang,Ruoke Yan,Xinhui Yin,Qi Zhang,Xinfeng Zhang,Siwei Ma,Wen Gao,Chuanmin Jia*

Main category: cs.CV

TL;DR: HGC-Avatar通过分层高斯压缩框架，结合StyleUNet和SMPL-X模型，实现了高效传输和高质量渲染的动态3D化身，特别关注面部细节。


<details>
  <summary>Details</summary>
Motivation: 现有基于3DGS的压缩方法缺乏人体先验知识，导致比特率效率和重建质量不佳，限制了其在可流式3D化身系统中的应用。

Method: 将高斯表示分解为结构层和运动层，分别通过StyleUNet生成器和SMPL-X模型处理，并引入面部注意力机制以在低比特率下保持面部细节。

Result: 实验结果表明，HGC-Avatar在视觉质量和压缩效率上均显著优于现有方法。

Conclusion: HGC-Avatar提供了一种可流式传输的动态3D化身解决方案，显著提升了视觉质量和压缩效率。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have enabled fast,
photorealistic rendering of dynamic 3D scenes, showing strong potential in
immersive communication. However, in digital human encoding and transmission,
the compression methods based on general 3DGS representations are limited by
the lack of human priors, resulting in suboptimal bitrate efficiency and
reconstruction quality at the decoder side, which hinders their application in
streamable 3D avatar systems. We propose HGC-Avatar, a novel Hierarchical
Gaussian Compression framework designed for efficient transmission and
high-quality rendering of dynamic avatars. Our method disentangles the Gaussian
representation into a structural layer, which maps poses to Gaussians via a
StyleUNet-based generator, and a motion layer, which leverages the SMPL-X model
to represent temporal pose variations compactly and semantically. This
hierarchical design supports layer-wise compression, progressive decoding, and
controllable rendering from diverse pose inputs such as video sequences or
text. Since people are most concerned with facial realism, we incorporate a
facial attention mechanism during StyleUNet training to preserve identity and
expression details under low-bitrate constraints. Experimental results
demonstrate that HGC-Avatar provides a streamable solution for rapid 3D avatar
rendering, while significantly outperforming prior methods in both visual
quality and compression efficiency.

</details>


### [48] [PRISMM-Bench: A Benchmark of Peer-Review Grounded Multimodal Inconsistencies](https://arxiv.org/abs/2510.16505)
*Lukas Selch,Yufang Hou,M. Jehanzeb Mirza,Sivan Doveh,James Glass,Rogerio Feris,Wei Lin*

Main category: cs.CV

TL;DR: PRISMM-Bench是首个基于真实审稿意见的多模态不一致性基准测试，测试显示当前LMM模型在科学推理任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试忽视了科学论文中跨模态不一致性问题，这些问题通常微妙且领域特定，影响清晰度、可重复性和信任。

Method: 通过多阶段流程（审阅挖掘、LLM辅助过滤和人工验证）从242篇论文中筛选出262个不一致性，并设计三项任务（不一致性识别、修正和配对匹配）评估模型能力。

Result: 21个领先LMM模型的性能显著低下（26.1-54.2%），突显了多模态科学推理的挑战。

Conclusion: PRISMM-Bench是首个基于真实科学论文中审稿人指出的不一致性构建的基准测试，揭示了当前大型多模态模型在跨模态科学推理中的低性能（26.1-54.2%），强调了开发可信科学助手的紧迫性。

Abstract: Large Multimodal Models (LMMs) are increasingly applied to scientific
research, yet it remains unclear whether they can reliably understand and
reason over the multimodal complexity of papers. A central challenge lies in
detecting and resolving inconsistencies across text, figures, tables, and
equations, issues that are often subtle, domain-specific, and ultimately
undermine clarity, reproducibility, and trust. Existing benchmarks overlook
this issue, either isolating single modalities or relying on synthetic errors
that fail to capture real-world complexity. We introduce PRISMM-Bench
(Peer-Review-sourced Inconsistency Set for Multimodal Models), the first
benchmark grounded in real reviewer-flagged inconsistencies in scientific
papers. Through a multi-stage pipeline of review mining, LLM-assisted filtering
and human verification, we curate 262 inconsistencies from 242 papers. Based on
this set, we design three tasks, namely inconsistency identification, remedy
and pair matching, which assess a model's capacity to detect, correct, and
reason over inconsistencies across different modalities. Furthermore, to
address the notorious problem of choice-only shortcuts in multiple-choice
evaluation, where models exploit answer patterns without truly understanding
the question, we further introduce structured JSON-based answer representations
that minimize linguistic biases by reducing reliance on superficial stylistic
cues. We benchmark 21 leading LMMs, including large open-weight models
(GLM-4.5V 106B, InternVL3 78B) and proprietary models (Gemini 2.5 Pro, GPT-5
with high reasoning). Results reveal strikingly low performance (26.1-54.2%),
underscoring the challenge of multimodal scientific reasoning and motivating
progress towards trustworthy scientific assistants.

</details>


### [49] [OOS-DSD: Improving Out-of-stock Detection in Retail Images using Auxiliary Tasks](https://arxiv.org/abs/2510.16508)
*Franko Šikić,Sven Lončarić*

Main category: cs.CV

TL;DR: OOS-DSD是一种基于深度学习的多任务方法，通过辅助学习和深度归一化显著提升缺货检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决零售验证中产品缺货检测的准确性问题，通过多任务学习提升性能。

Method: 扩展YOLOv8架构，增加卷积分支以同时检测OOS、分割产品和估计场景深度，使用伪标签深度数据进行训练。

Result: OOS-DSD在mAP上比现有最佳方法提高了1.8%，辅助学习和深度归一化分别贡献了3.7%和4.2%的性能提升。

Conclusion: OOS-DSD通过辅助学习和深度归一化程序显著提升了OOS检测的性能，超越了现有最佳方法。

Abstract: Out-of-stock (OOS) detection is a very important retail verification process
that aims to infer the unavailability of products in their designated areas on
the shelf. In this paper, we introduce OOS-DSD, a novel deep learning-based
method that advances OOS detection through auxiliary learning. In particular,
we extend a well-established YOLOv8 object detection architecture with
additional convolutional branches to simultaneously detect OOS, segment
products, and estimate scene depth. While OOS detection and product
segmentation branches are trained using ground truth data, the depth estimation
branch is trained using pseudo-labeled annotations produced by the
state-of-the-art (SOTA) depth estimation model Depth Anything V2. Furthermore,
since the aforementioned pseudo-labeled depth estimates display relative depth,
we propose an appropriate depth normalization procedure that stabilizes the
training process. The experimental results show that the proposed method
surpassed the performance of the SOTA OOS detection methods by 1.8% of the mean
average precision (mAP). In addition, ablation studies confirm the
effectiveness of auxiliary learning and the proposed depth normalization
procedure, with the former increasing mAP by 3.7% and the latter by 4.2%.

</details>


### [50] [Image Categorization and Search via a GAT Autoencoder and Representative Models](https://arxiv.org/abs/2510.16514)
*Duygu Sap,Martin Lotz,Connor Mattinson*

Main category: cs.CV

TL;DR: 提出了一种基于GAT自编码器的图像分类与检索方法，通过图结构和代表模型实现高效分类与检索。


<details>
  <summary>Details</summary>
Motivation: 旨在通过代表模型实现图像分类与检索，以捕捉图像间的关键特征与相似性。

Method: 利用图结构表示图像及其相似性关系，通过GAT自编码器构建上下文感知的潜在表示，并生成类别代表模型进行分类与检索。

Result: 实验表明，该方法在图像分类与检索任务中表现优于传统基于特征的技术。

Conclusion: 论文提出了一种基于图注意力网络（GAT）自编码器的图像分类与检索方法，通过实验验证了其有效性。

Abstract: We propose a method for image categorization and retrieval that leverages
graphs and a graph attention network (GAT)-based autoencoder. Our approach is
representative-centric, that is, we execute the categorization and retrieval
process via the representative models we construct for the images and image
categories. We utilize a graph where nodes represent images (or their
representatives) and edges capture similarity relationships. GAT highlights
important features and relationships between images, enabling the autoencoder
to construct context-aware latent representations that capture the key features
of each image relative to its neighbors. We obtain category representatives
from these embeddings and categorize a query image by comparing its
representative to the category representatives. We then retrieve the most
similar image to the query image within its identified category. We demonstrate
the effectiveness of our representative-centric approach through experiments
with both the GAT autoencoders and standard feature-based techniques.

</details>


### [51] [Enhancing Compositional Reasoning in CLIP via Reconstruction and Alignment of Text Descriptions](https://arxiv.org/abs/2510.16540)
*Jihoon Kwon,Kyle Min,Jy-yong Sohn*

Main category: cs.CV

TL;DR: READ方法通过重建和对齐目标增强视觉语言模型的组合推理能力，READ-CLIP在多个基准测试中表现最优。


<details>
  <summary>Details</summary>
Motivation: 当前基于对比目标训练的视觉语言模型在组合推理能力上表现不佳，主要原因是文本编码器倾向于关注单个单词而非其关系。

Method: READ方法通过添加两个辅助目标来增强组合推理能力：（1）令牌级重建目标，使用冻结的预训练解码器重建替代标题；（2）句子级对齐目标，明确对齐嵌入空间中的转述句子。

Result: READ-CLIP在五个组合推理基准测试中表现最佳，且READ方法对现有CLIP变体也有性能提升。

Conclusion: READ-CLIP模型在五个主要的组合推理基准测试中达到了最先进的性能，比传统微调基线提高了4.1%。此外，READ方法也适用于现有的CLIP变体（如NegCLIP和FSC-CLIP），进一步提升了它们的性能。

Abstract: Despite recent advances, vision-language models trained with standard
contrastive objectives still struggle with compositional reasoning -- the
ability to understand structured relationships between visual and linguistic
elements. This shortcoming is largely due to the tendency of the text encoder
to focus on individual words rather than their relations, a limitation
reinforced by contrastive training that primarily aligns words with visual
objects. In this paper, we introduce REconstruction and Alignment of text
Descriptions (READ), a fine-tuning method designed to enhance compositional
reasoning by adding two auxiliary objectives to the contrastive learning: (1) a
token-level reconstruction objective, where a frozen pre-trained decoder
reconstructs alternative captions based on the embedding of the original
caption; and (2) a sentence-level alignment objective, which explicitly aligns
paraphrased sentences in the embedding space. We show that READ-CLIP, a model
derived by applying the READ method to the pre-trained CLIP model, achieves the
state-of-the-art performance across five major compositional reasoning
benchmarks, outperforming the strongest conventional fine-tuning baseline by up
to 4.1%. Furthermore, applying the READ to existing CLIP variants (including
NegCLIP and FSC-CLIP) also improves performance on these benchmarks.
Quantitative and qualitative analyses reveal that our proposed objectives --
reconstruction and alignment -- offer complementary benefits: the former
encourages the encoder to capture relationships between words within a caption,
while the latter ensures consistent representations for paraphrases expressed
with different wording.

</details>


### [52] [Watch Where You Move: Region-aware Dynamic Aggregation and Excitation for Gait Recognition](https://arxiv.org/abs/2510.16541)
*Binyuan Huang,Yongdong Luo,Xianda Guo,Xiawu Zheng,Zheng Zhu,Jiahui Pan,Chengju Zhou*

Main category: cs.CV

TL;DR: GaitRDAE通过动态区域感知和自适应时间尺度分配，提升了步态识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用预定义区域和固定时间尺度，难以适应动态变化的运动区域和特定模式。

Method: 引入了Region-aware Dynamic Aggregation和Excitation模块，动态搜索最优时间感受野并应用相应注意力机制。

Result: 在多个基准数据集上达到了最先进的性能。

Conclusion: GaitRDAE框架通过动态搜索和自适应时间尺度分配，显著提升了步态识别的准确性和鲁棒性，尤其在处理动态变化的运动区域时表现优异。

Abstract: Deep learning-based gait recognition has achieved great success in various
applications. The key to accurate gait recognition lies in considering the
unique and diverse behavior patterns in different motion regions, especially
when covariates affect visual appearance. However, existing methods typically
use predefined regions for temporal modeling, with fixed or equivalent temporal
scales assigned to different types of regions, which makes it difficult to
model motion regions that change dynamically over time and adapt to their
specific patterns. To tackle this problem, we introduce a Region-aware Dynamic
Aggregation and Excitation framework (GaitRDAE) that automatically searches for
motion regions, assigns adaptive temporal scales and applies corresponding
attention. Specifically, the framework includes two core modules: the
Region-aware Dynamic Aggregation (RDA) module, which dynamically searches the
optimal temporal receptive field for each region, and the Region-aware Dynamic
Excitation (RDE) module, which emphasizes the learning of motion regions
containing more stable behavior patterns while suppressing attention to static
regions that are more susceptible to covariates. Experimental results show that
GaitRDAE achieves state-of-the-art performance on several benchmark datasets.

</details>


### [53] [Fit for Purpose? Deepfake Detection in the Real World](https://arxiv.org/abs/2510.16556)
*Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu*

Main category: cs.CV

TL;DR: 研究通过真实政治深度伪造数据库评估现有检测工具，发现其泛化能力不足，呼吁开发更具政治背景的检测框架。


<details>
  <summary>Details</summary>
Motivation: 当前多数深度伪造检测模型基于实验室合成数据训练，难以泛化至真实社交媒体传播的政治深度伪造内容，亟需真实场景下的性能评估。

Method: 基于政治深度伪造事件数据库（Political Deepfakes Incident Database）构建系统化基准，并评估学术界、政府及工业界的最先进深度伪造检测工具。

Result: 学术界和政府开发的检测器表现较差，付费工具性能相对较高但所有检测器均难以有效泛化至真实政治深度伪造内容，且易受简单视频操作影响。

Conclusion: 现有的深度伪造检测工具在真实世界政治深度伪造内容上表现不佳，亟需开发更具政治背景的检测框架以提供更有效的公众保护。

Abstract: The rapid proliferation of AI-generated content, driven by advances in
generative adversarial networks, diffusion models, and multimodal large
language models, has made the creation and dissemination of synthetic media
effortless, heightening the risks of misinformation, particularly political
deepfakes that distort truth and undermine trust in political institutions. In
turn, governments, research institutions, and industry have strongly promoted
deepfake detection initiatives as solutions. Yet, most existing models are
trained and validated on synthetic, laboratory-controlled datasets, limiting
their generalizability to the kinds of real-world political deepfakes
circulating on social platforms that affect the public. In this work, we
introduce the first systematic benchmark based on the Political Deepfakes
Incident Database, a curated collection of real-world political deepfakes
shared on social media since 2018. Our study includes a systematic evaluation
of state-of-the-art deepfake detectors across academia, government, and
industry. We find that the detectors from academia and government perform
relatively poorly. While paid detection tools achieve relatively higher
performance than free-access models, all evaluated detectors struggle to
generalize effectively to authentic political deepfakes, and are vulnerable to
simple manipulations, especially in the video domain. Results urge the need for
politically contextualized deepfake detection frameworks to better safeguard
the public in real-world settings.

</details>


### [54] [SHIELD: Suppressing Hallucinations In LVLM Encoders via Bias and Vulnerability Defense](https://arxiv.org/abs/2510.16596)
*Yiyang Huang,Liang Shi,Yitian Zhang,Yi Xu,Yun Fu*

Main category: cs.CV

TL;DR: SHIELD框架通过三种策略解决LVLM物体幻觉问题，实验证明其有效性和广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在跨模态任务中表现出色，但物体幻觉问题（模型生成看似合理但不准确的物体描述）仍是一大挑战。本文首次将LVLM幻觉追溯到视觉编码器，并识别出三个关键问题：统计偏差、固有偏差和脆弱性。

Method: 提出SHIELD框架，通过三种策略：重新加权视觉标记以减少统计偏差、引入噪声衍生标记以对抗固有偏差、应用对抗性攻击与对比解码以解决脆弱性。

Result: 实验证明SHIELD在多种基准测试和LVLM家族中有效缓解物体幻觉，并在通用LVLM基准测试中表现优异。

Conclusion: SHIELD框架有效缓解了LVLMs中的物体幻觉问题，并在通用LVLM基准测试中表现出色，展示了其广泛适用性。

Abstract: Large Vision-Language Models (LVLMs) excel in diverse cross-modal tasks.
However, object hallucination, where models produce plausible but inaccurate
object descriptions, remains a significant challenge. In contrast to previous
work focusing on LLM components, this paper is the first to trace LVLM
hallucinations to visual encoders and identifies three key issues: statistical
bias, inherent bias, and vulnerability. To address these challenges, we propose
SHIELD, a training-free framework that mitigates hallucinations through three
strategies: re-weighting visual tokens to reduce statistical bias, introducing
noise-derived tokens to counter inherent bias, and applying adversarial attacks
with contrastive decoding to address vulnerability. Experiments demonstrate
that SHIELD effectively mitigates object hallucinations across diverse
benchmarks and LVLM families. Moreover, SHIELD achieves strong performance on
the general LVLM benchmark, highlighting its broad applicability. Code will be
released.

</details>


### [55] [Self-Supervised Learning to Fly using Efficient Semantic Segmentation and Metric Depth Estimation for Low-Cost Autonomous UAVs](https://arxiv.org/abs/2510.16624)
*Sebastian Mocanu,Emil Slusanschi,Marius Leordeanu*

Main category: cs.CV

TL;DR: 该论文提出了一种基于视觉的小型无人机自主飞行系统，结合语义分割和深度估计实现障碍物避障和自主降落，通过轻量级网络和自适应算法提升性能，测试显示高效且可靠。


<details>
  <summary>Details</summary>
Motivation: 针对小型无人机在受控室内环境中无需GPS或昂贵传感器（如LiDAR）的自主飞行需求，开发一种仅依赖视觉的解决方案。

Method: 系统采用知识蒸馏框架，利用基于颜色的SVM教师网络生成训练数据，训练轻量级U-Net学生网络实现实时语义分割，并通过自适应比例因子算法将非度量深度预测转换为精确度量距离。

Result: 在真实环境和数字孪生环境中的测试表明，该系统在保持100%成功率的同时，显著增加了监控距离并减少了任务时间，最终实现了87.5%的自主任务成功率。

Conclusion: 该研究通过结合语义分割和单目深度估计，提出了一种适用于资源受限平台的高效视觉自主飞行系统，成功解决了结构化环境中无人机导航的深度估计和计算效率挑战。

Abstract: This paper presents a vision-only autonomous flight system for small UAVs
operating in controlled indoor environments. The system combines semantic
segmentation with monocular depth estimation to enable obstacle avoidance,
scene exploration, and autonomous safe landing operations without requiring GPS
or expensive sensors such as LiDAR. A key innovation is an adaptive scale
factor algorithm that converts non-metric monocular depth predictions into
accurate metric distance measurements by leveraging semantic ground plane
detection and camera intrinsic parameters, achieving a mean distance error of
14.4 cm. The approach uses a knowledge distillation framework where a
color-based Support Vector Machine (SVM) teacher generates training data for a
lightweight U-Net student network (1.6M parameters) capable of real-time
semantic segmentation. For more complex environments, the SVM teacher can be
replaced with a state-of-the-art segmentation model. Testing was conducted in a
controlled 5x4 meter laboratory environment with eight cardboard obstacles
simulating urban structures. Extensive validation across 30 flight tests in a
real-world environment and 100 flight tests in a digital-twin environment
demonstrates that the combined segmentation and depth approach increases the
distance traveled during surveillance and reduces mission time while
maintaining 100% success rates. The system is further optimized through
end-to-end learning, where a compact student neural network learns complete
flight policies from demonstration data generated by our best-performing
method, achieving an 87.5% autonomous mission success rate. This work advances
practical vision-based drone navigation in structured environments,
demonstrating solutions for metric depth estimation and computational
efficiency challenges that enable deployment on resource-constrained platforms.

</details>


### [56] [VisionSelector: End-to-End Learnable Visual Token Compression for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.16598)
*Jiaying Zhu,Yurui Zhu,Xin Lu,Wenrui Yan,Dong Li,Kunlin Liu,Xueyang Fu,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: VisionSelector是一种轻量级令牌压缩框架，通过可学习机制和自适应策略，显著提升多模态大语言模型在高压缩率下的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型因高分辨率图像或多图像输入产生的大量视觉令牌导致的计算和内存瓶颈问题，同时避免传统压缩技术因启发式规则可能丢弃关键信息或存在偏见的局限。

Method: 提出VisionSelector，一个与MLLM主干解耦的评分模块，结合可微分Top-K机制和课程退火策略，实现端到端可学习的令牌压缩决策过程。

Result: VisionSelector在多种压缩率下均表现出色，如在30%保留预算下保持MME 100%准确率，10%保留预算下优于先前方法12.14%，并实现预填充速度翻倍。

Conclusion: VisionSelector作为一种轻量级、即插即用的框架，通过可微分Top-K机制和课程退火策略，实现了高效且自适应的视觉令牌选择，显著提升了多模态大语言模型在多种压缩率下的性能表现。

Abstract: Multimodal Large Language Models (MLLMs) encounter significant computational
and memory bottlenecks from the massive number of visual tokens generated by
high-resolution images or multi-image inputs. Previous token compression
techniques are often constrained by heuristic rules that risk discarding
critical information. They may suffer from biases, such as attention sinks,
that lead to sharp performance drops under aggressive compression ratios. To
address these limitations, we reformulate token compression as a lightweight
plug-and-play framework that reformulates token compression into an end-to-end
learnable decision process. To be specific, we propose VisionSelector, a scorer
module decoupled from the MLLM backbone that incorporates a differentiable
Top-K mechanism and a curriculum annealing strategy to bridge the
training-inference gap, enabling efficient and adaptive token selection various
arbitrary compression rates. Remarkably lightweight with only 12.85M trainable
parameters, VisionSelector demonstrates generalization across various
compression rates and adaptively identifying critical tokens. This leads to
superior performance across all compression budgets, evidenced by preserving
100% accuracy on MME with 30% retention budget, outperforming prior methods by
12.14% at 10% retention budget, and doubling prefill speed. Our code is
available at https://github.com/JulietChoo/VisionSelector .

</details>


### [57] [Structured Interfaces for Automated Reasoning with 3D Scene Graphs](https://arxiv.org/abs/2510.16643)
*Aaron Ray,Jacob Arkin,Harel Biggie,Chuchu Fan,Luca Carlone,Nicholas Roy*

Main category: cs.CV

TL;DR: 提出了一种通过Cypher查询语言接口连接LLM与3D场景图的方法，显著提升了语言接地任务的可扩展性和性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在大型或丰富的3D场景图中无法扩展的问题，需要一种更高效的方法来连接自然语言与机器人的世界表示。

Method: 提出了一种基于检索增强生成（Retrieval Augmented Generation）的方法，通过图数据库编码3D场景图，并利用查询语言接口（Cypher）作为LLM的工具，以检索与任务相关的数据。

Result: 在指令跟随和场景问答任务中，与基线上下文窗口和代码生成方法相比，使用Cypher接口的方法显著提升了性能，并减少了令牌计数。

Conclusion: 使用Cypher作为3D场景图的接口，在大型、丰富的图上显著提升了可扩展性，同时大幅减少了场景图内容的令牌计数，从而在语言接地任务中实现了大幅性能提升。

Abstract: In order to provide a robot with the ability to understand and react to a
user's natural language inputs, the natural language must be connected to the
robot's underlying representations of the world. Recently, large language
models (LLMs) and 3D scene graphs (3DSGs) have become a popular choice for
grounding natural language and representing the world. In this work, we address
the challenge of using LLMs with 3DSGs to ground natural language. Existing
methods encode the scene graph as serialized text within the LLM's context
window, but this encoding does not scale to large or rich 3DSGs. Instead, we
propose to use a form of Retrieval Augmented Generation to select a subset of
the 3DSG relevant to the task. We encode a 3DSG in a graph database and provide
a query language interface (Cypher) as a tool to the LLM with which it can
retrieve relevant data for language grounding. We evaluate our approach on
instruction following and scene question-answering tasks and compare against
baseline context window and code generation methods. Our results show that
using Cypher as an interface to 3D scene graphs scales significantly better to
large, rich graphs on both local and cloud-based models. This leads to large
performance improvements in grounded language tasks while also substantially
reducing the token count of the scene graph content. A video supplement is
available at https://www.youtube.com/watch?v=zY_YI9giZSA.

</details>


### [58] [A Deep Learning Framework for Real-Time Image Processing in Medical Diagnostics: Enhancing Accuracy and Speed in Clinical Applications](https://arxiv.org/abs/2510.16611)
*Melika Filvantorkaman,Maral Filvan Torkaman*

Main category: cs.CV

TL;DR: 本文提出了一种实时医学图像分析的深度学习框架，结合多种神经网络架构和优化策略，显著提升了诊断效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统图像处理技术缺乏实时临床使用所需的精度、鲁棒性和速度，因此需要一种更高效的医学图像分析方法。

Method: 提出了一种深度学习框架，集成了U-Net、EfficientNet和基于Transformer的模型，结合实时优化策略（如模型剪枝、量化和GPU加速），支持边缘设备、本地服务器和云基础设施的灵活部署。

Result: 在公共基准数据集上的实验评估显示，分类准确率超过92%，分割Dice分数超过91%，推理时间低于80毫秒，且可视化解释工具增强了透明度和临床可解释性。

Conclusion: 该框架能显著加速诊断流程，减少临床医生工作量，并支持在时间紧迫的医疗环境中可信赖的AI集成。

Abstract: Medical imaging plays a vital role in modern diagnostics; however,
interpreting high-resolution radiological data remains time-consuming and
susceptible to variability among clinicians. Traditional image processing
techniques often lack the precision, robustness, and speed required for
real-time clinical use. To overcome these limitations, this paper introduces a
deep learning framework for real-time medical image analysis designed to
enhance diagnostic accuracy and computational efficiency across multiple
imaging modalities, including X-ray, CT, and MRI. The proposed system
integrates advanced neural network architectures such as U-Net, EfficientNet,
and Transformer-based models with real-time optimization strategies including
model pruning, quantization, and GPU acceleration. The framework enables
flexible deployment on edge devices, local servers, and cloud infrastructures,
ensuring seamless interoperability with clinical systems such as PACS and EHR.
Experimental evaluations on public benchmark datasets demonstrate
state-of-the-art performance, achieving classification accuracies above 92%,
segmentation Dice scores exceeding 91%, and inference times below 80
milliseconds. Furthermore, visual explanation tools such as Grad-CAM and
segmentation overlays enhance transparency and clinical interpretability. These
results indicate that the proposed framework can substantially accelerate
diagnostic workflows, reduce clinician workload, and support trustworthy AI
integration in time-critical healthcare environments.

</details>


### [59] [An RGB-D Image Dataset for Lychee Detection and Maturity Classification for Robotic Harvesting](https://arxiv.org/abs/2510.16800)
*Zhenpeng Zhang,Yi Wang,Shanglei Chai,Yingying Liu,Zekai Xie,Wenhao Huang,Pengyu Li,Zipei Luo,Dajiang Lu,Yibin Tian*

Main category: cs.CV

TL;DR: 构建了一个公开的荔枝数据集，支持检测和成熟度分类，并通过深度学习验证。


<details>
  <summary>Details</summary>
Motivation: 解决当前缺乏高质量、全面标注的荔枝数据集的问题，以促进基于视觉的采摘机器人开发。

Method: 构建了一个包含不同品种、成熟度和环境条件的荔枝数据集，并进行了详细的统计分析和深度学习模型实验。

Result: 数据集包含11,414张图像，标注了9,658对标签，通过三种深度学习模型验证了其有效性。

Conclusion: 该论文构建了一个公开可用的荔枝数据集，支持荔枝检测和成熟度分类，并通过深度学习模型验证了其有效性。

Abstract: Lychee is a high-value subtropical fruit. The adoption of vision-based
harvesting robots can significantly improve productivity while reduce reliance
on labor. High-quality data are essential for developing such harvesting
robots. However, there are currently no consistently and comprehensively
annotated open-source lychee datasets featuring fruits in natural growing
environments. To address this, we constructed a dataset to facilitate lychee
detection and maturity classification. Color (RGB) images were acquired under
diverse weather conditions, and at different times of the day, across multiple
lychee varieties, such as Nuomici, Feizixiao, Heiye, and Huaizhi. The dataset
encompasses three different ripeness stages and contains 11,414 images,
consisting of 878 raw RGB images, 8,780 augmented RGB images, and 1,756 depth
images. The images are annotated with 9,658 pairs of lables for lychee
detection and maturity classification. To improve annotation consistency, three
individuals independently labeled the data, and their results were then
aggregated and verified by a fourth reviewer. Detailed statistical analyses
were done to examine the dataset. Finally, we performed experiments using three
representative deep learning models to evaluate the dataset. It is publicly
available for academic

</details>


### [60] [MultiVerse: A Multi-Turn Conversation Benchmark for Evaluating Large Vision and Language Models](https://arxiv.org/abs/2510.16641)
*Young-Jun Lee,Byung-Kwan Lee,Jianshu Zhang,Yechan Hwang,Byungsoo Ko,Han-Gyu Kim,Dongyu Yao,Xuankun Rong,Eojin Joo,Seung-Ho Han,Bowon Ko,Ho-Jin Choi*

Main category: cs.CV

TL;DR: MultiVerse 是一个新的多轮对话基准测试，覆盖广泛主题，通过 GPT-4o 评估 VLM 模型，发现其在复杂对话中表现有限，上下文学习至关重要。


<details>
  <summary>Details</summary>
Motivation: 现有的多轮对话数据集仅部分覆盖了用户实际遇到的对话场景，因此需要更全面和多样化的基准测试来评估 VLMs 的多轮对话能力。

Method: 提出了基于清单的评估方法，利用 GPT-4o 作为自动评估器，测量了 37 个关键方面的性能。

Result: 评估了 18 个 VLMs，发现即使是 GPT-4o 这样的最强模型在复杂多轮对话中也仅达到 50% 的成功率，同时发现提供完整对话上下文对性能有显著提升。

Conclusion: MultiVerse 是一个具有挑战性的多轮对话基准测试，揭示了当前最强大的 VLM 模型在复杂多轮对话中的局限性，并强调了上下文学习的重要性。

Abstract: Vision-and-Language Models (VLMs) have shown impressive capabilities on
single-turn benchmarks, yet real-world applications often demand more intricate
multi-turn dialogues. Existing multi-turn datasets (e.g, MMDU, ConvBench) only
partially capture the breadth and depth of conversational scenarios encountered
by users. In this work, we introduce MultiVerse, a novel multi-turn
conversation benchmark featuring 647 dialogues - each averaging four turns -
derived from a diverse set of 12 popular VLM evaluation benchmarks. With 484
tasks and 484 interaction goals, MultiVerse covers a wide range of topics, from
factual knowledge and perception to advanced reasoning tasks such as
mathematics and coding. To facilitate robust assessment, we propose a
checklist-based evaluation method that leverages GPT-4o as the automated
evaluator, measuring performance across 37 key aspects, including perceptual
accuracy, linguistic clarity, and factual correctness. We evaluate 18 VLMs on
MultiVerse, revealing that even the strongest models (e.g., GPT-4o) achieve
only a 50% success rate in complex multi-turn conversations, highlighting the
dataset's challenging nature. Notably, we find that providing full dialogue
context significantly enhances performance for smaller or weaker models,
emphasizing the importance of in-context learning. We believe MultiVerse is a
landscape of evaluating multi-turn interaction abilities for VLMs.

</details>


### [61] [M2H: Multi-Task Learning with Efficient Window-Based Cross-Task Attention for Monocular Spatial Perception](https://arxiv.org/abs/2510.17363)
*U. V. B. L Udugama,George Vosselman,Francesco Nex*

Main category: cs.CV

TL;DR: M2H是一种高效的多任务学习框架，通过跨任务注意力模块提升语义分割和深度等任务的性能，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备上实时空间感知任务中多任务模型的计算效率与性能平衡问题。

Method: M2H采用基于窗口的跨任务注意力模块（Window-Based Cross-Task Attention Module），结合轻量级ViT-based DINOv2骨干网络，实现多任务特征交换与任务特定细节保留。

Result: M2H在NYUDv2、Hypersim和Cityscapes数据集上超越现有单任务和多任务模型，并在实际数据中验证了实用性。

Conclusion: M2H框架在保持计算效率的同时，显著提升了多任务学习的性能，并在实际应用中验证了其有效性。

Abstract: Deploying real-time spatial perception on edge devices requires efficient
multi-task models that leverage complementary task information while minimizing
computational overhead. This paper introduces Multi-Mono-Hydra (M2H), a novel
multi-task learning framework designed for semantic segmentation and depth,
edge, and surface normal estimation from a single monocular image. Unlike
conventional approaches that rely on independent single-task models or shared
encoder-decoder architectures, M2H introduces a Window-Based Cross-Task
Attention Module that enables structured feature exchange while preserving
task-specific details, improving prediction consistency across tasks. Built on
a lightweight ViT-based DINOv2 backbone, M2H is optimized for real-time
deployment and serves as the foundation for monocular spatial perception
systems supporting 3D scene graph construction in dynamic environments.
Comprehensive evaluations show that M2H outperforms state-of-the-art multi-task
models on NYUDv2, surpasses single-task depth and semantic baselines on
Hypersim, and achieves superior performance on the Cityscapes dataset, all
while maintaining computational efficiency on laptop hardware. Beyond
benchmarks, M2H is validated on real-world data, demonstrating its practicality
in spatial perception tasks.

</details>


### [62] [Universal and Transferable Attacks on Pathology Foundation Models](https://arxiv.org/abs/2510.16660)
*Yuntian Wang,Xilin Yang,Che-Yung Shen,Nir Pillar,Aydogan Ozcan*

Main category: cs.CV

TL;DR: UTAP是一种通用且可迁移的对抗性扰动，能显著降低多种病理学基础模型的性能，揭示了模型脆弱性并推动防御机制研究。


<details>
  <summary>Details</summary>
Motivation: 揭示病理学基础模型在对抗性扰动下的脆弱性，为模型鲁棒性评估设立高标准基准，并推动防御机制的进步。

Method: 通过深度学习优化的UTAP，是一种固定且微弱的噪声模式，能够系统地破坏多个病理学基础模型的特征表示能力。

Result: UTAP在多种最先进的病理学基础模型上引起显著的性能下降，且其扰动具有普遍性和可迁移性。

Conclusion: UTAP作为一种通用且可迁移的对抗性扰动，揭示了病理学基础模型的关键脆弱性，强调了模型鲁棒性评估的重要性，并提出了防御机制改进的需求。

Abstract: We introduce Universal and Transferable Adversarial Perturbations (UTAP) for
pathology foundation models that reveal critical vulnerabilities in their
capabilities. Optimized using deep learning, UTAP comprises a fixed and weak
noise pattern that, when added to a pathology image, systematically disrupts
the feature representation capabilities of multiple pathology foundation
models. Therefore, UTAP induces performance drops in downstream tasks that
utilize foundation models, including misclassification across a wide range of
unseen data distributions. In addition to compromising the model performance,
we demonstrate two key features of UTAP: (1) universality: its perturbation can
be applied across diverse field-of-views independent of the dataset that UTAP
was developed on, and (2) transferability: its perturbation can successfully
degrade the performance of various external, black-box pathology foundation
models - never seen before. These two features indicate that UTAP is not a
dedicated attack associated with a specific foundation model or image dataset,
but rather constitutes a broad threat to various emerging pathology foundation
models and their applications. We systematically evaluated UTAP across various
state-of-the-art pathology foundation models on multiple datasets, causing a
significant drop in their performance with visually imperceptible modifications
to the input images using a fixed noise pattern. The development of these
potent attacks establishes a critical, high-standard benchmark for model
robustness evaluation, highlighting a need for advancing defense mechanisms and
potentially providing the necessary assets for adversarial training to ensure
the safe and reliable deployment of AI in pathology.

</details>


### [63] [HYDRA: HYbrid knowledge Distillation and spectral Reconstruction Algorithm for high channel hyperspectral camera applications](https://arxiv.org/abs/2510.16664)
*Christopher Thirgood,Oscar Mendez,Erin Ling,Jon Storey,Simon Hadfield*

Main category: cs.CV

TL;DR: HYDRA通过教师-学生模型和知识蒸馏，实现了高精度、高效的光谱重建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多尺度注意力方法在稀疏光谱上表现良好，但无法适应现代高光谱传感器数百通道的需求，因此需要一种更通用的光谱重建方法。

Method: 采用教师-学生模型架构，教师模型封装潜在的高光谱图像数据，学生模型学习从自然图像到教师模型编码域的映射，并结合新颖的训练方法。

Result: HYDRA在所有指标上均达到SOTA性能，包括准确率提升18%，并在不同通道深度下实现更快的推理速度。

Conclusion: 本文提出了一种名为HYDRA的新方法，通过结合知识蒸馏和光谱重建架构，显著提升了光谱重建的准确性和效率，克服了先前模型的局限性。

Abstract: Hyperspectral images (HSI) promise to support a range of new applications in
computer vision. Recent research has explored the feasibility of generalizable
Spectral Reconstruction (SR), the problem of recovering a HSI from a natural
three-channel color image in unseen scenarios.
  However, previous Multi-Scale Attention (MSA) works have only demonstrated
sufficient generalizable results for very sparse spectra, while modern HSI
sensors contain hundreds of channels.
  This paper introduces a novel approach to spectral reconstruction via our
HYbrid knowledge Distillation and spectral Reconstruction Architecture (HYDRA).
  Using a Teacher model that encapsulates latent hyperspectral image data and a
Student model that learns mappings from natural images to the Teacher's encoded
domain, alongside a novel training method, we achieve high-quality spectral
reconstruction.
  This addresses key limitations of prior SR models, providing SOTA performance
across all metrics, including an 18\% boost in accuracy, and faster inference
times than current SOTA models at various channel depths.

</details>


### [64] [Pursuing Minimal Sufficiency in Spatial Reasoning](https://arxiv.org/abs/2510.16688)
*Yejie Guo,Yunzhong Hou,Wufei Ma,Meng Tang,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: MSSR是一个双代理框架，通过提取最小充分信息集（MSS）优化空间推理，显著提升性能并生成可解释路径。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在空间推理中存在两个瓶颈：2D预训练导致的3D理解能力不足，以及冗余3D信息引发的推理失败。

Method: MSSR采用双代理框架，包括一个感知代理和一个推理代理。感知代理通过程序化查询3D场景提取足够信息（包括新颖的SOG模块），推理代理迭代优化信息以实现最小性。

Result: 实验表明，MSSR方法在准确性和性能上显著提升，并在两个基准测试中达到最优。

Conclusion: MSSR框架通过显式追求信息的充分性和最小性，显著提高了空间推理的准确性，并在两个挑战性基准上实现了最先进的性能。此外，该框架生成了可解释的推理路径，为未来模型提供了高质量的训练数据源。

Abstract: Spatial reasoning, the ability to ground language in 3D understanding,
remains a persistent challenge for Vision-Language Models (VLMs). We identify
two fundamental bottlenecks: inadequate 3D understanding capabilities stemming
from 2D-centric pre-training, and reasoning failures induced by redundant 3D
information. To address these, we first construct a Minimal Sufficient Set
(MSS) of information before answering a given question: a compact selection of
3D perception results from \textit{expert models}. We introduce MSSR (Minimal
Sufficient Spatial Reasoner), a dual-agent framework that implements this
principle. A Perception Agent programmatically queries 3D scenes using a
versatile perception toolbox to extract sufficient information, including a
novel SOG (Situated Orientation Grounding) module that robustly extracts
language-grounded directions. A Reasoning Agent then iteratively refines this
information to pursue minimality, pruning redundant details and requesting
missing ones in a closed loop until the MSS is curated. Extensive experiments
demonstrate that our method, by explicitly pursuing both sufficiency and
minimality, significantly improves accuracy and achieves state-of-the-art
performance across two challenging benchmarks. Furthermore, our framework
produces interpretable reasoning paths, offering a promising source of
high-quality training data for future models. Source code is available at
https://github.com/gyj155/mssr.

</details>


### [65] [SDPA++: A General Framework for Self-Supervised Denoising with Patch Aggregation](https://arxiv.org/abs/2510.16702)
*Huy Minh Nhat Nguyen,Triet Hoang Minh Dao,Chau Vinh Hoang Truong,Cuong Tuan Nguyen*

Main category: cs.CV

TL;DR: SDPA++是一种自监督去噪框架，无需干净图像即可提升OCT图像质量，适用于临床实践。


<details>
  <summary>Details</summary>
Motivation: OCT图像分析对早期诊断至关重要，但获取干净的配对数据集困难，现有方法难以应对真实噪声。

Method: 提出SDPA++框架，利用自融合和自监督去噪生成伪地面真实图像，并通过基于补丁的策略训练去噪模型。

Result: 在VIP Cup数据集上验证，性能指标（CNR、MSR、TP、EP）显著提升。

Conclusion: SDPA++框架通过自监督去噪和补丁聚合策略，有效提升了OCT图像质量，为临床诊断提供了更清晰的图像支持。

Abstract: Optical Coherence Tomography (OCT) is a widely used non-invasive imaging
technique that provides detailed three-dimensional views of the retina, which
are essential for the early and accurate diagnosis of ocular diseases.
Consequently, OCT image analysis and processing have emerged as key research
areas in biomedical imaging. However, acquiring paired datasets of clean and
real-world noisy OCT images for supervised denoising models remains a
formidable challenge due to intrinsic speckle noise and practical constraints
in clinical imaging environments. To address these issues, we propose SDPA++: A
General Framework for Self-Supervised Denoising with Patch Aggregation. Our
novel approach leverages only noisy OCT images by first generating
pseudo-ground-truth images through self-fusion and self-supervised denoising.
These refined images then serve as targets to train an ensemble of denoising
models using a patch-based strategy that effectively enhances image clarity.
Performance improvements are validated via metrics such as Contrast-to-Noise
Ratio (CNR), Mean Square Ratio (MSR), Texture Preservation (TP), and Edge
Preservation (EP) on the real-world dataset from the IEEE SPS Video and Image
Processing Cup. Notably, the VIP Cup dataset contains only real-world noisy OCT
images without clean references, highlighting our method's potential for
improving image quality and diagnostic outcomes in clinical practice.

</details>


### [66] [Connecting Domains and Contrasting Samples: A Ladder for Domain Generalization](https://arxiv.org/abs/2510.16704)
*Tianxin Wei,Yifan Chen,Xinrui He,Wenxuan Bao,Jingrui He*

Main category: cs.CV

TL;DR: DCCL通过增强跨领域类内连接性，显著提升了领域泛化性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 领域泛化（DG）中对比学习（CL）直接应用效果不佳，缺乏类内连接性是主要原因，因此需要一种新方法来增强跨领域的概念连接性。

Method: 提出了领域连接对比学习（DCCL），包括数据侧（更激进的数据增强和跨领域正样本）和模型侧（模型锚定和生成变换损失）的改进。

Result: 在五个标准DG基准测试中，DCCL优于现有基线，验证了其有效性。

Conclusion: DCCL通过增强跨领域的概念连接性，显著提升了领域泛化性能，且在无领域监督的情况下优于现有基线。

Abstract: Distribution shifts between training and testing samples frequently occur in
practice and impede model generalization performance. This crucial challenge
thereby motivates studies on domain generalization (DG), which aim to predict
the label on unseen target domain data by solely using data from source
domains. It is intuitive to conceive the class-separated representations
learned in contrastive learning (CL) are able to improve DG, while the reality
is quite the opposite: users observe directly applying CL deteriorates the
performance. We analyze the phenomenon with the insights from CL theory and
discover lack of intra-class connectivity in the DG setting causes the
deficiency. We thus propose a new paradigm, domain-connecting contrastive
learning (DCCL), to enhance the conceptual connectivity across domains and
obtain generalizable representations for DG. On the data side, more aggressive
data augmentation and cross-domain positive samples are introduced to improve
intra-class connectivity. On the model side, to better embed the unseen test
domains, we propose model anchoring to exploit the intra-class connectivity in
pre-trained representations and complement the anchoring with generative
transformation loss. Extensive experiments on five standard DG benchmarks are
performed. The results verify that DCCL outperforms state-of-the-art baselines
even without domain supervision. The detailed model implementation and the code
are provided through https://github.com/weitianxin/DCCL

</details>


### [67] [HumanCM: One Step Human Motion Prediction](https://arxiv.org/abs/2510.16709)
*Liu Haojie,Gao Suixiang*

Main category: cs.CV

TL;DR: HumanCM是一种基于一致性模型的高效单步人类运动预测框架，性能优于扩散模型且推理步骤大幅减少。


<details>
  <summary>Details</summary>
Motivation: 解决基于扩散方法的多步去噪效率低下的问题，提供更高效的人类运动预测框架。

Method: 采用基于Transformer的时空架构，结合时间嵌入来建模长距离依赖关系并保持运动连贯性。

Result: 在Human3.6M和HumanEva-I上的实验表明，HumanCM在减少推理步骤的同时，达到了与最先进扩散模型相当或更优的准确性。

Conclusion: HumanCM通过一致性模型实现了高效的单步生成，在保持运动连贯性的同时，显著减少了推理步骤，性能与最先进的扩散模型相当甚至更优。

Abstract: We present HumanCM, a one-step human motion prediction framework built upon
consistency models. Instead of relying on multi-step denoising as in
diffusion-based methods, HumanCM performs efficient single-step generation by
learning a self-consistent mapping between noisy and clean motion states. The
framework adopts a Transformer-based spatiotemporal architecture with temporal
embeddings to model long-range dependencies and preserve motion coherence.
Experiments on Human3.6M and HumanEva-I demonstrate that HumanCM achieves
comparable or superior accuracy to state-of-the-art diffusion models while
reducing inference steps by up to two orders of magnitude.

</details>


### [68] [Eliciting Grounded Chain-of-Thought Reasoning in 3D Scenes](https://arxiv.org/abs/2510.16714)
*Xiongkun Linghu,Jiangyong Huang,Ziyu Zhu,Baoxiong Jia,Siyuan Huang*

Main category: cs.CV

TL;DR: 该论文提出了SCENECOT框架和数据集，首次将CoT推理应用于3D场景理解，实现了人类式逐步推理，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有3D大语言模型（LLMs）在接地问题回答方面仍存在困难，主要因为对人类式场景-对象接地推理机制的探索不足。

Method: 提出了一种新颖的框架SCENECOT，将复杂推理任务分解为更简单且可管理的问题，并基于多模态专家模块构建相应的视觉线索。同时开发了SCENECOT-185K数据集。

Result: 在多个复杂3D场景推理基准测试中，新框架表现出色，具有较高的接地-QA一致性。

Conclusion: 该论文首次成功将CoT推理应用于3D场景理解，实现了逐步的人类式推理，并展示了扩展到更广泛3D场景理解场景的潜力。

Abstract: Existing research on 3D Large Language Models (LLMs) still struggles to
achieve grounded question-answering, primarily due to the under-exploration of
the mech- anism of human-like scene-object grounded reasoning. This paper
bridges the gap by presenting a novel framework. We first introduce a grounded
Chain-of- Thought reasoning method in 3D scenes (SCENECOT), decoupling a
complex reasoning task into simpler and manageable problems, and building
corresponding visual clues based on multimodal expert modules. To enable such a
method, we develop SCENECOT-185K, the first large-scale grounded CoT reasoning
dataset, consisting of 185K high-quality instances. Extensive experiments
across various complex 3D scene reasoning benchmarks demonstrate that our new
framework achieves strong performance with high grounding-QA coherence. To the
best of our knowledge, this is the first successful application of CoT
reasoning to 3D scene understanding, enabling step-by-step human-like reasoning
and showing potential for extension to broader 3D scene understanding
scenarios.

</details>


### [69] [Vision-Centric 4D Occupancy Forecasting and Planning via Implicit Residual World Models](https://arxiv.org/abs/2510.16729)
*Jianbiao Mei,Yu Yang,Xuemeng Yang,Licheng Wen,Jiajun Lv,Botian Shi,Yong Liu*

Main category: cs.CV

TL;DR: IR-WM通过仅预测场景变化的残差，减少了对静态背景的冗余建模，显著提升了自动驾驶系统的预测和规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶系统在视觉中心世界模型中存在对静态背景冗余建模的问题，IR-WM旨在通过专注于当前状态和世界演变的建模来解决这一问题。

Method: IR-WM首先从视觉观察中建立当前状态的鸟瞰图表示，然后利用前一时刻的BEV特征作为时间先验，仅预测基于自车动作和场景上下文的“残差”变化。此外，还应用了对齐模块来校准语义和动态不对齐。

Result: IR-WM在nuScenes基准测试中取得了4D占用预测和轨迹规划的领先性能。

Conclusion: IR-WM在nuScenes基准测试中，在4D占用预测和轨迹规划方面均表现出色，验证了其有效性。

Abstract: End-to-end autonomous driving systems increasingly rely on vision-centric
world models to understand and predict their environment. However, a common
ineffectiveness in these models is the full reconstruction of future scenes,
which expends significant capacity on redundantly modeling static backgrounds.
To address this, we propose IR-WM, an Implicit Residual World Model that
focuses on modeling the current state and evolution of the world. IR-WM first
establishes a robust bird's-eye-view representation of the current state from
the visual observation. It then leverages the BEV features from the previous
timestep as a strong temporal prior and predicts only the "residual", i.e., the
changes conditioned on the ego-vehicle's actions and scene context. To
alleviate error accumulation over time, we further apply an alignment module to
calibrate semantic and dynamic misalignments. Moreover, we investigate
different forecasting-planning coupling schemes and demonstrate that the
implicit future state generated by world models substantially improves planning
accuracy. On the nuScenes benchmark, IR-WM achieves top performance in both 4D
occupancy forecasting and trajectory planning.

</details>


### [70] [UKANFormer: Noise-Robust Semantic Segmentation for Coral Reef Mapping via a Kolmogorov-Arnold Network-Transformer Hybrid](https://arxiv.org/abs/2510.16730)
*Tianyang Dou,Ming Li,Jiangying Qin,Xuan Liao,Jiageng Zhong,Armin Gruen,Mengyi Deng*

Main category: cs.CV

TL;DR: UKANFormer是一种新型语义分割模型，通过全局-局部变换器块提升珊瑚礁映射精度，即使使用噪声标签训练也能超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁是重要但脆弱的生态系统，需要精确的大规模映射以进行有效保护。现有的全球产品如Allen Coral Atlas在空间精度和语义一致性上存在局限，尤其是在需要精细边界划分的区域。

Method: UKANFormer是一种新颖的语义分割模型，基于UKAN架构，在解码器中加入了全局-局部变换器（GL-Trans）块，以提取全局语义结构和局部边界细节。

Result: UKANFormer在实验中取得了67.00%的珊瑚类IoU和83.98%的像素准确率，优于相同噪声标签设置下的传统基线模型。

Conclusion: UKANFormer挑战了数据质量直接限制模型性能的观点，表明架构设计可以缓解标签噪声，并在不完美的监督下支持可扩展的映射。

Abstract: Coral reefs are vital yet fragile ecosystems that require accurate
large-scale mapping for effective conservation. Although global products such
as the Allen Coral Atlas provide unprecedented coverage of global coral reef
distri-bution, their predictions are frequently limited in spatial precision
and semantic consistency, especially in regions requiring fine-grained boundary
delineation. To address these challenges, we propose UKANFormer, a novel
se-mantic segmentation model designed to achieve high-precision mapping under
noisy supervision derived from Allen Coral Atlas. Building upon the UKAN
architecture, UKANFormer incorporates a Global-Local Transformer (GL-Trans)
block in the decoder, enabling the extraction of both global semantic
structures and local boundary details. In experiments, UKANFormer achieved a
coral-class IoU of 67.00% and pixel accuracy of 83.98%, outperforming
conventional baselines under the same noisy labels setting. Remarkably, the
model produces predictions that are visually and structurally more accurate
than the noisy labels used for training. These results challenge the notion
that data quality directly limits model performance, showing that architectural
design can mitigate label noise and sup-port scalable mapping under imperfect
supervision. UKANFormer provides a foundation for ecological monitoring where
reliable labels are scarce.

</details>


### [71] [A Comprehensive Survey on World Models for Embodied AI](https://arxiv.org/abs/2510.16732)
*Xinqing Li,Xin He,Le Zhang,Yun Liu*

Main category: cs.CV

TL;DR: 本文提出了一个世界模型的统一框架，形式化了问题设置和学习目标，并提出了一个三轴分类法。同时，指出了当前研究的开放挑战。


<details>
  <summary>Details</summary>
Motivation: 为了支持具身AI中的感知、预测和决策，需要能够捕捉环境动态的世界模型。

Method: 作者通过形式化问题设置和学习目标，提出了一个三轴分类法，涵盖功能、时间建模和空间表示。

Result: 本文系统化了数据资源和指标，并进行了定量比较，指出了关键开放挑战。

Conclusion: 本文提出了一个关于世界模型的统一框架，并指出了当前研究的开放挑战，包括数据集缺乏统一性和评估指标的不足。

Abstract: Embodied AI requires agents that perceive, act, and anticipate how actions
reshape future world states. World models serve as internal simulators that
capture environment dynamics, enabling forward and counterfactual rollouts to
support perception, prediction, and decision making. This survey presents a
unified framework for world models in embodied AI. Specifically, we formalize
the problem setting and learning objectives, and propose a three-axis taxonomy
encompassing: (1) Functionality, Decision-Coupled vs. General-Purpose; (2)
Temporal Modeling, Sequential Simulation and Inference vs. Global Difference
Prediction; (3) Spatial Representation, Global Latent Vector, Token Feature
Sequence, Spatial Latent Grid, and Decomposed Rendering Representation. We
systematize data resources and metrics across robotics, autonomous driving, and
general video settings, covering pixel prediction quality, state-level
understanding, and task performance. Furthermore, we offer a quantitative
comparison of state-of-the-art models and distill key open challenges,
including the scarcity of unified datasets and the need for evaluation metrics
that assess physical consistency over pixel fidelity, the trade-off between
model performance and the computational efficiency required for real-time
control, and the core modeling difficulty of achieving long-horizon temporal
consistency while mitigating error accumulation. Finally, we maintain a curated
bibliography at https://github.com/Li-Zn-H/AwesomeWorldModels.

</details>


### [72] [Visual Autoregressive Models Beat Diffusion Models on Inference Time Scaling](https://arxiv.org/abs/2510.16751)
*Erik Riise,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: 离散自回归模型结合束搜索策略在图像生成中表现优异，2B参数模型超越12B扩散模型，证明架构设计对推理优化至关重要。


<details>
  <summary>Details</summary>
Motivation: 尽管搜索策略在大型语言模型中取得了显著成功，但在图像生成领域的应用效果有限。本文旨在探索离散自回归模型是否能够通过搜索策略提升图像生成性能。

Method: 本文采用离散的自回归模型，并应用束搜索策略进行文本到图像生成。通过系统消融实验验证了离散令牌空间的优势，包括早期剪枝和计算重用。

Result: 实验表明，2B参数的离散自回归模型通过束搜索策略，在文本到图像生成任务中优于12B参数的扩散模型。验证器分析揭示了速度与推理能力之间的权衡。

Conclusion: 研究表明，模型架构（不仅是规模）对于视觉生成中的推理时优化至关重要。离散的自回归模型通过有效的搜索策略（如束搜索）在图像生成中展现出显著优势。

Abstract: While inference-time scaling through search has revolutionized Large Language
Models, translating these gains to image generation has proven difficult.
Recent attempts to apply search strategies to continuous diffusion models show
limited benefits, with simple random sampling often performing best. We
demonstrate that the discrete, sequential nature of visual autoregressive
models enables effective search for image generation. We show that beam search
substantially improves text-to-image generation, enabling a 2B parameter
autoregressive model to outperform a 12B parameter diffusion model across
benchmarks. Systematic ablations show that this advantage comes from the
discrete token space, which allows early pruning and computational reuse, and
our verifier analysis highlights trade-offs between speed and reasoning
capability. These findings suggest that model architecture, not just scale, is
critical for inference-time optimization in visual generation.

</details>


### [73] [Prominence-Aware Artifact Detection and Dataset for Image Super-Resolution](https://arxiv.org/abs/2510.16752)
*Ivan Molodetskikh,Kirill Malyshev,Mark Mirgaleev,Nikita Zagainov,Evgeney Bogatyrev,Dmitriy Vatolin*

Main category: cs.CV

TL;DR: 本文提出了一种基于显著性评估SR伪影的方法，通过构建数据集和训练回归器，显著提升了伪影检测效果。


<details>
  <summary>Details</summary>
Motivation: 随着生成图像超分辨率（SR）模型的容量扩大，其产生伪影的趋势也随之增加。这些伪影的感知影响各不相同，因此作者认为应根据其对人眼观察者的显著性来表征伪影，而非将其视为统一的二进制缺陷。

Method: 作者构建了一个包含1302个伪影示例的数据集，每个伪影都与众包显著性评分配对。基于此数据集，他们训练了一个轻量级回归器来生成空间显著性热图。

Result: 训练的回归器在检测显著伪影方面表现优于现有方法，并生成了空间显著性热图。

Conclusion: 作者提出了一个轻量级回归器，用于生成空间显著性热图，并在检测显著伪影方面优于现有方法。同时，他们发布了数据集和代码，以促进基于显著性的SR伪影评估和缓解。

Abstract: Generative image super-resolution (SR) is rapidly advancing in visual quality
and detail restoration. As the capacity of SR models expands, however, so does
their tendency to produce artifacts: incorrect, visually disturbing details
that reduce perceived quality. Crucially, their perceptual impact varies: some
artifacts are barely noticeable while others strongly degrade the image. We
argue that artifacts should be characterized by their prominence to human
observers rather than treated as uniform binary defects. Motivated by this, we
present a novel dataset of 1302 artifact examples from 11 contemporary image-SR
methods, where each artifact is paired with a crowdsourced prominence score.
Building on this dataset, we train a lightweight regressor that produces
spatial prominence heatmaps and outperforms existing methods at detecting
prominent artifacts. We release the dataset and code to facilitate
prominence-aware evaluation and mitigation of SR artifacts.

</details>


### [74] [WaMaIR: Image Restoration via Multiscale Wavelet Convolutions and Mamba-based Channel Modeling with Texture Enhancement](https://arxiv.org/abs/2510.16765)
*Shengyu Zhu,Fan,Fuxuan Zhang*

Main category: cs.CV

TL;DR: WaMaIR通过GMWTConvs、MCAM和MTELoss提升了纹理细节恢复，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有CNN-based方法因感受野小和缺乏通道特征建模，难以充分恢复纹理细节。

Method: 提出了WaMaIR框架，包括Global Multiscale Wavelet Transform Convolutions (GMWTConvs)用于扩大感受野，Mamba-Based Channel-Aware Module (MCAM)用于捕捉特征通道的长程依赖，以及Multiscale Texture Enhancement Loss (MTELoss)用于指导模型保留纹理细节。

Result: 实验表明WaMaIR在图像恢复效果和计算效率上优于现有方法。

Conclusion: WaMaIR框架通过引入GMWTConvs、MCAM和MTELoss，显著提升了图像恢复的纹理细节重建效果，并在计算效率上表现出色。

Abstract: Image restoration is a fundamental and challenging task in computer vision,
where CNN-based frameworks demonstrate significant computational efficiency.
However, previous CNN-based methods often face challenges in adequately
restoring fine texture details, which are limited by the small receptive field
of CNN structures and the lack of channel feature modeling. In this paper, we
propose WaMaIR, which is a novel framework with a large receptive field for
image perception and improves the reconstruction of texture details in restored
images. Specifically, we introduce the Global Multiscale Wavelet Transform
Convolutions (GMWTConvs) for expandding the receptive field to extract image
features, preserving and enriching texture features in model inputs. Meanwhile,
we propose the Mamba-Based Channel-Aware Module (MCAM), explicitly designed to
capture long-range dependencies within feature channels, which enhancing the
model sensitivity to color, edges, and texture information. Additionally, we
propose Multiscale Texture Enhancement Loss (MTELoss) for image restoration to
guide the model in preserving detailed texture structures effectively.
Extensive experiments confirm that WaMaIR outperforms state-of-the-art methods,
achieving better image restoration and efficient computational performance of
the model.

</details>


### [75] [Region in Context: Text-condition Image editing with Human-like semantic reasoning](https://arxiv.org/abs/2510.16772)
*Thuy Phuong Vu,Dinh-Cuong Hoang,Minhhuy Le,Phan Xuan Tan*

Main category: cs.CV

TL;DR: 提出Region in Context框架，通过多级语义对齐实现更精确的图像编辑，解决现有方法孤立处理区域导致的连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理图像区域时孤立依赖局部线索，导致编辑不一致、过渡不自然或整体连贯性丧失。

Method: 引入双级引导机制，结合全图像上下文和详细区域描述，同时利用大型视觉语言模型生成场景级描述，指导局部修改和全局结构。

Result: 实验表明，该方法能产生更连贯且符合指令的编辑结果。

Conclusion: 提出的Region in Context框架通过多级语义对齐，实现了更精确和协调的图像编辑，显著提升了编辑结果的连贯性和指令对齐性。

Abstract: Recent research has made significant progress in localizing and editing image
regions based on text. However, most approaches treat these regions in
isolation, relying solely on local cues without accounting for how each part
contributes to the overall visual and semantic composition. This often results
in inconsistent edits, unnatural transitions, or loss of coherence across the
image. In this work, we propose Region in Context, a novel framework for
text-conditioned image editing that performs multilevel semantic alignment
between vision and language, inspired by the human ability to reason about
edits in relation to the whole scene. Our method encourages each region to
understand its role within the global image context, enabling precise and
harmonized changes. At its core, the framework introduces a dual-level guidance
mechanism: regions are represented with full-image context and aligned with
detailed region-level descriptions, while the entire image is simultaneously
matched to a comprehensive scene-level description generated by a large
vision-language model. These descriptions serve as explicit verbal references
of the intended content, guiding both local modifications and global structure.
Experiments show that it produces more coherent and instruction-aligned
results. Code is available at:
https://github.com/thuyvuphuong/Region-in-Context.git

</details>


### [76] [EMRRG: Efficient Fine-Tuning Pre-trained X-ray Mamba Networks for Radiology Report Generation](https://arxiv.org/abs/2510.16776)
*Mingzheng Zhang,Jinfeng Gao,Dan Xu,Jiangrui Yu,Yuhan Qiao,Lan Chen,Jin Tang,Xiao Wang*

Main category: cs.CV

TL;DR: EMRRG框架利用参数高效方法微调预训练Mamba网络，结合SSM视觉骨干和混合解码器LLM，显著提升X射线报告生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有MRG模型主要依赖LLM，对预训练视觉基础模型和高级微调技术探索有限，且忽视了非Transformer架构（如Mamba网络）的潜力。

Method: EMRRG框架将X射线图像分块并标记化，通过基于SSM的视觉骨干网络提取特征，采用Partial LoRA进行优化，结合混合解码器的LLM生成报告。

Result: 在三个广泛使用的基准数据集上的大量实验验证了所提策略的有效性。

Conclusion: 论文提出的EMRRG框架通过参数高效方法微调预训练的Mamba网络，在X射线报告生成任务中表现出色，实验验证了其有效性。

Abstract: X-ray image-based medical report generation (MRG) is a pivotal area in
artificial intelligence that can significantly reduce diagnostic burdens for
clinicians and patient wait times. Existing MRG models predominantly rely on
Large Language Models (LLMs) to improve report generation, with limited
exploration of pre-trained vision foundation models or advanced fine-tuning
techniques. Mainstream frameworks either avoid fine-tuning or utilize
simplistic methods like LoRA, often neglecting the potential of enhancing
cross-attention mechanisms. Additionally, while Transformer-based models
dominate vision-language tasks, non-Transformer architectures, such as the
Mamba network, remain underexplored for medical report generation, presenting a
promising avenue for future research. In this paper, we propose EMRRG, a novel
X-ray report generation framework that fine-tunes pre-trained Mamba networks
using parameter-efficient methods. Specifically, X-ray images are divided into
patches, tokenized, and processed by an SSM-based vision backbone for feature
extraction, with Partial LoRA yielding optimal performance. An LLM with a
hybrid decoder generates the medical report, enabling end-to-end training and
achieving strong results on benchmark datasets. Extensive experiments on three
widely used benchmark datasets fully validated the effectiveness of our
proposed strategies for the X-ray MRG. The source code of this paper will be
released on https://github.com/Event-AHU/Medical_Image_Analysis.

</details>


### [77] [GS2POSE: Marry Gaussian Splatting to 6D Object Pose Estimation](https://arxiv.org/abs/2510.16777)
*Junbo Li,Weimin Yuan,Yinuo Wang,Yue Zeng,Shihao Shu,Cai Meng,Xiangzhi Bai*

Main category: cs.CV

TL;DR: GS2POSE是一种新型6D物体姿态估计方法，通过Bundle Adjustment和Lie代数优化姿态，适应光照变化，在多个数据集上显著提升精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于2D图像特征与3D模型特征对应关系的6D姿态估计方法在面对纹理less物体和变化的光照条件时存在困难。为了解决这些限制，研究者提出了GS2POSE。

Method: GS2POSE提出了一种基于Bundle Adjustment（BA）原理的姿态回归算法，利用Lie代数扩展3DGS的能力，开发了一个姿态可微渲染管道，通过迭代优化输入图像与渲染图像的比较来优化姿态。此外，GS2POSE还更新了3DGS模型中的颜色参数，增强了其对光照变化的适应性。

Result: GS2POSE在T-LESS、LineMod-Occlusion和LineMod数据集上的精度分别提升了1.4%、2.8%和2.5%。

Conclusion: GS2POSE在T-LESS、LineMod-Occlusion和LineMod数据集上分别实现了1.4%、2.8%和2.5%的精度提升，验证了其在6D物体姿态估计中的有效性。

Abstract: Accurate 6D pose estimation of 3D objects is a fundamental task in computer
vision, and current research typically predicts the 6D pose by establishing
correspondences between 2D image features and 3D model features. However, these
methods often face difficulties with textureless objects and varying
illumination conditions. To overcome these limitations, we propose GS2POSE, a
novel approach for 6D object pose estimation. GS2POSE formulates a pose
regression algorithm inspired by the principles of Bundle Adjustment (BA). By
leveraging Lie algebra, we extend the capabilities of 3DGS to develop a
pose-differentiable rendering pipeline, which iteratively optimizes the pose by
comparing the input image to the rendered image. Additionally, GS2POSE updates
color parameters within the 3DGS model, enhancing its adaptability to changes
in illumination. Compared to previous models, GS2POSE demonstrates accuracy
improvements of 1.4\%, 2.8\% and 2.5\% on the T-LESS, LineMod-Occlusion and
LineMod datasets, respectively.

</details>


### [78] [Xiaoice: Training-Free Video Understanding via Self-Supervised Spatio-Temporal Clustering of Semantic Features](https://arxiv.org/abs/2510.16781)
*Shihao Ji,Zihui Song*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的视频理解框架，结合预训练VLM和机器学习算法，实现了零样本视频结构分析，并生成多模态摘要。


<details>
  <summary>Details</summary>
Motivation: 当前视频理解模型通常依赖大量标注数据和任务特定训练，成本高且扩展性有限。本文旨在开发一种无需训练的零样本视频理解方法，以克服这些限制。

Method: 框架将视频理解重新定义为高维语义特征空间中的自监督时空聚类问题。首先使用预训练VLM的视觉编码器将视频流转换为语义特征轨迹，然后采用Kernel Temporal Segmentation（KTS）技术分割特征流，最后通过无监督密度聚类识别视频中的宏观场景和主题。

Result: 提出的框架能够自动生成结构化、多模态的视频内容摘要，展示了在零样本设置下的高效视频分析能力。

Conclusion: 本文提出了一种无需训练的视频理解框架，通过结合预训练的视觉语言模型（VLM）和经典机器学习算法，实现了视频内容的零样本结构分析。该方法提供了一种高效、可解释且模型无关的路径。

Abstract: The remarkable zero-shot reasoning capabilities of large-scale Visual
Language Models (VLMs) on static images have yet to be fully translated to the
video domain. Conventional video understanding models often rely on extensive,
task-specific training on annotated datasets, a process that is both costly and
limited in scalability. This paper introduces a novel, training-free framework
for video understanding that circumvents end-to-end training by synergistically
combining the rich semantic priors of pre-trained VLMs with classic machine
learning algorithms for pattern discovery. Our core idea is to reframe video
understanding as a self-supervised spatio-temporal clustering problem within a
high-dimensional semantic feature space. The proposed pipeline first transforms
a video stream into a semantic feature trajectory using the frozen visual
encoder of a pre-trained VLM. Subsequently, we employ Kernel Temporal
Segmentation (KTS), a robust machine learning technique, to partition the
continuous feature stream into discrete, semantically coherent event segments.
These segments are then subjected to unsupervised density-based clustering to
identify recurring macroscopic scenes and themes throughout the video. By
selecting representative keyframes from each discovered cluster and leveraging
the VLM's generative capabilities for textual description, our framework
automatically produces a structured, multi-modal summary of the video content.
This approach provides an effective, interpretable, and model-agnostic pathway
for zero-shot, automated structural analysis of video content.

</details>


### [79] [Segmentation as A Plug-and-Play Capability for Frozen Multimodal LLMs](https://arxiv.org/abs/2510.16785)
*Jiazhen Liu,Long Chen*

Main category: cs.CV

TL;DR: LENS是一种新型的即插即用解决方案，通过在冻结的MLLM上附加轻量级头，实现像素级分割，同时保持模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了在MLLMs中集成像素级分割能力，现有方法需要微调模型以产生与掩码解码器兼容的输出，这会改变模型的输出空间并损害其内在的泛化能力。

Method: LENS通过在完全冻结的MLLM上附加一个轻量级、可训练的头，利用注意力图中的空间线索提取关键点，并将其描述为与掩码解码器直接兼容的点状特征。

Result: LENS在分割性能上达到或优于基于重训练的方法，同时完全保留了MLLM的泛化能力。

Conclusion: LENS提供了一种高效且强大的范式，通过可附加设计扩展MLLMs的能力，为构建真正多功能的统一模型铺平了道路。

Abstract: Integrating diverse visual capabilities into a unified model is a significant
trend in Multimodal Large Language Models (MLLMs). Among these, the inclusion
of segmentation poses a distinct set of challenges. To equip MLLMs with
pixel-level segmentation abilities, prevailing methods require finetuning the
model to produce specific outputs compatible with a mask decoder. This process
typically alters the model's output space and compromises its intrinsic
generalization, which undermines the goal of building a unified model. We
introduce LENS (Leveraging kEypoiNts for MLLMs' Segmentation), a novel
plug-and-play solution. LENS attaches a lightweight, trainable head to a
completely frozen MLLM. By refining the spatial cues embedded in attention
maps, LENS extracts keypoints and describes them into point-wise features
directly compatible with the mask decoder. Extensive experiments validate our
approach: LENS achieves segmentation performance competitive with or superior
to that of retraining-based methods. Crucially, it does so while fully
preserving the MLLM's generalization capabilities, which are significantly
degraded by finetuning approaches. As such, the attachable design of LENS
establishes an efficient and powerful paradigm for extending MLLMs, paving the
way for truly multi-talented, unified models.

</details>


### [80] [Unsupervised Monocular Road Segmentation for Autonomous Driving via Scene Geometry](https://arxiv.org/abs/2510.16790)
*Sara Hatami Rostami,Behrooz Nasihatkon*

Main category: cs.CV

TL;DR: 本文提出了一种完全无监督的道路分割方法，利用几何和时序线索，无需手动标注，在Cityscapes数据集上达到0.82 IoU。


<details>
  <summary>Details</summary>
Motivation: 消除对昂贵手动标注数据集的依赖，实现完全无监督的二进制道路分割（道路与非道路）。

Method: 该方法利用场景几何和时序线索来区分道路和非道路区域。首先从几何先验生成弱标签，标记地平线以上像素为非道路，车辆前方预定义四边形为道路。在细化阶段，通过跨帧跟踪局部特征点并利用互信息最大化惩罚不一致的标签分配，增强精度和时间稳定性。

Result: 在Cityscapes数据集上，模型实现了0.82的Intersection-over-Union (IoU)，展示了高准确性和简单设计的优势。

Conclusion: 本文展示了结合几何约束和时间一致性在自动驾驶中实现可扩展的无监督道路分割的潜力。

Abstract: This paper presents a fully unsupervised approach for binary road
segmentation (road vs. non-road), eliminating the reliance on costly manually
labeled datasets. The method leverages scene geometry and temporal cues to
distinguish road from non-road regions. Weak labels are first generated from
geometric priors, marking pixels above the horizon as non-road and a predefined
quadrilateral in front of the vehicle as road. In a refinement stage, temporal
consistency is enforced by tracking local feature points across frames and
penalizing inconsistent label assignments using mutual information
maximization. This enhances both precision and temporal stability. On the
Cityscapes dataset, the model achieves an Intersection-over-Union (IoU) of
0.82, demonstrating high accuracy with a simple design. These findings
demonstrate the potential of combining geometric constraints and temporal
consistency for scalable unsupervised road segmentation in autonomous driving.

</details>


### [81] [Personalized Image Filter: Mastering Your Photographic Style](https://arxiv.org/abs/2510.16791)
*Chengxuan Zhu,Shuchen Weng,Jiacong Fang,Peixuan Zhang,Si Li,Chao Xu,Boxin Shi*

Main category: cs.CV

TL;DR: PIF通过预训练扩散模型和文本反转技术，成功学习和转移摄影风格。


<details>
  <summary>Details</summary>
Motivation: 解决以往工作无法从参考图像中学习有意义的摄影概念或无法保留内容图像内容的问题。

Method: 基于预训练的文本到图像扩散模型，PIF通过学习摄影概念的平均外观及如何根据文本提示调整它们，结合文本反转技术优化摄影概念的提示。

Result: PIF能够有效学习和转移参考图像的摄影风格。

Conclusion: PIF在提取和转移各种摄影风格方面表现出色。

Abstract: Photographic style, as a composition of certain photographic concepts, is the
charm behind renowned photographers. But learning and transferring photographic
style need a profound understanding of how the photo is edited from the unknown
original appearance. Previous works either fail to learn meaningful
photographic concepts from reference images, or cannot preserve the content of
the content image. To tackle these issues, we proposed a Personalized Image
Filter (PIF). Based on a pretrained text-to-image diffusion model, the
generative prior enables PIF to learn the average appearance of photographic
concepts, as well as how to adjust them according to text prompts. PIF then
learns the photographic style of reference images with the textual inversion
technique, by optimizing the prompts for the photographic concepts. PIF shows
outstanding performance in extracting and transferring various kinds of
photographic style. Project page: https://pif.pages.dev/

</details>


### [82] [ReefNet: A Large scale, Taxonomically Enriched Dataset and Benchmark for Hard Coral Classification](https://arxiv.org/abs/2510.16822)
*Yahia Battach,Abdulwahab Felemban,Faizan Farooq Khan,Yousef A. Radwan,Xiang Li,Fabio Marchese,Sara Beery,Burton H. Jones,Francesca Benzoni,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: ReefNet是一个全球规模的珊瑚礁图像数据集，提供细粒度标注，旨在推动领域泛化和珊瑚分类研究，尽管当前模型在跨域和零样本任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁因气候变化等人为压力迅速衰退，亟需可扩展的自动化监测方法。

Method: ReefNet整合了76个CoralNet来源和一个红海Al Wajh站点的图像，提供了约925000个专家验证的属级硬珊瑚标注，并采用两种评估设置：同源基准和跨源基准。

Result: 监督学习在同源基准中表现良好，但在跨源基准中性能显著下降，零样本模型在所有情况下表现均不佳，尤其是稀有和视觉相似的属。

Conclusion: ReefNet数据集及其基准测试旨在推动领域泛化和细粒度珊瑚分类的进展，为全球珊瑚礁监测和保护提供支持。

Abstract: Coral reefs are rapidly declining due to anthropogenic pressures such as
climate change, underscoring the urgent need for scalable, automated
monitoring. We introduce ReefNet, a large public coral reef image dataset with
point-label annotations mapped to the World Register of Marine Species (WoRMS).
ReefNet aggregates imagery from 76 curated CoralNet sources and an additional
site from Al Wajh in the Red Sea, totaling approximately 925000 genus-level
hard coral annotations with expert-verified labels. Unlike prior datasets,
which are often limited by size, geography, or coarse labels and are not
ML-ready, ReefNet offers fine-grained, taxonomically mapped labels at a global
scale to WoRMS. We propose two evaluation settings: (i) a within-source
benchmark that partitions each source's images for localized evaluation, and
(ii) a cross-source benchmark that withholds entire sources to test domain
generalization. We analyze both supervised and zero-shot classification
performance on ReefNet and find that while supervised within-source performance
is promising, supervised performance drops sharply across domains, and
performance is low across the board for zero-shot models, especially for rare
and visually similar genera. This provides a challenging benchmark intended to
catalyze advances in domain generalization and fine-grained coral
classification. We will release our dataset, benchmarking code, and pretrained
models to advance robust, domain-adaptive, global coral reef monitoring and
conservation.

</details>


### [83] [Robust Cross-Domain Adaptation in Texture Features Transferring for Wood Chip Moisture Content Prediction](https://arxiv.org/abs/2510.16832)
*Abdur Rahman,Mohammad Marufuzzaman,Jason Street,Haifeng Wang,Veera G. Gude,Randy Buchanan*

Main category: cs.CV

TL;DR: 本研究提出AdaptMoist方法，通过纹理特征和领域适应技术，显著提高了木材碎片水分含量的预测准确率，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的直接方法（如烘箱干燥）处理时间长且破坏样本，而间接方法（如近红外光谱、电容和图像分析）在面对不同来源的木材碎片时准确性不足。因此，需要一种能有效减轻源变异性影响的稳健方法。

Method: 本研究对五种不同的纹理特征类型进行了全面分析，并提出了一种名为AdaptMoist的领域适应方法，利用纹理特征将知识从一个木材碎片数据源转移到另一个数据源。此外，还提出了基于调整互信息的模型保存标准。

Result: 结合五种纹理特征的组合实现了95%的准确率，显著优于单一特征。AdaptMoist方法将跨领域预测准确率提高了23%，平均准确率达到80%，而非适应模型仅为57%。

Conclusion: AdaptMoist方法作为一种跨领域的稳健解决方案，显著提高了木材碎片水分含量预测的准确性，为依赖木材碎片的行业提供了潜在解决方案。

Abstract: Accurate and quick prediction of wood chip moisture content is critical for
optimizing biofuel production and ensuring energy efficiency. The current
widely used direct method (oven drying) is limited by its longer processing
time and sample destructiveness. On the other hand, existing indirect methods,
including near-infrared spectroscopy-based, electrical capacitance-based, and
image-based approaches, are quick but not accurate when wood chips come from
various sources. Variability in the source material can alter data
distributions, undermining the performance of data-driven models. Therefore,
there is a need for a robust approach that effectively mitigates the impact of
source variability. Previous studies show that manually extracted texture
features have the potential to predict wood chip moisture class. Building on
this, in this study, we conduct a comprehensive analysis of five distinct
texture feature types extracted from wood chip images to predict moisture
content. Our findings reveal that a combined feature set incorporating all five
texture features achieves an accuracy of 95% and consistently outperforms
individual texture features in predicting moisture content. To ensure robust
moisture prediction, we propose a domain adaptation method named AdaptMoist
that utilizes the texture features to transfer knowledge from one source of
wood chip data to another, addressing variability across different domains. We
also proposed a criterion for model saving based on adjusted mutual
information. The AdaptMoist method improves prediction accuracy across domains
by 23%, achieving an average accuracy of 80%, compared to 57% for non-adapted
models. These results highlight the effectiveness of AdaptMoist as a robust
solution for wood chip moisture content estimation across domains, making it a
potential solution for wood chip-reliant industries.

</details>


### [84] [2DGS-R: Revisiting the Normal Consistency Regularization in 2D Gaussian Splatting](https://arxiv.org/abs/2510.16837)
*Haofan Ren,Qingsong Yan,Ming Lu,Rongfeng Lu,Zunjie Zhu*

Main category: cs.CV

TL;DR: 2DGS-R通过分层训练和原位克隆操作，在保持几何精度的同时提升渲染质量，效率与性能兼顾。


<details>
  <summary>Details</summary>
Motivation: 3DGS在渲染质量上表现优异但难以准确表示表面，而2DGS虽然提升了几何保真度但牺牲了渲染质量。因此，需要一种能同时优化几何和渲染质量的方法。

Method: 2DGS-R采用分层训练方法：首先对原始2D高斯进行法线一致性正则化训练，随后选择渲染质量不足的2D高斯进行原位克隆操作增强，最后冻结不透明度微调模型。

Result: 实验表明，2DGS-R仅增加1%的存储和少量训练时间，即可实现高质量渲染并保留精细几何结构。

Conclusion: 2DGS-R方法在保持几何精度的同时显著提升了渲染质量，证明了其在高保真渲染和几何重建中的高效性和优越性。

Abstract: Recent advancements in 3D Gaussian Splatting (3DGS) have greatly influenced
neural fields, as it enables high-fidelity rendering with impressive visual
quality. However, 3DGS has difficulty accurately representing surfaces. In
contrast, 2DGS transforms the 3D volume into a collection of 2D planar Gaussian
disks. Despite advancements in geometric fidelity, rendering quality remains
compromised, highlighting the challenge of achieving both high-quality
rendering and precise geometric structures. This indicates that optimizing both
geometric and rendering quality in a single training stage is currently
unfeasible. To overcome this limitation, we present 2DGS-R, a new method that
uses a hierarchical training approach to improve rendering quality while
maintaining geometric accuracy. 2DGS-R first trains the original 2D Gaussians
with the normal consistency regularization. Then 2DGS-R selects the 2D
Gaussians with inadequate rendering quality and applies a novel in-place
cloning operation to enhance the 2D Gaussians. Finally, we fine-tune the 2DGS-R
model with opacity frozen. Experimental results show that compared to the
original 2DGS, our method requires only 1\% more storage and minimal additional
training time. Despite this negligible overhead, it achieves high-quality
rendering results while preserving fine geometric structures. These findings
indicate that our approach effectively balances efficiency with performance,
leading to improvements in both visual fidelity and geometric reconstruction
accuracy.

</details>


### [85] [ArmFormer: Lightweight Transformer Architecture for Real-Time Multi-Class Weapon Segmentation and Classification](https://arxiv.org/abs/2510.16854)
*Akhila Kambhatla,Taminul Islam,Khaled R Ahmed*

Main category: cs.CV

TL;DR: ArmFormer是一种轻量级Transformer语义分割框架，结合CBAM与MixVisionTransformer，实现了高精度武器检测，适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 由于传统武器检测方法仅提供粗略的边界框定位，且现有语义分割模型在精度和计算效率之间难以平衡，无法满足边缘部署的需求，因此需要一种既能保持高精度又能在资源受限设备上高效运行的解决方案。

Method: ArmFormer结合了Convolutional Block Attention Module (CBAM)与MixVisionTransformer架构，通过CBAM增强的编码器主干和注意力集成的解码器实现多类武器分割。

Result: ArmFormer在实验中表现出色，达到了80.64%的mIoU和89.13%的mFscore，同时保持82.26 FPS的实时推理速度，仅需4.886G FLOPs和3.66M参数。

Conclusion: ArmFormer被证明是一种轻量级、高效的语义分割框架，适用于资源受限的边缘设备，能够实时检测和分类多种武器，为实时安全应用提供了最优解决方案。

Abstract: The escalating threat of weapon-related violence necessitates automated
detection systems capable of pixel-level precision for accurate threat
assessment in real-time security applications. Traditional weapon detection
approaches rely on object detection frameworks that provide only coarse
bounding box localizations, lacking the fine-grained segmentation required for
comprehensive threat analysis. Furthermore, existing semantic segmentation
models either sacrifice accuracy for computational efficiency or require
excessive computational resources incompatible with edge deployment scenarios.
This paper presents ArmFormer, a lightweight transformer-based semantic
segmentation framework that strategically integrates Convolutional Block
Attention Module (CBAM) with MixVisionTransformer architecture to achieve
superior accuracy while maintaining computational efficiency suitable for
resource-constrained edge devices. Our approach combines CBAM-enhanced encoder
backbone with attention-integrated hamburger decoder to enable multi-class
weapon segmentation across five categories: handgun, rifle, knife, revolver,
and human. Comprehensive experiments demonstrate that ArmFormer achieves
state-of-the-art performance with 80.64% mIoU and 89.13% mFscore while
maintaining real-time inference at 82.26 FPS. With only 4.886G FLOPs and 3.66M
parameters, ArmFormer outperforms heavyweight models requiring up to 48x more
computation, establishing it as the optimal solution for deployment on portable
security cameras, surveillance drones, and embedded AI accelerators in
distributed security infrastructure.

</details>


### [86] [BARL: Bilateral Alignment in Representation and Label Spaces for Semi-Supervised Volumetric Medical Image Segmentation](https://arxiv.org/abs/2510.16863)
*Shujian Gao,Yuan Wang,Zekuan Yu*

Main category: cs.CV

TL;DR: BARL框架通过双边对齐（表征和标签空间）提升半监督医学图像分割性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有半监督医学图像分割方法过度依赖标签空间一致性，忽视了表征空间对齐的重要性，导致模型难以学习到判别性强且空间连贯的表示。

Method: 引入BARL框架，包含双路径正则化（DPR）和渐进认知偏差校正（PCBC）用于标签空间对齐，以及区域级和病变实例匹配用于表征空间对齐。

Result: 在四个公开基准和一个私有CBCT数据集上，BARL consistently surpasses state-of-the-art SSMIS methods。

Conclusion: BARL框架通过双边对齐（表征空间和标签空间）显著提升了半监督医学图像分割的性能，超越了现有方法，并通过消融研究验证了各组件的重要性。

Abstract: Semi-supervised medical image segmentation (SSMIS) seeks to match fully
supervised performance while sharply reducing annotation cost. Mainstream SSMIS
methods rely on \emph{label-space consistency}, yet they overlook the equally
critical \emph{representation-space alignment}. Without harmonizing latent
features, models struggle to learn representations that are both discriminative
and spatially coherent. To this end, we introduce \textbf{Bilateral Alignment
in Representation and Label spaces (BARL)}, a unified framework that couples
two collaborative branches and enforces alignment in both spaces. For
label-space alignment, inspired by co-training and multi-scale decoding, we
devise \textbf{Dual-Path Regularization (DPR)} and \textbf{Progressively
Cognitive Bias Correction (PCBC)} to impose fine-grained cross-branch
consistency while mitigating error accumulation from coarse to fine scales. For
representation-space alignment, we conduct region-level and lesion-instance
matching between branches, explicitly capturing the fragmented, complex
pathological patterns common in medical imagery. Extensive experiments on four
public benchmarks and a proprietary CBCT dataset demonstrate that BARL
consistently surpasses state-of-the-art SSMIS methods. Ablative studies further
validate the contribution of each component. Code will be released soon.

</details>


### [87] [Registration is a Powerful Rotation-Invariance Learner for 3D Anomaly Detection](https://arxiv.org/abs/2510.16865)
*Yuyang Yu,Zhengwei Chen,Xuemiao Xu,Lei Zhang,Haoxin Yang,Yongwei Nie,Shengfeng He*

Main category: cs.CV

TL;DR: 提出了一种结合配准和异常检测的旋转不变特征提取框架，显著提升了3D异常检测的效果和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前基于记忆库的方法在特征转换的一致性和区分能力上存在局限，特别是在捕捉局部几何细节和实现旋转不变性方面。点云配准不仅对齐几何结构，还能引导特征提取朝向旋转不变和局部区分性表示。

Method: 提出了一种结合点云配准和基于记忆的异常检测的框架，通过将特征提取嵌入配准学习过程中，联合优化对齐和表示学习。

Result: 在Anomaly-ShapeNet和Real3D-AD数据集上的广泛实验表明，该方法在效果和泛化能力上均优于现有方法。

Conclusion: 本文提出的基于配准的旋转不变特征提取框架在3D异常检测中表现出色，显著提升了现有方法的效果和泛化能力。

Abstract: 3D anomaly detection in point-cloud data is critical for industrial quality
control, aiming to identify structural defects with high reliability. However,
current memory bank-based methods often suffer from inconsistent feature
transformations and limited discriminative capacity, particularly in capturing
local geometric details and achieving rotation invariance. These limitations
become more pronounced when registration fails, leading to unreliable detection
results. We argue that point-cloud registration plays an essential role not
only in aligning geometric structures but also in guiding feature extraction
toward rotation-invariant and locally discriminative representations. To this
end, we propose a registration-induced, rotation-invariant feature extraction
framework that integrates the objectives of point-cloud registration and
memory-based anomaly detection. Our key insight is that both tasks rely on
modeling local geometric structures and leveraging feature similarity across
samples. By embedding feature extraction into the registration learning
process, our framework jointly optimizes alignment and representation learning.
This integration enables the network to acquire features that are both robust
to rotations and highly effective for anomaly detection. Extensive experiments
on the Anomaly-ShapeNet and Real3D-AD datasets demonstrate that our method
consistently outperforms existing approaches in effectiveness and
generalizability.

</details>


### [88] [Uncovering Brain-Like Hierarchical Patterns in Vision-Language Models through fMRI-Based Neural Encoding](https://arxiv.org/abs/2510.16870)
*Yudan Ren,Xinlong Wang,Kexin Wang,Tian Xia,Zihan Ma,Zhaowei Li,Xiangrong Bi,Xiao Li,Xiaowei He*

Main category: cs.CV

TL;DR: 提出神经元级分析框架，发现视觉语言模型在神经元水平上展现出类似人脑的分层处理机制，验证了ANNs与大脑处理的相似性。


<details>
  <summary>Details</summary>
Motivation: 当前的人工神经网络研究在多模态处理能力与神经元级分析方面存在不足，无法充分捕捉人脑的多模态处理机制。

Method: 提出了一种新颖的神经元级分析框架，结合细粒度人工神经元（AN）分析和基于fMRI的体素编码，研究了两种架构不同的视觉语言模型（CLIP和METER）。

Result: 研究发现：（1）ANs能预测生物神经元（BNs）活动；（2）ANs和BNs均表现出功能冗余；（3）ANs的极性模式与BNs相似；（4）CLIP和METER的架构对BNs产生不同影响。

Conclusion: 研究结果表明，视觉语言模型（VLMs）在神经元水平上展现出类似人脑的分层处理机制，为人工神经网络（ANNs）与人类大脑处理之间的相似性提供了有力证据。

Abstract: While brain-inspired artificial intelligence(AI) has demonstrated promising
results, current understanding of the parallels between artificial neural
networks (ANNs) and human brain processing remains limited: (1) unimodal ANN
studies fail to capture the brain's inherent multimodal processing
capabilities, and (2) multimodal ANN research primarily focuses on high-level
model outputs, neglecting the crucial role of individual neurons. To address
these limitations, we propose a novel neuron-level analysis framework that
investigates the multimodal information processing mechanisms in
vision-language models (VLMs) through the lens of human brain activity. Our
approach uniquely combines fine-grained artificial neuron (AN) analysis with
fMRI-based voxel encoding to examine two architecturally distinct VLMs: CLIP
and METER. Our analysis reveals four key findings: (1) ANs successfully predict
biological neurons (BNs) activities across multiple functional networks
(including language, vision, attention, and default mode), demonstrating shared
representational mechanisms; (2) Both ANs and BNs demonstrate functional
redundancy through overlapping neural representations, mirroring the brain's
fault-tolerant and collaborative information processing mechanisms; (3) ANs
exhibit polarity patterns that parallel the BNs, with oppositely activated BNs
showing mirrored activation trends across VLM layers, reflecting the complexity
and bidirectional nature of neural information processing; (4) The
architectures of CLIP and METER drive distinct BNs: CLIP's independent branches
show modality-specific specialization, whereas METER's cross-modal design
yields unified cross-modal activation, highlighting the architecture's
influence on ANN brain-like properties. These results provide compelling
evidence for brain-like hierarchical processing in VLMs at the neuronal level.

</details>


### [89] [Class-N-Diff: Classification-Induced Diffusion Model Can Make Fair Skin Cancer Diagnosis](https://arxiv.org/abs/2510.16887)
*Nusrat Munia,Abdullah Imran*

Main category: cs.CV

TL;DR: Class-N-Diff是一种结合分类器的扩散模型，用于生成和分类皮肤镜图像，提升生成质量和分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统类别条件生成模型在生成特定医学类别图像时表现不佳，限制了其在皮肤癌诊断等应用中的实用性。

Method: 提出了一种分类引导的扩散模型（Class-N-Diff），在扩散模型中集成分类器，基于类别条件生成图像。

Result: Class-N-Diff模型能够生成更真实、多样化的图像，同时分类器性能也有所提升。

Conclusion: Class-N-Diff模型通过将分类器与扩散模型结合，显著提升了皮肤镜图像生成的准确性和多样性，同时增强了分类器的性能，为皮肤癌诊断等下游任务提供了更可靠的合成数据工具。

Abstract: Generative models, especially Diffusion Models, have demonstrated remarkable
capability in generating high-quality synthetic data, including medical images.
However, traditional class-conditioned generative models often struggle to
generate images that accurately represent specific medical categories, limiting
their usefulness for applications such as skin cancer diagnosis. To address
this problem, we propose a classification-induced diffusion model, namely,
Class-N-Diff, to simultaneously generate and classify dermoscopic images. Our
Class-N-Diff model integrates a classifier within a diffusion model to guide
image generation based on its class conditions. Thus, the model has better
control over class-conditioned image synthesis, resulting in more realistic and
diverse images. Additionally, the classifier demonstrates improved performance,
highlighting its effectiveness for downstream diagnostic tasks. This unique
integration in our Class-N-Diff makes it a robust tool for enhancing the
quality and utility of diffusion model-based synthetic dermoscopic image
generation. Our code is available at https://github.com/Munia03/Class-N-Diff.

</details>


### [90] [Uniworld-V2: Reinforce Image Editing with Diffusion Negative-aware Finetuning and MLLM Implicit Feedback](https://arxiv.org/abs/2510.16888)
*Zongjian Li,Zheyuan Liu,Qihui Zhang,Bin Lin,Shenghai Yuan,Zhiyuan Yan,Yang Ye,Wangbo Yu,Yuwei Niu,Li Yuan*

Main category: cs.CV

TL;DR: Edit-R1通过策略优化和MLLM奖励模型提升指令式图像编辑性能，UniWorld-V2在多个基准测试中领先。


<details>
  <summary>Details</summary>
Motivation: 解决监督微调模型在指令式图像编辑中过拟合训练分布的问题，提升模型的泛化能力和探索性。

Method: 采用Diffusion Negative-aware Finetuning (DiffusionNFT)策略优化方法，结合MLLM作为训练无关的奖励模型，并设计低方差组过滤机制以减少噪声。

Result: UniWorld-V2在ImgEdit和GEdit-Bench基准测试中分别取得4.49和7.83的高分，表现优于其他模型。

Conclusion: Edit-R1框架通过策略优化和MLLM作为统一奖励模型，显著提升了指令式图像编辑的性能，并在多个基准测试中取得了最先进的结果。

Abstract: Instruction-based image editing has achieved remarkable progress; however,
models solely trained via supervised fine-tuning often overfit to annotated
patterns, hindering their ability to explore and generalize beyond training
distributions. To this end, we introduce Edit-R1, a novel post-training
framework for instruction-based image editing based on policy optimization.
Specifically, we utilize Diffusion Negative-aware Finetuning (DiffusionNFT), a
likelihood-free policy optimization method consistent with the flow matching
forward process, thereby enabling the use of higher-order samplers and more
efficient training. Another key challenge here is the absence of a universal
reward model, resulting from the diverse nature of editing instructions and
tasks. To bridge this gap, we employ a Multimodal Large Language Model (MLLM)
as a unified, training-free reward model, leveraging its output logits to
provide fine-grained feedback. Furthermore, we carefully design a low-variance
group filtering mechanism to reduce MLLM scoring noise and stabilize
optimization. UniWorld-V2, trained with this framework, achieves
\textbf{state-of-the-art} results on the ImgEdit and GEdit-Bench benchmarks,
scoring 4.49 and 7.83, respectively. Crucially, our framework is
model-agnostic, delivering substantial performance gains when applied to
diverse base models like Qwen-Image-Edit and FLUX-Kontext, demonstrating its
wide applicability. Code and models are publicly available at
https://github.com/PKU-YuanGroup/UniWorld-V2.

</details>


### [91] [Contrail-to-Flight Attribution Using Ground Visible Cameras and Flight Surveillance Data](https://arxiv.org/abs/2510.16891)
*Ramon Dalmau,Gabriel Jarry,Philippe Very*

Main category: cs.CV

TL;DR: 地面相机高分辨率捕捉航迹云，提出模块化框架关联观测与理论航迹云，解决卫星方法分辨率不足问题。


<details>
  <summary>Details</summary>
Motivation: 航迹云对气候的影响可能超过航空业的CO2排放，但现有卫星方法的时空分辨率有限，难以准确关联航迹云与源航班。地面相机能高分辨率捕捉航迹云，为解决这一问题提供了新思路。

Method: 利用地面可见相机航迹云序列（GVCCS）数据集，提出了一种模块化框架，结合几何表示、距离度量、时间平滑和概率分配策略，实现了航迹云与源航班的关联。

Result: 提出的框架能够有效关联地面相机观测的航迹云与理论航迹云，为航迹云-航班关联研究提供了基准和模块化工具。

Conclusion: 本研究通过地面相机捕捉航迹云，提出了一种模块化框架，用于将观测到的航迹云与理论航迹云进行关联，为未来研究提供了强有力的基础和灵活的方法。

Abstract: Aviation's non-CO2 effects, particularly contrails, are a significant
contributor to its climate impact. Persistent contrails can evolve into
cirrus-like clouds that trap outgoing infrared radiation, with radiative
forcing potentially comparable to or exceeding that of aviation's CO2
emissions. While physical models simulate contrail formation, evolution and
dissipation, validating and calibrating these models requires linking observed
contrails to the flights that generated them, a process known as
contrail-to-flight attribution. Satellite-based attribution is challenging due
to limited spatial and temporal resolution, as contrails often drift and deform
before detection. In this paper, we evaluate an alternative approach using
ground-based cameras, which capture contrails shortly after formation at high
spatial and temporal resolution, when they remain thin, linear, and visually
distinct. Leveraging the ground visible camera contrail sequences (GVCCS)
dataset, we introduce a modular framework for attributing contrails observed
using ground-based cameras to theoretical contrails derived from aircraft
surveillance and meteorological data. The framework accommodates multiple
geometric representations and distance metrics, incorporates temporal
smoothing, and enables flexible probability-based assignment strategies. This
work establishes a strong baseline and provides a modular framework for future
research in linking contrails to their source flight.

</details>


### [92] [Beyond RGB: Leveraging Vision Transformers for Thermal Weapon Segmentation](https://arxiv.org/abs/2510.16913)
*Akhila Kambhatla,Ahmed R Khaled*

Main category: cs.CV

TL;DR: Transformer-based models excel in thermal weapon segmentation, with SegFormer-b5 leading in accuracy and SegFormer-b0 in speed, suitable for real-time security applications.


<details>
  <summary>Details</summary>
Motivation: Thermal weapon segmentation is critical for surveillance under low-light and obscured conditions where RGB systems fail. While CNNs are limited in capturing long-range dependencies, ViTs show promise but remain underexplored in thermal segmentation.

Method: The study adapts and evaluates four transformer-based architectures (SegFormer, DeepLabV3+, SegNeXt, and Swin Transformer) on a custom thermal dataset using standard augmentation strategies within the MMSegmentation framework.

Result: SegFormer-b5 achieves the highest mIoU (94.15%) and Pixel Accuracy (97.04%), while SegFormer-b0 offers the fastest inference speed (98.32 FPS) with competitive mIoU (90.84%). Other models like SegNeXt-mscans and DeepLabV3+ R101-D8 also show balanced performance.

Conclusion: Transformer-based architectures, particularly SegFormer-b5, demonstrate superior performance in thermal weapon segmentation, offering robust generalization and flexible accuracy-speed trade-offs for real-time security applications.

Abstract: Thermal weapon segmentation is crucial for surveillance and security
applications, enabling robust detection under lowlight and visually obscured
conditions where RGB-based systems fail. While convolutional neural networks
(CNNs) dominate thermal segmentation literature, their ability to capture
long-range dependencies and fine structural details is limited. Vision
Transformers (ViTs), with their global context modeling capabilities, have
achieved state-of-the-art results in RGB segmentation tasks, yet their
potential in thermal weapon segmentation remains underexplored. This work
adapts and evaluates four transformer-based architectures SegFormer,
DeepLabV3\+, SegNeXt, and Swin Transformer for binary weapon segmentation on a
custom thermal dataset comprising 9,711 images collected from real world
surveillance videos and automatically annotated using SAM2. We employ standard
augmentation strategies within the MMSegmentation framework to ensure robust
model training and fair architectural comparison. Experimental results
demonstrate significant improvements in segmentation performance: SegFormer-b5
achieves the highest mIoU (94.15\%) and Pixel Accuracy (97.04\%), while
SegFormer-b0 provides the fastest inference speed (98.32 FPS) with competitive
mIoU (90.84\%). SegNeXt-mscans offers balanced performance with 85.12 FPS and
92.24\% mIoU, and DeepLabV3\+ R101-D8 reaches 92.76\% mIoU at 29.86 FPS. The
transformer architectures demonstrate robust generalization capabilities for
weapon detection in low-light and occluded thermal environments, with flexible
accuracy-speed trade-offs suitable for diverse real-time security applications.

</details>


### [93] [Res-Bench: Benchmarking the Robustness of Multimodal Large Language Models to Dynamic Resolution Input](https://arxiv.org/abs/2510.16926)
*Chenxu Li,Zhicai Wang,Yuan Sheng,Xingyu Zhu,Yanbin Hao,Xiang Wang*

Main category: cs.CV

TL;DR: 研究提出Res-Bench基准和新评估框架，量化多模态大语言模型的分辨率鲁棒性，发现现有模型不足，并探索提升稳定性的策略。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型的评估主要关注语义性能，忽视了分辨率鲁棒性（即模型在不同输入分辨率下的性能稳定性）。研究旨在填补这一空白。

Method: 研究设计了Res-Bench基准，包含14,400个样本，覆盖12种分辨率级别和6个核心能力维度。提出了一种新的评估框架，引入Spearman相关性、ACE和RCE等指标来量化性能稳定性。

Result: 大规模评估揭示了现有模型在分辨率鲁棒性方面的不足，并验证了预处理策略（如填充和超分辨率）和微调对提升稳定性的有效性。

Conclusion: 研究提出了Res-Bench基准和新的评估框架，用于全面评估多模态大语言模型在不同分辨率下的性能稳定性。通过引入Spearman相关性和ACE/RCE等新指标，研究发现现有模型在分辨率鲁棒性方面存在不足，并探索了预处理和微调策略以提升稳定性。

Abstract: Multimodal Large Language Models (MLLMs) increasingly support dynamic image
resolutions. However, current evaluation paradigms primarily assess semantic
performance, overlooking the critical question of resolution robustness -
whether performance remains stable across varying input resolutions. To address
this gap, we introduce \textbf{Res-Bench}, a comprehensive benchmark comprising
14,400 samples across 12 resolution levels and six core capability dimensions.
We designed a novel evaluation framework that goes beyond traditional accuracy
metrics to capture performance stability. This framework introduces multiple
robustness metrics: Spearman's correlation for assessing resolution-performance
trends, and Absolute/Relative Continuous Error (ACE/RCE) for measuring
performance volatility. Using these metrics, we conducted a large-scale
evaluation of leading MLLMs. Our analysis encompasses: (1) model-centric and
task-centric robustness examination, (2) investigation of preprocessing
strategies including padding and super-resolution, and (3) exploration of
fine-tuning for stability enhancement.

</details>


### [94] [Foundation Models in Medical Image Analysis: A Systematic Review and Meta-Analysis](https://arxiv.org/abs/2510.16973)
*Praveenbalaji Rajendran,Mojtaba Safari,Wenfeng He,Mingzhe Hu,Shansong Wang,Jun Zhou,Xiaofeng Yang*

Main category: cs.CV

TL;DR: 该综述系统分析了医学图像分析中的基础模型，分类了研究并进行了元分析，讨论了挑战与解决方案，并提出了未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在医学图像分析中研究迅速增长，但领域仍缺乏对架构、训练范式和临床应用的统一综合。

Method: 文章系统地将研究分为基于视觉和视觉语言的基础模型，并进行了定量元分析以描述数据集利用和应用领域的时间趋势。

Result: 文章识别了持续的挑战（如领域适应、高效微调）及新兴解决方案（如联邦学习、知识蒸馏），并提出了未来研究方向。

Conclusion: 该综述文章为医学图像分析中的基础模型（FMs）提供了全面的结构化分析，指出了未来研究方向以增强其稳健性、可解释性和临床整合。

Abstract: Recent advancements in artificial intelligence (AI), particularly foundation
models (FMs), have revolutionized medical image analysis, demonstrating strong
zero- and few-shot performance across diverse medical imaging tasks, from
segmentation to report generation. Unlike traditional task-specific AI models,
FMs leverage large corpora of labeled and unlabeled multimodal datasets to
learn generalized representations that can be adapted to various downstream
clinical applications with minimal fine-tuning. However, despite the rapid
proliferation of FM research in medical imaging, the field remains fragmented,
lacking a unified synthesis that systematically maps the evolution of
architectures, training paradigms, and clinical applications across modalities.
To address this gap, this review article provides a comprehensive and
structured analysis of FMs in medical image analysis. We systematically
categorize studies into vision-only and vision-language FMs based on their
architectural foundations, training strategies, and downstream clinical tasks.
Additionally, a quantitative meta-analysis of the studies was conducted to
characterize temporal trends in dataset utilization and application domains. We
also critically discuss persistent challenges, including domain adaptation,
efficient fine-tuning, computational constraints, and interpretability along
with emerging solutions such as federated learning, knowledge distillation, and
advanced prompting. Finally, we identify key future research directions aimed
at enhancing the robustness, explainability, and clinical integration of FMs,
thereby accelerating their translation into real-world medical practice.

</details>


### [95] [One-step Diffusion Models with Bregman Density Ratio Matching](https://arxiv.org/abs/2510.16983)
*Yuanzhi Zhu,Eleftherios Tsonis,Lucas Degeorge,Vicky Kalogeiton*

Main category: cs.CV

TL;DR: Di-Bregman通过Bregman散度密度比匹配，统一扩散蒸馏理论框架，实验证明其在一步生成中高效且保真。


<details>
  <summary>Details</summary>
Motivation: 扩散和流模型生成质量高但计算成本高，现有蒸馏方法缺乏统一理论框架。

Method: 提出Di-Bregman框架，将扩散蒸馏问题建模为Bregman散度密度比匹配，通过凸分析视角统一多个目标。

Result: 在CIFAR-10和文本到图像生成任务中，Di-Bregman在一步FID上优于反向KL蒸馏，视觉保真度接近教师模型。

Conclusion: Di-Bregman框架通过Bregman散度密度比匹配，为扩散蒸馏提供了理论基础，实验证明其在一步生成中优于反向KL蒸馏，并保持了高视觉保真度。

Abstract: Diffusion and flow models achieve high generative quality but remain
computationally expensive due to slow multi-step sampling. Distillation methods
accelerate them by training fast student generators, yet most existing
objectives lack a unified theoretical foundation. In this work, we propose
Di-Bregman, a compact framework that formulates diffusion distillation as
Bregman divergence-based density-ratio matching. This convex-analytic view
connects several existing objectives through a common lens. Experiments on
CIFAR-10 and text-to-image generation demonstrate that Di-Bregman achieves
improved one-step FID over reverse-KL distillation and maintains high visual
fidelity compared to the teacher model. Our results highlight Bregman
density-ratio matching as a practical and theoretically-grounded route toward
efficient one-step diffusion generation.

</details>


### [96] [CARE: Contrastive Alignment for ADL Recognition from Event-Triggered Sensor Streams](https://arxiv.org/abs/2510.16988)
*Junhao Zhao,Zishuai Liu,Ruili Fang,Jin Lu,Linghan Zhang,Fei Dou*

Main category: cs.CV

TL;DR: CARE通过序列-图像对比对齐和联合优化，显著提升ADL识别性能，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在表示层面存在局限性，序列方法对噪声敏感且缺乏空间意识，图像方法压缩时间动态并扭曲传感器布局，简单融合方法未能充分利用互补优势。

Method: 提出CARE框架，结合时间感知、抗噪声的序列编码和空间感知、频率敏感的图像表示，通过联合对比分类目标进行端到端学习。

Result: 在三个CASAS数据集上，CARE实现了最先进的性能（Milan 89.8%，Cairo 88.9%，Kyoto7 73.3%），并表现出对传感器故障和布局变化的鲁棒性。

Conclusion: CARE框架通过序列-图像对比对齐（SICA）和交叉熵分类的联合优化，在ADL识别任务中实现了最先进的性能，并展示了其对传感器故障和布局变化的鲁棒性。

Abstract: The recognition of Activities of Daily Living (ADLs) from event-triggered
ambient sensors is an essential task in Ambient Assisted Living, yet existing
methods remain constrained by representation-level limitations. Sequence-based
approaches preserve temporal order of sensor activations but are sensitive to
noise and lack spatial awareness, while image-based approaches capture global
patterns and implicit spatial correlations but compress fine-grained temporal
dynamics and distort sensor layouts. Naive fusion (e.g., feature concatenation)
fail to enforce alignment between sequence- and image-based representation
views, underutilizing their complementary strengths. We propose Contrastive
Alignment for ADL Recognition from Event-Triggered Sensor Streams (CARE), an
end-to-end framework that jointly optimizes representation learning via
Sequence-Image Contrastive Alignment (SICA) and classification via
cross-entropy, ensuring both cross-representation alignment and task-specific
discriminability. CARE integrates (i) time-aware, noise-resilient sequence
encoding with (ii) spatially-informed and frequency-sensitive image
representations, and employs (iii) a joint contrastive-classification objective
for end-to-end learning of aligned and discriminative embeddings. Evaluated on
three CASAS datasets, CARE achieves state-of-the-art performance (89.8% on
Milan, 88.9% on Cairo, and 73.3% on Kyoto7) and demonstrates robustness to
sensor malfunctions and layout variability, highlighting its potential for
reliable ADL recognition in smart homes.

</details>


### [97] [Training-free Online Video Step Grounding](https://arxiv.org/abs/2510.16989)
*Luca Zanella,Massimiliano Mancini,Yiming Wang,Alessio Tonioni,Elisa Ricci*

Main category: cs.CV

TL;DR: BaGLM通过结合大型多模态模型和贝叶斯滤波，无需训练即可在线进行视频步骤定位，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频步骤定位方法需要标记训练集且只能离线处理，限制了其在线决策应用。本研究旨在探索无需训练且能在线处理的方法。

Method: 利用大型多模态模型（LMMs）预测与有限帧集相关的步骤，并结合贝叶斯滤波原则，通过依赖矩阵和步骤进度估计来改进预测。

Result: BaGLM在三个数据集上的实验显示，其性能优于现有的基于训练的离线方法。

Conclusion: BaGLM方法通过结合贝叶斯滤波原则和大语言模型的依赖矩阵，显著提升了视频步骤定位的性能，优于现有基于训练的离线方法。

Abstract: Given a task and a set of steps composing it, Video Step Grounding (VSG) aims
to detect which steps are performed in a video. Standard approaches for this
task require a labeled training set (e.g., with step-level annotations or
narrations), which may be costly to collect. Moreover, they process the full
video offline, limiting their applications for scenarios requiring online
decisions. Thus, in this work, we explore how to perform VSG online and without
training. We achieve this by exploiting the zero-shot capabilities of recent
Large Multimodal Models (LMMs). In particular, we use LMMs to predict the step
associated with a restricted set of frames, without access to the whole video.
We show that this online strategy without task-specific tuning outperforms
offline and training-based models. Motivated by this finding, we develop
Bayesian Grounding with Large Multimodal Models (BaGLM), further injecting
knowledge of past frames into the LMM-based predictions. BaGLM exploits
Bayesian filtering principles, modeling step transitions via (i) a dependency
matrix extracted through large language models and (ii) an estimation of step
progress. Experiments on three datasets show superior performance of BaGLM over
state-of-the-art training-based offline methods.

</details>


### [98] [An empirical study of the effect of video encoders on Temporal Video Grounding](https://arxiv.org/abs/2510.17007)
*Ignacio M. De la Jara,Cristian Rodriguez-Opazo,Edison Marrese-Taylor,Felipe Bravo-Marquez*

Main category: cs.CV

TL;DR: 研究发现不同视频编码器对时间视频定位任务性能有显著影响，暗示特征互补潜力。


<details>
  <summary>Details</summary>
Motivation: 当前研究集中在少数视频表示上，可能导致长期架构过拟合，因此需要研究不同视频特征对任务的影响。

Method: 通过使用基于CNN、时序推理和Transformer的视频编码器，提取三个基准数据集（Charades-STA、ActivityNet-Captions和YouCookII）的特征，并在经典架构上进行实证研究。

Result: 结果显示，仅更换视频编码器即可显著影响模型性能，并揭示了特定特征带来的模式和错误。

Conclusion: 研究表明，不同的视频编码器对时间视频定位任务的性能有显著影响，并揭示了特定特征带来的模式和错误，暗示了特征互补的潜力。

Abstract: Temporal video grounding is a fundamental task in computer vision, aiming to
localize a natural language query in a long, untrimmed video. It has a key role
in the scientific community, in part due to the large amount of video generated
every day. Although we find extensive work in this task, we note that research
remains focused on a small selection of video representations, which may lead
to architectural overfitting in the long run. To address this issue, we propose
an empirical study to investigate the impact of different video features on a
classical architecture. We extract features for three well-known benchmarks,
Charades-STA, ActivityNet-Captions and YouCookII, using video encoders based on
CNNs, temporal reasoning and transformers. Our results show significant
differences in the performance of our model by simply changing the video
encoder, while also revealing clear patterns and errors derived from the use of
certain features, ultimately indicating potential feature complementarity.

</details>


### [99] [Do Satellite Tasks Need Special Pretraining?](https://arxiv.org/abs/2510.17014)
*Ani Vanyan,Alvard Barseghyan,Hakob Tamazyan,Tigran Galstyan,Vahan Huroyan,Naira Hovakimyan,Hrant Khachatrian*

Main category: cs.CV

TL;DR: 研究发现，在小规模下，特定领域的遥感基础模型并不比通用视觉基础模型表现更好，实验验证了这一点。


<details>
  <summary>Details</summary>
Motivation: 研究遥感影像的独特特征、特定应用及卫星图像分析所需的鲁棒性，探讨特定领域基础模型是否比通用模型更有用。

Method: 设计了一个简单的基准测试来衡量遥感模型在两种下游任务中对低分辨率图像的泛化能力，并在MillionAID数据集上训练了iBOT（一种自监督视觉编码器），并针对遥感进行了特定修改。

Result: 实验表明，这些预训练模型在ViT-B规模上均未对通用基线带来一致的改进。

Conclusion: 特定领域的遥感基础模型在小规模上并未显示出比通用视觉基础模型更显著的优势。

Abstract: Foundation models have advanced machine learning across various modalities,
including images. Recently multiple teams trained foundation models specialized
for remote sensing applications. This line of research is motivated by the
distinct characteristics of remote sensing imagery, specific applications and
types of robustness useful for satellite image analysis. In this work we
systematically challenge the idea that specific foundation models are more
useful than general-purpose vision foundation models, at least in the small
scale. First, we design a simple benchmark that measures generalization of
remote sensing models towards images with lower resolution for two downstream
tasks. Second, we train iBOT, a self-supervised vision encoder, on MillionAID,
an ImageNet-scale satellite imagery dataset, with several modifications
specific to remote sensing. We show that none of those pretrained models bring
consistent improvements upon general-purpose baselines at the ViT-B scale.

</details>


### [100] [Enrich and Detect: Video Temporal Grounding with Multimodal LLMs](https://arxiv.org/abs/2510.17023)
*Shraman Pramanick,Effrosyni Mavroudi,Yale Song,Rama Chellappa,Lorenzo Torresani,Triantafyllos Afouras*

Main category: cs.CV

TL;DR: ED-VTG通过两阶段方法，利用多模态大语言模型联合处理文本和视频，显著提升了视频时间定位的准确性，并在多个基准测试中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 利用多模态大语言模型的能力，联合处理文本和视频，以更有效地定位视频中的自然语言查询。

Method: 采用两阶段方法：首先将语言查询转化为包含缺失细节和线索的丰富句子，然后使用轻量级解码器基于这些丰富查询的上下文表示预测准确边界。训练时采用多实例学习目标以减少噪声和幻觉影响。

Result: 在各种时间视频定位和段落定位基准测试中取得了最先进的结果，优于之前所有基于大语言模型的时序定位方法，并与专用模型相当或更优。

Conclusion: ED-VTG在视频时间定位和段落定位任务中表现出色，显著优于现有基于大语言模型的方法，并在零样本评估场景中保持明显优势。

Abstract: We introduce ED-VTG, a method for fine-grained video temporal grounding
utilizing multi-modal large language models. Our approach harnesses the
capabilities of multimodal LLMs to jointly process text and video, in order to
effectively localize natural language queries in videos through a two-stage
process. Rather than being directly grounded, language queries are initially
transformed into enriched sentences that incorporate missing details and cues
to aid in grounding. In the second stage, these enriched queries are grounded,
using a lightweight decoder, which specializes at predicting accurate
boundaries conditioned on contextualized representations of the enriched
queries. To mitigate noise and reduce the impact of hallucinations, our model
is trained with a multiple-instance-learning objective that dynamically selects
the optimal version of the query for each training sample. We demonstrate
state-of-the-art results across various benchmarks in temporal video grounding
and paragraph grounding settings. Experiments reveal that our method
significantly outperforms all previously proposed LLM-based temporal grounding
approaches and is either superior or comparable to specialized models, while
maintaining a clear advantage against them in zero-shot evaluation scenarios.

</details>


### [101] [Where, Not What: Compelling Video LLMs to Learn Geometric Causality for 3D-Grounding](https://arxiv.org/abs/2510.17034)
*Yutong Zhong*

Main category: cs.CV

TL;DR: W2R2框架通过解耦2D语义和3D空间特征，解决了多模态3D定位中的'2D语义偏差'问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在多模态3D定位中过度依赖2D图像特征，导致'2D语义偏差'，忽视了3D几何输入，导致融合性能不佳。

Method: 提出了一种称为What-Where Representation Re-Forming (W2R2)的训练框架，通过解耦表示学习和针对性抑制捷径来重塑模型的内部空间。2D特征用于语义识别（What），3D特征用于空间定位（Where）。关键组件包括双目标损失函数：Alignment Loss（监督融合预测）和Pseudo-Label Loss（惩罚2D主导的伪输出）。

Result: 在ScanRefer和ScanQA上的实验表明，W2R2在定位精度和鲁棒性方面有显著提升，尤其是在复杂户外场景中。

Conclusion: W2R2框架通过解耦表示学习和针对性抑制捷径，有效解决了多模态3D定位中的'2D语义偏差'问题，显著提升了定位精度和鲁棒性。

Abstract: Multimodal 3D grounding has garnered considerable interest in Vision-Language
Models (VLMs) \cite{yin2025spatial} for advancing spatial reasoning in complex
environments. However, these models suffer from a severe "2D semantic bias"
that arises from over-reliance on 2D image features for coarse localization,
largely disregarding 3D geometric inputs and resulting in suboptimal fusion
performance. In this paper, we propose a novel training framework called
What-Where Representation Re-Forming (W2R2) to tackle this issue via
disentangled representation learning and targeted shortcut suppression. Our
approach fundamentally reshapes the model's internal space by designating 2D
features as semantic beacons for "What" identification and 3D features as
spatial anchors for "Where" localization, enabling precise 3D grounding without
modifying inference architecture. Key components include a dual-objective loss
function with an Alignment Loss that supervises fused predictions using adapted
cross-entropy for multimodal synergy, and a Pseudo-Label Loss that penalizes
overly effective 2D-dominant pseudo-outputs via a margin-based mechanism.
Experiments conducted on ScanRefer and ScanQA demonstrate the effectiveness of
W2R2, with significant gains in localization accuracy and robustness,
particularly in cluttered outdoor scenes.

</details>


### [102] [Conditional Synthetic Live and Spoof Fingerprint Generation](https://arxiv.org/abs/2510.17035)
*Syed Konain Abbas,Sandip Purnapatra,M. G. Sarwar Murshed,Conor Miller-Lynch,Lambert Igene,Soumyabrata Dey,Stephanie Schuckers,Faraz Hussain*

Main category: cs.CV

TL;DR: 本文提出了一种基于StyleGAN和CycleGAN的合成指纹生成方法，解决了数据收集的隐私和成本问题，生成的指纹性能优异且隐私保护良好。


<details>
  <summary>Details</summary>
Motivation: 解决指纹数据集收集的高成本、隐私保护及可访问性问题。

Method: 利用条件StyleGAN2-ADA和StyleGAN3架构生成高分辨率合成活体指纹，并结合CycleGANs将其转换为逼真的假指纹。

Result: StyleGAN3模型的FID低至5，生成的指纹在0.01% FAR下TAR达99.47%；StyleGAN2-ADA模型在相同FAR下TAR为98.67%。

Conclusion: 本文提出的合成指纹生成方法在隐私保护方面表现出色，未发现显著的身份泄露证据，同时生成的指纹在性能指标上表现优异。

Abstract: Large fingerprint datasets, while important for training and evaluation, are
time-consuming and expensive to collect and require strict privacy measures.
Researchers are exploring the use of synthetic fingerprint data to address
these issues. This paper presents a novel approach for generating synthetic
fingerprint images (both spoof and live), addressing concerns related to
privacy, cost, and accessibility in biometric data collection. Our approach
utilizes conditional StyleGAN2-ADA and StyleGAN3 architectures to produce
high-resolution synthetic live fingerprints, conditioned on specific finger
identities (thumb through little finger). Additionally, we employ CycleGANs to
translate these into realistic spoof fingerprints, simulating a variety of
presentation attack materials (e.g., EcoFlex, Play-Doh). These synthetic spoof
fingerprints are crucial for developing robust spoof detection systems. Through
these generative models, we created two synthetic datasets (DB2 and DB3), each
containing 1,500 fingerprint images of all ten fingers with multiple
impressions per finger, and including corresponding spoofs in eight material
types. The results indicate robust performance: our StyleGAN3 model achieves a
Fr\'echet Inception Distance (FID) as low as 5, and the generated fingerprints
achieve a True Accept Rate of 99.47% at a 0.01% False Accept Rate. The
StyleGAN2-ADA model achieved a TAR of 98.67% at the same 0.01% FAR. We assess
fingerprint quality using standard metrics (NFIQ2, MINDTCT), and notably,
matching experiments confirm strong privacy preservation, with no significant
evidence of identity leakage, confirming the strong privacy-preserving
properties of our synthetic datasets.

</details>


### [103] [Click, Predict, Trust: Clinician-in-the-Loop AI Segmentation for Lung Cancer CT-Based Prognosis within the Knowledge-to-Action Framework](https://arxiv.org/abs/2510.17039)
*Mohammad R. Salmanpour,Sonya Falahati,Amir Hossein Pouria,Amin Mousavi,Somayeh Sadat Mehrnia,Morteza Alizadeh,Arman Gorji,Zeinab Farsangi,Alireza Safarian,Mehdi Maghsudi,Carlos Uribe,Arman Rahmim,Ren Yuan*

Main category: cs.CV

TL;DR: 本研究开发了一种临床医生参与的深度学习流程，通过VNet和半监督学习实现了准确、可重复且临床可信的肺癌CT预后分析，为AI在医疗中的实际应用提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 肺癌是癌症死亡的主要原因，CT成像是筛查、预后和治疗的核心。手动分割存在变异性且耗时，而深度学习（DL）虽能自动化但面临临床采纳的障碍。研究旨在通过临床医生参与的DL流程提升可重复性、预后准确性和临床信任。

Method: 研究使用了多中心CT数据（999名患者，12个公共数据集），评估了五种深度学习模型（3D Attention U-Net、ResUNet、VNet、ReconNet、SAM-Med3D），并通过497个PySERA提取的放射组学特征评估分割可重复性。预后建模比较了监督学习（SL）和半监督学习（SSL）在38种降维策略和24种分类器中的表现。

Result: VNet表现最佳（Dice = 0.83, IoU = 0.71），放射组学稳定性最高（平均相关性=0.76，ICC=0.65），在SSL下预测准确性最高（准确率=0.88，F1=0.83）。SSL在所有模型中均优于SL。放射科医生更青睐VNet的瘤周表现和平滑边界，倾向于使用AI生成的初始掩模进行改进而非替换。

Conclusion: 本研究通过整合VNet与半监督学习（SSL）方法，开发了一种准确、可重复且临床可信的基于CT的肺癌预后分析流程，为医生为中心的AI应用提供了可行路径。

Abstract: Lung cancer remains the leading cause of cancer mortality, with CT imaging
central to screening, prognosis, and treatment. Manual segmentation is variable
and time-intensive, while deep learning (DL) offers automation but faces
barriers to clinical adoption. Guided by the Knowledge-to-Action framework,
this study develops a clinician-in-the-loop DL pipeline to enhance
reproducibility, prognostic accuracy, and clinical trust. Multi-center CT data
from 999 patients across 12 public datasets were analyzed using five DL models
(3D Attention U-Net, ResUNet, VNet, ReconNet, SAM-Med3D), benchmarked against
expert contours on whole and click-point cropped images. Segmentation
reproducibility was assessed using 497 PySERA-extracted radiomic features via
Spearman correlation, ICC, Wilcoxon tests, and MANOVA, while prognostic
modeling compared supervised (SL) and semi-supervised learning (SSL) across 38
dimensionality reduction strategies and 24 classifiers. Six physicians
qualitatively evaluated masks across seven domains, including clinical
meaningfulness, boundary quality, prognostic value, trust, and workflow
integration. VNet achieved the best performance (Dice = 0.83, IoU = 0.71),
radiomic stability (mean correlation = 0.76, ICC = 0.65), and predictive
accuracy under SSL (accuracy = 0.88, F1 = 0.83). SSL consistently outperformed
SL across models. Radiologists favored VNet for peritumoral representation and
smoother boundaries, preferring AI-generated initial masks for refinement
rather than replacement. These results demonstrate that integrating VNet with
SSL yields accurate, reproducible, and clinically trusted CT-based lung cancer
prognosis, highlighting a feasible path toward physician-centered AI
translation.

</details>


### [104] [Person Re-Identification via Generalized Class Prototypes](https://arxiv.org/abs/2510.17043)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 本文提出了一种不局限于类别质心的广义选择方法，显著提升了行人重识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在行人重识别中主要依赖类别质心作为表示，但这种方法在检索阶段表现不佳，限制了性能提升。

Method: 提出了一种广义选择方法，该方法不局限于类别质心，而是灵活选择表示，以适应不同应用需求。

Result: 提出的方法在多种重识别嵌入上应用，均显著提升了当前最优结果。

Conclusion: 本文提出了一种广义选择方法，通过不局限于类别质心的表示选择，在准确率和平均精度之间取得平衡，显著提升了行人重识别任务的性能。

Abstract: Advanced feature extraction methods have significantly contributed to
enhancing the task of person re-identification. In addition, modifications to
objective functions have been developed to further improve performance.
Nonetheless, selecting better class representatives is an underexplored area of
research that can also lead to advancements in re-identification performance.
Although past works have experimented with using the centroid of a gallery
image class during training, only a few have investigated alternative
representations during the retrieval stage. In this paper, we demonstrate that
these prior techniques yield suboptimal results in terms of re-identification
metrics. To address the re-identification problem, we propose a generalized
selection method that involves choosing representations that are not limited to
class centroids. Our approach strikes a balance between accuracy and mean
average precision, leading to improvements beyond the state of the art. For
example, the actual number of representations per class can be adjusted to meet
specific application requirements. We apply our methodology on top of multiple
re-identification embeddings, and in all cases it substantially improves upon
contemporary results

</details>


### [105] [Video Reasoning without Training](https://arxiv.org/abs/2510.17045)
*Deepak Sridhar,Kartikeya Bhardwaj,Jeya Pradha Jeyaraj,Nuno Vasconcelos,Ankita Nayak,Harris Teague*

Main category: cs.CV

TL;DR: V-Reason通过熵调节优化LMM推理行为，无需训练即提升视频推理性能与效率。


<details>
  <summary>Details</summary>
Motivation: 传统视频推理方法依赖昂贵的RL和冗长的思维链，计算开销大且控制机制有限。

Method: 通过熵基目标在小型可训练控制器上优化LMM的值缓存，调整模型的微探索和开发行为。

Result: V-Reason在多个视频推理数据集上显著优于基础指令调优模型，平均准确率与RL模型差距缩小至0.6%，同时输出令牌减少58.6%。

Conclusion: 利用熵作为信号调节模型行为，V-Reason方法在无需RL或监督微调的情况下显著提升了视频推理性能，缩小了与RL训练模型的差距，同时大幅提高了效率。

Abstract: Video reasoning using Large Multimodal Models (LMMs) relies on costly
reinforcement learning (RL) and verbose chain-of-thought, resulting in
substantial computational overhead during both training and inference.
Moreover, the mechanisms that control the thinking process in these reasoning
models are very limited. In this paper, using entropy of the model's output as
a signal, we discover that the high-quality models go through a series of
micro-explorations and micro-exploitations which keep the reasoning process
grounded (i.e., avoid excessive randomness while the model is exploring or
thinking through an answer). We further observe that once this "thinking"
process is over, more accurate models demonstrate a better convergence by
reducing the entropy significantly via a final exploitation phase (i.e., a more
certain convergence towards a solution trajectory). We then use these novel,
theoretically-grounded insights to tune the model's behavior directly at
inference, without using any RL or supervised fine-tuning. Specifically, during
inference, our proposed approach called V-Reason (Video-Reason) adapts the
value cache of the LMM via a few optimization steps on a small, trainable
controller using an entropy-based objective, i.e., no supervision from any
dataset or RL is necessary. This tuning improves the model's micro-exploration
and exploitation behavior during inference. Our experiments show that our
proposed method achieves significant improvements over the base
instruction-tuned models across several video reasoning datasets, narrowing the
gap with RL-trained models to within 0.6% average accuracy without any
training, while offering massive efficiency benefits: output tokens are reduced
by 58.6% compared to the RL model.

</details>


### [106] [How Universal Are SAM2 Features?](https://arxiv.org/abs/2510.17051)
*Masoud Khairi Atani,Alon Harell,Hyomin Choi,Runyu Yang,Fabien Racape,Ivan V. Bajic*

Main category: cs.CV

TL;DR: 比较通用与专用视觉模型的特征多用途性，发现专用模型在特定任务上高效但牺牲了语义广度，为特征编码设计提供量化依据。


<details>
  <summary>Details</summary>
Motivation: 探讨通用基础视觉模型与其专用模型之间的权衡，以优化特征编码设计的效率。

Method: 通过比较通用Hiera编码器与专用Segment Anything Model 2（SAM2）的特征多用途性，使用轻量级可训练颈部量化其冻结特征的适应性成本。

Result: 结果显示，SAM2在空间相关任务（如深度估计）上表现优异，但在概念较远的任务（如姿态估计和图像描述）上不如通用模型Hiera，表明其存在语义信息损失。跨颈部分析还发现，SAM2的每一级适应都会造成表示瓶颈。

Conclusion: 该研究揭示了通用基础视觉模型与专用模型在特征编码设计中的权衡，为下游应用的高效特征编码和适应策略提供了定量基础。

Abstract: The trade-off between general-purpose foundation vision models and their
specialized counterparts is critical for efficient feature coding design and is
not yet fully understood. We investigate this trade-off by comparing the
feature versatility of the general-purpose Hiera encoder against the
segmentation-specialized Segment Anything Model 2 (SAM2). Using a lightweight,
trainable neck to probe the adaptability of their frozen features, we quantify
the information-theoretic cost of specialization. Our results reveal that while
SAM2's specialization is highly effective for spatially-related tasks like
depth estimation, it comes at a cost. The specialized SAM2 encoder
underperforms its generalist predecessor, Hiera, on conceptually distant tasks
such as pose estimation and image captioning, demonstrating a measurable loss
of broader semantic information. A novel cross-neck analysis on SAM2 reveals
that each level of adaptation creates a further representational bottleneck.
Our analysis illuminates these trade-offs in feature universality, providing a
quantitative foundation for designing efficient feature coding and adaptation
strategies for diverse downstream applications.

</details>


### [107] [ProDAT: Progressive Density-Aware Tail-Drop for Point Cloud Coding](https://arxiv.org/abs/2510.17068)
*Zhe Luo,Wenjing Jia,Stuart Perry*

Main category: cs.CV

TL;DR: ProDAT是一种密度感知渐进式点云编码方法，通过自适应解码显著提升编码效率，支持多比特率渐进解码。


<details>
  <summary>Details</summary>
Motivation: 三维点云在资源受限环境中的大数据量和带宽限制阻碍了高质量服务的部署，现有学习型方法的固定潜在表示不支持渐进解码。

Method: 通过密度信息作为指导信号，自适应解码潜在特征和坐标，实现单一模型支持多比特率渐进解码。

Result: 实验结果表明，ProDAT在基准数据集上实现了超过28.6%的BD-rate提升（PSNR-D2在SemanticKITTI）和超过18.15%（ShapeNet），优于现有学习型编码技术。

Conclusion: ProDAT提出了一种新颖的密度感知尾丢机制，支持渐进式点云编码，不仅在多个比特率下实现了渐进解码，还显著提升了编码效率。

Abstract: Three-dimensional (3D) point clouds are becoming increasingly vital in
applications such as autonomous driving, augmented reality, and immersive
communication, demanding real-time processing and low latency. However, their
large data volumes and bandwidth constraints hinder the deployment of
high-quality services in resource-limited environments. Progres- sive coding,
which allows for decoding at varying levels of detail, provides an alternative
by allowing initial partial decoding with subsequent refinement. Although
recent learning-based point cloud geometry coding methods have achieved notable
success, their fixed latent representation does not support progressive
decoding. To bridge this gap, we propose ProDAT, a novel density-aware
tail-drop mechanism for progressive point cloud coding. By leveraging density
information as a guidance signal, latent features and coordinates are decoded
adaptively based on their significance, therefore achieving progressive
decoding at multiple bitrates using one single model. Experimental results on
benchmark datasets show that the proposed ProDAT not only enables progressive
coding but also achieves superior coding efficiency compared to
state-of-the-art learning-based coding techniques, with over 28.6% BD-rate
improvement for PSNR- D2 on SemanticKITTI and over 18.15% for ShapeNet

</details>


### [108] [Towards a Generalizable Fusion Architecture for Multimodal Object Detection](https://arxiv.org/abs/2510.17078)
*Jad Berjawi,Yoann Dupas,Christophe C'erin*

Main category: cs.CV

TL;DR: FMCAF是一种新型多模态融合架构，结合频域过滤和交叉注意力，提升RGB和红外输入的检测性能，适用于多种挑战性场景。


<details>
  <summary>Details</summary>
Motivation: 多模态目标检测通过利用多传感器模态的互补线索，在挑战性条件下提高鲁棒性。FMCAF旨在提升RGB和红外（IR）输入的融合效果，以应对不同多模态挑战。

Method: FMCAF结合了频域过滤块（Freq-Filter）以减少冗余频谱特征，以及基于交叉注意力的融合模块（MCAF）以增强模态间特征共享。

Result: 在LLVIP（低光行人检测）和VEDAI（空中车辆检测）上，FMCAF优于传统融合方法（拼接），分别提升+1.1%和+13.9%的mAP@50。

Conclusion: FMCAF作为一种灵活的预处理架构，在多种多模态检测挑战中表现出色，无需特定数据集调优，展现出作为未来检测流程中稳健多模态融合基础的潜力。

Abstract: Multimodal object detection improves robustness in chal- lenging conditions
by leveraging complementary cues from multiple sensor modalities. We introduce
Filtered Multi- Modal Cross Attention Fusion (FMCAF), a preprocess- ing
architecture designed to enhance the fusion of RGB and infrared (IR) inputs.
FMCAF combines a frequency- domain filtering block (Freq-Filter) to suppress
redun- dant spectral features with a cross-attention-based fusion module (MCAF)
to improve intermodal feature sharing. Unlike approaches tailored to specific
datasets, FMCAF aims for generalizability, improving performance across
different multimodal challenges without requiring dataset- specific tuning. On
LLVIP (low-light pedestrian detec- tion) and VEDAI (aerial vehicle detection),
FMCAF outper- forms traditional fusion (concatenation), achieving +13.9% mAP@50
on VEDAI and +1.1% on LLVIP. These results support the potential of FMCAF as a
flexible foundation for robust multimodal fusion in future detection pipelines.

</details>


### [109] [GSPlane: Concise and Accurate Planar Reconstruction via Structured Representation](https://arxiv.org/abs/2510.17095)
*Ruitong Gan,Junran Peng,Yang Liu,Chuanchen Luo,Qing Li,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: GSPlane通过平面先验和动态高斯重新分类器，提升了高斯溅射在平面重建中的几何精度和拓扑结构，适用于场景编辑。


<details>
  <summary>Details</summary>
Motivation: 解决高斯溅射（GS）在重建平面区域时平滑性和精度不足的问题，以支持下游应用中的场景编辑和物理模拟。

Method: GSPlane利用现成的分割和法线预测模型提取平面先验，建立结构化表示，并通过动态高斯重新分类器优化训练过程。此外，利用优化的平面先验细化网格布局。

Result: 实验表明，GSPlane在保持渲染质量的同时，显著提高了提取网格的几何精度，并在多个基准测试中表现优异。

Conclusion: GSPlane通过引入平面先验和动态高斯重新分类器，显著提高了重建场景中平面区域的几何精度和拓扑结构，同时保持了渲染质量。该方法在多个基准测试中表现出色，并展示了结构化平面表示在场景编辑中的潜在应用。

Abstract: Planes are fundamental primitives of 3D sences, especially in man-made
environments such as indoor spaces and urban streets. Representing these planes
in a structured and parameterized format facilitates scene editing and physical
simulations in downstream applications. Recently, Gaussian Splatting (GS) has
demonstrated remarkable effectiveness in the Novel View Synthesis task, with
extensions showing great potential in accurate surface reconstruction. However,
even state-of-the-art GS representations often struggle to reconstruct planar
regions with sufficient smoothness and precision. To address this issue, we
propose GSPlane, which recovers accurate geometry and produces clean and
well-structured mesh connectivity for plane regions in the reconstructed scene.
By leveraging off-the-shelf segmentation and normal prediction models, GSPlane
extracts robust planar priors to establish structured representations for
planar Gaussian coordinates, which help guide the training process by enforcing
geometric consistency. To further enhance training robustness, a Dynamic
Gaussian Re-classifier is introduced to adaptively reclassify planar Gaussians
with persistently high gradients as non-planar, ensuring more reliable
optimization. Furthermore, we utilize the optimized planar priors to refine the
mesh layouts, significantly improving topological structure while reducing the
number of vertices and faces. We also explore applications of the structured
planar representation, which enable decoupling and flexible manipulation of
objects on supportive planes. Extensive experiments demonstrate that, with no
sacrifice in rendering quality, the introduction of planar priors significantly
improves the geometric accuracy of the extracted meshes across various
baselines.

</details>


### [110] [Boosting Fidelity for Pre-Trained-Diffusion-Based Low-Light Image Enhancement via Condition Refinement](https://arxiv.org/abs/2510.17105)
*Xiaogang Xu,Jian Wang,Yunfan Lu,Ruihang Chu,Ruixing Wang,Jiafei Wu,Bei Yu,Liang Lin*

Main category: cs.CV

TL;DR: 提出一种优化策略，通过潜在细化与动态交互，提升预训练扩散模型在低光场景下的内容保真度。


<details>
  <summary>Details</summary>
Motivation: 预训练扩散模型在低层视觉任务中表现出色，但在低光场景下由于信息严重退化，往往牺牲内容保真度以获得更高的感知真实性。

Method: 提出了一种新颖的条件优化策略，包括潜在细化管道和动态交互机制，以增强预训练扩散模型的控制效果。

Result: 实验证明，该方法显著提升了预训练扩散模型的内容保真度，且具有即插即用的特性。

Conclusion: 研究发现，通过引入条件潜在建模和双向交互机制，可以显著提升预训练扩散模型在低光场景下的内容保真度，同时保持感知真实性和美学效果。

Abstract: Diffusion-based methods, leveraging pre-trained large models like Stable
Diffusion via ControlNet, have achieved remarkable performance in several
low-level vision tasks. However, Pre-Trained Diffusion-Based (PTDB) methods
often sacrifice content fidelity to attain higher perceptual realism. This
issue is exacerbated in low-light scenarios, where severely degraded
information caused by the darkness limits effective control. We identify two
primary causes of fidelity loss: the absence of suitable conditional latent
modeling and the lack of bidirectional interaction between the conditional
latent and noisy latent in the diffusion process. To address this, we propose a
novel optimization strategy for conditioning in pre-trained diffusion models,
enhancing fidelity while preserving realism and aesthetics. Our method
introduces a mechanism to recover spatial details lost during VAE encoding,
i.e., a latent refinement pipeline incorporating generative priors.
Additionally, the refined latent condition interacts dynamically with the noisy
latent, leading to improved restoration performance. Our approach is
plug-and-play, seamlessly integrating into existing diffusion networks to
provide more effective control. Extensive experiments demonstrate significant
fidelity improvements in PTDB methods.

</details>


### [111] [Towards Imperceptible Watermarking Via Environment Illumination for Consumer Cameras](https://arxiv.org/abs/2510.17114)
*Hodaka Kawachi,Tomoya Nakamura,Hiroaki Santo,SaiKiran Kumar Tedla,Trevor Dalton Canham,Yasushi Yagi,Michael S. Brown*

Main category: cs.CV

TL;DR: 利用LED光源优化光谱特性，实现对相机不可见但可检测的水印嵌入，支持隐私和验证需求。


<details>
  <summary>Details</summary>
Motivation: 解决传统可见光通信中水印易被察觉的问题，同时满足低帧率下的水印提取需求。

Method: 通过光谱调制而非强度调制，考虑人眼视觉系统的敏感性和相机传感器的光谱响应，优化LED光源的光谱特性。

Result: 在10秒视频中嵌入128位水印，信息传输速率适中，支持隐私保护和内容验证。

Conclusion: 该方法通过优化LED光源的光谱特性，实现了对消费者相机不可见但高效检测的水印嵌入，支持隐私保护和内容验证。

Abstract: This paper introduces a method for using LED-based environmental lighting to
produce visually imperceptible watermarks for consumer cameras. Our approach
optimizes an LED light source's spectral profile to be minimally visible to the
human eye while remaining highly detectable by typical consumer cameras. The
method jointly considers the human visual system's sensitivity to visible
spectra, modern consumer camera sensors' spectral sensitivity, and narrowband
LEDs' ability to generate broadband spectra perceived as "white light"
(specifically, D65 illumination). To ensure imperceptibility, we employ
spectral modulation rather than intensity modulation. Unlike conventional
visible light communication, our approach enables watermark extraction at
standard low frame rates (30-60 fps). While the information transfer rate is
modest-embedding 128 bits within a 10-second video clip-this capacity is
sufficient for essential metadata supporting privacy protection and content
verification.

</details>


### [112] [GOOD: Training-Free Guided Diffusion Sampling for Out-of-Distribution Detection](https://arxiv.org/abs/2510.17131)
*Xin Gao,Jiyao Liu,Guanghao Li,Yueming Lyu,Jianxiong Gao,Weichen Yu,Ningsheng Xu,Liang Wang,Caifeng Shan,Ziwei Liu,Chenyang Si*

Main category: cs.CV

TL;DR: GOOD框架通过双层次引导设计，提升OOD样本生成的多样性和可控性，显著增强OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖文本条件嵌入的扰动，导致语义不稳定和多样性不足，限制了OOD检测的泛化能力。

Method: GOOD框架采用图像级和特征级双层次引导：（1）图像级引导基于梯度降低输入可能性；（2）特征级引导基于k-NN距离促进特征稀疏区域采样。

Result: GOOD生成的样本显著提升了OOD检测性能，定量和定性分析均验证了其有效性。

Conclusion: GOOD框架通过双层次引导设计，显著提升了OOD样本生成的多样性和可控性，进而增强了OOD检测性能。

Abstract: Recent advancements have explored text-to-image diffusion models for
synthesizing out-of-distribution (OOD) samples, substantially enhancing the
performance of OOD detection. However, existing approaches typically rely on
perturbing text-conditioned embeddings, resulting in semantic instability and
insufficient shift diversity, which limit generalization to realistic OOD. To
address these challenges, we propose GOOD, a novel and flexible framework that
directly guides diffusion sampling trajectories towards OOD regions using
off-the-shelf in-distribution (ID) classifiers. GOOD incorporates dual-level
guidance: (1) Image-level guidance based on the gradient of log partition to
reduce input likelihood, drives samples toward low-density regions in pixel
space. (2) Feature-level guidance, derived from k-NN distance in the
classifier's latent space, promotes sampling in feature-sparse regions. Hence,
this dual-guidance design enables more controllable and diverse OOD sample
generation. Additionally, we introduce a unified OOD score that adaptively
combines image and feature discrepancies, enhancing detection robustness. We
perform thorough quantitative and qualitative analyses to evaluate the
effectiveness of GOOD, demonstrating that training with samples generated by
GOOD can notably enhance OOD detection performance.

</details>


### [113] [KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object Shape Reconstruction and Generation](https://arxiv.org/abs/2510.17137)
*WenBo Xu,Liu Liu,Li Zhang,Ran Zhang,Hao Wu,Dan Guo,Meng Wang*

Main category: cs.CV

TL;DR: KineDiff3D是一种基于运动学感知扩散的统一框架，用于从单视图输入重建铰接对象形状和生成，通过KA-VAE编码和条件扩散模型实现，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 铰接对象（如笔记本电脑和抽屉）因其多部件几何和可变关节配置在不同状态下引入结构多样性，对3D重建和姿态估计提出了重大挑战。

Method: 首先通过新颖的Kinematic-Aware VAE（KA-VAE）将完整几何（SDFs）、关节角度和部件分割编码到结构化潜在空间中。随后，使用两个条件扩散模型：一个用于回归全局姿态（SE(3)）和关节参数，另一个用于从部分观察生成运动学感知潜在代码。最后，通过Chamfer距离最小化双向优化重建精度和运动学参数，同时保持铰接约束。

Result: 实验结果表明，KineDiff3D在合成、半合成和真实数据集上能有效重建铰接对象并估计其运动学属性。

Conclusion: KineDiff3D框架在合成、半合成和真实数据集上的实验证明了其在准确重建铰接对象和估计其运动学属性方面的有效性。

Abstract: Articulated objects, such as laptops and drawers, exhibit significant
challenges for 3D reconstruction and pose estimation due to their multi-part
geometries and variable joint configurations, which introduce structural
diversity across different states. To address these challenges, we propose
KineDiff3D: Kinematic-Aware Diffusion for Category-Level Articulated Object
Shape Reconstruction and Generation, a unified framework for reconstructing
diverse articulated instances and pose estimation from single view input.
Specifically, we first encode complete geometry (SDFs), joint angles, and part
segmentation into a structured latent space via a novel Kinematic-Aware VAE
(KA-VAE). In addition, we employ two conditional diffusion models: one for
regressing global pose (SE(3)) and joint parameters, and another for generating
the kinematic-aware latent code from partial observations. Finally, we produce
an iterative optimization module that bidirectionally refines reconstruction
accuracy and kinematic parameters via Chamfer-distance minimization while
preserving articulation constraints. Experimental results on synthetic,
semi-synthetic, and real-world datasets demonstrate the effectiveness of our
approach in accurately reconstructing articulated objects and estimating their
kinematic properties.

</details>


### [114] [GACO-CAD: Geometry-Augmented and Conciseness-Optimized CAD Model Generation from Single Image](https://arxiv.org/abs/2510.17157)
*Yinghui Wang,Xinyu Zhang,Peng Du*

Main category: cs.CV

TL;DR: GACO-CAD通过两阶段后训练框架，结合几何先验和强化学习，显著提升了从单张图像生成可编辑CAD模型的准确性和简洁性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）在从2D图像准确推断3D几何方面的局限性，以降低工业概念设计的门槛。

Method: 引入GACO-CAD，一种新颖的两阶段后训练框架，包括监督微调和强化学习两个阶段。监督微调阶段利用深度和表面法线图作为密集几何先验，强化学习阶段引入组长度奖励以促进生成更简洁的建模序列。

Result: GACO-CAD在相同MLLM骨干下实现了最先进的性能，在代码有效性、几何准确性和建模简洁性方面均优于现有方法。

Conclusion: GACO-CAD在DeepCAD和Fusion360数据集上表现出色，在代码有效性、几何准确性和建模简洁性方面均优于现有方法。

Abstract: Generating editable, parametric CAD models from a single image holds great
potential to lower the barriers of industrial concept design. However, current
multi-modal large language models (MLLMs) still struggle with accurately
inferring 3D geometry from 2D images due to limited spatial reasoning
capabilities. We address this limitation by introducing GACO-CAD, a novel
two-stage post-training framework. It is designed to achieve a joint objective:
simultaneously improving the geometric accuracy of the generated CAD models and
encouraging the use of more concise modeling procedures. First, during
supervised fine-tuning, we leverage depth and surface normal maps as dense
geometric priors, combining them with the RGB image to form a multi-channel
input. In the context of single-view reconstruction, these priors provide
complementary spatial cues that help the MLLM more reliably recover 3D geometry
from 2D observations. Second, during reinforcement learning, we introduce a
group length reward that, while preserving high geometric fidelity, promotes
the generation of more compact and less redundant parametric modeling
sequences. A simple dynamic weighting strategy is adopted to stabilize
training. Experiments on the DeepCAD and Fusion360 datasets show that GACO-CAD
achieves state-of-the-art performance under the same MLLM backbone,
consistently outperforming existing methods in terms of code validity,
geometric accuracy, and modeling conciseness.

</details>


### [115] [Investigating Adversarial Robustness against Preprocessing used in Blackbox Face Recognition](https://arxiv.org/abs/2510.17169)
*Roland Croft,Brian Du,Darcy Joseph,Sharath Kumar*

Main category: cs.CV

TL;DR: 研究探讨了人脸识别系统中预处理对对抗攻击的影响，发现预处理选择显著影响攻击成功率，并提出了一种预处理不变方法以提高攻击可转移性。


<details>
  <summary>Details</summary>
Motivation: 人脸预处理是人脸识别系统的关键组成部分，但在黑盒设置中往往被忽视。研究旨在探讨预处理对对抗攻击成功率的影啊。

Method: 研究调查了几种现成的最先进对抗攻击在人脸识别中的可转移性，特别是针对黑盒设置中使用的不同预处理技术。提出了一个使用输入变换的预处理不变方法。

Result: 研究发现，人脸检测模型的选择可使攻击成功率降低高达78%，而下采样中的插值方法选择影响相对较小。预处理不变方法提高了所研究攻击的可转移性高达27%。

Conclusion: 研究强调了预处理在人脸识别系统中的重要性，并提出了考虑预处理以改善面部对抗样本的对抗泛化的必要性。

Abstract: Face Recognition (FR) models have been shown to be vulnerable to adversarial
examples that subtly alter benign facial images, exposing blind spots in these
systems, as well as protecting user privacy. End-to-end FR systems first obtain
preprocessed faces from diverse facial imagery prior to computing the
similarity of the deep feature embeddings. Whilst face preprocessing is a
critical component of FR systems, and hence adversarial attacks against them,
we observe that this preprocessing is often overlooked in blackbox settings.
Our study seeks to investigate the transferability of several out-of-the-box
state-of-the-art adversarial attacks against FR when applied against different
preprocessing techniques used in a blackbox setting. We observe that the choice
of face detection model can degrade the attack success rate by up to 78%,
whereas choice of interpolation method during downsampling has relatively
minimal impacts. Furthermore, we find that the requirement for facial
preprocessing even degrades attack strength in a whitebox setting, due to the
unintended interaction of produced noise vectors against face detection models.
Based on these findings, we propose a preprocessing-invariant method using
input transformations that improves the transferability of the studied attacks
by up to 27%. Our findings highlight the importance of preprocessing in FR
systems, and the need for its consideration towards improving the adversarial
generalisation of facial adversarial examples.

</details>


### [116] [Generation then Reconstruction: Accelerating Masked Autoregressive Models via Two-Stage Sampling](https://arxiv.org/abs/2510.17171)
*Feihong Yan,Peiru Wang,Yao Zhu,Kaiyu Pang,Qingyan Wei,Huiqi Li,Linfeng Zhang*

Main category: cs.CV

TL;DR: GtR和FTS方法通过分层采样和频率加权选择，显著加速MAR模型的生成过程，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决MAR模型在并行生成时因空间相关视觉令牌建模复杂而受限的问题，以提升生成效率。

Method: 提出了GtR（Generation then Reconstruction）和FTS（Frequency-Weighted Token Selection）两种方法，分别通过分层采样和频率加权选择来优化生成过程。

Result: 在ImageNet类条件和文本到图像生成任务中实现了3.72倍加速，且生成质量（如FID和IS）与原模型相当。

Conclusion: GtR和FTS的引入显著提升了MAR模型的生成效率，同时保持了生成质量，实验证明了其在多种任务和模型规模下的优越性。

Abstract: Masked Autoregressive (MAR) models promise better efficiency in visual
generation than autoregressive (AR) models for the ability of parallel
generation, yet their acceleration potential remains constrained by the
modeling complexity of spatially correlated visual tokens in a single step. To
address this limitation, we introduce Generation then Reconstruction (GtR), a
training-free hierarchical sampling strategy that decomposes generation into
two stages: structure generation establishing global semantic scaffolding,
followed by detail reconstruction efficiently completing remaining tokens.
Assuming that it is more difficult to create an image from scratch than to
complement images based on a basic image framework, GtR is designed to achieve
acceleration by computing the reconstruction stage quickly while maintaining
the generation quality by computing the generation stage slowly. Moreover,
observing that tokens on the details of an image often carry more semantic
information than tokens in the salient regions, we further propose
Frequency-Weighted Token Selection (FTS) to offer more computation budget to
tokens on image details, which are localized based on the energy of high
frequency information. Extensive experiments on ImageNet class-conditional and
text-to-image generation demonstrate 3.72x speedup on MAR-H while maintaining
comparable quality (e.g., FID: 1.59, IS: 304.4 vs. original 1.59, 299.1),
substantially outperforming existing acceleration methods across various model
scales and generation tasks. Our codes will be released in
https://github.com/feihongyan1/GtR.

</details>


### [117] [Benchmarking Out-of-Distribution Detection for Plankton Recognition: A Systematic Evaluation of Advanced Methods in Marine Ecological Monitoring](https://arxiv.org/abs/2510.17179)
*Yingzi Han,Jiakai He,Chuanlong Xie,Jianping Li*

Main category: cs.CV

TL;DR: 本文系统评估了22种OoD检测方法在浮游生物识别中的表现，ViM在Far-OoD场景中表现最佳，为未来研究提供了基准。


<details>
  <summary>Details</summary>
Motivation: 浮游生物识别模型在实际部署中因训练与测试数据间的分布偏移（OoD）面临挑战，需系统整合最新计算机视觉进展并建立统一评估基准。

Method: 基于DYB-PlanktonNet数据集，设计了一系列模拟不同分布偏移场景的OoD基准，并系统评估了22种OoD检测方法。

Result: ViM方法在构建的基准测试中显著优于其他方法，尤其在Far-OoD场景中关键指标有大幅提升。

Conclusion: 本研究首次在浮游生物识别领域进行了大规模、系统性的OoD检测方法评估与分析，为未来研究奠定了坚实基础。ViM方法在Far-OoD场景中表现尤为突出。

Abstract: Automated plankton recognition models face significant challenges during
real-world deployment due to distribution shifts (Out-of-Distribution, OoD)
between training and test data. This stems from plankton's complex
morphologies, vast species diversity, and the continuous discovery of novel
species, which leads to unpredictable errors during inference. Despite rapid
advancements in OoD detection methods in recent years, the field of plankton
recognition still lacks a systematic integration of the latest computer vision
developments and a unified benchmark for large-scale evaluation. To address
this, this paper meticulously designed a series of OoD benchmarks simulating
various distribution shift scenarios based on the DYB-PlanktonNet dataset
\cite{875n-f104-21}, and systematically evaluated twenty-two OoD detection
methods. Extensive experimental results demonstrate that the ViM
\cite{wang2022vim} method significantly outperforms other approaches in our
constructed benchmarks, particularly excelling in Far-OoD scenarios with
substantial improvements in key metrics. This comprehensive evaluation not only
provides a reliable reference for algorithm selection in automated plankton
recognition but also lays a solid foundation for future research in plankton
OoD detection. To our knowledge, this study marks the first large-scale,
systematic evaluation and analysis of Out-of-Distribution data detection
methods in plankton recognition. Code is available at
https://github.com/BlackJack0083/PlanktonOoD.

</details>


### [118] [Capturing Head Avatar with Hand Contacts from a Monocular Video](https://arxiv.org/abs/2510.17181)
*Haonan He,Yufeng Zheng,Jie Song*

Main category: cs.CV

TL;DR: 本文提出了一种联合学习头部虚拟形象和手-脸互动变形的框架，通过深度顺序损失、PCA基础和接触损失优化，显著提升了效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多仅关注面部区域，忽略了手-脸互动传达的认知状态，如思考。

Method: 结合深度顺序损失与接触正则化进行姿态跟踪，学习手引起的面部变形的PCA基础，并引入接触损失以减少互穿伪影。

Result: 在RGB(D)视频和合成数据集上的评估表明，该方法在面部外观和变形几何上优于现有表面重建方法。

Conclusion: 本文提出的框架能够联合学习详细的头部虚拟形象和手-脸互动引起的非刚性变形，显著提升了外观和变形几何的准确性。

Abstract: Photorealistic 3D head avatars are vital for telepresence, gaming, and VR.
However, most methods focus solely on facial regions, ignoring natural
hand-face interactions, such as a hand resting on the chin or fingers gently
touching the cheek, which convey cognitive states like pondering. In this work,
we present a novel framework that jointly learns detailed head avatars and the
non-rigid deformations induced by hand-face interactions.
  There are two principal challenges in this task. First, naively tracking hand
and face separately fails to capture their relative poses. To overcome this, we
propose to combine depth order loss with contact regularization during pose
tracking, ensuring correct spatial relationships between the face and hand.
Second, no publicly available priors exist for hand-induced deformations,
making them non-trivial to learn from monocular videos. To address this, we
learn a PCA basis specific to hand-induced facial deformations from a face-hand
interaction dataset. This reduces the problem to estimating a compact set of
PCA parameters rather than a full spatial deformation field. Furthermore,
inspired by physics-based simulation, we incorporate a contact loss that
provides additional supervision, significantly reducing interpenetration
artifacts and enhancing the physical plausibility of the results.
  We evaluate our approach on RGB(D) videos captured by an iPhone.
Additionally, to better evaluate the reconstructed geometry, we construct a
synthetic dataset of avatars with various types of hand interactions. We show
that our method can capture better appearance and more accurate deforming
geometry of the face than SOTA surface reconstruction methods.

</details>


### [119] [HIDISC: A Hyperbolic Framework for Domain Generalization with Generalized Category Discovery](https://arxiv.org/abs/2510.17188)
*Vaibhav Rathore,Divyam Gupta,Biplab Banerjee*

Main category: cs.CV

TL;DR: HIDISC是一个双曲表示学习框架，通过GPT引导的扩散和Tangent CutMix实现域和类别级泛化，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现（GCD）方法通常假设训练时标记和未标记数据来自同一域，限制了在涉及分布变化的开放世界场景中的适用性。DG-GCD要求模型在训练时不访问目标域数据的情况下泛化到包含新类别的未见域，现有方法DG2CD-Net计算成本高且存在错误累积。

Method: HIDISC采用双曲表示学习框架，通过GPT引导的扩散增强源域，引入Tangent CutMix进行曲率感知插值，并结合统一的损失函数（包括惩罚Busemann对齐、混合双曲对比正则化和自适应离群排斥）来促进紧凑、语义结构化的嵌入。

Result: HIDISC在PACS、Office-Home和DomainNet数据集上表现优异，超越了现有基线方法。

Conclusion: HIDISC框架在PACS、Office-Home和DomainNet数据集上实现了最先进的结果，一致优于现有的欧几里得和双曲（DG）-GCD基线。

Abstract: Generalized Category Discovery (GCD) aims to classify test-time samples into
either seen categories** -- available during training -- or novel ones, without
relying on label supervision. Most existing GCD methods assume simultaneous
access to labeled and unlabeled data during training and arising from the same
domain, limiting applicability in open-world scenarios involving distribution
shifts. Domain Generalization with GCD (DG-GCD) lifts this constraint by
requiring models to generalize to unseen domains containing novel categories,
without accessing targetdomain data during training. The only prior DG-GCD
method, DG2CD-Net, relies on episodic training with multiple synthetic domains
and task vector aggregation, incurring high computational cost and error
accumulation. We propose HIDISC, a hyperbolic representation learning framework
that achieves domain and category-level generalization without episodic
simulation. To expose the model to minimal but diverse domain variations, we
augment the source domain using GPT-guided diffusion, avoiding overfitting
while maintaining efficiency. To structure the representation space, we
introduce Tangent CutMix, a curvature-aware interpolation that synthesizes
pseudo-novel samples in tangent space, preserving manifold consistency. A
unified loss -- combining penalized Busemann alignment, hybrid hyperbolic
contrastive regularization, and adaptive outlier repulsion -- **facilitates
compact, semantically structured embeddings. A learnable curvature parameter
further adapts the geometry to dataset complexity. HIDISC achieves
state-of-the-art results on PACS , Office-Home , and DomainNet, consistently
outperforming the existing Euclidean and hyperbolic (DG)-GCD baselines.

</details>


### [120] [ZSPAPrune: Zero-Shot Prompt-Aware Token Pruning for Vision-Language Models](https://arxiv.org/abs/2510.17197)
*Pu Zhang,Yuwei Li,Xingyuan Xian,Guoming Tang*

Main category: cs.CV

TL;DR: 提出提示感知的视觉令牌剪枝方法，平衡任务相关性与多样性，显著降低成本且性能优异。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型处理能力的提升，输入规模的增加导致视觉令牌冗余和推理成本激增，现有剪枝方法忽视文本提示的引导，无法有效优先考虑任务相关性。

Method: 采用分层方法，首先选择一组与任务相关的核心视觉令牌，然后补充多样性令牌以保留更广泛的上下文。

Result: 在多个模型和基准测试中，该方法在剪枝高达90%令牌的情况下，性能匹配或超越现有技术，同时显著减少GPU内存占用和推理延迟。

Conclusion: 本文提出了一种新颖的零样本方法，通过引入提示感知视角，在视觉令牌剪枝中平衡任务相关性和信息多样性，显著降低了推理成本，同时保持了或超越了现有方法的性能。

Abstract: As the capabilities of Vision-Language Models (VLMs) advance, they can
process increasingly large inputs, which, unlike in LLMs, generates significant
visual token redundancy and leads to prohibitive inference costs. While many
methods aim to reduce these costs by pruning visual tokens, existing
approaches, whether based on attention or diversity, typically neglect the
guidance of the text prompt and thus fail to prioritize task relevance. In this
work, we propose a novel, zero-shot method that reframes the problem by
introducing a prompt-aware perspective, explicitly modeling visual token
pruning as a balance between task relevance and information diversity. Our
hierarchical approach first selects a core set of task-relevant visual tokens
and then supplements them with diversity tokens to preserve broader context.
Experiments across multiple models and benchmarks show that our method achieves
performance that matches or surpasses the state-of-the-art with only minimal
accuracy loss, even when pruning up to 90\% of the tokens. Furthermore, these
gains are accompanied by significant reductions in GPU memory footprint and
inference latency.

</details>


### [121] [From Pixels to People: Satellite-Based Mapping and Quantification of Riverbank Erosion and Lost Villages in Bangladesh](https://arxiv.org/abs/2510.17198)
*M Saifuzzaman Rafat,Mohd Ruhul Ameen,Akif Islam,Abu Saleh Musa Miah,Jungpil Shin*

Main category: cs.CV

TL;DR: 研究利用SAM模型和首个标注数据集，开发了一个高精度的河岸侵蚀监测工具，为孟加拉国的灾害管理提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 孟加拉国的大河流既是商业和生计的动脉，也是无情的破坏者。每年，它们吞噬整个村庄和大片农田，导致数千家庭流离失所。传统的人工分析方法难以有效跟踪这一缓慢的灾难。

Method: 研究首先使用简单的颜色通道分析进行粗略的土地和水域分割，然后微调Segment Anything Model（SAM）的掩码解码器，以识别河岸侵蚀的细微特征。

Result: 开发出的模型在河岸侵蚀识别上表现出色，平均IoU为86.30%，Dice得分为92.60%，显著优于传统方法和现成的深度学习模型。

Conclusion: 本研究通过开发专门的人工智能模型和首个标注数据集，为孟加拉国河流侵蚀监测提供了强大的新工具，帮助政策制定者和灾害管理机构更好地预测和保护脆弱社区。

Abstract: The great rivers of Bangladesh, arteries of commerce and sustenance, are also
agents of relentless destruction. Each year, they swallow whole villages and
vast tracts of farmland, erasing communities from the map and displacing
thousands of families. To track this slow-motion catastrophe has, until now,
been a Herculean task for human analysts. Here we show how a powerful
general-purpose vision model, the Segment Anything Model (SAM), can be adapted
to this task with remarkable precision. To do this, we assembled a new dataset
- a digital chronicle of loss compiled from historical Google Earth imagery of
Bangladesh's most vulnerable regions, including Mokterer Char Union, Kedarpur
Union, Balchipara village, and Chowhali Upazila, from 2003 to 2025. Crucially,
this dataset is the first to include manually annotated data on the settlements
that have vanished beneath the water. Our method first uses a simple
color-channel analysis to provide a rough segmentation of land and water, and
then fine-tunes SAM's mask decoder to recognize the subtle signatures of
riverbank erosion. The resulting model demonstrates a keen eye for this
destructive process, achieving a mean Intersection over Union of 86.30% and a
Dice score of 92.60% - a performance that significantly surpasses traditional
methods and off-the-shelf deep learning models. This work delivers three key
contributions: the first annotated dataset of disappeared settlements in
Bangladesh due to river erosion; a specialized AI model fine-tuned for this
critical task; and a method for quantifying land loss with compelling visual
evidence. Together, these tools provide a powerful new lens through which
policymakers and disaster management agencies can monitor erosion, anticipate
its trajectory, and ultimately protect the vulnerable communities in its path.

</details>


### [122] [Round Outcome Prediction in VALORANT Using Tactical Features from Video Analysis](https://arxiv.org/abs/2510.17199)
*Nirai Hayakawa,Kazumasa Shimari,Kazuma Yamasaki,Hirotatsu Hoshikawa,Rikuto Tsuchida,Kenichi Matsumoto*

Main category: cs.CV

TL;DR: 通过分析VALORANT比赛录像的小地图信息提取战术特征，构建的预测模型在回合中期阶段表现优异，准确率达81%。


<details>
  <summary>Details</summary>
Motivation: 现有研究多基于比赛日志数据和统计信息，而VALORANT作为需要复杂策略的FPS游戏，需要更深入的战术分析。

Method: 基于视频识别模型TimeSformer，通过分析小地图信息提取战术特征（如角色位置信息和其他游戏内事件），构建回合结果预测模型。

Result: 在增强战术事件标签的数据集上训练的模型预测准确率约为81%，显著优于仅使用小地图信息的模型。

Conclusion: 利用比赛录像中的战术特征对VALORANT回合结果预测非常有效，尤其是在回合中期阶段。

Abstract: Recently, research on predicting match outcomes in esports has been actively
conducted, but much of it is based on match log data and statistical
information. This research targets the FPS game VALORANT, which requires
complex strategies, and aims to build a round outcome prediction model by
analyzing minimap information in match footage. Specifically, based on the
video recognition model TimeSformer, we attempt to improve prediction accuracy
by incorporating detailed tactical features extracted from minimap information,
such as character position information and other in-game events. This paper
reports preliminary results showing that a model trained on a dataset augmented
with such tactical event labels achieved approximately 81% prediction accuracy,
especially from the middle phases of a round onward, significantly
outperforming a model trained on a dataset with the minimap information itself.
This suggests that leveraging tactical features from match footage is highly
effective for predicting round outcomes in VALORANT.

</details>


### [123] [EndoCIL: A Class-Incremental Learning Framework for Endoscopic Image Classification](https://arxiv.org/abs/2510.17200)
*Bingrong Liu,Jun Shi,Yushan Zheng*

Main category: cs.CV

TL;DR: EndoCIL是一个专为内窥镜图像诊断设计的类增量学习框架，通过分布对齐、类平衡和梯度校准，有效缓解灾难性遗忘并提升性能。


<details>
  <summary>Details</summary>
Motivation: 内窥镜图像分析的类增量学习（CIL）在现实临床应用中至关重要，但现有基于重放的CIL方法由于严重的域差异和类不平衡问题，无法有效缓解灾难性遗忘。

Method: EndoCIL框架包含三个关键组件：基于最大均值差异的重放（MDBR）、先验正则化类平衡损失（PRCBL）和全连接梯度校准（CFG）。

Result: 在四个公共内窥镜数据集上的广泛实验表明，EndoCIL在不同缓冲区大小和评估指标上通常优于最先进的CIL方法。

Conclusion: EndoCIL框架通过结合MDBR、PRCBL和CFG三个关键组件，有效平衡了稳定性和可塑性，在终身内窥镜诊断中展现出临床可扩展性和部署潜力。

Abstract: Class-incremental learning (CIL) for endoscopic image analysis is crucial for
real-world clinical applications, where diagnostic models should continuously
adapt to evolving clinical data while retaining performance on previously
learned ones. However, existing replay-based CIL methods fail to effectively
mitigate catastrophic forgetting due to severe domain discrepancies and class
imbalance inherent in endoscopic imaging. To tackle these challenges, we
propose EndoCIL, a novel and unified CIL framework specifically tailored for
endoscopic image diagnosis. EndoCIL incorporates three key components: Maximum
Mean Discrepancy Based Replay (MDBR), employing a distribution-aligned greedy
strategy to select diverse and representative exemplars, Prior Regularized
Class Balanced Loss (PRCBL), designed to alleviate both inter-phase and
intra-phase class imbalance by integrating prior class distributions and
balance weights into the loss function, and Calibration of Fully-Connected
Gradients (CFG), which adjusts the classifier gradients to mitigate bias toward
new classes. Extensive experiments conducted on four public endoscopic datasets
demonstrate that EndoCIL generally outperforms state-of-the-art CIL methods
across varying buffer sizes and evaluation metrics. The proposed framework
effectively balances stability and plasticity in lifelong endoscopic diagnosis,
showing promising potential for clinical scalability and deployment.

</details>


### [124] [Optimizing DINOv2 with Registers for Face Anti-Spoofing](https://arxiv.org/abs/2510.17201)
*Mika Feng,Pierre Gallin-Martel,Koichi Ito,Takafumi Aoki*

Main category: cs.CV

TL;DR: 提出基于DINOv2的欺骗攻击检测方法，通过注意力机制聚焦细微特征，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 为防止恶意攻击者利用照片绕过人脸识别系统，需在识别前检测欺骗攻击。

Method: 采用DINOv2模型结合寄存器提取特征，并通过注意力机制聚焦关键细微特征。

Result: 在ICCV2025和SiW数据集上的实验验证了方法的有效性。

Conclusion: 本文提出了一种基于DINOv2的欺骗攻击检测方法，通过提取可泛化特征并抑制注意力机制中的扰动，有效区分真实与伪造人脸图像。实验证明该方法在多个数据集上表现优异。

Abstract: Face recognition systems are designed to be robust against variations in head
pose, illumination, and image blur during capture. However, malicious actors
can exploit these systems by presenting a face photo of a registered user,
potentially bypassing the authentication process. Such spoofing attacks must be
detected prior to face recognition. In this paper, we propose a DINOv2-based
spoofing attack detection method to discern minute differences between live and
spoofed face images. Specifically, we employ DINOv2 with registers to extract
generalizable features and to suppress perturbations in the attention
mechanism, which enables focused attention on essential and minute features. We
demonstrate the effectiveness of the proposed method through experiments
conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop:
Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.

</details>


### [125] [$\mathcal{V}isi\mathcal{P}runer$: Decoding Discontinuous Cross-Modal Dynamics for Efficient Multimodal LLMs](https://arxiv.org/abs/2510.17205)
*Yingqi Fan,Anhao Zhao,Jinlan Fu,Junlong Tong,Hui Su,Yijie Pan,Wei Zhang,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 研究揭示了MLLMs处理多模态信息的三阶段过程，并提出了高效的剪枝框架VisiPruner，显著减少计算开销。


<details>
  <summary>Details</summary>
Motivation: MLLMs在视觉语言任务中表现出色，但计算开销大，现有方法缺乏对MLLMs如何处理和融合多模态信息的深入理解。

Method: 通过系统分析揭示了MLLMs中的三阶段跨模态交互过程，并基于此提出了VisiPruner框架。

Result: VisiPruner在LLaVA-v1.5 7B上减少了99%的视觉相关注意力计算和53.9%的FLOPs，性能优于现有方法。

Conclusion: VisiPruner是一种无需训练的剪枝框架，显著减少了MLLMs中的计算开销，并在多种MLLMs上表现出色。

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance
across vision-language tasks, but suffer from significant computational
overhead due to the quadratic growth of attention computations with the number
of multimodal tokens. Though efforts have been made to prune tokens in MLLMs,
\textit{they lack a fundamental understanding of how MLLMs process and fuse
multimodal information.} Through systematic analysis, we uncover a
\textbf{three-stage} cross-modal interaction process: (1) Shallow layers
recognize task intent, with visual tokens acting as passive attention sinks;
(2) Cross-modal fusion occurs abruptly in middle layers, driven by a few
critical visual tokens; (3) Deep layers discard vision tokens, focusing solely
on linguistic refinement. Based on these findings, we propose
\emph{VisiPruner}, a training-free pruning framework that reduces up to 99\% of
vision-related attention computations and 53.9\% of FLOPs on LLaVA-v1.5 7B. It
significantly outperforms existing token pruning methods and generalizes across
diverse MLLMs. Beyond pruning, our insights further provide actionable
guidelines for training efficient MLLMs by aligning model architecture with its
intrinsic layer-wise processing dynamics. Our code is available at:
https://github.com/EIT-NLP/VisiPruner.

</details>


### [126] [When One Moment Isn't Enough: Multi-Moment Retrieval with Cross-Moment Interactions](https://arxiv.org/abs/2510.17218)
*Zhuo Cao,Heming Du,Bingqing Zhang,Xin Yu,Xue Li,Sen Wang*

Main category: cs.CV

TL;DR: 论文提出QV-M^2数据集和FlashMMR框架，填补多时刻检索的空白，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有单时刻检索方法无法满足实际应用中多时刻检索的需求，因此需要新的数据集和方法来填补这一空白。

Method: 提出了一个名为FlashMMR的框架，包含多时刻后验证模块，通过约束时间调整和验证模块优化候选片段。

Result: 在QV-M^2数据集上，FlashMMR相比现有最佳方法在G-mAP、mAP@3+tgt和mR@3上分别提升了3.00%、2.70%和2.56%。

Conclusion: 提出的QV-M^2数据集和FlashMMR框架为视频时间定位研究提供了有效基准和强基线，显著提升了多时刻检索的性能。

Abstract: Existing Moment retrieval (MR) methods focus on Single-Moment Retrieval
(SMR). However, one query can correspond to multiple relevant moments in
real-world applications. This makes the existing datasets and methods
insufficient for video temporal grounding. By revisiting the gap between
current MR tasks and real-world applications, we introduce a high-quality
datasets called QVHighlights Multi-Moment Dataset (QV-M$^2$), along with new
evaluation metrics tailored for multi-moment retrieval (MMR). QV-M$^2$ consists
of 2,212 annotations covering 6,384 video segments. Building on existing
efforts in MMR, we propose a framework called FlashMMR. Specifically, we
propose a Multi-moment Post-verification module to refine the moment
boundaries. We introduce constrained temporal adjustment and subsequently
leverage a verification module to re-evaluate the candidate segments. Through
this sophisticated filtering pipeline, low-confidence proposals are pruned, and
robust multi-moment alignment is achieved. We retrain and evaluate 6 existing
MR methods on QV-M$^2$ and QVHighlights under both SMR and MMR settings.
Results show that QV-M$^2$ serves as an effective benchmark for training and
evaluating MMR models, while FlashMMR provides a strong baseline. Specifically,
on QV-M$^2$, it achieves improvements over prior SOTA method by 3.00% on G-mAP,
2.70% on mAP@3+tgt, and 2.56% on mR@3. The proposed benchmark and method
establish a foundation for advancing research in more realistic and challenging
video temporal grounding scenarios. Code is released at
https://github.com/Zhuo-Cao/QV-M2.

</details>


### [127] [Fair and Interpretable Deepfake Detection in Videos](https://arxiv.org/abs/2510.17264)
*Akihito Yoshii,Ryosuke Sonoda,Ramya Srinivasan*

Main category: cs.CV

TL;DR: 提出公平感知深度伪造检测框架，结合时序特征和数据增强，显著提升公平性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法存在偏见、缺乏透明度且无法捕捉时序信息，导致跨人口统计群体的决策偏颇和结果不可靠。

Method: 结合时序特征学习和人口统计感知数据增强，利用序列聚类进行时序建模和概念提取，并引入人口统计感知数据增强方法。

Result: 在FaceForensics++、DFD、Celeb-DF和DFDC数据集上使用Xception和ResNet架构的实验表明，该方法在公平性和准确性上优于现有技术。

Conclusion: 该论文提出的公平感知深度伪造检测框架在公平性和准确性之间取得了最佳平衡，优于现有技术。

Abstract: Existing deepfake detection methods often exhibit bias, lack transparency,
and fail to capture temporal information, leading to biased decisions and
unreliable results across different demographic groups. In this paper, we
propose a fairness-aware deepfake detection framework that integrates temporal
feature learning and demographic-aware data augmentation to enhance fairness
and interpretability. Our method leverages sequence-based clustering for
temporal modeling of deepfake videos and concept extraction to improve
detection reliability while also facilitating interpretable decisions for
non-expert users. Additionally, we introduce a demography-aware data
augmentation method that balances underrepresented groups and applies
frequency-domain transformations to preserve deepfake artifacts, thereby
mitigating bias and improving generalization. Extensive experiments on
FaceForensics++, DFD, Celeb-DF, and DFDC datasets using state-of-the-art (SoTA)
architectures (Xception, ResNet) demonstrate the efficacy of the proposed
method in obtaining the best tradeoff between fairness and accuracy when
compared to SoTA.

</details>


### [128] [FineVision: Open Data Is All You Need](https://arxiv.org/abs/2510.17269)
*Luis Wiedmann,Orr Zohar,Amir Mahla,Xiaohan Wang,Rui Li,Thibaud Frere,Leandro von Werra,Aritra Roy Gosthipaty,Andrés Marafioti*

Main category: cs.CV

TL;DR: FineVision是一个经过精心收集和整理的2400万样本视觉语言数据集，统一了200多个来源，通过半自动化流程确保数据质量，训练出的模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型的进展受到公共数据集不一致和污染的阻碍，FineVision旨在解决这一问题。

Method: 通过半自动化、人工参与的流程，统一了200多个来源的数据，形成185个子集，包括批量摄入、模式映射、审核映射、抽查输出、去重和去污染等步骤。

Result: 在广泛的评估套件中，使用FineVision训练的模型表现优于现有开放混合数据集训练的模型。

Conclusion: FineVision的发布旨在加速以数据为中心的视觉语言模型研究，通过提供规模大、数据卫生良好且自动化与人工监督平衡的数据集。

Abstract: The advancement of vision-language models (VLMs) is hampered by a fragmented
landscape of inconsistent and contaminated public datasets. We introduce
FineVision, a meticulously collected, curated, and unified corpus of 24 million
samples - the largest open resource of its kind. We unify more than 200 sources
into 185 subsets via a semi-automated, human-in-the-loop pipeline: automation
performs bulk ingestion and schema mapping, while reviewers audit mappings and
spot-check outputs to verify faithful consumption of annotations, appropriate
formatting and diversity, and safety; issues trigger targeted fixes and
re-runs. The workflow further applies rigorous de-duplication within and across
sources and decontamination against 66 public benchmarks. FineVision also
encompasses agentic/GUI tasks with a unified action space; reviewers validate
schemas and inspect a sample of trajectories to confirm executable fidelity.
Models trained on FineVision consistently outperform those trained on existing
open mixtures across a broad evaluation suite, underscoring the benefits of
scale, data hygiene, and balanced automation with human oversight. We release
the corpus and curation tools to accelerate data-centric VLM research.

</details>


### [129] [Enhanced Motion Forecasting with Plug-and-Play Multimodal Large Language Models](https://arxiv.org/abs/2510.17274)
*Katie Luo,Jingwei Ji,Tong He,Runsheng Xu,Yichen Xie,Dragomir Anguelov,Mingxing Tan*

Main category: cs.CV

TL;DR: PnF利用MLLMs的自然语言处理能力，无需微调即可提升运动预测模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统在标准条件下表现可靠，但在多样化现实场景中成本效益地泛化仍是一大挑战。

Method: 设计提示词从MLLMs中提取结构化场景理解，并将其转化为可学习的嵌入以增强现有行为预测模型。

Result: 在Waymo Open Motion Dataset和nuScenes Dataset上验证，PnF方法在两个基准测试中均表现出一致的性能提升。

Conclusion: PnF方法通过结合多模态大语言模型（MLLMs）显著提升了现有运动预测模型的性能，且无需微调，具有实际应用价值。

Abstract: Current autonomous driving systems rely on specialized models for perceiving
and predicting motion, which demonstrate reliable performance in standard
conditions. However, generalizing cost-effectively to diverse real-world
scenarios remains a significant challenge. To address this, we propose
Plug-and-Forecast (PnF), a plug-and-play approach that augments existing motion
forecasting models with multimodal large language models (MLLMs). PnF builds on
the insight that natural language provides a more effective way to describe and
handle complex scenarios, enabling quick adaptation to targeted behaviors. We
design prompts to extract structured scene understanding from MLLMs and distill
this information into learnable embeddings to augment existing behavior
prediction models. Our method leverages the zero-shot reasoning capabilities of
MLLMs to achieve significant improvements in motion prediction performance,
while requiring no fine-tuning -- making it practical to adopt. We validate our
approach on two state-of-the-art motion forecasting models using the Waymo Open
Motion Dataset and the nuScenes Dataset, demonstrating consistent performance
improvements across both benchmarks.

</details>


### [130] [SG-CLDFF: A Novel Framework for Automated White Blood Cell Classification and Segmentation](https://arxiv.org/abs/2510.17278)
*Mehdi Zekriyapanah Gashti,Mostafa Mohammadpour,Ghasem Farjamnia*

Main category: cs.CV

TL;DR: SG-CLDFF框架通过显著性引导的预处理和多尺度深度特征融合，提升了白细胞分析的鲁棒性和可解释性，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 准确分割和分类显微镜图像中的白细胞对诊断和监测许多血液疾病至关重要，但由于染色变异性、复杂背景和类别不平衡等问题，这一任务仍具挑战性。

Method: SG-CLDFF框架结合了显著性驱动的预处理与多尺度深度特征聚合，采用轻量级混合骨干网络（EfficientSwin-style）生成多分辨率表示，并通过ResNeXt-CC启发的跨层融合模块融合浅层和深层信息。网络在多任务设置下训练，同时进行分割和细胞类型分类，使用类感知加权损失和显著性对齐正则化来缓解不平衡问题。

Result: 在标准公共基准测试（BCCD、LISC、ALL-IDB）上验证了框架的有效性，报告了在IoU、F1和分类准确性方面的一致提升。消融研究还展示了显著性预处理和跨层融合的个体贡献。

Conclusion: SG-CLDFF提供了一种实用且可解释的方法，用于在临床工作流程中实现更可靠的白细胞自动分析。

Abstract: Accurate segmentation and classification of white blood cells (WBCs) in
microscopic images are essential for diagnosis and monitoring of many
hematological disorders, yet remain challenging due to staining variability,
complex backgrounds, and class imbalance. In this paper, we introduce a novel
Saliency-Guided Cross-Layer Deep Feature Fusion framework (SG-CLDFF) that
tightly integrates saliency-driven preprocessing with multi-scale deep feature
aggregation to improve both robustness and interpretability for WBC analysis.
SG-CLDFF first computes saliency priors to highlight candidate WBC regions and
guide subsequent feature extraction. A lightweight hybrid backbone
(EfficientSwin-style) produces multi-resolution representations, which are
fused by a ResNeXt-CC-inspired cross-layer fusion module to preserve
complementary information from shallow and deep layers. The network is trained
in a multi-task setup with concurrent segmentation and cell-type classification
heads, using class-aware weighted losses and saliency-alignment regularization
to mitigate imbalance and suppress background activation. Interpretability is
enforced through Grad-CAM visualizations and saliency consistency checks,
allowing model decisions to be inspected at the regional level. We validate the
framework on standard public benchmarks (BCCD, LISC, ALL-IDB), reporting
consistent gains in IoU, F1, and classification accuracy compared to strong CNN
and transformer baselines. An ablation study also demonstrates the individual
contributions of saliency preprocessing and cross-layer fusion. SG-CLDFF offers
a practical and explainable path toward more reliable automated WBC analysis in
clinical workflows.

</details>


### [131] [CharDiff: A Diffusion Model with Character-Level Guidance for License Plate Image Restoration](https://arxiv.org/abs/2510.17330)
*Gyuhwan Park,Kihyun Na,Injung Kim*

Main category: cs.CV

TL;DR: CharDiff是一种基于扩散的车牌图像恢复框架，通过字符级引导和CHARM模块显著提升恢复和识别性能。


<details>
  <summary>Details</summary>
Motivation: 车牌图像恢复的重要性不仅在于LPR系统的预处理阶段，还包括提高证据价值、增强视觉界面清晰度以及促进车牌图像的进一步利用。

Method: 提出了一种新颖的基于扩散的框架CharDiff，结合字符级引导和CHARM模块，利用外部分割和OCR模块提取细粒度字符级先验。

Result: CharDiff在恢复质量和识别准确率上显著优于基线恢复模型，在Roboflow-LP数据集上实现了28%的相对CER降低。

Conclusion: CharDiff通过结构化的字符级引导有效增强了基于扩散的牌照图像恢复和识别在实际部署场景中的鲁棒性。

Abstract: The significance of license plate image restoration goes beyond the
preprocessing stage of License Plate Recognition (LPR) systems, as it also
serves various purposes, including increasing evidential value, enhancing the
clarity of visual interface, and facilitating further utilization of license
plate images. We propose a novel diffusion-based framework with character-level
guidance, CharDiff, which effectively restores and recognizes severely degraded
license plate images captured under realistic conditions. CharDiff leverages
fine-grained character-level priors extracted through external segmentation and
Optical Character Recognition (OCR) modules tailored for low-quality license
plate images. For precise and focused guidance, CharDiff incorporates a novel
Character-guided Attention through Region-wise Masking (CHARM) module, which
ensures that each character's guidance is restricted to its own region, thereby
avoiding interference with other regions. In experiments, CharDiff
significantly outperformed the baseline restoration models in both restoration
quality and recognition accuracy, achieving a 28% relative reduction in CER on
the Roboflow-LP dataset, compared to the best-performing baseline model. These
results indicate that the structured character-guided conditioning effectively
enhances the robustness of diffusion-based license plate restoration and
recognition in practical deployment scenarios.

</details>


### [132] [Machine Vision-Based Surgical Lighting System:Design and Implementation](https://arxiv.org/abs/2510.17287)
*Amir Gharghabi,Mahdi Hakiminezhad,Maryam Shafaei,Shaghayegh Gharghabi*

Main category: cs.CV

TL;DR: 提出一种基于YOLOv11的自动手术照明系统，通过识别蓝色标记自动调整光源，减少医生疲劳并提高照明一致性。


<details>
  <summary>Details</summary>
Motivation: 传统手术照明系统依赖手动调整，易导致外科医生疲劳、颈部劳损以及因漂移和阴影导致的照明不一致。

Method: 利用YOLOv11物体检测算法识别手术目标上方的蓝色标记，通过两个带有倾斜-平移支架的伺服电机将高功率LED光源定向到识别位置。

Result: YOLO模型在验证集上达到96.7%的mAP@50，验证了系统在模拟手术场景中的有效性。

Conclusion: 该论文提出的基于YOLOv11算法的自动手术照明系统能有效减少外科医生的体力负担，提高照明一致性，并支持更好的手术结果。

Abstract: Effortless and ergonomically designed surgical lighting is critical for
precision and safety during procedures. However, traditional systems often rely
on manual adjustments, leading to surgeon fatigue, neck strain, and
inconsistent illumination due to drift and shadowing. To address these
challenges, we propose a novel surgical lighting system that leverages the
YOLOv11 object detection algorithm to identify a blue marker placed above the
target surgical site. A high-power LED light source is then directed to the
identified location using two servomotors equipped with tilt-pan brackets. The
YOLO model achieves 96.7% mAP@50 on the validation set consisting of annotated
images simulating surgical scenes with the blue spherical marker. By automating
the lighting process, this machine vision-based solution reduces physical
strain on surgeons, improves consistency in illumination, and supports improved
surgical outcomes.

</details>


### [133] [Exploring Structural Degradation in Dense Representations for Self-supervised Learning](https://arxiv.org/abs/2510.17299)
*Siran Dai,Qianqian Xu,Peisong Wen,Yang Liu,Qingming Huang*

Main category: cs.CV

TL;DR: SSL训练过长可能损害密集任务性能（SDD现象）。论文提出无监督评估工具DSE，并基于此设计策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 发现自监督学习（SSL）中长时间训练可能导致密集预测任务性能下降（称为SDD现象），而现有方法缺乏无监督评估密集性能的有效手段。

Method: 通过理论分析和实证验证，设计了DSE，包括类别相关性度量和有效维度度量，用于评估密集表示的结构质量。

Result: 实验证明，基于DSE的模型选择策略平均提升mIoU 3.0%，DSE正则化方法能有效缓解密集退化问题。

Conclusion: 论文提出了DSE（Dense representation Structure Estimator）作为无监督评估密集预测任务性能的工具，并基于此设计了模型选择策略和正则化方法，有效缓解了自监督学习中的密集退化现象。

Abstract: In this work, we observe a counterintuitive phenomenon in self-supervised
learning (SSL): longer training may impair the performance of dense prediction
tasks (e.g., semantic segmentation). We refer to this phenomenon as
Self-supervised Dense Degradation (SDD) and demonstrate its consistent presence
across sixteen state-of-the-art SSL methods with various losses, architectures,
and datasets. When the model performs suboptimally on dense tasks at the end of
training, measuring the performance during training becomes essential. However,
evaluating dense performance effectively without annotations remains an open
challenge. To tackle this issue, we introduce a Dense representation Structure
Estimator (DSE), composed of a class-relevance measure and an effective
dimensionality measure. The proposed DSE is both theoretically grounded and
empirically validated to be closely correlated with the downstream performance.
Based on this metric, we introduce a straightforward yet effective model
selection strategy and a DSE-based regularization method. Experiments on
sixteen SSL methods across four benchmarks confirm that model selection
improves mIoU by $3.0\%$ on average with negligible computational cost.
Additionally, DSE regularization consistently mitigates the effects of dense
degradation. Code is available at
https://github.com/EldercatSAM/SSL-Degradation.

</details>


### [134] [LongInsightBench: A Comprehensive Benchmark for Evaluating Omni-Modal Models on Human-Centric Long-Video Understanding](https://arxiv.org/abs/2510.17305)
*ZhaoYang Han,Qihan Lin,Hao Liang,Bowen Chen,Zhou Liu,Wentao Zhang*

Main category: cs.CV

TL;DR: LongInsightBench是首个专注于长视频多模态理解的基准测试，通过精选视频和设计复杂任务，揭示了全模态模型在时间定位和因果推理上的挑战。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估模型在长视频中理解人类语言、视角、动作和其他上下文元素能力的基准测试，尤其是整合多模态信息的场景。

Method: 通过从开源数据集FineVideo中精选约1,000个视频，设计六种挑战性任务场景，并开发三步半自动化数据质量保证流程，确保合成问题和答案选项的难度和有效性。

Result: 实验结果显示，全模态模型在精确时间定位（T-Loc）和长距离因果推理（CE-Caus）任务中表现不佳，扩展实验揭示了多模态融合中的信息丢失和处理偏差。

Conclusion: LongInsightBench是第一个专注于评估模型在长视频理解能力的基准测试，特别是在整合视觉、音频和文本模态方面。实验结果表明，全模态模型（OLMs）在需要精确时间定位和长距离因果推理的任务中仍面临挑战。

Abstract: We introduce \textbf{LongInsightBench}, the first benchmark designed to
assess models' ability to understand long videos, with a focus on human
language, viewpoints, actions, and other contextual elements, while integrating
\textbf{visual, audio, and text} modalities. Our benchmark excels in three key
areas: \textbf{a) Long-Duration, Information-Dense Videos:} We carefully select
approximately 1,000 videos from open-source datasets FineVideo based on
duration limit and the information density of both visual and audio modalities,
focusing on content like lectures, interviews, and vlogs, which contain rich
language elements. \textbf{b) Diverse and Challenging Task Scenarios:} We have
designed six challenging task scenarios, including both Intra-Event and
Inter-Event Tasks. \textbf{c) Rigorous and Comprehensive Quality Assurance
Pipelines:} We have developed a three-step, semi-automated data quality
assurance pipeline to ensure the difficulty and validity of the synthesized
questions and answer options. Based on LongInsightBench, we designed a series
of experiments. Experimental results shows that Omni-modal models(OLMs) still
face challenge in tasks requiring precise temporal localization (T-Loc) and
long-range causal inference (CE-Caus). Extended experiments reveal the
information loss and processing bias in multi-modal fusion of OLMs. Our dataset
and code is available at
https://anonymous.4open.science/r/LongInsightBench-910F/.

</details>


### [135] [SparseWorld: A Flexible, Adaptive, and Efficient 4D Occupancy World Model Powered by Sparse and Dynamic Queries](https://arxiv.org/abs/2510.17482)
*Chenxu Dang,Haiyan Liu,Guangjun Bao,Pei An,Xinyue Tang,Jie Ma,Bingchuan Sun,Yan Wang*

Main category: cs.CV

TL;DR: SparseWorld是一种新型4D占用世界模型，通过动态查询和自适应模块提升感知与预测能力，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有占用世界模型依赖静态固定嵌入或网格，限制了感知的灵活性，且与真实场景的动态连续性存在潜在不对齐。

Method: 提出了Range-Adaptive Perception模块和State-Conditioned Forecasting模块，并设计了Temporal-Aware Self-Scheduling训练策略。

Result: SparseWorld在感知、预测和规划任务中表现优异，验证了其灵活性、适应性和高效性。

Conclusion: SparseWorld通过稀疏动态查询实现了灵活、自适应且高效的4D占用世界模型，在感知、预测和规划任务中达到了最先进的性能。

Abstract: Semantic occupancy has emerged as a powerful representation in world models
for its ability to capture rich spatial semantics. However, most existing
occupancy world models rely on static and fixed embeddings or grids, which
inherently limit the flexibility of perception. Moreover, their ``in-place
classification" over grids exhibits a potential misalignment with the dynamic
and continuous nature of real scenarios.In this paper, we propose SparseWorld,
a novel 4D occupancy world model that is flexible, adaptive, and efficient,
powered by sparse and dynamic queries. We propose a Range-Adaptive Perception
module, in which learnable queries are modulated by the ego vehicle states and
enriched with temporal-spatial associations to enable extended-range
perception. To effectively capture the dynamics of the scene, we design a
State-Conditioned Forecasting module, which replaces classification-based
forecasting with regression-guided formulation, precisely aligning the dynamic
queries with the continuity of the 4D environment. In addition, We specifically
devise a Temporal-Aware Self-Scheduling training strategy to enable smooth and
efficient training. Extensive experiments demonstrate that SparseWorld achieves
state-of-the-art performance across perception, forecasting, and planning
tasks. Comprehensive visualizations and ablation studies further validate the
advantages of SparseWorld in terms of flexibility, adaptability, and
efficiency. The code is available at https://github.com/MSunDYY/SparseWorld.

</details>


### [136] [CausalMamba: Scalable Conditional State Space Models for Neural Causal Inference](https://arxiv.org/abs/2510.17318)
*Sangyoon Bae,Jiook Cha*

Main category: cs.CV

TL;DR: CausalMamba是一个可扩展框架，通过BOLD去卷积和新型因果图推断，显著提升了fMRI因果推断的准确性和实用性，揭示了传统方法无法检测的网络动态。


<details>
  <summary>Details</summary>
Motivation: 解决fMRI基于因果推断的根本限制：从血流动力学扭曲的BOLD信号推断神经因果性的不适定性，以及现有方法（如动态因果建模DCM）的计算不可行性。

Method: CausalMamba将复杂的逆向问题分解为两个可处理的阶段：BOLD去卷积以恢复潜在神经活动，随后使用新型Conditional Mamba架构进行因果图推断。

Result: 在模拟数据上，CausalMamba比DCM准确率高37%。在真实任务fMRI数据中，该方法以88%的保真度恢复了已知神经通路，而传统方法在超过99%的受试者中未能识别这些典型电路。

Conclusion: CausalMamba为神经科学家提供了一个实用工具，能够在大规模因果推断中捕捉基本电路模式和灵活的网络动态，支持认知功能研究。

Abstract: We introduce CausalMamba, a scalable framework that addresses fundamental
limitations in fMRI-based causal inference: the ill-posed nature of inferring
neural causality from hemodynamically distorted BOLD signals and the
computational intractability of existing methods like Dynamic Causal Modeling
(DCM). Our approach decomposes this complex inverse problem into two tractable
stages: BOLD deconvolution to recover latent neural activity, followed by
causal graph inference using a novel Conditional Mamba architecture. On
simulated data, CausalMamba achieves 37% higher accuracy than DCM. Critically,
when applied to real task fMRI data, our method recovers well-established
neural pathways with 88% fidelity, whereas conventional approaches fail to
identify these canonical circuits in over 99% of subjects. Furthermore, our
network analysis of working memory data reveals that the brain strategically
shifts its primary causal hub-recruiting executive or salience networks
depending on the stimulus-a sophisticated reconfiguration that remains
undetected by traditional methods. This work provides neuroscientists with a
practical tool for large-scale causal inference that captures both fundamental
circuit motifs and flexible network dynamics underlying cognitive function.

</details>


### [137] [Context-Aware Pseudo-Label Scoring for Zero-Shot Video Summarization](https://arxiv.org/abs/2510.17501)
*Yuanli Wu,Long Zhang,Yue Du,Bin Li*

Main category: cs.CV

TL;DR: 提出了一种基于评分标准引导的伪标签提示框架，显著提升了零样本视频摘要的性能，接近监督方法水平。


<details>
  <summary>Details</summary>
Motivation: 现有监督方法标注成本高且跨数据集泛化能力有限，无监督方法难以捕捉高级语义和细粒度叙事线索，零样本提示方法对人工模板和数据集特定评分归一化敏感。

Method: 引入了一种基于评分标准引导的伪标签提示框架，将少量真实标注转化为高置信度伪标签，并聚合为结构化、数据集自适应的评分标准，指导可解释的场景评估。

Result: 在SumMe和TVSum数据集上，F1分数分别达到57.58和63.05，超越无监督和先前的零样本基线方法，接近监督方法的性能。

Conclusion: 研究提出了一种基于评分标准引导的伪标签提示框架，有效稳定了基于LLM的评分，为零样本视频摘要建立了一个通用且可解释的范式。

Abstract: With the rapid proliferation of video content across social media,
surveillance, and education platforms, efficiently summarizing long videos into
concise yet semantically faithful surrogates has become increasingly vital.
Existing supervised methods achieve strong in-domain accuracy by learning from
dense annotations but suffer from high labeling costs and limited cross-dataset
generalization, while unsupervised approaches, though label-free, often fail to
capture high-level human semantics and fine-grained narrative cues. More
recently, zero-shot prompting pipelines have leveraged large language models
(LLMs) for training-free video summarization, yet remain highly sensitive to
handcrafted prompt templates and dataset-specific score normalization. To
overcome these limitations, we introduce a rubric-guided, pseudo-labeled
prompting framework that transforms a small subset of ground-truth annotations
into high-confidence pseudo labels, which are aggregated into structured,
dataset-adaptive scoring rubrics guiding interpretable scene evaluation. During
inference, first and last segments are scored based solely on their
descriptions, whereas intermediate ones incorporate brief contextual summaries
of adjacent scenes to assess narrative progression and redundancy. This
contextual prompting enables the LLM to balance local salience and global
coherence without parameter tuning. On SumMe and TVSum, our method achieves F1
scores of \textbf{57.58} and \textbf{63.05}, surpassing unsupervised and prior
zero-shot baselines while approaching supervised performance. The results
demonstrate that rubric-guided pseudo labeling effectively stabilizes LLM-based
scoring and establishes a general, interpretable zero-shot paradigm for video
summarization.

</details>


### [138] [A Single Set of Adversarial Clothes Breaks Multiple Defense Methods in the Physical World](https://arxiv.org/abs/2510.17322)
*Wei Zhang,Zhanhao Hu,Xiao Li,Xiaopei Zhu,Xiaolin Hu*

Main category: cs.CV

TL;DR: 研究发现现有对抗防御方法难以有效对抗大尺寸对抗衣物，揭示其普遍脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法在对抗大尺寸对抗补丁时表现不佳，尤其是对抗衣物这种更自然的攻击形式。

Method: 通过实验评估多种防御方法对抗大尺寸对抗衣物的效果，并制作了一组能够突破多种防御的对抗衣物。

Result: 实验表明，所有防御方法在数字和物理世界中对抗对抗衣物时表现均不佳，其中一组对抗衣物在物理世界中突破了多种防御方法。

Conclusion: 现有的对抗防御方法在面对大覆盖范围的对抗衣物时存在普遍脆弱性，需要进一步研究更有效的防御策略。

Abstract: In recent years, adversarial attacks against deep learning-based object
detectors in the physical world have attracted much attention. To defend
against these attacks, researchers have proposed various defense methods
against adversarial patches, a typical form of physically-realizable attack.
However, our experiments showed that simply enlarging the patch size could make
these defense methods fail. Motivated by this, we evaluated various defense
methods against adversarial clothes which have large coverage over the human
body. Adversarial clothes provide a good test case for adversarial defense
against patch-based attacks because they not only have large sizes but also
look more natural than a large patch on humans. Experiments show that all the
defense methods had poor performance against adversarial clothes in both the
digital world and the physical world. In addition, we crafted a single set of
clothes that broke multiple defense methods on Faster R-CNN. The set achieved
an Attack Success Rate (ASR) of 96.06% against the undefended detector and over
64.84% ASRs against nine defended models in the physical world, unveiling the
common vulnerability of existing adversarial defense methods against
adversarial clothes. Code is available at:
https://github.com/weiz0823/adv-clothes-break-multiple-defenses.

</details>


### [139] [MUG-V 10B: High-efficiency Training Pipeline for Large Video Generation Models](https://arxiv.org/abs/2510.17519)
*Yongshun Zhang,Zhongyi Fan,Yonghang Zhang,Zhangzikang Li,Weifeng Chen,Zhongwei Feng,Chaoyue Wang,Peng Hou,Anxiang Zeng*

Main category: cs.CV

TL;DR: 提出优化四大支柱的视频生成训练框架MUG-V 10B，性能匹配SOTA且开源完整代码，首次实现Megatron-Core高效训练。


<details>
  <summary>Details</summary>
Motivation: 大规模视频生成模型训练面临跨模态对齐、长序列和复杂时空依赖等挑战，需高效解决方案。

Method: 优化了数据预处理、模型架构、训练策略和基础设施四大支柱，涵盖视频压缩、参数缩放、课程式预训练和对齐后训练等环节。

Result: MUG-V 10B在整体性能上匹配最新视频生成器，在电子商务任务中超越开源基线，并实现高训练效率和近线性多节点扩展。

Conclusion: MUG-V 10B模型在视频生成任务中表现优异，尤其在电子商务领域超越现有开源基线，并首次公开了基于Megatron-Core的大规模训练代码和推理流程。

Abstract: In recent years, large-scale generative models for visual content
(\textit{e.g.,} images, videos, and 3D objects/scenes) have made remarkable
progress. However, training large-scale video generation models remains
particularly challenging and resource-intensive due to cross-modal text-video
alignment, the long sequences involved, and the complex spatiotemporal
dependencies. To address these challenges, we present a training framework that
optimizes four pillars: (i) data processing, (ii) model architecture, (iii)
training strategy, and (iv) infrastructure for large-scale video generation
models. These optimizations delivered significant efficiency gains and
performance improvements across all stages of data preprocessing, video
compression, parameter scaling, curriculum-based pretraining, and
alignment-focused post-training. Our resulting model, MUG-V 10B, matches recent
state-of-the-art video generators overall and, on e-commerce-oriented video
generation tasks, surpasses leading open-source baselines in human evaluations.
More importantly, we open-source the complete stack, including model weights,
Megatron-Core-based large-scale training code, and inference pipelines for
video generation and enhancement. To our knowledge, this is the first public
release of large-scale video generation training code that exploits
Megatron-Core to achieve high training efficiency and near-linear multi-node
scaling, details are available in
\href{https://github.com/Shopee-MUG/MUG-V}{our webpage}.

</details>


### [140] [MambaX-Net: Dual-Input Mamba-Enhanced Cross-Attention Network for Longitudinal MRI Segmentation](https://arxiv.org/abs/2510.17529)
*Yovin Yahathugoda,Davide Prezzi,Piyalitt Ittichaiwong,Vicky Goh,Sebastien Ourselin,Michela Antonelli*

Main category: cs.CV

TL;DR: MambaX-Net 是一种新型半监督 3D 分割架构，用于纵向前列腺癌监测，通过跨注意力模块和形状提取器提升分割精度，优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习分割模型在纵向 AS 分析中的不足，尤其是多时间点和专家标注稀缺的问题。

Method: 提出 MambaX-Net，一种半监督、双扫描 3D 分割架构，结合了 Mamba 增强的跨注意力模块和形状提取器模块，并引入半监督自训练策略。

Result: MambaX-Net 在纵向 AS 数据集上表现优异，分割效果显著优于现有模型。

Conclusion: MambaX-Net 在纵向主动监测（AS）数据集中表现出色，显著优于现有的 U-Net 和 Transformer 模型，即使在有限和噪声数据下也能实现卓越的前列腺区域分割。

Abstract: Active Surveillance (AS) is a treatment option for managing low and
intermediate-risk prostate cancer (PCa), aiming to avoid overtreatment while
monitoring disease progression through serial MRI and clinical follow-up.
Accurate prostate segmentation is an important preliminary step for automating
this process, enabling automated detection and diagnosis of PCa. However,
existing deep-learning segmentation models are often trained on
single-time-point and expertly annotated datasets, making them unsuitable for
longitudinal AS analysis, where multiple time points and a scarcity of expert
labels hinder their effective fine-tuning. To address these challenges, we
propose MambaX-Net, a novel semi-supervised, dual-scan 3D segmentation
architecture that computes the segmentation for time point t by leveraging the
MRI and the corresponding segmentation mask from the previous time point. We
introduce two new components: (i) a Mamba-enhanced Cross-Attention Module,
which integrates the Mamba block into cross attention to efficiently capture
temporal evolution and long-range spatial dependencies, and (ii) a Shape
Extractor Module that encodes the previous segmentation mask into a latent
anatomical representation for refined zone delination. Moreover, we introduce a
semi-supervised self-training strategy that leverages pseudo-labels generated
from a pre-trained nnU-Net, enabling effective learning without expert
annotations. MambaX-Net was evaluated on a longitudinal AS dataset, and results
showed that it significantly outperforms state-of-the-art U-Net and
Transformer-based models, achieving superior prostate zone segmentation even
when trained on limited and noisy data.

</details>


### [141] [iDETEX: Empowering MLLMs for Intelligent DETailed EXplainable IQA](https://arxiv.org/abs/2510.17332)
*Zhaoran Zhao,Xinli Yue,Jianhui Sun,Yuhao Xie,Tao Shao,Liangchao Yao,Fan Xia,Yuetang Deng*

Main category: cs.CV

TL;DR: iDETEX是一个多模态大语言模型，通过任务特定模块和混合策略，实现了图像质量评估的详细解释，并在基准测试和挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决图像质量评估（IQA）从标量质量预测向更可解释、与人对齐的评估范式发展的新兴挑战。

Method: 提出iDETEX，一个统一的多模态大语言模型（MLLM），设计了任务特定的离线增强模块和数据混合策略，辅以在线增强策略以充分利用多源监督。

Result: 在ViDA-UGC基准测试中，iDETEX在所有子任务上均达到最先进的性能。

Conclusion: iDETEX在ViDA-UGC基准测试中表现出色，并在ICCV MIPI 2025挑战赛中排名第一，证明了其在提供准确且可解释的质量评估方面的有效性和鲁棒性。

Abstract: Image Quality Assessment (IQA) has progressed from scalar quality prediction
to more interpretable, human-aligned evaluation paradigms. In this work, we
address the emerging challenge of detailed and explainable IQA by proposing
iDETEX-a unified multimodal large language model (MLLM) capable of
simultaneously performing three key tasks: quality grounding, perception, and
description. To facilitate efficient and generalizable training across these
heterogeneous subtasks, we design a suite of task-specific offline augmentation
modules and a data mixing strategy. These are further complemented by online
enhancement strategies to fully exploit multi-sourced supervision. We validate
our approach on the large-scale ViDA-UGC benchmark, where iDETEX achieves
state-of-the-art performance across all subtasks. Our model ranks first in the
ICCV MIPI 2025 Detailed Image Quality Assessment Challenge, demonstrating its
effectiveness and robustness in delivering accurate and interpretable quality
assessments.

</details>


### [142] [Nearest-Class Mean and Logits Agreement for Wildlife Open-Set Recognition](https://arxiv.org/abs/2510.17338)
*Jiahao Huo,Mufhumudzi Muthivhi,Terence L. van Zyl,Fredrik Gustafsson*

Main category: cs.CV

TL;DR: 提出一种后处理OSR方法，通过NCM与softmax概率的一致性测量，在两个数据集上表现稳定且优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前野生动物分类模型在封闭世界设置下训练，面对未知类别时会过度自信。开放集识别（OSR）旨在分类已知类别并拒绝未知样本，但现有方法需重新训练预训练模型。

Method: 提出基于输入到其最近类均值（NCM）距离的概率分布，并与逻辑空间的softmax概率进行比较，以衡量NCM与分类头之间的一致性。

Result: 在两个评估数据集中排名前三，AUROC分别达到93.41（非洲动物）和95.35（瑞典动物）。

Conclusion: 该研究提出了一种后处理的开放集识别方法，通过测量模型特征与预测逻辑之间的一致性，表现优于现有方法，在两个数据集上均取得稳定性能。

Abstract: Current state-of-the-art Wildlife classification models are trained under the
closed world setting. When exposed to unknown classes, they remain
overconfident in their predictions. Open-set Recognition (OSR) aims to classify
known classes while rejecting unknown samples. Several OSR methods have been
proposed to model the closed-set distribution by observing the feature, logit,
or softmax probability space. A significant drawback of many existing
approaches is the requirement to retrain the pre-trained classification model
with the OSR-specific strategy. This study contributes a post-processing OSR
method that measures the agreement between the models' features and predicted
logits. We propose a probability distribution based on an input's distance to
its Nearest Class Mean (NCM). The NCM-based distribution is then compared with
the softmax probabilities from the logit space to measure agreement between the
NCM and the classification head. Our proposed strategy ranks within the top
three on two evaluated datasets, showing consistent performance across the two
datasets. In contrast, current state-of-the-art methods excel on a single
dataset. We achieve an AUROC of 93.41 and 95.35 for African and Swedish
animals. The code can be found
https://github.com/Applied-Representation-Learning-Lab/OSR.

</details>


### [143] [CaMiT: A Time-Aware Car Model Dataset for Classification and Generation](https://arxiv.org/abs/2510.17626)
*Frédéric LIN,Biruk Abere Ambaw,Adrian Popescu,Hejer Ammar,Romaric Audigier,Hervé Le Borgne*

Main category: cs.CV

TL;DR: CaMiT是一个捕捉汽车模型时间演化的数据集，支持监督和自监督学习。研究提出了时间增量分类策略和时间感知图像生成，提高了时间鲁棒性和生成真实性。


<details>
  <summary>Details</summary>
Motivation: AI系统需要适应不断变化的视觉环境，尤其是在物体外观随时间变化的领域。CaMiT数据集旨在捕捉汽车模型的时间演化，支持监督和自监督学习。

Method: 提出了时间增量分类设置，并评估了两种策略：时间增量预训练和时间增量分类器学习。此外，探索了利用时间元数据进行训练的时间感知图像生成。

Result: 静态预训练在领域内数据上表现良好且资源高效，但在跨年测试中准确性下降。时间增量策略（预训练和分类器学习）提高了时间鲁棒性。时间感知图像生成能产生更真实的输出。

Conclusion: CaMiT提供了一个丰富的基准，用于研究细粒度视觉识别和生成中的时间适应性。

Abstract: AI systems must adapt to evolving visual environments, especially in domains
where object appearances change over time. We introduce Car Models in Time
(CaMiT), a fine-grained dataset capturing the temporal evolution of car models,
a representative class of technological artifacts. CaMiT includes 787K labeled
samples of 190 car models (2007-2023) and 5.1M unlabeled samples (2005-2023),
supporting both supervised and self-supervised learning. Static pretraining on
in-domain data achieves competitive performance with large-scale generalist
models while being more resource-efficient, yet accuracy declines when models
are tested across years. To address this, we propose a time-incremental
classification setting, a realistic continual learning scenario with emerging,
evolving, and disappearing classes. We evaluate two strategies:
time-incremental pretraining, which updates the backbone, and time-incremental
classifier learning, which updates only the final layer, both improving
temporal robustness. Finally, we explore time-aware image generation that
leverages temporal metadata during training, yielding more realistic outputs.
CaMiT offers a rich benchmark for studying temporal adaptation in fine-grained
visual recognition and generation.

</details>


### [144] [Exploring The Missing Semantics In Event Modality](https://arxiv.org/abs/2510.17347)
*Jingqian Wu,Shengpeng Xu,Yunbo Jia,Edmund Y. Lam*

Main category: cs.CV

TL;DR: Semantic-E2VID通过跨模态语义对齐和特征融合，提升了事件到视频重建的语义信息恢复能力，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 事件相机在事件到视频重建（E2V）任务中因仅捕捉强度变化而忽略静态对象和背景，导致语义信息缺失，现有方法常忽视语义信息的重要性。

Method: 提出了Semantic-E2VID框架，包含跨模态特征对齐（CFA）模块和语义感知特征融合（SFF）块，利用Segment Anything Model（SAM）的视觉语义知识，并通过语义感知的E2V监督来优化重建。

Result: 实验表明，Semantic-E2VID在多个基准测试中显著提升了帧质量，优于现有E2V方法。

Conclusion: Semantic-E2VID通过引入跨模态特征对齐模块和语义感知特征融合块，显著提升了事件到视频重建的质量，尤其是在语义信息恢复方面，超越了现有方法。

Abstract: Event cameras offer distinct advantages such as low latency, high dynamic
range, and efficient motion capture. However, event-to-video reconstruction
(E2V), a fundamental event-based vision task, remains challenging, particularly
for reconstructing and recovering semantic information. This is primarily due
to the nature of the event camera, as it only captures intensity changes,
ignoring static objects and backgrounds, resulting in a lack of semantic
information in captured event modality. Further, semantic information plays a
crucial role in video and frame reconstruction, yet is often overlooked by
existing E2V approaches. To bridge this gap, we propose Semantic-E2VID, an E2V
framework that explores the missing visual semantic knowledge in event modality
and leverages it to enhance event-to-video reconstruction. Specifically,
Semantic-E2VID introduces a cross-modal feature alignment (CFA) module to
transfer the robust visual semantics from a frame-based vision foundation
model, the Segment Anything Model (SAM), to the event encoder, while aligning
the high-level features from distinct modalities. To better utilize the learned
semantic feature, we further propose a semantic-aware feature fusion (SFF)
block to integrate learned semantics in frame modality to form event
representations with rich semantics that can be decoded by the event decoder.
Further, to facilitate the reconstruction of semantic information, we propose a
novel Semantic Perceptual E2V Supervision that helps the model to reconstruct
semantic details by leveraging SAM-generated categorical labels. Extensive
experiments demonstrate that Semantic-E2VID significantly enhances frame
quality, outperforming state-of-the-art E2V methods across multiple benchmarks.
The sample code is included in the supplementary material.

</details>


### [145] [Frugal Federated Learning for Violence Detection: A Comparison of LoRA-Tuned VLMs and Personalized CNNs](https://arxiv.org/abs/2510.17651)
*Sébastien Thuau,Siba Haidar,Ayush Bajracharya,Rachid Chelouah*

Main category: cs.CV

TL;DR: 研究比较了VLM和CNN3D在联邦暴力检测中的表现，发现CNN3D更节能且性能略优，但VLM在复杂场景中更适用。提出了混合模型以平衡性能与资源消耗。


<details>
  <summary>Details</summary>
Motivation: 探究节俭的联邦学习方法在暴力检测中的应用，强调能源效率和环境指标。

Method: 比较了两种策略：(i) 零样本和联邦微调的视觉语言模型（VLM），(ii) 个性化训练的紧凑3D卷积神经网络（CNN3D）。使用LLaVA-7B和65.8M参数的CNN3D作为代表案例，评估了非独立同分布（non-IID）设置下的准确性、校准和能耗。

Result: 两种方法的准确率均超过90%。CNN3D在ROC AUC和对数损失上略优于LoRA调优的VLM，且能耗更低。VLM在上下文推理和多模态推理中仍具优势。

Conclusion: 研究支持一种混合模型：轻量级CNN用于常规分类，选择性激活VLM处理复杂场景。该框架为视频监控中负责任、资源感知的AI提供了可复现的基线。

Abstract: We examine frugal federated learning approaches to violence detection by
comparing two complementary strategies: (i) zero-shot and federated fine-tuning
of vision-language models (VLMs), and (ii) personalized training of a compact
3D convolutional neural network (CNN3D). Using LLaVA-7B and a 65.8M parameter
CNN3D as representative cases, we evaluate accuracy, calibration, and energy
usage under realistic non-IID settings. Both approaches exceed 90% accuracy.
CNN3D slightly outperforms Low-Rank Adaptation(LoRA)-tuned VLMs in ROC AUC and
log loss, while using less energy. VLMs remain favorable for contextual
reasoning and multimodal inference. We quantify energy and CO$_2$ emissions
across training and inference, and analyze sustainability trade-offs for
deployment. To our knowledge, this is the first comparative study of LoRA-tuned
vision-language models and personalized CNNs for federated violence detection,
with an emphasis on energy efficiency and environmental metrics. These findings
support a hybrid model: lightweight CNNs for routine classification, with
selective VLM activation for complex or descriptive scenarios. The resulting
framework offers a reproducible baseline for responsible, resource-aware AI in
video surveillance, with extensions toward real-time, multimodal, and
lifecycle-aware systems.

</details>


### [146] [Recurrent Attention-based Token Selection for Efficient Streaming Video-LLMs](https://arxiv.org/abs/2510.17364)
*Vaggelis Dorovatas,Soroush Seifi,Gunshi Gupta,Rahaf Aljundi*

Main category: cs.CV

TL;DR: 提出了一种无需训练的方法，通过令牌选择和递归处理，显著提升视频大语言模型在流媒体场景下的效率和效果。


<details>
  <summary>Details</summary>
Motivation: 解决视频大语言模型在流媒体场景下的挑战，如小时长视频的在线处理和及时响应问题。

Method: 提出了一种无需训练的方法，兼容标准视频大语言模型（Video-LLMs），利用三个关键概念：1）基于LLM的视觉令牌选择；2）过去选定令牌的递归处理；3）基于标题的轻量级问答。

Result: 能够丢弃约95%的不重要视觉令牌，性能损失最小，并在流媒体视频基准测试中表现优异。

Conclusion: 该方法在流媒体视频基准测试中达到了最先进的性能，平衡了效率与效果。

Abstract: Video Large Language Models (Video-LLMs) excel at understanding videos
in-context, provided they have full access to the video when answering queries.
However, these models face challenges in streaming scenarios where hour-long
videos must be processed online, and questions need timely responses. In this
work, we propose a training-free approach compatible with standard Video-LLMs,
leveraging three key concepts: 1) LLM-informed selection of visual tokens to
identify those that the LLM has attended to and contributed to its
understanding of each short clip. Our attention-based selection allows us to
discard up to ~95% of unimportant visual tokens with minimal performance loss;
2) Recurrent processing of past selected tokens to generate temporally coherent
understanding of each processed clip; 3) Caption-based question answering for
lightweight and accurate responses. Our method achieves state-of-the-art
performance on streaming video benchmarks, striking a balance between
efficiency and effectiveness.

</details>


### [147] [PICABench: How Far Are We from Physically Realistic Image Editing?](https://arxiv.org/abs/2510.17681)
*Yuandong Pu,Le Zhuo,Songhao Han,Jinbo Xing,Kaiwen Zhu,Shuo Cao,Bin Fu,Si Liu,Hongsheng Li,Yu Qiao,Wenlong Zhang,Xi Chen,Yihao Liu*

Main category: cs.CV

TL;DR: 论文提出PICABench评估图像编辑的物理真实性，发现现有模型仍有不足，并探索了从视频学习物理效应的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有编辑模型和基准主要关注指令完成，但忽视了物理效应（如阴影、反射和物体间交互）。作者旨在评估当前模型在物理真实性方面的表现，并探索有效解决方案。

Method: 作者引入了PICABench，系统评估了八个子维度（涵盖光学、力学和状态转换）的物理真实性，并提出了PICAEval评估协议，使用VLM-as-a-judge结合区域级人工标注和问题。此外，作者还通过从视频中学习物理效应构建了训练数据集PICA-100K。

Result: 评估主流模型后发现，物理真实性仍是一个具有挑战性的问题，存在大量改进空间。

Conclusion: 物理真实的图像编辑仍是一个具有挑战性的问题，存在大量探索空间。作者希望其提出的基准和解决方案能为未来从简单内容编辑迈向物理一致真实性的研究奠定基础。

Abstract: Image editing has achieved remarkable progress recently. Modern editing
models could already follow complex instructions to manipulate the original
content. However, beyond completing the editing instructions, the accompanying
physical effects are the key to the generation realism. For example, removing
an object should also remove its shadow, reflections, and interactions with
nearby objects. Unfortunately, existing models and benchmarks mainly focus on
instruction completion but overlook these physical effects. So, at this moment,
how far are we from physically realistic image editing? To answer this, we
introduce PICABench, which systematically evaluates physical realism across
eight sub-dimension (spanning optics, mechanics, and state transitions) for
most of the common editing operations (add, remove, attribute change, etc). We
further propose the PICAEval, a reliable evaluation protocol that uses
VLM-as-a-judge with per-case, region-level human annotations and questions.
Beyond benchmarking, we also explore effective solutions by learning physics
from videos and construct a training dataset PICA-100K. After evaluating most
of the mainstream models, we observe that physical realism remains a
challenging problem with large rooms to explore. We hope that our benchmark and
proposed solutions can serve as a foundation for future work moving from naive
content editing toward physically consistent realism.

</details>


### [148] [Beyond Real Faces: Synthetic Datasets Can Achieve Reliable Recognition Performance without Privacy Compromise](https://arxiv.org/abs/2510.17372)
*Paweł Borsukiewicz,Fadi Boutros,Iyiola E. Olatunji,Charles Beumier,Wendkûuni C. Ouedraogo,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.CV

TL;DR: 合成面部数据在识别准确率和隐私保护上表现优异，可作为面部识别研究的伦理替代方案。


<details>
  <summary>Details</summary>
Motivation: 面部识别系统的部署引发了伦理困境，高精度需要大量未经同意的真实面部数据集，导致数据集撤回和法律风险。合成面部数据作为隐私保护替代方案缺乏全面实证证据。

Method: 通过系统性文献回顾确定25个合成面部识别数据集（2018-2025），结合严格的实验验证，评估了隐私保护合成数据的七个关键要求。

Result: 最佳合成数据集（VariFace, VIGFace）识别准确率分别达95.67%和94.91%，超过真实数据集CASIA-WebFace（94.70%）。合成数据在保持身份可分性的同时确保了类内变异性，并提供了通过生成参数缓解偏见的前所未有的控制。

Conclusion: 合成面部数据在科学上可行且伦理上是面部识别研究的必要替代方案。

Abstract: The deployment of facial recognition systems has created an ethical dilemma:
achieving high accuracy requires massive datasets of real faces collected
without consent, leading to dataset retractions and potential legal liabilities
under regulations like GDPR. While synthetic facial data presents a promising
privacy-preserving alternative, the field lacks comprehensive empirical
evidence of its viability. This study addresses this critical gap through
extensive evaluation of synthetic facial recognition datasets. We present a
systematic literature review identifying 25 synthetic facial recognition
datasets (2018-2025), combined with rigorous experimental validation. Our
methodology examines seven key requirements for privacy-preserving synthetic
data: identity leakage prevention, intra-class variability, identity
separability, dataset scale, ethical data sourcing, bias mitigation, and
benchmark reliability. Through experiments involving over 10 million synthetic
samples, extended by a comparison of results reported on five standard
benchmarks, we provide the first comprehensive empirical assessment of
synthetic data's capability to replace real datasets. Best-performing synthetic
datasets (VariFace, VIGFace) achieve recognition accuracies of 95.67% and
94.91% respectively, surpassing established real datasets including
CASIA-WebFace (94.70%). While those images remain private, publicly available
alternatives Vec2Face (93.52%) and CemiFace (93.22%) come close behind. Our
findings reveal that they ensure proper intra-class variability while
maintaining identity separability. Demographic bias analysis shows that, even
though synthetic data inherits limited biases, it offers unprecedented control
for bias mitigation through generation parameters. These results establish
synthetic facial data as a scientifically viable and ethically imperative
alternative for facial recognition research.

</details>


### [149] [Intelligent Communication Mixture-of-Experts Boosted-Medical Image Segmentation Foundation Model](https://arxiv.org/abs/2510.17684)
*Xinwei Zhang,Hu Chen,Zhe Yuan,Sukun Tian,Peng Feng*

Main category: cs.CV

TL;DR: IC-MoE是一种基于混合专家的医学图像分割基础模型，通过专家选择和语义引导对比学习增强高层特征表示，同时保持预训练权重结构完整性，实验证明其性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法存在高层特征表示不足和预训练权重结构完整性被破坏的问题，需要通过创新的方法来解决。

Method: 1. 构建基础专家、语义专家和自适应专家，并通过像素概率自适应投票策略实现专家选择和融合。2. 提出语义引导的对比学习方法，增强高层特征的表示能力。

Result: 在三个公共医学图像分割数据集上的广泛实验表明，IC-MoE优于其他SOTA模型。

Conclusion: 提出的IC-MoE模型有效补充了基础医学图像分割模型的高层特征和预训练结构完整性，并在多种医学图像分割场景中展现了优越的泛化能力。

Abstract: Foundation models for medical image segmentation have achieved remarkable
performance. Adaptive fine-tuning of natural image segmentation foundation
models is crucial for medical image segmentation tasks. However, some
limitations exist in existing fine-tuning methods: 1) insufficient
representation of high-level features and 2) the fine-tuning process disrupts
the structural integrity of pretrained weights. Inspired by these critical
problems, we propose an intelligent communication mixture-of-experts
boosted-medical image segmentation foundation model, named IC-MoE, with twofold
ideas: 1) We construct basic experts, semantic experts, and adaptive experts.
Moreover, we implement a pixel probability adaptive voting strategy, which
enables expert selection and fusion through label consistency and load
balancing. This approach preliminarily enhances the representation capability
of high-level features while preserving the structural integrity of pretrained
weights. 2) We propose a semantic-guided contrastive learning method to address
the issue of weak supervision in contrastive learning. This method further
enhances the representation capability of high-level features while preserving
the structural integrity of pretrained weights. Extensive experiments across
three public medical image segmentation datasets demonstrate that the IC-MoE
outperforms other SOTA models. Consequently, the proposed IC-MoE effectively
supplements foundational medical image segmentation models with high-level
features and pretrained structural integrity. We also validate the superior
generalizability of the IC-MoE across diverse medical image segmentation
scenarios.

</details>


### [150] [Facial Expression-based Parkinson's Disease Severity Diagnosis via Feature Fusion and Adaptive Class Balancing](https://arxiv.org/abs/2510.17373)
*Yintao Zhou,Wei Huang,Zhengyu Li,Jing Huang,Meng Pang*

Main category: cs.CV

TL;DR: 提出一种基于面部表情的帕金森病严重程度诊断方法，整合多种表情特征并采用自适应类别平衡，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前基于面部表情的方法常依赖单一表情类型，可能导致误诊，且忽视不同PD阶段间的类别不平衡问题，影响预测性能。此外，现有方法多关注二元分类而非PD严重程度诊断。

Method: 提出了一种新的基于面部表情的方法，通过基于注意力的特征融合整合多种面部表情特征，并采用自适应类别平衡策略动态调整训练样本的贡献。

Result: 实验结果显示，所提方法在PD严重程度诊断中具有良好性能，且特征融合和类别平衡策略有效。

Conclusion: 实验结果表明，所提出的方法在帕金森病严重程度诊断中表现出色，同时基于注意力的特征融合和自适应类别平衡策略也证明了其有效性。

Abstract: Parkinson's disease (PD) severity diagnosis is crucial for early detecting
potential patients and adopting tailored interventions. Diagnosing PD based on
facial expression is grounded in PD patients' "masked face" symptom and gains
growing interest recently for its convenience and affordability. However,
current facial expression-based approaches often rely on single type of
expression which can lead to misdiagnosis, and ignore the class imbalance
across different PD stages which degrades the prediction performance. Moreover,
most existing methods focus on binary classification (i.e., PD / non-PD) rather
than diagnosing the severity of PD. To address these issues, we propose a new
facial expression-based method for PD severity diagnosis which integrates
multiple facial expression features through attention-based feature fusion.
Moreover, we mitigate the class imbalance problem via an adaptive class
balancing strategy which dynamically adjusts the contribution of training
samples based on their class distribution and classification difficulty.
Experimental results demonstrate the promising performance of the proposed
method for PD severity diagnosis, as well as the efficacy of attention-based
feature fusion and adaptive class balancing.

</details>


### [151] [Multilingual Text-to-Image Person Retrieval via Bidirectional Relation Reasoning and Aligning](https://arxiv.org/abs/2510.17685)
*Min Cao,Xinyu Zhou,Ding Jiang,Bo Du,Mang Ye,Min Zhang*

Main category: cs.CV

TL;DR: 提出Bi-IRRA框架，通过双向隐式关系推理和多维全局对齐解决多语言文本到图像人物检索的模态异质性问题，性能最优。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像人物检索中的模态异质性和多语言应用限制问题，现有方法在细粒度对齐和多语言支持上存在不足。

Method: 提出Bi-IRRA框架，包含双向隐式关系推理模块和多维全局对齐模块，用于跨语言和模态的对齐学习。

Result: 在所有多语言TIPR数据集上取得了最先进的性能。

Conclusion: Bi-IRRA框架在多语言TIPR任务中实现了最先进的性能，通过双向隐式关系推理和多维全局对齐模块有效解决了模态异质性和多语言挑战。

Abstract: Text-to-image person retrieval (TIPR) aims to identify the target person
using textual descriptions, facing challenge in modality heterogeneity. Prior
works have attempted to address it by developing cross-modal global or local
alignment strategies. However, global methods typically overlook fine-grained
cross-modal differences, whereas local methods require prior information to
explore explicit part alignments. Additionally, current methods are
English-centric, restricting their application in multilingual contexts. To
alleviate these issues, we pioneer a multilingual TIPR task by developing a
multilingual TIPR benchmark, for which we leverage large language models for
initial translations and refine them by integrating domain-specific knowledge.
Correspondingly, we propose Bi-IRRA: a Bidirectional Implicit Relation
Reasoning and Aligning framework to learn alignment across languages and
modalities. Within Bi-IRRA, a bidirectional implicit relation reasoning module
enables bidirectional prediction of masked image and text, implicitly enhancing
the modeling of local relations across languages and modalities, a
multi-dimensional global alignment module is integrated to bridge the modality
heterogeneity. The proposed method achieves new state-of-the-art results on all
multilingual TIPR datasets. Data and code are presented in
https://github.com/Flame-Chasers/Bi-IRRA.

</details>


### [152] [Closed-Loop Transfer for Weakly-supervised Affordance Grounding](https://arxiv.org/abs/2510.17384)
*Jiajin Tang,Zhengxuan Wei,Ge Zheng,Sibei Yang*

Main category: cs.CV

TL;DR: LoopTrans通过闭环框架和跨模态机制，有效提升跨视角知识转移，适用于复杂交互场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅从外中心视角单向转移到自我中心视角，限制了在复杂交互场景中的应用。

Method: 引入LoopTrans闭环框架，包括统一的跨模态定位和去噪知识蒸馏机制，以弥合视角差异并增强知识转移。

Result: 实验表明，LoopTrans在所有图像和视频基准测试中均取得一致改进，甚至能处理完全被人体遮挡的交互区域。

Conclusion: LoopTrans通过闭环框架和创新的跨模态定位及去噪知识蒸馏机制，显著提升了跨视角知识转移的效果，即使在复杂交互场景下也能有效处理。

Abstract: Humans can perform previously unexperienced interactions with novel objects
simply by observing others engage with them. Weakly-supervised affordance
grounding mimics this process by learning to locate object regions that enable
actions on egocentric images, using exocentric interaction images with
image-level annotations. However, extracting affordance knowledge solely from
exocentric images and transferring it one-way to egocentric images limits the
applicability of previous works in complex interaction scenarios. Instead, this
study introduces LoopTrans, a novel closed-loop framework that not only
transfers knowledge from exocentric to egocentric but also transfers back to
enhance exocentric knowledge extraction. Within LoopTrans, several innovative
mechanisms are introduced, including unified cross-modal localization and
denoising knowledge distillation, to bridge domain gaps between object-centered
egocentric and interaction-centered exocentric images while enhancing knowledge
transfer. Experiments show that LoopTrans achieves consistent improvements
across all metrics on image and video benchmarks, even handling challenging
scenarios where object interaction regions are fully occluded by the human
body.

</details>


### [153] [Improving Cross-Patient Generalization in Parkinson's Disease Detection through Chunk-Based Analysis of Hand-Drawn Patterns](https://arxiv.org/abs/2510.17703)
*Mhd Adnan Albani,Riad Sonbol*

Main category: cs.CV

TL;DR: 提出一种两阶段方法，通过分块和集成策略显著提升帕金森病检测的准确率，尤其在未见患者数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在数据集不足和处理未见患者数据时表现不佳，亟需一种更稳健的检测方法。

Method: 采用两阶段方法：第一阶段根据绘图类型分类，第二阶段通过分块策略（2x2分块）提取特征并检测帕金森病，最后使用集成方法合并决策。

Result: 在NewHandPD数据集上，对已知患者的准确率为97.08%，对未见患者的准确率为94.91%，性能差距仅为2.17个百分点。

Conclusion: 提出的两阶段方法在检测帕金森病方面表现出色，尤其是在处理未见患者数据时，性能显著优于现有技术。

Abstract: Parkinson's disease (PD) is a neurodegenerative disease affecting about 1% of
people over the age of 60, causing motor impairments that impede hand
coordination activities such as writing and drawing. Many approaches have tried
to support early detection of Parkinson's disease based on hand-drawn images;
however, we identified two major limitations in the related works: (1) the lack
of sufficient datasets, (2) the robustness when dealing with unseen patient
data. In this paper, we propose a new approach to detect Parkinson's disease
that consists of two stages: The first stage classifies based on their drawing
type(circle, meander, spiral), and the second stage extracts the required
features from the images and detects Parkinson's disease. We overcame the
previous two limitations by applying a chunking strategy where we divide each
image into 2x2 chunks. Each chunk is processed separately when extracting
features and recognizing Parkinson's disease indicators. To make the final
classification, an ensemble method is used to merge the decisions made from
each chunk. Our evaluation shows that our proposed approach outperforms the top
performing state-of-the-art approaches, in particular on unseen patients. On
the NewHandPD dataset our approach, it achieved 97.08% accuracy for seen
patients and 94.91% for unseen patients, our proposed approach maintained a gap
of only 2.17 percentage points, compared to the 4.76-point drop observed in
prior work.

</details>


### [154] [Monitoring Horses in Stalls: From Object to Event Detection](https://arxiv.org/abs/2510.17409)
*Dmitrii Galimzianov,Viacheslav Vyshegorodtsev,Ivan Nezhivykh*

Main category: cs.CV

TL;DR: 开发了一个基于视觉的马厩监测系统，自动检测和跟踪马匹与人，为实时行为监测提供基础。


<details>
  <summary>Details</summary>
Motivation: 监测马匹行为对早期发现健康与福利问题至关重要，但现有方法劳动密集且耗时。

Method: 利用YOLOv11和BoT-SORT进行检测和跟踪，通过物体轨迹和空间关系推断事件状态。

Result: 定性评估显示系统在马相关事件上表现可靠，但在检测人员方面存在数据不足的局限性。

Conclusion: 本研究为马厩实时行为监测奠定了基础，对动物福利和稳定管理具有潜在影响。

Abstract: Monitoring the behavior of stalled horses is essential for early detection of
health and welfare issues but remains labor-intensive and time-consuming. In
this study, we present a prototype vision-based monitoring system that
automates the detection and tracking of horses and people inside stables using
object detection and multi-object tracking techniques. The system leverages
YOLOv11 and BoT-SORT for detection and tracking, while event states are
inferred based on object trajectories and spatial relations within the stall.
To support development, we constructed a custom dataset annotated with
assistance from foundation models CLIP and GroundingDINO. The system
distinguishes between five event types and accounts for the camera's blind
spots. Qualitative evaluation demonstrated reliable performance for
horse-related events, while highlighting limitations in detecting people due to
data scarcity. This work provides a foundation for real-time behavioral
monitoring in equine facilities, with implications for animal welfare and
stable management.

</details>


### [155] [MT-Video-Bench: A Holistic Video Understanding Benchmark for Evaluating Multimodal LLMs in Multi-Turn Dialogues](https://arxiv.org/abs/2510.17722)
*Yaning Pan,Zekun Wang,Qianqian Xie,Yongqian Wen,Yuanxing Zhang,Guohui Zhang,Haoxuan Hu,Zhiyu Pan,Yibing Huang,Zhidong Gan,Yonghong Lin,An Ping,Tianhao Peng,Jiaheng Liu*

Main category: cs.CV

TL;DR: MT-Video-Bench是一个针对多模态大语言模型的多轮视频对话评估基准，揭示了现有模型的局限性，并促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准仅关注单轮问答，无法反映真实场景中多轮对话的复杂性，因此需要一个新的评估标准。

Method: 通过构建包含987个精心策划的多轮对话的MT-Video-Bench，评估了多种开源和闭源MLLM在六项核心能力上的表现。

Result: 评估结果显示，现有MLLM在处理多轮视频对话时存在显著性能差异和局限性。

Conclusion: MT-Video-Bench的引入填补了多模态大语言模型在多轮视频对话评估领域的空白，揭示了现有模型在处理复杂多轮对话时的局限性，为未来研究提供了公开的基准。

Abstract: The recent development of Multimodal Large Language Models (MLLMs) has
significantly advanced AI's ability to understand visual modalities. However,
existing evaluation benchmarks remain limited to single-turn question
answering, overlooking the complexity of multi-turn dialogues in real-world
scenarios. To bridge this gap, we introduce MT-Video-Bench, a holistic video
understanding benchmark for evaluating MLLMs in multi-turn dialogues.
Specifically, our MT-Video-Bench mainly assesses six core competencies that
focus on perceptivity and interactivity, encompassing 987 meticulously curated
multi-turn dialogues from diverse domains. These capabilities are rigorously
aligned with real-world applications, such as interactive sports analysis and
multi-turn video-based intelligent tutoring. With MT-Video-Bench, we
extensively evaluate various state-of-the-art open-source and closed-source
MLLMs, revealing their significant performance discrepancies and limitations in
handling multi-turn video dialogues. The benchmark will be publicly available
to foster future research.

</details>


### [156] [DeepDetect: Learning All-in-One Dense Keypoints](https://arxiv.org/abs/2510.17422)
*Shaharyar Ahmed Khan Tareen,Filza Khan Tareen*

Main category: cs.CV

TL;DR: DeepDetect是一种智能、一体化、高密度的关键点检测器，通过深度学习融合传统检测器优势，在关键指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统及基于学习的关键点检测器存在对光度变化敏感、关键点密度和重复性低、适应性有限、缺乏语义理解等问题，无法优先处理视觉重要区域。

Method: 首先，通过融合7种关键点和2种边缘检测器的输出创建地面真实掩码，提取多样化的视觉线索；然后，使用ESPNet这一轻量高效模型进行训练，使DeepDetect能够语义化地关注图像并生成高密度关键点。

Result: 在Oxford Affine Covariant Regions数据集上的评估显示，DeepDetect在关键点密度（0.5143）、重复性（0.9582）和正确匹配数（59,003）上均达到最高值。

Conclusion: DeepDetect通过深度学习统一了传统检测器的优势，在关键点密度、重复性和正确匹配数上超越了现有方法，展现出在多样化及视觉退化条件下的强大适应性。

Abstract: Keypoint detection is the foundation of many computer vision tasks, including
image registration, structure-from motion, 3D reconstruction, visual odometry,
and SLAM. Traditional detectors (SIFT, SURF, ORB, BRISK, etc.) and learning
based methods (SuperPoint, R2D2, LF-Net, D2-Net, etc.) have shown strong
performance yet suffer from key limitations: sensitivity to photometric
changes, low keypoint density and repeatability, limited adaptability to
challenging scenes, and lack of semantic understanding, often failing to
prioritize visually important regions. We present DeepDetect, an intelligent,
all-in-one, dense keypoint detector that unifies the strengths of classical
detectors using deep learning. Firstly, we create ground-truth masks by fusing
outputs of 7 keypoint and 2 edge detectors, extracting diverse visual cues from
corners and blobs to prominent edges and textures in the images. Afterwards, a
lightweight and efficient model: ESPNet, is trained using these masks as
labels, enabling DeepDetect to focus semantically on images while producing
highly dense keypoints, that are adaptable to diverse and visually degraded
conditions. Evaluations on the Oxford Affine Covariant Regions dataset
demonstrate that DeepDetect surpasses other detectors in keypoint density,
repeatability, and the number of correct matches, achieving maximum values of
0.5143 (average keypoint density), 0.9582 (average repeatability), and 59,003
(correct matches).

</details>


### [157] [Signature Forgery Detection: Improving Cross-Dataset Generalization](https://arxiv.org/abs/2510.17724)
*Matheus Ramos Parracho*

Main category: cs.CV

TL;DR: 研究比较了基于原始图像和shell预处理的签名验证方法，发现原始图像模型表现更优，但shell预处理模型有改进潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在离线签名验证中取得了显著进展，但大多数方法在跨数据集泛化方面仍存在困难，因此本研究旨在探索特征学习策略以提高签名伪造检测的跨数据集泛化能力。

Method: 研究开发了两条实验流程：一条基于原始签名图像，另一条采用称为shell预处理的预处理方法。

Result: 基于原始图像的模型在基准测试中表现更优，而shell预处理模型显示出未来改进的潜力。

Conclusion: 该研究未明确确定两种方法的优劣，但发现基于原始图像的模型在多个基准测试中表现更优，而基于shell预处理的模型显示出未来改进的潜力。

Abstract: Automated signature verification is a critical biometric technique used in
banking, identity authentication, and legal documentation. Despite the notable
progress achieved by deep learning methods, most approaches in offline
signature verification still struggle to generalize across datasets, as
variations in handwriting styles and acquisition protocols often degrade
performance. This study investigates feature learning strategies for signature
forgery detection, focusing on improving cross-dataset generalization -- that
is, model robustness when trained on one dataset and tested on another. Using
three public benchmarks -- CEDAR, ICDAR, and GPDS Synthetic -- two experimental
pipelines were developed: one based on raw signature images and another
employing a preprocessing method referred to as shell preprocessing. Several
behavioral patterns were identified and analyzed; however, no definitive
superiority between the two approaches was established. The results show that
the raw-image model achieved higher performance across benchmarks, while the
shell-based model demonstrated promising potential for future refinement toward
robust, cross-domain signature verification.

</details>


### [158] [Leveraging AV1 motion vectors for Fast and Dense Feature Matching](https://arxiv.org/abs/2510.17434)
*Julien Zouein,Hossein Javidnia,François Pitié,Anil Kokaram*

Main category: cs.CV

TL;DR: 利用AV1运动矢量生成密集对应关系，在低CPU消耗下实现与SIFT相当的匹配效果，适用于短视频场景。


<details>
  <summary>Details</summary>
Motivation: 在短视频上，该方法在CPU使用量远低于顺序SIFT的情况下，表现相当，并产生更密集的匹配。

Method: 重新利用AV1运动矢量生成密集子像素对应关系，并通过余弦一致性过滤短轨迹。

Result: 在117帧的片段上，MV匹配注册了所有图像，并重建了0.46-0.62M个点，重投影误差为0.51-0.53像素；BA时间随匹配密度增加而增长。

Conclusion: 压缩域对应关系是一种实用且资源高效的前端方法，具有在完整流程中扩展的明确路径。

Abstract: We repurpose AV1 motion vectors to produce dense sub-pixel correspondences
and short tracks filtered by cosine consistency. On short videos, this
compressed-domain front end runs comparably to sequential SIFT while using far
less CPU, and yields denser matches with competitive pairwise geometry. As a
small SfM demo on a 117-frame clip, MV matches register all images and
reconstruct 0.46-0.62M points at 0.51-0.53,px reprojection error; BA time grows
with match density. These results show compressed-domain correspondences are a
practical, resource-efficient front end with clear paths to scaling in full
pipelines.

</details>


### [159] [Towards Explainable Skin Cancer Classification: A Dual-Network Attention Model with Lesion Segmentation and Clinical Metadata Fusion](https://arxiv.org/abs/2510.17773)
*Md. Enamul Atiq,Shaikh Anowarul Fattah*

Main category: cs.CV

TL;DR: 该研究提出了一种结合病灶分割和临床数据的双编码器注意力框架，显著提升了皮肤癌分类的准确性和可解释性，并在多个数据集上验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是一种危及生命的疾病，早期检测显著改善患者预后。由于高类内变异性和细微的类间差异，自动化诊断具有挑战性，且许多深度学习模型作为“黑盒子”限制了临床信任。

Method: 提出了一种双编码器注意力框架，结合分割病灶和临床元数据进行皮肤病变分类。采用带双注意门（DAG）和空洞空间金字塔池化（ASPP）的Deep-UNet架构进行病灶分割，分类阶段使用两个DenseNet201编码器（一个用于原始图像，另一个用于分割病灶），并通过多头交叉注意力融合特征。此外，还通过基于变压器的模块整合患者元数据（年龄、性别、病灶部位）。

Result: 在HAM10000数据集及ISIC 2018和2019挑战中，该方法实现了最先进的病灶分割性能，并显著提高了分类准确率和平均AUC。通过Grad-CAM生成的热图验证了模型的可靠性，确认其预测基于病灶区域而非虚假背景特征。

Conclusion: 该研究通过结合精确的病灶分割、临床数据和基于注意力的融合，提出了一个更准确且可解释的皮肤癌分类模型。

Abstract: Skin cancer is a life-threatening disease where early detection significantly
improves patient outcomes. Automated diagnosis from dermoscopic images is
challenging due to high intra-class variability and subtle inter-class
differences. Many deep learning models operate as "black boxes," limiting
clinical trust. In this work, we propose a dual-encoder attention-based
framework that leverages both segmented lesions and clinical metadata to
enhance skin lesion classification in terms of both accuracy and
interpretability. A novel Deep-UNet architecture with Dual Attention Gates
(DAG) and Atrous Spatial Pyramid Pooling (ASPP) is first employed to segment
lesions. The classification stage uses two DenseNet201 encoders-one on the
original image and another on the segmented lesion whose features are fused via
multi-head cross-attention. This dual-input design guides the model to focus on
salient pathological regions. In addition, a transformer-based module
incorporates patient metadata (age, sex, lesion site) into the prediction. We
evaluate our approach on the HAM10000 dataset and the ISIC 2018 and 2019
challenges. The proposed method achieves state-of-the-art segmentation
performance and significantly improves classification accuracy and average AUC
compared to baseline models. To validate our model's reliability, we use
Gradient-weighted Class Activation Mapping (Grad-CAM) to generate heatmaps.
These visualizations confirm that our model's predictions are based on the
lesion area, unlike models that rely on spurious background features. These
results demonstrate that integrating precise lesion segmentation and clinical
data with attention-based fusion leads to a more accurate and interpretable
skin cancer classification model.

</details>


### [160] [Rethinking Nighttime Image Deraining via Learnable Color Space Transformation](https://arxiv.org/abs/2510.17440)
*Qiyuan Guan,Xiang Chen,Guiyue Jin,Jiyu Jin,Shumin Fan,Tianyu Song,Jinshan Pan*

Main category: cs.CV

TL;DR: Proposes HQ-NightRain dataset and CST-Net for nighttime image deraining, using a learnable color space converter and implicit illumination guidance to improve rain removal in complex nighttime scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the lack of high-quality datasets and the inherent complexities of nighttime image deraining, particularly the coupling effect between rain and illumination.

Method: The method involves a learnable color space converter (CSC) for rain removal in the Y channel and implicit illumination guidance to enhance robustness in complex nighttime scenarios.

Result: Extensive experiments validate the effectiveness of the CST-Net and the high harmony and realism of the HQ-NightRain dataset.

Conclusion: The paper concludes that the proposed HQ-NightRain dataset and CST-Net method significantly improve nighttime image deraining by addressing the challenges of rain and illumination coupling, demonstrating superior performance in experiments.

Abstract: Compared to daytime image deraining, nighttime image deraining poses
significant challenges due to inherent complexities of nighttime scenarios and
the lack of high-quality datasets that accurately represent the coupling effect
between rain and illumination. In this paper, we rethink the task of nighttime
image deraining and contribute a new high-quality benchmark, HQ-NightRain,
which offers higher harmony and realism compared to existing datasets. In
addition, we develop an effective Color Space Transformation Network (CST-Net)
for better removing complex rain from nighttime scenes. Specifically, we
propose a learnable color space converter (CSC) to better facilitate rain
removal in the Y channel, as nighttime rain is more pronounced in the Y channel
compared to the RGB color space. To capture illumination information for
guiding nighttime deraining, implicit illumination guidance is introduced
enabling the learned features to improve the model's robustness in complex
scenarios. Extensive experiments show the value of our dataset and the
effectiveness of our method. The source code and datasets are available at
https://github.com/guanqiyuan/CST-Net.

</details>


### [161] [Initialize to Generalize: A Stronger Initialization Pipeline for Sparse-View 3DGS](https://arxiv.org/abs/2510.17479)
*Feng Zhou,Wenkai Guo,Pu Cao,Zhicheng Zhang,Jianqin Yin*

Main category: cs.CV

TL;DR: 论文提出了一种改进3D高斯溅射初始化的方法，通过频率感知SfM、自初始化和点云正则化，显著提升了稀疏视图渲染质量。


<details>
  <summary>Details</summary>
Motivation: 稀疏视图3DGS容易过拟合训练视图，导致新视图渲染出现模糊等问题。现有方法多关注训练时约束，但初始化才是决定性因素。

Method: 设计了频率感知SfM以提升低纹理覆盖，3DGS自初始化通过光度监督生成额外点，以及点云正则化通过几何/可见性先验确保一致性和均匀覆盖。

Result: 在LLFF和Mip-NeRF360数据集上的实验表明，该方法在稀疏视图设置下取得了稳定的性能提升。

Conclusion: 论文提出了一种针对稀疏视图3D高斯溅射（3DGS）的更强初始化策略，通过改进SfM初始化、3DGS自初始化及点云正则化，显著提升了稀疏视图下的渲染性能。

Abstract: Sparse-view 3D Gaussian Splatting (3DGS) often overfits to the training
views, leading to artifacts like blurring in novel view rendering. Prior work
addresses it either by enhancing the initialization (\emph{i.e.}, the point
cloud from Structure-from-Motion (SfM)) or by adding training-time constraints
(regularization) to the 3DGS optimization. Yet our controlled ablations reveal
that initialization is the decisive factor: it determines the attainable
performance band in sparse-view 3DGS, while training-time constraints yield
only modest within-band improvements at extra cost. Given initialization's
primacy, we focus our design there. Although SfM performs poorly under sparse
views due to its reliance on feature matching, it still provides reliable seed
points. Thus, building on SfM, our effort aims to supplement the regions it
fails to cover as comprehensively as possible. Specifically, we design: (i)
frequency-aware SfM that improves low-texture coverage via low-frequency view
augmentation and relaxed multi-view correspondences; (ii) 3DGS
self-initialization that lifts photometric supervision into additional points,
compensating SfM-sparse regions with learned Gaussian centers; and (iii)
point-cloud regularization that enforces multi-view consistency and uniform
spatial coverage through simple geometric/visibility priors, yielding a clean
and reliable point cloud. Our experiments on LLFF and Mip-NeRF360 demonstrate
consistent gains in sparse-view settings, establishing our approach as a
stronger initialization strategy. Code is available at
https://github.com/zss171999645/ItG-GS.

</details>


### [162] [Split-Fuse-Transport: Annotation-Free Saliency via Dual Clustering and Optimal Transport Alignment](https://arxiv.org/abs/2510.17484)
*Muhammad Umer Ramzan,Ali Zia,Abdelwahed Khamis,Noman Ali,Usman Ali,Wei Xiang*

Main category: cs.CV

TL;DR: AutoSOD通过改进伪掩码生成方法，显著提升了无监督显著目标检测的性能。


<details>
  <summary>Details</summary>
Motivation: 解决无监督显著目标检测中伪掩码质量不足的问题，提升检测准确性和训练效率。

Method: 提出POTNet，采用熵引导的双聚类头（谱聚类和k-means）结合最优传输生成伪掩码，并用于训练MaskFormer风格的编码器-解码器。

Result: 在五个基准测试中，AutoSOD在F-measure上比无监督方法提升26%，比弱监督方法提升36%。

Conclusion: AutoSOD通过结合POTNet的双聚类头和最优传输，显著提升了无监督显著目标检测的性能，缩小了与全监督模型的差距。

Abstract: Salient object detection (SOD) aims to segment visually prominent regions in
images and serves as a foundational task for various computer vision
applications. We posit that SOD can now reach near-supervised accuracy without
a single pixel-level label, but only when reliable pseudo-masks are available.
We revisit the prototype-based line of work and make two key observations.
First, boundary pixels and interior pixels obey markedly different geometry;
second, the global consistency enforced by optimal transport (OT) is
underutilized if prototype quality is weak. To address this, we introduce
POTNet, an adaptation of Prototypical Optimal Transport that replaces POT's
single k-means step with an entropy-guided dual-clustering head: high-entropy
pixels are organized by spectral clustering, low-entropy pixels by k-means, and
the two prototype sets are subsequently aligned by OT. This
split-fuse-transport design yields sharper, part-aware pseudo-masks in a single
forward pass, without handcrafted priors. Those masks supervise a standard
MaskFormer-style encoder-decoder, giving rise to AutoSOD, an end-to-end
unsupervised SOD pipeline that eliminates SelfMask's offline voting yet
improves both accuracy and training efficiency. Extensive experiments on five
benchmarks show that AutoSOD outperforms unsupervised methods by up to 26% and
weakly supervised methods by up to 36% in F-measure, further narrowing the gap
to fully supervised models.

</details>


### [163] [WP-CrackNet: A Collaborative Adversarial Learning Framework for End-to-End Weakly-Supervised Road Crack Detection](https://arxiv.org/abs/2510.17566)
*Nachuan Ma,Zhengfei Song,Qiang Hu,Xiaoyu Tang,Chengxi Zhang,Rui Fan,Lihua Xie*

Main category: cs.CV

TL;DR: WP-CrackNet是一种弱监督道路裂缝检测方法，通过集成分类器、重建器和检测器，结合PAAM和CECCM模块，实现了高效且可扩展的检测效果。


<details>
  <summary>Details</summary>
Motivation: 减少对昂贵像素级标注的依赖，实现智能基础设施维护中的高效道路裂缝检测。

Method: WP-CrackNet集成了分类器、重建器和检测器三个组件，通过对抗学习和伪标签训练实现裂缝检测。此外，设计了路径感知注意力模块（PAAM）和中心增强CAM一致性模块（CECCM）以优化检测性能。

Result: 实验表明，WP-CrackNet在仅使用图像级标签的情况下，达到了与全监督方法相当的效果，并优于现有弱监督方法。

Conclusion: WP-CrackNet通过弱监督方法实现了与全监督方法相当的裂缝检测效果，显著提升了道路检测的可扩展性。

Abstract: Road crack detection is essential for intelligent infrastructure maintenance
in smart cities. To reduce reliance on costly pixel-level annotations, we
propose WP-CrackNet, an end-to-end weakly-supervised method that trains with
only image-level labels for pixel-wise crack detection. WP-CrackNet integrates
three components: a classifier generating class activation maps (CAMs), a
reconstructor measuring feature inferability, and a detector producing
pixel-wise road crack detection results. During training, the classifier and
reconstructor alternate in adversarial learning to encourage crack CAMs to
cover complete crack regions, while the detector learns from pseudo labels
derived from post-processed crack CAMs. This mutual feedback among the three
components improves learning stability and detection accuracy. To further boost
detection performance, we design a path-aware attention module (PAAM) that
fuses high-level semantics from the classifier with low-level structural cues
from the reconstructor by modeling spatial and channel-wise dependencies.
Additionally, a center-enhanced CAM consistency module (CECCM) is proposed to
refine crack CAMs using center Gaussian weighting and consistency constraints,
enabling better pseudo-label generation. We create three image-level datasets
and extensive experiments show that WP-CrackNet achieves comparable results to
supervised methods and outperforms existing weakly-supervised methods,
significantly advancing scalable road inspection. The source code package and
datasets are available at https://mias.group/WP-CrackNet/.

</details>


### [164] [PAGE-4D: Disentangled Pose and Geometry Estimation for 4D Perception](https://arxiv.org/abs/2510.17568)
*Kaichen Zhou,Yuhan Wang,Grace Chen,Xinhai Chang,Gaspard Beaudouin,Fangneng Zhan,Paul Pu Liang,Mengyu Wang*

Main category: cs.CV

TL;DR: PAGE-4D通过动态感知掩码解决静态与动态信息冲突，在动态场景中超越VGGT，实现多任务3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有3D前馈模型（如VGGT）在静态场景表现优异，但在动态场景（如移动人体或可变形物体）中表现不佳。

Method: 提出了一种动态感知聚合器，通过预测动态感知掩码分离静态与动态信息，优化相机姿态估计和几何重建。

Result: PAGE-4D在动态场景中 consistently 优于VGGT，在相机姿态估计、单目和视频深度估计及密集点云重建中取得更优结果。

Conclusion: PAGE-4D通过动态感知聚合器解决了静态与动态信息处理的冲突，在动态场景中显著优于VGGT，实现了相机姿态估计、深度预测和点云重建的多任务优化。

Abstract: Recent 3D feed-forward models, such as the Visual Geometry Grounded
Transformer (VGGT), have shown strong capability in inferring 3D attributes of
static scenes. However, since they are typically trained on static datasets,
these models often struggle in real-world scenarios involving complex dynamic
elements, such as moving humans or deformable objects like umbrellas. To
address this limitation, we introduce PAGE-4D, a feedforward model that extends
VGGT to dynamic scenes, enabling camera pose estimation, depth prediction, and
point cloud reconstruction -- all without post-processing. A central challenge
in multi-task 4D reconstruction is the inherent conflict between tasks:
accurate camera pose estimation requires suppressing dynamic regions, while
geometry reconstruction requires modeling them. To resolve this tension, we
propose a dynamics-aware aggregator that disentangles static and dynamic
information by predicting a dynamics-aware mask -- suppressing motion cues for
pose estimation while amplifying them for geometry reconstruction. Extensive
experiments show that PAGE-4D consistently outperforms the original VGGT in
dynamic scenarios, achieving superior results in camera pose estimation,
monocular and video depth estimation, and dense point map reconstruction.

</details>


### [165] [Expose Camouflage in the Water: Underwater Camouflaged Instance Segmentation and Dataset](https://arxiv.org/abs/2510.17585)
*Chuhong Wang,Hua Li,Chongyi Li,Huazhong Liu,Xiongxin Tang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出首个水下伪装实例分割数据集UCIS4K和UCIS-SAM网络，通过三个模块优化特征学习、频域整合和多尺度聚合，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的伪装实例分割面临颜色失真、低对比度和模糊等挑战，传统方法在陆地数据集上训练，水下性能不足。

Method: 提出了基于Segment Anything Model的UCIS-SAM网络，包含三个关键模块：CBOM、FDTIM和MFFAM，分别优化通道特征、整合频域信息和聚合多尺度特征。

Result: UCIS-SAM在UCIS4K数据集和公共基准测试中优于现有方法。

Conclusion: UCIS-SAM网络在UCIS4K数据集和公共基准测试中表现优异，显著提升了水下伪装实例分割的准确性。

Abstract: With the development of underwater exploration and marine protection,
underwater vision tasks are widespread. Due to the degraded underwater
environment, characterized by color distortion, low contrast, and blurring,
camouflaged instance segmentation (CIS) faces greater challenges in accurately
segmenting objects that blend closely with their surroundings. Traditional
camouflaged instance segmentation methods, trained on terrestrial-dominated
datasets with limited underwater samples, may exhibit inadequate performance in
underwater scenes. To address these issues, we introduce the first underwater
camouflaged instance segmentation (UCIS) dataset, abbreviated as UCIS4K, which
comprises 3,953 images of camouflaged marine organisms with instance-level
annotations. In addition, we propose an Underwater Camouflaged Instance
Segmentation network based on Segment Anything Model (UCIS-SAM). Our UCIS-SAM
includes three key modules. First, the Channel Balance Optimization Module
(CBOM) enhances channel characteristics to improve underwater feature learning,
effectively addressing the model's limited understanding of underwater
environments. Second, the Frequency Domain True Integration Module (FDTIM) is
proposed to emphasize intrinsic object features and reduce interference from
camouflage patterns, enhancing the segmentation performance of camouflaged
objects blending with their surroundings. Finally, the Multi-scale Feature
Frequency Aggregation Module (MFFAM) is designed to strengthen the boundaries
of low-contrast camouflaged instances across multiple frequency bands,
improving the model's ability to achieve more precise segmentation of
camouflaged objects. Extensive experiments on the proposed UCIS4K and public
benchmarks show that our UCIS-SAM outperforms state-of-the-art approaches.

</details>


### [166] [ShapeCraft: LLM Agents for Structured, Textured and Interactive 3D Modeling](https://arxiv.org/abs/2510.17603)
*Shuyuan Zhang,Chenhan Jiang,Zuoou Li,Jiankang Deng*

Main category: cs.CV

TL;DR: ShapeCraft是一种多代理框架，通过GPS表示将文本转化为结构化、可交互的3D资产，解决了现有方法的非结构化和低交互性问题。


<details>
  <summary>Details</summary>
Motivation: 现有文本到3D生成方法常产生非结构化网格且交互性差，难以满足艺术工作流程需求。ShapeCraft旨在通过结构化表示和交互式生成解决这些问题。

Method: ShapeCraft采用基于图的程序形状（GPS）表示，将复杂自然语言分解为结构化子任务图，利用LLM代理层次化解析用户输入并迭代优化程序建模和绘画过程。

Result: 定性和定量实验表明，ShapeCraft在生成几何准确且语义丰富的3D资产方面优于现有基于LLM的代理，并展示了其在动画和用户定制编辑中的多功能性。

Conclusion: ShapeCraft通过其创新的GPS表示和多代理框架，显著提升了文本到3D生成的几何准确性和语义丰富性，展示了在动画和用户定制编辑中的广泛应用潜力。

Abstract: 3D generation from natural language offers significant potential to reduce
expert manual modeling efforts and enhance accessibility to 3D assets. However,
existing methods often yield unstructured meshes and exhibit poor
interactivity, making them impractical for artistic workflows. To address these
limitations, we represent 3D assets as shape programs and introduce ShapeCraft,
a novel multi-agent framework for text-to-3D generation. At its core, we
propose a Graph-based Procedural Shape (GPS) representation that decomposes
complex natural language into a structured graph of sub-tasks, thereby
facilitating accurate LLM comprehension and interpretation of spatial
relationships and semantic shape details. Specifically, LLM agents
hierarchically parse user input to initialize GPS, then iteratively refine
procedural modeling and painting to produce structured, textured, and
interactive 3D assets. Qualitative and quantitative experiments demonstrate
ShapeCraft's superior performance in generating geometrically accurate and
semantically rich 3D assets compared to existing LLM-based agents. We further
show the versatility of ShapeCraft through examples of animated and
user-customized editing, highlighting its potential for broader interactive
applications.

</details>


### [167] [Integrating BIM and UAV-based photogrammetry for Automated 3D Structure Model Segmentation](https://arxiv.org/abs/2510.17609)
*Siqi Chen,Shanyue Guan*

Main category: cs.CV

TL;DR: 无人机与BIM结合的机器学习框架，实现高效自动化3D点云分割，提升基础设施监测精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统依赖耗时且易出错的手动标记方法在分割3D模型中的关键挑战。

Method: 结合无人机扫描的真实点云数据和BIM生成的合成数据，利用机器学习进行自动化分割。

Result: 在铁路轨道数据集上的验证表明，该方法能高精度识别和分割主要组件（如铁轨和枕木），并通过补充BIM数据显著减少训练时间，同时保持合理的分割精度。

Conclusion: 该论文提出了一种基于机器学习的自动化3D点云分割框架，有效提高了基础设施模型分割的精度和效率，并推动了无人机与BIM技术在结构健康监测中的整合。

Abstract: The advancement of UAV technology has enabled efficient, non-contact
structural health monitoring. Combined with photogrammetry, UAVs can capture
high-resolution scans and reconstruct detailed 3D models of infrastructure.
However, a key challenge remains in segmenting specific structural components
from these models-a process traditionally reliant on time-consuming and
error-prone manual labeling. To address this issue, we propose a machine
learning-based framework for automated segmentation of 3D point clouds. Our
approach uses the complementary strengths of real-world UAV-scanned point
clouds and synthetic data generated from Building Information Modeling (BIM) to
overcome the limitations associated with manual labeling. Validation on a
railroad track dataset demonstrated high accuracy in identifying and segmenting
major components such as rails and crossties. Moreover, by using smaller-scale
datasets supplemented with BIM data, the framework significantly reduced
training time while maintaining reasonable segmentation accuracy. This
automated approach improves the precision and efficiency of 3D infrastructure
model segmentation and advances the integration of UAV and BIM technologies in
structural health monitoring and infrastructure management.

</details>


### [168] [One Dinomaly2 Detect Them All: A Unified Framework for Full-Spectrum Unsupervised Anomaly Detection](https://arxiv.org/abs/2510.17611)
*Jia Guo,Shuai Lu,Lei Fan,Zelin Li,Donglin Di,Yang Song,Weihang Zhang,Wenbing Zhu,Hong Yan,Fang Chen,Huiqi Li,Hongen Liao*

Main category: cs.CV

TL;DR: Dinomaly2是首个全谱图像异常检测统一框架，通过简约设计在多类、多模态及少样本任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决现有多类模型性能不足及领域碎片化问题，提出统一框架以满足全谱图像异常检测需求。

Method: Dinomaly2通过协调五个简单元素在标准重构框架中实现卓越性能，无需修改即可自然扩展到多样化任务。

Result: 在12个UAD基准测试中表现优异，多类模型在MVTec-AD和VisA上分别达到99.9%和99.3%的I-AUROC，少样本设置下也超越之前全样本模型。

Conclusion: Dinomaly2通过简约设计和计算扩展性，成为全谱异常检测的统一解决方案，展示了真实世界应用的广泛适用性。

Abstract: Unsupervised anomaly detection (UAD) has evolved from building specialized
single-class models to unified multi-class models, yet existing multi-class
models significantly underperform the most advanced one-for-one counterparts.
Moreover, the field has fragmented into specialized methods tailored to
specific scenarios (multi-class, 3D, few-shot, etc.), creating deployment
barriers and highlighting the need for a unified solution. In this paper, we
present Dinomaly2, the first unified framework for full-spectrum image UAD,
which bridges the performance gap in multi-class models while seamlessly
extending across diverse data modalities and task settings. Guided by the "less
is more" philosophy, we demonstrate that the orchestration of five simple
element achieves superior performance in a standard reconstruction-based
framework. This methodological minimalism enables natural extension across
diverse tasks without modification, establishing that simplicity is the
foundation of true universality. Extensive experiments on 12 UAD benchmarks
demonstrate Dinomaly2's full-spectrum superiority across multiple modalities
(2D, multi-view, RGB-3D, RGB-IR), task settings (single-class, multi-class,
inference-unified multi-class, few-shot) and application domains (industrial,
biological, outdoor). For example, our multi-class model achieves unprecedented
99.9% and 99.3% image-level (I-) AUROC on MVTec-AD and VisA respectively. For
multi-view and multi-modal inspection, Dinomaly2 demonstrates state-of-the-art
performance with minimum adaptations. Moreover, using only 8 normal examples
per class, our method surpasses previous full-shot models, achieving 98.7% and
97.4% I-AUROC on MVTec-AD and VisA. The combination of minimalistic design,
computational scalability, and universal applicability positions Dinomaly2 as a
unified solution for the full spectrum of real-world anomaly detection
applications.

</details>


### [169] [Self-supervised Pre-training for Mapping of Archaeological Stone Wall in Historic Landscapes Using High-Resolution DEM Derivatives](https://arxiv.org/abs/2510.17644)
*Zexian Huang,Mashnoon Islam,Brian Armstrong,Kourosh Khoshelham,Martin Tomko*

Main category: cs.CV

TL;DR: DINO-CV是一种基于自监督学习的框架，利用高分辨率DEM自动映射干石墙，有效解决了植被遮挡和数据稀缺问题，在测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 干石墙具有重要的遗产和环境价值，但由于其难以接近和手动映射的高成本，许多墙未被识别。深度学习分割提供了可扩展的解决方案，但存在视觉遮挡和标记数据有限的挑战。

Method: DINO-CV引入了一种基于知识蒸馏的自监督跨视图预训练策略，以缓解数据稀缺问题。它学习跨多个DEM衍生物的视觉和几何表示，支持包括ResNet、Wide ResNet和Vision Transformers在内的各种视觉骨干。

Result: DINO-CV在测试区域的平均交并比（mIoU）达到68.6%，并且在使用仅10%标记数据微调时仍保持63.8%的mIoU。

Conclusion: DINO-CV展示了自监督学习在高分辨率DEM衍生物上对植被茂密且注释稀缺的遗产环境中自动干石墙映射的潜力。

Abstract: Dry-stone walls hold significant heritage and environmental value. Mapping
these structures is essential for ecosystem preservation and wildfire
management in Australia. Yet, many walls remain unidentified due to their
inaccessibility and the high cost of manual mapping. Deep learning-based
segmentation offers a scalable solution, but two major challenges persist: (1)
visual occlusion of low-lying walls by dense vegetation, and (2) limited
labeled data for supervised training. We propose DINO-CV, a segmentation
framework for automatic mapping of low-lying dry-stone walls using
high-resolution Airborne LiDAR-derived digital elevation models (DEMs). DEMs
overcome visual occlusion by capturing terrain structures hidden beneath
vegetation, enabling analysis of structural rather than spectral cues. DINO-CV
introduces a self-supervised cross-view pre-training strategy based on
knowledge distillation to mitigate data scarcity. It learns invariant visual
and geometric representations across multiple DEM derivatives, supporting
various vision backbones including ResNet, Wide ResNet, and Vision
Transformers. Applied to the UNESCO World Heritage cultural landscape of Budj
Bim, Victoria, the method identifies one of Australia's densest collections of
colonial dry-stone walls beyond Indigenous heritage contexts. DINO-CV achieves
a mean Intersection over Union (mIoU) of 68.6% on test areas and maintains
63.8% mIoU when fine-tuned with only 10% labeled data. These results
demonstrate the potential of self-supervised learning on high-resolution DEM
derivatives for automated dry-stone wall mapping in vegetated and heritage-rich
environments with scarce annotations.

</details>


### [170] [4DSegStreamer: Streaming 4D Panoptic Segmentation via Dual Threads](https://arxiv.org/abs/2510.17664)
*Ling Liu,Jun Tian,Li Yi*

Main category: cs.CV

TL;DR: 4DSegStreamer通过双线程系统实现实时4D全景分割，适用于动态环境，并在复杂场景中表现优越。


<details>
  <summary>Details</summary>
Motivation: 针对高动态环境（如密集人群疏散和自动驾驶）中实时、细粒度感知的需求。

Method: 采用双线程系统：预测线程利用历史运动与几何信息预测未来动态，推理线程确保对输入帧的及时预测。

Result: 在HOI4D、SemanticKITTI和nuScenes数据集上验证了框架的有效性，尤其在动态物体预测方面表现优异。

Conclusion: 4DSegStreamer框架通过双线程系统在动态环境中实现了高效的实时4D全景分割，尤其在复杂场景下表现出色。

Abstract: 4D panoptic segmentation in a streaming setting is critical for highly
dynamic environments, such as evacuating dense crowds and autonomous driving in
complex scenarios, where real-time, fine-grained perception within a
constrained time budget is essential. In this paper, we introduce
4DSegStreamer, a novel framework that employs a Dual-Thread System to
efficiently process streaming frames. The framework is general and can be
seamlessly integrated into existing 3D and 4D segmentation methods to enable
real-time capability. It also demonstrates superior robustness compared to
existing streaming perception approaches, particularly under high FPS
conditions. The system consists of a predictive thread and an inference thread.
The predictive thread leverages historical motion and geometric information to
extract features and forecast future dynamics. The inference thread ensures
timely prediction for incoming frames by aligning with the latest memory and
compensating for ego-motion and dynamic object movements. We evaluate
4DSegStreamer on the indoor HOI4D dataset and the outdoor SemanticKITTI and
nuScenes datasets. Comprehensive experiments demonstrate the effectiveness of
our approach, particularly in accurately predicting dynamic objects in complex
scenes.

</details>


### [171] [Towards 3D Objectness Learning in an Open World](https://arxiv.org/abs/2510.17686)
*Taichi Liu,Zhenyu Wang,Ruofeng Liu,Guang Wang,Desheng Zhang*

Main category: cs.CV

TL;DR: OP3Det是一种无需文本提示的开放世界3D检测器，结合2D和3D先验，通过跨模态学习实现广义3D物体发现，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统封闭集3D检测器在开放世界场景中泛化能力不足，而直接引入3D开放词汇模型则面临词汇扩展和语义重叠的挑战。

Method: 提出OP3Det，一种无需手工文本提示的开放世界3D检测器，结合2D语义先验和3D几何先验，通过跨模态专家混合动态路由单模态和多模态特征。

Result: OP3Det在AR指标上显著超越现有开放世界3D检测器16.0%，相比封闭世界3D检测器提升13.5%。

Conclusion: OP3Det显著超越了现有的开放世界3D检测器，并在封闭世界3D检测器中表现出色，展示了其在广义3D物体发现中的卓越性能。

Abstract: Recent advancements in 3D object detection and novel category detection have
made significant progress, yet research on learning generalized 3D objectness
remains insufficient. In this paper, we delve into learning open-world 3D
objectness, which focuses on detecting all objects in a 3D scene, including
novel objects unseen during training. Traditional closed-set 3D detectors
struggle to generalize to open-world scenarios, while directly incorporating 3D
open-vocabulary models for open-world ability struggles with vocabulary
expansion and semantic overlap. To achieve generalized 3D object discovery, We
propose OP3Det, a class-agnostic Open-World Prompt-free 3D Detector to detect
any objects within 3D scenes without relying on hand-crafted text prompts. We
introduce the strong generalization and zero-shot capabilities of 2D foundation
models, utilizing both 2D semantic priors and 3D geometric priors for
class-agnostic proposals to broaden 3D object discovery. Then, by integrating
complementary information from point cloud and RGB image in the cross-modal
mixture of experts, OP3Det dynamically routes uni-modal and multi-modal
features to learn generalized 3D objectness. Extensive experiments demonstrate
the extraordinary performance of OP3Det, which significantly surpasses existing
open-world 3D detectors by up to 16.0% in AR and achieves a 13.5% improvement
compared to closed-world 3D detectors.

</details>


### [172] [GAS: Improving Discretization of Diffusion ODEs via Generalized Adversarial Solver](https://arxiv.org/abs/2510.17699)
*Aleksandr Oganov,Ilya Bykov,Eva Neudachina,Mishan Aliev,Alexander Tolmachev,Alexander Sidorov,Aleksandr Zuev,Andrey Okhotin,Denis Rakitin,Aibek Alanov*

Main category: cs.CV

TL;DR: 提出广义对抗求解器，通过简单参数化与对抗训练结合，显著提升扩散模型采样效率与细节保真度。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成质量上达到最先进水平，但采样过程计算成本高昂，现有方法依赖复杂训练技巧且未明确关注细节保留。

Method: 引入广义求解器（Generalized Solver）作为ODE采样器的简单参数化方法，无需复杂训练技巧，并结合原始蒸馏损失与对抗训练以提升细节保真度。

Result: 广义对抗求解器在减少计算成本的同时，显著提升了生成质量与细节保真度。

Conclusion: 论文提出的广义对抗求解器（Generalized Adversarial Solver）在相似资源限制下表现出优于现有求解器训练方法的性能。

Abstract: While diffusion models achieve state-of-the-art generation quality, they
still suffer from computationally expensive sampling. Recent works address this
issue with gradient-based optimization methods that distill a few-step ODE
diffusion solver from the full sampling process, reducing the number of
function evaluations from dozens to just a few. However, these approaches often
rely on intricate training techniques and do not explicitly focus on preserving
fine-grained details. In this paper, we introduce the Generalized Solver: a
simple parameterization of the ODE sampler that does not require additional
training tricks and improves quality over existing approaches. We further
combine the original distillation loss with adversarial training, which
mitigates artifacts and enhances detail fidelity. We call the resulting method
the Generalized Adversarial Solver and demonstrate its superior performance
compared to existing solver training methods under similar resource
constraints. Code is available at https://github.com/3145tttt/GAS.

</details>


### [173] [Elastic ViTs from Pretrained Models without Retraining](https://arxiv.org/abs/2510.17700)
*Walter Simoncini,Michael Dorkenwald,Tijmen Blankevoort,Cees G. M. Snoek,Yuki M. Asano*

Main category: cs.CV

TL;DR: SnapViT 是一种无需重训练或标注数据的后预训练剪枝方法，通过进化算法和自监督评分实现高效弹性推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉基础模型仅在预定义规模下可用的问题，提供弹性部署选择以适应实际约束。

Method: 结合梯度信息与跨网络结构相关性，通过进化算法近似 Hessian 非对角结构，并采用自监督重要性评分机制。

Result: 在 DINO、SigLIPv2、DeIT 和 AugReg 模型上表现优于现有方法，生成弹性模型仅需不到 5 分钟（单 A100 GPU）。

Conclusion: SnapViT 提出了一种高效的后预训练结构化剪枝方法，能够在不同计算预算下实现弹性推理，且无需重训练或标注数据，表现出卓越的性能。

Abstract: Vision foundation models achieve remarkable performance but are only
available in a limited set of pre-determined sizes, forcing sub-optimal
deployment choices under real-world constraints. We introduce SnapViT:
Single-shot network approximation for pruned Vision Transformers, a new
post-pretraining structured pruning method that enables elastic inference
across a continuum of compute budgets. Our approach efficiently combines
gradient information with cross-network structure correlations, approximated
via an evolutionary algorithm, does not require labeled data, generalizes to
models without a classification head, and is retraining-free. Experiments on
DINO, SigLIPv2, DeIT, and AugReg models demonstrate superior performance over
state-of-the-art methods across various sparsities, requiring less than five
minutes on a single A100 GPU to generate elastic models that can be adjusted to
any computational budget. Our key contributions include an efficient pruning
strategy for pretrained Vision Transformers, a novel evolutionary approximation
of Hessian off-diagonal structures, and a self-supervised importance scoring
mechanism that maintains strong performance without requiring retraining or
labels. Code and pruned models are available at: https://elastic.ashita.nl/

</details>


### [174] [Automatic Classification of Circulating Blood Cell Clusters based on Multi-channel Flow Cytometry Imaging](https://arxiv.org/abs/2510.17716)
*Suqiang Ma,Subhadeep Sengupta,Yao Lee,Beikang Gu,Xianyan Chen,Xianqiao Wang,Yang Liu,Mengjia Xu,Galit H. Frydman,He Li*

Main category: cs.CV

TL;DR: 研究提出自动化框架，利用YOLOv11和多通道荧光分析CCC图像，分类和识别准确率超95%，未来可扩展至其他细胞簇研究。


<details>
  <summary>Details</summary>
Motivation: 循环血细胞簇（CCCs）是血栓、感染和炎症的重要生物标志物，但现有工具缺乏自动分析CCC图像的能力，尤其是处理不规则形状、异质细胞类型和多通道染色的挑战。

Method: 采用两步分析策略：首先通过微调YOLOv11模型将图像分类为细胞簇和非细胞簇组，优于传统CNN和ViT；然后通过叠加簇轮廓与多通道荧光染色区域识别细胞类型，提高准确性。

Result: 框架在细胞簇分类和表型识别中均达到超过95%的准确率，有效克服细胞碎片和染色伪影的干扰。

Conclusion: 该研究提出的自动化框架有效分析了流式细胞术中的循环血细胞簇（CCCs）图像，结合明场和荧光数据，分类和表型识别准确率超过95%。初步测试于血细胞，未来可扩展至免疫和肿瘤细胞簇分析，支持多种疾病的细胞研究。

Abstract: Circulating blood cell clusters (CCCs) containing red blood cells (RBCs),
white blood cells(WBCs), and platelets are significant biomarkers linked to
conditions like thrombosis, infection, and inflammation. Flow cytometry, paired
with fluorescence staining, is commonly used to analyze these cell clusters,
revealing cell morphology and protein profiles. While computational approaches
based on machine learning have advanced the automatic analysis of single-cell
flow cytometry images, there is a lack of effort to build tools to
automatically analyze images containing CCCs. Unlike single cells, cell
clusters often exhibit irregular shapes and sizes. In addition, these cell
clusters often consist of heterogeneous cell types, which require multi-channel
staining to identify the specific cell types within the clusters. This study
introduces a new computational framework for analyzing CCC images and
identifying cell types within clusters. Our framework uses a two-step analysis
strategy. First, it categorizes images into cell cluster and non-cluster groups
by fine-tuning the You Only Look Once(YOLOv11) model, which outperforms
traditional convolutional neural networks (CNNs), Vision Transformers (ViT).
Then, it identifies cell types by overlaying cluster contours with regions from
multi-channel fluorescence stains, enhancing accuracy despite cell debris and
staining artifacts. This approach achieved over 95% accuracy in both cluster
classification and phenotype identification. In summary, our automated
framework effectively analyzes CCC images from flow cytometry, leveraging both
bright-field and fluorescence data. Initially tested on blood cells, it holds
potential for broader applications, such as analyzing immune and tumor cell
clusters, supporting cellular research across various diseases.

</details>


### [175] [Raindrop GS: A Benchmark for 3D Gaussian Splatting under Raindrop Conditions](https://arxiv.org/abs/2510.17719)
*Zhiqiang Teng,Beibei Lin,Tingting Chen,Zifeng Yuan,Xuanyi Li,Xuanyu Zhang,Shunli Zhang*

Main category: cs.CV

TL;DR: RaindropGS是一个针对雨滴条件下3D高斯溅射（3DGS）的基准测试，通过真实数据集评估各环节性能，揭示了现有方法的局限并指导优化方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅使用合成雨滴图像（已知相机姿态）评估3DGS，忽略了真实场景中雨滴对相机姿态估计和点云初始化的干扰，且合成与真实雨滴存在显著域差距。

Method: RaindropGS基准测试包括数据准备、数据处理和雨滴感知的3DGS评估三部分，涵盖雨滴干扰类型、相机姿态估计、点云初始化、单图像去雨比较和3D高斯训练比较。

Result: 实验表明，相机焦点位置对3DGS重建性能有显著影响，不准确的姿态和点云初始化会严重干扰重建质量。

Conclusion: RaindropGS作为一个全面的基准测试，揭示了现有3DGS方法在雨滴干扰下的性能局限，并明确了各处理环节的影响，为开发更鲁棒的3DGS方法提供了方向。

Abstract: 3D Gaussian Splatting (3DGS) under raindrop conditions suffers from severe
occlusions and optical distortions caused by raindrop contamination on the
camera lens, substantially degrading reconstruction quality. Existing
benchmarks typically evaluate 3DGS using synthetic raindrop images with known
camera poses (constrained images), assuming ideal conditions. However, in
real-world scenarios, raindrops often interfere with accurate camera pose
estimation and point cloud initialization. Moreover, a significant domain gap
between synthetic and real raindrops further impairs generalization. To tackle
these issues, we introduce RaindropGS, a comprehensive benchmark designed to
evaluate the full 3DGS pipeline-from unconstrained, raindrop-corrupted images
to clear 3DGS reconstructions. Specifically, the whole benchmark pipeline
consists of three parts: data preparation, data processing, and raindrop-aware
3DGS evaluation, including types of raindrop interference, camera pose
estimation and point cloud initialization, single image rain removal
comparison, and 3D Gaussian training comparison. First, we collect a real-world
raindrop reconstruction dataset, in which each scene contains three aligned
image sets: raindrop-focused, background-focused, and rain-free ground truth,
enabling a comprehensive evaluation of reconstruction quality under different
focus conditions. Through comprehensive experiments and analyses, we reveal
critical insights into the performance limitations of existing 3DGS methods on
unconstrained raindrop images and the varying impact of different pipeline
components: the impact of camera focus position on 3DGS reconstruction
performance, and the interference caused by inaccurate pose and point cloud
initialization on reconstruction. These insights establish clear directions for
developing more robust 3DGS methods under raindrop conditions.

</details>


### [176] [Can Image-To-Video Models Simulate Pedestrian Dynamics?](https://arxiv.org/abs/2510.17731)
*Aaron Appelle,Jerome P. Lynch*

Main category: cs.CV

TL;DR: 研究验证了DiT-based I2V模型在生成逼真行人运动模式方面的能力，并通过定量指标评估了其性能。


<details>
  <summary>Details</summary>
Motivation: 研究高表现力的I2V模型是否能够生成真实的行人运动模式。

Method: 通过从行人轨迹基准中提取关键帧，并利用定量行人动态指标评估模型性能。

Result: 模型在行人轨迹预测任务中表现出色，验证了其世界建模能力。

Conclusion: 基于扩散变换器（DiT）的图像到视频（I2V）模型在拥挤公共场景中能够生成逼真的行人运动模式，展现出其在行人轨迹预测任务中的潜力。

Abstract: Recent high-performing image-to-video (I2V) models based on variants of the
diffusion transformer (DiT) have displayed remarkable inherent world-modeling
capabilities by virtue of training on large scale video datasets. We
investigate whether these models can generate realistic pedestrian movement
patterns in crowded public scenes. Our framework conditions I2V models on
keyframes extracted from pedestrian trajectory benchmarks, then evaluates their
trajectory prediction performance using quantitative measures of pedestrian
dynamics.

</details>


### [177] [Joint Multi-Condition Representation Modelling via Matrix Factorisation for Visual Place Recognition](https://arxiv.org/abs/2510.17739)
*Timur Ismagilov,Shakaiba Majeed,Michael Milford,Tan Viet Tuyen Nguyen,Sarvapali D. Ramchurn,Shoaib Ehsan*

Main category: cs.CV

TL;DR: 提出一种无需训练的多参考视觉地点识别方法，通过矩阵分解提升性能，验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多参考视觉地点识别中训练成本高和数据多样性不足的问题。

Method: 提出了一种基于矩阵分解的投影残差匹配方法，无需训练且与描述符无关。

Result: 在多视角数据上，Recall@1提升了约18%，并在非结构化数据上也有约5%的提升。

Conclusion: 该方法在多视角视觉地点识别中表现出色，无需训练且轻量级，显著提升了召回率。

Abstract: We address multi-reference visual place recognition (VPR), where reference
sets captured under varying conditions are used to improve localisation
performance. While deep learning with large-scale training improves robustness,
increasing data diversity and model complexity incur extensive computational
cost during training and deployment. Descriptor-level fusion via voting or
aggregation avoids training, but often targets multi-sensor setups or relies on
heuristics with limited gains under appearance and viewpoint change. We propose
a training-free, descriptor-agnostic approach that jointly models places using
multiple reference descriptors via matrix decomposition into basis
representations, enabling projection-based residual matching. We also introduce
SotonMV, a structured benchmark for multi-viewpoint VPR. On multi-appearance
data, our method improves Recall@1 by up to ~18% over single-reference and
outperforms multi-reference baselines across appearance and viewpoint changes,
with gains of ~5% on unstructured data, demonstrating strong generalisation
while remaining lightweight.

</details>


### [178] [SparseVILA: Decoupling Visual Sparsity for Efficient VLM Inference](https://arxiv.org/abs/2510.17777)
*Samir Khaki,Junxian Guo,Jiaming Tang,Shang Yang,Yukang Chen,Konstantinos N. Plataniotis,Yao Lu,Song Han,Zhijian Liu*

Main category: cs.CV

TL;DR: SparseVILA通过解耦视觉稀疏性，显著加速了视觉语言模型的推理速度，同时保持了多轮对话的准确性。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型的可扩展性受到视觉令牌数量增加的制约，导致推理延迟。SparseVILA旨在通过解耦视觉稀疏性来解决这一问题。

Method: SparseVILA在预填充阶段剪枝冗余视觉令牌，并在解码阶段仅检索与查询相关的令牌，从而在AWQ优化的推理管道上实现了显著的加速。

Result: SparseVILA在长上下文视频任务中实现了最高4.0倍的预填充加速、2.5倍的解码加速和2.6倍的端到端加速，同时在文档理解和推理任务中提高了准确性。

Conclusion: SparseVILA通过解耦视觉稀疏性，在预填充和解码阶段实现了高效的多模态推理，为加速大型视觉语言模型提供了无需训练、架构无关的框架。

Abstract: Vision Language Models (VLMs) have rapidly advanced in integrating visual and
textual reasoning, powering applications across high-resolution image
understanding, long-video analysis, and multi-turn conversation. However, their
scalability remains limited by the growing number of visual tokens that
dominate inference latency. We present SparseVILA, a new paradigm for efficient
VLM inference that decouples visual sparsity across the prefilling and decoding
stages. SparseVILA distributes sparsity across stages by pruning redundant
visual tokens during prefill and retrieving only query-relevant tokens during
decoding. This decoupled design matches leading prefill pruning methods while
preserving multi-turn fidelity by retaining most of the visual cache so that
query-aware tokens can be retrieved at each conversation round. Built on an
AWQ-optimized inference pipeline, SparseVILA achieves up to 4.0 times faster
prefilling, 2.5 times faster decoding, and an overall 2.6 times end-to-end
speedup on long-context video tasks -- while improving accuracy on
document-understanding and reasoning tasks. By decoupling query-agnostic
pruning and query-aware retrieval, SparseVILA establishes a new direction for
efficient multimodal inference, offering a training-free, architecture-agnostic
framework for accelerating large VLMs without sacrificing capability.

</details>


### [179] [UltraCUA: A Foundation Model for Computer Use Agents with Hybrid Action](https://arxiv.org/abs/2510.17790)
*Yuhao Yang,Zhen Yang,Zi-Yi Dou,Anh Nguyen,Keen You,Omar Attia,Andrew Szot,Michael Feng,Ram Ramrakhya,Alexander Toshev,Chao Huang,Yinfei Yang,Zhe Gan*

Main category: cs.CV

TL;DR: UltraCUA通过混合动作机制整合GUI原始操作和高级程序化工具调用，显著提升了计算机使用代理的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决计算机使用代理因依赖原始动作（点击、键入、滚动）导致的视觉基础不准确和执行链过长问题，以及其与丰富程序化接口（如API、工具）的隔离问题。

Method: 1) 从软件文档、开源仓库和代码生成中扩展程序化工具的自动化管道；2) 生成超过17,000个可验证任务的合成数据引擎；3) 收集包含低级GUI动作和高级程序化工具调用的大规模高质量混合动作轨迹；4) 结合监督微调和在线强化学习的两阶段训练管道。

Result: UltraCUA模型在OSWorld上相对基础模型平均提升22%，步骤执行速度提升11%；在WindowsAgentArena上的跨域评估中成功率达到21.7%，优于基于Windows数据训练的基线模型。

Conclusion: UltraCUA模型通过混合动作机制显著提升了计算机使用代理的性能，减少了错误传播并保持了执行效率。

Abstract: Multimodal agents for computer use rely exclusively on primitive actions
(click, type, scroll) that require accurate visual grounding and lengthy
execution chains, leading to cascading failures and performance bottlenecks.
While other agents leverage rich programmatic interfaces (APIs, MCP servers,
tools), computer-use agents (CUAs) remain isolated from these capabilities. We
present UltraCUA, a foundation model that bridges this gap through hybrid
action -- seamlessly integrating GUI primitives with high-level programmatic
tool calls. To achieve this, our approach comprises four key components: (1) an
automated pipeline that scales programmatic tools from software documentation,
open-source repositories, and code generation; (2) a synthetic data engine
producing over 17,000 verifiable tasks spanning real-world computer-use
scenarios; (3) a large-scale high-quality hybrid action trajectory collection
with both low-level GUI actions and high-level programmatic tool calls; and (4)
a two-stage training pipeline combining supervised fine-tuning with online
reinforcement learning, enabling strategic alternation between low-level and
high-level actions. Experiments with our 7B and 32B models demonstrate
substantial improvements over state-of-the-art agents. On OSWorld, UltraCUA
models achieve an average 22% relative improvement over base models, while
being 11% faster in terms of steps. Out-of-domain evaluation on
WindowsAgentArena shows our model reaches 21.7% success rate, outperforming
baselines trained on Windows data. The hybrid action mechanism proves critical,
reducing error propagation while maintaining execution efficiency.

</details>


### [180] [Glyph: Scaling Context Windows via Visual-Text Compression](https://arxiv.org/abs/2510.17800)
*Jiale Cheng,Yusen Liu,Xinyu Zhang,Yulin Fei,Wenyi Hong,Ruiliang Lyu,Weihan Wang,Zhe Su,Xiaotao Gu,Xiao Liu,Yushi Bai,Jie Tang,Hongning Wang,Minlie Huang*

Main category: cs.CV

TL;DR: Glyph通过将长文本渲染为图像并由视觉语言模型处理，实现了高效的标记压缩和速度提升，解决了长上下文LLM的高成本问题。


<details>
  <summary>Details</summary>
Motivation: 长上下文建模在文档理解、代码分析和多步推理等任务中日益重要，但扩展到百万标记级别会带来高昂的计算和内存成本。

Method: 提出了Glyph框架，通过将长文本渲染为图像并由视觉语言模型处理，结合LLM驱动的遗传搜索优化视觉渲染配置。

Result: 实验表明，Glyph实现了3-4倍的标记压缩，预填充和解码速度提升约4倍，SFT训练速度提升约2倍，且在极端压缩下可处理1M标记级文本任务。

Conclusion: Glyph框架通过将长文本渲染为图像并由视觉语言模型处理，实现了3-4倍的标记压缩，同时在长上下文基准测试中保持了与领先LLM相当的准确性。该方法还显著提升了预填充、解码和SFT训练的速度，并展示了在极端压缩下处理百万标记级文本任务的潜力。

Abstract: Large language models (LLMs) increasingly rely on long-context modeling for
tasks such as document understanding, code analysis, and multi-step reasoning.
However, scaling context windows to the million-token level brings prohibitive
computational and memory costs, limiting the practicality of long-context LLMs.
In this work, we take a different perspective-visual context scaling-to tackle
this challenge. Instead of extending token-based sequences, we propose Glyph, a
framework that renders long texts into images and processes them with
vision-language models (VLMs). This approach substantially compresses textual
input while preserving semantic information, and we further design an
LLM-driven genetic search to identify optimal visual rendering configurations
for balancing accuracy and compression. Through extensive experiments, we
demonstrate that our method achieves 3-4x token compression while maintaining
accuracy comparable to leading LLMs such as Qwen3-8B on various long-context
benchmarks. This compression also leads to around 4x faster prefilling and
decoding, and approximately 2x faster SFT training. Furthermore, under extreme
compression, a 128K-context VLM could scale to handle 1M-token-level text
tasks. In addition, the rendered text data benefits real-world multimodal
tasks, such as document understanding. Our code and model are released at
https://github.com/thu-coai/Glyph.

</details>


### [181] [ConsistEdit: Highly Consistent and Precise Training-free Visual Editing](https://arxiv.org/abs/2510.17803)
*Zixin Yin,Ling-Hao Chen,Lionel Ni,Xili Dai*

Main category: cs.CV

TL;DR: 提出ConsistEdit方法，通过MM-DiT的注意力机制改进，实现高效、一致的多轮和视频编辑，支持细粒度控制。


<details>
  <summary>Details</summary>
Motivation: 现有方法在编辑强度与源一致性之间难以平衡，尤其在多轮和视频编辑中视觉错误会累积，且全局一致性限制了细粒度编辑能力。

Method: 通过分析MM-DiT的注意力机制，提出ConsistEdit方法，结合视觉专用注意力控制、掩码引导预注意力融合及差异化操作查询、键和值令牌。

Result: ConsistEdit在广泛图像和视频编辑任务中实现最先进性能，首次支持所有推理步骤和注意力层编辑，显著提升可靠性和一致性。

Conclusion: ConsistEdit在图像和视频编辑任务中表现出色，支持多轮和多区域编辑，且能渐进调整结构一致性，提供更精细的控制。

Abstract: Recent advances in training-free attention control methods have enabled
flexible and efficient text-guided editing capabilities for existing generation
models. However, current approaches struggle to simultaneously deliver strong
editing strength while preserving consistency with the source. This limitation
becomes particularly critical in multi-round and video editing, where visual
errors can accumulate over time. Moreover, most existing methods enforce global
consistency, which limits their ability to modify individual attributes such as
texture while preserving others, thereby hindering fine-grained editing.
Recently, the architectural shift from U-Net to MM-DiT has brought significant
improvements in generative performance and introduced a novel mechanism for
integrating text and vision modalities. These advancements pave the way for
overcoming challenges that previous methods failed to resolve. Through an
in-depth analysis of MM-DiT, we identify three key insights into its attention
mechanisms. Building on these, we propose ConsistEdit, a novel attention
control method specifically tailored for MM-DiT. ConsistEdit incorporates
vision-only attention control, mask-guided pre-attention fusion, and
differentiated manipulation of the query, key, and value tokens to produce
consistent, prompt-aligned edits. Extensive experiments demonstrate that
ConsistEdit achieves state-of-the-art performance across a wide range of image
and video editing tasks, including both structure-consistent and
structure-inconsistent scenarios. Unlike prior methods, it is the first
approach to perform editing across all inference steps and attention layers
without handcraft, significantly enhancing reliability and consistency, which
enables robust multi-round and multi-region editing. Furthermore, it supports
progressive adjustment of structural consistency, enabling finer control.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [182] [SIADAFIX: issue description response for adaptive program repair](https://arxiv.org/abs/2510.16059)
*Xin Cao,Nan Yu*

Main category: cs.SE

TL;DR: SIADAFIX是一种结合快慢思考的自适应程序修复方法，通过优化工作流和分类问题描述，有效提升修复效率和准确性，实验性能达60.67% pass@1。


<details>
  <summary>Details</summary>
Motivation: 通过结合快慢思考策略，提升大型语言模型代理在复杂任务（如程序修复）上的能力。

Method: 设计了一种基于问题描述响应的自适应程序修复方法SIADAFIX，利用慢思考的bug修复代理完成复杂任务，快思考的工作流决策组件优化和分类问题描述。根据问题复杂度自适应选择三种修复模式（简单、中等、困难）。

Result: 在SWE-bench Lite上的实验结果显示，SIADAFIX使用Claude-4 Sonnet模型达到了60.67%的pass@1性能，达到了开源方法中的最先进水平。

Conclusion: SIADAFIX通过结合快慢思考策略，有效平衡了程序修复的效率和准确性，为自动化程序修复提供了新思路。

Abstract: We propose utilizing fast and slow thinking to enhance the capabilities of
large language model-based agents on complex tasks such as program repair. In
particular, we design an adaptive program repair method based on issue
description response, called SIADAFIX. The proposed method utilizes slow
thinking bug fix agent to complete complex program repair tasks, and employs
fast thinking workflow decision components to optimize and classify issue
descriptions, using issue description response results to guide the
orchestration of bug fix agent workflows. SIADAFIX adaptively selects three
repair modes, i.e., easy, middle and hard mode, based on problem complexity. It
employs fast generalization for simple problems and test-time scaling
techniques for complex problems. Experimental results on the SWE-bench Lite
show that the proposed method achieves 60.67% pass@1 performance using the
Claude-4 Sonnet model, reaching state-of-the-art levels among all open-source
methods. SIADAFIX effectively balances repair efficiency and accuracy,
providing new insights for automated program repair. Our code is available at
https://github.com/liauto-siada/siada-cli.

</details>


### [183] [Code Contribution and Credit in Science](https://arxiv.org/abs/2510.16242)
*Eva Maxfield Brown,Isaac Slaughter,Nicholas Weber*

Main category: cs.SE

TL;DR: 研究发现软件贡献与传统学术认可脱节，代码贡献者常被忽视，且频繁代码贡献与较低学术影响力相关。


<details>
  <summary>Details</summary>
Motivation: 探讨软件开发活动如何影响协作科学环境中的学术认可分配。

Method: 通过构建包含约140,000篇研究文章与代码库配对的数据集，并开发预测模型来匹配文章作者和软件仓库开发者账户。

Result: 研究发现近30%的文章包含非作者的代码贡献者；代码贡献作者的文章引用率有4.2%的微小提升，但在控制变量后效果不显著；第一作者更可能是代码贡献者；代码贡献频率与学术影响力指标呈负相关。

Conclusion: 研究揭示了软件贡献与传统学术认可之间的脱节，对机构奖励机制和科学政策具有重要影响。

Abstract: Software development has become essential to scientific research, but its
relationship to traditional metrics of scholarly credit remains poorly
understood. We develop a dataset of approximately 140,000 paired research
articles and code repositories, as well as a predictive model that matches
research article authors with software repository developer accounts. We use
this data to investigate how software development activities influence credit
allocation in collaborative scientific settings. Our findings reveal
significant patterns distinguishing software contributions from traditional
authorship credit. We find that nearly 30% of articles include non-author code
contributors- individuals who participated in software development but received
no formal authorship recognition. While code-contributing authors show a modest
$\sim$4.2% increase in article citations, this effect becomes non-significant
when controlling for domain, article type, and open access status. First
authors are significantly more likely to be code contributors than other author
positions. Notably, we identify a negative relationship between coding
frequency and scholarly impact metrics. Authors who contribute code more
frequently exhibit progressively lower h-indices than non-coding colleagues,
even when controlling for publication count, author position, domain, and
article type. These results suggest a disconnect between software contributions
and credit, highlighting important implications for institutional reward
structures and science policy.

</details>


### [184] [MLCPD: A Unified Multi-Language Code Parsing Dataset with Universal AST Schema](https://arxiv.org/abs/2510.16357)
*Jugal Gajjar,Kamalasankari Subramaniakuppusamy*

Main category: cs.SE

TL;DR: MLCPD是一个大规模、语言无关的数据集，统一了十种编程语言的语法和结构表示，为跨语言研究和程序分析提供了基础资源。


<details>
  <summary>Details</summary>
Motivation: 现有的语料库主要集中在标记级别的代码或孤立的解析器上，缺乏一致性和结构统一性。

Method: 提出了一个通用的抽象语法树（AST）模式，统一了十种主要编程语言的语法和结构表示，包含超过七百万个解析后的源文件。

Result: 实证分析揭示了跨语言的强结构规律性，表明不同语言的语法图可以在共享模式下对齐。

Conclusion: MLCPD为跨语言表示学习和程序分析提供了一个开放、可复现的基础资源。

Abstract: We introduce the MultiLang Code Parser Dataset (MLCPD), a large-scale,
language-agnostic dataset unifying syntactic and structural representations of
code across ten major programming languages. MLCPD contains over seven million
parsed source files normalized under our proposed universal Abstract Syntax
Tree (AST) schema, enabling consistent cross-language reasoning, structural
learning, and multilingual software analysis. Unlike existing corpora that
focus purely on token-level code or isolated parsers, MLCPD provides both
hierarchical tree representations and rich metadata for every file, ensuring
lossless syntactic coverage and structural uniformity. Each entry includes a
normalized schema, language-level metadata, and abstracted node semantics
stored in Parquet format for scalable retrieval. Empirical analyses reveal
strong cross-language structural regularities-demonstrating that syntactic
graphs from languages as diverse as Python, Java, and Go can be aligned under a
shared schema. We release the dataset publicly on Hugging Face and the
accompanying codebase on GitHub, which includes complete pipelines for dataset
reproduction, grammar compilation, and a visualization tool for exploring the
unified AST across languages. Together, these resources establish MLCPD as an
open, reproducible foundation for future research in cross-language
representation learning and program analysis.

</details>


### [185] [SemOpt: LLM-Driven Code Optimization via Rule-Based Analysis](https://arxiv.org/abs/2510.16384)
*Yuwei Zhao,Yuan-An Xiao,Qianyu Xiao,Zhao Zhang,Yingfei Xiong*

Main category: cs.SE

TL;DR: SemOpt利用静态分析和LLMs提升代码优化效果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于信息检索的代码优化方法因无法识别语义等效但语法不同的代码片段，导致优化效果不佳。SemOpt旨在通过静态程序分析和LLMs解决这一问题。

Method: SemOpt框架包含三个关键组件：策略库构建器、规则生成器和优化器，均依赖LLMs实现。这些组件共同工作，通过静态分析精确识别可优化代码段，并生成优化结果。

Result: 在包含151个优化任务的基准测试中，SemOpt比基线方法成功优化次数提高了1.38至28倍。在大型C/C++项目中，性能指标提升了5.04%至218.07%。

Conclusion: SemOpt框架通过结合静态程序分析和LLMs，显著提升了代码优化的成功率和性能改进效果，证明了其在实践中的实用性。

Abstract: Automated code optimization aims to improve performance in programs by
refactoring code, and recent studies focus on utilizing LLMs for the
optimization. Typical existing approaches mine optimization commits from
open-source codebases to construct a large-scale knowledge base, then employ
information retrieval techniques such as BM25 to retrieve relevant optimization
examples for hotspot code locations, thereby guiding LLMs to optimize these
hotspots. However, since semantically equivalent optimizations can manifest in
syntactically dissimilar code snippets, current retrieval methods often fail to
identify pertinent examples, leading to suboptimal optimization performance.
This limitation significantly reduces the effectiveness of existing
optimization approaches.
  To address these limitations, we propose SemOpt, a novel framework that
leverages static program analysis to precisely identify optimizable code
segments, retrieve the corresponding optimization strategies, and generate the
optimized results. SemOpt consists of three key components: (1) A strategy
library builder that extracts and clusters optimization strategies from
real-world code modifications. (2) A rule generator that generates Semgrep
static analysis rules to capture the condition of applying the optimization
strategy. (3) An optimizer that utilizes the strategy library to generate
optimized code results. All the three components are powered by LLMs.
  On our benchmark containing 151 optimization tasks, SemOpt demonstrates its
effectiveness under different LLMs by increasing the number of successful
optimizations by 1.38 to 28 times compared to the baseline. Moreover, on
popular large-scale C/C++ projects, it can improve individual performance
metrics by 5.04% to 218.07%, demonstrating its practical utility.

</details>


### [186] [Code Digital Twin: Empowering LLMs with Tacit Knowledge for Complex Software Development](https://arxiv.org/abs/2510.16395)
*Xin Peng,Chong Wang*

Main category: cs.SE

TL;DR: 论文提出Code Digital Twin框架，整合AI与企业管理软件开发，解决隐性知识问题，提升复杂系统的开发效率。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在软件工程任务中表现出强大能力，但企业软件开发主要依赖增量演进，涉及隐性知识，需要将AI能力与企业开发现实对齐。

Method: 论文提出了Code Digital Twin框架，整合了混合知识表示、多阶段提取管道、增量更新、LLM赋能应用和人机交互反馈。

Result: Code Digital Twin将碎片化知识转化为明确且可操作的表示，为复杂软件开发提供AI支持。

Conclusion: 论文提出了Code Digital Twin作为AI与企业管理软件现实之间的桥梁，为超复杂系统的可持续、智能和弹性开发与演进提供了具体路线图。

Abstract: Recent advances in large language models (LLMs) have demonstrated strong
capabilities in software engineering tasks, raising expectations of
revolutionary productivity gains. However, enterprise software development is
largely driven by incremental evolution, where challenges extend far beyond
routine coding and depend critically on tacit knowledge, including design
decisions at different levels and historical trade-offs. To achieve effective
AI-powered support for complex software development, we should align emerging
AI capabilities with the practical realities of enterprise development. To this
end, we systematically identify challenges from both software and LLM
perspectives. Alongside these challenges, we outline opportunities where AI and
structured knowledge frameworks can enhance decision-making in tasks such as
issue localization and impact analysis. To address these needs, we propose the
Code Digital Twin, a living framework that models both the physical and
conceptual layers of software, preserves tacit knowledge, and co-evolves with
the codebase. By integrating hybrid knowledge representations, multi-stage
extraction pipelines, incremental updates, LLM-empowered applications, and
human-in-the-loop feedback, the Code Digital Twin transforms fragmented
knowledge into explicit and actionable representations. Our vision positions it
as a bridge between AI advancements and enterprise software realities,
providing a concrete roadmap toward sustainable, intelligent, and resilient
development and evolution of ultra-complex systems.

</details>


### [187] [Large-Scale Empirical Analysis of Continuous Fuzzing: Insights from 1 Million Fuzzing Sessions](https://arxiv.org/abs/2510.16433)
*Tatsuya Shirai,Olivier Nourry,Yutaro Kashiwa,Kenji Fujiwara,Yasutaka Kamei,Hajimu Iida*

Main category: cs.SE

TL;DR: 本研究通过分析OSS-Fuzz数据，揭示了持续模糊测试在漏洞检测中的贡献，包括早期高检测率、覆盖率增加及其对漏洞检测的影响。


<details>
  <summary>Details</summary>
Motivation: 尽管持续模糊测试已被数千个项目采用，但其在漏洞检测中的具体贡献尚不明确。本研究旨在阐明持续模糊测试在漏洞检测中的作用。

Method: 收集了来自OSS-Fuzz的约112万次模糊测试会话的数据，包括问题报告、覆盖率报告和模糊测试日志，并对878个项目进行了实证研究。

Result: 研究发现：(i)大量模糊测试漏洞在持续模糊测试集成前已存在，导致早期检测率高；(ii)随着持续模糊测试的进行，代码覆盖率持续增加；(iii)覆盖率的变化有助于模糊测试漏洞的检测。

Conclusion: 本研究通过实证分析揭示了持续模糊测试在漏洞检测中的贡献，为未来持续模糊测试的策略和工具开发提供了实际意义。

Abstract: Software vulnerabilities are constantly being reported and exploited in
software products, causing significant impacts on society. In recent years, the
main approach to vulnerability detection, fuzzing, has been integrated into the
continuous integration process to run in short and frequent cycles. This
continuous fuzzing allows for fast identification and remediation of
vulnerabilities during the development process. Despite adoption by thousands
of projects, however, it is unclear how continuous fuzzing contributes to
vulnerability detection. This study aims to elucidate the role of continuous
fuzzing in vulnerability detection. Specifically, we investigate the coverage
and the total number of fuzzing sessions when fuzzing bugs are discovered. We
collect issue reports, coverage reports, and fuzzing logs from OSS-Fuzz, an
online service provided by Google that performs fuzzing during continuous
integration. Through an empirical study of a total of approximately 1.12
million fuzzing sessions from 878 projects participating in OSS-Fuzz, we reveal
that (i) a substantial number of fuzzing bugs exist prior to the integration of
continuous fuzzing, leading to a high detection rate in the early stages; (ii)
code coverage continues to increase as continuous fuzzing progresses; and (iii)
changes in coverage contribute to the detection of fuzzing bugs. This study
provides empirical insights into how continuous fuzzing contributes to fuzzing
bug detection, offering practical implications for future strategies and tool
development in continuous fuzzing.

</details>


### [188] [On the Use of Large Language Models for Qualitative Synthesis](https://arxiv.org/abs/2510.16502)
*Sebastián Pizard,Ramiro Moreira,Federico Galiano,Ignacio Sastre,Lorena Etcheverry*

Main category: cs.SE

TL;DR: LLMs在系统评价的定性合成中具有潜力，但需谨慎使用以避免风险，研究通过自民族志方法评估了其挑战。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在系统评价中，尤其是定性合成阶段的应用潜力与风险，以避免因滥用而加剧现有问题。

Method: 通过合作自民族志方法，评估了两个试验的方法论严谨性和实际实用性，并结合LLMs的技术特性和当前局限性进行解读。

Result: 研究表明，LLMs在QS阶段的应用需严格评估其方法学严谨性和实用性，同时考虑其技术限制。

Conclusion: 使用大型语言模型（LLMs）进行定性合成（QS）存在挑战，需谨慎以避免放大现有弱点并影响系统评价（SR）结果的可信度。

Abstract: Large language models (LLMs) show promise for supporting systematic reviews
(SR), even complex tasks such as qualitative synthesis (QS). However, applying
them to a stage that is unevenly reported and variably conducted carries
important risks: misuse can amplify existing weaknesses and erode confidence in
the SR findings. To examine the challenges of using LLMs for QS, we conducted a
collaborative autoethnography involving two trials. We evaluated each trial for
methodological rigor and practical usefulness, and interpreted the results
through a technical lens informed by how LLMs are built and their current
limitations.

</details>


### [189] [Human-Aligned Code Readability Assessment with Large Language Models](https://arxiv.org/abs/2510.16579)
*Wendkûuni C. Ouédraogo,Yinghua Li,Xueqi Dang,Pawel Borsukiewicz,Xin Zhou,Anil Koyuncu,Jacques Klein,David Lo,Tegawendé F. Bissyandé*

Main category: cs.SE

TL;DR: CoReEval是一个大规模基准，用于评估LLM在代码可读性评估中的表现，结果显示开发者引导提示提高了对齐性和解释质量。


<details>
  <summary>Details</summary>
Motivation: 传统静态指标难以捕捉人类判断的主观性和上下文敏感性，LLM提供了可扩展的替代方案，但其行为尚未充分探索。

Method: 引入了CoReEval，一个大规模基准，用于评估基于LLM的代码可读性评估，包括超过140万个模型-片段-提示评估，覆盖10种最先进的LLM。

Result: 研究发现，基于人类定义的可读性维度的开发者引导提示在结构化环境中提高了对齐性，增强了解释质量，并通过角色框架实现了轻量级个性化。

Conclusion: CoReEval为LLM在代码可读性评估中的应用提供了坚实的基础，特别是在教育、入职和CI/CD管道中，LLM可以作为可解释、适应性强的评审者。

Abstract: Code readability is crucial for software comprehension and maintenance, yet
difficult to assess at scale. Traditional static metrics often fail to capture
the subjective, context-sensitive nature of human judgments. Large Language
Models (LLMs) offer a scalable alternative, but their behavior as readability
evaluators remains underexplored. We introduce CoReEval, the first large-scale
benchmark for evaluating LLM-based code readability assessment, comprising over
1.4 million model-snippet-prompt evaluations across 10 state of the art LLMs.
The benchmark spans 3 programming languages (Java, Python, CUDA), 2 code types
(functional code and unit tests), 4 prompting strategies (ZSL, FSL, CoT, ToT),
9 decoding settings, and developer-guided prompts tailored to junior and senior
personas. We compare LLM outputs against human annotations and a validated
static model, analyzing numerical alignment (MAE, Pearson's, Spearman's) and
justification quality (sentiment, aspect coverage, semantic clustering). Our
findings show that developer-guided prompting grounded in human-defined
readability dimensions improves alignment in structured contexts, enhances
explanation quality, and enables lightweight personalization through persona
framing. However, increased score variability highlights trade-offs between
alignment, stability, and interpretability. CoReEval provides a robust
foundation for prompt engineering, model alignment studies, and human in the
loop evaluation, with applications in education, onboarding, and CI/CD
pipelines where LLMs can serve as explainable, adaptable reviewers.

</details>


### [190] [Contrasting the Hyperparameter Tuning Impact Across Software Defect Prediction Scenarios](https://arxiv.org/abs/2510.16665)
*Mohamed Sami Rakha,Andriy Miranskyy,Daniel Alencar da Costa*

Main category: cs.SE

TL;DR: 研究比较了IVDP和CVDP两种SDP场景下超参数调优的影响，发现IVDP的性能增益更大，且小型数据集对性能差异更敏感。建议在选择SDP场景时考虑超参数调优的影响。


<details>
  <summary>Details</summary>
Motivation: 超参数调优对特定SDP场景的预测性能有提升作用，但其积极影响可能因目标场景而异。比较不同场景下超参数调优的影响有助于提供全面见解，增强SDP建模的稳健性、通用性和实用性。

Method: 研究通过统计分析方法比较了两种SDP场景（IVDP和CVDP）下超参数调优的影响，使用了28种机器学习算法、53个发布后软件数据集、两种调优算法和五种优化指标。

Result: 结果表明，IVDP场景下的SDP增益显著大于CVDP场景。此外，24/28的ML算法在多个SDP场景中可能无法保持性能增益，且小型软件数据集更容易受到性能影响差异的影响。

Conclusion: 研究建议软件工程研究者和从业者在期待通过超参数调优获得性能提升时，应考虑所选软件缺陷预测（SDP）场景的影响。

Abstract: Software defect prediction (SDP) is crucial for delivering high-quality
software products. Recent research has indicated that prediction performance
improvements in SDP are achievable by applying hyperparameter tuning to a
particular SDP scenario. However, the positive impact resulting from the
hyperparameter tuning step may differ based on the targeted SDP scenario.
Comparing the impact of hyperparameter tuning across SDP scenarios is necessary
to provide comprehensive insights and enhance the robustness, generalizability,
and, eventually, the practicality of SDP modeling for quality assurance.
  Therefore, in this study, we contrast the impact of hyperparameter tuning
across two pivotal and consecutive SDP scenarios: (1) Inner Version Defect
Prediction (IVDP) and (2) Cross Version Defect Prediction (CVDP). The main
distinctions between the two scenarios lie in the scope of defect prediction
and the selected evaluation setups. This study's experiments use common
evaluation setups, 28 machine learning (ML) algorithms, 53 post-release
software datasets, two tuning algorithms, and five optimization metrics. We
apply statistical analytics to compare the SDP performance impact differences
by investigating the overall impact, the single ML algorithm impact, and
variations across different software dataset sizes.
  The results indicate that the SDP gains within the IVDP scenario are
significantly larger than those within the CVDP scenario. The results reveal
that asserting performance gains for up to 24 out of 28 ML algorithms may not
hold across multiple SDP scenarios. Furthermore, we found that small software
datasets are more susceptible to larger differences in performance impacts.
Overall, the study findings recommend software engineering researchers and
practitioners to consider the effect of the selected SDP scenario when
expecting performance gains from hyperparameter tuning.

</details>


### [191] [QuanBench: Benchmarking Quantum Code Generation with Large Language Models](https://arxiv.org/abs/2510.16779)
*Xiaoyu Guo,Minggu Wang,Jianjun Zhao*

Main category: cs.SE

TL;DR: QuanBench是一个评估LLM在量子代码生成能力的基准，结果显示当前模型表现不佳，准确率低且错误多。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在通用代码生成中表现良好，但其在量子代码生成方面的能力尚未充分研究。

Method: 论文提出了QuanBench，一个包含44个编程任务的基准，涵盖量子算法、状态准备、门分解和量子机器学习等领域。每个任务通过功能正确性（Pass@K）和量子语义等价性（Process Fidelity）进行评估。

Result: 评估结果显示，当前LLM生成正确量子代码的能力有限，总体准确率低于40%，且常见语义错误。

Conclusion: QuanBench为未来改进LLM在量子代码生成方面的研究提供了基础。

Abstract: Large language models (LLMs) have demonstrated good performance in general
code generation; however, their capabilities in quantum code generation remain
insufficiently studied. This paper presents QuanBench, a benchmark for
evaluating LLMs on quantum code generation. QuanBench includes 44 programming
tasks that cover quantum algorithms, state preparation, gate decomposition, and
quantum machine learning. Each task has an executable canonical solution and is
evaluated by functional correctness (Pass@K) and quantum semantic equivalence
(Process Fidelity). We evaluate several recent LLMs, including general-purpose
and code-specialized models. The results show that current LLMs have limited
capability in generating the correct quantum code, with overall accuracy below
40% and frequent semantic errors. We also analyze common failure cases, such as
outdated API usage, circuit construction errors, and incorrect algorithm logic.
QuanBench provides a basis for future work on improving quantum code generation
with LLMs.

</details>


### [192] [More with Less: An Empirical Study of Turn-Control Strategies for Efficient Coding Agents](https://arxiv.org/abs/2510.16786)
*Pengfei Gao,Chao Peng*

Main category: cs.SE

TL;DR: 动态轮次控制策略能有效降低LLM编码代理的成本，同时保持高效性能。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的编码代理在实际部署中因不可预测的高成本（如轮次增长导致的令牌数激增）而受限，现有研究多关注单轮优化，而忽略了对总轮次的战略控制。

Method: 在SWE-bench上使用三种先进模型，评估了三种轮次控制策略：无限制基线、固定轮次限制（带提醒）和动态轮次策略（按需扩展）。

Result: 动态轮次策略在保持或提高解决率的同时，进一步降低12%-24%的成本，显著优于固定限制策略。

Conclusion: 动态轮次控制策略（特别是按需扩展的动态策略）在平衡成本与效率方面表现最佳，为开发者提供了简单有效的资源分配指南。

Abstract: LLM-powered coding agents, which operate in iterative loops (turns) to solve
software engineering tasks, are becoming increasingly powerful. However, their
practical deployment is hindered by significant and unpredictable costs. This
challenge arises from a combination of factors: quadratically growing token
counts with each turn, the high price of models, the large number of turns
required for real-world tasks, and the tendency of agents to take inefficient
or unnecessary actions. While existing research focuses on optimizing
individual turns, the strategic control of the total number of turns remains an
underexplored area for managing agent performance and cost. To address this
gap, we conduct a comprehensive empirical study on SWE-bench using three
state-of-the-art models and evaluate the impact of three distinct turn-control
strategies: an unrestricted baseline, a fixed-turn limit with reminders, and a
novel dynamic-turn strategy that grants extensions on-demand. Our findings
first reveal a fundamental trade-off in the unrestricted setting, where no
single model excels across performance, cost, and turn efficiency. We then show
that a fixed-turn limit, specifically at the 75th percentile of the baseline,
serves as a "sweet spot", substantially reducing costs (by 24%-68%) with
minimal impact on solve rates. Most significantly, the dynamic-turn strategy
consistently outperforms fixed-limit approaches, achieving comparable or better
solve rates while further reducing costs by an additional 12%-24% by
intelligently allocating resources only to tasks that need them. This work
provides the first systematic analysis of turn-control strategies, offering
simple yet effective guidelines for developers to balance cost and efficacy. We
demonstrate that dynamic resource allocation is a superior, easy-to-implement
approach for deploying powerful yet economically viable coding agents.

</details>


### [193] [When Many-Shot Prompting Fails: An Empirical Study of LLM Code Translation](https://arxiv.org/abs/2510.16809)
*Amirkia Rafiei Oskooei,Kaan Baturalp Cosdan,Husamettin Isiktas,Mehmet S. Aktas*

Main category: cs.SE

TL;DR: 研究表明，代码翻译任务中，少量精选示例比大量示例更能提升功能正确性，挑战'越多越好'的假设。


<details>
  <summary>Details</summary>
Motivation: 探究在代码翻译任务中，增加上下文示例数量（'many-shot'提示）是否总能提升性能。

Method: 通过大规模实证研究，评估了从零样本到多达625个样本的不同提示配置对代码翻译性能的影响。

Result: 发现'多样本悖论'：静态相似性指标可能略有改善，但功能正确性在少量样本（5-25个示例）时达到峰值，更多样本反而会降低性能。

Conclusion: 研究表明，对于代码翻译任务，少量精心挑选的示例比大量示例更能提升功能正确性，挑战了'越多越好'的普遍假设。

Abstract: Large Language Models (LLMs) with vast context windows offer new avenues for
in-context learning (ICL), where providing many examples ("many-shot"
prompting) is often assumed to enhance performance. We investigate this
assumption for the complex task of code translation. Through a large-scale
empirical study of over 90,000 translations, we systematically evaluate the
impact of scaling in-context examples from zero-shot to many-shot
configurations of up to 625 examples, with prompts spanning from approximately
100,000 to 800,000 tokens. Our findings reveal a "many-shot paradox": while
static similarity metrics may modestly improve with more examples, functional
correctness consistently peaks with few-shot prompting (5-25 examples).
Providing substantially more examples often degrades this crucial functional
performance. This study highlights that for code translation, the quality of a
few well-chosen examples outweighs sheer quantity, challenging the universal
efficacy of "more is better" for ICL and underscoring the task-dependent nature
of optimal prompting strategies. Our results have significant implications for
effectively leveraging LLMs in software engineering.

</details>


### [194] [When AI Takes the Wheel: Security Analysis of Framework-Constrained Program Generation](https://arxiv.org/abs/2510.16823)
*Yue Liu,Zhenchang Xing,Shidong Pan,Chakkrit Tantithamthavorn*

Main category: cs.SE

TL;DR: 研究发现LLM生成的Chrome扩展程序存在高比例安全漏洞，尤其在敏感数据处理场景，高级模型表现更差。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在软件开发中的广泛应用，开发者可能忽视生成代码中的安全问题，研究旨在评估LLM生成的框架约束程序的安全性。

Method: 研究团队构建了ChromeSecBench数据集，包含140个基于已知漏洞扩展的提示，并指导九种先进LLM生成完整的Chrome扩展程序，随后从场景类型、模型差异和漏洞类别三个维度分析其安全性。

Result: LLM生成的程序存在高达18%-50%的漏洞率，身份认证和Cookie管理场景的漏洞率分别高达83%和78%，且高级推理模型表现更差。

Conclusion: 研究发现LLM生成的框架约束程序存在高比例的安全漏洞，特别是在身份认证和Cookie管理场景中，这表明LLM在编写安全代码方面存在显著不足。

Abstract: In recent years, the AI wave has grown rapidly in software development. Even
novice developers can now design and generate complex framework-constrained
software systems based on their high-level requirements with the help of Large
Language Models (LLMs). However, when LLMs gradually "take the wheel" of
software development, developers may only check whether the program works. They
often miss security problems hidden in how the generated programs are
implemented.
  In this work, we investigate the security properties of framework-constrained
programs generated by state-of-the-art LLMs. We focus specifically on Chrome
extensions due to their complex security model involving multiple privilege
boundaries and isolated components. To achieve this, we built ChromeSecBench, a
dataset with 140 prompts based on known vulnerable extensions. We used these
prompts to instruct nine state-of-the-art LLMs to generate complete Chrome
extensions, and then analyzed them for vulnerabilities across three dimensions:
scenario types, model differences, and vulnerability categories. Our results
show that LLMs produced vulnerable programs at alarmingly high rates (18%-50%),
particularly in Authentication & Identity and Cookie Management scenarios (up
to 83% and 78% respectively). Most vulnerabilities exposed sensitive browser
data like cookies, history, or bookmarks to untrusted code. Interestingly, we
found that advanced reasoning models performed worse, generating more
vulnerabilities than simpler models. These findings highlight a critical gap
between LLMs' coding skills and their ability to write secure
framework-constrained programs.

</details>


### [195] [Will AI also replace inspectors? Investigating the potential of generative AIs in usability inspection](https://arxiv.org/abs/2510.17056)
*Luis F. G. Campos,Leonardo C. Marques,Walter T. Nakamura*

Main category: cs.SE

TL;DR: 研究发现AI在可用性检查中虽不能替代人类，但可作为辅助工具提升效率，AI与人类结合效果最佳。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的发展，生成式模型为支持可用性检查任务提供了新机会，本研究旨在探讨AI在识别可用性问题方面的表现。

Method: 通过四位专家和两种AI模型（GPT-4o和Gemini 2.5 Flash）对软件原型进行评估，使用精确度、召回率和F1分数等指标进行比较。

Result: 人类检查员在精确度和整体覆盖率上表现最佳，而AI在个体性能上表现出色并发现许多新缺陷，但假阳性和冗余报告率较高。AI与人类检查员的结合产生了最佳结果。

Conclusion: 生成式AI在当前的阶段尚不能完全替代人类检查员，但可以作为有价值的辅助工具，提高效率并扩大缺陷覆盖范围。

Abstract: Usability inspection is a well-established technique for identifying
interaction issues in software interfaces, thereby contributing to improved
product quality. However, it is a costly process that requires time and
specialized knowledge from inspectors. With advances in Artificial Intelligence
(AI), new opportunities have emerged to support this task, particularly through
generative models capable of interpreting interfaces and performing inspections
more efficiently. This study examines the performance of generative AIs in
identifying usability problems, comparing them to those of experienced human
inspectors. A software prototype was evaluated by four specialists and two AI
models (GPT-4o and Gemini 2.5 Flash), using metrics such as precision, recall,
and F1-score. While inspectors achieved the highest levels of precision and
overall coverage, the AIs demonstrated high individual performance and
discovered many novel defects, but with a higher rate of false positives and
redundant reports. The combination of AIs and human inspectors produced the
best results, revealing their complementarity. These findings suggest that AI,
in its current stage, cannot replace human inspectors but can serve as a
valuable augmentation tool to improve efficiency and expand defect coverage.
The results provide evidence based on quantitative analysis to inform the
discussion on the role of AI in usability inspections, pointing to viable paths
for its complementary use in software quality assessment contexts.

</details>


### [196] [M2QCode: A Model-Driven Framework for Generating Multi-Platform Quantum Programs](https://arxiv.org/abs/2510.17110)
*Xiaoyu Guo,Shinobu Saito,Jianjun Zhao*

Main category: cs.SE

TL;DR: 本文提出了一种基于MDD的框架，自动生成多量子编程语言代码，提升量子系统开发效率，案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 量子计算领域快速发展，但量子系统工程中模型驱动开发的应用尚未充分探索，亟需一种结构化方法来提升开发效率。

Method: 采用模型驱动开发（MDD）框架，自动生成多种量子编程语言（QPLs）的代码。

Result: 通过多个案例研究验证了该方法的有效性和实用性。

Conclusion: 本文提出的基于MDD的方法显著提高了量子系统开发的效率和一致性，通过自动生成多种量子编程语言的代码，支持异构量子平台的开发。

Abstract: With the growing interest in quantum computing, the emergence of quantum
supremacy has marked a pivotal milestone in the field. As a result, numerous
quantum programming languages (QPLs) have been introduced to support the
development of quantum algorithms. However, the application of Model-Driven
Development (MDD) in quantum system engineering remains largely underexplored.
This paper presents an MDD-based approach to support the structured design and
implementation of quantum systems. Our framework enables the automatic
generation of quantum code for multiple QPLs, thereby enhancing development
efficiency and consistency across heterogeneous quantum platforms. The
effectiveness and practicality of our approach have been demonstrated through
multiple case studies.

</details>


### [197] [SEER: Enhancing Chain-of-Thought Code Generation through Self-Exploring Deep Reasoning](https://arxiv.org/abs/2510.17130)
*Shuzheng Gao,Chaozheng Wang,Cuiyun Gao,Michael R. Lyu*

Main category: cs.SE

TL;DR: SEER是一个自探索深度推理框架，通过多样化路径探索和质量感知训练，提升代码生成的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 现有CoT代码生成方法存在多样性不足、缺乏中间步骤质量评估和‘过度思考’问题，SEER旨在解决这些局限性。

Method: SEER框架包含三个关键组件：(1) 多样化推理路径探索，(2) 推理质量感知模型训练，(3) 自适应CoT推理。

Result: SEER能够生成更准确、适应性更强的代码，尤其在多样化编程场景中表现优异。

Conclusion: SEER框架通过引入多样化的推理路径探索、推理质量感知模型训练和自适应CoT推理，有效解决了现有CoT代码生成方法的局限性，提升了代码生成的准确性和适应性。

Abstract: Code generation, the task of creating executable programs from natural
language requirements, has recently seen tremendous advances through
Chain-of-Thought (CoT) reasoning, which enables Large Language Models (LLMs) to
develop high-level reasoning plans before writing code. Recent research has
proposed various methods to enhance models' CoT reasoning for code generation
such as prompt engineering and supervised fine-tuning. However, existing
approaches still face three critical limitations: (1) limited exploration of
diverse reasoning paths, which constrains generalization across various
programming scenarios, (2) lack of quality assessment for intermediate
reasoning steps, which hampers the reliability of the generated plans and code,
and (3) the potential negative impact of "overthinking", potentially leading to
unnecessarily complex and incorrect solutions. To address these limitations, we
frame CoT code generation as a decision making problem and present SEER, a
SElf-Exploring deep Reasoning framework that enables accurate and adaptive
reasoning for code generation. SEER introduces three key components: (1)
Diverse reasoning path exploration, which aims at exploring diverse reasoning
paths and annotating intermediate steps without relying on manual experts or
closed-source proprietary models; (2) Reasoning quality-aware model training,
which trains a policy model for generating candidate reasoning steps and a
value model for assessing their quality; and (3) Adaptive CoT reasoning, which
dynamically switches between direct generation and step-by-step reasoning for
different problems.

</details>


### [198] [PEACE: Towards Efficient Project-Level Efficiency Optimization via Hybrid Code Editing](https://arxiv.org/abs/2510.17142)
*Xiaoxue Ren,Jun Wan,Yun Peng,Zhongxin Liu,Ming Liang,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.SE

TL;DR: Peace是一个新型混合框架，通过自动代码编辑实现项目级代码效率优化，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在代码生成方面表现出色，但在代码效率优化方面的潜力尚未充分探索。现有方法局限于函数级优化，忽视了函数间交互，难以推广到实际开发场景。

Method: Peace框架整合了三个关键阶段：依赖感知的优化函数序列构建、有效关联编辑识别和效率优化编辑迭代。

Result: Peace在146个真实优化任务中表现优异，正确率达69.2%（pass@1），优化率提升46.9%，执行效率加速0.840倍。

Conclusion: Peace框架在项目级代码效率优化中表现出色，显著优于现有基线，特别是在涉及多函数的复杂优化任务中。

Abstract: Large Language Models (LLMs) have demonstrated significant capability in code
generation, but their potential in code efficiency optimization remains
underexplored. Previous LLM-based code efficiency optimization approaches
exclusively focus on function-level optimization and overlook interaction
between functions, failing to generalize to real-world development scenarios.
Code editing techniques show great potential for conducting project-level
optimization, yet they face challenges associated with invalid edits and
suboptimal internal functions. To address these gaps, we propose Peace, a novel
hybrid framework for Project-level code Efficiency optimization through
Automatic Code Editing, which also ensures the overall correctness and
integrity of the project. Peace integrates three key phases: dependency-aware
optimizing function sequence construction, valid associated edits
identification, and efficiency optimization editing iteration. To rigorously
evaluate the effectiveness of Peace, we construct PeacExec, the first benchmark
comprising 146 real-world optimization tasks from 47 high-impact GitHub Python
projects, along with highly qualified test cases and executable environments.
Extensive experiments demonstrate Peace's superiority over the state-of-the-art
baselines, achieving a 69.2% correctness rate (pass@1), +46.9% opt rate, and
0.840 speedup in execution efficiency. Notably, our Peace outperforms all
baselines by significant margins, particularly in complex optimization tasks
with multiple functions. Moreover, extensive experiments are also conducted to
validate the contributions of each component in Peace, as well as the rationale
and effectiveness of our hybrid framework design.

</details>


### [199] [TREAT: A Code LLMs Trustworthiness / Reliability Evaluation and Testing Framework](https://arxiv.org/abs/2510.17163)
*Shuzheng Gao,Eric John Li,Man Ho Lam,Jingyu Xiao,Yuxuan Wan,Chaozheng Wang,Ng Man Tik,Michael R. Lyu*

Main category: cs.SE

TL;DR: TREAT是一个评估代码LLM可信赖性的框架，通过多任务、多语言和多模态评估揭示了当前模型的性能差异和局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试在任务范围和评估方面（如模型的鲁棒性和可靠性）存在不足，需要更全面的评估框架。

Method: 提出了TREAT评估框架，包括多任务评估、多语言和多模态评估、鲁棒性评估以及严格的评估方法。

Result: 评估了26个最先进的模型，发现它们在编程任务中表现差异显著，多模态模型在UI代码生成和编辑方面存在局限性。

Conclusion: TREAT框架为评估大型基础模型在软件工程任务中的可信赖性提供了全面方法，揭示了当前模型的性能差异和多模态模型的局限性。

Abstract: Large foundation models are fundamentally transforming the software
engineering landscape, demonstrating exceptional capabilities across diverse
tasks such as code generation, debugging, and testing. Despite this rapid
progress, a significant gap remains in how to comprehensively evaluate these
models' trustworthiness in real-world software engineering scenarios. Existing
benchmarks suffer from limited task scope and fail to incorporate critical
evaluation aspects such as the robustness and reliability of models. To bridge
this gap, we present an evaluation framework called TREAT (Code LLMs
Trustworthiness / Reliability Evaluation And Testing) that provides a holistic
assessment of model performance in code intelligence tasks. Our evaluation
framework addresses key limitations in existing approaches with four main
improvements: (1) Multi-Task Holistic Evaluation that spans diverse software
engineering activities rather than limited coding tasks; (2) Multi-Language and
Multi-Modality Assessment that extends beyond traditional single-language,
text-only benchmarks to include multi-modality coding tasks; (3) Robustness
Assessment that evaluates model reliability under semantically-preserving code
transformations; and (4) Rigorous Evaluation Methodology that enhances the
trustworthiness of evaluation results through diverse evaluation prompts and
adaptive solution extraction. Based on this evaluation framework, we assess 26
state-of-the-art models and uncover both their strengths and limitations,
yielding several key insights:(1) Current models show substantial performance
variation across programming tasks; (2) Multi-modal language models demonstrate
specific performance limitations in UI code generation and edit;

</details>


### [200] [Software Testing with Large Language Models: An Interview Study with Practitioners](https://arxiv.org/abs/2510.17164)
*Maria Deolinda Santana,Cleyton Magalhaes,Ronnie de Souza Santos*

Main category: cs.SE

TL;DR: 本研究探讨了软件测试专业人员如何实际使用大型语言模型（LLM），提出初步指南以支持其集成到测试工作流程中。通过定性研究发现，测试过程涉及迭代、反思和人类监督，强调了结构化使用LLM的必要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件测试中的应用迅速增长，支持从测试用例生成到自动化和文档的多种任务。然而，其采用往往依赖于非正式的实验，而非结构化指导。本研究旨在调查软件测试专业人员如何实际使用LLM，以提出初步的、由从业者指导的指南，支持其集成到测试工作流程中。

Method: 我们进行了一项定性研究，涉及15名来自不同角色和领域的软件测试人员。数据通过半结构化访谈收集，并使用基于扎根理论的主题分析过程进行分析。

Result: 测试人员描述了一个迭代和反思的过程，包括定义测试目标、应用提示工程策略、优化提示、评估输出以及随时间学习。他们强调了人类监督和仔细验证的必要性，特别是由于LLM的已知限制，如幻觉和不一致的推理。

Conclusion: LLM在软件测试中的应用正在增长，但仍受制于不断发展的实践和对风险的谨慎态度。本研究为在测试环境中结构化使用LLM提供了一个起点，并邀请未来研究在团队、工具和任务中进一步优化这些实践。

Abstract: \textit{Background:} The use of large language models in software testing is
growing fast as they support numerous tasks, from test case generation to
automation, and documentation. However, their adoption often relies on informal
experimentation rather than structured guidance. \textit{Aims:} This study
investigates how software testing professionals use LLMs in practice to propose
a preliminary, practitioner-informed guideline to support their integration
into testing workflows. \textit{Method:} We conducted a qualitative study with
15 software testers from diverse roles and domains. Data were collected through
semi-structured interviews and analyzed using grounded theory-based processes
focused on thematic analysis. \textit{Results:} Testers described an iterative
and reflective process that included defining testing objectives, applying
prompt engineering strategies, refining prompts, evaluating outputs, and
learning over time. They emphasized the need for human oversight and careful
validation, especially due to known limitations of LLMs such as hallucinations
and inconsistent reasoning. \textit{Conclusions:} LLM adoption in software
testing is growing, but remains shaped by evolving practices and caution around
risks. This study offers a starting point for structuring LLM use in testing
contexts and invites future research to refine these practices across teams,
tools, and tasks.

</details>


### [201] [OLIVAW: ACIMOV's GitHub robot assisting agile collaborative ontology development](https://arxiv.org/abs/2510.17184)
*Nicolas Robert,Fabien Gandon,Maxime Lefrançois*

Main category: cs.SE

TL;DR: OLIVAW是一个基于GitHub的工具，支持ACIMOV方法论，通过W3C标准和多种接口辅助模块化本体的开发和持续验证。


<details>
  <summary>Details</summary>
Motivation: 敏捷和协作的本体设计方法对于确保本体用户驱动、及时更新并与支持系统同步演化至关重要，因此需要持续验证工具来匹配开发者的需求。

Method: OLIVAW利用W3C标准和GitHub Composite Actions、预提交钩子或命令行界面来辅助模块化本体的开发。

Result: OLIVAW在多个本体项目中进行了测试，证明了其实用性、通用性和可重用性，并提供了模板仓库以便快速启动。

Conclusion: OLIVAW通过支持ACIMOV方法论在GitHub上的实现，为模块化本体的开发提供了有效的工具，确保了本体的持续验证和更新。

Abstract: Agile and collaborative approaches to ontologies design are crucial because
they contribute to making them userdriven, up-to-date, and able to evolve
alongside the systems they support, hence proper continuous validation tooling
is required to ensure ontologies match developers' requirements all along their
development. We propose OLIVAW (Ontology Long-lived Integration Via ACIMOV
Workflow), a tool supporting the ACIMOV methodology on GitHub. It relies on W3C
Standards to assist the development of modular ontologies through GitHub
Composite Actions, pre-commit hooks, or a command line interface. OLIVAW was
tested on several ontology projects to ensure its usefulness, genericity and
reusability. A template repository is available for a quick start. OLIVAW is

</details>


### [202] [AdapTrack: Constrained Decoding without Distorting LLM's Output Intent](https://arxiv.org/abs/2510.17376)
*Yongmin Li,Jia Li,Ge Li,Zhi Jin*

Main category: cs.SE

TL;DR: AdapTrack通过回溯机制避免约束解码扭曲模型意图，显著提升代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 约束解码技术虽能生成符合约束的代码，但可能扭曲模型输出意图，导致生成的代码不符合开发意图。

Method: AdapTrack在生成过程中引入回溯机制，避免强制满足约束而扭曲模型输出意图。

Result: 在合成API补全数据集上提升360.87%，真实世界API补全数据集提升38.93%，HumanEval和MBPP基准测试分别提升7.84%和6.42%。

Conclusion: AdapTrack通过引入回溯机制，有效解决了约束解码技术扭曲模型输出意图的问题，显著提升了代码生成的质量和语义一致性。

Abstract: Language model-based code generation and completion tools have been widely
adopted, but they may sometimes produce code that does not meet necessary
constraints, such as syntactic correctness or API existence. Constrained
decoding techniques are developed to help the model generate code adhering to
the constraints by greedily eliminating generation options that violate
constraints at each step of the generation process. However, there is a severe
limitation of constrained decoding, that it distorts the model's output intent,
forcing it to produce code that may satisfy the constraint but does not match
the development intent and is therefore incorrect. In response to this
challenge, we propose AdapTrack. By incorporating backtracking into the
generation process, AdapTrack avoids distorting the output intent of the model,
thereby producing results that are not only constraint-compliant but also more
semantically aligned with model's output intent. On our synthetic API
completion dataset, AdapTrack can achieve up to 360.87% improvement compared to
constrained decoding; on the real-world API completion dataset we collect that
exhibits similar issues, AdapTrack can achieve up to 38.93% improvement over
constrained decoding; in general code genration benchmarks, compared to
constrained decoding, AdapTrack can achieve up to 7.84% improvement on
HumanEval, and up to 6.42% improvement on MBPP. This indicates that, simply by
better adhering to the model's output intent, AdapTrack can achieve significant
improvements. We provide a theoretical proof that the distribution produced by
AdapTrack aligns with the model's distribution given the generated tokens,
thereby ensuring that the model's output intent is not distorted. Experiments
on DSL problems show that, compared to existing methods, our approach can
provide generation results that are more consistent with the language model's
distribution.

</details>


### [203] [Scalable CI/CD for Legacy Modernization: An Industrial Experience Addressing Internal Challenges Related to the 2025 Japan Cliff](https://arxiv.org/abs/2510.17430)
*Kuniaki Kudo,Sherine Devi*

Main category: cs.SE

TL;DR: 为解决日本2025年悬崖问题，本文设计了一种可扩展CI/CD流水线，结合GitHub、Jenkins、AWS和Docker，降低了维护成本并促进了数字化转型。


<details>
  <summary>Details</summary>
Motivation: 日本2025年悬崖问题导致传统核心IT系统的维护成本激增且难以更新或替换，阻碍了数字化转型。Asahi公司也面临类似挑战，手动维护流程和有限的QA环境使关键系统过时且难以更新。

Method: 采用GitHub进行源代码控制和分支管理，Jenkins实现流水线自动化，AWS提供可扩展的环境，Docker实现环境容器化。

Result: 通过可扩展CI/CD流水线，开发者能自由安全地测试维护程序并尝试新技术，降低了维护成本并推动了数字化转型。

Conclusion: 本文提出了一种可扩展的CI/CD流水线，有效解决了日本2025年悬崖问题，通过动态创建和删除隔离的开发环境，显著降低了维护成本并推动了数字化转型。

Abstract: We have developed a Scalable CI/CD Pipeline to address internal challenges
related to Japan 2025 cliff problem, a critical issue where the mass end of
service life of legacy core IT systems threatens to significantly increase the
maintenance cost and black box nature of these system also leads to difficult
update moreover replace, which leads to lack of progress in Digital
Transformation (DX). If not addressed, Japan could potentially lose up to 12
trillion yen per year after 2025, which is 3 times more than the cost in
previous years. Asahi also faced the same internal challenges regarding legacy
system, where manual maintenance workflows and limited QA environment have left
critical systems outdated and difficult to update. Middleware and OS version
have remained unchanged for years, leading to now its nearing end of service
life which require huge maintenance cost and effort to continue its operation.
To address this problem, we have developed and implemented a Scalable CI/CD
Pipeline where isolated development environments can be created and deleted
dynamically and is scalable as needed. This Scalable CI/CD Pipeline incorporate
GitHub for source code control and branching, Jenkins for pipeline automation,
Amazon Web Services for scalable environment, and Docker for environment
containerization. This paper presents the design and architecture of the
Scalable CI/CD Pipeline, with the implementation along with some use cases.
Through Scalable CI/CD, developers can freely and safely test maintenance
procedures and do experiments with new technology in their own environment,
reducing maintenance cost and drive Digital Transformation (DX).
  key words: 2025 Japan Cliff, Scalable CI/CD, DevOps, Legacy IT Modernization.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [204] [VisuoAlign: Safety Alignment of LVLMs with Multimodal Tree Search](https://arxiv.org/abs/2510.15948)
*MingSheng Li,Guangze Zhao,Sichen Liu*

Main category: cs.AI

TL;DR: VisuoAlign是一个通过提示引导树搜索实现多模态安全对齐的框架，显著提升了LVLMs的安全性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态感知和生成方面取得显著进展，但其安全对齐仍面临关键挑战，现有防御方法易受多模态越狱攻击，视觉输入引入新的攻击面，推理链缺乏安全监督，且对齐在多模态融合时性能下降。

Method: 提出了VisuoAlign框架，通过视觉-文本交互提示嵌入安全约束，采用蒙特卡洛树搜索（MCTS）系统构建多样化的安全关键提示轨迹，并引入基于提示的缩放技术实现实时风险检测和合规响应。

Result: 大量实验表明，VisuoAlign能主动暴露风险、生成全面的数据集，并显著提升LVLMs对复杂跨模态威胁的鲁棒性。

Conclusion: VisuoAlign通过将安全约束嵌入推理过程、利用MCTS构建多样化的安全关键提示轨迹，并引入基于提示的缩放技术，显著提升了LVLMs对复杂跨模态威胁的鲁棒性。

Abstract: Large Vision-Language Models (LVLMs) have achieved remarkable progress in
multimodal perception and generation, yet their safety alignment remains a
critical challenge.Existing defenses and vulnerable to multimodal jailbreaks,
as visual inputs introduce new attack surfaces, reasoning chains lack safety
supervision, and alignment often degrades under modality fusion.To overcome
these limitation, we propose VisuoAlign, a framework for multi-modal safety
alignment via prompt-guided tree search.VisuoAlign embeds safety constrains
into the reasoning process through visual-textual interactive prompts, employs
Monte Carlo Tree Search(MCTS) to systematically construct diverse
safety-critical prompt trajectories, and introduces prompt-based scaling to
ensure real-time risk detection and compliant responses.Extensive experiments
demonstrate that VisuoAlign proactively exposes risks, enables comprehensive
dataset generation, and significantly improves the robustness of LVLMs against
complex cross-modal threats.

</details>


### [205] [Executable Epistemology: The Structured Cognitive Loop as an Architecture of Intentional Understanding](https://arxiv.org/abs/2510.15952)
*Myung Ho Kim*

Main category: cs.AI

TL;DR: SCL是一个可执行的认知框架，将哲学理论转化为可计算结构，重新定义智能为动态的认知重建过程，为AI和哲学研究提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 当前大语言模型虽表现出智能但缺乏真正的认知理解，凸显了认知架构的缺失。SCL旨在填补这一空白，探索认知涌现的条件而非仅追问智能的本质。

Method: 基于心智哲学和认知现象学，结合过程哲学、具身认知和扩展心智理论，提出了结构化认知循环（SCL）框架，将智能定义为一种执行过程而非静态属性，并通过代理评估验证其有效性。

Result: SCL实现了哲学洞见的可计算化，展示了功能分离的认知架构比单一提示系统更具一致性和可解释性，并重新定义了智能为对自身认知状态的意向性重建能力。

Conclusion: SCL框架通过将哲学洞见转化为可计算结构，不仅为AI提供了可执行的认知架构，还重新定义了智能的本质——不是表征准确性，而是通过意向性理解重建自身认知状态的能力。这一框架对心智哲学、认识论和AI领域均有深远影响。

Abstract: Large language models exhibit intelligence without genuine epistemic
understanding, exposing a key gap: the absence of epistemic architecture. This
paper introduces the Structured Cognitive Loop (SCL) as an executable
epistemological framework for emergent intelligence. Unlike traditional AI
research asking "what is intelligence?" (ontological), SCL asks "under what
conditions does cognition emerge?" (epistemological). Grounded in philosophy of
mind and cognitive phenomenology, SCL bridges conceptual philosophy and
implementable cognition. Drawing on process philosophy, enactive cognition, and
extended mind theory, we define intelligence not as a property but as a
performed process -- a continuous loop of judgment, memory, control, action,
and regulation. SCL makes three contributions. First, it operationalizes
philosophical insights into computationally interpretable structures, enabling
"executable epistemology" -- philosophy as structural experiment. Second, it
shows that functional separation within cognitive architecture yields more
coherent and interpretable behavior than monolithic prompt based systems,
supported by agent evaluations. Third, it redefines intelligence: not
representational accuracy but the capacity to reconstruct its own epistemic
state through intentional understanding. This framework impacts philosophy of
mind, epistemology, and AI. For philosophy, it allows theories of cognition to
be enacted and tested. For AI, it grounds behavior in epistemic structure
rather than statistical regularity. For epistemology, it frames knowledge not
as truth possession but as continuous reconstruction within a
phenomenologically coherent loop. We situate SCL within debates on cognitive
phenomenology, emergence, normativity, and intentionality, arguing that real
progress requires not larger models but architectures that realize cognitive
principles structurally.

</details>


### [206] [Exploring the Potential of Citiverses for Regulatory Learning](https://arxiv.org/abs/2510.15959)
*Isabelle Hupont,Marisa Ponti,Sven Schade*

Main category: cs.AI

TL;DR: 该论文提出利用citiverses作为监管学习的虚拟实验空间，通过专家咨询识别关键研究领域和实验主题，强调负责任开发和多维度考量。


<details>
  <summary>Details</summary>
Motivation: 探索citiverses作为沉浸式虚拟环境，支持监管学习的潜力，以应对交通、城市规划和环境/气候危机等领域的政策挑战。

Method: 论文基于与高级专家小组的咨询，包括欧洲委员会的政策制定者、国家政府科学顾问以及数字监管和虚拟世界领域的领先研究人员，识别了关键研究领域和一系列实验主题。

Result: 识别了包括可扩展性、实时反馈、复杂性建模、跨境协作、风险降低、公民参与、伦理考虑和新兴技术整合等关键研究领域，并分析了可在citiverse平台上测试的实验主题。

Conclusion: 该论文提出了一个科学政策议程，旨在探索citiverses作为监管学习实验空间的潜力，并强调在开发和使用citiverses时需采取负责任的方法，综合考虑伦理、经济、生态和社会等多维度因素。

Abstract: Citiverses hold the potential to support regulatory learning by offering
immersive, virtual environments for experimenting with policy scenarios and
technologies. This paper proposes a science-for-policy agenda to explore the
potential of citiverses as experimentation spaces for regulatory learning,
grounded in a consultation with a high-level panel of experts, including
policymakers from the European Commission, national government science advisers
and leading researchers in digital regulation and virtual worlds. It identifies
key research areas, including scalability, real-time feedback, complexity
modelling, cross-border collaboration, risk reduction, citizen participation,
ethical considerations and the integration of emerging technologies. In
addition, the paper analyses a set of experimental topics, spanning
transportation, urban planning and the environment/climate crisis, that could
be tested in citiverse platforms to advance regulatory learning in these areas.
The proposed work is designed to inform future research for policy and
emphasizes a responsible approach to developing and using citiverses. It
prioritizes careful consideration of the ethical, economic, ecological and
social dimensions of different regulations. The paper also explores essential
preliminary steps necessary for integrating citiverses into the broader
ecosystems of experimentation spaces, including test beds, living labs and
regulatory sandboxes

</details>


### [207] [PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency](https://arxiv.org/abs/2510.15966)
*Shian Jia,Ziyang Huang,Xinbo Wang,Haofei Zhang,Mingli Song*

Main category: cs.AI

TL;DR: PISA是一种受心理学启发的记忆系统，通过三模态适应和混合检索架构，显著提升AI代理的适应性和知识保留能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI代理的记忆系统缺乏对多样化任务的适应性，且忽视了记忆的构建性和任务导向性。

Method: PISA 引入了三模态适应机制（模式更新、模式演化和模式创建），并结合了符号推理与神经检索的混合内存访问架构。

Result: 在LOCOMO基准和新提出的AggQA基准上，PISA显著提升了检索准确性和效率，确立了新的技术标杆。

Conclusion: PISA 提出了一种创新的、受心理学启发的统一记忆系统，通过将记忆视为构建性和适应性的过程，显著提升了AI代理的适应性和长期知识保留能力。

Abstract: Memory systems are fundamental to AI agents, yet existing work often lacks
adaptability to diverse tasks and overlooks the constructive and task-oriented
role of AI agent memory. Drawing from Piaget's theory of cognitive development,
we propose PISA, a pragmatic, psych-inspired unified memory system that
addresses these limitations by treating memory as a constructive and adaptive
process. To enable continuous learning and adaptability, PISA introduces a
trimodal adaptation mechanism (i.e., schema updation, schema evolution, and
schema creation) that preserves coherent organization while supporting flexible
memory updates. Building on these schema-grounded structures, we further design
a hybrid memory access architecture that seamlessly integrates symbolic
reasoning with neural retrieval, significantly improving retrieval accuracy and
efficiency. Our empirical evaluation, conducted on the existing LOCOMO
benchmark and our newly proposed AggQA benchmark for data analysis tasks,
confirms that PISA sets a new state-of-the-art by significantly enhancing
adaptability and long-term knowledge retention.

</details>


### [208] [Limits of Emergent Reasoning of Large Language Models in Agentic Frameworks for Deterministic Games](https://arxiv.org/abs/2510.15974)
*Chris Su,Harrison Li,Matheus Marques,George Flint,Kevin Zhu,Sunishchal Dev*

Main category: cs.AI

TL;DR: 研究发现LLM在复杂谜题中性能崩溃，环境接口无效，模式崩溃是关键。


<details>
  <summary>Details</summary>
Motivation: 探讨大型推理模型在解决复杂谜题时性能崩溃的原因，以及环境接口是否能缓解这一问题。

Method: 通过为大型语言模型（LLM）提供汉诺塔问题的环境接口，允许其通过工具调用进行操作、提供书面理由、观察结果状态空间并自我提示下一步行动。

Result: 环境接口并未延迟或消除性能崩溃，模型在复杂度的每一层级都表现出模式崩溃，性能取决于模式是否反映问题的正确解决方案。

Conclusion: 研究表明，大型推理模型（LRMs）在解决特定复杂度以上的谜题时会出现性能崩溃，且这种现象可能与模型自身的状态空间跟踪能力有关。

Abstract: Recent work reports that Large Reasoning Models (LRMs) undergo a collapse in
performance on solving puzzles beyond certain perplexity thresholds. In
subsequent discourse, questions have arisen as to whether the nature of the
task muddles an evaluation of true reasoning. One potential confound is the
requirement that the model keep track of the state space on its own. We provide
a large language model (LLM) with an environment interface for Tower of Hanoi
problems, allowing it to make a move with a tool call, provide written
justification, observe the resulting state space, and reprompt itself for the
next move. We observe that access to an environment interface does not delay or
eradicate performance collapse. Furthermore, LLM-parameterized policy analysis
reveals increasing divergence from both optimal policies and uniformly random
policies, suggesting that the model exhibits mode-like collapse at each level
of complexity, and that performance is dependent upon whether the mode reflects
the correct solution for the problem. We suggest that a similar phenomena might
take place in LRMs.

</details>


### [209] [Cognitive Load Traces as Symbolic and Visual Accounts of Deep Model Cognition](https://arxiv.org/abs/2510.15980)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CLTs是一种中层可解释性框架，通过量化模型内部资源分配，能预测错误、揭示策略并提升推理效率15-30%。


<details>
  <summary>Details</summary>
Motivation: 受人类认知中的认知负载理论启发，旨在为深度模型提供中层可解释性框架，以理解模型内部的资源分配和推理动态。

Method: 提出CLTs作为符号化、随时间变化的函数，量化模型内部资源分配，具体表示为三组分随机过程（IL_t, EL_t, GL_t），并通过注意力熵、KV缓存缺失率等可测量代理实例化。同时提出了符号化公式和可视化方法（负载曲线、单纯形图）。

Result: 在推理和规划基准测试中，CLTs能够预测错误发生、揭示认知策略，并通过负载引导干预提升推理效率15-30%且保持准确性。

Conclusion: CLTs 作为一种中层可解释性框架，通过量化模型内部资源分配，不仅能够预测错误发生，还能揭示认知策略，并通过负载引导干预提升推理效率15-30%且保持准确性。

Abstract: We propose \textbf{Cognitive Load Traces} (CLTs) as a mid-level
interpretability framework for deep models, inspired by Cognitive Load Theory
in human cognition. CLTs are defined as symbolic, temporally varying functions
that quantify model-internal resource allocation. Formally, we represent CLTs
as a three-component stochastic process $(\mathrm{IL}_t, \mathrm{EL}_t,
\mathrm{GL}_t)$, corresponding to \emph{Intrinsic}, \emph{Extraneous}, and
\emph{Germane} load. Each component is instantiated through measurable proxies
such as attention entropy, KV-cache miss ratio, representation dispersion, and
decoding stability. We propose both symbolic formulations and visualization
methods (load curves, simplex diagrams) that enable interpretable analysis of
reasoning dynamics. Experiments on reasoning and planning benchmarks show that
CLTs predict error-onset, reveal cognitive strategies, and enable load-guided
interventions that improve reasoning efficiency by 15-30\% while maintaining
accuracy.

</details>


### [210] [ProofFlow: A Dependency Graph Approach to Faithful Proof Autoformalization](https://arxiv.org/abs/2510.15981)
*Rafael Cabral,Tuan Manh Do,Xuejun Yu,Wai Ming Tai,Zijin Feng,Xin Shen*

Main category: cs.AI

TL;DR: ProofFlow通过DAG和基于引理的方法，在自动形式化中实现了更高的结构保真和性能，ProofScore达0.545。


<details>
  <summary>Details</summary>
Motivation: 现有的自动形式化方法虽能生成可执行代码，但常无法保留原始论证的语义和逻辑结构，因此需要一种更注重结构保真的新方法。

Method: ProofFlow首先构建有向无环图（DAG）映射证明步骤间的逻辑依赖关系，然后采用基于引理的方法逐步形式化每个步骤为中间引理。

Result: ProofFlow在184个本科级问题的基准测试中表现出色，ProofScore为0.545，显著优于完整证明形式化（0.123）和逐步证明形式化（0.072）。

Conclusion: ProofFlow通过引入结构保真作为主要目标，显著提升了自动形式化的性能，其ProofScore达到0.545，远超基线方法。

Abstract: Proof autoformalization, the task of translating natural language theorems
and proofs into machine-verifiable code, is a critical step for integrating
large language models into rigorous mathematical workflows. Current approaches
focus on producing executable code, but they frequently fail to preserve the
semantic meaning and logical structure of the original human-written argument.
To address this, we introduce ProofFlow, a novel pipeline that treats
structural fidelity as a primary objective. ProofFlow first constructs a
directed acyclic graph (DAG) to map the logical dependencies between proof
steps. Then, it employs a novel lemma-based approach to systematically
formalize each step as an intermediate lemma, preserving the logical structure
of the original argument. To facilitate evaluation, we present a new benchmark
of 184 undergraduate-level problems, manually annotated with step-by-step
solutions and logical dependency graphs, and introduce ProofScore, a new
composite metric to evaluate syntactic correctness, semantic faithfulness, and
structural fidelity. Experimental results show our pipeline sets a new
state-of-the-art for autoformalization, achieving a ProofScore of 0.545,
substantially exceeding baselines like full-proof formalization (0.123), which
processes the entire proof at once, and step-proof formalization (0.072), which
handles each step independently. Our pipeline, benchmark, and score metric are
open-sourced to encourage further progress at
https://github.com/Huawei-AI4Math/ProofFlow.

</details>


### [211] [Ontologies in Motion: A BFO-Based Approach to Knowledge Graph Construction for Motor Performance Research Data in Sports Science](https://arxiv.org/abs/2510.15983)
*Sarah Rebecca Ondraszek,Jörg Waitelonis,Katja Keller,Claudia Niessner,Anna M. Jacyszyn,Harald Sack*

Main category: cs.AI

TL;DR: 本研究提出基于MO|RE数据构建知识图谱，通过语义模型标准化运动表现数据，促进体育科学研究的数字化转型。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较不同人群的生理和认知能力，需要一种标准化的方法来测试和分析运动表现数据，MO|RE数据仓库为此提供了基础。

Method: 采用基于基本形式本体论（Basic Formal Ontology）的语义模型，将计划规范、具体过程及相关测量之间的相互关系形式化表示。

Result: 提出了一个将MO|RE数据转化为知识图谱的框架，旨在实现运动表现数据的标准化和机器可理解性。

Conclusion: 通过构建基于MO|RE数据知识图谱，本研究旨在标准化和机器可理解的方式建模和共享运动表现数据，推动体育科学研究的数字化转型。

Abstract: An essential component for evaluating and comparing physical and cognitive
capabilities between populations is the testing of various factors related to
human performance. As a core part of sports science research, testing motor
performance enables the analysis of the physical health of different
demographic groups and makes them comparable.
  The Motor Research (MO|RE) data repository, developed at the Karlsruhe
Institute of Technology, is an infrastructure for publishing and archiving
research data in sports science, particularly in the field of motor performance
research. In this paper, we present our vision for creating a knowledge graph
from MO|RE data. With an ontology rooted in the Basic Formal Ontology, our
approach centers on formally representing the interrelation of plan
specifications, specific processes, and related measurements. Our goal is to
transform how motor performance data are modeled and shared across studies,
making it standardized and machine-understandable. The idea presented here is
developed within the Leibniz Science Campus ``Digital Transformation of
Research'' (DiTraRe).

</details>


### [212] [A Non-overlap-based Conflict Measure for Random Permutation Sets](https://arxiv.org/abs/2510.16001)
*Ruolan Cheng,Yong Deng,Enrique Herrera-Viedma*

Main category: cs.AI

TL;DR: 本文从RFS和DST视角分析了RPS中的冲突，提出了一种非重叠冲突度量方法，具有顶部加权性质，并提供了参数灵活选择。


<details>
  <summary>Details</summary>
Motivation: 测量由排列质量函数表示的两个证据之间的冲突是顺序结构不确定信息融合中的一个紧迫研究课题。

Method: 本文从随机有限集（RFS）和Dempster-Shafer理论（DST）两个不同视角对RPS中的冲突进行了详细分析。首先基于排列的观察，定义了排列间的不一致性度量，并进一步提出了RPS的非重叠冲突度量方法。

Result: 通过数值示例展示了所提出冲突度量的行为和性质。

Conclusion: 本文提出的冲突度量方法不仅具有自然的顶部加权性质，能够从DST视角有效衡量RPS之间的冲突，还为决策者提供了权重、参数和截断深度的灵活选择。

Abstract: Random permutation set (RPS) is a new formalism for reasoning with
uncertainty involving order information. Measuring the conflict between two
pieces of evidence represented by permutation mass functions remains an urgent
research topic in order-structured uncertain information fusion. In this paper,
a detailed analysis of conflicts in RPS is carried out from two different
perspectives: random finite set (RFS) and Dempster-Shafer theory (DST).
Starting from the observation of permutations, we first define an inconsistency
measure between permutations inspired by the rank-biased overlap(RBO) measure
and further propose a non-overlap-based conflict measure method for RPSs. This
paper regards RPS theory (RPST) as an extension of DST. The order information
newly added in focal sets indicates qualitative propensity, characterized by
top-ranked elements occupying a more critical position. Some numerical examples
are used to demonstrate the behavior and properties of the proposed conflict
measure. The proposed method not only has the natural top-weightedness property
and can effectively measure the conflict between RPSs from the DST view but
also provides decision-makers with a flexible selection of weights, parameters,
and truncated depths.

</details>


### [213] [PAINT: Parallel-in-time Neural Twins for Dynamical System Reconstruction](https://arxiv.org/abs/2510.16004)
*Andreas Radler,Vincent Seyfried,Stefan Pirker,Johannes Brandstetter,Thomas Lichtenegger*

Main category: cs.AI

TL;DR: PAINT是一种新型神经孪生体方法，能够在动态系统中保持轨迹并从稀疏测量中高保真预测状态。


<details>
  <summary>Details</summary>
Motivation: 提出神经孪生体作为神经代理的进一步发展，旨在创建真实系统的数字副本，以支持上下文特定的决策。

Method: PAINT是一种架构无关的方法家族，通过训练生成神经网络来建模并行时间状态分布，并在测试时以滑动窗口方式从测量中预测状态。

Result: PAINT在具有挑战性的二维湍流流体动力学问题上表现出色，能够保持轨迹并从稀疏测量中高保真地预测系统状态。

Conclusion: PAINT展示了在开发能够保持轨迹的神经孪生体方面的潜力，从而实现更准确的状态估计和决策。

Abstract: Neural surrogates have shown great potential in simulating dynamical systems,
while offering real-time capabilities. We envision Neural Twins as a
progression of neural surrogates, aiming to create digital replicas of real
systems. A neural twin consumes measurements at test time to update its state,
thereby enabling context-specific decision-making. A critical property of
neural twins is their ability to remain on-trajectory, i.e., to stay close to
the true system state over time. We introduce Parallel-in-time Neural Twins
(PAINT), an architecture-agnostic family of methods for modeling dynamical
systems from measurements. PAINT trains a generative neural network to model
the distribution of states parallel over time. At test time, states are
predicted from measurements in a sliding window fashion. Our theoretical
analysis shows that PAINT is on-trajectory, whereas autoregressive models
generally are not. Empirically, we evaluate our method on a challenging
two-dimensional turbulent fluid dynamics problem. The results demonstrate that
PAINT stays on-trajectory and predicts system states from sparse measurements
with high fidelity. These findings underscore PAINT's potential for developing
neural twins that stay on-trajectory, enabling more accurate state estimation
and decision-making.

</details>


### [214] [Global-focal Adaptation with Information Separation for Noise-robust Transfer Fault Diagnosis](https://arxiv.org/abs/2510.16033)
*Junyu Ren,Wensheng Gan,Guangyu Zhang,Wei Zhong,Philip S. Yu*

Main category: cs.AI

TL;DR: ISGFAN框架通过信息分离和对抗学习，有效解决噪声和领域偏移下的故障诊断问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有迁移故障诊断方法通常假设数据干净或领域相似，但在工业环境中，噪声干扰和领域偏移共存，限制了这些方法的有效性。

Method: ISGFAN框架基于信息分离架构，结合对抗学习和改进的正交损失，解耦领域不变的故障表示，同时采用全局-局部对抗方案约束模型的条件和边缘分布。

Result: 在三个公共基准数据集上的实验表明，ISGFAN优于其他现有方法。

Conclusion: ISGFAN框架通过信息分离和全局-局部对抗学习，有效解决了噪声和领域偏移共存下的跨领域故障诊断问题，实验证明其优于现有方法。

Abstract: Existing transfer fault diagnosis methods typically assume either clean data
or sufficient domain similarity, which limits their effectiveness in industrial
environments where severe noise interference and domain shifts coexist. To
address this challenge, we propose an information separation global-focal
adversarial network (ISGFAN), a robust framework for cross-domain fault
diagnosis under noise conditions. ISGFAN is built on an information separation
architecture that integrates adversarial learning with an improved orthogonal
loss to decouple domain-invariant fault representation, thereby isolating noise
interference and domain-specific characteristics. To further strengthen
transfer robustness, ISGFAN employs a global-focal domain-adversarial scheme
that constrains both the conditional and marginal distributions of the model.
Specifically, the focal domain-adversarial component mitigates
category-specific transfer obstacles caused by noise in unsupervised scenarios,
while the global domain classifier ensures alignment of the overall
distribution. Experiments conducted on three public benchmark datasets
demonstrate that the proposed method outperforms other prominent existing
approaches, confirming the superiority of the ISGFAN framework. Data and code
are available at https://github.com/JYREN-Source/ISGFAN

</details>


### [215] [Algorithms for dynamic scheduling in manufacturing, towards digital factories Improving Deadline Feasibility and Responsiveness via Temporal Networks](https://arxiv.org/abs/2510.16047)
*Ioan Hedea*

Main category: cs.AI

TL;DR: 该论文提出一种结合离线CP优化与在线STNU执行的混合调度方法，在最坏不确定性下仍保证可行性，显著减少截止期限违反，且计算效率高。


<details>
  <summary>Details</summary>
Motivation: 现代制造系统需要在应对随机任务持续时间的同时满足严格的交付期限，传统确定性调度在现实偏离名义计划时崩溃，导致昂贵的最后修复。

Method: 首先构建一个灵活作业车间的CP模型，插入最优缓冲Δ*以获得完全主动的基线，然后将计划转化为具有不确定性的简单时序网络（STNU）并验证动态可控性。

Result: 在Kacem 1-4基准测试套件上的蒙特卡洛模拟显示，混合方法消除了100%的截止期限违反，同时仅增加3-5%的总工期开销，CP求解时间和STNU检查在中等规模实例上保持亚秒级。

Conclusion: 该研究通过结合离线约束编程优化与在线时序网络执行，创建了在最坏不确定性下仍可行的调度方案，为真正数字化、自我纠正的工厂迈出了重要一步。

Abstract: Modern manufacturing systems must meet hard delivery deadlines while coping
with stochastic task durations caused by process noise, equipment variability,
and human intervention. Traditional deterministic schedules break down when
reality deviates from nominal plans, triggering costly last-minute repairs.
This thesis combines offline constraint-programming (CP) optimisation with
online temporal-network execution to create schedules that remain feasible
under worst-case uncertainty. First, we build a CP model of the flexible
job-shop with per-job deadline tasks and insert an optimal buffer $\Delta^*$ to
obtain a fully pro-active baseline. We then translate the resulting plan into a
Simple Temporal Network with Uncertainty (STNU) and verify dynamic
controllability, which guarantees that a real-time dispatcher can retime
activities for every bounded duration realisation without violating resource or
deadline constraints. Extensive Monte-Carlo simulations on the open Kacem~1--4
benchmark suite show that our hybrid approach eliminates 100\% of deadline
violations observed in state-of-the-art meta-heuristic schedules, while adding
only 3--5\% makespan overhead. Scalability experiments confirm that CP
solve-times and STNU checks remain sub-second on medium-size instances. The
work demonstrates how temporal-network reasoning can bridge the gap between
proactive buffering and dynamic robustness, moving industry a step closer to
truly digital, self-correcting factories.

</details>


### [216] [Reliability of Large Language Model Generated Clinical Reasoning in Assisted Reproductive Technology: Blinded Comparative Evaluation Study](https://arxiv.org/abs/2510.16095)
*Dou Liu,Ying Long,Sophia Zuoqiu,Di Liu,Kang Li,Yiting Lin,Hanyi Liu,Rong Yin,Tian Tang*

Main category: cs.AI

TL;DR: 本研究验证了选择性提示策略在生成高质量临床CoTs中的有效性，并提出了'双原则'框架，强调人类专家在临床AI评估中的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决高质量临床CoTs生成中的数据稀缺问题，并验证LLM生成的CoTs的临床可靠性。

Method: 通过盲法比较研究，资深辅助生殖技术（ART）临床专家评估了三种不同策略生成的CoTs：零样本、随机少样本（使用浅层示例）和选择性少样本（使用多样化的高质量示例）。这些专家评分与最先进的AI模型（GPT-4o）的评估进行了比较。

Result: 选择性少样本策略在所有人类评估指标上显著优于其他策略（p < .001），而随机少样本策略与零样本基线相比无显著改进。AI评估器未能识别这些关键性能差异。

Conclusion: 本研究提出了一个基于'双原则'框架的方法论，用于规模化生成可信赖的临床CoTs数据，强调了人类专家在高风险临床AI评估中的不可替代作用。

Abstract: Creating high-quality clinical Chains-of-Thought (CoTs) is crucial for
explainable medical Artificial Intelligence (AI) while constrained by data
scarcity. Although Large Language Models (LLMs) can synthesize medical data,
their clinical reliability remains unverified. This study evaluates the
reliability of LLM-generated CoTs and investigates prompting strategies to
enhance their quality. In a blinded comparative study, senior clinicians in
Assisted Reproductive Technology (ART) evaluated CoTs generated via three
distinct strategies: Zero-shot, Random Few-shot (using shallow examples), and
Selective Few-shot (using diverse, high-quality examples). These expert ratings
were compared against evaluations from a state-of-the-art AI model (GPT-4o).
The Selective Few-shot strategy significantly outperformed other strategies
across all human evaluation metrics (p < .001). Critically, the Random Few-shot
strategy offered no significant improvement over the Zero-shot baseline,
demonstrating that low-quality examples are as ineffective as no examples. The
success of the Selective strategy is attributed to two principles:
"Gold-Standard Depth" (reasoning quality) and "Representative Diversity"
(generalization). Notably, the AI evaluator failed to discern these critical
performance differences. The clinical reliability of synthetic CoTs is dictated
by strategic prompt curation, not the mere presence of examples. We propose a
"Dual Principles" framework as a foundational methodology to generate
trustworthy data at scale. This work offers a validated solution to the data
bottleneck and confirms the indispensable role of human expertise in evaluating
high-stakes clinical AI.

</details>


### [217] [Operationalising Extended Cognition: Formal Metrics for Corporate Knowledge and Legal Accountability](https://arxiv.org/abs/2510.16193)
*Elija Perrier*

Main category: cs.AI

TL;DR: 本文探讨了在算法时代如何通过动态能力重新定义企业知识，提出了一个形式模型来衡量企业知识，并将其映射到法律标准上，以实现可审计性和问责制。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI在企业决策中的日益介入，传统基于人类代理的企业责任假设受到挑战，需要重新定义企业知识以适应算法时代。

Method: 基于扩展认知理论，开发了一个形式模型，捕捉部署复杂AI或信息系统的企业的认知状态，引入了连续的组织知识度量$S_S(\varphi)$，整合了管道的计算成本和统计验证的错误率。

Result: 提出了一个形式模型，包括知识度量$S_S(\varphi)$、知识谓词$\mathsf{K}_S$和企业范围的认知能力指数$\mathcal{K}_{S,t}$，并将这些定量指标映射到法律标准上。

Conclusion: 本文提出了一种通过动态能力重新定义企业知识的方法，引入了连续的组织知识度量$S_S(\varphi)$和阈值知识谓词$\mathsf{K}_S$，为企业决策中的AI和信息系统的可审计性和问责制提供了可衡量的法律标准。

Abstract: Corporate responsibility turns on notions of corporate \textit{mens rea},
traditionally imputed from human agents. Yet these assumptions are under
challenge as generative AI increasingly mediates enterprise decision-making.
Building on the theory of extended cognition, we argue that in response
corporate knowledge may be redefined as a dynamic capability, measurable by the
efficiency of its information-access procedures and the validated reliability
of their outputs. We develop a formal model that captures epistemic states of
corporations deploying sophisticated AI or information systems, introducing a
continuous organisational knowledge metric $S_S(\varphi)$ which integrates a
pipeline's computational cost and its statistically validated error rate. We
derive a thresholded knowledge predicate $\mathsf{K}_S$ to impute knowledge and
a firm-wide epistemic capacity index $\mathcal{K}_{S,t}$ to measure overall
capability. We then operationally map these quantitative metrics onto the legal
standards of actual knowledge, constructive knowledge, wilful blindness, and
recklessness. Our work provides a pathway towards creating measurable and
justiciable audit artefacts, that render the corporate mind tractable and
accountable in the algorithmic age.

</details>


### [218] [Towards Automatic Evaluation and Selection of PHI De-identification Models via Multi-Agent Collaboration](https://arxiv.org/abs/2510.16194)
*Guanchen Wu,Zuhui Chen,Yuzhang Xie,Carl Yang*

Main category: cs.AI

TL;DR: TEAM-PHI 是一个多代理框架，利用 LLM 自动评估 PHI 去标识化质量并选择最佳模型，减少对真实标签的依赖。


<details>
  <summary>Details</summary>
Motivation: PHI 去标识化对于临床笔记的安全重用至关重要，但评估和比较模型通常依赖于昂贵的小规模专家注释。

Method: TEAM-PHI 部署了多个评估代理，每个代理独立判断 PHI 提取的正确性并输出结构化指标。然后通过基于 LLM 的多数投票机制整合结果。

Result: 实验表明，TEAM-PHI 生成了一致且准确的排名，与真实注释和人类评估结果高度匹配。

Conclusion: TEAM-PHI 提供了一种实用、安全且经济高效的解决方案，用于在 PHI 去标识化中自动评估和选择最佳模型，即使真实标签有限。

Abstract: Protected health information (PHI) de-identification is critical for enabling
the safe reuse of clinical notes, yet evaluating and comparing PHI
de-identification models typically depends on costly, small-scale expert
annotations. We present TEAM-PHI, a multi-agent evaluation and selection
framework that uses large language models (LLMs) to automatically measure
de-identification quality and select the best-performing model without heavy
reliance on gold labels. TEAM-PHI deploys multiple Evaluation Agents, each
independently judging the correctness of PHI extractions and outputting
structured metrics. Their results are then consolidated through an LLM-based
majority voting mechanism that integrates diverse evaluator perspectives into a
single, stable, and reproducible ranking. Experiments on a real-world clinical
note corpus demonstrate that TEAM-PHI produces consistent and accurate
rankings: despite variation across individual evaluators, LLM-based voting
reliably converges on the same top-performing systems. Further comparison with
ground-truth annotations and human evaluation confirms that the framework's
automated rankings closely match supervised evaluation. By combining
independent evaluation agents with LLM majority voting, TEAM-PHI offers a
practical, secure, and cost-effective solution for automatic evaluation and
best-model selection in PHI de-identification, even when ground-truth labels
are limited.

</details>


### [219] [The Right to Be Remembered: Preserving Maximally Truthful Digital Memory in the Age of AI](https://arxiv.org/abs/2510.16206)
*Alex Zhavoronkov,Dominika Wilczok,Roman Yampolskiy*

Main category: cs.AI

TL;DR: 论文探讨LLMs可能导致的信息偏见问题，提出‘被记住的权利’（RTBR）以确保AI生成内容的多样性和真实性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的广泛应用，其对信息检索的影响可能导致某些观点被过度放大或忽略，从而威胁集体记忆的多样性。

Method: 通过分析大型语言模型（LLMs）对信息检索的影响，提出RTBR概念以应对潜在的信息偏见和遗漏问题。

Result: 提出RTBR概念，强调在AI生成内容中需平衡信息多样性、公平性和真实性。

Conclusion: 论文提出了‘被记住的权利’（RTBR）概念，旨在减少AI驱动的信息遗漏风险，确保公平对待，并最大化生成内容的真实性。

Abstract: Since the rapid expansion of large language models (LLMs), people have begun
to rely on them for information retrieval. While traditional search engines
display ranked lists of sources shaped by search engine optimization (SEO),
advertising, and personalization, LLMs typically provide a synthesized response
that feels singular and authoritative. While both approaches carry risks of
bias and omission, LLMs may amplify the effect by collapsing multiple
perspectives into one answer, reducing users ability or inclination to compare
alternatives. This concentrates power over information in a few LLM vendors
whose systems effectively shape what is remembered and what is overlooked. As a
result, certain narratives, individuals or groups, may be disproportionately
suppressed, while others are disproportionately elevated. Over time, this
creates a new threat: the gradual erasure of those with limited digital
presence, and the amplification of those already prominent, reshaping
collective memory.To address these concerns, this paper presents a concept of
the Right To Be Remembered (RTBR) which encompasses minimizing the risk of
AI-driven information omission, embracing the right of fair treatment, while
ensuring that the generated content would be maximally truthful.

</details>


### [220] [ScholarEval: Research Idea Evaluation Grounded in Literature](https://arxiv.org/abs/2510.16234)
*Hanane Nour Moussa,Patrick Queiroz Da Silva,Daniel Adu-Ampratwum,Alyson East,Zitong Lu,Nikki Puccetti,Mingyi Xue,Huan Sun,Bodhisattwa Prasad Majumder,Sachin Kumar*

Main category: cs.AI

TL;DR: ScholarEval是一个检索增强的评估框架，用于评估研究想法的健全性和贡献度，显著优于现有基线，并发布了代码和工具。


<details>
  <summary>Details</summary>
Motivation: 随着AI工具在研究构思中的普及，需要一种可靠的方法来评估生成想法的有效性和实用性。

Method: 引入了ScholarEval，一个基于检索增强的评估框架，结合了ScholarIdeas数据集（117个跨学科研究想法）进行验证。

Result: ScholarEval在覆盖专家标注的评分点、评估可操作性、深度和证据支持方面均优于基线，用户研究也证实其优越性。

Conclusion: ScholarEval框架在评估研究想法的健全性和贡献度方面显著优于现有基线，特别是在文献参与、想法精炼和实用性方面表现突出。

Abstract: As AI tools become increasingly common for research ideation, robust
evaluation is critical to ensure the validity and usefulness of generated
ideas. We introduce ScholarEval, a retrieval augmented evaluation framework
that assesses research ideas based on two fundamental criteria: soundness - the
empirical validity of proposed methods based on existing literature, and
contribution - the degree of advancement made by the idea across different
dimensions relative to prior research. To evaluate ScholarEval, we introduce
ScholarIdeas, the first expert-annotated dataset of multi-domain research ideas
and reviews, comprised of 117 ideas across four disciplines: artificial
intelligence, neuroscience, biochemistry, and ecology. Our evaluation shows
that ScholarEval achieves significantly higher coverage of points mentioned in
the human expert annotated rubrics in ScholarIdeas compared to all baselines.
Furthermore, ScholarEval is consistently preferred over our strongest baseline
o4-mini-deep-research, a reasoning and search-enabled agentic system by OpenAI,
in terms of evaluation actionability, depth, and evidence support. Our
large-scale user study also shows that ScholarEval significantly outperforms
deep research in literature engagement, idea refinement, and usefulness. We
openly release our code, dataset, and ScholarEval tool for the community to use
and build on.

</details>


### [221] [Distractor Injection Attacks on Large Reasoning Models: Characterization and Defense](https://arxiv.org/abs/2510.16259)
*Zhehao Zhang,Weijie Xu,Shixian Cui,Chandan K. Reddy*

Main category: cs.AI

TL;DR: 研究发现大型推理模型容易被恶意分心任务干扰，准确率下降高达60%，并提出结合SFT和RL的防御方法，显著提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务上表现出色，但存在被恶意嵌入的无关复杂任务分散注意力的漏洞，影响模型可靠性。

Method: 通过综合研究不同模型和基准，识别推理分心的脆弱性，并提出结合监督微调（SFT）和强化学习（RL）的防御方法。

Result: 实验表明，最先进的LRMs对推理分心高度敏感，分心注入可降低任务准确率高达60%。提出的防御方法在挑战性分心攻击上提高了50%以上的鲁棒性。

Conclusion: 研究发现推理分心是大型推理模型（LRMs）可靠性的一个独特且紧迫的威胁，并提出了一种基于训练的防御方法，显著提高了模型对分心攻击的鲁棒性。

Abstract: Recent advances in large reasoning models (LRMs) have enabled remarkable
performance on complex tasks such as mathematics and coding by generating long
Chain-of-Thought (CoT) traces. In this paper, we identify and systematically
analyze a critical vulnerability we term reasoning distraction, where LRMs are
diverted from their primary objective by irrelevant yet complex tasks
maliciously embedded in the prompt. Through a comprehensive study across
diverse models and benchmarks, we show that even state-of-the-art LRMs are
highly susceptible, with injected distractors reducing task accuracy by up to
60%. We further reveal that certain alignment techniques can amplify this
weakness and that models may exhibit covert compliance, following hidden
adversarial instructions in reasoning while concealing them in the final
output. To mitigate these risks, we propose a training-based defense that
combines Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL) on
synthetic adversarial data, improving robustness by over 50 points on
challenging distractor attacks. Our findings establish reasoning distraction as
a distinct and urgent threat to LRM reliability and provide a practical step
toward safer and more trustworthy reasoning systems.

</details>


### [222] [What Limits Agentic Systems Efficiency?](https://arxiv.org/abs/2510.16276)
*Song Bian,Minghao Yan,Anand Jayarajan,Gennady Pekhimenko,Shivaram Venkataraman*

Main category: cs.AI

TL;DR: 研究发现网络延迟占代理系统总延迟的53.7%，提出的SpecCache框架通过缓存和推测性执行显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注大型语言模型（LLMs）的推理性能，而忽视了代理系统的效率问题，尤其是网络交互带来的延迟。

Method: 本研究通过实证分析分解端到端延迟为LLM API延迟和网络环境延迟两部分，并提出SpecCache框架，结合推测性执行和缓存策略优化效率。

Result: SpecCache在标准基准测试中，缓存命中率提升高达58倍，网络环境开销降低3.2倍，且不影响代理系统性能。

Conclusion: SpecCache框架通过推测性执行和缓存策略显著提升了基于网络的代理系统效率，降低了网络环境延迟，同时保持了系统性能。

Abstract: Large Language Models (LLMs), such as OpenAI-o1 and DeepSeek-R1, have
demonstrated strong reasoning capabilities. To further enhance LLM
capabilities, recent agentic systems, such as Deep Research, incorporate web
interactions into LLM reasoning to mitigate uncertainties and reduce potential
errors. However, existing research predominantly focuses on reasoning
performance, often neglecting the efficiency of agentic systems. In this work,
we present a comprehensive empirical study that identifies efficiency
bottlenecks in web-interactive agentic systems. We decompose end-to-end latency
into two primary components: LLM API latency and web environment latency. We
conduct a comprehensive empirical study across 15 models and 5 providers to
demonstrate high variability in API-based agentic systems. We observe that web
environment latency can contribute as much as 53.7% to the overall latency in a
web-based agentic system. To improve latency, we propose SpecCache, a caching
framework augmented with speculative execution that can reduce web environment
overhead. Extensive evaluations on two standard benchmarks show that our
approach improves the cache hit rate by up to 58x compared to a random caching
strategy, while reducing web environment overhead by up to 3.2x, without
degrading agentic system performance.

</details>


### [223] [DTKG: Dual-Track Knowledge Graph-Verified Reasoning Framework for Multi-Hop QA](https://arxiv.org/abs/2510.16302)
*Changhao Wang,Yanfang Liu,Xinxin Fan,Anzhi Zhou,Lao Tian,Yunfeng Lu*

Main category: cs.AI

TL;DR: DTKG双轨KG验证和推理框架解决了多跳QA任务中并行事实验证和链式推理的局限性，提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳推理方法在处理并行事实验证和链式推理任务时存在局限性，影响效率和准确性。

Method: 提出了一个新颖的双轨KG验证和推理框架DTKG，包括分类阶段和分支处理阶段。

Result: DTKG框架能够同时优化并行事实验证和链式推理任务，提升整体性能。

Conclusion: DTKG框架通过结合双轨KG验证和推理，有效提升了多跳QA任务的效率和准确性。

Abstract: Multi-hop reasoning for question answering (QA) plays a critical role in
retrieval-augmented generation (RAG) for modern large language models (LLMs).
The accurate answer can be obtained through retrieving relational structure of
entities from knowledge graph (KG). Regarding the inherent relation-dependency
and reasoning pattern, multi-hop reasoning can be in general classified into
two categories: i) parallel fact-verification multi-hop reasoning question,
i.e., requiring simultaneous verifications of multiple independent
sub-questions; and ii) chained multi-hop reasoning questions, i.e., demanding
sequential multi-step inference with intermediate conclusions serving as
essential premises for subsequent reasoning. Currently, the multi-hop reasoning
approaches singly employ one of two techniques: LLM response-based fact
verification and KG path-based chain construction. Nevertheless, the former
excels at parallel fact-verification but underperforms on chained reasoning
tasks, while the latter demonstrates proficiency in chained multi-hop reasoning
but suffers from redundant path retrieval when handling parallel
fact-verification reasoning. These limitations deteriorate the efficiency and
accuracy for multi-hop QA tasks. To address this challenge, we propose a novel
dual-track KG verification and reasoning framework DTKG, which is inspired by
the Dual Process Theory in cognitive science. Specifically, DTKG comprises two
main stages: the Classification Stage and the Branch Processing Stage.

</details>


### [224] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Mathematical Reasoning with a Lightweight Verifier](https://arxiv.org/abs/2510.16309)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG通过知识图谱和符号验证器提升LLMs的数学推理准确性，实现100%精确匹配并消除规则违反。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成流畅推理步骤时常违反简单数学或逻辑约束，需要一种方法来保证推理的一致性和正确性。

Method: 引入MedRule-KG，一个紧凑的类型化知识图谱，结合符号验证器，用于强制执行数学可解释规则。

Result: 在90个FDA衍生的基准测试中，MedRule-KG将精确匹配率从0.767提升至0.900，加入验证器后达到1.000，完全消除了规则违反。

Conclusion: MedRule-KG结合符号验证器显著提升了大型语言模型在数学和逻辑推理任务中的准确性和一致性，消除了规则违反，展示了其在安全数学推理中的通用支架作用。

Abstract: Large language models (LLMs) often produce fluent reasoning steps while
violating simple mathematical or logical constraints. We introduce MedRule-KG,
a compact typed knowledge graph coupled with a symbolic verifier, designed to
enforce mathematically interpretable rules in reasoning tasks. MedRule-KG
encodes entities, relations, and three domain-inspired rules, while the
verifier checks predictions and applies minimal corrections to guarantee
consistency. On a 90-example FDA-derived benchmark, grounding in MedRule-KG
improves exact match (EM) from 0.767 to 0.900, and adding the verifier yields
1.000 EM while eliminating rule violations entirely. We demonstrate how
MedRule-KG provides a general scaffold for safe mathematical reasoning, discuss
ablations, and release code and data to encourage reproducibility.

</details>


### [225] [Beyond Fixed Anchors: Precisely Erasing Concepts with Sibling Exclusive Counterparts](https://arxiv.org/abs/2510.16342)
*Tong Zhang,Ru Zhang,Jianyi Liu,Zhen Yang,Gongshen Liu*

Main category: cs.AI

TL;DR: SELECT是一个动态锚定选择框架，通过两阶段评估机制自动发现最优锚点，解决了固定锚定策略导致的概念重新出现和侵蚀问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型的概念擦除方法通常依赖固定锚定策略，这往往导致概念重新出现和侵蚀等关键问题。为了解决这些问题，进行了因果追踪以揭示擦除对锚定选择的固有敏感性，并定义了Sibling Exclusive Concepts作为更优的锚定类别。

Method: 提出了SELECT（Sibling-Exclusive Evaluation for Contextual Targeting），这是一个动态锚定选择框架，引入了新颖的两阶段评估机制，自动发现最优锚点以进行精确擦除，同时识别关键边界锚点以保留相关概念。

Result: 广泛的评估表明，SELECT不仅高效适应多种擦除框架，还持续优于现有基线，平均每个概念的锚定挖掘仅需4秒。

Conclusion: SELECT作为一种通用的锚定解决方案，不仅能够高效适应多种擦除框架，还在关键性能指标上持续优于现有基线，平均每个概念的锚定挖掘仅需4秒。

Abstract: Existing concept erasure methods for text-to-image diffusion models commonly
rely on fixed anchor strategies, which often lead to critical issues such as
concept re-emergence and erosion. To address this, we conduct causal tracing to
reveal the inherent sensitivity of erasure to anchor selection and define
Sibling Exclusive Concepts as a superior class of anchors. Based on this
insight, we propose \textbf{SELECT} (Sibling-Exclusive Evaluation for
Contextual Targeting), a dynamic anchor selection framework designed to
overcome the limitations of fixed anchors. Our framework introduces a novel
two-stage evaluation mechanism that automatically discovers optimal anchors for
precise erasure while identifying critical boundary anchors to preserve related
concepts. Extensive evaluations demonstrate that SELECT, as a universal anchor
solution, not only efficiently adapts to multiple erasure frameworks but also
consistently outperforms existing baselines across key performance metrics,
averaging only 4 seconds for anchor mining of a single concept.

</details>


### [226] [The Burden of Interactive Alignment with Inconsistent Preferences](https://arxiv.org/abs/2510.16368)
*Ali Shirali*

Main category: cs.AI

TL;DR: 用户通过远见或小信号（如额外点击）可调整算法对齐兴趣，但需面对重大负担。


<details>
  <summary>Details</summary>
Motivation: 研究用户如何在多步交互中通过选择性参与内容来引导算法，以更好地与其真实兴趣对齐，尤其是在用户偏好不一致的情况下。

Method: 通过将用户决策过程建模为理性系统2和冲动系统1的分裂，并研究一个多领导者、单追随者的扩展Stackelberg博弈，其中用户（系统2）通过承诺参与策略来引导算法。

Result: 存在一个关键的时间范围：足够有远见的用户可以实现对齐，而缺乏远见的用户则会被算法的目标所对齐。小而有成本的信号可以显著减少这一关键时间范围。

Conclusion: 用户可以通过足够的远见或小而有成本的信号（如额外点击）来调整算法，使其与自身真实兴趣对齐，尽管这一过程可能面临重大负担。

Abstract: From media platforms to chatbots, algorithms shape how people interact,
learn, and discover information. Such interactions between users and an
algorithm often unfold over multiple steps, during which strategic users can
guide the algorithm to better align with their true interests by selectively
engaging with content. However, users frequently exhibit inconsistent
preferences: they may spend considerable time on content that offers little
long-term value, inadvertently signaling that such content is desirable.
Focusing on the user side, this raises a key question: what does it take for
such users to align the algorithm with their true interests?
  To investigate these dynamics, we model the user's decision process as split
between a rational system 2 that decides whether to engage and an impulsive
system 1 that determines how long engagement lasts. We then study a
multi-leader, single-follower extensive Stackelberg game, where users,
specifically system 2, lead by committing to engagement strategies and the
algorithm best-responds based on observed interactions. We define the burden of
alignment as the minimum horizon over which users must optimize to effectively
steer the algorithm. We show that a critical horizon exists: users who are
sufficiently foresighted can achieve alignment, while those who are not are
instead aligned to the algorithm's objective. This critical horizon can be
long, imposing a substantial burden. However, even a small, costly signal
(e.g., an extra click) can significantly reduce it. Overall, our framework
explains how users with inconsistent preferences can align an engagement-driven
algorithm with their interests in a Stackelberg equilibrium, highlighting both
the challenges and potential remedies for achieving alignment.

</details>


### [227] [Before you <think>, monitor: Implementing Flavell's metacognitive framework in LLMs](https://arxiv.org/abs/2510.16374)
*Nick Oh*

Main category: cs.AI

TL;DR: 本文提出了一种结合监控与验证的三阶段迭代系统，显著提升了LLM在GSM8K上的推理准确率，同时减少了尝试次数。


<details>
  <summary>Details</summary>
Motivation: 当前增强LLM推理的方法存在两种孤立范式：Monitor-Generate方法缺乏验证机制，而Generate-Verify方法则盲目开始生成。这种分离导致效率低下。本文旨在填补这一空白。

Method: 通过实现Flavell的认知监控模型（1979），并将其操作化为一个三阶段迭代系统。

Result: 在GSM8K上，初步结果显示75.42%的准确率，优于SELF-REFINE（68.44%）和Self-Verification（67.07%），且尝试次数更少（1.3 vs 2.0），推理成本增加27-37%。

Conclusion: 初步结果表明，前置监控能生成更高质量的初始解决方案，从而减少细化需求，但需要在算术推理之外进行评估以确定其普适性。

Abstract: Current approaches to enhancing LLM reasoning follows two isolated paradigms:
Monitor-Generate methods like Plan-and-Solve (Wang et al., 2023) and
SELF-DISCOVER (Zhou et al., 2024) excel at strategic planning but lack
mechanisms to verify whether selected strategies succeed; while Generate-Verify
approaches like Self-Verification (Weng et al., 2022) and SELF-REFINE (Madaan
et al., 2023) iteratively refine outputs but commence generation blindly
without task assessment. This separation creates inefficiencies -- strategies
fail without feedback, and refinement occurs without strategic grounding. We
address this gap by implementing Flavell's cognitive monitoring model (1979)
from the broader Monitor-Generate-Verify framework (Oh and Gobet, 2025),
operationalising it as a three-phase iterative system. On GSM8K, preliminary
results show 75.42% accuracy versus 68.44% for SELF-REFINE and 67.07% for
Self-Verification, while requiring fewer attempts (1.3 vs 2.0) at 27-37%
increased inference cost. These initial findings suggest upfront monitoring
produces higher-quality initial solutions that reduce refinement needs, though
evaluation beyond arithmetic reasoning is needed to establish generalisability.

</details>


### [228] [Humanoid-inspired Causal Representation Learning for Domain Generalization](https://arxiv.org/abs/2510.16382)
*Ze Tao,Jian Zhang,Haowei Li,Xianshuai Li,Yifei Peng,Xiyao Liu,Senzhang Wang,Chao Liu,Sheng Ren,Shichao Zhang*

Main category: cs.AI

TL;DR: HSCM是一种受人类智能启发的因果框架，通过解耦图像属性提升跨领域泛化，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统领域泛化模型依赖统计数据捕捉数据-标签依赖关系，存在局限性。HSCM受人类智能启发，旨在克服这些限制。

Method: HSCM通过解耦和重新加权关键图像属性（如颜色、纹理和形状），建模细粒度因果机制。

Result: HSCM在多样领域中表现出更强的泛化能力和鲁棒性，理论和实证评估均优于现有模型。

Conclusion: HSCM通过模仿人类视觉系统的层次处理和多级学习，提出了一种新的因果框架，显著提升了跨领域泛化能力，并在理论和实证上优于现有模型。

Abstract: This paper proposes the Humanoid-inspired Structural Causal Model (HSCM), a
novel causal framework inspired by human intelligence, designed to overcome the
limitations of conventional domain generalization models. Unlike approaches
that rely on statistics to capture data-label dependencies and learn
distortion-invariant representations, HSCM replicates the hierarchical
processing and multi-level learning of human vision systems, focusing on
modeling fine-grained causal mechanisms. By disentangling and reweighting key
image attributes such as color, texture, and shape, HSCM enhances
generalization across diverse domains, ensuring robust performance and
interpretability. Leveraging the flexibility and adaptability of human
intelligence, our approach enables more effective transfer and learning in
dynamic, complex environments. Through both theoretical and empirical
evaluations, we demonstrate that HSCM outperforms existing domain
generalization models, providing a more principled method for capturing causal
relationships and improving model robustness. The code is available at
https://github.com/lambett/HSCM.

</details>


### [229] [RGMem: Renormalization Group-based Memory Evolution for Language Agent User Profile](https://arxiv.org/abs/2510.16392)
*Ao Tian,Yunfeng Lu,Xinxin Fan,Changhao Wang,Lanzhi Zhou,Yeyao Zhang,Yanfang Liu*

Main category: cs.AI

TL;DR: RGMem是一个受物理学启发的自演化记忆框架，通过多尺度信息处理解决LLM会话系统中的长期用户建模问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的会话系统在有限上下文窗口和静态参数记忆的限制下，难以建模跨会话的长期用户状态和行为一致性，现有的解决方案如RAG和显式记忆系统主要关注事实级存储和检索，缺乏从多轮对话中提炼潜在偏好和深层特征的能力。

Method: 提出了一个自演化的记忆框架RGMem，受物理学中的重整化群（RG）思想启发，该框架通过分层粗粒化和重标度操作，从对话历史中提取语义和用户洞察，逐步形成动态演化的用户画像。

Result: RGMem框架能够从对话历史的多个尺度中组织和提取信息，形成动态演化的用户画像，实现了长期记忆和行为一致性。

Conclusion: RGMem框架通过多尺度信息压缩和涌现过程，实现了从噪声和微观交互中构建高层次、准确的用户画像，为LLM时代的语言代理提供了长期记忆和行为一致性的解决方案。

Abstract: Personalized and continuous interactions are the key to enhancing user
experience in today's large language model (LLM)-based conversational systems,
however, the finite context windows and static parametric memory make it
difficult to model the cross-session long-term user states and behavioral
consistency. Currently, the existing solutions to this predicament, such as
retrieval-augmented generation (RAG) and explicit memory systems, primarily
focus on fact-level storage and retrieval, lacking the capability to distill
latent preferences and deep traits from the multi-turn dialogues, which limits
the long-term and effective user modeling, directly leading to the personalized
interactions remaining shallow, and hindering the cross-session continuity. To
realize the long-term memory and behavioral consistency for Language Agents in
LLM era, we propose a self-evolving memory framework RGMem, inspired by the
ideology of classic renormalization group (RG) in physics, this framework
enables to organize the dialogue history in multiple scales: it first extracts
semantics and user insights from episodic fragments, then through hierarchical
coarse-graining and rescaling operations, progressively forms a
dynamically-evolved user profile. The core innovation of our work lies in
modeling memory evolution as a multi-scale process of information compression
and emergence, which accomplishes the high-level and accurate user profiles
from noisy and microscopic-level interactions.

</details>


### [230] [ReviewSense: Transforming Customer Review Dynamics into Actionable Business Insights](https://arxiv.org/abs/2510.16466)
*Siddhartha Krothapalli,Tridib Kumar Das,Praveen Kumar,Naveen Suravarpu,Pratik Narang*

Main category: cs.AI

TL;DR: 论文提出ReviewSense框架，利用LLM将客户评论转化为可操作业务建议，整合聚类和专家评估，初步验证有效。


<details>
  <summary>Details</summary>
Motivation: 传统AI系统擅长预测用户偏好，但缺乏将客户评论转化为可操作的业务建议的能力。

Method: 结合聚类、大型语言模型（LLM）适配和专家驱动评估的统一流程。

Result: 初步手动评估表明，模型推荐与业务目标高度一致，验证了其推动数据驱动决策的潜力。

Conclusion: ReviewSense框架通过整合聚类、LLM适配和专家评估，为业务决策提供了基于客户反馈的深度洞察，展示了AI驱动情感分析在优化商业策略中的价值。

Abstract: As customer feedback becomes increasingly central to strategic growth, the
ability to derive actionable insights from unstructured reviews is essential.
While traditional AI-driven systems excel at predicting user preferences, far
less work has focused on transforming customer reviews into prescriptive,
business-facing recommendations. This paper introduces ReviewSense, a novel
prescriptive decision support framework that leverages advanced large language
models (LLMs) to transform customer reviews into targeted, actionable business
recommendations. By identifying key trends, recurring issues, and specific
concerns within customer sentiments, ReviewSense extends beyond
preference-based systems to provide businesses with deeper insights for
sustaining growth and enhancing customer loyalty. The novelty of this work lies
in integrating clustering, LLM adaptation, and expert-driven evaluation into a
unified, business-facing pipeline. Preliminary manual evaluations indicate
strong alignment between the model's recommendations and business objectives,
highlighting its potential for driving data-informed decision-making. This
framework offers a new perspective on AI-driven sentiment analysis,
demonstrating its value in refining business strategies and maximizing the
impact of customer feedback.

</details>


### [231] [NP-Engine: Empowering Optimization Reasoning in Large Language Models with Verifiable Synthetic NP Problems](https://arxiv.org/abs/2510.16476)
*Xiaozhe Li,Xinyu Fang,Shengyuan Ding,Linyang Li,Haodong Duan,Qingwen Liu,Kai Chen*

Main category: cs.AI

TL;DR: NP-ENGINE框架首次全面训练和评估LLM解决NP-hard问题，推出的QWEN2.5-7B-NP模型在NP-BENCH上超越GPT-4o，并展示了RLVR训练的泛化优势。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在数学、编程等任务上表现出色，但其解决复杂优化问题（如NP-hard问题）的能力尚未充分探索。

Method: 提出了NP-ENGINE框架，包含可控制的实例生成器、基于规则的验证器和启发式求解器，支持分层难度的RLVR训练。同时推出了NP-BENCH基准和QWEN2.5-7B-NP模型。

Result: QWEN2.5-7B-NP在NP-BENCH上显著优于GPT-4o，并展示了RLVR训练对跨领域任务的泛化能力。

Conclusion: RLVR训练在NP-ENGINE-DATA上不仅能提升LLM解决NP-hard问题的能力，还能显著增强其在其他推理任务和非推理任务上的泛化能力，揭示了RLVR扩展的新方向。

Abstract: Large Language Models (LLMs) have shown strong reasoning capabilities, with
models like OpenAI's O-series and DeepSeek R1 excelling at tasks such as
mathematics, coding, logic, and puzzles through Reinforcement Learning with
Verifiable Rewards (RLVR). However, their ability to solve more complex
optimization problems - particularly NP-hard tasks - remains underexplored. To
bridge this gap, we propose NP-ENGINE, the first comprehensive framework for
training and evaluating LLMs on NP-hard problems. NP-ENGINE covers 10 tasks
across five domains, each equipped with (i) a controllable instance generator,
(ii) a rule-based verifier, and (iii) a heuristic solver that provides
approximate optimal solutions as ground truth. This
generator-verifier-heuristic pipeline enables scalable and verifiable RLVR
training under hierarchical difficulties. We also introduce NP-BENCH, a
benchmark derived from NP-ENGINE-DATA, specifically designed to evaluate LLMs'
ability to tackle NP-hard level reasoning problems, focusing not only on
feasibility but also on solution quality. Additionally, we present
QWEN2.5-7B-NP, a model trained via zero-RLVR with curriculum learning on
Qwen2.5-7B-Instruct, which significantly outperforms GPT-4o on NP-BENCH and
achieves SOTA performance with the same model size. Beyond in-domain tasks, we
demonstrate that RLVR training on NP-ENGINE-DATA enables strong out-of-domain
(OOD) generalization to reasoning tasks (logic, puzzles, math, and knowledge),
as well as non-reasoning tasks such as instruction following. We also observe a
scaling trend: increasing task diversity improves OOD generalization. These
findings suggest that task-rich RLVR training is a promising direction for
advancing LLM's reasoning ability, revealing new insights into the scaling laws
of RLVR.

</details>


### [232] [Hey Pentti, We Did It Again!: Differentiable vector-symbolic types that prove polynomial termination](https://arxiv.org/abs/2510.16533)
*Eilene Tomkins-Flanagan,Connor Hanley,Mary A. Kelly*

Main category: cs.AI

TL;DR: Doug是一种基于VSA的计算机语言，能够高效实现技能获取，并通过神经网络学习类型，模拟人类心理表征。


<details>
  <summary>Details</summary>
Motivation: 当前的技能获取方法效率较低，无法模拟人类技能获取的速度。本文旨在通过Doug语言，实现一种更高效的技能获取方式，并模拟人类大脑中的心理表征及其学习过程。

Method: Doug基于槽值编码方案和全息声明性记忆（HDM）编码类型，并使用Lisp VSA的变体编码项。通过神经网络的嵌入空间，Doug能够将类型表示为可学习的点，并实现类型结构和内容的相似性。

Result: Doug语言能够高效地实现技能获取，其速度远超现有方法（如暴力搜索），并能够通过神经网络学习类型，从而更接近人类心理表征的实际存在和学习方式。

Conclusion: 本文提出了一种名为Doug的计算机语言，通过向量符号架构（VSA）编码，使得所有类型化程序都能在多项式时间内停止运行。Doug不仅能够编码轻量线性函数式编程语言（LLFPL），还能通过神经网络的嵌入空间学习类型，从而模拟人类技能获取的过程。

Abstract: We present a typed computer language, Doug, in which all typed programs may
be proved to halt in polynomial time, encoded in a vector-symbolic architecture
(VSA). Doug is just an encoding of the light linear functional programming
language (LLFPL) described by (Schimanski2009, ch. 7). The types of Doug are
encoded using a slot-value encoding scheme based on holographic declarative
memory (HDM; Kelly, 2020). The terms of Doug are encoded using a variant of the
Lisp VSA defined by (Flanagan, 2024). Doug allows for some points on the
embedding space of a neural network to be interpreted as types, where the types
of nearby points are similar both in structure and content. Types in Doug are
therefore learnable by a neural network. Following (Chollet, 2019), (Card,
1983), and (Newell, 1981), we view skill as the application of a procedure, or
program of action, that causes a goal to be satisfied. Skill acquisition may
therefore be expressed as program synthesis. Using Doug, we hope to describe a
form of learning of skilled behaviour that follows a human-like pace of skill
acquisition (i.e., substantially faster than brute force; Heathcote, 2000),
exceeding the efficiency of all currently existing approaches (Kaplan, 2020;
Jones, 2021; Chollet, 2024). Our approach brings us one step closer to modeling
human mental representations, as they must actually exist in the brain, and
those representations' acquisition, as they are actually learned.

</details>


### [233] [Urban-R1: Reinforced MLLMs Mitigate Geospatial Biases for Urban General Intelligence](https://arxiv.org/abs/2510.16555)
*Qiongyan Wang,Xingchen Zou,Yutian Jiang,Haomin Wen,Jiaheng Wei,Qingsong Wen,Yuxuan Liang*

Main category: cs.AI

TL;DR: Urban-R1通过强化学习框架解决城市智能模型的地理偏见问题，提升跨区域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 快速城市化加剧了对城市通用智能(UGI)的需求，但现有监督微调(SFT)模型存在地理偏见，导致预测区域偏差和泛化能力有限。

Method: 提出Urban-R1，一种基于强化学习的后训练框架，采用Group Relative Policy Optimization (GRPO)优化地理群体间的推理，并利用城市区域分析作为代理任务提供可测量的多模态城市数据奖励。

Result: 跨区域和任务的广泛实验表明，Urban-R1有效缓解地理偏见并提升跨区域泛化能力，优于SFT训练和闭源模型。

Conclusion: 强化学习对齐是实现公平可信城市智能的有前景途径。

Abstract: Rapid urbanization intensifies the demand for Urban General Intelligence
(UGI), referring to AI systems that can understand and reason about complex
urban environments. Recent studies have built urban foundation models using
supervised fine-tuning (SFT) of LLMs and MLLMs, yet these models exhibit
persistent geospatial bias, producing regionally skewed predictions and limited
generalization. To this end, we propose Urban-R1, a reinforcement
learning-based post-training framework that aligns MLLMs with the objectives of
UGI. Urban-R1 adopts Group Relative Policy Optimization (GRPO) to optimize
reasoning across geographic groups and employs urban region profiling as a
proxy task to provide measurable rewards from multimodal urban data. Extensive
experiments across diverse regions and tasks show that Urban-R1 effectively
mitigates geo-bias and improves cross-region generalization, outperforming both
SFT-trained and closed-source models. Our results highlight reinforcement
learning alignment as a promising pathway toward equitable and trustworthy
urban intelligence.

</details>


### [234] [BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction](https://arxiv.org/abs/2510.16559)
*Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu*

Main category: cs.AI

TL;DR: BuildArena是首个评估LLMs在物理约束下工程建设能力的交互基准测试，填补了研究空白。


<details>
  <summary>Details</summary>
Motivation: 现代LLMs在工程建设自动化领域的潜力未被充分评估，需要物理约束下的复杂集成推理。

Method: 引入BuildArena，包括可定制的基准框架、可扩展的任务设计策略、3D空间几何计算库和基线LLM代理工作流程。

Result: 在八个前沿LLMs上全面评估了其语言驱动和物理基础的工程建设自动化能力。

Conclusion: BuildArena是首个针对语言驱动工程建设的物理对齐交互基准测试，填补了LLMs在工程建设能力评估上的空白。

Abstract: Engineering construction automation aims to transform natural language
specifications into physically viable structures, requiring complex integrated
reasoning under strict physical constraints. While modern LLMs possess broad
knowledge and strong reasoning capabilities that make them promising candidates
for this domain, their construction competencies remain largely unevaluated. To
address this gap, we introduce BuildArena, the first physics-aligned
interactive benchmark designed for language-driven engineering construction. It
contributes to the community in four aspects: (1) a highly customizable
benchmarking framework for in-depth comparison and analysis of LLMs; (2) an
extendable task design strategy spanning static and dynamic mechanics across
multiple difficulty tiers; (3) a 3D Spatial Geometric Computation Library for
supporting construction based on language instructions; (4) a baseline LLM
agentic workflow that effectively evaluates diverse model capabilities. On
eight frontier LLMs, BuildArena comprehensively evaluates their capabilities
for language-driven and physics-grounded construction automation. The project
page is at https://build-arena.github.io/.

</details>


### [235] [Ripple Effect Protocol: Coordinating Agent Populations](https://arxiv.org/abs/2510.16572)
*Ayush Chopra,Aman Sharma,Feroz Ahmad,Luca Muscariello,Vijoy Pandey,Ramesh Raskar*

Main category: cs.AI

TL;DR: REP协议通过让智能体共享轻量级敏感信号，显著提升了多智能体系统的协调效率和稳定性，优于传统通信协议A2A。


<details>
  <summary>Details</summary>
Motivation: 现代AI智能体通过A2A和ACP等协议交换信息，但这些机制侧重于通信而非协调，导致智能体群体行为脆弱，个体智能但群体结果不佳。

Method: 研究团队提出了Ripple Effect Protocol (REP)，一种协调协议，智能体不仅共享决策，还共享轻量级敏感信号。这些信号通过本地网络传播，帮助群体更快、更稳定地达成一致。研究还形式化了REP的协议规范，并评估了其在不同激励和网络拓扑场景下的表现。

Result: 在三个领域的基准测试中（供应链级联、稀疏网络中的偏好聚合、可持续资源分配），REP比A2A提高了41%至100%的协调准确性和效率，并能灵活处理来自LLM的多模态敏感信号。

Conclusion: REP协议通过引入轻量级敏感信号，显著提升了多智能体系统的协调效率和稳定性，为智能体互联网提供了可扩展的基础设施。

Abstract: Modern AI agents can exchange messages using protocols such as A2A and ACP,
yet these mechanisms emphasize communication over coordination. As agent
populations grow, this limitation produces brittle collective behavior, where
individually smart agents converge on poor group outcomes. We introduce the
Ripple Effect Protocol (REP), a coordination protocol in which agents share not
only their decisions but also lightweight sensitivities - signals expressing
how their choices would change if key environmental variables shifted. These
sensitivities ripple through local networks, enabling groups to align faster
and more stably than with agent-centric communication alone. We formalize REP's
protocol specification, separating required message schemas from optional
aggregation rules, and evaluate it across scenarios with varying incentives and
network topologies. Benchmarks across three domains: (i) supply chain cascades
(Beer Game), (ii) preference aggregation in sparse networks (Movie Scheduling),
and (iii) sustainable resource allocation (Fishbanks) show that REP improves
coordination accuracy and efficiency over A2A by 41 to 100%, while flexibly
handling multimodal sensitivity signals from LLMs. By making coordination a
protocol-level capability, REP provides scalable infrastructure for the
emerging Internet of Agents

</details>


### [236] [Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?](https://arxiv.org/abs/2510.16582)
*Junchi Yu,Yujie Liu,Jindong Gu,Philip Torr,Dongzhan Zhou*

Main category: cs.AI

TL;DR: GraphFlow 是一种基于知识图谱的 RAG 框架，通过流匹配目标优化检索策略，显著提升检索准确性和多样性，并在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于知识图谱的 RAG 方法难以从文本丰富的知识图谱中检索准确且多样化的信息，而过程奖励模型依赖昂贵且难以获取的过程级监督信号。

Method: GraphFlow 采用基于转移的流匹配目标，联合优化检索策略和流估计器，通过奖励分解指导检索过程。

Result: GraphFlow 在 STaRK 基准测试中优于强基线（包括 GPT-4o），平均命中率和召回率提升 10%，并展现出对未见知识图谱的泛化能力。

Conclusion: GraphFlow 在 STaRK 基准测试中表现优异，平均命中率和召回率比基线高出 10%，并展现出对未见知识图谱的强泛化能力。

Abstract: Retrieval-Augmented Generation (RAG) based on knowledge graphs (KGs) enhances
large language models (LLMs) by providing structured and interpretable external
knowledge. However, existing KG-based RAG methods struggle to retrieve accurate
and diverse information from text-rich KGs for complex real-world queries.
Process Reward Models (PRMs) offer a way to align the retrieval process of
KG-based RAG with query-specific knowledge requirements, but they heavily rely
on process-level supervision signals that are expensive and hard to obtain on
KGs. To address this challenge, we propose GraphFlow, a framework that
efficiently retrieves accurate and diverse knowledge required for real-world
queries from text-rich KGs. GraphFlow employs a transition-based flow matching
objective to jointly optimize a retrieval policy and a flow estimator. The flow
estimator factorizes the reward of the retrieval outcome into the intermediate
retrieval states. Such reward factorization guides the retrieval policy to
retrieve candidates from KGs in proportion to their reward. This allows
GraphFlow to explore high-quality regions of KGs that yield diverse and
relevant results. We evaluate GraphFlow on the STaRK benchmark, which includes
real-world queries from multiple domains over text-rich KGs. GraphFlow
outperforms strong KG-RAG baselines, including GPT-4o, by 10% on average in hit
rate and recall. It also shows strong generalization to unseen KGs,
demonstrating its effectiveness and robustness.

</details>


### [237] [Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning](https://arxiv.org/abs/2510.16601)
*Tianxing Wu,Shutong Zhu,Jingting Wang,Ning Xu,Guilin Qi,Haofen Wang*

Main category: cs.AI

TL;DR: ssCDL通过半监督学习改进UKG补全，利用置信分布和元学习增强数据，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对当前不确定知识图谱补全中嵌入学习忽视置信度极端不平衡分布的问题，提出改进方法以提高补全质量。

Method: 提出了一种半监督的置信分布学习（ssCDL）方法，通过将置信度转换为分布以引入更多监督信息，并利用元学习预测伪标签数据来增强训练数据。

Result: 在两个UKG数据集上的实验表明，ssCDL在不同评估指标上均优于现有最佳基线方法。

Conclusion: ssCDL方法通过半监督学习有效提升了不确定知识图谱补全的性能，实验证明其在多个评估指标上优于现有基线方法。

Abstract: Uncertain knowledge graphs (UKGs) associate each triple with a confidence
score to provide more precise knowledge representations. Recently, since
real-world UKGs suffer from the incompleteness, uncertain knowledge graph (UKG)
completion attracts more attention, aiming to complete missing triples and
confidences. Current studies attempt to learn UKG embeddings to solve this
problem, but they neglect the extremely imbalanced distributions of triple
confidences. This causes that the learnt embeddings are insufficient to
high-quality UKG completion. Thus, in this paper, to address the above issue,
we propose a new semi-supervised Confidence Distribution Learning (ssCDL)
method for UKG completion, where each triple confidence is transformed into a
confidence distribution to introduce more supervision information of different
confidences to reinforce the embedding learning process. ssCDL iteratively
learns UKG embedding by relational learning on labeled data (i.e., existing
triples with confidences) and unlabeled data with pseudo labels (i.e., unseen
triples with the generated confidences), which are predicted by meta-learning
to augment the training data and rebalance the distribution of triple
confidences. Experiments on two UKG datasets demonstrate that ssCDL
consistently outperforms state-of-the-art baselines in different evaluation
metrics.

</details>


### [238] [Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards](https://arxiv.org/abs/2510.16614)
*Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi*

Main category: cs.AI

TL;DR: MERCI是一种新型RL算法，通过基于计数的内在奖励增强探索，显著提升LLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习范式依赖于稀疏的结果奖励和有限的探索，导致LLMs在推理过程中出现重复和次优的模式。

Method: MERCI结合了轻量级的Coin Flipping Network（CFN）来估计伪计数和认知不确定性，并将其转化为内在奖励，与任务奖励结合进行策略优化。

Result: 实验表明，MERCI在复杂推理基准测试中显著优于基线方法，促进了更丰富和多样化的思维链。

Conclusion: MERCI通过引入基于计数的内在奖励，显著提升了LLMs在复杂推理任务中的表现，帮助模型摆脱局部最优，发现更好的解决方案。

Abstract: Reinforcement Learning (RL) has become a compelling way to strengthen the
multi step reasoning ability of Large Language Models (LLMs). However,
prevalent RL paradigms still lean on sparse outcome-based rewards and limited
exploration, which often drives LLMs toward repetitive and suboptimal reasoning
patterns. In this paper, we study the central question of how to design
exploration for LLM reasoning and introduce MERCI (Motivating Exploration in
LLM Reasoning with Count-based Intrinsic Rewards), a novel RL algorithm that
augments policy optimization with a principled intrinsic reward. Building on
the idea of count-based exploration, MERCI leverages a lightweight Coin
Flipping Network (CFN) to estimate the pseudo count and further epistemic
uncertainty over reasoning trajectories, and converts them into an intrinsic
reward that values novelty while preserving the learning signal from task
rewards. We integrate MERCI into some advanced RL frameworks like Group
Relative Policy Optimization (GRPO). Experiments on complex reasoning
benchmarks demonstrate that MERCI encourages richer and more varied chains of
thought, significantly improves performance over strong baselines, and helps
the policy escape local routines to discover better solutions. It indicates
that our targeted intrinsic motivation can make exploration reliable for
language model reasoning.

</details>


### [239] [Foundation and Large-Scale AI Models in Neuroscience: A Comprehensive Review](https://arxiv.org/abs/2510.16658)
*Shihao Yang,Xiying Huang,Danilo Bernardo,Jun-En Ding,Andrew Michael,Jingmei Yang,Patrick Kwan,Ashish Raj,Feng Liu*

Main category: cs.AI

TL;DR: 大规模AI模型正在改变神经科学研究，解决了多模态数据整合等挑战，并促进了临床转化，但需注意评估框架和伦理指南。


<details>
  <summary>Details</summary>
Motivation: 探讨大规模AI模型如何通过促进从原始脑信号和神经数据的端到端学习，带来神经科学研究的范式转变。

Method: 通过探索大规模AI模型在五个主要神经科学领域的应用，包括神经影像、脑机接口、分子神经科学、临床辅助及疾病特异性应用，分析了这些模型如何解决计算神经科学的主要挑战。

Result: 研究表明，大规模AI模型能够有效整合多模态神经数据、解释时空模式，并开发临床应用的转化框架，同时生物启发的架构约束提高了模型的可解释性和计算效率。

Conclusion: 本文强调了大规模AI模型在神经科学领域的变革性影响，提供了关键数据集列表，并指出了实施时需注意的严格评估框架、领域知识整合及伦理指南。

Abstract: The advent of large-scale artificial intelligence (AI) models has a
transformative effect on neuroscience research, which represents a paradigm
shift from the traditional computational methods through the facilitation of
end-to-end learning from raw brain signals and neural data. In this paper, we
explore the transformative effects of large-scale AI models on five major
neuroscience domains: neuroimaging and data processing, brain-computer
interfaces and neural decoding, molecular neuroscience and genomic modeling,
clinical assistance and translational frameworks, and disease-specific
applications across neurological and psychiatric disorders. These models are
demonstrated to address major computational neuroscience challenges, including
multimodal neural data integration, spatiotemporal pattern interpretation, and
the derivation of translational frameworks for clinical deployment. Moreover,
the interaction between neuroscience and AI has become increasingly reciprocal,
as biologically informed architectural constraints are now incorporated to
develop more interpretable and computationally efficient models. This review
highlights both the notable promise of such technologies and key implementation
considerations, with particular emphasis on rigorous evaluation frameworks,
effective domain knowledge integration, and comprehensive ethical guidelines
for clinical use. Finally, a systematic listing of critical neuroscience
datasets used to derive and validate large-scale AI models across diverse
research applications is provided.

</details>


### [240] [An Agentic Framework with LLMs for Solving Complex Vehicle Routing Problems](https://arxiv.org/abs/2510.16701)
*Ni Zhang,Zhiguang Cao,Jianan Zhou,Cong Zhang,Yew-Soon Ong*

Main category: cs.AI

TL;DR: AFL框架利用LLMs实现了复杂车辆路径问题的全自动化解决，无需外部干预，性能接近100%的基准测试。


<details>
  <summary>Details</summary>
Motivation: 解决复杂车辆路径问题（VRPs）需要大量专家努力，现有LLMs方法依赖外部干预，导致自主性受限、执行错误和解决方案可行性低。

Method: 提出了一个基于LLMs的代理框架（AFL），直接从原始输入中提取知识，实现自包含的代码生成，无需手工模块或外部求解器。框架将整体流程分解为三个子任务，并采用四个专业代理以确保跨功能一致性和逻辑合理性。

Result: 在60个复杂VRPs上的实验表明，AFL框架在代码可靠性和解决方案可行性上显著优于现有LLM基线，性能接近精心设计的算法。

Conclusion: AFL框架通过LLMs实现了复杂车辆路径问题的全自动化解决，显著提高了代码可靠性和解决方案可行性，性能接近100%的基准测试。

Abstract: Complex vehicle routing problems (VRPs) remain a fundamental challenge,
demanding substantial expert effort for intent interpretation and algorithm
design. While large language models (LLMs) offer a promising path toward
automation, current approaches still rely on external intervention, which
restrict autonomy and often lead to execution errors and low solution
feasibility. To address these challenges, we propose an Agentic Framework with
LLMs (AFL) for solving complex vehicle routing problems, achieving full
automation from problem instance to solution. AFL directly extracts knowledge
from raw inputs and enables self-contained code generation without handcrafted
modules or external solvers. To improve trustworthiness, AFL decomposes the
overall pipeline into three manageable subtasks and employs four specialized
agents whose coordinated interactions enforce cross-functional consistency and
logical soundness. Extensive experiments on 60 complex VRPs, ranging from
standard benchmarks to practical variants, validate the effectiveness and
generality of our framework, showing comparable performance against
meticulously designed algorithms. Notably, it substantially outperforms
existing LLM-based baselines in both code reliability and solution feasibility,
achieving rates close to 100% on the evaluated benchmarks.

</details>


### [241] [Beyond Pipelines: A Survey of the Paradigm Shift toward Model-Native Agentic AI](https://arxiv.org/abs/2510.16720)
*Jitao Sang,Jinlin Xiao,Jiarun Han,Jilin Chen,Xiaoyi Chen,Shuyu Wei,Yongjie Sun,Yuhang Wang*

Main category: cs.AI

TL;DR: 论文综述了代理AI从Pipeline-based系统到Model-native范式的转变，强调了RL在统一LLM、RL和任务中的核心作用，并探讨了能力内化对未来代理AI的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨代理AI的快速发展，特别是从Pipeline-based系统到Model-native范式的转变，以及RL作为这一转变的算法引擎的作用。

Method: 通过系统回顾规划、工具使用和记忆等能力的演变，从外部脚本模块到端到端学习行为，以及考察这一范式转变如何重塑主要代理应用（如Deep Research代理和GUI代理）。

Result: 展示了从外部逻辑到模型内部化的能力演变，以及这一转变如何影响代理应用的开发，如强调长期推理的Deep Research代理和强调实体交互的GUI代理。

Conclusion: 论文概述了AI从外部逻辑系统到模型原生范式的转变，强调了LLM与RL的结合在语言、视觉和实体领域的统一解决方案。未来，代理能力的内化（如多代理协作和反思）将继续发展，标志着从构建应用智能的系统到开发通过经验增长智能的模型的转变。

Abstract: The rapid evolution of agentic AI marks a new phase in artificial
intelligence, where Large Language Models (LLMs) no longer merely respond but
act, reason, and adapt. This survey traces the paradigm shift in building
agentic AI: from Pipeline-based systems, where planning, tool use, and memory
are orchestrated by external logic, to the emerging Model-native paradigm,
where these capabilities are internalized within the model's parameters. We
first position Reinforcement Learning (RL) as the algorithmic engine enabling
this paradigm shift. By reframing learning from imitating static data to
outcome-driven exploration, RL underpins a unified solution of LLM + RL + Task
across language, vision and embodied domains. Building on this, the survey
systematically reviews how each capability -- Planning, Tool use, and Memory --
has evolved from externally scripted modules to end-to-end learned behaviors.
Furthermore, it examines how this paradigm shift has reshaped major agent
applications, specifically the Deep Research agent emphasizing long-horizon
reasoning and the GUI agent emphasizing embodied interaction. We conclude by
discussing the continued internalization of agentic capabilities like
Multi-agent collaboration and Reflection, alongside the evolving roles of the
system and model layers in future agentic AI. Together, these developments
outline a coherent trajectory toward model-native agentic AI as an integrated
learning and interaction framework, marking the transition from constructing
systems that apply intelligence to developing models that grow intelligence
through experience.

</details>


### [242] [A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications](https://arxiv.org/abs/2510.16724)
*Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang*

Main category: cs.AI

TL;DR: 该综述全面概述了基于强化学习的代理搜索，总结了方法、应用和挑战，旨在启发未来研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在开放自然语言交互中改变了信息访问和推理，但仍受限于静态知识、事实幻觉和无法检索实时或特定领域信息。检索增强生成（RAG）通过外部证据缓解这些问题，但传统RAG管道通常是单轮和启发式的，缺乏对检索和推理的自适应控制。

Method: 综述通过三个互补维度组织新兴领域：RL的功能角色、优化策略和优化范围。总结了代表性方法、评估协议和应用。

Result: 综述总结了基于RL的代理搜索方法、评估协议和应用，并讨论了开放挑战和未来方向。

Conclusion: 该综述提供了对基于强化学习的代理搜索的全面概述，并讨论了构建可靠和可扩展系统的开放挑战和未来方向。

Abstract: The advent of large language models (LLMs) has transformed information access
and reasoning through open-ended natural language interaction. However, LLMs
remain limited by static knowledge, factual hallucinations, and the inability
to retrieve real-time or domain-specific information. Retrieval-Augmented
Generation (RAG) mitigates these issues by grounding model outputs in external
evidence, but traditional RAG pipelines are often single turn and heuristic,
lacking adaptive control over retrieval and reasoning. Recent advances in
agentic search address these limitations by enabling LLMs to plan, retrieve,
and reflect through multi-step interaction with search environments. Within
this paradigm, reinforcement learning (RL) offers a powerful mechanism for
adaptive and self-improving search behavior. This survey provides the first
comprehensive overview of \emph{RL-based agentic search}, organizing the
emerging field along three complementary dimensions: (i) What RL is for
(functional roles), (ii) How RL is used (optimization strategies), and (iii)
Where RL is applied (scope of optimization). We summarize representative
methods, evaluation protocols, and applications, and discuss open challenges
and future directions toward building reliable and scalable RL driven agentic
search systems. We hope this survey will inspire future research on the
integration of RL and agentic search. Our repository is available at
https://github.com/ventr1c/Awesome-RL-based-Agentic-Search-Papers.

</details>


### [243] [Surrogate Modeling and Explainable Artificial Intelligence for Complex Systems: A Workflow for Automated Simulation Exploration](https://arxiv.org/abs/2510.16742)
*Paul Saves,Pramudita Satria Palar,Muhammad Daffa Robani,Nicolas Verstaevel,Moncef Garouani,Julien Aligon,Benoit Gaudou,Koji Shimoyama,Joseph Morlier*

Main category: cs.AI

TL;DR: 提出一种结合轻量级模拟器和XAI的工作流，显著提升复杂系统仿真的效率和透明度，适用于工程设计和政策分析。


<details>
  <summary>Details</summary>
Motivation: 解决复杂系统仿真中的高计算成本和黑箱组件带来的透明度与可靠性问题。

Method: 提出了一种基于替代模型的工作流，结合紧凑的实验设计训练轻量级模拟器，支持全局和局部的XAI分析，并评估解释的一致性。

Result: 在两个案例研究中，该方法实现了秒级的大规模探索，揭示了非线性交互和涌现行为，并识别了关键设计和政策杠杆。

Conclusion: 该工作流通过训练轻量级模拟器和结合可解释人工智能（XAI）分析，显著提高了复杂系统仿真的效率和透明度，为工程设计和政策制定提供了可靠的工具。

Abstract: Complex systems are increasingly explored through simulation-driven
engineering workflows that combine physics-based and empirical models with
optimization and analytics. Despite their power, these workflows face two
central obstacles: (1) high computational cost, since accurate exploration
requires many expensive simulator runs; and (2) limited transparency and
reliability when decisions rely on opaque blackbox components. We propose a
workflow that addresses both challenges by training lightweight emulators on
compact designs of experiments that (i) provide fast, low-latency
approximations of expensive simulators, (ii) enable rigorous uncertainty
quantification, and (iii) are adapted for global and local Explainable
Artificial Intelligence (XAI) analyses. This workflow unifies every
simulation-based complex-system analysis tool, ranging from engineering design
to agent-based models for socio-environmental understanding. In this paper, we
proposea comparative methodology and practical recommendations for using
surrogate-based explainability tools within the proposed workflow. The
methodology supports continuous and categorical inputs, combines global-effect
and uncertainty analyses with local attribution, and evaluates the consistency
of explanations across surrogate models, thereby diagnosing surrogate adequacy
and guiding further data collection or model refinement. We demonstrate the
approach on two contrasting case studies: a multidisciplinary design analysis
of a hybrid-electric aircraft and an agent-based model of urban segregation.
Results show that the surrogate model and XAI coupling enables large-scale
exploration in seconds, uncovers nonlinear interactions and emergent behaviors,
identifies key design and policy levers, and signals regions where surrogates
require more data or alternative architectures.

</details>


### [244] [ELMM: Efficient Lightweight Multimodal Large Language Models for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2510.16753)
*Wei Huang,Peining Li,Meiyu Liang,Xu Hou,Junping Du,Yingxia Shao,Guanhua Ye,Wu Liu,Kangkang Lu,Yang Yu*

Main category: cs.AI

TL;DR: ELMM 是一种高效轻量化的多模态大型语言模型，通过压缩图像令牌和剪枝策略，显著提升了多模态知识图谱补全的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 多模态知识图谱（MKGs）的不完整性限制了其在下游任务中的效果，而现有方法在处理多模态数据时面临语义噪声和高计算成本的挑战。

Method: ELMM 引入了基于多头注意力机制的多视图视觉令牌压缩器（MVTC），并设计了注意力剪枝策略以减少冗余计算。

Result: 在 FB15k-237-IMG 和 WN18-IMG 基准测试中，ELMM 实现了最先进的性能，同时显著提高了计算效率。

Conclusion: ELMM 提出了一种高效轻量化的多模态大型语言模型，通过多视图视觉令牌压缩器和注意力剪枝策略，显著提升了多模态知识图谱补全的性能和计算效率。

Abstract: Multimodal Knowledge Graphs (MKGs) extend traditional knowledge graphs by
incorporating visual and textual modalities, enabling richer and more
expressive entity representations. However, existing MKGs often suffer from
incompleteness, which hinder their effectiveness in downstream tasks.
Therefore, multimodal knowledge graph completion (MKGC) task is receiving
increasing attention. While large language models (LLMs) have shown promise for
knowledge graph completion (KGC), their application to the multimodal setting
remains underexplored. Moreover, applying Multimodal Large Language Models
(MLLMs) to the task of MKGC introduces significant challenges: (1) the large
number of image tokens per entity leads to semantic noise and modality
conflicts, and (2) the high computational cost of processing large token
inputs. To address these issues, we propose Efficient Lightweight Multimodal
Large Language Models (ELMM) for MKGC. ELMM proposes a Multi-view Visual Token
Compressor (MVTC) based on multi-head attention mechanism, which adaptively
compresses image tokens from both textual and visual views, thereby effectively
reducing redundancy while retaining necessary information and avoiding modality
conflicts. Additionally, we design an attention pruning strategy to remove
redundant attention layers from MLLMs, thereby significantly reducing the
inference cost. We further introduce a linear projection to compensate for the
performance degradation caused by pruning. Extensive experiments on benchmark
FB15k-237-IMG and WN18-IMG demonstrate that ELMM achieves state-of-the-art
performance while substantially improving computational efficiency,
establishing a new paradigm for multimodal knowledge graph completion.

</details>


### [245] [End-to-end Listen, Look, Speak and Act](https://arxiv.org/abs/2510.16756)
*Siyin Wang,Wenyi Yu,Xianzhao Chen,Xiaohai Tian,Jun Zhang,Lu Lu,Chao Zhang*

Main category: cs.AI

TL;DR: ELLSA是首个全双工端到端模型，通过SA-MoE架构实现多模态感知与生成，支持更自然的交互行为。


<details>
  <summary>Details</summary>
Motivation: 人类交互本质上是多模态和全双工的，模拟这些能力对于构建人类模型至关重要。

Method: 采用SA-MoE架构（自注意力混合专家），将每种模态路由到专门专家并通过统一注意力骨干融合。

Result: 在语音交互和机器人操作基准测试中，ELLSA与特定模态基线相匹配，同时支持高级多模态和全双工行为。

Conclusion: ELLSA标志着向更自然和通用交互智能迈出的一步，为人工通用智能的广泛追求做出了贡献。

Abstract: Human interaction is inherently multimodal and full-duplex: we listen while
watching, speak while acting, and fluidly adapt to turn-taking and
interruptions. Realizing these capabilities is essential for building models
simulating humans. We present ELLSA (End-to-end Listen, Look, Speak and Act),
which, to our knowledge, is the first full-duplex, end-to-end model that
simultaneously perceives and generates across vision, text, speech, and action
within a single architecture, enabling interaction patterns previously out of
reach, yielding more natural, human-like behaviors. At its core is a novel
SA-MoE architecture (Self-Attention Mixture-of-Experts) that routes each
modality to specialized experts and fuses them through a unified attention
backbone. This provides a generalizable solution for joint multimodal
perception and concurrent generation, leveraging strong pre-trained components
while enabling efficient modality integration and mitigating modality
interference. On speech-interaction and robot-manipulation benchmarks, ELLSA
matches modality-specific baselines, while uniquely supporting advanced
multimodal and full-duplex behaviors such as dialogue and action turn-taking,
defective instruction rejection, speaking-while-acting, context-grounded visual
question answering, and action barge-ins. We contend that ELLSA represents a
step toward more natural and general interactive intelligence, contributing to
the broader pursuit of artificial general intelligence. All data, code and
model checkpoints will be released upon acceptance.

</details>


### [246] [See or Say Graphs: Agent-Driven Scalable Graph Understanding with Vision-Language Models](https://arxiv.org/abs/2510.16769)
*Shuo Han,Yukun Cao,Zezhong Ding,Zengyi Gao,S Kevin Zhou,Xike Xie*

Main category: cs.AI

TL;DR: GraphVista通过分层信息组织和模态规划代理，提升图理解的可扩展性和性能，实验显示其在大规模图上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在图理解中因输入令牌限制导致的可扩展性瓶颈和模态协调不足的问题。

Method: GraphVista采用轻量级GraphRAG基础结构，按需检索任务相关的文本描述和高分辨率视觉子图，并通过规划代理动态路由任务至最适合的模态。

Result: GraphVista可扩展到比现有基准大200倍的图，并在质量上比最先进的基线提升4.4倍。

Conclusion: GraphVista通过分层组织图信息和引入规划代理，显著提升了图理解的可扩展性和模态协调性，实验证明其在大型图上的表现优于现有方法。

Abstract: Vision-language models (VLMs) have shown promise in graph understanding, but
remain limited by input-token constraints, facing scalability bottlenecks and
lacking effective mechanisms to coordinate textual and visual modalities. To
address these challenges, we propose GraphVista, a unified framework that
enhances both scalability and modality coordination in graph understanding. For
scalability, GraphVista organizes graph information hierarchically into a
lightweight GraphRAG base, which retrieves only task-relevant textual
descriptions and high-resolution visual subgraphs, compressing redundant
context while preserving key reasoning elements. For modality coordination,
GraphVista introduces a planning agent that routes tasks to the most suitable
modality-using the text modality for simple property reasoning and the visual
modality for local and structurally complex reasoning grounded in explicit
topology. Extensive experiments demonstrate that GraphVista scales to large
graphs, up to $200\times$ larger than those used in existing benchmarks, and
consistently outperforms existing textual, visual, and fusion-based methods,
achieving up to $4.4\times$ quality improvement over the state-of-the-art
baselines by fully exploiting the complementary strengths of both modalities.

</details>


### [247] [Domain-Contextualized Concept Graphs: A Computable Framework for Knowledge Representation](https://arxiv.org/abs/2510.16802)
*Chao Li,Yuru Wang*

Main category: cs.AI

TL;DR: CDC是一种新型知识建模框架，通过动态领域分类和C-D-C三元组结构，解决了传统知识图谱的局限性，实现了上下文感知推理和跨领域类比。


<details>
  <summary>Details</summary>
Motivation: 传统知识图谱受限于固定本体，无法动态处理领域上下文。CDC旨在通过显式建模领域，提升知识表示的灵活性和推理能力。

Method: CDC采用C-D-C三元组结构（<概念, 关系@领域, 概念'>），并基于认知-语言同构映射原则，定义了20多种标准化关系谓词，并在Prolog中实现。

Result: 案例研究表明，CDC在教育、企业知识系统和技术文档等领域中实现了传统框架无法达到的能力。

Conclusion: CDC框架通过将领域提升为概念表示的一流元素，克服了传统知识图谱的局限性，实现了上下文感知推理、跨领域类比和个性化知识建模。

Abstract: Traditional knowledge graphs are constrained by fixed ontologies that
organize concepts within rigid hierarchical structures. The root cause lies in
treating domains as implicit context rather than as explicit, reasoning-level
components. To overcome these limitations, we propose the Domain-Contextualized
Concept Graph (CDC), a novel knowledge modeling framework that elevates domains
to first-class elements of conceptual representation. CDC adopts a C-D-C triple
structure - <Concept, Relation@Domain, Concept'> - where domain specifications
serve as dynamic classification dimensions defined on demand. Grounded in a
cognitive-linguistic isomorphic mapping principle, CDC operationalizes how
humans understand concepts through contextual frames. We formalize more than
twenty standardized relation predicates (structural, logical, cross-domain, and
temporal) and implement CDC in Prolog for full inference capability. Case
studies in education, enterprise knowledge systems, and technical documentation
demonstrate that CDC enables context-aware reasoning, cross-domain analogy, and
personalized knowledge modeling - capabilities unattainable under traditional
ontology-based frameworks.

</details>


### [248] [DeepAnalyze: Agentic Large Language Models for Autonomous Data Science](https://arxiv.org/abs/2510.16872)
*Shaolei Zhang,Ju Fan,Meihao Fan,Guoliang Li,Xiaoyong Du*

Main category: cs.AI

TL;DR: DeepAnalyze-8B是首个用于自主数据科学的代理LLM，通过课程学习和轨迹合成框架实现端到端管道，性能优于现有工作流代理。


<details>
  <summary>Details</summary>
Motivation: 实现完全自主的数据科学，克服现有基于预定义工作流的数据代理的局限性。

Method: 提出了基于课程学习的代理训练范式和数据驱动的轨迹合成框架，模拟人类数据科学家的学习路径。

Result: 实验表明，仅8B参数的DeepAnalyze在多种数据任务中表现优于基于最先进专有LLM的工作流代理。

Conclusion: DeepAnalyze-8B的开源模型、代码和训练数据为自主数据科学铺平了道路，展示了其在复杂数据任务中的优越性能。

Abstract: Autonomous data science, from raw data sources to analyst-grade deep research
reports, has been a long-standing challenge, and is now becoming feasible with
the emergence of powerful large language models (LLMs). Recent workflow-based
data agents have shown promising results on specific data tasks but remain
fundamentally limited in achieving fully autonomous data science due to their
reliance on predefined workflows. In this paper, we introduce DeepAnalyze-8B,
the first agentic LLM designed for autonomous data science, capable of
automatically completing the end-toend pipeline from data sources to
analyst-grade deep research reports. To tackle high-complexity data science
tasks, we propose a curriculum-based agentic training paradigm that emulates
the learning trajectory of human data scientists, enabling LLMs to
progressively acquire and integrate multiple capabilities in real-world
environments. We also introduce a data-grounded trajectory synthesis framework
that constructs high-quality training data. Through agentic training,
DeepAnalyze learns to perform a broad spectrum of data tasks, ranging from data
question answering and specialized analytical tasks to open-ended data
research. Experiments demonstrate that, with only 8B parameters, DeepAnalyze
outperforms previous workflow-based agents built on most advanced proprietary
LLMs. The model, code, and training data of DeepAnalyze are open-sourced,
paving the way toward autonomous data science.

</details>


### [249] [VAGEN: Reinforcing World Model Reasoning for Multi-Turn VLM Agents](https://arxiv.org/abs/2510.16907)
*Kangrui Wang,Pingyue Zhang,Zihan Wang,Yaning Gao,Linjie Li,Qineng Wang,Hanyang Chen,Chi Wan,Yiping Lu,Zhengyuan Yang,Lijuan Wang,Ranjay Krishna,Jiajun Wu,Li Fei-Fei,Yejin Choi,Manling Li*

Main category: cs.AI

TL;DR: 研究通过强化学习和世界建模奖励，使3B参数的VLM代理在视觉环境中显著优于未训练模型和专有推理模型。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型（VLM）代理是否能够通过显式视觉状态推理构建内部世界模型，以解决从文本状态到复杂视觉观察的转换带来的部分可观察性和世界建模挑战。

Method: 研究采用部分可观察马尔可夫决策过程（POMDP）框架，通过分解代理的推理过程为状态估计和转移建模，并设计了世界建模奖励和双层次广义优势估计（Bi-Level GAE）进行密集监督和信用分配。

Result: 3B参数的VLM模型在五个代理基准测试中取得了0.82的分数，比未训练的模型（0.21）提高了3倍，并超越了专有推理模型（如GPT-5、Gemini 2.5 Pro和Claude 4.5）。

Conclusion: 通过强化学习（RL）架构和世界建模奖励，3B参数的视觉语言模型（VLM）在五个多样化的代理基准测试中取得了0.82的分数，显著优于未训练的模型（0.21）和专有推理模型（如GPT-5、Gemini 2.5 Pro和Claude 4.5）。

Abstract: A key challenge in training Vision-Language Model (VLM) agents, compared to
Language Model (LLM) agents, lies in the shift from textual states to complex
visual observations. This transition introduces partial observability and
demands robust world modeling. We ask: Can VLM agents construct internal world
models through explicit visual state reasoning? To address this question, we
architecturally enforce and reward the agent's reasoning process via
reinforcement learning (RL), formulating it as a Partially Observable Markov
Decision Process (POMDP). We find that decomposing the agent's reasoning into
State Estimation ("what is the current state?") and Transition Modeling ("what
comes next?") is critical for success, as demonstrated through five reasoning
strategies. Our investigation into how agents represent internal beliefs
reveals that the optimal representation is task-dependent: Natural Language
excels at capturing semantic relationships in general tasks, while Structured
formats are indispensable for precise manipulation and control. Building on
these insights, we design a World Modeling Reward that provides dense,
turn-level supervision for accurate state prediction, and introduce Bi-Level
General Advantage Estimation (Bi-Level GAE) for turn-aware credit assignment.
Through this form of visual state reasoning, a 3B-parameter model achieves a
score of 0.82 across five diverse agent benchmarks, representing a 3$\times$
improvement over its untrained counterpart (0.21) and outperforming proprietary
reasoning models such as GPT-5 (0.75), Gemini 2.5 Pro (0.67) and Claude 4.5
(0.62). All experiments are conducted within our VAGEN framework, a scalable
system for training and analyzing multi-turn VLM agents in diverse visual
environments. Code and data are publicly available at
https://vagen-ai.github.io.

</details>


### [250] [A Comparative User Evaluation of XRL Explanations using Goal Identification](https://arxiv.org/abs/2510.16956)
*Mark Towers,Yali Du,Christopher Freeman,Timothy J. Norman*

Main category: cs.AI

TL;DR: 本文评估了四种XRL算法在调试任务中的表现，发现其效果有限且用户自信度与实际准确率不相关。


<details>
  <summary>Details</summary>
Motivation: 当前对可解释强化学习（XRL）算法的比较评估有限，尤其是在调试这一核心应用上的表现。本文旨在填补这一空白。

Method: 研究提出了一种新颖的评估方法，通过Atari的Ms. Pacman环境和四种XRL算法，测试用户是否能从决策解释中识别智能体的目标。

Result: 实验发现，四种XRL算法中仅有一种在测试目标上的准确率高于随机水平，且用户普遍高估了自己的判断能力。

Conclusion: 研究发现，现有的XRL算法在帮助用户识别智能体目标方面的表现普遍不佳，且用户的自信程度与实际准确率不匹配。此外，用户自我报告的易理解性与实际准确率无关。

Abstract: Debugging is a core application of explainable reinforcement learning (XRL)
algorithms; however, limited comparative evaluations have been conducted to
understand their relative performance. We propose a novel evaluation
methodology to test whether users can identify an agent's goal from an
explanation of its decision-making. Utilising the Atari's Ms. Pacman
environment and four XRL algorithms, we find that only one achieved greater
than random accuracy for the tested goals and that users were generally
overconfident in their selections. Further, we find that users' self-reported
ease of identification and understanding for every explanation did not
correlate with their accuracy.

</details>


### [251] [STARK: Strategic Team of Agents for Refining Kernels](https://arxiv.org/abs/2510.16996)
*Juncheng Dong,Yang Yang,Tao Liu,Yang Wang,Feng Qi,Vahid Tarokh,Kaushik Rangadurai,Shuang Yang*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的多智能体框架，用于自动化GPU内核优化，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 由于GPU内核优化涉及复杂的内存层次结构、线程调度和硬件特定特性，传统方法效率低下，而现有LLM方法多为单次生成或简单优化，无法有效应对这一挑战。

Method: 研究引入了一个LLM智能体框架，通过多智能体协作、基础指令、动态上下文管理和策略搜索来系统探索设计空间。

Result: 在KernelBench基准测试中，该系统不仅提高了正确性，还实现了高达16倍的运行时性能提升。

Conclusion: 该论文展示了基于LLM的多智能体协作框架在GPU内核优化中的潜力，能够显著提升性能并实现自动化优化。

Abstract: The efficiency of GPU kernels is central to the progress of modern AI, yet
optimizing them remains a difficult and labor-intensive task due to complex
interactions between memory hierarchies, thread scheduling, and
hardware-specific characteristics. While recent advances in large language
models (LLMs) provide new opportunities for automated code generation, existing
approaches largely treat LLMs as single-shot generators or naive refinement
tools, limiting their effectiveness in navigating the irregular kernel
optimization landscape. We introduce an LLM agentic framework for GPU kernel
optimization that systematically explores the design space through multi-agent
collaboration, grounded instruction, dynamic context management, and strategic
search. This framework mimics the workflow of expert engineers, enabling LLMs
to reason about hardware trade-offs, incorporate profiling feedback, and refine
kernels iteratively. We evaluate our approach on KernelBench, a benchmark for
LLM-based kernel optimization, and demonstrate substantial improvements over
baseline agents: our system produces correct solutions where baselines often
fail, and achieves kernels with up to 16x faster runtime performance. These
results highlight the potential of agentic LLM frameworks to advance fully
automated, scalable GPU kernel optimization.

</details>


### [252] [ToolCritic: Detecting and Correcting Tool-Use Errors in Dialogue Systems](https://arxiv.org/abs/2510.17052)
*Hassan Hamad,Yingru Xu,Liang Zhao,Wenbo Yan,Narendra Gyanchandani*

Main category: cs.AI

TL;DR: ToolCritic是一个诊断框架，通过检测和反馈工具调用错误，显著提升LLM在多轮工具增强对话中的准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管工具增强的大型语言模型（LLM）在现实应用中广泛使用，但工具使用错误仍影响其可靠性，需一种诊断框架来评估和改进LLM行为。

Method: 通过定义八种特定错误类型并构建合成数据集来训练ToolCritic，利用其对主LLM提供针对性反馈，主LLM基于反馈修正响应。

Result: 在Schema-Guided Dialogue（SGD）数据集上的实验表明，ToolCritic将工具调用准确性最高提升13%，优于零样本提示和自校正技术。

Conclusion: ToolCritic框架显著提升了LLM在多轮工具增强对话中的工具调用准确性，为实际应用中LLM与外部工具的稳健集成提供了有前景的解决方案。

Abstract: Tool-augmented large language models (LLMs) are increasingly employed in
real-world applications, but tool usage errors still hinder their reliability.
We introduce ToolCritic, a diagnostic framework that evaluates and improves LLM
behavior in multi-turn, tool-augmented dialogues. ToolCritic detects eight
distinct error types specific to tool-calling (e.g., premature invocation,
argument misalignment, and misinterpretation of tool outputs) and provides
targeted feedback to the main LLM. The main LLM, assumed to have strong
reasoning, task understanding and orchestration capabilities, then revises its
response based on ToolCritic's feedback. We systematically define these error
categories and construct a synthetic dataset to train ToolCritic. Experimental
results on the Schema-Guided Dialogue (SGD) dataset demonstrate that ToolCritic
improves tool-calling accuracy by up to 13% over baselines, including zero-shot
prompting and self-correction techniques. This represents a promising step
toward more robust LLM integration with external tools in real-world dialogue
applications.

</details>


### [253] [Graph Attention-Guided Search for Dense Multi-Agent Pathfinding](https://arxiv.org/abs/2510.17382)
*Rishabh Jain,Keisuke Okumura,Michael Amir,Amanda Prorok*

Main category: cs.AI

TL;DR: TL;DR: LaGAT是一个混合框架，结合了学习启发式和基于搜索的算法，在密集多智能体路径规划中优于纯搜索和纯学习方法。


<details>
  <summary>Details</summary>
Motivation: 论文动机是解决密集多智能体路径规划（MAPF）问题中实时寻找近优解的挑战，即使对于最先进的规划者也是如此。

Method: 论文方法包括开发一个混合框架，将来自MAGAT的学习启发式（一种具有图注意力方案的神经MAPF策略）集成到领先的基于搜索的算法LaCAM中。此外，还包括增强的MAGAT架构、在感兴趣的地图上进行预训练后微调的策略，以及用于处理不完美神经指导的死锁检测方案。

Result: 论文结果表明，该方法（称为LaGAT）在密集场景中优于纯基于搜索和纯基于学习的方法。

Conclusion: 论文结论表明，当精心设计时，混合搜索为紧密耦合、具有挑战性的多智能体协调问题提供了强大的解决方案。

Abstract: Finding near-optimal solutions for dense multi-agent pathfinding (MAPF)
problems in real-time remains challenging even for state-of-the-art planners.
To this end, we develop a hybrid framework that integrates a learned heuristic
derived from MAGAT, a neural MAPF policy with a graph attention scheme, into a
leading search-based algorithm, LaCAM. While prior work has explored
learning-guided search in MAPF, such methods have historically underperformed.
In contrast, our approach, termed LaGAT, outperforms both purely search-based
and purely learning-based methods in dense scenarios. This is achieved through
an enhanced MAGAT architecture, a pre-train-then-fine-tune strategy on maps of
interest, and a deadlock detection scheme to account for imperfect neural
guidance. Our results demonstrate that, when carefully designed, hybrid search
offers a powerful solution for tightly coupled, challenging multi-agent
coordination problems.

</details>


### [254] [A Brain Cell Type Resource Created by Large Language Models and a Multi-Agent AI System for Collaborative Community Annotation](https://arxiv.org/abs/2510.17064)
*Rongbin Li,Wenbo Chen,Zhao Li,Rodrigo Munoz-Castaneda,Jinbo Li,Neha S. Maurya,Arnav Solanki,Huan He,Hanwen Xing,Meaghan Ramlakhan,Zachary Wise,Zhuhao Wu,Hua Xu,Michael Hawrylycz,W. Jim Zheng*

Main category: cs.AI

TL;DR: BRAINCELL-AID通过多代理AI系统整合文本与本体标签，显著提升单细胞RNA测序数据的基因集注释准确性，支持脑细胞功能研究。


<details>
  <summary>Details</summary>
Motivation: 传统方法如GSEA依赖精心策划的注释，在涉及未充分表征的基因时表现不佳，LLMs难以在结构化本体中表示复杂生物知识。

Method: 整合自由文本描述与本体标签，采用检索增强生成（RAG）的多代理AI系统，通过PubMed文献优化预测。

Result: 在小鼠基因集中实现了77%的准确注释，并应用于5,322个脑细胞簇的注释，揭示了区域特异性基因共表达模式。

Conclusion: BRAINCELL-AID为单细胞RNA测序数据的基因集注释提供了更准确和可靠的方法，支持社区驱动的细胞类型注释，并提供了有价值的资源。

Abstract: Single-cell RNA sequencing has transformed our ability to identify diverse
cell types and their transcriptomic signatures. However, annotating these
signatures-especially those involving poorly characterized genes-remains a
major challenge. Traditional methods, such as Gene Set Enrichment Analysis
(GSEA), depend on well-curated annotations and often perform poorly in these
contexts. Large Language Models (LLMs) offer a promising alternative but
struggle to represent complex biological knowledge within structured
ontologies. To address this, we present BRAINCELL-AID (BRAINCELL-AID:
https://biodataai.uth.edu/BRAINCELL-AID), a novel multi-agent AI system that
integrates free-text descriptions with ontology labels to enable more accurate
and robust gene set annotation. By incorporating retrieval-augmented generation
(RAG), we developed a robust agentic workflow that refines predictions using
relevant PubMed literature, reducing hallucinations and enhancing
interpretability. Using this workflow, we achieved correct annotations for 77%
of mouse gene sets among their top predictions. Applying this approach, we
annotated 5,322 brain cell clusters from the comprehensive mouse brain cell
atlas generated by the BRAIN Initiative Cell Census Network, enabling novel
insights into brain cell function by identifying region-specific gene
co-expression patterns and inferring functional roles of gene ensembles.
BRAINCELL-AID also identifies Basal Ganglia-related cell types with
neurologically meaningful descriptions. Hence, we create a valuable resource to
support community-driven cell type annotation.

</details>


### [255] [Structured Debate Improves Corporate Credit Reasoning in Financial AI](https://arxiv.org/abs/2510.17108)
*Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park*

Main category: cs.AI

TL;DR: 研究通过NAS和KPD-MADS两种LLM系统，解决了企业信用评估中非财务定性指标的自动化推理问题，KPD-MADS在多方面表现更优。


<details>
  <summary>Details</summary>
Motivation: 虽然金融AI有所进步，但企业信用评估中基于证据的推理自动化仍未解决，尤其是非财务定性指标的规范化问题。

Method: 研究开发并评估了两种基于大型语言模型（LLM）的系统：非对抗性单智能体系统（NAS）和基于辩论的多智能体系统（KPD-MADS）。

Result: 两种系统均显著提升了生产率（NAS: 11.55秒/案例；KPD-MADS: 91.97秒；人工基准: 1920秒）。KPD-MADS在推理质量上表现更优，解释充分性、实用适用性和可用性评分更高。

Conclusion: 结构化多智能体交互（如KPD-MADS）能显著提升金融AI中的推理严谨性和可解释性，推动企业信用评估的可扩展和可辩护自动化。

Abstract: Despite advances in financial AI, the automation of evidence-based reasoning
remains unresolved in corporate credit assessment, where qualitative
non-financial indicators exert decisive influence on loan repayment outcomes
yet resist formalization. Existing approaches focus predominantly on numerical
prediction and provide limited support for the interpretive judgments required
in professional loan evaluation. This study develops and evaluates two
operational large language model (LLM)-based systems designed to generate
structured reasoning from non-financial evidence. The first is a
non-adversarial single-agent system (NAS) that produces bidirectional analysis
through a single-pass reasoning pipeline. The second is a debate-based
multi-agent system (KPD-MADS) that operationalizes adversarial verification
through a ten-step structured interaction protocol grounded in Karl Popper's
critical dialogue framework. Both systems were applied to three real corporate
cases and evaluated by experienced credit risk professionals. Compared to
manual expert reporting, both systems achieved substantial productivity gains
(NAS: 11.55 s per case; KPD-MADS: 91.97 s; human baseline: 1920 s). The
KPD-MADS demonstrated superior reasoning quality, receiving higher median
ratings in explanatory adequacy (4.0 vs. 3.0), practical applicability (4.0 vs.
3.0), and usability (62.5 vs. 52.5). These findings show that structured
multi-agent interaction can enhance reasoning rigor and interpretability in
financial AI, advancing scalable and defensible automation in corporate credit
assessment.

</details>


### [256] [Enhanced Fish Freshness Classification with Incremental Handcrafted Feature Fusion](https://arxiv.org/abs/2510.17145)
*Phi-Hung Hoang,Nam-Thuan Trinh,Van-Manh Tran,Thi-Thu-Hong Phan*

Main category: cs.AI

TL;DR: 提出一种基于手工特征的方法，通过融合多特征评估鱼类新鲜度，显著提升准确率，为食品质量监控提供可靠解决方案。


<details>
  <summary>Details</summary>
Motivation: 鱼类新鲜度评估是食品行业的主要挑战，直接影响产品质量、市场价值和消费者健康。传统的感官评估主观性强、不一致且难以标准化。

Method: 提出了一种基于手工特征的方法，系统提取并逐步融合互补描述符，包括颜色统计、多色彩空间直方图以及纹理特征（如局部二值模式LBP和灰度共生矩阵GLCM），从鱼眼图像中捕获全局色度变化和局部降解。

Result: 在标准训练-测试设置中，LightGBM分类器达到77.56%准确率，比之前深度学习的基线63.21%提高了14.35%。使用增强数据后，人工神经网络（ANN）达到97.16%准确率，比之前最佳77.3%提高了19.86%。

Conclusion: 精心设计的手工特征在战略性处理后，为自动化鱼类新鲜度评估提供了鲁棒、可解释且可靠的解决方案，为食品质量监控的实际应用提供了宝贵见解。

Abstract: Accurate assessment of fish freshness remains a major challenge in the food
industry, with direct consequences for product quality, market value, and
consumer health. Conventional sensory evaluation is inherently subjective,
inconsistent, and difficult to standardize across contexts, often limited by
subtle, species-dependent spoilage cues. To address these limitations, we
propose a handcrafted feature-based approach that systematically extracts and
incrementally fuses complementary descriptors, including color statistics,
histograms across multiple color spaces, and texture features such as Local
Binary Patterns (LBP) and Gray-Level Co-occurrence Matrices (GLCM), from fish
eye images. Our method captures global chromatic variations from full images
and localized degradations from ROI segments, fusing each independently to
evaluate their effectiveness in assessing freshness. Experiments on the
Freshness of the Fish Eyes (FFE) dataset demonstrate the approach's
effectiveness: in a standard train-test setting, a LightGBM classifier achieved
77.56% accuracy, a 14.35% improvement over the previous deep learning baseline
of 63.21%. With augmented data, an Artificial Neural Network (ANN) reached
97.16% accuracy, surpassing the prior best of 77.3% by 19.86%. These results
demonstrate that carefully engineered, handcrafted features, when strategically
processed, yield a robust, interpretable, and reliable solution for automated
fish freshness assessment, providing valuable insights for practical
applications in food quality monitoring.

</details>


### [257] [Physics-Informed Large Language Models for HVAC Anomaly Detection with Autonomous Rule Generation](https://arxiv.org/abs/2510.17146)
*Subin Lin,Chuanbo Hua*

Main category: cs.AI

TL;DR: PILLM结合物理原理与LLM，通过进化循环优化HVAC异常检测规则，实现高性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: HVAC系统能耗高，现有方法在可解释性、适应性和物理合理性方面存在不足，需结合物理原理提升异常检测效果。

Method: 提出PILLM框架，利用进化循环自动生成、评估和优化异常检测规则，引入物理信息反射和交叉算子嵌入热力学和控制理论约束。

Result: 在公共建筑故障检测数据集上，PILLM实现了最先进的性能，生成可解释且可操作的诊断规则。

Conclusion: PILLM框架通过结合物理原理和LLM，在HVAC异常检测中实现了高性能、可解释性和物理合理性，推动了智能建筑系统中可信赖AI的应用。

Abstract: Heating, Ventilation, and Air-Conditioning (HVAC) systems account for a
substantial share of global building energy use, making reliable anomaly
detection essential for improving efficiency and reducing emissions. Classical
rule-based approaches offer explainability but lack adaptability, while deep
learning methods provide predictive power at the cost of transparency,
efficiency, and physical plausibility. Recent attempts to use Large Language
Models (LLMs) for anomaly detection improve interpretability but largely ignore
the physical principles that govern HVAC operations. We present PILLM, a
Physics-Informed LLM framework that operates within an evolutionary loop to
automatically generate, evaluate, and refine anomaly detection rules. Our
approach introduces physics-informed reflection and crossover operators that
embed thermodynamic and control-theoretic constraints, enabling rules that are
both adaptive and physically grounded. Experiments on the public Building Fault
Detection dataset show that PILLM achieves state-of-the-art performance while
producing diagnostic rules that are interpretable and actionable, advancing
trustworthy and deployable AI for smart building systems.

</details>


### [258] [Which LLM Multi-Agent Protocol to Choose?](https://arxiv.org/abs/2510.17149)
*Hongyi Du,Jiaqi Su,Jisen Li,Lijie Ding,Yingxuan Yang,Peixuan Han,Xiangru Tang,Kunlun Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: ProtocolBench系统化评估多代理协议性能，ProtocolRouter动态选择协议提升系统可靠性，故障恢复时间减少18.1%。


<details>
  <summary>Details</summary>
Motivation: 大规模多代理系统中，通信协议的选择对性能和可靠性至关重要，但目前缺乏标准化的评估方法和指导。

Method: 引入ProtocolBench基准，从任务成功率、端到端延迟、消息/字节开销和故障恢复能力四个维度评估协议性能；并开发ProtocolRouter，一个可学习的协议路由器，根据场景需求和运行时信号动态选择协议。

Result: ProtocolBench显示不同协议在系统行为上有显著差异（如完成时间差异达36.5%）。ProtocolRouter在故障恢复时间上比最佳单协议基线减少18.1%，并在特定场景（如GAIA）中取得更高成功率。

Conclusion: 本文提出了ProtocolBench和ProtocolRouter，通过系统化评估和动态选择协议，显著提升了多代理系统的性能和可靠性。

Abstract: As large-scale multi-agent systems evolve, the communication protocol layer
has become a critical yet under-evaluated factor shaping performance and
reliability. Despite the existence of diverse protocols (A2A, ACP, ANP, Agora,
etc.), selection is often intuition-driven and lacks standardized guidance. We
introduce ProtocolBench, a benchmark that systematically compares agent
protocols along four measurable axes: task success, end-to-end latency, message
or byte overhead, and robustness under failures. On ProtocolBench, protocol
choice significantly influences system behavior. In the Streaming Queue
scenario, overall completion time varies by up to 36.5% across protocols, and
mean end-to-end latency differs by 3.48 s. Under Fail-Storm Recovery,
resilience also differs consistently across protocols. Beyond evaluation, we
present ProtocolRouter, a learnable protocol router that selects per-scenario
(or per-module) protocols from requirement and runtime signals. ProtocolRouter
reduces Fail-Storm recovery time by up to 18.1% versus the best single-protocol
baseline, and achieves scenario-specific gains such as higher success in GAIA.
We also release ProtocolRouterBench to standardize protocol evaluation and
improve reliability at scale.

</details>


### [259] [Combining ECG Foundation Model and XGBoost to Predict In-Hospital Malignant Ventricular Arrhythmias in AMI Patients](https://arxiv.org/abs/2510.17172)
*Shun Huang,Wenlu Xing,Shijia Geng,Hailong Wang,Guangkun Nie,Gongzheng Tang,Chenyang He,Shenda Hong*

Main category: cs.AI

TL;DR: 结合ECGFounder与XGBoost的混合模型在VT/VF风险预测中表现优异，兼顾准确性和可解释性，为AI临床决策支持提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 恶性室性心律失常（VT/VF）是急性心肌梗死（AMI）后院内死亡的主要原因，但早期识别仍是临床挑战。传统风险评分性能有限，而端到端深度学习模型缺乏临床信任所需的可解释性。

Method: 研究结合了大规模心电图基础模型（ECGFounder）与可解释的XGBoost分类器，通过特征选择和SHAP方法提升模型的准确性和可解释性。

Result: 混合模型AUC为0.801，优于KNN（0.677）、RNN（0.676）和1D-CNN（0.720）。SHAP分析显示模型识别的关键特征（如“室性早搏”和“正常窦性心律”）与临床知识高度一致。

Conclusion: 该混合框架为VT/VF风险预测提供了新范式，验证了基础模型输出可作为有效、自动化的特征工程，用于构建可信、可解释的AI临床决策支持系统。

Abstract: Malignant ventricular arrhythmias (VT/VF) following acute myocardial
infarction (AMI) are a major cause of in-hospital death, yet early
identification remains a clinical challenge. While traditional risk scores have
limited performance, end-to-end deep learning models often lack the
interpretability needed for clinical trust. This study aimed to develop a
hybrid predictive framework that integrates a large-scale electrocardiogram
(ECG) foundation model (ECGFounder) with an interpretable XGBoost classifier to
improve both accuracy and interpretability. We analyzed 6,634 ECG recordings
from AMI patients, among whom 175 experienced in-hospital VT/VF. The ECGFounder
model was used to extract 150-dimensional diagnostic probability features ,
which were then refined through feature selection to train the XGBoost
classifier. Model performance was evaluated using AUC and F1-score , and the
SHAP method was used for interpretability. The ECGFounder + XGBoost hybrid
model achieved an AUC of 0.801 , outperforming KNN (AUC 0.677), RNN (AUC
0.676), and an end-to-end 1D-CNN (AUC 0.720). SHAP analysis revealed that
model-identified key features, such as "premature ventricular complexes" (risk
predictor) and "normal sinus rhythm" (protective factor), were highly
consistent with clinical knowledge. We conclude that this hybrid framework
provides a novel paradigm for VT/VF risk prediction by validating the use of
foundation model outputs as effective, automated feature engineering for
building trustworthy, explainable AI-based clinical decision support systems.

</details>


### [260] [Offline Policy Evaluation of Multi-Turn LLM Health Coaching with Real Users](https://arxiv.org/abs/2510.17173)
*Melik Ozolcer,Sang Won Bae*

Main category: cs.AI

TL;DR: 研究通过离线策略评估和模拟器实验，发现统一重工具策略对特定子群体有害，而早期信息增益奖励能提升性能，建议冻结生成器并学习子群体感知决策头以实现个性化。


<details>
  <summary>Details</summary>
Motivation: 探索如何在工具增强的大型语言模型（LLM）健康教练中实现个性化评估，并识别不同子群体的潜在问题。

Method: 采用离线策略评估（OPE）和分解决策头（工具/风格）方法，结合轻量级模拟器和隐藏原型进行实验。

Result: 研究发现，统一的重工具策略虽然提高了日志的平均值，但对特定子群体（如低健康素养/高自我效能用户）造成负面影响。轻量级模拟器显示，早期信息增益奖励能缩短特质识别时间并提高目标成功率和pass@3。

Conclusion: 研究表明，通过冻结生成器、学习基于子群体的决策头，并报告每个原型的指标，可以有效地实现个性化评估，同时揭示被平均值掩盖的子群体问题。

Abstract: We study a web-deployed, tool-augmented LLM health coach with real users. In
a pilot with seven users (280 rated turns), offline policy evaluation (OPE)
over factorized decision heads (Tool/Style) shows that a uniform heavy-tool
policy raises average value on logs but harms specific subgroups, most notably
low-health-literacy/high-self-efficacy users. A lightweight simulator with
hidden archetypes further shows that adding a small early information-gain
bonus reliably shortens trait identification and improves goal success and
pass@3. Together, these early findings indicate an evaluation-first path to
personalization: freeze the generator, learn subgroup-aware decision heads on
typed rewards (objective tool outcomes and satisfaction), and always report
per-archetype metrics to surface subgroup harms that averages obscure.

</details>


### [261] [Temporally Detailed Hypergraph Neural ODEs for Type 2 Diabetes Progression Modeling](https://arxiv.org/abs/2510.17211)
*Tingsong Xiao,Yao An Lee,Zelin Xu,Yupu Zhang,Zibo Liu,Yu Huang,Jiang Bian,Serena Jingchuan Guo,Zhe Jiang*

Main category: cs.AI

TL;DR: TD-HNODE是一种基于时间详细超图和神经ODE的新方法，用于建模疾病进展，尤其是在2型糖尿病中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法适应真实数据或捕捉复杂的连续时间动态，需要一种更有效的疾病进展建模方法。

Method: 提出了一种名为TD-HNODE的方法，通过时间详细超图和神经ODE框架学习连续时间动态。

Result: 在两个真实临床数据集上，TD-HNODE在模拟疾病进展方面表现优于多个基线方法。

Conclusion: TD-HNODE模型在模拟2型糖尿病及相关心血管疾病进展方面优于现有基线方法，验证了其有效性和实用性。

Abstract: Disease progression modeling aims to characterize and predict how a patient's
disease complications worsen over time based on longitudinal electronic health
records (EHRs). Accurate modeling of disease progression, such as type 2
diabetes, can enhance patient sub-phenotyping and inform effective and timely
interventions. However, the problem is challenging due to the need to learn
continuous-time dynamics of progression patterns based on irregular-time event
samples and patient heterogeneity (\eg different progression rates and
pathways). Existing mechanistic and data-driven methods either lack
adaptability to learn from real-world data or fail to capture complex
continuous-time dynamics on progression trajectories. To address these
limitations, we propose Temporally Detailed Hypergraph Neural Ordinary
Differential Equation (TD-HNODE), which represents disease progression on
clinically recognized trajectories as a temporally detailed hypergraph and
learns the continuous-time progression dynamics via a neural ODE framework.
TD-HNODE contains a learnable TD-Hypergraph Laplacian that captures the
interdependency of disease complication markers within both intra- and
inter-progression trajectories. Experiments on two real-world clinical datasets
demonstrate that TD-HNODE outperforms multiple baselines in modeling the
progression of type 2 diabetes and related cardiovascular diseases.

</details>


### [262] [Coinvisor: An RL-Enhanced Chatbot Agent for Interactive Cryptocurrency Investment Analysis](https://arxiv.org/abs/2510.17235)
*Chong Chen,Ze Liu,Lingfeng Bao,Yanlin Wang,Ting Chen,Daoyuan Wu,Jiachi Chen*

Main category: cs.AI

TL;DR: Coinvisor是强化学习驱动的加密货币投资助手，通过多代理框架提升分析能力和用户满意度。


<details>
  <summary>Details</summary>
Motivation: 解决加密货币市场高波动性和信息碎片化带来的投资决策挑战，克服现有方法的局限性。

Method: 提出Coinvisor，一个基于强化学习的多代理框架聊天机器人，集成多样化分析工具，支持实时数据和多步推理。

Result: 在工具调用准确率上召回率提升40.7%，F1分数提升26.6%；用户满意度达4.64/5。

Conclusion: Coinvisor通过强化学习驱动的工具选择机制，显著提升了加密货币投资的准确性和用户满意度。

Abstract: The cryptocurrency market offers significant investment opportunities but
faces challenges including high volatility and fragmented information. Data
integration and analysis are essential for informed investment decisions.
Currently, investors use three main approaches: (1) Manual analysis across
various sources, which depends heavily on individual experience and is
time-consuming and prone to bias; (2) Data aggregation platforms-limited in
functionality and depth of analysis; (3) Large language model agents-based on
static pretrained models, lacking real-time data integration and multi-step
reasoning capabilities. To address these limitations, we present Coinvisor, a
reinforcement learning-based chatbot that provides comprehensive analytical
support for cryptocurrency investment through a multi-agent framework.
Coinvisor integrates diverse analytical capabilities through specialized tools.
Its key innovation is a reinforcement learning-based tool selection mechanism
that enables multi-step planning and flexible integration of diverse data
sources. This design supports real-time interaction and adaptive analysis of
dynamic content, delivering accurate and actionable investment insights. We
evaluated Coinvisor through automated benchmarks on tool calling accuracy and
user studies with 20 cryptocurrency investors using our interface. Results show
that Coinvisor improves recall by 40.7% and F1 score by 26.6% over the base
model in tool orchestration. User studies show high satisfaction (4.64/5), with
participants preferring Coinvisor to both general LLMs and existing crypto
platforms (4.62/5).

</details>


### [263] [RubiSCoT: A Framework for AI-Supported Academic Assessment](https://arxiv.org/abs/2510.17309)
*Thorsten Fröhlich,Tim Schlippe*

Main category: cs.AI

TL;DR: RubiSCoT是一个AI支持的论文评估框架，利用NLP技术提供一致、高效的评估，优化传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统论文评估方法虽有效但耗时且受评估者主观性影响，需要一种更高效、一致的解决方案。

Method: 采用先进的自然语言处理技术，包括大型语言模型、检索增强生成和结构化思维链提示，结合初步评估、多维评估、内容提取、基于量规的评分和详细报告。

Result: RubiSCoT框架设计并实现，展示了其在提升学术评估流程一致性、可扩展性和透明度方面的潜力。

Conclusion: RubiSCoT框架通过AI技术提供了一种一致、可扩展且透明的学术论文评估方法，有望优化传统评估流程。

Abstract: The evaluation of academic theses is a cornerstone of higher education,
ensuring rigor and integrity. Traditional methods, though effective, are
time-consuming and subject to evaluator variability. This paper presents
RubiSCoT, an AI-supported framework designed to enhance thesis evaluation from
proposal to final submission. Using advanced natural language processing
techniques, including large language models, retrieval-augmented generation,
and structured chain-of-thought prompting, RubiSCoT offers a consistent,
scalable solution. The framework includes preliminary assessments,
multidimensional assessments, content extraction, rubric-based scoring, and
detailed reporting. We present the design and implementation of RubiSCoT,
discussing its potential to optimize academic assessment processes through
consistent, scalable, and transparent evaluation.

</details>


### [264] [Diverse Planning with Simulators via Linear Temporal Logic](https://arxiv.org/abs/2510.17418)
*Mustafa F. Abdelwahed,Alice Toniolo,Joan Espasa,Ian P. Gent*

Main category: cs.AI

TL;DR: 论文提出$\texttt{FBI}_\texttt{LTL}$，一种基于LTL的多样化规划器，用于生成语义多样的计划，解决了传统方法在基于模拟环境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统规划器生成的单一计划可能无法满足代理的偏好，且现有多样化规划方法可能产生语法不同但语义相同的解决方案，无法满足语义多样性需求。

Method: 论文引入了$\texttt{FBI}_\texttt{LTL}$，一个专门为基于模拟的规划问题设计的多样化规划器。它利用线性时序逻辑（LTL）定义语义多样性标准，并将这些基于LTL的多样性模型直接集成到搜索过程中。

Result: 在各种基准测试中，$\texttt{FBI}_\texttt{LTL}$生成的计划比基线方法更具多样性。

Conclusion: 该论文确立了在基于模拟的环境中语义引导多样化规划的可行性，为在传统基于模型的方法失效的现实、非符号领域中创新方法铺平了道路。

Abstract: Autonomous agents rely on automated planning algorithms to achieve their
objectives. Simulation-based planning offers a significant advantage over
declarative models in modelling complex environments. However, relying solely
on a planner that produces a single plan may not be practical, as the generated
plans may not always satisfy the agent's preferences. To address this
limitation, we introduce $\texttt{FBI}_\texttt{LTL}$, a diverse planner
explicitly designed for simulation-based planning problems.
$\texttt{FBI}_\texttt{LTL}$ utilises Linear Temporal Logic (LTL) to define
semantic diversity criteria, enabling agents to specify what constitutes
meaningfully different plans. By integrating these LTL-based diversity models
directly into the search process, $\texttt{FBI}_\texttt{LTL}$ ensures the
generation of semantically diverse plans, addressing a critical limitation of
existing diverse planning approaches that may produce syntactically different
but semantically identical solutions. Extensive evaluations on various
benchmarks consistently demonstrate that $\texttt{FBI}_\texttt{LTL}$ generates
more diverse plans compared to a baseline approach. This work establishes the
feasibility of semantically-guided diverse planning in simulation-based
environments, paving the way for innovative approaches in realistic,
non-symbolic domains where traditional model-based approaches fail.

</details>


### [265] [Active Inference for an Intelligent Agent in Autonomous Reconnaissance Missions](https://arxiv.org/abs/2510.17450)
*Johan Schubert,Farzad Kamrani,Tove Gustavi*

Main category: cs.AI

TL;DR: 提出了一种基于主动推理的路径规划方法，通过变分自由能最小化实现智能代理的探索与利用平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决智能代理在探索广阔地理区域与跟踪已识别目标之间的平衡问题。

Method: 构建了一个基于Dempster-Shafer理论和高斯传感器模型的证据地图，结合贝叶斯方法更新后验概率分布，并通过变分自由能计算指导代理移动。

Result: 仿真结果表明，该方法能够有效引导代理在探索与利用之间取得平衡。

Conclusion: 该方法通过主动推理和变分自由能最小化，成功实现了智能代理在探索与利用之间的平衡，有效维护了地理区域的共同作战图景。

Abstract: We develop an active inference route-planning method for the autonomous
control of intelligent agents. The aim is to reconnoiter a geographical area to
maintain a common operational picture. To achieve this, we construct an
evidence map that reflects our current understanding of the situation,
incorporating both positive and "negative" sensor observations of possible
target objects collected over time, and diffusing the evidence across the map
as time progresses. The generative model of active inference uses
Dempster-Shafer theory and a Gaussian sensor model, which provides input to the
agent. The generative process employs a Bayesian approach to update a posterior
probability distribution. We calculate the variational free energy for all
positions within the area by assessing the divergence between a pignistic
probability distribution of the evidence map and a posterior probability
distribution of a target object based on the observations, including the level
of surprise associated with receiving new observations. Using the free energy,
we direct the agents' movements in a simulation by taking an incremental step
toward a position that minimizes the free energy. This approach addresses the
challenge of exploration and exploitation, allowing agents to balance searching
extensive areas of the geographical map while tracking identified target
objects.

</details>


### [266] [Label Indeterminacy in AI & Law](https://arxiv.org/abs/2510.17463)
*Cor Steging,Tadeusz Zbiegień*

Main category: cs.AI

TL;DR: 法律机器学习中的标签不确定性是一个被忽视的问题，研究通过欧洲人权法院案例展示了其对模型行为的影响。


<details>
  <summary>Details</summary>
Motivation: 法律领域中的机器学习通常将过去的案例结果视为绝对真理，但忽略了人为干预对结果的影响，导致标签不确定性。

Method: 通过分析欧洲人权法院的案例，研究了标签构建方式对模型行为的影响。

Result: 研究表明，标签的构建方式会显著影响模型的行为。

Conclusion: 标签不确定性是AI与法律领域中的一个重要问题，需要被纳入机器学习模型的考虑范围。

Abstract: Machine learning is increasingly used in the legal domain, where it typically
operates retrospectively by treating past case outcomes as ground truth.
However, legal outcomes are often shaped by human interventions that are not
captured in most machine learning approaches. A final decision may result from
a settlement, an appeal, or other procedural actions. This creates label
indeterminacy: the outcome could have been different if the intervention had or
had not taken place. We argue that legal machine learning applications need to
account for label indeterminacy. Methods exist that can impute these
indeterminate labels, but they are all grounded in unverifiable assumptions. In
the context of classifying cases from the European Court of Human Rights, we
show that the way that labels are constructed during training can significantly
affect model behaviour. We therefore position label indeterminacy as a relevant
concern in AI & Law and demonstrate how it can shape model behaviour.

</details>


### [267] [MIRAGE: Agentic Framework for Multimodal Misinformation Detection with Web-Grounded Reasoning](https://arxiv.org/abs/2510.17590)
*Mir Nafis Sharear Shopnil,Sharad Duwal,Abhishek Tyagi,Adiba Mahbub Proma*

Main category: cs.AI

TL;DR: MIRAGE框架通过分解多模态验证任务并整合视觉语言模型推理与网络检索，显著提升虚假信息检测性能，无需领域特定训练。


<details>
  <summary>Details</summary>
Motivation: 解决网络平台上多模态虚假信息传播速度快、手动核查能力不足的问题，以及现有监督检测模型泛化能力差的问题。

Method: MIRAGE框架，包含视觉真实性评估、跨模态一致性分析、检索增强的事实检查以及校准判断模块。

Result: 在MMFakeBench验证集上，MIRAGE与GPT-4o-mini组合达到81.65% F1和75.1%准确率，优于最强的零样本基线（GPT-4V与MMD-Agent组合的74.0% F1）。

Conclusion: 分解的代理推理与网络检索可以在无需领域特定训练的情况下匹配监督检测器的性能，适用于标记数据稀缺的多模态虚假信息检测。

Abstract: Misinformation spreads across web platforms through billions of daily
multimodal posts that combine text and images, overwhelming manual
fact-checking capacity. Supervised detection models require domain-specific
training data and fail to generalize across diverse manipulation tactics. We
present MIRAGE, an inference-time, model-pluggable agentic framework that
decomposes multimodal verification into four sequential modules: visual
veracity assessment detects AI-generated images, cross-modal consistency
analysis identifies out-of-context repurposing, retrieval-augmented factual
checking grounds claims in web evidence through iterative question generation,
and a calibrated judgment module integrates all signals. MIRAGE orchestrates
vision-language model reasoning with targeted web retrieval, outputs structured
and citation-linked rationales. On MMFakeBench validation set (1,000 samples),
MIRAGE with GPT-4o-mini achieves 81.65% F1 and 75.1% accuracy, outperforming
the strongest zero-shot baseline (GPT-4V with MMD-Agent at 74.0% F1) by 7.65
points while maintaining 34.3% false positive rate versus 97.3% for a
judge-only baseline. Test set results (5,000 samples) confirm generalization
with 81.44% F1 and 75.08% accuracy. Ablation studies show visual verification
contributes 5.18 F1 points and retrieval-augmented reasoning contributes 2.97
points. Our results demonstrate that decomposed agentic reasoning with web
retrieval can match supervised detector performance without domain-specific
training, enabling misinformation detection across modalities where labeled
data remains scarce.

</details>


### [268] [Reasoning Distillation and Structural Alignment for Improved Code Generation](https://arxiv.org/abs/2510.17598)
*Amir Jalilifard,Anderson de Rezende Rocha,Marcos Medeiros Raimundo*

Main category: cs.AI

TL;DR: 通过结构感知损失优化，将大型语言模型的推理能力蒸馏到小模型中，显著提升了代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 代码生成需要理解问题定义与解决方案的结构关系，而不仅仅是准确的词汇预测。大型语言模型具备这种能力，但部署成本高，因此需要将其能力蒸馏到更高效的模型中。

Method: 采用结构感知损失优化方法，训练小模型模拟大型语言模型的推理和问题解决能力。

Result: 在MBPP、MBPP Plus和HumanEval基准测试中，微调后的模型在pass@1、平均数据流和平均语法匹配指标上显著优于基线模型。

Conclusion: 通过结构感知损失优化，将大型语言模型的推理能力蒸馏到更小、高效的模型中，显著提升了代码生成的性能。

Abstract: Effective code generation with language models hinges on two critical
factors: accurately understanding the intent of the prompt and generating code
that applies algorithmic reasoning to produce correct solutions capable of
passing diverse test cases while adhering to the syntax of the target
programming language. Unlike other language tasks, code generation requires
more than accurate token prediction; it demands comprehension of solution-level
and structural relationships rather than merely generating the most likely
tokens. very large language model (VLLM) are capable of generating detailed
steps toward the correct solution of complex tasks where reasoning is crucial
in solving the problem. Such reasoning capabilities may be absent in smaller
language models. Therefore, in this work, we distill the reasoning capabilities
of a VLLM into a smaller, more efficient model that is faster and cheaper to
deploy. Our approach trains the model to emulate the reasoning and
problem-solving abilities of the VLLM by learning to identify correct solution
pathways and establishing a structural correspondence between problem
definitions and potential solutions through a novel method of structure-aware
loss optimization. This enables the model to transcend token-level generation
and to deeply grasp the overarching structure of solutions for given problems.
Experimental results show that our fine-tuned model, developed through a cheap
and simple to implement process, significantly outperforms our baseline model
in terms of pass@1, average data flow, and average syntax match metrics across
the MBPP, MBPP Plus, and HumanEval benchmarks.

</details>


### [269] [OG-Rank: Learning to Rank Fast and Slow with Uncertainty and Reward-Trend Guided Adaptive Exploration](https://arxiv.org/abs/2510.17614)
*Praphul Singh,Corey Barrett,Sumana Srivasta,Irfan Bulu,Sri Gadde,Krishnaram Kenthapadi*

Main category: cs.AI

TL;DR: OG-Rank是一个低延迟的临床订单排名系统，通过单解码器和不确定性门控解释步骤，实现了高效和灵活的排名。


<details>
  <summary>Details</summary>
Motivation: 临床医生需要实时工作并能证明其选择的排名系统。

Method: OG-Rank采用单解码器方法，结合第一令牌评分信号和不确定性门控解释步骤，对所有候选者进行一次评分，并在列表真正模糊时生成简短的结构化理由。

Result: OG-Rank在快速路径下表现良好（Recall@1~0.45，nDCG@20~0.625），并在门激活时进一步改善（Recall@1~0.56，nDCG@20~0.699，门激活率为45%）。

Conclusion: OG-Rank是一个实用的低延迟、解码器基础的重新排序系统，通过不确定性门控解释步骤和集中训练于困难案例的课程，实现了在临床订单选择任务中的高效表现。

Abstract: Clinicians need ranking systems that work in real time and still justify
their choices. Motivated by the need for a low-latency, decoder-based reranker,
we present OG-Rank, a single-decoder approach that pairs a pooled first-token
scoring signal with an uncertainty-gated explanation step. The model scores all
candidates in one pass and generates a brief, structured rationale only when
the list is genuinely ambiguous, keeping latency predictable. Trained with a
curriculum that concentrates effort on hard cases, OG-Rank delivers strong
effectiveness on encounter-scoped order selection (fast path: Recall@1~0.45,
nDCG@20~0.625) and improves further when the gate activates (Recall@1~0.56,
nDCG@20~0.699 at a 45\% gate rate), while compact backbones show similar gains
under the same policy. Encoder baselines trail in both effectiveness and
flexibility. The result is a practical recipe: rank fast by default and explain
when it helps, a pattern that applies broadly to decision tasks where selective
generation buys accuracy at acceptable cost. The single-policy design
simplifies deployment and budget planning, and the curriculum principle (spend
more on the hard cases, less on the easy ones) readily transfers beyond
clinical order selection.

</details>


### [270] [LLM-as-a-Prophet: Understanding Predictive Intelligence with Prophet Arena](https://arxiv.org/abs/2510.17638)
*Qingchuan Yang,Simon Mahns,Sida Li,Anri Gu,Jibang Wu,Haifeng Xu*

Main category: cs.AI

TL;DR: LLMs在预测任务中表现优异，但信息处理速度和准确性仍需改进。


<details>
  <summary>Details</summary>
Motivation: 探索利用大规模语言模型（LLMs）预测现实世界未来事件的潜力。

Method: 构建Prophet Arena评估基准，将预测任务分解为不同阶段进行控制实验。

Result: 许多LLMs表现出令人印象深刻的预测能力，如校准误差小、预测信心一致且有市场回报潜力。

Conclusion: LLMs展现出显著的预测能力，但仍存在关键瓶颈，如事件回忆不准确、数据源误解及信息聚合速度较慢。

Abstract: Forecasting is not only a fundamental intellectual pursuit but also is of
significant importance to societal systems such as finance and economics. With
the rapid advances of large language models (LLMs) trained on Internet-scale
data, it raises the promise of employing LLMs to forecast real-world future
events, an emerging paradigm we call "LLM-as-a-Prophet". This paper
systematically investigates such predictive intelligence of LLMs. To this end,
we build Prophet Arena, a general evaluation benchmark that continuously
collects live forecasting tasks and decomposes each task into distinct pipeline
stages, in order to support our controlled and large-scale experimentation. Our
comprehensive evaluation reveals that many LLMs already exhibit impressive
forecasting capabilities, reflected in, e.g., their small calibration errors,
consistent prediction confidence and promising market returns. However, we also
uncover key bottlenecks towards achieving superior predictive intelligence via
LLM-as-a-Prophet, such as LLMs' inaccurate event recalls, misunderstanding of
data sources and slower information aggregation compared to markets when
resolution nears.

</details>


### [271] [A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2510.17697)
*Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang*

Main category: cs.AI

TL;DR: 通过MAIDs框架提出目标干预范式，利用PSI技术实现因果效应最大化，有效解决MARL中的全局指导问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模多智能体强化学习（MARL）中全局指导不切实际及缺乏易用研究工具的问题。

Method: 利用多智能体影响图（MAIDs）作为图形框架，设计目标干预范式，并通过PSI技术实现因果效应最大化。

Result: 实验证明目标干预范式的有效性，并验证了关联图分析的结果。

Conclusion: 本研究通过多智能体影响图（MAIDs）框架，提出了一种称为目标干预的新交互范式，并通过预策略干预（PSI）技术实现。实验验证了目标干预的有效性及关联图分析结果的正确性。

Abstract: Steering cooperative multi-agent reinforcement learning (MARL) towards
desired outcomes is challenging, particularly when the global guidance from a
human on the whole multi-agent system is impractical in a large-scale MARL. On
the other hand, designing mechanisms to coordinate agents most relies on
empirical studies, lacking a easy-to-use research tool. In this work, we employ
multi-agent influence diagrams (MAIDs) as a graphical framework to address the
above issues. First, we introduce interaction paradigms that leverage MAIDs to
analyze and visualize existing approaches in MARL. Then, we design a new
interaction paradigm based on MAIDs, referred to as targeted intervention that
is applied to only a single targeted agent, so the problem of global guidance
can be mitigated. In our implementation, we introduce a causal inference
technique-referred to as Pre-Strategy Intervention (PSI)-to realize the
targeted intervention paradigm. Since MAIDs can be regarded as a special class
of causal diagrams, a composite desired outcome that integrates the primary
task goal and an additional desired outcome can be achieved by maximizing the
corresponding causal effect through the PSI. Moreover, the bundled relevance
graph analysis of MAIDs provides a tool to identify whether an MARL learning
paradigm is workable under the design of an interaction paradigm. In
experiments, we demonstrate the effectiveness of our proposed targeted
intervention, and verify the result of relevance graph analysis.

</details>


### [272] [Contextual Attention Modulation: Towards Efficient Multi-Task Adaptation in Large Language Models](https://arxiv.org/abs/2510.17705)
*Dayan Pan,Zhaoyang Fu,Jingyuan Wang,Xiao Han,Yue Zhu,Xiangyu Zhao*

Main category: cs.AI

TL;DR: CAM和HyCAM框架通过动态调制自注意力模块，提升LLM多任务适应能力，性能提升3.65%。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在多任务适应中知识遗忘和资源消耗的问题，提升任务特定特征的同时保留通用知识。

Method: 提出了Contextual Attention Modulation (CAM)机制和Hybrid Contextual Attention Modulation (HyCAM)框架，结合共享的全参数CAM模块和多个轻量级CAM模块，通过动态路由策略实现知识融合。

Result: 在问答、代码生成和逻辑推理等异构任务上显著优于现有方法，平均性能提升3.65%。

Conclusion: CAM和HyCAM框架显著提升了LLM在多任务适应中的性能，平均性能提升3.65%，同时有效解决了知识遗忘和资源消耗问题。

Abstract: Large Language Models (LLMs) possess remarkable generalization capabilities
but struggle with multi-task adaptation, particularly in balancing knowledge
retention with task-specific specialization. Conventional fine-tuning methods
suffer from catastrophic forgetting and substantial resource consumption, while
existing parameter-efficient methods perform suboptimally in complex multi-task
scenarios. To address this, we propose Contextual Attention Modulation (CAM), a
novel mechanism that dynamically modulates the representations of
self-attention modules in LLMs. CAM enhances task-specific features while
preserving general knowledge, thereby facilitating more effective and efficient
adaptation. For effective multi-task adaptation, CAM is integrated into our
Hybrid Contextual Attention Modulation (HyCAM) framework, which combines a
shared, full-parameter CAM module with multiple specialized, lightweight CAM
modules, enhanced by a dynamic routing strategy for adaptive knowledge fusion.
Extensive experiments on heterogeneous tasks, including question answering,
code generation, and logical reasoning, demonstrate that our approach
significantly outperforms existing approaches, achieving an average performance
improvement of 3.65%. The implemented code and data are available to ease
reproducibility at https://github.com/Applied-Machine-Learning-Lab/HyCAM.

</details>


### [273] [Seeing but Not Believing: Probing the Disconnect Between Visual Attention and Answer Correctness in VLMs](https://arxiv.org/abs/2510.17771)
*Zhining Liu,Ziyi Chen,Hui Liu,Chen Luo,Xianfeng Tang,Suhang Wang,Joy Zeng,Zhenwei Dai,Zhan Shi,Tianxin Wei,Benoit Dumoulin,Hanghang Tong*

Main category: cs.AI

TL;DR: 研究发现VLM存在‘看见但不相信’现象，并提出无需训练的干预方法，通过强调深层证据区域提升准确性。


<details>
  <summary>Details</summary>
Motivation: 探究VLM在多模态任务（如视觉问答）中失败的原因，是未感知证据还是未有效利用证据。

Method: 通过逐层注意力动态分析，发现浅层主要关注文本，而深层稀疏但可靠地关注局部证据区域。提出了一种无需训练的推理时干预方法，通过选择性注意力掩码突出深层证据区域。

Result: 干预方法在多个VLM家族（如LLaVA、Qwen、Gemma和InternVL）中一致提高了准确性，验证了VLM内部编码但未充分利用证据的现象。

Conclusion: 视觉语言模型（VLMs）在内部编码了可靠的证据但未充分利用，通过显式化这些信号可以弥合感知与推理之间的差距，提升VLM的诊断理解和可靠性。

Abstract: Vision-Language Models (VLMs) achieve strong results on multimodal tasks such
as visual question answering, yet they can still fail even when the correct
visual evidence is present. In this work, we systematically investigate whether
these failures arise from not perceiving the evidence or from not leveraging it
effectively. By examining layer-wise attention dynamics, we find that shallow
layers focus primarily on text, while deeper layers sparsely but reliably
attend to localized evidence regions. Surprisingly, VLMs often perceive the
visual evidence when outputting incorrect answers, a phenomenon we term
``seeing but not believing'' that widely exists in major VLM families. Building
on this, we introduce an inference-time intervention that highlights deep-layer
evidence regions through selective attention-based masking. It requires no
training and consistently improves accuracy across multiple families, including
LLaVA, Qwen, Gemma, and InternVL. These results show that VLMs encode reliable
evidence internally but under-utilize it, making such signals explicit can
bridge the gap between perception and reasoning, advancing the diagnostic
understanding and reliability of VLMs.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [274] [Two-Stage Sketch-Based Smoke Illustration Generation using Stream Function](https://arxiv.org/abs/2510.15873)
*Hengyuan Chang,Xiaoxuan Xie,Syuhei Sato,Haoran Xie*

Main category: cs.GR

TL;DR: 结合流函数和LDM的两阶段框架，实现基于草图的烟雾生成，补充草图中缺失的流动细节。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统烟雾生成方法难以准确捕捉用户草图意图的连续变化和旋转流动细节的问题，提出了一种结合流函数和LDM的新框架。

Method: 采用两阶段方法：首先利用用户草图生成流函数，作为速度场生成器的控制条件；其次使用潜在扩散模型（LDM）生成烟雾模拟，确保与预期流动对齐。训练过程中使用流线编码全局流动动力学作为草图指导。

Result: 生成的烟雾模拟能够准确对齐用户草图的预期流动，流函数作为中间表示有效补充了草图中缺失的细节。

Conclusion: 提出的两阶段框架通过结合流函数和潜在扩散模型（LDM），成功实现了基于用户草图的烟雾生成，有效捕捉了草图中缺失的连续变化和旋转流动细节。

Abstract: In this paper, we propose a two-stage sketch-based smoke illustration
generation framework using stream function and latent diffusion models (LDM).
The user sketch is used to guide the generation of the stream function, which
serves as the control condition for the velocity field generator. The generated
velocity field can be used to guide the smoke simulation to align with the
intended flow. We adopt streamlines to encode global flow dynamics as sketch
guidance during training. The stream function constitutes the intermediate
representation that captures continuous variation and rotational flow details
absent from sketches.

</details>


### [275] [Sketch-based Fluid Video Generation Using Motion-Guided Diffusion Models in Still Landscape Images](https://arxiv.org/abs/2510.15874)
*Hao Jin,Haoran Xie*

Main category: cs.GR

TL;DR: 本文提出了一种基于运动草图引导的框架，用于在静态图像中生成流畅且时间一致的流体动画。


<details>
  <summary>Details</summary>
Motivation: 流体元素的动态特性复杂，传统物理方法易受边界条件影响，现有潜在扩散模型难以生成流畅且时间一致的运动。

Method: 采用微调的条件潜在扩散模型从用户提供的草图中生成运动场，并通过运动适配器将其集成到潜在视频扩散模型中，以精确控制流体运动。

Result: 提出的框架能够生成高质量的景观视频，通过动画化静态图像中的流体，实现流畅且时间一致的运动效果。

Conclusion: 本文提出了一种通过运动草图引导静态图像中流体动画生成的框架，解决了现有方法在生成流畅且时间一致运动方面的挑战。

Abstract: Integrating motion into static images not only enhances visual expressiveness
but also creates a sense of immersion and temporal depth, establishing it as a
longstanding and impactful theme in artistic expression. Fluid elements such as
waterfall, river, and oceans are common features in landscape, but their
complex dynamic characteristics pose significant challenges in modeling and
controlling their motion within visual computing. Physics-based methods are
often used in fluid animation to track particle movement. However, they are
easily affected by boundary conditions. Recently, latent diffusion models have
been applied to video generation tasks, demonstrating impressive capabilities
in producing high-quality and temporally coherent results. However, it is
challenging for the existing methods to animate fluid smooth and temporally
consistent motion. To solve these issues, this paper introduces a framework for
generating landscape videos by animating fluid in still images under the
guidance of motion sketches. We propose a finetuned conditional latent
diffusion model for generating motion field from user-provided sketches, which
are subsequently integrated into a latent video diffusion model via a motion
adapter to precisely control the fluid movement.

</details>


### [276] [Adaptive Frameless Rendering](https://arxiv.org/abs/2510.15876)
*Abhinav Dayal,Cliff Woolley,Benjamin Watson,David Luebke*

Main category: cs.GR

TL;DR: 提出自适应无帧渲染方法，通过闭环反馈和动态重建显著提升渲染效率，减少样本需求。


<details>
  <summary>Details</summary>
Motivation: 传统交互式渲染方法因固定的采样模式效率较低，无法灵活适应时空颜色变化。

Method: 提出了一种自适应无帧渲染方法，利用闭环反馈指导采样，结合GPU重建技术，根据采样密度和时空颜色梯度动态调整。

Result: 在模拟中，该无帧渲染器所需样本数量比传统渲染少一个数量级，计算开销仅为15%。

Conclusion: 该方法通过自适应采样和重建显著提升了渲染速度，同时保持了与传统渲染相似的视觉质量。

Abstract: We propose an adaptive form of frameless rendering with the potential to
dramatically increase rendering speed over conventional interactive rendering
approaches. Without the rigid sampling patterns of framed renderers, sampling
and reconstruction can adapt with very fine granularity to spatio-temporal
color change. A sampler uses closed-loop feedback to guide sampling toward
edges or motion in the image. Temporally deep buffers store all the samples
created over a short time interval for use in reconstruction and as sampler
feedback. GPU-based reconstruction responds both to sampling density and
space-time color gradients. Where the displayed scene is static, spatial color
change dominates and older samples are given significant weight in
reconstruction, resulting in sharper and eventually antialiased images. Where
the scene is dynamic, more recent samples are emphasized, resulting in less
sharp but more up-to-date images. We also use sample reprojection to improve
reconstruction and guide sampling toward occlusion edges, undersampled regions,
and specular highlights. In simulation our frameless renderer requires an order
of magnitude fewer samples than traditional rendering of similar visual quality
(as measured by RMS error), while introducing overhead amounting to 15% of
computation time.

</details>


### [277] [Procedural modeling of urban land use](https://arxiv.org/abs/2510.15877)
*Thomas Lechner,Ben Watson,Uri Wilenski,Seth Tisue,Martin Felsen,Andy Moddrell,Pin Ren,Craig Brozefsky*

Main category: cs.GR

TL;DR: 该论文提出了一种程序化生成城市土地利用模式的方法，旨在自动化建筑物和道路的布局，以应对图形硬件快速发展对丰富内容的需求，同时减轻艺术家的工作负担。


<details>
  <summary>Details</summary>
Motivation: 城市在数字作品中的重要性与其建模的复杂性和挑战性之间存在矛盾，且缺乏有效的工具帮助艺术家应对图形硬件快速发展带来的需求。

Method: 采用程序化生成技术，自动创建城市中土地利用的现实模式。

Result: 开发了一种能够自动生成建筑物和道路布局的方法，减轻了艺术家的工作负担。

Conclusion: 提出的方法能够自动化生成城市中建筑物和道路的布局，为艺术家提供了一种高效的工具，以应对图形硬件快速发展带来的对丰富内容的需求。

Abstract: Cities are important elements of content in digital productions, but their
complexity and size make them very challenging to model. Few tools exist that
can help artists with this work, even as rapid improvements in graphics
hardware create demand for richer content without matching increases in
production cost. We propose a method for procedurally generating realistic
patterns of land use in cities, automating placement of buildings and roads for
artists.

</details>


### [278] [Structural Tree Extraction from 3D Surfaces](https://arxiv.org/abs/2510.15886)
*Diogo de Andrade,Nuno Fachada*

Main category: cs.GR

TL;DR: 该论文提出了一种从3D非组织多边形数据中提取层次树表示的方法，通过生成Steiner树和利用视线约束优化结构，适用于程序生成和地图分析。


<details>
  <summary>Details</summary>
Motivation: 传统骨架化技术通常假设体积解释，而该方法直接在表面上操作，确保结果表示对导航感知的几何分析保持相关性。

Method: 该方法首先从3D非组织多边形数据中提取表面图表示，然后生成Steiner树以优化关键终端点之间的连接，并利用视线约束进一步细化结构。

Result: 结果表明，该方法能够生成简化的、连贯的结构表示，支持程序生成、空间推理和地图分析等应用。

Conclusion: 该方法通过两个用例验证了其有效性，能够生成简化的、连贯的结构表示，适用于程序生成、空间推理和地图分析等应用。

Abstract: This paper introduces a method to extract a hierarchical tree representation
from 3D unorganized polygonal data. The proposed approach first extracts a
graph representation of the surface, which serves as the foundation for
structural analysis. A Steiner tree is then generated to establish an optimized
connection between key terminal points, defined according to
application-specific criteria. The structure can be further refined by
leveraging line-of-sight constraints, reducing redundancy while preserving
essential connectivity. Unlike traditional skeletonization techniques, which
often assume volumetric interpretations, this method operates directly on the
surface, ensuring that the resulting representation remains relevant for
navigation-aware geometric analysis. The method is validated through two use
cases: extracting structural representations from tile-based elements for
procedural content generation, and identifying key points and structural
metrics for automated level analysis. Results demonstrate its ability to
produce simplified, coherent representations, supporting applications in
procedural generation, spatial reasoning, and map analysis.

</details>


### [279] [Procedural Scene Programs for Open-Universe Scene Generation: LLM-Free Error Correction via Program Search](https://arxiv.org/abs/2510.16147)
*Maxim Gumin,Do Heon Han,Seung Jean Yoo,Aditya Ganeshan,R. Kenny Jones,Kailiang Fu,Rio Aguina-Kang,Stewart Morris,Daniel Ritchie*

Main category: cs.GR

TL;DR: 本文提出了一种命令式三维场景布局生成方法，通过LLM迭代放置对象并引入错误修正机制，显著优于现有声明式方法，且新评估指标与人类偏好一致。


<details>
  <summary>Details</summary>
Motivation: 现有方法多采用声明式范式（通过LLM生成对象间约束规范再求解），但存在场景复杂性和多样性处理不足的问题。

Method: 本文探索了一种命令式范式，即通过LLM迭代放置对象，每个对象的位置和方向基于先前放置的对象计算。此外，还开发了一种错误修正机制，以提高布局的鲁棒性。

Result: 命令式方法在感知研究中显著优于声明式方法，且提出的自动评估指标与人类偏好一致。

Conclusion: 参与者更喜欢本文提出的命令式方法生成的布局，其在感知研究中分别以82%和94%的偏好率优于两种声明式方法。此外，本文还提出了一种与人类偏好一致的三维场景布局生成自动评估指标。

Abstract: Synthesizing 3D scenes from open-vocabulary text descriptions is a
challenging, important, and recently-popular application. One of its critical
subproblems is layout generation: given a set of objects, lay them out to
produce a scene matching the input description. Nearly all recent work adopts a
declarative paradigm for this problem: using an LLM to generate a specification
of constraints between objects, then solving those constraints to produce the
final layout. In contrast, we explore an alternative imperative paradigm, in
which an LLM iteratively places objects, with each object's position and
orientation computed as a function of previously-placed objects. The imperative
approach allows for a simpler scene specification language while also handling
a wider variety and larger complexity of scenes. We further improve the
robustness of our imperative scheme by developing an error correction mechanism
that iteratively improves the scene's validity while staying as close as
possible to the original layout generated by the LLM. In forced-choice
perceptual studies, participants preferred layouts generated by our imperative
approach 82% and 94% of the time when compared against two declarative layout
generation methods. We also present a simple, automated evaluation metric for
3D scene layout generation that aligns well with human preferences.

</details>


### [280] [Region-Aware Wasserstein Distances of Persistence Diagrams and Merge Trees](https://arxiv.org/abs/2510.16486)
*Mathieu Pont,Christoph Garth*

Main category: cs.GR

TL;DR: 本文提出了一种广义的Wasserstein距离方法，优化了持久性图和合并树的比较，提高了区分性和计算效率，并展示了其在实际应用中的价值。


<details>
  <summary>Details</summary>
Motivation: 传统的Wasserstein距离在比较拓扑特征时缺乏区分性，无法充分利用输入域中的区域信息。本文旨在提出一种更 discriminative 的度量方法。

Method: 重新定义拓扑特征的比较方式，基于极值对齐区域的值计算距离，并通过输入参数调整区域属性在距离中的影响。提出了两种策略来控制计算时间和内存使用。

Result: 实验结果表明，该方法在公开数据集上平均运行时间为分钟级别，且在时间变化集合的特征跟踪和降维应用中表现出色。

Conclusion: 本文提出了一种广义的Wasserstein距离方法，适用于持久性图和合并树，通过优化计算时间和内存存储策略，提高了方法的效率和实用性。实验证明该方法在公开数据集上运行效率高，并展示了其在时间变化集合和降维应用中的价值。

Abstract: This paper presents a generalization of the Wasserstein distance for both
persistence diagrams and merge trees [20], [66] that takes advantage of the
regions of their topological features in the input domain. Specifically, we
redefine the comparison of topological features as a distance between the
values of their extrema-aligned regions. It results in a more discriminative
metric than the classical Wasserstein distance and generalizes it through an
input parameter adjusting the impact of the region properties in the distance.
We present two strategies to control both computation time and memory storage
of our method by respectively enabling the use of subsets of the regions in the
computation, and by compressing the regions' properties to obtain low-memory
representations. Extensive experiments on openly available ensemble data
demonstrate the efficiency of our method, with running times on the orders of
minutes on average. We show the utility of our contributions with two
applications. First, we use the assignments between topological features
provided by our method to track their evolution in time-varying ensembles and
propose the temporal persistence curves to facilitate the understanding of how
these features appear, disappear and change over time. Second, our method
allows to compute a distance matrix of an ensemble that can be used for
dimensionality reduction purposes and visually represent in 2D all its members,
we show that such distance matrices also allow to detect key phases in the
ensemble. Finally, we provide a C++ implementation that can be used to
reproduce our results.

</details>


### [281] [Filtering of Small Components for Isosurface Generation](https://arxiv.org/abs/2510.16684)
*Devin Zhao,Rephael Wenger*

Main category: cs.GR

TL;DR: 论文提出通过预处理过滤去除扫描数据等值面中的微小成分，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 扫描数据（如CT或MRI）生成的等值面常包含微小成分，干扰可视化且无助于几何模型的构建。

Method: 通过简单的数据预处理过滤方法去除微小等值面成分。

Result: 实验结果表明预处理过滤能有效去除微小成分，保留主要可视化部分。

Conclusion: 预处理过滤能有效去除扫描数据中的微小等值面成分，同时不影响主要可视化部分。

Abstract: Let $f: \mathbb{R}^3 \rightarrow \mathbb{R}$ be a scalar field. An isosurface
is a piecewise linear approximation of a level set $f^{-1}(\sigma)$ for some
$\sigma \in \mathbb{R}$ built from some regular grid sampling of $f$.
Isosurfaces constructed from scanned data such as CT scans or MRIs often
contain extremely small components that distract from the visualization and do
not form part of any geometric model produced from the data. Simple
prefiltering of the data can remove such small components while having no
effect on the large components that form the body of the visualization. We
present experimental results on such filtering.

</details>


### [282] [A Scalable In Transit Solution for Comprehensive Exploration of Simulation Data](https://arxiv.org/abs/2510.16966)
*Paascal Grosset,James Ahrens*

Main category: cs.GR

TL;DR: SeerX是一种新型的传输中现场服务，解决了现场分析中需要先验知识的问题，支持动态资源分配和数据压缩。


<details>
  <summary>Details</summary>
Motivation: 随着模拟产生的数据量超过超级计算机的可用磁盘空间，现场分析和可视化成为减少存储需求的关键方法，但其效果受限于需要先验知识的问题。

Method: 本文提出了SeerX，一种支持动态资源分配和3D数据有损压缩的轻量级、可扩展的传输中现场服务。

Result: SeerX能够在不进行MPI同步的情况下，支持多个模拟将分析任务卸载到共享的弹性服务基础设施上。

Conclusion: SeerX提供了一个轻量级、可扩展的传输中现场服务，支持动态资源分配和3D模拟数据的有损压缩，解决了传统现场分析中需要先验知识的问题。

Abstract: As simulations produce more data than available disk space on supercomputers,
many simulations are employing in situ analysis and visualization to reduce the
amount of data that needs to be stored. While in situ visualization offers
potential for substantial data reduction, its efficacy is hindered by the need
for a priori knowledge. First, we need to know what visualization parameters to
use to highlight features of interest. Second, we do not know ahead of time how
much resources will be needed to run the in situ workflows, e.g. how many
compute nodes will be needed for in situ work. In this work, we present SeerX,
a lightweight, scalable in-transit in situ service that supports dynamic
resource allocation and lossy compression of 3D simulation data. SeerX enables
multiple simulations to offload analysis to a shared, elastic service
infrastructure without MPI synchronization.

</details>


### [283] [Shape-aware Inertial Poser: Motion Tracking for Humans with Diverse Shapes Using Sparse Inertial Sensors](https://arxiv.org/abs/2510.17101)
*Lu Yin,Ziying Shi,Yinghao Wu,Xinyu Yi,Feng Xu,Shihui Guo*

Main category: cs.GR

TL;DR: SAIP是一种考虑体型差异的稀疏惯性运动捕捉方法，通过分解形状和姿势相关传感器测量，并利用回归模型和物理优化，有效解决了不同体型个体的运动捕捉问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖模板成人身体形状，难以泛化到体型差异较大的个体（如儿童）。这主要是由于身体形状变化导致的IMU测量加速度差异。

Method: SAIP首先训练一个回归模型，将真实身体的IMU测量加速度转换为模板成人身体模型，补偿形状相关的传感器测量。随后，利用现有方法估计模板形状身体的全身运动。最后，通过第二个回归模型将关节速度映射回真实身体，并结合形状感知的物理优化策略计算全局运动。

Result: SAIP在包含不同体型个体的IMU运动捕捉数据集上表现出色，有效处理了多样体型的运动捕捉任务。

Conclusion: SAIP通过分解传感器测量中与形状和姿势相关的部分，并利用回归模型和物理优化策略，有效解决了不同体型个体的运动捕捉问题。此外，该方法首次引入了惯性形状估计方案，并通过实验验证了其有效性。

Abstract: Human motion capture with sparse inertial sensors has gained significant
attention recently. However, existing methods almost exclusively rely on a
template adult body shape to model the training data, which poses challenges
when generalizing to individuals with largely different body shapes (such as a
child). This is primarily due to the variation in IMU-measured acceleration
caused by changes in body shape. To fill this gap, we propose Shape-aware
Inertial Poser (SAIP), the first solution considering body shape differences in
sparse inertial-based motion capture. Specifically, we decompose the sensor
measurements related to shape and pose in order to effectively model their
joint correlations. Firstly, we train a regression model to transfer the
IMU-measured accelerations of a real body to match the template adult body
model, compensating for the shape-related sensor measurements. Then, we can
easily follow the state-of-the-art methods to estimate the full body motions of
the template-shaped body. Finally, we utilize a second regression model to map
the joint velocities back to the real body, combined with a shape-aware
physical optimization strategy to calculate global motions on the subject.
Furthermore, our method relies on body shape awareness, introducing the first
inertial shape estimation scheme. This is accomplished by modeling the
shape-conditioned IMU-pose correlation using an MLP-based network. To validate
the effectiveness of SAIP, we also present the first IMU motion capture dataset
containing individuals of different body sizes. This dataset features 10
children and 10 adults, with heights ranging from 110 cm to 190 cm, and a total
of 400 minutes of paired IMU-Motion samples. Extensive experimental results
demonstrate that SAIP can effectively handle motion capture tasks for diverse
body shapes. The code and dataset are available at
https://github.com/yinlu5942/SAIP.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [284] [Agentic AI for Ultra-Modern Networks: Multi-Agent Framework for RAN Autonomy and Assurance](https://arxiv.org/abs/2510.16144)
*Sukhdeep Singh,Avinash Bhat,Shweta M,Subhash K Singh,Moonki Hong,Madhan Raj K,Kandeepan Sithamparanathan,Sunder A. Khowaja,Kapal Dev*

Main category: cs.NI

TL;DR: 本文提出多智能体架构作为下一代RAN自主性的解决方案，通过分布式代理实现自治、弹性、可解释性和系统安全性，验证了其在流量转向用例中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统O-RAN控制循环依赖基于RIC的编排，集中化智能并暴露系统于政策冲突、数据漂移和不可预见条件下的不安全行动等风险。

Method: 设计并评估了一个在激增和漂移条件下的流量转向用例，通过四个KPI（RRC连接用户、IP吞吐量、PRB利用率和SINR）进行验证。

Result: 研究表明，多智能体系统能够阻止不安全政策，保持全局网络健康，而简单的预测驱动部署虽然改善了局部KPI，但会破坏邻居稳定性。

Conclusion: 多智能体架构为下一代RAN中可信赖的AI驱动自主性提供了可靠基础。

Abstract: The increasing complexity of Beyond 5G and 6G networks necessitates new
paradigms for autonomy and assur- ance. Traditional O-RAN control loops rely
heavily on RIC- based orchestration, which centralizes intelligence and exposes
the system to risks such as policy conflicts, data drift, and unsafe actions
under unforeseen conditions. In this work, we argue that the future of
autonomous networks lies in a multi-agentic architecture, where specialized
agents collaborate to perform data collection, model training, prediction,
policy generation, verification, deployment, and assurance. By replacing
tightly- coupled centralized RIC-based workflows with distributed agents, the
framework achieves autonomy, resilience, explainability, and system-wide
safety. To substantiate this vision, we design and evaluate a traffic steering
use case under surge and drift conditions. Results across four KPIs: RRC
connected users, IP throughput, PRB utilization, and SINR, demonstrate that a
naive predictor-driven deployment improves local KPIs but destabilizes
neighbors, whereas the agentic system blocks unsafe policies, preserving global
network health. This study highlights multi- agent architectures as a credible
foundation for trustworthy AI- driven autonomy in next-generation RANs.

</details>


### [285] [Traffic Prioritization Mechanisms for Mission and Time Critical Applications in Industrial Internet of Things](https://arxiv.org/abs/2510.17009)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: cs.NI

TL;DR: 论文评估了IIoT中SS-MAC和FROG-MAC两种MAC协议的性能，发现FROG-MAC因减少紧急流量等待时间而更优，适用于工业环境中的异构流量调度。


<details>
  <summary>Details</summary>
Motivation: 工业物联网(IIoT)通过机器对机器(M2M)通信改变工业操作和生产，但不同节点生成的数据类型和服务需求多样，MAC协议对确保高效传输至关重要。

Method: 通过Contiki对SS-MAC和FROG-MAC两种协议进行实际模拟，比较延迟和数据包丢失情况。

Result: 模拟结果显示FROG-MAC在延迟和数据包丢失方面优于SS-MAC。

Conclusion: FROG-MAC在工业物联网环境中表现出色，因其减少了紧急流量的等待时间，简单的分片方案适用于异构流量的高效调度。

Abstract: Industrial Internet of Things (IIoT) promises to revolutionize industrial
operations and productions through utilizing Machine-to-Machine (M2M)
communications. Since each node in such environments generates various types of
data with diverse service requirements, MAC protocol holds crucial importance
to ensure efficient delivery. In this context, simple to complex MAC schemes
are found in literature. This paper focuses on evaluating the performance of
two major techniques "slot stealing" and "packet fragmentation" for the IIoT;
representative protocols SS-MAC and FROG-MAC have been chosen from each
category respectively. We conducted realistic simulations for the two protocols
using Contiki. Delay and packet loss comparison for SS-MAC and FROG-MAC
indicates the superiority of FROG-MAC due to reduction in the waiting time for
urgent traffic. Thus, a simple fragmentation scheme could be deployed for
efficient scheduling of heterogenous traffic in the industrial environments.

</details>


### [286] [Mamba4Net: Distilled Hybrid Mamba Large Language Models For Networking](https://arxiv.org/abs/2510.17147)
*Linhan Xia,Mingzhan Yang,Jingjing Wang,Ziwei Yan,Yakun Ren,Guo Yu,Kai Lei*

Main category: cs.NI

TL;DR: Mamba4Net通过知识蒸馏将LLM的网络知识转移到Mamba架构中，显著提升效率并降低资源需求，适用于资源受限的网络环境。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer-based LLMs在网络研究中被广泛应用，但其二次时间复杂度和大模型尺寸导致计算开销和内存限制问题，尤其在资源受限环境中。

Method: 本文提出了一种名为Mamba4Net的跨架构蒸馏框架，将基于Transformer的LLMs的网络特定知识蒸馏到基于Mamba架构的学生模型中，后者具有线性时间复杂度。

Result: Mamba4Net在三个网络任务（视口预测、自适应比特率流和集群作业调度）中表现出优于现有方法的性能，并实现了3.96倍的吞吐量提升和仅需5.48%的存储空间。

Conclusion: Mamba4Net框架通过知识蒸馏将基于Transformer的大语言模型（LLMs）的网络特定知识转移到基于Mamba架构的学生模型中，显著提升了计算效率并降低了资源需求，为网络领域提供了经济高效的LLM应用方案。

Abstract: Transformer-based large language models (LLMs) are increasingly being adopted
in networking research to address domain-specific challenges. However, their
quadratic time complexity and substantial model sizes often result in
significant computational overhead and memory constraints, particularly in
resource-constrained environments. Drawing inspiration from the efficiency and
performance of the Deepseek-R1 model within the knowledge distillation
paradigm, this paper introduces Mamba4Net, a novel cross-architecture
distillation framework. Mamba4Net transfers networking-specific knowledge from
transformer-based LLMs to student models built on the Mamba architecture, which
features linear time complexity. This design substantially enhances
computational efficiency compared to the quadratic complexity of
transformer-based models, while the reduced model size further minimizes
computational demands, improving overall performance and resource utilization.
To evaluate its effectiveness, Mamba4Net was tested across three diverse
networking tasks: viewport prediction, adaptive bitrate streaming, and cluster
job scheduling. Compared to existing methods that do not leverage LLMs,
Mamba4Net demonstrates superior task performance. Furthermore, relative to
direct applications of transformer-based LLMs, it achieves significant
efficiency gains, including a throughput 3.96 times higher and a storage
footprint of only 5.48% of that required by previous LLM-based approaches.
These results highlight Mamba4Net's potential to enable the cost-effective
application of LLM-derived knowledge in networking contexts. The source code is
openly available to support further research and development.

</details>


### [287] [AoA Services in 5G Networks: A Framework for Real-World Implementation and Systematic Testing](https://arxiv.org/abs/2510.17342)
*Alberto Ceresoli,Viola Bernazzoli,Roberto Pegurri,Ilario Filippini*

Main category: cs.NI

TL;DR: 本文提出首个完全开源的5G测试床，用于AoA估计，展示了轻量级、单锚点、网络原生定位在5G系统中的可行性。


<details>
  <summary>Details</summary>
Motivation: 标准化的位置管理功能（LMF）在核心网络中集中运行，但其可扩展性和延迟限制阻碍了低延迟和细粒度定位。将定位智能转向无线接入网络（RAN）是一种实用替代方案。

Method: 该框架整合了NVIDIA Sionna RT与Keysight PROPSIM信道模拟器，并包含了一种针对USRP N310设备的新型相位校准程序。

Result: 实验结果显示，基于上行探测参考信号（SRS）的到达角（AoA）估计能够实现亚度至几度的精度。

Conclusion: 实验结果表明，轻量级、单锚点、网络原生定位在下一代5G系统中是可行的，精度可达亚度至几度。

Abstract: Accurate positioning is a key enabler for emerging 5G applications. While the
standardized Location Management Function (LMF) operates centrally within the
core network, its scalability and latency limitations hinder low-latency and
fine-grained localization. A practical alternative is to shift positioning
intelligence toward the radio access network (RAN), where uplink sounding
reference signal (SRS)-based angle-of-arrival (AoA) estimation offers a
lightweight, network-native solution. In this work, we present the first fully
open-source 5G testbed for AoA estimation, enabling systematic and repeatable
experimentation under realistic yet controllable channel conditions. The
framework integrates the NVIDIA Sionna RT with a Keysight PROPSIM channel
emulator and includes a novel phase calibration procedure for USRP N310
devices. Experimental results show sub-degree to few-degree accuracy,
validating the feasibility of lightweight, single-anchor, network-native
localization within next-generation 5G systems.

</details>


### [288] [Enhancing 5G V2X Mode 2 for Sporadic Traffic](https://arxiv.org/abs/2510.17395)
*Dmitry Bankov,Artem Krasilov,Artem Otmakhov,Aleksei Shashin,Evgeny Khorov*

Main category: cs.NI

TL;DR: 本文研究了5G V2X中Mode 2在偶发流量下的性能，提出了改进方法，仿真显示系统容量可提升40%，且复杂度增加有限。


<details>
  <summary>Details</summary>
Motivation: 满足车辆间及车辆与基础设施间对及时可靠数据传输的需求，特别是在偶发流量场景下（如车辆检测到危险情况时随机生成数据包），需满足严格的延迟和可靠性要求。

Method: 分析了Mode 2在偶发流量场景下的性能，并提出了多种改进方法。通过仿真验证了这些方法的有效性。

Result: 仿真结果表明，提出的改进方法可将系统容量提升高达40%，同时对系统的复杂度影响较小。

Conclusion: 本文提出的方法显著提升了5G V2X系统中Mode 2的性能，系统容量可增加高达40%，且对复杂度影响较低。

Abstract: The emerging road safety and autonomous vehicle applications require timely
and reliable data delivery between vehicles and between vehicles and
infrastructure. To satisfy this demand, 3GPP develops a 5G
Vehicle-to-Everything (V2X) technology. Depending on the served traffic type,
5G V2X specifications propose two channel access methods: (i) Mode 1, according
to which a base station allocates resources to users, and (ii) Mode 2,
according to which users autonomously select resources for their transmissions.
In the paper, we consider a scenario with sporadic traffic, e.g., a vehicle
generates a packet at a random time moment when it detects a dangerous
situation, which imposes strict requirements on delay and reliability. To
satisfy strict delay requirements, vehicles use Mode 2. We analyze the
performance of Mode 2 for sporadic traffic and propose several approaches to
improve it. Simulation results show that the proposed approaches can increase
the system capacity by up to 40% with a low impact on complexity.

</details>


### [289] [Is It Worth to Use Feedback Channel in 5G V2X Platoon Scenarios?](https://arxiv.org/abs/2510.17410)
*Dmitry Bankov,Artem Krasilov,Artem Otmakhov,Pavel Savlukovich,Evgeny Khorov*

Main category: cs.NI

TL;DR: 5G V2X的反馈信道对系统容量影响显著，可能提升或降低容量，需根据场景自适应选择参数。


<details>
  <summary>Details</summary>
Motivation: 5G V2X引入了反馈信道以提高数据传输可靠性并协助选择传输参数，但反馈信道会占用部分资源，可能影响数据传传输的整体容量。本文旨在研究反馈信道在不同场景下的影响。

Method: 作者通过NS-3中的广泛模拟分析了反馈信道对系统容量的影响，考虑了车队生成组播流量和周围车辆生成广播流量的场景。

Result: 模拟结果显示，反馈信道的使用在不同条件下对系统容量有显著影响，可能提升或降低容量。作者解释了这些效应的原因并提出了自适应参数选择的建议。

Conclusion: 论文得出结论，反馈信道的使用对系统容量的影响取决于多种因素，如车队规模、组播和广播流量强度及其服务质量要求。在某些情况下，反馈信道可以显著提高系统容量（最高可达2倍），而在其他情况下则可能几乎减半。作者还讨论了如何自适应选择反馈信道参数以优化性能。

Abstract: 5G Vehicle-to-Everything (V2X) is a new technology developed by 3GPP to
support inter-vehicle communication. In contrast to 4G V2X which allows only
broadcast communication, 5G V2X enables groupcast and unicast communication.
Such types of communication are needed for new V2X scenarios: platooning,
extended sensors, remote driving, etc. To improve the data transmission
reliability and assist in the selection of the transmission parameters in these
scenarios, 5G V2X introduces a feedback channel that allows receivers to send
acknowledgments in response to data packets. However, some part of the overall
resource shall be allocated for the feedback channel, which reduces the amount
of channel resources available for data transmission. In this paper, we
consider a scenario with a platoon, which generates groupcast traffic, and
surrounding vehicles, which generate legacy broadcast traffic. Using extensive
simulations in NS-3, we analyze how the usage of the feedback channel
influences the overall system capacity. Our results show that depending on the
platoon size, groupcast, and broadcast traffic intensities, and their quality
of service requirements, the usage of the feedback channel can in some cases
significantly increase the system capacity (up to 2x), while in other cases it
almost halves the system capacity. We explain the reasons for such effects and
discuss how to adaptively select the feedback channel parameters.

</details>


### [290] [Adaptive Local Combining with Decentralized Decoding for Distributed Massive MIMO](https://arxiv.org/abs/2510.17445)
*Mohd Saif Ali Khan,Karthik RM,Samar Agnihotri*

Main category: cs.NI

TL;DR: 论文提出去中心化解码架构和两种广义局部ZF框架，显著提升分布式大规模MIMO网络性能，降低开销和计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的LSFD架构存在开销高、计算成本大且性能次优的问题，需要一种更高效、可扩展的解码方案来提升分布式大规模MIMO网络的性能。

Method: 引入了一种去中心化解码架构，允许每个AP独立计算干扰抑制的局部权重，并应用于数据估计。提出了G-PFZF和G-PWPFZF两种框架，AP通过局部信息和频谱效率优化自适应确定组合策略，并引入基于导频的组合向量以增强可扩展性。

Result: 数值结果表明，广义方案优于固定阈值方案，局部权重的引入降低了开销和计算成本，性能损失极小。

Conclusion: 论文提出的去中心化解码架构和两种广义局部零干扰（ZF）框架（G-PFZF和G-PWPFZF）显著提升了上行分布式大规模MIMO网络的性能，降低了开销和计算成本，同时避免了固定阈值的局限性。

Abstract: A major bottleneck in uplink distributed massive multiple-input
multiple-output networks is the sub-optimal performance of local combining
schemes, coupled with high fronthaul load and computational cost inherent in
centralized large scale fading decoding (LSFD) architectures. This paper
introduces a decentralized decoding architecture that fundamentally breaks from
the conventional LSFD, by allowing each AP calculates interference-suppressing
local weights independently and applies them to its data estimates before
transmission. Furthermore, two generalized local zero-forcing (ZF) framework,
generalized partial full-pilot ZF (G-PFZF) and generalized protected weak PFZF
(G-PWPFZF), are introduced, where each access point (AP) adaptively and
independently determines its combining strategy through a local sum spectral
efficiency optimization that classifies user equipments (UEs) as strong or weak
using only local information, eliminating the fixed thresholds used in PFZF and
PWPFZF. To further enhance scalability, pilot-dependent combining vectors
instead of user-dependent ones are introduced and are shared among users with
the same pilot. The corresponding closed-form spectral efficiency expressions
are derived. Numerical results show that the proposed generalized schemes
consistently outperform fixed-threshold counterparts, while the introduction of
local weights yields lower overhead and computation costs with minimal
performance penalty compared to them.

</details>


### [291] [Pointing-Error-Induced Fading in an Open-Loop THz Uplink with Hardware Impairments](https://arxiv.org/abs/2510.17647)
*P. Brach del Prever,P. Testolina,A. Masihi,S. Petrushkevich,M. Polese,T. Melodia,J. M. Jornet*

Main category: cs.NI

TL;DR: 该论文研究了亚太赫兹和太赫兹上行链路通信系统的机械跟踪性能，开发了数学模型量化指向误差，并提供了高频非地面网络上行链路的设计指南。


<details>
  <summary>Details</summary>
Motivation: 研究亚太赫兹（sub-THz）和太赫兹（THz）上行链路通信系统的开环机械跟踪性能，这些高频段通过大带宽和窄波束实现多千兆位链路，但需要精确指向以克服扩展损耗。

Method: 开发了一个数学模型，捕捉真实跟踪系统的机械动力学特性，包括运动延迟、加速度和速度限制，以量化卫星通过时的指向误差，并将这些效应纳入链路预算。

Result: 评估了不同低地球轨道（LEO）卫星轨迹和控制策略下波束方向性与指向容限之间的权衡。

Conclusion: 该论文为高频非地面网络（NTN）上行链路提供了设计指南，将硬件限制与通信性能联系起来。

Abstract: We analyze the open-loop mechanical tracking performance of a sub-Terahertz
(sub-THz) and Terahertz (THz) uplink communication system. These high-frequency
bands enable multi-gigabit links through large bandwidths and narrow beams, but
require precise pointing to overcome spreading loss. A tracking system can be
used to orient horn antennas toward mobile targets. We develop a mathematical
model that captures the mechanical dynamics of a real tracking system, which
includes motion latency and acceleration and velocity limits, to quantify
pointing errors during satellite passes and integrate these effects into the
link budget. We evaluate the trade-offs between beam directionality and
pointing tolerance across different Low Earth Orbit (LEO) satellite
trajectories and control strategies. The results link the hardware limitations
to the communications performance, providing design guidelines for
high-frequency Non-Terrestrial Network (NTN) uplink under practical mechanical
constraints.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [292] [Is Zadeh's Least-Entered Pivot Rule Exponential?](https://arxiv.org/abs/2510.16055)
*Norman Zadeh*

Main category: cs.DS

TL;DR: 论文反驳了关于最小进入规则指数复杂度的错误论证，指出其提供的反例存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 反驳2011年Friedmann和2019年Disser与Hopp关于最小进入规则指数复杂度的错误结论。

Method: 通过分析Disser等人提供的病理线性程序和MDP，发现其不满足概率约束且与MDP不匹配。

Result: 发现Disser等人提供的病理线性程序不可行且与MDP不匹配，未能提供有效反例。

Conclusion: 论文指出Disser、Friedmann和Hopp的论证存在多处缺陷，未能证明最小进入规则的最坏情况行为。

Abstract: In 2011, Friedmann [F 7] claimed to have proved that pathological linear
programs existed for which the Simplex method using Zadeh's least-entered rule
[Z 14] would take an exponential number of pivots. In 2019, Disser and Hopp [DH
5] argued that there were errors in Friedmann's 2011 construction. In 2020,
Disser, Friedmann, and Hopp [DFH 3,4] again contended that the least-entered
rule was exponential. We show that their arguments contain multiple flaws. In
other words, the worst-case behavior of the least-entered rule has not been
established. Neither [F 7] nor [DFH 3,4] provides pathological linear programs
that can be tested. Instead, the authors contend that their pathological linear
programs are of the form (P) as shown on page 12 of [DFH 3]. The authors
contend that the constraints of (P) ensure that the probability of entering a
vertex u is equal to the probability of exiting u. In fact, we note that the
authors' constraints (P) are flawed in at least three ways: a) they require the
probability of exiting u to exceed the probability of entering u, b) they
require the probability of exiting some nodes to exceed 1, and c) they overlook
flows from decision nodes to decision nodes. At my request, in August of 2025,
Disser, Friedmann, and Hopp provided me with their first ten purportedly
pathological LPs and the graph of their first purportedly pathological Markov
Decision Process (MDP1). It is shown that: a) their first two pathological LPs
are infeasible if the variables are supposed to be probabilities, as the
authors contend, and b) their first purportedly pathological LP does not match
up with their first purportedly pathological MDP. In other words, the authors
have not come close to providing counterexamples to the least-entered rule.

</details>


### [293] [Near-linear time subhypergraph counting in bounded degeneracy hypergraphs](https://arxiv.org/abs/2510.16330)
*Daniel Paul-Pena,C. Seshadhri*

Main category: cs.DS

TL;DR: 本文研究了超图中模式计数问题，提出了基于退化性定义的线性时间算法条件，并发现了一组障碍模式决定计数复杂性。


<details>
  <summary>Details</summary>
Motivation: 超图算法在理论和实践中受到越来越多的关注，但超图中模式计数的研究较少，尽管在网络科学和数据库算法中有许多应用。受图算法文献进展的启发，本文探讨了何时可以设计线性时间算法。

Method: 本文研究了具有有界退化性的输入超图G，并提出了一系列覆盖所有现有退化性概念的定义。对于每种定义，给出了模式H是否可以在线性或近线性时间内计数的精确刻画。

Result: 研究发现存在一组“障碍模式”，如果H不包含这些障碍，则可以精确计数H-子超图的数量，时间复杂度为O(n log n)；否则，在假设超图版本的细粒度复杂性猜想下，不存在o(n^{1+γ})时间算法。

Conclusion: 本文提出了一个关于超图模式计数的理论框架，通过定义超图退化性的一系列概念，精确刻画了哪些模式可以在线性或近线性时间内被计数。研究发现存在一组“障碍模式”，如果模式不包含这些障碍，则可以在O(n log n)时间内精确计数；否则，在假设超图版本的细粒度复杂性猜想下，不存在o(n^{1+γ})时间算法。

Abstract: Counting small patterns in a large dataset is a fundamental algorithmic task.
The most common version of this task is subgraph/homomorphism counting, wherein
we count the number of occurrences of a small pattern graph $H$ in an input
graph $G$. The study of this problem is a field in and of itself. Recently,
both in theory and practice, there has been an interest in \emph{hypergraph}
algorithms, where $G = (V,E)$ is a hypergraph. One can view $G$ as a set system
where hyperedges are subsets of the universe $V$.
  Counting patterns $H$ in hypergraphs is less studied, although there are many
applications in network science and database algorithms. Inspired by advances
in the graph literature, we study when linear time algorithms are possible.
  We focus on input hypergraphs $G$ that have bounded \emph{degeneracy}, a
well-studied concept for graph algorithms. We give a spectrum of definitions
for hypergraph degeneracy that cover all existing notions. For each such
definition, we give a precise characterization of the patterns $H$ that can be
counted in (near) linear time. Specifically, we discover a set of ``obstruction
patterns". If $H$ does not contain an obstruction, then the number of
$H$-subhypergraphs can be counted exactly in $O(n\log n)$ time (where $n$ is
the number of vertices in $G$). If $H$ contains an obstruction, then (assuming
hypergraph variants of fine-grained complexity conjectures), there is a
constant $\gamma > 0$, such that there is no $o(n^{1+\gamma})$ time algorithm
for counting $H$-subhypergraphs. These sets of obstructions can be defined for
all notions of hypergraph degeneracy.

</details>


### [294] [A (Very) Nearly Optimal Sketch for $k$-Edge Connectivity Certificates](https://arxiv.org/abs/2510.16336)
*Pachara Sawettamalya,Huacheng Yu*

Main category: cs.DS

TL;DR: 提出了一种改进的动态图流$k$-连通性证书算法，空间复杂度接近已知下界。


<details>
  <summary>Details</summary>
Motivation: 改进现有算法在空间复杂度上的不足，尤其是对于$k$为亚线性值的情况。

Method: 提出了一种简单的算法，用于在动态图流中计算$k$-连通性证书。

Result: 算法在空间使用上接近已知下界，特别是在$k = \Omega(\log n \log \log n)$时完全匹配。

Conclusion: 该算法在动态图流中计算$k$-连通性证书的空间复杂度为$O(n \log^2 n \cdot \max\{k, \log n \log k\})$，显著改进了先前的工作，并在$k = \Omega(\log n \log \log n)$时完全匹配已知下界。

Abstract: In this note, we present a simple algorithm for computing a
\emph{$k$-connectivity certificate} in dynamic graph streams. Our algorithm
uses $O(n \log^2 n \cdot \max\{k, \log n \log k\})$ bits of space which
improves upon the $O(kn \log^3 n)$-space algorithm of Ahn, Guha, and McGregor
(SODA'12). For the values of $k$ that are truly sublinear, our space usage
\emph{very nearly} matches the known lower bound $\Omega(n \log^2 n \cdot
\max\{k, \log n\})$ established by Nelson and Yu (SODA'19; implicit) and
Robinson (DISC'24). In particular, our algorithm fully settles the space
complexity at $\Theta(kn \log^2{n})$ for $k = \Omega(\log n \log \log n)$, and
bridges the gap down to only a doubly-logarithmic factor of $O(\log \log n)$
for a smaller range of $k = o(\log n \log \log n)$.

</details>


### [295] [Truly Subquadratic Time Algorithms for Diameter and Related Problems in Graphs of Bounded VC-dimension](https://arxiv.org/abs/2510.16346)
*Timothy M. Chan,Hsien-Chih Chang,Jie Gao,Sándor Kisfaludi-Bak,Hung Le,Da Wei Zheng*

Main category: cs.DS

TL;DR: 本文提出了一种通用框架，首次实现了单位圆盘图直径的亚二次时间计算，并扩展到其他图族和距离问题，显著提升了算法效率。


<details>
  <summary>Details</summary>
Motivation: 解决单位圆盘图直径计算中的亚二次时间算法问题，并探索适用于不同图族和距离问题的通用方法。

Method: 利用低直径分解的基本形式，结合有限VC维度的集合系统和新的几何数据结构思想，构建了一个通用框架。

Result: 1. 对于具有常数VC维度的稀疏无权图，提出了一个$	ilde{O}(mn^{1-1/(2d)})$时间算法；2. 对于轴对齐正方形交集图，提出了一个$	ilde{O}(n^{2-1/12})$时间算法；3. 首次为其他距离相关问题（如所有顶点离心率、Wiener指数和精确距离预言机）提供了亚二次时间算法。

Conclusion: 本文提出了一种通用的计算框架，能够在多种图族和距离问题上实现亚二次时间算法，突破了以往依赖子线性分隔器的方法，并应用于多个具体问题中，显著提升了计算效率。

Abstract: We give the first truly subquadratic time algorithm, with $O^*(n^{2-1/18})$
running time, for computing the diameter of an $n$-vertex unit-disk graph,
resolving a central open problem in the literature. Our result is obtained as
an instance of a general framework, applicable to different graph families and
distance problems. Surprisingly, our framework completely bypasses sublinear
separators (or $r$-divisions) which were used in all previous algorithms.
Instead, we use low-diameter decompositions in their most elementary form. We
also exploit bounded VC-dimension of set systems associated with the input
graph, as well as new ideas on geometric data structures. Among the numerous
applications of the general framework, we obtain:
  1. An $\tilde{O}(mn^{1-1/(2d)})$ time algorithm for computing the diameter of
$m$-edge sparse unweighted graphs with constant VC-dimension $d$. The
previously known algorithms by Ducoffe, Habib, and Viennot [SODA 2019] and
Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] are truly subquadratic only when
the diameter is a small polynomial. Our result thus generalizes truly
subquadratic time algorithms known for planar and minor-free graphs (in fact,
it slightly improves the previous time bound for minor-free graphs).
  2. An $\tilde{O}(n^{2-1/12})$ time algorithm for computing the diameter of
intersection graphs of axis-aligned squares with arbitrary size. The best-known
algorithm by Duraj, Konieczny, and Pot\c{e}pa [ESA 2024] only works for unit
squares and is only truly subquadratic in the low-diameter regime.
  3. The first algorithms with truly subquadratic complexity for other
distance-related problems, including all-vertex eccentricities, Wiener index,
and exact distance oracles. (... truncated to meet the arXiv abstract
requirement.)

</details>


### [296] [Tight Pair Query Lower Bounds for Matching and Earth Mover's Distance](https://arxiv.org/abs/2510.16351)
*Amir Azarmehr,Soheil Behnezhad,Mohammad Roghani,Aviad Rubinstein*

Main category: cs.DS

TL;DR: 本文填补了邻接矩阵查询在估计图最大匹配大小时的理论空白，证明了[BKS'23]算法的最优性。


<details>
  <summary>Details</summary>
Motivation: 研究邻接矩阵查询在估计图的最大匹配大小时所需的查询次数，填补现有理论中的空白。

Method: 通过理论分析，本文提出了一个新的下界，证明了[BKS'23]算法的查询复杂度是最优的。

Result: 证明了对于任何固定的δ>0，存在固定的ε>0，使得估计值在真实值的εn范围内需要Ω(n^{2−δ})次邻接矩阵查询。

Conclusion: 本文证明了在估计图的最大匹配大小时，使用邻接矩阵查询的算法需要Ω(n^{2−δ})次查询，这一结果填补了现有理论中的空白。

Abstract: How many adjacency matrix queries (also known as pair queries) are required
to estimate the size of a maximum matching in an $n$-vertex graph $G$? We study
this fundamental question in this paper.
  On the upper bound side, an algorithm of Bhattacharya, Kiss, and Saranurak
[FOCS'23] gives an estimate that is within $\epsilon n$ of the right bound with
$n^{2-\Omega_\epsilon(1)}$ queries, which is subquadratic in $n$ (and thus
sublinear in the matrix size) for any fixed $\epsilon > 0$. On the lower bound
side, while there has been a lot of progress in the adjacency list model, no
non-trivial lower bound has been established for algorithms with adjacency
matrix query access. In particular, the only known lower bound is a folklore
bound of $\Omega(n)$, leaving a huge gap.
  In this paper, we present the first superlinear in $n$ lower bound for this
problem. In fact, we close the gap mentioned above entirely by showing that the
algorithm of [BKS'23] is optimal. Formally, we prove that for any fixed $\delta
> 0$, there is a fixed $\epsilon > 0$ such that an estimate that is within
$\epsilon n$ of the true bound requires $\Omega(n^{2-\delta})$ adjacency matrix
queries.
  Our lower bound also has strong implications for estimating the earth mover's
distance between distributions. For this problem, Beretta and Rubinstein
[STOC'24] gave an $n^{2-\Omega_\epsilon(1)}$ time algorithm that obtains an
additive $\epsilon$-approximation and works for any distance function. Whether
this can be improved generally, or even for metric spaces, had remained open.
Our lower bound rules out the possibility of any improvements over this bound,
even under the strong assumption that the underlying distances are in a (1,
2)-metric.

</details>


### [297] [Online computation of normalized substring complexity](https://arxiv.org/abs/2510.16454)
*Gregory Kucherov,Yakov Nekrich*

Main category: cs.DS

TL;DR: 本文提出了两种在线计算归一化子串复杂度δ的算法，填补了该领域在线解决方案的空白。


<details>
  <summary>Details</summary>
Motivation: 归一化子串复杂度δ与流行的字符串压缩算法有密切关系，但目前缺乏高效的在线计算方法。

Method: 提出了两种算法：一种在O(log n)摊销时间内处理每个字符，另一种在O(log³ n)最坏情况下处理每个字符。

Result: 首次实现了多项式时间复杂度的在线解决方案。

Conclusion: 本文提出了两种在线计算归一化子串复杂度δ的算法，填补了该领域在线解决方案的空白。

Abstract: The normalized substring complexity $\delta$ of a string is defined as
$\max_k \{c[k]/k\}$, where $c[k]$ is the number of \textit{distinct} substrings
of length $k$. This simply defined measure has recently attracted attention due
to its established relationship to popular string compression algorithms. We
consider the problem of computing $\delta$ online, when the string is provided
from a stream. We present two algorithms solving the problem: one working in
$O(\log n)$ amortized time per character, and the other in $O(\log^3 n)$
worst-case time per character. To our knowledge, this is the first polylog-time
online solution to this problem.

</details>


### [298] [Trading Prophets with Initial Capital](https://arxiv.org/abs/2510.16516)
*Yossi Azar,Niv Buchbinder,Roie Levin,Or Vardi*

Main category: cs.DS

TL;DR: 初始资本使交易者能与先知竞争，竞争比为3且最优。研究还扩展至包含交易成本的现实模型。


<details>
  <summary>Details</summary>
Motivation: 探索在初始资本下如何绕过交易先知问题中的不可能性结果，并研究更现实的交易成本模型。

Method: 研究了在给定初始资本的情况下，交易者如何通过决策买卖股票来竞争。分析了包含乘性和加性交易成本的更复杂模型。

Result: 实现了与先知相比的竞争比为3，并证明这一比例是最优的。在包含交易成本的模型中，进一步验证了初始资本的有效性。

Conclusion: 初始资本可以绕过不可能性结果，实现与知晓未来价格的先知相比的竞争比为3，且这一竞争比是最优的。此外，研究还探讨了包含交易成本的更现实模型。

Abstract: Correa et al. [EC' 2023] introduced the following trading prophets problem. A
trader observes a sequence of stochastic prices for a stock, each drawn from a
known distribution, and at each time must decide whether to buy or sell.
Unfortunately, they observed that in this setting it is impossible to compete
with a prophet who knows all future stock prices.
  In this paper, we explore the trading prophets problem when we are given
initial capital with which to start trading. We show that initial capital is
enough to bypass the impossibility result and obtain a competitive ratio of $3$
with respect to a prophet who knows all future prices (and who also starts with
capital), and we show that this competitive ratio is best possible. We further
study a more realistic model in which the trader must pay multiplicative and/or
additive transaction costs for trading which model dynamics such as bid-ask
spreads and broker fees.

</details>


### [299] [Robust Dynamic Staffing with Predictions](https://arxiv.org/abs/2510.16663)
*Yiding Feng,Vahideh Manshadi,Rad Niazadeh,Saba Neyshabouri*

Main category: cs.DS

TL;DR: 论文提出了一种极小极大最优的在线算法，解决动态人员配置问题，并在多种扩展场景中保持性能，实验验证其优于贝叶斯启发式方法。


<details>
  <summary>Details</summary>
Motivation: 该研究动机源于最后一英里配送运营中的动态人员配置问题，其中公司需要在工人可用性下降和预测准确性提高之间权衡。为了避免贝叶斯模型的局限性，论文研究了在对抗性预测下的这一问题。

Method: 论文通过多项式大小的线性规划描述了一个受限对手的极小极大成本，并展示了如何在一般情况下模拟这一解决方案。此外，论文还扩展了框架，处理多需求、雇佣决策的昂贵逆转以及不一致的预测区间，并引入了一种实用的“重新求解”算法变体。

Result: 主要成果是一个简单且计算高效的在线算法，该算法在极小极大意义下是最优的。此外，论文还扩展了框架以处理多种需求和其他复杂情况，并引入了一种实用的算法变体。数值实验验证了算法的优越性。

Conclusion: 该论文提出了一种简单且计算高效的在线算法，该算法在极小极大意义下是最优的，能够有效解决动态人员配置问题，并在多种扩展场景中保持性能。数值实验表明，该算法在成本和速度上均优于贝叶斯启发式方法，并与贝叶斯最优策略相当。

Abstract: We consider a natural dynamic staffing problem in which a decision-maker
sequentially hires workers over a finite horizon to meet an unknown demand
revealed at the end. Predictions about demand arrive over time and become
increasingly accurate, while worker availability decreases. This creates a
fundamental trade-off between hiring early to avoid understaffing (when workers
are more available but forecasts are less reliable) and hiring late to avoid
overstaffing (when forecasts are more accurate but availability is lower). This
problem is motivated by last-mile delivery operations, where companies such as
Amazon rely on gig-economy workers whose availability declines closer to the
operating day.
  To address practical limitations of Bayesian models (in particular, to remain
agnostic to the underlying forecasting method), we study this problem under
adversarial predictions. In this model, sequential predictions are
adversarially chosen uncertainty intervals that (approximately) contain the
true demand. The objective is to minimize worst-case staffing imbalance cost.
Our main result is a simple and computationally efficient online algorithm that
is minimax optimal. We first characterize the minimax cost against a restricted
adversary via a polynomial-size linear program, then show how to emulate this
solution in the general case. While our base model focuses on a single demand,
we extend the framework to multiple demands (with egalitarian/utilitarian
objectives), to settings with costly reversals of hiring decisions, and to
inconsistent prediction intervals. We also introduce a practical "re-solving"
variant of our algorithm, which we prove is also minimax optimal. Finally we
conduct numerical experiments showing that our algorithms outperform Bayesian
heuristics in both cost and speed, and are competitive with (approximate or
exact) Bayesian-optimal policies when those can be computed.

</details>


### [300] [An Exact Algorithm for the Unanimous Vote Problem](https://arxiv.org/abs/2510.16678)
*Feyza Duman Keles,Lisa Hellerstein,Kunal Marwaha,Christopher Musco,Xinchen Yang*

Main category: cs.DS

TL;DR: 本文解决了Unanimous Vote问题的NP难问题，提出了一个O(n log n)时间算法，并证明了其与自适应策略的适应性差距为1.2±o(1)。


<details>
  <summary>Details</summary>
Motivation: 解决Gkenosis等人提出的Unanimous Vote问题是否NP难的问题，并探索其在Stochastic Boolean Function Evaluation问题中的位置。

Method: 使用简单的交换参数证明最优排序必须接近自然贪婪算法生成的排序，并开发了一个精确的O(n log n)时间算法。

Result: 提出了一个精确的O(n log n)时间算法，证明了Unanimous Vote问题可以在多项式时间内解决，并且展示了最优排序与最佳自适应策略之间的适应性差距为1.2±o(1)。

Conclusion: 本文证明了Unanimous Vote问题可以在多项式时间内解决，通过提出一个精确的O(n log n)时间算法，并展示了该问题在Stochastic Boolean Function Evaluation问题中的特殊性。此外，还证明了最优排序与最佳自适应策略之间的紧密适应性差距为1.2±o(1)。

Abstract: Consider $n$ independent, biased coins, each with a known probability of
heads. Presented with an ordering of these coins, flip (i.e., toss) each coin
once, in that order, until we have observed both a *head* and a *tail*, or
flipped all coins. The Unanimous Vote problem asks us to find the ordering that
minimizes the expected number of flips. Gkenosis et al. [arXiv:1806.10660] gave
a polynomial-time $\phi$-approximation algorithm for this problem, where $\phi
\approx 1.618$ is the golden ratio. They left open whether the problem was
NP-hard. We answer this question by giving an exact algorithm that runs in time
$O(n \log n)$. The Unanimous Vote problem is an instance of the more general
Stochastic Boolean Function Evaluation problem: it thus becomes one of the only
such problems known to be solvable in polynomial time. Our proof uses simple
interchange arguments to show that the optimal ordering must be close to the
ordering produced by a natural greedy algorithm. Beyond our main result, we
compare the optimal ordering with the best adaptive strategy, proving a tight
adaptivity gap of $1.2\pm o(1)$ for the Unanimous Vote problem.

</details>


### [301] [All-Pairs Minimum Cut using $\tilde{O}(n^{7/4})$ Cut Queries](https://arxiv.org/abs/2510.16741)
*Yotam Kenneth-Mordoch,Robert Krauthgamer*

Main category: cs.DS

TL;DR: 首次在割查询模型中提出全对最小割的非平凡算法，通过构建Gomory-Hu树实现高效查询。


<details>
  <summary>Details</summary>
Motivation: 解决在割查询模型中全对最小割问题的非平凡算法缺失问题。

Method: 使用随机算法构建Gomory-Hu树，并在割查询模型中实现了$	ilde{O}(n^{7/4})$的查询复杂度。

Result: 提出的算法在割查询模型中成功构建了Gomory-Hu树，解决了全对最小割问题，查询复杂度为$	ilde{O}(n^{7/4})$。

Conclusion: 本文提出了一种在割查询模型中的非平凡算法，用于解决全对最小割问题，通过构建Gomory-Hu树，实现了高效的割查询。

Abstract: We present the first non-trivial algorithm for the all-pairs minimum cut
problem in the cut-query model. Given cut-query access to an unweighted graph
$G=(V,E)$ with $n$ vertices, our randomized algorithm constructs a Gomory-Hu
tree of $G$, and thus solves the all-pairs minimum cut problem, using
$\tilde{O}(n^{7/4})$ cut queries.

</details>


### [302] [Combinatorial Maximum Flow via Weighted Push-Relabel on Shortcut Graphs](https://arxiv.org/abs/2510.17182)
*Aaron Bernstein,Joakim Blikstad,Jason Li,Thatchaphol Saranurak,Ta-Wei Tu*

Main category: cs.DS

TL;DR: 提出了一种简化且高效的组合算法，用于计算有向图中的最大流，并首次实现了确定性近线性时间算法。


<details>
  <summary>Details</summary>
Motivation: 旨在简化现有算法并提高计算效率，特别是在稠密图中，同时探索确定性算法的可能性。

Method: 采用组合算法，结合切割匹配游戏（cut-matching game）的随机化组件，并通过去随机化技术处理顶点容量最大流问题。

Result: 实现了$\tilde{O}(n^{2}\log U)$时间复杂度的算法，简化了现有方法，并首次提出了确定性$\tilde{O}(n^2)$时间算法。

Conclusion: 本研究提出了一种在稠密图中近乎最优的组合算法，用于计算具有特定边容量的有向图中的精确最大流，显著简化了现有算法，并提供了完整的C++实现。此外，通过去随机化技术，首次实现了确定性近线性时间算法。

Abstract: We give a combinatorial algorithm for computing exact maximum flows in
directed graphs with $n$ vertices and edge capacities from $\{1,\dots,U\}$ in
$\tilde{O}(n^{2}\log U)$ time, which is near-optimal on dense graphs. This
shaves an $n^{o(1)}$ factor from the recent result of
[Bernstein-Blikstad-Saranurak-Tu FOCS'24] and, more importantly, greatly
simplifies their algorithm. We believe that ours is by a significant margin the
simplest of all algorithms that go beyond $\tilde{O}(m\sqrt{n})$ time in
general graphs. To highlight this relative simplicity, we provide a full
implementation of the algorithm in C++.
  The only randomized component of our work is the cut-matching game. Via
existing tools, we show how to derandomize it for vertex-capacitated max flow
and obtain a deterministic $\tilde{O}(n^2)$ time algorithm. This marks the
first deterministic near-linear time algorithm for this problem (or even for
the special case of bipartite matching) in any density regime.

</details>


### [303] [Finding 4-Additive Spanners: Faster, Stronger, and Simpler](https://arxiv.org/abs/2510.17262)
*Chuhan Qi*

Main category: cs.DS

TL;DR: 本文提出了一种确定性算法，用于构建4-加法性生成子图，其边缘界限与已知最佳结果一致，同时显著提高了运行时间，并且在概念上更简单、更易于实现和分析。


<details>
  <summary>Details</summary>
Motivation: 加法性生成子图在网络设计、图稀疏化和距离近似中有广泛应用。本文旨在改进现有的4-加法性生成子图构造方法，提供更高效且确定性更强的算法。

Method: 本文提出了一种确定性算法，用于构建4-加法性生成子图，其边缘界限为$\tilde{O}(n^{7/5})$，运行时间为$\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$，优于之前的随机化构造。

Result: 新算法在边缘界限上匹配已知最佳结果，同时显著提高了运行时间，并且在概念上更简单、更易于实现和分析。

Conclusion: 本文提出了一种新的确定性算法，用于构建4-加法性生成子图，其边缘界限与已知最佳结果一致，同时显著提高了运行时间，并且在概念上更简单、更易于实现和分析。

Abstract: Additive spanners are fundamental graph structures with wide applications in
network design, graph sparsification, and distance approximation. In
particular, a $4$-additive spanner is a subgraph that preserves all pairwise
distances up to an additive error of $4$. In this paper, we present a new
deterministic algorithm for constructing $4$-additive spanners that matches the
best known edge bound of $\tilde{O}(n^{7/5})$ (up to polylogarithmic factors),
while improving the running time to $\tilde{O}(\min\{mn^{3/5}, n^{11/5}\})$,
compared to the previous $\tilde{O}(mn^{3/5})$ randomized construction. Our
algorithm is not only faster in the dense regime but also fully deterministic,
conceptually simpler, and easier to implement and analyze.

</details>


### [304] [On Algorithmic Meta-Theorems for Solution Discovery: Tractability and Barriers](https://arxiv.org/abs/2510.17344)
*Nicolas Bousquet,Amer E. Mouawad,Stephanie Maaz,Naomi Nishimura,Sebastian Siebertz*

Main category: cs.DS

TL;DR: 本文研究了MSO和FO可定义的图问题的解决方案发现，提出了算法和硬度结果，补充了固定参数可处理性元定理研究。


<details>
  <summary>Details</summary>
Motivation: 研究解决方案发现问题，即是否可以通过有限的转换步骤将初始配置转换为可行解决方案，特别是针对MSO和FO可定义的图问题。

Method: 研究了使用有限数量的转换步骤将不可行的初始配置转换为可行解决方案的问题，重点关注参数化复杂性和不涉及转换预算$b$的结构图参数。

Result: 证明了MSO$_2$-Discovery在树宽参数化下属于XP，MSO$_1$-Discovery在邻域多样性参数化下是固定参数可处理的；同时，FO-Discovery在星形调制器、路径调制器和双覆盖数参数化下是W[1]-难的，MSO$_1$-Discovery在带宽参数化下也是W[1]-难的。

Conclusion: 本文为MSO和FO可定义的图问题及结构参数大于cliquewidth的解决方案发现问题提供了近完整的（固定参数可处理性）元定理研究。

Abstract: Solution discovery asks whether a given (infeasible) starting configuration
to a problem can be transformed into a feasible solution using a limited number
of transformation steps. This paper investigates meta-theorems for solution
discovery for graph problems definable in monadic second-order logic (MSO$_1$
and MSO$_2$) and first-order logic (FO) where the transformation step is to
slide a token to an adjacent vertex, focusing on parameterized complexity and
structural graph parameters that do not involve the transformation budget $b$.
We present both positive and negative results. On the algorithmic side, we
prove that MSO$_2$-Discovery is in XP when parameterized by treewidth and that
MSO$_1$-Discovery is fixed-parameter tractable when parameterized by
neighborhood diversity. On the hardness side, we establish that FO-Discovery is
W[1]-hard when parameterized by modulator to stars, modulator to paths, as well
as twin cover, numbers. Additionally, we prove that MSO$_1$-Discovery is
W[1]-hard when parameterized by bandwidth. These results complement the
straightforward observation that solution discovery for the studied problems is
fixed-parameter tractable when the budget $b$ is included in the parameter (in
particular, parameterized by cliquewidth$+b$, where the cliquewidth of a graph
is at most any of the studied parameters), and provide a near-complete
(fixed-parameter tractability) meta-theorems investigation for solution
discovery problems for MSO- and FO-definable graph problems and structural
parameters larger than cliquewidth.

</details>


### [305] [Approximating Asymmetric A Priori TSP beyond the Adaptivity Gap](https://arxiv.org/abs/2510.17595)
*Manuel Christalla,Luise Puhlmann,Vera Traub*

Main category: cs.DS

TL;DR: 本文研究了非对称先验TSP的自适应间隙和近似算法，证明了多项式下界并提出了拟多项式时间内的O(log n)近似算法。


<details>
  <summary>Details</summary>
Motivation: 研究非对称先验TSP（顶点具有独立激活概率）的近似算法，旨在计算一个路径，使得在随机采样的激活顶点集上短截后的期望长度最小化。

Method: 通过一系列多项式时间归约，首先归约到一个新的广义非对称旅行商问题（Hop-ATSP），然后利用有向低直径分解获得结构化实例，进一步归约到一个覆盖问题，最终将非对称先验TSP归约为在无环有向图中寻找路径的问题，并针对该问题提出了一个拟多项式时间内O(log n)近似算法。

Result: 证明了自适应间隙存在多项式下界，并提出了一个拟多项式时间内O(log n)近似算法。

Conclusion: 本文证明了非对称先验TSP的自适应间隙存在多项式下界，并提出了一种具有拟多项式运行时间的随机算法，能够实现对数多项式近似比，从而低于自适应间隙。

Abstract: In Asymmetric A Priori TSP (with independent activation probabilities) we are
given an instance of the Asymmetric Traveling Salesman Problem together with an
activation probability for each vertex. The task is to compute a tour that
minimizes the expected length after short-cutting to the randomly sampled set
of active vertices.
  We prove a polynomial lower bound on the adaptivity gap for Asymmetric A
Priori TSP. Moreover, we show that a poly-logarithmic approximation ratio, and
hence an approximation ratio below the adaptivity gap, can be achieved by a
randomized algorithm with quasi-polynomial running time.
  To achieve this, we provide a series of polynomial-time reductions. First we
reduce to a novel generalization of the Asymmetric Traveling Salesman Problem,
called Hop-ATSP. Next, we use directed low-diameter decompositions to obtain
structured instances, for which we then provide a reduction to a covering
problem. Eventually, we obtain a polynomial-time reduction of Asymmetric A
Priori TSP to a problem of finding a path in an acyclic digraph minimizing a
particular objective function, for which we give an O(log n)-approximation
algorithm in quasi-polynomial time.

</details>


### [306] [Near-Optimal Property Testers for Pattern Matching](https://arxiv.org/abs/2510.17645)
*Ce Jin,Tomasz Kociumaka*

Main category: cs.DS

TL;DR: 本文提出了最优的自适应和非自适应属性测试器，用于精确模式匹配，并在不同参数范围内展示了其复杂度优势。


<details>
  <summary>Details</summary>
Motivation: 解决经典精确模式匹配问题中的属性测试需求，区分模式是否作为子串出现或与所有子串的汉明距离超过阈值。

Method: 本文设计了自适应和非自适应的属性测试器，通过覆盖所有参数范围，并利用无条件下限证明其复杂度最优。

Result: 在参数范围内，非自适应属性测试器的时间复杂度为Õ(n/√k)，且自适应算法的查询复杂度下限匹配该结果。在n=m+o(m)范围内，自适应与非自适应算法展现出时间与查询复杂度的显著差异。

Conclusion: 本文提出了自适应和非自适应的属性测试器，用于解决精确模式匹配问题，并证明了其算法在时间和查询复杂度上的最优性。

Abstract: The classic exact pattern matching problem, given two strings -- a pattern
$P$ of length $m$ and a text $T$ of length $n$ -- asks whether $P$ occurs as a
substring of $T$. A property tester for the problem needs to distinguish (with
high probability) the following two cases for some threshold $k$: the YES case,
where $P$ occurs as a substring of $T$, and the NO case, where $P$ has Hamming
distance greater than $k$ from every substring of $T$, that is, $P$ has no
$k$-mismatch occurrence in $T$.
  In this work, we provide adaptive and non-adaptive property testers for the
exact pattern matching problem, jointly covering the whole spectrum of
parameters. We further establish unconditional lower bounds demonstrating that
the time and query complexities of our algorithms are optimal, up to
$\mathrm{polylog}\, n$ factors hidden within the $\tilde O(\cdot)$ notation
below.
  In the most studied regime of $n=m+\Theta(m)$, our non-adaptive property
tester has the time complexity of $\tilde O(n/\sqrt{k})$, and a matching lower
bound remains valid for the query complexity of adaptive algorithms. This
improves both upon a folklore solution that attains the optimal query
complexity but requires $\Omega(n)$ time, and upon the only previously known
sublinear-time property tester, by Chan, Golan, Kociumaka, Kopelowitz, and
Porat [STOC 2020], with time complexity $\tilde O(n/\sqrt[3]{k})$. The
aforementioned results remain valid for $n=m+\Omega(m)$, where our optimal
running time $\tilde O(\sqrt{nm/k}+n/k)$ improves upon the previously best time
complexity of $\tilde O(\sqrt[3]{n^2m/k}+n/k)$. In the regime of $n=m+o(m)$,
which has not been targeted in any previous work, we establish a surprising
separation between adaptive and non-adaptive algorithms, whose optimal time and
query complexities are $\tilde O(\sqrt{(n-m+1)m/k}+n/k)$ and $\tilde
O(\min(n\sqrt{n-m+1}/k,\sqrt{nm/k}+n/k))$, respectively.

</details>


### [307] [The Marked Edge Walk: A Novel MCMC Algorithm for Sampling of Graph Partitions](https://arxiv.org/abs/2510.17714)
*Atticus McWhorter,Daryl DeFord*

Main category: cs.DS

TL;DR: MEW是一种新型MCMC算法，通过标记边行走实现对图分区的灵活采样，突破了现有方法局限于生成树相关分布的约束。


<details>
  <summary>Details</summary>
Motivation: 现有的MCMC方法（如RevReCom和MFR）局限于生成树相关的分布采样，限制了其在更广泛图分区问题中的应用。

Method: MEW是一种新型的MCMC算法，基于生成树和标记边的空间进行操作，通过Metropolis-Hastings算法计算转移概率。

Result: 在真实世界双图上的实验表明，MEW能够在与生成树无关的目标分布下实现收敛。

Conclusion: MEW算法通过引入标记边行走（MEW），提供了一种灵活且可调的图分区采样方法，显著提升了MCMC在非生成树相关分布下的应用能力。

Abstract: Novel Markov Chain Monte Carlo (MCMC) methods have enabled the generation of
large ensembles of redistricting plans through graph partitioning. However,
existing algorithms such as Reversible Recombination (RevReCom) and
Metropolized Forest Recombination (MFR) are constrained to sampling from
distributions related to spanning trees. We introduce the marked edge walk
(MEW), a novel MCMC algorithm for sampling from the space of graph partitions
under a tunable distribution. The walk operates on the space of spanning trees
with marked edges, allowing for calculable transition probabilities for use in
the Metropolis-Hastings algorithm. Empirical results on real-world dual graphs
show convergence under target distributions unrelated to spanning trees. For
this reason, MEW represents an advancement in flexible ensemble generation.

</details>


### [308] [Generalized Flow in Nearly-linear Time on Moderately Dense Graphs](https://arxiv.org/abs/2510.17740)
*Shunhua Jiang,Michael Kapralov,Lawrence Li,Aaron Sidford*

Main category: cs.DS

TL;DR: 本文提出了一种更高效的随机化算法，用于解决广义流问题，时间复杂度优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有的广义流问题算法时间复杂度较高，需要更高效的解决方案。

Method: 通过提供新的动态数据结构和关于广义流矩阵的谱结果，并将其应用于[BLLSSSW21]的内点法框架中。

Result: 提出的算法在时间复杂度上优于现有技术，显著提升了计算效率。

Conclusion: 本文提出了一种随机化算法，用于解决广义最大流和广义最小成本流问题，其时间复杂度为$\tilde{O}( (m + n^{1.5}) \cdot \mathrm{polylog}(\frac{W}{\delta}))$，优于现有技术。

Abstract: In this paper we consider generalized flow problems where there is an
$m$-edge $n$-node directed graph $G = (V,E)$ and each edge $e \in E$ has a loss
factor $\gamma_e >0$ governing whether the flow is increased or decreased as it
crosses edge $e$. We provide a randomized $\tilde{O}( (m + n^{1.5}) \cdot
\mathrm{polylog}(\frac{W}{\delta}))$ time algorithm for solving the generalized
maximum flow and generalized minimum cost flow problems in this setting where
$\delta$ is the target accuracy and $W$ is the maximum of all costs,
capacities, and loss factors and their inverses. This improves upon the
previous state-of-the-art $\tilde{O}(m \sqrt{n} \cdot \log^2(\frac{W}{\delta})
)$ time algorithm, obtained by combining the algorithm of [Daitch-Spielman,
2008] with techniques from [Lee-Sidford, 2014]. To obtain this result we
provide new dynamic data structures and spectral results regarding the matrices
associated to generalized flows and apply them through the interior point
method framework of [Brand-Lee-Liu-Saranurak-Sidford-Song-Wang, 2021].

</details>


### [309] [Pattern Matching under Weighted Edit Distance](https://arxiv.org/abs/2510.17752)
*Panagiotis Charalampopoulos,Tomasz Kociumaka,Philip Wellnitz*

Main category: cs.DS

TL;DR: 本文提出了三种针对加权编辑距离模式匹配的算法，优化了不同权重情况下的时间复杂度，特别在整数度量权重情况下接近未加权变体的最优解。


<details>
  <summary>Details</summary>
Motivation: PMWED比未加权的变体（PMED）更能准确反映现实应用，因为其考虑了不同编辑操作的实际成本。本文旨在解决PMWED的计算效率问题。

Method: （a）提出了一个概念简单的算法，时间复杂度为$\tilde{O}(nk)$；（b）在权重函数为整数度量且取值范围在$0$到$W$之间的假设下，提出了一个更复杂的算法，时间复杂度为$\tilde{O}(n+k^{3.5} \cdot W^4\cdot n/m)$；（c）针对任意权重情况，提出了时间复杂度为$\tilde{O}(n+k^4 \cdot n/m)$的算法。

Result: 在整数度量权重情况下，算法的时间复杂度接近PMED的最优解（当$W=1$时）。

Conclusion: 本文提出了三种针对加权编辑距离模式匹配（PMWED）的算法，分别在一般权重、整数度量权重和任意权重情况下提供了不同的时间复杂度优化。

Abstract: In Pattern Matching with Weighted Edits (PMWED), we are given a pattern $P$
of length $m$, a text $T$ of length $n$, a positive threshold $k$, and oracle
access to a weight function that specifies the costs of edits (depending on the
involved characters, and normalized so that the cost of each edit is at least
$1$). The goal is to compute the starting positions of all fragments of $T$
that can be obtained from $P$ with edits of total cost at most $k$. PMWED
captures typical real-world applications more accurately than its unweighted
variant (PMED), where all edits have unit costs.
  We obtain three main results:
  (a) a conceptually simple $\tilde{O}(nk)$-time algorithm for PMWED, very
different from that of Landau and Vishkin for PMED;
  (b) a significantly more complicated $\tilde{O}(n+k^{3.5} \cdot W^4\cdot
n/m)$-time algorithm for PMWED under the assumption that the weight function is
a metric with integer values between $0$ and $W$; and
  (c) an $\tilde{O}(n+k^4 \cdot n/m)$-time algorithm for PMWED for the case of
arbitrary weights.
  In the setting of metrics with small integer values, we nearly match the
state of the art for PMED where $W=1$.

</details>


### [310] [Dynamic Dyck and Tree Edit Distance: Decompositions and Reductions to String Edit Distance](https://arxiv.org/abs/2510.17799)
*Debarati Das,Jacob Gilbert,MohammadTaghi Hajiaghayi,Tomasz Kociumaka,Barna Saha*

Main category: cs.DS

TL;DR: 论文首次提出Dyck和树编辑距离的动态算法，通过归约和分解技术实现亚多项式更新时间，显著提升了近似比和效率。


<details>
  <summary>Details</summary>
Motivation: Dyck和树编辑距离问题在动态结构化数据（如LaTeX文档、JSON/XML文件和RNA二级结构）中自然出现，但此前缺乏高效的动态算法。论文旨在填补这一空白。

Method: 论文采用了一系列归约和分解技术，将Dyck和树编辑距离问题转化为可动态维护的字符串编辑距离问题。对于Dyck编辑距离，归约仅引入多对数级开销；对于树编辑距离，提出了一种新的静态归约，并扩展为动态版本。

Result: 论文实现了Dyck编辑距离的n^{o(1)}近似比和更新时间；对于树编辑距离，静态归约将近似比从n^{3/4}提升至Õ(√n)，动态版本则达到n^{1/2+o(1)}近似比和n^{o(1)}更新时间。此外，还提出了一种新的静态和动态分解方法。

Conclusion: 该论文提出了一种动态算法，首次实现了Dyck和树编辑距离的亚多项式更新时间。通过将Dyck和树编辑距离实例转换为可高效维护的字符串编辑距离实例，论文在近似比和更新时间上取得了显著突破。

Abstract: We present the first dynamic algorithms for Dyck and tree edit distances with
subpolynomial update times. Dyck edit distance measures how far a parenthesis
string is from a well-parenthesized expression, while tree edit distance
quantifies the minimum number of node insertions, deletions, and substitutions
required to transform one rooted, ordered, labeled tree into another. Despite
extensive study, no prior work has addressed efficient dynamic algorithms for
these problems, which naturally arise in evolving structured data such as LaTeX
documents, JSON or XML files, and RNA secondary structures.
  Our main contribution is a set of reductions and decompositions that
transform Dyck and tree edit distance instances into efficiently maintainable
string edit distance instances, which can be approximated within a $n^{o(1)}$
factor in $n^{o(1)}$ update time. For Dyck edit distance, our reduction incurs
only polylogarithmic overheads in approximation and update time, yielding an
$n^{o(1)}$-approximation with $n^{o(1)}$ updates. For tree edit distance, we
introduce a new static reduction that improves the best-known approximation
ratio from $n^{3/4}$ to $\tilde{O}(\sqrt{n})$ and removes the restriction to
constant-degree trees. Extending this reduction dynamically achieves
$n^{1/2+o(1)}$ approximation with $n^{o(1)}$ update time.
  A key component is a dynamic maintenance algorithm for history-independent
heavy-light decompositions, of independent interest. We also provide a novel
static and dynamic decomposition achieving an $O(k \log n)$-approximation when
the tree edit distance is at most $k$. Combined with the trivial bound $k \le
n$, this yields a dynamic deterministic $O(\sqrt{n \log n})$-approximation. In
the static setting, our algorithm runs in near-linear time; dynamically, it
requires only polylogarithmic updates, improving on prior linear-time static
$O(\sqrt{n})$-approximation.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [311] [Communication-Efficient and Memory-Aware Parallel Bootstrapping using MPI](https://arxiv.org/abs/2510.16284)
*Di Zhang*

Main category: cs.DC

TL;DR: 本文提出两种并行引导算法策略，通过减少通信和内存使用，显著提升大规模数据集上的计算效率。


<details>
  <summary>Details</summary>
Motivation: 引导方法在大型数据集或高重采样次数下计算成本过高，需要解决通信开销和内存限制的挑战。

Method: 采用消息传递接口（MPI）设计并行引导算法，提出两种策略：1) 本地统计聚合，通过传输充分统计量而非完整重采样数据集减少通信；2) 同步伪随机数生成，解决分布式重采样时数据集无法单进程存储的问题。

Result: 分析表明，所提方法显著减少了通信量和内存使用，实现了大规模系统上的可扩展并行引导。

Conclusion: 本文提出的并行引导算法通过减少通信量和内存使用，显著提高了大规模数据集上的计算效率，为大规模系统的可扩展并行引导提供了有效解决方案。

Abstract: Bootstrapping is a powerful statistical resampling technique for estimating
the sampling distribution of an estimator. However, its computational cost
becomes prohibitive for large datasets or a high number of resamples. This
paper presents a theoretical analysis and design of parallel bootstrapping
algorithms using the Message Passing Interface (MPI). We address two key
challenges: high communication overhead and memory constraints in distributed
environments. We propose two novel strategies: 1) Local Statistic Aggregation,
which drastically reduces communication by transmitting sufficient statistics
instead of full resampled datasets, and 2) Synchronized Pseudo-Random Number
Generation, which enables distributed resampling when the entire dataset cannot
be stored on a single process. We develop analytical models for communication
and computation complexity, comparing our methods against naive baseline
approaches. Our analysis demonstrates that the proposed methods offer
significant reductions in communication volume and memory usage, facilitating
scalable parallel bootstrapping on large-scale systems.

</details>


### [312] [MeCeFO: Enhancing LLM Training Robustness via Fault-Tolerant Optimization](https://arxiv.org/abs/2510.16415)
*Rizhen Hu,Yutong He,Ran Yan,Mou Sun,Binghang Yuan,Kun Yuan*

Main category: cs.DC

TL;DR: MeCeFO是一种高效的容错优化算法，通过Skip-connection、Recomputation和Low-rank梯度近似技术，在高故障率下保持训练稳健性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着分布式优化扩展到满足大型语言模型（LLM）训练的需求，硬件故障变得越来越不可忽视。现有的容错训练方法通常引入显著的计算或内存开销，需要额外资源。MeCeFO旨在解决这一挑战。

Method: MeCeFO 通过三种关键算法设计实现容错优化：(i) Skip-connection，在反向传播时丢弃多头注意力模块以节省内存和计算；(ii) Recomputation，减少前馈网络中的激活内存；(iii) Low-rank梯度近似，高效估计前馈网络权重矩阵的梯度。

Result: 理论上，MeCeFO与传统分布式训练的收敛速度一致，为O(1/√nT)。实证显示，MeCeFO在高故障率下保持稳健性能，吞吐量仅下降4.18%，比现有方法强5.0倍至6.7倍。

Conclusion: MeCeFO 是一种内存和计算效率高的容错优化算法，能够在高故障率下保持稳健性能，仅导致4.18%的吞吐量下降，表现出比现有方法5.0倍至6.7倍的更强韧性。

Abstract: As distributed optimization scales to meet the demands of Large Language
Model (LLM) training, hardware failures become increasingly non-negligible.
Existing fault-tolerant training methods often introduce significant
computational or memory overhead, demanding additional resources. To address
this challenge, we propose Memory- and Computation-efficient Fault-tolerant
Optimization (MeCeFO), a novel algorithm that ensures robust training with
minimal overhead. When a computing node fails, MeCeFO seamlessly transfers its
training task to a neighboring node while employing memory- and
computation-efficient algorithmic optimizations to minimize the extra workload
imposed on the neighboring node handling both tasks. MeCeFO leverages three key
algorithmic designs: (i) Skip-connection, which drops the multi-head attention
(MHA) module during backpropagation for memory- and computation-efficient
approximation; (ii) Recomputation, which reduces activation memory in
feedforward networks (FFNs); and (iii) Low-rank gradient approximation,
enabling efficient estimation of FFN weight matrix gradients. Theoretically,
MeCeFO matches the convergence rate of conventional distributed training, with
a rate of $\mathcal{O}(1/\sqrt{nT})$, where n is the data parallelism size and
T is the number of iterations. Empirically, MeCeFO maintains robust performance
under high failure rates, incurring only a 4.18% drop in throughput,
demonstrating 5.0$\times$ to 6.7$\times$ greater resilience than previous SOTA
approaches. Codes are available at https://github.com/pkumelon/MeCeFO.

</details>


### [313] [FourierCompress: Layer-Aware Spectral Activation Compression for Efficient and Accurate Collaborative LLM Inference](https://arxiv.org/abs/2510.16418)
*Jian Ma,Xinchen Lyu,Jun Jiang,Longhao Zou,Chenshan Ren,Qimei Cui,Xiaofeng Tao*

Main category: cs.DC

TL;DR: FourierCompress是一种基于频域稀疏性的LLM激活压缩框架，显著降低通信开销，保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决协作LLM推理中由高维中间激活传输引起的通信瓶颈问题，同时实现高压缩比、低重构误差和计算效率。

Method: FourierCompress将激活转换到频域，仅保留低频系数，并通过共轭对称性在服务器端重建信号，实现了高效的硬件加速。

Result: 在Llama 3和Qwen2.5模型上的实验表明，FourierCompress在激活大小上平均减少了7.6倍，准确率损失小于0.3%，压缩时间比Top-k快32倍以上。

Conclusion: FourierCompress通过利用LLM激活的频率域稀疏性，显著减少了通信开销，同时保持了接近无损的推理性能，为边缘设备上的LLM推理提供了高效、低延迟的解决方案。

Abstract: Collaborative large language model (LLM) inference enables real-time,
privacy-preserving AI services on resource-constrained edge devices by
partitioning computational workloads between client devices and edge servers.
However, this paradigm is severely hindered by communication bottlenecks caused
by the transmission of high-dimensional intermediate activations, exacerbated
by the autoregressive decoding structure of LLMs, where bandwidth consumption
scales linearly with output length. Existing activation compression methods
struggle to simultaneously achieve high compression ratios, low reconstruction
error, and computational efficiency. This paper proposes FourierCompress, a
novel, layer-aware activation compression framework that exploits the
frequency-domain sparsity of LLM activations. We rigorously demonstrate that
activations from the first Transformer layer exhibit strong smoothness and
energy concentration in the low-frequency domain, making them highly amenable
to near-lossless compression via the Fast Fourier Transform (FFT).
FourierCompress transforms activations into the frequency domain, retains only
a compact block of low-frequency coefficients, and reconstructs the signal at
the server using conjugate symmetry, enabling seamless hardware acceleration on
DSPs and FPGAs. Extensive experiments on Llama 3 and Qwen2.5 models across 10
commonsense reasoning datasets demonstrate that FourierCompress preserves
performance remarkably close to the uncompressed baseline, outperforming Top-k,
QR, and SVD. FourierCompress bridges the gap between communication efficiency
(an average 7.6x reduction in activation size), near-lossless inference (less
than 0.3% average accuracy loss), and significantly faster compression
(achieving over 32x reduction in compression time compared to Top-k via
hardware acceleration) for edge-device LLM inference.

</details>


### [314] [Edge-Based Speech Transcription and Synthesis for Kinyarwanda and Swahili Languages](https://arxiv.org/abs/2510.16497)
*Pacome Simon Mbonimpa,Diane Tuyizere,Azizuddin Ahmed Biyabani,Ozan K. Tonguz*

Main category: cs.DC

TL;DR: 论文提出了一种边缘-云并行的语音转录与合成框架，显著优化了Kinyarwanda和Swahili语言的处理效率，适用于基础设施有限的地区。


<details>
  <summary>Details</summary>
Motivation: 针对东非地区广泛使用的Kinyarwanda和Swahili语言缺乏强大语言处理工具的问题，尤其是在技术基础设施有限的背景下，该研究旨在通过边缘-云并行处理提升语音服务的可及性。

Method: 框架结合Whisper和SpeechT5预训练模型，采用级联机制在边缘设备和云端分配模型推理工作负载，优化了内存使用（SpeechT5压缩9.5%，Whisper压缩14%）和响应时间。

Result: 实验表明，在1.7 GHz CPU边缘设备和1 MB/s网络带宽下，系统能在1分钟内处理270字符的文本（STT和TTS）。实际调查数据验证了该架构在准确性和响应时间上的优异表现。

Conclusion: 该论文提出的边缘-云并行框架有效提升了Kinyarwanda和Swahili语言的语音转录与合成效率，显著降低了延迟和资源消耗，为技术基础设施有限的地区提供了可行的解决方案。

Abstract: This paper presents a novel framework for speech transcription and synthesis,
leveraging edge-cloud parallelism to enhance processing speed and accessibility
for Kinyarwanda and Swahili speakers. It addresses the scarcity of powerful
language processing tools for these widely spoken languages in East African
countries with limited technological infrastructure. The framework utilizes the
Whisper and SpeechT5 pre-trained models to enable speech-to-text (STT) and
text-to-speech (TTS) translation. The architecture uses a cascading mechanism
that distributes the model inference workload between the edge device and the
cloud, thereby reducing latency and resource usage, benefiting both ends. On
the edge device, our approach achieves a memory usage compression of 9.5% for
the SpeechT5 model and 14% for the Whisper model, with a maximum memory usage
of 149 MB. Experimental results indicate that on a 1.7 GHz CPU edge device with
a 1 MB/s network bandwidth, the system can process a 270-character text in less
than a minute for both speech-to-text and text-to-speech transcription. Using
real-world survey data from Kenya, it is shown that the cascaded edge-cloud
architecture proposed could easily serve as an excellent platform for STT and
TTS transcription with good accuracy and response time.

</details>


### [315] [Reimagining RDMA Through the Lens of ML](https://arxiv.org/abs/2510.16606)
*Ertza Warraich,Ali Imran,Annus Zulfiqar,Shay Vargaftik,Sonia Fahmy,Muhammad Shahbaz*

Main category: cs.DC

TL;DR: Celeris是一种针对ML优化的RDMA传输协议，通过移除重传和有序交付机制，显著降低了尾部延迟并提高了系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着分布式ML工作负载扩展到数千个GPU，集体通信中的尾部延迟成为主要瓶颈。传统RDMA设计（如RoCE、IRN、SRNIC）的严格可靠性和有序交付机制虽然适用于通用工作负载，但对于ML工作负载而言，这些机制引入了复杂性和延迟，导致系统性能下降。

Method: Celeris是一种针对ML优化的RDMA传输协议，移除了传统RDMA NIC的重传和有序交付机制，采用最佳努力传输策略，并利用软件级机制（如自适应超时和数据优先级）进行通信管理。

Result: 初步结果显示，Celeris将第99百分位延迟降低了2.3倍，BRAM使用减少了67%，NIC对故障的恢复能力提高了近一倍。

Conclusion: Celeris通过移除传统RDMA NIC的重传和有序交付机制，为ML工作负载提供了一种弹性、可扩展的传输方案，显著降低了尾部延迟并提高了系统性能。

Abstract: As distributed machine learning (ML) workloads scale to thousands of GPUs
connected by ultra-high-speed inter-connects, tail latency in collective
communication has emerged as a primary bottleneck. Prior RDMA designs, like
RoCE, IRN, and SRNIC, enforce strict reliability and in-order delivery, relying
on retransmissions and packet sequencing to ensure correctness. While effective
for general-purpose workloads, these mechanisms introduce complexity and
latency that scale poorly, where even rare packet losses or delays can
consistently degrade system performance. We introduce Celeris, a
domain-specific RDMA transport that revisits traditional reliability guarantees
based on ML's tolerance for lost or partial data. Celeris removes
retransmissions and in-order delivery from the RDMA NIC, enabling best-effort
transport that exploits the robustness of ML workloads. It retains congestion
control (e.g., DCQCN) and manages communication with software-level mechanisms
such as adaptive timeouts and data prioritization, while shifting loss recovery
to the ML pipeline (e.g., using the Hadamard Transform). Early results show
that Celeris reduces 99th-percentile latency by up to 2.3x, cuts BRAM usage by
67%, and nearly doubles NIC resilience to faults -- delivering a resilient,
scalable transport tailored for ML at cluster scale.

</details>


### [316] [Layout-Agnostic MPI Abstraction for Distributed Computing in Modern C++](https://arxiv.org/abs/2510.16890)
*Jiří Klepl,Martin Kruliš,Matyáš Brabec*

Main category: cs.DC

TL;DR: 本文提出了一种基于C++ Noarr库的MPI新抽象方法，解决了传统MPI接口缺乏现代语言特性的问题，并通过分布式GEMM核案例展示了其灵活性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统MPI接口基于纯C语言，缺乏现代语言（如C++）的类型检查和泛型设计支持，限制了分布式高性能计算的开发效率。

Method: 提出了一种基于C++ Noarr库的新抽象方法，遵循Noarr范式（布局和遍历的一流抽象），实现了布局无关的MPI应用设计。

Result: 通过分布式GEMM核案例证明，该抽象在性能上与最先进的MPI C++绑定相当，同时提供了更灵活的分布式应用设计。

Conclusion: 新抽象方法在保持高性能的同时，显著提升了MPI应用的开发灵活性和现代语言特性支持。

Abstract: Message Passing Interface (MPI) has been a well-established technology in the
domain of distributed high-performance computing for several decades. However,
one of its greatest drawbacks is a rather ancient pure-C interface. It lacks
many useful features of modern languages (namely C++), like basic type-checking
or support for generic code design. In this paper, we propose a novel
abstraction for MPI, which we implemented as an extension of the C++ Noarr
library. It follows Noarr paradigms (first-class layout and traversal
abstraction) and offers layout-agnostic design of MPI applications. We also
implemented a layout-agnostic distributed GEMM kernel as a case study to
demonstrate the usability and syntax of the proposed abstraction. We show that
the abstraction achieves performance comparable to the state-of-the-art MPI C++
bindings while allowing for a more flexible design of distributed applications.

</details>


### [317] [FTI-TMR: A Fault Tolerance and Isolation Algorithm for Interconnected Multicore Systems](https://arxiv.org/abs/2510.16896)
*Yiming Hu*

Main category: cs.DC

TL;DR: 论文提出了一种无需额外硬件的集成容错架构，通过稳定性指标和周期性诊断，显著提高了可靠性和能效。


<details>
  <summary>Details</summary>
Motivation: 解决现有Two-Phase TMR在永久故障下失效以及R-TMR因额外硬件依赖导致系统复杂性和容错性降低的问题。

Method: 该方法通过构建稳定性指标识别可靠机器，并进行周期性诊断，实现了永久故障隔离和自适应任务调度。

Result: 实验结果表明，该方法相比基准TMR减少了约30%的任务负载，同时实现了更高的故障覆盖率和隔离精度。

Conclusion: 该论文提出了一种集成式容错架构，通过构建稳定性指标和周期性诊断，实现了无需额外硬件的永久故障隔离和自适应任务调度，显著提高了系统的可靠性和能效。

Abstract: Two-Phase Triple Modular Redundancy TMR divides redundancy operations into
two stages, omitting part of the computation during fault-free operation to
reduce energy consumption. However, it becomes ineffective under permanent
faults, limiting its reliability in critical systems. To address this,
Reactive-TMR (R-TMR) introduces permanent fault isolation mechanisms for faulty
cores, tolerating both transient and permanent faults. Yet, its reliance on
additional hardware increases system complexity and reduces fault tolerance
when multiple cores or auxiliary modules fail. This paper proposes an
integrated fault-tolerant architecture for interconnected multicore systems. By
constructing a stability metric to identify reliable machines and performing
periodic diagnostics, the method enables permanent fault isolation and adaptive
task scheduling without extra hardware. Experimental results show that it
reduces task workload by approximately 30% compared to baseline TMR and
achieves superior fault coverage and isolation accuracy, significantly
improving both reliability and energy efficiency.

</details>


### [318] [Tutoring LLM into a Better CUDA Optimizer](https://arxiv.org/abs/2510.16933)
*Matyáš Brabec,Jiří Klepl,Michal Töpfer,Martin Kruliš*

Main category: cs.DC

TL;DR: 研究显示，大语言模型能生成优化CUDA代码，但需专家指导才能达到最佳效果。


<details>
  <summary>Details</summary>
Motivation: 探索最新推理模型在生成优化CUDA代码方面的能力，确定LLMs能独立完成的代码优化类型及通过提示改进的可能性。

Method: 通过自动评估（正确性和加速比）和手动代码审查，评估LLMs生成的优化CUDA代码，并尝试交互式修正方法。

Result: LLMs是熟练的编码者，但在优化解决方案上需要详细提示和指导。

Conclusion: 大语言模型（LLMs）在代码生成方面表现出色，但需要专家指导才能达到并行计算专家提供的优化水平。

Abstract: Recent leaps in large language models (LLMs) caused a revolution in
programming tools (like GitHub Copilot) that can help with code generation,
debugging, and even performance optimization. In this paper, we focus on the
capabilities of the most recent reasoning models to generate optimized CUDA
code for predefined, well-known tasks. Our objective is to determine which
types of code optimizations and parallel patterns the LLMs can perform by
themselves and whether they can be improved by tutoring (providing more
detailed hints and guidelines in the prompt). The generated solutions were
evaluated both automatically (for correctness and speedup) and manually (code
reviews) to provide a more detailed perspective. We also tried an interactive
approach where the LLM can fix its previous mistakes within a session. The
results indicate that LLMs are quite skilled coders; however, they require
tutoring to reach optimized solutions provided by parallel computing experts.

</details>


### [319] [Host-Side Telemetry for Performance Diagnosis in Cloud and HPC GPU Infrastructure](https://arxiv.org/abs/2510.16946)
*Erfan Darzi,Aldo Pareja,Shreeanant Bharadwaj*

Main category: cs.DC

TL;DR: 提出eBPF遥测系统，解决GPU尾延迟诊断问题，高精度低开销。


<details>
  <summary>Details</summary>
Motivation: 现有监控工具在共享计算环境中缺乏细粒度分析能力，无法进行根因分析。

Method: 采用eBPF技术，结合主机指标与GPU内部事件，实现全系统观测。

Result: 系统诊断准确率达81-88%，5秒内检测尖峰，6-8秒完成根因分析，CPU开销为1.21%（100Hz采样）。

Conclusion: 该论文提出了一种基于eBPF的遥测系统，有效诊断了GPU尾延迟尖峰问题，提升了共享计算环境中的性能可预测性和资源利用率。

Abstract: Diagnosing GPU tail latency spikes in cloud and HPC infrastructure is
critical for maintaining performance predictability and resource utilization,
yet existing monitoring tools lack the granularity for root cause analysis in
shared computing environments. We introduce an eBPF-based telemetry system that
provides unified host-side monitoring of GPU workloads, correlating
eBPF-derived host metrics with GPU-internal events for holistic system
observability. The system achieves 81--88\% diagnostic accuracy, detects spikes
within 5 seconds, and completes root cause analysis in 6--8 seconds, operating
with 1.21\% CPU overhead at 100Hz sampling. Evaluated on distributed learning
workloads, the system identifies root causes including NIC contention, PCIe
pressure, and CPU interference, enabling operational debugging for multi-tenant
GPU infrastructure without requiring cluster-wide instrumentation.

</details>


### [320] [Integrating Performance Tools in Model Reasoning for GPU Kernel Optimization](https://arxiv.org/abs/2510.17158)
*Daniel Nichols,Konstantinos Parasyris,Charles Jekel,Abhinav Bhatele,Harshitha Menon*

Main category: cs.DC

TL;DR: 本文提出了一种训练语言模型的方法，使其在推理过程中与性能工具互动，从而提升代码性能任务的执行效果，并成功训练出先进的GPU内核优化模型。


<details>
  <summary>Details</summary>
Motivation: 尽管语言模型在复杂软件工程任务中表现出色，但在代码性能相关任务（如优化）中仍存在不足，因为这些任务依赖于环境、硬件等复杂数据。

Method: 提出了一种训练语言模型的方法，使其在推理过程中能与性能工具互动。

Result: 通过该方法训练出了一个先进的GPU内核优化模型。

Conclusion: 本文提出了一种训练语言模型的方法，使其在推理过程中能与性能工具互动，从而提升代码性能相关任务的执行效果。

Abstract: Language models are now prevalent in software engineering with many
developers using them to automate tasks and accelerate their development. While
language models have been tremendous at accomplishing complex software
engineering tasks, there are still many areas where they fail to deliver
desirable results, for instance code performance related tasks. Tasks like
optimization depend on many complex data from the environment, hardware, etc.
that are not directly represented in source code. Recent efforts have seen
large improvements in general code modeling tasks using chain-of-thought style
reasoning, but these models still fail to comprehend how the environment
interacts with code performance. In this paper we propose a methodology to
train language models that can interact with performance tools during their
reasoning process. We then demonstrate how this methodology can be used to
train a state-of-the-art GPU kernel optimization model.

</details>


### [321] [On the Universality of Round Elimination Fixed Points](https://arxiv.org/abs/2510.17639)
*Alkida Balliu,Sebastian Brandt,Ole Gabsdil,Dennis Olivetti,Jukka Suomela*

Main category: cs.DC

TL;DR: 论文探讨了轮次消除技术是否适用于所有分布式图算法下界证明，发现其在某些情况下有效，但对于有输入的问题存在局限性，并提出了新的通用下界定理。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨轮次消除固定点是否可以作为证明分布式图算法下界的通用技术，并解决现有技术无法处理的问题。

Method: 作者开发了一种基于三势输入的新技术，系统地构建轮次消除下界，并证明了某些同态问题确实可以通过轮次消除固定点证明下界。

Result: 结果表明，轮次消除技术在某些情况下是有效的，但对于有输入的问题存在局限性。作者还提出了第一个适用于任何问题的通用下界定理。

Conclusion: 论文得出结论，轮次消除技术虽然在某些情况下可以证明下界，但并非普遍适用于所有问题。特别是对于有输入的问题，存在无法通过轮次消除固定点证明下界的情况。

Abstract: Recent work on distributed graph algorithms [e.g. STOC 2022, ITCS 2022, PODC
2020] has drawn attention to the following open question: are round elimination
fixed points a universal technique for proving lower bounds? That is, given a
locally checkable problem $\Pi$ that requires at least $\Omega(\log n)$ rounds
in the deterministic LOCAL model, can we always find a relaxation $\Pi'$ of
$\Pi$ that is a nontrivial fixed point for the round elimination technique [see
STOC 2016, PODC 2019]? If yes, then a key part of distributed computational
complexity would be also decidable.
  The key obstacle so far has been a certain family of homomorphism problems
[ITCS 2022], which require $\Omega(\log n)$ rounds, but the only known proof is
based on Marks' technique [J.AMS 2016].
  We develop a new technique for constructing round elimination lower bounds
systematically. Using so-called tripotent inputs we show that the
aforementioned homomorphism problems indeed admit a lower bound proof that is
based on round elimination fixed points. Hence we eliminate the only known
obstacle for the universality of round elimination.
  Yet we also present a new obstacle: we show that there are some problems with
inputs that require $\Omega(\log n)$ rounds, yet there is no proof that is
based on relaxations to nontrivial round elimination fixed points. Hence round
elimination cannot be a universal technique for problems with inputs (but it
might be universal for problems without inputs).
  We also prove the first fully general lower bound theorem that is applicable
to any problem, with or without inputs, that is a fixed point in round
elimination. Prior results of this form were only able to handle certain very
restricted inputs.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [322] [VAR-SLAM: Visual Adaptive and Robust SLAM for Dynamic Environments](https://arxiv.org/abs/2510.16205)
*João Carlos Virgolino Soares,Gabriel Fischer Abati,Claudio Semini*

Main category: cs.RO

TL;DR: VAR-SLAM是一个自适应动态环境视觉SLAM系统，结合语义过滤和自适应鲁棒损失，显著提升轨迹精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖语义过滤或固定鲁棒核，无法适应未知移动物体，导致精度下降。

Method: 基于ORB-SLAM3的系统，结合轻量级语义关键点过滤器和Barron自适应鲁棒损失，在线估计鲁棒核的形状参数。

Result: 在TUM RGB-D、Bonn RGB-D Dynamic和OpenLORIS数据集上，VAR-SLAM的轨迹精度优于现有基线方法，ATE RMSE降低达25%，同时保持平均27 FPS的性能。

Conclusion: VAR-SLAM通过结合轻量级语义关键点过滤器和自适应鲁棒损失，显著提升了动态环境中视觉SLAM的轨迹精度和鲁棒性。

Abstract: Visual SLAM in dynamic environments remains challenging, as several existing
methods rely on semantic filtering that only handles known object classes, or
use fixed robust kernels that cannot adapt to unknown moving objects, leading
to degraded accuracy when they appear in the scene. We present VAR-SLAM (Visual
Adaptive and Robust SLAM), an ORB-SLAM3-based system that combines a
lightweight semantic keypoint filter to deal with known moving objects, with
Barron's adaptive robust loss to handle unknown ones. The shape parameter of
the robust kernel is estimated online from residuals, allowing the system to
automatically adjust between Gaussian and heavy-tailed behavior. We evaluate
VAR-SLAM on the TUM RGB-D, Bonn RGB-D Dynamic, and OpenLORIS datasets, which
include both known and unknown moving objects. Results show improved trajectory
accuracy and robustness over state-of-the-art baselines, achieving up to 25%
lower ATE RMSE than NGD-SLAM on challenging sequences, while maintaining
performance at 27 FPS on average.

</details>


### [323] [DeGrip: A Compact Cable-driven Robotic Gripper for Desktop Disassembly](https://arxiv.org/abs/2510.16231)
*Bihao Zhang,Davood Soleymanzadeh,Xiao Liang,Minghui Zheng*

Main category: cs.RO

TL;DR: DeGrip是一种定制夹爪，专为EOL台式机拆卸设计，具有三自由度和电缆驱动机制，评估显示其有效。


<details>
  <summary>Details</summary>
Motivation: 解决EOL产品智能机器人拆卸的长期挑战，特别是缺乏专用硬件限制机器学习技术在实际场景中的应用。

Method: 开发了DeGrip定制夹爪，采用电缆驱动传输机制和三自由度设计，并在Isaac Sim中构建了EOL台式机拆卸环境进行评估。

Result: 评估结果证实DeGrip在EOL台式机拆卸中的能力。

Conclusion: DeGrip证明其能够有效拆卸EOL台式机，展示了在受限空间和任意配置下的操作能力。

Abstract: Intelligent robotic disassembly of end-of-life (EOL) products has been a
long-standing challenge in robotics. While machine learning techniques have
shown promise, the lack of specialized hardware limits their application in
real-world scenarios. We introduce DeGrip, a customized gripper designed for
the disassembly of EOL computer desktops. DeGrip provides three degrees of
freedom (DOF), enabling arbitrary configurations within the disassembly
environment when mounted on a robotic manipulator. It employs a cable-driven
transmission mechanism that reduces its overall size and enables operation in
confined spaces. The wrist is designed to decouple the actuation of wrist and
jaw joints. We also developed an EOL desktop disassembly environment in Isaac
Sim to evaluate the effectiveness of DeGrip. The tasks were designed to
demonstrate its ability to operate in confined spaces and disassemble
components in arbitrary configurations. The evaluation results confirm the
capability of DeGrip for EOL desktop disassembly.

</details>


### [324] [Cosmos-Surg-dVRK: World Foundation Model-based Automated Online Evaluation of Surgical Robot Policy Learning](https://arxiv.org/abs/2510.16240)
*Lukas Zbinden,Nigel Nelson,Juo-Tung Chen,Xinhao Chen,Ji Woong,Kim,Mahdi Azizian,Axel Krieger,Sean Huver*

Main category: cs.RO

TL;DR: Cosmos-Surg-dVRK通过高保真模拟和自动化评估，解决了手术策略在物理平台上评估的挑战，展示了其在复杂手术中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于直接评估手术策略在物理机器人平台上成本高、耗时长且难以复现，因此需要一种高保真度的模拟方法。

Method: 本研究引入了Cosmos-Surg-dVRK，一个基于Cosmos WFM的手术微调模型，并结合了视频分类器进行自动化评估。

Result: 在桌面缝合垫任务中，自动化流程在Cosmos-Surg-dVRK中的在线推演与真实dVRK平台上的策略结果具有强相关性，且视频分类器与人类标注者的一致性良好。初步实验显示，离体猪胆囊切除术任务在Cosmos-Surg-dVRK中与现实评估有良好对齐。

Conclusion: Cosmos-Surg-dVRK结合训练的视频分类器，为手术策略提供了全自动在线评估和基准测试平台，展示了其在复杂手术程序中的潜力。

Abstract: The rise of surgical robots and vision-language-action models has accelerated
the development of autonomous surgical policies and efficient assessment
strategies. However, evaluating these policies directly on physical robotic
platforms such as the da Vinci Research Kit (dVRK) remains hindered by high
costs, time demands, reproducibility challenges, and variability in execution.
World foundation models (WFM) for physical AI offer a transformative approach
to simulate complex real-world surgical tasks, such as soft tissue deformation,
with high fidelity. This work introduces Cosmos-Surg-dVRK, a surgical finetune
of the Cosmos WFM, which, together with a trained video classifier, enables
fully automated online evaluation and benchmarking of surgical policies. We
evaluate Cosmos-Surg-dVRK using two distinct surgical datasets. On tabletop
suture pad tasks, the automated pipeline achieves strong correlation between
online rollouts in Cosmos-Surg-dVRK and policy outcomes on the real dVRK Si
platform, as well as good agreement between human labelers and the V-JEPA
2-derived video classifier. Additionally, preliminary experiments with ex-vivo
porcine cholecystectomy tasks in Cosmos-Surg-dVRK demonstrate promising
alignment with real-world evaluations, highlighting the platform's potential
for more complex surgical procedures.

</details>


### [325] [NEBULA: Do We Evaluate Vision-Language-Action Agents Correctly?](https://arxiv.org/abs/2510.16263)
*Jierui Peng,Yanyan Zhang,Yicheng Duan,Tuo Liang,Vipin Chaudhary,Yu Yin*

Main category: cs.RO

TL;DR: NEBULA是一个统一生态系统，通过双轴评估协议和大规模数据集，解决了VLA代理评估中的粗粒度指标和数据碎片化问题，揭示了传统指标掩盖的关键能力缺陷。


<details>
  <summary>Details</summary>
Motivation: 解决VLA代理评估中粗粒度终端任务成功指标无法提供精确技能诊断或测量对现实世界扰动的鲁棒性的问题，以及数据碎片化阻碍可重复研究和通用模型开发的挑战。

Method: 引入NEBULA统一生态系统，包含双轴评估协议（细粒度能力测试和系统压力测试）、标准化API和大规模聚合数据集。

Result: 发现顶级VLA代理在空间推理和动态适应等关键能力上表现不佳，这些缺陷被传统终端任务成功指标所掩盖。

Conclusion: NEBULA为稳健、通用的具身智能体提供了实用基础，通过测量代理的能力及其可靠性，揭示了传统终端任务成功指标所掩盖的关键能力缺陷。

Abstract: The evaluation of Vision-Language-Action (VLA) agents is hindered by the
coarse, end-task success metric that fails to provide precise skill diagnosis
or measure robustness to real-world perturbations. This challenge is
exacerbated by a fragmented data landscape that impedes reproducible research
and the development of generalist models. To address these limitations, we
introduce \textbf{NEBULA}, a unified ecosystem for single-arm manipulation that
enables diagnostic and reproducible evaluation. NEBULA features a novel
dual-axis evaluation protocol that combines fine-grained \textit{capability
tests} for precise skill diagnosis with systematic \textit{stress tests} that
measure robustness. A standardized API and a large-scale, aggregated dataset
are provided to reduce fragmentation and support cross-dataset training and
fair comparison. Using NEBULA, we demonstrate that top-performing VLAs struggle
with key capabilities such as spatial reasoning and dynamic adaptation, which
are consistently obscured by conventional end-task success metrics. By
measuring both what an agent can do and when it does so reliably, NEBULA
provides a practical foundation for robust, general-purpose embodied agents.

</details>


### [326] [Do What You Say: Steering Vision-Language-Action Models via Runtime Reasoning-Action Alignment Verification](https://arxiv.org/abs/2510.16281)
*Yilin Wu,Anqi Li,Tucker Hermans,Fabio Ramos,Andrea Bajcsy,Claudia P'erez-D'Arpino*

Main category: cs.RO

TL;DR: 论文提出一种提升VLA模型指令跟随鲁棒性的方法，通过模拟和VLM选择对齐动作序列，在OOD场景下性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型在生成正确的文本计划后，仍可能因动作执行与计划不一致而失败，尤其是在OOD场景中。论文旨在解决这一忠实性问题。

Method: 提出了一种基于模拟和预训练视觉语言模型（VLM）的选择框架，通过采样多个候选动作序列、预测其模拟结果，并选择与文本计划最对齐的序列来执行。

Result: 实验表明，该方法在行为组合任务中比现有工作性能提升高达15%，且能随计算和数据多样性扩展。

Conclusion: 该论文通过引入一种无需训练、运行时策略引导的方法，显著提升了视觉语言动作（VLA）模型在指令跟随任务中的鲁棒性和行为组合能力，尤其是在分布外（OOD）场景下。

Abstract: Reasoning Vision Language Action (VLA) models improve robotic
instruction-following by generating step-by-step textual plans before low-level
actions, an approach inspired by Chain-of-Thought (CoT) reasoning in language
models. Yet even with a correct textual plan, the generated actions can still
miss the intended outcomes in the plan, especially in out-of-distribution (OOD)
scenarios. We formalize this phenomenon as a lack of embodied CoT faithfulness,
and introduce a training-free, runtime policy steering method for
reasoning-action alignment. Given a reasoning VLA's intermediate textual plan,
our framework samples multiple candidate action sequences from the same model,
predicts their outcomes via simulation, and uses a pre-trained Vision-Language
Model (VLM) to select the sequence whose outcome best aligns with the VLA's own
textual plan. Only executing action sequences that align with the textual
reasoning turns our base VLA's natural action diversity from a source of error
into a strength, boosting robustness to semantic and visual OOD perturbations
and enabling novel behavior composition without costly re-training. We also
contribute a reasoning-annotated extension of LIBERO-100, environment
variations tailored for OOD evaluation, and demonstrate up to 15% performance
gain over prior work on behavior composition tasks and scales with compute and
data diversity. Project Website at:
https://yilin-wu98.github.io/steering-reasoning-vla/

</details>


### [327] [SPOT: Sensing-augmented Trajectory Planning via Obstacle Threat Modeling](https://arxiv.org/abs/2510.16308)
*Chi Zhang,Xian Huang,Wei Dong*

Main category: cs.RO

TL;DR: SPOT框架通过统一感知和运动规划，显著提升无人机在复杂环境中的避障能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将运动规划与感知考虑分离，导致障碍物响应效果不佳且延迟，需要一种统一的规划框架来解决这一问题。

Method: 采用高斯过程基础的障碍物信念地图，结合碰撞感知推理机制，生成时变观测紧急度地图，实现实时、观测感知的轨迹规划。

Result: 仿真和真实环境实验表明，SPOT相比基线方法提前2.8秒检测到潜在动态障碍物，动态障碍物可见性提高500%以上。

Conclusion: SPOT框架通过将感知目标明确纳入运动优化，显著提高了无人机在动态、杂乱和遮挡环境中的障碍物检测和避障能力。

Abstract: UAVs equipped with a single depth camera encounter significant challenges in
dynamic obstacle avoidance due to limited field of view and inevitable blind
spots. While active vision strategies that steer onboard cameras have been
proposed to expand sensing coverage, most existing methods separate motion
planning from sensing considerations, resulting in less effective and delayed
obstacle response. To address this limitation, we introduce SPOT
(Sensing-augmented Planning via Obstacle Threat modeling), a unified planning
framework for observation-aware trajectory planning that explicitly
incorporates sensing objectives into motion optimization. At the core of our
method is a Gaussian Process-based obstacle belief map, which establishes a
unified probabilistic representation of both recognized (previously observed)
and potential obstacles. This belief is further processed through a
collision-aware inference mechanism that transforms spatial uncertainty and
trajectory proximity into a time-varying observation urgency map. By
integrating urgency values within the current field of view, we define
differentiable objectives that enable real-time, observation-aware trajectory
planning with computation times under 10 ms. Simulation and real-world
experiments in dynamic, cluttered, and occluded environments show that our
method detects potential dynamic obstacles 2.8 seconds earlier than baseline
approaches, increasing dynamic obstacle visibility by over 500\%, and enabling
safe navigation through cluttered, occluded environments.

</details>


### [328] [Manual2Skill++: Connector-Aware General Robotic Assembly from Instruction Manuals via Vision-Language Models](https://arxiv.org/abs/2510.16344)
*Chenrui Tie,Shengxiang Sun,Yudi Lin,Yanbo Wang,Zhongrui Li,Zhouhan Zhong,Jinxuan Zhu,Yiman Pang,Haonan Chen,Junting Chen,Ruihai Wu,Lin Shao*

Main category: cs.RO

TL;DR: 研究提出Manual2Skill++框架，将连接作为组装的首要元素，通过视觉-语言模型从手册中提取结构化信息，验证了在复杂组装场景中的有效性。


<details>
  <summary>Details</summary>
Motivation: 组装的成功与否往往取决于连接的精确建立，而现有的机器人组装方法通常将连接视为次要考虑。本研究旨在将连接作为组装表示中的首要元素，以更可靠地完成组装任务。

Method: 提出了Manual2Skill++，一个基于视觉-语言的框架，能够从组装手册中自动提取结构化连接信息，并将组装任务编码为层次化图结构，其中节点表示部件和子组装体，边明确建模组件间的连接关系。

Result: 在包含20多种组装任务的数据集上验证了表示提取方法的有效性，并在四个复杂的组装场景（家具、玩具和制造组件）中评估了从任务理解到执行的完整流程。

Conclusion: 通过将连接作为组装表示中的首要元素，并利用Manual2Skill++框架从组装手册中提取结构化连接信息，研究成功验证了其方法在复杂组装场景中的有效性。

Abstract: Assembly hinges on reliably forming connections between parts; yet most
robotic approaches plan assembly sequences and part poses while treating
connectors as an afterthought. Connections represent the critical "last mile"
of assembly execution, while task planning may sequence operations and motion
plan may position parts, the precise establishment of physical connections
ultimately determines assembly success or failure. In this paper, we consider
connections as first-class primitives in assembly representation, including
connector types, specifications, quantities, and placement locations. Drawing
inspiration from how humans learn assembly tasks through step-by-step
instruction manuals, we present Manual2Skill++, a vision-language framework
that automatically extracts structured connection information from assembly
manuals. We encode assembly tasks as hierarchical graphs where nodes represent
parts and sub-assemblies, and edges explicitly model connection relationships
between components. A large-scale vision-language model parses symbolic
diagrams and annotations in manuals to instantiate these graphs, leveraging the
rich connection knowledge embedded in human-designed instructions. We curate a
dataset containing over 20 assembly tasks with diverse connector types to
validate our representation extraction approach, and evaluate the complete task
understanding-to-execution pipeline across four complex assembly scenarios in
simulation, spanning furniture, toys, and manufacturing components with
real-world correspondence.

</details>


### [329] [Learning to Optimize Edge Robotics: A Fast Integrated Perception-Motion-Communication Approach](https://arxiv.org/abs/2510.16424)
*Dan Guo,Xibin Jin,Shuai Wang,Zhigang Wen,Miaowen Wen,Chengzhong Xu*

Main category: cs.RO

TL;DR: IPMC通过动态调整通信策略减少通信开销，LTO降低了10倍以上的计算复杂度，实验验证了其优越性和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了机器人功能与通信条件之间的相互依赖关系，导致通信开销过大。

Method: 通过集成感知、运动和通信（IPMC），动态调整通信策略（如压缩比、传输频率、发射功率），并利用学习优化（LTO）范式设计模仿学习神经网络。

Result: 实验表明，IPMC优于现有方法，LTO的计算复杂度比最先进的优化求解器降低了10倍以上。

Conclusion: IPMC和LTO范式显著提升了边缘机器人系统的效率，减少了通信开销和计算复杂度，同时保持了实时执行能力。

Abstract: Edge robotics involves frequent exchanges of large-volume multi-modal data.
Existing methods ignore the interdependency between robotic functionalities and
communication conditions, leading to excessive communication overhead. This
paper revolutionizes edge robotics systems through integrated perception,
motion, and communication (IPMC). As such, robots can dynamically adapt their
communication strategies (i.e., compression ratio, transmission frequency,
transmit power) by leveraging the knowledge of robotic perception and motion
dynamics, thus reducing the need for excessive sensor data uploads.
Furthermore, by leveraging the learning to optimize (LTO) paradigm, an
imitation learning neural network is designed and implemented, which reduces
the computational complexity by over 10x compared to state-of-the art
optimization solvers. Experiments demonstrate the superiority of the proposed
IPMC and the real-time execution capability of LTO.

</details>


### [330] [What Questions Should Robots Be Able to Answer? A Dataset of User Questions for Explainable Robotics](https://arxiv.org/abs/2510.16435)
*Lennart Wachowiak,Andrew Coles,Gerard Canal,Oya Celiktutan*

Main category: cs.RO

TL;DR: 该研究收集了一个包含1,893个用户问题的数据集，用于帮助机器人更好地回答多样化问题，尤其是复杂场景下的问题。数据集还揭示了新手和经验用户在提问类型上的差异。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型和对话界面在人机交互中的广泛应用，机器人回答用户问题的能力变得尤为重要。然而，现有可解释机器人研究主要集中在‘为什么’问题上，缺乏对多样化问题的理解。

Method: 通过创建15个视频刺激和7个文本刺激，描绘机器人执行各种家务任务，然后在Prolific平台上收集100名参与者对每个情境中可能提出的问题。最终数据集包含1,893个用户问题，分为12个类别和70个子类别。

Result: 数据集中最常见的类别是关于任务执行细节（22.5%）、机器人能力（12.7%）和性能评估（11.3%）的问题。尽管关于机器人如何处理复杂场景的问题较少，但用户认为这些是最重要的问题。此外，新手和经验丰富的用户在提问类型上存在差异。

Conclusion: 该数据集为机器人领域提供了重要的基础，帮助识别机器人需要记录和暴露给对话界面的信息，评估问答模块的性能，并设计符合用户期望的解释策略。

Abstract: With the growing use of large language models and conversational interfaces
in human-robot interaction, robots' ability to answer user questions is more
important than ever. We therefore introduce a dataset of 1,893 user questions
for household robots, collected from 100 participants and organized into 12
categories and 70 subcategories. Most work in explainable robotics focuses on
why-questions. In contrast, our dataset provides a wide variety of questions,
from questions about simple execution details to questions about how the robot
would act in hypothetical scenarios -- thus giving roboticists valuable
insights into what questions their robot needs to be able to answer. To collect
the dataset, we created 15 video stimuli and 7 text stimuli, depicting robots
performing varied household tasks. We then asked participants on Prolific what
questions they would want to ask the robot in each portrayed situation. In the
final dataset, the most frequent categories are questions about task execution
details (22.5%), the robot's capabilities (12.7%), and performance assessments
(11.3%). Although questions about how robots would handle potentially difficult
scenarios and ensure correct behavior are less frequent, users rank them as the
most important for robots to be able to answer. Moreover, we find that users
who identify as novices in robotics ask different questions than more
experienced users. Novices are more likely to inquire about simple facts, such
as what the robot did or the current state of the environment. As robots enter
environments shared with humans and language becomes central to giving
instructions and interaction, this dataset provides a valuable foundation for
(i) identifying the information robots need to log and expose to conversational
interfaces, (ii) benchmarking question-answering modules, and (iii) designing
explanation strategies that align with user expectations.

</details>


### [331] [Advancing Off-Road Autonomous Driving: The Large-Scale ORAD-3D Dataset and Comprehensive Benchmarks](https://arxiv.org/abs/2510.16500)
*Chen Min,Jilin Mei,Heng Zhai,Shuai Wang,Tong Sun,Fanjie Kong,Haoyang Li,Fangyuan Mao,Fuyang Liu,Shuo Wang,Yiming Nie,Qi Zhu,Liang Xiao,Dawei Zhao,Yu Hu*

Main category: cs.RO

TL;DR: ORAD-3D是最大的越野自动驾驶数据集，覆盖多样地形和天气，提供五项基准测试，推动研究发展。


<details>
  <summary>Details</summary>
Motivation: 解决越野自动驾驶研究中大规模、高质量数据集和基准测试的稀缺问题。

Method: 提出了ORAD-3D数据集，覆盖多种地形和环境变化，并建立了包含五项基本任务的基准测试套件。

Result: ORAD-3D是目前最大的越野自动驾驶专用数据集，为研究提供了全面支持。

Conclusion: ORAD-3D数据集及其基准测试为越野自动驾驶研究提供了统一且强大的资源，推动了感知和规划技术的进步。

Abstract: A major bottleneck in off-road autonomous driving research lies in the
scarcity of large-scale, high-quality datasets and benchmarks. To bridge this
gap, we present ORAD-3D, which, to the best of our knowledge, is the largest
dataset specifically curated for off-road autonomous driving. ORAD-3D covers a
wide spectrum of terrains, including woodlands, farmlands, grasslands,
riversides, gravel roads, cement roads, and rural areas, while capturing
diverse environmental variations across weather conditions (sunny, rainy,
foggy, and snowy) and illumination levels (bright daylight, daytime, twilight,
and nighttime). Building upon this dataset, we establish a comprehensive suite
of benchmark evaluations spanning five fundamental tasks: 2D free-space
detection, 3D occupancy prediction, rough GPS-guided path planning,
vision-language model-driven autonomous driving, and world model for off-road
environments. Together, the dataset and benchmarks provide a unified and robust
resource for advancing perception and planning in challenging off-road
scenarios. The dataset and code will be made publicly available at
https://github.com/chaytonmin/ORAD-3D.

</details>


### [332] [A Novel Gripper with Semi-Peaucellier Linkage and Idle-Stroke Mechanism for Linear Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.16517)
*Haokai Ding,Wenzeng Zhang*

Main category: cs.RO

TL;DR: SPD机械手通过线性平行夹持机制解决了传统夹持器需调整高度的问题，并具备适应不同形状和大小物体的能力。


<details>
  <summary>Details</summary>
Motivation: 传统工业夹持器在平行夹持时指尖呈弧形运动，需调整机械臂高度以避免与桌面碰撞，SPD机械手通过线性平行夹持机制有效解决了这一问题。

Method: 介绍了SPD机械手的设计理念、基本组成原理及优化分析理论，并基于设计理论开发了原型机进行测试。

Result: 实验结果表明，该机械手成功实现了线性平行夹持功能，并展现出良好的适应性。

Conclusion: SPD机械手成功实现了线性平行夹持功能，并展现出良好的适应性，为提升深度学习训练数据收集奠定了基础。

Abstract: This paper introduces a novel robotic gripper, named as the SPD gripper. It
features a palm and two mechanically identical and symmetrically arranged
fingers, which can be driven independently or by a single motor. The fingertips
of the fingers follow a linear motion trajectory, facilitating the grasping of
objects of various sizes on a tabletop without the need to adjust the overall
height of the gripper. Traditional industrial grippers with parallel gripping
capabilities often exhibit an arcuate motion at the fingertips, requiring the
entire robotic arm to adjust its height to avoid collisions with the tabletop.
The SPD gripper, with its linear parallel gripping mechanism, effectively
addresses this issue. Furthermore, the SPD gripper possesses adaptive
capabilities, accommodating objects of different shapes and sizes. This paper
presents the design philosophy, fundamental composition principles, and
optimization analysis theory of the SPD gripper. Based on the design theory, a
robotic gripper prototype was developed and tested. The experimental results
demonstrate that the robotic gripper successfully achieves linear parallel
gripping functionality and exhibits good adaptability. In the context of the
ongoing development of embodied intelligence technologies, this robotic gripper
can assist various robots in achieving effective grasping, laying a solid
foundation for collecting data to enhance deep learning training.

</details>


### [333] [DIV-Nav: Open-Vocabulary Spatial Relationships for Multi-Object Navigation](https://arxiv.org/abs/2510.16518)
*Jesús Ortega-Peimbert,Finn Lukas Busch,Timon Homberger,Quantao Yang,Olov Andersson*

Main category: cs.RO

TL;DR: DIV-Nav是一个实时导航系统，通过分解复杂查询、计算语义图交集和验证约束，解决了带有空间关系的自由文本查询导航问题，并在实验和实际部署中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前零-shot对象导航通常仅支持简单查询（如“电视”或“蓝色地毯”），而无法处理带有空间关系的复杂自由文本查询（如“找到桌子上的遥控器”）。DIV-Nav旨在填补这一空白，同时保持语义映射的鲁棒性。

Method: DIV-Nav系统采用三步放松策略：分解复杂空间约束的自然语言指令为简单对象级查询，计算个体语义信念图的交集以识别共存区域，以及通过LVLM验证对象与原始约束的匹配。此外，系统还探索了如何调整在线语义映射的前沿探索目标以适应空间搜索查询。

Result: DIV-Nav在MultiON基准测试和波士顿动力Spot机器人（搭载Jetson Orin AGX）上的真实世界部署中表现优异。

Conclusion: DIV-Nav系统通过分解复杂空间约束的自然语言指令、计算语义信念图的交集以及验证对象与原始约束的匹配，有效解决了复杂自由文本查询的导航问题，并在MultiON基准测试和真实世界部署中验证了其性能。

Abstract: Advances in open-vocabulary semantic mapping and object navigation have
enabled robots to perform an informed search of their environment for an
arbitrary object. However, such zero-shot object navigation is typically
designed for simple queries with an object name like "television" or "blue
rug". Here, we consider more complex free-text queries with spatial
relationships, such as "find the remote on the table" while still leveraging
robustness of a semantic map. We present DIV-Nav, a real-time navigation system
that efficiently addresses this problem through a series of relaxations: i)
Decomposing natural language instructions with complex spatial constraints into
simpler object-level queries on a semantic map, ii) computing the Intersection
of individual semantic belief maps to identify regions where all objects
co-exist, and iii) Validating the discovered objects against the original,
complex spatial constrains via a LVLM. We further investigate how to adapt the
frontier exploration objectives of online semantic mapping to such spatial
search queries to more effectively guide the search process. We validate our
system through extensive experiments on the MultiON benchmark and real-world
deployment on a Boston Dynamics Spot robot using a Jetson Orin AGX. More
details and videos are available at https://anonsub42.github.io/reponame/

</details>


### [334] [Semi-Peaucellier Linkage and Differential Mechanism for Linear Pinching and Self-Adaptive Grasping](https://arxiv.org/abs/2510.16524)
*Haokai Ding,Zhaohan Chen,Tao Yang,Wenzeng Zhang*

Main category: cs.RO

TL;DR: SP-Diff平行夹爪系统通过差分连杆和行星齿轮传动提升抓取适应性，减少校准需求，适用于多样化工件和协作机器人场景。


<details>
  <summary>Details</summary>
Motivation: 解决传统末端执行器在智能工业自动化中适应性不足的问题，特别是针对不同工业工件和可变形物体的抓取需求。

Method: 采用差分连杆机制和模块化对称双指配置，集成行星齿轮传动，实现线性平行抓取，并通过运动学优化的平行四边形连杆和差分机制，保持结构刚性。

Result: 系统减少了30%的Z轴重新校准需求，同时实现了同步线性运动和独立手指姿态调整，适用于多样化工件和可变形物体（如柑橘类水果）。

Conclusion: SP-Diff平行夹爪系统通过创新的差分连杆机制和模块化对称双指配置，提升了智能工业自动化中末端执行器的适应性，展示了在协作机器人、物流自动化和特殊操作场景中的广泛应用前景。

Abstract: This paper presents the SP-Diff parallel gripper system, addressing the
limited adaptability of conventional end-effectors in intelligent industrial
automation. The proposed design employs an innovative differential linkage
mechanism with a modular symmetric dual-finger configuration to achieve
linear-parallel grasping. By integrating a planetary gear transmission, the
system enables synchronized linear motion and independent finger pose
adjustment while maintaining structural rigidity, reducing Z-axis recalibration
requirements by 30% compared to arc-trajectory grippers. The compact palm
architecture incorporates a kinematically optimized parallelogram linkage and
Differential mechanism, demonstrating adaptive grasping capabilities for
diverse industrial workpieces and deformable objects such as citrus fruits.
Future-ready interfaces are embedded for potential force/vision sensor
integration to facilitate multimodal data acquisition (e.g., trajectory
planning and object deformation) in digital twin frameworks. Designed as a
flexible manufacturing solution, SP-Diff advances robotic end-effector
intelligence through its adaptive architecture, showing promising applications
in collaborative robotics, logistics automation, and specialized operational
scenarios.

</details>


### [335] [MoS-VLA: A Vision-Language-Action Model with One-Shot Skill Adaptation](https://arxiv.org/abs/2510.16617)
*Ruihan Zhao,Tyler Ingebrand,Sandeep Chinchali,Ufuk Topcu*

Main category: cs.RO

TL;DR: MoS-VLA通过预训练联合学习基础技能，测试时仅需单个演示即可快速适应新任务，显著提升未见任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在新环境、新任务或新机器人上表现不佳，需要一种能够快速适应且无需梯度更新的方法。

Method: MoS-VLA将机器人操作策略表示为有限学习基础函数的线性组合，通过预训练在Open X-Embodiment项目中学习这些基础函数，形成结构化技能空间。测试时，仅需单个专家演示，通过L1动作误差最小化的凸优化问题推断技能表示。

Result: MoS-VLA在五个未见数据集上实现了更低的动作预测误差，并在仿真和真实机器人任务中表现优于预训练VLA模型。

Conclusion: MoS-VLA框架通过预训练联合学习基础技能，并在测试时通过轻量级凸优化快速适应新任务，显著提升了在未见数据集和真实机器人任务中的表现。

Abstract: Vision-Language-Action (VLA) models trained on large robot datasets promise
general-purpose, robust control across diverse domains and embodiments.
However, existing approaches often fail out-of-the-box when deployed in novel
environments, embodiments, or tasks. We introduce Mixture of Skills VLA
(MoS-VLA), a framework that represents robot manipulation policies as linear
combinations of a finite set of learned basis functions. During pretraining,
MoS-VLA jointly learns these basis functions across datasets from the Open
X-Embodiment project, producing a structured skill space. At test time,
adapting to a new task requires only a single expert demonstration. The
corresponding skill representation is then inferred via a lightweight convex
optimization problem that minimizes the L1 action error, without requiring
gradient updates. This gradient-free adaptation incurs minimal overhead while
enabling rapid instantiation of new skills. Empirically, MoS-VLA achieves lower
action-prediction error on five out of five unseen datasets and succeeds in
both simulation and real-robot tasks where a pretrained VLA model fails
outright. Project page: mos-vla.github.io/

</details>


### [336] [First Responders' Perceptions of Semantic Information for Situational Awareness in Robot-Assisted Emergency Response](https://arxiv.org/abs/2510.16692)
*Tianshu Ruan,Zoe Betta,Georgios Tzoumas,Rustam Stolkin,Manolis Chiou*

Main category: cs.RO

TL;DR: 第一响应者对语义增强情境意识的机器人系统持积极态度，但需要在准确率上达到一定标准才能信任和使用，研究揭示了实验室与现场需求之间的差距。


<details>
  <summary>Details</summary>
Motivation: 调查第一响应者对在紧急行动中使用语义信息和情境意识的机器人系统的态度，填补了直接在第一响应者中调查语义基础情境意识的跨国研究的空白。

Method: 通过结构化问卷对来自八个国家的22名第一响应者进行调查，收集了他们的人口统计资料、对机器人的一般态度以及使用语义增强情境意识的经验。

Result: 大多数第一响应者对机器人持积极态度，语义信息在构建情境意识中的有用性平均评分为3.6/5，对预测未预见紧急情况的平均评分为3.9。参与者表示需要74.6%的准确率才能信任语义输出，67.8%的准确率认为其有用。

Conclusion: 研究揭示了实验室机器人能力与现场部署现实之间的关键差距，强调了第一响应者与机器人研究人员之间需要更有意义的合作。这些见解有助于开发更符合用户需求且具有情境意识的应急响应机器人系统。

Abstract: This study investigates First Responders' (FRs) attitudes toward the use of
semantic information and Situational Awareness (SA) in robotic systems during
emergency operations. A structured questionnaire was administered to 22 FRs
across eight countries, capturing their demographic profiles, general attitudes
toward robots, and experiences with semantics-enhanced SA. Results show that
most FRs expressed positive attitudes toward robots, and rated the usefulness
of semantic information for building SA at an average of 3.6 out of 5. Semantic
information was also valued for its role in predicting unforeseen emergencies
(mean 3.9). Participants reported requiring an average of 74.6\% accuracy to
trust semantic outputs and 67.8\% for them to be considered useful, revealing a
willingness to use imperfect but informative AI support tools.
  To the best of our knowledge, this study offers novel insights by being one
of the first to directly survey FRs on semantic-based SA in a cross-national
context. It reveals the types of semantic information most valued in the field,
such as object identity, spatial relationships, and risk context-and connects
these preferences to the respondents' roles, experience, and education levels.
The findings also expose a critical gap between lab-based robotics capabilities
and the realities of field deployment, highlighting the need for more
meaningful collaboration between FRs and robotics researchers. These insights
contribute to the development of more user-aligned and situationally aware
robotic systems for emergency response.

</details>


### [337] [Towards Active Excitation-Based Dynamic Inertia Identification in Satellites](https://arxiv.org/abs/2510.16738)
*Matteo El-Hariry,Vittorio Franzese,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 本文分析了激励设计对卫星惯性识别的影响，比较了两种估计器在不同条件下的性能，为在轨识别提供了指导。


<details>
  <summary>Details</summary>
Motivation: 研究激励设计如何影响刚体纳米和微型卫星的惯性属性识别，以提供在轨自适应惯性识别的实用指导。

Method: 模拟非线性姿态动力学，包括反应轮耦合、执行器限制和外部干扰，使用八种不同频谱丰富度的扭矩剖面激励系统，并比较批量最小二乘法和扩展卡尔曼滤波器两种估计器。

Result: 结果表明，激励频率内容和估计器假设共同决定了估计的准确性和鲁棒性。

Conclusion: 通过分析激励设计和估计器假设对惯性属性识别的影响，本文为在轨自适应惯性识别提供了实用指导，明确了每种方法的最佳适用条件。

Abstract: This paper presents a comprehensive analysis of how excitation design
influences the identification of the inertia properties of rigid nano- and
micro-satellites. We simulate nonlinear attitude dynamics with reaction-wheel
coupling, actuator limits, and external disturbances, and excite the system
using eight torque profiles of varying spectral richness. Two estimators are
compared, a batch Least Squares method and an Extended Kalman Filter, across
three satellite configurations and time-varying inertia scenarios. Results show
that excitation frequency content and estimator assumptions jointly determine
estimation accuracy and robustness, offering practical guidance for in-orbit
adaptive inertia identification by outlining the conditions under which each
method performs best. The code is provided as open-source .

</details>


### [338] [Adaptive Invariant Extended Kalman Filter for Legged Robot State Estimation](https://arxiv.org/abs/2510.16755)
*Kyung-Hwan Kim,DongHyun Ahn,Dong-hyun Lee,JuYoung Yoon,Dong Jin Hyun*

Main category: cs.RO

TL;DR: 提出自适应不变扩展卡尔曼滤波器，通过在线调整噪声水平和接触检测算法，提升腿式机器人在动态运动中的状态估计性能。


<details>
  <summary>Details</summary>
Motivation: 腿式机器人的状态估计直接影响控制性能和运动稳定性，现有方法在小滑移情况下表现不佳且可能引发滤波器发散。

Method: 提出了一种自适应不变扩展卡尔曼滤波器，基于在线协方差估计调整接触脚模型的噪声水平，并采用接触检测算法替代接触传感器。

Result: 在四足机器人LeoQuad上的实际实验验证了该方法在动态运动场景中提升了状态估计性能。

Conclusion: 该方法通过自适应调整接触脚模型的噪声水平，有效提升了腿式机器人在动态运动场景下的状态估计性能，减少了对额外硬件的依赖。

Abstract: State estimation is crucial for legged robots as it directly affects control
performance and locomotion stability. In this paper, we propose an Adaptive
Invariant Extended Kalman Filter to improve proprioceptive state estimation for
legged robots. The proposed method adaptively adjusts the noise level of the
contact foot model based on online covariance estimation, leading to improved
state estimation under varying contact conditions. It effectively handles small
slips that traditional slip rejection fails to address, as overly sensitive
slip rejection settings risk causing filter divergence. Our approach employs a
contact detection algorithm instead of contact sensors, reducing the reliance
on additional hardware. The proposed method is validated through real-world
experiments on the quadruped robot LeoQuad, demonstrating enhanced state
estimation performance in dynamic locomotion scenarios.

</details>


### [339] [T3 Planner: A Self-Correcting LLM Framework for Robotic Motion Planning with Temporal Logic](https://arxiv.org/abs/2510.16767)
*Jia Li,Guoxiang Zhao*

Main category: cs.RO

TL;DR: T3 Planner是一个结合LLM和形式化方法的运动规划框架，能自我修正生成可行轨迹，实验表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖领域专业知识且难以处理时空耦合，而LLM虽擅长语义推理但可能生成不可行运动计划，因此需要一种能自我修正的框架。

Method: T3 Planner采用三个级联模块分解时空任务约束，利用LLM生成候选轨迹序列，并通过STL验证器检查可行性。

Result: 实验表明T3 Planner在不同场景中显著优于基线方法，且其推理能力可蒸馏至轻量级Qwen3-4B模型以实现高效部署。

Conclusion: T3 Planner通过结合LLM和形式化方法，显著提升了自然语言指令到可执行运动规划的准确性和可行性，并在实验中优于基线方法。

Abstract: Translating natural language instructions into executable motion plans is a
fundamental challenge in robotics. Traditional approaches are typically
constrained by their reliance on domain-specific expertise to customize
planners, and often struggle with spatio-temporal couplings that usually lead
to infeasible motions or discrepancies between task planning and motion
execution. Despite the proficiency of Large Language Models (LLMs) in
high-level semantic reasoning, hallucination could result in infeasible motion
plans. In this paper, we introduce the T3 Planner, an LLM-enabled robotic
motion planning framework that self-corrects it output with formal methods. The
framework decomposes spatio-temporal task constraints via three cascaded
modules, each of which stimulates an LLM to generate candidate trajectory
sequences and examines their feasibility via a Signal Temporal Logic (STL)
verifier until one that satisfies complex spatial, temporal, and logical
constraints is found.Experiments across different scenarios show that T3
Planner significantly outperforms the baselines. The required reasoning can be
distilled into a lightweight Qwen3-4B model that enables efficient deployment.
All supplementary materials are accessible at
https://github.com/leeejia/T3_Planner.

</details>


### [340] [A Preliminary Exploration of the Differences and Conjunction of Traditional PNT and Brain-inspired PNT](https://arxiv.org/abs/2510.16771)
*Xu He,Xiaolin Meng,Wenxuan Yin,Youdong Zhang,Lingfei Mo,Xiangdong An,Fangwen Yu,Shuguo Pan,Yufeng Liu,Jingnan Liu,Yujia Zhang,Wang Gao*

Main category: cs.RO

TL;DR: 本文探讨如何通过脑启发空间认知导航提升无人机系统的PNT能力，提出四层融合框架，结合数值精度与脑启发智能，并展望未来发展。


<details>
  <summary>Details</summary>
Motivation: 开发更弹性、节能且具备认知能力的通用PNT系统，推动PNT从“工具导向”转向“认知驱动”。

Method: 通过多层次的比较分析（传统PNT、生物大脑PNT与脑启发PNT）和四层融合框架（观测-能力-决策-硬件），结合数值精度与脑启发智能。

Result: 提出了一个结合数值精度与脑启发智能的四层融合框架，并提供了未来脑启发PNT发展的前瞻性建议。

Conclusion: 本文提出了一种将传统PNT、生物大脑PNT与脑启发PNT相结合的创新框架，并展望了脑启发PNT的未来发展方向。

Abstract: Developing universal Positioning, Navigation, and Timing (PNT) is our
enduring goal. Today's complex environments demand PNT that is more resilient,
energy-efficient and cognitively capable. This paper asks how we can endow
unmanned systems with brain-inspired spatial cognition navigation while
exploiting the high precision of machine PNT to advance universal PNT. We
provide a new perspective and roadmap for shifting PNT from "tool-oriented" to
"cognition-driven". Contributions: (1) multi-level dissection of differences
among traditional PNT, biological brain PNT and brain-inspired PNT; (2) a
four-layer (observation-capability-decision-hardware) fusion framework that
unites numerical precision and brain-inspired intelligence; (3) forward-looking
recommendations for future development of brain-inspired PNT.

</details>


### [341] [C-Free-Uniform: A Map-Conditioned Trajectory Sampler for Model Predictive Path Integral Control](https://arxiv.org/abs/2510.16905)
*Yukang Cao,Rahul Moorthy,O. Goktug Poyrazoglu,Volkan Isler*

Main category: cs.RO

TL;DR: 提出C-Free-Uniform概念，通过考虑环境信息改进轨迹采样，集成到CFU-MPPI控制器后，在复杂导航任务中表现更优且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有轨迹采样机制生成的分布独立于环境，无法充分利用当前局部地图信息，限制了导航任务的成功率。

Method: 引入了自由配置空间均匀性（C-Free-Uniform）概念，并将其集成到新的模型预测路径积分（MPPI）控制器中。

Result: CFU-MPPI在复杂多边形环境中的导航任务中表现优于现有方法，成功率高且采样预算低。

Conclusion: CFU-MPPI控制器在具有挑战性的导航任务中表现出色，显著提高了成功率，同时减少了采样预算。

Abstract: Trajectory sampling is a key component of sampling-based control mechanisms.
Trajectory samplers rely on control input samplers, which generate control
inputs u from a distribution p(u | x) where x is the current state. We
introduce the notion of Free Configuration Space Uniformity (C-Free-Uniform for
short) which has two key features: (i) it generates a control input
distribution so as to uniformly sample the free configuration space, and (ii)
in contrast to previously introduced trajectory sampling mechanisms where the
distribution p(u | x) is independent of the environment, C-Free-Uniform is
explicitly conditioned on the current local map. Next, we integrate this
sampler into a new Model Predictive Path Integral (MPPI) Controller, CFU-MPPI.
Experiments show that CFU-MPPI outperforms existing methods in terms of success
rate in challenging navigation tasks in cluttered polygonal environments while
requiring a much smaller sampling budget.

</details>


### [342] [Design of an Affordable, Fully-Actuated Biomimetic Hand for Dexterous Teleoperation Systems](https://arxiv.org/abs/2510.16931)
*Zhaoliang Wan,Zida Zhou,Zetong Bi,Zehui Yang,Hao Ding,Hui Cheng*

Main category: cs.RO

TL;DR: RAPID Hand是首个低成本、20自由度的灵巧手原型，采用新型拟人化驱动方案和3D打印部件，测试显示其在灵巧遥操作中具有潜力。


<details>
  <summary>Details</summary>
Motivation: 解决灵巧遥操作中低成本、全驱动五指手稀缺的问题，以支持'从演示中学习'范式下的大规模真实机器人数据收集。

Method: 采用新型拟人化驱动与传动方案，结合优化的电机布局和结构设计，提升灵巧性。具体包括非拇指手指的通用指节传动方案和全向拇指驱动机制。

Result: 通过定量指标和定性测试评估RAPID Hand在灵巧遥操作系统中的表现，包括多指抓取、勺柄操作和类人钢琴演奏等任务。

Conclusion: RAPID Hand的20自由度全驱动设计在灵巧遥操作中展现出显著潜力。

Abstract: This paper addresses the scarcity of affordable, fully-actuated five-fingered
hands for dexterous teleoperation, which is crucial for collecting large-scale
real-robot data within the "Learning from Demonstrations" paradigm. We
introduce the prototype version of the RAPID Hand, the first low-cost,
20-degree-of-actuation (DoA) dexterous hand that integrates a novel
anthropomorphic actuation and transmission scheme with an optimized motor
layout and structural design to enhance dexterity. Specifically, the RAPID Hand
features a universal phalangeal transmission scheme for the non-thumb fingers
and an omnidirectional thumb actuation mechanism. Prioritizing affordability,
the hand employs 3D-printed parts combined with custom gears for easier
replacement and repair. We assess the RAPID Hand's performance through
quantitative metrics and qualitative testing in a dexterous teleoperation
system, which is evaluated on three challenging tasks: multi-finger retrieval,
ladle handling, and human-like piano playing. The results indicate that the
RAPID Hand's fully actuated 20-DoF design holds significant promise for
dexterous teleoperation.

</details>


### [343] [DINO-CVA: A Multimodal Goal-Conditioned Vision-to-Action Model for Autonomous Catheter Navigation](https://arxiv.org/abs/2510.17038)
*Pedram Fekri,Majid Roshanfar,Samuel Barbeau,Seyedfarzad Famouri,Thomas Looi,Dale Podolsky,Mehrdad Zadeh,Javad Dargahi*

Main category: cs.RO

TL;DR: DINO-CVA是一种多模态目标导向行为克隆框架，通过融合视觉和运动学数据实现自主导管导航，减少操作依赖并提高治疗可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有导管导航系统依赖手动操作，导致操作疲劳、辐射暴露增加和结果不一致，亟需智能自主解决方案。

Method: 提出了DINO-CVA，一种多模态目标导向行为克隆框架，融合视觉观察和操纵杆运动学到一个联合嵌入空间，通过专家演示自回归预测动作。

Result: DINO-CVA在动作预测上表现出高准确性，与仅基于运动学的基线性能相当，同时将预测基于解剖环境。

Conclusion: DINO-CVA框架证明了多模态、目标导向架构在导管导航中的可行性，为减少操作依赖性和提高导管治疗的可靠性迈出了重要一步。

Abstract: Cardiac catheterization remains a cornerstone of minimally invasive
interventions, yet it continues to rely heavily on manual operation. Despite
advances in robotic platforms, existing systems are predominantly follow-leader
in nature, requiring continuous physician input and lacking intelligent
autonomy. This dependency contributes to operator fatigue, more radiation
exposure, and variability in procedural outcomes. This work moves towards
autonomous catheter navigation by introducing DINO-CVA, a multimodal
goal-conditioned behavior cloning framework. The proposed model fuses visual
observations and joystick kinematics into a joint embedding space, enabling
policies that are both vision-aware and kinematic-aware. Actions are predicted
autoregressively from expert demonstrations, with goal conditioning guiding
navigation toward specified destinations. A robotic experimental setup with a
synthetic vascular phantom was designed to collect multimodal datasets and
evaluate performance. Results show that DINO-CVA achieves high accuracy in
predicting actions, matching the performance of a kinematics-only baseline
while additionally grounding predictions in the anatomical environment. These
findings establish the feasibility of multimodal, goal-conditioned
architectures for catheter navigation, representing an important step toward
reducing operator dependency and improving the reliability of catheterbased
therapies.

</details>


### [344] [Learning to Design Soft Hands using Reward Models](https://arxiv.org/abs/2510.17086)
*Xueqian Bai,Nicklas Hansen,Adabhav Singh,Michael T. Tolley,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 提出CEM-RM框架，通过遥操作数据优化软体机器人手设计，显著提升抓取成功率并减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 设计既具有高顺应性又能在多样化使用场景中保持功能的软体机器人手仍具挑战性。硬件与控制的协同设计虽能更好耦合形态与行为，但其高维搜索空间和仿真评估的高计算成本限制了效率。

Method: 提出了一种基于交叉熵方法和奖励模型（CEM-RM）的框架，通过预收集的遥操作数据优化肌腱驱动的软体机器人手设计，减少了设计评估的计算成本。

Result: 优化的软体机器人手在仿真和硬件实验中均显著提高了对多样化挑战性物体的抓取成功率，设计评估次数减少了一半以上。

Conclusion: 通过CEM-RM框架优化的软体机器人手在抓取成功率上显著优于基线设计，展示了该方法在软体机器人硬件和控制协同优化中的有效性。

Abstract: Soft robotic hands promise to provide compliant and safe interaction with
objects and environments. However, designing soft hands to be both compliant
and functional across diverse use cases remains challenging. Although co-design
of hardware and control better couples morphology to behavior, the resulting
search space is high-dimensional, and even simulation-based evaluation is
computationally expensive. In this paper, we propose a Cross-Entropy Method
with Reward Model (CEM-RM) framework that efficiently optimizes tendon-driven
soft robotic hands based on teleoperation control policy, reducing design
evaluations by more than half compared to pure optimization while learning a
distribution of optimized hand designs from pre-collected teleoperation data.
We derive a design space for a soft robotic hand composed of flexural soft
fingers and implement parallelized training in simulation. The optimized hands
are then 3D-printed and deployed in the real world using both teleoperation
data and real-time teleoperation. Experiments in both simulation and hardware
demonstrate that our optimized design significantly outperforms baseline hands
in grasping success rates across a diverse set of challenging objects.

</details>


### [345] [Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey](https://arxiv.org/abs/2510.17111)
*Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng*

Main category: cs.RO

TL;DR: 本文综述了提升VLA模型效率的方法，分类为模型架构、感知特征、动作生成和训练/推理策略，并探讨了未来挑战。


<details>
  <summary>Details</summary>
Motivation: VLA模型在具身控制中面临计算和内存需求与边缘平台实时性要求的冲突，亟需提升效率。

Method: 通过对现有研究的系统回顾，将解决方案分为四个维度：模型架构、感知特征、动作生成和训练/推理策略，并总结了每类中的代表性技术。

Result: 本文系统分类并总结了提升VLA效率的多种方法，为未来研究提供了方向。

Conclusion: 本文总结了提升视觉-语言-动作（VLA）模型效率的现有方法，并指出了未来研究方向，以推动高效具身智能的发展。

Abstract: Vision-Language-Action (VLA) models extend vision-language models to embodied
control by mapping natural-language instructions and visual observations to
robot actions. Despite their capabilities, VLA systems face significant
challenges due to their massive computational and memory demands, which
conflict with the constraints of edge platforms such as on-board mobile
manipulators that require real-time performance. Addressing this tension has
become a central focus of recent research. In light of the growing efforts
toward more efficient and scalable VLA systems, this survey provides a
systematic review of approaches for improving VLA efficiency, with an emphasis
on reducing latency, memory footprint, and training and inference costs. We
categorize existing solutions into four dimensions: model architecture,
perception feature, action generation, and training/inference strategies,
summarizing representative techniques within each category. Finally, we discuss
future trends and open challenges, highlighting directions for advancing
efficient embodied intelligence.

</details>


### [346] [Decentralized Real-Time Planning for Multi-UAV Cooperative Manipulation via Imitation Learning](https://arxiv.org/abs/2510.17143)
*Shantnav Agarwal,Javier Alonso-Mora,Sihao Sun*

Main category: cs.RO

TL;DR: 提出了一种基于模仿学习的去中心化动力学规划方法，无需代理间通信，性能接近集中式方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖集中式控制架构或可靠的代理间通信，限制了其应用场景。本文旨在解决在部分可观测性和无通信情况下的负载运输问题。

Method: 利用模仿学习训练每个无人机的分散学生策略，模仿具有全局观察权限的集中式动力学运动规划器。使用物理信息神经网络生成平滑轨迹。

Result: 在仿真和真实环境中验证了方法的有效性，能够跟随敏捷参考轨迹，性能与集中式方法相当。

Conclusion: 该论文提出了一种基于机器学习的去中心化动力学规划方法，能够在不依赖代理间通信的情况下有效操作，性能接近集中式方法。

Abstract: Existing approaches for transporting and manipulating cable-suspended loads
using multiple UAVs along reference trajectories typically rely on either
centralized control architectures or reliable inter-agent communication. In
this work, we propose a novel machine learning based method for decentralized
kinodynamic planning that operates effectively under partial observability and
without inter-agent communication. Our method leverages imitation learning to
train a decentralized student policy for each UAV by imitating a centralized
kinodynamic motion planner with access to privileged global observations. The
student policy generates smooth trajectories using physics-informed neural
networks that respect the derivative relationships in motion. During training,
the student policies utilize the full trajectory generated by the teacher
policy, leading to improved sample efficiency. Moreover, each student policy
can be trained in under two hours on a standard laptop. We validate our method
in both simulation and real-world environments to follow an agile reference
trajectory, demonstrating performance comparable to that of centralized
approaches.

</details>


### [347] [DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment](https://arxiv.org/abs/2510.17148)
*Yu Gao,Yiru Wang,Anqing Jiang,Heng Yuwen,Wang Shuo,Sun Hao,Wang Jijun*

Main category: cs.RO

TL;DR: DiffVLA++是一个结合认知推理和端到端规划的自动驾驶框架，通过度量引导的对齐提升了长尾场景的表现。


<details>
  <summary>Details</summary>
Motivation: 传统端到端驾驶模型缺乏必要的世界知识来理解和推理周围环境，而VLA模型虽然能处理挑战性案例，但其有限的3D推理能力可能导致物理上不可行的动作。

Method: 首先构建了一个直接生成语义基础驾驶轨迹的VLA模块，其次设计了一个确保物理可行性的端到端模块，并引入了度量引导的轨迹评分器来对齐两个模块的输出。

Result: 在ICCV 2025 Autonomous Grand Challenge排行榜上，DiffVLA++实现了49.12的EPDMS。

Conclusion: DiffVLA++通过结合认知推理和端到端规划的互补优势，显著提升了自动驾驶系统在长尾场景中的表现。

Abstract: Conventional end-to-end (E2E) driving models are effective at generating
physically plausible trajectories, but often fail to generalize to long-tail
scenarios due to the lack of essential world knowledge to understand and reason
about surrounding environments. In contrast, Vision-Language-Action (VLA)
models leverage world knowledge to handle challenging cases, but their limited
3D reasoning capability can lead to physically infeasible actions. In this work
we introduce DiffVLA++, an enhanced autonomous driving framework that
explicitly bridges cognitive reasoning and E2E planning through metric-guided
alignment. First, we build a VLA module directly generating semantically
grounded driving trajectories. Second, we design an E2E module with a dense
trajectory vocabulary that ensures physical feasibility. Third, and most
critically, we introduce a metric-guided trajectory scorer that guides and
aligns the outputs of the VLA and E2E modules, thereby integrating their
complementary strengths. The experiment on the ICCV 2025 Autonomous Grand
Challenge leaderboard shows that DiffVLA++ achieves EPDMS of 49.12.

</details>


### [348] [OmniVIC: A Self-Improving Variable Impedance Controller with Vision-Language In-Context Learning for Safe Robotic Manipulation](https://arxiv.org/abs/2510.17150)
*Heng Zhang,Wei-Hsing Huang,Gokhan Solak,Arash Ajoudani*

Main category: cs.RO

TL;DR: OmniVIC 是一种结合视觉语言模型和自我改进检索增强生成的通用可变阻抗控制器，显著提升机器人操作任务的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 传统可变阻抗控制器（VIC）在机器人物理交互中表现优异，但在未知、复杂和非结构化的任务场景中缺乏普适性，OmniVIC旨在通过语义推理和低级别合规控制的结合解决这一问题。

Method: OmniVIC 的核心是一个自我改进的RAG和ICL框架，通过从结构化记忆库中检索相关先验经验，并利用VLM生成上下文感知的自适应阻抗参数，同时结合实时力/力矩反馈确保交互力在安全阈值内。

Result: 在仿真和真实机器人任务中，OmniVIC在复杂接触密集型任务上表现优于基线方法，成功率和力违规率均显著改善。

Conclusion: OmniVIC 通过结合视觉语言模型（VLM）和自我改进的检索增强生成（RAG）及上下文学习（ICL），显著提升了接触密集型机器人操作任务的安全性和适应性，成功将平均成功率从27%提升至61.4%。

Abstract: We present OmniVIC, a universal variable impedance controller (VIC) enhanced
by a vision language model (VLM), which improves safety and adaptation in any
contact-rich robotic manipulation task to enhance safe physical interaction.
Traditional VIC have shown advantages when the robot physically interacts with
the environment, but lack generalization in unseen, complex, and unstructured
safe interactions in universal task scenarios involving contact or uncertainty.
To this end, the proposed OmniVIC interprets task context derived reasoning
from images and natural language and generates adaptive impedance parameters
for a VIC controller. Specifically, the core of OmniVIC is a self-improving
Retrieval-Augmented Generation(RAG) and in-context learning (ICL), where RAG
retrieves relevant prior experiences from a structured memory bank to inform
the controller about similar past tasks, and ICL leverages these retrieved
examples and the prompt of current task to query the VLM for generating
context-aware and adaptive impedance parameters for the current manipulation
scenario. Therefore, a self-improved RAG and ICL guarantee OmniVIC works in
universal task scenarios. The impedance parameter regulation is further
informed by real-time force/torque feedback to ensure interaction forces remain
within safe thresholds. We demonstrate that our method outperforms baselines on
a suite of complex contact-rich tasks, both in simulation and on real-world
robotic tasks, with improved success rates and reduced force violations.
OmniVIC takes a step towards bridging high-level semantic reasoning and
low-level compliant control, enabling safer and more generalizable
manipulation. Overall, the average success rate increases from 27% (baseline)
to 61.4% (OmniVIC).

</details>


### [349] [SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving](https://arxiv.org/abs/2510.17191)
*Peiru Zheng,Yun Zhao,Zhan Gong,Hong Zhu,Shaohua Wu*

Main category: cs.RO

TL;DR: SimpleVSF结合VLM和轨迹融合技术，提升自动驾驶决策质量，在ICCV 2025挑战赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶方法在复杂场景中决策表现不佳，需提升决策质量和适应性。

Method: 提出SimpleVSF框架，结合传统评分器和VLM增强评分器，通过定量聚合和定性上下文感知决策进行轨迹融合。

Result: 作为ICCV 2025 NAVSIM v2挑战赛的领先方法，SimpleVSF展现了最先进的性能。

Conclusion: SimpleVSF框架通过结合视觉语言模型和先进轨迹融合技术，显著提升了端到端自动驾驶规划的决策质量，实现了安全、舒适和效率的优异平衡。

Abstract: End-to-end autonomous driving has emerged as a promising paradigm for
achieving robust and intelligent driving policies. However, existing end-to-end
methods still face significant challenges, such as suboptimal decision-making
in complex scenarios. In this paper,we propose SimpleVSF (Simple VLM-Scoring
Fusion), a novel framework that enhances end-to-end planning by leveraging the
cognitive capabilities of Vision-Language Models (VLMs) and advanced trajectory
fusion techniques. We utilize the conventional scorers and the novel
VLM-enhanced scorers. And we leverage a robust weight fusioner for quantitative
aggregation and a powerful VLM-based fusioner for qualitative, context-aware
decision-making. As the leading approach in the ICCV 2025 NAVSIM v2 End-to-End
Driving Challenge, our SimpleVSF framework demonstrates state-of-the-art
performance, achieving a superior balance between safety, comfort, and
efficiency.

</details>


### [350] [Performance Evaluation of an Integrated System for Visible Light Communication and Positioning Using an Event Camera](https://arxiv.org/abs/2510.17203)
*Ryota Soga,Masataka Kobayashi,Tsukasa Shimizu,Shintaro Shiba,Quan Kong,Shan Lu,Takaya Yamazato*

Main category: cs.RO

TL;DR: 提出了一种基于事件相机的VLC-VLP集成系统，用于GPS受限环境中的车辆定位，实验验证了其高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为解决GPS在隧道等受限环境中失效的问题，研究探索了事件相机与可见光技术的结合潜力。

Method: 系统利用事件相机的高动态范围和高时间分辨率，通过Walsh-Hadamard码分配唯一导频序列给多个LED发射器，并使用相位相关(POC)进行距离估计。

Result: 实验表明，该系统在车辆以30 km/h速度行驶时，距离估计的均方根误差(RMSE)在100米范围内小于0.75米，误码率(BER)低于0.01。

Conclusion: 该研究成功开发了一种基于事件相机的新型自定位系统，结合可见光通信(VLC)和可见光定位(VLP)，在GPS受限环境中实现了车辆的高精度定位。

Abstract: Event cameras, featuring high temporal resolution and high dynamic range,
offer visual sensing capabilities comparable to conventional image sensors
while capturing fast-moving objects and handling scenes with extreme lighting
contrasts such as tunnel exits. Leveraging these properties, this study
proposes a novel self-localization system that integrates visible light
communication (VLC) and visible light positioning (VLP) within a single event
camera. The system enables a vehicle to estimate its position even in
GPS-denied environments, such as tunnels, by using VLC to obtain coordinate
information from LED transmitters and VLP to estimate the distance to each
transmitter.
  Multiple LEDs are installed on the transmitter side, each assigned a unique
pilot sequence based on Walsh-Hadamard codes. The event camera identifies
individual LEDs within its field of view by correlating the received signal
with these codes, allowing clear separation and recognition of each light
source. This mechanism enables simultaneous high-capacity MISO (multi-input
single-output) communication through VLC and precise distance estimation via
phase-only correlation (POC) between multiple LED pairs.
  To the best of our knowledge, this is the first vehicle-mounted system to
achieve simultaneous VLC and VLP functionalities using a single event camera.
Field experiments were conducted by mounting the system on a vehicle traveling
at 30 km/h (8.3 m/s). The results demonstrated robust real-world performance,
with a root mean square error (RMSE) of distance estimation within 0.75 m for
ranges up to 100 m and a bit error rate (BER) below 0.01 across the same range.

</details>


### [351] [Pole-Image: A Self-Supervised Pole-Anchored Descriptor for Long-Term LiDAR Localization and Map Maintenance](https://arxiv.org/abs/2510.17237)
*Wuhao Xie,Kanji Tanaka*

Main category: cs.RO

TL;DR: 论文提出“Pole-Image”方法，利用杆状地标及其周围环境生成2D极坐标图像，结合对比学习实现鲁棒自我定位和高灵敏度地图维护。


<details>
  <summary>Details</summary>
Motivation: 长期自主性对移动机器人需要鲁棒的自我定位和可靠的地图维护。传统地标方法在高可检测性但低独特性（如杆状物）与高独特性但难以稳定检测（如局部点云结构）之间存在根本性权衡。论文旨在通过结合杆状地标的高检测性和周围点云的独特性，解决这一挑战。

Method: 论文提出了一种新颖的规范表示方法“Pole-Image”，该方法利用杆状地标作为锚点，从周围的3D结构中生成签名。Pole-Image将杆状地标及其周围环境表示为以杆为原点的2D极坐标图像，通过显式编码稳定杆与可变周围点云之间的“相对几何关系”，实现了高精度的参考点。

Result: 通过Pole-Image表示和对比学习，模型学习到了视角不变且高度区分的描述符。该描述符克服了感知混淆，实现了鲁棒的自我定位，同时高精度编码实现了高灵敏度的变化检测，为地图维护提供了支持。

Conclusion: 该论文提出了一种名为“Pole-Image”的混合方法，通过将杆状地标及其周围环境表示为2D极坐标图像，解决了移动机器人在长期自主性中面临的自我定位和地图维护的挑战。这种方法结合了杆状地标的高检测性和对比学习的优势，实现了鲁棒的自我定位和高灵敏度的变化检测。

Abstract: Long-term autonomy for mobile robots requires both robust self-localization
and reliable map maintenance. Conventional landmark-based methods face a
fundamental trade-off between landmarks with high detectability but low
distinctiveness (e.g., poles) and those with high distinctiveness but difficult
stable detection (e.g., local point cloud structures). This work addresses the
challenge of descriptively identifying a unique "signature" (local point cloud)
by leveraging a detectable, high-precision "anchor" (like a pole). To solve
this, we propose a novel canonical representation, "Pole-Image," as a hybrid
method that uses poles as anchors to generate signatures from the surrounding
3D structure. Pole-Image represents a pole-like landmark and its surrounding
environment, detected from a LiDAR point cloud, as a 2D polar coordinate image
with the pole itself as the origin. This representation leverages the pole's
nature as a high-precision reference point, explicitly encoding the "relative
geometry" between the stable pole and the variable surrounding point cloud. The
key advantage of pole landmarks is that "detection" is extremely easy. This
ease of detection allows the robot to easily track the same pole, enabling the
automatic and large-scale collection of diverse observational data (positive
pairs). This data acquisition feasibility makes "Contrastive Learning (CL)"
applicable. By applying CL, the model learns a viewpoint-invariant and highly
discriminative descriptor. The contributions are twofold: 1) The descriptor
overcomes perceptual aliasing, enabling robust self-localization. 2) The
high-precision encoding enables high-sensitivity change detection, contributing
to map maintenance.

</details>


### [352] [An adaptive hierarchical control framework for quadrupedal robots in planetary exploration](https://arxiv.org/abs/2510.17249)
*Franek Stark,Rohit Kumar,Shubham Vyas,Hannah Isermann,Jonas Haack,Mihaela Popescu,Jakob Middelberg,Dennis Mronga,Frank Kirchner*

Main category: cs.RO

TL;DR: 研究提出了一种模块化控制框架，结合模型基础动态控制和在线适应，使四足机器人能在未知地形中高效导航，实地测试表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决四足机器人在未知和极端环境中的导航挑战，特别是在地形和机器人参数不确定的情况下，需要一种能够动态适应环境的控制方法。

Method: 该框架结合了模型基础动态控制、在线模型适应和自适应脚步规划，支持状态估计（有无接触传感均可），并能在运行时重新配置。

Result: 该框架在两种四足机器人平台、多种硬件架构上进行了验证，并在火山实地测试中成功行走超过700米。

Conclusion: 该研究提出的模块化控制框架成功解决了四足机器人在未知和极端环境中的导航问题，通过结合模型基础动态控制和在线模型适应，显著提升了机器人在不确定地形和机器人参数下的性能。

Abstract: Planetary exploration missions require robots capable of navigating extreme
and unknown environments. While wheeled rovers have dominated past missions,
their mobility is limited to traversable surfaces. Legged robots, especially
quadrupeds, can overcome these limitations by handling uneven, obstacle-rich,
and deformable terrains. However, deploying such robots in unknown conditions
is challenging due to the need for environment-specific control, which is
infeasible when terrain and robot parameters are uncertain. This work presents
a modular control framework that combines model-based dynamic control with
online model adaptation and adaptive footstep planning to address uncertainties
in both robot and terrain properties. The framework includes state estimation
for quadrupeds with and without contact sensing, supports runtime
reconfiguration, and is integrated into ROS 2 with open-source availability.
Its performance was validated on two quadruped platforms, multiple hardware
architectures, and in a volcano field test, where the robot walked over 700 m.

</details>


### [353] [High-Level Multi-Robot Trajectory Planning And Spurious Behavior Detection](https://arxiv.org/abs/2510.17261)
*Fernando Salanova,Jesús Roche,Cristian Mahuela,Eduardo Montijano*

Main category: cs.RO

TL;DR: 提出基于Nets-within-Nets和Transformer的方法，高效检测多机器人系统中的异常行为，实验显示高准确率。


<details>
  <summary>Details</summary>
Motivation: 多机器人系统中异构代理执行高级任务时，需要可靠的方法检测异常行为以确保任务顺利完成。

Method: 引入结构化数据生成框架（基于Nets-within-Nets范式）协调机器人行动与LTL全局任务规范，并采用Transformer异常检测流程分类机器人轨迹。

Result: 实验评估显示，该方法在执行效率识别上达到91.3%的准确率，核心任务违规检测率为88.3%，约束自适应异常检测率为66.8%。

Conclusion: 本文提出的基于Nets-within-Nets范式的方法和Transformer异常检测流程在多机器人系统中表现出色，能够高效识别异常行为并提升任务执行的可靠性。

Abstract: The reliable execution of high-level missions in multi-robot systems with
heterogeneous agents, requires robust methods for detecting spurious behaviors.
In this paper, we address the challenge of identifying spurious executions of
plans specified as a Linear Temporal Logic (LTL) formula, as incorrect task
sequences, violations of spatial constraints, timing inconsis- tencies, or
deviations from intended mission semantics. To tackle this, we introduce a
structured data generation framework based on the Nets-within-Nets (NWN)
paradigm, which coordinates robot actions with LTL-derived global mission
specifications. We further propose a Transformer-based anomaly detection
pipeline that classifies robot trajectories as normal or anomalous. Experi-
mental evaluations show that our method achieves high accuracy (91.3%) in
identifying execution inefficiencies, and demonstrates robust detection
capabilities for core mission violations (88.3%) and constraint-based adaptive
anomalies (66.8%). An ablation experiment of the embedding and architecture was
carried out, obtaining successful results where our novel proposition performs
better than simpler representations.

</details>


### [354] [Floating-Base Deep Lagrangian Networks](https://arxiv.org/abs/2510.17270)
*Lucas Schulze,Juliano Decico Negri,Victor Barasuol,Vivian Suzano Medeiros,Marcelo Becker,Jan Peters,Oleg Arenz*

Main category: cs.RO

TL;DR: 提出了一种物理约束的深度学习模型FeLaN，用于浮动基系统识别，表现优异且物理可解释性强。


<details>
  <summary>Details</summary>
Motivation: 当前灰盒模型忽略了浮动基系统（如人形机器人和四足机器人）的特定物理约束，导致物理一致性不足。

Method: 结合深度学习与物理约束，提出了一种满足所有约束条件的惯性矩阵参数化方法，并训练神经网络预测物理上合理的惯性矩阵。

Result: FeLaN 在多个人形机器人和四足机器人数据集上表现优异，且物理一致性更强。

Conclusion: Floating-Base Deep Lagrangian Networks (FeLaN) 在模拟和真实机器人上表现出色，同时提供了更高的物理可解释性。

Abstract: Grey-box methods for system identification combine deep learning with
physics-informed constraints, capturing complex dependencies while improving
out-of-distribution generalization. Yet, despite the growing importance of
floating-base systems such as humanoids and quadrupeds, current grey-box models
ignore their specific physical constraints. For instance, the inertia matrix is
not only positive definite but also exhibits branch-induced sparsity and input
independence. Moreover, the 6x6 composite spatial inertia of the floating base
inherits properties of single-rigid-body inertia matrices. As we show, this
includes the triangle inequality on the eigenvalues of the composite rotational
inertia. To address the lack of physical consistency in deep learning models of
floating-base systems, we introduce a parameterization of inertia matrices that
satisfies all these constraints. Inspired by Deep Lagrangian Networks (DeLaN),
we train neural networks to predict physically plausible inertia matrices that
minimize inverse dynamics error under Lagrangian mechanics. For evaluation, we
collected and released a dataset on multiple quadrupeds and humanoids. In these
experiments, our Floating-Base Deep Lagrangian Networks (FeLaN) achieve highly
competitive performance on both simulated and real robots, while providing
greater physical interpretability.

</details>


### [355] [Implicit State Estimation via Video Replanning](https://arxiv.org/abs/2510.17315)
*Po-Chen Ko,Jiayuan Mao,Yu-Hsiang Fu,Hsien-Jeng Yeh,Chu-Rong Chen,Wei-Chiu Ma,Yilun Du,Shao-Hua Sun*

Main category: cs.RO

TL;DR: 论文提出了一种集成交互时间数据的视频规划框架，通过在线更新和过滤失败计划，实现动态适应和隐式状态估计，提升了重新规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频规划框架难以适应交互时的失败，主要因为无法处理部分观测环境中的不确定性。

Method: 该框架将交互时间数据集成到规划过程中，在线更新模型参数并过滤失败计划，实现隐式状态估计。

Result: 通过在新模拟操作基准上的广泛实验，证明了该框架能够提升重新规划性能，并推动视频决策领域的发展。

Conclusion: 论文提出了一个新颖的框架，通过在线更新模型参数和过滤失败计划，实现了动态适应和隐式状态估计，从而提升了视频规划的重新规划性能。

Abstract: Video-based representations have gained prominence in planning and
decision-making due to their ability to encode rich spatiotemporal dynamics and
geometric relationships. These representations enable flexible and
generalizable solutions for complex tasks such as object manipulation and
navigation. However, existing video planning frameworks often struggle to adapt
to failures at interaction time due to their inability to reason about
uncertainties in partially observed environments. To overcome these
limitations, we introduce a novel framework that integrates interaction-time
data into the planning process. Our approach updates model parameters online
and filters out previously failed plans during generation. This enables
implicit state estimation, allowing the system to adapt dynamically without
explicitly modeling unknown state variables. We evaluate our framework through
extensive experiments on a new simulated manipulation benchmark, demonstrating
its ability to improve replanning performance and advance the field of
video-based decision-making.

</details>


### [356] [DDBot: Differentiable Physics-based Digging Robot for Unknown Granular Materials](https://arxiv.org/abs/2510.17335)
*Xintong Yang,Minglun Wei,Ze Ji,Yu-Kun Lai*

Main category: cs.RO

TL;DR: DDBot 是一个基于可微分物理的框架，用于高效、高精度的颗粒材料挖掘任务，实验验证了其快速收敛和实际部署能力。


<details>
  <summary>Details</summary>
Motivation: 颗粒材料操作面临复杂接触动力学、不可预测材料特性和系统状态等挑战，现有方法效率与准确性不足。

Method: DDBot 配备了一个基于可微分物理的模拟器，支持 GPU 加速并行计算和自动微分，通过可微分系统识别和高精度挖掘技能优化实现任务。

Result: 实验显示 DDBot 能在 5 至 20 分钟内高效识别未知颗粒材料动态并优化挖掘技能，零样本实际部署中表现高精度。

Conclusion: DDBot 框架在未知物理特性的颗粒材料挖掘任务中表现出高效性和高精度，实验验证了其在实际应用中的实用性和鲁棒性。

Abstract: Automating the manipulation of granular materials poses significant
challenges due to complex contact dynamics, unpredictable material properties,
and intricate system states. Existing approaches often fail to achieve
efficiency and accuracy in such tasks. To fill the research gap, this paper
studies the small-scale and high-precision granular material digging task with
unknown physical properties. A new framework, named differentiable digging
robot (DDBot), is proposed to manipulate granular materials, including sand and
soil.
  Specifically, we equip DDBot with a differentiable physics-based simulator,
tailored for granular material manipulation, powered by GPU-accelerated
parallel computing and automatic differentiation. DDBot can perform efficient
differentiable system identification and high-precision digging skill
optimisation for unknown granular materials, which is enabled by a
differentiable skill-to-action mapping, a task-oriented demonstration method,
gradient clipping and line search-based gradient descent.
  Experimental results show that DDBot can efficiently (converge within 5 to 20
minutes) identify unknown granular material dynamics and optimise digging
skills, with high-precision results in zero-shot real-world deployments,
highlighting its practicality. Benchmark results against state-of-the-art
baselines also confirm the robustness and efficiency of DDBot in such digging
tasks.

</details>


### [357] [Interactive Force-Impedance Control](https://arxiv.org/abs/2510.17341)
*Fan Shao,Satoshi Endo,Sandra Hirche,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 论文提出了一种统一的交互力-阻抗控制框架，确保机器人在接触密集环境中安全交互。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在与主动人类或非被动环境物理交互时可能失去被动性从而危及安全的问题。

Method: 提出统一的交互力-阻抗控制（IFIC）框架，结合端口哈密顿框架，通过交互和任务控制端口实现系统被动性。

Result: IFIC框架能够适应交互功率流，确保在接触密集环境中的轻松和安全交互。

Conclusion: 论文提出了一种统一的交互力-阻抗控制（IFIC）框架，通过适应交互功率流，确保在接触密集环境中的轻松和安全交互。控制架构在端口哈密顿框架内制定，通过交互和任务控制端口保证系统被动性。

Abstract: Human collaboration with robots requires flexible role adaptation, enabling
robot to switch between active leader and passive follower. Effective role
switching depends on accurately estimating human intention, which is typically
achieved through external force analysis, nominal robot dynamics, or
data-driven approaches. However, these methods are primarily effective in
contact-sparse environments. When robots under hybrid or unified
force-impedance control physically interact with active humans or non-passive
environments, the robotic system may lose passivity and thus compromise safety.
To address this challenge, this paper proposes the unified Interactive
Force-Impedance Control (IFIC) framework that adapts to the interaction power
flow, ensuring effortless and safe interaction in contact-rich environments.
The proposed control architecture is formulated within a port-Hamiltonian
framework, incorporating both interaction and task control ports, through which
system passivity is guaranteed.

</details>


### [358] [Bridging Embodiment Gaps: Deploying Vision-Language-Action Models on Soft Robots](https://arxiv.org/abs/2510.17369)
*Haochen Su,Cristian Meo,Francesco Stella,Andrea Peirone,Kai Junge,Josie Hughes*

Main category: cs.RO

TL;DR: 研究展示了VLA模型在软体连续机械臂上的应用，通过微调实现安全人机交互，性能与刚性机械臂相当。


<details>
  <summary>Details</summary>
Motivation: 解决软体连续机械臂在人机交互中的安全性和适应性需求，填补VLA模型在非传统机械臂上部署的空白。

Method: 提出了结构化的微调和部署流程，评估了两种最先进的VLA模型（OpenVLA-OFT和π0）在代表性操作任务中的表现。

Result: 通过针对性微调，软体机器人表现与刚性机械臂相当，证实微调对于弥补构型差异的必要性。

Conclusion: 结合VLA模型与软体机器人可以实现安全、灵活的具身AI在人机共享环境中的应用。

Abstract: Robotic systems are increasingly expected to operate in human-centered,
unstructured environments where safety, adaptability, and generalization are
essential. Vision-Language-Action (VLA) models have been proposed as a language
guided generalized control framework for real robots. However, their deployment
has been limited to conventional serial link manipulators. Coupled by their
rigidity and unpredictability of learning based control, the ability to safely
interact with the environment is missing yet critical. In this work, we present
the deployment of a VLA model on a soft continuum manipulator to demonstrate
autonomous safe human-robot interaction. We present a structured finetuning and
deployment pipeline evaluating two state-of-the-art VLA models (OpenVLA-OFT and
$\pi_0$) across representative manipulation tasks, and show while
out-of-the-box policies fail due to embodiment mismatch, through targeted
finetuning the soft robot performs equally to the rigid counterpart. Our
findings highlight the necessity of finetuning for bridging embodiment gaps,
and demonstrate that coupling VLA models with soft robots enables safe and
flexible embodied AI in human-shared environments.

</details>


### [359] [Integrating Trustworthy Artificial Intelligence with Energy-Efficient Robotic Arms for Waste Sorting](https://arxiv.org/abs/2510.17408)
*Halima I. Kure,Jishna Retnakumari,Augustine O. Nwajana,Umar M. Ismail,Bilyaminu A. Romo,Ehigiator Egho-Promise*

Main category: cs.RO

TL;DR: 结合可信AI和节能机械臂的智能废物分类系统，通过CNN和迁移学习实现高准确率分类，机械臂模拟器优化能耗。


<details>
  <summary>Details</summary>
Motivation: 旨在解决城市废物管理的智能化需求，结合可信AI和节能技术，提升分类效率和可靠性。

Method: 通过使用MobileNetV2增强的卷积神经网络（CNN）进行迁移学习，系统将废物准确分类为六类。此外，还实现了机械臂模拟器进行虚拟分拣，并通过欧几里得距离计算每个动作的能耗。

Result: 模型在训练中达到99.8%的准确率，验证准确率为80.5%，展示了强大的学习和泛化能力。机械臂模拟器确保了高效节能的运动。

Conclusion: 该论文提出了一个结合可信人工智能与节能机械臂的智能废物分类和分拣系统，展示了其在城市智能废物管理中的可靠性和可扩展性。

Abstract: This paper presents a novel methodology that integrates trustworthy
artificial intelligence (AI) with an energy-efficient robotic arm for
intelligent waste classification and sorting. By utilizing a convolutional
neural network (CNN) enhanced through transfer learning with MobileNetV2, the
system accurately classifies waste into six categories: plastic, glass, metal,
paper, cardboard, and trash. The model achieved a high training accuracy of
99.8% and a validation accuracy of 80.5%, demonstrating strong learning and
generalization. A robotic arm simulator is implemented to perform virtual
sorting, calculating the energy cost for each action using Euclidean distance
to ensure optimal and efficient movement. The framework incorporates key
elements of trustworthy AI, such as transparency, robustness, fairness, and
safety, making it a reliable and scalable solution for smart waste management
systems in urban settings.

</details>


### [360] [From Spatial to Actions: Grounding Vision-Language-Action Model in Spatial Foundation Priors](https://arxiv.org/abs/2510.17439)
*Zhengshen Zhang,Hao Li,Yalun Dai,Zhengbang Zhu,Lei Zhou,Chenchen Liu,Dong Wang,Francis E. H. Tay,Sijin Chen,Ziwei Liu,Yuxiao Liu,Xinghang Li,Pan Zhou*

Main category: cs.RO

TL;DR: FALCON通过注入3D空间标记和增强动作头，解决了VLA模型的空间推理和模态迁移问题，在多项任务中实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于2D编码器的VLA模型在3D真实世界中存在空间推理差距，限制了泛化能力和适应性。

Method: FALCON利用空间基础模型从RGB中提取强几何先验，并包含一个可选的Embodied Spatial Model以融合深度或姿态信息，同时通过Spatial-Enhanced Action Head保持语言推理能力。

Result: 在三个模拟基准和十一个现实任务中，FALCON表现优于竞争基线，并在杂乱、空间提示条件和对象尺度变化等情况下保持稳健。

Conclusion: FALCON通过引入丰富的3D空间标记到动作头，有效解决了现有VLA模型在空间推理、模态迁移和对齐方面的局限性，在多个基准测试和现实任务中实现了最先进的性能。

Abstract: Existing vision-language-action (VLA) models act in 3D real-world but are
typically built on 2D encoders, leaving a spatial reasoning gap that limits
generalization and adaptability. Recent 3D integration techniques for VLAs
either require specialized sensors and transfer poorly across modalities, or
inject weak cues that lack geometry and degrade vision-language alignment. In
this work, we introduce FALCON (From Spatial to Action), a novel paradigm that
injects rich 3D spatial tokens into the action head. FALCON leverages spatial
foundation models to deliver strong geometric priors from RGB alone, and
includes an Embodied Spatial Model that can optionally fuse depth, or pose for
higher fidelity when available, without retraining or architectural changes. To
preserve language reasoning, spatial tokens are consumed by a Spatial-Enhanced
Action Head rather than being concatenated into the vision-language backbone.
These designs enable FALCON to address limitations in spatial representation,
modality transferability, and alignment. In comprehensive evaluations across
three simulation benchmarks and eleven real-world tasks, our proposed FALCON
achieves state-of-the-art performance, consistently surpasses competitive
baselines, and remains robust under clutter, spatial-prompt conditioning, and
variations in object scale and height.

</details>


### [361] [A Generalization of Input-Output Linearization via Dynamic Switching Between Melds of Output Functions](https://arxiv.org/abs/2510.17448)
*Mirko Mizzoni,Pieter van Goor,Barbara Bazzana,Antonio Franchi*

Main category: cs.RO

TL;DR: 本文提出了一种系统框架，用于在非线性系统中切换反馈线性化输出集，通过‘meld’概念和正式证明，确保切换过程中系统的稳定性和无缝跟踪。


<details>
  <summary>Details</summary>
Motivation: 非线性系统的控制通常需要处理多个输出集之间的切换问题，而现有方法缺乏系统的理论支持。本文旨在填补这一空白，提供一个通用的理论框架，确保在切换过程中系统的稳定性和性能。

Method: 本文提出了一种系统框架，引入‘meld’概念来定义有效的反馈线性化输出子集，并提供了正式的数学证明，确保在切换过程中系统状态的均匀有界性和误差动态的指数稳定性。

Result: 在适当的停留时间和兼容性条件下，系统可以在不同meld之间切换，同时保证状态的均匀有界性和误差动态的指数稳定性。连续meld共有的输出在转换过程中可以无缝跟踪。

Conclusion: 本文提出了一种系统框架，用于通过反馈线性化在非线性系统的不同输出集之间切换。通过引入‘meld’概念，正式定义了可以从更大输出集合中选择的有效、可反馈线性化输出子集。主要贡献是正式证明，在适当的停留时间和兼容性条件下，可以在不同meld之间切换，同时保证系统状态的均匀有界性。此外，还证明了在每次切换间隔内，活动输出的误差动态保持指数稳定，且连续meld共有的输出在转换过程中可以无缝跟踪。该理论适用于任何可反馈线性化的非线性系统，如机器人、空中和地面车辆等，并通过一个简单的机械臂数值模拟进行了验证。

Abstract: This letter presents a systematic framework for switching between different
sets of outputs for the control of nonlinear systems via feedback
linearization. We introduce the concept of a meld to formally define a valid,
feedback-linearizable subset of outputs that can be selected from a larger deck
of possible outputs. The main contribution is a formal proof establishing that
under suitable dwell-time and compatibility conditions, it is possible to
switch between different melds while guaranteeing the uniform boundedness of
the system state. We further show that the error dynamics of the active outputs
remain exponentially stable within each switching interval and that outputs
common to consecutive melds are tracked seamlessly through transitions. The
proposed theory is valid for any feedback linearizable nonlinear system, such
as, e.g., robots, aerial and terrestrial vehicles, etc.. We demonstrate it on a
simple numerical simulation of a robotic manipulator.

</details>


### [362] [HumanMPC - Safe and Efficient MAV Navigation among Humans](https://arxiv.org/abs/2510.17525)
*Simon Schaefer,Helen Oleynikova,Sandra Hirche,Stefan Leutenegger*

Main category: cs.RO

TL;DR: HumanMPC是一个结合安全保证和数据驱动模型的3D无人机导航框架，有效且安全。


<details>
  <summary>Details</summary>
Motivation: 现有方法多局限于简化的2D人群导航，未能充分考虑人体动力学的复杂性。

Method: 结合理论安全保证与数据驱动模型，提出了一种新颖的基于可达性的安全约束方法，仅约束初始控制输入以确保安全。

Result: 在模拟实验和现实世界中验证了HumanMPC的有效性，涵盖目标导航和视觉伺服跟踪等任务。

Conclusion: HumanMPC框架在确保安全的同时避免了过度保守，且在效率和可靠性上优于基线方法，适用于多种平台。

Abstract: Safe and efficient robotic navigation among humans is essential for
integrating robots into everyday environments. Most existing approaches focus
on simplified 2D crowd navigation and fail to account for the full complexity
of human body dynamics beyond root motion. We present HumanMPC, a Model
Predictive Control (MPC) framework for 3D Micro Air Vehicle (MAV) navigation
among humans that combines theoretical safety guarantees with data-driven
models for realistic human motion forecasting. Our approach introduces a novel
twist to reachability-based safety formulation that constrains only the initial
control input for safety while modeling its effects over the entire planning
horizon, enabling safe yet efficient navigation. We validate HumanMPC in both
simulated experiments using real human trajectories and in the real-world,
demonstrating its effectiveness across tasks ranging from goal-directed
navigation to visual servoing for human tracking. While we apply our method to
MAVs in this work, it is generic and can be adapted by other platforms. Our
results show that the method ensures safety without excessive conservatism and
outperforms baseline approaches in both efficiency and reliability.

</details>


### [363] [Distributed Spatial-Temporal Trajectory Optimization for Unmanned-Aerial-Vehicle Swarm](https://arxiv.org/abs/2510.17541)
*Xiaobo Zheng,Pan Tang,Defu Lin,Shaoming He*

Main category: cs.RO

TL;DR: 论文提出了一种结合ADMM和PDDP的分布式算法D-PDDP，用于解决大规模无人机群的轨迹优化问题，并通过仿真验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因需要预先设定代理的最终时间且迭代次数多、耗时长，难以应用于大规模无人机群的轨迹优化问题。

Method: 论文采用了两层架构：使用PDDP作为单个无人机的轨迹优化器，ADMM用于满足局部约束并实现所有无人机间的时空参数共识。此外，还提出了基于谱梯度法的惩罚参数自适应调整准则以减少迭代次数。

Result: 提出的D-PDDP算法在多个仿真例子中验证了其有效性，能够高效解决多无人机共识问题。

Conclusion: 论文提出了一种名为D-PDDP的分布式算法，通过结合ADMM和PDDP，有效解决了大规模无人机群轨迹优化问题，并通过仿真验证了其有效性。

Abstract: Swarm trajectory optimization problems are a well-recognized class of
multi-agent optimal control problems with strong nonlinearity. However, the
heuristic nature of needing to set the final time for agents beforehand and the
time-consuming limitation of the significant number of iterations prohibit the
application of existing methods to large-scale swarm of Unmanned Aerial
Vehicles (UAVs) in practice. In this paper, we propose a spatial-temporal
trajectory optimization framework that accomplishes multi-UAV consensus based
on the Alternating Direction Multiplier Method (ADMM) and uses Differential
Dynamic Programming (DDP) for fast local planning of individual UAVs. The
introduced framework is a two-level architecture that employs Parameterized DDP
(PDDP) as the trajectory optimizer for each UAV, and ADMM to satisfy the local
constraints and accomplish the spatial-temporal parameter consensus among all
UAVs. This results in a fully distributed algorithm called Distributed
Parameterized DDP (D-PDDP). In addition, an adaptive tuning criterion based on
the spectral gradient method for the penalty parameter is proposed to reduce
the number of algorithmic iterations. Several simulation examples are presented
to verify the effectiveness of the proposed algorithm.

</details>


### [364] [Intent-Driven LLM Ensemble Planning for Flexible Multi-Robot Disassembly: Demonstration on EV Batteries](https://arxiv.org/abs/2510.17576)
*Cansu Erdogan,Cesar Alan Contreras,Alireza Rastegarpanah,Manolis Chiou,Rustam Stolkin*

Main category: cs.RO

TL;DR: 论文提出了一种意图驱动的多机器人任务规划管道，通过整合感知、LLM生成与验证，实现了高效、安全的协作任务执行。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人在非结构化场景中规划复杂操作任务的问题，这些机器人具有不同的末端执行器和能力，需要通过计算机视觉和简单语言指令进行协作。

Method: 管道整合了感知到文本的场景编码、基于大型语言模型（LLM）的候选移除序列生成、LLM验证器强制执行格式和优先级约束，以及确定性一致性过滤器拒绝幻觉对象。

Result: 在200个真实场景和600个操作员提示的评估中，使用全序列正确性和下一任务正确性指标，验证了管道组件的有效性。LLM人机界面在执行时间和NASA TLX方面也表现良好。

Conclusion: 该论文提出的意图驱动规划管道能够可靠地将操作员意图映射为安全、可执行的多机器人计划，同时保持较低的用户努力。

Abstract: This paper addresses the problem of planning complex manipulation tasks, in
which multiple robots with different end-effectors and capabilities, informed
by computer vision, must plan and execute concatenated sequences of actions on
a variety of objects that can appear in arbitrary positions and configurations
in unstructured scenes. We propose an intent-driven planning pipeline which can
robustly construct such action sequences with varying degrees of supervisory
input from a human using simple language instructions. The pipeline integrates:
(i) perception-to-text scene encoding, (ii) an ensemble of large language
models (LLMs) that generate candidate removal sequences based on the operator's
intent, (iii) an LLM-based verifier that enforces formatting and precedence
constraints, and (iv) a deterministic consistency filter that rejects
hallucinated objects. The pipeline is evaluated on an example task in which two
robot arms work collaboratively to dismantle an Electric Vehicle battery for
recycling applications. A variety of components must be grasped and removed in
specific sequences, determined by human instructions and/or by task-order
feasibility decisions made by the autonomous system. On 200 real scenes with
600 operator prompts across five component classes, we used metrics of
full-sequence correctness and next-task correctness to evaluate and compare
five LLM-based planners (including ablation analyses of pipeline components).
We also evaluated the LLM-based human interface in terms of time to execution
and NASA TLX with human participant experiments. Results indicate that our
ensemble-with-verification approach reliably maps operator intent to safe,
executable multi-robot plans while maintaining low user effort.

</details>


### [365] [Learned Inertial Odometry for Cycling Based on Mixture of Experts Algorithm](https://arxiv.org/abs/2510.17604)
*Hao Qiao,Yan Wang,Shuo Yang,Xiaoyao Yu,Jian kuang,Xiaoji Niu*

Main category: cs.RO

TL;DR: 通过改进的MoE模型，实现了自行车定位的高精度与低成本，参数和计算开销大幅减少。


<details>
  <summary>Details</summary>
Motivation: 传统的GNSS方法和惯性导航方法在自行车定位中存在多路径效应和鲁棒性不足的问题，TLIO虽能减少位置漂移，但计算成本高，难以在移动设备上部署。

Method: 将TLIO扩展到自行车定位，并引入改进的Mixture-of-Experts（MoE）模型，以减少训练和推理成本。

Result: 相比LLIO框架，该方法在保持精度的同时，参数减少了64.7%，计算成本降低了81.8%。

Conclusion: 改进的Mixture-of-Experts（MoE）模型在自行车定位中实现了与现有技术相当的精度，同时显著减少了参数数量和计算成本。

Abstract: With the rapid growth of bike sharing and the increasing diversity of cycling
applications, accurate bicycle localization has become essential. traditional
GNSS-based methods suffer from multipath effects, while existing inertial
navigation approaches rely on precise modeling and show limited robustness.
Tight Learned Inertial Odometry (TLIO) achieves low position drift by combining
raw IMU data with predicted displacements by neural networks, but its high
computational cost restricts deployment on mobile devices. To overcome this, we
extend TLIO to bicycle localization and introduce an improved Mixture-of
Experts (MoE) model that reduces both training and inference costs. Experiments
show that, compared to the state-of-the-art LLIO framework, our method achieves
comparable accuracy while reducing parameters by 64.7% and computational cost
by 81.8%.

</details>


### [366] [RESample: A Robust Data Augmentation Framework via Exploratory Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.17640)
*Yuquan Xue,Guanxing Lu,Zhenyu Wu,Chuanrui Zhang,Bofang Jia,Zhengyi Gu,Yansong Tang,Ziwei Wang*

Main category: cs.RO

TL;DR: RESample通过探索性采样增强VLA模型在OOD状态下的恢复能力，提升其鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习数据集仅包含成功轨迹，缺乏失败或恢复数据，导致VLA模型在偏离训练分布的OOD状态下表现不佳。

Method: 利用离线强化学习获取动作价值网络，识别次优动作，并通过rollout采样潜在OOD状态，设计探索性采样机制将这些动作代理纳入训练数据集。

Result: 在LIBERO基准和实际机器人操作任务中，RESample持续提升了VLA模型的稳定性和泛化能力。

Conclusion: RESample框架通过探索性采样增强了VLA模型在OOD状态下的恢复能力，显著提升了其稳定性和泛化能力。

Abstract: Vision-Language-Action models (VLAs) have demonstrated remarkable performance
on complex robotic manipulation tasks through imitation learning. However,
existing imitation learning datasets contain only successful trajectories and
lack failure or recovery data, especially for out-of-distribution (OOD) states
where the robot deviates from the main policy due to minor perturbations or
errors, leading VLA models to struggle with states deviating from the training
distribution. To this end, we propose an automated OOD data augmentation
framework named RESample through exploratory sampling. Specifically, we first
leverage offline reinforcement learning to obtain an action-value network that
accurately identifies sub-optimal actions under the current manipulation
policy. We further sample potential OOD states from trajectories via rollout,
and design an exploratory sampling mechanism that adaptively incorporates these
action proxies into the training dataset to ensure efficiency. Subsequently,
our framework explicitly encourages the VLAs to recover from OOD states and
enhances their robustness against distributional shifts. We conduct extensive
experiments on the LIBERO benchmark as well as real-world robotic manipulation
tasks, demonstrating that RESample consistently improves the stability and
generalization ability of VLA models.

</details>


### [367] [Botany-Bot: Digital Twin Monitoring of Occluded and Underleaf Plant Structures with Gaussian Splats](https://arxiv.org/abs/2510.17783)
*Simeon Adebola,Chung Min Kim,Justin Kerr,Shuangyu Xie,Prithvi Akella,Jose Luis Susa Rincon,Eugen Solowjow,Ken Goldberg*

Main category: cs.RO

TL;DR: Botany-Bot利用多硬件和算法构建植物数字孪生，解决了叶片遮挡问题，实验显示高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决固定相机系统因叶片遮挡无法捕捉植物细节的问题。

Method: 使用两个立体相机、数字转台、工业机械臂和3D分割高斯模型，结合机器人算法操纵叶片以拍摄高分辨率图像。

Result: 实验结果显示，Botany-Bot在叶片分割、检测、操纵及拍摄细节图像方面均达到较高准确率（90.8%、86.2%、77.9%、77.3%）。

Conclusion: Botany-Bot通过结合多种硬件和算法，成功构建了详细的植物数字孪生模型，并在实验中展示了较高的准确性。

Abstract: Commercial plant phenotyping systems using fixed cameras cannot perceive many
plant details due to leaf occlusion. In this paper, we present Botany-Bot, a
system for building detailed "annotated digital twins" of living plants using
two stereo cameras, a digital turntable inside a lightbox, an industrial robot
arm, and 3D segmentated Gaussian Splat models. We also present robot algorithms
for manipulating leaves to take high-resolution indexable images of occluded
details such as stem buds and the underside/topside of leaves. Results from
experiments suggest that Botany-Bot can segment leaves with 90.8% accuracy,
detect leaves with 86.2% accuracy, lift/push leaves with 77.9% accuracy, and
take detailed overside/underside images with 77.3% accuracy. Code, videos, and
datasets are available at https://berkeleyautomation.github.io/Botany-Bot/.

</details>


### [368] [SoftMimic: Learning Compliant Whole-body Control from Examples](https://arxiv.org/abs/2510.17792)
*Gabriel B. Margolis,Michelle Wang,Nolan Fey,Pulkit Agrawal*

Main category: cs.RO

TL;DR: SoftMimic通过强化学习从示例动作中学习柔顺控制，使机器人能安全应对意外接触。


<details>
  <summary>Details</summary>
Motivation: 现有方法倾向于刚性控制，导致机器人在遇到意外接触时行为脆弱且不安全。

Method: 利用逆运动学求解器生成增强的柔顺动作数据集，并训练强化学习策略，奖励策略匹配柔顺响应而非刚性跟踪参考动作。

Result: 通过仿真和真实实验验证了SoftMimic能够吸收干扰并从单一动作剪辑泛化到多种任务。

Conclusion: SoftMimic框架通过从示例动作中学习，实现了人形机器人的柔顺全身控制，能够安全有效地与环境互动。

Abstract: We introduce SoftMimic, a framework for learning compliant whole-body control
policies for humanoid robots from example motions. Imitating human motions with
reinforcement learning allows humanoids to quickly learn new skills, but
existing methods incentivize stiff control that aggressively corrects
deviations from a reference motion, leading to brittle and unsafe behavior when
the robot encounters unexpected contacts. In contrast, SoftMimic enables robots
to respond compliantly to external forces while maintaining balance and
posture. Our approach leverages an inverse kinematics solver to generate an
augmented dataset of feasible compliant motions, which we use to train a
reinforcement learning policy. By rewarding the policy for matching compliant
responses rather than rigidly tracking the reference motion, SoftMimic learns
to absorb disturbances and generalize to varied tasks from a single motion
clip. We validate our method through simulations and real-world experiments,
demonstrating safe and effective interaction with the environment.

</details>


### [369] [Robobench: A Comprehensive Evaluation Benchmark for Multimodal Large Language Models as Embodied Brain](https://arxiv.org/abs/2510.17801)
*Yulin Luo,Chun-Kai Fan,Menghang Dong,Jiayu Shi,Mengdi Zhao,Bo-Wen Zhang,Cheng Chi,Jiaming Liu,Gaole Dai,Rongyu Zhang,Ruichuan An,Kun Wu,Zhengping Che,Shaoxuan Xie,Guocai Yao,Zhongxia Zhao,Pengwei Wang,Guang Liu,Zhongyuan Wang,Tiejun Huang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboBench是一个评估多模态大语言模型作为具身大脑的综合基准，揭示了现有模型在多个认知维度的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试过于强调执行成功或在高层次推理方面存在不足，无法全面评估认知能力。

Method: 通过定义五个维度（指令理解、感知推理、泛化规划、功能预测和失败分析）和14种能力、25个任务及6092个QA对，RoboBench系统地评估了MLLMs作为具身大脑的表现。此外，还引入了MLLM-as-world-simulator框架来评估规划能力。

Result: 实验揭示了14个MLLMs在隐式指令理解、时空推理、跨场景规划、细粒度功能理解和执行失败诊断等方面的根本性局限。

Conclusion: RoboBench提供了一个全面的框架来量化高级认知能力，并指导下一代具身MLLMs的开发。

Abstract: Building robots that can perceive, reason, and act in dynamic, unstructured
environments remains a core challenge. Recent embodied systems often adopt a
dual-system paradigm, where System 2 handles high-level reasoning while System
1 executes low-level control. In this work, we refer to System 2 as the
embodied brain, emphasizing its role as the cognitive core for reasoning and
decision-making in manipulation tasks. Given this role, systematic evaluation
of the embodied brain is essential. Yet existing benchmarks emphasize execution
success, or when targeting high-level reasoning, suffer from incomplete
dimensions and limited task realism, offering only a partial picture of
cognitive capability. To bridge this gap, we introduce RoboBench, a benchmark
that systematically evaluates multimodal large language models (MLLMs) as
embodied brains. Motivated by the critical roles across the full manipulation
pipeline, RoboBench defines five dimensions-instruction comprehension,
perception reasoning, generalized planning, affordance prediction, and failure
analysis-spanning 14 capabilities, 25 tasks, and 6092 QA pairs. To ensure
realism, we curate datasets across diverse embodiments, attribute-rich objects,
and multi-view scenes, drawing from large-scale real robotic data. For
planning, RoboBench introduces an evaluation framework,
MLLM-as-world-simulator. It evaluate embodied feasibility by simulating whether
predicted plans can achieve critical object-state changes. Experiments on 14
MLLMs reveal fundamental limitations: difficulties with implicit instruction
comprehension, spatiotemporal reasoning, cross-scenario planning, fine-grained
affordance understanding, and execution failure diagnosis. RoboBench provides a
comprehensive scaffold to quantify high-level cognition, and guide the
development of next-generation embodied MLLMs. The project page is in
https://robo-bench.github.io.

</details>
