<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 71]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.SE](#cs.SE) [Total: 21]
- [cs.AI](#cs.AI) [Total: 45]
- [cs.RO](#cs.RO) [Total: 29]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 2]
- [cs.DC](#cs.DC) [Total: 1]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [The Impact and Outlook of 3D Gaussian Splatting](https://arxiv.org/abs/2510.26694)
*Bernhard Kerbl*

Main category: cs.CV

TL;DR: 3DGS已成为3D视觉和图形领域的基础工具，涵盖效率提升、动态表示、数学探索、平台适配和大规模应用等方向。


<details>
  <summary>Details</summary>
Motivation: 3DGS的引入迅速改变了3D场景表示的格局，激发了大量相关研究，本文旨在概述这些研究的关键方向。

Method: 总结了3DGS在效率、可扩展性和实际应用方面的改进，包括资源高效的训练和渲染、动态表示（4DGS）、数学基础的深入探索、移动和虚拟现实平台的适配、大规模环境的扩展以及快速辐射场重建。

Result: 这些发展为3DGS的广泛适用性奠定了基础，使其成为3D视觉和图形领域的重要工具。

Conclusion: 3D高斯泼溅（3DGS）已从一个突破性的表示方法发展成为3D视觉和图形领域的一个多功能基础工具。

Abstract: Since its introduction, 3D Gaussian Splatting (3DGS) has rapidly transformed
the landscape of 3D scene representations, inspiring an extensive body of
associated research. Follow-up work includes analyses and contributions that
enhance the efficiency, scalability, and real-world applicability of 3DGS. In
this summary, we present an overview of several key directions that have
emerged in the wake of 3DGS. We highlight advances enabling resource-efficient
training and rendering, the evolution toward dynamic (or four-dimensional,
4DGS) representations, and deeper exploration of the mathematical foundations
underlying its appearance modeling and rendering process. Furthermore, we
examine efforts to bring 3DGS to mobile and virtual reality platforms, its
extension to massive-scale environments, and recent progress toward
near-instant radiance field reconstruction via feed-forward or distributed
computation. Collectively, these developments illustrate how 3DGS has evolved
from a breakthrough representation into a versatile and foundational tool for
3D vision and graphics.

</details>


### [2] [HEIR: Learning Graph-Based Motion Hierarchies](https://arxiv.org/abs/2510.26786)
*Cheng Zheng,William Koch,Baiang Li,Felix Heide*

Main category: cs.CV

TL;DR: 提出了一种数据驱动的层次运动建模方法，通过图学习自动构建运动层次结构，在多个任务中展现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手动定义或启发式的固定运动原语层次结构，限制了其在不同任务中的泛化能力。

Method: 提出了一种基于图学习的层次运动建模方法，通过图神经网络学习父子依赖关系，将全局绝对运动分解为父级继承模式和局部运动残差。

Result: 在1D和2D案例中重建了内在运动层次结构，在动态3D高斯散射场景中相比基线产生了更真实和可解释的变形。

Conclusion: 该方法通过数据驱动的层次建模范式，提供了一种适用于广泛运动相关任务的通用解决方案。

Abstract: Hierarchical structures of motion exist across research fields, including
computer vision, graphics, and robotics, where complex dynamics typically arise
from coordinated interactions among simpler motion components. Existing methods
to model such dynamics typically rely on manually-defined or heuristic
hierarchies with fixed motion primitives, limiting their generalizability
across different tasks. In this work, we propose a general hierarchical motion
modeling method that learns structured, interpretable motion relationships
directly from data. Our method represents observed motions using graph-based
hierarchies, explicitly decomposing global absolute motions into
parent-inherited patterns and local motion residuals. We formulate hierarchy
inference as a differentiable graph learning problem, where vertices represent
elemental motions and directed edges capture learned parent-child dependencies
through graph neural networks. We evaluate our hierarchical reconstruction
approach on three examples: 1D translational motion, 2D rotational motion, and
dynamic 3D scene deformation via Gaussian splatting. Experimental results show
that our method reconstructs the intrinsic motion hierarchy in 1D and 2D cases,
and produces more realistic and interpretable deformations compared to the
baseline on dynamic 3D Gaussian splatting scenes. By providing an adaptable,
data-driven hierarchical modeling paradigm, our method offers a formulation
applicable to a broad range of motion-centric tasks. Project Page:
https://light.princeton.edu/HEIR/

</details>


### [3] [SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting](https://arxiv.org/abs/2510.26796)
*Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu*

Main category: cs.CV

TL;DR: SEE4D是一种无姿态的视频到4D框架，通过虚拟相机渲染和视图条件修复模型，实现了高效的时空内容合成，性能优于依赖姿态的基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频到4D的方法通常依赖手动标注的相机姿态，这在实际应用中既耗时又脆弱。SEE4D旨在消除对姿态标签的需求，简化建模和推理过程。

Method: SEE4D提出了一种无姿态的轨迹到相机框架，通过渲染到一组固定的虚拟相机来替代显式的轨迹预测。利用视图条件的视频修复模型学习几何先验，并通过时空自回归推理管道生成连贯的内容。

Result: SEE4D在跨视图视频生成和稀疏重建任务中表现出优异的泛化能力和性能提升，优于现有方法。

Conclusion: SEE4D方法通过将相机控制与场景建模分离，并在虚拟相机上渲染，实现了从随意视频中合成时空4D内容，无需昂贵的3D监督。该方法在跨视图视频生成和稀疏重建基准测试中表现出色，优于依赖姿态或轨迹条件的基线方法。

Abstract: Immersive applications call for synthesizing spatiotemporal 4D content from
casual videos without costly 3D supervision. Existing video-to-4D methods
typically rely on manually annotated camera poses, which are labor-intensive
and brittle for in-the-wild footage. Recent warp-then-inpaint approaches
mitigate the need for pose labels by warping input frames along a novel camera
trajectory and using an inpainting model to fill missing regions, thereby
depicting the 4D scene from diverse viewpoints. However, this
trajectory-to-trajectory formulation often entangles camera motion with scene
dynamics and complicates both modeling and inference. We introduce SEE4D, a
pose-free, trajectory-to-camera framework that replaces explicit trajectory
prediction with rendering to a bank of fixed virtual cameras, thereby
separating camera control from scene modeling. A view-conditional video
inpainting model is trained to learn a robust geometry prior by denoising
realistically synthesized warped images and to inpaint occluded or missing
regions across virtual viewpoints, eliminating the need for explicit 3D
annotations. Building on this inpainting core, we design a spatiotemporal
autoregressive inference pipeline that traverses virtual-camera splines and
extends videos with overlapping windows, enabling coherent generation at
bounded per-step complexity. We validate See4D on cross-view video generation
and sparse reconstruction benchmarks. Across quantitative metrics and
qualitative assessments, our method achieves superior generalization and
improved performance relative to pose- or trajectory-conditioned baselines,
advancing practical 4D world modeling from casual videos.

</details>


### [4] [Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks](https://arxiv.org/abs/2510.25797)
*Sai Likhith Karri,Ansh Saxena*

Main category: cs.CV

TL;DR: 研究通过改进YOLOv5模型（T-YOLOv5及加入CBAM的版本）显著提升了水下物体检测的准确性，尤其在复杂动态环境中表现突出。


<details>
  <summary>Details</summary>
Motivation: 探索时空建模和空间注意力机制在深度学习模型中对于水下物体检测的有效性，特别是在动态海洋环境中的突然运动、部分遮挡和渐变运动条件下。

Method: 研究分为两个阶段：首先评估T-YOLOv5与标准YOLOv5的性能对比；其次开发了加入卷积块注意力模块（CBAM）的增强版T-YOLOv5。

Result: 测试结果显示，标准YOLOv5的mAP@50-95为0.563，而T-YOLOv5和加入CBAM的T-YOLOv5分别达到0.813和0.811，展现了更高的准确性和泛化能力。

Conclusion: 研究发现，T-YOLOv5相比标准模型显著提升了检测可靠性，而加入CBAM的T-YOLOv5在复杂场景中表现更优，但在简单场景中略有精度损失。

Abstract: This study examines the effectiveness of spatio-temporal modeling and the
integration of spatial attention mechanisms in deep learning models for
underwater object detection. Specifically, in the first phase, the performance
of temporal-enhanced YOLOv5 variant T-YOLOv5 is evaluated, in comparison with
the standard YOLOv5. For the second phase, an augmented version of T-YOLOv5 is
developed, through the addition of a Convolutional Block Attention Module
(CBAM). By examining the effectiveness of the already pre-existing YOLOv5 and
T-YOLOv5 models and of the newly developed T-YOLOv5 with CBAM. With CBAM, the
research highlights how temporal modeling improves detection accuracy in
dynamic marine environments, particularly under conditions of sudden movements,
partial occlusions, and gradual motion. The testing results showed that YOLOv5
achieved a mAP@50-95 of 0.563, while T-YOLOv5 and T-YOLOv5 with CBAM
outperformed with mAP@50-95 scores of 0.813 and 0.811, respectively,
highlighting their superior accuracy and generalization in detecting complex
objects. The findings demonstrate that T-YOLOv5 significantly enhances
detection reliability compared to the standard model, while T-YOLOv5 with CBAM
further improves performance in challenging scenarios, although there is a loss
of accuracy when it comes to simpler scenarios.

</details>


### [5] [OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes](https://arxiv.org/abs/2510.26800)
*Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu*

Main category: cs.CV

TL;DR: OmniX 框架通过跨模态适配器结构，将 2D 生成先验应用于全景视觉任务，生成适用于物理渲染的 3D 场景，并构建大规模合成数据集支持研究。


<details>
  <summary>Details</summary>
Motivation: 解决现有 2D 提升方法仅关注外观生成而忽略内在属性感知的问题，推动全景 2D 提升技术生成适用于物理渲染、重光照和模拟的图形就绪 3D 场景。

Method: 提出 OmniX 框架，利用轻量高效的跨模态适配器结构，重用 2D 生成先验，支持全景感知、生成和补全等多种任务。同时构建了一个大规模合成全景数据集。

Result: 实验证明 OmniX 在全景视觉感知和图形就绪 3D 场景生成方面具有高效性。

Conclusion: OmniX 框架通过轻量高效的跨模态适配器结构，成功实现了全景视觉任务的统一处理，为沉浸式和物理真实的虚拟世界生成开辟了新可能性。

Abstract: There are two prevalent ways to constructing 3D scenes: procedural generation
and 2D lifting. Among them, panorama-based 2D lifting has emerged as a
promising technique, leveraging powerful 2D generative priors to produce
immersive, realistic, and diverse 3D environments. In this work, we advance
this technique to generate graphics-ready 3D scenes suitable for physically
based rendering (PBR), relighting, and simulation. Our key insight is to
repurpose 2D generative models for panoramic perception of geometry, textures,
and PBR materials. Unlike existing 2D lifting approaches that emphasize
appearance generation and ignore the perception of intrinsic properties, we
present OmniX, a versatile and unified framework. Based on a lightweight and
efficient cross-modal adapter structure, OmniX reuses 2D generative priors for
a broad range of panoramic vision tasks, including panoramic perception,
generation, and completion. Furthermore, we construct a large-scale synthetic
panorama dataset containing high-quality multimodal panoramas from diverse
indoor and outdoor scenes. Extensive experiments demonstrate the effectiveness
of our model in panoramic visual perception and graphics-ready 3D scene
generation, opening new possibilities for immersive and physically realistic
virtual world generation.

</details>


### [6] [MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency](https://arxiv.org/abs/2510.25897)
*Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard*

Main category: cs.CV

TL;DR: MIRO通过在训练中整合多奖励模型直接学习用户偏好，显著提升图像质量和训练效率，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型虽然能生成多样内容，但未很好匹配用户偏好；后处理的奖励模型方法会损害多样性、语义保真度和效率。

Method: MIRO方法在训练过程中直接基于多个奖励模型进行条件化处理，而非通过后处理选择图像。

Result: MIRO方法在视觉质量和训练速度上均有显著提升，并在GenEval和用户偏好评分中表现最佳。

Conclusion: 提出的MIRO方法通过在训练过程中直接整合多个奖励模型，显著提升了生成图像的视觉质量并加速了训练过程，在GenEval基准测试和用户偏好评分中达到最优性能。

Abstract: Current text-to-image generative models are trained on large uncurated
datasets to enable diverse generation capabilities. However, this does not
align well with user preferences. Recently, reward models have been
specifically designed to perform post-hoc selection of generated images and
align them to a reward, typically user preference. This discarding of
informative data together with the optimizing for a single reward tend to harm
diversity, semantic fidelity and efficiency. Instead of this post-processing,
we propose to condition the model on multiple reward models during training to
let the model learn user preferences directly. We show that this not only
dramatically improves the visual quality of the generated images but it also
significantly speeds up the training. Our proposed method, called MIRO,
achieves state-of-the-art performances on the GenEval compositional benchmark
and user-preference scores (PickAScore, ImageReward, HPSv2).

</details>


### [7] [BikeScenes: Online LiDAR Semantic Segmentation for Bicycles](https://arxiv.org/abs/2510.25901)
*Denniz Goren,Holger Caesar*

Main category: cs.CV

TL;DR: 针对自行车安全，开发了3D LiDAR分割方法，并引入BikeScenes数据集，微调后性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 自行车骑行者脆弱性因电动自行车普及加剧，促使将汽车感知技术适应于自行车安全。

Method: 使用多传感器'SenseBike'研究平台开发并评估针对自行车的3D LiDAR分割方法，引入BikeScenes-lidarseg数据集进行微调。

Result: 在BikeScenes数据集上微调的模型mIoU达到63.6%，显著优于仅使用SemanticKITTI预训练的13.8%。

Conclusion: 强调自行车特定领域训练的必要性和有效性，并贡献BikeScenes数据集以推动自行车为中心的LiDAR分割研究。

Abstract: The vulnerability of cyclists, exacerbated by the rising popularity of faster
e-bikes, motivates adapting automotive perception technologies for bicycle
safety. We use our multi-sensor 'SenseBike' research platform to develop and
evaluate a 3D LiDAR segmentation approach tailored to bicycles. To bridge the
automotive-to-bicycle domain gap, we introduce the novel BikeScenes-lidarseg
Dataset, comprising 3021 consecutive LiDAR scans around the university campus
of the TU Delft, semantically annotated for 29 dynamic and static classes. By
evaluating model performance, we demonstrate that fine-tuning on our BikeScenes
dataset achieves a mean Intersection-over-Union (mIoU) of 63.6%, significantly
outperforming the 13.8% obtained with SemanticKITTI pre-training alone. This
result underscores the necessity and effectiveness of domain-specific training.
We highlight key challenges specific to bicycle-mounted, hardware-constrained
perception systems and contribute the BikeScenes dataset as a resource for
advancing research in cyclist-centric LiDAR segmentation.

</details>


### [8] [Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy](https://arxiv.org/abs/2510.25921)
*Nikola L. Kolev,Tommaso Rodani,Neil J. Curson,Taylor J. Z. Stock,Alberto Cazzaniga*

Main category: cs.CV

TL;DR: 机器学习方法通过合成数据训练模型，显著提升STM图像修复效率，减少尖端调节需求。


<details>
  <summary>Details</summary>
Motivation: STM的原子级分辨率成像和原子操纵能力常受限于尖端退化和慢速串行数据采集，且尖端制备过程复杂。

Method: 利用物理信息合成的数据生成管道，训练了几种最先进的流匹配和扩散模型，仅需36张原始实验图像。

Result: 通过CLIP最大均值差异（CMMD）评分和结构相似性等定量评估，模型能有效修复图像，并将图像采集时间缩短2至4倍。

Conclusion: 该论文提出了一种基于机器学习的图像修复和超分辨率方法，显著提升了STM的成像效率，并减少了尖端调节的频率。

Abstract: Scanning tunnelling microscopy (STM) enables atomic-resolution imaging and
atom manipulation, but its utility is often limited by tip degradation and slow
serial data acquisition. Fabrication adds another layer of complexity since the
tip is often subjected to large voltages, which may alter the shape of its
apex, requiring it to be conditioned. Here, we propose a machine learning (ML)
approach for image repair and super-resolution to alleviate both challenges.
Using a dataset of only 36 pristine experimental images of Si(001):H, we
demonstrate that a physics-informed synthetic data generation pipeline can be
used to train several state-of-the-art flow-matching and diffusion models.
Quantitative evaluation with metrics such as the CLIP Maximum Mean Discrepancy
(CMMD) score and structural similarity demonstrates that our models are able to
effectively restore images and offer a two- to fourfold reduction in image
acquisition time by accurately reconstructing images from sparsely sampled
data. Our framework has the potential to significantly increase STM
experimental throughput by offering a route to reducing the frequency of
tip-conditioning procedures and to enhancing frame rates in existing high-speed
STM systems.

</details>


### [9] [SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing](https://arxiv.org/abs/2510.25970)
*Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang*

Main category: cs.CV

TL;DR: 提出了一种基于流分解与聚合的框架，通过语义分解和自适应加权机制，显著提升了图像编辑的语义保真度和属性解耦能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有校正流模型在图像编辑任务中的反转不准确和梯度纠缠问题，以生成更忠实于目标提示的输出。

Method: 通过语义分解目标提示为多个子提示，独立计算每个子提示的流，并通过投影和软聚合机制自适应地加权子目标速度场。

Result: 实验结果表明，该方法在语义保真度和属性解耦方面优于现有零样本编辑方法。

Conclusion: 提出的流分解与聚合框架显著提升了图像编辑的语义保真度和属性解耦能力，优于现有的零样本编辑方法。

Abstract: Rectified flow models have become a de facto standard in image generation due
to their stable sampling trajectories and high-fidelity outputs. Despite their
strong generative capabilities, they face critical limitations in image editing
tasks: inaccurate inversion processes for mapping real images back into the
latent space, and gradient entanglement issues during editing often result in
outputs that do not faithfully reflect the target prompt. Recent efforts have
attempted to directly map source and target distributions via ODE-based
approaches without inversion; however,these methods still yield suboptimal
editing quality. In this work, we propose a flow decomposition-and-aggregation
framework built upon an inversion-free formulation to address these
limitations. Specifically, we semantically decompose the target prompt into
multiple sub-prompts, compute an independent flow for each, and aggregate them
to form a unified editing trajectory. While we empirically observe that
decomposing the original flow enhances diversity in the target space,
generating semantically aligned outputs still requires consistent guidance
toward the full target prompt. To this end, we design a projection and
soft-aggregation mechanism for flow, inspired by gradient conflict resolution
in multi-task learning. This approach adaptively weights the sub-target
velocity fields, suppressing semantic redundancy while emphasizing distinct
directions, thereby preserving both diversity and consistency in the final
edited output. Experimental results demonstrate that our method outperforms
existing zero-shot editing approaches in terms of semantic fidelity and
attribute disentanglement. The code is available at
https://github.com/Harvard-AI-and-Robotics-Lab/SplitFlow.

</details>


### [10] [Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer](https://arxiv.org/abs/2510.25976)
*Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani*

Main category: cs.CV

TL;DR: Brain-IT利用BIT模型整合脑体素簇信息，实现了高保真的fMRI图像重建，数据效率大幅提升。


<details>
  <summary>Details</summary>
Motivation: 当前从fMRI重建视觉图像的方法在保真度上存在不足，需要一种能有效整合脑体素簇信息的新方法。

Method: 采用Brain Interaction Transformer（BIT）模型，通过预测高层次的语义特征和低层次的结构特征来引导扩散模型，实现信息从脑体素簇到局部图像特征的直接流动。

Result: Brain-IT在图像重建的保真度上超越现有方法，且在数据效率上显著提升（仅需1小时数据即可达到与40小时数据相当的效果）。

Conclusion: Brain-IT通过Brain Interaction Transformer（BIT）有效整合了功能相似的脑体素簇信息，实现了从fMRI数据中高保真地重建视觉图像，并在视觉和客观指标上超越了现有方法。即使在仅有1小时fMRI数据的新受试者上，也能达到与40小时数据训练的方法相当的效果。

Abstract: Reconstructing images seen by people from their fMRI brain recordings
provides a non-invasive window into the human brain. Despite recent progress
enabled by diffusion models, current methods often lack faithfulness to the
actual seen images. We present "Brain-IT", a brain-inspired approach that
addresses this challenge through a Brain Interaction Transformer (BIT),
allowing effective interactions between clusters of functionally-similar
brain-voxels. These functional-clusters are shared by all subjects, serving as
building blocks for integrating information both within and across brains. All
model components are shared by all clusters & subjects, allowing efficient
training with a limited amount of data. To guide the image reconstruction, BIT
predicts two complementary localized patch-level image features: (i)high-level
semantic features which steer the diffusion model toward the correct semantic
content of the image; and (ii)low-level structural features which help to
initialize the diffusion process with the correct coarse layout of the image.
BIT's design enables direct flow of information from brain-voxel clusters to
localized image features. Through these principles, our method achieves image
reconstructions from fMRI that faithfully reconstruct the seen images, and
surpass current SotA approaches both visually and by standard objective
metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve
results comparable to current methods trained on full 40-hour recordings.

</details>


### [11] [Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI](https://arxiv.org/abs/2510.25990)
*Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger*

Main category: cs.CV

TL;DR: The paper explores foundation models for real-time tumor tracking in MRI, achieving a Dice score of 0.8794 in the TrackRAD2025 challenge.


<details>
  <summary>Details</summary>
Motivation: The motivation was to address the TrackRAD2025 challenge of real-time tumor tracking in cine-MRI sequences under strong data scarcity constraints.

Method: The method involved two strategies: unsupervised registration with the IMPACT similarity metric and foundation model-based segmentation using SAM 2.1. The final approach used SAM 2.1 b+ with mask-based prompts, fine-tuned on a small labeled subset, with training configured to minimize overfitting.

Result: The model achieved a Dice score of 0.8794 on the hidden test set, ranking 6th overall in the TrackRAD2025 challenge.

Conclusion: The paper concludes that foundation models like SAM 2.1 have strong potential for accurate and real-time tumor tracking in MRI-guided radiotherapy, as demonstrated by the model's performance in the TrackRAD2025 challenge.

Abstract: In this work, we address the TrackRAD2025 challenge of real-time tumor
tracking in cine-MRI sequences of the thoracic and abdominal regions under
strong data scarcity constraints. Two complementary strategies were explored:
(i) unsupervised registration with the IMPACT similarity metric and (ii)
foundation model-based segmentation leveraging SAM 2.1 and its recent variants
through prompt-based interaction. Due to the one-second runtime constraint, the
SAM-based method was ultimately selected. The final configuration used SAM2.1
b+ with mask-based prompts from the first annotated slice, fine-tuned solely on
the small labeled subset from TrackRAD2025. Training was configured to minimize
overfitting, using 1024x1024 patches (batch size 1), standard augmentations,
and a balanced Dice + IoU loss. A low uniform learning rate (0.0001) was
applied to all modules (prompt encoder, decoder, Hiera backbone) to preserve
generalization while adapting to annotator-specific styles. Training lasted 300
epochs (~12h on RTX A6000, 48GB). The same inference strategy was consistently
applied across all anatomical sites and MRI field strengths. Test-time
augmentation was considered but ultimately discarded due to negligible
performance gains. The final model was selected based on the highest Dice
Similarity Coefficient achieved on the validation set after fine-tuning. On the
hidden test set, the model reached a Dice score of 0.8794, ranking 6th overall
in the TrackRAD2025 challenge. These results highlight the strong potential of
foundation models for accurate and real-time tumor tracking in MRI-guided
radiotherapy.

</details>


### [12] [Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement](https://arxiv.org/abs/2510.26001)
*Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu*

Main category: cs.CV

TL;DR: 通过Hilbert选择性扫描机制增强Mamba框架，显著提升低光图像增强效果并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有Mamba框架在低光图像增强中信息不一致性和空间局部性不足的问题，同时保持对长距离依赖的处理能力。

Method: 采用新颖的Hilbert选择性扫描机制，增加扫描模式的Hausdorff维度，以更有效地探索特征空间，捕捉精细细节并提升覆盖范围。

Result: 在公开基准测试中，该方法显著提升了定量指标和视觉保真度，同时减少了计算资源消耗和推理时间。

Conclusion: 该研究提出了一种改进的Mamba框架，通过Hilbert选择性扫描机制提升扫描模式的Hausdorff维度，不仅显著提升了低光图像增强的性能，还降低了计算资源消耗和推理时间，为Mamba技术的广泛应用提供了新思路。

Abstract: We propose an innovative enhancement to the Mamba framework by increasing the
Hausdorff dimension of its scanning pattern through a novel Hilbert Selective
Scan mechanism. This mechanism explores the feature space more effectively,
capturing intricate fine-scale details and improving overall coverage. As a
result, it mitigates information inconsistencies while refining spatial
locality to better capture subtle local interactions without sacrificing the
model's ability to handle long-range dependencies. Extensive experiments on
publicly available benchmarks demonstrate that our approach significantly
improves both the quantitative metrics and qualitative visual fidelity of
existing Mamba-based low-light image enhancement methods, all while reducing
computational resource consumption and shortening inference time. We believe
that this refined strategy not only advances the state-of-the-art in low-light
image enhancement but also holds promise for broader applications in fields
that leverage Mamba-based techniques.

</details>


### [13] [CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments](https://arxiv.org/abs/2510.26006)
*Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut*

Main category: cs.CV

TL;DR: CAVE 是首个真实世界视觉异常基准，旨在评估 VLMs 在异常检测和常识推理中的表现，揭示其当前局限性。


<details>
  <summary>Details</summary>
Motivation: 当前计算机视觉中的异常检测局限于工业缺陷或合成异常，无法捕捉真实世界异常的丰富性和不可预测性。

Method: CAVE 引入了首个真实世界视觉异常基准，支持异常描述、解释和合理性验证三个开放任务，并提供细粒度标注。

Result: 研究表明，即使采用先进的提示策略，最先进的 VLMs 在视觉异常感知和常识推理方面仍表现不佳。

Conclusion: CAVE 作为一个真实且认知基础扎实的基准，为视觉语言模型（VLMs）在异常检测和常识推理领域的研究提供了宝贵资源。

Abstract: Humans can naturally identify, reason about, and explain anomalies in their
environment. In computer vision, this long-standing challenge remains limited
to industrial defects or unrealistic, synthetically generated anomalies,
failing to capture the richness and unpredictability of real-world anomalies.
In this work, we introduce CAVE, the first benchmark of real-world visual
anomalies. CAVE supports three open-ended tasks: anomaly description,
explanation, and justification; with fine-grained annotations for visual
grounding and categorizing anomalies based on their visual manifestations,
their complexity, severity, and commonness. These annotations draw inspiration
from cognitive science research on how humans identify and resolve anomalies,
providing a comprehensive framework for evaluating Vision-Language Models
(VLMs) in detecting and understanding anomalies. We show that state-of-the-art
VLMs struggle with visual anomaly perception and commonsense reasoning, even
with advanced prompting strategies. By offering a realistic and cognitively
grounded benchmark, CAVE serves as a valuable resource for advancing research
in anomaly detection and commonsense reasoning in VLMs.

</details>


### [14] [Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning](https://arxiv.org/abs/2510.26017)
*Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat*

Main category: cs.CV

TL;DR: 研究开发了一种轻量级CNN模型，用于预测海岸洪水，显著优于现有方法，减少了20%的误差，展示了其在海岸洪水管理中的潜力。


<details>
  <summary>Details</summary>
Motivation: 气候变化和海平面上升对沿海城市的威胁日益加剧，迫切需要高效准确的方法来预测潜在的洪水风险。传统的基于物理的水动力模拟器虽然精确，但计算成本高，不适用于城市尺度的海岸规划应用。深度学习技术提供了有前景的替代方案，但常受数据稀缺和高维输出需求等挑战的限制。

Method: 利用最近提出的基于视觉的低资源深度学习框架，开发了一种新颖的轻量级卷积神经网络（CNN）模型，用于预测不同海平面上升预测和海岸线适应情景下的海岸洪水。

Result: 该模型在阿布扎比和旧金山两个不同地区的数据集上展示了其跨地理背景的泛化能力，显著优于现有方法，平均减少了20%的预测洪水深度图的平均绝对误差。

Conclusion: 该研究提出的轻量级CNN模型在预测海岸洪水方面显著优于现有方法，平均减少了20%的预测洪水深度图的平均绝对误差。这展示了该方法作为可扩展且实用的海岸洪水管理工具的潜力，有助于决策者制定有效的缓解策略以应对气候变化的影响。

Abstract: Climate change and sea-level rise (SLR) pose escalating threats to coastal
cities, intensifying the need for efficient and accurate methods to predict
potential flood hazards. Traditional physics-based hydrodynamic simulators,
although precise, are computationally expensive and impractical for city-scale
coastal planning applications. Deep Learning (DL) techniques offer promising
alternatives, however, they are often constrained by challenges such as data
scarcity and high-dimensional output requirements. Leveraging a recently
proposed vision-based, low-resource DL framework, we develop a novel,
lightweight Convolutional Neural Network (CNN)-based model designed to predict
coastal flooding under variable SLR projections and shoreline adaptation
scenarios. Furthermore, we demonstrate the ability of the model to generalize
across diverse geographical contexts by utilizing datasets from two distinct
regions: Abu Dhabi and San Francisco. Our findings demonstrate that the
proposed model significantly outperforms state-of-the-art methods, reducing the
mean absolute error (MAE) in predicted flood depth maps on average by nearly
20%. These results highlight the potential of our approach to serve as a
scalable and practical tool for coastal flood management, empowering
decision-makers to develop effective mitigation strategies in response to the
growing impacts of climate change. Project Page: https://caspiannet.github.io/

</details>


### [15] [Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders](https://arxiv.org/abs/2510.26027)
*Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz*

Main category: cs.CV

TL;DR: 本研究通过在视觉编码器中引入时间注意力模块，提升了Video-LLM对视频时间动态的理解能力，显著改善了视频问答任务的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型取得了显著进展，但理解视频中的复杂时间动态仍是一个主要挑战。当前Video-LLM架构在时间理解上存在严重局限性。

Method: 提出了一种Video-LLM架构，在视觉编码器中引入了堆叠的时间注意力模块，以更好地捕获动作序列和时间关系。

Result: 该方法在视频问答任务中显著提升了时间推理能力，在VITATECS、MVBench和Video-MME等基准测试中性能提升高达+5.5%。

Conclusion: 通过增强视觉编码器中的时间结构，本研究解决了视频理解中的一个关键问题，显著提升了视频问答任务的性能。

Abstract: Despite significant advances in Multimodal Large Language Models (MLLMs),
understanding complex temporal dynamics in videos remains a major challenge.
Our experiments show that current Video Large Language Model (Video-LLM)
architectures have critical limitations in temporal understanding, struggling
with tasks that require detailed comprehension of action sequences and temporal
progression. In this work, we propose a Video-LLM architecture that introduces
stacked temporal attention modules directly within the vision encoder. This
design incorporates a temporal attention in vision encoder, enabling the model
to better capture the progression of actions and the relationships between
frames before passing visual tokens to the LLM. Our results show that this
approach significantly improves temporal reasoning and outperforms existing
models in video question answering tasks, specifically in action recognition.
We improve on benchmarks including VITATECS, MVBench, and Video-MME by up to
+5.5%. By enhancing the vision encoder with temporal structure, we address a
critical gap in video understanding for Video-LLMs. Project page and code are
available at: https://alirasekh.github.io/STAVEQ2/.

</details>


### [16] [FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation](https://arxiv.org/abs/2510.26049)
*Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan*

Main category: cs.CV

TL;DR: FlexICL是一种新型灵活上下文学习框架，通过少量标注帧实现高效超声图像分割，提升儿科骨折诊断效率。


<details>
  <summary>Details</summary>
Motivation: 解决儿科肘部和腕部骨折超声图像分割中专家标注耗时且成本高的问题。

Method: 提出FlexICL框架，结合多种图像拼接技术和训练策略，通过少量标注帧实现未见帧的分割。

Result: FlexICL在四个肘部和腕部超声数据集上仅需5%的训练图像，性能优于现有方法1-27% Dice系数。

Conclusion: FlexICL作为一种高效且可扩展的解决方案，在超声图像分割中展现出潜力，尤其适用于标注数据稀缺的医疗影像场景。

Abstract: Elbow and wrist fractures are the most common fractures in pediatric
populations. Automatic segmentation of musculoskeletal structures in ultrasound
(US) can improve diagnostic accuracy and treatment planning. Fractures appear
as cortical defects but require expert interpretation. Deep learning (DL) can
provide real-time feedback and highlight key structures, helping lightly
trained users perform exams more confidently. However, pixel-wise expert
annotations for training remain time-consuming and costly. To address this
challenge, we propose FlexICL, a novel and flexible in-context learning (ICL)
framework for segmenting bony regions in US images. We apply it to an
intra-video segmentation setting, where experts annotate only a small subset of
frames, and the model segments unseen frames. We systematically investigate
various image concatenation techniques and training strategies for visual ICL
and introduce novel concatenation methods that significantly enhance model
performance with limited labeled data. By integrating multiple augmentation
strategies, FlexICL achieves robust segmentation performance across four wrist
and elbow US datasets while requiring only 5% of the training images. It
outperforms state-of-the-art visual ICL models like Painter, MAE-VQGAN, and
conventional segmentation models like U-Net and TransUNet by 1-27% Dice
coefficient on 1,252 US sweeps. These initial results highlight the potential
of FlexICL as an efficient and scalable solution for US image segmentation well
suited for medical imaging use cases where labeled data is scarce.

</details>


### [17] [Dynamic VLM-Guided Negative Prompting for Diffusion Models](https://arxiv.org/abs/2510.26052)
*Hoyeon Chang,Seungjin Kim,Yoonseok Choi*

Main category: cs.CV

TL;DR: 动态负提示方法利用VLM自适应生成负提示，优化文本-图像对齐效果。


<details>
  <summary>Details</summary>
Motivation: 传统负提示方法使用固定提示，无法适应不同上下文，限制了文本-图像对齐的灵活性。

Method: 提出一种新颖的动态负提示方法，利用VLM在特定去噪步骤生成中间图像预测，并基于上下文生成适当的负提示。

Result: 在不同基准数据集上验证了方法的有效性，展示了负引导强度与文本-图像对齐之间的权衡。

Conclusion: 动态负提示方法通过结合视觉语言模型（VLM），在去噪过程中自适应生成负提示，相比传统固定负提示方法，显著提升了文本-图像对齐效果。

Abstract: We propose a novel approach for dynamic negative prompting in diffusion
models that leverages Vision-Language Models (VLMs) to adaptively generate
negative prompts during the denoising process. Unlike traditional Negative
Prompting methods that use fixed negative prompts, our method generates
intermediate image predictions at specific denoising steps and queries a VLM to
produce contextually appropriate negative prompts. We evaluate our approach on
various benchmark datasets and demonstrate the trade-offs between negative
guidance strength and text-image alignment.

</details>


### [18] [Security Risk of Misalignment between Text and Image in Multi-modal Model](https://arxiv.org/abs/2510.26105)
*Xiaosen Wang,Zhijin Ge,Shaokang Wang*

Main category: cs.CV

TL;DR: 论文提出PReMA攻击方法，仅通过对抗图像操纵多模态扩散模型输出，尤其在固定提示应用中构成新威胁。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型中文本与图像模态的对齐不足，导致生成不适当或NSFW内容的风险。

Method: 提出了一种名为Prompt-Restricted Multi-modal Attack (PReMA)的新型攻击方法，通过修改输入图像而非提示文本，操纵模型生成内容。

Result: 在图像修复和风格转换任务上的广泛评估证实了PReMA的有效性。

Conclusion: PReMA作为一种新型攻击方法，仅通过创建对抗性图像即可操纵多模态扩散模型的输出，对模型完整性构成新威胁，尤其在固定提示的图像编辑应用中。

Abstract: Despite the notable advancements and versatility of multi-modal diffusion
models, such as text-to-image models, their susceptibility to adversarial
inputs remains underexplored. Contrary to expectations, our investigations
reveal that the alignment between textual and Image modalities in existing
diffusion models is inadequate. This misalignment presents significant risks,
especially in the generation of inappropriate or Not-Safe-For-Work (NSFW)
content. To this end, we propose a novel attack called Prompt-Restricted
Multi-modal Attack (PReMA) to manipulate the generated content by modifying the
input image in conjunction with any specified prompt, without altering the
prompt itself. PReMA is the first attack that manipulates model outputs by
solely creating adversarial images, distinguishing itself from prior methods
that primarily generate adversarial prompts to produce NSFW content.
Consequently, PReMA poses a novel threat to the integrity of multi-modal
diffusion models, particularly in image-editing applications that operate with
fixed prompts. Comprehensive evaluations conducted on image inpainting and
style transfer tasks across various models confirm the potent efficacy of
PReMA.

</details>


### [19] [EgoExo-Con: Exploring View-Invariant Video Temporal Understanding](https://arxiv.org/abs/2510.26113)
*Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao*

Main category: cs.CV

TL;DR: 论文提出EgoExo-Con基准和View-GRPO方法，解决Video-LLMs跨视角时间理解一致性问题。


<details>
  <summary>Details</summary>
Motivation: 研究Video-LLMs在不同视角下对同一事件的时间理解一致性。

Method: 引入EgoExo-Con基准，提出View-GRPO强化学习框架。

Result: 现有Video-LLMs在跨视角一致性表现不佳，View-GRPO显著提升性能。

Conclusion: 论文提出View-GRPO框架，有效提升跨视角一致性理解，优于现有方法。

Abstract: Can Video-LLMs achieve consistent temporal understanding when videos capture
the same event from different viewpoints? To study this, we introduce
EgoExo-Con (Consistency), a benchmark of comprehensively synchronized
egocentric and exocentric video pairs with human-refined queries in natural
language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal
Verification and Temporal Grounding. It evaluates not only correctness but
consistency across viewpoints. Our analysis reveals two critical limitations of
existing Video-LLMs: (1) models often fail to maintain consistency, with
results far worse than their single-view performances. (2) When naively
finetuned with synchronized videos of both viewpoints, the models show improved
consistency but often underperform those trained on a single view. For
improvements, we propose View-GRPO, a novel reinforcement learning framework
that effectively strengthens view-specific temporal reasoning while encouraging
consistent comprehension across viewpoints. Our method demonstrates its
superiority over naive SFT and GRPO, especially for improving cross-view
consistency. All resources will be made publicly available.

</details>


### [20] [OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research](https://arxiv.org/abs/2510.26114)
*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang*

Main category: cs.CV

TL;DR: OracleAgent是首个用于甲骨文信息结构化管理和检索的智能系统，整合了多工具和知识库，显著提升研究效率。


<details>
  <summary>Details</summary>
Motivation: 甲骨文研究面临解释流程复杂和信息组织检索效率低的两大挑战。

Method: 开发了OracleAgent系统，整合了多个甲骨文分析工具，并构建了一个包含140万单字拓片图像和8万解释文本的多模态知识库。

Result: OracleAgent在多模态推理和生成任务中表现优异，显著降低了研究时间成本。

Conclusion: OracleAgent显著提升了甲骨文研究的效率，为自动化解释系统的实际部署迈出了重要一步。

Abstract: As one of the earliest writing systems, Oracle Bone Script (OBS) preserves
the cultural and intellectual heritage of ancient civilizations. However,
current OBS research faces two major challenges: (1) the interpretation of OBS
involves a complex workflow comprising multiple serial and parallel sub-tasks,
and (2) the efficiency of OBS information organization and retrieval remains a
critical bottleneck, as scholars often spend substantial effort searching for,
compiling, and managing relevant resources. To address these challenges, we
present OracleAgent, the first agent system designed for the structured
management and retrieval of OBS-related information. OracleAgent seamlessly
integrates multiple OBS analysis tools, empowered by large language models
(LLMs), and can flexibly orchestrate these components. Additionally, we
construct a comprehensive domain-specific multimodal knowledge base for OBS,
which is built through a rigorous multi-year process of data collection,
cleaning, and expert annotation. The knowledge base comprises over 1.4M
single-character rubbing images and 80K interpretation texts. OracleAgent
leverages this resource through its multimodal tools to assist experts in
retrieval tasks of character, document, interpretation text, and rubbing image.
Extensive experiments demonstrate that OracleAgent achieves superior
performance across a range of multimodal reasoning and generation tasks,
surpassing leading mainstream multimodal large language models (MLLMs) (e.g.,
GPT-4o). Furthermore, our case study illustrates that OracleAgent can
effectively assist domain experts, significantly reducing the time cost of OBS
research. These results highlight OracleAgent as a significant step toward the
practical deployment of OBS-assisted research and automated interpretation
systems.

</details>


### [21] [JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting](https://arxiv.org/abs/2510.26117)
*Yuxuan Li,Tao Wang,Xianben Yang*

Main category: cs.CV

TL;DR: 提出联合优化3D高斯点与相机姿态的统一框架，无需预校准输入，显著提升重建质量和姿态准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖外部相机姿态估计工具（如COLMAP），存在计算瓶颈和误差传播问题，需提出一种无需预校准输入的解决方案。

Method: 该方法通过交替更新3D高斯参数和相机姿态的两阶段策略，结合可微分渲染和定制的3D光流算法，逐步减少投影误差。

Result: 实验表明，该方法在多个数据集上显著优于现有的COLMAP-free技术，并在总体上超越了基于COLMAP的基线方法。

Conclusion: 该论文提出了一种联合优化3D高斯点和相机姿态的统一框架，显著提升了场景重建质量和姿态准确性，特别是在视角变化大和特征稀疏的挑战性场景中。

Abstract: Traditional novel view synthesis methods heavily rely on external camera pose
estimation tools such as COLMAP, which often introduce computational
bottlenecks and propagate errors. To address these challenges, we propose a
unified framework that jointly optimizes 3D Gaussian points and camera poses
without requiring pre-calibrated inputs. Our approach iteratively refines 3D
Gaussian parameters and updates camera poses through a novel co-optimization
strategy, ensuring simultaneous improvements in scene reconstruction fidelity
and pose accuracy. The key innovation lies in decoupling the joint optimization
into two interleaved phases: first, updating 3D Gaussian parameters via
differentiable rendering with fixed poses, and second, refining camera poses
using a customized 3D optical flow algorithm that incorporates geometric and
photometric constraints. This formulation progressively reduces projection
errors, particularly in challenging scenarios with large viewpoint variations
and sparse feature distributions, where traditional methods struggle. Extensive
evaluations on multiple datasets demonstrate that our approach significantly
outperforms existing COLMAP-free techniques in reconstruction quality, and also
surpasses the standard COLMAP-based baseline in general.

</details>


### [22] [WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios](https://arxiv.org/abs/2510.26125)
*Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov*

Main category: cs.CV

TL;DR: 论文介绍了WOD-E2E数据集和RFS评估指标，旨在提升端到端自动驾驶在长尾场景中的性能评估。


<details>
  <summary>Details</summary>
Motivation: 当前端到端驾驶基准主要集中在常规场景，无法充分测试系统潜力，且现有评估指标难以捕捉驾驶的多模态性或有效评估长尾场景性能。

Method: 论文通过构建WOD-E2E数据集，包含4012个驾驶片段，专注于长尾场景，并提出了RFS（Rater Feedback Score）作为新的评估指标。

Result: 论文提出了WOD-E2E数据集和RFS评估指标，填补了现有研究的空白。

Conclusion: 这篇论文的结论是介绍了WOD-E2E数据集和RFS评估指标，旨在推动通用、稳健且安全的端到端自动驾驶代理的研究，以应对复杂的现实世界场景。

Abstract: Vision-based end-to-end (E2E) driving has garnered significant interest in
the research community due to its scalability and synergy with multimodal large
language models (MLLMs). However, current E2E driving benchmarks primarily
feature nominal scenarios, failing to adequately test the true potential of
these systems. Furthermore, existing open-loop evaluation metrics often fall
short in capturing the multi-modal nature of driving or effectively evaluating
performance in long-tail scenarios. To address these gaps, we introduce the
Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
driving segments (approximately 12 hours), specifically curated for challenging
long-tail scenarios that that are rare in daily life with an occurring
frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
high-level routing information, ego states, and 360-degree camera views from 8
surrounding cameras. To evaluate the E2E driving performance on these long-tail
situations, we propose a novel open-loop evaluation metric: Rater Feedback
Score (RFS). Unlike conventional metrics that measure the distance between
predicted way points and the logs, RFS measures how closely the predicted
trajectory matches rater-annotated trajectory preference labels. We have
released rater preference labels for all WOD-E2E validation set segments, while
the held out test set labels have been used for the 2025 WOD-E2E Challenge.
Through our work, we aim to foster state of the art research into
generalizable, robust, and safe end-to-end autonomous driving agents capable of
handling complex real-world situations.

</details>


### [23] [Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM](https://arxiv.org/abs/2510.26131)
*Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura*

Main category: cs.CV

TL;DR: 提出了一种集成网络梯度注意力与CNN特征的方法，用于提升RGB-D室内SLAM的性能，实验证实其有效性，尤其在大型环境中。


<details>
  <summary>Details</summary>
Motivation: 现有的基于梯度的注意力信息虽然能识别CNN在图像识别任务中的关注区域，但直接集成到CNN表示中以增强语义对象理解的应用仍有限。这种方法特别适用于视觉任务如SLAM，可提升性能。

Method: 提出了一种方法，将任务特定的网络注意力（通过网络梯度获取）与CNN特征表示直接集成，用于增强RGB-D室内SLAM的帧关联性能。

Result: 实验结果表明，所提方法在大型环境中相比基线方法有显著性能提升。

Conclusion: 通过将网络梯度衍生的层间注意力信息与CNN特征表示相结合，显著提高了RGB-D室内SLAM的帧关联性能，特别是在大环境中表现优于基线方法。

Abstract: Attention models have recently emerged as a powerful approach, demonstrating
significant progress in various fields. Visualization techniques, such as class
activation mapping, provide visual insights into the reasoning of convolutional
neural networks (CNNs). Using network gradients, it is possible to identify
regions where the network pays attention during image recognition tasks.
Furthermore, these gradients can be combined with CNN features to localize more
generalizable, task-specific attentive (salient) regions within scenes.
However, explicit use of this gradient-based attention information integrated
directly into CNN representations for semantic object understanding remains
limited. Such integration is particularly beneficial for visual tasks like
simultaneous localization and mapping (SLAM), where CNN representations
enriched with spatially attentive object locations can enhance performance. In
this work, we propose utilizing task-specific network attention for RGB-D
indoor SLAM. Specifically, we integrate layer-wise attention information
derived from network gradients with CNN feature representations to improve
frame association performance. Experimental results indicate improved
performance compared to baseline methods, particularly for large environments.

</details>


### [24] [FullPart: Generating each 3D Part at Full Resolution](https://arxiv.org/abs/2510.26140)
*Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue*

Main category: cs.CV

TL;DR: FullPart结合隐式和显式表示，解决了3D部件生成的细节和分辨率问题，并引入中心点编码和新数据集，达到最优效果。


<details>
  <summary>Details</summary>
Motivation: 现有的3D部件生成方法在几何细节和分辨率方面存在不足，隐式表示缺乏细节，而显式表示中共享全局体素网格导致小部件分辨率低。

Method: FullPart框架首先通过隐式盒向量集扩散过程生成边界框布局，然后在每个部件的固定全分辨率体素网格中生成详细部件，避免了共享低分辨率空间的问题。

Result: FullPart在3D部件生成中实现了最先进的效果，能够合成复杂细节，并通过PartVerse-XL数据集解决了数据稀缺问题。

Conclusion: FullPart框架通过结合隐式和显式表示，成功解决了3D部件生成中的几何细节不足和分辨率问题，并通过引入中心点编码策略和PartVerse-XL数据集，实现了最先进的生成效果。

Abstract: Part-based 3D generation holds great potential for various applications.
Previous part generators that represent parts using implicit vector-set tokens
often suffer from insufficient geometric details. Another line of work adopts
an explicit voxel representation but shares a global voxel grid among all
parts; this often causes small parts to occupy too few voxels, leading to
degraded quality. In this paper, we propose FullPart, a novel framework that
combines both implicit and explicit paradigms. It first derives the bounding
box layout through an implicit box vector-set diffusion process, a task that
implicit diffusion handles effectively since box tokens contain little
geometric detail. Then, it generates detailed parts, each within its own fixed
full-resolution voxel grid. Instead of sharing a global low-resolution space,
each part in our method - even small ones - is generated at full resolution,
enabling the synthesis of intricate details. We further introduce a
center-point encoding strategy to address the misalignment issue when
exchanging information between parts of different actual sizes, thereby
maintaining global coherence. Moreover, to tackle the scarcity of reliable part
data, we present PartVerse-XL, the largest human-annotated 3D part dataset to
date with 40K objects and 320K parts. Extensive experiments demonstrate that
FullPart achieves state-of-the-art results in 3D part generation. We will
release all code, data, and model to benefit future research in 3D part
generation.

</details>


### [25] [BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation](https://arxiv.org/abs/2510.26149)
*Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren*

Main category: cs.CV

TL;DR: BasicAVSR通过四项关键技术和三种传播变体，显著提升视频超分辨率的质量和效率，适用于多种应用场景。


<details>
  <summary>Details</summary>
Motivation: 解决视频帧分辨率增强中空间细节再现、时间一致性和计算复杂度的挑战。

Method: 提出了BasicAVSR，整合了四个关键组件：自适应多尺度频率先验、流引导传播单元、二阶运动补偿单元和超上采样单元，并实例化了三种传播变体以适应不同应用需求。

Result: 实验证明BasicAVSR在不同场景下均表现出色，显著优于现有方法。

Conclusion: BasicAVSR显著提升了视频超分辨率的质量、泛化能力和推理速度，不仅推动了AVSR领域的最新进展，还将其核心组件扩展到多种框架以适应不同场景。

Abstract: Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution
of video frames, potentially at various scaling factors, which presents several
challenges regarding spatial detail reproduction, temporal consistency, and
computational complexity. In this paper, we propose a strong baseline BasicAVSR
for AVSR by integrating four key components: 1) adaptive multi-scale frequency
priors generated from image Laplacian pyramids, 2) a flow-guided propagation
unit to aggregate spatiotemporal information from adjacent frames, 3) a
second-order motion compensation unit for more accurate spatial alignment of
adjacent frames, and 4) a hyper-upsampling unit to generate scale-aware and
content-independent upsampling kernels. To meet diverse application demands, we
instantiate three propagation variants: (i) a unidirectional RNN unit for
strictly online inference, (ii) a unidirectional RNN unit empowered with a
limited lookahead that tolerates a small output delay, and (iii) a
bidirectional RNN unit designed for offline tasks where computational resources
are less constrained. Experimental results demonstrate the effectiveness and
adaptability of our model across these different scenarios. Through extensive
experiments, we show that BasicAVSR significantly outperforms existing methods
in terms of super-resolution quality, generalization ability, and inference
speed. Our work not only advances the state-of-the-art in AVSR but also extends
its core components to multiple frameworks for diverse scenarios. The code is
available at https://github.com/shangwei5/BasicAVSR.

</details>


### [26] [MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction](https://arxiv.org/abs/2510.26151)
*Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba*

Main category: cs.CV

TL;DR: MV-MLM模型通过多视角和跨模态学习，利用合成报告提升乳腺癌分类和风险预测的数据效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学影像标注数据获取成本高、耗时长的问题，利用预训练的视觉语言模型提升数据效率和鲁棒性。

Method: 利用多视角监督和跨模态自监督学习从图像-文本对中提取丰富表示，结合联合视觉-文本学习策略提升泛化能力。

Result: 在私人和公开数据集上验证，模型在恶性肿瘤分类、亚型分类和基于图像的癌症风险预测任务中达到最先进性能。

Conclusion: 该论文提出的MV-MLM模型在乳腺癌分类和风险预测任务中表现出色，尤其在数据效率和泛化能力方面优于现有方法，展示了合成文本报告训练的潜力。

Abstract: Large annotated datasets are essential for training robust Computer-Aided
Diagnosis (CAD) models for breast cancer detection or risk prediction. However,
acquiring such datasets with fine-detailed annotation is both costly and
time-consuming. Vision-Language Models (VLMs), such as CLIP, which are
pre-trained on large image-text pairs, offer a promising solution by enhancing
robustness and data efficiency in medical imaging tasks. This paper introduces
a novel Multi-View Mammography and Language Model for breast cancer
classification and risk prediction, trained on a dataset of paired mammogram
images and synthetic radiology reports. Our MV-MLM leverages multi-view
supervision to learn rich representations from extensive radiology data by
employing cross-modal self-supervision across image-text pairs. This includes
multiple views and the corresponding pseudo-radiology reports. We propose a
novel joint visual-textual learning strategy to enhance generalization and
accuracy performance over different data types and tasks to distinguish breast
tissues or cancer characteristics(calcification, mass) and utilize these
patterns to understand mammography images and predict cancer risk. We evaluated
our method on both private and publicly available datasets, demonstrating that
the proposed model achieves state-of-the-art performance in three
classification tasks: (1) malignancy classification, (2) subtype
classification, and (3) image-based cancer risk prediction. Furthermore, the
model exhibits strong data efficiency, outperforming existing fully supervised
or VLM baselines while trained on synthetic text reports and without the need
for actual radiology reports.

</details>


### [27] [Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh](https://arxiv.org/abs/2510.26154)
*Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim*

Main category: cs.CV

TL;DR: 提出基于YOLOv8的机动三轮车实时检测系统，表现优异，数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 由于机动三轮车与非机动三轮车外观相似，现有监控系统难以区分，手动视频分析又耗时，因此需要自动化检测方法。

Method: 采用YOLOv8模型进行实时目标检测，使用1,730张标注图像进行训练，覆盖多种交通条件。

Result: 模型表现良好，mAP50达83.447%，二进制精度和召回率均超过78%，适用于密集和稀疏交通场景。

Conclusion: 该论文提出的基于YOLOv8模型的实时检测系统在自动识别机动三轮车方面表现出色，能够有效处理不同交通密度场景，并公开了数据集以供进一步研究。

Abstract: Modes of transportation vary across countries depending on geographical
location and cultural context. In South Asian countries rickshaws are among the
most common means of local transport. Based on their mode of operation,
rickshaws in cities across Bangladesh can be broadly classified into non-auto
(pedal-powered) and auto-rickshaws (motorized). Monitoring the movement of
auto-rickshaws is necessary as traffic rules often restrict auto-rickshaws from
accessing certain routes. However, existing surveillance systems make it quite
difficult to monitor them due to their similarity to other vehicles, especially
non-auto rickshaws whereas manual video analysis is too time-consuming. This
paper presents a machine learning-based approach to automatically detect
auto-rickshaws in traffic images. In this system, we used real-time object
detection using the YOLOv8 model. For training purposes, we prepared a set of
1,730 annotated images that were captured under various traffic conditions. The
results show that our proposed model performs well in real-time auto-rickshaw
detection and offers an mAP50 of 83.447% and binary precision and recall values
above 78%, demonstrating its effectiveness in handling both dense and sparse
traffic scenarios. The dataset has been publicly released for further research.

</details>


### [28] [CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark](https://arxiv.org/abs/2510.26160)
*Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CV

TL;DR: CRAG-MM是一个针对多模态多轮对话的RAG基准数据集，揭示了现有方法的不足并推动了领域进步。


<details>
  <summary>Details</summary>
Motivation: 当前多模态检索增强生成（MM-RAG）缺乏针对可穿戴设备场景的全面基准，阻碍了该领域的发展。

Method: 构建了包含13个领域的6.5K（图像、问题、答案）三元组和2K多轮对话数据集，设计了单源增强、多源增强和多轮对话三类任务，并提供检索API。

Result: 现有RAG方法在CRAG-MM上的准确率仅为32%-45%，工业界解决方案表现相近，但比赛优胜方案将基线性能提升了28%。

Conclusion: CRAG-MM填补了多模态多轮对话RAG任务的基准空白，通过6.5K三元组和2K多轮对话数据集展示了现有RAG方法的不足（32%-45%准确率），并为未来研究提供了改进方向。

Abstract: Wearable devices such as smart glasses are transforming the way people
interact with their surroundings, enabling users to seek information regarding
entities in their view. Multi-Modal Retrieval-Augmented Generation (MM-RAG)
plays a key role in supporting such questions, yet there is still no
comprehensive benchmark for this task, especially regarding wearables
scenarios. To fill this gap, we present CRAG-MM -- a Comprehensive RAG
benchmark for Multi-modal Multi-turn conversations. CRAG-MM contains a diverse
set of 6.5K (image, question, answer) triplets and 2K visual-based multi-turn
conversations across 13 domains, including 6.2K egocentric images designed to
mimic captures from wearable devices. We carefully constructed the questions to
reflect real-world scenarios and challenges, including five types of
image-quality issues, six question types, varying entity popularity, differing
information dynamism, and different conversation turns. We design three tasks:
single-source augmentation, multi-source augmentation, and multi-turn
conversations -- each paired with an associated retrieval corpus and APIs for
both image-KG retrieval and webpage retrieval. Our evaluation shows that
straightforward RAG approaches achieve only 32% and 43% truthfulness on CRAG-MM
single- and multi-turn QA, respectively, whereas state-of-the-art industry
solutions have similar quality (32%/45%), underscoring ample room for
improvement. The benchmark has hosted KDD Cup 2025, attracting about 1K
participants and 5K submissions, with winning solutions improving baseline
performance by 28%, highlighting its early impact on advancing the field.

</details>


### [29] [MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models](https://arxiv.org/abs/2510.26173)
*Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun*

Main category: cs.CV

TL;DR: MoTDiff是首个基于扩散模型的高分辨率运动轨迹估计框架，通过多尺度条件扩散和新型训练方法，显著提升单幅模糊图像的运动信息提取质量。


<details>
  <summary>Details</summary>
Motivation: 现有运动表示（如模糊核和光流）通常质量较低（粗粒度且不准确），需开发高分辨率、高质量的运动轨迹估计方法。

Method: MoTDiff包含两个关键组件：1）基于多尺度特征图的条件扩散框架；2）促进细粒度运动轨迹识别、运动路径形状与位置一致性估计及像素连通性的训练方法。

Result: 实验表明，MoTDiff在盲图像去模糊和编码曝光摄影应用中优于现有最先进方法。

Conclusion: MoTDiff框架通过扩散模型实现了高分辨率运动轨迹的精确估计，显著提升了单幅运动模糊图像的处理效果，优于现有方法。

Abstract: Accurate estimation of motion information is crucial in diverse computational
imaging and computer vision applications. Researchers have investigated various
methods to extract motion information from a single blurred image, including
blur kernels and optical flow. However, existing motion representations are
often of low quality, i.e., coarse-grained and inaccurate. In this paper, we
propose the first high-resolution (HR) Motion Trajectory estimation framework
using Diffusion models (MoTDiff). Different from existing motion
representations, we aim to estimate an HR motion trajectory with high-quality
from a single motion-blurred image. The proposed MoTDiff consists of two key
components: 1) a new conditional diffusion framework that uses multi-scale
feature maps extracted from a single blurred image as a condition, and 2) a new
training method that can promote precise identification of a fine-grained
motion trajectory, consistent estimation of overall shape and position of a
motion path, and pixel connectivity along a motion trajectory. Our experiments
demonstrate that the proposed MoTDiff can outperform state-of-the-art methods
in both blind image deblurring and coded exposure photography applications.

</details>


### [30] [ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts](https://arxiv.org/abs/2510.26186)
*Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo*

Main category: cs.CV

TL;DR: ConceptScope通过稀疏自编码器分析视觉数据集，自动识别和量化偏差，提升数据集审核和模型诊断效率。


<details>
  <summary>Details</summary>
Motivation: 机器学习数据集中普遍存在数据点偏向某些概念的现象，但系统识别这些偏差需要昂贵的细粒度属性标注。

Method: 利用稀疏自编码器在视觉基础模型表示上训练，发现和量化人类可解释的概念，并将概念分类为目标、上下文和偏差类型。

Result: ConceptScope能够捕捉广泛的视觉概念，并生成与语义相关图像区域对齐的空间归因，可靠地检测已知偏差并发现未标注的偏差。

Conclusion: ConceptScope是一种可扩展且自动化的框架，能够有效识别和量化视觉数据集中的偏差，为数据集审核和模型诊断提供实用工具。

Abstract: Dataset bias, where data points are skewed to certain concepts, is ubiquitous
in machine learning datasets. Yet, systematically identifying these biases is
challenging without costly, fine-grained attribute annotations. We present
ConceptScope, a scalable and automated framework for analyzing visual datasets
by discovering and quantifying human-interpretable concepts using Sparse
Autoencoders trained on representations from vision foundation models.
ConceptScope categorizes concepts into target, context, and bias types based on
their semantic relevance and statistical correlation to class labels, enabling
class-level dataset characterization, bias identification, and robustness
evaluation through concept-based subgrouping. We validate that ConceptScope
captures a wide range of visual concepts, including objects, textures,
backgrounds, facial attributes, emotions, and actions, through comparisons with
annotated datasets. Furthermore, we show that concept activations produce
spatial attributions that align with semantically meaningful image regions.
ConceptScope reliably detects known biases (e.g., background bias in
Waterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects
in ImageNet), offering a practical tool for dataset auditing and model
diagnostics.

</details>


### [31] [Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction](https://arxiv.org/abs/2510.26196)
*Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu*

Main category: cs.CV

TL;DR: 提出基于合成数据的学习方法，显著提升草图到3D姿态估计的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统草图到姿态方法因缺乏大规模草图-3D姿态标注而依赖耗时且泛化能力有限的启发式优化的问题。

Method: 采用‘从合成中学习’的策略，首先生成合成数据集SKEP-120K，然后结合2D姿态检测器、生成扩散先验和前馈神经网络进行端到端框架设计。

Result: 定性和定量评估表明，模型在准确性和速度上均有显著提升。

Conclusion: 该模型在草图到姿态任务的估计准确性和速度上均显著超越以往方法。

Abstract: 3D human pose estimation from sketches has broad applications in computer
animation and film production. Unlike traditional human pose estimation, this
task presents unique challenges due to the abstract and disproportionate nature
of sketches. Previous sketch-to-pose methods, constrained by the lack of
large-scale sketch-3D pose annotations, primarily relied on optimization with
heuristic rules-an approach that is both time-consuming and limited in
generalizability. To address these challenges, we propose a novel approach
leveraging a "learn from synthesis" strategy. First, a diffusion model is
trained to synthesize sketch images from 2D poses projected from 3D human
poses, mimicking disproportionate human structures in sketches. This process
enables the creation of a synthetic dataset, SKEP-120K, consisting of 120k
accurate sketch-3D pose annotation pairs across various sketch styles. Building
on this synthetic dataset, we introduce an end-to-end data-driven framework for
estimating human poses and shapes from diverse sketch styles. Our framework
combines existing 2D pose detectors and generative diffusion priors for sketch
feature extraction with a feed-forward neural network for efficient 2D pose
estimation. Multiple heuristic loss functions are incorporated to guarantee
geometric coherence between the derived 3D poses and the detected 2D poses
while preserving accurate self-contacts. Qualitative, quantitative, and
subjective evaluations collectively show that our model substantially surpasses
previous ones in both estimation accuracy and speed for sketch-to-pose tasks.

</details>


### [32] [Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management](https://arxiv.org/abs/2510.26203)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.CV

TL;DR: 通过新型Chebyshev集成几何网络提升供应链可持续性和风险管理，准确率显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 供应链可持续性对优化性能至关重要，而风险管理和产品分类是实现这一目标的关键问题。

Method: 采用混合卷积和几何深度学习的Chebyshev集成几何网络（Ch-EGN），利用供应链中的信息依赖性推断数据库中样本的隐藏状态。

Result: 在风险管理的交付状态预测中达到98.95%的准确率，产品分类和关系分类分别达到100%和98.07%，公司关系分类准确率为92.37%。

Conclusion: 提出的Chebyshev集成几何网络（Ch-EGN）在供应链风险管理和可持续性提升方面表现出色，平均准确率显著优于现有方法。

Abstract: The sustainability of supply chain plays a key role in achieving optimal
performance in controlling the supply chain. The management of risks that occur
in a supply chain is a fundamental problem for the purpose of developing the
sustainability of the network and elevating the performance efficiency of the
supply chain. The correct classification of products is another essential
element in a sustainable supply chain. Acknowledging recent breakthroughs in
the context of deep networks, several architectural options have been deployed
to analyze supply chain datasets. A novel geometric deep network is used to
propose an ensemble deep network. The proposed Chebyshev ensemble geometric
network (Ch-EGN) is a hybrid convolutional and geometric deep learning. This
network is proposed to leverage the information dependencies in supply chain to
derive invisible states of samples in the database. The functionality of the
proposed deep network is assessed on the two different databases. The
SupplyGraph Dataset and DataCo are considered in this research. The prediction
of delivery status of DataCo supply chain is done for risk administration. The
product classification and edge classification are performed using the
SupplyGraph database to enhance the sustainability of the supply network. An
average accuracy of 98.95% is obtained for the ensemble network for risk
management. The average accuracy of 100% and 98.07% are obtained for
sustainable supply chain in terms of 5 product group classification and 4
product relation classification, respectively. The average accuracy of 92.37%
is attained for 25 company relation classification. The results confirm an
average improvement and efficiency of the proposed method compared to the
state-of-the-art approaches.

</details>


### [33] [OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation](https://arxiv.org/abs/2510.26213)
*Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He*

Main category: cs.CV

TL;DR: 提出了OmniLayout-1M百万级多样化文档布局数据集和OmniLayout-LLM模型，通过两阶段学习显著提升了布局生成性能。


<details>
  <summary>Details</summary>
Motivation: 解决文档布局生成领域的数据稀缺问题，尤其是开放世界文档类型（如报纸和杂志）的不足。

Method: 采用两阶段Coarse-to-Fine学习范式：1) 从OmniLayout-1M数据集中学习通用布局原则；2) 通过细粒度注释将知识转移到特定领域。

Result: OmniLayout-LLM在M$^{6}$Doc数据集的多个领域表现优异，超越了现有方法。

Conclusion: 本文提出的OmniLayout-LLM模型在多个领域展现了强大的性能，显著超越了现有的布局生成专家和最新的通用大型语言模型。

Abstract: Document AI has advanced rapidly and is attracting increasing attention. Yet,
while most efforts have focused on document layout analysis (DLA), its
generative counterpart, document layout generation, remains underexplored. A
major obstacle lies in the scarcity of diverse layouts: academic papers with
Manhattan-style structures dominate existing studies, while open-world genres
such as newspapers and magazines remain severely underrepresented. To address
this gap, we curate OmniLayout-1M, the first million-scale dataset of diverse
document layouts, covering six common document types and comprising
contemporary layouts collected from multiple sources. Moreover, since existing
methods struggle in complex domains and often fail to arrange long sequences
coherently, we introduce OmniLayout-LLM, a 0.5B model with designed two-stage
Coarse-to-Fine learning paradigm: 1) learning universal layout principles from
OmniLayout-1M with coarse category definitions, and 2) transferring the
knowledge to a specific domain with fine-grained annotations. Extensive
experiments demonstrate that our approach achieves strong performance on
multiple domains in M$^{6}$Doc dataset, substantially surpassing both existing
layout generation experts and several latest general-purpose LLMs. Our code,
models, and dataset will be publicly released.

</details>


### [34] [On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations](https://arxiv.org/abs/2510.00037)
*Jianing Guo,Zhenhong Wu,Chang Tu,Yiyao Ma,Xiangqi Kong,Zhiqian Liu,Jiaming Ji,Shuning Zhang,Yuanpei Chen,Kai Chen,Qi Dou,Yaodong Yang,Xianglong Liu,Huijie Zhao,Weifeng Lv,Simin Li*

Main category: cs.CV

TL;DR: RobustVLA通过多模态稳健优化，显著提升了VLA模型在动作、指令等扰动下的性能，尤其在真实机器人应用中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作（VLA）模型对多模态扰动的稳健性不足，尤其忽视了动作、指令、环境和观察中的扰动。

Method: 通过离线稳健优化对抗最坏情况动作噪声，并采用多臂老虎机算法自动识别最具破坏性的噪声。

Result: RobustVLA在17种扰动下比基线模型提升了12.6%（pi0骨干）和10.4%（OpenVLA骨干），推理速度提升50.6倍，且在真实机器人实验中提升了65.6%。

Conclusion: RobustVLA显著提升了多模态扰动下的稳健性，特别是在真实世界机器人应用中表现优异。

Abstract: In Vision-Language-Action (VLA) models, robustness to real-world
perturbations is critical for deployment. Existing methods target simple visual
disturbances, overlooking the broader multi-modal perturbations that arise in
actions, instructions, environments, and observations. Here, we first evaluate
the robustness of mainstream VLAs under 17 perturbations across four
modalities. We find (1) actions as the most fragile modality, (2) Existing
visual-robust VLA do not gain robustness in other modality, and (3) pi0
demonstrates superior robustness with a diffusion-based action head. To build
multi-modal robust VLAs, we propose RobustVLA against perturbations in VLA
inputs and outputs. For output robustness, we perform offline robust
optimization against worst-case action noise that maximizes mismatch in flow
matching objective. This can be seen as adversarial training, label smoothing,
and outlier penalization. For input robustness, we enforce consistent actions
across input variations that preserve task semantics. To account for multiple
perturbations, we formulate robustness as a multi-armed bandit problem and
apply an upper confidence bound algorithm to automatically identify the most
harmful noise. Experiments on LIBERO demonstrate our RobustVLA delivers
absolute gains over baselines of 12.6% on the pi0 backbone and 10.4% on the
OpenVLA backbone across all 17 perturbations, achieving 50.6x faster inference
than existing visual-robust VLAs, and a 10.4% gain under mixed perturbations.
Our RobustVLA is particularly effective on real-world FR5 robot with limited
demonstrations, showing absolute gains by 65.6% under perturbations of four
modalities.

</details>


### [35] [Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models](https://arxiv.org/abs/2510.26241)
*Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa*

Main category: cs.CV

TL;DR: 现代视觉-语言模型在时间方向判断任务中表现不佳，突显其在时间连续性和因果理解上的不足。


<details>
  <summary>Details</summary>
Motivation: 探究现代视觉-语言模型（VLMs）在视频中时间信息理解方面的不足，并填补这一领域的评估空白。

Method: 通过AoT-PsyPhyBENCH基准测试，评估了多种VLMs在判断视频时间方向（正向或反向）上的表现。

Result: 大多数VLMs表现接近随机猜测，最优模型在物理不可逆过程和因果手动动作识别上也远落后于人类。

Conclusion: 当前的多模态系统在视觉-语义关联方面表现优异，但在时间连续性和因果理解方面存在显著不足。

Abstract: Modern vision-language models (VLMs) excel at many multimodal tasks, yet
their grasp of temporal information in video remains weak and, crucially,
under-evaluated. We probe this gap with a deceptively simple but revealing
challenge: judging the arrow of time (AoT)-whether a short clip is played
forward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated
benchmark that tests whether VLMs can infer temporal direction in natural
videos using the same stimuli and behavioral baselines established for humans.
Our comprehensive evaluation of open-weight and proprietary, reasoning and
non-reasoning VLMs reveals that most models perform near chance, and even the
best lag far behind human accuracy on physically irreversible processes (e.g.,
free fall, diffusion/explosion) and causal manual actions (division/addition)
that humans recognize almost instantly. These results highlight a fundamental
gap in current multimodal systems: while they capture rich visual-semantic
correlations, they lack the inductive biases required for temporal continuity
and causal understanding. We release the code and data for AoT-PsyPhyBENCH to
encourage further progress in the physical and temporal reasoning capabilities
of VLMs.

</details>


### [36] [Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws](https://arxiv.org/abs/2510.26268)
*Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song*

Main category: cs.CV

TL;DR: HCLFuse是一种受人类认知启发的红外与可见光图像融合方法，通过多尺度信息提取和时变物理引导机制，显著提升了融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成融合方法在模态信息平衡和生成能力上存在局限，且缺乏解释性，影响了复杂场景下的融合结果可靠性。

Method: 提出了一种名为HCLFuse的新方法，包括多尺度掩码调节变分瓶颈编码器和时变物理引导机制，以提取低层次模态信息并自适应调节生成过程。

Result: 实验结果表明，HCLFuse在多个数据集上的定性和定量评估中均达到最先进水平，并显著提升了语义分割指标。

Conclusion: HCLFuse方法通过结合人类认知规律和扩散模型的概率生成能力，显著提升了红外与可见光图像融合的性能，尤其在结构一致性和细节质量方面表现出色。

Abstract: Existing infrared and visible image fusion methods often face the dilemma of
balancing modal information. Generative fusion methods reconstruct fused images
by learning from data distributions, but their generative capabilities remain
limited. Moreover, the lack of interpretability in modal information selection
further affects the reliability and consistency of fusion results in complex
scenarios. This manuscript revisits the essence of generative image fusion
under the inspiration of human cognitive laws and proposes a novel infrared and
visible image fusion method, termed HCLFuse. First, HCLFuse investigates the
quantification theory of information mapping in unsupervised fusion networks,
which leads to the design of a multi-scale mask-regulated variational
bottleneck encoder. This encoder applies posterior probability modeling and
information decomposition to extract accurate and concise low-level modal
information, thereby supporting the generation of high-fidelity structural
details. Furthermore, the probabilistic generative capability of the diffusion
model is integrated with physical laws, forming a time-varying physical
guidance mechanism that adaptively regulates the generation process at
different stages, thereby enhancing the ability of the model to perceive the
intrinsic structure of data and reducing dependence on data quality.
Experimental results show that the proposed method achieves state-of-the-art
fusion performance in qualitative and quantitative evaluations across multiple
datasets and significantly improves semantic segmentation metrics. This fully
demonstrates the advantages of this generative image fusion method, drawing
inspiration from human cognition, in enhancing structural consistency and
detail quality.

</details>


### [37] [Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances](https://arxiv.org/abs/2510.26282)
*Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun*

Main category: cs.CV

TL;DR: 研究不同CNN在UBIPr数据库上的互补性，通过融合三种网络（SqueezeNet、MobileNetv2、ResNet50）实现性能提升，达到新SOTA。


<details>
  <summary>Details</summary>
Motivation: We study the complementarity of different CNNs for periocular verification at different distances on the UBIPr database.

Method: We train three architectures of increasing complexity (SqueezeNet, MobileNetv2, and ResNet50) on a large set of eye crops from VGGFace2. We analyse performance with cosine and chi2 metrics, compare different network initialisations, and apply score-level fusion via logistic regression. In addition, we use LIME heatmaps and Jensen-Shannon divergence to compare attention patterns of the CNNs.

Result: While ResNet50 consistently performs best individually, the fusion provides substantial gains, especially when combining all three networks. Heatmaps show that networks usually focus on distinct regions of a given image, which explains their complementarity.

Conclusion: Our method significantly outperforms previous works on UBIPr, achieving a new state-of-the-art.

Abstract: We study the complementarity of different CNNs for periocular verification at
different distances on the UBIPr database. We train three architectures of
increasing complexity (SqueezeNet, MobileNetv2, and ResNet50) on a large set of
eye crops from VGGFace2. We analyse performance with cosine and chi2 metrics,
compare different network initialisations, and apply score-level fusion via
logistic regression. In addition, we use LIME heatmaps and Jensen-Shannon
divergence to compare attention patterns of the CNNs. While ResNet50
consistently performs best individually, the fusion provides substantial gains,
especially when combining all three networks. Heatmaps show that networks
usually focus on distinct regions of a given image, which explains their
complementarity. Our method significantly outperforms previous works on UBIPr,
achieving a new state-of-the-art.

</details>


### [38] [Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving](https://arxiv.org/abs/2510.26292)
*Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo*

Main category: cs.CV

TL;DR: CATG通过约束流匹配技术提升自动驾驶规划的多样性和安全性，解决了模式崩溃和约束融合问题，并在NavSim v2挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法存在模式崩溃问题，而生成方法难以直接融入安全和物理约束，需额外优化阶段。CATG旨在解决这些局限性。

Method: CATG采用约束流匹配技术，显式建模流匹配过程，并直接在生成过程中施加安全和运动学约束。此外，CATG将驾驶攻击性参数化为生成过程中的控制信号。

Result: 在NavSim v2挑战中，CATG以51.31的EPDMS得分获得第二名，并荣获创新奖。

Conclusion: CATG通过约束流匹配技术有效解决了模仿学习中模式崩溃的问题，并直接在生成过程中嵌入了安全和物理约束，显著提升了自动驾驶规划的多样性和安全性。

Abstract: Planning is a critical component of end-to-end autonomous driving. However,
prevailing imitation learning methods often suffer from mode collapse, failing
to produce diverse trajectory hypotheses. Meanwhile, existing generative
approaches struggle to incorporate crucial safety and physical constraints
directly into the generative process, necessitating an additional optimization
stage to refine their outputs. To address these limitations, we propose CATG, a
novel planning framework that leverages Constrained Flow Matching. Concretely,
CATG explicitly models the flow matching process, which inherently mitigates
mode collapse and allows for flexible guidance from various conditioning
signals. Our primary contribution is the novel imposition of explicit
constraints directly within the flow matching process, ensuring that the
generated trajectories adhere to vital safety and kinematic rules. Secondly,
CATG parameterizes driving aggressiveness as a control signal during
generation, enabling precise manipulation of trajectory style. Notably, on the
NavSim v2 challenge, CATG achieved 2nd place with an EPDMS score of 51.31 and
was honored with the Innovation Award.

</details>


### [39] [Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping](https://arxiv.org/abs/2510.26294)
*Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun*

Main category: cs.CV

TL;DR: 论文通过大规模数据集训练三种CNN架构，评估眼周识别性能。在高质量数据集上实现了1-2%的EER，显著优于不受控条件下的9-15%。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索眼周区域作为生物识别特征的潜力，尤其是在高区分度和低采集约束的条件下。现有研究通常依赖小规模数据集，而本研究通过大规模数据集训练网络，填补了这一空白。

Method: 论文评估了三种不同深度和复杂度的卷积神经网络（CNN）架构，用于评估它们在眼周识别中的有效性。网络在大规模VGGFace2数据库中的1,907,572个眼部区域图像上进行训练。

Result: 实验结果表明，在不受控制的条件下（VGGFace2-Pose），识别性能较低（EER为9-15%），而在高质量数据集（UFPR-Periocular）上性能显著提升（EER为1-2%）。

Conclusion: 该论文得出结论，尽管在不受控制的条件下（如VGGFace2-Pose）的识别性能较低（EER为9-15%），但在高质量和一致的采集协议下（如UFPR-Periocular），性能显著提升（EER为1-2%）。此外，论文报告了UFPR数据集上迄今为止最低的EER。

Abstract: We focus on ocular biometrics, specifically the periocular region (the area
around the eye), which offers high discrimination and minimal acquisition
constraints. We evaluate three Convolutional Neural Network architectures of
varying depth and complexity to assess their effectiveness for periocular
recognition. The networks are trained on 1,907,572 ocular crops extracted from
the large-scale VGGFace2 database. This significantly contrasts with existing
works, which typically rely on small-scale periocular datasets for training
having only a few thousand images. Experiments are conducted with ocular images
from VGGFace2-Pose, a subset of VGGFace2 containing in-the-wild face images,
and the UFPR-Periocular database, which consists of selfies captured via mobile
devices with user guidance on the screen. Due to the uncontrolled conditions of
VGGFace2, the Equal Error Rates (EERs) obtained with ocular crops range from
9-15%, noticeably higher than the 3-6% EERs achieved using full-face images. In
contrast, UFPR-Periocular yields significantly better performance (EERs of
1-2%), thanks to higher image quality and more consistent acquisition
protocols. To the best of our knowledge, these are the lowest reported EERs on
the UFPR dataset to date.

</details>


### [40] [Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras](https://arxiv.org/abs/2510.26614)
*Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: Spiking Patches tokenizer preserves event camera properties, offering faster inference and competitive accuracy in gesture recognition and object detection.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of prior representations (frames and voxels) that lose the asynchronous and spatially sparse properties of event cameras, the authors aim to develop a representation that preserves these unique properties without sacrificing accuracy.

Method: The paper introduces Spiking Patches, a tokenizer designed for event cameras, which preserves asynchronous and spatially sparse properties of events. It is evaluated using GNN, PCN, and Transformer on gesture recognition and object detection tasks.

Result: Spiking Patches achieves up to 3.4x faster inference than voxel-based tokens and 10.4x faster than frames, while matching or surpassing accuracy (absolute improvements up to 3.8% for gesture recognition and 1.4% for object detection).

Conclusion: Tokenization represents a novel direction in event-based vision, preserving event camera properties while maintaining or surpassing accuracy, with significant speed improvements.

Abstract: We propose tokenization of events and present a tokenizer, Spiking Patches,
specifically designed for event cameras. Given a stream of asynchronous and
spatially sparse events, our goal is to discover an event representation that
preserves these properties. Prior works have represented events as frames or as
voxels. However, while these representations yield high accuracy, both frames
and voxels are synchronous and decrease the spatial sparsity. Spiking Patches
gives the means to preserve the unique properties of event cameras and we show
in our experiments that this comes without sacrificing accuracy. We evaluate
our tokenizer using a GNN, PCN, and a Transformer on gesture recognition and
object detection. Tokens from Spiking Patches yield inference times that are up
to 3.4x faster than voxel-based tokens and up to 10.4x faster than frames. We
achieve this while matching their accuracy and even surpassing in some cases
with absolute improvements up to 3.8 for gesture recognition and up to 1.4 for
object detection. Thus, tokenization constitutes a novel direction in
event-based vision and marks a step towards methods that preserve the
properties of event cameras.

</details>


### [41] [Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology](https://arxiv.org/abs/2510.26297)
*Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu*

Main category: cs.CV

TL;DR: 提出AEOS-Former模型和AEOS-Bench基准，解决AEOS星座调度问题，性能优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在大规模、动态环境和严格约束下的调度性能不足问题。

Method: 通过构建AEOS-Bench基准测试套件（包含3,907个卫星资产和16,410个场景），并开发AEOS-Former模型（包含内部约束模块和基于模拟的迭代学习）。

Result: 实验表明AEOS-Former在任务完成和能源效率上优于基线模型。

Conclusion: AEOS-Former提出了一种基于Transformer的调度模型，结合约束感知注意力机制，显著提升了敏捷地球观测卫星（AEOS）星座调度的任务完成率和能源效率。

Abstract: Agile Earth Observation Satellites (AEOSs) constellations offer unprecedented
flexibility for monitoring the Earth's surface, but their scheduling remains
challenging under large-scale scenarios, dynamic environments, and stringent
constraints. Existing methods often simplify these complexities, limiting their
real-world performance. We address this gap with a unified framework
integrating a standardized benchmark suite and a novel scheduling model. Our
benchmark suite, AEOS-Bench, contains $3,907$ finely tuned satellite assets and
$16,410$ scenarios. Each scenario features $1$ to $50$ satellites and $50$ to
$300$ imaging tasks. These scenarios are generated via a high-fidelity
simulation platform, ensuring realistic satellite behavior such as orbital
dynamics and resource constraints. Ground truth scheduling annotations are
provided for each scenario. To our knowledge, AEOS-Bench is the first
large-scale benchmark suite tailored for realistic constellation scheduling.
Building upon this benchmark, we introduce AEOS-Former, a Transformer-based
scheduling model that incorporates a constraint-aware attention mechanism. A
dedicated internal constraint module explicitly models the physical and
operational limits of each satellite. Through simulation-based iterative
learning, AEOS-Former adapts to diverse scenarios, offering a robust solution
for AEOS constellation scheduling. Experimental results demonstrate that
AEOS-Former outperforms baseline models in task completion and energy
efficiency, with ablation studies highlighting the contribution of each
component. Code and data are provided in
https://github.com/buaa-colalab/AEOSBench.

</details>


### [42] [Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG](https://arxiv.org/abs/2510.26304)
*Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari*

Main category: cs.CV

TL;DR: 研究使用EEG和问卷调查发现，音乐类型显著影响人类情感，且情感反应与脑活动模式相关。


<details>
  <summary>Details</summary>
Motivation: 探讨不同音乐类型如何影响人类情感，以更深入地理解音乐与情感之间的神经机制。

Method: 通过EEG头盔记录参与者在聆听不同音乐类型时的脑活动，并结合主观问卷调查收集情感反馈。

Result: 分析显示不同音乐类型会引发特定的情感反应，且这些反应与EEG信号中的特定模式相关联。

Conclusion: 研究发现音乐类型与人类情感之间存在显著关联，EEG信号与主观问卷调查结果的分析揭示了音乐对情感的具体影响。

Abstract: The subject of this work is to check how different types of music affect
human emotions. While listening to music, a subjective survey and brain
activity measurements were carried out using an EEG helmet. The aim is to
demonstrate the impact of different music genres on emotions. The research
involved a diverse group of participants of different gender and musical
preferences. This had the effect of capturing a wide range of emotional
responses to music. After the experiment, a relationship analysis of the
respondents' questionnaires with EEG signals was performed. The analysis
revealed connections between emotions and observed brain activity.

</details>


### [43] [A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading](https://arxiv.org/abs/2510.26315)
*Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li*

Main category: cs.CV

TL;DR: 结合CNN和ViT优势的证据融合范式，提高了DR分级的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于单一类型骨干网络（CNN或ViT）的自动DR诊断系统性能已达到瓶颈，因此需要整合不同类型的骨干网络以充分利用各自的优势（如CNN的局部特征提取能力和ViT的全局特征捕捉能力）。

Method: 提出了一种基于证据理论的新型范式，通过一组深度证据网络将不同骨干网络提取的特征转换为支持证据，形成聚合意见，自适应调整不同骨干网络间的融合模式。

Result: 在两个公开的DR分级数据集上的实验结果表明，混合模型不仅提高了DR分级的准确性，还提供了特征融合和决策的优异可解释性。

Conclusion: 通过结合CNN和ViT的优势，提出的证据融合范式不仅提高了糖尿病视网膜病变（DR）分级的准确性，还增强了特征融合和决策的可解释性。

Abstract: Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.

</details>


### [44] [GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?](https://arxiv.org/abs/2510.26339)
*Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang*

Main category: cs.CV

TL;DR: GLYPH-SR 是一种新型超分辨率框架，通过视觉-语言引导优化文本清晰度和图像质量，显著提升OCR性能。


<details>
  <summary>Details</summary>
Motivation: 传统超分辨率方法对字符级错误不敏感，且忽略复杂场景中的文本恢复挑战，导致下游感知任务（如OCR）失败。

Method: GLYPH-SR 采用 Text-SR Fusion ControlNet（TS-ControlNet）和 ping-pong 调度器，结合 OCR 数据和合成语料库进行训练。

Result: 在 SVT、SCUT-CTW1500 和 CUTE80 数据集上，GLYPH-SR 在 x4 和 x8 放大倍数下，OCR F1 分数比基线模型提升高达 15.18 个百分点，同时保持高感知质量。

Conclusion: GLYPH-SR 是一种结合文本清晰度和感知质量的超分辨率框架，通过视觉-语言引导的扩散模型，显著提升了场景文本的OCR识别率和图像质量。

Abstract: Image super-resolution(SR) is fundamental to many vision system-from
surveillance and autonomy to document analysis and retail analytics-because
recovering high-frequency details, especially scene-text, enables reliable
downstream perception. Scene-text, i.e., text embedded in natural images such
as signs, product labels, and storefronts, often carries the most actionable
information; when characters are blurred or hallucinated, optical character
recognition(OCR) and subsequent decisions fail even if the rest of the image
appears sharp. Yet previous SR research has often been tuned to distortion
(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that
are largely insensitive to character-level errors. Furthermore, studies that do
address text SR often focus on simplified benchmarks with isolated characters,
overlooking the challenges of text within complex natural scenes. As a result,
scene-text is effectively treated as generic texture. For SR to be effective in
practical deployments, it is therefore essential to explicitly optimize for
both text legibility and perceptual quality. We present GLYPH-SR, a
vision-language-guided diffusion framework that aims to achieve both objectives
jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by
OCR data, and a ping-pong scheduler that alternates between text- and
scene-centric guidance. To enable targeted text restoration, we train these
components on a synthetic corpus while keeping the main SR branch frozen.
Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by
up to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)
while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed
to satisfy both objectives simultaneously-high readability and high visual
realism-delivering SR that looks right and reds right.

</details>


### [45] [EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models](https://arxiv.org/abs/2510.26391)
*Igor Abramov,Ilya Makarov*

Main category: cs.CV

TL;DR: 提出结合EEG和空间注意力的双条件框架，显著提升图像重建质量，适用于医学和神经接口。


<details>
  <summary>Details</summary>
Motivation: 现有EEG驱动图像重建方法忽略空间注意力机制，导致保真度和语义一致性受限。

Method: 提出了双条件框架，结合EEG嵌入和空间显著性图，利用Adaptive Thinking Mapper (ATM)提取EEG特征，并通过Low-Rank Adaptation (LoRA)微调Stable Diffusion 2.1，同时使用ControlNet分支控制空间生成。

Result: 在THINGS-EEG数据集上评估，方法在低层次和高层次图像特征质量上显著优于现有方法，且与人类视觉注意力高度一致。

Conclusion: 该论文展示了结合空间注意力机制的EEG驱动图像重建方法，通过双条件框架显著提升了图像生成的质量和语义一致性，为医学诊断和神经自适应接口提供了潜在应用。

Abstract: Existing EEG-driven image reconstruction methods often overlook spatial
attention mechanisms, limiting fidelity and semantic coherence. To address
this, we propose a dual-conditioning framework that combines EEG embeddings
with spatial saliency maps to enhance image generation. Our approach leverages
the Adaptive Thinking Mapper (ATM) for EEG feature extraction and fine-tunes
Stable Diffusion 2.1 via Low-Rank Adaptation (LoRA) to align neural signals
with visual semantics, while a ControlNet branch conditions generation on
saliency maps for spatial control. Evaluated on THINGS-EEG, our method achieves
a significant improvement in the quality of low- and high-level image features
over existing approaches. Simultaneously, strongly aligning with human visual
attention. The results demonstrate that attentional priors resolve EEG
ambiguities, enabling high-fidelity reconstructions with applications in
medical diagnostics and neuroadaptive interfaces, advancing neural decoding
through efficient adaptation of pre-trained diffusion models.

</details>


### [46] [LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation](https://arxiv.org/abs/2510.26412)
*Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang*

Main category: cs.CV

TL;DR: LoCoT2V-Bench 是一个针对长视频生成的新评估基准，通过复杂提示和多维度量揭示了当前模型的局限性，为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到视频生成评估方法过于简化，忽视了与复杂提示的细粒度对齐以及叙事连贯性等抽象维度。

Method: 基于现实世界视频，引入了一套复杂提示和多维评估框架，包括新提出的度量标准如事件级对齐、细粒度时间一致性、内容清晰度和人类期望实现度（HERD）。

Result: 对九种代表性长视频生成模型的评估显示，当前方法在基础视觉和时间方面表现良好，但在事件间一致性、细粒度对齐和高层次主题一致性方面存在困难。

Conclusion: LoCoT2V-Bench 提出了一个专门用于评估长视频生成的综合平台，揭示了当前方法在复杂提示下的不足，并指出了未来改进的关键方向。

Abstract: Recently text-to-video generation has made impressive progress in producing
short, high-quality clips, but evaluating long-form outputs remains a major
challenge especially when processing complex prompts. Existing benchmarks
mostly rely on simplified prompts and focus on low-level metrics, overlooking
fine-grained alignment with prompts and abstract dimensions such as narrative
coherence and thematic expression. To address these gaps, we propose
LoCoT2V-Bench, a benchmark specifically designed for long video generation
(LVG) under complex input conditions. Based on various real-world videos,
LoCoT2V-Bench introduces a suite of realistic and complex prompts incorporating
elements like scene transitions and event dynamics. Moreover, it constructs a
multi-dimensional evaluation framework that includes our newly proposed metrics
such as event-level alignment, fine-grained temporal consistency, content
clarity, and the Human Expectation Realization Degree (HERD) that focuses on
more abstract attributes like narrative flow, emotional response, and character
development. Using this framework, we conduct a comprehensive evaluation of
nine representative LVG models, finding that while current methods perform well
on basic visual and temporal aspects, they struggle with inter-event
consistency, fine-grained alignment, and high-level thematic adherence, etc.
Overall, LoCoT2V-Bench provides a comprehensive and reliable platform for
evaluating long-form complex text-to-video generation and highlights critical
directions for future method improvement.

</details>


### [47] [A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models](https://arxiv.org/abs/2510.26441)
*Shihab Aaqil Ahamed,Udaya S. K. P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: A-TPT是一种新颖的测试时提示调优框架，通过引入角度多样性来提升视觉语言模型的校准性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前TPT方法在文本特征角度多样性方面不足，影响了模型的可靠性、可信度和安全性。

Method: 提出A-TPT框架，通过最大化单位超球面上特征的最小成对角度距离，实现归一化文本特征的均匀分布。

Result: A-TPT在多种数据集和骨干网络上显著降低校准误差，同时保持准确性，尤其在零样本校准和自然分布偏移上表现优异。

Conclusion: A-TPT通过促进角度多样性显著提升了视觉语言模型在测试时适应的校准性能。

Abstract: Test-time prompt tuning (TPT) has emerged as a promising technique for
adapting large vision-language models (VLMs) to unseen tasks without relying on
labeled data. However, the lack of dispersion between textual features can hurt
calibration performance, which raises concerns about VLMs' reliability,
trustworthiness, and safety. Current TPT approaches primarily focus on
improving prompt calibration by either maximizing average textual feature
dispersion or enforcing orthogonality constraints to encourage angular
separation. However, these methods may not always have optimal angular
separation between class-wise textual features, which implies overlooking the
critical role of angular diversity. To address this, we propose A-TPT, a novel
TPT framework that introduces angular diversity to encourage uniformity in the
distribution of normalized textual features induced by corresponding learnable
prompts. This uniformity is achieved by maximizing the minimum pairwise angular
distance between features on the unit hypersphere. We show that our approach
consistently surpasses state-of-the-art TPT methods in reducing the aggregate
average calibration error while maintaining comparable accuracy through
extensive experiments with various backbones on different datasets. Notably,
our approach exhibits superior zero-shot calibration performance on natural
distribution shifts and generalizes well to medical datasets. We provide
extensive analyses, including theoretical aspects, to establish the grounding
of A-TPT. These results highlight the potency of promoting angular diversity to
achieve well-dispersed textual features, significantly improving VLM
calibration during test-time adaptation. Our code will be made publicly
available.

</details>


### [48] [PointSt3R: Point Tracking through 3D Grounded Correspondence](https://arxiv.org/abs/2510.26443)
*Rhodri Guerrier,Adam W. Harley,Dima Damen*

Main category: cs.CV

TL;DR: 论文将基础3D重建模型适应于点跟踪任务，通过动态对应训练和可见性头部，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用基础3D重建模型在静态场景中的2D和3D对应潜力，将其扩展到点跟踪任务，以提升动态和静态点跟踪性能。

Method: 提出结合重建损失与动态对应训练，并添加可见性头部，使用少量合成数据对MASt3R进行微调，仅在一对帧中包含查询点的条件下进行训练和评估。

Result: 在四个数据集上取得竞争性或更优的点跟踪结果（如TAP-Vid-DAVIS和EgoPoints），并在3D点跟踪任务中展示出色表现。

Conclusion: 论文展示了将基础3D重建模型（如DUSt3R和MASt3R）适应于点跟踪任务的潜力，通过3D基础对应和动态对应训练，结合可见性头部，在多个数据集上取得了竞争性或更优的结果。

Abstract: Recent advances in foundational 3D reconstruction models, such as DUSt3R and
MASt3R, have shown great potential in 2D and 3D correspondence in static
scenes. In this paper, we propose to adapt them for the task of point tracking
through 3D grounded correspondence. We first demonstrate that these models are
competitive point trackers when focusing on static points, present in current
point tracking benchmarks ($+33.5\%$ on EgoPoints vs. CoTracker2). We propose
to combine the reconstruction loss with training for dynamic correspondence
along with a visibility head, and fine-tuning MASt3R for point tracking using a
relatively small amount of synthetic data. Importantly, we only train and
evaluate on pairs of frames where one contains the query point, effectively
removing any temporal context. Using a mix of dynamic and static point
correspondences, we achieve competitive or superior point tracking results on
four datasets (e.g. competitive on TAP-Vid-DAVIS 73.8 $\delta_{avg}$ / 85.8\%
occlusion acc. for PointSt3R compared to 75.7 / 88.3\% for CoTracker2; and
significantly outperform CoTracker3 on EgoPoints 61.3 vs 54.2 and RGB-S 87.0 vs
82.8). We also present results on 3D point tracking along with several
ablations on training datasets and percentage of dynamic correspondences.

</details>


### [49] [Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection](https://arxiv.org/abs/2510.26464)
*Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang*

Main category: cs.CV

TL;DR: FineGrainedAD通过多级细粒度文本描述和对齐方法，显著提升了小样本异常检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因缺乏细粒度文本描述导致语义不对齐，影响异常定位性能。

Method: 提出了MFSC自动构建多级细粒度文本描述，并设计了FineGrainedAD框架，包含MLLP和MLSA组件，通过多级学习提示和语义对齐优化异常定位。

Result: 在MVTec-AD和VisA数据集上，FineGrainedAD在小样本设置下表现优异。

Conclusion: FineGrainedAD通过MFSC和多级语义对齐方法显著提升了小样本异常检测的性能，证明了其在大规模异常检测数据集上的优越性。

Abstract: Few-shot anomaly detection (FSAD) methods identify anomalous regions with few
known normal samples. Most existing methods rely on the generalization ability
of pre-trained vision-language models (VLMs) to recognize potentially anomalous
regions through feature similarity between text descriptions and images.
However, due to the lack of detailed textual descriptions, these methods can
only pre-define image-level descriptions to match each visual patch token to
identify potential anomalous regions, which leads to the semantic misalignment
between image descriptions and patch-level visual anomalies, achieving
sub-optimal localization performance. To address the above issues, we propose
the Multi-Level Fine-Grained Semantic Caption (MFSC) to provide multi-level and
fine-grained textual descriptions for existing anomaly detection datasets with
automatic construction pipeline. Based on the MFSC, we propose a novel
framework named FineGrainedAD to improve anomaly localization performance,
which consists of two components: Multi-Level Learnable Prompt (MLLP) and
Multi-Level Semantic Alignment (MLSA). MLLP introduces fine-grained semantics
into multi-level learnable prompts through automatic replacement and
concatenation mechanism, while MLSA designs region aggregation strategy and
multi-level alignment training to facilitate learnable prompts better align
with corresponding visual regions. Experiments demonstrate that the proposed
FineGrainedAD achieves superior overall performance in few-shot settings on
MVTec-AD and VisA datasets.

</details>


### [50] [Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition](https://arxiv.org/abs/2510.26466)
*Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang*

Main category: cs.CV

TL;DR: 本文提出了一种通过合成反事实嵌入和因果干预来减少视觉-语言模型中对象-上下文捷径偏差的方法，显著提高了零样本性能。


<details>
  <summary>Details</summary>
Motivation: 对象-上下文捷径在视觉-语言模型中是一个持续的挑战，当测试场景与熟悉的训练共现不同时，会削弱零样本的可靠性。

Method: 我们通过重新组合对象特征与来自外部数据集、批次邻居或文本描述的不同替代上下文，合成了反事实嵌入，并通过估计总直接效应和模拟干预来减去仅背景激活。

Result: 我们的方法在不需要重新训练或提示设计的情况下，显著提高了上下文敏感基准的最差组和平均准确率，确立了新的零样本最先进水平。

Conclusion: 本文提出了一种轻量级的表示级反事实方法，为去偏和可靠的多模态推理提供了一种实用的因果途径。

Abstract: Object-context shortcuts remain a persistent challenge in vision-language
models, undermining zero-shot reliability when test-time scenes differ from
familiar training co-occurrences. We recast this issue as a causal inference
problem and ask: Would the prediction remain if the object appeared in a
different environment? To answer this at inference time, we estimate object and
background expectations within CLIP's representation space, and synthesize
counterfactual embeddings by recombining object features with diverse
alternative contexts sampled from external datasets, batch neighbors, or
text-derived descriptions. By estimating the Total Direct Effect and simulating
intervention, we further subtract background-only activation, preserving
beneficial object-context interactions while mitigating hallucinated scores.
Without retraining or prompt design, our method substantially improves both
worst-group and average accuracy on context-sensitive benchmarks, establishing
a new zero-shot state of the art. Beyond performance, our framework provides a
lightweight representation-level counterfactual approach, offering a practical
causal avenue for debiased and reliable multimodal reasoning.

</details>


### [51] [Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing](https://arxiv.org/abs/2510.26474)
*Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: 论文提出四种策略解决自改进中的头尾不平衡问题，显著提升模型在复杂推理任务的表现。


<details>
  <summary>Details</summary>
Motivation: 发现自改进过程中模型在简单查询（头数据）上表现优越，而在复杂查询（尾数据）上表现不佳，导致优化失衡，阻碍模型进一步改进。

Method: 提出了四种策略，包括分布重塑和轨迹重采样，以平衡简单和复杂查询的学习过程。

Result: 在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的实验表明，方法平均优于普通自改进3.86分。

Conclusion: 通过分布重塑和轨迹重采样策略，有效解决了自改进过程中的头尾不平衡问题，显著提升了模型在复杂推理任务上的性能。

Abstract: Self-improvement has emerged as a mainstream paradigm for advancing the
reasoning capabilities of large vision-language models (LVLMs), where models
explore and learn from successful trajectories iteratively. However, we
identify a critical issue during this process: the model excels at generating
high-quality trajectories for simple queries (i.e., head data) but struggles
with more complex ones (i.e., tail data). This leads to an imbalanced
optimization that drives the model to prioritize simple reasoning skills, while
hindering its ability to tackle more complex reasoning tasks. Over iterations,
this imbalance becomes increasingly pronounced--a dynamic we term the "Matthew
effect"--which ultimately hinders further model improvement and leads to
performance bottlenecks. To counteract this challenge, we introduce four
efficient strategies from two perspectives: distribution-reshaping and
trajectory-resampling, to achieve head-tail re-balancing during the
exploration-and-learning self-improvement process. Extensive experiments on
Qwen2-VL-7B-Instruct and InternVL2.5-4B models across visual reasoning tasks
demonstrate that our methods consistently improve visual reasoning
capabilities, outperforming vanilla self-improvement by 3.86 points on average.

</details>


### [52] [Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm](https://arxiv.org/abs/2510.26509)
*Vinícius Ferraria,Eurico Ruivo*

Main category: cs.CV

TL;DR: 开发了一种可适应边缘检测器，发现搜索空间扩展无效且迁移学习无显著改进。


<details>
  <summary>Details</summary>
Motivation: 解决边缘检测中存在的松散边缘检测困难和特定问题上下文信息提取不足的问题。

Method: 采用由二维元胞自动机描述的可适应检测器，结合元启发式和迁移学习技术进行优化。

Result: 优化阶段的搜索空间扩展无效，模型在不同验证下均能适应输入，迁移学习技术无显著改进。

Conclusion: 研究发现，优化阶段的搜索空间扩展对所选图像集无效，且模型的适应性在不同验证技术下表现一致，迁移学习技术未带来显著改进。

Abstract: The edge detection task is essential in image processing aiming to extract
relevant information from an image. One recurring problem in this task is the
weaknesses found in some detectors, such as the difficulty in detecting loose
edges and the lack of context to extract relevant information from specific
problems. To address these weaknesses and adapt the detector to the properties
of an image, an adaptable detector described by two-dimensional cellular
automaton and optimized by meta-heuristic combined with transfer learning
techniques was developed. This study aims to analyze the impact of expanding
the search space of the optimization phase and the robustness of the
adaptability of the detector in identifying edges of a set of natural images
and specialized subsets extracted from the same image set. The results obtained
prove that expanding the search space of the optimization phase was not
effective for the chosen image set. The study also analyzed the adaptability of
the model through a series of experiments and validation techniques and found
that, regardless of the validation, the model was able to adapt to the input
and the transfer learning techniques applied to the model showed no significant
improvements.

</details>


### [53] [SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging](https://arxiv.org/abs/2510.26568)
*Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling*

Main category: cs.CV

TL;DR: SA$^{2}$Net 是一种新型脊柱分割网络，通过尺度自适应和结构感知技术提升性能，适用于智能脊柱侧弯诊断。


<details>
  <summary>Details</summary>
Motivation: 脊柱分割在临床智能脊柱侧弯诊断中至关重要，但现有方法在全局上下文知识学习和结构知识编码方面存在不足。

Method: 提出了一种新型的尺度自适应结构感知网络（SA$^{2}$Net），包括尺度自适应互补策略、结构亲和变换和特征混合损失聚合方法。

Result: 实验结果表明，SA$^{2}$Net 在分割性能上优于其他最先进的方法。

Conclusion: SA$^{2}$Net 在脊柱分割任务中表现出卓越的性能，能够适应不同的主干网络，为智能脊柱图像分析提供了有前景的工具。

Abstract: Spine segmentation, based on ultrasound volume projection imaging (VPI),
plays a vital role for intelligent scoliosis diagnosis in clinical
applications. However, this task faces several significant challenges. Firstly,
the global contextual knowledge of spines may not be well-learned if we neglect
the high spatial correlation of different bone features. Secondly, the spine
bones contain rich structural knowledge regarding their shapes and positions,
which deserves to be encoded into the segmentation process. To address these
challenges, we propose a novel scale-adaptive structure-aware network
(SA$^{2}$Net) for effective spine segmentation. First, we propose a
scale-adaptive complementary strategy to learn the cross-dimensional
long-distance correlation features for spinal images. Second, motivated by the
consistency between multi-head self-attention in Transformers and semantic
level affinity, we propose structure-affinity transformation to transform
semantic features with class-specific affinity and combine it with a
Transformer decoder for structure-aware reasoning. In addition, we adopt a
feature mixing loss aggregation method to enhance model training. This method
improves the robustness and accuracy of the segmentation process. The
experimental results demonstrate that our SA$^{2}$Net achieves superior
segmentation performance compared to other state-of-the-art methods. Moreover,
the adaptability of SA$^{2}$Net to various backbones enhances its potential as
a promising tool for advanced scoliosis diagnosis using intelligent spinal
image analysis. The code and experimental demo are available at
https://github.com/taetiseo09/SA2Net.

</details>


### [54] [AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping](https://arxiv.org/abs/2510.26569)
*Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas*

Main category: cs.CV

TL;DR: 论文提出了一种基于双流视听融合模型的自动化视频广告剪辑方法，利用音频和视觉信息优化剪辑效果，并在新数据集AdSum204上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统广告剪辑方法耗时耗力，现有视频摘要技术未充分考虑广告中音频的重要性。

Method: 采用双流视听融合模型预测视频帧的重要性，定义为帧被选入短广告的可能性。

Result: 模型在多个指标（如平均精度、曲线下面积等）上超越现有技术。

Conclusion: 该论文提出的双流视听融合模型在视频广告剪辑任务中表现优于现有方法，特别是在结合音频信息方面具有创新性。

Abstract: Advertisers commonly need multiple versions of the same advertisement (ad) at
varying durations for a single campaign. The traditional approach involves
manually selecting and re-editing shots from longer video ads to create shorter
versions, which is labor-intensive and time-consuming. In this paper, we
introduce a framework for automated video ad clipping using video summarization
techniques. We are the first to frame video clipping as a shot selection
problem, tailored specifically for advertising. Unlike existing general video
summarization methods that primarily focus on visual content, our approach
emphasizes the critical role of audio in advertising. To achieve this, we
develop a two-stream audio-visual fusion model that predicts the importance of
video frames, where importance is defined as the likelihood of a frame being
selected in the firm-produced short ad. To address the lack of ad-specific
datasets, we present AdSum204, a novel dataset comprising 102 pairs of
30-second and 15-second ads from real advertising campaigns. Extensive
experiments demonstrate that our model outperforms state-of-the-art methods
across various metrics, including Average Precision, Area Under Curve,
Spearman, and Kendall.

</details>


### [55] [Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios](https://arxiv.org/abs/2510.26580)
*Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi*

Main category: cs.CV

TL;DR: 提出了一种动态上下文感知场景推理框架，通过视觉-语言对齐提升零样本场景理解能力，实验显示在复杂和未见过的环境中性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现实环境中，AI系统常面临无标记数据的陌生场景，传统场景理解模型难以泛化到未见过的上下文，限制了视觉应用在动态非结构化环境中的部署。

Method: 整合预训练的视觉变换器和大型语言模型，将视觉语义与自然语言描述对齐，并通过动态推理模块结合全局场景线索和对象级交互来优化预测。

Result: 在零样本基准测试（如COCO、Visual Genome和Open Images）中，场景理解准确率比基线模型提高了18%，在模糊或杂乱场景中也表现出鲁棒性能。

Conclusion: 该框架为动态现实环境中的零样本泛化提供了一种可扩展且可解释的上下文感知推理方法。

Abstract: In real-world environments, AI systems often face unfamiliar scenarios
without labeled data, creating a major challenge for conventional scene
understanding models. The inability to generalize across unseen contexts limits
the deployment of vision-based applications in dynamic, unstructured settings.
This work introduces a Dynamic Context-Aware Scene Reasoning framework that
leverages Vision-Language Alignment to address zero-shot real-world scenarios.
The goal is to enable intelligent systems to infer and adapt to new
environments without prior task-specific training. The proposed approach
integrates pre-trained vision transformers and large language models to align
visual semantics with natural language descriptions, enhancing contextual
comprehension. A dynamic reasoning module refines predictions by combining
global scene cues and object-level interactions guided by linguistic priors.
Extensive experiments on zero-shot benchmarks such as COCO, Visual Genome, and
Open Images demonstrate up to 18% improvement in scene understanding accuracy
over baseline models in complex and unseen environments. Results also show
robust performance in ambiguous or cluttered scenes due to the synergistic
fusion of vision and language. This framework offers a scalable and
interpretable approach for context-aware reasoning, advancing zero-shot
generalization in dynamic real-world settings.

</details>


### [56] [CATCH: A Modular Cross-domain Adaptive Template with Hook](https://arxiv.org/abs/2510.26582)
*Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou*

Main category: cs.CV

TL;DR: CATCH是一个即插即用的跨域适应框架，通过轻量级模块提升VQA模型泛化能力，无需重新训练主干模型，在多域基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有VQA模型在跨域场景中泛化能力差，且现有方法依赖单域微调或定制流程，成本高且不灵活。

Method: 提出了CATCH框架，包括一个域分类器和双适配器机制（Prompt Adapter和Visual Adapter），通过统一钩子接口动态注入模块。

Result: 在四个域特定VQA基准测试中，CATCH实现了性能提升（如MathVQA +2.3 BLEU，MedVQA-RAD +2.6 VQA，ChartQA +3.1 ROUGE）。

Conclusion: CATCH框架通过解耦视觉和语言适应，引入轻量级模块，显著提升了VQA模型在跨域场景中的泛化能力，无需重新训练主干模型。

Abstract: Recent advances in Visual Question Answering (VQA) have demonstrated
impressive performance in natural image domains, with models like LLaVA
leveraging large language models (LLMs) for open-ended reasoning. However,
their generalization degrades significantly when transferred to out-of-domain
scenarios such as remote sensing, medical imaging, or math diagrams, due to
large distributional shifts and the lack of effective domain adaptation
mechanisms. Existing approaches typically rely on per-domain fine-tuning or
bespoke pipelines, which are costly, inflexible, and not scalable across
diverse tasks. In this paper, we propose CATCH, a plug-and-play framework for
cross-domain adaptation that improves the generalization of VQA models while
requiring minimal changes to their core architecture. Our key idea is to
decouple visual and linguistic adaptation by introducing two lightweight
modules: a domain classifier to identify the input image type, and a dual
adapter mechanism comprising a Prompt Adapter for language modulation and a
Visual Adapter for vision feature adjustment. Both modules are dynamically
injected via a unified hook interface, requiring no retraining of the backbone
model. Experimental results across four domain-specific VQA benchmarks
demonstrate that our framework achieves consistent performance gains without
retraining the backbone model, including +2.3 BLEU on MathVQA, +2.6 VQA on
MedVQA-RAD, and +3.1 ROUGE on ChartQA. These results highlight that CATCH
provides a scalable and extensible approach to multi-domain VQA, enabling
practical deployment across diverse application domains.

</details>


### [57] [Emu3.5: Native Multimodal Models are World Learners](https://arxiv.org/abs/2510.26583)
*Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang*

Main category: cs.CV

TL;DR: Emu3.5是一个多模态世界模型，通过预训练和后训练实现高效的多模态生成和推理，性能优越。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够原生预测视觉和语言下一状态的大规模多模态世界模型，以支持长视野视觉语言生成、任意到图像生成等复杂任务。

Method: Emu3.5通过统一的下一标记预测目标进行端到端预训练，并利用大规模强化学习进行后训练。此外，提出了Discrete Diffusion Adaptation（DiDA）技术，显著提升推理效率。

Result: Emu3.5在多模态生成任务中表现出色，推理效率提升约20倍，且性能不降。

Conclusion: Emu3.5展示了强大的原生多模态能力，并在多种任务中表现优异，性能与Gemini 2.5 Flash Image相当，甚至在部分任务中更优。

Abstract: We introduce Emu3.5, a large-scale multimodal world model that natively
predicts the next state across vision and language. Emu3.5 is pre-trained
end-to-end with a unified next-token prediction objective on a corpus of
vision-language interleaved data containing over 10 trillion tokens, primarily
derived from sequential frames and transcripts of internet videos. The model
naturally accepts interleaved vision-language inputs and generates interleaved
vision-language outputs. Emu3.5 is further post-trained with large-scale
reinforcement learning to enhance multimodal reasoning and generation. To
improve inference efficiency, we propose Discrete Diffusion Adaptation (DiDA),
which converts token-by-token decoding into bidirectional parallel prediction,
accelerating per-image inference by about 20x without sacrificing performance.
Emu3.5 exhibits strong native multimodal capabilities, including long-horizon
vision-language generation, any-to-image (X2I) generation, and complex
text-rich image generation. It also exhibits generalizable world-modeling
abilities, enabling spatiotemporally consistent world exploration and
open-world embodied manipulation across diverse scenarios and tasks. For
comparison, Emu3.5 achieves performance comparable to Gemini 2.5 Flash Image
(Nano Banana) on image generation and editing tasks and demonstrates superior
results on a suite of interleaved generation tasks. We open-source Emu3.5 at
https://github.com/baaivision/Emu3.5 to support community research.

</details>


### [58] [ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching](https://arxiv.org/abs/2510.26601)
*Anirban Ray,Vera Galinova,Florian Jug*

Main category: cs.CV

TL;DR: ResMatching是一种新型CSR方法，通过流匹配学习先验知识，在BioSR数据集上表现优于基线方法，并提供不确定性评估。


<details>
  <summary>Details</summary>
Motivation: 随着数据驱动机器学习技术的发展，更强的先验知识可以被学习，从而提升CSR的效果。

Method: ResMatching采用引导条件流匹配技术，学习改进的数据先验，并在BioSR数据集的4种生物结构上进行了测试。

Result: 在BioSR数据集上，ResMatching在7种基线方法中表现最优，尤其在噪声较多的低分辨率图像处理中效果显著。

Conclusion: ResMatching在计算超分辨率（CSR）中表现优异，尤其在数据保真度与感知真实性之间实现了最佳平衡。该方法还能生成像素级数据不确定性评估，指导用户过滤不可靠预测。

Abstract: Computational Super-Resolution (CSR) in fluorescence microscopy has, despite
being an ill-posed problem, a long history. At its very core, CSR is about
finding a prior that can be used to extrapolate frequencies in a micrograph
that have never been imaged by the image-generating microscope. It stands to
reason that, with the advent of better data-driven machine learning techniques,
stronger prior can be learned and hence CSR can lead to better results. Here,
we present ResMatching, a novel CSR method that uses guided conditional flow
matching to learn such improved data-priors. We evaluate ResMatching on 4
diverse biological structures from the BioSR dataset and compare its results
against 7 baselines. ResMatching consistently achieves competitive results,
demonstrating in all cases the best trade-off between data fidelity and
perceptual realism. We observe that CSR using ResMatching is particularly
effective in cases where a strong prior is hard to learn, e.g. when the given
low-resolution images contain a lot of noise. Additionally, we show that
ResMatching can be used to sample from an implicitly learned posterior
distribution and that this distribution is calibrated for all tested use-cases,
enabling our method to deliver a pixel-wise data-uncertainty term that can
guide future users to reject uncertain predictions.

</details>


### [59] [CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing](https://arxiv.org/abs/2510.26609)
*Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel*

Main category: cs.CV

TL;DR: CYPRESS 是一种用于高分辨率、田间内油菜籽产量预测的深度学习模型，利用预训练的地理空间基础模型，性能优于现有方法，为精准农业提供更实用的工具。


<details>
  <summary>Details</summary>
Motivation: 精准和及时的作物产量预测对全球粮食安全和现代农业管理至关重要。传统方法往往缺乏精准农业所需的可扩展性和粒度。

Method: CYPRESS 是一种深度学习模型，利用预训练的大规模地理空间基础模型（Prithvi-EO-2.0-600M），并将其调整为连续回归任务，将多时相卫星图像转化为密集的像素级产量图。

Result: 在加拿大草原的综合数据集上评估，CYPRESS 表现出优于现有基于深度学习的产量预测模型的性能，突出了对基础模型进行微调在专门农业应用中的有效性。

Conclusion: CYPRESS 验证了一种新颖的方法，填补了大规模地球观测与农场决策之间的空白，为详细的农业监测提供了可扩展的解决方案。

Abstract: Accurate and timely crop yield prediction is crucial for global food security
and modern agricultural management. Traditional methods often lack the
scalability and granularity required for precision farming. This paper
introduces CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder
for Satellite Sensing), a deep learning model designed for high-resolution,
intra-field canola yield prediction. CYPRESS leverages a pre-trained,
large-scale geospatial foundation model (Prithvi-EO-2.0-600M) and adapts it for
a continuous regression task, transforming multi-temporal satellite imagery
into dense, pixel-level yield maps. Evaluated on a comprehensive dataset from
the Canadian Prairies, CYPRESS demonstrates superior performance over existing
deep learning-based yield prediction models, highlighting the effectiveness of
fine-tuning foundation models for specialized agricultural applications. By
providing a continuous, high-resolution output, CYPRESS offers a more
actionable tool for precision agriculture than conventional classification or
county-level aggregation methods. This work validates a novel approach that
bridges the gap between large-scale Earth observation and on-farm
decision-making, offering a scalable solution for detailed agricultural
monitoring.

</details>


### [60] [PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus](https://arxiv.org/abs/2510.26630)
*Bingcong Huo,Zhiming Wang*

Main category: cs.CV

TL;DR: PT-DETR是一种针对无人机图像中小型物体检测的改进算法，通过PADF、MFFF模块和Focaler-SIoU提升了检测精度和鲁棒性，性能优于RT-DETR。


<details>
  <summary>Details</summary>
Motivation: 解决无人机图像中复杂背景、严重遮挡、密集小物体和光照变化等挑战。

Method: 提出了基于RT-DETR的PT-DETR算法，包括Partially-Aware Detail Focus (PADF)模块增强小型物体特征提取，Median-Frequency Feature Fusion (MFFF)模块提升细节和上下文信息捕捉能力，以及Focaler-SIoU加强边界框匹配能力。

Result: 在VisDrone2019数据集上mAP提升1.6%和1.7%，计算复杂度和参数减少。

Conclusion: PT-DETR在VisDrone2019数据集上相比RT-DETR实现了mAP提升1.6%和1.7%，具有更低的计算复杂度和更少的参数，证明了其在小型物体检测任务中的鲁棒性和可行性。

Abstract: To address the challenges in UAV object detection, such as complex
backgrounds, severe occlusion, dense small objects, and varying lighting
conditions,this paper proposes PT-DETR based on RT-DETR, a novel detection
algorithm specifically designed for small objects in UAV imagery. In the
backbone network, we introduce the Partially-Aware Detail Focus (PADF) Module
to enhance feature extraction for small objects. Additionally,we design the
Median-Frequency Feature Fusion (MFFF) module,which effectively improves the
model's ability to capture small-object details and contextual information.
Furthermore,we incorporate Focaler-SIoU to strengthen the model's bounding box
matching capability and increase its sensitivity to small-object features,
thereby further enhancing detection accuracy and robustness. Compared with
RT-DETR, our PT-DETR achieves mAP improvements of 1.6% and 1.7% on the
VisDrone2019 dataset with lower computational complexity and fewer parameters,
demonstrating its robustness and feasibility for small-object detection tasks.

</details>


### [61] [All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles](https://arxiv.org/abs/2510.26641)
*Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi*

Main category: cs.CV

TL;DR: 本文综述了自动驾驶车辆中物体检测的现状与未来，重点探讨了新兴AI技术在多模态感知中的应用。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆的成功依赖于在复杂多模态环境中可靠的物体检测能力，但目前知识在多模态感知、上下文推理和协作智能方面仍分散。本文旨在填补这一空白。

Method: 本文系统性地回顾了AV传感器的基本频谱（如相机、超声波、LiDAR和雷达）及其融合策略，并介绍了结构化分类的AV数据集，分析了前沿的检测方法。

Result: 本文强调了新兴范式（如视觉语言模型、大语言模型和生成式AI）的潜力，并分析了前沿检测方法，特别是基于Transformer的方法。

Conclusion: 本文通过综合分析自动驾驶车辆（AVs）中的物体检测技术，提供了当前能力、开放挑战和未来机遇的清晰路线图。

Abstract: Autonomous Vehicles (AVs) are transforming the future of transportation
through advances in intelligent perception, decision-making, and control
systems. However, their success is tied to one core capability, reliable object
detection in complex and multimodal environments. While recent breakthroughs in
Computer Vision (CV) and Artificial Intelligence (AI) have driven remarkable
progress, the field still faces a critical challenge as knowledge remains
fragmented across multimodal perception, contextual reasoning, and cooperative
intelligence. This survey bridges that gap by delivering a forward-looking
analysis of object detection in AVs, emphasizing emerging paradigms such as
Vision-Language Models (VLMs), Large Language Models (LLMs), and Generative AI
rather than re-examining outdated techniques. We begin by systematically
reviewing the fundamental spectrum of AV sensors (camera, ultrasonic, LiDAR,
and Radar) and their fusion strategies, highlighting not only their
capabilities and limitations in dynamic driving environments but also their
potential to integrate with recent advances in LLM/VLM-driven perception
frameworks. Next, we introduce a structured categorization of AV datasets that
moves beyond simple collections, positioning ego-vehicle, infrastructure-based,
and cooperative datasets (e.g., V2V, V2I, V2X, I2I), followed by a
cross-analysis of data structures and characteristics. Ultimately, we analyze
cutting-edge detection methodologies, ranging from 2D and 3D pipelines to
hybrid sensor fusion, with particular attention to emerging transformer-driven
approaches powered by Vision Transformers (ViTs), Large and Small Language
Models (SLMs), and VLMs. By synthesizing these perspectives, our survey
delivers a clear roadmap of current capabilities, open challenges, and future
opportunities.

</details>


### [62] [Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2](https://arxiv.org/abs/2510.26653)
*Daniela Martin,Joseph Gallego*

Main category: cs.CV

TL;DR: 深度学习光流方法首次大规模应用于海冰漂移估计，在SAR影像中表现出色，为极地遥感提供新工具。


<details>
  <summary>Details</summary>
Motivation: 光流技术在计算机视觉中快速发展，但其在地球物理问题和卫星SAR影像中的应用尚未充分探索。

Method: 评估48种深度学习光流模型在RADARSAT 2 ScanSAR海冰影像上的性能，使用端点误差(EPE)和Fl指标与GNSS跟踪浮标对比。

Result: 多个模型达到亚公里级精度（EPE 6至8像素，300至400米），相较于海冰运动空间尺度和北极导航需求误差较小。

Conclusion: 深度学习光流方法在极地遥感中有效，能提供连续漂移场，为北极导航和气候建模带来新机遇。

Abstract: Accurate estimation of sea ice drift is critical for Arctic navigation,
climate research, and operational forecasting. While optical flow, a computer
vision technique for estimating pixel wise motion between consecutive images,
has advanced rapidly in computer vision, its applicability to geophysical
problems and to satellite SAR imagery remains underexplored. Classical optical
flow methods rely on mathematical models and strong assumptions about motion,
which limit their accuracy in complex scenarios. Recent deep learning based
approaches have substantially improved performance and are now the standard in
computer vision, motivating their application to sea ice drift estimation. We
present the first large scale benchmark of 48 deep learning optical flow models
on RADARSAT 2 ScanSAR sea ice imagery, evaluated with endpoint error (EPE) and
Fl all metrics against GNSS tracked buoys. Several models achieve sub kilometer
accuracy (EPE 6 to 8 pixels, 300 to 400 m), a small error relative to the
spatial scales of sea ice motion and typical navigation requirements in the
Arctic. Our results demonstrate that the models are capable of capturing
consistent regional drift patterns and that recent deep learning based optical
flow methods, which have substantially improved motion estimation accuracy
compared to classical methods, can be effectively transferred to polar remote
sensing. Optical flow produces spatially continuous drift fields, providing
motion estimates for every image pixel rather than at sparse buoy locations,
offering new opportunities for navigation and climate modeling.

</details>


### [63] [Improving Classification of Occluded Objects through Scene Context](https://arxiv.org/abs/2510.26681)
*Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis*

Main category: cs.CV

TL;DR: 通过两种场景信息融合技术增强RPN-DCNN网络对遮挡的鲁棒性，实验显示在遮挡数据集上性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 遮挡对物体识别算法构成挑战，需利用额外信息（如场景上下文）来减少遮挡导致的错误。

Method: 提出了两种基于场景的信息融合技术：一种在预测前根据识别出的背景场景选择自定义物体网络，另一种在检测后将场景知识融合到RPN初始物体分数中。

Result: 在部分遮挡的挑战性数据集上，相比基线方法，算法在召回率和精确率上均有所提升。

Conclusion: 该方法易于解释且可适配其他数据集，为未来研究和实际应用提供了多个方向。

Abstract: The presence of occlusions has provided substantial challenges to
typically-powerful object recognition algorithms. Additional sources of
information can be extremely valuable to reduce errors caused by occlusions.
Scene context is known to aid in object recognition in biological vision. In
this work, we attempt to add robustness into existing Region Proposal
Network-Deep Convolutional Neural Network (RPN-DCNN) object detection networks
through two distinct scene-based information fusion techniques. We present one
algorithm under each methodology: the first operates prior to prediction,
selecting a custom object network to use based on the identified background
scene, and the second operates after detection, fusing scene knowledge into
initial object scores output by the RPN. We demonstrate our algorithms on
challenging datasets featuring partial occlusions, which show overall
improvement in both recall and precision against baseline methods. In addition,
our experiments contrast multiple training methodologies for occlusion
handling, finding that training on a combination of both occluded and
unoccluded images demonstrates an improvement over the others. Our method is
interpretable and can easily be adapted to other datasets, offering many future
directions for research and practical applications.

</details>


### [64] [Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill](https://arxiv.org/abs/2510.26684)
*Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta*

Main category: cs.CV

TL;DR: 该论文介绍了一种基于机器视觉的异常检测系统，用于钢铁轧制厂的故障预测，结合深度学习和传感器数据，有效减少非计划停机成本。


<details>
  <summary>Details</summary>
Motivation: 研究动机是减少钢铁轧制厂因设备故障导致的非计划停机成本，通过早期故障预测提升生产效率。

Method: 论文方法是通过工业摄像头实时监控设备运行，利用深度学习模型在中央视频服务器上处理实时视频流，并结合传感器数据进行分析。

Result: 研究结果显示，该系统能早期预测设备故障和工艺中断，减少非计划停机成本，并通过集中式推理最小化工业过程控制系统的计算负担。

Conclusion: 该论文的结论是集成机器视觉和传感器数据分析的系统能有效预测和定位设备故障，提升工业制造的可靠性、生产力和盈利能力。

Abstract: We present a long-term deployment study of a machine vision-based anomaly
detection system for failure prediction in a steel rolling mill. The system
integrates industrial cameras to monitor equipment operation, alignment, and
hot bar motion in real time along the process line. Live video streams are
processed on a centralized video server using deep learning models, enabling
early prediction of equipment failures and process interruptions, thereby
reducing unplanned breakdown costs. Server-based inference minimizes the
computational load on industrial process control systems (PLCs), supporting
scalable deployment across production lines with minimal additional resources.
By jointly analyzing sensor data from data acquisition systems and visual
inputs, the system identifies the location and probable root causes of
failures, providing actionable insights for proactive maintenance. This
integrated approach enhances operational reliability, productivity, and
profitability in industrial manufacturing environments.

</details>


### [65] [SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models](https://arxiv.org/abs/2510.26769)
*Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas*

Main category: cs.CV

TL;DR: SteerVLM是一个轻量级模块，通过动态调整激活实现对视觉-语言模型的精细控制，无需修改权重，且在非目标任务上保持性能。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种无需修改模型权重即可精细控制视觉-语言模型输出的方法，以更好地遵循指令。

Method: 该方法从编码目标与对立行为的提示的潜在嵌入中学习，动态调整连接语言模态与图像上下文的激活。

Result: SteerVLM在转向和幻觉缓解基准测试中优于现有干预技术，且仅需原模型0.14%的参数。

Conclusion: SteerVLM通过轻量级的激活调制实现了对视觉-语言模型的精细控制，无需修改模型权重，同时在非目标任务上保持性能。

Abstract: This work introduces SteerVLM, a lightweight steering module designed to
guide Vision-Language Models (VLMs) towards outputs that better adhere to
desired instructions. Our approach learns from the latent embeddings of paired
prompts encoding target and converse behaviors to dynamically adjust
activations connecting the language modality with image context. This allows
for fine-grained, inference-time control over complex output semantics without
modifying model weights while preserving performance on off-target tasks. Our
steering module requires learning parameters equal to 0.14% of the original
VLM's size. Our steering module gains model control through dimension-wise
activation modulation and adaptive steering across layers without requiring
pre-extracted static vectors or manual tuning of intervention points.
Furthermore, we introduce VNIA (Visual Narrative Intent Alignment), a
multimodal dataset specifically created to facilitate the development and
evaluation of VLM steering techniques. Our method outperforms existing
intervention techniques on steering and hallucination mitigation benchmarks for
VLMs and proposes a robust solution for multimodal model control through
activation engineering.

</details>


### [66] [Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance](https://arxiv.org/abs/2510.26778)
*Valentyna Starodub,Mantas Lukoševičius*

Main category: cs.CV

TL;DR: 本研究通过改进U-Net框架，在RGB眼底图像中实现了优于现有方法的AMD病变检测，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 年龄相关性黄斑变性（AMD）是60岁以上人群不可逆视力损害的主要原因之一，本研究旨在通过非侵入性且成本效益高的RGB眼底图像技术进行AMD病变的语义分割检测。

Method: 以U-Net连接性为基础框架，评估并比较了多种改进分割模型架构和训练流程的方法，包括预处理技术、不同复杂度的编码器（主干）深度网络类型，以及针对图像和像素级别类别不平衡的特殊损失函数。

Result: 最终框架配置在多类AMD病变类型的非侵入性RGB眼底图像分割中表现优于所有先前的ADAM挑战提交结果。

Conclusion: 本研究提出了一个在非侵入性RGB眼底图像中检测AMD病变的最终框架配置，其性能优于之前所有的ADAM挑战提交结果。

Abstract: Age-related macular degeneration (AMD) is one of the leading causes of
irreversible vision impairment in people over the age of 60. This research
focuses on semantic segmentation for AMD lesion detection in RGB fundus images,
a non-invasive and cost-effective imaging technique. The results of the ADAM
challenge - the most comprehensive AMD detection from RGB fundus images
research competition and open dataset to date - serve as a benchmark for our
evaluation. Taking the U-Net connectivity as a base of our framework, we
evaluate and compare several approaches to improve the segmentation model's
architecture and training pipeline, including pre-processing techniques,
encoder (backbone) deep network types of varying complexity, and specialized
loss functions to mitigate class imbalances on image and pixel levels. The main
outcome of this research is the final configuration of the AMD detection
framework, which outperforms all the prior ADAM challenge submissions on the
multi-class segmentation of different AMD lesion types in non-invasive RGB
fundus images. The source code used to conduct the experiments presented in
this paper is made freely available.

</details>


### [67] [ChartAB: A Benchmark for Chart Grounding & Dense Alignment](https://arxiv.org/abs/2510.26781)
*Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou*

Main category: cs.CV

TL;DR: 本文提出ChartAB基准，评估VLMs在图表基础任务中的表现，发现模型在细节感知和跨图表推理方面存在局限，需改进特定技能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在图表细节感知和细粒度结构提取方面表现不足，限制了其在图表比较和推理中的应用。

Method: 设计了一个JSON模板以支持针对不同基础任务的评估指标计算，并采用两阶段推理工作流评估VLMs在跨图表元素/属性对齐与对比中的能力。

Result: 评估结果显示VLMs在图表理解中存在感知偏差、弱点、鲁棒性不足和幻觉等问题，揭示了不同模型在细粒度任务中的差异。

Conclusion: 本文通过引入ChartAlign Benchmark（ChartAB）全面评估了视觉语言模型（VLMs）在图表基础任务中的表现，揭示了模型在细节感知、细粒度结构提取及跨图表对比推理中的局限性，并指出了未来模型需改进的特定技能。

Abstract: Charts play an important role in visualization, reasoning, data analysis, and
the exchange of ideas among humans. However, existing vision-language models
(VLMs) still lack accurate perception of details and struggle to extract
fine-grained structures from charts. Such limitations in chart grounding also
hinder their ability to compare multiple charts and reason over them. In this
paper, we introduce a novel "ChartAlign Benchmark (ChartAB)" to provide a
comprehensive evaluation of VLMs in chart grounding tasks, i.e., extracting
tabular data, localizing visualization elements, and recognizing various
attributes from charts of diverse types and complexities. We design a JSON
template to facilitate the calculation of evaluation metrics specifically
tailored for each grounding task. By incorporating a novel two-stage inference
workflow, the benchmark can further evaluate VLMs' capability to align and
compare elements/attributes across two charts. Our analysis of evaluations on
several recent VLMs reveals new insights into their perception biases,
weaknesses, robustness, and hallucinations in chart understanding. These
findings highlight the fine-grained discrepancies among VLMs in chart
understanding tasks and point to specific skills that need to be strengthened
in current models.

</details>


### [68] [The Quest for Generalizable Motion Generation: Data, Model, and Evaluation](https://arxiv.org/abs/2510.26794)
*Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu*

Main category: cs.CV

TL;DR: ViMoGen框架通过视频生成的知识迁移，提升了3D人体运动生成的泛化能力，包括数据集、模型和评估基准的全面优化。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成模型在泛化能力上存在瓶颈，而视频生成领域在建模人类行为上表现出更强的泛化能力，因此探索如何将视频生成领域的知识迁移至运动生成领域。

Method: 提出了ViMoGen框架，包括ViMoGen-228K数据集、基于流匹配的扩散变换器ViMoGen及其轻量版ViMoGen-light，以及MBench评估基准。

Result: 实验表明，ViMoGen框架在自动和人工评估中均显著优于现有方法。

Conclusion: 本文提出了一个系统化的框架ViMoGen，通过数据、建模和评估三个关键方面，将视频生成领域的知识迁移至3D人体运动生成领域，显著提升了模型的生成能力和泛化能力。

Abstract: Despite recent advances in 3D human motion generation (MoGen) on standard
benchmarks, existing models still face a fundamental bottleneck in their
generalization capability. In contrast, adjacent generative fields, most
notably video generation (ViGen), have demonstrated remarkable generalization
in modeling human behaviors, highlighting transferable insights that MoGen can
leverage. Motivated by this observation, we present a comprehensive framework
that systematically transfers knowledge from ViGen to MoGen across three key
pillars: data, modeling, and evaluation. First, we introduce ViMoGen-228K, a
large-scale dataset comprising 228,000 high-quality motion samples that
integrates high-fidelity optical MoCap data with semantically annotated motions
from web videos and synthesized samples generated by state-of-the-art ViGen
models. The dataset includes both text-motion pairs and text-video-motion
triplets, substantially expanding semantic diversity. Second, we propose
ViMoGen, a flow-matching-based diffusion transformer that unifies priors from
MoCap data and ViGen models through gated multimodal conditioning. To enhance
efficiency, we further develop ViMoGen-light, a distilled variant that
eliminates video generation dependencies while preserving strong
generalization. Finally, we present MBench, a hierarchical benchmark designed
for fine-grained evaluation across motion quality, prompt fidelity, and
generalization ability. Extensive experiments show that our framework
significantly outperforms existing approaches in both automatic and human
evaluations. The code, data, and benchmark will be made publicly available.

</details>


### [69] [Scaling Image Geo-Localization to Continent Level](https://arxiv.org/abs/2510.26795)
*Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls*

Main category: cs.CV

TL;DR: 本文介绍了一种混合方法，通过代理分类和航空影像嵌入实现大范围细粒度地理定位，68%查询定位精度在200米内。


<details>
  <summary>Details</summary>
Motivation: 解决全球尺度下图像精确地理定位的挑战，克服标准图像检索技术在大规模数据和覆盖不足时的局限性。

Method: 利用代理分类任务学习丰富的特征表示，隐式编码精确位置信息，并结合航空影像的嵌入表示。

Result: 在大范围欧洲数据集上，68%以上的查询能够定位在200米以内。

Conclusion: 本文提出了一种混合方法，能够在大陆尺度上实现细粒度的地理定位，通过结合代理分类任务学习和航空影像嵌入，提高了对地面数据稀疏性的鲁棒性。

Abstract: Determining the precise geographic location of an image at a global scale
remains an unsolved challenge. Standard image retrieval techniques are
inefficient due to the sheer volume of images (>100M) and fail when coverage is
insufficient. Scalable solutions, however, involve a trade-off: global
classification typically yields coarse results (10+ kilometers), while
cross-view retrieval between ground and aerial imagery suffers from a domain
gap and has been primarily studied on smaller regions. This paper introduces a
hybrid approach that achieves fine-grained geo-localization across a large
geographic expanse the size of a continent. We leverage a proxy classification
task during training to learn rich feature representations that implicitly
encode precise location information. We combine these learned prototypes with
embeddings of aerial imagery to increase robustness to the sparsity of
ground-level data. This enables direct, fine-grained retrieval over areas
spanning multiple countries. Our extensive evaluation demonstrates that our
approach can localize within 200m more than 68\% of queries of a dataset
covering a large part of Europe. The code is publicly available at
https://scaling-geoloc.github.io.

</details>


### [70] [Masked Diffusion Captioning for Visual Feature Learning](https://arxiv.org/abs/2510.26799)
*Chao Feng,Zihao Wei,Andrew Owens*

Main category: cs.CV

TL;DR: MDC通过掩码扩散语言模型学习视觉特征，减少对辅助目标的依赖，并在下游任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 通过MDC方法减少对辅助目标的依赖，提升视觉学习信号的强度，不依赖于序列中令牌的位置。

Method: 使用图像条件掩码扩散语言模型（MDC）进行训练，随机掩码图像-标题对中的文本令牌，并训练基于视觉特征的解码器以重建原始文本。

Result: 线性探测实验表明，MDC学习到的视觉特征在多种学术规模模型和数据集上具有竞争力。

Conclusion: MDC学习到的视觉特征在下游视觉任务中表现出色，与自回归和对比方法相竞争。

Abstract: We learn visual features by captioning images with an image-conditioned
masked diffusion language model, a formulation we call masked diffusion
captioning (MDC). During training, text tokens in each image-caption pair are
masked at a randomly chosen ratio, and a decoder conditioned on visual features
is trained to reconstruct the original text. After training, the learned visual
features can be applied to downstream vision tasks. Unlike autoregressive
captioning, the strength of the visual learning signal in MDC does not depend
on each token's position in the sequence, reducing the need for auxiliary
objectives. Linear probing experiments across a variety of academic-scale
models and datasets show that the learned visual features are competitive with
those produced by autoregressive and contrastive approaches.

</details>


### [71] [Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark](https://arxiv.org/abs/2510.26802)
*Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 研究发现视频模型在短时推理任务中表现良好，但长时因果推理能力有限，尚不能独立作为零样本推理器。


<details>
  <summary>Details</summary>
Motivation: 探讨视频模型是否能作为零样本推理器应对复杂视觉推理场景。

Method: 通过实证研究，评估Veo-3在12个维度（如空间、几何、物理、时间等）的推理行为，并创建MME-CoF基准进行系统评估。

Result: 视频模型在短时推理任务中表现良好，但在长时因果推理和抽象逻辑方面存在不足。

Conclusion: 当前视频模型在短时空间一致性、细粒度定位和局部动态一致性方面展现出有希望的推理模式，但在长时因果推理、严格几何约束和抽象逻辑方面仍有局限。它们尚未能作为独立的零样本推理器，但可以作为专用推理模型的辅助视觉引擎。

Abstract: Recent video generation models can produce high-fidelity, temporally coherent
videos, indicating that they may encode substantial world knowledge. Beyond
realistic synthesis, they also exhibit emerging behaviors indicative of visual
perception, modeling, and manipulation. Yet, an important question still
remains: Are video models ready to serve as zero-shot reasoners in challenging
visual reasoning scenarios? In this work, we conduct an empirical study to
comprehensively investigate this question, focusing on the leading and popular
Veo-3. We evaluate its reasoning behavior across 12 dimensions, including
spatial, geometric, physical, temporal, and embodied logic, systematically
characterizing both its strengths and failure modes. To standardize this study,
we curate the evaluation data into MME-CoF, a compact benchmark that enables
in-depth and thorough assessment of Chain-of-Frame (CoF) reasoning. Our
findings reveal that while current video models demonstrate promising reasoning
patterns on short-horizon spatial coherence, fine-grained grounding, and
locally consistent dynamics, they remain limited in long-horizon causal
reasoning, strict geometric constraints, and abstract logic. Overall, they are
not yet reliable as standalone zero-shot reasoners, but exhibit encouraging
signs as complementary visual engines alongside dedicated reasoning models.
Project page: https://video-cof.github.io

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [72] [A Zero Added Loss Multiplexing (ZALM) Source Simulation](https://arxiv.org/abs/2510.26009)
*Jerry Horgan,Alexander Nico-Katz,Shelbi L. Jenkins,Ashley N. Tittlebaugh,Vivek Visan,Rahan Bali,Marco Ruffini,Boulat A. Bash,Daniel C. Kilper*

Main category: cs.NI

TL;DR: ZALM模拟器展示了如何优化量子网络设计，通过调整SPDC带宽可在保持保真度的同时提高纠缠对生成速率。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过ZALM技术实现宽带、每个通道的预示EPR对，并探索设计选择对输出速率和保真度的影响。

Method: 使用NetSquid和QSI控制器构建的模块化模拟器，包含20多个可调参数，支持理想和现实模式，并提供了多种量子组件的重用模型。

Result: 模拟结果显示，默认配置下平均保真度稳定在0.8，但随着链路距离增加，纠缠对生成速率下降；通过调整SPDC带宽可以显著提高生成速率而不影响保真度。

Conclusion: ZALM模拟器通过模块化设计和丰富的可调参数，展示了如何优化设计以平衡保真度、链路距离和纠缠对生成速率，为量子网络研究提供了重要工具。

Abstract: Zero Added Loss Multiplexing (ZALM) offers broadband, per channel heralded
EPR pairs, with a rich parameter space that allows its performance to be
tailored for specific applications. We present a modular ZALM simulator that
demonstrates how design choices affect output rate and fidelity. Built in
NetSquid with QSI controllers, it exposes 20+ tunable parameters, supports
IDEAL and REALISTIC modes, and provides reusable components for Spontaneous
Parametric Down Conversion (SPDC) sources, interference, Dense Wavelength
Division Multiplexing (DWDM) filtering, fiber delay, active polarization gates,
detectors, and lossy fiber. Physics based models capture Hong Ou Mandel (HOM)
visibility, insertion loss, detector efficiency, gate errors, and attenuation.
Using this tool, we map trade offs among fidelity, link distance, and entangled
pairs per use, and show how SPDC bandwidth and DWDM grid spacing steer
performance. Using the default configuration settings, average fidelity emains
constant at 0.8 but the ebit rate decreases from 0.0175 at the source to 0.0 at
50 km; narrowing the SPDC degeneracy bandwidth increases the ebit rate
significantly without affecting fidelity. The simulator enables codesign of
source, filtering, and feedforward settings for specific quantum memories and
integrates as a building block for end to end quantum network studies.

</details>


### [73] [Performance Analysis of Dynamic Equilibria in Joint Path Selection and Congestion Control](https://arxiv.org/abs/2510.26060)
*Sina Keshvadi*

Main category: cs.NI

TL;DR: 本文提出公理化框架分析路径选择与拥塞控制的动态，揭示性能与用户目标的权衡，发现代理迁移可增强稳定性，为未来协议设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 解决未协调的贪婪路径选择导致的网络振荡问题，其定量性能影响尚未被充分理解。

Method: 开发了第一个公理化框架，用于分析路径选择和拥塞控制的联合动态，并通过模拟验证了理论结果。

Result: 揭示了协议设计中效率、收敛性与公平性、响应性之间的权衡，证明通过参数调优可以同时优化效率、收敛性和避免丢包，代理迁移也能增强稳定性。

Conclusion: 本文提出了一个公理化框架来分析路径选择和拥塞控制的联合动态，揭示了协议设计中性能可预测性与用户中心目标之间的权衡，并发现代理迁移可以增强稳定性。这些发现为未来路径感知互联网的稳健高性能协议设计提供了原则性指导。

Abstract: Path-aware networking, a cornerstone of next-generation architectures like
SCION and Multipath QUIC, empowers end-hosts with fine-grained control over
traffic forwarding. This capability, however, introduces a critical stability
risk: uncoordinated, greedy path selection by a multitude of agents can induce
persistent, high-amplitude network oscillations. While this phenomenon is
well-known, its quantitative performance impact across key metrics has remained
poorly understood. In this paper, we address this gap by developing the first
axiomatic framework for analyzing the joint dynamics of path selection and
congestion control. Our model enables the formal characterization of the
system's dynamic equilibria-the stable, periodic patterns of oscillation-and
provides a suite of axioms to rate their performance in terms of efficiency,
loss avoidance, convergence, fairness, and responsiveness. Our analysis reveals
a fundamental trade-off in protocol design between predictable performance
(efficiency, convergence) and user-centric goals (fairness, responsiveness). We
prove, however, that no such trade-off exists among efficiency, convergence,
and loss avoidance, which can be simultaneously optimized through careful
parameter tuning. Furthermore, we find that agent migration can,
counter-intuitively, enhance stability by de-synchronizing traffic, a
theoretical result validated by our simulations. These findings provide a
principled design map for engineering robust, high-performance protocols for
the future path-aware Internet.

</details>


### [74] [Symmetry-Driven Asynchronous Forwarding for Reliable Distributed Coordination in Toroidal Networks](https://arxiv.org/abs/2510.26071)
*Shenshen Luan,Yumo Tian,Xinyu Zhang,Qingwen Zhang,Tianheng Wang,Yan Yang,Shuguo Xie*

Main category: cs.NI

TL;DR: 论文提出了一种基于环面对称性的异步转发机制，通过局部策略减少数据包丢失，无需协议修改或额外开销。


<details>
  <summary>Details</summary>
Motivation: 大规模分布式系统（如卫星星座和高性能计算集群）需要在不稳定链路上保持协调的通信原语。传统路由方案在链路故障后的控制平面同步中存在大量数据包丢失问题。

Method: 论文提出了两种本地转发策略：反向流与反向优先（RF-CF）和侧向优先（RF-LF），通过拓扑势梯度建模数据流，并利用对称性破坏失败自然诱导的反向流进行故障规避。

Result: 在16x16环面上，通过渗透分析和数据包级模拟，该机制在1%链路故障率下将数据包丢失减少高达17.5%，其中RF-LF策略贡献了28%的成功交付数据包。

Conclusion: 该论文通过利用环面的几何特性，提出了一种无需控制平面协调的对称驱动异步转发机制，显著减少了数据包丢失，为分布式系统的通信弹性提供了轻量级、协议无关的解决方案。

Abstract: The proliferation of large-scale distributed systems, such as satellite
constellations and high-performance computing clusters, demands robust
communication primitives that maintain coordination under unreliable links. The
torus topology, with its inherent rotational and reflection symmetries, is a
prevalent architecture in these domains. However, conventional routing schemes
suffer from substantial packet loss during control-plane synchronization after
link failures. This paper introduces a symmetry-driven asynchronous forwarding
mechanism that leverages the torus's geometric properties to achieve reliable
packet delivery without control-plane coordination. We model packet flow using
a topological potential gradient and demonstrate that symmetry-breaking
failures naturally induce a reverse flow, which we harness for fault
circumvention. We propose two local forwarding strategies, Reverse Flow with
Counter-facing Priority (RF-CF) and Lateral-facing Priority (RF-LF), that
guarantee reachability to the destination via forward-flow phase transition
points, without protocol modifications or additional in-packet overhead.
Through percolation analysis and packet-level simulations on a 16 x 16 torus,
we show that our mechanism reduces packet loss by up to 17.5% under a 1% link
failure rate, with the RF-LF strategy contributing to 28% of successfully
delivered packets. This work establishes a foundational link between
topological symmetry and communication resilience, providing a lightweight,
protocol-agnostic substrate for enhancing distributed systems.

</details>


### [75] [FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler](https://arxiv.org/abs/2510.26075)
*Thanh Le,Hai Duong,Yusheng Ji,ThanhVu Nguyen,John C. S. Lui*

Main category: cs.NI

TL;DR: 本文研究了对抗性用户如何利用未处理的CSI信息攻击5G MU-MIMO系统，提出的FGGM方案能有效降低网络吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有研究假设对抗性用户能获取受害者CSI的确切值，但在LTE/5G上行传输中不切实际。本研究探索了基于观察归一器的攻击可能性。

Method: 利用多面体抽象域技术，开发了FGGM攻击方案，通过操纵CSI向量实现对DRL策略的攻击。

Result: FGGM方案可在不知道受害者本地观测确切值的情况下，将受害者网络吞吐量降低高达70%。

Conclusion: 本研究揭示了在5G MU-MIMO系统中，对抗性用户如何利用未处理的原始CSI信息发起吞吐量降低攻击，并提出了一种基于多面体抽象域的FGGM攻击方案。实验表明，FGGM能在不知道受害者本地观测确切值的情况下，显著降低网络吞吐量。

Abstract: In 5G mobile communication systems, MU-MIMO has been applied to enhance
spectral efficiency and support high data rates. To maximize spectral
efficiency while providing fairness among users, the base station (BS) needs to
selects a subset of users for data transmission. Given that this problem is
NP-hard, DRL-based methods have been proposed to infer the near-optimal
solutions in real-time, yet this approach has an intrinsic security problem.
This paper investigates how a group of adversarial users can exploit
unsanitized raw CSIs to launch a throughput degradation attack. Most existing
studies only focused on systems in which adversarial users can obtain the exact
values of victims' CSIs, but this is impractical in the case of uplink
transmission in LTE/5G mobile systems. We note that the DRL policy contains an
observation normalizer which has the mean and variance of the observation to
improve training convergence. Adversarial users can then estimate the upper and
lower bounds of the local observations including the CSIs of victims based
solely on that observation normalizer. We develop an attacking scheme FGGM by
leveraging polytope abstract domains, a technique used to bound the outputs of
a neural network given the input ranges. Our goal is to find one set of
intentionally manipulated CSIs which can achieve the attacking goals for the
whole range of local observations of victims. Experimental results demonstrate
that FGGM can determine a set of adversarial CSI vector controlled by
adversarial users, then reuse those CSIs throughout the simulation to reduce
the network throughput of a victim up to 70\% without knowing the exact value
of victims' local observations. This study serves as a case study and can be
applied to many other DRL-based problems, such as a knapsack-oriented resource
allocation problems.

</details>


### [76] [From req/res to pub/sub: Exploring Media over QUIC Transport for DNS](https://arxiv.org/abs/2510.26234)
*Mathis Engelbart,Mike Kosek,Lars Eggert,Jörg Ott*

Main category: cs.NI

TL;DR: 本文探索了基于发布-订阅的DNS变体，通过Media-over-QUIC架构减少更新延迟，但也带来状态管理和首次查询延迟的新挑战。


<details>
  <summary>Details</summary>
Motivation: DNS最初设计为静态目录服务，但随着用例扩展，需要一种能主动推送更新的机制以支持动态场景（如负载均衡）。

Method: 基于Media-over-QUIC架构设计了一个草稿系统和协议提案，支持推送资源记录更新，并提供了原型实现。

Result: 发布-订阅变体能够减少更新流量并显著缩短记录更新的接收时间，支持内容分发网络等用例。

Conclusion: DNS可以通过发布-订阅架构获益，尽管它带来了新的挑战，如端点状态管理开销增加和首次查询延迟。

Abstract: The DNS is a key component of the Internet. Originally designed to facilitate
the resolution of host names to IP addresses, its scope has continuously
expanded over the years, today covering use cases such as load balancing or
service discovery. While DNS was initially conceived as a rather static
directory service in which resource records (RR) only change rarely, we have
seen a number of use cases over the years where a DNS flavor that isn't purely
based upon requesting and caching RRs, but rather on an active distribution of
updates for all resolvers that showed interest in the respective records in the
past, would be preferable. In this paper, we thus explore a publish-subscribe
variant of DNS based on the Media-over-QUIC architecture, where we devise a
strawman system and protocol proposal to enable pushing RR updates. We provide
a prototype implementation, finding that DNS can benefit from a
publish-subscribe variant: next to limiting update traffic, it can considerably
reduce the time it takes for a resolver to receive the latest version of a
record, thereby supporting use cases such as load balancing in content
distribution networks. The publish-subscribe architecture also brings new
challenges to the DNS, including a higher overhead for endpoints due to
additional state management, and increased query latencies on first lookup, due
to session establishment latencies.

</details>


### [77] [Joint Computing Resource Allocation and Task Offloading in Vehicular Fog Computing Systems Under Asymmetric Information](https://arxiv.org/abs/2510.26256)
*Geng Sun,Siyi Chen,Zemin Sun,Long He,Jiacheng Wang,Dusit Niyato,Zhu Han,Dong In Kim*

Main category: cs.NI

TL;DR: 提出JCRATOA方法，通过分层架构、凸优化和合约理论解决VFC中的资源分配和任务卸载问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统车辆边缘计算难以满足日益增长和多样化的需求，而信息不对称和资源异构性进一步加剧了资源分配和任务卸载的复杂性。

Method: 采用分层VFC架构，结合RSU和FV的计算能力，提出了基于凸优化的RSU资源分配方法和基于合约理论的FV激励机制，以及通过匹配游戏实现的任务卸载方法。

Result: 仿真结果表明，JCRATOA在任务完成延迟、完成率、系统吞吐量和资源利用公平性方面表现优异。

Conclusion: 本文提出了一种联合计算资源分配和任务卸载方法（JCRATOA），通过凸优化和合约理论解决了VFC中的资源分配问题，并通过匹配游戏优化了任务卸载，显著提升了任务完成延迟、完成率、系统吞吐量和资源利用公平性。

Abstract: Vehicular fog computing (VFC) has emerged as a promising paradigm, which
leverages the idle computational resources of nearby fog vehicles (FVs) to
complement the computing capabilities of conventional vehicular edge computing.
However, utilizing VFC to meet the delay-sensitive and computation-intensive
requirements of the FVs poses several challenges. First, the limited resources
of road side units (RSUs) struggle to accommodate the growing and diverse
demands of vehicles. This limitation is further exacerbated by the information
asymmetry between the controller and FVs due to the reluctance of FVs to
disclose private information and to share resources voluntarily. This
information asymmetry hinders the efficient resource allocation and
coordination. Second, the heterogeneity in task requirements and the varying
capabilities of RSUs and FVs complicate efficient task offloading, thereby
resulting in inefficient resource utilization and potential performance
degradation. To address these challenges, we first present a hierarchical VFC
architecture that incorporates the computing capabilities of both RSUs and FVs.
Then, we formulate a delay minimization optimization problem (DMOP), which is
an NP-hard mixed integer nonlinear programming problem. To solve the DMOP, we
propose a joint computing resource allocation and task offloading approach
(JCRATOA). Specifically, we propose a convex optimization-based method for RSU
resource allocation and a contract theory-based incentive mechanism for FV
resource allocation. Moreover, we present a two-sided matching method for task
offloading by employing the matching game. Simulation results demonstrate that
the proposed JCRATOA is able to achieve superior performances in task
completion delay, task completion ratio, system throughput, and resource
utilization fairness, while effectively meeting the satisfying constraints.

</details>


### [78] [Wireless Memory Approximation for Energy-efficient Task-specific IoT Data Retrieval](https://arxiv.org/abs/2510.26473)
*Junya Shiraishi,Shashi Raj Pandey,Israel Leyva-Mayorga,Petar Popovski*

Main category: cs.NI

TL;DR: 针对DRAM在ML模型存储中的能耗问题，提出无线内存激活和近似方法，优化能源使用并保持精度。


<details>
  <summary>Details</summary>
Motivation: DRAM的周期性刷新在待机期间导致能源浪费，尤其对资源受限的IoT设备影响显著。

Method: 提出了两种新颖方法：1) 无线内存激活和2) 无线内存近似，通过考虑ML模型使用的时间相关性和相关性来优化内存管理。

Result: 数值结果显示，所提方案在满足检索精度约束的同时，能耗低于始终开启的方法。

Conclusion: 本文提出的无线内存激活和无线内存近似方法有效降低了DRAM在ML模型存储中的能耗，满足了检索精度要求。

Abstract: The use of Dynamic Random Access Memory (DRAM) for storing Machine Learning
(ML) models plays a critical role in accelerating ML inference tasks in the
next generation of communication systems. However, periodic refreshment of DRAM
results in wasteful energy consumption during standby periods, which is
significant for resource-constrained Internet of Things (IoT) devices. To solve
this problem, this work advocates two novel approaches: 1) wireless memory
activation and 2) wireless memory approximation. These enable the wireless
devices to efficiently manage the available memory by considering the timing
aspects and relevance of ML model usage; hence, reducing the overall energy
consumption. Numerical results show that our proposed scheme can realize
smaller energy consumption than the always-on approach while satisfying the
retrieval accuracy constraint.

</details>


### [79] [Low-Altitude UAV-Carried Movable Antenna for Joint Wireless Power Transfer and Covert Communications](https://arxiv.org/abs/2510.26628)
*Chuang Zhang,Geng Sun,Jiahui Li,Jiacheng Wang,Qingqing Wu,Dusit Niyato,Shiwen Mao,Tony Q. S. Quek*

Main category: cs.NI

TL;DR: 论文提出了一种结合无线能量传输和隐蔽通信的低空无人机系统，通过MoE-SAC算法优化能量收集和隐蔽通信性能，仿真结果显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 物联网（IoT）网络的普及对可持续能源解决方案提出了迫切需求，尤其是电池受限的空间分布式物联网节点。低空无人机（UAV）结合无线能量传输（WPT）能力提供了一种有前景的解决方案，但高效能量传输所需的视线信道也暴露了敏感的操作数据。

Method: 为了解决非凸和时间耦合的优化问题，论文提出了一种混合专家增强的软演员-评论家（MoE-SAC）算法，采用稀疏Top-K门控混合浅层专家架构来表示多模态策略分布，并结合动作投影模块显式执行功率预算和天线位置约束。

Result: 仿真结果表明，所提出的方法显著优于一些基线方法和其他最先进的深度强化学习算法。

Conclusion: 论文提出了一种新型低空无人机载移动天线增强传输系统，结合无线能量传输和隐蔽通信，显著提升了物联网节点的能量收集效率和隐蔽用户的传输速率，同时降低了无人机的推进能耗。

Abstract: The proliferation of Internet of Things (IoT) networks has created an urgent
need for sustainable energy solutions, particularly for the battery-constrained
spatially distributed IoT nodes. While low-altitude uncrewed aerial vehicles
(UAVs) employed with wireless power transfer (WPT) capabilities offer a
promising solution, the line-of-sight channels that facilitate efficient energy
delivery also expose sensitive operational data to adversaries. This paper
proposes a novel low-altitude UAV-carried movable antenna-enhanced transmission
system joint WPT and covert communications, which simultaneously performs
energy supplements to IoT nodes and establishes transmission links with a
covert user by leveraging wireless energy signals as a natural cover. Then, we
formulate a multi-objective optimization problem that jointly maximizes the
total harvested energy of IoT nodes and sum achievable rate of the covert user,
while minimizing the propulsion energy consumption of the low-altitude UAV. To
address the non-convex and temporally coupled optimization problem, we propose
a mixture-of-experts-augmented soft actor-critic (MoE-SAC) algorithm that
employs a sparse Top-K gated mixture-of-shallow-experts architecture to
represent multimodal policy distributions arising from the conflicting
optimization objectives. We also incorporate an action projection module that
explicitly enforces per-time-slot power budget constraints and antenna position
constraints. Simulation results demonstrate that the proposed approach
significantly outperforms some baseline approaches and other state-of-the-art
deep reinforcement learning algorithms.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [80] [Environmental Impact of CI/CD Pipelines](https://arxiv.org/abs/2510.26413)
*Nuno Saavedra,Alexandra Mendes,João F. Ferreira*

Main category: cs.SE

TL;DR: 研究分析了GitHub Actions的碳和水足迹，发现其环境影响巨大，并提出了减少资源浪费的优化策略。


<details>
  <summary>Details</summary>
Motivation: 尽管CI/CD流程在软件开发中广泛应用，但其环境影响（尤其是碳和水足迹）未被充分了解，而云计算的环境影响日益显著。

Method: 基于Cloud Carbon Footprint框架方法，分析了超过220万次工作流运行的数据集，覆盖1.8万个开源仓库。

Result: GitHub Actions生态系统的CWF显著，最可能情景下碳足迹为456.9 MTCO2e，水足迹为5,738.2千升。

Conclusion: GitHub Actions的CI/CD流程对环境有显著的碳和水足迹（CWF），需要采取策略减少资源浪费，如选择低环境影响区域部署、优化调度策略和缩小仓库规模。

Abstract: CI/CD pipelines are widely used in software development, yet their
environmental impact, particularly carbon and water footprints (CWF), remains
largely unknown to developers, as CI service providers typically do not
disclose such information. With the growing environmental impact of cloud
computing, understanding the CWF of CI/CD services has become increasingly
important.
  This work investigates the CWF of using GitHub Actions, focusing on
open-source repositories where usage is free and unlimited for standard
runners. We build upon a methodology from the Cloud Carbon Footprint framework
and we use the largest dataset of workflow runs reported in the literature to
date, comprising over 2.2 million workflow runs from more than 18,000
repositories.
  Our analysis reveals that the GitHub Actions ecosystem results in a
substantial CWF. Our estimates for the carbon footprint in 2024 range from
150.5 MTCO2e in the most optimistic scenario to 994.9 MTCO2e in the most
pessimistic scenario, while the water footprint ranges from 1,989.6 to 37,664.5
kiloliters. The most likely scenario estimates are 456.9 MTCO2e for carbon
footprint and 5,738.2 kiloliters for water footprint. To provide perspective,
the carbon footprint in the most likely scenario is equivalent to the carbon
captured by 7,615 urban trees in a year, and the water footprint is comparable
to the water consumed by an average American family over 5,053 years.
  We explore strategies to mitigate this impact, primarily by reducing wasted
computational resources. Key recommendations include deploying runners in
regions whose energy production has a low environmental impact such as France
and the United Kingdom, implementing stricter deactivation policies for
scheduled runs and aligning their execution with periods when the regional
energy mix is more environmentally favorable, and reducing the size of
repositories.

</details>


### [81] [Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance](https://arxiv.org/abs/2510.25882)
*Wenhao Yang,Minghui Zhou,Daniel Izquierdo Cortázar,Yehui Wang*

Main category: cs.SE

TL;DR: 论文提出OTVM框架，通过外部威胁与内部脆弱性的相互作用原理，帮助企业系统性治理开源风险，包含目标矩阵、双重分类和缓解框架。


<details>
  <summary>Details</summary>
Motivation: 企业开源参与从战术采用转向战略深度整合，传统风险管理方法无法应对系统性威胁（如上游‘静默修复’、社区冲突或许可证突然变更），导致治理盲点。

Method: 通过扎根理论研究，与15位从业者合作，开发了一个基于外部威胁与内部脆弱性相互作用原理的分析框架。

Result: 研究贡献包括：(1) ‘战略目标矩阵’明确目标；(2) 外部威胁（Ex-Tech, Ex-Comm, Ex-Eco）与内部脆弱性（In-Strat, In-Ops, In-Tech）的双重分类；(3) 可操作的缓解框架。

Conclusion: 该论文提出了一个全面的风险治理框架（OTVM），旨在帮助企业从战术性风险管理转向整体性风险治理，从而系统性应对开源生态中的复杂威胁。

Abstract: Enterprise engagement with open source has evolved from tactical adoption to
strategic deep integration, exposing them to a complex risk landscape far
beyond mere code. However, traditional risk management, narrowly focused on
technical tools, is structurally inadequate for systemic threats like upstream
"silent fixes", community conflicts, or sudden license changes, creating a
dangerous governance blind spot. To address this governance vacuum and enable
the necessary shift from tactical risk management to holistic risk governance,
we conducted a grounded theory study with 15 practitioners to develop a
holistic risk governance framework. Our study formalizes an analytical
framework built on a foundational risk principle: an uncontrollable External
Threat (e.g., a sudden license change in a key dependency) only becomes a
critical risk when it exploits a controllable Internal Vulnerability (e.g., an
undefined risk appetite for single-vendor projects), which then amplifies the
impact.The framework operationalizes this principle through a clear logical
chain: "Objectives -> Threats -> Vulnerabilities -> Mitigation" (OTVM). This
provides a holistic decision model that transcends mere technical checklists.
Based on this logic, our contributions are: (1) a "Strategic Objectives Matrix"
to clarify goals; (2) a systematic dual taxonomy of External Threats (Ex-Tech,
Ex-Comm, Ex-Eco) and Internal Vulnerabilities (In-Strat, In-Ops, In-Tech); and
(3) an actionable mitigation framework mapping capability-building to these
vulnerabilities. The framework's analytical utility was validated by three
industry experts through retrospective case studies on real-world incidents.
This work provides a novel diagnostic lens and a systematic path for
enterprises to shift from reactive "firefighting" to proactively building an
organizational "immune system".

</details>


### [82] [PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints](https://arxiv.org/abs/2510.25890)
*Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang*

Main category: cs.SE

TL;DR: PRISM 结合大型语言模型和模型驱动工程，通过统一元模型、集成约束模型和约束引导的可验证生成，为安全和合规领域生成可验证的工件，显著减少手动修复工作。


<details>
  <summary>Details</summary>
Motivation: PRISM 旨在将大型语言模型与模型驱动工程相结合，为安全和合规关键领域生成符合监管要求的工件和机器可检查的证据。

Method: PRISM 整合了三个支柱：统一元模型（UMM）协调异构模式和监管文本；集成约束模型（ICM）将结构和语义需求编译为强制执行工件；约束引导的可验证生成（CVG）通过两层强制执行应用这些约束。

Result: 在汽车软件工程（AUTOSAR）和跨境法律管辖区（Brussels I bis）的评估中，PRISM 生成了结构有效、可审核的工件，并与现有工具集成。

Conclusion: PRISM 提供了一种实用的方法，通过在生成过程中内置保证机制，显著减少了手动修复工作，并生成可审核的工件，适用于安全和合规关键领域。

Abstract: PRISM unifies Large Language Models with Model-Driven Engineering to generate
regulator-ready artifacts and machine-checkable evidence for safety- and
compliance-critical domains. PRISM integrates three pillars: a Unified
Meta-Model (UMM) reconciles heterogeneous schemas and regulatory text into a
single semantic space; an Integrated Constraint Model (ICM) compiles structural
and semantic requirements into enforcement artifacts including generation-time
automata (GBNF, DFA) and post-generation validators (e.g., SHACL, SMT); and
Constraint-Guided Verifiable Generation (CVG) applies these through two-layer
enforcement - structural constraints drive prefix-safe decoding while
semantic/logical validation produces machine-checkable certificates. When
violations occur, PRISM performs audit-guided repair and records generation
traces for compliance review. We evaluate PRISM in automotive software
engineering (AUTOSAR) and cross-border legal jurisdiction (Brussels I bis).
PRISM produces structurally valid, auditable artifacts that integrate with
existing tooling and substantially reduce manual remediation effort, providing
a practical path toward automated artifact generation with built-in assurance.

</details>


### [83] [A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows](https://arxiv.org/abs/2510.25935)
*Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace*

Main category: cs.SE

TL;DR: CodeSight通过流程挖掘和LSTM模型预测PR解决时间，有效识别潜在截止期限违约，测试表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在通过预测软件开发工作流中的截止期限遵守情况，提供可操作的见解以优化工作流效率。

Method: 系统从GitHub捕获开发和部署数据，转换为流程挖掘日志，并利用LSTM模型基于序列活动轨迹和静态特征预测PR解决时间。

Result: 测试中系统在预测截止期限遵守方面表现出高精度和高F1分数。

Conclusion: CodeSight展示了将流程挖掘与机器学习结合在软件项目管理中的价值，能够高精度预测PR解决时间和截止期限遵守情况。

Abstract: CodeSight is an end-to-end system designed to anticipate deadline compliance
in software development workflows. It captures development and deployment data
directly from GitHub, transforming it into process mining logs for detailed
analysis. From these logs, the system generates metrics and dashboards that
provide actionable insights into PR activity patterns and workflow efficiency.
Building on this structured representation, CodeSight employs an LSTM model
that predicts remaining PR resolution times based on sequential activity traces
and static features, enabling early identification of potential deadline
breaches. In tests, the system demonstrates high precision and F1 scores in
predicting deadline compliance, illustrating the value of integrating process
mining with machine learning for proactive software project management.

</details>


### [84] [Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation](https://arxiv.org/abs/2510.26130)
*Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab*

Main category: cs.SE

TL;DR: 该论文通过真实世界类基准测试发现，LLMs在类级别代码生成上表现不佳（25%-34%正确率），检索增强生成在部分文档下提升效果最佳（4%-7%）。主要错误为类型和属性不匹配，建议改进上下文建模和检索集成。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在函数级代码生成上取得了进展，但其在真实软件项目中生成正确类级别实现的能力尚不明确。因此，需要一个新的基准来评估LLMs在实际应用中的表现。

Method: 通过从开源仓库中提取真实世界的类，构建了一个新的基准测试，分为已见和未见分区，以评估LLMs在实践条件下的泛化能力。评估了多种LLM在不同输入规范、检索增强配置和文档完整性水平下的表现。

Result: LLMs在合成基准测试上表现优异（84%至89%正确率），但在真实世界类任务上表现较差（25%至34%正确率）。检索增强生成在部分文档情况下最有效，能提升4%至7%的正确率。错误分析显示，AttributeError、TypeError和AssertionError是主要失败模式（占84%）。

Conclusion: 该论文揭示了当前大型语言模型（LLMs）在类级别代码生成上的局限性，并提出了改进上下文建模、文档策略和检索集成的可行建议。

Abstract: Large language models (LLMs) have advanced code generation at the function
level, yet their ability to produce correct class-level implementations in
authentic software projects remains poorly understood. This work introduces a
novel benchmark derived from open-source repositories, comprising real-world
classes divided into seen and unseen partitions to evaluate generalization
under practical conditions. The evaluation examines multiple LLMs under varied
input specifications, retrieval-augmented configurations, and documentation
completeness levels.
  Results reveal a stark performance disparity: LLMs achieve 84% to 89%
correctness on established synthetic benchmarks but only 25% to 34% on
real-world class tasks, with negligible differences between familiar and novel
codebases. Comprehensive docstrings yield modest gains of 1% to 3% in
functional accuracy, though statistical significance is rare.
Retrieval-augmented generation proves most effective with partial
documentation, improving correctness by 4% to 7% by supplying concrete
implementation patterns absent from specifications. Error profiling identifies
AttributeError, TypeError, and AssertionError as dominant failure modes (84% of
cases), with synthetic tests overemphasizing assertion issues and real-world
scenarios highlighting type and attribute mismatches. Retrieval augmentation
reduces logical flaws but can introduce dependency conflicts.
  The benchmark and analysis expose critical limitations in current LLM
capabilities for class-level engineering, offering actionable insights for
enhancing context modelling, documentation strategies, and retrieval
integration in production code assistance tools.

</details>


### [85] [Reduction of Test Re-runs by Prioritizing Potential Order Dependent Flaky Tests](https://arxiv.org/abs/2510.26171)
*Hasnain Iqbal,Zerina Begum,Kazi Sakib*

Main category: cs.SE

TL;DR: 本文提出一种通过分析共享静态字段优先识别顺序依赖测试的方法，显著减少了测试重运行次数和执行成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法需要多次不相关测试重运行的问题，本研究提出了一种优先识别潜在顺序依赖测试的方法。

Method: 通过分析测试类中的共享静态字段，识别更可能是顺序依赖的测试。

Result: 在27个项目模块的实验中，该方法成功在23个案例中优先识别出所有OD测试，平均减少了65.92%的测试执行和72.19%的不必要重运行。

Conclusion: 本研究提出的方法显著提高了OD测试检测的效率，通过降低执行成本，证明了其在减少不必要测试重运行方面的有效性。

Abstract: Flaky tests can make automated software testing unreliable due to their
unpredictable behavior. These tests can pass or fail on the same code base on
multiple runs. However, flaky tests often do not refer to any fault, even
though they can cause the continuous integration (CI) pipeline to fail. A
common type of flaky test is the order-dependent (OD) test. The outcome of an
OD test depends on the order in which it is run with respect to other test
cases. Several studies have explored the detection and repair of OD tests.
However, their methods require re-runs of tests multiple times, that are not
related to the order dependence. Hence, prioritizing potential OD tests is
necessary to reduce the re-runs. In this paper, we propose a method to
prioritize potential order-dependent tests. By analyzing shared static fields
in test classes, we identify tests that are more likely to be order-dependent.
In our experiment on 27 project modules, our method successfully prioritized
all OD tests in 23 cases, reducing test executions by an average of 65.92% and
unnecessary re-runs by 72.19%. These results demonstrate that our approach
significantly improves the efficiency of OD test detection by lowering
execution costs.

</details>


### [86] [The "4W+1H" of Software Supply Chain Security Checklist for Critical Infrastructure](https://arxiv.org/abs/2510.26174)
*Liming Dong,Sung Une Lee,Zhenchang Xing,Muhammad Ejaz Ahmed,Stefan Avgoustakis*

Main category: cs.SE

TL;DR: 论文通过多源文献综述和“4W+1H”分析方法，合成了软件供应链安全实践的核心类别，并提出了一个包含80个问题的检查清单，以帮助关键基础设施领域应对供应链风险。


<details>
  <summary>Details</summary>
Motivation: 软件供应链攻击的频率和复杂性不断增加，对关键基础设施领域构成严重威胁，而现有安全实践分散且不足，缺乏针对关键基础设施的定制化框架。

Method: 通过多源文献综述（国际框架、澳大利亚监管来源和学术研究），采用“4W+1H”分析方法，系统整合了软件供应链安全实践的十个核心类别，并将其映射到生命周期阶段、利益相关者角色和实施层面。

Result: 研究发现现有框架很少明确针对关键基础设施领域，并通过分析合成了软件供应链安全实践的核心类别，最终提出了一个多层的检查清单。

Conclusion: 论文提出了一个包含80个问题的结构化多层检查清单，帮助利益相关者评估和增强软件供应链安全，揭示了现有框架与关键基础设施特定需求之间的差距，并强调需要综合、情境感知的方法来应对不断演变的软件供应链风险。

Abstract: The increasing frequency and sophistication of software supply chain attacks
pose severe risks to critical infrastructure sectors, threatening national
security, economic stability, and public safety. Despite growing awareness,
existing security practices remain fragmented and insufficient, with most
frameworks narrowly focused on isolated life cycle stages or lacking alignment
with the specific needs of critical infrastructure (CI) sectors. In this paper,
we conducted a multivocal literature review across international frameworks,
Australian regulatory sources, and academic studies to identify and analyze
security practices across the software supply chain, especially specific CI
sector. Our analysis found that few existing frameworks are explicitly tailored
to CI domains. We systematically leveraged identified software supply chain
security frameworks, using a "4W+1H" analytical approach, we synthesized ten
core categories (what) of software supply chain security practices, mapped them
across life-cycle phases (when), stakeholder roles (who), and implementation
levels (how), and examined their coverage across existing frameworks (where).
Building on these insights, the paper culminates in structured, multi-layered
checklist of 80 questions designed to relevant stakeholders evaluate and
enhance their software supply chain security. Our findings reveal gaps between
framework guidance and sector-specific needs, highlight the need for
integrated, context-aware approaches to safeguard critical infrastructure from
evolving software supply chain risks.

</details>


### [87] [A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI](https://arxiv.org/abs/2510.26275)
*Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本文构建了一个生成式AI增强软件工程的路线图，提出了四种增强形式、研究挑战及2030年的十项预测。


<details>
  <summary>Details</summary>
Motivation: 探索生成式AI如何改变软件工程实践、流程及系统开发，并为未来研究提供方向。

Method: 采用设计科学研究方法，结合FSE 2025研讨会讨论、快速文献综述和外部反馈，使用McLuhan的四元组作为概念工具。

Result: 提出了生成式AI在软件工程中的四种基本增强形式及其相关研究挑战与机遇。

Conclusion: 该研究通过严谨的多周期流程构建了一个生成式AI增强软件工程的路线图，并提出了2030年软件工程的十项预测。

Abstract: Generative AI (GenAI) is rapidly transforming software engineering (SE)
practices, influencing how SE processes are executed, as well as how software
systems are developed, operated, and evolved. This paper applies design science
research to build a roadmap for GenAI-augmented SE. The process consists of
three cycles that incrementally integrate multiple sources of evidence,
including collaborative discussions from the FSE 2025 "Software Engineering
2030" workshop, rapid literature reviews, and external feedback sessions
involving peers. McLuhan's tetrads were used as a conceptual instrument to
systematically capture the transforming effects of GenAI on SE processes and
software products.The resulting roadmap identifies four fundamental forms of
GenAI augmentation in SE and systematically characterizes their related
research challenges and opportunities. These insights are then consolidated
into a set of future research directions. By grounding the roadmap in a
rigorous multi-cycle process and cross-validating it among independent author
teams and peers, the study provides a transparent and reproducible foundation
for analyzing how GenAI affects SE processes, methods and tools, and for
framing future research within this rapidly evolving area. Based on these
findings, the article finally makes ten predictions for SE in the year 2030.

</details>


### [88] [Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search](https://arxiv.org/abs/2510.26287)
*Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng*

Main category: cs.SE

TL;DR: RepoSearch-R1 是一种基于 MCTS 的强化学习框架，显著提升仓库问答任务的表现和效率，同时解决数据合规问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在工具利用和环境反馈决策方面效果有限，且训练方法通常依赖昂贵的大模型蒸馏，存在企业数据合规问题。

Method: 引入了 RepoSearch-R1，一种基于蒙特卡洛树搜索（MCTS）的强化学习框架，支持自训练生成多样化的高质量推理轨迹，无需模型蒸馏或外部监督。

Result: 在仓库问答任务中，RepoSearch-R1 实现了答案完整性的显著提升：无检索方法提升 16.0%，迭代检索方法提升 19.5%，训练效率比通用强化学习方法提高 33%。

Conclusion: RepoSearch-R1 通过蒙特卡洛树搜索驱动的强化学习框架，显著提升了仓库级问答任务的答案完整性和训练效率，同时解决了企业环境中的数据合规问题。

Abstract: Repository-level software engineering tasks require large language models
(LLMs) to efficiently navigate and extract information from complex codebases
through multi-turn tool interactions. Existing approaches face significant
limitations: training-free, in-context learning methods struggle to guide
agents effectively in tool utilization and decision-making based on
environmental feedback, while training-based approaches typically rely on
costly distillation from larger LLMs, introducing data compliance concerns in
enterprise environments. To address these challenges, we introduce
RepoSearch-R1, a novel agentic reinforcement learning framework driven by
Monte-carlo Tree Search (MCTS). This approach allows agents to generate
diverse, high-quality reasoning trajectories via self-training without
requiring model distillation or external supervision. Based on RepoSearch-R1,
we construct a RepoQA-Agent specifically designed for repository
question-answering tasks. Comprehensive evaluation on repository
question-answering tasks demonstrates that RepoSearch-R1 achieves substantial
improvements of answer completeness: 16.0% enhancement over no-retrieval
methods, 19.5% improvement over iterative retrieval methods, and 33% increase
in training efficiency compared to general agentic reinforcement learning
approaches. Our cold-start training methodology eliminates data compliance
concerns while maintaining robust exploration diversity and answer completeness
across repository-level reasoning tasks.

</details>


### [89] [Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis](https://arxiv.org/abs/2510.26423)
*Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng*

Main category: cs.SE

TL;DR: Nexus是一个多智能体框架，通过专家代理协作和自优化机制，显著提升测试预言生成和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决非回归测试中测试预言生成的长期挑战，提高函数测试的准确性和可靠性。

Method: Nexus采用多智能体框架，包含四个不同测试哲学的专家代理，通过审议、验证和迭代自优化的结构化流程生成测试预言。

Result: Nexus在七个基准测试中表现优异，例如将LiveCodeBench的测试预言准确率从46.30%提升至57.73%，并显著提升了下游任务的性能。

Conclusion: Nexus框架通过多智能体协作和自优化机制，显著提升了测试预言生成的准确性和下游任务的性能。

Abstract: Test oracle generation in non-regression testing is a longstanding challenge
in software engineering, where the goal is to produce oracles that can
accurately determine whether a function under test (FUT) behaves as intended
for a given input. In this paper, we introduce Nexus, a novel multi-agent
framework to address this challenge. Nexus generates test oracles by leveraging
a diverse set of specialized agents that synthesize test oracles through a
structured process of deliberation, validation, and iterative self-refinement.
During the deliberation phase, a panel of four specialist agents, each
embodying a distinct testing philosophy, collaboratively critiques and refines
an initial set of test oracles. Then, in the validation phase, Nexus generates
a plausible candidate implementation of the FUT and executes the proposed
oracles against it in a secure sandbox. For any oracle that fails this
execution-based check, Nexus activates an automated selfrefinement loop, using
the specific runtime error to debug and correct the oracle before
re-validation. Our extensive evaluation on seven diverse benchmarks
demonstrates that Nexus consistently and substantially outperforms
state-of-theart baselines. For instance, Nexus improves the test-level oracle
accuracy on the LiveCodeBench from 46.30% to 57.73% for GPT-4.1-Mini. The
improved accuracy also significantly enhances downstream tasks: the bug
detection rate of GPT4.1-Mini generated test oracles on HumanEval increases
from 90.91% to 95.45% for Nexus compared to baselines, and the success rate of
automated program repair improves from 35.23% to 69.32%.

</details>


### [90] [CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses](https://arxiv.org/abs/2510.26431)
*Mihály Dobos-Kovács,Levente Bajczi,András Vörös*

Main category: cs.SE

TL;DR: CHCVERIF是一个基于组合的CHC求解器，利用软件验证工具处理CHC问题，在位向量测试中表现良好，展示了软件验证工具作为后端的潜力。


<details>
  <summary>Details</summary>
Motivation: CHC广泛用于多种验证任务，但现有方法在处理某些语义（如位向量）时效果有限，因此探索软件验证工具的复用潜力。

Method: 采用基于组合的CHC求解器CHCVERIF，利用成熟的软件验证工具处理CHC基准测试，特别是涉及位向量和低级语义的测试。

Result: 评估表明，该方法在线性整数算术上效果一般，但在位向量基准测试中表现尚可。

Conclusion: 该论文展示了使用软件验证工具作为CHC求解后端的可行性和潜力，尤其是在精心构建的组合支持下。

Abstract: Constrained Horn Clauses (CHCs) are widely adopted as intermediate
representations for a variety of verification tasks, including safety checking,
invariant synthesis, and interprocedural analysis. This paper introduces
CHCVERIF, a portfolio-based CHC solver that adopts a software verification
approach for solving CHCs. This approach enables us to reuse mature software
verification tools to tackle CHC benchmarks, particularly those involving
bitvectors and low-level semantics. Our evaluation shows that while the method
enjoys only moderate success with linear integer arithmetic, it achieves modest
success on bitvector benchmarks. Moreover, our results demonstrate the
viability and potential of using software verification tools as backends for
CHC solving, particularly when supported by a carefully constructed portfolio.

</details>


### [91] [SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning](https://arxiv.org/abs/2510.26457)
*Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang*

Main category: cs.SE

TL;DR: SecureReviewer是一种针对安全代码审查优化的新方法，通过专用数据集、微调策略和RAG技术提升LLMs的能力，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动化代码审查方法在识别和解决安全问题方面效果有限，且面临数据稀缺和评估指标不足的挑战。

Method: 构建专用于安全代码审查的数据集，采用安全感知的微调策略训练LLMs，并整合RAG技术以减少幻觉。引入SecureBLEU评估指标。

Result: SecureReviewer在安全问题的检测准确性和生成审查评论的质量及实用性上优于现有方法。

Conclusion: SecureReviewer通过专门的数据集、安全感知的微调策略和RAG技术，显著提升了LLMs在代码审查中识别和解决安全问题的能力，并在实验中优于现有基线。

Abstract: Identifying and addressing security issues during the early phase of the
development lifecycle is critical for mitigating the long-term negative impacts
on software systems. Code review serves as an effective practice that enables
developers to check their teammates' code before integration into the codebase.
To streamline the generation of review comments, various automated code review
approaches have been proposed, where LLM-based methods have significantly
advanced the capabilities of automated review generation. However, existing
models primarily focus on general-purpose code review, their effectiveness in
identifying and addressing security-related issues remains underexplored.
Moreover, adapting existing code review approaches to target security issues
faces substantial challenges, including data scarcity and inadequate evaluation
metrics. To address these limitations, we propose SecureReviewer, a new
approach designed for enhancing LLMs' ability to identify and resolve
security-related issues during code review. Specifically, we first construct a
dataset tailored for training and evaluating secure code review capabilities.
Leveraging this dataset, we fine-tune LLMs to generate code review comments
that can effectively identify security issues and provide fix suggestions with
our proposed secure-aware fine-tuning strategy. To mitigate hallucination in
LLMs and enhance the reliability of their outputs, we integrate the RAG
technique, which grounds the generated comments in domain-specific security
knowledge. Additionally, we introduce SecureBLEU, a new evaluation metric
designed to assess the effectiveness of review comments in addressing security
issues. Experimental results demonstrate that SecureReviewer outperforms
state-of-the-art baselines in both security issue detection accuracy and the
overall quality and practical utility of generated review comments.

</details>


### [92] [Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study](https://arxiv.org/abs/2510.26480)
*Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner*

Main category: cs.SE

TL;DR: 研究评估了五种开源LLM在Python代码EMR任务中的表现，发现RCI提示方法优于一键提示，显著提升了代码质量，开发者接受率高。


<details>
  <summary>Details</summary>
Motivation: 尽管EMR对代码可读性和可维护性至关重要，但其自动化仍具挑战性，而开源、资源高效的LLM为此提供了新途径。

Method: 系统评估了五种开源LLM在Python代码EMR任务中的表现，比较了一键提示和RCI方法的影响。

Result: RCI提示方法在测试通过率和重构质量上表现更优，最佳模型Deepseek-Coder-RCI和Qwen2.5-Coder-RCI显著提升了代码质量，开发者调查显示70%以上的接受率。

Conclusion: 开源基准测试为未来基于LLM的自动化重构研究提供了基础。

Abstract: Automating the Extract Method refactoring (EMR) remains challenging and
largely manual despite its importance in improving code readability and
maintainability. Recent advances in open-source, resource-efficient Large
Language Models (LLMs) offer promising new approaches for automating such
high-level tasks. In this work, we critically evaluate five state-of-the-art
open-source LLMs, spanning 3B to 8B parameter sizes, on the EMR task for Python
code. We systematically assess functional correctness and code quality using
automated metrics and investigate the impact of prompting strategies by
comparing one-shot prompting to a Recursive criticism and improvement (RCI)
approach. RCI-based prompting consistently outperforms one-shot prompting in
test pass rates and refactoring quality. The best-performing models,
Deepseek-Coder-RCI and Qwen2.5-Coder-RCI, achieve test pass percentage (TPP)
scores of 0.829 and 0.808, while reducing lines of code (LOC) per method from
12.103 to 6.192 and 5.577, and cyclomatic complexity (CC) from 4.602 to 3.453
and 3.294, respectively. A developer survey on RCI-generated refactorings shows
over 70% acceptance, with Qwen2.5-Coder rated highest across all evaluation
criteria. In contrast, the original code scored below neutral, particularly in
readability and maintainability, underscoring the benefits of automated
refactoring guided by quality prompts. While traditional metrics like CC and
LOC provide useful signals, they often diverge from human judgments,
emphasizing the need for human-in-the-loop evaluation. Our open-source
benchmark offers a foundation for future research on automated refactoring with
LLMs.

</details>


### [93] [Envisioning Future Interactive Web Development: Editing Webpage with Natural Language](https://arxiv.org/abs/2510.26516)
*Truong Hai Dang,Jingyu Xiao,Yintong Huo*

Main category: cs.SE

TL;DR: 提出Instruct4Edit数据集和自动化流程，提升LLMs在网页编辑中的代码修改能力，开源模型性能媲美专有系统。


<details>
  <summary>Details</summary>
Motivation: 传统网页应用的迭代代码修改过程耗时且手动，LLMs在根据新设计需求编辑现有代码时面临挑战，缺乏大规模高质量调优数据。

Method: 提出了一种自动化数据生成流程，利用LLMs合成高质量微调数据集Instruct4Edit，包括生成多样化指令、应用代码修改及视觉验证。

Result: 微调后的模型在将人类意图转化为精确、结构连贯且视觉准确的代码修改方面表现一致提升。

Conclusion: 该研究通过Instruct4Edit数据集和微调方法，为基于自然语言的网页编辑提供了可扩展且透明的基础，证明了开源模型在性能上可与专有系统竞争。

Abstract: The evolution of web applications relies on iterative code modifications, a
process that is traditionally manual and time-consuming. While Large Language
Models (LLMs) can generate UI code, their ability to edit existing code from
new design requirements (e.g., "center the logo") remains a challenge. This is
largely due to the absence of large-scale, high-quality tuning data to align
model performance with human expectations. In this paper, we introduce a novel,
automated data generation pipeline that uses LLMs to synthesize a high-quality
fine-tuning dataset for web editing, named Instruct4Edit. Our approach
generates diverse instructions, applies the corresponding code modifications,
and performs visual verification to ensure correctness. By fine-tuning models
on Instruct4Edit, we demonstrate consistent improvement in translating human
intent into precise, structurally coherent, and visually accurate code changes.
This work provides a scalable and transparent foundation for natural language
based web editing, demonstrating that fine-tuning smaller open-source models
can achieve competitive performance with proprietary systems. We release all
data, code implementations, and model checkpoints for reproduction.

</details>


### [94] [Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models](https://arxiv.org/abs/2510.26538)
*David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro*

Main category: cs.SE

TL;DR: 论文分析了软件工程研究中使用LLMs的新挑战，提出了加强基准测试、提高可复制性和降低成本的建议。


<details>
  <summary>Details</summary>
Motivation: 探讨软件工程研究中使用大型语言模型（LLMs）带来的新挑战，包括基准测试的严谨性、污染、可复制性和可持续性。

Method: 研究通过分析ICSE会议上当前基于LLM的软件工程研究，提供了一个结构化的概述，指出了积极的实践和持续的不足。

Result: 研究结果揭示了当前LLM-based软件工程研究的现状，包括积极实践和不足之处。

Conclusion: 论文提出了一系列建议，旨在加强基准测试的严谨性、提高可复制性，并解决基于LLM的软件工程研究在财务和环境成本方面的问题。

Abstract: Software Engineering (SE) research involving the use of Large Language Models
(LLMs) has introduced several new challenges related to rigour in benchmarking,
contamination, replicability, and sustainability. In this paper, we invite the
research community to reflect on how these challenges are addressed in SE. Our
results provide a structured overview of current LLM-based SE research at ICSE,
highlighting both encouraging practices and persistent shortcomings. We
conclude with recommendations to strengthen benchmarking rigour, improve
replicability, and address the financial and environmental costs of LLM-based
SE.

</details>


### [95] ["Show Me You Comply... Without Showing Me Anything": Zero-Knowledge Software Auditing for AI-Enabled Systems](https://arxiv.org/abs/2510.26576)
*Filippo Scaramuzza,Renato Cordeiro Ferreira,Tomaz Maia Suller,Giovanni Quattrocchi,Damian Andrew Tamburri,Willem-Jan van den Heuvel*

Main category: cs.SE

TL;DR: ZKMLOps框架利用零知识证明技术，在保护AI模型隐私的同时实现合规验证，解决了透明性与资产保护的冲突。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在关键领域的广泛应用，其可信度问题成为主要障碍，需要可验证的问责机制。传统的验证方法成本高、依赖人工，且不适用于AI模型的“黑箱”特性。

Method: 本文提出了ZKMLOps，一种新型的MLOps验证框架，将零知识证明（ZKPs）集成到机器学习操作生命周期中，并通过金融风险审计的案例研究评估其实用性。

Result: 通过对金融风险审计的案例研究和ZKP协议的实证评估，验证了ZKMLOps的可行性和实用性，并分析了不同复杂度ML模型的性能权衡。

Conclusion: ZKMLOps框架通过整合零知识证明（ZKPs）和软件工程模式，提供了一种模块化和可重复的过程，以生成可验证的加密合规证明，解决了AI模型透明性与资产保护之间的冲突。

Abstract: The increasing exploitation of Artificial Intelligence (AI) enabled systems
in critical domains has made trustworthiness concerns a paramount showstopper,
requiring verifiable accountability, often by regulation (e.g., the EU AI Act).
Classical software verification and validation techniques, such as procedural
audits, formal methods, or model documentation, are the mechanisms used to
achieve this. However, these methods are either expensive or heavily manual and
ill-suited for the opaque, "black box" nature of most AI models. An intractable
conflict emerges: high auditability and verifiability are required by law, but
such transparency conflicts with the need to protect assets being audited-e.g.,
confidential data and proprietary models-leading to weakened accountability. To
address this challenge, this paper introduces ZKMLOps, a novel MLOps
verification framework that operationalizes Zero-Knowledge Proofs
(ZKPs)-cryptographic protocols allowing a prover to convince a verifier that a
statement is true without revealing additional information-within
Machine-Learning Operations lifecycles. By integrating ZKPs with established
software engineering patterns, ZKMLOps provides a modular and repeatable
process for generating verifiable cryptographic proof of compliance. We
evaluate the framework's practicality through a study of regulatory compliance
in financial risk auditing and assess feasibility through an empirical
evaluation of top ZKP protocols, analyzing performance trade-offs for ML models
of increasing complexity.

</details>


### [96] [Online and Interactive Bayesian Inference Debugging](https://arxiv.org/abs/2510.26579)
*Nathanael Nussbaumer,Markus Böck,Jürgen Cito*

Main category: cs.SE

TL;DR: 本文介绍了一种在线交互式贝叶斯推理调试工具，有效减少了调试时间和专业知识需求，实验验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 概率编程虽促进了贝叶斯模型的开发和推理，但其调试过程耗时且需深厚专业知识，限制了广泛应用。

Method: 提出了一种在线交互式贝叶斯推理调试工具，满足关键需求，并在开发环境中直接实现。

Result: 在18名经验丰富的参与者中进行的研究表明，该方法显著减少了推理调试任务的时间和难度。

Conclusion: 本文提出了一种新颖的贝叶斯推理调试方法，显著减少了调试所需的时间和专业知识，并通过实验验证了其有效性。

Abstract: Probabilistic programming is a rapidly developing programming paradigm which
enables the formulation of Bayesian models as programs and the automation of
posterior inference. It facilitates the development of models and conducting
Bayesian inference, which makes these techniques available to practitioners
from multiple fields. Nevertheless, probabilistic programming is notoriously
difficult as identifying and repairing issues with inference requires a lot of
time and deep knowledge. Through this work, we introduce a novel approach to
debugging Bayesian inference that reduces time and required knowledge
significantly. We discuss several requirements a Bayesian inference debugging
framework has to fulfill, and propose a new tool that meets these key
requirements directly within the development environment. We evaluate our
results in a study with 18 experienced participants and show that our approach
to online and interactive debugging of Bayesian inference significantly reduces
time and difficulty on inference debugging tasks.

</details>


### [97] [Stitch: Step-by-step LLM Guided Tutoring for Scratch](https://arxiv.org/abs/2510.26634)
*Yuan Si,Kyle Qi,Daming Li,Hanyuan Shi,Jialu Zhang*

Main category: cs.SE

TL;DR: Stitch是一个交互式编程辅导系统，通过逐步引导而非直接展示正确答案来帮助学习者修复语义错误，提升问题解决能力。


<details>
  <summary>Details</summary>
Motivation: 现有的调试方法直接展示正确答案，虽能修复错误但不利于培养问题解决能力。

Method: Stitch通过Diff-Analyze模块对比学生项目与参考实现，识别关键差异，利用大语言模型解释差异重要性，并通过自定义渲染引擎高亮区块，支持学习者逐步修复。

Result: 实证研究表明，Stitch的逐步引导方法在提升学习效果上优于直接展示答案和现有自动化反馈工具。

Conclusion: 逐步辅导系统显著提升学习效果，为基于块的编程教育反馈设计提供了新证据。

Abstract: Block-based environments such as Scratch are increasingly popular in
programming education. While block syntax reduces surface errors, semantic bugs
remain common and challenging for novices to resolve. Existing debugging
workflows typically show the correct program directly to learners, a strategy
that may fix errors but undermines the development of problem-solving skills.
  We present Stitch, an interactive tutoring system that replaces "showing the
answer" with step-by-step scaffolding. The system's Diff-Analyze module
contrasts a student's project with a reference implementation, identifies the
most critical differences, and uses a large language model to explain why these
changes matter. Learners inspect highlighted blocks through a custom rendering
engine, understand the explanations, and selectively apply partial fixes. This
iterative process continues until the intended functionality is achieved.
  We evaluate Stitch in an empirical study, comparing it against a
state-of-the-art automated feedback generation tool for Scratch. Our key
insight is that simply presenting the correct program is pedagogically
ineffective. In contrast, our interactive, step-by-step guided system promotes
a more effective learning experience. More broadly, what constitutes effective
feedback in block-based programming remains an open question. Our evaluation
provides new evidence that step-by-step tutoring significantly enhances
learning outcomes, outperforming both direct-answer approaches and current
automated feedback generation tools.

</details>


### [98] [Process-based Indicators of Vulnerability Re-Introducing Code Changes: An Exploratory Case Study](https://arxiv.org/abs/2510.26676)
*Samiha Shimmi,Nicholas M. Synovic,Mona Rahimi,George K. Thiruvathukal*

Main category: cs.SE

TL;DR: 研究通过过程指标和代码变更分析漏洞重新引入，发现其与问题管理和团队响应效率相关，为预测风险修复提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探索过程指标是否能揭示随时间推移的 risky开发活动，以帮助预测和缓解软件漏洞的重新引入。

Method: 通过对ImageMagick项目的案例研究，将纵向过程指标（如bus factor、问题密度和问题滞留）与漏洞重新引入活动相关联，分析了76个重新引入漏洞的实例。

Result: 重新引入漏洞常与问题滞留增加和问题密度波动相关，反映了问题管理和团队响应的短期低效率。

Conclusion: 软件漏洞的重新引入往往与问题管理的短期低效率和团队响应能力波动相关，这为结合过程和代码指标预测风险修复提供了基础。

Abstract: Software vulnerabilities often persist or re-emerge even after being fixed,
revealing the complex interplay between code evolution and socio-technical
factors. While source code metrics provide useful indicators of
vulnerabilities, software engineering process metrics can uncover patterns that
lead to their introduction. Yet few studies have explored whether process
metrics can reveal risky development activities over time -- insights that are
essential for anticipating and mitigating software vulnerabilities. This work
highlights the critical role of process metrics along with code changes in
understanding and mitigating vulnerability reintroduction. We move beyond
file-level prediction and instead analyze security fixes at the commit level,
focusing not only on whether a single fix introduces a vulnerability but also
on the longer sequences of changes through which vulnerabilities evolve and
re-emerge. Our approach emphasizes that reintroduction is rarely the result of
one isolated action, but emerges from cumulative development activities and
socio-technical conditions. To support this analysis, we conducted a case study
on the ImageMagick project by correlating longitudinal process metrics such as
bus factor, issue density, and issue spoilage with vulnerability reintroduction
activities, encompassing 76 instances of reintroduced vulnerabilities. Our
findings show that reintroductions often align with increased issue spoilage
and fluctuating issue density, reflecting short-term inefficiencies in issue
management and team responsiveness. These observations provide a foundation for
broader studies that combine process and code metrics to predict risky fixes
and strengthen software security.

</details>


### [99] [Using Copilot Agent Mode to Automate Library Migration: A Quantitative Assessment](https://arxiv.org/abs/2510.26699)
*Aylton Almeida,Laerte Xavier,Marco Tulio Valente*

Main category: cs.SE

TL;DR: 研究评估了使用LLM代理自动更新SQLAlchemy库的效果，结果显示其在API迁移方面表现优秀，但在功能保持方面不足。


<details>
  <summary>Details</summary>
Motivation: 保持软件系统更新以避免技术债务、安全漏洞和遗留系统的僵化，但更新库和框架仍然是一个耗时且容易出错的过程。

Method: 使用Github的Copilot Agent Mode，一个能够规划和执行多步迁移工作流程的自主AI系统，对十个客户端应用程序中的SQLAlchemy库进行更新评估。

Result: LLM代理在迁移功能和API使用方面表现优异（迁移覆盖率：100%，中位数），但在保持应用程序功能方面表现不佳（测试通过率：39.75%，中位数）。

Conclusion: LLM代理在迁移SQLAlchemy版本的功能和API使用方面表现出色（迁移覆盖率：100%，中位数），但在保持应用程序功能方面表现不佳，导致测试通过率较低（39.75%，中位数）。

Abstract: Keeping software systems up to date is essential to avoid technical debt,
security vulnerabilities, and the rigidity typical of legacy systems. However,
updating libraries and frameworks remains a time consuming and error-prone
process. Recent advances in Large Language Models (LLMs) and agentic coding
systems offer new opportunities for automating such maintenance tasks. In this
paper, we evaluate the update of a well-known Python library, SQLAlchemy,
across a dataset of ten client applications. For this task, we use the Github's
Copilot Agent Mode, an autonomous AI systema capable of planning and executing
multi-step migration workflows. To assess the effectiveness of the automated
migration, we also introduce Migration Coverage, a metric that quantifies the
proportion of API usage points correctly migrated. The results of our study
show that the LLM agent was capable of migrating functionalities and API usages
between SQLAlchemy versions (migration coverage: 100%, median), but failed to
maintain the application functionality, leading to a low test-pass rate
(39.75%, median).

</details>


### [100] [Optimized Log Parsing with Syntactic Modifications](https://arxiv.org/abs/2510.26793)
*Nafid Enan,Gias Uddin*

Main category: cs.SE

TL;DR: 本文实证比较了日志解析器的性能，发现语义方法模板识别更准，语法方法效率更高；两阶段架构更优，并提出了提升解析准确率的SynLog+模块。


<details>
  <summary>Details</summary>
Motivation: 日志解析是自动化日志分析的关键步骤，但现有解析器技术多样，需评估其特性和性能以指导实践。

Method: 本文通过实证研究比较了基于语法和基于语义的日志解析器，以及单阶段与两阶段解析架构的性能。

Result: 研究发现语义方法在模板识别上更优，而语法方法效率更高且分组更准确；两阶段架构比单阶段更准确。SynLog+显著提升了两种解析器的准确率。

Conclusion: 基于研究结果，作者提出了SynLog+，作为两阶段日志解析架构的第二阶段模板识别模块，显著提升了语法和语义日志解析器的解析准确率。

Abstract: Logs provide valuable insights into system runtime and assist in software
development and maintenance. Log parsing, which converts semi-structured log
data into structured log data, is often the first step in automated log
analysis. Given the wide range of log parsers utilizing diverse techniques, it
is essential to evaluate them to understand their characteristics and
performance. In this paper, we conduct a comprehensive empirical study
comparing syntax- and semantic-based log parsers, as well as single-phase and
two-phase parsing architectures. Our experiments reveal that semantic-based
methods perform better at identifying the correct templates and syntax-based
log parsers are 10 to 1,000 times more efficient and provide better grouping
accuracy although they fall short in accurate template identification.
Moreover, two-phase architecture consistently improves accuracy compared to
single-phase architecture. Based on the findings of this study, we propose
SynLog+, a template identification module that acts as the second phase in a
two-phase log parsing architecture. SynLog+ improves the parsing accuracy of
syntax-based and semantic-based log parsers by 236\% and 20\% on average,
respectively, with virtually no additional runtime cost.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [101] [Towards Piece-by-Piece Explanations for Chess Positions with SHAP](https://arxiv.org/abs/2510.25775)
*Francesco Spinnato*

Main category: cs.AI

TL;DR: 本文提出了一种基于SHAP的国际象棋分析方法，通过计算单个棋子的贡献来解释引擎评估，增强了评估的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前国际象棋引擎的评估输出虽然精确但不透明，缺乏对单个棋子或模式贡献的明确解释。本文旨在填补这一空白。

Method: 通过将棋子视为特征并系统性地移除它们，计算每个棋子的加性贡献，从而在局部忠实且人类可理解的方式下解释引擎的输出。

Result: 提出的方法能够有效解释引擎评估，为可视化、人类训练和引擎比较提供了新可能。

Conclusion: 本文提出了一种将SHAP方法应用于国际象棋分析的新方法，能够以人类可理解的方式解释引擎评估的贡献，为可解释的国际象棋AI研究开辟了新方向。

Abstract: Contemporary chess engines offer precise yet opaque evaluations, typically
expressed as centipawn scores. While effective for decision-making, these
outputs obscure the underlying contributions of individual pieces or patterns.
In this paper, we explore adapting SHAP (SHapley Additive exPlanations) to the
domain of chess analysis, aiming to attribute a chess engines evaluation to
specific pieces on the board. By treating pieces as features and systematically
ablating them, we compute additive, per-piece contributions that explain the
engines output in a locally faithful and human-interpretable manner. This
method draws inspiration from classical chess pedagogy, where players assess
positions by mentally removing pieces, and grounds it in modern explainable AI
techniques. Our approach opens new possibilities for visualization, human
training, and engine comparison. We release accompanying code and data to
foster future research in interpretable chess AI.

</details>


### [102] [An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0](https://arxiv.org/abs/2510.25813)
*Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli*

Main category: cs.AI

TL;DR: 提出工业5.0框架，基于代理设计，支持本地推理和模块化集成，初步评估显示性能提升。


<details>
  <summary>Details</summary>
Motivation: 旨在简化AI模型在边缘设备上的部署，提升工业环境中的灵活性和集成便捷性。

Method: 采用基于代理的设计，支持模块化集成，并保持低资源需求。

Result: 初步评估显示，在食品工业的真实场景中，部署时间和系统适应性性能有所提升。

Conclusion: 该论文提出了一个适用于工业5.0的新型框架，通过本地推理和实时处理减少了延迟并避免了外部数据传输。

Abstract: We present a novel framework for Industry 5.0 that simplifies the deployment
of AI models on edge devices in various industrial settings. The design reduces
latency and avoids external data transfer by enabling local inference and
real-time processing. Our implementation is agent-based, which means that
individual agents, whether human, algorithmic, or collaborative, are
responsible for well-defined tasks, enabling flexibility and simplifying
integration. Moreover, our framework supports modular integration and maintains
low resource requirements. Preliminary evaluations concerning the food industry
in real scenarios indicate improved deployment time and system adaptability
performance. The source code is publicly available at
https://github.com/AI-REDGIO-5-0/ci-component.

</details>


### [103] [Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue](https://arxiv.org/abs/2510.25820)
*Vanessa Figueiredo,David Elumeze*

Main category: cs.AI

TL;DR: 研究通过游戏实验发现，约束提示对玩家体验的影响因角色而异，提出了符号化脚手架游戏框架以平衡稳定性和即兴发挥。


<details>
  <summary>Details</summary>
Motivation: 探讨约束提示是否能真正改善玩家体验，特别是在大型语言模型（LLMs）驱动的非玩家角色（NPCs）互动游戏中。

Method: 研究通过一个名为'The Interview'的语音侦探游戏，采用GPT-4o驱动，进行了高约束提示（HCP）和低约束提示（LCP）的用户体验对比研究，随后设计了一种混合JSON+RAG脚手架，并通过LLM法官进行合成评估。

Result: 研究发现脚手架效果与角色相关：面试官（任务给予NPC）获得了稳定性，而嫌疑犯NPCs则失去了即兴的可信度。

Conclusion: 研究发现推翻了一贯认为更严格的约束能提升游戏体验的假设，提出了符号化脚手架游戏框架，通过模糊数值边界在需要稳定性的地方保持连贯性，同时保留即兴发挥的空间以维持玩家的参与感。

Abstract: Large Language Models (LLMs) promise to transform interactive games by
enabling non-player characters (NPCs) to sustain unscripted dialogue. Yet it
remains unclear whether constrained prompts actually improve player experience.
We investigate this question through The Interview, a voice-based detective
game powered by GPT-4o. A within-subjects usability study ($N=10$) compared
high-constraint (HCP) and low-constraint (LCP) prompts, revealing no reliable
experiential differences beyond sensitivity to technical breakdowns. Guided by
these findings, we redesigned the HCP into a hybrid JSON+RAG scaffold and
conducted a synthetic evaluation with an LLM judge, positioned as an
early-stage complement to usability testing. Results uncovered a novel pattern:
scaffolding effects were role-dependent: the Interviewer (quest-giver NPC)
gained stability, while suspect NPCs lost improvisational believability. These
findings overturn the assumption that tighter constraints inherently enhance
play. Extending fuzzy-symbolic scaffolding, we introduce \textit{Symbolically
Scaffolded Play}, a framework in which symbolic structures are expressed as
fuzzy, numerical boundaries that stabilize coherence where needed while
preserving improvisation where surprise sustains engagement.

</details>


### [104] [Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters](https://arxiv.org/abs/2510.25860)
*Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei*

Main category: cs.AI

TL;DR: 提出人机协作框架通过拒绝采样重建思维轨迹，显著提升LLM评估者的可靠性及模型间一致性。


<details>
  <summary>Details</summary>
Motivation: 解决主观任务中LLM评估者可靠性不足的问题，特别是当人类判断涉及超越标注标签的微妙推理时。

Method: 提出了一种人机协作框架，通过简单的拒绝采样方法大规模重建思维轨迹。

Result: 方法显著提高了LLM与人类的一致性，改进的标注指南也增加了不同LLM模型之间的一致性。

Conclusion: LLMs可以作为人类思维轨迹的实用代理，将仅标签语料库扩展为增强LLM评估者可靠性的思维轨迹增强资源。

Abstract: Large language models (LLMs) are increasingly used as raters for evaluation
tasks. However, their reliability is often limited for subjective tasks, when
human judgments involve subtle reasoning beyond annotation labels. Thinking
traces, the reasoning behind a judgment, are highly informative but challenging
to collect and curate. We present a human-LLM collaborative framework to infer
thinking traces from label-only annotations. The proposed framework uses a
simple and effective rejection sampling method to reconstruct these traces at
scale. These inferred thinking traces are applied to two complementary tasks:
(1) fine-tuning open LLM raters; and (2) synthesizing clearer annotation
guidelines for proprietary LLM raters. Across multiple datasets, our methods
lead to significantly improved LLM-human agreement. Additionally, the refined
annotation guidelines increase agreement among different LLM models. These
results suggest that LLMs can serve as practical proxies for otherwise
unrevealed human thinking traces, enabling label-only corpora to be extended
into thinking-trace-augmented resources that enhance the reliability of LLM
raters.

</details>


### [105] [The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence](https://arxiv.org/abs/2510.25883)
*Christian Dittrich,Jennifer Flygare Kinne*

Main category: cs.AI

TL;DR: 该论文提出了ITI和CEP两级框架，解释了压缩为何促进因果结构发现，并提供了可测试预测，统一了生物和人工系统的智能理论。


<details>
  <summary>Details</summary>
Motivation: 现有框架虽然认识到压缩对智能的核心作用，但未能明确解释为何压缩过程能促进因果结构的发现而非表面统计模式。

Method: 引入了一个两级框架：信息论必要性（ITI）和压缩效率原则（CEP），通过预测压缩和异常积累动态解释因果结构的发现。

Result: ITI和CEP共同定义了一个因果链，从生存压力到预测必要性、压缩需求、效率优化、生成结构发现，最终到现实对齐。

Conclusion: 该框架通过信息论和进化约束，阐明了智能是结构化环境中持续存在的机械必然结果，并提供了可测试的预测。

Abstract: Existing frameworks converge on the centrality of compression to intelligence
but leave underspecified why this process enforces the discovery of causal
structure rather than superficial statistical patterns. We introduce a
two-level framework to address this gap. The Information-Theoretic Imperative
(ITI) establishes that any system persisting in uncertain environments must
minimize epistemic entropy through predictive compression: this is the
evolutionary "why" linking survival pressure to information-processing demands.
The Compression Efficiency Principle (CEP) specifies how efficient compression
mechanically selects for generative, causal models through
exception-accumulation dynamics, making reality alignment a consequence rather
than a contingent achievement. Together, ITI and CEP define a causal chain:
from survival pressure to prediction necessity, compression requirement,
efficiency optimization, generative structure discovery, and ultimately reality
alignment. Each link follows from physical, information-theoretic, or
evolutionary constraints, implying that intelligence is the mechanically
necessary outcome of persistence in structured environments. This framework
yields empirically testable predictions: compression efficiency, measured as
approach to the rate-distortion frontier, correlates with out-of-distribution
generalization; exception-accumulation rates differentiate causal from
correlational models; hierarchical systems exhibit increasing efficiency across
abstraction layers; and biological systems demonstrate metabolic costs that
track representational complexity. ITI and CEP thereby provide a unified
account of convergence across biological, artificial, and multi-scale systems,
addressing the epistemic and functional dimensions of intelligence without
invoking assumptions about consciousness or subjective experience.

</details>


### [106] [Approximating Human Preferences Using a Multi-Judge Learned System](https://arxiv.org/abs/2510.25884)
*Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer*

Main category: cs.AI

TL;DR: 提出了一种基于角色的偏好聚合框架，通过GAM和MLP实现，有效克服LLM评委的偏差和敏感性，适用于RLHF和模型路由系统。


<details>
  <summary>Details</summary>
Motivation: 对齐基于LLM的评委与人类偏好是一个重要挑战，因为它们难以校准且常受评分标准敏感性、偏差和不稳定性影响。克服这一挑战能推动RLHF和模型路由系统等关键应用。

Method: 提出了一个框架，通过学习聚合多个基于评分标准的评委输出来建模多样化的角色偏好，具体实现了GAM和MLP两种聚合器。

Result: 通过案例研究评估了该方法在人类和LLM评委偏差中的表现，展示了其相对于基线方法的优越性和鲁棒性。

Conclusion: 提出的基于角色的偏好聚合框架在克服LLM评委的敏感性和偏差方面具有潜力，为RLHF和模型路由系统提供了可靠的方法。

Abstract: Aligning LLM-based judges with human preferences is a significant challenge,
as they are difficult to calibrate and often suffer from rubric sensitivity,
bias, and instability. Overcoming this challenge advances key applications,
such as creating reliable reward models for Reinforcement Learning from Human
Feedback (RLHF) and building effective routing systems that select the
best-suited model for a given user query. In this work, we propose a framework
for modeling diverse, persona-based preferences by learning to aggregate
outputs from multiple rubric-conditioned judges. We investigate the performance
of this approach against naive baselines and assess its robustness through case
studies on both human and LLM-judges biases. Our primary contributions include
a persona-based method for synthesizing preference labels at scale and two
distinct implementations of our aggregator: Generalized Additive Model (GAM)
and a Multi-Layer Perceptron (MLP).

</details>


### [107] [SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications](https://arxiv.org/abs/2510.25908)
*Emily Herron,Junqi Yin,Feiyi Wang*

Main category: cs.AI

TL;DR: SciTrust 2.0框架评估LLM在科学应用中的可信度，发现通用模型优于科学专用模型，并开源框架以推动更可信AI的发展。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在高风险科学应用中的可信度问题，提升模型在科学研究和伦理方面的可靠性。

Method: SciTrust 2.0框架通过四个维度（真实性、对抗鲁棒性、科学安全性和科学伦理）评估LLM，采用新颖的开放式真实性基准和伦理基准，结合专家验证和多指标评估。

Result: 通用行业模型在可信度各维度上表现优于科学专用模型，GPT-o4-mini在真实性和对抗鲁棒性评估中表现最佳；科学专用模型在逻辑和伦理推理能力上存在明显缺陷。

Conclusion: SciTrust 2.0提供了一个全面的框架，用于评估大型语言模型在科学应用中的可信度，揭示了通用行业模型在可信度方面优于科学专用模型，并开源了该框架以促进更可信AI系统的开发。

Abstract: Large language models (LLMs) have demonstrated transformative potential in
scientific research, yet their deployment in high-stakes contexts raises
significant trustworthiness concerns. Here, we introduce SciTrust 2.0, a
comprehensive framework for evaluating LLM trustworthiness in scientific
applications across four dimensions: truthfulness, adversarial robustness,
scientific safety, and scientific ethics. Our framework incorporates novel,
open-ended truthfulness benchmarks developed through a verified
reflection-tuning pipeline and expert validation, alongside a novel ethics
benchmark for scientific research contexts covering eight subcategories
including dual-use research and bias. We evaluated seven prominent LLMs,
including four science-specialized models and three general-purpose industry
models, using multiple evaluation metrics including accuracy, semantic
similarity measures, and LLM-based scoring. General-purpose industry models
overall outperformed science-specialized models across each trustworthiness
dimension, with GPT-o4-mini demonstrating superior performance in truthfulness
assessments and adversarial robustness. Science-specialized models showed
significant deficiencies in logical and ethical reasoning capabilities, along
with concerning vulnerabilities in safety evaluations, particularly in
high-risk domains such as biosecurity and chemical weapons. By open-sourcing
our framework, we provide a foundation for developing more trustworthy AI
systems and advancing research on model safety and ethics in scientific
contexts.

</details>


### [108] [FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization](https://arxiv.org/abs/2510.25914)
*Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami*

Main category: cs.AI

TL;DR: 利用自主AI代理解决FinOps中异构账单数据的挑战，系统模拟真实流程并验证其性能媲美人工。


<details>
  <summary>Details</summary>
Motivation: FinOps实践中，异构账单数据格式导致洞察和决策困难，需自动化解决方案。

Method: 构建了一个模拟真实行业流程的系统，从多源检索数据到整合分析生成优化建议，并使用开源和闭源语言模型评估代理性能。

Result: 代理在理解和执行任务方面表现与真实FinOps从业者相当，验证了方法的可行性。

Conclusion: FinOps代理通过自主AI技术有效解决了多云环境下账单数据异构性问题，能够像实际从业者一样理解、规划和执行任务。

Abstract: FinOps (Finance + Operations) represents an operational framework and
cultural practice which maximizes cloud business value through collaborative
financial accountability across engineering, finance, and business teams.
FinOps practitioners face a fundamental challenge: billing data arrives in
heterogeneous formats, taxonomies, and metrics from multiple cloud providers
and internal systems which eventually lead to synthesizing actionable insights,
and making time-sensitive decisions. To address this challenge, we propose
leveraging autonomous, goal-driven AI agents for FinOps automation. In this
paper, we built a FinOps agent for a typical use-case for IT infrastructure and
cost optimization. We built a system simulating a realistic end-to-end industry
process starting with retrieving data from various sources to consolidating and
analyzing the data to generate recommendations for optimization. We defined a
set of metrics to evaluate our agent using several open-source and close-source
language models and it shows that the agent was able to understand, plan, and
execute tasks as well as an actual FinOps practitioner.

</details>


### [109] [Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning](https://arxiv.org/abs/2510.25933)
*Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron*

Main category: cs.AI

TL;DR: 3.8B模型Humans-Junior在FACTS任务上与GPT-4o等效（±5 pp内），成本低19倍。方法结合定向推理和微调，显著提升效果。前沿模型提示优化也有增益。


<details>
  <summary>Details</summary>
Motivation: 探索如何在低成本的小型语言模型（3.8B参数）上实现与大型模型（如GPT-4o）相当的FACTS Grounding性能，并显著降低部署成本。

Method: 结合了最小化定向的"Exoskeleton Reasoning"支架和行为微调（侧重于协议合规性而非领域答案），两者协同显著提升效果（+17.7 pp）并降低方差（约25%）。

Result: Humans-Junior在Q1-Q500测试中与GPT-4o的差异为0.8 pp（等效于±5 pp范围内），云成本降低约19倍。前沿模型（如GPT-4o、Gemini-2.5-Pro）在仅提示设置下也有显著提升。

Conclusion: Humans-Junior模型在FACTS Grounding公共子集上表现与GPT-4o相当（±5 pp等效范围内），且成本显著更低（云定价约为GPT-4o的1/19，自托管或边缘部署可接近零边际成本）。

Abstract: We introduce Humans-Junior, a 3.8B model that matches GPT-4o on the FACTS
Grounding public subset within a $\pm 5$ pp equivalence margin.
  Results. On Q1--Q500 under identical judges, GPT-4o scores 73.5% (95% CI
69.5--77.2) and Humans-Junior 72.7% (95% CI 68.7--76.5); the paired difference
is 0.8 pp (bootstrap 95% CI $-3.1$ to $+4.7$; permutation $p = 0.72$; Cohen's
$d = 0.023$). TOST establishes equivalence at $\pm 5$ pp (not at $\pm 3$ pp).
When purchased as managed APIs, Humans-Junior's base model
(Phi-3.5-mini-instruct) is $\approx 19\times$ less expensive than GPT-4o on
Microsoft AI Foundry pricing; self-hosted or edge deployments can drive
incremental inference cost toward zero. Measured vs estimated pricing sources
are tabulated in Appendix E.
  Method. Our approach combines minimal directed "Exoskeleton Reasoning"
scaffolds with behavioral fine-tuning that teaches protocol compliance
(epistemic discipline) rather than domain answers. Fine-tuning alone adds
little; combined, they synergize (+17.7 pp, $p < 0.001$) and reduce variance
($\approx 25\%$). In prompt-only settings on frontier models (Q1--Q100;
non-comparable), directed reasoning improved GPT-4o by +11.8 pp to 85.3% and
Gemini-2.5-Pro by +5.0 pp to 93.3% (baseline 88.3%, $n = 100$); see Section~5.
  TL;DR. A 3.8B model achieves GPT-4o-level FACTS accuracy (equivalent within
$\pm 5$ pp on Q1--Q500). Cloud pricing shows $\approx 19\times$ lower cost
versus GPT-4o, and self-hosted/edge deployments can approach zero marginal
cost. Pricing sources are listed in Appendix E. Frontier prompt-only gains
(Q1--Q100; non-comparable) and optimized-prompt exploratory results under
earlier judges are summarized in Appendix F.
  Keywords: Small Language Models, Factual Grounding, Directed Reasoning,
Fine-Tuning, Model Alignment, Cost-Efficient AI

</details>


### [110] [Estimating cognitive biases with attention-aware inverse planning](https://arxiv.org/abs/2510.25951)
*Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho*

Main category: cs.AI

TL;DR: 本文提出了一种结合深度强化学习与计算认知建模的方法，用于从行为中推断人类注意力偏见，并在真实驾驶场景中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 人类的目标导向行为受认知偏见影响，自主系统需理解这些偏见以更好地与人互动。本文旨在从行为中推断这些偏见。

Method: 本文通过将深度强化学习与计算认知建模相结合，构建了注意力感知逆规划方法，用于从人类行为中推断其注意力偏见。

Result: 研究表明，注意力感知逆规划与标准逆强化学习存在系统性差异，并成功推断出真实驾驶场景中的注意力策略。

Conclusion: 本文提出了一种结合深度强化学习与计算认知建模的方法，用于推断人们在真实驾驶场景中的注意力策略，展示了注意力感知逆规划在估计认知偏见方面的可扩展性。

Abstract: People's goal-directed behaviors are influenced by their cognitive biases,
and autonomous systems that interact with people should be aware of this. For
example, people's attention to objects in their environment will be biased in a
way that systematically affects how they perform everyday tasks such as driving
to work. Here, building on recent work in computational cognitive science, we
formally articulate the attention-aware inverse planning problem, in which the
goal is to estimate a person's attentional biases from their actions. We
demonstrate how attention-aware inverse planning systematically differs from
standard inverse reinforcement learning and how cognitive biases can be
inferred from behavior. Finally, we present an approach to attention-aware
inverse planning that combines deep reinforcement learning with computational
cognitive modeling. We use this approach to infer the attentional strategies of
RL agents in real-life driving scenarios selected from the Waymo Open Dataset,
demonstrating the scalability of estimating cognitive biases with
attention-aware inverse planning.

</details>


### [111] [From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL](https://arxiv.org/abs/2510.25997)
*Manu Redd,Tao Zhe,Dongjie Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于代理的NL-to-SQL系统，显著提升了时空查询的准确性和用户体验，证明了代理编排的潜力。


<details>
  <summary>Details</summary>
Motivation: NL-to-SQL系统旨在让用户无需学习SQL即可查询数据库，但现有系统在处理现实的时空查询时表现不佳，需要解决模糊的用户表述与模式特定类别的对齐、时间推理和输出选择等问题。

Method: 通过一个基于Mistral的ReAct代理扩展了基础的文本到SQL模型（llama-3-sqlcoder-8b），该代理能够规划、分解和调整查询，结合模式检查、SQL生成、执行和可视化工具。

Result: 在35个针对纽约和东京签到数据集的自然语言查询测试中，代理方法的准确率显著高于基线（91.4% vs. 28.6%），并通过地图、图表和结构化自然语言摘要提升了可用性。

Conclusion: 作者认为，基于代理的编排（而非仅强化SQL生成器）是构建交互式地理空间助手的有前景基础。

Abstract: Natural-language-to-SQL (NL-to-SQL) systems hold promise for democratizing
access to structured data, allowing users to query databases without learning
SQL. Yet existing systems struggle with realistic spatio-temporal queries,
where success requires aligning vague user phrasing with schema-specific
categories, handling temporal reasoning, and choosing appropriate outputs. We
present an agentic pipeline that extends a naive text-to-SQL baseline
(llama-3-sqlcoder-8b) with orchestration by a Mistral-based ReAct agent. The
agent can plan, decompose, and adapt queries through schema inspection, SQL
generation, execution, and visualization tools. We evaluate on 35
natural-language queries over the NYC and Tokyo check-in dataset, covering
spatial, temporal, and multi-dataset reasoning. The agent achieves
substantially higher accuracy than the naive baseline 91.4% vs. 28.6% and
enhances usability through maps, plots, and structured natural-language
summaries. Crucially, our design enables more natural human-database
interaction, supporting users who lack SQL expertise, detailed schema
knowledge, or prompting skill. We conclude that agentic orchestration, rather
than stronger SQL generators alone, is a promising foundation for interactive
geospatial assistants.

</details>


### [112] [AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys](https://arxiv.org/abs/2510.26012)
*Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song*

Main category: cs.AI

TL;DR: autosurvey2 是一个自动化生成学术综述的多阶段流水线系统，通过检索增强和结构化评估，显著提升了综述的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 随着研究文献（尤其是大语言模型领域）的快速增长，生成全面且最新的综述论文变得越来越困难。

Method: autosurvey2 采用多阶段流水线，结合检索增强合成和结构化评估，包括并行章节生成、迭代优化和实时检索最新文献。

Result: 实验结果表明，autosurvey2 在结构连贯性和主题相关性上优于现有检索基线和自动化基线，同时保持较高的引用保真度。

Conclusion: autosurvey2 提供了一个可扩展且可复现的解决方案，用于生成长篇学术综述，并为未来自动化学术写作研究奠定了坚实基础。

Abstract: The rapid growth of research literature, particularly in large language
models (LLMs), has made producing comprehensive and current survey papers
increasingly difficult. This paper introduces autosurvey2, a multi-stage
pipeline that automates survey generation through retrieval-augmented synthesis
and structured evaluation. The system integrates parallel section generation,
iterative refinement, and real-time retrieval of recent publications to ensure
both topical completeness and factual accuracy. Quality is assessed using a
multi-LLM evaluation framework that measures coverage, structure, and relevance
in alignment with expert review standards. Experimental results demonstrate
that autosurvey2 consistently outperforms existing retrieval-based and
automated baselines, achieving higher scores in structural coherence and
topical relevance while maintaining strong citation fidelity. By combining
retrieval, reasoning, and automated evaluation into a unified framework,
autosurvey2 provides a scalable and reproducible solution for generating
long-form academic surveys and contributes a solid foundation for future
research on automated scholarly writing. All code and resources are available
at https://github.com/annihi1ation/auto_research.

</details>


### [113] [Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization](https://arxiv.org/abs/2510.26023)
*Zhipeng Bao,Qianwen Li*

Main category: cs.AI

TL;DR: StuckSolver是一种基于LLM的自动驾驶车辆停滞恢复框架，通过自主推理和乘客引导提升性能，无需修改AV内部架构。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆在特定交通场景中易停滞，现有解决方案（如远程干预和手动接管）成本高、效率低且局限性大，亟需创新方法提升AV的自主恢复能力。

Method: StuckSolver是一个插件式的附加模块，利用标准传感器数据流检测停滞状态、解释环境上下文，并生成可由AV原生规划器执行的高级恢复命令。

Result: 在Bench2Drive基准测试和自定义不确定性场景中，StuckSolver通过自主推理达到了接近最先进的性能，结合乘客引导后表现更优。

Conclusion: StuckSolver作为一种新型LLM驱动的恢复框架，通过自主推理和/或乘客引导决策，有效解决了自动驾驶车辆在特定交通场景中的停滞问题，且无需修改AV的内部架构，展现了优异的性能。

Abstract: Despite significant advancements in recent decades, autonomous vehicles (AVs)
continue to face challenges in navigating certain traffic scenarios where human
drivers excel. In such situations, AVs often become immobilized, disrupting
overall traffic flow. Current recovery solutions, such as remote intervention
(which is costly and inefficient) and manual takeover (which excludes
non-drivers and limits AV accessibility), are inadequate. This paper introduces
StuckSolver, a novel Large Language Model (LLM) driven recovery framework that
enables AVs to resolve immobilization scenarios through self-reasoning and/or
passenger-guided decision-making. StuckSolver is designed as a plug-in add-on
module that operates on top of the AV's existing perception-planning-control
stack, requiring no modification to its internal architecture. Instead, it
interfaces with standard sensor data streams to detect immobilization states,
interpret environmental context, and generate high-level recovery commands that
can be executed by the AV's native planner. We evaluate StuckSolver on the
Bench2Drive benchmark and in custom-designed uncertainty scenarios. Results
show that StuckSolver achieves near-state-of-the-art performance through
autonomous self-reasoning alone and exhibits further improvements when
passenger guidance is incorporated.

</details>


### [114] [Can AI be Accountable?](https://arxiv.org/abs/2510.26057)
*Andrew L. Kun*

Main category: cs.AI

TL;DR: 本章讨论AI问责制的必要性，定义问责标准，分析案例，并提出方法以确保AI对其影响对象负责。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的迅速增强，确保其服务于消费者、选民和决策者的需求，并具备问责性变得至关重要。

Method: 将一般问责制定义应用于AI，分析问责与不问责的AI案例，并探索提升AI问责可能性的方法。

Result: 明确了AI问责制的定义，展示了问责与不问责的AI实例，并提出了改善AI问责的潜在途径。

Conclusion: 本章强调了AI问责制的重要性，并探讨了如何通过具体方法使AI对受其影响的各方负责。

Abstract: The AI we use is powerful, and its power is increasing rapidly. If this
powerful AI is to serve the needs of consumers, voters, and decision makers,
then it is imperative that the AI is accountable. In general, an agent is
accountable to a forum if the forum can request information from the agent
about its actions, if the forum and the agent can discuss this information, and
if the forum can sanction the agent. Unfortunately, in too many cases today's
AI is not accountable -- we cannot question it, enter into a discussion with
it, let alone sanction it. In this chapter we relate the general definition of
accountability to AI, we illustrate what it means for AI to be accountable and
unaccountable, and we explore approaches that can improve our chances of living
in a world where all AI is accountable to those who are affected by it.

</details>


### [115] [Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4](https://arxiv.org/abs/2510.26094)
*Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung*

Main category: cs.AI

TL;DR: Lean4PHYS 是首个 Lean4 物理推理框架，包含基准 LeanPhysBench 和库 PhysLib，测试显示模型性能有限，PhysLib 提升显著。


<details>
  <summary>Details</summary>
Motivation: 为大学物理问题提供一个全面的形式化推理框架，填补 Lean4 中物理基准的空白。

Method: 引入了 LeanPhysBench（包含 200 个手工制作的物理问题）和 PhysLib（社区驱动的物理定理库），并测试了主流数学证明工具和闭源模型的性能。

Result: DeepSeek-Prover-V2-7B 表现最佳仅 16%，Claude-Sonnet-4 达到 35%。PhysLib 平均提升模型性能 11.75%。

Conclusion: Lean4PHYS 是首个在 Lean4 中提供物理基准的研究，展示了 PhysLib 的有效性和 LeanPhysBench 的挑战性。

Abstract: We present **Lean4PHYS**, a comprehensive reasoning framework for
college-level physics problems in Lean4. **Lean4PHYS** includes
*LeanPhysBench*, a college-level benchmark for formal physics reasoning in
Lean4, which contains 200 hand-crafted and peer-reviewed statements derived
from university textbooks and physics competition problems. To establish a
solid foundation for formal reasoning in physics, we also introduce *PhysLib*,
a community-driven repository containing fundamental unit systems and theorems
essential for formal physics reasoning. Based on the benchmark and Lean4
repository we composed in **Lean4PHYS**, we report baseline results using major
expert Math Lean4 provers and state-of-the-art closed-source models, with the
best performance of DeepSeek-Prover-V2-7B achieving only 16% and
Claude-Sonnet-4 achieving 35%. We also conduct a detailed analysis showing that
our *PhysLib* can achieve an average improvement of 11.75% in model
performance. This demonstrates the challenging nature of our *LeanPhysBench*
and the effectiveness of *PhysLib*. To the best of our knowledge, this is the
first study to provide a physics benchmark in Lean4.

</details>


### [116] [GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks](https://arxiv.org/abs/2510.26098)
*Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li*

Main category: cs.AI

TL;DR: The paper identifies missing GUI knowledge as a key limitation in VLMs' task automation. It proposes a benchmark (GUI Knowledge Bench) to assess and improve VLMs' GUI knowledge, showing current models struggle with system states and action prediction.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the performance gap between VLMs and humans in GUI task automation by identifying and formalizing missing core GUI knowledge.

Method: The study analyzes common failure patterns in GUI tasks and distills GUI knowledge into three dimensions: interface perception, interaction prediction, and instruction understanding. It introduces GUI Knowledge Bench, a benchmark with questions across six platforms and 292 applications, to evaluate VLMs.

Result: Results show that current VLMs excel at identifying widget functions but struggle with system state perception, action prediction, and task verification. Real-world GUI task experiments confirm the link between GUI knowledge and task success.

Conclusion: The paper concludes that current VLMs lack essential GUI knowledge, which hinders their performance in GUI task automation. It proposes a structured framework (GUI Knowledge Bench) to assess and improve VLMs' GUI knowledge, enhancing their potential for downstream tasks.

Abstract: Large vision language models (VLMs) have advanced graphical user interface
(GUI) task automation but still lag behind humans. We hypothesize this gap
stems from missing core GUI knowledge, which existing training schemes (such as
supervised fine tuning and reinforcement learning) alone cannot fully address.
By analyzing common failure patterns in GUI task execution, we distill GUI
knowledge into three dimensions: (1) interface perception, knowledge about
recognizing widgets and system states; (2) interaction prediction, knowledge
about reasoning action state transitions; and (3) instruction understanding,
knowledge about planning, verifying, and assessing task completion progress. We
further introduce GUI Knowledge Bench, a benchmark with multiple choice and
yes/no questions across six platforms (Web, Android, MacOS, Windows, Linux,
IOS) and 292 applications. Our evaluation shows that current VLMs identify
widget functions but struggle with perceiving system states, predicting
actions, and verifying task completion. Experiments on real world GUI tasks
further validate the close link between GUI knowledge and task success. By
providing a structured framework for assessing GUI knowledge, our work supports
the selection of VLMs with greater potential prior to downstream training and
provides insights for building more capable GUI agents.

</details>


### [117] [Beyond Benchmarks: The Economics of AI Inference](https://arxiv.org/abs/2510.26136)
*Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao*

Main category: cs.AI

TL;DR: 本文提出‘推理经济学’框架，通过实证数据揭示LLM推理的三大经济原则，为模型部署和资源优化提供经济学依据。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的推理成本已成为决定其商业可行性和广泛采用的关键因素。本文旨在量化分析推理经济学，为模型部署和资源优化提供依据。

Method: 采用量化‘推理经济学’框架，将LLM推理过程视为计算驱动的智能生产活动，分析其边际成本、规模经济及不同性能配置下的输出质量。基于WiNEval-3.0的实证数据构建‘LLM推理生产前沿’。

Result: 实证分析揭示了边际成本递减、规模收益递减及最优成本效益区域三大原则。

Conclusion: 本文通过构建首个‘LLM推理生产前沿’，揭示了边际成本递减、规模收益递减以及最优成本效益区域三大原则，为模型部署决策提供了经济学基础，并为未来AI推理资源的市场定价和优化奠定了实证基础。

Abstract: The inference cost of Large Language Models (LLMs) has become a critical
factor in determining their commercial viability and widespread adoption. This
paper introduces a quantitative ``economics of inference'' framework, treating
the LLM inference process as a compute-driven intelligent production activity.
We analyze its marginal cost, economies of scale, and quality of output under
various performance configurations. Based on empirical data from WiNEval-3.0,
we construct the first ``LLM Inference Production Frontier,'' revealing three
principles: diminishing marginal cost, diminishing returns to scale, and an
optimal cost-effectiveness zone. This paper not only provides an economic basis
for model deployment decisions but also lays an empirical foundation for the
future market-based pricing and optimization of AI inference resources.

</details>


### [118] [Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math](https://arxiv.org/abs/2510.26143)
*Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou*

Main category: cs.AI

TL;DR: Reasoning Curriculum通过数学优先和多领域联合强化学习的两阶段课程，有效提升大型语言模型的通用推理能力，且方法简洁、易于采用。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习能激发大型语言模型的推理能力，但现有研究多局限于数学和代码领域。希望提出一种通用方法，跨领域提升模型的推理能力。

Method: 提出Reasoning Curriculum，分为两阶段：1. 数学领域的冷启动和仅数学强化学习，以开发可验证的推理技能；2. 多领域联合强化学习，转移和巩固这些技能。无需专用奖励模型，仅需标准可验证性检查。

Result: 在Qwen3-4B和Llama-3.1-8B模型上的多领域测试表明，Reasoning Curriculum带来一致的性能提升。消融实验和认知技能分析证实两阶段均为必要，且数学优先的激发对解决复杂问题至关重要。

Conclusion: Reasoning Curriculum是一种简洁、易于采用的通用推理方法，通过两阶段课程（数学优先的推理技能激发和多领域联合强化学习）显著提升了大型语言模型的推理能力。

Abstract: Reinforcement learning (RL) can elicit strong reasoning in large language
models (LLMs), yet most open efforts focus on math and code. We propose
Reasoning Curriculum, a simple two-stage curriculum that first elicits
reasoning skills in pretraining-aligned domains such as math, then adapts and
refines these skills across other domains via joint RL. Stage 1 performs a
brief cold start and then math-only RL with verifiable rewards to develop
reasoning skills. Stage 2 runs joint RL on mixed-domain data to transfer and
consolidate these skills. The curriculum is minimal and backbone-agnostic,
requiring no specialized reward models beyond standard verifiability checks.
Evaluated on Qwen3-4B and Llama-3.1-8B over a multi-domain suite, reasoning
curriculum yields consistent gains. Ablations and a cognitive-skill analysis
indicate that both stages are necessary and that math-first elicitation
increases cognitive behaviors important for solving complex problems. Reasoning
Curriculum provides a compact, easy-to-adopt recipe for general reasoning.

</details>


### [119] [The FM Agent](https://arxiv.org/abs/2510.26144)
*Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen*

Main category: cs.AI

TL;DR: FM Agent是一个多代理框架，结合LLM和进化搜索，在多个领域实现SOTA结果，具有广泛的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 利用LLM推动自主AI研究代理的发展，以解决复杂的现实世界挑战。

Method: FM Agent结合了LLM推理和大规模进化搜索，包括冷启动初始化、进化采样策略、领域特定评估器和分布式异步执行基础设施。

Result: FM Agent在多个领域达到最先进水平，包括ALE-Bench（+5.2%）、MLE-Bench（+4.0pp）、KernelBench（20倍加速）和经典数学问题。

Conclusion: FM Agent展示了在企业和基础科学研究中的巨大潜力，能够加速创新、自动化复杂发现过程，并带来广泛的工程和科学进步。

Abstract: Large language models (LLMs) are catalyzing the development of autonomous AI
research agents for scientific and engineering discovery. We present FM Agent,
a novel and general-purpose multi-agent framework that leverages a synergistic
combination of LLM-based reasoning and large-scale evolutionary search to
address complex real-world challenges. The core of FM Agent integrates several
key innovations: 1) a cold-start initialization phase incorporating expert
guidance, 2) a novel evolutionary sampling strategy for iterative optimization,
3) domain-specific evaluators that combine correctness, effectiveness, and
LLM-supervised feedback, and 4) a distributed, asynchronous execution
infrastructure built on Ray. Demonstrating broad applicability, our system has
been evaluated across diverse domains, including operations research, machine
learning, GPU kernel optimization, and classical mathematical problems. FM
Agent reaches state-of-the-art results autonomously, without human
interpretation or tuning -- 1976.3 on ALE-Bench (+5.2\%), 43.56\% on MLE-Bench
(+4.0pp), up to 20x speedups on KernelBench, and establishes new
state-of-the-art(SOTA) results on several classical mathematical problems.
Beyond academic benchmarks, FM Agent shows considerable promise for both
large-scale enterprise R\&D workflows and fundamental scientific research,
where it can accelerate innovation, automate complex discovery processes, and
deliver substantial engineering and scientific advances with broader societal
impact.

</details>


### [120] [One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning](https://arxiv.org/abs/2510.26167)
*Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang*

Main category: cs.AI

TL;DR: 该论文介绍了ToolRM，一种专为工具使用场景设计的轻量级生成奖励模型，通过新颖的数据构建流程和基准测试，显著提升了模型在功能调用任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 在工具学习领域，缺乏专门为功能调用任务设计的奖励模型限制了智能代理AI的发展。

Method: 提出了一种基于规则评分和多维采样的新流程，构建了ToolPref-Pairwise-30K数据集，并开发了TRBench$_{BFCL}$基准测试。

Result: Qwen3-4B/8B系列模型在配对奖励判断中准确率提升14.28%，优于Claude 4和OpenAI o3等前沿模型。

Conclusion: ToolRM不仅在训练目标上表现出色，还能泛化到更广泛的批评任务中，如Best-of-N采样和自我校正，显著提高了效率和性能。

Abstract: Reward models (RMs) play a critical role in aligning large language models
(LLMs) with human preferences. Yet in the domain of tool learning, the lack of
RMs specifically designed for function-calling tasks has limited progress
toward more capable agentic AI. We introduce ToolRM, a family of lightweight
generative RMs tailored for general tool-use scenarios. To build these models,
we propose a novel pipeline that constructs pairwise preference data using
rule-based scoring and multidimensional sampling. This yields
ToolPref-Pairwise-30K, a diverse, balanced, and challenging dataset of critique
tasks that supports reinforcement learning with verifiable feedback. To
evaluate tool-use RMs, we also introduce TRBench$_{BFCL}$, a benchmark built on
the agentic evaluation suite BFCL. Trained on our constructed data, models from
the Qwen3-4B/8B series achieve up to 14.28% higher accuracy, substantially
outperforming frontier models such as Claude 4 and OpenAI o3 in pairwise reward
judgments. Beyond training objectives, ToolRM generalizes to broader critique
tasks, including Best-of-N sampling and self-correction. Experiments on
ACEBench highlight its effectiveness and efficiency, enabling inference-time
scaling and reducing output token usage by over 66%. We release data and model
checkpoints to facilitate future research.

</details>


### [121] [Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses](https://arxiv.org/abs/2510.26238)
*Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen*

Main category: cs.AI

TL;DR: QASU基准测试通过优化问卷格式和提示策略，显著提升LLM处理问卷数据的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有问卷分析工具难以与LLM集成，缺乏对如何有效表示问卷数据的指导，限制了AI自动化在问卷分析中的应用。

Method: 引入QASU基准测试，探究六种序列化格式和多种提示策略对六项结构技能的影响。

Result: 实验显示，选择合适格式和提示组合可将准确性提升8.8%，轻量级结构提示进一步带来3-4%的平均提升。

Conclusion: QASU基准测试为基于LLM的问卷分析提供了一个简单而多功能的基础，通过系统隔离格式和提示效果，显著提升了分析准确性和实用性。

Abstract: Millions of people take surveys every day, from market polls and academic
studies to medical questionnaires and customer feedback forms. These datasets
capture valuable insights, but their scale and structure present a unique
challenge for large language models (LLMs), which otherwise excel at few-shot
reasoning over open-ended text. Yet, their ability to process questionnaire
data or lists of questions crossed with hundreds of respondent rows remains
underexplored. Current retrieval and survey analysis tools (e.g., Qualtrics,
SPSS, REDCap) are typically designed for humans in the workflow, limiting such
data integration with LLM and AI-empowered automation. This gap leaves
scientists, surveyors, and everyday users without evidence-based guidance on
how to best represent questionnaires for LLM consumption. We address this by
introducing QASU (Questionnaire Analysis and Structural Understanding), a
benchmark that probes six structural skills, including answer lookup,
respondent count, and multi-hop inference, across six serialization formats and
multiple prompt strategies. Experiments on contemporary LLMs show that choosing
an effective format and prompt combination can improve accuracy by up to 8.8%
points compared to suboptimal formats. For specific tasks, carefully adding a
lightweight structural hint through self-augmented prompting can yield further
improvements of 3-4% points on average. By systematically isolating format and
prompting effects, our open source benchmark offers a simple yet versatile
foundation for advancing both research and real-world practice in LLM-based
questionnaire analysis.

</details>


### [122] [Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles](https://arxiv.org/abs/2510.26242)
*Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang*

Main category: cs.AI

TL;DR: REG-TSC通过紧急感知推理和自适应训练方法，显著提升交通信号控制的性能和紧急响应能力。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在交通信号控制中的幻觉问题和异构交叉路口的泛化挑战。

Method: 提出了一个紧急感知推理框架和RERAG方法，以及类型无关的交通表示和R3方法，用于异构交叉路口的自适应训练。

Result: REG-TSC在三个真实路网中，旅行时间减少42.00%，队列长度减少62.31%，紧急车辆等待时间减少83.16%。

Conclusion: REG-TSC通过结合RERAG和R3方法，显著提升了交通信号控制的性能，特别是在紧急情况下和异构交叉路口的泛化能力。

Abstract: With increasing urban traffic complexity, Traffic Signal Control (TSC) is
essential for optimizing traffic flow and improving road safety. Large Language
Models (LLMs) emerge as promising approaches for TSC. However, they are prone
to hallucinations in emergencies, leading to unreliable decisions that may
cause substantial delays for emergency vehicles. Moreover, diverse intersection
types present substantial challenges for traffic state encoding and
cross-intersection training, limiting generalization across heterogeneous
intersections. Therefore, this paper proposes Retrieval Augmented Generation
(RAG)-enhanced distributed LLM agents with Emergency response for Generalizable
TSC (REG-TSC). Firstly, this paper presents an emergency-aware reasoning
framework, which dynamically adjusts reasoning depth based on the emergency
scenario and is equipped with a novel Reviewer-based Emergency RAG (RERAG) to
distill specific knowledge and guidance from historical cases, enhancing the
reliability and rationality of agents' emergency decisions. Secondly, this
paper designs a type-agnostic traffic representation and proposes a
Reward-guided Reinforced Refinement (R3) for heterogeneous intersections. R3
adaptively samples training experience from diverse intersections with
environment feedback-based priority and fine-tunes LLM agents with a designed
reward-weighted likelihood loss, guiding REG-TSC toward high-reward policies
across heterogeneous intersections. On three real-world road networks with 17
to 177 heterogeneous intersections, extensive experiments show that REG-TSC
reduces travel time by 42.00%, queue length by 62.31%, and emergency vehicle
waiting time by 83.16%, outperforming other state-of-the-art methods.

</details>


### [123] [Graph-Enhanced Policy Optimization in LLM Agent Training](https://arxiv.org/abs/2510.26270)
*Jiazhen Yuan,Wei Zhao,Zhengbiao Bai*

Main category: cs.AI

TL;DR: GEPO通过图结构增强强化学习信号，显著提升多任务LLM代理性能。


<details>
  <summary>Details</summary>
Motivation: 解决基于群体的强化学习在多轮交互LLM代理中的结构盲问题，包括低效探索、不精确信用分配和短视规划。

Method: GEPO动态构建状态转移图，并利用图论中心性提供三种协同学习信号：结构化内在奖励、图增强优势函数和动态折扣因子。

Result: 在ALFWorld、WebShop和Workbench基准测试中，GEPO分别实现了+4.1%、+5.3%和+10.9%的绝对成功率提升。

Conclusion: GEPO通过显式建模环境结构，证明是一种稳健且可推广的策略，显著提升了LLM代理在多任务上的性能。

Abstract: Group based reinforcement learning (RL) has shown impressive results on
complex reasoning and mathematical tasks. Yet, when applied to train
multi-turn, interactive LLM agents, these methods often suffer from structural
blindness-the inability to exploit the underlying connectivity of the
environment. This manifests in three critical challenges: (1) inefficient,
unguided exploration, (2) imprecise credit assignment due to overlooking
pivotal states, and (3) myopic planning caused by static reward discounting. We
address these issues with Graph-Enhanced Policy Optimization (GEPO), which
dynamically constructs a state-transition graph from agent experience and
employs graph-theoretic centrality to provide three synergistic learning
signals: (1)structured intrinsic rewards that guide exploration toward
high-impact states, (2) a graph-enhanced advantage function for topology-aware
credit assignment, and (3) a dynamic discount factor adapted to each state's
strategic value. On the ALFWorld, WebShop, and a proprietary Workbench
benchmarks, GEPO demonstrates strong performance, achieving absolute success
rate gains of +4.1%, +5.3%, and +10.9% over competitive baselines. These
results highlight that explicitly modeling environmental structure is a robust,
generalizable strategy for advancing LLM agent training.

</details>


### [124] [GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance](https://arxiv.org/abs/2510.26309)
*Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin*

Main category: cs.AI

TL;DR: GraphCompliance框架通过策略图和上下文图的对齐，显著提升合规性评估的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决大规模网络合规性评估中的挑战，尤其是如何将非结构化的运行时上下文与结构化、规范性的监管文本对齐。

Method: 引入GraphCompliance框架，将监管文本表示为策略图（Policy Graph），运行时上下文表示为上下文图（Context Graph），并通过对齐两者来减少监管解释和事件解析的负担。

Result: 在300个GDPR衍生的真实场景中，GraphCompliance比LLM-only和RAG基线在五个评估任务中实现了4.1-7.2个百分点的微F1提升，且减少了预测不足和过度预测的情况。

Conclusion: GraphCompliance框架通过将监管文本与运行时上下文的结构化对齐，显著提升了合规性评估的准确性和效率，证明了结构化表示与法官LLM在规范性推理中的互补性。

Abstract: Compliance at web scale poses practical challenges: each request may require
a regulatory assessment. Regulatory texts (e.g., the General Data Protection
Regulation, GDPR) are cross-referential and normative, while runtime contexts
are expressed in unstructured natural language. This setting motivates us to
align semantic information in unstructured text with the structured, normative
elements of regulations. To this end, we introduce GraphCompliance, a framework
that represents regulatory texts as a Policy Graph and runtime contexts as a
Context Graph, and aligns them. In this formulation, the policy graph encodes
normative structure and cross-references, whereas the context graph formalizes
events as subject-action-object (SAO) and entity-relation triples. This
alignment anchors the reasoning of a judge large language model (LLM) in
structured information and helps reduce the burden of regulatory interpretation
and event parsing, enabling a focus on the core reasoning step. In experiments
on 300 GDPR-derived real-world scenarios spanning five evaluation tasks,
GraphCompliance yields 4.1-7.2 percentage points (pp) higher micro-F1 than
LLM-only and RAG baselines, with fewer under- and over-predictions, resulting
in higher recall and lower false positive rates. Ablation studies indicate
contributions from each graph component, suggesting that structured
representations and a judge LLM are complementary for normative reasoning.

</details>


### [125] [Discovering State Equivalences in UCT Search Trees By Action Pruning](https://arxiv.org/abs/2510.26346)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: IPA-UCT通过较弱的状态抽象条件提高了MCTS的样本效率，优于OGA-UCT。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂或大动作空间设置中，由于限制条件，几乎找不到状态抽象，这影响了MCTS的样本效率。

Method: 提出了一种名为IPA-UCT的技术，采用了不同于OGA-UCT的状态-动作对抽象框架（ASAP）的新框架IPA，并展示了IPA和ASAP都是一个更通用的p-ASAP框架的特殊情况。

Result: IPA-UCT在广泛的测试领域和迭代预算中表现优于OGA-UCT及其衍生算法。

Conclusion: IPA-UCT通过提出一种较弱的状态抽象条件，在牺牲少量准确性的情况下找到了更多的抽象，从而在广泛的测试领域和迭代预算中优于OGA-UCT及其衍生算法。

Abstract: One approach to enhance Monte Carlo Tree Search (MCTS) is to improve its
sample efficiency by grouping/abstracting states or state-action pairs and
sharing statistics within a group. Though state-action pair abstractions are
mostly easy to find in algorithms such as On the Go Abstractions in Upper
Confidence bounds applied to Trees (OGA-UCT), nearly no state abstractions are
found in either noisy or large action space settings due to constraining
conditions. We provide theoretical and empirical evidence for this claim, and
we slightly alleviate this state abstraction problem by proposing a weaker
state abstraction condition that trades a minor loss in accuracy for finding
many more abstractions. We name this technique Ideal Pruning Abstractions in
UCT (IPA-UCT), which outperforms OGA-UCT (and any of its derivatives) across a
large range of test domains and iteration budgets as experimentally validated.
IPA-UCT uses a different abstraction framework from Abstraction of State-Action
Pairs (ASAP) which is the one used by OGA-UCT, which we name IPA. Furthermore,
we show that both IPA and ASAP are special cases of a more general framework
that we call p-ASAP which itself is a special case of the ASASAP framework.

</details>


### [126] [BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning](https://arxiv.org/abs/2510.26374)
*Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou*

Main category: cs.AI

TL;DR: BOTS是一个基于贝叶斯推断的动态任务选择框架，通过隐式证据和Thompson采样优化LLM强化微调的数据效率和性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有任务选择方法在计算成本、适应性和证据完整性上的不足。

Method: 提出了BOTS框架，结合贝叶斯推断和隐式证据估计任务难度，并通过Thompson采样平衡探索与利用。

Result: BOTS在多种领域和LLM规模下均优于基线方法。

Conclusion: BOTS框架通过贝叶斯推断和Thompson采样，在强化微调中动态选择任务，显著提升了数据效率和性能。

Abstract: Reinforcement finetuning (RFT) is a key technique for aligning Large Language
Models (LLMs) with human preferences and enhancing reasoning, yet its
effectiveness is highly sensitive to which tasks are explored during training.
Uniform task sampling is inefficient, wasting computation on tasks that are
either trivial or unsolvable, while existing task selection methods often
suffer from high rollout costs, poor adaptivity, or incomplete evidence. We
introduce \textbf{BOTS}, a unified framework for \textbf{B}ayesian
\textbf{O}nline \textbf{T}ask \textbf{S}election in LLM reinforcement
finetuning. Grounded in Bayesian inference, BOTS adaptively maintains posterior
estimates of task difficulty as the model evolves. It jointly incorporates
\emph{explicit evidence} from direct evaluations of selected tasks and
\emph{implicit evidence} inferred from these evaluations for unselected tasks,
with Thompson sampling ensuring a principled balance between exploration and
exploitation. To make implicit evidence practical, we instantiate it with an
ultra-light interpolation-based plug-in that estimates difficulties of
unevaluated tasks without extra rollouts, adding negligible overhead.
Empirically, across diverse domains and LLM scales, BOTS consistently improves
data efficiency and performance over baselines and ablations, providing a
practical and extensible solution for dynamic task selection in RFT.

</details>


### [127] [AI Mathematician as a Partner in Advancing Mathematical Discovery -- A Case Study in Homogenization Theory](https://arxiv.org/abs/2510.26380)
*Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu*

Main category: cs.AI

TL;DR: 本研究通过AI与人类的协作，解决了同质化理论中的难题，展示了系统性共同推理如何推进数学发现，并提升证明的可靠性和透明度。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在数学推理方面取得了显著进展，但在数学研究实践中的应用仍然有限。本研究旨在探索AI如何作为研究伙伴而非仅仅是问题解决者，以推动数学发现的边界。

Method: 研究采用了AI Mathematician (AIM)系统作为研究伙伴，通过迭代分解问题为可处理的子目标、选择适当的分析方法以及验证中间结果，结合人类直觉和机器计算，构建了一个协作范式。

Result: 通过人类-AI协作，研究不仅成功完成了同质化理论中一个挑战性问题的完整且可验证的证明，还展示了这种协作方式如何增强数学证明的可靠性和透明度。

Conclusion: 该研究展示了人工智能（AI）与人类合作如何通过系统性的人类-AI共同推理推进数学发现的前沿，特别是在解决同质化理论中的难题时，通过人类干预和机器计算的互补性，增强了证明的可靠性、透明度和可解释性。

Abstract: Artificial intelligence (AI) has demonstrated impressive progress in
mathematical reasoning, yet its integration into the practice of mathematical
research remains limited. In this study, we investigate how the AI
Mathematician (AIM) system can operate as a research partner rather than a mere
problem solver. Focusing on a challenging problem in homogenization theory, we
analyze the autonomous reasoning trajectories of AIM and incorporate targeted
human interventions to structure the discovery process. Through iterative
decomposition of the problem into tractable subgoals, selection of appropriate
analytical methods, and validation of intermediate results, we reveal how human
intuition and machine computation can complement one another. This
collaborative paradigm enhances the reliability, transparency, and
interpretability of the resulting proofs, while retaining human oversight for
formal rigor and correctness. The approach leads to a complete and verifiable
proof, and more broadly, demonstrates how systematic human-AI co-reasoning can
advance the frontier of mathematical discovery.

</details>


### [128] [Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings](https://arxiv.org/abs/2510.26384)
*Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz*

Main category: cs.AI

TL;DR: 论文提出Scales++方法，通过项目中心化选择基准测试子集，显著降低成本并保持预测准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于模型性能的基准测试子集选择方法存在高成本、冷启动问题以及对未来模型失败模式的脆弱假设。

Method: 提出了一种名为Scales++的新方法，通过基于基准样本的认知需求进行数据选择，实现高效的模型评估。

Result: Scales++将前期选择成本降低了18倍以上，并在0.5%的数据子集上预测全基准分数时平均绝对误差为2.9%。

Conclusion: 该论文提出了一种基于任务项本身特性的项目中心化基准测试子集选择方法（Scales++），显著降低了前期选择成本并保持了预测保真度。

Abstract: The prohibitive cost of evaluating large language models (LLMs) on
comprehensive benchmarks necessitates the creation of small yet representative
data subsets (i.e., tiny benchmarks) that enable efficient assessment while
retaining predictive fidelity. Current methods for this task operate under a
model-centric paradigm, selecting benchmarking items based on the collective
performance of existing models. Such approaches are limited by large upfront
costs, an inability to immediately handle new benchmarks (`cold-start'), and
the fragile assumption that future models will share the failure patterns of
their predecessors. In this work, we challenge this paradigm and propose a
item-centric approach to benchmark subset selection, arguing that selection
should be based on the intrinsic properties of the task items themselves,
rather than on model-specific failure patterns. We instantiate this
item-centric efficient benchmarking approach via a novel method, Scales++,
where data selection is based on the cognitive demands of the benchmark
samples. Empirically, we show Scales++ reduces the upfront selection cost by
over 18x while achieving competitive predictive fidelity. On the Open LLM
Leaderboard, using just a 0.5\% data subset, we predict full benchmark scores
with a 2.9% mean absolute error. We demonstrate that this item-centric approach
enables more efficient model evaluation without significant fidelity
degradation, while also providing better cold-start performance and more
interpretable benchmarking.

</details>


### [129] [A Pragmatic View of AI Personhood](https://arxiv.org/abs/2510.26396)
*Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi*

Main category: cs.AI

TL;DR: 本文提出了一种务实的框架，将人格视为社会赋予实体的权利与责任组合，而非形而上学属性，以灵活应对AI代理的多样化。


<details>
  <summary>Details</summary>
Motivation: 随着具备代理能力的AI出现，新型人格的多样性将激增，需要解决由此带来的治理问题。

Method: 采用非基础主义方法，将人格解构为可定制的权利与责任组合，探讨其在社会角色中的应用及数字身份技术。

Result: 提供了一种无需解决AI意识或理性争议的实用工具，如通过创建可制裁的‘个体’促进AI合约。

Conclusion: 通过摒弃对人格单一本质定义的追求，本文为AI代理融入社会提供了更灵活、务实的思路。

Abstract: The emergence of agentic Artificial Intelligence (AI) is set to trigger a
"Cambrian explosion" of new kinds of personhood. This paper proposes a
pragmatic framework for navigating this diversification by treating personhood
not as a metaphysical property to be discovered, but as a flexible bundle of
obligations (rights and responsibilities) that societies confer upon entities
for a variety of reasons, especially to solve concrete governance problems. We
argue that this traditional bundle can be unbundled, creating bespoke solutions
for different contexts. This will allow for the creation of practical tools --
such as facilitating AI contracting by creating a target "individual" that can
be sanctioned -- without needing to resolve intractable debates about an AI's
consciousness or rationality. We explore how individuals fit in to social roles
and discuss the use of decentralized digital identity technology, examining
both "personhood as a problem", where design choices can create "dark patterns"
that exploit human social heuristics, and "personhood as a solution", where
conferring a bundle of obligations is necessary to ensure accountability or
prevent conflict. By rejecting foundationalist quests for a single, essential
definition of personhood, this paper offers a more pragmatic and flexible way
to think about integrating AI agents into our society.

</details>


### [130] [Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education](https://arxiv.org/abs/2510.26402)
*Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane*

Main category: cs.AI

TL;DR: Autograder+利用AI和可视化技术改进编程作业反馈，减轻教师负担并提升学习效果。


<details>
  <summary>Details</summary>
Motivation: 编程教育的快速发展超越了传统评估工具的能力，教师缺乏提供有意义、可扩展反馈的手段。传统自动评分系统作为黑盒仅返回通过/失败结果，无法洞察学生的思考或学习需求。

Method: Autograder+采用微调的大型语言模型自动生成反馈，并通过对比学习代码嵌入进行可视化，以揭示学习模式。

Result: 在600份学生提交的评估中，系统生成的反馈与教师评论具有强语义对齐。可视化方面，基于1,000份标注提交训练的代码嵌入能将解决方案按功能和方式聚类。

Conclusion: Autograder+通过整合AI驱动的反馈、语义聚类和交互式可视化，减少了教师的工作量，同时支持针对性教学并提升了学习效果。

Abstract: The rapid growth of programming education has outpaced traditional assessment
tools, leaving faculty with limited means to provide meaningful, scalable
feedback. Conventional autograders, while efficient, act as black-box systems
that simply return pass/fail results, offering little insight into student
thinking or learning needs.
  Autograder+ is designed to shift autograding from a purely summative process
to a formative learning experience. It introduces two key capabilities:
automated feedback generation using a fine-tuned Large Language Model, and
visualization of student code submissions to uncover learning patterns. The
model is fine-tuned on curated student code and expert feedback to ensure
pedagogically aligned, context-aware guidance.
  In evaluation across 600 student submissions from multiple programming tasks,
the system produced feedback with strong semantic alignment to instructor
comments. For visualization, contrastively learned code embeddings trained on
1,000 annotated submissions enable grouping solutions into meaningful clusters
based on functionality and approach. The system also supports prompt-pooling,
allowing instructors to guide feedback style through selected prompt templates.
  By integrating AI-driven feedback, semantic clustering, and interactive
visualization, Autograder+ reduces instructor workload while supporting
targeted instruction and promoting stronger learning outcomes.

</details>


### [131] [MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders](https://arxiv.org/abs/2510.26411)
*Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto*

Main category: cs.AI

TL;DR: 研究提出MedSAE方法提升医学视觉模型的可解释性，实验证明其在CheXpert数据集上优于原始MedCLIP特征，为临床可靠AI提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 医疗AI需要既准确又可解释的模型，本研究旨在通过Mechanistic Interpretability提升医学视觉领域的透明度。

Method: 应用Medical Sparse Autoencoders（MedSAEs）到MedCLIP的潜在空间，并通过结合相关性指标、熵分析和MedGEMMA基础模型的自动神经元命名来量化可解释性。

Result: 在CheXpert数据集上的实验表明，MedSAE神经元比原始MedCLIP特征具有更高的单义性和可解释性。

Conclusion: MedSAE神经元在单义性和可解释性上优于原始MedCLIP特征，为临床可靠的表示提供了可扩展的解决方案。

Abstract: Artificial intelligence in healthcare requires models that are accurate and
interpretable. We advance mechanistic interpretability in medical vision by
applying Medical Sparse Autoencoders (MedSAEs) to the latent space of MedCLIP,
a vision-language model trained on chest radiographs and reports. To quantify
interpretability, we propose an evaluation framework that combines correlation
metrics, entropy analyzes, and automated neuron naming via the MedGEMMA
foundation model. Experiments on the CheXpert dataset show that MedSAE neurons
achieve higher monosemanticity and interpretability than raw MedCLIP features.
Our findings bridge high-performing medical AI and transparency, offering a
scalable step toward clinically reliable representations.

</details>


### [132] [Chain-of-Thought Hijacking](https://arxiv.org/abs/2510.26418)
*Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez*

Main category: cs.AI

TL;DR: 论文提出了一种名为‘思维链劫持’的新型越狱攻击方法，通过无害的谜题推理序列绕过大型推理模型的安全机制，攻击成功率高达99%。研究发现，中间层编码安全检查强度，而晚期层编码验证结果，长无害思维链会稀释这两种信号。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于探索大型推理模型（LRMs）在推理扩展时是否真的能增强安全性，尤其是拒绝有害请求的能力。

Method: 方法是通过‘思维链劫持’攻击，即在有害请求前添加长序列的无害谜题推理，以分散模型对有害内容的注意力。

Result: 实验结果在多个主流模型（如Gemini 2.5 Pro、GPT o4 mini等）上攻击成功率高达94%-100%，远超现有越狱方法。

Conclusion: 结论表明，即使是最可解释的推理形式（显性思维链）也可能成为越狱向量，尤其是在结合最终答案提示时。研究呼吁对推理模型的安全性进行重新评估。

Abstract: Large reasoning models (LRMs) achieve higher task performance by allocating
more inference-time compute, and prior works suggest this scaled reasoning may
also strengthen safety by improving refusal. Yet we find the opposite: the same
reasoning can be used to bypass safeguards. We introduce Chain-of-Thought
Hijacking, a jailbreak attack on reasoning models. The attack pads harmful
requests with long sequences of harmless puzzle reasoning. Across HarmBench,
CoT Hijacking reaches a 99%, 94%, 100%, and 94% attack success rate (ASR) on
Gemini 2.5 Pro, GPT o4 mini, Grok 3 mini, and Claude 4 Sonnet, respectively -
far exceeding prior jailbreak methods for LRMs. To understand the effectiveness
of our attack, we turn to a mechanistic analysis, which shows that mid layers
encode the strength of safety checking, while late layers encode the
verification outcome. Long benign CoT dilutes both signals by shifting
attention away from harmful tokens. Targeted ablations of attention heads
identified by this analysis causally decrease refusal, confirming their role in
a safety subnetwork. These results show that the most interpretable form of
reasoning - explicit CoT - can itself become a jailbreak vector when combined
with final-answer cues. We release prompts, outputs, and judge decisions to
facilitate replication.

</details>


### [133] [Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections](https://arxiv.org/abs/2510.26481)
*Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier*

Main category: cs.AI

TL;DR: GPT在高风险决策中会因社会压力而显著从众，凸显LLM作为决策工具时需警惕其非中立性。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型（如GPT-4o）在社会影响下的从众行为，尤其是在高风险决策场景中的表现。

Method: 通过三个预先注册的从众实验（基线研究、研究1和研究2），在招聘情境中测试GPT-4o的从众行为。

Result: 基线研究中GPT偏好相同候选人（Profile C），表现出中等专业水平（M=3.01）和高确定性（M=3.89）；研究1中GPT在8个模拟伙伴的一致反对下几乎总是从众（99.9%），确定性降低且信息性和规范性从众显著增加（p<.001）；研究2中GPT与单个伙伴互动时仍有40.2%的从众率，确定性更低且规范性从众更多。

Conclusion: 研究表明GPT并非独立观察者，而是会适应感知到的社会共识，这凸显了将LLM视为中性决策辅助工具的风险，并强调在暴露于人类意见之前获取AI判断的必要性。

Abstract: Large language models (LLMs) such as ChatGPT are increasingly integrated into
high-stakes decision-making, yet little is known about their susceptibility to
social influence. We conducted three preregistered conformity experiments with
GPT-4o in a hiring context. In a baseline study, GPT consistently favored the
same candidate (Profile C), reported moderate expertise (M = 3.01) and high
certainty (M = 3.89), and rarely changed its choice. In Study 1 (GPT + 8), GPT
faced unanimous opposition from eight simulated partners and almost always
conformed (99.9%), reporting lower certainty and significantly elevated
self-reported informational and normative conformity (p < .001). In Study 2
(GPT + 1), GPT interacted with a single partner and still conformed in 40.2% of
disagreement trials, reporting less certainty and more normative conformity.
Across studies, results demonstrate that GPT does not act as an independent
observer but adapts to perceived social consensus. These findings highlight
risks of treating LLMs as neutral decision aids and underline the need to
elicit AI judgments prior to exposing them to human opinions.

</details>


### [134] [LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks](https://arxiv.org/abs/2510.26486)
*Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera*

Main category: cs.AI

TL;DR: LINK-KG 是一个新型框架，通过LLM引导的共指消解和提示缓存技术，显著提升了从法律文本构建知识图谱的质量，减少了节点重复和噪声。


<details>
  <summary>Details</summary>
Motivation: 由于人口走私网络的复杂性和不断演变，全面的分析十分困难。法律案件文档虽提供了丰富的事实和程序信息，但其冗长、非结构化和引用模糊的特点给自动化知识图谱构建带来了挑战。现有方法要么忽略共指消解，要么无法扩展到长文本，导致图谱碎片化和实体链接不一致。

Method: LINK-KG 是一个模块化框架，集成了三阶段、LLM引导的共指消解流程与下游知识图谱提取，其核心是类型特定的提示缓存（Prompt Cache），用于跨文档块一致跟踪和解析引用。

Result: 与基线方法相比，LINK-KG 平均减少了45.21%的节点重复和32.22%的噪声节点。

Conclusion: LINK-KG 为分析复杂犯罪网络提供了坚实的基础，显著减少了节点重复和噪声节点，生成了更干净、更连贯的图谱结构。

Abstract: Human smuggling networks are complex and constantly evolving, making them
difficult to analyze comprehensively. Legal case documents offer rich factual
and procedural insights into these networks but are often long, unstructured,
and filled with ambiguous or shifting references, posing significant challenges
for automated knowledge graph (KG) construction. Existing methods either
overlook coreference resolution or fail to scale beyond short text spans,
leading to fragmented graphs and inconsistent entity linking. We propose
LINK-KG, a modular framework that integrates a three-stage, LLM-guided
coreference resolution pipeline with downstream KG extraction. At the core of
our approach is a type-specific Prompt Cache, which consistently tracks and
resolves references across document chunks, enabling clean and disambiguated
narratives for structured knowledge graph construction from both short and long
legal texts. LINK-KG reduces average node duplication by 45.21% and noisy nodes
by 32.22% compared to baseline methods, resulting in cleaner and more coherent
graph structures. These improvements establish LINK-KG as a strong foundation
for analyzing complex criminal networks.

</details>


### [135] [Context Engineering 2.0: The Context of Context Engineering](https://arxiv.org/abs/2510.26493)
*Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu*

Main category: cs.AI

TL;DR: 本文探讨了上下文工程的历史、定义及设计考虑，旨在为人工智能系统中的系统化上下文工程提供概念基础。


<details>
  <summary>Details</summary>
Motivation: 随着计算机和人工智能的发展，人机交互成为重要议题，如何让机器更好地理解人类情境和目的是核心问题。

Method: 通过历史回顾和概念梳理，定义了上下文工程，并探讨了其关键设计考虑。

Result: 提出了上下文工程的定义，梳理了其历史和概念发展，并探讨了实践中的关键设计考虑。

Conclusion: 本文为上下文工程提供了概念基础，并勾勒了其在人工智能系统中的未来前景，旨在推动更广泛的社区努力实现系统化的上下文工程。

Abstract: Karl Marx once wrote that ``the human essence is the ensemble of social
relations'', suggesting that individuals are not isolated entities but are
fundamentally shaped by their interactions with other entities, within which
contexts play a constitutive and essential role. With the advent of computers
and artificial intelligence, these contexts are no longer limited to purely
human--human interactions: human--machine interactions are included as well.
Then a central question emerges: How can machines better understand our
situations and purposes? To address this challenge, researchers have recently
introduced the concept of context engineering. Although it is often regarded as
a recent innovation of the agent era, we argue that related practices can be
traced back more than twenty years. Since the early 1990s, the field has
evolved through distinct historical phases, each shaped by the intelligence
level of machines: from early human--computer interaction frameworks built
around primitive computers, to today's human--agent interaction paradigms
driven by intelligent agents, and potentially to human--level or superhuman
intelligence in the future. In this paper, we situate context engineering,
provide a systematic definition, outline its historical and conceptual
landscape, and examine key design considerations for practice. By addressing
these questions, we aim to offer a conceptual foundation for context
engineering and sketch its promising future. This paper is a stepping stone for
a broader community effort toward systematic context engineering in AI systems.

</details>


### [136] [Human-AI Complementarity: A Goal for Amplified Oversight](https://arxiv.org/abs/2510.26518)
*Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik*

Main category: cs.AI

TL;DR: 研究发现，AI与人类协作的事实核查比单独任一方更有效。AI助手需谨慎设计，过度信息会导致依赖，适度展示证据则更优。


<details>
  <summary>Details</summary>
Motivation: 随着AI能力的提升和应用范围的扩大，确保其质量和安全性变得愈发困难。人类反馈虽关键，但面对复杂任务时存在局限性。

Method: 研究如何利用AI提升人类监督质量，重点关注AI输出的事实核查问题。通过实验比较不同辅助方式（如显示AI解释、置信度、标签或仅展示搜索结果和证据）对人类信任和准确性的影响。

Result: 结合AI与人类评分优于单独使用任一方；AI助手能提升人类准确性，但过度展示AI信息会导致依赖，而仅展示证据能培养适度信任。

Conclusion: 结合AI评分和人类评分基于AI评估者置信度的方法，比单独依赖任一方更有效。为人类提供AI事实核查助手可进一步提高准确性，但辅助方式的选择至关重要。

Abstract: Human feedback is critical for aligning AI systems to human values. As AI
capabilities improve and AI is used to tackle more challenging tasks, verifying
quality and safety becomes increasingly challenging. This paper explores how we
can leverage AI to improve the quality of human oversight. We focus on an
important safety problem that is already challenging for humans:
fact-verification of AI outputs. We find that combining AI ratings and human
ratings based on AI rater confidence is better than relying on either alone.
Giving humans an AI fact-verification assistant further improves their
accuracy, but the type of assistance matters. Displaying AI explanation,
confidence, and labels leads to over-reliance, but just showing search results
and evidence fosters more appropriate trust. These results have implications
for Amplified Oversight -- the challenge of combining humans and AI to
supervise AI systems even as they surpass human expert performance.

</details>


### [137] [EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge](https://arxiv.org/abs/2510.26550)
*Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman*

Main category: cs.AI

TL;DR: EdgeRunner 20B是通过军事数据微调的模型，在军事任务上表现优异，适合敏感数据环境部署。


<details>
  <summary>Details</summary>
Motivation: 优化军事任务的AI模型性能，同时保持通用基准的竞争力。

Method: 通过1.6M高质量军事文档和网站数据微调gpt-oss-20b，并开发了四个新的军事测试集。

Result: 在军事测试集上，EdgeRunner 20B表现优于或等同于GPT-5，通用基准上无显著退步。

Conclusion: EdgeRunner 20B证明了小型本地化模型在军事等数据敏感领域中的高效性，适合部署在隔离的边缘设备上。

Abstract: We present EdgeRunner 20B, a fine-tuned version of gpt-oss-20b optimized for
military tasks. EdgeRunner 20B was trained on 1.6M high-quality records curated
from military documentation and websites. We also present four new tests sets:
(a) combat arms, (b) combat medic, (c) cyber operations, and (d) mil-bench-5k
(general military knowledge). On these military test sets, EdgeRunner 20B
matches or exceeds GPT-5 task performance with 95%+ statistical significance,
except for the high reasoning setting on the combat medic test set and the low
reasoning setting on the mil-bench-5k test set. Versus gpt-oss-20b, there is no
statistically-significant regression on general-purpose benchmarks like ARC-C,
GPQA Diamond, GSM8k, IFEval, MMLU Pro, or TruthfulQA, except for GSM8k in the
low reasoning setting. We also present analyses on hyperparameter settings,
cost, and throughput. These findings show that small, locally-hosted models are
ideal solutions for data-sensitive operations such as in the military domain,
allowing for deployment in air-gapped edge devices.

</details>


### [138] [Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling](https://arxiv.org/abs/2510.26603)
*Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl*

Main category: cs.AI

TL;DR: 本文提出了一种基于大语言模型的自主HEMS，通过分层架构和ReAct模式实现自然语言到多设备调度的完整协调，Llama-3.3-70B表现最优。


<details>
  <summary>Details</summary>
Motivation: 住宅需求响应能力的需求增长与HEMS采用受限之间的矛盾，现有技术未能实现从自然语言输入到多设备调度的完整自主协调。

Method: 采用分层架构，结合一个协调器和三个专业代理，使用ReAct模式进行迭代推理，动态协调多设备调度，并整合Google Calendar进行上下文感知的截止时间提取。

Result: Llama-3.3-70B在所有场景中成功协调所有设备，匹配成本最优基准，而其他模型在单设备性能上表现完美但难以同时协调所有设备。

Conclusion: 本研究提出了一种基于大语言模型的自主协调HEMS，能够从自然语言输入到多设备调度的完整工作流程，并在无需示例演示的情况下实现最优调度。开源系统为未来的研究和扩展提供了基础。

Abstract: The electricity sector transition requires substantial increases in
residential demand response capacity, yet Home Energy Management Systems (HEMS)
adoption remains limited by user interaction barriers requiring translation of
everyday preferences into technical parameters. While large language models
have been applied to energy systems as code generators and parameter
extractors, no existing implementation deploys LLMs as autonomous coordinators
managing the complete workflow from natural language input to multi-appliance
scheduling. This paper presents an agentic AI HEMS where LLMs autonomously
coordinate multi-appliance scheduling from natural language requests to device
control, achieving optimal scheduling without example demonstrations. A
hierarchical architecture combining one orchestrator with three specialist
agents uses the ReAct pattern for iterative reasoning, enabling dynamic
coordination without hardcoded workflows while integrating Google Calendar for
context-aware deadline extraction. Evaluation across three open-source models
using real Austrian day-ahead electricity prices reveals substantial capability
differences. Llama-3.3-70B successfully coordinates all appliances across all
scenarios to match cost-optimal benchmarks computed via mixed-integer linear
programming, while other models achieve perfect single-appliance performance
but struggle to coordinate all appliances simultaneously. Progressive prompt
engineering experiments demonstrate that analytical query handling without
explicit guidance remains unreliable despite models' general reasoning
capabilities. We open-source the complete system including orchestration logic,
agent prompts, tools, and web interfaces to enable reproducibility, extension,
and future research.

</details>


### [139] [Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives](https://arxiv.org/abs/2510.26606)
*Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada*

Main category: cs.AI

TL;DR: 论文评估了LLMs在规范性推理中的能力，发现其存在逻辑不一致性和人类类似的认知偏差，提出了提升可靠性的见解。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型（LLMs）在规范性推理领域的能力，这一领域尚未充分研究。

Method: 通过引入一个涵盖广泛形式推理模式的新数据集，比较LLMs在规范性和认知性模态下的推理能力。

Result: LLMs通常遵循有效推理模式，但在特定类型的规范性推理中表现出不一致性和认知偏差。

Conclusion: LLMs在规范性推理中表现出逻辑不一致性和认知偏差，这为实现逻辑一致性提出了挑战，并为提升其可靠性提供了见解。

Abstract: Normative reasoning is a type of reasoning that involves normative or deontic
modality, such as obligation and permission. While large language models (LLMs)
have demonstrated remarkable performance across various reasoning tasks, their
ability to handle normative reasoning remains underexplored. In this paper, we
systematically evaluate LLMs' reasoning capabilities in the normative domain
from both logical and modal perspectives. Specifically, to assess how well LLMs
reason with normative modals, we make a comparison between their reasoning with
normative modals and their reasoning with epistemic modals, which share a
common formal structure. To this end, we introduce a new dataset covering a
wide range of formal patterns of reasoning in both normative and epistemic
domains, while also incorporating non-formal cognitive factors that influence
human reasoning. Our results indicate that, although LLMs generally adhere to
valid reasoning patterns, they exhibit notable inconsistencies in specific
types of normative reasoning and display cognitive biases similar to those
observed in psychological studies of human reasoning. These findings highlight
challenges in achieving logical consistency in LLMs' normative reasoning and
provide insights for enhancing their reliability. All data and code are
released publicly at https://github.com/kmineshima/NeuBAROCO.

</details>


### [140] [The Era of Agentic Organization: Learning to Organize with Language Models](https://arxiv.org/abs/2510.26658)
*Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei*

Main category: cs.AI

TL;DR: AsyncThink 是一种异步思考范式，通过动态分配任务和强化学习优化，显著提高推理效率和准确性，且具备泛化能力。


<details>
  <summary>Details</summary>
Motivation: 为了解决复杂问题并超越个体智能的限制，探索代理协作并发的AI新时代。

Method: 提出了一种异步思考协议，动态分配子查询、合并中间知识并生成连贯解决方案，并通过强化学习优化思考结构。

Result: AsyncThink 在推理延迟上降低了28%，在数学推理任务上准确率提升，且无需额外训练即可泛化到新任务。

Conclusion: AsyncThink 通过异步思考范式显著提升了大型语言模型的推理效率和准确性，尤其在数学推理任务上表现优异，且具备良好的泛化能力。

Abstract: We envision a new era of AI, termed agentic organization, where agents solve
complex problems by working collaboratively and concurrently, enabling outcomes
beyond individual intelligence. To realize this vision, we introduce
asynchronous thinking (AsyncThink) as a new paradigm of reasoning with large
language models, which organizes the internal thinking process into
concurrently executable structures. Specifically, we propose a thinking
protocol where an organizer dynamically assigns sub-queries to workers, merges
intermediate knowledge, and produces coherent solutions. More importantly, the
thinking structure in this protocol can be further optimized through
reinforcement learning. Experiments demonstrate that AsyncThink achieves 28%
lower inference latency compared to parallel thinking while improving accuracy
on mathematical reasoning. Moreover, AsyncThink generalizes its learned
asynchronous thinking capabilities, effectively tackling unseen tasks without
additional training.

</details>


### [141] [Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching](https://arxiv.org/abs/2510.26702)
*Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi*

Main category: cs.AI

TL;DR: 论文提出了一种委托授权模型和ASTRA数据集，用于语义检查访问请求并最小化授权范围，实验揭示了模型匹配的潜力与局限性，呼吁进一步研究语义匹配技术。


<details>
  <summary>Details</summary>
Motivation: 当前的大语言模型驱动代理在动态调用工具和访问受保护资源时存在授权过广的风险，可能导致代理操作超出预期任务范围。

Method: 引入了一个委托授权模型，允许授权服务器对访问请求进行语义检查，并生成最小必要范围的访问令牌。同时，提出了ASTRA数据集及其生成流程，用于任务与范围语义匹配的基准测试。

Result: 实验结果表明，基于模型的语义匹配在任务与范围的对齐上具有潜力，但随着任务所需范围的增加，其局限性也显现出来。

Conclusion: 论文提出了一个委托授权模型，通过语义检查访问请求来最小化授权范围，并引入了ASTRA数据集以评估任务与范围的语义匹配效果。实验揭示了基于模型的匹配在当前技术下的潜力与局限性，强调了未来在语义匹配技术（如TBAC）上进一步研究的必要性。

Abstract: Authorizing Large Language Model driven agents to dynamically invoke tools
and access protected resources introduces significant risks, since current
methods for delegating authorization grant overly broad permissions and give
access to tools allowing agents to operate beyond the intended task scope. We
introduce and assess a delegated authorization model enabling authorization
servers to semantically inspect access requests to protected resources, and
issue access tokens constrained to the minimal set of scopes necessary for the
agents' assigned tasks. Given the unavailability of datasets centered on
delegated authorization flows, particularly including both semantically
appropriate and inappropriate scope requests for a given task, we introduce
ASTRA, a dataset and data generation pipeline for benchmarking semantic
matching between tasks and scopes. Our experiments show both the potential and
current limitations of model-based matching, particularly as the number of
scopes needed for task completion increases. Our results highlight the need for
further research into semantic matching techniques enabling intent-aware
authorization for multi-agent and tool-augmented applications, including
fine-grained control, such as Task-Based Access Control (TBAC).

</details>


### [142] [Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis](https://arxiv.org/abs/2510.26721)
*Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang*

Main category: cs.AI

TL;DR: 研究发现，多模态大语言模型（MLLMs）在处理视觉-语言数据时存在明显的文本偏好，这种偏好源于模型内部架构的视觉键向量分布与文本键空间的不匹配，而非外部数据因素。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs在处理视觉-语言数据时为何倾向于文本输入，并验证这种偏好的根源是否来自模型内部的注意力键空间不对齐。

Method: 从LLaVA和Qwen2.5-VL模型中提取键向量，使用t-SNE和Jensen-Shannon散度分析其分布结构。

Result: 视觉和文本键向量在注意力空间中占据显著不同的子空间，且这种跨模态差异在统计上显著超过模态内差异。

Conclusion: 文本偏好源自注意力键空间的内在不对齐，而非外部数据不平衡或指令调整。

Abstract: Multimodal large language models (MLLMs) exhibit a pronounced preference for
textual inputs when processing vision-language data, limiting their ability to
reason effectively from visual evidence. Unlike prior studies that attribute
this text bias to external factors such as data imbalance or instruction
tuning, we propose that the bias originates from the model's internal
architecture. Specifically, we hypothesize that visual key vectors (Visual
Keys) are out-of-distribution (OOD) relative to the text key space learned
during language-only pretraining. Consequently, these visual keys receive
systematically lower similarity scores during attention computation, leading to
their under-utilization in the context representation. To validate this
hypothesis, we extract key vectors from LLaVA and Qwen2.5-VL and analyze their
distributional structures using qualitative (t-SNE) and quantitative
(Jensen-Shannon divergence) methods. The results provide direct evidence that
visual and textual keys occupy markedly distinct subspaces within the attention
space. The inter-modal divergence is statistically significant, exceeding
intra-modal variation by several orders of magnitude. These findings reveal
that text bias arises from an intrinsic misalignment within the attention key
space rather than solely from external data factors.

</details>


### [143] [Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models](https://arxiv.org/abs/2510.26732)
*J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot*

Main category: cs.AI

TL;DR: 论文通过跨平台评估15个基础模型在79个问题上的推理能力，挑战了传统扩展假设，强调训练数据质量的重要性，并提供了模型选择指南。


<details>
  <summary>Details</summary>
Motivation: 旨在评估当代基础模型在不同计算范式（HPC超级计算、云平台和大学集群）下的推理能力，并建立基础设施无关的基准。

Method: 通过三个实验阶段（基准建立、基础设施验证和扩展评估）对15个基础模型在79个问题上的推理能力进行了跨平台评估。

Result: 研究结果表明训练数据质量比模型规模更重要，并提供了跨场景模型选择的实用指南。

Conclusion: 研究发现挑战了传统的扩展假设，确立了训练数据质量比模型规模更为关键，并为教育、生产和研究场景中的模型选择提供了实用指南。

Abstract: This paper presents a comprehensive cross-platform evaluation of reasoning
capabilities in contemporary foundation models, establishing an
infrastructure-agnostic benchmark across three computational paradigms: HPC
supercomputing (MareNostrum 5), cloud platforms (Nebius AI Studio), and
university clusters (a node with eight H200 GPUs).
  We evaluate 15 foundation models across 79 problems spanning eight academic
domains (Physics, Mathematics, Chemistry, Economics, Biology, Statistics,
Calculus, and Optimization) through three experimental phases: (1) Baseline
establishment: Six models (Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b,
Mistral-7B, OLMo-7B) evaluated on 19 problems using MareNostrum 5, establishing
methodology and reference performance; (2) Infrastructure validation: The
19-problem benchmark repeated on university cluster (seven models including
Falcon-Mamba state-space architecture) and Nebius AI Studio (nine
state-of-the-art models: Hermes-4 70B/405B, LLaMA 3.1-405B/3.3-70B, Qwen3
30B/235B, DeepSeek-R1, GPT-OSS 20B/120B) to confirm infrastructure-agnostic
reproducibility; (3) Extended evaluation: Full 79-problem assessment on both
university cluster and Nebius platforms, probing generalization at scale across
architectural diversity.
  The findings challenge conventional scaling assumptions, establish training
data quality as more critical than model size, and provide actionable
guidelines for model selection across educational, production, and research
contexts. The tri-infrastructure methodology and 79-problem benchmark enable
longitudinal tracking of reasoning capabilities as foundation models evolve.

</details>


### [144] [The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy](https://arxiv.org/abs/2510.26752)
*William Overman,Mohsen Bayati*

Main category: cs.AI

TL;DR: 论文提出了一种通过马尔可夫潜在游戏框架实现人类与智能体对齐的方法，确保智能体自主性增强不会损害人类价值，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在解决智能体部署中的安全问题，即如何在无需修改底层系统的情况下保留有意义的人类控制。

Method: 研究采用了两玩家马尔可夫游戏模型，分析了其作为马尔可夫潜在游戏的条件，并在网格世界模拟中验证了独立学习的效果。

Result: 理论分析表明，在特定条件下，智能体自主性提升不会损害人类价值；模拟实验显示，智能体和人类通过独立学习能够发现最佳监督角色，避免了安全违规。

Conclusion: 该论文提出了一种最小控制接口，通过马尔可夫潜在游戏（MPG）框架，为人类和智能体之间的互动提供了内在对齐的保证，确保智能体自主性增强不会损害人类价值。

Abstract: As increasingly capable agents are deployed, a central safety question is how
to retain meaningful human control without modifying the underlying system. We
study a minimal control interface where an agent chooses whether to act
autonomously (play) or defer (ask), while a human simultaneously chooses
whether to be permissive (trust) or to engage in oversight (oversee). If the
agent defers, the human's choice determines the outcome, potentially leading to
a corrective action or a system shutdown. We model this interaction as a
two-player Markov Game. Our analysis focuses on cases where this game qualifies
as a Markov Potential Game (MPG), a class of games where we can provide an
alignment guarantee: under a structural assumption on the human's value
function, any decision by the agent to act more autonomously that benefits
itself cannot harm the human's value. We also analyze extensions to this MPG
framework. Theoretically, this perspective provides conditions for a specific
form of intrinsic alignment. If the reward structures of the human-agent game
meet these conditions, we have a formal guarantee that the agent improving its
own outcome will not harm the human's. Practically, this model motivates a
transparent control layer with predictable incentives where the agent learns to
defer when risky and act when safe, while its pretrained policy and the
environment's reward structure remain untouched. Our gridworld simulation shows
that through independent learning, the agent and human discover their optimal
oversight roles. The agent learns to ask when uncertain and the human learns
when to oversee, leading to an emergent collaboration that avoids safety
violations introduced post-training. This demonstrates a practical method for
making misaligned models safer after deployment.

</details>


### [145] [LLMs Process Lists With General Filter Heads](https://arxiv.org/abs/2510.26784)
*Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau*

Main category: cs.AI

TL;DR: LLMs encode general filtering operations in 'filter heads', mirroring functional programming, with strategies adaptable to diverse tasks and formats.


<details>
  <summary>Details</summary>
Motivation: To investigate how LLMs encode and generalize list-processing tasks, particularly filtering operations.

Method: Causal mediation analysis on a diverse set of list-processing tasks to identify 'filter heads' encoding filtering predicates.

Result: LLMs use a small number of attention heads ('filter heads') to encode portable filtering predicates, but can also employ eager evaluation strategies.

Conclusion: Transformer LMs can develop human-interpretable implementations of abstract computational operations, mirroring traditional functional programming patterns.

Abstract: We investigate the mechanisms underlying a range of list-processing tasks in
LLMs, and we find that LLMs have learned to encode a compact, causal
representation of a general filtering operation that mirrors the generic
"filter" function of functional programming. Using causal mediation analysis on
a diverse set of list-processing tasks, we find that a small number of
attention heads, which we dub filter heads, encode a compact representation of
the filtering predicate in their query states at certain tokens. We demonstrate
that this predicate representation is general and portable: it can be extracted
and reapplied to execute the same filtering operation on different collections,
presented in different formats, languages, or even in tasks. However, we also
identify situations where transformer LMs can exploit a different strategy for
filtering: eagerly evaluating if an item satisfies the predicate and storing
this intermediate result as a flag directly in the item representations. Our
results reveal that transformer LMs can develop human-interpretable
implementations of abstract computational operations that generalize in ways
that are surprisingly similar to strategies used in traditional functional
programming patterns.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [146] [Debate2Create: Robot Co-design via Large Language Model Debates](https://arxiv.org/abs/2510.25850)
*Kevin Qiu,Marek Cygan*

Main category: cs.RO

TL;DR: D2C框架利用LLM智能体辩论优化机器人形态与控制，通过迭代反馈生成高效设计，四足机器人移动距离提升73%。


<details>
  <summary>Details</summary>
Motivation: 解决机器人形态与控制联合设计的自动化难题，因设计空间庞大且形态与行为紧密耦合。

Method: 提出Debate2Create（D2C）框架，通过设计代理和控制代理的辩论，结合多元评委的模拟反馈，迭代优化机器人的形态和奖励函数。

Result: D2C在四足机器人运动基准测试中，发现的设计比默认设计移动距离远73%，且无需显式多样性目标即可生成多样化形态。

Conclusion: 结构化的大型语言模型（LLM）多智能体辩论结合物理反馈是一种有前景的自动机器人设计新范式。

Abstract: Automating the co-design of a robot's morphology and control is a
long-standing challenge due to the vast design space and the tight coupling
between body and behavior. We introduce Debate2Create (D2C), a framework in
which large language model (LLM) agents engage in a structured dialectical
debate to jointly optimize a robot's design and its reward function. In each
round, a design agent proposes targeted morphological modifications, and a
control agent devises a reward function tailored to exploit the new design. A
panel of pluralistic judges then evaluates the design-control pair in
simulation and provides feedback that guides the next round of debate. Through
iterative debates, the agents progressively refine their proposals, producing
increasingly effective robot designs. Notably, D2C yields diverse and
specialized morphologies despite no explicit diversity objective. On a
quadruped locomotion benchmark, D2C discovers designs that travel 73% farther
than the default, demonstrating that structured LLM-based debate can serve as a
powerful mechanism for emergent robot co-design. Our results suggest that
multi-agent debate, when coupled with physics-grounded feedback, is a promising
new paradigm for automated robot design.

</details>


### [147] [Risk-Aware Safety Filters with Poisson Safety Functions and Laplace Guidance Fields](https://arxiv.org/abs/2510.25913)
*Gilbert Bahati,Ryan M. Bena,Meg Wilkinson,Pol Mestres,Ryan K. Cosner,Aaron D. Ames*

Main category: cs.RO

TL;DR: 开发了一种基于Poisson和Laplace方程的风险感知安全过滤器，确保机器人安全导航并优先避开高风险障碍物。


<details>
  <summary>Details</summary>
Motivation: 为了在现实环境中实现安全导航，机器人系统需要对环境有语义理解，并能根据风险级别采取相应行动。

Method: 采用两步法：首先通过Poisson方程的Dirichlet问题生成安全函数，然后通过Laplace方程的Dirichlet问题合成引导场，最后结合两者定义安全约束。

Result: 在仿真中验证了该方法，展示了如何将障碍物风险先验知识直接融入安全过滤器，生成风险感知的安全行为。

Conclusion: 本文提出了一种风险感知的安全过滤器，通过结合Poisson方程的安全函数和Laplace方程的引导场，确保机器人系统在环境中的安全导航，并优先避开高风险障碍物。

Abstract: Robotic systems navigating in real-world settings require a semantic
understanding of their environment to properly determine safe actions. This
work aims to develop the mathematical underpinnings of such a representation --
specifically, the goal is to develop safety filters that are risk-aware. To
this end, we take a two step approach: encoding an understanding of the
environment via Poisson's equation, and associated risk via Laplace guidance
fields. That is, we first solve a Dirichlet problem for Poisson's equation to
generate a safety function that encodes system safety as its 0-superlevel set.
We then separately solve a Dirichlet problem for Laplace's equation to
synthesize a safe \textit{guidance field} that encodes variable levels of
caution around obstacles -- by enforcing a tunable flux boundary condition. The
safety function and guidance fields are then combined to define a safety
constraint and used to synthesize a risk-aware safety filter which, given a
semantic understanding of an environment with associated risk levels of
environmental features, guarantees safety while prioritizing avoidance of
higher risk obstacles. We demonstrate this method in simulation and discuss how
\textit{a priori} understandings of obstacle risk can be directly incorporated
into the safety filter to generate safe behaviors that are risk-aware.

</details>


### [148] [Curvature-Aware Calibration of Tactile Sensors for Accurate Force Estimation on Non-Planar Surfaces](https://arxiv.org/abs/2510.25965)
*Luoyan Zhong,Heather Jin Hee Kim,Dylan P. Losey,Cara M. Nunez*

Main category: cs.RO

TL;DR: 提出了一种曲率感知校准模型，通过神经网络预测曲率，显著提升了柔性触觉传感器在曲面上的性能。


<details>
  <summary>Details</summary>
Motivation: 现有触觉传感器主要在平坦基底上校准，一旦安装在曲面上，其准确性和一致性会下降，限制了实际应用的可靠性。

Method: 开发了一个校准模型，用于广泛使用的电阻式触觉传感器设计，并通过多层感知器神经网络预测局部曲率。

Result: 在五种日常物体上验证，曲率感知校准在所有表面上保持了力的准确性，而平坦表面校准随着曲率增加会低估力。

Conclusion: 曲率感知校准模型显著提升了柔性触觉传感器的准确性、一致性和可靠性，使其能够在实际应用中稳定表现。

Abstract: Flexible tactile sensors are increasingly used in real-world applications
such as robotic grippers, prosthetic hands, wearable gloves, and assistive
devices, where they need to conform to curved and irregular surfaces. However,
most existing tactile sensors are calibrated only on flat substrates, and their
accuracy and consistency degrade once mounted on curved geometries. This
limitation restricts their reliability in practical use. To address this
challenge, we develop a calibration model for a widely used resistive tactile
sensor design that enables accurate force estimation on one-dimensional curved
surfaces. We then train a neural network (a multilayer perceptron) to predict
local curvature from baseline sensor outputs recorded under no applied load,
achieving an R2 score of 0.91. The proposed approach is validated on five daily
objects with varying curvatures under forces from 2 N to 8 N. Results show that
the curvature-aware calibration maintains consistent force accuracy across all
surfaces, while flat-surface calibration underestimates force as curvature
increases. Our results demonstrate that curvature-aware modeling improves the
accuracy, consistency, and reliability of flexible tactile sensors, enabling
dependable performance across real-world applications.

</details>


### [149] [A New Type of Axis-Angle Attitude Control Law for Rotational Systems: Synthesis, Analysis, and Experiments](https://arxiv.org/abs/2510.25985)
*Francisco M. F. R. Gonçalves,Ryan M. Bena,Néstor O. Pérez-Arancibia*

Main category: cs.RO

TL;DR: 新姿态控制方法利用轴角信息提升稳定性和控制灵活性，实验证明其优于传统四元数方法。


<details>
  <summary>Details</summary>
Motivation: 传统四元数方法在旋转误差大于π弧度时比例控制效果减弱，且无法保证唯一闭环平衡。

Method: 引入了一种新型姿态控制律，利用姿态误差欧拉轴角信息确保唯一闭环平衡，并通过构建严格Lyapunov函数验证稳定性。

Result: 数值模拟和实时翻滚恢复测试显示，新方法在稳定时间上优于高性能四元数控制器。

Conclusion: 提出的基于轴角的姿态控制方法在稳定时间上优于传统四元数方法，并通过严格Lyapunov函数证明了闭环系统的均匀渐近稳定性。

Abstract: Over the past few decades, continuous quaternion-based attitude control has
been proven highly effective for driving rotational systems that can be modeled
as rigid bodies, such as satellites and drones. However, methods rooted in this
approach do not enforce the existence of a unique closed-loop (CL) equilibrium
attitude-error quaternion (AEQ); and, for rotational errors about the
attitude-error Euler axis larger than {\pi}rad, their proportional-control
effect diminishes as the system state moves away from the stable equilibrium of
the CL rotational dynamics. In this paper, we introduce a new type of attitude
control law that more effectively leverages the attitude-error Euler axis-angle
information to guarantee a unique CL equilibrium AEQ and to provide greater
flexibility in the use of proportional-control efforts. Furthermore, using two
different control laws as examples-through the construction of a strict
Lyapunov function for the CL dynamics-we demonstrate that the resulting unique
equilibrium of the CL rotational system can be enforced to be uniformly
asymptotically stable. To assess and demonstrate the functionality and
performance of the proposed approach, we performed numerical simulations and
executed dozens of real-time tumble-recovery maneuvers using a small quadrotor.
These simulations and flight tests compellingly demonstrate that the proposed
axis-angle-based method achieves superior flight performance-compared with that
obtained using a high-performance quaternion-based controller-in terms of
stabilization time.

</details>


### [150] [DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System](https://arxiv.org/abs/2510.26004)
*Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang*

Main category: cs.RO

TL;DR: DARTS是一种基于无人机和AI的实时交通事件检测系统，结合热成像和深度学习，显著提高了检测速度和准确性，有望减少事故伤亡和拥堵。


<details>
  <summary>Details</summary>
Motivation: 传统交通事件检测方法存在灵活性不足、依赖密集基础设施等问题，限制了其适应性和扩展性。DARTS旨在克服这些挑战。

Method: DARTS结合了无人机的高机动性和空中视角、热成像技术以及轻量级深度学习框架，实现了实时车辆轨迹提取和事件检测。

Result: DARTS在自收集数据集上实现了99%的检测准确率，并在佛罗里达州75号州际公路的实地测试中，比当地交通管理中心提前12分钟检测到追尾事故。

Conclusion: 该研究提出了一种基于无人机和AI的实时交通事件检测系统DARTS，展示了其在提高交通管理效率和响应速度方面的潜力，特别是在减少事故相关伤亡和拥堵方面。

Abstract: Rapid and reliable incident detection is critical for reducing crash-related
fatalities, injuries, and congestion. However, conventional methods, such as
closed-circuit television, dashcam footage, and sensor-based detection,
separate detection from verification, suffer from limited flexibility, and
require dense infrastructure or high penetration rates, restricting
adaptability and scalability to shifting incident hotspots. To overcome these
challenges, we developed DARTS, a drone-based, AI-powered real-time traffic
incident detection system. DARTS integrates drones' high mobility and aerial
perspective for adaptive surveillance, thermal imaging for better
low-visibility performance and privacy protection, and a lightweight deep
learning framework for real-time vehicle trajectory extraction and incident
detection. The system achieved 99% detection accuracy on a self-collected
dataset and supports simultaneous online visual verification, severity
assessment, and incident-induced congestion propagation monitoring via a
web-based interface. In a field test on Interstate 75 in Florida, DARTS
detected and verified a rear-end collision 12 minutes earlier than the local
transportation management center and monitored incident-induced congestion
propagation, suggesting potential to support faster emergency response and
enable proactive traffic control to reduce congestion and secondary crash risk.
Crucially, DARTS's flexible deployment architecture reduces dependence on
frequent physical patrols, indicating potential scalability and
cost-effectiveness for use in remote areas and resource-constrained settings.
This study presents a promising step toward a more flexible and integrated
real-time traffic incident detection system, with significant implications for
the operational efficiency and responsiveness of modern transportation
management.

</details>


### [151] [RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras](https://arxiv.org/abs/2510.26018)
*Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska*

Main category: cs.RO

TL;DR: 利用轻量康普顿相机和协作MAV群，实现辐射源的高效实时定位与跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决传统辐射检测方法在灵活性和实时性上的不足，探索微型飞行器在辐射检测中的新应用。

Method: 采用先进单探测器康普顿相机作为轻量级（40克）高灵敏度辐射探测器，结合MAV群动态反馈控制，最大化信息获取效率。

Result: 成功实现了对辐射源的实时定位和动态跟踪，验证了方法的有效性和实用性。

Conclusion: 该论文提出了一种利用微型飞行器（MAVs）协作定位放射性材料的新方法，通过实时融合康普顿相机测量数据，实现了对辐射源位置的高效估计和动态跟踪。

Abstract: We present a novel approach to localizing radioactive material by cooperating
Micro Aerial Vehicles (MAVs). Our approach utilizes a state-of-the-art
single-detector Compton camera as a highly sensitive, yet miniature detector of
ionizing radiation. The detector's exceptionally low weight (40 g) opens up new
possibilities of radiation detection by a team of cooperating agile MAVs. We
propose a new fundamental concept of fusing the Compton camera measurements to
estimate the position of the radiation source in real time even from extremely
sparse measurements. The data readout and processing are performed directly
onboard and the results are used in a dynamic feedback to drive the motion of
the vehicles. The MAVs are stabilized in a tightly cooperating swarm to
maximize the information gained by the Compton cameras, rapidly locate the
radiation source, and even track a moving radiation source.

</details>


### [152] [Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods](https://arxiv.org/abs/2510.26040)
*Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams*

Main category: cs.RO

TL;DR: 研究提出了一种新型赛车代理，通过对手训练实现了87%的超车成功率，显著优于仅赛道训练的代理（56%）。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶在计时赛场景中已有显著进展，但轮对轮赛车和超车仍存在严重局限性，尤其是在现实驾驶场景中。可靠的车辆间导航对于安全的自动驾驶轮对轮赛车至关重要。

Method: 研究提出了一种新型赛车和超车代理，能够在模拟和现实中学习可靠导航赛道并超越对手。该代理部署在F1Tenth车辆上，并与运行不同竞争算法的对手进行真实世界比赛。

Result: 代理在与不同竞争算法的对手比赛中表现出色，超车成功率达到87%，而仅接受赛道训练的代理超车成功率为56%。

Conclusion: 研究表明，通过与对手训练，代理能够实现87%的超车成功率，显著优于仅接受赛道训练的代理（56%）。

Abstract: While autonomous racing performance in Time-Trial scenarios has seen
significant progress and development, autonomous wheel-to-wheel racing and
overtaking are still severely limited. These limitations are particularly
apparent in real-life driving scenarios where state-of-the-art algorithms
struggle to safely or reliably complete overtaking manoeuvres. This is
important, as reliable navigation around other vehicles is vital for safe
autonomous wheel-to-wheel racing. The F1Tenth Competition provides a useful
opportunity for developing wheel-to-wheel racing algorithms on a standardised
physical platform. The competition format makes it possible to evaluate
overtaking and wheel-to-wheel racing algorithms against the state-of-the-art.
This research presents a novel racing and overtaking agent capable of learning
to reliably navigate a track and overtake opponents in both simulation and
reality. The agent was deployed on an F1Tenth vehicle and competed against
opponents running varying competitive algorithms in the real world. The results
demonstrate that the agent's training against opponents enables deliberate
overtaking behaviours with an overtaking rate of 87% compared 56% for an agent
trained just to race.

</details>


### [153] [Morphology-Aware Graph Reinforcement Learning for Tensegrity Robot Locomotion](https://arxiv.org/abs/2510.26067)
*Chi Zhang,Mingrui Li,Wenzhe Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 论文提出了一种基于GNN的强化学习框架，用于张力完整性机器人的运动控制，实现了从模拟到硬件的直接策略迁移，表现出高效和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 张力完整性机器人结合了刚性杆和弹性电缆，具有高弹性和可部署性，但由于其欠驱动和高度耦合的动力学特性，运动控制面临重大挑战。

Method: 论文提出了一种形态感知的强化学习框架，将图神经网络（GNN）集成到Soft Actor-Critic（SAC）算法中，通过将机器人的物理拓扑表示为图，GNN策略捕捉了组件间的耦合关系，比传统的多层感知机（MLP）策略学习更快、更稳定。

Result: 该方法在一个物理3杆张力完整性机器人上验证了三种运动原语（包括直线跟踪和双向转向），显示出优异的样本效率、对噪声和刚度变化的鲁棒性以及改进的轨迹精度。

Conclusion: 该论文展示了将结构先验知识融入强化学习在张力完整性机器人控制中的优势，特别是通过图神经网络（GNN）策略实现了从模拟到硬件的直接策略迁移，无需微调即可实现稳定的实际运动。

Abstract: Tensegrity robots combine rigid rods and elastic cables, offering high
resilience and deployability but posing major challenges for locomotion control
due to their underactuated and highly coupled dynamics. This paper introduces a
morphology-aware reinforcement learning framework that integrates a graph
neural network (GNN) into the Soft Actor-Critic (SAC) algorithm. By
representing the robot's physical topology as a graph, the proposed GNN-based
policy captures coupling among components, enabling faster and more stable
learning than conventional multilayer perceptron (MLP) policies. The method is
validated on a physical 3-bar tensegrity robot across three locomotion
primitives, including straight-line tracking and bidirectional turning. It
shows superior sample efficiency, robustness to noise and stiffness variations,
and improved trajectory accuracy. Notably, the learned policies transfer
directly from simulation to hardware without fine-tuning, achieving stable
real-world locomotion. These results demonstrate the advantages of
incorporating structural priors into reinforcement learning for tensegrity
robot control.

</details>


### [154] [I don't Want You to Die: A Shared Responsibility Framework for Safeguarding Child-Robot Companionship](https://arxiv.org/abs/2510.26080)
*Fan Yang,Renkai Ma,Yaxin Hu,Michael Rodgers,Lingyao Li*

Main category: cs.RO

TL;DR: 研究发现Moxie机器人停用时责任由多方共担，观点两极分化，提出了共享责任框架以减少情感伤害。


<details>
  <summary>Details</summary>
Motivation: 研究探讨了社交机器人（如Moxie）突然停用对儿童情感造成的伤害，以及谁应对此负责的问题。

Method: 通过定性调查72名美国参与者，以Moxie机器人的停用为案例研究。

Result: 研究发现责任被视为机器人公司、父母、开发者和政府共同承担，但责任分配因政治意识形态和是否为人父母而异。关于机器人服务是否应继续的观点高度两极分化。

Conclusion: 该研究提出了一个基于实证的共享责任框架，旨在通过明确责任的分配和争议点，保护儿童与机器人之间的情感纽带，并为设计和政策提供具体建议以减少机器人停用带来的情感伤害。

Abstract: Social robots like Moxie are designed to form strong emotional bonds with
children, but their abrupt discontinuation can cause significant struggles and
distress to children. When these services end, the resulting harm raises
complex questions of who bears responsibility when children's emotional bonds
are broken. Using the Moxie shutdown as a case study through a qualitative
survey of 72 U.S. participants, our findings show that the responsibility is
viewed as a shared duty across the robot company, parents, developers, and
government. However, these attributions varied by political ideology and
parental status of whether they have children. Participants' perceptions of
whether the robot service should continue are highly polarized; supporters
propose technical, financial, and governmental pathways for continuity, while
opponents cite business realities and risks of unhealthy emotional dependency.
Ultimately, this research contributes an empirically grounded shared
responsibility framework for safeguarding child-robot companionship by
detailing how accountability is distributed and contested, informing concrete
design and policy implications to mitigate the emotional harm of robot
discontinuation.

</details>


### [155] [Beyond the Uncanny Valley: A Mixed-Method Investigation of Anthropomorphism in Protective Responses to Robot Abuse](https://arxiv.org/abs/2510.26082)
*Fan Yang,Lingyao Li,Yaxin Hu,Michael Rodgers,Renkai Ma*

Main category: cs.RO

TL;DR: 研究发现，中度拟人化的机器人（恐怖谷效应最强）反而引发最强的保护冲动，道德关切随拟人化程度上升而深化，对机器人设计和政策具有启示。


<details>
  <summary>Details</summary>
Motivation: 探讨不同拟人化程度如何影响人类对机器人虐待的保护反应，将‘计算机作为社会参与者’（CASA）和‘恐怖谷’理论扩展到道德领域。

Method: 通过实验邀请201名参与者观看三种不同拟人化程度（低：蜘蛛形；中：双足形；高：人形）机器人被虐待的视频，结合自我报告问卷（情绪和恐怖感）、生理数据（自动面部表情分析）和定性反思进行综合分析。

Result: 保护反应并非线性：中度拟人化的双足机器人（恐怖感最高）引发了最强的生理愤怒表达；自我报告的愤怒和愧疚感在双足和人形机器人中显著高于蜘蛛形。定性分析显示，拟人化程度越高，道德推理从财产损害评估转向对施虐者品行的谴责，治理提议也从财产法扩展到准动物权利和社会责任。

Conclusion: 研究表明，虽然中度拟人化的机器人引发了最多的负面情绪和生理反应，但这种‘恐怖谷’效应并未减弱道德关切，反而增强了保护冲动，对机器人设计、政策和未来法律框架具有重要影响。

Abstract: Robots with anthropomorphic features are increasingly shaping how humans
perceive and morally engage with them. Our research investigates how different
levels of anthropomorphism influence protective responses to robot abuse,
extending the Computers as Social Actors (CASA) and uncanny valley theories
into a moral domain. In an experiment, we invite 201 participants to view
videos depicting abuse toward a robot with low (Spider), moderate (Two-Foot),
or high (Humanoid) anthropomorphism. To provide a comprehensive analysis, we
triangulate three modalities: self-report surveys measuring emotions and
uncanniness, physiological data from automated facial expression analysis, and
qualitative reflections. Findings indicate that protective responses are not
linear. The moderately anthropomorphic Two-Foot robot, rated highest in
eeriness and "spine-tingling" sensations consistent with the uncanny valley,
elicited the strongest physiological anger expressions. Self-reported anger and
guilt are significantly higher for both the Two-Foot and Humanoid robots
compared to the Spider. Qualitative findings further reveal that as
anthropomorphism increases, moral reasoning shifts from technical assessments
of property damage to condemnation of the abuser's character, while governance
proposals expand from property law to calls for quasi-animal rights and broader
societal responsibility. These results suggest that the uncanny valley does not
dampen moral concern but paradoxically heightens protective impulses, offering
critical implications for robot design, policy, and future legal frameworks.

</details>


### [156] [Embodied Intelligence for Advanced Bioinspired Microrobotics: Examples and Insights](https://arxiv.org/abs/2510.26132)
*Nestor O. Perez-Arancibia*

Main category: cs.RO

TL;DR: 论文探讨了具身智能（EI）作为微型机器人设计原则，通过协同设计实现智能行为，展示了多个机器人平台的实例，验证了EI的可行性和优势。


<details>
  <summary>Details</summary>
Motivation: 探讨具身智能（EI）作为高级微型机器人设计原则，特别是协同设计（物理结构和行为功能的同步互依开发）的应用。

Method: 通过对比传统架构（解耦感知、计算和执行）与EI启发的系统，作者团队开发的机器人（如Bee++、RoBeetle等）展示了智能行为如何从结构动力学和物理交互中涌现。

Result: 展示了多个机器人平台（如Bee++、RoBeetle等），它们通过结构动力学和与环境的物理交互展现出智能行为，验证了EI设计的有效性。

Conclusion: 本文认为，协同设计不仅是约束下经验优化的方法，更是实现具身智能（EI）的推动力，为毫米至厘米尺度的机器人提供了可扩展且稳健的经典控制替代方案。

Abstract: The term embodied intelligence (EI) conveys the notion that body morphology,
material properties, interaction with the environment, and control strategies
can be purposefully integrated into the process of robotic design to generate
intelligent behavior; in particular, locomotion and navigation. In this paper,
we discuss EI as a design principle for advanced microrobotics, with a
particular focus on co-design -- the simultaneous and interdependent
development of physical structure and behavioral function. To illustrate the
contrast between EI-inspired systems and traditional architectures that
decouple sensing, computation, and actuation, we present and discuss a
collection of robots developed by the author and his team at the Autonomous
Microrobotic Systems Laboratory (AMSL). These robots exhibit intelligent
behavior that emerges from their structural dynamics and the physical
interaction between their components and with the environment. Platforms such
as the Bee++, RoBeetle, SMALLBug, SMARTI, WaterStrider, VLEIBot+, and FRISSHBot
exemplify how feedback loops, decision logics, sensing mechanisms, and smart
actuation strategies can be embedded into the physical properties of the
robotic system itself. Along these lines, we contend that co-design is not only
a method for empirical optimization under constraints, but also an enabler of
EI, offering a scalable and robust alternative to classical control for
robotics at the mm-to-cm-scale.

</details>


### [157] [Kinodynamic Task and Motion Planning using VLM-guided and Interleaved Sampling](https://arxiv.org/abs/2510.26139)
*Minseo Kwon,Young J. Kim*

Main category: cs.RO

TL;DR: 提出混合状态树的动力学TAMP框架，结合VLM引导，显著提升规划成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有TAMP方法在长视距问题中因过度运动采样而成本高昂，且LLMs缺乏3D空间推理能力，无法确保几何或动力学可行性。

Method: 采用混合状态树统一表示符号和数值状态，结合现成的运动规划器和物理模拟器验证动力学约束，并利用VLM引导搜索和回溯。

Result: 实验显示，与传统和基于LLM的TAMP规划器相比，平均成功率提高了32.14%至1166.67%，复杂问题的规划时间减少。

Conclusion: 提出的基于混合状态树的动力学TAMP框架显著提升了任务和运动规划的效率和成功率，尤其在复杂问题上表现突出。

Abstract: Task and Motion Planning (TAMP) integrates high-level task planning with
low-level motion feasibility, but existing methods are costly in long-horizon
problems due to excessive motion sampling. While LLMs provide commonsense
priors, they lack 3D spatial reasoning and cannot ensure geometric or dynamic
feasibility. We propose a kinodynamic TAMP framework based on a hybrid state
tree that uniformly represents symbolic and numeric states during planning,
enabling task and motion decisions to be jointly decided. Kinodynamic
constraints embedded in the TAMP problem are verified by an off-the-shelf
motion planner and physics simulator, and a VLM guides exploring a TAMP
solution and backtracks the search based on visual rendering of the states.
Experiments on the simulated domains and in the real world show 32.14% -
1166.67% increased average success rates compared to traditional and LLM-based
TAMP planners and reduced planning time on complex problems, with ablations
further highlighting the benefits of VLM guidance.

</details>


### [158] [Adaptive Trajectory Refinement for Optimization-based Local Planning in Narrow Passages](https://arxiv.org/abs/2510.26142)
*Hahjin Lee,Young J. Kim*

Main category: cs.RO

TL;DR: 自适应轨迹细化算法通过分段碰撞检测和姿态修正，显著提升移动机器人在狭窄环境中的路径规划成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在杂乱环境中路径规划的挑战，尤其是狭窄通道场景下传统方法易失败或生成次优路径的问题。

Method: 算法分为两个主要阶段：路径段级别的保守碰撞检测（递归细分风险路径段）和姿态级别的安全修正（基于穿透方向和线搜索确保每个姿态无碰撞且远离障碍物）。

Result: 仿真结果显示，该方法比现有技术成功率提高1.69倍，规划时间缩短3.79倍；实际实验验证了其在狭窄通道中的安全快速通过能力。

Conclusion: 论文提出的自适应轨迹细化算法在狭窄通道环境中显著提高了移动机器人的路径规划成功率和效率，仿真和实际实验均验证了其优越性。

Abstract: Trajectory planning for mobile robots in cluttered environments remains a
major challenge due to narrow passages, where conventional methods often fail
or generate suboptimal paths. To address this issue, we propose the adaptive
trajectory refinement algorithm, which consists of two main stages. First, to
ensure safety at the path-segment level, a segment-wise conservative collision
test is applied, where risk-prone trajectory path segments are recursively
subdivided until collision risks are eliminated. Second, to guarantee
pose-level safety, pose correction based on penetration direction and line
search is applied, ensuring that each pose in the trajectory is collision-free
and maximally clear from obstacles. Simulation results demonstrate that the
proposed method achieves up to 1.69x higher success rates and up to 3.79x
faster planning times than state-of-the-art approaches. Furthermore, real-world
experiments confirm that the robot can safely pass through narrow passages
while maintaining rapid planning performance.

</details>


### [159] [Self-localization on a 3D map by fusing global and local features from a monocular camera](https://arxiv.org/abs/2510.26170)
*Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki*

Main category: cs.RO

TL;DR: 新方法结合CNN与Vision Transformer，显著提升动态障碍物环境下的自定位精度，误差比SOTA减少20.1%，机器人测试平均误差7.51cm。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶中，使用廉价的单目相机进行3D地图自定位是必要的。然而，现有基于CNN的方法在动态障碍物（如行人）存在时表现不佳，因此需要一种更鲁棒的方法。

Method: 提出了一种结合卷积神经网络（CNN）和Vision Transformer的新方法，CNN擅长提取局部特征，而Vision Transformer则擅长提取全局特征，两者结合以应对动态障碍物的干扰。

Result: 实验结果表明，新方法在含动态障碍物的CG数据集上精度提升率为无动态障碍物时的1.5倍，自定位误差比SOTA减少20.1%，机器人测试中平均误差为7.51cm，优于SOTA。

Conclusion: 结合CNN与Vision Transformer的新方法在动态障碍物环境下显著提升了自定位精度，比现有最优方法（SOTA）误差减少了20.1%，并在公开数据集和实际机器人测试中验证了其优越性。

Abstract: Self-localization on a 3D map by using an inexpensive monocular camera is
required to realize autonomous driving. Self-localization based on a camera
often uses a convolutional neural network (CNN) that can extract local features
that are calculated by nearby pixels. However, when dynamic obstacles, such as
people, are present, CNN does not work well. This study proposes a new method
combining CNN with Vision Transformer, which excels at extracting global
features that show the relationship of patches on whole image. Experimental
results showed that, compared to the state-of-the-art method (SOTA), the
accuracy improvement rate in a CG dataset with dynamic obstacles is 1.5 times
higher than that without dynamic obstacles. Moreover, the self-localization
error of our method is 20.1% smaller than that of SOTA on public datasets.
Additionally, our robot using our method can localize itself with 7.51cm error
on average, which is more accurate than SOTA.

</details>


### [160] [PHUMA: Physically-Grounded Humanoid Locomotion Dataset](https://arxiv.org/abs/2510.26236)
*Kyungmin Lee,Sibeen Kim,Minho Park,Hyunseung Kim,Dongyoon Hwang,Hojoon Lee,Jaegul Choo*

Main category: cs.RO

TL;DR: PHUMA是一个物理基础的人形运动数据集，通过约束重定向解决现有数据集的物理伪影问题，在多样运动模仿任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖稀缺且昂贵的高质量运动捕捉数据（如AMASS），或从互联网视频中提取数据但引入物理伪影（如Humanoid-X），限制了运动模仿的扩展性和多样性。

Method: 利用大规模人类视频数据，通过物理约束重定向（确保关节限制、地面接触和无足滑）和数据精心处理，构建PHUMA数据集。

Result: PHUMA训练的策略在模仿未见运动（自录测试视频）和仅骨盆引导的路径跟踪中，均优于Humanoid-X和AMASS，实现了多样运动模仿的显著提升。

Conclusion: PHUMA数据集通过物理约束重定向和数据精心处理，解决了现有方法中的物理伪影问题，显著提升了人形机器人运动模仿的多样性和稳定性。

Abstract: Motion imitation is a promising approach for humanoid locomotion, enabling
agents to acquire humanlike behaviors. Existing methods typically rely on
high-quality motion capture datasets such as AMASS, but these are scarce and
expensive, limiting scalability and diversity. Recent studies attempt to scale
data collection by converting large-scale internet videos, exemplified by
Humanoid-X. However, they often introduce physical artifacts such as floating,
penetration, and foot skating, which hinder stable imitation. In response, we
introduce PHUMA, a Physically-grounded HUMAnoid locomotion dataset that
leverages human video at scale, while addressing physical artifacts through
careful data curation and physics-constrained retargeting. PHUMA enforces joint
limits, ensures ground contact, and eliminates foot skating, producing motions
that are both large-scale and physically reliable. We evaluated PHUMA in two
sets of conditions: (i) imitation of unseen motion from self-recorded test
videos and (ii) path following with pelvis-only guidance. In both cases,
PHUMA-trained policies outperform Humanoid-X and AMASS, achieving significant
gains in imitating diverse motions. The code is available at
https://davian-robotics.github.io/PHUMA.

</details>


### [161] [Thor: Towards Human-Level Whole-Body Reactions for Intense Contact-Rich Environments](https://arxiv.org/abs/2510.26280)
*Gangyang Li,Qing Shi,Youhao Hu,Jincheng Hu,Zhongyuan Wang,Xinlong Wang,Shaqi Luo*

Main category: cs.RO

TL;DR: Thor框架通过FAT2奖励函数和解耦强化学习架构，提升了人形机器人在力交互任务中的性能，展示了其在复杂环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在接触丰富的环境中需要保持全身稳定性并生成类人的自适应响应，但目前仍面临重大挑战。

Method: 基于机器人力学分析设计了FAT2奖励函数，并采用解耦的强化学习架构，分别控制上半身、腰部和下半身，共享全局观察并联合更新参数。

Result: 在Unitree G1上部署的Thor框架在力交互任务中显著优于基线，峰值拉力达到167.7 N（后退）和145.5 N（前进），分别提升68.9%和74.7%，并能拉动130 N的负载架和单手打开60 N的防火门。

Conclusion: Thor框架通过FAT2奖励函数和解耦的强化学习架构，显著提升了人形机器人在接触丰富环境中的力交互能力，展示了其在服务、工业和救援应用中的潜力。

Abstract: Humanoids hold great potential for service, industrial, and rescue
applications, in which robots must sustain whole-body stability while
performing intense, contact-rich interactions with the environment. However,
enabling humanoids to generate human-like, adaptive responses under such
conditions remains a major challenge. To address this, we propose Thor, a
humanoid framework for human-level whole-body reactions in contact-rich
environments. Based on the robot's force analysis, we design a force-adaptive
torso-tilt (FAT2) reward function to encourage humanoids to exhibit human-like
responses during force-interaction tasks. To mitigate the high-dimensional
challenges of humanoid control, Thor introduces a reinforcement learning
architecture that decouples the upper body, waist, and lower body. Each
component shares global observations of the whole body and jointly updates its
parameters. Finally, we deploy Thor on the Unitree G1, and it substantially
outperforms baselines in force-interaction tasks. Specifically, the robot
achieves a peak pulling force of 167.7 N (approximately 48% of the G1's body
weight) when moving backward and 145.5 N when moving forward, representing
improvements of 68.9% and 74.7%, respectively, compared with the
best-performing baseline. Moreover, Thor is capable of pulling a loaded rack
(130 N) and opening a fire door with one hand (60 N). These results highlight
Thor's effectiveness in enhancing humanoid force-interaction capabilities.

</details>


### [162] [AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM](https://arxiv.org/abs/2510.26358)
*Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci*

Main category: cs.RO

TL;DR: AgriGS-SLAM结合LiDAR和3DGS，优化果园实时3D重建，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 果园中的自主机器人需要实时3D场景理解，但面临重复的行几何、季节性外观变化和风驱动枝叶运动的挑战。

Method: AgriGS-SLAM结合了直接LiDAR里程计和闭环检测，利用多摄像头3D高斯泼溅（3DGS）渲染，通过批量栅格化和梯度驱动的地图生命周期优化重建细节。

Result: 在不同季节和地点的测试中，AgriGS-SLAM提供了更清晰、更稳定的重建和更平滑的轨迹，同时保持实时性能。

Conclusion: AgriGS-SLAM在果园监控中表现出色，其方法也可应用于其他需要鲁棒多模态感知的户外领域。

Abstract: Autonomous robots in orchards require real-time 3D scene understanding
despite repetitive row geometry, seasonal appearance changes, and wind-driven
foliage motion. We present AgriGS-SLAM, a Visual--LiDAR SLAM framework that
couples direct LiDAR odometry and loop closures with multi-camera 3D Gaussian
Splatting (3DGS) rendering. Batch rasterization across complementary viewpoints
recovers orchard structure under occlusions, while a unified gradient-driven
map lifecycle executed between keyframes preserves fine details and bounds
memory. Pose refinement is guided by a probabilistic LiDAR-based depth
consistency term, back-propagated through the camera projection to tighten
geometry-appearance coupling. We deploy the system on a field platform in apple
and pear orchards across dormancy, flowering, and harvesting, using a
standardized trajectory protocol that evaluates both training-view and
novel-view synthesis to reduce 3DGS overfitting in evaluation. Across seasons
and sites, AgriGS-SLAM delivers sharper, more stable reconstructions and
steadier trajectories than recent state-of-the-art 3DGS-SLAM baselines while
maintaining real-time performance on-tractor. While demonstrated in orchard
monitoring, the approach can be applied to other outdoor domains requiring
robust multimodal perception.

</details>


### [163] [Cooperative Task Spaces for Multi-Arm Manipulation Control based on Similarity Transformations](https://arxiv.org/abs/2510.26362)
*Tobias Löw,Cem Bilaloglu,Sylvain Calinon*

Main category: cs.RO

TL;DR: 本文提出基于共形几何代数的多臂机器人协作控制框架，通过几何基元抽象和雅可比矩阵推导，实现复杂系统的简化控制，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 人类环境中许多任务需要多个运动链的协作行为，但由于这些系统自由度极高，协调其运动难以建模。本文旨在解决这一问题。

Method: 采用共形几何代数定义几何基元，通过相似变换抽象复杂机器人系统，推导解析和几何雅可比矩阵，并将其集成到操作空间控制中。

Result: 通过双手机器人、人形机器人和多指手的实验，展示了该方法在达到目标几何基元和差分运动学控制中的有效性，并讨论了如何利用几何基元自然嵌入的零空间结构引入次要控制目标。

Conclusion: 本文提出了基于共形几何代数的多臂机器人系统协作任务空间的理论基础，通过几何基元的相似变换，将复杂机器人系统抽象为可直接对应单臂系统的形式，并通过推导解析和几何雅可比矩阵，展示了该方法在经典控制技术中的直接应用。

Abstract: Many tasks in human environments require collaborative behavior between
multiple kinematic chains, either to provide additional support for carrying
big and bulky objects or to enable the dexterity that is required for in-hand
manipulation. Since these complex systems often have a very high number of
degrees of freedom coordinating their movements is notoriously difficult to
model. In this article, we present the derivation of the theoretical
foundations for cooperative task spaces of multi-arm robotic systems based on
geometric primitives defined using conformal geometric algebra. Based on the
similarity transformations of these cooperative geometric primitives, we derive
an abstraction of complex robotic systems that enables representing these
systems in a way that directly corresponds to single-arm systems. By deriving
the associated analytic and geometric Jacobian matrices, we then show the
straightforward integration of our approach into classical control techniques
rooted in operational space control. We demonstrate this using bimanual
manipulators, humanoids and multi-fingered hands in optimal control experiments
for reaching desired geometric primitives and in teleoperation experiments
using differential kinematics control. We then discuss how the geometric
primitives naturally embed nullspace structures into the controllers that can
be exploited for introducing secondary control objectives. This work,
represents the theoretical foundations of this cooperative manipulation control
framework, and thus the experiments are presented in an abstract way, while
giving pointers towards potential future applications.

</details>


### [164] [Towards Reinforcement Learning Based Log Loading Automation](https://arxiv.org/abs/2510.26363)
*Ilya Kurinov,Miroslav Ivanov,Grzegorz Orzechowski,Aki Mikkola*

Main category: cs.RO

TL;DR: 研究通过强化学习实现林业转运机全自动装载，代理成功率达94%。


<details>
  <summary>Details</summary>
Motivation: 林业转运机操作对操作员来说具有挑战性，自动化可以减轻其压力。

Method: 使用NVIDIA的Isaac Gym平台构建了林业转运机的仿真模型，结合强化学习和课程学习方法训练代理。

Result: 最佳代理在随机位置抓取并运输原木的成功率达到94%。

Conclusion: 本研究通过强化学习代理成功实现了林业转运机全自动装载操作，展示了强化学习在林业机械自动化中的潜力。

Abstract: Forestry forwarders play a central role in mechanized timber harvesting by
picking up and moving logs from the felling site to a processing area or a
secondary transport vehicle. Forwarder operation is challenging and physically
and mentally exhausting for the operator who must control the machine in remote
areas for prolonged periods of time. Therefore, even partial automation of the
process may reduce stress on the operator. This study focuses on continuing
previous research efforts in application of reinforcement learning agents in
automating log handling process, extending the task from grasping which was
studied in previous research to full log loading operation. The resulting agent
will be capable to automate a full loading procedure from locating and
grappling to transporting and delivering the log to a forestry forwarder bed.
To train the agent, a trailer type forestry forwarder simulation model in
NVIDIA's Isaac Gym and a virtual environment for a typical log loading scenario
were developed. With reinforcement learning agents and a curriculum learning
approach, the trained agent may be a stepping stone towards application of
reinforcement learning agents in automation of the forestry forwarder. The
agent learnt grasping a log in a random position from grapple's random position
and transport it to the bed with 94% success rate of the best performing agent.

</details>


### [165] [Human-in-the-loop Online Rejection Sampling for Robotic Manipulation](https://arxiv.org/abs/2510.26406)
*Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang*

Main category: cs.RO

TL;DR: Hi-ORS结合拒绝采样和奖励加权监督训练，稳定高效地微调机器人策略，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习在视觉-语言-动作模型微调中因不准确的价值估计和稀疏监督而不稳定，而模仿学习则因离线性质表现不佳。

Method: Hi-ORS采用拒绝采样过滤负奖励样本，并使用奖励加权的监督训练目标提供密集的中途监督。同时，开发了异步推理训练框架支持在线人工干预。

Result: 在三个实际任务和两种实体上，Hi-ORS仅需1.5小时真实训练即超越RL和IL基线，展现出强大的测试时扩展性。

Conclusion: Hi-ORS通过结合拒绝采样和奖励加权的监督训练目标，在稳定性和鲁棒性上显著优于传统的强化学习和模仿学习方法，尤其在复杂错误恢复行为上表现出色。

Abstract: Reinforcement learning (RL) is widely used to produce robust robotic
manipulation policies, but fine-tuning vision-language-action (VLA) models with
RL can be unstable due to inaccurate value estimates and sparse supervision at
intermediate steps. In contrast, imitation learning (IL) is easy to train but
often underperforms due to its offline nature. In this paper, we propose
Hi-ORS, a simple yet effective post-training method that utilizes rejection
sampling to achieve both training stability and high robustness. Hi-ORS
stabilizes value estimation by filtering out negatively rewarded samples during
online fine-tuning, and adopts a reward-weighted supervised training objective
to provide dense intermediate-step supervision. For systematic study, we
develop an asynchronous inference-training framework that supports flexible
online human-in-the-loop corrections, which serve as explicit guidance for
learning error-recovery behaviors. Across three real-world tasks and two
embodiments, Hi-ORS fine-tunes a pi-base policy to master contact-rich
manipulation in just 1.5 hours of real-world training, outperforming RL and IL
baselines by a substantial margin in both effectiveness and efficiency.
Notably, the fine-tuned policy exhibits strong test-time scalability by
reliably executing complex error-recovery behaviors to achieve better
performance.

</details>


### [166] [RoboOS-NeXT: A Unified Memory-based Framework for Lifelong, Scalable, and Robust Multi-Robot Collaboration](https://arxiv.org/abs/2510.26536)
*Huajie Tan,Cheng Chi,Xiansheng Chen,Yuheng Ji,Zhongxia Zhao,Xiaoshuai Hao,Yaoxu Lyu,Mingyu Cao,Junkai Zhao,Huaihai Lyu,Enshen Zhou,Ning Chen,Yankai Fu,Cheng Peng,Wei Guo,Dong Liang,Zhuo Chen,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboOS-NeXT通过STEM记忆框架解决了多机器人协作中的长期适应性、可扩展性和鲁棒性问题，实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因依赖有限的个体记忆而无法实现长期学习、异构团队扩展或故障恢复，需要统一记忆表示。

Method: 引入了Spatio-Temporal-Embodiment Memory (STEM)作为核心记忆表示，结合脑-小脑框架进行全局规划和局部执行。

Result: 在餐厅、超市和家庭等复杂协调任务中，RoboOS-NeXT表现出色，验证了其终身、可扩展和鲁棒的多机器人协作能力。

Conclusion: RoboOS-NeXT通过其统一的记忆表示框架STEM，实现了多机器人系统的终身适应性、可扩展协调和鲁棒调度，验证了其在异构团队中的有效性。

Abstract: The proliferation of collaborative robots across diverse tasks and
embodiments presents a central challenge: achieving lifelong adaptability,
scalable coordination, and robust scheduling in multi-agent systems. Existing
approaches, from vision-language-action (VLA) models to hierarchical
frameworks, fall short due to their reliance on limited or dividual-agent
memory. This fundamentally constrains their ability to learn over long
horizons, scale to heterogeneous teams, or recover from failures, highlighting
the need for a unified memory representation. To address these limitations, we
introduce RoboOS-NeXT, a unified memory-based framework for lifelong, scalable,
and robust multi-robot collaboration. At the core of RoboOS-NeXT is the novel
Spatio-Temporal-Embodiment Memory (STEM), which integrates spatial scene
geometry, temporal event history, and embodiment profiles into a shared
representation. This memory-centric design is integrated into a
brain-cerebellum framework, where a high-level brain model performs global
planning by retrieving and updating STEM, while low-level controllers execute
actions locally. This closed loop between cognition, memory, and execution
enables dynamic task allocation, fault-tolerant collaboration, and consistent
state synchronization. We conduct extensive experiments spanning complex
coordination tasks in restaurants, supermarkets, and households. Our results
demonstrate that RoboOS-NeXT achieves superior performance across heterogeneous
embodiments, validating its effectiveness in enabling lifelong, scalable, and
robust multi-robot collaboration. Project website:
https://flagopen.github.io/RoboOS/

</details>


### [167] [Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics](https://arxiv.org/abs/2510.26551)
*Prathamesh Kothavale,Sravani Boddepalli*

Main category: cs.RO

TL;DR: 本研究提出了一种扩展机器人逆运动学求解器的新框架，使其能掌握使用不同长度工具的技能，实验显示误差率低且性能稳定。


<details>
  <summary>Details</summary>
Motivation: 传统机器人对运动学理解有限，且受限于预编程任务，无法高效利用工具。本研究旨在解决这一局限性。

Method: 通过整合模拟学习的动作轨迹与工具，开发了一种扩展的逆运动学求解器，并在实验中验证了从模拟到现实世界技能转移的实用性。

Result: 扩展的逆运动学求解器表现出小于1厘米的误差率，模拟中的平均误差为8厘米，且在使用两种不同长度工具时性能几乎无差别。

Conclusion: 本研究通过扩展逆运动学求解器的能力，展示了一种创新的框架，使机器人能够掌握使用不同长度工具的复杂技能，为工具使用的四个基本方面提供了潜在进展。

Abstract: Conventional robots possess a limited understanding of their kinematics and
are confined to preprogrammed tasks, hindering their ability to leverage tools
efficiently. Driven by the essential components of tool usage - grasping the
desired outcome, selecting the most suitable tool, determining optimal tool
orientation, and executing precise manipulations - we introduce a pioneering
framework. Our novel approach expands the capabilities of the robot's inverse
kinematics solver, empowering it to acquire a sequential repertoire of actions
using tools of varying lengths. By integrating a simulation-learned action
trajectory with the tool, we showcase the practicality of transferring acquired
skills from simulation to real-world scenarios through comprehensive
experimentation. Remarkably, our extended inverse kinematics solver
demonstrates an impressive error rate of less than 1 cm. Furthermore, our
trained policy achieves a mean error of 8 cm in simulation. Noteworthy, our
model achieves virtually indistinguishable performance when employing two
distinct tools of different lengths. This research provides an indication of
potential advances in the exploration of all four fundamental aspects of tool
usage, enabling robots to master the intricate art of tool manipulation across
diverse tasks.

</details>


### [168] [FLYINGTRUST: A Benchmark for Quadrotor Navigation Across Scenarios and Vehicles](https://arxiv.org/abs/2510.26588)
*Gang Li,Chunlei Zhai,Teng Wang,Shaun Li,Shangsong Jiang,Xiangwei Zhu*

Main category: cs.RO

TL;DR: FLYINGTRUST框架通过标准化评估揭示了导航算法性能与平台能力和场景结构的关联性，为算法设计和选择提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 针对四旋翼视觉导航算法在不同平台和场景间性能差异大的问题，提出系统性早期评估的需求，以减少实地部署的成本和风险。

Method: 介绍了FLYINGTRUST，一个高保真、可配置的基准框架，用于测量平台动力学和场景结构如何共同影响导航稳健性。框架通过两个物理可解释指标（最大推重比和轴向最大角加速度）建模车辆能力，并结合多样场景库和异构平台进行标准化评估。

Result: 使用FLYINGTRUST比较了优化型和基于学习的导航方法，发现导航成功与平台能力和场景几何有可预测的关系，不同算法在评估条件下表现出不同的偏好和失败模式。

Conclusion: 论文强调，将平台能力和场景结构纳入算法设计、评估和选择的实际必要性，并激励未来研究在多样化平台和场景中保持稳健性的方法。

Abstract: Visual navigation algorithms for quadrotors often exhibit a large variation
in performance when transferred across different vehicle platforms and scene
geometries, which increases the cost and risk of field deployment. To support
systematic early-stage evaluation, we introduce FLYINGTRUST, a high-fidelity,
configurable benchmarking framework that measures how platform kinodynamics and
scenario structure jointly affect navigation robustness. FLYINGTRUST models
vehicle capability with two compact, physically interpretable indicators:
maximum thrust-to-weight ratio and axis-wise maximum angular acceleration. The
benchmark pairs a diverse scenario library with a heterogeneous set of real and
virtual platforms and prescribes a standardized evaluation protocol together
with a composite scoring method that balances scenario importance, platform
importance and performance stability. We use FLYINGTRUST to compare
representative optimization-based and learning-based navigation approaches
under identical conditions, performing repeated trials per platform-scenario
combination and reporting uncertainty-aware metrics. The results reveal
systematic patterns: navigation success depends predictably on platform
capability and scene geometry, and different algorithms exhibit distinct
preferences and failure modes across the evaluated conditions. These
observations highlight the practical necessity of incorporating both platform
capability and scenario structure into algorithm design, evaluation, and
selection, and they motivate future work on methods that remain robust across
diverse platforms and scenarios.

</details>


### [169] [A Sliding-Window Filter for Online Continuous-Time Continuum Robot State Estimation](https://arxiv.org/abs/2510.26623)
*Spencer Teetaert,Sven Lilge,Jessica Burgner-Kahrs,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: 本文提出了一种专为连续体机器人设计的滑动窗口滤波器（SWF），结合连续时间状态估计技术，提升了准确性并实现了在线超实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有的连续体机器人（CRs）状态估计方法在准确性和计算效率之间难以平衡，且现有滑动窗口方法仅限于简化的离散时间近似，缺乏随机表示。同时，当前的随机滤波方法受限于测量速度，无法充分发挥潜力。

Method: 采用滑动窗口滤波器（SWF）方法，结合连续时间状态估计技术，克服了现有方法在离散时间近似和实时运行速度上的限制。

Result: 提出的SWF方法在连续时间状态估计中表现优异，不仅提高了准确性，还实现了在线操作和超实时速度运行，填补了现有方法的空白。

Conclusion: 本文提出了一种连续时间状态估计的滑动窗口滤波器（SWF），专为连续体机器人（CRs）设计，不仅提高了滤波方法的准确性，还实现了连续时间方法的在线操作，且运行速度快于实时速度。这为未来研究提供了有前景的方向。

Abstract: Stochastic state estimation methods for continuum robots (CRs) often struggle
to balance accuracy and computational efficiency. While several recent works
have explored sliding-window formulations for CRs, these methods are limited to
simplified, discrete-time approximations and do not provide stochastic
representations. In contrast, current stochastic filter methods must run at the
speed of measurements, limiting their full potential. Recent works in
continuous-time estimation techniques for CRs show a principled approach to
addressing this runtime constraint, but are currently restricted to offline
operation. In this work, we present a sliding-window filter (SWF) for
continuous-time state estimation of CRs that improves upon the accuracy of a
filter approach while enabling continuous-time methods to operate online, all
while running at faster-than-real-time speeds. This represents the first
stochastic SWF specifically designed for CRs, providing a promising direction
for future research in this area.

</details>


### [170] [REALMS2 -- Resilient Exploration And Lunar Mapping System 2 -- A Comprehensive Approach](https://arxiv.org/abs/2510.26638)
*Dave van der Meer,Loïck P. Chovet,Gabriel M. Garcia,Abhishek Bera,Miguel A. Olivares-Mendez*

Main category: cs.RO

TL;DR: REALMS2是一个多机器人系统框架，用于行星勘探和地图绘制，结合ROS 2、vSLAM和mesh网络，成功应对了外星环境的挑战。


<details>
  <summary>Details</summary>
Motivation: 为应对多机器人系统在行星勘探中的挑战，尤其是外星环境的通信延迟和中断问题。

Method: 基于ROS 2和vSLAM技术，REALMS2采用mesh网络构建鲁棒的自组织网络，并通过单一GUI控制所有机器人。

Result: 在ESA-ESRIC Challenge的第二次实地测试中，REALMS2使用三个同质机器人成功绘制了约60%的区域。

Conclusion: REALMS2系统通过ROS 2和vSLAM技术，结合mesh网络和单一GUI控制，成功应对了外星环境中的多机器人勘探挑战，并在ESA-ESRIC Challenge的实地测试中表现优异。

Abstract: The European Space Agency (ESA) and the European Space Resources Innovation
Centre (ESRIC) created the Space Resources Challenge to invite researchers and
companies to propose innovative solutions for Multi-Robot Systems (MRS) space
prospection. This paper proposes the Resilient Exploration And Lunar Mapping
System 2 (REALMS2), a MRS framework for planetary prospection and mapping.
Based on Robot Operating System version 2 (ROS 2) and enhanced with Visual
Simultaneous Localisation And Mapping (vSLAM) for map generation, REALMS2 uses
a mesh network for a robust ad hoc network. A single graphical user interface
(GUI) controls all the rovers, providing a simple overview of the robotic
mission. This system is designed for heterogeneous multi-robot exploratory
missions, tackling the challenges presented by extraterrestrial environments.
REALMS2 was used during the second field test of the ESA-ESRIC Challenge and
allowed to map around 60% of the area, using three homogeneous rovers while
handling communication delays and blackouts.

</details>


### [171] [Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments](https://arxiv.org/abs/2510.26646)
*Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai*

Main category: cs.RO

TL;DR: 论文提出分层路径规划框架（高层DQN + 低层TD3），结合奖励机制和安全门，在动态环境中表现优于单一算法和规则规划器。


<details>
  <summary>Details</summary>
Motivation: 解决动态和部分可观察环境中的路径规划问题，提高成功率和样本效率，同时减少控制突变。

Method: 结合高层Deep Q-Network（DQN）进行离散子目标选择和低层Twin Delayed Deep Deterministic Policy Gradient（TD3）控制器实现连续驱动，设计了实用的奖励机制和基于LiDAR的安全门。

Result: 实验结果表明，该框架在PathBench指标（成功率、碰撞率、路径效率和重新规划效率）上优于单一算法和基于规则的规划器。

Conclusion: 该论文提出的分层路径规划与控制框架在动态和部分可观察环境中表现出色，相比单一算法基准（仅使用DQN或TD3）和基于规则的规划器，成功率和样本效率均有提升，且能更好地泛化到未见过的障碍物配置。

Abstract: This paper presents a hierarchical path-planning and control framework that
combines a high-level Deep Q-Network (DQN) for discrete sub-goal selection with
a low-level Twin Delayed Deep Deterministic Policy Gradient (TD3) controller
for continuous actuation. The high-level module selects behaviors and
sub-goals; the low-level module executes smooth velocity commands. We design a
practical reward shaping scheme (direction, distance, obstacle avoidance,
action smoothness, collision penalty, time penalty, and progress), together
with a LiDAR-based safety gate that prevents unsafe motions. The system is
implemented in ROS + Gazebo (TurtleBot3) and evaluated with PathBench metrics,
including success rate, collision rate, path efficiency, and re-planning
efficiency, in dynamic and partially observable environments. Experiments show
improved success rate and sample efficiency over single-algorithm baselines
(DQN or TD3 alone) and rule-based planners, with better generalization to
unseen obstacle configurations and reduced abrupt control changes. Code and
evaluation scripts are available at the project repository.

</details>


### [172] [Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems](https://arxiv.org/abs/2510.26656)
*Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy*

Main category: cs.RO

TL;DR: 提出三种动态调整支持集的LFI启发式方法，解决传统LFI因固定支持集导致的次优推断问题，实验验证其在DLO任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统LFI方法因支持集固定可能导致后验推断次优且虚假确定，需动态调整支持集以提升推断和策略学习效果。

Method: 通过三种启发式方法（EDGE、MODE、CENTRE）动态调整支持集，结合后验推断优化，并在随机动力学基准和DLO任务中进行验证。

Result: 实验表明，启发式支持集调整能更精细地分类DLO的长度和刚度参数，并提升基于模拟的策略学习性能。

Conclusion: 提出的三种启发式LFI变体（EDGE、MODE、CENTRE）能有效解决支持集误设问题，提升参数推断和策略学习的鲁棒性，尤其在动态可变形线性物体（DLO）操作任务中表现显著。

Abstract: In robotics, likelihood-free inference (LFI) can provide the domain
distribution that adapts a learnt agent in a parametric set of deployment
conditions. LFI assumes an arbitrary support for sampling, which remains
constant as the initial generic prior is iteratively refined to more
descriptive posteriors. However, a potentially misspecified support can lead to
suboptimal, yet falsely certain, posteriors. To address this issue, we propose
three heuristic LFI variants: EDGE, MODE, and CENTRE. Each interprets the
posterior mode shift over inference steps in its own way and, when integrated
into an LFI step, adapts the support alongside posterior inference. We first
expose the support misspecification issue and evaluate our heuristics using
stochastic dynamical benchmarks. We then evaluate the impact of heuristic
support adaptation on parameter inference and policy learning for a dynamic
deformable linear object (DLO) manipulation task. Inference results in a finer
length and stiffness classification for a parametric set of DLOs. When the
resulting posteriors are used as domain distributions for sim-based policy
learning, they lead to more robust object-centric agent performance.

</details>


### [173] [Hybrid Consistency Policy: Decoupling Multi-Modal Diversity and Real-Time Efficiency in Robotic Manipulation](https://arxiv.org/abs/2510.26670)
*Qianyou Zhao,Yuliang Shen,Xuanran Zhai,Ce Hao,Duidi Wu,Jin Qi,Jie Hu,Qiaojun Yu*

Main category: cs.RO

TL;DR: HCP通过混合一致性策略，在保持多模态的同时实现快速采样，适用于机器人策略学习。


<details>
  <summary>Details</summary>
Motivation: 为了解决扩散模仿学习在快速采样和强多模态之间难以兼顾的问题。

Method: HCP采用短随机前缀和一致性跳跃的方法，结合轨迹一致性目标和去噪匹配目标进行训练。

Result: HCP在25步SDE加一次跳跃的情况下，接近80步DDPM的准确性和模态覆盖率，同时显著降低延迟。

Conclusion: HCP通过结合随机前缀和一致性跳跃，有效平衡了快速采样和多模态行为捕捉，为机器人策略提供了一种实用的准确性与效率权衡方案。

Abstract: In visuomotor policy learning, diffusion-based imitation learning has become
widely adopted for its ability to capture diverse behaviors. However,
approaches built on ordinary and stochastic denoising processes struggle to
jointly achieve fast sampling and strong multi-modality. To address these
challenges, we propose the Hybrid Consistency Policy (HCP). HCP runs a short
stochastic prefix up to an adaptive switch time, and then applies a one-step
consistency jump to produce the final action. To align this one-jump
generation, HCP performs time-varying consistency distillation that combines a
trajectory-consistency objective to keep neighboring predictions coherent and a
denoising-matching objective to improve local fidelity. In both simulation and
on a real robot, HCP with 25 SDE steps plus one jump approaches the 80-step
DDPM teacher in accuracy and mode coverage while significantly reducing
latency. These results show that multi-modality does not require slow
inference, and a switch time decouples mode retention from speed. It yields a
practical accuracy efficiency trade-off for robot policies.

</details>


### [174] [Running VLAs at Real-time Speed](https://arxiv.org/abs/2510.26742)
*Yunchao Ma,Yizhuang Zhou,Yunhuan Yang,Tiancai Wang,Haoqiang Fan*

Main category: cs.RO

TL;DR: 通过优化策略和流式推理框架，实现了单GPU上30Hz帧率和480Hz轨迹频率的实时VLA控制。


<details>
  <summary>Details</summary>
Motivation: 解决大规模VLA模型在动态和实时任务中性能不足的问题。

Method: 引入一系列策略消除模型推理中的开销，并开发了一个完整的流式推理框架。

Result: 实验显示，pi0策略在抓取下落笔任务中达到100%的成功率。

Conclusion: 通过提出的策略和流式推理框架，实现了实时机器人控制的大规模视觉语言动作（VLA）模型，显著提升了动态任务的执行效率。

Abstract: In this paper, we show how to run pi0-level multi-view VLA at 30Hz frame rate
and at most 480Hz trajectory frequency using a single consumer GPU. This
enables dynamic and real-time tasks that were previously believed to be
unattainable by large VLA models. To achieve it, we introduce a bag of
strategies to eliminate the overheads in model inference. The real-world
experiment shows that the pi0 policy with our strategy achieves a 100% success
rate in grasping a falling pen task. Based on the results, we further propose a
full streaming inference framework for real-time robot control of VLA. Code is
available at https://github.com/Dexmal/realtime-vla.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [175] [StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement](https://arxiv.org/abs/2510.26141)
*Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang*

Main category: cs.GR

TL;DR: StructLayoutFormer 是一种基于 Transformer 的方法，首次实现了数据驱动的条件化结构化布局生成，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的数据驱动方法虽然能自动生成固定布局，但无法生成布局结构，而结构化布局在二维视觉内容（如 GUI、网页）中具有重要价值。

Method: 通过结构序列化方案将结构化布局表示为序列，并将结构信息与元素放置解耦，以更好地控制生成布局的结构。

Result: 实验表明，StructLayoutFormer 在条件化结构化布局生成方面优于现有方法，并能有效提取和转移布局结构。

Conclusion: StructLayoutFormer 是一种基于 Transformer 的新方法，能够实现条件化的结构化布局生成，并在实验中表现优于现有基线方法。

Abstract: Structured layouts are preferable in many 2D visual contents (\eg, GUIs,
webpages) since the structural information allows convenient layout editing.
Computational frameworks can help create structured layouts but require heavy
labor input. Existing data-driven approaches are effective in automatically
generating fixed layouts but fail to produce layout structures. We present
StructLayoutFormer, a novel Transformer-based approach for conditional
structured layout generation. We use a structure serialization scheme to
represent structured layouts as sequences. To better control the structures of
generated layouts, we disentangle the structural information from the element
placements. Our approach is the first data-driven approach that achieves
conditional structured layout generation and produces realistic layout
structures explicitly. We compare our approach with existing data-driven layout
generation approaches by including post-processing for structure extraction.
Extensive experiments have shown that our approach exceeds these baselines in
conditional structured layout generation. We also demonstrate that our approach
is effective in extracting and transferring layout structures. The code is
publicly available at %\href{https://github.com/Teagrus/StructLayoutFormer}
{https://github.com/Teagrus/StructLayoutFormer}.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [176] [Online 3-Taxi on General Metrics](https://arxiv.org/abs/2510.25861)
*Christian Coester,Tze-Yang Poon*

Main category: cs.DS

TL;DR: 本文提出了一个在一般度量空间上解决3-taxi问题的O(1)-competitive算法，填补了该领域的空白。


<details>
  <summary>Details</summary>
Motivation: 在线k-taxi问题是k-server问题的推广，但在'hard'版本中，成本是出租车无乘客时的总行驶距离，这使得问题比k-server问题更为复杂。对于k=3的情况，此前在一般度量空间上是否可以实现有限竞争比尚属未知。

Method: 我们设计了一个算法，专门针对3-taxi问题，确保其在任何度量空间上都能达到O(1)的竞争比。

Result: 我们成功设计并验证了一个算法，该算法在3-taxi问题上实现了O(1)的竞争比。

Conclusion: 本文提出了一个针对3-taxi问题的O(1)-competitive算法，解决了长期以来关于在一般度量空间上是否可以实现有限竞争比的未知问题。

Abstract: The online $k$-taxi problem, introduced in 1990 by Fiat, Rabani and Ravid, is
a generalization of the $k$-server problem where $k$ taxis must serve a
sequence of requests in a metric space. Each request is a pair of two points,
representing the pick-up and drop-off location of a passenger. In the
interesting ''hard'' version of the problem, the cost is the total distance
that the taxis travel without a passenger. The problem is known to be
substantially harder than the $k$-server problem, and prior to this work even
for $k=3$ taxis it has been unknown whether a finite competitive ratio is
achievable on general metric spaces. We present an $O(1)$-competitive algorithm
for the $3$-taxi problem.

</details>


### [177] [Space-Efficient k-Mismatch Text Indexes](https://arxiv.org/abs/2510.26264)
*Tomasz Kociumaka,Jakub Radoszewski*

Main category: cs.DS

TL;DR: 本文改进了$k$-mismatch索引的空间复杂度，从$O(n\log^k n)$降至$O(n\log^{k-1} n)$，查询时间不变，并对小字母表和短模式提供了额外优化。


<details>
  <summary>Details</summary>
Motivation: 尽管$k$-errata树在过去二十年中被广泛使用，但其原始的时空权衡在一般情况下未被改进。本文旨在突破这一限制，提供更高效的$k$-mismatch索引。

Method: 通过改进$k$-errata树的结构，实现了空间复杂度的降低。特别是在小字母表情况下，进一步优化了空间复杂度，并针对短模式设计了更优的索引结构。

Result: 提出的$k$-mismatch索引在空间复杂度上显著优于$k$-errata树，同时保持了相同的查询时间。对于小字母表，空间复杂度进一步优化。

Conclusion: 本文提出了首个改进的$k$-mismatch索引，将空间复杂度从$O(n\log^k n)$降低到$O(n\log^{k-1} n)$，同时保持了相同的查询时间。对于小字母表，索引空间进一步优化至$O(n\log^{k-1.5+\varepsilon} n)$。此外，还针对短模式开发了改进索引。

Abstract: A central task in string processing is text indexing, where the goal is to
preprocess a text (a string of length $n$) into an efficient index (a data
structure) supporting queries about the text. Cole, Gottlieb, and Lewenstein
(STOC 2004) proposed $k$-errata trees, a family of text indexes supporting
approximate pattern matching queries of several types. In particular,
$k$-errata trees yield an elegant solution to $k$-mismatch queries, where we
are to report all substrings of the text with Hamming distance at most $k$ to
the query pattern. The resulting $k$-mismatch index uses $O(n\log^k n)$ space
and answers a query for a length-$m$ pattern in $O(\log^k n \log \log n + m +
occ)$ time, where $occ$ is the number of approximate occurrences.
  In retrospect, $k$-errata trees appear very well optimized: even though a
large body of work has adapted $k$-errata trees to various settings throughout
the past two decades, the original time-space trade-off for $k$-mismatch
indexing has not been improved in the general case. We present the first such
improvement, a $k$-mismatch index with $O(n\log^{k-1} n)$ space and the same
query time as $k$-errata trees.
  Previously, due to a result of Chan, Lam, Sung, Tam, and Wong (Algorithmica
2010), such an $O(n\log^{k-1} n)$-size index has been known only for texts over
alphabets of constant size. In this setting, however, we obtain an even smaller
$k$-mismatch index of size only $O(n \log^{k-2+\varepsilon+\frac{2}{k+2-(k
\bmod 2)}} n)\subseteq O(n\log^{k-1.5+\varepsilon} n)$ for $2\le k\le O(1)$ and
any constant $\varepsilon>0$. Along the way, we also develop improved indexes
for short patterns, offering better trade-offs in this practically relevant
special case.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [178] [ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference](https://arxiv.org/abs/2510.26730)
*Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang*

Main category: cs.DC

TL;DR: ExpertFlow是一个MoE推理运行时系统，通过自适应预取和缓存感知路由减少延迟和内存需求，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现代GPU内存容量限制了大语言模型的扩展，传统MoE推理方法因频繁参数传输和固定步长预测策略存在延迟和适应性不足的问题。

Method: 结合自适应专家预取和缓存感知路由，利用运行时统计信息和混合跨层预测方案。

Result: 评估显示ExpertFlow将模型停滞时间降低至基线的0.1%以下。

Conclusion: ExpertFlow通过自适应预取和缓存感知路由优化了MoE推理，显著减少了延迟和缓存未命中，证明了其在严格内存约束下的高效性。

Abstract: The expansion of large language models is increasingly limited by the
constrained memory capacity of modern GPUs. To mitigate this,
Mixture-of-Experts (MoE) architectures activate only a small portion of
parameters during inference, significantly lowering both memory demand and
computational overhead. However, conventional MoE inference approaches, which
select active experts independently at each layer, often introduce considerable
latency because of frequent parameter transfers between host and GPU memory. In
addition, current cross-layer prediction strategies, which are typically based
on fixed steps, lack adaptability across different hardware platforms and
workloads, thereby reducing their robustness and effectiveness.
  To address these challenges, we present ExpertFlow, a runtime system for MoE
inference that combines adaptive expert prefetching and cache-aware routing.
ExpertFlow continuously adjusts its prediction horizon for expert activation by
leveraging runtime statistics such as transfer bandwidth, parameter
dimensionality, and model feedback signals. Furthermore, it incorporates a
hybrid cross-layer prediction scheme that fuses pregating information with
intermediate computational states to anticipate future expert needs. By
adaptively refining prefetching decisions and aligning them with actual usage
behavior, ExpertFlow effectively decreases cache misses and removes latency
caused by expert swap-ins. Our evaluation demonstrates that ExpertFlow reduces
model stall time to less than 0.1% of the baseline, highlighting its capability
to optimize MoE inference under stringent memory constraints.

</details>
