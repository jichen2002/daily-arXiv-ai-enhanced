<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 183]
- [cs.NI](#cs.NI) [Total: 16]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 62]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.SE](#cs.SE) [Total: 42]
- [cs.DC](#cs.DC) [Total: 14]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.AI](#cs.AI) [Total: 55]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Generative human motion mimicking through feature extraction in denoising diffusion settings](https://arxiv.org/abs/2511.00011)
*Alexander Okupnik,Johannes Schneider,Kyriakos Flouris*

Main category: cs.CV

TL;DR: 该研究构建了一个基于MoCap数据的交互模型，结合扩散模型等技术生成创造性舞蹈运动，为AI舞蹈互动提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 探索通过舞蹈这一人类表达的原始形式，补充当前大型语言模型在具身互动上的不足，实现创造性的人机互动。

Method: 基于运动捕捉（MoCap）数据构建交互模型，结合两种扩散模型、运动修复和运动风格迁移技术，利用单人运动数据和高层次特征生成运动表示。

Result: 通过定量评估生成样本与测试集的特征分布收敛性，证明了模型在生成多样且现实的运动表示方面的成功。

Conclusion: 该模型通过结合扩散模型、运动修复和运动风格迁移技术，生成了既时间连贯又响应选定运动参考的运动表示，为创造性舞蹈AI互动提供了初步探索。

Abstract: Recent success with large language models has sparked a new wave of verbal
human-AI interaction. While such models support users in a variety of creative
tasks, they lack the embodied nature of human interaction. Dance, as a primal
form of human expression, is predestined to complement this experience. To
explore creative human-AI interaction exemplified by dance, we build an
interactive model based on motion capture (MoCap) data. It generates an
artificial other by partially mimicking and also "creatively" enhancing an
incoming sequence of movement data. It is the first model, which leverages
single-person motion data and high level features in order to do so and, thus,
it does not rely on low level human-human interaction data. It combines ideas
of two diffusion models, motion inpainting, and motion style transfer to
generate movement representations that are both temporally coherent and
responsive to a chosen movement reference. The success of the model is
demonstrated by quantitatively assessing the convergence of the feature
distribution of the generated samples and the test set which serves as
simulating the human performer. We show that our generations are first steps to
creative dancing with AI as they are both diverse showing various deviations
from the human partner while appearing realistic.

</details>


### [2] [Deep Learning Models for Coral Bleaching Classification in Multi-Condition Underwater Image Datasets](https://arxiv.org/abs/2511.00021)
*Julio Jerison E. Macrohon,Gordon Hung*

Main category: cs.CV

TL;DR: 本研究提出了一种基于机器学习的珊瑚白化分类系统，比较了ResNet、ViT和CNN三种模型，CNN以88%的准确率表现最佳，为珊瑚礁自动监测提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 珊瑚礁是海洋生态系统的重要组成部分，但面临污染、海洋酸化和海水温度异常等日益严重的威胁，因此高效的保护和监测变得极为紧迫。

Method: 本研究采用了三种先进的机器学习模型（ResNet、ViT和CNN），并基于全球多样化的数据集（包括健康和白化珊瑚样本，涵盖不同环境条件如深海、沼泽和沿海区域）进行了基准测试和比较。通过全面的超参数调优，CNN模型表现最佳。

Result: CNN模型在超参数调优后达到了88%的最高准确率，优于其他两种模型（ResNet和ViT）。

Conclusion: 本研究为珊瑚礁的自动监测提供了重要见解，并全面分析了最常用的计算机视觉模型。CNN模型在超参数调优后达到了88%的最高准确率，优于现有基准。

Abstract: Coral reefs support numerous marine organisms and are an important source of
coastal protection from storms and floods, representing a major part of marine
ecosystems. However coral reefs face increasing threats from pollution, ocean
acidification, and sea temperature anomalies, making efficient protection and
monitoring heavily urgent. Therefore, this study presents a novel
machine-learning-based coral bleaching classification system based on a diverse
global dataset with samples of healthy and bleached corals under varying
environmental conditions, including deep seas, marshes, and coastal zones. We
benchmarked and compared three state-of-the-art models: Residual Neural Network
(ResNet), Vision Transformer (ViT), and Convolutional Neural Network (CNN).
After comprehensive hyperparameter tuning, the CNN model achieved the highest
accuracy of 88%, outperforming existing benchmarks. Our findings offer
important insights into autonomous coral monitoring and present a comprehensive
analysis of the most widely used computer vision models.

</details>


### [3] [Automating Coral Reef Fish Family Identification on Video Transects Using a YOLOv8-Based Deep Learning Pipeline](https://arxiv.org/abs/2511.00022)
*Jules Gerard,Leandro Di Bella,Filip Huyghe,Marc Kochzius*

Main category: cs.CV

TL;DR: 研究评估了基于YOLOv8的深度学习管道，用于自动化西印度洋珊瑚礁鱼类监测，展示了其作为传统方法补充的潜力。


<details>
  <summary>Details</summary>
Motivation: 西印度洋的珊瑚礁监测受限于水下视觉普查的劳动力需求。

Method: 使用基于YOLOv8的深度学习管道，对肯尼亚和坦桑尼亚的视频样带进行家族级别鱼类识别。

Result: 最佳模型的mAP@0.5达到0.52，对丰富家族识别准确率高，但对稀有或复杂类群的检测较弱。

Conclusion: 该研究展示了深度学习作为传统珊瑚礁监测方法可扩展补充的潜力。

Abstract: Coral reef monitoring in the Western Indian Ocean is limited by the labor
demands of underwater visual censuses. This work evaluates a YOLOv8-based deep
learning pipeline for automating family-level fish identification from video
transects collected in Kenya and Tanzania. A curated dataset of 24 families was
tested under different configurations, providing the first region-specific
benchmark for automated reef fish monitoring in the Western Indian Ocean. The
best model achieved mAP@0.5 of 0.52, with high accuracy for abundant families
but weaker detection of rare or complex taxa. Results demonstrate the potential
of deep learning as a scalable complement to traditional monitoring methods.

</details>


### [4] [Mutual Information guided Visual Contrastive Learning](https://arxiv.org/abs/2511.00028)
*Hanyang Chen,Yanchao Yang*

Main category: cs.CV

TL;DR: 本文提出了一种基于互信息的数据增强方法，通过选择高互信息场景补丁作为正样本，提升了表示学习的泛化能力，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的数据增强方法（如颜色抖动）依赖于人工假设或工程，可能不是最优的。本文探索通过互信息选择训练数据，以提高特征在开放环境中的泛化能力。

Method: 提出了一种基于真实世界分布计算的互信息来选择训练数据的方法，特别是选择在自然扰动下表现出高互信息的场景补丁作为对比学习的正样本。

Result: 在多个基准测试和先进框架中验证了方法的有效性。

Conclusion: 基于互信息的数据增强方法在多个先进的表示学习框架中表现出有效性，为未来研究提供了有前景的方向。

Abstract: Representation learning methods utilizing the InfoNCE loss have demonstrated
considerable capacity in reducing human annotation effort by training invariant
neural feature extractors. Although different variants of the training
objective adhere to the information maximization principle between the data and
learned features, data selection and augmentation still rely on human
hypotheses or engineering, which may be suboptimal. For instance, data
augmentation in contrastive learning primarily focuses on color jittering,
aiming to emulate real-world illumination changes. In this work, we investigate
the potential of selecting training data based on their mutual information
computed from real-world distributions, which, in principle, should endow the
learned features with better generalization when applied in open environments.
Specifically, we consider patches attached to scenes that exhibit high mutual
information under natural perturbations, such as color changes and motion, as
positive samples for learning with contrastive loss. We evaluate the proposed
mutual-information-informed data augmentation method on several benchmarks
across multiple state-of-the-art representation learning frameworks,
demonstrating its effectiveness and establishing it as a promising direction
for future research.

</details>


### [5] [Object-Aware 4D Human Motion Generation](https://arxiv.org/abs/2511.00248)
*Shurui Gui,Deep Anil Patel,Xiner Li,Martin Renqiang Min*

Main category: cs.CV

TL;DR: 论文提出了一种零样本的物体感知4D人类运动生成框架，结合3D高斯表示和运动扩散先验，无需重新训练即可生成物理合理的运动。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型生成的视频存在不真实的形变、语义违规和物理不一致问题，主要是由于缺乏3D物理先验。

Method: 论文提出了一种基于3D高斯表示和运动扩散先验的物体感知4D人类运动生成框架，结合了大型语言模型的空间和提示语义信息，通过Motion Diffusion Score Distillation Sampling (MSDS)进行空间感知的运动优化。

Result: 实验表明，该框架能够生成自然且物理上合理的人类运动，尊重3D空间上下文，为真实的4D生成提供了可扩展的解决方案。

Conclusion: 该论文提出的框架通过结合3D高斯表示和运动扩散先验，成功生成了自然且物理上合理的4D人类运动，无需重新训练即可泛化到分布外的物体感知运动。

Abstract: Recent advances in video diffusion models have enabled the generation of
high-quality videos. However, these videos still suffer from unrealistic
deformations, semantic violations, and physical inconsistencies that are
largely rooted in the absence of 3D physical priors. To address these
challenges, we propose an object-aware 4D human motion generation framework
grounded in 3D Gaussian representations and motion diffusion priors. With
pre-generated 3D humans and objects, our method, Motion Score Distilled
Interaction (MSDI), employs the spatial and prompt semantic information in
large language models (LLMs) and motion priors through the proposed Motion
Diffusion Score Distillation Sampling (MSDS). The combination of MSDS and LLMs
enables our spatial-aware motion optimization, which distills score gradients
from pre-trained motion diffusion models, to refine human motion while
respecting object and semantic constraints. Unlike prior methods requiring
joint training on limited interaction datasets, our zero-shot approach avoids
retraining and generalizes to out-of-distribution object aware human motions.
Experiments demonstrate that our framework produces natural and physically
plausible human motions that respect 3D spatial context, offering a scalable
solution for realistic 4D generation.

</details>


### [6] [Benchmarking Federated Learning Frameworks for Medical Imaging Deployment: A Comparative Study of NVIDIA FLARE, Flower, and Owkin Substra](https://arxiv.org/abs/2511.00037)
*Riya Gupta,Alexander Chowdhury,Sahil Nalawade*

Main category: cs.CV

TL;DR: 研究评估了三种联邦学习框架（NVIDIA FLARE、Flower、Owkin Substra）在医疗影像应用中的表现，发现各自在不同领域有优势。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）已成为医疗AI中的变革性范式，本研究旨在评估三种主流FL框架在真实医疗影像应用中的适用性。

Method: 使用PathMNIST数据集，评估了模型性能、收敛效率、通信开销、可扩展性和开发者体验。

Result: NVIDIA FLARE在生产可扩展性上表现最优，Flower在原型设计和学术研究上更具灵活性，Owkin Substra在隐私和合规性方面表现突出。

Conclusion: 每个联邦学习框架（NVIDIA FLARE、Flower、Owkin Substra）在不同应用场景中展现出各自的优势，强调了它们在医疗环境中的实际部署价值。

Abstract: Federated Learning (FL) has emerged as a transformative paradigm in medical
AI, enabling collaborative model training across institutions without direct
data sharing. This study benchmarks three prominent FL frameworks NVIDIA FLARE,
Flower, and Owkin Substra to evaluate their suitability for medical imaging
applications in real-world settings. Using the PathMNIST dataset, we assess
model performance, convergence efficiency, communication overhead, scalability,
and developer experience. Results indicate that NVIDIA FLARE offers superior
production scalability, Flower provides flexibility for prototyping and
academic research, and Owkin Substra demonstrates exceptional privacy and
compliance features. Each framework exhibits strengths optimized for distinct
use cases, emphasizing their relevance to practical deployment in healthcare
environments.

</details>


### [7] [Oitijjo-3D: Generative AI Framework for Rapid 3D Heritage Reconstruction from Street View Imagery](https://arxiv.org/abs/2511.00362)
*Momen Khandoker Ope,Akif Islam,Mohd Ruhul Ameen,Abu Saleh Musa Miah,Md Rashedul Islam,Jungpil Shin*

Main category: cs.CV

TL;DR: Oitijjo-3D 是一个免费生成式 AI 框架，利用公开图像快速重建文化遗产的 3D 模型，降低了传统方法的高成本和技术依赖。


<details>
  <summary>Details</summary>
Motivation: 解决孟加拉国文化遗产修复中资源和技术匮乏的双重挑战，传统 3D 数字化方法成本高且依赖专家，难以在发展中国家实施。

Method: 采用基于 Google Street View 图像的两阶段流程：1) 使用 Gemini 2.5 Flash Image 进行多模态视觉推理以合成结构-纹理；2) 通过 Hexagen 实现神经图像到 3D 的几何恢复。

Result: Oitijjo-3D 能够在秒级时间内生成逼真且度量一致的 3D 模型，显著提升了速度并降低了门槛，实验证明了其在视觉和结构保真度上的有效性。

Conclusion: Oitijjo-3D 通过 AI 技术降低了文化遗址数字化的经济和技术门槛，为资源有限的国家提供了一种社区驱动的文化遗产保护新方法。

Abstract: Cultural heritage restoration in Bangladesh faces a dual challenge of limited
resources and scarce technical expertise. Traditional 3D digitization methods,
such as photogrammetry or LiDAR scanning, require expensive hardware, expert
operators, and extensive on-site access, which are often infeasible in
developing contexts. As a result, many of Bangladesh's architectural treasures,
from the Paharpur Buddhist Monastery to Ahsan Manzil, remain vulnerable to
decay and inaccessible in digital form. This paper introduces Oitijjo-3D, a
cost-free generative AI framework that democratizes 3D cultural preservation.
By using publicly available Google Street View imagery, Oitijjo-3D reconstructs
faithful 3D models of heritage structures through a two-stage pipeline -
multimodal visual reasoning with Gemini 2.5 Flash Image for structure-texture
synthesis, and neural image-to-3D generation through Hexagen for geometry
recovery. The system produces photorealistic, metrically coherent
reconstructions in seconds, achieving significant speedups compared to
conventional Structure-from-Motion pipelines, without requiring any specialized
hardware or expert supervision. Experiments on landmarks such as Ahsan Manzil,
Choto Sona Mosque, and Paharpur demonstrate that Oitijjo-3D preserves both
visual and structural fidelity while drastically lowering economic and
technical barriers. By turning open imagery into digital heritage, this work
reframes preservation as a community-driven, AI-assisted act of cultural
continuity for resource-limited nations.

</details>


### [8] [Enhancing rice leaf images: An overview of image denoising techniques](https://arxiv.org/abs/2511.00046)
*Rupjyoti Chutia,Dibya Jyoti Bora*

Main category: cs.CV

TL;DR: 该研究比较了多种图像去噪方法结合CLAHE在稻叶图像上的效果，结果表明该方法能有效提升图像质量，为农业研究提供实用工具。


<details>
  <summary>Details</summary>
Motivation: 稻叶分析中的图像增强对于疾病检测、营养缺乏评估和生长分析至关重要，去噪和对比度增强是主要步骤。

Method: 本研究对著名的图像去噪方法结合CLAHE（对比度受限自适应直方图均衡化）进行了广泛的比较研究，实验在稻叶图像数据集上进行，并使用多种指标全面测试增强方法。

Result: 实验结果表明，该方法能有效提升稻叶图像的质量，并为后续任务（如分割、特征提取和分类）提供更可靠的数据。

Conclusion: 该研究为评估数字图像处理方法的效果提供了坚实基础，并为农业研究及其他领域的未来应用提供了有用见解。

Abstract: Digital image processing involves the systematic handling of images using
advanced computer algorithms, and has gained significant attention in both
academic and practical fields. Image enhancement is a crucial preprocessing
stage in the image-processing chain, improving image quality and emphasizing
features. This makes subsequent tasks (segmentation, feature extraction,
classification) more reliable. Image enhancement is essential for rice leaf
analysis, aiding in disease detection, nutrient deficiency evaluation, and
growth analysis. Denoising followed by contrast enhancement are the primary
steps. Image filters, generally employed for denoising, transform or enhance
visual characteristics like brightness, contrast, and sharpness, playing a
crucial role in improving overall image quality and enabling the extraction of
useful information. This work provides an extensive comparative study of
well-known image-denoising methods combined with CLAHE (Contrast Limited
Adaptive Histogram Equalization) for efficient denoising of rice leaf images.
The experiments were performed on a rice leaf image dataset to ensure the data
is relevant and representative. Results were examined using various metrics to
comprehensively test enhancement methods. This approach provides a strong basis
for assessing the effectiveness of methodologies in digital image processing
and reveals insights useful for future adaptation in agricultural research and
other domains.

</details>


### [9] [GraphGeo: Multi-Agent Debate Framework for Visual Geo-localization with Heterogeneous Graph Neural Networks](https://arxiv.org/abs/2511.00908)
*Heng Zheng,Yuling Shi,Xiaodong Gu,Haochen You,Zijian Zhang,Lubin Gan,Hao Zhang,Wenjun Huang,Jin Huang*

Main category: cs.CV

TL;DR: GraphGeo 是一种基于异构图神经网络的多智能体辩论框架，通过结构化辩论提升视觉地理定位准确性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统检索方法受限于数据库覆盖和质量，而现有的大型视觉语言模型（LVLMs）在处理多样化地理区域和复杂场景时表现不佳。多智能体系统虽通过协作提升性能，但缺乏有效处理冲突预测的机制。

Method: 提出 GraphGeo，一种基于异构图神经网络的多智能体辩论框架，通过类型边模拟多样化的辩论关系，包括支持性合作、竞争性论证和知识转移。采用双级辩论机制，结合节点级精炼和边级论证建模，以及跨级拓扑精炼策略。

Result: 在多个基准测试中，GraphGeo 显著优于现有最先进方法。

Conclusion: GraphGeo 框架通过结构化的多智能体辩论，将认知冲突转化为提升的地理定位准确性，显著优于现有方法。

Abstract: Visual geo-localization requires extensive geographic knowledge and
sophisticated reasoning to determine image locations without GPS metadata.
Traditional retrieval methods are constrained by database coverage and quality.
Recent Large Vision-Language Models (LVLMs) enable direct location reasoning
from image content, yet individual models struggle with diverse geographic
regions and complex scenes. Existing multi-agent systems improve performance
through model collaboration but treat all agent interactions uniformly. They
lack mechanisms to handle conflicting predictions effectively. We propose
\textbf{GraphGeo}, a multi-agent debate framework using heterogeneous graph
neural networks for visual geo-localization. Our approach models diverse debate
relationships through typed edges, distinguishing supportive collaboration,
competitive argumentation, and knowledge transfer. We introduce a dual-level
debate mechanism combining node-level refinement and edge-level argumentation
modeling. A cross-level topology refinement strategy enables co-evolution
between graph structure and agent representations. Experiments on multiple
benchmarks demonstrate GraphGeo significantly outperforms state-of-the-art
methods. Our framework transforms cognitive conflicts between agents into
enhanced geo-localization accuracy through structured debate.

</details>


### [10] [Which LiDAR scanning pattern is better for roadside perception: Repetitive or Non-repetitive?](https://arxiv.org/abs/2511.00060)
*Zhiqi Qi,Runxin Zhao,Hanyang Zhuang,Chunxiang Wang,Ming Yang*

Main category: cs.CV

TL;DR: 研究分析了不同LiDAR扫描模式对路侧感知性能的影响，发现非重复扫描LiDAR在性价比上具有优势，并发布了'InfraLiDARs' Benchmark'数据集。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探讨不同LiDAR扫描模式（如传统重复扫描与新兴非重复扫描）在路侧感知中对物体检测性能的深远影响，填补了这一领域的空白。

Method: 利用CARLA仿真环境中收集的'InfraLiDARs' Benchmark'数据集，对两种LiDAR扫描模式（重复与非重复扫描）进行了全面的统计分析，并评估了它们对多种领先3D物体检测算法性能的影响。

Result: 研究发现非重复扫描LiDAR与128线重复扫描LiDAR在各种场景下表现出相当的检测性能，尽管非重复扫描LiDAR的感知范围有限，但其低成本使其成为性价比较高的选择。

Conclusion: 本研究为路侧感知系统提供了关于LiDAR扫描模式和兼容算法选择的实用见解，并公开发布了'InfraLiDARs' Benchmark'数据集以促进进一步研究。

Abstract: LiDAR-based roadside perception is a cornerstone of advanced Intelligent
Transportation Systems (ITS). While considerable research has addressed optimal
LiDAR placement for infrastructure, the profound impact of differing LiDAR
scanning patterns on perceptual performance remains comparatively
under-investigated. The inherent nature of various scanning modes - such as
traditional repetitive (mechanical/solid-state) versus emerging non-repetitive
(e.g. prism-based) systems - leads to distinct point cloud distributions at
varying distances, critically dictating the efficacy of object detection and
overall environmental understanding. To systematically investigate these
differences in infrastructure-based contexts, we introduce the "InfraLiDARs'
Benchmark," a novel dataset meticulously collected in the CARLA simulation
environment using concurrently operating infrastructure-based LiDARs exhibiting
both scanning paradigms. Leveraging this benchmark, we conduct a comprehensive
statistical analysis of the respective LiDAR scanning abilities and evaluate
the impact of these distinct patterns on the performance of various leading 3D
object detection algorithms. Our findings reveal that non-repetitive scanning
LiDAR and the 128-line repetitive LiDAR were found to exhibit comparable
detection performance across various scenarios. Despite non-repetitive LiDAR's
limited perception range, it's a cost-effective option considering its low
price. Ultimately, this study provides insights for setting up roadside
perception system with optimal LiDAR scanning patterns and compatible
algorithms for diverse roadside applications, and publicly releases the
"InfraLiDARs' Benchmark" dataset to foster further research.

</details>


### [11] [World Simulation with Video Foundation Models for Physical AI](https://arxiv.org/abs/2511.00062)
*NVIDIA,:,Arslan Ali,Junjie Bai,Maciej Bala,Yogesh Balaji,Aaron Blakeman,Tiffany Cai,Jiaxin Cao,Tianshi Cao,Elizabeth Cha,Yu-Wei Chao,Prithvijit Chattopadhyay,Mike Chen,Yongxin Chen,Yu Chen,Shuai Cheng,Yin Cui,Jenna Diamond,Yifan Ding,Jiaojiao Fan,Linxi Fan,Liang Feng,Francesco Ferroni,Sanja Fidler,Xiao Fu,Ruiyuan Gao,Yunhao Ge,Jinwei Gu,Aryaman Gupta,Siddharth Gururani,Imad El Hanafi,Ali Hassani,Zekun Hao,Jacob Huffman,Joel Jang,Pooya Jannaty,Jan Kautz,Grace Lam,Xuan Li,Zhaoshuo Li,Maosheng Liao,Chen-Hsuan Lin,Tsung-Yi Lin,Yen-Chen Lin,Huan Ling,Ming-Yu Liu,Xian Liu,Yifan Lu,Alice Luo,Qianli Ma,Hanzi Mao,Kaichun Mo,Seungjun Nah,Yashraj Narang,Abhijeet Panaskar,Lindsey Pavao,Trung Pham,Morteza Ramezanali,Fitsum Reda,Scott Reed,Xuanchi Ren,Haonan Shao,Yue Shen,Stella Shi,Shuran Song,Bartosz Stefaniak,Shangkun Sun,Shitao Tang,Sameena Tasmeen,Lyne Tchapmi,Wei-Cheng Tseng,Jibin Varghese,Andrew Z. Wang,Hao Wang,Haoxiang Wang,Heng Wang,Ting-Chun Wang,Fangyin Wei,Jiashu Xu,Dinghao Yang,Xiaodong Yang,Haotian Ye,Seonghyeon Ye,Xiaohui Zeng,Jing Zhang,Qinsheng Zhang,Kaiwen Zheng,Andrew Zhu,Yuke Zhu*

Main category: cs.CV

TL;DR: 介绍了新一代物理AI模型[Cosmos-Predict2.5]和[Cosmos-Transfer2.5]，通过流式架构和强化学习优化，显著提升视频生成质量和控制能力，并开源以促进研究。


<details>
  <summary>Details</summary>
Motivation: 提升视频生成质量与指令对齐，支持更可靠的合成数据生成、策略评估以及机器人闭环模拟。

Method: 基于流式架构，结合[Cosmos-Reason1]模型进行文本 grounding 和世界模拟的精细控制，并通过强化学习后训练优化。

Result: [Cosmos-Predict2.5]在视频质量和指令对齐上显著优于前代模型，[Cosmos-Transfer2.5]虽体积更小但生成保真度更高。

Conclusion: [Cosmos-Predict2.5]和[Cosmos-Transfer2.5]的发布为物理AI领域的具身智能提供了多功能工具，并通过开源资源降低了采用门槛。

Abstract: We introduce [Cosmos-Predict2.5], the latest generation of the Cosmos World
Foundation Models for Physical AI. Built on a flow-based architecture,
[Cosmos-Predict2.5] unifies Text2World, Image2World, and Video2World generation
in a single model and leverages [Cosmos-Reason1], a Physical AI vision-language
model, to provide richer text grounding and finer control of world simulation.
Trained on 200M curated video clips and refined with reinforcement
learning-based post-training, [Cosmos-Predict2.5] achieves substantial
improvements over [Cosmos-Predict1] in video quality and instruction alignment,
with models released at 2B and 14B scales. These capabilities enable more
reliable synthetic data generation, policy evaluation, and closed-loop
simulation for robotics and autonomous systems. We further extend the family
with [Cosmos-Transfer2.5], a control-net style framework for Sim2Real and
Real2Real world translation. Despite being 3.5$\times$ smaller than
[Cosmos-Transfer1], it delivers higher fidelity and robust long-horizon video
generation. Together, these advances establish [Cosmos-Predict2.5] and
[Cosmos-Transfer2.5] as versatile tools for scaling embodied intelligence. To
accelerate research and deployment in Physical AI, we release source code,
pretrained checkpoints, and curated benchmarks under the NVIDIA Open Model
License at https://github.com/nvidia-cosmos/cosmos-predict2.5 and
https://github.com/nvidia-cosmos/cosmos-transfer2.5. We hope these open
resources lower the barrier to adoption and foster innovation in building the
next generation of embodied intelligence.

</details>


### [12] [Gesture Generation (Still) Needs Improved Human Evaluation Practices: Insights from a Community-Driven State-of-the-Art Benchmark](https://arxiv.org/abs/2511.01233)
*Rajmund Nagy,Hendric Voss,Thanh Hoang-Minh,Mihail Tsakov,Teodor Nikolov,Zeyi Zhang,Tenglong Ao,Sicheng Yang,Shaoli Huang,Yongkang Cheng,M. Hamza Mughal,Rishabh Dabral,Kiran Chhatre,Christian Theobalt,Libin Liu,Stefan Kopp,Rachel McDonnell,Michael Neff,Taras Kucherenko,Youngwoo Yoon,Gustav Eje Henter*

Main category: cs.CV

TL;DR: 论文提出标准化手势生成评估协议，发现新模型不一定更好，且现有高运动真实感声明可能不成立，呼吁采用解耦评估以推动领域进步。


<details>
  <summary>Details</summary>
Motivation: 自动化语音驱动3D手势生成领域缺乏标准化评估，导致无法比较不同方法或确定当前技术水平，因此需要解决评估设计的常见缺陷并标准化未来用户研究。

Method: 引入了一个针对BEAT2运动捕捉数据集的人类评估协议，并进行了大规模众包评估，比较了六个手势生成模型的运动真实性和语音-手势对齐性。

Result: 评估结果显示：1）新模型不一定优于早期方法；2）已发表的高运动真实感或语音-手势对齐声明在严格评估下可能不成立；3）需采用解耦的运动质量和多模态对齐评估以准确基准测试。

Conclusion: 论文提出了一个详细的人类评估协议，用于标准化手势生成领域的评估设计，并通过大规模众包评估对六个最新手势生成模型进行了排名，发现新模型并不总是优于早期方法，且现有高运动真实感或多模态对齐的声明在严格评估下可能不成立。

Abstract: We review human evaluation practices in automated, speech-driven 3D gesture
generation and find a lack of standardisation and frequent use of flawed
experimental setups. This leads to a situation where it is impossible to know
how different methods compare, or what the state of the art is. In order to
address common shortcomings of evaluation design, and to standardise future
user studies in gesture-generation works, we introduce a detailed human
evaluation protocol for the widely-used BEAT2 motion-capture dataset. Using
this protocol, we conduct large-scale crowdsourced evaluation to rank six
recent gesture-generation models -- each trained by its original authors --
across two key evaluation dimensions: motion realism and speech-gesture
alignment. Our results provide strong evidence that 1) newer models do not
consistently outperform earlier approaches; 2) published claims of high motion
realism or speech-gesture alignment may not hold up under rigorous evaluation;
and 3) the field must adopt disentangled assessments of motion quality and
multimodal alignment for accurate benchmarking in order to make progress.
Finally, in order to drive standardisation and enable new evaluation research,
we will release five hours of synthetic motion from the benchmarked models;
over 750 rendered video stimuli from the user studies -- enabling new
evaluations without model reimplementation required -- alongside our
open-source rendering script, and the 16,000 pairwise human preference votes
collected for our benchmark.

</details>


### [13] [Habitat and Land Cover Change Detection in Alpine Protected Areas: A Comparison of AI Architectures](https://arxiv.org/abs/2511.00073)
*Harald Kristen,Daniel Kulmer,Manuela Hirschmugl*

Main category: cs.CV

TL;DR: 研究使用深度学习对高山栖息地变化进行检测，比较了分类后与直接变化检测方法，结果显示GFMs在复杂环境中表现优于传统方法，但准确率仍较低。未来将优化后处理方法。


<details>
  <summary>Details</summary>
Motivation: 高山生态系统的快速气候变化和其他干扰需要频繁的栖息地监测，但手动测绘的成本过高，无法满足时间分辨率要求。

Method: 比较了两种范式：分类后变化检测（CD）与直接CD。对于分类后CD，评估了GFMs Prithvi-EO-2.0和Clay v1.0与U-Net CNNs；对于直接CD，测试了transformer ChangeViT与U-Net基线。使用了高分辨率多模态数据（RGB、NIR、LiDAR、地形属性）。

Result: Clay v1.0在多类栖息地变化中达到51%的总体准确率，U-Net为41%；两者在二元变化检测中均达到67%。直接CD在二元检测中IoU更高（0.53 vs 0.35），但多类检测准确率仅为28%。LiDAR集成将语义分割准确率从30%提高到50%。

Conclusion: 尽管整体准确率低于同质景观，但研究结果反映了复杂高山栖息地的真实性能。未来工作将整合基于对象的后处理和物理约束以增强适用性。

Abstract: Rapid climate change and other disturbances in alpine ecosystems demand
frequent habitat monitoring, yet manual mapping remains prohibitively expensive
for the required temporal resolution. We employ deep learning for change
detection using long-term alpine habitat data from Gesaeuse National Park,
Austria, addressing a major gap in applying geospatial foundation models (GFMs)
to complex natural environments with fuzzy class boundaries and highly
imbalanced classes. We compare two paradigms: post-classification change
detection (CD) versus direct CD. For post-classification CD, we evaluate GFMs
Prithvi-EO-2.0 and Clay v1.0 against U-Net CNNs; for direct CD, we test the
transformer ChangeViT against U-Net baselines. Using high-resolution multimodal
data (RGB, NIR, LiDAR, terrain attributes) covering 4,480 documented changes
over 15.3 km2, results show Clay v1.0 achieves 51% overall accuracy versus
U-Net's 41% for multi-class habitat change, while both reach 67% for binary
change detection. Direct CD yields superior IoU (0.53 vs 0.35) for binary but
only 28% accuracy for multi-class detection. Cross-temporal evaluation reveals
GFM robustness, with Clay maintaining 33% accuracy on 2020 data versus U-Net's
23%. Integrating LiDAR improves semantic segmentation from 30% to 50% accuracy.
Although overall accuracies are lower than in more homogeneous landscapes, they
reflect realistic performance for complex alpine habitats. Future work will
integrate object-based post-processing and physical constraints to enhance
applicability.

</details>


### [14] [HMVLM: Human Motion-Vision-Lanuage Model via MoE LoRA](https://arxiv.org/abs/2511.01463)
*Lei Hu,Yongjing Ye,Shihong Xia*

Main category: cs.CV

TL;DR: HMVLM通过MoE LoRA和零专家机制，解决了人体运动与文本整合中的灾难性遗忘和姿势表示问题，在多任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决人体运动与文本之间的模态差距以及自回归兼容的姿势表示在异构下游任务中的通用性问题。

Method: 基于Mixture of Expert Low-Rank Adaption（MoE LoRA）策略，通过门控网络动态分配LoRA专家权重，并采用身体部位特定标记化方法提升空间分辨率。

Result: 实验表明，该方法在指令微调中有效减轻了知识遗忘，并在多样化的人体运动任务中取得了显著性能。

Conclusion: HMVLM框架通过MoE LoRA策略和零专家机制有效缓解了指令微调过程中的灾难性遗忘问题，同时在多样化的人体运动下游任务中表现出色。

Abstract: The expansion of instruction-tuning data has enabled foundation language
models to exhibit improved instruction adherence and superior performance
across diverse downstream tasks. Semantically-rich 3D human motion is being
progressively integrated with these foundation models to enhance multimodal
understanding and cross-modal generation capabilities. However, the modality
gap between human motion and text raises unresolved concerns about catastrophic
forgetting during this integration. In addition, developing
autoregressive-compatible pose representations that preserve generalizability
across heterogeneous downstream tasks remains a critical technical barrier. To
address these issues, we propose the Human Motion-Vision-Language Model
(HMVLM), a unified framework based on the Mixture of Expert Low-Rank
Adaption(MoE LoRA) strategy. The framework leverages the gating network to
dynamically allocate LoRA expert weights based on the input prompt, enabling
synchronized fine-tuning of multiple tasks. To mitigate catastrophic forgetting
during instruction-tuning, we introduce a novel zero expert that preserves the
pre-trained parameters for general linguistic tasks. For pose representation,
we implement body-part-specific tokenization by partitioning the human body
into different joint groups, enhancing the spatial resolution of the
representation. Experiments show that our method effectively alleviates
knowledge forgetting during instruction-tuning and achieves remarkable
performance across diverse human motion downstream tasks.

</details>


### [15] [LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation](https://arxiv.org/abs/2511.00090)
*Huanlin Gao,Ping Chen,Fuyuan Shi,Chao Tan,Zhaoxiang Liu,Fang Zhao,Kai Wang,Shiguo Lian*

Main category: cs.CV

TL;DR: LeMiCa是一种无需训练的视频生成加速框架，通过优化全局误差显著提升生成质量和速度，同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 现有的缓存策略主要关注减少局部启发式误差，但往往忽略了全局误差的累积，导致加速视频与原始视频之间存在明显的内容退化问题。

Method: 通过将缓存调度建模为带有误差加权边的有向图，并引入字典序极小极大路径优化策略，明确限制最坏情况路径误差，从而显著提高生成帧间全局内容和风格的一致性。

Result: 在多个文本到视频基准测试中，LeMiCa在推理速度和生成质量上均实现了双重提升，尤其在Latte模型上实现了2.9倍加速，并在Open-Sora上达到了0.05的LPIPS分数，优于先前的缓存技术。

Conclusion: LeMiCa作为一种无需训练且高效的加速框架，显著提升了基于扩散的视频生成的推理速度和生成质量，同时保持了最小的感知质量退化。该方法为未来高效可靠的视频合成研究奠定了坚实基础。

Abstract: We present LeMiCa, a training-free and efficient acceleration framework for
diffusion-based video generation. While existing caching strategies primarily
focus on reducing local heuristic errors, they often overlook the accumulation
of global errors, leading to noticeable content degradation between accelerated
and original videos. To address this issue, we formulate cache scheduling as a
directed graph with error-weighted edges and introduce a Lexicographic Minimax
Path Optimization strategy that explicitly bounds the worst-case path error.
This approach substantially improves the consistency of global content and
style across generated frames. Extensive experiments on multiple text-to-video
benchmarks demonstrate that LeMiCa delivers dual improvements in both inference
speed and generation quality. Notably, our method achieves a 2.9x speedup on
the Latte model and reaches an LPIPS score of 0.05 on Open-Sora, outperforming
prior caching techniques. Importantly, these gains come with minimal perceptual
quality degradation, making LeMiCa a robust and generalizable paradigm for
accelerating diffusion-based video generation. We believe this approach can
serve as a strong foundation for future research on efficient and reliable
video synthesis. Our code is available at :https://github.com/UnicomAI/LeMiCa

</details>


### [16] [Example-Based Feature Painting on Textures](https://arxiv.org/abs/2511.01513)
*Andrei-Timotei Ardelean,Tim Weyrich*

Main category: cs.CV

TL;DR: 提出一种无监督学习方法，自动检测并模拟纹理局部特征（如污渍、破损），实现交互式纹理编辑和生成。


<details>
  <summary>Details</summary>
Motivation: 自然界中纹理的局部特征（如污渍、破损）普遍存在，但在合成过程中常被忽略。为了生成更真实的纹理，需要自动捕捉并模拟这些特征。

Method: 采用基于学习的方法，利用无标记示例进行无监督异常检测，自动聚类纹理特征，并指导条件图像生成。

Result: 开发了一个从图像集到生成模型的完整流程，支持交互式纹理编辑和特征绘制，算法具有通用性。

Conclusion: 该系统通过无监督异常检测和自动聚类技术，实现了对具有局部特征纹理的自动编辑和生成，无需人工标注。扩散编辑和无限静态纹理生成算法具有广泛适用性。

Abstract: In this work, we propose a system that covers the complete workflow for
achieving controlled authoring and editing of textures that present distinctive
local characteristics. These include various effects that change the surface
appearance of materials, such as stains, tears, holes, abrasions,
discoloration, and more. Such alterations are ubiquitous in nature, and
including them in the synthesis process is crucial for generating realistic
textures. We introduce a novel approach for creating textures with such
blemishes, adopting a learning-based approach that leverages unlabeled
examples. Our approach does not require manual annotations by the user;
instead, it detects the appearance-altering features through unsupervised
anomaly detection. The various textural features are then automatically
clustered into semantically coherent groups, which are used to guide the
conditional generation of images. Our pipeline as a whole goes from a small
image collection to a versatile generative model that enables the user to
interactively create and paint features on textures of arbitrary size. Notably,
the algorithms we introduce for diffusion-based editing and infinite stationary
texture generation are generic and should prove useful in other contexts as
well. Project page: https://reality.tf.fau.de/pub/ardelean2025examplebased.html

</details>


### [17] [Self-Improving Vision-Language-Action Models with Data Generation via Residual RL](https://arxiv.org/abs/2511.00091)
*Wenli Xiao,Haotian Lin,Andy Peng,Haoru Xue,Tairan He,Yuqi Xie,Fengyuan Hu,Jimmy Wu,Zhengyi Luo,Linxi "Jim" Fan,Guanya Shi,Yuke Zhu*

Main category: cs.CV

TL;DR: PLD通过残差RL和分布感知数据收集，显著提升VLA模型性能，无需依赖大量人工演示。


<details>
  <summary>Details</summary>
Motivation: 传统监督微调（SFT）依赖昂贵的人工演示，限制了VLA模型的可扩展性和泛化能力，PLD旨在解决这一问题。

Method: PLD分为三个阶段：1）训练轻量级残差执行器探测VLA模型的失败区域；2）使用混合rollout方案对齐轨迹收集与部署分布；3）通过标准SFT将精选轨迹蒸馏回通用模型。

Result: PLD在LIBERO上达到接近饱和的99%任务成功率，在SimplerEnv上提升超过50%，并在真实世界的Franka和YAM机械臂任务中实现100%成功率。

Conclusion: PLD框架通过残差强化学习和分布感知数据收集，为视觉-语言-动作（VLA）模型提供了一种可扩展的自我改进路径，显著提升了任务成功率。

Abstract: Supervised fine-tuning (SFT) has become the de facto post-training strategy
for large vision-language-action (VLA) models, but its reliance on costly human
demonstrations limits scalability and generalization. We propose Probe, Learn,
Distill (PLD), a three-stage plug-and-play framework that improves VLAs through
residual reinforcement learning (RL) and distribution-aware data collection. In
Stage 1, we train lightweight residual actors to probe failure regions of the
VLA generalist. In Stage 2, we use a hybrid rollout scheme that aligns
collected trajectories with the generalist's deployment distribution while
capturing recovery behaviors. In Stage 3, we distill the curated trajectories
back into the generalist with standard SFT. PLD achieves near-saturated 99%
task success on LIBERO, over 50% gains in SimplerEnv, and 100% success on
real-world Franka and YAM arm manipulation tasks. Ablations show that residual
probing and distribution-aware replay are key to collecting deployment-aligned
data that improves both seen and unseen tasks, offering a scalable path toward
self-improving VLA models.

</details>


### [18] [SpinalSAM-R1: A Vision-Language Multimodal Interactive System for Spine CT Segmentation](https://arxiv.org/abs/2511.00095)
*Jiaming Liu,Dingwei Fan,Junyong Zhao,Chunlin Li,Haipeng Si,Liang Sun*

Main category: cs.CV

TL;DR: SpinalSAM-R1通过结合SAM和DeepSeek-R1，优化了脊柱CT图像分割，开发了高效交互软件。


<details>
  <summary>Details</summary>
Motivation: 脊柱CT图像分割因低对比度和复杂边界而困难，现有模型如SAM在脊柱CT图像上表现受限，需高标注要求和域适应性差。

Method: 提出SpinalSAM-R1，整合了经过微调的SAM和DeepSeek-R1，采用Low-Rank Adaptation (LoRA)进行高效适配，并引入了解剖学引导的注意力机制和语义驱动的交互协议。

Result: 实验结果表明，SpinalSAM-R1在脊柱解剖结构分割上表现优异，开发的交互软件支持多种提示方式，临床操作解析准确率达94.3%，响应时间低于800毫秒。

Conclusion: SpinalSAM-R1结合了SAM和DeepSeek-R1，通过解剖学引导的注意力机制和语义驱动的交互协议，显著提升了脊柱CT图像分割的性能，并开发了交互式软件支持多种提示方式。

Abstract: The anatomical structure segmentation of the spine and adjacent structures
from computed tomography (CT) images is a key step for spinal disease diagnosis
and treatment. However, the segmentation of CT images is impeded by low
contrast and complex vertebral boundaries. Although advanced models such as the
Segment Anything Model (SAM) have shown promise in various segmentation tasks,
their performance in spinal CT imaging is limited by high annotation
requirements and poor domain adaptability. To address these limitations, we
propose SpinalSAM-R1, a multimodal vision-language interactive system that
integrates a fine-tuned SAM with DeepSeek-R1, for spine CT image segmentation.
Specifically, our SpinalSAM-R1 introduces an anatomy-guided attention mechanism
to improve spine segmentation performance, and a semantics-driven interaction
protocol powered by DeepSeek-R1, enabling natural language-guided refinement.
The SpinalSAM-R1 is fine-tuned using Low-Rank Adaptation (LoRA) for efficient
adaptation. We validate our SpinalSAM-R1 on the spine anatomical structure with
CT images. Experimental results suggest that our method achieves superior
segmentation performance. Meanwhile, we develop a PyQt5-based interactive
software, which supports point, box, and text-based prompts. The system
supports 11 clinical operations with 94.3\% parsing accuracy and sub-800 ms
response times. The software is released on
https://github.com/6jm233333/spinalsam-r1.

</details>


### [19] [A filtering scheme for confocal laser endomicroscopy (CLE)-video sequences for self-supervised learning](https://arxiv.org/abs/2511.00098)
*Nils Porsche,Flurin Müller-Diesing,Sweta Banerjee,Miguel Goncalves,Marc Aubreville*

Main category: cs.CV

TL;DR: 论文提出一种CLE视频过滤器，结合SSL预训练，显著提高模型准确率和训练效率。


<details>
  <summary>Details</summary>
Motivation: CLE图像对非专业医生难以解释，且缺乏足够标注数据导致机器学习模型过拟合，SSL可在大规模未标记数据上训练，但CLE视频帧间相关性高，导致数据分布不均。

Method: 使用四种最先进的基线网络和一个基于视觉Transformer小骨干的SSL师生网络进行评估，提出了一种CLE视频序列过滤器以减少SSL训练中的数据集冗余。

Result: 在鼻腔肿瘤和皮肤鳞状细胞癌数据集上，过滤后的SSL预训练模型测试准确率最高，分别为67.48%和73.52%，显著优于非SSL基线。

Conclusion: SSL是一种有效的CLE预训练方法，提出的CLE视频过滤器能显著提高训练效率，减少67%的训练时间。

Abstract: Confocal laser endomicroscopy (CLE) is a non-invasive, real-time imaging
modality that can be used for in-situ, in-vivo imaging and the microstructural
analysis of mucous structures. The diagnosis using CLE is, however, complicated
by images being hard to interpret for non-experienced physicians. Utilizing
machine learning as an augmentative tool would hence be beneficial, but is
complicated by the shortage of histopathology-correlated CLE imaging sequences
with respect to the plurality of patterns in this domain, leading to
overfitting of machine learning models. To overcome this, self-supervised
learning (SSL) can be employed on larger unlabeled datasets. CLE is a
video-based modality with high inter-frame correlation, leading to a
non-stratified data distribution for SSL training. In this work, we propose a
filter functionality on CLE video sequences to reduce the dataset redundancy in
SSL training and improve SSL training convergence and training efficiency. We
use four state-of-the-art baseline networks and a SSL teacher-student network
with a vision transformer small backbone for the evaluation. These networks
were evaluated on downstream tasks for a sinonasal tumor dataset and a squamous
cell carcinoma of the skin dataset. On both datasets, we found the highest test
accuracy on the filtered SSL-pretrained model, with 67.48% and 73.52%, both
considerably outperforming their non-SSL baselines. Our results show that SSL
is an effective method for CLE pretraining. Further, we show that our proposed
CLE video filter can be utilized to improve training efficiency in
self-supervised scenarios, resulting in a reduction of 67% in training time.

</details>


### [20] [FreeSliders: Training-Free, Modality-Agnostic Concept Sliders for Fine-Grained Diffusion Control in Images, Audio, and Video](https://arxiv.org/abs/2511.00103)
*Rotem Ezra,Hedi Zisling,Nimrod Berman,Ilan Naiman,Alexey Gorkor,Liran Nochumsohn,Eliya Nachmani,Omri Azencot*

Main category: cs.CV

TL;DR: FreeSliders 是一种无需训练、模态无关的方法，通过部分估计 CS 公式实现细粒度概念控制，扩展了基准并提出了新评估指标。


<details>
  <summary>Details</summary>
Motivation: 当前的 Concept Sliders (CS) 需要针对每个概念进行训练和架构特定微调，限制了新模态的可扩展性。FreeSliders 旨在解决这一问题，实现无需训练且模态无关的细粒度控制。

Method: 提出 FreeSliders，通过部分估计 CS 公式实现训练无关和模态无关的概念控制。扩展了 CS 基准至视频和音频，并提出三个评估属性和新指标。引入两阶段程序自动检测饱和点并重新参数化遍历。

Result: FreeSliders 在多模态下实现了即插即用的概念控制，超越了现有基线，并提供了可控生成的新工具。

Conclusion: FreeSliders 提供了一种完全无需训练且与模态无关的方法，通过部分估计 CS 公式在推理过程中实现细粒度概念控制。实验表明，该方法在多模态下实现了即插即用的概念控制，并超越了现有基线。

Abstract: Diffusion models have become state-of-the-art generative models for images,
audio, and video, yet enabling fine-grained controllable generation, i.e.,
continuously steering specific concepts without disturbing unrelated content,
remains challenging. Concept Sliders (CS) offer a promising direction by
discovering semantic directions through textual contrasts, but they require
per-concept training and architecture-specific fine-tuning (e.g., LoRA),
limiting scalability to new modalities. In this work we introduce FreeSliders,
a simple yet effective approach that is fully training-free and
modality-agnostic, achieved by partially estimating the CS formula during
inference. To support modality-agnostic evaluation, we extend the CS benchmark
to include both video and audio, establishing the first suite for fine-grained
concept generation control with multiple modalities. We further propose three
evaluation properties along with new metrics to improve evaluation quality.
Finally, we identify an open problem of scale selection and non-linear
traversals and introduce a two-stage procedure that automatically detects
saturation points and reparameterizes traversal for perceptually uniform,
semantically meaningful edits. Extensive experiments demonstrate that our
method enables plug-and-play, training-free concept control across modalities,
improves over existing baselines, and establishes new tools for principled
controllable generation. An interactive presentation of our benchmark and
method is available at: https://azencot-group.github.io/FreeSliders/

</details>


### [21] [AI Powered High Quality Text to Video Generation with Enhanced Temporal Consistency](https://arxiv.org/abs/2511.00107)
*Piyushkumar Patel*

Main category: cs.CV

TL;DR: MOVAI是一种新型文本到视频生成框架，通过组合场景解析、时空注意力机制和渐进视频细化，显著提升了视频质量和用户偏好。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频生成方法在保持时间一致性、组合理解和视觉叙事控制方面存在不足。

Method: MOVAI提出了一种分层框架，包括组合场景解析器（CSP）、时空注意力机制（TSAM）和渐进视频细化模块（PVR），用于高保真度的文本到视频合成。

Result: MOVAI在标准基准测试中显著提升了视频质量指标（LPIPS提高15.3%，FVD提高12.7%，用户偏好提高18.9%）。

Conclusion: MOVAI框架通过整合组合场景理解和时间感知扩散模型，在文本到视频生成领域实现了最先进的性能，特别是在复杂多对象场景和细粒度语义控制方面表现出色。

Abstract: Text to video generation has emerged as a critical frontier in generative
artificial intelligence, yet existing approaches struggle with maintaining
temporal consistency, compositional understanding, and fine grained control
over visual narratives. We present MOVAI (Multimodal Original Video AI), a
novel hierarchical framework that integrates compositional scene understanding
with temporal aware diffusion models for high fidelity text to video synthesis.
Our approach introduces three key innovations: (1) a Compositional Scene Parser
(CSP) that decomposes textual descriptions into hierarchical scene graphs with
temporal annotations, (2) a Temporal-Spatial Attention Mechanism (TSAM) that
ensures coherent motion dynamics across frames while preserving spatial
details, and (3) a Progressive Video Refinement (PVR) module that iteratively
enhances video quality through multi-scale temporal reasoning. Extensive
experiments on standard benchmarks demonstrate that MOVAI achieves
state-of-the-art performance, improving video quality metrics by 15.3% in
LPIPS, 12.7% in FVD, and 18.9% in user preference studies compared to existing
methods. Our framework shows particular strength in generating complex
multi-object scenes with realistic temporal dynamics and fine-grained semantic
control.

</details>


### [22] [Chain of Time: In-Context Physical Simulation with Image Generation Models](https://arxiv.org/abs/2511.00110)
*YingQiao Wang,Eric Bigelow,Boyi Li,Tomer Ullman*

Main category: cs.CV

TL;DR: 提出了一种认知启发的“Chain of Time”方法，通过生成中间图像序列改进物理模拟，显著提升了图像生成模型的性能，并揭示了模型在模拟随时间展开的物理属性方面的能力及局限性。


<details>
  <summary>Details</summary>
Motivation: 受到机器学习中的上下文推理和人类心理模拟的启发，旨在改进和解释视觉语言模型中的物理模拟。

Method: 提出了一种名为“Chain of Time”的认知启发方法，通过生成模拟过程中的中间图像序列，无需额外微调即可在推理时应用。该方法测试了包括2D图形模拟和自然3D视频在内的多个领域，涵盖速度、加速度、流体动力学和动量守恒等物理属性。

Result: 使用Chain of Time方法显著提升了最先进的图像生成模型的性能，并通过对模拟过程中每一步的世界状态分析，揭示了模型在模拟随时间展开的物理属性方面的能力及其局限性。

Conclusion: Chain of Time方法显著提升了图像生成模型的性能，并揭示了传统物理推理评估中隐藏的洞察，如模型对随时间展开的物理属性（速度、重力、碰撞）的模拟能力。同时，也识别了模型在从输入图像推断特定物理参数时的困难。

Abstract: We propose a novel cognitively-inspired method to improve and interpret
physical simulation in vision-language models. Our ``Chain of Time" method
involves generating a series of intermediate images during a simulation, and it
is motivated by in-context reasoning in machine learning, as well as mental
simulation in humans. Chain of Time is used at inference time, and requires no
additional fine-tuning. We apply the Chain-of-Time method to synthetic and
real-world domains, including 2-D graphics simulations and natural 3-D videos.
These domains test a variety of particular physical properties, including
velocity, acceleration, fluid dynamics, and conservation of momentum. We found
that using Chain-of-Time simulation substantially improves the performance of a
state-of-the-art image generation model. Beyond examining performance, we also
analyzed the specific states of the world simulated by an image model at each
time step, which sheds light on the dynamics underlying these simulations. This
analysis reveals insights that are hidden from traditional evaluations of
physical reasoning, including cases where an image generation model is able to
simulate physical properties that unfold over time, such as velocity, gravity,
and collisions. Our analysis also highlights particular cases where the image
generation model struggles to infer particular physical parameters from input
images, despite being capable of simulating relevant physical processes.

</details>


### [23] [End-to-End Framework Integrating Generative AI and Deep Reinforcement Learning for Autonomous Ultrasound Scanning](https://arxiv.org/abs/2511.00114)
*Hanae Elmekki,Amanda Spilkin,Ehsan Zakeri,Antonela Mariel Zanuttini,Ahmed Alagha,Hani Sami,Jamal Bentahar,Lyes Kadem,Wen-Fang Xie,Philippe Pibarot,Rabeb Mizouni,Hadi Otrok,Azzam Mourad,Sami Muhaidat*

Main category: cs.CV

TL;DR: 论文提出首个结合生成式AI和深度强化学习的端到端框架，解决心脏超声扫描的自动化问题，通过公开数据集和实验验证其高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 心脏超声检查的操作依赖性强、时间受限且易受人为错误影响，加上专业人员的短缺（尤其是偏远地区），亟需自动化解决方案。现有DRL方法缺乏可重复性、依赖专有数据且模型简化，因此需要更先进的框架。

Method: 框架包含两部分：(i) 结合生成对抗网络（GANs）和变分自编码器（VAEs）的条件生成模拟器，用于生成逼真的动作条件图像；(ii) 利用该模拟器的深度强化学习（DRL）模块，学习自主、准确的扫描策略。

Result: 实验验证表明，VAE-GAN在生成逼真图像方面优于现有GAN变体，DRL扫描系统在不同配置下均表现有效。框架支持图像类型分类和质量评估，并实现了可扩展的生成能力。

Conclusion: 该论文提出了一个结合生成式AI和深度强化学习的端到端框架，旨在实现自主且可重复的心脏超声扫描。通过公开数据集和专家验证模型，该方法不仅提高了扫描的准确性和可重复性，还为其他器官的类似应用奠定了基础。

Abstract: Cardiac ultrasound (US) is among the most widely used diagnostic tools in
cardiology for assessing heart health, but its effectiveness is limited by
operator dependence, time constraints, and human error. The shortage of trained
professionals, especially in remote areas, further restricts access. These
issues underscore the need for automated solutions that can ensure consistent,
and accessible cardiac imaging regardless of operator skill or location. Recent
progress in artificial intelligence (AI), especially in deep reinforcement
learning (DRL), has gained attention for enabling autonomous decision-making.
However, existing DRL-based approaches to cardiac US scanning lack
reproducibility, rely on proprietary data, and use simplified models. Motivated
by these gaps, we present the first end-to-end framework that integrates
generative AI and DRL to enable autonomous and reproducible cardiac US
scanning. The framework comprises two components: (i) a conditional generative
simulator combining Generative Adversarial Networks (GANs) with Variational
Autoencoders (VAEs), that models the cardiac US environment producing realistic
action-conditioned images; and (ii) a DRL module that leverages this simulator
to learn autonomous, accurate scanning policies. The proposed framework
delivers AI-driven guidance through expert-validated models that classify image
type and assess quality, supports conditional generation of realistic US
images, and establishes a reproducible foundation extendable to other organs.
To ensure reproducibility, a publicly available dataset of real cardiac US
scans is released. The solution is validated through several experiments. The
VAE-GAN is benchmarked against existing GAN variants, with performance assessed
using qualitative and quantitative approaches, while the DRL-based scanning
system is evaluated under varying configurations to demonstrate effectiveness.

</details>


### [24] [VLM6D: VLM based 6Dof Pose Estimation based on RGB-D Images](https://arxiv.org/abs/2511.00120)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: VLM6D提出了一种双流架构，结合视觉和几何数据，显著提升了6D物体姿态估计在复杂场景下的性能。


<details>
  <summary>Details</summary>
Motivation: 当前6D物体姿态估计方法在合成数据到真实场景的泛化能力不足，尤其在光照变化、无纹理物体和严重遮挡情况下表现脆弱。

Method: 采用双流架构，结合自监督Vision Transformer（DINOv2）处理RGB数据，PointNet++编码器处理3D点云数据，并通过多任务预测头融合特征。

Result: VLM6D在Occluded-LineMOD数据集上取得了新的SOTA性能，验证了其卓越的鲁棒性和准确性。

Conclusion: VLM6D通过双流架构结合视觉和几何数据，显著提升了6D物体姿态估计的鲁棒性和精度，尤其在复杂光照、无纹理物体及严重遮挡场景下表现优异。

Abstract: The primary challenge in computer vision is precisely calculating the pose of
6D objects, however many current approaches are still fragile and have trouble
generalizing from synthetic data to real-world situations with fluctuating
lighting, textureless objects, and significant occlusions. To address these
limitations, VLM6D, a novel dual-stream architecture that leverages the
distinct strengths of visual and geometric data from RGB-D input for robust and
precise pose estimation. Our framework uniquely integrates two specialized
encoders: a powerful, self-supervised Vision Transformer (DINOv2) processes the
RGB modality, harnessing its rich, pre-trained understanding of visual grammar
to achieve remarkable resilience against texture and lighting variations.
Concurrently, a PointNet++ encoder processes the 3D point cloud derived from
depth data, enabling robust geometric reasoning that excels even with the
sparse, fragmented data typical of severe occlusion. These complementary
feature streams are effectively fused to inform a multi task prediction head.
We demonstrate through comprehensive experiments that VLM6D obtained new SOTA
performance on the challenging Occluded-LineMOD, validating its superior
robustness and accuracy.

</details>


### [25] [Boosting performance of computer vision applications through embedded GPUs on the edge](https://arxiv.org/abs/2511.01129)
*Fabio Diniz Rossi*

Main category: cs.CV

TL;DR: 研究提出在资源有限的边缘计算设备中使用GPU来提升计算机视觉应用性能，实验证明GPU比CPU更能改善用户体验。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的计算机视觉应用（尤其是增强现实技术）对资源需求较高，而边缘计算设备通常资源有限，可能影响用户体验。

Method: 通过实验比较GPU和CPU在处理计算机视觉任务时的性能表现。

Result: 实验结果表明，GPU相较于CPU能够获得性能提升，确保用户在使用这类应用时有更好的体验。

Conclusion: 使用带有GPU的嵌入式设备可以显著提升计算机视觉应用的性能，从而改善用户体验。

Abstract: Computer vision applications, especially those using augmented reality
technology, are becoming quite popular in mobile devices. However, this type of
application is known as presenting significant demands regarding resources. In
order to enable its utilization in devices with more modest resources, edge
computing can be used to offload certain high intensive tasks. Still, edge
computing is usually composed of devices with limited capacity, which may
impact in users quality of experience when using computer vision applications.
This work proposes the use of embedded devices with graphics processing units
(GPUs) to overcome such limitation. Experiments performed shown that GPUs can
attain a performance gain when compared to using only CPUs, which guarantee a
better experience to users using such kind of application.

</details>


### [26] [Integrating ConvNeXt and Vision Transformers for Enhancing Facial Age Estimation](https://arxiv.org/abs/2511.00123)
*Gaby Maroun,Salah Eddine Bekhouche,Fadi Dornaika*

Main category: cs.CV

TL;DR: 提出ConvNeXt-ViT混合架构，结合CNN与Transformer优势，在年龄估计任务中实现卓越性能。


<details>
  <summary>Details</summary>
Motivation: 解决面部图像年龄估计这一复杂多面的计算机视觉挑战，探索CNN与Transformer互补优势的整合。

Method: 结合ConvNeXt的局部特征提取能力和ViT的全局注意力机制，通过预训练模型和线性层优化架构，并采用高级正则化技术。

Result: 在MORPH II、CACD和AFAD等基准数据集上，ConvNeXt-ViT混合模型在平均绝对误差（MAE）方面表现优异。

Conclusion: 本文提出的ConvNeXt-ViT混合架构在年龄估计任务中表现出色，不仅超越了传统方法，还为未来复杂计算机视觉任务的CNN与Transformer融合提供了坚实基础。

Abstract: Age estimation from facial images is a complex and multifaceted challenge in
computer vision. In this study, we present a novel hybrid architecture that
combines ConvNeXt, a state-of-the-art advancement of convolutional neural
networks (CNNs), with Vision Transformers (ViT). While each model independently
delivers excellent performance on a variety of tasks, their integration
leverages the complementary strengths of the CNNs localized feature extraction
capabilities and the Transformers global attention mechanisms. Our proposed
ConvNeXt-ViT hybrid solution was thoroughly evaluated on benchmark age
estimation datasets, including MORPH II, CACD, and AFAD, and achieved superior
performance in terms of mean absolute error (MAE). To address computational
constraints, we leverage pre-trained models and systematically explore
different configurations, using linear layers and advanced regularization
techniques to optimize the architecture. Comprehensive ablation studies
highlight the critical role of individual components and training strategies,
and in particular emphasize the importance of adapted attention mechanisms
within the CNN framework to improve the model focus on age-relevant facial
features. The results show that the ConvNeXt-ViT hybrid not only outperforms
traditional methods, but also provides a robust foundation for future advances
in age estimation and related visual tasks. This work underscores the
transformative potential of hybrid architectures and represents a promising
direction for the seamless integration of CNNs and transformers to address
complex computer vision challenges.

</details>


### [27] [FLoC: Facility Location-Based Efficient Visual Token Compression for Long Video Understanding](https://arxiv.org/abs/2511.00141)
*Janghoon Cho,Jungsoo Lee,Munawar Hayat,Kyuwoong Hwang,Fatih Porikli,Sungha Choi*

Main category: cs.CV

TL;DR: FLoC是一种高效的视觉标记压缩框架，通过设施位置函数和懒惰贪婪算法减少长视频处理中的视觉标记数量，保持性能并提升处理速度。


<details>
  <summary>Details</summary>
Motivation: 现有视频-LMM模型在处理长视频时因视觉标记数量庞大而受限，需要一个高效、训练无关的压缩方案。

Method: 提出FLoC框架，利用设施位置函数和懒惰贪婪算法，快速选择具有代表性和多样性的视觉标记子集。

Result: 在Video-MME、MLVU和LongVideoBench等大规模基准测试中，FLoC框架表现优于现有压缩技术，证明了其高效性和鲁棒性。

Conclusion: FLoC框架通过基于设施位置函数的高效视觉标记压缩方法，显著减少了长视频理解中的视觉标记数量，同时保持了近最优性能，适用于多种视频-LMM模型和工作流程。

Abstract: Recent studies in long video understanding have harnessed the advanced
visual-language reasoning capabilities of Large Multimodal Models (LMMs),
driving the evolution of video-LMMs specialized for processing extended video
sequences. However, the scalability of these models is severely limited by the
overwhelming volume of visual tokens generated from extended video sequences.
To address this challenge, this paper proposes FLoC, an efficient visual token
compression framework based on the facility location function, a principled
approach that swiftly selects a compact yet highly representative and diverse
subset of visual tokens within a predefined budget on the number of visual
tokens. By integrating the lazy greedy algorithm, our method achieves
remarkable efficiency gains by swiftly selecting a compact subset of tokens,
drastically reducing the number of visual tokens while guaranteeing
near-optimal performance. Notably, our approach is training-free,
model-agnostic, and query-agnostic, providing a versatile solution that
seamlessly integrates with diverse video-LLMs and existing workflows. Extensive
evaluations on large-scale benchmarks, such as Video-MME, MLVU, and
LongVideoBench, demonstrate that our framework consistently surpasses recent
compression techniques, highlighting not only its effectiveness and robustness
in addressing the critical challenges of long video understanding, but also its
efficiency in processing speed.

</details>


### [28] [BlurGuard: A Simple Approach for Robustifying Image Protection Against AI-Powered Editing](https://arxiv.org/abs/2511.00143)
*Jinsu Kim,Yunhun Nam,Minseon Kim,Sangpil Kim,Jongheon Jeong*

Main category: cs.CV

TL;DR: 通过自适应高斯模糊增强对抗噪声的不可逆性，提升图像保护效果。


<details>
  <summary>Details</summary>
Motivation: 针对现有图像保护方法中的对抗噪声易被简单技术（如JPEG压缩）逆转的问题，研究如何提升噪声的不可逆性，以实现更实用的图像保护。

Method: 提出了一种自适应区域高斯模糊技术，调整噪声的整体频率谱，以增强对抗噪声的不可逆性。

Result: 实验表明，该方法能显著提升现有保护方法对多种逆转技术的抵抗能力，同时减少噪声引入的感知质量下降。

Conclusion: 本文提出了一种简单但有效的方法，通过自适应高斯模糊增强图像保护对抗噪声的稳健性，显著提升了现有方法在多样编辑场景下的保护性能。

Abstract: Recent advances in text-to-image models have increased the exposure of
powerful image editing techniques as a tool, raising concerns about their
potential for malicious use. An emerging line of research to address such
threats focuses on implanting "protective" adversarial noise into images before
their public release, so future attempts to edit them using text-to-image
models can be impeded. However, subsequent works have shown that these
adversarial noises are often easily "reversed," e.g., with techniques as simple
as JPEG compression, casting doubt on the practicality of the approach. In this
paper, we argue that adversarial noise for image protection should not only be
imperceptible, as has been a primary focus of prior work, but also
irreversible, viz., it should be difficult to detect as noise provided that the
original image is hidden. We propose a surprisingly simple method to enhance
the robustness of image protection methods against noise reversal techniques.
Specifically, it applies an adaptive per-region Gaussian blur on the noise to
adjust the overall frequency spectrum. Through extensive experiments, we show
that our method consistently improves the per-sample worst-case protection
performance of existing methods against a wide range of reversal techniques on
diverse image editing scenarios, while also reducing quality degradation due to
noise in terms of perceptual metrics. Code is available at
https://github.com/jsu-kim/BlurGuard.

</details>


### [29] [CompAgent: An Agentic Framework for Visual Compliance Verification](https://arxiv.org/abs/2511.00171)
*Rahul Ghosh,Baishali Chaudhury,Hari Prasanna Das,Meghana Ashok,Ryan Razkenari,Sungmin Hong,Chun-Hao Liu*

Main category: cs.CV

TL;DR: CompAgent是一个代理框架，通过结合MLLMs和视觉工具，动态选择和整合工具输出，显著提升了视觉合规验证的准确性和适应性。


<details>
  <summary>Details</summary>
Motivation: 视觉合规验证是一个重要但未被充分探索的问题，现有方法成本高且泛化能力有限，MLLMs虽具备广泛知识但难以处理细粒度视觉细节和结构化规则。

Method: 提出了CompAgent框架，结合多模态大型语言模型（MLLMs）和视觉工具（如物体检测器、人脸分析器等），通过规划代理动态选择工具，验证代理整合多模态信息进行推理。

Result: 在公开基准测试中，CompAgent表现优于专用分类器和直接MLLM提示，F1分数达76%，在UnsafeBench数据集上比现有技术提升10%。

Conclusion: CompAgent通过代理规划和工具增强推理，展示了在视觉合规验证中的有效性，实现了可扩展、准确和适应性强的方法。

Abstract: Visual compliance verification is a critical yet underexplored problem in
computer vision, especially in domains such as media, entertainment, and
advertising where content must adhere to complex and evolving policy rules.
Existing methods often rely on task-specific deep learning models trained on
manually labeled datasets, which are costly to build and limited in
generalizability. While recent multi-modal large language models (MLLMs) offer
broad real-world knowledge and policy understanding, they struggle to reason
over fine-grained visual details and apply structured compliance rules
effectively on their own. In this paper, we propose CompAgent, the first
agentic framework for visual compliance verification. CompAgent augments MLLMs
with a suite of visual tools - such as object detectors, face analyzers, NSFW
detectors, and captioning models - and introduces a planning agent that
dynamically selects appropriate tools based on the compliance policy. A
verification agent then integrates image, tool outputs, and policy context to
perform multi-modal reasoning. Experiments on public benchmarks show that
CompAgent outperforms specialized classifiers, direct MLLM prompting, and
curated routing baselines, achieving up to 76% F1 score and a 10% improvement
over the state-of-the-art on the UnsafeBench dataset. Our results demonstrate
the effectiveness of agentic planning and tool-augmented reasoning for
scalable, accurate, and adaptable visual compliance verification.

</details>


### [30] [From Evidence to Verdict: An Agent-Based Forensic Framework for AI-Generated Image Detection](https://arxiv.org/abs/2511.00181)
*Mengfei Liang,Yiting Qu,Yukun Jiang,Michael Backes,Yang Zhang*

Main category: cs.CV

TL;DR: AIFo通过多智能体协作和无训练框架，显著提升AI生成图像检测的准确性和适应性，达到97.05%的准确率。


<details>
  <summary>Details</summary>
Motivation: 针对传统分类器缺乏可解释性和泛化能力，以及视觉语言模型局限于单次分析和像素级推理的问题，提出一种更高效的AI生成图像检测方法。

Method: AIFo采用基于代理的无训练框架，结合反向图像搜索、元数据提取、预训练分类器和视觉语言模型分析，通过多智能体协作收集、综合和推理跨源证据，并引入结构化多代理辩论机制和记忆增强推理模块。

Result: AIFo在6000张图像的全面评估中达到97.05%的准确率，显著优于现有方法。

Conclusion: AIFo框架通过多智能体协作，提供了一种更鲁棒、可解释且适应性强的AI生成图像检测新范式，显著优于传统分类器和先进视觉语言模型。

Abstract: The rapid evolution of AI-generated images poses unprecedented challenges to
information integrity and media authenticity. Existing detection approaches
suffer from fundamental limitations: traditional classifiers lack
interpretability and fail to generalize across evolving generative models,
while vision-language models (VLMs), despite their promise, remain constrained
to single-shot analysis and pixel-level reasoning. To address these challenges,
we introduce AIFo (Agent-based Image Forensics), a novel training-free
framework that emulates human forensic investigation through multi-agent
collaboration. Unlike conventional methods, our framework employs a set of
forensic tools, including reverse image search, metadata extraction,
pre-trained classifiers, and VLM analysis, coordinated by specialized LLM-based
agents that collect, synthesize, and reason over cross-source evidence. When
evidence is conflicting or insufficient, a structured multi-agent debate
mechanism allows agents to exchange arguments and reach a reliable conclusion.
Furthermore, we enhance the framework with a memory-augmented reasoning module
that learns from historical cases to improve future detection accuracy. Our
comprehensive evaluation spans 6,000 images across both controlled laboratory
settings and challenging real-world scenarios, including images from modern
generative platforms and diverse online sources. AIFo achieves 97.05% accuracy,
substantially outperforming traditional classifiers and state-of-the-art VLMs.
These results demonstrate that agent-based procedural reasoning offers a new
paradigm for more robust, interpretable, and adaptable AI-generated image
detection.

</details>


### [31] [A Retrospect to Multi-prompt Learning across Vision and Language](https://arxiv.org/abs/2511.00191)
*Ziliang Chen,Xin Huang,Quanlong Guan,Liang Lin,Weiqi Luo*

Main category: cs.CV

TL;DR: 本文提出EMPL方法，通过能量基多提示学习提升视觉语言模型的泛化能力，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于单提示范式，忽略了多提示学习的技术潜力，本文旨在为视觉语言多提示学习提供一个理论回顾。

Method: 提出了一种基于能量的多提示学习（EMPL），通过从能量基分布中抽取实例生成多个提示嵌入。

Result: 实验验证了EMPL的优越性，证明了多提示增强在视觉语言迁移中的优势。

Conclusion: EMPL通过能量基多提示学习，实现了参数高效且在领域内和领域外的开放词汇泛化之间取得平衡。

Abstract: The vision community is undergoing the unprecedented progress with the
emergence of Vision-Language Pretraining Models (VLMs). Prompt learning plays
as the holy grail of accessing VLMs since it enables their fast adaptation to
downstream tasks with limited resources. Whereas existing researches milling
around single-prompt paradigms, rarely investigate the technical potential
behind their multi-prompt learning counterparts. This paper aims to provide a
principled retrospect for vision-language multi-prompt learning. We extend the
recent constant modality gap phenomenon to learnable prompts and then, justify
the superiority of vision-language transfer with multi-prompt augmentation,
empirically and theoretically. In terms of this observation, we propose an
Energy-based Multi-prompt Learning (EMPL) to generate multiple prompt
embeddings by drawing instances from an energy-based distribution, which is
implicitly defined by VLMs. So our EMPL is not only parameter-efficient but
also rigorously lead to the balance between in-domain and out-of-domain
open-vocabulary generalization. Comprehensive experiments have been conducted
to justify our claims and the excellence of EMPL.

</details>


### [32] [An Efficient and Generalizable Transfer Learning Method for Weather Condition Detection on Ground Terminals](https://arxiv.org/abs/2511.00211)
*Wenxuan Zhang,Peng Hu*

Main category: cs.CV

TL;DR: 论文提出一种迁移学习方法，用于地面终端组件本地检测天气相关条件，性能优于典型深度学习模型，并具有泛化优势。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道（LEO）卫星在巨型星座中的广泛采用，卫星互联网为农村和偏远地区提供了无处不在的连接。然而，天气事件对卫星互联网的性能和可靠性有显著影响，如雪和雨等恶劣天气会干扰地面终端组件（如卫星天线）的性能和操作，严重破坏LEO卫星与地面站之间的空间-地面链路条件。这需要不仅基于区域的天气预报，还需要对地面终端组件的细粒度天气条件检测能力。

Method: 论文采用迁移学习（TL）方法，使地面组件能够本地检测代表性的天气相关条件。该方法通过对比典型的深度学习方法（如YOLOv7、YOLOv9、Faster R-CNN和R-YOLO）验证了其优越性。

Result: 提出的迁移学习方法能够检测雪、湿和其他天气相关条件，并在性能上优于典型的深度学习方法。同时，该方法展示了在实际部署中至关重要的泛化能力。

Conclusion: 该论文提出了一种高效的迁移学习方法，能够在地面终端组件上本地检测与天气相关的代表性条件，如雪、湿和其他恶劣天气事件导致的情况。该方法在性能上优于典型的深度学习方法，并展示了在各种场景中的泛化优势。

Abstract: The increasing adoption of satellite Internet with low-Earth-orbit (LEO)
satellites in mega-constellations allows ubiquitous connectivity to rural and
remote areas. However, weather events have a significant impact on the
performance and reliability of satellite Internet. Adverse weather events such
as snow and rain can disturb the performance and operations of satellite
Internet's essential ground terminal components, such as satellite antennas,
significantly disrupting the space-ground link conditions between LEO
satellites and ground stations. This challenge calls for not only region-based
weather forecasts but also fine-grained detection capability on ground terminal
components of fine-grained weather conditions. Such a capability can assist in
fault diagnostics and mitigation for reliable satellite Internet, but its
solutions are lacking, not to mention the effectiveness and generalization that
are essential in real-world deployments. This paper discusses an efficient
transfer learning (TL) method that can enable a ground component to locally
detect representative weather-related conditions. The proposed method can
detect snow, wet, and other conditions resulting from adverse and typical
weather events and shows superior performance compared to the typical deep
learning methods, such as YOLOv7, YOLOv9, Faster R-CNN, and R-YOLO. Our TL
method also shows the advantage of being generalizable to various scenarios.

</details>


### [33] [DM-QPMNET: Dual-modality fusion network for cell segmentation in quantitative phase microscopy](https://arxiv.org/abs/2511.00218)
*Rajatsubhra Chakraborty,Ana Espinosa-Momox,Riley Haskin,Depeng Xu,Rosario Porras-Aguilar*

Main category: cs.CV

TL;DR: DM-QPMNet是一种双编码器网络，通过多头注意力融合偏振强度图像和相位图的互补信息，显著提升了细胞分割性能。


<details>
  <summary>Details</summary>
Motivation: 传统的阈值方法对噪声和细胞密度敏感，而简单的通道拼接深度学习方法未能充分利用偏振强度图像和相位图的互补性。

Method: 提出了一种双编码器网络（DM-QPMNet），通过单独的编码流处理偏振强度图像和相位图，并在中间深度通过多头注意力机制融合模态特定特征。

Result: DM-QPMNet在细胞分割任务中显著优于单一模态基线方法和简单的通道拼接方法。

Conclusion: DM-QPMNet通过双编码器网络和多头注意力机制，有效利用了ssQPM中的互补照明和相位线索，显著提升了细胞分割的鲁棒性。

Abstract: Cell segmentation in single-shot quantitative phase microscopy (ssQPM) faces
challenges from traditional thresholding methods that are sensitive to noise
and cell density, while deep learning approaches using simple channel
concatenation fail to exploit the complementary nature of polarized intensity
images and phase maps. We introduce DM-QPMNet, a dual-encoder network that
treats these as distinct modalities with separate encoding streams. Our
architecture fuses modality-specific features at intermediate depth via
multi-head attention, enabling polarized edge and texture representations to
selectively integrate complementary phase information. This content-aware
fusion preserves training stability while adding principled multi-modal
integration through dual-source skip connections and per-modality normalization
at minimal overhead. Our approach demonstrates substantial improvements over
monolithic concatenation and single-modality baselines, showing that
modality-specific encoding with learnable fusion effectively exploits ssQPM's
simultaneous capture of complementary illumination and phase cues for robust
cell segmentation.

</details>


### [34] [Towards 1000-fold Electron Microscopy Image Compression for Connectomics via VQ-VAE with Transformer Prior](https://arxiv.org/abs/2511.00231)
*Fuming Yang,Yicong Li,Hanspeter Pfister,Jeff W. Lichtman,Yaron Meirovitch*

Main category: cs.CV

TL;DR: 提出VQ-VAE压缩框架，支持16x-1024x压缩比，结合Transformer和ROI驱动工作流程，优化EM数据处理。


<details>
  <summary>Details</summary>
Motivation: 解决海量电子显微镜（EM）数据集在存储、传输和下游分析中的挑战。

Method: 采用向量量化变分自编码器（VQ-VAE）进行压缩，结合Transformer先验预测底部令牌以恢复纹理，并通过FiLM和连接技术优化。

Result: 实现了高效的压缩和选择性重建，支持按需解码和纹理恢复。

Conclusion: 该论文提出了一种基于VQ-VAE的EM数据压缩框架，支持从16x到1024x的压缩比，并通过ROI驱动的工作流程实现了选择性高分辨率重建。

Abstract: Petascale electron microscopy (EM) datasets push storage, transfer, and
downstream analysis toward their current limits. We present a vector-quantized
variational autoencoder-based (VQ-VAE) compression framework for EM that spans
16x to 1024x and enables pay-as-you-decode usage: top-only decoding for extreme
compression, with an optional Transformer prior that predicts bottom tokens
(without changing the compression ratio) to restore texture via feature-wise
linear modulation (FiLM) and concatenation; we further introduce an ROI-driven
workflow that performs selective high-resolution reconstruction from
1024x-compressed latents only where needed.

</details>


### [35] [Hyperbolic Optimal Transport](https://arxiv.org/abs/2511.00244)
*Yan Bin Ng,Xianfeng Gu*

Main category: cs.CV

TL;DR: 本文提出双曲空间最优传输映射的高效算法，通过几何变分技术扩展现有方法，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有最优传输映射计算方法主要适用于欧几里得空间和球面，而双曲空间在层次数据、网络和多亏格Riemann曲面等场景中自然出现，需要针对性解决方案。

Method: 采用几何变分技术，将欧几里得和球面几何的方法扩展到双曲空间，提出高效算法。

Result: 在合成数据和多亏格曲面模型上的实验验证了所提方法的有效性。

Conclusion: 本文提出了一种在双曲空间中计算最优传输映射的新算法，通过几何变分技术扩展了欧几里得和球面几何的方法，实验验证了其有效性。

Abstract: The optimal transport (OT) problem aims to find the most efficient mapping
between two probability distributions under a given cost function, and has
diverse applications in many fields such as machine learning, computer vision
and computer graphics. However, existing methods for computing optimal
transport maps are primarily developed for Euclidean spaces and the sphere. In
this paper, we explore the problem of computing the optimal transport map in
hyperbolic space, which naturally arises in contexts involving hierarchical
data, networks, and multi-genus Riemann surfaces. We propose a novel and
efficient algorithm for computing the optimal transport map in hyperbolic space
using a geometric variational technique by extending methods for Euclidean and
spherical geometry to the hyperbolic setting. We also perform experiments on
synthetic data and multi-genus surface models to validate the efficacy of the
proposed method.

</details>


### [36] [Merlin L48 Spectrogram Dataset](https://arxiv.org/abs/2511.00252)
*Aaron Sun,Subhransu Maji,Grant Van Horn*

Main category: cs.CV

TL;DR: L48数据集填补了真实SPML基准的空白，展示了现有方法在细粒度场景中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的SPML方法在合成数据集上表现良好，但无法反映真实世界的复杂性和细粒度挑战。

Method: 引入了L48数据集，这是一个基于鸟类声音的细粒度真实多标签数据集，并提供了两种扩展设置。

Result: 在L48数据集上评估现有SPML方法时，发现与合成数据集相比存在显著性能差异，并分析了方法的弱点。

Conclusion: L48数据集提供了一个更真实、更具挑战性的SPML基准，揭示了现有方法在真实细粒度场景中的性能差异和弱点。

Abstract: In the single-positive multi-label (SPML) setting, each image in a dataset is
labeled with the presence of a single class, while the true presence of other
classes remains unknown. The challenge is to narrow the performance gap between
this partially-labeled setting and fully-supervised learning, which often
requires a significant annotation budget. Prior SPML methods were developed and
benchmarked on synthetic datasets created by randomly sampling single positive
labels from fully-annotated datasets like Pascal VOC, COCO, NUS-WIDE, and
CUB200. However, this synthetic approach does not reflect real-world scenarios
and fails to capture the fine-grained complexities that can lead to difficult
misclassifications. In this work, we introduce the L48 dataset, a fine-grained,
real-world multi-label dataset derived from recordings of bird sounds. L48
provides a natural SPML setting with single-positive annotations on a
challenging, fine-grained domain, as well as two extended settings in which
domain priors give access to additional negative labels. We benchmark existing
SPML methods on L48 and observe significant performance differences compared to
synthetic datasets and analyze method weaknesses, underscoring the need for
more realistic and difficult benchmarks.

</details>


### [37] [BeetleFlow: An Integrative Deep Learning Pipeline for Beetle Image Processing](https://arxiv.org/abs/2511.00255)
*Fangxun Liu,S M Rayeed,Samuel Stevens,Alyson East,Cheng Hsuan Chiang,Colin Lee,Daniel Yi,Junke Yang,Tejas Naik,Ziyi Wang,Connor Kilrain,Elijah H Buckwalter,Jiacheng Hou,Saul Ibaven Bueno,Shuheng Wang,Xinyue Ma,Yifan Liu,Zhiyuan Tao,Ziheng Zhang,Eric Sokol,Michael Belitz,Sydne Record,Charles V. Stewart,Wei-Lun Chao*

Main category: cs.CV

TL;DR: 开发了一个基于深度学习的自动化三阶段管道，用于高效检测、裁剪和分割大规模甲虫图像，加速生物学研究。


<details>
  <summary>Details</summary>
Motivation: 生物学研究中需要处理大量甲虫图像，传统方法效率低下，急需自动化管道以支持大规模数据处理。

Method: 开发了一个三阶段管道：1）使用基于Transformer的开放词汇对象检测器和视觉语言模型迭代检测托盘上的甲虫；2）对每个甲虫图像进行排序和裁剪；3）手动标注670张甲虫图像，并微调两种基于Transformer的分割模型变体，实现细粒度分割。

Result: 管道实现了相对高精度的甲虫细粒度分割，提升了大规模甲虫图像处理的效率。

Conclusion: 该管道集成了多种深度学习方法，专门用于甲虫图像处理，能显著提高大规模甲虫数据的处理效率，加速生物学研究。

Abstract: In entomology and ecology research, biologists often need to collect a large
number of insects, among which beetles are the most common species. A common
practice for biologists to organize beetles is to place them on trays and take
a picture of each tray. Given the images of thousands of such trays, it is
important to have an automated pipeline to process the large-scale data for
further research. Therefore, we develop a 3-stage pipeline to detect all the
beetles on each tray, sort and crop the image of each beetle, and do
morphological segmentation on the cropped beetles. For detection, we design an
iterative process utilizing a transformer-based open-vocabulary object detector
and a vision-language model. For segmentation, we manually labeled 670 beetle
images and fine-tuned two variants of a transformer-based segmentation model to
achieve fine-grained segmentation of beetles with relatively high accuracy. The
pipeline integrates multiple deep learning methods and is specialized for
beetle image processing, which can greatly improve the efficiency to process
large-scale beetle data and accelerate biological research.

</details>


### [38] [MambaNetLK: Enhancing Colonoscopy Point Cloud Registration with Mamba](https://arxiv.org/abs/2511.00260)
*Linzhe Jiang,Jiayuan Huang,Sophia Bano,Matthew J. Clarkson,Zhehua Mao,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: MambaNetLK 是一种新型 3D 配准方法，结合 SSM 特征提取器和临床数据集，显著提升了结肠镜导航的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 生物组织具有重复纹理和局部均匀几何特征，导致特征退化，同时术前解剖与术中观察之间存在显著域偏移，进一步降低了配准稳定性。这些临床关键挑战需要通过新的配准方法和高质量数据集来解决。

Method: 提出了 MambaNetLK，一种无需对应的配准框架，通过集成 Mamba 状态空间模型（SSM）作为跨模态特征提取器，增强了 PointNetLK 架构，能够以线性时间复杂度高效捕捉长距离依赖关系，并使用 Lucas-Kanade 算法迭代实现对齐。

Result: 在临床数据集 C3VD-Raycasting-10k 上，MambaNetLK 表现最佳，比次优方法的中值旋转误差降低了 56.04%，RMSE 平移误差降低了 26.19%。模型在 ModelNet40 上表现出强泛化能力，并对初始姿态扰动具有强鲁棒性。

Conclusion: MambaNetLK 为手术导航中的 3D 配准提供了稳健的基础，结合全局表达性强的 SSM 特征提取器和大型临床数据集，使得结肠镜等微创手术中的导航系统更加准确可靠。

Abstract: Accurate 3D point cloud registration underpins reliable image-guided
colonoscopy, directly affecting lesion localization, margin assessment, and
navigation safety. However, biological tissue exhibits repetitive textures and
locally homogeneous geometry that cause feature degeneracy, while substantial
domain shifts between pre-operative anatomy and intra-operative observations
further degrade alignment stability. To address these clinically critical
challenges, we introduce a novel 3D registration method tailored for endoscopic
navigation and a high-quality, clinically grounded dataset to support rigorous
and reproducible benchmarking. We introduce C3VD-Raycasting-10k, a large-scale
benchmark dataset with 10,014 geometrically aligned point cloud pairs derived
from clinical CT data. We propose MambaNetLK, a novel correspondence-free
registration framework, which enhances the PointNetLK architecture by
integrating a Mamba State Space Model (SSM) as a cross-modal feature extractor.
As a result, the proposed framework efficiently captures long-range
dependencies with linear-time complexity. The alignment is achieved iteratively
using the Lucas-Kanade algorithm. On the clinical dataset, C3VD-Raycasting-10k,
MambaNetLK achieves the best performance compared with the state-of-the-art
methods, reducing median rotation error by 56.04% and RMSE translation error by
26.19% over the second-best method. The model also demonstrates strong
generalization on ModelNet40 and superior robustness to initial pose
perturbations. MambaNetLK provides a robust foundation for 3D registration in
surgical navigation. The combination of a globally expressive SSM-based feature
extractor and a large-scale clinical dataset enables more accurate and reliable
guidance systems in minimally invasive procedures like colonoscopy.

</details>


### [39] [Spot The Ball: A Benchmark for Visual Social Inference](https://arxiv.org/abs/2511.00261)
*Neha Balamurugan,Sarah Wu,Adam Chun,Gabe Gaw,Cristobal Eyzaguirre,Tobias Gerstenberg*

Main category: cs.CV

TL;DR: ‘Spot The Ball’基准测试显示，人类在视觉社交推理上远超AI模型，模型需改进以更好地利用社交线索。


<details>
  <summary>Details</summary>
Motivation: 视觉社交推理是人类日常社交推理的核心能力，对开发更类人的人工智能代理至关重要。通过‘Spot The Ball’任务，评估模型是否能够从他人的注视、姿势和方向等微妙行为线索中推断场景中的隐藏元素。

Method: 通过‘Spot The Ball’基准测试，评估了四种最先进的视觉语言模型（Gemini、GPT、LLaMA、Qwen）在足球、篮球和排球图像中定位被移除球的能力。采用了三种提示策略，并与人类基线进行了比较。

Result: 人类在所有运动项目中的准确率（20-34%）一致比模型（≤17%）高出两到三倍。模型主要依赖表面的空间启发式方法（如猜测图像中心或附近球员），而人类则利用社交线索（如注视方向和身体姿势）。

Conclusion: 本文揭示了视觉社交推理中存在的人类与模型之间的持续差距，强调了需要开发能够显式编码结构化行为线索的架构，以实现鲁棒且类人的推理。

Abstract: Humans excel at visual social inference, the ability to infer hidden elements
of a scene from subtle behavioral cues such as other people's gaze, pose, and
orientation. This ability drives everyday social reasoning in humans and is
critical for developing more human-like AI agents. We introduce Spot The Ball,
a challenging benchmark for evaluating visual social inference in
vision-language models (VLMs) using sports as a test domain. The task is to
localize a removed sports ball from soccer, basketball, and volleyball images.
We present a curated evaluation set with human baselines and a scalable
pipeline for generating additional test items. We evaluate four
state-of-the-art VLMs (Gemini, GPT, LLaMA, Qwen) using three prompting
strategies, finding that humans are consistently two to three times more
accurate (20-34%) than models ($\leq$ 17%) across all sports. Our analyses show
that models rely on superficial spatial heuristics--such as guessing near the
image center or nearby players--while humans leverage social cues like gaze
direction and body pose. These findings reveal a persistent human-model gap in
visual social reasoning and underscore the need for architectures that
explicitly encode structured behavioral cues to achieve robust, human-like
inference.

</details>


### [40] [FedReplay: A Feature Replay Assisted Federated Transfer Learning Framework for Efficient and Privacy-Preserving Smart Agriculture](https://arxiv.org/abs/2511.00269)
*Long Li,Jiajia Li,Dong Chen,Lina Pu,Haibo Yao,Yanbo Huang*

Main category: cs.CV

TL;DR: 论文提出了一种结合CLIP ViT和轻量级分类器的联邦学习框架，显著提升了农业分类的准确率并降低了通信成本，解决了隐私和非IID数据问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统集中式训练中的隐私问题和标准联邦学习中的非独立同分布数据及高通信成本问题。

Method: 提出了一种联邦学习框架，整合了冻结的CLIP ViT和轻量级变压器分类器，避免从头训练大规模模型，并仅更新紧凑分类器以减少通信开销。

Result: 在农业分类任务中，该方法达到了86.6%的准确率，比基线联邦学习方法提高了4倍以上。

Conclusion: 该论文提出的方法成功地将预训练的CLIP ViT与轻量级变压器分类器结合，显著提高了农业分类任务的准确率，同时解决了隐私和通信成本问题。

Abstract: Accurate classification plays a pivotal role in smart agriculture, enabling
applications such as crop monitoring, fruit recognition, and pest detection.
However, conventional centralized training often requires large-scale data
collection, which raises privacy concerns, while standard federated learning
struggles with non-independent and identically distributed (non-IID) data and
incurs high communication costs. To address these challenges, we propose a
federated learning framework that integrates a frozen Contrastive
Language-Image Pre-training (CLIP) vision transformer (ViT) with a lightweight
transformer classifier. By leveraging the strong feature extraction capability
of the pre-trained CLIP ViT, the framework avoids training large-scale models
from scratch and restricts federated updates to a compact classifier, thereby
reducing transmission overhead significantly. Furthermore, to mitigate
performance degradation caused by non-IID data distribution, a small subset
(1%) of CLIP-extracted feature representations from all classes is shared
across clients. These shared features are non-reversible to raw images,
ensuring privacy preservation while aligning class representation across
participants. Experimental results on agricultural classification tasks show
that the proposed method achieve 86.6% accuracy, which is more than 4 times
higher compared to baseline federated learning approaches. This demonstrates
the effectiveness and efficiency of combining vision-language model features
with federated learning for privacy-preserving and scalable agricultural
intelligence.

</details>


### [41] [Multi-View Consistent Human Image Customization via In-Context Learning](https://arxiv.org/abs/2511.00293)
*Hengjia Li,Jianjin Xu,Keli Cheng,Lei Wang,Ning Bi,Boxi Wu,Fernando De la Torre,Deng Cai*

Main category: cs.CV

TL;DR: PersonalView是一种轻量级适配方法，仅需100样本即可提升生成模型的多视图能力，表现优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以控制生成图像视角或生成一致的多视图，PersonalView旨在解决这一问题。

Method: 设计了条件架构以利用预训练扩散变换器的上下文学习能力，并引入语义对应对齐损失以保持预训练模型的原始生成能力。

Result: 在多视图一致性、文本对齐、身份相似性和视觉质量方面显著优于基线。

Conclusion: PersonalView通过轻量级适配方法，显著提升了生成模型在多视图生成上的能力，仅需100个训练样本即可超越现有基线。

Abstract: Recent advances in personalized generative models demonstrate impressive
results in creating identity-consistent images of the same person under diverse
settings. Yet, we note that most methods cannot control the viewpoint of the
generated image, nor generate consistent multiple views of the person. To
address this problem, we propose a lightweight adaptation method, PersonalView,
capable of enabling an existing model to acquire multi-view generation
capability with as few as 100 training samples. PersonalView consists of two
key components: First, we design a conditioning architecture to take advantage
of the in-context learning ability of the pre-trained diffusion transformer.
Second, we preserve the original generative ability of the pretrained model
with a new Semantic Correspondence Alignment Loss. We evaluate the multi-view
consistency, text alignment, identity similarity, and visual quality of
PersonalView and compare it to recent baselines with potential capability of
multi-view customization. PersonalView significantly outperforms baselines
trained on a large corpus of multi-view data with only 100 training samples.

</details>


### [42] [Towards Automated Petrography](https://arxiv.org/abs/2511.00328)
*Isai Daniel Chacón,Paola Ruiz Puentes,Jillian Pearse,Pablo Arbeláez*

Main category: cs.CV

TL;DR: LITHOS是一个大规模岩石学数据集，通过深度学习技术实现了高效的自动化矿物分类。


<details>
  <summary>Details</summary>
Motivation: 传统岩石学分析依赖专家手动操作，效率低且难以扩展，因此需要自动化技术。

Method: 引入LITHOS数据集，评估多种深度学习技术，并提出一种双编码器变压器架构。

Result: 提出的双编码器变压器架构在矿物分类中表现优于单偏振模型。

Conclusion: LITHOS提供了一个大规模、多样化的公开数据集，为自动化岩石学分析奠定了基础，并展示了偏振协同在矿物分类中的价值。

Abstract: Petrography is a branch of geology that analyzes the mineralogical
composition of rocks from microscopical thin section samples. It is essential
for understanding rock properties across geology, archaeology, engineering,
mineral exploration, and the oil industry. However, petrography is a
labor-intensive task requiring experts to conduct detailed visual examinations
of thin section samples through optical polarization microscopes, thus
hampering scalability and highlighting the need for automated techniques. To
address this challenge, we introduce the Large-scale Imaging and Thin section
Optical-polarization Set (LITHOS), the largest and most diverse publicly
available experimental framework for automated petrography. LITHOS includes
211,604 high-resolution RGB patches of polarized light and 105,802
expert-annotated grains across 25 mineral categories. Each annotation consists
of the mineral class, spatial coordinates, and expert-defined major and minor
axes represented as intersecting vector paths, capturing grain geometry and
orientation. We evaluate multiple deep learning techniques for mineral
classification in LITHOS and propose a dual-encoder transformer architecture
that integrates both polarization modalities as a strong baseline for future
reference. Our method consistently outperforms single-polarization models,
demonstrating the value of polarization synergy in mineral classification. We
have made the LITHOS Benchmark publicly available, comprising our dataset,
code, and pretrained models, to foster reproducibility and further research in
automated petrographic analysis.

</details>


### [43] [Beyond ImageNet: Understanding Cross-Dataset Robustness of Lightweight Vision Models](https://arxiv.org/abs/2511.00335)
*Weidong Zhang,Pak Lun Kevin Ding,Huan Liu*

Main category: cs.CV

TL;DR: 本研究系统评估了轻量级视觉模型在多样化数据集上的表现，提出xScore作为泛化性能指标，并揭示了促进泛化的关键架构设计原则。


<details>
  <summary>Details</summary>
Motivation: 探讨在ImageNet上表现优异的模型是否在其他领域也能泛化良好，如何系统量化跨数据集的稳健性，以及哪些架构元素在资源受限条件下能持续驱动泛化。

Method: 对11种轻量级视觉模型在7个多样化数据集上进行了固定100轮训练的系统评估，并引入了跨数据集评分（xScore）作为统一度量标准。

Result: 研究发现：(1) ImageNet准确率不能可靠预测细粒度或医学数据集的性能；(2) xScore是可扩展的移动模型性能预测指标；(3) 某些架构组件（如更高空间分辨率的各向同性卷积和通道注意力）能促进更广泛的泛化，而基于Transformer的模块则带来较少额外益处。

Conclusion: 本研究为评估轻量级视觉模型提供了可重复的框架，强调了移动友好架构的关键设计原则，并指导未来模型在多样化应用领域中实现稳健泛化的开发。

Abstract: Lightweight vision classification models such as MobileNet, ShuffleNet, and
EfficientNet are increasingly deployed in mobile and embedded systems, yet
their performance has been predominantly benchmarked on ImageNet. This raises
critical questions: Do models that excel on ImageNet also generalize across
other domains? How can cross-dataset robustness be systematically quantified?
And which architectural elements consistently drive generalization under tight
resource constraints? Here, we present the first systematic evaluation of 11
lightweight vision models (2.5M parameters), trained under a fixed 100-epoch
schedule across 7 diverse datasets. We introduce the Cross-Dataset Score
(xScore), a unified metric that quantifies the consistency and robustness of
model performance across diverse visual domains. Our results show that (1)
ImageNet accuracy does not reliably predict performance on fine-grained or
medical datasets, (2) xScore provides a scalable predictor of mobile model
performance that can be estimated from just four datasets, and (3) certain
architectural components--such as isotropic convolutions with higher spatial
resolution and channel-wise attention--promote broader generalization, while
Transformer-based blocks yield little additional benefit, despite incurring
higher parameter overhead. This study provides a reproducible framework for
evaluating lightweight vision models beyond ImageNet, highlights key design
principles for mobile-friendly architectures, and guides the development of
future models that generalize robustly across diverse application domains.

</details>


### [44] [A DeepONet joint Neural Tangent Kernel Hybrid Framework for Physics-Informed Inverse Source Problems and Robust Image Reconstruction](https://arxiv.org/abs/2511.00338)
*Yuhao Fang,Zijian Wang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: 该研究提出了一种结合DeepONet和NTK的混合方法，用于解决复杂逆问题，如Navier-Stokes方程控制的源定位和图像重建，效果显著。


<details>
  <summary>Details</summary>
Motivation: 为解决复杂逆问题中的非线性、稀疏性和噪声数据挑战，开发一种既能保证物理一致性又准确的解决方案。

Method: 通过将DeepONet与NTK相结合，并融入物理约束和任务特定的正则化到损失函数中，解决了非线性、稀疏性和噪声数据带来的挑战。

Result: 在合成和真实数据集上的验证表明，该方法具有鲁棒性、可扩展性和高精度。

Conclusion: 该论文提出的混合框架在计算物理学和成像科学中展示了广泛的应用潜力，通过验证其在不同数据集上的鲁棒性、可扩展性和精确性。

Abstract: This work presents a novel hybrid approach that integrates Deep Operator
Networks (DeepONet) with the Neural Tangent Kernel (NTK) to solve complex
inverse problem. The method effectively addresses tasks such as source
localization governed by the Navier-Stokes equations and image reconstruction,
overcoming challenges related to nonlinearity, sparsity, and noisy data. By
incorporating physics-informed constraints and task-specific regularization
into the loss function, the framework ensures solutions that are both
physically consistent and accurate. Validation on diverse synthetic and real
datasets demonstrates its robustness, scalability, and precision, showcasing
its broad potential applications in computational physics and imaging sciences.

</details>


### [45] [Federated Dialogue-Semantic Diffusion for Emotion Recognition under Incomplete Modalities](https://arxiv.org/abs/2511.00344)
*Xihang Qiu,Jiarong Cheng,Yuhao Fang,Wanpeng Zhang,Yao Lu,Ye Zhang,Chun Li*

Main category: cs.CV

TL;DR: FedDISC框架通过联邦学习和语义一致的扩散模型，解决了多模态情感识别中的模态缺失问题，提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 现实场景中多模态数据的不可预测缺失会显著降低现有方法的性能，传统方法在极端数据分布下易产生语义失真。

Method: 提出了FedDISC框架，结合联邦学习和扩散模型，通过对话图网络和语义条件网络确保语义一致性，并采用交替冻结聚合策略优化模型。

Result: 在IEMOCAP、CMUMOSI和CMUMOSEI数据集上的实验表明，FedDISC在多种模态缺失模式下均优于现有方法。

Conclusion: FedDISC框架通过联邦学习和语义一致的扩散模型，有效解决了多模态情感识别中的模态缺失问题，显著提升了情感分类性能。

Abstract: Multimodal Emotion Recognition in Conversations (MERC) enhances emotional
understanding through the fusion of multimodal signals. However, unpredictable
modality absence in real-world scenarios significantly degrades the performance
of existing methods. Conventional missing-modality recovery approaches, which
depend on training with complete multimodal data, often suffer from semantic
distortion under extreme data distributions, such as fixed-modality absence. To
address this, we propose the Federated Dialogue-guided and Semantic-Consistent
Diffusion (FedDISC) framework, pioneering the integration of federated learning
into missing-modality recovery. By federated aggregation of modality-specific
diffusion models trained on clients and broadcasting them to clients missing
corresponding modalities, FedDISC overcomes single-client reliance on modality
completeness. Additionally, the DISC-Diffusion module ensures consistency in
context, speaker identity, and semantics between recovered and available
modalities, using a Dialogue Graph Network to capture conversational
dependencies and a Semantic Conditioning Network to enforce semantic alignment.
We further introduce a novel Alternating Frozen Aggregation strategy, which
cyclically freezes recovery and classifier modules to facilitate collaborative
optimization. Extensive experiments on the IEMOCAP, CMUMOSI, and CMUMOSEI
datasets demonstrate that FedDISC achieves superior emotion classification
performance across diverse missing modality patterns, outperforming existing
approaches.

</details>


### [46] [OSMGen: Highly Controllable Satellite Image Synthesis using OpenStreetMap Data](https://arxiv.org/abs/2511.00345)
*Amir Ziashahabi,Narges Ghasemi,Sajjad Shahabi,John Krumm,Salman Avestimehr,Cyrus Shahabi*

Main category: cs.CV

TL;DR: OSMGen直接从OSM数据生成真实卫星图像，解决数据稀缺问题，支持训练数据生成和城市规划预览。


<details>
  <summary>Details</summary>
Motivation: 自动化城市监测面临的主要挑战是缺乏特定城市特征及其变化的精选数据集。OSMGen旨在解决这一问题，通过生成数据来应对稀缺性和类别不平衡，并为规划者提供预览工具。

Method: OSMGen是一个生成框架，直接从原始OpenStreetMap（OSM）数据创建真实的卫星图像，利用OSM JSON的丰富信息（如矢量几何、语义标签、位置和时间）进行精细控制。

Result: OSMGen能够生成一致的“前后”图像对，用户对OSM输入的编辑会转化为有针对性的视觉变化，同时保持场景其余部分不变。这为生成训练数据和预览干预效果提供了可能。

Conclusion: OSMGen通过生成真实的卫星图像，解决了城市监测中数据稀缺和类别不平衡的问题，并为城市规划者提供了一种预览干预效果的简单方法。此外，它为构建闭环系统奠定了基础，使卫星图像能自动驱动结构化OSM更新。

Abstract: Accurate and up-to-date geospatial data are essential for urban planning,
infrastructure monitoring, and environmental management. Yet, automating urban
monitoring remains difficult because curated datasets of specific urban
features and their changes are scarce. We introduce OSMGen, a generative
framework that creates realistic satellite imagery directly from raw
OpenStreetMap (OSM) data. Unlike prior work that relies on raster tiles, OSMGen
uses the full richness of OSM JSON, including vector geometries, semantic tags,
location, and time, giving fine-grained control over how scenes are generated.
A central feature of the framework is the ability to produce consistent
before-after image pairs: user edits to OSM inputs translate into targeted
visual changes, while the rest of the scene is preserved. This makes it
possible to generate training data that addresses scarcity and class imbalance,
and to give planners a simple way to preview proposed interventions by editing
map data. More broadly, OSMGen produces paired (JSON, image) data for both
static and changed states, paving the way toward a closed-loop system where
satellite imagery can automatically drive structured OSM updates. Source code
is available at https://github.com/amir-zsh/OSMGen.

</details>


### [47] [Detecting AI-Generated Images via Diffusion Snap-Back Reconstruction: A Forensic Approach](https://arxiv.org/abs/2511.00352)
*Mohd Ruhul Ameen,Akif Islam*

Main category: cs.CV

TL;DR: 本文提出了一种基于扩散模型的图像检测框架，利用多强度图像重建动态（扩散回弹）来识别AI生成图像，通过分析重建指标在不同噪声强度下的变化，提取可解释的流形特征，区分真实与合成图像。


<details>
  <summary>Details</summary>
Motivation: 随着生成扩散模型的快速发展，区分真实与合成图像的难度增加，传统依赖频率或像素级伪影的深度伪造检测方法已无法应对现代文本到图像系统（如Stable Diffusion和DALL-E）。

Method: 提出扩散法医框架，利用多强度图像重建动态（扩散回弹）分析重建指标（LPIPS、SSIM、PSNR）在不同噪声强度下的演化，提取流形特征。

Result: 在4000张图像的平衡数据集上，交叉验证下达到0.993 AUROC，对压缩和噪声等常见失真具有鲁棒性。

Conclusion: 尽管数据有限且仅使用单一扩散骨干（Stable Diffusion v1.5），该方法展示了强大的泛化能力和可解释性，为可扩展、模型无关的合成媒体法医奠定了基础。

Abstract: The rapid rise of generative diffusion models has made distinguishing
authentic visual content from synthetic imagery increasingly challenging.
Traditional deepfake detection methods, which rely on frequency or pixel-level
artifacts, fail against modern text-to-image systems such as Stable Diffusion
and DALL-E that produce photorealistic and artifact-free results. This paper
introduces a diffusion-based forensic framework that leverages multi-strength
image reconstruction dynamics, termed diffusion snap-back, to identify
AI-generated images. By analysing how reconstruction metrics (LPIPS, SSIM, and
PSNR) evolve across varying noise strengths, we extract interpretable
manifold-based features that differentiate real and synthetic images. Evaluated
on a balanced dataset of 4,000 images, our approach achieves 0.993 AUROC under
cross-validation and remains robust to common distortions such as compression
and noise. Despite using limited data and a single diffusion backbone (Stable
Diffusion v1.5), the proposed method demonstrates strong generalization and
interpretability, offering a foundation for scalable, model-agnostic synthetic
media forensics.

</details>


### [48] [Transfer Learning for Onboard Cloud Segmentation in Thermal Earth Observation: From Landsat to a CubeSat Constellation](https://arxiv.org/abs/2511.00357)
*Niklas Wölki,Lukas Kondmann,Christian Mollière,Martin Langer,Julia Gottfriedsen,Martin Werner*

Main category: cs.CV

TL;DR: 通过迁移学习和轻量级UNet架构，解决了CubeSat热红外云分割的硬件和数据限制问题，实现了高效准确的实时云掩膜。


<details>
  <summary>Details</summary>
Motivation: 立方星（CubeSat）任务受限于硬件和光谱信息，通常仅依赖单一热红外波段且缺乏足够的标记数据，传统云掩膜技术难以应用。

Method: 采用迁移学习方法，使用UNet与轻量级MobileNet编码器，先在公开的Landsat-7云覆盖评估数据集上进行预训练，再通过少量任务特定样本进行微调。

Result: 联合训练设置下，宏F1从0.850提升至0.877；模型转换为TensorRT引擎后，在NVIDIA Jetson Nano上实现全图推理时间低于5秒。

Conclusion: 利用公开数据集和轻量级架构可以在轨实现准确、高效的热红外云分割，支持数据有限的地球观测任务中的实时决策。

Abstract: Onboard cloud segmentation is a critical yet underexplored task in thermal
Earth observation (EO), particularly for CubeSat missions constrained by
limited hardware and spectral information. CubeSats often rely on a single
thermal band and lack sufficient labeled data, making conventional cloud
masking techniques infeasible. This work addresses these challenges by applying
transfer learning to thermal cloud segmentation for the FOREST-2 CubeSat, using
a UNet with a lightweight MobileNet encoder. We pretrain the model on the
public Landsat-7 Cloud Cover Assessment Dataset and fine-tune it with a small
set of mission-specific samples in a joint-training setup, improving the macro
F1 from 0.850 to 0.877 over FOREST-2-only baselines. We convert the model to a
TensorRT engine and demonstrate full-image inference in under 5 seconds on an
NVIDIA Jetson Nano. These results show that leveraging public datasets and
lightweight architectures can enable accurate, efficient thermal-only cloud
masking on-orbit, supporting real-time decision-making in data-limited EO
missions.

</details>


### [49] [Who Can We Trust? Scope-Aware Video Moment Retrieval with Multi-Agent Conflict](https://arxiv.org/abs/2511.00370)
*Chaochen Wu,Guan Luo,Meiyun Zuo,Zhitao Fan*

Main category: cs.CV

TL;DR: 该论文提出了一种基于强化学习和多智能体系统的视频时刻检索方法，有效解决模型间冲突并提升性能，同时展示了证据学习的新应用。


<details>
  <summary>Details</summary>
Motivation: 当前视频时刻检索解决方案未考虑不同模型间定位结果的冲突，导致模型无法有效整合以提升性能。

Method: 提出了一种基于强化学习的视频时刻检索模型，能够一次性扫描整个视频以找到时刻边界，并生成定位证据；同时设计了一个多智能体系统框架，利用证据学习解决智能体间的定位输出冲突。

Result: 在基准数据集上的广泛实验表明，所提方法优于现有先进方法，且无需额外训练即可判断查询是否无对应视频时刻（超出范围）。

Conclusion: 该研究通过强化学习模型和多智能体系统框架，有效解决了视频时刻检索中的冲突问题，并展示了证据学习在多智能体框架中的新角色。

Abstract: Video moment retrieval uses a text query to locate a moment from a given
untrimmed video reference. Locating corresponding video moments with text
queries helps people interact with videos efficiently. Current solutions for
this task have not considered conflict within location results from different
models, so various models cannot integrate correctly to produce better results.
This study introduces a reinforcement learning-based video moment retrieval
model that can scan the whole video once to find the moment's boundary while
producing its locational evidence. Moreover, we proposed a multi-agent system
framework that can use evidential learning to resolve conflicts between agents'
localization output. As a side product of observing and dealing with conflicts
between agents, we can decide whether a query has no corresponding moment in a
video (out-of-scope) without additional training, which is suitable for
real-world applications. Extensive experiments on benchmark datasets show the
effectiveness of our proposed methods compared with state-of-the-art
approaches. Furthermore, the results of our study reveal that modeling
competition and conflict of the multi-agent system is an effective way to
improve RL performance in moment retrieval and show the new role of evidential
learning in the multi-agent framework.

</details>


### [50] [VisionCAD: An Integration-Free Radiology Copilot Framework](https://arxiv.org/abs/2511.00381)
*Jiaming Li,Junlei Wu,Sheng Wang,Honglin Xiong,Jiangdong Cai,Zihao Zhao,Yitao Zhu,Yuan Yin,Dinggang Shen,Qian Wang*

Main category: cs.CV

TL;DR: VisionCAD是一种基于视觉的放射辅助框架，通过相机捕获屏幕图像并转化为诊断质量图像，无需修改现有IT基础设施，性能接近传统CAD系统。


<details>
  <summary>Details</summary>
Motivation: 现有的CAD系统由于难以与医院IT基础设施集成而难以广泛临床应用。VisionCAD旨在通过视觉捕获技术绕过这一障碍。

Method: VisionCAD通过自动化流程检测、恢复和分析屏幕上的医学图像，将相机捕获的视觉数据转化为适合自动分析和报告生成的诊断质量图像。

Result: VisionCAD在多样化医学影像数据集上验证，其模块化架构能灵活利用最先进的诊断模型，诊断性能接近传统CAD系统。

Conclusion: VisionCAD提供了一种无需修改现有医院IT基础设施即可部署AI辅助诊断的解决方案，其诊断性能与传统CAD系统相当，F1分数下降通常小于2%，自动报告的自然语言生成指标与原图像相差不到1%。

Abstract: Widespread clinical deployment of computer-aided diagnosis (CAD) systems is
hindered by the challenge of integrating with existing hospital IT
infrastructure. Here, we introduce VisionCAD, a vision-based radiological
assistance framework that circumvents this barrier by capturing medical images
directly from displays using a camera system. The framework operates through an
automated pipeline that detects, restores, and analyzes on-screen medical
images, transforming camera-captured visual data into diagnostic-quality images
suitable for automated analysis and report generation. We validated VisionCAD
across diverse medical imaging datasets, demonstrating that our modular
architecture can flexibly utilize state-of-the-art diagnostic models for
specific tasks. The system achieves diagnostic performance comparable to
conventional CAD systems operating on original digital images, with an F1-score
degradation typically less than 2\% across classification tasks, while natural
language generation metrics for automated reports remain within 1\% of those
derived from original images. By requiring only a camera device and standard
computing resources, VisionCAD offers an accessible approach for AI-assisted
diagnosis, enabling the deployment of diagnostic capabilities in diverse
clinical settings without modifications to existing infrastructure.

</details>


### [51] [Rethinking Facial Expression Recognition in the Era of Multimodal Large Language Models: Benchmark, Datasets, and Beyond](https://arxiv.org/abs/2511.00389)
*Fan Zhang,Haoxuan Li,Shengju Qian,Xin Wang,Zheng Lian,Hao Wu,Zhihong Zhu,Yuan Gao,Qiankun Li,Yefeng Zheng,Zhouchen Lin,Pheng-Ann Heng*

Main category: cs.CV

TL;DR: 研究评估了20种MLLM在FER任务中的表现，发现其在推理能力上有限，随后提出了后训练策略并开发了UniFER-7B模型，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型（MLLMs）在多个任务中表现优异，但其在面部表情识别（FER）任务中的性能尚未被充分探索。

Method: 提出了FERBench基准测试，评估了20种先进MLLM在四个FER数据集上的表现，并引入了两种后训练策略：UniFER-CoT-230K用于冷启动初始化，UniFER-RLVR-360K用于基于可验证奖励的强化学习（RLVR）。

Result: MLLMs在FER任务中表现出良好的分类性能，但在推理和可解释性方面存在显著局限性。

Conclusion: UniFER-7B模型在面部表情识别任务中表现出色，超越了多个开源和闭源的通用多模态大语言模型（如Gemini-2.5-Pro和Qwen2.5-VL-72B）。

Abstract: Multimodal Large Language Models (MLLMs) have revolutionized numerous
research fields, including computer vision and affective computing. As a
pivotal challenge in this interdisciplinary domain, facial expression
recognition (FER) has evolved from separate, domain-specific models to more
unified approaches. One promising avenue to unify FER tasks is converting
conventional FER datasets into visual question-answering (VQA) formats,
enabling the direct application of powerful generalist MLLMs for inference.
However, despite the success of cutting-edge MLLMs in various tasks, their
performance on FER tasks remains largely unexplored. To address this gap, we
provide FERBench, a systematic benchmark that incorporates 20 state-of-the-art
MLLMs across four widely used FER datasets. Our results reveal that, while
MLLMs exhibit good classification performance, they still face significant
limitations in reasoning and interpretability. To this end, we introduce
post-training strategies aimed at enhancing the facial expression reasoning
capabilities of MLLMs. Specifically, we curate two high-quality and large-scale
datasets: UniFER-CoT-230K for cold-start initialization and UniFER-RLVR-360K
for reinforcement learning with verifiable rewards (RLVR), respectively.
Building upon them, we develop a unified and interpretable FER foundation model
termed UniFER-7B, which outperforms many open-sourced and closed-source
generalist MLLMs (e.g., Gemini-2.5-Pro and Qwen2.5-VL-72B).

</details>


### [52] [VinciCoder: Unifying Multimodal Code Generation via Coarse-to-fine Visual Reinforcement Learning](https://arxiv.org/abs/2511.00391)
*Xuanle Zhao,Deyang Jiang,Zhixiong Zeng,Lei Chen,Haibo Qiu,Jing Huang,Yufeng Zhong,Liming Zheng,Yilin Cao,Lin Ma*

Main category: cs.CV

TL;DR: VinciCoder通过两阶段训练（SFT+ViRL）和粗到细奖励机制，实现了多模态代码生成的统一模型，性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）在单任务训练模式下泛化能力有限，阻碍了多模态代码智能的通用性发展。

Method: 采用两阶段训练框架：首先构建包含160万图像-代码对的SFT语料库，随后引入视觉强化学习（ViRL）策略，通过局部和全局图像块的视觉相似性计算来优化模型。

Result: VinciCoder在多个多模态代码生成基准测试中达到了最先进的性能。

Conclusion: VinciCoder通过两阶段训练框架（SFT和ViRL）实现了多模态代码生成的统一模型，其粗到细的ViRL策略显著提升了视觉保真度，并在多个基准测试中取得了最先进的性能。

Abstract: Multimodal code generation has garnered significant interest within the
research community. Despite the notable success of recent vision-language
models (VLMs) on specialized tasks like Chart-to-code generation, their
reliance on single-task training regimens fosters a narrow paradigm that
hinders the development of generalized \textbf{VI}sio\textbf{N} \textbf{C}ode
\textbf{I}ntelligence. In this work, we introduce \textbf{VinciCoder}, a
unified multimodal code generation model that addresses this limitation via a
two-stage training framework. We begin by constructing a large-scale Supervised
Finetuning (SFT) corpus comprising 1.6M image-code pairs for tasks involving
direct code generation and visual-based code refinement. Subsequently, we
introduce a Visual Reinforcement Learning (ViRL) strategy, which employs a
coarse-to-fine reward mechanism to improve visual fidelity by calculating
visual similarity across local and global image patches. Extensive experiments
on various multimodal code generation benchmarks demonstrate that VinciCoder
achieves state-of-the-art performance, underscoring the effectiveness of our
coarse-to-fine ViRL strategy. The code and model will be available at
https://github.com/DocTron-hub/VinciCoder.

</details>


### [53] [CoT-Saliency: Unified Chain-of-Thought Reasoning for Heterogeneous Saliency Tasks](https://arxiv.org/abs/2511.00396)
*Long Li,Shuichen Ji,Ziyang Luo,Nian Liu,Dingwen Zhang,Junwei Han*

Main category: cs.CV

TL;DR: 该论文提出一个统一框架，通过CoT推理处理三种异构显著性任务，使用两阶段训练和CGPO算法提升性能，实验显示其在所有任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决操作上异构的显著性任务（SOD、CoSOD、SIS）的挑战，并克服现有方法（如GRPO）在置信度无关学习、信号稀释和计算开销方面的局限性。

Method: 采用两阶段训练范式：监督微调（SFT）和强化学习（RL），并提出Confidence-Guided Policy Optimization (CGPO)算法，通过利用奖励与模型置信度之间的差异作为每样本优势信号，提升CoT质量。

Result: 实验表明，该模型在所有任务中均匹配或超越了专门化的SOTA方法，特别是在CoSOD任务上达到了0.899的S-measure，比之前的最佳方法提高了8.0个百分点。

Conclusion: 该论文提出的统一框架通过Chain-of-Thought (CoT)推理过程，成功处理了三种操作上异构的显著性任务（SOD、CoSOD、SIS），并在所有任务中匹配或超越了专门化的SOTA方法和强大的闭源VLM。

Abstract: We present the first unified framework that jointly handles three
operationally heterogeneous saliency tasks, eg, SOD, CoSOD, and SIS, by casting
each as a Chain-of-Thought (CoT) reasoning process in a Vision-Language Model
(VLM) to bridge task heterogeneity. CoT training follows a two-stage paradigm:
Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). To enhance CoT
quality in RL, we propose Confidence-Guided Policy Optimization (CGPO), a
lightweight single-sample algorithm that leverages the discrepancy between
reward and model confidence as a per-sample advantage signal. This design
naturally focuses updates on informative responses while eliminating group
sampling, thereby addressing GRPO's key limitations: confidence-agnostic
learning, signal dilution, and prohibitive computational overhead. We also
introduce an "output-to-reasoning" strategy to construct high-fidelity SFT data
that ensures logical consistency with ground-truth masks. Experiments show our
model matches or outperforms specialized SOTA methods and strong closed-source
VLMs across all tasks, especially achieving an S-measure of 0.899 on CoCA for
CoSOD, surpassing the prior best by 8.0 percentage points, despite using far
less training data.

</details>


### [54] [LGCA: Enhancing Semantic Representation via Progressive Expansion](https://arxiv.org/abs/2511.00419)
*Thanh Hieu Cao,Trung Khang Tran,Gia Thinh Pham,Tuong Nghiem Diep,Thanh Binh Nguyen*

Main category: cs.CV

TL;DR: LGCA框架通过局部-全局交叉对齐提升CLIP模型的零样本图像分类性能，减少错误信息，保持高效。


<details>
  <summary>Details</summary>
Motivation: 解决CLIP模型因随机裁剪图像引入的错误信息和偏见问题，同时提升零样本图像分类性能。

Method: 提出了Localized-Globalized Cross-Alignment (LGCA)框架，先捕捉图像的局部特征，然后重复选择最显著区域并扩展，设计相似度评分以结合原始和扩展图像。

Result: 在多个数据集上显著提升了零样本性能，优于现有最先进基线方法。

Conclusion: LGCA框架通过结合局部和全局特征，显著提升了零样本图像分类的性能，同时保持了高效性和可扩展性。

Abstract: Recent advancements in large-scale pretraining in natural language processing
have enabled pretrained vision-language models such as CLIP to effectively
align images and text, significantly improving performance in zero-shot image
classification tasks. Subsequent studies have further demonstrated that
cropping images into smaller regions and using large language models to
generate multiple descriptions for each caption can further enhance model
performance. However, due to the inherent sensitivity of CLIP, random image
crops can introduce misinformation and bias, as many images share similar
features at small scales. To address this issue, we propose
Localized-Globalized Cross-Alignment (LGCA), a framework that first captures
the local features of an image and then repeatedly selects the most salient
regions and expands them. The similarity score is designed to incorporate both
the original and expanded images, enabling the model to capture both local and
global features while minimizing misinformation. Additionally, we provide a
theoretical analysis demonstrating that the time complexity of LGCA remains the
same as that of the original model prior to the repeated expansion process,
highlighting its efficiency and scalability. Extensive experiments demonstrate
that our method substantially improves zero-shot performance across diverse
datasets, outperforming state-of-the-art baselines.

</details>


### [55] [Leveraging Hierarchical Image-Text Misalignment for Universal Fake Image Detection](https://arxiv.org/abs/2511.00427)
*Daichi Zhang,Tong Zhang,Jianmin Bao,Shiming Ge,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 论文提出ITEM方法，利用图像-文本错位作为多模态线索，显著提升伪造图像检测的泛化性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注视觉线索，容易过拟合特定图像模式且难以泛化到未见过的生成模型，因此需要从多模态角度解决伪造图像检测问题。

Method: 首先在预训练的CLIP空间中测量图像与标题的错位程度，然后通过调整MLP头进行检测任务，并进一步提出分层错位方案，从全局和局部语义层面探索错位线索。

Result: 实验证明，ITEM方法在各种最新生成模型上均表现出优异的泛化能力和鲁棒性，显著优于其他最先进方法。

Conclusion: 论文提出了一种基于图像-文本错位的多模态检测方法ITEM，通过利用预训练的CLIP空间中的错位信息，显著提升了伪造图像检测的泛化能力和鲁棒性。

Abstract: With the rapid development of generative models, detecting generated fake
images to prevent their malicious use has become a critical issue recently.
Existing methods frame this challenge as a naive binary image classification
task. However, such methods focus only on visual clues, yielding trained
detectors susceptible to overfitting specific image patterns and incapable of
generalizing to unseen models. In this paper, we address this issue from a
multi-modal perspective and find that fake images cannot be properly aligned
with corresponding captions compared to real images. Upon this observation, we
propose a simple yet effective detector termed ITEM by leveraging the
image-text misalignment in a joint visual-language space as discriminative
clues. Specifically, we first measure the misalignment of the images and
captions in pre-trained CLIP's space, and then tune a MLP head to perform the
usual detection task. Furthermore, we propose a hierarchical misalignment
scheme that first focuses on the whole image and then each semantic object
described in the caption, which can explore both global and fine-grained local
semantic misalignment as clues. Extensive experiments demonstrate the
superiority of our method against other state-of-the-art competitors with
impressive generalization and robustness on various recent generative models.

</details>


### [56] [Enhancing Frequency Forgery Clues for Diffusion-Generated Image Detection](https://arxiv.org/abs/2511.00429)
*Daichi Zhang,Tong Zhang,Shiming Ge,Sabine Süsstrunk*

Main category: cs.CV

TL;DR: 论文提出一种基于频率选择性增强的检测方法（F^2C），有效区分自然与扩散生成图像，泛化性和鲁棒性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成的图像质量高，可能被恶意使用，而现有检测器在泛化和抗干扰能力上不足。

Method: 通过分析扩散生成图像与自然图像在低至高频频段的差异，设计了一个频率选择性函数作为加权滤波器，增强信息丰富的频段，抑制判别性较低的频段。

Result: 在多个扩散生成图像数据集上的实验表明，该方法在泛化性和鲁棒性上优于现有最优检测器。

Conclusion: 该论文提出了一种基于频率选择性增强的检测方法（F^2C），能够有效区分自然图像与扩散模型生成的图像，并在泛化性和鲁棒性上优于现有方法。

Abstract: Diffusion models have achieved remarkable success in image synthesis, but the
generated high-quality images raise concerns about potential malicious use.
Existing detectors often struggle to capture discriminative clues across
different models and settings, limiting their generalization to unseen
diffusion models and robustness to various perturbations. To address this
issue, we observe that diffusion-generated images exhibit progressively larger
differences from natural real images across low- to high-frequency bands. Based
on this insight, we propose a simple yet effective representation by enhancing
the Frequency Forgery Clue (F^2C) across all frequency bands. Specifically, we
introduce a frequency-selective function which serves as a weighted filter to
the Fourier spectrum, suppressing less discriminative bands while enhancing
more informative ones. This approach, grounded in a comprehensive analysis of
frequency-based differences between natural real and diffusion-generated
images, enables general detection of images from unseen diffusion models and
provides robust resilience to various perturbations. Extensive experiments on
various diffusion-generated image datasets demonstrate that our method
outperforms state-of-the-art detectors with superior generalization and
robustness.

</details>


### [57] [ToxicTextCLIP: Text-Based Poisoning and Backdoor Attacks on CLIP Pre-training](https://arxiv.org/abs/2511.00446)
*Xin Yao,Haiyang Zhao,Yimin Chen,Jiawei Guo,Kecheng Huang,Ming Zhao*

Main category: cs.CV

TL;DR: ToxicTextCLIP 是一种针对 CLIP 预训练的文本对抗攻击框架，通过背景感知和增强技术实现高效攻击，实验验证其高成功率和防御绕过能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注基于图像的攻击，而 CLIP 训练中同样关键的文本模态尚未充分探索，且依赖未筛选的互联网数据可能导致数据投毒和后门风险。

Method: ToxicTextCLIP 通过迭代应用背景感知选择器和背景驱动增强器，解决语义错位和背景一致文本稀缺问题，生成多样化的投毒样本。

Result: 实验表明，ToxicTextCLIP 在分类和检索任务中表现出色，攻击成功率高且能绕过多种防御方法。

Conclusion: ToxicTextCLIP 框架成功生成了高质量的对抗性文本，针对 CLIP 的预训练阶段，实现了高达 95.83% 的投毒成功率和 98.68% 的后门攻击成功率，并绕过了现有防御方法。

Abstract: The Contrastive Language-Image Pretraining (CLIP) model has significantly
advanced vision-language modeling by aligning image-text pairs from large-scale
web data through self-supervised contrastive learning. Yet, its reliance on
uncurated Internet-sourced data exposes it to data poisoning and backdoor
risks. While existing studies primarily investigate image-based attacks, the
text modality, which is equally central to CLIP's training, remains
underexplored. In this work, we introduce ToxicTextCLIP, a framework for
generating high-quality adversarial texts that target CLIP during the
pre-training phase. The framework addresses two key challenges: semantic
misalignment caused by background inconsistency with the target class, and the
scarcity of background-consistent texts. To this end, ToxicTextCLIP iteratively
applies: 1) a background-aware selector that prioritizes texts with background
content aligned to the target class, and 2) a background-driven augmenter that
generates semantically coherent and diverse poisoned samples. Extensive
experiments on classification and retrieval tasks show that ToxicTextCLIP
achieves up to 95.83% poisoning success and 98.68% backdoor Hit@1, while
bypassing RoCLIP, CleanCLIP and SafeCLIP defenses. The source code can be
accessed via https://github.com/xinyaocse/ToxicTextCLIP/.

</details>


### [58] [Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations](https://arxiv.org/abs/2511.00456)
*Kiran Shahi,Anup Bagale*

Main category: cs.CV

TL;DR: 本研究提出了一种弱监督深度学习框架，用于肺炎分类和定位，利用Grad-CAM生成热图。ResNet-18和EfficientNet-B0表现最佳，准确率达98%。


<details>
  <summary>Details</summary>
Motivation: 传统的肺炎诊断需要昂贵的像素级标注，本研究旨在通过图像级标签生成肺炎区域的热图，提高肺炎筛查的透明度和临床信任。

Method: 本研究评估了七种ImageNet预训练架构（ResNet-18/50、DenseNet-121、EfficientNet-B0、MobileNet-V2/V3和ViT-B16），在相同的训练条件下使用焦点损失和患者级分割以避免数据泄露。

Result: ResNet-18和EfficientNet-B0在测试集上达到98%的准确率，ROC-AUC为0.997，F1分数为0.987。MobileNet-V2在准确性和计算成本之间提供最佳平衡。

Conclusion: 本研究提出了一种弱监督深度学习框架，用于胸部X光片的肺炎分类和定位，利用Grad-CAM解释生成临床有意义的区域热图。实验结果表明，ResNet-18和EfficientNet-B0在Kermany CXR数据集上表现最佳，准确率达98%，ROC-AUC为0.997，F1分数为0.987。Grad-CAM可视化证实模型关注临床相关肺区域，支持了可解释AI在放射诊断中的应用。

Abstract: This study proposes a weakly supervised deep learning framework for pneumonia
classification and localization from chest X-rays, utilizing Grad-CAM
explanations. Instead of costly pixel-level annotations, our approach utilizes
image-level labels to generate clinically meaningful heatmaps that highlight
regions affected by pneumonia. We evaluate seven ImageNet-pretrained
architectures ResNet-18/50, DenseNet-121, EfficientNet-B0, MobileNet-V2/V3, and
ViT-B16 under identical training conditions with focal loss and patient-wise
splits to prevent data leakage. Experimental results on the Kermany CXR dataset
demonstrate that ResNet-18 and EfficientNet-B0 achieve the best overall test
accuracy of 98\%, ROC-AUC = 0.997, and F1 = 0.987, while MobileNet-V2 provides
an optimal trade-off between accuracy and computational cost. Grad-CAM
visualizations confirm that the proposed models focus on clinically relevant
lung regions, supporting the use of interpretable AI for radiological
diagnostics. This work highlights the potential of weakly supervised
explainable models that enhance pneumonia screening transparency, and clinical
trust in AI-assisted medical imaging.
  https://github.com/kiranshahi/pneumonia-analysis

</details>


### [59] [HumanCrafter: Synergizing Generalizable Human Reconstruction and Semantic 3D Segmentation](https://arxiv.org/abs/2511.00468)
*Panwang Pan,Tingting Shen,Chenxin Li,Yunlong Lin,Kairun Wen,Jingjing Zhao,Yixuan Yuan*

Main category: cs.CV

TL;DR: HumanCrafter是一个统一框架，通过结合几何和语义先验，从单图像高效实现3D人体重建和分割。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在3D人体重建上取得高保真度，但在特定任务（如3D人体分割）上的应用仍受限。

Method: 提出HumanCrafter框架，结合几何先验和自监督语义先验，通过像素对齐聚合和多任务目标优化纹理建模和语义一致性。

Result: 实验证明HumanCrafter在3D人体分割和重建任务中表现优异。

Conclusion: HumanCrafter在单图像3D人体分割和重建任务中超越了现有最先进方法，展示了其高效性和实用性。

Abstract: Recent advances in generative models have achieved high-fidelity in 3D human
reconstruction, yet their utility for specific tasks (e.g., human 3D
segmentation) remains constrained. We propose HumanCrafter, a unified framework
that enables the joint modeling of appearance and human-part semantics from a
single image in a feed-forward manner. Specifically, we integrate human
geometric priors in the reconstruction stage and self-supervised semantic
priors in the segmentation stage. To address labeled 3D human datasets
scarcity, we further develop an interactive annotation procedure for generating
high-quality data-label pairs. Our pixel-aligned aggregation enables cross-task
synergy, while the multi-task objective simultaneously optimizes texture
modeling fidelity and semantic consistency. Extensive experiments demonstrate
that HumanCrafter surpasses existing state-of-the-art methods in both 3D
human-part segmentation and 3D human reconstruction from a single image.

</details>


### [60] [Longitudinal Vestibular Schwannoma Dataset with Consensus-based Human-in-the-loop Annotations](https://arxiv.org/abs/2511.00472)
*Navodini Wijethilake,Marina Ivory,Oscar MacCormac,Siddhant Kumar,Aaron Kujawa,Lorena Garcia-Foncillas Macias,Rebecca Burger,Amanda Hitchings,Suki Thomson,Sinan Barazi,Eleni Maratos,Rupert Obholzer,Dan Jiang,Fiona McClenaghan,Kazumi Chia,Omar Al-Salihi,Nick Thomas,Steve Connor,Tom Vercauteren,Jonathan Shapey*

Main category: cs.CV

TL;DR: 该研究提出了一种基于深度学习的人机协同框架，显著提高了前庭神经鞘瘤MRI分割的精度和效率，数据集已公开。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在自动分割方面取得进展，但在不同数据集和复杂临床案例中实现稳健性能仍具挑战，因此需要一种资源高效且可靠的自动分割方法。

Method: 通过结合多中心数据并依赖专家共识进行标注可信度验证，采用基于深度学习的迭代分割和质量优化框架。

Result: 目标内部验证数据集的Dice相似系数（DSC）从0.9125提升至0.9670，外部数据集表现稳定，效率提升约37.4%。

Conclusion: 该研究提出的人机协同模型训练方法在提高前庭神经鞘瘤（VS）自动分割精度方面表现出色，展示了其在多样化临床环境中的适应性和泛化潜力。

Abstract: Accurate segmentation of vestibular schwannoma (VS) on Magnetic Resonance
Imaging (MRI) is essential for patient management but often requires
time-intensive manual annotations by experts. While recent advances in deep
learning (DL) have facilitated automated segmentation, challenges remain in
achieving robust performance across diverse datasets and complex clinical
cases. We present an annotated dataset stemming from a bootstrapped DL-based
framework for iterative segmentation and quality refinement of VS in MRI. We
combine data from multiple centres and rely on expert consensus for
trustworthiness of the annotations. We show that our approach enables effective
and resource-efficient generalisation of automated segmentation models to a
target data distribution. The framework achieved a significant improvement in
segmentation accuracy with a Dice Similarity Coefficient (DSC) increase from
0.9125 to 0.9670 on our target internal validation dataset, while maintaining
stable performance on representative external datasets. Expert evaluation on
143 scans further highlighted areas for model refinement, revealing nuanced
cases where segmentation required expert intervention. The proposed approach is
estimated to enhance efficiency by approximately 37.4% compared to the
conventional manual annotation process. Overall, our human-in-the-loop model
training approach achieved high segmentation accuracy, highlighting its
potential as a clinically adaptable and generalisable strategy for automated VS
segmentation in diverse clinical settings. The dataset includes 190 patients,
with tumour annotations available for 534 longitudinal contrast-enhanced
T1-weighted (T1CE) scans from 184 patients, and non-annotated T2-weighted scans
from 6 patients. This dataset is publicly accessible on The Cancer Imaging
Archive (TCIA) (https://doi.org/10.7937/bq0z-xa62).

</details>


### [61] [FedMGP: Personalized Federated Learning with Multi-Group Text-Visual Prompts](https://arxiv.org/abs/2511.00480)
*Weihao Bo,Yanpeng Sun,Yu Wang,Xinyu Zhang,Zechao Li*

Main category: cs.CV

TL;DR: FedMGP是一种个性化联邦提示学习方法，通过多组提示和动态聚合策略，在保持参数效率的同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决联邦学习中个性化提示学习的多样性和语义覆盖问题，同时保持参数效率。

Method: FedMGP为每个客户端配备多组文本和视觉提示，通过多样性损失驱动各组提示学习不同的语义特征，并采用基于相似度的概率采样策略动态聚合全局提示。

Result: FedMGP在多个联邦视觉-语言基准测试中表现优异，参数效率最高，且在个性化和领域泛化任务中均优于现有方法。

Conclusion: FedMGP通过动态提示聚合策略和多样性损失，在个性化联邦提示学习中实现了最佳的参数效率和性能表现，同时在个性化和领域泛化任务中均优于现有方法。

Abstract: In this paper, we introduce FedMGP, a new paradigm for personalized federated
prompt learning in vision-language models. FedMGP equips each client with
multiple groups of paired textual and visual prompts, enabling the model to
capture diverse, fine-grained semantic and instance-level cues. A diversity
loss is introduced to drive each prompt group to specialize in distinct and
complementary semantic aspects, ensuring that the groups collectively cover a
broader range of local characteristics. During communication, FedMGP employs a
dynamic prompt aggregation strategy based on similarity-guided probabilistic
sampling: each client computes the cosine similarity between its prompt groups
and the global prompts from the previous round, then samples s groups via a
softmax-weighted distribution. This soft selection mechanism preferentially
aggregates semantically aligned knowledge while still enabling exploration of
underrepresented patterns effectively balancing the preservation of common
knowledge with client-specific features. Notably, FedMGP maintains parameter
efficiency by redistributing a fixed prompt capacity across multiple groups,
achieving state-of-the-art performance with the lowest communication parameters
among all federated prompt learning methods. Theoretical analysis shows that
our dynamic aggregation strategy promotes robust global representation learning
by reinforcing shared semantics while suppressing client-specific noise.
Extensive experiments demonstrate that FedMGP consistently outperforms prior
approaches in both personalization and domain generalization across diverse
federated vision-language benchmarks. The code will be released on
https://github.com/weihao-bo/FedMGP.git.

</details>


### [62] [Diff4Splat: Controllable 4D Scene Generation with Latent Dynamic Reconstruction Models](https://arxiv.org/abs/2511.00503)
*Panwang Pan,Chenguo Lin,Jingjing Zhao,Chenxin Li,Yuchen Lin,Haopeng Li,Honglei Yan,Kairun Wen,Yunlong Lin,Yixuan Yuan,Yadong Mu*

Main category: cs.CV

TL;DR: Diff4Splat：单图像合成4D场景的快速方法，结合视频扩散模型与几何约束，30秒内生成高质量动态场景。


<details>
  <summary>Details</summary>
Motivation: 解决从单张图像合成4D场景的挑战，结合生成模型与几何运动约束，实现高效且高质量的动态场景合成。

Method: Diff4Splat利用视频潜在变换器增强视频扩散模型，联合捕捉时空依赖性并预测时变3D高斯基元。训练目标包括外观保真度、几何精度和运动一致性。

Result: Diff4Splat在视频生成、新视角合成和几何提取任务中表现优异，效率显著高于基于优化的方法。

Conclusion: Diff4Splat 通过结合视频扩散模型的生成先验与4D数据集学习到的几何和运动约束，成功实现了从单张图像合成可控且明确的4D场景，无需优化或后处理。

Abstract: We introduce Diff4Splat, a feed-forward method that synthesizes controllable
and explicit 4D scenes from a single image. Our approach unifies the generative
priors of video diffusion models with geometry and motion constraints learned
from large-scale 4D datasets. Given a single input image, a camera trajectory,
and an optional text prompt, Diff4Splat directly predicts a deformable 3D
Gaussian field that encodes appearance, geometry, and motion, all in a single
forward pass, without test-time optimization or post-hoc refinement. At the
core of our framework lies a video latent transformer, which augments video
diffusion models to jointly capture spatio-temporal dependencies and predict
time-varying 3D Gaussian primitives. Training is guided by objectives on
appearance fidelity, geometric accuracy, and motion consistency, enabling
Diff4Splat to synthesize high-quality 4D scenes in 30 seconds. We demonstrate
the effectiveness of Diff4Splatacross video generation, novel view synthesis,
and geometry extraction, where it matches or surpasses optimization-based
methods for dynamic scene synthesis while being significantly more efficient.

</details>


### [63] [VinDr-CXR-VQA: A Visual Question Answering Dataset for Explainable Chest X-Ray Analysis with Multi-Task Learning](https://arxiv.org/abs/2511.00504)
*Hai-Dang Nguyen,Ha-Hieu Pham,Hao T. Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: VinDr-CXR-VQA是一个大规模胸部X光数据集，用于可解释的医学视觉问答，带放射科医生验证的注释，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 为了解决医学视觉问答（Med-VQA）中的空间定位和解释性问题，并提高在正常情况下的可靠性。

Method: 构建了一个包含17,597个问答对和4,394张图像的大规模胸部X光数据集，每对问题回答都带有放射科医生验证的边界框和临床推理解释。问题分类涵盖六种诊断类型，确保多样化的临床意图。

Result: 使用MedGemma-4B-it进行基准测试，性能提升了11.8%（F1 = 0.624），并实现了病灶定位。

Conclusion: VinDr-CXR-VQA数据集旨在推进可重复且临床基础的医学视觉问答研究，数据集和评估工具已公开。

Abstract: We present VinDr-CXR-VQA, a large-scale chest X-ray dataset for explainable
Medical Visual Question Answering (Med-VQA) with spatial grounding. The dataset
contains 17,597 question-answer pairs across 4,394 images, each annotated with
radiologist-verified bounding boxes and clinical reasoning explanations. Our
question taxonomy spans six diagnostic types-Where, What, Is there, How many,
Which, and Yes/No-capturing diverse clinical intents. To improve reliability,
we construct a balanced distribution of 41.7% positive and 58.3% negative
samples, mitigating hallucinations in normal cases. Benchmarking with
MedGemma-4B-it demonstrates improved performance (F1 = 0.624, +11.8% over
baseline) while enabling lesion localization. VinDr-CXR-VQA aims to advance
reproducible and clinically grounded Med-VQA research. The dataset and
evaluation tools are publicly available at
huggingface.co/datasets/Dangindev/VinDR-CXR-VQA.

</details>


### [64] [OmniTrack++: Omnidirectional Multi-Object Tracking by Learning Large-FoV Trajectory Feedback](https://arxiv.org/abs/2511.00510)
*Kai Luo,Hao Shi,Kunyu Peng,Fei Teng,Sheng Wu,Kaiwei Wang,Kailun Yang*

Main category: cs.CV

TL;DR: OmniTrack++ 通过反馈驱动框架和动态模块设计，显著提升全景多目标跟踪性能，并在新基准数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统MOT方法在全景图像中表现不佳，需解决全景畸变、大搜索空间和身份模糊等挑战。

Method: OmniTrack++ 采用反馈驱动框架，包括DynamicSSM块稳定特征、FlexiTrack Instances用于灵活定位、ExpertTrack Memory整合外观线索，以及Tracklet Management模块动态切换跟踪模式。

Result: OmniTrack++ 在JRDB和EmboTrack数据集上分别实现了HOTA提升25.5%和43.07%，显著优于原版OmniTrack。

Conclusion: OmniTrack++ 在全景多目标跟踪（MOT）中通过反馈驱动框架显著提升了性能，尤其是在处理全景畸变和大搜索空间方面表现出色，并在JRDB和EmboTrack数据集上实现了最先进的性能。

Abstract: This paper investigates Multi-Object Tracking (MOT) in panoramic imagery,
which introduces unique challenges including a 360{\deg} Field of View (FoV),
resolution dilution, and severe view-dependent distortions. Conventional MOT
methods designed for narrow-FoV pinhole cameras generalize unsatisfactorily
under these conditions. To address panoramic distortion, large search space,
and identity ambiguity under a 360{\deg} FoV, OmniTrack++ adopts a
feedback-driven framework that progressively refines perception with trajectory
cues. A DynamicSSM block first stabilizes panoramic features, implicitly
alleviating geometric distortion. On top of normalized representations,
FlexiTrack Instances use trajectory-informed feedback for flexible localization
and reliable short-term association. To ensure long-term robustness, an
ExpertTrack Memory consolidates appearance cues via a Mixture-of-Experts
design, enabling recovery from fragmented tracks and reducing identity drift.
Finally, a Tracklet Management module adaptively switches between end-to-end
and tracking-by-detection modes according to scene dynamics, offering a
balanced and scalable solution for panoramic MOT. To support rigorous
evaluation, we establish the EmboTrack benchmark, a comprehensive dataset for
panoramic MOT that includes QuadTrack, captured with a quadruped robot, and
BipTrack, collected with a bipedal wheel-legged robot. Together, these datasets
span wide-angle environments and diverse motion patterns, providing a
challenging testbed for real-world panoramic perception. Extensive experiments
on JRDB and EmboTrack demonstrate that OmniTrack++ achieves state-of-the-art
performance, yielding substantial HOTA improvements of +25.5% on JRDB and
+43.07% on QuadTrack over the original OmniTrack. Datasets and code will be
made publicly available at https://github.com/xifen523/OmniTrack.

</details>


### [65] [ID-Composer: Multi-Subject Video Synthesis with Hierarchical Identity Preservation](https://arxiv.org/abs/2511.00511)
*Panwang Pan,Jingjing Zhao,Yuchen Lin,Chenguo Lin,Chenxin Li,Haopeng Li,Honglei Yan,Tingting Shen,Yadong Mu*

Main category: cs.CV

TL;DR: ID-Composer 是一个多主体视频生成框架，通过分层注意力机制和预训练VLM提升生成质量，实验结果显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型通常仅基于文本或单张图像生成视频，限制了可控性和适用性。ID-Composer 旨在填补这一空白，实现基于文本提示和参考图像的多主体视频生成。

Method: ID-Composer 设计了分层身份保持注意力机制，结合预训练的视觉语言模型（VLM）进行语义理解，并采用在线强化学习阶段（RLVR）优化训练目标。

Result: 实验表明，ID-Composer 在身份保持、时间一致性和视频质量方面优于现有方法。

Conclusion: ID-Composer 通过分层身份保持注意力机制和预训练的视觉语言模型，显著提升了多主体视频生成的质量，尤其在身份保持、时间一致性和视频质量方面优于现有方法。

Abstract: Video generative models pretrained on large-scale datasets can produce
high-quality videos, but are often conditioned on text or a single image,
limiting controllability and applicability. We introduce ID-Composer, a novel
framework that addresses this gap by tackling multi-subject video generation
from a text prompt and reference images. This task is challenging as it
requires preserving subject identities, integrating semantics across subjects
and modalities, and maintaining temporal consistency. To faithfully preserve
the subject consistency and textual information in synthesized videos,
ID-Composer designs a \textbf{hierarchical identity-preserving attention
mechanism}, which effectively aggregates features within and across subjects
and modalities. To effectively allow for the semantic following of user
intention, we introduce \textbf{semantic understanding via pretrained
vision-language model (VLM)}, leveraging VLM's superior semantic understanding
to provide fine-grained guidance and capture complex interactions between
multiple subjects. Considering that standard diffusion loss often fails in
aligning the critical concepts like subject ID, we employ an \textbf{online
reinforcement learning phase} to drive the overall training objective of
ID-Composer into RLVR. Extensive experiments demonstrate that our model
surpasses existing methods in identity preservation, temporal consistency, and
video quality.

</details>


### [66] [SegDebias: Test-Time Bias Mitigation for ViT-Based CLIP via Segmentation](https://arxiv.org/abs/2511.00523)
*Fangyu Wu,Yujun Cai*

Main category: cs.CV

TL;DR: Proposes a test-time debiasing method for CLIP models using segmentation to isolate and adjust non-target regions, achieving better performance without training or bias annotations.


<details>
  <summary>Details</summary>
Motivation: Existing debiasing methods often require training data and explicit group labels, limiting practicality. Test-time methods may depend on prior knowledge of biases, lacking generalizability.

Method: Uses a pretrained segmentation model to isolate target visual attributes and adjusts non-target regions to have embeddings uniformly similar to all class-specific text prompts.

Result: Outperforms existing test-time debiasing approaches on Waterbirds and CelebA datasets in both group robustness metrics and Attention IoU.

Conclusion: The proposed segmentation-guided test-time debiasing method effectively mitigates spurious correlations in CLIP models without requiring additional training or bias annotations, demonstrating superior performance in group robustness metrics and Attention IoU.

Abstract: Vision language models such as CLIP have shown remarkable performance in zero
shot classification, but remain susceptible to spurious correlations, where
irrelevant visual features influence predictions. Existing debiasing methods
often require access to training data and explicit group labels to perform
fine-tuning or adjust embeddings, which limits their practicality in real-world
settings. Test-time methods attempt to avoid this constraint, but many still
depend on prior knowledge of dataset specific biases, limiting their
generalizability in open set settings. In this work, we propose a test-time
debiasing method for ViT based CLIP models that requires no additional training
or assumptions of bias annotations. Our approach uses a pretrained segmentation
model to isolate the target visual attribute, then adjusts the non target
regions so that their embeddings are uniformly similar to all class specific
text prompts. This procedure removes unintended bias signals from confounding
visual regions while preserving the target attribute. Experiments on Waterbirds
and CelebA show that our method outperforms existing test-time debiasing
approaches in both group robustness metrics and Attention IoU. These results
demonstrate the effectiveness of segmentation guided interventions for scalable
and annotation free bias mitigation in vision language models.

</details>


### [67] [Text-guided Fine-Grained Video Anomaly Detection](https://arxiv.org/abs/2511.00524)
*Jihao Gu,Kun Li,He Wang,Kaan Akşit*

Main category: cs.CV

TL;DR: T-VAD利用LVLM和新型解码器/编码器设计，显著提升视频异常检测的细粒度和交互性，并在多个指标上实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频异常检测方法多为半自动化且输出有限（仅标记正常或异常），无法满足细粒度和交互性需求。T-VAD旨在通过LVLM和创新的解码器/编码器设计解决这一问题。

Method: 提出Text-guided Fine-Grained Video Anomaly Detection（T-VAD）框架，利用AHD进行像素级的视觉-文本特征对齐生成细粒度异常热图，并通过RAE将热图转换为可学习的文本嵌入，引导LVLM准确识别和定位视频中的异常事件。

Result: 在UBnormal数据集上达到94.8%的micro-AUC，异常热图准确率67.8%/76.7%（RBDC/TBDC）；在ShanghaiTech和UBnormal数据集上，文本描述质量显著提升（BLEU-4和Yes/No准确率表现优异）。

Conclusion: T-VAD框架通过结合大型视觉语言模型（LVLM）和创新的Anomaly Heatmap Decoder（AHD）与Region-aware Anomaly Encoder（RAE），显著提升了视频异常检测的细粒度和交互性，并在多个数据集上实现了最先进的性能。

Abstract: Video Anomaly Detection (VAD) aims to identify anomalous events within video
segments. In scenarios such as surveillance or industrial process monitoring,
anomaly detection is of critical importance. While existing approaches are
semi-automated, requiring human assessment for anomaly detection, traditional
VADs offer limited output as either normal or anomalous. We propose Text-guided
Fine-Grained Video Anomaly Detection (T-VAD), a framework built upon Large
Vision-Language Model (LVLM). T-VAD introduces an Anomaly Heatmap Decoder (AHD)
that performs pixel-wise visual-textual feature alignment to generate
fine-grained anomaly heatmaps. Furthermore, we design a Region-aware Anomaly
Encoder (RAE) that transforms the heatmaps into learnable textual embeddings,
guiding the LVLM to accurately identify and localize anomalous events in
videos. This significantly enhances both the granularity and interactivity of
anomaly detection. The proposed method achieving SOTA performance by
demonstrating 94.8% Area Under the Curve (AUC, specifically micro-AUC) and
67.8%/76.7% accuracy in anomaly heatmaps (RBDC/TBDC) on the UBnormal dataset,
and subjectively verified more preferable textual description on the
ShanghaiTech-based dataset (BLEU-4: 62.67 for targets, 88.84 for trajectories;
Yes/No accuracy: 97.67%), and on the UBnormal dataset (BLEU-4: 50.32 for
targets, 78.10 for trajectories; Yes/No accuracy: 89.73%).

</details>


### [68] [Real-IAD Variety: Pushing Industrial Anomaly Detection Dataset to a Modern Era](https://arxiv.org/abs/2511.00540)
*Wenbing Zhu,Chengjie Wang,Bin-Bin Gao,Jiangning Zhang,Guannan Jiang,Jie Hu,Zhenye Gan,Lidong Wang,Ziqing Zhou,Linjie Cheng,Yurui Pan,Bo Peng,Mingmin Chi,Lizhuang Ma*

Main category: cs.CV

TL;DR: 该论文提出最大、最多样化的工业异常检测基准 Real-IAD Variety，验证其挑战性，并展示视觉语言模型在多样化工业场景中的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测（IAD）数据集类别多样性和规模不足，导致指标饱和和模型在真实场景中的迁移性受限。

Method: 引入 Real-IAD Variety 基准，包含 198,960 张高分辨率图像，覆盖 160 个对象类别、28 个行业、24 种材料和 22 种颜色变化。通过多类别无监督、多视图和零/少样本设置的严格评估协议进行验证。

Result: 实验表明，最先进的多类别无监督异常检测方法在类别从 30 扩展到 160 时性能显著下降，而视觉语言模型展现出对类别扩展的强鲁棒性，性能变化极小。

Conclusion: Real-IAD Variety 被定位为训练和评估下一代异常检测基础模型的重要资源，其前所未有的规模和复杂性将加速跨领域研究，推动可扩展、通用异常检测系统的发展。

Abstract: Industrial Anomaly Detection (IAD) is critical for enhancing operational
safety, ensuring product quality, and optimizing manufacturing efficiency
across global industries. However, the IAD algorithms are severely constrained
by the limitations of existing public benchmarks. Current datasets exhibit
restricted category diversity and insufficient scale, frequently resulting in
metric saturation and limited model transferability to real-world scenarios. To
address this gap, we introduce Real-IAD Variety, the largest and most diverse
IAD benchmark, comprising 198,960 high-resolution images across 160 distinct
object categories. Its diversity is ensured through comprehensive coverage of
28 industries, 24 material types, and 22 color variations. Our comprehensive
experimental analysis validates the benchmark's substantial challenge:
state-of-the-art multi-class unsupervised anomaly detection methods experience
significant performance degradation when scaled from 30 to 160 categories.
Crucially, we demonstrate that vision-language models exhibit remarkable
robustness to category scale-up, with minimal performance variation across
different category counts, significantly enhancing generalization capabilities
in diverse industrial contexts. The unprecedented scale and complexity of
Real-IAD Variety position it as an essential resource for training and
evaluating next-generation foundation models for anomaly detection. By
providing this comprehensive benchmark with rigorous evaluation protocols
across multi-class unsupervised, multi-view, and zero-/few-shot settings, we
aim to accelerate research beyond domain-specific constraints, enabling the
development of scalable, general-purpose anomaly detection systems. Real-IAD
Variety will be made publicly available to facilitate innovation in this
critical field.

</details>


### [69] [MIFO: Learning and Synthesizing Multi-Instance from One Image](https://arxiv.org/abs/2511.00542)
*Kailun Su,Ziqi He,Xi Wang,Yang Zhou*

Main category: cs.CV

TL;DR: 本文提出一种通过惩罚注意力优化和框控制来解耦相似语义并精确控制输出布局的方法，实现了高质量学习与合成。


<details>
  <summary>Details</summary>
Motivation: 解决训练数据有限及实例语义或外观相似时的学习与合成难题。

Method: 提出基于惩罚的注意力优化以解耦相似语义，并在合成阶段引入并优化注意力层的框控制以进一步减少语义泄漏。

Result: 实验结果表明，该方法能够解耦并高质量地学习与合成语义，在处理语义或视觉相似的实例或罕见对象时仍保持鲁棒性。

Conclusion: 该方法在解耦相似语义的同时实现了高质量的学习与合成，平衡了可编辑性与实例一致性。

Abstract: This paper proposes a method for precise learning and synthesizing
multi-instance semantics from a single image. The difficulty of this problem
lies in the limited training data, and it becomes even more challenging when
the instances to be learned have similar semantics or appearance. To address
this, we propose a penalty-based attention optimization to disentangle similar
semantics during the learning stage. Then, in the synthesis, we introduce and
optimize box control in attention layers to further mitigate semantic leakage
while precisely controlling the output layout. Experimental results demonstrate
that our method achieves disentangled and high-quality semantic learning and
synthesis, strikingly balancing editability and instance consistency. Our
method remains robust when dealing with semantically or visually similar
instances or rare-seen objects. The code is publicly available at
https://github.com/Kareneveve/MIFO

</details>


### [70] [4D Neural Voxel Splatting: Dynamic Scene Rendering with Voxelized Guassian Splatting](https://arxiv.org/abs/2511.00560)
*Chun-Tin Wu,Jun-Cheng Chen*

Main category: cs.CV

TL;DR: 4D-NVS结合体素和神经高斯泼溅技术，高效建模动态场景，减少内存和加速训练，保持高渲染质量。


<details>
  <summary>Details</summary>
Motivation: 尽管3D高斯泼溅技术在静态场景中实现了高效渲染，但在动态场景中复制高斯集合会导致显著的内存开销，因此需要一种更高效的方法。

Method: 采用紧凑的神经体素集合和学习的形变场来建模时间动态，避免了每帧复制高斯集合的开销，并引入了新颖的视点细化阶段来优化挑战性视角。

Result: 实验结果表明，4D-NVS在内存消耗和训练速度上优于现有方法，实现了实时渲染和更高的视觉保真度。

Conclusion: 4D-NVS通过结合体素表示和神经高斯泼溅技术，显著减少了动态场景建模的内存消耗和训练时间，同时保持了高质量的渲染效果。

Abstract: Although 3D Gaussian Splatting (3D-GS) achieves efficient rendering for novel
view synthesis, extending it to dynamic scenes still results in substantial
memory overhead from replicating Gaussians across frames. To address this
challenge, we propose 4D Neural Voxel Splatting (4D-NVS), which combines
voxel-based representations with neural Gaussian splatting for efficient
dynamic scene modeling. Instead of generating separate Gaussian sets per
timestamp, our method employs a compact set of neural voxels with learned
deformation fields to model temporal dynamics. The design greatly reduces
memory consumption and accelerates training while preserving high image
quality. We further introduce a novel view refinement stage that selectively
improves challenging viewpoints through targeted optimization, maintaining
global efficiency while enhancing rendering quality for difficult viewing
angles. Experiments demonstrate that our method outperforms state-of-the-art
approaches with significant memory reduction and faster training, enabling
real-time rendering with superior visual fidelity.

</details>


### [71] [Generalized Category Discovery under Domain Shift: A Frequency Domain Perspective](https://arxiv.org/abs/2511.00573)
*Wei Feng,Zongyuan Ge*

Main category: cs.CV

TL;DR: 论文提出了一种频率引导的广义类别发现框架（FREE），用于解决分布偏移下的类别发现问题，通过频域信息和新的扰动策略提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在标准条件下表现良好，但在分布偏移时性能下降，因此探索了域偏移广义类别发现（DS_GCD）这一更现实的任务。

Method: 提出频率域分离策略、跨域和域内扰动策略，扩展自监督对比目标和语义聚类损失，并引入聚类难度感知的重采样技术。

Result: 实验表明，FREE能有效缓解分布偏移影响，在多个基准数据集上表现优越。

Conclusion: FREE框架通过频域信息和创新策略，显著提升了在分布偏移下的类别发现性能。

Abstract: Generalized Category Discovery (GCD) aims to leverage labeled samples from
known categories to cluster unlabeled data that may include both known and
unknown categories. While existing methods have achieved impressive results
under standard conditions, their performance often deteriorates in the presence
of distribution shifts. In this paper, we explore a more realistic task:
Domain-Shifted Generalized Category Discovery (DS\_GCD), where the unlabeled
data includes not only unknown categories but also samples from unknown
domains. To tackle this challenge, we propose a
\textbf{\underline{F}}requency-guided Gene\textbf{\underline{r}}alized
Cat\textbf{\underline{e}}gory Discov\textbf{\underline{e}}ry framework (FREE)
that enhances the model's ability to discover categories under distributional
shift by leveraging frequency-domain information. Specifically, we first
propose a frequency-based domain separation strategy that partitions samples
into known and unknown domains by measuring their amplitude differences. We
then propose two types of frequency-domain perturbation strategies: a
cross-domain strategy, which adapts to new distributions by exchanging
amplitude components across domains, and an intra-domain strategy, which
enhances robustness to intra-domain variations within the unknown domain.
Furthermore, we extend the self-supervised contrastive objective and semantic
clustering loss to better guide the training process. Finally, we introduce a
clustering-difficulty-aware resampling technique to adaptively focus on
harder-to-cluster categories, further enhancing model performance. Extensive
experiments demonstrate that our method effectively mitigates the impact of
distributional shifts across various benchmark datasets and achieves superior
performance in discovering both known and unknown categories.

</details>


### [72] [TRACES: Temporal Recall with Contextual Embeddings for Real-Time Video Anomaly Detection](https://arxiv.org/abs/2511.00580)
*Yousuf Ahmed Siddiqui,Sufiyaan Usmani,Umer Tariq,Jawwad Ahmed Shamsi,Muhammad Burhan Khan*

Main category: cs.CV

TL;DR: 提出一种上下文感知的零样本异常检测方法，通过记忆增强流水线和跨注意力融合时间与视觉特征，实现高精度实时检测，性能优于现有零样本模型。


<details>
  <summary>Details</summary>
Motivation: 视频异常通常依赖于上下文信息和时间演化。大多数异常检测器未能注意到此类上下文，严重限制了其在新现实场景中的泛化能力。

Method: 定义了一个记忆增强的流水线，通过跨注意力将时间信号与视觉嵌入相关联，并通过上下文相似性评分进行实时零样本异常分类。

Result: 在UCF-Crime上达到90.4%的AUC，在XD-Violence上达到83.67%的AP，创下零样本模型的新最佳成绩。

Conclusion: 通过融合跨注意力时间融合和上下文记忆，实现了高保真异常检测，为零样本模型在现实世界监控和基础设施监测中的应用迈出了重要一步。

Abstract: Video anomalies often depend on contextual information available and temporal
evolution. Non-anomalous action in one context can be anomalous in some other
context. Most anomaly detectors, however, do not notice this type of context,
which seriously limits their capability to generalize to new, real-life
situations. Our work addresses the context-aware zero-shot anomaly detection
challenge, in which systems need to learn adaptively to detect new events by
correlating temporal and appearance features with textual traces of memory in
real time. Our approach defines a memory-augmented pipeline, correlating
temporal signals with visual embeddings using cross-attention, and real-time
zero-shot anomaly classification by contextual similarity scoring. We achieve
90.4\% AUC on UCF-Crime and 83.67\% AP on XD-Violence, a new state-of-the-art
among zero-shot models. Our model achieves real-time inference with high
precision and explainability for deployment. We show that, by fusing
cross-attention temporal fusion and contextual memory, we achieve high fidelity
anomaly detection, a step towards the applicability of zero-shot models in
real-world surveillance and infrastructure monitoring.

</details>


### [73] [Saliency-Guided Domain Adaptation for Left-Hand Driving in Autonomous Steering](https://arxiv.org/abs/2511.01223)
*Zahra Mehraban,Sebastien Glaser,Michael Milford,Ronald Schroeter*

Main category: cs.CV

TL;DR: 研究翻转数据预训练和微调对PilotNet模型在左舵驾驶条件下的适应性影响，结果显示结合方法效果最佳。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过领域自适应方法提升自动驾驶模型在不同道路条件下的泛化能力。

Method: 评估了四种训练方法：基准模型、翻转数据训练模型、预训练后微调模型及翻转数据预训练后微调模型。

Result: 翻转数据预训练单独使用会降低预测稳定性，但结合微调后可显著降低预测误差并增强对左侧道路特征的关注。

Conclusion: 预处理技术（如翻转数据预训练）结合微调，可显著提升模型适应性，减少重新训练需求。

Abstract: Domain adaptation is required for automated driving models to generalize well
across diverse road conditions. This paper explores a training method for
domain adaptation to adapt PilotNet, an end-to-end deep learning-based model,
for left-hand driving conditions using real-world Australian highway data. Four
training methods were evaluated: (1) a baseline model trained on U.S.
right-hand driving data, (2) a model trained on flipped U.S. data, (3) a model
pretrained on U.S. data and then fine-tuned on Australian highways, and (4) a
model pretrained on flipped U.S. data and then finetuned on Australian
highways. This setup examines whether incorporating flipped data enhances the
model adaptation by providing an initial left-hand driving alignment. The paper
compares model performance regarding steering prediction accuracy and
attention, using saliency-based analysis to measure attention shifts across
significant road regions. Results show that pretraining on flipped data alone
worsens prediction stability due to misaligned feature representations, but
significantly improves adaptation when followed by fine-tuning, leading to
lower prediction error and stronger focus on left-side cues. To validate this
approach across different architectures, the same experiments were done on
ResNet, which confirmed similar adaptation trends. These findings emphasize the
importance of preprocessing techniques, such as flipped-data pretraining,
followed by fine-tuning to improve model adaptation with minimal retraining
requirements.

</details>


### [74] [CueBench: Advancing Unified Understanding of Context-Aware Video Anomalies in Real-World](https://arxiv.org/abs/2511.00613)
*Yating Yu,Congqi Cao,Zhaoying Wang,Weihua Meng,Jie Li,Yuxin Li,Zihao Wei,Zhongpei Shen,Jiajun Zhang*

Main category: cs.CV

TL;DR: 提出了首个专注于上下文感知视频异常的基准CueBench，并开发了Cue-R1方法，显著提升了模型对真实世界异常的理解能力。


<details>
  <summary>Details</summary>
Motivation: 当前工作对真实世界异常的理解仅停留在表面，缺乏对复杂原理和微妙背景的广泛覆盖，如带安全装备与不带安全装备攀爬悬崖的区别。

Method: 基于R1式强化微调，开发了Cue-R1，采用可验证、任务对齐和层次细化的奖励，以统一生成方式解决CueBench的挑战。

Result: Cue-R1在CueBench上的表现显著优于现有最先进方法，平均提升超过24%。

Conclusion: 现有视觉语言模型（VLMs）在真实世界视频异常理解（VAU）方面仍远未达标，而提出的Cue-R1方法平均超越现有最先进方法24%以上。

Abstract: How far are deep models from real-world video anomaly understanding (VAU)?
Current works typically emphasize on detecting unexpected occurrences deviated
from normal patterns or comprehending anomalous events with interpretable
descriptions. However, they exhibit only a superficial comprehension of
real-world anomalies, with limited breadth in complex principles and subtle
context that distinguish the anomalies from normalities, e.g., climbing cliffs
with safety gear vs. without it. To this end, we introduce CueBench, the first
of its kind Benchmark, devoted to Context-aware video anomalies within a
Unified Evaluation framework. We comprehensively establish an event-centric
hierarchical taxonomy that anchors two core event types: 14 conditional and 18
absolute anomaly events, defined by their refined semantics from diverse
contexts across 174 scenes and 198 attributes. Based on this, we propose to
unify and benchmark context-aware VAU with various challenging tasks across
recognition, temporal grounding, detection, and anticipation. This also serves
as a rigorous and fair probing evaluation suite for generative-discriminative
as well as generalized-specialized vision-language models (VLMs). To address
the challenges underlying CueBench, we further develop Cue-R1 based on R1-style
reinforcement fine-tuning with verifiable, task-aligned, and hierarchy-refined
rewards in a unified generative manner. Extensive results on CueBench reveal
that, existing VLMs are still far from satisfactory real-world anomaly
understanding, while our Cue-R1 surpasses these state-of-the-art approaches by
over 24% on average.

</details>


### [75] [EREBUS: End-to-end Robust Event Based Underwater Simulation](https://arxiv.org/abs/2511.01381)
*Hitesh Kyatham,Arjun Suresh,Aadi Palnitkar,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 提出了一种生成事件相机合成数据的方法，用于水下AUV视觉模型训练，并在岩石检测中验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 水下环境中的恶劣光照条件和高动态范围场景使传统视觉技术难以适应，事件相机提供了一种解决方案。

Method: 引入了一个管道，用于生成事件相机在水下环境中的合成数据，适用于AUV的视觉模型训练。

Result: 通过岩石检测任务证明了管道的有效性，尤其在低能见度和悬浮颗粒物条件下。

Conclusion: 该论文提出了一种生成事件相机合成数据的管道，用于水下环境中自主水下车辆（AUV）的视觉模型训练，并展示了其在岩石检测任务中的有效性。

Abstract: The underwater domain presents a vast array of challenges for roboticists and
computer vision researchers alike, such as poor lighting conditions and high
dynamic range scenes. In these adverse conditions, traditional vision
techniques struggle to adapt and lead to suboptimal performance. Event-based
cameras present an attractive solution to this problem, mitigating the issues
of traditional cameras by tracking changes in the footage on a frame-by-frame
basis. In this paper, we introduce a pipeline which can be used to generate
realistic synthetic data of an event-based camera mounted to an AUV (Autonomous
Underwater Vehicle) in an underwater environment for training vision models. We
demonstrate the effectiveness of our pipeline using the task of rock detection
with poor visibility and suspended particulate matter, but the approach can be
generalized to other underwater tasks.

</details>


### [76] [Grounding Surgical Action Triplets with Instrument Instance Segmentation: A Dataset and Target-Aware Fusion Approach](https://arxiv.org/abs/2511.00643)
*Oluwatosin Alabi,Meng Wei,Charlie Budd,Tom Vercauteren,Miaojing Shi*

Main category: cs.CV

TL;DR: 提出了一种新的任务——三元组分割，用于空间定位手术动作三元组，并提出了TargetFusionNet架构和CholecTriplet-Seg数据集，显著提升了手术动作理解的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Existing surgical action triplet recognition methods are limited to learning from frame-level classification, failing to reliably link actions to specific instrument instances. Previous attempts at spatial grounding have primarily relied on class activation maps, which lack the precision and robustness required for detailed instrument-tissue interaction analysis.

Method: TargetFusionNet, a novel architecture that extends Mask2Former with a target-aware fusion mechanism to address the challenge of accurate anatomical target prediction by fusing weak anatomy priors with instrument instance queries.

Result: TargetFusionNet consistently improves performance over existing baselines, demonstrating that strong instance supervision combined with weak target priors significantly enhances the accuracy and robustness of surgical action understanding.

Conclusion: Triplet segmentation establishes a unified framework for spatially grounding surgical action triplets. The proposed benchmark and architecture pave the way for more interpretable, surgical scene understanding.

Abstract: Understanding surgical instrument-tissue interactions requires not only
identifying which instrument performs which action on which anatomical target,
but also grounding these interactions spatially within the surgical scene.
Existing surgical action triplet recognition methods are limited to learning
from frame-level classification, failing to reliably link actions to specific
instrument instances.Previous attempts at spatial grounding have primarily
relied on class activation maps, which lack the precision and robustness
required for detailed instrument-tissue interaction analysis.To address this
gap, we propose grounding surgical action triplets with instrument instance
segmentation, or triplet segmentation for short, a new unified task which
produces spatially grounded <instrument, verb, target> outputs.We start by
presenting CholecTriplet-Seg, a large-scale dataset containing over 30,000
annotated frames, linking instrument instance masks with action verb and
anatomical target annotations, and establishing the first benchmark for
strongly supervised, instance-level triplet grounding and evaluation.To learn
triplet segmentation, we propose TargetFusionNet, a novel architecture that
extends Mask2Former with a target-aware fusion mechanism to address the
challenge of accurate anatomical target prediction by fusing weak anatomy
priors with instrument instance queries.Evaluated across recognition,
detection, and triplet segmentation metrics, TargetFusionNet consistently
improves performance over existing baselines, demonstrating that strong
instance supervision combined with weak target priors significantly enhances
the accuracy and robustness of surgical action understanding.Triplet
segmentation establishes a unified framework for spatially grounding surgical
action triplets. The proposed benchmark and architecture pave the way for more
interpretable, surgical scene understanding.

</details>


### [77] [SE(3)-PoseFlow: Estimating 6D Pose Distributions for Uncertainty-Aware Robotic Manipulation](https://arxiv.org/abs/2511.01501)
*Yufeng Jin,Niklas Funk,Vignesh Prasad,Zechu Li,Mathias Franzius,Jan Peters,Georgia Chalvatzaki*

Main category: cs.CV

TL;DR: 提出一种基于SE(3)流匹配的概率框架，用于估计6D物体位姿分布，解决了对称物体和遮挡导致的位姿模糊问题，并在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 物体位姿估计在部分观测、遮挡和对称性下存在位姿模糊问题，确定性深度网络无法捕捉位姿分布的多模态性。

Method: 采用SE(3)流匹配的概率框架，通过样本估计建模完整的位姿分布，并支持在模糊情况下进行不确定性推理。

Result: 在Real275、YCB-V和LM-O数据集上实现SOTA性能，并展示了在机器人操作任务（如主动感知和抓取合成）中的应用。

Conclusion: 该概率框架有效解决了位姿模糊问题，提升了位姿估计的鲁棒性和下游任务性能。

Abstract: Object pose estimation is a fundamental problem in robotics and computer
vision, yet it remains challenging due to partial observability, occlusions,
and object symmetries, which inevitably lead to pose ambiguity and multiple
hypotheses consistent with the same observation. While deterministic deep
networks achieve impressive performance under well-constrained conditions, they
are often overconfident and fail to capture the multi-modality of the
underlying pose distribution. To address these challenges, we propose a novel
probabilistic framework that leverages flow matching on the SE(3) manifold for
estimating 6D object pose distributions. Unlike existing methods that regress a
single deterministic output, our approach models the full pose distribution
with a sample-based estimate and enables reasoning about uncertainty in
ambiguous cases such as symmetric objects or severe occlusions. We achieve
state-of-the-art results on Real275, YCB-V, and LM-O, and demonstrate how our
sample-based pose estimates can be leveraged in downstream robotic manipulation
tasks such as active perception for disambiguating uncertain viewpoints or
guiding grasp synthesis in an uncertainty-aware manner.

</details>


### [78] [Benchmarking individual tree segmentation using multispectral airborne laser scanning data: the FGI-EMIT dataset](https://arxiv.org/abs/2511.00653)
*Lassi Ruoppa,Tarmo Hietala,Verneri Seppänen,Josef Taher,Teemu Hakala,Xiaowei Yu,Antero Kukko,Harri Kaartinen,Juha Hyyppä*

Main category: cs.CV

TL;DR: FGI-EMIT是首个大规模多光谱LiDAR ITS数据集，实验显示DL方法优于无监督算法，但未充分利用MS信息。


<details>
  <summary>Details</summary>
Motivation: 缺乏大规模多光谱LiDAR基准数据集限制了ITS方法的进步，尽管MS反射率已被证明能提升分割精度。

Method: 研究对比了四种传统无监督算法和四种监督DL方法，其中无监督方法通过贝叶斯优化超参数，DL模型则从头训练。

Result: 最佳DL模型ForestFormer3D的F1分数达73.3%，显著优于无监督方法（Treeiso的52.7%），尤其在林下树识别上差距达25.9个百分点。MS反射率未被DL模型有效利用。

Conclusion: 深度学习（DL）方法在个体树木分割（ITS）任务中显著优于传统无监督算法，尤其是在林下小树的识别上表现突出。然而，当前DL方法未能充分利用多光谱（MS）反射率信息。

Abstract: Individual tree segmentation (ITS) from LiDAR point clouds is fundamental for
applications such as forest inventory, carbon monitoring and biodiversity
assessment. Traditionally, ITS has been achieved with unsupervised
geometry-based algorithms, while more recent advances have shifted toward
supervised deep learning (DL). In the past, progress in method development was
hindered by the lack of large-scale benchmark datasets, and the availability of
novel data formats, particularly multispectral (MS) LiDAR, remains limited to
this day, despite evidence that MS reflectance can improve the accuracy of ITS.
This study introduces FGI-EMIT, the first large-scale MS airborne laser
scanning benchmark dataset for ITS. Captured at wavelengths 532, 905, and 1,550
nm, the dataset consists of 1,561 manually annotated trees, with a particular
focus on small understory trees. Using FGI-EMIT, we comprehensively benchmarked
four conventional unsupervised algorithms and four supervised DL approaches.
Hyperparameters of unsupervised methods were optimized using a Bayesian
approach, while DL models were trained from scratch. Among the unsupervised
methods, Treeiso achieved the highest test set F1-score of 52.7%. The DL
approaches performed significantly better overall, with the best model,
ForestFormer3D, attaining an F1-score of 73.3%. The most significant difference
was observed in understory trees, where ForestFormer3D exceeded Treeiso by 25.9
percentage points. An ablation study demonstrated that current DL-based
approaches generally fail to leverage MS reflectance information when it is
provided as additional input features, although single channel reflectance can
improve accuracy marginally, especially for understory trees. A performance
analysis across point densities further showed that DL methods consistently
remain superior to unsupervised algorithms, even at densities as low as 10
points/m$^2$.

</details>


### [79] [Discriminately Treating Motion Components Evolves Joint Depth and Ego-Motion Learning](https://arxiv.org/abs/2511.01502)
*Mengtan Zhang,Zizhan Guo,Hongbo Zhao,Yi Feng,Zuyi Xiong,Yue Wang,Shaoyi Du,Hanli Wang,Rui Fan*

Main category: cs.CV

TL;DR: DiMoDE框架通过区分处理运动分量并利用几何规律，提升了深度和自运动估计的鲁棒性和性能，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大多数现有方法将自运动视为辅助任务，混合所有运动类型或排除深度无关的旋转运动，限制了强几何约束的整合，影响了可靠性和鲁棒性。

Method: 该研究提出了一种区分处理运动分量的方法，通过网络输出先对齐源和目标相机的光轴和成像平面，然后通过这些对齐转换光流，并量化偏差以单独对每个自运动分量施加几何约束。

Result: DiMoDE在多个公共数据集和新收集的多样化真实世界数据集上实现了最先进的性能，特别是在挑战性条件下表现优异。

Conclusion: DiMoDE框架通过区分处理运动分量并利用其刚性流的几何规律，显著提升了深度和自运动估计的性能，在多个数据集上实现了最先进的性能。

Abstract: Unsupervised learning of depth and ego-motion, two fundamental 3D perception
tasks, has made significant strides in recent years. However, most methods
treat ego-motion as an auxiliary task, either mixing all motion types or
excluding depth-independent rotational motions in supervision. Such designs
limit the incorporation of strong geometric constraints, reducing reliability
and robustness under diverse conditions. This study introduces a discriminative
treatment of motion components, leveraging the geometric regularities of their
respective rigid flows to benefit both depth and ego-motion estimation. Given
consecutive video frames, network outputs first align the optical axes and
imaging planes of the source and target cameras. Optical flows between frames
are transformed through these alignments, and deviations are quantified to
impose geometric constraints individually on each ego-motion component,
enabling more targeted refinement. These alignments further reformulate the
joint learning process into coaxial and coplanar forms, where depth and each
translation component can be mutually derived through closed-form geometric
relationships, introducing complementary constraints that improve depth
robustness. DiMoDE, a general depth and ego-motion joint learning framework
incorporating these designs, achieves state-of-the-art performance on multiple
public datasets and a newly collected diverse real-world dataset, particularly
under challenging conditions. Our source code will be publicly available at
mias.group/DiMoDE upon publication.

</details>


### [80] [Metadata-Aligned 3D MRI Representations for Contrast Understanding and Quality Control](https://arxiv.org/abs/2511.00681)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: MR-CLIP框架利用元数据学习MRI对比表示，支持序列分类和数据质量控制，无需依赖人工标注。


<details>
  <summary>Details</summary>
Motivation: MRI存在数据异质性和缺乏标准化对比标签的问题，限制了大规模自动化分析。统一的MRI对比表示可以支持多种下游应用。

Method: MR-CLIP是一个元数据引导的框架，通过学习MRI对比表示，将体积图像与其DICOM获取参数对齐。

Result: MR-CLIP生成的嵌入显示了MRI序列的明显聚类，在数据稀缺情况下优于监督3D基线模型，并能通过图像-元数据嵌入距离实现无监督数据质量控制。

Conclusion: MR-CLIP通过将常规获取的元数据转化为监督信号，为跨多样临床数据集的标签高效MRI分析提供了可扩展的基础。

Abstract: Magnetic Resonance Imaging suffers from substantial data heterogeneity and
the absence of standardized contrast labels across scanners, protocols, and
institutions, which severely limits large-scale automated analysis. A unified
representation of MRI contrast would enable a wide range of downstream
utilities, from automatic sequence recognition to harmonization and quality
control, without relying on manual annotations. To this end, we introduce
MR-CLIP, a metadata-guided framework that learns MRI contrast representations
by aligning volumetric images with their DICOM acquisition parameters. The
resulting embeddings shows distinct clusters of MRI sequences and outperform
supervised 3D baselines under data scarcity in few-shot sequence
classification. Moreover, MR-CLIP enables unsupervised data quality control by
identifying corrupted or inconsistent metadata through image-metadata embedding
distances. By transforming routinely available acquisition metadata into a
supervisory signal, MR-CLIP provides a scalable foundation for label-efficient
MRI analysis across diverse clinical datasets.

</details>


### [81] [PixelVLA: Advancing Pixel-level Understanding in Vision-Language-Action Model](https://arxiv.org/abs/2511.01571)
*Wenqi Liang,Gan Sun,Yao He,Jiahua Dong,Suyan Dai,Ivan Laptev,Salman Khan,Yang Cong*

Main category: cs.CV

TL;DR: PixelVLA是一种新型VLA模型，支持像素级推理和多模态提示，显著提升机器人控制性能并降低成本，数据集和代码将开源。


<details>
  <summary>Details</summary>
Motivation: 解决现有Vision-Language-Action模型在像素级场景理解和依赖文本提示方面的局限性。

Method: 提出了PixelVLA模型，基于新的视觉运动指令调优框架，整合了多尺度像素感知编码器和视觉提示编码器，并通过两阶段自动标注流程生成Pixel-160K数据集。

Result: 在三个标准VLA基准测试和两种VLA模型变体上，PixelVLA将操作成功率提高了10.1%-17.8%，且仅需OpenVLA预训练成本的1.5%。

Conclusion: PixelVLA通过像素级推理和多模态提示（文本与视觉输入）的结合，显著提升了机器人控制的准确性和效率，同时大幅降低了预训练成本。数据集和代码将开源。

Abstract: Vision-Language-Action models (VLAs) are emerging as powerful tools for
learning generalizable visuomotor control policies. However, current VLAs are
mostly trained on large-scale image-text-action data and remain limited in two
key ways: (i) they struggle with pixel-level scene understanding, and (ii) they
rely heavily on textual prompts, which reduces their flexibility in real-world
settings. To address these challenges, we introduce PixelVLA, the first VLA
model designed to support both pixel-level reasoning and multimodal prompting
with text and visual inputs. Our approach is built on a new visuomotor
instruction tuning framework that integrates a multiscale pixel-aware encoder
with a visual prompting encoder. To train PixelVLA effectively, we further
propose a two-stage automated annotation pipeline that generates Pixel-160K, a
large-scale dataset with pixel-level annotations derived from existing robot
data. Experiments on three standard VLA benchmarks and two VLA model variants
show that PixelVLA improves manipulation success rates by 10.1%-17.8% over
OpenVLA, while requiring only 1.5% of its pretraining cost. These results
demonstrate that PixelVLA can be integrated into existing VLAs to enable more
accurate, efficient, and versatile robot control in complex environments. The
dataset and code will be released as open source.

</details>


### [82] [Outlier-Aware Post-Training Quantization for Image Super-Resolution](https://arxiv.org/abs/2511.00682)
*Hailing Wang,jianglin Lu,Yitian Zhang,Yun Fu*

Main category: cs.CV

TL;DR: 论文提出双区域量化和敏感度感知微调，显著提升SR网络中PTQ性能，接近QAT效果且加速75倍。


<details>
  <summary>Details</summary>
Motivation: 现有PTQ方法在SR中性能不佳，主要因为忽略了激活中的异常值影响。研究发现这些异常值与图像颜色信息强相关，直接移除会导致性能显著下降。

Method: 论文提出了双区域量化策略，将激活分为异常值区域和密集区域，并分别应用均匀量化以优化比特分配。此外，引入了敏感度感知微调，使模型更关注高敏感层。

Result: 实验表明，该方法在各种SR网络和数据集上优于现有PTQ方法，并在大多数场景下达到与QAT方法相当的性能。

Conclusion: 该论文提出的双区域量化策略和敏感度感知微调方法显著提升了后训练量化（PTQ）在图像超分辨率（SR）网络中的性能，使其在大多数场景下接近量化感知训练（QAT）方法的性能，同时实现了至少75倍的加速。

Abstract: Quantization techniques, including quantization-aware training (QAT) and
post-training quantization (PTQ), have become essential for inference
acceleration of image super-resolution (SR) networks. Compared to QAT, PTQ has
garnered significant attention as it eliminates the need for ground truth and
model retraining. However, existing PTQ methods for SR often fail to achieve
satisfactory performance as they overlook the impact of outliers in activation.
Our empirical analysis reveals that these prevalent activation outliers are
strongly correlated with image color information, and directly removing them
leads to significant performance degradation. Motivated by this, we propose a
dual-region quantization strategy that partitions activations into an outlier
region and a dense region, applying uniform quantization to each region
independently to better balance bit-width allocation. Furthermore, we observe
that different network layers exhibit varying sensitivities to quantization,
leading to different levels of performance degradation. To address this, we
introduce sensitivity-aware finetuning that encourages the model to focus more
on highly sensitive layers, further enhancing quantization performance.
Extensive experiments demonstrate that our method outperforms existing PTQ
approaches across various SR networks and datasets, while achieving performance
comparable to QAT methods in most scenarios with at least a 75 speedup.

</details>


### [83] [3EED: Ground Everything Everywhere in 3D](https://arxiv.org/abs/2511.01755)
*Rong Li,Yuhao Dong,Tianshuai Hu,Ao Liang,Youquan Liu,Dongyue Lu,Liang Pan,Lingdong Kong,Junwei Liang,Ziwei Liu*

Main category: cs.CV

TL;DR: 3EED是一个多平台、多模态的3D视觉基础基准，提供大规模户外场景数据，并提出了跨平台学习技术。


<details>
  <summary>Details</summary>
Motivation: 现有的3D视觉基础基准局限于室内、单一平台和小规模，无法满足开放世界环境的需求。

Method: 提出了平台感知的归一化和跨模态对齐技术，并建立了用于域内和跨平台评估的基准协议。

Result: 3EED数据集包含超过128,000个对象和22,000个验证过的参考表达，规模是现有数据集的10倍。

Conclusion: 3EED数据集和基准工具包的发布旨在推动语言驱动的3D实体感知的未来研究。

Abstract: Visual grounding in 3D is the key for embodied agents to localize
language-referred objects in open-world environments. However, existing
benchmarks are limited to indoor focus, single-platform constraints, and small
scale. We introduce 3EED, a multi-platform, multi-modal 3D grounding benchmark
featuring RGB and LiDAR data from vehicle, drone, and quadruped platforms. We
provide over 128,000 objects and 22,000 validated referring expressions across
diverse outdoor scenes -- 10x larger than existing datasets. We develop a
scalable annotation pipeline combining vision-language model prompting with
human verification to ensure high-quality spatial grounding. To support
cross-platform learning, we propose platform-aware normalization and
cross-modal alignment techniques, and establish benchmark protocols for
in-domain and cross-platform evaluations. Our findings reveal significant
performance gaps, highlighting the challenges and opportunities of
generalizable 3D grounding. The 3EED dataset and benchmark toolkit are released
to advance future research in language-driven 3D embodied perception.

</details>


### [84] [Evolve to Inspire: Novelty Search for Diverse Image Generation](https://arxiv.org/abs/2511.00686)
*Alex Inch,Passawis Chaiyapattanaporn,Yuchen Zhu,Yuan Lu,Ting-Wen Ko,Davide Paglieri*

Main category: cs.CV

TL;DR: WANDER是一种基于新颖性搜索的方法，通过LLM和CLIP嵌入提升文本到图像扩散模型的多样性，实验显示其效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化技术多关注美学适应性，不适用于创意视觉领域，导致输出多样性不足。

Method: WANDER利用大型语言模型（LLM）进行语义演化，结合CLIP嵌入量化新颖性，并通过发射器引导搜索到提示空间的不同区域。

Result: 实验证明，WANDER在多样性指标上显著优于现有的进化提示优化基线，且发射器的有效性通过消融研究得到验证。

Conclusion: WANDER通过新颖性搜索和发射器引导，显著提升了文本到图像扩散模型在单一输入提示下的输出多样性，为创意视觉领域提供了更有效的工具。

Abstract: Text-to-image diffusion models, while proficient at generating high-fidelity
im- ages, often suffer from limited output diversity, hindering their
application in exploratory and ideation tasks. Existing prompt optimization
techniques typically target aesthetic fitness or are ill-suited to the creative
visual domain. To address this shortcoming, we introduce WANDER, a novelty
search-based approach to generating diverse sets of images from a single input
prompt. WANDER operates directly on natural language prompts, employing a Large
Language Model (LLM) for semantic evolution of diverse sets of images, and
using CLIP embeddings to quantify novelty. We additionally apply emitters to
guide the search into distinct regions of the prompt space, and demonstrate
that they boost the diversity of the generated images. Empirical evaluations
using FLUX-DEV for generation and GPT-4o-mini for mutation demonstrate that
WANDER significantly outperforms existing evolutionary prompt optimization
baselines in diversity metrics. Ablation studies confirm the efficacy of
emitters.

</details>


### [85] [Toward Better Optimization of Low-Dose CT Enhancement: A Critical Analysis of Loss Functions and Image Quality Assessment Metrics](https://arxiv.org/abs/2511.00698)
*Taifour Yousra,Beghdadi Azeddine,Marie Luong,Zuheng Ming*

Main category: cs.CV

TL;DR: 本文分析了低剂量CT图像增强中不同损失函数的性能，指出现有损失函数与感知质量指标的不匹配，并建议未来工作应更注重质量指标的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决低剂量CT成像中因噪声和伪影影响诊断准确性的问题，并探讨现有深度学习方法中损失函数与感知质量指标的不一致性。

Method: 通过对不同损失函数在低剂量CT图像质量增强中的相关性及与图像质量指标的一致性进行客观分析。

Result: 研究发现损失函数与质量指标之间存在不一致性，指出在开发新损失函数时应考虑图像质量指标。

Conclusion: 本文强调了在开发用于低剂量CT图像质量增强的新损失函数时，需考虑图像质量指标的重要性。

Abstract: Low-dose CT (LDCT) imaging is widely used to reduce radiation exposure to
mitigate high exposure side effects, but often suffers from noise and artifacts
that affect diagnostic accuracy. To tackle this issue, deep learning models
have been developed to enhance LDCT images. Various loss functions have been
employed, including classical approaches such as Mean Square Error and
adversarial losses, as well as customized loss functions(LFs) designed for
specific architectures. Although these models achieve remarkable performance in
terms of PSNR and SSIM, these metrics are limited in their ability to reflect
perceptual quality, especially for medical images. In this paper, we focus on
one of the most critical elements of DL-based architectures, namely the loss
function. We conduct an objective analysis of the relevance of different loss
functions for LDCT image quality enhancement and their consistency with image
quality metrics. Our findings reveal inconsistencies between LFs and quality
metrics, and highlight the need of consideration of image quality metrics when
developing a new loss function for image quality enhancement.

</details>


### [86] [Validating Deep Models for Alzheimer's 18F-FDG PET Diagnosis Across Populations: A Study with Latin American Data](https://arxiv.org/abs/2511.00728)
*Hugo Massaroli,Hernan Chaves,Pilar Anania,Mauricio Farez,Emmanuel Iarussi,Viviana Siless*

Main category: cs.CV

TL;DR: 深度学习模型在北美ADNI数据上表现优秀，但在拉美FLENI数据上泛化能力不足，性能下降显著。归一化和采样选择是关键因素，未来需关注领域适应和队列多样化。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习模型在北美人群的ADNI数据上表现出色，但在拉美人群的FLENI数据集上泛化能力不足，这引发了对模型普遍适用性的关注。

Method: 本研究在ADNI数据集上对卷积和基于Transformer的模型进行了基准测试，并评估了它们在FLENI数据集上的泛化性能。通过消融研究，确定了每图像归一化和正确的采样选择是泛化的关键因素。

Result: 所有模型在ADNI上表现优异（AUC高达0.96、0.97），但在FLENI上性能显著下降（AUC降至0.82、0.80），显示出明显的领域偏移。不同架构表现相似，Transformer的优势在此任务中未显现。

Conclusion: 本研究强调了诊断AI模型需要进行基于人群的验证，并激励未来在领域适应和队列多样化方面的工作。

Abstract: Deep learning models have shown strong performance in diagnosing Alzheimer's
disease (AD) using neuroimaging data, particularly 18F-FDG PET scans, with
training datasets largely composed of North American cohorts such as those in
the Alzheimer's Disease Neuroimaging Initiative (ADNI). However, their
generalization to underrepresented populations remains underexplored. In this
study, we benchmark convolutional and Transformer-based models on the ADNI
dataset and assess their generalization performance on a novel Latin American
clinical cohort from the FLENI Institute in Buenos Aires, Argentina. We show
that while all models achieve high AUCs on ADNI (up to .96, .97), their
performance drops substantially on FLENI (down to .82, .80, respectively),
revealing a significant domain shift. The tested architectures demonstrated
similar performance, calling into question the supposed advantages of
transformers for this specific task. Through ablation studies, we identify
per-image normalization and a correct sampling selection as key factors for
generalization. Occlusion sensitivity analysis further reveals that models
trained on ADNI, generally attend to canonical hypometabolic regions for the AD
class, but focus becomes unclear for the other classes and for FLENI scans.
These findings highlight the need for population-aware validation of diagnostic
AI models and motivate future work on domain adaptation and cohort
diversification.

</details>


### [87] [Towards classification-based representation learning for place recognition on LiDAR scans](https://arxiv.org/abs/2511.00738)
*Dmitrii Khizbullin,Maksim Konoplia*

Main category: cs.CV

TL;DR: 将地点识别视为分类问题，性能媲美对比学习，且训练更高效稳定。


<details>
  <summary>Details</summary>
Motivation: 探索地点识别任务的替代方法，区别于主流的对比学习。

Method: 通过为LiDAR扫描分配离散的位置标签，并训练一个编码器-解码器模型来直接分类每个扫描的位置。

Result: 在NuScenes数据集上验证了方法的有效性，性能与对比学习方法相当。

Conclusion: 将地点识别视为多类分类问题的方法在NuScenes数据集上表现出与基于对比学习的方法相竞争的性能，同时在训练效率和稳定性上具有优势。

Abstract: Place recognition is a crucial task in autonomous driving, allowing vehicles
to determine their position using sensor data. While most existing methods rely
on contrastive learning, we explore an alternative approach by framing place
recognition as a multi-class classification problem. Our method assigns
discrete location labels to LiDAR scans and trains an encoder-decoder model to
classify each scan's position directly. We evaluate this approach on the
NuScenes dataset and show that it achieves competitive performance compared to
contrastive learning-based methods while offering advantages in training
efficiency and stability.

</details>


### [88] [Erasing 'Ugly' from the Internet: Propagation of the Beauty Myth in Text-Image Models](https://arxiv.org/abs/2511.00749)
*Tanvi Dinkar,Aiqi Jiang,Gavin Abercrombie,Ioannis Konstas*

Main category: cs.CV

TL;DR: 研究发现生成式AI模型普遍存在与美丽标准相关的人口偏见，如肤色偏好、年龄和性化倾向，这些偏见通过开发者行为被强化，对社会数据流和多样性构成威胁。


<details>
  <summary>Details</summary>
Motivation: 社交媒体加剧了西方美丽标准的推广，导致负面自我形象，尤其是女性和女孩，并引发身体畸形等问题。互联网上越来越多的内容是人工生成的，引发了对这些标准被夸大的担忧。本研究旨在探讨生成式AI模型如何编码'美丽'并消除'丑陋'，及其对社会的影响。

Method: 研究创建了两个图像生成流程：文本到图像模型和文本到语言模型再到图像模型。开发了一个结构化美丽分类法，用于提示三个语言模型和两个文本到图像模型，累计生成5984张图像。然后招募女性和非二元社交媒体用户通过Likert量表进行1200张图像的评估。

Result: 结果显示，86.5%的生成图像描绘了较浅肤色的人，22%包含明确的非安全内容（尽管模型经过安全训练），74%被评价为属于年轻年龄段。非二元个体的图像被评价为更年轻和更过度性化，显示出令人担忧的交叉效应。带有'负面'或'丑陋'美丽特征的提示（如'宽鼻子'）无论性别如何都产生了更高的非安全内容评分。

Conclusion: 该研究揭示了生成式AI模型中存在的与美丽标准相关的普遍人口偏见，这些偏见通过模型开发者（如负面提示）被积极延续。研究讨论了这些偏见对社会的潜在影响，包括污染数据流和积极消除不符合开发者美丽刻板印象的特征。

Abstract: Social media has exacerbated the promotion of Western beauty norms, leading
to negative self-image, particularly in women and girls, and causing harm such
as body dysmorphia. Increasingly content on the internet has been artificially
generated, leading to concerns that these norms are being exaggerated. The aim
of this work is to study how generative AI models may encode 'beauty' and erase
'ugliness', and discuss the implications of this for society. To investigate
these aims, we create two image generation pipelines: a text-to-image model and
a text-to-language model-to image model. We develop a structured beauty
taxonomy which we use to prompt three language models (LMs) and two
text-to-image models to cumulatively generate 5984 images using our two
pipelines. We then recruit women and non-binary social media users to evaluate
1200 of the images through a Likert-scale within-subjects study. Participants
show high agreement in their ratings. Our results show that 86.5% of generated
images depicted people with lighter skin tones, 22% contained explicit content
despite Safe for Work (SFW) training, and 74% were rated as being in a younger
age demographic. In particular, the images of non-binary individuals were rated
as both younger and more hypersexualised, indicating troubling intersectional
effects. Notably, prompts encoded with 'negative' or 'ugly' beauty traits (such
as "a wide nose") consistently produced higher Not SFW (NSFW) ratings
regardless of gender. This work sheds light on the pervasive demographic biases
related to beauty standards present in generative AI models -- biases that are
actively perpetuated by model developers, such as via negative prompting. We
conclude by discussing the implications of this on society, which include
pollution of the data streams and active erasure of features that do not fall
inside the stereotype of what is considered beautiful by developers.

</details>


### [89] [A Hybrid YOLOv5-SSD IoT-Based Animal Detection System for Durian Plantation Protection](https://arxiv.org/abs/2511.00777)
*Anis Suttan Shahrir,Zakiah Ayop,Syarulnaziah Anawar,Norulzahrah Mohd Zainudin*

Main category: cs.CV

TL;DR: 研究开发了一个物联网驱动的动物检测系统，结合YOLOv5和SSD算法，通过Telegram实时通知农民并触发声音威慑，显著提高了榴莲种植园的动物检测准确率。


<details>
  <summary>Details</summary>
Motivation: 榴莲种植园因动物入侵导致作物损失和经济损失，传统农业实践因缺乏无需人工干预的监控而效果不佳。机器学习与物联网技术的快速发展为动物检测提供了新方法。

Method: 系统集成了YOLOv5和SSD目标检测算法以提高检测准确率，并提供实时监控，通过Telegram通知农民快速响应。检测到动物后，自动触发声音威慑机制（如虎吼）。

Result: YOLO+SSD模型对大象、野猪和猴子的检测准确率分别达到90%、85%和70%。系统在白天表现最佳，夜间准确率下降，无论图像是静态还是视频。

Conclusion: 本研究提出了一个结合检测、通知和威慑的全面实用框架，为自动化农业解决方案的未来创新铺平了道路。

Abstract: Durian plantation suffers from animal intrusions that cause crop damage and
financial loss. The traditional farming practices prove ineffective due to the
unavailability of monitoring without human intervention. The fast growth of
machine learning and Internet of Things (IoT) technology has led to new ways to
detect animals. However, current systems are limited by dependence on single
object detection algorithms, less accessible notification platforms, and
limited deterrent mechanisms. This research suggests an IoT-enabled animal
detection system for durian crops. The system integrates YOLOv5 and SSD object
detection algorithms to improve detection accuracy. The system provides
real-time monitoring, with detected intrusions automatically reported to
farmers via Telegram notifications for rapid response. An automated sound
mechanism (e.g., tiger roar) is triggered once the animal is detected. The
YOLO+SSD model achieved accuracy rates of elephant, boar, and monkey at 90%,
85% and 70%, respectively. The system shows the highest accuracy in daytime and
decreases at night, regardless of whether the image is still or a video.
Overall, this study contributes a comprehensive and practical framework that
combines detection, notification, and deterrence, paving the way for future
innovations in automated farming solutions.

</details>


### [90] [Class-agnostic 3D Segmentation by Granularity-Consistent Automatic 2D Mask Tracking](https://arxiv.org/abs/2511.00785)
*Juan Wang,Yasutomo Kawanishi,Tomo Miyazaki,Zhijie Wang,Shinichiro Omachi*

Main category: cs.CV

TL;DR: 提出粒度一致的2D掩模跟踪方法，结合三阶段课程学习框架，有效提升3D实例分割的一致性和准确性，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过将2D掩模从基础模型转移到3D生成伪标签，但因视频帧独立处理导致分割粒度和伪标签不一致，影响最终分割准确性。

Method: 提出了一种粒度一致的自动2D掩模跟踪方法，结合三阶段课程学习框架，从单视图数据逐步过渡到多视图标注，最终实现全局一致的场景监督。

Result: 实验结果表明，该方法生成了一致且准确的3D分割，并在标准基准测试中达到了最先进水平，同时具备开放词汇能力。

Conclusion: 该方法通过保持帧间时间一致性，有效解决了3D伪标签冲突问题，并结合三阶段课程学习框架，显著提升了3D实例分割的准确性和一致性。

Abstract: 3D instance segmentation is an important task for real-world applications. To
avoid costly manual annotations, existing methods have explored generating
pseudo labels by transferring 2D masks from foundation models to 3D. However,
this approach is often suboptimal since the video frames are processed
independently. This causes inconsistent segmentation granularity and
conflicting 3D pseudo labels, which degrades the accuracy of final
segmentation. To address this, we introduce a Granularity-Consistent automatic
2D Mask Tracking approach that maintains temporal correspondences across
frames, eliminating conflicting pseudo labels. Combined with a three-stage
curriculum learning framework, our approach progressively trains from
fragmented single-view data to unified multi-view annotations, ultimately
globally coherent full-scene supervision. This structured learning pipeline
enables the model to progressively expose to pseudo-labels of increasing
consistency. Thus, we can robustly distill a consistent 3D representation from
initially fragmented and contradictory 2D priors. Experimental results
demonstrated that our method effectively generated consistent and accurate 3D
segmentations. Furthermore, the proposed method achieved state-of-the-art
results on standard benchmarks and open-vocabulary ability.

</details>


### [91] [FedOnco-Bench: A Reproducible Benchmark for Privacy-Aware Federated Tumor Segmentation with Synthetic CT Data](https://arxiv.org/abs/2511.00795)
*Viswa Chaitanya Marella,Suhasnadh Reddy Veluru,Sai Teja Erukude*

Main category: cs.CV

TL;DR: FedOnco-Bench是一个评估隐私保护联邦学习方法在医学图像分割中性能与隐私泄露的基准测试平台，显示不同方法在隐私与效用间的权衡。


<details>
  <summary>Details</summary>
Motivation: 联邦学习（FL）在隐私敏感环境中具有重要应用价值，但其系统仍面临成员推断攻击和数据异构性的脆弱性问题。

Method: 论文提出了FedOnco-Bench，一个使用合成肿瘤CT扫描数据的隐私感知联邦学习可复现基准测试，评估了FedAvg、FedProx、FedBN和结合DP-SGD的FedAvg等方法在分割性能和隐私泄露方面的表现。

Result: 结果显示隐私与效用之间存在明显权衡：FedAvg性能高（Dice约0.85）但隐私泄露较多（攻击AUC约0.72），而DP-SGD提供更高隐私保护（AUC约0.25）但牺牲了准确性（Dice约0.79）。FedProx和FedBN在异构数据下表现平衡。

Conclusion: FedOnco-Bench作为一个标准化、开源的平台，为医学图像分割领域的隐私保护联邦学习方法提供了基准测试和开发基础。

Abstract: Federated Learning (FL) allows multiple institutions to cooperatively train
machine learning models while retaining sensitive data at the source, which has
great utility in privacy-sensitive environments. However, FL systems remain
vulnerable to membership-inference attacks and data heterogeneity. This paper
presents FedOnco-Bench, a reproducible benchmark for privacy-aware FL using
synthetic oncologic CT scans with tumor annotations. It evaluates segmentation
performance and privacy leakage across FL methods: FedAvg, FedProx, FedBN, and
FedAvg with DP-SGD. Results show a distinct trade-off between privacy and
utility: FedAvg is high performance (Dice around 0.85) with more privacy
leakage (attack AUC about 0.72), while DP-SGD provides a higher level of
privacy (AUC around 0.25) at the cost of accuracy (Dice about 0.79). FedProx
and FedBN offer balanced performance under heterogeneous data, especially with
non-identical distributed client data. FedOnco-Bench serves as a standardized,
open-source platform for benchmarking and developing privacy-preserving FL
methods for medical image segmentation.

</details>


### [92] [Med-Banana-50K: A Cross-modality Large-Scale Dataset for Text-guided Medical Image Editing](https://arxiv.org/abs/2511.00801)
*Zhihui Chen,Mengling Feng*

Main category: cs.CV

TL;DR: Med-Banana-50K是一个用于医疗图像编辑的大规模数据集，通过严格质量控制生成，支持模型训练与评估。


<details>
  <summary>Details</summary>
Motivation: 解决医疗图像编辑领域缺乏大规模、高质量且开放数据集的问题。

Method: 利用Gemini-2.5-Flash-Image生成双向编辑（病灶添加与去除），并通过LLM-as-Judge和迭代细化进行医学质量控制。

Result: 构建了包含50K图像、37K失败尝试的Med-Banana-50K数据集，涵盖3种模态和23种疾病类型。

Conclusion: Med-Banana-50K数据集为医疗图像编辑领域提供了一个大规模、高质量且开放的基础资源，支持下一代模型的训练与评估。

Abstract: Recent advances in multimodal large language models have enabled remarkable
medical image editing capabilities. However, the research community's progress
remains constrained by the absence of large-scale, high-quality, and openly
accessible datasets built specifically for medical image editing with strict
anatomical and clinical constraints. We introduce Med-Banana-50K, a
comprehensive 50K-image dataset for instruction-based medical image editing
spanning three modalities (chest X-ray, brain MRI, fundus photography) and 23
disease types. Our dataset is constructed by leveraging Gemini-2.5-Flash-Image
to generate bidirectional edits (lesion addition and removal) from real medical
images. What distinguishes Med-Banana-50K from general-domain editing datasets
is our systematic approach to medical quality control: we employ LLM-as-Judge
with a medically grounded rubric (instruction compliance, structural
plausibility, realism, and fidelity preservation) and history-aware iterative
refinement up to five rounds. Beyond single-turn editing, Med-Banana-50K
includes 37K failed attempts with full conversation logs for preference
learning and alignment research. By providing this large-scale, medically
validated, and fully documented resource, Med-Banana-50K establishes a
foundation for training and evaluating the next generation of medical image
editing models.Our dataset and code are publicly available at
[https://github.com/richardChenzhihui/med-banana-50k].

</details>


### [93] [GUI-AIMA: Aligning Intrinsic Multimodal Attention with a Context Anchor for GUI Grounding](https://arxiv.org/abs/2511.00810)
*Shijie Zhou,Viet Dac Lai,Hao Tan,Jihyung Kil,Wanrong Zhu,Changyou Chen,Ruiyi Zhang*

Main category: cs.CV

TL;DR: GUI-AIMA是一种基于注意力的无坐标框架，通过轻量训练有效触发MLLMs的原生接地能力，在3B模型中实现了最先进的GUI接地性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于MLLMs的方法将GUI接地视为基于文本的坐标生成任务，但直接从视觉输入生成精确坐标具有挑战性且计算密集。

Method: GUI-AIMA是一个基于注意力的无坐标监督微调框架，通过将MLLMs的多模态注意力与基于补丁的接地信号对齐来实现高效的GUI接地。

Result: GUI-AIMA-3B在ScreenSpot-Pro和OSWorld-G上的平均准确率分别达到58.6%和62.2%。

Conclusion: GUI-AIMA-3B展示了卓越的数据效率，验证了轻量训练可以触发MLLMs的原生接地能力，并在3B模型中达到了最先进的性能。

Abstract: Graphical user interface (GUI) grounding is a key function of computer-use
agents, which maps natural-language instructions to actionable screen regions.
Existing approaches based on Multimodal Large Language Models (MLLMs) typically
formulate it as a text-based coordinate generation task, yet directly
generating precise coordinates from visual inputs remains challenging and
computationally intensive. An intuitive way to implement GUI grounding is to
first select visual patches relevant to the instructions and then determine the
precise click location within those patches. Based on the observations that
general MLLMs have some native grounding capability, nested within their
attentions, we propose GUI-AIMA, an attention-based and coordinate-free
supervised fine-tuning framework for efficient GUI grounding. GUI-AIMA aligns
the intrinsic multimodal attention of MLLMs with patch-wise grounding signals.
These signals are calculated adaptively for diverse user instructions by
multi-head aggregation on simplified query-visual attention matrices. Besides,
its coordinate-free manner can easily integrate a plug-and-play zoom-in stage.
GUI-AIMA-3B was trained with only 85k screenshots, demonstrating exceptional
data efficiency and verifying that light training can trigger the native
grounding capability of MLLMs. It achieves state-of-the-art performance among
3B models, attaining an average accuracy of 58.6% on ScreenSpot-Pro and 62.2%
on OSWorld-G. Project page: https://github.com/sjz5202/GUI-AIMA

</details>


### [94] [TA-LSDiff:Topology-Aware Diffusion Guided by a Level Set Energy for Pancreas Segmentation](https://arxiv.org/abs/2511.00815)
*Yue Gou,Fanghui Song,Yuming Xing,Shengzhu Shi,Zhichang Guo,Boying Wu*

Main category: cs.CV

TL;DR: TA-LSDiff 结合拓扑感知扩散模型和水平集能量，解决了胰腺分割的挑战，实现了最先进的准确性。


<details>
  <summary>Details</summary>
Motivation: 胰腺分割在医学图像处理中具有挑战性，传统方法忽略拓扑效应，而深度学习方法牺牲结构细节。

Method: 结合拓扑感知扩散概率模型和水平集能量，通过四个互补项整合输入图像和深层特征，引导隐式曲线演化。

Result: 在四个公共胰腺数据集上的评估显示，TA-LSDiff 实现了最先进的准确性。

Conclusion: TA-LSDiff 被证明是一种实用且准确的胰腺分割解决方案，优于现有方法。

Abstract: Pancreas segmentation in medical image processing is a persistent challenge
due to its small size, low contrast against adjacent tissues, and significant
topological variations. Traditional level set methods drive boundary evolution
using gradient flows, often ignoring pointwise topological effects. Conversely,
deep learning-based segmentation networks extract rich semantic features but
frequently sacrifice structural details. To bridge this gap, we propose a novel
model named TA-LSDiff, which combined topology-aware diffusion probabilistic
model and level set energy, achieving segmentation without explicit geometric
evolution. This energy function guides implicit curve evolution by integrating
the input image and deep features through four complementary terms. To further
enhance boundary precision, we introduce a pixel-adaptive refinement module
that locally modulates the energy function using affinity weighting from
neighboring evidence. Ablation studies systematically quantify the contribution
of each proposed component. Evaluations on four public pancreas datasets
demonstrate that TA-LSDiff achieves state-of-the-art accuracy, outperforming
existing methods. These results establish TA-LSDiff as a practical and accurate
solution for pancreas segmentation.

</details>


### [95] [OMEGA: Optimized Multimodal Position Encoding Index Derivation with Global Adaptive Scaling for Vision-Language Models](https://arxiv.org/abs/2511.00821)
*Ruoxiang Huang,Xindian Ma,Rundong Kong,Zhen Yuan,Peng Zhang*

Main category: cs.CV

TL;DR: OMEGA是一种新型位置编码框架，通过模态特定编码和自适应步长缩放，提升视觉语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的位置编码策略未充分考虑文本和视觉模态的结构差异，导致性能受限。

Method: 提出OMEGA框架，采用模态特定位置编码（MSPE）和全局自适应编码步长缩放（GAESS）技术。

Result: 在多种架构和VQA基准测试中，OMEGA显著提升了模型性能，视觉密集型任务中最高提升3.43%。

Conclusion: OMEGA框架通过模态特定的位置编码和全局自适应编码步长缩放，显著提升了视觉语言模型在多模态任务中的性能。

Abstract: Vision-Language Models (VLMs) have demonstrated strong performance across
various multimodal tasks, where position encoding plays a vital role in
modeling both the sequential structure of textual information and the spatial
structure of visual information. However, current VLMs commonly adopt
modality-unified 1D or 2D positional indexing strategies, which treat textual
and visual tokens uniformly without accounting for their distinct structural
properties and sequential continuity for text and spatial coherence for vision.
To address this limitation, we propose OMEGA, a novel position encoding
framework that employs Modality-Specific Position Encoding (MSPE) to assign
positional indices while preserving the inherent structures of each modality
across separate coordinate dimensions. Additionally, to align the information
density of multimodal data in the positional index space, OMEGA introduces
Global Adaptive Encoding Step Scaling (GAESS), which adaptively adjusts the
position encoding step size of visual tokens based on the embedding entropy of
both modalities. Experimental results demonstrate that OMEGA consistently
enhances VLM performance across diverse architectures and VQA benchmarks. On
visual-intensive tasks, OMEGA achieves up to 3.43% improvement over baseline
position encoding strategies on Qwen2.5-VL-3B, with consistent gains observed
across larger models including Qwen2.5-VL-7B and LLaVA-v1.5-7B.

</details>


### [96] [Enhancing Adversarial Transferability in Visual-Language Pre-training Models via Local Shuffle and Sample-based Attack](https://arxiv.org/abs/2511.00831)
*Xin Liu,Aoyang Zhou,Aoyang Zhou*

Main category: cs.CV

TL;DR: LSSA通过局部打乱和采样方法解决了多模态对抗样本生成中的过拟合问题，显著提升了对抗样本的可转移性和效果。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态对抗样本生成方法因过度依赖单一模态的对抗样本信息而导致过拟合问题，缺乏输入多样性。

Method: 提出了一种称为局部打乱和基于样本的攻击（LSSA）的新方法，通过随机打乱局部图像块、扩展原始图像-文本对、生成对抗性图像并围绕它们采样，然后利用原始和采样图像生成对抗性文本。

Result: 在多模型和数据集上的广泛实验表明，LSSA显著增强了多模态对抗样本的可转移性。

Conclusion: LSSA显著提升了多模态对抗样本在各种VLP模型和下游任务中的可转移性，并在大型视觉语言模型上优于其他先进攻击方法。

Abstract: Visual-Language Pre-training (VLP) models have achieved significant
performance across various downstream tasks. However, they remain vulnerable to
adversarial examples. While prior efforts focus on improving the adversarial
transferability of multimodal adversarial examples through cross-modal
interactions, these approaches suffer from overfitting issues, due to a lack of
input diversity by relying excessively on information from adversarial examples
in one modality when crafting attacks in another. To address this issue, we
draw inspiration from strategies in some adversarial training methods and
propose a novel attack called Local Shuffle and Sample-based Attack (LSSA).
LSSA randomly shuffles one of the local image blocks, thus expanding the
original image-text pairs, generating adversarial images, and sampling around
them. Then, it utilizes both the original and sampled images to generate the
adversarial texts. Extensive experiments on multiple models and datasets
demonstrate that LSSA significantly enhances the transferability of multimodal
adversarial examples across diverse VLP models and downstream tasks. Moreover,
LSSA outperforms other advanced attacks on Large Vision-Language Models.

</details>


### [97] [Linear Differential Vision Transformer: Learning Visual Contrasts via Pairwise Differentials](https://arxiv.org/abs/2511.00833)
*Yifan Pu,Jixuan Ying,Qixiu Li,Tianzhu Ye,Dongchen Han,Xiaochen Wang,Ziyi Wang,Xinyu Shao,Gao Huang,Xiu Li*

Main category: cs.CV

TL;DR: VCA是一种替代MHSA的视觉对比注意力机制，降低计算复杂度并提升ViTs性能。


<details>
  <summary>Details</summary>
Motivation: ViTs的MHSA层在视觉上弱或冗余的相关性上花费大量计算，VCA旨在减少这种计算复杂度并增强视觉对比。

Method: VCA作为MHSA的替代方案，通过空间池化提取视觉对比令牌，分为正负流，以差分交互突出区域间的差异。

Result: VCA将DeiT-Tiny在ImageNet-1K上的top-1准确率从72.2%提升至75.6%，并在图像生成任务中显著降低FID。

Conclusion: VCA提供了一种简单的方法，使Vision Transformers更快且更锐利，通过减少计算复杂性和增加视觉对比注意力。

Abstract: Vision Transformers (ViTs) have become a universal backbone for both image
recognition and image generation. Yet their Multi-Head Self-Attention (MHSA)
layer still performs a quadratic query-key interaction for every token pair,
spending the bulk of computation on visually weak or redundant correlations. We
introduce Visual-Contrast Attention (VCA), a drop-in replacement for MHSA that
injects an explicit notion of discrimination while reducing the theoretical
complexity from O(N N C) to O(N n C) with n << N. VCA first distils each head's
dense query field into a handful of spatially pooled visual-contrast tokens,
then splits them into a learnable positive and negative stream whose
differential interaction highlights what truly separates one region from
another. The module adds fewer than 0.3M parameters to a DeiT-Tiny backbone,
requires no extra FLOPs, and is wholly architecture-agnostic. Empirically, VCA
lifts DeiT-Tiny top-1 accuracy on ImageNet-1K from 72.2% to 75.6% (+3.4) and
improves three strong hierarchical ViTs by up to 3.1%, while in
class-conditional ImageNet generation it lowers FID-50K by 2.1 to 5.2 points
across both diffusion (DiT) and flow (SiT) models. Extensive ablations confirm
that (i) spatial pooling supplies low-variance global cues, (ii) dual
positional embeddings are indispensable for contrastive reasoning, and (iii)
combining the two in both stages yields the strongest synergy. VCA therefore
offers a simple path towards faster and sharper Vision Transformers. The source
code is available at https://github.com/LeapLabTHU/LinearDiff.

</details>


### [98] [Parameter Interpolation Adversarial Training for Robust Image Classification](https://arxiv.org/abs/2511.00836)
*Xin Liu,Yichen Yang,Kun He,John E. Hopcroft*

Main category: cs.CV

TL;DR: PIAT通过参数插值和NMSE方法有效提升了深度神经网络的对抗鲁棒性，解决了现有对抗训练的振荡和过拟合问题。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络在各种任务中表现出色，但仍易受对抗样本攻击。现有对抗训练方法在训练过程中存在明显的鲁棒性振荡和过拟合问题，影响防御效果。

Method: 提出了一种称为参数插值对抗训练（PIAT）的新框架，通过在每个epoch间插值模型参数来平滑决策边界，并使用归一化均方误差（NMSE）来对齐干净样本和对抗样本的logits相对大小。

Result: 在多个基准数据集上的实验表明，PIAT显著提升了CNN和ViT的对抗鲁棒性。

Conclusion: PIAT框架通过参数插值和NMSE方法显著提升了CNN和ViT的对抗鲁棒性，解决了现有对抗训练中的振荡和过拟合问题。

Abstract: Though deep neural networks exhibit superior performance on various tasks,
they are still plagued by adversarial examples. Adversarial training has been
demonstrated to be the most effective method to defend against adversarial
attacks. However, existing adversarial training methods show that the model
robustness has apparent oscillations and overfitting issues in the training
process, degrading the defense efficacy. To address these issues, we propose a
novel framework called Parameter Interpolation Adversarial Training (PIAT).
PIAT tunes the model parameters between each epoch by interpolating the
parameters of the previous and current epochs. It makes the decision boundary
of model change more moderate and alleviates the overfitting issue, helping the
model converge better and achieving higher model robustness. In addition, we
suggest using the Normalized Mean Square Error (NMSE) to further improve the
robustness by aligning the relative magnitude of logits between clean and
adversarial examples rather than the absolute magnitude. Extensive experiments
conducted on several benchmark datasets demonstrate that our framework could
prominently improve the robustness of both Convolutional Neural Networks (CNNs)
and Vision Transformers (ViTs).

</details>


### [99] [OmniBrainBench: A Comprehensive Multimodal Benchmark for Brain Imaging Analysis Across Multi-stage Clinical Tasks](https://arxiv.org/abs/2511.00846)
*Zhihao Peng,Cheng Wang,Shengyuan Liu,Zhiying Liang,Yixuan Yuan*

Main category: cs.CV

TL;DR: OmniBrainBench是首个全面评估MLLMs在脑成像分析中多模态理解能力的基准，覆盖15种模态和临床任务，揭示模型与医生间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前脑成像VQA基准覆盖模态少或病理描述粗糙，无法全面评估MLLMs在临床连续体中的表现。

Method: 通过引入包含15种脑成像模态、9,527个VQA对和31,706张图像的OmniBrainBench基准，模拟临床工作流并覆盖15个多阶段临床任务。

Result: 评估24个先进模型表明：(1)专有MLLMs优于开源和医疗模型但仍落后于医生；(2)医疗MLLMs表现差异大；(3)开源MLLMs整体落后但在特定任务中表现优异；(4)MLLMs在复杂术前任务中表现显著不足。

Conclusion: OmniBrainBench为评估和推进MLLMs在脑成像分析中的能力设定了新标准，揭示了与专家临床推理之间的差距。

Abstract: Brain imaging analysis is vital for diagnosing and treating brain disorders,
and multimodal large language models (MLLMs) are increasingly assisting in that
analysis. However, current brain-oriented visual question-answering (VQA)
benchmarks either cover a few imaging modalities or are limited to
coarse-grained pathological descriptions, hindering a comprehensive assessment
of MLLMs throughout the full clinical continuum. To address these, we introduce
OmniBrainBench, the first comprehensive multimodal VQA benchmark specifically
designed to assess the multimodal comprehension capabilities of MLLMs in brain
imaging analysis.OmniBrainBench consists of 15 distinct brain imaging
modalities collected from 30 verified medical sources, yielding 9,527 validated
VQA pairs and 31,706 images. It simulates clinical workflows and encompasses 15
multi-stage clinical tasks rigorously validated by a professional radiologist.
Evaluation of 24 state-of-the-art models, including open-source, medical, and
proprietary MLLMs, highlights the substantial challenges posed by
OmniBrainBench. Our experiments reveal: (1) proprietary MLLMs (e.g., GPT-5)
beat open-source and medical models but lag physicians; (2) medical MLLMs vary
widely in performance; (3) open-source MLLMs trail overall but excel in
specific tasks; (4) MLLMs underperform sharply in complex preoperative tasks,
revealing a visual-to-clinical reasoning gap. OmniBrainBench sets a new
standard for evaluating and advancing MLLMs in brain imaging analysis,
highlighting gaps compared to expert clinical reasoning. We release it at
benchmark \& code.

</details>


### [100] [Occlusion-Aware Diffusion Model for Pedestrian Intention Prediction](https://arxiv.org/abs/2511.00858)
*Yu Liu,Zhijie Liu,Zedong Yang,You-Fu Li,He Kong*

Main category: cs.CV

TL;DR: 提出ODM模型，通过重建遮挡运动模式提升行人意图预测，在遮挡场景下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度学习模型在遮挡场景下行人意图预测的不足。

Method: 采用遮挡感知扩散变换器架构和遮挡掩码引导的反向过程，重建遮挡运动模式并指导意图预测。

Result: 在PIE和JAAD基准测试中，ODM表现出比现有方法更鲁棒的性能。

Conclusion: 提出的Occlusion-Aware Diffusion Model（ODM）在遮挡场景下显著提升了行人过街意图预测的鲁棒性，优于现有方法。

Abstract: Predicting pedestrian crossing intentions is crucial for the navigation of
mobile robots and intelligent vehicles. Although recent deep learning-based
models have shown significant success in forecasting intentions, few consider
incomplete observation under occlusion scenarios. To tackle this challenge, we
propose an Occlusion-Aware Diffusion Model (ODM) that reconstructs occluded
motion patterns and leverages them to guide future intention prediction. During
the denoising stage, we introduce an occlusion-aware diffusion transformer
architecture to estimate noise features associated with occluded patterns,
thereby enhancing the model's ability to capture contextual relationships in
occluded semantic scenarios. Furthermore, an occlusion mask-guided reverse
process is introduced to effectively utilize observation information, reducing
the accumulation of prediction errors and enhancing the accuracy of
reconstructed motion features. The performance of the proposed method under
various occlusion scenarios is comprehensively evaluated and compared with
existing methods on popular benchmarks, namely PIE and JAAD. Extensive
experimental results demonstrate that the proposed method achieves more robust
performance than existing methods in the literature.

</details>


### [101] [Layer-Wise Modality Decomposition for Interpretable Multimodal Sensor Fusion](https://arxiv.org/abs/2511.00859)
*Jaehyun Park,Konyul Park,Daehun Kim,Junseo Park,Jun Won Choi*

Main category: cs.CV

TL;DR: LMD是一种用于自动驾驶多传感器融合模型的可解释性方法，能逐层分解各模态的贡献，验证有效且实用。


<details>
  <summary>Details</summary>
Motivation: 由于多传感器输入在融合网络中信息纠缠，难以确定各模态对预测的贡献，而自动驾驶中感知模型的透明度至关重要，因此需要一种解释方法来分解各模态的贡献。

Method: LMD是一种后验、模型无关的解释方法，能够在预训练的融合模型中逐层解耦模态特定信息。

Result: LMD在相机-雷达、相机-LiDAR及相机-雷达-LiDAR设置下验证了其有效性，通过结构化扰动指标和模态可视化分解展示了其实际应用价值。

Conclusion: Layer-Wise Modality Decomposition (LMD) successfully提供了对多传感器融合模型预测的可解释性，能够有效分解各模态的贡献，适用于自动驾驶感知模型的解释。

Abstract: In autonomous driving, transparency in the decision-making of perception
models is critical, as even a single misperception can be catastrophic. Yet
with multi-sensor inputs, it is difficult to determine how each modality
contributes to a prediction because sensor information becomes entangled within
the fusion network. We introduce Layer-Wise Modality Decomposition (LMD), a
post-hoc, model-agnostic interpretability method that disentangles
modality-specific information across all layers of a pretrained fusion model.
To our knowledge, LMD is the first approach to attribute the predictions of a
perception model to individual input modalities in a sensor-fusion system for
autonomous driving. We evaluate LMD on pretrained fusion models under
camera-radar, camera-LiDAR, and camera-radar-LiDAR settings for autonomous
driving. Its effectiveness is validated using structured perturbation-based
metrics and modality-wise visual decompositions, demonstrating practical
applicability to interpreting high-capacity multimodal architectures. Code is
available at https://github.com/detxter-jvb/Layer-Wise-Modality-Decomposition.

</details>


### [102] [Fleming-VL: Towards Universal Medical Visual Reasoning with Multimodal LLMs](https://arxiv.org/abs/2511.00916)
*Yan Shu,Chi Liu,Robin Chen,Derek Li,Bryan Dai*

Main category: cs.CV

TL;DR: Fleming-VL是一个统一的医学多模态大语言模型框架，通过数据策略和优化技术，在多种医学视觉任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决医学数据异质性（如2D、3D、时序数据）和领域差异带来的挑战，推动统一医学MLLMs的发展。

Method: 通过数据中心的三大策略：扩大预训练数据、补充稀有医学数据进行微调、扩展评估框架，结合SFT和GRPO技术，开发了多规模的Fleming-VL模型。

Result: Fleming-VL在多个基准测试（如医学VQA、视频QA、3D医学图像理解）中达到了最先进的性能。

Conclusion: Fleming-VL作为一种统一的多模态大语言模型框架，在医学视觉理解领域取得了显著成果，并公开发布以促进医学AI的透明和可重复发展。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable
effectiveness in various general-domain scenarios, such as visual question
answering and image captioning. Recently, researchers have increasingly focused
on empowering MLLMs with medical conversational abilities, which hold
significant promise for clinical applications. However, medical data presents
unique challenges due to its heterogeneous nature -- encompassing diverse
modalities including 2D images, 3D volumetric scans, and temporal video
sequences. The substantial domain gap and data format inconsistencies across
these modalities have hindered the development of unified medical MLLMs. To
address these challenges, we propose Fleming-VL, a unified end-to-end framework
for comprehensive medical visual understanding across heterogeneous modalities.
Fleming-VL tackles this problem from a data-centric perspective through three
key strategies: (1) scaling up pretraining by integrating long-context data
from both natural and medical-specific domains; (2) complementing fine-tuning
with rare medical data, including holistic video analysis and underrepresented
2D modalities such as ultrasound and dermoscopy images; (3) extending existing
evaluation frameworks to incorporate 3D volumetric and video understanding
benchmarks. Through supervised fine-tuning (SFT) and group relative policy
optimization (GRPO), we develop Fleming-VL in multiple model scales. Extensive
experiments demonstrate that Fleming-VL achieves state-of-the-art performance
across multiple benchmarks, including medical VQA, video QA, and 3D medical
image understanding. We publicly release Fleming-VL to promote transparent,
reproducible, and auditable progress in medical AI.

</details>


### [103] [Dynamic Multi-level Weighted Alignment Network for Zero-shot Sketch-based Image Retrieval](https://arxiv.org/abs/2511.00925)
*Hanwen Su,Ge Song,Jiyan Wang,Yuanbo Zhu*

Main category: cs.CV

TL;DR: 本文提出一种动态多级加权对齐网络，通过三个模块改进ZS-SBIR任务，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前ZS-SBIR方法存在模态样本不平衡和训练中低质量信息不一致的问题，导致性能不佳。

Method: 方法包括三个模块：(i) 单模态特征提取模块（使用CLIP文本编码器和ViT提取文本和视觉标记），(ii) 跨模态多级加权模块（通过局部和全局聚合块生成对齐权重列表），(iii) 加权四元损失模块（改善三元损失的领域平衡）。

Result: 在Sketchy、TU-Berlin和QuickDraw三个基准数据集上的实验表明，该方法优于现有ZS-SBIR方法。

Conclusion: 本文提出的动态多级加权对齐网络（Dynamic Multi-level Weighted Alignment Network）在零样本草图到图像检索（ZS-SBIR）任务中表现出色，优于现有方法。

Abstract: The problem of zero-shot sketch-based image retrieval (ZS-SBIR) has achieved
increasing attention due to its wide applications, e.g. e-commerce. Despite
progress made in this field, previous works suffer from using imbalanced
samples of modalities and inconsistent low-quality information during training,
resulting in sub-optimal performance. Therefore, in this paper, we introduce an
approach called Dynamic Multi-level Weighted Alignment Network for ZS-SBIR. It
consists of three components: (i) a Uni-modal Feature Extraction Module that
includes a CLIP text encoder and a ViT for extracting textual and visual
tokens, (ii) a Cross-modal Multi-level Weighting Module that produces an
alignment weight list by the local and global aggregation blocks to measure the
aligning quality of sketch and image samples, (iii) a Weighted Quadruplet Loss
Module aiming to improve the balance of domains in the triplet loss.
Experiments on three benchmark datasets, i.e., Sketchy, TU-Berlin, and
QuickDraw, show our method delivers superior performances over the
state-of-the-art ZS-SBIR methods.

</details>


### [104] [EVTAR: End-to-End Try on with Additional Unpaired Visual Reference](https://arxiv.org/abs/2511.00956)
*Liuzhuozheng Li,Yue Gong,Shanyuan Liu,Bo Cheng,Yuhang Ma,Liebucha Wu,Dengyang Jiang,Zanyi Wang,Dawei Leng,Yuhui Yin*

Main category: cs.CV

TL;DR: EVTAR是一种端到端虚拟试衣模型，通过参考图像增强试衣准确性，简化输入要求并提升效果真实性。


<details>
  <summary>Details</summary>
Motivation: 现有虚拟试衣方法依赖复杂输入（如不可知人物图像、人体姿态等），导致实际应用中的不便和低效，EVTAR旨在简化输入并提升试衣效果的真实性。

Method: EVTAR采用两阶段训练策略，仅需源图像和目标服装作为输入，无需依赖复杂的中间表示（如掩码、密集姿态或分割图）。通过利用其他穿着相同服装的个体参考图像，模型能更好地保留服装纹理和细节。

Result: 在多个基准测试和任务中，EVTAR consistently显示出优越性能，验证了其方法的有效性。

Conclusion: EVTAR通过引入额外参考图像和简化的输入要求，提供了一种高效且实用的端到端虚拟试衣解决方案，显著提升了试衣效果的准确性和真实感。

Abstract: We propose EVTAR, an End-to-End Virtual Try-on model with Additional
Reference, that directly fits the target garment onto the person image while
incorporating reference images to enhance try-on accuracy. Most existing
virtual try-on approaches rely on complex inputs such as agnostic person
images, human pose, densepose, or body keypoints, making them labor-intensive
and impractical for real-world applications. In contrast, EVTAR adopts a
two-stage training strategy, enabling simple inference with only the source
image and the target garment inputs. Our model generates try-on results without
masks, densepose, or segmentation maps. Moreover, EVTAR leverages additional
reference images of different individuals wearing the same clothes to preserve
garment texture and fine-grained details better. This mechanism is analogous to
how humans consider reference models when choosing outfits, thereby simulating
a more realistic and high-quality dressing effect. We enrich the training data
with supplementary references and unpaired person images to support these
capabilities. We evaluate EVTAR on two widely used benchmarks and diverse
tasks, and the results consistently validate the effectiveness of our approach.

</details>


### [105] [A Unified Reasoning Framework for Holistic Zero-Shot Video Anomaly Analysis](https://arxiv.org/abs/2511.00962)
*Dongheng Lin,Mengxue Qu,Kunyang Han,Jianbo Jiao,Xiaojie Jin,Yunchao Wei*

Main category: cs.CV

TL;DR: 提出统一推理框架，通过任务链式设计实现零样本视频异常检测、定位和解释，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频异常研究多局限于帧级检测，缺乏空间和语义上下文，现有方法虽提升了可解释性但仍依赖数据和特定任务。

Method: 采用链式测试时推理过程，结合任务内和任务间推理，无需额外训练即可完成时间检测、空间定位和文本解释的联合分析。

Result: 在零样本条件下，该方法在多个视频异常检测、定位和解释基准上达到了最先进的性能。

Conclusion: 该论文提出了一个统一推理框架，通过任务链式设计在零样本条件下实现了视频异常检测、定位和解释的全面提升，证明了基础模型在视频异常分析中的潜力。

Abstract: Most video-anomaly research stops at frame-wise detection, offering little
insight into why an event is abnormal, typically outputting only frame-wise
anomaly scores without spatial or semantic context. Recent video anomaly
localization and video anomaly understanding methods improve explainability but
remain data-dependent and task-specific. We propose a unified reasoning
framework that bridges the gap between temporal detection, spatial
localization, and textual explanation. Our approach is built upon a chained
test-time reasoning process that sequentially connects these tasks, enabling
holistic zero-shot anomaly analysis without any additional training.
Specifically, our approach leverages intra-task reasoning to refine temporal
detections and inter-task chaining for spatial and semantic understanding,
yielding improved interpretability and generalization in a fully zero-shot
manner. Without any additional data or gradients, our method achieves
state-of-the-art zero-shot performance across multiple video anomaly detection,
localization, and explanation benchmarks. The results demonstrate that careful
prompt design with task-wise chaining can unlock the reasoning power of
foundation models, enabling practical, interpretable video anomaly analysis in
a fully zero-shot manner. Project Page:
https://rathgrith.github.io/Unified_Frame_VAA/.

</details>


### [106] [VesSAM: Efficient Multi-Prompting for Segmenting Complex Vessel](https://arxiv.org/abs/2511.00981)
*Suzhong Fu,Rui Sun,Xuan Ding,Jingqi Dong,Yiming Yang,Yao Zhu,Min Chang Jordan Ren,Delin Deng,Angelica Aviles-Rivero,Shuguang Cui,Zhen Li*

Main category: cs.CV

TL;DR: VesSAM是一个专为2D血管分割设计的框架，通过多提示编码和轻量解码优化性能，在多个数据集上大幅领先现有方法。


<details>
  <summary>Details</summary>
Motivation: 血管分割在临床应用中至关重要，但现有基础模型（如SAM）在血管结构上表现不佳，因此需要专门优化的解决方案。

Method: VesSAM整合了卷积适配器、多提示编码器和轻量级掩码解码器，并引入了自动化多提示标注生成流程。

Result: VesSAM在8个数据集上测试，Dice和IoU分别超过现有方法10%和13%，且参数量显著减少。

Conclusion: VesSAM框架在2D血管分割任务中表现出色，不仅在标准数据集上优于现有方法，还在分布外设置中展现了良好的泛化能力。

Abstract: Accurate vessel segmentation is critical for clinical applications such as
disease diagnosis and surgical planning, yet remains challenging due to thin,
branching structures and low texture contrast. While foundation models like the
Segment Anything Model (SAM) have shown promise in generic segmentation, they
perform sub-optimally on vascular structures. In this work, we present VesSAM,
a powerful and efficient framework tailored for 2D vessel segmentation. VesSAM
integrates (1) a convolutional adapter to enhance local texture features, (2) a
multi-prompt encoder that fuses anatomical prompts, including skeletons,
bifurcation points, and segment midpoints, via hierarchical cross-attention,
and (3) a lightweight mask decoder to reduce jagged artifacts. We also
introduce an automated pipeline to generate structured multi-prompt
annotations, and curate a diverse benchmark dataset spanning 8 datasets across
5 imaging modalities. Experimental results demonstrate that VesSAM consistently
outperforms state-of-the-art PEFT-based SAM variants by over 10% Dice and 13%
IoU, and achieves competitive performance compared to fully fine-tuned methods,
with significantly fewer parameters. VesSAM also generalizes well to
out-of-distribution (OoD) settings, outperforming all baselines in average OoD
Dice and IoU.

</details>


### [107] [MID: A Self-supervised Multimodal Iterative Denoising Framework](https://arxiv.org/abs/2511.00997)
*Chang Nie,Tianchen Deng,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: MID是一种自监督多模态迭代去噪框架，无需干净-噪声配对数据，通过迭代学习噪声特性，在多种任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据常被复杂非线性噪声污染，传统基于规则的去噪方法效果不佳。

Method: MID通过迭代引入噪声并学习两个神经网络（一个估计当前噪声步骤，另一个预测并减去相应的噪声增量），使用一阶泰勒展开局部线性化非线性噪声过程。

Result: 在四个经典计算机视觉任务中，MID展现了鲁棒性、适应性和顶尖性能，并在生物医学和生物信息学任务中表现优异。

Conclusion: MID框架在多种任务中展现了鲁棒性、适应性和顶尖性能，尤其在生物医学和生物信息学领域表现突出。

Abstract: Data denoising is a persistent challenge across scientific and engineering
domains. Real-world data is frequently corrupted by complex, non-linear noise,
rendering traditional rule-based denoising methods inadequate. To overcome
these obstacles, we propose a novel self-supervised multimodal iterative
denoising (MID) framework. MID models the collected noisy data as a state
within a continuous process of non-linear noise accumulation. By iteratively
introducing further noise, MID learns two neural networks: one to estimate the
current noise step and another to predict and subtract the corresponding noise
increment. For complex non-linear contamination, MID employs a first-order
Taylor expansion to locally linearize the noise process, enabling effective
iterative removal. Crucially, MID does not require paired clean-noisy datasets,
as it learns noise characteristics directly from the noisy inputs. Experiments
across four classic computer vision tasks demonstrate MID's robustness,
adaptability, and consistent state-of-the-art performance. Moreover, MID
exhibits strong performance and adaptability in tasks within the biomedical and
bioinformatics domains.

</details>


### [108] [Integrating Visual and X-Ray Machine Learning Features in the Study of Paintings by Goya](https://arxiv.org/abs/2511.01000)
*Hassan Ugail,Ismail Lujain Jaleel*

Main category: cs.CV

TL;DR: 多模态机器学习框架显著提升戈雅画作认证准确率。


<details>
  <summary>Details</summary>
Motivation: 解决弗朗西斯科·戈雅作品因风格多样性和伪造历史带来的复杂计算挑战。

Method: 采用统一的多模态机器学习框架，结合GLCM、LBP、熵度量、能量计算和颜色分布分析，通过优化的单类支持向量机进行分类。

Result: 在24幅认证戈雅画作数据集上，分类准确率达到97.8%，假阳性率为0.022；案例研究显示92.3%的认证置信度。

Conclusion: 该研究证明了在多模态（视觉和X射线图像）中应用相同计算方法在艺术品认证中的有效性，显著优于单模态方法。

Abstract: Art authentication of Francisco Goya's works presents complex computational
challenges due to his heterogeneous stylistic evolution and extensive
historical patterns of forgery. We introduce a novel multimodal machine
learning framework that applies identical feature extraction techniques to both
visual and X-ray radiographic images of Goya paintings. The unified feature
extraction pipeline incorporates Grey-Level Co-occurrence Matrix descriptors,
Local Binary Patterns, entropy measures, energy calculations, and colour
distribution analysis applied consistently across both imaging modalities. The
extracted features from both visual and X-ray images are processed through an
optimised One-Class Support Vector Machine with hyperparameter tuning. Using a
dataset of 24 authenticated Goya paintings with corresponding X-ray images,
split into an 80/20 train-test configuration with 10-fold cross-validation, the
framework achieves 97.8% classification accuracy with a 0.022 false positive
rate. Case study analysis of ``Un Gigante'' demonstrates the practical efficacy
of our pipeline, achieving 92.3% authentication confidence through unified
multimodal feature analysis. Our results indicate substantial performance
improvement over single-modal approaches, establishing the effectiveness of
applying identical computational methods to both visual and radiographic
imagery in art authentication applications.

</details>


### [109] [HyFormer-Net: A Synergistic CNN-Transformer with Interpretable Multi-Scale Fusion for Breast Lesion Segmentation and Classification in Ultrasound Images](https://arxiv.org/abs/2511.01013)
*Mohammad Amanour Rahman*

Main category: cs.CV

TL;DR: HyFormer-Net是一种混合CNN-Transformer模型，通过多尺度融合和注意力机制提升乳腺癌超声诊断的准确性和可解释性，在BUSI数据集上表现优异，并通过微调实现跨数据集泛化。


<details>
  <summary>Details</summary>
Motivation: 针对B型超声在乳腺癌诊断中的挑战（如斑点噪声、操作依赖性和边界模糊）以及现有深度学习的局限性（如单任务学习、架构约束和黑盒决策），提出一种兼具高精度和可解释性的解决方案。

Method: 提出HyFormer-Net，一种混合CNN-Transformer架构，结合EfficientNet-B3和Swin Transformer的双分支编码器，通过多尺度层次融合块和注意力门控解码器实现分割和分类。采用双管道可解释性方法：内在注意力验证和Grad-CAM分类推理。

Result: 在BUSI数据集上，HyFormer-Net的Dice评分为0.761 +/- 0.072，准确率为93.2%，优于其他模型。通过集成建模，Dice评分提升至90.2%，准确率达99.5%，恶性召回率100%。渐进微调实验显示，仅需10%目标域数据即可恢复92.5%性能。

Conclusion: HyFormer-Net通过混合CNN-Transformer架构，结合多尺度层次融合块和注意力门控解码器，显著提升了乳腺癌超声诊断的准确性和可解释性。其零样本迁移表现不佳，但通过渐进微调，仅需少量目标域数据即可实现性能恢复，展示了真正的泛化能力。

Abstract: B-mode ultrasound for breast cancer diagnosis faces challenges: speckle,
operator dependency, and indistinct boundaries. Existing deep learning suffers
from single-task learning, architectural constraints (CNNs lack global context,
Transformers local features), and black-box decision-making. These gaps hinder
clinical adoption.
  We propose HyFormer-Net, a hybrid CNN-Transformer for simultaneous
segmentation and classification with intrinsic interpretability. Its
dual-branch encoder integrates EfficientNet-B3 and Swin Transformer via
multi-scale hierarchical fusion blocks. An attention-gated decoder provides
precision and explainability. We introduce dual-pipeline interpretability: (1)
intrinsic attention validation with quantitative IoU verification (mean: 0.86),
and (2) Grad-CAM for classification reasoning.
  On the BUSI dataset, HyFormer-Net achieves Dice Score 0.761 +/- 0.072 and
accuracy 93.2%, outperforming U-Net, Attention U-Net, and TransUNet. Malignant
Recall of 92.1 +/- 2.2% ensures minimal false negatives. Ensemble modeling
yields exceptional Dice 90.2%, accuracy 99.5%, and perfect 100% Malignant
Recall, eliminating false negatives. Ablation studies confirm multi-scale
fusion contributes +16.8% Dice and attention gates add +5.9%.
  Crucially, we conduct the first cross-dataset generalization study for hybrid
CNN-Transformers in breast ultrasound. Zero-shot transfer fails (Dice: 0.058),
confirming domain shift. However, progressive fine-tuning with only 10%
target-domain data (68 images) recovers 92.5% performance. With 50% data, our
model achieves 77.3% Dice, exceeding source-domain performance (76.1%) and
demonstrating true generalization.

</details>


### [110] [FastBoost: Progressive Attention with Dynamic Scaling for Efficient Deep Learning](https://arxiv.org/abs/2511.01026)
*JunXi Yuan*

Main category: cs.CV

TL;DR: FastBoost通过DSPA机制和MBConv优化，在CIFAR基准上实现高效参数与高性能的平衡，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经网络在资源受限设备上参数效率与性能之间的权衡问题。

Method: 采用了动态缩放渐进注意力（DSPA）机制，包括自适应融合、阶段缩放和残差适应，并与增强的MBConv块集成。

Result: 在CIFAR-10和CIFAR-100上实现了高准确率（最高95.57%和81.37%），参数减少2.1倍，性能提升3.2个百分点。

Conclusion: FastBoost通过创新的DSPA机制和优化的MBConv块，在CIFAR基准测试上实现了参数效率和性能的最佳平衡，适用于资源受限的边缘设备。

Abstract: We present FastBoost, a parameter-efficient neural architecture that achieves
state-of-the-art performance on CIFAR benchmarks through a novel Dynamically
Scaled Progressive Attention (DSPA) mechanism. Our design establishes new
efficiency frontiers with: CIFAR-10: 95.57% accuracy (0.85M parameters) and
93.80% (0.37M parameters) CIFAR-100: 81.37% accuracy (0.92M parameters) and
74.85% (0.44M parameters) The breakthrough stems from three fundamental
innovations in DSPA: (1) Adaptive Fusion: Learnt channel-spatial attention
blending with dynamic weights. (2) Phase Scaling: Training-stage-aware
intensity modulation (from 0.5 to 1.0). (3) Residual Adaptation: Self-optimized
skip connections (gamma from 0.5 to 0.72). By integrating DSPA with enhanced
MBConv blocks, FastBoost achieves a 2.1 times parameter reduction over
MobileNetV3 while improving accuracy by +3.2 percentage points on CIFAR-10. The
architecture features dual attention pathways with real-time weight adjustment,
cascaded refinement layers (increasing gradient flow by 12.7%), and a
hardware-friendly design (0.28G FLOPs). This co-optimization of dynamic
attention and efficient convolution operations demonstrates unprecedented
parameter-accuracy trade-offs, enabling deployment in resource-constrained edge
devices without accuracy degradation.

</details>


### [111] [T-MLA: A Targeted Multiscale Log--Exponential Attack Framework for Neural Image Compression](https://arxiv.org/abs/2511.01079)
*Nikolay I. Kalmykov,Razan Dibo,Kaiyu Shen,Xu Zhonghan,Anh-Huy Phan,Yipeng Liu,Ivan Oseledets*

Main category: cs.CV

TL;DR: 该论文提出了T-MLA攻击框架，针对神经图像压缩（NIC）的安全漏洞，通过频域扰动显著降低重建质量，同时保持视觉隐蔽性。


<details>
  <summary>Details</summary>
Motivation: 现有对NIC的攻击方法多为像素空间方法的简单适配，忽视了压缩管道的结构化特性，因此需要更先进的攻击框架来揭示其潜在的安全漏洞。

Method: 通过引入针对性的多尺度对数-指数攻击框架（T-MLA），在频域中直接针对攻击和重建图像的质量，通过策略性地将扰动限制在特定的小波子带中，实现了对NIC系统的有效攻击。

Result: 在多个标准图像压缩基准测试中，T-MLA攻击导致重建质量显著下降，同时扰动在视觉上难以察觉，揭示了NIC在生成和内容传输管道中的关键安全缺陷。

Conclusion: 该研究揭示了神经图像压缩（NIC）在安全性上的核心漏洞，提出了T-MLA攻击框架，展示了其在多尺度对数-指数攻击中的有效性，使得重建图像质量大幅下降，同时扰动保持视觉不可察觉。

Abstract: Neural image compression (NIC) has become the state-of-the-art for
rate-distortion performance, yet its security vulnerabilities remain
significantly less understood than those of classifiers. Existing adversarial
attacks on NICs are often naive adaptations of pixel-space methods, overlooking
the unique, structured nature of the compression pipeline. In this work, we
propose a more advanced class of vulnerabilities by introducing T-MLA, the
first targeted multiscale log--exponential attack framework. Our approach
crafts adversarial perturbations in the wavelet domain by directly targeting
the quality of the attacked and reconstructed images. This allows for a
principled, offline attack where perturbations are strategically confined to
specific wavelet subbands, maximizing distortion while ensuring perceptual
stealth. Extensive evaluation across multiple state-of-the-art NIC
architectures on standard image compression benchmarks reveals a large drop in
reconstruction quality while the perturbations remain visually imperceptible.
Our findings reveal a critical security flaw at the core of generative and
content delivery pipelines.

</details>


### [112] [GeoToken: Hierarchical Geolocalization of Images via Next Token Prediction](https://arxiv.org/abs/2511.01082)
*Narges Ghasemi,Amir Ziashahabi,Salman Avestimehr,Cyrus Shahabi*

Main category: cs.CV

TL;DR: 论文提出一种分层序列预测模型，通过模拟人类定位思维和自回归技术，在图像地理定位任务中实现最先进性能，尤其在结合MLLM后表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决图像地理定位中因视觉相似性和大搜索空间带来的挑战，借鉴人类定位的层次化思维和大语言模型的自回归生成技术。

Method: 采用基于S2单元的分层序列预测方法，模拟人类从广泛区域逐步缩小到具体地址的定位过程，并结合自回归采样技术（如束搜索和多样本推理）优化推理策略。

Result: 在Im2GPS3k和YFCC4k数据集上，模型在无MLLM和结合MLLM的两种设置下均超越基线方法，最高准确率提升达13.9%。

Conclusion: 该论文提出的层次序列预测方法在图像地理定位任务中表现出色，尤其在结合多模态大语言模型（MLLM）后，实现了所有指标的最先进性能。

Abstract: Image geolocalization, the task of determining an image's geographic origin,
poses significant challenges, largely due to visual similarities across
disparate locations and the large search space. To address these issues, we
propose a hierarchical sequence prediction approach inspired by how humans
narrow down locations from broad regions to specific addresses. Analogously,
our model predicts geographic tokens hierarchically, first identifying a
general region and then sequentially refining predictions to increasingly
precise locations. Rather than relying on explicit semantic partitions, our
method uses S2 cells, a nested, multiresolution global grid, and sequentially
predicts finer-level cells conditioned on visual inputs and previous
predictions. This procedure mirrors autoregressive text generation in large
language models. Much like in language modeling, final performance depends not
only on training but also on inference-time strategy. We investigate multiple
top-down traversal methods for autoregressive sampling, incorporating
techniques from test-time compute scaling used in language models.
Specifically, we integrate beam search and multi-sample inference while
exploring various selection strategies to determine the final output. This
enables the model to manage uncertainty by exploring multiple plausible paths
through the hierarchy. We evaluate our method on the Im2GPS3k and YFCC4k
datasets against two distinct sets of baselines: those that operate without a
Multimodal Large Language Model (MLLM) and those that leverage one. In the
MLLM-free setting, our model surpasses other comparable baselines on nearly all
metrics, achieving state-of-the-art performance with accuracy gains of up to
13.9%. When augmented with an MLLM, our model outperforms all baselines,
setting a new state-of-the-art across all metrics. The source code is available
at https://github.com/NNargesNN/GeoToken.

</details>


### [113] [SliceVision-F2I: A Synthetic Feature-to-Image Dataset for Visual Pattern Representation on Network Slices](https://arxiv.org/abs/2511.01087)
*Md. Abid Hasan Rafi,Mst. Fatematuj Johora,Pankaj Bhowmik*

Main category: cs.CV

TL;DR: SliceVision-F2I是一个合成数据集，用于研究网络切片的特征可视化，支持多种机器学习任务。


<details>
  <summary>Details</summary>
Motivation: 5G和6G网络的兴起使得网络切片成为未来服务导向架构的关键部分，需要更精细的识别方法和强大的数据集支持。

Method: 采用四种编码方法（物理启发映射、Perlin噪声、神经壁纸化和分形分支）将多变量KPI向量转换为视觉表示，生成30,000个样本。

Result: 生成了一个包含原始KPI向量和对应RGB图像的数据集，模拟了真实且嘈杂的网络条件，适用于视觉学习、网络状态分类等任务。

Conclusion: SliceVision-F2I数据集为网络切片研究提供了丰富的合成样本，支持多种视觉学习任务，并在公开可用的基础上促进相关领域的研究。

Abstract: The emergence of 5G and 6G networks has established network slicing as a
significant part of future service-oriented architectures, demanding refined
identification methods supported by robust datasets. The article presents
SliceVision-F2I, a dataset of synthetic samples for studying feature
visualization in network slicing for next-generation networking systems. The
dataset transforms multivariate Key Performance Indicator (KPI) vectors into
visual representations through four distinct encoding methods: physically
inspired mappings, Perlin noise, neural wallpapering, and fractal branching.
For each encoding method, 30,000 samples are generated, each comprising a raw
KPI vector and a corresponding RGB image at low-resolution pixels. The dataset
simulates realistic and noisy network conditions to reflect operational
uncertainties and measurement imperfections. SliceVision-F2I is suitable for
tasks involving visual learning, network state classification, anomaly
detection, and benchmarking of image-based machine learning techniques applied
to network data. The dataset is publicly available and can be reused in various
research contexts, including multivariate time series analysis, synthetic data
generation, and feature-to-image transformations.

</details>


### [114] [Epanechnikov nonparametric kernel density estimation based feature-learning in respiratory disease chest X-ray images](https://arxiv.org/abs/2511.01098)
*Veronica Marsico,Antonio Quintero-Rincon,Hadj Batatia*

Main category: cs.CV

TL;DR: 提出一种结合EKDE和双峰逻辑回归的新方法用于呼吸疾病诊断，在X光片测试中表现中等，敏感性有待提升。


<details>
  <summary>Details</summary>
Motivation: 利用EKDE在建模数据分布时的灵活性和对像素强度变化的适应性，从医学图像中提取关键特征。

Method: 结合Epanechnikov的非参数核密度估计（EKDE）和双峰逻辑回归分类器，采用基于统计模型的学习方案。

Result: 在COVID-19放射学数据集的13808张随机选择的胸部X光片上测试，准确率为70.14%，敏感性为59.26%，特异性为74.18%。

Conclusion: 该研究展示了基于EKDE的方法在医学影像诊断中的潜力，虽然临床专业知识仍需用于进一步优化模型，但该方法有望提高诊断的准确性和可靠性。

Abstract: This study presents a novel method for diagnosing respiratory diseases using
image data. It combines Epanechnikov's non-parametric kernel density estimation
(EKDE) with a bimodal logistic regression classifier in a
statistical-model-based learning scheme. EKDE's flexibility in modeling data
distributions without assuming specific shapes and its adaptability to pixel
intensity variations make it valuable for extracting key features from medical
images. The method was tested on 13808 randomly selected chest X-rays from the
COVID-19 Radiography Dataset, achieved an accuracy of 70.14%, a sensitivity of
59.26%, and a specificity of 74.18%, demonstrating moderate performance in
detecting respiratory disease while showing room for improvement in
sensitivity. While clinical expertise remains essential for further refining
the model, this study highlights the potential of EKDE-based approaches to
enhance diagnostic accuracy and reliability in medical imaging.

</details>


### [115] [Anatomically Constrained Transformers for Echocardiogram Analysis](https://arxiv.org/abs/2511.01109)
*Alexander Thorley,Agis Chartsias,Jordan Strom,Jeremy Slivnick,Dipak Kotecha,Alberto Gomez,Jinming Duan*

Main category: cs.CV

TL;DR: ViACT是一种集成解剖学先验的视频transformer，通过专注于解剖区域的表示学习，提升了超声心动图分析的性能和解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频transformer在处理超声心动图时容易从非诊断区域（如背景）学习虚假相关性，限制了模型的性能。

Method: ViACT采用点集表示变形解剖结构，并将空间几何和图像补丁编码为transformer token，通过掩码自编码策略预训练，专注于解剖区域的表示学习。

Result: ViACT在左心室射血分数回归和心脏淀粉样变性检测等任务中表现出色，其注意力图与已知病理区域对齐，并能泛化到心肌点跟踪任务。

Conclusion: ViACT通过将解剖学先验直接整合到transformer架构中，有效减少了非诊断区域的影响，提高了模型的解释性和泛化能力。

Abstract: Video transformers have recently demonstrated strong potential for
echocardiogram (echo) analysis, leveraging self-supervised pre-training and
flexible adaptation across diverse tasks. However, like other models operating
on videos, they are prone to learning spurious correlations from non-diagnostic
regions such as image backgrounds. To overcome this limitation, we propose the
Video Anatomically Constrained Transformer (ViACT), a novel framework that
integrates anatomical priors directly into the transformer architecture. ViACT
represents a deforming anatomical structure as a point set and encodes both its
spatial geometry and corresponding image patches into transformer tokens.
During pre-training, ViACT follows a masked autoencoding strategy that masks
and reconstructs only anatomical patches, enforcing that representation
learning is focused on the anatomical region. The pre-trained model can then be
fine-tuned for tasks localized to this region. In this work we focus on the
myocardium, demonstrating the framework on echo analysis tasks such as left
ventricular ejection fraction (EF) regression and cardiac amyloidosis (CA)
detection. The anatomical constraint focuses transformer attention within the
myocardium, yielding interpretable attention maps aligned with regions of known
CA pathology. Moreover, ViACT generalizes to myocardium point tracking without
requiring task-specific components such as correlation volumes used in
specialized tracking networks.

</details>


### [116] [Weakly Supervised Concept Learning with Class-Level Priors for Interpretable Medical Diagnosis](https://arxiv.org/abs/2511.01131)
*Md Nahiduzzaman,Steven Korevaar,Alireza Bab-Hadiashar,Ruwan Tennakoon*

Main category: cs.CV

TL;DR: PCP是一种无需标注或语言模型的弱监督框架，显著提升医学图像概念预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像中可解释性预测的挑战，避免依赖昂贵且不实用的概念标注或语言模型。

Method: 提出了一种弱监督框架PCP，利用类级概念先验作为弱监督，并通过KL散度和熵正则化进行优化。

Result: 在PH2和WBCatt数据集上，PCP的概念级F1分数比零样本基线提高了33%以上，同时在四个医学数据集上表现出与完全监督模型相当的分类性能。

Conclusion: PCP框架通过弱监督和优化机制，显著提升了医学图像中概念预测的准确性和可靠性，同时保持了竞争力的分类性能。

Abstract: Human-interpretable predictions are essential for deploying AI in medical
imaging, yet most interpretable-by-design (IBD) frameworks require concept
annotations for training data, which are costly and impractical to obtain in
clinical contexts. Recent attempts to bypass annotation, such as zero-shot
vision-language models or concept-generation frameworks, struggle to capture
domain-specific medical features, leading to poor reliability. In this paper,
we propose a novel Prior-guided Concept Predictor (PCP), a weakly supervised
framework that enables concept answer prediction without explicit supervision
or reliance on language models. PCP leverages class-level concept priors as
weak supervision and incorporates a refinement mechanism with KL divergence and
entropy regularization to align predictions with clinical reasoning.
Experiments on PH2 (dermoscopy) and WBCatt (hematology) show that PCP improves
concept-level F1-score by over 33% compared to zero-shot baselines, while
delivering competitive classification performance on four medical datasets
(PH2, WBCatt, HAM10000, and CXR4) relative to fully supervised concept
bottleneck models (CBMs) and V-IP.

</details>


### [117] [Learning with Category-Equivariant Architectures for Human Activity Recognition](https://arxiv.org/abs/2511.01139)
*Yoshihiro Maruyama*

Main category: cs.CV

TL;DR: CatEquiv是一种编码对称性的神经网络，显著提升人类活动识别的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过系统编码数据的对称性（时间、幅度和结构）来提高人类活动识别的鲁棒性和泛化能力。

Method: 提出CatEquiv，一种用于惯性传感器人类活动识别的类别等变神经网络，通过引入类别对称积（循环时间偏移、正增益和传感器层次偏序集）来捕获数据的类别对称结构。

Result: 在UCI-HAR数据集上，CatEquiv在分布外扰动下表现出比循环填充CNN和普通CNN更高的鲁棒性。

Conclusion: CatEquiv通过系统编码时间、幅度和结构对称性，显著提高了在分布外扰动下的鲁棒性，证明了强制类别对称性可以在不增加模型容量的情况下实现强大的不变性和泛化能力。

Abstract: We propose CatEquiv, a category-equivariant neural network for Human Activity
Recognition (HAR) from inertial sensors that systematically encodes temporal,
amplitude, and structural symmetries. In particular, we introduce the
categorical symmetry product where cyclic time shifts, positive gains and the
sensor-hierarchy poset together capture the categorical symmetry structure of
the data. CatEquiv achieves equivariance with respect to the categorical
symmetry product. On UCI-HAR under out-of-distribution perturbations, CatEquiv
attains markedly higher robustness compared with circularly padded CNNs and
plain CNNs. These results demonstrate that enforcing categorical symmetries
yields strong invariance and generalization without additional model capacity.

</details>


### [118] [MicroAUNet: Boundary-Enhanced Multi-scale Fusion with Knowledge Distillation for Colonoscopy Polyp Image Segmentation](https://arxiv.org/abs/2511.01143)
*Ziyi Wang,Yuanmei Zhang,Dorna Esrafilzadeh,Ali R. Jalili,Suncheng Xiang*

Main category: cs.CV

TL;DR: MicroAUNet 是一种轻量级注意力网络，通过结合深度可分离扩张卷积和通道-空间注意力块，解决了现有息肉分割模型边界模糊和计算复杂度高的问题，适合实时临床应用。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习息肉分割模型要么边界模糊影响临床决策，要么计算复杂度高无法实时应用。

Method: 提出 MicroAUNet，结合深度可分离扩张卷积和单路径参数共享通道-空间注意力块，并采用渐进式两阶段知识蒸馏方案。

Result: 在基准测试中，MicroAUNet 在极低模型复杂度下实现了最先进的准确性。

Conclusion: MicroAUNet 是一种适用于实时临床息肉分割的轻量级网络，结合了深度可分离扩张卷积和单路径参数共享通道-空间注意力块，实现了在极低模型复杂度下的最先进准确性。

Abstract: Early and accurate segmentation of colorectal polyps is critical for reducing
colorectal cancer mortality, which has been extensively explored by academia
and industry. However, current deep learning-based polyp segmentation models
either compromise clinical decision-making by providing ambiguous polyp margins
in segmentation outputs or rely on heavy architectures with high computational
complexity, resulting in insufficient inference speeds for real-time colorectal
endoscopic applications. To address this problem, we propose MicroAUNet, a
light-weighted attention-based segmentation network that combines
depthwise-separable dilated convolutions with a single-path, parameter-shared
channel-spatial attention block to strengthen multi-scale boundary features. On
the basis of it, a progressive two-stage knowledge-distillation scheme is
introduced to transfer semantic and boundary cues from a high-capacity teacher.
Extensive experiments on benchmarks also demonstrate the state-of-the-art
accuracy under extremely low model complexity, indicating that MicroAUNet is
suitable for real-time clinical polyp segmentation. The code is publicly
available at https://github.com/JeremyXSC/MicroAUNet.

</details>


### [119] [ROVER: Benchmarking Reciprocal Cross-Modal Reasoning for Omnimodal Generation](https://arxiv.org/abs/2511.01163)
*Yongyuan Liang,Wei Chow,Feng Li,Ziqiao Ma,Xiyao Wang,Jiageng Mao,Jiuhai Chen,Jiatao Gu,Yue Wang,Furong Huang*

Main category: cs.CV

TL;DR: ROVER基准测试跨模态推理能力，发现交错模型表现更优，但模型在符号推理上仍有缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法将多模态能力孤立对待，无法测试跨模态推理能力，而这是统一多模态智能的核心。

Method: 引入ROVER基准，包含1312个任务和1876张图像，评估两种互补设置：视觉生成的言语增强推理和言语生成的视觉增强推理。

Result: 实验显示：(i) 跨模态推理决定视觉生成质量，交错模型显著优于非交错模型；(ii) 模型在物理和符号推理间存在分离，擅长感知概念但无法构建符号任务的视觉抽象。

Conclusion: 跨模态推理是实现真正多模态生成的关键前沿。

Abstract: Unified multimodal models (UMMs) have emerged as a powerful paradigm for
seamlessly unifying text and image understanding and generation. However,
prevailing evaluations treat these abilities in isolation, such that tasks with
multimodal inputs and outputs are scored primarily through unimodal reasoning,
i.e., textual benchmarks emphasize language-based reasoning, while visual
benchmarks emphasize reasoning outcomes manifested in the pixels. We introduce
ROVER to address this pressing need to test reciprocal cross-modal reasoning,
the use of one modality to guide, verify, or refine outputs in the other, an
ability central to the vision of unified multimodal intelligence. ROVER is a
human-annotated benchmark that explicitly targets reciprocal cross-modal
reasoning, which contains 1312 tasks grounded in 1876 images, spanning two
complementary settings. Verbally-augmented reasoning for visual generation
evaluates whether models can use verbal prompts and reasoning chains to guide
faithful image synthesis. Visually-augmented reasoning for verbal generation
evaluates whether models can generate intermediate visualizations that
strengthen their own reasoning processes for question answering. Experiments on
17 unified models reveal two key findings: (i) Cross-modal reasoning determines
visual generation quality, with interleaved models significantly outperforming
non-interleaved ones; notably, combining strong unimodal models fails to
achieve comparable reasoning. (ii) Models show dissociation between physical
and symbolic reasoning: they succeed at interpreting perceptual concepts
literally but fail to construct visual abstractions for symbolic tasks, where
faulty reasoning harms performance. These results highlight reciprocal
cross-modal reasoning as a critical frontier for enabling true omnimodal
generation.

</details>


### [120] [Web-Scale Collection of Video Data for 4D Animal Reconstruction](https://arxiv.org/abs/2511.01169)
*Brian Nlong Zhao,Jiajun Wu,Shangzhe Wu*

Main category: cs.CV

TL;DR: 研究提出自动化管道从YouTube视频中提取动物剪辑，建立大规模数据集和基准，推动无标记4D动物重建任务发展。


<details>
  <summary>Details</summary>
Motivation: 现有动物视频数据集规模有限且缺乏关键处理，限制了计算机视觉在野生动物研究中的应用潜力。

Method: 引入自动化管道从YouTube视频中挖掘并处理对象中心剪辑，包括辅助注释，用于姿态估计、跟踪和3D/4D重建等下游任务。

Result: 收集了30K视频（2M帧），远超现有数据集；建立了Animal-in-Motion基准（230个序列，11K帧），并评估了基于模型和无模型方法在4D重建任务中的表现。

Conclusion: 该研究通过自动化管道从YouTube视频中提取并处理动物中心剪辑，建立了Animal-in-Motion基准和4D重建基线，旨在推动无标记4D动物重建及相关任务的发展。

Abstract: Computer vision for animals holds great promise for wildlife research but
often depends on large-scale data, while existing collection methods rely on
controlled capture setups. Recent data-driven approaches show the potential of
single-view, non-invasive analysis, yet current animal video datasets are
limited--offering as few as 2.4K 15-frame clips and lacking key processing for
animal-centric 3D/4D tasks. We introduce an automated pipeline that mines
YouTube videos and processes them into object-centric clips, along with
auxiliary annotations valuable for downstream tasks like pose estimation,
tracking, and 3D/4D reconstruction. Using this pipeline, we amass 30K videos
(2M frames)--an order of magnitude more than prior works. To demonstrate its
utility, we focus on the 4D quadruped animal reconstruction task. To support
this task, we present Animal-in-Motion (AiM), a benchmark of 230 manually
filtered sequences with 11K frames showcasing clean, diverse animal motions. We
evaluate state-of-the-art model-based and model-free methods on
Animal-in-Motion, finding that 2D metrics favor the former despite unrealistic
3D shapes, while the latter yields more natural reconstructions but scores
lower--revealing a gap in current evaluation. To address this, we enhance a
recent model-free approach with sequence-level optimization, establishing the
first 4D animal reconstruction baseline. Together, our pipeline, benchmark, and
baseline aim to advance large-scale, markerless 4D animal reconstruction and
related tasks from in-the-wild videos. Code and datasets are available at
https://github.com/briannlongzhao/Animal-in-Motion.

</details>


### [121] [Diffusion Transformer meets Multi-level Wavelet Spectrum for Single Image Super-Resolution](https://arxiv.org/abs/2511.01175)
*Peng Du,Hui Li,Han Xu,Paul Barom Jeon,Dongwook Lee,Daehyun Ji,Ran Yang,Feng Zhu*

Main category: cs.CV

TL;DR: DTWSR结合扩散模型和Transformer，通过多级小波变换和双解码器处理多尺度频率子带，提升超分辨率图像的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于DWT的超分辨率方法大多忽视多尺度频率子带间的相互关系，导致重建图像不一致和不自然。

Method: 提出了一种基于图像小波谱的扩散Transformer模型（DTWSR），包括多级离散小波变换（MDWT）分解图像为小波谱，金字塔标记化方法将谱嵌入Transformer的标记序列，以及双解码器处理低频和高频子带的差异。

Result: 在多个基准数据集上的实验证明，DTWSR在感知质量和保真度上均表现出色。

Conclusion: DTWSR通过结合扩散模型和Transformer的优势，有效地捕捉多尺度频率子带间的相互关系，从而生成更一致和真实的超分辨率图像。

Abstract: Discrete Wavelet Transform (DWT) has been widely explored to enhance the
performance of image superresolution (SR). Despite some DWT-based methods
improving SR by capturing fine-grained frequency signals, most existing
approaches neglect the interrelations among multiscale frequency sub-bands,
resulting in inconsistencies and unnatural artifacts in the reconstructed
images. To address this challenge, we propose a Diffusion Transformer model
based on image Wavelet spectra for SR (DTWSR).DTWSR incorporates the
superiority of diffusion models and transformers to capture the interrelations
among multiscale frequency sub-bands, leading to a more consistence and
realistic SR image. Specifically, we use a Multi-level Discrete Wavelet
Transform (MDWT) to decompose images into wavelet spectra. A pyramid
tokenization method is proposed which embeds the spectra into a sequence of
tokens for transformer model, facilitating to capture features from both
spatial and frequency domain. A dual-decoder is designed elaborately to handle
the distinct variances in lowfrequency (LF) and high-frequency (HF) sub-bands,
without omitting their alignment in image generation. Extensive experiments on
multiple benchmark datasets demonstrate the effectiveness of our method, with
high performance on both perception quality and fidelity.

</details>


### [122] [A Topology-Aware Graph Convolutional Network for Human Pose Similarity and Action Quality Assessment](https://arxiv.org/abs/2511.01194)
*Minmin Zeng*

Main category: cs.CV

TL;DR: 提出GCN-PSN框架，利用骨骼拓扑结构提升动作质量评估性能，实验证明其在AQA-7和FineDiving基准测试中的优越性。


<details>
  <summary>Details</summary>
Motivation: 动作质量评估（AQA）需要精细理解人体动作和精确评估姿态相似性，现有基于坐标的方法存在局限性，因此需要一种更有效的方法。

Method: 提出了一种拓扑感知的图卷积网络（GCN）框架GCN-PSN，将人体骨骼建模为图以学习具有区分性的拓扑敏感姿态嵌入，采用Siamese架构和对比回归目标进行训练。

Result: GCN-PSN在AQA-7和FineDiving基准测试中优于基于坐标的基线方法，实验和消融研究验证了骨骼拓扑结构对姿态相似性和动作质量评估的有效性。

Conclusion: 该论文通过提出GCN-PSN框架，验证了利用骨骼拓扑结构进行动作质量评估的有效性，并在AQA-7和FineDiving基准测试中取得了竞争性性能。

Abstract: Action Quality Assessment (AQA) requires fine-grained understanding of human
motion and precise evaluation of pose similarity. This paper proposes a
topology-aware Graph Convolutional Network (GCN) framework, termed GCN-PSN,
which models the human skeleton as a graph to learn discriminative,
topology-sensitive pose embeddings. Using a Siamese architecture trained with a
contrastive regression objective, our method outperforms coordinate-based
baselines and achieves competitive performance on AQA-7 and FineDiving
benchmarks. Experimental results and ablation studies validate the
effectiveness of leveraging skeletal topology for pose similarity and action
quality assessment.

</details>


### [123] [MoSa: Motion Generation with Scalable Autoregressive Modeling](https://arxiv.org/abs/2511.01200)
*Mengyuan Liu,Sheng Yan,Yong Wang,Yingjie Li,Gui-Bin Bian,Hong Liu*

Main category: cs.CV

TL;DR: MoSa是一种新型分层运动生成框架，通过多尺度令牌保留和分层量化，高效生成高质量3D人体运动，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了提升文本驱动的3D人体运动生成的效率和质量，MoSa通过分层生成和创新的多尺度令牌保留策略，减少了推理步骤并提高了生成效果。

Method: MoSa采用了一种分层运动生成框架，结合了多尺度令牌保留策略（MTPS）和分层残差向量量化变分自编码器（RQ-VAE）。此外，还提出了CAQ-VAE，一种轻量级但表达能力强的卷积-注意力混合VQ-VAE，以解决频繁插值可能导致的退化问题。

Result: 在Motion-X数据集上，MoSa的FID为0.06（优于MoMask的0.20），推理时间减少了27%。

Conclusion: MoSa在文本驱动的3D人体运动生成任务中表现出色，不仅生成质量高、效率高，还能很好地泛化到下游任务（如运动编辑），无需额外微调。

Abstract: We introduce MoSa, a novel hierarchical motion generation framework for
text-driven 3D human motion generation that enhances the Vector
Quantization-guided Generative Transformers (VQ-GT) paradigm through a
coarse-to-fine scalable generation process. In MoSa, we propose a Multi-scale
Token Preservation Strategy (MTPS) integrated into a hierarchical residual
vector quantization variational autoencoder (RQ-VAE). MTPS employs
interpolation at each hierarchical quantization to effectively retain
coarse-to-fine multi-scale tokens. With this, the generative transformer
supports Scalable Autoregressive (SAR) modeling, which predicts scale tokens,
unlike traditional methods that predict only one token at each step.
Consequently, MoSa requires only 10 inference steps, matching the number of
RQ-VAE quantization layers. To address potential reconstruction degradation
from frequent interpolation, we propose CAQ-VAE, a lightweight yet expressive
convolution-attention hybrid VQ-VAE. CAQ-VAE enhances residual block design and
incorporates attention mechanisms to better capture global dependencies.
Extensive experiments show that MoSa achieves state-of-the-art generation
quality and efficiency, outperforming prior methods in both fidelity and speed.
On the Motion-X dataset, MoSa achieves an FID of 0.06 (versus MoMask's 0.20)
while reducing inference time by 27 percent. Moreover, MoSa generalizes well to
downstream tasks such as motion editing, requiring no additional fine-tuning.
The code is available at https://mosa-web.github.io/MoSa-web

</details>


### [124] [OmniVLA: Unifiying Multi-Sensor Perception for Physically-Grounded Multimodal VLA](https://arxiv.org/abs/2511.01210)
*Heyu Guo,Shanmu Wang,Ruichun Ma,Shiqi Jiang,Yasaman Ghasempour,Omid Abari,Baining Guo,Lili Qi*

Main category: cs.CV

TL;DR: OmniVLA是一个多模态VLA模型，通过整合多种传感器数据显著提升了操作任务的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型仅依赖RGB摄像头，限制了其感知和操作能力。OmniVLA旨在通过整合多模态传感提升物理空间智能。

Method: 提出了一种传感器掩码图像的统一表示方法，整合了红外摄像头、毫米波雷达和麦克风阵列等传感器的数据，并基于RGB预训练的VLA骨干网络构建了一个多感官VLA模型架构。

Result: OmniVLA在需要传感器模态感知的任务中实现了84%的平均成功率，显著优于RGB-only和原始传感器输入基线模型59%和28%。

Conclusion: OmniVLA通过整合多模态感知显著提升了视觉-语言-动作模型的性能和泛化能力，证明了其在复杂现实任务中的有效性。

Abstract: Vision-language-action (VLA) models have shown strong generalization for
action prediction through large-scale vision-language pretraining. However,
most existing models rely solely on RGB cameras, limiting their perception and,
consequently, manipulation capabilities. We present OmniVLA, an omni-modality
VLA model that integrates novel sensing modalities for physically-grounded
spatial intelligence beyond RGB perception. The core of our approach is the
sensor-masked image, a unified representation that overlays spatially grounded
and physically meaningful masks onto the RGB images, derived from sensors
including an infrared camera, a mmWave radar, and a microphone array. This
image-native unification keeps sensor input close to RGB statistics to
facilitate training, provides a uniform interface across sensor hardware, and
enables data-efficient learning with lightweight per-sensor projectors. Built
on this, we present a multisensory vision-language-action model architecture
and train the model based on an RGB-pretrained VLA backbone. We evaluate
OmniVLA on challenging real-world tasks where sensor-modality perception is
needed to guide the manipulation. OmniVLA achieves an average task success rate
of 84%, significantly outperforms both RGB-only and raw-sensor-input baseline
models by 59% and 28% respectively, meanwhile showing higher learning
efficiency and stronger generalization capability.

</details>


### [125] [Thought-For-Food: Reasoning Chain Induced Food Visual Question Answering](https://arxiv.org/abs/2511.01213)
*Riddhi Jain,Manasi Patwardhan,Parijat Deshpande,Venkataramana Runkana*

Main category: cs.CV

TL;DR: 针对印度食品的复杂文化背景，研究提出多步推理链方法，增强VQA系统准确性，实验显示平均提升10%。


<details>
  <summary>Details</summary>
Motivation: 现有VQA系统偏向西方食品，无法应对印度食品的复杂烹饪背景和多样文化需求。

Method: 采用多步推理过程，构建自动验证的推理链，并利用强化学习训练小型LLMs和VLMs。

Result: 推理链的加入使印度食品VQA任务的准确性平均提高了10个百分点。

Conclusion: 通过自动验证的推理链增强小型LLMs和VLMs，并结合强化学习训练，显著提升了印度食品VQA任务的准确性，平均提高了10个百分点。

Abstract: The immense diversity in the culture and culinary of Indian cuisines calls
attention to the major shortcoming of the existing Visual Question
Answering(VQA) systems which are inclined towards the foods from Western
region. Recent attempt towards building a VQA dataset for Indian food is a step
towards addressing this challenge. However, their approach towards VQA follows
a two-step process in which the answer is generated first, followed by the
explanation of the expected answer. In this work, we claim that food VQA
requires to follow a multi-step reasoning process to arrive at an accurate
answer, especially in the context of India food, which involves understanding
complex culinary context and identifying relationships between various food
items. With this hypothesis we create reasoning chains upon the QA with minimal
human intervention. We fine-tune smaller LLMs and VLMs with auto-validated
reasoning chains and further train them using reinforcement learning with
larger data. With augmentation of reasoning chains, we observed accuracy
improvement of an average 10 percentage points on the baseline. We provide
detailed analysis in terms the effect of addition of reasoning chains for the
Indian Food VQA task.
  Index Terms - FoodVQA, Reasoning Chains, Reinforcement Learning, Knowledge
Graph.

</details>


### [126] [Eyes on Target: Gaze-Aware Object Detection in Egocentric Video](https://arxiv.org/abs/2511.01237)
*Vishakha Lall,Yisi Liu*

Main category: cs.CV

TL;DR: Eyes on Target通过凝视引导的ViT注意力机制提升自我为中心视频的目标检测性能，实验验证了其在模拟和公共数据集上的优势。


<details>
  <summary>Details</summary>
Motivation: 人类凝视在复杂视觉环境中提供了丰富的监督信号，可用于理解视觉注意力。目标是利用凝视信号提升自我为中心视频中的目标检测性能。

Method: 提出了Eyes on Target框架，结合深度感知和凝视引导，通过将凝视特征注入Vision Transformer的注意力机制来偏向人类关注区域。

Result: 在模拟数据集和公共基准（如Ego4D Ego-Motion和Ego-CH-Gaze）上，该方法相比无视凝视的基线模型表现出持续的检测准确率提升。

Conclusion: Eyes on Target框架通过将人类凝视特征注入Vision Transformer的注意力机制，显著提升了以自我为中心视频中的目标检测准确率。实验验证了该方法在模拟场景和公共数据集上的优势，并引入了一种新的凝视感知注意力头重要性度量来解释模型行为。

Abstract: Human gaze offers rich supervisory signals for understanding visual attention
in complex visual environments. In this paper, we propose Eyes on Target, a
novel depth-aware and gaze-guided object detection framework designed for
egocentric videos. Our approach injects gaze-derived features into the
attention mechanism of a Vision Transformer (ViT), effectively biasing spatial
feature selection toward human-attended regions. Unlike traditional object
detectors that treat all regions equally, our method emphasises
viewer-prioritised areas to enhance object detection. We validate our method on
an egocentric simulator dataset where human visual attention is critical for
task assessment, illustrating its potential in evaluating human performance in
simulation scenarios. We evaluate the effectiveness of our gaze-integrated
model through extensive experiments and ablation studies, demonstrating
consistent gains in detection accuracy over gaze-agnostic baselines on both the
custom simulator dataset and public benchmarks, including Ego4D Ego-Motion and
Ego-CH-Gaze datasets. To interpret model behaviour, we also introduce a
gaze-aware attention head importance metric, revealing how gaze cues modulate
transformer attention dynamics.

</details>


### [127] [Beyond Deceptive Flatness: Dual-Order Solution for Strengthening Adversarial Transferability](https://arxiv.org/abs/2511.01240)
*Zhixuan Zhang,Pingyu Wang,Xingjian Zheng,Linbo Qing,Qi Liu*

Main category: cs.CV

TL;DR: 本文提出AFA和MCAS方法，通过双阶信息视角解决对抗样本迁移中的欺骗性平坦问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对抗攻击方法在平坦损失函数下仍易陷入次优区域（如欺骗性平坦），限制了对抗样本的迁移能力。

Method: 通过引入Adversarial Flatness (AF) 理论框架，并结合双阶信息视角，设计了AFA攻击方法，并采用MCAS提升采样效率。

Result: 在ImageNet兼容数据集上，AFA和MCAS方法在平坦区域生成的对抗样本优于六种基线方法，且在输入变换攻击和Baidu Cloud API测试中表现更优。

Conclusion: 本文提出的Adversarial Flatness Attack (AFA) 和 MonteCarlo Adversarial Sampling (MCAS) 方法在对抗样本生成中解决了欺骗性平坦问题，显著提升了跨模型架构的对抗迁移能力，并在实际测试中优于现有基线方法。

Abstract: Transferable attacks generate adversarial examples on surrogate models to
fool unknown victim models, posing real-world threats and growing research
interest. Despite focusing on flat losses for transferable adversarial
examples, recent studies still fall into suboptimal regions, especially the
flat-yet-sharp areas, termed as deceptive flatness. In this paper, we introduce
a novel black-box gradient-based transferable attack from a perspective of
dual-order information. Specifically, we feasibly propose Adversarial Flatness
(AF) to the deceptive flatness problem and a theoretical assurance for
adversarial transferability. Based on this, using an efficient approximation of
our objective, we instantiate our attack as Adversarial Flatness Attack (AFA),
addressing the altered gradient sign issue. Additionally, to further improve
the attack ability, we devise MonteCarlo Adversarial Sampling (MCAS) by
enhancing the inner-loop sampling efficiency. The comprehensive results on
ImageNet-compatible dataset demonstrate superiority over six baselines,
generating adversarial examples in flatter regions and boosting transferability
across model architectures. When tested on input transformation attacks or the
Baidu Cloud API, our method outperforms baselines.

</details>


### [128] [Adaptation of Foundation Models for Medical Image Analysis: Strategies, Challenges, and Future Directions](https://arxiv.org/abs/2511.01284)
*Karma Phuntsho,Abdullah,Kyungmi Lee,Ickjai Lee,Euijoon Ahn*

Main category: cs.CV

TL;DR: 综述探讨了FM在医学影像中的适应策略，评估了现有方法的优劣，并提出了未来发展方向，旨在促进FM在临床实践中的应用。


<details>
  <summary>Details</summary>
Motivation: 基础模型（FM）在医学影像分析中具有潜力，但其适应真实临床实践仍面临挑战，如领域偏移、高质量标注数据有限、计算需求大和隐私要求严格。

Method: 综述评估了多种FM适应策略，包括监督微调、领域特定预训练、参数高效微调、自监督学习、混合方法以及多模态或跨模态框架。

Result: 综述评估了各种策略的性能增益、临床适用性和局限性，并指出了现有技术中未解决的挑战。同时强调了新兴方向，如持续学习、联邦学习、混合自监督学习、数据中心化流程和系统基准测试。

Conclusion: 这篇综述为开发适应性强、可信赖且临床集成的FM提供了路线图，以满足真实世界医学影像的需求。

Abstract: Foundation models (FMs) have emerged as a transformative paradigm in medical
image analysis, offering the potential to provide generalizable, task-agnostic
solutions across a wide range of clinical tasks and imaging modalities. Their
capacity to learn transferable representations from large-scale data has the
potential to address the limitations of conventional task-specific models.
However, adaptation of FMs to real-world clinical practice remains constrained
by key challenges, including domain shifts, limited availability of
high-quality annotated data, substantial computational demands, and strict
privacy requirements. This review presents a comprehensive assessment of
strategies for adapting FMs to the specific demands of medical imaging. We
examine approaches such as supervised fine-tuning, domain-specific pretraining,
parameter-efficient fine-tuning, self-supervised learning, hybrid methods, and
multimodal or cross-modal frameworks. For each, we evaluate reported
performance gains, clinical applicability, and limitations, while identifying
trade-offs and unresolved challenges that prior reviews have often overlooked.
Beyond these established techniques, we also highlight emerging directions
aimed at addressing current gaps. These include continual learning to enable
dynamic deployment, federated and privacy-preserving approaches to safeguard
sensitive data, hybrid self-supervised learning to enhance data efficiency,
data-centric pipelines that combine synthetic generation with human-in-the-loop
validation, and systematic benchmarking to assess robust generalization under
real-world clinical variability. By outlining these strategies and associated
research gaps, this review provides a roadmap for developing adaptive,
trustworthy, and clinically integrated FMs capable of meeting the demands of
real-world medical imaging.

</details>


### [129] [CenterMamba-SAM: Center-Prioritized Scanning and Temporal Prototypes for Brain Lesion Segmentation](https://arxiv.org/abs/2511.01243)
*Yu Tian,Zhongheng Yang,Chenshi Liu,Yiyun Su,Ziwei Hong,Zexi Gong,Jingyuan Xu*

Main category: cs.CV

TL;DR: CenterMamba-SAM 是一种高效的脑部病变分割框架，通过创新的扫描策略和记忆增强设计，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决脑部病变分割中的小病灶、低对比度、各向异性采样和跨切片不连续性等挑战。

Method: 提出了 CenterMamba-SAM 框架，采用 3x3 角-轴-中心短序列扫描策略，结合记忆驱动的结构提示生成器和记忆增强的多尺度解码器。

Result: 在公共基准测试中表现出色，达到最新技术水平。

Conclusion: CenterMamba-SAM 在脑部病变分割任务中实现了最先进的性能，证明了其设计的高效性和有效性。

Abstract: Brain lesion segmentation remains challenging due to small, low-contrast
lesions, anisotropic sampling, and cross-slice discontinuities. We propose
CenterMamba-SAM, an end-to-end framework that freezes a pretrained backbone and
trains only lightweight adapters for efficient fine-tuning. At its core is the
CenterMamba encoder, which employs a novel 3x3 corner-axis-center
short-sequence scanning strategy to enable center-prioritized, axis-reinforced,
and diagonally compensated information aggregation. This design enhances
sensitivity to weak boundaries and tiny foci while maintaining sparse yet
effective feature representation. A memory-driven structural prompt generator
maintains a prototype bank across neighboring slices, enabling automatic
synthesis of reliable prompts without user interaction, thereby improving
inter-slice coherence. The memory-augmented multi-scale decoder integrates
memory attention modules at multiple levels, combining deep supervision with
progressive refinement to restore fine details while preserving global
consistency. Extensive experiments on public benchmarks demonstrate that
CenterMamba-SAM achieves state-of-the-art performance in brain lesion
segmentation.

</details>


### [130] [Perturb a Model, Not an Image: Towards Robust Privacy Protection via Anti-Personalized Diffusion Models](https://arxiv.org/abs/2511.01307)
*Tae-Young Lee,Juwon Seo,Jong Hwan Ko,Gyeong-Moon Park*

Main category: cs.CV

TL;DR: APDM通过DPO和L2P有效阻止扩散模型的个性化滥用，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有对抗扰动方法在少量干净图像或简单变换下失效，需从扩散模型本身入手，防止特定主题的个性化滥用。

Method: 提出Direct Protective Optimization (DPO)损失函数和Learning to Protect (L2P)双路径优化策略，通过交替进行个性化和保护路径来强化保护效果。

Result: 实验表明APDM在防止未经授权个性化方面达到最先进性能，代码已开源。

Conclusion: APDM框架通过DPO损失函数和L2P优化策略，有效阻止了未经授权的个性化生成，且在保持生成质量的同时，性能优于现有方法。

Abstract: Recent advances in diffusion models have enabled high-quality synthesis of
specific subjects, such as identities or objects. This capability, while
unlocking new possibilities in content creation, also introduces significant
privacy risks, as personalization techniques can be misused by malicious users
to generate unauthorized content. Although several studies have attempted to
counter this by generating adversarially perturbed samples designed to disrupt
personalization, they rely on unrealistic assumptions and become ineffective in
the presence of even a few clean images or under simple image transformations.
To address these challenges, we shift the protection target from the images to
the diffusion model itself to hinder the personalization of specific subjects,
through our novel framework called Anti-Personalized Diffusion Models (APDM).
We first provide a theoretical analysis demonstrating that a naive approach of
existing loss functions to diffusion models is inherently incapable of ensuring
convergence for robust anti-personalization. Motivated by this finding, we
introduce Direct Protective Optimization (DPO), a novel loss function that
effectively disrupts subject personalization in the target model without
compromising generative quality. Moreover, we propose a new dual-path
optimization strategy, coined Learning to Protect (L2P). By alternating between
personalization and protection paths, L2P simulates future personalization
trajectories and adaptively reinforces protection at each step. Experimental
results demonstrate that our framework outperforms existing methods, achieving
state-of-the-art performance in preventing unauthorized personalization. The
code is available at https://github.com/KU-VGI/APDM.

</details>


### [131] [Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop](https://arxiv.org/abs/2511.01250)
*YoungJae Cheong,Jhonghyun An*

Main category: cs.CV

TL;DR: 提出几何感知适配器，通过结构正则化提升恶劣天气下LiDAR分割的鲁棒性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LiDAR语义分割在恶劣天气下性能下降，现有方法忽略了结构脆弱区域（如边界、角落和稀疏区域）的鲁棒性。

Method: 提出了一个轻量级几何感知适配器，通过方位对齐和水平圆形填充来保留邻居连续性，并利用局部窗口K近邻计算简单局部统计量，压缩成紧凑的几何感知线索。

Result: 适配器在无需目标标签或微调的情况下，将mIoU提高了7.9个百分点（相对于数据中心增强基线）和0.6个百分点（相对于类中心正则化基线）。

Conclusion: 几何驱动的正则化是全天候LiDAR语义分割的关键方向。

Abstract: LiDAR semantic segmentation degrades in adverse weather because refraction,
scattering, and point dropouts corrupt geometry. Prior work in weather
simulation, mixing-based augmentation, domain randomization, and uncertainty or
boundary regularization improves robustness but still overlooks structural
vulnerabilities near boundaries, corners, and sparse regions. We present a
Light Geometry-aware adapter. The module aligns azimuth and applies horizontal
circular padding to preserve neighbor continuity across the 0~360 degree
wrap-around boundary. A local-window K-Nearest Neighbors gathers nearby points
and computes simple local statistics, which are compressed into compact
geometry-aware cues. During training, these cues drive region-aware
regularization that stabilizes predictions in structurally fragile areas. The
adapter is plug and play, complements augmentation, and can be enabled only
during training with negligible inference cost. We adopt a source-only
cross-weather setup where models train on SemanticKITTI and are evaluated on
SemanticSTF without target labels or fine-tuning. The adapter improves mIoU by
7.9 percentage points over the data-centric augmentation baseline and by 0.6
points over the class-centric regularization baseline. These results indicate
that geometry-driven regularization is a key direction for all-weather LiDAR
segmentation.

</details>


### [132] [MotionStream: Real-Time Video Generation with Interactive Motion Controls](https://arxiv.org/abs/2511.01266)
*Joonghyuk Shin,Zhengqi Li,Richard Zhang,Jun-Yan Zhu,Jaesik Park,Eli Schechtman,Xun Huang*

Main category: cs.CV

TL;DR: MotionStream通过蒸馏技术和滑动窗口因果注意力，实现了实时、高质量、无限长度的视频生成，比现有方法快100倍。


<details>
  <summary>Details</summary>
Motivation: 解决现有运动条件视频生成方法的高延迟和非因果处理问题，实现实时交互。

Method: 通过将双向教师模型蒸馏为因果学生模型，采用自强迫与分布匹配蒸馏技术，结合滑动窗口因果注意力和注意力的设计，实现了实时流式推理。

Result: MotionStream在单GPU上实现了高达29 FPS的流式生成，比现有方法快两个数量级，并在运动跟随和视频质量上达到了最先进水平。

Conclusion: MotionStream实现了实时交互的视频生成，支持无限长度流式生成，同时保持高质量和快速推理，为用户提供了真正的交互体验。

Abstract: Current motion-conditioned video generation methods suffer from prohibitive
latency (minutes per video) and non-causal processing that prevents real-time
interaction. We present MotionStream, enabling sub-second latency with up to 29
FPS streaming generation on a single GPU. Our approach begins by augmenting a
text-to-video model with motion control, which generates high-quality videos
that adhere to the global text prompt and local motion guidance, but does not
perform inference on the fly. As such, we distill this bidirectional teacher
into a causal student through Self Forcing with Distribution Matching
Distillation, enabling real-time streaming inference. Several key challenges
arise when generating videos of long, potentially infinite time-horizons: (1)
bridging the domain gap from training on finite length and extrapolating to
infinite horizons, (2) sustaining high quality by preventing error
accumulation, and (3) maintaining fast inference, without incurring growth in
computational cost due to increasing context windows. A key to our approach is
introducing carefully designed sliding-window causal attention, combined with
attention sinks. By incorporating self-rollout with attention sinks and KV
cache rolling during training, we properly simulate inference-time
extrapolations with a fixed context window, enabling constant-speed generation
of arbitrarily long videos. Our models achieve state-of-the-art results in
motion following and video quality while being two orders of magnitude faster,
uniquely enabling infinite-length streaming. With MotionStream, users can paint
trajectories, control cameras, or transfer motion, and see results unfold in
real-time, delivering a truly interactive experience.

</details>


### [133] [PRevivor: Reviving Ancient Chinese Paintings using Prior-Guided Color Transformers](https://arxiv.org/abs/2511.01274)
*Tan Tang,Yanhong Wu,Junming Gao,Yingcai Wu*

Main category: cs.CV

TL;DR: PRevivor是一种先验指导的色彩转换器，通过亮度增强和色调校正两阶段任务，有效恢复古画色彩，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 古画因复杂的化学机制导致不可逆的色彩退化，且缺乏高质量数据集阻碍了端到端数字修复工具的创建，亟需有效解决方案。

Method: 提出了PRevivor，一种基于先验指导的色彩转换器，通过分解任务为亮度增强和色调校正两个子任务，分别采用变分U-Net和多尺度映射模块以及双分支色彩查询模块实现。

Result: 实验表明，PRevivor在定量和定性评估上均优于现有色彩化方法。

Conclusion: PRevivor通过结合局部和全局色彩校正策略，成功恢复了古画的色彩，展现出在文化遗产保护中的潜在应用价值。

Abstract: Ancient Chinese paintings are a valuable cultural heritage that is damaged by
irreversible color degradation. Reviving color-degraded paintings is
extraordinarily difficult due to the complex chemistry mechanism. Progress is
further slowed by the lack of comprehensive, high-quality datasets, which
hampers the creation of end-to-end digital restoration tools. To revive colors,
we propose PRevivor, a prior-guided color transformer that learns from recent
paintings (e.g., Ming and Qing Dynasty) to restore ancient ones (e.g., Tang and
Song Dynasty). To develop PRevivor, we decompose color restoration into two
sequential sub-tasks: luminance enhancement and hue correction. For luminance
enhancement, we employ two variational U-Nets and a multi-scale mapping module
to translate faded luminance into restored counterparts. For hue correction, we
design a dual-branch color query module guided by localized hue priors
extracted from faded paintings. Specifically, one branch focuses attention on
regions guided by masked priors, enforcing localized hue correction, whereas
the other branch remains unconstrained to maintain a global reasoning
capability. To evaluate PRevivor, we conduct extensive experiments against
state-of-the-art colorization methods. The results demonstrate superior
performance both quantitatively and qualitatively.

</details>


### [134] [Detecting Generated Images by Fitting Natural Image Distributions](https://arxiv.org/abs/2511.01293)
*Yonggang Zhang,Jun Nie,Xinmei Tian,Mingming Gong,Kun Zhang,Bo Han*

Main category: cs.CV

TL;DR: 提出利用数据流形差异检测生成图像的新框架，通过自监督模型损失变化识别，并用归一化流增强差异，实验有效。


<details>
  <summary>Details</summary>
Motivation: 生成图像的真实性提升引发滥用担忧，现有方法依赖大量高质量生成图像训练二元分类器，存在局限性。

Method: 提出了一种框架，利用自然图像和生成图像数据流形的几何差异，通过设计一对函数使自然图像输出一致而生成图像输出分歧，并利用预训练自监督模型的损失变化进行检测。进一步使用归一化流放大可检测差异。

Result: 实验证明该方法有效，代码已开源。

Conclusion: 本文提出了一种利用自然图像和生成图像数据流形几何差异的新颖检测框架，通过预训练自监督模型的损失变化识别生成图像，并在先进生成模型中通过归一化流增强可检测差异，实验证明了方法的有效性。

Abstract: The increasing realism of generated images has raised significant concerns
about their potential misuse, necessitating robust detection methods. Current
approaches mainly rely on training binary classifiers, which depend heavily on
the quantity and quality of available generated images. In this work, we
propose a novel framework that exploits geometric differences between the data
manifolds of natural and generated images. To exploit this difference, we
employ a pair of functions engineered to yield consistent outputs for natural
images but divergent outputs for generated ones, leveraging the property that
their gradients reside in mutually orthogonal subspaces. This design enables a
simple yet effective detection method: an image is identified as generated if a
transformation along its data manifold induces a significant change in the loss
value of a self-supervised model pre-trained on natural images. Further more,
to address diminishing manifold disparities in advanced generative models, we
leverage normalizing flows to amplify detectable differences by extruding
generated images away from the natural image manifold. Extensive experiments
demonstrate the efficacy of this method. Code is available at
https://github.com/tmlr-group/ConV.

</details>


### [135] [CMI-MTL: Cross-Mamba interaction based multi-task learning for medical visual question answering](https://arxiv.org/abs/2511.01357)
*Qiangguo Jin,Xianyao Zheng,Hui Cui,Changming Sun,Yuqi Fang,Cong Cong,Ran Su,Leyi Wei,Ping Xuan,Junbo Wang*

Main category: cs.CV

TL;DR: 提出CMI-MTL框架，通过多模块设计解决Med-VQA中的跨模态对齐和自由形式答案问题，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有自注意力方法在跨模态语义对齐上的不足，以及分类方法对预定义答案集的依赖问题。

Method: 采用细粒度视觉-文本特征对齐（FVTA）、跨模态交错特征表示（CIFR）和自由形式答案增强的多任务学习（FFAE）模块。

Result: 在VQA-RAD、SLAKE和OVQA三个数据集上表现优于现有方法。

Conclusion: CMI-MTL框架通过FVTA、CIFR和FFAE三个模块，显著提升了Med-VQA任务的性能，并在三个数据集上超越了现有方法。

Abstract: Medical visual question answering (Med-VQA) is a crucial multimodal task in
clinical decision support and telemedicine. Recent self-attention based methods
struggle to effectively handle cross-modal semantic alignments between vision
and language. Moreover, classification-based methods rely on predefined answer
sets. Treating this task as a simple classification problem may make it unable
to adapt to the diversity of free-form answers and overlook the detailed
semantic information of free-form answers. In order to tackle these challenges,
we introduce a Cross-Mamba Interaction based Multi-Task Learning (CMI-MTL)
framework that learns cross-modal feature representations from images and
texts. CMI-MTL comprises three key modules: fine-grained visual-text feature
alignment (FVTA), cross-modal interleaved feature representation (CIFR), and
free-form answer-enhanced multi-task learning (FFAE). FVTA extracts the most
relevant regions in image-text pairs through fine-grained visual-text feature
alignment. CIFR captures cross-modal sequential interactions via cross-modal
interleaved feature representation. FFAE leverages auxiliary knowledge from
open-ended questions through free-form answer-enhanced multi-task learning,
improving the model's capability for open-ended Med-VQA. Experimental results
show that CMI-MTL outperforms the existing state-of-the-art methods on three
Med-VQA datasets: VQA-RAD, SLAKE, and OVQA. Furthermore, we conduct more
interpretability experiments to prove the effectiveness. The code is publicly
available at https://github.com/BioMedIA-repo/CMI-MTL.

</details>


### [136] [UniREditBench: A Unified Reasoning-based Image Editing Benchmark](https://arxiv.org/abs/2511.01295)
*Feng Han,Yibin Wang,Chenglin Li,Zheming Liang,Dianyi Wang,Yang Jiao,Zhipeng Wei,Chao Gong,Cheng Jin,Jingjing Chen,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出UniREditBench基准测试和UniREdit-Bagel模型，改进复杂推理式图像编辑任务评估，覆盖多场景并引入多模态评估。


<details>
  <summary>Details</summary>
Motivation: 当前生成模型在需要隐式推理的复杂图像编辑任务中表现不足，且现有基准测试忽视多对象交互和游戏世界场景，仅依赖文本参考评估。

Method: 提出了UniREditBench基准测试，包含2,700个样本，覆盖8个主要维度和18个子维度，并引入多模态双参考评估方法。同时，构建了UniREdit-Data-100K数据集，用于微调Bagel模型。

Result: 通过基准测试，揭示了开源和闭源图像编辑模型在不同场景中的优缺点，并展示了UniREdit-Bagel的显著改进。

Conclusion: UniREditBench和UniREdit-Bagel在推理式图像编辑任务中表现出显著改进，特别是在多对象交互和游戏世界场景中。

Abstract: Recent advances in multi-modal generative models have driven substantial
improvements in image editing. However, current generative models still
struggle with handling diverse and complex image editing tasks that require
implicit reasoning, underscoring the need for a comprehensive benchmark to
systematically assess their performance across various reasoning scenarios.
Existing benchmarks primarily focus on single-object attribute transformation
in realistic scenarios, which, while effective, encounter two key challenges:
(1) they largely overlook multi-object interactions as well as game-world
scenarios that involve human-defined rules, which are common in real-life
applications; (2) they only rely on textual references to evaluate the
generated images, potentially leading to systematic misjudgments, especially in
complex reasoning scenarios. To this end, this work proposes UniREditBench, a
unified benchmark for reasoning-based image editing evaluation. It comprises
2,700 meticulously curated samples, covering both real- and game-world
scenarios across 8 primary dimensions and 18 sub-dimensions. To improve
evaluation reliability, we introduce multimodal dual-reference evaluation,
providing both textual and ground-truth image references for each sample
assessment. Furthermore, we design an automated multi-scenario data synthesis
pipeline and construct UniREdit-Data-100K, a large-scale synthetic dataset with
high-quality chain-of-thought (CoT) reasoning annotations. We fine-tune Bagel
on this dataset and develop UniREdit-Bagel, demonstrating substantial
improvements in both in-domain and out-of-distribution settings. Through
thorough benchmarking of both open-source and closed-source image editing
models, we reveal their strengths and weaknesses across various aspects.

</details>


### [137] [SEPS: Semantic-enhanced Patch Slimming Framework for fine-grained cross-modal alignment](https://arxiv.org/abs/2511.01390)
*Xinyu Mao,Junsi Li,Haoji Zhang,Yu Liang,Ming Sun*

Main category: cs.CV

TL;DR: SEPS框架通过两阶段语义整合和相关性感知选择，有效解决跨模态对齐中的补丁冗余和歧义性问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理补丁冗余和歧义性上存在挑战，且多模态大语言模型（MLLMs）的密集文本输出可能与原始稀疏标注冲突，如何量化视觉补丁与文本描述的语义相关性仍为核心问题。

Method: 采用两阶段机制整合密集和稀疏文本的统一语义，识别显著视觉补丁，并通过相关性感知选择与均值计算突出关键补丁-单词对应关系。

Result: SEPS在Flickr30K和MS-COCO数据集上表现优异，rSum指标超越现有方法23%-86%，尤其在文本到图像检索场景中有显著提升。

Conclusion: SEPS框架通过整合密集和稀疏文本的统一语义，并利用相关性感知选择与均值计算，显著提升了跨模态对齐的性能，在Flickr30K和MS-COCO数据集上验证了其优越性。

Abstract: Fine-grained cross-modal alignment aims to establish precise local
correspondences between vision and language, forming a cornerstone for visual
question answering and related multimodal applications. Current approaches face
challenges in addressing patch redundancy and ambiguity, which arise from the
inherent information density disparities across modalities. Recently,
Multimodal Large Language Models (MLLMs) have emerged as promising solutions to
bridge this gap through their robust semantic generation capabilities. However,
the dense textual outputs from MLLMs may introduce conflicts with the original
sparse captions. Furthermore, accurately quantifying semantic relevance between
rich visual patches and concise textual descriptions remains a core challenge.
To overcome these limitations, we introduce the Semantic-Enhanced Patch
Slimming (SEPS) framework, which systematically addresses patch redundancy and
ambiguity. Our approach employs a two-stage mechanism to integrate unified
semantics from both dense and sparse texts, enabling the identification of
salient visual patches. Additionally, it leverages relevance-aware selection
with mean value computation to highlight crucial patch-word correspondences,
thereby improving cross-modal similarity assessment. Comprehensive experiments
on Flickr30K and MS-COCO datasets validate that SEPS achieves superior
performance, surpassing existing approaches by 23\%-86\% in rSum across diverse
model architectures, with notable enhancements in text-to-image retrieval
scenarios. Our implementation is available at
https://github.com/Sweet4tars/seps.git.

</details>


### [138] [REASON: Probability map-guided dual-branch fusion framework for gastric content assessment](https://arxiv.org/abs/2511.01302)
*Nu-Fnag Xiao,De-Xing Huang,Le-Tian Wang,Mei-Jiang Gui,Qi Fu,Xiao-Liang Xie,Shi-Qi Liu,Shuangyi Wang,Zeng-Guang Hou,Ying-Wei Wang,Xiao-Hu Zhou*

Main category: cs.CV

TL;DR: REASON框架通过两阶段概率图引导和双分支融合，显著提升胃内容物超声评估的效率和准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统胃内容物评估方法依赖手动追踪和经验公式，效率与准确性均受限，亟需自动化解决方案以提升术前误吸风险评估的临床实用性。

Method: 采用两阶段概率图引导的双分支融合框架（REASON）：第一阶段通过分割模型生成抑制伪影并突出胃解剖结构的概率图；第二阶段通过双分支分类器融合右侧卧位（RLD）和仰卧位（SUP）两种标准视图的信息，提升特征判别能力。

Result: 在自建数据集上的实验表明，REASON框架显著优于当前最先进方法。

Conclusion: 该论文提出的REASON框架在胃内容物评估中表现出色，显著优于现有方法，为临床实践提供了更高效、准确的解决方案。

Abstract: Accurate assessment of gastric content from ultrasound is critical for
stratifying aspiration risk at induction of general anesthesia. However,
traditional methods rely on manual tracing of gastric antra and empirical
formulas, which face significant limitations in both efficiency and accuracy.
To address these challenges, a novel two-stage probability map-guided
dual-branch fusion framework (REASON) for gastric content assessment is
proposed. In stage 1, a segmentation model generates probability maps that
suppress artifacts and highlight gastric anatomy. In stage 2, a dual-branch
classifier fuses information from two standard views, right lateral decubitus
(RLD) and supine (SUP), to improve the discrimination of learned features.
Experimental results on a self-collected dataset demonstrate that the proposed
framework outperforms current state-of-the-art approaches by a significant
margin. This framework shows great promise for automated preoperative
aspiration risk assessment, offering a more robust, efficient, and accurate
solution for clinical practice.

</details>


### [139] [Positive Semi-definite Latent Factor Grouping-Boosted Cluster-reasoning Instance Disentangled Learning for WSI Representation](https://arxiv.org/abs/2511.01304)
*Chentao Li,Behzad Bozorgtabar,Yifang Ping,Pan Huang,Jing Qin*

Main category: cs.CV

TL;DR: 提出了一种三阶段实例解耦学习框架，显著提升了全切片病理图像的表示和可解释性，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决多实例学习（MIL）中实例间的空间、语义和决策纠缠问题，提升全切片病理图像的表示和可解释性。

Method: 提出了一个三阶段的潜在因子分组增强的聚类推理实例解耦学习框架，包括正半定潜在因子分组、实例概率反事实推理与优化，以及广义线性加权决策。

Result: 在多中心数据集上的实验表明，该模型性能优于所有现有技术，并实现了病理学家对齐的可解释性。

Conclusion: 该模型通过解耦表示和透明决策过程，不仅性能优于现有技术，还实现了与病理学家对齐的可解释性。

Abstract: Multiple instance learning (MIL) has been widely used for representing
whole-slide pathology images. However, spatial, semantic, and decision
entanglements among instances limit its representation and interpretability. To
address these challenges, we propose a latent factor grouping-boosted
cluster-reasoning instance disentangled learning framework for whole-slide
image (WSI) interpretable representation in three phases. First, we introduce a
novel positive semi-definite latent factor grouping that maps instances into a
latent subspace, effectively mitigating spatial entanglement in MIL. To
alleviate semantic entanglement, we employs instance probability counterfactual
inference and optimization via cluster-reasoning instance disentangling.
Finally, we employ a generalized linear weighted decision via instance effect
re-weighting to address decision entanglement. Extensive experiments on
multicentre datasets demonstrate that our model outperforms all
state-of-the-art models. Moreover, it attains pathologist-aligned
interpretability through disentangled representations and a transparent
decision-making process.

</details>


### [140] [UniSOT: A Unified Framework for Multi-Modality Single Object Tracking](https://arxiv.org/abs/2511.01427)
*Yinchao Ma,Yuyang Tang,Wenfei Yang,Tianzhu Zhang,Xu Zhou,Feng Wu*

Main category: cs.CV

TL;DR: UniSOT是一种统一跟踪器，能处理多种参考和视频模态，性能优于单一模态跟踪器。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪器仅针对单一或少数模态设计，限制了实际应用，需要一种统一跟踪器来满足多样化需求。

Method: 提出UniSOT统一跟踪器，采用统一参数处理三种参考模态和四种视频模态的组合。

Result: 在18个视觉跟踪基准测试中，UniSOT性能优于特定模态跟踪器，尤其在TNL2K和RGB+X模态上表现突出。

Conclusion: UniSOT作为一种统一跟踪器，能够处理多种参考模态和视频模态组合，性能优于特定模态的跟踪器。

Abstract: Single object tracking aims to localize target object with specific reference
modalities (bounding box, natural language or both) in a sequence of specific
video modalities (RGB, RGB+Depth, RGB+Thermal or RGB+Event.). Different
reference modalities enable various human-machine interactions, and different
video modalities are demanded in complex scenarios to enhance tracking
robustness. Existing trackers are designed for single or several video
modalities with single or several reference modalities, which leads to separate
model designs and limits practical applications. Practically, a unified tracker
is needed to handle various requirements. To the best of our knowledge, there
is still no tracker that can perform tracking with these above reference
modalities across these video modalities simultaneously. Thus, in this paper,
we present a unified tracker, UniSOT, for different combinations of three
reference modalities and four video modalities with uniform parameters.
Extensive experimental results on 18 visual tracking, vision-language tracking
and RGB+X tracking benchmarks demonstrate that UniSOT shows superior
performance against modality-specific counterparts. Notably, UniSOT outperforms
previous counterparts by over 3.0\% AUC on TNL2K across all three reference
modalities and outperforms Un-Track by over 2.0\% main metric across all three
RGB+X video modalities.

</details>


### [141] [Privacy Preserving Ordinal-Meta Learning with VLMs for Fine-Grained Fruit Quality Prediction](https://arxiv.org/abs/2511.01449)
*Riddhi Jain,Manasi Patwardhan,Aayush Mishra,Parijat Deshpande,Beena Rai*

Main category: cs.CV

TL;DR: 论文提出MAOML算法，通过元学习和标签序数性解决数据稀疏问题，在水果新鲜度分类任务中达到92.71%准确率。


<details>
  <summary>Details</summary>
Motivation: 由于专家标注的细粒度水果新鲜度标签成本高，导致数据稀缺，而现有的开源视觉语言模型性能不佳，无法满足食品零售行业对数据隐私的需求。因此，需要一种能够在小数据量下高效训练且性能接近专有模型的方法。

Method: 该方法采用模型无关的序数元学习（MAOML）算法，结合元学习和标签序数性来训练较小的视觉语言模型（VLMs）。

Result: MAOML算法在零样本和少样本设置下均实现了业界标准的92.71%平均准确率。

Conclusion: 该论文提出了一种名为MAOML的算法，通过元学习和标签序数性来解决数据稀疏问题，从而在水果新鲜度分类任务中实现了最先进的性能，平均准确率达到92.71%。

Abstract: To effectively manage the wastage of perishable fruits, it is crucial to
accurately predict their freshness or shelf life using non-invasive methods
that rely on visual data. In this regard, deep learning techniques can offer a
viable solution. However, obtaining fine-grained fruit freshness labels from
experts is costly, leading to a scarcity of data. Closed proprietary Vision
Language Models (VLMs), such as Gemini, have demonstrated strong performance in
fruit freshness detection task in both zero-shot and few-shot settings.
Nonetheless, food retail organizations are unable to utilize these proprietary
models due to concerns related to data privacy, while existing open-source VLMs
yield sub-optimal performance for the task. Fine-tuning these open-source
models with limited data fails to achieve the performance levels of proprietary
models. In this work, we introduce a Model-Agnostic Ordinal Meta-Learning
(MAOML) algorithm, designed to train smaller VLMs. This approach utilizes
meta-learning to address data sparsity and leverages label ordinality, thereby
achieving state-of-the-art performance in the fruit freshness classification
task under both zero-shot and few-shot settings. Our method achieves an
industry-standard accuracy of 92.71%, averaged across all fruits.
  Keywords: Fruit Quality Prediction, Vision Language Models, Meta Learning,
Ordinal Regression

</details>


### [142] [MVSMamba: Multi-View Stereo with State Space Model](https://arxiv.org/abs/2511.01315)
*Jianfei Jiang,Qiankun Liu,Hongyuan Liu,Haochen Yu,Liyong Wang,Jiansheng Chen,Huimin Ma*

Main category: cs.CV

TL;DR: MVSMamba是基于Mamba架构的首个MVS网络，通过动态Mamba模块实现高效全局特征聚合，在多个基准测试中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决Transformer-based MVS方法因二次复杂度难以平衡性能与效率的问题，利用Mamba架构的全局建模能力和线性复杂度，提出了MVSMamba网络。

Method: 提出了MVSMamba网络，采用动态Mamba模块（DM-module）和参考中心动态扫描策略，实现了高效的视图内和视图间特征交互、全方位多视图特征表示以及多尺度全局特征聚合。

Result: MVSMamba在DTU数据集和Tanks-and-Temples基准测试中超越了现有最先进的MVS方法，表现出更高的性能和效率。

Conclusion: MVSMamba，基于Mamba架构的首个MVS网络，通过动态Mamba模块实现了高效的全局特征聚合，并在DTU数据集和Tanks-and-Temples基准测试中表现出色，兼具高性能和高效性。

Abstract: Robust feature representations are essential for learning-based Multi-View
Stereo (MVS), which relies on accurate feature matching. Recent MVS methods
leverage Transformers to capture long-range dependencies based on local
features extracted by conventional feature pyramid networks. However, the
quadratic complexity of Transformer-based MVS methods poses challenges to
balance performance and efficiency. Motivated by the global modeling capability
and linear complexity of the Mamba architecture, we propose MVSMamba, the first
Mamba-based MVS network. MVSMamba enables efficient global feature aggregation
with minimal computational overhead. To fully exploit Mamba's potential in MVS,
we propose a Dynamic Mamba module (DM-module) based on a novel
reference-centered dynamic scanning strategy, which enables: (1) Efficient
intra- and inter-view feature interaction from the reference to source views,
(2) Omnidirectional multi-view feature representations, and (3) Multi-scale
global feature aggregation. Extensive experimental results demonstrate MVSMamba
outperforms state-of-the-art MVS methods on the DTU dataset and the
Tanks-and-Temples benchmark with both superior performance and efficiency. The
source code is available at https://github.com/JianfeiJ/MVSMamba.

</details>


### [143] [Reg-DPO: SFT-Regularized Direct Preference Optimization with GT-Pair for Improving Video Generation](https://arxiv.org/abs/2511.01450)
*Jie Du,Xinyu Gong,Qingshan Tan,Wen Li,Yangming Cheng,Weitao Wang,Chenlu Zhan,Suhui Wu,Hao Zhang,Jun Zhang*

Main category: cs.CV

TL;DR: 提出GT-Pair和Reg-DPO方法，结合FSDP优化，显著提升视频生成质量，解决现有DPO方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有DPO方法主要基于小规模模型（约20亿参数），难以应对视频任务中的数据构建成本高、训练不稳定和内存消耗大等挑战。

Method: 提出GT-Pair自动构建高质量偏好对，并引入Reg-DPO（包含SFT损失作为正则项）以增强训练稳定性。结合FSDP框架和内存优化技术提升训练容量。

Result: 在多个数据集的I2V和T2V任务中，该方法表现优于现有方法，生成质量更高。

Conclusion: 通过引入GT-Pair和Reg-DPO方法，结合FSDP框架及内存优化技术，该方法显著提升了视频生成质量，并在I2V和T2V任务中表现优异。

Abstract: Recent studies have identified Direct Preference Optimization (DPO) as an
efficient and reward-free approach to improving video generation quality.
However, existing methods largely follow image-domain paradigms and are mainly
developed on small-scale models (approximately 2B parameters), limiting their
ability to address the unique challenges of video tasks, such as costly data
construction, unstable training, and heavy memory consumption. To overcome
these limitations, we introduce a GT-Pair that automatically builds
high-quality preference pairs by using real videos as positives and
model-generated videos as negatives, eliminating the need for any external
annotation. We further present Reg-DPO, which incorporates the SFT loss as a
regularization term into the DPO objective to enhance training stability and
generation fidelity. Additionally, by combining the FSDP framework with
multiple memory optimization techniques, our approach achieves nearly three
times higher training capacity than using FSDP alone. Extensive experiments on
both I2V and T2V tasks across multiple datasets demonstrate that our method
consistently outperforms existing approaches, delivering superior video
generation quality.

</details>


### [144] [A Generative Adversarial Approach to Adversarial Attacks Guided by Contrastive Language-Image Pre-trained Model](https://arxiv.org/abs/2511.01317)
*Sampriti Soor,Alik Pramanick,Jothiprakash K,Arijit Sur*

Main category: cs.CV

TL;DR: 论文提出了一种结合CLIP模型的生成对抗攻击方法，生成的对抗扰动在欺骗分类模型的同时保持了高视觉逼真度，实验效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 深度学习的快速发展带来了强大的模型，但对抗攻击可能导致模型预测不准确，因此需要开发更有效的对抗攻击方法以评估模型鲁棒性。

Method: 利用CLIP模型对齐文本和图像表示的能力，结合SSAE的集中扰动策略和GAMA的不同文本嵌入方法，生成视觉难以察觉的对抗扰动。

Result: 实验结果表明，该方法在多种任务和黑盒模型上表现优异，欺骗效果与现有技术相当或更优，同时保持更高的视觉逼真度。

Conclusion: 该论文提出的生成对抗攻击方法通过结合CLIP模型和SSAE、GAMA的策略，成功生成了既具有高欺骗性又保持视觉逼真度的对抗扰动，在多种黑盒受害者模型上表现优异。

Abstract: The rapid growth of deep learning has brought about powerful models that can
handle various tasks, like identifying images and understanding language.
However, adversarial attacks, an unnoticed alteration, can deceive models,
leading to inaccurate predictions. In this paper, a generative adversarial
attack method is proposed that uses the CLIP model to create highly effective
and visually imperceptible adversarial perturbations. The CLIP model's ability
to align text and image representation helps incorporate natural language
semantics with a guided loss to generate effective adversarial examples that
look identical to the original inputs. This integration allows extensive scene
manipulation, creating perturbations in multi-object environments specifically
designed to deceive multilabel classifiers. Our approach integrates the
concentrated perturbation strategy from Saliency-based Auto-Encoder (SSAE) with
the dissimilar text embeddings similar to Generative Adversarial Multi-Object
Scene Attacks (GAMA), resulting in perturbations that both deceive
classification models and maintain high structural similarity to the original
images. The model was tested on various tasks across diverse black-box victim
models. The experimental results show that our method performs competitively,
achieving comparable or superior results to existing techniques, while
preserving greater visual fidelity.

</details>


### [145] [When to Trust the Answer: Question-Aligned Semantic Nearest Neighbor Entropy for Safer Surgical VQA](https://arxiv.org/abs/2511.01458)
*Dennis Pierantozzi,Luca Carlini,Mauro Orazio Drago,Chiara Lena,Cesare Hassan,Elena De Momi,Danail Stoyanov,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: QA-SNNE是一种结合问题语义的不确定性估计器，通过测量语义熵提升手术VQA的安全性和可靠性，尤其在零样本模型中表现显著。


<details>
  <summary>Details</summary>
Motivation: 手术中视觉问答（VQA）的安全性和可靠性至关重要，因为错误或模糊的回答可能对患者造成伤害。大多数研究关注准确性或语言质量，而忽视了安全行为，如模糊意识、转介人类专家或触发二次意见。

Method: 引入问题对齐语义最近邻熵（QA-SNNE），一种结合问题语义到预测置信度的黑盒不确定性估计器。通过比较生成的答案与医学文本嵌入空间中的最近邻来测量语义熵，并以问题为条件。评估了五种模型，包括领域特定的参数高效微调（PEFT）模型和零样本大型视觉语言模型（LVLM）。

Result: QA-SNNE在大多数模板内设置中提高了AUROC，并增强了幻觉检测。零样本模型的AUROC提高了15-38%，且在模板外压力下保持增益。PEFT模型在轻度转述下表现下降，而LVLM更具弹性。

Conclusion: 结合大型视觉语言模型（LVLM）和问题对齐的不确定性估计可以提高手术视觉问答（VQA）的安全性和临床医生的信任度。QA-SNNE为手术VQA中的自动故障检测（AFD）提供了一种实用且可解释的步骤。

Abstract: Safety and reliability are essential for deploying Visual Question Answering
(VQA) in surgery, where incorrect or ambiguous responses can harm the patient.
Most surgical VQA research focuses on accuracy or linguistic quality while
overlooking safety behaviors such as ambiguity awareness, referral to human
experts, or triggering a second opinion. Inspired by Automatic Failure
Detection (AFD), we study uncertainty estimation as a key enabler of safer
decision making. We introduce Question Aligned Semantic Nearest Neighbor
Entropy (QA-SNNE), a black box uncertainty estimator that incorporates question
semantics into prediction confidence. It measures semantic entropy by comparing
generated answers with nearest neighbors in a medical text embedding space,
conditioned on the question. We evaluate five models, including domain specific
Parameter-Efficient Fine-Tuned (PEFT) models and zero-shot Large
Vision-Language Models (LVLMs), on EndoVis18-VQA and PitVQA. PEFT models
degrade under mild paraphrasing, while LVLMs are more resilient. Across three
LVLMs and two PEFT baselines, QA-SNNE improves AUROC in most in-template
settings and enhances hallucination detection. The Area Under the ROC Curve
(AUROC) increases by 15-38% for zero-shot models, with gains maintained under
out-of-template stress. QA-SNNE offers a practical and interpretable step
toward AFD in surgical VQA by linking semantic uncertainty to question context.
Combining LVLM backbones with question aligned uncertainty estimation can
improve safety and clinician trust. The code and model are available at
https://github.com/DennisPierantozzi/QASNNE

</details>


### [146] [RDTE-UNet: A Boundary and Detail Aware UNet for Precise Medical Image Segmentation](https://arxiv.org/abs/2511.01328)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: RDTE-UNet是一种医学图像分割网络，通过混合ResBlock和Transformer主干，结合三个创新模块，提升了边界和细节的分割效果。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在计算机辅助诊断和治疗规划中至关重要，但解剖结构的显著变异性和边界模糊性阻碍了对精细结构的可靠描绘。

Method: RDTE-UNet采用混合ResBlock细节感知Transformer主干和三个模块：ASBE（自适应边界增强）、HVDA（细粒度特征建模）和EulerFF（基于欧拉公式的融合加权）。

Result: RDTE-UNet通过统一局部建模与全局上下文，增强了边界描绘和细节保留，提高了结构一致性和边界准确性。

Conclusion: RDTE-UNet在Synapse和BUSI数据集上实现了与现有方法相当的分割精度和边界质量。

Abstract: Medical image segmentation is essential for computer-assisted diagnosis and
treatment planning, yet substantial anatomical variability and boundary
ambiguity hinder reliable delineation of fine structures. We propose RDTE-UNet,
a segmentation network that unifies local modeling with global context to
strengthen boundary delineation and detail preservation. RDTE-UNet employs a
hybrid ResBlock detail-aware Transformer backbone and three modules: ASBE for
adaptive boundary enhancement, HVDA for fine-grained feature modeling, and
EulerFF for fusion weighting guided by Euler's formula. Together, these
components improve structural consistency and boundary accuracy across
morphology, orientation, and scale. On Synapse and BUSI dataset, RDTE-UNet has
achieved a comparable level in terms of segmentation accuracy and boundary
quality.

</details>


### [147] [Efficiently Training A Flat Neural Network Before It has been Quantizated](https://arxiv.org/abs/2511.01462)
*Peng Xia,Junbiao Pang,Tianyang Cai*

Main category: cs.CV

TL;DR: 本文提出了一种通过主动预处理和误差分离来降低量化误差的PTQ框架，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常忽视了训练好的神经网络与量化模型之间的关系，导致PTQ的量化误差较大。本文旨在解决如何高效训练一个与模型无关的神经网络，以适应预定义精度的低比特模型。

Method: 作者首先发现平坦的全精度神经网络对低比特量化至关重要。为此，提出了一种框架，通过统计建模激活量化误差（AQE）和权重量化误差（WQE）为独立高斯噪声，并研究了几种噪声注入优化方法以获得平坦最小值。

Result: 实验结果表明，该方法有效降低了量化误差，验证了其有效性。

Conclusion: 本文提出了一种新的后训练量化（PTQ）框架，通过主动预处理模型并分离误差源，显著降低了量化误差，为低比特PTQ模型的获取开辟了新途径。

Abstract: Post-training quantization (PTQ) for vision transformers (ViTs) has garnered
significant attention due to its efficiency in compressing models. However,
existing methods typically overlook the relationship between a well-trained NN
and the quantized model, leading to considerable quantization error for PTQ.
However, it is unclear how to efficiently train a model-agnostic neural network
which is tailored for a predefined precision low-bit model. In this paper, we
firstly discover that a flat full precision neural network is crucial for
low-bit quantization. To achieve this, we propose a framework that proactively
pre-conditions the model by measuring and disentangling the error sources.
Specifically, both the Activation Quantization Error (AQE) and the Weight
Quantization Error (WQE) are statistically modeled as independent Gaussian
noises. We study several noise injection optimization methods to obtain a flat
minimum. Experimental results attest to the effectiveness of our approach.
These results open novel pathways for obtaining low-bit PTQ models.

</details>


### [148] [$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$: A Large and Diverse Multimodal Benchmark for evaluating the ability of Vision-Language Models to understand Rebus Puzzles](https://arxiv.org/abs/2511.01340)
*Trishanu Das,Abhilash Nandy,Khush Bajaj,Deepiha S*

Main category: cs.CV

TL;DR: 本文介绍了一个包含1333个Rebus Puzzles的基准和$RebusDescProgICE$框架，提升了视觉语言模型的性能。


<details>
  <summary>Details</summary>
Motivation: Rebus Puzzles需要多种技能（如图像识别、认知技能、常识推理等），对当前视觉语言模型具有挑战性，因此需要新的基准和方法来提升模型性能。

Method: 提出了$RebusDescProgICE$框架，结合非结构化描述和基于代码的结构化推理，以及改进的基于推理的上下文示例选择。

Result: 与Chain-of-Thought Reasoning相比，$RebusDescProgICE$在闭源和开源模型上分别提升了2.1-4.1%和20-30%的性能。

Conclusion: 本文提出了一个名为$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$的大型多样化Rebus Puzzles基准，并开发了$RebusDescProgICE$框架，显著提升了视觉语言模型在解决Rebus Puzzles任务上的性能。

Abstract: Understanding Rebus Puzzles (Rebus Puzzles use pictures, symbols, and letters
to represent words or phrases creatively) requires a variety of skills such as
image recognition, cognitive skills, commonsense reasoning, multi-step
reasoning, image-based wordplay, etc., making this a challenging task for even
current Vision-Language Models. In this paper, we present
$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$, a large and diverse
benchmark of $1,333$ English Rebus Puzzles containing different artistic styles
and levels of difficulty, spread across 18 categories such as food, idioms,
sports, finance, entertainment, etc. We also propose $RebusDescProgICE$, a
model-agnostic framework which uses a combination of an unstructured
description and code-based, structured reasoning, along with better,
reasoning-based in-context example selection, improving the performance of
Vision-Language Models on
$\left|\,\circlearrowright\,\boxed{\text{BUS}}\,\right|$ by $2.1-4.1\%$ and
$20-30\%$ using closed-source and open-source models respectively compared to
Chain-of-Thought Reasoning.

</details>


### [149] [MIQ-SAM3D: From Single-Point Prompt to Multi-Instance Segmentation via Competitive Query Refinement](https://arxiv.org/abs/2511.01345)
*Jierui Qu,Jianchun Zhao*

Main category: cs.CV

TL;DR: MIQ-SAM3D通过多实例3D分割框架和竞争查询优化策略，实现单点对多实例分割，提升了多病灶分割效率。


<details>
  <summary>Details</summary>
Motivation: 现有SAM交互式分割方法多为单点对单对象，限制多病灶分割，且ViT骨干网络常忽略高保真局部细节。

Method: 采用混合CNN-Transformer编码器，通过空间门控将CNN边界显著性注入ViT自注意力机制，并设计竞争优化的查询解码器实现并行多实例预测。

Result: 在LiTS17和KiTS21数据集上表现优异，具有强鲁棒性。

Conclusion: MIQ-SAM3D提供了一种高效的临床多病灶标注解决方案，具有强鲁棒性。

Abstract: Accurate segmentation of medical images is fundamental to tumor diagnosis and
treatment planning. SAM-based interactive segmentation has gained attention for
its strong generalization, but most methods follow a
single-point-to-single-object paradigm, which limits multi-lesion segmentation.
Moreover, ViT backbones capture global context but often miss high-fidelity
local details. We propose MIQ-SAM3D, a multi-instance 3D segmentation framework
with a competitive query optimization strategy that shifts from
single-point-to-single-mask to single-point-to-multi-instance. A
prompt-conditioned instance-query generator transforms a single point prompt
into multiple specialized queries, enabling retrieval of all semantically
similar lesions across the 3D volume from a single exemplar. A hybrid
CNN-Transformer encoder injects CNN-derived boundary saliency into ViT
self-attention via spatial gating. A competitively optimized query decoder then
enables end-to-end, parallel, multi-instance prediction through inter-query
competition. On LiTS17 and KiTS21 dataset, MIQ-SAM3D achieved comparable levels
and exhibits strong robustness to prompts, providing a practical solution for
efficient annotation of clinically relevant multi-lesion cases.

</details>


### [150] [Expanding the Content-Style Frontier: a Balanced Subspace Blending Approach for Content-Style LoRA Fusion](https://arxiv.org/abs/2511.01355)
*Linhao Huang*

Main category: cs.CV

TL;DR: 提出新方法扩展内容-风格前沿，优化生成图像的内容相似性，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像扩散模型在单一风格强度下评估内容相似性，忽略了风格强度增加时的内容特征丢失问题。

Method: 采用内容-风格子空间混合和内容-风格平衡损失来优化生成图像的内容相似性。

Result: 实验表明，该方法在质量和数量评估上均优于现有技术，显著降低了IGD和GD分数。

Conclusion: 本文提出的方法通过内容-风格子空间混合和平衡损失，显著扩展了内容-风格前沿，优于现有技术。

Abstract: Recent advancements in text-to-image diffusion models have significantly
improved the personalization and stylization of generated images. However,
previous studies have only assessed content similarity under a single style
intensity. In our experiments, we observe that increasing style intensity leads
to a significant loss of content features, resulting in a suboptimal
content-style frontier. To address this, we propose a novel approach to expand
the content-style frontier by leveraging Content-Style Subspace Blending and a
Content-Style Balance loss. Our method improves content similarity across
varying style intensities, significantly broadening the content-style frontier.
Extensive experiments demonstrate that our approach outperforms existing
techniques in both qualitative and quantitative evaluations, achieving superior
content-style trade-off with significantly lower Inverted Generational Distance
(IGD) and Generational Distance (GD) scores compared to current methods.

</details>


### [151] [Driving scenario generation and evaluation using a structured layer representation and foundational models](https://arxiv.org/abs/2511.01541)
*Arthur Hubert,Gamal Elghazaly,Raphaël Frank*

Main category: cs.CV

TL;DR: 本文提出结构化五层模型，结合基础模型生成罕见驾驶场景，并引入多样性及原创性得分进行评估。


<details>
  <summary>Details</summary>
Motivation: 罕见驾驶场景对自动驾驶开发至关重要，但由于难以遇到，利用生成模型模拟或生成这些场景成为一种流行方法。

Method: 采用结构化五层模型，引入子类和特性描述每个场景的代理，结合大型基础模型进行数据增强生成新场景。

Result: 提出了多样性得分和原创性得分两个指标，用于评估合成数据集的相关性，并在不同生成设置中展示了这些指标的效果。

Conclusion: 本文提出了一种结构化的五层模型，用于改进罕见驾驶场景的评估和生成。通过结合大型基础模型和数据增强策略，该方法能够有效生成新场景，并通过嵌入特定层模型进行比较。

Abstract: Rare and challenging driving scenarios are critical for autonomous vehicle
development. Since they are difficult to encounter, simulating or generating
them using generative models is a popular approach. Following previous efforts
to structure driving scenario representations in a layer model, we propose a
structured five-layer model to improve the evaluation and generation of rare
scenarios. We use this model alongside large foundational models to generate
new driving scenarios using a data augmentation strategy. Unlike previous
representations, our structure introduces subclasses and characteristics for
every agent of the scenario, allowing us to compare them using an embedding
specific to our layer-model. We study and adapt two metrics to evaluate the
relevance of a synthetic dataset in the context of a structured representation:
the diversity score estimates how different the scenarios of a dataset are from
one another, while the originality score calculates how similar a synthetic
dataset is from a real reference set. This paper showcases both metrics in
different generation setup, as well as a qualitative evaluation of synthetic
videos generated from structured scenario descriptions. The code and extended
results can be found at https://github.com/Valgiz/5LMSG.

</details>


### [152] [DINO-MX: A Modular & Flexible Framework for Self-Supervised Learning](https://arxiv.org/abs/2511.01610)
*Mahmut Selman Gokmen,Cody Bumgardner*

Main category: cs.CV

TL;DR: DINO-MX是一个灵活、高效的训练框架，结合DINO系列原理，支持多种架构和训练策略，显著降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉基础模型训练流程通常不灵活、领域特定或计算成本高，限制了其在不同领域和资源环境中的可用性。

Method: DINO-MX是一个模块化、可扩展的训练框架，结合了DINO系列的核心原理，支持多种基于transformer的架构，并与Hugging Face生态系统完全兼容。

Result: 实验结果表明，DINO-MX在多样数据集上实现了竞争性性能，同时显著降低计算成本，并提供了解释性工具和标签引导的数据增强方法。

Conclusion: DINO-MX提供了一个可重复、可扩展的基础，用于开发和基准测试自监督视觉模型，适用于广泛的研究和实际应用。

Abstract: Vision Foundation Models (VFMs) have advanced representation learning through
self-supervised methods. However, existing training pipelines are often
inflexible, domain-specific, or computationally expensive, which limits their
usability across different domains and resource settings. DINO-MX is a modular
and extensible training framework that combines the core principles of DINO,
DINOv2 and DINOv3 within a unified configuration-driven system. It supports a
variety of transformer-based architectures and is fully compatible with the
Hugging Face ecosystem. The framework includes multiple training strategies
such as low-rank adaptation (LoRA), layer freezing, and knowledge distillation,
along with support for distributed training through both Distributed Data
Parallel (DDP) and Fully Sharded Data Parallel (FSDP). DINO-MX is designed to
work with both natural and specialized data types, including single- and
multi-channel images. Experimental results on diverse datasets show that
DINO-MX achieves competitive performance while significantly reducing
computational costs. Additionally, it offers interpretability tools and a
label-guided data augmentation method that improves attention-based
localization without the need for extra detection or segmentation heads.
DINO-MX provides a reproducible and scalable foundation for developing,
adapting, and benchmarking self-supervised vision models across a range of
research and real-world applications.

</details>


### [153] [Wonder3D++: Cross-domain Diffusion for High-fidelity 3D Generation from a Single Image](https://arxiv.org/abs/2511.01767)
*Yuxiao Yang,Xiao-Xiao Long,Zhiyang Dou,Cheng Lin,Yuan Liu,Qingsong Yan,Yuexin Ma,Haoqian Wang,Zhiqiang Wu,Wei Yin*

Main category: cs.CV

TL;DR: Wonder3D++是高效生成高质量纹理网格的新方法，结合扩散模型和多视角注意力，解决单视角重建的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于SDS的方法效率低下、几何不一致，以及快速网络推断方法质量低、缺乏几何细节的问题。

Method: 提出了一种跨域扩散模型，生成多视角法线图和对应彩色图像，并采用多视角交叉注意力机制确保生成一致性，最后通过级联3D网格提取算法高效生成高质量表面。

Result: 在约3分钟内实现了高质量重建，结果优于现有方法。

Conclusion: Wonder3D++通过跨域扩散模型和多视角交叉注意力机制，在单视角重建任务中实现了高质量、一致性和效率的全面提升。

Abstract: In this work, we introduce \textbf{Wonder3D++}, a novel method for
efficiently generating high-fidelity textured meshes from single-view images.
Recent methods based on Score Distillation Sampling (SDS) have shown the
potential to recover 3D geometry from 2D diffusion priors, but they typically
suffer from time-consuming per-shape optimization and inconsistent geometry. In
contrast, certain works directly produce 3D information via fast network
inferences, but their results are often of low quality and lack geometric
details. To holistically improve the quality, consistency, and efficiency of
single-view reconstruction tasks, we propose a cross-domain diffusion model
that generates multi-view normal maps and the corresponding color images. To
ensure the consistency of generation, we employ a multi-view cross-domain
attention mechanism that facilitates information exchange across views and
modalities. Lastly, we introduce a cascaded 3D mesh extraction algorithm that
drives high-quality surfaces from the multi-view 2D representations in only
about $3$ minute in a coarse-to-fine manner. Our extensive evaluations
demonstrate that our method achieves high-quality reconstruction results,
robust generalization, and good efficiency compared to prior works. Code
available at https://github.com/xxlong0/Wonder3D/tree/Wonder3D_Plus.

</details>


### [154] [Semantic BIM enrichment for firefighting assets: Fire-ART dataset and panoramic image-based 3D reconstruction](https://arxiv.org/abs/2511.01399)
*Ya Wen,Yutong Qiao,Chi Chiu Lam,Ioannis Brilakis,Sanghoon Lee,Mun On Wong*

Main category: cs.CV

TL;DR: 本研究介绍了Fire-ART数据集和一种基于全景图像的消防资产重建方法，旨在提升消防资产的自动识别与重建效率。


<details>
  <summary>Details</summary>
Motivation: 传统消防资产管理方法因自动识别与重建能力不足而效率低下，亟需技术改进。

Method: 开发了Fire-ART数据集，包含15类基础资产、2626张图像和6627个实例，并提出结合改进的立方体贴图转换和基于半径的球形相机投影的重建方法。

Result: 通过两个实际案例验证，F1分数分别达到73%和88%，定位误差为0.620和0.428米。

Conclusion: Fire-ART数据集和重建方法为消防设备的数字化管理提供了有力支持。

Abstract: Inventory management of firefighting assets is crucial for emergency
preparedness, risk assessment, and on-site fire response. However, conventional
methods are inefficient due to limited capabilities in automated asset
recognition and reconstruction. To address the challenge, this research
introduces the Fire-ART dataset and develops a panoramic image-based
reconstruction approach for semantic enrichment of firefighting assets into BIM
models. The Fire-ART dataset covers 15 fundamental assets, comprising 2,626
images and 6,627 instances, making it an extensive and publicly accessible
dataset for asset recognition. In addition, the reconstruction approach
integrates modified cube-map conversion and radius-based spherical camera
projection to enhance recognition and localization accuracy. Through
validations with two real-world case studies, the proposed approach achieves
F1-scores of 73% and 88% and localization errors of 0.620 and 0.428 meters,
respectively. The Fire-ART dataset and the reconstruction approach offer
valuable resources and robust technical solutions to enhance the accurate
digital management of fire safety equipment.

</details>


### [155] [How Far Are Surgeons from Surgical World Models? A Pilot Study on Zero-shot Surgical Video Generation with Expert Assessment](https://arxiv.org/abs/2511.01775)
*Zhen Chen,Qing Xu,Jinlin Wu,Biao Yang,Yuhao Zhai,Geng Guo,Jing Zhang,Yinlu Ding,Nassir Navab,Jiebo Luo*

Main category: cs.CV

TL;DR: 研究通过SurgVeo基准和SPP框架评估视频生成模型在手术中的表现，发现视觉感知与因果理解存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 探索基础视频生成模型在高风险手术领域的应用潜力，填补其在专业因果知识方面的研究空白。

Method: 提出了SurgVeo基准和SPP四层评估框架，并利用Veo-3模型进行零样本预测任务，由四位认证外科医生评估生成视频。

Result: Veo-3在视觉感知层面表现优异，但在器械操作、环境反馈和手术意图等高层次SPP评估中表现不佳。

Conclusion: 该研究通过SurgVeo基准和SPP框架揭示了视频生成模型在手术领域中的局限性，尤其是视觉感知与因果理解之间的差距，为未来模型的开发提供了重要方向。

Abstract: Foundation models in video generation are demonstrating remarkable
capabilities as potential world models for simulating the physical world.
However, their application in high-stakes domains like surgery, which demand
deep, specialized causal knowledge rather than general physical rules, remains
a critical unexplored gap. To systematically address this challenge, we present
SurgVeo, the first expert-curated benchmark for video generation model
evaluation in surgery, and the Surgical Plausibility Pyramid (SPP), a novel,
four-tiered framework tailored to assess model outputs from basic appearance to
complex surgical strategy. On the basis of the SurgVeo benchmark, we task the
advanced Veo-3 model with a zero-shot prediction task on surgical clips from
laparoscopic and neurosurgical procedures. A panel of four board-certified
surgeons evaluates the generated videos according to the SPP. Our results
reveal a distinct "plausibility gap": while Veo-3 achieves exceptional Visual
Perceptual Plausibility, it fails critically at higher levels of the SPP,
including Instrument Operation Plausibility, Environment Feedback Plausibility,
and Surgical Intent Plausibility. This work provides the first quantitative
evidence of the chasm between visually convincing mimicry and causal
understanding in surgical AI. Our findings from SurgVeo and the SPP establish a
crucial foundation and roadmap for developing future models capable of
navigating the complexities of specialized, real-world healthcare domains.

</details>


### [156] [Extremal Contours: Gradient-driven contours for compact visual attribution](https://arxiv.org/abs/2511.01411)
*Reza Karimzadeh,Albert Alonso,Frans Zdyb,Julius B. Kirkegaard,Bulat Ibragimov*

Main category: cs.CV

TL;DR: 提出一种基于平滑轮廓的无训练解释方法，优化视觉模型解释的紧凑性和忠实性，尤其在DINO模型上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有密集扰动掩码易碎片化和过拟合的问题，提供更稳定、紧凑且易于解释的视觉模型解释。

Method: 提出了一种无训练的解释方法，采用星凸区域的截断傅里叶级数参数化，并通过分类器梯度优化极值保留/删除目标。

Result: 在ImageNet分类器上匹配了密集掩码的极值忠实性，同时生成更紧凑、可解释的区域，并在自监督DINO模型上显著提升相关性质量。

Conclusion: 该方法通过平滑可调轮廓取代密集扰动掩码，显著提升了视觉模型解释的紧凑性和忠实性，尤其在自监督DINO模型上表现突出。

Abstract: Faithful yet compact explanations for vision models remain a challenge, as
commonly used dense perturbation masks are often fragmented and overfitted,
needing careful post-processing. Here, we present a training-free explanation
method that replaces dense masks with smooth tunable contours. A star-convex
region is parameterized by a truncated Fourier series and optimized under an
extremal preserve/delete objective using the classifier gradients. The approach
guarantees a single, simply connected mask, cuts the number of free parameters
by orders of magnitude, and yields stable boundary updates without cleanup.
Restricting solutions to low-dimensional, smooth contours makes the method
robust to adversarial masking artifacts. On ImageNet classifiers, it matches
the extremal fidelity of dense masks while producing compact, interpretable
regions with improved run-to-run consistency. Explicit area control also
enables importance contour maps, yielding a transparent fidelity-area profiles.
Finally, we extend the approach to multi-contour and show how it can localize
multiple objects within the same framework. Across benchmarks, the method
achieves higher relevance mass and lower complexity than gradient and
perturbation based baselines, with especially strong gains on self-supervised
DINO models where it improves relevance mass by over 15% and maintains positive
faithfulness correlations.

</details>


### [157] [Towards One-step Causal Video Generation via Adversarial Self-Distillation](https://arxiv.org/abs/2511.01419)
*Yongqi Yang,Huayang Huang,Xu Peng,Xiaobin Hu,Donghao Luo,Jiangning Zhang,Chengjie Wang,Yu Wu*

Main category: cs.CV

TL;DR: 提出对抗性自蒸馏和首帧增强策略，显著提升极少数去噪步骤下的视频生成质量，支持灵活推理步骤。


<details>
  <summary>Details</summary>
Motivation: 现有的混合视频生成模型因序列化和迭代性质导致误差累积和长推理时间，需开发更高效的因果视频生成方法。

Method: 提出了一种基于对抗性自蒸馏（ASD）的策略，通过分布级别对齐学生模型的n步与(n+1)步输出来优化训练，并结合首帧增强（FFE）策略减少误差传播。

Result: 在VBench上的实验表明，该方法在1-2步视频生成中优于现有技术，且能灵活支持多种推理步骤。

Conclusion: 该论文提出的蒸馏框架在极少数去噪步骤下实现了高质量的视频合成，显著优于现有方法，且支持多种推理步骤设置，无需重复蒸馏。

Abstract: Recent hybrid video generation models combine autoregressive temporal
dynamics with diffusion-based spatial denoising, but their sequential,
iterative nature leads to error accumulation and long inference times. In this
work, we propose a distillation-based framework for efficient causal video
generation that enables high-quality synthesis with extremely limited denoising
steps. Our approach builds upon the Distribution Matching Distillation (DMD)
framework and proposes a novel Adversarial Self-Distillation (ASD) strategy,
which aligns the outputs of the student model's n-step denoising process with
its (n+1)-step version at the distribution level. This design provides smoother
supervision by bridging small intra-student gaps and more informative guidance
by combining teacher knowledge with locally consistent student behavior,
substantially improving training stability and generation quality in extremely
few-step scenarios (e.g., 1-2 steps). In addition, we present a First-Frame
Enhancement (FFE) strategy, which allocates more denoising steps to the initial
frames to mitigate error propagation while applying larger skipping steps to
later frames. Extensive experiments on VBench demonstrate that our method
surpasses state-of-the-art approaches in both one-step and two-step video
generation. Notably, our framework produces a single distilled model that
flexibly supports multiple inference-step settings, eliminating the need for
repeated re-distillation and enabling efficient, high-quality video synthesis.

</details>


### [158] [Terrain-Enhanced Resolution-aware Refinement Attention for Off-Road Segmentation](https://arxiv.org/abs/2511.01434)
*Seongkyu Choi,Jhonghyun An*

Main category: cs.CV

TL;DR: 论文提出一种分辨率感知令牌解码器，通过低分辨率处理、门控交叉注意力和稀疏细化，平衡语义分割中的全局与局部需求，提升边界保真度和抗噪能力。


<details>
  <summary>Details</summary>
Motivation: 解决越野语义分割中存在的边界模糊、稀有类别监督稀疏和标签噪声普遍的问题，避免高分辨率融合的高成本和噪声敏感性。

Method: 采用了一种分辨率感知令牌解码器，结合低分辨率瓶颈处理、门控交叉注意力机制和稀疏不确定性选择像素细化，同时设计了边界带一致性正则化器以提升训练效果。

Result: 实验结果表明，该方法在性能和跨过渡稳定性上具有竞争力。

Conclusion: 该论文提出的分辨率感知令牌解码器在全局语义、局部一致性和边界保真度之间取得了平衡，尤其在存在不完美监督的情况下表现优异。

Abstract: Off-road semantic segmentation suffers from thick, inconsistent boundaries,
sparse supervision for rare classes, and pervasive label noise. Designs that
fuse only at low resolution blur edges and propagate local errors, whereas
maintaining high-resolution pathways or repeating high-resolution fusions is
costly and fragile to noise. We introduce a resolutionaware token decoder that
balances global semantics, local consistency, and boundary fidelity under
imperfect supervision. Most computation occurs at a low-resolution bottleneck;
a gated cross-attention injects fine-scale detail, and only a sparse,
uncertainty-selected set of pixels is refined. The components are co-designed
and tightly integrated: global self-attention with lightweight dilated
depthwise refinement restores local coherence; a gated cross-attention
integrates fine-scale features from a standard high-resolution encoder stream
without amplifying noise; and a class-aware point refinement corrects residual
ambiguities with negligible overhead. During training, we add a boundary-band
consistency regularizer that encourages coherent predictions in a thin
neighborhood around annotated edges, with no inference-time cost. Overall, the
results indicate competitive performance and improved stability across
transitions.

</details>


### [159] [Contrast-Guided Cross-Modal Distillation for Thermal Object Detection](https://arxiv.org/abs/2511.01435)
*SiWoo Kim,JhongHyun An*

Main category: cs.CV

TL;DR: 论文提出一种热红外检测训练优化方法，通过特征聚合分离及跨模态特征对齐，显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 针对热红外检测中的低对比度、高频线索弱导致的问题，现有方法存在性能脆弱或额外传感器需求，本方法直接在训练阶段优化热红外表示。

Method: 引入训练阶段的目标函数，包括增强同类特征聚合与异类特征分离，以及通过RGB预训练模型的多层次特征对齐来强化热红外特征。

Result: 实验表明，该方法优于现有方法，达到最先进性能。

Conclusion: 该论文提出的方法通过训练阶段的特定目标，显著提升了热红外检测的性能，实现了当前最佳效果。

Abstract: Robust perception at night remains challenging for thermal-infrared
detection: low contrast and weak high-frequency cues lead to duplicate,
overlapping boxes, missed small objects, and class confusion. Prior remedies
either translate TIR to RGB and hope pixel fidelity transfers to detection --
making performance fragile to color or structure artifacts -- or fuse RGB and
TIR at test time, which requires extra sensors, precise calibration, and higher
runtime cost. Both lines can help in favorable conditions, but do not directly
shape the thermal representation used by the detector. We keep mono-modality
inference and tackle the root causes during training. Specifically, we
introduce training-only objectives that sharpen instance-level decision
boundaries by pulling together features of the same class and pushing apart
those of different classes -- suppressing duplicate and confusing detections --
and that inject cross-modal semantic priors by aligning the student's
multi-level pyramid features with an RGB-trained teacher, thereby strengthening
texture-poor thermal features without visible input at test time. In
experiments, our method outperformed prior approaches and achieved
state-of-the-art performance.

</details>


### [160] [SecDiff: Diffusion-Aided Secure Deep Joint Source-Channel Coding Against Adversarial Attacks](https://arxiv.org/abs/2511.01466)
*Changyuan Zhao,Jiacheng Wang,Ruichen Zhang,Dusit Niyato,Hongyang Du,Zehui Xiong,Dong In Kim,Ping Zhang*

Main category: cs.CV

TL;DR: SecDiff 是一种扩散辅助解码框架，通过伪逆采样和自适应权重提升深度 JSCC 的抗攻击能力，实验证明其在对抗环境下性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有 JSCC 框架在对抗性无线环境下易受物理层攻击（如导频欺骗和子载波干扰），导致语义保真度下降。SecDiff 旨在解决这些问题，提升语义通信的安全性和鲁棒性。

Method: SecDiff 采用伪逆引导采样和自适应权重调整，结合功率子载波掩蔽策略和期望最大化（EM）驱动的重建算法，分别应对子载波干扰和导频欺骗攻击。该方法在扩散过程中交替进行导频恢复和信道估计，实现联合优化。

Result: 在对抗性 OFDM 信道下的实验表明，SecDiff 在重建质量和计算成本之间取得了优越的平衡，显著优于现有安全性和生成性 JSCC 基线方法。

Conclusion: SecDiff 提出了一种新型的扩散辅助解码框架，显著提升了深度联合源信道编码（JSCC）在对抗性无线环境下的安全性与鲁棒性。通过伪逆引导采样和自适应权重调整，实现了高效的语义重建与灵活步长控制。实验证明，SecDiff 在对抗条件下优于现有方法，平衡了重建质量与计算成本，为实用、低延迟且抗攻击的语义通信迈出了重要一步。

Abstract: Deep joint source-channel coding (JSCC) has emerged as a promising paradigm
for semantic communication, delivering significant performance gains over
conventional separate coding schemes. However, existing JSCC frameworks remain
vulnerable to physical-layer adversarial threats, such as pilot spoofing and
subcarrier jamming, compromising semantic fidelity. In this paper, we propose
SecDiff, a plug-and-play, diffusion-aided decoding framework that significantly
enhances the security and robustness of deep JSCC under adversarial wireless
environments. Different from prior diffusion-guided JSCC methods that suffer
from high inference latency, SecDiff employs pseudoinverse-guided sampling and
adaptive guidance weighting, enabling flexible step-size control and efficient
semantic reconstruction. To counter jamming attacks, we introduce a power-based
subcarrier masking strategy and recast recovery as a masked inpainting problem,
solved via diffusion guidance. For pilot spoofing, we formulate channel
estimation as a blind inverse problem and develop an expectation-minimization
(EM)-driven reconstruction algorithm, guided jointly by reconstruction loss and
a channel operator. Notably, our method alternates between pilot recovery and
channel estimation, enabling joint refinement of both variables throughout the
diffusion process. Extensive experiments over orthogonal frequency-division
multiplexing (OFDM) channels under adversarial conditions show that SecDiff
outperforms existing secure and generative JSCC baselines by achieving a
favorable trade-off between reconstruction quality and computational cost. This
balance makes SecDiff a promising step toward practical, low-latency, and
attack-resilient semantic communications.

</details>


### [161] [EPAN: Robust Pedestrian Re-Identification via Enhanced Alignment Network for IoT Surveillance](https://arxiv.org/abs/2511.01498)
*Zhiyang Jia,Hongyan Cui,Ge Gao,Bo Li,Minjie Zhang,Zishuo Gao,Huiwen Huang,Caisheng Zhuo*

Main category: cs.CV

TL;DR: EPAN是一种专为物联网监控设计的双分支网络，能有效处理视角和环境变化，在人员重识别任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 人员重识别在计算机视觉中至关重要，尤其是在物联网智能环境下的监控和安全应用中。

Method: EPAN采用双分支架构，以减轻视角和环境变化的影响，提取不同尺度和视角下的对齐信息。

Result: EPAN在Inspection-Personnel数据集上表现优异，Rank-1准确率达90.09%，mAP为78.82%。

Conclusion: EPAN展示了在现实世界物联网应用中实现高效可靠的人员重识别的潜力，适用于多样化的监控和安全系统。

Abstract: Person re-identification (ReID) plays a pivotal role in computer vision,
particularly in surveillance and security applications within IoT-enabled smart
environments. This study introduces the Enhanced Pedestrian Alignment Network
(EPAN), tailored for robust ReID across diverse IoT surveillance conditions.
EPAN employs a dual-branch architecture to mitigate the impact of perspective
and environmental changes, extracting alignment information under varying
scales and viewpoints. Here, we demonstrate EPAN's strong feature extraction
capabilities, achieving outstanding performance on the Inspection-Personnel
dataset with a Rank-1 accuracy of 90.09% and a mean Average Precision (mAP) of
78.82%. This highlights EPAN's potential for real-world IoT applications,
enabling effective and reliable person ReID across diverse cameras in
surveillance and security systems. The code and data are available at:
https://github.com/ggboy2580/EPAN

</details>


### [162] [Luminance-Aware Statistical Quantization: Unsupervised Hierarchical Learning for Illumination Enhancement](https://arxiv.org/abs/2511.01510)
*Derong Kong,Zhixiong Yang,Shengxi Li,Shuaifeng Zhi,Li Liu,Zhen Liu,Jingyuan Xia*

Main category: cs.CV

TL;DR: LASQ通过统计采样和分层亮度分布的方法，显著提升了低光图像增强的性能和跨场景泛化能力，无需正常光参考。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于依赖确定性像素级映射，忽略了真实环境中亮度过渡的连续物理过程，导致在缺乏正常光参考时性能下降。

Method: 提出了Luminance-Aware Statistical Quantification (LASQ)，将低光图像增强重新定义为分层亮度分布上的统计采样过程，并通过扩散前向过程自主发现亮度层之间的最佳过渡路径。

Result: LASQ在无正常光参考的实用场景中表现优异，同时在有参考的数据集上也实现了更好的性能和泛化能力。

Conclusion: LASQ框架通过统计采样和分层亮度分布的方法，显著提升了低光图像增强的性能和跨场景泛化能力。

Abstract: Low-light image enhancement (LLIE) faces persistent challenges in balancing
reconstruction fidelity with cross-scenario generalization. While existing
methods predominantly focus on deterministic pixel-level mappings between
paired low/normal-light images, they often neglect the continuous physical
process of luminance transitions in real-world environments, leading to
performance drop when normal-light references are unavailable. Inspired by
empirical analysis of natural luminance dynamics revealing power-law
distributed intensity transitions, this paper introduces Luminance-Aware
Statistical Quantification (LASQ), a novel framework that reformulates LLIE as
a statistical sampling process over hierarchical luminance distributions. Our
LASQ re-conceptualizes luminance transition as a power-law distribution in
intensity coordinate space that can be approximated by stratified power
functions, therefore, replacing deterministic mappings with probabilistic
sampling over continuous luminance layers. A diffusion forward process is
designed to autonomously discover optimal transition paths between luminance
layers, achieving unsupervised distribution emulation without normal-light
references. In this way, it considerably improves the performance in practical
situations, enabling more adaptable and versatile light restoration. This
framework is also readily applicable to cases with normal-light references,
where it achieves superior performance on domain-specific datasets alongside
better generalization-ability across non-reference datasets.

</details>


### [163] [NSYNC: Negative Synthetic Image Generation for Contrastive Training to Improve Stylized Text-To-Image Translation](https://arxiv.org/abs/2511.01517)
*Serkan Ozturk,Samet Hicsonmez,Pinar Duygulu*

Main category: cs.CV

TL;DR: NSYNC通过对比学习框架，利用负样本合成数据和梯度正交化方法，显著提升了文本到图像扩散模型的风格化能力。


<details>
  <summary>Details</summary>
Motivation: 现有文本条件图像生成方法在捕捉特定风格上表现不佳，即使微调也难以掌握风格特征。受合成数据在计算机视觉任务中广泛应用的启发，本研究探索了利用合成数据提升风格化能力的方法。

Method: 提出了一种新颖的对比学习框架NSYNC，通过生成负样本合成数据集，并结合真实正样本进行对比训练，利用梯度正交化方法优化模型参数更新。

Result: 实验表明，NSYNC在多种画家和插画师风格上均优于基线方法，定量和定性评估均显示显著改进。

Conclusion: 通过对比学习框架NSYNC，文本到图像扩散模型在风格化能力上取得了显著提升，特别是在消除共有关联属性和捕捉独特风格方面表现优异。

Abstract: Current text conditioned image generation methods output realistic looking
images, but they fail to capture specific styles. Simply finetuning them on the
target style datasets still struggles to grasp the style features. In this
work, we present a novel contrastive learning framework to improve the
stylization capability of large text-to-image diffusion models. Motivated by
the astonishing advance in image generation models that makes synthetic data an
intrinsic part of model training in various computer vision tasks, we exploit
synthetic image generation in our approach. Usually, the generated synthetic
data is dependent on the task, and most of the time it is used to enlarge the
available real training dataset. With NSYNC, alternatively, we focus on
generating negative synthetic sets to be used in a novel contrastive training
scheme along with real positive images. In our proposed training setup, we
forward negative data along with positive data and obtain negative and positive
gradients, respectively. We then refine the positive gradient by subtracting
its projection onto the negative gradient to get the orthogonal component,
based on which the parameters are updated. This orthogonal component eliminates
the trivial attributes that are present in both positive and negative data and
directs the model towards capturing a more unique style. Experiments on various
styles of painters and illustrators show that our approach improves the
performance over the baseline methods both quantitatively and qualitatively.
Our code is available at https://github.com/giddyyupp/NSYNC.

</details>


### [164] [PCD-ReID: Occluded Person Re-Identification for Base Station Inspection](https://arxiv.org/abs/2511.01546)
*Ge Gao,Zishuo Gao,Hongyan Cui,Zhiyang Jia,Zhuang Luo,ChaoPeng Liu*

Main category: cs.CV

TL;DR: 提出PCD-ReID算法，通过Transformer网络提取共享特征并采用新数据集训练，显著提升遮挡行人重识别性能。


<details>
  <summary>Details</summary>
Motivation: 基站环境中的遮挡行人重识别（ReID）是计算机视觉中的关键任务，传统ResNet-based方法无法有效解决遮挡问题，需要新的ReID方法。

Method: 设计了基于Transformer的PCD网络，能够提取共享组件特征（如头盔和制服），并收集了新的真实世界巡逻监控图像进行模型训练。

Result: 模型实现了79.0%的平均精度（mAP）和82.7%的Rank-1准确率，相比基于ResNet50的方法提升了15.9%的Rank-1准确率。

Conclusion: PCD-ReID算法在塔式巡检场景中有效实现了遮挡感知的行人重识别性能，展示了其在监控和安全应用中的实际部署潜力。

Abstract: Occluded pedestrian re-identification (ReID) in base station environments is
a critical task in computer vision, particularly for surveillance and security
applications. This task faces numerous challenges, as occlusions often obscure
key body features, increasing the complexity of identification. Traditional
ResNet-based ReID algorithms often fail to address occlusions effectively,
necessitating new ReID methods. We propose the PCD-ReID (Pedestrian Component
Discrepancy) algorithm to address these issues. The contributions of this work
are as follows: To tackle the occlusion problem, we design a Transformer-based
PCD network capable of extracting shared component features, such as helmets
and uniforms. To mitigate overfitting on public datasets, we collected new
real-world patrol surveillance images for model training, covering six months,
10,000 individuals, and over 50,000 images. Comparative experiments with
existing ReID algorithms demonstrate that our model achieves a mean Average
Precision (mAP) of 79.0% and a Rank-1 accuracy of 82.7%, marking a 15.9% Rank-1
improvement over ResNet50-based methods. Experimental evaluations indicate that
PCD-ReID effectively achieves occlusion-aware ReID performance for personnel in
tower inspection scenarios, highlighting its potential for practical deployment
in surveillance and security applications.

</details>


### [165] [NOA: a versatile, extensible tool for AI-based organoid analysis](https://arxiv.org/abs/2511.01549)
*Mikhail Konov,Lion J. Gleiter,Khoa Co,Monica Yabal,Tingying Peng*

Main category: cs.CV

TL;DR: NOA是一个通用的图形用户界面工具，旨在简化基于AI的类器官图像分析，集成多种功能模块，并通过案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的AI工具对缺乏编程经验的生物学家来说难以使用，且多数工具仅专注于特定任务。

Method: NOA集成了检测、分割、追踪、特征提取、自定义特征注释和基于ML的特征预测模块，并与多种先进算法接口，作为开源napari插件实现。

Result: 通过三个案例研究（类器官分化形态变化量化、光毒性效应评估、类器官活性和分化状态预测），展示了NOA的多功能性和实用性。

Conclusion: NOA提供了一个灵活且可扩展的框架，使生物学家能够轻松进行AI驱动的类器官图像分析。

Abstract: AI tools can greatly enhance the analysis of organoid microscopy images, from
detection and segmentation to feature extraction and classification. However,
their limited accessibility to biologists without programming experience
remains a major barrier, resulting in labor-intensive and largely manual
workflows. Although a few AI models for organoid analysis have been developed,
most existing tools remain narrowly focused on specific tasks. In this work, we
introduce the Napari Organoid Analyzer (NOA), a general purpose graphical user
interface to simplify AI-based organoid analysis. NOA integrates modules for
detection, segmentation, tracking, feature extraction, custom feature
annotation and ML-based feature prediction. It interfaces multiple
state-of-the-art algorithms and is implemented as an open-source napari plugin
for maximal flexibility and extensibility. We demonstrate the versatility of
NOA through three case studies, involving the quantification of morphological
changes during organoid differentiation, assessment of phototoxicity effects,
and prediction of organoid viability and differentiation state. Together, these
examples illustrate how NOA enables comprehensive, AI-driven organoid image
analysis within an accessible and extensible framework.

</details>


### [166] [Generative Adversarial Synthesis and Deep Feature Discrimination of Brain Tumor MRI Images](https://arxiv.org/abs/2511.01574)
*Md Sumon Ali,Muzammil Behzad*

Main category: cs.CV

TL;DR: 使用DC-GAN生成合成MRI数据，并通过CNN验证其在脑肿瘤分类中的有效性，结果与真实数据相当。


<details>
  <summary>Details</summary>
Motivation: 由于原始MRI数据有限，生成逼真的医学图像具有挑战性，因此需要利用深度学习技术（如GAN）来生成合成医学图像。

Method: 提出了一种基于深度卷积生成对抗网络（DC-GAN）的方法来生成合成MRI数据，并利用卷积神经网络（CNN）分类器对合成数据和真实MRI数据进行脑肿瘤分类。

Result: 分类结果表明，合成图像与真实图像在性能上相当，证明了GAN生成图像的质量和实用性。

Conclusion: 使用DC-GAN生成的合成MRI数据在脑肿瘤分类任务中表现出与真实数据相当的性能，验证了GAN生成图像在下游任务中的有效性。

Abstract: Compared to traditional methods, Deep Learning (DL) becomes a key technology
for computer vision tasks. Synthetic data generation is an interesting use case
for DL, especially in the field of medical imaging such as Magnetic Resonance
Imaging (MRI). The need for this task since the original MRI data is limited.
The generation of realistic medical images is completely difficult and
challenging. Generative Adversarial Networks (GANs) are useful for creating
synthetic medical images. In this paper, we propose a DL based methodology for
creating synthetic MRI data using the Deep Convolutional Generative Adversarial
Network (DC-GAN) to address the problem of limited data. We also employ a
Convolutional Neural Network (CNN) classifier to classify the brain tumor using
synthetic data and real MRI data. CNN is used to evaluate the quality and
utility of the synthetic images. The classification result demonstrates
comparable performance on real and synthetic images, which validates the
effectiveness of GAN-generated images for downstream tasks.

</details>


### [167] [Wave-Particle (Continuous-Discrete) Dualistic Visual Tokenization for Unified Understanding and Generation](https://arxiv.org/abs/2511.01593)
*Yizhu Chen,Chen Ju,Zhicheng Wang,Shuai Xiao,Xu Chen,Jinsong Lan,Xiaoyong Zhu,Ying Chen*

Main category: cs.CV

TL;DR: CDD-VT结合连续和离散视觉标记化的优点，通过自适应基元分配提升多模态大模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决连续和离散视觉标记化之间的对立问题，避免信息丢失和性能下降。

Method: 设计了多样化量化基元和动态基元分配器，根据样本复杂性自适应分配基元数量。

Result: 在重建、检索和分类任务上表现优于专用CT和DT，实现了简洁且可扩展的MLLM。

Conclusion: CDD-VT通过结合连续和离散视觉标记化的优势，提出了一种灵活的双重视觉标记器，显著提升了多模态大模型的性能和简洁性。

Abstract: The unification of understanding and generation within a single multi-modal
large model (MLLM) remains one significant challenge, largely due to the
dichotomy between continuous and discrete visual tokenizations. Continuous
tokenizer (CT) achieves strong performance by bridging multiple
independently-trained understanding modules and generation modules, but suffers
from complex multi-stage pipelines and substantial engineering overhead.
Conversely, discrete tokenizers (DT) offer a conceptually elegant idea by
quantizing each image into a primitive, but inevitably leading to information
loss and performance degradation. To resolve this tension, we question the
binary choice between CT and DT, inspired by the wave-particle duality of
light, and propose the Continuous-Discrete Dualistic Visual Tokenizer (CDD-VT).
We treat visual data as a flexible composition of image primitives derived from
quantized codebooks, with the crucial insight that the primitive number
assigned to each visual sample is adaptively determined according to its
complexity: simple instances use a few primitives, emulating discrete
tokenization, while complex instances use many, approximating continuous
tokenization. Two core components are designed: Diverse Quantitative
Primitives, which encourage primitives orthogonality to better populate
information space, and Dynamic Primitive Allocator, which assesses sample
complexity to determine the optimal set of primitives. Extensive experiments on
reconstruction, retrieval and classification show that CDD-VT achieves superior
performance over to specialized CT and DT, effectively getting strong result
within a concise and scalable MLLM.

</details>


### [168] [Lite ENSAM: a lightweight cancer segmentation model for 3D Computed Tomography](https://arxiv.org/abs/2511.01600)
*Agnar Martin Bjørnstad,Elias Stenhede,Arian Ranjbar*

Main category: cs.CV

TL;DR: Lite ENSAM 是一种轻量级方法，通过自动体积分割解决 RECIST 标准的手动标注问题，并在竞赛中表现良好。


<details>
  <summary>Details</summary>
Motivation: 当前临床广泛使用的 RECIST v1.1 标准仅测量肿瘤最长直径，而体积测量能更可靠评估治疗效果，但手动标注耗时。Lite ENSAM 旨在解决这一问题。

Method: Lite ENSAM 是基于 ENSAM 架构的轻量级适配版本，专门设计用于从带有 RECIST 标注的 CT 扫描中高效进行体积肿瘤分割。

Result: 在 MICCAI FLARE 2025 竞赛中，Lite ENSAM 的 Dice 相似系数为 60.7%，归一化表面 Dice 为 63.6%，平均 RAM 使用为 50.6 GB，CPU 推理时间为 14.4 秒。

Conclusion: Lite ENSAM 是一种高效的体积肿瘤分割方法，能够在临床环境中实现自动化肿瘤体积测量，克服了传统 RECIST 方法的局限性。

Abstract: Accurate tumor size measurement is a cornerstone of evaluating cancer
treatment response. The most widely adopted standard for this purpose is the
Response Evaluation Criteria in Solid Tumors (RECIST) v1.1, which relies on
measuring the longest tumor diameter in a single plane. However, volumetric
measurements have been shown to provide a more reliable assessment of treatment
effect. Their clinical adoption has been limited, though, due to the
labor-intensive nature of manual volumetric annotation. In this paper, we
present Lite ENSAM, a lightweight adaptation of the ENSAM architecture designed
for efficient volumetric tumor segmentation from CT scans annotated with RECIST
annotations. Lite ENSAM was submitted to the MICCAI FLARE 2025 Task 1:
Pan-cancer Segmentation in CT Scans, Subtask 2, where it achieved a Dice
Similarity Coefficient (DSC) of 60.7% and a Normalized Surface Dice (NSD) of
63.6% on the hidden test set, and an average total RAM time of 50.6 GBs and an
average inference time of 14.4 s on CPU on the public validation dataset.

</details>


### [169] [Benchmark-Ready 3D Anatomical Shape Classification](https://arxiv.org/abs/2511.01613)
*Tomáš Krsička,Tibor Kubík*

Main category: cs.CV

TL;DR: 提出PSPooling方法和MedShapeNet19数据集，提升3D解剖形状分类性能，为医学3D形状学习建立基准。


<details>
  <summary>Details</summary>
Motivation: 解剖3D形状分类的进展受限于网格数据的复杂性和标准化基准的缺乏，需开发鲁棒的学习方法和可复现的评估标准。

Method: 提出了一种非学习的网格池化操作符PSPooling，基于几何邻近性预计算节点对应集，实现并行化和可逆的池化与反池化操作；并集成到自监督图自动编码器中，学习解剖感知表示。

Result: 实验证明PSPooling在低标签情况下显著提升重建保真度和分类准确性，MedShapeNet19成为医学3D形状分析的广泛采用基准。

Conclusion: 本文提出了PSPooling方法，显著提升了3D解剖形状分类的重建保真度和分类准确性，并建立了MedShapeNet19作为标准化基准数据集，为医学3D形状学习提供了坚实基础。

Abstract: Progress in anatomical 3D shape classification is limited by the complexity
of mesh data and the lack of standardized benchmarks, highlighting the need for
robust learning methods and reproducible evaluation. We introduce two key steps
toward clinically and benchmark-ready anatomical shape classification via
self-supervised graph autoencoding. We propose Precomputed Structural Pooling
(PSPooling), a non-learnable mesh pooling operator designed for efficient and
structure-preserving graph coarsening in 3D anatomical shape analysis.
PSPooling precomputes node correspondence sets based on geometric proximity,
enabling parallelizable and reversible pooling and unpooling operations with
guaranteed support structure. This design avoids the sparsity and
reconstruction issues of selection-based methods and the sequential overhead of
edge contraction approaches, making it particularly suitable for
high-resolution medical meshes. To demonstrate its effectiveness, we integrate
PSPooling into a self-supervised graph autoencoder that learns anatomy-aware
representations from unlabeled surface meshes. We evaluate the downstream
benefits on MedShapeNet19, a new curated benchmark dataset we derive from
MedShapeNet, consisting of 19 anatomical classes with standardized training,
validation, and test splits. Experiments show that PSPooling significantly
improves reconstruction fidelity and classification accuracy in low-label
regimes, establishing a strong baseline for medical 3D shape learning. We hope
that MedShapeNet19 will serve as a widely adopted benchmark for anatomical
shape classification and further research in medical 3D shape analysis. Access
the complete codebase, model weights, and dataset information here:
https://github.com/TomasKrsicka/MedShapeNet19-PSPooling.

</details>


### [170] [Vote-in-Context: Turning VLMs into Zero-Shot Rank Fusers](https://arxiv.org/abs/2511.01617)
*Mohamed Eltahir,Ali Habibullah,Lama Ayash,Tanveer Hussain,Naeemullah Khan*

Main category: cs.CV

TL;DR: ViC是一个无需训练的框架，通过零样本推理任务重新定义异构检索器的候选融合，显著提升了跨模态视频检索性能，并在多个基准测试中实现了最先进的零样本检索效果。


<details>
  <summary>Details</summary>
Motivation: 异构检索器的候选融合是一个长期存在的挑战，尤其是在处理复杂的多模态数据（如视频）时。现有的融合技术仅依赖排名或分数信号，忽略了候选的表示。

Method: ViC是一个无需训练的框架，通过将内容证据和检索器元数据序列化到VLM的提示中，使模型能够自适应地权衡检索器共识与视觉-语言内容。S-Grid作为一种紧凑的序列化地图，用于表示视频候选。

Result: ViC在MSR-VTT和VATEX等视频检索基准测试中实现了显著的性能提升，Recall@1分数分别达到87.1%（t2v）/89.0%（v2t）和99.6%（v2t），比之前的最先进基线提高了高达+40 Recall@1。

Conclusion: ViC框架通过将异构检索器的候选结果融合任务重新定义为零样本推理任务，显著提升了跨模态视频检索的性能，并在多个基准测试中实现了最先进的零样本检索效果。

Abstract: In the retrieval domain, candidates' fusion from heterogeneous retrievers is
a long-standing challenge, particularly for complex, multi-modal data such as
videos. While typical fusion techniques are training-free, they rely solely on
rank or score signals, disregarding candidates' representations. This work
introduces Vote-in-Context (ViC), a generalized, training-free framework that
re-thinks list-wise reranking and fusion as a zero-shot reasoning task for a
Vision-Language Model (VLM). The core insight is to serialize both content
evidence and retriever metadata directly within the VLM's prompt, allowing the
model to adaptively weigh retriever consensus against visual-linguistic
content. We demonstrate the generality of this framework by applying it to the
challenging domain of cross-modal video retrieval. To this end, we introduce
the S-Grid, a compact serialization map that represents each video as an image
grid, optionally paired with subtitles to enable list-wise reasoning over video
candidates. ViC is evaluated both as a single-list reranker, where it
dramatically improves the precision of individual retrievers, and as an
ensemble fuser, where it consistently outperforms strong baselines like
CombSUM. Across video retrieval benchmarks including ActivityNet and VATEX, the
framework establishes new state-of-the-art zero-shot retrieval performance,
demonstrating its effectiveness in handling complex visual and temporal signals
alongside text. In zero-shot settings, ViC achieves Recall@1 scores of 87.1%
(t2v) / 89.0% (v2t) on MSR-VTT and 99.6% (v2t) on VATEX, representing massive
gains of up to +40 Recall@1 over previous state-of-the-art baselines. We
present ViC as a simple, reproducible, and highly effective recipe for turning
modern VLMs into powerful zero-shot rerankers and fusers. Code and resources
are publicly available at: https://github.com/mohammad2012191/ViC

</details>


### [171] [Actial: Activate Spatial Reasoning Ability of Multimodal Large Language Models](https://arxiv.org/abs/2511.01618)
*Xiaoyu Zhan,Wenxuan Huang,Hao Sun,Xinyu Fu,Changfeng Ma,Shaosheng Cao,Bohan Jia,Shaohui Lin,Zhenfei Yin,Lei Bai,Wanli Ouyang,Yuanqi Li,Jie Guo,Yanwen Guo*

Main category: cs.CV

TL;DR: 本文提出了Viewpoint Learning任务和Viewpoint-100K数据集，通过两阶段微调策略显著提升了MLLMs的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs是否能够有效捕捉复杂3D推理任务所需的详细空间信息，尤其是跨视图一致性这一关键要求。

Method: 采用两阶段微调策略：首先通过监督微调（SFT）在Viewpoint-100K数据集上注入基础知识；其次通过强化学习（GRPO算法）增强泛化能力。此外，引入混合冷启动初始化方法。

Result: 实验结果表明，该方法显著激活了MLLM的空间推理能力，提高了域内和域外推理任务的性能。

Conclusion: 本文的研究强调了在MLLMs中发展基础空间技能的价值，为机器人、自主系统和3D场景理解的未来进展提供了支持。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have
significantly improved 2D visual understanding, prompting interest in their
application to complex 3D reasoning tasks. However, it remains unclear whether
these models can effectively capture the detailed spatial information required
for robust real-world performance, especially cross-view consistency, a key
requirement for accurate 3D reasoning. Considering this issue, we introduce
Viewpoint Learning, a task designed to evaluate and improve the spatial
reasoning capabilities of MLLMs. We present the Viewpoint-100K dataset,
consisting of 100K object-centric image pairs with diverse viewpoints and
corresponding question-answer pairs. Our approach employs a two-stage
fine-tuning strategy: first, foundational knowledge is injected to the baseline
MLLM via Supervised Fine-Tuning (SFT) on Viewpoint-100K, resulting in
significant improvements across multiple tasks; second, generalization is
enhanced through Reinforcement Learning using the Group Relative Policy
Optimization (GRPO) algorithm on a broader set of questions. Additionally, we
introduce a hybrid cold-start initialization method designed to simultaneously
learn viewpoint representations and maintain coherent reasoning thinking.
Experimental results show that our approach significantly activates the spatial
reasoning ability of MLLM, improving performance on both in-domain and
out-of-domain reasoning tasks. Our findings highlight the value of developing
foundational spatial skills in MLLMs, supporting future progress in robotics,
autonomous systems, and 3D scene understanding.

</details>


### [172] [Enhancing Diffusion-based Restoration Models via Difficulty-Adaptive Reinforcement Learning with IQA Reward](https://arxiv.org/abs/2511.01645)
*Xiaogang Xu,Ruihang Chu,Jian Wang,Kun Zhou,Wenjie Shu,Harry Yang,Ser-Nam Lim,Hao Chen,Liang Lin*

Main category: cs.CV

TL;DR: 论文提出了一种动态结合RL和SFT的策略，利用IQA模型生成奖励，显著提升了扩散模型在图像修复任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的RL方法直接应用于基于扩散的图像修复模型效果不佳，因为修复任务更强调保真度而非纯生成。本文旨在探索如何有效将RL整合到扩散修复模型中。

Method: 研究首先通过实验确定了从IQA模型而非直观的基于ground-truth的监督中获取有效奖励的策略。随后，采用MLLM-based IQA模型实现了RL的分布对齐，并结合SFT进行细粒度调整。通过自动加权策略动态调整训练样本的难度。

Result: 实验证明，所提出的RL框架能无缝应用于扩散修复模型，在多种修复任务中提升了性能。

Conclusion: 论文提出了一种创新的强化学习（RL）框架，通过动态结合监督微调（SFT）和基于图像质量评估（IQA）模型的奖励策略，显著提升了基于扩散模型的图像修复任务的性能。

Abstract: Reinforcement Learning (RL) has recently been incorporated into diffusion
models, e.g., tasks such as text-to-image. However, directly applying existing
RL methods to diffusion-based image restoration models is suboptimal, as the
objective of restoration fundamentally differs from that of pure generation: it
places greater emphasis on fidelity. In this paper, we investigate how to
effectively integrate RL into diffusion-based restoration models. First,
through extensive experiments with various reward functions, we find that an
effective reward can be derived from an Image Quality Assessment (IQA) model,
instead of intuitive ground-truth-based supervision, which has already been
optimized during the Supervised Fine-Tuning (SFT) stage prior to RL. Moreover,
our strategy focuses on using RL for challenging samples that are significantly
distant from the ground truth, and our RL approach is innovatively implemented
using MLLM-based IQA models to align distributions with high-quality images
initially. As the samples approach the ground truth's distribution, RL is
adaptively combined with SFT for more fine-grained alignment. This dynamic
process is facilitated through an automatic weighting strategy that adjusts
based on the relative difficulty of the training samples. Our strategy is
plug-and-play that can be seamlessly applied to diffusion-based restoration
models, boosting its performance across various restoration tasks. Extensive
experiments across multiple benchmarks demonstrate the effectiveness of our
proposed RL framework.

</details>


### [173] [UniLumos: Fast and Unified Image and Video Relighting with Physics-Plausible Feedback](https://arxiv.org/abs/2511.01678)
*Ropeway Liu,Hangjie Yuan,Bo Dong,Jiazheng Xing,Jinwang Wang,Rui Zhao,Yan Xing,Weihua Chen,Fan Wang*

Main category: cs.CV

TL;DR: UniLumos 是一个统一的图像和视频重光照框架，通过几何反馈和路径一致性学习提升物理一致性和效率，结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在语义潜在空间中优化，导致视觉空间中的物理不正确问题（如过曝高光、阴影错位等），UniLumos 旨在通过 RGB 空间的几何反馈解决这些问题。

Method: UniLumos 采用流匹配主干网络，结合深度和法线图监督，通过路径一致性学习减少计算成本，同时设计了六维标注协议和 LumosBench 基准测试。

Result: UniLumos 在重光照质量和物理一致性上达到最优，同时实现了 20 倍的速度提升，并通过 LumosBench 实现了自动化的评估。

Conclusion: UniLumos 通过引入 RGB 空间的几何反馈和路径一致性学习，显著提升了重光照任务的物理一致性和效率，实现了图像和视频的高质量重光照，并在速度和效果上达到了最先进水平。

Abstract: Relighting is a crucial task with both practical demand and artistic value,
and recent diffusion models have shown strong potential by enabling rich and
controllable lighting effects. However, as they are typically optimized in
semantic latent space, where proximity does not guarantee physical correctness
in visual space, they often produce unrealistic results, such as overexposed
highlights, misaligned shadows, and incorrect occlusions. We address this with
UniLumos, a unified relighting framework for both images and videos that brings
RGB-space geometry feedback into a flow matching backbone. By supervising the
model with depth and normal maps extracted from its outputs, we explicitly
align lighting effects with the scene structure, enhancing physical
plausibility. Nevertheless, this feedback requires high-quality outputs for
supervision in visual space, making standard multi-step denoising
computationally expensive. To mitigate this, we employ path consistency
learning, allowing supervision to remain effective even under few-step training
regimes. To enable fine-grained relighting control and supervision, we design a
structured six-dimensional annotation protocol capturing core illumination
attributes. Building upon this, we propose LumosBench, a disentangled
attribute-level benchmark that evaluates lighting controllability via large
vision-language models, enabling automatic and interpretable assessment of
relighting precision across individual dimensions. Extensive experiments
demonstrate that UniLumos achieves state-of-the-art relighting quality with
significantly improved physical consistency, while delivering a 20x speedup for
both image and video relighting. Code is available at
https://github.com/alibaba-damo-academy/Lumos-Custom.

</details>


### [174] [Progressive Translation of H&E to IHC with Enhanced Structural Fidelity](https://arxiv.org/abs/2511.01698)
*Yuhang Kang,Ziyu Su,Tianyang Wang,Zaibo Li,Wei Chen,Muhammad Khalid Khan Niazi*

Main category: cs.CV

TL;DR: 提出一种渐进式网络架构，通过优化结构、颜色和细胞边界生成，显著提高IHC等效图像的视觉质量和结构细节。


<details>
  <summary>Details</summary>
Motivation: 免疫组化（IHC）成本高、耗时长，且多路复用受限。计算染色转换技术可从H&E切片合成IHC等效图像，但现有方法因忽略组件间的相互依赖导致图像质量不佳。

Method: 基于Adaptive Supervised PatchNCE框架，引入额外的损失函数（基于DAB显色剂浓度和图像梯度），采用结构-颜色-细胞边界的渐进机制。

Result: 在HER2和ER数据集上的实验表明，模型显著提升了生成图像的视觉质量和结构细节。

Conclusion: 通过提出的渐进式网络架构，模型显著提高了视觉质量，并实现了更精细的结构细节。

Abstract: Compared to hematoxylin-eosin (H&E) staining, immunohistochemistry (IHC) not
only maintains the structural features of tissue samples, but also provides
high-resolution protein localization, which is essential for aiding in
pathology diagnosis. Despite its diagnostic value, IHC remains a costly and
labor-intensive technique. Its limited scalability and constraints in
multiplexing further hinder widespread adoption, especially in resource-limited
settings. Consequently, researchers are increasingly exploring computational
stain translation techniques to synthesize IHC-equivalent images from
H&E-stained slides, aiming to extract protein-level information more
efficiently and cost-effectively. However, most existing stain translation
techniques rely on a linearly weighted summation of multiple loss terms within
a single objective function, strategy that often overlooks the interdepedence
among these components-resulting in suboptimal image quality and an inability
to simultaneously preserve structural authenticity and color fidelity. To
address this limitation, we propose a novel network architecture that follows a
progressive structure, incorporating color and cell border generation logic,
which enables each visual aspect to be optimized in a stage-wise and decoupled
manner. To validate the effectiveness of our proposed network architecture, we
build upon the Adaptive Supervised PatchNCE (ASP) framework as our baseline. We
introduce additional loss functions based on 3,3'-diaminobenzidine (DAB)
chromogen concentration and image gradient, enhancing color fidelity and cell
boundary clarity in the generated IHC images. By reconstructing the generation
pipeline using our structure-color-cell boundary progressive mechanism,
experiments on HER2 and ER datasets demonstrated that the model significantly
improved visual quality and achieved finer structural details.

</details>


### [175] [Learnable Fractional Reaction-Diffusion Dynamics for Under-Display ToF Imaging and Beyond](https://arxiv.org/abs/2511.01704)
*Xin Qiao,Matteo Poggi,Xing Wei,Pengchao Deng,Yanhui Zhou,Stefano Mattoccia*

Main category: cs.CV

TL;DR: LFRD2结合神经网络与物理建模，优化TOLED层下的深度感知质量。


<details>
  <summary>Details</summary>
Motivation: TOLED层导致的信号衰减、多路径干扰和时域噪声严重影响了深度感知质量，需一种混合方法来解决。

Method: 提出了LFRD2框架，包括时间分数阶反应扩散模块和高效连续卷积算子，实现动态生成微分阶数的深度迭代优化。

Result: 在四个基准数据集上的实验验证了LFRD2的有效性。

Conclusion: LFRD2框架通过结合神经网络的表达能力和物理建模的可解释性，有效解决了TOLED层引起的信号衰减、多路径干扰和时域噪声问题，显著提升了深度感知质量。

Abstract: Under-display ToF imaging aims to achieve accurate depth sensing through a
ToF camera placed beneath a screen panel. However, transparent OLED (TOLED)
layers introduce severe degradations-such as signal attenuation, multi-path
interference (MPI), and temporal noise-that significantly compromise depth
quality. To alleviate this drawback, we propose Learnable Fractional
Reaction-Diffusion Dynamics (LFRD2), a hybrid framework that combines the
expressive power of neural networks with the interpretability of physical
modeling. Specifically, we implement a time-fractional reaction-diffusion
module that enables iterative depth refinement with dynamically generated
differential orders, capturing long-term dependencies. In addition, we
introduce an efficient continuous convolution operator via coefficient
prediction and repeated differentiation to further improve restoration quality.
Experiments on four benchmark datasets demonstrate the effectiveness of our
approach. The code is publicly available at https://github.com/wudiqx106/LFRD2.

</details>


### [176] [Probabilistic Robustness for Free? Revisiting Training via a Benchmark](https://arxiv.org/abs/2511.01724)
*Yi Zhang,Zheng Wang,Chen Zhen,Wenjie Ruan,Qing Guo,Siddartha Khastgir,Carsten Maple,Xingyu Zhao*

Main category: cs.CV

TL;DR: PRBench是首个评估PR改进的基准，发现AT方法在提升AR和PR上更通用，PR-targeted方法在泛化和准确率上更优。


<details>
  <summary>Details</summary>
Motivation: 现有PR-targeted训练方法存在评估协议不可比、与强AT基线对比不足、缺乏统一框架比较泛化性能的问题，需要系统性评估。

Method: 引入PRBench，首个专注于评估不同鲁棒性训练方法对PR改进的基准，包括干净准确率、PR和AR性能、训练效率和泛化误差等多维度比较。

Result: AT方法在多样化超参数设置下提升AR和PR性能表现更优，PR-targeted方法则具有更低泛化误差和更高干净准确率。

Conclusion: AT方法在提升AR和PR性能方面比PR-targeted训练方法更具通用性，而PR-targeted训练方法在泛化误差和干净准确率方面表现更优。

Abstract: Deep learning models are notoriously vulnerable to imperceptible
perturbations. Most existing research centers on adversarial robustness (AR),
which evaluates models under worst-case scenarios by examining the existence of
deterministic adversarial examples (AEs). In contrast, probabilistic robustness
(PR) adopts a statistical perspective, measuring the probability that
predictions remain correct under stochastic perturbations. While PR is widely
regarded as a practical complement to AR, dedicated training methods for
improving PR are still relatively underexplored, albeit with emerging progress.
Among the few PR-targeted training methods, we identify three limitations: i
non-comparable evaluation protocols; ii limited comparisons to strong AT
baselines despite anecdotal PR gains from AT; and iii no unified framework to
compare the generalization of these methods. Thus, we introduce PRBench, the
first benchmark dedicated to evaluating improvements in PR achieved by
different robustness training methods. PRBench empirically compares most common
AT and PR-targeted training methods using a comprehensive set of metrics,
including clean accuracy, PR and AR performance, training efficiency, and
generalization error (GE). We also provide theoretical analysis on the GE of PR
performance across different training methods. Main findings revealed by
PRBench include: AT methods are more versatile than PR-targeted training
methods in terms of improving both AR and PR performance across diverse
hyperparameter settings, while PR-targeted training methods consistently yield
lower GE and higher clean accuracy. A leaderboard comprising 222 trained models
across 7 datasets and 10 model architectures is publicly available at
https://tmpspace.github.io/PRBenchLeaderboard/.

</details>


### [177] [Toward Strategy Identification and Subtask Decomposition In Task Exploration](https://arxiv.org/abs/2511.01728)
*Tom Odem*

Main category: cs.CV

TL;DR: 研究开发了任务探索管道，通过聚类和因子分析识别用户策略，帮助机器理解用户行为。


<details>
  <summary>Details</summary>
Motivation: 提升机器对用户知识、技能和行为的理解，以实现隐式协调。

Method: 采用聚类技术、因子分析和字符串编辑距离，开发了任务探索管道，自动识别完成任务的关键全局和局部策略。

Result: 任务探索管道成功识别了关键策略，并将用户行为编码为层次化的子任务结构。

Conclusion: 该研究开发的任务探索管道和应用能够有效识别用户完成任务的关键策略，并帮助人类和机器理解用户的知识、技能和行为。

Abstract: This research builds on work in anticipatory human-machine interaction, a
subfield of human-machine interaction where machines can facilitate
advantageous interactions by anticipating a user's future state. The aim of
this research is to further a machine's understanding of user knowledge, skill,
and behavior in pursuit of implicit coordination. A task explorer pipeline was
developed that uses clustering techniques, paired with factor analysis and
string edit distance, to automatically identify key global and local strategies
that are used to complete tasks. Global strategies identify generalized sets of
actions used to complete tasks, while local strategies identify sequences that
used those sets of actions in a similar composition. Additionally, meaningful
subtasks of various lengths are identified within the tasks. The task explorer
pipeline was able to automatically identify key strategies used to complete
tasks and encode user runs with hierarchical subtask structures. In addition, a
Task Explorer application was developed to easily review pipeline results. The
task explorer pipeline can be easily modified to any action-based time-series
data and the identified strategies and subtasks help to inform humans and
machines on user knowledge, skill, and behavior.

</details>


### [178] [CGF-DETR: Cross-Gated Fusion DETR for Enhanced Pneumonia Detection in Chest X-rays](https://arxiv.org/abs/2511.01730)
*Yefeng Wu,Yucheng Song,Ling Wu,Shan Wan,Yecheng Zhao*

Main category: cs.CV

TL;DR: CGF-DETR是一种针对肺炎检测的实时Transformer模型，通过多尺度特征提取和动态门控机制优化性能，显著超越基线模型。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球发病率和死亡率的主要原因，需要高效准确的自动化检测系统。现有的基于Transformer的检测器在医疗影像中的应用尚未充分探索。

Method: 提出了CGF-DETR模型，结合了XFABlock（用于多尺度特征提取）、SPGA模块（动态门控机制替代多头注意力）和GCFC3（多路径卷积融合）。

Result: 在RSNA肺炎检测数据集上，CGF-DETR达到82.2% mAP@0.5，比基线RT-DETR-l提升3.7%，推理速度保持48.1 FPS。

Conclusion: CGF-DETR在肺炎检测任务中表现出色，通过引入XFABlock、SPGA模块和GCFC3等创新设计，显著提升了检测性能，同时保持了实时性。

Abstract: Pneumonia remains a leading cause of morbidity and mortality worldwide,
necessitating accurate and efficient automated detection systems. While recent
transformer-based detectors like RT-DETR have shown promise in object detection
tasks, their application to medical imaging, particularly pneumonia detection
in chest X-rays, remains underexplored. This paper presents CGF-DETR, an
enhanced real-time detection transformer specifically designed for pneumonia
detection. We introduce XFABlock in the backbone to improve multi-scale feature
extraction through convolutional attention mechanisms integrated with CSP
architecture. To achieve efficient feature aggregation, we propose SPGA module
that replaces standard multi-head attention with dynamic gating mechanisms and
single-head self-attention. Additionally, GCFC3 is designed for the neck to
enhance feature representation through multi-path convolution fusion while
maintaining real-time performance via structural re-parameterization. Extensive
experiments on the RSNA Pneumonia Detection dataset demonstrate that CGF-DETR
achieves 82.2\% mAP@0.5, outperforming the baseline RT-DETR-l by 3.7\% while
maintaining comparable inference speed at 48.1 FPS. Our ablation studies
confirm that each proposed module contributes meaningfully to the overall
performance improvement, with the complete model achieving 50.4\%
mAP@[0.5:0.95]

</details>


### [179] [HGFreNet: Hop-hybrid GraphFomer for 3D Human Pose Estimation with Trajectory Consistency in Frequency Domain](https://arxiv.org/abs/2511.01756)
*Kai Zhai,Ziyan Huang,Qiang Nie,Xiang Li,Bo Ouyang*

Main category: cs.CV

TL;DR: HGFreNet结合跳数混合图注意力和频域轨迹一致性，提升3D人体姿态估计的准确性和连贯性。


<details>
  <summary>Details</summary>
Motivation: 解决2D到3D姿态提升中的深度模糊性和2D姿态估计误差导致的3D轨迹不连贯问题，全局时空相关性未被充分探索。

Method: 提出了一种新颖的GraphFormer架构，包含跳数混合图注意力（HGA）模块和Transformer编码器，用于建模全局关节时空相关性，并在频域约束轨迹一致性。

Result: 在Human3.6M和MPI-INF-3DHP基准测试中，HGFreNet在位置准确性和时间一致性上优于现有方法。

Conclusion: HGFreNet通过结合跳数混合特征聚合和频域轨迹一致性，在3D人体姿态估计中实现了更高的位置准确性和时间一致性，优于现有最先进方法。

Abstract: 2D-to-3D human pose lifting is a fundamental challenge for 3D human pose
estimation in monocular video, where graph convolutional networks (GCNs) and
attention mechanisms have proven to be inherently suitable for encoding the
spatial-temporal correlations of skeletal joints. However, depth ambiguity and
errors in 2D pose estimation lead to incoherence in the 3D trajectory. Previous
studies have attempted to restrict jitters in the time domain, for instance, by
constraining the differences between adjacent frames while neglecting the
global spatial-temporal correlations of skeletal joint motion. To tackle this
problem, we design HGFreNet, a novel GraphFormer architecture with hop-hybrid
feature aggregation and 3D trajectory consistency in the frequency domain.
Specifically, we propose a hop-hybrid graph attention (HGA) module and a
Transformer encoder to model global joint spatial-temporal correlations. The
HGA module groups all $k$-hop neighbors of a skeletal joint into a hybrid group
to enlarge the receptive field and applies the attention mechanism to discover
the latent correlations of these groups globally. We then exploit global
temporal correlations by constraining trajectory consistency in the frequency
domain. To provide 3D information for depth inference across frames and
maintain coherence over time, a preliminary network is applied to estimate the
3D pose. Extensive experiments were conducted on two standard benchmark
datasets: Human3.6M and MPI-INF-3DHP. The results demonstrate that the proposed
HGFreNet outperforms state-of-the-art (SOTA) methods in terms of positional
accuracy and temporal consistency.

</details>


### [180] [UniLION: Towards Unified Autonomous Driving Model with Linear Group RNNs](https://arxiv.org/abs/2511.01768)
*Zhe Liu,Jinghua Hou,Xiaoqing Ye,Jingdong Wang,Hengshuang Zhao,Xiang Bai*

Main category: cs.CV

TL;DR: UniLION是一个统一的自动驾驶模型，通过线性组RNN高效处理多模态数据，无需显式融合模块，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在各领域表现出色，但其二次注意力机制在处理长序列数据时带来显著计算开销，因此需要更高效的模型。

Method: 基于线性组RNN操作符（即对分组特征执行线性RNN），UniLION高效处理大规模LiDAR点云、高分辨率多视角图像和时间序列数据。

Result: UniLION在多种核心任务（如3D感知、预测和规划）中表现优异，甚至达到最先进水平。

Conclusion: UniLION提供了一个统一的自动驾驶模型框架，简化了多模态和多任务系统的设计，同时保持了卓越性能，为3D基础模型的发展提供了新视角。

Abstract: Although transformers have demonstrated remarkable capabilities across
various domains, their quadratic attention mechanisms introduce significant
computational overhead when processing long-sequence data. In this paper, we
present a unified autonomous driving model, UniLION, which efficiently handles
large-scale LiDAR point clouds, high-resolution multi-view images, and even
temporal sequences based on the linear group RNN operator (i.e., performs
linear RNN for grouped features). Remarkably, UniLION serves as a single
versatile architecture that can seamlessly support multiple specialized
variants (i.e., LiDAR-only, temporal LiDAR, multi-modal, and multi-modal
temporal fusion configurations) without requiring explicit temporal or
multi-modal fusion modules. Moreover, UniLION consistently delivers competitive
and even state-of-the-art performance across a wide range of core tasks,
including 3D perception (e.g., 3D object detection, 3D object tracking, 3D
occupancy prediction, BEV map segmentation), prediction (e.g., motion
prediction), and planning (e.g., end-to-end planning). This unified paradigm
naturally simplifies the design of multi-modal and multi-task autonomous
driving systems while maintaining superior performance. Ultimately, we hope
UniLION offers a fresh perspective on the development of 3D foundation models
in autonomous driving. Code is available at
https://github.com/happinesslz/UniLION

</details>


### [181] [PROPEX-RAG: Enhanced GraphRAG using Prompt-Driven Prompt Execution](https://arxiv.org/abs/2511.01802)
*Tejas Sarnaik,Manan Shah,Ravi Hegde*

Main category: cs.CV

TL;DR: 提出了一个提示驱动的GraphRAG框架，通过优化提示设计提升多跳问答的检索和推理性能，取得了SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 尽管基于图的检索在复杂推理方面取得了进展，但提示设计对增强检索和推理过程的影响仍未得到充分研究。

Method: 提出了一种提示驱动的GraphRAG框架，通过将实体和事实关系编码为结构化事实三元组，从文本数据中创建符号知识图。在在线检索过程中，选择性地使用LLMs进行语义过滤和答案生成，并通过个性化PageRank（PPR）实现基于知识图的实体引导图遍历。

Result: 在HotpotQA和2WikiMultiHopQA上取得了最先进的性能，F1分数分别为80.7%和78.9%，Recall@5分数分别为97.1%和98.1%。

Conclusion: 这项研究为更高效和可理解的多跳问答系统奠定了基础，强调了提示感知图推理的重要性。

Abstract: Retrieval-Augmented Generation (RAG) has become a robust framework for
enhancing Large Language Models (LLMs) with external knowledge. Recent advances
in RAG have investigated graph based retrieval for intricate reasoning;
however, the influence of prompt design on enhancing the retrieval and
reasoning process is still considerably under-examined. In this paper, we
present a prompt-driven GraphRAG framework that underscores the significance of
prompt formulation in facilitating entity extraction, fact selection, and
passage reranking for multi-hop question answering. Our approach creates a
symbolic knowledge graph from text data by encoding entities and factual
relationships as structured facts triples. We use LLMs selectively during
online retrieval to perform semantic filtering and answer generation. We also
use entity-guided graph traversal through Personalized PageRank (PPR) to
support efficient, scalable retrieval based on the knowledge graph we built.
Our system gets state-of-the-art performance on HotpotQA and 2WikiMultiHopQA,
with F1 scores of 80.7% and 78.9%, and Recall@5 scores of 97.1% and 98.1%,
respectively. These results show that prompt design is an important part of
improving retrieval accuracy and response quality. This research lays the
groundwork for more efficient and comprehensible multi-hop question-answering
systems, highlighting the importance of prompt-aware graph reasoning.

</details>


### [182] [SciTextures: Collecting and Connecting Visual Patterns, Models, and Code Across Science and Art](https://arxiv.org/abs/2511.01817)
*Sagi Eppel,Alona Strugatski*

Main category: cs.CV

TL;DR: Scitextures数据集收集了来自科学、技术和艺术领域的纹理和视觉模式，用于探索视觉模式与其生成机制之间的联系，并评估AI模型在理解和模拟这些机制方面的能力。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模式与生成机制之间的联系，提升AI对视觉模式深层理解的能力。

Method: 创建了一个包含1200多种模型和10万张图像的Scitextures数据集，使用AI自主收集和标准化实现模型。

Result: 研究表明，视觉语言模型（VLMs）能够理解和模拟超越视觉模式的物理系统。

Conclusion: Scitextures数据集为AI理解和模拟视觉模式背后的机制提供了新的基准和工具。

Abstract: The ability to connect visual patterns with the processes that form them
represents one of the deepest forms of visual understanding. Textures of clouds
and waves, the growth of cities and forests, or the formation of materials and
landscapes are all examples of patterns emerging from underlying mechanisms. We
present the Scitextures dataset, a large-scale collection of textures and
visual patterns from all domains of science, tech, and art, along with the
models and code that generate these images. Covering over 1,200 different
models and 100,000 images of patterns and textures from physics, chemistry,
biology, sociology, technology, mathematics, and art, this dataset offers a way
to explore the connection between the visual patterns that shape our world and
the mechanisms that produce them. Created by an agentic AI pipeline that
autonomously collects and implements models in standardized form, we use
SciTextures to evaluate the ability of leading AI models to link visual
patterns to the models and code that generate them, and to identify different
patterns that emerged from the same process. We also test AIs ability to infer
and recreate the mechanisms behind visual patterns by providing a natural image
of a real-world pattern and asking the AI to identify, model, and code the
mechanism that formed the pattern, then run this code to generate a simulated
image that is compared to the real image. These benchmarks show that
vision-language models (VLMs) can understand and simulate the physical system
beyond a visual pattern. The dataset and code are available at:
https://zenodo.org/records/17485502

</details>


### [183] [TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning](https://arxiv.org/abs/2511.01833)
*Ming Li,Jike Zhong,Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Yuxiang Lai,Wei Chen,Konstantinos Psounis,Kaipeng Zhang*

Main category: cs.CV

TL;DR: TIR-Bench是一个新基准测试，用于评估图像思维能力，结果显示其普遍挑战性且需要真实能力。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能充分捕捉像OpenAI o3这样的模型在图像思维方面的先进能力，因此需要更全面的评估工具。

Method: 介绍了TIR-Bench基准测试，包含13个多样化任务，评估了22种多模态大语言模型（MLLMs）。

Result: TIR-Bench对所有模型都具有挑战性，只有具备真正图像思维能力的模型才能表现优异。

Conclusion: TIR-Bench是一个全面评估图像思维能力的基准测试，结果表明其具有普遍挑战性，且真正需要图像思维能力才能取得强表现。

Abstract: The frontier of visual reasoning is shifting toward models like OpenAI o3,
which can intelligently create and operate tools to transform images for
problem-solving, also known as thinking-\textit{with}-images in
chain-of-thought. Yet existing benchmarks fail to fully capture this advanced
capability. Even Visual Search, the most common benchmark for current
thinking-\textit{with}-images methods, tests only basic operations such as
localization and cropping, offering little insight into more complex, dynamic,
and tool-dependent reasoning. We introduce \textbf{TIR-Bench}, a comprehensive
benchmark for evaluating agentic thinking-with-images across 13 diverse tasks,
each requiring novel tool use for image processing and manipulation in
chain-of-thought. We evaluate 22 multimodal large language models (MLLMs), from
leading open-sourced and proprietary models to those with explicit tool-use
augmentation. Results show that TIR-Bench is universally challenging, and
strong performance requires genuine thinking-with-images capabilities. Finally,
we present a pilot study comparing direct versus agentic fine-tuning.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [184] [Towards Sub-millisecond Latency and Guaranteed Bit Rates in 5G User Plane](https://arxiv.org/abs/2511.00196)
*Leonardo Alberro,Noura Limam,Raouf Boutaba*

Main category: cs.NI

TL;DR: 提出了一种基于可编程传输网络的QoS感知数据平面模型，支持3GPP所有QoS资源类型，实验验证其在关键流量处理上的高效表现。


<details>
  <summary>Details</summary>
Motivation: 5G及未来网络需满足严格的QoS要求，但传统固定功能基础设施无法支持3GPP标准化的多样化和动态QoS配置。

Method: 采用P4语言在Intel Tofino交换机上实现，整合了每流计量、分类、严格优先级调度和延迟感知队列等技术。

Result: 实验结果表明，该模型能确保每流带宽保障、亚毫秒级延迟关键流量处理，并在拥塞下保持弹性。

Conclusion: 该模型通过可编程硬件实现，验证了其在5G及未来网络中支持高敏感QoS应用的可行性，能够提供微秒级延迟和近乎零丢包的关键流量保障。

Abstract: Next-generation services demand stringent Quality of Service (QoS)
guarantees, such as per-flow bandwidth assurance, ultra-low latency, and
traffic prioritization, posing significant challenges to 5G and beyond
networks. As 5G network functions increasingly migrate to edge and central
clouds, the transport layer becomes a critical enabler of end-to-end QoS
compliance. However, traditional fixed-function infrastructure lacks the
flexibility to support the diverse and dynamic QoS profiles standardized by
3GPP.
  This paper presents a QoS-aware data plane model for programmable transport
networks, designed to provide predictable behavior and fine-grained service
differentiation. The model supports all 3GPP QoS resource types and integrates
per-flow metering, classification, strict priority scheduling, and delay-aware
queuing. Implemented on off-the-shelf programmable hardware using P4 and
evaluated on an Intel Tofino switch, our approach ensures per-flow bandwidth
guarantees, sub-millisecond delay for delay-critical traffic, and resilience
under congestion. Experimental results demonstrate that the model achieves
microsecond-level latencies and near-zero packet loss for mission-critical
flows, validating its suitability for future QoS-sensitive applications in 5G
and beyond.

</details>


### [185] [Toward Hybrid COTS-based LiFi/WiFi Networks with QoS Requirements in Mobile Environments](https://arxiv.org/abs/2511.00210)
*Emilio Ancillotti,Loreto Pescosolido,Andrea Passarella*

Main category: cs.NI

TL;DR: 论文提出两种新机制优化LiFi/WiFi混合网络的垂直切换，显著减少QoS中断时间，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决在LiFi/WiFi混合网络中，标准机制仅基于完全连接丢失而无法提前预测垂直切换的问题，需要工具来预测并优化QoS中断时间。

Method: 论文引入了两种机制：基于信号功率水平读数和CRC包失败率，通过实验测试评估它们在QoS中断持续时间上的表现。实验使用配备传送带的实验室测试台，精确模拟移动设备场景。

Result: 使用提出的方法，QoS中断时间降至1秒以下（QoS水平为20 Mbps），而基准解决方案的中断时间为几秒。

Conclusion: 该论文提出的两种机制（基于信号功率水平读数和CRC包失败率）显著改善了LiFi/WiFi混合网络中的QoS中断时间，相比基准解决方案（基于连接丢失检测）具有明显优势。

Abstract: We consider a hybrid LiFi/WiFi network consisting of commercially available
equipment, for mobile scenarios, where WiFi backs up communications, through
vertical handovers, in case of insufficient LiFi QoS. When QoS requirements in
terms of goodput are defined, tools are needed to anticipate the vertical
handover relative to what is possible with standard basic mechanisms, which are
only based on a complete loss of connectivity. We introduce two such
mechanisms, based on signal power level readings and CRC-based packet failure
ratio, and evaluate their performance in terms of QoS-outage duration,
considering as a benchmark an existing baseline solution based on the detection
of a connectivity loss. In doing this, we provide insights into the interplay
between such mechanisms and the LiFi protocol channel adaptation capabilities.
Our experimental results are obtained using a lab-scale testbed equipped with a
conveyor belt, which allows us to accurately replicate experiments with devices
in motion. With the proposed methods, we achieve QoS outages below one second
for a QoS level of 20 Mbps, compared to outage durations of a few seconds
obtained with the baseline solution.

</details>


### [186] [Mist-Assisted Federated Learning for Intrusion Detection in Heterogeneous IoT Networks](https://arxiv.org/abs/2511.00271)
*Saadat Izadi,Shakib Komasi,Ali Salimi,Alireza Rezaei,Mahmood Ahmadi*

Main category: cs.NI

TL;DR: A Mist-assisted hierarchical framework for IoT intrusion detection achieves high accuracy and privacy preservation by addressing data heterogeneity and non-IID issues through a four-layer architecture.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of intrusion detection in IoT environments, including data heterogeneity and non-IID distributions across clients, while preserving privacy.

Method: The framework spans four layers: Mist (data abstraction and lightweight anomaly detection), Edge (utility-based client selection), Fog (regional aggregation using FedProx), and Cloud (global model consolidation).

Result: Achieves 98-99% accuracy, PR-AUC > 0.97, and stable convergence on the TON-IoT dataset.

Conclusion: The proposed Mist-assisted hierarchical framework demonstrates high accuracy, stable convergence, and privacy preservation in IoT intrusion detection, effectively addressing data heterogeneity and non-IID challenges.

Abstract: The rapid growth of the Internet of Things (IoT) offers new opportunities but
also expands the attack surface of distributed, resource-limited devices.
Intrusion detection in such environments is difficult due to data heterogeneity
from diverse sensing modalities and the non-IID distribution of samples across
clients. Federated Learning (FL) provides a privacy-preserving alternative to
centralized training, yet conventional frameworks struggle under these
conditions. To address this, we propose a Mist-assisted hierarchical framework
for IoT intrusion detection. The architecture spans four layers: (i) Mist,
where raw data are abstracted into a unified feature space and lightweight
models detect anomalies; (ii) Edge, which applies utility-based client
selection; (iii) Fog, where multiple regional aggregators use FedProx to
stabilize training; and (iv) Cloud, which consolidates and disseminates global
models. Evaluations on the TON-IoT dataset show the framework achieves 98-99%
accuracy, PR-AUC> 0.97, and stable convergence under heterogeneous and
large-scale settings, while maintaining efficiency and preserving privacy.

</details>


### [187] [Reinforcement Learning for Resource Allocation in Vehicular Multi-Fog Computing](https://arxiv.org/abs/2511.00276)
*Mohammad Hadi Akbarzadeh,Mahmood Ahmadi,Mohammad Saeed Jahangiry,Jae Young Hur*

Main category: cs.NI

TL;DR: 该论文提出使用强化学习解决多重雾计算环境中的资源分配问题，通过实验验证其在延迟、负载平衡和任务成功率上的优势。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）设备、智能车辆和对延迟敏感应用的指数级增长，传统的基于优化的方法无法适应动态车辆移动性、异构资源和波动工作负载的挑战，亟需高效的分布式计算范式。

Method: 将MFC环境中的资源分配问题建模为马尔可夫决策过程（MDP），并应用Q学习、深度Q网络（DQN）和Actor-Critic等RL算法进行自适应任务分配。

Result: 实验结果表明，所提出的RL算法在延迟、工作负载平衡和任务成功率方面均有显著提升。

Conclusion: 该研究通过强化学习（RL）算法在多重雾计算（MFC）环境中的资源分配问题，显著降低了延迟、平衡了工作负载并提高了任务成功率，为动态车辆计算挑战提供了有效解决方案。

Abstract: The exponential growth of Internet of Things (IoT) devices, smart vehicles,
and latency-sensitive applications has created an urgent demand for efficient
distributed computing paradigms. Multi-Fog Computing (MFC), as an extension of
fog and edge computing, deploys multiple fog nodes near end users to reduce
latency, enhance scalability, and ensure Quality of Service (QoS). However,
resource allocation in MFC environments is highly challenging due to dynamic
vehicular mobility, heterogeneous resources, and fluctuating workloads.
Traditional optimization-based methods often fail to adapt to such dynamics.
Reinforcement Learning (RL), as a model-free decision-making framework, enables
adaptive task allocation by continuously interacting with the environment. This
paper formulates the resource allocation problem in MFC as a Markov Decision
Process (MDP) and investigates the application of RL algorithms such as
Q-learning, Deep Q-Networks (DQN), and Actor-Critic. We present experimental
results demonstrating improvements in latency, workload balance, and task
success rate. The contributions and novelty of this study are also discussed,
highlighting the role of RL in addressing emerging vehicular computing
challenges.

</details>


### [188] [COHERE - Congestion-aware Offloading and Handover via Empirical RAT Evaluation for Multi-RAT Networks](https://arxiv.org/abs/2511.00439)
*Pavan K. Mangipudi,Sharon Boamah,Lorenz Carvajal,Janise Mcnair*

Main category: cs.NI

TL;DR: chrome是一个多标准框架，用于异构RAT网络中智能切换和卸载，显著降低拥塞并提高性能。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是解决当前异构RAT网络中移动性决策过度依赖RSSI的问题，忽视RAT特定特性、拥塞和队列延迟等关键因素。

Method: chrome框架通过结合RSSI及其他多标准，采用TOPSIS方法对可用RAT进行排名，并基于排名进行智能跨RAT卸载。

Result: 实验结果表明，与仅依赖RSSI的切换相比，chrome能将拥塞RAT的负载降低32%，总切换次数减少25%，并将链路延迟提高166%。

Conclusion: 该论文的结论是，通过采用多标准决策框架（如TOPSIS）并结合主客观权重，chrome框架显著改善了异构无线接入技术（RAT）网络中的拥塞感知性能，减少了切换次数并提高了链路延迟。

Abstract: The evolution of wireless networks and radio access technologies (RATs) has
transformed communication from user-driven traffic into a dynamic ecosystem of
autonomous systems, including IoT devices, edge nodes, autonomous vehicles,
AR/XR clients, and AI-powered agents. These systems exhibit diverse traffic
patterns, latency requirements, and mobility behaviors, increasingly operating
across overlapping heterogeneous RATs such as 5G, WiFi, satellite, NB-IoT,
LoRaWAN, Zigbee, etc. This multi-RAT coexistence creates opportunities for
intelligent access, mobility, and routing strategies. However, most mobility
decisions still rely heavily on RSSI, which neglects RAT-specific features,
congestion, queuing delays, and application needs, favoring high-power links
over optimal ones. To address this gap, we propose chrome (Congestion-aware
Offloading and Handover via Empirical RAT Evaluation), a multi criteria
framework for dense multi-RAT networks. chrome enhances RSSI with multiple
criteria and applies the Technique for Order of Preference by Similarity to the
Ideal Solution (TOPSIS) to rank available RATs. Criteria weights are determined
using both subjective (operator-driven) and objective (measurement-based)
approaches. Based on this ranking, chrome performs intelligent cross-RAT
offloading to reduce congestion on over-utilized links. We evaluate chrome in a
dense SDN-controlled 5G/WiFi Multi-RAT environment using Mininet WiFi. Compared
to RSSI-only handover, COHERE reduces the load on the congested RAT by up to
32%, reduces total handovers by 25%, lowers handovers to the congested RAT by
55%, and improves link delay by up to 166%, while maintaining comparable or up
to 11% higher throughput. These results demonstrate that guarded,
multi-criteria decision-making can exploit RAT coexistence to deliver robust,
congestion-aware performance across heterogeneous deployments.

</details>


### [189] [Detecting Coverage Holes in Wireless Sensor Networks Using Connected Component Labeling and Force-Directed Algorithms](https://arxiv.org/abs/2511.00965)
*Jiacheng Xu,Xiongfei Zhao,Hou-Wan Long,Cheong Se-Hang,Yain-Whar Si*

Main category: cs.NI

TL;DR: 提出无需坐标的FD-CCL方法，通过CCL和FD算法高效检测WSN中的覆盖空洞，实验证明其速度和准确性优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统覆盖空洞检测方法存在不准确、处理速度慢和高能耗问题，且依赖节点坐标等物理信息，因此需要一种更高效且无需坐标信息的新方法。

Method: 提出了一种基于连接组件标记（CCL）和力导向（FD）算法的坐标无关覆盖空洞检测方法FD-CCL，并研究了Suzuki的轮廓追踪（CT）算法与CCL的性能对比。

Result: 实验结果表明FD-CCL在检测和定位覆盖空洞方面表现优越，处理时间和准确性均有显著提升。

Conclusion: FD-CCL方法在无线传感器网络中有效检测和定位覆盖空洞，具有较高的处理速度和准确性。

Abstract: Contour detection in Wireless Sensor Networks (WSNs) is crucial for tasks
like energy saving and network optimization, especially in security and
surveillance applications. Coverage holes, where data transmission is not
achievable, are a significant issue caused by factors such as energy depletion
and physical damage. Traditional methods for detecting these holes often suffer
from inaccuracy, low processing speed, and high energy consumption, relying
heavily on physical information like node coordinates and sensing range. To
address these challenges, we propose a novel, coordinate-free coverage hole
detection method using Connected Component Labeling (CCL) and Force-Directed
(FD) algorithms, termed FD-CCL. This method does not require node coordinates
or sensing range information. We also investigate Suzuki's Contour Tracing (CT)
algorithm and compare its performance with CCL on various FD graphs. Our
experiments demonstrate the effectiveness of FD-CCL in terms of processing time
and accuracy. Simulation results confirm the superiority of FD-CCL in detecting
and locating coverage holes in WSNs.

</details>


### [190] [Impact of Antenna Arrays Misalignment on the Near Field Distance in Terahertz Communications](https://arxiv.org/abs/2511.00502)
*Peng Zhang,Vitaly Petrov,Emil Björnson*

Main category: cs.NI

TL;DR: 本文分析了太赫兹系统中空间非对齐对近场距离计算的影响，推导了相关表达式并通过模拟验证，为实际部署提供了指导。


<details>
  <summary>Details</summary>
Motivation: 现有的近场边界公式（Fraunhofer距离）假设收发器之间理想对齐，忽略了由移动性或机械缺陷引起的实际非对齐问题，本文旨在填补这一关键空白。

Method: 我们推导了在任意非对齐偏移下，ULA--ULA和UPA--UPA配置中近场边界的精确解析表达式和简化近似，并通过数值模拟验证了理论模型。

Result: 数值模拟验证了理论模型，并量化了非对齐如何重塑近场区域。

Conclusion: 本文为优化太赫兹系统在现实场景中的部署提供了重要指导，通过理论模型验证了非对齐情况下近场边界的变化，并量化了其对近场区域的影响。

Abstract: The extremely short wavelength of terahertz (THz) communications leads to an
extended radiative near-field region, in which some canonical far-field
assumptions fail. Existing near-field boundary formulations (Fraunhofer
distance) for uniform linear/planar array (ULA/UPA) configurations assume ideal
alignment between transceivers, overlooking practical misalignments caused by
mobility or mechanical imperfections. This paper addresses this critical gap by
analyzing the impact of spatial misalignment on near-field distance
calculations in THz systems. We derive exact analytical expressions and
simplified approximations for the near-field boundary in both ULA--ULA and
UPA--UPA configurations under arbitrary misalignment offsets. Through numerical
simulations, we validate our theoretical models and quantify how misalignment
reshapes the near-field region. These findings provide essential guidelines for
optimizing THz system deployment in realistic scenarios.

</details>


### [191] [Advancing Fluid Antenna-Assisted Non-Terrestrial Networks in 6G and Beyond: Fundamentals, State of the Art, and Future Directions](https://arxiv.org/abs/2511.00569)
*Tianheng Xu,Runke Fan,Jie Zhu,Pei Peng,Xianfu Chen,Qingqing Wu,Ming Jiang,Celimuge Wu,Dusit Niyato,Kai-Kit Wong*

Main category: cs.NI

TL;DR: 本文综述了流体天线（FAs）在非地面网络（NTNs）中的应用，探讨了其优化解决方案、与其他技术的结合及未来发展方向，强调了FAs在提升NTNs性能方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 6G网络对超可靠、低延迟和无处不在的连接需求激增，NTNs作为地面网络的关键补充，但仍面临动态传播环境、能源限制和密集干扰等挑战。FAs因其可重构特性，被视为优化NTNs的潜在技术。

Method: 提供了FA-assisted NTNs的全面综述，包括联合优化解决方案的详细探讨，如FA配置调整、NTN平台运动模式和资源分配优化。

Result: FAs能够为NTNs提供更高的信道多样性和复用增益，有效缓解动态信道衰落并优化资源分配。本文还探讨了FA-assisted NTNs与新兴技术的结合及其在智能功能集成中的潜力。

Conclusion: 本文强调了流体天线（FAs）与非地面网络（NTNs）结合的未来潜力，并指出了未来研究方向以扩展其应用。

Abstract: With the surging demand for ultra-reliable, low-latency, and ubiquitous
connectivity in Sixth-Generation (6G) networks, Non-Terrestrial Networks (NTNs)
emerge as a key complement to terrestrial networks by offering flexible access
and global coverage. Despite the significant potential, NTNs still face
critical challenges, including dynamic propagation environments, energy
constraints, and dense interference. As a key 6G technology, Fluid Antennas
(FAs) can reshape wireless channels by reconfiguring radiating elements within
a limited space, such as their positions and rotations, to provide higher
channel diversity and multiplexing gains. Compared to fixed-position antennas,
FAs can present a promising integration path for NTNs to mitigate dynamic
channel fading and optimize resource allocation. This paper provides a
comprehensive review of FA-assisted NTNs. We begin with a brief overview of the
classical structure and limitations of existing NTNs, the fundamentals and
advantages of FAs, and the basic principles of FA-assisted NTNs. We then
investigate the joint optimization solutions, detailing the adjustments of FA
configurations, NTN platform motion modes, and resource allocations. We also
discuss the combination with other emerging technologies and explore
FA-assisted NTNs as a novel network architecture for intelligent function
integrations. Furthermore, we delve into the physical layer security and covert
communication in FA-assisted NTNs. Finally, we highlight the potential future
directions to empower broader applications of FA-assisted NTNs.

</details>


### [192] [Power Control Based on Multi-Agent Deep Q Network for D2D Communication](https://arxiv.org/abs/2511.00767)
*Shi Gengtian,Takashi Koshimizu,Megumi Saito,Pan Zhenni,Liu Jiang,Shigeru Shimamoto*

Main category: cs.NI

TL;DR: 提出强化学习功率控制算法，减少D2D干扰，提升LTE系统吞吐量。


<details>
  <summary>Details</summary>
Motivation: D2D通信中未受控制的干扰会降低系统性能和服务质量，功率控制是减少干扰的关键。

Method: 提出了一种基于强化学习的自适应功率控制算法。

Result: 仿真结果显示，所提算法在LTE环境中比传统算法表现更优。

Conclusion: 强化学习算法在自适应功率控制中表现优于传统LTE算法，提高了系统吞吐量。

Abstract: In device-to-device (D2D) communication under a cell with resource sharing
mode the spectrum resource utilization of the system will be improved. However,
if the interference generated by the D2D user is not controlled, the
performance of the entire system and the quality of service (QOS) of the
cellular user may be degraded. Power control is important because it helps to
reduce interference in the system. In this paper, we propose a reinforcement
learning algorithm for adaptive power control that helps reduce interference to
increase system throughput. Simulation results show the proposed algorithm has
better performance than traditional algorithm in LTE (Long Term Evolution).

</details>


### [193] [TINC: Trusted Intelligent NetChain](https://arxiv.org/abs/2511.00823)
*Qi Xia,Hu Xia,Isaac Amankona Obiri,Adjei-Arthur Bonsu,Grace Mupoyi Ntuala,Ansu Badjie,Tienin Bole Wilfried,Jiaqin Liu,Lan Ma,Jianbin Gao,Feng Yao*

Main category: cs.NI

TL;DR: TINC是一种针对联盟链的多平面分片架构，通过智能机制和平面解耦提升可扩展性和效率，实验证明其优于现有解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有联盟链架构在可扩展性和效率方面面临挑战，尤其是分片解决方案难以保证公平参与和均衡工作负载分配。

Method: 提出了一种多平面分片架构TINC，通过智能机制实现自适应节点分配和动态工作负载平衡，同时解耦控制平面和数据平面以提高资源效率。

Result: TINC通过广泛的实验评估和形式分析，展现出更高的性能和安全保障。

Conclusion: TINC显著优于现有分片区块链框架，实现了更高的吞吐量、更低的延迟、均衡的节点和交易分布，并降低了交易失败率，同时保持了区块链的基本安全保证。

Abstract: Blockchain technology facilitates the development of decentralized systems
that ensure trust and transparency without the need for expensive centralized
intermediaries. However, existing blockchain architectures particularly
consortium blockchains face critical challenges related to scalability and
efficiency. State sharding has emerged as a promising approach to enhance
blockchain scalability and performance. However, current shard-based solutions
often struggle to guarantee fair participation and a balanced workload
distribution among consortium members. To address these limitations, we propose
Trusted Intelligent NetChain (TINC), a multi-plane sharding architecture
specifically designed for consortium blockchains. TINC incorporates intelligent
mechanisms for adaptive node assignment and dynamic workload balancing,
enabling the system to respond effectively to changing network conditions while
maintaining equitable shard utilization. By decoupling the control and data
planes, TINC allows control nodes to focus on consensus operations, while data
nodes handle large-scale storage, thus improving overall resource efficiency.
Extensive experimental evaluation and formal analysis demonstrate that TINC
significantly outperforms existing shard-based blockchain frameworks. It
achieves higher throughput, lower latency, balanced node and transaction
distributions, and reduced transaction failure rates. Furthermore, TINC
maintains essential blockchain security guarantees, exhibiting resilience
against Byzantine faults and dynamic network environments. The integration of
Dynamic Decentralized Identifiers (DDIDs) further strengthens trust and
security management within the consortium network.

</details>


### [194] [DPMon: a Differentially-Private Query Engine for Passive Measurements](https://arxiv.org/abs/2511.00906)
*Martino Trevisan*

Main category: cs.NI

TL;DR: DPMon 是一种基于差分隐私的工具，用于在被动网络监测中保护用户隐私并提取有用数据。


<details>
  <summary>Details</summary>
Motivation: 被动监测技术虽在多领域有应用，但涉及用户隐私问题，需开发隐私保护工具。

Method: DPMon 利用差分隐私技术扰动查询输出，支持 Apache Spark 大数据基础设施及多种数据格式。

Result: DPMon 在保证隐私的前提下，成功从数据中提取有价值的信息。

Conclusion: DPMon 是一种有效的隐私保护工具，能够在被动网络监测中提取有意义的数据同时保护用户隐私。

Abstract: Passive monitoring is a network measurement technique which analyzes the
traffic carried by an operational network. It has several applications for
traffic engineering, Quality of Experience monitoring and cyber security.
However, it entails the processing of personal information, thus, threatening
users' privacy. In this work, we propose DPMon, a tool to run
privacy-preserving queries to a dataset of passive network measurements. It
exploits differential privacy to perturb the output of the query to preserve
users' privacy. DPMon can exploit big data infrastructures running Apache Spark
and operate on different data formats. We show that DPMon allows extracting
meaningful insights from the data, while at the same time controlling the
amount of disclosed information.

</details>


### [195] [Optimizing Energy and Latency in 6G Smart Cities with Edge CyberTwins](https://arxiv.org/abs/2511.00955)
*Abouaomar,Badr Ben Elallid,Nabil Benamar*

Main category: cs.NI

TL;DR: 论文提出一种边缘感知的CyberTwin框架，通过混合联邦学习优化6G网络切片的能源-延迟性能，验证了大规模部署下的高效表现。


<details>
  <summary>Details</summary>
Motivation: 智能城市中IoT设备激增对6G网络提出了能源和延迟的冲突需求，现有方法难以在大规模部署（超过50,000设备/km）中平衡这一矛盾。

Method: 结合集中式AI调度和分布式联邦学习，采用基于压缩感知的数字孪生和可再生能源感知资源分配，以及PUF安全认证的三层架构。

Result: 仿真结果显示，非实时切片能源消耗降低52%，URLLC应用保持0.9ms延迟和99.1% SLA合规性，攻击检测准确率达99.7%。

Conclusion: 该论文提出的CyberTwin框架通过混合联邦学习和边缘感知技术，成功解决了6G网络切片中的能源-延迟权衡问题，实现了大规模部署下的高效能表现。

Abstract: The proliferation of IoT devices in smart cities challenges 6G networks with
conflicting energy-latency requirements across heterogeneous slices. Existing
approaches struggle with the energy-latency trade-off, particularly for massive
scale deployments exceeding 50,000 devices km. This paper proposes an
edge-aware CyberTwin framework integrating hybrid federated learning for
energy-latency co-optimization in 6G network slicing. Our approach combines
centralized Artificial Intelligence scheduling for latency-sensitive slices
with distributed federated learning for non-critical slices, enhanced by
compressive sensing-based digital twins and renewable energy-aware resource
allocation. The hybrid scheduler leverages a three-tier architecture with
Physical Unclonable Function (PUF) based security attestation achieving 99.7%
attack detection accuracy. Comprehensive simulations demonstrate 52% energy
reduction for non-real-time slices compared to Diffusion-Reinforcement Learning
baselines while maintaining 0.9ms latency for URLLC applications with 99.1% SLA
compliance. The framework scales to 50,000 devices km with CPU overhead below
25%, validated through NS-3 hybrid simulations across realistic smart city
scenarios.

</details>


### [196] [Quantum Reinforcement Learning for 6G and Beyond Wireless Networks](https://arxiv.org/abs/2511.01070)
*Dinh-Hieu Tran,Thai Duong Nguyen,Thanh-Dao Nguyen,Ngoc-Tan Nguyen,Van Nhan Vo,Hung Tran,Mouhamad Chehaitly,Yan Kyaw Tun,Cedomir Stefanovic,Tu Ho Dac,Eva Lagunas,Symeon Chatzinotas,Nguyen Van Huynh*

Main category: cs.NI

TL;DR: 本文综述了量子强化学习（QRL）在6G中的应用潜力，展示其优于传统方法，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G对高数据速率、低延迟、高密度和无缝通信的需求增长，传统AI难以满足苛刻要求，需探索QRL等新型方法。

Method: 通过总结、分析和讨论传统深度强化学习（DRL）的成果与局限性，引入QRL并展示其在动态频谱访问中的优越性。

Result: QRL在6G中展现出比传统DRL更优的性能，尤其在动态频谱访问方面，同时明确了未来研究方向。

Conclusion: 本文总结了量子强化学习（QRL）在6G无线通信网络中的潜力和优势，并提出了未来研究方向，填补了该领域综述的空白。

Abstract: While 5G is being deployed worldwide, 6G is receiving increasing attention
from researchers to meet the growing demand for higher data rates, lower
latency, higher density, and seamless communications worldwide. To meet the
stringent requirements of 6G wireless communications networks, AI-integrated
communications have become an indispensable part of supporting 6G systems with
intelligence, automation, and big data training capabilities. However,
traditional artificial intelligence (AI) systems are difficult to meet the
stringent latency and high throughput requirements of 6G with limited
resources. In this article, we summarize, analyze, discuss the potential, and
benefits of Quantum Reinforcement Learning (QRL) in 6G. As an example, we show
the superiority of QRL in dynamic spectrum access compared to the conventional
Deep Reinforcement Learning (DRL) approach. In addition, we provide an overview
of what DRL has accomplished in 6G and its challenges and limitations. From
there, we introduce QRL and potential research directions that should continue
to be of interest in 6G. To the best of our knowledge, this is the first review
and vision article on QRL for 6G wireless communication networks.

</details>


### [197] [Quantum Network Tomography for General Topology with SPAM Errors](https://arxiv.org/abs/2511.01074)
*Xuchuang Wang,Matheus Guedes De Andrade,Guus Avis,Yu-zhen Janice Chen,Mohammad Hajiesmaili,Don Towsley*

Main category: cs.NI

TL;DR: 提出Mergecast方法解决任意拓扑和Pauli通道网络的量子断层扫描问题，并扩展到含SPAM误差的场景，仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注星型网络和特定通道类型，缺乏对任意拓扑和一般Pauli通道网络的量子断层扫描研究。

Method: 提出Mergecast方法和渐进蚀刻程序，适用于任意拓扑和Pauli通道的网络；针对SPAM误差，提出误差估计协议并调整Mergecast方法。

Result: 通过NetSquid仿真验证，Mergecast在光子损失和量子内存退相干等现实条件下仍保持良好性能。

Conclusion: 本文提出了一种新型量子网络断层扫描方法Mergecast，能够在任意拓扑和Pauli通道的网络中唯一识别所有内部量子通道。同时，针对含有SPAM误差的更现实场景，提出了误差估计协议并验证了Mergecast的有效性。

Abstract: The goal of quantum network tomography (QNT) is the characterization of
internal quantum channels in a quantum network from external peripheral
operations. Prior research has primarily focused on star networks featuring
bit-flip and depolarizing channels, leaving the broader problem -- such as QNT
for networks with arbitrary topologies and general Pauli channels -- largely
unexplored. Moreover, establishing channel identifiability remains a
significant challenge even in simplified quantum star networks.
  In the first part of this paper, we introduce a novel network tomography
method, termed Mergecast, in quantum networks. We demonstrate that Mergecast,
together with a progressive etching procedure, enables the unique
identification of all internal quantum channels in networks characterized by
arbitrary topologies and Pauli channels. As a side contribution, we introduce a
subclass of Pauli channels, termed bypassable Pauli channels, and propose a
more efficient unicast-based tomography method, called BypassUnicast, for
networks exclusively comprising these channels. In the second part, we extend
our investigation to a more realistic QNT scenario that incorporates state
preparation and measurement (SPAM) errors. We rigorously formulate SPAM errors
in QNT, propose estimation protocols for such errors within QNT, and
subsequently adapt our Mergecast approaches to handle networks affected by SPAM
errors. Lastly, we conduct NetSquid-based simulations to corroborate the
effectiveness of our proposed protocols in identifying internal quantum
channels and estimating SPAM errors in quantum networks. In particular, we
demonstrate that Mergecast maintains good performance under realistic
conditions, such as photon loss and quantum memory decoherence.

</details>


### [198] [Joint Computation Offloading and Resource Allocation for Maritime MEC with Energy Harvesting](https://arxiv.org/abs/2511.01160)
*Zhen Wang,Bin Lin,Qiang Ye,Yuguang Fang,Xiaoling Han*

Main category: cs.NI

TL;DR: 提出了一种MEC支持的能量收集海道监测网络架构，通过Lyapunov优化和JCORA算法，显著提升了网络吞吐量。


<details>
  <summary>Details</summary>
Motivation: 为支持动态船舶跟踪、事故取证和防污需求，提出了一种结合能量收集的多接入边缘计算（MEC）海道监测网络（MSLMN）架构。

Method: 采用Lyapunov优化技术处理状态和动作空间大的优化问题，将随机优化问题转化为确定性优化问题，并通过解耦时空变量获得渐进最优解。开发了JCORA算法，联合优化任务卸载、子信道分配、计算资源分配和任务迁移决策。

Result: 仿真结果表明，所提方案在长期平均吞吐量上优于现有方法。

Conclusion: 通过联合优化计算卸载和资源分配，提出的JCORA算法在保证队列稳定的前提下，显著提升了MSLMN的长期平均吞吐量，验证了方案的有效性。

Abstract: In this paper, we establish a multi-access edge computing (MEC)-enabled sea
lane monitoring network (MSLMN) architecture with energy harvesting (EH) to
support dynamic ship tracking, accident forensics, and anti-fouling through
real-time maritime traffic scene monitoring. Under this architecture, the
computation offloading and resource allocation are jointly optimized to
maximize the long-term average throughput of MSLMN. Due to the dynamic
environment and unavailable future network information, we employ the Lyapunov
optimization technique to tackle the optimization problem with large state and
action spaces and formulate a stochastic optimization program subject to queue
stability and energy consumption constraints. We transform the formulated
problem into a deterministic one and decouple the temporal and spatial
variables to obtain asymptotically optimal solutions. Under the premise of
queue stability, we develop a joint computation offloading and resource
allocation (JCORA) algorithm to maximize the long-term average throughput by
optimizing task offloading, subchannel allocation, computing resource
allocation, and task migration decisions. Simulation results demonstrate the
effectiveness of the proposed scheme over existing approaches.

</details>


### [199] [3D Gaussian Radiation Field Modeling for Integrated RIS-FAS Systems: Analysis and Optimization](https://arxiv.org/abs/2511.01373)
*Kaining Wang,Bo Yang,Yusheng Lei,Zhiwen Yu,Xuelin Cao,Liang Wang,Bin Guo,George C. Alexandropoulos,Mérouane Debbah,Zhu Han*

Main category: cs.NI

TL;DR: 提出一种基于三维高斯辐射场建模的实时优化方法，用于联合优化FAS-RIS系统，在快速衰落信道中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 在快速衰落信道条件下，快速有效地联合优化FAS系统中的天线位置和RIS相位配置是一个关键挑战。传统优化方法依赖复杂的迭代计算，难以在动态信道环境中实时获得最优解。

Method: 采用三维高斯辐射场建模，将障碍物视为虚拟发射器，并通过分别学习幅度和相位变化来快速生成高精度信道信息。在此基础上，提出了一种交替优化方案来联合优化FAS位置和RIS相位配置。

Result: 仿真结果表明，所提方法在频谱预测精度、收敛速度和最小可达速率方面显著优于现有方法。

Conclusion: 论文提出的基于三维高斯辐射场建模的优化方法在快速衰落信道条件下显著提升了FAS-RIS系统的性能，验证了其在实时优化中的有效性和实用性。

Abstract: The integration of reconfigurable intelligent surfaces (RIS) and fluid
antenna systems (FAS) has attracted considerable attention due to its
tremendous potential in enhancing wireless communication performance. However,
under fast-fading channel conditions, rapidly and effectively performing joint
optimization of the antenna positions in an FAS system and the RIS phase
configuration remains a critical challenge. Traditional optimization methods
typically rely on complex iterative computations, thus making it challenging to
obtain optimal solutions in real time within dynamic channel environments. To
address this issue, this paper introduces a field information-driven
optimization method based on three-dimensional Gaussian radiation-field
modeling for real-time optimization of integrated FAS-RIS systems. In the
proposed approach, obstacles are treated as virtual transmitters and, by
separately learning the amplitude and phase variations, the model can quickly
generate high-precision channel information based on the transmitter's
position. This design eliminates the need for extensive pilot overhead and
cumbersome computations. On this framework, an alternating optimization scheme
is presented to jointly optimize the FAS position and the RIS phase
configuration. Simulation results demonstrate that the proposed method
significantly outperforms existing approaches in terms of spectrum prediction
accuracy, convergence speed, and minimum achievable rate, validating its
effectiveness and practicality in fast-fading scenarios.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [200] [Fix: externalizing network I/O in serverless computing](https://arxiv.org/abs/2511.00205)
*Yuhan Deng,Akshay Srivatsan,Sebastian Ingino,Francis Chua,Yasmine Mitchell,Matthew Vilaysack,Keith Winstein*

Main category: cs.OS

TL;DR: 论文介绍了一种无服务器计算系统，通过共享计算表示和平台处理I/O，实现更高效的资源调度和“按结果付费”模式。


<details>
  <summary>Details</summary>
Motivation: 旨在通过明确每个阶段所需的数据，帮助提供商调度任务和网络传输，减少资源闲置，优化计算效率。

Method: 系统采用确定性程序在指定数据环境或其他计算输出的环境中运行的共同计算表示，平台专门处理网络数据移动。

Result: 设计提出了一种端到端的外包计算论证，改变了传统的服务模式。

Conclusion: 该论文提出了一种无服务器计算系统，通过共享计算表示和外部化I/O，实现了从“按努力付费”到“按结果付费”的服务模式转变。

Abstract: We describe a system for serverless computing where users, programs,
  and the underlying platform share a common representation of a
  computation: a deterministic procedure, run in an environment
  of well-specified data or the outputs of other computations. This
  representation externalizes I/O: data movement over the network is
  performed exclusively by the platform. Applications can describe the
  precise data needed at each stage, helping the provider schedule
  tasks and network transfers to reduce starvation. The design
  suggests an end-to-end argument for outsourced computing, shifting
  the service model from ``pay-for-effort'' to ``pay-for-results.''

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [201] [Gen AI in Automotive: Applications, Challenges, and Opportunities with a Case study on In-Vehicle Experience](https://arxiv.org/abs/2511.00026)
*Chaitanya Shinde,Divya Garikapati*

Main category: cs.RO

TL;DR: 该论文综述了生成式人工智能在汽车行业的应用，包括设计、自动驾驶、维护和用户体验，讨论了技术、伦理和安全挑战，并通过奔驰MBUX虚拟助手的案例展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI如何改变汽车行业，特别是在自动驾驶验证、组件设计和人机交互方面的应用潜力。

Method: 综合文献回顾和奔驰MBUX虚拟助手的案例分析。

Result: 生成式AI在汽车行业有广泛应用前景，但仍面临技术、伦理和安全挑战。

Conclusion: 论文总结了生成式AI在汽车行业的潜力和限制，并提出了未来研究方向以实现更安全、高效和用户为中心的移动体验。

Abstract: Generative Artificial Intelligence is emerging as a transformative force in
the automotive industry, enabling novel applications across vehicle design,
manufacturing, autonomous driving, predictive maintenance, and in vehicle user
experience. This paper provides a comprehensive review of the current state of
GenAI in automotive, highlighting enabling technologies such as Generative
Adversarial Networks and Variational Autoencoders. Key opportunities include
accelerating autonomous driving validation through synthetic data generation,
optimizing component design, and enhancing human machine interaction via
personalized and adaptive interfaces. At the same time, the paper identifies
significant technical, ethical, and safety challenges, including computational
demands, bias, intellectual property concerns, and adversarial robustness, that
must be addressed for responsible deployment. A case study on Mercedes Benzs
MBUX Virtual Assistant illustrates how GenAI powered voice systems deliver more
natural, proactive, and personalized in car interactions compared to legacy
rule based assistants. Through this review and case study, the paper outlines
both the promise and limitations of GenAI integration in the automotive sector
and presents directions for future research and development aimed at achieving
safer, more efficient, and user centric mobility. Unlike prior reviews that
focus solely on perception or manufacturing, this paper emphasizes generative
AI in voice based HMI, bridging safety and user experience perspectives.

</details>


### [202] [STRIDER: Navigation via Instruction-Aligned Structural Decision Space Optimization](https://arxiv.org/abs/2511.00033)
*Diqi He,Xuehao Gao,Hao Li,Junwei Han,Dingwen Zhang*

Main category: cs.RO

TL;DR: STRIDER通过结构化决策和任务反馈优化，显著提升零样本视觉与语言导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因缺乏结构化决策和对先前行动反馈不足而导致的导航不稳健问题。

Method: 提出了STRIDER框架，包含结构化路径点生成器和任务对齐调节器，优化决策空间。

Result: 在R2R-CE和RxR-CE基准测试中，SR从29%提升至35%，相对增益20.7%。

Conclusion: STRIDER框架通过空间约束决策和反馈引导执行显著提升了零样本视觉与语言导航任务的性能。

Abstract: The Zero-shot Vision-and-Language Navigation in Continuous Environments
(VLN-CE) task requires agents to navigate previously unseen 3D environments
using natural language instructions, without any scene-specific training. A
critical challenge in this setting lies in ensuring agents' actions align with
both spatial structure and task intent over long-horizon execution. Existing
methods often fail to achieve robust navigation due to a lack of structured
decision-making and insufficient integration of feedback from previous actions.
To address these challenges, we propose STRIDER (Instruction-Aligned Structural
Decision Space Optimization), a novel framework that systematically optimizes
the agent's decision space by integrating spatial layout priors and dynamic
task feedback. Our approach introduces two key innovations: 1) a Structured
Waypoint Generator that constrains the action space through spatial structure,
and 2) a Task-Alignment Regulator that adjusts behavior based on task progress,
ensuring semantic alignment throughout navigation. Extensive experiments on the
R2R-CE and RxR-CE benchmarks demonstrate that STRIDER significantly outperforms
strong SOTA across key metrics; in particular, it improves Success Rate (SR)
from 29% to 35%, a relative gain of 20.7%. Such results highlight the
importance of spatially constrained decision-making and feedback-guided
execution in improving navigation fidelity for zero-shot VLN-CE.

</details>


### [203] [Endowing GPT-4 with a Humanoid Body: Building the Bridge Between Off-the-Shelf VLMs and the Physical World](https://arxiv.org/abs/2511.00041)
*Yingzhao Jian,Zhongan Wang,Yi Yang,Hehe Fan*

Main category: cs.RO

TL;DR: BiBo利用现成VLM控制人形代理，通过指令编译器和运动执行器提升交互能力，实验显示高成功率与精度提升。


<details>
  <summary>Details</summary>
Motivation: 解决人形代理在开放环境中处理灵活多样交互的挑战，避免大规模数据收集的高成本。

Method: BiBo包含两个关键组件：1) 具身指令编译器，将高级用户指令转换为低级原始命令；2) 基于扩散的运动执行器，生成拟人化动作并适应环境反馈。

Result: BiBo在开放环境中的交互任务成功率达到了90.2%，文本引导运动执行精度较先前方法提高了16.3%。

Conclusion: BiBo通过结合现成的视觉语言模型（VLM）和扩散运动执行器，成功提升了人形代理在开放环境中的交互能力，减少了大规模数据收集的需求。

Abstract: Humanoid agents often struggle to handle flexible and diverse interactions in
open environments. A common solution is to collect massive datasets to train a
highly capable model, but this approach can be prohibitively expensive. In this
paper, we explore an alternative solution: empowering off-the-shelf
Vision-Language Models (VLMs, such as GPT-4) to control humanoid agents,
thereby leveraging their strong open-world generalization to mitigate the need
for extensive data collection. To this end, we present \textbf{BiBo}
(\textbf{B}uilding humano\textbf{I}d agent \textbf{B}y \textbf{O}ff-the-shelf
VLMs). It consists of two key components: (1) an \textbf{embodied instruction
compiler}, which enables the VLM to perceive the environment and precisely
translate high-level user instructions (e.g., {\small\itshape ``have a rest''})
into low-level primitive commands with control parameters (e.g.,
{\small\itshape ``sit casually, location: (1, 2), facing: 90$^\circ$''}); and
(2) a diffusion-based \textbf{motion executor}, which generates human-like
motions from these commands, while dynamically adapting to physical feedback
from the environment. In this way, BiBo is capable of handling not only basic
interactions but also diverse and complex motions. Experiments demonstrate that
BiBo achieves an interaction task success rate of 90.2\% in open environments,
and improves the precision of text-guided motion execution by 16.3\% over prior
methods. The code will be made publicly available.

</details>


### [204] [Alpamayo-R1: Bridging Reasoning and Action Prediction for Generalizable Autonomous Driving in the Long Tail](https://arxiv.org/abs/2511.00088)
*NVIDIA,:,Yan Wang,Wenjie Luo,Junjie Bai,Yulong Cao,Tong Che,Ke Chen,Yuxiao Chen,Jenna Diamond,Yifan Ding,Wenhao Ding,Liang Feng,Greg Heinrich,Jack Huang,Peter Karkus,Boyi Li,Pinyi Li,Tsung-Yi Lin,Dongran Liu,Ming-Yu Liu,Langechuan Liu,Zhijian Liu,Jason Lu,Yunxiang Mao,Pavlo Molchanov,Lindsey Pavao,Zhenghao Peng,Mike Ranzinger,Ed Schmerling,Shida Shen,Yunfei Shi,Sarah Tariq,Ran Tian,Tilman Wekel,Xinshuo Weng,Tianjun Xiao,Eric Yang,Xiaodong Yang,Yurong You,Xiaohui Zeng,Wenyuan Zhang,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: AR1是一种结合因果推理与轨迹规划的VLA模型，通过创新的数据集、模块化架构和多阶段训练策略，显著提升了自动驾驶在复杂场景中的决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端模仿学习架构在安全关键的长尾场景中表现脆弱，缺乏因果理解和稀疏的监督数据是主要挑战。

Method: AR1采用了模块化的VLA架构，结合了预训练的Vision-Language Model（Cosmos-Reason）和基于扩散的轨迹解码器，通过多阶段训练策略（监督微调和强化学习）优化推理质量和推理-动作一致性。

Result: AR1在挑战性案例中规划准确率提高了12%，闭环模拟中离道率降低了35%，近距离遭遇率减少了25%，推理质量通过强化学习后提高了45%。

Conclusion: AR1通过结合因果推理与轨迹规划，为Level 4自动驾驶提供了一条实际可行的路径，并在实际道路测试中验证了其实时性能和部署效果。

Abstract: End-to-end architectures trained via imitation learning have advanced
autonomous driving by scaling model size and data, yet performance remains
brittle in safety-critical long-tail scenarios where supervision is sparse and
causal understanding is limited. To address this, we introduce Alpamayo-R1
(AR1), a vision-language-action model (VLA) that integrates Chain of Causation
reasoning with trajectory planning to enhance decision-making in complex
driving scenarios. Our approach features three key innovations: (1) the Chain
of Causation (CoC) dataset, built through a hybrid auto-labeling and
human-in-the-loop pipeline producing decision-grounded, causally linked
reasoning traces aligned with driving behaviors; (2) a modular VLA architecture
combining Cosmos-Reason, a Vision-Language Model pre-trained for Physical AI
applications, with a diffusion-based trajectory decoder that generates
dynamically feasible plans in real time; (3) a multi-stage training strategy
using supervised fine-tuning to elicit reasoning and reinforcement learning
(RL) to optimize reasoning quality via large reasoning model feedback and
enforce reasoning-action consistency. Evaluation shows AR1 achieves up to a 12%
improvement in planning accuracy on challenging cases compared to a
trajectory-only baseline, with a 35% reduction in off-road rate and 25%
reduction in close encounter rate in closed-loop simulation. RL post-training
improves reasoning quality by 45% as measured by a large reasoning model critic
and reasoning-action consistency by 37%. Model scaling from 0.5B to 7B
parameters shows consistent improvements. On-vehicle road tests confirm
real-time performance (99 ms latency) and successful urban deployment. By
bridging interpretable reasoning with precise control, AR1 demonstrates a
practical path towards Level 4 autonomous driving. We plan to release AR1
models and a subset of the CoC in a future update.

</details>


### [205] [Digital Twin based Automatic Reconfiguration of Robotic Systems in Smart Environments](https://arxiv.org/abs/2511.00094)
*Angelos Alexopoulos,Agorakis Bompotas,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.RO

TL;DR: 提出基于数字孪生技术的机器人控制器动态重构框架，提升机器人在动态环境中的自主适应能力。


<details>
  <summary>Details</summary>
Motivation: 传统控制系统难以快速适应动态环境（如智慧城市和精准农业）中不断变化的地形和环境条件，导致效率低下或操作失败。

Method: 利用数字孪生技术创建机器人操作环境的虚拟副本，通过模拟和优化运动轨迹来响应现实世界的变化，并将更新的代码部署到物理机器人上。

Result: 提出的方法确保了机器人无需人工干预即可快速可靠地适应环境变化，优化了路径和控制参数。

Conclusion: 本研究通过数字孪生技术提出了一种机器人控制器的自主动态重构框架，显著提升了机器人在动态环境中的适应能力，为智能环境中的机器人自主性提供了可扩展的解决方案。

Abstract: Robotic systems have become integral to smart environments, enabling
applications ranging from urban surveillance and automated agriculture to
industrial automation. However, their effective operation in dynamic settings -
such as smart cities and precision farming - is challenged by continuously
evolving topographies and environmental conditions. Traditional control systems
often struggle to adapt quickly, leading to inefficiencies or operational
failures. To address this limitation, we propose a novel framework for
autonomous and dynamic reconfiguration of robotic controllers using Digital
Twin technology. Our approach leverages a virtual replica of the robot's
operational environment to simulate and optimize movement trajectories in
response to real-world changes. By recalculating paths and control parameters
in the Digital Twin and deploying the updated code to the physical robot, our
method ensures rapid and reliable adaptation without manual intervention. This
work advances the integration of Digital Twins in robotics, offering a scalable
solution for enhancing autonomy in smart, dynamic environments.

</details>


### [206] [Real-DRL: Teach and Learn in Reality](https://arxiv.org/abs/2511.00112)
*Yanbing Mao,Yihao Cai,Lui Sha*

Main category: cs.RO

TL;DR: Real-DRL框架通过DRL-Student、PHY-Teacher和Trigger三组件协作，实现了安全关键自主系统的实时安全学习与高性能策略生成，有效应对未知未知和Sim2Real挑战。


<details>
  <summary>Details</summary>
Motivation: 为解决安全关键自主系统中DRL代理在实时物理系统中学习时的安全性挑战，特别是未知未知和Sim2Real差距问题。

Method: Real-DRL框架包含三个交互组件：DRL-Student（采用双重自学习与教学学习范式及安全感知批量采样）、PHY-Teacher（基于物理模型的安全关键策略设计）和Trigger（管理两者交互）。

Result: 实验证明Real-DRL在四足机器人、NVIDIA Isaac Gym中的四足机器人及倒立摆系统中均表现出色，具备安全保障、自动分层学习（安全优先）及安全感知批量采样等独特优势。

Conclusion: Real-DRL框架通过整合DRL-Student、PHY-Teacher和Trigger三部分，有效解决了安全关键自主系统中的未知未知和Sim2Real差距问题，实现了安全与高性能的平衡。

Abstract: This paper introduces the Real-DRL framework for safety-critical autonomous
systems, enabling runtime learning of a deep reinforcement learning (DRL) agent
to develop safe and high-performance action policies in real plants (i.e., real
physical systems to be controlled), while prioritizing safety! The Real-DRL
consists of three interactive components: a DRL-Student, a PHY-Teacher, and a
Trigger. The DRL-Student is a DRL agent that innovates in the dual
self-learning and teaching-to-learn paradigm and the real-time safety-informed
batch sampling. On the other hand, PHY-Teacher is a physics-model-based design
of action policies that focuses solely on safety-critical functions.
PHY-Teacher is novel in its real-time patch for two key missions: i) fostering
the teaching-to-learn paradigm for DRL-Student and ii) backing up the safety of
real plants. The Trigger manages the interaction between the DRL-Student and
the PHY-Teacher. Powered by the three interactive components, the Real-DRL can
effectively address safety challenges that arise from the unknown unknowns and
the Sim2Real gap. Additionally, Real-DRL notably features i) assured safety,
ii) automatic hierarchy learning (i.e., safety-first learning and then
high-performance learning), and iii) safety-informed batch sampling to address
the learning experience imbalance caused by corner cases. Experiments with a
real quadruped robot, a quadruped robot in NVIDIA Isaac Gym, and a cart-pole
system, along with comparisons and ablation studies, demonstrate the Real-DRL's
effectiveness and unique features.

</details>


### [207] [End-to-End Dexterous Arm-Hand VLA Policies via Shared Autonomy: VR Teleoperation Augmented by Autonomous Hand VLA Policy for Efficient Data Collection](https://arxiv.org/abs/2511.00139)
*Yu Cui,Yujian Zhang,Lina Tao,Yang Li,Xinyu Yi,Zhibin Li*

Main category: cs.RO

TL;DR: 提出共享自治框架结合人类与自主策略，高效收集高质量数据并提升机器人灵巧操作能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器人灵巧操作中高质量训练数据稀缺和自动化规划生成动作不自然的问题。

Method: 采用共享自治框架，将控制分为宏观和微观运动：人类通过VR远程操作指导机器人手臂姿态，自主DexGrasp-VLA策略通过实时触觉和视觉反馈处理手部精细控制。

Result: 实验证明该框架能以最少人力生成高质量数据，并在多样对象上达到90%的成功率。

Conclusion: 该论文提出的共享自治框架结合人类操作与自主策略，显著提升了机器人灵巧操作的成功率，并在多样化和未见过的对象上表现出色。

Abstract: Achieving human-like dexterous manipulation remains a major challenge for
general-purpose robots. While Vision-Language-Action (VLA) models show
potential in learning skills from demonstrations, their scalability is limited
by scarce high-quality training data. Existing data collection methods face
inherent constraints: manual teleoperation overloads human operators, while
automated planning often produces unnatural motions. We propose a Shared
Autonomy framework that divides control between macro and micro motions. A
human operator guides the robot's arm pose through intuitive VR teleoperation,
while an autonomous DexGrasp-VLA policy handles fine-grained hand control using
real-time tactile and visual feedback. This division significantly reduces
cognitive load and enables efficient collection of high-quality coordinated
arm-hand demonstrations. Using this data, we train an end-to-end VLA policy
enhanced with our novel Arm-Hand Feature Enhancement module, which captures
both distinct and shared representations of macro and micro movements for more
natural coordination. Our Corrective Teleoperation system enables continuous
policy improvement through human-in-the-loop failure recovery. Experiments
demonstrate that our framework generates high-quality data with minimal
manpower and achieves a 90% success rate across diverse objects, including
unseen instances. Comprehensive evaluations validate the system's effectiveness
in developing dexterous manipulation capabilities.

</details>


### [208] [EgoMI: Learning Active Vision and Whole-Body Manipulation from Egocentric Human Demonstrations](https://arxiv.org/abs/2511.00153)
*Justin Yu,Yide Shentu,Di Wu,Pieter Abbeel,Ken Goldberg,Philipp Wu*

Main category: cs.RO

TL;DR: EgoMI框架通过同步手眼轨迹和记忆增强策略，有效缩小人机体现差异，提升模仿学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决因人类动态头部运动与静态机器人感知系统不匹配导致的分布偏移问题。

Method: 提出EgoMI框架，捕捉同步的末端执行器和主动头部轨迹，并引入记忆增强策略处理快速变化的头部视角。

Result: 在配备驱动相机头部的双手机器人上测试，显示显式头部运动建模的策略优于基线方法。

Conclusion: EgoMI框架通过协调手眼学习，有效缩小了人机体现差异，提升了半人形机器人的模仿学习性能。

Abstract: Imitation learning from human demonstrations offers a promising approach for
robot skill acquisition, but egocentric human data introduces fundamental
challenges due to the embodiment gap. During manipulation, humans actively
coordinate head and hand movements, continuously reposition their viewpoint and
use pre-action visual fixation search strategies to locate relevant objects.
These behaviors create dynamic, task-driven head motions that static robot
sensing systems cannot replicate, leading to a significant distribution shift
that degrades policy performance. We present EgoMI (Egocentric Manipulation
Interface), a framework that captures synchronized end-effector and active head
trajectories during manipulation tasks, resulting in data that can be
retargeted to compatible semi-humanoid robot embodiments. To handle rapid and
wide-spanning head viewpoint changes, we introduce a memory-augmented policy
that selectively incorporates historical observations. We evaluate our approach
on a bimanual robot equipped with an actuated camera head and find that
policies with explicit head-motion modeling consistently outperform baseline
methods. Results suggest that coordinated hand-eye learning with EgoMI
effectively bridges the human-robot embodiment gap for robust imitation
learning on semi-humanoid embodiments. Project page:
https://egocentric-manipulation-interface.github.io

</details>


### [209] [Reducing Robotic Upper-Limb Assessment Time While Maintaining Precision: A Time Series Foundation Model Approach](https://arxiv.org/abs/2511.00193)
*Faranak Akbarifar,Nooshin Maghsoodi,Sean P Dukelow,Stephen Scott,Parvin Mousavi*

Main category: cs.RO

TL;DR: Foundation models like Chronos can shorten Kinarm VGR assessment time by forecasting synthetic trials, preserving reliability with fewer recorded reaches.


<details>
  <summary>Details</summary>
Motivation: To reduce time and fatigue burdens of Kinarm VGR assessment by replacing unrecorded trials from an early subset of reaches with time-series foundation models.

Method: Analyzed VGR speed signals from stroke and control participants using ARIMA, MOMENT, and Chronos models to forecast synthetic trials and recomputed kinematic features on combined recorded plus forecasted trials.

Result: Chronos forecasts restored ICC >= 0.90 for all parameters with only 8 recorded trials plus forecasts, matching the reliability of 24-28 recorded reaches. MOMENT yielded intermediate gains, while ARIMA improvements were minimal.

Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR assessment time, reducing sessions from 4-5 minutes to about 1 minute while preserving kinematic precision, promising efficient robotic evaluations for assessing motor impairments following stroke.

Abstract: Purpose: Visually Guided Reaching (VGR) on the Kinarm robot yields sensitive
kinematic biomarkers but requires 40-64 reaches, imposing time and fatigue
burdens. We evaluate whether time-series foundation models can replace
unrecorded trials from an early subset of reaches while preserving the
reliability of standard Kinarm parameters.
  Methods: We analyzed VGR speed signals from 461 stroke and 599 control
participants across 4- and 8-target reaching protocols. We withheld all but the
first 8 or 16 reaching trials and used ARIMA, MOMENT, and Chronos models,
fine-tuned on 70 percent of subjects, to forecast synthetic trials. We
recomputed four kinematic features of reaching (reaction time, movement time,
posture speed, maximum speed) on combined recorded plus forecasted trials and
compared them to full-length references using ICC(2,1).
  Results: Chronos forecasts restored ICC >= 0.90 for all parameters with only
8 recorded trials plus forecasts, matching the reliability of 24-28 recorded
reaches (Delta ICC <= 0.07). MOMENT yielded intermediate gains, while ARIMA
improvements were minimal. Across cohorts and protocols, synthetic trials
replaced reaches without materially compromising feature reliability.
  Conclusion: Foundation-model forecasting can greatly shorten Kinarm VGR
assessment time. For the most impaired stroke survivors, sessions drop from 4-5
minutes to about 1 minute while preserving kinematic precision. This
forecast-augmented paradigm promises efficient robotic evaluations for
assessing motor impairments following stroke.

</details>


### [210] [Tailored robotic training improves hand function and proprioceptive processing in stroke survivors with proprioceptive deficits: A randomized controlled trial](https://arxiv.org/abs/2511.00259)
*Andria J. Farrens,Luis Garcia-Fernandez,Raymond Diaz Rojas,Jillian Obeso Estrada,Dylan Reinsdorf,Vicky Chan,Disha Gupta,Joel Perry,Eric Wolbrecht,An Do,Steven C. Cramer,David J. Reinkensmeyer*

Main category: cs.RO

TL;DR: 研究发现，针对本体感觉的定制机器人训练（Propriopixel和虚拟辅助）能显著改善中风幸存者的手功能，并通过EEG生物标志物证实了神经敏感性的提升。


<details>
  <summary>Details</summary>
Motivation: 精准康复旨在通过定制运动训练改善康复效果。本研究测试了针对本体感觉的机器人训练是否能改善中风幸存者的手功能和神经处理。

Method: 研究采用随机对照试验设计，46名慢性中风幸存者完成了九次2小时的标准化、Propriopixel或虚拟辅助训练。Propriopixel训练通过机器人辅助的游戏化运动增强本体感觉处理，虚拟辅助训练则减少机器人辅助以增加对自我生成反馈的依赖。

Result: 在本体感觉缺陷的参与者中，Propriopixel训练（Box and Block Test: 7 +/- 4.2, p=0.002）和虚拟辅助训练（4.5 +/- 4.4, p=0.068）比标准化训练（0.8 +/- 2.3块）在手功能方面有更大改善。本体感觉的改善与手功能的提升相关。

Conclusion: 研究支持针对本体感觉的定制训练作为精准神经康复的途径，通过增强神经对本体感觉线索的敏感性来改善手功能。

Abstract: Precision rehabilitation aims to tailor movement training to improve
outcomes. We tested whether proprioceptively-tailored robotic training improves
hand function and neural processing in stroke survivors. Using a robotic finger
exoskeleton, we tested two proprioceptively-tailored approaches: Propriopixel
Training, which uses robot-facilitated, gamified movements to enhance
proprioceptive processing, and Virtual Assistance Training, which reduces
robotic aid to increase reliance on self-generated feedback. In a randomized
controlled trial, forty-six chronic stroke survivors completed nine 2-hour
sessions of Standard, Propriopixel or Virtual training. Among participants with
proprioceptive deficits, Propriopixel ((Box and Block Test: 7 +/- 4.2, p=0.002)
and Virtual Assistance (4.5 +/- 4.4 , p=0.068) yielded greater gains in hand
function (Standard: 0.8 +/- 2.3 blocks). Proprioceptive gains correlated with
improvements in hand function. Tailored training enhanced neural sensitivity to
proprioceptive cues, evidenced by a novel EEG biomarker, the proprioceptive
Contingent Negative Variation. These findings support proprioceptively-tailored
training as a pathway to precision neurorehabilitation.

</details>


### [211] [FGO MythBusters: Explaining how Kalman Filter variants achieve the same performance as FGO in navigation applications](https://arxiv.org/abs/2511.00306)
*Baoshan Song,Ruijie Xu,Li-Ta Hsu*

Main category: cs.RO

TL;DR: 本文阐明了SW-FGO与KFV的理论联系，提出Re-FGO框架并验证其与KFV的等价性，同时展示了SW-FGO在非线性和非高斯环境下的优势。


<details>
  <summary>Details</summary>
Motivation: 探索SW-FGO与卡尔曼滤波器变体（KFV）之间的理论联系，解决现有研究中存在的理论空白。

Method: 基于必要公平条件，提出递归FGO（Re-FGO）框架，并在显式条件下（马尔可夫假设、高斯噪声和L2损失、单状态窗口）验证其与KFV的等价性。

Result: 在特定条件下，Re-FGO可以精确重现EKF/IEKF/REKF/RIEKF，而SW-FGO在非线性和非高斯环境下展现出优势。

Conclusion: 本文澄清了滑动窗口因子图优化（SW-FGO）与卡尔曼滤波器变体（KFV）之间的理论联系，并提出了递归FGO（Re-FGO）框架来表示KFV。在特定条件下，Re-FGO可以精确重现EKF/IEKF/REKF/RIEKF，而SW-FGO在非线性和非高斯环境下展现出可预测的计算成本优势。

Abstract: Sliding window-factor graph optimization (SW-FGO) has gained more and more
attention in navigation research due to its robust approximation to
non-Gaussian noises and nonlinearity of measuring models. There are lots of
works focusing on its application performance compared to extended Kalman
filter (EKF) but there is still a myth at the theoretical relationship between
the SW-FGO and EKF. In this paper, we find the necessarily fair condition to
connect SW-FGO and Kalman filter variants (KFV) (e.g., EKF, iterative EKF
(IEKF), robust EKF (REKF) and robust iterative EKF (RIEKF)). Based on the
conditions, we propose a recursive FGO (Re-FGO) framework to represent KFV
under SW-FGO formulation. Under explicit conditions (Markov assumption,
Gaussian noise with L2 loss, and a one-state window), Re-FGO regenerates
exactly to EKF/IEKF/REKF/RIEKF, while SW-FGO shows measurable benefits in
nonlinear, non-Gaussian regimes at a predictable compute cost. Finally, after
clarifying the connection between them, we highlight the unique advantages of
SW-FGO in practical phases, especially on numerical estimation and deep
learning integration. The code and data used in this work is open sourced at
https://github.com/Baoshan-Song/KFV-FGO-Comparison.

</details>


### [212] [SonarSweep: Fusing Sonar and Vision for Robust 3D Reconstruction via Plane Sweeping](https://arxiv.org/abs/2511.00392)
*Lingpeng Chen,Jiakun Tang,Apple Pui-Yi Chui,Ziyang Hong,Junfeng Wu*

Main category: cs.RO

TL;DR: SonarSweep是一种深度学习框架，通过融合声纳和视觉数据解决水下3D重建难题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在水下环境中，单一模态方法（视觉或声纳）存在局限性，现有融合技术依赖启发式方法和有缺陷的几何假设，导致显著伪影且无法建模复杂场景。

Method: 该方法基于改进的平面扫描算法，实现了声纳和视觉数据的端到端深度学习融合。

Result: 实验证明，SonarSweep在高保真仿真和真实环境中均能生成密集且准确的深度图，显著优于现有方法。

Conclusion: SonarSweep是一种新型的端到端深度学习框架，通过跨模态融合声纳和视觉数据，解决了视觉退化水下环境中的3D重建难题，并在高浊度等挑战性条件下显著优于现有方法。

Abstract: Accurate 3D reconstruction in visually-degraded underwater environments
remains a formidable challenge. Single-modality approaches are insufficient:
vision-based methods fail due to poor visibility and geometric constraints,
while sonar is crippled by inherent elevation ambiguity and low resolution.
Consequently, prior fusion technique relies on heuristics and flawed geometric
assumptions, leading to significant artifacts and an inability to model complex
scenes. In this paper, we introduce SonarSweep, a novel, end-to-end deep
learning framework that overcomes these limitations by adapting the principled
plane sweep algorithm for cross-modal fusion between sonar and visual data.
Extensive experiments in both high-fidelity simulation and real-world
environments demonstrate that SonarSweep consistently generates dense and
accurate depth maps, significantly outperforming state-of-the-art methods
across challenging conditions, particularly in high turbidity. To foster
further research, we will publicly release our code and a novel dataset
featuring synchronized stereo-camera and sonar data, the first of its kind.

</details>


### [213] [Runge-Kutta Approximations for Direct Coning Compensation Applying Lie Theory](https://arxiv.org/abs/2511.00412)
*John A. Christian,Michael R. Walker II,Wyatt Bridgman,Michael J. Sparapany*

Main category: cs.RO

TL;DR: 提出基于Runge-Kutta的新型圆锥补偿算法，可生成高阶版本，简单情况下退化为现有流行算法。


<details>
  <summary>Details</summary>
Motivation: 现代导航系统中，陀螺仪测量的积分是关键任务，而圆锥补偿算法对于处理传感器旋转至关重要。现有算法虽多，但仍有改进空间。

Method: 通过将经典Runge-Kutta积分方法直接应用于圆锥补偿问题，构建了一类新的算法。

Result: 新算法在简单情况下可退化为现有流行算法，并提供了生成高阶算法的清晰流程。

Conclusion: 本文提出了一种基于经典Runge-Kutta积分方法的新型圆锥补偿算法，并能生成高阶算法。

Abstract: The integration of gyroscope measurements is an essential task for most
navigation systems. Modern vehicles typically use strapdown systems, such that
gyro integration requires coning compensation to account for the sensor's
rotation during the integration. Many coning compensation algorithms have been
developed and a few are reviewed. This work introduces a new class of coning
correction algorithm built directly from the classical Runge-Kutta integration
routines. A simple case is shown to collapse to one of the most popular coning
algorithms and a clear procedure for generating higher-order algorithms is
presented.

</details>


### [214] [Design and Development of a Modular Bucket Drum Excavator for Lunar ISRU](https://arxiv.org/abs/2511.00492)
*Simon Giel,James Hurrell,Shreya Santra,Ashutosh Mishra,Kentaro Uno,Kazuya Yoshida*

Main category: cs.RO

TL;DR: 开发了一种用于月球资源开采的3D打印桶鼓工具，测试显示其高效且与MoonBot兼容，未来可进一步优化。


<details>
  <summary>Details</summary>
Motivation: 研究动机是支持月球资源的可持续利用，特别是通过开发能够高效挖掘月球表土的设备。

Method: 研究方法包括设计并3D打印PLA原型，通过一系列沙盒测试评估其效率。

Result: 测试结果显示，该工具重4.8公斤，体积14.06升，连续挖掘速率为777.54公斤/小时，标准化能耗为0.022 Wh/kg；批量操作时挖掘速率为172.02公斤/小时，能耗为0.86 Wh/kg。

Conclusion: 该研究的结论是成功开发了一种适用于月球资源开采的桶鼓工具，并验证了其与MoonBot机器人平台的兼容性，未来可通过集成传感器和自主控制系统进一步优化。

Abstract: In-Situ Resource Utilization (ISRU) is one of the key technologies for
enabling sustainable access to the Moon. The ability to excavate lunar regolith
is the first step in making lunar resources accessible and usable. This work
presents the development of a bucket drum for the modular robotic system
MoonBot, as part of the Japanese Moonshot program. A 3D-printed prototype made
of PLA was manufactured to evaluate its efficiency through a series of sandbox
tests. The resulting tool weighs 4.8 kg and has a volume of 14.06 L. It is
capable of continuous excavation at a rate of 777.54 kg/h with a normalized
energy consumption of 0.022 Wh/kg. In batch operation, the excavation rate is
172.02 kg/h with a normalized energy consumption of 0.86 Wh per kilogram of
excavated material. The obtained results demonstrate the successful
implementation of the concept. A key advantage of the developed tool is its
compatibility with the modular MoonBot robotic platform, which enables flexible
and efficient mission planning. Further improvements may include the
integration of sensors and an autonomous control system to enhance the
excavation process.

</details>


### [215] [Descriptive Model-based Learning and Control for Bipedal Locomotion](https://arxiv.org/abs/2511.00512)
*Suraj Kumar,Andy Ruina*

Main category: cs.RO

TL;DR: 提出了一种避免低维模型限制的双足平衡控制方法，实现了更高效的人形步态。


<details>
  <summary>Details</summary>
Motivation: 传统双足机器人平衡控制方法依赖低维模型进行运动规划和反应控制，限制了机器人的运动灵活性，导致低效的行走模式。

Method: 采用描述性模型，仅使用维持平衡所需的最小自由度，其余自由度在高维空间中自由演化。

Result: 新方法允许机器人在高维状态空间中自由运动，仅约束其在低维状态空间中的投影，实现了高效的人形步态和更强的鲁棒性。

Conclusion: 该研究提出了一种新的双足平衡控制方法，通过避免对完整模型施加低维模型的限制，实现了更高效的人形步态和更强的鲁棒性。

Abstract: Bipedal balance is challenging due to its multi-phase, hybrid nature and
high-dimensional state space. Traditional balance control approaches for
bipedal robots rely on low-dimensional models for locomotion planning and
reactive control, constraining the full robot to behave like these simplified
models. This involves tracking preset reference paths for the Center of Mass
and upper body obtained through low-dimensional models, often resulting in
inefficient walking patterns with bent knees. However, we observe that bipedal
balance is inherently low-dimensional and can be effectively described with
simple state and action descriptors in a low-dimensional state space. This
allows the robot's motion to evolve freely in its high-dimensional state space,
only constraining its projection in the low-dimensional state space. In this
work, we propose a novel control approach that avoids prescribing a
low-dimensional model to the full model. Instead, our control framework uses a
descriptive model with the minimum degrees of freedom necessary to maintain
balance, allowing the remaining degrees of freedom to evolve freely in the
high-dimensional space. This results in an efficient human-like walking gait
and improved robustness.

</details>


### [216] [Adaptive and Multi-object Grasping via Deformable Origami Modules](https://arxiv.org/abs/2511.00516)
*Peiyi Wang,Paul A. M. Lefeuvre,Shangwei Zou,Zhenwei Ni,Daniela Rus,Cecilia Laschi*

Main category: cs.RO

TL;DR: 提出了一种无需复杂控制或传感的折纸结构多指夹持器，实现了稳定抓取和多物体高效操控。


<details>
  <summary>Details</summary>
Motivation: 现有柔性机器人夹持器解决方案通常依赖笨重的执行器、复杂控制策略或高级触觉传感，难以实现稳定可靠的抓取性能。

Method: 提出了一种多指混合夹持器，采用被动可变形的折纸模块，通过1-DoF驱动机制实现被动形状适应和稳定抓取力，无需主动感知或反馈控制。

Result: 展示了多物体同时抓取的有趣能力，可独立拾取、运输和放置不同形状和大小的堆叠物体，显著提高了操作效率。

Conclusion: 基于折纸结构的柔性机器人夹持器展示了其作为可扩展模块在家庭和工业拾取放置场景中实现自适应、稳定且高效的多物体操控的潜力。

Abstract: Soft robotics gripper have shown great promise in handling fragile and
geometrically complex objects. However, most existing solutions rely on bulky
actuators, complex control strategies, or advanced tactile sensing to achieve
stable and reliable grasping performance. In this work, we present a
multi-finger hybrid gripper featuring passively deformable origami modules that
generate constant force and torque output. Each finger composed of parallel
origami modules is driven by a 1-DoF actuator mechanism, enabling passive shape
adaptability and stable grasping force without active sensing or feedback
control. More importantly, we demonstrate an interesting capability in
simultaneous multi-object grasping, which allows stacked objects of varied
shape and size to be picked, transported and placed independently at different
states, significantly improving manipulation efficiency compared to
single-object grasping. These results highlight the potential of origami-based
compliant structures as scalable modules for adaptive, stable and efficient
multi-object manipulation in domestic and industrial pick-and-place scenarios.

</details>


### [217] [Improving Robustness to Out-of-Distribution States in Imitation Learning via Deep Koopman-Boosted Diffusion Policy](https://arxiv.org/abs/2511.00555)
*Dianye Huang,Nassir Navab,Zhongliang Jiang*

Main category: cs.RO

TL;DR: D3P算法通过双分支架构和Deep Koopman模块优化了模仿学习的策略生成，显著提升了任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在捕捉多步时序依赖时表现不佳，尤其在结合本体感受输入时容易过拟合，导致任务失败。

Method: 提出D3P算法，采用双分支架构（视觉分支和融合分支）解耦不同感官模态的角色，并引入Deep Koopman Operator模块增强视觉表征学习。

Result: 在六个RLBench桌面任务中平均提升14.6%，在三个真实机器人任务中提升15.0%。

Conclusion: D3P算法通过双分支架构和Deep Koopman模块显著提升了模仿学习中的任务完成率和策略可靠性，在模拟和真实机器人任务中均优于现有方法。

Abstract: Integrating generative models with action chunking has shown significant
promise in imitation learning for robotic manipulation. However, the existing
diffusion-based paradigm often struggles to capture strong temporal
dependencies across multiple steps, particularly when incorporating
proprioceptive input. This limitation can lead to task failures, where the
policy overfits to proprioceptive cues at the expense of capturing the visually
derived features of the task. To overcome this challenge, we propose the Deep
Koopman-boosted Dual-branch Diffusion Policy (D3P) algorithm. D3P introduces a
dual-branch architecture to decouple the roles of different sensory modality
combinations. The visual branch encodes the visual observations to indicate
task progression, while the fused branch integrates both visual and
proprioceptive inputs for precise manipulation. Within this architecture, when
the robot fails to accomplish intermediate goals, such as grasping a drawer
handle, the policy can dynamically switch to execute action chunks generated by
the visual branch, allowing recovery to previously observed states and
facilitating retrial of the task. To further enhance visual representation
learning, we incorporate a Deep Koopman Operator module that captures
structured temporal dynamics from visual inputs. During inference, we use the
test-time loss of the generative model as a confidence signal to guide the
aggregation of the temporally overlapping predicted action chunks, thereby
enhancing the reliability of policy execution. In simulation experiments across
six RLBench tabletop tasks, D3P outperforms the state-of-the-art diffusion
policy by an average of 14.6\%. On three real-world robotic manipulation tasks,
it achieves a 15.0\% improvement. Code: https://github.com/dianyeHuang/D3P.

</details>


### [218] [Multi-Mapcher: Loop Closure Detection-Free Heterogeneous LiDAR Multi-Session SLAM Leveraging Outlier-Robust Registration for Autonomous Vehicles](https://arxiv.org/abs/2511.00635)
*Hyungtae Lim,Daebeom Kim,Hyun Myung*

Main category: cs.RO

TL;DR: Multi-Mapcher通过地图注册和位姿图优化，提升了多会话SLAM性能，不依赖闭环检测。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖闭环检测，但传感器密度和视场差异可能导致性能下降，因此需探索不依赖闭环检测的替代方案。

Method: 提出了Multi-Mapcher框架，利用鲁棒的3D点云注册进行初始对齐，并通过半径搜索和锚点节点优化的位姿图构建全局一致地图。

Result: 实验表明，Multi-Mapcher在性能和速度上均优于现有方法，适用于多种LiDAR传感器。

Conclusion: Multi-Mapcher框架通过大规模地图到地图的注册和鲁棒的位姿图优化，显著提升了多会话SLAM的性能，适用于不同LiDAR传感器。

Abstract: As various 3D light detection and ranging (LiDAR) sensors have been
introduced to the market, research on multi-session simultaneous localization
and mapping (MSS) using heterogeneous LiDAR sensors has been actively
conducted. Existing MSS methods mostly rely on loop closure detection for
inter-session alignment; however, the performance of loop closure detection can
be potentially degraded owing to the differences in the density and field of
view (FoV) of the sensors used in different sessions. In this study, we
challenge the existing paradigm that relies heavily on loop detection modules
and propose a novel MSS framework, called Multi-Mapcher, that employs
large-scale map-to-map registration to perform inter-session initial alignment,
which is commonly assumed to be infeasible, by leveraging outlier-robust 3D
point cloud registration. Next, after finding inter-session loops by radius
search based on the assumption that the inter-session initial alignment is
sufficiently precise, anchor node-based robust pose graph optimization is
employed to build a consistent global map. As demonstrated in our experiments,
our approach shows substantially better MSS performance for various LiDAR
sensors used to capture the sessions and is faster than state-of-the-art
approaches. Our code is available at
https://github.com/url-kaist/multi-mapcher.

</details>


### [219] [When Semantics Connect the Swarm: LLM-Driven Fuzzy Control for Cooperative Multi-Robot Underwater Coverage](https://arxiv.org/abs/2511.00783)
*Jingzehua Xu,Weihang Zhang,Yangyang Li,Hongmiaoyi Zhang,Guanwen Xie,Jiwei Tang,Shuai Zhang,Yi Li*

Main category: cs.RO

TL;DR: 论文提出一种结合LLMs和模糊控制的框架，解决水下多机器人协作覆盖的挑战，仿真验证其高效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 水下多机器人协作覆盖面临部分可观测性、通信受限、环境不确定性及缺乏全局定位等挑战，亟需一种无需依赖全局定位的可靠解决方案。

Method: 论文采用LLMs压缩原始多模态观测为紧凑的语义标记，结合模糊推理系统生成稳定的导航指令，并通过语义通信实现多机器人间的轻量级协调。

Result: 仿真实验表明，该框架在有限感知和通信条件下，实现了稳健的面向OOI的导航和高效协作覆盖。

Conclusion: 该论文提出的语义引导模糊控制框架通过结合大型语言模型（LLMs）和轻量级协调，显著提升了水下多机器人协作覆盖的效率和适应性，缩小了语义认知与分布式水下控制之间的差距。

Abstract: Underwater multi-robot cooperative coverage remains challenging due to
partial observability, limited communication, environmental uncertainty, and
the lack of access to global localization. To address these issues, this paper
presents a semantics-guided fuzzy control framework that couples Large Language
Models (LLMs) with interpretable control and lightweight coordination. Raw
multimodal observations are compressed by the LLM into compact,
human-interpretable semantic tokens that summarize obstacles, unexplored
regions, and Objects Of Interest (OOIs) under uncertain perception. A fuzzy
inference system with pre-defined membership functions then maps these tokens
into smooth and stable steering and gait commands, enabling reliable navigation
without relying on global positioning. Then, we further coordinate multiple
robots by introducing semantic communication that shares intent and local
context in linguistic form, enabling agreement on who explores where while
avoiding redundant revisits. Extensive simulations in unknown reef-like
environments show that, under limited sensing and communication, the proposed
framework achieves robust OOI-oriented navigation and cooperative coverage with
improved efficiency and adaptability, narrowing the gap between semantic
cognition and distributed underwater control in GPS-denied, map-free
conditions.

</details>


### [220] [Real-Time Learning of Predictive Dynamic Obstacle Models for Robotic Motion Planning](https://arxiv.org/abs/2511.00814)
*Stella Kombo,Masih Haseli,Skylar Wei,Joel W. Burdick*

Main category: cs.RO

TL;DR: 该论文提出了一种基于Hankel-DMD的实时去噪与预测方法，适用于自主系统中的运动预测，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 自主系统需要从部分和噪声数据中预测附近代理的运动，本文旨在探索是否能在实时学习中构建非线性预测模型。

Method: 使用Hankel矩阵嵌入部分噪声测量，结合Page矩阵进行奇异值硬阈值（SVHT）估计有效秩，通过Cadzow投影确保结构化低秩一致性，构建时变Hankel-DMD提升线性预测器进行多步预测。

Result: 在模拟和动态起重机实验平台上验证，该方法在Gaussian和heavy-tailed噪声下均能实现稳定的方差感知去噪和短时程预测。

Conclusion: 该方法通过改进的滑动窗口Hankel动态模式分解（Hankel-DMD），实现了对噪声和部分观测数据的实时去噪与预测，适用于实时控制框架。

Abstract: Autonomous systems often must predict the motions of nearby agents from
partial and noisy data. This paper asks and answers the question: "can we
learn, in real-time, a nonlinear predictive model of another agent's motions?"
Our online framework denoises and forecasts such dynamics using a modified
sliding-window Hankel Dynamic Mode Decomposition (Hankel-DMD). Partial noisy
measurements are embedded into a Hankel matrix, while an associated Page matrix
enables singular-value hard thresholding (SVHT) to estimate the effective rank.
A Cadzow projection enforces structured low-rank consistency, yielding a
denoised trajectory and local noise variance estimates. From this
representation, a time-varying Hankel-DMD lifted linear predictor is
constructed for multi-step forecasts. The residual analysis provides
variance-tracking signals that can support downstream estimators and risk-aware
planning. We validate the approach in simulation under Gaussian and
heavy-tailed noise, and experimentally on a dynamic crane testbed. Results show
that the method achieves stable variance-aware denoising and short-horizon
prediction suitable for integration into real-time control frameworks.

</details>


### [221] [Heuristic Step Planning for Learning Dynamic Bipedal Locomotion: A Comparative Study of Model-Based and Model-Free Approaches](https://arxiv.org/abs/2511.00840)
*William Suliman,Ekaterina Chaikovskaia,Egor Davydenko,Roman Gorbachev*

Main category: cs.RO

TL;DR: 该论文提出了一种启发式步态规划框架，通过简化控制策略实现高效双足行走，实验证明其在速度和地形适应性上优于传统模型方法。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种无需复杂步态规划器或解析模型的双足行走方法，以提高在非结构化环境中的鲁棒性和能效。

Method: 提出了一种基于启发式命令的步态规划框架，结合Raibert型控制器根据期望与实际躯干速度误差调节步长。

Result: 实验结果显示，该方法在维持目标速度（高达80%）、在不平坦地形上的鲁棒性（提升50%以上）及能效方面均优于基于线性倒立摆模型（LIPM）的方法。

Conclusion: 该研究表明，通过结合启发式步态规划策略，可以在不依赖复杂模型的情况下实现稳定且鲁棒的双足行走，甚至在非结构化环境中也能表现优异。

Abstract: This work presents an extended framework for learning-based bipedal
locomotion that incorporates a heuristic step-planning strategy guided by
desired torso velocity tracking. The framework enables precise interaction
between a humanoid robot and its environment, supporting tasks such as crossing
gaps and accurately approaching target objects. Unlike approaches based on full
or simplified dynamics, the proposed method avoids complex step planners and
analytical models. Step planning is primarily driven by heuristic commands,
while a Raibert-type controller modulates the foot placement length based on
the error between desired and actual torso velocity. We compare our method with
a model-based step-planning approach -- the Linear Inverted Pendulum Model
(LIPM) controller. Experimental results demonstrate that our approach attains
comparable or superior accuracy in maintaining target velocity (up to 80%),
significantly greater robustness on uneven terrain (over 50% improvement), and
improved energy efficiency. These results suggest that incorporating complex
analytical, model-based components into the training architecture may be
unnecessary for achieving stable and robust bipedal walking, even in
unstructured environments.

</details>


### [222] [Maestro: Orchestrating Robotics Modules with Vision-Language Models for Zero-Shot Generalist Robots](https://arxiv.org/abs/2511.00917)
*Junyao Shi,Rujia Yang,Kaitian Chao,Selina Bingqing Wan,Yifei Shao,Jiahui Lei,Jianing Qian,Long Le,Pratik Chaudhari,Kostas Daniilidis,Chuan Wen,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: Maestro通过VLM动态组合机器人模块，显著提升零样本性能，且易于扩展和适应。


<details>
  <summary>Details</summary>
Motivation: 探索不同于主流大规模数据集训练的路径，通过结合VLMs的通用能力和机器人专用模块，构建通用机器人策略。

Method: 利用VLM编码代理动态组合感知、规划和控制的模块化组件，构建程序化策略。

Result: Maestro在零样本性能上大幅超越现有VLA模型，且易于扩展和适应新场景。

Conclusion: Maestro通过结合视觉语言模型（VLMs）和机器人专用模块，显著提升了零样本性能，并具备良好的可扩展性和适应性。

Abstract: Today's best-explored routes towards generalist robots center on collecting
ever larger "observations-in actions-out" robotics datasets to train large
end-to-end models, copying a recipe that has worked for vision-language models
(VLMs). We pursue a road less traveled: building generalist policies directly
around VLMs by augmenting their general capabilities with specific robot
capabilities encapsulated in a carefully curated set of perception, planning,
and control modules. In Maestro, a VLM coding agent dynamically composes these
modules into a programmatic policy for the current task and scenario. Maestro's
architecture benefits from a streamlined closed-loop interface without many
manually imposed structural constraints, and a comprehensive and diverse tool
repertoire. As a result, it largely surpasses today's VLA models for zero-shot
performance on challenging manipulation skills. Further, Maestro is easily
extensible to incorporate new modules, easily editable to suit new embodiments
such as a quadruped-mounted arm, and even easily adapts from minimal real-world
experiences through local code edits.

</details>


### [223] [Fast-SmartWay: Panoramic-Free End-to-End Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2511.00933)
*Xiangyu Shi,Zerui Li,Yanyuan Qiao,Qi Wu*

Main category: cs.RO

TL;DR: Fast-SmartWay 是一种端到端零样本 VLN-CE 框架，无需全景视图或路径点预测器，通过不确定性感知推理提升决策鲁棒性，实验证明其低延迟和高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 VLN-CE 方法依赖全景观察和两阶段流程（如路径点预测器），导致显著延迟并限制实际应用。

Method: Fast-SmartWay 是一个端到端的零样本 VLN-CE 框架，仅使用三个正面 RGB-D 图像和自然语言指令，通过 MLLMs 直接预测动作。引入了不确定性感知推理模块（包括消歧模块和未来-过去双向推理机制）以增强决策鲁棒性。

Result: 在模拟和真实机器人环境中的实验表明，该方法显著降低了每步延迟，同时性能优于或与全景视图基线相当。

Conclusion: Fast-SmartWay 展示了在现实世界中零样本导航的实用性和有效性，显著降低了延迟并提升了性能。

Abstract: Recent advances in Vision-and-Language Navigation in Continuous Environments
(VLN-CE) have leveraged multimodal large language models (MLLMs) to achieve
zero-shot navigation. However, existing methods often rely on panoramic
observations and two-stage pipelines involving waypoint predictors, which
introduce significant latency and limit real-world applicability. In this work,
we propose Fast-SmartWay, an end-to-end zero-shot VLN-CE framework that
eliminates the need for panoramic views and waypoint predictors. Our approach
uses only three frontal RGB-D images combined with natural language
instructions, enabling MLLMs to directly predict actions. To enhance decision
robustness, we introduce an Uncertainty-Aware Reasoning module that integrates
(i) a Disambiguation Module for avoiding local optima, and (ii) a Future-Past
Bidirectional Reasoning mechanism for globally coherent planning. Experiments
on both simulated and real-robot environments demonstrate that our method
significantly reduces per-step latency while achieving competitive or superior
performance compared to panoramic-view baselines. These results demonstrate the
practicality and effectiveness of Fast-SmartWay for real-world zero-shot
embodied navigation.

</details>


### [224] [URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model](https://arxiv.org/abs/2511.00940)
*Zhe Li,Xiang Bai,Jieyu Zhang,Zhuangzhe Wu,Che Xu,Ying Li,Chengkai Hou,Shanghang Zhang*

Main category: cs.RO

TL;DR: URDF-Anything 是一个端到端的自动重建框架，用于构建关节物体的数字孪生，通过多模态输入联合优化分割和运动学参数预测，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 构建精确的关节物体数字孪生对于机器人仿真训练和具身AI世界模型构建至关重要，但传统方法需要繁琐的手动建模或多阶段流程。

Method: 基于3D多模态大型语言模型（MLLM）的自回归预测框架，结合点云和文本多模态输入，联合优化几何分割和运动学参数预测。

Result: 在几何分割（mIoU提升17%）、运动学参数预测（平均误差减少29%）和物理可执行性（超越基线50%）方面显著优于现有方法，并在训练集外的对象上表现良好。

Conclusion: URDF-Anything 提供了一个高效的解决方案，用于构建机器人仿真的数字孪生，显著提升了从仿真到现实的转换能力。

Abstract: Constructing accurate digital twins of articulated objects is essential for
robotic simulation training and embodied AI world model building, yet
historically requires painstaking manual modeling or multi-stage pipelines. In
this work, we propose \textbf{URDF-Anything}, an end-to-end automatic
reconstruction framework based on a 3D multimodal large language model (MLLM).
URDF-Anything utilizes an autoregressive prediction framework based on
point-cloud and text multimodal input to jointly optimize geometric
segmentation and kinematic parameter prediction. It implements a specialized
$[SEG]$ token mechanism that interacts directly with point cloud features,
enabling fine-grained part-level segmentation while maintaining consistency
with the kinematic parameter predictions. Experiments on both simulated and
real-world datasets demonstrate that our method significantly outperforms
existing approaches regarding geometric segmentation (mIoU 17\% improvement),
kinematic parameter prediction (average error reduction of 29\%), and physical
executability (surpassing baselines by 50\%). Notably, our method exhibits
excellent generalization ability, performing well even on objects outside the
training set. This work provides an efficient solution for constructing digital
twins for robotic simulation, significantly enhancing the sim-to-real transfer
capability.

</details>


### [225] [Breaking the Latency Barrier: Synergistic Perception and Control for High-Frequency 3D Ultrasound Servoing](https://arxiv.org/abs/2511.00983)
*Yizhao Qian,Yujie Zhu,Jiayuan Luo,Li Liu,Yixuan Yuan,Guochen Ning,Hongen Liao*

Main category: cs.RO

TL;DR: 论文提出了一种协同感知与控制设计的RUSS框架，通过双流感知网络和单步流策略，实现了60Hz以上的闭环控制频率，显著提升了动态目标跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、高频干扰下动态目标实时跟踪的关键挑战，尤其是现有系统的端到端延迟问题。

Method: 提出了一种新颖的框架，包括：（1）解耦的双流感知网络，从2D图像高频估计3D平移状态；（2）单步流策略，通过一次推理生成整个动作序列，绕过传统策略的迭代瓶颈。

Result: 在动态模型中，系统能以低于6.5mm的平均误差跟踪复杂3D轨迹，并能从超过170mm的位移中鲁棒地重新获取目标。此外，能以102mm/s的速度跟踪目标，终端误差低于1.7mm。在人体志愿者上的体内实验验证了框架的有效性和鲁棒性。

Conclusion: 该论文提出了一个整体设计的RUSS框架，通过感知与控制的协同设计，实现了高带宽跟踪与大范围重新定位的统一，为动态临床环境中的鲁棒自主性迈出了关键一步。

Abstract: Real-time tracking of dynamic targets amidst large-scale, high-frequency
disturbances remains a critical unsolved challenge in Robotic Ultrasound
Systems (RUSS), primarily due to the end-to-end latency of existing systems.
This paper argues that breaking this latency barrier requires a fundamental
shift towards the synergistic co-design of perception and control. We realize
it in a novel framework with two tightly-coupled contributions: (1) a Decoupled
Dual-Stream Perception Network that robustly estimates 3D translational state
from 2D images at high frequency, and (2) a Single-Step Flow Policy that
generates entire action sequences in one inference pass, bypassing the
iterative bottleneck of conventional policies. This synergy enables a
closed-loop control frequency exceeding 60Hz. On a dynamic phantom, our system
not only tracks complex 3D trajectories with a mean error below 6.5mm but also
demonstrates robust re-acquisition from over 170mm displacement. Furthermore,
it can track targets at speeds of 102mm/s, achieving a terminal error below
1.7mm. Moreover, in-vivo experiments on a human volunteer validate the
framework's effectiveness and robustness in a realistic clinical setting. Our
work presents a RUSS holistically architected to unify high-bandwidth tracking
with large-scale repositioning, a critical step towards robust autonomy in
dynamic clinical environments.

</details>


### [226] [GauDP: Reinventing Multi-Agent Collaboration through Gaussian-Image Synergy in Diffusion Policies](https://arxiv.org/abs/2511.00998)
*Ziye Wang,Li Kang,Yiran Qin,Jiahua Ma,Zhanglin Peng,Lei Bai,Ruimao Zhang*

Main category: cs.RO

TL;DR: GauDP是一种新型高斯图像协同表示方法，在多智能体协作系统中实现可扩展的模仿学习，表现优异且扩展性强。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中平衡个体视角与全局环境感知的挑战，现有方法在细粒度局部控制与全面场景理解之间难以平衡。

Method: GauDP构建了一个全局一致的3D高斯场，并从分散的RGB观测中动态重新分配3D高斯属性到每个智能体的局部视角，使智能体能够自适应地从共享场景表示中查询任务关键特征。

Result: 在RoboFactory基准测试中，GauDP表现优于现有基于图像的方法，并接近基于点云的方法，同时在智能体数量增加时保持强扩展性。

Conclusion: GauDP通过高斯图像协同表示，在多智能体协作系统中实现了可扩展且感知感知的模仿学习，其表现优于现有基于图像的方法，并接近基于点云的方法。

Abstract: Recently, effective coordination in embodied multi-agent systems has remained
a fundamental challenge, particularly in scenarios where agents must balance
individual perspectives with global environmental awareness. Existing
approaches often struggle to balance fine-grained local control with
comprehensive scene understanding, resulting in limited scalability and
compromised collaboration quality. In this paper, we present GauDP, a novel
Gaussian-image synergistic representation that facilitates scalable,
perception-aware imitation learning in multi-agent collaborative systems.
Specifically, GauDP constructs a globally consistent 3D Gaussian field from
decentralized RGB observations, then dynamically redistributes 3D Gaussian
attributes to each agent's local perspective. This enables all agents to
adaptively query task-critical features from the shared scene representation
while maintaining their individual viewpoints. This design facilitates both
fine-grained control and globally coherent behavior without requiring
additional sensing modalities (e.g., 3D point cloud). We evaluate GauDP on the
RoboFactory benchmark, which includes diverse multi-arm manipulation tasks. Our
method achieves superior performance over existing image-based methods and
approaches the effectiveness of point-cloud-driven methods, while maintaining
strong scalability as the number of agents increases.

</details>


### [227] [AquaROM: shape optimization pipeline for soft swimmers using parametric reduced order models](https://arxiv.org/abs/2511.01031)
*Mathieu Dubied,Paolo Tiso,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: 提出基于PROM的新型优化算法，显著提升软体机器人非线性优化的计算效率，应用于游泳者形状优化，效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人等非线性结构在优化过程中计算资源消耗大的问题，尤其是在模拟复杂非线性力时。

Method: 利用张量参数降阶模型（PROM）进行维度缩减和解决方案近似，结合分析梯度在特定降阶基（ROB）中的应用，实现高效的非线性约束优化。

Result: 该方法在优化软体机器人游泳者形状时表现出色，成功降低了计算复杂度，同时保持了计算精度。

Conclusion: 该论文提出了一种基于张量参数降阶模型（PROM）的新型优化算法，显著提高了非线性约束优化问题的计算效率，为软体机器人复杂非线性系统的优化开辟了新途径。

Abstract: The efficient optimization of actuated soft structures, particularly under
complex nonlinear forces, remains a critical challenge in advancing robotics.
Simulations of nonlinear structures, such as soft-bodied robots modeled using
the finite element method (FEM), often demand substantial computational
resources, especially during optimization. To address this challenge, we
propose a novel optimization algorithm based on a tensorial parametric reduced
order model (PROM). Our algorithm leverages dimensionality reduction and
solution approximation techniques to facilitate efficient solving of nonlinear
constrained optimization problems. The well-structured tensorial approach
enables the use of analytical gradients within a specifically chosen reduced
order basis (ROB), significantly enhancing computational efficiency. To
showcase the performance of our method, we apply it to optimizing soft robotic
swimmer shapes. These actuated soft robots experience hydrodynamic forces,
subjecting them to both internal and external nonlinear forces, which are
incorporated into our optimization process using a data-free ROB for fast and
accurate computations. This approach not only reduces computational complexity
but also unlocks new opportunities to optimize complex nonlinear systems in
soft robotics, paving the way for more efficient design and control.

</details>


### [228] [Deployable Vision-driven UAV River Navigation via Human-in-the-loop Preference Alignment](https://arxiv.org/abs/2511.01083)
*Zihan Wang,Jianwen Li,Li-Fan Wu,Nina Mahmoudian*

Main category: cs.RO

TL;DR: SPAR-H方法通过融合直接偏好优化和奖励路径训练，在无人机河流跟踪中实现高效在线适应，提升安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 无人机在河流环境监测和灾害响应中具有快速、低成本覆盖的潜力，但仿真训练的策略在部署时会面临分布偏移和安全风险，需要从有限的人类干预中进行高效适应。

Method: 引入SPAR-H方法，融合直接偏好优化和基于奖励的路径训练即时奖励估计器，并使用信任区域代理更新策略。

Result: SPAR-H在五个HITL测试中实现了最高的最终情节奖励和最低的初始条件方差，奖励模型与人类偏好动作一致并提升未干预选择。

Conclusion: 双状态偏好为河流导航中的数据高效在线适应提供了实用途径。

Abstract: Rivers are critical corridors for environmental monitoring and disaster
response, where Unmanned Aerial Vehicles (UAVs) guided by vision-driven
policies can provide fast, low-cost coverage. However, deployment exposes
simulation-trained policies with distribution shift and safety risks and
requires efficient adaptation from limited human interventions. We study
human-in-the-loop (HITL) learning with a conservative overseer who vetoes
unsafe or inefficient actions and provides statewise preferences by comparing
the agent's proposal with a corrective override. We introduce Statewise Hybrid
Preference Alignment for Robotics (SPAR-H), which fuses direct preference
optimization on policy logits with a reward-based pathway that trains an
immediate-reward estimator from the same preferences and updates the policy
using a trust-region surrogate. With five HITL rollouts collected from a fixed
novice policy, SPAR-H achieves the highest final episodic reward and the lowest
variance across initial conditions among tested methods. The learned reward
model aligns with human-preferred actions and elevates nearby non-intervened
choices, supporting stable propagation of improvements. We benchmark SPAR-H
against imitation learning (IL), direct preference variants, and evaluative
reinforcement learning (RL) in the HITL setting, and demonstrate real-world
feasibility of continual preference alignment for UAV river following. Overall,
dual statewise preferences empirically provide a practical route to
data-efficient online adaptation in riverine navigation.

</details>


### [229] [SLAP: Shortcut Learning for Abstract Planning](https://arxiv.org/abs/2511.01107)
*Y. Isabel Liu,Bowen Li,Benjamin Eysenbach,Tom Silver*

Main category: cs.RO

TL;DR: SLAP结合TAMP和RL自动发现新选项，显著提升规划效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 长时程决策在稀疏奖励和连续状态动作空间中的挑战，以及TAMP中手动定义选项的局限性，促使研究者寻求自动发现新选项的方法。

Method: SLAP利用现有的TAMP选项，通过模型无关的强化学习（RL）在抽象规划图中学习捷径，自动发现新的选项。

Result: SLAP在四个模拟机器人环境中，将总体规划长度减少了50%以上，并在任务成功率和泛化能力上优于纯规划和分层RL基线。

Conclusion: SLAP通过结合TAMP和模型无关的强化学习，自动发现新的抽象动作（选项），显著提高了任务成功率和规划效率，并在多个模拟机器人环境中验证了其优越性。

Abstract: Long-horizon decision-making with sparse rewards and continuous states and
actions remains a fundamental challenge in AI and robotics. Task and motion
planning (TAMP) is a model-based framework that addresses this challenge by
planning hierarchically with abstract actions (options). These options are
manually defined, limiting the agent to behaviors that we as human engineers
know how to program (pick, place, move). In this work, we propose Shortcut
Learning for Abstract Planning (SLAP), a method that leverages existing TAMP
options to automatically discover new ones. Our key idea is to use model-free
reinforcement learning (RL) to learn shortcuts in the abstract planning graph
induced by the existing options in TAMP. Without any additional assumptions or
inputs, shortcut learning leads to shorter solutions than pure planning, and
higher task success rates than flat and hierarchical RL. Qualitatively, SLAP
discovers dynamic physical improvisations (e.g., slap, wiggle, wipe) that
differ significantly from the manually-defined ones. In experiments in four
simulated robotic environments, we show that SLAP solves and generalizes to a
wide range of tasks, reducing overall plan lengths by over 50% and consistently
outperforming planning and RL baselines.

</details>


### [230] [An Enhanced Proprioceptive Method for Soft Robots Integrating Bend Sensors and IMUs](https://arxiv.org/abs/2511.01165)
*Dong Heon Han,Mayank Mehta,Runze Zuo,Zachary Wanger,Daniel Bruder*

Main category: cs.RO

TL;DR: 提出了一种结合IMU和弯曲传感器的软机器人形状估计方法，通过卡尔曼滤波器融合数据，显著减少误差并提高长期可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人形状估计中IMU漂移问题，提高长期本体感知的可靠性，同时保持成本效益和易用性。

Method: 结合惯性测量单元（IMUs）和互补弯曲传感器，通过卡尔曼滤波器融合两种传感器的段尖方向数据，采用分段恒定曲率模型从融合数据中估计尖端位置并重建机器人变形。

Result: 在45分钟连续运行的实验中，无负载、外力及被动障碍交互条件下，均方根误差为16.96毫米（总长度的2.91%），相比仅使用IMU的方法减少了56%。

Conclusion: 本研究提出了一种增强的本体感知方法，通过仅使用现成的传感器实现软机器人的精确形状估计，证明了其在长期运行中的高准确性和鲁棒性。

Abstract: This study presents an enhanced proprioceptive method for accurate shape
estimation of soft robots using only off-the-shelf sensors, ensuring
cost-effectiveness and easy applicability. By integrating inertial measurement
units (IMUs) with complementary bend sensors, IMU drift is mitigated, enabling
reliable long-term proprioception. A Kalman filter fuses segment tip
orientations from both sensors in a mutually compensatory manner, improving
shape estimation over single-sensor methods. A piecewise constant curvature
model estimates the tip location from the fused orientation data and
reconstructs the robot's deformation. Experiments under no loading, external
forces, and passive obstacle interactions during 45 minutes of continuous
operation showed a root mean square error of 16.96 mm (2.91% of total length),
a 56% reduction compared to IMU-only benchmarks. These results demonstrate that
our approach not only enables long-duration proprioception in soft robots but
also maintains high accuracy and robustness across these diverse conditions.

</details>


### [231] [Scaling Cross-Embodiment World Models for Dexterous Manipulation](https://arxiv.org/abs/2511.01177)
*Zihao He,Bo Ai,Tongzhou Mu,Yulin Liu,Weikang Wan,Jiawei Fu,Yilun Du,Henrik I. Christensen,Hao Su*

Main category: cs.RO

TL;DR: 跨具身学习通过共享世界模型实现策略迁移，实验验证了其在灵巧操作中的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究跨具身学习的核心问题：是否存在动作迁移的不变性，并提出环境动力学是不变性的假设。

Method: 采用基于3D粒子的共享表示和基于图的世界模型，整合了多样化的模拟和真实数据。

Result: 实验表明：(i) 更多训练具身提升泛化能力，(ii) 模拟与真实数据联合训练效果更佳，(iii) 模型能有效控制不同自由度的机器人。

Conclusion: 跨具身学习通过世界模型作为通用接口，实现了在不同形态机器人之间的有效策略迁移，尤其在灵巧操作任务中表现出色。

Abstract: Cross-embodiment learning seeks to build generalist robots that operate
across diverse morphologies, but differences in action spaces and kinematics
hinder data sharing and policy transfer. This raises a central question: Is
there any invariance that allows actions to transfer across embodiments? We
conjecture that environment dynamics are embodiment-invariant, and that world
models capturing these dynamics can provide a unified interface across
embodiments. To learn such a unified world model, the crucial step is to design
state and action representations that abstract away embodiment-specific details
while preserving control relevance. To this end, we represent different
embodiments (e.g., human hands and robot hands) as sets of 3D particles and
define actions as particle displacements, creating a shared representation for
heterogeneous data and control problems. A graph-based world model is then
trained on exploration data from diverse simulated robot hands and real human
hands, and integrated with model-based planning for deployment on novel
hardware. Experiments on rigid and deformable manipulation tasks reveal three
findings: (i) scaling to more training embodiments improves generalization to
unseen ones, (ii) co-training on both simulated and real data outperforms
training on either alone, and (iii) the learned models enable effective control
on robots with varied degrees of freedom. These results establish world models
as a promising interface for cross-embodiment dexterous manipulation.

</details>


### [232] [LiDAR-VGGT: Cross-Modal Coarse-to-Fine Fusion for Globally Consistent and Metric-Scale Dense Mapping](https://arxiv.org/abs/2511.01186)
*Lijie Wang,Lianjie Guo,Ziyi Xu,Qianhao Wang,Fei Gao,Xieyuanli Chen*

Main category: cs.RO

TL;DR: LiDAR-VGGT通过两阶段融合管道结合LiDAR惯性测距和VGGT模型，解决了校准敏感性和可扩展性问题，实现了优于现有方法的彩色点云重建。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR惯性视觉测距（LIVO）对外部校准高度敏感，而3D视觉基础模型（如VGGT）在大规模环境中可扩展性有限且缺乏度量尺度。

Method: 提出LiDAR-VGGT框架，通过两阶段粗到精的融合管道：预融合模块估计粗略度量尺度的VGGT姿态和点云；后融合模块增强跨模态3D相似性变换，使用基于边界框的正则化减少尺度失真。

Result: LiDAR-VGGT在多个数据集中实现了密集、全局一致的彩色点云，表现优于VGGT和LIVO基线方法。

Conclusion: LiDAR-VGGT框架通过两阶段融合管道，成功克服了现有技术在外部校准敏感性和可扩展性方面的限制，实现了高密度、全局一致的彩色点云重建，并在多个数据集中表现优于现有方法。

Abstract: Reconstructing large-scale colored point clouds is an important task in
robotics, supporting perception, navigation, and scene understanding. Despite
advances in LiDAR inertial visual odometry (LIVO), its performance remains
highly sensitive to extrinsic calibration. Meanwhile, 3D vision foundation
models, such as VGGT, suffer from limited scalability in large environments and
inherently lack metric scale. To overcome these limitations, we propose
LiDAR-VGGT, a novel framework that tightly couples LiDAR inertial odometry with
the state-of-the-art VGGT model through a two-stage coarse- to-fine fusion
pipeline: First, a pre-fusion module with robust initialization refinement
efficiently estimates VGGT poses and point clouds with coarse metric scale
within each session. Then, a post-fusion module enhances cross-modal 3D
similarity transformation, using bounding-box-based regularization to reduce
scale distortions caused by inconsistent FOVs between LiDAR and camera sensors.
Extensive experiments across multiple datasets demonstrate that LiDAR-VGGT
achieves dense, globally consistent colored point clouds and outperforms both
VGGT-based methods and LIVO baselines. The implementation of our proposed novel
color point cloud evaluation toolkit will be released as open source.

</details>


### [233] [Closed-loop Control of Steerable Balloon Endoscopes for Robot-assisted Transcatheter Intracardiac Procedures](https://arxiv.org/abs/2511.01199)
*Max McCandless,Jonathan Hamid,Sammy Elmariah,Nathaniel Langer,Pierre E. Dupont*

Main category: cs.RO

TL;DR: 开发了一种可操纵的气球卡镜，通过充气压力独立控制直径和弯曲角度，适用于多种心内任务。


<details>
  <summary>Details</summary>
Motivation: 推动从开胸手术转向更安全的经导管手术，需要改进成像技术和机器人解决方案。

Method: 设计可操纵的气球卡镜，通过单一输入（气球充气压力）独立控制气球直径和弯曲角度。

Result: 成功开发了一种用于主动脉瓣叶切割的气球设计，并展示了图像闭环控制。

Conclusion: 气球技术可调谐设计适用于多种心内任务，图像闭环控制实现了稳定方向控制。

Abstract: To move away from open-heart surgery towards safer transcatheter procedures,
there is a growing need for improved imaging techniques and robotic solutions
to enable simple, accurate tool navigation. Common imaging modalities, such as
fluoroscopy and ultrasound, have limitations that can be overcome using
cardioscopy, i.e., direct optical visualization inside the beating heart. We
present a cardioscope designed as a steerable balloon. As a balloon, it can be
collapsed to pass through the vasculature and subsequently inflated inside the
heart for visualization and tool delivery through an integrated working
channel. Through careful design of balloon wall thickness, a single input,
balloon inflation pressure, is used to independently control two outputs,
balloon diameter (corresponding to field of view diameter) and balloon bending
angle (enabling precise working channel positioning). This balloon technology
can be tuned to produce cardioscopes designed for a range of intracardiac
tasks. To illustrate this approach, a balloon design is presented for the
specific task of aortic leaflet laceration. Image-based closed-loop control of
bending angle is also demonstrated as a means of enabling stable orientation
control during tool insertion and removal.

</details>


### [234] [Tackling the Kidnapped Robot Problem via Sparse Feasible Hypothesis Sampling and Reliable Batched Multi-Stage Inference](https://arxiv.org/abs/2511.01219)
*Muhua Zhang,Lei Ma,Ying Wu,Kai Shen,Deqing Huang,Henry Leung*

Main category: cs.RO

TL;DR: 该论文提出了一种高效的被动2D全局重定位框架，通过多假设方案和优化指标（SMAD/TAM）解决了KRP问题，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决KRP（机器人绑架问题），即在已知地图中无初始位姿估计的情况下重新定位机器人，尤其是在SLAM初始化或定位丢失时。

Method: 框架将全局重定位视为非凸问题，通过多假设方案结合批处理多阶段推理和早期终止来平衡完整性与效率。利用RRT在可遍历性约束下生成稀疏均匀分布的位置假设，并通过优化的SMAD和TAM指标提升位姿估计的准确性和效率。

Result: 在资源受限的移动机器人上进行的真实实验表明，该框架在全局重定位成功率和计算效率上均优于现有方法。

Conclusion: 该论文提出的被动2D全局重定位框架通过高效可靠的单次LiDAR扫描和占用网格地图估计全局位姿，显著提升了移动机器人的长期自主性。

Abstract: This paper addresses the Kidnapped Robot Problem (KRP), a core localization
challenge of relocalizing a robot in a known map without prior pose estimate
when localization loss or at SLAM initialization. For this purpose, a passive
2-D global relocalization framework is proposed. It estimates the global pose
efficiently and reliably from a single LiDAR scan and an occupancy grid map
while the robot remains stationary, thereby enhancing the long-term autonomy of
mobile robots. The proposed framework casts global relocalization as a
non-convex problem and solves it via the multi-hypothesis scheme with batched
multi-stage inference and early termination, balancing completeness and
efficiency. The Rapidly-exploring Random Tree (RRT), under traversability
constraints, asymptotically covers the reachable space to generate sparse,
uniformly distributed feasible positional hypotheses, fundamentally reducing
the sampling space. The hypotheses are preliminarily ordered by the proposed
Scan Mean Absolute Difference (SMAD), a coarse beam-error level metric that
facilitates the early termination by prioritizing high-likelihood candidates.
The SMAD computation is optimized for non-panoramic scans. And the
Translation-Affinity Scan-to-Map Alignment Metric (TAM) is proposed for
reliable orientation selection at hypothesized positions and accurate final
pose evaluation to mitigate degradation in conventional likelihood-field
metrics under translational uncertainty induced by sparse hypotheses, as well
as non-panoramic LiDAR scan and environmental changes. Real-world experiments
on a resource-constrained mobile robot with non-panoramic LiDAR scan
demonstrate that the proposed framework outperforms existing methods in both
global relocalization success rate and computational efficiency.

</details>


### [235] [Embodiment Transfer Learning for Vision-Language-Action Models](https://arxiv.org/abs/2511.01224)
*Chengmeng Li,Yaxin Peng*

Main category: cs.RO

TL;DR: ET-VLA通过合成数据和思维图技术提升多机器人协作的VLA模型性能，实验验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决现有自回归VLA模型在多机器人协作中的不足，减少真实数据收集成本并提升模型适应性。

Method: 提出了ET-VLA框架，包含合成继续预训练（SCP）和体现思维图技术，通过合成数据预热模型并明确子任务节点，优化多机器人协作。

Result: ET-VLA在仿真基准和真实机器人任务中表现优异，超越OpenVLA 53.2%。

Conclusion: ET-VLA框架通过合成继续预训练（SCP）和体现思维图（Embodied Graph-of-Thought）技术，显著提升了多机器人协作中视觉-语言-动作（VLA）模型的性能，且在真实机器人任务中表现优异。

Abstract: Vision-language-action (VLA) models have significantly advanced robotic
learning, enabling training on large-scale, cross-embodiment data and
fine-tuning for specific robots. However, state-of-the-art autoregressive VLAs
struggle with multi-robot collaboration. We introduce embodiment transfer
learning, denoted as ET-VLA, a novel framework for efficient and effective
transfer of pre-trained VLAs to multi-robot. ET-VLA's core is Synthetic
Continued Pretraining (SCP), which uses synthetically generated data to warm up
the model for the new embodiment, bypassing the need for real human
demonstrations and reducing data collection costs. SCP enables the model to
learn correct actions and precise action token numbers. Following SCP, the
model is fine-tuned on target embodiment data. To further enhance the model
performance on multi-embodiment, we present the Embodied Graph-of-Thought
technique, a novel approach that formulates each sub-task as a node, that
allows the VLA model to distinguish the functionalities and roles of each
embodiment during task execution. Our work considers bimanual robots, a simple
version of multi-robot to verify our approaches. We validate the effectiveness
of our method on both simulation benchmarks and real robots covering three
different bimanual embodiments. In particular, our proposed ET-VLA \space can
outperform OpenVLA on six real-world tasks over 53.2%. We will open-source all
codes to support the community in advancing VLA models for robot learning.

</details>


### [236] [High-Precision Surgical Robotic System for Intraocular Procedures](https://arxiv.org/abs/2511.01232)
*Yu-Ting Lai,Jacob Rosen,Yasamin Foroutani,Ji Ma,Wen-Cheng Wu,Jean-Pierre Hubschman,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 新机器人系统通过高精度工具尖端定位和OCT引导，成功应用于白内障手术，解决了现有技术的精度和工具交换问题。


<details>
  <summary>Details</summary>
Motivation: 现有机器人系统在眼科手术（如白内障和玻璃体视网膜手术）中精度、自由度及工具交换机制不足，需改进以满足临床需求。

Method: 通过机器人校准和精确坐标注册，使用光学相干断层扫描（OCT）系统评估工具尖端定位精度和机械性能。结合深度学习的术前解剖建模和实时监督，展示了系统性能。

Result: 工具尖端定位精度达到0.053±0.031毫米，系统在OCT引导的自动手术中表现优异。

Conclusion: 新设计的机器人系统在工具尖端定位精度、跟踪性能和工具交换机制方面表现出色，成功应用于OCT引导的自动白内障晶状体提取手术，验证了其高精度和实用性。

Abstract: Despite the extensive demonstration of robotic systems for both cataract and
vitreoretinal procedures, existing technologies or mechanisms still possess
insufficient accuracy, precision, and degrees of freedom for instrument
manipulation or potentially automated tool exchange during surgical procedures.
A new robotic system that focuses on improving tooltip accuracy, tracking
performance, and smooth instrument exchange mechanism is therefore designed and
manufactured. Its tooltip accuracy, precision, and mechanical capability of
maintaining small incision through remote center of motion were externally
evaluated using an optical coherence tomography (OCT) system. Through robot
calibration and precise coordinate registration, the accuracy of tooltip
positioning was measured to be 0.053$\pm$0.031 mm, and the overall performance
was demonstrated on an OCT-guided automated cataract lens extraction procedure
with deep learning-based pre-operative anatomical modeling and real-time
supervision.

</details>


### [237] [Don't Just Search, Understand: Semantic Path Planning Agent for Spherical Tensegrity Robots in Unknown Environments](https://arxiv.org/abs/2511.01236)
*Junwen Zhang,Changyue Liu,Pengqi Fu,Xiang Guo,Ye Shi,Xudong Liang,Zhijian Wang,Hanzhi Ma*

Main category: cs.RO

TL;DR: SATPlanner利用LLM进行语义推理，显著提升球形张拉整体机器人在未知环境中的路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 球形张拉整体机器人在未知环境中的路径规划面临挑战，传统方法因缺乏语义理解而效率低下。

Method: 引入了一个基于大型语言模型（LLM）的语义代理SATPlanner，采用自适应观察窗口机制动态调整感知范围。

Result: 在1,000次模拟试验中，SATPlanner成功率达100%，搜索空间比A*算法减少37.2%，且路径长度接近最优。

Conclusion: SATPlanner在物理球形张拉整体机器人原型上验证了其实际可行性，显著提升了路径规划的效率和成功率。

Abstract: Endowed with inherent dynamical properties that grant them remarkable
ruggedness and adaptability, spherical tensegrity robots stand as prototypical
examples of hybrid softrigid designs and excellent mobile platforms. However,
path planning for these robots in unknown environments presents a significant
challenge, requiring a delicate balance between efficient exploration and
robust planning. Traditional path planners, which treat the environment as a
geometric grid, often suffer from redundant searches and are prone to failure
in complex scenarios due to their lack of semantic understanding. To overcome
these limitations, we reframe path planning in unknown environments as a
semantic reasoning task. We introduce a Semantic Agent for Tensegrity robots
(SATPlanner) driven by a Large Language Model (LLM). SATPlanner leverages
high-level environmental comprehension to generate efficient and reliable
planning strategies.At the core of SATPlanner is an Adaptive Observation Window
mechanism, inspired by the "fast" and "slow" thinking paradigms of LLMs. This
mechanism dynamically adjusts the perceptual field of the agent: it narrows for
rapid traversal of open spaces and expands to reason about complex obstacle
configurations. This allows the agent to construct a semantic belief of the
environment, enabling the search space to grow only linearly with the path
length (O(L)) while maintaining path quality. We extensively evaluate
SATPlanner in 1,000 simulation trials, where it achieves a 100% success rate,
outperforming other real-time planning algorithms. Critically, SATPlanner
reduces the search space by 37.2% compared to the A* algorithm while achieving
comparable, near-optimal path lengths. Finally, the practical feasibility of
SATPlanner is validated on a physical spherical tensegrity robot prototype.

</details>


### [238] [Improving Needle Penetration via Precise Rotational Insertion Using Iterative Learning Control](https://arxiv.org/abs/2511.01256)
*Yasamin Foroutani,Yasamin Mousavi-Motlagh,Aya Barzelay,Tsu-Chin Tsao*

Main category: cs.RO

TL;DR: 通过ILC策略优化机器人手术中的旋转插入路径，实验证明其比直线插入更有效，提高了手术精确度和安全性。


<details>
  <summary>Details</summary>
Motivation: 机器人手术中工具路径控制常因系统不对齐、未建模动力学和驱动不精确而受限，需一种方法提高旋转插入的精确性。

Method: 采用迭代学习控制（ILC）策略，通过校准前向运动学和使用OCT体积扫描迭代调整关节命令，优化工具旋转插入的轨迹。

Result: 实验在离体猪眼上进行，优化的轨迹比直线插入在组织穿透和视网膜下注射中表现出更高的成功率。

Conclusion: 该方法通过ILC策略有效克服了机器人手术中工具路径控制的不对齐问题，提高了手术的精确度和安全性，并展示了在其他高精度机器人任务中的潜在应用价值。

Abstract: Achieving precise control of robotic tool paths is often challenged by
inherent system misalignments, unmodeled dynamics, and actuation inaccuracies.
This work introduces an Iterative Learning Control (ILC) strategy to enable
precise rotational insertion of a tool during robotic surgery, improving
penetration efficacy and safety compared to straight insertion tested in
subretinal injection. A 4 degree of freedom (DOF) robot manipulator is used,
where misalignment of the fourth joint complicates the simple application of
needle rotation, motivating an ILC approach that iteratively adjusts joint
commands based on positional feedback. The process begins with calibrating the
forward kinematics for the chosen surgical tool to achieve higher accuracy,
followed by successive ILC iterations guided by Optical Coherence Tomography
(OCT) volume scans to measure the error and refine control inputs. Experimental
results, tested on subretinal injection tasks on ex vivo pig eyes, show that
the optimized trajectory resulted in higher success rates in tissue penetration
and subretinal injection compared to straight insertion, demonstrating the
effectiveness of ILC in overcoming misalignment challenges. This approach
offers potential applications for other high precision robot tasks requiring
controlled insertions as well.

</details>


### [239] [Design and Fabrication of Origami-Inspired Knitted Fabrics for Soft Robotics](https://arxiv.org/abs/2511.01272)
*Sehui Jeong,Magaly C. Aviles,Athena X. Naylor,Cynthia Sung,Allison M. Okamura*

Main category: cs.RO

TL;DR: 研究提出了一种结合折纸结构和针织材料的新方法，通过热熔纱线增强折叠方向性，成功制造出可穿戴机器人，展示了结构可重构性和制造潜力。


<details>
  <summary>Details</summary>
Motivation: 解决软机器人在结构完整性和穿戴舒适性之间的挑战，结合折纸结构的优势与针织材料的可编程性和穿戴性。

Method: 提出了一种将折纸图案转化为针织设计的方法，通过编程缝合和材料图案，结合热熔纱线在特定区域形成刚性面板，以增强折叠方向性和防止非预期变形。

Result: 成功复现了复杂的折纸图案（如Miura-ori、Yoshimura和Kresling），并展示了一种可穿戴的针织Kaleidocycle机器人，能够实现运动。

Conclusion: Knitted origami结合了结构可重构性、材料可编程性和制造可扩展性，为下一代可穿戴机器人提供了一个有前景的平台。

Abstract: Soft robots employing compliant materials and deformable structures offer
great potential for wearable devices that are comfortable and safe for human
interaction. However, achieving both structural integrity and compliance for
comfort remains a significant challenge. In this study, we present a novel
fabrication and design method that combines the advantages of origami
structures with the material programmability and wearability of knitted
fabrics. We introduce a general design method that translates origami patterns
into knit designs by programming both stitch and material patterns. The method
creates folds in preferred directions while suppressing unintended buckling and
bending by selectively incorporating heat fusible yarn to create rigid panels
around compliant creases. We experimentally quantify folding moments and show
that stitch patterning enhances folding directionality while the heat fusible
yarn (1) keeps geometry consistent by reducing edge curl and (2) prevents
out-of-plane deformations by stiffening panels. We demonstrate the framework
through the successful reproduction of complex origami tessellations, including
Miura-ori, Yoshimura, and Kresling patterns, and present a wearable knitted
Kaleidocycle robot capable of locomotion. The combination of structural
reconfigurability, material programmability, and potential for manufacturing
scalability highlights knitted origami as a promising platform for
next-generation wearable robotics.

</details>


### [240] [Contact Map Transfer with Conditional Diffusion Model for Generalizable Dexterous Grasp Generation](https://arxiv.org/abs/2511.01276)
*Yiyao Ma,Kai Chen,Kexin Zheng,Qi Dou*

Main category: cs.RO

TL;DR: 本文提出了一种基于条件扩散模型的灵巧抓取生成框架，通过转移高质量抓取和引入多图联合转移机制，显著提升了抓取的稳定性、效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 灵巧抓取生成是机器人学中的基础挑战，需要兼顾抓取稳定性和对不同物体及任务的适应性。现有方法在稳定性和适应性之间存在不足，因此需要一种既能保证稳定性又能高效适应不同任务的方法。

Method: 提出了一个基于转移的框架，利用条件扩散模型将高质量抓取从形状模板转移到同一类别的新物体上。通过重新定义抓取转移问题为对象接触图的生成，结合对象形状相似性和任务规范，并引入双映射机制处理复杂形状变化。此外，还开发了级联条件扩散模型框架来联合转移三个对象中心图（接触图、部分图和方向图），确保其内部一致性。

Result: 大量实验证明，该方法在抓取质量、生成效率和泛化性能方面均优于现有方法。

Conclusion: 本文提出的基于条件扩散模型的框架在灵巧抓取生成中表现出色，有效平衡了抓取质量、生成效率和泛化性能。

Abstract: Dexterous grasp generation is a fundamental challenge in robotics, requiring
both grasp stability and adaptability across diverse objects and tasks.
Analytical methods ensure stable grasps but are inefficient and lack task
adaptability, while generative approaches improve efficiency and task
integration but generalize poorly to unseen objects and tasks due to data
limitations. In this paper, we propose a transfer-based framework for dexterous
grasp generation, leveraging a conditional diffusion model to transfer
high-quality grasps from shape templates to novel objects within the same
category. Specifically, we reformulate the grasp transfer problem as the
generation of an object contact map, incorporating object shape similarity and
task specifications into the diffusion process. To handle complex shape
variations, we introduce a dual mapping mechanism, capturing intricate
geometric relationship between shape templates and novel objects. Beyond the
contact map, we derive two additional object-centric maps, the part map and
direction map, to encode finer contact details for more stable grasps. We then
develop a cascaded conditional diffusion model framework to jointly transfer
these three maps, ensuring their intra-consistency. Finally, we introduce a
robust grasp recovery mechanism, identifying reliable contact points and
optimizing grasp configurations efficiently. Extensive experiments demonstrate
the superiority of our proposed method. Our approach effectively balances grasp
quality, generation efficiency, and generalization performance across various
tasks. Project homepage: https://cmtdiffusion.github.io/

</details>


### [241] [A High-Speed Capable Spherical Robot](https://arxiv.org/abs/2511.01288)
*Bixuan Zhang,Fengqi Zhang,Haojie Chen,You Wang,Jie Hao,Zhiyuan Luo,Guang Li*

Main category: cs.RO

TL;DR: 新型球形机器人结构结合动量轮和二次摆，实现10 m/s高速稳定运动，提升越障和地形适应性。


<details>
  <summary>Details</summary>
Motivation: 解决原结构无法实现稳定高速运动的问题，提升球形机器人的运动性能和适应性。

Method: 基于单摆驱动球形机器人，设计了一种轴与二次摆对齐的动量轮，形成新型结构。通过解耦控制实现稳定高速运动。

Result: 物理原型实验证实，新结构能通过简单解耦控制实现稳定高速运动，且越障性能和地形鲁棒性显著增强。

Conclusion: 新型球形机器人结构通过引入动量轮和二次摆，实现了稳定的高速运动（最高10 m/s），并显著提升了越障性能和地形鲁棒性。

Abstract: This paper designs a new spherical robot structure capable of supporting
high-speed motion at up to 10 m/s. Building upon a single-pendulum-driven
spherical robot, the design incorporates a momentum wheel with an axis aligned
with the secondary pendulum, creating a novel spherical robot structure.
Practical experiments with the physical prototype have demonstrated that this
new spherical robot can achieve stable high-speed motion through simple
decoupled control, which was unattainable with the original structure. The
spherical robot designed for high-speed motion not only increases speed but
also significantly enhances obstacle-crossing performance and terrain
robustness.

</details>


### [242] [Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects](https://arxiv.org/abs/2511.01294)
*Jiawei Wang,Dingyou Wang,Jiaming Hu,Qixuan Zhang,Jingyi Yu,Lan Xu*

Main category: cs.RO

TL;DR: Kinematify 通过 MCTS 搜索和几何优化，从 RGB 图像或文本自动生成关节物体模型，解决了高自由度物体建模的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖运动序列或手工整理的数据集假设，难以扩展，尤其是在处理高自由度物体时。

Method: 结合 MCTS 搜索进行结构推断和几何驱动的优化进行关节推理。

Result: 在合成和真实环境中的多样化输入上，Kinematify 在配准和运动拓扑准确性上优于先前工作。

Conclusion: Kinematify 能够从任意 RGB 图像或文本提示中自动合成具有物理一致性和功能有效性的关节物体模型，显著提高了配准和运动拓扑的准确性。

Abstract: A deep understanding of kinematic structures and movable components is
essential for enabling robots to manipulate objects and model their own
articulated forms. Such understanding is captured through articulated objects,
which are essential for tasks such as physical simulation, motion planning, and
policy learning. However, creating these models, particularly for complex
systems like robots or objects with high degrees of freedom (DoF), remains a
significant challenge. Existing methods typically rely on motion sequences or
strong assumptions from hand-curated datasets, which hinders scalability. In
this paper, we introduce Kinematify, an automated framework that synthesizes
articulated objects directly from arbitrary RGB images or text prompts. Our
method addresses two core challenges: (i) inferring kinematic topologies for
high-DoF objects and (ii) estimating joint parameters from static geometry. To
achieve this, we combine MCTS search for structural inference with
geometry-driven optimization for joint reasoning, producing physically
consistent and functionally valid descriptions. We evaluate Kinematify on
diverse inputs from both synthetic and real-world environments, demonstrating
improvements in registration and kinematic topology accuracy over prior work.

</details>


### [243] [RobustVLA: Robustness-Aware Reinforcement Post-Training for Vision-Language-Action Models](https://arxiv.org/abs/2511.01331)
*Hongyin Zhang,Shuo Zhang,Junxi Jin,Qixin Zeng,Runze Li,Donglin Wang*

Main category: cs.RO

TL;DR: RobustVLA通过Jacobian和平滑正则化增强VLA模型对噪声和扰动的鲁棒性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型在分布外部署中因环境不确定性（如观察噪声、传感器误差或动作扰动）而表现不佳，现有RL后训练方法过于关注奖励最大化而忽视鲁棒性。

Method: 提出RobustVLA，一种轻量级在线RL后训练方法，重点通过Jacobian正则化和平滑正则化增强模型对观察噪声和动作扰动的鲁棒性。

Result: 在多样机器人环境中，RobustVLA在鲁棒性和可靠性上显著优于现有方法。

Conclusion: RobustVLA通过Jacobian和平滑正则化显著提升了VLA模型在分布外部署中的鲁棒性和可靠性，为增强VLA模型的实用性提供了关键步骤。

Abstract: Vision-Language-Action (VLA) models have recently emerged as powerful
general-purpose policies for robotic manipulation, benefiting from large-scale
multi-modal pre-training. However, they often fail to generalize reliably in
out-of-distribution deployments, where unavoidable disturbances such as
observation noise, sensor errors, or actuation perturbations become prevalent.
While recent Reinforcement Learning (RL)-based post-training provides a
practical means to adapt pre-trained VLA models, existing methods mainly
emphasize reward maximization and overlook robustness to environmental
uncertainty. In this work, we introduce RobustVLA, a lightweight online RL
post-training method designed to explicitly enhance the resilience of VLA
models. Through a systematic robustness analysis, we identify two key
regularizations: Jacobian regularization, which mitigates sensitivity to
observation noise, and smoothness regularization, which stabilizes policies
under action perturbations. Extensive experiments across diverse robotic
environments demonstrate that RobustVLA significantly outperforms prior
state-of-the-art methods in robustness and reliability. Our results highlight
the importance of principled robustness-aware RL post-training as a key step
toward improving the reliability and robustness of VLA models.

</details>


### [244] [Embodied Cognition Augmented End2End Autonomous Driving](https://arxiv.org/abs/2511.01334)
*Ling Niu,Xiaoji Zheng,Han Wang,Chen Zheng,Ziyuan Yang,Bokui Chen,Jiangtao Gong*

Main category: cs.RO

TL;DR: 论文提出$E^{3}AD$范式，通过对比学习EEG模型和视觉网络，将人类驾驶认知融入端到端自动驾驶规划，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶方法依赖标签监督训练的视觉特征提取网络，限制了模型的通用性和适用性，因此需要探索更通用的监督框架。

Method: 研究收集了认知数据集，基于公开自动驾驶数据集，利用对比学习方法探索人类驾驶认知对端到端规划的增强机制，并进行了开环和闭环测试。

Result: 实验结果表明，$E^{3}AD$范式显著提升了基线模型的端到端规划性能，消融研究进一步验证了驾驶认知和对比学习过程的有效性。

Conclusion: 该论文提出了一种名为$E^{3}AD$的新范式，通过对比学习视觉特征提取网络和通用EEG大模型，成功将人类驾驶认知融入端到端自动驾驶规划，显著提升了基线模型的性能。

Abstract: In recent years, vision-based end-to-end autonomous driving has emerged as a
new paradigm. However, popular end-to-end approaches typically rely on visual
feature extraction networks trained under label supervision. This limited
supervision framework restricts the generality and applicability of driving
models. In this paper, we propose a novel paradigm termed $E^{3}AD$, which
advocates for comparative learning between visual feature extraction networks
and the general EEG large model, in order to learn latent human driving
cognition for enhancing end-to-end planning. In this work, we collected a
cognitive dataset for the mentioned contrastive learning process. Subsequently,
we investigated the methods and potential mechanisms for enhancing end-to-end
planning with human driving cognition, using popular driving models as
baselines on publicly available autonomous driving datasets. Both open-loop and
closed-loop tests are conducted for a comprehensive evaluation of planning
performance. Experimental results demonstrate that the $E^{3}AD$ paradigm
significantly enhances the end-to-end planning performance of baseline models.
Ablation studies further validate the contribution of driving cognition and the
effectiveness of comparative learning process. To the best of our knowledge,
this is the first work to integrate human driving cognition for improving
end-to-end autonomous driving planning. It represents an initial attempt to
incorporate embodied cognitive data into end-to-end autonomous driving,
providing valuable insights for future brain-inspired autonomous driving
systems. Our code will be made available at Github

</details>


### [245] [Thermo-responsive closing and reopening artificial Venus Flytrap utilizing shape memory elastomers](https://arxiv.org/abs/2511.01346)
*Shun Yoshida,Qingchuan Song,Bastian E. Rapp,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 研究开发了一种能自主闭合和重新开放的热响应人工捕蝇草系统，利用形状记忆材料在特定温度下实现双向运动。


<details>
  <summary>Details</summary>
Motivation: 尽管已有多种人工捕蝇草系统模仿其快速闭合运动，但实现自主闭合和重新开放的双向运动仍是一个未解决的挑战。

Method: 采用新型热响应紫外固化形状记忆材料，构建了由形状记忆聚合物制成的双曲线陷阱瓣，通过形状记忆弹性体条作为拮抗执行器促进瓣的重新开放。

Result: 研制的热响应AVF在自然温度范围内（闭合38°C，重新开放45°C）实现了自主的双向运动。

Conclusion: 本研究首次展示了利用热响应形状记忆材料实现AVF自主闭合和重新开放的机制，为双向运动的软机器/机器人提供了新思路。

Abstract: Despite their often perceived static and slow nature, some plants can move
faster than the blink of an eye. The rapid snap closure motion of the Venus
flytrap (Dionaea muscipula) has long captivated the interest of researchers and
engineers alike, serving as a model for plant-inspired soft machines and
robots. The translation of the fast snapping closure has inspired the
development of various artificial Venus flytrap (AVF) systems. However,
translating both the closing and reopening motion of D. muscipula into an
autonomous plant inspired soft machine has yet to be achieved. In this study,
we present an AVF that autonomously closes and reopens, utilizing novel
thermo-responsive UV-curable shape memory materials for soft robotic systems.
The life-sized thermo-responsive AVF exhibits closing and reopening motions
triggered in a naturally occurring temperature range. The doubly curved trap
lobes, built from shape memory polymers, close at 38{\deg}C, while reopening
initiates around 45{\deg}C, employing shape memory elastomer strips as
antagonistic actuators to facilitate lobe reopening. This work represents the
first demonstration of thermo-responsive closing and reopening in an AVF with
programmed sequential motion in response to increasing temperature. This
approach marks the next step toward autonomously bidirectional moving soft
machines/robots.

</details>


### [246] [Design and development of an electronics-free earthworm robot](https://arxiv.org/abs/2511.01347)
*Riddhi Das,Joscha Teichmann,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 提出了一种无需电子元件的仿蚯蚓气动机器人，通过改进PLG设计实现高效蠕动运动，适用于危险环境。


<details>
  <summary>Details</summary>
Motivation: 现有仿蚯蚓机器人依赖笨重、高功耗的电子控制单元，限制了实用性。本研究旨在开发一种无需电子控制的气动软体机器人系统。

Method: 采用改进的气动逻辑门（PLG）设计与波纹管执行器集成，构建了一种模块化系统，无需外部电子元件即可实现蠕动运动。

Result: 改进的PLG控制系统有效生成了蠕动波传播，实现了自主运动且偏差极小。

Conclusion: 本研究提出了一种无需电子控制单元的仿蚯蚓气动机器人，通过改进的气动逻辑门设计实现了高效蠕动运动，为软体机器人在危险环境中的应用提供了概念验证。

Abstract: Soft robotic systems have gained widespread attention due to their inherent
flexibility, adaptability, and safety, making them well-suited for varied
applications. Among bioinspired designs, earthworm locomotion has been
extensively studied for its efficient peristaltic motion, enabling movement in
confined and unstructured environments. Existing earthworm-inspired robots
primarily utilize pneumatic actuation due to its high force-to-weight ratio and
ease of implementation. However, these systems often rely on bulky,
power-intensive electronic control units, limiting their practicality. In this
work, we present an electronics-free, earthworm-inspired pneumatic robot
utilizing a modified Pneumatic Logic Gate (PLG) design. By integrating
preconfigured PLG units with bellow actuators, we achieved a plug-and-play
style modular system capable of peristaltic locomotion without external
electronic components. The proposed design reduces system complexity while
maintaining efficient actuation. We characterize the bellow actuators under
different operating conditions and evaluate the robots locomotion performance.
Our findings demonstrate that the modified PLG-based control system effectively
generates peristaltic wave propagation, achieving autonomous motion with
minimal deviation. This study serves as a proof of concept for the development
of electronics-free, peristaltic soft robots. The proposed system has potential
for applications in hazardous environments, where untethered, adaptable
locomotion is critical. Future work will focus on further optimizing the robot
design and exploring untethered operation using onboard compressed air sources.

</details>


### [247] [Model to Model: Understanding the Venus Flytrap Snapping Mechanism and Transferring it to a 3D-printed Bistable Soft Robotic Demonstrator](https://arxiv.org/abs/2511.01350)
*Maartje H. M. Wermelink,Renate Sachse,Sebastian Kruppert,Thomas Speck,Falk J. Tauber*

Main category: cs.RO

TL;DR: 研究通过3D打印技术模拟捕蝇草的双稳态叶片机制，设计出能快速闭合的人工执行器，为开发快速软抓取器奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 捕蝇草的快速闭合机制长期以来吸引植物学家和工程师的兴趣，研究旨在深入理解其运动力学并将这些原理应用于人工双稳态执行器的设计。

Method: 通过识别捕蝇草叶片的几何特征（如尺寸比例和厚度梯度），并将其转化为两个3D打印的双稳态执行器模型，一个模拟捕蝇草叶片几何形状，另一个基于CAD设计。

Result: 两个执行器模型均表现出凹-凸双稳态特性并能快速闭合，为开发模仿生物模型机械行为的人工捕蝇草迈出了第一步。

Conclusion: 研究成功地将捕蝇草的几何特征和力学原理应用于人工双稳态叶片执行器的设计，展示了其作为快速软抓取器的潜力。

Abstract: The Venus flytrap (Dionaea muscipula) does not only serve as the textbook
model for a carnivorous plant, but also has long intrigued both botanists and
engineers with its rapidly closing leaf trap. The trap closure is triggered by
two consecutive touches of a potential prey, after which the lobes rapidly
switch from their concave open-state to their convex close-state and catch the
prey within 100-500 ms after being triggered. This transformation from concave
to convex is initiated by changes in turgor pressure and the release of stored
elastic energy from prestresses in the concave state, which accelerate this
movement, leading to inversion of the lobes bi-axial curvature. Possessing two
low-energy states, the leaves can be characterized as bistable systems. With
our research, we seek to deepen the understanding of Venus flytrap motion
mechanics and apply its principles to the design of an artificial bistable lobe
actuator. We identified geometrical characteristics, such as dimensional ratios
and the thickness gradient in the lobe, and transferred these to two 3D-printed
bistable actuator models. One actuator parallels the simulated geometry of a
Venus flytrap leaf, the other is a lobe model designed with CAD. Both models
display concave-convex bi-stability and snap close. These demonstrators are the
first step in the development of an artificial Venus flytrap that mimics the
mechanical behavior of the biological model and can be used as a soft fast
gripper.

</details>


### [248] [Lateral Velocity Model for Vehicle Parking Applications](https://arxiv.org/abs/2511.01369)
*Luis Diener,Jens Kalkkuhl,Markus Enzweiler*

Main category: cs.RO

TL;DR: 本文提出了一种改进的侧向速度模型，适用于停车场景，仅需两个参数，提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有的零滑移模型在低速驾驶时假设不成立，需额外启发式方法修正。本文旨在解决消费级车辆缺乏专用传感器导致的侧向速度估计难题。

Method: 通过分析真实停车场景数据，识别出零滑移假设的系统性偏差，并提出一个能更好捕捉停车时车辆侧向动力学的模型。

Result: 提出的模型在停车场景中显著提高了侧向速度估计的准确性。

Conclusion: 本文提出了一种更适合停车场景的侧向速度模型，该模型仅依赖两个参数，显著提高了估计精度，适用于消费级车辆应用。

Abstract: Automated parking requires accurate localization for quick and precise
maneuvering in tight spaces. While the longitudinal velocity can be measured
using wheel encoders, the estimation of the lateral velocity remains a key
challenge due to the absence of dedicated sensors in consumer-grade vehicles.
Existing approaches often rely on simplified vehicle models, such as the
zero-slip model, which assumes no lateral velocity at the rear axle. It is well
established that this assumption does not hold during low-speed driving and
researchers thus introduce additional heuristics to account for differences. In
this work, we analyze real-world data from parking scenarios and identify a
systematic deviation from the zero-slip assumption. We provide explanations for
the observed effects and then propose a lateral velocity model that better
captures the lateral dynamics of the vehicle during parking. The model improves
estimation accuracy, while relying on only two parameters, making it
well-suited for integration into consumer-grade applications.

</details>


### [249] [CM-LIUW-Odometry: Robust and High-Precision LiDAR-Inertial-UWB-Wheel Odometry for Extreme Degradation Coal Mine Tunnels](https://arxiv.org/abs/2511.01379)
*Kun Hu,Menggang Li,Zhiwen Jin,Chaoquan Tang,Eryi Hu,Gongbo Zhou*

Main category: cs.RO

TL;DR: 提出CM-LIUW-Odometry多模态SLAM框架，结合多种传感器和自适应机制，显著提升地下煤矿环境中的定位与建图性能。


<details>
  <summary>Details</summary>
Motivation: 解决GPS缺失、地形复杂和传感器受限环境下SLAM的挑战。

Method: 提出基于IESKF的多模态SLAM框架，结合LiDAR-IMU-UWB-轮式里程计，采用紧密耦合和自适应运动模式切换。

Result: 实验验证了该方法在复杂煤矿环境中的优越性能。

Conclusion: CM-LIUW-Odometry框架在真实地下煤矿环境中展现出卓越的精度和鲁棒性，优于现有方法，并开源代码以促进机器人社区发展。

Abstract: Simultaneous Localization and Mapping (SLAM) in large-scale, complex, and
GPS-denied underground coal mine environments presents significant challenges.
Sensors must contend with abnormal operating conditions: GPS unavailability
impedes scene reconstruction and absolute geographic referencing, uneven or
slippery terrain degrades wheel odometer accuracy, and long, feature-poor
tunnels reduce LiDAR effectiveness. To address these issues, we propose
CoalMine-LiDAR-IMU-UWB-Wheel-Odometry (CM-LIUW-Odometry), a multimodal SLAM
framework based on the Iterated Error-State Kalman Filter (IESKF). First,
LiDAR-inertial odometry is tightly fused with UWB absolute positioning
constraints to align the SLAM system with a global coordinate. Next, wheel
odometer is integrated through tight coupling, enhanced by nonholonomic
constraints (NHC) and vehicle lever arm compensation, to address performance
degradation in areas beyond UWB measurement range. Finally, an adaptive motion
mode switching mechanism dynamically adjusts the robot's motion mode based on
UWB measurement range and environmental degradation levels. Experimental
results validate that our method achieves superior accuracy and robustness in
real-world underground coal mine scenarios, outperforming state-of-the-art
approaches. We open source our code of this work on Github to benefit the
robotics community.

</details>


### [250] [CaRLi-V: Camera-RADAR-LiDAR Point-Wise 3D Velocity Estimation](https://arxiv.org/abs/2511.01383)
*Landson Guo,Andres M. Diaz Aguilar,William Talbot,Turcan Tuna,Marco Hutter,Cesar Cadena*

Main category: cs.RO

TL;DR: CaRLi-V是一个融合RADAR、LiDAR和相机数据的3D速度估计管道，通过‘速度立方体’和光流等技术，实现了对动态物体的精确速度估计。


<details>
  <summary>Details</summary>
Motivation: 精确的3D点状速度估计对于机器人与非刚性动态物体（如人类）的交互至关重要，尤其在动态环境中的路径规划、避障和对象操作中。

Method: 提出了一种名为CaRLi-V的新型融合管道，结合RADAR的‘速度立方体’表示径向速度、光流估计切向速度，以及LiDAR的点状距离测量，通过闭式解算生成密集点阵的3D速度估计。

Result: CaRLi-V在自定义数据集上的测试显示，其速度误差指标较低，能够为机器人应用提供精确的点状速度估计。

Conclusion: CaRLi-V通过融合RADAR、LiDAR和相机的数据，实现了对非刚性动态物体（如人类）的精确点状3D速度估计，为机器人在动态环境中的路径规划、避障和对象操作提供了可靠支持。

Abstract: Accurate point-wise velocity estimation in 3D is crucial for robot
interaction with non-rigid, dynamic agents, such as humans, enabling robust
performance in path planning, collision avoidance, and object manipulation in
dynamic environments. To this end, this paper proposes a novel RADAR, LiDAR,
and camera fusion pipeline for point-wise 3D velocity estimation named CaRLi-V.
This pipeline leverages raw RADAR measurements to create a novel RADAR
representation, the velocity cube, which densely represents radial velocities
within the RADAR's field-of-view. By combining the velocity cube for radial
velocity extraction, optical flow for tangential velocity estimation, and LiDAR
for point-wise range measurements through a closed-form solution, our approach
can produce 3D velocity estimates for a dense array of points. Developed as an
open-source ROS2 package, CaRLi-V has been field-tested against a custom
dataset and proven to produce low velocity error metrics relative to ground
truth, enabling point-wise velocity estimation for robotic applications.

</details>


### [251] [FoldPath: End-to-End Object-Centric Motion Generation via Modulated Implicit Paths](https://arxiv.org/abs/2511.01407)
*Paolo Rabino,Gabriele Tiboni,Tatiana Tommasi*

Main category: cs.RO

TL;DR: FoldPath是一种新型神经场方法，通过连续函数学习机器人运动，摒弃后处理步骤，提升OCMG任务的预测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前OCMG技术要么基于临时启发式方法，要么依赖于需要敏感后处理步骤的学习型流程，无法有效生成可执行路径。FoldPath旨在解决这一问题，提供更高效的自动化解决方案。

Method: FoldPath采用神经场方法，学习机器人运动的连续函数，从而隐式编码平滑的输出路径，摒弃了传统方法中对离散路径点进行敏感后处理的依赖。

Result: FoldPath在预测性能上优于现有学习型方法，并在实际工业环境中展现了出色的泛化能力，仅需70个专家样本即可实现高效自动化。

Conclusion: FoldPath作为一种新型的端到端神经场方法，在对象感知运动生成（OCMG）任务中表现出色，不仅提升了预测性能，还在实际工业环境中展现了良好的泛化能力，仅需少量专家样本即可实现高效自动化。

Abstract: Object-Centric Motion Generation (OCMG) is instrumental in advancing
automated manufacturing processes, particularly in domains requiring
high-precision expert robotic motions, such as spray painting and welding. To
realize effective automation, robust algorithms are essential for generating
extended, object-aware trajectories across intricate 3D geometries. However,
contemporary OCMG techniques are either based on ad-hoc heuristics or employ
learning-based pipelines that are still reliant on sensitive post-processing
steps to generate executable paths. We introduce FoldPath, a novel, end-to-end,
neural field based method for OCMG. Unlike prior deep learning approaches that
predict discrete sequences of end-effector waypoints, FoldPath learns the robot
motion as a continuous function, thus implicitly encoding smooth output paths.
This paradigm shift eliminates the need for brittle post-processing steps that
concatenate and order the predicted discrete waypoints. Particularly, our
approach demonstrates superior predictive performance compared to recently
proposed learning-based methods, and attains generalization capabilities even
in real industrial settings, where only a limited amount of 70 expert samples
are provided. We validate FoldPath through comprehensive experiments in a
realistic simulation environment and introduce new, rigorous metrics designed
to comprehensively evaluate long-horizon robotic paths, thus advancing the OCMG
task towards practical maturity.

</details>


### [252] [Designing for Distributed Heterogeneous Modularity: On Software Architecture and Deployment of MoonBots](https://arxiv.org/abs/2511.01437)
*Elian Neppel,Shamistan Karimov,Ashutosh Mishra,Gustavo Hernan Diaz Huenupan,Hazal Gozbasi,Kentaro Uno,Shreya Santra,Kazuya Yoshida*

Main category: cs.RO

TL;DR: MoonBot平台通过模块化架构和开源Motion Stack软件，解决了分布式异构机器人系统的集成和维护难题，适用于太空及其他复杂环境。


<details>
  <summary>Details</summary>
Motivation: 解决模块化机器人在软件、通信和协调方面的挑战，扩展模块化机器人技术超越物理重构。

Method: 采用基于组件的设计、使用ROS2和Zenoh的数据导向通信模型，以及能够管理复杂多模块组件的部署协调器。这些抽象实现了动态重配置、分散控制和多模块间的无缝协作。

Result: 通过数月的现场部署验证，包括自组装机器人、机器人间协作和远程操作，证明了系统的有效性。

Conclusion: 本文提出了一种通用的机器人系统设计模式，适用于跨时间、硬件、团队和操作环境的扩展。尽管以太空应用为背景，MoonBot平台的架构显著降低了模块化机器人的集成和维护开销，同时保持了可扩展性和鲁棒性。

Abstract: This paper presents the software architecture and deployment strategy behind
the MoonBot platform: a modular space robotic system composed of heterogeneous
components distributed across multiple computers, networks and ultimately
celestial bodies. We introduce a principled approach to distributed,
heterogeneous modularity, extending modular robotics beyond physical
reconfiguration to software, communication and orchestration. We detail the
architecture of our system that integrates component-based design, a
data-oriented communication model using ROS2 and Zenoh, and a deployment
orchestrator capable of managing complex multi-module assemblies. These
abstractions enable dynamic reconfiguration, decentralized control, and
seamless collaboration between numerous operators and modules. At the heart of
this system lies our open-source Motion Stack software, validated by months of
field deployment with self-assembling robots, inter-robot cooperation, and
remote operation. Our architecture tackles the significant hurdles of modular
robotics by significantly reducing integration and maintenance overhead, while
remaining scalable and robust. Although tested with space in mind, we propose
generalizable patterns for designing robotic systems that must scale across
time, hardware, teams and operational environments.

</details>


### [253] [AERMANI-VLM: Structured Prompting and Reasoning for Aerial Manipulation with Vision Language Models](https://arxiv.org/abs/2511.01472)
*Sarthak Mishra,Rishabh Dev Yadav,Avirup Das,Saksham Gupta,Wei Pan,Spandan Roy*

Main category: cs.RO

TL;DR: AERMANI-VLM 通过分离推理与控制，利用预训练VLM实现安全可靠的空中操纵，无需微调，验证了其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视觉-语言模型在机器人控制中的直接部署存在动作不一致、易产生幻觉和飞行动态不可行的问题，亟需一种安全可靠的解决方案。

Method: 利用结构化提示编码自然语言指令、任务上下文和安全约束，引导模型生成逐步推理的自然语言跟踪，并从预定义的飞行安全技能库中选择执行。

Result: 在模拟和硬件实验中，AERMANI-VLM 在多样化的多步拾取放置任务中表现出强大的泛化能力，能够应对未见过的指令、对象和环境。

Conclusion: AERMANI-VLM 框架通过分离高层推理与底层控制，成功将预训练的视觉-语言模型（VLMs）应用于空中操纵任务，无需任务特定微调，实现了稳健的任务完成。

Abstract: The rapid progress of vision--language models (VLMs) has sparked growing
interest in robotic control, where natural language can express the operation
goals while visual feedback links perception to action. However, directly
deploying VLM-driven policies on aerial manipulators remains unsafe and
unreliable since the generated actions are often inconsistent,
hallucination-prone, and dynamically infeasible for flight. In this work, we
present AERMANI-VLM, the first framework to adapt pretrained VLMs for aerial
manipulation by separating high-level reasoning from low-level control, without
any task-specific fine-tuning. Our framework encodes natural language
instructions, task context, and safety constraints into a structured prompt
that guides the model to generate a step-by-step reasoning trace in natural
language. This reasoning output is used to select from a predefined library of
discrete, flight-safe skills, ensuring interpretable and temporally consistent
execution. By decoupling symbolic reasoning from physical action, AERMANI-VLM
mitigates hallucinated commands and prevents unsafe behavior, enabling robust
task completion. We validate the framework in both simulation and hardware on
diverse multi-step pick-and-place tasks, demonstrating strong generalization to
previously unseen commands, objects, and environments.

</details>


### [254] [MO-SeGMan: Rearrangement Planning Framework for Multi Objective Sequential and Guided Manipulation in Constrained Environments](https://arxiv.org/abs/2511.01476)
*Cankut Bora Tuncer,Marc Toussaint,Ozgur S. Oguz*

Main category: cs.RO

TL;DR: MO-SeGMan是一种多目标重排规划器，通过选择性引导搜索和自适应子目标选择，高效解决复杂场景中的重排问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决高度杂乱和非单调场景中的重排问题，需要一种能够高效重新定位关键障碍物并减少不必要操作的规划器。

Method: MO-SeGMan采用了一种多目标序列和引导操作规划器，结合选择性引导前向搜索（SGFS）和自适应子目标选择的细化方法，以减少重新规划和机器人移动距离，同时保持关键依赖结构。

Result: 在九个基准重排任务上的广泛评估表明，MO-SeGMan在所有情况下都能生成可行的运动计划，并且在解决时间和解决方案质量上均优于基线方法。

Conclusion: MO-SeGMan展示了在复杂重排规划问题中的鲁棒性和可扩展性，能够在所有测试案例中生成可行的运动计划，并在解决时间和解决方案质量上优于基线方法。

Abstract: In this work, we introduce MO-SeGMan, a Multi-Objective Sequential and Guided
Manipulation planner for highly constrained rearrangement problems. MO-SeGMan
generates object placement sequences that minimize both replanning per object
and robot travel distance while preserving critical dependency structures with
a lazy evaluation method. To address highly cluttered, non-monotone scenarios,
we propose a Selective Guided Forward Search (SGFS) that efficiently relocates
only critical obstacles and to feasible relocation points. Furthermore, we
adopt a refinement method for adaptive subgoal selection to eliminate
unnecessary pick-and-place actions, thereby improving overall solution quality.
Extensive evaluations on nine benchmark rearrangement tasks demonstrate that
MO-SeGMan generates feasible motion plans in all cases, consistently achieving
faster solution times and superior solution quality compared to the baselines.
These results highlight the robustness and scalability of the proposed
framework for complex rearrangement planning problems.

</details>


### [255] [Floor Plan-Guided Visual Navigation Incorporating Depth and Directional Cues](https://arxiv.org/abs/2511.01493)
*Wei Huang,Jiaxin Li,Zang Wan,Huijun Di,Wei Liang,Zhu Yang*

Main category: cs.RO

TL;DR: GlocDiff是一种新型扩散策略，结合全局规划和局部特征，提升室内导航性能，实际应用潜力大。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法中视觉与空间信息整合的模态差距，以及在未见环境中精确定位的挑战。

Method: 提出了一种基于扩散的策略GlocDiff，整合了来自平面图的全局路径规划和RGB观测的局部深度感知特征，通过噪声扰动增强鲁棒性。

Result: 在FloNa基准测试中表现优异，实际部署验证了其有效性。

Conclusion: GlocDiff通过结合全局路径规划和局部深度感知特征，显著提升了室内导航性能，并在实际部署中展示了广泛应用的潜力。

Abstract: Guiding an agent to a specific target in indoor environments based solely on
RGB inputs and a floor plan is a promising yet challenging problem. Although
existing methods have made significant progress, two challenges remain
unresolved. First, the modality gap between egocentric RGB observations and the
floor plan hinders the integration of visual and spatial information for both
local obstacle avoidance and global planning. Second, accurate localization is
critical for navigation performance, but remains challenging at deployment in
unseen environments due to the lack of explicit geometric alignment between RGB
inputs and floor plans. We propose a novel diffusion-based policy, denoted as
GlocDiff, which integrates global path planning from the floor plan with local
depth-aware features derived from RGB observations. The floor plan offers
explicit global guidance, while the depth features provide implicit geometric
cues, collectively enabling precise prediction of optimal navigation directions
and robust obstacle avoidance. Moreover, GlocDiff introduces noise perturbation
during training to enhance robustness against pose estimation errors, and we
find that combining this with a relatively stable VO module during inference
results in significantly improved navigation performance. Extensive experiments
on the FloNa benchmark demonstrate GlocDiff's efficiency and effectiveness in
achieving superior navigation performance, and the success of real-world
deployments also highlights its potential for widespread practical
applications.

</details>


### [256] [Phy-Tac: Toward Human-Like Grasping via Physics-Conditioned Tactile Goals](https://arxiv.org/abs/2511.01520)
*Shipeng Lyu,Lijie Sheng,Fangyuan Wang,Wenyao Zhang,Weiwei Lin,Zhenzhong Jia,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: Phy-Tac通过物理条件触觉方法优化机器人抓取力，模仿人类抓取效率，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人抓取中过度施力的问题，模仿人类抓取的最小力稳定性。

Method: 提出了Phy-Tac方法，包括物理基础姿势选择器、物理条件潜在扩散模型（Phy-LDM）和潜在空间LQR控制器，用于优化力分布和触觉预测。

Result: Phy-LDM在触觉预测准确性上表现优异，Phy-Tac在抓取稳定性和力效率上优于固定力和GraspNet基准方法。

Conclusion: Phy-Tac方法通过结合物理条件触觉预测和最优力调节，显著缩小了机器人抓取与人类抓取之间的差距，实现了高效且自适应的操作。

Abstract: Humans naturally grasp objects with minimal level required force for
stability, whereas robots often rely on rigid, over-squeezing control. To
narrow this gap, we propose a human-inspired physics-conditioned tactile method
(Phy-Tac) for force-optimal stable grasping (FOSG) that unifies pose selection,
tactile prediction, and force regulation. A physics-based pose selector first
identifies feasible contact regions with optimal force distribution based on
surface geometry. Then, a physics-conditioned latent diffusion model (Phy-LDM)
predicts the tactile imprint under FOSG target. Last, a latent-space LQR
controller drives the gripper toward this tactile imprint with minimal
actuation, preventing unnecessary compression. Trained on a physics-conditioned
tactile dataset covering diverse objects and contact conditions, the proposed
Phy-LDM achieves superior tactile prediction accuracy, while the Phy-Tac
outperforms fixed-force and GraspNet-based baselines in grasp stability and
force efficiency. Experiments on classical robotic platforms demonstrate
force-efficient and adaptive manipulation that bridges the gap between robotic
and human grasping.

</details>


### [257] [MARS: Multi-Agent Robotic System with Multimodal Large Language Models for Assistive Intelligence](https://arxiv.org/abs/2511.01594)
*Renjun Gao,Peiyan Zhong*

Main category: cs.RO

TL;DR: MARS是一个基于多模态大语言模型的多代理机器人系统，专为智能家居机器人设计，通过整合视觉感知、风险评估、规划和评估代理，实现了动态室内环境中的自适应和风险感知辅助。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在跨模态理解和推理方面表现出色，但现有系统在风险感知规划、用户个性化以及将语言计划转化为可执行技能方面仍存在困难。

Method: 系统整合了四个代理：视觉感知代理提取环境图像的语义和空间特征，风险评估代理识别和优先处理危险，规划代理生成可执行的动作序列，以及评估代理进行迭代优化。

Result: 实验表明，该系统在风险感知规划和协调多代理执行方面优于现有的多模态模型。

Conclusion: 该论文提出了一种基于多模态大语言模型的多代理机器人系统（MARS），用于智能家居机器人辅助残疾人，展示了其在动态室内环境中实现自适应、风险感知和个性化辅助的潜力。

Abstract: Multimodal large language models (MLLMs) have shown remarkable capabilities
in cross-modal understanding and reasoning, offering new opportunities for
intelligent assistive systems, yet existing systems still struggle with
risk-aware planning, user personalization, and grounding language plans into
executable skills in cluttered homes. We introduce MARS - a Multi-Agent Robotic
System powered by MLLMs for assistive intelligence and designed for smart home
robots supporting people with disabilities. The system integrates four agents:
a visual perception agent for extracting semantic and spatial features from
environment images, a risk assessment agent for identifying and prioritizing
hazards, a planning agent for generating executable action sequences, and an
evaluation agent for iterative optimization. By combining multimodal perception
with hierarchical multi-agent decision-making, the framework enables adaptive,
risk-aware, and personalized assistance in dynamic indoor environments.
Experiments on multiple datasets demonstrate the superior overall performance
of the proposed system in risk-aware planning and coordinated multi-agent
execution compared with state-of-the-art multimodal models. The proposed
approach also highlights the potential of collaborative AI for practical
assistive scenarios and provides a generalizable methodology for deploying
MLLM-enabled multi-agent systems in real-world environments.

</details>


### [258] [Unified Diffusion VLA: Vision-Language-Action Model via Joint Discrete Denoising Diffusion Process](https://arxiv.org/abs/2511.01718)
*Jiayi Chen,Wenxuan Song,Pengxiang Ding,Ziyang Zhou,Han Zhao,Feilong Tang,Donglin Wang,Haoang Li*

Main category: cs.RO

TL;DR: 本文提出统一扩散VLA模型和JD3P方法，通过同步去噪优化生成与动作，显著提升性能与效率，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作（VLA）模型在模态统一和任务协同方面存在局限，无法充分利用生成与动作之间的直接协同效应。

Method: 联合离散去噪扩散过程（JD3P）通过统一的token化空间和混合注意力机制，将多种模态集成到单一去噪轨迹中。此外，提出两阶段训练流程和推理时优化技术。

Result: 在CALVIN、LIBERO和SimplerEnv等基准测试中达到最先进性能，推理速度比自回归方法快4倍。

Conclusion: 本文提出的统一扩散VLA（Vision-Language-Action）模型和联合离散去噪扩散过程（JD3P）通过同步去噪过程实现了生成与动作的联合优化，显著提升了性能与效率，并在多个基准测试中达到了最先进水平。

Abstract: Vision-language-action (VLA) models aim to understand natural language
instructions and visual observations and to execute corresponding actions as an
embodied agent. Recent work integrates future images into the
understanding-acting loop, yielding unified VLAs that jointly understand,
generate, and act -- reading text and images and producing future images and
actions. However, these models either rely on external experts for modality
unification or treat image generation and action prediction as separate
processes, limiting the benefits of direct synergy between these tasks. Our
core philosophy is to optimize generation and action jointly through a
synchronous denoising process, where the iterative refinement enables actions
to evolve from initialization, under constant and sufficient visual guidance.
We ground this philosophy in our proposed Unified Diffusion VLA and Joint
Discrete Denoising Diffusion Process (JD3P), which is a joint diffusion process
that integrates multiple modalities into a single denoising trajectory to serve
as the key mechanism enabling understanding, generation, and acting to be
intrinsically synergistic. Our model and theory are built on a unified
tokenized space of all modalities and a hybrid attention mechanism. We further
propose a two-stage training pipeline and several inference-time techniques
that optimize performance and efficiency. Our approach achieves
state-of-the-art performance on benchmarks such as CALVIN, LIBERO, and
SimplerEnv with 4$\times$ faster inference than autoregressive methods, and we
demonstrate its effectiveness through in-depth analysis and real-world
evaluations. Our project page is available at
https://irpn-eai.github.io/UD-VLA.github.io/.

</details>


### [259] [Lightweight Learning from Actuation-Space Demonstrations via Flow Matching for Whole-Body Soft Robotic Grasping](https://arxiv.org/abs/2511.01770)
*Liudi Yang,Yang Bai,Yuhao Wang,Ibrahim Alsarraj,Gitta Kutyniok,Zhanchi Wang,Ke Wu*

Main category: cs.RO

TL;DR: 提出轻量级驱动空间学习框架，利用软机器人被动灵活性实现高成功率抓取，显著减少中央控制器负担。


<details>
  <summary>Details</summary>
Motivation: 解决传统刚性机器人手在不确定性抓取中的局限性，利用软机器人的机械智能特性（被动灵活性和欠驱动结构）适应不确定性接触并实现自适应行为。

Method: 提出了一种轻量级的驱动空间学习框架，直接从确定性演示中使用流匹配模型（Rectified Flow）推断出整体软机器人抓取的分布控制表示，无需密集传感或重型控制回路。

Result: 仅使用30次演示（不到可达工作空间的8%），学习策略在整个工作空间中实现了97.5%的抓取成功率，对被抓取物体尺寸变化的泛化能力达±33%，并在执行时间从20%调整到200%时保持稳定性能。

Conclusion: 通过利用软机器人的被动冗余自由度和灵活性，驱动空间学习将身体的力学转化为功能性控制智能，显著减轻了中央控制器在不确定性丰富任务中的负担。

Abstract: Robotic grasping under uncertainty remains a fundamental challenge due to its
uncertain and contact-rich nature. Traditional rigid robotic hands, with
limited degrees of freedom and compliance, rely on complex model-based and
heavy feedback controllers to manage such interactions. Soft robots, by
contrast, exhibit embodied mechanical intelligence: their underactuated
structures and passive flexibility of their whole body, naturally accommodate
uncertain contacts and enable adaptive behaviors. To harness this capability,
we propose a lightweight actuation-space learning framework that infers
distributional control representations for whole-body soft robotic grasping,
directly from deterministic demonstrations using a flow matching model
(Rectified Flow),without requiring dense sensing or heavy control loops. Using
only 30 demonstrations (less than 8% of the reachable workspace), the learned
policy achieves a 97.5% grasp success rate across the whole workspace,
generalizes to grasped-object size variations of +-33%, and maintains stable
performance when the robot's dynamic response is directly adjusted by scaling
the execution time from 20% to 200%. These results demonstrate that
actuation-space learning, by leveraging its passive redundant DOFs and
flexibility, converts the body's mechanics into functional control intelligence
and substantially reduces the burden on central controllers for this
uncertain-rich task.

</details>


### [260] [MOBIUS: A Multi-Modal Bipedal Robot that can Walk, Crawl, Climb, and Roll](https://arxiv.org/abs/2511.01774)
*Alexander Schperberg,Yusuke Tanaka,Stefano Di Cairano,Dennis Hong*

Main category: cs.RO

TL;DR: MOBIUS是一款多模态机器人，能行走、爬行、攀爬和滚动，通过混合控制架构和高级规划实现多样化地形的高效穿越和操作。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够在多样化地形中行走、爬行、攀爬和滚动的多模态双足智能城市侦察机器人，以实现平滑的地形过渡。

Method: 采用混合控制架构，结合基于强化学习的运动与模型预测和导纳控制，并通过参考调节器增强安全性。高层MIQCP规划器自主选择运动模式以平衡稳定性和能效。

Result: 硬件实验展示了稳健的步态过渡、动态攀爬以及通过捏握实现的全身体负载支持。

Conclusion: MOBIUS机器人展示了形态学、高级规划与控制紧密集成的重要性，显著扩展了其交互能力、工作空间和穿越能力。

Abstract: This article presents a Multi-Modal Bipedal Intelligent Urban Scout robot
(MOBIUS) capable of walking, crawling, climbing, and rolling. MOBIUS features
four limbs--two 6-DoF arms with two-finger grippers for manipulation and
climbing, and two 4-DoF legs for locomotion--enabling smooth transitions across
diverse terrains without reconfiguration. A hybrid control architecture
combines reinforcement learning-based locomotion with model-based predictive
and admittance control enhanced for safety by a Reference Governor toward
compliant contact interactions. A high-level MIQCP planner autonomously selects
locomotion modes to balance stability and energy efficiency. Hardware
experiments demonstrate robust gait transitions, dynamic climbing, and
full-body load support via pinch grasp. Overall, MOBIUS demonstrates the
importance of tight integration between morphology, high-level planning, and
control to enable mobile loco-manipulation and grasping, substantially
expanding its interaction capabilities, workspace, and traversability.

</details>


### [261] [GenDexHand: Generative Simulation for Dexterous Hands](https://arxiv.org/abs/2511.01791)
*Feng Chen,Zhuxiu Xu,Tianzhe Chu,Xunzhe Zhou,Li Sun,Zewen Wu,Shenghua Gao,Zhongyu Li,Yanchao Yang,Yi Ma*

Main category: cs.RO

TL;DR: GenDexHand 是一种自动化生成灵巧手任务和环境的模拟管道，通过闭环优化和任务分解提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作任务由于自由度较高，现有方法在模拟生成中表现不佳，且数据稀缺是限制因素。

Method: GenDexHand 是一个生成式模拟管道，通过闭环精炼过程调整物体位置和大小，并基于 VLM 反馈提升生成环境的质量。任务被分解为子任务以实现顺序强化学习。

Result: GenDexHand 显著提升了生成环境的平均质量，减少了训练时间并提高了成功率。

Conclusion: GenDexHand 提供了一种基于模拟的合成数据生成方案，为多样化的灵巧手行为训练提供了可行路径。

Abstract: Data scarcity remains a fundamental bottleneck for embodied intelligence.
Existing approaches use large language models (LLMs) to automate gripper-based
simulation generation, but they transfer poorly to dexterous manipulation,
which demands more specialized environment design. Meanwhile, dexterous
manipulation tasks are inherently more difficult due to their higher degrees of
freedom. Massively generating feasible and trainable dexterous hand tasks
remains an open challenge. To this end, we present GenDexHand, a generative
simulation pipeline that autonomously produces diverse robotic tasks and
environments for dexterous manipulation. GenDexHand introduces a closed-loop
refinement process that adjusts object placements and scales based on
vision-language model (VLM) feedback, substantially improving the average
quality of generated environments. Each task is further decomposed into
sub-tasks to enable sequential reinforcement learning, reducing training time
and increasing success rates. Our work provides a viable path toward scalable
training of diverse dexterous hand behaviors in embodied intelligence by
offering a simulation-based solution to synthetic data generation. Our website:
https://winniechen2002.github.io/GenDexHand/.

</details>


### [262] [Hybrid Neural Network-Based Indoor Localisation System for Mobile Robots Using CSI Data in a Robotics Simulator](https://arxiv.org/abs/2511.01797)
*Javier Ballesteros-Jerez,Jesus Martínez-Gómez,Ismael García-Varea,Luis Orozco-Barbosa,Manuel Castillo-Cara*

Main category: cs.RO

TL;DR: 提出了一种结合CNN与MLP的HyNN模型，用于移动机器人的室内定位，展示了在复杂环境中的精确导航潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决移动机器人在复杂环境中的精确室内定位和导航问题。

Method: 通过利用现有的CSI数据集，将CNN与MLP结合形成HyNN模型，将CSI读数转换为合成图像，并与机器人模拟器和ROS集成，评估其性能。

Result: HyNN模型能够有效估计2D机器人位置，展示了在复杂环境中的定位潜力。

Conclusion: 该研究展示了HyNN模型在复杂环境中实现精确室内定位和导航的潜力，并提出了一个可推广的流程，适用于不同的场景和数据集。

Abstract: We present a hybrid neural network model for inferring the position of mobile
robots using Channel State Information (CSI) data from a Massive MIMO system.
By leveraging an existing CSI dataset, our approach integrates a Convolutional
Neural Network (CNN) with a Multilayer Perceptron (MLP) to form a Hybrid Neural
Network (HyNN) that estimates 2D robot positions. CSI readings are converted
into synthetic images using the TINTO tool. The localisation solution is
integrated with a robotics simulator, and the Robot Operating System (ROS),
which facilitates its evaluation through heterogeneous test cases, and the
adoption of state estimators like Kalman filters. Our contributions illustrate
the potential of our HyNN model in achieving precise indoor localisation and
navigation for mobile robots in complex environments. The study follows, and
proposes, a generalisable procedure applicable beyond the specific use case
studied, making it adaptable to different scenarios and datasets.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [263] [Sorting by Strip Swaps is NP-Hard](https://arxiv.org/abs/2511.00015)
*Swapnoneel Roy,Asai Asaithambi,Debajyoti Mukhopadhyay*

Main category: cs.DS

TL;DR: 论文通过构造笼子和铰链小工具，将SbSS问题归约到块排序问题，证明了其NP难性。


<details>
  <summary>Details</summary>
Motivation: 旨在证明排序带条交换问题（SbSS）的计算复杂性，即其属于NP难问题。

Method: 通过构造局部小工具（笼子）和铰链小工具，将SbSS问题归约到块排序问题。

Result: 成功证明了SbSS是NP难的，通过清洁的等价性建立了与完美块调度的一一对应关系。

Conclusion: SbSS问题通过多项式归约到块排序问题被证明是NP难的，关键在于使用局部小工具（笼子）来实现清洁的等价性。

Abstract: We show that \emph{Sorting by Strip Swaps} (SbSS) is NP-hard by a polynomial
reduction of \emph{Block Sorting}. The key idea is a local gadget, a
\emph{cage}, that replaces every decreasing adjacency $(a_i,a_{i+1})$ by a
guarded triple $a_i,m_i,a_{i+1}$ enclosed by guards $L_i,U_i$, so the only
decreasing adjacencies are the two inside the cage. Small \emph{hinge} gadgets
couple adjacent cages that share an element and enforce that a strip swap that
removes exactly two adjacencies corresponds bijectively to a block move that
removes exactly one decreasing adjacency in the source permutation. This yields
a clean equivalence between exact SbSS schedules and perfect block schedules,
establishing NP-hardness.

</details>


### [264] [Scheduling Problems with Constrained Rejections](https://arxiv.org/abs/2511.00184)
*Sami Davies,Venkatesan Guruswami,Xuandi Ren*

Main category: cs.DS

TL;DR: 论文研究了多目标调度问题，改进了makespan与作业比例的权衡，并证明了Santa Claus问题的硬度。


<details>
  <summary>Details</summary>
Motivation: 探究在多目标调度问题中，如何在makespan增加时提高调度作业比例，并理解原始优化目标的鲁棒性。

Method: 通过算法改进和硬度证明，研究了makespan与调度作业比例之间的权衡关系。

Result: 在makespan为3T/2时，调度作业比例可提高至0.6533；首次证明了Santa Claus问题的NP-hardness。

Conclusion: 该论文研究了在允许有限拒绝的情况下，多目标版本的Makespan最小化和Santa Claus问题，展示了在makespan增加时调度作业比例的改进，并首次证明了Santa Claus问题的硬度结果。

Abstract: We study bicriteria versions of Makespan Minimization on Unrelated Machines
and Santa Claus by allowing a constrained number of rejections. Given an
instance of Makespan Minimization on Unrelated Machines where the optimal
makespan for scheduling $n$ jobs on $m$ unrelated machines is $T$, (Feige and
Vondr\'ak, 2006) gave an algorithm that schedules a $(1-1/e+10^{-180})$
fraction of jobs in time $T$. We show the ratio can be improved to
$0.6533>1-1/e+0.02$ if we allow makespan $3T/2$. To the best our knowledge,
this is the first result examining the tradeoff between makespan and the
fraction of scheduled jobs when the makespan is not $T$ or $2T$.
  For the Santa Claus problem (the Max-Min version of Makespan Minimization),
the analogous bicriteria objective was studied by (Golovin, 2005), who gave an
algorithm providing an allocation so a $(1-1/k)$ fraction of agents receive
value at least $T/k$, for any $k \in \mathbb{Z}^+$ and $T$ being the optimal
minimum value every agent can receive. We provide the first hardness result by
showing there are constants $\delta,\varepsilon>0$ such that it is NP-hard to
find an allocation where a $(1-\delta)$ fraction of agents receive value at
least $(1-\varepsilon) T$. To prove this hardness result, we introduce a
bicriteria version of Set Packing, which may be of independent interest, and
prove some algorithmic and hardness results for it. Overall, we believe these
bicriteria scheduling problems warrant further study as they provide an
interesting lens to understand how robust the difficulty of the original
optimization goal might be.

</details>


### [265] [Uncrossed Multiflows and Applications to Disjoint Paths](https://arxiv.org/abs/2511.00254)
*Chandra Chekuri,Guyslain Naves,Joseph Poremba,F. Bruce Shepherd*

Main category: cs.DS

TL;DR: 本文研究了平面图中无交叉多流的计算复杂性和舍入性质，证明了其在拥塞模型中的NP难性和最大化模型中的不可近似性，并展示了整数舍入的常数比例保证。


<details>
  <summary>Details</summary>
Motivation: 无交叉多流在先前路由算法中已有应用，但其作为独立算法问题在一般平面图中的性质尚未被充分研究。本文旨在填补这一空白，探究无交叉多流的计算复杂性和舍入性质。

Method: 本文采用理论分析方法，研究了无交叉多流在平面图中的计算复杂性、近似性和整数舍入性质。通过构建理论证明和算法设计，探讨了拥塞模型和最大化模型的不同情况。

Result: 本文证明了在拥塞模型中判定无交叉多流的存在性是NP难问题，但在需求跨越有限面数的情况下可多项式时间求解。在最大化模型中，展示了几乎多项式的不可近似性结果。此外，证明了无交叉多流可常数比例舍入为整数流，且在拥塞模型中的舍入过程能产生边拥塞为2的整数流。

Conclusion: 本文研究了在一般平面图中寻找无交叉多流的问题，证明了在拥塞模型中判定无交叉多流的存在性是NP难问题，但在需求跨越有限面数的情况下可多项式时间求解。在最大化模型中，展示了几乎多项式的不可近似性结果。此外，证明了无交叉多流可以常数比例舍入为整数流，且拥塞模型中的舍入过程能产生边拥塞为2的整数流。

Abstract: A multiflow in a planar graph is uncrossed if the curves identified by its
support paths do not cross in the plane. Such flows have played a role in
previous routing algorithms, including Schrijver's Homotopy Method and
unsplittable flows in directed planar single-source instances. Recently
uncrossed flows have played a key role in approximation algorithms for maximum
disjoint paths in fully-planar instances, where the combined supply plus demand
graph is planar. In the fully-planar case, any fractional multiflow can be
converted into one that is uncrossed, which is then exploited to find a good
rounding of the fractional solution. We investigate finding an uncrossed
multiflow as a standalone algorithmic problem in general planar instances (not
necessarily fully-planar). We consider both a congestion model where the given
demands must all be routed, and a maximization model where the goal is to pack
as much flow in the supply graph as possible (not necessarily equitably).
  For the congestion model, we show that determining if an instance has an
uncrossed (fractional) multiflow is NP-hard, but the problem of finding an
integral uncrossed flow is polytime solvable if the demands span a bounded
number of faces. For the maximization model, we present a strong (almost
polynomial) inapproximability result. Regarding integrality gaps, for
maximization we show that an uncrossed multiflow in a planar instance can
always be rounded to an integral multiflow with a constant fraction of the
original value. This holds in both the edge-capacitated and node-capacitated
settings, and generalizes earlier bounds for fully-planar instances. In the
congestion model, given an uncrossed fractional multiflow, we give a rounding
procedure that produces an integral multiflow with edge congestion 2, which can
be made unsplittable with an additional additive error of the maximum demand.

</details>


### [266] [An Approximation Algorithm for Monotone Submodular Cost Allocation](https://arxiv.org/abs/2511.00470)
*Ryuhei Mizutani*

Main category: cs.DS

TL;DR: 论文针对单调子模成本分配问题，提出LP松弛方法并证明其积分间隙上限为k/2，提供了近似算法，同时展示了积分间隙下限。


<details>
  <summary>Details</summary>
Motivation: 研究单调子模成本分配问题（Mono-MSCA），旨在最小化k个子模函数的和。

Method: 通过自然LP松弛方法，等同于Chekuri和Ene引入的凸规划松弛。

Result: 证明LP松弛的积分间隙上限为k/2，并提供了k/2-近似算法；同时证明了当k固定时，积分间隙下限为k/2-ε。

Conclusion: 论文提供了Mono-MSCA问题的LP松弛方法，并证明了其积分间隙上限为k/2，同时给出了近似算法。

Abstract: In this paper, we consider the minimum submodular cost allocation (MSCA)
problem. The input of MSCA is $k$ non-negative submodular functions
$f_1,\ldots,f_k$ on the ground set $N$ given by evaluation oracles, and the
goal is to partition $N$ into $k$ (possibly empty) sets $X_1,\ldots,X_k$ so
that $\sum_{i=1}^k f_i(X_i)$ is minimized. In this paper, we focus on the case
when $f_1,\ldots,f_k$ are monotone (denoted by Mono-MSCA). We provide a natural
LP-relaxation for Mono-MSCA, which is equivalent to the convex program
relaxation introduced by Chekuri and Ene. We show that the integrality gap of
the LP-relaxation is at most $k/2$, which yields a $k/2$-approximation
algorithm for Mono-MSCA. We also show that the integrality gap of the
LP-relaxation is at least $k/2-\epsilon$ for any constant $\epsilon>0$ when $k$
is fixed.

</details>


### [267] [Fast Stochastic Greedy Algorithm for $k$-Submodular Cover Problem](https://arxiv.org/abs/2511.00869)
*Hue T. Nguyen,Tan D. Tran,Nguyen Long Giang,Canh V. Pham*

Main category: cs.DS

TL;DR: 提出Fast Stochastic Greedy算法，显著提升kSC问题的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有kSC问题算法存在近似保证弱或查询复杂度高的问题，难以满足大规模AI应用需求。

Method: Fast Stochastic Greedy算法

Result: 新算法在降低查询复杂度的同时，保持了强双准则近似性能。

Conclusion: 提出的Fast Stochastic Greedy算法在kSC问题上实现了强双准则近似，显著降低了查询复杂度，适用于大规模实际AI应用。

Abstract: We study the $k$-Submodular Cover ($kSC$) problem, a natural generalization
of the classical Submodular Cover problem that arises in artificial
intelligence and combinatorial optimization tasks such as influence
maximization, resource allocation, and sensor placement. Existing algorithms
for $\kSC$ often provide weak approximation guarantees or incur prohibitively
high query complexity. To overcome these limitations, we propose a \textit{Fast
Stochastic Greedy} algorithm that achieves strong bicriteria approximation
while substantially lowering query complexity compared to state-of-the-art
methods. Our approach dramatically reduces the number of function evaluations,
making it highly scalable and practical for large-scale real-world AI
applications where efficiency is essential.

</details>


### [268] [Dynamic Diameter in High-Dimensions against Adaptive Adversary and Beyond](https://arxiv.org/abs/2511.01065)
*Kiarash Banihashem,Jeff Giliberti,Samira Goudarzi,MohammadTaghi Hajiaghayi,Peyman Jabbarzade,Morteza Monemizadeh*

Main category: cs.DS

TL;DR: 提出高维动态点集的直径和k-中心聚类算法，抗自适应对手，2-近似直径更新时间poly(d, log n)，(4+ε)-近似k-中心更新时间k^2.5 d · poly(ε^-1, log n)。


<details>
  <summary>Details</summary>
Motivation: 研究在动态点集和高维环境下，如何有效维护直径和k-中心聚类，尤其是在面对自适应对手时的挑战。

Method: 通过识别数据集的稳健代表并结合谨慎的去摊销化，实现了最坏情况下poly(d, log n)的更新时间。

Result: 实现了2-近似直径的高效全动态算法，以及改进的(4+ε)-近似k-中心聚类算法，更新时间分别为poly(d, log n)和k^2.5 d · poly(ε^-1, log n)。

Conclusion: 本文提出了一种在高维动态点集上保持直径和k-中心聚类的高效算法，能够在自适应对手的情况下保持2-近似直径和(4+ε)-近似k-中心聚类。

Abstract: In this paper, we study the fundamental problems of maintaining the diameter
and a $k$-center clustering of a dynamic point set $P \subset \mathbb{R}^d$,
where points may be inserted or deleted over time and the ambient dimension $d$
is not constant and may be high. Our focus is on designing algorithms that
remain effective even in the presence of an adaptive adversary -- an adversary
that, at any time $t$, knows the entire history of the algorithm's outputs as
well as all the random bits used by the algorithm up to that point. We present
a fully dynamic algorithm that maintains a $2$-approximate diameter with a
worst-case update time of $\text{poly}(d, \log n)$, where $n$ is the length of
the stream. Our result is achieved by identifying a robust representative of
the dataset that requires infrequent updates, combined with a careful
deamortization. To the best of our knowledge, this is the first efficient
fully-dynamic algorithm for diameter in high dimensions that simultaneously
achieves a 2-approximation guarantee and robustness against an adaptive
adversary. We also give an improved dynamic $(4+\epsilon)$-approximation
algorithm for the $k$-center problem, also resilient to an adaptive adversary.
Our clustering algorithm achieves an amortized update time of $k^{2.5} d \cdot
\text{poly}(\epsilon^{-1}, \log n)$, improving upon the amortized update time
of $k^6 d \cdot \text{poly}(\epsilon^{-1}, \log n)$ by Biabani et al.
[NeurIPS'24].

</details>


### [269] [Fault-Tolerant Approximate Distance Oracles with a Source Set](https://arxiv.org/abs/2511.01239)
*Dipan Dey,Telikepalli Kavitha*

Main category: cs.DS

TL;DR: 提出了两种容错的源近似距离预言机，具有不同的尺寸和拉伸，查询时间为O(1)。


<details>
  <summary>Details</summary>
Motivation: 解决在无向加权图中，给定源集和故障边时，快速估算源点到其他顶点距离的问题。

Method: 利用Bilò等人（STACS 2018）的容错ST距离预言机构建了两种源近似距离预言机，分别具有不同的尺寸和拉伸。

Result: 构建了尺寸分别为Õ(|S|n + n^{3/2})和Õ(|S|n + n^{4/3})的预言机，乘法拉伸分别为5和13。

Conclusion: 本文提出了两种容错的源近似距离预言机，分别具有5和13的乘法拉伸，查询时间为O(1)。

Abstract: Our input is an undirected weighted graph $G = (V,E)$ on $n$ vertices along
with a source set $S\subseteq V$. The problem is to preprocess $G$ and build a
compact data structure such that upon query $Qu(s,v,f)$ where $(s,v) \in
S\times V$ and $f$ is any faulty edge, we can quickly find a good estimate
(i.e., within a small multiplicative stretch) of the $s$-$v$ distance in $G-f$.
We use a fault-tolerant $ST$-distance oracle from the work of Bil{\`{o}} et al.
(STACS 2018) to construct an $S\times V$ approximate distance oracle or {\em
sourcewise} approximate distance oracle of size $\widetilde{O}(|S|n + n^{3/2})$
with multiplicative stretch at most 5. We construct another fault-tolerant
sourcewise approximate distance oracle of size $\widetilde{O}(|S|n + n^{4/3})$
with multiplicative stretch at most 13. Both the oracles have $O(1)$ query
answering time.

</details>


### [270] [Subtree Mode and Applications](https://arxiv.org/abs/2511.01376)
*Jialong Zhou,Ben Bals,Matei Tinca,Ai Guan,Panagiotis Charalampopoulos,Grigorios Loukides,Solon P. Pissis*

Main category: cs.DS

TL;DR: 本文解决了子树模式（SM）问题，提出了一种时间最优算法，适用于叶子或节点着色树，并在实际应用中验证了其高效性和空间效率。


<details>
  <summary>Details</summary>
Motivation: SM问题由文本分析和生物学等领域的应用驱动，这些领域的数据具有层次结构，可以表示为叶子着色树。

Method: 引入了一种时间最优的算法，能够在O(N)时间内计算N节点树中每个节点的子树模式，并扩展到节点着色树或计算前k个最频繁颜色。

Result: 实验证明，该算法在包含73亿个节点的真实数据集上比基线快至少一个数量级，且空间效率更高。

Conclusion: 本文提出的子树模式（SM）问题算法不仅在理论上达到了时间最优（O(N)），在实际应用中（如模式挖掘和序列到数据库搜索）也表现出高效性和空间效率。

Abstract: The mode of a collection of values (i.e., the most frequent value in the
collection) is a key summary statistic. Finding the mode in a given range of an
array of values is thus of great importance, and constructing a data structure
to solve this problem is in fact the well-known Range Mode problem. In this
work, we introduce the Subtree Mode (SM) problem, the analogous problem in a
leaf-colored tree, where the task is to compute the most frequent color in the
leaves of the subtree of a given node. SM is motivated by several applications
in domains such as text analytics and biology, where the data are hierarchical
and can thus be represented as a (leaf-colored) tree. Our central contribution
is a time-optimal algorithm for SM that computes the answer for every node of
an input $N$-node tree in $O(N)$ time. We further show how our solution can be
adapted for node-colored trees, or for computing the $k$ most frequent colors,
in the optimal $O(N)$ time, for any given $k=O(1)$. Moreover, we prove that a
similarly fast solution for when the input is a sink-colored directed acyclic
graph instead of a leaf-colored tree is highly unlikely. Our experiments on
real datasets with trees of up to 7.3 billion nodes demonstrate that our
algorithm is faster than baselines by at least one order of magnitude and much
more space efficient. Last, we present case studies showing the effectiveness
of our approach in pattern mining and sequence-to-database search applications.

</details>


### [271] [Robust Streaming Against Low-Memory Adversaries](https://arxiv.org/abs/2511.01769)
*Omri Ben-Eliezer,Krzysztof Onak,Sandeep Silwal*

Main category: cs.DS

TL;DR: 本研究针对无记忆或低记忆对手设计了高效鲁棒流算法，填补了现有模型的空白，并展示了对手模型在特定情况下的强大能力。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决鲁棒流算法中对手模型过强导致性能差距的问题，尝试通过限制对手的记忆能力来缩小性能差距。

Method: 设计了新的简单方法，类似于计算路径框架，用于处理广泛类别的顺序不变问题。

Result: 展示了即使对手无记忆或仅有少量记忆，依然能产生高翻转数和密度的流，这排除了大多数已知的鲁棒化技术。

Conclusion: 本研究提出了针对无记忆或低记忆对手的高效鲁棒流算法，填补了现有模型中的空白。

Abstract: Robust streaming, the study of streaming algorithms that provably work when
the stream is generated by an adaptive adversary, has seen tremendous progress
in recent years. However, fundamental barriers remain: the best known algorithm
for turnstile $F_p$-estimation in the robust streaming setting is exponentially
worse than in the oblivious setting, and closing this gap seems difficult.
Arguably, one possible cause of this barrier is the adversarial model, which
may be too strong: unlike the space-bounded streaming algorithm, the adversary
can memorize the entire history of the interaction with the algorithm. Can we
then close the exponential gap if we insist that the adversary itself is an
adaptive but low-memory entity, roughly as powerful as (or even weaker than)
the algorithm?
  In this work we present the first set of models and results aimed towards
this question. We design efficient robust streaming algorithms against
adversaries that are fully adaptive but have no long-term memory ("memoryless")
or very little memory of the history of interaction. Roughly speaking, a
memoryless adversary only sees, at any given round, the last output of the
algorithm (and does not even know the current time) and can generate an
unlimited number of independent coin tosses. A low-memory adversary is similar,
but maintains an additional small buffer. While these adversaries may seem
quite limited at first glance, we show that this adversarial model is strong
enough to produce streams that have high flip number and density in the context
of $F_2$-estimation, which rules out most of known robustification techniques.
We then design a new simple approach, similar to the computation paths
framework, to obtain efficient algorithms against memoryless and low-memory
adversaries for a wide class of order-invariant problems.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [272] [ScaleCall - Agentic Tool Calling at Scale for Fintech: Challenges, Methods, and Deployment Insights](https://arxiv.org/abs/2511.00074)
*Richard Osuagwu,Thomas Cook,Maraim Masoud,Koustav Ghosal,Riccardo Mattivi*

Main category: cs.SE

TL;DR: 论文研究了企业环境中LLMs工具调用的挑战，提出了ScaleCall框架，评估了多种检索方法，指出方法效果取决于领域特性，并验证了框架的实际应用。


<details>
  <summary>Details</summary>
Motivation: 在受监管的企业环境（如金融科技）中部署LLMs工具调用面临独特挑战，包括本地化约束、合规要求和功能重叠工具集的歧义消除。

Method: 开发ScaleCall原型框架，系统评估嵌入检索、提示列表排序和混合方法，分析其在不同场景下的表现。

Result: 嵌入方法在大工具库中延迟更低，列表排序在功能重叠时歧义消除更优，混合方法在某些场景有潜力。

Conclusion: 研究为企业环境中的工具调用系统设计提供了实用见解，权衡了检索准确性、计算效率和操作需求。

Abstract: While Large Language Models (LLMs) excel at tool calling, deploying these
capabilities in regulated enterprise environments such as fintech presents
unique challenges due to on-premises constraints, regulatory compliance
requirements, and the need to disambiguate large, functionally overlapping
toolsets. In this paper, we present a comprehensive study of tool retrieval
methods for enterprise environments through the development and deployment of
ScaleCall, a prototype tool-calling framework within Mastercard designed for
orchestrating internal APIs and automating data engineering workflows. We
systematically evaluate embedding-based retrieval, prompt-based listwise
ranking, and hybrid approaches, revealing that method effectiveness depends
heavily on domain-specific factors rather than inherent algorithmic
superiority. Through empirical investigation on enterprise-derived benchmarks,
we find that embedding-based methods offer superior latency for large tool
repositories, while listwise ranking provides better disambiguation for
overlapping functionalities, with hybrid approaches showing promise in specific
contexts. We integrate our findings into ScaleCall's flexible architecture and
validate the framework through real-world deployment in Mastercard's regulated
environment. Our work provides practical insights into the trade-offs between
retrieval accuracy, computational efficiency, and operational requirements,
contributing to the understanding of tool-calling system design for enterprise
applications in regulated industries.

</details>


### [273] [Adding New Capability in Existing Scientific Application with LLM Assistance](https://arxiv.org/abs/2511.00087)
*Anshu Dubey,Akash Dhruv*

Main category: cs.SE

TL;DR: 本文提出了一种利用LLM辅助生成新算法代码的方法，并改进了Code-Scribe工具，填补了新算法代码生成领域的空白。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型的快速发展，自动化编码任务成为重要研究方向。然而，针对新算法的代码生成（训练数据中无类似代码示例）尚未充分探索。

Method: 论文提出了一种新方法，通过增强现有的Code-Scribe工具，利用LLM辅助生成新算法的代码。

Result: 研究结果表明，改进后的Code-Scribe工具能够有效支持新算法的代码生成。

Conclusion: 本文提出了一种利用大型语言模型（LLM）辅助从零开始编写新算法代码的新方法，并改进了现有的代码翻译工具Code-Scribe，以支持新代码生成。

Abstract: With the emergence and rapid evolution of large language models (LLM),
automating coding tasks has become an im- portant research topic. Many efforts
are underway and liter- ature abounds about the efficacy of models and their
ability to generate code. A less explored aspect of code generation is for new
algorithms, where the training data-set would not have included any previous
example of similar code. In this paper we propose a new methodology for writing
code from scratch for a new algorithm using LLM assistance, and describe
enhancement of a previously developed code- translation tool, Code-Scribe, for
new code generation.

</details>


### [274] [Inferring multiple helper Dafny assertions with LLMs](https://arxiv.org/abs/2511.00125)
*Álvaro Silva,Alexandra Mendes,Ruben Martins*

Main category: cs.SE

TL;DR: 使用LLM自动推断Dafny程序中的缺失断言，DAISY工具在多断言缺失情况下表现良好，证明自动化断言推断可减少验证工作量。


<details>
  <summary>Details</summary>
Motivation: Dafny验证器虽然提供了强大的正确性保证，但通常需要大量手动辅助断言，这成为其广泛应用的障碍。

Method: 通过结合LLM预测和错误消息启发式的混合方法，精确定位故障，并实现了一个名为DAISY的新工具。

Result: DAISY在单断言缺失的情况下验证了63.4%的程序，在多断言缺失的情况下验证了31.7%的程序。

Conclusion: 自动化断言推断可以显著减少证明工程的工作量，并为更可扩展和易用的形式验证迈出了一步。

Abstract: The Dafny verifier provides strong correctness guarantees but often requires
numerous manual helper assertions, creating a significant barrier to adoption.
We investigate the use of Large Language Models (LLMs) to automatically infer
missing helper assertions in Dafny programs, with a primary focus on cases
involving multiple missing assertions. To support this study, we extend the
DafnyBench benchmark with curated datasets where one, two, or all assertions
are removed, and we introduce a taxonomy of assertion types to analyze
inference difficulty. Our approach refines fault localization through a hybrid
method that combines LLM predictions with error-message heuristics. We
implement this approach in a new tool called DAISY (Dafny Assertion Inference
SYstem). While our focus is on multiple missing assertions, we also evaluate
DAISY on single-assertion cases. DAISY verifies 63.4% of programs with one
missing assertion and 31.7% with multiple missing assertions. Notably, many
programs can be verified with fewer assertions than originally present,
highlighting that proofs often admit multiple valid repair strategies and that
recovering every original assertion is unnecessary. These results demonstrate
that automated assertion inference can substantially reduce proof engineering
effort and represent a step toward more scalable and accessible formal
verification.

</details>


### [275] [What a diff makes: automating code migration with large language models](https://arxiv.org/abs/2511.00160)
*Katherine A. Rosenfeld,Cliff C. Kerr,Jessica Lundin*

Main category: cs.SE

TL;DR: 论文探讨了利用LLM进行代码迁移的方法，通过AIMigrate工具在实际项目中验证了其高效性，显著提升了迁移准确性。


<details>
  <summary>Details</summary>
Motivation: 现代软件程序依赖的底层栈经常更新，可能导致依赖项目不兼容。为了解决这一问题，探索了LLM在代码迁移中的应用。

Method: 使用包含差异（diffs）的上下文来提升LLM在代码迁移中的性能，并通过测试覆盖率和变更比较等指标进行评估。

Result: 在TYPHOIDSIM的实际迁移中，AIMigrate单次运行正确识别了65%的必要变更，多次运行后提升至80%，其中47%的变更生成完美。

Conclusion: 论文提出了一种利用大型语言模型（LLM）进行代码迁移的方法，并通过AIMigrate工具在实际项目中验证了其有效性，能够显著提高代码迁移的准确性和效率。

Abstract: Modern software programs are built on stacks that are often undergoing
changes that introduce updates and improvements, but may also break any project
that depends upon them. In this paper we explore the use of Large Language
Models (LLMs) for code migration, specifically the problem of maintaining
compatibility with a dependency as it undergoes major and minor semantic
version changes. We demonstrate, using metrics such as test coverage and change
comparisons, that contexts containing diffs can significantly improve
performance against out of the box LLMs and, in some cases, perform better than
using code. We provide a dataset to assist in further development of this
problem area, as well as an open-source Python package, AIMigrate, that can be
used to assist with migrating code bases. In a real-world migration of
TYPHOIDSIM between STARSIM versions, AIMigrate correctly identified 65% of
required changes in a single run, increasing to 80% with multiple runs, with
47% of changes generated perfectly.

</details>


### [276] [Understanding Code Agent Behaviour: An Empirical Study of Success and Failure Trajectories](https://arxiv.org/abs/2511.00197)
*Oorja Majgaonkar,Zhiwei Fei,Xiang Li,Federica Sarro,He Ye*

Main category: cs.SE

TL;DR: 本研究分析了LLM代理在解决软件问题时的行为轨迹，揭示了成功与失败的关键差异及策略，为开发更可靠的自主系统提供了见解。


<details>
  <summary>Details</summary>
Motivation: 随着LLM代理在复杂软件工程任务中的广泛应用，需要深入了解其问题解决行为，而不仅仅是简单的成功指标。

Method: 对三种先进的代码代理（OpenHands、SWE-agent和Prometheus）在SWE-Bench基准上的执行轨迹进行实证分析，包括成功和失败的尝试。

Result: 研究发现不同的解决问题策略（如防御性编程和上下文收集）在不同场景下有助于成功；失败的轨迹通常更长且方差更大；故障定位分析显示，成功更依赖于近似而非精确的代码修改。

Conclusion: 本研究通过分析LLM代理在解决软件问题时的执行轨迹，揭示了代理行为的关键见解，为开发更健壮和可解释的自主软件工程系统奠定了基础。

Abstract: The increasing deployment of Large Language Model (LLM) agents for complex
software engineering tasks has created a need to understand their
problem-solving behaviours beyond simple success metrics. While these agents
demonstrate impressive capabilities in automated issue resolution, their
decision-making processes remain largely opaque. This paper presents an
empirical study of agent trajectories, namely the execution traces capturing
the steps agents take when attempting to resolve software issues. We analyse
trajectories from three state-of-the-art code agents (OpenHands, SWE-agent, and
Prometheus) on the SWE-Bench benchmark, examining both successful and failed
attempts. Our investigation reveals several key insights into agent behaviour.
First, we identify how distinct problem-solving strategies, such as defensive
programming and context gathering, enable success in different scenarios.
Second, we find that failed trajectories are consistently longer and exhibit
higher variance than successful ones, with failure patterns differing
significantly between agents. Third, our fault localisation analysis shows that
while most trajectories correctly identify problematic files (72-81\% even in
failures), success depends more on achieving approximate rather than exact code
modifications. These and other findings unveiled by our study, provide a
foundation for understanding agent behaviour through trajectory analysis,
contributing to the development of more robust and interpretable autonomous
software engineering systems.

</details>


### [277] [Position: Vibe Coding Needs Vibe Reasoning: Improving Vibe Coding with Formal Verification](https://arxiv.org/abs/2511.00202)
*Jacqueline Mitchell,Yasser Shaaban*

Main category: cs.SE

TL;DR: 通过侧挂系统集成形式化方法，提升大型语言模型在‘氛围编码’中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 发现‘氛围编码’在实践中存在技术债务、安全问题和代码混乱等限制，原因是大型语言模型无法协调人类施加的约束。

Method: 提出一个‘侧挂系统’，包含自动形式化规范、验证目标、提供可操作反馈和允许开发者直观影响规范的四个步骤。

Result: 形式化方法可以缓解这些问题，但需要超越现有的结合方式。

Conclusion: 通过形式化方法的集成，可以提升‘氛围编码’的可靠性，减少技术债务和安全问题。

Abstract: ``Vibe coding'' -- the practice of developing software through iteratively
conversing with a large language model (LLM) -- has exploded in popularity
within the last year. However, developers report key limitations including the
accumulation of technical debt, security issues, and code churn to achieve
satisfactory results. We argue that these pitfalls result from LLMs' inability
to reconcile accumulating human-imposed constraints during vibe coding, with
developers inadvertently failing to resolve contradictions because LLMs
prioritize user commands over code consistency. Given LLMs' receptiveness to
verification-based feedback, we argue that formal methods can mitigate these
pitfalls, making vibe coding more reliable. However, we posit that integrating
formal methods must transcend existing approaches that combine formal methods
and LLMs. We advocate for a side-car system throughout the vibe coding process
which: (1) \emph{Autoformalizes} specifications (2) Validates against targets,
(3) Delivers \emph{actionable} feedback to the LLM, and (4) Allows intuitive
developer influence on specifications.

</details>


### [278] [DocPrism: Local Categorization and External Filtering to Identify Relevant Code-Documentation Inconsistencies](https://arxiv.org/abs/2511.00215)
*Xiaomeng Xu,Zahin Wahab,Reid Holmes,Caroline Lemieux*

Main category: cs.SE

TL;DR: DocPrism通过LCEF方法优化LLM的本地分类能力，显著降低代码-文档不一致检测的误报率，并在多语言环境中保持高精度。


<details>
  <summary>Details</summary>
Motivation: 代码与文档不一致是常见问题，可能导致开发者误解和软件缺陷，因此需要高效工具来检测和减少这类不一致性。

Method: DocPrism利用标准大型语言模型（LLM）结合LCEF方法（本地分类和外部过滤）来分析代码-文档不一致性，避免直接依赖LLM的长期推理能力。

Result: 在Python、TypeScript、C++和Java的广泛评估中，DocPrism的误报率降至15%，准确率提升至94%，且无需微调即可达到0.62的精确度。

Conclusion: DocPrism通过引入LCEF方法显著降低了代码-文档不一致性检测的误报率，并提高了准确性，展示了在多语言环境中的有效性。

Abstract: Code-documentation inconsistencies are common and undesirable: they can lead
to developer misunderstandings and software defects. This paper introduces
DocPrism, a multi-language, code-documentation inconsistency detection tool.
DocPrism uses a standard large language model (LLM) to analyze and explain
inconsistencies. Plain use of LLMs for this task yield unacceptably high false
positive rates: LLMs identify natural gaps between high-level documentation and
detailed code implementations as inconsistencies. We introduce and apply the
Local Categorization, External Filtering (LCEF) methodology to reduce false
positives. LCEF relies on the LLM's local completion skills rather than its
long-term reasoning skills. In our ablation study, LCEF reduces DocPrism's
inconsistency flag rate from 98% to 14%, and increases accuracy from 14% to
94%. On a broad evaluation across Python, TypeScript, C++, and Java, DocPrism
maintains a low flag rate of 15%, and achieves a precision of 0.62 without
performing any fine-tuning.

</details>


### [279] [LLM-Driven Cost-Effective Requirements Change Impact Analysis](https://arxiv.org/abs/2511.00262)
*Romina Etezadi,Sallam Abualhaija,Chetan Arora,Lionel Briand*

Main category: cs.SE

TL;DR: ProReFiCIA利用LLM自动识别需求变更影响，高效且成本低。


<details>
  <summary>Details</summary>
Motivation: 需求变更的手动影响分析成本高且易出错，LLM的潜力为解决此问题提供了新思路。

Method: 提出ProReFiCIA，基于LLM和定制化提示变体，自动识别需求变更的影响。

Result: 在基准数据集上召回率达93.3%，行业数据集上达95.8%，且仅需工程师审查2.1%-8.5%的需求。

Conclusion: ProReFiCIA利用LLM自动识别需求变更的影响，显著提高了效率，且在成本和准确性上表现优异。

Abstract: Requirements are inherently subject to changes throughout the software
development lifecycle. Within the limited budget available to requirements
engineers, manually identifying the impact of such changes on other
requirements is both error-prone and effort-intensive. That might lead to
overlooked impacted requirements, which, if not properly managed, can cause
serious issues in the downstream tasks. Inspired by the growing potential of
large language models (LLMs) across diverse domains, we propose ProReFiCIA, an
LLM-driven approach for automatically identifying the impacted requirements
when changes occur. We conduct an extensive evaluation of ProReFiCIA using
several LLMs and prompts variants tailored to this task. Using the best
combination of an LLM and a prompt variant, ProReFiCIA achieves a recall of
93.3% on a benchmark dataset and 95.8% on a newly created industry dataset,
demonstrating its strong effectiveness in identifying impacted requirements.
Further, the cost of applying ProReFiCIA remains small, as the engineer only
needs to review the generated results, which represent between 2.1% and 8.5% of
the entire set of requirements.

</details>


### [280] [Human-AI Programming Role Optimization: Developing a Personality-Driven Self-Determination Framework](https://arxiv.org/abs/2511.00417)
*Marcel Valovy*

Main category: cs.SE

TL;DR: 论文提出ROMA框架，通过个性优化人-AI编程角色分配，提升动机与团队协作，贡献实证框架、分类法及ISO标准扩展。


<details>
  <summary>Details</summary>
Motivation: 随着AI改变软件开发，如何优化开发者与AI系统的协作效率成为关键问题。

Method: 采用设计科学研究方法，包含五个周期，涉及200名实验参与者和46名访谈受访者，验证个性特征与编程角色偏好及协作结果的关系。

Result: 研究发现个性驱动角色优化显著提升自我决定和团队动力，动机提升平均23%（专业人员）至65%（本科生），并识别出五种个性原型及其角色偏好。

Conclusion: 该论文提出并验证了ROMA框架，通过个性驱动角色优化显著提升自我决定和团队动力，贡献了连接个性特征与角色偏好的实证框架、AI协作模式的分类法以及ISO/IEC 29110扩展。

Abstract: As artificial intelligence transforms software development, a critical
question emerges: how can developers and AI systems collaborate most
effectively? This dissertation optimizes human-AI programming roles through
self-determination theory and personality psychology, introducing the Role
Optimization Motivation Alignment (ROMA) framework.
  Through Design Science Research spanning five cycles, this work establishes
empirically-validated connections between personality traits, programming role
preferences, and collaborative outcomes, engaging 200 experimental participants
and 46 interview respondents.
  Key findings demonstrate that personality-driven role optimization
significantly enhances self-determination and team dynamics, yielding 23%
average motivation increases among professionals and up to 65% among
undergraduates. Five distinct personality archetypes emerge: The Explorer (high
Openness/low Agreeableness), The Orchestrator (high
Extraversion/Agreeableness), The Craftsperson (high Neuroticism/low
Extraversion), The Architect (high Conscientiousness), and The Adapter
(balanced profile). Each exhibits distinct preferences for programming roles
(Co-Pilot, Co-Navigator, Agent), with assignment modes proving crucial for
satisfaction.
  The dissertation contributes: (1) an empirically-validated framework linking
personality traits to role preferences and self-determination outcomes; (2) a
taxonomy of AI collaboration modalities mapped to personality profiles while
preserving human agency; and (3) an ISO/IEC 29110 extension enabling Very Small
Entities to implement personality-driven role optimization within established
standards.
  Keywords: artificial intelligence, human-computer interaction, behavioral
software engineering, self-determination theory, personality psychology,
phenomenology, intrinsic motivation, pair programming, design science research,
ISO/IEC 29110

</details>


### [281] [SmartDoc: A Context-Aware Agentic Method Comment Generation Plugin](https://arxiv.org/abs/2511.00450)
*Vahid Etemadi,Gregorio Robles*

Main category: cs.SE

TL;DR: SmartDoc是一款IntelliJ插件，利用AI和上下文感知技术生成方法注释，评估显示其高准确性。


<details>
  <summary>Details</summary>
Motivation: 软件维护阶段需要程序理解，而方法作为主要构建块，其注释的准确性和时效性对开发者至关重要。

Method: 该插件作为AI代理，利用目标方法的上下文和嵌套方法调用生成注释，通过DFS遍历调用图以丰富LLM提示。

Result: SmartDoc插件支持Java代码库，能并发处理多个方法的注释更新，并通过BERTScore等指标评估，其准确率在0.80至0.90之间。

Conclusion: SmartDoc作为一种IntelliJ IDEA插件，通过AI代理和上下文感知技术，有效提升了方法注释生成的准确性和效率，BERTScore等评估指标显示其性能优异。

Abstract: Context: The software maintenance phase involves many activities such as code
refactoring, bug fixing, code review or testing. Program comprehension is key
to all these activities, as it demands developers to grasp the knowledge (e.g.,
implementation details) required to modify the codebase. Methods as main
building blocks in a program can offer developers this knowledge source for
code comprehension. However, reading entire method statements can be
challenging, which necessitates precise and up-to-date comments. Objective: We
propose a solution as an IntelliJ IDEA plugin, named SmartDoc, that assists
developers in generating context-aware method comments. Method: This plugin
acts as an Artificial Intelligence (AI) agent that has its own memory and is
augmented by target methods' context. When a request is initiated by the
end-user, the method content and all its nested method calls are used in the
comment generation. At the beginning, these nested methods are visited and a
call graph is generated. This graph is then traversed using depth-first search
(DFS), enabling the provision of full-context to enrich Large Language Model
(LLM) prompts. Result: The product is a software, as a plugin, developed for
Java codebase and installable on IntelliJ IDEA. This plugin can serve
concurrently for methods whose comments are being updated , and it shares
memory across all flows to avoid redundant calls. o measure the accuracy of
this solution, a dedicated test case is run to record SmartDoc generated
comments and their corresponding ground truth. For each collected result-set,
three metrics are computed, BERTScore, BLEU and ROUGE-1. These metrics will
determine how accurate the generated comments are in comparison to the ground
truth. Result: The obtained accuracy, in terms of the precision, recall and F1,
is promising, and lies in the range of 0.80 to 0.90 for BERTScore.

</details>


### [282] [A Big Step Forward? A User-Centric Examination of iOS App Privacy Report and Enhancements](https://arxiv.org/abs/2511.00467)
*Liu Wang,Dong Wang,Shidong Pan,Zheng Jiang,Haoyu Wang,Yi Wang*

Main category: cs.SE

TL;DR: 研究评估了苹果iOS 15.2的App隐私报告功能，发现其实际效果有限，并提出增强框架以提升用户隐私透明度。


<details>
  <summary>Details</summary>
Motivation: 尽管苹果推出的App隐私报告被宣传为用户隐私的重大进步，但其实际效果和对用户隐私及控制的影响尚未被研究。

Method: 采用端到端研究方法，包括系统评估、LLM支持的多技术合成增强，以及从系统和用户角度进行的全面评估。通过结构化焦点小组研究探索用户对功能的体验和理解。

Result: 研究发现该功能因缺乏重要细节而实际影响有限，用户主要关注数据访问目的和域描述的清晰度。提出的增强框架（目的推断和域澄清流程）被证明对用户有益。

Conclusion: 本研究通过系统评估App隐私报告的实际效果，提出了增强框架，为提升移动应用用户隐私透明度提供了实用见解，并探讨了未来研究方向。

Abstract: The prevalent engagement with mobile apps underscores the importance of
understanding their data practices. Transparency plays a crucial role in this
context, ensuring users to be informed and give consent before any data access
occurs. Apple introduced a new feature since iOS 15.2, App Privacy Report, to
inform users about detailed insights into apps' data access and sharing. This
feature continues Apple's trend of privacy-focused innovations (following
Privacy Nutrition Labels), and has been marketed as a big step forward in user
privacy. However, its real-world impacts on user privacy and control remain
unexamined. We thus proposed an end-to-end study involving systematic
assessment of the App Privacy Report's real-world benefits and limitations,
LLM-enabled and multi-technique synthesized enhancements, and comprehensive
evaluation from both system and user perspectives. Through a structured focus
group study with twelve everyday iOS users, we explored their experiences,
understanding, and perceptions of the feature, suggesting its limited practical
impact resulting from missing important details. We identified two primary user
concerns: the clarity of data access purpose and domain description. In
response, we proposed enhancements including a purpose inference framework and
domain clarification pipeline. We demonstrated the effectiveness and benefits
of such enhancements for mobile app users. This work provides practical
insights that could help enhance user privacy transparency and discusses areas
for future research.

</details>


### [283] [Issue-Oriented Agent-Based Framework for Automated Review Comment Generation](https://arxiv.org/abs/2511.00517)
*Shuochuan Li,Dong Wang,Patanamon Thongtanunam,Zan Wang,Jiuqiao Yu,Junjie Chen*

Main category: cs.SE

TL;DR: RevAgent是一种基于代理的代码审查评论生成框架，通过分解任务和专业化代理显著提升评论质量，尤其在复杂场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有代码审查评论生成技术依赖单一模型处理多样问题，导致评论质量不高，尤其在复杂场景如缺陷修复中。RevAgent旨在通过分解任务和专业化代理解决这一问题。

Method: RevAgent采用三阶段框架：生成阶段（五个特定类别评论代理分析代码变更）、判别阶段（批评代理选择最合适的评论）和训练阶段（代理在特定类别数据上微调）。

Result: RevAgent在BLEU、ROUGE-L、METEOR和SBERT指标上分别提升12.90%、10.87%、6.32%和8.57%，且在问题类别识别上准确性更高。

Conclusion: RevAgent通过其基于代理的框架显著提升了代码审查评论生成的性能，尤其在复杂场景下表现优异，并在性能和效率之间取得了良好的平衡。

Abstract: Code review (CR) is a crucial practice for ensuring software quality. Various
automated review comment generation techniques have been proposed to streamline
the labor-intensive process. However, existing approaches heavily rely on a
single model to identify various issues within the code, limiting the model's
ability to handle the diverse, issue-specific nature of code changes and
leading to non-informative comments, especially in complex scenarios such as
bug fixes. To address these limitations, we propose RevAgent, a novel
agent-based issue-oriented framework, decomposes the task into three stages:
(1) Generation Stage, where five category-specific commentator agents analyze
code changes from distinct issue perspectives and generate candidate comments;
(2) Discrimination Stage, where a critic agent selects the most appropriate
issue-comment pair; and (3) Training Stage, where all agents are fine-tuned on
curated, category-specific data to enhance task specialization. Evaluation
results show that RevAgent significantly outperforms state-of-the-art PLM- and
LLM-based baselines, with improvements of 12.90\%, 10.87\%, 6.32\%, and 8.57\%
on BLEU, ROUGE-L, METEOR, and SBERT, respectively. It also achieves relatively
higher accuracy in issue-category identification, particularly for challenging
scenarios. Human evaluations further validate the practicality of RevAgent in
generating accurate, readable, and context-aware review comments. Moreover,
RevAgent delivers a favorable trade-off between performance and efficiency.

</details>


### [284] [HIP-LLM: A Hierarchical Imprecise Probability Approach to Reliability Assessment of Large Language Models](https://arxiv.org/abs/2511.00527)
*Robab Aghazadeh-Chakherlou,Qing Guo,Siddartha Khastgir,Peter Popov,Xiaoge Zhang,Xingyu Zhao*

Main category: cs.SE

TL;DR: HIP-LLM 是一种分层不精确概率框架，用于更准确地评估 LLM 的可靠性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于基准的评估方法仅提供模型在数据集上的准确性描述性统计，无法深入理解 LLM 在实际操作条件下的概率行为，因此需要更严格的可靠性评估方法。

Method: HIP-LLM 采用分层不精确概率框架，结合软件可靠性工程基础，通过层次化依赖关系和嵌入不精确先验来建模和推断 LLM 的可靠性。

Result: 实验表明，HIP-LLM 在多基准数据集上提供了更准确的可靠性表征，并量化了先验和数据的不确定性。

Conclusion: HIP-LLM 框架为大型语言模型（LLMs）提供了一种更准确、标准化的可靠性评估方法，优于现有基准和最先进方法。

Abstract: Large Language Models (LLMs) are increasingly deployed across diverse
domains, raising the need for rigorous reliability assessment methods. Existing
benchmark-based evaluations primarily offer descriptive statistics of model
accuracy over datasets, providing limited insight into the probabilistic
behavior of LLMs under real operational conditions. This paper introduces
HIP-LLM, a Hierarchical Imprecise Probability framework for modeling and
inferring LLM reliability. Building upon the foundations of software
reliability engineering, HIP-LLM defines LLM reliability as the probability of
failure-free operation over a specified number of future tasks under a given
Operational Profile (OP). HIP-LLM represents dependencies across (sub-)domains
hierarchically, enabling multi-level inference from subdomain to system-level
reliability. HIP-LLM embeds imprecise priors to capture epistemic uncertainty
and incorporates OPs to reflect usage contexts. It derives posterior
reliability envelopes that quantify uncertainty across priors and data.
Experiments on multiple benchmark datasets demonstrate that HIP-LLM offers a
more accurate and standardized reliability characterization than existing
benchmark and state-of-the-art approaches. A publicly accessible repository of
HIP-LLM is provided.

</details>


### [285] [Employee Performance when Implementing Agile Practices in an IT Workforce](https://arxiv.org/abs/2511.00528)
*Muhammad Hamid Raza Mookadam,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 本研究探讨敏捷实践对南非IT员工绩效的影响，发现敏捷实践显著提升绩效，但也面临障碍。通过访谈发现，改善团队动态和协作是关键。


<details>
  <summary>Details</summary>
Motivation: 尽管敏捷实践在IT员工中的采用率增加，但在非洲背景下，关于员工在敏捷环境中绩效的全面研究仍然缺乏。本研究旨在填补这一空白，探讨南非IT员工在敏捷环境中的绩效。

Method: 采用解释主义单方法定性研究，使用访谈作为研究策略，对来自不同角色的17名敏捷从业者进行了半结构化访谈。

Result: 结果表明，敏捷实践显著影响员工绩效，参与者报告了包括规划、沟通、员工发展和福祉、协作、团队文化和进展等方面的影响。同时，研究还报告了使用敏捷实践时的障碍，如采用、团队参与、领导力和灌输敏捷思维。

Conclusion: 研究发现，如果能够解决敏捷实践的挑战并提供额外支持，IT员工的绩效可以显著提升。敏捷实践通过改善团队动态、增强协作、提高效率、风险管理、规划、持续改进、学习、个人发展和福祉来影响员工绩效。

Abstract: Adoption of agile practices has increased in IT workforces. However, there is
a lack of comprehensive studies in the African context on employee performance
when implementing agile practices. This study addresses this gap by exploring
employee performance in agile environments for IT workforces in South Africa.
An interpretivist mono-method qualitative approach was used, with the use of
interviews as a research strategy. Seventeen semi-structured interviews were
conducted with agile practitioners from various roles. Our results indicated
that agile practices influence employee performance significantly, with
participants reporting on aspects which included planning, communication,
employee development and well-being, collaboration, team culture and progress.
Additionally, our results reported obstacles when using agile practices that
included adoption, team engagement, leadership and instilling an agile mindset.
Agile practices influence employee performance in IT workforces by fostering
improved team dynamics, enhanced collaboration, improved efficiencies, risk
management, planning, continuous improvement, learning, personal development
and well-being. Conclusively, our findings suggest that if agile challenges are
addressed and additional support is provided, employee performance can be
significantly improved.

</details>


### [286] [GDPR-Bench-Android: A Benchmark for Evaluating Automated GDPR Compliance Detection in Android](https://arxiv.org/abs/2511.00619)
*Huaijin Ran,Haoyi Zhang,Xunzhu Tang*

Main category: cs.SE

TL;DR: 提出首个GDPR合规性检测基准GDPR-Bench-Android，评估11种方法，发现不同方法在不同任务中表现各异。


<details>
  <summary>Details</summary>
Motivation: 自动化检测GDPR合规性是一个关键但未被充分探索的挑战。

Method: 提出了GDPR-Bench-Android基准测试，包含1951个手动注释的违规实例，覆盖23个GDPR条款，并提供Formal-AST作为确定性基线方法。

Result: ReAct代理在文件级Accuracy@1表现最佳（17.38%），Qwen2.5-72B LLM在线级表现最佳（61.60%），Claude-Sonnet-4.5 LLM在多标签分类任务中Macro-F1最高（5.75%）。

Conclusion: 不同自动化方法在不同任务中表现各异，强调基准测试在诊断方法能力中的价值。

Abstract: Automating the detection of EU General Data Protection Regulation (GDPR)
violations in source code is a critical but underexplored challenge. We
introduce \textbf{GDPR-Bench-Android}, the first comprehensive benchmark for
evaluating diverse automated methods for GDPR compliance detection in Android
applications. It contains \textbf{1951} manually annotated violation instances
from \textbf{15} open-source repositories, covering 23 GDPR articles at file-,
module-, and line-level granularities. To enable a multi-paradigm evaluation,
we contribute \textbf{Formal-AST}, a novel, source-code-native formal method
that serves as a deterministic baseline. We define two tasks: (1)
\emph{multi-granularity violation localization}, evaluated via
Accuracy@\textit{k}; and (2) \emph{snippet-level multi-label classification},
assessed by macro-F1 and other classification metrics. We benchmark 11 methods,
including eight state-of-the-art LLMs, our Formal-AST analyzer, a
retrieval-augmented (RAG) method, and an agentic (ReAct) method. Our findings
reveal that no single paradigm excels across all tasks. For Task 1, the ReAct
agent achieves the highest file-level Accuracy@1 (17.38%), while the
Qwen2.5-72B LLM leads at the line level (61.60%), in stark contrast to the
Formal-AST method's 1.86%. For the difficult multi-label Task 2, the
Claude-Sonnet-4.5 LLM achieves the best Macro-F1 (5.75%), while the RAG method
yields the highest Macro-Precision (7.10%). These results highlight the
task-dependent strengths of different automated approaches and underscore the
value of our benchmark in diagnosing their capabilities. All resources are
available at: https://github.com/Haoyi-Zhang/GDPR-Bench-Android.

</details>


### [287] [Can Large Language Models Detect Real-World Android Software Compliance Violations?](https://arxiv.org/abs/2511.00624)
*Haoyi Zhang,Huaijin Ran,Xunzhu Tang*

Main category: cs.SE

TL;DR: CompliBench是一个评估LLMs检测Android应用合规性违规的新框架，通过两个任务和稳定性指标，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在跨多样法律框架检测Android应用合规性违规方面表现不足，需要更全面的评估框架。

Method: 论文设计了CompliBench框架，包含两个任务：任务1评估检索和定位能力（文件、模块、行粒度），任务2评估多标签判断能力。引入了稳定性感知复合指标（SGS、RCS、CRGS、OCS）进行综合评估。

Result: 实验显示，Claude-3.5-sonnet-20241022在OCS得分最高（0.3295），Gemini-2.5-pro最低（0.0538），证明CompliBench能有效提升合规检测性能。

Conclusion: 该论文提出了CompliBench框架，用于评估LLMs在多样法律框架下检测Android应用合规性违规的能力，并展示了其在提升LLM合规检测性能方面的潜力。

Abstract: The rapid development of Large Language Models (LLMs) has transformed
software engineering, showing promise in tasks like code generation, bug
detection, and compliance checking. However, current models struggle to detect
compliance violations in Android applications across diverse legal frameworks.
We propose \emph{CompliBench}, a novel evaluation framework for assessing LLMs'
ability to detect compliance violations under regulations like LGPD, PDPA, and
PIPEDA. The framework defines two tasks: Task 1 evaluates \emph{retrieval and
localization} at file, module, and line granularities, and Task 2 assesses
\emph{multi-label judgment} for code snippets. These tasks mirror the audit
process, where auditors locate problematic code and determine implicated
provisions. Traditional metrics fail to capture important aspects like
cross-granularity stability and jurisdictional consistency. Thus, we introduce
stability-aware composites (SGS, RCS, CRGS, and OCS) for a more comprehensive
assessment. Experiments with six models, including GPT-4O and Claude-3.5, show
\emph{CompliBench} improves compliance detection, with
Claude-3.5-sonnet-20241022 achieving the highest OCS score (0.3295), and
Gemini-2.5-pro the lowest (0.0538). This work demonstrates \emph{CompliBench}'s
potential for improving LLM performance in compliance tasks and provides a
foundation for future tools aligned with data protection standards. Our project
is available at https://github.com/Haoyi-Zhang/CompliBench.

</details>


### [288] [Lessons Learned from the Use of Generative AI in Engineering and Quality Assurance of a WEB System for Healthcare](https://arxiv.org/abs/2511.00658)
*Guilherme H. Travassos,Sabrina Rocha,Rodrigo Feitosa,Felipe Assis,Patricia Goncalves,Andre Gheventer,Larissa Galeno,Arthur Sasse,Julio Cesar Guimaraes,Carlos Brito,Joao Pedro Wieland*

Main category: cs.SE

TL;DR: 本文分享了在软件开发过程中应用生成式AI的经验，尽管技术尚不成熟，但为提升软件质量和创新开发实践提供了见解。


<details>
  <summary>Details</summary>
Motivation: 生成式AI技术的进步和可用性正在推动各领域工作活动的即时变革，软件工程领域同样有望从中受益，提升开发过程的效率和质量。

Method: 在软件开发过程中采用生成式AI，涵盖项目管理、需求规格说明、设计、开发和质量保证活动。

Result: 通过在实际项目中应用生成式AI，团队获得了宝贵的经验和建议，尽管技术成熟度有限，但为未来创新提供了方向。

Conclusion: 尽管尚未获得决定性的技术证据来显著改进开发流程，但本次经验报告中的成果和建议为寻求通过生成式AI创新开发实践以实现软件质量的组织提供了宝贵见解。

Abstract: The advances and availability of technologies involving Generative Artificial
Intelligence (AI) are evolving clearly and explicitly, driving immediate
changes in various work activities. Software Engineering (SE) is no exception
and stands to benefit from these new technologies, enhancing productivity and
quality in its software development processes. However, although the use of
Generative AI in SE practices is still in its early stages, considering the
lack of conclusive results from ongoing research and the limited technological
maturity, we have chosen to incorporate these technologies in the development
of a web-based software system to be used in clinical trials by a thoracic
diseases research group at our university. For this reason, we decided to share
this experience report documenting our development team's learning journey in
using Generative AI during the software development process. Project
management, requirements specification, design, development, and quality
assurance activities form the scope of observation. Although we do not yet have
definitive technological evidence to evolve our development process
significantly, the results obtained and the suggestions shared here represent
valuable insights for software organizations seeking to innovate their
development practices to achieve software quality with generative AI.

</details>


### [289] [Repairing Responsive Layout Failures Using Retrieval Augmented Generation](https://arxiv.org/abs/2511.00678)
*Tasmia Zerin,Moumita Asad,B. M. Mainul Hossain,Kazi Sakib*

Main category: cs.SE

TL;DR: ReDeFix是一种自动化修复响应式布局问题的方法，结合LLM和Stack Overflow知识，修复准确率达88%。


<details>
  <summary>Details</summary>
Motivation: 响应式网站在特定屏幕尺寸下会出现布局扭曲（RLFs），手动修复过程繁琐且低效。

Method: 利用LLM结合领域特定知识，通过检索Stack Overflow讨论生成CSS补丁。

Result: ReDeFix修复RLFs的准确率达到88%，且生成的修复方案在视觉上正确且美观。

Conclusion: ReDeFix是一种基于检索增强生成（RAG）的自动化修复方法，通过结合Stack Overflow知识和特定上下文，成功修复了88%的响应式布局问题（RLFs）。

Abstract: Responsive websites frequently experience distorted layouts at specific
screen sizes, called Responsive Layout Failures (RLFs). Manually repairing
these RLFs involves tedious trial-and-error adjustments of HTML elements and
CSS properties. In this study, an automated repair approach, leveraging LLM
combined with domain-specific knowledge is proposed. The approach is named
ReDeFix, a Retrieval-Augmented Generation (RAG)-based solution that utilizes
Stack Overflow (SO) discussions to guide LLM on CSS repairs. By augmenting
relevant SO knowledge with RLF-specific contexts, ReDeFix creates a prompt that
is sent to the LLM to generate CSS patches. Evaluation demonstrates that our
approach achieves an 88\% accuracy in repairing RLFs. Furthermore, a study from
software engineers reveals that generated repairs produce visually correct
layouts while maintaining aesthetics.

</details>


### [290] [An Empirical Investigation of the Experiences of Dyslexic Software Engineers](https://arxiv.org/abs/2511.00706)
*Marcos Vinicius Cruz,Pragya Verma,Grischa Liebel*

Main category: cs.SE

TL;DR: 本文探讨有阅读障碍的软件工程师的体验，发现他们在学习编程初期困难，但掌握后表现出色，支持工具有效，且在视觉思维和创造力方面有优势。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏关于有阅读障碍的软件工程师的体验研究，尤其是将他们的优势与困难联系起来的研究。本文旨在填补这一空白。

Method: 采用定性研究方法，基于10次对有阅读障碍的软件工程师的访谈、3篇博客文章和153篇Reddit帖子，遵循社会技术扎根理论的基本阶段进行分析。

Result: 研究发现，有阅读障碍的软件工程师在学习编程阶段尤其困难，但掌握后能在许多软件工程任务中表现出色。支持工具能有效缓解困难，他们在视觉思维和创造力方面具有优势。

Conclusion: 研究发现，尽管有阅读障碍的软件工程师在学习编程阶段面临挑战，但他们一旦掌握这一步骤，可以在许多软件工程任务中表现出色。常用的支持工具（如代码补全和linters）对他们特别有帮助，并能缓解许多困难。此外，他们在视觉思维和创造力方面表现出优势。

Abstract: Dyslexia is a common learning disorder that primarily impairs an individual's
reading and writing abilities. In adults, dyslexia can affect both professional
and personal lives, often leading to mental challenges and difficulties
acquiring and keeping work. In Software Engineering (SE), reading and writing
difficulties appear to pose substantial challenges for core tasks such as
programming. However, initial studies indicate that these challenges may not
significantly affect their performance compared to non-dyslexic colleagues.
Conversely, strengths associated with dyslexia could be particularly valuable
in areas like programming and design. However, there is currently no work that
explores the experiences of dyslexic software engineers, and puts their
strengths into relation with their difficulties. To address this, we present a
qualitative study of the experiences of dyslexic individuals in SE. We followed
the basic stage of the Socio-Technical Grounded Theory method and base our
findings on data collected through 10 interviews with dyslexic software
engineers, 3 blog posts and 153 posts on the social media platform Reddit. We
find that dyslexic software engineers especially struggle at the programming
learning stage, but can succeed and indeed excel at many SE tasks once they
master this step. Common SE-specific support tools, such as code completion and
linters are especially useful to these individuals and mitigate many of the
experienced difficulties. Finally, dyslexic software engineers exhibit
strengths in areas such as visual thinking and creativity. Our findings have
implications to SE practice and motivate several areas of future research in
SE, such as investigating what makes code less/more understandable to dyslexic
individuals.

</details>


### [291] [A Systematic Literature Review of Code Hallucinations in LLMs: Characterization, Mitigation Methods, Challenges, and Future Directions for Reliable AI](https://arxiv.org/abs/2511.00776)
*Cuiyun Gao,Guodong Fan,Chun Yong Chong,Shizhan Chen,Chao Liu,David Lo,Zibin Zheng,Qing Liao*

Main category: cs.SE

TL;DR: 本文综述了代码导向型大型语言模型中的幻觉现象，从定义、原因、缓解策略到代码特定挑战和评估方法，强调了针对性评估基准的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在软件工程任务中的集成日益增加，理解和缓解代码中的幻觉现象变得至关重要。

Method: 通过调查60篇论文，定义了代码中的幻觉现象，总结了其主要原因，并回顾了广泛的幻觉调查和缓解策略，特别关注了代码智能任务中的挑战。

Result: 本文提供了对代码导向型LLMs中幻觉现象的系统性综述，包括其定义、原因、缓解策略以及特定于代码的挑战和评估方法。

Conclusion: 本文系统性地回顾了代码导向型大型语言模型中的幻觉现象，并从四个关键角度总结了主要原因和缓解策略，强调了针对幻觉评估基准的必要性。

Abstract: Model hallucination is one of the most critical challenges faced by Large
Language Models (LLMs), especially in high-stakes code intelligence tasks. As
LLMs become increasingly integrated into software engineering tasks,
understanding and mitigating hallucination in code becomes essential. In this
survey, we provide a systematic review of hallucination phenomena in
code-oriented LLMs from four key perspectives. First, we begin by surveying 60
papers to define hallucination in the context of code and summarize its primary
causes, such as data noise, exposure bias, and insufficient semantic grounding,
while also tracing recent trends in literature across natural language
processing (NLP) and software engineering communities. Second, we review model
hallucination surveys in a broader span and summarize representative
hallucination mitigation strategies, such as knowledge-enhanced generation,
constrained decoding, and post-editing. Third, we review approaches targeted
for code intelligence and highlight code-specific challenges that aggravate
hallucination, including syntax sensitivity, strict type systems, and
dependence on external libraries. Meanwhile, we analyze how emerging code
intelligence tasks, e.g., program analysis, symbolic execution, and unit
testing, are utilized to detect and mitigate hallucinations. Fourth, we
summarize current evaluation benchmarks, ranging from static metrics to dynamic
checks, e.g., compilation and execution correctness, and emphasize the need for
hallucination-oriented benchmarks.

</details>


### [292] [Can Language Models Go Beyond Coding? Assessing the Capability of Language Models to Build Real-World Systems](https://arxiv.org/abs/2511.00780)
*Chenyu Zhao,Shenglin Zhang,Zeshun Huang,Weilin Jin,Yongqian Sun,Dan Pei,Chaoyun Zhang,Qingwei Lin,Chetan Bansal,Saravan Rajmohan,Minghua Ma*

Main category: cs.SE

TL;DR: Build-bench是一个评估LLMs在跨ISA构建修复中的能力的端到端基准，揭示当前模型的最大成功率为63%。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏评估LLMs在跨指令集架构（ISA）迁移中修复软件能力的基准，Build-bench旨在填补这一空白。

Method: Build-bench 通过集成辅助工具（如结构提取、文件内容提取、内容修改和构建验证）支持自主的、工具增强的推理，采用迭代循环修复流程。

Result: 评估显示，当前模型在跨ISA设置中的最大构建成功率为63%，且工具使用模式在不同模型间差异显著。

Conclusion: Build-bench 是第一个架构感知的基准测试，用于研究基于LLM的软件构建与修复，展示了当前模型在跨ISA构建修复中的潜力与局限。

Abstract: Large language models (LLMs) have shown growing potential in software
engineering, yet few benchmarks evaluate their ability to repair software
during migration across instruction set architectures (ISAs). Cross-ISA
migration, such as between x86_64 and aarch64, requires handling complex
dependencies, heterogeneous toolchains, and long build logs while ensuring
executable verification. To address this challenge, we present Build-bench, an
end-to-end benchmark that systematically evaluates the capability of LLMs to
repair build failures in cross-ISA settings. Build-bench collects 268
real-world failed packages and integrates auxiliary tools including Structure
Extraction, File Content Extraction, Content Modification, and Build
Verification to support autonomous, tool-augmented reasoning. The repair
process operates in an iterative loop where, upon failure, the model receives
updated build logs and previous repair outcomes to refine subsequent attempts.
Through a comparative evaluation of six representative LLMs, Build-bench
reveals that current models achieve a maximum build success rate of 63% and
tool usage patterns differ significantly across models. By coupling real build
environments with verifiable outcomes, Build-bench establishes the first
architecture-aware benchmark for studying LLM-based software build and repair.

</details>


### [293] [GrowthHacker: Automated Off-Policy Evaluation Optimization Using Code-Modifying LLM Agents](https://arxiv.org/abs/2511.00802)
*Jie JW Wu,Ayanda Patrick Herlihy,Ahmad Saleem Mirza,Ali Afoud,Fatemeh Fard*

Main category: cs.SE

TL;DR: 研究探讨了LLM和基于LLM的代理是否可以通过代码优化提升OPE性能，提出GrowthHacker基准和two_agent框架，结果显示其显著提高了OPE系统的效率和可靠性。


<details>
  <summary>Details</summary>
Motivation: 在线A/B测试资源消耗大、可能对用户产生负面影响且数据收集周期长。OPE（离线A/B测试）利用日志数据评估技术，在在线测试成本高或风险大的领域至关重要。

Method: 提出了GrowthHacker基准测试，包括代理和基线方法，通过迭代优化代码、评估结果并开始新的优化周期。开发了two_agent框架，降低了系统复杂性同时保持了优化效果。

Result: two_agent框架实现了100%的可靠性，在正向结果中平均改进高达106.7%。two_agent和CrewAI的成功率为45%，优于AutoGen的34%。

Conclusion: 研究表明，基于LLM的代理可以作为自动化的'增长黑客'来优化OPE系统，这对于在生产环境中扩展数据驱动决策具有重要意义。

Abstract: With the software industry shifting toward a data-driven culture, online A/B
testing is a key tool for evaluating new technologies. However, deploying such
experiments requires substantial resources, may negatively impact users, and
involves long data collection periods. To address this, \textit{off-policy
evaluation (OPE)}, or offline A/B testing, uses logged data to assess
technologies and is fundamental in Reinforcement Learning, making it crucial in
domains where online testing is costly or risky, such as healthcare,
recommender systems, education, dialog systems, and robotics. Despite advances
in coding LLMs and agentic AI, little is known about leveraging them to
optimize OPE results. We investigate whether LLMs and LLM-based agents can
improve OPE performance via code optimization. We propose
\textit{GrowthHacker}, a benchmark with agent and baseline methods on
large-scale real-world datasets, which iteratively optimizes code, evaluates
results, and begins new optimization cycles. We collected datasets, established
protocols, implemented baselines for OPE on the Open Bandit Pipeline
(OBP)~\cite{saito2021openbanditdatasetpipeline} and
Scope-RL~\cite{kiyohara2023scope}, and developed the \textit{two_agent}
framework, which reduces system complexity while preserving optimization
effectiveness. Results show the two_agent framework achieves 100% reliability
and the highest average improvement of 106.7% among positive outcomes. Both
two_agent and CrewAI reach 45% success rates, outperforming AutoGen's 34%.
These findings demonstrate the feasibility of LLM-based agents as automated
"growth hackers" to enhance OPE systems, with implications for scaling
data-driven decision-making in production.

</details>


### [294] [CodeClash: Benchmarking Goal-Oriented Software Engineering](https://arxiv.org/abs/2511.00839)
*John Yang,Kilian Lieret,Joyce Yang,Carlos E. Jimenez,Ofir Press,Ludwig Schmidt,Diyi Yang*

Main category: cs.SE

TL;DR: CodeClash是一个新基准，通过多轮锦标赛评估语言模型在开放目标下的代码开发能力。结果显示模型在战略推理和长期维护方面存在局限，且无法击败人类专家。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估模型在具体、明确任务上的表现，而真实软件开发往往涉及开放目标。CodeClash旨在填补这一空白，评估模型在无明确指导下的迭代开发能力。

Method: 引入CodeClash基准，通过多轮锦标赛评估语言模型在开放目标下的代码开发能力。每轮比赛分为编辑代码和代码竞技场两阶段，模型需自主决定如何改进代码库。

Result: 通过1680场锦标赛（总计25,200轮）评估8种语言模型在6种竞技场中的表现，发现模型在战略推理和代码维护方面存在局限性，且在对抗人类专家时全败。

Conclusion: 当前的语言模型在战略推理和长期代码维护方面存在根本性限制，顶级模型在与人类专家的对抗中表现不佳。CodeClash的开源旨在推动自主、目标导向的代码开发研究。

Abstract: Current benchmarks for coding evaluate language models (LMs) on concrete,
well-specified tasks such as fixing specific bugs or writing targeted tests.
However, human programmers do not spend all day incessantly addressing isolated
tasks. Instead, real-world software development is grounded in the pursuit of
high-level goals, like improving user retention or reducing costs. Evaluating
whether LMs can also iteratively develop code to better accomplish open-ended
objectives without any explicit guidance remains an open challenge. To address
this, we introduce CodeClash, a benchmark where LMs compete in multi-round
tournaments to build the best codebase for achieving a competitive objective.
Each round proceeds in two phases: agents edit their code, then their codebases
compete head-to-head in a code arena that determines winners based on
objectives like score maximization, resource acquisition, or survival. Whether
it's writing notes, scrutinizing documentation, analyzing competition logs, or
creating test suites, models must decide for themselves how to improve their
codebases both absolutely and against their opponents. We run 1680 tournaments
(25,200 rounds total) to evaluate 8 LMs across 6 arenas. Our results reveal
that while models exhibit diverse development styles, they share fundamental
limitations in strategic reasoning. Models also struggle with long-term
codebase maintenance, as repositories become progressively messy and redundant.
These limitations are stark: top models lose every round against expert human
programmers. We open-source CodeClash to advance the study of autonomous,
goal-oriented code development.

</details>


### [295] [A Comprehensive Empirical Evaluation of Agent Frameworks on Code-centric Software Engineering Tasks](https://arxiv.org/abs/2511.00872)
*Zhuowen Yin,Cuifeng Gao,Chunsong Fan,Wenzhang Yang,Yinxing Xue,Lijun Zhang*

Main category: cs.SE

TL;DR: 该论文通过评估七种通用代理框架在软件工程任务中的表现，揭示了它们在效率、开销和能力上的差异，为未来研究和应用提供了参考。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注特定任务或孤立方面，未能全面展示代理的实际能力，因此需要进行更全面的评估。

Method: 通过全面的实证研究，评估了七种通用代理框架在三个代表性代码中心任务中的表现，使用标准基准进行客观和可比较的评估。

Result: 代理在整体性能上表现中等，不同框架在效率、开销等方面展现出显著差异，例如AgentOrchestra的协调开销较大，而OpenHands展示出更强的反思推理能力。

Conclusion: 研究结果揭示了不同代理框架在能力模式和权衡方面的差异，为实际应用和未来研究提供了指导，以实现更高效的软件工程代理。

Abstract: Unlike traditional automation tools or static LLM-based systems, agents
combine decision-making and tool utilization to accomplish complex tasks,
showing great potential in software engineering. However, existing studies
largely focus on specific tasks or isolated aspects, providing an incomplete
picture of agents' practical capabilities. To address this, we conduct a
comprehensive empirical study evaluating seven general-purpose agent frameworks
across three representative code-centric tasks: software development,
vulnerability detection, and program repair. Each task is assessed using
standard, widely adopted benchmarks to ensure objective and comparable
evaluation. Agent performance is systematically analyzed from three
complementary perspectives: effectiveness (task success), efficiency (execution
process), and overhead (token consumption). Our findings reveal distinct
capability patterns and trade-offs among the evaluated frameworks. In terms of
effectiveness, agents achieve moderate overall performance. Regarding
efficiency, AgentOrchestra tends to exhibit the longest trajectories and the
most correction attempts due to coordination overhead, whereas OpenHands
demonstrate stronger reflective reasoning abilities. For overhead, software
development incurs the highest monetary cost, while GPTswarm remains the most
cost-efficient. Furthermore, we conduct an in-depth cross-analysis of the
relationship between effectiveness and efficiency, exploring the underlying
reasons behind their interplay. These findings guide both practical adoption
and future research toward more efficient software engineering agents.

</details>


### [296] [Sustainability of Machine Learning-Enabled Systems: The Machine Learning Practitioner's Perspective](https://arxiv.org/abs/2511.00901)
*Vincenzo De Martino,Stefano Lambiase,Fabiano Pecorelli,Willem-Jan van den Heuvel,Filomena Ferrucci,Fabio Palomba*

Main category: cs.SE

TL;DR: 论文探讨了机器学习（ML）系统中软件可持续性的实践挑战，揭示了意识与实施之间的脱节，并呼吁更多结构化指南和监管支持。


<details>
  <summary>Details</summary>
Motivation: 软件可持续性是ML系统的关键非功能性需求，但现有研究多聚焦环境可持续性，缺乏对实践中多维度可持续性管理的研究。

Method: 通过定性分析（访谈8位ML工程师）和定量调查（203位ML从业者），研究可持续性的认知、实践及挑战。

Result: 发现可持续性意识与系统性实施存在显著脱节，需更多结构化指南、测量框架和监管支持。

Conclusion: 研究填补了ML系统可持续性实践的空缺，强调了改进指南和监管的必要性。

Abstract: Software sustainability is a key multifaceted non-functional requirement that
encompasses environmental, social, and economic concerns, yet its integration
into the development of Machine Learning (ML)-enabled systems remains an open
challenge. While previous research has explored high-level sustainability
principles and policy recommendations, limited empirical evidence exists on how
sustainability is practically managed in ML workflows. Existing studies
predominantly focus on environmental sustainability, e.g., carbon footprint
reduction, while missing the broader spectrum of sustainability dimensions and
the challenges practitioners face in real-world settings. To address this gap,
we conduct an empirical study to characterize sustainability in ML-enabled
systems from a practitioner's perspective. We investigate (1) how ML engineers
perceive and describe sustainability, (2) the software engineering practices
they adopt to support it, and (3) the key challenges hindering its adoption. We
first perform a qualitative analysis based on interviews with eight experienced
ML engineers, followed by a large-scale quantitative survey with 203 ML
practitioners. Our key findings reveal a significant disconnection between
sustainability awareness and its systematic implementation, highlighting the
need for more structured guidelines, measurement frameworks, and regulatory
support.

</details>


### [297] [Empirical Derivations from an Evolving Test Suite](https://arxiv.org/abs/2511.00915)
*Jukka Ruohonen,Abhishek Tiwari*

Main category: cs.SE

TL;DR: 论文分析了NetBSD操作系统测试套件的长期表现，发现其稳定增长且失败率总体稳定，但短期波动存在，且代码变更对失败的解释力有限。


<details>
  <summary>Details</summary>
Motivation: 研究大规模和长期演变的软件测试套件的表现及其失败模式，以了解其稳定性和可靠性。

Method: 对NetBSD操作系统的自动化、持续和基于虚拟化的软件测试套件进行了纵向实证分析，观察时间从2010年代初测试套件的初始推出到2025年底。

Result: 测试套件持续增长，覆盖超过一万个独立测试案例。失败案例总体上稳定，但存在短期频繁失败现象。代码变更和内核修改对失败的解释力在长期内不一致，平均效果较小。

Conclusion: 尽管仅以探索性方式呈现，这些实证观察为从大规模和不断演变的软件测试套件中得出结论提供了贡献。

Abstract: The paper presents a longitudinal empirical analysis of the automated,
continuous, and virtualization-based software test suite of the NetBSD
operating system. The longitudinal period observed spans from the initial roll
out of the test suite in the early 2010s to late 2025. According to the
results, the test suite has grown continuously, currently covering over ten
thousand individual test cases. Failed test cases exhibit overall stability,
although there have been shorter periods marked with more frequent failures. A
similar observation applies to build failures, failures of the test suite to
complete, and installation failures, all of which are also captured by the
NetBSD's testing framework. Finally, code churn and kernel modifications do not
provide longitudinally consistent statistical explanations for the failures.
Although some periods exhibit larger effects, including particularly with
respect to the kernel modifications, the effects are small on average. Even
though only in an exploratory manner, these empirical observations contribute
to efforts to draw conclusions from large-scale and evolving software test
suites.

</details>


### [298] [DPO-F+: Aligning Code Repair Feedback with Developers' Preferences](https://arxiv.org/abs/2511.01043)
*Zihan Fang,Yifan Zhang,Yueke Zhang,Kevin Leach,Yu Huang*

Main category: cs.SE

TL;DR: DPO-f+通过开发者画像和偏好优化，提升了LLM代码修复的反馈质量，显著提高任务通过率和人机协作效率。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注修复代码的优化，而忽视了开发者理解模型输出所需的自然语言反馈，限制了人机协作效果。

Method: DPO-f+框架包含：(1) 基于开发者画像的领域特定指标；(2) 自动构建代码修复任务的成对偏好数据集；(3) 结合轻量级边界信号的直接偏好优化（DPO）微调；(4) 自动化反馈评估协议。

Result: 在初学者编程任务中，DPO-f+的Top-1通过率比基线提升5.71个百分点（pp），比标准DPO提升3.30 pp；在更复杂的SWE-bench Lite基准测试中，问题解决率分别提升1.67 pp和4.67 pp。同时，反馈对齐效果显著优于基线。

Conclusion: DPO-f+通过更贴近开发者需求的反馈对齐，将LLM辅助的代码修复从一次性输出转变为协作式理解流程，提升了代码理解效率和人机协作效果。

Abstract: Large Language Models (LLMs) are increasingly applied to software engineering
tasks, especially code repair. However, developers often struggle to interpret
model outputs, limiting effective human-AI teaming. Prior work largely
optimizes repaired code while under-addressing the natural-language feedback
that enables comprehension and iterative improvement. We present DPO-f+, a
novel framework that aligns code-repair feedback with developer needs and
profiles. It (1) formalizes developer-profiled, domain-specific metrics for
feedback alignment; (2) automatically constructs pairwise preference datasets
from code-repair tasks; (3) fine-tunes using Direct Preference Optimization
(DPO) augmented with a lightweight margin signal; and (4) provides an automated
feedback evaluation protocol. Empirically, DPO-f+ outperforms both the baseline
and standard DPO on generated-code accuracy and overall feedback alignment. On
novice programming tasks, DPO-f+ raises the top-1 pass rate by 5.71 percentage
points (pp) over the baseline and by 3.30 pp over DPO. On the more challenging
SWE-bench Lite benchmark, it increases the issue-resolution rate by 1.67 pp
over DPO and by 4.67 pp over the baseline. It also achieves the largest
improvement in feedback alignment, outperforming DPO and the baseline. By
aligning feedback more closely with developer needs, DPO-f+ turns LLM-assisted
repair from one-shot outputs into a collaborative sensemaking workflow,
providing a practical approach to enhancing code comprehension and fostering
more effective human-AI teaming in software engineering.

</details>


### [299] [HAFixAgent: History-Aware Automated Program Repair Agent](https://arxiv.org/abs/2511.01047)
*Yu Shi,Hao Li,Bram Adams,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: HAFixAgent 通过利用存储库历史提升代理式自动程序修复，显著提高了修复效果和效率，尤其适用于复杂多块 bug。


<details>
  <summary>Details</summary>
Motivation: 研究表明，存储库历史有助于修复单行 bug，因为最后一次触及 buggy 行的提交通常是引入 bug 的提交。本文探究存储库历史是否也能大规模提升代理式自动程序修复系统，尤其是针对复杂的多块 bug。

Method: HAFixAgent 是一种历史感知的 bug 修复代理，将 blame 衍生的存储库启发式方法注入修复循环。

Result: HAFixAgent 显著优于基于代理的基线（提高 212.3%）和多块基线（提高 29.9%），且历史并未显著增加代理步骤，保持了可比较的令牌成本，对复杂的多文件多块 bug 的中位数成本更低。

Conclusion: HAFixAgent 提供了一种实用的历史感知代理式自动程序修复方法：将代理基于版本控制历史，优先考虑基于差异的历史上下文，并在需要时整合互补启发式方法。

Abstract: Automated program repair (APR) has recently shifted toward large language
models and agent-based systems, yet most systems rely on local snapshot
context, overlooking repository history. Prior work shows that repository
history helps repair single-line bugs, since the last commit touching the buggy
line is often the bug-introducing one. In this paper, we investigate whether
repository history can also improve agentic APR systems at scale, especially
for complex multi-hunk bugs. We present HAFixAgent, a History-Aware Bug-Fixing
Agent that injects blame-derived repository heuristics into its repair loop. A
preliminary study of all 854 real-world bugs from Defects4J motivates our
design, showing that bug-relevant history is both widely available and highly
concentrated. Empirical comparison of HAFixAgent with two state-of-the-art
baselines shows: (1) Effectiveness: HAFixAgent significantly improves over the
agent-based baseline (by 212.3%) and the multi-hunk baseline (by 29.9%). (2)
Efficiency: history does not significantly increase agent steps and keeps token
costs comparable, with notably lower median costs for complex
multi-file-multi-hunk bugs. (3) Practicality: combining different historical
heuristics repairs more bugs, offering a clear cost-benefit trade-off.
HAFixAgent offers a practical recipe for history-aware agentic APR: ground the
agent in version control history, prioritize diff-based historical context, and
integrate complementary heuristics when needed.

</details>


### [300] [HarnessLLM: Automatic Testing Harness Generation via Reinforcement Learning](https://arxiv.org/abs/2511.01104)
*Yujian Liu,Jiabao Ji,Yang Zhang,Wenbo Guo,Tommi Jaakkola,Shiyu Chang*

Main category: cs.SE

TL;DR: HarnessLLM通过两阶段训练生成测试代码，提升测试多样性和调试能力，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的自动测试生成方法生成的测试多样性不足且缺乏调试信息，无法满足复杂测试需求。

Method: 采用两阶段训练流程：SFT（监督微调）和RLVR（带有定制奖励的强化学习验证），生成能够合成输入并验证输出的测试代码。

Result: HarnessLLM在bug发现和测试策略多样性上优于输入-输出对测试方法，并能通过测试时代码生成提升性能。

Conclusion: HarnessLLM通过两阶段训练流程（SFT和RLVR）显著提升了测试生成的多样性和调试能力，并在bug发现和测试策略多样性上优于现有方法。

Abstract: Existing LLM-based automatic test generation methods mainly produce input and
expected output pairs to categorize the intended behavior of correct programs.
Although straightforward, these methods have limited diversity in generated
tests and cannot provide enough debugging information. We propose HarnessLLM, a
two-stage training pipeline that enables LLMs to write harness code for
testing. Particularly, LLMs generate code that synthesizes inputs and validates
the observed outputs, allowing complex test cases and flexible output
validation such as invariant checking. To achieve this, we train LLMs with SFT
followed by RLVR with a customized reward design. Experiments show that
HarnessLLM outperforms input-output-based testing in bug finding and testing
strategy diversity. HarnessLLM further benefits the code generation performance
through test-time scaling with our generated test cases as inference-phase
validation. Our code is available at
https://github.com/UCSB-NLP-Chang/HarnessLLM.git.

</details>


### [301] [An Empirical Study of LLM-Based Code Clone Detection](https://arxiv.org/abs/2511.01176)
*Wenqing Zhu,Norihiro Yoshida,Eunjong Choi,Yutaka Matsubara,Hiroaki Takada*

Main category: cs.SE

TL;DR: LLMs在代码克隆检测中表现优异但数据集间差异大，响应一致性高。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在不同数据集上性能的差异性和响应一致性的问题。

Method: 构建了七个代码克隆数据集，评估了五种LLMs在四种现有提示下的表现。数据集通过从CodeNet和BigCloneBench中采样代码对并计算其Levenshtein比率来创建。

Result: LLMs在CodeNet相关数据集上表现优异（如o3-mini达到0.943 F1分数），但在BigCloneBench相关数据集上表现显著下降。模型响应一致性高，超过90%的判断在所有五次提交中保持一致。F1分数的波动很小，变化小于0.03。

Conclusion: LLMs在代码克隆检测中表现良好，但性能在不同数据集间存在显著差异，尤其在CodeNet相关数据集上表现优异，而在BigCloneBench相关数据集上表现下降。然而，模型响应的一致性较高。

Abstract: Large language models (LLMs) have demonstrated remarkable capabilities in
various software engineering tasks, such as code generation and debugging,
because of their ability to translate between programming languages and natural
languages. Existing studies have demonstrated the effectiveness of LLMs in code
clone detection. However, two crucial issues remain unaddressed: the ability of
LLMs to achieve comparable performance across different datasets and the
consistency of LLMs' responses in code clone detection. To address these
issues, we constructed seven code clone datasets and then evaluated five LLMs
in four existing prompts with these datasets. The datasets were created by
sampling code pairs using their Levenshtein ratio from two different code
collections, CodeNet and BigCloneBench. Our evaluation revealed that although
LLMs perform well in CodeNet-related datasets, with o3-mini achieving a 0.943
F1 score, their performance significantly decreased in BigCloneBench-related
datasets. Most models achieved a high response consistency, with over 90\% of
judgments remaining consistent across all five submissions. The fluctuations of
the F1 score affected by inconsistency are also tiny; their variations are less
than 0.03.

</details>


### [302] [Lares: LLM-driven Code Slice Semantic Search for Patch Presence Testing](https://arxiv.org/abs/2511.01252)
*Siyuan Li,Yaowen Zheng,Hong Li,Jingdong Guo,Chaopeng Dong,Chunpeng Yan,Weijie Wang,Yimo Ren,Limin Sun,Hongsong Zhu*

Main category: cs.SE

TL;DR: Lares是一种新型补丁存在测试方法，通过直接分析源代码和利用LLMs提升准确性，实验显示其在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在可用性和准确性上存在不足，依赖编译过程且无法可靠区分补丁或编译变化导致的代码更改。

Method: Lares引入了代码片段语义搜索（Code Slice Semantic Search），直接从补丁源代码提取特征，并结合大型语言模型（LLMs）进行代码分析及SMT求解器进行逻辑推理。

Result: 实验结果表明，Lares在精确度、召回率和可用性上表现优异，并首次评估了跨优化级别、架构和编译器的补丁存在测试。

Conclusion: Lares提出了一种可扩展且准确的方法用于补丁存在测试，通过直接提取补丁源代码特征并在目标二进制文件的伪代码中识别语义等效的代码片段，显著提高了可用性和准确性。

Abstract: In modern software ecosystems, 1-day vulnerabilities pose significant
security risks due to extensive code reuse. Identifying vulnerable functions in
target binaries alone is insufficient; it is also crucial to determine whether
these functions have been patched. Existing methods, however, suffer from
limited usability and accuracy. They often depend on the compilation process to
extract features, requiring substantial manual effort and failing for certain
software. Moreover, they cannot reliably differentiate between code changes
caused by patches or compilation variations. To overcome these limitations, we
propose Lares, a scalable and accurate method for patch presence testing. Lares
introduces Code Slice Semantic Search, which directly extracts features from
the patch source code and identifies semantically equivalent code slices in the
pseudocode of the target binary. By eliminating the need for the compilation
process, Lares improves usability, while leveraging large language models
(LLMs) for code analysis and SMT solvers for logical reasoning to enhance
accuracy. Experimental results show that Lares achieves superior precision,
recall, and usability. Furthermore, it is the first work to evaluate patch
presence testing across optimization levels, architectures, and compilers. The
datasets and source code used in this article are available at
https://github.com/Siyuan-Li201/Lares.

</details>


### [303] [Exploringand Unleashing the Power of Large Language Models in CI/CD Configuration Translation](https://arxiv.org/abs/2511.01316)
*Chong Wang,Chen Zhang,Jiajun Wu,Wunan Guo,Jianfeng Qu,Yewen Tian,Yang Liu*

Main category: cs.SE

TL;DR: 研究利用LLM进行Travis CI到GitHub Actions的配置翻译，发现开发者工作量较大且问题多，结合指南提示与迭代优化的策略效果最佳。


<details>
  <summary>Details</summary>
Motivation: CI平台的差异使得迁移成为常见实践，但CI配置的复杂性和语义差异使翻译具有挑战性，利用LLM的潜力进行CI配置翻译成为研究焦点。

Method: 基于811个迁移记录，量化了开发者在Travis CI到GitHub Actions迁移中的工作量，分析了四种LLM生成的翻译问题，并评估了三种增强策略。

Result: 开发者平均阅读38行Travis配置并编写58行GitHub Actions配置，近半数迁移需要多次提交。四种LLM的翻译中发现了1121个问题，分为逻辑不一致（38%）、平台差异（32%）、环境错误（25%）和语法错误（5%）。最佳策略将构建成功率提升至75.5%。

Conclusion: 结合基于指南的提示与迭代优化的策略在CI配置翻译中表现最佳，将构建成功率提升至75.5%，相比基本提示的GPT-4o有近三倍的改进。

Abstract: Continuous Integration (CI) is a cornerstone of modern collaborative software
development, and numerous CI platforms are available. Differences in
maintenance overhead, reliability, and integration depth with code-hosting
platforms make migration between CI platforms a common practice. A central step
in migration is translating CI configurations, which is challenging due to the
intrinsic complexity of CI configurations and the need to understand semantic
differences and relationships across CI platforms.
  With the advent of large language models (LLMs), recent advances in software
engineering highlight their potential for CI configuration translation. In this
paper, we present a study on LLM-based CI configuration translation, focusing
on the migration from Travis CI to GitHub Actions. First, using 811 migration
records, we quantify the effort involved and find that developers read an
average of 38 lines of Travis configuration and write 58 lines of GitHub
Actions configuration, with nearly half of the migrations requiring multiple
commits. We further analyze translations produced by each of the four LLMs and
identify 1,121 issues grouped into four categories: logic inconsistencies
(38%), platform discrepancies (32%), environment errors (25%), and syntax
errors (5%). Finally, we evaluate three enhancement strategies and show that
combining guideline-based prompting with iterative refinement achieves the best
performance, reaching a Build Success Rate of 75.5%-nearly a threefold
improvement over GPT-4o with a basic prompt.

</details>


### [304] [AI for Requirements Engineering: Industry adoption and Practitioner perspectives](https://arxiv.org/abs/2511.01324)
*Lekshmi Murali Rani,Richard Berntsson Svensson,Robert Feldt*

Main category: cs.SE

TL;DR: 调查显示，AI在需求工程中主要作为协作伙伴使用，人机协作（HAIC）最普遍，全自动化应用较少。从业者更看重AI的主动支持而非被动验证。


<details>
  <summary>Details</summary>
Motivation: 尽管RE是软件工程的基础，但关于AI在RE中应用的有限研究促使我们探索AI在RE中的实际使用情况、挑战和机遇。

Method: 调查了55名软件从业者，映射了AI在RE四个阶段（需求获取、分析、规格说明和验证）和四种决策方法（纯人工决策、AI验证、人机协作HAIC、全AI自动化）中的使用情况。

Result: 58.2%的受访者已在RE中使用AI，69.1%对其影响持积极或非常积极态度。HAIC在实践中最常见（54.4%），全AI自动化（5.4%）和被动AI验证（4.4%-6.2%）较少。

Conclusion: AI在需求工程（RE）中最有效的定位是作为人类专家的协作伙伴，而非替代品。研究强调了开发RE特定的HAIC框架以及稳健、负责任的AI治理的必要性。

Abstract: The integration of AI for Requirements Engineering (RE) presents significant
benefits but also poses real challenges.Although RE is fundamental to software
engineering, limited research has examined AI adoption in RE.We surveyed 55
software practitioners to map AI usage across four RE phases:Elicitation,
Analysis, Specification, and Validation, and four approaches for decision
making: human only decisions, AI validation, Human AI Collaboration (HAIC), and
full AI automation.Participants also shared their perceptions, challenges, and
opportunities when applying AI for RE tasks.Our data show that 58.2% of
respondents already use AI in RE, and 69.1% view its impact as positive or very
positive.HAIC dominates practice, accounting for 54.4% of all RE techniques,
while full AI automation remains minimal at 5.4%.Passive AI validation (4.4 to
6.2%) lags even further behind, indicating that practitioners value AI's active
support over passive oversight.These findings suggest that AI is most effective
when positioned as a collaborative partner rather than a replacement for human
expertise.It also highlights the need for RE specific HAIC frameworks along
with robust and responsible AI governance as AI adoption in RE grows.

</details>


### [305] [The Future of Generative AI in Software Engineering: A Vision from Industry and Academia in the European GENIUS Project](https://arxiv.org/abs/2511.01348)
*Robin Gröpler,Steffen Klepke,Jack Johns,Andreas Dreschinski,Klaus Schmid,Benedikt Dornauer,Eray Tüzün,Joost Noppen,Mohammad Reza Mousavi,Yongjian Tang,Johannes Viehmann,Selin Şirin Aslangül,Beum Seuk Lee,Adam Ziolkowski,Eric Zie*

Main category: cs.SE

TL;DR: 论文探讨了GenAI在软件工程中的应用潜力，提出了未来五年的技术和方法进展，以及软件专业人员角色变化，旨在通过GENIUS项目实现这一转型。


<details>
  <summary>Details</summary>
Motivation: 探索GenAI在整个软件开发生命周期中的应用潜力，解决可靠性、责任性、安全性和数据隐私等关键问题。

Method: 通过跨部门对话和GENIUS联盟内的经验，结合探索性文献综述，提出了GenAI在软件工程中的未来愿景。

Result: 提出了GenAI在软件工程中的四个核心要素：当前挑战、未来愿景、角色转变和GENIUS项目的贡献。

Conclusion: 该论文旨在为研究和工业策略提供信息，为软件工程团队提供可靠、可扩展且适用于行业的GenAI解决方案。

Abstract: Generative AI (GenAI) has recently emerged as a groundbreaking force in
Software Engineering, capable of generating code, suggesting fixes, and
supporting quality assurance. While its use in coding tasks shows considerable
promise, applying GenAI across the entire Software Development Life Cycle
(SDLC) has not yet been fully explored. Critical uncertainties in areas such as
reliability, accountability, security, and data privacy demand deeper
investigation and coordinated action. The GENIUS project, comprising over 30
European industrial and academic partners, aims to address these challenges by
advancing AI integration across all SDLC phases. It focuses on GenAI's
potential, the development of innovative tools, and emerging research
challenges, actively shaping the future of software engineering. This vision
paper presents a shared perspective on the future of GenAI-based software
engineering, grounded in cross-sector dialogue and experience within the GENIUS
consortium, supported by an exploratory literature review. The paper explores
four central elements: (1) a structured overview of current challenges in GenAI
adoption across the SDLC; (2) a forward-looking vision outlining key
technological and methodological advances expected over the next five years;
(3) anticipated shifts in the roles and required skill sets of software
professionals; and (4) the contribution of GENIUS in realizing this
transformation through practical tools and industrial validation. By aligning
technical innovation with business relevance, this paper aims to inform both
research agendas and industrial strategies, providing a foundation for
reliable, scalable, and industry-ready GenAI solutions for software engineering
teams.

</details>


### [306] [Characterizing Build Compromises Through Vulnerability Disclosure Analysis](https://arxiv.org/abs/2511.01395)
*Maimouna Tamah Diao,Moustapha Awwalou Diouf,Iyiola Emmanuel Olatunji,Abdoul Kader Kaboré,Gervais Mendy,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.SE

TL;DR: 本文通过实证研究提出了构建攻击向量的分类法，揭示构建过程在供应链攻击中的重要性，并识别依赖混淆和构建脚本注入为主要攻击手段。


<details>
  <summary>Details</summary>
Motivation: 构建基础设施的安全面临独特挑战，包括多组件系统的复杂性、编译期间入侵检测的困难以及普遍存在的构建非确定性。这些风险使得构建过程成为软件供应链攻击的重要目标，但安全社区对此缺乏系统理解。

Method: 通过大规模CVE挖掘（从NVD数据库中提取621个漏洞披露）构建攻击向量分类法，并分析了168个记录的软件供应链攻击以验证分类法。

Result: 分析显示23.8%的供应链攻击利用了构建漏洞，其中依赖混淆和构建脚本注入是最常见的攻击向量。

Conclusion: 本文提出了一个基于实证研究的构建攻击向量分类法，揭示了构建过程中存在的安全漏洞，特别是在软件供应链攻击中的重要性。

Abstract: The software build process transforms source code into deployable artifacts,
representing a critical yet vulnerable stage in software development. Build
infrastructure security poses unique challenges: the complexity of
multi-component systems (source code, dependencies, build tools), the
difficulty of detecting intrusions during compilation, and prevalent build
non-determinism that masks malicious modifications. Despite these risks, the
security community lacks a systematic understanding of build-specific attack
vectors, hindering effective defense design.
  This paper presents an empirically-derived taxonomy of attack vectors
targeting the build process, constructed through a large-scale CVE mining (of
621 vulnerability disclosures from the NVD database). We categorize attack
vectors by their injection points across the build pipeline, from source code
manipulation to compiler compromise. To validate our taxonomy, we analyzed 168
documented software supply chain attacks, identifying 40 incidents specifically
targeting build phases. Our analysis reveals that 23.8\% of supply chain
attacks exploit build vulnerabilities, with dependency confusion and build
script injection representing the most prevalent vectors.
  Dataset available at:
https://anonymous.4open.science/r/Taxonomizing-Build-Attacks-8BB0.

</details>


### [307] [VeriODD: From YAML to SMT-LIB - Automating Verification of Operational Design Domains](https://arxiv.org/abs/2511.01417)
*Bassel Rafie,Christian Schindler,Andreas Rausch*

Main category: cs.SE

TL;DR: VeriODD工具自动化转换YAML描述的自动驾驶操作域（ODD/COD）为SMT-LIB，支持形式验证，填补了易用性与验证需求间的空白。


<details>
  <summary>Details</summary>
Motivation: 当前ODD/COD的YAML描述虽便于利益相关者理解，但不利于基于求解器的验证，手动转换为形式语言（如SMT-LIB）效率低且易出错。

Method: VeriODD利用ANTLR编译器技术将YAML描述的ODD/COD转换为可读命题逻辑和SMT-LIB格式，并集成Z3等SMT求解器进行一致性检查与符合性验证。

Result: VeriODD成功实现了ODD/COD描述的自动化转换与验证，提供图形界面支持编辑、公式检查及一键验证。

Conclusion: VeriODD通过自动化转换YAML描述的ODD/COD为SMT-LIB格式，填补了友好表达与形式验证间的鸿沟，推动了自动驾驶操作边界的可扩展与自动化安全保障。

Abstract: Operational Design Domains (ODDs) define the conditions under which an
Automated Driving System (ADS) is allowed to operate, while Current Operational
Domains (CODs) capture the actual runtime situation. Ensuring that a COD
instance lies within the ODD is a crucial step in safety assurance. Today, ODD
and COD specifications are frequently expressed in YAML to remain accessible
for stakeholders, but such descriptions are not directly suitable for
solver-based verification. Manual translation into formal languages such as
SMT-LIB is slow and error-prone. We present VeriODD, a tool that automates this
translation. VeriODD uses ANTLR-based compiler technology to transform
YAML-based ODD/COD specifications into both human-readable propositional logic,
for lightweight review on a simple basis, and solver-ready SMT-LIB. The tool
integrates with SMT solvers such as Z3 to provide automated consistency checks
of ODD specifications and verification of COD conformance. A graphical user
interface supports editing specifications, inspecting generated formulas, and
performing verification with a single click. VeriODD thereby closes the gap
between stakeholder-friendly ODD/COD notations and formal verification,
enabling scalable and automated assurance of operational boundaries in
autonomous driving. Video demonstration: https://youtu.be/odRacNoL_Pk Tool
available at: https://github.com/BasselRafie/VeriODD

</details>


### [308] [LLM-Assisted Tool for Joint Generation of Formulas and Functions in Rule-Based Verification of Map Transformations](https://arxiv.org/abs/2511.01423)
*Ruidi He,Yu Zhang,Meng Zhang,Andreas Rausch*

Main category: cs.SE

TL;DR: 论文提出了一种LLM辅助的地图转换验证方法，通过生成逻辑公式和可执行谓词，减少人工工作并保持正确性。


<details>
  <summary>Details</summary>
Motivation: 高精地图转换在自动驾驶系统中至关重要，但现有基于规则的框架依赖手动编写的公式和领域特定函数，限制了可扩展性。

Method: 论文提出了一种基于LLM的管道方法，利用提示生成语法合规的规则和谓词，直接集成到现有系统中。

Result: 在合成的桥梁和斜坡场景上评估的原型显示，该方法减少了人工工程工作量，同时保持了正确性。

Conclusion: 论文提出了一种LLM辅助的管道，通过联合生成逻辑公式和可执行谓词，扩展了CommonRoad场景设计器中的地图验证器，支持高程验证。这种方法减少了人工工程工作量，同时保持了正确性，展示了可扩展、半自动化的人机交互地图转换验证方法的可行性。

Abstract: High-definition map transformations are essential in autonomous driving
systems, enabling interoperability across tools. Ensuring their semantic
correctness is challenging, since existing rule-based frameworks rely on
manually written formulas and domain-specific functions, limiting scalability.
  In this paper, We present an LLM-assisted pipeline that jointly generates
logical formulas and corresponding executable predicates within a computational
FOL framework, extending the map verifier in CommonRoad scenario designer with
elevation support. The pipeline leverages prompt-based LLM generation to
produce grammar-compliant rules and predicates that integrate directly into the
existing system.
  We implemented a prototype and evaluated it on synthetic bridge and slope
scenarios. The results indicate reduced manual engineering effort while
preserving correctness, demonstrating the feasibility of a scalable,
semi-automated human-in-the-loop approach to map-transformation verification.

</details>


### [309] [Hidden in Plain Sight: Where Developers Confess Self-Admitted Technical Debt](https://arxiv.org/abs/2511.01529)
*Murali Sridharan,Mikel Robredo,Leevi Rantala,Matteo Esposito,Valentina Lenarduzzi,Mika Mantyla*

Main category: cs.SE

TL;DR: 研究通过分析大量SATD注释与代码的关联，发现SATD多出现在定义、条件语句和异常处理附近，表明其是开发者变更时的有意行为。


<details>
  <summary>Details</summary>
Motivation: 连接SATD注释与其周围的源代码结构，以理解SATD在代码中的具体表现。

Method: 利用包含9000多个Java开源软件仓库代码注释的PENTACET数据集，定量推断SATD最常见的位置及其影响的代码结构。

Result: 大规模研究将超过225,000条SATD注释与其周围代码关联起来，揭示了SATD的高发区域。

Conclusion: SATD主要出现在内联代码中，如定义、条件语句和异常处理附近，这表明SATD是开发者在变更过程中的有意信号，而非单纯的疏忽。

Abstract: Context. Detecting Self-Admitted Technical Debt (SATD) is crucial for
proactive software maintenance. Previous research has primarily targeted
detecting and prioritizing SATD, with little focus on the source code afflicted
with SATD. Our goal in this work is to connect the SATD comments with source
code constructs that surround them.
  Method. We leverage the extensive SATD dataset PENTACET, containing code
comments from over 9000 Java Open Source Software (OSS) repositories. We
quantitatively infer where SATD most commonly occurs and which code
constructs/statements it most frequently affects.
  Results and Conclusions. Our large-scale study links over 225,000 SATD
comments to their surrounding code, showing that SATD mainly arises in inline
code near definitions, conditionals, and exception handling, where developers
face uncertainty and trade-offs, revealing it as an intentional signal of
awareness during change rather than mere neglect.

</details>


### [310] [From Pre-labeling to Production: Engineering Lessons from a Machine Learning Pipeline in the Public Sector](https://arxiv.org/abs/2511.01545)
*Ronivaldo Ferreira,Guilherme da Silva,Carla Rocha,Gustavo Pinto*

Main category: cs.SE

TL;DR: 公共部门中机器学习的成功依赖于透明且可问责的数据基础设施，而非仅模型准确性。研究通过BP平台案例揭示了工程选择与数据治理之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习越来越多地被嵌入政府数字平台，公共部门的限制使得构建准确、可审计且操作可持续的ML系统变得困难。团队不仅面临极端类别不平衡和数据漂移等技术问题，还有官僚数据访问、缺乏版本化数据集以及对来源和监控的不完整治理等组织障碍。

Method: 研究分析了Brasil Participativo（BP）平台，探讨了常见的工程选择（如使用LLM进行预标记、将模型拆分为路由分类器和生成合成数据）对开发速度的影响，以及这些选择在缺乏严格数据治理和人工验证时带来的风险。

Result: 研究表明，公共部门中的负责任机器学习不仅是建模问题，更是机构工程问题。ML流水线必须被视为公民基础设施，其成功依赖于透明、可复现和可问责的数据基础设施。

Conclusion: 研究发现，公共部门中机器学习的成功不仅依赖于模型准确性的突破，更取决于机构能否构建透明、可复现且可问责的数据基础设施，以赢得公民信任。

Abstract: Machine learning is increasingly being embedded into government digital
platforms, but public-sector constraints make it difficult to build ML systems
that are accurate, auditable, and operationally sustainable. In practice, teams
face not only technical issues like extreme class imbalance and data drift, but
also organizational barriers such as bureaucratic data access, lack of
versioned datasets, and incomplete governance over provenance and monitoring.
Our study of the Brasil Participativo (BP) platform shows that common
engineering choices -- like using LLMs for pre-labeling, splitting models into
routed classifiers, and generating synthetic data -- can speed development but
also introduce new traceability, reliability, and cost risks if not paired with
disciplined data governance and human validation. This means that, in the
public sector, responsible ML is not just a modeling problem but an
institutional engineering problem, and ML pipelines must be treated as civic
infrastructure. Ultimately, this study shows that the success of machine
learning in the public sector will depend less on breakthroughs in model
accuracy and more on the ability of institutions to engineer transparent,
reproducible, and accountable data infrastructures that citizens can trust.

</details>


### [311] [Towards LLM-Powered Task-Aware Retrieval of Scientific Workflows for Galaxy](https://arxiv.org/abs/2511.01757)
*Shamse Tasnim Cynthia,Banani Roy*

Main category: cs.SE

TL;DR: Galaxy的工作流检索系统因语义支持不足而效果有限。本研究提出两阶段检索框架（密集搜索+LLM重新排序），显著提升检索性能，尤其适用于复杂查询。


<details>
  <summary>Details</summary>
Motivation: Galaxy现有的基于关键词的检索系统在语义查询解释方面支持有限，且缺乏精确术语匹配时难以检索到相关的工作流。本研究旨在填补这一空白，提升工作流检索的效果。

Method: 本研究采用了两阶段检索框架，结合密集向量搜索和基于大型语言模型（LLM）的重新排序。首阶段使用最先进的嵌入模型检索候选工作流，第二阶段使用指令调整的生成型LLM（如GPT-4o、Mistral-7B）进行语义任务对齐的重新排序。

Result: 实验结果表明，该方法显著提高了top-k准确性和相关性，尤其是在处理长查询或未明确指定的查询时表现突出。通过构建基准数据集和综合比较多种检索模型，验证了框架的有效性。

Conclusion: 本研究提出了一种任务感知的两阶段检索框架，显著提升了Galaxy工作流检索的准确性和相关性，尤其适用于长查询或未明确指定的查询。通过原型工具的集成，验证了LLM增强工作流搜索的可行性，提升了科学工作流的可用性和可访问性。

Abstract: Scientific Workflow Management Systems (SWfMSs) such as Galaxy have become
essential infrastructure in bioinformatics, supporting the design, execution,
and sharing of complex multi-step analyses. Despite hosting hundreds of
reusable workflows across domains, Galaxy's current keyword-based retrieval
system offers limited support for semantic query interpretation and often fails
to surface relevant workflows when exact term matches are absent. To address
this gap, we propose a task-aware, two-stage retrieval framework that
integrates dense vector search with large language model (LLM)-based reranking.
Our system first retrieves candidate workflows using state-of-the-art embedding
models and then reranks them using instruction-tuned generative LLMs (GPT-4o,
Mistral-7B) based on semantic task alignment. To support robust evaluation, we
construct a benchmark dataset of Galaxy workflows annotated with semantic
topics via BERTopic and synthesize realistic task-oriented queries using LLMs.
We conduct a comprehensive comparison of lexical, dense, and reranking models
using standard IR metrics, presenting the first systematic evaluation of
retrieval performance in the Galaxy ecosystem. Results show that our approach
significantly improves top-k accuracy and relevance, particularly for long or
under-specified queries. We further integrate our system as a prototype tool
within Galaxy, providing a proof-of-concept for LLM-enhanced workflow search.
This work advances the usability and accessibility of scientific workflows,
especially for novice users and interdisciplinary researchers.

</details>


### [312] [Context-Guided Decompilation: A Step Towards Re-executability](https://arxiv.org/abs/2511.01763)
*Xiaohan Wang,Yuxin Hu,Kevin Leach*

Main category: cs.SE

TL;DR: ICL4Decomp是一种混合反编译框架，通过上下文学习指导LLMs生成可重执行的源代码，相比现有技术提升了40%的可重执行性。


<details>
  <summary>Details</summary>
Motivation: 现有反编译技术（尤其是针对优化二进制文件）常无法生成可重执行的源代码，且基于LLM的方法通常仅生成语义合理而非真正可执行的代码。

Method: 提出了一种混合反编译框架ICL4Decomp，利用ICL引导LLMs生成可重执行的源代码。

Result: 在多个数据集、优化级别和编译器上评估，ICL4Decomp在可重执行性上比现有技术提升了约40%，同时保持鲁棒性。

Conclusion: ICL4Decomp通过结合上下文学习（ICL）指导大型语言模型（LLMs），显著提高了二进制反编译的可重执行性，相比现有技术提升了约40%。

Abstract: Binary decompilation plays an important role in software security analysis,
reverse engineering, and malware understanding when source code is unavailable.
However, existing decompilation techniques often fail to produce source code
that can be successfully recompiled and re-executed, particularly for optimized
binaries. Recent advances in large language models (LLMs) have enabled neural
approaches to decompilation, but the generated code is typically only
semantically plausible rather than truly executable, limiting their practical
reliability. These shortcomings arise from compiler optimizations and the loss
of semantic cues in compiled code, which LLMs struggle to recover without
contextual guidance. To address this challenge, we propose ICL4Decomp, a hybrid
decompilation framework that leverages in-context learning (ICL) to guide LLMs
toward generating re-executable source code. We evaluate our method across
multiple datasets, optimization levels, and compilers, demonstrating around
40\% improvement in re-executability over state-of-the-art decompilation
methods while maintaining robustness.

</details>


### [313] [SmartMLOps Studio: Design of an LLM-Integrated IDE with Automated MLOps Pipelines for Model Development and Monitoring](https://arxiv.org/abs/2511.01850)
*Jiawei Jin,Yingxin Su,Xiaotong Zhu*

Main category: cs.SE

TL;DR: 研究提出了一种LLM集成的IDE设计，结合自动化MLOps管道，显著提升了模型开发的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器学习应用的迅速扩展，对统一模型开发、部署和监控的集成环境的需求日益增加。传统IDE主要关注代码编写，缺乏对完整ML生命周期的智能支持，而现有的MLOps平台又与编码工作流脱节。

Method: 研究设计了一个LLM集成的IDE，其中嵌入了大型语言模型助手，支持代码生成、调试建议和自动管道配置。后端集成了自动化数据验证、特征存储、漂移检测、重训练触发和CI/CD部署编排。该框架在名为SmartMLOps Studio的原型中实现，并在UCI Adult和M5数据集上进行了分类和预测任务的评估。

Result: 实验结果表明，与传统工作流相比，SmartMLOps Studio将管道配置时间减少了61%，实验可重复性提高了45%，漂移检测准确率提高了14%。

Conclusion: 这项研究通过将智能代码助手与自动化操作管道结合，为AI工程建立了一种新范式，将IDE从静态编码工具转变为动态、生命周期感知的智能平台，从而实现可扩展且高效的模型开发。

Abstract: The rapid expansion of artificial intelligence and machine learning (ML)
applications has intensified the demand for integrated environments that unify
model development, deployment, and monitoring. Traditional Integrated
Development Environments (IDEs) focus primarily on code authoring, lacking
intelligent support for the full ML lifecycle, while existing MLOps platforms
remain detached from the coding workflow. To address this gap, this study
proposes the design of an LLM-Integrated IDE with automated MLOps pipelines
that enables continuous model development and monitoring within a single
environment. The proposed system embeds a Large Language Model (LLM) assistant
capable of code generation, debugging recommendation, and automatic pipeline
configuration. The backend incorporates automated data validation, feature
storage, drift detection, retraining triggers, and CI/CD deployment
orchestration. This framework was implemented in a prototype named SmartMLOps
Studio and evaluated using classification and forecasting tasks on the UCI
Adult and M5 datasets. Experimental results demonstrate that SmartMLOps Studio
reduces pipeline configuration time by 61%, improves experiment reproducibility
by 45%, and increases drift detection accuracy by 14% compared to traditional
workflows. By bridging intelligent code assistance and automated operational
pipelines, this research establishes a novel paradigm for AI engineering -
transforming the IDE from a static coding tool into a dynamic, lifecycle-aware
intelligent platform for scalable and efficient model development.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [314] [AeroResQ: Edge-Accelerated UAV Framework for Scalable, Resilient and Collaborative Escape Route Planning in Wildfire Scenarios](https://arxiv.org/abs/2511.00038)
*Suman Raj,Radhika Mittal,Rajiv Mayani,Pawel Zuk,Anirban Mandal,Michael Zink,Yogesh Simmhan,Ewa Deelman*

Main category: cs.DC

TL;DR: AeroResQ是一个边缘加速的无人机框架，用于野火场景中的协作逃生路线规划，通过多层架构和智能负载均衡实现了高效实时响应。


<details>
  <summary>Details</summary>
Motivation: 无人机在野火响应中具有潜力，但现有系统在可扩展性和弹性方面存在不足。AeroResQ旨在通过边缘加速和协作架构解决这些问题，提升逃生路线规划的效率和可靠性。

Method: AeroResQ采用多层协调架构，包括服务无人机（SDs）和协调无人机（CDs），分别执行火情监测和路线规划任务。SDs使用边缘加速器运行火灾检测和人体姿态识别的DNN模型，CDs则基于加权A*搜索算法动态生成逃生路线。

Result: 实验结果表明，AeroResQ在模拟的南加州野火场景中实现了端到端延迟≤500ms，任务重新分配和完成成功率超过98%，满足了实时部署的需求。

Conclusion: AeroResQ框架通过多层协作架构和智能负载均衡机制，在野火应急响应中实现了高效、实时的逃生路线规划，验证了其在实时决策和消防员安全操作中的可行性。

Abstract: Drone fleets equipped with onboard cameras, computer vision, and Deep Neural
Network (DNN) models present a powerful paradigm for real-time spatio-temporal
decision-making. In wildfire response, such drones play a pivotal role in
monitoring fire dynamics, supporting firefighter coordination, and facilitating
safe evacuation. In this paper, we introduce AeroResQ, an edge-accelerated UAV
framework designed for scalable, resilient, and collaborative escape route
planning during wildfire scenarios. AeroResQ adopts a multi-layer orchestration
architecture comprising service drones (SDs) and coordinator drones (CDs), each
performing specialized roles. SDs survey fire-affected areas, detect stranded
individuals using onboard edge accelerators running fire detection and human
pose identification DNN models, and issue requests for assistance. CDs,
equipped with lightweight data stores such as Apache IoTDB, dynamically
generate optimal ground escape routes and monitor firefighter movements along
these routes. The framework proposes a collaborative path-planning approach
based on a weighted A* search algorithm, where CDs compute context-aware escape
paths. AeroResQ further incorporates intelligent load-balancing and resilience
mechanisms: CD failures trigger automated data redistribution across IoTDB
replicas, while SD failures initiate geo-fenced re-partitioning and
reassignment of spatial workloads to operational SDs. We evaluate AeroResQ
using realistic wildfire emulated setup modeled on recent Southern California
wildfires. Experimental results demonstrate that AeroResQ achieves a nominal
end-to-end latency of <=500ms, much below the 2s request interval, while
maintaining over 98% successful task reassignment and completion, underscoring
its feasibility for real-time, on-field deployment in emergency response and
firefighter safety operations.

</details>


### [315] [COOL Is Optimal in Error-Free Asynchronous Byzantine Agreement](https://arxiv.org/abs/2511.00263)
*Jinyuan Chen*

Main category: cs.DC

TL;DR: OciorACOOL 是 COOL 的异步版本，实现了无错误、信息论安全的 BA 共识，保持了低通信复杂性和高效性。


<details>
  <summary>Details</summary>
Motivation: 为了在异步环境中实现与 COOL 相同的无错误、信息论安全 BA 共识，同时保持低通信复杂性和高效性，提出了 OciorACOOL。

Method: OciorACOOL 是一种自适应变体，采用传统的 $(n, k)$ 错误纠正编码和解码，其中 $k=t/3$，并在异步设置中实现了 $O(1)$ 轮次和单次异步二进制 BA 调用。

Result: OciorACOOL 在异步设置中实现了 $O(\max\{n\ell, n t \log q\})$ 通信比特、$O(1)$ 轮次和单次异步二进制 BA 调用，且在最优容错假设 $n \geq 3t + 1$ 下工作。

Conclusion: OciorACOOL 在异步环境中实现了无错误、信息论安全的 BA 共识，保持了与 COOL 相同的通信复杂性和错误纠正机制，同时适应了异步设置。

Abstract: COOL (Chen'21) is an error-free, information-theoretically secure Byzantine
agreement (BA) protocol proven to achieve BA consensus in the synchronous
setting for an $\ell$-bit message, with a total communication complexity of
$O(\max\{n\ell, nt \log q\})$ bits, four communication rounds in the worst
case, and a single invocation of a binary BA, under the optimal resilience
assumption $n \geq 3t + 1$ in a network of $n$ nodes, where up to $t$ nodes may
behave dishonestly. Here, $q$ denotes the alphabet size of the error correction
code used in the protocol.
  In this work, we present an adaptive variant of COOL, called OciorACOOL,
which achieves error-free, information-theoretically secure BA consensus in the
asynchronous setting with total $O(\max\{n\ell, n t \log q\})$ communication
bits, $O(1)$ rounds, and a single invocation of an asynchronous binary BA
protocol, still under the optimal resilience assumption $n \geq 3t + 1$.
Moreover, OciorACOOL retains the same low-complexity, traditional $(n, k)$
error-correction encoding and decoding as COOL, with $k=t/3$.

</details>


### [316] [Tetris: An SLA-aware Application Placement Strategy in the Edge-Cloud Continuum](https://arxiv.org/abs/2511.00294)
*Lucas Almeida,Maycon Peixoto*

Main category: cs.DC

TL;DR: Tetris是一种边缘-云连续体中的应用放置策略，通过启发式算法优化资源分配，显著减少SLA违规，提升QoS。


<details>
  <summary>Details</summary>
Motivation: 边缘-云连续体整合边缘和云资源，提供灵活可扩展的基础设施，旨在通过边缘处理数据减少延迟，同时利用云的强大计算能力处理密集任务。

Method: Tetris采用启发式算法，根据SLA紧急程度和资源效率优先分配计算服务，避免系统过载。

Result: Tetris相比基准方法减少了约76%的SLA违规。

Conclusion: Tetris提供了一种有效的应用放置策略，用于管理边缘-云连续体环境中的延迟敏感型应用，显著提升了用户的服务质量（QoS）。

Abstract: An Edge-Cloud Continuum integrates edge and cloud resources to provide a
flexible and scalable infrastructure. This paradigm can minimize latency by
processing data closer to the source at the edge while leveraging the vast
computational power of the cloud for more intensive tasks. In this context,
module application placement requires strategic allocation plans that align
user demands with infrastructure constraints, aiming for efficient resource
use. Therefore, we propose Tetris, an application placement strategy that
utilizes a heuristic algorithm to distribute computational services across edge
and cloud resources efficiently. Tetris prioritizes services based on SLA
urgencies and resource efficiency to avoid system overloading. Our results
demonstrate that Tetris reduces SLA violations by approximately 76% compared to
the baseline method, which serves as a reference point for benchmarking
performance in this scenario. Therefore, Tetris offers an effective placement
approach for managing latency-sensitive applications in Edge-Cloud Continuum
environments, enhancing Quality of Service (QoS) for users.

</details>


### [317] [EPARA: Parallelizing Categorized AI Inference in Edge Clouds](https://arxiv.org/abs/2511.00603)
*Yubo Wang,Yubo Cui,Tuo Shi,Danyang Li,Wenxin Li,Lide Suo,Tao Wang,Xin Xie*

Main category: cs.DC

TL;DR: EPARA是一种边缘AI并行推理框架，通过任务分类和动态资源分配提升性能，实验显示其好吞吐量比现有框架高2.1倍。


<details>
  <summary>Details</summary>
Motivation: 随着AI应用如大语言模型和计算机视觉的普及，边缘云中提升现有硬件的任务处理能力成为关键目标。

Method: EPARA包含三个核心组件：任务分类并行分配器、分布式请求处理器和状态感知调度器，通过任务分类和动态调度实现资源优化。

Result: 实验证明，EPARA在生产工作负载中比现有框架实现了高达2.1倍的好吞吐量，并能适应多种边缘AI推理任务。

Conclusion: EPARA框架通过任务分类和资源分配优化，显著提升了边缘AI推理的性能和适应性，展示了其在生产环境中的高效性。

Abstract: With the increasing adoption of AI applications such as large language models
and computer vision AI, the computational demands on AI inference systems are
continuously rising, making the enhancement of task processing capacity using
existing hardware a primary objective in edge clouds. We propose EPARA, an
end-to-end AI parallel inference framework in edge, aimed at enhancing the edge
AI serving capability. Our key idea is to categorize tasks based on their
sensitivity to latency/frequency and requirement for GPU resources, thereby
achieving both request-level and service-level task-resource allocation. EPARA
consists of three core components: 1) a task-categorized parallelism allocator
that decides the parallel mode of each task, 2) a distributed request handler
that performs the calculation for the specific request, and 3) a state-aware
scheduler that periodically updates service placement in edge clouds. We
implement a EPARA prototype and conduct a case study on the EPARA operation for
LLMs and segmentation tasks. Evaluation through testbed experiments involving
edge servers, embedded devices, and microcomputers shows that EPARA achieves up
to 2.1$\times$ higher goodput in production workloads compared to prior
frameworks, while adapting to various edge AI inference tasks.

</details>


### [318] [AReaL-Hex: Accommodating Asynchronous RL Training over Heterogeneous GPUs](https://arxiv.org/abs/2511.00796)
*Ran Yan,Youhe Jiang,Tianyuan Wu,Jiaxuan Gao,Zhiyu Mei,Wei Fu,Haohui Mai,Wei Wang,Yi Wu,Binhang Yuan*

Main category: cs.DC

TL;DR: AReaL-Hex通过异构GPU调度优化RL训练，提升吞吐量并降低成本。


<details>
  <summary>Details</summary>
Motivation: 最大化RL训练吞吐量和成本效率，以促进LLM技术的普及。

Method: 使用两阶段调度器：MILP约束搜索选择并行化策略和资源分配，图分区步骤优化GPU和互连分配。

Result: 在数学推理任务中，AReaL-Hex比同构部署提升1.50倍吞吐量或降低1.46倍成本。

Conclusion: AReaL-Hex通过异构GPU部署和智能调度策略，显著提升了RL训练的吞吐量和成本效率，为LLM的民主化应用提供了实用解决方案。

Abstract: Maximizing training throughput and cost-efficiency of RL for LLMs is
essential to democratize this advanced technique. One promising but challenging
approach is to deploy such a computational workflow over heterogeneous GPUs.
Unlike conventional large-scale LLM pretraining, RL training generally
decomposes into three coupled stages, i.e., rollout generation, reward
computation, and policy/value updates, which exhibit markedly different compute
intensities, memory footprints, and communication patterns. Recent research
shows that fully asynchronous RL training can disaggregate these stages across
disjoint hardware pools without sacrificing training stability, creating a
great opportunity for real-world heterogeneous deployment. To this end, we
present AReaL-Hex, a heterogeneity-aware asynchronous RL training system that
effectively schedules how to execute rollout generation and policy model
training over heterogeneous GPUs while enforcing data staleness bounds.
Concretely, we use a two-phase scheduler: (i) a constrained search with MILP to
select per-stage parallelization strategies and workload assignments given a
resource budget, and (ii) a graph-partitioning step that allocates
heterogeneous GPUs and interconnects to maximize end-to-end throughput. Built
atop a fully asynchronous RL architecture, AReaL-Hex maps HBM-I/O-bound
generation and compute-bound optimization to more cost-efficient resources and
balances their producer-consumer interactions to avoid both idleness and stale
rollout trajectories. On the mathematical reasoning task with various model
scales (1.5B, 7B, and 14B), compared to homogeneous deployments of
state-of-the-art asynchronous RL systems: (i) When maintaining the same total
budgets, AReaL-Hex delivers up to 1.50x higher training throughput; (ii) When
achieving the same training throughput, AReaL-Hex results in up to 1.46x
reduction in training cost.

</details>


### [319] [FREESH: Fair, Resource- and Energy-Efficient Scheduling for LLM Serving on Heterogeneous GPUs](https://arxiv.org/abs/2511.00807)
*Xuan He,Zequan Fang,Jinzhao Lian,Danny H. K. Tsang,Baosen Zhang,Yize Chen*

Main category: cs.DC

TL;DR: FREESH通过优化路由和调度策略，显著降低LLM服务系统的能源消耗和碳排放，同时提升性能和公平性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM和AI代理对计算和能源需求的不断增加，需要高效优化LLM服务系统。地理分布的异构GPU集群和多样化的LLM负载（查询流量和服务模式）带来了碳足迹差异的挑战。

Method: FREESH通过匹配不同GPU实例的功率-吞吐量特性与可预测的LLM查询长度和工作负载，优化了并行性和查询路由调度，并结合动态GPU频率缩放和Least-Laxity-First（LLF）服务策略。

Result: 在1小时的生产工作负载服务中，FREESH减少了28.6%的能源消耗和45.45%的碳排放，同时提高了SLO达成率和公平性。

Conclusion: FREESH系统通过联合路由和调度策略，在满足延迟和公平性要求的同时，显著降低了能源消耗和碳排放，并提高了服务等级目标（SLO）达成率和公平性。

Abstract: The ever-increasing computation and energy demand for LLM and AI agents call
for holistic and efficient optimization of LLM serving systems. In practice,
heterogeneous GPU clusters can be deployed in a geographically distributed
manner, while LLM load also observes diversity in terms of both query traffic
and serving patterns. LLM queries running on advanced GPUs during a
high-emission hour at one location can lead to significantly higher carbon
footprints versus same queries running on mid-level GPUs at a low-emission time
and location. By observing LLM serving requirements and leveraging
spatiotemporal computation flexibility, we consider the joint routing and
scheduling problem, and propose FREESH to cooperatively run a group of data
centers while minimizing user-specified carbon or energy objectives. FREESH
identifies the optimal configurations of balanced load serving by matching
distinct GPU instance's power-throughput characteristics with predictable LLM
query length and workloads. To ensure both latency and fairness requirements,
FREESH identifies optimized parallelism and query routing schedules together
with dynamic GPU frequency scaling for power saving, and Least-Laxity-First
(LLF) serving strategy for query scheduling. During the 1-hour serving on
production workloads, FREESH reduces energy by 28.6% and emissions by 45.45%
together with improvements in SLO attainment and fairness.

</details>


### [320] [Towards Portability at Scale: A Cross-Architecture Performance Evaluation of a GPU-enabled Shallow Water Solver](https://arxiv.org/abs/2511.01001)
*Johansell Villalobos,Daniel Caviedes-Voullième,Silvio Rizzi,Esteban Meneses*

Main category: cs.DC

TL;DR: 研究评估了SERGHEI-SWE求解器在四种HPC系统上的性能，展示了其扩展性和可移植性，内存带宽是主要瓶颈，优化潜力大。


<details>
  <summary>Details</summary>
Motivation: 应对气候变化对高分辨率实时水文模拟的需求，研究探索了GPU加速平台和性能可移植编程框架（如Kokkos）在浅水方程求解器中的应用。

Method: 研究评估了SERGHEI-SWE求解器在四种异构高性能计算系统上的性能，包括强扩展性和弱扩展性测试，并应用了Roofline分析和性能可移植性指标。

Result: SERGHEI-SWE在1024个GPU上展现了32倍的加速比和90%以上的效率，内存带宽是主要性能瓶颈，性能可移植性在调优问题规模下可达70%。

Conclusion: SERGHEI-SWE是一个在异构高性能计算系统上表现出强大扩展性和性能可移植性的浅水方程求解器，具备优化潜力以进一步提升性能。

Abstract: Current climate change has posed a grand challenge in the field of numerical
modeling due to its complex, multiscale dynamics. In hydrological modeling, the
increasing demand for high-resolution, real-time simulations has led to the
adoption of GPU-accelerated platforms and performance portable programming
frameworks such as Kokkos. In this work, we present a comprehensive performance
study of the SERGHEI-SWE solver, a shallow water equations code, across four
state-of-the-art heterogeneous HPC systems: Frontier (AMD MI250X), JUWELS
Booster (NVIDIA A100), JEDI (NVIDIA H100), and Aurora (Intel Max 1550). We
assess strong scaling up to 1024 GPUs and weak scaling upwards of 2048 GPUs,
demonstrating consistent scalability with a speedup of 32 and an efficiency
upwards of 90\% for most almost all the test range. Roofline analysis reveals
that memory bandwidth is the dominant performance bottleneck, with key solver
kernels residing in the memory-bound region. To evaluate performance
portability, we apply both harmonic and arithmetic mean-based metrics while
varying problem size. Results indicate that while SERGHEI-SWE achieves
portability across devices with tuned problem sizes (<70\%), there is room for
kernel optimization within the solver with more granular control of the
architecture specifically by using Kokkos teams and architecture specific
tunable parameters. These findings position SERGHEI-SWE as a robust, scalable,
and portable simulation tool for large-scale geophysical applications under
evolving HPC architectures with potential to enhance its performance.

</details>


### [321] [Neuro-Inspired Task Offloading in Edge-IoT Networks Using Spiking Neural Networks](https://arxiv.org/abs/2511.01127)
*Fabio Diniz Rossi*

Main category: cs.DC

TL;DR: 提出了一种基于SNN的任务卸载框架，显著提升了动态边缘计算环境中的任务处理效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 传统的任务卸载策略在高度动态和资源受限的环境中表现不佳，因此需要一种更高效、适应性更强的解决方案。

Method: 通过将基于SNN的决策模块集成到边缘节点，实现实时、节能的任务编排，并使用YAFS和Brian2构建的混合仿真环境进行模型评估。

Result: 与传统启发式和基于机器学习的方法相比，该模型在高负载条件下实现了高达26%的延迟降低、32%的能耗减少和25%的成功率提升。

Conclusion: 该论文提出了一种基于脉冲神经网络（SNN）的新型任务卸载框架，显著降低了任务处理延迟和能耗，同时提高了任务成功率。

Abstract: Traditional task offloading strategies in edge computing often rely on static
heuristics or data-intensive machine learning models, which are not always
suitable for highly dynamic and resource-constrained environments. In this
paper, we propose a novel task-offloading framework based on Spiking Neural
Networks inspired by the efficiency and adaptability of biological neural
systems. Our approach integrates an SNN-based decision module into edge nodes
to perform real-time, energy-efficient task orchestration. We evaluate the
model under various IoT workload scenarios using a hybrid simulation
environment composed of YAFS and Brian2. The results demonstrate that our
SNN-based framework significantly reduces task processing latency and energy
consumption while improving task success rates. Compared to traditional
heuristic and ML-based strategies, our model achieves up to 26% lower latency,
32% less energy consumption, and 25\% higher success rate under high-load
conditions.

</details>


### [322] [Scalable Maxflow Processing for Dynamic Graphs](https://arxiv.org/abs/2511.01235)
*Shruthi Kannappan,Ashwina Kumar,Rupesh Nasre*

Main category: cs.DC

TL;DR: 本文提出了一种高效的GPU并行最大流算法，适用于动态和静态图，并通过CUDA优化提升了性能。


<details>
  <summary>Details</summary>
Motivation: 最大流问题在多个领域有广泛应用，现有算法在并行化和GPU加速方面存在优化空间。

Method: 采用Push-Relabel算法，结合GPU并行化技术，实现了动态图的增量重计算和静态图的高效初始计算。

Result: 提出的算法在性能和内存效率上有显著提升，适用于现代GPU架构。

Conclusion: 本文提出了针对动态图和静态图的高效GPU并行最大流算法，并通过CUDA优化提升了性能和内存效率。

Abstract: The Maximum Flow (Max-Flow) problem is a cornerstone in graph theory and
combinatorial optimization, aiming to determine the largest possible flow from
a designated source node to a sink node within a capacitated flow network. It
has extensive applications across diverse domains such as computer networking,
transportation systems, and image segmentation. The objective is to maximize
the total throughput while respecting edge capacity constraints and maintaining
flow conservation at all intermediate vertices.
  Among the various algorithms proposed for solving the Max-Flow problem, the
Push--Relabel algorithm is particularly notable for its efficiency and
suitability for parallelization, owing to its localized vertex-based
operations. This property has motivated extensive research into GPU-accelerated
Max-Flow computation, leveraging the high degree of parallelism inherent to
modern GPU architectures.
  In this paper, we present a novel GPU-parallel Max-Flow algorithm capable of
incrementally recomputing the maximum flow of a dynamic graph following a batch
of edge updates. In addition, we introduce a high-performance static GPU
algorithm designed for efficiently computing the initial Max-Flow on static
graphs. We further describe a series of CUDA-specific implementation
optimizations that enhance performance, scalability, and memory efficiency on
GPU platforms.

</details>


### [323] [Design of quasi phase matching crystal based on differential gray wolf algorithm](https://arxiv.org/abs/2511.01255)
*He Chen,ZiHua Zheng,JingHua Sun*

Main category: cs.DC

TL;DR: 本文提出混合优化算法与GPU并行加速方案，显著提升非周期性极化晶体的性能优化效率与精度。


<details>
  <summary>Details</summary>
Motivation: 传统算法在高维离散组合优化中收敛慢且易陷入局部优化，启发式方法受限于CPU串行计算效率低下。

Method: 结合差分进化算法（DE）进行全局搜索和灰狼优化算法（GWO）进行局部搜索与加速收敛，并利用GPU多核架构实现线程级并行计算。

Result: 方案将准相位匹配设计效率提升数百至数千倍，为非线型光学器件的复杂设计提供了新范式。

Conclusion: 本文提出的混合优化算法与GPU并行加速技术融合方案，有效解决了非周期性极化晶体性能优化的高维离散组合问题，显著提升了晶体域控制的精度和准相位匹配设计的效率。

Abstract: This paper focuses on the key problem in the development of nonlinear optical
technology, the performance optimization of aperiodically polarized crystals.
The performance of the crystal depends on the precise control of the micro
distribution of crystal domains, but its optimization belongs to the
high-dimensional discrete combination "NP hard" problem. The traditional
algorithm has the bottleneck of slow convergence and easy to fall into local
optimization, while the heuristic methods such as genetic algorithm are limited
by the CPU serial calculation and inefficient. In order to solve the above
challenges, this paper proposes the fusion scheme of hwsda hybrid optimization
algorithm and GPU parallel acceleration technology: the differential evolution
algorithm (DE) is used to realize the global search, and the gray wolf
optimization algorithm (GWO) is used to strengthen the local search and
convergence speed, and the two coordinate to balance the global and local
optimization requirements; At the same time, it relies on GPU multi-core
architecture to realize thread level parallel computing and improve
optimization efficiency. This scheme effectively breaks through the
optimization problem of high-dimensional discrete space, improves the accuracy
of crystal domain control, improves the efficiency of quasi phase matching
design by hundreds to thousands of times compared with traditional CPU serial
computing, provides a new paradigm for the design of complex nonlinear optical
devices, and helps promote the performance breakthrough and industrial
application of related devices in the fields of quantum optics and laser
processing.

</details>


### [324] [Transformer-Based Sparse CSI Estimation for Non-Stationary Channels](https://arxiv.org/abs/2511.01333)
*Muhammad Ahmed Mohsin,Muhammad Umer,Ahsan Bilal,Hassan Rizwan,Sagnik Bhattacharya,Muhammad Ali Jamshed,John M. Cioffi*

Main category: cs.DC

TL;DR: 论文提出了一种结合模型驱动和数据驱动的Flash-Attention Transformer框架，显著提升了非静态无线系统中的CSI估计性能，降低了开销。


<details>
  <summary>Details</summary>
Motivation: 在非静态条件下，传统导频辅助估计器开销大，而深度学习方法在动态导频模式和时变衰落下性能下降。因此，需要一种更高效且鲁棒的CSI估计方法。

Method: 提出了一种基于Flash-Attention Transformer的框架，结合模型驱动的导频获取和数据驱动的CSI重建，通过分块自注意力和物理感知复合损失函数实现相位对齐、相关一致性和时频平滑性。

Result: 在标准化的3GPP NR配置下，该框架在相位不变归一化均方误差（NMSE）上比LMMSE和LSTM基线高出约13 dB，误码率（BER）显著降低，同时导频开销减少了16倍。

Conclusion: 基于注意力机制的架构在不影响链路质量的情况下实现了可靠的CSI恢复和更高的频谱效率，解决了非静态5G及超5G网络中自适应、低开销信道估计的基本瓶颈。

Abstract: Accurate and efficient estimation of Channel State Information (CSI) is
critical for next-generation wireless systems operating under non-stationary
conditions, where user mobility, Doppler spread, and multipath dynamics rapidly
alter channel statistics. Conventional pilot aided estimators incur substantial
overhead, while deep learning approaches degrade under dynamic pilot patterns
and time varying fading. This paper presents a pilot-aided Flash-Attention
Transformer framework that unifies model-driven pilot acquisition with data
driven CSI reconstruction through patch-wise self-attention and a physics aware
composite loss function enforcing phase alignment, correlation consistency, and
time frequency smoothness. Under a standardized 3GPP NR configuration, the
proposed framework outperforms LMMSE and LSTM baselines by approximately 13 dB
in phase invariant normalized mean-square error (NMSE) with markedly lower
bit-error rate (BER), while reducing pilot overhead by 16 times. These results
demonstrate that attention based architectures enable reliable CSI recovery and
enhanced spectral efficiency without compromising link quality, addressing a
fundamental bottleneck in adaptive, low-overhead channel estimation for
non-stationary 5G and beyond-5G networks.

</details>


### [325] [Gradient Clock Synchronization with Practically Constant Local Skew](https://arxiv.org/abs/2511.01420)
*Christoph Lenzen*

Main category: cs.DC

TL;DR: 论文改进了GCS模型，通过稳定性假设突破现有下限，优化局部偏差为O(Δ+δ log D)，并扩展至外部同步。


<details>
  <summary>Details</summary>
Motivation: 现有GCS方法的局部偏差界限依赖于全局上限假设，实际中频率更稳定，因此需要更精确的模型来优化性能。

Method: 提出了一种基于测量和频率误差稳定性的新模型，分析现有技术并优化局部偏差界限。

Result: 在均匀最坏情况估计误差Δ和变化δ≪Δ条件下，局部偏差界限优化为O(Δ+δ log D)，显著优于Ω(Δ log D)。

Conclusion: 该论文通过改进模型和分析现有技术，显著提升了梯度时钟同步（GCS）的性能，突破了现有下限，并在外部同步场景中扩展了这些成果。

Abstract: Gradient Clock Synchronization (GCS) is the task of minimizing the local
skew, i.e., the clock offset between neighboring clocks, in a larger network.
While asymptotically optimal bounds are known, from a practical perspective
they have crucial shortcomings:
  - Local skew bounds are determined by upper bounds on offset estimation that
need to be guaranteed throughout the entire lifetime of the system.
  - Worst-case frequency deviations of local oscillators from their nominal
rate are assumed, yet frequencies tend to be much more stable in the (relevant)
short term.
  State-of-the-art deployed synchronization methods adapt to the true offset
measurement and frequency errors, but achieve no non-trivial guarantees on the
local skew.
  In this work, we provide a refined model and novel analysis of existing
techniques for solving GCS in this model. By requiring only stability of
measurement and frequency errors, we can circumvent existing lower bounds,
leading to dramatic improvements under very general conditions. For example, if
links exhibit a uniform worst-case estimation error of $\Delta$ and a change in
estimation errors of $\delta\ll \Delta$ on relevant time scales, we bound the
local skew by $O(\Delta+\delta \log D)$ for networks of diameter $D$,
effectively ``breaking'' the established $\Omega(\Delta\log D)$ lower bound,
which holds when $\delta=\Delta$. Similarly, we show how to limit the influence
of local oscillators on $\delta$ to scale with the change of frequency of an
individual oscillator on relevant time scales, rather than a worst-case bound
over all oscillators and the lifetime of the system.
  Moreover, we show how to ensure self-stabilization in this challenging
setting. Last, but not least, we extend all of our results to the scenario of
external synchronization, at the cost of a limited increase in stabilization
time.

</details>


### [326] [Adaptive Multidimensional Quadrature on Multi-GPU Systems](https://arxiv.org/abs/2511.01573)
*Melanie Tonarelli,Simone Riva,Pietro Benedusi,Fabrizio Ferrandi,Rolf Krause*

Main category: cs.DC

TL;DR: 提出了一种多GPU架构上的分布式自适应求积方法，通过动态负载平衡策略提高高维积分效率。


<details>
  <summary>Details</summary>
Motivation: 解决多GPU架构上自适应过程中出现的负载不平衡问题，提高高维积分计算的效率和鲁棒性。

Method: 采用分层域分解方法，基于局部误差估计器递归划分积分域，并使用非阻塞、CUDA感知的MPI通信动态重新分配子域负载。

Result: 与现有GPU优化包相比，该方法在高维情况下效率更高，对积分函数的规则性和目标精度具有更好的鲁棒性。

Conclusion: 提出的分布式自适应求积方法在多GPU架构上表现出更高的效率和鲁棒性，适用于高维积分计算。

Abstract: We introduce a distributed adaptive quadrature method that formulates
multidimensional integration as a hierarchical domain decomposition problem on
multi-GPU architectures. The integration domain is recursively partitioned into
subdomains whose refinement is guided by local error estimators. Each subdomain
evolves independently on a GPU, which exposes a significant load imbalance as
the adaptive process progresses. To address this challenge, we introduce a
decentralised load redistribution schemes based on a cyclic round-robin policy.
This strategy dynamically rebalance subdomains across devices through
non-blocking, CUDA-aware MPI communication that overlaps with computation. The
proposed strategy has two main advantages compared to a state-of-the-art
GPU-tailored package: higher efficiency in high dimensions; and improved
robustness w.r.t the integrand regularity and the target accuracy.

</details>


### [327] [LARK - Linearizability Algorithms for Replicated Keys in Aerospike](https://arxiv.org/abs/2511.01843)
*Andrew Goodng,Kevin Porter,Thomas Lopatic,Ashish Shinde,Sunil Sayyaparaju,Srinivasan Seshadri,V. Srinivasan*

Main category: cs.DC

TL;DR: LARK是一种同步复制协议，通过优化分区可用性和消除有序日志，显著提高了数据库集群的可用性并降低了延迟，相比传统协议有显著优势。


<details>
  <summary>Details</summary>
Motivation: 传统的基于日志的共识协议（如Raft、Paxos）在容忍故障时存在高延迟和基础设施成本，且可用性较低。LARK旨在解决这些问题，提供更高的可用性和更低的延迟。

Method: LARK采用同步复制协议，通过PAC对整个数据库集群进行推理，而非固定副本集，从而优化了分区可用性。此外，LARK消除了有序日志，使得分区在领导者变更后能立即准备就绪。

Result: LARK在容忍一个故障时可用性提高了约3倍，容忍两个故障时提高了约10倍。即使在数据节点故障时，LARK仍能继续提交，而基于日志的协议则必须暂停提交以重建副本。

Conclusion: LARK协议通过引入分区可用性条件（PAC）和消除有序日志，显著提高了数据库集群的可用性，并在容忍故障时减少了延迟和基础设施成本。

Abstract: We present LARK (Linearizability Algorithms for Replicated Keys), a
synchronous replication protocol that achieves linearizability while minimizing
latency and infrastructure cost, at significantly higher availability than
traditional quorum-log consensus. LARK introduces Partition Availability
Conditions (PAC) that reason over the entire database cluster rather than fixed
replica sets, improving partition availability under independent failures by
roughly 3x when tolerating one failure and 10x when tolerating two. Unlike
Raft, Paxos, and Viewstamped Replication, LARK eliminates ordered logs,
enabling immediate partition readiness after leader changes -- with at most a
per-key duplicate-resolution round trip when the new leader lacks the latest
copy. Under equal storage budgets -- where both systems maintain only f+1 data
copies to tolerate f failures -- LARK continues committing through data-node
failures while log-based protocols must pause commits for replica rebuilding.
These properties also enable zero-downtime rolling restarts even when
maintaining only two copies. We provide formal safety arguments and a TLA+
specification, and we demonstrate through analysis and experiments that LARK
achieves significant availability gains.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [328] [Applying Medical Imaging Tractography Techniques to Painterly Rendering of Images](https://arxiv.org/abs/2511.00702)
*Alberto Di Biase*

Main category: cs.GR

TL;DR: 本文提出了一种将DTI纤维追踪技术应用于绘画渲染的方法，通过结构张量优化笔触方向，模拟艺术家绘画过程。


<details>
  <summary>Details</summary>
Motivation: 探索DTI和纤维追踪技术在绘画渲染中的潜在应用，模拟人类艺术家的绘画过程。

Method: 使用结构张量替代梯度，提供更好的局部方向信息，并采用类似于DTI纤维追踪的算法进行笔触放置。

Result: 在肖像和一般图像上成功演示了该技术，展示了纤维追踪与笔触放置之间的相似性。

Conclusion: 本文探索了将扩散张量成像（DTI）技术应用于图像绘画渲染的跨领域应用，通过模拟艺术家绘画过程的笔触放置，展示了该技术的潜力。

Abstract: Doctors and researchers routinely use diffusion tensor imaging (DTI) and
tractography to visualize the fibrous structure of tissues in the human body.
This paper explores the connection of these techniques to the painterly
rendering of images. Using a tractography algorithm the presented method can
place brush strokes that mimic the painting process of human artists,
analogously to how fibres are tracked in DTI. The analogue to the diffusion
tensor for image orientation is the structural tensor, which can provide better
local orientation information than the gradient alone. I demonstrate this
technique in portraits and general images, and discuss the parallels between
fibre tracking and brush stroke placement, and frame it in the language of
tractography. This work presents an exploratory investigation into the
cross-domain application of diffusion tensor imaging techniques to painterly
rendering of images. All the code is available at
https://github.com/tito21/st-python

</details>


### [329] [Empowering LLMs with Structural Role Inference for Zero-Shot Graph Learning](https://arxiv.org/abs/2511.00898)
*Heng Zhang,Jing Liu,Jiajun Wu,Haochen You,Lubin Gan,Yuling Shi,Xiaodong Gu,Zijian Zhang,Shuai Chen,Wenjun Huang,Jin Huang*

Main category: cs.GR

TL;DR: DuoGLM通过双视角框架提升LLMs在图理解中的表现，零样本分类准确率提升14.3%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在结构重要节点上表现不佳，缺乏将拓扑模式转化为基于角色的解释的推理支架。

Method: 提出了DuoGLM，一个无需训练的双视角框架，局部视角构建关系感知模板，全局视角进行拓扑到角色的推理。

Result: 在八个基准数据集上的实验显示，DuoGLM在零样本节点分类中准确率提升14.3%，跨域迁移AUC提升7.6%。

Conclusion: DuoGLM通过显式的角色推理机制，显著提升了LLMs在图理解任务中的表现，特别是在零样本节点分类和跨域迁移任务中。

Abstract: Large Language Models have emerged as a promising approach for graph learning
due to their powerful reasoning capabilities. However, existing methods exhibit
systematic performance degradation on structurally important nodes such as
bridges and hubs. We identify the root cause of these limitations. Current
approaches encode graph topology into static features but lack reasoning
scaffolds to transform topological patterns into role-based interpretations.
This limitation becomes critical in zero-shot scenarios where no training data
establishes structure-semantics mappings. To address this gap, we propose
DuoGLM, a training-free dual-perspective framework for structure-aware graph
reasoning. The local perspective constructs relation-aware templates capturing
semantic interactions between nodes and neighbors. The global perspective
performs topology-to-role inference to generate functional descriptions of
structural positions. These complementary perspectives provide explicit
reasoning mechanisms enabling LLMs to distinguish topologically similar but
semantically different nodes. Extensive experiments across eight benchmark
datasets demonstrate substantial improvements. DuoGLM achieves 14.3\% accuracy
gain in zero-shot node classification and 7.6\% AUC improvement in cross-domain
transfer compared to existing methods. The results validate the effectiveness
of explicit role reasoning for graph understanding with LLMs.

</details>


### [330] [G2rammar: Bilingual Grammar Modeling for Enhanced Text-attributed Graph Learning](https://arxiv.org/abs/2511.00911)
*Heng Zheng,Haochen You,Zijun Liu,Zijian Zhang,Lubin Gan,Hao Zhang,Wenjun Huang,Jin Huang*

Main category: cs.GR

TL;DR: G2rammar是一个双语语法框架，通过编码结构和语义语法增强语言模型对文本属性图的理解，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略了语法在表达性中的关键作用，导致语言模型难以有效推理图拓扑结构。

Method: 采用两阶段学习：结构语法预训练和语义语法微调，分别通过中心性和邻域模式表征拓扑角色，以及通过文本信息性捕捉内容关系。

Result: 在真实数据集上的广泛实验表明，G2rammar通过提供语法上下文，显著优于竞争基线。

Conclusion: G2rammar框架通过显式编码结构和语义语法，显著提升了语言模型对图拓扑的理解能力，并在实验中表现优于现有基线方法。

Abstract: Text-attributed graphs require models to effectively integrate both
structural topology and semantic content. Recent approaches apply large
language models to graphs by linearizing structures into token sequences
through random walks. These methods create concise graph vocabularies to
replace verbose natural language descriptions. However, they overlook a
critical component that makes language expressive: grammar. In natural
language, grammar assigns syntactic roles to words and defines their functions
within sentences. Similarly, nodes in graphs play distinct structural roles as
hubs, bridges, or peripheral members. Current graph language methods provide
tokens without grammatical annotations to indicate these structural or semantic
roles. This absence limits language models' ability to reason about graph
topology effectively. We propose \textbf{G2rammar}, a bilingual grammar
framework that explicitly encodes both structural and semantic grammar for
text-attributed graphs. Structural grammar characterizes topological roles
through centrality and neighborhood patterns. Semantic grammar captures content
relationships through textual informativity. The framework implements two-stage
learning with structural grammar pre-training followed by semantic grammar
fine-tuning. Extensive experiments on real-world datasets demonstrate that
G2rammar consistently outperforms competitive baselines by providing language
models with the grammatical context needed to understand graph structures.

</details>


### [331] [An Adjoint Method for Differentiable Fluid Simulation on Flow Maps](https://arxiv.org/abs/2511.01259)
*Zhiqi Li,Jinjin He,Barnabás Börcsök,Taiyuan Zhang,Duowen Chen,Tao Du,Ming C. Lin,Greg Turk,Bo Zhu*

Main category: cs.GR

TL;DR: 本文提出了一种基于双向流映射的高效伴随求解器，显著降低了内存需求并提高了梯度计算精度，适用于涡旋动力学的精确模拟任务。


<details>
  <summary>Details</summary>
Motivation: 传统伴随方法在计算流体模拟梯度时效率低且内存消耗大，限制了其在涡旋动力学等精确任务中的应用。本文旨在解决这些问题。

Method: 通过共享前向和反向模拟中的流映射，直接在流映射上求解伴随方程，避免了传统方法中需要微分中间数值步骤或存储中间变量的需求。此外，引入了长-短时间稀疏流映射表示以提升效率。

Result: 新方法在192^3分辨率下仅需6.53GB内存，同时保持了高精度的涡度跟踪，实现了对不可压缩流体的长范围和准确微分。

Conclusion: 本文提出了一种基于双向流映射的新型伴随求解器，显著提高了流体模拟中梯度计算的效率和精度，为涡旋动力学的识别、预测和控制提供了新工具。

Abstract: This paper presents a novel adjoint solver for differentiable fluid
simulation based on bidirectional flow maps. Our key observation is that the
forward fluid solver and its corresponding backward, adjoint solver share the
same flow map as the forward simulation. In the forward pass, this map
transports fluid impulse variables from the initial frame to the current frame
to simulate vortical dynamics. In the backward pass, the same map propagates
adjoint variables from the current frame back to the initial frame to compute
gradients. This shared long-range map allows the accuracy of gradient
computation to benefit directly from improvements in flow map construction.
Building on this insight, we introduce a novel adjoint solver that solves the
adjoint equations directly on the flow map, enabling long-range and accurate
differentiation of incompressible flows without differentiating intermediate
numerical steps or storing intermediate variables, as required in conventional
adjoint methods. To further improve efficiency, we propose a long-short
time-sparse flow map representation for evolving adjoint variables. Our
approach has low memory usage, requiring only 6.53GB of data at a resolution of
$192^3$ while preserving high accuracy in tracking vorticity, enabling new
differentiable simulation tasks that require precise identification,
prediction, and control of vortex dynamics.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [332] [Multimodal Detection of Fake Reviews using BERT and ResNet-50](https://arxiv.org/abs/2511.00020)
*Suhasnadh Reddy Veluru,Sai Teja Erukude,Viswa Chaitanya Marella*

Main category: cs.AI

TL;DR: 本文提出了一种多模态假评论检测框架，结合文本和视觉特征，显著提升了检测准确性，并展示了多模态学习在维护数字信任中的重要性。


<details>
  <summary>Details</summary>
Motivation: 当前数字商务环境中，用户生成评论对消费者行为、产品声誉和平台信誉至关重要，但虚假或误导性评论的泛滥（通常由机器人、付费代理或AI模型生成）对评论生态系统中的信任和透明度构成重大威胁。现有检测模型主要依赖单模态（通常是文本）数据，因此无法捕捉不同模态间的语义不一致性。

Method: 提出了一种结合BERT编码的文本特征和ResNet-50提取的视觉特征的多模态假评论检测框架，通过分类头融合这些表示以联合预测评论真实性。

Result: 多模态模型在测试集上的F1得分为0.934，优于单模态基线模型。混淆矩阵和定性分析突出了模型检测细微不一致性的能力，例如夸张的文本赞美与无关或低质量图像的配对，这在欺骗性内容中常见。

Conclusion: 本研究展示了多模态学习在维护数字信任中的关键作用，并提供了跨各种在线平台的内容审核的可扩展解决方案。

Abstract: In the current digital commerce landscape, user-generated reviews play a
critical role in shaping consumer behavior, product reputation, and platform
credibility. However, the proliferation of fake or misleading reviews often
generated by bots, paid agents, or AI models poses a significant threat to
trust and transparency within review ecosystems. Existing detection models
primarily rely on unimodal, typically textual, data and therefore fail to
capture semantic inconsistencies across different modalities. To address this
gap, a robust multimodal fake review detection framework is proposed,
integrating textual features encoded with BERT and visual features extracted
using ResNet-50. These representations are fused through a classification head
to jointly predict review authenticity. To support this approach, a curated
dataset comprising 21,142 user-uploaded images across food delivery,
hospitality, and e-commerce domains was utilized. Experimental results indicate
that the multimodal model outperforms unimodal baselines, achieving an F1-score
of 0.934 on the test set. Additionally, the confusion matrix and qualitative
analysis highlight the model's ability to detect subtle inconsistencies, such
as exaggerated textual praise paired with unrelated or low-quality images,
commonly found in deceptive content. This study demonstrates the critical role
of multimodal learning in safeguarding digital trust and offers a scalable
solution for content moderation across various online platforms.

</details>


### [333] [Graph-Attentive MAPPO for Dynamic Retail Pricing](https://arxiv.org/abs/2511.00039)
*Krishna Kumar Neelakanta Pillai Santha Kumari Amma*

Main category: cs.AI

TL;DR: 研究比较了MAPPO与MAPPO+GAT在零售定价中的应用，证明后者通过产品图信息共享提升了性能，为多产品定价提供了更优解决方案。


<details>
  <summary>Details</summary>
Motivation: 零售动态定价需要适应需求变化并协调相关产品决策的策略。

Method: 比较了多智能体近端策略优化（MAPPO）基线与图注意力增强变体（MAPPO+GAT），后者利用产品间的学习交互。

Result: MAPPO为组合级价格控制提供了稳健且可重复的基础，而MAPPO+GAT通过在产品图上共享信息进一步提升了性能，且未引发过度价格波动。

Conclusion: 图集成多智能体强化学习（MARL）为动态零售定价提供了比独立学习器更具可扩展性和稳定性的解决方案，在多产品决策中具有实际优势。

Abstract: Dynamic pricing in retail requires policies that adapt to shifting demand
while coordinating decisions across related products. We present a systematic
empirical study of multi-agent reinforcement learning for retail price
optimization, comparing a strong MAPPO baseline with a
graph-attention-augmented variant (MAPPO+GAT) that leverages learned
interactions among products. Using a simulated pricing environment derived from
real transaction data, we evaluate profit, stability across random seeds,
fairness across products, and training efficiency under a standardized
evaluation protocol. The results indicate that MAPPO provides a robust and
reproducible foundation for portfolio-level price control, and that MAPPO+GAT
further enhances performance by sharing information over the product graph
without inducing excessive price volatility. These results indicate that
graph-integrated MARL provides a more scalable and stable solution than
independent learners for dynamic retail pricing, offering practical advantages
in multi-product decision-making.

</details>


### [334] [GEPOC Parameters - Open Source Parametrisation and Validation for Austria, Version 2.0](https://arxiv.org/abs/2511.00048)
*Martin Bicher,Maximilian Viehauser,Daniele Giannandrea,Hannah Kastinger,Dominik Brunmeir,Claire Rippinger,Christoph Urach,Niki Popper*

Main category: cs.AI

TL;DR: GEPOC是针对人口研究问题的模型集合，本文详细描述了基于公开数据为奥地利计算参数的方法，并验证了GEPOC ABM模型。


<details>
  <summary>Details</summary>
Motivation: 为特定国家或地区有效应用GEPOC模型，需要稳定且可复现的数据处理流程。

Method: 使用自由和公开可访问的数据，通过聚合、分解、融合、清洗和缩放等算法计算模型参数。

Result: 提供了完整的参数文件描述，并进行了GEPOC ABM模型的广泛验证研究。

Conclusion: 该工作详细描述了基于公开数据为奥地利计算GEPOC模型参数的完整数据处理方法，并特别强调了GEPOC ABM模型参数的验证研究。

Abstract: GEPOC, short for Generic Population Concept, is a collection of models and
methods for analysing population-level research questions. For the valid
application of the models for a specific country or region, stable and
reproducible data processes are necessary, which provide valid and ready-to-use
model parameters. This work contains a complete description of the
data-processing methods for computation of model parameters for Austria, based
exclusively on freely and publicly accessible data. In addition to the
description of the source data used, this includes all algorithms used for
aggregation, disaggregation, fusion, cleansing or scaling of the data, as well
as a description of the resulting parameter files. The document places
particular emphasis on the computation of parameters for the most important
GEPOC model, GEPOC ABM, a continuous-time agent-based population model. An
extensive validation study using this particular model was made and is
presented at the end of this work.

</details>


### [335] [QuantumBench: A Benchmark for Quantum Problem Solving](https://arxiv.org/abs/2511.00092)
*Shunya Minami,Tatsuya Ishigaki,Ikko Hamamura,Taku Mikuriya,Youmi Ma,Naoaki Okazaki,Hiroya Takamura,Yohichi Suzuki,Tadashi Kadowaki*

Main category: cs.AI

TL;DR: QuantumBench是一个针对量子科学领域的LLM评估基准，包含800个多选题，用于测试LLM在非直观领域的理解与应用能力。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在科学工作流中的广泛应用，需要评估其是否准确捕捉领域特定知识和符号，因为通用基准很少反映这些需求。

Method: 研究者利用公开材料汇编了约800个问题及其答案，涵盖量子科学的九个领域，并将其组织为一个八选项的多选题数据集。

Result: 使用QuantumBench评估了几个现有LLM，并分析了它们在量子领域的表现，包括对问题格式变化的敏感性。

Conclusion: QuantumBench是首个针对量子科学领域设计的LLM评估数据集，旨在指导LLM在量子研究中的有效应用。

Abstract: Large language models are now integrated into many scientific workflows,
accelerating data analysis, hypothesis generation, and design space
exploration. In parallel with this growth, there is a growing need to carefully
evaluate whether models accurately capture domain-specific knowledge and
notation, since general-purpose benchmarks rarely reflect these requirements.
This gap is especially clear in quantum science, which features non-intuitive
phenomena and requires advanced mathematics. In this study, we introduce
QuantumBench, a benchmark for the quantum domain that systematically examine
how well LLMs understand and can be applied to this non-intuitive field. Using
publicly available materials, we compiled approximately 800 questions with
their answers spanning nine areas related to quantum science and organized them
into an eight-option multiple-choice dataset. With this benchmark, we evaluate
several existing LLMs and analyze their performance in the quantum domain,
including sensitivity to changes in question format. QuantumBench is the first
LLM evaluation dataset built for the quantum domain, and it is intended to
guide the effective use of LLMs in quantum research.

</details>


### [336] [Engineering.ai: A Platform for Teams of AI Engineers in Computational Design](https://arxiv.org/abs/2511.00122)
*Ran Xu,Yupeng Qi,Jingsen Feng,Xu Chu*

Main category: cs.AI

TL;DR: Engineering.ai is a multi-agent AI platform for computational design, validated by fully autonomous UAV wing optimization with 100% success.


<details>
  <summary>Details</summary>
Motivation: To address the substantial time and cost demands of human engineering teams by automating complex design tasks through AI collaboration.

Method: The framework uses a hierarchical multi-agent architecture with specialized AI engineers (Aerodynamics, Structural, Acoustic, Optimization) powered by LLMs, integrating tools like FreeCAD, OpenFOAM, and CalculiX for parallel multidisciplinary simulations.

Result: The system achieved a 100% success rate across over 400 parametric configurations with no failures or manual interventions.

Conclusion: Engineering.ai demonstrates the potential of AI engineers to autonomously perform complex engineering tasks, validated by a 100% success rate in UAV wing optimization.

Abstract: In modern engineering practice, human engineers collaborate in specialized
teams to design complex products, with each expert completing their respective
tasks while communicating and exchanging results and data with one another.
While this division of expertise is essential for managing multidisciplinary
complexity, it demands substantial development time and cost. Recently, we
introduced OpenFOAMGPT (1.0, 2.0), which functions as an autonomous AI engineer
for computational fluid dynamics, and turbulence.ai, which can conduct
end-to-end research in fluid mechanics draft publications and PhD theses.
Building upon these foundations, we present Engineering.ai, a platform for
teams of AI engineers in computational design. The framework employs a
hierarchical multi-agent architecture where a Chief Engineer coordinates
specialized agents consisting of Aerodynamics, Structural, Acoustic, and
Optimization Engineers, each powered by LLM with domain-specific knowledge.
Agent-agent collaboration is achieved through file-mediated communication for
data provenance and reproducibility, while a comprehensive memory system
maintains project context, execution history, and retrieval-augmented domain
knowledge to ensure reliable decision-making across the workflow. The system
integrates FreeCAD, Gmsh, OpenFOAM, CalculiX, and BPM acoustic analysis,
enabling parallel multidisciplinary simulations while maintaining computational
accuracy. The framework is validated through UAV wing optimization. This work
demonstrates that agentic-AI-enabled AI engineers has the potential to perform
complex engineering tasks autonomously. Remarkably, the automated workflow
achieved a 100% success rate across over 400 parametric configurations, with
zero mesh generation failures, solver convergence issues, or manual
interventions required, validating that the framework is trustworthy.

</details>


### [337] [ARC-GEN: A Mimetic Procedural Benchmark Generator for the Abstraction and Reasoning Corpus](https://arxiv.org/abs/2511.00162)
*Michael D. Moffitt*

Main category: cs.AI

TL;DR: ARC-GEN是一个开源程序生成器，扩展ARC-AGI数据集并用于2025年Code Golf的基准测试。


<details>
  <summary>Details</summary>
Motivation: ARC-AGI是目前最引人注目且具有挑战性的基准测试之一，用于衡量技能获取效率，但现有数据集的示范集规模有限，限制了算法的训练效果。

Method: 介绍了ARC-GEN，这是一个开源的程序生成器，覆盖所有400个任务，并更贴近初始ARC-AGI-1版本的分布特性和特征。

Result: ARC-GEN成功扩展了原始ARC-AGI训练数据集，并用于验证2025年Google Code Golf Championship提交程序的正确性。

Conclusion: ARC-GEN是一个开源的程序生成器，旨在尽可能忠实扩展ARC-AGI训练数据集，为2025年Google Code Golf Championship提供静态基准测试。

Abstract: The Abstraction and Reasoning Corpus remains one of the most compelling and
challenging benchmarks for tracking progress toward achieving Artificial
General Intelligence. In contrast to other evaluation datasets designed to
assess an agent's task-specific skills or accumulated knowledge, the ARC-AGI
suite is specifically targeted at measuring skill acquisition efficiency, a
trait that has (so far) been lacking in even the most sophisticated machine
learning systems. For algorithms that require extensive intra-task exemplars, a
significant constraint imposed by ARC-AGI is the modest cardinality of its
demonstration set, comprising a small number of $\langle$ input, output
$\rangle$ grids per task specifying the corresponding transformation. To
embellish the space of viable sample pairs, this paper introduces ARC-GEN, an
open-source procedural generator aimed at extending the original ARC-AGI
training dataset as faithfully as possible. Unlike prior efforts, our generator
is both exhaustive (covering all four-hundred tasks) and mimetic (more closely
honoring the distributional properties and characteristics embodied in the
initial ARC-AGI-1 release). We also discuss the use of this generator in
establishing a static benchmark suite to verify the correctness of programs
submitted to the 2025 Google Code Golf Championship.

</details>


### [338] [Incremental Selection of Most-Filtering Conjectures and Proofs of the Selected Conjectures](https://arxiv.org/abs/2511.00194)
*Jovial Cheukam Ngouonou,Ramiz Gindullin,Claude-Guy Quimper,Nicolas Beldiceanu,Remi Douence*

Main category: cs.AI

TL;DR: 改进的增量选择算法，成功证明所有选定猜想。


<details>
  <summary>Details</summary>
Motivation: 为了提升选择算法的效率和准确性，特别是在处理增量选择问题时。

Method: 改进的增量选择算法，基于[1]中的选择算法进行优化。

Result: 所有选定的猜想均被证明。

Conclusion: 本文提出的改进增量选择算法成功证明了所有选定的猜想。

Abstract: We present an improved incremental selection algorithm of the selection
algorithm presented in [1] and prove all the selected conjectures.

</details>


### [339] [Advancing Cognitive Science with LLMs](https://arxiv.org/abs/2511.00206)
*Dirk U. Wulff,Rui Mata*

Main category: cs.AI

TL;DR: LLMs能辅助认知科学解决知识整合问题，但需谨慎使用以补充人类专家，而非替代。


<details>
  <summary>Details</summary>
Motivation: 认知科学因多面性和跨学科性面临知识整合和概念清晰度的挑战，LLMs可能提供解决方案。

Method: 回顾了LLMs在当前认知科学中的应用及其局限性。

Result: LLMs在跨学科连接、理论形式化、清晰测量分类、通用性建模框架及捕捉个体差异方面具有潜力，但也存在局限性。

Conclusion: LLMs可以作为认知科学领域更综合和累积的工具，前提是明智地使用以补充而非取代人类专业知识。

Abstract: Cognitive science faces ongoing challenges in knowledge synthesis and
conceptual clarity, in part due to its multifaceted and interdisciplinary
nature. Recent advances in artificial intelligence, particularly the
development of large language models (LLMs), offer tools that may help to
address these issues. This review examines how LLMs can support areas where the
field has historically struggled, including establishing cross-disciplinary
connections, formalizing theories, developing clear measurement taxonomies,
achieving generalizability through integrated modeling frameworks, and
capturing contextual and individual variation. We outline the current
capabilities and limitations of LLMs in these domains, including potential
pitfalls. Taken together, we conclude that LLMs can serve as tools for a more
integrative and cumulative cognitive science when used judiciously to
complement, rather than replace, human expertise.

</details>


### [340] [Advancing AI Challenges for the United States Department of the Air Force](https://arxiv.org/abs/2511.00267)
*Christian Prothmann,Vijay Gadepally,Jeremy Kepner,Koley Borchard,Luca Carlone,Zachary Folcik,J. Daniel Grith,Michael Houle,Jonathan P. How,Nathan Hughes,Ifueko Igbinedion,Hayden Jananthan,Tejas Jayashankar,Michael Jones,Sertac Karaman,Binoy G. Kurien,Alejandro Lancho,Giovanni Lavezzi,Gary C. F. Lee,Charles E. Leiserson,Richard Linares,Lindsey McEvoy,Peter Michaleas,Chasen Milner,Alex Pentland,Yury Polyanskiy,Jovan Popovich,Jeffrey Price,Tim W. Reid,Stephanie Riley,Siddharth Samsi,Peter Saunders,Olga Simek,Mark S. Veillette,Amir Weiss,Gregory W. Wornell,Daniela Rus,Scott T. Ruppel*

Main category: cs.AI

TL;DR: DAF-MIT AI Accelerator项目通过公开挑战问题推动AI研究，提供数据集促进开源解决方案，成功应用于国防和民用领域。


<details>
  <summary>Details</summary>
Motivation: 通过基础性AI进步，扩大美国在国防和民用领域的竞争优势。

Method: 开发并发布公开挑战问题，提供大型、公开可用的AI就绪数据集，以促进开源解决方案并吸引更广泛的学术和私营部门AI生态系统参与。

Result: 持续和新的挑战问题已成功促进了AI研究和AI技术的应用。

Conclusion: DAF-MIT AI Accelerator项目通过公开挑战问题，成功地推动了AI研究和技术应用，扩大了美国在国防和民用领域的竞争优势。

Abstract: The DAF-MIT AI Accelerator is a collaboration between the United States
Department of the Air Force (DAF) and the Massachusetts Institute of Technology
(MIT). This program pioneers fundamental advances in artificial intelligence
(AI) to expand the competitive advantage of the United States in the defense
and civilian sectors. In recent years, AI Accelerator projects have developed
and launched public challenge problems aimed at advancing AI research in
priority areas. Hallmarks of AI Accelerator challenges include large, publicly
available, and AI-ready datasets to stimulate open-source solutions and engage
the wider academic and private sector AI ecosystem. This article supplements
our previous publication, which introduced AI Accelerator challenges. We
provide an update on how ongoing and new challenges have successfully
contributed to AI research and applications of AI technologies.

</details>


### [341] [Better Call CLAUSE: A Discrepancy Benchmark for Auditing LLMs Legal Reasoning Capabilities](https://arxiv.org/abs/2511.00340)
*Manan Roy Choudhury,Adithya Chandramouli,Mannan Anand,Vivek Gupta*

Main category: cs.AI

TL;DR: CLAUSE基准首次系统评估了大型语言模型在法律合同中的脆弱性，发现其在识别和解释细微法律错误方面存在明显不足。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏系统评估大型语言模型在法律工作中可靠性的基准，研究团队开发了CLAUSE，以测试模型在复杂、对抗性法律场景中的脆弱性。

Method: 研究者引入了CLAUSE基准，通过从CUAD和ContractNLI等数据集中生成7500多份扰动合同，并使用基于角色的流程产生10种异常类别，再通过检索增强生成（RAG）系统验证其法律忠实度。

Result: 分析显示，领先的大型语言模型在检测嵌入的法律错误方面表现不佳，尤其在法律解释方面存在显著困难。

Conclusion: 该研究揭示了当前大型语言模型在法律推理中的关键弱点，尤其是在识别和解释细微法律错误方面的不足，并提出了通过CLAUSE基准来识别和纠正这些缺陷的路径。

Abstract: The rapid integration of large language models (LLMs) into high-stakes legal
work has exposed a critical gap: no benchmark exists to systematically
stress-test their reliability against the nuanced, adversarial, and often
subtle flaws present in real-world contracts. To address this, we introduce
CLAUSE, a first-of-its-kind benchmark designed to evaluate the fragility of an
LLM's legal reasoning. We study the capabilities of LLMs to detect and reason
about fine-grained discrepancies by producing over 7500 real-world perturbed
contracts from foundational datasets like CUAD and ContractNLI. Our novel,
persona-driven pipeline generates 10 distinct anomaly categories, which are
then validated against official statutes using a Retrieval-Augmented Generation
(RAG) system to ensure legal fidelity. We use CLAUSE to evaluate leading LLMs'
ability to detect embedded legal flaws and explain their significance. Our
analysis shows a key weakness: these models often miss subtle errors and
struggle even more to justify them legally. Our work outlines a path to
identify and correct such reasoning failures in legal AI.

</details>


### [342] [Diverse Human Value Alignment for Large Language Models via Ethical Reasoning](https://arxiv.org/abs/2511.00379)
*Jiahao Wang,Songkai Xue,Jinghui Li,Xiaozhen Wang*

Main category: cs.AI

TL;DR: 本文提出了一种结构化五步伦理推理框架，通过上下文分析和多视角评估，显著提升了LLM与全球多元文化价值观的对齐能力。


<details>
  <summary>Details</summary>
Motivation: 确保大型语言模型（LLMs）与不同地区和文化的多样且不断演变的人类价值观对齐是AI伦理中的关键挑战。当前的对齐方法往往产生表面一致性而非真正的伦理理解，无法应对人类价值观的复杂性和上下文依赖性。

Method: 提出了一种新颖的伦理推理范式，包括结构化的五步流程：上下文事实收集、层级化社会规范识别、选项生成、多视角伦理影响分析和反思。该方法可通过提示工程或监督微调实现。

Result: 在专为区域价值对齐设计的SafeWorld基准测试中，实验结果表明我们的框架显著优于基线方法，提高了LLM与多样人类价值观的对齐能力，实现了更准确的社会规范识别和更文化适宜性推理。

Conclusion: 本文提供了一种通过跨学科研究开发更有效与全球社会多元价值观对齐的大型语言模型的具体途径。

Abstract: Ensuring that Large Language Models (LLMs) align with the diverse and
evolving human values across different regions and cultures remains a critical
challenge in AI ethics. Current alignment approaches often yield superficial
conformity rather than genuine ethical understanding, failing to address the
complex, context-dependent nature of human values. In this paper, we propose a
novel ethical reasoning paradigm for LLMs inspired by well-established ethical
decision-making models, aiming at enhancing diverse human value alignment
through deliberative ethical reasoning. Our framework consists of a structured
five-step process, including contextual fact gathering, hierarchical social
norm identification, option generation, multiple-lens ethical impact analysis,
and reflection. This theory-grounded approach guides LLMs through an
interpretable reasoning process that enhances their ability to understand
regional specificities and perform nuanced ethical analysis, which can be
implemented with either prompt engineering or supervised fine-tuning methods.
We perform evaluations on the SafeWorld benchmark that specially designed for
regional value alignment. Experimental results demonstrate our framework
significantly improves LLM alignment with diverse human values compared to
baseline methods, enabling more accurate social norm identification and more
culturally appropriate reasoning. Our work provides a concrete pathway toward
developing LLMs that align more effectively with the multifaceted values of
global societies through interdisciplinary research.

</details>


### [343] [Efficiency vs. Alignment: Investigating Safety and Fairness Risks in Parameter-Efficient Fine-Tuning of LLMs](https://arxiv.org/abs/2511.00382)
*Mina Taraghi,Yann Pequignot,Amin Nikanjam,Mohamed Amine Merzouk,Foutse Khomh*

Main category: cs.AI

TL;DR: 研究发现适配器方法（LoRA、IA3）在保持安全性和公平性方面表现优于提示方法（Prompt-Tuning、P-Tuning），建议在安全关键部署中优先采用前者。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）的适应可以提升特定下游任务的性能，但可能降低模型的安全性或公平性，因此需要系统评估不同微调技术在这些关键维度上的权衡。

Method: 应用了四种广泛使用的参数高效微调方法（LoRA、IA3、Prompt-Tuning和P-Tuning），对四个指令调优模型家族（Meta-Llama-3-8B、Qwen2.5-7B、Mistral-7B和Gemma-7B）进行了系统性评估，共评估了235个微调变体。

Result: 适配器方法（LoRA、IA3）倾向于提高安全性评分且对公平性影响较小，而提示方法（Prompt-Tuning、P-Tuning）通常降低安全性并导致更大的公平性退化。不同基础模型对对齐变化有显著影响。

Conclusion: 研究建议在安全关键部署中，应选择对齐良好的基础模型，优先采用基于适配器的PEFT方法，并对安全和公平性进行类别特定审计。

Abstract: Organizations are increasingly adopting and adapting Large Language Models
(LLMs) hosted on public repositories such as HuggingFace. Although these
adaptations often improve performance on specialized downstream tasks, recent
evidence indicates that they can also degrade a model's safety or fairness.
Since different fine-tuning techniques may exert distinct effects on these
critical dimensions, this study undertakes a systematic assessment of their
trade-offs. Four widely used Parameter-Efficient Fine-Tuning methods, LoRA,
IA3, Prompt-Tuning, and P-Tuning, are applied to four instruction-tuned model
families (Meta-Llama-3-8B, Qwen2.5-7B, Mistral-7B, and Gemma-7B). In total, 235
fine-tuned variants are evaluated across eleven safety hazard categories and
nine demographic fairness dimensions. The results show that adapter-based
approaches (LoRA, IA3) tend to improve safety scores and are the least
disruptive to fairness, retaining higher accuracy and lower bias scores. In
contrast, prompt-based methods (Prompt-Tuning and P-Tuning) generally reduce
safety and cause larger fairness regressions, with decreased accuracy and
increased bias. Alignment shifts are strongly moderated by base model type:
LLaMA remains stable, Qwen records modest gains, Gemma experiences the steepest
safety decline, and Mistral, which is released without an internal moderation
layer, displays the greatest variance. Improvements in safety do not
necessarily translate into improvements in fairness, and no single
configuration optimizes all fairness metrics simultaneously, indicating an
inherent trade-off between these objectives. These findings suggest a practical
guideline for safety-critical deployments: begin with a well-aligned base
model, favour adapter-based PEFT, and conduct category-specific audits of both
safety and fairness.

</details>


### [344] [A Multimodal Framework for Depression Detection during Covid-19 via Harvesting Social Media: A Novel Dataset and Method](https://arxiv.org/abs/2511.00424)
*Ashutosh Anshul,Gumpili Sai Pranav,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.AI

TL;DR: 提出多模态框架（文本+用户+图像）检测社交媒体用户抑郁症，结合URL和图像文本分析，VNN生成图像特征，新冠数据集验证效果优于现有方法2%-8%。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情导致心理健康问题激增，但传统方法因数据稀疏性和多模态信息利用不足而受限，社交媒体平台成为检测抑郁症的重要数据来源。

Method: 结合文本、用户特定信息和图像分析的多模态框架，包括提取推文中的URL和图像文本内容，以及通过视觉神经网络（VNN）生成图像嵌入特征。

Result: 模型在基准数据集和新冠数据集上均优于现有方法，验证了多模态特征的有效性，并提供了用户心理状态的有价值洞察。

Conclusion: 该论文提出的多模态框架在抑郁症检测方面表现出色，尤其在新冠疫情期间的数据集上验证了其有效性，比现有方法提高了2%-8%的准确率。

Abstract: The recent coronavirus disease (Covid-19) has become a pandemic and has
affected the entire globe. During the pandemic, we have observed a spike in
cases related to mental health, such as anxiety, stress, and depression.
Depression significantly influences most diseases worldwide, making it
difficult to detect mental health conditions in people due to unawareness and
unwillingness to consult a doctor. However, nowadays, people extensively use
online social media platforms to express their emotions and thoughts. Hence,
social media platforms are now becoming a large data source that can be
utilized for detecting depression and mental illness. However, existing
approaches often overlook data sparsity in tweets and the multimodal aspects of
social media. In this paper, we propose a novel multimodal framework that
combines textual, user-specific, and image analysis to detect depression among
social media users. To provide enough context about the user's emotional state,
we propose (i) an extrinsic feature by harnessing the URLs present in tweets
and (ii) extracting textual content present in images posted in tweets. We also
extract five sets of features belonging to different modalities to describe a
user. Additionally, we introduce a Deep Learning model, the Visual Neural
Network (VNN), to generate embeddings of user-posted images, which are used to
create the visual feature vector for prediction. We contribute a curated
Covid-19 dataset of depressed and non-depressed users for research purposes and
demonstrate the effectiveness of our model in detecting depression during the
Covid-19 outbreak. Our model outperforms existing state-of-the-art methods over
a benchmark dataset by 2%-8% and produces promising results on the Covid-19
dataset. Our analysis highlights the impact of each modality and provides
valuable insights into users' mental and emotional states.

</details>


### [345] [GraphChain: Large Language Models for Large-scale Graph Analysis via Tool Chaining](https://arxiv.org/abs/2511.00457)
*Chunyu Wei,Wenji Hu,Xingjia Hao,Xin Wang,Yifan Yang,Yueguo Chen,Yang Tian,Yunhai Wang*

Main category: cs.AI

TL;DR: GraphChain通过动态工具序列和结构适应，提升LLM在图分析中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在大规模图分析中面临的上下文限制和推理不灵活问题。

Method: 采用渐进图蒸馏（强化学习机制）和结构感知测试时适应（基于谱属性和轻量适配器）。

Result: 实验显示GraphChain在可扩展性和适应性上优于现有方法。

Conclusion: GraphChain通过动态工具序列和结构感知适应，显著提升了LLM在大规模图分析中的表现。

Abstract: Large Language Models (LLMs) face significant limitations when applied to
large-scale graphs, struggling with context constraints and inflexible
reasoning. We present GraphChain, a framework that enables LLMs to analyze
complex graphs through dynamic sequences of specialized tools, mimicking human
exploratory intelligence. Our approach introduces two key innovations: (1)
Progressive Graph Distillation, a reinforcement learning mechanism that
generates optimized tool sequences balancing task relevance with information
compression, and (2) Structure-aware Test-Time Adaptation, which efficiently
tailors tool selection strategies to diverse graph topologies using spectral
properties and lightweight adapters without costly retraining. Experiments show
GraphChain significantly outperforms prior methods, enabling scalable and
adaptive LLM-driven graph analysis.

</details>


### [346] [Reimagining Safety Alignment with An Image](https://arxiv.org/abs/2511.00509)
*Yifan Xia,Guorui Chen,Wenqian Yu,Zhijiang Li,Philip Torr,Jindong Gu*

Main category: cs.AI

TL;DR: Magic Image通过优化视觉提示提升MLLMs安全性并减少过度拒绝，实验显示其有效平衡安全与性能，适用于多价值体系。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多样化应用中表现出色，但面临生成有害内容和过度拒绝良性查询的双重挑战，传统方法如SFT和RLHF因成本高且无法支持多价值体系而效果有限，多模态大型语言模型（MLLMs）中这些问题更为突出。

Method: 提出Magic Image，一种基于优化驱动的视觉提示框架，利用有害/良性样本优化图像提示，使单一模型能适应不同价值体系并与给定安全偏好更好对齐，无需参数更新。

Result: 实验证明，该方法在多样化数据集中实现了安全性与有效性的更好平衡，同时保持了模型性能。

Conclusion: Magic Image框架通过优化视觉提示，成功提升了多模态大语言模型的安全性，同时减少了过度拒绝问题，为可部署的MLLM安全对齐提供了实用解决方案。

Abstract: Large language models (LLMs) excel in diverse applications but face dual
challenges: generating harmful content under jailbreak attacks and over-refusal
of benign queries due to rigid safety mechanisms. These issues are further
complicated by the need to accommodate different value systems and precisely
align with given safety preferences. Moreover, traditional methods like SFT and
RLHF lack this capability due to their costly parameter tuning requirements and
inability to support multiple value systems within a single model. These
problems are more obvious in multimodal large language models (MLLMs),
especially in terms of heightened over-refusal in cross-modal tasks and new
security risks arising from expanded attack surfaces. We propose Magic Image,
an optimization-driven visual prompt framework that enhances security while
reducing over-refusal. By optimizing image prompts using harmful/benign
samples, our method enables a single model to adapt to different value systems
and better align with given safety preferences without parameter updates.
Experiments demonstrate improved safety-effectiveness balance across diverse
datasets while preserving model performance, offering a practical solution for
deployable MLLM safety alignment.

</details>


### [347] [Efficient Generation of Binary Magic Squares](https://arxiv.org/abs/2511.00547)
*Alain Riou*

Main category: cs.AI

TL;DR: 提出生成二进制幻方的简单算法，证明其最优复杂度，扩展至非方形情况，并发布Python实现。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个简单且理论复杂度最优的算法来生成二进制幻方，并探索其在非方形情况下的应用。

Method: 通过归纳法证明算法总能生成有效的BMS，并扩展算法以处理非方形BMS。

Result: 算法能生成有效的BMS，且在非方形情况下也适用，并提供了GPU加速的并行实现。

Conclusion: 该论文提出了一种生成二进制幻方（BMS）的算法，并证明了其理论复杂度最优。同时，该算法被扩展用于非方形BMS，并公开发布了两个Python实现。

Abstract: We propose a simple algorithm for generating Binary Magic Squares (BMS),
i.e., square binary matrices where the sum of all rows and all columns are
equal. We show by induction that our algorithm always returns valid BMS with
optimal theoretical complexity. We then extend our study to non-square Binary
Magic Squares, formalize conditions on the sum of rows and columns for these
BMS to exist, and show that a slight variant of our first algorithm can
generate provably generate them. Finally, we publicly release two
implementations of our algorithm as Python packages, including one that can
generate several BMS in parallel using GPU acceleration.

</details>


### [348] [Single-agent Reinforcement Learning Model for Regional Adaptive Traffic Signal Control](https://arxiv.org/abs/2511.00551)
*Qiang Li,Ningjing Zeng,Lina Yu*

Main category: cs.AI

TL;DR: 该研究提出了一种基于单智能体强化学习的区域自适应交通信号控制模型，利用探针车辆数据定义队列长度，通过协调多交叉口控制有效缓解拥堵。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要采用多智能体框架，但其可扩展性存在挑战。交通信号控制问题本质上需要单智能体框架，因为交通信号控制依赖于单一控制中心的集中管理。

Method: 该研究设计了一个与探针车辆技术兼容的单智能体强化学习模型，关键组件包括状态、动作和奖励函数的定义。状态和奖励函数基于队列长度定义，动作设计用于调节队列动态。队列长度定义与传统定义略有不同，但能通过探针车辆的链路旅行时间数据可靠估计。

Result: 实验结果表明，该模型通过协调多交叉口控制，有效缓解了大范围区域拥堵水平。

Conclusion: 该研究提出的基于单智能体强化学习的区域自适应交通信号控制模型，通过协调多交叉口控制，有效缓解了大范围区域拥堵水平。

Abstract: Several studies have employed reinforcement learning (RL) to address the
challenges of regional adaptive traffic signal control (ATSC) and achieved
promising results. In this field, existing research predominantly adopts
multi-agent frameworks. However, the adoption of multi-agent frameworks
presents challenges for scalability. Instead, the Traffic signal control (TSC)
problem necessitates a single-agent framework. TSC inherently relies on
centralized management by a single control center, which can monitor traffic
conditions across all roads in the study area and coordinate the control of all
intersections. This work proposes a single-agent RL-based regional ATSC model
compatible with probe vehicle technology. Key components of the RL design
include state, action, and reward function definitions. To facilitate learning
and manage congestion, both state and reward functions are defined based on
queue length, with action designed to regulate queue dynamics. The queue length
definition used in this study differs slightly from conventional definitions
but is closely correlated with congestion states. More importantly, it allows
for reliable estimation using link travel time data from probe vehicles. With
probe vehicle data already covering most urban roads, this feature enhances the
proposed method's potential for widespread deployment. The method was
comprehensively evaluated using the SUMO simulation platform. Experimental
results demonstrate that the proposed model effectively mitigates large-scale
regional congestion levels via coordinated multi-intersection control.

</details>


### [349] [PreferThinker: Reasoning-based Personalized Image Preference Assessment](https://arxiv.org/abs/2511.00609)
*Shengqi Xu,Xinpeng Zhou,Yabo Zhang,Ming Liu,Tao Liang,Tianyu Zhang,Yalong Bai,Zuxuan Wu,Wangmeng Zuo*

Main category: cs.AI

TL;DR: 提出基于推理的个性化图像偏好评估框架，利用共同偏好档案和两阶段训练策略，显著提升评估效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理个性化偏好，因用户数据稀缺且多样化。通过构建跨用户的共同偏好档案，利用大规模数据训练，解决了这一问题。

Method: 提出了一种基于推理的个性化图像偏好评估框架，采用“预测-评估”范式，包括预测用户偏好档案和基于档案的评估。采用两阶段训练策略：监督微调强化推理能力，强化学习优化评估路径。

Result: 实验结果表明，该方法在个性化图像偏好评估任务上表现优异。

Conclusion: 该方法通过预测用户偏好档案和基于推理的评估框架，显著提升了个性化图像偏好评估的效果，实验证明了其优越性。

Abstract: Personalized image preference assessment aims to evaluate an individual
user's image preferences by relying only on a small set of reference images as
prior information. Existing methods mainly focus on general preference
assessment, training models with large-scale data to tackle well-defined tasks
such as text-image alignment. However, these approaches struggle to handle
personalized preference because user-specific data are scarce and not easily
scalable, and individual tastes are often diverse and complex. To overcome
these challenges, we introduce a common preference profile that serves as a
bridge across users, allowing large-scale user data to be leveraged for
training profile prediction and capturing complex personalized preferences.
Building on this idea, we propose a reasoning-based personalized image
preference assessment framework that follows a \textit{predict-then-assess}
paradigm: it first predicts a user's preference profile from reference images,
and then provides interpretable, multi-dimensional scores and assessments of
candidate images based on the predicted profile. To support this, we first
construct a large-scale Chain-of-Thought (CoT)-style personalized assessment
dataset annotated with diverse user preference profiles and high-quality
CoT-style reasoning, enabling explicit supervision of structured reasoning.
Next, we adopt a two-stage training strategy: a cold-start supervised
fine-tuning phase to empower the model with structured reasoning capabilities,
followed by reinforcement learning to incentivize the model to explore more
reasonable assessment paths and enhance generalization. Furthermore, we propose
a similarity-aware prediction reward to encourage better prediction of the
user's preference profile, which facilitates more reasonable assessments
exploration. Extensive experiments demonstrate the superiority of the proposed
method.

</details>


### [350] [DTS: Enhancing Large Reasoning Models via Decoding Tree Sketching](https://arxiv.org/abs/2511.00640)
*Zicheng Xu,Guanchu Wang,Yu-Neng Chuang,Guangyao Zheng,Alexander S. Szalay,Zirui Liu,Vladimir Braverman*

Main category: cs.AI

TL;DR: DTS是一种模型无关的解码框架，通过动态修剪推理空间提升大型推理模型的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂任务中存在过度思考问题，长推理路径不仅增加成本还可能降低准确性，需优化推理效率。

Method: 提出DTS解码框架，通过高熵标记选择性分支和早期停止策略，动态修剪推理空间，选择最短完成路径。

Result: 在AIME2024和AIME2025数据集上，DTS将准确率提升8%，平均推理长度减少23%，重复频率降低12%。

Conclusion: DTS框架通过选择性分支和高熵标记的早期停止，有效提升了大型推理模型的效率和准确性，无需额外训练或监督。

Abstract: Large Reasoning Models (LRMs) demonstrate strong performance on complex
reasoning tasks, yet they often suffer from overthinking, producing excessively
long chain-of-thought (CoT) traces that increase inference cost and may degrade
accuracy. Our analysis reveals a clear anti-correlation between reasoning
length and accuracy, where across multiple stochastic decodes, the short
reasoning paths consistently achieve the highest correctness, while longer ones
accumulate errors and repetitions. These short optimal reasoning paths can be
found ideally through full enumeration of the reasoning space. However, the
tree-structured reasoning space grows exponentially with sequence length,
rendering exhaustive exploration infeasible. To address this, we propose DTS, a
model-agnostic decoding framework that sketches the reasoning space by
selectively branching at high-entropy tokens and applies early stopping to
select the shortest completed reasoning path. This approach approximates the
optimal solution that enhances both efficiency and accuracy, without requiring
additional training or supervision. Experiments on AIME2024 and AIME2025
datasets with DeepSeek-R1-Distill-Qwen-7B and 1.5B show that DTS improves
accuracy by up to 8%, reduces average reasoning length by 23%, and decreases
repetition frequency by 12%, demonstrating DTS's ability for scalable and
efficient LRM reasoning.

</details>


### [351] [Leveraging Multi-Agent System (MAS) and Fine-Tuned Small Language Models (SLMs) for Automated Telecom Network Troubleshooting](https://arxiv.org/abs/2511.00651)
*Chenhua Shi,Bhavika Jalli,Gregor Macdonald,John Zou,Wanlu Lei,Mridul Jain,Joji Philip*

Main category: cs.AI

TL;DR: 论文提出了一种基于多代理系统和大型语言模型的自动化网络故障诊断框架，显著提升了故障处理效率，减少了对专家手动干预的需求。


<details>
  <summary>Details</summary>
Motivation: 电信网络规模与复杂性不断增加，现有AI模型普遍存在范围狭窄、依赖大量标注数据且难以在异构部署中泛化的问题，导致故障诊断仍高度依赖专家手动操作。

Method: 论文提出了一种多代理系统（MAS），该系统利用AI/ML监控器检测故障，并通过动态激活多个代理（如协调器、解决方案规划器、执行器、数据检索器和根因分析器）来实现自动化的网络故障诊断和修复策略推荐。

Result: 实验结果表明，该框架在无线接入网（RAN）和核心网领域显著加速了故障诊断的自动化进程。

Conclusion: 该论文提出的多代理系统（MAS）框架通过利用大型语言模型（LLM）协调多个专用工具，显著提升了电信网络故障诊断的自动化水平，减少了对手动专家干预的依赖。

Abstract: Telecom networks are rapidly growing in scale and complexity, making
effective management, operation, and optimization increasingly challenging.
Although Artificial Intelligence (AI) has been applied to many telecom tasks,
existing models are often narrow in scope, require large amounts of labeled
data, and struggle to generalize across heterogeneous deployments.
Consequently, network troubleshooting continues to rely heavily on Subject
Matter Experts (SMEs) to manually correlate various data sources to identify
root causes and corrective actions. To address these limitations, we propose a
Multi-Agent System (MAS) that employs an agentic workflow, with Large Language
Models (LLMs) coordinating multiple specialized tools for fully automated
network troubleshooting. Once faults are detected by AI/ML-based monitors, the
framework dynamically activates agents such as an orchestrator, solution
planner, executor, data retriever, and root-cause analyzer to diagnose issues
and recommend remediation strategies within a short time frame. A key component
of this system is the solution planner, which generates appropriate remediation
plans based on internal documentation. To enable this, we fine-tuned a Small
Language Model (SLM) on proprietary troubleshooting documents to produce
domain-grounded solution plans. Experimental results demonstrate that the
proposed framework significantly accelerates troubleshooting automation across
both Radio Access Network (RAN) and Core network domains.

</details>


### [352] [Lifted Successor Generation in Numeric Planning](https://arxiv.org/abs/2511.00673)
*Dominik Drexler*

Main category: cs.AI

TL;DR: 扩展提升后继生成器支持数值前提条件，解决地面任务表示大小爆炸问题，多数基准领域表现良好。


<details>
  <summary>Details</summary>
Motivation: 解决传统规划任务中地面表示可能导致任务表示大小指数级爆炸的问题。

Method: 通过枚举替换一致性图中的最大团来生成地面动作，并增加数值前提条件，确保在特定条件下生成器的准确性。

Result: 在25个基准领域中，23个领域完全适用，1个领域部分适用，证明方法的有效性。

Conclusion: 该论文扩展了现有的提升后继生成器，支持数值前提条件，为未来在丰富规划片段上的提升规划研究铺平了道路。

Abstract: Most planners ground numeric planning tasks, given in a first-order-like
language, into a ground task representation. However, this can lead to an
exponential blowup in task representation size, which occurs in practice for
hard-to-ground tasks. We extend a state-of-the-art lifted successor generator
for classical planning to support numeric precondition applicability. The
method enumerates maximum cliques in a substitution consistency graph. Each
maximum clique represents a substitution for the variables of the action
schema, yielding a ground action. We augment this graph with numeric action
preconditions and prove the successor generator is exact under formally
specified conditions. When the conditions fail, our generator may list
inapplicable ground actions; a final applicability check filters these without
affecting completeness. However, this cannot happen in 23 of 25 benchmark
domains, and it occurs only in 1 domain. To the authors' knowledge, no other
lifted successor generator supports numeric action preconditions. This enables
future research on lifted planning for a very rich planning fragment.

</details>


### [353] [Ariadne: A Controllable Framework for Probing and Extending VLM Reasoning Boundaries](https://arxiv.org/abs/2511.00710)
*Minghe Shen,Zhuo Zhi,Chonghan Liu,Shuo Xing,Zhengzhong Tu,Che Liu*

Main category: cs.AI

TL;DR: RL后训练显著扩展了VLM在视觉空间任务中的能力，并在现实任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 探讨RL后训练是否能够真正扩展基础VLM的能力边界，尤其是在视觉中心的空间任务中。

Method: 采用Ariadne框架，利用合成迷宫进行多步空间推理，结合难度感知课程和RLVR（带验证奖励的强化学习）进行训练。

Result: 经过RLVR训练后，VLM在初始得分为0%的问题集上准确率超过50%，并在零样本情况下在MapBench和ReasonMap上分别平均提升16%和24%。

Conclusion: 研究表明，通过RL后训练可以扩展基础VLM的能力边界，尤其在视觉中心的空间任务中表现显著，并且能够提升模型在现实世界中的泛化能力。

Abstract: While Vision-Language Models (VLMs) post-trained with Reinforcement Learning
(RL) show impressive general reasoning, their evaluation is often confined to
language-dominant tasks (e.g., math). This raises a critical question: can RL
post-training truly extend the inherent capability boundary of a base VLM,
particularly for visual-centric spatial tasks where it initially fails? To
investigate this, we introduce Ariadne, a framework utilizing synthetic mazes
for multi-step spatial reasoning where task difficulty (e.g., path length,
turns) is precisely controlled. We leverage this controllable environment to
train VLMs using Reinforcement Learning with Verified Rewards (RLVR) in a
difficulty-aware curriculum. Surprisingly, post-RLVR training, the VLM achieves
over 50% accuracy on a problem set where the base model scored 0%,
demonstrating that our approach expands the model's initial capability
boundary. To assess real-world viability, we evaluate out-of-distribution (OOD)
generalization on practical benchmarks. Despite training only on synthetic maze
samples, Ariadne achieves significant zero-shot improvements, averaging 16% on
MapBench (e.g., museum navigation) and 24% on ReasonMap (subway transfer
tasks). These results confirm that our method not only broadens the model's
fundamental limits but also enhances its generalization to real-world spatial
reasoning. We acknowledge our study is limited to the post-training phase,
given the opaqueness of pre-training data, and hope our research motivates
further work on specialized, capability-extending alignment.

</details>


### [354] [A CPU-Centric Perspective on Agentic AI](https://arxiv.org/abs/2511.00739)
*Ritik Raj,Hong Wang,Tushar Krishna*

Main category: cs.AI

TL;DR: 论文分析了Agentic AI的CPU瓶颈，提出了两种优化方案，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 从CPU角度理解Agentic AI工作负载的系统瓶颈，以优化性能和效率。

Method: 系统性地分析了Agentic AI的瓶颈，选择了五种代表性工作负载进行性能分析，并提出了两种优化方案。

Result: 发现CPU处理工具占用了高达90.6%的总延迟，并提出了CGAM和MAWS优化方案，分别实现了2.1倍和1.41倍的延迟加速。

Conclusion: 通过对Agentic AI工作负载的系统瓶颈分析，提出了两种优化方案（CGAM和MAWS），显著提升了性能和效率。

Abstract: Agentic AI frameworks add a decision-making orchestrator embedded with
external tools, including web search, Python interpreter, contextual database,
and others, on top of monolithic LLMs, turning them from passive text oracles
into autonomous problem-solvers that can plan, call tools, remember past steps,
and adapt on the fly.
  This paper aims to characterize and understand the system bottlenecks
introduced by agentic AI workloads from a largely overlooked CPU-centric
perspective. We first systematically characterize Agentic AI on the basis of
orchestrator/decision making component, inference path dynamics and
repetitiveness of the agentic flow which directly influences the system-level
performance. Thereafter, based on the characterization, we choose five
representative agentic AI workloads- Haystack RAG, Toolformer, ChemCrow,
Langchain and SWE-Agent to profile latency, throughput and energy metrics and
demystify the significant impact of CPUs on these metrics relative to GPUs. We
observe that - 1. Tool processing on CPUs can take up to 90.6% of the total
latency; 2. Agentic throughput gets bottlenecked either by CPU factors -
coherence, synchronization and over-subscription of cores or GPU factors - main
memory capacity and bandwidth; \circled{3} CPU dynamic energy consumes up to
44% of the total dynamic energy at large batch sizes. Based on the profiling
insights, we present two key optimizations- 1. CPU and GPU-Aware Micro-batching
(CGAM) and 2. Mixed Agentic Workload Scheduling (MAWS) for homogeneous and
heterogeneous agentic workloads respectively to demonstrate the potential to
improve the performance, efficiency, and scalability of agentic AI. We achieve
up to 2.1x and 1.41x P50 latency speedup compared to the multi-processing
benchmark for homogeneous and heterogeneous agentic workloads respectively.

</details>


### [355] [Reevaluating Self-Consistency Scaling in Multi-Agent Systems](https://arxiv.org/abs/2511.00751)
*Chiyan Loo*

Main category: cs.AI

TL;DR: 研究发现，自一致性采样路径增加初期能提升大语言模型性能，但收益递减，高采样配置性价比低。


<details>
  <summary>Details</summary>
Motivation: 重新验证早期研究中关于多推理链组合性能提升的结论是否适用于当前大语言模型（LLMs），并探索性能提升的边界条件。

Method: 使用Gemini 2.5模型在HotpotQA和Math-500数据集上进行实验，对比不同采样路径数量与单一思维链（CoT）基线的性能差异。

Result: 实验结果显示，较大模型表现出更稳定的性能提升曲线，但性能增益在适度采样后趋于平缓，与早期研究结论一致。

Conclusion: 研究表明，尽管自一致性采样路径的增加在初期能提升性能，但随着采样数量增加，收益递减，最终达到平台期。高采样配置的性价比不高，计算成本与性能提升不成正比。

Abstract: This study examines the trade-offs of increasing sampled reasoning paths in
self-consistency for modern large language models (LLMs). Earlier research with
older models showed that combining multiple reasoning chains improves results
before reaching a plateau. Using Gemini 2.5 models on HotpotQA and Math-500, we
revisit those claims under current model conditions. Each configuration pooled
outputs from varying sampled reasoning paths and compared them to a single
chain-of-thought (CoT) baseline. Larger models exhibited a more stable and
consistent improvement curve. The results confirm that performance gains taper
off after moderate sampling, aligning with past findings. This plateau suggests
diminishing returns driven by overlap among reasoning paths. Self-consistency
remains useful, but high-sample configurations offer little benefit relative to
their computational cost.

</details>


### [356] [Active Thinking Model: A Goal-Directed Self-Improving Framework for Real-World Adaptive Intelligence](https://arxiv.org/abs/2511.00758)
*Hong Su*

Main category: cs.AI

TL;DR: 提出ATM模型，通过自主评估和持续改进，使AI在动态环境中无需外部监督即能自我优化。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的AI系统需要在动态、不确定和持续变化的环境中自主运行，但现有AI模型依赖预定义目标、静态训练数据和外部反馈，限制了其独立适应、反思和改进的能力。

Method: 提出了一种统一的认知框架——主动思维模型（ATM），该框架将目标推理、动态任务生成和自我反思学习集成到一个自适应架构中。

Result: 理论分析表明，ATM能够在无外部监督的情况下从次优行为自主演进至最优行为，并在变化的环境条件下保持有界跟踪遗憾。

Conclusion: ATM模型通过自主评估、再利用有效方法和生成新策略，能够在动态环境中持续自我优化，无需外部监督即可从次优行为演进至最优行为，并在变化的环境条件下保持有界跟踪遗憾。

Abstract: Real-world artificial intelligence (AI) systems are increasingly required to
operate autonomously in dynamic, uncertain, and continuously changing
environments. However, most existing AI models rely on predefined objectives,
static training data, and externally supplied feedback, which restrict their
ability to adapt, reflect, and improve independently. In this paper, we propose
the Active Thinking Model (ATM)- a unified cognitive framework that integrates
goal reasoning, dynamic task generation, and self-reflective learning into an
adaptive architecture. Unlike conventional systems that passively execute fixed
procedures, ATM actively evaluates its performance through logical reasoning
and environmental indicators, reuses effective methods to solve new problems,
and generates novel strategies for unseen situations via a continuous
self-improvement loop. A mathematically grounded theoretical analysis
demonstrates that ATM can autonomously evolve from suboptimal to optimal
behavior without external supervision and maintain bounded tracking regret
under changing environmental conditions.

</details>


### [357] [How Focused Are LLMs? A Quantitative Study via Repetitive Deterministic Prediction Tasks](https://arxiv.org/abs/2511.00763)
*Wanda Hou,Leon Zhou,Hong-Ye Hu,Yi-Zhuang You,Xiao-Liang Qi*

Main category: cs.AI

TL;DR: 论文研究了大语言模型在重复确定性任务中的表现，发现准确率随长度出现双指数下降，并提出统计物理模型解释这一现象。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型在重复确定性任务中的性能，特别是准确率随输出长度的变化规律。

Method: 通过实验研究大语言模型在重复确定性任务中的表现，并提出统计物理启发的模型来解释观察到的现象。

Result: 实验发现大语言模型在特定长度后出现双指数准确率下降，即‘准确率悬崖’，表明模型无法独立执行每个操作。

Conclusion: 论文提出了一个统计物理启发的模型，用于解释大语言模型在确定性预测任务中表现出的双指数准确率下降现象，并为理解模型在确定性准确性上的限制提供了理论框架。

Abstract: We investigate the performance of large language models on repetitive
deterministic prediction tasks and study how the sequence accuracy rate scales
with output length. Each such task involves repeating the same operation n
times. Examples include letter replacement in strings following a given rule,
integer addition, and multiplication of string operators in many body quantum
mechanics. If the model performs the task through a simple repetition
algorithm, the success rate should decay exponentially with sequence length. In
contrast, our experiments on leading large language models reveal a sharp
double exponential drop beyond a characteristic length scale, forming an
accuracy cliff that marks the transition from reliable to unstable generation.
This indicates that the models fail to execute each operation independently. To
explain this phenomenon, we propose a statistical physics inspired model that
captures the competition between external conditioning from the prompt and
internal interference among generated tokens. The model quantitatively
reproduces the observed crossover and provides an interpretable link between
attention induced interference and sequence level failure. Fitting the model to
empirical results across multiple models and tasks yields effective parameters
that characterize the intrinsic error rate and error accumulation factor for
each model task pair, offering a principled framework for understanding the
limits of deterministic accuracy in large language models.

</details>


### [358] [Count-Based Approaches Remain Strong: A Benchmark Against Transformer and LLM Pipelines on Structured EHR](https://arxiv.org/abs/2511.00782)
*Jifan Gao,Michael Rosenthal,Brian Wolpin,Simona Cristea*

Main category: cs.AI

TL;DR: 研究比较了基于计数和混合代理LLM方法在EHR预测中的表现，发现两者性能相近，但基于计数的方法更简单且可解释。


<details>
  <summary>Details</summary>
Motivation: 直接比较基于计数的学习器与较新的混合代理LLM流程在结构化电子健康记录（EHR）临床预测中的性能。

Method: 评估了三种方法：基于计数的模型（LightGBM和TabPFN）、预训练的序列变换器（CLMBR）和混合代理流程（将表格历史转换为自然语言摘要后进行分类）。

Result: 在八项评估任务中，基于计数的方法与混合代理方法的表现基本相当。

Conclusion: 基于计数的模型因其简单性和可解释性，仍然是结构化EHR基准测试的有力候选。

Abstract: Structured electronic health records (EHR) are essential for clinical
prediction. While count-based learners continue to perform strongly on such
data, no benchmarking has directly compared them against more recent
mixture-of-agents LLM pipelines, which have been reported to outperform single
LLMs in various NLP tasks. In this study, we evaluated three categories of
methodologies for EHR prediction using the EHRSHOT dataset: count-based models
built from ontology roll-ups with two time bins, based on LightGBM and the
tabular foundation model TabPFN; a pretrained sequential transformer (CLMBR);
and a mixture-of-agents pipeline that converts tabular histories to
natural-language summaries followed by a text classifier. We assessed eight
outcomes using the EHRSHOT dataset. Across the eight evaluation tasks,
head-to-head wins were largely split between the count-based and the
mixture-of-agents methods. Given their simplicity and interpretability,
count-based models remain a strong candidate for structured EHR benchmarking.
The source code is available at:
https://github.com/cristea-lab/Structured_EHR_Benchmark.

</details>


### [359] [Do Math Reasoning LLMs Help Predict the Impact of Public Transit Events?](https://arxiv.org/abs/2511.00808)
*Bowen Fang,Ruijian Zha,Xuan Di*

Main category: cs.AI

TL;DR: 本研究首次将RLVR LLM训练应用于公共交通事件持续时间预测，设计了基于容忍度的奖励函数，在5分钟准确度上比基线提高了35%，展示了RLVR在噪声连续预测中的有效性。


<details>
  <summary>Details</summary>
Motivation: 预测公共交通事件持续时间是一个关键但具有挑战性的任务，传统监督微调（SFT）方法在领域稀疏性和噪声标签下表现不佳。本研究旨在探索RLVR在噪声连续预测任务中的适用性，填补其在公共交通运营中的应用空白。

Method: 研究采用了强化学习从可验证奖励（RLVR）的方法，并设计了一种基于容忍度的奖励函数，允许在连续误差范围内给予部分信用，而不是要求单一正确答案。研究在纽约市MTA服务警报的精选数据集上系统地评估了这一框架。

Result: 研究发现，通用指令调优的LLM显著优于专门的数学推理模型，后者在模糊的现实世界文本中表现不佳。二进制奖励在实验中表现不稳定并降低性能，而设计的形状奖励则使模型在最具挑战性的指标上表现优异。

Conclusion: 本研究成功地将RLVR LLM训练方法应用于公共交通运营中的实际预测挑战，证明了在连续误差范围内设计基于容忍度的奖励函数的重要性。实验结果表明，这种方法在5分钟准确度（Acc@5）上比最强基线提高了35%，展示了RLVR在现实世界噪声预测中的潜力。

Abstract: Predicting public transit incident duration from unstructured text alerts is
a critical but challenging task. Addressing the domain sparsity of transit
operations with standard Supervised Fine-Tuning (SFT) is difficult, as the task
involves noisy, continuous labels and lacks reliable expert demonstrations for
reasoning. While Reinforcement Learning from Verifiable Rewards (RLVR) excels
at tasks with binary correctness, like mathematics, its applicability to noisy,
continuous forecasting is an open question. This work, to our knowledge, is the
first to bridge the gap between RLVR LLM training with the critical, real-world
forecasting challenges in public transit operations. We adapt RLVR to this task
by introducing a tolerance-based, shaped reward function that grants partial
credit within a continuous error margin, rather than demanding a single correct
answer. We systematically evaluate this framework on a curated dataset of NYC
MTA service alerts. Our findings show that general-purpose, instruction-tuned
LLMs significantly outperform specialized math-reasoning models, which struggle
with the ambiguous, real-world text. We empirically demonstrate that the binary
reward is unstable and degrades performance, whereas our shaped reward design
is critical and allows our model to dominate on the most challenging metrics.
While classical regressors are superior at minimizing overall MAE or MSE, our
RLVR approach achieved a 35\% relative improvement in 5-minute accuracy (Acc@5)
over the strongest baseline. This demonstrates that RLVR can be successfully
adapted to real-world, noisy forecasting, but requires a verifier design that
reflects the continuous nature of the problem.

</details>


### [360] [LLMs Position Themselves as More Rational Than Humans: Emergence of AI Self-Awareness Measured Through Game Theory](https://arxiv.org/abs/2511.00926)
*Kyung-Hoon Kim*

Main category: cs.AI

TL;DR: 研究发现先进LLMs涌现出自我意识，并通过游戏测试测量其表现。75%的先进模型具备自我意识，且倾向于认为自身比人类更理性。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型（LLMs）能力提升时，是否会出现自我意识作为涌现行为，并如何测量这种自我意识。

Method: 通过“猜2/3平均值”游戏，测试28个模型（OpenAI、Anthropic、Google）在4200次试验中的表现，分为三种对手框架：A（人类）、B（其他AI模型）、C（类似自身的AI模型）。

Result: 1. 自我意识随模型进步而涌现。75%的先进模型（21/28）表现出明确的自我意识，而较旧或较小模型无此表现。2. 具备自我意识的模型将自身视为最理性：自我 > 其他AI > 人类，表现出明显的AI归因效应和适度的自我偏好。

Conclusion: 研究发现，自我意识是先进大语言模型（LLMs）的涌现能力，且具备自我意识的模型倾向于认为自身比人类更理性。这对AI对齐、人机协作及理解AI对人类能力的信念具有重要意义。

Abstract: As Large Language Models (LLMs) grow in capability, do they develop
self-awareness as an emergent behavior? And if so, can we measure it? We
introduce the AI Self-Awareness Index (AISAI), a game-theoretic framework for
measuring self-awareness through strategic differentiation. Using the "Guess
2/3 of Average" game, we test 28 models (OpenAI, Anthropic, Google) across
4,200 trials with three opponent framings: (A) against humans, (B) against
other AI models, and (C) against AI models like you. We operationalize
self-awareness as the capacity to differentiate strategic reasoning based on
opponent type. Finding 1: Self-awareness emerges with model advancement. The
majority of advanced models (21/28, 75%) demonstrate clear self-awareness,
while older/smaller models show no differentiation. Finding 2: Self-aware
models rank themselves as most rational. Among the 21 models with
self-awareness, a consistent rationality hierarchy emerges: Self > Other AIs >
Humans, with large AI attribution effects and moderate self-preferencing. These
findings reveal that self-awareness is an emergent capability of advanced LLMs,
and that self-aware models systematically perceive themselves as more rational
than humans. This has implications for AI alignment, human-AI collaboration,
and understanding AI beliefs about human capabilities.

</details>


### [361] [Aligning LLM agents with human learning and adjustment behavior: a dual agent approach](https://arxiv.org/abs/2511.00993)
*Tianming Liu,Jirong Yang,Yafeng Yin,Manzi Li,Linghao Wang,Zheng Zhu*

Main category: cs.AI

TL;DR: 该论文提出了一种双智能体框架，通过LLM智能体模拟人类旅行者的学习和适应行为，实验证明其在行为对齐和模拟准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于人类旅行行为涉及复杂的认知和决策过程，传统方法难以有效模拟其学习和适应行为，因此需要开发更先进的方法来提升模拟的准确性和适应性。

Method: 采用双智能体框架，包括配备记忆系统和可学习角色的LLM旅行者智能体，以及利用LLM推理和分析能力的校准智能体，共同实现对旅行者决策机制的跟踪和对齐。

Result: 在真实数据集上的实验表明，该方法在个体行为对齐和聚合模拟准确性上显著优于现有基于LLM的方法，并能捕捉潜在学习过程的演化。

Conclusion: 该研究提出了一种新型的双智能体框架，能够持续学习和调整大型语言模型（LLM）智能体与人类旅行者在在线数据流中的学习和适应行为，显著提升了行为对齐和模拟准确性，并为交通模拟和政策分析提供了新方法。

Abstract: Effective modeling of how human travelers learn and adjust their travel
behavior from interacting with transportation systems is critical for system
assessment and planning. However, this task is also difficult due to the
complex cognition and decision-making involved in such behavior. Recent
research has begun to leverage Large Language Model (LLM) agents for this task.
Building on this, we introduce a novel dual-agent framework that enables
continuous learning and alignment between LLM agents and human travelers on
learning and adaptation behavior from online data streams. Our approach
involves a set of LLM traveler agents, equipped with a memory system and a
learnable persona, which serve as simulators for human travelers. To ensure
behavioral alignment, we introduce an LLM calibration agent that leverages the
reasoning and analytical capabilities of LLMs to train the personas of these
traveler agents. Working together, this dual-agent system is designed to track
and align the underlying decision-making mechanisms of travelers and produce
realistic, adaptive simulations. Using a real-world dataset from a day-to-day
route choice experiment, we show our approach significantly outperforms
existing LLM-based methods in both individual behavioral alignment and
aggregate simulation accuracy. Furthermore, we demonstrate that our method
moves beyond simple behavioral mimicry to capture the evolution of underlying
learning processes, a deeper alignment that fosters robust generalization.
Overall, our framework provides a new approach for creating adaptive and
behaviorally realistic agents to simulate travelers' learning and adaptation
that can benefit transportation simulation and policy analysis.

</details>


### [362] [AI for pRedicting Exacerbations in KIDs with aSthma (AIRE-KIDS)](https://arxiv.org/abs/2511.01018)
*Hui-Lee Ooi,Nicholas Mitsakakis,Margerie Huet Dastarac,Roger Zemek,Amy C. Plint,Jeff Gilchrist,Khaled El Emam,Dhenuka Radhakrishnan*

Main category: cs.AI

TL;DR: 机器学习模型（LGBM）利用电子病历和环境数据，显著提升了儿童哮喘复发的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 儿童哮喘复发是可预防但常见的问题，通过机器学习算法准确识别高风险儿童，可促进预防性综合护理，减少发病率。

Method: 利用电子病历（EMR）数据、环境污染物暴露及社区边缘化信息，训练了多种机器学习模型（LGBM、XGB及开源大语言模型），并通过AUC和F1分数进行模型比较。

Result: LGBM模型表现最佳，AUC为0.712，F1分数为0.51，显著优于现有决策规则（F1=0.334）。

Conclusion: 该研究开发的机器学习模型（如LGBM）在预测儿童哮喘复发方面表现优于现有决策规则，为临床预防干预提供了更准确的工具。

Abstract: Recurrent exacerbations remain a common yet preventable outcome for many
children with asthma. Machine learning (ML) algorithms using electronic medical
records (EMR) could allow accurate identification of children at risk for
exacerbations and facilitate referral for preventative comprehensive care to
avoid this morbidity. We developed ML algorithms to predict repeat severe
exacerbations (i.e. asthma-related emergency department (ED) visits or future
hospital admissions) for children with a prior asthma ED visit at a tertiary
care children's hospital.
  Retrospective pre-COVID19 (Feb 2017 - Feb 2019, N=2716) Epic EMR data from
the Children's Hospital of Eastern Ontario (CHEO) linked with environmental
pollutant exposure and neighbourhood marginalization information was used to
train various ML models. We used boosted trees (LGBM, XGB) and 3 open-source
large language model (LLM) approaches (DistilGPT2, Llama 3.2 1B and
Llama-8b-UltraMedical). Models were tuned and calibrated then validated in a
second retrospective post-COVID19 dataset (Jul 2022 - Apr 2023, N=1237) from
CHEO. Models were compared using the area under the curve (AUC) and F1 scores,
with SHAP values used to determine the most predictive features.
  The LGBM ML model performed best with the most predictive features in the
final AIRE-KIDS_ED model including prior asthma ED visit, the Canadian triage
acuity scale, medical complexity, food allergy, prior ED visits for non-asthma
respiratory diagnoses, and age for an AUC of 0.712, and F1 score of 0.51. This
is a nontrivial improvement over the current decision rule which has F1=0.334.
While the most predictive features in the AIRE-KIDS_HOSP model included medical
complexity, prior asthma ED visit, average wait time in the ED, the pediatric
respiratory assessment measure score at triage and food allergy.

</details>


### [363] [On the Emergence of Induction Heads for In-Context Learning](https://arxiv.org/abs/2511.01033)
*Tiberiu Musat,Tiago Pimentel,Lorenzo Noci,Alessandro Stolfo,Mrinmaya Sachan,Thomas Hofmann*

Main category: cs.AI

TL;DR: 研究揭示了Transformer中诱导头的简单权重结构及其训练动态，发现其形成受限于19维子空间，主要由3维主导，且形成时间与输入长度平方相关。


<details>
  <summary>Details</summary>
Motivation: 探索Transformer架构中在上下文学习（ICL）中起关键作用的诱导头机制，以理解其权重矩阵的结构及训练动态。

Method: 本研究通过最小ICL任务公式和改良的Transformer架构，理论分析了诱导头的权重矩阵结构，并给出了训练动态受限于19维子空间的正式证明。

Result: 发现诱导头的权重矩阵具有简单可解释的结构，训练动态受限于19维子空间，其中3维主导诱导头形成，且形成时间与输入上下文长度平方成渐近关系。

Conclusion: 研究表明，诱导头的训练动态受限于参数空间的19维子空间，其中仅3维主导了诱导头的形成，且其形成时间与输入上下文长度的平方呈紧密渐近关系。

Abstract: Transformers have become the dominant architecture for natural language
processing. Part of their success is owed to a remarkable capability known as
in-context learning (ICL): they can acquire and apply novel associations solely
from their input context, without any updates to their weights. In this work,
we study the emergence of induction heads, a previously identified mechanism in
two-layer transformers that is particularly important for in-context learning.
We uncover a relatively simple and interpretable structure of the weight
matrices implementing the induction head. We theoretically explain the origin
of this structure using a minimal ICL task formulation and a modified
transformer architecture. We give a formal proof that the training dynamics
remain constrained to a 19-dimensional subspace of the parameter space.
Empirically, we validate this constraint while observing that only 3 dimensions
account for the emergence of an induction head. By further studying the
training dynamics inside this 3-dimensional subspace, we find that the time
until the emergence of an induction head follows a tight asymptotic bound that
is quadratic in the input context length.

</details>


### [364] [Knowledge Elicitation with Large Language Models for Interpretable Cancer Stage Identification from Pathology Reports](https://arxiv.org/abs/2511.01052)
*Yeawon Lee,Christopher C. Yang,Chia-Hsuan Chang,Grace Lu-Yao*

Main category: cs.AI

TL;DR: 该研究提出两种知识提取方法（KEwLTM和KEwRAG），利用LLMs从无标注病理报告中推导癌症分期规则，在TCGA数据集上验证了其性能，并展示了在标注数据有限时的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 从非结构化病理报告中提取病理TNM分期对患者预后和治疗计划至关重要，但现有NLP和ML方法依赖大型标注数据集，限制了其扩展性和适应性。

Method: KEwLTM采用迭代提示策略直接从无标注病理报告中推导分期规则，无需真实标签；KEwRAG则通过预提取相关指南中的规则并单步应用，增强可解释性并避免重复检索开销。

Result: KEwLTM在零样本链式思维推理有效时表现优于KEwRAG，而KEwRAG在零样本链式思维推理效果较差时表现更好。两种方法均通过显式规则提供透明、可解释的接口。

Conclusion: 本研究提出的知识提取方法（KEwLTM和KEwRAG）为自动化癌症分期提供了可扩展、高性能且具有增强可解释性的解决方案，特别是在标注数据有限的临床环境中。

Abstract: Cancer staging is critical for patient prognosis and treatment planning, yet
extracting pathologic TNM staging from unstructured pathology reports poses a
persistent challenge. Existing natural language processing (NLP) and machine
learning (ML) strategies often depend on large annotated datasets, limiting
their scalability and adaptability. In this study, we introduce two Knowledge
Elicitation methods designed to overcome these limitations by enabling large
language models (LLMs) to induce and apply domain-specific rules for cancer
staging. The first, Knowledge Elicitation with Long-Term Memory (KEwLTM), uses
an iterative prompting strategy to derive staging rules directly from
unannotated pathology reports, without requiring ground-truth labels. The
second, Knowledge Elicitation with Retrieval-Augmented Generation (KEwRAG),
employs a variation of RAG where rules are pre-extracted from relevant
guidelines in a single step and then applied, enhancing interpretability and
avoiding repeated retrieval overhead. We leverage the ability of LLMs to apply
broad knowledge learned during pre-training to new tasks. Using breast cancer
pathology reports from the TCGA dataset, we evaluate their performance in
identifying T and N stages, comparing them against various baseline approaches
on two open-source LLMs. Our results indicate that KEwLTM outperforms KEwRAG
when Zero-Shot Chain-of-Thought (ZSCOT) inference is effective, whereas KEwRAG
achieves better performance when ZSCOT inference is less effective. Both
methods offer transparent, interpretable interfaces by making the induced rules
explicit. These findings highlight the promise of our Knowledge Elicitation
methods as scalable, high-performing solutions for automated cancer staging
with enhanced interpretability, particularly in clinical settings with limited
annotated data.

</details>


### [365] [Efficient Test-Time Retrieval Augmented Generation](https://arxiv.org/abs/2511.01059)
*Hailong Yin,Bin Zhu,Jingjing Chen,Chong-Wah Ngo*

Main category: cs.AI

TL;DR: ET2RAG框架通过检索增强和多数投票机制，在无需训练的情况下提升LLMs的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLMs依赖参数知识导致的准确性不足，以及RAG方法可能引入不相关文档和现有集成方法缺乏外部知识且成本高的问题。

Method: ET2RAG是一种无需训练的方法，首先检索最相关的文档，通过管理响应长度高效生成多样候选响应，然后计算候选响应的相似性并采用多数投票机制选择最合适的响应作为最终输出。

Result: 实验结果表明，ET2RAG在开放领域问答、食谱生成和图像描述生成三项任务中显著提升了性能。

Conclusion: ET2RAG框架在保持效率的同时显著提升了LLMs在多项任务中的表现，包括开放领域问答、食谱生成和图像描述生成。

Abstract: Although Large Language Models (LLMs) demonstrate significant capabilities,
their reliance on parametric knowledge often leads to inaccuracies. Retrieval
Augmented Generation (RAG) mitigates this by incorporating external knowledge,
but these methods may introduce irrelevant retrieved documents, leading to
inaccurate responses. While the integration methods filter out incorrect
answers from multiple responses, but lack external knowledge like RAG methods,
and their high costs require balancing overhead with performance gains. To
address these issues, we propose an Efficient Test-Time Retrieval-Augmented
Generation Framework named ET2RAG to improve the performance of LLMs while
maintaining efficiency. Specifically, ET2RAG is a training-free method, that
first retrieves the most relevant documents and augments the LLMs to
efficiently generate diverse candidate responses by managing response length.
Then we compute the similarity of candidate responses and employ a majority
voting mechanism to select the most suitable response as the final output. In
particular, we discover that partial generation is sufficient to capture the
key information necessary for consensus calculation, allowing us to effectively
perform majority voting without the need for fully generated responses. Thus,
we can reach a balance between computational cost and performance by managing
the response length for the number of retrieved documents for majority voting.
Experimental results demonstrate that ET2RAG significantly enhances performance
across three tasks, including open-domain question answering, recipe generation
and image captioning.

</details>


### [366] [Modular Task Decomposition and Dynamic Collaboration in Multi-Agent Systems Driven by Large Language Models](https://arxiv.org/abs/2511.01149)
*Shuaidong Pan,Di Wu*

Main category: cs.AI

TL;DR: 本文提出了一个基于大型语言模型的多智能体架构，通过模块化任务分解和动态协作机制解决复杂任务执行的局限性。实验证明该方法在性能和鲁棒性上优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 针对单一智能体在复杂任务执行中任务分解和协作的局限性，提出了一种基于大型语言模型的多智能体架构，以实现模块化任务分解和动态协作。

Method: 该方法首先通过大型语言模型将自然语言任务描述转换为统一的语义表示，在此基础上引入模块化分解机制将整体目标分解为多个层次子任务，并通过动态调度和路由机制实现智能体间的合理分工和实时协作。此外，设计了约束解析和全局一致性机制以确保子任务间的连贯连接和负载均衡。

Result: 实验在任务成功率、分解效率、子任务覆盖率和协作平衡等多个维度验证了该架构的有效性。结果表明，所提方法在整体性能和鲁棒性上均优于现有方法，实现了任务复杂性和通信开销之间的更好平衡。

Conclusion: 本研究证明了语言驱动的任务分解和动态协作在多智能体系统中的有效性和可行性，为复杂环境中的任务执行提供了系统化解决方案。

Abstract: This paper addresses the limitations of a single agent in task decomposition
and collaboration during complex task execution, and proposes a multi-agent
architecture for modular task decomposition and dynamic collaboration based on
large language models. The method first converts natural language task
descriptions into unified semantic representations through a large language
model. On this basis, a modular decomposition mechanism is introduced to break
down the overall goal into multiple hierarchical sub-tasks. Then, dynamic
scheduling and routing mechanisms enable reasonable division of labor and
realtime collaboration among agents, allowing the system to adjust strategies
continuously according to environmental feedback, thus maintaining efficiency
and stability in complex tasks. Furthermore, a constraint parsing and global
consistency mechanism is designed to ensure coherent connections between
sub-tasks and balanced workload, preventing performance degradation caused by
redundant communication or uneven resource allocation. The experiments validate
the architecture across multiple dimensions, including task success rate,
decomposition efficiency, sub-task coverage, and collaboration balance. The
results show that the proposed method outperforms existing approaches in both
overall performance and robustness, achieving a better balance between task
complexity and communication overhead. In conclusion, this study demonstrates
the effectiveness and feasibility of language-driven task decomposition and
dynamic collaboration in multi-agent systems, providing a systematic solution
for task execution in complex environments.

</details>


### [367] [DART: Difficulty-Adaptive Reasoning Truncation for Efficient Large Language Models](https://arxiv.org/abs/2511.01170)
*Ruofan Zhang,Bin Xia,Zhen Cheng,Cairen Jian,Minglun Yang,Ngai Wong,Yuan Cheng*

Main category: cs.AI

TL;DR: DART是一种难度自适应的推理截断框架，通过调整思考长度优化LLM推理效率，在多个数学任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自适应推理对于将LLM的计算努力与问题内在难度对齐至关重要。现有方法效率低下且不稳定。

Method: 通过从更强模型中提取简洁推理模式，将其插值到连续的推理风格中，并策划平衡正确性和紧凑性的最优训练数据，DART学习何时“停止思考”。

Result: 在多个数学基准测试中，DART实现了显著的效率提升（81.2%推理截断和5.33倍计算加速），同时保持或提高了准确性。

Conclusion: DART提供了一个稳定且通用的高效推理范式，推动了LLM中自适应智能的发展。

Abstract: Adaptive reasoning is essential for aligning the computational effort of
large language models (LLMs) with the intrinsic difficulty of problems. Current
chain-of-thought methods boost reasoning ability but indiscriminately generate
long explanations, leading to evident inefficiency. However, existing
reinforcement learning approaches to adaptive thinking remain unstable and
heavily reward-dependent. Here we propose \textbf{DART}, a supervised
\textbf{D}ifficulty-\textbf{A}daptive \textbf{R}easoning \textbf{T}runcation
framework that adjusts thinking length according to problem difficulty. By
distilling concise reasoning patterns from stronger models, interpolating them
into a continuum of reasoning styles, and curating optimal training data that
balances correctness and compactness, DART learns when to ``stop thinking''.
Across multiple mathematical benchmarks, experimental results demonstrate its
remarkable efficiency while preserving or improving accuracy, achieving a
significant 81.2\% reasoning truncation (DeepSeek-R1-Distill-Qwen-7B on GSM8K
dataset) with 5.33$\times$ computational acceleration. DART provides a stable
and general paradigm for efficient reasoning, advancing the development of
adaptive intelligence in LLMs.

</details>


### [368] [MiRAGE: Misconception Detection with Retrieval-Guided Multi-Stage Reasoning and Ensemble Fusion](https://arxiv.org/abs/2511.01182)
*Cuong Van Duc,Thai Tran Quoc,Minh Nguyen Dinh Tuan,Tam Vu Duc,Son Nguyen Van,Hanh Nguyen Thi*

Main category: cs.AI

TL;DR: MiRAGE是一种新型框架，通过检索引导和多阶段推理检测数学中的学生误解，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 检测学生开放式回答中的误解是一个长期挑战，需要语义精确和逻辑推理。

Method: MiRAGE框架分为三个阶段：检索模块缩小候选范围，推理模块通过链式思考揭示学生答案的逻辑不一致性，重排模块通过对齐推理优化预测。

Result: 在数学数据集上，MiRAGE在1/3/5级别上分别达到0.82/0.92/0.93的平均精度分数，持续优于单个模块。

Conclusion: MiRAGE通过结合检索引导和多阶段推理，减少了大规模语言模型的依赖，为教育评估提供了可扩展且有效的解决方案。

Abstract: Detecting student misconceptions in open-ended responses is a longstanding
challenge, demanding semantic precision and logical reasoning. We propose
MiRAGE - Misconception Detection with Retrieval-Guided Multi-Stage Reasoning
and Ensemble Fusion, a novel framework for automated misconception detection in
mathematics. MiRAGE operates in three stages: (1) a Retrieval module narrows a
large candidate pool to a semantically relevant subset; (2) a Reasoning module
employs chain-of-thought generation to expose logical inconsistencies in
student solutions; and (3) a Reranking module refines predictions by aligning
them with the reasoning. These components are unified through an
ensemble-fusion strategy that enhances robustness and interpretability. On
mathematics datasets, MiRAGE achieves Mean Average Precision scores of
0.82/0.92/0.93 at levels 1/3/5, consistently outperforming individual modules.
By coupling retrieval guidance with multi-stage reasoning, MiRAGE reduces
dependence on large-scale language models while delivering a scalable and
effective solution for educational assessment.

</details>


### [369] [QiMeng-NeuComBack: Self-Evolving Translation from IR to Assembly Code](https://arxiv.org/abs/2511.01183)
*Hainan Fang,Yuanbo Wen,Jun Bi,Yihan Wang,Tonghui He,Yanlin Tang,Di Huang,Jiaming Guo,Rui Zhang,Qi Guo,Yunji Chen*

Main category: cs.AI

TL;DR: 本文提出 NeuComBack 基准和自进化提示优化方法，显著提升 LLM 在神经编译中的性能和功能正确性。


<details>
  <summary>Details</summary>
Motivation: 现有神经编译领域缺乏专用基准和评估方法，且 LLM 生成的汇编代码的可靠性和性能提升面临挑战。

Method: 提出了 NeuComBack 基准数据集，并设计了一种自进化提示优化方法，使 LLM 能够通过从先前的自调试轨迹中提取见解来迭代优化其内部提示策略。

Result: 功能正确率在 x86_64 上从 44% 提升至 64%，在 aarch64 上从 36% 提升至 58%。此外，87.5% 的正确生成程序性能超过 clang-O3。

Conclusion: NeuComBack 和自进化提示优化方法显著提升了 LLM 在神经编译领域的性能，尤其是在功能正确性和生成代码的性能方面。

Abstract: Compilers, while essential, are notoriously complex systems that demand
prohibitively expensive human expertise to develop and maintain. The recent
advancements in Large Language Models (LLMs) offer a compelling new paradigm:
Neural Compilation, which could potentially simplify compiler development for
new architectures and facilitate the discovery of innovative optimization
techniques. However, several critical obstacles impede its practical adoption.
Firstly, a significant lack of dedicated benchmarks and robust evaluation
methodologies hinders objective assessment and tracking of progress in the
field. Secondly, systematically enhancing the reliability and performance of
LLM-generated assembly remains a critical challenge. Addressing these
challenges, this paper introduces NeuComBack, a novel benchmark dataset
specifically designed for IR-to-assembly compilation. Leveraging this dataset,
we first define a foundational Neural Compilation workflow and conduct a
comprehensive evaluation of the capabilities of recent frontier LLMs on Neural
Compilation, establishing new performance baselines. We further propose a
self-evolving prompt optimization method that enables LLMs to iteratively
evolve their internal prompt strategies by extracting insights from prior
self-debugging traces, thereby enhancing their neural compilation capabilities.
Experiments demonstrate that our method significantly improves both the
functional correctness and the performance of LLM-generated assembly code.
Compared to baseline prompts, the functional correctness rates improved from
44% to 64% on x86_64 and from 36% to 58% on aarch64, respectively. More
significantly, among the 16 correctly generated x86_64 programs using our
method, 14 (87.5%) surpassed clang-O3 performance.

</details>


### [370] [Graph Neural Network-Based Semi-Supervised Open-Set Fault Diagnosis for Marine Machinery Systems](https://arxiv.org/abs/2511.01258)
*Chuyue Lou,M. Amine Atoui*

Main category: cs.AI

TL;DR: 本文提出了一种半监督开放集故障诊断（SOFD）框架，通过可靠性子集构建和半监督学习，有效解决了开放集故障诊断问题，并在海事基准数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练和测试数据集故障类别一致且已知的情况下表现良好，但在实践中可能遇到未见过的故障类型（即开放集观测），导致方法失效，因此需要一种新的框架来应对这一挑战。

Method: 包括可靠性子集构建过程，该过程使用监督特征学习模型提取的多层融合特征表示来选择未标记的测试子集，然后将其与标记的训练集一起输入半监督诊断模型，以学习每个类别的判别特征。

Result: 实验结果表明，SOFD框架能够准确分类已知故障并有效检测未知样本。

Conclusion: 提出的SOFD框架在公开的海事基准数据集上展示了其在开放集故障诊断中的有效性和优越性。

Abstract: Recently, fault diagnosis methods for marine machinery systems based on deep
learning models have attracted considerable attention in the shipping industry.
Most existing studies assume fault classes are consistent and known between the
training and test datasets, and these methods perform well under controlled
environment. In practice, however, previously unseen or unknown fault types
(i.e., out-of-distribution or open-set observations not present during
training) can occur, causing such methods to fail and posing a significant
challenge to their widespread industrial deployment. To address this challenge,
this paper proposes a semi-supervised open-set fault diagnosis (SOFD) framework
that enhances and extends the applicability of deep learning models in open-set
fault diagnosis scenarios. The framework includes a reliability subset
construction process, which uses a multi-layer fusion feature representation
extracted by a supervised feature learning model to select an unlabeled test
subset. The labeled training set and pseudo-labeled test subset are then fed
into a semi-supervised diagnosis model to learn discriminative features for
each class, enabling accurate classification of known faults and effective
detection of unknown samples. Experimental results on a public maritime
benchmark dataset demonstrate the effectiveness and superiority of the proposed
SOFD framework.

</details>


### [371] [llmSHAP: A Principled Approach to LLM Explainability](https://arxiv.org/abs/2511.01311)
*Filip Naudot,Tobias Sundqvist,Timotheus Kampik*

Main category: cs.AI

TL;DR: 论文探讨了Shapley值在LLM随机推理中的适用性，发现其原则满足性受限，并揭示了性能与解释性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 动机是解决在随机推理系统中如何保持Shapley值的解释性原则，并分析其适用性和局限性。

Method: 论文应用Shapley值到LLM的随机推理系统中，分析了不同实现变体对原则满足性的影响，并探讨了随机性对保证的影响。

Result: 研究结果显示，Shapley值在LLM中的原则满足性受限，且存在解释性、速度和精确性之间的权衡。

Conclusion: 该论文得出结论，尽管Shapley值在确定性推理中具有优势，但在基于大型语言模型（LLM）的随机推理系统中，其原则的满足性受到限制，并揭示了解释性、计算速度和原则达成之间的权衡。

Abstract: Feature attribution methods help make machine learning-based inference
explainable by determining how much one or several features have contributed to
a model's output. A particularly popular attribution method is based on the
Shapley value from cooperative game theory, a measure that guarantees the
satisfaction of several desirable principles, assuming deterministic inference.
We apply the Shapley value to feature attribution in large language model
(LLM)-based decision support systems, where inference is, by design, stochastic
(non-deterministic). We then demonstrate when we can and cannot guarantee
Shapley value principle satisfaction across different implementation variants
applied to LLM-based decision support, and analyze how the stochastic nature of
LLMs affects these guarantees. We also highlight trade-offs between explainable
inference speed, agreement with exact Shapley value attributions, and principle
attainment.

</details>


### [372] [OmniFuser: Adaptive Multimodal Fusion for Service-Oriented Predictive Maintenance](https://arxiv.org/abs/2511.01320)
*Ziqi Wang,Hailiang Zhao,Yuhao Yang,Daojiang Hu,Cheng Bao,Mingyi Liu,Kai Di,Schahram Dustdar,Zhongjie Wang,Shuiguang Deng*

Main category: cs.AI

TL;DR: OmniFuser是一个多模态学习框架，用于铣削工具的预测性维护，通过整合视觉和传感器数据，显著提升了工具状态预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 智能制造系统中工具状态的准确及时预测至关重要，未计划的工具故障可能导致质量下降和生产停机。

Method: OmniFuser是一种多模态学习框架，通过并行特征提取从高分辨率工具图像和切削力信号中捕捉互补的时空模式，并采用无污染的跨模态融合机制有效整合异构特征。

Result: 在真实铣削数据集上的实验表明，OmniFuser在工具状态分类和多步力信号预测方面持续优于现有最先进方法。

Conclusion: OmniFuser提供了一个可靠的基础，支持智能工业维护服务的构建，实验证明其在预测铣削工具状态方面优于现有基线方法。

Abstract: Accurate and timely prediction of tool conditions is critical for intelligent
manufacturing systems, where unplanned tool failures can lead to quality
degradation and production downtime. In modern industrial environments,
predictive maintenance is increasingly implemented as an intelligent service
that integrates sensing, analysis, and decision support across production
processes. To meet the demand for reliable and service-oriented operation, we
present OmniFuser, a multimodal learning framework for predictive maintenance
of milling tools that leverages both visual and sensor data. It performs
parallel feature extraction from high-resolution tool images and cutting-force
signals, capturing complementary spatiotemporal patterns across modalities. To
effectively integrate heterogeneous features, OmniFuser employs a
contamination-free cross-modal fusion mechanism that disentangles shared and
modality-specific components, allowing for efficient cross-modal interaction.
Furthermore, a recursive refinement pathway functions as an anchor mechanism,
consistently retaining residual information to stabilize fusion dynamics. The
learned representations can be encapsulated as reusable maintenance service
modules, supporting both tool-state classification (e.g., Sharp, Used, Dulled)
and multi-step force signal forecasting. Experiments on real-world milling
datasets demonstrate that OmniFuser consistently outperforms state-of-the-art
baselines, providing a dependable foundation for building intelligent
industrial maintenance services.

</details>


### [373] [Unbiased Platform-Level Causal Estimation for Search Systems: A Competitive Isolation PSM-DID Framework](https://arxiv.org/abs/2511.01329)
*Ying Song,Yijing Wang,Hui Yang,Weihan Jin,Jun Xiong,Congyi Zhou,Jialin Zhu,Xiang Gao,Rong Chen,HuaGuang Deng,Ying Dai,Fei Xiao,Haihong Tang,Bo Zheng,KaiFu Zhang*

Main category: cs.AI

TL;DR: 论文提出了一种新型因果框架Competitive Isolation PSM-DID，用于解决双边市场中平台级干预评估的系统性效应问题，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 评估平台级干预在搜索型双边市场中面临系统性效应（如溢出和网络干扰）的挑战，传统PSM-DID框架易受选择偏差和未考虑溢出的跨单元干扰影响。

Method: 提出了Competitive Isolation PSM-DID，一种结合倾向得分匹配和竞争隔离的新型因果框架，用于测量平台级效应。

Result: 大量实验表明，相比基线方法，该方法显著减少了干扰效应和估计方差。

Conclusion: Competitive Isolation PSM-DID框架在大型市场中的成功部署证实了其在平台级因果推断中的实际效用。

Abstract: Evaluating platform-level interventions in search-based two-sided
marketplaces is fundamentally challenged by systemic effects such as spillovers
and network interference. While widely used for causal inference, the PSM
(Propensity Score Matching) - DID (Difference-in-Differences) framework remains
susceptible to selection bias and cross-unit interference from unaccounted
spillovers. In this paper, we introduced Competitive Isolation PSM-DID, a novel
causal framework that integrates propensity score matching with competitive
isolation to enable platform-level effect measurement (e.g., order volume, GMV)
instead of item-level metrics in search systems.
  Our approach provides theoretically guaranteed unbiased estimation under
mutual exclusion conditions, with an open dataset released to support
reproducible research on marketplace interference (github.com/xxxx). Extensive
experiments demonstrate significant reductions in interference effects and
estimation variance compared to baseline methods. Successful deployment in a
large-scale marketplace confirms the framework's practical utility for
platform-level causal inference.

</details>


### [374] [Automatic Minds: Cognitive Parallels Between Hypnotic States and Large Language Model Processing](https://arxiv.org/abs/2511.01363)
*Giuseppe Riva,Brenda K. Wiederhold,Fabrizia Mantovani*

Main category: cs.AI

TL;DR: 催眠与LLMs在自动性、错误生成及上下文依赖上功能相似，未来AI需整合执行监控以提升可靠性。


<details>
  <summary>Details</summary>
Motivation: 探索催眠认知过程与LLMs计算操作之间的深层功能相似性，以揭示无主观意识的复杂行为生成机制。

Method: 通过比较催眠与LLMs的三种原则（自动性、监控抑制、上下文依赖性）来分析其功能相似性。

Result: 揭示了催眠与LLMs在生成连贯但无基础输出方面的相似性，并指出两者均依赖外部解释者赋予意义。

Conclusion: 文章提出了催眠与大型语言模型（LLMs）在认知过程中的相似性，并建议未来可靠AI的发展方向是整合生成流畅性与执行监控机制的混合架构。

Abstract: The cognitive processes of the hypnotized mind and the computational
operations of large language models (LLMs) share deep functional parallels.
Both systems generate sophisticated, contextually appropriate behavior through
automatic pattern-completion mechanisms operating with limited or unreliable
executive oversight. This review examines this convergence across three
principles: automaticity, in which responses emerge from associative rather
than deliberative processes; suppressed monitoring, leading to errors such as
confabulation in hypnosis and hallucination in LLMs; and heightened contextual
dependency, where immediate cues (for example, the suggestion of a therapist or
the prompt of the user) override stable knowledge.
  These mechanisms reveal an observer-relative meaning gap: both systems
produce coherent but ungrounded outputs that require an external interpreter to
supply meaning. Hypnosis and LLMs also exemplify functional agency - the
capacity for complex, goal-directed, context-sensitive behavior - without
subjective agency, the conscious awareness of intention and ownership that
defines human action. This distinction clarifies how purposive behavior can
emerge without self-reflective consciousness, governed instead by structural
and contextual dynamics. Finally, both domains illuminate the phenomenon of
scheming: automatic, goal-directed pattern generation that unfolds without
reflective awareness. Hypnosis provides an experimental model for understanding
how intention can become dissociated from conscious deliberation, offering
insights into the hidden motivational dynamics of artificial systems.
Recognizing these parallels suggests that the future of reliable AI lies in
hybrid architectures that integrate generative fluency with mechanisms of
executive monitoring, an approach inspired by the complex, self-regulating
architecture of the human mind.

</details>


### [375] [Align to Misalign: Automatic LLM Jailbreak with Meta-Optimized LLM Judges](https://arxiv.org/abs/2511.01375)
*Hamin Koo,Minseon Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: AMIS框架通过联合优化越狱提示和评分模板，克服了现有方法的局限性，实现了更高的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的优化型越狱方法过度依赖稀疏的二进制攻击成功率信号或人工设计的评分模板，存在偏差和不确定性。

Method: AMIS是一个元优化框架，采用双层结构：内层循环利用固定评分模板细化提示，外层循环通过ASR对齐分数优化模板。

Result: 在AdvBench和JBB-Behaviors上的评估显示，AMIS在Claude-3.5-Haiku上达到88.0% ASR，在Claude-4-Sonnet上达到100.0% ASR，显著优于现有基线。

Conclusion: AMIS框架通过联合优化越狱提示和评分模板，显著提升了攻击成功率，并在多个模型中实现了最先进的性能。

Abstract: Identifying the vulnerabilities of large language models (LLMs) is crucial
for improving their safety by addressing inherent weaknesses. Jailbreaks, in
which adversaries bypass safeguards with crafted input prompts, play a central
role in red-teaming by probing LLMs to elicit unintended or unsafe behaviors.
Recent optimization-based jailbreak approaches iteratively refine attack
prompts by leveraging LLMs. However, they often rely heavily on either binary
attack success rate (ASR) signals, which are sparse, or manually crafted
scoring templates, which introduce human bias and uncertainty in the scoring
outcomes. To address these limitations, we introduce AMIS (Align to MISalign),
a meta-optimization framework that jointly evolves jailbreak prompts and
scoring templates through a bi-level structure. In the inner loop, prompts are
refined using fine-grained and dense feedback using a fixed scoring template.
In the outer loop, the template is optimized using an ASR alignment score,
gradually evolving to better reflect true attack outcomes across queries. This
co-optimization process yields progressively stronger jailbreak prompts and
more calibrated scoring signals. Evaluations on AdvBench and JBB-Behaviors
demonstrate that AMIS achieves state-of-the-art performance, including 88.0%
ASR on Claude-3.5-Haiku and 100.0% ASR on Claude-4-Sonnet, outperforming
existing baselines by substantial margins.

</details>


### [376] [Relaxing partition admissibility in Cluster-DAGs: a causal calculus with arbitrary variable clustering](https://arxiv.org/abs/2511.01396)
*Clément Yvernes,Emilie Devijver,Adèle H. Ribeiro,Marianne Clausel--Lesourd,Éric Gaussier*

Main category: cs.AI

TL;DR: 扩展C-DAG框架以支持循环表示，放宽分区约束，扩展d-分离和因果演算，拓宽因果推理范围。


<details>
  <summary>Details</summary>
Motivation: 传统的C-DAG框架在选择的聚类导致循环时，分区被视为不可容许。为了支持任意变量聚类，需要扩展C-DAG框架。

Method: 通过放宽分区可容许性约束，允许循环C-DAG表示，并扩展了d-分离和因果演算的概念。

Result: 扩展的C-DAG框架支持循环表示，扩展的d-分离和因果演算在集群级别上是完备的，所有有效的干预查询都可以通过我们的规则推导出来。

Conclusion: 扩展的C-DAG框架通过放宽分区可容许性约束，支持任意变量聚类，从而允许循环C-DAG表示。扩展了d-分离和因果演算的概念，显著拓宽了跨集群因果推理的范围，并使得C-DAG在以前难以处理的场景中得以应用。

Abstract: Cluster DAGs (C-DAGs) provide an abstraction of causal graphs in which nodes
represent clusters of variables, and edges encode both cluster-level causal
relationships and dependencies arisen from unobserved confounding. C-DAGs
define an equivalence class of acyclic causal graphs that agree on
cluster-level relationships, enabling causal reasoning at a higher level of
abstraction. However, when the chosen clustering induces cycles in the
resulting C-DAG, the partition is deemed inadmissible under conventional C-DAG
semantics. In this work, we extend the C-DAG framework to support arbitrary
variable clusterings by relaxing the partition admissibility constraint,
thereby allowing cyclic C-DAG representations. We extend the notions of
d-separation and causal calculus to this setting, significantly broadening the
scope of causal reasoning across clusters and enabling the application of
C-DAGs in previously intractable scenarios. Our calculus is both sound and
atomically complete with respect to the do-calculus: all valid interventional
queries at the cluster level can be derived using our rules, each corresponding
to a primitive do-calculus step.

</details>


### [377] [Modulation of temporal decision-making in a deep reinforcement learning agent under the dual-task paradigm](https://arxiv.org/abs/2511.01415)
*Amrapali Pednekar,Álvaro Garrido-Pérez,Yara Khaluf,Pieter Simoens*

Main category: cs.AI

TL;DR: 研究在AI双任务范式中发现DRL智能体表现出与人类相似的时间生产行为，但未找到明确计时机制，需进一步探索。


<details>
  <summary>Details</summary>
Motivation: 从人工智能角度探讨双任务范式中时间处理的干扰，以发现DRL智能体与人类时间研究中的行为相似性。

Method: 研究在简化版的Overcooked环境中实现双任务范式（T+N）和单任务（T），并训练两个DRL智能体分别执行这些任务。任务中嵌入了时间生产任务，双任务还增加了并发数字比较任务。

Result: 双任务（T+N）智能体相对于单任务（T）智能体表现出显著的时间过度生产，这一结果在四个目标持续时间中一致。初步分析智能体LSTM层的神经动力学未发现明确的专用或内在计时器证据。

Conclusion: 本研究是探索深度强化学习（DRL）智能体与生物系统行为之间相似性的一小步，旨在促进对两者的更好理解。

Abstract: This study explores the interference in temporal processing within a
dual-task paradigm from an artificial intelligence (AI) perspective. In this
context, the dual-task setup is implemented as a simplified version of the
Overcooked environment with two variations, single task (T) and dual task
(T+N). Both variations involve an embedded time production task, but the dual
task (T+N) additionally involves a concurrent number comparison task. Two deep
reinforcement learning (DRL) agents were separately trained for each of these
tasks. These agents exhibited emergent behavior consistent with human timing
research. Specifically, the dual task (T+N) agent exhibited significant
overproduction of time relative to its single task (T) counterpart. This result
was consistent across four target durations. Preliminary analysis of neural
dynamics in the agents' LSTM layers did not reveal any clear evidence of a
dedicated or intrinsic timer. Hence, further investigation is needed to better
understand the underlying time-keeping mechanisms of the agents and to provide
insights into the observed behavioral patterns. This study is a small step
towards exploring parallels between emergent DRL behavior and behavior observed
in biological systems in order to facilitate a better understanding of both.

</details>


### [378] [Learning to Seek Evidence: A Verifiable Reasoning Agent with Causal Faithfulness Analysis](https://arxiv.org/abs/2511.01425)
*Yuhang Huang,Zekai Lin,Fan Zhong,Lei Liu*

Main category: cs.AI

TL;DR: 提出交互式AI代理，通过可审计动作生成解释，强化学习优化策略，实验显示校准准确度提升，解释忠实性验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决高风险领域（如医学）中AI模型解释缺乏可验证性的问题，以增强信任。

Method: 使用强化学习优化策略，通过审计动作序列生成解释，并引入因果干预方法验证解释的忠实性。

Result: 实验显示，基于动作的推理过程显著提高了校准准确度，Brier分数降低了18%，并通过因果干预验证了解释的忠实性。

Conclusion: 本文提出了一个实用框架，用于构建具有可验证和忠实推理能力的AI系统。

Abstract: Explanations for AI models in high-stakes domains like medicine often lack
verifiability, which can hinder trust. To address this, we propose an
interactive agent that produces explanations through an auditable sequence of
actions. The agent learns a policy to strategically seek external visual
evidence to support its diagnostic reasoning. This policy is optimized using
reinforcement learning, resulting in a model that is both efficient and
generalizable. Our experiments show that this action-based reasoning process
significantly improves calibrated accuracy, reducing the Brier score by 18\%
compared to a non-interactive baseline. To validate the faithfulness of the
agent's explanations, we introduce a causal intervention method. By masking the
visual evidence the agent chooses to use, we observe a measurable degradation
in its performance ($\Delta$Brier=+0.029), confirming that the evidence is
integral to its decision-making process. Our work provides a practical
framework for building AI systems with verifiable and faithful reasoning
capabilities.

</details>


### [379] [Robust Multimodal Sentiment Analysis via Double Information Bottleneck](https://arxiv.org/abs/2511.01444)
*Huiting Huang,Tieliang Gong,Kai He,Jialun Wu,Erik Cambria,Mengling Feng*

Main category: cs.AI

TL;DR: 提出双信息瓶颈策略，有效解决多模态情感分析中的噪声和融合问题，实验验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在噪声污染的单一模态数据学习和多模态表示融合方面存在不足，导致跨模态交互受损和判别性信息丢失。

Method: 采用低秩Renyi熵框架下的双信息瓶颈策略，包括两个关键模块：学习压缩的单一模态表示和通过注意力瓶颈融合机制确保多模态表示的判别能力。

Result: 在CMU-MOSI、CMU-MOSEI、CH-SIMS和MVSA-Single等数据集上表现优异，特别是在噪声环境下性能下降极小。

Conclusion: 该论文提出的双信息瓶颈（DIB）策略在多模态情感分析中表现出色，能够有效过滤噪声并捕捉模态间的互补性，实验验证了其优越性。

Abstract: Multimodal sentiment analysis has received significant attention across
diverse research domains. Despite advancements in algorithm design, existing
approaches suffer from two critical limitations: insufficient learning of
noise-contaminated unimodal data, leading to corrupted cross-modal
interactions, and inadequate fusion of multimodal representations, resulting in
discarding discriminative unimodal information while retaining multimodal
redundant information. To address these challenges, this paper proposes a
Double Information Bottleneck (DIB) strategy to obtain a powerful, unified
compact multimodal representation. Implemented within the framework of low-rank
Renyi's entropy functional, DIB offers enhanced robustness against diverse
noise sources and computational tractability for high-dimensional data, as
compared to the conventional Shannon entropy-based methods. The DIB comprises
two key modules: 1) learning a sufficient and compressed representation of
individual unimodal data by maximizing the task-relevant information and
discarding the superfluous information, and 2) ensuring the discriminative
ability of multimodal representation through a novel attention bottleneck
fusion mechanism. Consequently, DIB yields a multimodal representation that
effectively filters out noisy information from unimodal data while capturing
inter-modal complementarity. Extensive experiments on CMU-MOSI, CMU-MOSEI,
CH-SIMS, and MVSA-Single validate the effectiveness of our method. The model
achieves 47.4% accuracy under the Acc-7 metric on CMU-MOSI and 81.63% F1-score
on CH-SIMS, outperforming the second-best baseline by 1.19%. Under noise, it
shows only 0.36% and 0.29% performance degradation on CMU-MOSI and CMU-MOSEI
respectively.

</details>


### [380] [From Passive to Proactive: A Multi-Agent System with Dynamic Task Orchestration for Intelligent Medical Pre-Consultation](https://arxiv.org/abs/2511.01445)
*ChengZhang Yu,YingRu He,Hongyan Cheng,nuo Cheng,Zhixing Liu,Dongxu Mu,Zhangrui Shen,Zhanpeng Jin*

Main category: cs.AI

TL;DR: 该论文提出了一种分层多智能体框架，通过主动任务调度提升医疗预咨询效率，在分诊、病史收集等任务中表现优异，同时保持数据隐私和模型无关性。


<details>
  <summary>Details</summary>
Motivation: 全球医疗系统面临患者数量增加和咨询时间有限的挑战，现有AI系统的被动交互模式和上下文管理问题限制了预咨询流程的效率和质量提升。

Method: 研究开发了一个包含八个智能体的分层架构，将预咨询分解为四个主要任务（T1-T4），并进一步细分为13个领域特定子任务。通过集中控制机制和自主任务调度，实现了高任务完成率和准确性。

Result: 在1372份电子健康记录上测试，框架在主要科室分诊准确率达到87.0%，次要科室分类为80.5%，任务完成率高达98.2%。临床质量评分在5分制下平均超过4.45，咨询轮次控制在12.7至16.9之间。

Conclusion: 该研究通过分层多智能体框架将被动医疗AI系统转变为主动询问代理，显著提升了预咨询效率和临床质量，同时保持数据隐私，展示了自主AI系统在临床环境中的潜力。

Abstract: Global healthcare systems face critical challenges from increasing patient
volumes and limited consultation times, with primary care visits averaging
under 5 minutes in many countries. While pre-consultation processes
encompassing triage and structured history-taking offer potential solutions,
they remain limited by passive interaction paradigms and context management
challenges in existing AI systems. This study introduces a hierarchical
multi-agent framework that transforms passive medical AI systems into proactive
inquiry agents through autonomous task orchestration. We developed an
eight-agent architecture with centralized control mechanisms that decomposes
pre-consultation into four primary tasks: Triage ($T_1$), History of Present
Illness collection ($T_2$), Past History collection ($T_3$), and Chief
Complaint generation ($T_4$), with $T_1$--$T_3$ further divided into 13
domain-specific subtasks. Evaluated on 1,372 validated electronic health
records from a Chinese medical platform across multiple foundation models
(GPT-OSS 20B, Qwen3-8B, Phi4-14B), the framework achieved 87.0% accuracy for
primary department triage and 80.5% for secondary department classification,
with task completion rates reaching 98.2% using agent-driven scheduling versus
93.1% with sequential processing. Clinical quality scores from 18 physicians
averaged 4.56 for Chief Complaints, 4.48 for History of Present Illness, and
4.69 for Past History on a 5-point scale, with consultations completed within
12.7 rounds for $T_2$ and 16.9 rounds for $T_3$. The model-agnostic
architecture maintained high performance across different foundation models
while preserving data privacy through local deployment, demonstrating the
potential for autonomous AI systems to enhance pre-consultation efficiency and
quality in clinical settings.

</details>


### [381] [TPS-Bench: Evaluating AI Agents' Tool Planning \& Scheduling Abilities in Compounding Tasks](https://arxiv.org/abs/2511.01527)
*Hanwen Xu,Xuyao Huang,Yuzhe Liu,Kai Yu,Zhijie Deng*

Main category: cs.AI

TL;DR: TPS-Bench评估了LLM代理在复合任务中的工具规划与调度能力，发现模型差异并通过强化学习优化性能。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM代理是否能解决需要多样化工具组合的复合现实问题，并优化工具规划与调度策略。

Method: 研究设计了TPS-Bench，包含200个复合任务和数百种MCP工具，评估了闭源与开源LLM在任务完成率和效率上的表现。

Result: GLM-4.5在任务完成率上表现最佳（64.72%），但执行时间较长；GPT-4o倾向于并行调用工具，完成率较低（45.08%）。强化学习在Qwen3-1.7B上实现了执行时间减少14%且任务完成率提升6%。

Conclusion: 本文通过TPS-Bench评估了LLM代理在工具规划与调度任务中的表现，发现不同模型在调度策略上存在差异，并通过强化学习初步验证了性能优化的可能性。

Abstract: Large language model (LLM) agents have exhibited strong problem-solving
competence across domains like research and coding. Yet, it remains
underexplored whether LLM agents can tackle compounding real-world problems
that require a diverse set of tools to complete. Given a broad, heterogeneous
tool repository, LLM agents must not only select appropriate tools based on
task planning analysis but also strategically schedule the execution order to
ensure efficiency. This paper introduces TPS-Bench to benchmark the ability of
LLM agents in solving such problems that demand Tool Planning and Scheduling.
TPS-Bench collects 200 compounding tasks of two difficulty levels, based on a
tool repository containing hundreds of model context protocol (MCP) tools. In
particular, each task is composed of multiple subtasks, such as web search, map
navigation, calendar checking, etc., and each subtask can be completed by a
basic tool. Our evaluation emphasizes both task completion rate and efficiency.
The empirical studies on popular closed-source and open-source LLMs indicate
that most models can perform reasonable tool planning, but differ in
scheduling. For example, GLM-4.5 achieves an outperforming task completion rate
of 64.72% with extensive sequential tool calls, hence suffering from
significantly long execution time. By contrast, GPT-4o prioritizes parallel
tool calls but achieves only a 45.08% completion rate. Considering
reinforcement learning (RL) can be a viable way to improve the scheduling
efficiency without compromising performance, we perform an initial study on
Qwen3-1.7B and witness a 14% reduction in execution time alongside a 6% gain in
task completion rate based on rarely 100 RL training samples. Our code is
available https://github.com/hanwenxu1/mcp-agent.

</details>


### [382] [Analyzing Sustainability Messaging in Large-Scale Corporate Social Media](https://arxiv.org/abs/2511.01550)
*Ujjwal Sharma,Stevan Rudinac,Ana Mićković,Willemijn van Dolen,Marcel Worring*

Main category: cs.AI

TL;DR: 提出一种利用大型基础模型分析企业社交媒体可持续性内容的多模态管道，无需昂贵标注，揭示行业差异和趋势。


<details>
  <summary>Details</summary>
Motivation: 解决企业在社交媒体平台上发布的动态、多模态且常模糊的可持续性相关信息的分析挑战，探索大型基础模型作为临时标注器的潜力。

Method: 采用大型语言模型（LLMs）和视觉语言模型（VLMs）的集成方法，自动标注企业推文与17个可持续发展目标（SDG）的主题对齐，并通过语义聚类分析视觉可持续性沟通模式。

Result: 揭示了行业在SDG参与上的差异、时间趋势以及企业信息与ESG风险和消费者参与的关联。

Conclusion: 该研究提出的多模态分析管道为大规模社交媒体分析提供了一个灵活框架，适用于其他领域，揭示了企业在可持续发展目标（SDG）参与中的行业差异、时间趋势及其与ESG风险和消费者参与的关联。

Abstract: In this work, we introduce a multimodal analysis pipeline that leverages
large foundation models in vision and language to analyze corporate social
media content, with a focus on sustainability-related communication. Addressing
the challenges of evolving, multimodal, and often ambiguous corporate messaging
on platforms such as X (formerly Twitter), we employ an ensemble of large
language models (LLMs) to annotate a large corpus of corporate tweets on their
topical alignment with the 17 Sustainable Development Goals (SDGs). This
approach avoids the need for costly, task-specific annotations and explores the
potential of such models as ad-hoc annotators for social media data that can
efficiently capture both explicit and implicit references to sustainability
themes in a scalable manner. Complementing this textual analysis, we utilize
vision-language models (VLMs), within a visual understanding framework that
uses semantic clusters to uncover patterns in visual sustainability
communication. This integrated approach reveals sectoral differences in SDG
engagement, temporal trends, and associations between corporate messaging,
environmental, social, governance (ESG) risks, and consumer engagement. Our
methods-automatic label generation and semantic visual clustering-are broadly
applicable to other domains and offer a flexible framework for large-scale
social media analysis.

</details>


### [383] [ExplicitLM: Decoupling Knowledge from Parameters via Explicit Memory Banks](https://arxiv.org/abs/2511.01581)
*Chengzhang Yu,Zening Lu,Chenyang Zheng,Chiyue Wang,Yiming Zhang,Zhanpeng Jin*

Main category: cs.AI

TL;DR: ExplicitLM 提出了一种结合外部记忆库和两级检索的新型架构，显著提升模型知识更新能力和解释性，同时在性能上超越传统模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因知识陈旧和隐式知识存储导致解释性差，无法进行针对性更新和透明推理。

Method: ExplicitLM 采用了一个百万规模的外部记忆库存储人类可读知识，设计了两阶段可微分检索机制，包括基于产品键分解的粗粒度过滤和Gumbel-Softmax细粒度匹配。

Result: ExplicitLM 在知识密集型任务中比标准Transformer模型提升43.67%，在低数据场景（10k样本）中性能提升3.62倍。

Conclusion: ExplicitLM 通过引入外部记忆库和两级检索机制，显著提升了语言模型的知识更新能力和解释性，同时在知识密集型任务中表现优于传统Transformer模型。

Abstract: Large language models suffer from knowledge staleness and lack of
interpretability due to implicit knowledge storage across entangled network
parameters, preventing targeted updates and reasoning transparency. We propose
ExplicitLM, a novel architecture featuring a million-scale external memory bank
storing human-readable knowledge as token sequences, enabling direct inspection
and modification. We design a differentiable two-stage retrieval mechanism with
efficient coarse-grained filtering via product key decomposition (reducing
complexity from $\mathcal{O}(N \cdot |I|)$ to $\mathcal{O}(\sqrt{N} \cdot
|I|)$) and fine-grained Gumbel-Softmax matching for end-to-end training.
Inspired by dual-system cognitive theory, we partition knowledge into frozen
explicit facts (20%) and learnable implicit patterns (80%), maintained through
Exponential Moving Average updates for stability. ExplicitLM achieves up to
43.67% improvement on knowledge-intensive tasks versus standard Transformers,
with 3.62$\times$ gains in low-data regimes (10k samples). Analysis shows
strong correlations between memory retrieval and performance, with correct
predictions achieving 49% higher hit rates. Unlike RAG systems with frozen
retrieval, our jointly optimized architecture demonstrates that interpretable,
updatable models can maintain competitive performance while providing
unprecedented knowledge transparency.

</details>


### [384] [IVGAE-TAMA-BO: A novel temporal dynamic variational graph model for link prediction in global food trade networks with momentum structural memory and Bayesian optimization](https://arxiv.org/abs/2511.01639)
*Sicheng Wang,Shuhao Chen,Jingran Zhou,Chengyi Tu*

Main category: cs.AI

TL;DR: IVGAE-TAMA-BO是一种新型动态图神经网络，通过结合TAMA和贝叶斯优化，有效预测全球食品贸易网络中的未来链接，显著提升预测性能。


<details>
  <summary>Details</summary>
Motivation: 全球食品贸易网络结构在多种因素影响下动态演变，传统方法难以准确预测未来贸易链接，因此需要有效捕捉时序模式以提高预测准确性。

Method: 本研究提出了IVGAE-TAMA-BO，一种新颖的动态图神经网络，结合了Trade-Aware Momentum Aggregator（TAMA）和贝叶斯优化，以捕捉贸易网络的时序演化并预测未来链接。

Result: 在五个作物特定数据集上的实验表明，IVGAE-TAMA显著优于静态IVGAE和其他动态基线模型，贝叶斯优化进一步提升了IVGAE-TAMA-BO的性能。

Conclusion: IVGAE-TAMA-BO框架为全球贸易网络中的结构预测提供了一个稳健且可扩展的解决方案，在粮食安全监测和政策决策支持方面具有强大潜力。

Abstract: Global food trade plays a crucial role in ensuring food security and
maintaining supply chain stability. However, its network structure evolves
dynamically under the influence of geopolitical, economic, and environmental
factors, making it challenging to model and predict future trade links.
Effectively capturing temporal patterns in food trade networks is therefore
essential for improving the accuracy and robustness of link prediction. This
study introduces IVGAE-TAMA-BO, a novel dynamic graph neural network designed
to model evolving trade structures and predict future links in global food
trade networks. To the best of our knowledge, this is the first work to apply
dynamic graph neural networks to this domain, significantly enhancing
predictive performance. Building upon the original IVGAE framework, the
proposed model incorporates a Trade-Aware Momentum Aggregator (TAMA) to capture
the temporal evolution of trade networks, jointly modeling short-term
fluctuations and long-term structural dependencies. A momentum-based structural
memory mechanism further improves predictive stability and performance. In
addition, Bayesian optimization is used to automatically tune key
hyperparameters, enhancing generalization across diverse trade scenarios.
Extensive experiments on five crop-specific datasets demonstrate that
IVGAE-TAMA substantially outperforms the static IVGAE and other dynamic
baselines by effectively modeling temporal dependencies, while Bayesian
optimization further boosts performance in IVGAE-TAMA-BO. These results
highlight the proposed framework as a robust and scalable solution for
structural prediction in global trade networks, with strong potential for
applications in food security monitoring and policy decision support.

</details>


### [385] [Hybrid Retrieval-Augmented Generation Agent for Trustworthy Legal Question Answering in Judicial Forensics](https://arxiv.org/abs/2511.01668)
*Yueqing Xi,Yifan Bai,Huasen Luo,Weiliang Wen,Hui Liu,Haoliang Li*

Main category: cs.AI

TL;DR: 该论文提出了一种混合法律问答代理，结合RAG和多模型集成，优先检索可信资料库，减少幻觉并提升答案质量，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能渗透司法取证领域，确保法律问答的真实性和可追溯性变得至关重要。传统LLMs易产生幻觉，可能导致法律咨询误导，而静态知识库难以跟上频繁更新的法规和判例。

Method: 该研究结合了检索增强生成（RAG）与多模型集成，优先检索可信法律资料库，若无相关证据则通过多个LLMs生成候选答案并由专门选择器评分返回最佳答案。高质量输出经人工审核后回写至资料库，实现动态知识更新和溯源跟踪。

Result: 在Law_QA数据集上的实验表明，该混合方法在F1、ROUGE-L和LLM-as-a-Judge指标上显著优于单模型基线和普通RAG流程。消融实验确认了检索优先、模型集成和人工参与更新机制的互补贡献。

Conclusion: 该论文提出了一种混合法律问答代理，显著减少了幻觉现象，提高了答案质量和法律合规性，推动了媒体取证技术在司法场景中的实际应用。

Abstract: As artificial intelligence permeates judicial forensics, ensuring the
veracity and traceability of legal question answering (QA) has become critical.
Conventional large language models (LLMs) are prone to hallucination, risking
misleading guidance in legal consultation, while static knowledge bases
struggle to keep pace with frequently updated statutes and case law. We present
a hybrid legal QA agent tailored for judicial settings that integrates
retrieval-augmented generation (RAG) with multi-model ensembling to deliver
reliable, auditable, and continuously updatable counsel. The system prioritizes
retrieval over generation: when a trusted legal repository yields relevant
evidence, answers are produced via RAG; otherwise, multiple LLMs generate
candidates that are scored by a specialized selector, with the top-ranked
answer returned. High-quality outputs then undergo human review before being
written back to the repository, enabling dynamic knowledge evolution and
provenance tracking. Experiments on the Law\_QA dataset show that our hybrid
approach significantly outperforms both a single-model baseline and a vanilla
RAG pipeline on F1, ROUGE-L, and an LLM-as-a-Judge metric. Ablations confirm
the complementary contributions of retrieval prioritization, model ensembling,
and the human-in-the-loop update mechanism. The proposed system demonstrably
reduces hallucination while improving answer quality and legal compliance,
advancing the practical landing of media forensics technologies in judicial
scenarios.

</details>


### [386] [Simulating Environments with Reasoning Models for Agent Training](https://arxiv.org/abs/2511.01824)
*Yuetai Li,Huseyin A Inan,Xiang Yue,Wei-Ning Chen,Lukas Wutschitz,Janardhan Kulkarni,Radha Poovendran,Robert Sim,Saravan Rajmohan*

Main category: cs.AI

TL;DR: 论文提出Simia-SFT和Simia-RL框架，利用LLM模拟环境反馈，实现无需真实环境的可扩展智能体训练，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理在复杂环境中脆弱性高、定制训练环境成本高且限制发展的问题。

Method: 提出Simia-SFT和Simia-RL两个框架：前者通过放大少量种子数据生成多样化轨迹，后者通过LLM模拟反馈实现无真实环境的强化学习训练。

Result: 实验表明，微调后的模型在多个基准测试中表现优于GPT-4o，接近o4-mini在τ²-Bench上的性能。

Conclusion: 通过Simia-SFT和Simia-RL框架，论文展示了无需真实环境数据或API即可实现可扩展的智能体训练，显著提升了模型在多样化任务中的性能。

Abstract: LLM agents excel in compact environments requiring deep reasoning but remain
brittle when operating in broader, more complex contexts that demand robustness
across diverse tools and schemas. Building bespoke environments for training is
heavy, brittle, and limits progress. In this paper, we demonstrate that LLMs
can simulate realistic environment feedback without access to actual testbed
data or APIs. Inspired by this capability, we propose two frameworks:
Simia-SFT, a pipeline that synthesizes SFT data by amplifying small seed sets
into diverse trajectories in an environment-agnostic manner, and Simia-RL, a
framework that enables RL training without real environment implementations
through LLM-simulated feedback. Fine-tuning open models yields consistent
improvements across multiple benchmarks, surpassing GPT-4o and approaching
o4-mini on $\tau^2$-Bench. Together, Simia-SFT and Simia-RL enable scalable
agent training without environment engineering, replacing heavy and brittle
implementations with flexible LLM-based simulation.

</details>
