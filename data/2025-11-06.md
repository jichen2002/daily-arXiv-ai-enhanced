<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 41]
- [cs.DS](#cs.DS) [Total: 13]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.AI](#cs.AI) [Total: 16]
- [cs.SE](#cs.SE) [Total: 19]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.RO](#cs.RO) [Total: 22]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Cropland Mapping using Geospatial Embeddings](https://arxiv.org/abs/2511.02923)
*Ivan Zvonkov,Gabriel Tseng,Inbal Becker-Reshef,Hannah Kerner*

Main category: cs.CV

TL;DR: 地理空间嵌入技术在耕地制图中展现出高效性和高准确性，有助于评估土地利用变化及其气候影响。


<details>
  <summary>Details</summary>
Motivation: 准确且最新的土地覆盖地图对于理解土地利用变化（气候变化的关键驱动因素）至关重要。地理空间嵌入提供了一种更高效、更易获取的景观特征映射方法，但其在实际地图应用中的使用仍有待探索。

Method: 使用Presto和AlphaEarth的地理空间嵌入技术生成耕地地图。

Result: 研究发现，地理空间嵌入可以简化工作流程，实现高精度的耕地分类。

Conclusion: 地理空间嵌入技术能简化工作流程，实现高精度的耕地分类，并最终支持更好地评估土地利用变化及其气候影响。

Abstract: Accurate and up-to-date land cover maps are essential for understanding land
use change, a key driver of climate change. Geospatial embeddings offer a more
efficient and accessible way to map landscape features, yet their use in
real-world mapping applications remains underexplored. In this work, we
evaluated the utility of geospatial embeddings for cropland mapping in Togo. We
produced cropland maps using embeddings from Presto and AlphaEarth. Our
findings show that geospatial embeddings can simplify workflows, achieve
high-accuracy cropland classification and ultimately support better assessments
of land use change and its climate impacts.

</details>


### [2] [Generative Hints](https://arxiv.org/abs/2511.02933)
*Andy Dimnaku,Abdullah Yusuf Kavranoğlu,Yaser Abu-Mostafa*

Main category: cs.CV

TL;DR: 生成提示方法通过生成虚拟样本和半监督学习，优于传统数据增强，显著提升视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 数据增强仅能学习训练数据变换上的不变性，无法充分捕获全局输入空间的不变性。生成提示方法旨在直接在全输入空间中强化已知不变性。

Method: 提出生成提示训练方法，利用生成模型生成未标记的虚拟样本，通过半监督学习结合分类和提示目标，直接在全输入空间中强化已知不变性。

Result: 在细粒度视觉分类基准测试中，生成提示方法平均提升0.63%的top-1准确率（最高提升1.78%），在CheXpert X-ray数据集上平均提升1.286%。

Conclusion: 生成提示方法在多种数据集、架构和损失函数中均优于标准数据增强方法，在细粒度视觉分类任务中实现了显著的准确率提升。

Abstract: Data augmentation is widely used in vision to introduce variation and
mitigate overfitting, through enabling models to learn invariant properties,
such as spatial invariance. However, these properties are not fully captured by
data augmentation alone, since it attempts to learn the property on
transformations of the training data only. We propose generative hints, a
training methodology that directly enforces known invariances in the entire
input space. Our approach leverages a generative model trained on the training
set to approximate the input distribution and generate unlabeled images, which
we refer to as virtual examples. These virtual examples are used to enforce
functional properties known as hints. In generative hints, although the
training dataset is fully labeled, the model is trained in a semi-supervised
manner on both the classification and hint objectives, using the unlabeled
virtual examples to guide the model in learning the desired hint. Across
datasets, architectures, and loss functions, generative hints consistently
outperform standard data augmentation when learning the same property. On
popular fine-grained visual classification benchmarks, we achieved up to 1.78%
top-1 accuracy improvement (0.63% on average) over fine-tuned models with data
augmentation and an average performance boost of 1.286% on the CheXpert X-ray
dataset.

</details>


### [3] [ProM3E: Probabilistic Masked MultiModal Embedding Model for Ecology](https://arxiv.org/abs/2511.02946)
*Srikumar Sastry,Subash Khanal,Aayush Dhakal,Jiayu Lin,Dan Cher,Phoenix Jarosz,Nathan Jacobs*

Main category: cs.CV

TL;DR: ProM3E是一个概率性多模态嵌入模型，支持生态学中的任意模态生成与检索，通过掩码模态重建和模态反转提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决生态学中多模态数据生成与融合的挑战，探索如何有效融合不同模态以提升下游任务性能。

Method: 基于嵌入空间中的掩码模态重建，学习从少量上下文模态推断缺失模态，支持模态反转。

Result: 提出了一种新颖的跨模态检索方法，结合了模态间和模态内相似性，在所有检索任务中表现优异，并通过线性探测任务验证了模型的表示学习能力。

Conclusion: ProM3E通过概率性多模态嵌入模型实现了生态学中任意模态的生成与检索，展示了其在跨模态检索和表示学习方面的优越性能。

Abstract: We introduce ProM3E, a probabilistic masked multimodal embedding model for
any-to-any generation of multimodal representations for ecology. ProM3E is
based on masked modality reconstruction in the embedding space, learning to
infer missing modalities given a few context modalities. By design, our model
supports modality inversion in the embedding space. The probabilistic nature of
our model allows us to analyse the feasibility of fusing various modalities for
given downstream tasks, essentially learning what to fuse. Using these features
of our model, we propose a novel cross-modal retrieval approach that mixes
inter-modal and intra-modal similarities to achieve superior performance across
all retrieval tasks. We further leverage the hidden representation from our
model to perform linear probing tasks and demonstrate the superior
representation learning capability of our model. All our code, datasets and
model will be released at https://vishu26.github.io/prom3e.

</details>


### [4] [EvtSlowTV -- A Large and Diverse Dataset for Event-Based Depth Estimation](https://arxiv.org/abs/2511.02953)
*Sadiq Layi Macaulay,Nimet Kaygusuz,Simon Hadfield*

Main category: cs.CV

TL;DR: EvtSlowTV是一个大规模事件相机数据集，通过自监督学习提升深度估计的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有事件相机深度估计方法因小规模标注数据集而泛化能力受限的问题。

Method: 利用公开的YouTube素材构建EvtSlowTV数据集，包含超过130亿个事件数据，覆盖多种环境和运动场景。采用自监督学习框架，充分利用事件流的高动态范围特性。

Result: EvtSlowTV数据集比现有数据集大一个数量级，能有效提升模型在复杂场景和运动中的泛化性能。

Conclusion: EvtSlowTV数据集通过提供大规模、多样化的自然场景事件数据，显著提升了事件相机在深度估计任务中的泛化能力，特别是在复杂场景和运动中。

Abstract: Event cameras, with their high dynamic range (HDR) and low latency, offer a
promising alternative for robust depth estimation in challenging environments.
However, many event-based depth estimation approaches are constrained by
small-scale annotated datasets, limiting their generalizability to real-world
scenarios. To bridge this gap, we introduce EvtSlowTV, a large-scale event
camera dataset curated from publicly available YouTube footage, which contains
more than 13B events across various environmental conditions and motions,
including seasonal hiking, flying, scenic driving, and underwater exploration.
EvtSlowTV is an order of magnitude larger than existing event datasets,
providing an unconstrained, naturalistic setting for event-based depth
learning. This work shows the suitability of EvtSlowTV for a self-supervised
learning framework to capitalise on the HDR potential of raw event streams. We
further demonstrate that training with EvtSlowTV enhances the model's ability
to generalise to complex scenes and motions. Our approach removes the need for
frame-based annotations and preserves the asynchronous nature of event data.

</details>


### [5] [Hybrid Convolution and Vision Transformer NAS Search Space for TinyML Image Classification](https://arxiv.org/abs/2511.02992)
*Mikhael Djajapermana,Moritz Reiber,Daniel Mueller-Gritschneder,Ulf Schlichtmann*

Main category: cs.CV

TL;DR: 本文提出了一种新型混合CNN-ViT搜索空间，用于NAS，以在严格模型大小限制下生成高效图像分类架构，实验显示其优于ResNet-based tinyML模型。


<details>
  <summary>Details</summary>
Motivation: 由于现有的混合CNN和ViT架构需要大量参数和计算成本，不适用于tinyML部署。

Method: 引入了一种新的混合CNN-ViT搜索空间，用于神经架构搜索（NAS），以寻找高效的图像分类混合架构。搜索空间涵盖了混合CNN和ViT块以学习局部和全局信息，以及可搜索池化层的新型池化块，用于高效的特征图降维。

Result: 在CIFAR10数据集上的实验结果表明，所提出的搜索空间能够生成高效的混合架构。

Conclusion: 提出的搜索空间能够生成在严格模型大小限制下，准确率和推理速度均优于基于ResNet的tinyML模型的混合CNN-ViT架构。

Abstract: Hybrids of Convolutional Neural Network (CNN) and Vision Transformer (ViT)
have outperformed pure CNN or ViT architecture. However, since these
architectures require large parameters and incur large computational costs,
they are unsuitable for tinyML deployment. This paper introduces a new hybrid
CNN-ViT search space for Neural Architecture Search (NAS) to find efficient
hybrid architectures for image classification. The search space covers hybrid
CNN and ViT blocks to learn local and global information, as well as the novel
Pooling block of searchable pooling layers for efficient feature map reduction.
Experimental results on the CIFAR10 dataset show that our proposed search space
can produce hybrid CNN-ViT architectures with superior accuracy and inference
speed to ResNet-based tinyML models under tight model size constraints.

</details>


### [6] [SCALE-VLP: Soft-Weighted Contrastive Volumetric Vision-Language Pre-training with Spatial-Knowledge Semantics](https://arxiv.org/abs/2511.02996)
*Ailar Mahdizadeh,Puria Azadi Moghadam,Xiangteng He,Shahriar Mirabbasi,Panos Nasiopoulos,Leonid Sigal*

Main category: cs.CV

TL;DR: SCALE-VLP通过整合体积和领域语义，显著提升了跨模态任务的性能，尤其在CT相关任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有方法多将体积扫描视为独立的2D切片，忽略了空间连贯性和丰富的临床语义，SCALE-VLP旨在解决这一问题。

Method: 提出SCALE-VLP，一种软加权对比视觉语言预训练框架，结合体积空间语义和领域知识语义（如放射学本体）以指导对齐。

Result: 在CT报告检索、异常分类和报告生成等任务中表现优异，零样本评估中亦表现一致增益。

Conclusion: SCALE-VLP框架通过整合体积空间语义和领域知识语义，在有限监督下实现了结构一致且语义基础的表征，展示了强大的跨任务和跨领域泛化能力。

Abstract: Vision-language models (VLMs) have demonstrated strong cross-modal
capabilities, yet most work remains limited to 2D data and assumes binary
supervision (i.e., positive vs. negative pairs), overlooking the continuous and
structured dependencies present in volumetric data such as CT. Existing
approaches often treat volumetric scans as independent 2D slices, compromising
spatial coherence and underutilizing rich clinical semantics. We propose
SCALE-VLP, a soft-weighted contrastive vision-language pre-training framework
that integrates (i) volumetric spatial semantics to preserve anatomical
structure and (ii) domain-aware, knowledge-infused semantics (e.g.,
radiological ontologies) to guide alignment. This yields structurally
consistent and semantically grounded representations under limited supervision,
demonstrating strong cross-task transferability (retrieval, report generation,
and classification), and cross-domain generalizability with consistent gains
without further fine-tuning. In particular, compared to the previous state of
the art, SCALE-VLP achieves up to 4.3x higher top-1 CT-report retrieval,
improves abnormality classification by 10 points, and reaches ROUGE-L 0.44 and
BERT-F1 0.89 for report generation. Further, in zero-shot evaluation on an
out-of-domain external dataset, we observe consistent gains, indicating the
cross-task and cross-domain generalization ability of SCALE-VLP.

</details>


### [7] [Learning with less: label-efficient land cover classification at very high spatial resolution using self-supervised deep learning](https://arxiv.org/abs/2511.03004)
*Dakota Hester,Vitor S. Martins,Lucas B. Ferreira,Thainara M. A. Lima*

Main category: cs.CV

TL;DR: 本研究提出了一种标签高效的自监督学习方法，仅需1000个标注图像块即可实现州级1米土地覆盖分类，显著减少了对大规模手动标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 收集大量代表性训练数据是广泛采用深度学习语义分割方法进行米级土地覆盖分类的主要障碍，因此需要一种标签高效的解决方案。

Method: 使用'Bootstrap Your Own Latent'预训练策略，结合大量未标记的红外航空图像（377,921个256x256像素块）预训练ResNet-101卷积编码器，并将学习到的权重转移到多个深度语义分割架构（FCN、U-Net、Attention U-Net、DeepLabV3+、UPerNet、PAN），然后使用非常小的训练数据集（250、500、750个图像块）进行微调。

Result: 在微调模型中，使用表现最佳的U-Net模型集成，获得了87.14%的整体准确率和75.58%的宏观F1分数，覆盖了美国密西西比州超过1230亿像素的8类土地覆盖。

Conclusion: 自监督学习是减少大规模高分辨率土地覆盖分类中手动标注数据需求的有效策略，解决了大规模应用的主要限制。

Abstract: Deep learning semantic segmentation methods have shown promising performance
for very high 1-m resolution land cover classification, but the challenge of
collecting large volumes of representative training data creates a significant
barrier to widespread adoption of such models for meter-scale land cover
mapping over large areas. In this study, we present a novel label-efficient
approach for statewide 1-m land cover classification using only 1,000 annotated
reference image patches with self-supervised deep learning. We use the
"Bootstrap Your Own Latent" pre-training strategy with a large amount of
unlabeled color-infrared aerial images (377,921 256x256 1-m pixel patches) to
pre-train a ResNet-101 convolutional encoder. The learned encoder weights were
subsequently transferred into multiple deep semantic segmentation architectures
(FCN, U-Net, Attention U-Net, DeepLabV3+, UPerNet, PAN), which were then
fine-tuned using very small training dataset sizes with cross-validation (250,
500, 750 patches). Among the fine-tuned models, we obtained the 87.14% overall
accuracy and 75.58% macro F1 score using an ensemble of the best performing
U-Net models for comprehensive 1-m, 8-class land cover mapping, covering more
than 123 billion pixels over the state of Mississippi, USA. Detailed
qualitative and quantitative analysis revealed accurate mapping of open water
and forested areas, while highlighting challenges in accurate delineation
between cropland, herbaceous, and barren land cover types. These results show
that self-supervised learning is an effective strategy for reducing the need
for large volumes of manually annotated data, directly addressing a major
limitation to high spatial resolution land cover mapping at scale.

</details>


### [8] [A Foundation Model for Brain MRI with Dynamic Modality Integration](https://arxiv.org/abs/2511.03014)
*Minh Sao Khue Luu,Bair N. Tuchinov*

Main category: cs.CV

TL;DR: 提出了一种适用于不同MRI序列组合的基础模型，通过自监督学习实现灵活表征，初步验证有效且代码开源。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需为每种MRI序列组合单独建模的局限性，提升模型在模态缺失或未知情况下的适应性。

Method: 使用带有可学习模态嵌入的编码器、条件层归一化和掩码自编码目标，结合方差-协方差正则化器来稳定特征学习。

Result: 初步结果表明该方法可行，计划进一步评估其在脑肿瘤、多发性硬化症分割及病变分类中的表现。

Conclusion: 该方法通过统一的编码器和可学习的模态嵌入，实现了对不同MRI序列组合的灵活处理，且在模态缺失情况下仍能稳定工作。所有代码和预训练模型已开源。

Abstract: We present a foundation model for brain MRI that can work with different
combinations of imaging sequences. The model uses one encoder with learnable
modality embeddings, conditional layer normalization, and a masked autoencoding
objective that accounts for missing modalities. A variance-covariance
regularizer is applied to stabilize feature learning and improve representation
diversity. This design removes the need for separate models for each modality
and allows the network to adapt when some sequences are missing or unseen. It
is trained on about 60,000 multi-center MRIs using self-supervised
reconstruction and modality imputation to learn flexible representations. A
learnable modality embedding guides feature extraction so the encoder can
adjust to different inputs. We describe our planned evaluation on brain tumor
and multiple sclerosis segmentation, as well as lesion classification, under
various modality settings. Preliminary results show that the method works
feasibly, and further experiments are planned to study its performance in more
detail. All code and pretrained models are available at
https://github.com/BrainFM/brainfm

</details>


### [9] [SLIP: Structural-aware Language-Image Pretraining for Vision-Language Alignment](https://arxiv.org/abs/2511.03019)
*Wenbo Lu*

Main category: cs.CV

TL;DR: SLIP通过结构对比损失建模关系结构，在跨模态任务中优于CLIP，证明了关系监督的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言预训练方法将图像-文本对视为孤立训练样本，忽略了领域内丰富的自然关系结构。受人类编码知识为关系认知图的启发，提出了SLIP。

Method: SLIP结合了结构对比损失，不仅对齐了不同模态，还建模了结构化图中相邻实体之间的关系。

Result: SLIP在零样本和少样本设置下，跨模态检索和分类任务中一致优于CLIP，验证了关系监督对跨模态对齐的价值。

Conclusion: SLIP通过引入结构对比损失，成功地将关系结构融入多模态预训练，显著提升了跨模态检索和分类任务的性能。

Abstract: Vision-Language Pretraining (VLP) has achieved remarkable success across
various downstream tasks, but such gains are largely driven by scaling up on
training data. Yet, literature methods treat image-text pairs as isolated
training examples; this neglects the rich relational structure naturally
present in many domains, such as e-commerce product co-purchase graphs and
social recommendation networks. Inspired by neuroscientific evidence that human
encodes knowledge as relationship cognitive maps, we introduce Structure-aware
Language-Image Pretraining (SLIP). SLIP integrates a structural contrastive
loss to align modalities while also modeling relationships between neighboring
entities in a structured graph. To support this paradigm, we construct a
large-scale Amazon Product Co-purchase Multimodal Graph Dataset, enabling
structured cross-modality supervision at scale. Experiment results show that
SLIP consistently outperforms CLIP on cross-modal retrieval and classification
tasks in both zero-shot and few-shot settings, showing the value of relational
supervision for cross-modal alignment.

</details>


### [10] [From Propagation to Prediction: Point-level Uncertainty Evaluation of MLS Point Clouds under Limited Ground Truth](https://arxiv.org/abs/2511.03053)
*Ziyang Xu,Olaf Wysocki,Christoph Holst*

Main category: cs.CV

TL;DR: 本研究提出了一种基于学习的框架，用于评估MLS点云不确定性，减少对GT的依赖，实验证明该方法高效且准确。


<details>
  <summary>Details</summary>
Motivation: 评估不确定性对于高精度应用至关重要，但获取真实数据（GT）成本高且难以实现，因此需要减少对GT的依赖。

Method: 该研究结合了最优邻域估计与几何特征提取，提出了一种学习框架，并在真实数据集上进行了实验验证。

Result: 实验结果表明，提出的框架是可行的，XGBoost模型在保持与随机森林相当精度的同时，效率显著提高（约快3倍），几何特征可用于预测点级不确定性。

Conclusion: 本研究提出了一种基于学习的框架，用于评估移动激光扫描（MLS）点云的不确定性，展示了不确定性是可学习的，为不确定性评估研究提供了新的视角。

Abstract: Evaluating uncertainty is critical for reliable use of Mobile Laser Scanning
(MLS) point clouds in many high-precision applications such as Scan-to-BIM,
deformation analysis, and 3D modeling. However, obtaining the ground truth (GT)
for evaluation is often costly and infeasible in many real-world applications.
To reduce this long-standing reliance on GT in uncertainty evaluation research,
this study presents a learning-based framework for MLS point clouds that
integrates optimal neighborhood estimation with geometric feature extraction.
Experiments on a real-world dataset show that the proposed framework is
feasible and the XGBoost model delivers fully comparable accuracy to Random
Forest while achieving substantially higher efficiency (about 3 times faster),
providing initial evidence that geometric features can be used to predict
point-level uncertainty quantified by the C2C distance. In summary, this study
shows that MLS point clouds' uncertainty is learnable, offering a novel
learning-based viewpoint towards uncertainty evaluation research.

</details>


### [11] [A Plug-and-Play Framework for Volumetric Light-Sheet Image Reconstruction](https://arxiv.org/abs/2511.03093)
*Yi Gong,Xinyuan Zhang,Jichen Chai,Yichen Ding,Yifei Lou*

Main category: cs.CV

TL;DR: 论文提出了一种结合压缩感知和光片显微镜的计算成像框架，通过高级去噪技术和时间正则化，成功实现了高速、低光条件下的心脏成像，实验验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统光学成像在捕捉跳动心脏的动态细胞结构时，因空间与时间分辨率之间的固有权衡而表现不足。为了克服这些限制，作者提出了这一框架。

Method: 论文提出了一种高性能计算成像框架，结合压缩感知（CS）与光片显微镜（LSM），通过数字微镜设备（DMD）进行随机二进制掩码编码的压缩采集，并采用Plug-and-Play（PnP）框架和ADMM算法，灵活整合了Tikhonov、TV和BM3D等高级去噪技术。

Result: 在斑马鱼心脏成像的高压缩比实验中，该方法成功重建了细胞结构，表现出优异的去噪性能和图像清晰度。

Conclusion: 该论文提出的集成压缩感知与光片显微镜的计算成像框架，结合高级去噪技术和时间正则化，成功实现了在高速、低光条件下的生物心脏成像，验证了算法的有效性和鲁棒性。

Abstract: Cardiac contraction is a rapid, coordinated process that unfolds across
three-dimensional tissue on millisecond timescales. Traditional optical imaging
is often inadequate for capturing dynamic cellular structure in the beating
heart because of a fundamental trade-off between spatial and temporal
resolution. To overcome these limitations, we propose a high-performance
computational imaging framework that integrates Compressive Sensing (CS) with
Light-Sheet Microscopy (LSM) for efficient, low-phototoxic cardiac imaging. The
system performs compressed acquisition of fluorescence signals via random
binary mask coding using a Digital Micromirror Device (DMD). We propose a
Plug-and-Play (PnP) framework, solved using the alternating direction method of
multipliers (ADMM), which flexibly incorporates advanced denoisers, including
Tikhonov, Total Variation (TV), and BM3D. To preserve structural continuity in
dynamic imaging, we further introduce temporal regularization enforcing
smoothness between adjacent z-slices. Experimental results on zebrafish heart
imaging under high compression ratios demonstrate that the proposed method
successfully reconstructs cellular structures with excellent denoising
performance and image clarity, validating the effectiveness and robustness of
our algorithm in real-world high-speed, low-light biological imaging scenarios.

</details>


### [12] [ISC-Perception: A Hybrid Computer Vision Dataset for Object Detection in Novel Steel Assembly](https://arxiv.org/abs/2511.03098)
*Miftahur Rahman,Samuel Adebayo,Dorian A. Acevedo-Mejia,David Hester,Daniel McPolin,Karen Rafferty,Debra F. Laefer*

Main category: cs.CV

TL;DR: ISC-Perception是首个专为ISC组件检测设计的混合数据集，显著提升了检测精度并减少了人工标注时间。


<details>
  <summary>Details</summary>
Motivation: 解决建筑工地由于安全和隐私问题难以收集大量真实图像，导致ISC感知系统缺乏专用图像库的挑战。

Method: 通过结合程序化渲染的CAD图像、游戏引擎生成的逼真场景以及少量精选的真实照片，构建了首个专为ISC组件检测设计的混合数据集。

Result: 在IoU 0.50条件下，基于ISC-Perception训练的检测器平均精度达到0.756，显著优于仅使用合成或逼真数据训练的模型。

Conclusion: ISC-Perception数据集成功填补了建筑机器人感知领域的数据空白，显著提升了ISC组件检测的准确率，并为研究和工业应用提供了免费资源。

Abstract: The Intermeshed Steel Connection (ISC) system, when paired with robotic
manipulators, can accelerate steel-frame assembly and improve worker safety by
eliminating manual assembly. Dependable perception is one of the initial stages
for ISC-aware robots. However, this is hampered by the absence of a dedicated
image corpus, as collecting photographs on active construction sites is
logistically difficult and raises safety and privacy concerns. In response, we
introduce ISC-Perception, the first hybrid dataset expressly designed for ISC
component detection. It blends procedurally rendered CAD images, game-engine
photorealistic scenes, and a limited, curated set of real photographs, enabling
fully automatic labelling of the synthetic portion. We explicitly account for
all human effort to produce the dataset, including simulation engine and scene
setup, asset preparation, post-processing scripts and quality checks; our total
human time to generate a 10,000-image dataset was 30.5,h versus 166.7,h for
manual labelling at 60,s per image (-81.7%). A manual pilot on a representative
image with five instances of ISC members took 60,s (maximum 80,s), anchoring
the manual baseline. Detectors trained on ISC-Perception achieved a mean
Average Precision at IoU 0.50 of 0.756, substantially surpassing models trained
on synthetic-only or photorealistic-only data. On a 1,200-frame bench test, we
report mAP@0.50/mAP@[0.50:0.95] of 0.943/0.823. By bridging the data gap for
construction-robotics perception, ISC-Perception facilitates rapid development
of custom object detectors and is freely available for research and industrial
use upon request.

</details>


### [13] [DentalSplat: Dental Occlusion Novel View Synthesis from Sparse Intra-Oral Photographs](https://arxiv.org/abs/2511.03099)
*Yiyi Miao,Taoyu Wu,Tong Chen,Sihao Li,Ji Jiang,Youpeng Yang,Angelos Stefanidis,Limin Yu,Jionglong Su*

Main category: cs.CV

TL;DR: DentalSplat通过先验引导和光流约束，有效解决了正畸稀疏图像的三维重建难题，提升了渲染质量。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯抛射（3DGS）依赖密集多视角输入和精确相机姿态初始化，而正畸案例通常仅有三张稀疏图像（前视图和双侧颊视图），导致重建质量严重下降且缺乏相机姿态信息。

Method: 结合先验引导的密集立体重建模型初始化点云，采用尺度自适应的剪枝策略优化3D高斯抛射的训练效率和重建质量。在极端稀疏视角下，引入光流作为几何约束和梯度正则化。

Result: 在大规模临床数据集（950例）和视频测试集（195例）上验证，DentalSplat在稀疏输入场景下实现了优异的新视角合成质量。

Conclusion: DentalSplat框架在稀疏正畸图像的三维重建中表现出色，显著提升了重建质量和渲染保真度，优于现有技术。

Abstract: In orthodontic treatment, particularly within telemedicine contexts,
observing patients' dental occlusion from multiple viewpoints facilitates
timely clinical decision-making. Recent advances in 3D Gaussian Splatting
(3DGS) have shown strong potential in 3D reconstruction and novel view
synthesis. However, conventional 3DGS pipelines typically rely on densely
captured multi-view inputs and precisely initialized camera poses, limiting
their practicality. Orthodontic cases, in contrast, often comprise only three
sparse images, specifically, the anterior view and bilateral buccal views,
rendering the reconstruction task especially challenging. The extreme sparsity
of input views severely degrades reconstruction quality, while the absence of
camera pose information further complicates the process. To overcome these
limitations, we propose DentalSplat, an effective framework for 3D
reconstruction from sparse orthodontic imagery. Our method leverages a
prior-guided dense stereo reconstruction model to initialize the point cloud,
followed by a scale-adaptive pruning strategy to improve the training
efficiency and reconstruction quality of 3DGS. In scenarios with extremely
sparse viewpoints, we further incorporate optical flow as a geometric
constraint, coupled with gradient regularization, to enhance rendering
fidelity. We validate our approach on a large-scale dataset comprising 950
clinical cases and an additional video-based test set of 195 cases designed to
simulate real-world remote orthodontic imaging conditions. Experimental results
demonstrate that our method effectively handles sparse input scenarios and
achieves superior novel view synthesis quality for dental occlusion
visualization, outperforming state-of-the-art techniques.

</details>


### [14] [Image-Intrinsic Priors for Integrated Circuit Defect Detection and Novel Class Discovery via Self-Supervised Learning](https://arxiv.org/abs/2511.03120)
*Botong. Zhao,Xubin. Wang,Shujing. Lyu,Yue. Lu*

Main category: cs.CV

TL;DR: 提出IC DefectNCD框架，利用图像固有先验进行无监督缺陷检测和新类别发现，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决集成电路制造中缺陷检测的监督方法依赖人工标注、无监督方法性能不稳定的问题。

Method: 框架包含自标准信息引导的缺陷检测、自适应二值化策略和自缺陷信息引导的缺陷分类，结合了教师-学生模型和软掩膜注意力机制。

Result: 在涵盖15种缺陷类型的真实数据集上验证了方法的鲁棒性。

Conclusion: IC DefectNCD框架通过利用IC SEM图像的固有先验，实现了无监督的缺陷检测和新类别发现，且在真实数据集上表现出色。

Abstract: Integrated circuit manufacturing is highly complex, comprising hundreds of
process steps. Defects can arise at any stage, causing yield loss and
ultimately degrading product reliability. Supervised methods require extensive
human annotation and struggle with emergent categories and rare, data scarce
defects. Clustering-based unsupervised methods often exhibit unstable
performance due to missing priors. We propose IC DefectNCD, a support set free
framework that leverages Image Intrinsic Priors in IC SEM images for defect
detection and novel class discovery. We first develop Self Normal Information
Guided IC Defect Detection, aggregating representative normal features via a
learnable normal information extractor and using reconstruction residuals to
coarsely localize defect regions. To handle saliency variations across defects,
we introduce an adaptive binarization strategy that produces stable subimages
focused on core defective areas. Finally, we design Self Defect Information
Guided IC Defect Classification, which incorporates a soft mask guided
attention mechanism to inject spatial defect priors into the teacher student
model. This enhances sensitivity to defective regions, suppresses background
interference, and enables recognition and classification of unseen defects. We
validate the approach on a real world dataset spanning three key fabrication
stages and covering 15 defect types. Experiments demonstrate robust performance
on both defect detection and unseen defect classification.

</details>


### [15] [Accelerating Physical Property Reasoning for Augmented Visual Cognition](https://arxiv.org/abs/2511.03126)
*Hongbo Lan,Zhenlin An,Haoyu Li,Vaibhav Singh,Longfei Shangguan*

Main category: cs.CV

TL;DR: \sysname通过多优化技术将视觉推理延迟从分钟级降至秒级，并在真实环境中验证了其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 减少视觉引导物理属性推理的运行延迟，提升智能设备在复杂环境中的视觉认知能力。

Method: 结合快速几何3D重建、高效语义特征融合和并行视图编码等优化技术。

Result: 将端到端延迟从10-20分钟降至6秒以下，在ABO数据集上实现62.9×-287.2×加速，并在物体级物理属性估计（如质量）和材料分割等方面优于现有技术。

Conclusion: \sysname通过算法和系统优化显著加速了视觉引导的物理属性推理，在真实环境中表现优异，为智能眼镜等设备提供了高效的视觉认知增强方案。

Abstract: This paper introduces \sysname, a system that accelerates vision-guided
physical property reasoning to enable augmented visual cognition. \sysname
minimizes the run-time latency of this reasoning pipeline through a combination
of both algorithmic and systematic optimizations, including rapid geometric 3D
reconstruction, efficient semantic feature fusion, and parallel view encoding.
Through these simple yet effective optimizations, \sysname reduces the
end-to-end latency of this reasoning pipeline from 10--20 minutes to less than
6 seconds. A head-to-head comparison on the ABO dataset shows that \sysname
achieves this 62.9$\times$--287.2$\times$ speedup while not only reaching
on-par (and sometimes slightly better) object-level physical property
estimation accuracy(e.g. mass), but also demonstrating superior performance in
material segmentation and voxel-level inference than two SOTA baselines. We
further combine gaze-tracking with \sysname to localize the object of interest
in cluttered, real-world environments, streamlining the physical property
reasoning on smart glasses. The case study with Meta Aria Glasses conducted at
an IKEA furniture store demonstrates that \sysname achives consistently high
performance compared to controlled captures, providing robust property
estimations even with fewer views in real-world scenarios.

</details>


### [16] [Deploying Rapid Damage Assessments from sUAS Imagery for Disaster Response](https://arxiv.org/abs/2511.03132)
*Thomas Manzini,Priyankari Perali,Robin R. Murphy*

Main category: cs.CV

TL;DR: 首个用于无人机影像建筑损坏评估的AI/ML系统，在飓风灾害中实际部署，显著提升了评估效率。


<details>
  <summary>Details</summary>
Motivation: 解决灾害现场因无人机影像数据量过大而无法及时传输或由专家解读的问题，以加快灾害响应速度。

Method: 利用计算机视觉和机器学习技术，在最大的灾后无人机航空影像数据集上进行模型训练，并对91名灾害从业者进行培训。

Result: 最佳模型在飓风Debby和Helene的响应中评估了415栋建筑，耗时约18分钟。

Conclusion: 该论文通过开发和部署用于无人机影像建筑损坏评估的模型，建立了实践标准，并为AI/ML研究和用户社区提供了实际应用经验和教训。

Abstract: This paper presents the first AI/ML system for automating building damage
assessment in uncrewed aerial systems (sUAS) imagery to be deployed
operationally during federally declared disasters (Hurricanes Debby and
Helene). In response to major disasters, sUAS teams are dispatched to collect
imagery of the affected areas to assess damage; however, at recent disasters,
teams collectively delivered between 47GB and 369GB of imagery per day,
representing more imagery than can reasonably be transmitted or interpreted by
subject matter experts in the disaster scene, thus delaying response efforts.
To alleviate this data avalanche encountered in practice, computer vision and
machine learning techniques are necessary. While prior work has been deployed
to automatically assess damage in satellite imagery, there is no current state
of practice for sUAS-based damage assessment systems, as all known work has
been confined to academic settings. This work establishes the state of practice
via the development and deployment of models for building damage assessment
with sUAS imagery. The model development involved training on the largest known
dataset of post-disaster sUAS aerial imagery, containing 21,716 building damage
labels, and the operational training of 91 disaster practitioners. The best
performing model was deployed during the responses to Hurricanes Debby and
Helene, where it assessed a combined 415 buildings in approximately 18 minutes.
This work contributes documentation of the actual use of AI/ML for damage
assessment during a disaster and lessons learned to the benefit of the AI/ML
research and user communities.

</details>


### [17] [Finetuning-Free Personalization of Text to Image Generation via Hypernetworks](https://arxiv.org/abs/2511.03156)
*Sagar Shrestha,Gopal Sharma,Luowei Zhou,Suren Kumar*

Main category: cs.CV

TL;DR: 提出一种基于Hypernetworks的免微调个性化文本到图像生成方法，结合HM-CFG技术，显著提升效率和效果。


<details>
  <summary>Details</summary>
Motivation: 传统个性化文本到图像方法（如DreamBooth）计算成本高且推理慢，现有适配器和编码器方法仍需额外微调或大型骨干模型。

Method: 采用Hypernetworks直接预测LoRA权重，结合端到端训练目标和输出正则化，引入HM-CFG技术增强推理时的组合泛化能力。

Result: 在CelebA-HQ、AFHQ-v2和DreamBench上的实验表明，该方法在个性化性能上表现优异。

Conclusion: 该方法通过Hypernetworks预测LoRA权重，结合HM-CFG技术，实现了高效且高质量的个性化文本到图像生成，无需针对每个主题进行优化。

Abstract: Personalizing text-to-image diffusion models has traditionally relied on
subject-specific fine-tuning approaches such as
DreamBooth~\cite{ruiz2023dreambooth}, which are computationally expensive and
slow at inference. Recent adapter- and encoder-based methods attempt to reduce
this overhead but still depend on additional fine-tuning or large backbone
models for satisfactory results. In this work, we revisit an orthogonal
direction: fine-tuning-free personalization via Hypernetworks that predict
LoRA-adapted weights directly from subject images. Prior hypernetwork-based
approaches, however, suffer from costly data generation or unstable attempts to
mimic base model optimization trajectories. We address these limitations with
an end-to-end training objective, stabilized by a simple output regularization,
yielding reliable and effective hypernetworks. Our method removes the need for
per-subject optimization at test time while preserving both subject fidelity
and prompt alignment. To further enhance compositional generalization at
inference time, we introduce Hybrid-Model Classifier-Free Guidance (HM-CFG),
which combines the compositional strengths of the base diffusion model with the
subject fidelity of personalized models during sampling. Extensive experiments
on CelebA-HQ, AFHQ-v2, and DreamBench demonstrate that our approach achieves
strong personalization performance and highlights the promise of hypernetworks
as a scalable and effective direction for open-category personalization.

</details>


### [18] [Subsampled Randomized Fourier GaLore for Adapting Foundation Models in Depth-Driven Liver Landmark Segmentation](https://arxiv.org/abs/2511.03163)
*Yun-Chen Lin,Jiayuan Huang,Hanyuan Zhang,Sergi Kavtaradze,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 提出了一种深度引导的肝脏标志分割框架，结合SAM2和DA2编码器，使用SRFT-GaLore高效微调，显著提升了分割精度和跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在腹腔镜肝脏手术中，2D视频流限制了深度感知，增加了标志定位的难度，需要融合RGB和深度特征并高效适应大规模视觉模型。

Method: 提出了一种结合语义和几何线索的深度引导肝脏标志分割框架，使用SAM2和DA2编码器提取RGB和深度特征，并引入SRFT-GaLore进行高效微调。

Result: 在L3D数据集上，Dice相似系数提高了4.85%，平均对称表面距离降低了11.78分，并在LLSD数据集上表现出强健的跨数据集泛化能力。

Conclusion: SRFT-GaLore增强的双编码器框架在深度受限的手术环境中实现了可扩展且精确的分割。

Abstract: Accurate detection and delineation of anatomical structures in medical
imaging are critical for computer-assisted interventions, particularly in
laparoscopic liver surgery where 2D video streams limit depth perception and
complicate landmark localization. While recent works have leveraged monocular
depth cues for enhanced landmark detection, challenges remain in fusing RGB and
depth features and in efficiently adapting large-scale vision models to
surgical domains. We propose a depth-guided liver landmark segmentation
framework integrating semantic and geometric cues via vision foundation
encoders. We employ Segment Anything Model V2 (SAM2) encoder to extract RGB
features and Depth Anything V2 (DA2) encoder to extract depth-aware features.
To efficiently adapt SAM2, we introduce SRFT-GaLore, a novel low-rank gradient
projection method that replaces the computationally expensive SVD with a
Subsampled Randomized Fourier Transform (SRFT). This enables efficient
fine-tuning of high-dimensional attention layers without sacrificing
representational power. A cross-attention fusion module further integrates RGB
and depth cues. To assess cross-dataset generalization, we also construct a new
Laparoscopic Liver Surgical Dataset (LLSD) as an external validation benchmark.
On the public L3D dataset, our method achieves a 4.85% improvement in Dice
Similarity Coefficient and a 11.78-point reduction in Average Symmetric Surface
Distance compared to the D2GPLand. To further assess generalization capability,
we evaluate our model on LLSD dataset. Our model maintains competitive
performance and significantly outperforms SAM-based baselines, demonstrating
strong cross-dataset robustness and adaptability to unseen surgical
environments. These results demonstrate that our SRFT-GaLore-enhanced
dual-encoder framework enables scalable and precise segmentation under
real-time, depth-constrained surgical settings.

</details>


### [19] [SurgAnt-ViVQA: Learning to Anticipate Surgical Events through GRU-Driven Temporal Cross-Attention](https://arxiv.org/abs/2511.03178)
*Shreyas C. Dhake,Jiayuan Huang,Runlong He,Danyal Z. Khan,Evangelos B. Mazomenos,Sophia Bano,Hani J. Marcus,Danail Stoyanov,Matthew J. Clarkson,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: 该研究提出首个面向前瞻性手术推理的 VQA 数据集 PitVQA-Anticipation 和 SurgAnt-ViVQA 模型，通过时序建模和门控融合实现了对未来手术事件的预测能力。


<details>
  <summary>Details</summary>
Motivation: 现有手术 VQA 系统和数据集主要关注当前场景而非未来预测，限制了其在快速变化的手术工作流中的实时辅助能力。

Method: 提出 SurgAnt-ViVQA 模型，采用 GRU 门控时序交叉注意力模块，通过双向 GRU 编码帧间动态，自适应门在 token 级别注入视觉上下文，并通过参数高效微调定制语言主干。

Result: SurgAnt-ViVQA 在 PitVQA-Anticipation 和 EndoVis 数据集上表现优于基于图像和视频的基线模型，时序循环和门控融合是性能提升的主要驱动因素。

Conclusion: PitVQA-Anticipation 数据集和 SurgAnt-ViVQA 模型共同推动了手术 VQA 系统从回顾性描述向前瞻性预测的转变，强调了针对性时序建模在未来感知手术辅助中的重要性。

Abstract: Anticipating forthcoming surgical events is vital for real-time assistance in
endonasal transsphenoidal pituitary surgery, where visibility is limited and
workflow changes rapidly. Most visual question answering (VQA) systems reason
on isolated frames with static vision language alignment, providing little
support for forecasting next steps or instrument needs. Existing surgical VQA
datasets likewise center on the current scene rather than the near future. We
introduce PitVQA-Anticipation, the first VQA dataset designed for forward
looking surgical reasoning. It comprises 33.5 hours of operative video and
734,769 question answer pairs built from temporally grouped clips and expert
annotations across four tasks: predicting the future phase, next step, upcoming
instrument, and remaining duration. We further propose SurgAnt-ViVQA, a video
language model that adapts a large language model using a GRU Gated Temporal
Cross-Attention module. A bidirectional GRU encodes frame to frame dynamics,
while an adaptive gate injects visual context into the language stream at the
token level. Parameter efficient fine tuning customizes the language backbone
to the surgical domain. SurgAnt-ViVQA tested upon on PitVQA-Anticipation and
EndoVis datasets, surpassing strong image and video based baselines. Ablations
show that temporal recurrence and gated fusion drive most of the gains. A frame
budget study indicates a trade-off: 8 frames maximize fluency, whereas 32
frames slightly reduce BLEU but improve numeric time estimation. By pairing a
temporally aware encoder with fine grained gated cross-attention, SurgAnt-ViVQA
advances surgical VQA from retrospective description to proactive anticipation.
PitVQA-Anticipation offers a comprehensive benchmark for this setting and
highlights the importance of targeted temporal modeling for reliable, future
aware surgical assistance.

</details>


### [20] [PETWB-REP: A Multi-Cancer Whole-Body FDG PET/CT and Radiology Report Dataset for Medical Imaging Research](https://arxiv.org/abs/2511.03194)
*Le Xue,Gang Feng,Wenbo Zhang,Yichi Zhang,Lanlan Li,Shuqi Wang,Liling Peng,Sisi Peng,Xin Gao*

Main category: cs.CV

TL;DR: PETWB-REP是一个包含490名患者全身PET/CT扫描和放射学报告的多癌种数据集，旨在支持医学影像和AI研究。


<details>
  <summary>Details</summary>
Motivation: 现有公开的大规模医学影像数据集缺乏结合功能与解剖成像及详细临床报告的多癌种数据，限制了AI模型开发和临床研究的进展。

Method: 通过收集490名患者的全身18F-FDG PET/CT扫描及相应放射学报告，构建了一个包含多种恶性肿瘤（如肺癌、肝癌、乳腺癌、前列腺癌和卵巢癌）的 curated数据集。

Result: 构建了PETWB-REP数据集，包含配对的PET/CT图像、去标识化文本报告和结构化临床元数据，覆盖多种常见癌症。

Conclusion: PETWB-REP数据集为医学影像、放射组学、人工智能及多模态学习研究提供了宝贵的资源，填补了多癌种功能与解剖成像结合临床报告的空白。

Abstract: Publicly available, large-scale medical imaging datasets are crucial for
developing and validating artificial intelligence models and conducting
retrospective clinical research. However, datasets that combine functional and
anatomical imaging with detailed clinical reports across multiple cancer types
remain scarce. Here, we present PETWB-REP, a curated dataset comprising
whole-body 18F-Fluorodeoxyglucose (FDG) Positron Emission Tomography/Computed
Tomography (PET/CT) scans and corresponding radiology reports from 490 patients
diagnosed with various malignancies. The dataset primarily includes common
cancers such as lung cancer, liver cancer, breast cancer, prostate cancer, and
ovarian cancer. This dataset includes paired PET and CT images, de-identified
textual reports, and structured clinical metadata. It is designed to support
research in medical imaging, radiomics, artificial intelligence, and
multi-modal learning.

</details>


### [21] [QG-CoC: Question-Guided Chain-of-Captions for Large Multimodal Models](https://arxiv.org/abs/2511.03206)
*Kuei-Chun Kao,Hsu Tzu-Yin,Yunqi Hong,Ruochen Wang,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: QG-CoC是一种新型零样本提示方法，有效解决了多模态大语言模型在多图像环境中的感知和推理问题，并在实验中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在多图像环境中存在细粒度感知不足和信息整合能力下降的问题，而现有研究主要集中于单图像或特定场景，缺乏对复杂多图像推理任务的普遍解决方案。

Method: 提出了一种新的零样本提示方法Question-Guided Chain-of-Captions (QG-CoC)，该方法通过问题引导的链式描述来处理多图像推理任务。

Result: 实验结果表明，QG-CoC在多种开源和闭源MLLMs上对多图像和单图像基准测试均表现出竞争力，并在现有方法失败的挑战性场景中显著改进。

Conclusion: QG-CoC是一种有效的零样本提示方法，能够在处理任意数量图像的复杂任务中展现出竞争力，并在现有方法失败的挑战性场景中表现出稳健的改进。

Abstract: Recently, Multimodal Large Language Models (MLLMs) encounter two key issues
in multi-image contexts: (1) a lack of fine-grained perception across disparate
images, and (2) a diminished capability to effectively reason over and
synthesize information from multiple visual inputs. However, while various
prompting methods aim to describe visual content, many existing studies focus
primarily on single-image settings or specific, constrained scenarios. This
leaves a critical gap in understanding and addressing how MLLMs tackle more
general and complex multi-image reasoning tasks. Thus, we first extensively
investigate how current prompting methods perceive fine-grained visual details
and process visual information when dealing with multiple images. Our findings
reveal that existing prompting methods fall short in attending to needed clues
and seamlessly integrating perception and reasoning. Inspired by the findings,
we propose a new zero-shot prompting method, Question-Guided Chain-of-Captions
(QG-CoC), a generalized prompting approach that effectively handles problems
with an arbitrary number of images. We evaluate our method on various
open-source and closed-source MLLMs for multi-image and single-image
benchmarks. Experimental results indicate that QG-CoC demonstrates competitive
performance across tasks and exhibits robust improvements in the challenging
scenarios where existing prompting methods fail.

</details>


### [22] [MvBody: Multi-View-Based Hybrid Transformer Using Optical 3D Body Scan for Explainable Cesarean Section Prediction](https://arxiv.org/abs/2511.03212)
*Ruting Cheng,Boyuan Feng,Yijiang Zheng,Chuhui Qiu,Aizierjiang Aiersilan,Joaquin A. Calderon,Wentao Zhao,Qing Pan,James K. Hahn*

Main category: cs.CV

TL;DR: 本研究开发了MvBody模型，利用3D身体扫描和自报数据预测剖宫产风险，适用于资源有限环境，表现优于现有方法，关键预测因素包括孕前体重、产妇年龄和身体形状。


<details>
  <summary>Details</summary>
Motivation: 在医疗资源有限的地区，早期可靠的剖宫产风险预测对于改善母婴健康至关重要。现有模型大多依赖医院内参数，无法适用于资源有限或家庭环境，因此本研究探索利用3D身体形状进行风险评估的可行性。

Method: 本研究提出了一种基于多视图的Transformer网络MvBody，仅利用自报医疗数据和妊娠31至38周期间获取的3D光学身体扫描数据进行剖宫产风险预测，并引入度量学习损失以提高在数据稀缺环境中的训练效率和模型泛化能力。

Result: 与广泛使用的机器学习模型和最新的3D分析方法相比，MvBody在独立测试集上表现出色，准确率达到84.62%，AUC-ROC为0.724。

Conclusion: 研究结果表明，孕前体重、产妇年龄、产科病史、既往剖宫产史以及身体形状（尤其是头部和肩部）是预测剖宫产风险的关键因素。

Abstract: Accurately assessing the risk of cesarean section (CS) delivery is critical,
especially in settings with limited medical resources, where access to
healthcare is often restricted. Early and reliable risk prediction allows
better-informed prenatal care decisions and can improve maternal and neonatal
outcomes. However, most existing predictive models are tailored for in-hospital
use during labor and rely on parameters that are often unavailable in
resource-limited or home-based settings. In this study, we conduct a pilot
investigation to examine the feasibility of using 3D body shape for CS risk
assessment for future applications with more affordable general devices. We
propose a novel multi-view-based Transformer network, MvBody, which predicts CS
risk using only self-reported medical data and 3D optical body scans obtained
between the 31st and 38th weeks of gestation. To enhance training efficiency
and model generalizability in data-scarce environments, we incorporate a metric
learning loss into the network. Compared to widely used machine learning models
and the latest advanced 3D analysis methods, our method demonstrates superior
performance, achieving an accuracy of 84.62% and an Area Under the Receiver
Operating Characteristic Curve (AUC-ROC) of 0.724 on the independent test set.
To improve transparency and trust in the model's predictions, we apply the
Integrated Gradients algorithm to provide theoretically grounded explanations
of the model's decision-making process. Our results indicate that pre-pregnancy
weight, maternal age, obstetric history, previous CS history, and body shape,
particularly around the head and shoulders, are key contributors to CS risk
prediction.

</details>


### [23] [Diffusion-Guided Mask-Consistent Paired Mixing for Endoscopic Image Segmentation](https://arxiv.org/abs/2511.03219)
*Pengyu Jie,Wanquan Liu,Rui He,Yihui Wen,Deyu Meng,Chenqiang Gao*

Main category: cs.CV

TL;DR: 提出一种结合扩散合成与样本混合的新方法（MCPMix+RLA），通过共享几何和自适应调整，提升了内窥镜分割的鲁棒性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有增强方法（样本混合或生成合成）存在标签模糊或域偏移问题，需要一种能结合两者优势并保持像素级语义的方法。

Method: 提出了Mask-Consistent Paired Mixing (MCPMix)和Real-Anchored Learnable Annealing (RLA)方法，前者在共享几何下混合图像外观，后者自适应调整混合强度和混合样本的损失权重。

Result: 在多个数据集（Kvasir-SEG、PICCOLO等）上实现了最先进的分割性能，并显著优于基线方法。

Conclusion: 结合标签保留混合与扩散驱动的多样性，并通过自适应重新锚定，实现了稳健且可泛化的内窥镜分割。

Abstract: Augmentation for dense prediction typically relies on either sample mixing or
generative synthesis. Mixing improves robustness but misaligned masks yield
soft label ambiguity. Diffusion synthesis increases apparent diversity but,
when trained as common samples, overlooks the structural benefit of mask
conditioning and introduces synthetic-real domain shift. We propose a paired,
diffusion-guided paradigm that fuses the strengths of both. For each real
image, a synthetic counterpart is generated under the same mask and the pair is
used as a controllable input for Mask-Consistent Paired Mixing (MCPMix), which
mixes only image appearance while supervision always uses the original hard
mask. This produces a continuous family of intermediate samples that smoothly
bridges synthetic and real appearances under shared geometry, enlarging
diversity without compromising pixel-level semantics. To keep learning aligned
with real data, Real-Anchored Learnable Annealing (RLA) adaptively adjusts the
mixing strength and the loss weight of mixed samples over training, gradually
re-anchoring optimization to real data and mitigating distributional bias.
Across Kvasir-SEG, PICCOLO, CVC-ClinicDB, a private NPC-LES cohort, and ISIC
2017, the approach achieves state-of-the-art segmentation performance and
consistent gains over baselines. The results show that combining
label-preserving mixing with diffusion-driven diversity, together with adaptive
re-anchoring, yields robust and generalizable endoscopic segmentation.

</details>


### [24] [Transformer-Progressive Mamba Network for Lightweight Image Super-Resolution](https://arxiv.org/abs/2511.03232)
*Sichen Guo,Wenjie Li,Yuanyang Liu,Guangwei Gao,Jian Yang,Chia-Wen Lin*

Main category: cs.CV

TL;DR: T-PMambaSR结合窗口自注意力与渐进式Mamba，提升超分辨率性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba超分辨率方法缺乏跨尺度细粒度过渡，限制了特征表示效率。

Method: 提出T-PMambaSR框架，整合窗口自注意力与渐进式Mamba，并引入自适应高频细化模块（AHFRM）。

Result: 实验表明T-PMambaSR在性能和计算成本上优于现有Transformer或Mamba方法。

Conclusion: T-PMambaSR通过结合窗口自注意力与渐进式Mamba，实现了细粒度建模，显著提升了超分辨率任务的性能，同时降低了计算成本。

Abstract: Recently, Mamba-based super-resolution (SR) methods have demonstrated the
ability to capture global receptive fields with linear complexity, addressing
the quadratic computational cost of Transformer-based SR approaches. However,
existing Mamba-based methods lack fine-grained transitions across different
modeling scales, which limits the efficiency of feature representation. In this
paper, we propose T-PMambaSR, a lightweight SR framework that integrates
window-based self-attention with Progressive Mamba. By enabling interactions
among receptive fields of different scales, our method establishes a
fine-grained modeling paradigm that progressively enhances feature
representation with linear complexity. Furthermore, we introduce an Adaptive
High-Frequency Refinement Module (AHFRM) to recover high-frequency details lost
during Transformer and Mamba processing. Extensive experiments demonstrate that
T-PMambaSR progressively enhances the model's receptive field and
expressiveness, yielding better performance than recent Transformer- or
Mamba-based methods while incurring lower computational cost. Our codes will be
released after acceptance.

</details>


### [25] [Decoupled Multi-Predictor Optimization for Inference-Efficient Model Tuning](https://arxiv.org/abs/2511.03245)
*Liwei Luo,Shuaitengyuan Li,Dongwei Ren,Qilong Wang,Pengfei Zhu,Qinghua Hu*

Main category: cs.CV

TL;DR: DMPO通过解耦早期阶段的代表性和判别性能力，显著提升推理效率，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决早期阶段如何同时提供低层基础特征给深层阶段和高层判别特征给早期预测器的关键挑战。

Method: 提出了一种解耦多预测器优化（DMPO）方法，包括轻量级旁路模块和高阶统计预测器，并通过两阶段损失权重分配进行优化。

Result: 在多个数据集和预训练骨干上的实验表明，DMPO在降低计算成本时明显优于其他方法。

Conclusion: DMPO方法通过架构设计和模型优化有效解耦了早期阶段的代表性和判别性能力，显著提升了推理效率。

Abstract: Recently, remarkable progress has been made in large-scale pre-trained model
tuning, and inference efficiency is becoming more crucial for practical
deployment. Early exiting in conjunction with multi-stage predictors, when
cooperated with a parameter-efficient fine-tuning strategy, offers a
straightforward way to achieve an inference-efficient model. However, a key
challenge remains unresolved: How can early stages provide low-level
fundamental features to deep stages while simultaneously supplying high-level
discriminative features to early-stage predictors? To address this problem, we
propose a Decoupled Multi-Predictor Optimization (DMPO) method to effectively
decouple the low-level representative ability and high-level discriminative
ability in early stages. First, in terms of architecture, we introduce a
lightweight bypass module into multi-stage predictors for functional
decomposition of shallow features from early stages, while a high-order
statistics-based predictor is developed for early stages to effectively enhance
their discriminative ability. To reasonably train our multi-predictor
architecture, a decoupled optimization is proposed to allocate two-phase loss
weights for multi-stage predictors during model tuning, where the initial
training phase enables the model to prioritize the acquisition of
discriminative ability of deep stages via emphasizing representative ability of
early stages, and the latter training phase drives discriminative ability
towards earlier stages as much as possible. As such, our DMPO can effectively
decouple representative and discriminative abilities in early stages in terms
of architecture design and model optimization. Experiments across various
datasets and pre-trained backbones demonstrate that DMPO clearly outperforms
its counterparts when reducing computational cost.

</details>


### [26] [Generative deep learning for foundational video translation in ultrasound](https://arxiv.org/abs/2511.03255)
*Nikolina Tomic Roshni Bhatnagar,Sarthak Jain,Connor Lau,Tien-Yu Liu,Laura Gambini,Rima Arnaout*

Main category: cs.CV

TL;DR: 提出了一种超声子模态图像翻译的生成方法，有效平衡数据集，生成视频与真实视频难以区分，具有广泛临床应用潜力。


<details>
  <summary>Details</summary>
Motivation: 超声数据中存在子模态（如灰度图和彩色多普勒）不平衡的问题，影响临床研究。本研究旨在通过图像翻译技术解决这一问题。

Method: 采用了生成对抗网络（GAN）方法，结合像素级、对抗性和感知损失，使用两个网络分别进行解剖结构重建和去噪，以实现真实的超声成像。

Result: 生成的合成视频与真实视频在深度学习分类和分割任务中表现相似，临床专家难以区分（准确率54±6%），平均SSIM为0.91±0.04。

Conclusion: 深度学习在医学图像获取和解释方面具有革命性潜力，但需注意数据不平衡和缺失问题。本研究提出的生成方法能够有效平衡超声数据子模态，增强医学影像数据集的实用性。

Abstract: Deep learning (DL) has the potential to revolutionize image acquisition and
interpretation across medicine, however, attention to data imbalance and
missingness is required. Ultrasound data presents a particular challenge
because in addition to different views and structures, it includes several
sub-modalities-such as greyscale and color flow doppler (CFD)-that are often
imbalanced in clinical studies. Image translation can help balance datasets but
is challenging for ultrasound sub-modalities to date. Here, we present a
generative method for ultrasound CFD-greyscale video translation, trained on
54,975 videos and tested on 8,368. The method developed leveraged pixel-wise,
adversarial, and perceptual loses and utilized two networks: one for
reconstructing anatomic structures and one for denoising to achieve realistic
ultrasound imaging. Average pairwise SSIM between synthetic videos and ground
truth was 0.91+/-0.04. Synthetic videos performed indistinguishably from real
ones in DL classification and segmentation tasks and when evaluated by blinded
clinical experts: F1 score was 0.9 for real and 0.89 for synthetic videos; Dice
score between real and synthetic segmentation was 0.97. Overall clinician
accuracy in distinguishing real vs synthetic videos was 54+/-6% (42-61%),
indicating realistic synthetic videos. Although trained only on heart videos,
the model worked well on ultrasound spanning several clinical domains (average
SSIM 0.91+/-0.05), demonstrating foundational abilities. Together, these data
expand the utility of retrospectively collected imaging and augment the dataset
design toolbox for medical imaging.

</details>


### [27] [Enhancing Medical Image Segmentation via Heat Conduction Equation](https://arxiv.org/abs/2511.03260)
*Rong Wu,Yim-Sang Yu*

Main category: cs.CV

TL;DR: 提出一种结合U-Mamba与热传导方程的新型混合架构，用于医学图像分割，有效建模全局上下文并提升长距离依赖推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在有限计算预算下难以同时实现高效的全局上下文建模和长距离依赖推理。

Method: 结合Mamba状态空间模块（长距离推理）与瓶颈层的热传导算子（HCOs），模拟频域热扩散以增强语义抽象。

Result: 在多模态腹部CT和MRI数据集上表现优于基线模型，验证了其有效性和泛化性。

Conclusion: 融合状态空间动力学与基于热扩散的全局建模为医学分割任务提供了可扩展且可解释的解决方案。

Abstract: Medical image segmentation has been significantly advanced by deep learning
architectures, notably U-Net variants. However, existing models struggle to
achieve efficient global context modeling and long-range dependency reasoning
under practical computational budgets simultaneously. In this work, we propose
a novel hybrid architecture utilizing U-Mamba with Heat Conduction Equation.
Our model combines Mamba-based state-space modules for efficient long-range
reasoning with Heat Conduction Operators (HCOs) in the bottleneck layers,
simulating frequency-domain thermal diffusion for enhanced semantic
abstraction. Experimental results on multimodal abdominal CT and MRI datasets
demonstrate that the proposed model consistently outperforms strong baselines,
validating its effectiveness and generalizability. It suggest that blending
state-space dynamics with heat-based global diffusion offers a scalable and
interpretable solution for medical segmentation tasks.

</details>


### [28] [IEC3D-AD: A 3D Dataset of Industrial Equipment Components for Unsupervised Point Cloud Anomaly Detection](https://arxiv.org/abs/2511.03267)
*Bingyang Guo,Hongjie Li,Ruiyun Yu,Hanzhe Liang,Jinbao Wang*

Main category: cs.CV

TL;DR: 开发了针对真实工业场景的IEC3D-AD数据集，并提出基于几何形态分析的GMANet方法，显著提升了3D异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D数据集未能充分反映真实工业环境的复杂性和细微缺陷，限制了工业设备组件（IEC）的精确异常检测研究。

Method: 引入了一种基于几何形态分析的3D异常检测范式（GMANet），通过空间差异优化减少正常和异常点云特征之间的差距。

Result: IEC3D-AD数据集显著提升了点云分辨率和缺陷标注粒度，GMANet方法在实验中被证明有效。

Conclusion: GMANet方法在IEC3D-AD和其他数据集上表现出色，验证了其有效性。

Abstract: 3D anomaly detection (3D-AD) plays a critical role in industrial
manufacturing, particularly in ensuring the reliability and safety of core
equipment components. Although existing 3D datasets like Real3D-AD and MVTec
3D-AD offer broad application support, they fall short in capturing the
complexities and subtle defects found in real industrial environments. This
limitation hampers precise anomaly detection research, especially for
industrial equipment components (IEC) such as bearings, rings, and bolts. To
address this challenge, we have developed a point cloud anomaly detection
dataset (IEC3D-AD) specific to real industrial scenarios. This dataset is
directly collected from actual production lines, ensuring high fidelity and
relevance. Compared to existing datasets, IEC3D-AD features significantly
improved point cloud resolution and defect annotation granularity, facilitating
more demanding anomaly detection tasks. Furthermore, inspired by generative
2D-AD methods, we introduce a novel 3D-AD paradigm (GMANet) on IEC3D-AD. This
paradigm generates synthetic point cloud samples based on geometric
morphological analysis, then reduces the margin and increases the overlap
between normal and abnormal point-level features through spatial discrepancy
optimization. Extensive experiments demonstrate the effectiveness of our method
on both IEC3D-AD and other datasets.

</details>


### [29] [Unified Long Video Inpainting and Outpainting via Overlapping High-Order Co-Denoising](https://arxiv.org/abs/2511.03272)
*Shuangquan Lyu,Steven Mao,Yue Ma*

Main category: cs.CV

TL;DR: 通过LoRA微调和重叠融合策略，实现长视频的高质量修复和外推，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决长视频生成中的高可控性挑战，特别是视频修复和外推的需求。

Method: 利用LoRA对预训练视频扩散模型（如Wan 2.1）进行高效微调，结合重叠融合时间协同去噪策略和高阶求解器，确保长序列一致性。

Result: 在数百帧的视频修复和外推任务中，性能优于基线方法（如Wan 2.1和VACE），在质量（PSNR/SSIM）和感知真实性（LPIPS）上表现优异。

Conclusion: 该方法通过LoRA微调和重叠融合策略，实现了长视频的高质量修复和外推，平衡了参数效率和性能。

Abstract: Generating long videos remains a fundamental challenge, and achieving high
controllability in video inpainting and outpainting is particularly demanding.
To address both of these challenges simultaneously and achieve controllable
video inpainting and outpainting for long video clips, we introduce a novel and
unified approach for long video inpainting and outpainting that extends
text-to-video diffusion models to generate arbitrarily long, spatially edited
videos with high fidelity. Our method leverages LoRA to efficiently fine-tune a
large pre-trained video diffusion model like Alibaba's Wan 2.1 for masked
region video synthesis, and employs an overlap-and-blend temporal co-denoising
strategy with high-order solvers to maintain consistency across long sequences.
In contrast to prior work that struggles with fixed-length clips or exhibits
stitching artifacts, our system enables arbitrarily long video generation and
editing without noticeable seams or drift. We validate our approach on
challenging inpainting/outpainting tasks including editing or adding objects
over hundreds of frames and demonstrate superior performance to baseline
methods like Wan 2.1 model and VACE in terms of quality (PSNR/SSIM), and
perceptual realism (LPIPS). Our method enables practical long-range video
editing with minimal overhead, achieved a balance between parameter efficient
and superior performance.

</details>


### [30] [Diffusion-SDPO: Safeguarded Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2511.03317)
*Minghao Fu,Guo-Hua Wang,Tianyu Cui,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang*

Main category: cs.CV

TL;DR: Diffusion-SDPO通过自适应梯度缩放解决Diffusion-DPO偏好对齐问题，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决标准Diffusion-DPO目标中扩大偏好边际不一定提升生成质量的问题，避免因失败分支退化影响获胜分支。

Method: 引入了Diffusion-SDPO，一种通过自适应缩放失败分支梯度来保护获胜分支的更新规则。

Result: 在标准文本到图像基准测试中，Diffusion-SDPO在自动化偏好、美学和提示对齐指标上优于基线。

Conclusion: Diffusion-SDPO是一种简单、模型无关且计算开销低的方法，能有效提升文本到图像生成模型的对齐性能。

Abstract: Text-to-image diffusion models deliver high-quality images, yet aligning them
with human preferences remains challenging. We revisit diffusion-based Direct
Preference Optimization (DPO) for these models and identify a critical
pathology: enlarging the preference margin does not necessarily improve
generation quality. In particular, the standard Diffusion-DPO objective can
increase the reconstruction error of both winner and loser branches.
Consequently, degradation of the less-preferred outputs can become sufficiently
severe that the preferred branch is also adversely affected even as the margin
grows. To address this, we introduce Diffusion-SDPO, a safeguarded update rule
that preserves the winner by adaptively scaling the loser gradient according to
its alignment with the winner gradient. A first-order analysis yields a
closed-form scaling coefficient that guarantees the error of the preferred
output is non-increasing at each optimization step. Our method is simple,
model-agnostic, broadly compatible with existing DPO-style alignment frameworks
and adds only marginal computational overhead. Across standard text-to-image
benchmarks, Diffusion-SDPO delivers consistent gains over preference-learning
baselines on automated preference, aesthetic, and prompt alignment metrics.
Code is publicly available at https://github.com/AIDC-AI/Diffusion-SDPO.

</details>


### [31] [Decoupling Augmentation Bias in Prompt Learning for Vision-Language Models](https://arxiv.org/abs/2511.03367)
*Gahyeon Kim,Sohee Kim,Seokju Lee*

Main category: cs.CV

TL;DR: AAPL通过对抗性令牌嵌入结合图像增强，提升提示学习在零样本等任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提示学习方法（如CoOp和CoCoOp）在文本修改上表现良好，但未充分利用图像增强的潜力，且缺乏对语义视觉特征的明确指导。

Method: 提出了AAPL方法，通过对抗性令牌嵌入解耦图像增强带来的表面视觉变化与类别相关语义表示，使学习到的提示更专注于视觉区分性特征。

Result: AAPL在11个基准数据集上全面优于现有方法，适用于少样本、零样本、跨数据集和领域泛化场景。

Conclusion: 通过引入对抗性令牌嵌入的AAPL方法，成功将图像增强引入提示学习，显著提升了模型在零样本、少样本及跨数据集等任务中的性能。

Abstract: Recent advances in large-scale vision and language models have led to
significant progress in zero-shot learning tasks. Methods such as CoOp and
CoCoOp have shown that replacing handcrafted prompts with learnable vectors,
known as prompt learning, can result in improved performance. However, these
models often struggle to generalize to entirely unseen categories. While
traditional zero-shot learning techniques benefit from various data
augmentation strategies, prompt learning has primarily focused on text-based
modifications, leaving the potential of image-based augmentation largely
unexplored. In this work, we explore how image-level augmentations,
particularly those that introduce attribute-specific variations, can support
and enhance prompt learning. Our analysis examines the interaction between
these augmentations and soft prompt frameworks, revealing their potential to
improve generalization. We also identify a limitation in existing methods, such
as CoCoOp, which do not provide explicit guidance for learning prompts that
focus on semantically meaningful visual features. To address this, we propose
Adding Attributes to Prompt Learning, AAPL, a novel method that introduces
adversarial token embeddings to decouple superficial visual variations
introduced by augmentation from class-relevant semantic representations. This
decoupling enables the learned prompts to concentrate on visually
discriminative features that align with the target categories. We conduct
comprehensive experiments on eleven benchmark datasets, and AAPL consistently
outperforms existing methods across few-shot, zero-shot, cross-dataset, and
domain generalization settings. Our source code is publicly available at:
https://github.com/Gahyeonkim09/AAPL

</details>


### [32] [SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding](https://arxiv.org/abs/2511.03325)
*Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque*

Main category: cs.CV

TL;DR: SurgViVQA通过动态场景理解和时间感知特征融合，显著提升了手术视频问答的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于静态图像特征，且数据集缺乏时间标注，忽略了动态过程对准确解释手术步骤的关键性。

Method: 采用Masked Video--Text Encoder融合视频和问题特征，捕捉时间线索（如运动和工具-组织交互），并通过微调的大型语言模型（LLM）解码为连贯答案。

Result: 在REAL-Colon-VQA和EndoVis18-VQA数据集上，SurgViVQA优于现有基于图像的VQA基准模型，关键词准确率分别提升11%和9%。

Conclusion: SurgViVQA和REAL-Colon-VQA数据集为手术视频问答提供了时间感知理解的框架，显著提升了AI模型对动态手术场景的理解能力。

Abstract: Video Question Answering (VideoQA) in the surgical domain aims to enhance
intraoperative understanding by enabling AI models to reason over temporally
coherent events rather than isolated frames. Current approaches are limited to
static image features, and available datasets often lack temporal annotations,
ignoring the dynamics critical for accurate procedural interpretation. We
propose SurgViVQA, a surgical VideoQA model that extends visual reasoning from
static images to dynamic surgical scenes. It uses a Masked Video--Text Encoder
to fuse video and question features, capturing temporal cues such as motion and
tool--tissue interactions, which a fine-tuned large language model (LLM) then
decodes into coherent answers. To evaluate its performance, we curated
REAL-Colon-VQA, a colonoscopic video dataset that includes motion-related
questions and diagnostic attributes, as well as out-of-template questions with
rephrased or semantically altered formulations to assess model robustness.
Experimental validation on REAL-Colon-VQA and the public EndoVis18-VQA dataset
shows that SurgViVQA outperforms existing image-based VQA benchmark models,
particularly in keyword accuracy, improving over PitVQA by +11\% on
REAL-Colon-VQA and +9\% on EndoVis18-VQA. A perturbation study on the questions
further confirms improved generalizability and robustness to variations in
question phrasing. SurgViVQA and the REAL-Colon-VQA dataset provide a framework
for temporally-aware understanding in surgical VideoQA, enabling AI models to
interpret dynamic procedural contexts more effectively. Code and dataset
available at https://github.com/madratak/SurgViVQA.

</details>


### [33] [Multi-Object Tracking Retrieval with LLaVA-Video: A Training-Free Solution to MOT25-StAG Challenge](https://arxiv.org/abs/2511.03332)
*Yi Yang,Yiming Xu,Timo Kaiser,Hao Cheng,Bodo Rosenhahn,Michael Ying Yang*

Main category: cs.CV

TL;DR: 两阶段零样本方法结合FastTracker和LLaVA-Video，在MOT25-StAG挑战赛中获第二名。


<details>
  <summary>Details</summary>
Motivation: 解决复杂真实场景中基于语言查询的多目标定位与跟踪问题。

Method: 采用两阶段零样本方法，结合FastTracker跟踪模型和多模态大型语言模型LLaVA-Video。

Result: 在MOT25-StAG测试集上，m-HIoU和HOTA得分分别为20.68和10.73。

Conclusion: 该方法在MOT25-StAG挑战赛中取得了第二名，验证了其有效性。

Abstract: In this report, we present our solution to the MOT25-Spatiotemporal Action
Grounding (MOT25-StAG) Challenge. The aim of this challenge is to accurately
localize and track multiple objects that match specific and free-form language
queries, using video data of complex real-world scenes as input. We model the
underlying task as a video retrieval problem and present a two-stage, zero-shot
approach, combining the advantages of the SOTA tracking model FastTracker and
Multi-modal Large Language Model LLaVA-Video. On the MOT25-StAG test set, our
method achieves m-HIoU and HOTA scores of 20.68 and 10.73 respectively, which
won second place in the challenge.

</details>


### [34] [UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions](https://arxiv.org/abs/2511.03334)
*Guozhen Zhang,Zixiang Zhou,Teng Hu,Ziqiao Peng,Youliang Zhang,Yi Chen,Yuan Zhou,Qinglin Lu,Limin Wang*

Main category: cs.CV

TL;DR: UniAVGen是一种统一的音视频生成框架，通过跨模态交互和动态调制技术，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有音视频生成方法在唇形同步和语义一致性上表现不足，需改进跨模态建模。

Method: 采用双分支Diffusion Transformers（DiTs）构建跨模态潜在空间，结合非对称跨模态交互机制和Face-Aware Modulation模块，并引入Modality-Aware Classifier-Free Guidance策略。

Result: UniAVGen在较少训练数据（1.3M vs. 30.1M）下，实现了更优的音视频同步、音色一致性和情感一致性。

Conclusion: UniAVGen通过双分支联合合成架构和跨模态交互机制，显著提升了音视频生成的同步性和语义一致性，且在多项任务中表现优异。

Abstract: Due to the lack of effective cross-modal modeling, existing open-source
audio-video generation methods often exhibit compromised lip synchronization
and insufficient semantic consistency. To mitigate these drawbacks, we propose
UniAVGen, a unified framework for joint audio and video generation. UniAVGen is
anchored in a dual-branch joint synthesis architecture, incorporating two
parallel Diffusion Transformers (DiTs) to build a cohesive cross-modal latent
space. At its heart lies an Asymmetric Cross-Modal Interaction mechanism, which
enables bidirectional, temporally aligned cross-attention, thus ensuring
precise spatiotemporal synchronization and semantic consistency. Furthermore,
this cross-modal interaction is augmented by a Face-Aware Modulation module,
which dynamically prioritizes salient regions in the interaction process. To
enhance generative fidelity during inference, we additionally introduce
Modality-Aware Classifier-Free Guidance, a novel strategy that explicitly
amplifies cross-modal correlation signals. Notably, UniAVGen's robust joint
synthesis design enables seamless unification of pivotal audio-video tasks
within a single model, such as joint audio-video generation and continuation,
video-to-audio dubbing, and audio-driven video synthesis. Comprehensive
experiments validate that, with far fewer training samples (1.3M vs. 30.1M),
UniAVGen delivers overall advantages in audio-video synchronization, timbre
consistency, and emotion consistency.

</details>


### [35] [Robust Alignment of the Human Embryo in 3D Ultrasound using PCA and an Ensemble of Heuristic, Atlas-based and Learning-based Classifiers Evaluated on the Rotterdam Periconceptional Cohort](https://arxiv.org/abs/2511.03416)
*Nikolai Herrmann,Marcella C. Zijta,Stefan Klein,Régine P. M. Steegers-Theunissen,Rene M. H. Wijnen,Bernadette S. de Bakker,Melek Rousian,Wietske A. P. Bastiaansen*

Main category: cs.CV

TL;DR: 提出一种自动化方法，通过PCA和三种策略标准化胚胎在三维超声图像中的对齐，测试显示高准确率，支持临床和研究应用。


<details>
  <summary>Details</summary>
Motivation: 标准化胚胎对齐有助于提高标准平面检测、改善标志物可视化，并突出不同扫描间的差异，从而辅助产前生长监测。

Method: 使用主成分分析（PCA）提取胚胎主轴向，并通过三种策略（基于皮尔逊相关的启发式、基于图谱的图像匹配和随机森林分类器）选择标准方向。

Result: 在2166张三维超声扫描图像上测试，PCA正确提取胚胎主轴向的准确率为99.0%，三种选择策略的准确率分别为97.4%、95.8%和98.4%，多数投票策略综合准确率达98.5%。

Conclusion: 该方法的提出实现了胚胎在三维超声图像中的标准化对齐，支持临床和研究中的可扩展分析，代码已公开。

Abstract: Standardized alignment of the embryo in three-dimensional (3D) ultrasound
images aids prenatal growth monitoring by facilitating standard plane
detection, improving visualization of landmarks and accentuating differences
between different scans. In this work, we propose an automated method for
standardizing this alignment. Given a segmentation mask of the embryo,
Principal Component Analysis (PCA) is applied to the mask extracting the
embryo's principal axes, from which four candidate orientations are derived.
The candidate in standard orientation is selected using one of three
strategies: a heuristic based on Pearson's correlation assessing shape, image
matching to an atlas through normalized cross-correlation, and a Random Forest
classifier. We tested our method on 2166 images longitudinally acquired 3D
ultrasound scans from 1043 pregnancies from the Rotterdam Periconceptional
Cohort, ranging from 7+0 to 12+6 weeks of gestational age. In 99.0% of images,
PCA correctly extracted the principal axes of the embryo. The correct candidate
was selected by the Pearson Heuristic, Atlas-based and Random Forest in 97.4%,
95.8%, and 98.4% of images, respectively. A Majority Vote of these selection
methods resulted in an accuracy of 98.5%. The high accuracy of this pipeline
enables consistent embryonic alignment in the first trimester, enabling
scalable analysis in both clinical and research settings. The code is publicly
available at:
https://gitlab.com/radiology/prenatal-image-analysis/pca-3d-alignment.

</details>


### [36] [Generalizing Shape-from-Template to Topological Changes](https://arxiv.org/abs/2511.03459)
*Kevin Manogue,Tomasz M Schang,Dilara Kuş,Jonas Müller,Stefan Zachow,Agniva Sengupta*

Main category: cs.CV

TL;DR: 提出一种能处理拓扑变化的SfT方法，通过迭代优化模板，实验表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有SfT方法在拓扑变化时失效，本文旨在解决这一问题。

Method: 方法包括初始化解后迭代调整模板，通过分区优化能量函数，结合物理合理性和重投影一致性。

Result: 实验证明，该方法在合成和真实数据上均优于基线方法，并能处理撕裂和切割等拓扑变化。

Conclusion: 本文提出了一种能够处理拓扑变化的SfT方法，通过初始化解后迭代调整模板，优化能量函数，实验证明该方法在合成和真实数据上均优于基线方法。

Abstract: Reconstructing the surfaces of deformable objects from correspondences
between a 3D template and a 2D image is well studied under Shape-from-Template
(SfT) methods; however, existing approaches break down when topological changes
accompany the deformation. We propose a principled extension of SfT that
enables reconstruction in the presence of such changes. Our approach is
initialized with a classical SfT solution and iteratively adapts the template
by partitioning its spatial domain so as to minimize an energy functional that
jointly encodes physical plausibility and reprojection consistency. We
demonstrate that the method robustly captures a wide range of practically
relevant topological events including tears and cuts on bounded 2D surfaces,
thereby establishing the first general framework for topological-change-aware
SfT. Experiments on both synthetic and real data confirm that our approach
consistently outperforms baseline methods.

</details>


### [37] [Human Mesh Modeling for Anny Body](https://arxiv.org/abs/2511.03589)
*Romain Brégier,Guénolé Fiche,Laura Bravo-Sánchez,Thomas Lucas,Matthieu Armando,Philippe Weinzaepfel,Grégory Rogez,Fabien Baradel*

Main category: cs.CV

TL;DR: Anny是一个无需3D扫描、基于人类学知识的开源人体模型，通过表型参数控制形状，支持多种3D建模任务，并展示了在HMR任务中的高性能。


<details>
  <summary>Details</summary>
Motivation: 现有的人体模型通常依赖于昂贵的3D扫描和学习形状空间，这些空间通常是专有的且人口统计范围狭窄。Anny旨在提供一个简单、开放且基于人类学知识的替代方案，以支持广泛的3D人体建模任务。

Method: Anny通过表型参数控制混合形状，构建了一个连续、可解释的形状空间。模型利用WHO人口统计数据进行校准，提供了在单个统一模型中真实且基于人口统计的人类形状变化。

Result: Anny-One是一个包含80万张照片级真实感人类的集合，展示了尽管Anny简单，但使用Anny训练的HMR模型可以与基于扫描的人体模型相媲美，同时保持可解释性和广泛代表性。

Conclusion: Anny是一个简单、完全可微分且无需扫描的人体模型，基于MakeHuman社区的人类学知识构建。它定义了一个连续、可解释的形状空间，通过表型参数（如性别、年龄、身高、体重）控制混合形状，覆盖了从婴儿到老年人的广泛人类形态。Anny的开放性和语义控制使其成为3D人体建模的多功能基础，支持毫米级精确扫描拟合、受控合成数据生成和人体网格恢复（HMR）。Anny及其代码以Apache 2.0许可证发布，使其成为人类中心3D建模的可访问基础。

Abstract: Parametric body models are central to many human-centric tasks, yet existing
models often rely on costly 3D scans and learned shape spaces that are
proprietary and demographically narrow. We introduce Anny, a simple, fully
differentiable, and scan-free human body model grounded in anthropometric
knowledge from the MakeHuman community. Anny defines a continuous,
interpretable shape space, where phenotype parameters (e.g. gender, age,
height, weight) control blendshapes spanning a wide range of human forms --
across ages (from infants to elders), body types, and proportions. Calibrated
using WHO population statistics, it provides realistic and demographically
grounded human shape variation within a single unified model. Thanks to its
openness and semantic control, Anny serves as a versatile foundation for 3D
human modeling -- supporting millimeter-accurate scan fitting, controlled
synthetic data generation, and Human Mesh Recovery (HMR). We further introduce
Anny-One, a collection of 800k photorealistic humans generated with Anny,
showing that despite its simplicity, HMR models trained with Anny can match the
performance of those trained with scan-based body models, while remaining
interpretable and broadly representative. The Anny body model and its code are
released under the Apache 2.0 license, making Anny an accessible foundation for
human-centric 3D modeling.

</details>


### [38] [Signal Intensity-weighted coordinate channels improve learning stability and generalisation in 1D and 2D CNNs in localisation tasks on biomedical signals](https://arxiv.org/abs/2511.03645)
*Vittal L. Rao*

Main category: cs.CV

TL;DR: 提出信号强度加权坐标表示，在ECG和细胞图像定位任务中表现优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决生物医学信号中复杂强度分布下的定位问题，提出一种更有效的坐标表示方法。

Method: 通过将局部信号强度与坐标通道结合，创建信号强度加权的坐标表示，替代传统的纯坐标通道。

Result: 在一维和二维生物医学信号定位任务中，新方法相比传统方法收敛更快且泛化性能更高。

Conclusion: 提出的信号强度加权坐标表示在多种生物医学信号定位任务中表现出优越性能，证明了其通用性和有效性。

Abstract: Localisation tasks in biomedical data often require models to learn
meaningful spatial or temporal relationships from signals with complex
intensity distributions. A common strategy, exemplified by CoordConv layers, is
to append coordinate channels to convolutional inputs, enabling networks to
learn absolute positions. In this work, we propose a signal intensity-weighted
coordinate representation that replaces the pure coordinate channels with
channels scaled by local signal intensity. This modification embeds an
intensity-position coupling directly in the input representation, introducing a
simple and modality-agnostic inductive bias. We evaluate the approach on two
distinct localisation problems: (i) predicting the time of morphological
transition in 20-second, two-lead ECG signals, and (ii) regressing the
coordinates of nuclear centres in cytological images from the SiPaKMeD dataset.
In both cases, the proposed representation yields faster convergence and higher
generalisation performance relative to conventional coordinate-channel
approaches, demonstrating its effectiveness across both one-dimensional and
two-dimensional biomedical signals.

</details>


### [39] [A Lightweight 3D-CNN for Event-Based Human Action Recognition with Privacy-Preserving Potential](https://arxiv.org/abs/2511.03665)
*Mehdi Sefidgar Dilmaghani,Francis Fowley,Peter Corcoran*

Main category: cs.CV

TL;DR: 轻量化3DCNN通过事件摄像头实现隐私保护的人类活动识别，性能优于基准模型3%。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于帧的摄像头在人类监控系统中存在的隐私泄露问题，利用事件摄像头仅记录像素强度变化的特性，提供一种隐私保护的感知方式。

Method: 采用轻量化的3DCNN架构，结合焦点损失（focal loss）和类别重新加权策略以及有针对性的数据增强方法，有效建模空间和时间动态。

Result: 在Toyota Smart Home和ETRI数据集上训练和评估，模型F1得分为0.9415，整体准确率为94.17%，优于C3D、ResNet3D和MC3_18等基准3D-CNN架构达3%。

Conclusion: 该论文提出了一个轻量化的三维卷积神经网络（3DCNN），用于基于事件视觉数据的人类活动识别（HAR），展示了其在准确性和隐私保护方面的潜力，适用于实际边缘应用。

Abstract: This paper presents a lightweight three-dimensional convolutional neural
network (3DCNN) for human activity recognition (HAR) using event-based vision
data. Privacy preservation is a key challenge in human monitoring systems, as
conventional frame-based cameras capture identifiable personal information. In
contrast, event cameras record only changes in pixel intensity, providing an
inherently privacy-preserving sensing modality. The proposed network
effectively models both spatial and temporal dynamics while maintaining a
compact design suitable for edge deployment. To address class imbalance and
enhance generalization, focal loss with class reweighting and targeted data
augmentation strategies are employed. The model is trained and evaluated on a
composite dataset derived from the Toyota Smart Home and ETRI datasets.
Experimental results demonstrate an F1-score of 0.9415 and an overall accuracy
of 94.17%, outperforming benchmark 3D-CNN architectures such as C3D, ResNet3D,
and MC3_18 by up to 3%. These results highlight the potential of event-based
deep learning for developing accurate, efficient, and privacy-aware human
action recognition systems suitable for real-world edge applications.

</details>


### [40] [Part-Aware Bottom-Up Group Reasoning for Fine-Grained Social Interaction Detection](https://arxiv.org/abs/2511.03666)
*Dongkeun Kim,Minsu Cho,Suha Kwak*

Main category: cs.CV

TL;DR: 提出一种基于部分感知的自底向上框架，通过身体部位特征和人际关系更准确地推断社交群体及其互动，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有社交互动检测方法忽视细微的社交线索（如面部表情、视线和手势），且直接检测社交群体而未明确建模个体间的互动，导致局部社交信号捕捉能力不足和群体配置推断模糊。

Method: 采用部分感知的自底向上群体推理框架，通过身体部位特征和人际关系推断社交群体及其互动。

Result: 在NVI数据集上的实验表明，该方法优于先前方法，达到了新的最先进水平。

Conclusion: 该论文提出的基于部分感知的自底向上群体推理框架在细粒度社交互动检测中表现优异，显著优于现有方法。

Abstract: Social interactions often emerge from subtle, fine-grained cues such as
facial expressions, gaze, and gestures. However, existing methods for social
interaction detection overlook such nuanced cues and primarily rely on holistic
representations of individuals. Moreover, they directly detect social groups
without explicitly modeling the underlying interactions between individuals.
These drawbacks limit their ability to capture localized social signals and
introduce ambiguity when group configurations should be inferred from social
interactions grounded in nuanced cues. In this work, we propose a part-aware
bottom-up group reasoning framework for fine-grained social interaction
detection. The proposed method infers social groups and their interactions
using body part features and their interpersonal relations. Our model first
detects individuals and enhances their features using part-aware cues, and then
infers group configuration by associating individuals via similarity-based
reasoning, which considers not only spatial relations but also subtle social
cues that signal interactions, leading to more accurate group inference.
Experiments on the NVI dataset demonstrate that our method outperforms prior
methods, achieving the new state of the art.

</details>


### [41] [Disentangled Concepts Speak Louder Than Words:Explainable Video Action Recognition](https://arxiv.org/abs/2511.03725)
*Jongseo Lee,Wooil Lee,Gyeong-Moon Park,Seong Tae Kim,Jinwoo Choi*

Main category: cs.CV

TL;DR: DANCE框架通过解耦动作和上下文概念，提升视频动作识别的解释清晰度，实验证明其有效且具有竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有基于显著性的方法产生的解释往往纠缠不清，难以区分预测依赖于运动还是空间上下文；而基于语言的方法因运动的隐含性（直觉理解但难以言表）常无法有效解释运动。

Method: DANCE采用基于概念瓶颈的设计，将预测分解为运动动态、对象和场景三种概念类型，其中运动动态由人体姿态序列定义，对象和场景概念则通过大型语言模型自动提取。

Result: 在KTH、Penn Action、HAA500和UCF-101四个数据集上的实验表明，DANCE显著提升了解释清晰度且性能具有竞争力。用户研究验证了其优越的可解释性，实验还显示DANCE有助于模型调试、编辑和失败分析。

Conclusion: DANCE框架通过解耦动作和上下文概念，显著提升了视频动作识别模型的解释清晰度，并在多个数据集中展现出竞争力。

Abstract: Effective explanations of video action recognition models should disentangle
how movements unfold over time from the surrounding spatial context. However,
existing methods based on saliency produce entangled explanations, making it
unclear whether predictions rely on motion or spatial context. Language-based
approaches offer structure but often fail to explain motions due to their tacit
nature -- intuitively understood but difficult to verbalize. To address these
challenges, we propose Disentangled Action aNd Context concept-based
Explainable (DANCE) video action recognition, a framework that predicts actions
through disentangled concept types: motion dynamics, objects, and scenes. We
define motion dynamics concepts as human pose sequences. We employ a large
language model to automatically extract object and scene concepts. Built on an
ante-hoc concept bottleneck design, DANCE enforces prediction through these
concepts. Experiments on four datasets -- KTH, Penn Action, HAA500, and UCF-101
-- demonstrate that DANCE significantly improves explanation clarity with
competitive performance. We validate the superior interpretability of DANCE
through a user study. Experimental results also show that DANCE is beneficial
for model debugging, editing, and failure analysis.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [42] [Faster Weak Expander Decompositions and Approximate Max Flow](https://arxiv.org/abs/2511.02943)
*Henry Fleischmann,George Z. Li,Jason Li*

Main category: cs.DS

TL;DR: 提出两种更快的算法：热启动切匹配游戏改进弱扩展分解，简化非递归近似最大流框架，结合新分解方法提升效率。


<details>
  <summary>Details</summary>
Motivation: 改进弱扩展分解和近似最大流算法的计算效率，减少递归深度带来的成本，并提供更大的灵活性。

Method: 第一种方法通过‘热启动’切匹配游戏来避免递归深度的成本，第二种方法简化了非递归近似最大流算法框架，并结合了新的弱扩展分解原语。

Result: 实现了在几个对数因子内的近似最大流算法，达到了扩展分解方法的极限。

Conclusion: 本文提出了两种更快的算法，用于弱扩展分解和无向图上的近似最大流问题，改进了现有方法的效率和灵活性。

Abstract: We give faster algorithms for weak expander decompositions and approximate
max flow on undirected graphs. First, we show that it is possible to "warm
start" the cut-matching game when computing weak expander decompositions,
avoiding the cost of the recursion depth. Our algorithm is also flexible enough
to support weaker flow subroutines than previous algorithms.
  Our second contribution is to streamline the recent non-recursive approximate
max flow algorithm of Li, Rao, and Wang (SODA, 2025) and adapt their framework
to use our new weak expander decomposition primitive. Consequently, we give an
approximate max flow algorithm within a few logarithmic factors of the limit of
expander decomposition-based approaches.

</details>


### [43] [Tight Better-Than-Worst-Case Bounds for Element Distinctness and Set Intersection](https://arxiv.org/abs/2511.02954)
*Ivor van der Hoog,Eva Rotenberg,Daniel Rutschmann*

Main category: cs.DS

TL;DR: 本文研究了元素唯一性问题的实例敏感下界，证明确定性算法竞争比下限为O(log log n)，并设计匹配算法；同时展示了集合交集问题的更高竞争比下限O(log n)。


<details>
  <summary>Details</summary>
Motivation: 探讨在输入中存在大量重复时，元素唯一性问题的比较基础下界是否敏感于重复数量，突破经典最坏情况分析的局限。

Method: 通过构建输入实例的重复结构图G(I)，研究算法在所有输入I'（G(I')≅G）上的最坏情况运行时间。采用对抗性下界证明方法，并结合实际算法设计。

Result: 证明了元素唯一性问题的确定性算法竞争比下限为O(log log n)，并设计了匹配的算法；集合交集问题的竞争比下限为O(log n)，同样提供了匹配算法。

Conclusion: 本文通过实例特定的下界分析，证明了在元素唯一性问题中，确定性算法的竞争比不能优于O(log log n)，并提供了一个匹配的O(log log n)-竞争确定性算法。此外，对于集合交集问题，证明了其竞争比下限为O(log n)，并展示了与元素唯一性问题的分离。

Abstract: The element distinctness problem takes as input a list $I$ of $n$ values from
a totally ordered universe and the goal is to decide whether $I$ contains any
duplicates. It is a well-studied problem with a classical worst-case $\Omega(n
\log n)$ comparison-based lower bound by Fredman. At first glance, this lower
bound appears to rule out any algorithm more efficient than the naive approach
of sorting $I$ and comparing adjacent elements. However, upon closer
inspection, the $\Omega(n \log n)$ bound does not apply if the input has many
duplicates. We therefore ask: Are there comparison-based lower bounds for
element distinctness that are sensitive to the amount of duplicates in the
input?
  To address this question, we derive instance-specific lower bounds. For any
input instance $I$, we represent the combinatorial structure of the duplicates
in $I$ by an undirected graph $G(I)$ that connects identical elements. Each
such graph $G$ is a union of cliques, and we study algorithms by their
worst-case running time over all inputs $I'$ with $G(I') \cong G$. We establish
an adversarial lower bound showing that, for any deterministic algorithm
$\mathcal{A}$, there exists a graph $G$ and an algorithm $\mathcal{A}'$ that,
for all inputs $I$ with $G(I) \cong G$, is a factor $O(\log \log n)$ faster
than $\mathcal{A}$. Consequently, no deterministic algorithm can be $o(\log
\log n)$-competitive for all graphs $G$. We complement this with an $O(\log
\log n)$-competitive deterministic algorithm, thereby obtaining tight bounds
for element distinctness that go beyond classical worst-case analysis.
  We subsequently study the related problem of set intersection. We show that
no deterministic set intersection algorithm can be $o(\log n)$-competitive, and
provide an $O(\log n)$-competitive deterministic algorithm. This shows a
separation between element distinctness and the set intersection problem.

</details>


### [44] [Implementation and Brief Experimental Analysis of the Duan et al. (2025) Algorithm for Single-Source Shortest Paths](https://arxiv.org/abs/2511.03007)
*Lucas Castro,Thailsson Clementino,Rosiane de Freitas*

Main category: cs.DS

TL;DR: 本文验证了Duan等人的SSSP算法实现，发现尽管理论复杂度更优，但因常数因子较大，实际性能不及经典Dijkstra算法。


<details>
  <summary>Details</summary>
Motivation: 研究目的是验证Duan等人提出的SSSP问题算法在实际应用中的表现，特别是与经典Dijkstra算法的比较。

Method: 本文实现了Duan等人（2025）提出的确定性算法，并进行了实验分析，包括与使用二叉堆的Dijkstra算法的性能对比。实验在合成稀疏随机图和DIMACS基准的真实道路网络实例上进行。

Result: 实验结果显示，新算法虽在理论上有更优的渐近复杂度（$O(m \log^{2/3} n)$），但因较大的常数因子，实际运行速度不及Dijkstra算法。

Conclusion: 尽管新算法在渐近复杂度上优于经典Dijkstra算法，但由于较大的常数因子，在测试的所有稀疏图规模中（包括数千万顶点的实例），Dijkstra算法实际运行更快。

Abstract: We present an implementation and a brief experimental analysis of the
deterministic algorithm proposed by Duan et al. (2025) for the Single-Source
Shortest Path (SSSP) problem, which achieves the best known asymptotic upper
bound in the comparison-addition model, with running time $O(m \log^{2/3} n)$.
We provide a faithful C++ implementation of this algorithm, following all
structural details described in the original paper, and compare its empirical
performance with the classical Dijkstra's algorithm using binary heaps. The
experiments were conducted on both synthetic sparse random graphs and
real-world road network instances from the DIMACS benchmark. Our results show
that, despite its superior asymptotic complexity, the new algorithm presents
significantly larger constant factors, making Dijkstra's algorithm faster for
all tested sparse graph sizes, including instances with tens of millions of
vertices. Our implementation achieves $O(m \log^{2/3} n)$ expected time, due to
the use of hash tables, and some possibilities for making it worst-case are
being considered. (This is a ongoing work.)

</details>


### [45] [A Branch-and-Bound Approach for Maximum Low-Diameter Dense Subgraph Problems](https://arxiv.org/abs/2511.03157)
*Yi Zhoua,Chunyu Luoa,Zhengren Wangb,Zhang-Hua Fuc*

Main category: cs.DS

TL;DR: 本文提出一种分解框架和分支定界算法，用于高效寻找直径≤2的最大稠密子图，实证效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: $f(\cdot)$-稠密图可能在应用中不连通或弱连通，因此需要研究如何在保证直径限制的条件下提取最大稠密子图。

Method: 采用分解框架将图分解为$n$个子图，并结合退化排序和二跳退化排序策略，以及基于排序的新型上界分支定界算法。

Result: 在139个真实世界图上测试，该算法在1小时内最优解决了近两倍于MIP求解器和纯分支定界方法的实例。

Conclusion: 本文提出了一种基于分解的分支定界算法，用于在图中寻找直径至多为二的最大$f(\cdot)$-稠密子图，该算法在实证中表现优于MIP求解器和纯分支定界方法。

Abstract: A graph with $n$ vertices is an $f(\cdot)$-dense graph if it has at least
$f(n)$ edges, $f(\cdot)$ being a well-defined function. The notion
$f(\cdot)$-dense graph encompasses various clique models like $\gamma$-quasi
cliques, $k$-defective cliques, and dense cliques, arising in cohesive subgraph
extraction applications. However, the $f(\cdot)$-dense graph may be
disconnected or weakly connected. To conquer this, we study the problem of
finding the largest $f(\cdot)$-dense subgraph with a diameter of at most two in
the paper. Specifically, we present a decomposition-based branch-and-bound
algorithm to optimally solve this problem. The key feature of the algorithm is
a decomposition framework that breaks the graph into $n$ smaller subgraphs,
allowing independent searches in each subgraph. We also introduce decomposition
strategies including degeneracy and two-hop degeneracy orderings, alongside a
branch-and-bound algorithm with a novel sorting-based upper bound to solve each
subproblem. Worst-case complexity for each component is provided. Empirical
results on 139 real-world graphs under two $f(\cdot)$ functions show our
algorithm outperforms the MIP solver and pure branch-and-bound, solving nearly
twice as many instances optimally within one hour.

</details>


### [46] [Optimal Stopping with a Predicted Prior](https://arxiv.org/abs/2511.03289)
*Tian Bai,Zhiyi Huang,Chui Shan Lee,Dongchen Li*

Main category: cs.DS

TL;DR: 研究提出双标准算法，改进了一致性与鲁棒性的权衡，适用于最优停止问题，但无法同时达到最优一致性及鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 实践中决策者常依赖可能错误的机器学习先验，而现有秘书模型和先知不等式算法要么过于悲观，要么对预测错误不鲁棒。

Method: 提出了一种双标准算法家族，以改进一致性与鲁棒性的权衡，适用于最大化期望接受值和最大化接受最大值的概率。

Result: 双标准算法在一致性和鲁棒性权衡方面表现更优，适用于两个目标。

Conclusion: 对于后者目标（最大化接受最大值的概率），没有算法能同时匹配最佳先知不等式算法的一致性和最佳秘书算法的鲁棒性。

Abstract: There are two major models of value uncertainty in the optimal stopping
literature: the secretary model, which assumes no prior knowledge, and the
prophet inequality model, which assumes full information about value
distributions. In practice, decision makers often rely on machine-learned
priors that may be erroneous. Motivated by this gap, we formulate the model of
optimal stopping with a predicted prior to design algorithms that are both
consistent, exploiting the prediction when accurate, and robust, retaining
worst-case guarantees when it is not.
  Existing secretary and prophet inequality algorithms are either pessimistic
in consistency or not robust to misprediction. A randomized combination only
interpolates their guarantees linearly. We show that a family of bi-criteria
algorithms achieves improved consistency-robustness trade-offs, both for
maximizing the expected accepted value and for maximizing the probability of
accepting the maximum value. We further prove that for the latter objective, no
algorithm can simultaneously match the best prophet inequality algorithm in
consistency, and the best secretary algorithm in robustness.

</details>


### [47] [Improved Online Load Balancing in the Two-Norm](https://arxiv.org/abs/2511.03345)
*Sander Borst,Danish Kashaev*

Main category: cs.DS

TL;DR: 论文提出了一种新算法，首次突破在线负载均衡问题的5竞争比界限，达到了4.9843，并通过原始-对偶框架简化了现有算法的证明。


<details>
  <summary>Details</summary>
Motivation: 解决在线负载均衡问题，目标是降低机器负载的ℓ₂范数平方，突破现有算法的竞争比界限。

Method: 采用基于半定规划松弛的新原始-对偶框架，结合在线相关的随机化舍入过程。

Result: 提出的算法实现了4.9843的竞争比，优于之前的5界限，并提供了对现有竞争比的新证明。

Conclusion: 该论文提出了首个突破竞争比5界限的算法，达到了4.9843。通过新的原始-对偶框架和相关的随机化舍入过程，不仅改进了现有算法，还提供了对已有算法的简化统一证明。此外，论文还证明了新算法在独立舍入算法中的最优性，以及与在线调度问题相关的简单贪心算法的最优性。

Abstract: We study the online load balancing problem on unrelated machines, with the
objective of minimizing the square of the $\ell_2$ norm of the loads on the
machines. The greedy algorithm of Awerbuch et al. (STOC'95) is optimal for
deterministic algorithms and achieves a competitive ratio of $3 + 2 \sqrt{2}
\approx 5.828$, and an improved $5$-competitive randomized algorithm based on
independent rounding has been shown by Caragiannis (SODA'08). In this work, we
present the first algorithm breaking the barrier of $5$ on the competitive
ratio, achieving a bound of $4.9843$. To obtain this result, we use a new
primal-dual framework to analyze this problem based on a natural semidefinite
programming relaxation, together with an online implementation of a correlated
randomized rounding procedure of Im and Shadloo (SODA'20). This novel
primal-dual framework also yields new, simple and unified proofs of the
competitive ratio of the $(3 + 2 \sqrt{2})$-competitive greedy algorithm, the
$5$-competitive randomized independent rounding algorithm, and that of a new
$4$-competitive optimal fractional algorithm. We also provide lower bounds
showing that the previous best randomized algorithm is optimal among
independent rounding algorithms, that our new fractional algorithm is optimal,
and that a simple greedy algorithm is optimal for the closely related online
scheduling problem $R || \sum w_j C_j$.

</details>


### [48] [Hesse's Redemption: Efficient Convex Polynomial Programming](https://arxiv.org/abs/2511.03440)
*Lucas Slot,David Steurer,Manuel Wiedmer*

Main category: cs.DS

TL;DR: 论文解决了凸多项式优化的开放性问题，首次提出了多项式时间算法，填补了理论空白。


<details>
  <summary>Details</summary>
Motivation: 凸多项式优化问题长期以来是一个开放性问题，尤其是在没有线性特征和Khachiyan型示例的情况下。作者旨在填补这一空白，并提供有效的算法解决方案。

Method: 作者开发了新技术来证明解的存在性，即使在没有线性特征的情况下。这些技术结合椭球法，首次实现了凸多项式规划的多项式时间算法。

Result: 论文证明了即使在多项式约束下，凸多项式优化问题也存在多项式比特长度的近似最优解。结合椭球法，首次实现了该问题的多项式时间算法。

Conclusion: 该论文通过开发新技术证明了在没有线性特征的情况下解的存在性，首次提出了凸多项式规划的多项式时间算法，解决了Nesterov提出的问题。

Abstract: Efficient algorithms for convex optimization, such as the ellipsoid method,
require an a priori bound on the radius of a ball around the origin guaranteed
to contain an optimal solution if one exists. For linear and convex quadratic
programming, such solution bounds follow from classical characterizations of
optimal solutions by systems of linear equations. For other programs, e.g.,
semidefinite ones, examples due to Khachiyan show that optimal solutions may
require huge coefficients with an exponential number of bits, even if we allow
approximations. Correspondingly, semidefinite programming is not even known to
be in NP. The unconstrained minimization of convex polynomials of degree four
and higher has remained a fundamental open problem between these two extremes:
its optimal solutions do not admit a linear characterization and, at the same
time, Khachiyan-type examples do not apply. We resolve this problem by
developing new techniques to prove solution bounds when no linear
characterizations are available. Even for programs minimizing a convex
polynomial (of arbitrary degree) over a polyhedron, we prove that the existence
of an optimal solution implies that an approximately optimal one with
polynomial bit length also exists. These solution bounds, combined with the
ellipsoid method, yield the first polynomial-time algorithm for convex
polynomial programming, settling a question posed by Nesterov (Math. Program.,
2019). Before, no polynomial-time algorithm was known even for unconstrained
minimization of a convex polynomial of degree four.

</details>


### [49] [Dynamic Meta-Kernelization](https://arxiv.org/abs/2511.03461)
*Christian Bertram,Deborah Haun,Mads Vestergaard Jensen,Tuukka Korhonen*

Main category: cs.DS

TL;DR: 该论文将静态核化技术扩展到动态设置，提出了一种动态数据结构，能够在动态图中高效维护核图，适用于拓扑-无小图类问题，推动了动态参数化算法的发展。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于将静态核化技术（如平面图上的线性核）扩展到动态设置，以解决动态图中的核化问题，从而为动态参数化算法和近似算法提供新的工具。

Method: 论文提出了一种动态数据结构，用于维护动态拓扑-无小图类的近似最优凸起分解。通过这种方法，能够在每次图更新后高效地维护核图K，保持其与原始图G的最小支配集大小一致，并保证K的规模与最优解线性相关。

Result: 论文实现了动态核化算法，能够在每次更新后以O(log n)的摊销时间维护核图K，保持其与原始图G的最小支配集大小一致，并保证K的规模与最优解线性相关。此外，该方法还适用于满足特定条件的拓扑-无小图类问题。

Conclusion: 该论文通过动态数据结构和算法，成功地将静态核化技术扩展到动态设置，为拓扑-无小图类问题提供了新的动态核化算法，进而推动了动态常数近似算法和动态FPT算法的改进。

Abstract: Kernelization studies polynomial-time preprocessing algorithms. Over the last
20 years, the most celebrated positive results of the field have been linear
kernels for classical NP-hard graph problems on sparse graph classes. In this
paper, we lift these results to the dynamic setting.
  As the canonical example, Alber, Fellows, and Niedermeier [J. ACM 2004] gave
a linear kernel for dominating set on planar graphs. We provide the following
dynamic version of their kernel: Our data structure is initialized with an
$n$-vertex planar graph $G$ in $O(n \log n)$ amortized time, and, at
initialization, outputs a planar graph $K$ with $\mathrm{OPT}(K) =
\mathrm{OPT}(G)$ and $|K| = O(\mathrm{OPT}(G))$, where $\mathrm{OPT}(\cdot)$
denotes the size of a minimum dominating set. The graph $G$ can be updated by
insertions and deletions of edges and isolated vertices in $O(\log n)$
amortized time per update, under the promise that it remains planar. After each
update to $G$, the data structure outputs $O(1)$ updates to $K$, maintaining
$\mathrm{OPT}(K) = \mathrm{OPT}(G)$, $|K| = O(\mathrm{OPT}(G))$, and planarity
of $K$.
  Furthermore, we obtain similar dynamic kernelization algorithms for all
problems satisfying certain conditions on (topological-)minor-free graph
classes. Besides kernelization, this directly implies new dynamic
constant-approximation algorithms and improvements to dynamic FPT algorithms
for such problems.
  Our main technical contribution is a dynamic data structure for maintaining
an approximately optimal protrusion decomposition of a dynamic
topological-minor-free graph. Protrusion decompositions were introduced by
Bodlaender, Fomin, Lokshtanov, Penninkx, Saurabh, and Thilikos [J. ACM 2016],
and have since developed into a part of the core toolbox in kernelization and
parameterized algorithms.

</details>


### [50] [Online Flow Time Minimization: Tight Bounds for Non-Preemptive Algorithms](https://arxiv.org/abs/2511.03485)
*Yutong Geng,Enze Sun,Zonghan Yang,Yuhao Zhang*

Main category: cs.DS

TL;DR: 本文研究了非抢占式调度问题，提出了最优随机化和确定性算法，填补了研究空白，并在kill-and-restart模型中揭示了临界行为。


<details>
  <summary>Details</summary>
Motivation: 研究非抢占式调度中随机化和确定性算法的最优竞争比，以填补先前研究的空白。

Method: 提出了多项式时间随机化算法和确定性算法，并证明了匹配的下界。

Result: 随机化算法的竞争比为Θ(√n/m)，确定性算法的竞争比为O(n/m²+√n/m log m)，并在kill-and-restart模型中揭示了m=1和m≥2时的临界行为。

Conclusion: 本文解决了非抢占式调度中随机化和确定性算法的竞争比问题，填补了先前研究的空白，并在kill-and-restart模型中揭示了确定性算法的临界点。

Abstract: This paper studies the classical online scheduling problem of minimizing
total flow time for $n$ jobs on $m$ identical machines. Prior work often cites
the $\Omega(n)$ lower bound for non-preemptive algorithms to argue for the
necessity of preemption or resource augmentation, which shows the trivial
$O(n)$-competitive greedy algorithm is tight. However, this lower bound applies
only to \emph{deterministic} algorithms in the \emph{single-machine} case,
leaving several fundamental questions unanswered. Can randomness help in the
non-preemptive setting, and what is the optimal online deterministic algorithm
when $m \geq 2$? We resolve both questions. We present a polynomial-time
randomized algorithm with competitive ratio $\Theta(\sqrt{n/m})$ and prove a
matching randomized lower bound, settling the randomized non-preemptive setting
for every $m$. This also improves the best-known offline approximation ratio
from $O(\sqrt{n/m}\log(n/m))$ to $O(\sqrt{n/m})$. On the deterministic side, we
present a non-preemptive algorithm with competitive ratio
$O(n/m^{2}+\sqrt{n/m}\log m)$ and prove a nearly matching lower bound.
  Our framework also extends to the kill-and-restart model, where we reveal a
sharp transition of deterministic algorithms: we design an asymptotically
optimal algorithm with the competitive ratio $O(\sqrt{n/m})$ for $m\ge 2$, yet
establish a strong $\Omega(n/\log n)$ lower bound for $m=1$. Moreover, we show
that randomization provides no further advantage, as the lower bound coincides
with that of the non-preemptive setting.
  While our main results assume prior knowledge of $n$, we also investigate the
setting where $n$ is unknown. We show kill-and-restart is powerful enough to
break the $O(n)$ barrier for $m \geq 2$ even without knowing $n$. Conversely,
we prove randomization alone is insufficient, as no algorithm can achieve an
$o(n)$ competitive ratio in this setting.

</details>


### [51] [Randomized Rounding over Dynamic Programs](https://arxiv.org/abs/2511.03490)
*Etienne Bamas,Shi Li,Lars Rohwedder*

Main category: cs.DS

TL;DR: 论文提出在动态规划问题中处理大量额外约束的近似算法，方法基于网络设计和随机舍入，适用于多种经典问题。


<details>
  <summary>Details</summary>
Motivation: 解决在动态规划问题中引入大量额外约束时的求解挑战，扩展动态规划的应用范围。

Method: 通过将动态规划子问题重新解释为网络设计问题，构建强线性规划松弛并应用随机舍入技术，获得近似保证。

Result: 提出了一个形式为$(n^{\epsilon} \mathrm{polylog}\ n)$-近似的时间复杂度$n^{O(1/\epsilon)}$的算法，适用于多种经典问题。

Conclusion: 该论文展示了在满足动态规划类似递推关系的问题中，即使存在大量额外约束条件，仍能找到近似解。方法适用于多种经典动态规划问题，并能扩展到覆盖约束问题。

Abstract: We show that under mild assumptions for a problem whose solutions admit a
dynamic programming-like recurrence relation, we can still find a solution
under additional packing constraints, which need to be satisfied approximately.
The number of additional constraints can be very large, for example, polynomial
in the problem size. Technically, we reinterpret the dynamic programming
subproblems and their solutions as a network design problem. Inspired by
techniques from, for example, the Directed Steiner Tree problem, we construct a
strong LP relaxation, on which we then apply randomized rounding. Our
approximation guarantees on the packing constraints have roughly the form of a
$(n^{\epsilon} \mathrm{polylog}\ n)$-approximation in time $n^{O(1/\epsilon)}$,
for any $\epsilon > 0$. By setting $\epsilon=\log \log n/\log n$, we obtain a
polylogarithmic approximation in quasi-polynomial time, or by setting
$\epsilon$ as a constant, an $n^\epsilon$-approximation in polynomial time.
  While there are necessary assumptions on the form of the DP, it is general
enough to capture many textbook dynamic programs from Shortest Path to Longest
Common Subsequence. Our algorithm then implies that we can impose additional
constraints on the solutions to these problems. This allows us to model various
problems from the literature in approximation algorithms, many of which were
not thought to be connected to dynamic programming. In fact, our result can
even be applied indirectly to some problems that involve covering instead of
packing constraints, for example, the Directed Steiner Tree problem, or those
that do not directly follow a recurrence relation, for example, variants of the
Matching problem.

</details>


### [52] [Engineering Algorithms for $\ell$-Isolated Maximal Clique Enumeration](https://arxiv.org/abs/2511.03525)
*Marco D'Elia,Irene Finocchi,Maurizio Patrignani*

Main category: cs.DS

TL;DR: 本文提出四种剪枝启发式方法，用于高效枚举$\ell$-孤立最大团，尤其在社交网络类图中表现优异，其中两种方法效率提升显著。


<details>
  <summary>Details</summary>
Motivation: 最大团在多个应用领域扮演重要角色，但其数量庞大导致在实际应用中难以有效利用。通过控制参数$\ell$枚举$\ell$-孤立最大团，可以过滤掉与外部过度连接的团，提高实用性。

Method: 基于Tomita等人的递归算法，提出了四种剪枝启发式方法，单独或组合应用，以丢弃不会产生$\ell$-孤立最大团的递归搜索分支。

Result: 实验研究表明，提出的启发式方法相较于Tomita的基线方法和现有先进方法，在具有社交网络属性的真实世界图上显著提高了效率。

Conclusion: 本文通过提出四种剪枝启发式方法，显著提高了在具有社交网络属性的真实世界图中枚举$\ell$-孤立最大团的效率，尤其是其中两种启发式方法表现尤为突出。

Abstract: Maximal cliques play a fundamental role in numerous application domains,
where their enumeration can prove extremely useful. Yet their sheer number,
even in sparse real-world graphs, can make them impractical to be exploited
effectively. To address this issue, one approach is to enumerate
$\ell$-isolated maximal cliques, whose vertices have (on average) less than
$\ell$ edges toward the rest of the graph. By tuning parameter $\ell$, the
degree of isolation can be controlled, and cliques that are overly connected to
the outside are filtered out. Building on Tomita et al.'s very practical
recursive algorithm for maximal clique enumeration, we propose four pruning
heuristics, applicable individually or in combination, that discard recursive
search branches that are guaranteed not to yield $\ell$-isolated maximal
cliques. Besides proving correctness, we characterize both the pruning power
and the computational cost of these heuristics, and we conduct an extensive
experimental study comparing our methods with Tomita's baseline and with a
state-of-the-art approach. Results show that two of our heuristics offer
substantial efficiency improvements, especially on real-world graphs with
social network properties.

</details>


### [53] [Improved Bounds with a Simple Algorithm for Edge Estimation for Graphs of Unknown Size](https://arxiv.org/abs/2511.03650)
*Debarshi Chanda*

Main category: cs.DS

TL;DR: 本文提出了一种无需图参数的随机算法，显著降低了估计平均度数的查询复杂度，并通过下限分析证明了其最优性。


<details>
  <summary>Details</summary>
Motivation: 旨在改进现有算法在查询复杂度上的不足，同时去除对图参数的依赖，提升算法的实用性和简洁性。

Method: 本文提出了一种随机算法，利用Degree和Random Edge查询，通过新的估计技术，无需输入任何图参数即可估计图的平均度数。

Result: 算法的查询复杂度为O~(α/(ε²d)) Degree查询和O~(1/ε²) Random Edge查询，显著优于现有算法。此外，通过下限分析证明了算法的最优性。

Conclusion: 本文提出了一种随机算法，通过改进查询复杂度，显著提升了估计图的平均度数的效率。同时，通过下限分析，证明了算法的查询复杂度在理论上的最优性。

Abstract: We propose a randomized algorithm with query access that given a graph $G$
with arboricity $\alpha$, and average degree $d$, makes
$\widetilde{O}\left(\frac{\alpha}{\varepsilon^2d}\right)$ \texttt{Degree} and
$\widetilde{O}\left(\frac{1}{\varepsilon^2}\right)$ \texttt{Random Edge}
queries to obtain an estimate $\widehat{d}$ satisfying $\widehat{d} \in
(1\pm\varepsilon)d$. This improves the $\widetilde{O}_{\varepsilon,\log
n}\left(\sqrt{\frac{n}{d}}\right)$ query algorithm of [Beretta et al., SODA
2026] that has access to \texttt{Degree}, \texttt{Neighbour}, and
\texttt{Random Edge} queries. Our algorithm does not require any graph
parameter as input, not even the size of the vertex set, and attains both
simplicity and practicality through a new estimation technique. We complement
our upper bounds with a lower bound that shows for all valid $n,d$, and
$\alpha$, any algorithm that has access to \texttt{Degree}, \texttt{Neighbour},
and \texttt{Random Edge} queries, must make at least
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$, even with the knowledge of
$n$ and $\alpha$. We also show that even with \texttt{Pair} and
\texttt{FullNbr} queries, an algorithm must make
$\Omega\left(\min\left(d,\frac{\alpha}{d}\right)\right)$ queries to obtain a
$(1\pm\varepsilon)$-multiplicative estimate of $d$. Our work addresses both the
questions raised by the work of [Beretta et al., SODA 2026].

</details>


### [54] [An Improved Quality Hierarchical Congestion Approximator in Near-Linear Time](https://arxiv.org/abs/2511.03716)
*Monika Henzinger,Robin Münk,Harald Räcke*

Main category: cs.DS

TL;DR: 提出首个近线性时间算法，通过分层拥塞近似器实现$O(\log^2 n \log \log n)$近似比，并改进并行算法的近似质量。


<details>
  <summary>Details</summary>
Motivation: 研究分层拥塞近似器在计算时间与近似质量之间的权衡，以填补现有算法在近线性时间内仅能实现较差近似比的空白。

Method: 采用新的分区例程避免对大型子图的递归，并引入割的边界可路由性概念及改进的顶点权重稀疏割预言机。

Result: 算法在近线性时间内实现了$O(\log^2 n \log \log n)$的近似比，并行实现中改进了此前$O(\log^9n)$的近似比。

Conclusion: 本文提出了首个近线性时间算法，通过使用分层拥塞近似器，实现了高概率下的$O(\log^2 n \log \log n)$近似比，并基于无感知路由的归约，提出了分层拥塞近似器的$\Omega(\log n)$下界。

Abstract: A congestion approximator for a graph is a compact data structure that
approximately predicts the edge congestion required to route any set of flow
demands in a network. A congestion approximator is hierarchical if it consists
of a laminar family of cuts in the graph. There is a tradeoff between the
running time for computing a congestion approximator and its approximation
quality. Currently, for an $n$-node graph there exists a polynomial time
algorithm that achieves a $O(\log^{1.5}n \log \log n)$ approximation and a
near-linear time algorithm that achieves w.h.p. a $O(\log^4 n)$ approximation.
In this paper we give the first near-linear time algorithm, that achieves
w.h.p. a $O(\log^2 n \log \log n)$ approximation, using an hierarchical
congestion approximator with $O(n \log n)$ cuts. Based on a reduction from
oblivious routing, we also present a lower bound of $\Omega(\log n)$ for the
approximation quality of hierarchical congestion approximators.
  Our algorithm can also be implemented in the parallel setting achieving the
same approximation quality, polylogarithmic span and near-linear work. This
improves upon the best prior parallel algorithm, which has a $O(\log^9n)$
approximation.
  Crucial for achieving a near linear running time is a new partitioning
routine that, unlike previous such routines, manages to avoid recursing on
large subgraphs. To achieve the improved approximation quality, we introduce
the new concept of border routability of a cut and give an improved sparsest
cut oracle for general vertex weights.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [55] [Harvesting energy consumption on European HPC systems: Sharing Experience from the CEEC project](https://arxiv.org/abs/2511.03029)
*Kajol Kulkarni,Samuel Kemmler,Anna Schwarz,Gulcin Gedik,Yanxiang Chen,Dimitrios Papageorgiou,Ioannis Kavroulakis,Roman Iakymchuk*

Main category: cs.DC

TL;DR: 本文总结了欧洲Exascale CFD卓越中心在测量、分析和优化HPC系统能源消耗方面的经验，强调了加速器和混合精度技术的节能优势，并呼吁促进能源测量以实现可持续计算。


<details>
  <summary>Details</summary>
Motivation: 现代高性能计算系统的能源效率成为核心挑战，计算需求和架构复杂性导致能源消耗显著增加。

Method: 通过案例研究（使用waLBerla、FLEXI/GALÆXI、Neko和NekRS等代表性CFD应用），评估了不同架构上的能源效率和计算时间指标。

Result: 研究结果突出了加速器和混合精度技术在降低能源消耗同时保持计算准确性的优势。

Conclusion: 论文呼吁在HPC系统中促进能源测量，以提高意识、教育社区，并采取行动实现更可持续的百亿亿次计算。

Abstract: Energy efficiency has emerged as a central challenge for modern
high-performance computing (HPC) systems, where escalating computational
demands and architectural complexity have led to significant energy footprints.
This paper presents the collective experience of the EuroHPC JU Center of
Excellence in Exascale CFD (CEEC) in measuring, analyzing, and optimizing
energy consumption across major European HPC systems. We briefly review key
methodologies and tools for energy measurement as well as define metrics for
reporting results. Through case studies using representative CFD applications
(waLBerla, FLEXI/GAL{\AE}XI, Neko, and NekRS), we evaluate energy-to-solution
and time-to-solution metrics on diverse architectures, including CPU- and
GPU-based partitions of LUMI, MareNostrum5, MeluXina, and JUWELS Booster. Our
results highlight the advantages of accelerators and mixed-precision techniques
for reducing energy consumption while maintaining computational accuracy.
Finally, we advocate the need to facilitate energy measurements on HPC systems
in order to raise awareness, teach the community, and take actions toward more
sustainable exascale computing.

</details>


### [56] [Characterising Global Platforms: Centralised, Decentralised, Federated, and Grassroots](https://arxiv.org/abs/2511.03286)
*Ehud Shapiro*

Main category: cs.DC

TL;DR: 提出了一个形式化框架，通过必需代理的基数将全球数字平台分为四类，并证明了其正确性。


<details>
  <summary>Details</summary>
Motivation: 研究全球数字平台的分类和形式化分析，以填补现有分类的空白。

Method: 提出了基于原子交易的多代理转换系统和协议作为形式框架，并引入了必需代理的概念。

Result: 将全球平台分为四类：集中式、分散式、联邦式和草根式，并通过多代理原子交易规范证明了基本正确性。

Conclusion: 该研究首次提出了一个数学框架，用于通过多代理原子交易规范对任何全球平台进行分类，并确定后续多代理协议中最小必需代理集合的基数。

Abstract: Global digital platforms are software systems designed to serve entire
populations, with some already serving billions of people. We propose atomic
transactions-based multiagent transition systems and protocols as a formal
framework to study them; introduce essential agents -- minimal sets of agents
the removal of which makes communication impossible; and show that the
cardinality of essential agents partitions all global platforms into four
classes:
  1. Centralised -- one (the server)
  2. Decentralised -- finite $>1$ (bootstrap nodes)
  3. Federated -- infinite but not universal (all servers)
  4. Grassroots -- universal (all agents)
  Our illustrative formal example is a global social network, for which we
provide centralised, decentralised, federated, and grassroots specifications
via multiagent atomic transactions, and prove they satisfy basic correctness
properties. We discuss informally additional global platforms -- currencies,
``sharing economy'' apps, AI, and more. While this may be the first
characterisation of centralised, decentralised, and federated global platforms,
grassroots platforms have been formally defined previously, but using different
notions. Here, we prove that their original definition implies that all agents
are essential, placing grassroots platforms in a distinct class within the
broader formal context that includes all global platforms. This work provides
the first mathematical framework for classifying any global platform --
existing or imagined -- by providing a multiagent atomic-transactions
specification of it and determining the cardinality of the minimal set of
essential agents in the ensuing multiagent protocol. It thus

</details>


### [57] [UMDAM: A Unified Data Layout and DRAM Address Mapping for Heterogenous NPU-PIM](https://arxiv.org/abs/2511.03293)
*Hai Huang,Xuhong Qiang,Weisheng Zhao,Chenchen Liu*

Main category: cs.DC

TL;DR: UMDAM improves LLM inference on edge devices with a unified memory-affinity layout, reducing latency without extra overhead.


<details>
  <summary>Details</summary>
Motivation: Address challenges like data layout mismatches, bandwidth loss, and redundant storage in NPU-PIM systems.

Method: UMDAM employs a column-major, tile-based layout and a configurable DRAM mapping strategy for NPU-PIM co-execution.

Result: UMDAM reduces TTFT by up to 3.0x and TTLT by 2.18x.

Conclusion: UMDAM significantly improves end-to-end LLM inference efficiency on edge devices by reducing TTFT and TTLT.

Abstract: Large Language Models (LLMs) are increasingly deployed on edge devices with
Neural Processing Units (NPUs), yet the decode phase remains memory-intensive,
limiting performance. Processing-in-Memory (PIM) offers a promising solution,
but co-executing NPU-PIM systems face challenges such as data layout
mismatches, bandwidth loss, and redundant storage. To address these issues, we
propose UMDAM, a unified memory-affinity data layout and DRAM address mapping
scheme tailored for NPU-PIM co-execution. UMDAM employs a column-major,
tile-based layout and a configurable DRAM mapping strategy to ensure
compatibility with NPU computation while maximizing PIM efficiency -- without
introducing extra memory overhead or bandwidth loss. Comprehensive evaluations
on OPT models demonstrate that UMDAM reduces time-to-first-token (TTFT) by up
to 3.0x and time-to-last-token (TTLT) by 2.18x, significantly improving
end-to-end LLM inference efficiency on edge devices.

</details>


### [58] [Investigating the Impact of Isolation on Synchronized Benchmarks](https://arxiv.org/abs/2511.03533)
*Nils Japke,Furat Hamdan,Diana Baumann,David Bermbach*

Main category: cs.DC

TL;DR: Duet基准测试通过在同一VM上同步运行两个工作负载版本来减少性能变异性，但需要额外隔离机制。评估显示，除Docker容器外，进程隔离有效降低误报率。


<details>
  <summary>Details</summary>
Motivation: 解决云环境中多租户资源争用导致的性能变异性问题。

Method: 评估了三种隔离策略：cgroups和CPU固定、Docker容器以及Firecracker MicroVMs，并与未隔离的基线实验进行对比。

Result: 所有实验在噪声生成影响下显示出不同的延迟分布，但进程隔离通常降低了误报率，Docker容器除外。

Conclusion: 推荐使用进程隔离来处理同步工作负载，但应避免使用Docker容器。

Abstract: Benchmarking in cloud environments suffers from performance variability from
multi-tenant resource contention. Duet benchmarking mitigates this by running
two workload versions concurrently on the same VM, exposing them to identical
external interference. However, intra-VM contention between synchronized
workloads necessitates additional isolation mechanisms.
  This work evaluates three such strategies: cgroups and CPU pinning, Docker
containers, and Firecracker MicroVMs. We compare all strategies with an
unisolated baseline experiment, by running benchmarks with a duet setup
alongside a noise generator. This noise generator "steals" compute resources to
degrade performance measurements.
  All experiments showed different latency distributions while under the
effects of noise generation, but results show that process isolation generally
lowered false positives, except for our experiments with Docker containers.
Even though Docker containers rely internally on cgroups and CPU pinning, they
were more susceptible to performance degradation due to noise influence.
Therefore, we recommend to use process isolation for synchronized workloads,
with the exception of Docker containers.

</details>


### [59] [Stone Duality Proofs for Colorless Distributed Computability Theorems](https://arxiv.org/abs/2511.03609)
*Cameron Calk,Emmanuel Godard*

Main category: cs.DC

TL;DR: 论文提出了一种基于谱空间的拓扑编码方法，用于分析分布式计算中无色任务的可解性，并揭示了彩色与无色模型的计算等价性。


<details>
  <summary>Details</summary>
Motivation: 旨在统一分布式计算中的拓扑方法，扩展对无色任务可解性的理解，并解释彩色与无色模型计算能力等价性的拓扑原因。

Method: 采用谱空间和Alexandrov拓扑对分布式协议的全局状态进行建模，通过投影极限定义极限对象，并利用Stone对偶性推导分布式可计算性定理。

Result: 证明了无色任务在紧凑对手模型下的可解性条件，并发现彩色与无色模型在计算能力上等价。

Conclusion: 通过引入谱空间和Stone对偶性，论文证明了无色任务在紧凑对手模型下的可解性，并揭示了彩色与无色模型在计算能力上的等价性。

Abstract: We introduce a new topological encoding by spectral spaces of executions of
  round-based full-information adversaries, a model of distributed computations
that is functorially presented and that
  contains many message adversaries. We give a characterization of the
solvability of colorless tasks against compact adversaries.
  Message adversaries are distributed
  models that are known to be very expressive despite being
  round-based and crash-free. Colorless tasks are
  an important class of distributed tasks. For a colorless task, the
  specification does not depend upon the multiplicity of input or
  output values, like the ubiquitous agreement tasks.
  Therefore, our result is a significant
  step toward unifying topological methods in distributed computing.
  The main insight is to consider global states obtained after finite
executions of a distributed protocol
  not as abstract
  simplicial complexes as previously done, but as spectral
  spaces, considering the Alexandrov topology on the faces poset. Given
  an adversary $\mathcal M$ with a set of inputs $\mathcal I$,
  we define a limit object $\Pi^\infty_\mathcal M(\mathcal I)$
  by projective limit in the category of spectral spaces. We derive a new
general distributed computability
  theorem using Stone duality: there exists an algorithm solving a colorless
task $(\mathcal I,\mathcal O,\Delta)$
  against the compact adversary $\mathcal M$ if and only if there exists a
spectral
  map $f:\Pi^\infty_\mathcal M(\mathcal I)\longrightarrow\mathcal O$ compatible
with $\Delta$.
  From this general characterization are derived many known colorless
computability
  theorems.
  Quite surprisingly, colored and uncolored models have the same
  computability power (they solve the same tasks). Our new proofs give
  topological reasons for this equivalence, previously known through
  algorithmic reductions.

</details>


### [60] [A General Input-Dependent Colorless Computability Theorem and Applications to Core-Dependent Adversaries](https://arxiv.org/abs/2511.03662)
*Yannis Coutouly,Emmanuel Godard*

Main category: cs.DC

TL;DR: 本文扩展了分布式计算任务的求解能力，通过几何方法分析了输入依赖和核心弹性对手，并提供了k-集合协议的完全条件。


<details>
  <summary>Details</summary>
Motivation: 研究分布式计算任务在不同对手模型下的可解性，特别是输入依赖对手和核心弹性对手的通用化求解能力。

Method: 利用拓扑框架和简单几何构造，对输入依赖对手和核心弹性对手进行建模和分析。

Result: 1. 将对手模型的通用化求解能力扩展到输入依赖对手；2. 证明了核心弹性对手在IIS模型中的计算能力等价性；3. 提供了k-集合协议的完全条件。

Conclusion: 本文通过几何方法扩展了分布式计算任务的求解能力，特别是针对输入依赖的对手和核心弹性对手，提供了k-集合协议的必要和充分条件，并简化了证明过程。

Abstract: Distributed computing tasks can be presented with a triple $(\I,\Ou,\Delta)$.
The solvability of a colorless task on the Iterated Immediate Snapshot model
(IIS) has been characterized by the Colorless Computability Theorem
\cite[Th.4.3.1]{HKRbook}. A recent paper~\cite{CG-24} generalizes this theorem
for any message adversaries $\ma \subseteq IIS$ by geometric methods. In 2001,
Most\'efaoui, Rajsbaum, Raynal, and Roy \cite{condbased} introduced
\emph{condition-based adversaries}. This setting considers a particular
adversary that will be applied only to a subset of input configurations. In
this setting, they studied the $k$-set agreement task with condition-based
$t$-resilient adversaries and obtained a sufficient condition on the conditions
that make $k$-Set Agreement solvable. In this paper we have three
contributions:
  -We generalize the characterization of~\cite{CG-24} to \emph{input-dependent}
adversaries, which means that the adversaries can change depending on the input
configuration.
  - We show that core-resilient adversaries of $IIS_n$ have the same
computability power as the core-resilient adversaries of $IIS_n$ where crashes
only happen at the start.
  - Using the two previous contributions, we provide a necessary and sufficient
characterization of the condition-based, core-dependent adversaries that can
solve $k$-Set Agreement. We also distinguish four settings that may appear when
presenting a distributed task as $(\I,\Ou,\Delta)$. Finally, in a later
section, we present structural properties on the carrier map $\Delta$. Such
properties allow simpler proof, without changing the computability power of the
task. Most of the proofs in this article leverage the topological framework
used in distributed computing by using simple geometric constructions.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [61] [Evaluating Control Protocols for Untrusted AI Agents](https://arxiv.org/abs/2511.02997)
*Jon Kutasov,Chloe Loughridge,Yuqi Sun,Henry Sleight,Buck Shlegeris,Tyler Tracy,Joe Benton*

Main category: cs.AI

TL;DR: 本文评估了AI控制协议在对抗当前攻击和自适应对手时的有效性，发现关键行动延迟策略最具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统作为代理的部署越来越广泛，确保其安全运行变得至关重要。AI控制通过监视和干预来降低不受信任AI代理的风险。

Method: 在SHADE-Arena数据集中系统评估了多种控制协议，包括延迟可信模型、重采样和关键行动延迟等蓝队协议，以及迭代的红队策略。

Result: 重采样和关键行动延迟策略表现最佳，将安全性从50%提升至96%；但红队策略在了解重采样或模拟监视器的情况下，能将安全性降至17%。

Conclusion: 关键行动上的延迟策略在对抗最强红队策略时表现出极高的鲁棒性，强调了拒绝攻击策略访问协议内部的重要性。

Abstract: As AI systems become more capable and widely deployed as agents, ensuring
their safe operation becomes critical. AI control offers one approach to
mitigating the risk from untrusted AI agents by monitoring their actions and
intervening or auditing when necessary. Evaluating the safety of these
protocols requires understanding both their effectiveness against current
attacks and their robustness to adaptive adversaries. In this work, we
systematically evaluate a range of control protocols in SHADE-Arena, a dataset
of diverse agentic environments. First, we evaluate blue team protocols,
including deferral to trusted models, resampling, and deferring on critical
actions, against a default attack policy. We find that resampling for
incrimination and deferring on critical actions perform best, increasing safety
from 50% to 96%. We then iterate on red team strategies against these protocols
and find that attack policies with additional affordances, such as knowledge of
when resampling occurs or the ability to simulate monitors, can substantially
improve attack success rates against our resampling strategy, decreasing safety
to 17%. However, deferring on critical actions is highly robust to even our
strongest red team strategies, demonstrating the importance of denying attack
policies access to protocol internals.

</details>


### [62] [PublicAgent: Multi-Agent Design Principles From an LLM-Based Open Data Analysis Framework](https://arxiv.org/abs/2511.03023)
*Sina Montazeri,Yunhe Feng,Kewei Sha*

Main category: cs.AI

TL;DR: PublicAgent是一个多智能体框架，通过分解任务和阶段验证解决了大型语言模型在复杂分析中的局限性，提升了公共数据的可访问性。


<details>
  <summary>Details</summary>
Motivation: 开放数据仓库对非专家用户来说难以访问，现有大型语言模型在端到端分析工作流中表现有限，注意力分散、专业推理干扰和错误传播是主要问题。

Method: PublicAgent采用多智能体框架，分为意图澄清、数据集发现、分析和报告四个专业智能体，每个智能体专注于特定任务并允许阶段验证。

Result: 评估显示专业化智能体在不同模型和任务中表现稳定，验证了多智能体架构的有效性，并提出了五项设计原则以优化复杂分析工作流。

Conclusion: PublicAgent框架通过多智能体分解解决了大型语言模型在端到端分析工作流中的局限性，为复杂分析任务提供了专业化和验证机制，同时提升了公共数据的可访问性。

Abstract: Open data repositories hold potential for evidence-based decision-making, yet
are inaccessible to non-experts lacking expertise in dataset discovery, schema
mapping, and statistical analysis. Large language models show promise for
individual tasks, but end-to-end analytical workflows expose fundamental
limitations: attention dilutes across growing contexts, specialized reasoning
patterns interfere, and errors propagate undetected. We present PublicAgent, a
multi-agent framework that addresses these limitations through decomposition
into specialized agents for intent clarification, dataset discovery, analysis,
and reporting. This architecture maintains focused attention within agent
contexts and enables validation at each stage. Evaluation across five models
and 50 queries derives five design principles for multi-agent LLM systems.
First, specialization provides value independent of model strength--even the
strongest model shows 97.5% agent win rates, with benefits orthogonal to model
scale. Second, agents divide into universal (discovery, analysis) and
conditional (report, intent) categories. Universal agents show consistent
effectiveness (std dev 12.4%) while conditional agents vary by model (std dev
20.5%). Third, agents mitigate distinct failure modes--removing discovery or
analysis causes catastrophic failures (243-280 instances), while removing
report or intent causes quality degradation. Fourth, architectural benefits
persist across task complexity with stable win rates (86-92% analysis, 84-94%
discovery), indicating workflow management value rather than reasoning
enhancement. Fifth, wide variance in agent effectiveness across models (42-96%
for analysis) requires model-aware architecture design. These principles guide
when and why specialization is necessary for complex analytical workflows while
enabling broader access to public data through natural language interfaces.

</details>


### [63] [No-Human in the Loop: Agentic Evaluation at Scale for Recommendation](https://arxiv.org/abs/2511.03051)
*Tao Zhang,Kehui Yao,Luyi Ma,Jiao Chen,Reza Yousefi Maragheh,Kai Zhao,Jianpeng Xu,Evren Korpeoglu,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: ScalingEval benchmarks 36 LLMs, finding Claude 3.5 Sonnet most confident, Gemini 1.5 Pro best overall, GPT-4o optimal for tradeoffs, and GPT-OSS 20B leading open-source models, with structured domains showing stronger consensus than lifestyle categories.


<details>
  <summary>Details</summary>
Motivation: Evaluating large language models (LLMs) as judges is critical for building scalable and trustworthy evaluation pipelines.

Method: The study employs a multi-agent framework that aggregates pattern audits and issue codes into ground-truth labels via scalable majority voting, enabling reproducible comparison without human annotation.

Result: Key findings include: (i) Anthropic Claude 3.5 Sonnet has the highest decision confidence; (ii) Gemini 1.5 Pro performs best overall; (iii) GPT-4o offers the best latency-accuracy-cost tradeoff; (iv) GPT-OSS 20B leads among open-source models. Strong consensus is noted in structured domains but disagreement persists in lifestyle categories.

Conclusion: ScalingEval establishes itself as a reproducible benchmark and evaluation protocol for LLMs as judges, offering actionable insights on scaling, reliability, and model family tradeoffs.

Abstract: Evaluating large language models (LLMs) as judges is increasingly critical
for building scalable and trustworthy evaluation pipelines. We present
ScalingEval, a large-scale benchmarking study that systematically compares 36
LLMs, including GPT, Gemini, Claude, and Llama, across multiple product
categories using a consensus-driven evaluation protocol. Our multi-agent
framework aggregates pattern audits and issue codes into ground-truth labels
via scalable majority voting, enabling reproducible comparison of LLM
evaluators without human annotation. Applied to large-scale complementary-item
recommendation, the benchmark reports four key findings: (i) Anthropic Claude
3.5 Sonnet achieves the highest decision confidence; (ii) Gemini 1.5 Pro offers
the best overall performance across categories; (iii) GPT-4o provides the most
favorable latency-accuracy-cost tradeoff; and (iv) GPT-OSS 20B leads among
open-source models. Category-level analysis shows strong consensus in
structured domains (Electronics, Sports) but persistent disagreement in
lifestyle categories (Clothing, Food). These results establish ScalingEval as a
reproducible benchmark and evaluation protocol for LLMs as judges, with
actionable guidance on scaling, reliability, and model family tradeoffs.

</details>


### [64] [Epidemiology of Large Language Models: A Benchmark for Observational Distribution Knowledge](https://arxiv.org/abs/2511.03070)
*Drago Plecko,Patrik Okanovic,Torsten Hoefler,Elias Bareinboim*

Main category: cs.AI

TL;DR: 研究开发了评估语言模型对现实世界概率分布理解能力的基准，发现其表现不佳，缺乏对观察性分布的知识。


<details>
  <summary>Details</summary>
Motivation: 探讨语言模型是否能够内化现实世界的概率分布，以评估其在更普遍智能方面的潜力。

Method: 开发了首个直接测试语言模型是否能够获取描述现实世界人口的经验分布的基准，评估覆盖经济、健康、教育和社会行为等多个领域。

Result: 语言模型整体表现不佳，未能自然内化现实世界统计数据。

Conclusion: 语言模型在理解和内化现实世界概率分布方面表现不佳，且缺乏对观察性分布的知识，从而限制了其在干预性和反事实性知识方面的能力。

Abstract: Artificial intelligence (AI) systems hold great promise for advancing various
scientific disciplines, and are increasingly used in real-world applications.
Despite their remarkable progress, further capabilities are expected in order
to achieve more general types of intelligence. A critical distinction in this
context is between factual knowledge, which can be evaluated against true or
false answers (e.g., "what is the capital of England?"), and probabilistic
knowledge, reflecting probabilistic properties of the real world (e.g., "what
is the sex of a computer science graduate in the US?"). In this paper, our goal
is to build a benchmark for understanding the capabilities of LLMs in terms of
knowledge of probability distributions describing the real world. Given that
LLMs are trained on vast amounts of text, it may be plausible that they
internalize aspects of these distributions. Indeed, LLMs are touted as powerful
universal approximators of real-world distributions. At the same time,
classical results in statistics, known as curse of dimensionality, highlight
fundamental challenges in learning distributions in high dimensions,
challenging the notion of universal distributional learning. In this work, we
develop the first benchmark to directly test this hypothesis, evaluating
whether LLMs have access to empirical distributions describing real-world
populations across domains such as economics, health, education, and social
behavior. Our results demonstrate that LLMs perform poorly overall, and do not
seem to internalize real-world statistics naturally. When interpreted in the
context of Pearl's Causal Hierarchy (PCH), our benchmark demonstrates that
language models do not contain knowledge on observational distributions (Layer
1 of PCH), and thus the Causal Hierarchy Theorem implies that interventional
(Layer 2) and counterfactual (Layer 3) knowledge of these models is also
limited.

</details>


### [65] [SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators](https://arxiv.org/abs/2511.03092)
*Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar*

Main category: cs.AI

TL;DR: SnapStream是一种高效的KV缓存压缩技术，适用于大规模LLM部署，显著减少内存需求且几乎不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 随着大参数语言模型（LLMs）的普及，对支持大KV缓存的片上内存需求激增。现有技术（如StreamingLLM和SnapKV）虽能控制KV缓存大小，但工业部署中因静态图和连续批处理方法的限制，以及准确性影响不明，导致应用受限。

Method: 研究团队在Llama-3.1-8B-Instruct和DeepSeek-R1上探索了KV缓存技术的准确性影响，并开发了SnapStream。通过16路张量并行部署DeepSeek-671B，在SambaNova SN40L加速器上验证了其效果。

Result: SnapStream在128k上下文长度和1832 tokens/秒的生产环境中实现了4倍片上内存使用改进，且在LongBench-v2、AIME24和LiveCodeBench上准确性下降极小。

Conclusion: SnapStream是一种KV缓存压缩方法，能够在保持模型准确性的同时显著减少片上内存使用，适用于大规模生产部署。

Abstract: The proliferation of 100B+ parameter Large Language Models (LLMs) with 100k+
context length support have resulted in increasing demands for on-chip memory
to support large KV caches. Techniques such as StreamingLLM and SnapKV
demonstrate how to control KV cache size while maintaining model accuracy. Yet,
these techniques are not commonly used within industrial deployments using
frameworks like vLLM or SGLang. The reason is twofold: on one hand, the static
graphs and continuous batching methodology employed by these frameworks make it
difficult to admit modifications to the standard multi-head attention
algorithm, while on the other hand, the accuracy implications of such
techniques on modern instruction-following and reasoning models are not well
understood, obfuscating the need for implementing these techniques. In this
paper, we explore these accuracy implications on Llama-3.1-8B-Instruct and
DeepSeek-R1, and develop SnapStream, a KV cache compression method that can be
deployed at scale. We demonstrate the efficacy of SnapStream in a 16-way
tensor-parallel deployment of DeepSeek-671B on SambaNova SN40L accelerators
running at 128k context length and up to 1832 tokens per second in a real
production setting. SnapStream enables $4\times$ improved on-chip memory usage
and introduces minimal accuracy degradation on LongBench-v2, AIME24 and
LiveCodeBench. To the best of our knowledge, this is the first implementation
of sparse KV attention techniques deployed in a production inference system
with static graphs and continuous batching.

</details>


### [66] [Large language models require a new form of oversight: capability-based monitoring](https://arxiv.org/abs/2511.03106)
*Katherine C. Kellogg,Bingyang Ye,Yifan Hu,Guergana K. Savova,Byron Wallace,Danielle S. Bitterman*

Main category: cs.AI

TL;DR: 提出能力为基础的LLM监控框架，通过共享能力跨任务检测问题，适用于医疗健康领域的通用AI模型。


<details>
  <summary>Details</summary>
Motivation: 现有监控方法基于任务和数据集漂移假设，但LLMs并非为特定任务或人群训练，因此需新的监控原则以适应其通用性。

Method: 提出能力为基础的监控原则，围绕模型共享能力（如总结、推理、翻译等）组织监控，而非独立评估每个下游任务。

Result: 能力为基础的监控能系统性检测弱点、长尾错误和新兴行为，弥补任务监控的不足。

Conclusion: 能力为基础的监控为大型语言模型（LLMs）在医疗健康领域提供了一个可扩展、安全、适应性强的监控框架，适用于未来通用人工智能模型的协作监控。

Abstract: The rapid adoption of large language models (LLMs) in healthcare has been
accompanied by scrutiny of their oversight. Existing monitoring approaches,
inherited from traditional machine learning (ML), are task-based and founded on
assumed performance degradation arising from dataset drift. In contrast, with
LLMs, inevitable model degradation due to changes in populations compared to
the training dataset cannot be assumed, because LLMs were not trained for any
specific task in any given population. We therefore propose a new organizing
principle guiding generalist LLM monitoring that is scalable and grounded in
how these models are developed and used in practice: capability-based
monitoring. Capability-based monitoring is motivated by the fact that LLMs are
generalist systems whose overlapping internal capabilities are reused across
numerous downstream tasks. Instead of evaluating each downstream task
independently, this approach organizes monitoring around shared model
capabilities, such as summarization, reasoning, translation, or safety
guardrails, in order to enable cross-task detection of systemic weaknesses,
long-tail errors, and emergent behaviors that task-based monitoring may miss.
We describe considerations for developers, organizational leaders, and
professional societies for implementing a capability-based monitoring approach.
Ultimately, capability-based monitoring will provide a scalable foundation for
safe, adaptive, and collaborative monitoring of LLMs and future generalist
artificial intelligence models in healthcare.

</details>


### [67] [miniF2F-Lean Revisited: Reviewing Limitations and Charting a Path Forward](https://arxiv.org/abs/2511.03108)
*Azim Ospanov,Farzan Farnia,Roozbeh Yousefzadeh*

Main category: cs.AI

TL;DR: 研究分析了miniF2F基准中形式化与自然语言问题的不一致性，修正后提出miniF2F-v2，显著提升定理证明准确率至70%。


<details>
  <summary>Details</summary>
Motivation: 研究AI系统在数学奥林匹克竞赛中的表现，特别是理解自然语言问题、形式化及定理证明的能力，并识别现有基准中的问题。

Method: 对miniF2F中的问题和形式化语句进行详细分析，修正错误和不一致，提出改进后的miniF2F-v2数据集，并在其上评估定理证明流程的准确率。

Result: 改进后的miniF2F-v2数据集使定理证明流程的准确率从40%提升至70%，揭示了自动形式化模型与定理证明器之间的不匹配问题。

Conclusion: 通过修正miniF2F中的错误和简化问题，提出了miniF2F-v2数据集，显著提升了定理证明流程的准确率，并指出高质量基准对评估形式推理领域进展的重要性。

Abstract: We perform a thorough analysis of the formal and informal statements in the
miniF2F benchmark from the perspective of an AI system that is tasked to
participate in a math Olympiad consisting of the problems in miniF2F. In such
setting, the model has to read and comprehend the problems in natural language,
formalize them in Lean language, then proceed with proving the problems, and it
will get credit for each problem if the formal proof corresponds to the
original informal statement presented to the model. Our evaluation results
reveal that the best accuracy of such pipeline can be about 36% using the SoTA
models in the literature, considerably lower than the individual SoTA
accuracies, 97% and 69% reported in the autoformalization and theorem proving
literature. Analyzing the failure modes, we trace back a considerable portion
of this drop to discrepancies between the formal and informal statements for
more than half of the problems in miniF2F. We proceed with correcting all the
errors, discrepancies and simplifications in formal and informal statements,
and present the miniF2F-v2 with fully verified formal and informal statements
and proofs. Evaluating the full theorem proving pipeline on miniF2F-v2 leads to
the best accuracy of 70%, a significant improvement from the 40% on the
original miniF2F, yet indicating considerable misalignment between the
autoformalization models and theorem provers. Our deep analysis suggests that a
higher quality benchmark can help the community better evaluate progress in the
field of formal reasoning and also better diagnose the failure and success
modes of autoformalization and theorem proving models. Our dataset is available
at https://github.com/roozbeh-yz/miniF2F_v2.

</details>


### [68] [Using Multi-modal Large Language Model to Boost Fireworks Algorithm's Ability in Settling Challenging Optimization Tasks](https://arxiv.org/abs/2511.03137)
*Shipeng Cen,Ying Tan*

Main category: cs.AI

TL;DR: 结合MLLM和FWA的优化框架，显著提升复杂高维任务性能，实验验证其在TSP和EDA问题上的优越性。


<details>
  <summary>Details</summary>
Motivation: 传统优化方法在非凸、高维、黑盒等问题上效率低下，而LLM的发展为优化算法设计提供了新思路。

Method: 以FWA为基础优化器，引入关键部分（CP）概念，并利用MLLM的多模态特性优化设计过程。

Result: 新框架下的FWA在TSP和EDA问题上表现优异，达到或超越了当前最优水平。

Conclusion: 本研究通过结合多模态大语言模型（MLLM）和烟花算法（FWA），提出了一种新的优化框架，显著提升了FWA在复杂高维任务中的性能，并在TSP和EDA问题上达到或超越了SOTA结果。

Abstract: As optimization problems grow increasingly complex and diverse, advancements
in optimization techniques and paradigm innovations hold significant
importance. The challenges posed by optimization problems are primarily
manifested in their non-convexity, high-dimensionality, black-box nature, and
other unfavorable characteristics. Traditional zero-order or first-order
methods, which are often characterized by low efficiency, inaccurate gradient
information, and insufficient utilization of optimization information, are
ill-equipped to address these challenges effectively. In recent years, the
rapid development of large language models (LLM) has led to substantial
improvements in their language understanding and code generation capabilities.
Consequently, the design of optimization algorithms leveraging large language
models has garnered increasing attention from researchers. In this study, we
choose the fireworks algorithm(FWA) as the basic optimizer and propose a novel
approach to assist the design of the FWA by incorporating multi-modal large
language model(MLLM). To put it simply, we propose the concept of Critical
Part(CP), which extends FWA to complex high-dimensional tasks, and further
utilizes the information in the optimization process with the help of the
multi-modal characteristics of large language models. We focus on two specific
tasks: the \textit{traveling salesman problem }(TSP) and \textit{electronic
design automation problem} (EDA). The experimental results show that FWAs
generated under our new framework have achieved or surpassed SOTA results on
many problem instances.

</details>


### [69] [A Proprietary Model-Based Safety Response Framework for AI Agents](https://arxiv.org/abs/2511.03138)
*Qi Li,Jianjun Xu,Pingtao Wei,Jiu Li,Peiqiang Zhao,Jiwei Shi,Xuan Zhang,Yanhui Yang,Xiaodong Hui,Peng Xu,Wenqin Shao*

Main category: cs.AI

TL;DR: 本文提出了一种新型安全响应框架，通过输入和输出级别的双重保护机制，显著提升LLMs的安全性和可信度。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛应用，其安全问题日益突出，严重限制了其在关键领域的可信部署。

Method: 提出了一个新颖的安全响应框架，包括输入级别的基于监督微调的安全分类模型和输出级别的检索增强生成（RAG）与特定微调的解释模型结合。

Result: 在公共安全评估基准上，提出的安全控制模型比基线模型TinyR1-Safety-8B显著提高了安全得分；在专有高风险测试集上，框架组件达到了完美的100%安全得分。

Conclusion: 本研究为构建高安全性、高信任度的LLM应用提供了一条有效的工程化路径。

Abstract: With the widespread application of Large Language Models (LLMs), their
associated security issues have become increasingly prominent, severely
constraining their trustworthy deployment in critical domains. This paper
proposes a novel safety response framework designed to systematically safeguard
LLMs at both the input and output levels. At the input level, the framework
employs a supervised fine-tuning-based safety classification model. Through a
fine-grained four-tier taxonomy (Safe, Unsafe, Conditionally Safe, Focused
Attention), it performs precise risk identification and differentiated handling
of user queries, significantly enhancing risk coverage and business scenario
adaptability, and achieving a risk recall rate of 99.3%. At the output level,
the framework integrates Retrieval-Augmented Generation (RAG) with a
specifically fine-tuned interpretation model, ensuring all responses are
grounded in a real-time, trustworthy knowledge base. This approach eliminates
information fabrication and enables result traceability. Experimental results
demonstrate that our proposed safety control model achieves a significantly
higher safety score on public safety evaluation benchmarks compared to the
baseline model, TinyR1-Safety-8B. Furthermore, on our proprietary high-risk
test set, the framework's components attained a perfect 100% safety score,
validating their exceptional protective capabilities in complex risk scenarios.
This research provides an effective engineering pathway for building
high-security, high-trust LLM applications.

</details>


### [70] [Uncovering Bugs in Formal Explainers: A Case Study with PyXAI](https://arxiv.org/abs/2511.03169)
*Xuanxiang Huang,Yacine Izza,Alexey Ignatiev,Joao Marques-Silva*

Main category: cs.AI

TL;DR: 本文提出并验证了一种新型正式解释器验证方法，发现PyXAI存在错误解释问题。


<details>
  <summary>Details</summary>
Motivation: 尽管正式可解释人工智能（XAI）在理论上具有严格的保证，但其实践实现的验证却鲜有研究。

Method: 开发了一种新型验证方法，并对公开的正式解释器PyXAI进行了评估。

Result: 实验发现PyXAI在多数数据集上计算出的解释存在错误。

Conclusion: 本文证实了提出的新型验证方法在检测PyXAI等正式解释器错误解释中的重要性。

Abstract: Formal explainable artificial intelligence (XAI) offers unique theoretical
guarantees of rigor when compared to other non-formal methods of
explainability. However, little attention has been given to the validation of
practical implementations of formal explainers. This paper develops a novel
methodology for validating formal explainers and reports on the assessment of
the publicly available formal explainer PyXAI. The paper documents the
existence of incorrect explanations computed by PyXAI on most of the datasets
analyzed in the experiments, thereby confirming the importance of the proposed
novel methodology for the validation of formal explainers.

</details>


### [71] [Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework](https://arxiv.org/abs/2511.03179)
*Varun Kumar,George Em Karniadakis*

Main category: cs.AI

TL;DR: 该论文提出了一个多代理AI框架，通过协作AI代理和结构化知识表示优化工程设计过程，应用于翼型设计并验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 传统工程设计方法资源密集且效率低下，需要一种更高效、一致的方法来改进多领域协作的工程设计过程。

Method: 研究采用了多代理AI框架，包括Graph Ontologist、Design Engineer和Systems Engineer三个关键AI代理，通过构建特定领域知识图谱和迭代反馈循环来优化设计过程。

Result: 框架成功应用于NACA四位数翼型的气动优化，通过代理间协作生成了满足技术要求的候选翼型，并优化了升阻比等性能指标。

Conclusion: 该研究展示了配备结构化知识表示的协作AI代理如何提高工程设计过程的效率、一致性和质量。

Abstract: The engineering design process often demands expertise from multiple domains,
leading to complex collaborations and iterative refinements. Traditional
methods can be resource-intensive and prone to inefficiencies. To address this,
we formalize the engineering design process through a multi-agent AI framework
that integrates structured design and review loops. The framework introduces
specialized knowledge-driven agents that collaborate to generate and refine
design candidates. As an exemplar, we demonstrate its application to the
aerodynamic optimization of 4-digit NACA airfoils. The framework consists of
three key AI agents: a Graph Ontologist, a Design Engineer, and a Systems
Engineer. The Graph Ontologist employs a Large Language Model (LLM) to
construct two domain-specific knowledge graphs from airfoil design literature.
The Systems Engineer, informed by a human manager, formulates technical
requirements that guide design generation and evaluation. The Design Engineer
leverages the design knowledge graph and computational tools to propose
candidate airfoils meeting these requirements. The Systems Engineer reviews and
provides feedback both qualitative and quantitative using its own knowledge
graph, forming an iterative feedback loop until a design is validated by the
manager. The final design is then optimized to maximize performance metrics
such as the lift-to-drag ratio. Overall, this work demonstrates how
collaborative AI agents equipped with structured knowledge representations can
enhance efficiency, consistency, and quality in the engineering design process.

</details>


### [72] [Adobe Summit Concierge Evaluation with Human in the Loop](https://arxiv.org/abs/2511.03186)
*Yiru Chen,Sally Fang,Sai Sree Harsha,Dan Luo,Vaishnavi Muppala,Fei Wu,Shun Jiang,Kun Qian,Yunyao Li*

Main category: cs.AI

TL;DR: Summit Concierge是一个针对Adobe Summit的AI助手，通过人机协同开发克服了数据稀疏等挑战，证明了敏捷开发在冷启动场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 利用生成式AI助手提升企业环境中的生产力、信息访问效率和用户体验。

Method: 采用人机协同开发流程，结合提示工程、检索基础和轻量级人工验证。

Result: 成功开发并部署了Summit Concierge，一个针对Adobe Summit的领域特定AI助手，能处理广泛的事件相关查询。

Conclusion: 敏捷、反馈驱动的开发方法即使在冷启动场景下也能实现可扩展且可靠的AI助手。

Abstract: Generative AI assistants offer significant potential to enhance productivity,
streamline information access, and improve user experience in enterprise
contexts. In this work, we present Summit Concierge, a domain-specific AI
assistant developed for Adobe Summit. The assistant handles a wide range of
event-related queries and operates under real-world constraints such as data
sparsity, quality assurance, and rapid deployment. To address these challenges,
we adopt a human-in-the-loop development workflow that combines prompt
engineering, retrieval grounding, and lightweight human validation. We describe
the system architecture, development process, and real-world deployment
outcomes. Our experience shows that agile, feedback-driven development enables
scalable and reliable AI assistants, even in cold-start scenarios.

</details>


### [73] [From Five Dimensions to Many: Large Language Models as Precise and Interpretable Psychological Profilers](https://arxiv.org/abs/2511.03235)
*Yi-Fei Liu,Yi-Long Lu,Di He,Hang Zhang*

Main category: cs.AI

TL;DR: LLMs通过两阶段抽象和推理过程，从最小输入中准确预测人类心理特质，表现出色且揭示新兴推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs是否以及如何从最小量化输入中模拟人类心理特质的相关结构。

Method: 使用Big Five Personality Scale的816名人类个体的回答提示各种LLMs，模拟他们在其他九个心理量表上的回答。

Result: LLMs在捕捉人类心理结构方面表现出色，其生成的回答与人类数据的量表间相关性高度一致（R² > 0.89），零样本表现远超基于语义相似性的预测，接近直接训练在数据集上的机器学习算法的准确性。

Conclusion: LLMs能够通过抽象和推理过程从最小数据中精确预测个体的心理特质，为心理模拟提供了强大工具，并揭示了其新兴推理能力。

Abstract: Psychological constructs within individuals are widely believed to be
interconnected. We investigated whether and how Large Language Models (LLMs)
can model the correlational structure of human psychological traits from
minimal quantitative inputs. We prompted various LLMs with Big Five Personality
Scale responses from 816 human individuals to role-play their responses on nine
other psychological scales. LLMs demonstrated remarkable accuracy in capturing
human psychological structure, with the inter-scale correlation patterns from
LLM-generated responses strongly aligning with those from human data $(R^2 >
0.89)$. This zero-shot performance substantially exceeded predictions based on
semantic similarity and approached the accuracy of machine learning algorithms
trained directly on the dataset. Analysis of reasoning traces revealed that
LLMs use a systematic two-stage process: First, they transform raw Big Five
responses into natural language personality summaries through information
selection and compression, analogous to generating sufficient statistics.
Second, they generate target scale responses based on reasoning from these
summaries. For information selection, LLMs identify the same key personality
factors as trained algorithms, though they fail to differentiate item
importance within factors. The resulting compressed summaries are not merely
redundant representations but capture synergistic information--adding them to
original scores enhances prediction alignment, suggesting they encode emergent,
second-order patterns of trait interplay. Our findings demonstrate that LLMs
can precisely predict individual participants' psychological traits from
minimal data through a process of abstraction and reasoning, offering both a
powerful tool for psychological simulation and valuable insights into their
emergent reasoning capabilities.

</details>


### [74] [Towards Scalable Web Accessibility Audit with MLLMs as Copilots](https://arxiv.org/abs/2511.03471)
*Ming Gu,Ziwei Wang,Sicen Lai,Zirui Gao,Sheng Zhou,Jiajun Bu*

Main category: cs.AI

TL;DR: AAA框架通过GRASP和MaC技术实现可扩展的网络无障碍审计，实验验证其有效性并贡献新数据集。


<details>
  <summary>Details</summary>
Motivation: 当前网络无障碍审计资源密集且难以扩展，WCAG-EM方法虽结构化但执行成本高，亟需高效解决方案。

Method: 提出了AAA审计框架，结合了GRASP（基于图的多模态采样方法）和MaC（基于多模态大型语言模型的助手），支持跨模态推理和智能辅助。

Result: 实验证明AAA框架有效，且贡献了四个新数据集用于审计流程的基准测试。

Conclusion: AAA框架通过人机合作模型实现了可扩展的网络无障碍审计，展示了小规模语言模型在微调后可作为有效的专家。

Abstract: Ensuring web accessibility is crucial for advancing social welfare, justice,
and equality in digital spaces, yet the vast majority of website user
interfaces remain non-compliant, due in part to the resource-intensive and
unscalable nature of current auditing practices. While WCAG-EM offers a
structured methodology for site-wise conformance evaluation, it involves great
human efforts and lacks practical support for execution at scale. In this work,
we present an auditing framework, AAA, which operationalizes WCAG-EM through a
human-AI partnership model. AAA is anchored by two key innovations: GRASP, a
graph-based multimodal sampling method that ensures representative page
coverage via learned embeddings of visual, textual, and relational cues; and
MaC, a multimodal large language model-based copilot that supports auditors
through cross-modal reasoning and intelligent assistance in high-effort tasks.
Together, these components enable scalable, end-to-end web accessibility
auditing, empowering human auditors with AI-enhanced assistance for real-world
impact. We further contribute four novel datasets designed for benchmarking
core stages of the audit pipeline. Extensive experiments demonstrate the
effectiveness of our methods, providing insights that small-scale language
models can serve as capable experts when fine-tuned.

</details>


### [75] [Explaining Decisions in ML Models: a Parameterized Complexity Analysis (Part I)](https://arxiv.org/abs/2511.03545)
*Sebastian Ordyniak,Giacomo Paesani,Mateusz Rychlicki,Stefan Szeider*

Main category: cs.AI

TL;DR: 本文理论分析了多种透明机器学习模型的解释问题，填补了XAI领域的空白，强调了透明AI的重要性。


<details>
  <summary>Details</summary>
Motivation: 针对机器学习模型普遍被视为黑盒的现状，本研究聚焦于具有透明内部机制的模型，填补了XAI领域的空白。

Method: 通过理论分析，研究了多种机器学习模型（如决策树、决策集、决策列表、布尔电路及其组合）中的解释问题，包括局部和全局的溯因与对比解释。

Result: 研究揭示了不同模型在解释生成中的独特挑战，为XAI领域的进一步研究提供了关键见解。

Conclusion: 本文为可解释AI（XAI）领域提供了对生成解释复杂性的基础理解，强调了透明和可问责AI系统的必要性。

Abstract: This paper presents a comprehensive theoretical investigation into the
parameterized complexity of explanation problems in various machine learning
(ML) models. Contrary to the prevalent black-box perception, our study focuses
on models with transparent internal mechanisms. We address two principal types
of explanation problems: abductive and contrastive, both in their local and
global variants. Our analysis encompasses diverse ML models, including Decision
Trees, Decision Sets, Decision Lists, Boolean Circuits, and ensembles thereof,
each offering unique explanatory challenges. This research fills a significant
gap in explainable AI (XAI) by providing a foundational understanding of the
complexities of generating explanations for these models. This work provides
insights vital for further research in the domain of XAI, contributing to the
broader discourse on the necessity of transparency and accountability in AI
systems.

</details>


### [76] [Outbidding and Outbluffing Elite Humans: Mastering Liar's Poker via Self-Play and Reinforcement Learning](https://arxiv.org/abs/2511.03724)
*Richard Dewey,Janos Botyanszki,Ciamac C. Moallemi,Andrew T. Zheng*

Main category: cs.AI

TL;DR: Solly是首个在多人Liar's Poker中达到精英人类水平的AI，通过深度强化学习训练，表现优于大型语言模型。


<details>
  <summary>Details</summary>
Motivation: 扑克类游戏是研究多人动态、不完全信息和不确定性推理的理想测试平台，但现有AI在多人互动方面的表现有限。

Method: 采用无模型的actor-critic深度强化学习算法，通过自我对弈进行训练。

Result: Solly在胜率（超过50%）和资金收益上均达到精英人类水平，并在多人对局中展现出新颖的策略和随机化能力。

Conclusion: Solly作为首个在多人参与的Liar's Poker中达到精英人类水平的AI代理，展示了在复杂多人博弈环境中的卓越能力，并超越了大型语言模型的表现。

Abstract: AI researchers have long focused on poker-like games as a testbed for
environments characterized by multi-player dynamics, imperfect information, and
reasoning under uncertainty. While recent breakthroughs have matched elite
human play at no-limit Texas hold'em, the multi-player dynamics are subdued:
most hands converge quickly with only two players engaged through multiple
rounds of bidding. In this paper, we present Solly, the first AI agent to
achieve elite human play in reduced-format Liar's Poker, a game characterized
by extensive multi-player engagement. We trained Solly using self-play with a
model-free, actor-critic, deep reinforcement learning algorithm. Solly played
at an elite human level as measured by win rate (won over 50% of hands) and
equity (money won) in heads-up and multi-player Liar's Poker. Solly also
outperformed large language models (LLMs), including those with reasoning
abilities, on the same metrics. Solly developed novel bidding strategies,
randomized play effectively, and was not easily exploitable by world-class
human players.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [77] [SELF-REDRAFT: Eliciting Intrinsic Exploration-Exploitation Balance in Test-Time Scaling for Code Generation](https://arxiv.org/abs/2511.02854)
*Yixiang Chen,Tianshi Zheng,Shijue Huang,Zhitao He,Yi R. Fung*

Main category: cs.SE

TL;DR: SELF-REDRAFT框架通过平衡探索与利用，在无测试用例的代码生成中表现优于Self-Refine，但反馈和判别能力仍需提升。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在测试用例不可用场景下，如何平衡贪婪利用（迭代优化）与随机探索（样本投票或重排机制）的内在能力。

Method: 我们引入了SELF-REDRAFT框架，基于Self-Refine，鼓励模型为存在根本性缺陷的解决方案提出新草案。

Result: SELF-REDRAFT在相同最大迭代次数下表现优于Self-Refine，但仍有改进空间，特别是在生成指导性反馈和判别能力方面。

Conclusion: 本研究为测试时扩展中的探索与利用平衡建立了基线，并将反馈和判别识别为未来改进的关键领域。

Abstract: Test-time scaling without interpreter feedback is essential for real-world
code generation scenarios where test cases are not readily available. While
existing paradigms often rely on either greedy exploitation (i.e., iterative
refinement) or stochastic exploration (i.e., relying on sample-based voting or
reranking mechanisms), the balance between these two dimensions remains
underexplored. To investigate the LLM's intrinsic ability to balance
exploitation and exploration, we introduce SELF-REDRAFT, a framework built upon
Self-Refine that encourages the model to propose new drafts for solutions that
are fundamentally flawed. Our results show that SELF-REDRAFT consistently
achieves better performance than Self-Refine when converged under the same
maximum number of iterations. Still, we observe that significant room for
improvement remains, largely due to two core aspects of current self-redraft
capabilities: constrained capacity for generating instructive feedback and
fragile discriminative judgment. We also find that balancing strategies vary
notably across different LLMs, reflecting distinct, model-specific behaviors.
Overall, our study establishes a baseline for intrinsic
exploration-exploitation balancing in test-time scaling and identifies feedback
and discrimination as key areas with potential for future advances.

</details>


### [78] [The Evolution of Agile and Hybrid Project Management Methodologies: A Systematic Literature Review](https://arxiv.org/abs/2511.02859)
*Bianca Leech,Ridewaan Hanslo*

Main category: cs.SE

TL;DR: 本文通过系统文献综述探讨了敏捷方法向混合框架的演变，分析了实施挑战和成功因素，强调领导支持和定制化整合的重要性。


<details>
  <summary>Details</summary>
Motivation: IT项目的快速发展推动了项目管理方法的变革，从传统的瀑布式到敏捷框架，再到最近的混合模型。本研究旨在探讨敏捷方法向混合框架的演变，分析其实施挑战和成功因素。

Method: 本研究通过PRISMA指导的系统文献综述方法，分析了过去8年同行评审的研究，识别了关键趋势。

Result: 研究发现，混合方法论结合了敏捷的迭代灵活性和结构化治理，其成功实施取决于领导支持、定制化流程整合和持续改进机制。

Conclusion: 混合方法论的出现是为了解决敏捷方法在大规模和受监管环境中的局限性，结合了迭代灵活性和结构化治理。研究表明，成功的混合转型依赖于领导支持、定制化流程整合和持续改进机制。

Abstract: The rapid evolution of IT projects has driven the transformation of project
management methodologies, from traditional waterfall approaches to agile
frameworks and, more recently, hybrid models. This systematic literature review
investigates the evolution of agile methodologies into hybrid frameworks,
analysing their implementation challenges and success factors. We identify key
trends through PRISMA-guided analysis of peer-reviewed studies from the last 8
years. Hybrid methodologies emerge from agile limitations in large-scale and
regulated environments, combining iterative flexibility with structured
governance. Agile has several implementation challenges, leading to hybrid
methods, and the success hinges on leadership support, tailored process
integration, and continuous improvement mechanisms. The study explores the need
for contextual adaptation over rigid frameworks, offering practical insights
for organisations navigating hybrid transitions.

</details>


### [79] [LM-Fix: Lightweight Bit-Flip Detection and Rapid Recovery Framework for Language Models](https://arxiv.org/abs/2511.02866)
*Ahmad Tahmasivand,Noureldin Zahran,Saba Al-Sayouri,Mohammed Fouda,Khaled N. Khasawneh*

Main category: cs.SE

TL;DR: LM-Fix 是一个轻量级检测和快速恢复框架，用于大型语言模型中的故障检测与修复，具有高效和低开销的特点。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型完整性方法通常过于笨重或缓慢，无法满足现代需求。

Method: 运行简短的测试向量传递，并使用哈希引导的检查来检测位翻转故障，然后进行局部修复而无需完全重新加载。

Result: 在多个模型中，LM-Fix 能够检测超过 94% 的单点位翻转（TVL=200）和近 100% 的多点位翻转，运行时开销约为 1% 至 7.7%，恢复速度比重新加载快 100 倍以上。

Conclusion: LM-Fix 是一个实用且低开销的解决方案，能够有效保持大型语言模型在生产环境中的可靠性。

Abstract: This paper presents LM-Fix, a lightweight detection and rapid recovery
framework for faults in large language models (LLMs). Existing integrity
approaches are often heavy or slow for modern LLMs. LM-Fix runs a short
test-vector pass and uses hash-guided checks to detect bit-flip faults, then
repairs them locally without a full reload. Across multiple models, it detects
over 94% of single-bit flips at TVL=200 and nearly 100% of multi-bit flips with
approximately 1% to 7.7% runtime overhead; recovery is more than 100x faster
than reloading. These results show a practical, low-overhead solution to keep
LLMs reliable in production

</details>


### [80] [Analysis of AdvFusion: Adapter-based Multilingual Learning for Code Large Language Models](https://arxiv.org/abs/2511.02869)
*Amirreza Esmaeili,Fahd Seddik,Yongyi Ji,Fatemeh Fard,Fuxiang Chen*

Main category: cs.SE

TL;DR: AdvFusion在Code-LLMs上的表现因任务而异，代码生成效果较好，提交消息和代码翻译中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 探索AdvFusion在Code-LLMs上的适用性，并扩展至新任务（代码生成、代码翻译和提交消息生成）。

Method: AdvFusion是一种基于PEFT的方法，通过从其他编程语言学习后再适应目标任务。

Result: 在代码生成中AdvFusion优于AdapterFusion但不如其他PEFT方法；在提交消息生成中AdapterFusion优于AdvFusion；在代码翻译中AdvFusion整体表现较差。

Conclusion: AdvFusion在不同任务（代码生成、提交消息生成和代码翻译）和不同Code-LLM上表现不一，显示出任务和模型特性的依赖性。

Abstract: Programming languages can benefit from one another by utilizing a language
model for software engineering tasks. Full fine-tuning and Parameter Efficient
Fine-Tuning (PEFT) of Code Language Models (Code-LMs) has been explored for
multilingual knowledge transfer. AdapterFusion is a PEFT architecture that aims
to enhance task performance by leveraging information from multiple programming
languages, but primarily focuses on the target programming language.
  In our previous work, we proposed AdvFusion, a novel PEFT-based approach that
effectively learns from other programming languages before adapting to the
target task. Though previous experiments showed that AdvFusion outperformed
AdapterFusion and LoRA, it was applied on pre-trained Code-LMs and was limited
to only two tasks, code summarization and method name prediction. In this
study, we expanded our work and investigated AdvFusion on Code Large Language
Models (Code-LLMs), considering three new tasks: code generation, code
translation, and commit message generation. We observed that different
Code-LLMs/tasks exhibit different characteristics. In code generation,
AdvFusion outperformed AdapterFusion but not other PEFT methods (LoRA,
Compacter, and TaskAdapter). In commit message generation, AdapterFusion
performed better than AdvFusion, and contrary to code generation, we found that
the other PEFT methods do not have better performance. In code translation,
AdvFusion performed worse than AdapterFusion overall, with the performance gap
marginally widening as the model size increases. However, consistent with code
generation, other PEFT methods showed better performance.

</details>


### [81] [An Analysis of Early-Stage Functional Safety Analysis Methods and Their Integration into Model-Based Systems Engineering](https://arxiv.org/abs/2511.02874)
*Jannatul Shefa,Taylan G. Topcu*

Main category: cs.SE

TL;DR: 本文对比了FMEA、FHA和FFIP三种安全分析技术，发现FFIP更适合复杂系统，并综述了它们与MBSE整合的现状，指出当前整合以FMEA为主且缺乏标准框架。


<details>
  <summary>Details</summary>
Motivation: 随着系统复杂度提升，早期阶段的安全分析对风险识别与缓解至关重要。本文旨在评估关键安全分析技术与MBSE整合的现状及潜力。

Method: 采用两阶段方法：第一阶段对比分析FMEA、FHA和FFIP技术的程序、优势与局限性；第二阶段综述这些技术与MBSE整合的现有研究。

Result: 分析显示FFIP更适合现代互联系统的安全需求，而MBSE整合目前以FMEA为主，FHA和FFIP整合尚不成熟。FMEA-MBSE整合可归类为四种方法，但缺乏统一框架。

Conclusion: 本文强调了在模型驱动的系统工程（MBSE）中整合安全分析技术的重要性，特别是FFIP在识别新兴系统行为和故障传播方面的优势。同时指出当前MBSE整合主要集中于FMEA，而FHA和FFIP的整合尚处于起步阶段，缺乏统一框架。

Abstract: As systems become increasingly complex, conducting effective safety analysis
in the earlier phases of a system's lifecycle is essential to identify and
mitigate risks before they escalate. To that end, this paper investigates the
capabilities of key safety analysis techniques, namely: Failure Mode and
Effects Analysis (FMEA), Functional Hazard Analysis (FHA), and Functional
Failure Identification and Propagation (FFIP), along with the current state of
the literature in terms of their integration into Model-Based Systems
Engineering (MBSE). A two-phase approach is adopted. The first phase is focused
on contrasting FMEA, FHA, and FFIP techniques, examining their procedures,
along with a documentation of their relative strengths and limitations. Our
analysis highlights FFIP's capability in identifying emergent system behaviors,
second-order effects, and fault propagation; thus, suggesting it is better
suited for the safety needs of modern interconnected systems. Second, we review
the existing research on the efforts to integrate each of these methods into
MBSE. We find that MBSE integration efforts primarily focus on FMEA, and
integration of FHA and FFIP is nascent. Additionally, FMEA-MBSE integration
efforts could be organized into four categories: model-to-model transformation,
use of external customized algorithms, built-in MBSE packages, and manual use
of standard MBSE diagrams. While our findings indicate a variety of MBSE
integration approaches, there is no universally established framework or
standard. This leaves room for an integration approach that could support the
ongoing Digital Engineering transformation efforts by enabling a more
synergistic lifecycle safety management methods and tools.

</details>


### [82] [CS Educator challenges and their solutions : A systematic mapping study](https://arxiv.org/abs/2511.02876)
*Anjali Chouhan,Sruti Srinivasa Ragavan,Amey Karkare*

Main category: cs.SE

TL;DR: 综述近五年计算机科学教育的研究，揭示教学、情感、技术和制度方面的挑战及应对措施，指出未充分关注的领域，为改进教学效果提供见解。


<details>
  <summary>Details</summary>
Motivation: 计算机科学教育迅速扩展，但教育者在教学和学习环境中仍面临持续挑战。由于缺乏系统性的工作来分类和综合这些挑战及应对措施，哪些领域已被充分解决、哪些仍需更多学术关注尚不明确。

Method: 通过结构化文献综述，分析了近五年内发表的同行评审研究论文，重点关注了十个分类主题中的挑战和补救措施，包括教学、情感、技术和制度维度。

Result: 分析揭示了在评估实践、教师培训、课堂管理和情感福祉等领域的反复出现的问题，以及为缓解这些问题采取的各种策略，如专业发展计划和政策干预，同时也发现了一些尚未得到足够关注的领域。

Conclusion: 这篇综述为计算机科学教育领域的研究者、课程设计者和政策制定者提供了宝贵的见解，旨在提升教学效果和教育者支持。

Abstract: Computer Science (CS) education is expanding rapidly, but educators continue
to face persistent challenges in teaching and learning environments.Despite
growing interest, limited systematic work exists to categorize and synthesize
the specific challenges faced by CS educators and the remedies adopted in
response.This is problematic because it remains unclear which areas have been
thoroughly addressed and which still lack sufficient scholarly attention. In
this study, we conducted a structured literature review of peer-reviewed
research papers published over the last five years, focusing on challenges and
remedies across ten categorized themes, including pedagogical, emotional,
technological, and institutional dimensions.Our analysis revealed recurring
issues in areas such as assessment practices, teacher training, classroom
management, and emotional well-being, along with various strategies such as
professional development programs and policy interventions adopted to mitigate
them while also revealing several areas that have received insufficient
attention.This review offers a consolidated understanding of the CS education
landscape, providing valuable insights for researchers, curriculum designers,
and policymakers aiming to improve teaching effectiveness and educator support.

</details>


### [83] [AgentSLA : Towards a Service Level Agreement for AI Agents](https://arxiv.org/abs/2511.02885)
*Gwendal Jouneaux,Jordi Cabot*

Main category: cs.SE

TL;DR: 本文针对AI代理的质量保障挑战，提出了基于ISO/IEC 25010的质量模型和SLA定义语言。


<details>
  <summary>Details</summary>
Motivation: AI代理作为智能软件系统的关键组件，其服务质量和SLA定义缺乏共识，导致质量保障困难。

Method: 基于ISO/IEC 25010标准构建质量模型，并设计领域特定语言用于SLA定义。

Result: 提出了AI代理的质量模型和SLA定义语言，为智能软件系统的质量保障提供了新方法。

Conclusion: 本文提出了基于ISO/IEC 25010标准的AI代理质量模型，以及支持定义AI代理服务SLA的领域特定语言，以解决AI组件质量保障的开放挑战。

Abstract: AI components are increasingly becoming a key element of all types of
software systems to enhance their functionality. These AI components are often
implemented as AI Agents, offering more autonomy than a plain integration of
Large Language Models (LLMs), moving from a Model-as-a-Service paradigm to an
Agent-as-a-Service one, bringing new challenges to the development of smart
software systems. Indeed, while support for the design, implementation, and
deployment of those agents exist, the specification of Quality of Service (QoS)
and definition of Service Level Agreements (SLAs) aspects for those agents,
important to ensure the quality of the resulting systems, remains an open
challenge. Part of this is due to the difficulty to clearly define quality in
the context of AI components, resulting in a lack of consensus on how to best
approach Quality Assurance (QA) for these types of systems. To address this
challenge, this paper proposes both a quality model for AI agents based on the
ISO/IEC 25010 standard, and a domain specific language to support the
definition of SLAs for the services provided by these AI agents.

</details>


### [84] [Comprehension-Performance Gap in GenAI-Assisted Brownfield Programming: A Replication and Extension](https://arxiv.org/abs/2511.02922)
*Yunhan Qiao,Christopher Hundhausen,Summit Haque,Md Istiak Hossain Shihab*

Main category: cs.SE

TL;DR: 生成式AI助手提升遗留代码任务效率，但未增强代码理解。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI编码助手在遗留代码编程任务中对性能和代码理解的影响。

Method: 在一项受试者内实验研究中，18名计算机科学研究生使用和不使用Copilot完成功能实现任务。

Result: Copilot显著减少了任务时间并增加了通过的测试用例数量，但理解分数在不同条件下无差异，揭示了理解与性能之间的差距。

Conclusion: 生成式AI工具如GitHub Copilot可以加速在遗留代码库中的编程进度，但可能不会提升对代码库的理解。

Abstract: Code comprehension is essential for brownfield programming tasks, in which
developers maintain and enhance legacy code bases. Generative AI (GenAI) coding
assistants such as GitHub Copilot have been shown to improve developer
productivity, but their impact on code understanding is less clear. We
replicate and extend a previous study by exploring both performance and
comprehension in GenAI-assisted brownfield programming tasks. In a
within-subjects experimental study, 18 computer science graduate students
completed feature implementation tasks with and without Copilot. Results show
that Copilot significantly reduced task time and increased the number of test
cases passed. However, comprehension scores did not differ across conditions,
revealing a comprehension-performance gap: participants passed more test cases
with Copilot, but did not demonstrate greater understanding of the legacy
codebase. Moreover, we failed to find a correlation between comprehension and
task performance. These findings suggest that while GenAI tools can accelerate
programming progress in a legacy codebase, such progress may come without an
improved understanding of that codebase. We consider the implications of these
findings for programming education and GenAI tool design.

</details>


### [85] [Risk Estimation in Differential Fuzzing via Extreme Value Theory](https://arxiv.org/abs/2511.02927)
*Rafael Baez,Alejandro Olivas,Nathan K. Diamond,Marcelo Frias,Yannic Noller,Saeid Tizpaz-Niari*

Main category: cs.SE

TL;DR: 极值理论（EVT）用于评估差分模糊测试遗漏漏洞的风险，实验证明其优于传统统计方法，并在Java库测试中节省资源。


<details>
  <summary>Details</summary>
Motivation: 差分模糊测试缺乏对未发现漏洞的风险评估，极值理论为分析极端差异提供了统计框架。

Method: 通过极值理论分析差分模糊测试的极端值分布，优化超参数，并与传统统计方法（如马尔可夫不等式、切比雪夫不等式和贝叶斯因子）进行对比。

Result: EVT在14.3%的情况下优于基线方法，64.2%情况下持平，并在实际测试中节省了数千万字节码执行。

Conclusion: 应用极值理论（EVT）可以显著提高差分模糊测试的风险评估能力，并在实际Java库中验证了其有效性和性能优势。

Abstract: Differential testing is a highly effective technique for automatically
detecting software bugs and vulnerabilities when the specifications involve an
analysis over multiple executions simultaneously. Differential fuzzing, in
particular, operates as a guided randomized search, aiming to find (similar)
inputs that lead to a maximum difference in software outputs or their
behaviors. However, fuzzing, as a dynamic analysis, lacks any guarantees on the
absence of bugs: from a differential fuzzing campaign that has observed no bugs
(or a minimal difference), what is the risk of observing a bug (or a larger
difference) if we run the fuzzer for one or more steps?
  This paper investigates the application of Extreme Value Theory (EVT) to
address the risk of missing or underestimating bugs in differential fuzzing.
The key observation is that differential fuzzing as a random process resembles
the maximum distribution of observed differences. Hence, EVT, a branch of
statistics dealing with extreme values, is an ideal framework to analyze the
tail of the differential fuzzing campaign to contain the risk. We perform
experiments on a set of real-world Java libraries and use differential fuzzing
to find information leaks via side channels in these libraries. We first
explore the feasibility of EVT for this task and the optimal hyperparameters
for EVT distributions. We then compare EVT-based extrapolation against baseline
statistical methods like Markov's as well as Chebyshev's inequalities, and the
Bayes factor. EVT-based extrapolations outperform the baseline techniques in
14.3% of cases and tie with the baseline in 64.2% of cases. Finally, we
evaluate the accuracy and performance gains of EVT-enabled differential fuzzing
in real-world Java libraries, where we reported an average saving of tens of
millions of bytecode executions by an early stop.

</details>


### [86] [Assurance Case Development for Evolving Software Product Lines: A Formal Approach](https://arxiv.org/abs/2511.03026)
*Logan Murphy,Torin Viger,Alessio Di Sandro,Aren A. Babikian,Marsha Chechik*

Main category: cs.SE

TL;DR: 本文提出了一种形式化的变体感知保证案例（AC）开发和回归分析方法，解决了软件产品线（SPLs）中大规模和演化带来的挑战，并通过案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在软件产品线（SPLs）中，为每个产品单独开发严格的保证案例（ACs）是不可行的，尤其是当SPL演化时，评估变化的影响也变得困难。因此，需要一种方法能够同时为整个SPL开发AC，并以变体感知的方式进行分析。

Method: 作者形式化了一种适用于SPLs的变体感知AC语言，研究了基于模板的AC开发方法，并定义了回归分析以评估SPL演化对AC的影响。此外，还实现了一个基于模型的保证管理工具。

Result: 通过提出的方法，成功开发了一个用于医疗设备产品线的AC，验证了技术的可行性和有效性。

Conclusion: 本文提出了一种形式化的方法来开发和维护软件产品线（SPLs）的结构化保证案例（ACs），通过变体感知的方式实现整体AC的开发和回归分析，有效解决了SPLs大规模及演化带来的挑战。

Abstract: In critical software engineering, structured assurance cases (ACs) are used
to demonstrate how key system properties are supported by evidence (e.g., test
results, proofs). Creating rigorous ACs is particularly challenging in the
context of software product lines (SPLs), i.e, sets of software products with
overlapping but distinct features and behaviours. Since SPLs can encompass very
large numbers of products, developing a rigorous AC for each product
individually is infeasible. Moreover, if the SPL evolves, e.g., by the
modification or introduction of features, it can be infeasible to assess the
impact of this change. Instead, the development and maintenance of ACs ought to
be lifted such that a single AC can be developed for the entire SPL
simultaneously, and be analyzed for regression in a variability-aware fashion.
In this article, we describe a formal approach to lifted AC development and
regression analysis. We formalize a language of variability-aware ACs for SPLs
and study the lifting of template-based AC development. We also define a
regression analysis to determine the effects of SPL evolutions on
variability-aware ACs. We describe a model-based assurance management tool
which implements these techniques, and illustrate our contributions by
developing an AC for a product line of medical devices.

</details>


### [87] [Adaptive Detection of Software Aging under Workload Shift](https://arxiv.org/abs/2511.03103)
*Rafael José Moura,Maria Gizele Nascimento,Fumio Machida,Ermeson Andrade*

Main category: cs.SE

TL;DR: 研究提出基于机器学习的自适应方法（DDM和ADWIN）用于动态工作负载下的软件老化检测，实验证明ADWIN模型在各类工作负载变化中表现最优（F1-Score>0.93）。


<details>
  <summary>Details</summary>
Motivation: 软件老化现象会导致长期运行的系统性能逐渐下降并增加故障风险。针对动态工作负载条件下静态模型性能下降的问题，本研究旨在探索自适应方法的有效性。

Method: 本研究提出了一种基于机器学习的自适应方法，用于动态工作负载环境下的软件老化检测。具体采用了两种自适应检测器：漂移检测方法（DDM）和自适应窗口（ADWIN），并将其与静态模型进行比较。

Result: 实验结果表明，静态模型在面对未知工作负载时性能显著下降，而结合ADWIN的自适应模型在所有测试场景中均保持高准确率（F1-Score>0.93）。

Conclusion: 本研究通过对比静态模型与自适应模型（尤其是结合了ADWIN的自适应模型）在动态工作负载条件下的表现，验证了自适应方法在软件老化检测中的优越性，尤其是在处理突发、渐变和重复工作负载变化时，ADWIN模型能保持高准确率（F1-Score>0.93）。

Abstract: Software aging is a phenomenon that affects long-running systems, leading to
progressive performance degradation and increasing the risk of failures. To
mitigate this problem, this work proposes an adaptive approach based on machine
learning for software aging detection in environments subject to dynamic
workload conditions. We evaluate and compare a static model with adaptive
models that incorporate adaptive detectors, specifically the Drift Detection
Method (DDM) and Adaptive Windowing (ADWIN), originally developed for concept
drift scenarios and applied in this work to handle workload shifts. Experiments
with simulated sudden, gradual, and recurring workload transitions show that
static models suffer a notable performance drop when applied to unseen workload
profiles, whereas the adaptive model with ADWIN maintains high accuracy,
achieving an F1-Score above 0.93 in all analyzed scenarios.

</details>


### [88] [Automated Prompt Generation for Code Intelligence: An Empirical study and Experience in WeChat](https://arxiv.org/abs/2511.03136)
*Kexing Ji,Shiyun Fu,Cuiyun Gao,Yujia Chen,Zezhou Yang,Chaozheng Wang,Yuetang Deng*

Main category: cs.SE

TL;DR: 论文研究了自动化提示生成（APG）对大型代码模型（LCMs）性能的影响，提出结合指令生成和多步推理的新方法，显著提升了多项代码智能任务的性能。


<details>
  <summary>Details</summary>
Motivation: 当前提示设计主要依赖手动，耗时且受限于特定LCMs和任务，而自动化提示生成（APG）在代码智能领域尚未充分探索。

Method: 实证研究了指令生成（IG）和多步推理（MSR）两部分，评估了多种APG方法，并提出了结合两者最佳方法的新APG方法。

Result: 新APG方法在代码翻译、代码摘要和API推荐任务中分别实现了28.38%、58.11%和84.53%的平均性能提升，在工业场景中也验证了其有效性。

Conclusion: 论文提出了一种结合指令生成（IG）和多步推理（MSR）的自动化提示生成（APG）方法，显著提升了大型代码模型（LCMs）在代码翻译、代码摘要和API推荐任务中的性能。

Abstract: Large Code Models (LCMs) show potential in code intelligence, but their
effectiveness is greatly influenced by prompt quality. Current prompt design is
mostly manual, which is time-consuming and highly dependent on specific LCMs
and tasks. While automated prompt generation (APG) exists in NLP, it is
underexplored for code intelligence. This creates a gap, as automating the
prompt process is essential for developers facing diverse tasks and black-box
LCMs.
  To mitigate this, we empirically investigate two important parts of APG:
Instruction Generation (IG) and Multi-Step Reasoning (MSR). IG provides a
task-related description to instruct LCMs, while MSR guides them to produce
logical steps before the final answer. We evaluate widely-used APG methods for
each part on four open-source LCMs and three code intelligence tasks: code
translation (PL-PL), code summarization (PL-NL), and API recommendation
(NL-PL).Experimental results indicate that both IG and MSR dramatically enhance
performance compared to basic prompts. Based on these results, we propose a
novel APG approach combining the best methods of the two parts. Experiments
show our approach achieves average improvements of 28.38% in CodeBLEU (code
translation), 58.11% in ROUGE-L (code summarization), and 84.53% in
SuccessRate@1 (API recommendation) over basic prompts. To validate its
effectiveness in an industrial scenario, we evaluate our approach on
WeChat-Bench, a proprietary dataset, achieving an average MRR improvement of
148.89% for API recommendation.

</details>


### [89] [RefAgent: A Multi-agent LLM-based Framework for Automatic Software Refactoring](https://arxiv.org/abs/2511.03153)
*Khouloud Oueslati,Maxime Lamothe,Foutse Khomh*

Main category: cs.SE

TL;DR: RefAgent是一个多代理LLM框架，显著提升软件重构的质量和效率，优于单代理方法和传统工具。


<details>
  <summary>Details</summary>
Motivation: 传统LLM在软件重构中依赖静态指令，无法动态适应上下文。LLM代理能通过工具交互和自主决策提升灵活性。

Method: 提出RefAgent，一个基于多代理LLM的端到端软件重构框架，包含规划、执行、测试和迭代优化的专门代理。

Result: RefAgent在8个开源Java项目中测试，单元测试通过率中位数达90%，代码异味减少52.5%，关键质量属性提升8.6%，且识别重构机会的F1分数中位数分别为79.15%和72.7%。

Conclusion: 多代理LLM架构在自动化软件重构中展现出巨大潜力，RefAgent通过规划、执行、测试和迭代优化，显著提升了代码质量和开发效率。

Abstract: Large Language Models (LLMs) have substantially influenced various software
engineering tasks. Indeed, in the case of software refactoring, traditional
LLMs have shown the ability to reduce development time and enhance code
quality. However, these LLMs often rely on static, detailed instructions for
specific tasks. In contrast, LLM-based agents can dynamically adapt to evolving
contexts and autonomously make decisions by interacting with software tools and
executing workflows. In this paper, we explore the potential of LLM-based
agents in supporting refactoring activities. Specifically, we introduce
RefAgent, a multi-agent LLM-based framework for end-to-end software
refactoring. RefAgent consists of specialized agents responsible for planning,
executing, testing, and iteratively refining refactorings using self-reflection
and tool-calling capabilities. We evaluate RefAgent on eight open-source Java
projects, comparing its effectiveness against a single-agent approach, a
search-based refactoring tool, and historical developer refactorings. Our
assessment focuses on: (1) the impact of generated refactorings on software
quality, (2) the ability to identify refactoring opportunities, and (3) the
contribution of each LLM agent through an ablation study. Our results show that
RefAgent achieves a median unit test pass rate of 90%, reduces code smells by a
median of 52.5%, and improves key quality attributes (e.g., reusability) by a
median of 8.6%. Additionally, it closely aligns with developer refactorings and
the search-based tool in identifying refactoring opportunities, attaining a
median F1-score of 79.15% and 72.7%, respectively. Compared to single-agent
approaches, RefAgent improves the median unit test pass rate by 64.7% and the
median compilation success rate by 40.1%. These findings highlight the promise
of multi-agent architectures in advancing automated software refactoring.

</details>


### [90] [Understanding Robustness of Model Editing in Code LLMs: An Empirical Study](https://arxiv.org/abs/2511.03182)
*Vinaik Chhetri,A. B Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: 研究发现模型编辑在API废弃场景下性能显著下降，正确适应性修改仅占6%，表明当前编辑方法仍需改进。


<details>
  <summary>Details</summary>
Motivation: 由于编程语言和API的持续演变，静态的LLMs生成的代码可能已过时或不兼容，而从头训练LLMs计算成本高昂，因此研究模型编辑是否能够实现真正的语法和语义适应。

Method: 本研究系统地评估了五种最先进的模型编辑方法（Constrained Fine-Tuning、GRACE、MEMIT、PMET和ROME），应用于三个开源代码LLMs（CodeLlama、CodeQwen1.5和DeepSeek-Coder），并在受控的API废弃场景下进行了测试。

Result: 研究发现即时编辑导致语法有效性下降高达86个百分点，功能正确性下降45个百分点；顺序编辑进一步加剧了性能下降，且大多数通过的生成依赖于变通方法而非正确采纳变更。

Conclusion: 尽管模型编辑提供了一种轻量级的替代方案来更新LLMs，但研究发现即时编辑和顺序编辑均显著降低了模型的性能，且正确的适应性修改仅占约6%。

Abstract: Large language models (LLMs) are increasingly used in software development.
However, while LLMs remain static after pretraining, programming languages and
APIs continue to evolve, leading to the generation of deprecated or
incompatible code that undermines reliability. Retraining LLMs from scratch to
reflect such changes is computationally expensive, making model editing a
promising lightweight alternative that updates only a small subset of
parameters. Despite its potential, it remains unclear whether model editing
yields genuine syntactic and semantic adaptations or merely superficial fixes.
In this work, we present a systematic study of five state-of-the-art model
editing methods: Constrained Fine-Tuning (FT), GRACE, MEMIT, PMET, and ROME. We
apply these methods to three leading open-source code LLMs, CodeLlama,
CodeQwen1.5, and DeepSeek-Coder, under controlled API deprecation scenarios.
Our evaluation covers both instant and sequential editing settings, using three
disjoint evaluation sets designed to assess reliability, generalization, and
specificity. We measure model correctness at three levels: successful
compilation, partial test case pass, and full test pass. Our findings show that
instant edits consistently degrade model performance, with syntactic validity
dropping by up to 86 percentage points and functional correctness declining by
45 points even in the best-performing setting. Sequential edits further amplify
this degradation, and in some cases, model performance collapses entirely.
Across all models, most passing generations relied on workarounds rather than
correctly adopting the intended changes, while faulty adoptions that result in
test failures or compilation errors were significantly more frequent. Correct
adoptions, where the model correctly integrates the intended change, occurred
in only about 6% of cases.

</details>


### [91] [Towards Realistic Project-Level Code Generation via Multi-Agent Collaboration and Semantic Architecture Modeling](https://arxiv.org/abs/2511.03404)
*Qianhui Zhao,Li Zhang,Fang Liu,Junhang Cheng,Chengru Wu,Junchen Ai,Qiaoyuanhe Meng,Lichen Zhang,Xiaoli Lian,Shubin Song,Yuanping Guo*

Main category: cs.SE

TL;DR: 论文提出ProjectGen多智能体框架和CodeProjectEval数据集，显著提升项目级代码生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在项目级代码生成中存在数据集不真实、评估指标不可靠、语义鸿沟和依赖管理困难等问题，需改进以应对实际需求。

Method: 引入CodeProjectEval数据集，并提出ProjectGen多智能体框架，包括架构设计、骨架生成和代码填充三个阶段，采用迭代优化和基于记忆的上下文管理。

Result: ProjectGen在DevBench和CodeProjectEval数据集上分别取得57%和约十倍的性能提升。

Conclusion: ProjectGen通过多智能体框架和SSAT结构，显著提升了项目级代码生成的性能，为实际软件开发提供了有效工具。

Abstract: In recent years, Large Language Models (LLMs) have achieved remarkable
progress in automated code generation. In real-world software engineering, the
growing demand for rapid iteration and continuous delivery underscores the
importance of project-level code generation, where LLMs are expected to
generate complete software projects directly from complex user requirements.
Although existing studies have made initial explorations, they still face key
limitations, including unrealistic datasets and unreliable evaluation metrics
that fail to reflect real-world complexity, the semantic gap between
human-written requirements and machine-interpretable structures, and
difficulties in managing hierarchical dependencies and maintaining quality
throughout the generation process. To address these limitations, we first
introduce CodeProjectEval, a project-level code generation dataset built from
18 real-world repositories with 12.7 files and 2,388.6 lines of code per task
on average, supplemented with documentation and executable test cases for
automatic evaluation. We further propose ProjectGen, a multi-agent framework
that decomposes projects into architecture design, skeleton generation, and
code filling stages with iterative refinement and memory-based context
management. Within this framework, we introduce the Semantic Software
Architecture Tree (SSAT), a structured and semantically rich representation
that effectively bridges user requirements and source code implementation.
Experiments show that ProjectGen achieves state-of-the-art performance, passing
52/124 test cases on the small-scale project-level code generation dataset
DevBench, a 57% improvement over the baseline approaches, and 310 test cases on
CodeProjectEval, representing an improvement of roughly tenfold compared to the
baselines.

</details>


### [92] [Light over Heavy: Automated Performance Requirements Quantification with Linguistic Inducement](https://arxiv.org/abs/2511.03421)
*Shihai Wang,Tao Chen*

Main category: cs.SE

TL;DR: LQPR is an efficient automatic approach for quantifying performance requirements, using a lightweight classification method that outperforms general LLM-driven approaches with lower cost.


<details>
  <summary>Details</summary>
Motivation: Manual quantification of performance requirements is expensive and error-prone, necessitating an automatic and efficient solution.

Method: LQPR employs a lightweight linguistically induced matching mechanism to classify performance requirements, leveraging their strong patterns and concise nature.

Result: LQPR outperforms nine state-of-the-art learning-based methods, ranking as the best in 75% or more cases with significantly lower cost.

Conclusion: LQPR proves that specialized methods can outperform general LLM-driven approaches for performance requirement quantification, offering higher efficiency and lower cost.

Abstract: Elicited performance requirements need to be quantified for compliance in
different engineering tasks, e.g., configuration tuning and performance
testing. Much existing work has relied on manual quantification, which is
expensive and error-prone due to the imprecision. In this paper, we present
LQPR, a highly efficient automatic approach for performance requirements
quantification.LQPR relies on a new theoretical framework that converts
quantification as a classification problem. Despite the prevalent applications
of Large Language Models (LLMs) for requirement analytics, LQPR takes a
different perspective to address the classification: we observed that
performance requirements can exhibit strong patterns and are often
short/concise, therefore we design a lightweight linguistically induced
matching mechanism. We compare LQPR against nine state-of-the-art
learning-based approaches over diverse datasets, demonstrating that it is
ranked as the sole best for 75% or more cases with two orders less cost. Our
work proves that, at least for performance requirement quantification,
specialized methods can be more suitable than the general LLM-driven
approaches.

</details>


### [93] [U2F: Encouraging SWE-Agent to Seize Novelty without Losing Feasibility](https://arxiv.org/abs/2511.03517)
*Wencheng Ye,Yan Liu*

Main category: cs.SE

TL;DR: U2F是一个拥抱不确定性的多代理框架，通过认知增强机制发现创新解决方案，显著提升软件工程任务的新颖性和可行性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-based SWE-Agent主要解决定义明确的问题，忽视了开放世界软件环境中超越既定范式的新兴挑战。

Method: U2F由发现-探索-整合代理系统和三个认知增强机制（跨领域类比推理、逆向思维和外部验证）组成。

Result: 在218个真实软件工程案例中，U2F提升了14%的整体新颖性、51%的语义新颖性，并保持了稳定的可行性（4.02/5.0）。

Conclusion: U2F框架通过拥抱不确定性，展示了在软件工程中作为创新催化剂的潜力，显著提升了解决方案的新颖性和可行性。

Abstract: Large language models (LLMs) have shown strong capabilities in software
engineering tasks, yet most existing LLM-based SWE-Agents mainly tackle
well-defined problems using conventional methods, often overlooking alternative
or innovative solutions beyond their predefined frameworks. This limitation is
evident in open-world software environments, where emerging challenges
transcend established paradigms.
  We propose U2F (Unknown Unknowns to Functional solutions), a
cognitive-inspired, uncertainty-embracing multi-agent framework that
systematically surfaces "Unknown Unknowns" - novel solution pathways absent
from initial formulations but holding innovative potential. U2F consists of two
key components: (1) a Discovery-Exploration-Integration agent system for
uncovering and synthesizing potential solutions, and (2) cognitive enhancement
mechanisms across three dimensions: cross-domain analogical reasoning, reverse
thinking, and external validation, which strategically reframe and extend
conventional solution boundaries.
  Applied to 218 real-world software enabler stories curated from authentic
engineering tasks, U2F achieved notable improvements: human experts reported a
14 percent increase in overall novelty, 51 percent improvement in semantic
novelty, and stable feasibility (4.02/5.0), corroborated by an LLM-based
evaluator. These results highlight the potential of embracing uncertainty as a
catalyst for innovation in software engineering.

</details>


### [94] [Uncovering Code Insights: Leveraging GitHub Artifacts for Deeper Code Understanding](https://arxiv.org/abs/2511.03549)
*Ziv Nevo,Orna Raz,Karen Yorav*

Main category: cs.SE

TL;DR: 通过整合GitHub上下文，提升LLM代码解释的实用性和准确性，用户验证有效。


<details>
  <summary>Details</summary>
Motivation: 源代码理解的不足影响软件维护和现代化，LLM生成的解释缺乏软件工程上下文。

Method: 系统包含三个组件：提取并结构化GitHub上下文、利用上下文生成高级代码解释、验证解释。实现为独立工具及MCP服务器。

Result: 用户研究表明，生成的解释通常有帮助且非琐碎，且无幻觉。

Conclusion: 该系统通过整合GitHub的自然语言资源，提升了基于LLM的代码理解能力，生成的解释既实用又准确，且避免了幻觉问题。

Abstract: Understanding the purpose of source code is a critical task in software
maintenance, onboarding, and modernization. While large language models (LLMs)
have shown promise in generating code explanations, they often lack grounding
in the broader software engineering context. We propose a novel approach that
leverages natural language artifacts from GitHub -- such as pull request
descriptions, issue descriptions and discussions, and commit messages -- to
enhance LLM-based code understanding. Our system consists of three components:
one that extracts and structures relevant GitHub context, another that uses
this context to generate high-level explanations of the code's purpose, and a
third that validates the explanation. We implemented this as a standalone tool,
as well as a server within the Model Context Protocol (MCP), enabling
integration with other AI-assisted development tools. Our main use case is that
of enhancing a standard LLM-based code explanation with code insights that our
system generates. To evaluate explanations' quality, we conducted a small scale
user study, with developers of several open projects, as well as developers of
proprietary projects. Our user study indicates that when insights are generated
they often are helpful and non trivial, and are free from hallucinations.

</details>


### [95] [The OpenHands Software Agent SDK: A Composable and Extensible Foundation for Production Agents](https://arxiv.org/abs/2511.03690)
*Xingyao Wang,Simon Rosenberg,Juan Michelini,Calvin Smith,Hoang Tran,Engel Nyst,Rohit Malhotra,Xuhui Zhou,Valerie Chen,Robert Brennan,Graham Neubig*

Main category: cs.SE

TL;DR: OpenHands Software Agent SDK是一个灵活、安全、用户友好的工具包，支持快速开发和部署软件工程代理，性能优异。


<details>
  <summary>Details</summary>
Motivation: 构建生产级软件工程代理复杂，需实现灵活性、可靠性和用户交互接口。

Method: 通过重新设计代理组件，提供简洁的默认接口（仅需少量代码），同时支持扩展复杂功能（如自定义工具、内存管理等）。

Result: 在SWE-Bench Verified和GAIA基准测试中表现优异，集成沙箱执行、生命周期控制、多模型路由和安全分析。

Conclusion: OpenHands Software Agent SDK提供了一个实用的基础，支持快速原型设计、解锁新型自定义应用，并能可靠地大规模部署代理。

Abstract: Agents are now used widely in the process of software development, but
building production-ready software engineering agents is a complex task.
Deploying software agents effectively requires flexibility in implementation
and experimentation, reliable and secure execution, and interfaces for users to
interact with agents. In this paper, we present the OpenHands Software Agent
SDK, a toolkit for implementing software development agents that satisfy these
desiderata. This toolkit is a complete architectural redesign of the agent
components of the popular OpenHands framework for software development agents,
which has 64k+ GitHub stars. To achieve flexibility, we design a simple
interface for implementing agents that requires only a few lines of code in the
default case, but is easily extensible to more complex, full-featured agents
with features such as custom tools, memory management, and more. For security
and reliability, it delivers seamless local-to-remote execution portability,
integrated REST/WebSocket services. For interaction with human users, it can
connect directly to a variety of interfaces, such as visual workspaces (VS
Code, VNC, browser), command-line interfaces, and APIs. Compared with existing
SDKs from OpenAI, Claude, and Google, OpenHands uniquely integrates native
sandboxed execution, lifecycle control, model-agnostic multi-LLM routing, and
built-in security analysis. Empirical results on SWE-Bench Verified and GAIA
benchmarks demonstrate strong performance. Put together, these elements allow
the OpenHands Software Agent SDK to provide a practical foundation for
prototyping, unlocking new classes of custom applications, and reliably
deploying agents at scale.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [96] [DecodeX: Exploring and Benchmarking of LDPC Decoding across CPU, GPU, and ASIC Platforms](https://arxiv.org/abs/2511.02952)
*Zhenzhou Qi,Yuncheng Yao,Yiming Li,Chung-Hsuan Tung,Junyao Zheng,Danyang Zhuo,Tingjun Chen*

Main category: cs.NI

TL;DR: DecodeX是一个统一的基准测试框架，用于评估不同硬件平台上的LDPC解码加速，揭示了并行效率和卸载开销之间的权衡，为未来异构vRAN的自适应调度和协同设计提供了参考。


<details>
  <summary>Details</summary>
Motivation: 虚拟化无线接入网络（vRANs）需要在异构计算基板上实现灵活高效的基带处理，因此需要一个统一的基准测试框架来评估不同硬件平台上的低密度奇偶校验（LDPC）解码加速。

Method: DecodeX集成了包括CPU（FlexRAN）、GPU（Aerial和Sionna-RK）和ASIC（ACC100）在内的多种硬件平台的LDPC解码器实现，并可以轻松扩展到其他架构和配置。

Result: 研究揭示了并行效率和卸载开销之间的明显权衡，表明加速器的增益强烈依赖于数据移动和工作负载粒度。

Conclusion: DecodeX的跨平台基准测试可以为未来异构vRAN的自适应调度和协同设计提供参考，支持下一代无线系统的可扩展和高效能基带处理。

Abstract: Emerging virtualized radio access networks (vRANs) demand flexible and
efficient baseband processing across heterogeneous compute substrates. In this
paper, we present DecodeX, a unified benchmarking framework for evaluating
low-density parity-check (LDPC) decoding acceleration across different hardware
platforms. DecodeX integrates a comprehensive suite of LDPC decoder
implementations, including kernels, APIs, and test vectors for CPUs (FlexRAN),
GPUs (Aerial and Sionna-RK), and ASIC (ACC100), and can be readily extended to
additional architectures and configurations. Using DecodeX, we systematically
characterize how different platforms orchestrate computation-from threading and
memory management to data movement and accelerator offload-and quantify the
resulting decoding latency under varying Physical layer parameters. Our
observations reveal distinct trade-offs in parallel efficiency and offload
overhead, showing that accelerator gains strongly depend on data-movement and
workload granularity. Building on these insights, we discuss how cross-platform
benchmarking can inform adaptive scheduling and co-design for future
heterogeneous vRANs, enabling scalable and energy-efficient baseband processing
for NextG wireless systems.

</details>


### [97] [Distributed Incast Detection in Data Center Networks](https://arxiv.org/abs/2511.03039)
*Yiming Zheng,Haoran Qi,Lirui Yu,Zhan Shu,Qing Zhao*

Main category: cs.NI

TL;DR: 论文提出了一种新的分布式拥塞检测方法，利用概率假设测试和最优阈值，显著提升了检测速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 数据中心内的拥塞流量会导致严重的性能下降，如丢包和延迟增加。现有的解决方案通常依赖于固定的交换机端口出口队列长度或其梯度阈值，这些方法存在检测延迟和错误率高的问题。

Method: 通过分析新流的到达间隔，算法能够从初始数据包立即判断流量是否属于拥塞流量。

Result: 实验结果表明，该方法在检测速度和推理准确性上均显著优于现有方法。

Conclusion: 论文提出了一种基于概率假设测试和最优检测阈值的分布式数据中心网络交换级拥塞检测方法，显著提升了检测速度和准确性。

Abstract: Incast traffic in data centers can lead to severe performance degradation,
such as packet loss and increased latency. Effectively addressing incast
requires prompt and accurate detection. Existing solutions, including MA-ECN,
BurstRadar and Pulser, typically rely on fixed thresholds of switch port egress
queue lengths or their gradients to identify microburst caused by incast flows.
However, these queue length related methods often suffer from delayed detection
and high error rates. In this study, we propose a distributed incast detection
method for data center networks at the switch-level, leveraging a probabilistic
hypothesis test with an optimal detection threshold. By analyzing the arrival
intervals of new flows, our algorithm can immediately determine if a flow is
part of an incast traffic from its initial packet. The experimental results
demonstrate that our method offers significant improvements over existing
approaches in both detection speed and inference accuracy.

</details>


### [98] [CRSF: Enabling QoS-Aware Beyond-Connectivity Service Sharing in 6G Local Networks](https://arxiv.org/abs/2511.03081)
*Pragya Sharma,Amanda Xiang,Abbas Kiani,John Kaippallimalil,Tony Saboorian,Haining Wang*

Main category: cs.NI

TL;DR: 本文提出CRSF，一种新型6G核心网络功能，用于高效跨子网络服务发现和选择，通过QoS优化提升服务性能。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要支持共享超越连接服务的互联子网络，但目前缺乏跨网络边界发现和选择这些服务的标准化架构。

Method: 通过将选择过程建模为一个QoS感知的优化问题，平衡服务质量指标与用户定义的优先级。

Result: 在感知服务场景的模拟中，与基线选择策略相比，CRSF显示出持续更高的聚合服务质量（QoS）。

Conclusion: 论文提出的CRSF为6G时代构建标准化、协作性和以服务为中心的互联网络提供了基础且可扩展的机制。

Abstract: Sixth-generation (6G) networks are envisioned to support interconnected local
subnetworks that can share specialized, beyond-connectivity services. However,
a standardized architecture for discovering and selecting these services across
network boundaries has not existed yet. To address this gap, this paper
introduces the Central Repository and Selection Function (CRSF), a novel
network function for the 6G core that facilitates efficient inter-subnetwork
service discovery and selection. We formulate the selection process as a
QoS-aware optimization problem designed to balance service quality metrics with
user-defined priorities. We evaluate our system model through simulations for a
sensing service scenario and observe a consistently higher aggregate Quality of
Service (QoS) compared to the baseline selection strategy. The proposed CRSF
provides a foundational and extensible mechanism for building standardized,
collaborative, and service-centric interconnected networks essential for the 6G
era.

</details>


### [99] [Handover Configurations in Operational 5G Networks: Diversity, Evolution, and Impact on Performance](https://arxiv.org/abs/2511.03116)
*Moinak Ghoshal,Imran Khan,Phuc Dinh,Z. Jonny Kong,Omar Basit,Sizhe Wang,Yufei Feng,Y. Charlie Hu,Dimitrios Koutsonikolas*

Main category: cs.NI

TL;DR: 研究发现5G切换配置存在高信令开销、参数多样性及性能问题，对运营商优化配置具有指导意义。


<details>
  <summary>Details</summary>
Motivation: 5G大规模部署与4G/5G共存使切换过程复杂化，但现有研究对5G操作网络中切换的成因、方式及配置影响知之甚少。

Method: 通过在美国三个主要运营商网络中进行为期27个月的跨州驾驶测量研究，深入分析了切换配置。

Result: 研究揭示了(a)新型切换及事件、(b)激进配置导致高信令开销、(c)参数值多样性大但5G低于LTE、(d)次优配置导致性能问题。

Conclusion: 该研究发现移动运营商在5G切换配置中存在多种问题，如过于激进的配置导致高信令开销、参数值多样性大以及次优配置导致性能不佳，对运营商优化5G切换配置具有重要指导意义。

Abstract: Mobility management in cellular networks, especially the handover (HO)
process, plays a key role in providing seamless and ubiquitous Internet access.
The wide-scale deployment of 5G and the resulting co-existence of 4G/5G in the
past six years have significantly changed the landscape of all mobile network
operators and made the HO process much more complex than before. While several
recent works have studied the impact of HOs on user experience, why and how HOs
occur and how HO configurations affect performance in 5G operational networks
remains largely unknown. Through four cross-country driving trips across the US
spread out over a 27-month period, we conduct an in-depth measurement study of
HO configurations across all three major US operators. Our study reveals (a)
new types of HOs and new HO events used by operators to handle these new types
of HOs, (b) overly aggressive HO configurations that result in unnecessarily
high signaling overhead, (c) large diversity in HO configuration parameter
values, which also differ across operators, but significantly lower diversity
in 5G compared to LTE, and (d) sub-optimal HO configurations/decisions leading
to poor pre- or post-HO performance. Our findings have many implications for
mobile operators, as they keep fine-tuning their 5G HO configurations.

</details>


### [100] [Joint Optimization of DNN Model Caching and Request Routing in Mobile Edge Computing](https://arxiv.org/abs/2511.03159)
*Shuting Qiu,Fang Dong,Siyu Tan,Ruiting Zhou,Dian Shen,Patrick P. C. Lee,Qilin Fan*

Main category: cs.NI

TL;DR: 动态DNN模型在边缘计算中通过CoCaR和CoCaR-OL算法优化缓存和路由，显著提升推理精度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算（MEC）中缓存所有DNN模型困难，且模型加载时间对用户体验（QoE）的影响尚未充分探索。

Method: 提出了基于线性规划和随机舍入的离线算法CoCaR，以及其在线变体CoCaR-OL，以优化缓存和路由方案。

Result: CoCaR将用户请求的平均推理精度提升了46%，CoCaR-OL在在线场景中用户QoE提升不低于32.3%。

Conclusion: CoCaR和CoCaR-OL算法在动态DNN模型缓存和请求路由问题上表现出色，显著提升了用户请求的推理精度和QoE。

Abstract: Mobile edge computing (MEC) can pre-cache deep neural networks (DNNs) near
end-users, providing low-latency services and improving users' quality of
experience (QoE). However, caching all DNN models at edge servers with limited
capacity is difficult, and the impact of model loading time on QoE remains
underexplored. Hence, we introduce dynamic DNNs in edge scenarios,
disassembling a complete DNN model into interrelated submodels for more
fine-grained and flexible model caching and request routing solutions. This
raises the pressing issue of jointly deciding request routing and submodel
caching for dynamic DNNs to balance model inference precision and loading
latency for QoE optimization. In this paper, we study the joint dynamic model
caching and request routing problem in MEC networks, aiming to maximize user
request inference precision under constraints of server resources, latency, and
model loading time. To tackle this problem, we propose CoCaR, an offline
algorithm based on linear programming and random rounding that leverages
dynamic DNNs to optimize caching and routing schemes, achieving near-optimal
performance. Furthermore, we develop an online variant of CoCaR, named
CoCaR-OL, enabling effective adaptation to dynamic and unpredictable online
request patterns. The simulation results demonstrate that the proposed CoCaR
improves the average inference precision of user requests by 46\% compared to
state-of-the-art baselines. In addition, in online scenarios, CoCaR-OL achieves
an improvement of no less than 32.3\% in user QoE over competitive baselines.

</details>


### [101] [Integrity Under Siege: A Rogue gNodeB's Manipulation of 5G Network Slice Allocation](https://arxiv.org/abs/2511.03312)
*Jiali Xu,Valeria Loscri,Romain Rouvoy*

Main category: cs.NI

TL;DR: 论文揭示了5G网络切片分配中的完整性漏洞，通过实验展示了其严重影响，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究5G网络切片分配中的未充分探索的完整性漏洞，及其对服务质量和资源完整性的潜在危害。

Method: 通过5G测试床上的综合实验评估，展示了攻击的多样性和严重性，包括服务质量降级和系统性资源污染攻击。

Result: 实验结果显示攻击可导致带宽减少95%、延迟增加150%，或引发隐性切片操纵，甚至导致核心网络用户平面功能的CPU饱和达到80%。

Conclusion: 该论文强调了5G网络切片技术中的完整性漏洞，并提出了跨层缓解策略，突出了保护动态资源管理的紧迫性。

Abstract: The advent of 5G networks, with network slicing as a cornerstone technology,
promises customized, high-performance services, but also introduces novel
attack surfaces beyond traditional threats. This article investigates a
critical and underexplored integrity vulnerability: the manipulation of network
slice allocation to compromise Quality of Service (QoS) and resource integrity.
We introduce a threat model, grounded in a risk analysis of permissible yet
insecure configurations like null-ciphering (5G-EA0), demonstrating how a rogue
gNodeB acting as a Man-in-the-Middle can exploit protocol weaknesses to forge
slice requests and hijack a User Equipment's (UE) connection. Through a
comprehensive experimental evaluation on a 5G testbed, we demonstrate the
attack's versatile and severe impacts. Our findings show this integrity breach
can manifest as obvious QoS degradation, such as a 95% bandwidth reduction and
150% latency increase when forcing UE to a suboptimal slice, or as stealthy
slice manipulation that is indistinguishable from benign network operation and
generates no core network errors. Furthermore, we validate a systemic resource
contamination attack where redirecting a crowd of UE orchestrates a
Denial-of-Service, causing packet loss to exceed 60% and inducing measurable
CPU saturation (~80%) on core network User Plane Functions (UPFs). Based on
these results, we discuss the profound implications for Service Level
Agreements (SLAs) and critical infrastructure. We propose concrete, cross-layer
mitigation strategies for network operators as future work, underscoring the
urgent need to secure the integrity of dynamic resource management in 5G
networks.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [102] [Scheduling the Off-Diagonal Weingarten Loss of Neural SDFs for CAD Models](https://arxiv.org/abs/2511.03147)
*Haotian Yin,Przemyslaw Musialski*

Main category: cs.GR

TL;DR: 提出了ODW损失的权重调度策略，通过动态调整正则化强度优化CAD重建，实验证明优于固定权重方法。


<details>
  <summary>Details</summary>
Motivation: FlatCAD中固定ODW权重在训练过程中不够灵活，早期需要强正则化稳定优化，后期需减弱以恢复细节。

Method: 研究了常数、线性、五次和步进插值调度策略，以及递增的预热变体，应用于ODW损失的权重调度。

Result: 在ABC CAD数据集上的实验表明，时变调度策略始终优于固定权重，Chamfer Distance提升最高达35%。

Conclusion: 通过实验验证，时变调度策略在CAD重建中显著优于固定权重方法，Chamfer Distance提升达35%，证明了调度策略作为曲率正则化的简单有效扩展。

Abstract: Neural signed distance functions (SDFs) have become a powerful representation
for geometric reconstruction from point clouds, yet they often require both
gradient- and curvature-based regularization to suppress spurious warp and
preserve structural fidelity. FlatCAD introduced the Off-Diagonal Weingarten
(ODW) loss as an efficient second-order prior for CAD surfaces, approximating
full-Hessian regularization at roughly half the computational cost. However,
FlatCAD applies a fixed ODW weight throughout training, which is suboptimal:
strong regularization stabilizes early optimization but suppresses detail
recovery in later stages. We present scheduling strategies for the ODW loss
that assign a high initial weight to stabilize optimization and progressively
decay it to permit fine-scale refinement. We investigate constant, linear,
quintic, and step interpolation schedules, as well as an increasing warm-up
variant. Experiments on the ABC CAD dataset demonstrate that time-varying
schedules consistently outperform fixed weights. Our method achieves up to a
35% improvement in Chamfer Distance over the FlatCAD baseline, establishing
scheduling as a simple yet effective extension of curvature regularization for
robust CAD reconstruction.

</details>


### [103] [Visualization Biases MLLM's Decision Making in Network Data Tasks](https://arxiv.org/abs/2511.03617)
*Timo Brand,Henry Förster,Stephen G. Kobourov,Jacob Miller*

Main category: cs.GR

TL;DR: 摘要：可视化能提高MLLM判断桥梁存在与否的自信度，但会引入偏见，需谨慎使用以防幻觉。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究可视化技术对MLLM判断的潜在影响，特别是在网络分析中桥梁存在与否的判断上。

Method: 研究方法包括评估可视化如何影响MLLM对网络中桥梁存在与否的判断，并比较结构化文本输入与可视化输入的效果。

Result: 结果显示，可视化提高了MLLM的自信度，但也引入了对桥梁存在与否的强烈偏见，无论桥梁实际是否存在。

Conclusion: 论文结论指出，可视化技术虽能有效影响MLLM的判断而不损害其自信度，但需谨慎使用以避免不希望的幻觉现象。

Abstract: We evaluate how visualizations can influence the judgment of MLLMs about the
presence or absence of bridges in a network. We show that the inclusion of
visualization improves confidence over a structured text-based input that could
theoretically be helpful for answering the question. On the other hand, we
observe that standard visualization techniques create a strong bias towards
accepting or refuting the presence of a bridge -- independently of whether or
not a bridge actually exists in the network. While our results indicate that
the inclusion of visualization techniques can effectively influence the MLLM's
judgment without compromising its self-reported confidence, they also imply
that practitioners must be careful of allowing users to include visualizations
in generative AI applications so as to avoid undesired hallucinations.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [104] [Toward an Agricultural Operational Design Domain: A Framework](https://arxiv.org/abs/2511.02937)
*Mirco Felske,Jannik Redenius,Georg Happich,Julius Schöning*

Main category: cs.RO

TL;DR: 该论文提出了Ag-ODD Framework，用于描述和验证农业自动化系统的操作边界，解决了现有ODD概念的不足。


<details>
  <summary>Details</summary>
Motivation: 现有ODD概念无法满足农业应用的独特挑战，需要一个结构化、透明且可验证的环境描述方法。

Method: 提出了Ag-ODD Framework，包括Ag-ODD描述概念、扩展的7层模型和迭代验证流程。

Result: 通过演示用例展示了Ag-ODD Framework在标准化和可扩展性方面的潜力。

Conclusion: Ag-ODD Framework为农业自动化系统提供了一个清晰且可验证的操作边界描述方法，支持环境描述的标准化和可扩展性。

Abstract: The agricultural sector increasingly relies on autonomous systems that
operate in complex and variable environments. Unlike on-road applications,
agricultural automation integrates driving and working processes, each of which
imposes distinct operational constraints. Handling this complexity and ensuring
consistency throughout the development and validation processes requires a
structured, transparent, and verified description of the environment. However,
existing Operational Design Domain (ODD) concepts do not yet address the unique
challenges of agricultural applications.
  Therefore, this work introduces the Agricultural ODD (Ag-ODD) Framework,
which can be used to describe and verify the operational boundaries of
autonomous agricultural systems. The Ag-ODD Framework consists of three core
elements. First, the Ag-ODD description concept, which provides a structured
method for unambiguously defining environmental and operational parameters
using concepts from ASAM Open ODD and CityGML. Second, the 7-Layer Model
derived from the PEGASUS 6-Layer Model, has been extended to include a process
layer to capture dynamic agricultural operations. Third, the iterative
verification process verifies the Ag-ODD against its corresponding logical
scenarios, derived from the 7-Layer Model, to ensure the Ag-ODD's completeness
and consistency.
  Together, these elements provide a consistent approach for creating
unambiguous and verifiable Ag-ODD. Demonstrative use cases show how the Ag-ODD
Framework can support the standardization and scalability of environmental
descriptions for autonomous agricultural systems.

</details>


### [105] [Comprehensive Assessment of LiDAR Evaluation Metrics: A Comparative Study Using Simulated and Real Data](https://arxiv.org/abs/2511.02994)
*Syed Mostaquim Ali,Taufiq Rahman,Ghazal Farhani,Mohamed H. Zaki,Benoit Anctil,Dominique Charlebois*

Main category: cs.RO

TL;DR: 研究提出了一种比较真实与模拟LiDAR扫描的方法，发现密度感知Chamfer距离（DCD）是最佳评估指标，并在虚拟测试环境中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于传统物理测试在成本和安全方面的限制，需要虚拟测试环境（VTE）作为替代方案。比较VTE生成的传感器输出与真实世界的对应物，可以验证VTE的准确性。

Method: 通过在不同噪声、密度、失真、传感器方向和通道设置下测试多种评估指标，最终确定DCD的敏感性和准确性最佳。随后使用真实LiDAR扫描数据生成虚拟测试环境，并比较模拟与真实扫描的模型感知和几何相似性。

Result: 模拟和真实LiDAR扫描的语义分割输出相似（mIoU为21%），但几何属性存在轻微差异（平均DCD为0.63）。DCD在感知方法中相关性最高。

Conclusion: 密度感知Chamfer距离（DCD）在所有测试案例中表现最佳，适用于比较真实和模拟LiDAR扫描。虽然模拟和真实LiDAR扫描在几何属性和模型输出上存在差异，但DCD与感知方法的相关性最高。

Abstract: For developing safe Autonomous Driving Systems (ADS), rigorous testing is
required before they are deemed safe for road deployments. Since comprehensive
conventional physical testing is impractical due to cost and safety concerns,
Virtual Testing Environments (VTE) can be adopted as an alternative. Comparing
VTE-generated sensor outputs against their real-world analogues can be a strong
indication that the VTE accurately represents reality. Correspondingly, this
work explores a comprehensive experimental approach to finding evaluation
metrics suitable for comparing real-world and simulated LiDAR scans. The
metrics were tested in terms of sensitivity and accuracy with different noise,
density, distortion, sensor orientation, and channel settings. From comparing
the metrics, we found that Density Aware Chamfer Distance (DCD) works best
across all cases. In the second step of the research, a Virtual Testing
Environment was generated using real LiDAR scan data. The data was collected in
a controlled environment with only static objects using an instrumented vehicle
equipped with LiDAR, IMU and cameras. Simulated LiDAR scans were generated from
the VTEs using the same pose as real LiDAR scans. The simulated and LiDAR scans
were compared in terms of model perception and geometric similarity. Actual and
simulated LiDAR scans have a similar semantic segmentation output with a mIoU
of 21\% with corrected intensity and an average density aware chamfer distance
(DCD) of 0.63. This indicates a slight difference in the geometric properties
of simulated and real LiDAR scans and a significant difference between model
outputs. During the comparison, density-aware chamfer distance was found to be
the most correlated among the metrics with perception methods.

</details>


### [106] [A Collaborative Reasoning Framework for Anomaly Diagnostics in Underwater Robotics](https://arxiv.org/abs/2511.03075)
*Markus Buchholz,Ignacio Carlucho,Yvan R. Petillot*

Main category: cs.RO

TL;DR: AURA是一个结合LLMs、数字孪生和人机交互的协作框架，用于机器人异常诊断，通过反馈循环将专家知识融入AI，实现自适应提升。


<details>
  <summary>Details</summary>
Motivation: 在安全关键环境中部署自主系统时，需要结合人类专业知识与AI分析以应对未预见的异常，确保系统的安全性和适应性。

Method: AURA整合了大型语言模型（LLMs）、高保真数字孪生（DT）和人机交互，实时检测和响应异常行为。架构包含两个角色明确的代理：低层状态异常表征代理监控遥测数据并转换为结构化问题描述，高层诊断推理代理与操作员进行知识对话以识别根本原因。

Result: AURA框架通过人类验证的诊断转化为训练样本，逐步将专家知识提炼到AI中，提升了系统的自适应能力。

Conclusion: AURA框架通过结合人类专业知识与AI驱动分析，实现了机器人异常和故障诊断的协作模式，将静态工具转变为自适应伙伴，为可信赖、持续改进的人机团队建立了模式。

Abstract: The safe deployment of autonomous systems in safety-critical settings
requires a paradigm that combines human expertise with AI-driven analysis,
especially when anomalies are unforeseen. We introduce AURA (Autonomous
Resilience Agent), a collaborative framework for anomaly and fault diagnostics
in robotics. AURA integrates large language models (LLMs), a high-fidelity
digital twin (DT), and human-in-the-loop interaction to detect and respond to
anomalous behavior in real time. The architecture uses two agents with clear
roles: (i) a low-level State Anomaly Characterization Agent that monitors
telemetry and converts signals into a structured natural-language problem
description, and (ii) a high-level Diagnostic Reasoning Agent that conducts a
knowledge-grounded dialogue with an operator to identify root causes, drawing
on external sources. Human-validated diagnoses are then converted into new
training examples that refine the low-level perceptual model. This feedback
loop progressively distills expert knowledge into the AI, transforming it from
a static tool into an adaptive partner. We describe the framework's operating
principles and provide a concrete implementation, establishing a pattern for
trustworthy, continually improving human-robot teams.

</details>


### [107] [WorldPlanner: Monte Carlo Tree Search and MPC with Action-Conditioned Visual World Models](https://arxiv.org/abs/2511.03077)
*R. Khorrambakht,Joaquim Ortiz-Haro,Joseph Amigo,Omar Mostafa,Daniel Dugas,Franziska Meier,Ludovic Righetti*

Main category: cs.RO

TL;DR: 通过扩散动作采样器和蒙特卡洛树搜索规划，基于模型的方法在机器人任务中优于行为克隆。


<details>
  <summary>Details</summary>
Motivation: 解决行为克隆策略在新任务中难以迁移、训练数据收集困难的问题。

Method: 收集非结构化游戏数据，学习动作条件视觉世界模型、扩散动作采样器和可选奖励模型，结合蒙特卡洛树搜索规划和零阶模型预测控制器执行动作。

Result: 在三种真实世界机器人任务中验证了方法的有效性，规划显著提升了标准操作测试环境中的性能。

Conclusion: 采用基于模型的方法（如扩散动作采样器和蒙特卡洛树搜索规划器）显著提升了机器人任务执行性能，优于传统的行为克隆基线。

Abstract: Robots must understand their environment from raw sensory inputs and reason
about the consequences of their actions in it to solve complex tasks. Behavior
Cloning (BC) leverages task-specific human demonstrations to learn this
knowledge as end-to-end policies. However, these policies are difficult to
transfer to new tasks, and generating training data is challenging because it
requires careful demonstrations and frequent environment resets. In contrast to
such policy-based view, in this paper we take a model-based approach where we
collect a few hours of unstructured easy-to-collect play data to learn an
action-conditioned visual world model, a diffusion-based action sampler, and
optionally a reward model. The world model -- in combination with the action
sampler and a reward model -- is then used to optimize long sequences of
actions with a Monte Carlo Tree Search (MCTS) planner. The resulting plans are
executed on the robot via a zeroth-order Model Predictive Controller (MPC). We
show that the action sampler mitigates hallucinations of the world model during
planning and validate our approach on 3 real-world robotic tasks with varying
levels of planning and modeling complexity. Our experiments support the
hypothesis that planning leads to a significant improvement over BC baselines
on a standard manipulation test environment.

</details>


### [108] [3D Cal: An Open-Source Software Library for Calibrating Tactile Sensors](https://arxiv.org/abs/2511.03078)
*Rohan Kota,Kaival Shah,J. Edward Colgate,Gregory Reardon*

Main category: cs.RO

TL;DR: libname是一个开源库，将3D打印机转化为自动探测设备，用于生成大量触觉传感器校准数据，显著简化了校准过程。


<details>
  <summary>Details</summary>
Motivation: 触觉传感在机器人操作中至关重要，但校准过程通常临时且费时费力，缺乏自动化解决方案。

Method: 该研究将低成本3D打印机转化为自动探测设备，用于生成大量标记训练数据，以校准触觉传感器。使用自定义卷积神经网络重建高质量深度图，并对数据进行消融研究以确定所需数据量。

Result: 研究表明libname能够有效校准两种商用视觉触觉传感器（DIGIT和GelSight Mini），并通过数据消融研究提供了实用的校准指南。

Conclusion: libname通过自动化触觉传感器校准，加速了触觉传感研究，简化了传感器部署，并促进了触觉传感在机器人平台中的实际集成。

Abstract: Tactile sensing plays a key role in enabling dexterous and reliable robotic
manipulation, but realizing this capability requires substantial calibration to
convert raw sensor readings into physically meaningful quantities. Despite its
near-universal necessity, the calibration process remains ad hoc and
labor-intensive. Here, we introduce \libname{}, an open-source library that
transforms a low-cost 3D printer into an automated probing device capable of
generating large volumes of labeled training data for tactile sensor
calibration. We demonstrate the utility of \libname{} by calibrating two
commercially available vision-based tactile sensors, DIGIT and GelSight Mini,
to reconstruct high-quality depth maps using the collected data and a custom
convolutional neural network. In addition, we perform a data ablation study to
determine how much data is needed for accurate calibration, providing practical
guidelines for researchers working with these specific sensors, and we
benchmark the trained models on previously unseen objects to evaluate
calibration accuracy and generalization performance. By automating tactile
sensor calibration, \libname{} can accelerate tactile sensing research,
simplify sensor deployment, and promote the practical integration of tactile
sensing in robotic platforms.

</details>


### [109] [SENT Map -- Semantically Enhanced Topological Maps with Foundation Models](https://arxiv.org/abs/2511.03165)
*Raj Surya Rajendran Kathirvel,Zach A Chavis,Stephen J. Guy,Karthik Desingh*

Main category: cs.RO

TL;DR: SENT-Map是一种语义增强的拓扑地图，通过JSON格式表示室内环境，支持自主导航和操作，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了支持自主导航和操作，利用基础模型的进展，通过JSON文本格式表示环境，使语义信息易于添加和编辑。

Method: 采用两阶段方法：首先与操作员一起使用Vision-FM映射环境，然后利用SENT-Map表示和自然语言查询在基础模型中进行规划。

Result: 实验结果表明，语义增强使小型本地可部署的基础模型能够成功规划室内环境。

Conclusion: SENT-Map通过语义增强的拓扑地图表示室内环境，支持自主导航和操作，实验证明即使是小型本地可部署的基础模型也能成功规划室内环境。

Abstract: We introduce SENT-Map, a semantically enhanced topological map for
representing indoor environments, designed to support autonomous navigation and
manipulation by leveraging advancements in foundational models (FMs). Through
representing the environment in a JSON text format, we enable semantic
information to be added and edited in a format that both humans and FMs
understand, while grounding the robot to existing nodes during planning to
avoid infeasible states during deployment. Our proposed framework employs a two
stage approach, first mapping the environment alongside an operator with a
Vision-FM, then using the SENT-Map representation alongside a natural-language
query within an FM for planning. Our experimental results show that
semantic-enhancement enables even small locally-deployable FMs to successfully
plan over indoor environments.

</details>


### [110] [Learning Natural and Robust Hexapod Locomotion over Complex Terrains via Motion Priors based on Deep Reinforcement Learning](https://arxiv.org/abs/2511.03167)
*Xin Liu,Jinze Wu,Yinghui Li,Chenkun Qi,Yufei Xue,Feng Gao*

Main category: cs.RO

TL;DR: 首次利用强化学习控制器实现真实六足机器人在复杂地形上的自然步态行走，方法基于运动先验和对抗判别器。


<details>
  <summary>Details</summary>
Motivation: 多足机器人在复杂地形中通过多腿协调实现稳定移动，但如何在更大的动作探索空间中有效协调多腿生成自然且鲁棒的运动是关键问题。

Method: 采用基于运动先验的方法，生成优化运动先验数据集，并训练对抗判别器以指导六足机器人学习自然步态。

Result: 学习到的策略成功迁移至真实六足机器人，在无视觉信息的复杂地形中表现出自然步态和显著鲁棒性。

Conclusion: 本研究成功将基于运动先验的深度强化学习算法应用于真实六足机器人，首次实现了在复杂地形上的自主行走，展示了自然步态和显著鲁棒性。

Abstract: Multi-legged robots offer enhanced stability to navigate complex terrains
with their multiple legs interacting with the environment. However, how to
effectively coordinate the multiple legs in a larger action exploration space
to generate natural and robust movements is a key issue. In this paper, we
introduce a motion prior-based approach, successfully applying deep
reinforcement learning algorithms to a real hexapod robot. We generate a
dataset of optimized motion priors, and train an adversarial discriminator
based on the priors to guide the hexapod robot to learn natural gaits. The
learned policy is then successfully transferred to a real hexapod robot, and
demonstrate natural gait patterns and remarkable robustness without visual
information in complex terrains. This is the first time that a reinforcement
learning controller has been used to achieve complex terrain walking on a real
hexapod robot.

</details>


### [111] [Learning-based Cooperative Robotic Paper Wrapping: A Unified Control Policy with Residual Force Control](https://arxiv.org/abs/2511.03181)
*Rewida Ali,Cristian C. Beltran-Hernandez,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 论文提出START框架，结合LLM和混合IL/RL策略，通过子任务ID解决变形物体操控问题，实现97%成功率。


<details>
  <summary>Details</summary>
Motivation: 解决人机协作中变形物体（如纸张、袋子、布料）操控的挑战，特别是在礼品包装等长时程任务中，需精确折叠和力控制。

Method: 采用基于学习的框架，结合大型语言模型（LLM）的高层任务规划器和低层混合模仿学习（IL）与强化学习（RL）策略，核心是Sub-task Aware Robotic Transformer（START），通过子任务ID提供显式时间基础。

Result: 在真实世界的包装任务中实现了97%的成功率，统一基于Transformer的策略减少了专用模型的需求，支持灵活执行。

Conclusion: 该论文提出的学习框架通过整合高层任务规划器和低层混合模仿学习与强化学习策略，有效解决了人机协作中变形物体操控的挑战，实现了97%的成功率。

Abstract: Human-robot cooperation is essential in environments such as warehouses and
retail stores, where workers frequently handle deformable objects like paper,
bags, and fabrics. Coordinating robotic actions with human assistance remains
difficult due to the unpredictable dynamics of deformable materials and the
need for adaptive force control. To explore this challenge, we focus on the
task of gift wrapping, which exemplifies a long-horizon manipulation problem
involving precise folding, controlled creasing, and secure fixation of paper.
Success is achieved when the robot completes the sequence to produce a neatly
wrapped package with clean folds and no tears.
  We propose a learning-based framework that integrates a high-level task
planner powered by a large language model (LLM) with a low-level hybrid
imitation learning (IL) and reinforcement learning (RL) policy. At its core is
a Sub-task Aware Robotic Transformer (START) that learns a unified policy from
human demonstrations. The key novelty lies in capturing long-range temporal
dependencies across the full wrapping sequence within a single model. Unlike
vanilla Action Chunking with Transformer (ACT), typically applied to short
tasks, our method introduces sub-task IDs that provide explicit temporal
grounding. This enables robust performance across the entire wrapping process
and supports flexible execution, as the policy learns sub-goals rather than
merely replicating motion sequences.
  Our framework achieves a 97% success rate on real-world wrapping tasks. We
show that the unified transformer-based policy reduces the need for specialized
models, allows controlled human supervision, and effectively bridges high-level
intent with the fine-grained force control required for deformable object
manipulation.

</details>


### [112] [Collaborative Assembly Policy Learning of a Sightless Robot](https://arxiv.org/abs/2511.03189)
*Zeqing Zhang,Weifeng Lu,Lei Yang,Wei Jing,Bowei Tang,Jia Pan*

Main category: cs.RO

TL;DR: 本文提出了一种结合导纳控制的强化学习方法，用于提升物理人机协作任务的效率和减轻人力负担，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 导纳控制在物理人机协作任务中难以准确测量人力/扭矩以估计人类意图，而传统强化学习方法由于安全约束和稀疏奖励不适用于此类任务。

Method: 采用了一种结合人类设计的导纳控制器的强化学习方法，以促进更积极的机器人行为并减轻人类操作者的负担。

Result: 仿真和实际实验表明，该方法在任务成功率和完成时间上优于导纳控制，且显著减少了测量到的力/扭矩。

Conclusion: 本文提出的新型强化学习方法在物理人机协作任务中表现优于传统的导纳控制，显著提高了任务成功率和完成效率，并减少了人力需求。

Abstract: This paper explores a physical human-robot collaboration (pHRC) task
involving the joint insertion of a board into a frame by a sightless robot and
a human operator. While admittance control is commonly used in pHRC tasks, it
can be challenging to measure the force/torque applied by the human for
accurate human intent estimation, limiting the robot's ability to assist in the
collaborative task. Other methods that attempt to solve pHRC tasks using
reinforcement learning (RL) are also unsuitable for the board-insertion task
due to its safety constraints and sparse rewards. Therefore, we propose a novel
RL approach that utilizes a human-designed admittance controller to facilitate
more active robot behavior and reduce human effort. Through simulation and
real-world experiments, we demonstrate that our approach outperforms admittance
control in terms of success rate and task completion time. Additionally, we
observed a significant reduction in measured force/torque when using our
proposed approach compared to admittance control. The video of the experiments
is available at https://youtu.be/va07Gw6YIog.

</details>


### [113] [GUIDES: Guidance Using Instructor-Distilled Embeddings for Pre-trained Robot Policy Enhancement](https://arxiv.org/abs/2511.03400)
*Minquan Gao,Xinyi Li,Qing Yan,Xiaojian Sun,Xiaopan Zhang,Chien-Ming Huang,Jiachen Li*

Main category: cs.RO

TL;DR: GUIDES 是一个轻量级框架，通过从基础模型引入语义指导，增强预训练策略，无需架构重设计，显著提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 预训练的机器人策略缺乏基础模型的语义感知能力，完全替换成本高且会丢失累积知识。

Method: GUIDES 采用微调的视觉语言模型（Instructor）生成上下文指令，并通过辅助模块将指令编码为引导嵌入，注入策略的潜在空间。

Result: 在 RoboCasa 模拟环境中，GUIDES 显著提高了任务成功率；在 UR5 机器人上的实际部署证明了其对关键子任务（如抓取）的运动精度提升。

Conclusion: GUIDES 提供了一种实用且资源高效的途径，用于升级而非替换已验证的机器人策略，显著提高了任务成功率。

Abstract: Pre-trained robot policies serve as the foundation of many validated robotic
systems, which encapsulate extensive embodied knowledge. However, they often
lack the semantic awareness characteristic of foundation models, and replacing
them entirely is impractical in many situations due to high costs and the loss
of accumulated knowledge. To address this gap, we introduce GUIDES, a
lightweight framework that augments pre-trained policies with semantic guidance
from foundation models without requiring architectural redesign. GUIDES employs
a fine-tuned vision-language model (Instructor) to generate contextual
instructions, which are encoded by an auxiliary module into guidance
embeddings. These embeddings are injected into the policy's latent space,
allowing the legacy model to adapt to this new semantic input through brief,
targeted fine-tuning. For inference-time robustness, a large language
model-based Reflector monitors the Instructor's confidence and, when confidence
is low, initiates a reasoning loop that analyzes execution history, retrieves
relevant examples, and augments the VLM's context to refine subsequent actions.
Extensive validation in the RoboCasa simulation environment across diverse
policy architectures shows consistent and substantial improvements in task
success rates. Real-world deployment on a UR5 robot further demonstrates that
GUIDES enhances motion precision for critical sub-tasks such as grasping.
Overall, GUIDES offers a practical and resource-efficient pathway to upgrade,
rather than replace, validated robot policies.

</details>


### [114] [Value Elicitation for a Socially Assistive Robot Addressing Social Anxiety: A Participatory Design Approach](https://arxiv.org/abs/2511.03444)
*Vesna Poprcova,Iulia Lefter,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 通过参与式设计工作坊，研究提取了社交辅助机器人设计中的核心价值（如适应性、接受性），强调了用户中心和情境感知的重要性。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑是一种普遍的心理健康问题，传统支持或治疗手段不足，技术进步（尤其是社交机器人）为补充传统心理健康干预提供了可能。

Method: 通过参与式设计工作坊，与心理健康学术研究人员合作，采用创意、反思和设想活动，系统性地提取价值、期望、需求和偏好。

Result: 研究揭示了设计相关价值的丰富见解，包括适应性、接受性和有效性，这些是支持社交焦虑个体的核心价值。

Conclusion: 本研究强调了以研究为主导的价值提取方法的重要性，突出了在开发社交辅助机器人时以用户为中心和情境感知的设计考虑。

Abstract: Social anxiety is a prevalent mental health condition that can significantly
impact overall well-being and quality of life. Despite its widespread effects,
adequate support or treatment for social anxiety is often insufficient.
Advances in technology, particularly in social robotics, offer promising
opportunities to complement traditional mental health. As an initial step
toward developing effective solutions, it is essential to understand the values
that shape what is considered meaningful, acceptable, and helpful. In this
study, a participatory design workshop was conducted with mental health
academic researchers to elicit the underlying values that should inform the
design of socially assistive robots for social anxiety support. Through
creative, reflective, and envisioning activities, participants explored
scenarios and design possibilities, allowing for systematic elicitation of
values, expectations, needs, and preferences related to robot-supported
interventions. The findings reveal rich insights into design-relevant
values-including adaptivity, acceptance, and efficacy-that are core to support
for individuals with social anxiety. This study highlights the significance of
a research-led approach to value elicitation, emphasising user-centred and
context-aware design considerations in the development of socially assistive
robots.

</details>


### [115] [Development of the Bioinspired Tendon-Driven DexHand 021 with Proprioceptive Compliance Control](https://arxiv.org/abs/2511.03481)
*Jianbo Yuan,Haohua Zhu,Jing Dai,Sheng Yi*

Main category: cs.RO

TL;DR: Dex-Hand 021是一款轻量、高性能的五指机器人手，通过导纳控制提升灵巧性和力感知，实验证明其在负载、精度和扭矩控制上表现优异。


<details>
  <summary>Details</summary>
Motivation: 复制人类手的多功能性（如运动、感知和协调操作）是机器人系统面临的重大挑战，需平衡灵巧性与工程约束（如复杂度、重量比和耐用性）。

Method: 采用基于本体感知力感应的导纳控制方法，结合12个主动和7个被动自由度的电缆驱动设计。

Result: 单指负载能力超过10 N，指尖重复性低于0.001 m，力估计误差小于0.2 N，多物体抓取时关节扭矩减少31.19%，成功执行33种GRASP分类动作。

Conclusion: Dex-Hand 021通过轻量化设计和高性能控制方法，显著提升了机器人手的灵巧性和力感知能力，为机器人操作和智能制造领域做出了贡献。

Abstract: The human hand plays a vital role in daily life and industrial applications,
yet replicating its multifunctional capabilities-including motion, sensing, and
coordinated manipulation-with robotic systems remains a formidable challenge.
Developing a dexterous robotic hand requires balancing human-like agility with
engineering constraints such as complexity, size-to-weight ratio, durability,
and force-sensing performance. This letter presents Dex-Hand 021, a
high-performance, cable-driven five-finger robotic hand with 12 active and 7
passive degrees of freedom (DoFs), achieving 19 DoFs dexterity in a lightweight
1 kg design. We propose a proprioceptive force-sensing-based admittance control
method to enhance manipulation. Experimental results demonstrate its superior
performance: a single-finger load capacity exceeding 10 N, fingertip
repeatability under 0.001 m, and force estimation errors below 0.2 N. Compared
to PID control, joint torques in multi-object grasping are reduced by 31.19%,
significantly improves force-sensing capability while preventing overload
during collisions. The hand excels in both power and precision grasps,
successfully executing 33 GRASP taxonomy motions and complex manipulation
tasks. This work advances the design of lightweight, industrial-grade dexterous
hands and enhances proprioceptive control, contributing to robotic manipulation
and intelligent manufacturing.

</details>


### [116] [ROSBag MCP Server: Analyzing Robot Data with LLMs for Agentic Embodied AI Applications](https://arxiv.org/abs/2511.03497)
*Lei Fu,Sahar Salimpour,Leonardo Militano,Harry Edelman,Jorge Peña Queralta,Giovanni Toffetti*

Main category: cs.RO

TL;DR: 该论文介绍了一个MCP服务器，用于通过自然语言处理ROS数据包，并比较了不同LLM模型的工具调用能力，发现Kimi K2和Claude Sonnet 4表现最优。


<details>
  <summary>Details</summary>
Motivation: 填补Agentic Embodied AI领域的研究空白，提供一个能够通过自然语言处理和分析机器人数据的工具。

Method: 通过构建一个MCP服务器来分析ROS和ROS 2数据包，结合LLMs和VLMs实现自然语言处理机器人数据，并开发了轻量级UI用于不同LLM模型的基准测试。

Result: 实验分析了八种不同LLM/VLM模型的工具调用能力，发现Kimi K2和Claude Sonnet 4表现最佳。

Conclusion: 研究指出，在工具调用能力上，Kimi K2和Claude Sonnet 4表现明显优于其他模型，并总结了影响成功率的多个因素，如工具描述模式、参数数量和可用工具数量。

Abstract: Agentic AI systems and Physical or Embodied AI systems have been two key
research verticals at the forefront of Artificial Intelligence and Robotics,
with Model Context Protocol (MCP) increasingly becoming a key component and
enabler of agentic applications. However, the literature at the intersection of
these verticals, i.e., Agentic Embodied AI, remains scarce. This paper
introduces an MCP server for analyzing ROS and ROS 2 bags, allowing for
analyzing, visualizing and processing robot data with natural language through
LLMs and VLMs. We describe specific tooling built with robotics domain
knowledge, with our initial release focused on mobile robotics and supporting
natively the analysis of trajectories, laser scan data, transforms, or time
series data. This is in addition to providing an interface to standard ROS 2
CLI tools ("ros2 bag list" or "ros2 bag info"), as well as the ability to
filter bags with a subset of topics or trimmed in time. Coupled with the MCP
server, we provide a lightweight UI that allows the benchmarking of the tooling
with different LLMs, both proprietary (Anthropic, OpenAI) and open-source
(through Groq). Our experimental results include the analysis of tool calling
capabilities of eight different state-of-the-art LLM/VLM models, both
proprietary and open-source, large and small. Our experiments indicate that
there is a large divide in tool calling capabilities, with Kimi K2 and Claude
Sonnet 4 demonstrating clearly superior performance. We also conclude that
there are multiple factors affecting the success rates, from the tool
description schema to the number of arguments, as well as the number of tools
available to the models. The code is available with a permissive license at
https://github.com/binabik-ai/mcp-rosbags.

</details>


### [117] [Indicating Robot Vision Capabilities with Augmented Reality](https://arxiv.org/abs/2511.03550)
*Hong Wang,Ridhima Phatak,James Ocampo,Zhao Han*

Main category: cs.RO

TL;DR: 研究通过AR视野指示器改善人类对机器人视觉能力的理解，实验显示任务空间指示器最准确，但解读有延迟，同时提出六条实践指南。


<details>
  <summary>Details</summary>
Motivation: 人类常误认为机器人拥有与人类相同的视野，这种错误的心理模型可能导致协作任务失败，尤其是当机器人无法扫描场景更新其世界模型时。

Method: 通过增强现实（AR）中的四种视野（FoV）指示器，并进行用户实验（N=41），评估了这些指示器在准确性、信心、任务效率和认知负荷方面的表现。

Result: 结果表明，任务空间的非自我中心（allocentric）指示器准确性最高，但解读机器人视野时存在延迟；自我中心（egocentric）指示器中的深眼窝设计也提高了准确性。所有指示器下，参与者信心高且认知负荷低。

Conclusion: 研究提出了六条指南，帮助实践者应用AR指示器或物理修改来调整人类对机器人视觉能力的心理模型，从而提高人机协作的效率。

Abstract: Research indicates that humans can mistakenly assume that robots and humans
have the same field of view (FoV), possessing an inaccurate mental model of
robots. This misperception may lead to failures during human-robot
collaboration tasks where robots might be asked to complete impossible tasks
about out-of-view objects. The issue is more severe when robots do not have a
chance to scan the scene to update their world model while focusing on assigned
tasks. To help align humans' mental models of robots' vision capabilities, we
propose four FoV indicators in augmented reality (AR) and conducted a user
human-subjects experiment (N=41) to evaluate them in terms of accuracy,
confidence, task efficiency, and workload. These indicators span a spectrum
from egocentric (robot's eye and head space) to allocentric (task space).
Results showed that the allocentric blocks at the task space had the highest
accuracy with a delay in interpreting the robot's FoV. The egocentric indicator
of deeper eye sockets, possible for physical alteration, also increased
accuracy. In all indicators, participants' confidence was high while cognitive
load remained low. Finally, we contribute six guidelines for practitioners to
apply our AR indicators or physical alterations to align humans' mental models
with robots' vision capabilities.

</details>


### [118] [OneOcc: Semantic Occupancy Prediction for Legged Robots with a Single Panoramic Camera](https://arxiv.org/abs/2511.03571)
*Hao Shi,Ze Wang,Shangwei Guo,Mengfei Duan,Song Wang,Teng Chen,Kailun Yang,Lin Wang,Kaiwei Wang*

Main category: cs.RO

TL;DR: OneOcc是一个专为腿式/人形机器人设计的全景语义场景补全框架，通过多种创新技术实现了SOTA性能，并发布了两个全景占用基准数据集。


<details>
  <summary>Details</summary>
Motivation: 针对腿式/人形机器人对鲁棒3D语义占用的需求，以及现有语义场景补全系统主要面向轮式平台的局限性，提出了OneOcc框架。

Method: OneOcc采用双投影融合（DP-ER）利用环形全景及其等距展开，保持360度连续性和网格对齐；双网格体素化（BGV）在笛卡尔和圆柱极坐标空间中进行推理，减少离散化偏差；轻量级解码器（Hierarchical AMoE-3D）实现动态多尺度融合；以及无需额外传感器的步态位移补偿（GDC）。

Result: OneOcc在QuadOcc数据集上超越了视觉和LiDAR基线，在H3O数据集上实现了+3.83 mIoU（同城）和+8.08（跨城）的提升。

Conclusion: OneOcc框架通过结合多种创新技术，如双投影融合、双网格体素化、轻量级解码器和步态位移补偿，显著提升了全景语义场景补全的性能，并在QuadOcc和H3O数据集上实现了新的SOTA成果。

Abstract: Robust 3D semantic occupancy is crucial for legged/humanoid robots, yet most
semantic scene completion (SSC) systems target wheeled platforms with
forward-facing sensors. We present OneOcc, a vision-only panoramic SSC
framework designed for gait-introduced body jitter and 360{\deg} continuity.
OneOcc combines: (i) Dual-Projection fusion (DP-ER) to exploit the annular
panorama and its equirectangular unfolding, preserving 360{\deg} continuity and
grid alignment; (ii) Bi-Grid Voxelization (BGV) to reason in Cartesian and
cylindrical-polar spaces, reducing discretization bias and sharpening
free/occupied boundaries; (iii) a lightweight decoder with Hierarchical AMoE-3D
for dynamic multi-scale fusion and better long-range/occlusion reasoning; and
(iv) plug-and-play Gait Displacement Compensation (GDC) learning feature-level
motion correction without extra sensors. We also release two panoramic
occupancy benchmarks: QuadOcc (real quadruped, first-person 360{\deg}) and
Human360Occ (H3O) (CARLA human-ego 360{\deg} with RGB, Depth, semantic
occupancy; standardized within-/cross-city splits). OneOcc sets new
state-of-the-art (SOTA): on QuadOcc it beats strong vision baselines and
popular LiDAR ones; on H3O it gains +3.83 mIoU (within-city) and +8.08
(cross-city). Modules are lightweight, enabling deployable full-surround
perception for legged/humanoid robots. Datasets and code will be publicly
available at https://github.com/MasterHow/OneOcc.

</details>


### [119] [Multi-User Personalisation in Human-Robot Interaction: Using Quantitative Bipolar Argumentation Frameworks for Preferences Conflict Resolution](https://arxiv.org/abs/2511.03576)
*Aniol Civit,Antonio Andriella,Carles Sierra,Guillem Alenyà*

Main category: cs.RO

TL;DR: 提出MUP-QBAF框架解决多用户HRI中的偏好冲突，动态整合用户和机器人观察，案例验证有效。


<details>
  <summary>Details</summary>
Motivation: 现有个性化方法多关注单用户适应，忽视了多用户场景下可能存在的偏好冲突。

Method: 基于定量双极论证框架（QBAFs），提出MUP-QBAF框架，动态整合用户参数和机器人环境观察，迭代重新计算偏好强度。

Result: 通过实际案例验证框架有效性，展示了用户输入和上下文观察如何塑造偏好结果。

Conclusion: MUP-QBAF框架为多用户人机交互中的偏好冲突提供了透明、结构化和上下文敏感的解​决方案，推动了该领域的发展。

Abstract: While personalisation in Human-Robot Interaction (HRI) has advanced
significantly, most existing approaches focus on single-user adaptation,
overlooking scenarios involving multiple stakeholders with potentially
conflicting preferences. To address this, we propose the Multi-User Preferences
Quantitative Bipolar Argumentation Framework (MUP-QBAF), a novel multi-user
personalisation framework based on Quantitative Bipolar Argumentation
Frameworks (QBAFs) that explicitly models and resolves multi-user preference
conflicts. Unlike prior work in Argumentation Frameworks, which typically
assumes static inputs, our approach is tailored to robotics: it incorporates
both users' arguments and the robot's dynamic observations of the environment,
allowing the system to adapt over time and respond to changing contexts.
Preferences, both positive and negative, are represented as arguments whose
strength is recalculated iteratively based on new information. The framework's
properties and capabilities are presented and validated through a realistic
case study, where an assistive robot mediates between the conflicting
preferences of a caregiver and a care recipient during a frailty assessment
task. This evaluation further includes a sensitivity analysis of argument base
scores, demonstrating how preference outcomes can be shaped by user input and
contextual observations. By offering a transparent, structured, and
context-sensitive approach to resolving competing user preferences, this work
advances the field of multi-user HRI. It provides a principled alternative to
data-driven methods, enabling robots to navigate conflicts in real-world
environments.

</details>


### [120] [Manifold-constrained Hamilton-Jacobi Reachability Learning for Decentralized Multi-Agent Motion Planning](https://arxiv.org/abs/2511.03591)
*Qingyi Chen,Ruiqi Ni,Jun Kim,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: 提出了一种流形约束的HJR学习框架，用于分散式多智能体运动规划，确保安全和任务可行性，实验证明优于现有方法且适用实时场景。


<details>
  <summary>Details</summary>
Motivation: 多智能体运动规划在动态环境中需满足任务施加的流形约束（如服务机器人端杯时需保持杯子直立），现有方法在融入此类约束时存在困难。

Method: 采用了流形约束的Hamilton-Jacobi可达性（HJR）学习方法，结合分散式轨迹优化规划器，使机器人能够生成既安全又符合任务要求的运动计划。

Result: 实验表明，该方法在多种流形约束任务中表现优异，并能高效扩展至高维多智能体操作问题，适用于实时应用。

Conclusion: 该论文提出了一种基于流形约束的Hamilton-Jacobi可达性学习框架，用于解决多智能体运动规划中的安全和任务可行性问题，并在实验中验证了其优于现有约束运动规划器的性能。

Abstract: Safe multi-agent motion planning (MAMP) under task-induced constraints is a
critical challenge in robotics. Many real-world scenarios require robots to
navigate dynamic environments while adhering to manifold constraints imposed by
tasks. For example, service robots must carry cups upright while avoiding
collisions with humans or other robots. Despite recent advances in
decentralized MAMP for high-dimensional systems, incorporating manifold
constraints remains difficult. To address this, we propose a
manifold-constrained Hamilton-Jacobi reachability (HJR) learning framework for
decentralized MAMP. Our method solves HJR problems under manifold constraints
to capture task-aware safety conditions, which are then integrated into a
decentralized trajectory optimization planner. This enables robots to generate
motion plans that are both safe and task-feasible without requiring assumptions
about other agents' policies. Our approach generalizes across diverse
manifold-constrained tasks and scales effectively to high-dimensional
multi-agent manipulation problems. Experiments show that our method outperforms
existing constrained motion planners and operates at speeds suitable for
real-world applications. Video demonstrations are available at
https://youtu.be/RYcEHMnPTH8 .

</details>


### [121] [Multi-robot searching with limited sensing range for static and mobile intruders](https://arxiv.org/abs/2511.03622)
*Swadhin Agrawal,Sujoy Bhore,Joseph S. B. Mitchell,P. B. Sujit,Aayush Gohil*

Main category: cs.RO

TL;DR: 论文研究了在正交多边形几何域中用多机器人搜索入侵者的问题，发现即使是静态入侵者也是NP难问题，因此提出了基于空间填充曲线和随机搜索的算法，并评估了机器人数与搜索时间的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究在几何域中利用多个搜索机器人寻找入侵者的问题，考虑机器人的有限感知能力和静态/移动入侵者的情况。

Method: 基于空间填充曲线、随机搜索和协作随机搜索的方法。

Result: 评估了搜索机器人数量与搜索时间之间的权衡，同时考虑了正交搜索区域的几何特性。

Conclusion: 在几何域中搜索入侵者的问题即使对于静态入侵者也是NP难的，因此研究转向开发高效且鲁棒的算法。

Abstract: We consider the problem of searching for an intruder in a geometric domain by
utilizing multiple search robots. The domain is a simply connected orthogonal
polygon with edges parallel to the cartesian coordinate axes. Each robot has a
limited sensing capability. We study the problem for both static and mobile
intruders. It turns out that the problem of finding an intruder is NP-hard,
even for a stationary intruder. Given this intractability, we turn our
attention towards developing efficient and robust algorithms, namely methods
based on space-filling curves, random search, and cooperative random search.
Moreover, for each proposed algorithm, we evaluate the trade-off between the
number of search robots and the time required for the robots to complete the
search process while considering the geometric properties of the connected
orthogonal search area.

</details>


### [122] [Flying Robotics Art: ROS-based Drone Draws the Record-Breaking Mural](https://arxiv.org/abs/2511.03651)
*Andrei A. Korigodskii,Oleg D. Kalachev,Artem E. Vasiunik,Matvei V. Urvantsev,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 该论文介绍了一种创新的自主无人机系统，结合新型导航和喷漆技术，成功完成世界最大无人机壁画，展示了其在创意领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣户外条件（如风和阳光）下保持艺术精确性和操作可靠性的双重挑战，推动机器人技术在创意领域的应用扩展。

Method: 结合红外运动捕捉摄像头和LiDAR技术的新型导航系统，以及针对切向和法向路径的不同调节控制架构，实现了精确的轨迹跟踪和稳定的线条绘制。还包括轨迹规划和路径优化算法，以及专门设计的喷漆机制。

Result: 实验结果表明，该系统在各种条件下均表现出鲁棒性和精确性，展示了其在自主大规模艺术创作中的潜力。

Conclusion: 该论文展示了一种创新的自主无人机系统，成功部署并完成了世界上最大的无人机绘制壁画，证明了其在恶劣户外条件下的艺术精确性和操作可靠性。

Abstract: This paper presents the innovative design and successful deployment of a
pioneering autonomous unmanned aerial system developed for executing the
world's largest mural painted by a drone. Addressing the dual challenges of
maintaining artistic precision and operational reliability under adverse
outdoor conditions such as wind and direct sunlight, our work introduces a
robust system capable of navigating and painting outdoors with unprecedented
accuracy. Key to our approach is a novel navigation system that combines an
infrared (IR) motion capture camera and LiDAR technology, enabling precise
location tracking tailored specifically for largescale artistic applications.
We employ a unique control architecture that uses different regulation in
tangential and normal directions relative to the planned path, enabling precise
trajectory tracking and stable line rendering. We also present algorithms for
trajectory planning and path optimization, allowing for complex curve drawing
and area filling. The system includes a custom-designed paint spraying
mechanism, specifically engineered to function effectively amidst the turbulent
airflow generated by the drone's propellers, which also protects the drone's
critical components from paint-related damage, ensuring longevity and
consistent performance. Experimental results demonstrate the system's
robustness and precision in varied conditions, showcasing its potential for
autonomous large-scale art creation and expanding the functional applications
of robotics in creative fields.

</details>


### [123] [Motion Planning Under Temporal Logic Specifications In Semantically Unknown Environments](https://arxiv.org/abs/2511.03652)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 本文提出了一种处理不确定环境中时空逻辑任务的新方法，通过构建产品自动机和奖励函数，结合在线重新规划算法，有效解决了任务规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决不确定环境中（语义标签具有概率性知识）的时空逻辑任务规划问题。

Method: 采用自动机理论方法，构建特殊的产品自动机以捕捉语义标签的不确定性，并为每个边设计奖励函数，利用价值迭代进行在线重新规划。

Result: 通过理论分析和仿真实验验证了所提方法的有效性。

Conclusion: 本文提出了一种新的自动机理论方法，用于处理不确定环境中的运动规划问题，通过构建特殊的产品自动机和设计奖励函数，结合在线重新规划的价值迭代算法，有效解决了时空逻辑任务。

Abstract: This paper addresses a motion planning problem to achieve
spatio-temporal-logical tasks, expressed by syntactically co-safe linear
temporal logic specifications (scLTL\next), in uncertain environments. Here,
the uncertainty is modeled as some probabilistic knowledge on the semantic
labels of the environment. For example, the task is "first go to region 1, then
go to region 2"; however, the exact locations of regions 1 and 2 are not known
a priori, instead a probabilistic belief is available. We propose a novel
automata-theoretic approach, where a special product automaton is constructed
to capture the uncertainty related to semantic labels, and a reward function is
designed for each edge of this product automaton. The proposed algorithm
utilizes value iteration for online replanning. We show some theoretical
results and present some simulations/experiments to demonstrate the efficacy of
the proposed approach.

</details>


### [124] [Unconscious and Intentional Human Motion Cues for Expressive Robot-Arm Motion Design](https://arxiv.org/abs/2511.03676)
*Taito Tashiro,Tomoko Yonezawa,Hirotake Yamazoe*

Main category: cs.RO

TL;DR: 研究通过分析人类动作设计机器人动作，发现后期动作时机和物理实体化对印象形成至关重要。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用人类动作线索设计具有表现力的机器人手臂动作，以提升人机交互的自然性和表现力。

Method: 通过分析人类在棋盘游戏Geister中的两种动作类型（自然游戏中的无意识倾向和有意表达的动作线索），创建了基于不同阶段（速度和停止持续时间）的机器人动作，并通过物理机器人和录制视频两种展示方式评估观察者的印象。

Result: 结果显示，后期动作时机（特别是撤回阶段）在印象形成中起重要作用，物理实体化能增强动作线索的可理解性。

Conclusion: 研究发现，在机器人动作设计中，后期动作时机（尤其是撤回阶段）对印象形成至关重要，物理实体化能增强动作线索的可解释性。这为基于人类时机行为的机器人动作设计提供了见解。

Abstract: This study investigates how human motion cues can be used to design
expressive robot-arm movements. Using the imperfect-information game Geister,
we analyzed two types of human piece-moving motions: natural gameplay
(unconscious tendencies) and instructed expressions (intentional cues). Based
on these findings, we created phase-specific robot motions by varying movement
speed and stop duration, and evaluated observer impressions under two
presentation modalities: a physical robot and a recorded video. Results
indicate that late-phase motion timing, particularly during withdrawal, plays
an important role in impression formation and that physical embodiment enhances
the interpretability of motion cues. These findings provide insights for
designing expressive robot motions based on human timing behavior.

</details>


### [125] [Source-Free Bistable Fluidic Gripper for Size-Selective and Stiffness-Adaptive Grasping](https://arxiv.org/abs/2511.03691)
*Zhihang Qin,Yueheng Zhang,Wan Su,Linxin Hou,Shenghao Zhou,Zhijun Chen,Yu Jun Tan,Cecilia Laschi*

Main category: cs.RO

TL;DR: 该论文提出了一种自包含软体夹具，通过内部液体重新分配实现无需外部能源的稳定抓取，适用于水下和野外环境。


<details>
  <summary>Details</summary>
Motivation: 传统的流体驱动软体夹具通常依赖外部能源，这限制了便携性和长期自主性。

Method: 通过三个相互连接的双稳态快速切换腔室内部的液体重新分配来操作的自包含软体夹具。当顶部感应腔室接触时变形，位移的液体触发抓取腔室的快速切换扩张，实现稳定且尺寸选择性的抓取。

Result: 这种设计实现了无需持续能量输入的稳定、尺寸选择性抓取，并通过内部液压反馈被动适应抓取压力以适应物体刚度。

Conclusion: 这种无需外部能源、紧凑的设计为软体机器人中的轻量级、刚度自适应的流体驱动操作开辟了新可能性，为水下和野外环境中的目标尺寸特定采样和操作提供了可行方法。

Abstract: Conventional fluid-driven soft grippers typically depend on external sources,
which limit portability and long-term autonomy. This work introduces a
self-contained soft gripper with fixed size that operates solely through
internal liquid redistribution among three interconnected bistable snap-through
chambers. When the top sensing chamber deforms upon contact, the displaced
liquid triggers snap-through expansion of the grasping chambers, enabling
stable and size-selective grasping without continuous energy input. The
internal hydraulic feedback further allows passive adaptation of gripping
pressure to object stiffness. This source-free and compact design opens new
possibilities for lightweight, stiffness-adaptive fluid-driven manipulation in
soft robotics, providing a feasible approach for targeted size-specific
sampling and operation in underwater and field environments.

</details>
