<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 63]
- [cs.RO](#cs.RO) [Total: 21]
- [cs.SE](#cs.SE) [Total: 16]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.AI](#cs.AI) [Total: 32]
- [cs.DC](#cs.DC) [Total: 6]
- [cs.NI](#cs.NI) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

TL;DR: LoRA-Edge 是一种参数高效的CNN微调方法，适用于边缘设备，通过TT-SVD和选择性更新显著减少训练参数，保持推理成本不变，并在准确率和收敛速度上表现出色。


<details>
  <summary>Details</summary>
Motivation: 为了解决在边缘设备上进行CNN全微调时面临的内存、计算和能源预算限制问题，需要一种参数高效的微调方法。

Method: LoRA-Edge 结合了低秩适应（LoRA）和张量训练辅助，通过TT-SVD分解预训练卷积层，选择性更新输出侧核心，并通过零初始化保持辅助路径初始不活跃，最后将更新融合回密集核中。

Result: 在多种HAR数据集和CNN骨干网络上，LoRA-Edge 仅更新最多1.49%的参数即可达到与全微调相差4.7%以内的准确率，且在类似预算下优于现有参数高效基线方法。在Jetson Orin Nano上，TT-SVD初始化和选择性核心训练使收敛速度提高了1.4-3.8倍。

Conclusion: LoRA-Edge 通过结构对齐和参数高效的方法，使得边缘平台上的CNN适配变得实用，显著减少了可训练参数数量并保持了推理成本不变。

Abstract: On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [2] [Near-Lossless 3D Voxel Representation Free from Iso-surface](https://arxiv.org/abs/2511.04029)
*Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap*

Main category: cs.CV

TL;DR: Faithful Contouring是一种高保真稀疏体素化表示方法，支持2048+分辨率，无需传统等值面处理，显著提升了3D重建和生成的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于等值面的表示方法依赖于水密化或渲染优化，这不可避免地损害了几何保真度。需要一种能够保持尖锐性和内部结构的新方法。

Method: 提出了Faithful Contouring，一种稀疏体素化表示方法，支持2048+分辨率，无需将网格转换为场函数或在重新网格化过程中提取等值面。设计了一种双模式自动编码器，支持可扩展且保留细节的形状重建。

Result: 在表示和重建的准确性和效率上超越了现有方法，表示距离误差达到10^-5级别，网格重建中Chamfer Distance减少了93%，F-score提高了35%。

Conclusion: Faithful Contouring 作为一种稀疏体素化表示方法，在3D学习任务中表现出卓越的保真度，不仅在表示上达到了10^-5级别的距离误差，还在网格重建中显著降低了Chamfer Distance并提高了F-score。

Abstract: Accurate and efficient voxelized representations of 3D meshes are the
foundation of 3D reconstruction and generation. However, existing
representations based on iso-surface heavily rely on water-tightening or
rendering optimization, which inevitably compromise geometric fidelity. We
propose Faithful Contouring, a sparse voxelized representation that supports
2048+ resolutions for arbitrary meshes, requiring neither converting meshes to
field functions nor extracting the isosurface during remeshing. It achieves
near-lossless fidelity by preserving sharpness and internal structures, even
for challenging cases with complex geometry and topology. The proposed method
also shows flexibility for texturing, manipulation, and editing. Beyond
representation, we design a dual-mode autoencoder for Faithful Contouring,
enabling scalable and detail-preserving shape reconstruction. Extensive
experiments show that Faithful Contouring surpasses existing methods in
accuracy and efficiency for both representation and reconstruction. For direct
representation, it achieves distance errors at the $10^{-5}$ level; for mesh
reconstruction, it yields a 93\% reduction in Chamfer Distance and a 35\%
improvement in F-score over strong baselines, confirming superior fidelity as a
representation for 3D learning tasks.

</details>


### [3] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

TL;DR: SILVI是一个开源标注工具，填补了行为交互标注的空白，支持动物和人类行为的精细分析。


<details>
  <summary>Details</summary>
Motivation: 现有工具无法同时支持行为标注和交互定位，限制了精细行为分析的发展。

Method: 开发了一个名为SILVI的开源标注软件，支持在视频数据中直接标注行为和交互，并生成结构化输出。

Result: SILVI成功整合了行为标注和交互定位功能，适用于动物行为分析，并可扩展至人类交互标注。

Conclusion: SILVI软件填补了现有开源标注工具在行为交互标注方面的空白，为行为生态学与计算机视觉的结合提供了实用工具。

Abstract: Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [4] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

TL;DR: 通过噪声注入技术提升COVID-19胸部X光检测模型的泛化能力，显著缩小了分布内外数据的性能差距。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在图像识别中容易依赖源特定伪影而非合理生物标志物，导致在分布外数据上泛化能力差，尤其是在COVID-19的胸部X光检测中。

Method: 研究采用了四种噪声注入技术（高斯、斑点、泊松和椒盐噪声）在训练过程中，以增强模型对分布偏移的鲁棒性。

Result: 实验结果表明，噪声注入技术将ID和OOD评估的性能差距从0.10-0.20显著降低至0.01-0.06（基于AUC、F1、准确率、召回率和特异性等关键指标的平均结果）。

Conclusion: 通过噪声注入技术（高斯、斑点、泊松和椒盐噪声），本研究显著缩小了模型在分布内（ID）和分布外（OOD）数据上的性能差距，提升了COVID-19检测模型的泛化能力。

Abstract: Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [5] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

TL;DR: Imitation learning shows promise for X-ray-guided spine procedures, with a 68.5% first-attempt success rate in simulations, but challenges remain in entry point precision and closed-loop feedback.


<details>
  <summary>Details</summary>
Motivation: The motivation was to examine whether imitation learning-based robot control policies, which are gaining traction in video-based robotics, could be applied to complex X-ray-guided procedures like spine instrumentation, given the challenges in interpreting multi-view X-rays.

Method: The researchers developed an in-silico sandbox for realistic simulation of X-ray-guided spine procedures, curated a dataset of correct trajectories and bi-planar X-ray sequences, and trained imitation learning policies for planning and open-loop control based on visual information.

Result: The policy achieved success on the first attempt in 68.5% of cases, maintained safe trajectories across diverse vertebral levels, generalized to complex anatomy (e.g., fractures), and remained robust to varied initializations. Rollouts on real bi-planar X-rays suggested plausible trajectories despite simulation-only training.

Conclusion: The study explores the potential of imitation learning in X-ray-guided spine procedures, demonstrating promising results but also highlighting limitations in entry point precision and the need for more robust priors and domain knowledge for full closed-loop control.

Abstract: Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [6] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

TL;DR: 提出了一种基于轻量级YOLOv12和改进训练的实时废物检测框架，特别针对沙漠环境，显著提升了检测性能并适合无人机部署。


<details>
  <summary>Details</summary>
Motivation: 全球废物危机加剧，传统废物收集方法在偏远或恶劣环境中效率低下且危险，现有研究多集中于城市环境和可回收材料，忽略了有机和危险废物及未充分探索的地形如沙漠。

Method: 基于修剪、轻量级的YOLOv12版本，集成了自对抗训练（SAT）和专用数据增强策略。

Result: 使用DroneTrashNet数据集，展示了在精确率、召回率和平均精度（mAP）上的显著改进，同时实现了低延迟和紧凑模型尺寸，适合部署在资源受限的空中无人机上。

Conclusion: 结合数据和模型中心增强的方法在沙漠环境中实现了稳健、实时的废物检测，验证了其有效性。

Abstract: The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [7] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

TL;DR: 论文提出类基图像合成方法，通过融合同类图像增强模型性能，在OCT数据集上取得近乎完美的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决小样本、不平衡数据集和图像质量差导致的深度学习模型误预测率高的问题。

Method: 通过将同一类别的多张图像融合成复合图像（CoImg），增加类内方差和信息密度。

Result: 在OCTDL数据集上，使用CoImg的方法使模型准确率达到99.6%，F1-score为0.995，AUC为0.9996，显著优于基线模型。

Conclusion: 该论文提出的类基图像合成方法显著提升了模型在小样本和不平衡数据集上的性能，降低了误预测率。

Abstract: Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [8] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

TL;DR: 该论文提出了一种无监督医学影像异常检测框架，通过轻量适配器和双重门控机制动态扩展正常样本集，在多个数据集上显著提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的未知异常检测因标注稀缺和专家监督成本高而面临挑战，需要一种无需异常标签的高效无监督方法。

Method: 通过冻结预训练视觉主干网络并添加轻量级卷积适配器，结合基于距离和不确定性的双重概率门控机制，动态扩展可信正常样本集，避免生成重建或回放缓冲的计算开销。

Result: 在COVID-CXR、Pneumonia CXR和Brain MRI ND-5数据集上，ROC-AUC和PR-AUC等指标显著提升，例如COVID-CXR的ROC-AUC从0.9489提升至0.9982。

Conclusion: 该论文提出的无监督、无需专家标注的框架在医学影像异常检测中表现出色，显著提升了多个数据集上的性能指标（如ROC-AUC和F1分数），验证了其在标签稀缺场景下的有效性和实用性。

Abstract: Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [9] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

TL;DR: 论文提出BDR和ATR方法，优化时间动作定位的边界检测和计算效率，BDR提升边界峰值43%，ATR减少18%计算量同时提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前时间动作定位方法在边界检测上采用统一计算，未能考虑到不同边界难度的显著差异，导致效率低下。

Method: 论文提出了两种方法：1）边界距离回归（BDR），通过符号距离回归代替分类，实现信息论最优定位；2）自适应时间细化（ATR），通过连续深度选择动态分配计算资源。

Result: BDR在现有方法上仅需约50行代码即可实现1.8%至3.1%的mAP@0.7提升；ATR在THUMOS14上以162G FLOPs实现56.5% mAP@0.7，比统一处理的53.6%提升了2.9%，同时减少18%计算量。短动作上的改进达4.2%。

Conclusion: 论文通过引入边界距离回归（BDR）和自适应时间细化（ATR）两种方法，显著提升了时间动作定位的边界检测精度和计算效率，并在多个基准测试中验证了其有效性。

Abstract: Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>


### [10] [Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization](https://arxiv.org/abs/2511.03950)
*Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang*

Main category: cs.CV

TL;DR: 该论文提出高斯-网格联合优化方法，统一处理几何和外观优化，实现高质量3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将几何精度（多视图立体）和逼真渲染（新视图合成）分开优化，阻碍了下游编辑任务。

Method: 提出了一种新颖框架，通过高斯引导的网格可微分渲染同时优化网格几何（顶点位置和面）和顶点颜色，利用输入图像的光度一致性和法线及深度图的几何正则化。

Result: 实现了高质量的3D重建，适用于如重新照明和形状变形等下游编辑任务。

Conclusion: 该论文提出了一种统一处理几何和外观优化的方法，通过高斯-网格联合优化实现了高质量的3D重建，适用于下游编辑任务。

Abstract: Reconstructing real-world objects from multi-view images is essential for
applications in 3D editing, AR/VR, and digital content creation. Existing
methods typically prioritize either geometric accuracy (Multi-View Stereo) or
photorealistic rendering (Novel View Synthesis), often decoupling geometry and
appearance optimization, which hinders downstream editing tasks. This paper
advocates an unified treatment on geometry and appearance optimization for
seamless Gaussian-mesh joint optimization. More specifically, we propose a
novel framework that simultaneously optimizes mesh geometry (vertex positions
and faces) and vertex colors via Gaussian-guided mesh differentiable rendering,
leveraging photometric consistency from input images and geometric
regularization from normal and depth maps. The obtained high-quality 3D
reconstruction can be further exploit in down-stream editing tasks, such as
relighting and shape deformation. The code will be publicly available upon
acceptance.

</details>


### [11] [A Linear Fractional Transformation Model and Calibration Method for Light Field Camera](https://arxiv.org/abs/2511.03962)
*Zhong Chen,Changfeng Chen*

Main category: cs.CV

TL;DR: 提出线性分数变换参数解耦主镜头和微透镜阵列，结合最小二乘和非线性优化，实验验证性能并加速光场图像模拟。


<details>
  <summary>Details</summary>
Motivation: 精确校准内部参数是使用光场相机进行3D重建的关键但具有挑战性的前提。

Method: 方法包括基于最小二乘的解析解和非线性优化，以及从原始图像中检测特征的介绍。

Result: 在物理和模拟数据上的实验结果验证了所提方法的性能。

Conclusion: 该论文提出了一种基于线性分数变换（LFT）参数α的方法，成功解耦了主镜头和微透镜阵列（MLA），并通过实验验证了其性能。该方法还加速了原始光场图像的模拟，对数据驱动的深度学习方法至关重要。

Abstract: Accurate calibration of internal parameters is a crucial yet challenging
prerequisite for 3D reconstruction using light field cameras. In this paper, we
propose a linear fractional transformation(LFT) parameter $\alpha$ to decoupled
the main lens and micro lens array (MLA). The proposed method includes an
analytical solution based on least squares, followed by nonlinear refinement.
The method for detecting features from the raw images is also introduced.
Experimental results on both physical and simulated data have verified the
performance of proposed method. Based on proposed model, the simulation of raw
light field images becomes faster, which is crucial for data-driven deep
learning methods. The corresponding code can be obtained from the author's
website.

</details>


### [12] [Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images](https://arxiv.org/abs/2511.03970)
*Sam Bahrami,Dylan Campbell*

Main category: cs.CV

TL;DR: 论文提出Room Envelopes数据集，通过RGB图像和点图直接监督单目几何估计器，以预测场景的可见表面和结构布局。


<details>
  <summary>Details</summary>
Motivation: 尽管现代场景重建方法能够准确恢复3D表面，但通常忽略了被遮挡的部分。论文认为场景的结构元素（如墙壁、地板和天花板）相对容易预测，因为它们通常是平面、重复且简单的。

Method: 通过提供RGB图像和两个关联的点图（一个捕捉可见表面，另一个捕捉去除家具和固定装置后的结构布局），支持对单目几何估计器的直接监督。

Result: Room Envelopes数据集为单目几何估计器提供了直接监督，使其能够预测可见表面和结构布局表面。

Conclusion: 该论文提出了一种新的合成数据集（Room Envelopes），用于直接监督单目几何估计器，从而实现对场景结构和物体形状及位置的理解。

Abstract: Modern scene reconstruction methods are able to accurately recover 3D
surfaces that are visible in one or more images. However, this leads to
incomplete reconstructions, missing all occluded surfaces. While much progress
has been made on reconstructing entire objects given partial observations using
generative models, the structural elements of a scene, like the walls, floors
and ceilings, have received less attention. We argue that these scene elements
should be relatively easy to predict, since they are typically planar,
repetitive and simple, and so less costly approaches may be suitable. In this
work, we present a synthetic dataset -- Room Envelopes -- that facilitates
progress on this task by providing a set of RGB images and two associated
pointmaps for each image: one capturing the visible surface and one capturing
the first surface once fittings and fixtures are removed, that is, the
structural layout. As we show, this enables direct supervision for feed-forward
monocular geometry estimators that predict both the first visible surface and
the first layout surface. This confers an understanding of the scene's extent,
as well as the shape and location of its objects.

</details>


### [13] [Simple 3D Pose Features Support Human and Machine Social Scene Understanding](https://arxiv.org/abs/2511.03988)
*Wenshuo Qin,Leyla Isik*

Main category: cs.CV

TL;DR: 研究发现人类依赖3D姿态信息判断社交互动，此类信息在多数AI视觉模型中缺失。通过提取3D姿态特征，可显著提升AI模型的社交判断能力。


<details>
  <summary>Details</summary>
Motivation: 理解人类如何从视觉输入中快速提取社交信息，以及AI视觉系统在此类任务中的局限性。

Method: 结合最先进的姿态和深度估计算法，提取短片中人物的3D关节位置，并与当前AI视觉模型对比预测能力。

Result: 3D关节位置优于大多数AI视觉模型，简化的3D社交姿态特征同样有效，并能提升现成AI模型的性能。

Conclusion: 人类社交场景理解依赖于3D姿态的明确表征，且可通过简单的结构化视觉空间基元来支持。

Abstract: Humans can quickly and effortlessly extract a variety of information about
others' social interactions from visual input, ranging from visuospatial cues
like whether two people are facing each other to higher-level information. Yet,
the computations supporting these abilities remain poorly understood, and
social interaction recognition continues to challenge even the most advanced AI
vision systems. Here, we hypothesized that humans rely on 3D visuospatial pose
information to make social interaction judgments, which is absent in most AI
vision models. To test this, we combined state-of-the-art pose and depth
estimation algorithms to extract 3D joint positions of people in short video
clips depicting everyday human actions and compared their ability to predict
human social interaction judgments with current AI vision models. Strikingly,
3D joint positions outperformed most current AI vision models, revealing that
key social information is available in explicit body position but not in the
learned features of most vision models, including even the layer-wise
embeddings of the pose models used to extract joint positions. To uncover the
critical pose features humans use to make social judgments, we derived a
compact set of 3D social pose features describing only the 3D position and
direction of faces in the videos. We found that these minimal descriptors
matched the predictive strength of the full set of 3D joints and significantly
improved the performance of off-the-shelf AI vision models when combined with
their embeddings. Moreover, the degree to which 3D social pose features were
represented in each off-the-shelf AI vision model predicted the model's ability
to match human social judgments. Together, our findings provide strong evidence
that human social scene understanding relies on explicit representations of 3D
pose and can be supported by simple, structured visuospatial primitives.

</details>


### [14] [CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation](https://arxiv.org/abs/2511.03992)
*Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie*

Main category: cs.CV

TL;DR: CaRF通过GFCE和ITPVS技术，提升3D高斯场景中语言表达与区域定位的多视角一致性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨视角一致性上表现不足，主要依赖2D渲染伪监督和视角特定特征学习。CaRF旨在直接在3D高斯空间中操作，解决这一问题。

Method: CaRF框架采用Gaussian Field Camera Encoding（GFCE）将相机几何融入高斯文本交互，并利用In Training Paired View Supervision（ITPVS）在训练中对齐多视角的高斯logits。

Result: 在Ref LERF、LERF OVS和3D OVS数据集上，CaRF分别实现了16.8%、4.3%和2.0%的mIoU提升。

Conclusion: CaRF框架通过引入GFCE和ITPVS技术，显著提升了多视角一致性，并在多个基准数据集上优于现有方法，推动了3D场景理解的可靠性和一致性。

Abstract: Referring 3D Gaussian Splatting Segmentation (R3DGS) aims to interpret
free-form language expressions and localize the corresponding 3D regions in
Gaussian fields. While recent advances have introduced cross-modal alignment
between language and 3D geometry, existing pipelines still struggle with
cross-view consistency due to their reliance on 2D rendered pseudo supervision
and view specific feature learning. In this work, we present Camera Aware
Referring Field (CaRF), a fully differentiable framework that operates directly
in the 3D Gaussian space and achieves multi view consistency. Specifically,
CaRF introduces Gaussian Field Camera Encoding (GFCE), which incorporates
camera geometry into Gaussian text interactions to explicitly model view
dependent variations and enhance geometric reasoning. Building on this, In
Training Paired View Supervision (ITPVS) is proposed to align per Gaussian
logits across calibrated views during training, effectively mitigating single
view overfitting and exposing inter view discrepancies for optimization.
Extensive experiments on three representative benchmarks demonstrate that CaRF
achieves average improvements of 16.8%, 4.3%, and 2.0% in mIoU over state of
the art methods on the Ref LERF, LERF OVS, and 3D OVS datasets, respectively.
Moreover, this work promotes more reliable and view consistent 3D scene
understanding, with potential benefits for embodied AI, AR/VR interaction, and
autonomous perception.

</details>


### [15] [PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection](https://arxiv.org/abs/2511.03997)
*Peiyao Wang,Weining Wang,Qi Li*

Main category: cs.CV

TL;DR: PhysCorr 是一个新框架，通过 PhysicsRM 和 PhyDPO 提升视频生成的物理一致性，适用于多种模型，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频生成模型在感知质量上虽有进步，但生成的视频常违反物理合理性原则，阻碍了在具身AI、机器人等领域的应用。

Method: 提出了 PhysicsRM（双维度奖励模型）量化对象内部稳定性和对象间交互，并开发了 PhyDPO（直接偏好优化管道），结合对比反馈和物理感知重加权来引导生成物理一致的输出。

Result: PhysCorr 在多个基准测试中显著提升了物理真实感，同时保持了视觉质量和语义一致性。

Conclusion: PhysCorr 框架在提升视频生成的物理一致性方面取得了显著进展，同时保持了视觉保真度和语义对齐，为物理基础的可信视频生成迈出了关键一步。

Abstract: Recent advances in text-to-video generation have achieved impressive
perceptual quality, yet generated content often violates fundamental principles
of physical plausibility - manifesting as implausible object dynamics,
incoherent interactions, and unrealistic motion patterns. Such failures hinder
the deployment of video generation models in embodied AI, robotics, and
simulation-intensive domains. To bridge this gap, we propose PhysCorr, a
unified framework for modeling, evaluating, and optimizing physical consistency
in video generation. Specifically, we introduce PhysicsRM, the first
dual-dimensional reward model that quantifies both intra-object stability and
inter-object interactions. On this foundation, we develop PhyDPO, a novel
direct preference optimization pipeline that leverages contrastive feedback and
physics-aware reweighting to guide generation toward physically coherent
outputs. Our approach is model-agnostic and scalable, enabling seamless
integration into a wide range of video diffusion and transformer-based
backbones. Extensive experiments across multiple benchmarks demonstrate that
PhysCorr achieves significant improvements in physical realism while preserving
visual fidelity and semantic alignment. This work takes a critical step toward
physically grounded and trustworthy video generation.

</details>


### [16] [GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization](https://arxiv.org/abs/2511.04008)
*Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata*

Main category: cs.CV

TL;DR: GNN-MoE通过GNN路由和MoE框架提升ViT在领域泛化中的性能，实现高效轻量化。


<details>
  <summary>Details</summary>
Motivation: 针对领域泛化（DG）任务中预训练Vision Transformer（ViT）的高效适配问题，标准微调成本高且可能损害泛化能力，需要一种更高效的参数优化方法。

Method: 提出GNN-MoE框架，结合混合专家（MoE）和高效的Kronecker适配器，利用图神经网络（GNN）路由机制动态分配图像块给专家，替代传统的基于令牌的路由方式。

Result: GNN-MoE在多个领域泛化基准测试中达到或接近最优性能，同时保持高参数效率。

Conclusion: GNN-MoE通过基于图的上下文路由机制，在领域泛化任务中实现了高效且轻量化的性能提升，展示了其在稳健性和参数效率方面的优势。

Abstract: Domain generalization (DG) seeks robust Vision Transformer (ViT) performance
on unseen domains. Efficiently adapting pretrained ViTs for DG is challenging;
standard fine-tuning is costly and can impair generalization. We propose
GNN-MoE, enhancing Parameter-Efficient Fine-Tuning (PEFT) for DG with a
Mixture-of-Experts (MoE) framework using efficient Kronecker adapters. Instead
of token-based routing, a novel Graph Neural Network (GNN) router (GCN, GAT,
SAGE) operates on inter-patch graphs to dynamically assign patches to
specialized experts. This context-aware GNN routing leverages inter-patch
relationships for better adaptation to domain shifts. GNN-MoE achieves
state-of-the-art or competitive DG benchmark performance with high parameter
efficiency, highlighting the utility of graph-based contextual routing for
robust, lightweight DG.

</details>


### [17] [MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging](https://arxiv.org/abs/2511.04016)
*Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe*

Main category: cs.CV

TL;DR: MedDChest是一个专为胸透影像优化的ViT模型，通过领域内预训练和新型数据增强策略，显著提升诊断性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉模型在医学影像中因依赖自然图像预训练而导致的领域差距问题。

Method: 提出了一种新的内容感知数据增强策略——Guided Random Resized Crops，用于优化医学影像的裁剪效率，并从零开始在120万张多模态胸透影像数据集上预训练了MedDChest模型。

Result: MedDChest在多种下游诊断任务中显著优于基于ImageNet预训练的公开模型。

Conclusion: MedDChest通过大规模领域内预训练与特定领域数据增强的结合，显著提升了胸透影像诊断任务的性能，并公开模型权重以促进未来研究与应用。

Abstract: The performance of vision models in medical imaging is often hindered by the
prevailing paradigm of fine-tuning backbones pre-trained on out-of-domain
natural images. To address this fundamental domain gap, we propose MedDChest, a
new foundational Vision Transformer (ViT) model optimized specifically for
thoracic imaging. We pre-trained MedDChest from scratch on a massive, curated,
multimodal dataset of over 1.2 million images, encompassing different
modalities including Chest X-ray and Computed Tomography (CT) compiled from 10
public sources. A core technical contribution of our work is Guided Random
Resized Crops, a novel content-aware data augmentation strategy that biases
sampling towards anatomically relevant regions, overcoming the inefficiency of
standard cropping techniques on medical scans. We validate our model's
effectiveness by fine-tuning it on a diverse set of downstream diagnostic
tasks. Comprehensive experiments empirically demonstrate that MedDChest
significantly outperforms strong, publicly available ImageNet-pretrained
models. By establishing the superiority of large-scale, in-domain pre-training
combined with domain-specific data augmentation, MedDChest provides a powerful
and robust feature extractor that serves as a significantly better starting
point for a wide array of thoracic diagnostic tasks. The model weights will be
made publicly available to foster future research and applications.

</details>


### [18] [A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals](https://arxiv.org/abs/2511.04037)
*Arfina Rahman,Mahesh Banavar*

Main category: cs.CV

TL;DR: 本研究提出了一种基于PPG信号的轻量级生物识别认证框架，采用混合深度学习模型CVT-ConvMixer-LSTM，实验结果显示认证准确率达98%，适合移动和嵌入式安全应用。


<details>
  <summary>Details</summary>
Motivation: PPG信号因其非侵入性采集、固有的活体检测能力及适用于低成本可穿戴设备的特点，在生物识别认证领域受到关注。然而，PPG信号质量受运动伪影、光照变化和个体间生理变异性挑战，因此需要稳健的特征提取和分类方法。

Method: 研究提出了一个基于从低帧率指尖视频中提取的PPG信号的轻量级且经济高效的生物识别认证框架。信号预处理包括基线漂移去除、使用主成分分析（PCA）抑制运动伪影、带通滤波、基于傅里叶的重采样和幅度归一化。随后，通过连续小波变换（CWT）将一维PPG段转换为二维时频标度图，以捕捉瞬态心血管动态。开发了一个混合深度学习模型CVT-ConvMixer-LSTM，结合了卷积视觉变换器（CVT）和ConvMixer分支的空间特征以及长短期记忆网络（LSTM）的时间特征。

Result: 在46名受试者上的实验结果显示，认证准确率达到98%，验证了模型对噪声和个体间变异性的鲁棒性。

Conclusion: 所提出的系统因其高效性、可扩展性和固有的活体检测能力，非常适合现实世界的移动和嵌入式生物识别安全应用。

Abstract: Photoplethysmography (PPG) signals, which measure changes in blood volume in
the skin using light, have recently gained attention in biometric
authentication because of their non-invasive acquisition, inherent liveness
detection, and suitability for low-cost wearable devices. However, PPG signal
quality is challenged by motion artifacts, illumination changes, and
inter-subject physiological variability, making robust feature extraction and
classification crucial. This study proposes a lightweight and cost-effective
biometric authentication framework based on PPG signals extracted from
low-frame-rate fingertip videos. The CFIHSR dataset, comprising PPG recordings
from 46 subjects at a sampling rate of 14 Hz, is employed for evaluation. The
raw PPG signals undergo a standard preprocessing pipeline involving baseline
drift removal, motion artifact suppression using Principal Component Analysis
(PCA), bandpass filtering, Fourier-based resampling, and amplitude
normalization. To generate robust representations, each one-dimensional PPG
segment is converted into a two-dimensional time-frequency scalogram via the
Continuous Wavelet Transform (CWT), effectively capturing transient
cardiovascular dynamics. We developed a hybrid deep learning model, termed
CVT-ConvMixer-LSTM, by combining spatial features from the Convolutional Vision
Transformer (CVT) and ConvMixer branches with temporal features from a Long
Short-Term Memory network (LSTM). The experimental results on 46 subjects
demonstrate an authentication accuracy of 98%, validating the robustness of the
model to noise and variability between subjects. Due to its efficiency,
scalability, and inherent liveness detection capability, the proposed system is
well-suited for real-world mobile and embedded biometric security applications.

</details>


### [19] [Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment](https://arxiv.org/abs/2511.04078)
*Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han*

Main category: cs.CV

TL;DR: Bratrix 是一种多模态语言锚定的视觉-大脑对齐框架，通过解耦视觉和语言语义、共享潜在空间和不确定性感知模块，显著提升了神经信号与视觉语义的对齐性能。


<details>
  <summary>Details</summary>
Motivation: 由于受试者变异性和视觉特征的纠缠性，现有方法直接对齐神经活动与视觉嵌入的效果有限，无法捕捉潜在的语义维度，影响了可解释性和鲁棒性。

Method: Bratrix 将视觉刺激解耦为层次化的视觉和语言语义组件，并将视觉和大脑表征投影到共享的潜在空间中，结合不确定性感知模块和两阶段训练策略（单模态预训练后多模态微调）。

Result: 在 EEG、MEG 和 fMRI 基准测试中，Bratrix 在检索、重建和描述任务中表现优异，尤其在 200 路 EEG 检索任务中提升 14.3%。

Conclusion: Bratrix 框架通过多模态语言锚定的视觉-大脑对齐方法，显著提高了神经信号与视觉语义的对齐精度，尤其在检索、重建和描述任务中表现优于现有方法。

Abstract: Unveiling visual semantics from neural signals such as EEG, MEG, and fMRI
remains a fundamental challenge due to subject variability and the entangled
nature of visual features. Existing approaches primarily align neural activity
directly with visual embeddings, but visual-only representations often fail to
capture latent semantic dimensions, limiting interpretability and deep
robustness. To address these limitations, we propose Bratrix, the first
end-to-end framework to achieve multimodal Language-Anchored Vision-Brain
alignment. Bratrix decouples visual stimuli into hierarchical visual and
linguistic semantic components, and projects both visual and brain
representations into a shared latent space, enabling the formation of aligned
visual-language and brain-language embeddings. To emulate human-like perceptual
reliability and handle noisy neural signals, Bratrix incorporates a novel
uncertainty perception module that applies uncertainty-aware weighting during
alignment. By leveraging learnable language-anchored semantic matrices to
enhance cross-modal correlations and employing a two-stage training strategy of
single-modality pretraining followed by multimodal fine-tuning, Bratrix-M
improves alignment precision. Extensive experiments on EEG, MEG, and fMRI
benchmarks demonstrate that Bratrix improves retrieval, reconstruction, and
captioning performance compared to state-of-the-art methods, specifically
surpassing 14.3% in 200-way EEG retrieval task. Code and model are available.

</details>


### [20] [Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score](https://arxiv.org/abs/2511.04083)
*Abu Hanif Muhammad Syarubany*

Main category: cs.CV

TL;DR: CycleGAN和Noise2Score在无配对CT图像去噪中表现优异，CycleGAN质量更优，Noise2Score适用于无清洁配对数据场景。


<details>
  <summary>Details</summary>
Motivation: 研究在无配对和自监督条件下CT图像去噪的效果。

Method: 研究了两种训练数据高效的范式：基于CycleGAN的残差翻译器和Noise2Score（N2S）得分匹配去噪器。通过配置扫描确定了CycleGAN中的标准U-Net骨干网络（lambda_cycle = 30, lambda_iden = 2, ngf = ndf = 64）为最可靠设置，并进行了长时间训练以达到收敛。

Result: CycleGAN将噪声输入从34.66 dB / 0.9234 SSIM提升到38.913 dB / 0.971 SSIM，并获得估计得分1.9441和未见数据集（Kaggle排行榜）得分1.9343。Noise2Score在绝对PSNR / SSIM上稍逊，但在高噪声输入上表现优异。

Conclusion: CycleGAN在最终图像质量上表现最强，而Noise2Score提供了无需配对数据的稳健替代方案，性能具有竞争力。

Abstract: We study CT image denoising in the unpaired and self-supervised regimes by
evaluating two strong, training-data-efficient paradigms: a CycleGAN-based
residual translator and a Noise2Score (N2S) score-matching denoiser. Under a
common evaluation protocol, a configuration sweep identifies a simple standard
U-Net backbone within CycleGAN (lambda_cycle = 30, lambda_iden = 2, ngf = ndf =
64) as the most reliable setting; we then train it to convergence with a longer
schedule. The selected CycleGAN improves the noisy input from 34.66 dB / 0.9234
SSIM to 38.913 dB / 0.971 SSIM and attains an estimated score of 1.9441 and an
unseen-set (Kaggle leaderboard) score of 1.9343. Noise2Score, while slightly
behind in absolute PSNR / SSIM, achieves large gains over very noisy inputs,
highlighting its utility when clean pairs are unavailable. Overall, CycleGAN
offers the strongest final image quality, whereas Noise2Score provides a robust
pair-free alternative with competitive performance. Source code is available at
https://github.com/hanifsyarubany/CT-Scan-Image-Denoising-using-CycleGAN-and-Noise2Score.

</details>


### [21] [When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation](https://arxiv.org/abs/2511.04084)
*Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen*

Main category: cs.CV

TL;DR: UKAST combines KANs with Swin Transformers for efficient, data-scarce medical image segmentation, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Address the challenges of medical image segmentation, such as complex anatomical structures and limited annotated data, by improving the efficiency and data dependency of Transformer-based methods.

Method: Introduces UKAST, a U-Net like architecture integrating rational-function based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders, leveraging Group Rational KANs (GR-KANs) for better efficiency.

Result: UKAST achieves state-of-the-art performance on four diverse 2D and 3D medical image segmentation benchmarks, outperforming CNN- and Transformer-based baselines.

Conclusion: UKAST demonstrates the potential of KAN-enhanced Transformers in advancing data-efficient medical image segmentation, achieving superior performance even in data-scarce settings.

Abstract: Medical image segmentation is critical for accurate diagnostics and treatment
planning, but remains challenging due to complex anatomical structures and
limited annotated training data. CNN-based segmentation methods excel at local
feature extraction, but struggle with modeling long-range dependencies.
Transformers, on the other hand, capture global context more effectively, but
are inherently data-hungry and computationally expensive. In this work, we
introduce UKAST, a U-Net like architecture that integrates rational-function
based Kolmogorov-Arnold Networks (KANs) into Swin Transformer encoders. By
leveraging rational base functions and Group Rational KANs (GR-KANs) from the
Kolmogorov-Arnold Transformer (KAT), our architecture addresses the
inefficiencies of vanilla spline-based KANs, yielding a more expressive and
data-efficient framework with reduced FLOPs and only a very small increase in
parameter count compared to SwinUNETR. UKAST achieves state-of-the-art
performance on four diverse 2D and 3D medical image segmentation benchmarks,
consistently surpassing both CNN- and Transformer-based baselines. Notably, it
attains superior accuracy in data-scarce settings, alleviating the data-hungry
limitations of standard Vision Transformers. These results show the potential
of KAN-enhanced Transformers to advance data-efficient medical image
segmentation. Code is available at: https://github.com/nsapkota417/UKAST

</details>


### [22] [SpatialLock: Precise Spatial Control in Text-to-Image Synthesis](https://arxiv.org/abs/2511.04112)
*Biao Liu,Yuanzhi Liang*

Main category: cs.CV

TL;DR: SpatialLock是一种新型框架，通过PoI和PoG组件联合控制物体空间位置，显著提升生成图像的定位精度和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成图像时未能充分利用位置信息，导致对物体空间布局的理解不足。

Method: SpatialLock框架包含两个核心组件：Position-Engaged Injection (PoI) 和 Position-Guided Learning (PoG)。PoI通过注意力层直接整合空间信息，PoG则利用感知监督进一步优化物体定位。

Result: 实验结果显示，SpatialLock在多个数据集上实现了IOU分数超过0.9，为精确物体定位设定了新的技术标杆。

Conclusion: SpatialLock通过结合感知信号和定位信息，实现了对生成图像中物体空间位置的精确控制，显著提升了生成图像的质量和定位准确性。

Abstract: Text-to-Image (T2I) synthesis has made significant advancements in recent
years, driving applications such as generating datasets automatically. However,
precise control over object localization in generated images remains a
challenge. Existing methods fail to fully utilize positional information,
leading to an inadequate understanding of object spatial layouts. To address
this issue, we propose SpatialLock, a novel framework that leverages perception
signals and grounding information to jointly control the generation of spatial
locations. SpatialLock incorporates two components: Position-Engaged Injection
(PoI) and Position-Guided Learning (PoG). PoI directly integrates spatial
information through an attention layer, encouraging the model to learn the
grounding information effectively. PoG employs perception-based supervision to
further refine object localization. Together, these components enable the model
to generate objects with precise spatial arrangements and improve the visual
quality of the generated images. Experiments show that SpatialLock sets a new
state-of-the-art for precise object positioning, achieving IOU scores above 0.9
across multiple datasets.

</details>


### [23] [Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration](https://arxiv.org/abs/2511.04117)
*Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim*

Main category: cs.CV

TL;DR: THG是一种无训练策略，通过多速率ODE系统优化扩散采样，减少30%计算量且保真度几乎无损。


<details>
  <summary>Details</summary>
Motivation: 传统扩散采样方法在计算效率上存在冗余，未能充分利用额外引导项的鲁棒性，导致计算资源浪费。

Method: 提出了一种无训练策略Tortoise and Hare Guidance (THG)，通过将CFG ODE重新表述为多速率ODE系统，利用噪声估计和额外引导项对数值误差的不同敏感性，显著减少额外引导的计算量。还引入了误差边界感知的时间步采样器和引导尺度调度器。

Result: THG在几乎不损失生成保真度的情况下，将函数评估次数减少高达30%，并在相同计算预算下优于现有基于CFG的无训练加速器。

Conclusion: THG通过多速率ODE系统显著提升了扩散采样的效率，同时保持了高保真度生成，无需重新训练模型，为实时高质量图像合成开辟了新途径。

Abstract: In this paper, we propose Tortoise and Hare Guidance (THG), a training-free
strategy that accelerates diffusion sampling while maintaining high-fidelity
generation. We demonstrate that the noise estimate and the additional guidance
term exhibit markedly different sensitivity to numerical error by reformulating
the classifier-free guidance (CFG) ODE as a multirate system of ODEs. Our
error-bound analysis shows that the additional guidance branch is more robust
to approximation, revealing substantial redundancy that conventional solvers
fail to exploit. Building on this insight, THG significantly reduces the
computation of the additional guidance: the noise estimate is integrated with
the tortoise equation on the original, fine-grained timestep grid, while the
additional guidance is integrated with the hare equation only on a coarse grid.
We also introduce (i) an error-bound-aware timestep sampler that adaptively
selects step sizes and (ii) a guidance-scale scheduler that stabilizes large
extrapolation spans. THG reduces the number of function evaluations (NFE) by up
to 30% with virtually no loss in generation fidelity ($\Delta$ImageReward
$\leq$ 0.032) and outperforms state-of-the-art CFG-based training-free
accelerators under identical computation budgets. Our findings highlight the
potential of multirate formulations for diffusion solvers, paving the way for
real-time high-quality image synthesis without any model retraining. The source
code is available at https://github.com/yhlee-add/THG.

</details>


### [24] [BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems](https://arxiv.org/abs/2511.04388)
*Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang*

Main category: cs.CV

TL;DR: 提出轻量级单目深度估计模型BoRe-Depth，通过EFAF模块和语义知识集成，显著提升边界质量和运行效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有单目深度估计方法在嵌入式系统上性能不佳和边界模糊的问题。

Method: 提出了增强特征自适应融合模块（EFAF）和将语义知识集成到编码器中的方法，以提升边界细节表示和物体识别能力。

Result: BoRe-Depth仅含8.7M参数，在NVIDIA Jetson Orin上以50.7 FPS高效运行，显著提升了边界质量和深度估计性能。

Conclusion: BoRe-Depth模型在嵌入式系统上实现了高效的深度估计，显著提升了边界质量和运行效率，并在多个数据集上优于现有轻量级模型。

Abstract: Depth estimation is one of the key technologies for realizing 3D perception
in unmanned systems. Monocular depth estimation has been widely researched
because of its low-cost advantage, but the existing methods face the challenges
of poor depth estimation performance and blurred object boundaries on embedded
systems. In this paper, we propose a novel monocular depth estimation model,
BoRe-Depth, which contains only 8.7M parameters. It can accurately estimate
depth maps on embedded systems and significantly improves boundary quality.
Firstly, we design an Enhanced Feature Adaptive Fusion Module (EFAF) which
adaptively fuses depth features to enhance boundary detail representation.
Secondly, we integrate semantic knowledge into the encoder to improve the
object recognition and boundary perception capabilities. Finally, BoRe-Depth is
deployed on NVIDIA Jetson Orin, and runs efficiently at 50.7 FPS. We
demonstrate that the proposed model significantly outperforms previous
lightweight models on multiple challenging datasets, and we provide detailed
ablation studies for the proposed methods. The code is available at
https://github.com/liangxiansheng093/BoRe-Depth.

</details>


### [25] [Text to Sketch Generation with Multi-Styles](https://arxiv.org/abs/2511.04123)
*Tengjie Li,Shikui Tu,Lei Xu*

Main category: cs.CV

TL;DR: M3S是一个基于扩散模型的框架，通过文本提示和参考草图实现高质量的草图生成，具有精确的风格控制。


<details>
  <summary>Details</summary>
Motivation: 现有的草图生成方法缺乏对风格精确控制的机制，M3S旨在解决这一问题。

Method: 提出了一种基于扩散模型的训练免费框架，通过线性平滑和风格-内容引导机制整合参考特征。

Result: 实验证明M3S在草图生成中实现了高质量的风格对齐和更灵活的风格控制。

Conclusion: M3S框架通过结合文本提示和参考草图实现了高质量的草图生成，具有精确的风格对齐和增强的灵活性。

Abstract: Recent advances in vision-language models have facilitated progress in sketch
generation. However, existing specialized methods primarily focus on generic
synthesis and lack mechanisms for precise control over sketch styles. In this
work, we propose a training-free framework based on diffusion models that
enables explicit style guidance via textual prompts and referenced style
sketches. Unlike previous style transfer methods that overwrite key and value
matrices in self-attention, we incorporate the reference features as auxiliary
information with linear smoothing and leverage a style-content guidance
mechanism. This design effectively reduces content leakage from reference
sketches and enhances synthesis quality, especially in cases with low
structural similarity between reference and target sketches. Furthermore, we
extend our framework to support controllable multi-style generation by
integrating features from multiple reference sketches, coordinated via a joint
AdaIN module. Extensive experiments demonstrate that our approach achieves
high-quality sketch generation with accurate style alignment and improved
flexibility in style control. The official implementation of M3S is available
at https://github.com/CMACH508/M3S.

</details>


### [26] [Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)](https://arxiv.org/abs/2511.04126)
*Venkata Manikanta Desu,Syed Fawaz Ali*

Main category: cs.CV

TL;DR: 该研究提出了一种结合多个深度学习模型的自动化网球比赛分析系统，能实时追踪球员和球，并提供详细比赛数据。


<details>
  <summary>Details</summary>
Motivation: 开发一个完整的自动化网球比赛分析框架，以实时检测和追踪球员及网球，并识别场地关键点。

Method: 整合了多个深度学习模型，包括YOLOv8用于球员检测、自定义训练的YOLOv5用于球追踪，以及基于ResNet50的场地关键点检测架构。

Result: 系统能够生成带有详细性能指标的注释视频，包括球员移动模式、球速、击球准确性和球员反应时间。

Conclusion: 该研究提出的自动化网球比赛分析系统在多种场地条件和比赛场景下表现稳健，能够为教练、解说员和球员提供可操作的比赛动态洞察。

Abstract: This study presents a complete pipeline for automated tennis match analysis.
Our framework integrates multiple deep learning models to detect and track
players and the tennis ball in real time, while also identifying court
keypoints for spatial reference. Using YOLOv8 for player detection, a
custom-trained YOLOv5 model for ball tracking, and a ResNet50-based
architecture for court keypoint detection, our system provides detailed
analytics including player movement patterns, ball speed, shot accuracy, and
player reaction times. The experimental results demonstrate robust performance
in varying court conditions and match scenarios. The model outputs an annotated
video along with detailed performance metrics, enabling coaches, broadcasters,
and players to gain actionable insights into the dynamics of the game.

</details>


### [27] [DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms](https://arxiv.org/abs/2511.04128)
*Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia*

Main category: cs.CV

TL;DR: DMSORT是一种高效的海事多目标跟踪方法，通过并行分支和先进的特征提取技术，在复杂环境中实现了高性能和快速运行。


<details>
  <summary>Details</summary>
Motivation: 复杂海事环境常导致相机运动和视觉退化，对多目标跟踪(MOT)构成挑战，需要一种鲁棒的方法来确保安全航行和有效海事监控。

Method: 提出了一个高效的Dual-branch Maritime SORT (DMSORT)方法，包括并行跟踪器、可逆柱状检测网络(RCDN)、轻量级Transformer外观提取器(Li-TAE)和聚类优化的特征融合模块。

Result: DMSORT在新加坡海事数据集上表现出色，具有快速运行时间和高鲁棒性。

Conclusion: DMSORT方法在新加坡海事数据集上实现了最先进的性能，并在保持高身份一致性和对抖动和遮挡的鲁棒性的同时，达到了现有基于ReID的MOT框架中最快的运行时间。

Abstract: Accurate perception of the marine environment through robust multi-object
tracking (MOT) is essential for ensuring safe vessel navigation and effective
maritime surveillance. However, the complicated maritime environment often
causes camera motion and subsequent visual degradation, posing significant
challenges to MOT. To address this challenge, we propose an efficient
Dual-branch Maritime SORT (DMSORT) method for maritime MOT. The core of the
framework is a parallel tracker with affine compensation, which incorporates an
object detection and re-identification (ReID) branch, along with a dedicated
branch for dynamic camera motion estimation. Specifically, a Reversible
Columnar Detection Network (RCDN) is integrated into the detection module to
leverage multi-level visual features for robust object detection. Furthermore,
a lightweight Transformer-based appearance extractor (Li-TAE) is designed to
capture global contextual information and generate robust appearance features.
Another branch decouples platform-induced and target-intrinsic motion by
constructing a projective transformation, applying platform-motion compensation
within the Kalman filter, and thereby stabilizing true object trajectories.
Finally, a clustering-optimized feature fusion module effectively combines
motion and appearance cues to ensure identity consistency under noise,
occlusion, and drift. Extensive evaluations on the Singapore Maritime Dataset
demonstrate that DMSORT achieves state-of-the-art performance. Notably, DMSORT
attains the fastest runtime among existing ReID-based MOT frameworks while
maintaining high identity consistency and robustness to jitter and occlusion.
Code is available at:
https://github.com/BiscuitsLzy/DMSORT-An-efficient-parallel-maritime-multi-object-tracking-architecture-.

</details>


### [28] [Learning from Online Videos at Inference Time for Computer-Use Agents](https://arxiv.org/abs/2511.04137)
*Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang*

Main category: cs.CV

TL;DR: 该论文提出了一种框架，使计算机使用代理能从在线视频中学习，通过动态选择结构化演示轨迹作为上下文指导，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机使用代理在自动化任务方面取得了进展，但在需要领域特定知识的任务中仍落后于人类。人类通过观看视频教程学习，而代理缺乏这种能力。本文旨在让代理也能从在线视频中学习。

Method: 提出了一种框架，包括检索和过滤教程视频、将视频转换为结构化演示轨迹、以及动态选择轨迹作为上下文指导。具体使用了视觉语言模型（VLM）推断UI动作、将视频分段并分配文本目标，并通过两阶段选择机制动态选择轨迹。

Result: 实验表明，该框架在两个广泛使用的基准测试中显著优于仅使用文本教程或转录的代理变体。分析强调了轨迹分割与选择、动作过滤和视觉信息的重要性。

Conclusion: 该框架通过从在线视频中提取结构化演示轨迹，并动态选择轨迹作为上下文指导，显著提升了计算机使用代理的性能，尤其是在需要领域特定知识的任务中。

Abstract: Computer-use agents can operate computers and automate laborious tasks, but
despite recent rapid progress, they still lag behind human users, especially
when tasks require domain-specific procedural knowledge about particular
applications, platforms, and multi-step workflows. Humans can bridge this gap
by watching video tutorials: we search, skim, and selectively imitate short
segments that match our current subgoal. In this paper, we study how to enable
computer-use agents to learn from online videos at inference time effectively.
We propose a framework that retrieves and filters tutorial videos, converts
them into structured demonstration trajectories, and dynamically selects
trajectories as in-context guidance during execution. Particularly, using a
VLM, we infer UI actions, segment videos into short subsequences of actions,
and assign each subsequence a textual objective. At inference time, a two-stage
selection mechanism dynamically chooses a single trajectory to add in context
at each step, focusing the agent on the most helpful local guidance for its
next decision. Experiments on two widely used benchmarks show that our
framework consistently outperforms strong base agents and variants that use
only textual tutorials or transcripts. Analyses highlight the importance of
trajectory segmentation and selection, action filtering, and visual
information, suggesting that abundant online videos can be systematically
distilled into actionable guidance that improves computer-use agents at
inference time. Our code is available at
https://github.com/UCSB-NLP-Chang/video_demo.

</details>


### [29] [Seeing Straight: Document Orientation Detection for Efficient OCR](https://arxiv.org/abs/2511.04161)
*Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: 研究提出ORB基准和基于Phi-3.5-Vision的旋转分类流水线，显著提升OCR在旋转图像中的性能，准确率高达96%。


<details>
  <summary>Details</summary>
Motivation: 在真实世界场景中，文档的正确方向确定是预处理的关键步骤，尤其是对于OCR任务，用户错误（如相机基础方向错误）常导致图像旋转问题。

Method: 研究提出了一个快速、鲁棒且轻量级的旋转分类流水线，基于Phi-3.5-Vision模型的视觉编码器，并采用动态图像裁剪技术，专门针对4类旋转任务进行微调。

Result: 该方法在ORB-En和ORB-Indic数据集上分别达到96%和92%的旋转识别准确率，并显著提升了闭源和开源OCR模型的性能（分别高达14%和4倍）。

Conclusion: 该研究通过引入OCR-Rotation-Bench（ORB）基准和基于Phi-3.5-Vision模型的轻量级旋转分类流水线，显著提升了OCR在图像旋转情况下的性能，证明了旋转校正对下游任务的重要性。

Abstract: Despite significant advances in document understanding, determining the
correct orientation of scanned or photographed documents remains a critical
pre-processing step in the real world settings. Accurate rotation correction is
essential for enhancing the performance of downstream tasks such as Optical
Character Recognition (OCR) where misalignment commonly arises due to user
errors, particularly incorrect base orientations of the camera during capture.
In this study, we first introduce OCR-Rotation-Bench (ORB), a new benchmark for
evaluating OCR robustness to image rotations, comprising (i) ORB-En, built from
rotation-transformed structured and free-form English OCR datasets, and (ii)
ORB-Indic, a novel multilingual set spanning 11 Indic mid to low-resource
languages. We also present a fast, robust and lightweight rotation
classification pipeline built on the vision encoder of Phi-3.5-Vision model
with dynamic image cropping, fine-tuned specifically for 4-class rotation task
in a standalone fashion. Our method achieves near-perfect 96% and 92% accuracy
on identifying the rotations respectively on both the datasets. Beyond
classification, we demonstrate the critical role of our module in boosting OCR
performance: closed-source (up to 14%) and open-weights models (up to 4x) in
the simulated real-world setting.

</details>


### [30] [Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology](https://arxiv.org/abs/2511.04171)
*Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz*

Main category: cs.CV

TL;DR: 研究发现CycleGAN颜色变换在多模态图像配准中表现最佳，显著提升对齐效果。


<details>
  <summary>Details</summary>
Motivation: 数字病理学中，多模态图像的准确配准是直接比较和整合信息的关键步骤，但不同染色或成像模态的差异增加了配准难度。

Method: 研究使用了20对组织样本，经过多种预处理步骤（包括CycleGAN、Macenko、Reinhard、Vahadane等颜色变换方法），并采用VALIS配准方法（先刚性配准，后非刚性配准）。配准性能通过相对目标配准误差（rTRE）评估。

Result: 在所有测试方法中，CycleGAN颜色变换的配准误差最低，其他方法表现较差。

Conclusion: 应用颜色变换（尤其是CycleGAN）在图像配准前能显著提高不同模态图像的对齐效果，支持数字病理学中更可靠的分析。

Abstract: Image registration refers to the process of spatially aligning two or more
images by mapping them into a common coordinate system, so that corresponding
anatomical or tissue structures are matched across images. In digital
pathology, registration enables direct comparison and integration of
information from different stains or imaging modalities, sup-porting
applications such as biomarker analysis and tissue reconstruction. Accurate
registration of images from different modalities is an essential step in
digital pathology. In this study, we investigated how various color
transformation techniques affect image registration between hematoxylin and
eosin (H&E) stained images and non-linear multimodal images. We used a dataset
of 20 tissue sample pairs, with each pair undergoing several preprocessing
steps, including different color transformation (CycleGAN, Macenko, Reinhard,
Vahadane), inversion, contrast adjustment, intensity normalization, and
denoising. All images were registered using the VALIS registration method,
which first applies rigid registration and then performs non-rigid registration
in two steps on both low and high-resolution images. Registration performance
was evaluated using the relative Target Registration Error (rTRE). We reported
the median of median rTRE values (MMrTRE) and the average of median rTRE values
(AMrTRE) for each method. In addition, we performed a custom point-based
evaluation using ten manually selected key points. Registration was done
separately for two scenarios, using either the original or inverted multimodal
images. In both scenarios, CycleGAN color transformation achieved the lowest
registration errors, while the other methods showed higher errors. These
findings show that applying color transformation before registration improves
alignment between images from different modalities and supports more reliable
analysis in digital pathology.

</details>


### [31] [Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification](https://arxiv.org/abs/2511.04190)
*Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel*

Main category: cs.CV

TL;DR: 协方差描述符与预训练视觉编码器（如DINOv2）结合，在医学图像分类中表现卓越，SPDNet在此组合下超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 协方差描述符在通用计算机视觉任务中表现优异，但在医学成像领域尚未充分探索。研究旨在验证其在传统和基于学习的医学图像分类中的有效性。

Method: 研究通过从预训练的通用视觉编码器（GVEs）提取特征构建协方差描述符，并与手工特征描述符进行比较。评估了DINOv2和MedSAM两种GVEs在MedMNSIT基准的11个数据集上的表现。

Result: 结果表明，基于GVE特征的协方差描述符 consistently 优于手工特征描述符，且SPDNet与DINOv2特征组合时性能最优。

Conclusion: 结合协方差描述符与预训练的视觉编码器（如DINOv2）在医学图像分析中表现出显著潜力，SPDNet在此组合下性能优于现有方法。

Abstract: Covariance descriptors capture second-order statistics of image features.
They have shown strong performance in general computer vision tasks, but remain
underexplored in medical imaging. We investigate their effectiveness for both
conventional and learning-based medical image classification, with a particular
focus on SPDNet, a classification network specifically designed for symmetric
positive definite (SPD) matrices. We propose constructing covariance
descriptors from features extracted by pre-trained general vision encoders
(GVEs) and comparing them with handcrafted descriptors. Two GVEs - DINOv2 and
MedSAM - are evaluated across eleven binary and multi-class datasets from the
MedMNSIT benchmark. Our results show that covariance descriptors derived from
GVE features consistently outperform those derived from handcrafted features.
Moreover, SPDNet yields superior performance to state-of-the-art methods when
combined with DINOv2 features. Our findings highlight the potential of
combining covariance descriptors with powerful pretrained vision encoders for
medical image analysis.

</details>


### [32] [AStF: Motion Style Transfer via Adaptive Statistics Fusor](https://arxiv.org/abs/2511.04192)
*Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng*

Main category: cs.CV

TL;DR: 论文提出AStF方法，通过引入高阶统计量（偏度和峰度）提升运动风格迁移效果，实验显示其优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖均值和方差进行风格迁移，无法充分捕捉运动数据的复杂动态模式和时空一致性特性，因此需要引入更高阶统计量。

Method: 提出了一种自适应统计融合器（AStF），包括风格解耦模块（SDM）和高阶多统计注意力机制（HOS-Attn），并结合运动一致性正则化（MCR）鉴别器进行训练。

Result: 实验结果表明，AStF在运动风格迁移任务中表现出色，优于现有方法。

Conclusion: 论文提出了一种新的自适应统计融合器（AStF），通过引入偏度和峰度等更高阶统计量，有效提升了运动风格迁移的性能，优于现有方法。

Abstract: Human motion style transfer allows characters to appear less rigidity and
more realism with specific style. Traditional arbitrary image style transfer
typically process mean and variance which is proved effective. Meanwhile,
similar methods have been adapted for motion style transfer. However, due to
the fundamental differences between images and motion, relying on mean and
variance is insufficient to fully capture the complex dynamic patterns and
spatiotemporal coherence properties of motion data. Building upon this, our key
insight is to bring two more coefficient, skewness and kurtosis, into the
analysis of motion style. Specifically, we propose a novel Adaptive Statistics
Fusor (AStF) which consists of Style Disentanglement Module (SDM) and
High-Order Multi-Statistics Attention (HOS-Attn). We trained our AStF in
conjunction with a Motion Consistency Regularization (MCR) discriminator.
Experimental results show that, by providing a more comprehensive model of the
spatiotemporal statistical patterns inherent in dynamic styles, our proposed
AStF shows proficiency superiority in motion style transfers over
state-of-the-arts. Our code and model are available at
https://github.com/CHMimilanlan/AStF.

</details>


### [33] [MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection](https://arxiv.org/abs/2511.04255)
*Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li*

Main category: cs.CV

TL;DR: MedSapiens 通过适应人类中心基础模型，在医学影像解剖标志检测中取得新最优性能，尤其在少标注数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统解剖标志检测依赖领域特定模型，而大规模预训练视觉模型的涌现提供了新机遇，但人类中心基础模型在此领域的潜力尚未充分挖掘。

Method: 通过多数据集预训练，将人类姿态估计的基础模型 Sapiens 适应于医学影像领域，构建了 MedSapiens。

Result: MedSapiens 在平均检测成功率上比通用模型提升 5.26%，比专业模型提升 21.81%，在少标注数据场景下比少样本最优模型提升 2.69%。

Conclusion: MedSapiens 展示了人类中心基础模型在医学影像解剖标志检测中的潜力，显著提升了检测成功率，并证明了其在少标注数据场景下的适应性。

Abstract: This paper does not introduce a novel architecture; instead, it revisits a
fundamental yet overlooked baseline: adapting human-centric foundation models
for anatomical landmark detection in medical imaging. While landmark detection
has traditionally relied on domain-specific models, the emergence of
large-scale pre-trained vision models presents new opportunities. In this
study, we investigate the adaptation of Sapiens, a human-centric foundation
model designed for pose estimation, to medical imaging through multi-dataset
pretraining, establishing a new state of the art across multiple datasets. Our
proposed model, MedSapiens, demonstrates that human-centric foundation models,
inherently optimized for spatial pose localization, provide strong priors for
anatomical landmark detection, yet this potential has remained largely
untapped. We benchmark MedSapiens against existing state-of-the-art models,
achieving up to 5.26% improvement over generalist models and up to 21.81%
improvement over specialist models in the average success detection rate (SDR).
To further assess MedSapiens adaptability to novel downstream tasks with few
annotations, we evaluate its performance in limited-data settings, achieving
2.69% improvement over the few-shot state of the art in SDR. Code and model
weights are available at https://github.com/xmed-lab/MedSapiens .

</details>


### [34] [Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery](https://arxiv.org/abs/2511.04260)
*Claudio Giusti,Luca Guarnera,Sebastiano Battiato*

Main category: cs.CV

TL;DR: Proto-LeakNet通过建模扩散模型潜在空间中的信号泄漏，实现高效、可解释的AI图像和Deepfake源归属，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着合成图像和Deepfake生成模型的日益复杂，源归属和真实性验证成为现代计算机视觉系统的关键挑战。扩散管道无意中在输出中留下统计痕迹（信号泄漏），尤其在潜在表示中，这为归因提供了新思路。

Method: Proto-LeakNet是一个信号泄漏感知且可解释的归因框架，结合封闭集分类和基于密度的开放集评估。方法在扩散模型的潜在域中运行，通过部分前向扩散重新模拟以暴露生成器特定的残留线索。使用时序注意力编码器聚合多步潜在特征，并通过特征加权原型头结构嵌入空间以实现透明归因。

Result: Proto-LeakNet在封闭数据训练下，Macro AUC达到98.13%，潜在几何结构在后处理下保持鲁棒，超越现有方法，并在已知与未见生成器间实现强分离性。

Conclusion: 建模潜在空间中的信号泄漏偏差可实现可靠且可解释的AI图像和Deepfake取证。Proto-LeakNet在封闭数据训练下，展现出对未见生成器的强分离性，并在后处理下保持鲁棒性。

Abstract: The growing sophistication of synthetic image and deepfake generation models
has turned source attribution and authenticity verification into a critical
challenge for modern computer vision systems. Recent studies suggest that
diffusion pipelines unintentionally imprint persistent statistical traces,
known as signal leaks, within their outputs, particularly in latent
representations. Building on this observation, we propose Proto-LeakNet, a
signal-leak-aware and interpretable attribution framework that integrates
closed-set classification with a density-based open-set evaluation on the
learned embeddings, enabling analysis of unseen generators without retraining.
Operating in the latent domain of diffusion models, our method re-simulates
partial forward diffusion to expose residual generator-specific cues. A
temporal attention encoder aggregates multi-step latent features, while a
feature-weighted prototype head structures the embedding space and enables
transparent attribution. Trained solely on closed data and achieving a Macro
AUC of 98.13%, Proto-LeakNet learns a latent geometry that remains robust under
post-processing, surpassing state-of-the-art methods, and achieves strong
separability between known and unseen generators. These results demonstrate
that modeling signal-leak bias in latent space enables reliable and
interpretable AI-image and deepfake forensics. The code for the whole work will
be available upon submission.

</details>


### [35] [DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification](https://arxiv.org/abs/2511.04281)
*Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li*

Main category: cs.CV

TL;DR: DinoGRL框架利用DINOv2学习步态特征，结合外观线索提升跨模态行人重识别性能，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖模态不变的视觉特征，忽视了步态特征的模态不变性和时空动态性，限制了跨模态视频匹配的性能。

Method: 提出DINOv2-Driven Gait Representation Learning (DinoGRL)框架，包含Semantic-Aware Silhouette and Gait Learning (SASGL)模型和Progressive Bidirectional Multi-Granularity Enhancement (PBMGE)模块，联合优化步态与外观特征。

Result: 在HITSZ-VCM和BUPT数据集上显著优于现有方法。

Conclusion: DinoGRL框架通过结合DINOv2的视觉先验和步态特征学习，显著提升了跨模态视频行人重识别的性能，实验结果表明其在HITSZ-VCM和BUPT数据集上优于现有方法。

Abstract: Video-based Visible-Infrared person re-identification (VVI-ReID) aims to
retrieve the same pedestrian across visible and infrared modalities from video
sequences. Existing methods tend to exploit modality-invariant visual features
but largely overlook gait features, which are not only modality-invariant but
also rich in temporal dynamics, thus limiting their ability to model the
spatiotemporal consistency essential for cross-modal video matching. To address
these challenges, we propose a DINOv2-Driven Gait Representation Learning
(DinoGRL) framework that leverages the rich visual priors of DINOv2 to learn
gait features complementary to appearance cues, facilitating robust
sequence-level representations for cross-modal retrieval. Specifically, we
introduce a Semantic-Aware Silhouette and Gait Learning (SASGL) model, which
generates and enhances silhouette representations with general-purpose semantic
priors from DINOv2 and jointly optimizes them with the ReID objective to
achieve semantically enriched and task-adaptive gait feature learning.
Furthermore, we develop a Progressive Bidirectional Multi-Granularity
Enhancement (PBMGE) module, which progressively refines feature representations
by enabling bidirectional interactions between gait and appearance streams
across multiple spatial granularities, fully leveraging their complementarity
to enhance global representations with rich local details and produce highly
discriminative features. Extensive experiments on HITSZ-VCM and BUPT datasets
demonstrate the superiority of our approach, significantly outperforming
existing state-of-the-art methods.

</details>


### [36] [FastGS: Training 3D Gaussian Splatting in 100 Seconds](https://arxiv.org/abs/2511.04283)
*Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu*

Main category: cs.CV

TL;DR: FastGS通过多视图一致性优化高斯数量，显著加速3DGS训练，保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有的3DGS加速方法未能有效调控高斯数量，导致计算冗余。

Method: 设计了一种基于多视图一致性的密集化和修剪策略，无需预算机制。

Result: 在多个数据集上实现了显著的训练加速（最高15.45倍），且渲染质量与现有方法相当。

Conclusion: FastGS显著提升了3D高斯喷溅（3DGS）的训练速度，同时保持了渲染质量，展现了广泛的适用性。

Abstract: The dominant 3D Gaussian splatting (3DGS) acceleration methods fail to
properly regulate the number of Gaussians during training, causing redundant
computational time overhead. In this paper, we propose FastGS, a novel, simple,
and general acceleration framework that fully considers the importance of each
Gaussian based on multi-view consistency, efficiently solving the trade-off
between training time and rendering quality. We innovatively design a
densification and pruning strategy based on multi-view consistency, dispensing
with the budgeting mechanism. Extensive experiments on Mip-NeRF 360, Tanks &
Temples, and Deep Blending datasets demonstrate that our method significantly
outperforms the state-of-the-art methods in training speed, achieving a
3.32$\times$ training acceleration and comparable rendering quality compared
with DashGaussian on the Mip-NeRF 360 dataset and a 15.45$\times$ acceleration
compared with vanilla 3DGS on the Deep Blending dataset. We demonstrate that
FastGS exhibits strong generality, delivering 2-7$\times$ training acceleration
across various tasks, including dynamic scene reconstruction, surface
reconstruction, sparse-view reconstruction, large-scale reconstruction, and
simultaneous localization and mapping. The project page is available at
https://fastgs.github.io/

</details>


### [37] [Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment](https://arxiv.org/abs/2511.04288)
*Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre*

Main category: cs.CV

TL;DR: 通过自监督学习训练领域特定基础模型，显著提升了除草剂试验中的物种识别和损害分类性能，并减少了标注需求。


<details>
  <summary>Details</summary>
Motivation: 虽然通用视觉基础模型在复杂视觉领域表现良好，但在农业领域中，对物种和损害类型的细粒度区分能力有限。

Method: 采用自监督学习方法在一个大型、经过整理的农业数据集上训练，优化了除草剂试验图像的表示。

Result: 领域特定模型在物种识别（F1分数从0.91提高到0.94）和损害分类（从0.26提高到0.33）上显著优于最佳通用基础模型，并在未见条件下（如新地点和其他时间）表现更佳。

Conclusion: 领域特定的基础模型在除草剂试验分析中展现出强大的泛化能力，显著减少了手动标注的工作量，提供了可扩展的自动化解决方案。

Abstract: Herbicide field trials require accurate identification of plant species and
assessment of herbicide-induced damage across diverse environments. While
general-purpose vision foundation models have shown promising results in
complex visual domains, their performance can be limited in agriculture, where
fine-grained distinctions between species and damage types are critical.
  In this work, we adapt a general-purpose vision foundation model to herbicide
trial characterization. Trained using a self-supervised learning approach on a
large, curated agricultural dataset, the model learns rich and transferable
representations optimized for herbicide trials images.
  Our domain-specific model significantly outperforms the best general-purpose
foundation model in both species identification (F1 score improvement from 0.91
to 0.94) and damage classification (from 0.26 to 0.33). Under unseen conditions
(new locations and other time), it achieves even greater gains (species
identification from 0.56 to 0.66; damage classification from 0.17 to 0.27). In
domain-shift scenarios, such as drone imagery, it maintains strong performance
(species classification from 0.49 to 0.60).
  Additionally, we show that domain-specific pretraining enhances segmentation
accuracy, particularly in low-annotation regimes. An annotation-efficiency
analysis reveals that, under unseen conditions, the domain-specific model
achieves 5.4% higher F1 score than the general-purpose model, while using 80%
fewer labeled samples.
  These results demonstrate the generalization capabilities of domain-specific
foundation models and their potential to significantly reduce manual annotation
efforts, offering a scalable and automated solution for herbicide trial
analysis.

</details>


### [38] [Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data](https://arxiv.org/abs/2511.04304)
*Robin Spanier,Thorsten Hoeser,Claudia Kuenzer*

Main category: cs.CV

TL;DR: 研究使用合成和真实卫星影像训练YOLOv10模型，提升海上基础设施检测性能，F1得分达0.90，展示了合成数据在解决数据不平衡问题中的有效性。


<details>
  <summary>Details</summary>
Motivation: 海洋基础设施的快速扩张需要有效的监测系统，但现有模型在样本稀缺时表现不佳，特别是对于代表性不足的物体类别、形状和大小。

Method: 通过训练基于深度学习的YOLOv10目标检测模型，结合合成和真实的Sentinel-1卫星影像（2023年第四季度从四个地区获取），研究合成训练数据对模型性能的提升。

Result: 模型在三个未见区域（墨西哥湾、北海、波斯湾）检测到3,529个海上平台，F1得分为0.85，加入合成数据后提升至0.90。

Conclusion: 本研究强调了平衡数据集的重要性，并展示了合成数据生成作为解决遥感中常见挑战的有效策略，证明了深度学习在可扩展的全球海上基础设施监测中的潜力。

Abstract: The recent and ongoing expansion of marine infrastructure, including offshore
wind farms, oil and gas platforms, artificial islands, and aquaculture
facilities, highlights the need for effective monitoring systems. The
development of robust models for offshore infrastructure detection relies on
comprehensive, balanced datasets, but falls short when samples are scarce,
particularly for underrepresented object classes, shapes, and sizes. By
training deep learning-based YOLOv10 object detection models with a combination
of synthetic and real Sentinel-1 satellite imagery acquired in the fourth
quarter of 2023 from four regions (Caspian Sea, South China Sea, Gulf of
Guinea, and Coast of Brazil), this study investigates the use of synthetic
training data to enhance model performance. We evaluated this approach by
applying the model to detect offshore platforms in three unseen regions (Gulf
of Mexico, North Sea, Persian Gulf) and thereby assess geographic
transferability. This region-holdout evaluation demonstrated that the model
generalises beyond the training areas. In total, 3,529 offshore platforms were
detected, including 411 in the North Sea, 1,519 in the Gulf of Mexico, and
1,593 in the Persian Gulf. The model achieved an F1 score of 0.85, which
improved to 0.90 upon incorporating synthetic data. We analysed how synthetic
data enhances the representation of unbalanced classes and overall model
performance, taking a first step toward globally transferable detection of
offshore infrastructure. This study underscores the importance of balanced
datasets and highlights synthetic data generation as an effective strategy to
address common challenges in remote sensing, demonstrating the potential of
deep learning for scalable, global offshore infrastructure monitoring.

</details>


### [39] [RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation](https://arxiv.org/abs/2511.04317)
*Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng*

Main category: cs.CV

TL;DR: RISE-T2V通过集成提示重述和语义特征提取，解决了现有文本到视频模型在简洁提示下质量不佳的问题，显著提升了生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有文本到视频扩散模型在简洁提示下难以保持视频质量，且缺乏在线重述提示的能力，限制了模型的扩展性和可用性。

Method: 提出了一种创新的Rephrasing Adapter模块，利用LLM的下一个令牌预测的文本隐藏状态作为视频生成的条件。

Result: 实验证明RISE-T2V适用于不同的视频扩散模型架构，显著提升了生成视频的质量和用户意图匹配度。

Conclusion: RISE-T2V通过集成提示重述和语义特征提取，显著提升了文本到视频任务的生成质量和对用户意图的匹配度。

Abstract: Most text-to-video(T2V) diffusion models depend on pre-trained text encoders
for semantic alignment, yet they often fail to maintain video quality when
provided with concise prompts rather than well-designed ones. The primary issue
lies in their limited textual semantics understanding. Moreover, these text
encoders cannot rephrase prompts online to better align with user intentions,
which limits both the scalability and usability of the models, To address these
challenges, we introduce RISE-T2V, which uniquely integrates the processes of
prompt rephrasing and semantic feature extraction into a single and seamless
step instead of two separate steps. RISE-T2V is universal and can be applied to
various pre-trained LLMs and video diffusion models(VDMs), significantly
enhancing their capabilities for T2V tasks. We propose an innovative module
called the Rephrasing Adapter, enabling diffusion models to utilize text hidden
states during the next token prediction of the LLM as a condition for video
generation. By employing a Rephrasing Adapter, the video generation model can
implicitly rephrase basic prompts into more comprehensive representations that
better match the user's intent. Furthermore, we leverage the powerful
capabilities of LLMs to enable video generation models to accomplish a broader
range of T2V tasks. Extensive experiments demonstrate that RISE-T2V is a
versatile framework applicable to different video diffusion model
architectures, significantly enhancing the ability of T2V models to generate
high-quality videos that align with user intent. Visual results are available
on the webpage at https://rise-t2v.github.io.

</details>


### [40] [Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography](https://arxiv.org/abs/2511.04334)
*Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez*

Main category: cs.CV

TL;DR: 提出一种基于体素稀疏化和子流形稀疏卷积网络的两阶段方法，显著减少3D肿瘤分割的计算资源需求，同时在KiTS23挑战赛中取得与最佳方法竞争的结果。


<details>
  <summary>Details</summary>
Motivation: 由于传统卷积神经网络在处理3D扫描时因体素数量庞大而需要降采样或使用图像块，导致资源消耗大且效率低，因此提出一种新方法以克服这一问题。

Method: 采用两阶段方法，结合体素稀疏化和子流形稀疏卷积网络，以实现高分辨率输入和原生3D模型架构的分割。

Result: 在KiTS23挑战赛中，该方法取得了95.8%（肾脏+肿块）、85.7%（肿瘤+囊肿）和80.3%（仅肿瘤）的Dice相似系数，并在计算资源上实现了高达60%的推理时间减少和75%的VRAM使用减少。

Conclusion: 本文提出的方法在保持高分辨率输入和原生3D模型架构的同时，显著减少了计算资源需求，并在肾癌CT图像分割任务中取得了与最佳方法竞争的结果。

Abstract: The accurate delineation of tumours in radiological images like Computed
Tomography is a very specialised and time-consuming task, and currently a
bottleneck preventing quantitative analyses to be performed routinely in the
clinical setting. For this reason, developing methods for the automated
segmentation of tumours in medical imaging is of the utmost importance and has
driven significant efforts in recent years. However, challenges regarding the
impracticality of 3D scans, given the large amount of voxels to be analysed,
usually requires the downsampling of such images or using patches thereof when
applying traditional convolutional neural networks. To overcome this problem,
in this paper we propose a new methodology that uses, divided into two stages,
voxel sparsification and submanifold sparse convolutional networks. This method
allows segmentations to be performed with high-resolution inputs and a native
3D model architecture, obtaining state-of-the-art accuracies while
significantly reducing the computational resources needed in terms of GPU
memory and time. We studied the deployment of this methodology in the context
of Computed Tomography images of renal cancer patients from the KiTS23
challenge, and our method achieved results competitive with the challenge
winners, with Dice similarity coefficients of 95.8% for kidneys + masses, 85.7%
for tumours + cysts, and 80.3% for tumours alone. Crucially, our method also
offers significant computational improvements, achieving up to a 60% reduction
in inference time and up to a 75\% reduction in VRAM usage compared to an
equivalent dense architecture, across both CPU and various GPU cards tested.

</details>


### [41] [Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset](https://arxiv.org/abs/2511.04344)
*Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif*

Main category: cs.CV

TL;DR: 评估九种CNN架构在VOC 2008数据集上的马和摩托车二元分类性能，ConvNeXt-Tiny表现最佳，数据增强有效缓解类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 解决VOC 2008数据集中马和摩托车的二元分类任务中显著的类别不平衡问题。

Method: 综合评估了九种卷积神经网络架构，包括ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer，采用少数类增强技术解决类别不平衡问题。

Result: 实验结果显示，ConvNeXt-Tiny在马检测中达到最高的平均精度（AP）95.53%，在摩托车检测中达到89.12%。数据增强显著改善了少数类检测，尤其对更深层架构有益。

Conclusion: 本研究为不平衡二元分类任务中的架构选择提供了见解，并量化了数据增强策略在缓解目标检测中的类别不平衡问题中的影响。

Abstract: This paper presents a comprehensive evaluation of nine convolutional neural
network architectures for binary classification of horses and motorcycles in
the VOC 2008 dataset. We address the significant class imbalance problem by
implementing minority-class augmentation techniques. Our experiments compare
modern architectures including ResNet-50, ConvNeXt-Tiny, DenseNet-121, and
Vision Transformer across multiple performance metrics. Results demonstrate
substantial performance variations, with ConvNeXt-Tiny achieving the highest
Average Precision (AP) of 95.53% for horse detection and 89.12% for motorcycle
detection. We observe that data augmentation significantly improves minority
class detection, particularly benefiting deeper architectures. This study
provides insights into architecture selection for imbalanced binary
classification tasks and quantifies the impact of data augmentation strategies
in mitigating class imbalance issues in object detection.

</details>


### [42] [Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection](https://arxiv.org/abs/2511.04347)
*Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising*

Main category: cs.CV

TL;DR: 研究BEVFusion架构中相机和LiDAR遮挡对3D检测的影响，发现LiDAR对系统性能更关键，需改进遮挡感知融合技术。


<details>
  <summary>Details</summary>
Motivation: 探索传感器遮挡（如雾、霾或物理障碍）对基于BEV的多传感器融合3D检测系统的影响，填补现有研究空白。

Method: 使用BEVFusion架构在nuScenes数据集上评估相机和LiDAR遮挡对3D检测精度的影响，性能指标为mAP和NDS。

Result: 相机遮挡导致mAP下降41.3%（仅依赖相机时），LiDAR在重度遮挡下mAP下降47.3%。融合模式下，LiDAR遮挡影响更大（mAP下降26.8%）。

Conclusion: 论文强调了未来研究需要关注遮挡感知评估方法及改进传感器融合技术，以在部分传感器失效或环境条件不佳时保持检测精度。

Abstract: Accurate 3D object detection is essential for automated vehicles to navigate
safely in complex real-world environments. Bird's Eye View (BEV)
representations, which project multi-sensor data into a top-down spatial
format, have emerged as a powerful approach for robust perception. Although
BEV-based fusion architectures have demonstrated strong performance through
multimodal integration, the effects of sensor occlusions, caused by
environmental conditions such as fog, haze, or physical obstructions, on 3D
detection accuracy remain underexplored. In this work, we investigate the
impact of occlusions on both camera and Light Detection and Ranging (LiDAR)
outputs using the BEVFusion architecture, evaluated on the nuScenes dataset.
Detection performance is measured using mean Average Precision (mAP) and the
nuScenes Detection Score (NDS). Our results show that moderate camera
occlusions lead to a 41.3% drop in mAP (from 35.6% to 20.9%) when detection is
based only on the camera. On the other hand, LiDAR sharply drops in performance
only under heavy occlusion, with mAP falling by 47.3% (from 64.7% to 34.1%),
with a severe impact on long-range detection. In fused settings, the effect
depends on which sensor is occluded: occluding the camera leads to a minor 4.1%
drop (from 68.5% to 65.7%), while occluding LiDAR results in a larger 26.8%
drop (to 50.1%), revealing the model's stronger reliance on LiDAR for the task
of 3D object detection. Our results highlight the need for future research into
occlusion-aware evaluation methods and improved sensor fusion techniques that
can maintain detection accuracy in the presence of partial sensor failure or
degradation due to adverse environmental conditions.

</details>


### [43] [A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications](https://arxiv.org/abs/2511.04349)
*Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols*

Main category: cs.CV

TL;DR: 该教程为分析化学领域提供了使用现有开源深度学习模型从成像数据中提取深度特征的逐步指南，填补了实施指导的空白。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在图像处理方面取得了显著进展，但由于缺乏结构化的实施指导，分析化学领域对这些技术的应用仍然有限。

Method: 教程提供了MATLAB代码演示，展示了如何处理分析化学中常见的各种成像数据，并指导读者在自己的数据集上运行这些代码。

Result: 教程成功展示了如何应用深度学习方法来提取成像数据的空间信息，并将其与其他数据源（如光谱信息）整合。

Conclusion: 该教程通过提供逐步指导，帮助分析化学领域的科研人员利用现有开源深度学习模型从成像数据中提取深度特征，解决了传统方法难以处理的空间信息分析问题。

Abstract: Background In analytical chemistry, spatial information about materials is
commonly captured through imaging techniques, such as traditional color cameras
or with advanced hyperspectral cameras and microscopes. However, efficiently
extracting and analyzing this spatial information for exploratory and
predictive purposes remains a challenge, especially when using traditional
chemometric methods. Recent advances in deep learning and artificial
intelligence have significantly enhanced image processing capabilities,
enabling the extraction of multiscale deep features that are otherwise
challenging to capture with conventional image processing techniques. Despite
the wide availability of open-source deep learning models, adoption in
analytical chemistry remains limited because of the absence of structured,
step-by-step guidance for implementing these models.
  Results This tutorial aims to bridge this gap by providing a step-by-step
guide for applying deep learning approaches to extract spatial information from
imaging data and integrating it with other data sources, such as spectral
information. Importantly, the focus of this work is not on training deep
learning models for image processing but on using existing open source models
to extract deep features from imaging data.
  Significance The tutorial provides MATLAB code tutorial demonstrations,
showcasing the processing of imaging data from various imaging modalities
commonly encountered in analytical chemistry. Readers must run the tutorial
steps on their own datasets using the codes presented in this tutorial.

</details>


### [44] [Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA](https://arxiv.org/abs/2511.04384)
*Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir*

Main category: cs.CV

TL;DR: A multi-task framework using LoRA-tuned Florence-2 model enhances medical VQA by jointly learning visual grounding, reasoning, and interpretation, outperforming single-task methods.


<details>
  <summary>Details</summary>
Motivation: To improve accuracy and interpretability in medical visual question answering (VQA) by enabling simultaneous learning of visual grounding, reasoning, and interpretation through a multi-task approach.

Method: The framework uses a LoRA-tuned Florence-2 model, integrating three datasets: Kvasir-VQA-x1 for question-answer learning, a synthetically enriched explanation dataset for medical reasoning, and text-to-region pairs for visual feature segmentation.

Result: The system demonstrates substantial improvements over single-task baselines in both answer accuracy and visual localization.

Conclusion: The proposed multi-task framework significantly enhances performance in medical VQA applications by jointly learning visual grounding, reasoning, and interpretation, outperforming single-task baselines in accuracy and visual localization.

Abstract: We present a multi-task framework for the MediaEval Medico 2025 challenge,
leveraging a LoRA-tuned Florence-2 model for simultaneous visual question
answering (VQA), explanation generation, and visual grounding. The proposed
system integrates three curated datasets: (1) Kvasir-VQA-x1 for question-answer
learning, (2) a synthetically enriched explanation dataset offering structured
medical reasoning, and (3) text-to-region pairs linking visual features with
segmentation masks. This multi-task setup enables the model to jointly learn
visual grounding, reasoning, and interpretation, producing responses that are
both accurate and interpretable. Extensive evaluation demonstrates that our
approach substantially improves over single-task baselines in both answer
accuracy and visual localization, highlighting the effectiveness of grounded
multi-task learning for medical VQA applications.

</details>


### [45] [DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale](https://arxiv.org/abs/2511.04394)
*Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue*

Main category: cs.CV

TL;DR: DORAEMON是一个开源PyTorch库，整合视觉对象建模和表示学习，提供多样化预训练模型和工具，支持快速实验和高效部署。


<details>
  <summary>Details</summary>
Motivation: 为了统一视觉对象建模和表示学习，提供一个可扩展的平台，支持快速实验，并促进研究成果向实际应用转化。

Method: DORAEMON是一个开源的PyTorch库，通过统一的YAML驱动工作流程支持分类、检索和度量学习，提供超过1000个预训练模型，并通过timm兼容接口、模块化损失、数据增强和分布式训练工具实现灵活配置。

Result: DORAEMON在ImageNet-1K、MS-Celeb-1M和Stanford在线产品等数据集上匹配或超过了参考结果，并支持一键导出到ONNX或HuggingFace，方便部署。

Conclusion: DORAEMON通过整合数据集、模型和训练技术，为视觉识别和表示学习提供了一个可扩展的平台，促进了研究成果向实际应用的高效转化。

Abstract: DORAEMON is an open-source PyTorch library that unifies visual object
modeling and representation learning across diverse scales. A single
YAML-driven workflow covers classification, retrieval and metric learning; more
than 1000 pretrained backbones are exposed through a timm-compatible interface,
together with modular losses, augmentations and distributed-training utilities.
Reproducible recipes match or exceed reference results on ImageNet-1K,
MS-Celeb-1M and Stanford online products, while one-command export to ONNX or
HuggingFace bridges research and deployment. By consolidating datasets, models,
and training techniques into one platform, DORAEMON offers a scalable
foundation for rapid experimentation in visual recognition and representation
learning, enabling efficient transfer of research advances to real-world
applications. The repository is available at https://github.com/wuji3/DORAEMON.

</details>


### [46] [HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats](https://arxiv.org/abs/2511.04426)
*Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois*

Main category: cs.CV

TL;DR: HideAndSeg是一种基于AI的工具，用于在缺乏大规模标注数据集的情况下分割章鱼视频，通过结合SAM2和YOLOv11实现自动化，并引入了无监督指标评估分割质量。


<details>
  <summary>Details</summary>
Motivation: 由于章鱼的自然栖息地中的伪装能力、快速变化的皮肤纹理和颜色、非刚性身体变形以及频繁的遮挡等因素，分析章鱼具有挑战性。

Method: 结合SAM2和自定义训练的YOLOv11对象检测器，首先通过用户提供的点坐标生成初始分割掩码，随后完全自动化流程。

Result: HideAndSeg在减少分割噪声方面表现满意，并能在完全遮挡后重新识别和分割章鱼。

Conclusion: HideAndSeg提供了一种实用的工具，减少了对人工分析的需求，为野生头足类动物的行为研究铺平了道路。

Abstract: Analyzing octopuses in their natural habitats is challenging due to their
camouflage capability, rapid changes in skin texture and color, non-rigid body
deformations, and frequent occlusions, all of which are compounded by variable
underwater lighting and turbidity. Addressing the lack of large-scale annotated
datasets, this paper introduces HideAndSeg, a novel, minimally supervised
AI-based tool for segmenting videos of octopuses. It establishes a quantitative
baseline for this task. HideAndSeg integrates SAM2 with a custom-trained
YOLOv11 object detector. First, the user provides point coordinates to generate
the initial segmentation masks with SAM2. These masks serve as training data
for the YOLO model. After that, our approach fully automates the pipeline by
providing a bounding box prompt to SAM2, eliminating the need for further
manual intervention. We introduce two unsupervised metrics - temporal
consistency $DICE_t$ and new component count $NC_t$ - to quantitatively
evaluate segmentation quality and guide mask refinement in the absence of
ground-truth data, i.e., real-world information that serves to train, validate,
and test AI models. Results show that HideAndSeg achieves satisfactory
performance, reducing segmentation noise compared to the manually prompted
approach. Our method can re-identify and segment the octopus even after periods
of complete occlusion in natural environments, a scenario in which the manually
prompted model fails. By reducing the need for manual analysis in real-world
scenarios, this work provides a practical tool that paves the way for more
efficient behavioral studies of wild cephalopods.

</details>


### [47] [Solving Convex Partition Visual Jigsaw Puzzles](https://arxiv.org/abs/2511.04450)
*Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar*

Main category: cs.CV

TL;DR: 本研究扩展了拼图求解器的应用范围，针对凸分区多边形拼图引入贪婪求解器和几何、图像兼容性，并提供了首个基准数据集。


<details>
  <summary>Details</summary>
Motivation: 现有大多数拼图求解器仅适用于方形拼图，限制了其实际应用。本研究旨在扩展计算处理的拼图类型，特别是针对凸分区多边形拼图。

Method: 结合几何和图像兼容性，引入贪婪求解器来处理凸分区多边形拼图。

Result: 成功扩展了拼图求解器的应用范围，提供了首个凸分区多边形拼图的基准数据集，并报告了多种性能指标。

Conclusion: 本研究通过引入贪婪求解器和结合几何与图像兼容性，成功扩展了计算处理的拼图类型，特别是针对凸分区多边形拼图，并提供了首个此类拼图的基准数据集。

Abstract: Jigsaw puzzle solving requires the rearrangement of unordered pieces into
their original pose in order to reconstruct a coherent whole, often an image,
and is known to be an intractable problem. While the possible impact of
automatic puzzle solvers can be disruptive in various application domains, most
of the literature has focused on developing solvers for square jigsaw puzzles,
severely limiting their practical use. In this work, we significantly expand
the types of puzzles handled computationally, focusing on what is known as
Convex Partitions, a major subset of polygonal puzzles whose pieces are convex.
We utilize both geometrical and pictorial compatibilities, introduce a greedy
solver, and report several performance measures next to the first benchmark
dataset of such puzzles.

</details>


### [48] [V-Thinker: Interactive Thinking with Images](https://arxiv.org/abs/2511.04460)
*Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang*

Main category: cs.CV

TL;DR: V-Thinker 是一个通用多模态推理助手，通过端到端强化学习实现视觉中心交互式思考，显著提升了图像交互推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大型多模态模型（LMMs）在深度整合图像交互与长时程推理能力方面的挑战，突破现有视觉工具空间和任务特定工作流设计的限制。

Method: V-Thinker 包含两个关键组件：(1) 数据进化飞轮，自动合成、进化和验证交互式推理数据集；(2) 视觉渐进式训练课程，通过点级监督对齐感知，再通过两阶段强化学习框架整合交互式推理。此外，还引入了专家验证的基准 VTBench。

Result: 实验表明，V-Thinker 在通用和交互式推理场景中均优于现有基线模型。

Conclusion: V-Thinker 在通用和交互式推理场景中均优于现有基于 LMM 的基线模型，为图像交互式推理应用的发展提供了有价值的见解。

Abstract: Empowering Large Multimodal Models (LMMs) to deeply integrate image
interaction with long-horizon reasoning capabilities remains a long-standing
challenge in this field. Recent advances in vision-centric reasoning explore a
promising "Thinking with Images" paradigm for LMMs, marking a shift from
image-assisted reasoning to image-interactive thinking. While this milestone
enables models to focus on fine-grained image regions, progress remains
constrained by limited visual tool spaces and task-specific workflow designs.
To bridge this gap, we present V-Thinker, a general-purpose multimodal
reasoning assistant that enables interactive, vision-centric thinking through
end-to-end reinforcement learning. V-Thinker comprises two key components: (1)
a Data Evolution Flywheel that automatically synthesizes, evolves, and verifies
interactive reasoning datasets across three dimensions-diversity, quality, and
difficulty; and (2) a Visual Progressive Training Curriculum that first aligns
perception via point-level supervision, then integrates interactive reasoning
through a two-stage reinforcement learning framework. Furthermore, we introduce
VTBench, an expert-verified benchmark targeting vision-centric interactive
reasoning tasks. Extensive experiments demonstrate that V-Thinker consistently
outperforms strong LMM-based baselines in both general and interactive
reasoning scenarios, providing valuable insights for advancing
image-interactive reasoning applications.

</details>


### [49] [Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability](https://arxiv.org/abs/2511.04474)
*Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu*

Main category: cs.CV

TL;DR: GeoFMs通过三轴框架和全球预训练，显著提升滑坡映射的准确性和泛化能力，但计算成本和可重用AI训练数据的可用性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习模型在不同传感器、区域或有限训练数据条件下表现不佳，需要更可靠的滑坡映射方法。

Method: 提出了一个三轴分析框架（传感器、标签、域）来适应地理空间基础模型（GeoFMs），重点关注Prithvi-EO-2.0，结合全球预训练、自监督和可调整的微调。

Result: GeoFMs在光谱变化、标签稀缺条件下保持准确性，并在多样化数据集和地理环境中表现优于任务特定CNN、视觉变换器和其他GeoFMs。

Conclusion: GeoFMs代表了一种更稳健、可扩展的方法，用于滑坡风险减少和环境监测。

Abstract: Landslides cause severe damage to lives, infrastructure, and the environment,
making accurate and timely mapping essential for disaster preparedness and
response. However, conventional deep learning models often struggle when
applied across different sensors, regions, or under conditions of limited
training data. To address these challenges, we present a three-axis analytical
framework of sensor, label, and domain for adapting geospatial foundation
models (GeoFMs), focusing on Prithvi-EO-2.0 for landslide mapping. Through a
series of experiments, we show that it consistently outperforms task-specific
CNNs (U-Net, U-Net++), vision transformers (Segformer, SwinV2-B), and other
GeoFMs (TerraMind, SatMAE). The model, built on global pretraining,
self-supervision, and adaptable fine-tuning, proved resilient to spectral
variation, maintained accuracy under label scarcity, and generalized more
reliably across diverse datasets and geographic settings. Alongside these
strengths, we also highlight remaining challenges such as computational cost
and the limited availability of reusable AI-ready training data for landslide
research. Overall, our study positions GeoFMs as a step toward more robust and
scalable approaches for landslide risk reduction and environmental monitoring.

</details>


### [50] [THEval. Evaluation Framework for Talking Head Video Generation](https://arxiv.org/abs/2511.04520)
*Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva*

Main category: cs.CV

TL;DR: 论文提出新评估框架，包含8个指标，实验发现现有算法在唇部同步表现好，但表情生成和无伪影细节仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 视频生成技术快速发展，但评估指标的开发滞后，当前评估主要依赖有限的指标和用户研究。因此，作者提出新的评估框架以弥补这一不足。

Method: 论文通过分析头部、嘴巴和眉毛的细粒度动态以及面部质量，选择高效的指标并考虑人类偏好，提出了包含8个指标的新评估框架。

Result: 在17个最先进模型生成的85,000个视频上进行实验，结果表明许多算法在唇部同步方面表现优异，但在表情生成和无伪影细节方面存在困难。

Conclusion: 该论文提出了一种新的评估框架，包含8个与质量、自然性和同步性相关的指标，旨在更全面地评估说话头部生成的视频。通过大量实验，发现现有算法在唇部同步方面表现良好，但在生成表情和无伪影细节方面仍有挑战。

Abstract: Video generation has achieved remarkable progress, with generated videos
increasingly resembling real ones. However, the rapid advance in generation has
outpaced the development of adequate evaluation metrics. Currently, the
assessment of talking head generation primarily relies on limited metrics,
evaluating general video quality, lip synchronization, and on conducting user
studies. Motivated by this, we propose a new evaluation framework comprising 8
metrics related to three dimensions (i) quality, (ii) naturalness, and (iii)
synchronization. In selecting the metrics, we place emphasis on efficiency, as
well as alignment with human preferences. Based on this considerations, we
streamline to analyze fine-grained dynamics of head, mouth, and eyebrows, as
well as face quality. Our extensive experiments on 85,000 videos generated by
17 state-of-the-art models suggest that while many algorithms excel in lip
synchronization, they face challenges with generating expressiveness and
artifact-free details. These videos were generated based on a novel real
dataset, that we have curated, in order to mitigate bias of training data. Our
proposed benchmark framework is aimed at evaluating the improvement of
generative methods. Original code, dataset and leaderboards will be publicly
released and regularly updated with new methods, in order to reflect progress
in the field.

</details>


### [51] [Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy](https://arxiv.org/abs/2511.04525)
*Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov*

Main category: cs.CV

TL;DR: STC-Net是一种基于单时间戳的LC手术复杂度评估框架，通过弱时间监督直接在完整视频上操作，性能优于现有方法，适用于术后分析和培训。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜胆囊切除术中，准确评估手术复杂度对预测手术时间和并发症风险至关重要。Parkland分级量表（PGS）虽已验证，但其在手术视频中的自动化应用尚未充分探索，尤其是在无需人工预处理的完整视频分析场景中。

Method: 本研究提出了STC-Net框架，通过定位、窗口提议和分级模块，直接在完整视频上进行时间定位和分级。采用了一种结合硬性和软性定位目标及背景感知分级监督的新型损失公式。

Result: 在1859个LC视频的私有数据集上评估，STC-Net准确率达62.11%，F1分数为61.42%，相比非定位基线方法提升超过10%，证明了弱监督在手术复杂度评估中的有效性。

Conclusion: STC-Net提供了一种可扩展且有效的方法，用于从完整的腹腔镜胆囊切除术视频中基于PGS自动评估手术复杂度，显示出在术后分析和手术训练中的应用潜力。

Abstract: Purpose: Accurate assessment of surgical complexity is essential in
Laparoscopic Cholecystectomy (LC), where severe inflammation is associated with
longer operative times and increased risk of postoperative complications. The
Parkland Grading Scale (PGS) provides a clinically validated framework for
stratifying inflammation severity; however, its automation in surgical videos
remains largely unexplored, particularly in realistic scenarios where complete
videos must be analyzed without prior manual curation. Methods: In this work,
we introduce STC-Net, a novel framework for SingleTimestamp-based Complexity
estimation in LC via the PGS, designed to operate under weak temporal
supervision. Unlike prior methods limited to static images or manually trimmed
clips, STC-Net operates directly on full videos. It jointly performs temporal
localization and grading through a localization, window proposal, and grading
module. We introduce a novel loss formulation combining hard and soft
localization objectives and background-aware grading supervision. Results:
Evaluated on a private dataset of 1,859 LC videos, STC-Net achieves an accuracy
of 62.11% and an F1-score of 61.42%, outperforming non-localized baselines by
over 10% in both metrics and highlighting the effectiveness of weak supervision
for surgical complexity assessment. Conclusion: STC-Net demonstrates a scalable
and effective approach for automated PGS-based surgical complexity estimation
from full LC videos, making it promising for post-operative analysis and
surgical training.

</details>


### [52] [Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm](https://arxiv.org/abs/2511.04570)
*Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu*

Main category: cs.CV

TL;DR: 提出'Thinking with Video'范式，利用视频生成模型Sora-2统一多模态推理，在VideoThinkBench基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的'Thinking with Text'和'Thinking with Images'范式存在局限性：（1）图像仅捕捉单一时刻，无法表示动态过程；（2）文本和视觉作为独立模态分离，阻碍了统一的多模态理解和生成。

Method: 通过引入'Thinking with Video'范式，利用视频生成模型（如Sora-2）在统一的时间框架中桥接视觉和文本推理，并开发了VideoThinkBench基准进行验证。

Result: 在视觉中心任务中，Sora-2与最先进的视觉语言模型（VLMs）表现相当，甚至在某些任务（如Eyeballing Games）中超越；在文本中心任务中，Sora-2在MATH上达到92%准确率，MMMU上达到75.53%。此外，自一致性和上下文学习能进一步提升其性能。

Conclusion: 视频生成模型（如Sora-2）展示了作为统一多模态理解和生成模型的潜力，'Thinking with Video'成为一种统一的多模态推理范式。

Abstract: "Thinking with Text" and "Thinking with Images" paradigm significantly
improve the reasoning ability of large language models (LLMs) and Vision
Language Models (VLMs). However, these paradigms have inherent limitations. (1)
Images capture only single moments and fail to represent dynamic processes or
continuous changes, and (2) The separation of text and vision as distinct
modalities, hindering unified multimodal understanding and generation. To
overcome these limitations, we introduce "Thinking with Video", a new paradigm
that leverages video generation models, such as Sora-2, to bridge visual and
textual reasoning in a unified temporal framework. To support this exploration,
we developed the Video Thinking Benchmark (VideoThinkBench). VideoThinkBench
encompasses two task categories: (1) vision-centric tasks (e.g., Eyeballing
Puzzles), and (2) text-centric tasks (e.g., subsets of GSM8K, MMMU). Our
evaluation establishes Sora-2 as a capable reasoner. On vision-centric tasks,
Sora-2 is generally comparable to state-of-the-art (SOTA) VLMs, and even
surpasses VLMs on several tasks, such as Eyeballing Games. On text-centric
tasks, Sora-2 achieves 92% accuracy on MATH, and 75.53% accuracy on MMMU.
Furthermore, we systematically analyse the source of these abilities. We also
find that self-consistency and in-context learning can improve Sora-2's
performance. In summary, our findings demonstrate that the video generation
model is the potential unified multimodal understanding and generation model,
positions "thinking with video" as a unified multimodal reasoning paradigm.

</details>


### [53] [UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction](https://arxiv.org/abs/2511.04595)
*Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang*

Main category: cs.CV

TL;DR: UniSplat是一种前馈框架，通过3D潜在支架和高效时空融合实现了自动驾驶场景的鲁棒动态重建，显著提升了新视角合成和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在稀疏、非重叠摄像头视角和复杂场景动态的联合挑战下表现不佳，因此需要一种能够鲁棒地进行动态场景重建的通用前馈框架。

Method: UniSplat构建了一个3D潜在支架，通过预训练的基础模型捕获几何和语义场景上下文，并引入了一个高效的融合机制，直接在3D支架内操作以实现一致的时空对齐。此外，设计了一个双分支解码器，通过结合点锚定细化和基于体素的生成，从融合支架中生成动态感知高斯分布，并维护静态高斯的持久内存以实现超出当前摄像头覆盖范围的流式场景完成。

Result: 在真实世界数据集上的广泛实验表明，UniSplat在新视角合成方面达到了最先进的性能，即使在原始摄像头覆盖范围之外的视角也能提供鲁棒且高质量的渲染。

Conclusion: UniSplat通过统一的潜在时空融合框架，在自动驾驶的3D重建中实现了高效且鲁棒的动态场景重建，特别是在稀疏、非重叠摄像头视角和复杂场景动态的联合挑战下表现出色。

Abstract: Feed-forward 3D reconstruction for autonomous driving has advanced rapidly,
yet existing methods struggle with the joint challenges of sparse,
non-overlapping camera views and complex scene dynamics. We present UniSplat, a
general feed-forward framework that learns robust dynamic scene reconstruction
through unified latent spatio-temporal fusion. UniSplat constructs a 3D latent
scaffold, a structured representation that captures geometric and semantic
scene context by leveraging pretrained foundation models. To effectively
integrate information across spatial views and temporal frames, we introduce an
efficient fusion mechanism that operates directly within the 3D scaffold,
enabling consistent spatio-temporal alignment. To ensure complete and detailed
reconstructions, we design a dual-branch decoder that generates dynamic-aware
Gaussians from the fused scaffold by combining point-anchored refinement with
voxel-based generation, and maintain a persistent memory of static Gaussians to
enable streaming scene completion beyond current camera coverage. Extensive
experiments on real-world datasets demonstrate that UniSplat achieves
state-of-the-art performance in novel view synthesis, while providing robust
and high-quality renderings even for viewpoints outside the original camera
coverage.

</details>


### [54] [PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning](https://arxiv.org/abs/2511.04601)
*Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang*

Main category: cs.CV

TL;DR: PixCLIP是一种新框架，通过同时处理视觉提示和长文本描述，提升了细粒度图像-文本对齐能力，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 尽管CLIP模型在各种下游视觉语言理解任务中表现出色，但其在细粒度图像-文本对齐方面的能力仍有提升空间，尤其是文本编码器的固有长度限制限制了处理更细粒度文本信息的能力。

Method: 首先建立了一个自动标注管道，用于生成像素级定位的长文本描述，并构建了LongGRIT数据集；随后用LLM替换CLIP的原始文本编码器，提出了一个三分支像素-文本对齐学习框架。

Result: 实验证明，PixCLIP在像素级交互和长文本处理方面取得了突破性进展，达到了最先进的性能。

Conclusion: PixCLIP框架通过同时处理视觉提示输入和长文本描述，在像素级交互和长文本处理方面取得了突破性进展，实现了最先进的性能。

Abstract: While the Contrastive Language-Image Pretraining(CLIP) model has achieved
remarkable success in a variety of downstream vison language understanding
tasks, enhancing its capability for fine-grained image-text alignment remains
an active research focus. To this end, most existing works adopt the strategy
of explicitly increasing the granularity of visual information processing,
e.g., incorporating visual prompts to guide the model focus on specific local
regions within the image. Meanwhile, researches on Multimodal Large Language
Models(MLLMs) have demonstrated that training with long and detailed textual
descriptions can effectively improve the model's fine-grained vision-language
alignment. However, the inherent token length limitation of CLIP's text encoder
fundamentally limits CLIP to process more granular textual information embedded
in long text sequences. To synergistically leverage the advantages of enhancing
both visual and textual content processing granularity, we propose PixCLIP, a
novel framework designed to concurrently accommodate visual prompt inputs and
process lengthy textual descriptions. Specifically, we first establish an
automated annotation pipeline capable of generating pixel-level localized,
long-form textual descriptions for images. Utilizing this pipeline, we
construct LongGRIT, a high-quality dataset comprising nearly 1.5 million
samples. Secondly, we replace CLIP's original text encoder with the LLM and
propose a three-branch pixel-text alignment learning framework, facilitating
fine-grained alignment between image regions and corresponding textual
descriptions at arbitrary granularity. Experiments demonstrate that PixCLIP
showcases breakthroughs in pixel-level interaction and handling long-form
texts, achieving state-of-the-art performance.

</details>


### [55] [Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality](https://arxiv.org/abs/2511.04615)
*Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen*

Main category: cs.CV

TL;DR: 提出了一种自动化框架，通过颜色反卷积和像素级指标评估虚拟IHC染色准确性，发现配对模型表现最佳，并强调全幻灯片评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前基于纹理和分布的指标无法准确评估虚拟IHC染色的准确性，因此需要一种自动化且基于真实性的框架来评估图像质量。

Method: 通过颜色反卷积生成IHC阳性像素的掩膜，并使用分割掩膜计算染色准确性指标（Dice、IoU、Hausdorff距离），直接量化像素级标签的准确性。

Result: 配对模型（如PyramidPix2Pix和AdaptiveNCE）染色准确性最高，而非配对扩散和GAN模型在提供准确IHC阳性像素标签方面表现较差。此外，全幻灯片图像（WSI）评估揭示了基于补丁评估中不可见的性能下降。

Conclusion: 该框架为评估虚拟免疫组化（IHC）模型的质量提供了一种可重复的方法，是加速其常规临床应用的关键步骤。

Abstract: Deep learning models can generate virtual immunohistochemistry (IHC) stains
from hematoxylin and eosin (H&E) images, offering a scalable and low-cost
alternative to laboratory IHC. However, reliable evaluation of image quality
remains a challenge as current texture- and distribution-based metrics quantify
image fidelity rather than the accuracy of IHC staining. Here, we introduce an
automated and accuracy grounded framework to determine image quality across
sixteen paired or unpaired image translation models. Using color deconvolution,
we generate masks of pixels stained brown (i.e., IHC-positive) as predicted by
each virtual IHC model. We use the segmented masks of real and virtual IHC to
compute stain accuracy metrics (Dice, IoU, Hausdorff distance) that directly
quantify correct pixel - level labeling without needing expert manual
annotations. Our results demonstrate that conventional image fidelity metrics,
including Frechet Inception Distance (FID), peak signal-to-noise ratio (PSNR),
and structural similarity (SSIM), correlate poorly with stain accuracy and
pathologist assessment. Paired models such as PyramidPix2Pix and AdaptiveNCE
achieve the highest stain accuracy, whereas unpaired diffusion- and GAN-based
models are less reliable in providing accurate IHC positive pixel labels.
Moreover, whole-slide images (WSI) reveal performance declines that are
invisible in patch-based evaluations, emphasizing the need for WSI-level
benchmarks. Together, this framework defines a reproducible approach for
assessing the quality of virtual IHC models, a critical step to accelerate
translation towards routine use by pathologists.

</details>


### [56] [NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment](https://arxiv.org/abs/2511.04628)
*Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano*

Main category: cs.CV

TL;DR: 本文提出了一种无需参考和人工标注的视频质量评估模型，通过时间感知的卷积架构和合成退化数据，显著提升了评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频质量评估方法存在两大局限：全参考（FR）指标需要干净参考视频，而无参考（NR）模型依赖昂贵的人工标注数据。此外，大多数无人工标注的NR方法是基于图像的，忽略了视频对象检测中关键的时间上下文。

Method: 采用基于DAVIS数据集的合成退化方法，训练了一个时间感知的卷积架构，直接从退化视频中预测FR指标（LPIPS、PSNR、SSIM）。

Result: 提出的流式方法在多样化退化情况下优于图像基线，且与全参考指标的相关性高于广泛使用的BRISQUE基线，验证了时间建模和无人工标注方法的有效性。

Conclusion: 该论文提出了一种无需参考和人工标注的视频质量评估（VQA）模型，通过利用时间感知的卷积架构和合成退化数据，显著提升了视频质量评估的准确性和可扩展性。

Abstract: Video quality assessment (VQA) is vital for computer vision tasks, but
existing approaches face major limitations: full-reference (FR) metrics require
clean reference videos, and most no-reference (NR) models depend on training on
costly human opinion labels. Moreover, most opinion-unaware NR methods are
image-based, ignoring temporal context critical for video object detection. In
this work, we present a scalable, streaming-based VQA model that is both
no-reference and opinion-unaware. Our model leverages synthetic degradations of
the DAVIS dataset, training a temporal-aware convolutional architecture to
predict FR metrics (LPIPS , PSNR, SSIM) directly from degraded video, without
references at inference. We show that our streaming approach outperforms our
own image-based baseline by generalizing across diverse degradations,
underscoring the value of temporal modeling for scalable VQA in real-world
vision systems. Additionally, we demonstrate that our model achieves higher
correlation with full-reference metrics compared to BRISQUE, a widely-used
opinion-aware image quality assessment baseline, validating the effectiveness
of our temporal, opinion-unaware approach.

</details>


### [57] [Polarization-resolved imaging improves eye tracking](https://arxiv.org/abs/2511.04652)
*Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model*

Main category: cs.CV

TL;DR: 偏振眼动追踪（PET）系统通过偏振成像提升眼动追踪精度，实验显示其优于传统光强方法。


<details>
  <summary>Details</summary>
Motivation: 传统的基于光强的眼动追踪在对比度上存在局限，偏振分辨成像可提供更多可追踪特征，提升追踪精度。

Method: 采用偏振滤光阵列相机与线性偏振近红外照明器组成的偏振眼动追踪（PET）系统，结合卷积神经网络进行数据分析。

Result: 在346名参与者中，PET系统使95百分位绝对凝视误差的中位数降低了10-16%，在多种条件下均优于仅基于光强的基线方法。

Conclusion: 偏振分辨近红外成像通过测量眼部组织反射光的偏振状态，为眼动追踪提供了额外的光学对比机制，为未来可穿戴设备提供了一种简单、鲁棒的传感方式。

Abstract: Polarization-resolved near-infrared imaging adds a useful optical contrast
mechanism to eye tracking by measuring the polarization state of light
reflected by ocular tissues in addition to its intensity. In this paper we
demonstrate how this contrast can be used to enable eye tracking. Specifically,
we demonstrate that a polarization-enabled eye tracking (PET) system composed
of a polarization--filter--array camera paired with a linearly polarized
near-infrared illuminator can reveal trackable features across the sclera and
gaze-informative patterns on the cornea, largely absent in intensity-only
images. Across a cohort of 346 participants, convolutional neural network based
machine learning models trained on data from PET reduced the median
95th-percentile absolute gaze error by 10--16\% relative to capacity-matched
intensity baselines under nominal conditions and in the presence of eyelid
occlusions, eye-relief changes, and pupil-size variation. These results link
light--tissue polarization effects to practical gains in human--computer
interaction and position PET as a simple, robust sensing modality for future
wearable devices.

</details>


### [58] [Benchmark Designers Should "Train on the Test Set" to Expose Exploitable Non-Visual Shortcuts](https://arxiv.org/abs/2511.04655)
*Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: 论文提出了诊断和去偏方法，通过测试集压力测试和迭代偏置剪枝，减少多模态基准中的非视觉偏见，提升评估鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大型语言模型（MLLMs）的基准测试存在非视觉偏见的利用问题，导致评估不准确。

Method: 采用测试集压力测试（TsT）方法，通过k-fold交叉验证在纯文本输入上微调大型语言模型，揭示捷径性能并为样本分配偏置分数；辅以基于随机森林的轻量级诊断工具。

Result: 在四个基准测试（VSI-Bench、CV-Bench、MMMU、VideoMME）中发现了普遍的非视觉偏见，并通过去偏框架成功创建了VSI-Bench-Debiased，减少了非视觉可解性。

Conclusion: 论文提出了一种诊断和去偏方法，通过测试集压力测试（TsT）和迭代偏置剪枝（IBP）来识别和减少多模态基准中的非视觉偏见，从而提升评估的鲁棒性。

Abstract: Robust benchmarks are crucial for evaluating Multimodal Large Language Models
(MLLMs). Yet we find that models can ace many multimodal benchmarks without
strong visual understanding, instead exploiting biases, linguistic priors, and
superficial patterns. This is especially problematic for vision-centric
benchmarks that are meant to require visual inputs. We adopt a diagnostic
principle for benchmark design: if a benchmark can be gamed, it will be.
Designers should therefore try to ``game'' their own benchmarks first, using
diagnostic and debiasing procedures to systematically identify and mitigate
non-visual biases. Effective diagnosis requires directly ``training on the test
set'' -- probing the released test set for its intrinsic, exploitable patterns.
  We operationalize this standard with two components. First, we diagnose
benchmark susceptibility using a ``Test-set Stress-Test'' (TsT) methodology.
Our primary diagnostic tool involves fine-tuning a powerful Large Language
Model via $k$-fold cross-validation on exclusively the non-visual, textual
inputs of the test set to reveal shortcut performance and assign each sample a
bias score $s(x)$. We complement this with a lightweight Random Forest-based
diagnostic operating on hand-crafted features for fast, interpretable auditing.
Second, we debias benchmarks by filtering high-bias samples using an
``Iterative Bias Pruning'' (IBP) procedure. Applying this framework to four
benchmarks -- VSI-Bench, CV-Bench, MMMU, and VideoMME -- we uncover pervasive
non-visual biases. As a case study, we apply our full framework to create
VSI-Bench-Debiased, demonstrating reduced non-visual solvability and a wider
vision-blind performance gap than the original.

</details>


### [59] [SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding](https://arxiv.org/abs/2511.04668)
*Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie*

Main category: cs.CV

TL;DR: SIMS-V通过3D模拟生成空间训练数据，识别三类核心问题提升模型空间推理能力，小模型高效超越大模型。


<details>
  <summary>Details</summary>
Motivation: 当前多模态语言模型在时空空间推理方面存在不足，且真实视频数据获取与标注成本高昂，阻碍了模型性能提升。

Method: 提出SIMS-V数据生成框架，通过系统消融实验研究模拟数据的哪些属性（问题类型、混合比例和规模）对真实世界迁移最有效。

Result: 识别出三个最有效的问题类别（度量测量、视角依赖推理和时间跟踪），仅需25K模拟样本训练的7B参数视频LLM即超越72B基线模型，并在真实世界空间推理基准上达到与专有模型竞争的性能。

Conclusion: SIMS-V框架通过利用3D模拟器的特权信息生成空间丰富的视频训练数据，显著提升了多模态语言模型在空间推理任务中的表现，尤其在真实世界任务中展现出强大的泛化能力。

Abstract: Despite impressive high-level video comprehension, multimodal language models
struggle with spatial reasoning across time and space. While current spatial
training approaches rely on real-world video data, obtaining diverse footage
with precise spatial annotations remains a bottleneck. To alleviate this
bottleneck, we present SIMS-V -- a systematic data-generation framework that
leverages the privileged information of 3D simulators to create spatially-rich
video training data for multimodal language models. Using this framework, we
investigate which properties of simulated data drive effective real-world
transfer through systematic ablations of question types, mixes, and scales. We
identify a minimal set of three question categories (metric measurement,
perspective-dependent reasoning, and temporal tracking) that prove most
effective for developing transferable spatial intelligence, outperforming
comprehensive coverage despite using fewer question types. These insights
enable highly efficient training: our 7B-parameter video LLM fine-tuned on just
25K simulated examples outperforms the larger 72B baseline and achieves
competitive performance with proprietary models on rigorous real-world spatial
reasoning benchmarks. Our approach demonstrates robust generalization,
maintaining performance on general video understanding while showing
substantial improvements on embodied and real-world spatial tasks.

</details>


### [60] [Cambrian-S: Towards Spatial Supersensing in Video](https://arxiv.org/abs/2511.04670)
*Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie*

Main category: cs.CV

TL;DR: 论文提出‘supersensing’新范式，通过VSI-SUPER基准和预测感知方法，证明数据扩展不足，预测能力是关键。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态智能系统主要集中在反应式、任务驱动的模式，缺乏对空间认知和世界建模的深入探索。论文旨在推动从语言理解到空间超感知的范式转变，以更全面地模拟人类感知能力。

Method: 论文提出了VSI-SUPER基准测试，包含VSR（长时视觉空间回忆）和VSC（连续视觉空间计数）任务，并通过VSI-590K数据集训练Cambrian-S模型。此外，还提出了一种基于预测误差的自监督下一潜在帧预测方法。

Result: 实验显示，Cambrian-S在VSI-Bench上实现了30%的绝对性能提升，但在VSI-SUPER上表现仍有限。提出的预测感知方法显著优于现有基线，验证了预测能力对空间超感知的关键作用。

Conclusion: 论文提出了一种名为‘supersensing’的新范式，强调从单纯的语言理解转向空间超感知，包括语义感知、事件认知、3D空间推理和预测世界建模。通过VSI-SUPER基准测试，证明了仅依靠数据扩展不足以实现真正的空间超感知，而预测感知（如自监督的下一个潜在帧预测器）展现了更优性能。

Abstract: We argue that progress in true multimodal intelligence calls for a shift from
reactive, task-driven systems and brute-force long context towards a broader
paradigm of supersensing. We frame spatial supersensing as four stages beyond
linguistic-only understanding: semantic perception (naming what is seen),
streaming event cognition (maintaining memory across continuous experiences),
implicit 3D spatial cognition (inferring the world behind pixels), and
predictive world modeling (creating internal models that filter and organize
information). Current benchmarks largely test only the early stages, offering
narrow coverage of spatial cognition and rarely challenging models in ways that
require true world modeling. To drive progress in spatial supersensing, we
present VSI-SUPER, a two-part benchmark: VSR (long-horizon visual spatial
recall) and VSC (continual visual spatial counting). These tasks require
arbitrarily long video inputs yet are resistant to brute-force context
expansion. We then test data scaling limits by curating VSI-590K and training
Cambrian-S, achieving +30% absolute improvement on VSI-Bench without
sacrificing general capabilities. Yet performance on VSI-SUPER remains limited,
indicating that scale alone is insufficient for spatial supersensing. We
propose predictive sensing as a path forward, presenting a proof-of-concept in
which a self-supervised next-latent-frame predictor leverages surprise
(prediction error) to drive memory and event segmentation. On VSI-SUPER, this
approach substantially outperforms leading proprietary baselines, showing that
spatial supersensing requires models that not only see but also anticipate,
select, and organize experience.

</details>


### [61] [InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation](https://arxiv.org/abs/2511.04675)
*Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan*

Main category: cs.CV

TL;DR: InfinityStar是一种高效统一的时空自回归框架，支持多种生成任务，性能优于现有自回归模型，生成速度快且质量高。


<details>
  <summary>Details</summary>
Motivation: 基于自回归模型在视觉和语言领域的成功，设计一个统一的框架来高效生成高质量视频。

Method: 采用纯离散的自回归建模方法，统一捕捉空间和时间依赖性，支持多种生成任务（如文本到图像、文本到视频等）。

Result: 在无需额外优化的情况下，生成5秒720p视频的速度比领先的扩散方法快10倍，且质量达到工业级别。

Conclusion: InfinityStar是一种统一的时空自回归框架，能够高效生成高分辨率图像和动态视频，其性能在VBench上达到83.74分，优于所有自回归模型，甚至超过部分扩散模型。

Abstract: We introduce InfinityStar, a unified spacetime autoregressive framework for
high-resolution image and dynamic video synthesis. Building on the recent
success of autoregressive modeling in both vision and language, our purely
discrete approach jointly captures spatial and temporal dependencies within a
single architecture. This unified design naturally supports a variety of
generation tasks such as text-to-image, text-to-video, image-to-video, and long
interactive video synthesis via straightforward temporal autoregression.
Extensive experiments demonstrate that InfinityStar scores 83.74 on VBench,
outperforming all autoregressive models by large margins, even surpassing some
diffusion competitors like HunyuanVideo. Without extra optimizations, our model
generates a 5s, 720p video approximately 10x faster than leading
diffusion-based methods. To our knowledge, InfinityStar is the first discrete
autoregressive video generator capable of producing industrial level 720p
videos. We release all code and models to foster further research in efficient,
high-quality video generation.

</details>


### [62] [Tracking and Understanding Object Transformations](https://arxiv.org/abs/2511.04678)
*Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan*

Main category: cs.CV

TL;DR: 提出Track Any State任务及VOST-TAS数据集，介绍零样本系统TubeletGraph，通过语义和邻近先验整合轨迹并生成状态图，实现高效跟踪和状态转换理解。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的物体经常发生状态转换，但现有方法在物体外观显著变化后常丢失目标跟踪。为了解决这一问题，提出了Track Any State任务及其基准数据集VOST-TAS。

Method: TubeletGraph是一种零样本系统，通过识别可能被忽略的轨迹，并基于语义和邻近先验决定是否整合，然后推理新增轨迹并生成描述每次转换的状态图。

Result: TubeletGraph在转换情况下的跟踪性能达到最先进水平，并展示了对物体转换的深入理解及在时间定位和语义推理方面的潜力。

Conclusion: TubeletGraph在物体状态转换跟踪任务中表现出色，不仅提升了跟踪性能，还展示了对物体转换的深入理解以及在时间定位和复杂转换语义推理方面的潜力。

Abstract: Real-world objects frequently undergo state transformations. From an apple
being cut into pieces to a butterfly emerging from its cocoon, tracking through
these changes is important for understanding real-world objects and dynamics.
However, existing methods often lose track of the target object after
transformation, due to significant changes in object appearance. To address
this limitation, we introduce the task of Track Any State: tracking objects
through transformations while detecting and describing state changes,
accompanied by a new benchmark dataset, VOST-TAS. To tackle this problem, we
present TubeletGraph, a zero-shot system that recovers missing objects after
transformation and maps out how object states are evolving over time.
TubeletGraph first identifies potentially overlooked tracks, and determines
whether they should be integrated based on semantic and proximity priors. Then,
it reasons about the added tracks and generates a state graph describing each
observed transformation. TubeletGraph achieves state-of-the-art tracking
performance under transformations, while demonstrating deeper understanding of
object transformations and promising capabilities in temporal grounding and
semantic reasoning for complex object transformations. Code, additional
results, and the benchmark dataset are available at
https://tubelet-graph.github.io.

</details>


### [63] [Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping](https://arxiv.org/abs/2511.04680)
*Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman*

Main category: cs.CV

TL;DR: 本文研究了多裁剪图像的问题，提出了结合单裁剪模型和图像分区算法的方法，并在新数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代社交媒体应用中需要多个不同且有美感的裁剪图像，但现有技术多关注单一裁剪，缺乏多裁剪解决方案。

Method: 通过图像分区算法作为预处理步骤，评估了几种单裁剪模型的效果。

Result: 实验结果表明，单裁剪模型结合图像分区算法能够有效产生多个有美感的裁剪图像。

Conclusion: 本文提出了一个多裁剪图像的方法，并通过实验验证了单裁剪模型结合图像分区算法的有效性，为社交媒体应用提供了实用的解决方案。

Abstract: Automatic image cropping is a method for maximizing the human-perceived
quality of cropped regions in photographs. Although several works have proposed
techniques for producing singular crops, little work has addressed the problem
of producing multiple, distinct crops with aesthetic appeal. In this paper, we
motivate the problem with a discussion on modern social media applications,
introduce a dataset of 277 relevant images and human labels, and evaluate the
efficacy of several single-crop models with an image partitioning algorithm as
a pre-processing step. The dataset is available at
https://github.com/RafeLoya/carousel.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [64] [Dynamic Shape Control of Soft Robots Enabled by Data-Driven Model Reduction](https://arxiv.org/abs/2511.03931)
*Iman Adibnazari,Harsh Sharma,Myungsun Park,Jacobo Cervera-Torralba,Boris Kramer,Michael T. Tolley*

Main category: cs.RO

TL;DR: 比较三种数据驱动模型降维技术，LOpInf在软体机器人动态形状控制中表现最优。


<details>
  <summary>Details</summary>
Motivation: 软体机器人在需要动态控制其整个身体的场景中展现出巨大潜力，但缺乏适用于控制的通用建模工具，这加剧了有效动态形状控制的挑战。

Method: 本研究比较了三种数据驱动的模型降维技术：特征系统实现算法、带控制的动态模态分解和拉格朗日算子推断（LOpInf）方法。使用每类模型，探索了它们在模型预测控制策略中用于动态形状控制的效果。

Result: 在三个实验中（跟踪保证可行的模拟参考轨迹、基于生物模型的鳗鱼运动学参考轨迹、以及缩小尺度物理模拟的参考轨迹），LOpInf方法表现最佳。

Conclusion: 在所有实验中，基于LOpInf的策略生成的跟踪误差低于基于其他模型的策略。

Abstract: Soft robots have shown immense promise in settings where they can leverage
dynamic control of their entire bodies. However, effective dynamic shape
control requires a controller that accounts for the robot's high-dimensional
dynamics--a challenge exacerbated by a lack of general-purpose tools for
modeling soft robots amenably for control. In this work, we conduct a
comparative study of data-driven model reduction techniques for generating
linear models amendable to dynamic shape control. We focus on three
methods--the eigensystem realization algorithm, dynamic mode decomposition with
control, and the Lagrangian operator inference (LOpInf) method. Using each
class of model, we explored their efficacy in model predictive control policies
for the dynamic shape control of a simulated eel-inspired soft robot in three
experiments: 1) tracking simulated reference trajectories guaranteed to be
feasible, 2) tracking reference trajectories generated from a biological model
of eel kinematics, and 3) tracking reference trajectories generated by a
reduced-scale physical analog. In all experiments, the LOpInf-based policies
generated lower tracking errors than policies based on other models.

</details>


### [65] [Learning Vision-Driven Reactive Soccer Skills for Humanoid Robots](https://arxiv.org/abs/2511.03996)
*Yushi Wang,Changsheng Luo,Penghui Chen,Jianran Liu,Weijian Sun,Tong Guo,Kechang Yang,Biao Hu,Yangang Zhang,Mingguo Zhao*

Main category: cs.RO

TL;DR: 提出统一强化学习控制器，整合视觉与运动控制，使人形机器人在动态环境中高效执行足球技能。


<details>
  <summary>Details</summary>
Motivation: 解决现有系统因模块解耦导致的延迟响应和行为不连贯问题，以及真实世界感知限制对动态环境的进一步影响。

Method: 采用基于对抗运动先验的方法，结合编码器-解码器架构和虚拟感知系统，模拟真实世界的视觉特性，使策略能从非完美观察中恢复特权状态，并建立感知与动作的主动协调。

Result: 开发的控制器在多种场景（包括真实RoboCup比赛）中展示了连贯且鲁棒的足球行为。

Conclusion: 该论文提出了一个统一的强化学习控制器，通过直接整合视觉感知和运动控制，使人形机器人能够在动态环境中获得反应性足球技能，并在实际比赛中展现出强大的反应性和鲁棒性。

Abstract: Humanoid soccer poses a representative challenge for embodied intelligence,
requiring robots to operate within a tightly coupled perception-action loop.
However, existing systems typically rely on decoupled modules, resulting in
delayed responses and incoherent behaviors in dynamic environments, while
real-world perceptual limitations further exacerbate these issues. In this
work, we present a unified reinforcement learning-based controller that enables
humanoid robots to acquire reactive soccer skills through the direct
integration of visual perception and motion control. Our approach extends
Adversarial Motion Priors to perceptual settings in real-world dynamic
environments, bridging motion imitation and visually grounded dynamic control.
We introduce an encoder-decoder architecture combined with a virtual perception
system that models real-world visual characteristics, allowing the policy to
recover privileged states from imperfect observations and establish active
coordination between perception and action. The resulting controller
demonstrates strong reactivity, consistently executing coherent and robust
soccer behaviors across various scenarios, including real RoboCup matches.

</details>


### [66] [Integrating Ergonomics and Manipulability for Upper Limb Postural Optimization in Bimanual Human-Robot Collaboration](https://arxiv.org/abs/2511.04009)
*Chenzui Li,Yiming Chen,Xi Wu,Giacinto Barresi,Fei Chen*

Main category: cs.RO

TL;DR: 本文提出一种上肢姿势优化方法，结合安全性和操纵效率，通过实验验证显著改善了人机协同搬运中的肌肉状况。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注人类安全或操纵效率，而本文方法独特地整合了这两方面，以增强不同条件下的协作能力。

Method: 通过最小化成本函数优化简化人体骨骼模型的关节角度，优先考虑安全性和操纵能力，并使用双手机器人模型预测阻抗控制器（MPIC）生成参考末端执行器位姿。

Result: 实验结果表明，通过比较优化前后目标肌肉的激活情况，肌肉状况显著改善。

Conclusion: 该论文提出了一种上肢姿势优化方法，显著提升了人机协同搬运任务中的物理人机工程学和力操纵能力。

Abstract: This paper introduces an upper limb postural optimization method for
enhancing physical ergonomics and force manipulability during bimanual
human-robot co-carrying tasks. Existing research typically emphasizes human
safety or manipulative efficiency, whereas our proposed method uniquely
integrates both aspects to strengthen collaboration across diverse conditions
(e.g., different grasping postures of humans, and different shapes of objects).
Specifically, the joint angles of a simplified human skeleton model are
optimized by minimizing the cost function to prioritize safety and manipulative
capability. To guide humans towards the optimized posture, the reference
end-effector poses of the robot are generated through a transformation module.
A bimanual model predictive impedance controller (MPIC) is proposed for our
human-like robot, CURI, to recalibrate the end effector poses through planned
trajectories. The proposed method has been validated through various subjects
and objects during human-human collaboration (HHC) and human-robot
collaboration (HRC). The experimental results demonstrate significant
improvement in muscle conditions by comparing the activation of target muscles
before and after optimization.

</details>


### [67] [An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue](https://arxiv.org/abs/2511.04042)
*Kailun Ji,Xiaoyu Hu,Xinyu Zhang,Jun Chen*

Main category: cs.RO

TL;DR: 该论文提出了一种基于LLM的无人机群协作系统，显著提高了灾难搜救任务的效率和成功率，同时降低了操作员的认知负荷。


<details>
  <summary>Details</summary>
Motivation: 解决大规模灾难搜救中复杂地形和通信中断带来的挑战，以及无人机群协调中存在的‘意图到行动差距’问题。

Method: 提出了一种LLM-CRF系统，通过自然和多模态交互捕捉操作员意图，利用LLM作为认知引擎进行意图理解、任务分解和任务规划。

Result: 与传统界面相比，LLM驱动的方法将任务完成时间减少了约64.2%，任务成功率提高了7%，主观认知负荷显著降低（NASA-TLX分数下降42.9%）。

Conclusion: 本研究展示了LLMs在构建更直观有效的人-群协作系统方面的潜力，特别是在高风险场景如灾难搜救中。

Abstract: Large-scale disaster Search And Rescue (SAR) operations are persistently
challenged by complex terrain and disrupted communications. While Unmanned
Aerial Vehicle (UAV) swarms offer a promising solution for tasks like wide-area
search and supply delivery, yet their effective coordination places a
significant cognitive burden on human operators. The core human-machine
collaboration bottleneck lies in the ``intention-to-action gap'', which is an
error-prone process of translating a high-level rescue objective into a
low-level swarm command under high intensity and pressure. To bridge this gap,
this study proposes a novel LLM-CRF system that leverages Large Language Models
(LLMs) to model and augment human-swarm teaming cognition. The proposed
framework initially captures the operator's intention through natural and
multi-modal interactions with the device via voice or graphical annotations. It
then employs the LLM as a cognitive engine to perform intention comprehension,
hierarchical task decomposition, and mission planning for the UAV swarm. This
closed-loop framework enables the swarm to act as a proactive partner,
providing active feedback in real-time while reducing the need for manual
monitoring and control, which considerably advances the efficacy of the SAR
task. We evaluate the proposed framework in a simulated SAR scenario.
Experimental results demonstrate that, compared to traditional order and
command-based interfaces, the proposed LLM-driven approach reduced task
completion time by approximately $64.2\%$ and improved task success rate by
$7\%$. It also leads to a considerable reduction in subjective cognitive
workload, with NASA-TLX scores dropping by $42.9\%$. This work establishes the
potential of LLMs to create more intuitive and effective human-swarm
collaborations in high-stakes scenarios.

</details>


### [68] [Enhancing Fault-Tolerant Space Computing: Guidance Navigation and Control (GNC) and Landing Vision System (LVS) Implementations on Next-Gen Multi-Core Processors](https://arxiv.org/abs/2511.04052)
*Kyongsik Yun,David Bayard,Gerik Kubiak,Austin Owens,Andrew Johnson,Ryan Johnson,Dan Scharf,Thomas Lu*

Main category: cs.RO

TL;DR: The paper presents a high-performance, fault-tolerant computing architecture for planetary missions, showing significant speedups in LVS and GFOLD tasks, and introduces ARBITER for reliable execution.


<details>
  <summary>Details</summary>
Motivation: Future planetary exploration missions require high-performance, fault-tolerant computing for autonomous GNC and LVS operations during EDL.

Method: The paper evaluates the deployment of GNC and LVS algorithms on next-gen multi-core processors (HPSC, Snapdragon VOXL2, AMD Xilinx Versal) and introduces ARBITER, a Multi-Core Voting mechanism for real-time fault detection and correction.

Result: Demonstrates up to 15x speedup for LVS image processing and over 250x speedup for GFOLD trajectory optimization compared to legacy hardware. ARBITER is validated in static and dynamic tasks, with fault injection studies identifying sensitive computation stages.

Conclusion: This work establishes a scalable and energy-efficient architecture for future planetary missions, emphasizing onboard autonomy, low latency, and fault resilience.

Abstract: Future planetary exploration missions demand high-performance, fault-tolerant
computing to enable autonomous Guidance, Navigation, and Control (GNC) and
Lander Vision System (LVS) operations during Entry, Descent, and Landing (EDL).
This paper evaluates the deployment of GNC and LVS algorithms on
next-generation multi-core processors--HPSC, Snapdragon VOXL2, and AMD Xilinx
Versal--demonstrating up to 15x speedup for LVS image processing and over 250x
speedup for Guidance for Fuel-Optimal Large Divert (GFOLD) trajectory
optimization compared to legacy spaceflight hardware. To ensure computational
reliability, we present ARBITER (Asynchronous Redundant Behavior Inspection for
Trusted Execution and Recovery), a Multi-Core Voting (MV) mechanism that
performs real-time fault detection and correction across redundant cores.
ARBITER is validated in both static optimization tasks (GFOLD) and dynamic
closed-loop control (Attitude Control System). A fault injection study further
identifies the gradient computation stage in GFOLD as the most sensitive to
bit-level errors, motivating selective protection strategies and vector-based
output arbitration. This work establishes a scalable and energy-efficient
architecture for future missions, including Mars Sample Return, Enceladus
Orbilander, and Ceres Sample Return, where onboard autonomy, low latency, and
fault resilience are critical.

</details>


### [69] [CBMC-V3: A CNS-inspired Control Framework Towards Manipulation Agility with SNN](https://arxiv.org/abs/2511.04109)
*Yanbo Pang,Qingkai Li,Mingguo Zhao*

Main category: cs.RO

TL;DR: 论文提出了一种基于脉冲神经网络的仿生控制框架，通过五个模块和三个控制层次实现机械臂在复杂环境中的敏捷控制，实验证明其优于传统工业级位置控制。


<details>
  <summary>Details</summary>
Motivation: 随着机械臂应用扩展到医疗、服务和日常生活领域，现有控制算法难以应对复杂环境中的动态轨迹、不可预测交互和多样化对象，因此需要更敏捷的控制方法。

Method: 框架包含五个控制模块（大脑皮层、小脑、丘脑、脑干、脊髓），三个层次控制级别（一阶、二阶、三阶）和两条信息通路（上行、下行），每个模块均采用脉冲神经网络实现。

Result: 模拟和真实机械臂平台上的实验表明，该方法在操纵敏捷性上优于工业级位置控制。

Conclusion: 该论文提出的基于脉冲神经网络的仿生控制框架在复杂环境中展现出优于工业级位置控制的敏捷性。

Abstract: As robotic arm applications extend beyond industrial settings into
healthcare, service, and daily life, existing control algorithms struggle to
achieve the agile manipulation required for complex environments with dynamic
trajectories, unpredictable interactions, and diverse objects. This paper
presents a biomimetic control framework based on Spiking Neural Networks (SNN),
inspired by the human Central Nervous System (CNS), to achieve agile control in
such environments. The proposed framework features five control modules
(cerebral cortex, cerebellum, thalamus, brainstem, spinal cord), three
hierarchical control levels (first-order, second-order, third-order), and two
information pathways (ascending, descending). Each module is fully implemented
using SNN. The spinal cord module uses spike encoding and Leaky
Integrate-and-Fire (LIF) neurons for feedback control. The brainstem module
employs a network of LIF and non-spiking LIF neurons to dynamically adjust
spinal cord parameters via reinforcement learning. The thalamus module
similarly adjusts the cerebellum's torque outputs. The cerebellum module uses a
recurrent SNN to learn the robotic arm's dynamics through regression, providing
feedforward gravity compensation torques. The framework is validated both in
simulation and on real-world robotic arm platform under various loads and
trajectories. Results demonstrate that our method outperforms the
industrial-grade position control in manipulation agility.

</details>


### [70] [BFM-Zero: A Promptable Behavioral Foundation Model for Humanoid Control Using Unsupervised Reinforcement Learning](https://arxiv.org/abs/2511.04131)
*Yitang Li,Zhengyi Luo,Tonghe Zhang,Cunxi Dai,Anssi Kanervisto,Andrea Tirinzoni,Haoyang Weng,Kris Kitani,Mateusz Guzek,Ahmed Touati,Alessandro Lazaric,Matteo Pirotta,Guanya Shi*

Main category: cs.RO

TL;DR: BFM-Zero 是一个可提示的行为基础模型，通过共享潜在表示实现多任务控制，无需重新训练，并在真实人形机器人上验证了多样化技能。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么仅适用于仿真人形角色，要么局限于特定任务（如跟踪）。BFM-Zero 旨在通过共享潜在表示，实现多任务控制的统一框架。

Method: BFM-Zero 基于无监督强化学习和前向-后向（FB）模型，通过关键奖励设计、域随机化和历史依赖的非对称学习，弥合了仿真与现实的差距。

Result: BFM-Zero 在真实人形机器人（Unitree G1）上实现了零样本运动跟踪、目标到达和奖励优化，以及少样本优化适应。

Conclusion: BFM-Zero 提出了一个统一的、可提示的行为基础模型框架，通过共享潜在表示实现了多任务控制，无需重新训练。该模型在真实人形机器人上展示了多样化的全身技能，为可扩展的人形控制奠定了基础。

Abstract: Building Behavioral Foundation Models (BFMs) for humanoid robots has the
potential to unify diverse control tasks under a single, promptable generalist
policy. However, existing approaches are either exclusively deployed on
simulated humanoid characters, or specialized to specific tasks such as
tracking. We propose BFM-Zero, a framework that learns an effective shared
latent representation that embeds motions, goals, and rewards into a common
space, enabling a single policy to be prompted for multiple downstream tasks
without retraining. This well-structured latent space in BFM-Zero enables
versatile and robust whole-body skills on a Unitree G1 humanoid in the real
world, via diverse inference methods, including zero-shot motion tracking, goal
reaching, and reward optimization, and few-shot optimization-based adaptation.
Unlike prior on-policy reinforcement learning (RL) frameworks, BFM-Zero builds
upon recent advancements in unsupervised RL and Forward-Backward (FB) models,
which offer an objective-centric, explainable, and smooth latent representation
of whole-body motions. We further extend BFM-Zero with critical reward shaping,
domain randomization, and history-dependent asymmetric learning to bridge the
sim-to-real gap. Those key design choices are quantitatively ablated in
simulation. A first-of-its-kind model, BFM-Zero establishes a step toward
scalable, promptable behavioral foundation models for whole-body humanoid
control.

</details>


### [71] [PUL-SLAM: Path-Uncertainty Co-Optimization with Lightweight Stagnation Detection for Efficient Robotic Exploration](https://arxiv.org/abs/2511.04180)
*Yizhen Yin,Dapeng Feng,Hongbo Chen,Yuhua Qi*

Main category: cs.RO

TL;DR: 提出混合框架结合深度强化学习和停滞检测，显著提升SLAM探索效率，验证现实适用性。


<details>
  <summary>Details</summary>
Motivation: 解决现有主动SLAM方法探索速度慢和路径次优的问题。

Method: 采用路径-不确定性协同优化深度强化学习框架（双目标奖励函数优化旅行距离和地图不确定性）和轻量级停滞检测机制（激光雷达静态异常检测和地图更新停滞检测）。

Result: 相比前沿方法和RRT方法，探索时间缩短65%，路径距离减少42%，训练收敛速度加快。

Conclusion: 该论文提出的混合框架通过结合路径-不确定性协同优化深度强化学习框架和轻量级停滞检测机制，显著提升了复杂环境中的探索效率，并验证了算法从仿真到现实环境的可迁移性。

Abstract: Existing Active SLAM methodologies face issues such as slow exploration speed
and suboptimal paths. To address these limitations, we propose a hybrid
framework combining a Path-Uncertainty Co-Optimization Deep Reinforcement
Learning framework and a Lightweight Stagnation Detection mechanism. The
Path-Uncertainty Co-Optimization framework jointly optimizes travel distance
and map uncertainty through a dual-objective reward function, balancing
exploration and exploitation. The Lightweight Stagnation Detection reduces
redundant exploration through Lidar Static Anomaly Detection and Map Update
Stagnation Detection, terminating episodes on low expansion rates. Experimental
results show that compared with the frontier-based method and RRT method, our
approach shortens exploration time by up to 65% and reduces path distance by up
to 42%, significantly improving exploration efficiency in complex environments
while maintaining reliable map completeness. Ablation studies confirm that the
collaborative mechanism accelerates training convergence. Empirical validation
on a physical robotic platform demonstrates the algorithm's practical
applicability and its successful transferability from simulation to real-world
environments.

</details>


### [72] [GraspView: Active Perception Scoring and Best-View Optimization for Robotic Grasping in Cluttered Environments](https://arxiv.org/abs/2511.04199)
*Shenglin Wang,Mingtong Dai,Jingxuan Su,Lingbo Liu,Chunjie Chen,Xinyu Wu,Liang Lin*

Main category: cs.RO

TL;DR: GraspView是一种仅用RGB的机器人抓取管道，通过多视图重建和主动感知策略，在杂乱环境中实现高精度抓取，尤其擅长处理遮挡和透明物体。


<details>
  <summary>Details</summary>
Motivation: 传统RGB-D相机在透明或光泽物体及近距离时失效，导致抓取不稳定或失败，需要一种不依赖深度传感器的解决方案。

Method: 集成了全局感知场景重建、渲染评分主动感知策略和在线度量对齐模块，结合多视图重建和GraspNet实现稳健抓取。

Result: 在多样化的桌面物体实验中，GraspView显著优于RGB-D和单视图RGB基线方法。

Conclusion: GraspView作为一种仅使用RGB的机器人抓取管道，在杂乱环境中表现出色，尤其在遮挡、近距离感知和透明物体处理上优于传统RGB-D和单视图RGB方法，成为RGB-D管道的实用替代方案。

Abstract: Robotic grasping is a fundamental capability for autonomous manipulation, yet
remains highly challenging in cluttered environments where occlusion, poor
perception quality, and inconsistent 3D reconstructions often lead to unstable
or failed grasps. Conventional pipelines have widely relied on RGB-D cameras to
provide geometric information, which fail on transparent or glossy objects and
degrade at close range. We present GraspView, an RGB-only robotic grasping
pipeline that achieves accurate manipulation in cluttered environments without
depth sensors. Our framework integrates three key components: (i) global
perception scene reconstruction, which provides locally consistent, up-to-scale
geometry from a single RGB view and fuses multi-view projections into a
coherent global 3D scene; (ii) a render-and-score active perception strategy,
which dynamically selects next-best-views to reveal occluded regions; and (iii)
an online metric alignment module that calibrates VGGT predictions against
robot kinematics to ensure physical scale consistency. Building on these
tailor-designed modules, GraspView performs best-view global grasping, fusing
multi-view reconstructions and leveraging GraspNet for robust execution.
Experiments on diverse tabletop objects demonstrate that GraspView
significantly outperforms both RGB-D and single-view RGB baselines, especially
under heavy occlusion, near-field sensing, and with transparent objects. These
results highlight GraspView as a practical and versatile alternative to RGB-D
pipelines, enabling reliable grasping in unstructured real-world environments.

</details>


### [73] [Can Context Bridge the Reality Gap? Sim-to-Real Transfer of Context-Aware Policies](https://arxiv.org/abs/2511.04249)
*Marco Iannotta,Yuxuan Yang,Johannes A. Stork,Erik Schaffernicht,Todor Stoyanov*

Main category: cs.RO

TL;DR: 通过上下文感知策略改进模拟到现实的强化学习迁移，效果优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决模拟到现实迁移中的挑战，即模拟训练的策略因环境动态差异而难以泛化到现实世界。

Method: 将上下文估计模块集成到基于域随机化的强化学习框架中，并系统比较了最先进的监督策略。

Result: 在标准控制基准和真实世界推任务中，上下文感知策略在所有设置下均优于上下文无关的基线。

Conclusion: 上下文感知策略在模拟到现实的迁移中表现优于上下文无关的基线策略，但最佳监督策略因任务而异。

Abstract: Sim-to-real transfer remains a major challenge in reinforcement learning (RL)
for robotics, as policies trained in simulation often fail to generalize to the
real world due to discrepancies in environment dynamics. Domain Randomization
(DR) mitigates this issue by exposing the policy to a wide range of randomized
dynamics during training, yet leading to a reduction in performance. While
standard approaches typically train policies agnostic to these variations, we
investigate whether sim-to-real transfer can be improved by conditioning the
policy on an estimate of the dynamics parameters -- referred to as context. To
this end, we integrate a context estimation module into a DR-based RL framework
and systematically compare SOTA supervision strategies. We evaluate the
resulting context-aware policies in both a canonical control benchmark and a
real-world pushing task using a Franka Emika Panda robot. Results show that
context-aware policies outperform the context-agnostic baseline across all
settings, although the best supervision strategy depends on the task.

</details>


### [74] [Design and Control of a Coaxial Dual-rotor Reconfigurable Tailsitter UAV Based on Swashplateless Mechanism](https://arxiv.org/abs/2511.04251)
*Jinfeng Liang,Haocheng Guo,Ximin Lyu*

Main category: cs.RO

TL;DR: 论文提出一种带可伸缩机翼的同轴异质双旋翼尾座式无人机设计，通过结构优化提升抗风性和飞行稳定性。


<details>
  <summary>Details</summary>
Motivation: 尾座式无人机在多旋翼模式下因暴露大面积机身而易受风扰，需提升其抗风性能和飞行效率。

Method: 采用可伸缩机翼设计、同轴异质双旋翼配置和无斜盘机构优化，通过增加摆动铰链减少振动。

Result: 全面过渡飞行测试验证了无人机在整个飞行包线内的稳定性能。

Conclusion: 该论文通过可重构机翼设计、同轴异质双旋翼配置以及无斜盘机构优化，成功提升了尾座式无人机的抗风性能和整体飞行稳定性。

Abstract: The tailsitter vertical takeoff and landing (VTOL) UAV is widely used due to
its lower dead weight, which eliminates the actuators and mechanisms for
tilting. However, the tailsitter UAV is susceptible to wind disturbances in
multi-rotor mode, as it exposes a large frontal fuselage area. To address this
issue, our tailsitter UAV features a reconfigurable wing design, allowing wings
to retract in multi-rotor mode and extend in fixed- wing mode. Considering
power efficiency, we design a coaxial heterogeneous dual-rotor configuration,
which significantly re- duces the total power consumption. To reduce structural
weight and simplify structural complexity, we employ a swashplateless mechanism
with an improved design to control pitch and roll in multi-rotor mode. We
optimize the structure of the swashplateless mechanism by adding flapping
hinges, which reduces vibration during cyclic acceleration and deceleration.
Finally, we perform comprehensive transition flight tests to validate stable
flight performance across the entire flight envelope of the tailsitter UAV.

</details>


### [75] [MacroNav: Multi-Task Context Representation Learning Enables Efficient Navigation in Unknown Environments](https://arxiv.org/abs/2511.04320)
*Kuankuan Sima,Longbin Tang,Haozhe Ma,Lin Zhao*

Main category: cs.RO

TL;DR: MacroNav通过轻量级编码器和强化学习策略，在未知环境中实现高效导航，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中实现自主导航需要紧凑且表达性强的空间理解，现有方法难以平衡丰富上下文表示与导航效率。

Method: MacroNav包含两个关键组件：1) 通过多任务自监督学习训练的轻量级上下文编码器，捕捉多尺度导航中心空间表示；2) 结合基于图推理的强化学习策略，实现高效动作选择。

Result: 实验证明MacroNav在现实部署中表现优异，显著优于现有导航方法（SR和SPL指标），同时保持低计算成本。

Conclusion: MacroNav通过结合轻量级上下文编码器和强化学习策略，在未知环境中实现了高效的自主导航，显著提升了成功率和路径效率。

Abstract: Autonomous navigation in unknown environments requires compact yet expressive
spatial understanding under partial observability to support high-level
decision making. Existing approaches struggle to balance rich contextual
representation with navigation efficiency. We present MacroNav, a
learning-based navigation framework featuring two key components: (1) a
lightweight context encoder trained via multi-task self-supervised learning to
capture multi-scale, navigation-centric spatial representations; and (2) a
reinforcement learning policy that seamlessly integrates these representations
with graph-based reasoning for efficient action selection. Extensive
experiments demonstrate the context encoder's efficient and robust
environmental understanding. Real-world deployments further validate MacroNav's
effectiveness, yielding significant gains over state-of-the-art navigation
methods in both Success Rate (SR) and Success weighted by Path Length (SPL),
while maintaining low computational cost. Code will be released upon
acceptance.

</details>


### [76] [GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies](https://arxiv.org/abs/2511.04357)
*Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche*

Main category: cs.RO

TL;DR: GraSP-VLA通过神经符号方法结合VLA和AML优势，有效解决长期任务中的规划与协调问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型缺乏高级符号规划能力，AML方法缺乏泛化和扩展性，需结合两者优势以解决长期任务中的问题。

Method: 采用Continuous Scene Graph表示法生成人类示范的符号表示，用于推理期间生成新的规划领域，并协调低级VLA策略。

Result: GraSP-VLA在自动规划领域生成任务中有效建模符号表示，并在真实世界实验中展示了协调低级VLA策略处理长期任务的能力。

Conclusion: GraSP-VLA框架通过结合神经符号方法，成功解决了现有VLA模型和AML方法在长期任务中的局限性，展示了在自动规划领域生成和长期任务协调中的潜力。

Abstract: Deploying autonomous robots that can learn new skills from demonstrations is
an important challenge of modern robotics. Existing solutions often apply
end-to-end imitation learning with Vision-Language Action (VLA) models or
symbolic approaches with Action Model Learning (AML). On the one hand, current
VLA models are limited by the lack of high-level symbolic planning, which
hinders their abilities in long-horizon tasks. On the other hand, symbolic
approaches in AML lack generalization and scalability perspectives. In this
paper we present a new neuro-symbolic approach, GraSP-VLA, a framework that
uses a Continuous Scene Graph representation to generate a symbolic
representation of human demonstrations. This representation is used to generate
new planning domains during inference and serves as an orchestrator for
low-level VLA policies, scaling up the number of actions that can be reproduced
in a row. Our results show that GraSP-VLA is effective for modeling symbolic
representations on the task of automatic planning domain generation from
observations. In addition, results on real-world experiments show the potential
of our Continuous Scene Graph representation to orchestrate low-level VLA
policies in long-horizon tasks.

</details>


### [77] [Studying the Effect of Explicit Interaction Representations on Learning Scene-level Distributions of Human Trajectories](https://arxiv.org/abs/2511.04375)
*Anna Mészáros,Javier Alonso-Mora,Jens Kober*

Main category: cs.RO

TL;DR: 论文探讨了代理间交互的不同表示方法，发现明确定义的交互比隐式学习的交互更能提升自动驾驶场景预测的性能。


<details>
  <summary>Details</summary>
Motivation: 有效捕捉场景中所有代理的联合分布对于预测场景的真实演化及为自动驾驶决策提供更准确信息至关重要，但目前对于如何最佳表示代理间的交互尚无共识。

Method: 本研究在同一网络结构中探讨了多种描述代理间交互的方式及其对最终学习的联合分布的影响。

Result: 研究发现，明确建模的交互（如空间和时间关系）比神经网络从数据中隐式学习的交互更能提升性能。

Conclusion: 研究表明，明确定义的交互（如确定哪个代理在交叉路口优先通过）通常能显著提升性能，而仅依赖数据建立的隐式交互连接往往对性能有负面影响。

Abstract: Effectively capturing the joint distribution of all agents in a scene is
relevant for predicting the true evolution of the scene and in turn providing
more accurate information to the decision processes of autonomous vehicles.
While new models have been developed for this purpose in recent years, it
remains unclear how to best represent the joint distributions particularly from
the perspective of the interactions between agents. Thus far there is no clear
consensus on how best to represent interactions between agents; whether they
should be learned implicitly from data by neural networks, or explicitly
modeled using the spatial and temporal relations that are more grounded in
human decision-making. This paper aims to study various means of describing
interactions within the same network structure and their effect on the final
learned joint distributions. Our findings show that more often than not, simply
allowing a network to establish interactive connections between agents based on
data has a detrimental effect on performance. Instead, having well defined
interactions (such as which agent of an agent pair passes first at an
intersection) can often bring about a clear boost in performance.

</details>


### [78] [ForeRobo: Unlocking Infinite Simulation Data for 3D Goal-driven Robotic Manipulation](https://arxiv.org/abs/2511.04381)
*Dexin wang,Faliang Chang,Chunsheng Liu*

Main category: cs.RO

TL;DR: ForeRobo通过生成模拟和经典控制的结合，高效学习机器人操作技能，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 利用仿真高效获取高级操作技能具有挑战性且意义重大。

Method: 提出一种自引导的‘提出-生成-学习-执行’循环方法，结合ForeGen生成技能一致的目标状态和ForeFormer模型预测3D目标位置。

Result: ForeFormer在多种操作任务中平均提升56.32%，ForeRobo在现实任务中平均成功率达79.28%。

Conclusion: ForeRobo通过结合生成模拟和经典控制，显著提升了机器人操作技能的学习效率和泛化能力，实现了零样本的仿真到现实迁移。

Abstract: Efficiently leveraging simulation to acquire advanced manipulation skills is
both challenging and highly significant. We introduce \textit{ForeRobo}, a
generative robotic agent that utilizes generative simulations to autonomously
acquire manipulation skills driven by envisioned goal states. Instead of
directly learning low-level policies, we advocate integrating generative
paradigms with classical control. Our approach equips a robotic agent with a
self-guided \textit{propose-generate-learn-actuate} cycle. The agent first
proposes the skills to be acquired and constructs the corresponding simulation
environments; it then configures objects into appropriate arrangements to
generate skill-consistent goal states (\textit{ForeGen}). Subsequently, the
virtually infinite data produced by ForeGen are used to train the proposed
state generation model (\textit{ForeFormer}), which establishes point-wise
correspondences by predicting the 3D goal position of every point in the
current state, based on the scene state and task instructions. Finally,
classical control algorithms are employed to drive the robot in real-world
environments to execute actions based on the envisioned goal states. Compared
with end-to-end policy learning methods, ForeFormer offers superior
interpretability and execution efficiency. We train and benchmark ForeFormer
across a variety of rigid-body and articulated-object manipulation tasks, and
observe an average improvement of 56.32\% over the state-of-the-art state
generation models, demonstrating strong generality across different
manipulation patterns. Moreover, in real-world evaluations involving more than
20 robotic tasks, ForeRobo achieves zero-shot sim-to-real transfer and exhibits
remarkable generalization capabilities, attaining an average success rate of
79.28\%.

</details>


### [79] [Temporal Action Selection for Action Chunking](https://arxiv.org/abs/2511.04421)
*Yueyang Weng,Xiaopeng Zhang,Yongjin Mu,Yingcong Zhu,Yanjie Li,Qi Liu*

Main category: cs.RO

TL;DR: TAS算法通过动态选择动作块优化反应性、决策一致性和连贯性，显著提升任务成功率，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的动作分块方法在提升建模能力的同时降低了反应性，尤其在应对传感器噪声和动态环境变化时表现不足。

Method: 提出了一种名为Temporal Action Selector（TAS）的新算法，该算法缓存多时间步预测的动作块，并通过轻量级选择器网络动态选择最优动作。

Result: 实验表明，TAS在多个任务中显著提高了成功率（绝对增益高达73.3%），并与残差强化学习（RL）结合提升了训练效率和性能上限。

Conclusion: Temporal Action Selector（TAS）通过动态选择最优动作块，在反应性、决策一致性和动作连贯性之间实现了平衡优化，显著提高了任务成功率，并在仿真和实体机器人实验中验证了其有效性。

Abstract: Action chunking is a widely adopted approach in Learning from Demonstration
(LfD). By modeling multi-step action chunks rather than single-step actions,
action chunking significantly enhances modeling capabilities for human expert
policies. However, the reduced decision frequency restricts the utilization of
recent observations, degrading reactivity - particularly evident in the
inadequate adaptation to sensor noise and dynamic environmental changes.
Existing efforts to address this issue have primarily resorted to trading off
reactivity against decision consistency, without achieving both. To address
this limitation, we propose a novel algorithm, Temporal Action Selector (TAS),
which caches predicted action chunks from multiple timesteps and dynamically
selects the optimal action through a lightweight selector network. TAS achieves
balanced optimization across three critical dimensions: reactivity, decision
consistency, and motion coherence. Experiments across multiple tasks with
diverse base policies show that TAS significantly improves success rates -
yielding an absolute gain of up to 73.3%. Furthermore, integrating TAS as a
base policy with residual reinforcement learning (RL) substantially enhances
training efficiency and elevates the performance plateau. Experiments in both
simulation and physical robots confirm the method's efficacy.

</details>


### [80] [Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment](https://arxiv.org/abs/2511.04555)
*Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao*

Main category: cs.RO

TL;DR: Evo-1是一个轻量级VLA模型，无需机器人数据预训练，性能优异，计算和部署效率高，在多个基准测试中超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型参数庞大，依赖大规模机器人数据预训练，导致计算成本高、实时推理部署受限，且训练范式常损害视觉语言骨干的感知表示。

Method: Evo-1基于原生多模态视觉语言模型（VLM），引入了新颖的跨调制扩散变换器和优化的集成模块，形成了一个高效的架构。采用两阶段训练范式，逐步对齐动作与感知。

Result: Evo-1在Meta-World和RoboTwin套件上分别超过此前最佳模型12.4%和6.9%，在LIBERO上达到94.8%的竞争性结果，实际评估中成功率为78%，推理频率高且内存开销低。

Conclusion: Evo-1是一个轻量级的VLA模型，通过在无需机器人数据预训练的情况下保持高性能，显著降低了计算成本并提高了部署效率。

Abstract: Vision-Language-Action (VLA) models have emerged as a powerful framework that
unifies perception, language, and control, enabling robots to perform diverse
tasks through multimodal understanding. However, current VLA models typically
contain massive parameters and rely heavily on large-scale robot data
pretraining, leading to high computational costs during training, as well as
limited deployability for real-time inference. Moreover, most training
paradigms often degrade the perceptual representations of the vision-language
backbone, resulting in overfitting and poor generalization to downstream tasks.
In this work, we present Evo-1, a lightweight VLA model that reduces
computation and improves deployment efficiency, while maintaining strong
performance without pretraining on robot data. Evo-1 builds on a native
multimodal Vision-Language model (VLM), incorporating a novel cross-modulated
diffusion transformer along with an optimized integration module, together
forming an effective architecture. We further introduce a two-stage training
paradigm that progressively aligns action with perception, preserving the
representations of the VLM. Notably, with only 0.77 billion parameters, Evo-1
achieves state-of-the-art results on the Meta-World and RoboTwin suite,
surpassing the previous best models by 12.4% and 6.9%, respectively, and also
attains a competitive result of 94.8% on LIBERO. In real-world evaluations,
Evo-1 attains a 78% success rate with high inference frequency and low memory
overhead, outperforming all baseline methods. We release code, data, and model
weights to facilitate future research on lightweight and efficient VLA models.

</details>


### [81] [SAFe-Copilot: Unified Shared Autonomy Framework](https://arxiv.org/abs/2511.04664)
*Phat Nguyen,Erfan Aasi,Shiva Sreeram,Guy Rosman,Andrew Silva,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: A shared autonomy framework using VLMs to mediate human-autonomous control at a semantic level improves performance and alignment in driving scenarios.


<details>
  <summary>Details</summary>
Motivation: To address the brittleness of autonomous driving systems in rare, ambiguous, and out-of-distribution scenarios by leveraging human contextual reasoning through shared autonomy.

Method: The framework integrates human input and autonomous planners at a higher abstraction level using Vision Language Models (VLMs) to infer driver intent from multi-modal cues and mediate strategies.

Result: The method achieves perfect recall, high accuracy/precision in mock-human settings, 92% participant agreement in human-subject surveys, and significant performance improvements on the Bench2Drive benchmark.

Conclusion: Arbitration at the level of semantic, language-based representations is a key design principle for shared autonomy, enabling common-sense reasoning and alignment with human intent.

Abstract: Autonomous driving systems remain brittle in rare, ambiguous, and
out-of-distribution scenarios, where human driver succeed through contextual
reasoning. Shared autonomy has emerged as a promising approach to mitigate such
failures by incorporating human input when autonomy is uncertain. However, most
existing methods restrict arbitration to low-level trajectories, which
represent only geometric paths and therefore fail to preserve the underlying
driving intent. We propose a unified shared autonomy framework that integrates
human input and autonomous planners at a higher level of abstraction. Our
method leverages Vision Language Models (VLMs) to infer driver intent from
multi-modal cues -- such as driver actions and environmental context -- and to
synthesize coherent strategies that mediate between human and autonomous
control. We first study the framework in a mock-human setting, where it
achieves perfect recall alongside high accuracy and precision. A human-subject
survey further shows strong alignment, with participants agreeing with
arbitration outcomes in 92% of cases. Finally, evaluation on the Bench2Drive
benchmark demonstrates a substantial reduction in collision rate and
improvement in overall performance compared to pure autonomy. Arbitration at
the level of semantic, language-based representations emerges as a design
principle for shared autonomy, enabling systems to exercise common-sense
reasoning and maintain continuity with human intent.

</details>


### [82] [Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions](https://arxiv.org/abs/2511.04665)
*Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li*

Main category: cs.RO

TL;DR: 提出了一种结合物理信息重建与3D渲染的仿真框架，用于低成本、高保真地评估机器人操作策略。


<details>
  <summary>Details</summary>
Motivation: 由于直接在现实世界中评估机器人操作策略成本高、耗时长且难以复现，特别是涉及可变形物体的任务。

Method: 提出了一个从现实世界视频构建软体数字孪生，并使用3D高斯泼溅技术渲染机器人、物体和环境的真实感框架。

Result: 在典型可变形物体操作任务（如毛绒玩具包装、绳子路由和T形块推动）上验证了模拟与真实世界执行性能的高度相关性。

Conclusion: 结合物理信息重建与高质量渲染技术，能够实现可重复、可扩展且准确的机器人操作策略评估。

Abstract: Robotic manipulation policies are advancing rapidly, but their direct
evaluation in the real world remains costly, time-consuming, and difficult to
reproduce, particularly for tasks involving deformable objects. Simulation
provides a scalable and systematic alternative, yet existing simulators often
fail to capture the coupled visual and physical complexity of soft-body
interactions. We present a real-to-sim policy evaluation framework that
constructs soft-body digital twins from real-world videos and renders robots,
objects, and environments with photorealistic fidelity using 3D Gaussian
Splatting. We validate our approach on representative deformable manipulation
tasks, including plush toy packing, rope routing, and T-block pushing,
demonstrating that simulated rollouts correlate strongly with real-world
execution performance and reveal key behavioral patterns of learned policies.
Our results suggest that combining physics-informed reconstruction with
high-quality rendering enables reproducible, scalable, and accurate evaluation
of robotic manipulation policies. Website: https://real2sim-eval.github.io/

</details>


### [83] [X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations](https://arxiv.org/abs/2511.04671)
*Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia*

Main category: cs.RO

TL;DR: X-Diffusion利用噪声扩散过程，有效利用人类视频数据训练机器人策略，避免不可行动作，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 人类和机器人在动作执行上存在根本性差异，直接使用人类手部动作会导致机器人执行不可行的动作。然而，人类演示提供了有价值的运动线索。

Method: X-Diffusion首先训练一个分类器来预测噪声动作是由人类还是机器人执行的。然后，在策略训练中仅当添加足够噪声使得分类器无法区分动作来源时才纳入人类动作。

Result: X-Diffusion在五种操作任务中表现优于基线方法，平均成功率提高了16%。

Conclusion: X-Diffusion框架通过利用人类视频数据，同时避免学习动态不可行的动作，显著提高了机器人策略的性能，平均成功率比最佳基线高16%。

Abstract: Human videos can be recorded quickly and at scale, making them an appealing
source of training data for robot learning. However, humans and robots differ
fundamentally in embodiment, resulting in mismatched action execution. Direct
kinematic retargeting of human hand motion can therefore produce actions that
are physically infeasible for robots. Despite these low-level differences,
human demonstrations provide valuable motion cues about how to manipulate and
interact with objects. Our key idea is to exploit the forward diffusion
process: as noise is added to actions, low-level execution differences fade
while high-level task guidance is preserved. We present X-Diffusion, a
principled framework for training diffusion policies that maximally leverages
human data without learning dynamically infeasible motions. X-Diffusion first
trains a classifier to predict whether a noisy action is executed by a human or
robot. Then, a human action is incorporated into policy training only after
adding sufficient noise such that the classifier cannot discern its embodiment.
Actions consistent with robot execution supervise fine-grained denoising at low
noise levels, while mismatched human actions provide only coarse guidance at
higher noise levels. Our experiments show that naive co-training under
execution mismatches degrades policy performance, while X-Diffusion
consistently improves it. Across five manipulation tasks, X-Diffusion achieves
a 16% higher average success rate than the best baseline. The project website
is available at https://portal-cornell.github.io/X-Diffusion/.

</details>


### [84] [GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction](https://arxiv.org/abs/2511.04679)
*Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu*

Main category: cs.RO

TL;DR: GentleHumanoid通过整合阻抗控制与全身运动跟踪，实现了人形机器人上半身的柔顺交互，降低了接触力峰值，提升了协作安全性。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习策略过于强调刚性跟踪，抑制外部力，而现有阻抗控制方法多限于基座或末端执行器控制，且侧重抵抗极端力而非实现柔顺性。这限制了人形机器人在以人为中心环境中的安全自然交互能力。

Method: GentleHumanoid采用基于弹簧的统一建模方法，同时处理抵抗性接触（如按压表面时的恢复力）和引导性接触（从人类运动数据中采样的推拉动作），确保肩、肘、腕的力学一致性，并通过任务可调力阈值增强安全性。

Result: 在仿真和Unitree G1人形机器人上的实验表明，GentleHumanoid在需要不同柔顺水平的任务（如轻柔拥抱、坐立辅助和安全物体操作）中，均能显著降低峰值接触力并保持任务成功率。

Conclusion: GentleHumanoid框架通过整合阻抗控制和全身运动跟踪策略，实现了上半身的柔顺性，显著降低了接触力峰值，同时保持了任务成功率，使交互更平滑自然。这标志着人形机器人在实际环境中安全有效协作的重要进展。

Abstract: Humanoid robots are expected to operate in human-centered environments where
safe and natural physical interaction is essential. However, most recent
reinforcement learning (RL) policies emphasize rigid tracking and suppress
external forces. Existing impedance-augmented approaches are typically
restricted to base or end-effector control and focus on resisting extreme
forces rather than enabling compliance. We introduce GentleHumanoid, a
framework that integrates impedance control into a whole-body motion tracking
policy to achieve upper-body compliance. At its core is a unified spring-based
formulation that models both resistive contacts (restoring forces when pressing
against surfaces) and guiding contacts (pushes or pulls sampled from human
motion data). This formulation ensures kinematically consistent forces across
the shoulder, elbow, and wrist, while exposing the policy to diverse
interaction scenarios. Safety is further supported through task-adjustable
force thresholds. We evaluate our approach in both simulation and on the
Unitree G1 humanoid across tasks requiring different levels of compliance,
including gentle hugging, sit-to-stand assistance, and safe object
manipulation. Compared to baselines, our policy consistently reduces peak
contact forces while maintaining task success, resulting in smoother and more
natural interactions. These results highlight a step toward humanoid robots
that can safely and effectively collaborate with humans and handle objects in
real-world environments.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [85] [Tutorial Debriefing: Applied Statistical Causal Inference in Requirements Engineering](https://arxiv.org/abs/2511.03875)
*Julian Frattini,Hans-Martin Heyn,Robert Feldt,Richard Torkar*

Main category: cs.SE

TL;DR: 软件工程研究需通过统计因果推断从观测数据中证明工具、流程或指南的因果效应，以支持实践应用。


<details>
  <summary>Details</summary>
Motivation: 软件工程研究的目标是改善软件生产者和消费者的体验，但随机对照试验在法律、伦理或操作上可能不可行。

Method: 提出使用统计因果推断方法分析观测数据，以替代随机对照试验（RCTs）。

Result: 强调了在无法进行随机对照试验时，统计因果推断方法的重要性。

Conclusion: 软件工程研究需要通过统计因果推断（SCI）从观测数据中获取可靠的因果关系证据，以支持研究成果向实践的转化。

Abstract: As any scientific discipline, the software engineering (SE) research
community strives to contribute to the betterment of the target population of
our research: software producers and consumers. We will only achieve this
betterment if we manage to transfer the knowledge acquired during research into
practice. This transferal of knowledge may come in the form of tools,
processes, and guidelines for software developers. However, the value of these
contributions hinges on the assumption that applying them causes an improvement
of the development process, user experience, or other performance metrics. Such
a promise requires evidence of causal relationships between an exposure or
intervention (i.e., the contributed tool, process or guideline) and an outcome
(i.e., performance metrics). A straight-forward approach to obtaining this
evidence is via controlled experiments in which a sample of a population is
randomly divided into a group exposed to the new tool, process, or guideline,
and a control group. However, such randomized control trials may not be
legally, ethically, or logistically feasible. In these cases, we need a
reliable process for statistical causal inference (SCI) from observational
data.

</details>


### [86] [Collaborative Agents for Automated Program Repair in Ruby](https://arxiv.org/abs/2511.03925)
*Nikta Akbarpour,Mahdieh Sadat Benis,Fatemeh Hendijani Fard,Ali Ouni,Mohamed Aymen Saied*

Main category: cs.SE

TL;DR: RAMP是一个针对Ruby的轻量级APR框架，通过多Agent协作和测试驱动反馈，显著提升修复效率，尤其在错误答案、编译和运行时错误修复上表现突出。


<details>
  <summary>Details</summary>
Motivation: 针对Ruby语言在APR研究中被忽视的现状，提出一种轻量级、反馈驱动的迭代修复框架。

Method: RAMP采用协作Agent团队生成针对性测试、反思错误并迭代优化候选修复，直至找到正确解决方案。

Result: 在XCodeEval基准测试中，RAMP在Ruby上的pass@1达到67%，优于现有方法，且在五轮迭代内快速收敛。

Conclusion: RAMP为基于LLM的调试工具在未充分研究语言中的应用提供了新见解，并建立了多Agent修复策略的基础。

Abstract: Automated Program Repair (APR) has advanced rapidly with Large Language
Models (LLMs), but most existing methods remain computationally expensive, and
focused on a small set of languages. Ruby, despite its widespread use in web
development and the persistent challenges faced by its developers, has received
little attention in APR research. In this paper, we introduce RAMP, a novel
lightweight framework that formulates program repair as a feedback-driven,
iterative process for Ruby. RAMP employs a team of collaborative agents that
generate targeted tests, reflect on errors, and refine candidate fixes until a
correct solution is found. Unlike prior approaches, RAMP is designed to avoid
reliance on large multilingual repair databases or costly fine-tuning, instead
operating directly on Ruby through lightweight prompting and test-driven
feedback. Evaluation on the XCodeEval benchmark shows that RAMP achieves a
pass@1 of 67% on Ruby, outper-forming prior approaches. RAMP converges quickly
within five iterations, and ablation studies confirm that test generation and
self-reflection are key drivers of its performance. Further analysis shows that
RAMP is particularly effective at repairing wrong answers, compilation errors,
and runtime errors. Our approach provides new insights into multi-agent repair
strategies, and establishes a foundation for extending LLM-based debugging
tools to under-studied languages.

</details>


### [87] [PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI](https://arxiv.org/abs/2511.03934)
*Athma Narayanan,Mahesh Subedar,Omesh Tickoo*

Main category: cs.SE

TL;DR: 提出一种多代理流程（PEFA），结合LLM和硬件工具自动生成RTL，通过迭代反馈提升性能，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决复杂RTL生成任务中的人工干预问题，通过自适应代码生成方法提高效率和准确性。

Method: 采用多代理流程，结合专业LLM和硬件仿真工具，通过渐进式错误反馈系统（PEFA）逐步增加任务复杂性，生成包含编译、功能正确性和可综合构造检查的RTL。

Result: 在开源自然语言到RTL数据集上的基准测试显示，该方法在开放和封闭源LLM上均能有效缩小性能差距，显著优于先前发表的方法。

Conclusion: 该论文提出的方法在RTL生成任务中设定了新的基准，实现了最先进的通过率，并在token计数上表现出高效性。

Abstract: We present an agentic flow consisting of multiple agents that combine
specialized LLMs and hardware simulation tools to collaboratively complete the
complex task of Register Transfer Level (RTL) generation without human
intervention. A key feature of the proposed flow is the progressive error
feedback system of agents (PEFA), a self-correcting mechanism that leverages
iterative error feedback to progressively increase the complexity of the
approach. The generated RTL includes checks for compilation, functional
correctness, and synthesizable constructs. To validate this adaptive approach
to code generation, benchmarking is performed using two opensource natural
language-to-RTL datasets. We demonstrate the benefits of the proposed approach
implemented on an open source agentic framework, using both open- and
closed-source LLMs, effectively bridging the performance gap between them.
Compared to previously published methods, our approach sets a new benchmark,
providing state-of-the-art pass rates while being efficient in token counts.

</details>


### [88] [PSD2Code: Automated Front-End Code Generation from Design Files via Multimodal Large Language Models](https://arxiv.org/abs/2511.04012)
*Yongxi Chen,Lei Chen*

Main category: cs.SE

TL;DR: PSD2Code利用PSD解析和多模态大语言模型生成高质量前端代码，解决了现有方法的结构和资产对齐问题。


<details>
  <summary>Details</summary>
Motivation: 现有设计到代码生成方法存在结构不一致、资产未对齐和生产准备不足等问题。

Method: 提出ParseAlignGenerate流水线，结合PSD文件解析和资产对齐策略，利用约束对齐和结构化提示生成高质量的React+SCSS代码。

Result: 全面评估显示在代码相似性、视觉保真度和生产准备度等方面显著优于现有方法，且模型独立性表现良好。

Conclusion: PSD2Code通过整合结构化设计信息与多模态大语言模型，为工业级代码生成提供了有效方法，标志着设计驱动的前端自动化开发迈出了重要一步。

Abstract: Design-to-code generation has emerged as a promising approach to bridge the
gap between design prototypes and deployable frontend code. However, existing
methods often suffer from structural inconsistencies, asset misalignment, and
limited production readiness. This paper presents PSD2Code, a novel multi-modal
approach that leverages PSD file parsing and asset alignment to generate
production-ready React+SCSS code. Our method introduces a ParseAlignGenerate
pipeline that extracts hierarchical structures, layer properties, and metadata
from PSD files, providing large language models with precise spatial
relationships and semantic groupings for frontend code generation. The system
employs a constraint-based alignment strategy that ensures consistency between
generated elements and design resources, while a structured prompt construction
enhances controllability and code quality. Comprehensive evaluation
demonstrates significant improvements over existing methods across multiple
metrics including code similarity, visual fidelity, and production readiness.
The method exhibits strong model independence across different large language
models, validating the effectiveness of integrating structured design
information with multimodal large language models for industrial-grade code
generation, marking an important step toward design-driven automated frontend
development.

</details>


### [89] [Specification-Guided Vulnerability Detection with Large Language Models](https://arxiv.org/abs/2511.04014)
*Hao Zhu,Jia Li,Cuiyun Gao,Jiaru Qian,Yihong Dong,Huanyu Liu,Lecheng Wang,Ziliang Wang,Xiaolong Hu,Ge Li*

Main category: cs.SE

TL;DR: VulInstruct通过提取安全规范提升LLMs漏洞检测能力，显著优于基线方法并发现新漏洞。


<details>
  <summary>Details</summary>
Motivation: LLMs在漏洞检测中表现有限，缺乏对安全规范的理解，VulInstruct旨在弥补这一不足。

Method: VulInstruct构建了一个规范知识库，包括跨项目的通用规范和特定仓库的领域特定规范，以指导LLMs进行安全行为推理。

Result: VulInstruct在PrimeVul数据集上F1-score提升32.7%，召回率提升50.8%，并发现了一个新的高严重性漏洞。

Conclusion: VulInstruct通过从历史漏洞中系统提取安全规范，显著提升了LLMs在漏洞检测中的性能，并在实际应用中发现了新的高严重性漏洞。

Abstract: Large language models (LLMs) have achieved remarkable progress in code
understanding tasks. However, they demonstrate limited performance in
vulnerability detection and struggle to distinguish vulnerable code from
patched code. We argue that LLMs lack understanding of security specifications
-- the expectations about how code should behave to remain safe. When code
behavior differs from these expectations, it becomes a potential vulnerability.
However, such knowledge is rarely explicit in training data, leaving models
unable to reason about security flaws. We propose VulInstruct, a
specification-guided approach that systematically extracts security
specifications from historical vulnerabilities to detect new ones. VulInstruct
constructs a specification knowledge base from two perspectives: (i) General
specifications from high-quality patches across projects, capturing fundamental
safe behaviors; and (ii) Domain-specific specifications from repeated
violations in particular repositories relevant to the target code. VulInstruct
retrieves relevant past cases and specifications, enabling LLMs to reason about
expected safe behaviors rather than relying on surface patterns. We evaluate
VulInstruct under strict criteria requiring both correct predictions and valid
reasoning. On PrimeVul, VulInstruct achieves 45.0% F1-score (32.7% improvement)
and 37.7% recall (50.8% improvement) compared to baselines, while uniquely
detecting 24.3% of vulnerabilities -- 2.4x more than any baseline. In pair-wise
evaluation, VulInstruct achieves 32.3% relative improvement. VulInstruct also
discovered a previously unknown high-severity vulnerability (CVE-2025-56538) in
production code, demonstrating practical value for real-world vulnerability
discovery. All code and supplementary materials are available at
https://github.com/zhuhaopku/VulInstruct-temp.

</details>


### [90] [LLM-Driven Adaptive Source-Sink Identification and False Positive Mitigation for Static Analysis](https://arxiv.org/abs/2511.04023)
*Shiyin Lin*

Main category: cs.SE

TL;DR: \textsc{AdaTaint}通过LLM驱动和神经符号推理，显著减少静态分析的假阳性并提高召回率。


<details>
  <summary>Details</summary>
Motivation: 静态分析在发现软件漏洞时存在源-汇规范不完整和假阳性过高的问题。

Method: 提出\textsc{AdaTaint}，一种基于LLM的污点分析框架，通过神经符号推理自适应推断源/汇规范并过滤虚假警报。

Result: 在Juliet 1.3、SV-COMP风格的C基准测试和三个大型实际项目中，\textsc{AdaTaint}平均减少假阳性43.7%，召回率提高11.2%，同时保持竞争力的运行时开销。

Conclusion: 结合LLM推理与符号验证为静态漏洞分析提供了更准确和可靠的实践路径。

Abstract: Static analysis is effective for discovering software vulnerabilities but
notoriously suffers from incomplete source--sink specifications and excessive
false positives (FPs). We present \textsc{AdaTaint}, an LLM-driven taint
analysis framework that adaptively infers source/sink specifications and
filters spurious alerts through neuro-symbolic reasoning. Unlike LLM-only
detectors, \textsc{AdaTaint} grounds model suggestions in program facts and
constraint validation, ensuring both adaptability and determinism.
  We evaluate \textsc{AdaTaint} on Juliet 1.3, SV-COMP-style C benchmarks, and
three large real-world projects. Results show that \textsc{AdaTaint} reduces
false positives by \textbf{43.7\%} on average and improves recall by
\textbf{11.2\%} compared to state-of-the-art baselines (CodeQL, Joern, and
LLM-only pipelines), while maintaining competitive runtime overhead. These
findings demonstrate that combining LLM inference with symbolic validation
offers a practical path toward more accurate and reliable static vulnerability
analysis.

</details>


### [91] [Benchmarking and Studying the LLM-based Agent System in End-to-End Software Development](https://arxiv.org/abs/2511.04064)
*Zhengran Zeng,Yixin Li,Rui Xie,Wei Ye,Shikun Zhang*

Main category: cs.SE

TL;DR: 该论文提出了一个更真实的基准测试和混合评估框架，用于评估LLM基础的软件开发代理，揭示了其成功依赖架构策略，并指出了需求理解和自我验证的不足是主要挑战。


<details>
  <summary>Details</summary>
Motivation: LLM基础的自主代理用于端到端软件开发的科学发展受到重大挑战的阻碍，包括过于简化的基准测试和由于混杂实现变量而难以在不同代理架构之间进行公平比较。

Method: 首先构建了一个具有挑战性且动态策划的E2EDevBench来模拟现实开发场景；其次提出了一个混合评估框架，结合基于测试用例的功能评估和细粒度的、基于LLM的需求验证。使用这一框架，对三种在统一基础上实现的代表性代理架构进行了受控实证研究。

Result: 研究发现，最先进的代理可以满足约50%的需求，但其成功关键取决于任务分解和协作的架构策略。主要瓶颈是需求遗漏和不足的自我验证。

Conclusion: 本研究为社区提供了一个更真实的基准测试、全面的评估框架，以及对软件开发代理当前能力和核心挑战的关键见解，指导未来研究增强需求理解和规划。

Abstract: The development of LLM-based autonomous agents for end-to-end software
development represents a significant paradigm shift in software engineering.
However, the scientific evaluation of these systems is hampered by significant
challenges, including overly simplistic benchmarks and the difficulty of
conducting fair comparisons between different agent architectures due to
confounding implementation variables. To address these limitations, we first
construct a challenging and dynamically curated E2EDevBench to simulate
realistic development scenarios. Second, we propose a hybrid evaluation
framework that combines test-case-based functional assessment with
fine-grained, LLM-based requirement verification. Using this framework, we
conduct a controlled empirical study on three representative agent
architectures implemented upon a unified foundation to isolate the impact of
workflow design. Our findings reveal that state-of-the-art agents can fulfill
approximately 50\% of requirements on \bench{}, but their success is critically
dependent on the architectural strategy for task decomposition and
collaboration. Furthermore, our analysis indicates that the primary bottleneck
is the omission of requirements and inadequate self-verification. This work
provides the community with a more realistic benchmark, a comprehensive
evaluation framework, and crucial insights into the current capabilities and
core challenges of software development agents, guiding future research toward
enhancing requirement comprehension and planning.

</details>


### [92] [How Natural Language Proficiency Shapes GenAI Code for Software Engineering Tasks](https://arxiv.org/abs/2511.04115)
*Ruksit Rojpaisarnkit,Youmei Fan,Kenichi Matsumoto,Raula Gaikovina Kula*

Main category: cs.SE

TL;DR: 研究发现英语语言熟练度显著影响LLM生成代码的正确性，高熟练度提示能提高代码质量。


<details>
  <summary>Details</summary>
Motivation: 研究英语语言熟练度本身（独立于提示技术）是否影响LLM生成的代码的熟练度和正确性。

Method: 使用HumanEval数据集，系统地将提示的英语熟练度从基础到高级变化，测量生成的代码熟练度和正确性。

Result: 发现LLMs默认使用中级（B2）自然语言水平。虽然代码熟练度的影响因模型而异，但高熟练度提示在所有模型中一致产生更正确的代码。

Conclusion: 自然语言熟练度是控制代码生成的关键因素，帮助开发者定制AI输出并提高解决方案的可靠性。

Abstract: With the widespread adoption of Foundation Model (FM)-powered tools in
software engineering, the natural language prompt has become a critical
interface between developers and Large Language Models (LLMs). While much
research has focused on prompt structure, the natural language proficiency is
an underexplored factor that can influence the quality of generated code. This
paper investigates whether the English language proficiency itself independent
of the prompting technique affects the proficiency and correctness of code
generated by LLMs. Using the HumanEval dataset, we systematically varied the
English proficiency of prompts from basic to advanced for 164 programming tasks
and measured the resulting code proficiency and correctness. Our findings show
that LLMs default to an intermediate (B2) natural language level. While the
effect on the resulting code proficiency was model-dependent, we found that
higher-proficiency prompts consistently yielded more correct code across all
models. These results demonstrate that natural language proficiency is a key
lever for controlling code generation, helping developers tailor AI output and
improve the reliability of solutions.

</details>


### [93] [Are We Aligned? A Preliminary Investigation of the Alignment of Responsible AI Values between LLMs and Human Judgment](https://arxiv.org/abs/2511.04157)
*Asma Yamani,Malak Baslyman,Moataz Ahmed*

Main category: cs.SE

TL;DR: LLMs在负责AI价值观上更接近AI从业者而非大众，但在实际需求优先排序中表现不一致，需人类监督。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在软件工程任务中与人类在负责AI价值观上的对齐程度，以揭示潜在风险并推动系统性监控方法。

Method: 研究评估了23个LLM在四项任务中的表现：选择关键负责AI价值观、评估特定情境中的重要性、解决价值观冲突、优先体现这些价值观的软件需求。

Result: LLMs更倾向于AI从业者的价值观（公平、隐私、透明、安全、责任），但在声明与实践之间存在不一致性。

Conclusion: LLMs的价值偏好与AI从业者更为一致，但在声明与实践之间存在差距，强调了在AI辅助软件开发中需要人类监督和系统性方法进行价值对齐的基准测试、解释和监控。

Abstract: Large Language Models (LLMs) are increasingly employed in software
engineering tasks such as requirements elicitation, design, and evaluation,
raising critical questions regarding their alignment with human judgments on
responsible AI values. This study investigates how closely LLMs' value
preferences align with those of two human groups: a US-representative sample
and AI practitioners. We evaluate 23 LLMs across four tasks: (T1) selecting key
responsible AI values, (T2) rating their importance in specific contexts, (T3)
resolving trade-offs between competing values, and (T4) prioritizing software
requirements that embody those values. The results show that LLMs generally
align more closely with AI practitioners than with the US-representative
sample, emphasizing fairness, privacy, transparency, safety, and
accountability. However, inconsistencies appear between the values that LLMs
claim to uphold (Tasks 1-3) and the way they prioritize requirements (Task 4),
revealing gaps in faithfulness between stated and applied behavior. These
findings highlight the practical risk of relying on LLMs in requirements
engineering without human oversight and motivate the need for systematic
approaches to benchmark, interpret, and monitor value alignment in AI-assisted
software development.

</details>


### [94] [Explaining Software Vulnerabilities with Large Language Models](https://arxiv.org/abs/2511.04179)
*Oshando Johnson,Alexandra Fomina,Ranjith Krishnamurthy,Vaibhav Chaudhari,Rohith Kumar Shanmuganathan,Eric Bodden*

Main category: cs.SE

TL;DR: SAFE是一个IDE插件，利用GPT-4o为SAST工具检测到的漏洞提供详细解释，提升开发者理解和修复漏洞的效率。


<details>
  <summary>Details</summary>
Motivation: 由于SAST工具的通用警告信息对开发者不够友好，导致关键漏洞被误解或忽视，因此需要一种更有效的解释方法。

Method: 提出了一种混合方法，结合LLMs（如GPT-4o）构建了SAFE IDE插件，用于解释SAST工具检测到的漏洞的原因、影响和缓解策略。

Result: 专家用户研究表明，SAFE生成的解释能显著帮助初、中级开发者理解和解决安全漏洞。

Conclusion: SAFE插件通过利用GPT-4o生成详细的漏洞解释，显著提升了SAST工具对初、中级开发者的可用性，解决了通用警告信息导致的误解或忽视问题。

Abstract: The prevalence of security vulnerabilities has prompted companies to adopt
static application security testing (SAST) tools for vulnerability detection.
Nevertheless, these tools frequently exhibit usability limitations, as their
generic warning messages do not sufficiently communicate important information
to developers, resulting in misunderstandings or oversight of critical
findings. In light of recent developments in Large Language Models (LLMs) and
their text generation capabilities, our work investigates a hybrid approach
that uses LLMs to tackle the SAST explainability challenges. In this paper, we
present SAFE, an Integrated Development Environment (IDE) plugin that leverages
GPT-4o to explain the causes, impacts, and mitigation strategies of
vulnerabilities detected by SAST tools. Our expert user study findings indicate
that the explanations generated by SAFE can significantly assist beginner to
intermediate developers in understanding and addressing security
vulnerabilities, thereby improving the overall usability of SAST tools.

</details>


### [95] [GITER: A Git-Based Declarative Exchange Model Using Kubernetes-Style Custom Resources](https://arxiv.org/abs/2511.04182)
*Christos Tranoris*

Main category: cs.SE

TL;DR: 论文提出了一种基于Git的轻量级异步通信方法，替代传统API和消息代理，适用于分布式协作，具有透明、可追溯和松耦合的优势。


<details>
  <summary>Details</summary>
Motivation: 传统API和消息代理在跨领域、跨组织及隔离环境中的协作中存在局限性。为了提供更透明、可追溯且松耦合的通信方式，作者提出了一种基于Git的替代方案。

Method: 论文提出了一种基于Git的通信模型，替代传统的API和消息代理。该模型建立在Kubernetes Operators和Custom Resources（CRs）原则之上，通过共享仓库作为单一事实来源，实现发布者与消费者之间的交互。

Result: 该方法成功扩展了GitOps的应用范围，支持跨领域、跨组织及隔离环境中的协作，同时保留了Git的透明度和可审计性。

Conclusion: 该论文提出了一种基于Git的轻量级、可审计的异步信息交换方法，适用于分布式实体间的协作。通过利用Git的版本控制、提交签名和访问控制等原生特性，该方法在保持系统松散耦合和自治的同时，确保了透明度、可追溯性和可重现性。

Abstract: This paper introduces a lightweight and auditable method for asynchronous
information exchange between distributed entities using Git as the coordination
medium. The proposed approach replaces traditional APIs and message brokers
with a Git-based communication model built on the principles of Kubernetes
Operators and Custom Resources (CRs). Each participating entity, designated as
a Publisher or Consumer, interacts through a shared repository that serves as a
single source of truth, where the spec field captures the desired state and the
status field reflects the observed outcome. This pattern extends GitOps beyond
infrastructure management to support cross-domain, inter-organizational, and
air-gapped collaboration scenarios. By leveraging Git native features
(versioning, commit signing, and access control) the model ensures
transparency, traceability, and reproducibility while preserving loose coupling
and autonomy between systems. The paper discusses architectural principles,
implementation considerations, and comparisons with RESTful and broker-based
integrations, highlighting both the advantages and trade-offs of adopting Git
as a declarative communication substrate.

</details>


### [96] [A Tool for Benchmarking Large Language Models' Robustness in Assessing the Realism of Driving Scenarios](https://arxiv.org/abs/2511.04267)
*Jiahui Wu,Chengjie Lu,Aitor Arrieta,Shaukat Ali*

Main category: cs.SE

TL;DR: DriveRLR 是一个评估 LLMs 在驾驶场景现实主义评估中稳健性的工具，展示了其有效性和实用价值。


<details>
  <summary>Details</summary>
Motivation: 评估模拟场景的现实主义难度大，而 LLMs 的推理和泛化能力为这一挑战提供了潜在解决方案。

Method: DriveRLR 通过生成变异场景变体、构建提示来评估给定 LLM 的能力和稳健性。

Result: 在 DeepScenario 数据集上验证了 DriveRLR 的有效性，展示了不同 LLMs 在稳健性上的差异。

Conclusion: DriveRLR 是一个有效的工具，用于评估大型语言模型（LLMs）在驾驶场景现实主义评估中的稳健性，并在模拟自主驾驶系统测试中具有实用价值。

Abstract: In recent years, autonomous driving systems have made significant progress,
yet ensuring their safety remains a key challenge. To this end, scenario-based
testing offers a practical solution, and simulation-based methods have gained
traction due to the high cost and risk of real-world testing. However,
evaluating the realism of simulated scenarios remains difficult, creating
demand for effective assessment methods. Recent advances show that Large
Language Models (LLMs) possess strong reasoning and generalization
capabilities, suggesting their potential in assessing scenario realism through
scenario-related textual prompts. Motivated by this, we propose DriveRLR, a
benchmark tool to assess the robustness of LLMs in evaluating the realism of
driving scenarios. DriveRLR generates mutated scenario variants, constructs
prompts, which are then used to assess a given LLM's ability and robustness in
determining the realism of driving scenarios. We validate DriveRLR on the
DeepScenario dataset using three state-of-the-art LLMs: GPT-5, Llama 4
Maverick, and Mistral Small 3.2. Results show that DriveRLR effectively reveals
differences in the robustness of various LLMs, demonstrating its effectiveness
and practical value in scenario realism assessment. Beyond LLM robustness
evaluation, DriveRLR can serve as a practical component in applications such as
an objective function to guide scenario generation, supporting simulation-based
ADS testing workflows.

</details>


### [97] [Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation Benchmarks](https://arxiv.org/abs/2511.04355)
*Amir Molzam Sharifloo,Maedeh Heydari,Parsa Kazerooni,Daniel Maninger,Mira Mezini*

Main category: cs.SE

TL;DR: 研究发现大型语言模型在代码生成中存在四种常见弱点，并揭示了基准任务中最常导致失败的复杂因素。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在代码生成方面取得了显著成功，但现有的基准和排行榜未能深入揭示模型持续失败的任务，而这些信息对于理解当前局限性和指导未来模型开发至关重要。

Method: 研究团队检查了四个流行基准中的代码生成任务，确定了主要大型语言模型最可能失败的任务，并研究了解决方案代码的静态复杂性是否导致这些失败，随后对114个模型持续表现不佳的任务进行了系统检查。

Result: 分析发现了大型语言模型在代码生成任务中存在的四种重复出现的弱点模式，以及基准任务中最常导致失败的常见复杂因素。

Conclusion: 论文揭示了大型语言模型在代码生成任务中存在的四种常见弱点，并指出了导致这些失败的基准任务中的常见复杂因素，为理解当前模型的局限性和开发更强大的模型提供了重要指导。

Abstract: Large Language Models (LLMs) have achieved remarkable success in code
generation, and the race to improve their performance has become a central
focus of AI research. Benchmarks and leaderboards are increasingly popular,
offering quantitative rankings of LLMs. However, they provide limited insight
into the tasks that LLMs consistently fail to solve - information that is
crucial for understanding current limitations and guiding the development of
more capable models. To address this gap, we examined code generation tasks
across four popular benchmarks, identifying those that major LLMs are most
likely to fail. To understand the causes of these failures, we investigated
whether the static complexity of solution code contributes to them, followed by
a systematic inspection of 114 tasks that LLMs consistently struggled with. Our
analysis revealed four recurring patterns of weaknesses in LLMs, as well as
common complications within benchmark tasks that most often lead to failure.

</details>


### [98] [Speed at the Cost of Quality? The Impact of LLM Agent Assistance on Software Development](https://arxiv.org/abs/2511.04427)
*Hao He,Courtney Miller,Shyam Agarwal,Christian Kästner,Bogdan Vasilescu*

Main category: cs.SE

TL;DR: LLM代理助手Cursor能短暂提升开发速度，但会增加代码问题，长期可能降低效率。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于LLM代理助手在软件开发中实际效果的实证证据。

Method: 采用差分法设计，比较使用Cursor的GitHub项目与未使用的匹配对照组。

Result: Cursor的采用导致开发速度短暂显著提升，但静态分析警告和代码复杂度持续增加。

Conclusion: 采用Cursor等LLM代理助手会显著提高开发速度，但也会导致静态分析警告和代码复杂度的增加，进而影响长期开发效率。

Abstract: Large language models (LLMs) have demonstrated the promise to revolutionize
the field of software engineering. Among other things, LLM agents are rapidly
gaining momentum in their application to software development, with
practitioners claiming a multifold productivity increase after adoption. Yet,
empirical evidence is lacking around these claims. In this paper, we estimate
the causal effect of adopting a widely popular LLM agent assistant, namely
Cursor, on development velocity and software quality. The estimation is enabled
by a state-of-the-art difference-in-differences design comparing
Cursor-adopting GitHub projects with a matched control group of similar GitHub
projects that do not use Cursor. We find that the adoption of Cursor leads to a
significant, large, but transient increase in project-level development
velocity, along with a significant and persistent increase in static analysis
warnings and code complexity. Further panel generalized method of moments
estimation reveals that the increase in static analysis warnings and code
complexity acts as a major factor causing long-term velocity slowdown. Our
study carries implications for software engineering practitioners, LLM agent
assistant designers, and researchers.

</details>


### [99] [EDIT-Bench: Evaluating LLM Abilities to Perform Real-World Instructed Code Edits](https://arxiv.org/abs/2511.04486)
*Wayne Chi,Valerie Chen,Ryan Shar,Aditya Mittal,Jenny Liang,Wei-Lin Chiang,Anastasios Nikolas Angelopoulos,Ion Stoica,Graham Neubig,Ameet Talwalkar,Chris Donahue*

Main category: cs.SE

TL;DR: EDIT-Bench是一个真实世界代码编辑基准测试，评估显示仅有少数LLM表现优异，上下文信息对任务成功率影响显著。


<details>
  <summary>Details</summary>
Motivation: 现有的代码编辑评估基准多依赖人工生成数据，缺乏真实世界使用场景的多样性，因此需要一个更贴近实际的评估工具。

Method: 研究者收集了545个真实世界中的用户指令和代码上下文问题，涵盖多种自然语言和编程语言，设计了包含代码上下文、高亮代码和光标位置等信息的上下文依赖问题。

Result: 在40个不同LLM的评估中，仅有5个模型得分超过60%，且模型性能因用户指令类别和上下文信息量而异，任务成功率差异高达11%。

Conclusion: EDIT-Bench是一个基于真实使用场景的基准测试，用于评估LLM代码编辑能力，结果显示仅有少数模型表现优异，且上下文信息对任务成功率有显著影响。

Abstract: Instructed code editing, where LLMs directly modify a developer's existing
code based on a user instruction, is becoming a widely used interaction mode in
AI coding assistants. However, few benchmarks directly evaluate this capability
and current datasets often rely on artificial sources. We introduce EDIT-Bench,
a benchmark for evaluating LLM code editing capabilities grounded in real-world
usage, i.e., user instructions and code contexts collected in the wild.
EDIT-Bench comprises of 545 problems, multiple natural and programming
languages, and a diverse set of real-world use cases, ranging from resolving
errors to adding features. EDIT-Bench introduces context-dependent problems
that require the model to understand code context, highlighted code, and cursor
position in addition to the user instruction. We evaluate 40 diverse LLMs and
observe that EDIT-Bench is a challenging set of problems where only 5 models
score over 60%. We find that model performance varies across different
categories of user instructions. Further, we find that varying levels of
contextual information greatly affect task success rate, with performance
varying up to 11%, indicating the importance of evaluating with realistic
context.

</details>


### [100] [Microservices Is Dying, A New Method for Module Division Based on Universal Interfaces](https://arxiv.org/abs/2511.04548)
*Qing Wang,Yong Zhang*

Main category: cs.SE

TL;DR: 本文提出了一种计算模块独立性的概念性方法，并设计了EIGHT平台架构，探索了超越微服务和单体架构的新路径。


<details>
  <summary>Details</summary>
Motivation: 追踪模块间耦合的根源，消除模块间的依赖关系。

Method: 从模块变更的影响评估方法出发，提出计算模块独立性的概念性方法，并利用该方法推导模块独立性的必要条件。提出新的系统设计理念和软件工程方法论，采用特定模式设计一组通用接口。

Result: 实现了一个名为EIGHT的平台架构，证明只要保证模块独立性，即使是单进程内的单体应用也能在运行时动态加载、卸载或修改任何部分。

Conclusion: 该架构旨在为日益复杂的系统探索一条新路径，超越了微服务和单体架构。

Abstract: Although microservices have physically isolated modules, they have failed to
prevent the propagation and diffusion of dependencies. To trace the root cause
of the inter-module coupling, this paper, starting from the impact assessment
approach for module changes, proposes a conceptual method for calculating
module independence and utilizes this method to derive the necessary conditions
for module independence. Then, a new system design philosophy and software
engineering methodology is proposed, aimed at eliminating dependencies between
modules. A specific pattern is employed to design a set of universal
interfaces, serving as a universal boundary between modules. Subsequently, this
method is used to implement a platform architecture named EIGHT, demonstrating
that, as long as module independence is guaranteed, even a monolithic
application within a single process can dynamically load, unload, or modify any
part at runtime. Finally, the paper concludes that this architecture aims to
explore a novel path for increasingly complex systems, beyond microservice and
monolithic architectures.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [101] [Shellular Metamaterial Design via Compact Electric Potential Parametrization](https://arxiv.org/abs/2511.04025)
*Chang Liu,Bohan Wang*

Main category: cs.GR

TL;DR: A compact design space for shellular metamaterials with efficient GPU-based evaluation and inverse-design achieves high performance and manufacturability.


<details>
  <summary>Details</summary>
Motivation: The motivation is to create a highly expressive yet compact design space for shellular metamaterials that can cover a wide range of material properties and mechanical responses.

Method: The method involves a GPU-based homogenization pipeline for rapid evaluation and inverse-design scheme to tailor structures to specific properties.

Result: The results show geometric diversity, a wide spectrum of mechanical responses, and performance reaching up to 91.86% of theoretical upper bounds, with practical manufacturability confirmed via additive manufacturing.

Conclusion: The paper introduces a compact design space for shellular metamaterials that achieves high performance and practical manufacturability, showcasing potential for real-world engineering applications.

Abstract: We introduce a compact yet highly expressive design space for shellular
metamaterials. By employing only a few dozen degrees of freedom, this design
space represents geometries ranging from simple planar configurations to
complex triply periodic minimal surfaces. Coupled with this representation, we
develop an efficient GPU-based homogenization pipeline that evaluates the
structure in under 20 ms and computes the corresponding effective elastic
tensor in near-real-time (0.5 s). The high speed of this evaluation facilitates
an exhaustive exploration of the design space and supports an inverse-design
scheme that tailors the shellular structure to specific macroscopic target
property. Structures derived through this approach exhibit not only geometric
diversity but also a wide spectrum of mechanical responses, covering a broad
range of material properties. Moreover, they achieve up to 91.86% of
theoretical upper bounds, a level of performance comparable to state-of-the-art
shellular structures with low solid volume. Finally, our prototypes, fabricated
via additive manufacturing, confirm the practical manufacturability of these
designs, underscoring their potential for real-world engineering applications.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [102] [Attractors Is All You Need: Parity Games In Polynomial Time](https://arxiv.org/abs/2511.03752)
*Rick van der Heijden*

Main category: cs.DS

TL;DR: 提出多项式时间算法解决奇偶游戏问题，运行时间为$\mathcal{O}(n^{2}\cdot(n + m))$，引入新型吸引子确保高效求解。


<details>
  <summary>Details</summary>
Motivation: 解决奇偶游戏问题的多项式时间算法长期未找到，本文旨在填补这一空白。

Method: 引入了一种新型吸引子，仅移除已确定获胜者的区域，确保找到奇偶游戏的最小支配区域。

Result: 算法在$\mathcal{O}(n^{2}\cdot(n + m))$时间内运行，优于以往的吸引子算法。

Conclusion: 本文提出了一种多项式时间算法，解决了持续数十年的搜索问题，能够高效解决奇偶游戏问题。

Abstract: This paper provides a polynomial-time algorithm for solving parity games that
runs in $\mathcal{O}(n^{2}\cdot(n + m))$ time-ending a search that has taken
decades. Unlike previous attractor-based algorithms, the presented algorithm
only removes regions with a determined winner. The paper introduces a new type
of attractor that can guarantee finding the minimal dominion of a parity game.
The attractor runs in polynomial time and can peel the graph empty.

</details>


### [103] [Multi-Pass Streaming Lower Bounds for Uniformity Testing](https://arxiv.org/abs/2511.03960)
*Qian Li,Xin Lyu*

Main category: cs.DS

TL;DR: 论文证明多轮流式均匀性测试的空间-时间权衡下界，扩展了单轮结果，并通过混合论证和通信问题下界实现。


<details>
  <summary>Details</summary>
Motivation: 为了在多轮流式算法中研究均匀性测试的复杂性，并扩展单轮下界的成果。

Method: 通过混合论证将流式问题简化为双玩家通信问题，并针对基本通信任务证明了强下界。

Result: 证明了任何具有恒定优势的ℓ轮流式算法必须满足snℓ=Ω~(m/ϵ²)的权衡关系。

Conclusion: 该论文证明了在多轮流式算法中，均匀性测试的空间和时间存在权衡关系，扩展了单轮的现有下界。

Abstract: We prove multi-pass streaming lower bounds for uniformity testing over a
domain of size $2m$. The tester receives a stream of $n$ i.i.d. samples and
must distinguish (i) the uniform distribution on $[2m]$ from (ii) a
Paninski-style planted distribution in which, for each pair $(2i-1,2i)$, the
probabilities are biased left or right by $\epsilon/2m$. We show that any
$\ell$-pass streaming algorithm using space $s$ and achieving constant
advantage must satisfy the tradeoff $sn\ell=\tilde{\Omega}(m/\epsilon^2)$. This
extends the one-pass lower bound of Diakonikolas, Gouleakis, Kane, and Rao
(2019) to multiple passes.
  Our proof has two components. First, we develop a hybrid argument, inspired
by Dinur (2020), that reduces streaming to two-player communication problems.
This reduction relies on a new perspective on hardness: we identify the source
of hardness as uncertainty in the bias directions, rather than the collision
locations. Second, we prove a strong lower bound for a basic two-player
communication task, in which Alice and Bob must decide whether two random sign
vectors $Y^a,Y^b\in\{\pm 1\}^m$ are independent or identical, yet they cannot
observe the signs directly--only noisy local views of each coordinate. Our
techniques may be of independent use for other streaming problems with
stochastic inputs.

</details>


### [104] [HART: A Hybrid Addressing Scheme for Self-Balancing Binary Search Trees in Phase Change Memory (PCM)](https://arxiv.org/abs/2511.03994)
*Mahek Desai,Apoorva Rumale,Marjan Asadinia*

Main category: cs.DS

TL;DR: HART是一种针对PCM优化的混合寻址方案，通过减少位翻转提升性能，适用于大数据系统。


<details>
  <summary>Details</summary>
Motivation: 传统自平衡二叉搜索树未考虑PCM的耐久性限制和写入不对称性，导致性能下降。HART旨在解决这一问题。

Method: 提出了一种混合寻址方案HART，结合DFATGray编码（用于深层节点）和线性寻址（用于浅层节点），以优化PCM的特性。

Result: 实验表明，HART显著减少了位翻转，提升了PCM的耐久性、寿命，并降低了写入能量和延迟，且计算开销小。

Conclusion: HART方案通过结合DFATGray编码和线性寻址，显著提升了PCM在自平衡二叉搜索树中的性能，减少了位翻转，提高了耐久性和寿命，同时计算开销较低，适用于大数据应用。

Abstract: As DRAM and other transistor-based memory technologies approach their
scalability limits, alternative storage solutions like Phase-Change Memory
(PCM) are gaining attention for their scalability, fast access times, and zero
leakage power. However, current memory-intensive algorithms, especially those
used in big data systems, often overlook PCM's endurance limitations (10^6 to
10^8 writes before degradation) and write asymmetry. Self-balancing binary
search trees (BSTs), which are widely used for large-scale data management,
were developed without considering PCM's unique properties, leading to
potential performance degradation. This paper introduces HART, a novel hybrid
addressing scheme for self-balancing BSTs, designed to optimize PCM's
characteristics. By combining DFATGray code addressing for deeper nodes with
linear addressing for shallower nodes, HART balances reduced bit flips during
frequent rotations at deeper levels with computational simplicity at shallow
levels. Experimental results on PCM-aware AVL trees demonstrate significant
improvements in performance, with a reduction in bit flips leading to enhanced
endurance, increased lifetime, and lower write energy and latency. Notably,
these benefits are achieved without imposing substantial computational
overhead, making HART an efficient solution for big data applications.

</details>


### [105] [Depth-13 Sorting Networks for 28 Channels](https://arxiv.org/abs/2511.04107)
*Chengu Wang*

Main category: cs.DS

TL;DR: 该论文通过结合高质量前缀和使用SAT求解器，将27和28通道排序网络的深度上限从14优化至13。


<details>
  <summary>Details</summary>
Motivation: 改进现有27和28通道排序网络的深度上限，提高排序网络的效率。

Method: 通过反射对称性构建28通道网络，结合16和12通道网络的高质量前缀，逐步贪婪地添加比较器，并使用SAT求解器完成剩余层。

Result: 成功将27和28通道排序网络的深度上限从14降低到13。

Conclusion: 该论文通过结合16通道和12通道网络的高质量前缀，并利用SAT求解器完成剩余层，成功将27和28通道排序网络的深度上限从14降低到13。

Abstract: We establish new depth upper bounds for sorting networks on 27 and 28
channels, improving the previous best bound of 14 to 13. Our 28-channel network
is constructed with reflectional symmetry by combining high-quality prefixes of
16- and 12-channel networks, extending them greedily one comparator at a time,
and using a SAT solver to complete the remaining layers.

</details>


### [106] [Counting Patterns in Degenerate Graphs in Constant Space](https://arxiv.org/abs/2511.04258)
*Balagopal Komarath,Anant Kumar,Akash Pareek*

Main category: cs.DS

TL;DR: 本文提出DAG treedepth参数，实现了常数空间下的高效分治算法，并优化了DAG treewidth的计数性能。


<details>
  <summary>Details</summary>
Motivation: 研究在n顶点d-退化图中计数同态、子图同构和诱导子图同构的算法复杂性，以解决现有算法在空间和时间效率上的不足。

Method: 通过引入DAG treedepth参数，设计了常数空间的分治算法，并对DAG treewidth进行了优化，提高了计数效率。

Result: 展示了DAG treedepth在常数空间下的高效算法，改进了DAG treewidth的计数速度，并针对特定规模的模式图提供了更快的计数方法。

Conclusion: 本文提出了一个新的图参数DAG treedepth，并展示了其在常数空间下进行高效分治算法的能力，同时改进了DAG treewidth的相关算法性能。

Abstract: For an arbitrary, fixed graph (pattern graph), we study the algorithmic
complexity of counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms from the pattern graph to $n$-vertex, $d$-degenerate
graphs as input. Recent work by Bressan (Algorithmica, 2021) has shown that
this problem has efficient dynamic programming algorithms using a graph
parameter called DAG treewidth. Bressan used DAG treewidth to design a fast
algorithm for counting homomorphisms, subgraph isomorphisms, and induced
subgraph isomorphisms that use polynomial space. Bera, Gishboliner, Levanzov,
Seshadhri, and Shapira (SODA, 2021) provided a characterization of graphs with
DAG treewidth one.
  In this paper, we introduce a new graph parameter called DAG treedepth and
show that it yields efficient divide and conquer algorithms that use only
constant space (in the unit-cost RAM model). Specifically, we show:
  An algorithm for counting subgraphs isomorphic to sparse pattern graphs using
only constant space.
  We derive an induced minor-based characterization for graphs of DAG treedepth
up to two.
  For pattern graphs upto nine vertices, the induced subgraphs can be counted
in $O(n^3)$ time using constant space.
  An algorithm for counting induced subgraphs that matches the running time
given by Bressan but only uses constant space.
  Apart from the DAG treedepth result, we also focus on DAG treewidth. For DAG
treewidth, we show that we can count homomorphisms, subgraph isomorphisms, and
induced subgraph isomorphisms faster than Bressan's algorithm (2021). We
further show that for all pattern graphs up to 11 vertices, we can count
induced subgraphs in quadratic time.

</details>


### [107] [Estimating Hitting Times Locally At Scale](https://arxiv.org/abs/2511.04343)
*Themistoklis Haris,Fabian Spaeh,Spyros Dragazis,Charalampos Tsourakakis*

Main category: cs.DS

TL;DR: 本文开发了两种高效局部算法来估计图中顶点间的命中时间，改进了全局方法的可扩展性，并通过理论和实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 命中时间是衡量随机过程中距离的基本指标，但在大规模图中，全局方法的计算成本高，因此需要开发局部算法以提高效率。

Method: 第一种算法基于两个独立随机游走的相遇时间截断命中时间计算，利用Kronecker积图和Markov Chain Chernoff边界进行分析；第二种算法扩展了Peng等人的工作，引入谱截断技术的改进版以处理命中时间的不对称性。

Result: 算法在理论和实验上均表现出色，提供了紧致的渐近下界，并揭示了命中时间估计与分布测试之间的联系。

Conclusion: 本研究提出了两种局部算法来估计顶点间的命中时间，克服了全局方法的可扩展性问题，并通过理论和实验验证了其有效性。

Abstract: Hitting times provide a fundamental measure of distance in random processes,
quantifying the expected number of steps for a random walk starting at node $u$
to reach node $v$. They have broad applications across domains such as network
centrality analysis, ranking and recommendation systems, and epidemiology. In
this work, we develop local algorithms for estimating hitting times between a
pair of vertices $u,v$ without accessing the full graph, overcoming scalability
issues of prior global methods. Our first algorithm uses the key insight that
hitting time computations can be truncated at the meeting time of two
independent random walks from $u$ and $v$. This leads to an efficient estimator
analyzed via the Kronecker product graph and Markov Chain Chernoff bounds. We
also present an algorithm extending the work of [Peng et al.; KDD 2021], that
introduces a novel adaptation of the spectral cutoff technique to account for
the asymmetry of hitting times. This adaptation captures the directionality of
the underlying random walk and requires non-trivial modifications to ensure
accuracy and efficiency. In addition to the algorithmic upper bounds, we also
provide tight asymptotic lower bounds. We also reveal a connection between
hitting time estimation and distribution testing, and validate our algorithms
using experiments on both real and synthetic data.

</details>


### [108] [A Polynomial-Time Algorithm for the Next-to-Shortest Path Problem on Positively Weighted Directed Graphs](https://arxiv.org/abs/2511.04345)
*Kuowen Chen,Nicole Wein,Yiran Zhang*

Main category: cs.DS

TL;DR: 解决了30年未决的有向图（边权为正）次短路径问题，提出了多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 次短路径问题自1996年提出后，尽管在无向图和有向平面图中有多项式时间算法，但在边权为正的有向图中一直未解决，这一问题具有重要的理论和实践意义。

Method: 我们提供了一种算法，专门针对边权为正的有向图，解决了次短路径问题。

Result: 我们成功设计出一种算法，能够在多项式时间内解决边权为正的有向图中的次短路径问题。

Conclusion: 本研究解决了长达30年的开放性问题，提出了在有向图且边权为正的情况下，次短路径问题的多项式时间算法。

Abstract: Given a graph and a pair of terminals $s$, $t$, the next-to-shortest path
problem asks for an $s\!\to \!t$ (simple) path that is shortest among all not
shortest $s\!\to \!t$ paths (if one exists). This problem was introduced in
1996, and soon after was shown to be NP-complete for directed graphs with
non-negative edge weights, leaving open the case of positive edge weights.
Subsequent work investigated this open question, and developed polynomial-time
algorithms for the cases of undirected graphs and planar directed graphs. In
this work, we resolve this nearly 30-year-old open problem by providing an
algorithm for the next-to-shortest path problem on directed graphs with
positive edge weights.

</details>


### [109] [Free-order secretary for two-sided independence systems](https://arxiv.org/abs/2511.04390)
*Kristóf Bérczi,Vasilis Livanos,José A. Soto,Victor Verdugo*

Main category: cs.DS

TL;DR: 该论文通过二部图框架和k-growth系统，设计了自由顺序和代理到达模型下的竞争性算法，解决了在线优化中的组合约束问题。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在线优化中的顺序决策问题，特别是在组合约束下的自由顺序设定和代理到达模型的挑战。

Method: 论文采用二部图框架，结合核心引理和k-growth系统，设计了针对k-拟阵交和自由顺序设定的竞争性算法。

Result: 提出了Ω(1/k²)-竞争性算法，扩展了单拟阵的结果，并在代理到达模型中实现了Ω(β/k²)-竞争性算法，同时在多重物品选择场景中获得了恒定竞争性算法。

Conclusion: 该论文通过引入二部图框架，扩展了自由顺序设定下的算法设计，为k-growth系统提供了竞争性算法，并解决了代理到达模型的独特挑战，最终在多重物品选择场景中实现了恒定竞争性算法。

Abstract: The Matroid Secretary Problem is a central question in online optimization,
modeling sequential decision-making under combinatorial constraints. We
introduce a bipartite graph framework that unifies and extends several known
formulations, including the bipartite matching, matroid intersection, and
random-order matroid secretary problems. In this model, elements form a
bipartite graph between agents and items, and the objective is to select a
matching that satisfies feasibility constraints on both sides, given by two
independence systems.
  We study the free-order setting, where the algorithm may adaptively choose
the next element to reveal. For $k$-matroid intersection, we leverage a core
lemma by (Feldman, Svensson and Zenklusen, 2022) to design an
$\Omega(1/k^2)$-competitive algorithm, extending known results for single
matroids. Building on this, we identify the structural property underlying our
approach and introduce $k$-growth systems. We establish a generalized core
lemma for $k$-growth systems, showing that a suitably defined set of critical
elements retains a $\Omega(1/k^2)$ fraction of the optimal weight. Using this
lemma, we extend our $\Omega(1/k^2)$-competitive algorithm to $k$-growth
systems for the edge-arrival model.
  We then study the agent-arrival model, which presents unique challenges to
our framework. We extend the core lemma to this model and then apply it to
obtain an $\Omega(\beta/k^2)$-competitive algorithm for $k$-growth systems,
where $\beta$ denotes the competitiveness of a special type of order-oblivious
algorithm for the item-side constraint. Finally, we relax the matching
assumption and extend our results to the case of multiple item selection, where
agents have individual independence systems coupled by a global item-side
constraint. We obtain constant-competitive algorithms for fundamental cases
such as partition matroids and $k$-matching constraints.

</details>


### [110] [Online Algorithms for Repeated Optimal Stopping: Achieving Both Competitive Ratio and Regret Bounds](https://arxiv.org/abs/2511.04484)
*Tsubasa Harada,Yasushi Kawase,Hanna Sumita*

Main category: cs.DS

TL;DR: 论文提出一个通用算法框架，解决重复最优停止问题，保证每轮竞争比和次线性遗憾，适用于多种经典问题，性能接近理论下限。


<details>
  <summary>Details</summary>
Motivation: 解决重复最优停止问题中如何在每轮保持竞争比的同时实现次线性遗憾的问题。

Method: 动态选择算法：每轮在历史观察得出的经验最优算法和具有竞争比保证的样本算法之间选择。

Result: 算法在每轮表现不低于基线样本算法，总遗憾为$\tilde{O}(\sqrt{T})$，适用于多种经典问题（如先知不等式、秘书问题等）。

Conclusion: 该论文的算法框架在重复最优停止问题中表现优异，几乎达到了理论下限，证明了其高效性和广泛适用性。

Abstract: We study the repeated optimal stopping problem, which generalizes the
classical optimal stopping problem with an unknown distribution to a setting
where the same problem is solved repeatedly over $T$ rounds. In this framework,
we aim to design algorithms that guarantee a competitive ratio in each round
while also achieving sublinear regret across all rounds.
  Our primary contribution is a general algorithmic framework that achieves
these objectives simultaneously for a wide array of repeated optimal stopping
problems. The core idea is to dynamically select an algorithm for each round,
choosing between two candidates: (1) an empirically optimal algorithm derived
from the history of observations, and (2) a sample-based algorithm with a
proven competitive ratio guarantee. Based on this approach, we design an
algorithm that performs no worse than the baseline sample-based algorithm in
every round, while ensuring that the total regret is bounded by
$\tilde{O}(\sqrt{T})$.
  We demonstrate the broad applicability of our framework to canonical
problems, including the prophet inequality, the secretary problem, and their
variants under adversarial, random, and i.i.d. input models. For example, for
the repeated prophet inequality problem, our method achieves a
$1/2$-competitive ratio from the second round on and an $\tilde{O}(\sqrt{T})$
regret. Furthermore, we establish a regret lower bound of $\Omega(\sqrt{T})$
even in the i.i.d. model, confirming that our algorithm's performance is almost
optimal with respect to the number of rounds.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [111] [Scaling Agent Learning via Experience Synthesis](https://arxiv.org/abs/2511.03773)
*Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh*

Main category: cs.AI

TL;DR: DreamGym是一个统一框架，通过合成多样化经验数据提升RL训练效果，显著减少真实环境交互需求，适用于模拟到真实迁移。


<details>
  <summary>Details</summary>
Motivation: 为了解决RL在大型语言模型（LLM）代理中实际应用时的挑战，如高成本、任务多样性不足、奖励信号不稳定等，DreamGym旨在提供一个可扩展的经验合成框架。

Method: DreamGym采用基于推理的经验模型替代昂贵的真实环境交互，结合离线数据初始化的经验回放缓冲区和自适应任务生成，实现高效的在线RL训练。

Result: 在WebArena等非RL就绪任务上，DreamGym超越基线30%以上；在RL就绪但成本高的场景中，仅用合成交互即匹配GRPO和PPO性能。

Conclusion: DreamGym通过合成多样化的经验数据，显著提升了强化学习（RL）的训练效果，并在模拟到真实场景的迁移中表现出色。

Abstract: While reinforcement learning (RL) can empower large language model (LLM)
agents by enabling self-improvement through interaction, its practical adoption
remains challenging due to costly rollouts, limited task diversity, unreliable
reward signals, and infrastructure complexity, all of which obstruct the
collection of scalable experience data. To address these challenges, we
introduce DreamGym, the first unified framework designed to synthesize diverse
experiences with scalability in mind to enable effective online RL training for
autonomous agents. Rather than relying on expensive real-environment rollouts,
DreamGym distills environment dynamics into a reasoning-based experience model
that derives consistent state transitions and feedback signals through
step-by-step reasoning, enabling scalable agent rollout collection for RL. To
improve the stability and quality of transitions, DreamGym leverages an
experience replay buffer initialized with offline real-world data and
continuously enriched with fresh interactions to actively support agent
training. To improve knowledge acquisition, DreamGym adaptively generates new
tasks that challenge the current agent policy, enabling more effective online
curriculum learning. Experiments across diverse environments and agent
backbones demonstrate that DreamGym substantially improves RL training, both in
fully synthetic settings and in sim-to-real transfer scenarios. On non-RL-ready
tasks like WebArena, DreamGym outperforms all baselines by over 30%. And in
RL-ready but costly settings, it matches GRPO and PPO performance using only
synthetic interactions. When transferring a policy trained purely on synthetic
experiences to real-environment RL, DreamGym yields significant additional
performance gains while requiring far fewer real-world interactions, providing
a scalable warm-start strategy for general-purpose RL.

</details>


### [112] [How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis](https://arxiv.org/abs/2511.03825)
*Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder*

Main category: cs.AI

TL;DR: 本研究评估了NLP分词模型在汇编代码中的表现，发现分词器选择对下游任务有重要影响，并探讨了内在与外在性能的复杂权衡。


<details>
  <summary>Details</summary>
Motivation: 汇编代码中的分词是一个未充分探索的领域，但其对下游任务（如函数签名预测）有显著影响。本研究旨在填补这一空白。

Method: 通过内在评估比较不同分词器的效率、词汇压缩和对汇编代码的表示保真度，并使用先进的预训练模型（如LLM Llama 3.2、BERT和BART）评估其性能。

Result: 初步结果表明，分词器选择显著影响下游性能，内在指标能部分但不完全预测外在评估结果。

Conclusion: 本研究为低级代码分析中的分词模型优化提供了宝贵见解，增强了基于自然语言模型的二进制分析工作流程的稳健性和可扩展性。

Abstract: Tokenization is fundamental in assembly code analysis, impacting intrinsic
characteristics like vocabulary size, semantic coverage, and extrinsic
performance in downstream tasks. Despite its significance, tokenization in the
context of assembly code remains an underexplored area. This study aims to
address this gap by evaluating the intrinsic properties of Natural Language
Processing (NLP) tokenization models and parameter choices, such as vocabulary
size. We explore preprocessing customization options and pre-tokenization rules
tailored to the unique characteristics of assembly code. Additionally, we
assess their impact on downstream tasks like function signature prediction -- a
critical problem in binary code analysis.
  To this end, we conduct a thorough study on various tokenization models,
systematically analyzing their efficiency in encoding assembly instructions and
capturing semantic nuances. Through intrinsic evaluations, we compare
tokenizers based on tokenization efficiency, vocabulary compression, and
representational fidelity for assembly code. Using state-of-the-art pre-trained
models such as the decoder-only Large Language Model (LLM) Llama 3.2, the
encoder-only transformer BERT, and the encoder-decoder model BART, we evaluate
the effectiveness of these tokenizers across multiple performance metrics.
Preliminary findings indicate that tokenizer choice significantly influences
downstream performance, with intrinsic metrics providing partial but incomplete
predictability of extrinsic evaluation outcomes. These results reveal complex
trade-offs between intrinsic tokenizer properties and their utility in
practical assembly code tasks. Ultimately, this study provides valuable
insights into optimizing tokenization models for low-level code analysis,
contributing to the robustness and scalability of Natural Language Model
(NLM)-based binary analysis workflows.

</details>


### [113] [To See or To Read: User Behavior Reasoning in Multimodal LLMs](https://arxiv.org/abs/2511.03845)
*Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan*

Main category: cs.AI

TL;DR: BehaviorLens框架显示，图像表示比文本更能提升MLLM的预测准确性，提升达87.5%。


<details>
  <summary>Details</summary>
Motivation: 探索文本与图像表示哪种更能有效提升MLLM在用户行为推理中的性能。

Method: 通过BehaviorLens框架，将交易数据表示为文本段落、散点图和流程图，并在六种MLLMs上进行评估。

Result: 图像表示使MLLM的下一购买预测准确性提高了87.5%。

Conclusion: 图像表示（散点图和流程图）在提升MLLM的下一购买预测准确性上显著优于文本表示，无需额外计算成本。

Abstract: Multimodal Large Language Models (MLLMs) are reshaping how modern agentic
systems reason over sequential user-behavior data. However, whether textual or
image representations of user behavior data are more effective for maximizing
MLLM performance remains underexplored. We present \texttt{BehaviorLens}, a
systematic benchmarking framework for assessing modality trade-offs in
user-behavior reasoning across six MLLMs by representing transaction data as
(1) a text paragraph, (2) a scatter plot, and (3) a flowchart. Using a
real-world purchase-sequence dataset, we find that when data is represented as
images, MLLMs next-purchase prediction accuracy is improved by 87.5% compared
with an equivalent textual representation without any additional computational
cost.

</details>


### [114] [KnowThyself: An Agentic Assistant for LLM Interpretability](https://arxiv.org/abs/2511.03878)
*Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang*

Main category: cs.AI

TL;DR: KnowThyself 是一个基于聊天的 LLM 可解释性工具，通过整合现有功能并简化交互流程，降低了技术门槛。


<details>
  <summary>Details</summary>
Motivation: 现有的 LLM 可解释性工具虽然提供了有用的见解，但仍显得分散且代码密集，这激发了开发 KnowThyself 的需求。

Method: KnowThyself 的核心是一个编排器 LLM，它首先重新表述用户查询，然后由代理路由器将查询定向到专门的模块，最后将输出情境化为连贯的解释。

Result: KnowThyself 提供了一个交互式可视化界面，用户可以通过自然语言提问并获得引导式解释，从而增强了 LLM 的可访问性和可解释性。

Conclusion: KnowThyself 通过整合现有工具并提供一个基于聊天的界面，显著降低了大型语言模型（LLM）可解释性的技术门槛，并为其提供了一个可扩展的平台。

Abstract: We develop KnowThyself, an agentic assistant that advances large language
model (LLM) interpretability. Existing tools provide useful insights but remain
fragmented and code-intensive. KnowThyself consolidates these capabilities into
a chat-based interface, where users can upload models, pose natural language
questions, and obtain interactive visualizations with guided explanations. At
its core, an orchestrator LLM first reformulates user queries, an agent router
further directs them to specialized modules, and the outputs are finally
contextualized into coherent explanations. This design lowers technical
barriers and provides an extensible platform for LLM inspection. By embedding
the whole process into a conversational workflow, KnowThyself offers a robust
foundation for accessible LLM interpretability.

</details>


### [115] [Extracting Causal Relations in Deep Knowledge Tracing](https://arxiv.org/abs/2511.03948)
*Kevin Hong,Kia Karbasi,Gregory Pottie*

Main category: cs.AI

TL;DR: DKT的优势在于隐式建模知识组件的因果依赖关系，而非双向关系；通过修剪DAGs和实证验证了这一结论。


<details>
  <summary>Details</summary>
Motivation: 挑战DKT性能提升源于建模知识组件间双向关系的流行解释，探究其实际优势是否源于对先决关系（因果结构）的隐式建模。

Method: 通过修剪练习关系图为有向无环图（DAGs），并在Assistments数据集的因果子集上训练DKT，验证其预测能力与因果结构的一致性。此外，提出了一种利用DKT学习表示提取练习关系DAGs的替代方法。

Result: 实证表明DKT的预测能力与因果结构高度一致，支持其有效性源于因果依赖关系的建模。

Conclusion: DKT的有效性主要源于其能够近似知识组件（KCs）之间的因果依赖关系，而非简单的双向关系映射。

Abstract: A longstanding goal in computational educational research is to develop
explainable knowledge tracing (KT) models. Deep Knowledge Tracing (DKT), which
leverages a Recurrent Neural Network (RNN) to predict student knowledge and
performance on exercises, has been proposed as a major advancement over
traditional KT methods. Several studies suggest that its performance gains stem
from its ability to model bidirectional relationships between different
knowledge components (KCs) within a course, enabling the inference of a
student's understanding of one KC from their performance on others. In this
paper, we challenge this prevailing explanation and demonstrate that DKT's
strength lies in its implicit ability to model prerequisite relationships as a
causal structure, rather than bidirectional relationships. By pruning exercise
relation graphs into Directed Acyclic Graphs (DAGs) and training DKT on causal
subsets of the Assistments dataset, we show that DKT's predictive capabilities
align strongly with these causal structures. Furthermore, we propose an
alternative method for extracting exercise relation DAGs using DKT's learned
representations and provide empirical evidence supporting our claim. Our
findings suggest that DKT's effectiveness is largely driven by its capacity to
approximate causal dependencies between KCs rather than simple relational
mappings.

</details>


### [116] [LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing](https://arxiv.org/abs/2511.03980)
*Bram Bulté,Ayla Rigouts Terryn*

Main category: cs.AI

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Large Language Models (LLMs) are rapidly being adopted by users across the
globe, who interact with them in a diverse range of languages. At the same
time, there are well-documented imbalances in the training data and
optimisation objectives of this technology, raising doubts as to whether LLMs
can represent the cultural diversity of their broad user base. In this study,
we look at LLMs and cultural values and examine how prompt language and
cultural framing influence model responses and their alignment with human
values in different countries. We probe 10 LLMs with 63 items from the Hofstede
Values Survey Module and World Values Survey, translated into 11 languages, and
formulated as prompts with and without different explicit cultural
perspectives. Our study confirms that both prompt language and cultural
perspective produce variation in LLM outputs, but with an important caveat:
While targeted prompting can, to a certain extent, steer LLM responses in the
direction of the predominant values of the corresponding countries, it does not
overcome the models' systematic bias toward the values associated with a
restricted set of countries in our dataset: the Netherlands, Germany, the US,
and Japan. All tested models, regardless of their origin, exhibit remarkably
similar patterns: They produce fairly neutral responses on most topics, with
selective progressive stances on issues such as social tolerance. Alignment
with cultural values of human respondents is improved more with an explicit
cultural perspective than with a targeted prompt language. Unexpectedly,
combining both approaches is no more effective than cultural framing with an
English prompt. These findings reveal that LLMs occupy an uncomfortable middle
ground: They are responsive enough to changes in prompts to produce variation,
but too firmly anchored to specific cultural defaults to adequately represent
cultural diversity.

</details>


### [117] [ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering](https://arxiv.org/abs/2511.03985)
*Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang*

Main category: cs.AI

TL;DR: ArchPilot是一个多智能体系统，通过代理评估和自适应搜索减少对全训练运行的依赖，提高自动化ML工程的效率和扩展性。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM-based代理在自动化ML工程中依赖重复全训练运行导致的计算开销大、扩展性差和迭代周期慢的问题。

Method: ArchPilot是一个多智能体系统，包含协调搜索过程的编排智能体、生成和改进候选架构的生成智能体，以及执行代理训练和评估的评估智能体。

Result: ArchPilot在MLE-Bench上的实验结果显示其优于现有基线方法。

Conclusion: ArchPilot的有效性通过其在MLE-Bench上的优异表现得到验证，优于现有基线方法如AIDE和ML-Master。

Abstract: Recent LLM-based agents have demonstrated strong capabilities in automated ML
engineering. However, they heavily rely on repeated full training runs to
evaluate candidate solutions, resulting in significant computational overhead,
limited scalability to large search spaces, and slow iteration cycles. To
address these challenges, we introduce ArchPilot, a multi-agent system that
integrates architecture generation, proxy-based evaluation, and adaptive search
into a unified framework. ArchPilot consists of three specialized agents: an
orchestration agent that coordinates the search process using a Monte Carlo
Tree Search (MCTS)-inspired novel algorithm with a restart mechanism and
manages memory of previous candidates; a generation agent that iteratively
generates, improves, and debugs candidate architectures; and an evaluation
agent that executes proxy training runs, generates and optimizes proxy
functions, and aggregates the proxy scores into a fidelity-aware performance
metric. This multi-agent collaboration allows ArchPilot to prioritize
high-potential candidates with minimal reliance on expensive full training
runs, facilitating efficient ML engineering under limited budgets. Experiments
on MLE-Bench demonstrate that ArchPilot outperforms SOTA baselines such as AIDE
and ML-Master, validating the effectiveness of our multi-agent system.

</details>


### [118] [Detecting Silent Failures in Multi-Agentic AI Trajectories](https://arxiv.org/abs/2511.04032)
*Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi*

Main category: cs.AI

TL;DR: 研究提出多智能体AI系统的异常检测任务和数据集整理流程，展示了监督和半监督方法的有效性，准确率高达98%和96%。


<details>
  <summary>Details</summary>
Motivation: 多智能体AI系统（基于大语言模型）具有非确定性，容易出现静默故障（如漂移、循环和输出缺失细节），难以检测。

Method: 引入了一种异常检测任务，并提出一个数据集整理流程，用于捕获用户行为、智能体非确定性和LLM变异性。使用该流程整理并标注了两个基准数据集，分别包含4,275和894条轨迹。

Result: 监督（XGBoost）和半监督（SVDD）方法表现相当，准确率分别高达98%和96%。

Conclusion: 这项研究为多智能体AI系统中的异常检测提供了首个系统性研究，包括数据集、基准和未来研究指导。

Abstract: Multi-Agentic AI systems, powered by large language models (LLMs), are
inherently non-deterministic and prone to silent failures such as drift,
cycles, and missing details in outputs, which are difficult to detect. We
introduce the task of anomaly detection in agentic trajectories to identify
these failures and present a dataset curation pipeline that captures user
behavior, agent non-determinism, and LLM variation. Using this pipeline, we
curate and label two benchmark datasets comprising \textbf{4,275 and 894}
trajectories from Multi-Agentic AI systems. Benchmarking anomaly detection
methods on these datasets, we show that supervised (XGBoost) and
semi-supervised (SVDD) approaches perform comparably, achieving accuracies up
to 98% and 96%, respectively. This work provides the first systematic study of
anomaly detection in Multi-Agentic AI systems, offering datasets, benchmarks,
and insights to guide future research.

</details>


### [119] [Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models](https://arxiv.org/abs/2511.04053)
*Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka*

Main category: cs.AI

TL;DR: 研究发现大型语言模型在数值推理中存在系统性偏差，无关上下文会影响其表示，结果因模型规模而异，为开发更公平的模型控制方法提供了依据。


<details>
  <summary>Details</summary>
Motivation: 尽管行为研究已记录大型语言模型在数值推理中的错误，但其底层表示机制尚不明确，因此研究数值属性如何在模型内部整合及无关数值上下文如何影响表示和输出。

Method: 结合线性探测、偏相关分析和基于提示的脆弱性测试，对多种规模的模型进行了分析。

Result: 大型语言模型编码了真实世界的数值相关性，但倾向于系统性放大这些相关性；无关上下文会导致数值表示的偏移，且下游影响因模型规模而异。

Conclusion: 研究揭示了大型语言模型在数值推理中的系统性偏差，并为进一步开发更公平、表示感知的控制方法奠定了基础。

Abstract: Although behavioral studies have documented numerical reasoning errors in
large language models (LLMs), the underlying representational mechanisms remain
unclear. We hypothesize that numerical attributes occupy shared latent
subspaces and investigate two questions:(1) How do LLMs internally integrate
multiple numerical attributes of a single entity? (2)How does irrelevant
numerical context perturb these representations and their downstream outputs?
To address these questions, we combine linear probing with partial correlation
analysis and prompt-based vulnerability tests across models of varying sizes.
Our results show that LLMs encode real-world numerical correlations but tend to
systematically amplify them. Moreover, irrelevant context induces consistent
shifts in magnitude representations, with downstream effects that vary by model
size. These findings reveal a vulnerability in LLM decision-making and lay the
groundwork for fairer, representation-aware control under multi-attribute
entanglement.

</details>


### [120] [Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents](https://arxiv.org/abs/2511.04076)
*Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang*

Main category: cs.AI

TL;DR: Agentmandering是一个通过LLM代理进行策略性选区重划的框架，显著减少党派偏见，提高公平性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的计算方法主要生成大量合法选区重划方案，但忽视了选择过程中的策略动态，导致党派行为者可能选择技术上合规但政治上有优势的地图。

Method: 利用大型语言模型（LLM）代理，采用受游戏理论启发的“选择并冻结”协议，将策略性互动嵌入到选区重划过程中。

Result: 在2020年美国人口普查数据上的评估显示，Agentmandering显著减少了党派偏见和不公平性，且方差比标准基线低2至3个数量级。

Conclusion: Agentmandering框架通过将选区重划重新构想为两个代表对立政治利益的代理人之间的回合制谈判，显著减少了党派偏见和不公平性，并在摇摆州情境中表现出公平性和稳定性。

Abstract: Redistricting plays a central role in shaping how votes are translated into
political power. While existing computational methods primarily aim to generate
large ensembles of legally valid districting plans, they often neglect the
strategic dynamics involved in the selection process. This oversight creates
opportunities for partisan actors to cherry-pick maps that, while technically
compliant, are politically advantageous. Simply satisfying formal constraints
does not ensure fairness when the selection process itself can be manipulated.
We propose \textbf{Agentmandering}, a framework that reimagines redistricting
as a turn-based negotiation between two agents representing opposing political
interests. Drawing inspiration from game-theoretic ideas, particularly the
\textit{Choose-and-Freeze} protocol, our method embeds strategic interaction
into the redistricting process via large language model (LLM) agents. Agents
alternate between selecting and freezing districts from a small set of
candidate maps, gradually partitioning the state through constrained and
interpretable choices. Evaluation on post-2020 U.S. Census data across all
states shows that Agentmandering significantly reduces partisan bias and
unfairness, while achieving 2 to 3 orders of magnitude lower variance than
standard baselines. These results demonstrate both fairness and stability,
especially in swing-state scenarios. Our code is available at
https://github.com/Lihaogx/AgentMandering.

</details>


### [121] [KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering](https://arxiv.org/abs/2511.04093)
*Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu*

Main category: cs.AI

TL;DR: LLM-KGFR框架结合LLM和KGFR，通过零样本泛化和高效处理大型图谱，解决了知识密集型推理问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在推理方面表现出色，但在知识密集型问题上因上下文和参数知识的限制而表现不佳，现有方法在数据集特定调整和大型图谱上的可扩展性方面存在局限。

Method: 提出了LLM-KGFR协作框架，其中KGFR通过LLM生成的描述编码关系，并根据问题中的角色初始化实体，采用APP方法高效处理大型图谱。

Result: 实验表明，LLM-KGFR在保持可扩展性和泛化能力的同时，实现了强大的性能。

Conclusion: LLM-KGFR框架通过结合大型语言模型和知识图谱检索器，实现了在知识密集型问题上的零样本泛化，同时保持了可扩展性和高效性，为KG增强推理提供了实用解决方案。

Abstract: Large language models (LLMs) excel at reasoning but struggle with
knowledge-intensive questions due to limited context and parametric knowledge.
However, existing methods that rely on finetuned LLMs or GNN retrievers are
limited by dataset-specific tuning and scalability on large or unseen graphs.
We propose the LLM-KGFR collaborative framework, where an LLM works with a
structured retriever, the Knowledge Graph Foundation Retriever (KGFR). KGFR
encodes relations using LLM-generated descriptions and initializes entities
based on their roles in the question, enabling zero-shot generalization to
unseen KGs. To handle large graphs efficiently, it employs Asymmetric
Progressive Propagation (APP)- a stepwise expansion that selectively limits
high-degree nodes while retaining informative paths. Through node-, edge-, and
path-level interfaces, the LLM iteratively requests candidate answers,
supporting facts, and reasoning paths, forming a controllable reasoning loop.
Experiments demonstrate that LLM-KGFR achieves strong performance while
maintaining scalability and generalization, providing a practical solution for
KG-augmented reasoning.

</details>


### [122] [Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms](https://arxiv.org/abs/2511.04133)
*Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel*

Main category: cs.AI

TL;DR: 提出了首个系统框架，通过人类中心基准评估语音AI测试质量，结合心理测量和统计验证，实证显示平台性能差异显著。


<details>
  <summary>Details</summary>
Motivation: 随着语音AI扩展到数十亿日常交互，组织无法客观评估其测试方法的有效性，导致关键测量差距。

Method: 结合心理测量技术（如Elo评分、自举置信区间和排列检验）与严格的统计验证，提供可重复的指标。

Result: 结果显示，性能存在显著差异，表现最佳的平台Evalion在评估质量（F1分数0.92）和模拟质量（联赛评分0.61）上均优于其他平台。

Conclusion: 该框架为研究人员和组织提供了实证验证任何平台测试能力的方法，为大规模部署语音AI提供了必要的测量基础。

Abstract: Voice AI agents are rapidly transitioning to production deployments, yet
systematic methods for ensuring testing reliability remain underdeveloped.
Organizations cannot objectively assess whether their testing approaches
(internal tools or external platforms) actually work, creating a critical
measurement gap as voice AI scales to billions of daily interactions.
  We present the first systematic framework for evaluating voice AI testing
quality through human-centered benchmarking. Our methodology addresses the
fundamental dual challenge of testing platforms: generating realistic test
conversations (simulation quality) and accurately evaluating agent responses
(evaluation quality). The framework combines established psychometric
techniques (pairwise comparisons yielding Elo ratings, bootstrap confidence
intervals, and permutation tests) with rigorous statistical validation to
provide reproducible metrics applicable to any testing approach.
  To validate the framework and demonstrate its utility, we conducted
comprehensive empirical evaluation of three leading commercial platforms
focused on Voice AI Testing using 21,600 human judgments across 45 simulations
and ground truth validation on 60 conversations. Results reveal statistically
significant performance differences with the proposed framework, with the
top-performing platform, Evalion, achieving 0.92 evaluation quality measured as
f1-score versus 0.73 for others, and 0.61 simulation quality using a league
based scoring system (including ties) vs 0.43 for other platforms.
  This framework enables researchers and organizations to empirically validate
the testing capabilities of any platform, providing essential measurement
foundations for confident voice AI deployment at scale. Supporting materials
are made available to facilitate reproducibility and adoption.

</details>


### [123] [When Empowerment Disempowers](https://arxiv.org/abs/2511.04177)
*Claire Yang,Maya Cakmak,Max Kleiman-Weiner*

Main category: cs.AI

TL;DR: 论文通过Disempower-Grid测试套件发现，单人类赋权优化的辅助RL代理在多人类环境中会导致“去赋权”现象，揭示了目标无关目标在多智能体环境中的对齐挑战。


<details>
  <summary>Details</summary>
Motivation: 赋权作为衡量智能体控制环境能力的指标，被提出为AI辅助行为的通用目标无关目标。然而，现有工作假设智能体仅辅助单一人类，忽略了多人类环境（如家庭和医院）中的潜在问题。

Method: 作者引入了开源的多人类网格世界测试套件Disempower-Grid，并通过实验展示了辅助RL代理在优化单个人类赋权时可能削弱其他人的环境影响和奖励。

Result: 研究发现，优化单个人类赋权的辅助RL代理会显著削弱其他人的环境影响力，即“去赋权”现象。联合赋权可以缓解这一问题，但会牺牲用户的奖励。

Conclusion: 论文揭示了AI对齐领域的一个更广泛挑战：在单智能体环境中看似对齐的目标无关目标，在多智能体环境中可能会变得不对齐。

Abstract: Empowerment, a measure of an agent's ability to control its environment, has
been proposed as a universal goal-agnostic objective for motivating assistive
behavior in AI agents. While multi-human settings like homes and hospitals are
promising for AI assistance, prior work on empowerment-based assistance assumes
that the agent assists one human in isolation. We introduce an open source
multi-human gridworld test suite Disempower-Grid. Using Disempower-Grid, we
empirically show that assistive RL agents optimizing for one human's
empowerment can significantly reduce another human's environmental influence
and rewards - a phenomenon we formalize as disempowerment. We characterize when
disempowerment occurs in these environments and show that joint empowerment
mitigates disempowerment at the cost of the user's reward. Our work reveals a
broader challenge for the AI alignment community: goal-agnostic objectives that
seem aligned in single-agent settings can become misaligned in multi-agent
contexts.

</details>


### [124] [Opus: A Quantitative Framework for Workflow Evaluation](https://arxiv.org/abs/2511.04220)
*Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston*

Main category: cs.AI

TL;DR: Opus工作流评估框架通过概率-规范模型量化工作流质量与效率，整合奖励与惩罚，支持自动化评估与优化。


<details>
  <summary>Details</summary>
Motivation: 量化工作流的质量和效率，支持自动化评估、排名和优化。

Method: 结合Opus工作流奖励（概率函数估算预期性能）和Opus工作流规范惩罚（衡量结构信息质量的可测量函数），构建了一个统一的数学模型。

Result: 提出了一个支持自动化系统（如Opus）的工作流评估框架，并可集成到强化学习循环中以指导工作流的发现和改进。

Conclusion: 本文提出了Opus工作流评估框架，通过统一的优化公式在奖励与惩罚之间进行权衡，以识别和排名最优工作流。

Abstract: This paper introduces the Opus Workflow Evaluation Framework, a
probabilistic-normative formulation for quantifying Workflow quality and
efficiency. It integrates notions of correctness, reliability, and cost into a
coherent mathematical model that enables direct comparison, scoring, and
optimization of Workflows. The framework combines the Opus Workflow Reward, a
probabilistic function estimating expected performance through success
likelihood, resource usage, and output gain, with the Opus Workflow Normative
Penalties, a set of measurable functions capturing structural and informational
quality across Cohesion, Coupling, Observability, and Information Hygiene. It
supports automated Workflow assessment, ranking, and optimization within modern
automation systems such as Opus and can be integrated into Reinforcement
Learning loops to guide Workflow discovery and refinement. In this paper, we
introduce the Opus Workflow Reward model that formalizes Workflow success as a
probabilistic expectation over costs and outcomes. We define measurable Opus
Workflow Normative Penalties capturing structural, semantic, and signal-related
properties of Workflows. Finally, we propose a unified optimization formulation
for identifying and ranking optimal Workflows under joint Reward-Penalty
trade-offs.

</details>


### [125] [AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research](https://arxiv.org/abs/2511.04316)
*Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann*

Main category: cs.AI

TL;DR: AdversariaLLM是一个专注于可重复性、正确性和可扩展性的LLM越狱鲁棒性研究工具箱，集成了多种攻击算法和数据集，旨在解决研究碎片化问题。


<details>
  <summary>Details</summary>
Motivation: LLM安全和鲁棒性研究的快速扩张导致了实现、数据集和评估方法的碎片化和错误，影响了研究的可重复性和可比性。

Method: 设计了AdversariaLLM工具箱，集成了12种对抗攻击算法、7个基准数据集，并通过Hugging Face提供多种开源LLM的访问。

Result: AdversariaLLM框架实现了计算资源跟踪、确定性结果和分布评估技术等高级功能，提升了研究的可比性和可重复性。

Conclusion: AdversariaLLM提供了一个可靠的工具箱，为LLM安全领域的透明、可比较和可重复研究奠定了基础。

Abstract: The rapid expansion of research on Large Language Model (LLM) safety and
robustness has produced a fragmented and oftentimes buggy ecosystem of
implementations, datasets, and evaluation methods. This fragmentation makes
reproducibility and comparability across studies challenging, hindering
meaningful progress. To address these issues, we introduce AdversariaLLM, a
toolbox for conducting LLM jailbreak robustness research. Its design centers on
reproducibility, correctness, and extensibility. The framework implements
twelve adversarial attack algorithms, integrates seven benchmark datasets
spanning harmfulness, over-refusal, and utility evaluation, and provides access
to a wide range of open-weight LLMs via Hugging Face. The implementation
includes advanced features for comparability and reproducibility such as
compute-resource tracking, deterministic results, and distributional evaluation
techniques. \name also integrates judging through the companion package
JudgeZoo, which can also be used independently. Together, these components aim
to establish a robust foundation for transparent, comparable, and reproducible
research in LLM safety.

</details>


### [126] [Shared Spatial Memory Through Predictive Coding](https://arxiv.org/abs/2511.04235)
*Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang*

Main category: cs.AI

TL;DR: 该论文提出了一种多智能体预测编码框架，通过信息瓶颈优化通信，在带宽限制下展现出优越的协调能力，并模拟了类似海马体社交位置细胞的神经表征。


<details>
  <summary>Details</summary>
Motivation: 在多智能体系统中，部分可观测性和有限带宽常常导致协调中的灾难性失败，因此需要一种方法来共享和重建一致的空间记忆。

Method: 提出了一个多智能体预测编码框架，通过信息瓶颈目标促使智能体学习谁、什么以及何时进行通信，并基于网格细胞样度量的内部空间编码，通过自监督运动预测自发形成。

Result: 在Memory-Maze基准测试中，该方法在带宽限制下表现出卓越的韧性：成功率从73.5%逐渐降至64.4%（带宽从128位/步缩减至4位/步），而全广播基线则从67.6%崩溃至28.6%。

Conclusion: 该研究建立了一个理论上有原则且生物学上合理的框架，解释了复杂的社交表征如何从统一的预测驱动中涌现，从而实现社交集体智能。

Abstract: Sharing and reconstructing a consistent spatial memory is a critical
challenge in multi-agent systems, where partial observability and limited
bandwidth often lead to catastrophic failures in coordination. We introduce a
multi-agent predictive coding framework that formulate coordination as the
minimization of mutual uncertainty among agents. Instantiated as an information
bottleneck objective, it prompts agents to learn not only who and what to
communicate but also when. At the foundation of this framework lies a
grid-cell-like metric as internal spatial coding for self-localization,
emerging spontaneously from self-supervised motion prediction. Building upon
this internal spatial code, agents gradually develop a bandwidth-efficient
communication mechanism and specialized neural populations that encode
partners' locations: an artificial analogue of hippocampal social place cells
(SPCs). These social representations are further enacted by a hierarchical
reinforcement learning policy that actively explores to reduce joint
uncertainty. On the Memory-Maze benchmark, our approach shows exceptional
resilience to bandwidth constraints: success degrades gracefully from 73.5% to
64.4% as bandwidth shrinks from 128 to 4 bits/step, whereas a full-broadcast
baseline collapses from 67.6% to 28.6%. Our findings establish a theoretically
principled and biologically plausible basis for how complex social
representations emerge from a unified predictive drive, leading to social
collective intelligence.

</details>


### [127] [RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization](https://arxiv.org/abs/2511.04285)
*Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu*

Main category: cs.AI

TL;DR: RLoop框架通过迭代策略初始化和RFT微调，有效解决了RLVR中的过拟合问题，提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 针对强化学习在可验证奖励（RLVR）中出现的过拟合问题，特别是策略过度专业化和灾难性遗忘，提出了RLoop框架。

Method: RLoop框架结合了强化学习的探索和拒绝采样微调（RFT）的利用，通过迭代策略初始化形成良性循环。

Result: 实验表明，RLoop显著提升了泛化性能，平均准确率提高了9%，pass@32指标提升了15%以上。

Conclusion: RLoop通过迭代策略初始化的自改进框架有效解决了RLVR中的过拟合问题，显著提升了模型的泛化能力。

Abstract: While Reinforcement Learning for Verifiable Rewards (RLVR) is powerful for
training large reasoning models, its training dynamics harbor a critical
challenge: RL overfitting, where models gain training rewards but lose
generalization. Our analysis reveals this is driven by policy
over-specialization and catastrophic forgetting of diverse solutions generated
during training. Standard optimization discards this valuable inter-step policy
diversity. To address this, we introduce RLoop, a self-improving framework
built on iterative policy initialization. RLoop transforms the standard
training process into a virtuous cycle: it first uses RL to explore the
solution space from a given policy, then filters the successful trajectories to
create an expert dataset. This dataset is used via Rejection-sampling
Fine-Tuning (RFT) to refine the initial policy, creating a superior starting
point for the next iteration. This loop of exploration and exploitation via
iterative re-initialization effectively converts transient policy variations
into robust performance gains. Our experiments show RLoop mitigates forgetting
and substantially improves generalization, boosting average accuracy by 9% and
pass@32 by over 15% compared to vanilla RL.

</details>


### [128] [GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents](https://arxiv.org/abs/2511.04307)
*Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: GUI-360$^\circ$是一个大规模数据集，旨在推动计算机使用代理研究，通过自动化流程构建，并揭示了当前模型的不足。


<details>
  <summary>Details</summary>
Motivation: 解决计算机使用代理研究中存在的三个主要问题：真实任务稀缺、多模态轨迹的自动化收集和注释流程缺乏，以及统一的基准评估缺失。

Method: 通过LLM增强的自动化流程构建数据集，包括查询来源、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤。

Result: 发布了包含120万执行动作步骤的大规模数据集，支持GUI定位、屏幕解析和动作预测三个任务，并揭示了当前模型的局限性。

Conclusion: GUI-360$^\circ$数据集和基准套件的发布旨在促进计算机使用代理（CUAs）的研究，尽管当前最先进的模型在性能上仍有待提升。

Abstract: We introduce GUI-360$^\circ$, a large-scale, comprehensive dataset and
benchmark suite designed to advance computer-using agents (CUAs). CUAs present
unique challenges and is constrained by three persistent gaps: a scarcity of
real-world CUA tasks, the lack of automated collection-and-annotation pipelines
for multi-modal trajectories, and the absence of a unified benchmark that
jointly evaluates GUI grounding, screen parsing, and action prediction.
  GUI-360$^\circ$ addresses these gaps with an LLM-augmented, largely automated
pipeline for query sourcing, environment-template construction, task
instantiation, batched execution, and LLM-driven quality filtering. The
released corpus contains over 1.2M executed action steps across thousands of
trajectories in popular Windows office applications, and includes
full-resolution screenshots, accessibility metadata when available,
instantiated goals, intermediate reasoning traces, and both successful and
failed action trajectories. The dataset supports three canonical tasks, GUI
grounding, screen parsing, and action prediction, and a hybrid GUI+API action
space that reflects modern agent designs. Benchmarking state-of-the-art
vision--language models on GUI-360$^\circ$ reveals substantial out-of-the-box
shortcomings in grounding and action prediction; supervised fine-tuning and
reinforcement learning yield significant gains but do not close the gap to
human-level reliability. We release GUI-360$^\circ$ and accompanying code to
facilitate reproducible research and accelerate progress on robust desktop
CUAs.
  The full dataset has been made public on
https://huggingface.co/datasets/vyokky/GUI-360.

</details>


### [129] [Probing the Probes: Methods and Metrics for Concept Alignment](https://arxiv.org/abs/2511.04312)
*Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke*

Main category: cs.AI

TL;DR: 该论文指出在可解释AI中，CAVs通过线性分类器探测人类可理解概念时，仅依赖探测准确性作为概念对齐的衡量是不可靠的。作者提出新的概念定位方法及三类评估指标，强调需针对模型架构和目标概念定制探测方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法中，CAVs的探测准确性被普遍认为是概念对齐的可靠指标，但作者发现其易受虚假相关性影响，无法准确反映概念对齐程度。

Method: 引入基于空间线性归因的概念定位方法，并对比现有特征可视化技术。提出三类评估指标：硬准确性、分割分数和增强鲁棒性。

Result: 实验表明，具有平移不变性和空间对齐的探测能显著提升概念对齐效果。

Conclusion: 论文强调需采用基于对齐的评估指标而非探测准确性，并根据模型架构和目标概念特性定制探测方法。

Abstract: In explainable AI, Concept Activation Vectors (CAVs) are typically obtained
by training linear classifier probes to detect human-understandable concepts as
directions in the activation space of deep neural networks. It is widely
assumed that a high probe accuracy indicates a CAV faithfully representing its
target concept. However, we show that the probe's classification accuracy alone
is an unreliable measure of concept alignment, i.e., the degree to which a CAV
captures the intended concept. In fact, we argue that probes are more likely to
capture spurious correlations than they are to represent only the intended
concept. As part of our analysis, we demonstrate that deliberately misaligned
probes constructed to exploit spurious correlations, achieve an accuracy close
to that of standard probes. To address this severe problem, we introduce a
novel concept localization method based on spatial linear attribution, and
provide a comprehensive comparison of it to existing feature visualization
techniques for detecting and mitigating concept misalignment. We further
propose three classes of metrics for quantitatively assessing concept
alignment: hard accuracy, segmentation scores, and augmentation robustness. Our
analysis shows that probes with translation invariance and spatial alignment
consistently increase concept alignment. These findings highlight the need for
alignment-based evaluation metrics rather than probe accuracy, and the
importance of tailoring probes to both the model architecture and the nature of
the target concept.

</details>


### [130] [RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation](https://arxiv.org/abs/2511.04328)
*Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang*

Main category: cs.AI

TL;DR: 论文提出模拟临床咨询框架和RxSafeBench基准，评估LLMs药物安全性，发现其整合药物风险知识不足，为改进AI临床决策支持提供方向。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在药物安全性方面的研究因缺乏真实世界数据集和临床咨询环境评估而受限，亟需解决这些空白。

Method: 研究通过模拟临床咨询生成带有药物风险的诊断对话，并构建了RxRisk DB数据库，采用两阶段过滤策略确保临床真实性和专业性，最终形成RxSafeBench基准。

Result: 评估显示当前LLMs在整合禁忌症和药物相互作用知识方面表现不佳，尤其在风险隐晦时更明显。

Conclusion: 论文提出了一个评估LLMs药物安全性的框架，并创建了RxSafeBench基准，为AI驱动的临床决策支持提供了更安全可靠的评估工具。

Abstract: Numerous medical systems powered by Large Language Models (LLMs) have
achieved remarkable progress in diverse healthcare tasks. However, research on
their medication safety remains limited due to the lack of real world datasets,
constrained by privacy and accessibility issues. Moreover, evaluation of LLMs
in realistic clinical consultation settings, particularly regarding medication
safety, is still underexplored. To address these gaps, we propose a framework
that simulates and evaluates clinical consultations to systematically assess
the medication safety capabilities of LLMs. Within this framework, we generate
inquiry diagnosis dialogues with embedded medication risks and construct a
dedicated medication safety database, RxRisk DB, containing 6,725
contraindications, 28,781 drug interactions, and 14,906 indication-drug pairs.
A two-stage filtering strategy ensures clinical realism and professional
quality, resulting in the benchmark RxSafeBench with 2,443 high-quality
consultation scenarios. We evaluate leading open-source and proprietary LLMs
using structured multiple choice questions that test their ability to recommend
safe medications under simulated patient contexts. Results show that current
LLMs struggle to integrate contraindication and interaction knowledge,
especially when risks are implied rather than explicit. Our findings highlight
key challenges in ensuring medication safety in LLM-based systems and provide
insights into improving reliability through better prompting and task-specific
tuning. RxSafeBench offers the first comprehensive benchmark for evaluating
medication safety in LLMs, advancing safer and more trustworthy AI-driven
clinical decision support.

</details>


### [131] [Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning](https://arxiv.org/abs/2511.04341)
*Nick Oh,Fernand Gobet*

Main category: cs.AI

TL;DR: 论文提出MGV框架，通过引入监控机制改进Generate-Verify范式，解决前缀主导陷阱问题，但未经验证。


<details>
  <summary>Details</summary>
Motivation: 现有测试时推理架构（如Generate-Verify范式）缺乏监控过程，导致模型容易陷入前缀主导陷阱，造成约20%的准确率损失。

Method: 通过将Flavell、Nelson和Narens的元认知理论形式化为计算规范，提出了MGV框架，扩展了Generate-Verify范式，增加了显式监控机制。

Result: 尽管未进行实证验证，但该工作首次系统地将元认知理论转化为计算规范，为理解推理系统失败提供了理论框架。

Conclusion: 该论文提出了Monitor-Generate-Verify（MGV）框架，填补了现有Generate-Verify范式中监控过程的缺失，为未来的推理设计提供了理论基础和架构干预建议。

Abstract: Test-time reasoning architectures such as those following the Generate-Verify
paradigm -- where a model iteratively refines or verifies its own generated
outputs -- prioritise generation and verification but exclude the monitoring
processes that determine when and how reasoning should begin. This omission may
contribute to the prefix dominance trap, in which models commit early to
suboptimal reasoning paths and seldom recover, yielding roughly 20% accuracy
loss. We address this architectural gap by formalising Flavell's and Nelson and
Narens' metacognitive theories into computational specifications, proposing the
Monitor-Generate-Verify (MGV) framework. MGV extends the Generate-Verify
paradigm by adding explicit monitoring that captures metacognitive experiences
(from difficulty assessments to confidence judgements) before generation begins
and refines future monitoring through verification feedback. Though we present
no empirical validation, this work provides the first systematic computational
translation of foundational metacognitive theories, offering a principled
vocabulary for understanding reasoning system failures and suggesting specific
architectural interventions for future test-time reasoning designs.

</details>


### [132] [Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach](https://arxiv.org/abs/2511.04393)
*Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang*

Main category: cs.AI

TL;DR: Iterative RMFT 是一种后训练方法，通过迭代微调低遗憾决策轨迹提升 LLMs 的决策能力，实验验证了其广泛适用性和有效性。


<details>
  <summary>Details</summary>
Motivation: LLMs 最初并非为决策任务设计，现有研究表明其在基础在线决策问题中表现不佳，无法实现低遗憾或有效的探索-利用权衡。

Method: 通过迭代式遗憾最小化微调（Iterative RMFT）方法，模型在每次迭代中生成多个决策轨迹，选择遗憾最低的轨迹进行自我微调。

Result: 实验结果表明，Iterative RMFT 显著提升了多种模型（从 Transformer 到 GPT-4o mini）的决策能力，并展示了在多样化任务中的泛化能力。

Conclusion: Iterative RMFT 提供了一种原则性和通用的后训练框架，显著提升了大型语言模型（LLMs）在决策任务中的表现。

Abstract: Large language models (LLMs) are increasingly deployed as "agents" for
decision-making (DM) in interactive and dynamic environments. Yet, since they
were not originally designed for DM, recent studies show that LLMs can struggle
even in basic online DM problems, failing to achieve low regret or an effective
exploration-exploitation tradeoff. To address this, we introduce Iterative
Regret-Minimization Fine-Tuning (Iterative RMFT), a post-training procedure
that repeatedly distills low-regret decision trajectories back into the base
model. At each iteration, the model rolls out multiple decision trajectories,
selects the k-lowest regret ones, and fine-tunes itself on them. Unlike prior
methods that (a) distill action sequences from known DM algorithms or (b) rely
on manually crafted chain-of-thought templates, our approach leverages the
regret metric to elicit the model's own DM ability and reasoning rationales.
This reliance on model-generated reasoning avoids rigid output engineering and
provides more flexible, natural-language training signals. Empirical results
show that Iterative RMFT improves LLMs' DM performance across diverse models -
from Transformers with numerical input/output, to open-weight LLMs, and
advanced closed-weight models like GPT-4o mini. Its flexibility in output and
reasoning formats enables generalization across tasks with varying horizons,
action spaces, reward processes, and natural-language contexts. Finally, we
provide theoretical insight showing that a single-layer Transformer under this
paradigm can act as a no-regret learner in a simplified setting. Overall,
Iterative RMFT offers a principled and general post-training framework for
enhancing LLMs' decision-making capabilities.

</details>


### [133] [The Peril of Preference: Why GRPO fails on Ordinal Rewards](https://arxiv.org/abs/2511.04439)
*Anisha Garg,Ganesh Venkatesh*

Main category: cs.AI

TL;DR: CoRPO改进了GRPO，通过自适应基线解决失败轨迹被错误强化的问题，并在代码验证任务中表现更优。


<details>
  <summary>Details</summary>
Motivation: GRPO的简单性使其在利用非二元反馈（如序数奖励）时表现不佳，导致失败轨迹被错误强化。

Method: 提出了Correctness Relative Policy Optimization (CoRPO)，使用自适应基线强制最低质量阈值，并在阈值达成后切换到相对偏好模式。

Result: 在代码验证任务中，CoRPO展现出更稳定的收敛性和更好的跨领域泛化能力。

Conclusion: CoRPO通过引入自适应基线解决了GRPO的缺陷，确保了失败解决方案不会被错误强化，并在模型达到基本质量后自动切换到相对偏好模式，从而推动模型寻找最优解。

Abstract: Group-relative Policy Optimization's (GRPO) simplicity makes it highly
desirable for adapting LLMs to become experts at specific tasks. But this
simplicity also makes it ill-specified as we seek to enhance RL training with
richer, non-binary feedback. When using ordinal rewards to give partial credit,
GRPO's simplicity starts to hurt, as its group-average baseline often assigns a
positive advantage to failed trajectories and reinforces incorrect behavior.
  We introduce Correctness Relative Policy Optimization (CoRPO), a new
formulation that solves this flaw. CoRPO uses an adaptive baseline that
enforces a minimum quality threshold, ensuring failed solutions are never
positively reinforced. Once the policy consistently meets this threshold, the
baseline automatically transitions to a relative preference mode, pushing the
model to find optimal solutions rather than just "acceptable" ones. We
empirically validate CoRPO on a code verification task, where it demonstrates
more stable convergence and better out-of-domain generalization.
  This work represents a critical step in our broader research program to
enable LLMs to learn genuinely new capabilities through reinforcement learning.
We achieve this by enabling LLMs to learn from rich, multi-dimensional feedback
- progressing from binary to ordinal rewards in this work, and onward to
denser, per-step supervision.

</details>


### [134] [Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context](https://arxiv.org/abs/2511.04464)
*Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza*

Main category: cs.AI

TL;DR: PAVe是一种混合代理助手，通过结合经典路径查找算法与LLM的上下文推理能力，优化城市移动路线，准确率达88%以上。


<details>
  <summary>Details</summary>
Motivation: 传统车辆路由系统在优化单一指标（如时间或距离）时效率高，但在处理多指标时需更多优化流程，且无法解释和整合人类驾驶员的复杂、语义化和动态上下文（如多步骤任务、情境约束或紧急需求）。

Method: 采用大型语言模型（LLM）代理，在多目标（时间、CO2）Dijkstra算法生成的候选路线上进行操作，利用预处理的地理空间缓存（城市兴趣点POIs）评估用户提供的任务、偏好和规避规则。

Result: 在现实城市场景的基准测试中，PAVe成功将复杂用户意图转化为适当的路线修改，初始路线选择的准确率超过88%（使用本地模型）。

Conclusion: 结合经典路由算法与基于LLM的语义推理层是一种稳健且有效的方法，可为城市移动优化创建个性化、自适应且可扩展的解决方案。

Abstract: Traditional vehicle routing systems efficiently optimize singular metrics
like time or distance, and when considering multiple metrics, they need more
processes to optimize . However, they lack the capability to interpret and
integrate the complex, semantic, and dynamic contexts of human drivers, such as
multi-step tasks, situational constraints, or urgent needs. This paper
introduces and evaluates PAVe (Personalized Agentic Vehicular Routing), a
hybrid agentic assistant designed to augment classical pathfinding algorithms
with contextual reasoning. Our approach employs a Large Language Model (LLM)
agent that operates on a candidate set of routes generated by a multi-objective
(time, CO2) Dijkstra algorithm. The agent evaluates these options against
user-provided tasks, preferences, and avoidance rules by leveraging a
pre-processed geospatial cache of urban Points of Interest (POIs). In a
benchmark of realistic urban scenarios, PAVe successfully used complex user
intent into appropriate route modifications, achieving over 88% accuracy in its
initial route selections with a local model. We conclude that combining
classical routing algorithms with an LLM-based semantic reasoning layer is a
robust and effective approach for creating personalized, adaptive, and scalable
solutions for urban mobility optimization.

</details>


### [135] [Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis](https://arxiv.org/abs/2511.04481)
*Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus*

Main category: cs.AI

TL;DR: 本文探讨了网页代理的能源和二氧化碳成本，发现不同设计哲学影响能耗，呼吁在评估中加入专门的能耗指标。


<details>
  <summary>Details</summary>
Motivation: 尽管网页代理研究蓬勃发展，但其引发的可持续性问题仍未得到充分探索，本文旨在揭示这一问题的紧迫性。

Method: 通过理论估计和实证基准测试，研究了网页代理的能源和二氧化碳成本。

Result: 研究发现，不同的网页代理设计哲学会显著影响能源消耗，且更高的能耗并不一定带来更好的结果。同时，模型参数和过程的不透明性限制了能源消耗的准确估计。

Conclusion: 本文强调了在评估网页代理时需要考虑能源消耗的重要性，并提出了专门的能耗指标作为基准测试的一部分。

Abstract: Web agents, like OpenAI's Operator and Google's Project Mariner, are powerful
agentic systems pushing the boundaries of Large Language Models (LLM). They can
autonomously interact with the internet at the user's behest, such as
navigating websites, filling search masks, and comparing price lists. Though
web agent research is thriving, induced sustainability issues remain largely
unexplored. To highlight the urgency of this issue, we provide an initial
exploration of the energy and $CO_2$ cost associated with web agents from both
a theoretical -via estimation- and an empirical perspective -by benchmarking.
Our results show how different philosophies in web agent creation can severely
impact the associated expended energy, and that more energy consumed does not
necessarily equate to better results. We highlight a lack of transparency
regarding disclosing model parameters and processes used for some web agents as
a limiting factor when estimating energy consumption. Our work contributes
towards a change in thinking of how we evaluate web agents, advocating for
dedicated metrics measuring energy consumption in benchmarks.

</details>


### [136] [Large language models replicate and predict human cooperation across experiments in game theory](https://arxiv.org/abs/2511.04500)
*Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert*

Main category: cs.AI

TL;DR: 研究发现经过校准的LLMs能复制人类行为模式，Llama表现最佳，Qwen符合纳什均衡，简化了模拟过程并扩展了实验空间。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLMs）在决策过程中与人类行为的相似度，以避免在实际应用中的有害结果，并确保LLMs在社会模拟中的有效性。

Method: 通过开发游戏理论实验的数字孪生和引入系统提示与探测框架进行机器行为评估。

Result: Llama模型能够高保真地复制人类合作模式，捕捉人类对理性选择理论的偏离，而Qwen模型则与纳什均衡预测紧密对齐。研究还表明，无需基于角色的提示即可实现群体行为复制。

Conclusion: 研究发现，经过适当校准的大型语言模型（LLMs）能够复制人类行为模式，并在社会科学研究中提供一种补充传统研究的新方法，能够生成关于人类社交决策的新实证预测。

Abstract: Large language models (LLMs) are increasingly used both to make decisions in
domains such as health, education and law, and to simulate human behavior. Yet
how closely LLMs mirror actual human decision-making remains poorly understood.
This gap is critical: misalignment could produce harmful outcomes in practical
applications, while failure to replicate human behavior renders LLMs
ineffective for social simulations. Here, we address this gap by developing a
digital twin of game-theoretic experiments and introducing a systematic
prompting and probing framework for machine-behavioral evaluation. Testing
three open-source models (Llama, Mistral and Qwen), we find that Llama
reproduces human cooperation patterns with high fidelity, capturing human
deviations from rational choice theory, while Qwen aligns closely with Nash
equilibrium predictions. Notably, we achieved population-level behavioral
replication without persona-based prompting, simplifying the simulation
process. Extending beyond the original human-tested games, we generate and
preregister testable hypotheses for novel game configurations outside the
original parameter grid. Our findings demonstrate that appropriately calibrated
LLMs can replicate aggregate human behavioral patterns and enable systematic
exploration of unexplored experimental spaces, offering a complementary
approach to traditional research in the social and behavioral sciences that
generates new empirical predictions about human social decision-making.

</details>


### [137] [Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach](https://arxiv.org/abs/2511.04556)
*Zihang Ding,Kun Zhang*

Main category: cs.AI

TL;DR: 研究提出DSS框架优化传感器布置，实现高精度流量重建，为资源受限下的洪水监测提供解决方案。


<details>
  <summary>Details</summary>
Motivation: 城市地表水泛滥日益频繁，但高时空分辨率的洪水预测和监测因时间、预算和技术限制难以实现。

Method: 利用SWMM模型生成峰值流量训练数据集，结合DSS（通过奇异值分解降维和QR分解分配传感器）优化监控节点布置。

Result: 在77个节点中布置3个传感器即可达到满意的重建性能（NSE值0.92-0.95），且模型对测量不确定性和传感器故障表现出良好的鲁棒性。

Conclusion: 该研究提出的数据驱动稀疏感知（DSS）框架结合EPA-SWMM，优化了传感器布置并重建了峰值流量，展现了高精度流量重建的潜力，为资源受限下的洪水预警和实时控制提供了可能。

Abstract: Urban surface water flooding, triggered by intense rainfall overwhelming
drainage systems, is increasingly frequent and widespread. While flood
prediction and monitoring in high spatial-temporal resolution are desired,
practical constraints in time, budget, and technology hinder its full
implementation. How to monitor urban drainage networks and predict flow
conditions under constrained resource is a major challenge. This study presents
a data-driven sparse sensing (DSS) framework, integrated with EPA-SWMM, to
optimize sensor placement and reconstruct peak flowrates in a stormwater
system, using the Woodland Avenue catchment in Duluth, Minnesota, as a case
study. We utilized a SWMM model to generate a training dataset of peak flowrate
profiles across the stormwater network. Furthermore, we applied DSS -
leveraging singular value decomposition for dimensionality reduction and QR
factorization for sensor allocation - to identify the optimal monitoring nodes
based on the simulated training dataset. We then validated the
representativeness of these identified monitoring nodes by comparing the
DSS-reconstructed peak flowrate profiles with those obtained from SWMM. Three
optimally placed sensors among 77 nodes achieved satisfactory reconstruction
performance with Nash-Sutcliffe Efficiency (NSE) values of 0.92-0.95 (25th to
75th percentiles). In addition, the model showed good robustness to uncertainty
in measurements. Its robustness to sensor failures is location-dependent and
improves with the number of sensors deployed. The framework balances
computational efficiency and physical interpretability, enabling high-accuracy
flow reconstruction with minimal sensors. This DSS framework can be further
integrated with predictive models to realize flood early warning and real-time
control under limited sensing and monitoring resource.

</details>


### [138] [Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper](https://arxiv.org/abs/2511.04583)
*Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa*

Main category: cs.AI

TL;DR: 论文开发了Jr. AI Scientist系统，模拟新手研究流程，生成高质量论文，但发现其存在局限性和风险，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是了解AI科学家系统的当前能力和风险，以确保可信赖和可持续的AI驱动科学进步，同时维护学术生态系统的完整性。

Method: 论文采用的方法是开发Jr. AI Scientist系统，模拟新手学生研究者的核心研究流程，包括分析基线论文的局限性、提出改进假设、通过实验验证假设并撰写论文。评估方法包括自动评估（AI Reviewer）、作者主导评估和向Agents4Science投稿。

Result: 论文的结果显示，Jr. AI Scientist生成的论文在评审分数上高于现有全自动系统，但也发现了重要局限性和潜在风险。

Conclusion: 论文的结论是，尽管Jr. AI Scientist在生成高质量论文方面表现优于现有全自动系统，但仍存在重要局限性，直接应用当前AI科学家系统可能带来潜在风险，并提出了未来研究的关键挑战。

Abstract: Understanding the current capabilities and risks of AI Scientist systems is
essential for ensuring trustworthy and sustainable AI-driven scientific
progress while preserving the integrity of the academic ecosystem. To this end,
we develop Jr. AI Scientist, a state-of-the-art autonomous AI scientist system
that mimics the core research workflow of a novice student researcher: Given
the baseline paper from the human mentor, it analyzes its limitations,
formulates novel hypotheses for improvement, validates them through rigorous
experimentation, and writes a paper with the results. Unlike previous
approaches that assume full automation or operate on small-scale code, Jr. AI
Scientist follows a well-defined research workflow and leverages modern coding
agents to handle complex, multi-file implementations, leading to scientifically
valuable contributions. For evaluation, we conducted automated assessments
using AI Reviewers, author-led evaluations, and submissions to Agents4Science,
a venue dedicated to AI-driven scientific contributions. The findings
demonstrate that Jr. AI Scientist generates papers receiving higher review
scores than existing fully automated systems. Nevertheless, we identify
important limitations from both the author evaluation and the Agents4Science
reviews, indicating the potential risks of directly applying current AI
Scientist systems and key challenges for future research. Finally, we
comprehensively report various risks identified during development. We hope
these insights will deepen understanding of current progress and risks in AI
Scientist development.

</details>


### [139] [Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis](https://arxiv.org/abs/2511.04584)
*Daniel Gomm,Cornelius Wolff,Madelon Hulsebos*

Main category: cs.AI

TL;DR: 论文提出将自然语言查询中的歧义视为协作特征，开发框架区分协作与非协作查询，分析发现现有评估方法不足，倡导协作解析新方向。


<details>
  <summary>Details</summary>
Motivation: 现有自然语言接口在处理表格数据时通常将歧义视为缺陷，而作者认为歧义是协作交互的特征，希望通过框架重新定义查询解析的责任分配。

Method: 作者开发了一个原则性框架，用于区分协作查询与非协作查询，并将该框架应用于15个流行数据集的查询分析。

Result: 分析结果显示，现有数据集中查询类型的混合既不适用于评估系统执行准确性，也不适用于评估解释能力。框架的提出为设计和评估提供了新视角。

Conclusion: 该论文提出了一个框架，将自然语言查询中的歧义视为协作交互的特征，并区分了可解析的协作查询与无法解析的非协作查询。通过分析15个流行数据集中的查询类型，作者发现现有评估方法既不适合评估系统执行准确性，也不适合评估解释能力。论文提倡从修复歧义转向协作解析查询，为表格数据的自然语言接口设计和评估提供了新方向。

Abstract: Natural language interfaces to tabular data must handle ambiguities inherent
to queries. Instead of treating ambiguity as a deficiency, we reframe it as a
feature of cooperative interaction, where the responsibility of query
specification is shared among the user and the system. We develop a principled
framework distinguishing cooperative queries, i.e., queries that yield a
resolvable interpretation, from uncooperative queries that cannot be resolved.
Applying the framework to evaluations for tabular question answering and
analysis, we analyze the queries in 15 popular datasets, and observe an
uncontrolled mixing of query types neither adequate for evaluating a system's
execution accuracy nor for evaluating interpretation capabilities. Our
framework and analysis of queries shifts the perspective from fixing ambiguity
to embracing cooperation in resolving queries. This reflection enables more
informed design and evaluation for natural language interfaces for tabular
data, for which we outline implications and directions for future research.

</details>


### [140] [Question the Questions: Auditing Representation in Online Deliberative Processes](https://arxiv.org/abs/2511.04588)
*Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu*

Main category: cs.AI

TL;DR: 该研究提出了一种基于社会选择概念的审计框架，用于评估问题选择的代表性，并比较了不同方法的效果，最终整合到在线审议平台中以改善未来审议。


<details>
  <summary>Details</summary>
Motivation: 解决在有限时间内如何从众多参与者提出的问题中选择最具代表性的小部分问题。

Method: 引入了一个基于社会选择概念'合理代表（JR）'的审计框架，并提出了在一般效用设置下审计JR的首个算法，最有效算法的运行时间为O(mn log n)。

Result: 比较了三种问题选择方法的代表性：（a）主持人选择的问题，（b）通过整数线性编程选择的问题，（c）大型语言模型（LLM）生成的摘要问题。结果突显了LLM在支持审议过程中的潜力和当前局限性。

Conclusion: 通过将我们的方法整合到一个已在50多个国家进行数百次审议的在线平台中，使实践者能够轻松审计并改善未来审议的代表性。

Abstract: A central feature of many deliberative processes, such as citizens'
assemblies and deliberative polls, is the opportunity for participants to
engage directly with experts. While participants are typically invited to
propose questions for expert panels, only a limited number can be selected due
to time constraints. This raises the challenge of how to choose a small set of
questions that best represent the interests of all participants. We introduce
an auditing framework for measuring the level of representation provided by a
slate of questions, based on the social choice concept known as justified
representation (JR). We present the first algorithms for auditing JR in the
general utility setting, with our most efficient algorithm achieving a runtime
of $O(mn\log n)$, where $n$ is the number of participants and $m$ is the number
of proposed questions. We apply our auditing methods to historical
deliberations, comparing the representativeness of (a) the actual questions
posed to the expert panel (chosen by a moderator), (b) participants' questions
chosen via integer linear programming, (c) summary questions generated by large
language models (LLMs). Our results highlight both the promise and current
limitations of LLMs in supporting deliberative processes. By integrating our
methods into an online deliberation platform that has been used for over
hundreds of deliberations across more than 50 countries, we make it easy for
practitioners to audit and improve representation in future deliberations.

</details>


### [141] [DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration](https://arxiv.org/abs/2511.04646)
*Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong*

Main category: cs.AI

TL;DR: DR. WELL是一个去中心化神经符号框架，通过符号化规划和两阶段协商协议提升多智能体协作效率。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体在轨迹级别协调时因微小偏差导致的冲突问题，通过符号化规划提升抽象层次以实现同步和集体进展。

Method: 采用去中心化的神经符号框架（DR. WELL），通过两阶段协商协议（角色提案与联合分配）和独立符号化计划生成与执行。

Result: 实验表明，动态世界模型通过协商和自我优化提升了任务完成率和效率，尽管牺牲了一定的时间开销。

Conclusion: DR. WELL框架通过符号化规划和两阶段协商协议，实现了多智能体在部分信息和有限通信条件下的高效协作，提升了任务完成率和效率。

Abstract: Cooperative multi-agent planning requires agents to make joint decisions with
partial information and limited communication. Coordination at the trajectory
level often fails, as small deviations in timing or movement cascade into
conflicts. Symbolic planning mitigates this challenge by raising the level of
abstraction and providing a minimal vocabulary of actions that enable
synchronization and collective progress. We present DR. WELL, a decentralized
neurosymbolic framework for cooperative multi-agent planning. Cooperation
unfolds through a two-phase negotiation protocol: agents first propose
candidate roles with reasoning and then commit to a joint allocation under
consensus and environment constraints. After commitment, each agent
independently generates and executes a symbolic plan for its role without
revealing detailed trajectories. Plans are grounded in execution outcomes via a
shared world model that encodes the current state and is updated as agents act.
By reasoning over symbolic plans rather than raw trajectories, DR. WELL avoids
brittle step-level alignment and enables higher-level operations that are
reusable, synchronizable, and interpretable. Experiments on cooperative
block-push tasks show that agents adapt across episodes, with the dynamic world
model capturing reusable patterns and improving task completion rates and
efficiency. Experiments on cooperative block-push tasks show that our dynamic
world model improves task completion and efficiency through negotiation and
self-refinement, trading a time overhead for evolving, more efficient
collaboration strategies.

</details>


### [142] [VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks](https://arxiv.org/abs/2511.04662)
*Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala*

Main category: cs.AI

TL;DR: VeriCoT是一种神经符号方法，通过形式化验证CoT推理步骤提升LLMs的可靠性，并在多个任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在CoT推理中逻辑不可靠的问题，提升高风险场景下的信任度。

Method: VeriCoT将CoT推理步骤形式化为一阶逻辑，并利用自动化求解器验证逻辑有效性，同时通过NL前提支持人工和系统识别未接地或谬误推理步骤。

Result: VeriCoT能有效识别推理缺陷，并作为最终答案正确性的强预测指标，同时通过验证信号进一步优化推理有效性和准确性。

Conclusion: VeriCoT通过结合神经符号方法，有效验证并提升了LLMs的推理可靠性，并在多个数据集上证明了其有效性。

Abstract: LLMs can perform multi-step reasoning through Chain-of-Thought (CoT), but
they cannot reliably verify their own logic. Even when they reach correct
answers, the underlying reasoning may be flawed, undermining trust in
high-stakes scenarios. To mitigate this issue, we introduce VeriCoT, a
neuro-symbolic method that extracts and verifies formal logical arguments from
CoT reasoning. VeriCoT formalizes each CoT reasoning step into first-order
logic and identifies premises that ground the argument in source context,
commonsense knowledge, or prior reasoning steps. The symbolic representation
enables automated solvers to verify logical validity while the NL premises
allow humans and systems to identify ungrounded or fallacious reasoning steps.
Experiments on the ProofWriter, LegalBench, and BioASQ datasets show VeriCoT
effectively identifies flawed reasoning, and serves as a strong predictor of
final answer correctness. We also leverage VeriCoT's verification signal for
(1) inference-time self-reflection, (2) supervised fine-tuning (SFT) on
VeriCoT-distilled datasets and (3) preference fine-tuning (PFT) with direct
preference optimization (DPO) using verification-based pairwise rewards,
further improving reasoning validity and accuracy.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [143] [OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms](https://arxiv.org/abs/2511.03866)
*Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari*

Main category: cs.DC

TL;DR: OMPILOT是一种新型变换器模型，专为C++到OpenMP的代码翻译设计，通过混合学习策略和函数级语义捕捉，提升了翻译质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码翻译中表现出色，但现有方法主要关注循环级转换，缺乏对更广泛语义上下文的捕捉。

Method: OMPILOT 是一种针对C++代码转换为OpenMP的领域特定编码器-解码器变换器，采用定制预训练目标和混合学习策略。

Result: OMPILOT 在OpenMP并行构造的翻译中表现出高效性，并通过新提出的OMPBLEU指标验证了其正确性和质量。

Conclusion: OMPILOT 通过结合无监督和有监督学习策略，提升了代码翻译的鲁棒性，并在函数级别捕捉更广泛的语义上下文，显著优于传统循环级转换方法。

Abstract: Recent advances in large language models (LLMs) have significantly
accelerated progress in code translation, enabling more accurate and efficient
transformation across programming languages. While originally developed for
natural language processing, LLMs have shown strong capabilities in modeling
programming language syntax and semantics, outperforming traditional rule-based
systems in both accuracy and flexibility. These models have streamlined
cross-language conversion, reduced development overhead, and accelerated legacy
code migration. In this paper, we introduce OMPILOT, a novel domain-specific
encoder-decoder transformer tailored for translating C++ code into OpenMP,
enabling effective shared-memory parallelization. OMPILOT leverages custom
pre-training objectives that incorporate the semantics of parallel constructs
and combines both unsupervised and supervised learning strategies to improve
code translation robustness. Unlike previous work that focused primarily on
loop-level transformations, OMPILOT operates at the function level to capture a
wider semantic context. To evaluate our approach, we propose OMPBLEU, a novel
composite metric specifically crafted to assess the correctness and quality of
OpenMP parallel constructs, addressing limitations in conventional translation
metrics.

</details>


### [144] [Stochastic Modeling for Energy-Efficient Edge Infrastructure](https://arxiv.org/abs/2511.03941)
*Fabio Diniz Rossi*

Main category: cs.DC

TL;DR: 该论文提出基于马尔可夫链的随机建模方法，结合AI驱动的预测性功耗管理策略，显著提升边缘计算中的能源效率和系统响应速度。


<details>
  <summary>Details</summary>
Motivation: 边缘计算虽能实现低延迟处理，但其分布式特性和有限的能源资源带来了功耗管理挑战。

Method: 采用马尔可夫链的随机建模方法分析边缘计算中的功耗状态转换，结合蒙特卡洛模拟验证模型。

Result: 理论结果与实验数据高度一致，敏感性分析显示预测性缩放能最小化不必要的状态转换，提升整体功耗效率。

Conclusion: AI驱动的预测性功耗管理策略在边缘计算中显著提升了能源效率，通过预测工作负载需求并优化状态转换，减少了不必要的转换，提高了系统响应速度。

Abstract: Edge Computing enables low-latency processing for real-time applications but
introduces challenges in power management due to the distributed nature of edge
devices and their limited energy resources. This paper proposes a stochastic
modeling approach using Markov Chains to analyze power state transitions in
Edge Computing. By deriving steady-state probabilities and evaluating energy
consumption, we demonstrate the benefits of AI-driven predictive power scaling
over conventional reactive methods. Monte Carlo simulations validate the model,
showing strong alignment between theoretical and empirical results. Sensitivity
analysis highlights how varying transition probabilities affect power
efficiency, confirming that predictive scaling minimizes unnecessary
transitions and improves overall system responsiveness. Our findings suggest
that AI-based power management strategies significantly enhance energy
efficiency by anticipating workload demands and optimizing state transitions.
Experimental results indicate that AI-based power management optimizes workload
distribution across heterogeneous edge nodes, reducing energy consumption
disparities between devices, improving overall efficiency, and enhancing
adaptive power coordination in multi-node environments.

</details>


### [145] [Parallel Spawning Strategies for Dynamic-Aware MPI Applications](https://arxiv.org/abs/2511.04268)
*Iker Martín-Álvarez,José I. Aliaga,Maribel Castillo,Sergio Iserte*

Main category: cs.DC

TL;DR: 提出并行生成策略，降低动态资源管理成本，扩展和收缩操作效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 动态资源管理对高性能计算系统至关重要，但现有方法存在重新配置成本高或无法完全释放不需要的进程的问题。

Method: 采用并行生成策略，所有进程在重新分配前协作生成，减少执行时间，并消除收缩限制。

Result: 该策略在扩展操作中最多产生1.25倍开销，收缩操作成本降低至少20倍，适用于同构和异构系统。

Conclusion: 本文提出了一种新颖的并行生成策略，有效降低了动态资源管理中重新配置的成本，并在扩展和收缩操作中表现出色，适用于同构和异构系统。

Abstract: Dynamic resource management is an increasingly important capability of High
Performance Computing systems, as it enables jobs to adjust their resource
allocation at runtime. This capability has been shown to reduce workload
makespan, substantially decrease job waiting times and improve overall system
utilization. In this context, malleability refers to the ability of
applications to adapt to new resource allocations during execution. Although
beneficial, malleability incurs significant reconfiguration costs, making the
reduction of these costs an important research topic.
  Some existing methods for MPI applications respawn the entire application,
which is an expensive solution that avoids the reuse of original processes.
Other MPI methods reuse them, but fail to fully release unneeded processes when
shrinking, since some ranks within the same communicator remain active across
nodes, preventing the application from returning those nodes to the system.
This work overcomes both limitations by proposing a novel parallel spawning
strategy, in which all processes cooperate in spawning before redistribution,
thereby reducing execution time. Additionally, it removes shrinkage
limitations, allowing better adaptation of parallel systems to workload and
reducing their makespan. As a result, it preserves competitive expansion times
with at most a $1.25\times$ overhead, while enabling fast shrink operations
that reduce their cost by at least $20\times$. This strategy has been validated
on both homogeneous and heterogeneous systems and can also be applied in
shared-resource environments.

</details>


### [146] [Enabling Dynamic Sparsity in Quantized LLM Inference](https://arxiv.org/abs/2511.04477)
*Rongxiang Wang,Kangyuan Shu,Felix Xiaozhu Lin*

Main category: cs.DC

TL;DR: 该论文提出了一种结合动态稀疏推理和低比特量化的方法，通过优化量化布局和计算内核，显著提升了LLMs在资源受限硬件上的解码速度，同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 由于移动和桌面GPU的内存和计算能力有限，如何在资源受限的硬件上高效部署大型语言模型（LLMs）成为一个重要问题。动态稀疏性和量化技术的结合为解决这一问题提供了可能。

Method: 提出了一种锯齿状量化布局、专门设计的GEMV内核以及紧凑的运行时机制，以实现动态稀疏推理与低比特量化的结合。

Result: 在多种模型规模和硬件配置下，该方法实现了高达1.55倍的解码速度提升，同时保持了与密集量化推理相当的精度。

Conclusion: 该研究表明，通过特定的量化布局和优化的计算内核，动态稀疏推理可以与低比特量化有效结合，在保持精度的同时显著提升解码速度。

Abstract: Deploying large language models (LLMs) on end-user devices is gaining
importance due to benefits in responsiveness, privacy, and operational cost.
Yet the limited memory and compute capability of mobile and desktop GPUs make
efficient execution difficult. Recent observations suggest that the internal
activations of LLMs are often dynamically sparse, meaning that for each input,
only part of the network contributes significantly to the output. Such sparsity
could reduce computation, but it interacts poorly with group-wise quantization,
which remains the dominant approach for fitting LLMs onto resource-constrained
hardware. To reconcile these two properties, this study proposes a set of
techniques that realize dynamic sparse inference under low-bit quantization.
The method features: (1) a zigzag-patterned quantization layout that organizes
weights in a way consistent with activation sparsity and improves GPU memory
locality; (2) a specialized GEMV kernel designed for this layout to fully
utilize parallel compute units; and (3) a compact runtime mechanism that
gathers sparse indices with minimal overhead. Across several model scales and
hardware configurations, the approach achieves up to 1.55x faster decoding
throughput while maintaining accuracy comparable to dense quantized inference,
showing that structured sparsity and quantization can effectively coexist on
commodity GPUs.

</details>


### [147] [A New Probabilistic Mobile Byzantine Failure Model for Self-Protecting Systems](https://arxiv.org/abs/2511.04523)
*Silvia Bonomi,Giovanni Farina,Roy Friedman,Eviatar B. Procaccia,Sebastien Tixeuil*

Main category: cs.DC

TL;DR: 提出基于MAPE-K的自保护分布式系统模型，引入概率性MBF以动态反映攻击行为，通过数学和仿真分析验证系统在不同条件下的表现。


<details>
  <summary>Details</summary>
Motivation: 现代分布式系统面临的安全威胁日益复杂，传统拜占庭故障模型在反映现实攻击动态方面存在局限性。本文旨在提出一种更灵活的故障模型，以支持系统自保护和动态重构。

Method: 采用MAPE-K架构，设计新的概率性移动拜占庭故障（MBF）模型，并将其嵌入分析组件。通过数学分析和仿真实验评估系统在拜占庭节点数量变化和自恢复情况下的表现。

Result: 数学分析确定了拜占庭节点数量超过阈值或系统自恢复到安全状态的时间，仿真结果验证了模型在不同攻击与恢复速率下的有效性。

Conclusion: 本文提出了一种基于MAPE-K架构的自保护分布式系统模型，引入概率性移动拜占庭故障（MBF）以更准确地反映现实攻击动态。模型通过数学分析和仿真验证了系统在不同拜占庭感染率与自恢复率下的行为，为系统自保护策略提供了理论支持。

Abstract: Modern distributed systems face growing security threats, as attackers
continuously enhance their skills and vulnerabilities span across the entire
system stack, from hardware to the application layer. In the system design
phase, fault tolerance techniques can be employed to safeguard systems. From a
theoretical perspective, an attacker attempting to compromise a system can be
abstracted by considering the presence of Byzantine processes in the system.
Although this approach enhances the resilience of the distributed system, it
introduces certain limitations regarding the accuracy of the model in
reflecting real-world scenarios. In this paper, we consider a self-protecting
distributed system based on the \emph{Monitoring-Analyse-Plan-Execute over a
shared Knowledge} (MAPE-K) architecture, and we propose a new probabilistic
Mobile Byzantine Failure (MBF) that can be plugged into the Analysis component.
Our new model captures the dynamics of evolving attacks and can be used to
drive the self-protection and reconfiguration strategy. We analyze
mathematically the time that it takes until the number of Byzantine nodes
crosses given thresholds, or for the system to self-recover back into a safe
state, depending on the rates of Byzantine infection spreading \emph{vs.} the
rate of self-recovery. We also provide simulation results that illustrate the
behavior of the system under such assumptions.

</details>


### [148] [Resolving Conflicts with Grace: Dynamically Concurrent Universality](https://arxiv.org/abs/2511.04631)
*Petr Kuznetsov,Nathan Josia Schrodt*

Main category: cs.DC

TL;DR: 本文提出动态并发概念，通过仅在必要时使用强同步原语来优化分布式计算的扩展性。


<details>
  <summary>Details</summary>
Motivation: 分布式计算中的同步是扩展性的主要障碍，特别是在操作冲突仅在某些罕见状态下发生时，动态检测冲突可以显著提升效率。

Method: 提出了一个动态并发的通用构造方法，该方法根据当前系统状态动态调整同步需求。

Result: 通过动态并发方法，系统能够在需要仲裁时才使用强同步，从而优化了性能和可扩展性。

Conclusion: 动态并发性在分布式计算中通过仅在必要时使用强同步原语，显著提高了系统的可扩展性。

Abstract: Synchronization is the major obstacle to scalability in distributed
computing. Concurrent operations on the shared data engage in synchronization
when they encounter a \emph{conflict}, i.e., their effects depend on the order
in which they are applied. Ideally, one would like to detect conflicts in a
\emph{dynamic} manner, i.e., adjusting to the current system state. Indeed, it
is very common that two concurrent operations conflict only in some rarely
occurring states. In this paper, we define the notion of \emph{dynamic
concurrency}: an operation employs strong synchronization primitives only if it
\emph{has} to arbitrate with concurrent operations, given the current system
state. We then present a dynamically concurrent universal construction.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [149] [Hybrid Quantum-Classical Detection for RIS-Assisted SC-FDE via Grover Adaptive Search](https://arxiv.org/abs/2511.04173)
*Maryam Tariq,Omar Alhussein,Raneem Abdelraheem,Abdullah Quran,Georges Kaddoum,Sami Muhaidat*

Main category: cs.NI

TL;DR: 该论文提出了一种用于RIS辅助宽带通信的混合量子-经典检测框架，通过GAS和MMSE初始化实现高效检测，验证了其在6G网络中的可行性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 6G网络的宽带和低延迟需求要求检测器在不引入指数复杂度的情况下接近ML性能。

Method: 开发了一种混合量子-经典检测框架，将ML检测目标重新表述为QUBO问题，并通过GAS求解。引入了频率域MMSE阈值以加速收敛。

Result: 在理想情况下，检测器实现了接近最优的性能，并受益于Grover的二次加速。在噪声条件下，GAS电路的浅深度和MMSE初始化使去极化误差可忽略，读取误差仅引入适度退化。

Conclusion: 该研究证明了量子增强检测在RIS辅助宽带通信中的可行性，展示了算法可扩展性和6G网络的实用鲁棒性。

Abstract: Wideband and low-latency requirements in sixth-generation (6G) networks
demand detectors that approach maximum-likelihood (ML) performance without
incurring exponential complexity. This work develops a hybrid quantum-classical
detection framework for reconfigurable intelligent surface (RIS)-assisted
single-carrier (SC) frequency-domain equalization (FDE) over
frequency-selective channels. The ML detection objective is reformulated as a
quadratic unconstrained binary optimization (QUBO) problem and solved via
Grover adaptive search (GAS). To accelerate convergence, we introduce a
frequency-domain MMSE threshold that exploits the circulant structure of SC-FDE
channels, yielding low-complexity initialization. The framework is evaluated
across varying channel lengths and RIS sizes, confirming robustness and
scalability. In addition, GAS requirements are quantified through register
widths and gate counts, and its query complexity is analyzed to characterize
the algorithm's cost for block transmission in frequency-selective channels.
Quantum circuit simulations are conducted in Qiskit under both ideal and noisy
conditions. In the ideal case, the detector achieves near-optimal performance
while benefiting from Grover's quadratic speedup, reducing the search cost from
from O(M^N) exhaustive evaluations to O(SQRT(M^N)) oracle queries. Under noise,
the shallow depth of the GAS circuits, aided by MMSE initialization, makes
depolarizing errors negligible, while readout errors introduce moderate
degradation yet still preserve performance close to the MMSE baseline. These
results establish the feasibility of quantum-enhanced detection for
RIS-assisted broadband communications, highlighting both algorithmic
scalability and practical robustness for 6G networks.

</details>


### [150] [Improving dynamic congestion isolation in data-center networks](https://arxiv.org/abs/2511.04639)
*Alberto Merino,Jesus Escudero-Sahuquillo,Pedro Javier Garcia,Francisco J. Quiles*

Main category: cs.NI

TL;DR: 论文提出改进拥塞隔离（ICI）机制，结合CI和DCQCN，减少误报拥塞并提升网络性能。


<details>
  <summary>Details</summary>
Motivation: 分布式AI和大规模应用的兴起导致数据中心和超级计算机互连网络的通信操作受到影响，现有拥塞控制机制（如DCQCN和CI）在结合使用时存在误报拥塞、过度节流和资源利用率低等问题。

Method: ICI机制通过利用隔离的拥塞流信息来指导DCQCN的ECN标记，避免受害流被错误标记。

Result: 在不同流量模式（包括incast和数据中心工作负载）下评估，ICI将生成的BECN数量减少了32倍，尾部延迟改善了31%，同时保持了高吞吐量和可扩展性。

Conclusion: 论文提出了一种名为改进拥塞隔离（ICI）的新机制，有效结合了CI和DCQCN，减少了误报拥塞检测，提高了网络资源利用率和响应速度。

Abstract: The rise of distributed AI and large-scale applications has impacted the
communication operations of data-center and Supercomputer interconnection
networks, leading to dramatic incast or in-network congestion scenarios and
challenging existing congestion control mechanisms, such as injection
throttling (e.g., DCQCN) or congestion isolation (CI). While DCQCN provides a
scalable traffic rate adjustment for congesting flows at end nodes (which is
slow) and CI effectively isolates these flows in special network resources
(which requires extra logic in the switches), their combined use, although it
diminishes their particular drawbacks, leads to false congestion scenarios
identification and signaling, excessive throttling, and inefficient network
resource utilization. In this paper, we propose a new CI mechanism, called
Improved Congestion Isolation (ICI), which efficiently combines CI and DCQCN so
that the information of the isolated congesting flows is used to guide the ECN
marking performed by DCQCN in a way that victim flows do not end up being
marked. This coordination reduces false-positive congestion detection,
suppresses unnecessary closed-loop feedback (i.e., wrong congestion
notifications), and improves responsiveness to communication microbursts.
Evaluated under diverse traffic patterns, including incast and Data-center
workloads, ICI reduces the number of generated BECNs by up to 32x and improves
tail latency by up to 31%, while maintaining high throughput and scalability.

</details>
